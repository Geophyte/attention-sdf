{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 4.996717484863958,
  "eval_steps": 500,
  "global_step": 68500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0007294478080093369,
      "grad_norm": 0.4959447979927063,
      "learning_rate": 4.999270552191991e-05,
      "loss": 0.0046,
      "step": 10
    },
    {
      "epoch": 0.0014588956160186738,
      "grad_norm": 0.2919958531856537,
      "learning_rate": 4.998541104383981e-05,
      "loss": 0.0065,
      "step": 20
    },
    {
      "epoch": 0.0021883434240280108,
      "grad_norm": 0.46707943081855774,
      "learning_rate": 4.9978116565759725e-05,
      "loss": 0.0044,
      "step": 30
    },
    {
      "epoch": 0.0029177912320373475,
      "grad_norm": 0.08566362410783768,
      "learning_rate": 4.997082208767963e-05,
      "loss": 0.0069,
      "step": 40
    },
    {
      "epoch": 0.0036472390400466848,
      "grad_norm": 0.5266549587249756,
      "learning_rate": 4.996352760959953e-05,
      "loss": 0.0058,
      "step": 50
    },
    {
      "epoch": 0.0043766868480560215,
      "grad_norm": 0.030128000304102898,
      "learning_rate": 4.995623313151944e-05,
      "loss": 0.0067,
      "step": 60
    },
    {
      "epoch": 0.005106134656065358,
      "grad_norm": 0.5259796380996704,
      "learning_rate": 4.994893865343935e-05,
      "loss": 0.0066,
      "step": 70
    },
    {
      "epoch": 0.005835582464074695,
      "grad_norm": 0.22008076310157776,
      "learning_rate": 4.9941644175359256e-05,
      "loss": 0.0037,
      "step": 80
    },
    {
      "epoch": 0.006565030272084033,
      "grad_norm": 0.1177249401807785,
      "learning_rate": 4.9934349697279163e-05,
      "loss": 0.0051,
      "step": 90
    },
    {
      "epoch": 0.0072944780800933695,
      "grad_norm": 0.29232075810432434,
      "learning_rate": 4.992705521919907e-05,
      "loss": 0.0061,
      "step": 100
    },
    {
      "epoch": 0.008023925888102705,
      "grad_norm": 0.14591433107852936,
      "learning_rate": 4.991976074111898e-05,
      "loss": 0.0067,
      "step": 110
    },
    {
      "epoch": 0.008753373696112043,
      "grad_norm": 0.0601373091340065,
      "learning_rate": 4.991246626303888e-05,
      "loss": 0.0036,
      "step": 120
    },
    {
      "epoch": 0.00948282150412138,
      "grad_norm": 0.23339307308197021,
      "learning_rate": 4.990517178495879e-05,
      "loss": 0.0056,
      "step": 130
    },
    {
      "epoch": 0.010212269312130717,
      "grad_norm": 0.291879266500473,
      "learning_rate": 4.9897877306878694e-05,
      "loss": 0.0039,
      "step": 140
    },
    {
      "epoch": 0.010941717120140054,
      "grad_norm": 0.10865150392055511,
      "learning_rate": 4.98905828287986e-05,
      "loss": 0.0064,
      "step": 150
    },
    {
      "epoch": 0.01167116492814939,
      "grad_norm": 0.14634400606155396,
      "learning_rate": 4.988328835071851e-05,
      "loss": 0.0074,
      "step": 160
    },
    {
      "epoch": 0.012400612736158728,
      "grad_norm": 0.467959463596344,
      "learning_rate": 4.987599387263842e-05,
      "loss": 0.0059,
      "step": 170
    },
    {
      "epoch": 0.013130060544168065,
      "grad_norm": 0.05885517597198486,
      "learning_rate": 4.9868699394558324e-05,
      "loss": 0.0056,
      "step": 180
    },
    {
      "epoch": 0.013859508352177401,
      "grad_norm": 0.41020384430885315,
      "learning_rate": 4.9861404916478225e-05,
      "loss": 0.0059,
      "step": 190
    },
    {
      "epoch": 0.014588956160186739,
      "grad_norm": 0.5831130146980286,
      "learning_rate": 4.985411043839813e-05,
      "loss": 0.0044,
      "step": 200
    },
    {
      "epoch": 0.015318403968196075,
      "grad_norm": 0.4081030786037445,
      "learning_rate": 4.984681596031805e-05,
      "loss": 0.0043,
      "step": 210
    },
    {
      "epoch": 0.01604785177620541,
      "grad_norm": 0.40782174468040466,
      "learning_rate": 4.983952148223795e-05,
      "loss": 0.0062,
      "step": 220
    },
    {
      "epoch": 0.01677729958421475,
      "grad_norm": 0.2917938530445099,
      "learning_rate": 4.9832227004157855e-05,
      "loss": 0.0053,
      "step": 230
    },
    {
      "epoch": 0.017506747392224086,
      "grad_norm": 0.29188504815101624,
      "learning_rate": 4.982493252607776e-05,
      "loss": 0.0055,
      "step": 240
    },
    {
      "epoch": 0.018236195200233424,
      "grad_norm": 0.2635159492492676,
      "learning_rate": 4.9817638047997664e-05,
      "loss": 0.0058,
      "step": 250
    },
    {
      "epoch": 0.01896564300824276,
      "grad_norm": 0.29221072793006897,
      "learning_rate": 4.981034356991757e-05,
      "loss": 0.0085,
      "step": 260
    },
    {
      "epoch": 0.019695090816252096,
      "grad_norm": 0.004837053827941418,
      "learning_rate": 4.9803049091837485e-05,
      "loss": 0.0054,
      "step": 270
    },
    {
      "epoch": 0.020424538624261433,
      "grad_norm": 0.2921575605869293,
      "learning_rate": 4.9795754613757386e-05,
      "loss": 0.0056,
      "step": 280
    },
    {
      "epoch": 0.02115398643227077,
      "grad_norm": 0.06002217158675194,
      "learning_rate": 4.9788460135677294e-05,
      "loss": 0.0072,
      "step": 290
    },
    {
      "epoch": 0.02188343424028011,
      "grad_norm": 0.4656212627887726,
      "learning_rate": 4.97811656575972e-05,
      "loss": 0.0072,
      "step": 300
    },
    {
      "epoch": 0.022612882048289446,
      "grad_norm": 0.29171743988990784,
      "learning_rate": 4.977387117951711e-05,
      "loss": 0.0057,
      "step": 310
    },
    {
      "epoch": 0.02334232985629878,
      "grad_norm": 0.2044963836669922,
      "learning_rate": 4.976657670143701e-05,
      "loss": 0.0058,
      "step": 320
    },
    {
      "epoch": 0.024071777664308118,
      "grad_norm": 0.11735741049051285,
      "learning_rate": 4.9759282223356924e-05,
      "loss": 0.0053,
      "step": 330
    },
    {
      "epoch": 0.024801225472317456,
      "grad_norm": 0.4184667766094208,
      "learning_rate": 4.975198774527683e-05,
      "loss": 0.0053,
      "step": 340
    },
    {
      "epoch": 0.025530673280326793,
      "grad_norm": 0.43745237588882446,
      "learning_rate": 4.974469326719673e-05,
      "loss": 0.0063,
      "step": 350
    },
    {
      "epoch": 0.02626012108833613,
      "grad_norm": 0.17600108683109283,
      "learning_rate": 4.973739878911664e-05,
      "loss": 0.006,
      "step": 360
    },
    {
      "epoch": 0.026989568896345465,
      "grad_norm": 0.10038230568170547,
      "learning_rate": 4.973010431103655e-05,
      "loss": 0.0073,
      "step": 370
    },
    {
      "epoch": 0.027719016704354803,
      "grad_norm": 0.007238632533699274,
      "learning_rate": 4.9722809832956455e-05,
      "loss": 0.0058,
      "step": 380
    },
    {
      "epoch": 0.02844846451236414,
      "grad_norm": 0.23467884957790375,
      "learning_rate": 4.971551535487636e-05,
      "loss": 0.005,
      "step": 390
    },
    {
      "epoch": 0.029177912320373478,
      "grad_norm": 0.11692598462104797,
      "learning_rate": 4.970822087679627e-05,
      "loss": 0.0066,
      "step": 400
    },
    {
      "epoch": 0.029907360128382816,
      "grad_norm": 0.05949326977133751,
      "learning_rate": 4.970092639871618e-05,
      "loss": 0.0066,
      "step": 410
    },
    {
      "epoch": 0.03063680793639215,
      "grad_norm": 0.46840494871139526,
      "learning_rate": 4.969363192063608e-05,
      "loss": 0.0054,
      "step": 420
    },
    {
      "epoch": 0.03136625574440149,
      "grad_norm": 0.3507060706615448,
      "learning_rate": 4.9686337442555986e-05,
      "loss": 0.0071,
      "step": 430
    },
    {
      "epoch": 0.03209570355241082,
      "grad_norm": 0.11769913136959076,
      "learning_rate": 4.967904296447589e-05,
      "loss": 0.0062,
      "step": 440
    },
    {
      "epoch": 0.03282515136042016,
      "grad_norm": 0.14606843888759613,
      "learning_rate": 4.96717484863958e-05,
      "loss": 0.0043,
      "step": 450
    },
    {
      "epoch": 0.0335545991684295,
      "grad_norm": 0.17522850632667542,
      "learning_rate": 4.966445400831571e-05,
      "loss": 0.0055,
      "step": 460
    },
    {
      "epoch": 0.03428404697643884,
      "grad_norm": 0.058844372630119324,
      "learning_rate": 4.9657159530235616e-05,
      "loss": 0.0068,
      "step": 470
    },
    {
      "epoch": 0.03501349478444817,
      "grad_norm": 0.40829700231552124,
      "learning_rate": 4.9649865052155516e-05,
      "loss": 0.0055,
      "step": 480
    },
    {
      "epoch": 0.035742942592457506,
      "grad_norm": 0.4661199748516083,
      "learning_rate": 4.9642570574075424e-05,
      "loss": 0.0067,
      "step": 490
    },
    {
      "epoch": 0.03647239040046685,
      "grad_norm": 0.34953317046165466,
      "learning_rate": 4.963527609599534e-05,
      "loss": 0.0046,
      "step": 500
    },
    {
      "epoch": 0.03720183820847618,
      "grad_norm": 0.08813738822937012,
      "learning_rate": 4.962798161791524e-05,
      "loss": 0.0038,
      "step": 510
    },
    {
      "epoch": 0.03793128601648552,
      "grad_norm": 0.05870756879448891,
      "learning_rate": 4.9620687139835147e-05,
      "loss": 0.0044,
      "step": 520
    },
    {
      "epoch": 0.03866073382449486,
      "grad_norm": 0.0587180033326149,
      "learning_rate": 4.9613392661755054e-05,
      "loss": 0.0075,
      "step": 530
    },
    {
      "epoch": 0.03939018163250419,
      "grad_norm": 0.11769350618124008,
      "learning_rate": 4.960609818367496e-05,
      "loss": 0.0047,
      "step": 540
    },
    {
      "epoch": 0.04011962944051353,
      "grad_norm": 0.11665533483028412,
      "learning_rate": 4.959880370559486e-05,
      "loss": 0.0075,
      "step": 550
    },
    {
      "epoch": 0.040849077248522866,
      "grad_norm": 0.4965839087963104,
      "learning_rate": 4.959150922751478e-05,
      "loss": 0.007,
      "step": 560
    },
    {
      "epoch": 0.04157852505653221,
      "grad_norm": 0.23426122963428497,
      "learning_rate": 4.9584214749434684e-05,
      "loss": 0.0058,
      "step": 570
    },
    {
      "epoch": 0.04230797286454154,
      "grad_norm": 0.17566081881523132,
      "learning_rate": 4.9576920271354585e-05,
      "loss": 0.0066,
      "step": 580
    },
    {
      "epoch": 0.043037420672550876,
      "grad_norm": 0.23862197995185852,
      "learning_rate": 4.956962579327449e-05,
      "loss": 0.0054,
      "step": 590
    },
    {
      "epoch": 0.04376686848056022,
      "grad_norm": 0.17546583712100983,
      "learning_rate": 4.95623313151944e-05,
      "loss": 0.0057,
      "step": 600
    },
    {
      "epoch": 0.04449631628856955,
      "grad_norm": 0.26342666149139404,
      "learning_rate": 4.955503683711431e-05,
      "loss": 0.0066,
      "step": 610
    },
    {
      "epoch": 0.04522576409657889,
      "grad_norm": 0.3216160237789154,
      "learning_rate": 4.9547742359034215e-05,
      "loss": 0.0068,
      "step": 620
    },
    {
      "epoch": 0.045955211904588227,
      "grad_norm": 0.23362214863300323,
      "learning_rate": 4.954044788095412e-05,
      "loss": 0.0044,
      "step": 630
    },
    {
      "epoch": 0.04668465971259756,
      "grad_norm": 0.7586060166358948,
      "learning_rate": 4.953315340287403e-05,
      "loss": 0.0048,
      "step": 640
    },
    {
      "epoch": 0.0474141075206069,
      "grad_norm": 0.007377599831670523,
      "learning_rate": 4.952585892479393e-05,
      "loss": 0.0059,
      "step": 650
    },
    {
      "epoch": 0.048143555328616236,
      "grad_norm": 0.11723652482032776,
      "learning_rate": 4.951856444671384e-05,
      "loss": 0.0056,
      "step": 660
    },
    {
      "epoch": 0.04887300313662558,
      "grad_norm": 0.0878911241889,
      "learning_rate": 4.9511269968633746e-05,
      "loss": 0.0046,
      "step": 670
    },
    {
      "epoch": 0.04960245094463491,
      "grad_norm": 0.3208949565887451,
      "learning_rate": 4.9503975490553653e-05,
      "loss": 0.0083,
      "step": 680
    },
    {
      "epoch": 0.050331898752644245,
      "grad_norm": 0.23316289484500885,
      "learning_rate": 4.949668101247356e-05,
      "loss": 0.0063,
      "step": 690
    },
    {
      "epoch": 0.05106134656065359,
      "grad_norm": 0.2917242646217346,
      "learning_rate": 4.948938653439347e-05,
      "loss": 0.0051,
      "step": 700
    },
    {
      "epoch": 0.05179079436866292,
      "grad_norm": 0.2920700013637543,
      "learning_rate": 4.9482092056313376e-05,
      "loss": 0.0058,
      "step": 710
    },
    {
      "epoch": 0.05252024217667226,
      "grad_norm": 0.058934640139341354,
      "learning_rate": 4.947479757823328e-05,
      "loss": 0.0078,
      "step": 720
    },
    {
      "epoch": 0.053249689984681596,
      "grad_norm": 0.14591769874095917,
      "learning_rate": 4.9467503100153184e-05,
      "loss": 0.0057,
      "step": 730
    },
    {
      "epoch": 0.05397913779269093,
      "grad_norm": 0.05864318087697029,
      "learning_rate": 4.94602086220731e-05,
      "loss": 0.0063,
      "step": 740
    },
    {
      "epoch": 0.05470858560070027,
      "grad_norm": 0.11786993592977524,
      "learning_rate": 4.9452914143993e-05,
      "loss": 0.0067,
      "step": 750
    },
    {
      "epoch": 0.055438033408709605,
      "grad_norm": 0.24626821279525757,
      "learning_rate": 4.944561966591291e-05,
      "loss": 0.0042,
      "step": 760
    },
    {
      "epoch": 0.05616748121671895,
      "grad_norm": 0.030030693858861923,
      "learning_rate": 4.9438325187832814e-05,
      "loss": 0.0049,
      "step": 770
    },
    {
      "epoch": 0.05689692902472828,
      "grad_norm": 0.3211776912212372,
      "learning_rate": 4.9431030709752715e-05,
      "loss": 0.0051,
      "step": 780
    },
    {
      "epoch": 0.057626376832737615,
      "grad_norm": 0.11734523624181747,
      "learning_rate": 4.942373623167262e-05,
      "loss": 0.0071,
      "step": 790
    },
    {
      "epoch": 0.058355824640746956,
      "grad_norm": 0.11696411669254303,
      "learning_rate": 4.941644175359254e-05,
      "loss": 0.0058,
      "step": 800
    },
    {
      "epoch": 0.05908527244875629,
      "grad_norm": 0.007687684148550034,
      "learning_rate": 4.940914727551244e-05,
      "loss": 0.0062,
      "step": 810
    },
    {
      "epoch": 0.05981472025676563,
      "grad_norm": 0.11726632714271545,
      "learning_rate": 4.9401852797432345e-05,
      "loss": 0.0055,
      "step": 820
    },
    {
      "epoch": 0.060544168064774966,
      "grad_norm": 0.23391778767108917,
      "learning_rate": 4.939455831935225e-05,
      "loss": 0.0049,
      "step": 830
    },
    {
      "epoch": 0.0612736158727843,
      "grad_norm": 0.23341992497444153,
      "learning_rate": 4.938726384127216e-05,
      "loss": 0.0043,
      "step": 840
    },
    {
      "epoch": 0.06200306368079364,
      "grad_norm": 0.1757362335920334,
      "learning_rate": 4.937996936319206e-05,
      "loss": 0.007,
      "step": 850
    },
    {
      "epoch": 0.06273251148880298,
      "grad_norm": 0.2925108075141907,
      "learning_rate": 4.9372674885111975e-05,
      "loss": 0.0062,
      "step": 860
    },
    {
      "epoch": 0.06346195929681231,
      "grad_norm": 0.3512793779373169,
      "learning_rate": 4.936538040703188e-05,
      "loss": 0.0063,
      "step": 870
    },
    {
      "epoch": 0.06419140710482164,
      "grad_norm": 0.2340078353881836,
      "learning_rate": 4.9358085928951784e-05,
      "loss": 0.0046,
      "step": 880
    },
    {
      "epoch": 0.06492085491283099,
      "grad_norm": 0.2925705015659332,
      "learning_rate": 4.935079145087169e-05,
      "loss": 0.0053,
      "step": 890
    },
    {
      "epoch": 0.06565030272084033,
      "grad_norm": 0.05856842175126076,
      "learning_rate": 4.93434969727916e-05,
      "loss": 0.0063,
      "step": 900
    },
    {
      "epoch": 0.06637975052884966,
      "grad_norm": 0.030165432021021843,
      "learning_rate": 4.9336202494711506e-05,
      "loss": 0.006,
      "step": 910
    },
    {
      "epoch": 0.067109198336859,
      "grad_norm": 0.145916149020195,
      "learning_rate": 4.9328908016631414e-05,
      "loss": 0.0034,
      "step": 920
    },
    {
      "epoch": 0.06783864614486833,
      "grad_norm": 0.4444158673286438,
      "learning_rate": 4.932161353855132e-05,
      "loss": 0.0076,
      "step": 930
    },
    {
      "epoch": 0.06856809395287768,
      "grad_norm": 0.11600077897310257,
      "learning_rate": 4.931431906047123e-05,
      "loss": 0.0045,
      "step": 940
    },
    {
      "epoch": 0.06929754176088701,
      "grad_norm": 0.11683298647403717,
      "learning_rate": 4.930702458239113e-05,
      "loss": 0.0053,
      "step": 950
    },
    {
      "epoch": 0.07002698956889634,
      "grad_norm": 0.2366022765636444,
      "learning_rate": 4.929973010431104e-05,
      "loss": 0.0078,
      "step": 960
    },
    {
      "epoch": 0.07075643737690568,
      "grad_norm": 0.4796743094921112,
      "learning_rate": 4.9292435626230945e-05,
      "loss": 0.0074,
      "step": 970
    },
    {
      "epoch": 0.07148588518491501,
      "grad_norm": 0.7575341463088989,
      "learning_rate": 4.928514114815085e-05,
      "loss": 0.0057,
      "step": 980
    },
    {
      "epoch": 0.07221533299292436,
      "grad_norm": 0.1743050515651703,
      "learning_rate": 4.927784667007076e-05,
      "loss": 0.0073,
      "step": 990
    },
    {
      "epoch": 0.0729447808009337,
      "grad_norm": 0.29104146361351013,
      "learning_rate": 4.927055219199067e-05,
      "loss": 0.0075,
      "step": 1000
    },
    {
      "epoch": 0.07367422860894303,
      "grad_norm": 0.030019426718354225,
      "learning_rate": 4.926325771391057e-05,
      "loss": 0.0051,
      "step": 1010
    },
    {
      "epoch": 0.07440367641695236,
      "grad_norm": 0.292317271232605,
      "learning_rate": 4.9255963235830476e-05,
      "loss": 0.0041,
      "step": 1020
    },
    {
      "epoch": 0.0751331242249617,
      "grad_norm": 0.23312288522720337,
      "learning_rate": 4.924866875775039e-05,
      "loss": 0.0051,
      "step": 1030
    },
    {
      "epoch": 0.07586257203297105,
      "grad_norm": 0.1747107207775116,
      "learning_rate": 4.924137427967029e-05,
      "loss": 0.0035,
      "step": 1040
    },
    {
      "epoch": 0.07659201984098038,
      "grad_norm": 0.1720217615365982,
      "learning_rate": 4.92340798015902e-05,
      "loss": 0.0061,
      "step": 1050
    },
    {
      "epoch": 0.07732146764898971,
      "grad_norm": 0.01254357397556305,
      "learning_rate": 4.9226785323510106e-05,
      "loss": 0.0065,
      "step": 1060
    },
    {
      "epoch": 0.07805091545699905,
      "grad_norm": 0.5520982146263123,
      "learning_rate": 4.921949084543001e-05,
      "loss": 0.0047,
      "step": 1070
    },
    {
      "epoch": 0.07878036326500838,
      "grad_norm": 0.05775061994791031,
      "learning_rate": 4.9212196367349914e-05,
      "loss": 0.0055,
      "step": 1080
    },
    {
      "epoch": 0.07950981107301773,
      "grad_norm": 0.08752068877220154,
      "learning_rate": 4.920490188926983e-05,
      "loss": 0.0073,
      "step": 1090
    },
    {
      "epoch": 0.08023925888102706,
      "grad_norm": 0.2332867830991745,
      "learning_rate": 4.9197607411189736e-05,
      "loss": 0.0061,
      "step": 1100
    },
    {
      "epoch": 0.0809687066890364,
      "grad_norm": 0.24470092356204987,
      "learning_rate": 4.9190312933109637e-05,
      "loss": 0.0048,
      "step": 1110
    },
    {
      "epoch": 0.08169815449704573,
      "grad_norm": 0.3059571087360382,
      "learning_rate": 4.9183018455029544e-05,
      "loss": 0.0072,
      "step": 1120
    },
    {
      "epoch": 0.08242760230505507,
      "grad_norm": 0.1745973825454712,
      "learning_rate": 4.917572397694945e-05,
      "loss": 0.006,
      "step": 1130
    },
    {
      "epoch": 0.08315705011306442,
      "grad_norm": 0.14531442523002625,
      "learning_rate": 4.916842949886936e-05,
      "loss": 0.0075,
      "step": 1140
    },
    {
      "epoch": 0.08388649792107375,
      "grad_norm": 0.010747483000159264,
      "learning_rate": 4.916113502078927e-05,
      "loss": 0.0057,
      "step": 1150
    },
    {
      "epoch": 0.08461594572908308,
      "grad_norm": 0.3778955042362213,
      "learning_rate": 4.9153840542709174e-05,
      "loss": 0.0072,
      "step": 1160
    },
    {
      "epoch": 0.08534539353709242,
      "grad_norm": 0.17535164952278137,
      "learning_rate": 4.914654606462908e-05,
      "loss": 0.0074,
      "step": 1170
    },
    {
      "epoch": 0.08607484134510175,
      "grad_norm": 0.29182085394859314,
      "learning_rate": 4.913925158654898e-05,
      "loss": 0.0032,
      "step": 1180
    },
    {
      "epoch": 0.0868042891531111,
      "grad_norm": 0.013794946484267712,
      "learning_rate": 4.913195710846889e-05,
      "loss": 0.0058,
      "step": 1190
    },
    {
      "epoch": 0.08753373696112043,
      "grad_norm": 0.16550631821155548,
      "learning_rate": 4.91246626303888e-05,
      "loss": 0.0082,
      "step": 1200
    },
    {
      "epoch": 0.08826318476912977,
      "grad_norm": 0.008596633560955524,
      "learning_rate": 4.9117368152308705e-05,
      "loss": 0.005,
      "step": 1210
    },
    {
      "epoch": 0.0889926325771391,
      "grad_norm": 0.5260468125343323,
      "learning_rate": 4.911007367422861e-05,
      "loss": 0.0062,
      "step": 1220
    },
    {
      "epoch": 0.08972208038514844,
      "grad_norm": 0.05824274569749832,
      "learning_rate": 4.910277919614852e-05,
      "loss": 0.0071,
      "step": 1230
    },
    {
      "epoch": 0.09045152819315778,
      "grad_norm": 0.11669550836086273,
      "learning_rate": 4.909548471806842e-05,
      "loss": 0.0057,
      "step": 1240
    },
    {
      "epoch": 0.09118097600116712,
      "grad_norm": 0.3786262273788452,
      "learning_rate": 4.908819023998833e-05,
      "loss": 0.0063,
      "step": 1250
    },
    {
      "epoch": 0.09191042380917645,
      "grad_norm": 0.6992634534835815,
      "learning_rate": 4.9080895761908236e-05,
      "loss": 0.007,
      "step": 1260
    },
    {
      "epoch": 0.09263987161718579,
      "grad_norm": 0.11726284772157669,
      "learning_rate": 4.9073601283828144e-05,
      "loss": 0.0052,
      "step": 1270
    },
    {
      "epoch": 0.09336931942519512,
      "grad_norm": 0.17486093938350677,
      "learning_rate": 4.906630680574805e-05,
      "loss": 0.0058,
      "step": 1280
    },
    {
      "epoch": 0.09409876723320447,
      "grad_norm": 0.14643433690071106,
      "learning_rate": 4.905901232766796e-05,
      "loss": 0.0069,
      "step": 1290
    },
    {
      "epoch": 0.0948282150412138,
      "grad_norm": 0.46684548258781433,
      "learning_rate": 4.9051717849587866e-05,
      "loss": 0.0081,
      "step": 1300
    },
    {
      "epoch": 0.09555766284922314,
      "grad_norm": 0.09498345851898193,
      "learning_rate": 4.904442337150777e-05,
      "loss": 0.0067,
      "step": 1310
    },
    {
      "epoch": 0.09628711065723247,
      "grad_norm": 0.17480359971523285,
      "learning_rate": 4.9037128893427674e-05,
      "loss": 0.0052,
      "step": 1320
    },
    {
      "epoch": 0.0970165584652418,
      "grad_norm": 0.23324252665042877,
      "learning_rate": 4.902983441534759e-05,
      "loss": 0.0072,
      "step": 1330
    },
    {
      "epoch": 0.09774600627325115,
      "grad_norm": 0.006036808248609304,
      "learning_rate": 4.902253993726749e-05,
      "loss": 0.0066,
      "step": 1340
    },
    {
      "epoch": 0.09847545408126049,
      "grad_norm": 0.1167336031794548,
      "learning_rate": 4.90152454591874e-05,
      "loss": 0.0057,
      "step": 1350
    },
    {
      "epoch": 0.09920490188926982,
      "grad_norm": 0.059482671320438385,
      "learning_rate": 4.9007950981107304e-05,
      "loss": 0.0049,
      "step": 1360
    },
    {
      "epoch": 0.09993434969727916,
      "grad_norm": 0.20415979623794556,
      "learning_rate": 4.900065650302721e-05,
      "loss": 0.0059,
      "step": 1370
    },
    {
      "epoch": 0.10066379750528849,
      "grad_norm": 0.2917343080043793,
      "learning_rate": 4.899336202494711e-05,
      "loss": 0.0073,
      "step": 1380
    },
    {
      "epoch": 0.10139324531329784,
      "grad_norm": 0.5517444014549255,
      "learning_rate": 4.898606754686703e-05,
      "loss": 0.0047,
      "step": 1390
    },
    {
      "epoch": 0.10212269312130717,
      "grad_norm": 0.3184983730316162,
      "learning_rate": 4.8978773068786935e-05,
      "loss": 0.005,
      "step": 1400
    },
    {
      "epoch": 0.10285214092931651,
      "grad_norm": 0.20600010454654694,
      "learning_rate": 4.8971478590706835e-05,
      "loss": 0.0054,
      "step": 1410
    },
    {
      "epoch": 0.10358158873732584,
      "grad_norm": 0.08842317759990692,
      "learning_rate": 4.896418411262674e-05,
      "loss": 0.0052,
      "step": 1420
    },
    {
      "epoch": 0.10431103654533518,
      "grad_norm": 0.08761046081781387,
      "learning_rate": 4.895688963454665e-05,
      "loss": 0.0041,
      "step": 1430
    },
    {
      "epoch": 0.10504048435334452,
      "grad_norm": 0.29264330863952637,
      "learning_rate": 4.894959515646655e-05,
      "loss": 0.0064,
      "step": 1440
    },
    {
      "epoch": 0.10576993216135386,
      "grad_norm": 0.06356872618198395,
      "learning_rate": 4.8942300678386465e-05,
      "loss": 0.0086,
      "step": 1450
    },
    {
      "epoch": 0.10649937996936319,
      "grad_norm": 0.4667302370071411,
      "learning_rate": 4.893500620030637e-05,
      "loss": 0.0048,
      "step": 1460
    },
    {
      "epoch": 0.10722882777737253,
      "grad_norm": 0.17701077461242676,
      "learning_rate": 4.8927711722226274e-05,
      "loss": 0.0045,
      "step": 1470
    },
    {
      "epoch": 0.10795827558538186,
      "grad_norm": 0.26198023557662964,
      "learning_rate": 4.892041724414618e-05,
      "loss": 0.0071,
      "step": 1480
    },
    {
      "epoch": 0.10868772339339121,
      "grad_norm": 0.2917776107788086,
      "learning_rate": 4.891312276606609e-05,
      "loss": 0.0055,
      "step": 1490
    },
    {
      "epoch": 0.10941717120140054,
      "grad_norm": 0.0606439970433712,
      "learning_rate": 4.8905828287985996e-05,
      "loss": 0.0086,
      "step": 1500
    },
    {
      "epoch": 0.11014661900940988,
      "grad_norm": 0.2619077265262604,
      "learning_rate": 4.8898533809905904e-05,
      "loss": 0.0027,
      "step": 1510
    },
    {
      "epoch": 0.11087606681741921,
      "grad_norm": 0.11705285310745239,
      "learning_rate": 4.889123933182581e-05,
      "loss": 0.0047,
      "step": 1520
    },
    {
      "epoch": 0.11160551462542855,
      "grad_norm": 0.11674080044031143,
      "learning_rate": 4.888394485374572e-05,
      "loss": 0.0044,
      "step": 1530
    },
    {
      "epoch": 0.1123349624334379,
      "grad_norm": 0.6415249109268188,
      "learning_rate": 4.887665037566562e-05,
      "loss": 0.0042,
      "step": 1540
    },
    {
      "epoch": 0.11306441024144723,
      "grad_norm": 0.05890027806162834,
      "learning_rate": 4.886935589758553e-05,
      "loss": 0.0056,
      "step": 1550
    },
    {
      "epoch": 0.11379385804945656,
      "grad_norm": 0.05865192040801048,
      "learning_rate": 4.886206141950544e-05,
      "loss": 0.0068,
      "step": 1560
    },
    {
      "epoch": 0.1145233058574659,
      "grad_norm": 0.3652675449848175,
      "learning_rate": 4.885476694142534e-05,
      "loss": 0.0058,
      "step": 1570
    },
    {
      "epoch": 0.11525275366547523,
      "grad_norm": 0.06036834418773651,
      "learning_rate": 4.884747246334525e-05,
      "loss": 0.0055,
      "step": 1580
    },
    {
      "epoch": 0.11598220147348458,
      "grad_norm": 0.34940460324287415,
      "learning_rate": 4.884017798526516e-05,
      "loss": 0.0046,
      "step": 1590
    },
    {
      "epoch": 0.11671164928149391,
      "grad_norm": 0.23258866369724274,
      "learning_rate": 4.8832883507185065e-05,
      "loss": 0.0067,
      "step": 1600
    },
    {
      "epoch": 0.11744109708950325,
      "grad_norm": 0.233718603849411,
      "learning_rate": 4.8825589029104966e-05,
      "loss": 0.0062,
      "step": 1610
    },
    {
      "epoch": 0.11817054489751258,
      "grad_norm": 0.17553365230560303,
      "learning_rate": 4.881829455102488e-05,
      "loss": 0.0067,
      "step": 1620
    },
    {
      "epoch": 0.11889999270552191,
      "grad_norm": 0.6994196772575378,
      "learning_rate": 4.881100007294479e-05,
      "loss": 0.0075,
      "step": 1630
    },
    {
      "epoch": 0.11962944051353126,
      "grad_norm": 0.29126492142677307,
      "learning_rate": 4.880370559486469e-05,
      "loss": 0.0079,
      "step": 1640
    },
    {
      "epoch": 0.1203588883215406,
      "grad_norm": 0.059228986501693726,
      "learning_rate": 4.8796411116784596e-05,
      "loss": 0.0061,
      "step": 1650
    },
    {
      "epoch": 0.12108833612954993,
      "grad_norm": 0.11748085916042328,
      "learning_rate": 4.87891166387045e-05,
      "loss": 0.006,
      "step": 1660
    },
    {
      "epoch": 0.12181778393755927,
      "grad_norm": 0.1757877916097641,
      "learning_rate": 4.878182216062441e-05,
      "loss": 0.0064,
      "step": 1670
    },
    {
      "epoch": 0.1225472317455686,
      "grad_norm": 0.11752160638570786,
      "learning_rate": 4.877452768254432e-05,
      "loss": 0.0049,
      "step": 1680
    },
    {
      "epoch": 0.12327667955357795,
      "grad_norm": 0.17606276273727417,
      "learning_rate": 4.8767233204464226e-05,
      "loss": 0.0067,
      "step": 1690
    },
    {
      "epoch": 0.12400612736158728,
      "grad_norm": 0.059037670493125916,
      "learning_rate": 4.8759938726384133e-05,
      "loss": 0.006,
      "step": 1700
    },
    {
      "epoch": 0.12473557516959662,
      "grad_norm": 0.17590732872486115,
      "learning_rate": 4.8752644248304034e-05,
      "loss": 0.0049,
      "step": 1710
    },
    {
      "epoch": 0.12546502297760595,
      "grad_norm": 0.29131823778152466,
      "learning_rate": 4.874534977022394e-05,
      "loss": 0.005,
      "step": 1720
    },
    {
      "epoch": 0.1261944707856153,
      "grad_norm": 0.1665264070034027,
      "learning_rate": 4.873805529214385e-05,
      "loss": 0.005,
      "step": 1730
    },
    {
      "epoch": 0.12692391859362462,
      "grad_norm": 0.1759137064218521,
      "learning_rate": 4.873076081406376e-05,
      "loss": 0.0067,
      "step": 1740
    },
    {
      "epoch": 0.12765336640163397,
      "grad_norm": 0.17652755975723267,
      "learning_rate": 4.8723466335983664e-05,
      "loss": 0.0054,
      "step": 1750
    },
    {
      "epoch": 0.1283828142096433,
      "grad_norm": 0.11668188869953156,
      "learning_rate": 4.871617185790357e-05,
      "loss": 0.0055,
      "step": 1760
    },
    {
      "epoch": 0.12911226201765263,
      "grad_norm": 0.06042330339550972,
      "learning_rate": 4.870887737982347e-05,
      "loss": 0.007,
      "step": 1770
    },
    {
      "epoch": 0.12984170982566198,
      "grad_norm": 0.17503425478935242,
      "learning_rate": 4.870158290174338e-05,
      "loss": 0.0051,
      "step": 1780
    },
    {
      "epoch": 0.1305711576336713,
      "grad_norm": 0.5826699733734131,
      "learning_rate": 4.869428842366329e-05,
      "loss": 0.0074,
      "step": 1790
    },
    {
      "epoch": 0.13130060544168065,
      "grad_norm": 0.17585179209709167,
      "learning_rate": 4.8686993945583195e-05,
      "loss": 0.0066,
      "step": 1800
    },
    {
      "epoch": 0.13203005324968997,
      "grad_norm": 0.05889538303017616,
      "learning_rate": 4.86796994675031e-05,
      "loss": 0.0056,
      "step": 1810
    },
    {
      "epoch": 0.13275950105769932,
      "grad_norm": 0.05895541235804558,
      "learning_rate": 4.867240498942301e-05,
      "loss": 0.005,
      "step": 1820
    },
    {
      "epoch": 0.13348894886570867,
      "grad_norm": 0.466652512550354,
      "learning_rate": 4.866511051134292e-05,
      "loss": 0.0051,
      "step": 1830
    },
    {
      "epoch": 0.134218396673718,
      "grad_norm": 0.2917540371417999,
      "learning_rate": 4.865781603326282e-05,
      "loss": 0.007,
      "step": 1840
    },
    {
      "epoch": 0.13494784448172734,
      "grad_norm": 0.11820033937692642,
      "learning_rate": 4.8650521555182726e-05,
      "loss": 0.0054,
      "step": 1850
    },
    {
      "epoch": 0.13567729228973666,
      "grad_norm": 0.407842218875885,
      "learning_rate": 4.864322707710264e-05,
      "loss": 0.0058,
      "step": 1860
    },
    {
      "epoch": 0.136406740097746,
      "grad_norm": 0.11671601980924606,
      "learning_rate": 4.863593259902254e-05,
      "loss": 0.0053,
      "step": 1870
    },
    {
      "epoch": 0.13713618790575535,
      "grad_norm": 0.29122495651245117,
      "learning_rate": 4.862863812094245e-05,
      "loss": 0.0061,
      "step": 1880
    },
    {
      "epoch": 0.13786563571376467,
      "grad_norm": 0.13926641643047333,
      "learning_rate": 4.8621343642862356e-05,
      "loss": 0.0041,
      "step": 1890
    },
    {
      "epoch": 0.13859508352177402,
      "grad_norm": 0.29513078927993774,
      "learning_rate": 4.8614049164782264e-05,
      "loss": 0.007,
      "step": 1900
    },
    {
      "epoch": 0.13932453132978334,
      "grad_norm": 0.11811625212430954,
      "learning_rate": 4.8606754686702164e-05,
      "loss": 0.0062,
      "step": 1910
    },
    {
      "epoch": 0.1400539791377927,
      "grad_norm": 0.23286627233028412,
      "learning_rate": 4.859946020862208e-05,
      "loss": 0.0042,
      "step": 1920
    },
    {
      "epoch": 0.14078342694580204,
      "grad_norm": 0.11682965606451035,
      "learning_rate": 4.8592165730541986e-05,
      "loss": 0.0036,
      "step": 1930
    },
    {
      "epoch": 0.14151287475381136,
      "grad_norm": 0.14661625027656555,
      "learning_rate": 4.858487125246189e-05,
      "loss": 0.0047,
      "step": 1940
    },
    {
      "epoch": 0.1422423225618207,
      "grad_norm": 0.19573460519313812,
      "learning_rate": 4.8577576774381795e-05,
      "loss": 0.0065,
      "step": 1950
    },
    {
      "epoch": 0.14297177036983003,
      "grad_norm": 0.29224497079849243,
      "learning_rate": 4.85702822963017e-05,
      "loss": 0.0052,
      "step": 1960
    },
    {
      "epoch": 0.14370121817783937,
      "grad_norm": 0.08756853640079498,
      "learning_rate": 4.85629878182216e-05,
      "loss": 0.0047,
      "step": 1970
    },
    {
      "epoch": 0.14443066598584872,
      "grad_norm": 0.20472382009029388,
      "learning_rate": 4.855569334014152e-05,
      "loss": 0.0058,
      "step": 1980
    },
    {
      "epoch": 0.14516011379385804,
      "grad_norm": 0.29116979241371155,
      "learning_rate": 4.8548398862061425e-05,
      "loss": 0.0068,
      "step": 1990
    },
    {
      "epoch": 0.1458895616018674,
      "grad_norm": 0.11720287799835205,
      "learning_rate": 4.8541104383981325e-05,
      "loss": 0.0061,
      "step": 2000
    },
    {
      "epoch": 0.1466190094098767,
      "grad_norm": 0.29355013370513916,
      "learning_rate": 4.853380990590123e-05,
      "loss": 0.0049,
      "step": 2010
    },
    {
      "epoch": 0.14734845721788606,
      "grad_norm": 0.17542842030525208,
      "learning_rate": 4.852651542782114e-05,
      "loss": 0.0067,
      "step": 2020
    },
    {
      "epoch": 0.1480779050258954,
      "grad_norm": 0.1748334914445877,
      "learning_rate": 4.851922094974105e-05,
      "loss": 0.0068,
      "step": 2030
    },
    {
      "epoch": 0.14880735283390473,
      "grad_norm": 0.11677645146846771,
      "learning_rate": 4.8511926471660956e-05,
      "loss": 0.0039,
      "step": 2040
    },
    {
      "epoch": 0.14953680064191407,
      "grad_norm": 0.0874037891626358,
      "learning_rate": 4.850463199358086e-05,
      "loss": 0.0061,
      "step": 2050
    },
    {
      "epoch": 0.1502662484499234,
      "grad_norm": 0.08740021288394928,
      "learning_rate": 4.849733751550077e-05,
      "loss": 0.0063,
      "step": 2060
    },
    {
      "epoch": 0.15099569625793274,
      "grad_norm": 0.030520575121045113,
      "learning_rate": 4.849004303742067e-05,
      "loss": 0.0068,
      "step": 2070
    },
    {
      "epoch": 0.1517251440659421,
      "grad_norm": 0.1746698021888733,
      "learning_rate": 4.848274855934058e-05,
      "loss": 0.0055,
      "step": 2080
    },
    {
      "epoch": 0.1524545918739514,
      "grad_norm": 0.23482859134674072,
      "learning_rate": 4.847545408126049e-05,
      "loss": 0.0035,
      "step": 2090
    },
    {
      "epoch": 0.15318403968196076,
      "grad_norm": 0.1642911583185196,
      "learning_rate": 4.8468159603180394e-05,
      "loss": 0.0055,
      "step": 2100
    },
    {
      "epoch": 0.15391348748997008,
      "grad_norm": 0.29133063554763794,
      "learning_rate": 4.84608651251003e-05,
      "loss": 0.0052,
      "step": 2110
    },
    {
      "epoch": 0.15464293529797943,
      "grad_norm": 0.08901942521333694,
      "learning_rate": 4.845357064702021e-05,
      "loss": 0.0051,
      "step": 2120
    },
    {
      "epoch": 0.15537238310598878,
      "grad_norm": 0.031218331307172775,
      "learning_rate": 4.8446276168940117e-05,
      "loss": 0.0078,
      "step": 2130
    },
    {
      "epoch": 0.1561018309139981,
      "grad_norm": 0.11703324317932129,
      "learning_rate": 4.843898169086002e-05,
      "loss": 0.0059,
      "step": 2140
    },
    {
      "epoch": 0.15683127872200744,
      "grad_norm": 0.11699788272380829,
      "learning_rate": 4.843168721277993e-05,
      "loss": 0.0054,
      "step": 2150
    },
    {
      "epoch": 0.15756072653001676,
      "grad_norm": 0.010865557007491589,
      "learning_rate": 4.842439273469984e-05,
      "loss": 0.0049,
      "step": 2160
    },
    {
      "epoch": 0.1582901743380261,
      "grad_norm": 0.34996092319488525,
      "learning_rate": 4.841709825661974e-05,
      "loss": 0.0036,
      "step": 2170
    },
    {
      "epoch": 0.15901962214603546,
      "grad_norm": 0.20478491485118866,
      "learning_rate": 4.840980377853965e-05,
      "loss": 0.0069,
      "step": 2180
    },
    {
      "epoch": 0.15974906995404478,
      "grad_norm": 0.11819494515657425,
      "learning_rate": 4.8402509300459555e-05,
      "loss": 0.0049,
      "step": 2190
    },
    {
      "epoch": 0.16047851776205413,
      "grad_norm": 0.6992939710617065,
      "learning_rate": 4.8395214822379456e-05,
      "loss": 0.0066,
      "step": 2200
    },
    {
      "epoch": 0.16120796557006345,
      "grad_norm": 0.11676130443811417,
      "learning_rate": 4.838792034429937e-05,
      "loss": 0.0075,
      "step": 2210
    },
    {
      "epoch": 0.1619374133780728,
      "grad_norm": 0.06037506088614464,
      "learning_rate": 4.838062586621928e-05,
      "loss": 0.0059,
      "step": 2220
    },
    {
      "epoch": 0.16266686118608215,
      "grad_norm": 0.40887507796287537,
      "learning_rate": 4.837333138813918e-05,
      "loss": 0.0074,
      "step": 2230
    },
    {
      "epoch": 0.16339630899409147,
      "grad_norm": 0.29256242513656616,
      "learning_rate": 4.8366036910059086e-05,
      "loss": 0.0067,
      "step": 2240
    },
    {
      "epoch": 0.16412575680210081,
      "grad_norm": 0.49423155188560486,
      "learning_rate": 4.835874243197899e-05,
      "loss": 0.0063,
      "step": 2250
    },
    {
      "epoch": 0.16485520461011013,
      "grad_norm": 0.17474614083766937,
      "learning_rate": 4.83514479538989e-05,
      "loss": 0.006,
      "step": 2260
    },
    {
      "epoch": 0.16558465241811948,
      "grad_norm": 0.14629752933979034,
      "learning_rate": 4.834415347581881e-05,
      "loss": 0.0057,
      "step": 2270
    },
    {
      "epoch": 0.16631410022612883,
      "grad_norm": 0.3492554724216461,
      "learning_rate": 4.8336858997738716e-05,
      "loss": 0.0058,
      "step": 2280
    },
    {
      "epoch": 0.16704354803413815,
      "grad_norm": 0.030815793201327324,
      "learning_rate": 4.8329564519658623e-05,
      "loss": 0.0048,
      "step": 2290
    },
    {
      "epoch": 0.1677729958421475,
      "grad_norm": 0.05968828499317169,
      "learning_rate": 4.8322270041578524e-05,
      "loss": 0.0062,
      "step": 2300
    },
    {
      "epoch": 0.16850244365015682,
      "grad_norm": 0.007049751002341509,
      "learning_rate": 4.831497556349843e-05,
      "loss": 0.0052,
      "step": 2310
    },
    {
      "epoch": 0.16923189145816617,
      "grad_norm": 0.17527103424072266,
      "learning_rate": 4.830768108541834e-05,
      "loss": 0.0057,
      "step": 2320
    },
    {
      "epoch": 0.16996133926617552,
      "grad_norm": 0.14582520723342896,
      "learning_rate": 4.830038660733825e-05,
      "loss": 0.0058,
      "step": 2330
    },
    {
      "epoch": 0.17069078707418484,
      "grad_norm": 0.030489481985569,
      "learning_rate": 4.8293092129258154e-05,
      "loss": 0.0048,
      "step": 2340
    },
    {
      "epoch": 0.17142023488219418,
      "grad_norm": 0.14592483639717102,
      "learning_rate": 4.828579765117806e-05,
      "loss": 0.0084,
      "step": 2350
    },
    {
      "epoch": 0.1721496826902035,
      "grad_norm": 0.05949927121400833,
      "learning_rate": 4.827850317309797e-05,
      "loss": 0.0049,
      "step": 2360
    },
    {
      "epoch": 0.17287913049821285,
      "grad_norm": 0.23318488895893097,
      "learning_rate": 4.827120869501787e-05,
      "loss": 0.0054,
      "step": 2370
    },
    {
      "epoch": 0.1736085783062222,
      "grad_norm": 0.3493957817554474,
      "learning_rate": 4.826391421693778e-05,
      "loss": 0.0052,
      "step": 2380
    },
    {
      "epoch": 0.17433802611423152,
      "grad_norm": 0.05996232479810715,
      "learning_rate": 4.825661973885769e-05,
      "loss": 0.0079,
      "step": 2390
    },
    {
      "epoch": 0.17506747392224087,
      "grad_norm": 0.08759860694408417,
      "learning_rate": 4.824932526077759e-05,
      "loss": 0.0056,
      "step": 2400
    },
    {
      "epoch": 0.1757969217302502,
      "grad_norm": 0.26211017370224,
      "learning_rate": 4.82420307826975e-05,
      "loss": 0.0056,
      "step": 2410
    },
    {
      "epoch": 0.17652636953825954,
      "grad_norm": 0.11700987070798874,
      "learning_rate": 4.823473630461741e-05,
      "loss": 0.0064,
      "step": 2420
    },
    {
      "epoch": 0.17725581734626888,
      "grad_norm": 0.02059835195541382,
      "learning_rate": 4.822744182653731e-05,
      "loss": 0.0056,
      "step": 2430
    },
    {
      "epoch": 0.1779852651542782,
      "grad_norm": 0.14578424394130707,
      "learning_rate": 4.8220147348457216e-05,
      "loss": 0.0069,
      "step": 2440
    },
    {
      "epoch": 0.17871471296228755,
      "grad_norm": 0.011035420000553131,
      "learning_rate": 4.821285287037713e-05,
      "loss": 0.0057,
      "step": 2450
    },
    {
      "epoch": 0.17944416077029687,
      "grad_norm": 0.29150843620300293,
      "learning_rate": 4.820555839229703e-05,
      "loss": 0.0052,
      "step": 2460
    },
    {
      "epoch": 0.18017360857830622,
      "grad_norm": 0.29146474599838257,
      "learning_rate": 4.819826391421694e-05,
      "loss": 0.0032,
      "step": 2470
    },
    {
      "epoch": 0.18090305638631557,
      "grad_norm": 0.08776111900806427,
      "learning_rate": 4.8190969436136846e-05,
      "loss": 0.0056,
      "step": 2480
    },
    {
      "epoch": 0.1816325041943249,
      "grad_norm": 0.1169244572520256,
      "learning_rate": 4.8183674958056754e-05,
      "loss": 0.0055,
      "step": 2490
    },
    {
      "epoch": 0.18236195200233424,
      "grad_norm": 0.00901547446846962,
      "learning_rate": 4.817638047997666e-05,
      "loss": 0.0056,
      "step": 2500
    },
    {
      "epoch": 0.18309139981034356,
      "grad_norm": 0.26266035437583923,
      "learning_rate": 4.816908600189657e-05,
      "loss": 0.0057,
      "step": 2510
    },
    {
      "epoch": 0.1838208476183529,
      "grad_norm": 0.17474666237831116,
      "learning_rate": 4.8161791523816476e-05,
      "loss": 0.0058,
      "step": 2520
    },
    {
      "epoch": 0.18455029542636225,
      "grad_norm": 0.01074953842908144,
      "learning_rate": 4.815449704573638e-05,
      "loss": 0.0054,
      "step": 2530
    },
    {
      "epoch": 0.18527974323437157,
      "grad_norm": 0.3498518168926239,
      "learning_rate": 4.8147202567656285e-05,
      "loss": 0.0065,
      "step": 2540
    },
    {
      "epoch": 0.18600919104238092,
      "grad_norm": 0.20463243126869202,
      "learning_rate": 4.813990808957619e-05,
      "loss": 0.007,
      "step": 2550
    },
    {
      "epoch": 0.18673863885039024,
      "grad_norm": 0.05967947840690613,
      "learning_rate": 4.81326136114961e-05,
      "loss": 0.0064,
      "step": 2560
    },
    {
      "epoch": 0.1874680866583996,
      "grad_norm": 0.17504866421222687,
      "learning_rate": 4.812531913341601e-05,
      "loss": 0.0063,
      "step": 2570
    },
    {
      "epoch": 0.18819753446640894,
      "grad_norm": 0.17523165047168732,
      "learning_rate": 4.8118024655335915e-05,
      "loss": 0.0055,
      "step": 2580
    },
    {
      "epoch": 0.18892698227441826,
      "grad_norm": 0.23354853689670563,
      "learning_rate": 4.811073017725582e-05,
      "loss": 0.0056,
      "step": 2590
    },
    {
      "epoch": 0.1896564300824276,
      "grad_norm": 0.05865737050771713,
      "learning_rate": 4.810343569917572e-05,
      "loss": 0.0072,
      "step": 2600
    },
    {
      "epoch": 0.19038587789043693,
      "grad_norm": 0.17460384964942932,
      "learning_rate": 4.809614122109563e-05,
      "loss": 0.0058,
      "step": 2610
    },
    {
      "epoch": 0.19111532569844628,
      "grad_norm": 0.031227773055434227,
      "learning_rate": 4.8088846743015545e-05,
      "loss": 0.0051,
      "step": 2620
    },
    {
      "epoch": 0.19184477350645562,
      "grad_norm": 0.2312210202217102,
      "learning_rate": 4.8081552264935446e-05,
      "loss": 0.0057,
      "step": 2630
    },
    {
      "epoch": 0.19257422131446494,
      "grad_norm": 0.05849369242787361,
      "learning_rate": 4.807425778685535e-05,
      "loss": 0.006,
      "step": 2640
    },
    {
      "epoch": 0.1933036691224743,
      "grad_norm": 0.17468300461769104,
      "learning_rate": 4.806696330877526e-05,
      "loss": 0.0045,
      "step": 2650
    },
    {
      "epoch": 0.1940331169304836,
      "grad_norm": 0.014365293085575104,
      "learning_rate": 4.805966883069516e-05,
      "loss": 0.0061,
      "step": 2660
    },
    {
      "epoch": 0.19476256473849296,
      "grad_norm": 0.1744079440832138,
      "learning_rate": 4.805237435261507e-05,
      "loss": 0.0064,
      "step": 2670
    },
    {
      "epoch": 0.1954920125465023,
      "grad_norm": 0.2646428346633911,
      "learning_rate": 4.804507987453498e-05,
      "loss": 0.0087,
      "step": 2680
    },
    {
      "epoch": 0.19622146035451163,
      "grad_norm": 0.007876481860876083,
      "learning_rate": 4.803778539645489e-05,
      "loss": 0.0069,
      "step": 2690
    },
    {
      "epoch": 0.19695090816252098,
      "grad_norm": 0.23295095562934875,
      "learning_rate": 4.803049091837479e-05,
      "loss": 0.0059,
      "step": 2700
    },
    {
      "epoch": 0.1976803559705303,
      "grad_norm": 0.08860837668180466,
      "learning_rate": 4.80231964402947e-05,
      "loss": 0.0064,
      "step": 2710
    },
    {
      "epoch": 0.19840980377853965,
      "grad_norm": 0.40780678391456604,
      "learning_rate": 4.8015901962214607e-05,
      "loss": 0.0041,
      "step": 2720
    },
    {
      "epoch": 0.199139251586549,
      "grad_norm": 0.7523500919342041,
      "learning_rate": 4.800860748413451e-05,
      "loss": 0.0053,
      "step": 2730
    },
    {
      "epoch": 0.1998686993945583,
      "grad_norm": 0.6403986215591431,
      "learning_rate": 4.800131300605442e-05,
      "loss": 0.0051,
      "step": 2740
    },
    {
      "epoch": 0.20059814720256766,
      "grad_norm": 0.2917692959308624,
      "learning_rate": 4.799401852797433e-05,
      "loss": 0.0074,
      "step": 2750
    },
    {
      "epoch": 0.20132759501057698,
      "grad_norm": 0.11669308692216873,
      "learning_rate": 4.798672404989423e-05,
      "loss": 0.0048,
      "step": 2760
    },
    {
      "epoch": 0.20205704281858633,
      "grad_norm": 0.08773060888051987,
      "learning_rate": 4.797942957181414e-05,
      "loss": 0.0049,
      "step": 2770
    },
    {
      "epoch": 0.20278649062659568,
      "grad_norm": 0.17491579055786133,
      "learning_rate": 4.7972135093734045e-05,
      "loss": 0.0057,
      "step": 2780
    },
    {
      "epoch": 0.203515938434605,
      "grad_norm": 0.02991415373980999,
      "learning_rate": 4.796484061565395e-05,
      "loss": 0.0055,
      "step": 2790
    },
    {
      "epoch": 0.20424538624261435,
      "grad_norm": 0.11663848161697388,
      "learning_rate": 4.795754613757386e-05,
      "loss": 0.007,
      "step": 2800
    },
    {
      "epoch": 0.20497483405062367,
      "grad_norm": 0.013608220964670181,
      "learning_rate": 4.795025165949377e-05,
      "loss": 0.0047,
      "step": 2810
    },
    {
      "epoch": 0.20570428185863301,
      "grad_norm": 0.11673873662948608,
      "learning_rate": 4.7942957181413675e-05,
      "loss": 0.0069,
      "step": 2820
    },
    {
      "epoch": 0.20643372966664236,
      "grad_norm": 0.23341217637062073,
      "learning_rate": 4.7935662703333576e-05,
      "loss": 0.0052,
      "step": 2830
    },
    {
      "epoch": 0.20716317747465168,
      "grad_norm": 0.3202042877674103,
      "learning_rate": 4.7928368225253483e-05,
      "loss": 0.0051,
      "step": 2840
    },
    {
      "epoch": 0.20789262528266103,
      "grad_norm": 0.5238118171691895,
      "learning_rate": 4.792107374717339e-05,
      "loss": 0.0049,
      "step": 2850
    },
    {
      "epoch": 0.20862207309067035,
      "grad_norm": 0.05836888775229454,
      "learning_rate": 4.79137792690933e-05,
      "loss": 0.0064,
      "step": 2860
    },
    {
      "epoch": 0.2093515208986797,
      "grad_norm": 0.17419888079166412,
      "learning_rate": 4.7906484791013206e-05,
      "loss": 0.0049,
      "step": 2870
    },
    {
      "epoch": 0.21008096870668905,
      "grad_norm": 0.05932015925645828,
      "learning_rate": 4.7899190312933114e-05,
      "loss": 0.0045,
      "step": 2880
    },
    {
      "epoch": 0.21081041651469837,
      "grad_norm": 0.17443691194057465,
      "learning_rate": 4.789189583485302e-05,
      "loss": 0.0051,
      "step": 2890
    },
    {
      "epoch": 0.21153986432270772,
      "grad_norm": 0.26169681549072266,
      "learning_rate": 4.788460135677292e-05,
      "loss": 0.0041,
      "step": 2900
    },
    {
      "epoch": 0.21226931213071704,
      "grad_norm": 0.059537239372730255,
      "learning_rate": 4.787730687869283e-05,
      "loss": 0.0065,
      "step": 2910
    },
    {
      "epoch": 0.21299875993872638,
      "grad_norm": 0.29059505462646484,
      "learning_rate": 4.7870012400612744e-05,
      "loss": 0.0046,
      "step": 2920
    },
    {
      "epoch": 0.21372820774673573,
      "grad_norm": 0.05833699554204941,
      "learning_rate": 4.7862717922532644e-05,
      "loss": 0.0051,
      "step": 2930
    },
    {
      "epoch": 0.21445765555474505,
      "grad_norm": 0.17485380172729492,
      "learning_rate": 4.785542344445255e-05,
      "loss": 0.0074,
      "step": 2940
    },
    {
      "epoch": 0.2151871033627544,
      "grad_norm": 0.28966376185417175,
      "learning_rate": 4.784812896637246e-05,
      "loss": 0.0068,
      "step": 2950
    },
    {
      "epoch": 0.21591655117076372,
      "grad_norm": 0.2665258049964905,
      "learning_rate": 4.784083448829236e-05,
      "loss": 0.0073,
      "step": 2960
    },
    {
      "epoch": 0.21664599897877307,
      "grad_norm": 0.11627910286188126,
      "learning_rate": 4.7833540010212275e-05,
      "loss": 0.0043,
      "step": 2970
    },
    {
      "epoch": 0.21737544678678242,
      "grad_norm": 0.38528868556022644,
      "learning_rate": 4.782624553213218e-05,
      "loss": 0.0062,
      "step": 2980
    },
    {
      "epoch": 0.21810489459479174,
      "grad_norm": 0.406344473361969,
      "learning_rate": 4.781895105405208e-05,
      "loss": 0.0059,
      "step": 2990
    },
    {
      "epoch": 0.21883434240280109,
      "grad_norm": 0.018554097041487694,
      "learning_rate": 4.781165657597199e-05,
      "loss": 0.0057,
      "step": 3000
    },
    {
      "epoch": 0.2195637902108104,
      "grad_norm": 0.23280659317970276,
      "learning_rate": 4.78043620978919e-05,
      "loss": 0.0051,
      "step": 3010
    },
    {
      "epoch": 0.22029323801881975,
      "grad_norm": 0.2910027503967285,
      "learning_rate": 4.7797067619811805e-05,
      "loss": 0.0059,
      "step": 3020
    },
    {
      "epoch": 0.2210226858268291,
      "grad_norm": 0.2332974523305893,
      "learning_rate": 4.778977314173171e-05,
      "loss": 0.0052,
      "step": 3030
    },
    {
      "epoch": 0.22175213363483842,
      "grad_norm": 0.35107627511024475,
      "learning_rate": 4.778247866365162e-05,
      "loss": 0.0071,
      "step": 3040
    },
    {
      "epoch": 0.22248158144284777,
      "grad_norm": 0.11750392615795135,
      "learning_rate": 4.777518418557153e-05,
      "loss": 0.0043,
      "step": 3050
    },
    {
      "epoch": 0.2232110292508571,
      "grad_norm": 0.14575599133968353,
      "learning_rate": 4.776788970749143e-05,
      "loss": 0.006,
      "step": 3060
    },
    {
      "epoch": 0.22394047705886644,
      "grad_norm": 0.14622066915035248,
      "learning_rate": 4.7760595229411336e-05,
      "loss": 0.005,
      "step": 3070
    },
    {
      "epoch": 0.2246699248668758,
      "grad_norm": 0.17517416179180145,
      "learning_rate": 4.7753300751331244e-05,
      "loss": 0.0066,
      "step": 3080
    },
    {
      "epoch": 0.2253993726748851,
      "grad_norm": 0.5244703888893127,
      "learning_rate": 4.774600627325115e-05,
      "loss": 0.0049,
      "step": 3090
    },
    {
      "epoch": 0.22612882048289445,
      "grad_norm": 0.20414334535598755,
      "learning_rate": 4.773871179517106e-05,
      "loss": 0.0047,
      "step": 3100
    },
    {
      "epoch": 0.22685826829090378,
      "grad_norm": 0.5246767401695251,
      "learning_rate": 4.7731417317090966e-05,
      "loss": 0.004,
      "step": 3110
    },
    {
      "epoch": 0.22758771609891312,
      "grad_norm": 0.11588487774133682,
      "learning_rate": 4.7724122839010874e-05,
      "loss": 0.0063,
      "step": 3120
    },
    {
      "epoch": 0.22831716390692247,
      "grad_norm": 0.11581939458847046,
      "learning_rate": 4.7716828360930775e-05,
      "loss": 0.0071,
      "step": 3130
    },
    {
      "epoch": 0.2290466117149318,
      "grad_norm": 0.05846765264868736,
      "learning_rate": 4.770953388285068e-05,
      "loss": 0.0052,
      "step": 3140
    },
    {
      "epoch": 0.22977605952294114,
      "grad_norm": 0.06005652993917465,
      "learning_rate": 4.7702239404770597e-05,
      "loss": 0.0054,
      "step": 3150
    },
    {
      "epoch": 0.23050550733095046,
      "grad_norm": 0.1744711697101593,
      "learning_rate": 4.76949449266905e-05,
      "loss": 0.0046,
      "step": 3160
    },
    {
      "epoch": 0.2312349551389598,
      "grad_norm": 0.2612094581127167,
      "learning_rate": 4.7687650448610405e-05,
      "loss": 0.0063,
      "step": 3170
    },
    {
      "epoch": 0.23196440294696916,
      "grad_norm": 0.2321099489927292,
      "learning_rate": 4.768035597053031e-05,
      "loss": 0.0045,
      "step": 3180
    },
    {
      "epoch": 0.23269385075497848,
      "grad_norm": 0.11581666767597198,
      "learning_rate": 4.767306149245021e-05,
      "loss": 0.0061,
      "step": 3190
    },
    {
      "epoch": 0.23342329856298782,
      "grad_norm": 0.060094237327575684,
      "learning_rate": 4.766576701437012e-05,
      "loss": 0.0049,
      "step": 3200
    },
    {
      "epoch": 0.23415274637099714,
      "grad_norm": 0.08845420181751251,
      "learning_rate": 4.7658472536290035e-05,
      "loss": 0.0064,
      "step": 3210
    },
    {
      "epoch": 0.2348821941790065,
      "grad_norm": 0.37973642349243164,
      "learning_rate": 4.7651178058209936e-05,
      "loss": 0.0064,
      "step": 3220
    },
    {
      "epoch": 0.23561164198701584,
      "grad_norm": 0.14645527303218842,
      "learning_rate": 4.764388358012984e-05,
      "loss": 0.0047,
      "step": 3230
    },
    {
      "epoch": 0.23634108979502516,
      "grad_norm": 0.1743677258491516,
      "learning_rate": 4.763658910204975e-05,
      "loss": 0.0059,
      "step": 3240
    },
    {
      "epoch": 0.2370705376030345,
      "grad_norm": 0.0592336431145668,
      "learning_rate": 4.762929462396966e-05,
      "loss": 0.0063,
      "step": 3250
    },
    {
      "epoch": 0.23779998541104383,
      "grad_norm": 0.23310734331607819,
      "learning_rate": 4.762200014588956e-05,
      "loss": 0.0052,
      "step": 3260
    },
    {
      "epoch": 0.23852943321905318,
      "grad_norm": 0.23278383910655975,
      "learning_rate": 4.761470566780947e-05,
      "loss": 0.0054,
      "step": 3270
    },
    {
      "epoch": 0.23925888102706253,
      "grad_norm": 0.05866974964737892,
      "learning_rate": 4.760741118972938e-05,
      "loss": 0.0069,
      "step": 3280
    },
    {
      "epoch": 0.23998832883507185,
      "grad_norm": 0.17515648901462555,
      "learning_rate": 4.760011671164928e-05,
      "loss": 0.0057,
      "step": 3290
    },
    {
      "epoch": 0.2407177766430812,
      "grad_norm": 0.17444796860218048,
      "learning_rate": 4.759282223356919e-05,
      "loss": 0.0053,
      "step": 3300
    },
    {
      "epoch": 0.24144722445109051,
      "grad_norm": 0.05925296992063522,
      "learning_rate": 4.75855277554891e-05,
      "loss": 0.0072,
      "step": 3310
    },
    {
      "epoch": 0.24217667225909986,
      "grad_norm": 0.11662087589502335,
      "learning_rate": 4.7578233277409004e-05,
      "loss": 0.0052,
      "step": 3320
    },
    {
      "epoch": 0.2429061200671092,
      "grad_norm": 0.4071332514286041,
      "learning_rate": 4.757093879932891e-05,
      "loss": 0.0083,
      "step": 3330
    },
    {
      "epoch": 0.24363556787511853,
      "grad_norm": 0.008553355932235718,
      "learning_rate": 4.756364432124882e-05,
      "loss": 0.0062,
      "step": 3340
    },
    {
      "epoch": 0.24436501568312788,
      "grad_norm": 0.1748839020729065,
      "learning_rate": 4.755634984316873e-05,
      "loss": 0.0053,
      "step": 3350
    },
    {
      "epoch": 0.2450944634911372,
      "grad_norm": 0.012952613644301891,
      "learning_rate": 4.754905536508863e-05,
      "loss": 0.0066,
      "step": 3360
    },
    {
      "epoch": 0.24582391129914655,
      "grad_norm": 0.06009586900472641,
      "learning_rate": 4.7541760887008535e-05,
      "loss": 0.0051,
      "step": 3370
    },
    {
      "epoch": 0.2465533591071559,
      "grad_norm": 0.010747111402451992,
      "learning_rate": 4.753446640892844e-05,
      "loss": 0.0049,
      "step": 3380
    },
    {
      "epoch": 0.24728280691516522,
      "grad_norm": 0.2132347673177719,
      "learning_rate": 4.752717193084835e-05,
      "loss": 0.0046,
      "step": 3390
    },
    {
      "epoch": 0.24801225472317456,
      "grad_norm": 0.09645453840494156,
      "learning_rate": 4.751987745276826e-05,
      "loss": 0.0058,
      "step": 3400
    },
    {
      "epoch": 0.24874170253118388,
      "grad_norm": 0.5243307948112488,
      "learning_rate": 4.7512582974688165e-05,
      "loss": 0.0046,
      "step": 3410
    },
    {
      "epoch": 0.24947115033919323,
      "grad_norm": 0.23268020153045654,
      "learning_rate": 4.7505288496608066e-05,
      "loss": 0.0059,
      "step": 3420
    },
    {
      "epoch": 0.2502005981472026,
      "grad_norm": 0.11644379049539566,
      "learning_rate": 4.7497994018527973e-05,
      "loss": 0.0046,
      "step": 3430
    },
    {
      "epoch": 0.2509300459552119,
      "grad_norm": 0.007454134523868561,
      "learning_rate": 4.749069954044788e-05,
      "loss": 0.0051,
      "step": 3440
    },
    {
      "epoch": 0.2516594937632212,
      "grad_norm": 0.00392554048448801,
      "learning_rate": 4.748340506236779e-05,
      "loss": 0.0063,
      "step": 3450
    },
    {
      "epoch": 0.2523889415712306,
      "grad_norm": 0.11682190746068954,
      "learning_rate": 4.7476110584287696e-05,
      "loss": 0.006,
      "step": 3460
    },
    {
      "epoch": 0.2531183893792399,
      "grad_norm": 0.23240186274051666,
      "learning_rate": 4.7468816106207604e-05,
      "loss": 0.0063,
      "step": 3470
    },
    {
      "epoch": 0.25384783718724924,
      "grad_norm": 0.012157915160059929,
      "learning_rate": 4.746152162812751e-05,
      "loss": 0.006,
      "step": 3480
    },
    {
      "epoch": 0.2545772849952586,
      "grad_norm": 0.3487318456172943,
      "learning_rate": 4.745422715004741e-05,
      "loss": 0.0058,
      "step": 3490
    },
    {
      "epoch": 0.25530673280326793,
      "grad_norm": 0.49395403265953064,
      "learning_rate": 4.7446932671967326e-05,
      "loss": 0.0052,
      "step": 3500
    },
    {
      "epoch": 0.25603618061127725,
      "grad_norm": 0.2908909320831299,
      "learning_rate": 4.7439638193887234e-05,
      "loss": 0.0079,
      "step": 3510
    },
    {
      "epoch": 0.2567656284192866,
      "grad_norm": 0.31948670744895935,
      "learning_rate": 4.7432343715807134e-05,
      "loss": 0.0062,
      "step": 3520
    },
    {
      "epoch": 0.25749507622729595,
      "grad_norm": 0.11669346690177917,
      "learning_rate": 4.742504923772704e-05,
      "loss": 0.0069,
      "step": 3530
    },
    {
      "epoch": 0.25822452403530527,
      "grad_norm": 0.03032848797738552,
      "learning_rate": 4.741775475964695e-05,
      "loss": 0.0064,
      "step": 3540
    },
    {
      "epoch": 0.2589539718433146,
      "grad_norm": 0.1116708517074585,
      "learning_rate": 4.741046028156686e-05,
      "loss": 0.0049,
      "step": 3550
    },
    {
      "epoch": 0.25968341965132397,
      "grad_norm": 0.23283256590366364,
      "learning_rate": 4.7403165803486765e-05,
      "loss": 0.0078,
      "step": 3560
    },
    {
      "epoch": 0.2604128674593333,
      "grad_norm": 0.007976270280778408,
      "learning_rate": 4.739587132540667e-05,
      "loss": 0.0056,
      "step": 3570
    },
    {
      "epoch": 0.2611423152673426,
      "grad_norm": 0.02134532667696476,
      "learning_rate": 4.738857684732658e-05,
      "loss": 0.0057,
      "step": 3580
    },
    {
      "epoch": 0.261871763075352,
      "grad_norm": 0.23305964469909668,
      "learning_rate": 4.738128236924648e-05,
      "loss": 0.0038,
      "step": 3590
    },
    {
      "epoch": 0.2626012108833613,
      "grad_norm": 0.2914860248565674,
      "learning_rate": 4.737398789116639e-05,
      "loss": 0.0061,
      "step": 3600
    },
    {
      "epoch": 0.2633306586913706,
      "grad_norm": 0.6968547105789185,
      "learning_rate": 4.7366693413086295e-05,
      "loss": 0.0075,
      "step": 3610
    },
    {
      "epoch": 0.26406010649937994,
      "grad_norm": 0.059112802147865295,
      "learning_rate": 4.73593989350062e-05,
      "loss": 0.0047,
      "step": 3620
    },
    {
      "epoch": 0.2647895543073893,
      "grad_norm": 0.0597655288875103,
      "learning_rate": 4.735210445692611e-05,
      "loss": 0.0071,
      "step": 3630
    },
    {
      "epoch": 0.26551900211539864,
      "grad_norm": 0.11677151173353195,
      "learning_rate": 4.734480997884602e-05,
      "loss": 0.0072,
      "step": 3640
    },
    {
      "epoch": 0.26624844992340796,
      "grad_norm": 0.23341435194015503,
      "learning_rate": 4.733751550076592e-05,
      "loss": 0.0071,
      "step": 3650
    },
    {
      "epoch": 0.26697789773141734,
      "grad_norm": 0.2330247163772583,
      "learning_rate": 4.7330221022685826e-05,
      "loss": 0.0051,
      "step": 3660
    },
    {
      "epoch": 0.26770734553942666,
      "grad_norm": 0.31990236043930054,
      "learning_rate": 4.7322926544605734e-05,
      "loss": 0.0053,
      "step": 3670
    },
    {
      "epoch": 0.268436793347436,
      "grad_norm": 0.2338237762451172,
      "learning_rate": 4.731563206652564e-05,
      "loss": 0.0041,
      "step": 3680
    },
    {
      "epoch": 0.26916624115544535,
      "grad_norm": 0.08725009113550186,
      "learning_rate": 4.730833758844555e-05,
      "loss": 0.0067,
      "step": 3690
    },
    {
      "epoch": 0.26989568896345467,
      "grad_norm": 0.5800150632858276,
      "learning_rate": 4.7301043110365456e-05,
      "loss": 0.0059,
      "step": 3700
    },
    {
      "epoch": 0.270625136771464,
      "grad_norm": 0.2015821486711502,
      "learning_rate": 4.7293748632285364e-05,
      "loss": 0.0069,
      "step": 3710
    },
    {
      "epoch": 0.2713545845794733,
      "grad_norm": 0.11791136860847473,
      "learning_rate": 4.7286454154205265e-05,
      "loss": 0.005,
      "step": 3720
    },
    {
      "epoch": 0.2720840323874827,
      "grad_norm": 0.007268024608492851,
      "learning_rate": 4.727915967612517e-05,
      "loss": 0.0046,
      "step": 3730
    },
    {
      "epoch": 0.272813480195492,
      "grad_norm": 0.4650443494319916,
      "learning_rate": 4.7271865198045087e-05,
      "loss": 0.0046,
      "step": 3740
    },
    {
      "epoch": 0.27354292800350133,
      "grad_norm": 0.05854601413011551,
      "learning_rate": 4.726457071996499e-05,
      "loss": 0.0075,
      "step": 3750
    },
    {
      "epoch": 0.2742723758115107,
      "grad_norm": 0.20694392919540405,
      "learning_rate": 4.7257276241884895e-05,
      "loss": 0.0053,
      "step": 3760
    },
    {
      "epoch": 0.27500182361952,
      "grad_norm": 0.05959636718034744,
      "learning_rate": 4.72499817638048e-05,
      "loss": 0.0055,
      "step": 3770
    },
    {
      "epoch": 0.27573127142752935,
      "grad_norm": 0.1742347627878189,
      "learning_rate": 4.724268728572471e-05,
      "loss": 0.0045,
      "step": 3780
    },
    {
      "epoch": 0.2764607192355387,
      "grad_norm": 0.4070333242416382,
      "learning_rate": 4.723539280764461e-05,
      "loss": 0.0054,
      "step": 3790
    },
    {
      "epoch": 0.27719016704354804,
      "grad_norm": 0.20538994669914246,
      "learning_rate": 4.7228098329564525e-05,
      "loss": 0.0053,
      "step": 3800
    },
    {
      "epoch": 0.27791961485155736,
      "grad_norm": 0.1751246154308319,
      "learning_rate": 4.722080385148443e-05,
      "loss": 0.0044,
      "step": 3810
    },
    {
      "epoch": 0.2786490626595667,
      "grad_norm": 0.29183050990104675,
      "learning_rate": 4.721350937340433e-05,
      "loss": 0.0055,
      "step": 3820
    },
    {
      "epoch": 0.27937851046757606,
      "grad_norm": 0.46673479676246643,
      "learning_rate": 4.720621489532424e-05,
      "loss": 0.0048,
      "step": 3830
    },
    {
      "epoch": 0.2801079582755854,
      "grad_norm": 0.5244544148445129,
      "learning_rate": 4.719892041724415e-05,
      "loss": 0.0056,
      "step": 3840
    },
    {
      "epoch": 0.2808374060835947,
      "grad_norm": 0.29137787222862244,
      "learning_rate": 4.7191625939164056e-05,
      "loss": 0.0048,
      "step": 3850
    },
    {
      "epoch": 0.2815668538916041,
      "grad_norm": 0.3491927683353424,
      "learning_rate": 4.718433146108396e-05,
      "loss": 0.0055,
      "step": 3860
    },
    {
      "epoch": 0.2822963016996134,
      "grad_norm": 0.11651673913002014,
      "learning_rate": 4.717703698300387e-05,
      "loss": 0.0048,
      "step": 3870
    },
    {
      "epoch": 0.2830257495076227,
      "grad_norm": 0.0592556893825531,
      "learning_rate": 4.716974250492378e-05,
      "loss": 0.0058,
      "step": 3880
    },
    {
      "epoch": 0.2837551973156321,
      "grad_norm": 0.1745092272758484,
      "learning_rate": 4.716244802684368e-05,
      "loss": 0.0069,
      "step": 3890
    },
    {
      "epoch": 0.2844846451236414,
      "grad_norm": 0.11695830523967743,
      "learning_rate": 4.715515354876359e-05,
      "loss": 0.0054,
      "step": 3900
    },
    {
      "epoch": 0.28521409293165073,
      "grad_norm": 0.2330579161643982,
      "learning_rate": 4.7147859070683494e-05,
      "loss": 0.0064,
      "step": 3910
    },
    {
      "epoch": 0.28594354073966005,
      "grad_norm": 0.05820097774267197,
      "learning_rate": 4.71405645926034e-05,
      "loss": 0.0063,
      "step": 3920
    },
    {
      "epoch": 0.2866729885476694,
      "grad_norm": 0.08705028891563416,
      "learning_rate": 4.713327011452331e-05,
      "loss": 0.0073,
      "step": 3930
    },
    {
      "epoch": 0.28740243635567875,
      "grad_norm": 0.005291738081723452,
      "learning_rate": 4.712597563644322e-05,
      "loss": 0.0071,
      "step": 3940
    },
    {
      "epoch": 0.28813188416368807,
      "grad_norm": 0.3803199827671051,
      "learning_rate": 4.711868115836312e-05,
      "loss": 0.0069,
      "step": 3950
    },
    {
      "epoch": 0.28886133197169744,
      "grad_norm": 0.47282689809799194,
      "learning_rate": 4.7111386680283025e-05,
      "loss": 0.0066,
      "step": 3960
    },
    {
      "epoch": 0.28959077977970676,
      "grad_norm": 0.5563496947288513,
      "learning_rate": 4.710409220220294e-05,
      "loss": 0.0051,
      "step": 3970
    },
    {
      "epoch": 0.2903202275877161,
      "grad_norm": 0.05893993750214577,
      "learning_rate": 4.709679772412284e-05,
      "loss": 0.0052,
      "step": 3980
    },
    {
      "epoch": 0.29104967539572546,
      "grad_norm": 0.1752939075231552,
      "learning_rate": 4.708950324604275e-05,
      "loss": 0.0055,
      "step": 3990
    },
    {
      "epoch": 0.2917791232037348,
      "grad_norm": 0.23313069343566895,
      "learning_rate": 4.7082208767962655e-05,
      "loss": 0.0062,
      "step": 4000
    },
    {
      "epoch": 0.2925085710117441,
      "grad_norm": 0.262061208486557,
      "learning_rate": 4.707491428988256e-05,
      "loss": 0.0045,
      "step": 4010
    },
    {
      "epoch": 0.2932380188197534,
      "grad_norm": 0.5248515605926514,
      "learning_rate": 4.7067619811802464e-05,
      "loss": 0.0044,
      "step": 4020
    },
    {
      "epoch": 0.2939674666277628,
      "grad_norm": 0.11665880680084229,
      "learning_rate": 4.706032533372238e-05,
      "loss": 0.0063,
      "step": 4030
    },
    {
      "epoch": 0.2946969144357721,
      "grad_norm": 0.11674036830663681,
      "learning_rate": 4.7053030855642285e-05,
      "loss": 0.0064,
      "step": 4040
    },
    {
      "epoch": 0.29542636224378144,
      "grad_norm": 0.5232574939727783,
      "learning_rate": 4.7045736377562186e-05,
      "loss": 0.0049,
      "step": 4050
    },
    {
      "epoch": 0.2961558100517908,
      "grad_norm": 0.37805595993995667,
      "learning_rate": 4.7038441899482094e-05,
      "loss": 0.006,
      "step": 4060
    },
    {
      "epoch": 0.29688525785980013,
      "grad_norm": 0.2035590559244156,
      "learning_rate": 4.7031147421402e-05,
      "loss": 0.0047,
      "step": 4070
    },
    {
      "epoch": 0.29761470566780945,
      "grad_norm": 0.4069288372993469,
      "learning_rate": 4.702385294332191e-05,
      "loss": 0.0061,
      "step": 4080
    },
    {
      "epoch": 0.29834415347581883,
      "grad_norm": 0.449894517660141,
      "learning_rate": 4.7016558465241816e-05,
      "loss": 0.0049,
      "step": 4090
    },
    {
      "epoch": 0.29907360128382815,
      "grad_norm": 0.4657595753669739,
      "learning_rate": 4.7009263987161724e-05,
      "loss": 0.006,
      "step": 4100
    },
    {
      "epoch": 0.29980304909183747,
      "grad_norm": 0.3759342432022095,
      "learning_rate": 4.700196950908163e-05,
      "loss": 0.0057,
      "step": 4110
    },
    {
      "epoch": 0.3005324968998468,
      "grad_norm": 0.007961207069456577,
      "learning_rate": 4.699467503100153e-05,
      "loss": 0.0066,
      "step": 4120
    },
    {
      "epoch": 0.30126194470785617,
      "grad_norm": 0.2304648607969284,
      "learning_rate": 4.698738055292144e-05,
      "loss": 0.0059,
      "step": 4130
    },
    {
      "epoch": 0.3019913925158655,
      "grad_norm": 0.030596867203712463,
      "learning_rate": 4.698008607484135e-05,
      "loss": 0.0056,
      "step": 4140
    },
    {
      "epoch": 0.3027208403238748,
      "grad_norm": 0.34913143515586853,
      "learning_rate": 4.6972791596761255e-05,
      "loss": 0.007,
      "step": 4150
    },
    {
      "epoch": 0.3034502881318842,
      "grad_norm": 0.1748913675546646,
      "learning_rate": 4.696549711868116e-05,
      "loss": 0.0056,
      "step": 4160
    },
    {
      "epoch": 0.3041797359398935,
      "grad_norm": 0.2907211482524872,
      "learning_rate": 4.695820264060107e-05,
      "loss": 0.0042,
      "step": 4170
    },
    {
      "epoch": 0.3049091837479028,
      "grad_norm": 0.23268872499465942,
      "learning_rate": 4.695090816252097e-05,
      "loss": 0.0056,
      "step": 4180
    },
    {
      "epoch": 0.3056386315559122,
      "grad_norm": 0.2901841402053833,
      "learning_rate": 4.694361368444088e-05,
      "loss": 0.0061,
      "step": 4190
    },
    {
      "epoch": 0.3063680793639215,
      "grad_norm": 0.059199776500463486,
      "learning_rate": 4.6936319206360786e-05,
      "loss": 0.0069,
      "step": 4200
    },
    {
      "epoch": 0.30709752717193084,
      "grad_norm": 0.05875459313392639,
      "learning_rate": 4.692902472828069e-05,
      "loss": 0.0073,
      "step": 4210
    },
    {
      "epoch": 0.30782697497994016,
      "grad_norm": 0.23265843093395233,
      "learning_rate": 4.69217302502006e-05,
      "loss": 0.0047,
      "step": 4220
    },
    {
      "epoch": 0.30855642278794954,
      "grad_norm": 0.11616717278957367,
      "learning_rate": 4.691443577212051e-05,
      "loss": 0.0047,
      "step": 4230
    },
    {
      "epoch": 0.30928587059595886,
      "grad_norm": 0.06127780303359032,
      "learning_rate": 4.6907141294040416e-05,
      "loss": 0.0058,
      "step": 4240
    },
    {
      "epoch": 0.3100153184039682,
      "grad_norm": 0.4669286608695984,
      "learning_rate": 4.6899846815960316e-05,
      "loss": 0.0057,
      "step": 4250
    },
    {
      "epoch": 0.31074476621197755,
      "grad_norm": 0.20359447598457336,
      "learning_rate": 4.6892552337880224e-05,
      "loss": 0.0046,
      "step": 4260
    },
    {
      "epoch": 0.3114742140199869,
      "grad_norm": 0.11700820177793503,
      "learning_rate": 4.688525785980014e-05,
      "loss": 0.0059,
      "step": 4270
    },
    {
      "epoch": 0.3122036618279962,
      "grad_norm": 0.11744576692581177,
      "learning_rate": 4.687796338172004e-05,
      "loss": 0.004,
      "step": 4280
    },
    {
      "epoch": 0.31293310963600557,
      "grad_norm": 0.35002174973487854,
      "learning_rate": 4.6870668903639946e-05,
      "loss": 0.0082,
      "step": 4290
    },
    {
      "epoch": 0.3136625574440149,
      "grad_norm": 0.15516893565654755,
      "learning_rate": 4.6863374425559854e-05,
      "loss": 0.0081,
      "step": 4300
    },
    {
      "epoch": 0.3143920052520242,
      "grad_norm": 0.1757286936044693,
      "learning_rate": 4.685607994747976e-05,
      "loss": 0.0053,
      "step": 4310
    },
    {
      "epoch": 0.31512145306003353,
      "grad_norm": 0.03471545875072479,
      "learning_rate": 4.684878546939966e-05,
      "loss": 0.0057,
      "step": 4320
    },
    {
      "epoch": 0.3158509008680429,
      "grad_norm": 0.06346383690834045,
      "learning_rate": 4.684149099131958e-05,
      "loss": 0.005,
      "step": 4330
    },
    {
      "epoch": 0.3165803486760522,
      "grad_norm": 0.1200399324297905,
      "learning_rate": 4.6834196513239484e-05,
      "loss": 0.0062,
      "step": 4340
    },
    {
      "epoch": 0.31730979648406155,
      "grad_norm": 0.006610744167119265,
      "learning_rate": 4.6826902035159385e-05,
      "loss": 0.0051,
      "step": 4350
    },
    {
      "epoch": 0.3180392442920709,
      "grad_norm": 0.35031452775001526,
      "learning_rate": 4.681960755707929e-05,
      "loss": 0.0039,
      "step": 4360
    },
    {
      "epoch": 0.31876869210008024,
      "grad_norm": 0.11675871908664703,
      "learning_rate": 4.68123130789992e-05,
      "loss": 0.0061,
      "step": 4370
    },
    {
      "epoch": 0.31949813990808956,
      "grad_norm": 0.37692856788635254,
      "learning_rate": 4.68050186009191e-05,
      "loss": 0.0058,
      "step": 4380
    },
    {
      "epoch": 0.32022758771609894,
      "grad_norm": 0.203227236866951,
      "learning_rate": 4.6797724122839015e-05,
      "loss": 0.0059,
      "step": 4390
    },
    {
      "epoch": 0.32095703552410826,
      "grad_norm": 0.3488633632659912,
      "learning_rate": 4.679042964475892e-05,
      "loss": 0.0057,
      "step": 4400
    },
    {
      "epoch": 0.3216864833321176,
      "grad_norm": 0.06679306924343109,
      "learning_rate": 4.678313516667882e-05,
      "loss": 0.0053,
      "step": 4410
    },
    {
      "epoch": 0.3224159311401269,
      "grad_norm": 0.11751615256071091,
      "learning_rate": 4.677584068859873e-05,
      "loss": 0.0057,
      "step": 4420
    },
    {
      "epoch": 0.3231453789481363,
      "grad_norm": 0.20538678765296936,
      "learning_rate": 4.676854621051864e-05,
      "loss": 0.0054,
      "step": 4430
    },
    {
      "epoch": 0.3238748267561456,
      "grad_norm": 0.2066826969385147,
      "learning_rate": 4.6761251732438546e-05,
      "loss": 0.0063,
      "step": 4440
    },
    {
      "epoch": 0.3246042745641549,
      "grad_norm": 0.23284131288528442,
      "learning_rate": 4.6753957254358453e-05,
      "loss": 0.0044,
      "step": 4450
    },
    {
      "epoch": 0.3253337223721643,
      "grad_norm": 0.1460127979516983,
      "learning_rate": 4.674666277627836e-05,
      "loss": 0.0059,
      "step": 4460
    },
    {
      "epoch": 0.3260631701801736,
      "grad_norm": 0.17729836702346802,
      "learning_rate": 4.673936829819827e-05,
      "loss": 0.0075,
      "step": 4470
    },
    {
      "epoch": 0.32679261798818293,
      "grad_norm": 0.19442950189113617,
      "learning_rate": 4.673207382011817e-05,
      "loss": 0.0055,
      "step": 4480
    },
    {
      "epoch": 0.3275220657961923,
      "grad_norm": 0.11829204112291336,
      "learning_rate": 4.672477934203808e-05,
      "loss": 0.0061,
      "step": 4490
    },
    {
      "epoch": 0.32825151360420163,
      "grad_norm": 0.03041781112551689,
      "learning_rate": 4.671748486395799e-05,
      "loss": 0.0043,
      "step": 4500
    },
    {
      "epoch": 0.32898096141221095,
      "grad_norm": 0.07299552112817764,
      "learning_rate": 4.671019038587789e-05,
      "loss": 0.0049,
      "step": 4510
    },
    {
      "epoch": 0.32971040922022027,
      "grad_norm": 0.35039207339286804,
      "learning_rate": 4.67028959077978e-05,
      "loss": 0.0047,
      "step": 4520
    },
    {
      "epoch": 0.33043985702822964,
      "grad_norm": 0.4664704501628876,
      "learning_rate": 4.669560142971771e-05,
      "loss": 0.0057,
      "step": 4530
    },
    {
      "epoch": 0.33116930483623896,
      "grad_norm": 0.05856110900640488,
      "learning_rate": 4.6688306951637614e-05,
      "loss": 0.0057,
      "step": 4540
    },
    {
      "epoch": 0.3318987526442483,
      "grad_norm": 0.3495979905128479,
      "learning_rate": 4.6681012473557515e-05,
      "loss": 0.0057,
      "step": 4550
    },
    {
      "epoch": 0.33262820045225766,
      "grad_norm": 0.03905739635229111,
      "learning_rate": 4.667371799547743e-05,
      "loss": 0.0081,
      "step": 4560
    },
    {
      "epoch": 0.333357648260267,
      "grad_norm": 0.06441714614629745,
      "learning_rate": 4.666642351739734e-05,
      "loss": 0.008,
      "step": 4570
    },
    {
      "epoch": 0.3340870960682763,
      "grad_norm": 0.4375353157520294,
      "learning_rate": 4.665912903931724e-05,
      "loss": 0.0046,
      "step": 4580
    },
    {
      "epoch": 0.3348165438762857,
      "grad_norm": 0.26260825991630554,
      "learning_rate": 4.6651834561237145e-05,
      "loss": 0.0066,
      "step": 4590
    },
    {
      "epoch": 0.335545991684295,
      "grad_norm": 0.2913365364074707,
      "learning_rate": 4.664454008315705e-05,
      "loss": 0.0049,
      "step": 4600
    },
    {
      "epoch": 0.3362754394923043,
      "grad_norm": 0.29141318798065186,
      "learning_rate": 4.6637245605076954e-05,
      "loss": 0.0056,
      "step": 4610
    },
    {
      "epoch": 0.33700488730031364,
      "grad_norm": 0.3502768576145172,
      "learning_rate": 4.662995112699687e-05,
      "loss": 0.0079,
      "step": 4620
    },
    {
      "epoch": 0.337734335108323,
      "grad_norm": 0.058823779225349426,
      "learning_rate": 4.6622656648916775e-05,
      "loss": 0.0069,
      "step": 4630
    },
    {
      "epoch": 0.33846378291633233,
      "grad_norm": 0.3491165339946747,
      "learning_rate": 4.6615362170836676e-05,
      "loss": 0.0054,
      "step": 4640
    },
    {
      "epoch": 0.33919323072434165,
      "grad_norm": 0.11676927655935287,
      "learning_rate": 4.6608067692756584e-05,
      "loss": 0.0056,
      "step": 4650
    },
    {
      "epoch": 0.33992267853235103,
      "grad_norm": 0.1462618112564087,
      "learning_rate": 4.660077321467649e-05,
      "loss": 0.005,
      "step": 4660
    },
    {
      "epoch": 0.34065212634036035,
      "grad_norm": 0.30069825053215027,
      "learning_rate": 4.65934787365964e-05,
      "loss": 0.0067,
      "step": 4670
    },
    {
      "epoch": 0.34138157414836967,
      "grad_norm": 0.2952561676502228,
      "learning_rate": 4.6586184258516306e-05,
      "loss": 0.0047,
      "step": 4680
    },
    {
      "epoch": 0.34211102195637905,
      "grad_norm": 0.6984318494796753,
      "learning_rate": 4.6578889780436214e-05,
      "loss": 0.0051,
      "step": 4690
    },
    {
      "epoch": 0.34284046976438837,
      "grad_norm": 0.34994134306907654,
      "learning_rate": 4.657159530235612e-05,
      "loss": 0.0043,
      "step": 4700
    },
    {
      "epoch": 0.3435699175723977,
      "grad_norm": 0.08778253942728043,
      "learning_rate": 4.656430082427602e-05,
      "loss": 0.0068,
      "step": 4710
    },
    {
      "epoch": 0.344299365380407,
      "grad_norm": 0.05906761810183525,
      "learning_rate": 4.655700634619593e-05,
      "loss": 0.0067,
      "step": 4720
    },
    {
      "epoch": 0.3450288131884164,
      "grad_norm": 0.23941558599472046,
      "learning_rate": 4.654971186811584e-05,
      "loss": 0.0054,
      "step": 4730
    },
    {
      "epoch": 0.3457582609964257,
      "grad_norm": 0.05930532142519951,
      "learning_rate": 4.6542417390035745e-05,
      "loss": 0.0062,
      "step": 4740
    },
    {
      "epoch": 0.346487708804435,
      "grad_norm": 0.11706539243459702,
      "learning_rate": 4.653512291195565e-05,
      "loss": 0.0056,
      "step": 4750
    },
    {
      "epoch": 0.3472171566124444,
      "grad_norm": 0.007686052471399307,
      "learning_rate": 4.652782843387556e-05,
      "loss": 0.0046,
      "step": 4760
    },
    {
      "epoch": 0.3479466044204537,
      "grad_norm": 0.2334161102771759,
      "learning_rate": 4.652053395579547e-05,
      "loss": 0.0069,
      "step": 4770
    },
    {
      "epoch": 0.34867605222846304,
      "grad_norm": 0.20431002974510193,
      "learning_rate": 4.651323947771537e-05,
      "loss": 0.005,
      "step": 4780
    },
    {
      "epoch": 0.3494055000364724,
      "grad_norm": 0.058515142649412155,
      "learning_rate": 4.6505944999635276e-05,
      "loss": 0.0068,
      "step": 4790
    },
    {
      "epoch": 0.35013494784448174,
      "grad_norm": 0.05828925967216492,
      "learning_rate": 4.649865052155519e-05,
      "loss": 0.0046,
      "step": 4800
    },
    {
      "epoch": 0.35086439565249106,
      "grad_norm": 0.11638060957193375,
      "learning_rate": 4.649135604347509e-05,
      "loss": 0.0058,
      "step": 4810
    },
    {
      "epoch": 0.3515938434605004,
      "grad_norm": 0.14560024440288544,
      "learning_rate": 4.6484061565395e-05,
      "loss": 0.0042,
      "step": 4820
    },
    {
      "epoch": 0.35232329126850975,
      "grad_norm": 0.4943406581878662,
      "learning_rate": 4.6476767087314906e-05,
      "loss": 0.0061,
      "step": 4830
    },
    {
      "epoch": 0.3530527390765191,
      "grad_norm": 0.07613818347454071,
      "learning_rate": 4.646947260923481e-05,
      "loss": 0.0078,
      "step": 4840
    },
    {
      "epoch": 0.3537821868845284,
      "grad_norm": 0.2613629400730133,
      "learning_rate": 4.6462178131154714e-05,
      "loss": 0.007,
      "step": 4850
    },
    {
      "epoch": 0.35451163469253777,
      "grad_norm": 0.014681940898299217,
      "learning_rate": 4.645488365307463e-05,
      "loss": 0.0072,
      "step": 4860
    },
    {
      "epoch": 0.3552410825005471,
      "grad_norm": 0.012593740597367287,
      "learning_rate": 4.6447589174994536e-05,
      "loss": 0.0075,
      "step": 4870
    },
    {
      "epoch": 0.3559705303085564,
      "grad_norm": 0.059122130274772644,
      "learning_rate": 4.6440294696914437e-05,
      "loss": 0.0069,
      "step": 4880
    },
    {
      "epoch": 0.3566999781165658,
      "grad_norm": 0.0585174486041069,
      "learning_rate": 4.6433000218834344e-05,
      "loss": 0.0062,
      "step": 4890
    },
    {
      "epoch": 0.3574294259245751,
      "grad_norm": 0.17490114271640778,
      "learning_rate": 4.642570574075425e-05,
      "loss": 0.0064,
      "step": 4900
    },
    {
      "epoch": 0.3581588737325844,
      "grad_norm": 0.1922304779291153,
      "learning_rate": 4.641841126267415e-05,
      "loss": 0.0068,
      "step": 4910
    },
    {
      "epoch": 0.35888832154059375,
      "grad_norm": 0.008788186125457287,
      "learning_rate": 4.641111678459407e-05,
      "loss": 0.0058,
      "step": 4920
    },
    {
      "epoch": 0.3596177693486031,
      "grad_norm": 0.01159160677343607,
      "learning_rate": 4.6403822306513974e-05,
      "loss": 0.0065,
      "step": 4930
    },
    {
      "epoch": 0.36034721715661244,
      "grad_norm": 0.14553005993366241,
      "learning_rate": 4.6396527828433875e-05,
      "loss": 0.0042,
      "step": 4940
    },
    {
      "epoch": 0.36107666496462176,
      "grad_norm": 0.2046375870704651,
      "learning_rate": 4.638923335035378e-05,
      "loss": 0.0055,
      "step": 4950
    },
    {
      "epoch": 0.36180611277263114,
      "grad_norm": 0.008080793544650078,
      "learning_rate": 4.638193887227369e-05,
      "loss": 0.0075,
      "step": 4960
    },
    {
      "epoch": 0.36253556058064046,
      "grad_norm": 0.20446380972862244,
      "learning_rate": 4.63746443941936e-05,
      "loss": 0.0064,
      "step": 4970
    },
    {
      "epoch": 0.3632650083886498,
      "grad_norm": 0.11698485165834427,
      "learning_rate": 4.6367349916113505e-05,
      "loss": 0.0044,
      "step": 4980
    },
    {
      "epoch": 0.36399445619665916,
      "grad_norm": 0.05889591574668884,
      "learning_rate": 4.636005543803341e-05,
      "loss": 0.0064,
      "step": 4990
    },
    {
      "epoch": 0.3647239040046685,
      "grad_norm": 0.8157882690429688,
      "learning_rate": 4.635276095995332e-05,
      "loss": 0.0061,
      "step": 5000
    },
    {
      "epoch": 0.3654533518126778,
      "grad_norm": 0.17460842430591583,
      "learning_rate": 4.634546648187322e-05,
      "loss": 0.0075,
      "step": 5010
    },
    {
      "epoch": 0.3661827996206871,
      "grad_norm": 0.611966073513031,
      "learning_rate": 4.633817200379313e-05,
      "loss": 0.0068,
      "step": 5020
    },
    {
      "epoch": 0.3669122474286965,
      "grad_norm": 0.35079899430274963,
      "learning_rate": 4.633087752571304e-05,
      "loss": 0.0053,
      "step": 5030
    },
    {
      "epoch": 0.3676416952367058,
      "grad_norm": 0.11589151620864868,
      "learning_rate": 4.6323583047632943e-05,
      "loss": 0.0052,
      "step": 5040
    },
    {
      "epoch": 0.36837114304471513,
      "grad_norm": 0.05861712247133255,
      "learning_rate": 4.631628856955285e-05,
      "loss": 0.0045,
      "step": 5050
    },
    {
      "epoch": 0.3691005908527245,
      "grad_norm": 0.4070974886417389,
      "learning_rate": 4.630899409147276e-05,
      "loss": 0.007,
      "step": 5060
    },
    {
      "epoch": 0.36983003866073383,
      "grad_norm": 0.17409174144268036,
      "learning_rate": 4.6301699613392666e-05,
      "loss": 0.0063,
      "step": 5070
    },
    {
      "epoch": 0.37055948646874315,
      "grad_norm": 0.05840501934289932,
      "learning_rate": 4.629440513531257e-05,
      "loss": 0.0055,
      "step": 5080
    },
    {
      "epoch": 0.3712889342767525,
      "grad_norm": 0.11632529646158218,
      "learning_rate": 4.628711065723248e-05,
      "loss": 0.0058,
      "step": 5090
    },
    {
      "epoch": 0.37201838208476184,
      "grad_norm": 0.11635198444128036,
      "learning_rate": 4.627981617915239e-05,
      "loss": 0.006,
      "step": 5100
    },
    {
      "epoch": 0.37274782989277117,
      "grad_norm": 0.058115534484386444,
      "learning_rate": 4.627252170107229e-05,
      "loss": 0.0039,
      "step": 5110
    },
    {
      "epoch": 0.3734772777007805,
      "grad_norm": 0.05885050445795059,
      "learning_rate": 4.62652272229922e-05,
      "loss": 0.0072,
      "step": 5120
    },
    {
      "epoch": 0.37420672550878986,
      "grad_norm": 0.011360001750290394,
      "learning_rate": 4.6257932744912104e-05,
      "loss": 0.0069,
      "step": 5130
    },
    {
      "epoch": 0.3749361733167992,
      "grad_norm": 0.05858663097023964,
      "learning_rate": 4.6250638266832005e-05,
      "loss": 0.0073,
      "step": 5140
    },
    {
      "epoch": 0.3756656211248085,
      "grad_norm": 0.5236740708351135,
      "learning_rate": 4.624334378875192e-05,
      "loss": 0.0055,
      "step": 5150
    },
    {
      "epoch": 0.3763950689328179,
      "grad_norm": 0.23399491608142853,
      "learning_rate": 4.623604931067183e-05,
      "loss": 0.0082,
      "step": 5160
    },
    {
      "epoch": 0.3771245167408272,
      "grad_norm": 0.05935989320278168,
      "learning_rate": 4.622875483259173e-05,
      "loss": 0.0057,
      "step": 5170
    },
    {
      "epoch": 0.3778539645488365,
      "grad_norm": 0.17412497103214264,
      "learning_rate": 4.6221460354511635e-05,
      "loss": 0.0063,
      "step": 5180
    },
    {
      "epoch": 0.3785834123568459,
      "grad_norm": 0.5242505669593811,
      "learning_rate": 4.621416587643154e-05,
      "loss": 0.0055,
      "step": 5190
    },
    {
      "epoch": 0.3793128601648552,
      "grad_norm": 0.011754990555346012,
      "learning_rate": 4.620687139835145e-05,
      "loss": 0.0038,
      "step": 5200
    },
    {
      "epoch": 0.38004230797286453,
      "grad_norm": 0.11720730364322662,
      "learning_rate": 4.619957692027136e-05,
      "loss": 0.0066,
      "step": 5210
    },
    {
      "epoch": 0.38077175578087386,
      "grad_norm": 0.05974702164530754,
      "learning_rate": 4.6192282442191265e-05,
      "loss": 0.0048,
      "step": 5220
    },
    {
      "epoch": 0.38150120358888323,
      "grad_norm": 0.23252961039543152,
      "learning_rate": 4.618498796411117e-05,
      "loss": 0.005,
      "step": 5230
    },
    {
      "epoch": 0.38223065139689255,
      "grad_norm": 0.23255158960819244,
      "learning_rate": 4.6177693486031074e-05,
      "loss": 0.0066,
      "step": 5240
    },
    {
      "epoch": 0.38296009920490187,
      "grad_norm": 0.1753903180360794,
      "learning_rate": 4.617039900795098e-05,
      "loss": 0.0046,
      "step": 5250
    },
    {
      "epoch": 0.38368954701291125,
      "grad_norm": 0.23432832956314087,
      "learning_rate": 4.616310452987089e-05,
      "loss": 0.0049,
      "step": 5260
    },
    {
      "epoch": 0.38441899482092057,
      "grad_norm": 0.11719171702861786,
      "learning_rate": 4.6155810051790796e-05,
      "loss": 0.0063,
      "step": 5270
    },
    {
      "epoch": 0.3851484426289299,
      "grad_norm": 0.46557483077049255,
      "learning_rate": 4.6148515573710704e-05,
      "loss": 0.007,
      "step": 5280
    },
    {
      "epoch": 0.38587789043693926,
      "grad_norm": 0.061233967542648315,
      "learning_rate": 4.614122109563061e-05,
      "loss": 0.0049,
      "step": 5290
    },
    {
      "epoch": 0.3866073382449486,
      "grad_norm": 0.2332974076271057,
      "learning_rate": 4.613392661755052e-05,
      "loss": 0.0049,
      "step": 5300
    },
    {
      "epoch": 0.3873367860529579,
      "grad_norm": 0.007214661687612534,
      "learning_rate": 4.612663213947042e-05,
      "loss": 0.0062,
      "step": 5310
    },
    {
      "epoch": 0.3880662338609672,
      "grad_norm": 0.14517976343631744,
      "learning_rate": 4.611933766139033e-05,
      "loss": 0.0062,
      "step": 5320
    },
    {
      "epoch": 0.3887956816689766,
      "grad_norm": 0.08776494115591049,
      "learning_rate": 4.611204318331024e-05,
      "loss": 0.0068,
      "step": 5330
    },
    {
      "epoch": 0.3895251294769859,
      "grad_norm": 0.01903461664915085,
      "learning_rate": 4.610474870523014e-05,
      "loss": 0.0064,
      "step": 5340
    },
    {
      "epoch": 0.39025457728499524,
      "grad_norm": 0.2581443190574646,
      "learning_rate": 4.609745422715005e-05,
      "loss": 0.0055,
      "step": 5350
    },
    {
      "epoch": 0.3909840250930046,
      "grad_norm": 0.23328441381454468,
      "learning_rate": 4.609015974906996e-05,
      "loss": 0.0074,
      "step": 5360
    },
    {
      "epoch": 0.39171347290101394,
      "grad_norm": 0.34934723377227783,
      "learning_rate": 4.608286527098986e-05,
      "loss": 0.0044,
      "step": 5370
    },
    {
      "epoch": 0.39244292070902326,
      "grad_norm": 0.4656246602535248,
      "learning_rate": 4.6075570792909766e-05,
      "loss": 0.0051,
      "step": 5380
    },
    {
      "epoch": 0.39317236851703263,
      "grad_norm": 0.05869203433394432,
      "learning_rate": 4.606827631482968e-05,
      "loss": 0.0046,
      "step": 5390
    },
    {
      "epoch": 0.39390181632504195,
      "grad_norm": 0.029311703518033028,
      "learning_rate": 4.606098183674958e-05,
      "loss": 0.0057,
      "step": 5400
    },
    {
      "epoch": 0.3946312641330513,
      "grad_norm": 0.05803261697292328,
      "learning_rate": 4.605368735866949e-05,
      "loss": 0.0063,
      "step": 5410
    },
    {
      "epoch": 0.3953607119410606,
      "grad_norm": 0.37793493270874023,
      "learning_rate": 4.6046392880589396e-05,
      "loss": 0.0051,
      "step": 5420
    },
    {
      "epoch": 0.39609015974906997,
      "grad_norm": 0.05859261378645897,
      "learning_rate": 4.60390984025093e-05,
      "loss": 0.0056,
      "step": 5430
    },
    {
      "epoch": 0.3968196075570793,
      "grad_norm": 0.008262609131634235,
      "learning_rate": 4.6031803924429204e-05,
      "loss": 0.0047,
      "step": 5440
    },
    {
      "epoch": 0.3975490553650886,
      "grad_norm": 0.27388453483581543,
      "learning_rate": 4.602450944634912e-05,
      "loss": 0.0048,
      "step": 5450
    },
    {
      "epoch": 0.398278503173098,
      "grad_norm": 0.08692283928394318,
      "learning_rate": 4.6017214968269026e-05,
      "loss": 0.0068,
      "step": 5460
    },
    {
      "epoch": 0.3990079509811073,
      "grad_norm": 0.11603224277496338,
      "learning_rate": 4.6009920490188927e-05,
      "loss": 0.0064,
      "step": 5470
    },
    {
      "epoch": 0.3997373987891166,
      "grad_norm": 0.23293358087539673,
      "learning_rate": 4.6002626012108834e-05,
      "loss": 0.0053,
      "step": 5480
    },
    {
      "epoch": 0.400466846597126,
      "grad_norm": 0.23258057236671448,
      "learning_rate": 4.599533153402874e-05,
      "loss": 0.0056,
      "step": 5490
    },
    {
      "epoch": 0.4011962944051353,
      "grad_norm": 0.17405347526073456,
      "learning_rate": 4.598803705594865e-05,
      "loss": 0.0044,
      "step": 5500
    },
    {
      "epoch": 0.40192574221314464,
      "grad_norm": 0.5810410976409912,
      "learning_rate": 4.598074257786856e-05,
      "loss": 0.0049,
      "step": 5510
    },
    {
      "epoch": 0.40265519002115396,
      "grad_norm": 0.17397376894950867,
      "learning_rate": 4.5973448099788464e-05,
      "loss": 0.0052,
      "step": 5520
    },
    {
      "epoch": 0.40338463782916334,
      "grad_norm": 0.05833994969725609,
      "learning_rate": 4.596615362170837e-05,
      "loss": 0.0052,
      "step": 5530
    },
    {
      "epoch": 0.40411408563717266,
      "grad_norm": 0.1745268553495407,
      "learning_rate": 4.595885914362827e-05,
      "loss": 0.0061,
      "step": 5540
    },
    {
      "epoch": 0.404843533445182,
      "grad_norm": 0.24493275582790375,
      "learning_rate": 4.595156466554818e-05,
      "loss": 0.0049,
      "step": 5550
    },
    {
      "epoch": 0.40557298125319136,
      "grad_norm": 0.05835162475705147,
      "learning_rate": 4.5944270187468094e-05,
      "loss": 0.0072,
      "step": 5560
    },
    {
      "epoch": 0.4063024290612007,
      "grad_norm": 0.17345693707466125,
      "learning_rate": 4.5936975709387995e-05,
      "loss": 0.006,
      "step": 5570
    },
    {
      "epoch": 0.40703187686921,
      "grad_norm": 0.435431569814682,
      "learning_rate": 4.59296812313079e-05,
      "loss": 0.0045,
      "step": 5580
    },
    {
      "epoch": 0.4077613246772194,
      "grad_norm": 0.1678391993045807,
      "learning_rate": 4.592238675322781e-05,
      "loss": 0.0077,
      "step": 5590
    },
    {
      "epoch": 0.4084907724852287,
      "grad_norm": 0.03127870708703995,
      "learning_rate": 4.591509227514771e-05,
      "loss": 0.0067,
      "step": 5600
    },
    {
      "epoch": 0.409220220293238,
      "grad_norm": 0.23287741839885712,
      "learning_rate": 4.590779779706762e-05,
      "loss": 0.0078,
      "step": 5610
    },
    {
      "epoch": 0.40994966810124733,
      "grad_norm": 0.029398266226053238,
      "learning_rate": 4.590050331898753e-05,
      "loss": 0.0053,
      "step": 5620
    },
    {
      "epoch": 0.4106791159092567,
      "grad_norm": 0.20349997282028198,
      "learning_rate": 4.5893208840907434e-05,
      "loss": 0.0055,
      "step": 5630
    },
    {
      "epoch": 0.41140856371726603,
      "grad_norm": 0.29103565216064453,
      "learning_rate": 4.588591436282734e-05,
      "loss": 0.0051,
      "step": 5640
    },
    {
      "epoch": 0.41213801152527535,
      "grad_norm": 0.11594290286302567,
      "learning_rate": 4.587861988474725e-05,
      "loss": 0.0056,
      "step": 5650
    },
    {
      "epoch": 0.4128674593332847,
      "grad_norm": 0.02956533245742321,
      "learning_rate": 4.5871325406667156e-05,
      "loss": 0.0052,
      "step": 5660
    },
    {
      "epoch": 0.41359690714129405,
      "grad_norm": 0.23294106125831604,
      "learning_rate": 4.586403092858706e-05,
      "loss": 0.0069,
      "step": 5670
    },
    {
      "epoch": 0.41432635494930337,
      "grad_norm": 0.17395739257335663,
      "learning_rate": 4.585673645050697e-05,
      "loss": 0.0078,
      "step": 5680
    },
    {
      "epoch": 0.41505580275731274,
      "grad_norm": 0.11651994287967682,
      "learning_rate": 4.584944197242688e-05,
      "loss": 0.0069,
      "step": 5690
    },
    {
      "epoch": 0.41578525056532206,
      "grad_norm": 0.11727540194988251,
      "learning_rate": 4.584214749434678e-05,
      "loss": 0.0059,
      "step": 5700
    },
    {
      "epoch": 0.4165146983733314,
      "grad_norm": 0.1745895892381668,
      "learning_rate": 4.583485301626669e-05,
      "loss": 0.0064,
      "step": 5710
    },
    {
      "epoch": 0.4172441461813407,
      "grad_norm": 0.464836061000824,
      "learning_rate": 4.5827558538186595e-05,
      "loss": 0.0063,
      "step": 5720
    },
    {
      "epoch": 0.4179735939893501,
      "grad_norm": 0.05990492179989815,
      "learning_rate": 4.58202640601065e-05,
      "loss": 0.0058,
      "step": 5730
    },
    {
      "epoch": 0.4187030417973594,
      "grad_norm": 0.05821127071976662,
      "learning_rate": 4.581296958202641e-05,
      "loss": 0.0062,
      "step": 5740
    },
    {
      "epoch": 0.4194324896053687,
      "grad_norm": 0.08805220574140549,
      "learning_rate": 4.580567510394632e-05,
      "loss": 0.0054,
      "step": 5750
    },
    {
      "epoch": 0.4201619374133781,
      "grad_norm": 0.05965843424201012,
      "learning_rate": 4.5798380625866225e-05,
      "loss": 0.0062,
      "step": 5760
    },
    {
      "epoch": 0.4208913852213874,
      "grad_norm": 0.06022920459508896,
      "learning_rate": 4.5791086147786125e-05,
      "loss": 0.0043,
      "step": 5770
    },
    {
      "epoch": 0.42162083302939674,
      "grad_norm": 0.11599640548229218,
      "learning_rate": 4.578379166970603e-05,
      "loss": 0.004,
      "step": 5780
    },
    {
      "epoch": 0.4223502808374061,
      "grad_norm": 0.059041932225227356,
      "learning_rate": 4.577649719162594e-05,
      "loss": 0.005,
      "step": 5790
    },
    {
      "epoch": 0.42307972864541543,
      "grad_norm": 0.4665658473968506,
      "learning_rate": 4.576920271354585e-05,
      "loss": 0.0033,
      "step": 5800
    },
    {
      "epoch": 0.42380917645342475,
      "grad_norm": 0.11683329194784164,
      "learning_rate": 4.5761908235465756e-05,
      "loss": 0.005,
      "step": 5810
    },
    {
      "epoch": 0.42453862426143407,
      "grad_norm": 0.4068598449230194,
      "learning_rate": 4.575461375738566e-05,
      "loss": 0.0056,
      "step": 5820
    },
    {
      "epoch": 0.42526807206944345,
      "grad_norm": 0.23243685066699982,
      "learning_rate": 4.5747319279305564e-05,
      "loss": 0.0068,
      "step": 5830
    },
    {
      "epoch": 0.42599751987745277,
      "grad_norm": 0.05901217833161354,
      "learning_rate": 4.574002480122547e-05,
      "loss": 0.0049,
      "step": 5840
    },
    {
      "epoch": 0.4267269676854621,
      "grad_norm": 0.1162586361169815,
      "learning_rate": 4.573273032314538e-05,
      "loss": 0.0056,
      "step": 5850
    },
    {
      "epoch": 0.42745641549347146,
      "grad_norm": 0.1454794704914093,
      "learning_rate": 4.5725435845065286e-05,
      "loss": 0.0054,
      "step": 5860
    },
    {
      "epoch": 0.4281858633014808,
      "grad_norm": 0.4647320508956909,
      "learning_rate": 4.5718141366985194e-05,
      "loss": 0.0063,
      "step": 5870
    },
    {
      "epoch": 0.4289153111094901,
      "grad_norm": 0.2320515662431717,
      "learning_rate": 4.57108468889051e-05,
      "loss": 0.0068,
      "step": 5880
    },
    {
      "epoch": 0.4296447589174994,
      "grad_norm": 0.059716127812862396,
      "learning_rate": 4.570355241082501e-05,
      "loss": 0.0055,
      "step": 5890
    },
    {
      "epoch": 0.4303742067255088,
      "grad_norm": 0.11562954634428024,
      "learning_rate": 4.569625793274491e-05,
      "loss": 0.0073,
      "step": 5900
    },
    {
      "epoch": 0.4311036545335181,
      "grad_norm": 0.20380134880542755,
      "learning_rate": 4.568896345466482e-05,
      "loss": 0.0055,
      "step": 5910
    },
    {
      "epoch": 0.43183310234152744,
      "grad_norm": 0.2949955463409424,
      "learning_rate": 4.568166897658473e-05,
      "loss": 0.0061,
      "step": 5920
    },
    {
      "epoch": 0.4325625501495368,
      "grad_norm": 0.05894521251320839,
      "learning_rate": 4.567437449850463e-05,
      "loss": 0.0066,
      "step": 5930
    },
    {
      "epoch": 0.43329199795754614,
      "grad_norm": 0.04439708963036537,
      "learning_rate": 4.566708002042454e-05,
      "loss": 0.0052,
      "step": 5940
    },
    {
      "epoch": 0.43402144576555546,
      "grad_norm": 0.05822514742612839,
      "learning_rate": 4.565978554234445e-05,
      "loss": 0.004,
      "step": 5950
    },
    {
      "epoch": 0.43475089357356483,
      "grad_norm": 0.39850348234176636,
      "learning_rate": 4.5652491064264355e-05,
      "loss": 0.0032,
      "step": 5960
    },
    {
      "epoch": 0.43548034138157415,
      "grad_norm": 0.23717591166496277,
      "learning_rate": 4.564519658618426e-05,
      "loss": 0.0048,
      "step": 5970
    },
    {
      "epoch": 0.4362097891895835,
      "grad_norm": 0.29028812050819397,
      "learning_rate": 4.563790210810417e-05,
      "loss": 0.0062,
      "step": 5980
    },
    {
      "epoch": 0.4369392369975928,
      "grad_norm": 0.6088395714759827,
      "learning_rate": 4.563060763002408e-05,
      "loss": 0.0053,
      "step": 5990
    },
    {
      "epoch": 0.43766868480560217,
      "grad_norm": 0.3504594564437866,
      "learning_rate": 4.562331315194398e-05,
      "loss": 0.0053,
      "step": 6000
    },
    {
      "epoch": 0.4383981326136115,
      "grad_norm": 0.029569532722234726,
      "learning_rate": 4.5616018673863886e-05,
      "loss": 0.0062,
      "step": 6010
    },
    {
      "epoch": 0.4391275804216208,
      "grad_norm": 0.14672598242759705,
      "learning_rate": 4.560872419578379e-05,
      "loss": 0.005,
      "step": 6020
    },
    {
      "epoch": 0.4398570282296302,
      "grad_norm": 0.2894439995288849,
      "learning_rate": 4.56014297177037e-05,
      "loss": 0.0054,
      "step": 6030
    },
    {
      "epoch": 0.4405864760376395,
      "grad_norm": 0.058943506330251694,
      "learning_rate": 4.559413523962361e-05,
      "loss": 0.0048,
      "step": 6040
    },
    {
      "epoch": 0.4413159238456488,
      "grad_norm": 0.17391657829284668,
      "learning_rate": 4.5586840761543516e-05,
      "loss": 0.0054,
      "step": 6050
    },
    {
      "epoch": 0.4420453716536582,
      "grad_norm": 0.08748575299978256,
      "learning_rate": 4.5579546283463423e-05,
      "loss": 0.0053,
      "step": 6060
    },
    {
      "epoch": 0.4427748194616675,
      "grad_norm": 0.29008743166923523,
      "learning_rate": 4.5572251805383324e-05,
      "loss": 0.0056,
      "step": 6070
    },
    {
      "epoch": 0.44350426726967684,
      "grad_norm": 0.20325107872486115,
      "learning_rate": 4.556495732730323e-05,
      "loss": 0.0067,
      "step": 6080
    },
    {
      "epoch": 0.44423371507768616,
      "grad_norm": 0.4061570167541504,
      "learning_rate": 4.5557662849223146e-05,
      "loss": 0.005,
      "step": 6090
    },
    {
      "epoch": 0.44496316288569554,
      "grad_norm": 0.11623690277338028,
      "learning_rate": 4.555036837114305e-05,
      "loss": 0.0051,
      "step": 6100
    },
    {
      "epoch": 0.44569261069370486,
      "grad_norm": 0.2343483418226242,
      "learning_rate": 4.5543073893062954e-05,
      "loss": 0.0054,
      "step": 6110
    },
    {
      "epoch": 0.4464220585017142,
      "grad_norm": 0.3786035180091858,
      "learning_rate": 4.553577941498286e-05,
      "loss": 0.0062,
      "step": 6120
    },
    {
      "epoch": 0.44715150630972356,
      "grad_norm": 0.40531814098358154,
      "learning_rate": 4.552848493690276e-05,
      "loss": 0.0051,
      "step": 6130
    },
    {
      "epoch": 0.4478809541177329,
      "grad_norm": 0.03023303486406803,
      "learning_rate": 4.552119045882267e-05,
      "loss": 0.0043,
      "step": 6140
    },
    {
      "epoch": 0.4486104019257422,
      "grad_norm": 0.4057348966598511,
      "learning_rate": 4.5513895980742584e-05,
      "loss": 0.0054,
      "step": 6150
    },
    {
      "epoch": 0.4493398497337516,
      "grad_norm": 0.28961488604545593,
      "learning_rate": 4.5506601502662485e-05,
      "loss": 0.0062,
      "step": 6160
    },
    {
      "epoch": 0.4500692975417609,
      "grad_norm": 0.0589669793844223,
      "learning_rate": 4.549930702458239e-05,
      "loss": 0.0053,
      "step": 6170
    },
    {
      "epoch": 0.4507987453497702,
      "grad_norm": 0.1731892228126526,
      "learning_rate": 4.54920125465023e-05,
      "loss": 0.0067,
      "step": 6180
    },
    {
      "epoch": 0.45152819315777953,
      "grad_norm": 0.31833410263061523,
      "learning_rate": 4.548471806842221e-05,
      "loss": 0.0059,
      "step": 6190
    },
    {
      "epoch": 0.4522576409657889,
      "grad_norm": 0.4060407876968384,
      "learning_rate": 4.547742359034211e-05,
      "loss": 0.0049,
      "step": 6200
    },
    {
      "epoch": 0.45298708877379823,
      "grad_norm": 0.2712816298007965,
      "learning_rate": 4.547012911226202e-05,
      "loss": 0.0053,
      "step": 6210
    },
    {
      "epoch": 0.45371653658180755,
      "grad_norm": 0.17419934272766113,
      "learning_rate": 4.546283463418193e-05,
      "loss": 0.0052,
      "step": 6220
    },
    {
      "epoch": 0.4544459843898169,
      "grad_norm": 0.4072677493095398,
      "learning_rate": 4.545554015610183e-05,
      "loss": 0.0066,
      "step": 6230
    },
    {
      "epoch": 0.45517543219782625,
      "grad_norm": 0.14544853568077087,
      "learning_rate": 4.544824567802174e-05,
      "loss": 0.0047,
      "step": 6240
    },
    {
      "epoch": 0.45590488000583557,
      "grad_norm": 0.43564483523368835,
      "learning_rate": 4.5440951199941646e-05,
      "loss": 0.0041,
      "step": 6250
    },
    {
      "epoch": 0.45663432781384494,
      "grad_norm": 0.05814814567565918,
      "learning_rate": 4.5433656721861554e-05,
      "loss": 0.0058,
      "step": 6260
    },
    {
      "epoch": 0.45736377562185426,
      "grad_norm": 0.007149350829422474,
      "learning_rate": 4.542636224378146e-05,
      "loss": 0.005,
      "step": 6270
    },
    {
      "epoch": 0.4580932234298636,
      "grad_norm": 0.26126953959465027,
      "learning_rate": 4.541906776570137e-05,
      "loss": 0.0051,
      "step": 6280
    },
    {
      "epoch": 0.4588226712378729,
      "grad_norm": 0.26638635993003845,
      "learning_rate": 4.5411773287621276e-05,
      "loss": 0.0051,
      "step": 6290
    },
    {
      "epoch": 0.4595521190458823,
      "grad_norm": 0.058109916746616364,
      "learning_rate": 4.540447880954118e-05,
      "loss": 0.0069,
      "step": 6300
    },
    {
      "epoch": 0.4602815668538916,
      "grad_norm": 0.11884631216526031,
      "learning_rate": 4.5397184331461085e-05,
      "loss": 0.0052,
      "step": 6310
    },
    {
      "epoch": 0.4610110146619009,
      "grad_norm": 0.7278311848640442,
      "learning_rate": 4.538988985338099e-05,
      "loss": 0.0051,
      "step": 6320
    },
    {
      "epoch": 0.4617404624699103,
      "grad_norm": 0.40709736943244934,
      "learning_rate": 4.53825953753009e-05,
      "loss": 0.0065,
      "step": 6330
    },
    {
      "epoch": 0.4624699102779196,
      "grad_norm": 0.0039787814021110535,
      "learning_rate": 4.537530089722081e-05,
      "loss": 0.0066,
      "step": 6340
    },
    {
      "epoch": 0.46319935808592894,
      "grad_norm": 0.7591769099235535,
      "learning_rate": 4.5368006419140715e-05,
      "loss": 0.0058,
      "step": 6350
    },
    {
      "epoch": 0.4639288058939383,
      "grad_norm": 0.06035767123103142,
      "learning_rate": 4.5360711941060615e-05,
      "loss": 0.0039,
      "step": 6360
    },
    {
      "epoch": 0.46465825370194763,
      "grad_norm": 0.2197355180978775,
      "learning_rate": 4.535341746298052e-05,
      "loss": 0.0055,
      "step": 6370
    },
    {
      "epoch": 0.46538770150995695,
      "grad_norm": 0.030746906995773315,
      "learning_rate": 4.534612298490043e-05,
      "loss": 0.0064,
      "step": 6380
    },
    {
      "epoch": 0.4661171493179663,
      "grad_norm": 0.4083089828491211,
      "learning_rate": 4.533882850682034e-05,
      "loss": 0.0079,
      "step": 6390
    },
    {
      "epoch": 0.46684659712597565,
      "grad_norm": 0.18640393018722534,
      "learning_rate": 4.5331534028740246e-05,
      "loss": 0.0061,
      "step": 6400
    },
    {
      "epoch": 0.46757604493398497,
      "grad_norm": 0.20906247198581696,
      "learning_rate": 4.532423955066015e-05,
      "loss": 0.0055,
      "step": 6410
    },
    {
      "epoch": 0.4683054927419943,
      "grad_norm": 0.20319895446300507,
      "learning_rate": 4.531694507258006e-05,
      "loss": 0.0063,
      "step": 6420
    },
    {
      "epoch": 0.46903494055000367,
      "grad_norm": 0.46506237983703613,
      "learning_rate": 4.530965059449996e-05,
      "loss": 0.0068,
      "step": 6430
    },
    {
      "epoch": 0.469764388358013,
      "grad_norm": 0.2913214862346649,
      "learning_rate": 4.5302356116419876e-05,
      "loss": 0.006,
      "step": 6440
    },
    {
      "epoch": 0.4704938361660223,
      "grad_norm": 0.5803361535072327,
      "learning_rate": 4.529506163833978e-05,
      "loss": 0.0061,
      "step": 6450
    },
    {
      "epoch": 0.4712232839740317,
      "grad_norm": 0.10089632123708725,
      "learning_rate": 4.5287767160259684e-05,
      "loss": 0.0055,
      "step": 6460
    },
    {
      "epoch": 0.471952731782041,
      "grad_norm": 0.29099684953689575,
      "learning_rate": 4.528047268217959e-05,
      "loss": 0.0055,
      "step": 6470
    },
    {
      "epoch": 0.4726821795900503,
      "grad_norm": 0.5495807528495789,
      "learning_rate": 4.52731782040995e-05,
      "loss": 0.0062,
      "step": 6480
    },
    {
      "epoch": 0.47341162739805964,
      "grad_norm": 0.2027558833360672,
      "learning_rate": 4.5265883726019407e-05,
      "loss": 0.0057,
      "step": 6490
    },
    {
      "epoch": 0.474141075206069,
      "grad_norm": 0.20356392860412598,
      "learning_rate": 4.5258589247939314e-05,
      "loss": 0.0055,
      "step": 6500
    },
    {
      "epoch": 0.47487052301407834,
      "grad_norm": 0.174324169754982,
      "learning_rate": 4.525129476985922e-05,
      "loss": 0.0051,
      "step": 6510
    },
    {
      "epoch": 0.47559997082208766,
      "grad_norm": 0.1755913496017456,
      "learning_rate": 4.524400029177913e-05,
      "loss": 0.004,
      "step": 6520
    },
    {
      "epoch": 0.47632941863009703,
      "grad_norm": 0.17419415712356567,
      "learning_rate": 4.523670581369903e-05,
      "loss": 0.0055,
      "step": 6530
    },
    {
      "epoch": 0.47705886643810635,
      "grad_norm": 0.17347994446754456,
      "learning_rate": 4.522941133561894e-05,
      "loss": 0.0058,
      "step": 6540
    },
    {
      "epoch": 0.4777883142461157,
      "grad_norm": 0.23255422711372375,
      "learning_rate": 4.5222116857538845e-05,
      "loss": 0.005,
      "step": 6550
    },
    {
      "epoch": 0.47851776205412505,
      "grad_norm": 0.14501522481441498,
      "learning_rate": 4.521482237945875e-05,
      "loss": 0.0065,
      "step": 6560
    },
    {
      "epoch": 0.47924720986213437,
      "grad_norm": 0.059461988508701324,
      "learning_rate": 4.520752790137866e-05,
      "loss": 0.0086,
      "step": 6570
    },
    {
      "epoch": 0.4799766576701437,
      "grad_norm": 0.28721797466278076,
      "learning_rate": 4.520023342329857e-05,
      "loss": 0.0052,
      "step": 6580
    },
    {
      "epoch": 0.480706105478153,
      "grad_norm": 0.2856858968734741,
      "learning_rate": 4.519293894521847e-05,
      "loss": 0.0061,
      "step": 6590
    },
    {
      "epoch": 0.4814355532861624,
      "grad_norm": 0.3495592772960663,
      "learning_rate": 4.5185644467138376e-05,
      "loss": 0.0033,
      "step": 6600
    },
    {
      "epoch": 0.4821650010941717,
      "grad_norm": 0.06127116456627846,
      "learning_rate": 4.517834998905828e-05,
      "loss": 0.0059,
      "step": 6610
    },
    {
      "epoch": 0.48289444890218103,
      "grad_norm": 0.30012214183807373,
      "learning_rate": 4.517105551097819e-05,
      "loss": 0.0037,
      "step": 6620
    },
    {
      "epoch": 0.4836238967101904,
      "grad_norm": 0.23284931480884552,
      "learning_rate": 4.51637610328981e-05,
      "loss": 0.0052,
      "step": 6630
    },
    {
      "epoch": 0.4843533445181997,
      "grad_norm": 0.5130258202552795,
      "learning_rate": 4.5156466554818006e-05,
      "loss": 0.0044,
      "step": 6640
    },
    {
      "epoch": 0.48508279232620904,
      "grad_norm": 0.059078361839056015,
      "learning_rate": 4.5149172076737913e-05,
      "loss": 0.005,
      "step": 6650
    },
    {
      "epoch": 0.4858122401342184,
      "grad_norm": 0.09127113968133926,
      "learning_rate": 4.5141877598657814e-05,
      "loss": 0.006,
      "step": 6660
    },
    {
      "epoch": 0.48654168794222774,
      "grad_norm": 0.2906228303909302,
      "learning_rate": 4.513458312057772e-05,
      "loss": 0.0062,
      "step": 6670
    },
    {
      "epoch": 0.48727113575023706,
      "grad_norm": 0.17773176729679108,
      "learning_rate": 4.5127288642497636e-05,
      "loss": 0.0053,
      "step": 6680
    },
    {
      "epoch": 0.4880005835582464,
      "grad_norm": 0.1742406040430069,
      "learning_rate": 4.511999416441754e-05,
      "loss": 0.007,
      "step": 6690
    },
    {
      "epoch": 0.48873003136625576,
      "grad_norm": 0.5510310530662537,
      "learning_rate": 4.5112699686337444e-05,
      "loss": 0.0056,
      "step": 6700
    },
    {
      "epoch": 0.4894594791742651,
      "grad_norm": 0.11674099415540695,
      "learning_rate": 4.510540520825735e-05,
      "loss": 0.0057,
      "step": 6710
    },
    {
      "epoch": 0.4901889269822744,
      "grad_norm": 0.00881941244006157,
      "learning_rate": 4.509811073017726e-05,
      "loss": 0.0063,
      "step": 6720
    },
    {
      "epoch": 0.4909183747902838,
      "grad_norm": 0.1753639578819275,
      "learning_rate": 4.509081625209716e-05,
      "loss": 0.0054,
      "step": 6730
    },
    {
      "epoch": 0.4916478225982931,
      "grad_norm": 0.11624173820018768,
      "learning_rate": 4.5083521774017074e-05,
      "loss": 0.0065,
      "step": 6740
    },
    {
      "epoch": 0.4923772704063024,
      "grad_norm": 0.11660436540842056,
      "learning_rate": 4.507622729593698e-05,
      "loss": 0.0058,
      "step": 6750
    },
    {
      "epoch": 0.4931067182143118,
      "grad_norm": 0.2626432776451111,
      "learning_rate": 4.506893281785688e-05,
      "loss": 0.0051,
      "step": 6760
    },
    {
      "epoch": 0.4938361660223211,
      "grad_norm": 0.08753234893083572,
      "learning_rate": 4.506163833977679e-05,
      "loss": 0.0053,
      "step": 6770
    },
    {
      "epoch": 0.49456561383033043,
      "grad_norm": 0.031177354976534843,
      "learning_rate": 4.50543438616967e-05,
      "loss": 0.0059,
      "step": 6780
    },
    {
      "epoch": 0.49529506163833975,
      "grad_norm": 0.5244959592819214,
      "learning_rate": 4.50470493836166e-05,
      "loss": 0.0043,
      "step": 6790
    },
    {
      "epoch": 0.4960245094463491,
      "grad_norm": 0.05929618701338768,
      "learning_rate": 4.503975490553651e-05,
      "loss": 0.0039,
      "step": 6800
    },
    {
      "epoch": 0.49675395725435845,
      "grad_norm": 0.008727248758077621,
      "learning_rate": 4.503246042745642e-05,
      "loss": 0.0077,
      "step": 6810
    },
    {
      "epoch": 0.49748340506236777,
      "grad_norm": 0.2333577275276184,
      "learning_rate": 4.502516594937632e-05,
      "loss": 0.0037,
      "step": 6820
    },
    {
      "epoch": 0.49821285287037714,
      "grad_norm": 0.46636462211608887,
      "learning_rate": 4.501787147129623e-05,
      "loss": 0.0076,
      "step": 6830
    },
    {
      "epoch": 0.49894230067838646,
      "grad_norm": 0.1169239804148674,
      "learning_rate": 4.5010576993216136e-05,
      "loss": 0.0085,
      "step": 6840
    },
    {
      "epoch": 0.4996717484863958,
      "grad_norm": 0.40767911076545715,
      "learning_rate": 4.5003282515136044e-05,
      "loss": 0.0059,
      "step": 6850
    },
    {
      "epoch": 0.5004011962944052,
      "grad_norm": 0.058420103043317795,
      "learning_rate": 4.499598803705595e-05,
      "loss": 0.006,
      "step": 6860
    },
    {
      "epoch": 0.5011306441024145,
      "grad_norm": 0.23183397948741913,
      "learning_rate": 4.498869355897586e-05,
      "loss": 0.0051,
      "step": 6870
    },
    {
      "epoch": 0.5018600919104238,
      "grad_norm": 0.052170392125844955,
      "learning_rate": 4.4981399080895766e-05,
      "loss": 0.0045,
      "step": 6880
    },
    {
      "epoch": 0.5025895397184331,
      "grad_norm": 0.6093759536743164,
      "learning_rate": 4.497410460281567e-05,
      "loss": 0.0046,
      "step": 6890
    },
    {
      "epoch": 0.5033189875264424,
      "grad_norm": 0.2613847851753235,
      "learning_rate": 4.4966810124735575e-05,
      "loss": 0.0042,
      "step": 6900
    },
    {
      "epoch": 0.5040484353344519,
      "grad_norm": 0.2907940149307251,
      "learning_rate": 4.495951564665548e-05,
      "loss": 0.0047,
      "step": 6910
    },
    {
      "epoch": 0.5047778831424612,
      "grad_norm": 0.11756673455238342,
      "learning_rate": 4.495222116857539e-05,
      "loss": 0.0062,
      "step": 6920
    },
    {
      "epoch": 0.5055073309504705,
      "grad_norm": 0.6384658217430115,
      "learning_rate": 4.49449266904953e-05,
      "loss": 0.0044,
      "step": 6930
    },
    {
      "epoch": 0.5062367787584798,
      "grad_norm": 0.23239247500896454,
      "learning_rate": 4.4937632212415205e-05,
      "loss": 0.0046,
      "step": 6940
    },
    {
      "epoch": 0.5069662265664892,
      "grad_norm": 0.14489762485027313,
      "learning_rate": 4.493033773433511e-05,
      "loss": 0.0036,
      "step": 6950
    },
    {
      "epoch": 0.5076956743744985,
      "grad_norm": 0.06047818809747696,
      "learning_rate": 4.492304325625501e-05,
      "loss": 0.005,
      "step": 6960
    },
    {
      "epoch": 0.5084251221825078,
      "grad_norm": 0.2026573270559311,
      "learning_rate": 4.491574877817493e-05,
      "loss": 0.0069,
      "step": 6970
    },
    {
      "epoch": 0.5091545699905172,
      "grad_norm": 0.23237791657447815,
      "learning_rate": 4.4908454300094835e-05,
      "loss": 0.0045,
      "step": 6980
    },
    {
      "epoch": 0.5098840177985265,
      "grad_norm": 0.05844751000404358,
      "learning_rate": 4.4901159822014736e-05,
      "loss": 0.0044,
      "step": 6990
    },
    {
      "epoch": 0.5106134656065359,
      "grad_norm": 0.058675698935985565,
      "learning_rate": 4.489386534393464e-05,
      "loss": 0.0069,
      "step": 7000
    },
    {
      "epoch": 0.5113429134145452,
      "grad_norm": 0.1742057502269745,
      "learning_rate": 4.488657086585455e-05,
      "loss": 0.0054,
      "step": 7010
    },
    {
      "epoch": 0.5120723612225545,
      "grad_norm": 0.40645626187324524,
      "learning_rate": 4.487927638777446e-05,
      "loss": 0.0065,
      "step": 7020
    },
    {
      "epoch": 0.5128018090305638,
      "grad_norm": 0.29012200236320496,
      "learning_rate": 4.4871981909694366e-05,
      "loss": 0.0063,
      "step": 7030
    },
    {
      "epoch": 0.5135312568385731,
      "grad_norm": 0.23200492560863495,
      "learning_rate": 4.486468743161427e-05,
      "loss": 0.0057,
      "step": 7040
    },
    {
      "epoch": 0.5142607046465826,
      "grad_norm": 0.20298370718955994,
      "learning_rate": 4.485739295353418e-05,
      "loss": 0.0066,
      "step": 7050
    },
    {
      "epoch": 0.5149901524545919,
      "grad_norm": 0.008414486423134804,
      "learning_rate": 4.485009847545408e-05,
      "loss": 0.0052,
      "step": 7060
    },
    {
      "epoch": 0.5157196002626012,
      "grad_norm": 0.1455434113740921,
      "learning_rate": 4.484280399737399e-05,
      "loss": 0.0052,
      "step": 7070
    },
    {
      "epoch": 0.5164490480706105,
      "grad_norm": 0.7555873394012451,
      "learning_rate": 4.48355095192939e-05,
      "loss": 0.0044,
      "step": 7080
    },
    {
      "epoch": 0.5171784958786199,
      "grad_norm": 0.08721930533647537,
      "learning_rate": 4.4828215041213804e-05,
      "loss": 0.004,
      "step": 7090
    },
    {
      "epoch": 0.5179079436866292,
      "grad_norm": 0.26117199659347534,
      "learning_rate": 4.482092056313371e-05,
      "loss": 0.0056,
      "step": 7100
    },
    {
      "epoch": 0.5186373914946386,
      "grad_norm": 0.05844214931130409,
      "learning_rate": 4.481362608505362e-05,
      "loss": 0.005,
      "step": 7110
    },
    {
      "epoch": 0.5193668393026479,
      "grad_norm": 0.4351220726966858,
      "learning_rate": 4.480633160697352e-05,
      "loss": 0.0078,
      "step": 7120
    },
    {
      "epoch": 0.5200962871106573,
      "grad_norm": 0.46368464827537537,
      "learning_rate": 4.479903712889343e-05,
      "loss": 0.006,
      "step": 7130
    },
    {
      "epoch": 0.5208257349186666,
      "grad_norm": 0.14474330842494965,
      "learning_rate": 4.4791742650813335e-05,
      "loss": 0.0071,
      "step": 7140
    },
    {
      "epoch": 0.5215551827266759,
      "grad_norm": 0.11646205186843872,
      "learning_rate": 4.478444817273324e-05,
      "loss": 0.0056,
      "step": 7150
    },
    {
      "epoch": 0.5222846305346852,
      "grad_norm": 0.05838600546121597,
      "learning_rate": 4.477715369465315e-05,
      "loss": 0.0035,
      "step": 7160
    },
    {
      "epoch": 0.5230140783426945,
      "grad_norm": 0.00855855643749237,
      "learning_rate": 4.476985921657306e-05,
      "loss": 0.0064,
      "step": 7170
    },
    {
      "epoch": 0.523743526150704,
      "grad_norm": 0.4821825325489044,
      "learning_rate": 4.4762564738492965e-05,
      "loss": 0.0057,
      "step": 7180
    },
    {
      "epoch": 0.5244729739587133,
      "grad_norm": 0.31871479749679565,
      "learning_rate": 4.4755270260412866e-05,
      "loss": 0.0078,
      "step": 7190
    },
    {
      "epoch": 0.5252024217667226,
      "grad_norm": 0.40433087944984436,
      "learning_rate": 4.4747975782332773e-05,
      "loss": 0.0047,
      "step": 7200
    },
    {
      "epoch": 0.5259318695747319,
      "grad_norm": 0.05814170464873314,
      "learning_rate": 4.474068130425269e-05,
      "loss": 0.0069,
      "step": 7210
    },
    {
      "epoch": 0.5266613173827412,
      "grad_norm": 0.05845487117767334,
      "learning_rate": 4.473338682617259e-05,
      "loss": 0.0053,
      "step": 7220
    },
    {
      "epoch": 0.5273907651907506,
      "grad_norm": 0.46336835622787476,
      "learning_rate": 4.4726092348092496e-05,
      "loss": 0.0055,
      "step": 7230
    },
    {
      "epoch": 0.5281202129987599,
      "grad_norm": 0.05831560492515564,
      "learning_rate": 4.4718797870012404e-05,
      "loss": 0.0044,
      "step": 7240
    },
    {
      "epoch": 0.5288496608067693,
      "grad_norm": 0.05824872851371765,
      "learning_rate": 4.471150339193231e-05,
      "loss": 0.0044,
      "step": 7250
    },
    {
      "epoch": 0.5295791086147786,
      "grad_norm": 0.14498086273670197,
      "learning_rate": 4.470420891385221e-05,
      "loss": 0.0048,
      "step": 7260
    },
    {
      "epoch": 0.530308556422788,
      "grad_norm": 0.030289264395833015,
      "learning_rate": 4.4696914435772126e-05,
      "loss": 0.006,
      "step": 7270
    },
    {
      "epoch": 0.5310380042307973,
      "grad_norm": 0.11643204092979431,
      "learning_rate": 4.4689619957692034e-05,
      "loss": 0.0047,
      "step": 7280
    },
    {
      "epoch": 0.5317674520388066,
      "grad_norm": 0.3759288787841797,
      "learning_rate": 4.4682325479611934e-05,
      "loss": 0.0052,
      "step": 7290
    },
    {
      "epoch": 0.5324968998468159,
      "grad_norm": 0.15111173689365387,
      "learning_rate": 4.467503100153184e-05,
      "loss": 0.0059,
      "step": 7300
    },
    {
      "epoch": 0.5332263476548254,
      "grad_norm": 0.3455721437931061,
      "learning_rate": 4.466773652345175e-05,
      "loss": 0.0062,
      "step": 7310
    },
    {
      "epoch": 0.5339557954628347,
      "grad_norm": 0.11686865240335464,
      "learning_rate": 4.466044204537165e-05,
      "loss": 0.0047,
      "step": 7320
    },
    {
      "epoch": 0.534685243270844,
      "grad_norm": 0.34682130813598633,
      "learning_rate": 4.4653147567291565e-05,
      "loss": 0.0059,
      "step": 7330
    },
    {
      "epoch": 0.5354146910788533,
      "grad_norm": 0.05936029180884361,
      "learning_rate": 4.464585308921147e-05,
      "loss": 0.0033,
      "step": 7340
    },
    {
      "epoch": 0.5361441388868626,
      "grad_norm": 0.009192537516355515,
      "learning_rate": 4.463855861113137e-05,
      "loss": 0.0083,
      "step": 7350
    },
    {
      "epoch": 0.536873586694872,
      "grad_norm": 0.05869879946112633,
      "learning_rate": 4.463126413305128e-05,
      "loss": 0.0065,
      "step": 7360
    },
    {
      "epoch": 0.5376030345028813,
      "grad_norm": 0.3488636016845703,
      "learning_rate": 4.462396965497119e-05,
      "loss": 0.0051,
      "step": 7370
    },
    {
      "epoch": 0.5383324823108907,
      "grad_norm": 0.0603768527507782,
      "learning_rate": 4.4616675176891095e-05,
      "loss": 0.0062,
      "step": 7380
    },
    {
      "epoch": 0.5390619301189,
      "grad_norm": 0.05823395773768425,
      "learning_rate": 4.4609380698811e-05,
      "loss": 0.005,
      "step": 7390
    },
    {
      "epoch": 0.5397913779269093,
      "grad_norm": 0.23389632999897003,
      "learning_rate": 4.460208622073091e-05,
      "loss": 0.0061,
      "step": 7400
    },
    {
      "epoch": 0.5405208257349187,
      "grad_norm": 0.05927472934126854,
      "learning_rate": 4.459479174265082e-05,
      "loss": 0.0047,
      "step": 7410
    },
    {
      "epoch": 0.541250273542928,
      "grad_norm": 0.7002708911895752,
      "learning_rate": 4.458749726457072e-05,
      "loss": 0.0061,
      "step": 7420
    },
    {
      "epoch": 0.5419797213509373,
      "grad_norm": 0.4959107041358948,
      "learning_rate": 4.4580202786490626e-05,
      "loss": 0.0068,
      "step": 7430
    },
    {
      "epoch": 0.5427091691589466,
      "grad_norm": 0.029787849634885788,
      "learning_rate": 4.457290830841054e-05,
      "loss": 0.007,
      "step": 7440
    },
    {
      "epoch": 0.5434386169669561,
      "grad_norm": 0.40776172280311584,
      "learning_rate": 4.456561383033044e-05,
      "loss": 0.0063,
      "step": 7450
    },
    {
      "epoch": 0.5441680647749654,
      "grad_norm": 0.0072128078900277615,
      "learning_rate": 4.455831935225035e-05,
      "loss": 0.0053,
      "step": 7460
    },
    {
      "epoch": 0.5448975125829747,
      "grad_norm": 0.11754736304283142,
      "learning_rate": 4.4551024874170256e-05,
      "loss": 0.0062,
      "step": 7470
    },
    {
      "epoch": 0.545626960390984,
      "grad_norm": 0.11606892198324203,
      "learning_rate": 4.4543730396090164e-05,
      "loss": 0.0063,
      "step": 7480
    },
    {
      "epoch": 0.5463564081989933,
      "grad_norm": 0.00746657932177186,
      "learning_rate": 4.4536435918010065e-05,
      "loss": 0.0053,
      "step": 7490
    },
    {
      "epoch": 0.5470858560070027,
      "grad_norm": 0.17471560835838318,
      "learning_rate": 4.452914143992998e-05,
      "loss": 0.007,
      "step": 7500
    },
    {
      "epoch": 0.5478153038150121,
      "grad_norm": 0.3490062355995178,
      "learning_rate": 4.4521846961849887e-05,
      "loss": 0.0075,
      "step": 7510
    },
    {
      "epoch": 0.5485447516230214,
      "grad_norm": 0.43664416670799255,
      "learning_rate": 4.451455248376979e-05,
      "loss": 0.0064,
      "step": 7520
    },
    {
      "epoch": 0.5492741994310307,
      "grad_norm": 0.057740382850170135,
      "learning_rate": 4.4507258005689695e-05,
      "loss": 0.0056,
      "step": 7530
    },
    {
      "epoch": 0.55000364723904,
      "grad_norm": 0.3485179543495178,
      "learning_rate": 4.44999635276096e-05,
      "loss": 0.0057,
      "step": 7540
    },
    {
      "epoch": 0.5507330950470494,
      "grad_norm": 0.2618542015552521,
      "learning_rate": 4.44926690495295e-05,
      "loss": 0.0071,
      "step": 7550
    },
    {
      "epoch": 0.5514625428550587,
      "grad_norm": 0.1749088317155838,
      "learning_rate": 4.448537457144942e-05,
      "loss": 0.0075,
      "step": 7560
    },
    {
      "epoch": 0.552191990663068,
      "grad_norm": 0.17403750121593475,
      "learning_rate": 4.4478080093369325e-05,
      "loss": 0.0056,
      "step": 7570
    },
    {
      "epoch": 0.5529214384710774,
      "grad_norm": 0.2610298991203308,
      "learning_rate": 4.4470785615289226e-05,
      "loss": 0.0054,
      "step": 7580
    },
    {
      "epoch": 0.5536508862790868,
      "grad_norm": 0.2169337272644043,
      "learning_rate": 4.446349113720913e-05,
      "loss": 0.0057,
      "step": 7590
    },
    {
      "epoch": 0.5543803340870961,
      "grad_norm": 0.11676187068223953,
      "learning_rate": 4.445619665912904e-05,
      "loss": 0.0059,
      "step": 7600
    },
    {
      "epoch": 0.5551097818951054,
      "grad_norm": 0.23178300261497498,
      "learning_rate": 4.444890218104895e-05,
      "loss": 0.004,
      "step": 7610
    },
    {
      "epoch": 0.5558392297031147,
      "grad_norm": 0.29004544019699097,
      "learning_rate": 4.4441607702968856e-05,
      "loss": 0.0046,
      "step": 7620
    },
    {
      "epoch": 0.556568677511124,
      "grad_norm": 0.22122733294963837,
      "learning_rate": 4.443431322488876e-05,
      "loss": 0.0044,
      "step": 7630
    },
    {
      "epoch": 0.5572981253191334,
      "grad_norm": 0.2897164821624756,
      "learning_rate": 4.442701874680867e-05,
      "loss": 0.0057,
      "step": 7640
    },
    {
      "epoch": 0.5580275731271428,
      "grad_norm": 0.2031184583902359,
      "learning_rate": 4.441972426872857e-05,
      "loss": 0.0036,
      "step": 7650
    },
    {
      "epoch": 0.5587570209351521,
      "grad_norm": 0.05806811526417732,
      "learning_rate": 4.441242979064848e-05,
      "loss": 0.0047,
      "step": 7660
    },
    {
      "epoch": 0.5594864687431614,
      "grad_norm": 0.463381826877594,
      "learning_rate": 4.440513531256839e-05,
      "loss": 0.0067,
      "step": 7670
    },
    {
      "epoch": 0.5602159165511708,
      "grad_norm": 0.31927722692489624,
      "learning_rate": 4.4397840834488294e-05,
      "loss": 0.0055,
      "step": 7680
    },
    {
      "epoch": 0.5609453643591801,
      "grad_norm": 0.6961628198623657,
      "learning_rate": 4.43905463564082e-05,
      "loss": 0.0063,
      "step": 7690
    },
    {
      "epoch": 0.5616748121671894,
      "grad_norm": 0.029311979189515114,
      "learning_rate": 4.438325187832811e-05,
      "loss": 0.0062,
      "step": 7700
    },
    {
      "epoch": 0.5624042599751988,
      "grad_norm": 0.40586838126182556,
      "learning_rate": 4.437595740024802e-05,
      "loss": 0.0058,
      "step": 7710
    },
    {
      "epoch": 0.5631337077832081,
      "grad_norm": 0.28339412808418274,
      "learning_rate": 4.436866292216792e-05,
      "loss": 0.0058,
      "step": 7720
    },
    {
      "epoch": 0.5638631555912175,
      "grad_norm": 0.012065013870596886,
      "learning_rate": 4.4361368444087825e-05,
      "loss": 0.0055,
      "step": 7730
    },
    {
      "epoch": 0.5645926033992268,
      "grad_norm": 0.28984466195106506,
      "learning_rate": 4.435407396600774e-05,
      "loss": 0.0065,
      "step": 7740
    },
    {
      "epoch": 0.5653220512072361,
      "grad_norm": 0.2614597976207733,
      "learning_rate": 4.434677948792764e-05,
      "loss": 0.0036,
      "step": 7750
    },
    {
      "epoch": 0.5660514990152454,
      "grad_norm": 0.26128941774368286,
      "learning_rate": 4.433948500984755e-05,
      "loss": 0.0046,
      "step": 7760
    },
    {
      "epoch": 0.5667809468232547,
      "grad_norm": 0.058714479207992554,
      "learning_rate": 4.4332190531767455e-05,
      "loss": 0.005,
      "step": 7770
    },
    {
      "epoch": 0.5675103946312642,
      "grad_norm": 0.058324869722127914,
      "learning_rate": 4.4324896053687356e-05,
      "loss": 0.0065,
      "step": 7780
    },
    {
      "epoch": 0.5682398424392735,
      "grad_norm": 0.4643142819404602,
      "learning_rate": 4.4317601575607263e-05,
      "loss": 0.0075,
      "step": 7790
    },
    {
      "epoch": 0.5689692902472828,
      "grad_norm": 0.23223218321800232,
      "learning_rate": 4.431030709752718e-05,
      "loss": 0.0076,
      "step": 7800
    },
    {
      "epoch": 0.5696987380552921,
      "grad_norm": 0.17344847321510315,
      "learning_rate": 4.430301261944708e-05,
      "loss": 0.006,
      "step": 7810
    },
    {
      "epoch": 0.5704281858633015,
      "grad_norm": 0.05834445357322693,
      "learning_rate": 4.4295718141366986e-05,
      "loss": 0.006,
      "step": 7820
    },
    {
      "epoch": 0.5711576336713108,
      "grad_norm": 0.1735106110572815,
      "learning_rate": 4.4288423663286894e-05,
      "loss": 0.0061,
      "step": 7830
    },
    {
      "epoch": 0.5718870814793201,
      "grad_norm": 0.029937583953142166,
      "learning_rate": 4.42811291852068e-05,
      "loss": 0.0061,
      "step": 7840
    },
    {
      "epoch": 0.5726165292873295,
      "grad_norm": 0.005626856815069914,
      "learning_rate": 4.42738347071267e-05,
      "loss": 0.0058,
      "step": 7850
    },
    {
      "epoch": 0.5733459770953389,
      "grad_norm": 0.004860646091401577,
      "learning_rate": 4.4266540229046616e-05,
      "loss": 0.0068,
      "step": 7860
    },
    {
      "epoch": 0.5740754249033482,
      "grad_norm": 0.23195111751556396,
      "learning_rate": 4.4259245750966524e-05,
      "loss": 0.006,
      "step": 7870
    },
    {
      "epoch": 0.5748048727113575,
      "grad_norm": 0.289974182844162,
      "learning_rate": 4.4251951272886424e-05,
      "loss": 0.0065,
      "step": 7880
    },
    {
      "epoch": 0.5755343205193668,
      "grad_norm": 0.4056051969528198,
      "learning_rate": 4.424465679480633e-05,
      "loss": 0.0047,
      "step": 7890
    },
    {
      "epoch": 0.5762637683273761,
      "grad_norm": 0.2034173309803009,
      "learning_rate": 4.423736231672624e-05,
      "loss": 0.0053,
      "step": 7900
    },
    {
      "epoch": 0.5769932161353856,
      "grad_norm": 0.05804072320461273,
      "learning_rate": 4.423006783864615e-05,
      "loss": 0.0051,
      "step": 7910
    },
    {
      "epoch": 0.5777226639433949,
      "grad_norm": 0.20284141600131989,
      "learning_rate": 4.4222773360566055e-05,
      "loss": 0.0046,
      "step": 7920
    },
    {
      "epoch": 0.5784521117514042,
      "grad_norm": 0.17454692721366882,
      "learning_rate": 4.421547888248596e-05,
      "loss": 0.0056,
      "step": 7930
    },
    {
      "epoch": 0.5791815595594135,
      "grad_norm": 0.1740189790725708,
      "learning_rate": 4.420818440440587e-05,
      "loss": 0.0067,
      "step": 7940
    },
    {
      "epoch": 0.5799110073674228,
      "grad_norm": 0.17466485500335693,
      "learning_rate": 4.420088992632577e-05,
      "loss": 0.0054,
      "step": 7950
    },
    {
      "epoch": 0.5806404551754322,
      "grad_norm": 0.20320168137550354,
      "learning_rate": 4.419359544824568e-05,
      "loss": 0.0072,
      "step": 7960
    },
    {
      "epoch": 0.5813699029834415,
      "grad_norm": 0.231977641582489,
      "learning_rate": 4.418630097016559e-05,
      "loss": 0.0069,
      "step": 7970
    },
    {
      "epoch": 0.5820993507914509,
      "grad_norm": 0.46350306272506714,
      "learning_rate": 4.417900649208549e-05,
      "loss": 0.0074,
      "step": 7980
    },
    {
      "epoch": 0.5828287985994602,
      "grad_norm": 0.2030363380908966,
      "learning_rate": 4.41717120140054e-05,
      "loss": 0.005,
      "step": 7990
    },
    {
      "epoch": 0.5835582464074696,
      "grad_norm": 0.23171089589595795,
      "learning_rate": 4.416441753592531e-05,
      "loss": 0.0046,
      "step": 8000
    },
    {
      "epoch": 0.5842876942154789,
      "grad_norm": 0.2891649901866913,
      "learning_rate": 4.415712305784521e-05,
      "loss": 0.0051,
      "step": 8010
    },
    {
      "epoch": 0.5850171420234882,
      "grad_norm": 0.08716551214456558,
      "learning_rate": 4.4149828579765116e-05,
      "loss": 0.0057,
      "step": 8020
    },
    {
      "epoch": 0.5857465898314975,
      "grad_norm": 0.05819511413574219,
      "learning_rate": 4.414253410168503e-05,
      "loss": 0.006,
      "step": 8030
    },
    {
      "epoch": 0.5864760376395068,
      "grad_norm": 0.34930533170700073,
      "learning_rate": 4.413523962360494e-05,
      "loss": 0.0068,
      "step": 8040
    },
    {
      "epoch": 0.5872054854475163,
      "grad_norm": 0.23109754920005798,
      "learning_rate": 4.412794514552484e-05,
      "loss": 0.0048,
      "step": 8050
    },
    {
      "epoch": 0.5879349332555256,
      "grad_norm": 0.1446302831172943,
      "learning_rate": 4.4120650667444746e-05,
      "loss": 0.0059,
      "step": 8060
    },
    {
      "epoch": 0.5886643810635349,
      "grad_norm": 0.11563550680875778,
      "learning_rate": 4.4113356189364654e-05,
      "loss": 0.0064,
      "step": 8070
    },
    {
      "epoch": 0.5893938288715442,
      "grad_norm": 0.23213519155979156,
      "learning_rate": 4.4106061711284555e-05,
      "loss": 0.0062,
      "step": 8080
    },
    {
      "epoch": 0.5901232766795536,
      "grad_norm": 0.05955904349684715,
      "learning_rate": 4.409876723320447e-05,
      "loss": 0.0044,
      "step": 8090
    },
    {
      "epoch": 0.5908527244875629,
      "grad_norm": 0.029962021857500076,
      "learning_rate": 4.4091472755124377e-05,
      "loss": 0.0041,
      "step": 8100
    },
    {
      "epoch": 0.5915821722955723,
      "grad_norm": 0.17435741424560547,
      "learning_rate": 4.408417827704428e-05,
      "loss": 0.0051,
      "step": 8110
    },
    {
      "epoch": 0.5923116201035816,
      "grad_norm": 0.02932770363986492,
      "learning_rate": 4.4076883798964185e-05,
      "loss": 0.0056,
      "step": 8120
    },
    {
      "epoch": 0.593041067911591,
      "grad_norm": 0.2316969782114029,
      "learning_rate": 4.406958932088409e-05,
      "loss": 0.0053,
      "step": 8130
    },
    {
      "epoch": 0.5937705157196003,
      "grad_norm": 0.4057089388370514,
      "learning_rate": 4.4062294842804e-05,
      "loss": 0.005,
      "step": 8140
    },
    {
      "epoch": 0.5944999635276096,
      "grad_norm": 0.08734432607889175,
      "learning_rate": 4.405500036472391e-05,
      "loss": 0.0077,
      "step": 8150
    },
    {
      "epoch": 0.5952294113356189,
      "grad_norm": 0.030938202515244484,
      "learning_rate": 4.4047705886643815e-05,
      "loss": 0.0047,
      "step": 8160
    },
    {
      "epoch": 0.5959588591436282,
      "grad_norm": 0.2309008240699768,
      "learning_rate": 4.404041140856372e-05,
      "loss": 0.0046,
      "step": 8170
    },
    {
      "epoch": 0.5966883069516377,
      "grad_norm": 0.2304299771785736,
      "learning_rate": 4.403311693048362e-05,
      "loss": 0.0065,
      "step": 8180
    },
    {
      "epoch": 0.597417754759647,
      "grad_norm": 0.23058554530143738,
      "learning_rate": 4.402582245240353e-05,
      "loss": 0.0061,
      "step": 8190
    },
    {
      "epoch": 0.5981472025676563,
      "grad_norm": 0.009709564968943596,
      "learning_rate": 4.401852797432344e-05,
      "loss": 0.0066,
      "step": 8200
    },
    {
      "epoch": 0.5988766503756656,
      "grad_norm": 0.28445643186569214,
      "learning_rate": 4.4011233496243346e-05,
      "loss": 0.0047,
      "step": 8210
    },
    {
      "epoch": 0.5996060981836749,
      "grad_norm": 0.0874812975525856,
      "learning_rate": 4.4003939018163253e-05,
      "loss": 0.0052,
      "step": 8220
    },
    {
      "epoch": 0.6003355459916843,
      "grad_norm": 0.17391733825206757,
      "learning_rate": 4.399664454008316e-05,
      "loss": 0.0066,
      "step": 8230
    },
    {
      "epoch": 0.6010649937996936,
      "grad_norm": 0.17339494824409485,
      "learning_rate": 4.398935006200307e-05,
      "loss": 0.0055,
      "step": 8240
    },
    {
      "epoch": 0.601794441607703,
      "grad_norm": 0.28979548811912537,
      "learning_rate": 4.398205558392297e-05,
      "loss": 0.0062,
      "step": 8250
    },
    {
      "epoch": 0.6025238894157123,
      "grad_norm": 0.34741559624671936,
      "learning_rate": 4.397476110584288e-05,
      "loss": 0.0068,
      "step": 8260
    },
    {
      "epoch": 0.6032533372237217,
      "grad_norm": 0.4344820976257324,
      "learning_rate": 4.396746662776279e-05,
      "loss": 0.0068,
      "step": 8270
    },
    {
      "epoch": 0.603982785031731,
      "grad_norm": 0.11591517180204391,
      "learning_rate": 4.396017214968269e-05,
      "loss": 0.0073,
      "step": 8280
    },
    {
      "epoch": 0.6047122328397403,
      "grad_norm": 0.057894110679626465,
      "learning_rate": 4.39528776716026e-05,
      "loss": 0.0054,
      "step": 8290
    },
    {
      "epoch": 0.6054416806477496,
      "grad_norm": 0.3186330199241638,
      "learning_rate": 4.394558319352251e-05,
      "loss": 0.0058,
      "step": 8300
    },
    {
      "epoch": 0.606171128455759,
      "grad_norm": 0.2892843186855316,
      "learning_rate": 4.393828871544241e-05,
      "loss": 0.0058,
      "step": 8310
    },
    {
      "epoch": 0.6069005762637684,
      "grad_norm": 0.2315407544374466,
      "learning_rate": 4.3930994237362315e-05,
      "loss": 0.0058,
      "step": 8320
    },
    {
      "epoch": 0.6076300240717777,
      "grad_norm": 0.17409712076187134,
      "learning_rate": 4.392369975928223e-05,
      "loss": 0.0031,
      "step": 8330
    },
    {
      "epoch": 0.608359471879787,
      "grad_norm": 0.14449237287044525,
      "learning_rate": 4.391640528120213e-05,
      "loss": 0.0068,
      "step": 8340
    },
    {
      "epoch": 0.6090889196877963,
      "grad_norm": 0.17379339039325714,
      "learning_rate": 4.390911080312204e-05,
      "loss": 0.0057,
      "step": 8350
    },
    {
      "epoch": 0.6098183674958056,
      "grad_norm": 0.05830133333802223,
      "learning_rate": 4.3901816325041945e-05,
      "loss": 0.0046,
      "step": 8360
    },
    {
      "epoch": 0.610547815303815,
      "grad_norm": 0.23174642026424408,
      "learning_rate": 4.389452184696185e-05,
      "loss": 0.0044,
      "step": 8370
    },
    {
      "epoch": 0.6112772631118244,
      "grad_norm": 0.11663991957902908,
      "learning_rate": 4.3887227368881754e-05,
      "loss": 0.0057,
      "step": 8380
    },
    {
      "epoch": 0.6120067109198337,
      "grad_norm": 0.05827096477150917,
      "learning_rate": 4.387993289080167e-05,
      "loss": 0.0067,
      "step": 8390
    },
    {
      "epoch": 0.612736158727843,
      "grad_norm": 0.29007571935653687,
      "learning_rate": 4.3872638412721575e-05,
      "loss": 0.0049,
      "step": 8400
    },
    {
      "epoch": 0.6134656065358524,
      "grad_norm": 0.31830355525016785,
      "learning_rate": 4.3865343934641476e-05,
      "loss": 0.0054,
      "step": 8410
    },
    {
      "epoch": 0.6141950543438617,
      "grad_norm": 0.20283983647823334,
      "learning_rate": 4.3858049456561384e-05,
      "loss": 0.0065,
      "step": 8420
    },
    {
      "epoch": 0.614924502151871,
      "grad_norm": 0.4186556935310364,
      "learning_rate": 4.385075497848129e-05,
      "loss": 0.0057,
      "step": 8430
    },
    {
      "epoch": 0.6156539499598803,
      "grad_norm": 0.05839734524488449,
      "learning_rate": 4.38434605004012e-05,
      "loss": 0.0066,
      "step": 8440
    },
    {
      "epoch": 0.6163833977678898,
      "grad_norm": 0.2317914068698883,
      "learning_rate": 4.3836166022321106e-05,
      "loss": 0.0062,
      "step": 8450
    },
    {
      "epoch": 0.6171128455758991,
      "grad_norm": 0.05836733058094978,
      "learning_rate": 4.3828871544241014e-05,
      "loss": 0.005,
      "step": 8460
    },
    {
      "epoch": 0.6178422933839084,
      "grad_norm": 0.005466105882078409,
      "learning_rate": 4.382157706616092e-05,
      "loss": 0.0063,
      "step": 8470
    },
    {
      "epoch": 0.6185717411919177,
      "grad_norm": 0.08784880489110947,
      "learning_rate": 4.381428258808082e-05,
      "loss": 0.006,
      "step": 8480
    },
    {
      "epoch": 0.619301188999927,
      "grad_norm": 0.0873849019408226,
      "learning_rate": 4.380698811000073e-05,
      "loss": 0.0046,
      "step": 8490
    },
    {
      "epoch": 0.6200306368079364,
      "grad_norm": 0.11578015983104706,
      "learning_rate": 4.3799693631920644e-05,
      "loss": 0.007,
      "step": 8500
    },
    {
      "epoch": 0.6207600846159458,
      "grad_norm": 0.17377883195877075,
      "learning_rate": 4.3792399153840545e-05,
      "loss": 0.0077,
      "step": 8510
    },
    {
      "epoch": 0.6214895324239551,
      "grad_norm": 0.1449134647846222,
      "learning_rate": 4.378510467576045e-05,
      "loss": 0.0064,
      "step": 8520
    },
    {
      "epoch": 0.6222189802319644,
      "grad_norm": 0.14510424435138702,
      "learning_rate": 4.377781019768036e-05,
      "loss": 0.0066,
      "step": 8530
    },
    {
      "epoch": 0.6229484280399737,
      "grad_norm": 0.2317476123571396,
      "learning_rate": 4.377051571960026e-05,
      "loss": 0.0068,
      "step": 8540
    },
    {
      "epoch": 0.6236778758479831,
      "grad_norm": 0.3470247983932495,
      "learning_rate": 4.376322124152017e-05,
      "loss": 0.0052,
      "step": 8550
    },
    {
      "epoch": 0.6244073236559924,
      "grad_norm": 0.46273499727249146,
      "learning_rate": 4.375592676344008e-05,
      "loss": 0.0054,
      "step": 8560
    },
    {
      "epoch": 0.6251367714640017,
      "grad_norm": 0.17410609126091003,
      "learning_rate": 4.374863228535998e-05,
      "loss": 0.006,
      "step": 8570
    },
    {
      "epoch": 0.6258662192720111,
      "grad_norm": 0.11641914397478104,
      "learning_rate": 4.374133780727989e-05,
      "loss": 0.0059,
      "step": 8580
    },
    {
      "epoch": 0.6265956670800205,
      "grad_norm": 0.2321726679801941,
      "learning_rate": 4.37340433291998e-05,
      "loss": 0.0041,
      "step": 8590
    },
    {
      "epoch": 0.6273251148880298,
      "grad_norm": 0.3181040287017822,
      "learning_rate": 4.3726748851119706e-05,
      "loss": 0.0059,
      "step": 8600
    },
    {
      "epoch": 0.6280545626960391,
      "grad_norm": 0.11574286222457886,
      "learning_rate": 4.3719454373039606e-05,
      "loss": 0.0069,
      "step": 8610
    },
    {
      "epoch": 0.6287840105040484,
      "grad_norm": 0.11559570580720901,
      "learning_rate": 4.371215989495952e-05,
      "loss": 0.007,
      "step": 8620
    },
    {
      "epoch": 0.6295134583120577,
      "grad_norm": 0.08675990998744965,
      "learning_rate": 4.370486541687943e-05,
      "loss": 0.0058,
      "step": 8630
    },
    {
      "epoch": 0.6302429061200671,
      "grad_norm": 0.009691719897091389,
      "learning_rate": 4.369757093879933e-05,
      "loss": 0.007,
      "step": 8640
    },
    {
      "epoch": 0.6309723539280765,
      "grad_norm": 0.6070586442947388,
      "learning_rate": 4.3690276460719237e-05,
      "loss": 0.0064,
      "step": 8650
    },
    {
      "epoch": 0.6317018017360858,
      "grad_norm": 0.14411737024784088,
      "learning_rate": 4.3682981982639144e-05,
      "loss": 0.006,
      "step": 8660
    },
    {
      "epoch": 0.6324312495440951,
      "grad_norm": 0.05818529427051544,
      "learning_rate": 4.367568750455905e-05,
      "loss": 0.0052,
      "step": 8670
    },
    {
      "epoch": 0.6331606973521045,
      "grad_norm": 0.17379097640514374,
      "learning_rate": 4.366839302647896e-05,
      "loss": 0.0064,
      "step": 8680
    },
    {
      "epoch": 0.6338901451601138,
      "grad_norm": 0.17390237748622894,
      "learning_rate": 4.366109854839887e-05,
      "loss": 0.0065,
      "step": 8690
    },
    {
      "epoch": 0.6346195929681231,
      "grad_norm": 0.14518405497074127,
      "learning_rate": 4.3653804070318774e-05,
      "loss": 0.0058,
      "step": 8700
    },
    {
      "epoch": 0.6353490407761325,
      "grad_norm": 0.030502665787935257,
      "learning_rate": 4.3646509592238675e-05,
      "loss": 0.0056,
      "step": 8710
    },
    {
      "epoch": 0.6360784885841418,
      "grad_norm": 0.11683288216590881,
      "learning_rate": 4.363921511415858e-05,
      "loss": 0.0072,
      "step": 8720
    },
    {
      "epoch": 0.6368079363921512,
      "grad_norm": 0.17374230921268463,
      "learning_rate": 4.363192063607849e-05,
      "loss": 0.0077,
      "step": 8730
    },
    {
      "epoch": 0.6375373842001605,
      "grad_norm": 0.34751394391059875,
      "learning_rate": 4.36246261579984e-05,
      "loss": 0.0046,
      "step": 8740
    },
    {
      "epoch": 0.6382668320081698,
      "grad_norm": 0.05836716666817665,
      "learning_rate": 4.3617331679918305e-05,
      "loss": 0.0059,
      "step": 8750
    },
    {
      "epoch": 0.6389962798161791,
      "grad_norm": 0.12793323397636414,
      "learning_rate": 4.361003720183821e-05,
      "loss": 0.0064,
      "step": 8760
    },
    {
      "epoch": 0.6397257276241884,
      "grad_norm": 0.17385052144527435,
      "learning_rate": 4.360274272375811e-05,
      "loss": 0.004,
      "step": 8770
    },
    {
      "epoch": 0.6404551754321979,
      "grad_norm": 0.28913968801498413,
      "learning_rate": 4.359544824567802e-05,
      "loss": 0.005,
      "step": 8780
    },
    {
      "epoch": 0.6411846232402072,
      "grad_norm": 0.34712672233581543,
      "learning_rate": 4.358815376759793e-05,
      "loss": 0.0057,
      "step": 8790
    },
    {
      "epoch": 0.6419140710482165,
      "grad_norm": 0.6366466879844666,
      "learning_rate": 4.3580859289517836e-05,
      "loss": 0.0053,
      "step": 8800
    },
    {
      "epoch": 0.6426435188562258,
      "grad_norm": 0.3479119837284088,
      "learning_rate": 4.3573564811437743e-05,
      "loss": 0.0052,
      "step": 8810
    },
    {
      "epoch": 0.6433729666642352,
      "grad_norm": 0.6355582475662231,
      "learning_rate": 4.356627033335765e-05,
      "loss": 0.008,
      "step": 8820
    },
    {
      "epoch": 0.6441024144722445,
      "grad_norm": 0.11665428429841995,
      "learning_rate": 4.355897585527756e-05,
      "loss": 0.0073,
      "step": 8830
    },
    {
      "epoch": 0.6448318622802538,
      "grad_norm": 0.23202359676361084,
      "learning_rate": 4.355168137719746e-05,
      "loss": 0.0053,
      "step": 8840
    },
    {
      "epoch": 0.6455613100882632,
      "grad_norm": 0.14490778744220734,
      "learning_rate": 4.354438689911737e-05,
      "loss": 0.0054,
      "step": 8850
    },
    {
      "epoch": 0.6462907578962725,
      "grad_norm": 0.23170159757137299,
      "learning_rate": 4.353709242103728e-05,
      "loss": 0.0063,
      "step": 8860
    },
    {
      "epoch": 0.6470202057042819,
      "grad_norm": 0.11698056757450104,
      "learning_rate": 4.352979794295718e-05,
      "loss": 0.0052,
      "step": 8870
    },
    {
      "epoch": 0.6477496535122912,
      "grad_norm": 0.289600133895874,
      "learning_rate": 4.352250346487709e-05,
      "loss": 0.007,
      "step": 8880
    },
    {
      "epoch": 0.6484791013203005,
      "grad_norm": 0.1734595000743866,
      "learning_rate": 4.3515208986797e-05,
      "loss": 0.0055,
      "step": 8890
    },
    {
      "epoch": 0.6492085491283098,
      "grad_norm": 0.23206086456775665,
      "learning_rate": 4.3507914508716904e-05,
      "loss": 0.0074,
      "step": 8900
    },
    {
      "epoch": 0.6499379969363192,
      "grad_norm": 0.11567655205726624,
      "learning_rate": 4.350062003063681e-05,
      "loss": 0.004,
      "step": 8910
    },
    {
      "epoch": 0.6506674447443286,
      "grad_norm": 0.17361856997013092,
      "learning_rate": 4.349332555255672e-05,
      "loss": 0.0072,
      "step": 8920
    },
    {
      "epoch": 0.6513968925523379,
      "grad_norm": 0.2319156527519226,
      "learning_rate": 4.348603107447663e-05,
      "loss": 0.0069,
      "step": 8930
    },
    {
      "epoch": 0.6521263403603472,
      "grad_norm": 0.28961196541786194,
      "learning_rate": 4.347873659639653e-05,
      "loss": 0.0052,
      "step": 8940
    },
    {
      "epoch": 0.6528557881683565,
      "grad_norm": 0.23198367655277252,
      "learning_rate": 4.3471442118316435e-05,
      "loss": 0.0043,
      "step": 8950
    },
    {
      "epoch": 0.6535852359763659,
      "grad_norm": 0.202468141913414,
      "learning_rate": 4.346414764023634e-05,
      "loss": 0.0084,
      "step": 8960
    },
    {
      "epoch": 0.6543146837843752,
      "grad_norm": 0.2892400622367859,
      "learning_rate": 4.345685316215625e-05,
      "loss": 0.0054,
      "step": 8970
    },
    {
      "epoch": 0.6550441315923846,
      "grad_norm": 0.23168127238750458,
      "learning_rate": 4.344955868407616e-05,
      "loss": 0.0061,
      "step": 8980
    },
    {
      "epoch": 0.6557735794003939,
      "grad_norm": 0.2892119586467743,
      "learning_rate": 4.3442264205996065e-05,
      "loss": 0.007,
      "step": 8990
    },
    {
      "epoch": 0.6565030272084033,
      "grad_norm": 0.14514683187007904,
      "learning_rate": 4.3434969727915966e-05,
      "loss": 0.004,
      "step": 9000
    },
    {
      "epoch": 0.6572324750164126,
      "grad_norm": 0.28904446959495544,
      "learning_rate": 4.3427675249835874e-05,
      "loss": 0.006,
      "step": 9010
    },
    {
      "epoch": 0.6579619228244219,
      "grad_norm": 0.05778951197862625,
      "learning_rate": 4.342038077175578e-05,
      "loss": 0.0068,
      "step": 9020
    },
    {
      "epoch": 0.6586913706324312,
      "grad_norm": 0.28966808319091797,
      "learning_rate": 4.341308629367569e-05,
      "loss": 0.0073,
      "step": 9030
    },
    {
      "epoch": 0.6594208184404405,
      "grad_norm": 0.28904375433921814,
      "learning_rate": 4.3405791815595596e-05,
      "loss": 0.0078,
      "step": 9040
    },
    {
      "epoch": 0.66015026624845,
      "grad_norm": 0.3182670474052429,
      "learning_rate": 4.3398497337515504e-05,
      "loss": 0.0063,
      "step": 9050
    },
    {
      "epoch": 0.6608797140564593,
      "grad_norm": 0.2314492166042328,
      "learning_rate": 4.339120285943541e-05,
      "loss": 0.0069,
      "step": 9060
    },
    {
      "epoch": 0.6616091618644686,
      "grad_norm": 0.11633281409740448,
      "learning_rate": 4.338390838135531e-05,
      "loss": 0.0059,
      "step": 9070
    },
    {
      "epoch": 0.6623386096724779,
      "grad_norm": 0.057962045073509216,
      "learning_rate": 4.337661390327522e-05,
      "loss": 0.0055,
      "step": 9080
    },
    {
      "epoch": 0.6630680574804872,
      "grad_norm": 0.664401650428772,
      "learning_rate": 4.3369319425195134e-05,
      "loss": 0.0053,
      "step": 9090
    },
    {
      "epoch": 0.6637975052884966,
      "grad_norm": 0.34619006514549255,
      "learning_rate": 4.3362024947115035e-05,
      "loss": 0.0056,
      "step": 9100
    },
    {
      "epoch": 0.6645269530965059,
      "grad_norm": 0.28967174887657166,
      "learning_rate": 4.335473046903494e-05,
      "loss": 0.0046,
      "step": 9110
    },
    {
      "epoch": 0.6652564009045153,
      "grad_norm": 0.2313949167728424,
      "learning_rate": 4.334743599095485e-05,
      "loss": 0.0049,
      "step": 9120
    },
    {
      "epoch": 0.6659858487125246,
      "grad_norm": 0.5768342614173889,
      "learning_rate": 4.334014151287476e-05,
      "loss": 0.0082,
      "step": 9130
    },
    {
      "epoch": 0.666715296520534,
      "grad_norm": 0.2326066941022873,
      "learning_rate": 4.333284703479466e-05,
      "loss": 0.0061,
      "step": 9140
    },
    {
      "epoch": 0.6674447443285433,
      "grad_norm": 0.01789809577167034,
      "learning_rate": 4.332555255671457e-05,
      "loss": 0.0053,
      "step": 9150
    },
    {
      "epoch": 0.6681741921365526,
      "grad_norm": 0.173759326338768,
      "learning_rate": 4.331825807863448e-05,
      "loss": 0.0056,
      "step": 9160
    },
    {
      "epoch": 0.6689036399445619,
      "grad_norm": 0.03150531277060509,
      "learning_rate": 4.331096360055438e-05,
      "loss": 0.0059,
      "step": 9170
    },
    {
      "epoch": 0.6696330877525714,
      "grad_norm": 0.1475123167037964,
      "learning_rate": 4.330366912247429e-05,
      "loss": 0.0054,
      "step": 9180
    },
    {
      "epoch": 0.6703625355605807,
      "grad_norm": 0.08750961720943451,
      "learning_rate": 4.3296374644394196e-05,
      "loss": 0.0044,
      "step": 9190
    },
    {
      "epoch": 0.67109198336859,
      "grad_norm": 0.28945085406303406,
      "learning_rate": 4.32890801663141e-05,
      "loss": 0.006,
      "step": 9200
    },
    {
      "epoch": 0.6718214311765993,
      "grad_norm": 0.011952667497098446,
      "learning_rate": 4.328178568823401e-05,
      "loss": 0.0057,
      "step": 9210
    },
    {
      "epoch": 0.6725508789846086,
      "grad_norm": 0.11601122468709946,
      "learning_rate": 4.327449121015392e-05,
      "loss": 0.0045,
      "step": 9220
    },
    {
      "epoch": 0.673280326792618,
      "grad_norm": 0.1735573410987854,
      "learning_rate": 4.3267196732073826e-05,
      "loss": 0.0058,
      "step": 9230
    },
    {
      "epoch": 0.6740097746006273,
      "grad_norm": 0.14525102078914642,
      "learning_rate": 4.3259902253993727e-05,
      "loss": 0.0055,
      "step": 9240
    },
    {
      "epoch": 0.6747392224086367,
      "grad_norm": 0.31785088777542114,
      "learning_rate": 4.3252607775913634e-05,
      "loss": 0.0063,
      "step": 9250
    },
    {
      "epoch": 0.675468670216646,
      "grad_norm": 0.17463554441928864,
      "learning_rate": 4.324531329783354e-05,
      "loss": 0.0072,
      "step": 9260
    },
    {
      "epoch": 0.6761981180246553,
      "grad_norm": 0.5200434327125549,
      "learning_rate": 4.323801881975345e-05,
      "loss": 0.0068,
      "step": 9270
    },
    {
      "epoch": 0.6769275658326647,
      "grad_norm": 0.11589686572551727,
      "learning_rate": 4.323072434167336e-05,
      "loss": 0.006,
      "step": 9280
    },
    {
      "epoch": 0.677657013640674,
      "grad_norm": 0.1164315864443779,
      "learning_rate": 4.3223429863593264e-05,
      "loss": 0.0037,
      "step": 9290
    },
    {
      "epoch": 0.6783864614486833,
      "grad_norm": 0.46292540431022644,
      "learning_rate": 4.3216135385513165e-05,
      "loss": 0.0056,
      "step": 9300
    },
    {
      "epoch": 0.6791159092566926,
      "grad_norm": 0.05809544399380684,
      "learning_rate": 4.320884090743307e-05,
      "loss": 0.0054,
      "step": 9310
    },
    {
      "epoch": 0.6798453570647021,
      "grad_norm": 0.23138658702373505,
      "learning_rate": 4.320154642935298e-05,
      "loss": 0.0054,
      "step": 9320
    },
    {
      "epoch": 0.6805748048727114,
      "grad_norm": 0.2936379015445709,
      "learning_rate": 4.319425195127289e-05,
      "loss": 0.0054,
      "step": 9330
    },
    {
      "epoch": 0.6813042526807207,
      "grad_norm": 0.3472278416156769,
      "learning_rate": 4.3186957473192795e-05,
      "loss": 0.008,
      "step": 9340
    },
    {
      "epoch": 0.68203370048873,
      "grad_norm": 0.05854806303977966,
      "learning_rate": 4.31796629951127e-05,
      "loss": 0.0049,
      "step": 9350
    },
    {
      "epoch": 0.6827631482967393,
      "grad_norm": 0.23184901475906372,
      "learning_rate": 4.317236851703261e-05,
      "loss": 0.0042,
      "step": 9360
    },
    {
      "epoch": 0.6834925961047487,
      "grad_norm": 0.40585559606552124,
      "learning_rate": 4.316507403895251e-05,
      "loss": 0.0048,
      "step": 9370
    },
    {
      "epoch": 0.6842220439127581,
      "grad_norm": 0.2316463440656662,
      "learning_rate": 4.315777956087242e-05,
      "loss": 0.0064,
      "step": 9380
    },
    {
      "epoch": 0.6849514917207674,
      "grad_norm": 0.0591035932302475,
      "learning_rate": 4.315048508279233e-05,
      "loss": 0.0058,
      "step": 9390
    },
    {
      "epoch": 0.6856809395287767,
      "grad_norm": 0.03062789887189865,
      "learning_rate": 4.3143190604712234e-05,
      "loss": 0.0061,
      "step": 9400
    },
    {
      "epoch": 0.686410387336786,
      "grad_norm": 0.3474874496459961,
      "learning_rate": 4.313589612663214e-05,
      "loss": 0.0043,
      "step": 9410
    },
    {
      "epoch": 0.6871398351447954,
      "grad_norm": 0.32073813676834106,
      "learning_rate": 4.312860164855205e-05,
      "loss": 0.005,
      "step": 9420
    },
    {
      "epoch": 0.6878692829528047,
      "grad_norm": 0.28883591294288635,
      "learning_rate": 4.3121307170471956e-05,
      "loss": 0.0065,
      "step": 9430
    },
    {
      "epoch": 0.688598730760814,
      "grad_norm": 0.007912790402770042,
      "learning_rate": 4.3114012692391864e-05,
      "loss": 0.0053,
      "step": 9440
    },
    {
      "epoch": 0.6893281785688234,
      "grad_norm": 0.4639652669429779,
      "learning_rate": 4.310671821431177e-05,
      "loss": 0.0048,
      "step": 9450
    },
    {
      "epoch": 0.6900576263768328,
      "grad_norm": 0.1533200889825821,
      "learning_rate": 4.309942373623168e-05,
      "loss": 0.0049,
      "step": 9460
    },
    {
      "epoch": 0.6907870741848421,
      "grad_norm": 0.08761916309595108,
      "learning_rate": 4.309212925815158e-05,
      "loss": 0.0056,
      "step": 9470
    },
    {
      "epoch": 0.6915165219928514,
      "grad_norm": 0.007699217647314072,
      "learning_rate": 4.308483478007149e-05,
      "loss": 0.0071,
      "step": 9480
    },
    {
      "epoch": 0.6922459698008607,
      "grad_norm": 0.17445583641529083,
      "learning_rate": 4.3077540301991395e-05,
      "loss": 0.0043,
      "step": 9490
    },
    {
      "epoch": 0.69297541760887,
      "grad_norm": 0.0870663970708847,
      "learning_rate": 4.30702458239113e-05,
      "loss": 0.0055,
      "step": 9500
    },
    {
      "epoch": 0.6937048654168794,
      "grad_norm": 0.40581101179122925,
      "learning_rate": 4.306295134583121e-05,
      "loss": 0.0048,
      "step": 9510
    },
    {
      "epoch": 0.6944343132248888,
      "grad_norm": 0.0294965747743845,
      "learning_rate": 4.305565686775112e-05,
      "loss": 0.0046,
      "step": 9520
    },
    {
      "epoch": 0.6951637610328981,
      "grad_norm": 0.46383941173553467,
      "learning_rate": 4.304836238967102e-05,
      "loss": 0.0047,
      "step": 9530
    },
    {
      "epoch": 0.6958932088409074,
      "grad_norm": 0.23191218078136444,
      "learning_rate": 4.3041067911590925e-05,
      "loss": 0.0058,
      "step": 9540
    },
    {
      "epoch": 0.6966226566489168,
      "grad_norm": 0.11563720554113388,
      "learning_rate": 4.303377343351083e-05,
      "loss": 0.0048,
      "step": 9550
    },
    {
      "epoch": 0.6973521044569261,
      "grad_norm": 0.11597336828708649,
      "learning_rate": 4.302647895543074e-05,
      "loss": 0.0048,
      "step": 9560
    },
    {
      "epoch": 0.6980815522649354,
      "grad_norm": 0.347242146730423,
      "learning_rate": 4.301918447735065e-05,
      "loss": 0.0069,
      "step": 9570
    },
    {
      "epoch": 0.6988110000729448,
      "grad_norm": 0.3476628363132477,
      "learning_rate": 4.3011889999270555e-05,
      "loss": 0.0075,
      "step": 9580
    },
    {
      "epoch": 0.6995404478809542,
      "grad_norm": 0.11598389595746994,
      "learning_rate": 4.300459552119046e-05,
      "loss": 0.007,
      "step": 9590
    },
    {
      "epoch": 0.7002698956889635,
      "grad_norm": 0.007049623876810074,
      "learning_rate": 4.2997301043110364e-05,
      "loss": 0.0052,
      "step": 9600
    },
    {
      "epoch": 0.7009993434969728,
      "grad_norm": 0.05861293151974678,
      "learning_rate": 4.299000656503027e-05,
      "loss": 0.006,
      "step": 9610
    },
    {
      "epoch": 0.7017287913049821,
      "grad_norm": 0.029675453901290894,
      "learning_rate": 4.2982712086950186e-05,
      "loss": 0.0059,
      "step": 9620
    },
    {
      "epoch": 0.7024582391129914,
      "grad_norm": 0.14519871771335602,
      "learning_rate": 4.2975417608870086e-05,
      "loss": 0.0067,
      "step": 9630
    },
    {
      "epoch": 0.7031876869210008,
      "grad_norm": 0.17320898175239563,
      "learning_rate": 4.2968123130789994e-05,
      "loss": 0.0067,
      "step": 9640
    },
    {
      "epoch": 0.7039171347290102,
      "grad_norm": 0.03047999180853367,
      "learning_rate": 4.29608286527099e-05,
      "loss": 0.0046,
      "step": 9650
    },
    {
      "epoch": 0.7046465825370195,
      "grad_norm": 0.05787119269371033,
      "learning_rate": 4.295353417462981e-05,
      "loss": 0.0052,
      "step": 9660
    },
    {
      "epoch": 0.7053760303450288,
      "grad_norm": 0.1733856499195099,
      "learning_rate": 4.294623969654971e-05,
      "loss": 0.006,
      "step": 9670
    },
    {
      "epoch": 0.7061054781530381,
      "grad_norm": 0.009356439113616943,
      "learning_rate": 4.2938945218469624e-05,
      "loss": 0.0058,
      "step": 9680
    },
    {
      "epoch": 0.7068349259610475,
      "grad_norm": 0.3175817131996155,
      "learning_rate": 4.293165074038953e-05,
      "loss": 0.0071,
      "step": 9690
    },
    {
      "epoch": 0.7075643737690568,
      "grad_norm": 0.10371942073106766,
      "learning_rate": 4.292435626230943e-05,
      "loss": 0.0074,
      "step": 9700
    },
    {
      "epoch": 0.7082938215770661,
      "grad_norm": 0.28864771127700806,
      "learning_rate": 4.291706178422934e-05,
      "loss": 0.0059,
      "step": 9710
    },
    {
      "epoch": 0.7090232693850755,
      "grad_norm": 0.5120924115180969,
      "learning_rate": 4.290976730614925e-05,
      "loss": 0.0055,
      "step": 9720
    },
    {
      "epoch": 0.7097527171930849,
      "grad_norm": 0.2890969514846802,
      "learning_rate": 4.290247282806915e-05,
      "loss": 0.0068,
      "step": 9730
    },
    {
      "epoch": 0.7104821650010942,
      "grad_norm": 0.14563286304473877,
      "learning_rate": 4.289517834998906e-05,
      "loss": 0.0059,
      "step": 9740
    },
    {
      "epoch": 0.7112116128091035,
      "grad_norm": 0.029364975169301033,
      "learning_rate": 4.288788387190897e-05,
      "loss": 0.0043,
      "step": 9750
    },
    {
      "epoch": 0.7119410606171128,
      "grad_norm": 0.28985321521759033,
      "learning_rate": 4.288058939382887e-05,
      "loss": 0.0066,
      "step": 9760
    },
    {
      "epoch": 0.7126705084251221,
      "grad_norm": 0.05774081125855446,
      "learning_rate": 4.287329491574878e-05,
      "loss": 0.0069,
      "step": 9770
    },
    {
      "epoch": 0.7133999562331316,
      "grad_norm": 0.23138678073883057,
      "learning_rate": 4.2866000437668686e-05,
      "loss": 0.0053,
      "step": 9780
    },
    {
      "epoch": 0.7141294040411409,
      "grad_norm": 0.4049607217311859,
      "learning_rate": 4.285870595958859e-05,
      "loss": 0.0055,
      "step": 9790
    },
    {
      "epoch": 0.7148588518491502,
      "grad_norm": 0.11599534004926682,
      "learning_rate": 4.28514114815085e-05,
      "loss": 0.0076,
      "step": 9800
    },
    {
      "epoch": 0.7155882996571595,
      "grad_norm": 0.11669166386127472,
      "learning_rate": 4.284411700342841e-05,
      "loss": 0.0064,
      "step": 9810
    },
    {
      "epoch": 0.7163177474651689,
      "grad_norm": 0.40491655468940735,
      "learning_rate": 4.2836822525348316e-05,
      "loss": 0.0043,
      "step": 9820
    },
    {
      "epoch": 0.7170471952731782,
      "grad_norm": 0.17338331043720245,
      "learning_rate": 4.282952804726822e-05,
      "loss": 0.0059,
      "step": 9830
    },
    {
      "epoch": 0.7177766430811875,
      "grad_norm": 0.11575260013341904,
      "learning_rate": 4.2822233569188124e-05,
      "loss": 0.0059,
      "step": 9840
    },
    {
      "epoch": 0.7185060908891969,
      "grad_norm": 0.11603986471891403,
      "learning_rate": 4.281493909110803e-05,
      "loss": 0.0068,
      "step": 9850
    },
    {
      "epoch": 0.7192355386972062,
      "grad_norm": 0.4046041667461395,
      "learning_rate": 4.280764461302794e-05,
      "loss": 0.0065,
      "step": 9860
    },
    {
      "epoch": 0.7199649865052156,
      "grad_norm": 0.17341801524162292,
      "learning_rate": 4.280035013494785e-05,
      "loss": 0.0053,
      "step": 9870
    },
    {
      "epoch": 0.7206944343132249,
      "grad_norm": 0.40433257818222046,
      "learning_rate": 4.2793055656867754e-05,
      "loss": 0.0048,
      "step": 9880
    },
    {
      "epoch": 0.7214238821212342,
      "grad_norm": 0.18013311922550201,
      "learning_rate": 4.278576117878766e-05,
      "loss": 0.0071,
      "step": 9890
    },
    {
      "epoch": 0.7221533299292435,
      "grad_norm": 0.1161152571439743,
      "learning_rate": 4.277846670070756e-05,
      "loss": 0.0053,
      "step": 9900
    },
    {
      "epoch": 0.7228827777372528,
      "grad_norm": 0.0060027590952813625,
      "learning_rate": 4.277117222262748e-05,
      "loss": 0.0036,
      "step": 9910
    },
    {
      "epoch": 0.7236122255452623,
      "grad_norm": 0.01458026934415102,
      "learning_rate": 4.2763877744547384e-05,
      "loss": 0.0077,
      "step": 9920
    },
    {
      "epoch": 0.7243416733532716,
      "grad_norm": 0.24564877152442932,
      "learning_rate": 4.2756583266467285e-05,
      "loss": 0.0044,
      "step": 9930
    },
    {
      "epoch": 0.7250711211612809,
      "grad_norm": 0.5757855176925659,
      "learning_rate": 4.274928878838719e-05,
      "loss": 0.0053,
      "step": 9940
    },
    {
      "epoch": 0.7258005689692902,
      "grad_norm": 0.17390866577625275,
      "learning_rate": 4.27419943103071e-05,
      "loss": 0.0056,
      "step": 9950
    },
    {
      "epoch": 0.7265300167772996,
      "grad_norm": 0.3214244246482849,
      "learning_rate": 4.2734699832227e-05,
      "loss": 0.0054,
      "step": 9960
    },
    {
      "epoch": 0.7272594645853089,
      "grad_norm": 0.326345294713974,
      "learning_rate": 4.2727405354146915e-05,
      "loss": 0.004,
      "step": 9970
    },
    {
      "epoch": 0.7279889123933183,
      "grad_norm": 0.23161272704601288,
      "learning_rate": 4.272011087606682e-05,
      "loss": 0.005,
      "step": 9980
    },
    {
      "epoch": 0.7287183602013276,
      "grad_norm": 0.6606770157814026,
      "learning_rate": 4.2712816397986724e-05,
      "loss": 0.0061,
      "step": 9990
    },
    {
      "epoch": 0.729447808009337,
      "grad_norm": 0.00856428686529398,
      "learning_rate": 4.270552191990663e-05,
      "loss": 0.0043,
      "step": 10000
    },
    {
      "epoch": 0.7301772558173463,
      "grad_norm": 0.11534453928470612,
      "learning_rate": 4.269822744182654e-05,
      "loss": 0.0049,
      "step": 10010
    },
    {
      "epoch": 0.7309067036253556,
      "grad_norm": 0.008489578031003475,
      "learning_rate": 4.2690932963746446e-05,
      "loss": 0.0066,
      "step": 10020
    },
    {
      "epoch": 0.7316361514333649,
      "grad_norm": 0.2907154858112335,
      "learning_rate": 4.2683638485666354e-05,
      "loss": 0.0064,
      "step": 10030
    },
    {
      "epoch": 0.7323655992413742,
      "grad_norm": 0.40318891406059265,
      "learning_rate": 4.267634400758626e-05,
      "loss": 0.0077,
      "step": 10040
    },
    {
      "epoch": 0.7330950470493837,
      "grad_norm": 0.23115651309490204,
      "learning_rate": 4.266904952950617e-05,
      "loss": 0.0061,
      "step": 10050
    },
    {
      "epoch": 0.733824494857393,
      "grad_norm": 0.23123577237129211,
      "learning_rate": 4.266175505142607e-05,
      "loss": 0.0064,
      "step": 10060
    },
    {
      "epoch": 0.7345539426654023,
      "grad_norm": 0.2893330752849579,
      "learning_rate": 4.265446057334598e-05,
      "loss": 0.0072,
      "step": 10070
    },
    {
      "epoch": 0.7352833904734116,
      "grad_norm": 0.029287271201610565,
      "learning_rate": 4.2647166095265885e-05,
      "loss": 0.0065,
      "step": 10080
    },
    {
      "epoch": 0.736012838281421,
      "grad_norm": 0.005328235682100058,
      "learning_rate": 4.263987161718579e-05,
      "loss": 0.0047,
      "step": 10090
    },
    {
      "epoch": 0.7367422860894303,
      "grad_norm": 0.23119735717773438,
      "learning_rate": 4.26325771391057e-05,
      "loss": 0.0039,
      "step": 10100
    },
    {
      "epoch": 0.7374717338974396,
      "grad_norm": 0.20268847048282623,
      "learning_rate": 4.262528266102561e-05,
      "loss": 0.0054,
      "step": 10110
    },
    {
      "epoch": 0.738201181705449,
      "grad_norm": 0.08940604329109192,
      "learning_rate": 4.2617988182945515e-05,
      "loss": 0.0041,
      "step": 10120
    },
    {
      "epoch": 0.7389306295134583,
      "grad_norm": 0.3758188486099243,
      "learning_rate": 4.2610693704865415e-05,
      "loss": 0.0063,
      "step": 10130
    },
    {
      "epoch": 0.7396600773214677,
      "grad_norm": 0.17368987202644348,
      "learning_rate": 4.260339922678532e-05,
      "loss": 0.0059,
      "step": 10140
    },
    {
      "epoch": 0.740389525129477,
      "grad_norm": 0.2017497718334198,
      "learning_rate": 4.259610474870524e-05,
      "loss": 0.0053,
      "step": 10150
    },
    {
      "epoch": 0.7411189729374863,
      "grad_norm": 0.34180784225463867,
      "learning_rate": 4.258881027062514e-05,
      "loss": 0.0069,
      "step": 10160
    },
    {
      "epoch": 0.7418484207454956,
      "grad_norm": 0.05805951729416847,
      "learning_rate": 4.2581515792545046e-05,
      "loss": 0.0057,
      "step": 10170
    },
    {
      "epoch": 0.742577868553505,
      "grad_norm": 0.37999385595321655,
      "learning_rate": 4.257422131446495e-05,
      "loss": 0.0055,
      "step": 10180
    },
    {
      "epoch": 0.7433073163615144,
      "grad_norm": 0.3021312355995178,
      "learning_rate": 4.256692683638486e-05,
      "loss": 0.0038,
      "step": 10190
    },
    {
      "epoch": 0.7440367641695237,
      "grad_norm": 0.23099415004253387,
      "learning_rate": 4.255963235830476e-05,
      "loss": 0.0071,
      "step": 10200
    },
    {
      "epoch": 0.744766211977533,
      "grad_norm": 0.008469943888485432,
      "learning_rate": 4.2552337880224676e-05,
      "loss": 0.0051,
      "step": 10210
    },
    {
      "epoch": 0.7454956597855423,
      "grad_norm": 0.4054349362850189,
      "learning_rate": 4.254504340214458e-05,
      "loss": 0.0057,
      "step": 10220
    },
    {
      "epoch": 0.7462251075935517,
      "grad_norm": 0.23107139766216278,
      "learning_rate": 4.2537748924064484e-05,
      "loss": 0.0056,
      "step": 10230
    },
    {
      "epoch": 0.746954555401561,
      "grad_norm": 0.2317580282688141,
      "learning_rate": 4.253045444598439e-05,
      "loss": 0.006,
      "step": 10240
    },
    {
      "epoch": 0.7476840032095704,
      "grad_norm": 0.3471599221229553,
      "learning_rate": 4.25231599679043e-05,
      "loss": 0.0045,
      "step": 10250
    },
    {
      "epoch": 0.7484134510175797,
      "grad_norm": 0.029256373643875122,
      "learning_rate": 4.25158654898242e-05,
      "loss": 0.0061,
      "step": 10260
    },
    {
      "epoch": 0.749142898825589,
      "grad_norm": 0.05858491733670235,
      "learning_rate": 4.2508571011744114e-05,
      "loss": 0.0047,
      "step": 10270
    },
    {
      "epoch": 0.7498723466335984,
      "grad_norm": 0.08705911785364151,
      "learning_rate": 4.250127653366402e-05,
      "loss": 0.0057,
      "step": 10280
    },
    {
      "epoch": 0.7506017944416077,
      "grad_norm": 0.17319338023662567,
      "learning_rate": 4.249398205558392e-05,
      "loss": 0.0058,
      "step": 10290
    },
    {
      "epoch": 0.751331242249617,
      "grad_norm": 0.17335553467273712,
      "learning_rate": 4.248668757750383e-05,
      "loss": 0.007,
      "step": 10300
    },
    {
      "epoch": 0.7520606900576263,
      "grad_norm": 0.14426890015602112,
      "learning_rate": 4.247939309942374e-05,
      "loss": 0.0043,
      "step": 10310
    },
    {
      "epoch": 0.7527901378656358,
      "grad_norm": 0.3469245433807373,
      "learning_rate": 4.2472098621343645e-05,
      "loss": 0.0061,
      "step": 10320
    },
    {
      "epoch": 0.7535195856736451,
      "grad_norm": 0.007917850278317928,
      "learning_rate": 4.246480414326355e-05,
      "loss": 0.0086,
      "step": 10330
    },
    {
      "epoch": 0.7542490334816544,
      "grad_norm": 0.2885477542877197,
      "learning_rate": 4.245750966518346e-05,
      "loss": 0.0054,
      "step": 10340
    },
    {
      "epoch": 0.7549784812896637,
      "grad_norm": 0.40373480319976807,
      "learning_rate": 4.245021518710337e-05,
      "loss": 0.0075,
      "step": 10350
    },
    {
      "epoch": 0.755707929097673,
      "grad_norm": 0.2614700198173523,
      "learning_rate": 4.244292070902327e-05,
      "loss": 0.0065,
      "step": 10360
    },
    {
      "epoch": 0.7564373769056824,
      "grad_norm": 0.0879293829202652,
      "learning_rate": 4.2435626230943176e-05,
      "loss": 0.0043,
      "step": 10370
    },
    {
      "epoch": 0.7571668247136918,
      "grad_norm": 0.029008859768509865,
      "learning_rate": 4.242833175286308e-05,
      "loss": 0.0058,
      "step": 10380
    },
    {
      "epoch": 0.7578962725217011,
      "grad_norm": 0.007555610965937376,
      "learning_rate": 4.242103727478299e-05,
      "loss": 0.0069,
      "step": 10390
    },
    {
      "epoch": 0.7586257203297104,
      "grad_norm": 0.40395405888557434,
      "learning_rate": 4.24137427967029e-05,
      "loss": 0.0075,
      "step": 10400
    },
    {
      "epoch": 0.7593551681377197,
      "grad_norm": 0.07103491574525833,
      "learning_rate": 4.2406448318622806e-05,
      "loss": 0.0046,
      "step": 10410
    },
    {
      "epoch": 0.7600846159457291,
      "grad_norm": 0.5767783522605896,
      "learning_rate": 4.2399153840542713e-05,
      "loss": 0.0069,
      "step": 10420
    },
    {
      "epoch": 0.7608140637537384,
      "grad_norm": 0.28897812962532043,
      "learning_rate": 4.2391859362462614e-05,
      "loss": 0.0085,
      "step": 10430
    },
    {
      "epoch": 0.7615435115617477,
      "grad_norm": 0.08692829310894012,
      "learning_rate": 4.238456488438253e-05,
      "loss": 0.0054,
      "step": 10440
    },
    {
      "epoch": 0.7622729593697571,
      "grad_norm": 0.03327249735593796,
      "learning_rate": 4.2377270406302436e-05,
      "loss": 0.0041,
      "step": 10450
    },
    {
      "epoch": 0.7630024071777665,
      "grad_norm": 0.17465369403362274,
      "learning_rate": 4.236997592822234e-05,
      "loss": 0.0056,
      "step": 10460
    },
    {
      "epoch": 0.7637318549857758,
      "grad_norm": 0.5765154957771301,
      "learning_rate": 4.2362681450142244e-05,
      "loss": 0.0043,
      "step": 10470
    },
    {
      "epoch": 0.7644613027937851,
      "grad_norm": 0.1152142658829689,
      "learning_rate": 4.235538697206215e-05,
      "loss": 0.0054,
      "step": 10480
    },
    {
      "epoch": 0.7651907506017944,
      "grad_norm": 0.03094746358692646,
      "learning_rate": 4.234809249398205e-05,
      "loss": 0.0038,
      "step": 10490
    },
    {
      "epoch": 0.7659201984098037,
      "grad_norm": 0.23039190471172333,
      "learning_rate": 4.234079801590197e-05,
      "loss": 0.0054,
      "step": 10500
    },
    {
      "epoch": 0.7666496462178131,
      "grad_norm": 0.40315964818000793,
      "learning_rate": 4.2333503537821874e-05,
      "loss": 0.0052,
      "step": 10510
    },
    {
      "epoch": 0.7673790940258225,
      "grad_norm": 0.3465021848678589,
      "learning_rate": 4.2326209059741775e-05,
      "loss": 0.0067,
      "step": 10520
    },
    {
      "epoch": 0.7681085418338318,
      "grad_norm": 0.1150364950299263,
      "learning_rate": 4.231891458166168e-05,
      "loss": 0.0067,
      "step": 10530
    },
    {
      "epoch": 0.7688379896418411,
      "grad_norm": 0.06032262369990349,
      "learning_rate": 4.231162010358159e-05,
      "loss": 0.0045,
      "step": 10540
    },
    {
      "epoch": 0.7695674374498505,
      "grad_norm": 0.23157906532287598,
      "learning_rate": 4.23043256255015e-05,
      "loss": 0.0051,
      "step": 10550
    },
    {
      "epoch": 0.7702968852578598,
      "grad_norm": 0.25436219573020935,
      "learning_rate": 4.2297031147421405e-05,
      "loss": 0.0066,
      "step": 10560
    },
    {
      "epoch": 0.7710263330658691,
      "grad_norm": 0.346250057220459,
      "learning_rate": 4.228973666934131e-05,
      "loss": 0.0054,
      "step": 10570
    },
    {
      "epoch": 0.7717557808738785,
      "grad_norm": 0.11622647941112518,
      "learning_rate": 4.228244219126122e-05,
      "loss": 0.0048,
      "step": 10580
    },
    {
      "epoch": 0.7724852286818878,
      "grad_norm": 0.11548726260662079,
      "learning_rate": 4.227514771318112e-05,
      "loss": 0.0048,
      "step": 10590
    },
    {
      "epoch": 0.7732146764898972,
      "grad_norm": 0.17349237203598022,
      "learning_rate": 4.226785323510103e-05,
      "loss": 0.0049,
      "step": 10600
    },
    {
      "epoch": 0.7739441242979065,
      "grad_norm": 0.0581502839922905,
      "learning_rate": 4.2260558757020936e-05,
      "loss": 0.0052,
      "step": 10610
    },
    {
      "epoch": 0.7746735721059158,
      "grad_norm": 0.1737983077764511,
      "learning_rate": 4.2253264278940844e-05,
      "loss": 0.0061,
      "step": 10620
    },
    {
      "epoch": 0.7754030199139251,
      "grad_norm": 0.005018319468945265,
      "learning_rate": 4.224596980086075e-05,
      "loss": 0.005,
      "step": 10630
    },
    {
      "epoch": 0.7761324677219344,
      "grad_norm": 0.23115794360637665,
      "learning_rate": 4.223867532278066e-05,
      "loss": 0.0048,
      "step": 10640
    },
    {
      "epoch": 0.7768619155299439,
      "grad_norm": 0.40415284037590027,
      "learning_rate": 4.2231380844700566e-05,
      "loss": 0.0072,
      "step": 10650
    },
    {
      "epoch": 0.7775913633379532,
      "grad_norm": 0.3461853861808777,
      "learning_rate": 4.222408636662047e-05,
      "loss": 0.0035,
      "step": 10660
    },
    {
      "epoch": 0.7783208111459625,
      "grad_norm": 0.2049895077943802,
      "learning_rate": 4.2216791888540375e-05,
      "loss": 0.0066,
      "step": 10670
    },
    {
      "epoch": 0.7790502589539718,
      "grad_norm": 0.2643778622150421,
      "learning_rate": 4.220949741046029e-05,
      "loss": 0.0029,
      "step": 10680
    },
    {
      "epoch": 0.7797797067619812,
      "grad_norm": 0.11631006002426147,
      "learning_rate": 4.220220293238019e-05,
      "loss": 0.0069,
      "step": 10690
    },
    {
      "epoch": 0.7805091545699905,
      "grad_norm": 0.05832691118121147,
      "learning_rate": 4.21949084543001e-05,
      "loss": 0.0048,
      "step": 10700
    },
    {
      "epoch": 0.7812386023779998,
      "grad_norm": 0.2604110836982727,
      "learning_rate": 4.2187613976220005e-05,
      "loss": 0.0089,
      "step": 10710
    },
    {
      "epoch": 0.7819680501860092,
      "grad_norm": 0.17436924576759338,
      "learning_rate": 4.2180319498139905e-05,
      "loss": 0.0064,
      "step": 10720
    },
    {
      "epoch": 0.7826974979940186,
      "grad_norm": 0.029696209356188774,
      "learning_rate": 4.217302502005981e-05,
      "loss": 0.0048,
      "step": 10730
    },
    {
      "epoch": 0.7834269458020279,
      "grad_norm": 0.26062628626823425,
      "learning_rate": 4.216573054197973e-05,
      "loss": 0.0072,
      "step": 10740
    },
    {
      "epoch": 0.7841563936100372,
      "grad_norm": 0.14517244696617126,
      "learning_rate": 4.215843606389963e-05,
      "loss": 0.0068,
      "step": 10750
    },
    {
      "epoch": 0.7848858414180465,
      "grad_norm": 0.17768608033657074,
      "learning_rate": 4.2151141585819536e-05,
      "loss": 0.0073,
      "step": 10760
    },
    {
      "epoch": 0.7856152892260558,
      "grad_norm": 0.008402381092309952,
      "learning_rate": 4.214384710773944e-05,
      "loss": 0.006,
      "step": 10770
    },
    {
      "epoch": 0.7863447370340653,
      "grad_norm": 0.08708794414997101,
      "learning_rate": 4.213655262965935e-05,
      "loss": 0.0055,
      "step": 10780
    },
    {
      "epoch": 0.7870741848420746,
      "grad_norm": 0.4421064555644989,
      "learning_rate": 4.212925815157925e-05,
      "loss": 0.0062,
      "step": 10790
    },
    {
      "epoch": 0.7878036326500839,
      "grad_norm": 0.6145156025886536,
      "learning_rate": 4.2121963673499166e-05,
      "loss": 0.0067,
      "step": 10800
    },
    {
      "epoch": 0.7885330804580932,
      "grad_norm": 0.057880766689777374,
      "learning_rate": 4.211466919541907e-05,
      "loss": 0.0052,
      "step": 10810
    },
    {
      "epoch": 0.7892625282661025,
      "grad_norm": 0.11549436300992966,
      "learning_rate": 4.2107374717338974e-05,
      "loss": 0.0048,
      "step": 10820
    },
    {
      "epoch": 0.7899919760741119,
      "grad_norm": 0.4739709496498108,
      "learning_rate": 4.210008023925888e-05,
      "loss": 0.0045,
      "step": 10830
    },
    {
      "epoch": 0.7907214238821212,
      "grad_norm": 0.02413012459874153,
      "learning_rate": 4.209278576117879e-05,
      "loss": 0.005,
      "step": 10840
    },
    {
      "epoch": 0.7914508716901306,
      "grad_norm": 0.7722559571266174,
      "learning_rate": 4.2085491283098697e-05,
      "loss": 0.0061,
      "step": 10850
    },
    {
      "epoch": 0.7921803194981399,
      "grad_norm": 0.37523484230041504,
      "learning_rate": 4.2078196805018604e-05,
      "loss": 0.0038,
      "step": 10860
    },
    {
      "epoch": 0.7929097673061493,
      "grad_norm": 0.012051557190716267,
      "learning_rate": 4.207090232693851e-05,
      "loss": 0.0069,
      "step": 10870
    },
    {
      "epoch": 0.7936392151141586,
      "grad_norm": 0.11634819209575653,
      "learning_rate": 4.206360784885842e-05,
      "loss": 0.0059,
      "step": 10880
    },
    {
      "epoch": 0.7943686629221679,
      "grad_norm": 0.11547499150037766,
      "learning_rate": 4.205631337077832e-05,
      "loss": 0.0052,
      "step": 10890
    },
    {
      "epoch": 0.7950981107301772,
      "grad_norm": 0.11738258600234985,
      "learning_rate": 4.204901889269823e-05,
      "loss": 0.0057,
      "step": 10900
    },
    {
      "epoch": 0.7958275585381865,
      "grad_norm": 0.17983342707157135,
      "learning_rate": 4.204172441461814e-05,
      "loss": 0.0055,
      "step": 10910
    },
    {
      "epoch": 0.796557006346196,
      "grad_norm": 0.11400686949491501,
      "learning_rate": 4.203442993653804e-05,
      "loss": 0.0049,
      "step": 10920
    },
    {
      "epoch": 0.7972864541542053,
      "grad_norm": 0.5187052488327026,
      "learning_rate": 4.202713545845795e-05,
      "loss": 0.0063,
      "step": 10930
    },
    {
      "epoch": 0.7980159019622146,
      "grad_norm": 0.5838209986686707,
      "learning_rate": 4.201984098037786e-05,
      "loss": 0.0036,
      "step": 10940
    },
    {
      "epoch": 0.7987453497702239,
      "grad_norm": 0.11701583117246628,
      "learning_rate": 4.201254650229776e-05,
      "loss": 0.0045,
      "step": 10950
    },
    {
      "epoch": 0.7994747975782333,
      "grad_norm": 0.28825652599334717,
      "learning_rate": 4.2005252024217666e-05,
      "loss": 0.0045,
      "step": 10960
    },
    {
      "epoch": 0.8002042453862426,
      "grad_norm": 0.23100650310516357,
      "learning_rate": 4.199795754613758e-05,
      "loss": 0.0055,
      "step": 10970
    },
    {
      "epoch": 0.800933693194252,
      "grad_norm": 0.2315552830696106,
      "learning_rate": 4.199066306805748e-05,
      "loss": 0.0065,
      "step": 10980
    },
    {
      "epoch": 0.8016631410022613,
      "grad_norm": 0.14409475028514862,
      "learning_rate": 4.198336858997739e-05,
      "loss": 0.004,
      "step": 10990
    },
    {
      "epoch": 0.8023925888102706,
      "grad_norm": 0.49071913957595825,
      "learning_rate": 4.1976074111897296e-05,
      "loss": 0.0053,
      "step": 11000
    },
    {
      "epoch": 0.80312203661828,
      "grad_norm": 0.11583378911018372,
      "learning_rate": 4.1968779633817204e-05,
      "loss": 0.0047,
      "step": 11010
    },
    {
      "epoch": 0.8038514844262893,
      "grad_norm": 0.007849222049117088,
      "learning_rate": 4.1961485155737104e-05,
      "loss": 0.0056,
      "step": 11020
    },
    {
      "epoch": 0.8045809322342986,
      "grad_norm": 0.6354525089263916,
      "learning_rate": 4.195419067765702e-05,
      "loss": 0.0059,
      "step": 11030
    },
    {
      "epoch": 0.8053103800423079,
      "grad_norm": 0.11594288796186447,
      "learning_rate": 4.1946896199576926e-05,
      "loss": 0.005,
      "step": 11040
    },
    {
      "epoch": 0.8060398278503174,
      "grad_norm": 0.23117810487747192,
      "learning_rate": 4.193960172149683e-05,
      "loss": 0.0065,
      "step": 11050
    },
    {
      "epoch": 0.8067692756583267,
      "grad_norm": 0.34885722398757935,
      "learning_rate": 4.1932307243416734e-05,
      "loss": 0.0053,
      "step": 11060
    },
    {
      "epoch": 0.807498723466336,
      "grad_norm": 0.08727150410413742,
      "learning_rate": 4.192501276533664e-05,
      "loss": 0.0038,
      "step": 11070
    },
    {
      "epoch": 0.8082281712743453,
      "grad_norm": 0.11552276462316513,
      "learning_rate": 4.191771828725655e-05,
      "loss": 0.0059,
      "step": 11080
    },
    {
      "epoch": 0.8089576190823546,
      "grad_norm": 0.1739078313112259,
      "learning_rate": 4.191042380917646e-05,
      "loss": 0.006,
      "step": 11090
    },
    {
      "epoch": 0.809687066890364,
      "grad_norm": 0.37506771087646484,
      "learning_rate": 4.1903129331096365e-05,
      "loss": 0.0044,
      "step": 11100
    },
    {
      "epoch": 0.8104165146983733,
      "grad_norm": 0.3580033481121063,
      "learning_rate": 4.189583485301627e-05,
      "loss": 0.005,
      "step": 11110
    },
    {
      "epoch": 0.8111459625063827,
      "grad_norm": 0.40424907207489014,
      "learning_rate": 4.188854037493617e-05,
      "loss": 0.0057,
      "step": 11120
    },
    {
      "epoch": 0.811875410314392,
      "grad_norm": 0.11539929360151291,
      "learning_rate": 4.188124589685608e-05,
      "loss": 0.0043,
      "step": 11130
    },
    {
      "epoch": 0.8126048581224014,
      "grad_norm": 0.2882772982120514,
      "learning_rate": 4.187395141877599e-05,
      "loss": 0.0055,
      "step": 11140
    },
    {
      "epoch": 0.8133343059304107,
      "grad_norm": 0.40515264868736267,
      "learning_rate": 4.1866656940695895e-05,
      "loss": 0.0058,
      "step": 11150
    },
    {
      "epoch": 0.81406375373842,
      "grad_norm": 0.009491683915257454,
      "learning_rate": 4.18593624626158e-05,
      "loss": 0.0065,
      "step": 11160
    },
    {
      "epoch": 0.8147932015464293,
      "grad_norm": 0.2891533374786377,
      "learning_rate": 4.185206798453571e-05,
      "loss": 0.0073,
      "step": 11170
    },
    {
      "epoch": 0.8155226493544387,
      "grad_norm": 0.46275749802589417,
      "learning_rate": 4.184477350645561e-05,
      "loss": 0.0071,
      "step": 11180
    },
    {
      "epoch": 0.8162520971624481,
      "grad_norm": 0.23144221305847168,
      "learning_rate": 4.183747902837552e-05,
      "loss": 0.0044,
      "step": 11190
    },
    {
      "epoch": 0.8169815449704574,
      "grad_norm": 0.12519070506095886,
      "learning_rate": 4.1830184550295426e-05,
      "loss": 0.0053,
      "step": 11200
    },
    {
      "epoch": 0.8177109927784667,
      "grad_norm": 0.2725186347961426,
      "learning_rate": 4.1822890072215334e-05,
      "loss": 0.0076,
      "step": 11210
    },
    {
      "epoch": 0.818440440586476,
      "grad_norm": 0.009177683852612972,
      "learning_rate": 4.181559559413524e-05,
      "loss": 0.0074,
      "step": 11220
    },
    {
      "epoch": 0.8191698883944853,
      "grad_norm": 0.11477041989564896,
      "learning_rate": 4.180830111605515e-05,
      "loss": 0.0061,
      "step": 11230
    },
    {
      "epoch": 0.8198993362024947,
      "grad_norm": 0.03052634745836258,
      "learning_rate": 4.1801006637975056e-05,
      "loss": 0.0064,
      "step": 11240
    },
    {
      "epoch": 0.8206287840105041,
      "grad_norm": 0.19562244415283203,
      "learning_rate": 4.179371215989496e-05,
      "loss": 0.0049,
      "step": 11250
    },
    {
      "epoch": 0.8213582318185134,
      "grad_norm": 0.3489430844783783,
      "learning_rate": 4.1786417681814865e-05,
      "loss": 0.005,
      "step": 11260
    },
    {
      "epoch": 0.8220876796265227,
      "grad_norm": 0.43274760246276855,
      "learning_rate": 4.177912320373478e-05,
      "loss": 0.0054,
      "step": 11270
    },
    {
      "epoch": 0.8228171274345321,
      "grad_norm": 0.14547017216682434,
      "learning_rate": 4.177182872565468e-05,
      "loss": 0.0062,
      "step": 11280
    },
    {
      "epoch": 0.8235465752425414,
      "grad_norm": 0.346401184797287,
      "learning_rate": 4.176453424757459e-05,
      "loss": 0.0047,
      "step": 11290
    },
    {
      "epoch": 0.8242760230505507,
      "grad_norm": 0.2658146023750305,
      "learning_rate": 4.1757239769494495e-05,
      "loss": 0.0046,
      "step": 11300
    },
    {
      "epoch": 0.82500547085856,
      "grad_norm": 0.0062118591740727425,
      "learning_rate": 4.17499452914144e-05,
      "loss": 0.0047,
      "step": 11310
    },
    {
      "epoch": 0.8257349186665695,
      "grad_norm": 0.40070340037345886,
      "learning_rate": 4.17426508133343e-05,
      "loss": 0.0033,
      "step": 11320
    },
    {
      "epoch": 0.8264643664745788,
      "grad_norm": 0.17881859838962555,
      "learning_rate": 4.173535633525422e-05,
      "loss": 0.0051,
      "step": 11330
    },
    {
      "epoch": 0.8271938142825881,
      "grad_norm": 0.008476251736283302,
      "learning_rate": 4.1728061857174125e-05,
      "loss": 0.0045,
      "step": 11340
    },
    {
      "epoch": 0.8279232620905974,
      "grad_norm": 0.2023991048336029,
      "learning_rate": 4.1720767379094026e-05,
      "loss": 0.0038,
      "step": 11350
    },
    {
      "epoch": 0.8286527098986067,
      "grad_norm": 0.11591167747974396,
      "learning_rate": 4.171347290101393e-05,
      "loss": 0.0053,
      "step": 11360
    },
    {
      "epoch": 0.829382157706616,
      "grad_norm": 0.1737428605556488,
      "learning_rate": 4.170617842293384e-05,
      "loss": 0.0048,
      "step": 11370
    },
    {
      "epoch": 0.8301116055146255,
      "grad_norm": 0.00989046972244978,
      "learning_rate": 4.169888394485375e-05,
      "loss": 0.0047,
      "step": 11380
    },
    {
      "epoch": 0.8308410533226348,
      "grad_norm": 0.034968167543411255,
      "learning_rate": 4.1691589466773656e-05,
      "loss": 0.008,
      "step": 11390
    },
    {
      "epoch": 0.8315705011306441,
      "grad_norm": 0.34318822622299194,
      "learning_rate": 4.168429498869356e-05,
      "loss": 0.0065,
      "step": 11400
    },
    {
      "epoch": 0.8322999489386534,
      "grad_norm": 0.37512001395225525,
      "learning_rate": 4.167700051061347e-05,
      "loss": 0.0055,
      "step": 11410
    },
    {
      "epoch": 0.8330293967466628,
      "grad_norm": 0.037408262491226196,
      "learning_rate": 4.166970603253337e-05,
      "loss": 0.0047,
      "step": 11420
    },
    {
      "epoch": 0.8337588445546721,
      "grad_norm": 0.3176921010017395,
      "learning_rate": 4.166241155445328e-05,
      "loss": 0.004,
      "step": 11430
    },
    {
      "epoch": 0.8344882923626814,
      "grad_norm": 0.3350086212158203,
      "learning_rate": 4.1655117076373193e-05,
      "loss": 0.0057,
      "step": 11440
    },
    {
      "epoch": 0.8352177401706908,
      "grad_norm": 0.11576163023710251,
      "learning_rate": 4.1647822598293094e-05,
      "loss": 0.0046,
      "step": 11450
    },
    {
      "epoch": 0.8359471879787002,
      "grad_norm": 0.46145638823509216,
      "learning_rate": 4.1640528120213e-05,
      "loss": 0.0045,
      "step": 11460
    },
    {
      "epoch": 0.8366766357867095,
      "grad_norm": 0.23099401593208313,
      "learning_rate": 4.163323364213291e-05,
      "loss": 0.0036,
      "step": 11470
    },
    {
      "epoch": 0.8374060835947188,
      "grad_norm": 0.20238611102104187,
      "learning_rate": 4.162593916405281e-05,
      "loss": 0.0051,
      "step": 11480
    },
    {
      "epoch": 0.8381355314027281,
      "grad_norm": 0.3931732475757599,
      "learning_rate": 4.161864468597272e-05,
      "loss": 0.0067,
      "step": 11490
    },
    {
      "epoch": 0.8388649792107374,
      "grad_norm": 0.14456355571746826,
      "learning_rate": 4.161135020789263e-05,
      "loss": 0.007,
      "step": 11500
    },
    {
      "epoch": 0.8395944270187468,
      "grad_norm": 0.10615025460720062,
      "learning_rate": 4.160405572981253e-05,
      "loss": 0.0063,
      "step": 11510
    },
    {
      "epoch": 0.8403238748267562,
      "grad_norm": 0.05805187672376633,
      "learning_rate": 4.159676125173244e-05,
      "loss": 0.0048,
      "step": 11520
    },
    {
      "epoch": 0.8410533226347655,
      "grad_norm": 0.37583866715431213,
      "learning_rate": 4.158946677365235e-05,
      "loss": 0.0063,
      "step": 11530
    },
    {
      "epoch": 0.8417827704427748,
      "grad_norm": 0.11604152619838715,
      "learning_rate": 4.1582172295572255e-05,
      "loss": 0.0055,
      "step": 11540
    },
    {
      "epoch": 0.8425122182507842,
      "grad_norm": 0.3470911979675293,
      "learning_rate": 4.1574877817492156e-05,
      "loss": 0.0043,
      "step": 11550
    },
    {
      "epoch": 0.8432416660587935,
      "grad_norm": 0.173946812748909,
      "learning_rate": 4.156758333941207e-05,
      "loss": 0.0051,
      "step": 11560
    },
    {
      "epoch": 0.8439711138668028,
      "grad_norm": 0.2807399332523346,
      "learning_rate": 4.156028886133198e-05,
      "loss": 0.0051,
      "step": 11570
    },
    {
      "epoch": 0.8447005616748122,
      "grad_norm": 0.37619370222091675,
      "learning_rate": 4.155299438325188e-05,
      "loss": 0.0057,
      "step": 11580
    },
    {
      "epoch": 0.8454300094828215,
      "grad_norm": 0.40973350405693054,
      "learning_rate": 4.1545699905171786e-05,
      "loss": 0.0046,
      "step": 11590
    },
    {
      "epoch": 0.8461594572908309,
      "grad_norm": 0.050574738532304764,
      "learning_rate": 4.1538405427091694e-05,
      "loss": 0.0055,
      "step": 11600
    },
    {
      "epoch": 0.8468889050988402,
      "grad_norm": 0.03045179881155491,
      "learning_rate": 4.15311109490116e-05,
      "loss": 0.0062,
      "step": 11610
    },
    {
      "epoch": 0.8476183529068495,
      "grad_norm": 0.17410342395305634,
      "learning_rate": 4.152381647093151e-05,
      "loss": 0.0052,
      "step": 11620
    },
    {
      "epoch": 0.8483478007148588,
      "grad_norm": 0.39496660232543945,
      "learning_rate": 4.1516521992851416e-05,
      "loss": 0.0055,
      "step": 11630
    },
    {
      "epoch": 0.8490772485228681,
      "grad_norm": 0.4620223045349121,
      "learning_rate": 4.1509227514771324e-05,
      "loss": 0.0039,
      "step": 11640
    },
    {
      "epoch": 0.8498066963308776,
      "grad_norm": 0.3191429376602173,
      "learning_rate": 4.1501933036691224e-05,
      "loss": 0.0053,
      "step": 11650
    },
    {
      "epoch": 0.8505361441388869,
      "grad_norm": 0.0870215967297554,
      "learning_rate": 4.149463855861113e-05,
      "loss": 0.0039,
      "step": 11660
    },
    {
      "epoch": 0.8512655919468962,
      "grad_norm": 0.0867646113038063,
      "learning_rate": 4.148734408053104e-05,
      "loss": 0.0056,
      "step": 11670
    },
    {
      "epoch": 0.8519950397549055,
      "grad_norm": 0.3931938111782074,
      "learning_rate": 4.148004960245095e-05,
      "loss": 0.0069,
      "step": 11680
    },
    {
      "epoch": 0.8527244875629149,
      "grad_norm": 0.28900226950645447,
      "learning_rate": 4.1472755124370855e-05,
      "loss": 0.0052,
      "step": 11690
    },
    {
      "epoch": 0.8534539353709242,
      "grad_norm": 0.3178209662437439,
      "learning_rate": 4.146546064629076e-05,
      "loss": 0.0052,
      "step": 11700
    },
    {
      "epoch": 0.8541833831789335,
      "grad_norm": 0.11977314203977585,
      "learning_rate": 4.145816616821066e-05,
      "loss": 0.0046,
      "step": 11710
    },
    {
      "epoch": 0.8549128309869429,
      "grad_norm": 0.5206738114356995,
      "learning_rate": 4.145087169013057e-05,
      "loss": 0.0069,
      "step": 11720
    },
    {
      "epoch": 0.8556422787949522,
      "grad_norm": 0.20261044800281525,
      "learning_rate": 4.144357721205048e-05,
      "loss": 0.0073,
      "step": 11730
    },
    {
      "epoch": 0.8563717266029616,
      "grad_norm": 0.031579285860061646,
      "learning_rate": 4.1436282733970385e-05,
      "loss": 0.0081,
      "step": 11740
    },
    {
      "epoch": 0.8571011744109709,
      "grad_norm": 0.05849926173686981,
      "learning_rate": 4.142898825589029e-05,
      "loss": 0.0063,
      "step": 11750
    },
    {
      "epoch": 0.8578306222189802,
      "grad_norm": 0.07504786550998688,
      "learning_rate": 4.14216937778102e-05,
      "loss": 0.0058,
      "step": 11760
    },
    {
      "epoch": 0.8585600700269895,
      "grad_norm": 0.11612102389335632,
      "learning_rate": 4.141439929973011e-05,
      "loss": 0.0051,
      "step": 11770
    },
    {
      "epoch": 0.8592895178349989,
      "grad_norm": 0.3466790020465851,
      "learning_rate": 4.140710482165001e-05,
      "loss": 0.0033,
      "step": 11780
    },
    {
      "epoch": 0.8600189656430083,
      "grad_norm": 0.20182174444198608,
      "learning_rate": 4.1399810343569916e-05,
      "loss": 0.0047,
      "step": 11790
    },
    {
      "epoch": 0.8607484134510176,
      "grad_norm": 0.05836951732635498,
      "learning_rate": 4.139251586548983e-05,
      "loss": 0.0052,
      "step": 11800
    },
    {
      "epoch": 0.8614778612590269,
      "grad_norm": 0.5212799310684204,
      "learning_rate": 4.138522138740973e-05,
      "loss": 0.006,
      "step": 11810
    },
    {
      "epoch": 0.8622073090670362,
      "grad_norm": 0.17364631593227386,
      "learning_rate": 4.137792690932964e-05,
      "loss": 0.0052,
      "step": 11820
    },
    {
      "epoch": 0.8629367568750456,
      "grad_norm": 0.17428307235240936,
      "learning_rate": 4.1370632431249546e-05,
      "loss": 0.0053,
      "step": 11830
    },
    {
      "epoch": 0.8636662046830549,
      "grad_norm": 0.23148170113563538,
      "learning_rate": 4.1363337953169454e-05,
      "loss": 0.0062,
      "step": 11840
    },
    {
      "epoch": 0.8643956524910643,
      "grad_norm": 0.14502446353435516,
      "learning_rate": 4.1356043475089355e-05,
      "loss": 0.0046,
      "step": 11850
    },
    {
      "epoch": 0.8651251002990736,
      "grad_norm": 0.17388594150543213,
      "learning_rate": 4.134874899700927e-05,
      "loss": 0.0048,
      "step": 11860
    },
    {
      "epoch": 0.865854548107083,
      "grad_norm": 0.40515756607055664,
      "learning_rate": 4.1341454518929177e-05,
      "loss": 0.0058,
      "step": 11870
    },
    {
      "epoch": 0.8665839959150923,
      "grad_norm": 0.02940361015498638,
      "learning_rate": 4.133416004084908e-05,
      "loss": 0.0068,
      "step": 11880
    },
    {
      "epoch": 0.8673134437231016,
      "grad_norm": 0.11594388633966446,
      "learning_rate": 4.1326865562768985e-05,
      "loss": 0.0051,
      "step": 11890
    },
    {
      "epoch": 0.8680428915311109,
      "grad_norm": 0.2888534963130951,
      "learning_rate": 4.131957108468889e-05,
      "loss": 0.0058,
      "step": 11900
    },
    {
      "epoch": 0.8687723393391202,
      "grad_norm": 0.005381044466048479,
      "learning_rate": 4.13122766066088e-05,
      "loss": 0.0056,
      "step": 11910
    },
    {
      "epoch": 0.8695017871471297,
      "grad_norm": 0.1735292226076126,
      "learning_rate": 4.130498212852871e-05,
      "loss": 0.0065,
      "step": 11920
    },
    {
      "epoch": 0.870231234955139,
      "grad_norm": 0.030173897743225098,
      "learning_rate": 4.1297687650448615e-05,
      "loss": 0.0065,
      "step": 11930
    },
    {
      "epoch": 0.8709606827631483,
      "grad_norm": 0.06965552270412445,
      "learning_rate": 4.1290393172368516e-05,
      "loss": 0.0069,
      "step": 11940
    },
    {
      "epoch": 0.8716901305711576,
      "grad_norm": 0.40407097339630127,
      "learning_rate": 4.128309869428842e-05,
      "loss": 0.0083,
      "step": 11950
    },
    {
      "epoch": 0.872419578379167,
      "grad_norm": 0.03337009251117706,
      "learning_rate": 4.127580421620833e-05,
      "loss": 0.0058,
      "step": 11960
    },
    {
      "epoch": 0.8731490261871763,
      "grad_norm": 0.4050634503364563,
      "learning_rate": 4.126850973812824e-05,
      "loss": 0.0052,
      "step": 11970
    },
    {
      "epoch": 0.8738784739951856,
      "grad_norm": 0.43147173523902893,
      "learning_rate": 4.1261215260048146e-05,
      "loss": 0.005,
      "step": 11980
    },
    {
      "epoch": 0.874607921803195,
      "grad_norm": 0.204276904463768,
      "learning_rate": 4.125392078196805e-05,
      "loss": 0.005,
      "step": 11990
    },
    {
      "epoch": 0.8753373696112043,
      "grad_norm": 0.07259689271450043,
      "learning_rate": 4.124662630388796e-05,
      "loss": 0.0046,
      "step": 12000
    },
    {
      "epoch": 0.8760668174192137,
      "grad_norm": 0.030202461406588554,
      "learning_rate": 4.123933182580786e-05,
      "loss": 0.0044,
      "step": 12010
    },
    {
      "epoch": 0.876796265227223,
      "grad_norm": 0.11676390469074249,
      "learning_rate": 4.123203734772777e-05,
      "loss": 0.0058,
      "step": 12020
    },
    {
      "epoch": 0.8775257130352323,
      "grad_norm": 0.20153917372226715,
      "learning_rate": 4.1224742869647683e-05,
      "loss": 0.0052,
      "step": 12030
    },
    {
      "epoch": 0.8782551608432416,
      "grad_norm": 0.2335870862007141,
      "learning_rate": 4.1217448391567584e-05,
      "loss": 0.0048,
      "step": 12040
    },
    {
      "epoch": 0.878984608651251,
      "grad_norm": 0.05838676914572716,
      "learning_rate": 4.121015391348749e-05,
      "loss": 0.0052,
      "step": 12050
    },
    {
      "epoch": 0.8797140564592604,
      "grad_norm": 0.23140200972557068,
      "learning_rate": 4.12028594354074e-05,
      "loss": 0.0052,
      "step": 12060
    },
    {
      "epoch": 0.8804435042672697,
      "grad_norm": 0.058456555008888245,
      "learning_rate": 4.119556495732731e-05,
      "loss": 0.0083,
      "step": 12070
    },
    {
      "epoch": 0.881172952075279,
      "grad_norm": 0.14457355439662933,
      "learning_rate": 4.118827047924721e-05,
      "loss": 0.0041,
      "step": 12080
    },
    {
      "epoch": 0.8819023998832883,
      "grad_norm": 0.2605891823768616,
      "learning_rate": 4.118097600116712e-05,
      "loss": 0.0052,
      "step": 12090
    },
    {
      "epoch": 0.8826318476912977,
      "grad_norm": 0.23126886785030365,
      "learning_rate": 4.117368152308703e-05,
      "loss": 0.0053,
      "step": 12100
    },
    {
      "epoch": 0.883361295499307,
      "grad_norm": 0.03015156462788582,
      "learning_rate": 4.116638704500693e-05,
      "loss": 0.0052,
      "step": 12110
    },
    {
      "epoch": 0.8840907433073164,
      "grad_norm": 0.3747481107711792,
      "learning_rate": 4.115909256692684e-05,
      "loss": 0.0054,
      "step": 12120
    },
    {
      "epoch": 0.8848201911153257,
      "grad_norm": 0.06146390736103058,
      "learning_rate": 4.1151798088846745e-05,
      "loss": 0.006,
      "step": 12130
    },
    {
      "epoch": 0.885549638923335,
      "grad_norm": 0.1445465087890625,
      "learning_rate": 4.1144503610766646e-05,
      "loss": 0.0046,
      "step": 12140
    },
    {
      "epoch": 0.8862790867313444,
      "grad_norm": 0.4685632288455963,
      "learning_rate": 4.113720913268656e-05,
      "loss": 0.0056,
      "step": 12150
    },
    {
      "epoch": 0.8870085345393537,
      "grad_norm": 0.23141801357269287,
      "learning_rate": 4.112991465460647e-05,
      "loss": 0.0057,
      "step": 12160
    },
    {
      "epoch": 0.887737982347363,
      "grad_norm": 0.21227239072322845,
      "learning_rate": 4.112262017652637e-05,
      "loss": 0.0047,
      "step": 12170
    },
    {
      "epoch": 0.8884674301553723,
      "grad_norm": 0.3520900309085846,
      "learning_rate": 4.1115325698446276e-05,
      "loss": 0.0045,
      "step": 12180
    },
    {
      "epoch": 0.8891968779633818,
      "grad_norm": 0.17401526868343353,
      "learning_rate": 4.1108031220366184e-05,
      "loss": 0.0047,
      "step": 12190
    },
    {
      "epoch": 0.8899263257713911,
      "grad_norm": 0.030923429876565933,
      "learning_rate": 4.110073674228609e-05,
      "loss": 0.0048,
      "step": 12200
    },
    {
      "epoch": 0.8906557735794004,
      "grad_norm": 0.08907605707645416,
      "learning_rate": 4.1093442264206e-05,
      "loss": 0.0043,
      "step": 12210
    },
    {
      "epoch": 0.8913852213874097,
      "grad_norm": 0.13954493403434753,
      "learning_rate": 4.1086147786125906e-05,
      "loss": 0.0051,
      "step": 12220
    },
    {
      "epoch": 0.892114669195419,
      "grad_norm": 0.3462674915790558,
      "learning_rate": 4.1078853308045814e-05,
      "loss": 0.0048,
      "step": 12230
    },
    {
      "epoch": 0.8928441170034284,
      "grad_norm": 0.11684072762727737,
      "learning_rate": 4.1071558829965715e-05,
      "loss": 0.0043,
      "step": 12240
    },
    {
      "epoch": 0.8935735648114378,
      "grad_norm": 0.29390713572502136,
      "learning_rate": 4.106426435188562e-05,
      "loss": 0.0051,
      "step": 12250
    },
    {
      "epoch": 0.8943030126194471,
      "grad_norm": 0.12127821147441864,
      "learning_rate": 4.105696987380553e-05,
      "loss": 0.0052,
      "step": 12260
    },
    {
      "epoch": 0.8950324604274564,
      "grad_norm": 0.11560776084661484,
      "learning_rate": 4.104967539572544e-05,
      "loss": 0.0044,
      "step": 12270
    },
    {
      "epoch": 0.8957619082354658,
      "grad_norm": 0.14683856070041656,
      "learning_rate": 4.1042380917645345e-05,
      "loss": 0.0036,
      "step": 12280
    },
    {
      "epoch": 0.8964913560434751,
      "grad_norm": 0.11586957424879074,
      "learning_rate": 4.103508643956525e-05,
      "loss": 0.0047,
      "step": 12290
    },
    {
      "epoch": 0.8972208038514844,
      "grad_norm": 0.036471929401159286,
      "learning_rate": 4.102779196148516e-05,
      "loss": 0.0037,
      "step": 12300
    },
    {
      "epoch": 0.8979502516594937,
      "grad_norm": 0.17356029152870178,
      "learning_rate": 4.102049748340506e-05,
      "loss": 0.0045,
      "step": 12310
    },
    {
      "epoch": 0.8986796994675031,
      "grad_norm": 0.012018430978059769,
      "learning_rate": 4.101320300532497e-05,
      "loss": 0.0044,
      "step": 12320
    },
    {
      "epoch": 0.8994091472755125,
      "grad_norm": 0.12392491102218628,
      "learning_rate": 4.100590852724488e-05,
      "loss": 0.0059,
      "step": 12330
    },
    {
      "epoch": 0.9001385950835218,
      "grad_norm": 0.3106166124343872,
      "learning_rate": 4.099861404916478e-05,
      "loss": 0.0051,
      "step": 12340
    },
    {
      "epoch": 0.9008680428915311,
      "grad_norm": 0.3783279359340668,
      "learning_rate": 4.099131957108469e-05,
      "loss": 0.0046,
      "step": 12350
    },
    {
      "epoch": 0.9015974906995404,
      "grad_norm": 0.14586102962493896,
      "learning_rate": 4.09840250930046e-05,
      "loss": 0.0047,
      "step": 12360
    },
    {
      "epoch": 0.9023269385075497,
      "grad_norm": 0.14594444632530212,
      "learning_rate": 4.0976730614924506e-05,
      "loss": 0.0068,
      "step": 12370
    },
    {
      "epoch": 0.9030563863155591,
      "grad_norm": 0.13458427786827087,
      "learning_rate": 4.096943613684441e-05,
      "loss": 0.0037,
      "step": 12380
    },
    {
      "epoch": 0.9037858341235685,
      "grad_norm": 0.7513858675956726,
      "learning_rate": 4.096214165876432e-05,
      "loss": 0.0053,
      "step": 12390
    },
    {
      "epoch": 0.9045152819315778,
      "grad_norm": 0.08749733120203018,
      "learning_rate": 4.095484718068423e-05,
      "loss": 0.005,
      "step": 12400
    },
    {
      "epoch": 0.9052447297395871,
      "grad_norm": 0.14429894089698792,
      "learning_rate": 4.094755270260413e-05,
      "loss": 0.0052,
      "step": 12410
    },
    {
      "epoch": 0.9059741775475965,
      "grad_norm": 0.260839581489563,
      "learning_rate": 4.0940258224524037e-05,
      "loss": 0.0058,
      "step": 12420
    },
    {
      "epoch": 0.9067036253556058,
      "grad_norm": 0.34702450037002563,
      "learning_rate": 4.0932963746443944e-05,
      "loss": 0.0043,
      "step": 12430
    },
    {
      "epoch": 0.9074330731636151,
      "grad_norm": 0.32685232162475586,
      "learning_rate": 4.092566926836385e-05,
      "loss": 0.0052,
      "step": 12440
    },
    {
      "epoch": 0.9081625209716245,
      "grad_norm": 0.5480322241783142,
      "learning_rate": 4.091837479028376e-05,
      "loss": 0.0059,
      "step": 12450
    },
    {
      "epoch": 0.9088919687796339,
      "grad_norm": 0.17361308634281158,
      "learning_rate": 4.091108031220367e-05,
      "loss": 0.0052,
      "step": 12460
    },
    {
      "epoch": 0.9096214165876432,
      "grad_norm": 0.03091583587229252,
      "learning_rate": 4.090378583412357e-05,
      "loss": 0.004,
      "step": 12470
    },
    {
      "epoch": 0.9103508643956525,
      "grad_norm": 0.2598505914211273,
      "learning_rate": 4.0896491356043475e-05,
      "loss": 0.0033,
      "step": 12480
    },
    {
      "epoch": 0.9110803122036618,
      "grad_norm": 0.2028072029352188,
      "learning_rate": 4.088919687796338e-05,
      "loss": 0.0064,
      "step": 12490
    },
    {
      "epoch": 0.9118097600116711,
      "grad_norm": 0.033154990524053574,
      "learning_rate": 4.088190239988329e-05,
      "loss": 0.0061,
      "step": 12500
    },
    {
      "epoch": 0.9125392078196805,
      "grad_norm": 0.28916114568710327,
      "learning_rate": 4.08746079218032e-05,
      "loss": 0.0062,
      "step": 12510
    },
    {
      "epoch": 0.9132686556276899,
      "grad_norm": 0.10204361379146576,
      "learning_rate": 4.0867313443723105e-05,
      "loss": 0.0059,
      "step": 12520
    },
    {
      "epoch": 0.9139981034356992,
      "grad_norm": 0.43724745512008667,
      "learning_rate": 4.086001896564301e-05,
      "loss": 0.0042,
      "step": 12530
    },
    {
      "epoch": 0.9147275512437085,
      "grad_norm": 0.4329865574836731,
      "learning_rate": 4.085272448756291e-05,
      "loss": 0.0047,
      "step": 12540
    },
    {
      "epoch": 0.9154569990517178,
      "grad_norm": 0.17350012063980103,
      "learning_rate": 4.084543000948282e-05,
      "loss": 0.005,
      "step": 12550
    },
    {
      "epoch": 0.9161864468597272,
      "grad_norm": 0.1739315688610077,
      "learning_rate": 4.0838135531402735e-05,
      "loss": 0.0056,
      "step": 12560
    },
    {
      "epoch": 0.9169158946677365,
      "grad_norm": 0.20200324058532715,
      "learning_rate": 4.0830841053322636e-05,
      "loss": 0.0053,
      "step": 12570
    },
    {
      "epoch": 0.9176453424757458,
      "grad_norm": 0.4333708584308624,
      "learning_rate": 4.0823546575242543e-05,
      "loss": 0.0046,
      "step": 12580
    },
    {
      "epoch": 0.9183747902837552,
      "grad_norm": 0.288419246673584,
      "learning_rate": 4.081625209716245e-05,
      "loss": 0.0056,
      "step": 12590
    },
    {
      "epoch": 0.9191042380917646,
      "grad_norm": 0.6927173733711243,
      "learning_rate": 4.080895761908236e-05,
      "loss": 0.0054,
      "step": 12600
    },
    {
      "epoch": 0.9198336858997739,
      "grad_norm": 0.12417542189359665,
      "learning_rate": 4.080166314100226e-05,
      "loss": 0.0039,
      "step": 12610
    },
    {
      "epoch": 0.9205631337077832,
      "grad_norm": 0.1169629618525505,
      "learning_rate": 4.0794368662922174e-05,
      "loss": 0.0061,
      "step": 12620
    },
    {
      "epoch": 0.9212925815157925,
      "grad_norm": 0.15672439336776733,
      "learning_rate": 4.078707418484208e-05,
      "loss": 0.0062,
      "step": 12630
    },
    {
      "epoch": 0.9220220293238018,
      "grad_norm": 0.46239426732063293,
      "learning_rate": 4.077977970676198e-05,
      "loss": 0.005,
      "step": 12640
    },
    {
      "epoch": 0.9227514771318113,
      "grad_norm": 0.03053213097155094,
      "learning_rate": 4.077248522868189e-05,
      "loss": 0.0041,
      "step": 12650
    },
    {
      "epoch": 0.9234809249398206,
      "grad_norm": 0.05912398174405098,
      "learning_rate": 4.07651907506018e-05,
      "loss": 0.0045,
      "step": 12660
    },
    {
      "epoch": 0.9242103727478299,
      "grad_norm": 0.14447087049484253,
      "learning_rate": 4.07578962725217e-05,
      "loss": 0.006,
      "step": 12670
    },
    {
      "epoch": 0.9249398205558392,
      "grad_norm": 0.23098577558994293,
      "learning_rate": 4.075060179444161e-05,
      "loss": 0.0046,
      "step": 12680
    },
    {
      "epoch": 0.9256692683638486,
      "grad_norm": 0.06477107107639313,
      "learning_rate": 4.074330731636152e-05,
      "loss": 0.0046,
      "step": 12690
    },
    {
      "epoch": 0.9263987161718579,
      "grad_norm": 0.059432510286569595,
      "learning_rate": 4.073601283828142e-05,
      "loss": 0.004,
      "step": 12700
    },
    {
      "epoch": 0.9271281639798672,
      "grad_norm": 0.08697157353162766,
      "learning_rate": 4.072871836020133e-05,
      "loss": 0.0056,
      "step": 12710
    },
    {
      "epoch": 0.9278576117878766,
      "grad_norm": 0.1440945714712143,
      "learning_rate": 4.0721423882121235e-05,
      "loss": 0.0049,
      "step": 12720
    },
    {
      "epoch": 0.9285870595958859,
      "grad_norm": 0.059537459164857864,
      "learning_rate": 4.071412940404114e-05,
      "loss": 0.0044,
      "step": 12730
    },
    {
      "epoch": 0.9293165074038953,
      "grad_norm": 0.11649135500192642,
      "learning_rate": 4.070683492596105e-05,
      "loss": 0.0054,
      "step": 12740
    },
    {
      "epoch": 0.9300459552119046,
      "grad_norm": 0.24005524814128876,
      "learning_rate": 4.069954044788096e-05,
      "loss": 0.0036,
      "step": 12750
    },
    {
      "epoch": 0.9307754030199139,
      "grad_norm": 0.23179620504379272,
      "learning_rate": 4.0692245969800865e-05,
      "loss": 0.0038,
      "step": 12760
    },
    {
      "epoch": 0.9315048508279232,
      "grad_norm": 0.5199776291847229,
      "learning_rate": 4.0684951491720766e-05,
      "loss": 0.006,
      "step": 12770
    },
    {
      "epoch": 0.9322342986359325,
      "grad_norm": 0.05966712161898613,
      "learning_rate": 4.0677657013640674e-05,
      "loss": 0.0047,
      "step": 12780
    },
    {
      "epoch": 0.932963746443942,
      "grad_norm": 0.1743096113204956,
      "learning_rate": 4.067036253556058e-05,
      "loss": 0.0034,
      "step": 12790
    },
    {
      "epoch": 0.9336931942519513,
      "grad_norm": 0.4337165355682373,
      "learning_rate": 4.066306805748049e-05,
      "loss": 0.0037,
      "step": 12800
    },
    {
      "epoch": 0.9344226420599606,
      "grad_norm": 0.2888832688331604,
      "learning_rate": 4.0655773579400396e-05,
      "loss": 0.0063,
      "step": 12810
    },
    {
      "epoch": 0.9351520898679699,
      "grad_norm": 0.37554866075515747,
      "learning_rate": 4.0648479101320304e-05,
      "loss": 0.0046,
      "step": 12820
    },
    {
      "epoch": 0.9358815376759793,
      "grad_norm": 0.4916895031929016,
      "learning_rate": 4.064118462324021e-05,
      "loss": 0.0072,
      "step": 12830
    },
    {
      "epoch": 0.9366109854839886,
      "grad_norm": 0.08647916465997696,
      "learning_rate": 4.063389014516011e-05,
      "loss": 0.0049,
      "step": 12840
    },
    {
      "epoch": 0.937340433291998,
      "grad_norm": 0.11574207991361618,
      "learning_rate": 4.062659566708002e-05,
      "loss": 0.0046,
      "step": 12850
    },
    {
      "epoch": 0.9380698811000073,
      "grad_norm": 0.2886604964733124,
      "learning_rate": 4.0619301188999934e-05,
      "loss": 0.0047,
      "step": 12860
    },
    {
      "epoch": 0.9387993289080167,
      "grad_norm": 0.17458386719226837,
      "learning_rate": 4.0612006710919835e-05,
      "loss": 0.007,
      "step": 12870
    },
    {
      "epoch": 0.939528776716026,
      "grad_norm": 0.22374823689460754,
      "learning_rate": 4.060471223283974e-05,
      "loss": 0.006,
      "step": 12880
    },
    {
      "epoch": 0.9402582245240353,
      "grad_norm": 0.3179541528224945,
      "learning_rate": 4.059741775475965e-05,
      "loss": 0.0063,
      "step": 12890
    },
    {
      "epoch": 0.9409876723320446,
      "grad_norm": 0.057847533375024796,
      "learning_rate": 4.059012327667955e-05,
      "loss": 0.0042,
      "step": 12900
    },
    {
      "epoch": 0.9417171201400539,
      "grad_norm": 0.6346772313117981,
      "learning_rate": 4.0582828798599465e-05,
      "loss": 0.0044,
      "step": 12910
    },
    {
      "epoch": 0.9424465679480634,
      "grad_norm": 0.23177872598171234,
      "learning_rate": 4.057553432051937e-05,
      "loss": 0.004,
      "step": 12920
    },
    {
      "epoch": 0.9431760157560727,
      "grad_norm": 0.03313799202442169,
      "learning_rate": 4.056823984243927e-05,
      "loss": 0.0053,
      "step": 12930
    },
    {
      "epoch": 0.943905463564082,
      "grad_norm": 0.4926108717918396,
      "learning_rate": 4.056094536435918e-05,
      "loss": 0.0031,
      "step": 12940
    },
    {
      "epoch": 0.9446349113720913,
      "grad_norm": 0.06202555447816849,
      "learning_rate": 4.055365088627909e-05,
      "loss": 0.0048,
      "step": 12950
    },
    {
      "epoch": 0.9453643591801006,
      "grad_norm": 0.2896803915500641,
      "learning_rate": 4.0546356408198996e-05,
      "loss": 0.0054,
      "step": 12960
    },
    {
      "epoch": 0.94609380698811,
      "grad_norm": 0.634009838104248,
      "learning_rate": 4.05390619301189e-05,
      "loss": 0.0059,
      "step": 12970
    },
    {
      "epoch": 0.9468232547961193,
      "grad_norm": 0.46901240944862366,
      "learning_rate": 4.053176745203881e-05,
      "loss": 0.0049,
      "step": 12980
    },
    {
      "epoch": 0.9475527026041287,
      "grad_norm": 0.05867910012602806,
      "learning_rate": 4.052447297395872e-05,
      "loss": 0.0063,
      "step": 12990
    },
    {
      "epoch": 0.948282150412138,
      "grad_norm": 0.0883059948682785,
      "learning_rate": 4.051717849587862e-05,
      "loss": 0.0064,
      "step": 13000
    },
    {
      "epoch": 0.9490115982201474,
      "grad_norm": 0.20312321186065674,
      "learning_rate": 4.0509884017798527e-05,
      "loss": 0.0035,
      "step": 13010
    },
    {
      "epoch": 0.9497410460281567,
      "grad_norm": 0.2027394026517868,
      "learning_rate": 4.0502589539718434e-05,
      "loss": 0.0041,
      "step": 13020
    },
    {
      "epoch": 0.950470493836166,
      "grad_norm": 0.1748705357313156,
      "learning_rate": 4.049529506163834e-05,
      "loss": 0.0042,
      "step": 13030
    },
    {
      "epoch": 0.9511999416441753,
      "grad_norm": 0.31771761178970337,
      "learning_rate": 4.048800058355825e-05,
      "loss": 0.0047,
      "step": 13040
    },
    {
      "epoch": 0.9519293894521847,
      "grad_norm": 0.011201885528862476,
      "learning_rate": 4.048070610547816e-05,
      "loss": 0.0037,
      "step": 13050
    },
    {
      "epoch": 0.9526588372601941,
      "grad_norm": 0.267639696598053,
      "learning_rate": 4.0473411627398064e-05,
      "loss": 0.005,
      "step": 13060
    },
    {
      "epoch": 0.9533882850682034,
      "grad_norm": 0.07290881127119064,
      "learning_rate": 4.0466117149317965e-05,
      "loss": 0.0059,
      "step": 13070
    },
    {
      "epoch": 0.9541177328762127,
      "grad_norm": 0.288499116897583,
      "learning_rate": 4.045882267123787e-05,
      "loss": 0.0052,
      "step": 13080
    },
    {
      "epoch": 0.954847180684222,
      "grad_norm": 0.08657389879226685,
      "learning_rate": 4.045152819315779e-05,
      "loss": 0.0052,
      "step": 13090
    },
    {
      "epoch": 0.9555766284922314,
      "grad_norm": 0.40404608845710754,
      "learning_rate": 4.044423371507769e-05,
      "loss": 0.0065,
      "step": 13100
    },
    {
      "epoch": 0.9563060763002407,
      "grad_norm": 0.6346738934516907,
      "learning_rate": 4.0436939236997595e-05,
      "loss": 0.0069,
      "step": 13110
    },
    {
      "epoch": 0.9570355241082501,
      "grad_norm": 0.08658743649721146,
      "learning_rate": 4.04296447589175e-05,
      "loss": 0.0061,
      "step": 13120
    },
    {
      "epoch": 0.9577649719162594,
      "grad_norm": 0.43436864018440247,
      "learning_rate": 4.04223502808374e-05,
      "loss": 0.0049,
      "step": 13130
    },
    {
      "epoch": 0.9584944197242687,
      "grad_norm": 0.11526884883642197,
      "learning_rate": 4.041505580275731e-05,
      "loss": 0.0043,
      "step": 13140
    },
    {
      "epoch": 0.9592238675322781,
      "grad_norm": 0.11614113301038742,
      "learning_rate": 4.0407761324677225e-05,
      "loss": 0.004,
      "step": 13150
    },
    {
      "epoch": 0.9599533153402874,
      "grad_norm": 0.34862178564071655,
      "learning_rate": 4.0400466846597126e-05,
      "loss": 0.0033,
      "step": 13160
    },
    {
      "epoch": 0.9606827631482967,
      "grad_norm": 0.4897114932537079,
      "learning_rate": 4.0393172368517033e-05,
      "loss": 0.0039,
      "step": 13170
    },
    {
      "epoch": 0.961412210956306,
      "grad_norm": 0.2019156664609909,
      "learning_rate": 4.038587789043694e-05,
      "loss": 0.0044,
      "step": 13180
    },
    {
      "epoch": 0.9621416587643155,
      "grad_norm": 0.3151674270629883,
      "learning_rate": 4.037858341235685e-05,
      "loss": 0.0056,
      "step": 13190
    },
    {
      "epoch": 0.9628711065723248,
      "grad_norm": 0.34743914008140564,
      "learning_rate": 4.037128893427675e-05,
      "loss": 0.0059,
      "step": 13200
    },
    {
      "epoch": 0.9636005543803341,
      "grad_norm": 0.26004868745803833,
      "learning_rate": 4.0363994456196664e-05,
      "loss": 0.0063,
      "step": 13210
    },
    {
      "epoch": 0.9643300021883434,
      "grad_norm": 0.35133931040763855,
      "learning_rate": 4.035669997811657e-05,
      "loss": 0.0057,
      "step": 13220
    },
    {
      "epoch": 0.9650594499963527,
      "grad_norm": 0.2881801128387451,
      "learning_rate": 4.034940550003647e-05,
      "loss": 0.0055,
      "step": 13230
    },
    {
      "epoch": 0.9657888978043621,
      "grad_norm": 0.14435291290283203,
      "learning_rate": 4.034211102195638e-05,
      "loss": 0.0035,
      "step": 13240
    },
    {
      "epoch": 0.9665183456123715,
      "grad_norm": 0.030740927904844284,
      "learning_rate": 4.033481654387629e-05,
      "loss": 0.0063,
      "step": 13250
    },
    {
      "epoch": 0.9672477934203808,
      "grad_norm": 0.20173268020153046,
      "learning_rate": 4.0327522065796194e-05,
      "loss": 0.005,
      "step": 13260
    },
    {
      "epoch": 0.9679772412283901,
      "grad_norm": 0.11516120284795761,
      "learning_rate": 4.03202275877161e-05,
      "loss": 0.0049,
      "step": 13270
    },
    {
      "epoch": 0.9687066890363994,
      "grad_norm": 0.23100408911705017,
      "learning_rate": 4.031293310963601e-05,
      "loss": 0.0037,
      "step": 13280
    },
    {
      "epoch": 0.9694361368444088,
      "grad_norm": 0.5014379620552063,
      "learning_rate": 4.030563863155592e-05,
      "loss": 0.0037,
      "step": 13290
    },
    {
      "epoch": 0.9701655846524181,
      "grad_norm": 0.11543413996696472,
      "learning_rate": 4.029834415347582e-05,
      "loss": 0.0055,
      "step": 13300
    },
    {
      "epoch": 0.9708950324604274,
      "grad_norm": 0.4623764455318451,
      "learning_rate": 4.0291049675395725e-05,
      "loss": 0.0046,
      "step": 13310
    },
    {
      "epoch": 0.9716244802684368,
      "grad_norm": 0.23104432225227356,
      "learning_rate": 4.028375519731563e-05,
      "loss": 0.0059,
      "step": 13320
    },
    {
      "epoch": 0.9723539280764462,
      "grad_norm": 0.010973812080919743,
      "learning_rate": 4.027646071923554e-05,
      "loss": 0.0061,
      "step": 13330
    },
    {
      "epoch": 0.9730833758844555,
      "grad_norm": 0.1745772808790207,
      "learning_rate": 4.026916624115545e-05,
      "loss": 0.0054,
      "step": 13340
    },
    {
      "epoch": 0.9738128236924648,
      "grad_norm": 0.28864091634750366,
      "learning_rate": 4.0261871763075355e-05,
      "loss": 0.0064,
      "step": 13350
    },
    {
      "epoch": 0.9745422715004741,
      "grad_norm": 0.4625210762023926,
      "learning_rate": 4.0254577284995256e-05,
      "loss": 0.0042,
      "step": 13360
    },
    {
      "epoch": 0.9752717193084834,
      "grad_norm": 0.6062718629837036,
      "learning_rate": 4.0247282806915164e-05,
      "loss": 0.0052,
      "step": 13370
    },
    {
      "epoch": 0.9760011671164928,
      "grad_norm": 0.23099422454833984,
      "learning_rate": 4.023998832883508e-05,
      "loss": 0.006,
      "step": 13380
    },
    {
      "epoch": 0.9767306149245022,
      "grad_norm": 0.9318392872810364,
      "learning_rate": 4.0232693850754986e-05,
      "loss": 0.0054,
      "step": 13390
    },
    {
      "epoch": 0.9774600627325115,
      "grad_norm": 0.12328556925058365,
      "learning_rate": 4.0225399372674886e-05,
      "loss": 0.0061,
      "step": 13400
    },
    {
      "epoch": 0.9781895105405208,
      "grad_norm": 0.14449653029441833,
      "learning_rate": 4.0218104894594794e-05,
      "loss": 0.0051,
      "step": 13410
    },
    {
      "epoch": 0.9789189583485302,
      "grad_norm": 0.07983340322971344,
      "learning_rate": 4.02108104165147e-05,
      "loss": 0.005,
      "step": 13420
    },
    {
      "epoch": 0.9796484061565395,
      "grad_norm": 0.007401023991405964,
      "learning_rate": 4.02035159384346e-05,
      "loss": 0.0062,
      "step": 13430
    },
    {
      "epoch": 0.9803778539645488,
      "grad_norm": 0.08801156282424927,
      "learning_rate": 4.0196221460354516e-05,
      "loss": 0.0031,
      "step": 13440
    },
    {
      "epoch": 0.9811073017725582,
      "grad_norm": 0.3717462420463562,
      "learning_rate": 4.0188926982274424e-05,
      "loss": 0.0052,
      "step": 13450
    },
    {
      "epoch": 0.9818367495805675,
      "grad_norm": 0.17316441237926483,
      "learning_rate": 4.0181632504194325e-05,
      "loss": 0.0051,
      "step": 13460
    },
    {
      "epoch": 0.9825661973885769,
      "grad_norm": 0.17289279401302338,
      "learning_rate": 4.017433802611423e-05,
      "loss": 0.0066,
      "step": 13470
    },
    {
      "epoch": 0.9832956451965862,
      "grad_norm": 0.031056160107254982,
      "learning_rate": 4.016704354803414e-05,
      "loss": 0.0049,
      "step": 13480
    },
    {
      "epoch": 0.9840250930045955,
      "grad_norm": 0.006870427634567022,
      "learning_rate": 4.015974906995405e-05,
      "loss": 0.0048,
      "step": 13490
    },
    {
      "epoch": 0.9847545408126048,
      "grad_norm": 0.11562900245189667,
      "learning_rate": 4.0152454591873955e-05,
      "loss": 0.0053,
      "step": 13500
    },
    {
      "epoch": 0.9854839886206141,
      "grad_norm": 0.23025380074977875,
      "learning_rate": 4.014516011379386e-05,
      "loss": 0.0053,
      "step": 13510
    },
    {
      "epoch": 0.9862134364286236,
      "grad_norm": 0.030570199713110924,
      "learning_rate": 4.013786563571377e-05,
      "loss": 0.0043,
      "step": 13520
    },
    {
      "epoch": 0.9869428842366329,
      "grad_norm": 0.030434807762503624,
      "learning_rate": 4.013057115763367e-05,
      "loss": 0.0059,
      "step": 13530
    },
    {
      "epoch": 0.9876723320446422,
      "grad_norm": 0.28827908635139465,
      "learning_rate": 4.012327667955358e-05,
      "loss": 0.0034,
      "step": 13540
    },
    {
      "epoch": 0.9884017798526515,
      "grad_norm": 0.17297160625457764,
      "learning_rate": 4.0115982201473486e-05,
      "loss": 0.006,
      "step": 13550
    },
    {
      "epoch": 0.9891312276606609,
      "grad_norm": 0.13162165880203247,
      "learning_rate": 4.010868772339339e-05,
      "loss": 0.0037,
      "step": 13560
    },
    {
      "epoch": 0.9898606754686702,
      "grad_norm": 0.43632498383522034,
      "learning_rate": 4.01013932453133e-05,
      "loss": 0.007,
      "step": 13570
    },
    {
      "epoch": 0.9905901232766795,
      "grad_norm": 0.08728551119565964,
      "learning_rate": 4.009409876723321e-05,
      "loss": 0.0057,
      "step": 13580
    },
    {
      "epoch": 0.9913195710846889,
      "grad_norm": 0.03455674648284912,
      "learning_rate": 4.0086804289153116e-05,
      "loss": 0.0055,
      "step": 13590
    },
    {
      "epoch": 0.9920490188926983,
      "grad_norm": 0.1939491331577301,
      "learning_rate": 4.007950981107302e-05,
      "loss": 0.0039,
      "step": 13600
    },
    {
      "epoch": 0.9927784667007076,
      "grad_norm": 0.16309843957424164,
      "learning_rate": 4.0072215332992924e-05,
      "loss": 0.0069,
      "step": 13610
    },
    {
      "epoch": 0.9935079145087169,
      "grad_norm": 0.029715079814195633,
      "learning_rate": 4.006492085491284e-05,
      "loss": 0.0056,
      "step": 13620
    },
    {
      "epoch": 0.9942373623167262,
      "grad_norm": 0.28929242491722107,
      "learning_rate": 4.005762637683274e-05,
      "loss": 0.0055,
      "step": 13630
    },
    {
      "epoch": 0.9949668101247355,
      "grad_norm": 0.05784842371940613,
      "learning_rate": 4.005033189875265e-05,
      "loss": 0.0039,
      "step": 13640
    },
    {
      "epoch": 0.995696257932745,
      "grad_norm": 0.20919063687324524,
      "learning_rate": 4.0043037420672554e-05,
      "loss": 0.0052,
      "step": 13650
    },
    {
      "epoch": 0.9964257057407543,
      "grad_norm": 0.24049502611160278,
      "learning_rate": 4.0035742942592455e-05,
      "loss": 0.004,
      "step": 13660
    },
    {
      "epoch": 0.9971551535487636,
      "grad_norm": 0.1445055454969406,
      "learning_rate": 4.002844846451236e-05,
      "loss": 0.0057,
      "step": 13670
    },
    {
      "epoch": 0.9978846013567729,
      "grad_norm": 0.1848410815000534,
      "learning_rate": 4.002115398643228e-05,
      "loss": 0.0054,
      "step": 13680
    },
    {
      "epoch": 0.9986140491647822,
      "grad_norm": 0.2879939675331116,
      "learning_rate": 4.001385950835218e-05,
      "loss": 0.0049,
      "step": 13690
    },
    {
      "epoch": 0.9993434969727916,
      "grad_norm": 0.052971914410591125,
      "learning_rate": 4.0006565030272085e-05,
      "loss": 0.005,
      "step": 13700
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.004848572891205549,
      "eval_runtime": 121.1171,
      "eval_samples_per_second": 1154.057,
      "eval_steps_per_second": 28.856,
      "step": 13709
    },
    {
      "epoch": 1.000072944780801,
      "grad_norm": 0.4796831011772156,
      "learning_rate": 3.999927055219199e-05,
      "loss": 0.0071,
      "step": 13710
    },
    {
      "epoch": 1.0008023925888103,
      "grad_norm": 0.29228702187538147,
      "learning_rate": 3.99919760741119e-05,
      "loss": 0.0052,
      "step": 13720
    },
    {
      "epoch": 1.0015318403968196,
      "grad_norm": 0.08753100037574768,
      "learning_rate": 3.99846815960318e-05,
      "loss": 0.006,
      "step": 13730
    },
    {
      "epoch": 1.002261288204829,
      "grad_norm": 0.3172089457511902,
      "learning_rate": 3.9977387117951715e-05,
      "loss": 0.004,
      "step": 13740
    },
    {
      "epoch": 1.0029907360128383,
      "grad_norm": 0.6654368042945862,
      "learning_rate": 3.997009263987162e-05,
      "loss": 0.0064,
      "step": 13750
    },
    {
      "epoch": 1.0037201838208476,
      "grad_norm": 0.23126035928726196,
      "learning_rate": 3.9962798161791524e-05,
      "loss": 0.0053,
      "step": 13760
    },
    {
      "epoch": 1.004449631628857,
      "grad_norm": 0.1443922370672226,
      "learning_rate": 3.995550368371143e-05,
      "loss": 0.0068,
      "step": 13770
    },
    {
      "epoch": 1.0051790794368662,
      "grad_norm": 0.4627682566642761,
      "learning_rate": 3.994820920563134e-05,
      "loss": 0.0055,
      "step": 13780
    },
    {
      "epoch": 1.0059085272448756,
      "grad_norm": 0.2608116865158081,
      "learning_rate": 3.9940914727551246e-05,
      "loss": 0.0049,
      "step": 13790
    },
    {
      "epoch": 1.0066379750528849,
      "grad_norm": 0.34722045063972473,
      "learning_rate": 3.9933620249471154e-05,
      "loss": 0.0049,
      "step": 13800
    },
    {
      "epoch": 1.0073674228608942,
      "grad_norm": 0.519966185092926,
      "learning_rate": 3.992632577139106e-05,
      "loss": 0.0058,
      "step": 13810
    },
    {
      "epoch": 1.0080968706689037,
      "grad_norm": 0.5874736905097961,
      "learning_rate": 3.991903129331097e-05,
      "loss": 0.0081,
      "step": 13820
    },
    {
      "epoch": 1.008826318476913,
      "grad_norm": 0.21788620948791504,
      "learning_rate": 3.991173681523087e-05,
      "loss": 0.0044,
      "step": 13830
    },
    {
      "epoch": 1.0095557662849224,
      "grad_norm": 0.37455663084983826,
      "learning_rate": 3.990444233715078e-05,
      "loss": 0.0039,
      "step": 13840
    },
    {
      "epoch": 1.0102852140929317,
      "grad_norm": 0.1161138191819191,
      "learning_rate": 3.9897147859070685e-05,
      "loss": 0.0049,
      "step": 13850
    },
    {
      "epoch": 1.011014661900941,
      "grad_norm": 0.232145756483078,
      "learning_rate": 3.988985338099059e-05,
      "loss": 0.0045,
      "step": 13860
    },
    {
      "epoch": 1.0117441097089503,
      "grad_norm": 0.06057196483016014,
      "learning_rate": 3.98825589029105e-05,
      "loss": 0.0051,
      "step": 13870
    },
    {
      "epoch": 1.0124735575169597,
      "grad_norm": 0.1459464430809021,
      "learning_rate": 3.987526442483041e-05,
      "loss": 0.0042,
      "step": 13880
    },
    {
      "epoch": 1.013203005324969,
      "grad_norm": 0.2309579998254776,
      "learning_rate": 3.986796994675031e-05,
      "loss": 0.005,
      "step": 13890
    },
    {
      "epoch": 1.0139324531329783,
      "grad_norm": 0.4743829369544983,
      "learning_rate": 3.9860675468670215e-05,
      "loss": 0.0046,
      "step": 13900
    },
    {
      "epoch": 1.0146619009409876,
      "grad_norm": 0.23246948421001434,
      "learning_rate": 3.985338099059013e-05,
      "loss": 0.0055,
      "step": 13910
    },
    {
      "epoch": 1.015391348748997,
      "grad_norm": 0.17398810386657715,
      "learning_rate": 3.984608651251003e-05,
      "loss": 0.0036,
      "step": 13920
    },
    {
      "epoch": 1.0161207965570063,
      "grad_norm": 0.02891395427286625,
      "learning_rate": 3.983879203442994e-05,
      "loss": 0.0064,
      "step": 13930
    },
    {
      "epoch": 1.0168502443650156,
      "grad_norm": 0.23845075070858002,
      "learning_rate": 3.9831497556349846e-05,
      "loss": 0.0049,
      "step": 13940
    },
    {
      "epoch": 1.0175796921730251,
      "grad_norm": 0.20248928666114807,
      "learning_rate": 3.982420307826975e-05,
      "loss": 0.0046,
      "step": 13950
    },
    {
      "epoch": 1.0183091399810345,
      "grad_norm": 0.030378863215446472,
      "learning_rate": 3.9816908600189654e-05,
      "loss": 0.0064,
      "step": 13960
    },
    {
      "epoch": 1.0190385877890438,
      "grad_norm": 0.2890680134296417,
      "learning_rate": 3.980961412210957e-05,
      "loss": 0.0056,
      "step": 13970
    },
    {
      "epoch": 1.019768035597053,
      "grad_norm": 0.11579164117574692,
      "learning_rate": 3.9802319644029476e-05,
      "loss": 0.005,
      "step": 13980
    },
    {
      "epoch": 1.0204974834050624,
      "grad_norm": 0.17376871407032013,
      "learning_rate": 3.9795025165949376e-05,
      "loss": 0.0054,
      "step": 13990
    },
    {
      "epoch": 1.0212269312130717,
      "grad_norm": 0.2060980349779129,
      "learning_rate": 3.9787730687869284e-05,
      "loss": 0.0065,
      "step": 14000
    },
    {
      "epoch": 1.021956379021081,
      "grad_norm": 0.28876543045043945,
      "learning_rate": 3.978043620978919e-05,
      "loss": 0.006,
      "step": 14010
    },
    {
      "epoch": 1.0226858268290904,
      "grad_norm": 0.11564546823501587,
      "learning_rate": 3.97731417317091e-05,
      "loss": 0.0064,
      "step": 14020
    },
    {
      "epoch": 1.0234152746370997,
      "grad_norm": 0.2598797678947449,
      "learning_rate": 3.9765847253629007e-05,
      "loss": 0.0051,
      "step": 14030
    },
    {
      "epoch": 1.024144722445109,
      "grad_norm": 0.23331084847450256,
      "learning_rate": 3.9758552775548914e-05,
      "loss": 0.0045,
      "step": 14040
    },
    {
      "epoch": 1.0248741702531183,
      "grad_norm": 0.2888878583908081,
      "learning_rate": 3.975125829746882e-05,
      "loss": 0.0052,
      "step": 14050
    },
    {
      "epoch": 1.0256036180611277,
      "grad_norm": 0.032457537949085236,
      "learning_rate": 3.974396381938872e-05,
      "loss": 0.004,
      "step": 14060
    },
    {
      "epoch": 1.026333065869137,
      "grad_norm": 0.5299186706542969,
      "learning_rate": 3.973666934130863e-05,
      "loss": 0.0067,
      "step": 14070
    },
    {
      "epoch": 1.0270625136771463,
      "grad_norm": 0.2885158956050873,
      "learning_rate": 3.972937486322854e-05,
      "loss": 0.0048,
      "step": 14080
    },
    {
      "epoch": 1.0277919614851558,
      "grad_norm": 0.5233768224716187,
      "learning_rate": 3.9722080385148445e-05,
      "loss": 0.0044,
      "step": 14090
    },
    {
      "epoch": 1.0285214092931652,
      "grad_norm": 0.11616170406341553,
      "learning_rate": 3.971478590706835e-05,
      "loss": 0.0056,
      "step": 14100
    },
    {
      "epoch": 1.0292508571011745,
      "grad_norm": 0.28875046968460083,
      "learning_rate": 3.970749142898826e-05,
      "loss": 0.0057,
      "step": 14110
    },
    {
      "epoch": 1.0299803049091838,
      "grad_norm": 0.1734880805015564,
      "learning_rate": 3.970019695090816e-05,
      "loss": 0.0056,
      "step": 14120
    },
    {
      "epoch": 1.0307097527171931,
      "grad_norm": 0.030020596459507942,
      "learning_rate": 3.969290247282807e-05,
      "loss": 0.0043,
      "step": 14130
    },
    {
      "epoch": 1.0314392005252024,
      "grad_norm": 0.12868475914001465,
      "learning_rate": 3.9685607994747976e-05,
      "loss": 0.0052,
      "step": 14140
    },
    {
      "epoch": 1.0321686483332118,
      "grad_norm": 0.260868102312088,
      "learning_rate": 3.967831351666788e-05,
      "loss": 0.0044,
      "step": 14150
    },
    {
      "epoch": 1.032898096141221,
      "grad_norm": 0.3685765266418457,
      "learning_rate": 3.967101903858779e-05,
      "loss": 0.0045,
      "step": 14160
    },
    {
      "epoch": 1.0336275439492304,
      "grad_norm": 0.11606550961732864,
      "learning_rate": 3.96637245605077e-05,
      "loss": 0.005,
      "step": 14170
    },
    {
      "epoch": 1.0343569917572397,
      "grad_norm": 0.26044759154319763,
      "learning_rate": 3.9656430082427606e-05,
      "loss": 0.0044,
      "step": 14180
    },
    {
      "epoch": 1.035086439565249,
      "grad_norm": 0.3926249146461487,
      "learning_rate": 3.964913560434751e-05,
      "loss": 0.0054,
      "step": 14190
    },
    {
      "epoch": 1.0358158873732584,
      "grad_norm": 0.1216622143983841,
      "learning_rate": 3.9641841126267414e-05,
      "loss": 0.003,
      "step": 14200
    },
    {
      "epoch": 1.0365453351812677,
      "grad_norm": 0.3124254047870636,
      "learning_rate": 3.963454664818733e-05,
      "loss": 0.0043,
      "step": 14210
    },
    {
      "epoch": 1.0372747829892772,
      "grad_norm": 0.11661537736654282,
      "learning_rate": 3.962725217010723e-05,
      "loss": 0.005,
      "step": 14220
    },
    {
      "epoch": 1.0380042307972865,
      "grad_norm": 0.37584346532821655,
      "learning_rate": 3.961995769202714e-05,
      "loss": 0.0051,
      "step": 14230
    },
    {
      "epoch": 1.0387336786052959,
      "grad_norm": 0.3471139669418335,
      "learning_rate": 3.9612663213947044e-05,
      "loss": 0.0024,
      "step": 14240
    },
    {
      "epoch": 1.0394631264133052,
      "grad_norm": 0.09802159667015076,
      "learning_rate": 3.960536873586695e-05,
      "loss": 0.0057,
      "step": 14250
    },
    {
      "epoch": 1.0401925742213145,
      "grad_norm": 0.09107627719640732,
      "learning_rate": 3.959807425778685e-05,
      "loss": 0.0045,
      "step": 14260
    },
    {
      "epoch": 1.0409220220293238,
      "grad_norm": 0.2321818470954895,
      "learning_rate": 3.959077977970677e-05,
      "loss": 0.0036,
      "step": 14270
    },
    {
      "epoch": 1.0416514698373331,
      "grad_norm": 0.28940534591674805,
      "learning_rate": 3.9583485301626674e-05,
      "loss": 0.0072,
      "step": 14280
    },
    {
      "epoch": 1.0423809176453425,
      "grad_norm": 0.3179081380367279,
      "learning_rate": 3.9576190823546575e-05,
      "loss": 0.0044,
      "step": 14290
    },
    {
      "epoch": 1.0431103654533518,
      "grad_norm": 0.34607940912246704,
      "learning_rate": 3.956889634546648e-05,
      "loss": 0.0052,
      "step": 14300
    },
    {
      "epoch": 1.043839813261361,
      "grad_norm": 0.14612998068332672,
      "learning_rate": 3.956160186738639e-05,
      "loss": 0.0059,
      "step": 14310
    },
    {
      "epoch": 1.0445692610693704,
      "grad_norm": 0.378724604845047,
      "learning_rate": 3.955430738930629e-05,
      "loss": 0.0044,
      "step": 14320
    },
    {
      "epoch": 1.0452987088773797,
      "grad_norm": 0.6634921431541443,
      "learning_rate": 3.9547012911226205e-05,
      "loss": 0.0044,
      "step": 14330
    },
    {
      "epoch": 1.046028156685389,
      "grad_norm": 0.02990896999835968,
      "learning_rate": 3.953971843314611e-05,
      "loss": 0.0043,
      "step": 14340
    },
    {
      "epoch": 1.0467576044933984,
      "grad_norm": 0.1356043964624405,
      "learning_rate": 3.9532423955066014e-05,
      "loss": 0.0046,
      "step": 14350
    },
    {
      "epoch": 1.047487052301408,
      "grad_norm": 0.058661799877882004,
      "learning_rate": 3.952512947698592e-05,
      "loss": 0.0044,
      "step": 14360
    },
    {
      "epoch": 1.0482165001094172,
      "grad_norm": 0.17373013496398926,
      "learning_rate": 3.951783499890583e-05,
      "loss": 0.0048,
      "step": 14370
    },
    {
      "epoch": 1.0489459479174266,
      "grad_norm": 0.058754950761795044,
      "learning_rate": 3.9510540520825736e-05,
      "loss": 0.004,
      "step": 14380
    },
    {
      "epoch": 1.049675395725436,
      "grad_norm": 0.22081510722637177,
      "learning_rate": 3.9503246042745644e-05,
      "loss": 0.0048,
      "step": 14390
    },
    {
      "epoch": 1.0504048435334452,
      "grad_norm": 0.11623303592205048,
      "learning_rate": 3.949595156466555e-05,
      "loss": 0.0053,
      "step": 14400
    },
    {
      "epoch": 1.0511342913414545,
      "grad_norm": 0.2590104937553406,
      "learning_rate": 3.948865708658546e-05,
      "loss": 0.0048,
      "step": 14410
    },
    {
      "epoch": 1.0518637391494638,
      "grad_norm": 0.41454625129699707,
      "learning_rate": 3.948136260850536e-05,
      "loss": 0.0055,
      "step": 14420
    },
    {
      "epoch": 1.0525931869574732,
      "grad_norm": 0.7785895466804504,
      "learning_rate": 3.947406813042527e-05,
      "loss": 0.0052,
      "step": 14430
    },
    {
      "epoch": 1.0533226347654825,
      "grad_norm": 0.26055023074150085,
      "learning_rate": 3.946677365234518e-05,
      "loss": 0.006,
      "step": 14440
    },
    {
      "epoch": 1.0540520825734918,
      "grad_norm": 0.12198054790496826,
      "learning_rate": 3.945947917426508e-05,
      "loss": 0.0044,
      "step": 14450
    },
    {
      "epoch": 1.0547815303815011,
      "grad_norm": 0.0651610791683197,
      "learning_rate": 3.945218469618499e-05,
      "loss": 0.0056,
      "step": 14460
    },
    {
      "epoch": 1.0555109781895105,
      "grad_norm": 0.0795387476682663,
      "learning_rate": 3.94448902181049e-05,
      "loss": 0.0054,
      "step": 14470
    },
    {
      "epoch": 1.0562404259975198,
      "grad_norm": 0.37360453605651855,
      "learning_rate": 3.9437595740024805e-05,
      "loss": 0.0038,
      "step": 14480
    },
    {
      "epoch": 1.0569698738055293,
      "grad_norm": 0.11563988029956818,
      "learning_rate": 3.9430301261944705e-05,
      "loss": 0.0057,
      "step": 14490
    },
    {
      "epoch": 1.0576993216135386,
      "grad_norm": 0.25148630142211914,
      "learning_rate": 3.942300678386462e-05,
      "loss": 0.0051,
      "step": 14500
    },
    {
      "epoch": 1.058428769421548,
      "grad_norm": 0.4048636257648468,
      "learning_rate": 3.941571230578453e-05,
      "loss": 0.0044,
      "step": 14510
    },
    {
      "epoch": 1.0591582172295573,
      "grad_norm": 0.0058111222460865974,
      "learning_rate": 3.940841782770443e-05,
      "loss": 0.0044,
      "step": 14520
    },
    {
      "epoch": 1.0598876650375666,
      "grad_norm": 0.19669531285762787,
      "learning_rate": 3.9401123349624336e-05,
      "loss": 0.0045,
      "step": 14530
    },
    {
      "epoch": 1.060617112845576,
      "grad_norm": 0.08264431357383728,
      "learning_rate": 3.939382887154424e-05,
      "loss": 0.0067,
      "step": 14540
    },
    {
      "epoch": 1.0613465606535852,
      "grad_norm": 0.021190375089645386,
      "learning_rate": 3.938653439346415e-05,
      "loss": 0.0042,
      "step": 14550
    },
    {
      "epoch": 1.0620760084615946,
      "grad_norm": 0.25982826948165894,
      "learning_rate": 3.937923991538406e-05,
      "loss": 0.0056,
      "step": 14560
    },
    {
      "epoch": 1.0628054562696039,
      "grad_norm": 0.05798377841711044,
      "learning_rate": 3.9371945437303966e-05,
      "loss": 0.0039,
      "step": 14570
    },
    {
      "epoch": 1.0635349040776132,
      "grad_norm": 0.030281124636530876,
      "learning_rate": 3.936465095922387e-05,
      "loss": 0.0052,
      "step": 14580
    },
    {
      "epoch": 1.0642643518856225,
      "grad_norm": 0.011444108560681343,
      "learning_rate": 3.9357356481143774e-05,
      "loss": 0.006,
      "step": 14590
    },
    {
      "epoch": 1.0649937996936318,
      "grad_norm": 0.11585968732833862,
      "learning_rate": 3.935006200306368e-05,
      "loss": 0.005,
      "step": 14600
    },
    {
      "epoch": 1.0657232475016412,
      "grad_norm": 0.11701953411102295,
      "learning_rate": 3.934276752498359e-05,
      "loss": 0.0053,
      "step": 14610
    },
    {
      "epoch": 1.0664526953096507,
      "grad_norm": 0.2892090082168579,
      "learning_rate": 3.9335473046903497e-05,
      "loss": 0.0037,
      "step": 14620
    },
    {
      "epoch": 1.06718214311766,
      "grad_norm": 0.46322503685951233,
      "learning_rate": 3.9328178568823404e-05,
      "loss": 0.0055,
      "step": 14630
    },
    {
      "epoch": 1.0679115909256693,
      "grad_norm": 0.03105599619448185,
      "learning_rate": 3.932088409074331e-05,
      "loss": 0.0042,
      "step": 14640
    },
    {
      "epoch": 1.0686410387336787,
      "grad_norm": 0.05250869318842888,
      "learning_rate": 3.931358961266321e-05,
      "loss": 0.0058,
      "step": 14650
    },
    {
      "epoch": 1.069370486541688,
      "grad_norm": 0.2887037992477417,
      "learning_rate": 3.930629513458312e-05,
      "loss": 0.0044,
      "step": 14660
    },
    {
      "epoch": 1.0700999343496973,
      "grad_norm": 0.20134009420871735,
      "learning_rate": 3.929900065650303e-05,
      "loss": 0.0059,
      "step": 14670
    },
    {
      "epoch": 1.0708293821577066,
      "grad_norm": 0.23170095682144165,
      "learning_rate": 3.9291706178422935e-05,
      "loss": 0.0051,
      "step": 14680
    },
    {
      "epoch": 1.071558829965716,
      "grad_norm": 0.14885087311267853,
      "learning_rate": 3.928441170034284e-05,
      "loss": 0.0036,
      "step": 14690
    },
    {
      "epoch": 1.0722882777737253,
      "grad_norm": 0.37541621923446655,
      "learning_rate": 3.927711722226275e-05,
      "loss": 0.0048,
      "step": 14700
    },
    {
      "epoch": 1.0730177255817346,
      "grad_norm": 0.44796350598335266,
      "learning_rate": 3.926982274418266e-05,
      "loss": 0.0028,
      "step": 14710
    },
    {
      "epoch": 1.073747173389744,
      "grad_norm": 0.11564300209283829,
      "learning_rate": 3.926252826610256e-05,
      "loss": 0.0037,
      "step": 14720
    },
    {
      "epoch": 1.0744766211977532,
      "grad_norm": 0.3564438223838806,
      "learning_rate": 3.9255233788022466e-05,
      "loss": 0.0066,
      "step": 14730
    },
    {
      "epoch": 1.0752060690057625,
      "grad_norm": 0.2808142900466919,
      "learning_rate": 3.924793930994238e-05,
      "loss": 0.0061,
      "step": 14740
    },
    {
      "epoch": 1.075935516813772,
      "grad_norm": 0.17300227284431458,
      "learning_rate": 3.924064483186228e-05,
      "loss": 0.0054,
      "step": 14750
    },
    {
      "epoch": 1.0766649646217814,
      "grad_norm": 0.404072105884552,
      "learning_rate": 3.923335035378219e-05,
      "loss": 0.0066,
      "step": 14760
    },
    {
      "epoch": 1.0773944124297907,
      "grad_norm": 0.17369619011878967,
      "learning_rate": 3.9226055875702096e-05,
      "loss": 0.0042,
      "step": 14770
    },
    {
      "epoch": 1.0781238602378,
      "grad_norm": 0.37560901045799255,
      "learning_rate": 3.9218761397622004e-05,
      "loss": 0.0043,
      "step": 14780
    },
    {
      "epoch": 1.0788533080458094,
      "grad_norm": 0.029918629676103592,
      "learning_rate": 3.9211466919541904e-05,
      "loss": 0.0045,
      "step": 14790
    },
    {
      "epoch": 1.0795827558538187,
      "grad_norm": 0.11501261591911316,
      "learning_rate": 3.920417244146182e-05,
      "loss": 0.0034,
      "step": 14800
    },
    {
      "epoch": 1.080312203661828,
      "grad_norm": 0.20256313681602478,
      "learning_rate": 3.9196877963381726e-05,
      "loss": 0.0045,
      "step": 14810
    },
    {
      "epoch": 1.0810416514698373,
      "grad_norm": 0.1157507449388504,
      "learning_rate": 3.918958348530163e-05,
      "loss": 0.0052,
      "step": 14820
    },
    {
      "epoch": 1.0817710992778466,
      "grad_norm": 0.34664443135261536,
      "learning_rate": 3.9182289007221534e-05,
      "loss": 0.0048,
      "step": 14830
    },
    {
      "epoch": 1.082500547085856,
      "grad_norm": 0.37532344460487366,
      "learning_rate": 3.917499452914144e-05,
      "loss": 0.0027,
      "step": 14840
    },
    {
      "epoch": 1.0832299948938653,
      "grad_norm": 0.058384038507938385,
      "learning_rate": 3.916770005106135e-05,
      "loss": 0.0041,
      "step": 14850
    },
    {
      "epoch": 1.0839594427018746,
      "grad_norm": 0.02967608906328678,
      "learning_rate": 3.916040557298126e-05,
      "loss": 0.004,
      "step": 14860
    },
    {
      "epoch": 1.084688890509884,
      "grad_norm": 0.5144779682159424,
      "learning_rate": 3.9153111094901164e-05,
      "loss": 0.0032,
      "step": 14870
    },
    {
      "epoch": 1.0854183383178935,
      "grad_norm": 0.4034239649772644,
      "learning_rate": 3.9145816616821065e-05,
      "loss": 0.0056,
      "step": 14880
    },
    {
      "epoch": 1.0861477861259028,
      "grad_norm": 0.14463356137275696,
      "learning_rate": 3.913852213874097e-05,
      "loss": 0.0053,
      "step": 14890
    },
    {
      "epoch": 1.0868772339339121,
      "grad_norm": 0.11583675444126129,
      "learning_rate": 3.913122766066088e-05,
      "loss": 0.0049,
      "step": 14900
    },
    {
      "epoch": 1.0876066817419214,
      "grad_norm": 0.11613800376653671,
      "learning_rate": 3.912393318258079e-05,
      "loss": 0.0048,
      "step": 14910
    },
    {
      "epoch": 1.0883361295499308,
      "grad_norm": 0.11498857289552689,
      "learning_rate": 3.9116638704500695e-05,
      "loss": 0.0058,
      "step": 14920
    },
    {
      "epoch": 1.08906557735794,
      "grad_norm": 0.2883811593055725,
      "learning_rate": 3.91093442264206e-05,
      "loss": 0.0055,
      "step": 14930
    },
    {
      "epoch": 1.0897950251659494,
      "grad_norm": 0.013718891888856888,
      "learning_rate": 3.910204974834051e-05,
      "loss": 0.0046,
      "step": 14940
    },
    {
      "epoch": 1.0905244729739587,
      "grad_norm": 0.2598450183868408,
      "learning_rate": 3.909475527026041e-05,
      "loss": 0.0036,
      "step": 14950
    },
    {
      "epoch": 1.091253920781968,
      "grad_norm": 0.008095255121588707,
      "learning_rate": 3.908746079218032e-05,
      "loss": 0.0032,
      "step": 14960
    },
    {
      "epoch": 1.0919833685899774,
      "grad_norm": 0.21016687154769897,
      "learning_rate": 3.908016631410023e-05,
      "loss": 0.0029,
      "step": 14970
    },
    {
      "epoch": 1.0927128163979867,
      "grad_norm": 0.058158498257398605,
      "learning_rate": 3.9072871836020134e-05,
      "loss": 0.0046,
      "step": 14980
    },
    {
      "epoch": 1.093442264205996,
      "grad_norm": 0.5832808613777161,
      "learning_rate": 3.906557735794004e-05,
      "loss": 0.0054,
      "step": 14990
    },
    {
      "epoch": 1.0941717120140053,
      "grad_norm": 0.26016491651535034,
      "learning_rate": 3.905828287985995e-05,
      "loss": 0.0044,
      "step": 15000
    },
    {
      "epoch": 1.0949011598220146,
      "grad_norm": 0.2317316234111786,
      "learning_rate": 3.9050988401779856e-05,
      "loss": 0.0043,
      "step": 15010
    },
    {
      "epoch": 1.095630607630024,
      "grad_norm": 0.4482985734939575,
      "learning_rate": 3.904369392369976e-05,
      "loss": 0.0058,
      "step": 15020
    },
    {
      "epoch": 1.0963600554380335,
      "grad_norm": 0.4913095235824585,
      "learning_rate": 3.903639944561967e-05,
      "loss": 0.0043,
      "step": 15030
    },
    {
      "epoch": 1.0970895032460428,
      "grad_norm": 0.23163087666034698,
      "learning_rate": 3.902910496753958e-05,
      "loss": 0.0063,
      "step": 15040
    },
    {
      "epoch": 1.0978189510540521,
      "grad_norm": 0.1554735153913498,
      "learning_rate": 3.902181048945948e-05,
      "loss": 0.0063,
      "step": 15050
    },
    {
      "epoch": 1.0985483988620615,
      "grad_norm": 0.08682004362344742,
      "learning_rate": 3.901451601137939e-05,
      "loss": 0.005,
      "step": 15060
    },
    {
      "epoch": 1.0992778466700708,
      "grad_norm": 0.46296027302742004,
      "learning_rate": 3.9007221533299295e-05,
      "loss": 0.0052,
      "step": 15070
    },
    {
      "epoch": 1.10000729447808,
      "grad_norm": 0.05827280133962631,
      "learning_rate": 3.8999927055219196e-05,
      "loss": 0.0057,
      "step": 15080
    },
    {
      "epoch": 1.1007367422860894,
      "grad_norm": 0.2883041799068451,
      "learning_rate": 3.899263257713911e-05,
      "loss": 0.0046,
      "step": 15090
    },
    {
      "epoch": 1.1014661900940987,
      "grad_norm": 0.11568260192871094,
      "learning_rate": 3.898533809905902e-05,
      "loss": 0.0056,
      "step": 15100
    },
    {
      "epoch": 1.102195637902108,
      "grad_norm": 0.28920137882232666,
      "learning_rate": 3.897804362097892e-05,
      "loss": 0.0064,
      "step": 15110
    },
    {
      "epoch": 1.1029250857101174,
      "grad_norm": 0.40516823530197144,
      "learning_rate": 3.8970749142898826e-05,
      "loss": 0.0077,
      "step": 15120
    },
    {
      "epoch": 1.1036545335181267,
      "grad_norm": 0.08788906037807465,
      "learning_rate": 3.896345466481873e-05,
      "loss": 0.0048,
      "step": 15130
    },
    {
      "epoch": 1.104383981326136,
      "grad_norm": 0.057704608887434006,
      "learning_rate": 3.895616018673864e-05,
      "loss": 0.0049,
      "step": 15140
    },
    {
      "epoch": 1.1051134291341453,
      "grad_norm": 0.3754155933856964,
      "learning_rate": 3.894886570865855e-05,
      "loss": 0.0049,
      "step": 15150
    },
    {
      "epoch": 1.1058428769421549,
      "grad_norm": 0.4038478136062622,
      "learning_rate": 3.8941571230578456e-05,
      "loss": 0.0049,
      "step": 15160
    },
    {
      "epoch": 1.1065723247501642,
      "grad_norm": 0.21513833105564117,
      "learning_rate": 3.893427675249836e-05,
      "loss": 0.0039,
      "step": 15170
    },
    {
      "epoch": 1.1073017725581735,
      "grad_norm": 0.17387539148330688,
      "learning_rate": 3.8926982274418264e-05,
      "loss": 0.0046,
      "step": 15180
    },
    {
      "epoch": 1.1080312203661828,
      "grad_norm": 0.08685147762298584,
      "learning_rate": 3.891968779633817e-05,
      "loss": 0.0041,
      "step": 15190
    },
    {
      "epoch": 1.1087606681741922,
      "grad_norm": 0.27371206879615784,
      "learning_rate": 3.891239331825808e-05,
      "loss": 0.0074,
      "step": 15200
    },
    {
      "epoch": 1.1094901159822015,
      "grad_norm": 0.15308959782123566,
      "learning_rate": 3.890509884017799e-05,
      "loss": 0.004,
      "step": 15210
    },
    {
      "epoch": 1.1102195637902108,
      "grad_norm": 0.25949522852897644,
      "learning_rate": 3.8897804362097894e-05,
      "loss": 0.0041,
      "step": 15220
    },
    {
      "epoch": 1.1109490115982201,
      "grad_norm": 0.11623197048902512,
      "learning_rate": 3.88905098840178e-05,
      "loss": 0.0044,
      "step": 15230
    },
    {
      "epoch": 1.1116784594062294,
      "grad_norm": 0.23179087042808533,
      "learning_rate": 3.888321540593771e-05,
      "loss": 0.004,
      "step": 15240
    },
    {
      "epoch": 1.1124079072142388,
      "grad_norm": 0.2427959144115448,
      "learning_rate": 3.887592092785761e-05,
      "loss": 0.0042,
      "step": 15250
    },
    {
      "epoch": 1.113137355022248,
      "grad_norm": 0.231095552444458,
      "learning_rate": 3.886862644977752e-05,
      "loss": 0.0044,
      "step": 15260
    },
    {
      "epoch": 1.1138668028302574,
      "grad_norm": 0.36528071761131287,
      "learning_rate": 3.886133197169743e-05,
      "loss": 0.0054,
      "step": 15270
    },
    {
      "epoch": 1.1145962506382667,
      "grad_norm": 0.05865795165300369,
      "learning_rate": 3.885403749361733e-05,
      "loss": 0.0042,
      "step": 15280
    },
    {
      "epoch": 1.1153256984462763,
      "grad_norm": 0.38883569836616516,
      "learning_rate": 3.884674301553724e-05,
      "loss": 0.0042,
      "step": 15290
    },
    {
      "epoch": 1.1160551462542856,
      "grad_norm": 0.02990398369729519,
      "learning_rate": 3.883944853745715e-05,
      "loss": 0.0043,
      "step": 15300
    },
    {
      "epoch": 1.116784594062295,
      "grad_norm": 0.3185557723045349,
      "learning_rate": 3.883215405937705e-05,
      "loss": 0.0036,
      "step": 15310
    },
    {
      "epoch": 1.1175140418703042,
      "grad_norm": 0.08726339787244797,
      "learning_rate": 3.8824859581296956e-05,
      "loss": 0.0047,
      "step": 15320
    },
    {
      "epoch": 1.1182434896783136,
      "grad_norm": 0.05893328785896301,
      "learning_rate": 3.881756510321687e-05,
      "loss": 0.0051,
      "step": 15330
    },
    {
      "epoch": 1.1189729374863229,
      "grad_norm": 0.4628414511680603,
      "learning_rate": 3.881027062513677e-05,
      "loss": 0.0046,
      "step": 15340
    },
    {
      "epoch": 1.1197023852943322,
      "grad_norm": 0.08691311627626419,
      "learning_rate": 3.880297614705668e-05,
      "loss": 0.0051,
      "step": 15350
    },
    {
      "epoch": 1.1204318331023415,
      "grad_norm": 0.17413243651390076,
      "learning_rate": 3.8795681668976586e-05,
      "loss": 0.0048,
      "step": 15360
    },
    {
      "epoch": 1.1211612809103508,
      "grad_norm": 0.5190390944480896,
      "learning_rate": 3.8788387190896494e-05,
      "loss": 0.0048,
      "step": 15370
    },
    {
      "epoch": 1.1218907287183602,
      "grad_norm": 0.16466861963272095,
      "learning_rate": 3.87810927128164e-05,
      "loss": 0.0033,
      "step": 15380
    },
    {
      "epoch": 1.1226201765263695,
      "grad_norm": 0.2415236383676529,
      "learning_rate": 3.877379823473631e-05,
      "loss": 0.0042,
      "step": 15390
    },
    {
      "epoch": 1.1233496243343788,
      "grad_norm": 0.12079446762800217,
      "learning_rate": 3.8766503756656216e-05,
      "loss": 0.0046,
      "step": 15400
    },
    {
      "epoch": 1.1240790721423881,
      "grad_norm": 0.20314708352088928,
      "learning_rate": 3.875920927857612e-05,
      "loss": 0.0044,
      "step": 15410
    },
    {
      "epoch": 1.1248085199503977,
      "grad_norm": 0.46877381205558777,
      "learning_rate": 3.8751914800496024e-05,
      "loss": 0.0046,
      "step": 15420
    },
    {
      "epoch": 1.125537967758407,
      "grad_norm": 0.279676616191864,
      "learning_rate": 3.874462032241593e-05,
      "loss": 0.0045,
      "step": 15430
    },
    {
      "epoch": 1.1262674155664163,
      "grad_norm": 0.20307891070842743,
      "learning_rate": 3.873732584433584e-05,
      "loss": 0.0043,
      "step": 15440
    },
    {
      "epoch": 1.1269968633744256,
      "grad_norm": 0.3470657467842102,
      "learning_rate": 3.873003136625575e-05,
      "loss": 0.003,
      "step": 15450
    },
    {
      "epoch": 1.127726311182435,
      "grad_norm": 0.08684737980365753,
      "learning_rate": 3.8722736888175655e-05,
      "loss": 0.0046,
      "step": 15460
    },
    {
      "epoch": 1.1284557589904443,
      "grad_norm": 0.23156167566776276,
      "learning_rate": 3.871544241009556e-05,
      "loss": 0.0028,
      "step": 15470
    },
    {
      "epoch": 1.1291852067984536,
      "grad_norm": 0.35328689217567444,
      "learning_rate": 3.870814793201546e-05,
      "loss": 0.003,
      "step": 15480
    },
    {
      "epoch": 1.129914654606463,
      "grad_norm": 0.02997835911810398,
      "learning_rate": 3.870085345393537e-05,
      "loss": 0.0041,
      "step": 15490
    },
    {
      "epoch": 1.1306441024144722,
      "grad_norm": 0.1155593991279602,
      "learning_rate": 3.8693558975855285e-05,
      "loss": 0.0056,
      "step": 15500
    },
    {
      "epoch": 1.1313735502224815,
      "grad_norm": 0.2893263101577759,
      "learning_rate": 3.8686264497775185e-05,
      "loss": 0.0051,
      "step": 15510
    },
    {
      "epoch": 1.1321029980304909,
      "grad_norm": 0.4464854598045349,
      "learning_rate": 3.867897001969509e-05,
      "loss": 0.0043,
      "step": 15520
    },
    {
      "epoch": 1.1328324458385002,
      "grad_norm": 0.058839939534664154,
      "learning_rate": 3.8671675541615e-05,
      "loss": 0.0057,
      "step": 15530
    },
    {
      "epoch": 1.1335618936465095,
      "grad_norm": 0.37565213441848755,
      "learning_rate": 3.866438106353491e-05,
      "loss": 0.0062,
      "step": 15540
    },
    {
      "epoch": 1.134291341454519,
      "grad_norm": 0.2887648642063141,
      "learning_rate": 3.865708658545481e-05,
      "loss": 0.0052,
      "step": 15550
    },
    {
      "epoch": 1.1350207892625284,
      "grad_norm": 0.11647626012563705,
      "learning_rate": 3.864979210737472e-05,
      "loss": 0.0052,
      "step": 15560
    },
    {
      "epoch": 1.1357502370705377,
      "grad_norm": 0.2028835266828537,
      "learning_rate": 3.864249762929463e-05,
      "loss": 0.0054,
      "step": 15570
    },
    {
      "epoch": 1.136479684878547,
      "grad_norm": 0.1152975782752037,
      "learning_rate": 3.863520315121453e-05,
      "loss": 0.0047,
      "step": 15580
    },
    {
      "epoch": 1.1372091326865563,
      "grad_norm": 0.09278456121683121,
      "learning_rate": 3.862790867313444e-05,
      "loss": 0.0045,
      "step": 15590
    },
    {
      "epoch": 1.1379385804945656,
      "grad_norm": 0.05977237969636917,
      "learning_rate": 3.8620614195054346e-05,
      "loss": 0.0045,
      "step": 15600
    },
    {
      "epoch": 1.138668028302575,
      "grad_norm": 0.2377433031797409,
      "learning_rate": 3.861331971697425e-05,
      "loss": 0.0058,
      "step": 15610
    },
    {
      "epoch": 1.1393974761105843,
      "grad_norm": 0.4835076928138733,
      "learning_rate": 3.860602523889416e-05,
      "loss": 0.0056,
      "step": 15620
    },
    {
      "epoch": 1.1401269239185936,
      "grad_norm": 0.2351282835006714,
      "learning_rate": 3.859873076081407e-05,
      "loss": 0.0061,
      "step": 15630
    },
    {
      "epoch": 1.140856371726603,
      "grad_norm": 0.17445312440395355,
      "learning_rate": 3.859143628273397e-05,
      "loss": 0.0048,
      "step": 15640
    },
    {
      "epoch": 1.1415858195346122,
      "grad_norm": 0.2606790363788605,
      "learning_rate": 3.858414180465388e-05,
      "loss": 0.0051,
      "step": 15650
    },
    {
      "epoch": 1.1423152673426216,
      "grad_norm": 0.008432980626821518,
      "learning_rate": 3.8576847326573785e-05,
      "loss": 0.0038,
      "step": 15660
    },
    {
      "epoch": 1.1430447151506309,
      "grad_norm": 0.2894836366176605,
      "learning_rate": 3.856955284849369e-05,
      "loss": 0.0039,
      "step": 15670
    },
    {
      "epoch": 1.1437741629586404,
      "grad_norm": 0.40611135959625244,
      "learning_rate": 3.85622583704136e-05,
      "loss": 0.0055,
      "step": 15680
    },
    {
      "epoch": 1.1445036107666495,
      "grad_norm": 0.14554248750209808,
      "learning_rate": 3.855496389233351e-05,
      "loss": 0.005,
      "step": 15690
    },
    {
      "epoch": 1.145233058574659,
      "grad_norm": 0.4882703721523285,
      "learning_rate": 3.8547669414253415e-05,
      "loss": 0.0052,
      "step": 15700
    },
    {
      "epoch": 1.1459625063826684,
      "grad_norm": 0.06244216859340668,
      "learning_rate": 3.8540374936173316e-05,
      "loss": 0.003,
      "step": 15710
    },
    {
      "epoch": 1.1466919541906777,
      "grad_norm": 0.4053556025028229,
      "learning_rate": 3.853308045809322e-05,
      "loss": 0.0047,
      "step": 15720
    },
    {
      "epoch": 1.147421401998687,
      "grad_norm": 0.2892219126224518,
      "learning_rate": 3.852578598001313e-05,
      "loss": 0.0058,
      "step": 15730
    },
    {
      "epoch": 1.1481508498066963,
      "grad_norm": 0.1742156445980072,
      "learning_rate": 3.851849150193304e-05,
      "loss": 0.0048,
      "step": 15740
    },
    {
      "epoch": 1.1488802976147057,
      "grad_norm": 0.2897249460220337,
      "learning_rate": 3.8511197023852946e-05,
      "loss": 0.0051,
      "step": 15750
    },
    {
      "epoch": 1.149609745422715,
      "grad_norm": 0.012548095546662807,
      "learning_rate": 3.850390254577285e-05,
      "loss": 0.0044,
      "step": 15760
    },
    {
      "epoch": 1.1503391932307243,
      "grad_norm": 0.40439051389694214,
      "learning_rate": 3.849660806769276e-05,
      "loss": 0.0045,
      "step": 15770
    },
    {
      "epoch": 1.1510686410387336,
      "grad_norm": 0.35641300678253174,
      "learning_rate": 3.848931358961266e-05,
      "loss": 0.0055,
      "step": 15780
    },
    {
      "epoch": 1.151798088846743,
      "grad_norm": 0.22019611299037933,
      "learning_rate": 3.848201911153257e-05,
      "loss": 0.0062,
      "step": 15790
    },
    {
      "epoch": 1.1525275366547523,
      "grad_norm": 0.20223522186279297,
      "learning_rate": 3.8474724633452483e-05,
      "loss": 0.005,
      "step": 15800
    },
    {
      "epoch": 1.1532569844627618,
      "grad_norm": 0.05888588726520538,
      "learning_rate": 3.8467430155372384e-05,
      "loss": 0.0042,
      "step": 15810
    },
    {
      "epoch": 1.153986432270771,
      "grad_norm": 0.17419849336147308,
      "learning_rate": 3.846013567729229e-05,
      "loss": 0.0044,
      "step": 15820
    },
    {
      "epoch": 1.1547158800787805,
      "grad_norm": 0.08683416247367859,
      "learning_rate": 3.84528411992122e-05,
      "loss": 0.0068,
      "step": 15830
    },
    {
      "epoch": 1.1554453278867898,
      "grad_norm": 0.2907469868659973,
      "learning_rate": 3.84455467211321e-05,
      "loss": 0.0035,
      "step": 15840
    },
    {
      "epoch": 1.156174775694799,
      "grad_norm": 0.009745686315000057,
      "learning_rate": 3.8438252243052014e-05,
      "loss": 0.0059,
      "step": 15850
    },
    {
      "epoch": 1.1569042235028084,
      "grad_norm": 0.2909749746322632,
      "learning_rate": 3.843095776497192e-05,
      "loss": 0.0045,
      "step": 15860
    },
    {
      "epoch": 1.1576336713108177,
      "grad_norm": 0.7515525817871094,
      "learning_rate": 3.842366328689182e-05,
      "loss": 0.0046,
      "step": 15870
    },
    {
      "epoch": 1.158363119118827,
      "grad_norm": 0.05889258533716202,
      "learning_rate": 3.841636880881173e-05,
      "loss": 0.0059,
      "step": 15880
    },
    {
      "epoch": 1.1590925669268364,
      "grad_norm": 0.28515371680259705,
      "learning_rate": 3.840907433073164e-05,
      "loss": 0.0046,
      "step": 15890
    },
    {
      "epoch": 1.1598220147348457,
      "grad_norm": 0.029722275212407112,
      "learning_rate": 3.8401779852651545e-05,
      "loss": 0.0057,
      "step": 15900
    },
    {
      "epoch": 1.160551462542855,
      "grad_norm": 0.014549273997545242,
      "learning_rate": 3.839448537457145e-05,
      "loss": 0.0042,
      "step": 15910
    },
    {
      "epoch": 1.1612809103508643,
      "grad_norm": 0.009503454901278019,
      "learning_rate": 3.838719089649136e-05,
      "loss": 0.006,
      "step": 15920
    },
    {
      "epoch": 1.1620103581588737,
      "grad_norm": 0.27376124262809753,
      "learning_rate": 3.837989641841127e-05,
      "loss": 0.0051,
      "step": 15930
    },
    {
      "epoch": 1.162739805966883,
      "grad_norm": 0.49335286021232605,
      "learning_rate": 3.837260194033117e-05,
      "loss": 0.0046,
      "step": 15940
    },
    {
      "epoch": 1.1634692537748923,
      "grad_norm": 0.08717668056488037,
      "learning_rate": 3.8365307462251076e-05,
      "loss": 0.0055,
      "step": 15950
    },
    {
      "epoch": 1.1641987015829018,
      "grad_norm": 0.37516579031944275,
      "learning_rate": 3.8358012984170984e-05,
      "loss": 0.0056,
      "step": 15960
    },
    {
      "epoch": 1.1649281493909112,
      "grad_norm": 0.14554522931575775,
      "learning_rate": 3.835071850609089e-05,
      "loss": 0.0053,
      "step": 15970
    },
    {
      "epoch": 1.1656575971989205,
      "grad_norm": 0.3575710952281952,
      "learning_rate": 3.83434240280108e-05,
      "loss": 0.005,
      "step": 15980
    },
    {
      "epoch": 1.1663870450069298,
      "grad_norm": 0.17295537889003754,
      "learning_rate": 3.8336129549930706e-05,
      "loss": 0.0062,
      "step": 15990
    },
    {
      "epoch": 1.1671164928149391,
      "grad_norm": 0.35258200764656067,
      "learning_rate": 3.8328835071850614e-05,
      "loss": 0.0054,
      "step": 16000
    },
    {
      "epoch": 1.1678459406229484,
      "grad_norm": 0.29021891951560974,
      "learning_rate": 3.8321540593770514e-05,
      "loss": 0.0052,
      "step": 16010
    },
    {
      "epoch": 1.1685753884309578,
      "grad_norm": 0.4072016477584839,
      "learning_rate": 3.831424611569042e-05,
      "loss": 0.0042,
      "step": 16020
    },
    {
      "epoch": 1.169304836238967,
      "grad_norm": 0.05810832977294922,
      "learning_rate": 3.8306951637610336e-05,
      "loss": 0.0063,
      "step": 16030
    },
    {
      "epoch": 1.1700342840469764,
      "grad_norm": 0.1160939559340477,
      "learning_rate": 3.829965715953024e-05,
      "loss": 0.0038,
      "step": 16040
    },
    {
      "epoch": 1.1707637318549857,
      "grad_norm": 0.14479760825634003,
      "learning_rate": 3.8292362681450145e-05,
      "loss": 0.0049,
      "step": 16050
    },
    {
      "epoch": 1.171493179662995,
      "grad_norm": 0.058771565556526184,
      "learning_rate": 3.828506820337005e-05,
      "loss": 0.0049,
      "step": 16060
    },
    {
      "epoch": 1.1722226274710044,
      "grad_norm": 0.05890246853232384,
      "learning_rate": 3.827777372528995e-05,
      "loss": 0.0058,
      "step": 16070
    },
    {
      "epoch": 1.1729520752790137,
      "grad_norm": 0.34602227807044983,
      "learning_rate": 3.827047924720986e-05,
      "loss": 0.0063,
      "step": 16080
    },
    {
      "epoch": 1.1736815230870232,
      "grad_norm": 0.34623318910598755,
      "learning_rate": 3.8263184769129775e-05,
      "loss": 0.0042,
      "step": 16090
    },
    {
      "epoch": 1.1744109708950325,
      "grad_norm": 0.3278915584087372,
      "learning_rate": 3.8255890291049675e-05,
      "loss": 0.0064,
      "step": 16100
    },
    {
      "epoch": 1.1751404187030419,
      "grad_norm": 0.030043477192521095,
      "learning_rate": 3.824859581296958e-05,
      "loss": 0.005,
      "step": 16110
    },
    {
      "epoch": 1.1758698665110512,
      "grad_norm": 0.14161545038223267,
      "learning_rate": 3.824130133488949e-05,
      "loss": 0.0045,
      "step": 16120
    },
    {
      "epoch": 1.1765993143190605,
      "grad_norm": 0.17369286715984344,
      "learning_rate": 3.82340068568094e-05,
      "loss": 0.0045,
      "step": 16130
    },
    {
      "epoch": 1.1773287621270698,
      "grad_norm": 0.11584953963756561,
      "learning_rate": 3.82267123787293e-05,
      "loss": 0.0041,
      "step": 16140
    },
    {
      "epoch": 1.1780582099350791,
      "grad_norm": 0.5723298788070679,
      "learning_rate": 3.821941790064921e-05,
      "loss": 0.0048,
      "step": 16150
    },
    {
      "epoch": 1.1787876577430885,
      "grad_norm": 0.29379555583000183,
      "learning_rate": 3.821212342256912e-05,
      "loss": 0.0047,
      "step": 16160
    },
    {
      "epoch": 1.1795171055510978,
      "grad_norm": 0.23169301450252533,
      "learning_rate": 3.820482894448902e-05,
      "loss": 0.005,
      "step": 16170
    },
    {
      "epoch": 1.180246553359107,
      "grad_norm": 0.14573857188224792,
      "learning_rate": 3.819753446640893e-05,
      "loss": 0.004,
      "step": 16180
    },
    {
      "epoch": 1.1809760011671164,
      "grad_norm": 0.08625457435846329,
      "learning_rate": 3.8190239988328836e-05,
      "loss": 0.0048,
      "step": 16190
    },
    {
      "epoch": 1.1817054489751257,
      "grad_norm": 0.17661558091640472,
      "learning_rate": 3.8182945510248744e-05,
      "loss": 0.0044,
      "step": 16200
    },
    {
      "epoch": 1.182434896783135,
      "grad_norm": 0.28927165269851685,
      "learning_rate": 3.817565103216865e-05,
      "loss": 0.0058,
      "step": 16210
    },
    {
      "epoch": 1.1831643445911446,
      "grad_norm": 0.3466278612613678,
      "learning_rate": 3.816835655408856e-05,
      "loss": 0.0043,
      "step": 16220
    },
    {
      "epoch": 1.183893792399154,
      "grad_norm": 0.12310635298490524,
      "learning_rate": 3.8161062076008467e-05,
      "loss": 0.0051,
      "step": 16230
    },
    {
      "epoch": 1.1846232402071633,
      "grad_norm": 0.057718269526958466,
      "learning_rate": 3.815376759792837e-05,
      "loss": 0.0045,
      "step": 16240
    },
    {
      "epoch": 1.1853526880151726,
      "grad_norm": 0.34815114736557007,
      "learning_rate": 3.8146473119848275e-05,
      "loss": 0.0036,
      "step": 16250
    },
    {
      "epoch": 1.186082135823182,
      "grad_norm": 0.23134572803974152,
      "learning_rate": 3.813917864176818e-05,
      "loss": 0.0071,
      "step": 16260
    },
    {
      "epoch": 1.1868115836311912,
      "grad_norm": 0.2574520409107208,
      "learning_rate": 3.813188416368809e-05,
      "loss": 0.0051,
      "step": 16270
    },
    {
      "epoch": 1.1875410314392005,
      "grad_norm": 0.032378360629081726,
      "learning_rate": 3.8124589685608e-05,
      "loss": 0.0052,
      "step": 16280
    },
    {
      "epoch": 1.1882704792472099,
      "grad_norm": 0.2751864194869995,
      "learning_rate": 3.8117295207527905e-05,
      "loss": 0.0039,
      "step": 16290
    },
    {
      "epoch": 1.1889999270552192,
      "grad_norm": 0.17447292804718018,
      "learning_rate": 3.8110000729447806e-05,
      "loss": 0.0057,
      "step": 16300
    },
    {
      "epoch": 1.1897293748632285,
      "grad_norm": 0.16161780059337616,
      "learning_rate": 3.810270625136771e-05,
      "loss": 0.0056,
      "step": 16310
    },
    {
      "epoch": 1.1904588226712378,
      "grad_norm": 0.17498481273651123,
      "learning_rate": 3.809541177328762e-05,
      "loss": 0.006,
      "step": 16320
    },
    {
      "epoch": 1.1911882704792471,
      "grad_norm": 0.3176618814468384,
      "learning_rate": 3.808811729520753e-05,
      "loss": 0.0048,
      "step": 16330
    },
    {
      "epoch": 1.1919177182872565,
      "grad_norm": 0.11949985474348068,
      "learning_rate": 3.8080822817127436e-05,
      "loss": 0.0049,
      "step": 16340
    },
    {
      "epoch": 1.192647166095266,
      "grad_norm": 0.031230637803673744,
      "learning_rate": 3.8073528339047343e-05,
      "loss": 0.0047,
      "step": 16350
    },
    {
      "epoch": 1.193376613903275,
      "grad_norm": 0.5196833610534668,
      "learning_rate": 3.806623386096725e-05,
      "loss": 0.005,
      "step": 16360
    },
    {
      "epoch": 1.1941060617112846,
      "grad_norm": 0.03048534318804741,
      "learning_rate": 3.805893938288715e-05,
      "loss": 0.0047,
      "step": 16370
    },
    {
      "epoch": 1.194835509519294,
      "grad_norm": 0.14494813978672028,
      "learning_rate": 3.8051644904807066e-05,
      "loss": 0.0033,
      "step": 16380
    },
    {
      "epoch": 1.1955649573273033,
      "grad_norm": 0.06080925837159157,
      "learning_rate": 3.8044350426726974e-05,
      "loss": 0.0059,
      "step": 16390
    },
    {
      "epoch": 1.1962944051353126,
      "grad_norm": 0.2604841887950897,
      "learning_rate": 3.8037055948646874e-05,
      "loss": 0.0043,
      "step": 16400
    },
    {
      "epoch": 1.197023852943322,
      "grad_norm": 0.1444006860256195,
      "learning_rate": 3.802976147056678e-05,
      "loss": 0.0036,
      "step": 16410
    },
    {
      "epoch": 1.1977533007513312,
      "grad_norm": 0.08726152777671814,
      "learning_rate": 3.802246699248669e-05,
      "loss": 0.0045,
      "step": 16420
    },
    {
      "epoch": 1.1984827485593406,
      "grad_norm": 0.1052045151591301,
      "learning_rate": 3.80151725144066e-05,
      "loss": 0.0067,
      "step": 16430
    },
    {
      "epoch": 1.1992121963673499,
      "grad_norm": 0.03129493072628975,
      "learning_rate": 3.8007878036326504e-05,
      "loss": 0.0054,
      "step": 16440
    },
    {
      "epoch": 1.1999416441753592,
      "grad_norm": 0.1442345678806305,
      "learning_rate": 3.800058355824641e-05,
      "loss": 0.0038,
      "step": 16450
    },
    {
      "epoch": 1.2006710919833685,
      "grad_norm": 0.31784623861312866,
      "learning_rate": 3.799328908016632e-05,
      "loss": 0.0046,
      "step": 16460
    },
    {
      "epoch": 1.2014005397913778,
      "grad_norm": 0.6342389583587646,
      "learning_rate": 3.798599460208622e-05,
      "loss": 0.0047,
      "step": 16470
    },
    {
      "epoch": 1.2021299875993874,
      "grad_norm": 0.461797297000885,
      "learning_rate": 3.797870012400613e-05,
      "loss": 0.0045,
      "step": 16480
    },
    {
      "epoch": 1.2028594354073965,
      "grad_norm": 0.23187977075576782,
      "learning_rate": 3.7971405645926035e-05,
      "loss": 0.0047,
      "step": 16490
    },
    {
      "epoch": 1.203588883215406,
      "grad_norm": 0.009667321108281612,
      "learning_rate": 3.796411116784594e-05,
      "loss": 0.0055,
      "step": 16500
    },
    {
      "epoch": 1.2043183310234153,
      "grad_norm": 0.08630086481571198,
      "learning_rate": 3.795681668976585e-05,
      "loss": 0.0055,
      "step": 16510
    },
    {
      "epoch": 1.2050477788314247,
      "grad_norm": 0.05797763541340828,
      "learning_rate": 3.794952221168576e-05,
      "loss": 0.0055,
      "step": 16520
    },
    {
      "epoch": 1.205777226639434,
      "grad_norm": 0.2602524757385254,
      "learning_rate": 3.794222773360566e-05,
      "loss": 0.0063,
      "step": 16530
    },
    {
      "epoch": 1.2065066744474433,
      "grad_norm": 0.11708571761846542,
      "learning_rate": 3.7934933255525566e-05,
      "loss": 0.003,
      "step": 16540
    },
    {
      "epoch": 1.2072361222554526,
      "grad_norm": 0.1728540062904358,
      "learning_rate": 3.7927638777445474e-05,
      "loss": 0.0056,
      "step": 16550
    },
    {
      "epoch": 1.207965570063462,
      "grad_norm": 0.2685904800891876,
      "learning_rate": 3.792034429936538e-05,
      "loss": 0.0052,
      "step": 16560
    },
    {
      "epoch": 1.2086950178714713,
      "grad_norm": 0.1734839826822281,
      "learning_rate": 3.791304982128529e-05,
      "loss": 0.0053,
      "step": 16570
    },
    {
      "epoch": 1.2094244656794806,
      "grad_norm": 0.34571099281311035,
      "learning_rate": 3.7905755343205196e-05,
      "loss": 0.0064,
      "step": 16580
    },
    {
      "epoch": 1.21015391348749,
      "grad_norm": 0.31396403908729553,
      "learning_rate": 3.7898460865125104e-05,
      "loss": 0.0034,
      "step": 16590
    },
    {
      "epoch": 1.2108833612954992,
      "grad_norm": 0.3189585506916046,
      "learning_rate": 3.7891166387045005e-05,
      "loss": 0.005,
      "step": 16600
    },
    {
      "epoch": 1.2116128091035085,
      "grad_norm": 0.08661334961652756,
      "learning_rate": 3.788387190896491e-05,
      "loss": 0.0051,
      "step": 16610
    },
    {
      "epoch": 1.2123422569115179,
      "grad_norm": 0.26908957958221436,
      "learning_rate": 3.7876577430884826e-05,
      "loss": 0.0068,
      "step": 16620
    },
    {
      "epoch": 1.2130717047195274,
      "grad_norm": 0.26681628823280334,
      "learning_rate": 3.786928295280473e-05,
      "loss": 0.0053,
      "step": 16630
    },
    {
      "epoch": 1.2138011525275367,
      "grad_norm": 0.48445838689804077,
      "learning_rate": 3.7861988474724635e-05,
      "loss": 0.0046,
      "step": 16640
    },
    {
      "epoch": 1.214530600335546,
      "grad_norm": 0.058164943009614944,
      "learning_rate": 3.785469399664454e-05,
      "loss": 0.0032,
      "step": 16650
    },
    {
      "epoch": 1.2152600481435554,
      "grad_norm": 0.23188379406929016,
      "learning_rate": 3.784739951856445e-05,
      "loss": 0.0057,
      "step": 16660
    },
    {
      "epoch": 1.2159894959515647,
      "grad_norm": 0.2896311581134796,
      "learning_rate": 3.784010504048435e-05,
      "loss": 0.006,
      "step": 16670
    },
    {
      "epoch": 1.216718943759574,
      "grad_norm": 0.11540792882442474,
      "learning_rate": 3.7832810562404265e-05,
      "loss": 0.0064,
      "step": 16680
    },
    {
      "epoch": 1.2174483915675833,
      "grad_norm": 0.08700650185346603,
      "learning_rate": 3.782551608432417e-05,
      "loss": 0.0051,
      "step": 16690
    },
    {
      "epoch": 1.2181778393755927,
      "grad_norm": 0.17337670922279358,
      "learning_rate": 3.781822160624407e-05,
      "loss": 0.0053,
      "step": 16700
    },
    {
      "epoch": 1.218907287183602,
      "grad_norm": 0.22690698504447937,
      "learning_rate": 3.781092712816398e-05,
      "loss": 0.0051,
      "step": 16710
    },
    {
      "epoch": 1.2196367349916113,
      "grad_norm": 0.11733999103307724,
      "learning_rate": 3.780363265008389e-05,
      "loss": 0.0043,
      "step": 16720
    },
    {
      "epoch": 1.2203661827996206,
      "grad_norm": 0.17416681349277496,
      "learning_rate": 3.7796338172003796e-05,
      "loss": 0.0051,
      "step": 16730
    },
    {
      "epoch": 1.22109563060763,
      "grad_norm": 0.5371836423873901,
      "learning_rate": 3.77890436939237e-05,
      "loss": 0.0052,
      "step": 16740
    },
    {
      "epoch": 1.2218250784156393,
      "grad_norm": 0.11570701748132706,
      "learning_rate": 3.778174921584361e-05,
      "loss": 0.0057,
      "step": 16750
    },
    {
      "epoch": 1.2225545262236488,
      "grad_norm": 0.23854829370975494,
      "learning_rate": 3.777445473776352e-05,
      "loss": 0.0047,
      "step": 16760
    },
    {
      "epoch": 1.2232839740316581,
      "grad_norm": 0.006219767965376377,
      "learning_rate": 3.776716025968342e-05,
      "loss": 0.0055,
      "step": 16770
    },
    {
      "epoch": 1.2240134218396674,
      "grad_norm": 0.3018897473812103,
      "learning_rate": 3.7759865781603327e-05,
      "loss": 0.0054,
      "step": 16780
    },
    {
      "epoch": 1.2247428696476768,
      "grad_norm": 0.11586692184209824,
      "learning_rate": 3.7752571303523234e-05,
      "loss": 0.004,
      "step": 16790
    },
    {
      "epoch": 1.225472317455686,
      "grad_norm": 0.46503183245658875,
      "learning_rate": 3.774527682544314e-05,
      "loss": 0.0063,
      "step": 16800
    },
    {
      "epoch": 1.2262017652636954,
      "grad_norm": 0.06017976626753807,
      "learning_rate": 3.773798234736305e-05,
      "loss": 0.0035,
      "step": 16810
    },
    {
      "epoch": 1.2269312130717047,
      "grad_norm": 0.10059130191802979,
      "learning_rate": 3.773068786928296e-05,
      "loss": 0.0037,
      "step": 16820
    },
    {
      "epoch": 1.227660660879714,
      "grad_norm": 0.17791883647441864,
      "learning_rate": 3.772339339120286e-05,
      "loss": 0.0053,
      "step": 16830
    },
    {
      "epoch": 1.2283901086877234,
      "grad_norm": 0.20805723965168,
      "learning_rate": 3.7716098913122765e-05,
      "loss": 0.0033,
      "step": 16840
    },
    {
      "epoch": 1.2291195564957327,
      "grad_norm": 0.519913911819458,
      "learning_rate": 3.770880443504268e-05,
      "loss": 0.005,
      "step": 16850
    },
    {
      "epoch": 1.229849004303742,
      "grad_norm": 0.14717596769332886,
      "learning_rate": 3.770150995696258e-05,
      "loss": 0.0056,
      "step": 16860
    },
    {
      "epoch": 1.2305784521117513,
      "grad_norm": 0.01326682697981596,
      "learning_rate": 3.769421547888249e-05,
      "loss": 0.0041,
      "step": 16870
    },
    {
      "epoch": 1.2313078999197606,
      "grad_norm": 0.37899357080459595,
      "learning_rate": 3.7686921000802395e-05,
      "loss": 0.0044,
      "step": 16880
    },
    {
      "epoch": 1.2320373477277702,
      "grad_norm": 0.20220278203487396,
      "learning_rate": 3.76796265227223e-05,
      "loss": 0.0054,
      "step": 16890
    },
    {
      "epoch": 1.2327667955357795,
      "grad_norm": 0.23161634802818298,
      "learning_rate": 3.76723320446422e-05,
      "loss": 0.0041,
      "step": 16900
    },
    {
      "epoch": 1.2334962433437888,
      "grad_norm": 0.05960098281502724,
      "learning_rate": 3.766503756656212e-05,
      "loss": 0.0048,
      "step": 16910
    },
    {
      "epoch": 1.2342256911517981,
      "grad_norm": 0.17260152101516724,
      "learning_rate": 3.7657743088482025e-05,
      "loss": 0.0039,
      "step": 16920
    },
    {
      "epoch": 1.2349551389598075,
      "grad_norm": 0.08625548332929611,
      "learning_rate": 3.7650448610401926e-05,
      "loss": 0.0048,
      "step": 16930
    },
    {
      "epoch": 1.2356845867678168,
      "grad_norm": 0.05970458313822746,
      "learning_rate": 3.7643154132321833e-05,
      "loss": 0.0065,
      "step": 16940
    },
    {
      "epoch": 1.236414034575826,
      "grad_norm": 0.14836256206035614,
      "learning_rate": 3.763585965424174e-05,
      "loss": 0.0052,
      "step": 16950
    },
    {
      "epoch": 1.2371434823838354,
      "grad_norm": 0.11608333140611649,
      "learning_rate": 3.762856517616165e-05,
      "loss": 0.0047,
      "step": 16960
    },
    {
      "epoch": 1.2378729301918447,
      "grad_norm": 0.46405065059661865,
      "learning_rate": 3.7621270698081556e-05,
      "loss": 0.0044,
      "step": 16970
    },
    {
      "epoch": 1.238602377999854,
      "grad_norm": 0.006278987508267164,
      "learning_rate": 3.7613976220001464e-05,
      "loss": 0.0045,
      "step": 16980
    },
    {
      "epoch": 1.2393318258078634,
      "grad_norm": 0.5769548416137695,
      "learning_rate": 3.760668174192137e-05,
      "loss": 0.006,
      "step": 16990
    },
    {
      "epoch": 1.2400612736158727,
      "grad_norm": 0.14475274085998535,
      "learning_rate": 3.759938726384127e-05,
      "loss": 0.0044,
      "step": 17000
    },
    {
      "epoch": 1.240790721423882,
      "grad_norm": 0.2178862988948822,
      "learning_rate": 3.759209278576118e-05,
      "loss": 0.0047,
      "step": 17010
    },
    {
      "epoch": 1.2415201692318916,
      "grad_norm": 0.057759325951337814,
      "learning_rate": 3.758479830768109e-05,
      "loss": 0.0066,
      "step": 17020
    },
    {
      "epoch": 1.2422496170399009,
      "grad_norm": 0.08264324069023132,
      "learning_rate": 3.7577503829600994e-05,
      "loss": 0.0039,
      "step": 17030
    },
    {
      "epoch": 1.2429790648479102,
      "grad_norm": 0.17335137724876404,
      "learning_rate": 3.75702093515209e-05,
      "loss": 0.0039,
      "step": 17040
    },
    {
      "epoch": 1.2437085126559195,
      "grad_norm": 0.4336595833301544,
      "learning_rate": 3.756291487344081e-05,
      "loss": 0.0071,
      "step": 17050
    },
    {
      "epoch": 1.2444379604639288,
      "grad_norm": 0.17347857356071472,
      "learning_rate": 3.755562039536071e-05,
      "loss": 0.0053,
      "step": 17060
    },
    {
      "epoch": 1.2451674082719382,
      "grad_norm": 0.33522215485572815,
      "learning_rate": 3.754832591728062e-05,
      "loss": 0.0063,
      "step": 17070
    },
    {
      "epoch": 1.2458968560799475,
      "grad_norm": 0.27769574522972107,
      "learning_rate": 3.7541031439200525e-05,
      "loss": 0.0055,
      "step": 17080
    },
    {
      "epoch": 1.2466263038879568,
      "grad_norm": 0.11614356935024261,
      "learning_rate": 3.753373696112043e-05,
      "loss": 0.0049,
      "step": 17090
    },
    {
      "epoch": 1.2473557516959661,
      "grad_norm": 0.004931327421218157,
      "learning_rate": 3.752644248304034e-05,
      "loss": 0.0057,
      "step": 17100
    },
    {
      "epoch": 1.2480851995039755,
      "grad_norm": 0.20202884078025818,
      "learning_rate": 3.751914800496025e-05,
      "loss": 0.0036,
      "step": 17110
    },
    {
      "epoch": 1.2488146473119848,
      "grad_norm": 0.05770072340965271,
      "learning_rate": 3.7511853526880155e-05,
      "loss": 0.0055,
      "step": 17120
    },
    {
      "epoch": 1.249544095119994,
      "grad_norm": 0.20424504578113556,
      "learning_rate": 3.7504559048800056e-05,
      "loss": 0.0043,
      "step": 17130
    },
    {
      "epoch": 1.2502735429280034,
      "grad_norm": 0.0714542344212532,
      "learning_rate": 3.7497264570719964e-05,
      "loss": 0.0048,
      "step": 17140
    },
    {
      "epoch": 1.251002990736013,
      "grad_norm": 0.059056926518678665,
      "learning_rate": 3.748997009263988e-05,
      "loss": 0.0046,
      "step": 17150
    },
    {
      "epoch": 1.251732438544022,
      "grad_norm": 0.3215518593788147,
      "learning_rate": 3.748267561455978e-05,
      "loss": 0.0042,
      "step": 17160
    },
    {
      "epoch": 1.2524618863520316,
      "grad_norm": 0.35772204399108887,
      "learning_rate": 3.7475381136479686e-05,
      "loss": 0.0044,
      "step": 17170
    },
    {
      "epoch": 1.253191334160041,
      "grad_norm": 0.04518156126141548,
      "learning_rate": 3.7468086658399594e-05,
      "loss": 0.005,
      "step": 17180
    },
    {
      "epoch": 1.2539207819680502,
      "grad_norm": 0.14480723440647125,
      "learning_rate": 3.74607921803195e-05,
      "loss": 0.0039,
      "step": 17190
    },
    {
      "epoch": 1.2546502297760596,
      "grad_norm": 0.2604004144668579,
      "learning_rate": 3.74534977022394e-05,
      "loss": 0.0038,
      "step": 17200
    },
    {
      "epoch": 1.2553796775840689,
      "grad_norm": 0.28962403535842896,
      "learning_rate": 3.7446203224159316e-05,
      "loss": 0.0029,
      "step": 17210
    },
    {
      "epoch": 1.2561091253920782,
      "grad_norm": 0.11509009450674057,
      "learning_rate": 3.7438908746079224e-05,
      "loss": 0.0065,
      "step": 17220
    },
    {
      "epoch": 1.2568385732000875,
      "grad_norm": 0.22723884880542755,
      "learning_rate": 3.7431614267999125e-05,
      "loss": 0.0047,
      "step": 17230
    },
    {
      "epoch": 1.2575680210080968,
      "grad_norm": 0.11538511514663696,
      "learning_rate": 3.742431978991903e-05,
      "loss": 0.0048,
      "step": 17240
    },
    {
      "epoch": 1.2582974688161062,
      "grad_norm": 0.08823248744010925,
      "learning_rate": 3.741702531183894e-05,
      "loss": 0.004,
      "step": 17250
    },
    {
      "epoch": 1.2590269166241155,
      "grad_norm": 0.625096321105957,
      "learning_rate": 3.740973083375884e-05,
      "loss": 0.0064,
      "step": 17260
    },
    {
      "epoch": 1.2597563644321248,
      "grad_norm": 0.2605474591255188,
      "learning_rate": 3.7402436355678755e-05,
      "loss": 0.0049,
      "step": 17270
    },
    {
      "epoch": 1.2604858122401343,
      "grad_norm": 0.3751964569091797,
      "learning_rate": 3.739514187759866e-05,
      "loss": 0.0053,
      "step": 17280
    },
    {
      "epoch": 1.2612152600481434,
      "grad_norm": 0.3461570143699646,
      "learning_rate": 3.738784739951856e-05,
      "loss": 0.0063,
      "step": 17290
    },
    {
      "epoch": 1.261944707856153,
      "grad_norm": 0.0865267962217331,
      "learning_rate": 3.738055292143847e-05,
      "loss": 0.0056,
      "step": 17300
    },
    {
      "epoch": 1.2626741556641623,
      "grad_norm": 0.3094865679740906,
      "learning_rate": 3.737325844335838e-05,
      "loss": 0.0034,
      "step": 17310
    },
    {
      "epoch": 1.2634036034721716,
      "grad_norm": 0.34984201192855835,
      "learning_rate": 3.7365963965278286e-05,
      "loss": 0.0053,
      "step": 17320
    },
    {
      "epoch": 1.264133051280181,
      "grad_norm": 0.23137390613555908,
      "learning_rate": 3.735866948719819e-05,
      "loss": 0.0056,
      "step": 17330
    },
    {
      "epoch": 1.2648624990881903,
      "grad_norm": 0.2043677121400833,
      "learning_rate": 3.73513750091181e-05,
      "loss": 0.0045,
      "step": 17340
    },
    {
      "epoch": 1.2655919468961996,
      "grad_norm": 0.11526582390069962,
      "learning_rate": 3.734408053103801e-05,
      "loss": 0.0027,
      "step": 17350
    },
    {
      "epoch": 1.266321394704209,
      "grad_norm": 0.37167471647262573,
      "learning_rate": 3.733678605295791e-05,
      "loss": 0.0052,
      "step": 17360
    },
    {
      "epoch": 1.2670508425122182,
      "grad_norm": 0.2729743719100952,
      "learning_rate": 3.7329491574877817e-05,
      "loss": 0.0069,
      "step": 17370
    },
    {
      "epoch": 1.2677802903202275,
      "grad_norm": 0.0584866888821125,
      "learning_rate": 3.732219709679773e-05,
      "loss": 0.006,
      "step": 17380
    },
    {
      "epoch": 1.2685097381282369,
      "grad_norm": 0.34649765491485596,
      "learning_rate": 3.731490261871763e-05,
      "loss": 0.0049,
      "step": 17390
    },
    {
      "epoch": 1.2692391859362462,
      "grad_norm": 0.43335863947868347,
      "learning_rate": 3.730760814063754e-05,
      "loss": 0.0059,
      "step": 17400
    },
    {
      "epoch": 1.2699686337442557,
      "grad_norm": 0.2307656705379486,
      "learning_rate": 3.730031366255745e-05,
      "loss": 0.0043,
      "step": 17410
    },
    {
      "epoch": 1.2706980815522648,
      "grad_norm": 0.114994116127491,
      "learning_rate": 3.7293019184477354e-05,
      "loss": 0.0034,
      "step": 17420
    },
    {
      "epoch": 1.2714275293602744,
      "grad_norm": 0.11601719260215759,
      "learning_rate": 3.7285724706397255e-05,
      "loss": 0.0044,
      "step": 17430
    },
    {
      "epoch": 1.2721569771682837,
      "grad_norm": 0.23307879269123077,
      "learning_rate": 3.727843022831717e-05,
      "loss": 0.005,
      "step": 17440
    },
    {
      "epoch": 1.272886424976293,
      "grad_norm": 0.23011712729930878,
      "learning_rate": 3.727113575023708e-05,
      "loss": 0.004,
      "step": 17450
    },
    {
      "epoch": 1.2736158727843023,
      "grad_norm": 0.031299374997615814,
      "learning_rate": 3.726384127215698e-05,
      "loss": 0.0048,
      "step": 17460
    },
    {
      "epoch": 1.2743453205923116,
      "grad_norm": 0.14556100964546204,
      "learning_rate": 3.7256546794076885e-05,
      "loss": 0.0039,
      "step": 17470
    },
    {
      "epoch": 1.275074768400321,
      "grad_norm": 0.4606441259384155,
      "learning_rate": 3.724925231599679e-05,
      "loss": 0.0047,
      "step": 17480
    },
    {
      "epoch": 1.2758042162083303,
      "grad_norm": 0.31837278604507446,
      "learning_rate": 3.7241957837916693e-05,
      "loss": 0.0051,
      "step": 17490
    },
    {
      "epoch": 1.2765336640163396,
      "grad_norm": 0.26123130321502686,
      "learning_rate": 3.723466335983661e-05,
      "loss": 0.0051,
      "step": 17500
    },
    {
      "epoch": 1.277263111824349,
      "grad_norm": 0.14443831145763397,
      "learning_rate": 3.7227368881756515e-05,
      "loss": 0.0054,
      "step": 17510
    },
    {
      "epoch": 1.2779925596323582,
      "grad_norm": 0.5402011275291443,
      "learning_rate": 3.7220074403676416e-05,
      "loss": 0.0032,
      "step": 17520
    },
    {
      "epoch": 1.2787220074403676,
      "grad_norm": 0.20237624645233154,
      "learning_rate": 3.7212779925596324e-05,
      "loss": 0.0033,
      "step": 17530
    },
    {
      "epoch": 1.2794514552483771,
      "grad_norm": 0.17295987904071808,
      "learning_rate": 3.720548544751623e-05,
      "loss": 0.0052,
      "step": 17540
    },
    {
      "epoch": 1.2801809030563862,
      "grad_norm": 0.20411336421966553,
      "learning_rate": 3.719819096943614e-05,
      "loss": 0.0043,
      "step": 17550
    },
    {
      "epoch": 1.2809103508643958,
      "grad_norm": 0.40461960434913635,
      "learning_rate": 3.7190896491356046e-05,
      "loss": 0.004,
      "step": 17560
    },
    {
      "epoch": 1.2816397986724049,
      "grad_norm": 0.05920693650841713,
      "learning_rate": 3.7183602013275954e-05,
      "loss": 0.0055,
      "step": 17570
    },
    {
      "epoch": 1.2823692464804144,
      "grad_norm": 0.12490635365247726,
      "learning_rate": 3.717630753519586e-05,
      "loss": 0.0047,
      "step": 17580
    },
    {
      "epoch": 1.2830986942884237,
      "grad_norm": 0.05874365568161011,
      "learning_rate": 3.716901305711576e-05,
      "loss": 0.0046,
      "step": 17590
    },
    {
      "epoch": 1.283828142096433,
      "grad_norm": 0.030424682423472404,
      "learning_rate": 3.716171857903567e-05,
      "loss": 0.0047,
      "step": 17600
    },
    {
      "epoch": 1.2845575899044424,
      "grad_norm": 0.361822247505188,
      "learning_rate": 3.715442410095558e-05,
      "loss": 0.0032,
      "step": 17610
    },
    {
      "epoch": 1.2852870377124517,
      "grad_norm": 0.030226483941078186,
      "learning_rate": 3.7147129622875485e-05,
      "loss": 0.0041,
      "step": 17620
    },
    {
      "epoch": 1.286016485520461,
      "grad_norm": 0.1174531877040863,
      "learning_rate": 3.713983514479539e-05,
      "loss": 0.0039,
      "step": 17630
    },
    {
      "epoch": 1.2867459333284703,
      "grad_norm": 0.11788803339004517,
      "learning_rate": 3.71325406667153e-05,
      "loss": 0.0031,
      "step": 17640
    },
    {
      "epoch": 1.2874753811364796,
      "grad_norm": 0.029094453901052475,
      "learning_rate": 3.712524618863521e-05,
      "loss": 0.0045,
      "step": 17650
    },
    {
      "epoch": 1.288204828944489,
      "grad_norm": 0.30830249190330505,
      "learning_rate": 3.711795171055511e-05,
      "loss": 0.0043,
      "step": 17660
    },
    {
      "epoch": 1.2889342767524983,
      "grad_norm": 0.030165094882249832,
      "learning_rate": 3.7110657232475015e-05,
      "loss": 0.0046,
      "step": 17670
    },
    {
      "epoch": 1.2896637245605076,
      "grad_norm": 0.010686828754842281,
      "learning_rate": 3.710336275439493e-05,
      "loss": 0.0041,
      "step": 17680
    },
    {
      "epoch": 1.2903931723685171,
      "grad_norm": 0.31826087832450867,
      "learning_rate": 3.709606827631483e-05,
      "loss": 0.0046,
      "step": 17690
    },
    {
      "epoch": 1.2911226201765262,
      "grad_norm": 0.008117614313960075,
      "learning_rate": 3.708877379823474e-05,
      "loss": 0.0043,
      "step": 17700
    },
    {
      "epoch": 1.2918520679845358,
      "grad_norm": 0.08819165825843811,
      "learning_rate": 3.7081479320154646e-05,
      "loss": 0.0048,
      "step": 17710
    },
    {
      "epoch": 1.292581515792545,
      "grad_norm": 0.40483108162879944,
      "learning_rate": 3.707418484207455e-05,
      "loss": 0.0036,
      "step": 17720
    },
    {
      "epoch": 1.2933109636005544,
      "grad_norm": 0.08763125538825989,
      "learning_rate": 3.7066890363994454e-05,
      "loss": 0.0039,
      "step": 17730
    },
    {
      "epoch": 1.2940404114085637,
      "grad_norm": 0.3190840780735016,
      "learning_rate": 3.705959588591437e-05,
      "loss": 0.0037,
      "step": 17740
    },
    {
      "epoch": 1.294769859216573,
      "grad_norm": 0.693194568157196,
      "learning_rate": 3.7052301407834276e-05,
      "loss": 0.0037,
      "step": 17750
    },
    {
      "epoch": 1.2954993070245824,
      "grad_norm": 0.46670249104499817,
      "learning_rate": 3.7045006929754176e-05,
      "loss": 0.0045,
      "step": 17760
    },
    {
      "epoch": 1.2962287548325917,
      "grad_norm": 0.032645247876644135,
      "learning_rate": 3.7037712451674084e-05,
      "loss": 0.0029,
      "step": 17770
    },
    {
      "epoch": 1.296958202640601,
      "grad_norm": 0.34738779067993164,
      "learning_rate": 3.703041797359399e-05,
      "loss": 0.0056,
      "step": 17780
    },
    {
      "epoch": 1.2976876504486103,
      "grad_norm": 0.23637667298316956,
      "learning_rate": 3.702312349551389e-05,
      "loss": 0.0049,
      "step": 17790
    },
    {
      "epoch": 1.2984170982566197,
      "grad_norm": 0.14524893462657928,
      "learning_rate": 3.7015829017433806e-05,
      "loss": 0.0043,
      "step": 17800
    },
    {
      "epoch": 1.299146546064629,
      "grad_norm": 0.20256614685058594,
      "learning_rate": 3.7008534539353714e-05,
      "loss": 0.004,
      "step": 17810
    },
    {
      "epoch": 1.2998759938726385,
      "grad_norm": 0.46243786811828613,
      "learning_rate": 3.7001240061273615e-05,
      "loss": 0.0047,
      "step": 17820
    },
    {
      "epoch": 1.3006054416806476,
      "grad_norm": 0.23083984851837158,
      "learning_rate": 3.699394558319352e-05,
      "loss": 0.0036,
      "step": 17830
    },
    {
      "epoch": 1.3013348894886572,
      "grad_norm": 0.11601550132036209,
      "learning_rate": 3.698665110511343e-05,
      "loss": 0.0053,
      "step": 17840
    },
    {
      "epoch": 1.3020643372966665,
      "grad_norm": 0.2254098355770111,
      "learning_rate": 3.697935662703334e-05,
      "loss": 0.0044,
      "step": 17850
    },
    {
      "epoch": 1.3027937851046758,
      "grad_norm": 0.19297608733177185,
      "learning_rate": 3.6972062148953245e-05,
      "loss": 0.0042,
      "step": 17860
    },
    {
      "epoch": 1.3035232329126851,
      "grad_norm": 0.1466332972049713,
      "learning_rate": 3.696476767087315e-05,
      "loss": 0.004,
      "step": 17870
    },
    {
      "epoch": 1.3042526807206944,
      "grad_norm": 0.20241311192512512,
      "learning_rate": 3.695747319279306e-05,
      "loss": 0.0032,
      "step": 17880
    },
    {
      "epoch": 1.3049821285287038,
      "grad_norm": 0.3468153178691864,
      "learning_rate": 3.695017871471296e-05,
      "loss": 0.0041,
      "step": 17890
    },
    {
      "epoch": 1.305711576336713,
      "grad_norm": 0.43369024991989136,
      "learning_rate": 3.694288423663287e-05,
      "loss": 0.007,
      "step": 17900
    },
    {
      "epoch": 1.3064410241447224,
      "grad_norm": 0.11621055752038956,
      "learning_rate": 3.693558975855278e-05,
      "loss": 0.0058,
      "step": 17910
    },
    {
      "epoch": 1.3071704719527317,
      "grad_norm": 0.05965537577867508,
      "learning_rate": 3.692829528047268e-05,
      "loss": 0.0024,
      "step": 17920
    },
    {
      "epoch": 1.307899919760741,
      "grad_norm": 0.030148709192872047,
      "learning_rate": 3.692100080239259e-05,
      "loss": 0.0047,
      "step": 17930
    },
    {
      "epoch": 1.3086293675687504,
      "grad_norm": 0.027847707271575928,
      "learning_rate": 3.69137063243125e-05,
      "loss": 0.0045,
      "step": 17940
    },
    {
      "epoch": 1.30935881537676,
      "grad_norm": 0.4687049984931946,
      "learning_rate": 3.6906411846232406e-05,
      "loss": 0.0042,
      "step": 17950
    },
    {
      "epoch": 1.310088263184769,
      "grad_norm": 0.2492356151342392,
      "learning_rate": 3.689911736815231e-05,
      "loss": 0.0052,
      "step": 17960
    },
    {
      "epoch": 1.3108177109927786,
      "grad_norm": 0.23180653154850006,
      "learning_rate": 3.689182289007222e-05,
      "loss": 0.0045,
      "step": 17970
    },
    {
      "epoch": 1.3115471588007879,
      "grad_norm": 0.41692352294921875,
      "learning_rate": 3.688452841199213e-05,
      "loss": 0.0054,
      "step": 17980
    },
    {
      "epoch": 1.3122766066087972,
      "grad_norm": 0.24989713728427887,
      "learning_rate": 3.687723393391203e-05,
      "loss": 0.0036,
      "step": 17990
    },
    {
      "epoch": 1.3130060544168065,
      "grad_norm": 0.1462029069662094,
      "learning_rate": 3.686993945583194e-05,
      "loss": 0.0053,
      "step": 18000
    },
    {
      "epoch": 1.3137355022248158,
      "grad_norm": 0.16332249343395233,
      "learning_rate": 3.6862644977751844e-05,
      "loss": 0.0043,
      "step": 18010
    },
    {
      "epoch": 1.3144649500328252,
      "grad_norm": 0.1728101372718811,
      "learning_rate": 3.6855350499671745e-05,
      "loss": 0.004,
      "step": 18020
    },
    {
      "epoch": 1.3151943978408345,
      "grad_norm": 0.47936776280403137,
      "learning_rate": 3.684805602159166e-05,
      "loss": 0.0039,
      "step": 18030
    },
    {
      "epoch": 1.3159238456488438,
      "grad_norm": 0.1172766461968422,
      "learning_rate": 3.684076154351157e-05,
      "loss": 0.0039,
      "step": 18040
    },
    {
      "epoch": 1.3166532934568531,
      "grad_norm": 0.08654256910085678,
      "learning_rate": 3.683346706543147e-05,
      "loss": 0.0048,
      "step": 18050
    },
    {
      "epoch": 1.3173827412648624,
      "grad_norm": 0.0928594097495079,
      "learning_rate": 3.6826172587351375e-05,
      "loss": 0.0042,
      "step": 18060
    },
    {
      "epoch": 1.3181121890728718,
      "grad_norm": 0.05955544114112854,
      "learning_rate": 3.681887810927128e-05,
      "loss": 0.0041,
      "step": 18070
    },
    {
      "epoch": 1.3188416368808813,
      "grad_norm": 0.28956151008605957,
      "learning_rate": 3.681158363119119e-05,
      "loss": 0.0031,
      "step": 18080
    },
    {
      "epoch": 1.3195710846888904,
      "grad_norm": 0.11649081110954285,
      "learning_rate": 3.68042891531111e-05,
      "loss": 0.006,
      "step": 18090
    },
    {
      "epoch": 1.3203005324969,
      "grad_norm": 0.17362000048160553,
      "learning_rate": 3.6796994675031005e-05,
      "loss": 0.0045,
      "step": 18100
    },
    {
      "epoch": 1.3210299803049093,
      "grad_norm": 0.05870995670557022,
      "learning_rate": 3.678970019695091e-05,
      "loss": 0.0051,
      "step": 18110
    },
    {
      "epoch": 1.3217594281129186,
      "grad_norm": 0.4048348069190979,
      "learning_rate": 3.6782405718870814e-05,
      "loss": 0.0028,
      "step": 18120
    },
    {
      "epoch": 1.322488875920928,
      "grad_norm": 0.28924721479415894,
      "learning_rate": 3.677511124079072e-05,
      "loss": 0.0027,
      "step": 18130
    },
    {
      "epoch": 1.3232183237289372,
      "grad_norm": 0.1448344886302948,
      "learning_rate": 3.676781676271063e-05,
      "loss": 0.0055,
      "step": 18140
    },
    {
      "epoch": 1.3239477715369465,
      "grad_norm": 0.37566304206848145,
      "learning_rate": 3.6760522284630536e-05,
      "loss": 0.0038,
      "step": 18150
    },
    {
      "epoch": 1.3246772193449559,
      "grad_norm": 0.22447451949119568,
      "learning_rate": 3.6753227806550444e-05,
      "loss": 0.0056,
      "step": 18160
    },
    {
      "epoch": 1.3254066671529652,
      "grad_norm": 0.49239689111709595,
      "learning_rate": 3.674593332847035e-05,
      "loss": 0.0059,
      "step": 18170
    },
    {
      "epoch": 1.3261361149609745,
      "grad_norm": 0.174234077334404,
      "learning_rate": 3.673863885039026e-05,
      "loss": 0.005,
      "step": 18180
    },
    {
      "epoch": 1.3268655627689838,
      "grad_norm": 0.05807965621352196,
      "learning_rate": 3.673134437231016e-05,
      "loss": 0.0051,
      "step": 18190
    },
    {
      "epoch": 1.3275950105769931,
      "grad_norm": 0.14555856585502625,
      "learning_rate": 3.672404989423007e-05,
      "loss": 0.0063,
      "step": 18200
    },
    {
      "epoch": 1.3283244583850027,
      "grad_norm": 0.2887282371520996,
      "learning_rate": 3.671675541614998e-05,
      "loss": 0.0058,
      "step": 18210
    },
    {
      "epoch": 1.3290539061930118,
      "grad_norm": 0.4062410593032837,
      "learning_rate": 3.670946093806988e-05,
      "loss": 0.0048,
      "step": 18220
    },
    {
      "epoch": 1.3297833540010213,
      "grad_norm": 0.1821422427892685,
      "learning_rate": 3.670216645998979e-05,
      "loss": 0.0043,
      "step": 18230
    },
    {
      "epoch": 1.3305128018090306,
      "grad_norm": 0.0318974144756794,
      "learning_rate": 3.66948719819097e-05,
      "loss": 0.0035,
      "step": 18240
    },
    {
      "epoch": 1.33124224961704,
      "grad_norm": 0.5203196406364441,
      "learning_rate": 3.66875775038296e-05,
      "loss": 0.0053,
      "step": 18250
    },
    {
      "epoch": 1.3319716974250493,
      "grad_norm": 0.24719272553920746,
      "learning_rate": 3.6680283025749505e-05,
      "loss": 0.0028,
      "step": 18260
    },
    {
      "epoch": 1.3327011452330586,
      "grad_norm": 0.0875539779663086,
      "learning_rate": 3.667298854766942e-05,
      "loss": 0.0055,
      "step": 18270
    },
    {
      "epoch": 1.333430593041068,
      "grad_norm": 0.11650718003511429,
      "learning_rate": 3.666569406958932e-05,
      "loss": 0.004,
      "step": 18280
    },
    {
      "epoch": 1.3341600408490772,
      "grad_norm": 0.08705642819404602,
      "learning_rate": 3.665839959150923e-05,
      "loss": 0.005,
      "step": 18290
    },
    {
      "epoch": 1.3348894886570866,
      "grad_norm": 0.3771629333496094,
      "learning_rate": 3.6651105113429136e-05,
      "loss": 0.0038,
      "step": 18300
    },
    {
      "epoch": 1.3356189364650959,
      "grad_norm": 0.19021013379096985,
      "learning_rate": 3.664381063534904e-05,
      "loss": 0.0055,
      "step": 18310
    },
    {
      "epoch": 1.3363483842731052,
      "grad_norm": 0.27418816089630127,
      "learning_rate": 3.663651615726895e-05,
      "loss": 0.0049,
      "step": 18320
    },
    {
      "epoch": 1.3370778320811145,
      "grad_norm": 0.18257030844688416,
      "learning_rate": 3.662922167918886e-05,
      "loss": 0.0031,
      "step": 18330
    },
    {
      "epoch": 1.337807279889124,
      "grad_norm": 0.1486620306968689,
      "learning_rate": 3.6621927201108766e-05,
      "loss": 0.0037,
      "step": 18340
    },
    {
      "epoch": 1.3385367276971332,
      "grad_norm": 0.3471517264842987,
      "learning_rate": 3.6614632723028666e-05,
      "loss": 0.0038,
      "step": 18350
    },
    {
      "epoch": 1.3392661755051427,
      "grad_norm": 0.12134914100170135,
      "learning_rate": 3.6607338244948574e-05,
      "loss": 0.0054,
      "step": 18360
    },
    {
      "epoch": 1.3399956233131518,
      "grad_norm": 0.20240259170532227,
      "learning_rate": 3.660004376686848e-05,
      "loss": 0.0035,
      "step": 18370
    },
    {
      "epoch": 1.3407250711211613,
      "grad_norm": 0.15431450307369232,
      "learning_rate": 3.659274928878839e-05,
      "loss": 0.0041,
      "step": 18380
    },
    {
      "epoch": 1.3414545189291707,
      "grad_norm": 0.1437857449054718,
      "learning_rate": 3.6585454810708297e-05,
      "loss": 0.0052,
      "step": 18390
    },
    {
      "epoch": 1.34218396673718,
      "grad_norm": 0.23168057203292847,
      "learning_rate": 3.6578160332628204e-05,
      "loss": 0.0047,
      "step": 18400
    },
    {
      "epoch": 1.3429134145451893,
      "grad_norm": 0.08652722835540771,
      "learning_rate": 3.657086585454811e-05,
      "loss": 0.004,
      "step": 18410
    },
    {
      "epoch": 1.3436428623531986,
      "grad_norm": 0.21513719856739044,
      "learning_rate": 3.656357137646801e-05,
      "loss": 0.0036,
      "step": 18420
    },
    {
      "epoch": 1.344372310161208,
      "grad_norm": 0.4027860462665558,
      "learning_rate": 3.655627689838792e-05,
      "loss": 0.0033,
      "step": 18430
    },
    {
      "epoch": 1.3451017579692173,
      "grad_norm": 0.20153699815273285,
      "learning_rate": 3.6548982420307834e-05,
      "loss": 0.0042,
      "step": 18440
    },
    {
      "epoch": 1.3458312057772266,
      "grad_norm": 0.11612346023321152,
      "learning_rate": 3.6541687942227735e-05,
      "loss": 0.0039,
      "step": 18450
    },
    {
      "epoch": 1.346560653585236,
      "grad_norm": 0.17458480596542358,
      "learning_rate": 3.653439346414764e-05,
      "loss": 0.0037,
      "step": 18460
    },
    {
      "epoch": 1.3472901013932452,
      "grad_norm": 0.0309800673276186,
      "learning_rate": 3.652709898606755e-05,
      "loss": 0.0044,
      "step": 18470
    },
    {
      "epoch": 1.3480195492012546,
      "grad_norm": 0.23050446808338165,
      "learning_rate": 3.651980450798745e-05,
      "loss": 0.0043,
      "step": 18480
    },
    {
      "epoch": 1.348748997009264,
      "grad_norm": 0.20243321359157562,
      "learning_rate": 3.651251002990736e-05,
      "loss": 0.0039,
      "step": 18490
    },
    {
      "epoch": 1.3494784448172732,
      "grad_norm": 0.2896178364753723,
      "learning_rate": 3.650521555182727e-05,
      "loss": 0.004,
      "step": 18500
    },
    {
      "epoch": 1.3502078926252827,
      "grad_norm": 0.05817873403429985,
      "learning_rate": 3.649792107374717e-05,
      "loss": 0.005,
      "step": 18510
    },
    {
      "epoch": 1.350937340433292,
      "grad_norm": 0.008664716966450214,
      "learning_rate": 3.649062659566708e-05,
      "loss": 0.0037,
      "step": 18520
    },
    {
      "epoch": 1.3516667882413014,
      "grad_norm": 0.43247708678245544,
      "learning_rate": 3.648333211758699e-05,
      "loss": 0.0036,
      "step": 18530
    },
    {
      "epoch": 1.3523962360493107,
      "grad_norm": 0.6062297821044922,
      "learning_rate": 3.6476037639506896e-05,
      "loss": 0.0051,
      "step": 18540
    },
    {
      "epoch": 1.35312568385732,
      "grad_norm": 0.03834502026438713,
      "learning_rate": 3.64687431614268e-05,
      "loss": 0.0037,
      "step": 18550
    },
    {
      "epoch": 1.3538551316653293,
      "grad_norm": 0.23054546117782593,
      "learning_rate": 3.646144868334671e-05,
      "loss": 0.0043,
      "step": 18560
    },
    {
      "epoch": 1.3545845794733387,
      "grad_norm": 0.18671080470085144,
      "learning_rate": 3.645415420526662e-05,
      "loss": 0.0037,
      "step": 18570
    },
    {
      "epoch": 1.355314027281348,
      "grad_norm": 0.11796171218156815,
      "learning_rate": 3.644685972718652e-05,
      "loss": 0.0047,
      "step": 18580
    },
    {
      "epoch": 1.3560434750893573,
      "grad_norm": 0.29391688108444214,
      "learning_rate": 3.643956524910643e-05,
      "loss": 0.0042,
      "step": 18590
    },
    {
      "epoch": 1.3567729228973666,
      "grad_norm": 0.44697731733322144,
      "learning_rate": 3.6432270771026334e-05,
      "loss": 0.0048,
      "step": 18600
    },
    {
      "epoch": 1.357502370705376,
      "grad_norm": 0.31153151392936707,
      "learning_rate": 3.642497629294624e-05,
      "loss": 0.0046,
      "step": 18610
    },
    {
      "epoch": 1.3582318185133855,
      "grad_norm": 0.05766507610678673,
      "learning_rate": 3.641768181486615e-05,
      "loss": 0.0039,
      "step": 18620
    },
    {
      "epoch": 1.3589612663213946,
      "grad_norm": 0.30901390314102173,
      "learning_rate": 3.641038733678606e-05,
      "loss": 0.005,
      "step": 18630
    },
    {
      "epoch": 1.3596907141294041,
      "grad_norm": 0.10783233493566513,
      "learning_rate": 3.6403092858705964e-05,
      "loss": 0.0045,
      "step": 18640
    },
    {
      "epoch": 1.3604201619374134,
      "grad_norm": 0.0864420235157013,
      "learning_rate": 3.6395798380625865e-05,
      "loss": 0.0052,
      "step": 18650
    },
    {
      "epoch": 1.3611496097454228,
      "grad_norm": 0.14463812112808228,
      "learning_rate": 3.638850390254577e-05,
      "loss": 0.0057,
      "step": 18660
    },
    {
      "epoch": 1.361879057553432,
      "grad_norm": 0.12187107652425766,
      "learning_rate": 3.638120942446568e-05,
      "loss": 0.0035,
      "step": 18670
    },
    {
      "epoch": 1.3626085053614414,
      "grad_norm": 0.3186754286289215,
      "learning_rate": 3.637391494638559e-05,
      "loss": 0.0034,
      "step": 18680
    },
    {
      "epoch": 1.3633379531694507,
      "grad_norm": 0.08775675296783447,
      "learning_rate": 3.6366620468305495e-05,
      "loss": 0.0044,
      "step": 18690
    },
    {
      "epoch": 1.36406740097746,
      "grad_norm": 0.4031994640827179,
      "learning_rate": 3.63593259902254e-05,
      "loss": 0.0039,
      "step": 18700
    },
    {
      "epoch": 1.3647968487854694,
      "grad_norm": 0.03298172354698181,
      "learning_rate": 3.6352031512145304e-05,
      "loss": 0.0038,
      "step": 18710
    },
    {
      "epoch": 1.3655262965934787,
      "grad_norm": 0.3330555558204651,
      "learning_rate": 3.634473703406521e-05,
      "loss": 0.0049,
      "step": 18720
    },
    {
      "epoch": 1.366255744401488,
      "grad_norm": 0.3749534785747528,
      "learning_rate": 3.633744255598512e-05,
      "loss": 0.0047,
      "step": 18730
    },
    {
      "epoch": 1.3669851922094973,
      "grad_norm": 0.14515867829322815,
      "learning_rate": 3.633014807790503e-05,
      "loss": 0.0042,
      "step": 18740
    },
    {
      "epoch": 1.3677146400175069,
      "grad_norm": 0.4031383693218231,
      "learning_rate": 3.6322853599824934e-05,
      "loss": 0.0053,
      "step": 18750
    },
    {
      "epoch": 1.368444087825516,
      "grad_norm": 0.21633337438106537,
      "learning_rate": 3.631555912174484e-05,
      "loss": 0.0038,
      "step": 18760
    },
    {
      "epoch": 1.3691735356335255,
      "grad_norm": 0.35309508442878723,
      "learning_rate": 3.630826464366475e-05,
      "loss": 0.004,
      "step": 18770
    },
    {
      "epoch": 1.3699029834415348,
      "grad_norm": 0.044028304517269135,
      "learning_rate": 3.630097016558465e-05,
      "loss": 0.0034,
      "step": 18780
    },
    {
      "epoch": 1.3706324312495441,
      "grad_norm": 0.17348168790340424,
      "learning_rate": 3.629367568750456e-05,
      "loss": 0.0044,
      "step": 18790
    },
    {
      "epoch": 1.3713618790575535,
      "grad_norm": 0.34703099727630615,
      "learning_rate": 3.628638120942447e-05,
      "loss": 0.0042,
      "step": 18800
    },
    {
      "epoch": 1.3720913268655628,
      "grad_norm": 0.05842575058341026,
      "learning_rate": 3.627908673134437e-05,
      "loss": 0.0047,
      "step": 18810
    },
    {
      "epoch": 1.372820774673572,
      "grad_norm": 0.029967160895466805,
      "learning_rate": 3.627179225326428e-05,
      "loss": 0.0057,
      "step": 18820
    },
    {
      "epoch": 1.3735502224815814,
      "grad_norm": 0.25576478242874146,
      "learning_rate": 3.626449777518419e-05,
      "loss": 0.0049,
      "step": 18830
    },
    {
      "epoch": 1.3742796702895907,
      "grad_norm": 0.20118199288845062,
      "learning_rate": 3.6257203297104095e-05,
      "loss": 0.0045,
      "step": 18840
    },
    {
      "epoch": 1.3750091180976,
      "grad_norm": 0.5480961203575134,
      "learning_rate": 3.6249908819024e-05,
      "loss": 0.0029,
      "step": 18850
    },
    {
      "epoch": 1.3757385659056094,
      "grad_norm": 0.14425523579120636,
      "learning_rate": 3.624261434094391e-05,
      "loss": 0.0046,
      "step": 18860
    },
    {
      "epoch": 1.3764680137136187,
      "grad_norm": 0.011323475278913975,
      "learning_rate": 3.623531986286382e-05,
      "loss": 0.0041,
      "step": 18870
    },
    {
      "epoch": 1.3771974615216283,
      "grad_norm": 0.11569114774465561,
      "learning_rate": 3.622802538478372e-05,
      "loss": 0.0052,
      "step": 18880
    },
    {
      "epoch": 1.3779269093296374,
      "grad_norm": 0.17510174214839935,
      "learning_rate": 3.6220730906703626e-05,
      "loss": 0.0036,
      "step": 18890
    },
    {
      "epoch": 1.378656357137647,
      "grad_norm": 0.18985414505004883,
      "learning_rate": 3.621343642862353e-05,
      "loss": 0.0051,
      "step": 18900
    },
    {
      "epoch": 1.3793858049456562,
      "grad_norm": 0.3171117603778839,
      "learning_rate": 3.620614195054344e-05,
      "loss": 0.0053,
      "step": 18910
    },
    {
      "epoch": 1.3801152527536655,
      "grad_norm": 0.2595309615135193,
      "learning_rate": 3.619884747246335e-05,
      "loss": 0.0044,
      "step": 18920
    },
    {
      "epoch": 1.3808447005616749,
      "grad_norm": 0.11587017774581909,
      "learning_rate": 3.6191552994383256e-05,
      "loss": 0.004,
      "step": 18930
    },
    {
      "epoch": 1.3815741483696842,
      "grad_norm": 0.48265624046325684,
      "learning_rate": 3.618425851630316e-05,
      "loss": 0.0039,
      "step": 18940
    },
    {
      "epoch": 1.3823035961776935,
      "grad_norm": 0.14870338141918182,
      "learning_rate": 3.6176964038223064e-05,
      "loss": 0.0048,
      "step": 18950
    },
    {
      "epoch": 1.3830330439857028,
      "grad_norm": 0.2909524142742157,
      "learning_rate": 3.616966956014297e-05,
      "loss": 0.0053,
      "step": 18960
    },
    {
      "epoch": 1.3837624917937121,
      "grad_norm": 0.08717457205057144,
      "learning_rate": 3.6162375082062886e-05,
      "loss": 0.0051,
      "step": 18970
    },
    {
      "epoch": 1.3844919396017215,
      "grad_norm": 0.12818685173988342,
      "learning_rate": 3.615508060398279e-05,
      "loss": 0.0038,
      "step": 18980
    },
    {
      "epoch": 1.3852213874097308,
      "grad_norm": 0.08728811889886856,
      "learning_rate": 3.6147786125902694e-05,
      "loss": 0.0031,
      "step": 18990
    },
    {
      "epoch": 1.38595083521774,
      "grad_norm": 0.25921082496643066,
      "learning_rate": 3.61404916478226e-05,
      "loss": 0.0029,
      "step": 19000
    },
    {
      "epoch": 1.3866802830257496,
      "grad_norm": 0.08673784881830215,
      "learning_rate": 3.61331971697425e-05,
      "loss": 0.004,
      "step": 19010
    },
    {
      "epoch": 1.3874097308337587,
      "grad_norm": 0.21368396282196045,
      "learning_rate": 3.612590269166241e-05,
      "loss": 0.0042,
      "step": 19020
    },
    {
      "epoch": 1.3881391786417683,
      "grad_norm": 0.21392954885959625,
      "learning_rate": 3.6118608213582324e-05,
      "loss": 0.005,
      "step": 19030
    },
    {
      "epoch": 1.3888686264497776,
      "grad_norm": 0.007247552275657654,
      "learning_rate": 3.6111313735502225e-05,
      "loss": 0.0031,
      "step": 19040
    },
    {
      "epoch": 1.389598074257787,
      "grad_norm": 0.15076209604740143,
      "learning_rate": 3.610401925742213e-05,
      "loss": 0.0038,
      "step": 19050
    },
    {
      "epoch": 1.3903275220657962,
      "grad_norm": 0.34062275290489197,
      "learning_rate": 3.609672477934204e-05,
      "loss": 0.0031,
      "step": 19060
    },
    {
      "epoch": 1.3910569698738056,
      "grad_norm": 0.2307029664516449,
      "learning_rate": 3.608943030126195e-05,
      "loss": 0.0043,
      "step": 19070
    },
    {
      "epoch": 1.3917864176818149,
      "grad_norm": 0.11633836477994919,
      "learning_rate": 3.608213582318185e-05,
      "loss": 0.0053,
      "step": 19080
    },
    {
      "epoch": 1.3925158654898242,
      "grad_norm": 0.4043305516242981,
      "learning_rate": 3.607484134510176e-05,
      "loss": 0.0048,
      "step": 19090
    },
    {
      "epoch": 1.3932453132978335,
      "grad_norm": 0.11567451804876328,
      "learning_rate": 3.606754686702167e-05,
      "loss": 0.0042,
      "step": 19100
    },
    {
      "epoch": 1.3939747611058428,
      "grad_norm": 0.23122672736644745,
      "learning_rate": 3.606025238894157e-05,
      "loss": 0.0046,
      "step": 19110
    },
    {
      "epoch": 1.3947042089138522,
      "grad_norm": 0.2898927330970764,
      "learning_rate": 3.605295791086148e-05,
      "loss": 0.006,
      "step": 19120
    },
    {
      "epoch": 1.3954336567218615,
      "grad_norm": 0.23146222531795502,
      "learning_rate": 3.6045663432781386e-05,
      "loss": 0.0043,
      "step": 19130
    },
    {
      "epoch": 1.396163104529871,
      "grad_norm": 0.2300177812576294,
      "learning_rate": 3.6038368954701294e-05,
      "loss": 0.0044,
      "step": 19140
    },
    {
      "epoch": 1.3968925523378801,
      "grad_norm": 0.08607575297355652,
      "learning_rate": 3.60310744766212e-05,
      "loss": 0.0039,
      "step": 19150
    },
    {
      "epoch": 1.3976220001458897,
      "grad_norm": 0.05827225372195244,
      "learning_rate": 3.602377999854111e-05,
      "loss": 0.0052,
      "step": 19160
    },
    {
      "epoch": 1.3983514479538988,
      "grad_norm": 0.19286713004112244,
      "learning_rate": 3.6016485520461016e-05,
      "loss": 0.0045,
      "step": 19170
    },
    {
      "epoch": 1.3990808957619083,
      "grad_norm": 0.11641455441713333,
      "learning_rate": 3.600919104238092e-05,
      "loss": 0.0039,
      "step": 19180
    },
    {
      "epoch": 1.3998103435699176,
      "grad_norm": 0.40369904041290283,
      "learning_rate": 3.6001896564300824e-05,
      "loss": 0.0054,
      "step": 19190
    },
    {
      "epoch": 1.400539791377927,
      "grad_norm": 0.24539653956890106,
      "learning_rate": 3.599460208622073e-05,
      "loss": 0.0059,
      "step": 19200
    },
    {
      "epoch": 1.4012692391859363,
      "grad_norm": 0.5472742915153503,
      "learning_rate": 3.598730760814064e-05,
      "loss": 0.0036,
      "step": 19210
    },
    {
      "epoch": 1.4019986869939456,
      "grad_norm": 0.43236181139945984,
      "learning_rate": 3.598001313006055e-05,
      "loss": 0.0048,
      "step": 19220
    },
    {
      "epoch": 1.402728134801955,
      "grad_norm": 0.24609604477882385,
      "learning_rate": 3.5972718651980455e-05,
      "loss": 0.0061,
      "step": 19230
    },
    {
      "epoch": 1.4034575826099642,
      "grad_norm": 0.1159077137708664,
      "learning_rate": 3.5965424173900355e-05,
      "loss": 0.0047,
      "step": 19240
    },
    {
      "epoch": 1.4041870304179735,
      "grad_norm": 0.25931617617607117,
      "learning_rate": 3.595812969582026e-05,
      "loss": 0.0035,
      "step": 19250
    },
    {
      "epoch": 1.4049164782259829,
      "grad_norm": 0.143910750746727,
      "learning_rate": 3.595083521774017e-05,
      "loss": 0.0032,
      "step": 19260
    },
    {
      "epoch": 1.4056459260339922,
      "grad_norm": 0.2926802337169647,
      "learning_rate": 3.594354073966008e-05,
      "loss": 0.0047,
      "step": 19270
    },
    {
      "epoch": 1.4063753738420015,
      "grad_norm": 0.23105938732624054,
      "learning_rate": 3.5936246261579985e-05,
      "loss": 0.0038,
      "step": 19280
    },
    {
      "epoch": 1.407104821650011,
      "grad_norm": 0.27293840050697327,
      "learning_rate": 3.592895178349989e-05,
      "loss": 0.0047,
      "step": 19290
    },
    {
      "epoch": 1.4078342694580201,
      "grad_norm": 0.14432546496391296,
      "learning_rate": 3.59216573054198e-05,
      "loss": 0.0056,
      "step": 19300
    },
    {
      "epoch": 1.4085637172660297,
      "grad_norm": 0.05758396163582802,
      "learning_rate": 3.59143628273397e-05,
      "loss": 0.0038,
      "step": 19310
    },
    {
      "epoch": 1.409293165074039,
      "grad_norm": 0.058377377688884735,
      "learning_rate": 3.5907068349259616e-05,
      "loss": 0.0041,
      "step": 19320
    },
    {
      "epoch": 1.4100226128820483,
      "grad_norm": 0.2614947259426117,
      "learning_rate": 3.589977387117952e-05,
      "loss": 0.0044,
      "step": 19330
    },
    {
      "epoch": 1.4107520606900577,
      "grad_norm": 0.0585586242377758,
      "learning_rate": 3.5892479393099424e-05,
      "loss": 0.0032,
      "step": 19340
    },
    {
      "epoch": 1.411481508498067,
      "grad_norm": 0.17481786012649536,
      "learning_rate": 3.588518491501933e-05,
      "loss": 0.004,
      "step": 19350
    },
    {
      "epoch": 1.4122109563060763,
      "grad_norm": 0.2313796877861023,
      "learning_rate": 3.587789043693924e-05,
      "loss": 0.0049,
      "step": 19360
    },
    {
      "epoch": 1.4129404041140856,
      "grad_norm": 0.08777003735303879,
      "learning_rate": 3.5870595958859146e-05,
      "loss": 0.0043,
      "step": 19370
    },
    {
      "epoch": 1.413669851922095,
      "grad_norm": 0.43390509486198425,
      "learning_rate": 3.5863301480779054e-05,
      "loss": 0.0044,
      "step": 19380
    },
    {
      "epoch": 1.4143992997301043,
      "grad_norm": 0.31735897064208984,
      "learning_rate": 3.585600700269896e-05,
      "loss": 0.0048,
      "step": 19390
    },
    {
      "epoch": 1.4151287475381136,
      "grad_norm": 0.3209523856639862,
      "learning_rate": 3.584871252461887e-05,
      "loss": 0.0058,
      "step": 19400
    },
    {
      "epoch": 1.415858195346123,
      "grad_norm": 0.31115517020225525,
      "learning_rate": 3.584141804653877e-05,
      "loss": 0.0037,
      "step": 19410
    },
    {
      "epoch": 1.4165876431541324,
      "grad_norm": 0.04158472269773483,
      "learning_rate": 3.583412356845868e-05,
      "loss": 0.0032,
      "step": 19420
    },
    {
      "epoch": 1.4173170909621415,
      "grad_norm": 0.031092768535017967,
      "learning_rate": 3.5826829090378585e-05,
      "loss": 0.0036,
      "step": 19430
    },
    {
      "epoch": 1.418046538770151,
      "grad_norm": 0.02968577668070793,
      "learning_rate": 3.581953461229849e-05,
      "loss": 0.0049,
      "step": 19440
    },
    {
      "epoch": 1.4187759865781604,
      "grad_norm": 0.37676340341567993,
      "learning_rate": 3.58122401342184e-05,
      "loss": 0.0044,
      "step": 19450
    },
    {
      "epoch": 1.4195054343861697,
      "grad_norm": 0.118032306432724,
      "learning_rate": 3.580494565613831e-05,
      "loss": 0.0038,
      "step": 19460
    },
    {
      "epoch": 1.420234882194179,
      "grad_norm": 0.23163661360740662,
      "learning_rate": 3.579765117805821e-05,
      "loss": 0.0047,
      "step": 19470
    },
    {
      "epoch": 1.4209643300021884,
      "grad_norm": 0.39187026023864746,
      "learning_rate": 3.5790356699978116e-05,
      "loss": 0.0051,
      "step": 19480
    },
    {
      "epoch": 1.4216937778101977,
      "grad_norm": 0.0307492446154356,
      "learning_rate": 3.578306222189802e-05,
      "loss": 0.0036,
      "step": 19490
    },
    {
      "epoch": 1.422423225618207,
      "grad_norm": 0.3956350088119507,
      "learning_rate": 3.577576774381793e-05,
      "loss": 0.0032,
      "step": 19500
    },
    {
      "epoch": 1.4231526734262163,
      "grad_norm": 0.11621242016553879,
      "learning_rate": 3.576847326573784e-05,
      "loss": 0.0037,
      "step": 19510
    },
    {
      "epoch": 1.4238821212342256,
      "grad_norm": 0.06060640513896942,
      "learning_rate": 3.5761178787657746e-05,
      "loss": 0.0046,
      "step": 19520
    },
    {
      "epoch": 1.424611569042235,
      "grad_norm": 0.23093192279338837,
      "learning_rate": 3.575388430957765e-05,
      "loss": 0.0049,
      "step": 19530
    },
    {
      "epoch": 1.4253410168502443,
      "grad_norm": 0.3289535343647003,
      "learning_rate": 3.5746589831497554e-05,
      "loss": 0.0042,
      "step": 19540
    },
    {
      "epoch": 1.4260704646582538,
      "grad_norm": 0.3463056683540344,
      "learning_rate": 3.573929535341746e-05,
      "loss": 0.0041,
      "step": 19550
    },
    {
      "epoch": 1.426799912466263,
      "grad_norm": 0.36694231629371643,
      "learning_rate": 3.5732000875337376e-05,
      "loss": 0.005,
      "step": 19560
    },
    {
      "epoch": 1.4275293602742725,
      "grad_norm": 0.02942132204771042,
      "learning_rate": 3.572470639725728e-05,
      "loss": 0.0053,
      "step": 19570
    },
    {
      "epoch": 1.4282588080822818,
      "grad_norm": 0.11665874719619751,
      "learning_rate": 3.5717411919177184e-05,
      "loss": 0.0041,
      "step": 19580
    },
    {
      "epoch": 1.428988255890291,
      "grad_norm": 0.1727149337530136,
      "learning_rate": 3.571011744109709e-05,
      "loss": 0.0039,
      "step": 19590
    },
    {
      "epoch": 1.4297177036983004,
      "grad_norm": 0.03318125382065773,
      "learning_rate": 3.5702822963017e-05,
      "loss": 0.0036,
      "step": 19600
    },
    {
      "epoch": 1.4304471515063097,
      "grad_norm": 0.030672473832964897,
      "learning_rate": 3.56955284849369e-05,
      "loss": 0.0054,
      "step": 19610
    },
    {
      "epoch": 1.431176599314319,
      "grad_norm": 0.22804631292819977,
      "learning_rate": 3.5688234006856814e-05,
      "loss": 0.0048,
      "step": 19620
    },
    {
      "epoch": 1.4319060471223284,
      "grad_norm": 0.11612479388713837,
      "learning_rate": 3.568093952877672e-05,
      "loss": 0.0036,
      "step": 19630
    },
    {
      "epoch": 1.4326354949303377,
      "grad_norm": 0.11523201316595078,
      "learning_rate": 3.567364505069662e-05,
      "loss": 0.0043,
      "step": 19640
    },
    {
      "epoch": 1.433364942738347,
      "grad_norm": 0.45979470014572144,
      "learning_rate": 3.566635057261653e-05,
      "loss": 0.0036,
      "step": 19650
    },
    {
      "epoch": 1.4340943905463563,
      "grad_norm": 0.039706844836473465,
      "learning_rate": 3.565905609453644e-05,
      "loss": 0.0049,
      "step": 19660
    },
    {
      "epoch": 1.4348238383543657,
      "grad_norm": 0.28821149468421936,
      "learning_rate": 3.565176161645634e-05,
      "loss": 0.004,
      "step": 19670
    },
    {
      "epoch": 1.4355532861623752,
      "grad_norm": 0.3179345428943634,
      "learning_rate": 3.564446713837625e-05,
      "loss": 0.0054,
      "step": 19680
    },
    {
      "epoch": 1.4362827339703843,
      "grad_norm": 0.012544051744043827,
      "learning_rate": 3.563717266029616e-05,
      "loss": 0.0046,
      "step": 19690
    },
    {
      "epoch": 1.4370121817783938,
      "grad_norm": 0.2601124048233032,
      "learning_rate": 3.562987818221606e-05,
      "loss": 0.0029,
      "step": 19700
    },
    {
      "epoch": 1.4377416295864032,
      "grad_norm": 0.14442653954029083,
      "learning_rate": 3.562258370413597e-05,
      "loss": 0.0036,
      "step": 19710
    },
    {
      "epoch": 1.4384710773944125,
      "grad_norm": 0.6925894021987915,
      "learning_rate": 3.5615289226055876e-05,
      "loss": 0.0058,
      "step": 19720
    },
    {
      "epoch": 1.4392005252024218,
      "grad_norm": 0.40387237071990967,
      "learning_rate": 3.5607994747975784e-05,
      "loss": 0.0036,
      "step": 19730
    },
    {
      "epoch": 1.4399299730104311,
      "grad_norm": 0.14549432694911957,
      "learning_rate": 3.560070026989569e-05,
      "loss": 0.0058,
      "step": 19740
    },
    {
      "epoch": 1.4406594208184405,
      "grad_norm": 0.29565227031707764,
      "learning_rate": 3.55934057918156e-05,
      "loss": 0.0026,
      "step": 19750
    },
    {
      "epoch": 1.4413888686264498,
      "grad_norm": 0.05805683881044388,
      "learning_rate": 3.5586111313735506e-05,
      "loss": 0.0043,
      "step": 19760
    },
    {
      "epoch": 1.442118316434459,
      "grad_norm": 0.28660848736763,
      "learning_rate": 3.557881683565541e-05,
      "loss": 0.006,
      "step": 19770
    },
    {
      "epoch": 1.4428477642424684,
      "grad_norm": 0.17272913455963135,
      "learning_rate": 3.5571522357575314e-05,
      "loss": 0.0036,
      "step": 19780
    },
    {
      "epoch": 1.4435772120504777,
      "grad_norm": 0.4931589961051941,
      "learning_rate": 3.556422787949522e-05,
      "loss": 0.0055,
      "step": 19790
    },
    {
      "epoch": 1.444306659858487,
      "grad_norm": 0.2220163345336914,
      "learning_rate": 3.555693340141513e-05,
      "loss": 0.0051,
      "step": 19800
    },
    {
      "epoch": 1.4450361076664966,
      "grad_norm": 0.523369550704956,
      "learning_rate": 3.554963892333504e-05,
      "loss": 0.0039,
      "step": 19810
    },
    {
      "epoch": 1.4457655554745057,
      "grad_norm": 0.05816463381052017,
      "learning_rate": 3.5542344445254945e-05,
      "loss": 0.0037,
      "step": 19820
    },
    {
      "epoch": 1.4464950032825152,
      "grad_norm": 0.2884639799594879,
      "learning_rate": 3.553504996717485e-05,
      "loss": 0.004,
      "step": 19830
    },
    {
      "epoch": 1.4472244510905246,
      "grad_norm": 0.009437216445803642,
      "learning_rate": 3.552775548909475e-05,
      "loss": 0.0053,
      "step": 19840
    },
    {
      "epoch": 1.4479538988985339,
      "grad_norm": 0.2607556879520416,
      "learning_rate": 3.552046101101467e-05,
      "loss": 0.0034,
      "step": 19850
    },
    {
      "epoch": 1.4486833467065432,
      "grad_norm": 0.23588843643665314,
      "learning_rate": 3.5513166532934575e-05,
      "loss": 0.0039,
      "step": 19860
    },
    {
      "epoch": 1.4494127945145525,
      "grad_norm": 0.2303023785352707,
      "learning_rate": 3.5505872054854475e-05,
      "loss": 0.006,
      "step": 19870
    },
    {
      "epoch": 1.4501422423225618,
      "grad_norm": 0.20261691510677338,
      "learning_rate": 3.549857757677438e-05,
      "loss": 0.003,
      "step": 19880
    },
    {
      "epoch": 1.4508716901305712,
      "grad_norm": 0.30419763922691345,
      "learning_rate": 3.549128309869429e-05,
      "loss": 0.0045,
      "step": 19890
    },
    {
      "epoch": 1.4516011379385805,
      "grad_norm": 0.31807661056518555,
      "learning_rate": 3.54839886206142e-05,
      "loss": 0.0032,
      "step": 19900
    },
    {
      "epoch": 1.4523305857465898,
      "grad_norm": 0.19947361946105957,
      "learning_rate": 3.5476694142534106e-05,
      "loss": 0.0049,
      "step": 19910
    },
    {
      "epoch": 1.4530600335545991,
      "grad_norm": 0.11593268811702728,
      "learning_rate": 3.546939966445401e-05,
      "loss": 0.0052,
      "step": 19920
    },
    {
      "epoch": 1.4537894813626084,
      "grad_norm": 0.3112054765224457,
      "learning_rate": 3.546210518637392e-05,
      "loss": 0.0044,
      "step": 19930
    },
    {
      "epoch": 1.454518929170618,
      "grad_norm": 0.20230582356452942,
      "learning_rate": 3.545481070829382e-05,
      "loss": 0.0047,
      "step": 19940
    },
    {
      "epoch": 1.455248376978627,
      "grad_norm": 0.2309807389974594,
      "learning_rate": 3.544751623021373e-05,
      "loss": 0.0035,
      "step": 19950
    },
    {
      "epoch": 1.4559778247866366,
      "grad_norm": 0.20332196354866028,
      "learning_rate": 3.5440221752133636e-05,
      "loss": 0.0031,
      "step": 19960
    },
    {
      "epoch": 1.4567072725946457,
      "grad_norm": 0.593285083770752,
      "learning_rate": 3.5432927274053544e-05,
      "loss": 0.0028,
      "step": 19970
    },
    {
      "epoch": 1.4574367204026553,
      "grad_norm": 0.375647634267807,
      "learning_rate": 3.542563279597345e-05,
      "loss": 0.0044,
      "step": 19980
    },
    {
      "epoch": 1.4581661682106646,
      "grad_norm": 0.1452701985836029,
      "learning_rate": 3.541833831789336e-05,
      "loss": 0.0046,
      "step": 19990
    },
    {
      "epoch": 1.458895616018674,
      "grad_norm": 0.28760826587677,
      "learning_rate": 3.541104383981326e-05,
      "loss": 0.0042,
      "step": 20000
    },
    {
      "epoch": 1.4596250638266832,
      "grad_norm": 0.29151251912117004,
      "learning_rate": 3.540374936173317e-05,
      "loss": 0.005,
      "step": 20010
    },
    {
      "epoch": 1.4603545116346925,
      "grad_norm": 0.37046945095062256,
      "learning_rate": 3.5396454883653075e-05,
      "loss": 0.0059,
      "step": 20020
    },
    {
      "epoch": 1.4610839594427019,
      "grad_norm": 0.5491164326667786,
      "learning_rate": 3.538916040557298e-05,
      "loss": 0.0063,
      "step": 20030
    },
    {
      "epoch": 1.4618134072507112,
      "grad_norm": 0.23169060051441193,
      "learning_rate": 3.538186592749289e-05,
      "loss": 0.0033,
      "step": 20040
    },
    {
      "epoch": 1.4625428550587205,
      "grad_norm": 0.49071457982063293,
      "learning_rate": 3.53745714494128e-05,
      "loss": 0.0034,
      "step": 20050
    },
    {
      "epoch": 1.4632723028667298,
      "grad_norm": 0.17483188211917877,
      "learning_rate": 3.5367276971332705e-05,
      "loss": 0.0052,
      "step": 20060
    },
    {
      "epoch": 1.4640017506747391,
      "grad_norm": 0.3470975458621979,
      "learning_rate": 3.5359982493252606e-05,
      "loss": 0.0052,
      "step": 20070
    },
    {
      "epoch": 1.4647311984827485,
      "grad_norm": 0.11603260785341263,
      "learning_rate": 3.535268801517251e-05,
      "loss": 0.0052,
      "step": 20080
    },
    {
      "epoch": 1.465460646290758,
      "grad_norm": 0.11606186628341675,
      "learning_rate": 3.534539353709243e-05,
      "loss": 0.0038,
      "step": 20090
    },
    {
      "epoch": 1.466190094098767,
      "grad_norm": 0.20253624022006989,
      "learning_rate": 3.533809905901233e-05,
      "loss": 0.0046,
      "step": 20100
    },
    {
      "epoch": 1.4669195419067766,
      "grad_norm": 0.030391691252589226,
      "learning_rate": 3.5330804580932236e-05,
      "loss": 0.0049,
      "step": 20110
    },
    {
      "epoch": 1.467648989714786,
      "grad_norm": 0.28871220350265503,
      "learning_rate": 3.532351010285214e-05,
      "loss": 0.0042,
      "step": 20120
    },
    {
      "epoch": 1.4683784375227953,
      "grad_norm": 0.418303519487381,
      "learning_rate": 3.531621562477205e-05,
      "loss": 0.0047,
      "step": 20130
    },
    {
      "epoch": 1.4691078853308046,
      "grad_norm": 0.009875993244349957,
      "learning_rate": 3.530892114669195e-05,
      "loss": 0.0056,
      "step": 20140
    },
    {
      "epoch": 1.469837333138814,
      "grad_norm": 0.20217204093933105,
      "learning_rate": 3.5301626668611866e-05,
      "loss": 0.005,
      "step": 20150
    },
    {
      "epoch": 1.4705667809468232,
      "grad_norm": 0.11548405140638351,
      "learning_rate": 3.5294332190531774e-05,
      "loss": 0.0035,
      "step": 20160
    },
    {
      "epoch": 1.4712962287548326,
      "grad_norm": 0.35044223070144653,
      "learning_rate": 3.5287037712451674e-05,
      "loss": 0.0053,
      "step": 20170
    },
    {
      "epoch": 1.472025676562842,
      "grad_norm": 0.31643152236938477,
      "learning_rate": 3.527974323437158e-05,
      "loss": 0.0048,
      "step": 20180
    },
    {
      "epoch": 1.4727551243708512,
      "grad_norm": 0.34623217582702637,
      "learning_rate": 3.527244875629149e-05,
      "loss": 0.0029,
      "step": 20190
    },
    {
      "epoch": 1.4734845721788605,
      "grad_norm": 0.17267026007175446,
      "learning_rate": 3.526515427821139e-05,
      "loss": 0.0031,
      "step": 20200
    },
    {
      "epoch": 1.4742140199868699,
      "grad_norm": 0.0870736688375473,
      "learning_rate": 3.5257859800131304e-05,
      "loss": 0.0061,
      "step": 20210
    },
    {
      "epoch": 1.4749434677948794,
      "grad_norm": 0.173756405711174,
      "learning_rate": 3.525056532205121e-05,
      "loss": 0.0034,
      "step": 20220
    },
    {
      "epoch": 1.4756729156028885,
      "grad_norm": 0.34866052865982056,
      "learning_rate": 3.524327084397111e-05,
      "loss": 0.0044,
      "step": 20230
    },
    {
      "epoch": 1.476402363410898,
      "grad_norm": 0.6639533042907715,
      "learning_rate": 3.523597636589102e-05,
      "loss": 0.0064,
      "step": 20240
    },
    {
      "epoch": 1.4771318112189074,
      "grad_norm": 0.5098307132720947,
      "learning_rate": 3.522868188781093e-05,
      "loss": 0.0061,
      "step": 20250
    },
    {
      "epoch": 1.4778612590269167,
      "grad_norm": 0.1442067176103592,
      "learning_rate": 3.5221387409730835e-05,
      "loss": 0.0049,
      "step": 20260
    },
    {
      "epoch": 1.478590706834926,
      "grad_norm": 0.030983883887529373,
      "learning_rate": 3.521409293165074e-05,
      "loss": 0.0044,
      "step": 20270
    },
    {
      "epoch": 1.4793201546429353,
      "grad_norm": 0.275949090719223,
      "learning_rate": 3.520679845357065e-05,
      "loss": 0.0046,
      "step": 20280
    },
    {
      "epoch": 1.4800496024509446,
      "grad_norm": 0.11494220048189163,
      "learning_rate": 3.519950397549056e-05,
      "loss": 0.0032,
      "step": 20290
    },
    {
      "epoch": 1.480779050258954,
      "grad_norm": 0.43934428691864014,
      "learning_rate": 3.519220949741046e-05,
      "loss": 0.0038,
      "step": 20300
    },
    {
      "epoch": 1.4815084980669633,
      "grad_norm": 0.20148742198944092,
      "learning_rate": 3.5184915019330366e-05,
      "loss": 0.0035,
      "step": 20310
    },
    {
      "epoch": 1.4822379458749726,
      "grad_norm": 0.08776035159826279,
      "learning_rate": 3.517762054125028e-05,
      "loss": 0.0038,
      "step": 20320
    },
    {
      "epoch": 1.482967393682982,
      "grad_norm": 0.17308349907398224,
      "learning_rate": 3.517032606317018e-05,
      "loss": 0.0043,
      "step": 20330
    },
    {
      "epoch": 1.4836968414909912,
      "grad_norm": 0.3453640043735504,
      "learning_rate": 3.516303158509009e-05,
      "loss": 0.0033,
      "step": 20340
    },
    {
      "epoch": 1.4844262892990008,
      "grad_norm": 0.08934549987316132,
      "learning_rate": 3.5155737107009996e-05,
      "loss": 0.0042,
      "step": 20350
    },
    {
      "epoch": 1.4851557371070099,
      "grad_norm": 0.02991270273923874,
      "learning_rate": 3.5148442628929904e-05,
      "loss": 0.005,
      "step": 20360
    },
    {
      "epoch": 1.4858851849150194,
      "grad_norm": 0.3319908380508423,
      "learning_rate": 3.5141148150849805e-05,
      "loss": 0.0039,
      "step": 20370
    },
    {
      "epoch": 1.4866146327230287,
      "grad_norm": 0.1730940341949463,
      "learning_rate": 3.513385367276972e-05,
      "loss": 0.0037,
      "step": 20380
    },
    {
      "epoch": 1.487344080531038,
      "grad_norm": 0.28172755241394043,
      "learning_rate": 3.5126559194689626e-05,
      "loss": 0.005,
      "step": 20390
    },
    {
      "epoch": 1.4880735283390474,
      "grad_norm": 0.3450360596179962,
      "learning_rate": 3.511926471660953e-05,
      "loss": 0.0057,
      "step": 20400
    },
    {
      "epoch": 1.4888029761470567,
      "grad_norm": 0.2120339572429657,
      "learning_rate": 3.5111970238529435e-05,
      "loss": 0.0041,
      "step": 20410
    },
    {
      "epoch": 1.489532423955066,
      "grad_norm": 0.2171848565340042,
      "learning_rate": 3.510467576044934e-05,
      "loss": 0.0044,
      "step": 20420
    },
    {
      "epoch": 1.4902618717630753,
      "grad_norm": 0.663935661315918,
      "learning_rate": 3.509738128236924e-05,
      "loss": 0.0039,
      "step": 20430
    },
    {
      "epoch": 1.4909913195710847,
      "grad_norm": 0.2094319611787796,
      "learning_rate": 3.509008680428916e-05,
      "loss": 0.0041,
      "step": 20440
    },
    {
      "epoch": 1.491720767379094,
      "grad_norm": 0.20307227969169617,
      "learning_rate": 3.5082792326209065e-05,
      "loss": 0.0039,
      "step": 20450
    },
    {
      "epoch": 1.4924502151871033,
      "grad_norm": 0.02996855601668358,
      "learning_rate": 3.5075497848128966e-05,
      "loss": 0.0047,
      "step": 20460
    },
    {
      "epoch": 1.4931796629951126,
      "grad_norm": 0.05837702378630638,
      "learning_rate": 3.506820337004887e-05,
      "loss": 0.0049,
      "step": 20470
    },
    {
      "epoch": 1.4939091108031222,
      "grad_norm": 0.28879719972610474,
      "learning_rate": 3.506090889196878e-05,
      "loss": 0.0048,
      "step": 20480
    },
    {
      "epoch": 1.4946385586111313,
      "grad_norm": 0.11583361029624939,
      "learning_rate": 3.505361441388869e-05,
      "loss": 0.0029,
      "step": 20490
    },
    {
      "epoch": 1.4953680064191408,
      "grad_norm": 0.11702849715948105,
      "learning_rate": 3.5046319935808596e-05,
      "loss": 0.0035,
      "step": 20500
    },
    {
      "epoch": 1.4960974542271501,
      "grad_norm": 0.0077295973896980286,
      "learning_rate": 3.50390254577285e-05,
      "loss": 0.0057,
      "step": 20510
    },
    {
      "epoch": 1.4968269020351594,
      "grad_norm": 0.031159376725554466,
      "learning_rate": 3.503173097964841e-05,
      "loss": 0.0049,
      "step": 20520
    },
    {
      "epoch": 1.4975563498431688,
      "grad_norm": 0.17360913753509521,
      "learning_rate": 3.502443650156831e-05,
      "loss": 0.004,
      "step": 20530
    },
    {
      "epoch": 1.498285797651178,
      "grad_norm": 0.14387181401252747,
      "learning_rate": 3.501714202348822e-05,
      "loss": 0.0033,
      "step": 20540
    },
    {
      "epoch": 1.4990152454591874,
      "grad_norm": 0.31710490584373474,
      "learning_rate": 3.5009847545408127e-05,
      "loss": 0.0062,
      "step": 20550
    },
    {
      "epoch": 1.4997446932671967,
      "grad_norm": 0.3703271150588989,
      "learning_rate": 3.5002553067328034e-05,
      "loss": 0.0056,
      "step": 20560
    },
    {
      "epoch": 1.500474141075206,
      "grad_norm": 0.14502553641796112,
      "learning_rate": 3.499525858924794e-05,
      "loss": 0.0058,
      "step": 20570
    },
    {
      "epoch": 1.5012035888832154,
      "grad_norm": 0.17316806316375732,
      "learning_rate": 3.498796411116785e-05,
      "loss": 0.0047,
      "step": 20580
    },
    {
      "epoch": 1.5019330366912247,
      "grad_norm": 0.23253878951072693,
      "learning_rate": 3.498066963308776e-05,
      "loss": 0.0047,
      "step": 20590
    },
    {
      "epoch": 1.502662484499234,
      "grad_norm": 0.033843111246824265,
      "learning_rate": 3.497337515500766e-05,
      "loss": 0.0042,
      "step": 20600
    },
    {
      "epoch": 1.5033919323072436,
      "grad_norm": 0.029326453804969788,
      "learning_rate": 3.4966080676927565e-05,
      "loss": 0.0035,
      "step": 20610
    },
    {
      "epoch": 1.5041213801152526,
      "grad_norm": 0.2018442153930664,
      "learning_rate": 3.495878619884748e-05,
      "loss": 0.0057,
      "step": 20620
    },
    {
      "epoch": 1.5048508279232622,
      "grad_norm": 0.20277628302574158,
      "learning_rate": 3.495149172076738e-05,
      "loss": 0.0051,
      "step": 20630
    },
    {
      "epoch": 1.5055802757312713,
      "grad_norm": 0.029734481126070023,
      "learning_rate": 3.494419724268729e-05,
      "loss": 0.0049,
      "step": 20640
    },
    {
      "epoch": 1.5063097235392808,
      "grad_norm": 0.20277735590934753,
      "learning_rate": 3.4936902764607195e-05,
      "loss": 0.0049,
      "step": 20650
    },
    {
      "epoch": 1.5070391713472902,
      "grad_norm": 0.06132641062140465,
      "learning_rate": 3.4929608286527096e-05,
      "loss": 0.0047,
      "step": 20660
    },
    {
      "epoch": 1.5077686191552995,
      "grad_norm": 0.417682945728302,
      "learning_rate": 3.4922313808447e-05,
      "loss": 0.0046,
      "step": 20670
    },
    {
      "epoch": 1.5084980669633088,
      "grad_norm": 0.30031219124794006,
      "learning_rate": 3.491501933036692e-05,
      "loss": 0.0057,
      "step": 20680
    },
    {
      "epoch": 1.5092275147713181,
      "grad_norm": 0.029229221865534782,
      "learning_rate": 3.490772485228682e-05,
      "loss": 0.0033,
      "step": 20690
    },
    {
      "epoch": 1.5099569625793274,
      "grad_norm": 0.05927920714020729,
      "learning_rate": 3.4900430374206726e-05,
      "loss": 0.0035,
      "step": 20700
    },
    {
      "epoch": 1.5106864103873368,
      "grad_norm": 0.11684207618236542,
      "learning_rate": 3.4893135896126633e-05,
      "loss": 0.0052,
      "step": 20710
    },
    {
      "epoch": 1.511415858195346,
      "grad_norm": 0.058291781693696976,
      "learning_rate": 3.488584141804654e-05,
      "loss": 0.0045,
      "step": 20720
    },
    {
      "epoch": 1.5121453060033554,
      "grad_norm": 0.020057355985045433,
      "learning_rate": 3.487854693996644e-05,
      "loss": 0.0049,
      "step": 20730
    },
    {
      "epoch": 1.512874753811365,
      "grad_norm": 0.08735613524913788,
      "learning_rate": 3.4871252461886356e-05,
      "loss": 0.0053,
      "step": 20740
    },
    {
      "epoch": 1.513604201619374,
      "grad_norm": 0.3169763386249542,
      "learning_rate": 3.4863957983806264e-05,
      "loss": 0.0054,
      "step": 20750
    },
    {
      "epoch": 1.5143336494273836,
      "grad_norm": 0.029351724311709404,
      "learning_rate": 3.4856663505726164e-05,
      "loss": 0.0056,
      "step": 20760
    },
    {
      "epoch": 1.5150630972353927,
      "grad_norm": 0.14385107159614563,
      "learning_rate": 3.484936902764607e-05,
      "loss": 0.0037,
      "step": 20770
    },
    {
      "epoch": 1.5157925450434022,
      "grad_norm": 0.5376380085945129,
      "learning_rate": 3.484207454956598e-05,
      "loss": 0.0038,
      "step": 20780
    },
    {
      "epoch": 1.5165219928514113,
      "grad_norm": 0.3463744521141052,
      "learning_rate": 3.483478007148589e-05,
      "loss": 0.0058,
      "step": 20790
    },
    {
      "epoch": 1.5172514406594209,
      "grad_norm": 0.31783291697502136,
      "learning_rate": 3.4827485593405794e-05,
      "loss": 0.003,
      "step": 20800
    },
    {
      "epoch": 1.5179808884674302,
      "grad_norm": 0.17330025136470795,
      "learning_rate": 3.48201911153257e-05,
      "loss": 0.0042,
      "step": 20810
    },
    {
      "epoch": 1.5187103362754395,
      "grad_norm": 0.315393328666687,
      "learning_rate": 3.481289663724561e-05,
      "loss": 0.0045,
      "step": 20820
    },
    {
      "epoch": 1.5194397840834488,
      "grad_norm": 0.5180657505989075,
      "learning_rate": 3.480560215916551e-05,
      "loss": 0.0048,
      "step": 20830
    },
    {
      "epoch": 1.5201692318914581,
      "grad_norm": 0.14385686814785004,
      "learning_rate": 3.479830768108542e-05,
      "loss": 0.0044,
      "step": 20840
    },
    {
      "epoch": 1.5208986796994675,
      "grad_norm": 0.25949594378471375,
      "learning_rate": 3.479101320300533e-05,
      "loss": 0.003,
      "step": 20850
    },
    {
      "epoch": 1.5216281275074768,
      "grad_norm": 0.030227744951844215,
      "learning_rate": 3.478371872492523e-05,
      "loss": 0.0038,
      "step": 20860
    },
    {
      "epoch": 1.5223575753154863,
      "grad_norm": 0.6613828539848328,
      "learning_rate": 3.477642424684514e-05,
      "loss": 0.0049,
      "step": 20870
    },
    {
      "epoch": 1.5230870231234954,
      "grad_norm": 0.20100705325603485,
      "learning_rate": 3.476912976876505e-05,
      "loss": 0.0038,
      "step": 20880
    },
    {
      "epoch": 1.523816470931505,
      "grad_norm": 0.5189695358276367,
      "learning_rate": 3.4761835290684955e-05,
      "loss": 0.0038,
      "step": 20890
    },
    {
      "epoch": 1.524545918739514,
      "grad_norm": 0.03045590966939926,
      "learning_rate": 3.4754540812604856e-05,
      "loss": 0.0042,
      "step": 20900
    },
    {
      "epoch": 1.5252753665475236,
      "grad_norm": 0.14473164081573486,
      "learning_rate": 3.474724633452477e-05,
      "loss": 0.0059,
      "step": 20910
    },
    {
      "epoch": 1.5260048143555327,
      "grad_norm": 0.05800127610564232,
      "learning_rate": 3.473995185644468e-05,
      "loss": 0.0037,
      "step": 20920
    },
    {
      "epoch": 1.5267342621635422,
      "grad_norm": 0.05826905742287636,
      "learning_rate": 3.473265737836458e-05,
      "loss": 0.0041,
      "step": 20930
    },
    {
      "epoch": 1.5274637099715516,
      "grad_norm": 0.12494727224111557,
      "learning_rate": 3.4725362900284486e-05,
      "loss": 0.0048,
      "step": 20940
    },
    {
      "epoch": 1.5281931577795609,
      "grad_norm": 0.031202860176563263,
      "learning_rate": 3.4718068422204394e-05,
      "loss": 0.004,
      "step": 20950
    },
    {
      "epoch": 1.5289226055875702,
      "grad_norm": 0.33036598563194275,
      "learning_rate": 3.4710773944124295e-05,
      "loss": 0.0051,
      "step": 20960
    },
    {
      "epoch": 1.5296520533955795,
      "grad_norm": 0.08730432391166687,
      "learning_rate": 3.470347946604421e-05,
      "loss": 0.0046,
      "step": 20970
    },
    {
      "epoch": 1.5303815012035888,
      "grad_norm": 0.21198800206184387,
      "learning_rate": 3.4696184987964116e-05,
      "loss": 0.0036,
      "step": 20980
    },
    {
      "epoch": 1.5311109490115982,
      "grad_norm": 0.1447334736585617,
      "learning_rate": 3.468889050988402e-05,
      "loss": 0.0048,
      "step": 20990
    },
    {
      "epoch": 1.5318403968196077,
      "grad_norm": 0.241075798869133,
      "learning_rate": 3.4681596031803925e-05,
      "loss": 0.0031,
      "step": 21000
    },
    {
      "epoch": 1.5325698446276168,
      "grad_norm": 0.05961126089096069,
      "learning_rate": 3.467430155372383e-05,
      "loss": 0.0056,
      "step": 21010
    },
    {
      "epoch": 1.5332992924356263,
      "grad_norm": 0.1184437945485115,
      "learning_rate": 3.466700707564374e-05,
      "loss": 0.0036,
      "step": 21020
    },
    {
      "epoch": 1.5340287402436354,
      "grad_norm": 0.41391655802726746,
      "learning_rate": 3.465971259756365e-05,
      "loss": 0.0038,
      "step": 21030
    },
    {
      "epoch": 1.534758188051645,
      "grad_norm": 0.14498281478881836,
      "learning_rate": 3.4652418119483555e-05,
      "loss": 0.0066,
      "step": 21040
    },
    {
      "epoch": 1.535487635859654,
      "grad_norm": 0.28848904371261597,
      "learning_rate": 3.464512364140346e-05,
      "loss": 0.004,
      "step": 21050
    },
    {
      "epoch": 1.5362170836676636,
      "grad_norm": 0.37546443939208984,
      "learning_rate": 3.463782916332336e-05,
      "loss": 0.004,
      "step": 21060
    },
    {
      "epoch": 1.536946531475673,
      "grad_norm": 0.399242639541626,
      "learning_rate": 3.463053468524327e-05,
      "loss": 0.0062,
      "step": 21070
    },
    {
      "epoch": 1.5376759792836823,
      "grad_norm": 0.2464466691017151,
      "learning_rate": 3.462324020716318e-05,
      "loss": 0.0057,
      "step": 21080
    },
    {
      "epoch": 1.5384054270916916,
      "grad_norm": 0.20152200758457184,
      "learning_rate": 3.4615945729083086e-05,
      "loss": 0.0029,
      "step": 21090
    },
    {
      "epoch": 1.539134874899701,
      "grad_norm": 0.05803554505109787,
      "learning_rate": 3.460865125100299e-05,
      "loss": 0.0047,
      "step": 21100
    },
    {
      "epoch": 1.5398643227077102,
      "grad_norm": 0.20265337824821472,
      "learning_rate": 3.46013567729229e-05,
      "loss": 0.004,
      "step": 21110
    },
    {
      "epoch": 1.5405937705157196,
      "grad_norm": 0.030850857496261597,
      "learning_rate": 3.459406229484281e-05,
      "loss": 0.0041,
      "step": 21120
    },
    {
      "epoch": 1.541323218323729,
      "grad_norm": 0.04860064759850502,
      "learning_rate": 3.458676781676271e-05,
      "loss": 0.0046,
      "step": 21130
    },
    {
      "epoch": 1.5420526661317382,
      "grad_norm": 0.11555813997983932,
      "learning_rate": 3.4579473338682617e-05,
      "loss": 0.0046,
      "step": 21140
    },
    {
      "epoch": 1.5427821139397477,
      "grad_norm": 0.2317361980676651,
      "learning_rate": 3.457217886060253e-05,
      "loss": 0.0034,
      "step": 21150
    },
    {
      "epoch": 1.5435115617477568,
      "grad_norm": 0.18810304999351501,
      "learning_rate": 3.456488438252243e-05,
      "loss": 0.0042,
      "step": 21160
    },
    {
      "epoch": 1.5442410095557664,
      "grad_norm": 0.4979192316532135,
      "learning_rate": 3.455758990444234e-05,
      "loss": 0.0035,
      "step": 21170
    },
    {
      "epoch": 1.5449704573637755,
      "grad_norm": 0.18690140545368195,
      "learning_rate": 3.455029542636225e-05,
      "loss": 0.0045,
      "step": 21180
    },
    {
      "epoch": 1.545699905171785,
      "grad_norm": 0.1730634570121765,
      "learning_rate": 3.454300094828215e-05,
      "loss": 0.0038,
      "step": 21190
    },
    {
      "epoch": 1.5464293529797943,
      "grad_norm": 0.42702051997184753,
      "learning_rate": 3.4535706470202055e-05,
      "loss": 0.0053,
      "step": 21200
    },
    {
      "epoch": 1.5471588007878037,
      "grad_norm": 0.04258597269654274,
      "learning_rate": 3.452841199212197e-05,
      "loss": 0.0048,
      "step": 21210
    },
    {
      "epoch": 1.547888248595813,
      "grad_norm": 0.31749361753463745,
      "learning_rate": 3.452111751404187e-05,
      "loss": 0.0034,
      "step": 21220
    },
    {
      "epoch": 1.5486176964038223,
      "grad_norm": 0.22184109687805176,
      "learning_rate": 3.451382303596178e-05,
      "loss": 0.0041,
      "step": 21230
    },
    {
      "epoch": 1.5493471442118316,
      "grad_norm": 0.11638600379228592,
      "learning_rate": 3.4506528557881685e-05,
      "loss": 0.0042,
      "step": 21240
    },
    {
      "epoch": 1.550076592019841,
      "grad_norm": 0.11583536118268967,
      "learning_rate": 3.449923407980159e-05,
      "loss": 0.0062,
      "step": 21250
    },
    {
      "epoch": 1.5508060398278505,
      "grad_norm": 0.5203516483306885,
      "learning_rate": 3.449193960172149e-05,
      "loss": 0.004,
      "step": 21260
    },
    {
      "epoch": 1.5515354876358596,
      "grad_norm": 0.11663753539323807,
      "learning_rate": 3.448464512364141e-05,
      "loss": 0.0038,
      "step": 21270
    },
    {
      "epoch": 1.5522649354438691,
      "grad_norm": 0.3426792323589325,
      "learning_rate": 3.4477350645561315e-05,
      "loss": 0.0023,
      "step": 21280
    },
    {
      "epoch": 1.5529943832518782,
      "grad_norm": 0.28959372639656067,
      "learning_rate": 3.4470056167481216e-05,
      "loss": 0.0042,
      "step": 21290
    },
    {
      "epoch": 1.5537238310598878,
      "grad_norm": 0.129262775182724,
      "learning_rate": 3.4462761689401123e-05,
      "loss": 0.0043,
      "step": 21300
    },
    {
      "epoch": 1.5544532788678969,
      "grad_norm": 0.11628887802362442,
      "learning_rate": 3.445546721132103e-05,
      "loss": 0.004,
      "step": 21310
    },
    {
      "epoch": 1.5551827266759064,
      "grad_norm": 0.1446538120508194,
      "learning_rate": 3.444817273324094e-05,
      "loss": 0.0038,
      "step": 21320
    },
    {
      "epoch": 1.5559121744839157,
      "grad_norm": 0.23088324069976807,
      "learning_rate": 3.4440878255160846e-05,
      "loss": 0.0044,
      "step": 21330
    },
    {
      "epoch": 1.556641622291925,
      "grad_norm": 0.05797472968697548,
      "learning_rate": 3.4433583777080754e-05,
      "loss": 0.0064,
      "step": 21340
    },
    {
      "epoch": 1.5573710700999344,
      "grad_norm": 0.18229730427265167,
      "learning_rate": 3.442628929900066e-05,
      "loss": 0.0042,
      "step": 21350
    },
    {
      "epoch": 1.5581005179079437,
      "grad_norm": 0.31271445751190186,
      "learning_rate": 3.441899482092056e-05,
      "loss": 0.0056,
      "step": 21360
    },
    {
      "epoch": 1.558829965715953,
      "grad_norm": 0.40351980924606323,
      "learning_rate": 3.441170034284047e-05,
      "loss": 0.0041,
      "step": 21370
    },
    {
      "epoch": 1.5595594135239623,
      "grad_norm": 0.5770443677902222,
      "learning_rate": 3.4404405864760384e-05,
      "loss": 0.0044,
      "step": 21380
    },
    {
      "epoch": 1.5602888613319716,
      "grad_norm": 0.48782387375831604,
      "learning_rate": 3.4397111386680284e-05,
      "loss": 0.0048,
      "step": 21390
    },
    {
      "epoch": 1.561018309139981,
      "grad_norm": 0.27268168330192566,
      "learning_rate": 3.438981690860019e-05,
      "loss": 0.0057,
      "step": 21400
    },
    {
      "epoch": 1.5617477569479905,
      "grad_norm": 0.31749269366264343,
      "learning_rate": 3.43825224305201e-05,
      "loss": 0.0049,
      "step": 21410
    },
    {
      "epoch": 1.5624772047559996,
      "grad_norm": 0.17376898229122162,
      "learning_rate": 3.437522795244e-05,
      "loss": 0.0032,
      "step": 21420
    },
    {
      "epoch": 1.5632066525640091,
      "grad_norm": 0.029960250481963158,
      "learning_rate": 3.436793347435991e-05,
      "loss": 0.0065,
      "step": 21430
    },
    {
      "epoch": 1.5639361003720182,
      "grad_norm": 0.11609647423028946,
      "learning_rate": 3.436063899627982e-05,
      "loss": 0.0041,
      "step": 21440
    },
    {
      "epoch": 1.5646655481800278,
      "grad_norm": 0.2881622612476349,
      "learning_rate": 3.435334451819972e-05,
      "loss": 0.0052,
      "step": 21450
    },
    {
      "epoch": 1.565394995988037,
      "grad_norm": 0.006228883285075426,
      "learning_rate": 3.434605004011963e-05,
      "loss": 0.003,
      "step": 21460
    },
    {
      "epoch": 1.5661244437960464,
      "grad_norm": 0.02892845869064331,
      "learning_rate": 3.433875556203954e-05,
      "loss": 0.0039,
      "step": 21470
    },
    {
      "epoch": 1.5668538916040557,
      "grad_norm": 0.173592671751976,
      "learning_rate": 3.4331461083959445e-05,
      "loss": 0.005,
      "step": 21480
    },
    {
      "epoch": 1.567583339412065,
      "grad_norm": 0.1239597275853157,
      "learning_rate": 3.4324166605879346e-05,
      "loss": 0.0045,
      "step": 21490
    },
    {
      "epoch": 1.5683127872200744,
      "grad_norm": 0.05870618298649788,
      "learning_rate": 3.431687212779926e-05,
      "loss": 0.0047,
      "step": 21500
    },
    {
      "epoch": 1.5690422350280837,
      "grad_norm": 0.23087698221206665,
      "learning_rate": 3.430957764971917e-05,
      "loss": 0.0039,
      "step": 21510
    },
    {
      "epoch": 1.569771682836093,
      "grad_norm": 0.12024082988500595,
      "learning_rate": 3.430228317163907e-05,
      "loss": 0.0039,
      "step": 21520
    },
    {
      "epoch": 1.5705011306441023,
      "grad_norm": 0.27225449681282043,
      "learning_rate": 3.4294988693558976e-05,
      "loss": 0.0047,
      "step": 21530
    },
    {
      "epoch": 1.571230578452112,
      "grad_norm": 0.08645069599151611,
      "learning_rate": 3.4287694215478884e-05,
      "loss": 0.0042,
      "step": 21540
    },
    {
      "epoch": 1.571960026260121,
      "grad_norm": 0.2104821652173996,
      "learning_rate": 3.428039973739879e-05,
      "loss": 0.0055,
      "step": 21550
    },
    {
      "epoch": 1.5726894740681305,
      "grad_norm": 0.11207126826047897,
      "learning_rate": 3.42731052593187e-05,
      "loss": 0.0034,
      "step": 21560
    },
    {
      "epoch": 1.5734189218761396,
      "grad_norm": 0.49099189043045044,
      "learning_rate": 3.4265810781238606e-05,
      "loss": 0.0049,
      "step": 21570
    },
    {
      "epoch": 1.5741483696841492,
      "grad_norm": 0.05786437168717384,
      "learning_rate": 3.4258516303158514e-05,
      "loss": 0.0033,
      "step": 21580
    },
    {
      "epoch": 1.5748778174921583,
      "grad_norm": 0.05876382440328598,
      "learning_rate": 3.4251221825078415e-05,
      "loss": 0.0046,
      "step": 21590
    },
    {
      "epoch": 1.5756072653001678,
      "grad_norm": 0.1770201474428177,
      "learning_rate": 3.424392734699832e-05,
      "loss": 0.005,
      "step": 21600
    },
    {
      "epoch": 1.5763367131081771,
      "grad_norm": 0.21057967841625214,
      "learning_rate": 3.423663286891823e-05,
      "loss": 0.0049,
      "step": 21610
    },
    {
      "epoch": 1.5770661609161865,
      "grad_norm": 0.17269562184810638,
      "learning_rate": 3.422933839083814e-05,
      "loss": 0.0037,
      "step": 21620
    },
    {
      "epoch": 1.5777956087241958,
      "grad_norm": 0.3467782735824585,
      "learning_rate": 3.4222043912758045e-05,
      "loss": 0.004,
      "step": 21630
    },
    {
      "epoch": 1.578525056532205,
      "grad_norm": 0.1163538247346878,
      "learning_rate": 3.421474943467795e-05,
      "loss": 0.0049,
      "step": 21640
    },
    {
      "epoch": 1.5792545043402144,
      "grad_norm": 0.4496915340423584,
      "learning_rate": 3.420745495659785e-05,
      "loss": 0.0041,
      "step": 21650
    },
    {
      "epoch": 1.5799839521482237,
      "grad_norm": 0.11540336906909943,
      "learning_rate": 3.420016047851776e-05,
      "loss": 0.0039,
      "step": 21660
    },
    {
      "epoch": 1.5807133999562333,
      "grad_norm": 0.0877893939614296,
      "learning_rate": 3.419286600043767e-05,
      "loss": 0.0048,
      "step": 21670
    },
    {
      "epoch": 1.5814428477642424,
      "grad_norm": 0.7198031544685364,
      "learning_rate": 3.4185571522357576e-05,
      "loss": 0.0054,
      "step": 21680
    },
    {
      "epoch": 1.582172295572252,
      "grad_norm": 0.20314179360866547,
      "learning_rate": 3.417827704427748e-05,
      "loss": 0.0038,
      "step": 21690
    },
    {
      "epoch": 1.582901743380261,
      "grad_norm": 0.23054389655590057,
      "learning_rate": 3.417098256619739e-05,
      "loss": 0.0047,
      "step": 21700
    },
    {
      "epoch": 1.5836311911882706,
      "grad_norm": 0.053908295929431915,
      "learning_rate": 3.41636880881173e-05,
      "loss": 0.003,
      "step": 21710
    },
    {
      "epoch": 1.5843606389962797,
      "grad_norm": 0.12061211466789246,
      "learning_rate": 3.41563936100372e-05,
      "loss": 0.0043,
      "step": 21720
    },
    {
      "epoch": 1.5850900868042892,
      "grad_norm": 0.1255490630865097,
      "learning_rate": 3.414909913195711e-05,
      "loss": 0.0039,
      "step": 21730
    },
    {
      "epoch": 1.5858195346122985,
      "grad_norm": 0.258761465549469,
      "learning_rate": 3.414180465387702e-05,
      "loss": 0.0072,
      "step": 21740
    },
    {
      "epoch": 1.5865489824203078,
      "grad_norm": 0.11646199226379395,
      "learning_rate": 3.413451017579692e-05,
      "loss": 0.004,
      "step": 21750
    },
    {
      "epoch": 1.5872784302283172,
      "grad_norm": 0.20227961242198944,
      "learning_rate": 3.412721569771683e-05,
      "loss": 0.0055,
      "step": 21760
    },
    {
      "epoch": 1.5880078780363265,
      "grad_norm": 0.011815333738923073,
      "learning_rate": 3.411992121963674e-05,
      "loss": 0.0039,
      "step": 21770
    },
    {
      "epoch": 1.5887373258443358,
      "grad_norm": 0.20177432894706726,
      "learning_rate": 3.4112626741556644e-05,
      "loss": 0.0022,
      "step": 21780
    },
    {
      "epoch": 1.5894667736523451,
      "grad_norm": 0.41650742292404175,
      "learning_rate": 3.410533226347655e-05,
      "loss": 0.0045,
      "step": 21790
    },
    {
      "epoch": 1.5901962214603547,
      "grad_norm": 0.030256623402237892,
      "learning_rate": 3.409803778539646e-05,
      "loss": 0.0043,
      "step": 21800
    },
    {
      "epoch": 1.5909256692683638,
      "grad_norm": 0.029550284147262573,
      "learning_rate": 3.409074330731637e-05,
      "loss": 0.0041,
      "step": 21810
    },
    {
      "epoch": 1.5916551170763733,
      "grad_norm": 0.032667145133018494,
      "learning_rate": 3.408344882923627e-05,
      "loss": 0.0048,
      "step": 21820
    },
    {
      "epoch": 1.5923845648843824,
      "grad_norm": 0.00962988380342722,
      "learning_rate": 3.4076154351156175e-05,
      "loss": 0.0048,
      "step": 21830
    },
    {
      "epoch": 1.593114012692392,
      "grad_norm": 0.7049245834350586,
      "learning_rate": 3.406885987307608e-05,
      "loss": 0.0037,
      "step": 21840
    },
    {
      "epoch": 1.593843460500401,
      "grad_norm": 0.2311408370733261,
      "learning_rate": 3.406156539499599e-05,
      "loss": 0.0036,
      "step": 21850
    },
    {
      "epoch": 1.5945729083084106,
      "grad_norm": 0.18720926344394684,
      "learning_rate": 3.40542709169159e-05,
      "loss": 0.0053,
      "step": 21860
    },
    {
      "epoch": 1.59530235611642,
      "grad_norm": 0.1151755303144455,
      "learning_rate": 3.4046976438835805e-05,
      "loss": 0.004,
      "step": 21870
    },
    {
      "epoch": 1.5960318039244292,
      "grad_norm": 0.173245370388031,
      "learning_rate": 3.4039681960755706e-05,
      "loss": 0.0031,
      "step": 21880
    },
    {
      "epoch": 1.5967612517324385,
      "grad_norm": 0.009257926605641842,
      "learning_rate": 3.4032387482675614e-05,
      "loss": 0.0048,
      "step": 21890
    },
    {
      "epoch": 1.5974906995404479,
      "grad_norm": 0.33680418133735657,
      "learning_rate": 3.402509300459552e-05,
      "loss": 0.0061,
      "step": 21900
    },
    {
      "epoch": 1.5982201473484572,
      "grad_norm": 0.20243659615516663,
      "learning_rate": 3.401779852651543e-05,
      "loss": 0.0052,
      "step": 21910
    },
    {
      "epoch": 1.5989495951564665,
      "grad_norm": 0.3456931710243225,
      "learning_rate": 3.4010504048435336e-05,
      "loss": 0.0063,
      "step": 21920
    },
    {
      "epoch": 1.599679042964476,
      "grad_norm": 0.11550626903772354,
      "learning_rate": 3.4003209570355244e-05,
      "loss": 0.0053,
      "step": 21930
    },
    {
      "epoch": 1.6004084907724851,
      "grad_norm": 0.03063436970114708,
      "learning_rate": 3.399591509227515e-05,
      "loss": 0.0042,
      "step": 21940
    },
    {
      "epoch": 1.6011379385804947,
      "grad_norm": 0.11385811120271683,
      "learning_rate": 3.398862061419505e-05,
      "loss": 0.0049,
      "step": 21950
    },
    {
      "epoch": 1.6018673863885038,
      "grad_norm": 0.43279463052749634,
      "learning_rate": 3.398132613611496e-05,
      "loss": 0.0046,
      "step": 21960
    },
    {
      "epoch": 1.6025968341965133,
      "grad_norm": 0.46148058772087097,
      "learning_rate": 3.3974031658034874e-05,
      "loss": 0.0026,
      "step": 21970
    },
    {
      "epoch": 1.6033262820045224,
      "grad_norm": 0.2600582242012024,
      "learning_rate": 3.3966737179954775e-05,
      "loss": 0.0041,
      "step": 21980
    },
    {
      "epoch": 1.604055729812532,
      "grad_norm": 0.17319156229496002,
      "learning_rate": 3.395944270187468e-05,
      "loss": 0.0037,
      "step": 21990
    },
    {
      "epoch": 1.6047851776205413,
      "grad_norm": 0.29200994968414307,
      "learning_rate": 3.395214822379459e-05,
      "loss": 0.0041,
      "step": 22000
    },
    {
      "epoch": 1.6055146254285506,
      "grad_norm": 0.08672341704368591,
      "learning_rate": 3.39448537457145e-05,
      "loss": 0.0055,
      "step": 22010
    },
    {
      "epoch": 1.60624407323656,
      "grad_norm": 0.3182414472103119,
      "learning_rate": 3.39375592676344e-05,
      "loss": 0.0048,
      "step": 22020
    },
    {
      "epoch": 1.6069735210445693,
      "grad_norm": 0.08795540779829025,
      "learning_rate": 3.393026478955431e-05,
      "loss": 0.0052,
      "step": 22030
    },
    {
      "epoch": 1.6077029688525786,
      "grad_norm": 0.37555447220802307,
      "learning_rate": 3.392297031147422e-05,
      "loss": 0.0051,
      "step": 22040
    },
    {
      "epoch": 1.608432416660588,
      "grad_norm": 0.25978323817253113,
      "learning_rate": 3.391567583339412e-05,
      "loss": 0.0041,
      "step": 22050
    },
    {
      "epoch": 1.6091618644685974,
      "grad_norm": 0.031122686341404915,
      "learning_rate": 3.390838135531403e-05,
      "loss": 0.0046,
      "step": 22060
    },
    {
      "epoch": 1.6098913122766065,
      "grad_norm": 0.2595658302307129,
      "learning_rate": 3.3901086877233936e-05,
      "loss": 0.0049,
      "step": 22070
    },
    {
      "epoch": 1.610620760084616,
      "grad_norm": 0.40471139550209045,
      "learning_rate": 3.389379239915384e-05,
      "loss": 0.0054,
      "step": 22080
    },
    {
      "epoch": 1.6113502078926252,
      "grad_norm": 0.04679565504193306,
      "learning_rate": 3.388649792107375e-05,
      "loss": 0.0051,
      "step": 22090
    },
    {
      "epoch": 1.6120796557006347,
      "grad_norm": 0.30271509289741516,
      "learning_rate": 3.387920344299366e-05,
      "loss": 0.0051,
      "step": 22100
    },
    {
      "epoch": 1.6128091035086438,
      "grad_norm": 0.11572027206420898,
      "learning_rate": 3.3871908964913566e-05,
      "loss": 0.0048,
      "step": 22110
    },
    {
      "epoch": 1.6135385513166534,
      "grad_norm": 0.1460052877664566,
      "learning_rate": 3.3864614486833466e-05,
      "loss": 0.0055,
      "step": 22120
    },
    {
      "epoch": 1.6142679991246627,
      "grad_norm": 0.3460942208766937,
      "learning_rate": 3.3857320008753374e-05,
      "loss": 0.0045,
      "step": 22130
    },
    {
      "epoch": 1.614997446932672,
      "grad_norm": 0.6481788754463196,
      "learning_rate": 3.385002553067328e-05,
      "loss": 0.0036,
      "step": 22140
    },
    {
      "epoch": 1.6157268947406813,
      "grad_norm": 0.3766627013683319,
      "learning_rate": 3.384273105259319e-05,
      "loss": 0.0034,
      "step": 22150
    },
    {
      "epoch": 1.6164563425486906,
      "grad_norm": 0.40405264496803284,
      "learning_rate": 3.3835436574513097e-05,
      "loss": 0.0056,
      "step": 22160
    },
    {
      "epoch": 1.6171857903567,
      "grad_norm": 0.08903257548809052,
      "learning_rate": 3.3828142096433004e-05,
      "loss": 0.0045,
      "step": 22170
    },
    {
      "epoch": 1.6179152381647093,
      "grad_norm": 0.36727970838546753,
      "learning_rate": 3.3820847618352905e-05,
      "loss": 0.0057,
      "step": 22180
    },
    {
      "epoch": 1.6186446859727186,
      "grad_norm": 0.09765729308128357,
      "learning_rate": 3.381355314027281e-05,
      "loss": 0.0053,
      "step": 22190
    },
    {
      "epoch": 1.619374133780728,
      "grad_norm": 0.418200820684433,
      "learning_rate": 3.380625866219272e-05,
      "loss": 0.0041,
      "step": 22200
    },
    {
      "epoch": 1.6201035815887375,
      "grad_norm": 0.34789353609085083,
      "learning_rate": 3.379896418411263e-05,
      "loss": 0.0042,
      "step": 22210
    },
    {
      "epoch": 1.6208330293967466,
      "grad_norm": 0.20262646675109863,
      "learning_rate": 3.3791669706032535e-05,
      "loss": 0.0051,
      "step": 22220
    },
    {
      "epoch": 1.621562477204756,
      "grad_norm": 0.29288604855537415,
      "learning_rate": 3.378437522795244e-05,
      "loss": 0.0039,
      "step": 22230
    },
    {
      "epoch": 1.6222919250127652,
      "grad_norm": 0.05798542499542236,
      "learning_rate": 3.377708074987235e-05,
      "loss": 0.0042,
      "step": 22240
    },
    {
      "epoch": 1.6230213728207747,
      "grad_norm": 0.08715122193098068,
      "learning_rate": 3.376978627179225e-05,
      "loss": 0.0069,
      "step": 22250
    },
    {
      "epoch": 1.623750820628784,
      "grad_norm": 0.23200638592243195,
      "learning_rate": 3.376249179371216e-05,
      "loss": 0.0055,
      "step": 22260
    },
    {
      "epoch": 1.6244802684367934,
      "grad_norm": 0.010480688884854317,
      "learning_rate": 3.375519731563207e-05,
      "loss": 0.0053,
      "step": 22270
    },
    {
      "epoch": 1.6252097162448027,
      "grad_norm": 0.13223877549171448,
      "learning_rate": 3.374790283755197e-05,
      "loss": 0.0047,
      "step": 22280
    },
    {
      "epoch": 1.625939164052812,
      "grad_norm": 0.2588402032852173,
      "learning_rate": 3.374060835947188e-05,
      "loss": 0.0044,
      "step": 22290
    },
    {
      "epoch": 1.6266686118608213,
      "grad_norm": 0.05959185212850571,
      "learning_rate": 3.373331388139179e-05,
      "loss": 0.0047,
      "step": 22300
    },
    {
      "epoch": 1.6273980596688307,
      "grad_norm": 0.6055264472961426,
      "learning_rate": 3.3726019403311696e-05,
      "loss": 0.0043,
      "step": 22310
    },
    {
      "epoch": 1.62812750747684,
      "grad_norm": 0.4618571996688843,
      "learning_rate": 3.3718724925231603e-05,
      "loss": 0.0049,
      "step": 22320
    },
    {
      "epoch": 1.6288569552848493,
      "grad_norm": 0.06291467696428299,
      "learning_rate": 3.371143044715151e-05,
      "loss": 0.0025,
      "step": 22330
    },
    {
      "epoch": 1.6295864030928588,
      "grad_norm": 0.05768172815442085,
      "learning_rate": 3.370413596907142e-05,
      "loss": 0.0042,
      "step": 22340
    },
    {
      "epoch": 1.630315850900868,
      "grad_norm": 0.34504401683807373,
      "learning_rate": 3.369684149099132e-05,
      "loss": 0.0053,
      "step": 22350
    },
    {
      "epoch": 1.6310452987088775,
      "grad_norm": 0.1599707156419754,
      "learning_rate": 3.368954701291123e-05,
      "loss": 0.0049,
      "step": 22360
    },
    {
      "epoch": 1.6317747465168866,
      "grad_norm": 0.17279860377311707,
      "learning_rate": 3.3682252534831134e-05,
      "loss": 0.0033,
      "step": 22370
    },
    {
      "epoch": 1.6325041943248961,
      "grad_norm": 0.287910133600235,
      "learning_rate": 3.367495805675104e-05,
      "loss": 0.0025,
      "step": 22380
    },
    {
      "epoch": 1.6332336421329052,
      "grad_norm": 0.2035844624042511,
      "learning_rate": 3.366766357867095e-05,
      "loss": 0.0035,
      "step": 22390
    },
    {
      "epoch": 1.6339630899409148,
      "grad_norm": 0.14554962515830994,
      "learning_rate": 3.366036910059086e-05,
      "loss": 0.0033,
      "step": 22400
    },
    {
      "epoch": 1.634692537748924,
      "grad_norm": 1.0201759338378906,
      "learning_rate": 3.365307462251076e-05,
      "loss": 0.0048,
      "step": 22410
    },
    {
      "epoch": 1.6354219855569334,
      "grad_norm": 0.11532881110906601,
      "learning_rate": 3.3645780144430665e-05,
      "loss": 0.0057,
      "step": 22420
    },
    {
      "epoch": 1.6361514333649427,
      "grad_norm": 0.49058791995048523,
      "learning_rate": 3.363848566635057e-05,
      "loss": 0.0052,
      "step": 22430
    },
    {
      "epoch": 1.636880881172952,
      "grad_norm": 0.14380468428134918,
      "learning_rate": 3.363119118827048e-05,
      "loss": 0.0053,
      "step": 22440
    },
    {
      "epoch": 1.6376103289809614,
      "grad_norm": 0.03019634261727333,
      "learning_rate": 3.362389671019039e-05,
      "loss": 0.0039,
      "step": 22450
    },
    {
      "epoch": 1.6383397767889707,
      "grad_norm": 0.11604579538106918,
      "learning_rate": 3.3616602232110295e-05,
      "loss": 0.005,
      "step": 22460
    },
    {
      "epoch": 1.6390692245969802,
      "grad_norm": 0.24213986098766327,
      "learning_rate": 3.36093077540302e-05,
      "loss": 0.0053,
      "step": 22470
    },
    {
      "epoch": 1.6397986724049893,
      "grad_norm": 0.11551786214113235,
      "learning_rate": 3.3602013275950104e-05,
      "loss": 0.0051,
      "step": 22480
    },
    {
      "epoch": 1.6405281202129989,
      "grad_norm": 0.009885014034807682,
      "learning_rate": 3.359471879787001e-05,
      "loss": 0.0026,
      "step": 22490
    },
    {
      "epoch": 1.641257568021008,
      "grad_norm": 0.27033305168151855,
      "learning_rate": 3.3587424319789925e-05,
      "loss": 0.0049,
      "step": 22500
    },
    {
      "epoch": 1.6419870158290175,
      "grad_norm": 0.260951429605484,
      "learning_rate": 3.3580129841709826e-05,
      "loss": 0.0057,
      "step": 22510
    },
    {
      "epoch": 1.6427164636370266,
      "grad_norm": 0.260210245847702,
      "learning_rate": 3.3572835363629734e-05,
      "loss": 0.0047,
      "step": 22520
    },
    {
      "epoch": 1.6434459114450362,
      "grad_norm": 0.17352673411369324,
      "learning_rate": 3.356554088554964e-05,
      "loss": 0.004,
      "step": 22530
    },
    {
      "epoch": 1.6441753592530455,
      "grad_norm": 0.3071155250072479,
      "learning_rate": 3.355824640746955e-05,
      "loss": 0.0063,
      "step": 22540
    },
    {
      "epoch": 1.6449048070610548,
      "grad_norm": 0.08687256276607513,
      "learning_rate": 3.355095192938945e-05,
      "loss": 0.0051,
      "step": 22550
    },
    {
      "epoch": 1.6456342548690641,
      "grad_norm": 0.3230232894420624,
      "learning_rate": 3.3543657451309364e-05,
      "loss": 0.0043,
      "step": 22560
    },
    {
      "epoch": 1.6463637026770734,
      "grad_norm": 0.3491182029247284,
      "learning_rate": 3.353636297322927e-05,
      "loss": 0.004,
      "step": 22570
    },
    {
      "epoch": 1.6470931504850828,
      "grad_norm": 0.5197765231132507,
      "learning_rate": 3.352906849514917e-05,
      "loss": 0.0034,
      "step": 22580
    },
    {
      "epoch": 1.647822598293092,
      "grad_norm": 0.37531137466430664,
      "learning_rate": 3.352177401706908e-05,
      "loss": 0.0058,
      "step": 22590
    },
    {
      "epoch": 1.6485520461011016,
      "grad_norm": 0.17352230846881866,
      "learning_rate": 3.351447953898899e-05,
      "loss": 0.0047,
      "step": 22600
    },
    {
      "epoch": 1.6492814939091107,
      "grad_norm": 0.26005205512046814,
      "learning_rate": 3.350718506090889e-05,
      "loss": 0.0036,
      "step": 22610
    },
    {
      "epoch": 1.6500109417171203,
      "grad_norm": 0.03005858324468136,
      "learning_rate": 3.34998905828288e-05,
      "loss": 0.0033,
      "step": 22620
    },
    {
      "epoch": 1.6507403895251294,
      "grad_norm": 0.03274506703019142,
      "learning_rate": 3.349259610474871e-05,
      "loss": 0.0034,
      "step": 22630
    },
    {
      "epoch": 1.651469837333139,
      "grad_norm": 0.12174852192401886,
      "learning_rate": 3.348530162666861e-05,
      "loss": 0.0056,
      "step": 22640
    },
    {
      "epoch": 1.652199285141148,
      "grad_norm": 0.058004993945360184,
      "learning_rate": 3.347800714858852e-05,
      "loss": 0.0028,
      "step": 22650
    },
    {
      "epoch": 1.6529287329491575,
      "grad_norm": 0.17359530925750732,
      "learning_rate": 3.3470712670508426e-05,
      "loss": 0.0038,
      "step": 22660
    },
    {
      "epoch": 1.6536581807571669,
      "grad_norm": 0.3744763135910034,
      "learning_rate": 3.346341819242833e-05,
      "loss": 0.004,
      "step": 22670
    },
    {
      "epoch": 1.6543876285651762,
      "grad_norm": 0.059408318251371384,
      "learning_rate": 3.345612371434824e-05,
      "loss": 0.0036,
      "step": 22680
    },
    {
      "epoch": 1.6551170763731855,
      "grad_norm": 0.0582989938557148,
      "learning_rate": 3.344882923626815e-05,
      "loss": 0.0041,
      "step": 22690
    },
    {
      "epoch": 1.6558465241811948,
      "grad_norm": 0.05018756538629532,
      "learning_rate": 3.3441534758188056e-05,
      "loss": 0.0055,
      "step": 22700
    },
    {
      "epoch": 1.6565759719892041,
      "grad_norm": 0.36780694127082825,
      "learning_rate": 3.3434240280107956e-05,
      "loss": 0.0041,
      "step": 22710
    },
    {
      "epoch": 1.6573054197972135,
      "grad_norm": 0.28848713636398315,
      "learning_rate": 3.3426945802027864e-05,
      "loss": 0.0039,
      "step": 22720
    },
    {
      "epoch": 1.658034867605223,
      "grad_norm": 0.030740773305296898,
      "learning_rate": 3.341965132394777e-05,
      "loss": 0.0046,
      "step": 22730
    },
    {
      "epoch": 1.658764315413232,
      "grad_norm": 0.1732567995786667,
      "learning_rate": 3.341235684586768e-05,
      "loss": 0.0043,
      "step": 22740
    },
    {
      "epoch": 1.6594937632212416,
      "grad_norm": 0.20222848653793335,
      "learning_rate": 3.3405062367787587e-05,
      "loss": 0.0063,
      "step": 22750
    },
    {
      "epoch": 1.6602232110292507,
      "grad_norm": 0.06245500594377518,
      "learning_rate": 3.3397767889707494e-05,
      "loss": 0.0044,
      "step": 22760
    },
    {
      "epoch": 1.6609526588372603,
      "grad_norm": 0.1436588019132614,
      "learning_rate": 3.33904734116274e-05,
      "loss": 0.0033,
      "step": 22770
    },
    {
      "epoch": 1.6616821066452694,
      "grad_norm": 0.2806057929992676,
      "learning_rate": 3.33831789335473e-05,
      "loss": 0.0052,
      "step": 22780
    },
    {
      "epoch": 1.662411554453279,
      "grad_norm": 0.061468299478292465,
      "learning_rate": 3.337588445546722e-05,
      "loss": 0.0037,
      "step": 22790
    },
    {
      "epoch": 1.6631410022612882,
      "grad_norm": 0.1538640409708023,
      "learning_rate": 3.3368589977387124e-05,
      "loss": 0.0053,
      "step": 22800
    },
    {
      "epoch": 1.6638704500692976,
      "grad_norm": 0.08684435486793518,
      "learning_rate": 3.3361295499307025e-05,
      "loss": 0.0026,
      "step": 22810
    },
    {
      "epoch": 1.6645998978773069,
      "grad_norm": 0.029203718528151512,
      "learning_rate": 3.335400102122693e-05,
      "loss": 0.0035,
      "step": 22820
    },
    {
      "epoch": 1.6653293456853162,
      "grad_norm": 0.2024347484111786,
      "learning_rate": 3.334670654314684e-05,
      "loss": 0.0052,
      "step": 22830
    },
    {
      "epoch": 1.6660587934933255,
      "grad_norm": 0.05846675857901573,
      "learning_rate": 3.333941206506674e-05,
      "loss": 0.0048,
      "step": 22840
    },
    {
      "epoch": 1.6667882413013348,
      "grad_norm": 0.058315109461545944,
      "learning_rate": 3.3332117586986655e-05,
      "loss": 0.004,
      "step": 22850
    },
    {
      "epoch": 1.6675176891093444,
      "grad_norm": 0.11588288843631744,
      "learning_rate": 3.332482310890656e-05,
      "loss": 0.0033,
      "step": 22860
    },
    {
      "epoch": 1.6682471369173535,
      "grad_norm": 0.031996190547943115,
      "learning_rate": 3.3317528630826463e-05,
      "loss": 0.0041,
      "step": 22870
    },
    {
      "epoch": 1.668976584725363,
      "grad_norm": 0.12470678985118866,
      "learning_rate": 3.331023415274637e-05,
      "loss": 0.0034,
      "step": 22880
    },
    {
      "epoch": 1.6697060325333721,
      "grad_norm": 0.31568995118141174,
      "learning_rate": 3.330293967466628e-05,
      "loss": 0.0051,
      "step": 22890
    },
    {
      "epoch": 1.6704354803413817,
      "grad_norm": 0.11580126732587814,
      "learning_rate": 3.3295645196586186e-05,
      "loss": 0.0038,
      "step": 22900
    },
    {
      "epoch": 1.6711649281493908,
      "grad_norm": 0.2663733661174774,
      "learning_rate": 3.3288350718506094e-05,
      "loss": 0.0043,
      "step": 22910
    },
    {
      "epoch": 1.6718943759574003,
      "grad_norm": 0.22999367117881775,
      "learning_rate": 3.3281056240426e-05,
      "loss": 0.0038,
      "step": 22920
    },
    {
      "epoch": 1.6726238237654096,
      "grad_norm": 0.20229223370552063,
      "learning_rate": 3.327376176234591e-05,
      "loss": 0.0033,
      "step": 22930
    },
    {
      "epoch": 1.673353271573419,
      "grad_norm": 0.3551717698574066,
      "learning_rate": 3.326646728426581e-05,
      "loss": 0.0043,
      "step": 22940
    },
    {
      "epoch": 1.6740827193814283,
      "grad_norm": 0.20130877196788788,
      "learning_rate": 3.325917280618572e-05,
      "loss": 0.0033,
      "step": 22950
    },
    {
      "epoch": 1.6748121671894376,
      "grad_norm": 0.08852595090866089,
      "learning_rate": 3.3251878328105624e-05,
      "loss": 0.004,
      "step": 22960
    },
    {
      "epoch": 1.675541614997447,
      "grad_norm": 0.14478065073490143,
      "learning_rate": 3.324458385002553e-05,
      "loss": 0.0045,
      "step": 22970
    },
    {
      "epoch": 1.6762710628054562,
      "grad_norm": 0.22987329959869385,
      "learning_rate": 3.323728937194544e-05,
      "loss": 0.006,
      "step": 22980
    },
    {
      "epoch": 1.6770005106134656,
      "grad_norm": 0.05816855654120445,
      "learning_rate": 3.322999489386535e-05,
      "loss": 0.0044,
      "step": 22990
    },
    {
      "epoch": 1.6777299584214749,
      "grad_norm": 0.25924840569496155,
      "learning_rate": 3.3222700415785255e-05,
      "loss": 0.0056,
      "step": 23000
    },
    {
      "epoch": 1.6784594062294844,
      "grad_norm": 0.25840064883232117,
      "learning_rate": 3.3215405937705155e-05,
      "loss": 0.0052,
      "step": 23010
    },
    {
      "epoch": 1.6791888540374935,
      "grad_norm": 0.20098163187503815,
      "learning_rate": 3.320811145962506e-05,
      "loss": 0.0043,
      "step": 23020
    },
    {
      "epoch": 1.679918301845503,
      "grad_norm": 0.41816505789756775,
      "learning_rate": 3.320081698154498e-05,
      "loss": 0.0058,
      "step": 23030
    },
    {
      "epoch": 1.6806477496535122,
      "grad_norm": 0.25956660509109497,
      "learning_rate": 3.319352250346488e-05,
      "loss": 0.0056,
      "step": 23040
    },
    {
      "epoch": 1.6813771974615217,
      "grad_norm": 0.3175143003463745,
      "learning_rate": 3.3186228025384785e-05,
      "loss": 0.0055,
      "step": 23050
    },
    {
      "epoch": 1.682106645269531,
      "grad_norm": 0.200375035405159,
      "learning_rate": 3.317893354730469e-05,
      "loss": 0.004,
      "step": 23060
    },
    {
      "epoch": 1.6828360930775403,
      "grad_norm": 0.37378522753715515,
      "learning_rate": 3.31716390692246e-05,
      "loss": 0.0039,
      "step": 23070
    },
    {
      "epoch": 1.6835655408855497,
      "grad_norm": 0.11564230173826218,
      "learning_rate": 3.31643445911445e-05,
      "loss": 0.006,
      "step": 23080
    },
    {
      "epoch": 1.684294988693559,
      "grad_norm": 0.28787854313850403,
      "learning_rate": 3.3157050113064416e-05,
      "loss": 0.0036,
      "step": 23090
    },
    {
      "epoch": 1.6850244365015683,
      "grad_norm": 0.28877875208854675,
      "learning_rate": 3.314975563498432e-05,
      "loss": 0.0036,
      "step": 23100
    },
    {
      "epoch": 1.6857538843095776,
      "grad_norm": 0.26416441798210144,
      "learning_rate": 3.3142461156904224e-05,
      "loss": 0.0037,
      "step": 23110
    },
    {
      "epoch": 1.686483332117587,
      "grad_norm": 0.5479162931442261,
      "learning_rate": 3.313516667882413e-05,
      "loss": 0.003,
      "step": 23120
    },
    {
      "epoch": 1.6872127799255963,
      "grad_norm": 0.11546598374843597,
      "learning_rate": 3.312787220074404e-05,
      "loss": 0.005,
      "step": 23130
    },
    {
      "epoch": 1.6879422277336058,
      "grad_norm": 0.2756180167198181,
      "learning_rate": 3.312057772266394e-05,
      "loss": 0.0035,
      "step": 23140
    },
    {
      "epoch": 1.688671675541615,
      "grad_norm": 0.23042088747024536,
      "learning_rate": 3.3113283244583854e-05,
      "loss": 0.0049,
      "step": 23150
    },
    {
      "epoch": 1.6894011233496244,
      "grad_norm": 0.17247870564460754,
      "learning_rate": 3.310598876650376e-05,
      "loss": 0.0053,
      "step": 23160
    },
    {
      "epoch": 1.6901305711576335,
      "grad_norm": 0.22962793707847595,
      "learning_rate": 3.309869428842366e-05,
      "loss": 0.004,
      "step": 23170
    },
    {
      "epoch": 1.690860018965643,
      "grad_norm": 0.2880222499370575,
      "learning_rate": 3.309139981034357e-05,
      "loss": 0.0056,
      "step": 23180
    },
    {
      "epoch": 1.6915894667736522,
      "grad_norm": 0.6470590233802795,
      "learning_rate": 3.308410533226348e-05,
      "loss": 0.0038,
      "step": 23190
    },
    {
      "epoch": 1.6923189145816617,
      "grad_norm": 0.25056859850883484,
      "learning_rate": 3.3076810854183385e-05,
      "loss": 0.0033,
      "step": 23200
    },
    {
      "epoch": 1.693048362389671,
      "grad_norm": 0.12981854379177094,
      "learning_rate": 3.306951637610329e-05,
      "loss": 0.0031,
      "step": 23210
    },
    {
      "epoch": 1.6937778101976804,
      "grad_norm": 0.747208833694458,
      "learning_rate": 3.30622218980232e-05,
      "loss": 0.0038,
      "step": 23220
    },
    {
      "epoch": 1.6945072580056897,
      "grad_norm": 0.20184211432933807,
      "learning_rate": 3.305492741994311e-05,
      "loss": 0.0046,
      "step": 23230
    },
    {
      "epoch": 1.695236705813699,
      "grad_norm": 0.20507359504699707,
      "learning_rate": 3.304763294186301e-05,
      "loss": 0.0057,
      "step": 23240
    },
    {
      "epoch": 1.6959661536217083,
      "grad_norm": 0.2603362500667572,
      "learning_rate": 3.3040338463782916e-05,
      "loss": 0.0052,
      "step": 23250
    },
    {
      "epoch": 1.6966956014297176,
      "grad_norm": 0.058951932936906815,
      "learning_rate": 3.303304398570282e-05,
      "loss": 0.0056,
      "step": 23260
    },
    {
      "epoch": 1.6974250492377272,
      "grad_norm": 0.012968764640390873,
      "learning_rate": 3.302574950762273e-05,
      "loss": 0.004,
      "step": 23270
    },
    {
      "epoch": 1.6981544970457363,
      "grad_norm": 0.14399389922618866,
      "learning_rate": 3.301845502954264e-05,
      "loss": 0.0034,
      "step": 23280
    },
    {
      "epoch": 1.6988839448537458,
      "grad_norm": 0.6631802320480347,
      "learning_rate": 3.3011160551462546e-05,
      "loss": 0.0035,
      "step": 23290
    },
    {
      "epoch": 1.699613392661755,
      "grad_norm": 0.11567234247922897,
      "learning_rate": 3.300386607338245e-05,
      "loss": 0.0038,
      "step": 23300
    },
    {
      "epoch": 1.7003428404697645,
      "grad_norm": 0.058420330286026,
      "learning_rate": 3.2996571595302354e-05,
      "loss": 0.0049,
      "step": 23310
    },
    {
      "epoch": 1.7010722882777736,
      "grad_norm": 0.08661279082298279,
      "learning_rate": 3.298927711722227e-05,
      "loss": 0.0036,
      "step": 23320
    },
    {
      "epoch": 1.7018017360857831,
      "grad_norm": 0.032028570771217346,
      "learning_rate": 3.2981982639142176e-05,
      "loss": 0.0026,
      "step": 23330
    },
    {
      "epoch": 1.7025311838937924,
      "grad_norm": 0.05913922190666199,
      "learning_rate": 3.297468816106208e-05,
      "loss": 0.0043,
      "step": 23340
    },
    {
      "epoch": 1.7032606317018018,
      "grad_norm": 0.2590155601501465,
      "learning_rate": 3.2967393682981984e-05,
      "loss": 0.0019,
      "step": 23350
    },
    {
      "epoch": 1.703990079509811,
      "grad_norm": 0.1434236466884613,
      "learning_rate": 3.296009920490189e-05,
      "loss": 0.0039,
      "step": 23360
    },
    {
      "epoch": 1.7047195273178204,
      "grad_norm": 0.23047922551631927,
      "learning_rate": 3.295280472682179e-05,
      "loss": 0.0041,
      "step": 23370
    },
    {
      "epoch": 1.7054489751258297,
      "grad_norm": 0.11603226512670517,
      "learning_rate": 3.294551024874171e-05,
      "loss": 0.0048,
      "step": 23380
    },
    {
      "epoch": 1.706178422933839,
      "grad_norm": 0.11562754213809967,
      "learning_rate": 3.2938215770661614e-05,
      "loss": 0.0043,
      "step": 23390
    },
    {
      "epoch": 1.7069078707418486,
      "grad_norm": 0.012779145501554012,
      "learning_rate": 3.2930921292581515e-05,
      "loss": 0.0024,
      "step": 23400
    },
    {
      "epoch": 1.7076373185498577,
      "grad_norm": 0.31646373867988586,
      "learning_rate": 3.292362681450142e-05,
      "loss": 0.0039,
      "step": 23410
    },
    {
      "epoch": 1.7083667663578672,
      "grad_norm": 0.38378384709358215,
      "learning_rate": 3.291633233642133e-05,
      "loss": 0.004,
      "step": 23420
    },
    {
      "epoch": 1.7090962141658763,
      "grad_norm": 0.012093756347894669,
      "learning_rate": 3.290903785834124e-05,
      "loss": 0.0038,
      "step": 23430
    },
    {
      "epoch": 1.7098256619738859,
      "grad_norm": 0.17725926637649536,
      "learning_rate": 3.2901743380261145e-05,
      "loss": 0.0034,
      "step": 23440
    },
    {
      "epoch": 1.710555109781895,
      "grad_norm": 0.06967197358608246,
      "learning_rate": 3.289444890218105e-05,
      "loss": 0.0037,
      "step": 23450
    },
    {
      "epoch": 1.7112845575899045,
      "grad_norm": 0.14568166434764862,
      "learning_rate": 3.288715442410096e-05,
      "loss": 0.005,
      "step": 23460
    },
    {
      "epoch": 1.7120140053979138,
      "grad_norm": 0.20276716351509094,
      "learning_rate": 3.287985994602086e-05,
      "loss": 0.0039,
      "step": 23470
    },
    {
      "epoch": 1.7127434532059231,
      "grad_norm": 0.05789170041680336,
      "learning_rate": 3.287256546794077e-05,
      "loss": 0.0038,
      "step": 23480
    },
    {
      "epoch": 1.7134729010139325,
      "grad_norm": 0.09542344510555267,
      "learning_rate": 3.2865270989860676e-05,
      "loss": 0.0057,
      "step": 23490
    },
    {
      "epoch": 1.7142023488219418,
      "grad_norm": 0.08721911162137985,
      "learning_rate": 3.2857976511780584e-05,
      "loss": 0.0046,
      "step": 23500
    },
    {
      "epoch": 1.714931796629951,
      "grad_norm": 0.4894552528858185,
      "learning_rate": 3.285068203370049e-05,
      "loss": 0.0045,
      "step": 23510
    },
    {
      "epoch": 1.7156612444379604,
      "grad_norm": 0.17394877970218658,
      "learning_rate": 3.28433875556204e-05,
      "loss": 0.0045,
      "step": 23520
    },
    {
      "epoch": 1.71639069224597,
      "grad_norm": 0.09262928366661072,
      "learning_rate": 3.2836093077540306e-05,
      "loss": 0.005,
      "step": 23530
    },
    {
      "epoch": 1.717120140053979,
      "grad_norm": 0.7473719716072083,
      "learning_rate": 3.282879859946021e-05,
      "loss": 0.0036,
      "step": 23540
    },
    {
      "epoch": 1.7178495878619886,
      "grad_norm": 0.4599471390247345,
      "learning_rate": 3.2821504121380114e-05,
      "loss": 0.0039,
      "step": 23550
    },
    {
      "epoch": 1.7185790356699977,
      "grad_norm": 0.34858161211013794,
      "learning_rate": 3.281420964330003e-05,
      "loss": 0.0048,
      "step": 23560
    },
    {
      "epoch": 1.7193084834780072,
      "grad_norm": 0.2551455497741699,
      "learning_rate": 3.280691516521993e-05,
      "loss": 0.004,
      "step": 23570
    },
    {
      "epoch": 1.7200379312860163,
      "grad_norm": 0.11612030118703842,
      "learning_rate": 3.279962068713984e-05,
      "loss": 0.0033,
      "step": 23580
    },
    {
      "epoch": 1.7207673790940259,
      "grad_norm": 0.0584712028503418,
      "learning_rate": 3.2792326209059745e-05,
      "loss": 0.0041,
      "step": 23590
    },
    {
      "epoch": 1.7214968269020352,
      "grad_norm": 0.23055997490882874,
      "learning_rate": 3.2785031730979645e-05,
      "loss": 0.004,
      "step": 23600
    },
    {
      "epoch": 1.7222262747100445,
      "grad_norm": 0.259304016828537,
      "learning_rate": 3.277773725289955e-05,
      "loss": 0.0043,
      "step": 23610
    },
    {
      "epoch": 1.7229557225180538,
      "grad_norm": 0.28195711970329285,
      "learning_rate": 3.277044277481947e-05,
      "loss": 0.0042,
      "step": 23620
    },
    {
      "epoch": 1.7236851703260632,
      "grad_norm": 0.43995383381843567,
      "learning_rate": 3.276314829673937e-05,
      "loss": 0.0041,
      "step": 23630
    },
    {
      "epoch": 1.7244146181340725,
      "grad_norm": 0.3848218023777008,
      "learning_rate": 3.2755853818659275e-05,
      "loss": 0.005,
      "step": 23640
    },
    {
      "epoch": 1.7251440659420818,
      "grad_norm": 0.1729438751935959,
      "learning_rate": 3.274855934057918e-05,
      "loss": 0.0035,
      "step": 23650
    },
    {
      "epoch": 1.7258735137500911,
      "grad_norm": 0.17284855246543884,
      "learning_rate": 3.274126486249909e-05,
      "loss": 0.0059,
      "step": 23660
    },
    {
      "epoch": 1.7266029615581004,
      "grad_norm": 0.02963857725262642,
      "learning_rate": 3.273397038441899e-05,
      "loss": 0.004,
      "step": 23670
    },
    {
      "epoch": 1.72733240936611,
      "grad_norm": 0.3951196074485779,
      "learning_rate": 3.2726675906338906e-05,
      "loss": 0.0047,
      "step": 23680
    },
    {
      "epoch": 1.728061857174119,
      "grad_norm": 0.25902482867240906,
      "learning_rate": 3.271938142825881e-05,
      "loss": 0.0041,
      "step": 23690
    },
    {
      "epoch": 1.7287913049821286,
      "grad_norm": 0.3243492841720581,
      "learning_rate": 3.2712086950178714e-05,
      "loss": 0.0044,
      "step": 23700
    },
    {
      "epoch": 1.7295207527901377,
      "grad_norm": 0.14358723163604736,
      "learning_rate": 3.270479247209862e-05,
      "loss": 0.0052,
      "step": 23710
    },
    {
      "epoch": 1.7302502005981473,
      "grad_norm": 0.21116642653942108,
      "learning_rate": 3.269749799401853e-05,
      "loss": 0.0037,
      "step": 23720
    },
    {
      "epoch": 1.7309796484061566,
      "grad_norm": 0.2300100177526474,
      "learning_rate": 3.2690203515938436e-05,
      "loss": 0.0033,
      "step": 23730
    },
    {
      "epoch": 1.731709096214166,
      "grad_norm": 0.08670961856842041,
      "learning_rate": 3.2682909037858344e-05,
      "loss": 0.0047,
      "step": 23740
    },
    {
      "epoch": 1.7324385440221752,
      "grad_norm": 0.4884885549545288,
      "learning_rate": 3.267561455977825e-05,
      "loss": 0.0053,
      "step": 23750
    },
    {
      "epoch": 1.7331679918301846,
      "grad_norm": 0.08728133141994476,
      "learning_rate": 3.266832008169816e-05,
      "loss": 0.0034,
      "step": 23760
    },
    {
      "epoch": 1.7338974396381939,
      "grad_norm": 0.011622697114944458,
      "learning_rate": 3.266102560361806e-05,
      "loss": 0.0032,
      "step": 23770
    },
    {
      "epoch": 1.7346268874462032,
      "grad_norm": 0.011446562595665455,
      "learning_rate": 3.265373112553797e-05,
      "loss": 0.0049,
      "step": 23780
    },
    {
      "epoch": 1.7353563352542125,
      "grad_norm": 0.14428693056106567,
      "learning_rate": 3.264643664745788e-05,
      "loss": 0.0058,
      "step": 23790
    },
    {
      "epoch": 1.7360857830622218,
      "grad_norm": 0.05974229797720909,
      "learning_rate": 3.263914216937778e-05,
      "loss": 0.0049,
      "step": 23800
    },
    {
      "epoch": 1.7368152308702314,
      "grad_norm": 0.45348653197288513,
      "learning_rate": 3.263184769129769e-05,
      "loss": 0.0036,
      "step": 23810
    },
    {
      "epoch": 1.7375446786782405,
      "grad_norm": 0.38927316665649414,
      "learning_rate": 3.26245532132176e-05,
      "loss": 0.0044,
      "step": 23820
    },
    {
      "epoch": 1.73827412648625,
      "grad_norm": 0.28808629512786865,
      "learning_rate": 3.26172587351375e-05,
      "loss": 0.0036,
      "step": 23830
    },
    {
      "epoch": 1.7390035742942591,
      "grad_norm": 0.18192090094089508,
      "learning_rate": 3.2609964257057406e-05,
      "loss": 0.0041,
      "step": 23840
    },
    {
      "epoch": 1.7397330221022687,
      "grad_norm": 0.5184106230735779,
      "learning_rate": 3.260266977897732e-05,
      "loss": 0.0044,
      "step": 23850
    },
    {
      "epoch": 1.7404624699102778,
      "grad_norm": 0.230483278632164,
      "learning_rate": 3.259537530089722e-05,
      "loss": 0.0039,
      "step": 23860
    },
    {
      "epoch": 1.7411919177182873,
      "grad_norm": 0.27946117520332336,
      "learning_rate": 3.258808082281713e-05,
      "loss": 0.0044,
      "step": 23870
    },
    {
      "epoch": 1.7419213655262966,
      "grad_norm": 0.3453812301158905,
      "learning_rate": 3.2580786344737036e-05,
      "loss": 0.004,
      "step": 23880
    },
    {
      "epoch": 1.742650813334306,
      "grad_norm": 0.60185307264328,
      "learning_rate": 3.257349186665694e-05,
      "loss": 0.0052,
      "step": 23890
    },
    {
      "epoch": 1.7433802611423153,
      "grad_norm": 0.25988128781318665,
      "learning_rate": 3.2566197388576844e-05,
      "loss": 0.0052,
      "step": 23900
    },
    {
      "epoch": 1.7441097089503246,
      "grad_norm": 0.1442602127790451,
      "learning_rate": 3.255890291049676e-05,
      "loss": 0.0051,
      "step": 23910
    },
    {
      "epoch": 1.744839156758334,
      "grad_norm": 0.23015351593494415,
      "learning_rate": 3.2551608432416666e-05,
      "loss": 0.0034,
      "step": 23920
    },
    {
      "epoch": 1.7455686045663432,
      "grad_norm": 0.30532053112983704,
      "learning_rate": 3.254431395433657e-05,
      "loss": 0.0051,
      "step": 23930
    },
    {
      "epoch": 1.7462980523743528,
      "grad_norm": 0.5762155652046204,
      "learning_rate": 3.2537019476256474e-05,
      "loss": 0.0041,
      "step": 23940
    },
    {
      "epoch": 1.7470275001823619,
      "grad_norm": 0.20901453495025635,
      "learning_rate": 3.252972499817638e-05,
      "loss": 0.0041,
      "step": 23950
    },
    {
      "epoch": 1.7477569479903714,
      "grad_norm": 0.5401341915130615,
      "learning_rate": 3.252243052009629e-05,
      "loss": 0.0048,
      "step": 23960
    },
    {
      "epoch": 1.7484863957983805,
      "grad_norm": 0.04502888023853302,
      "learning_rate": 3.25151360420162e-05,
      "loss": 0.0033,
      "step": 23970
    },
    {
      "epoch": 1.74921584360639,
      "grad_norm": 0.3740849494934082,
      "learning_rate": 3.2507841563936104e-05,
      "loss": 0.0043,
      "step": 23980
    },
    {
      "epoch": 1.7499452914143991,
      "grad_norm": 0.1731642484664917,
      "learning_rate": 3.250054708585601e-05,
      "loss": 0.0047,
      "step": 23990
    },
    {
      "epoch": 1.7506747392224087,
      "grad_norm": 0.05934995040297508,
      "learning_rate": 3.249325260777591e-05,
      "loss": 0.0063,
      "step": 24000
    },
    {
      "epoch": 1.751404187030418,
      "grad_norm": 0.17235668003559113,
      "learning_rate": 3.248595812969582e-05,
      "loss": 0.0038,
      "step": 24010
    },
    {
      "epoch": 1.7521336348384273,
      "grad_norm": 0.6068799495697021,
      "learning_rate": 3.247866365161573e-05,
      "loss": 0.0051,
      "step": 24020
    },
    {
      "epoch": 1.7528630826464366,
      "grad_norm": 0.4613030254840851,
      "learning_rate": 3.2471369173535635e-05,
      "loss": 0.0037,
      "step": 24030
    },
    {
      "epoch": 1.753592530454446,
      "grad_norm": 0.031024953350424767,
      "learning_rate": 3.246407469545554e-05,
      "loss": 0.0033,
      "step": 24040
    },
    {
      "epoch": 1.7543219782624553,
      "grad_norm": 0.006478145718574524,
      "learning_rate": 3.245678021737545e-05,
      "loss": 0.0045,
      "step": 24050
    },
    {
      "epoch": 1.7550514260704646,
      "grad_norm": 0.3830312490463257,
      "learning_rate": 3.244948573929535e-05,
      "loss": 0.0045,
      "step": 24060
    },
    {
      "epoch": 1.7557808738784741,
      "grad_norm": 0.2861783504486084,
      "learning_rate": 3.244219126121526e-05,
      "loss": 0.0035,
      "step": 24070
    },
    {
      "epoch": 1.7565103216864832,
      "grad_norm": 0.4401857554912567,
      "learning_rate": 3.2434896783135166e-05,
      "loss": 0.0043,
      "step": 24080
    },
    {
      "epoch": 1.7572397694944928,
      "grad_norm": 0.17801016569137573,
      "learning_rate": 3.2427602305055074e-05,
      "loss": 0.0053,
      "step": 24090
    },
    {
      "epoch": 1.7579692173025019,
      "grad_norm": 0.4030303359031677,
      "learning_rate": 3.242030782697498e-05,
      "loss": 0.0054,
      "step": 24100
    },
    {
      "epoch": 1.7586986651105114,
      "grad_norm": 0.4026281237602234,
      "learning_rate": 3.241301334889489e-05,
      "loss": 0.0044,
      "step": 24110
    },
    {
      "epoch": 1.7594281129185205,
      "grad_norm": 0.28913500905036926,
      "learning_rate": 3.2405718870814796e-05,
      "loss": 0.0048,
      "step": 24120
    },
    {
      "epoch": 1.76015756072653,
      "grad_norm": 0.05793299153447151,
      "learning_rate": 3.23984243927347e-05,
      "loss": 0.0039,
      "step": 24130
    },
    {
      "epoch": 1.7608870085345394,
      "grad_norm": 0.23071618378162384,
      "learning_rate": 3.2391129914654605e-05,
      "loss": 0.0043,
      "step": 24140
    },
    {
      "epoch": 1.7616164563425487,
      "grad_norm": 0.11700256913900375,
      "learning_rate": 3.238383543657452e-05,
      "loss": 0.0032,
      "step": 24150
    },
    {
      "epoch": 1.762345904150558,
      "grad_norm": 0.14468885958194733,
      "learning_rate": 3.237654095849442e-05,
      "loss": 0.0043,
      "step": 24160
    },
    {
      "epoch": 1.7630753519585673,
      "grad_norm": 0.4024452269077301,
      "learning_rate": 3.236924648041433e-05,
      "loss": 0.005,
      "step": 24170
    },
    {
      "epoch": 1.7638047997665767,
      "grad_norm": 0.2704826891422272,
      "learning_rate": 3.2361952002334235e-05,
      "loss": 0.0046,
      "step": 24180
    },
    {
      "epoch": 1.764534247574586,
      "grad_norm": 0.05813673883676529,
      "learning_rate": 3.235465752425414e-05,
      "loss": 0.0057,
      "step": 24190
    },
    {
      "epoch": 1.7652636953825955,
      "grad_norm": 0.46063002943992615,
      "learning_rate": 3.234736304617404e-05,
      "loss": 0.004,
      "step": 24200
    },
    {
      "epoch": 1.7659931431906046,
      "grad_norm": 0.48989856243133545,
      "learning_rate": 3.234006856809396e-05,
      "loss": 0.0057,
      "step": 24210
    },
    {
      "epoch": 1.7667225909986142,
      "grad_norm": 0.2595999538898468,
      "learning_rate": 3.2332774090013865e-05,
      "loss": 0.0056,
      "step": 24220
    },
    {
      "epoch": 1.7674520388066233,
      "grad_norm": 0.033481139689683914,
      "learning_rate": 3.2325479611933765e-05,
      "loss": 0.0036,
      "step": 24230
    },
    {
      "epoch": 1.7681814866146328,
      "grad_norm": 0.1811685413122177,
      "learning_rate": 3.231818513385367e-05,
      "loss": 0.0037,
      "step": 24240
    },
    {
      "epoch": 1.768910934422642,
      "grad_norm": 0.08857479691505432,
      "learning_rate": 3.231089065577358e-05,
      "loss": 0.0026,
      "step": 24250
    },
    {
      "epoch": 1.7696403822306515,
      "grad_norm": 0.589055597782135,
      "learning_rate": 3.230359617769349e-05,
      "loss": 0.0031,
      "step": 24260
    },
    {
      "epoch": 1.7703698300386608,
      "grad_norm": 0.2586398720741272,
      "learning_rate": 3.2296301699613396e-05,
      "loss": 0.0038,
      "step": 24270
    },
    {
      "epoch": 1.77109927784667,
      "grad_norm": 0.6585397124290466,
      "learning_rate": 3.22890072215333e-05,
      "loss": 0.0039,
      "step": 24280
    },
    {
      "epoch": 1.7718287256546794,
      "grad_norm": 0.08712770789861679,
      "learning_rate": 3.228171274345321e-05,
      "loss": 0.0028,
      "step": 24290
    },
    {
      "epoch": 1.7725581734626887,
      "grad_norm": 0.05807683616876602,
      "learning_rate": 3.227441826537311e-05,
      "loss": 0.0038,
      "step": 24300
    },
    {
      "epoch": 1.773287621270698,
      "grad_norm": 0.05854230746626854,
      "learning_rate": 3.226712378729302e-05,
      "loss": 0.0029,
      "step": 24310
    },
    {
      "epoch": 1.7740170690787074,
      "grad_norm": 0.4600726068019867,
      "learning_rate": 3.225982930921293e-05,
      "loss": 0.004,
      "step": 24320
    },
    {
      "epoch": 1.774746516886717,
      "grad_norm": 0.22929131984710693,
      "learning_rate": 3.2252534831132834e-05,
      "loss": 0.0046,
      "step": 24330
    },
    {
      "epoch": 1.775475964694726,
      "grad_norm": 0.032048046588897705,
      "learning_rate": 3.224524035305274e-05,
      "loss": 0.0035,
      "step": 24340
    },
    {
      "epoch": 1.7762054125027356,
      "grad_norm": 0.2019643932580948,
      "learning_rate": 3.223794587497265e-05,
      "loss": 0.0049,
      "step": 24350
    },
    {
      "epoch": 1.7769348603107447,
      "grad_norm": 0.08669479936361313,
      "learning_rate": 3.223065139689255e-05,
      "loss": 0.0031,
      "step": 24360
    },
    {
      "epoch": 1.7776643081187542,
      "grad_norm": 0.40181127190589905,
      "learning_rate": 3.222335691881246e-05,
      "loss": 0.0038,
      "step": 24370
    },
    {
      "epoch": 1.7783937559267633,
      "grad_norm": 0.1726061850786209,
      "learning_rate": 3.221606244073237e-05,
      "loss": 0.0042,
      "step": 24380
    },
    {
      "epoch": 1.7791232037347728,
      "grad_norm": 0.03561926633119583,
      "learning_rate": 3.220876796265227e-05,
      "loss": 0.0033,
      "step": 24390
    },
    {
      "epoch": 1.7798526515427822,
      "grad_norm": 0.4206969141960144,
      "learning_rate": 3.220147348457218e-05,
      "loss": 0.0042,
      "step": 24400
    },
    {
      "epoch": 1.7805820993507915,
      "grad_norm": 0.2977919578552246,
      "learning_rate": 3.219417900649209e-05,
      "loss": 0.0056,
      "step": 24410
    },
    {
      "epoch": 1.7813115471588008,
      "grad_norm": 0.2594519853591919,
      "learning_rate": 3.2186884528411995e-05,
      "loss": 0.003,
      "step": 24420
    },
    {
      "epoch": 1.7820409949668101,
      "grad_norm": 0.03315263241529465,
      "learning_rate": 3.2179590050331896e-05,
      "loss": 0.0042,
      "step": 24430
    },
    {
      "epoch": 1.7827704427748194,
      "grad_norm": 0.14429041743278503,
      "learning_rate": 3.217229557225181e-05,
      "loss": 0.0033,
      "step": 24440
    },
    {
      "epoch": 1.7834998905828288,
      "grad_norm": 0.029908528551459312,
      "learning_rate": 3.216500109417172e-05,
      "loss": 0.0043,
      "step": 24450
    },
    {
      "epoch": 1.784229338390838,
      "grad_norm": 0.0687698945403099,
      "learning_rate": 3.215770661609162e-05,
      "loss": 0.006,
      "step": 24460
    },
    {
      "epoch": 1.7849587861988474,
      "grad_norm": 0.4900478422641754,
      "learning_rate": 3.2150412138011526e-05,
      "loss": 0.0038,
      "step": 24470
    },
    {
      "epoch": 1.785688234006857,
      "grad_norm": 0.634027898311615,
      "learning_rate": 3.2143117659931433e-05,
      "loss": 0.0032,
      "step": 24480
    },
    {
      "epoch": 1.786417681814866,
      "grad_norm": 0.2021513283252716,
      "learning_rate": 3.213582318185134e-05,
      "loss": 0.0041,
      "step": 24490
    },
    {
      "epoch": 1.7871471296228756,
      "grad_norm": 0.1727321594953537,
      "learning_rate": 3.212852870377125e-05,
      "loss": 0.0038,
      "step": 24500
    },
    {
      "epoch": 1.7878765774308847,
      "grad_norm": 0.37366652488708496,
      "learning_rate": 3.2121234225691156e-05,
      "loss": 0.0048,
      "step": 24510
    },
    {
      "epoch": 1.7886060252388942,
      "grad_norm": 0.23024311661720276,
      "learning_rate": 3.2113939747611064e-05,
      "loss": 0.0039,
      "step": 24520
    },
    {
      "epoch": 1.7893354730469035,
      "grad_norm": 0.11499860137701035,
      "learning_rate": 3.2106645269530964e-05,
      "loss": 0.0049,
      "step": 24530
    },
    {
      "epoch": 1.7900649208549129,
      "grad_norm": 0.3461882472038269,
      "learning_rate": 3.209935079145087e-05,
      "loss": 0.0045,
      "step": 24540
    },
    {
      "epoch": 1.7907943686629222,
      "grad_norm": 0.34483101963996887,
      "learning_rate": 3.209205631337078e-05,
      "loss": 0.0052,
      "step": 24550
    },
    {
      "epoch": 1.7915238164709315,
      "grad_norm": 0.23156526684761047,
      "learning_rate": 3.208476183529069e-05,
      "loss": 0.004,
      "step": 24560
    },
    {
      "epoch": 1.7922532642789408,
      "grad_norm": 0.11558344215154648,
      "learning_rate": 3.2077467357210594e-05,
      "loss": 0.0041,
      "step": 24570
    },
    {
      "epoch": 1.7929827120869501,
      "grad_norm": 0.34657326340675354,
      "learning_rate": 3.20701728791305e-05,
      "loss": 0.0059,
      "step": 24580
    },
    {
      "epoch": 1.7937121598949595,
      "grad_norm": 0.37530815601348877,
      "learning_rate": 3.20628784010504e-05,
      "loss": 0.0039,
      "step": 24590
    },
    {
      "epoch": 1.7944416077029688,
      "grad_norm": 0.00827715266495943,
      "learning_rate": 3.205558392297031e-05,
      "loss": 0.0043,
      "step": 24600
    },
    {
      "epoch": 1.7951710555109783,
      "grad_norm": 0.17869587242603302,
      "learning_rate": 3.204828944489022e-05,
      "loss": 0.0037,
      "step": 24610
    },
    {
      "epoch": 1.7959005033189874,
      "grad_norm": 0.029714496806263924,
      "learning_rate": 3.2040994966810125e-05,
      "loss": 0.005,
      "step": 24620
    },
    {
      "epoch": 1.796629951126997,
      "grad_norm": 0.23109158873558044,
      "learning_rate": 3.203370048873003e-05,
      "loss": 0.0042,
      "step": 24630
    },
    {
      "epoch": 1.797359398935006,
      "grad_norm": 0.12641620635986328,
      "learning_rate": 3.202640601064994e-05,
      "loss": 0.0042,
      "step": 24640
    },
    {
      "epoch": 1.7980888467430156,
      "grad_norm": 0.16803637146949768,
      "learning_rate": 3.201911153256985e-05,
      "loss": 0.0064,
      "step": 24650
    },
    {
      "epoch": 1.7988182945510247,
      "grad_norm": 0.009804307483136654,
      "learning_rate": 3.201181705448975e-05,
      "loss": 0.0034,
      "step": 24660
    },
    {
      "epoch": 1.7995477423590343,
      "grad_norm": 0.11552214622497559,
      "learning_rate": 3.2004522576409656e-05,
      "loss": 0.0033,
      "step": 24670
    },
    {
      "epoch": 1.8002771901670436,
      "grad_norm": 0.5185597538948059,
      "learning_rate": 3.199722809832957e-05,
      "loss": 0.0053,
      "step": 24680
    },
    {
      "epoch": 1.801006637975053,
      "grad_norm": 0.5927574038505554,
      "learning_rate": 3.198993362024947e-05,
      "loss": 0.0054,
      "step": 24690
    },
    {
      "epoch": 1.8017360857830622,
      "grad_norm": 0.029139943420886993,
      "learning_rate": 3.198263914216938e-05,
      "loss": 0.0033,
      "step": 24700
    },
    {
      "epoch": 1.8024655335910715,
      "grad_norm": 0.03149693086743355,
      "learning_rate": 3.1975344664089286e-05,
      "loss": 0.0048,
      "step": 24710
    },
    {
      "epoch": 1.8031949813990809,
      "grad_norm": 0.44549211859703064,
      "learning_rate": 3.1968050186009194e-05,
      "loss": 0.0041,
      "step": 24720
    },
    {
      "epoch": 1.8039244292070902,
      "grad_norm": 0.20272861421108246,
      "learning_rate": 3.1960755707929095e-05,
      "loss": 0.0043,
      "step": 24730
    },
    {
      "epoch": 1.8046538770150997,
      "grad_norm": 0.32750412821769714,
      "learning_rate": 3.195346122984901e-05,
      "loss": 0.0046,
      "step": 24740
    },
    {
      "epoch": 1.8053833248231088,
      "grad_norm": 0.20269444584846497,
      "learning_rate": 3.1946166751768916e-05,
      "loss": 0.004,
      "step": 24750
    },
    {
      "epoch": 1.8061127726311184,
      "grad_norm": 0.5196602940559387,
      "learning_rate": 3.193887227368882e-05,
      "loss": 0.0047,
      "step": 24760
    },
    {
      "epoch": 1.8068422204391275,
      "grad_norm": 0.3517128825187683,
      "learning_rate": 3.1931577795608725e-05,
      "loss": 0.0054,
      "step": 24770
    },
    {
      "epoch": 1.807571668247137,
      "grad_norm": 0.1729695200920105,
      "learning_rate": 3.192428331752863e-05,
      "loss": 0.0032,
      "step": 24780
    },
    {
      "epoch": 1.808301116055146,
      "grad_norm": 0.4711487889289856,
      "learning_rate": 3.191698883944854e-05,
      "loss": 0.0033,
      "step": 24790
    },
    {
      "epoch": 1.8090305638631556,
      "grad_norm": 0.1448087841272354,
      "learning_rate": 3.190969436136845e-05,
      "loss": 0.0056,
      "step": 24800
    },
    {
      "epoch": 1.809760011671165,
      "grad_norm": 0.17381177842617035,
      "learning_rate": 3.1902399883288355e-05,
      "loss": 0.0036,
      "step": 24810
    },
    {
      "epoch": 1.8104894594791743,
      "grad_norm": 0.14432215690612793,
      "learning_rate": 3.1895105405208256e-05,
      "loss": 0.005,
      "step": 24820
    },
    {
      "epoch": 1.8112189072871836,
      "grad_norm": 0.2874876856803894,
      "learning_rate": 3.188781092712816e-05,
      "loss": 0.004,
      "step": 24830
    },
    {
      "epoch": 1.811948355095193,
      "grad_norm": 0.43120431900024414,
      "learning_rate": 3.188051644904807e-05,
      "loss": 0.0065,
      "step": 24840
    },
    {
      "epoch": 1.8126778029032022,
      "grad_norm": 0.20204786956310272,
      "learning_rate": 3.187322197096798e-05,
      "loss": 0.0037,
      "step": 24850
    },
    {
      "epoch": 1.8134072507112116,
      "grad_norm": 0.11606141179800034,
      "learning_rate": 3.1865927492887886e-05,
      "loss": 0.0031,
      "step": 24860
    },
    {
      "epoch": 1.814136698519221,
      "grad_norm": 0.08754090219736099,
      "learning_rate": 3.185863301480779e-05,
      "loss": 0.0052,
      "step": 24870
    },
    {
      "epoch": 1.8148661463272302,
      "grad_norm": 0.247733473777771,
      "learning_rate": 3.18513385367277e-05,
      "loss": 0.0043,
      "step": 24880
    },
    {
      "epoch": 1.8155955941352397,
      "grad_norm": 0.34569546580314636,
      "learning_rate": 3.18440440586476e-05,
      "loss": 0.0032,
      "step": 24890
    },
    {
      "epoch": 1.8163250419432488,
      "grad_norm": 0.31661006808280945,
      "learning_rate": 3.183674958056751e-05,
      "loss": 0.0056,
      "step": 24900
    },
    {
      "epoch": 1.8170544897512584,
      "grad_norm": 0.1150273010134697,
      "learning_rate": 3.182945510248742e-05,
      "loss": 0.0047,
      "step": 24910
    },
    {
      "epoch": 1.8177839375592675,
      "grad_norm": 0.31733086705207825,
      "learning_rate": 3.1822160624407324e-05,
      "loss": 0.0046,
      "step": 24920
    },
    {
      "epoch": 1.818513385367277,
      "grad_norm": 0.02936624549329281,
      "learning_rate": 3.181486614632723e-05,
      "loss": 0.0038,
      "step": 24930
    },
    {
      "epoch": 1.8192428331752863,
      "grad_norm": 0.28738081455230713,
      "learning_rate": 3.180757166824714e-05,
      "loss": 0.003,
      "step": 24940
    },
    {
      "epoch": 1.8199722809832957,
      "grad_norm": 0.030929014086723328,
      "learning_rate": 3.180027719016705e-05,
      "loss": 0.0052,
      "step": 24950
    },
    {
      "epoch": 1.820701728791305,
      "grad_norm": 0.2019723355770111,
      "learning_rate": 3.179298271208695e-05,
      "loss": 0.0054,
      "step": 24960
    },
    {
      "epoch": 1.8214311765993143,
      "grad_norm": 0.009157828986644745,
      "learning_rate": 3.178568823400686e-05,
      "loss": 0.0044,
      "step": 24970
    },
    {
      "epoch": 1.8221606244073236,
      "grad_norm": 0.03032759204506874,
      "learning_rate": 3.177839375592677e-05,
      "loss": 0.003,
      "step": 24980
    },
    {
      "epoch": 1.822890072215333,
      "grad_norm": 0.43168407678604126,
      "learning_rate": 3.177109927784667e-05,
      "loss": 0.0033,
      "step": 24990
    },
    {
      "epoch": 1.8236195200233425,
      "grad_norm": 0.2308254837989807,
      "learning_rate": 3.176380479976658e-05,
      "loss": 0.0056,
      "step": 25000
    },
    {
      "epoch": 1.8243489678313516,
      "grad_norm": 0.058343518525362015,
      "learning_rate": 3.1756510321686485e-05,
      "loss": 0.0033,
      "step": 25010
    },
    {
      "epoch": 1.8250784156393611,
      "grad_norm": 0.05861892178654671,
      "learning_rate": 3.1749215843606386e-05,
      "loss": 0.0036,
      "step": 25020
    },
    {
      "epoch": 1.8258078634473702,
      "grad_norm": 0.060072287917137146,
      "learning_rate": 3.17419213655263e-05,
      "loss": 0.0049,
      "step": 25030
    },
    {
      "epoch": 1.8265373112553798,
      "grad_norm": 0.07826487720012665,
      "learning_rate": 3.173462688744621e-05,
      "loss": 0.0036,
      "step": 25040
    },
    {
      "epoch": 1.8272667590633889,
      "grad_norm": 0.2884814143180847,
      "learning_rate": 3.172733240936611e-05,
      "loss": 0.0034,
      "step": 25050
    },
    {
      "epoch": 1.8279962068713984,
      "grad_norm": 0.2595108151435852,
      "learning_rate": 3.1720037931286016e-05,
      "loss": 0.0045,
      "step": 25060
    },
    {
      "epoch": 1.8287256546794077,
      "grad_norm": 0.3172253370285034,
      "learning_rate": 3.1712743453205923e-05,
      "loss": 0.0037,
      "step": 25070
    },
    {
      "epoch": 1.829455102487417,
      "grad_norm": 0.31692343950271606,
      "learning_rate": 3.170544897512583e-05,
      "loss": 0.0042,
      "step": 25080
    },
    {
      "epoch": 1.8301845502954264,
      "grad_norm": 0.029813332483172417,
      "learning_rate": 3.169815449704574e-05,
      "loss": 0.005,
      "step": 25090
    },
    {
      "epoch": 1.8309139981034357,
      "grad_norm": 0.2985328733921051,
      "learning_rate": 3.1690860018965646e-05,
      "loss": 0.0046,
      "step": 25100
    },
    {
      "epoch": 1.831643445911445,
      "grad_norm": 0.20175467431545258,
      "learning_rate": 3.1683565540885554e-05,
      "loss": 0.0045,
      "step": 25110
    },
    {
      "epoch": 1.8323728937194543,
      "grad_norm": 0.2880667448043823,
      "learning_rate": 3.1676271062805454e-05,
      "loss": 0.0041,
      "step": 25120
    },
    {
      "epoch": 1.8331023415274639,
      "grad_norm": 0.24483662843704224,
      "learning_rate": 3.166897658472536e-05,
      "loss": 0.0043,
      "step": 25130
    },
    {
      "epoch": 1.833831789335473,
      "grad_norm": 0.14608311653137207,
      "learning_rate": 3.166168210664527e-05,
      "loss": 0.0041,
      "step": 25140
    },
    {
      "epoch": 1.8345612371434825,
      "grad_norm": 0.08761361986398697,
      "learning_rate": 3.165438762856518e-05,
      "loss": 0.0031,
      "step": 25150
    },
    {
      "epoch": 1.8352906849514916,
      "grad_norm": 0.17325203120708466,
      "learning_rate": 3.1647093150485084e-05,
      "loss": 0.0032,
      "step": 25160
    },
    {
      "epoch": 1.8360201327595012,
      "grad_norm": 0.2880924344062805,
      "learning_rate": 3.163979867240499e-05,
      "loss": 0.0031,
      "step": 25170
    },
    {
      "epoch": 1.8367495805675103,
      "grad_norm": 0.15853430330753326,
      "learning_rate": 3.16325041943249e-05,
      "loss": 0.0032,
      "step": 25180
    },
    {
      "epoch": 1.8374790283755198,
      "grad_norm": 0.37463903427124023,
      "learning_rate": 3.16252097162448e-05,
      "loss": 0.0044,
      "step": 25190
    },
    {
      "epoch": 1.8382084761835291,
      "grad_norm": 0.34493401646614075,
      "learning_rate": 3.161791523816471e-05,
      "loss": 0.0036,
      "step": 25200
    },
    {
      "epoch": 1.8389379239915384,
      "grad_norm": 0.05918492004275322,
      "learning_rate": 3.161062076008462e-05,
      "loss": 0.0034,
      "step": 25210
    },
    {
      "epoch": 1.8396673717995478,
      "grad_norm": 0.12278090417385101,
      "learning_rate": 3.160332628200452e-05,
      "loss": 0.0057,
      "step": 25220
    },
    {
      "epoch": 1.840396819607557,
      "grad_norm": 0.33140772581100464,
      "learning_rate": 3.159603180392443e-05,
      "loss": 0.0047,
      "step": 25230
    },
    {
      "epoch": 1.8411262674155664,
      "grad_norm": 0.05855206772685051,
      "learning_rate": 3.158873732584434e-05,
      "loss": 0.0046,
      "step": 25240
    },
    {
      "epoch": 1.8418557152235757,
      "grad_norm": 0.11481926590204239,
      "learning_rate": 3.1581442847764245e-05,
      "loss": 0.0044,
      "step": 25250
    },
    {
      "epoch": 1.842585163031585,
      "grad_norm": 0.4461417496204376,
      "learning_rate": 3.157414836968415e-05,
      "loss": 0.005,
      "step": 25260
    },
    {
      "epoch": 1.8433146108395944,
      "grad_norm": 0.28846338391304016,
      "learning_rate": 3.156685389160406e-05,
      "loss": 0.0028,
      "step": 25270
    },
    {
      "epoch": 1.844044058647604,
      "grad_norm": 0.23044633865356445,
      "learning_rate": 3.155955941352397e-05,
      "loss": 0.0052,
      "step": 25280
    },
    {
      "epoch": 1.844773506455613,
      "grad_norm": 0.14549940824508667,
      "learning_rate": 3.155226493544387e-05,
      "loss": 0.0043,
      "step": 25290
    },
    {
      "epoch": 1.8455029542636225,
      "grad_norm": 0.059617429971694946,
      "learning_rate": 3.1544970457363776e-05,
      "loss": 0.0047,
      "step": 25300
    },
    {
      "epoch": 1.8462324020716316,
      "grad_norm": 0.11567986011505127,
      "learning_rate": 3.1537675979283684e-05,
      "loss": 0.0029,
      "step": 25310
    },
    {
      "epoch": 1.8469618498796412,
      "grad_norm": 0.2340773642063141,
      "learning_rate": 3.153038150120359e-05,
      "loss": 0.0025,
      "step": 25320
    },
    {
      "epoch": 1.8476912976876505,
      "grad_norm": 0.2875484526157379,
      "learning_rate": 3.15230870231235e-05,
      "loss": 0.0044,
      "step": 25330
    },
    {
      "epoch": 1.8484207454956598,
      "grad_norm": 0.34556055068969727,
      "learning_rate": 3.1515792545043406e-05,
      "loss": 0.0033,
      "step": 25340
    },
    {
      "epoch": 1.8491501933036691,
      "grad_norm": 0.08629883080720901,
      "learning_rate": 3.150849806696331e-05,
      "loss": 0.0052,
      "step": 25350
    },
    {
      "epoch": 1.8498796411116785,
      "grad_norm": 0.2921796143054962,
      "learning_rate": 3.1501203588883215e-05,
      "loss": 0.0057,
      "step": 25360
    },
    {
      "epoch": 1.8506090889196878,
      "grad_norm": 0.49134528636932373,
      "learning_rate": 3.149390911080312e-05,
      "loss": 0.0046,
      "step": 25370
    },
    {
      "epoch": 1.851338536727697,
      "grad_norm": 0.2531508803367615,
      "learning_rate": 3.148661463272303e-05,
      "loss": 0.0041,
      "step": 25380
    },
    {
      "epoch": 1.8520679845357064,
      "grad_norm": 0.2676278352737427,
      "learning_rate": 3.147932015464294e-05,
      "loss": 0.0049,
      "step": 25390
    },
    {
      "epoch": 1.8527974323437157,
      "grad_norm": 0.17268429696559906,
      "learning_rate": 3.1472025676562845e-05,
      "loss": 0.0053,
      "step": 25400
    },
    {
      "epoch": 1.8535268801517253,
      "grad_norm": 0.008837650530040264,
      "learning_rate": 3.146473119848275e-05,
      "loss": 0.0038,
      "step": 25410
    },
    {
      "epoch": 1.8542563279597344,
      "grad_norm": 0.1162521168589592,
      "learning_rate": 3.145743672040265e-05,
      "loss": 0.0036,
      "step": 25420
    },
    {
      "epoch": 1.854985775767744,
      "grad_norm": 0.3948892652988434,
      "learning_rate": 3.145014224232256e-05,
      "loss": 0.0033,
      "step": 25430
    },
    {
      "epoch": 1.855715223575753,
      "grad_norm": 0.010798340663313866,
      "learning_rate": 3.1442847764242475e-05,
      "loss": 0.0029,
      "step": 25440
    },
    {
      "epoch": 1.8564446713837626,
      "grad_norm": 0.2016533464193344,
      "learning_rate": 3.1435553286162376e-05,
      "loss": 0.0041,
      "step": 25450
    },
    {
      "epoch": 1.8571741191917717,
      "grad_norm": 0.35670483112335205,
      "learning_rate": 3.142825880808228e-05,
      "loss": 0.0029,
      "step": 25460
    },
    {
      "epoch": 1.8579035669997812,
      "grad_norm": 0.5175767540931702,
      "learning_rate": 3.142096433000219e-05,
      "loss": 0.003,
      "step": 25470
    },
    {
      "epoch": 1.8586330148077905,
      "grad_norm": 0.09127584844827652,
      "learning_rate": 3.14136698519221e-05,
      "loss": 0.0028,
      "step": 25480
    },
    {
      "epoch": 1.8593624626157998,
      "grad_norm": 0.3341907560825348,
      "learning_rate": 3.1406375373842e-05,
      "loss": 0.003,
      "step": 25490
    },
    {
      "epoch": 1.8600919104238092,
      "grad_norm": 0.403674453496933,
      "learning_rate": 3.139908089576191e-05,
      "loss": 0.0047,
      "step": 25500
    },
    {
      "epoch": 1.8608213582318185,
      "grad_norm": 0.14462171494960785,
      "learning_rate": 3.139178641768182e-05,
      "loss": 0.0031,
      "step": 25510
    },
    {
      "epoch": 1.8615508060398278,
      "grad_norm": 0.3740515112876892,
      "learning_rate": 3.138449193960172e-05,
      "loss": 0.0049,
      "step": 25520
    },
    {
      "epoch": 1.8622802538478371,
      "grad_norm": 0.5764350891113281,
      "learning_rate": 3.137719746152163e-05,
      "loss": 0.0048,
      "step": 25530
    },
    {
      "epoch": 1.8630097016558467,
      "grad_norm": 0.2839649021625519,
      "learning_rate": 3.136990298344154e-05,
      "loss": 0.0061,
      "step": 25540
    },
    {
      "epoch": 1.8637391494638558,
      "grad_norm": 0.014160824939608574,
      "learning_rate": 3.136260850536144e-05,
      "loss": 0.0042,
      "step": 25550
    },
    {
      "epoch": 1.8644685972718653,
      "grad_norm": 0.009201958775520325,
      "learning_rate": 3.135531402728135e-05,
      "loss": 0.0037,
      "step": 25560
    },
    {
      "epoch": 1.8651980450798744,
      "grad_norm": 0.05808180943131447,
      "learning_rate": 3.134801954920126e-05,
      "loss": 0.0044,
      "step": 25570
    },
    {
      "epoch": 1.865927492887884,
      "grad_norm": 0.030807169154286385,
      "learning_rate": 3.134072507112116e-05,
      "loss": 0.0052,
      "step": 25580
    },
    {
      "epoch": 1.866656940695893,
      "grad_norm": 0.5763127207756042,
      "learning_rate": 3.133343059304107e-05,
      "loss": 0.0035,
      "step": 25590
    },
    {
      "epoch": 1.8673863885039026,
      "grad_norm": 0.08660908043384552,
      "learning_rate": 3.1326136114960975e-05,
      "loss": 0.0033,
      "step": 25600
    },
    {
      "epoch": 1.868115836311912,
      "grad_norm": 0.48802754282951355,
      "learning_rate": 3.131884163688088e-05,
      "loss": 0.0046,
      "step": 25610
    },
    {
      "epoch": 1.8688452841199212,
      "grad_norm": 0.40278056263923645,
      "learning_rate": 3.131154715880079e-05,
      "loss": 0.0053,
      "step": 25620
    },
    {
      "epoch": 1.8695747319279306,
      "grad_norm": 0.11540509015321732,
      "learning_rate": 3.13042526807207e-05,
      "loss": 0.0032,
      "step": 25630
    },
    {
      "epoch": 1.8703041797359399,
      "grad_norm": 0.34544357657432556,
      "learning_rate": 3.1296958202640605e-05,
      "loss": 0.0054,
      "step": 25640
    },
    {
      "epoch": 1.8710336275439492,
      "grad_norm": 0.009201878681778908,
      "learning_rate": 3.1289663724560506e-05,
      "loss": 0.0048,
      "step": 25650
    },
    {
      "epoch": 1.8717630753519585,
      "grad_norm": 0.2342582643032074,
      "learning_rate": 3.1282369246480414e-05,
      "loss": 0.0039,
      "step": 25660
    },
    {
      "epoch": 1.872492523159968,
      "grad_norm": 0.25867539644241333,
      "learning_rate": 3.127507476840032e-05,
      "loss": 0.0055,
      "step": 25670
    },
    {
      "epoch": 1.8732219709679772,
      "grad_norm": 0.25968754291534424,
      "learning_rate": 3.126778029032023e-05,
      "loss": 0.0059,
      "step": 25680
    },
    {
      "epoch": 1.8739514187759867,
      "grad_norm": 0.32937091588974,
      "learning_rate": 3.1260485812240136e-05,
      "loss": 0.0049,
      "step": 25690
    },
    {
      "epoch": 1.8746808665839958,
      "grad_norm": 0.2880914807319641,
      "learning_rate": 3.1253191334160044e-05,
      "loss": 0.0034,
      "step": 25700
    },
    {
      "epoch": 1.8754103143920053,
      "grad_norm": 0.11701291054487228,
      "learning_rate": 3.124589685607995e-05,
      "loss": 0.0051,
      "step": 25710
    },
    {
      "epoch": 1.8761397622000144,
      "grad_norm": 0.3170953691005707,
      "learning_rate": 3.123860237799985e-05,
      "loss": 0.0033,
      "step": 25720
    },
    {
      "epoch": 1.876869210008024,
      "grad_norm": 0.8388407230377197,
      "learning_rate": 3.123130789991976e-05,
      "loss": 0.006,
      "step": 25730
    },
    {
      "epoch": 1.8775986578160333,
      "grad_norm": 0.6140235662460327,
      "learning_rate": 3.1224013421839674e-05,
      "loss": 0.0048,
      "step": 25740
    },
    {
      "epoch": 1.8783281056240426,
      "grad_norm": 0.466263085603714,
      "learning_rate": 3.1216718943759575e-05,
      "loss": 0.0042,
      "step": 25750
    },
    {
      "epoch": 1.879057553432052,
      "grad_norm": 0.14656995236873627,
      "learning_rate": 3.120942446567948e-05,
      "loss": 0.003,
      "step": 25760
    },
    {
      "epoch": 1.8797870012400613,
      "grad_norm": 0.007799079641699791,
      "learning_rate": 3.120212998759939e-05,
      "loss": 0.0033,
      "step": 25770
    },
    {
      "epoch": 1.8805164490480706,
      "grad_norm": 0.059022583067417145,
      "learning_rate": 3.119483550951929e-05,
      "loss": 0.0047,
      "step": 25780
    },
    {
      "epoch": 1.88124589685608,
      "grad_norm": 0.12982222437858582,
      "learning_rate": 3.1187541031439205e-05,
      "loss": 0.0038,
      "step": 25790
    },
    {
      "epoch": 1.8819753446640894,
      "grad_norm": 0.08663102984428406,
      "learning_rate": 3.118024655335911e-05,
      "loss": 0.003,
      "step": 25800
    },
    {
      "epoch": 1.8827047924720985,
      "grad_norm": 0.31658390164375305,
      "learning_rate": 3.117295207527901e-05,
      "loss": 0.0053,
      "step": 25810
    },
    {
      "epoch": 1.883434240280108,
      "grad_norm": 0.030123388394713402,
      "learning_rate": 3.116565759719892e-05,
      "loss": 0.0035,
      "step": 25820
    },
    {
      "epoch": 1.8841636880881172,
      "grad_norm": 0.34472185373306274,
      "learning_rate": 3.115836311911883e-05,
      "loss": 0.004,
      "step": 25830
    },
    {
      "epoch": 1.8848931358961267,
      "grad_norm": 0.11583566665649414,
      "learning_rate": 3.1151068641038736e-05,
      "loss": 0.0038,
      "step": 25840
    },
    {
      "epoch": 1.8856225837041358,
      "grad_norm": 0.32257622480392456,
      "learning_rate": 3.114377416295864e-05,
      "loss": 0.0041,
      "step": 25850
    },
    {
      "epoch": 1.8863520315121454,
      "grad_norm": 0.34525614976882935,
      "learning_rate": 3.113647968487855e-05,
      "loss": 0.0034,
      "step": 25860
    },
    {
      "epoch": 1.8870814793201547,
      "grad_norm": 0.34494978189468384,
      "learning_rate": 3.112918520679846e-05,
      "loss": 0.0031,
      "step": 25870
    },
    {
      "epoch": 1.887810927128164,
      "grad_norm": 0.40338632464408875,
      "learning_rate": 3.112189072871836e-05,
      "loss": 0.0036,
      "step": 25880
    },
    {
      "epoch": 1.8885403749361733,
      "grad_norm": 0.2010412961244583,
      "learning_rate": 3.1114596250638266e-05,
      "loss": 0.0035,
      "step": 25890
    },
    {
      "epoch": 1.8892698227441826,
      "grad_norm": 0.2311626672744751,
      "learning_rate": 3.1107301772558174e-05,
      "loss": 0.0036,
      "step": 25900
    },
    {
      "epoch": 1.889999270552192,
      "grad_norm": 0.3456416726112366,
      "learning_rate": 3.110000729447808e-05,
      "loss": 0.0037,
      "step": 25910
    },
    {
      "epoch": 1.8907287183602013,
      "grad_norm": 0.059452738612890244,
      "learning_rate": 3.109271281639799e-05,
      "loss": 0.005,
      "step": 25920
    },
    {
      "epoch": 1.8914581661682108,
      "grad_norm": 0.23063777387142181,
      "learning_rate": 3.1085418338317897e-05,
      "loss": 0.0049,
      "step": 25930
    },
    {
      "epoch": 1.89218761397622,
      "grad_norm": 0.4048721194267273,
      "learning_rate": 3.1078123860237804e-05,
      "loss": 0.0052,
      "step": 25940
    },
    {
      "epoch": 1.8929170617842295,
      "grad_norm": 0.11552106589078903,
      "learning_rate": 3.1070829382157705e-05,
      "loss": 0.0036,
      "step": 25950
    },
    {
      "epoch": 1.8936465095922386,
      "grad_norm": 0.031044773757457733,
      "learning_rate": 3.106353490407761e-05,
      "loss": 0.0035,
      "step": 25960
    },
    {
      "epoch": 1.8943759574002481,
      "grad_norm": 0.08690350502729416,
      "learning_rate": 3.105624042599753e-05,
      "loss": 0.0036,
      "step": 25970
    },
    {
      "epoch": 1.8951054052082572,
      "grad_norm": 0.3757949471473694,
      "learning_rate": 3.104894594791743e-05,
      "loss": 0.0033,
      "step": 25980
    },
    {
      "epoch": 1.8958348530162668,
      "grad_norm": 0.2593437433242798,
      "learning_rate": 3.1041651469837335e-05,
      "loss": 0.0047,
      "step": 25990
    },
    {
      "epoch": 1.896564300824276,
      "grad_norm": 0.058671362698078156,
      "learning_rate": 3.103435699175724e-05,
      "loss": 0.0048,
      "step": 26000
    },
    {
      "epoch": 1.8972937486322854,
      "grad_norm": 0.1727008819580078,
      "learning_rate": 3.102706251367714e-05,
      "loss": 0.0028,
      "step": 26010
    },
    {
      "epoch": 1.8980231964402947,
      "grad_norm": 0.23012542724609375,
      "learning_rate": 3.101976803559705e-05,
      "loss": 0.0027,
      "step": 26020
    },
    {
      "epoch": 1.898752644248304,
      "grad_norm": 0.11651129275560379,
      "learning_rate": 3.1012473557516965e-05,
      "loss": 0.0047,
      "step": 26030
    },
    {
      "epoch": 1.8994820920563134,
      "grad_norm": 0.1841444969177246,
      "learning_rate": 3.1005179079436866e-05,
      "loss": 0.0034,
      "step": 26040
    },
    {
      "epoch": 1.9002115398643227,
      "grad_norm": 0.5763525366783142,
      "learning_rate": 3.099788460135677e-05,
      "loss": 0.003,
      "step": 26050
    },
    {
      "epoch": 1.900940987672332,
      "grad_norm": 0.12176205217838287,
      "learning_rate": 3.099059012327668e-05,
      "loss": 0.0047,
      "step": 26060
    },
    {
      "epoch": 1.9016704354803413,
      "grad_norm": 0.05844372138381004,
      "learning_rate": 3.098329564519659e-05,
      "loss": 0.0047,
      "step": 26070
    },
    {
      "epoch": 1.9023998832883509,
      "grad_norm": 0.11577324569225311,
      "learning_rate": 3.097600116711649e-05,
      "loss": 0.0036,
      "step": 26080
    },
    {
      "epoch": 1.90312933109636,
      "grad_norm": 0.34623289108276367,
      "learning_rate": 3.0968706689036403e-05,
      "loss": 0.0034,
      "step": 26090
    },
    {
      "epoch": 1.9038587789043695,
      "grad_norm": 0.6378858089447021,
      "learning_rate": 3.096141221095631e-05,
      "loss": 0.0024,
      "step": 26100
    },
    {
      "epoch": 1.9045882267123786,
      "grad_norm": 0.3295750617980957,
      "learning_rate": 3.095411773287621e-05,
      "loss": 0.0033,
      "step": 26110
    },
    {
      "epoch": 1.9053176745203881,
      "grad_norm": 0.23106242716312408,
      "learning_rate": 3.094682325479612e-05,
      "loss": 0.0044,
      "step": 26120
    },
    {
      "epoch": 1.9060471223283975,
      "grad_norm": 0.058166686445474625,
      "learning_rate": 3.093952877671603e-05,
      "loss": 0.004,
      "step": 26130
    },
    {
      "epoch": 1.9067765701364068,
      "grad_norm": 0.3745764195919037,
      "learning_rate": 3.0932234298635934e-05,
      "loss": 0.0048,
      "step": 26140
    },
    {
      "epoch": 1.907506017944416,
      "grad_norm": 0.058749258518218994,
      "learning_rate": 3.092493982055584e-05,
      "loss": 0.0034,
      "step": 26150
    },
    {
      "epoch": 1.9082354657524254,
      "grad_norm": 0.316803902387619,
      "learning_rate": 3.091764534247575e-05,
      "loss": 0.0043,
      "step": 26160
    },
    {
      "epoch": 1.9089649135604347,
      "grad_norm": 0.2593393921852112,
      "learning_rate": 3.091035086439566e-05,
      "loss": 0.005,
      "step": 26170
    },
    {
      "epoch": 1.909694361368444,
      "grad_norm": 0.031059470027685165,
      "learning_rate": 3.090305638631556e-05,
      "loss": 0.0032,
      "step": 26180
    },
    {
      "epoch": 1.9104238091764534,
      "grad_norm": 0.11577210575342178,
      "learning_rate": 3.0895761908235465e-05,
      "loss": 0.0043,
      "step": 26190
    },
    {
      "epoch": 1.9111532569844627,
      "grad_norm": 0.36831900477409363,
      "learning_rate": 3.088846743015537e-05,
      "loss": 0.003,
      "step": 26200
    },
    {
      "epoch": 1.9118827047924722,
      "grad_norm": 0.3452819287776947,
      "learning_rate": 3.088117295207528e-05,
      "loss": 0.0041,
      "step": 26210
    },
    {
      "epoch": 1.9126121526004813,
      "grad_norm": 0.31725478172302246,
      "learning_rate": 3.087387847399519e-05,
      "loss": 0.0041,
      "step": 26220
    },
    {
      "epoch": 1.9133416004084909,
      "grad_norm": 0.1434735655784607,
      "learning_rate": 3.0866583995915095e-05,
      "loss": 0.0057,
      "step": 26230
    },
    {
      "epoch": 1.9140710482165,
      "grad_norm": 0.17380397021770477,
      "learning_rate": 3.0859289517834996e-05,
      "loss": 0.004,
      "step": 26240
    },
    {
      "epoch": 1.9148004960245095,
      "grad_norm": 0.11578275263309479,
      "learning_rate": 3.0851995039754904e-05,
      "loss": 0.0048,
      "step": 26250
    },
    {
      "epoch": 1.9155299438325186,
      "grad_norm": 0.11644314229488373,
      "learning_rate": 3.084470056167482e-05,
      "loss": 0.0052,
      "step": 26260
    },
    {
      "epoch": 1.9162593916405282,
      "grad_norm": 0.01026721391826868,
      "learning_rate": 3.0837406083594725e-05,
      "loss": 0.0027,
      "step": 26270
    },
    {
      "epoch": 1.9169888394485375,
      "grad_norm": 0.34653398394584656,
      "learning_rate": 3.0830111605514626e-05,
      "loss": 0.0039,
      "step": 26280
    },
    {
      "epoch": 1.9177182872565468,
      "grad_norm": 0.1443418562412262,
      "learning_rate": 3.0822817127434534e-05,
      "loss": 0.0034,
      "step": 26290
    },
    {
      "epoch": 1.9184477350645561,
      "grad_norm": 0.032701682299375534,
      "learning_rate": 3.081552264935444e-05,
      "loss": 0.0027,
      "step": 26300
    },
    {
      "epoch": 1.9191771828725654,
      "grad_norm": 0.42289337515830994,
      "learning_rate": 3.080822817127434e-05,
      "loss": 0.0042,
      "step": 26310
    },
    {
      "epoch": 1.9199066306805748,
      "grad_norm": 0.26118946075439453,
      "learning_rate": 3.0800933693194256e-05,
      "loss": 0.0036,
      "step": 26320
    },
    {
      "epoch": 1.920636078488584,
      "grad_norm": 0.29073211550712585,
      "learning_rate": 3.0793639215114164e-05,
      "loss": 0.0038,
      "step": 26330
    },
    {
      "epoch": 1.9213655262965936,
      "grad_norm": 0.40272170305252075,
      "learning_rate": 3.0786344737034065e-05,
      "loss": 0.0035,
      "step": 26340
    },
    {
      "epoch": 1.9220949741046027,
      "grad_norm": 0.06015049293637276,
      "learning_rate": 3.077905025895397e-05,
      "loss": 0.0039,
      "step": 26350
    },
    {
      "epoch": 1.9228244219126123,
      "grad_norm": 0.05828254297375679,
      "learning_rate": 3.077175578087388e-05,
      "loss": 0.0053,
      "step": 26360
    },
    {
      "epoch": 1.9235538697206214,
      "grad_norm": 0.20101866126060486,
      "learning_rate": 3.076446130279379e-05,
      "loss": 0.0035,
      "step": 26370
    },
    {
      "epoch": 1.924283317528631,
      "grad_norm": 0.11559081077575684,
      "learning_rate": 3.0757166824713695e-05,
      "loss": 0.0042,
      "step": 26380
    },
    {
      "epoch": 1.92501276533664,
      "grad_norm": 0.35548844933509827,
      "learning_rate": 3.07498723466336e-05,
      "loss": 0.004,
      "step": 26390
    },
    {
      "epoch": 1.9257422131446496,
      "grad_norm": 0.20234514772891998,
      "learning_rate": 3.074257786855351e-05,
      "loss": 0.0029,
      "step": 26400
    },
    {
      "epoch": 1.9264716609526589,
      "grad_norm": 0.17237819731235504,
      "learning_rate": 3.073528339047341e-05,
      "loss": 0.0036,
      "step": 26410
    },
    {
      "epoch": 1.9272011087606682,
      "grad_norm": 0.0323633998632431,
      "learning_rate": 3.072798891239332e-05,
      "loss": 0.0042,
      "step": 26420
    },
    {
      "epoch": 1.9279305565686775,
      "grad_norm": 0.058756023645401,
      "learning_rate": 3.0720694434313226e-05,
      "loss": 0.0049,
      "step": 26430
    },
    {
      "epoch": 1.9286600043766868,
      "grad_norm": 0.17326891422271729,
      "learning_rate": 3.071339995623313e-05,
      "loss": 0.0044,
      "step": 26440
    },
    {
      "epoch": 1.9293894521846962,
      "grad_norm": 0.4398209750652313,
      "learning_rate": 3.070610547815304e-05,
      "loss": 0.0045,
      "step": 26450
    },
    {
      "epoch": 1.9301188999927055,
      "grad_norm": 0.3765992820262909,
      "learning_rate": 3.069881100007295e-05,
      "loss": 0.0046,
      "step": 26460
    },
    {
      "epoch": 1.930848347800715,
      "grad_norm": 0.08670274913311005,
      "learning_rate": 3.0691516521992856e-05,
      "loss": 0.0034,
      "step": 26470
    },
    {
      "epoch": 1.9315777956087241,
      "grad_norm": 0.3190384805202484,
      "learning_rate": 3.0684222043912756e-05,
      "loss": 0.0031,
      "step": 26480
    },
    {
      "epoch": 1.9323072434167337,
      "grad_norm": 0.34582239389419556,
      "learning_rate": 3.0676927565832664e-05,
      "loss": 0.005,
      "step": 26490
    },
    {
      "epoch": 1.9330366912247428,
      "grad_norm": 0.46011319756507874,
      "learning_rate": 3.066963308775258e-05,
      "loss": 0.0056,
      "step": 26500
    },
    {
      "epoch": 1.9337661390327523,
      "grad_norm": 0.013291648589074612,
      "learning_rate": 3.066233860967248e-05,
      "loss": 0.0036,
      "step": 26510
    },
    {
      "epoch": 1.9344955868407614,
      "grad_norm": 0.030550502240657806,
      "learning_rate": 3.0655044131592387e-05,
      "loss": 0.0046,
      "step": 26520
    },
    {
      "epoch": 1.935225034648771,
      "grad_norm": 0.11669217795133591,
      "learning_rate": 3.0647749653512294e-05,
      "loss": 0.0038,
      "step": 26530
    },
    {
      "epoch": 1.9359544824567803,
      "grad_norm": 0.031077289953827858,
      "learning_rate": 3.0640455175432195e-05,
      "loss": 0.0039,
      "step": 26540
    },
    {
      "epoch": 1.9366839302647896,
      "grad_norm": 0.08628898859024048,
      "learning_rate": 3.06331606973521e-05,
      "loss": 0.0028,
      "step": 26550
    },
    {
      "epoch": 1.937413378072799,
      "grad_norm": 0.4493221640586853,
      "learning_rate": 3.062586621927202e-05,
      "loss": 0.0034,
      "step": 26560
    },
    {
      "epoch": 1.9381428258808082,
      "grad_norm": 0.21124792098999023,
      "learning_rate": 3.061857174119192e-05,
      "loss": 0.004,
      "step": 26570
    },
    {
      "epoch": 1.9388722736888175,
      "grad_norm": 0.1439274549484253,
      "learning_rate": 3.0611277263111825e-05,
      "loss": 0.005,
      "step": 26580
    },
    {
      "epoch": 1.9396017214968269,
      "grad_norm": 0.08642010390758514,
      "learning_rate": 3.060398278503173e-05,
      "loss": 0.0043,
      "step": 26590
    },
    {
      "epoch": 1.9403311693048364,
      "grad_norm": 0.0869663879275322,
      "learning_rate": 3.059668830695164e-05,
      "loss": 0.0027,
      "step": 26600
    },
    {
      "epoch": 1.9410606171128455,
      "grad_norm": 0.2619720697402954,
      "learning_rate": 3.058939382887154e-05,
      "loss": 0.0035,
      "step": 26610
    },
    {
      "epoch": 1.941790064920855,
      "grad_norm": 0.402201771736145,
      "learning_rate": 3.0582099350791455e-05,
      "loss": 0.0041,
      "step": 26620
    },
    {
      "epoch": 1.9425195127288641,
      "grad_norm": 0.2741095721721649,
      "learning_rate": 3.057480487271136e-05,
      "loss": 0.0042,
      "step": 26630
    },
    {
      "epoch": 1.9432489605368737,
      "grad_norm": 0.3169669508934021,
      "learning_rate": 3.056751039463126e-05,
      "loss": 0.0035,
      "step": 26640
    },
    {
      "epoch": 1.9439784083448828,
      "grad_norm": 0.08667292445898056,
      "learning_rate": 3.056021591655117e-05,
      "loss": 0.0049,
      "step": 26650
    },
    {
      "epoch": 1.9447078561528923,
      "grad_norm": 0.3456557095050812,
      "learning_rate": 3.055292143847108e-05,
      "loss": 0.0048,
      "step": 26660
    },
    {
      "epoch": 1.9454373039609016,
      "grad_norm": 0.14351722598075867,
      "learning_rate": 3.0545626960390986e-05,
      "loss": 0.0031,
      "step": 26670
    },
    {
      "epoch": 1.946166751768911,
      "grad_norm": 0.3329404592514038,
      "learning_rate": 3.0538332482310893e-05,
      "loss": 0.0035,
      "step": 26680
    },
    {
      "epoch": 1.9468961995769203,
      "grad_norm": 0.4608694016933441,
      "learning_rate": 3.05310380042308e-05,
      "loss": 0.0046,
      "step": 26690
    },
    {
      "epoch": 1.9476256473849296,
      "grad_norm": 0.23145067691802979,
      "learning_rate": 3.052374352615071e-05,
      "loss": 0.0041,
      "step": 26700
    },
    {
      "epoch": 1.948355095192939,
      "grad_norm": 0.029565982520580292,
      "learning_rate": 3.0516449048070613e-05,
      "loss": 0.004,
      "step": 26710
    },
    {
      "epoch": 1.9490845430009482,
      "grad_norm": 0.25920093059539795,
      "learning_rate": 3.0509154569990517e-05,
      "loss": 0.0036,
      "step": 26720
    },
    {
      "epoch": 1.9498139908089576,
      "grad_norm": 0.17366693913936615,
      "learning_rate": 3.0501860091910428e-05,
      "loss": 0.0031,
      "step": 26730
    },
    {
      "epoch": 1.9505434386169669,
      "grad_norm": 0.2025197148323059,
      "learning_rate": 3.0494565613830335e-05,
      "loss": 0.0046,
      "step": 26740
    },
    {
      "epoch": 1.9512728864249764,
      "grad_norm": 0.23202918469905853,
      "learning_rate": 3.048727113575024e-05,
      "loss": 0.0058,
      "step": 26750
    },
    {
      "epoch": 1.9520023342329855,
      "grad_norm": 0.23095247149467468,
      "learning_rate": 3.0479976657670144e-05,
      "loss": 0.0029,
      "step": 26760
    },
    {
      "epoch": 1.952731782040995,
      "grad_norm": 0.03872380778193474,
      "learning_rate": 3.047268217959005e-05,
      "loss": 0.0037,
      "step": 26770
    },
    {
      "epoch": 1.9534612298490042,
      "grad_norm": 0.17654964327812195,
      "learning_rate": 3.0465387701509955e-05,
      "loss": 0.0049,
      "step": 26780
    },
    {
      "epoch": 1.9541906776570137,
      "grad_norm": 0.032343361526727676,
      "learning_rate": 3.0458093223429866e-05,
      "loss": 0.0029,
      "step": 26790
    },
    {
      "epoch": 1.954920125465023,
      "grad_norm": 0.08671791851520538,
      "learning_rate": 3.0450798745349774e-05,
      "loss": 0.0029,
      "step": 26800
    },
    {
      "epoch": 1.9556495732730323,
      "grad_norm": 0.373327374458313,
      "learning_rate": 3.0443504267269678e-05,
      "loss": 0.0038,
      "step": 26810
    },
    {
      "epoch": 1.9563790210810417,
      "grad_norm": 0.14402799308300018,
      "learning_rate": 3.0436209789189585e-05,
      "loss": 0.0031,
      "step": 26820
    },
    {
      "epoch": 1.957108468889051,
      "grad_norm": 0.13486969470977783,
      "learning_rate": 3.042891531110949e-05,
      "loss": 0.0032,
      "step": 26830
    },
    {
      "epoch": 1.9578379166970603,
      "grad_norm": 0.08646369725465775,
      "learning_rate": 3.0421620833029397e-05,
      "loss": 0.0042,
      "step": 26840
    },
    {
      "epoch": 1.9585673645050696,
      "grad_norm": 0.23126497864723206,
      "learning_rate": 3.0414326354949308e-05,
      "loss": 0.0055,
      "step": 26850
    },
    {
      "epoch": 1.959296812313079,
      "grad_norm": 0.25884532928466797,
      "learning_rate": 3.0407031876869212e-05,
      "loss": 0.0041,
      "step": 26860
    },
    {
      "epoch": 1.9600262601210883,
      "grad_norm": 0.17372706532478333,
      "learning_rate": 3.039973739878912e-05,
      "loss": 0.0045,
      "step": 26870
    },
    {
      "epoch": 1.9607557079290978,
      "grad_norm": 0.4903992712497711,
      "learning_rate": 3.0392442920709024e-05,
      "loss": 0.0034,
      "step": 26880
    },
    {
      "epoch": 1.961485155737107,
      "grad_norm": 0.14441357553005219,
      "learning_rate": 3.038514844262893e-05,
      "loss": 0.0039,
      "step": 26890
    },
    {
      "epoch": 1.9622146035451165,
      "grad_norm": 0.23087595403194427,
      "learning_rate": 3.0377853964548835e-05,
      "loss": 0.0031,
      "step": 26900
    },
    {
      "epoch": 1.9629440513531256,
      "grad_norm": 0.7487810850143433,
      "learning_rate": 3.0370559486468746e-05,
      "loss": 0.0054,
      "step": 26910
    },
    {
      "epoch": 1.963673499161135,
      "grad_norm": 0.20140591263771057,
      "learning_rate": 3.0363265008388654e-05,
      "loss": 0.0038,
      "step": 26920
    },
    {
      "epoch": 1.9644029469691442,
      "grad_norm": 0.4145011305809021,
      "learning_rate": 3.0355970530308558e-05,
      "loss": 0.0037,
      "step": 26930
    },
    {
      "epoch": 1.9651323947771537,
      "grad_norm": 0.20175108313560486,
      "learning_rate": 3.0348676052228466e-05,
      "loss": 0.0045,
      "step": 26940
    },
    {
      "epoch": 1.965861842585163,
      "grad_norm": 0.2304055094718933,
      "learning_rate": 3.034138157414837e-05,
      "loss": 0.0048,
      "step": 26950
    },
    {
      "epoch": 1.9665912903931724,
      "grad_norm": 0.21649318933486938,
      "learning_rate": 3.0334087096068274e-05,
      "loss": 0.0034,
      "step": 26960
    },
    {
      "epoch": 1.9673207382011817,
      "grad_norm": 0.23046785593032837,
      "learning_rate": 3.0326792617988188e-05,
      "loss": 0.0043,
      "step": 26970
    },
    {
      "epoch": 1.968050186009191,
      "grad_norm": 0.40243813395500183,
      "learning_rate": 3.0319498139908092e-05,
      "loss": 0.0027,
      "step": 26980
    },
    {
      "epoch": 1.9687796338172003,
      "grad_norm": 0.4911118745803833,
      "learning_rate": 3.0312203661827996e-05,
      "loss": 0.0033,
      "step": 26990
    },
    {
      "epoch": 1.9695090816252097,
      "grad_norm": 0.1730356365442276,
      "learning_rate": 3.0304909183747904e-05,
      "loss": 0.0035,
      "step": 27000
    },
    {
      "epoch": 1.9702385294332192,
      "grad_norm": 0.11583727598190308,
      "learning_rate": 3.0297614705667808e-05,
      "loss": 0.0034,
      "step": 27010
    },
    {
      "epoch": 1.9709679772412283,
      "grad_norm": 0.3453823924064636,
      "learning_rate": 3.0290320227587716e-05,
      "loss": 0.0035,
      "step": 27020
    },
    {
      "epoch": 1.9716974250492378,
      "grad_norm": 0.5536942481994629,
      "learning_rate": 3.0283025749507627e-05,
      "loss": 0.0055,
      "step": 27030
    },
    {
      "epoch": 1.972426872857247,
      "grad_norm": 0.5180497169494629,
      "learning_rate": 3.027573127142753e-05,
      "loss": 0.0046,
      "step": 27040
    },
    {
      "epoch": 1.9731563206652565,
      "grad_norm": 0.009608923457562923,
      "learning_rate": 3.0268436793347438e-05,
      "loss": 0.0053,
      "step": 27050
    },
    {
      "epoch": 1.9738857684732656,
      "grad_norm": 0.03156394511461258,
      "learning_rate": 3.0261142315267342e-05,
      "loss": 0.0044,
      "step": 27060
    },
    {
      "epoch": 1.9746152162812751,
      "grad_norm": 0.37469303607940674,
      "learning_rate": 3.025384783718725e-05,
      "loss": 0.0029,
      "step": 27070
    },
    {
      "epoch": 1.9753446640892844,
      "grad_norm": 0.49731186032295227,
      "learning_rate": 3.0246553359107154e-05,
      "loss": 0.0027,
      "step": 27080
    },
    {
      "epoch": 1.9760741118972938,
      "grad_norm": 0.030030906200408936,
      "learning_rate": 3.0239258881027065e-05,
      "loss": 0.0038,
      "step": 27090
    },
    {
      "epoch": 1.976803559705303,
      "grad_norm": 0.2883393168449402,
      "learning_rate": 3.0231964402946972e-05,
      "loss": 0.0041,
      "step": 27100
    },
    {
      "epoch": 1.9775330075133124,
      "grad_norm": 0.11585025489330292,
      "learning_rate": 3.0224669924866877e-05,
      "loss": 0.0042,
      "step": 27110
    },
    {
      "epoch": 1.9782624553213217,
      "grad_norm": 0.11538931727409363,
      "learning_rate": 3.0217375446786784e-05,
      "loss": 0.0032,
      "step": 27120
    },
    {
      "epoch": 1.978991903129331,
      "grad_norm": 0.01072651706635952,
      "learning_rate": 3.0210080968706688e-05,
      "loss": 0.0049,
      "step": 27130
    },
    {
      "epoch": 1.9797213509373406,
      "grad_norm": 0.006481070537120104,
      "learning_rate": 3.0202786490626596e-05,
      "loss": 0.0047,
      "step": 27140
    },
    {
      "epoch": 1.9804507987453497,
      "grad_norm": 0.05898584425449371,
      "learning_rate": 3.0195492012546507e-05,
      "loss": 0.0039,
      "step": 27150
    },
    {
      "epoch": 1.9811802465533592,
      "grad_norm": 0.3121582269668579,
      "learning_rate": 3.018819753446641e-05,
      "loss": 0.0042,
      "step": 27160
    },
    {
      "epoch": 1.9819096943613683,
      "grad_norm": 0.05791372060775757,
      "learning_rate": 3.018090305638632e-05,
      "loss": 0.0037,
      "step": 27170
    },
    {
      "epoch": 1.9826391421693779,
      "grad_norm": 0.31631526350975037,
      "learning_rate": 3.0173608578306223e-05,
      "loss": 0.005,
      "step": 27180
    },
    {
      "epoch": 1.983368589977387,
      "grad_norm": 0.2884359657764435,
      "learning_rate": 3.016631410022613e-05,
      "loss": 0.0034,
      "step": 27190
    },
    {
      "epoch": 1.9840980377853965,
      "grad_norm": 0.05865297093987465,
      "learning_rate": 3.0159019622146034e-05,
      "loss": 0.0035,
      "step": 27200
    },
    {
      "epoch": 1.9848274855934058,
      "grad_norm": 0.12957993149757385,
      "learning_rate": 3.0151725144065945e-05,
      "loss": 0.0036,
      "step": 27210
    },
    {
      "epoch": 1.9855569334014151,
      "grad_norm": 0.08724460750818253,
      "learning_rate": 3.0144430665985853e-05,
      "loss": 0.004,
      "step": 27220
    },
    {
      "epoch": 1.9862863812094245,
      "grad_norm": 0.39432114362716675,
      "learning_rate": 3.0137136187905757e-05,
      "loss": 0.0048,
      "step": 27230
    },
    {
      "epoch": 1.9870158290174338,
      "grad_norm": 0.030245361849665642,
      "learning_rate": 3.012984170982566e-05,
      "loss": 0.0037,
      "step": 27240
    },
    {
      "epoch": 1.987745276825443,
      "grad_norm": 0.030741464346647263,
      "learning_rate": 3.012254723174557e-05,
      "loss": 0.0046,
      "step": 27250
    },
    {
      "epoch": 1.9884747246334524,
      "grad_norm": 0.43209201097488403,
      "learning_rate": 3.011525275366548e-05,
      "loss": 0.003,
      "step": 27260
    },
    {
      "epoch": 1.989204172441462,
      "grad_norm": 0.14491583406925201,
      "learning_rate": 3.0107958275585384e-05,
      "loss": 0.0035,
      "step": 27270
    },
    {
      "epoch": 1.989933620249471,
      "grad_norm": 0.5419437885284424,
      "learning_rate": 3.010066379750529e-05,
      "loss": 0.0038,
      "step": 27280
    },
    {
      "epoch": 1.9906630680574806,
      "grad_norm": 0.28770914673805237,
      "learning_rate": 3.0093369319425195e-05,
      "loss": 0.0032,
      "step": 27290
    },
    {
      "epoch": 1.9913925158654897,
      "grad_norm": 0.14538702368736267,
      "learning_rate": 3.0086074841345103e-05,
      "loss": 0.0034,
      "step": 27300
    },
    {
      "epoch": 1.9921219636734993,
      "grad_norm": 0.2872494161128998,
      "learning_rate": 3.0078780363265007e-05,
      "loss": 0.0048,
      "step": 27310
    },
    {
      "epoch": 1.9928514114815084,
      "grad_norm": 0.7785635590553284,
      "learning_rate": 3.0071485885184918e-05,
      "loss": 0.0032,
      "step": 27320
    },
    {
      "epoch": 1.993580859289518,
      "grad_norm": 0.0660996288061142,
      "learning_rate": 3.0064191407104825e-05,
      "loss": 0.0039,
      "step": 27330
    },
    {
      "epoch": 1.9943103070975272,
      "grad_norm": 0.08850251883268356,
      "learning_rate": 3.005689692902473e-05,
      "loss": 0.0043,
      "step": 27340
    },
    {
      "epoch": 1.9950397549055365,
      "grad_norm": 0.05834954231977463,
      "learning_rate": 3.0049602450944637e-05,
      "loss": 0.005,
      "step": 27350
    },
    {
      "epoch": 1.9957692027135459,
      "grad_norm": 0.17317520081996918,
      "learning_rate": 3.004230797286454e-05,
      "loss": 0.005,
      "step": 27360
    },
    {
      "epoch": 1.9964986505215552,
      "grad_norm": 0.17281970381736755,
      "learning_rate": 3.003501349478445e-05,
      "loss": 0.0031,
      "step": 27370
    },
    {
      "epoch": 1.9972280983295645,
      "grad_norm": 0.25997158885002136,
      "learning_rate": 3.002771901670436e-05,
      "loss": 0.005,
      "step": 27380
    },
    {
      "epoch": 1.9979575461375738,
      "grad_norm": 0.34570860862731934,
      "learning_rate": 3.0020424538624264e-05,
      "loss": 0.0025,
      "step": 27390
    },
    {
      "epoch": 1.9986869939455834,
      "grad_norm": 0.17315392196178436,
      "learning_rate": 3.001313006054417e-05,
      "loss": 0.0057,
      "step": 27400
    },
    {
      "epoch": 1.9994164417535925,
      "grad_norm": 0.42088204622268677,
      "learning_rate": 3.0005835582464075e-05,
      "loss": 0.0042,
      "step": 27410
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.004431820008903742,
      "eval_runtime": 113.7745,
      "eval_samples_per_second": 1228.536,
      "eval_steps_per_second": 30.719,
      "step": 27418
    },
    {
      "epoch": 2.000145889561602,
      "grad_norm": 0.05793626606464386,
      "learning_rate": 2.9998541104383983e-05,
      "loss": 0.0037,
      "step": 27420
    },
    {
      "epoch": 2.000875337369611,
      "grad_norm": 0.4118248522281647,
      "learning_rate": 2.9991246626303887e-05,
      "loss": 0.0042,
      "step": 27430
    },
    {
      "epoch": 2.0016047851776206,
      "grad_norm": 0.3749372959136963,
      "learning_rate": 2.9983952148223798e-05,
      "loss": 0.0044,
      "step": 27440
    },
    {
      "epoch": 2.0023342329856297,
      "grad_norm": 0.08614091575145721,
      "learning_rate": 2.9976657670143706e-05,
      "loss": 0.0035,
      "step": 27450
    },
    {
      "epoch": 2.0030636807936393,
      "grad_norm": 0.192571759223938,
      "learning_rate": 2.996936319206361e-05,
      "loss": 0.0044,
      "step": 27460
    },
    {
      "epoch": 2.0037931286016484,
      "grad_norm": 0.23121118545532227,
      "learning_rate": 2.9962068713983514e-05,
      "loss": 0.004,
      "step": 27470
    },
    {
      "epoch": 2.004522576409658,
      "grad_norm": 0.08718898892402649,
      "learning_rate": 2.995477423590342e-05,
      "loss": 0.0062,
      "step": 27480
    },
    {
      "epoch": 2.005252024217667,
      "grad_norm": 0.37485066056251526,
      "learning_rate": 2.9947479757823325e-05,
      "loss": 0.0045,
      "step": 27490
    },
    {
      "epoch": 2.0059814720256766,
      "grad_norm": 0.08532284945249557,
      "learning_rate": 2.9940185279743236e-05,
      "loss": 0.0038,
      "step": 27500
    },
    {
      "epoch": 2.006710919833686,
      "grad_norm": 0.11581733822822571,
      "learning_rate": 2.9932890801663144e-05,
      "loss": 0.004,
      "step": 27510
    },
    {
      "epoch": 2.007440367641695,
      "grad_norm": 0.019640401005744934,
      "learning_rate": 2.9925596323583048e-05,
      "loss": 0.0035,
      "step": 27520
    },
    {
      "epoch": 2.0081698154497047,
      "grad_norm": 0.04777095466852188,
      "learning_rate": 2.9918301845502956e-05,
      "loss": 0.0042,
      "step": 27530
    },
    {
      "epoch": 2.008899263257714,
      "grad_norm": 0.1453104317188263,
      "learning_rate": 2.991100736742286e-05,
      "loss": 0.0033,
      "step": 27540
    },
    {
      "epoch": 2.0096287110657234,
      "grad_norm": 0.08780451864004135,
      "learning_rate": 2.9903712889342767e-05,
      "loss": 0.0038,
      "step": 27550
    },
    {
      "epoch": 2.0103581588737325,
      "grad_norm": 0.40396279096603394,
      "learning_rate": 2.9896418411262678e-05,
      "loss": 0.0036,
      "step": 27560
    },
    {
      "epoch": 2.011087606681742,
      "grad_norm": 0.17272721230983734,
      "learning_rate": 2.9889123933182582e-05,
      "loss": 0.0033,
      "step": 27570
    },
    {
      "epoch": 2.011817054489751,
      "grad_norm": 0.5108925104141235,
      "learning_rate": 2.988182945510249e-05,
      "loss": 0.0032,
      "step": 27580
    },
    {
      "epoch": 2.0125465022977607,
      "grad_norm": 0.08744939416646957,
      "learning_rate": 2.9874534977022394e-05,
      "loss": 0.0047,
      "step": 27590
    },
    {
      "epoch": 2.0132759501057698,
      "grad_norm": 0.09548128396272659,
      "learning_rate": 2.98672404989423e-05,
      "loss": 0.0047,
      "step": 27600
    },
    {
      "epoch": 2.0140053979137793,
      "grad_norm": 0.4885544776916504,
      "learning_rate": 2.9859946020862206e-05,
      "loss": 0.0034,
      "step": 27610
    },
    {
      "epoch": 2.0147348457217884,
      "grad_norm": 0.6609761118888855,
      "learning_rate": 2.9852651542782117e-05,
      "loss": 0.0039,
      "step": 27620
    },
    {
      "epoch": 2.015464293529798,
      "grad_norm": 0.17209836840629578,
      "learning_rate": 2.9845357064702024e-05,
      "loss": 0.0028,
      "step": 27630
    },
    {
      "epoch": 2.0161937413378075,
      "grad_norm": 0.19969023764133453,
      "learning_rate": 2.9838062586621928e-05,
      "loss": 0.004,
      "step": 27640
    },
    {
      "epoch": 2.0169231891458166,
      "grad_norm": 0.34574273228645325,
      "learning_rate": 2.9830768108541836e-05,
      "loss": 0.0024,
      "step": 27650
    },
    {
      "epoch": 2.017652636953826,
      "grad_norm": 0.41843608021736145,
      "learning_rate": 2.982347363046174e-05,
      "loss": 0.004,
      "step": 27660
    },
    {
      "epoch": 2.0183820847618352,
      "grad_norm": 0.029382819309830666,
      "learning_rate": 2.9816179152381647e-05,
      "loss": 0.0035,
      "step": 27670
    },
    {
      "epoch": 2.0191115325698448,
      "grad_norm": 0.38387933373451233,
      "learning_rate": 2.980888467430156e-05,
      "loss": 0.0036,
      "step": 27680
    },
    {
      "epoch": 2.019840980377854,
      "grad_norm": 0.2873302102088928,
      "learning_rate": 2.9801590196221463e-05,
      "loss": 0.005,
      "step": 27690
    },
    {
      "epoch": 2.0205704281858634,
      "grad_norm": 0.14728707075119019,
      "learning_rate": 2.979429571814137e-05,
      "loss": 0.0049,
      "step": 27700
    },
    {
      "epoch": 2.0212998759938725,
      "grad_norm": 0.22717060148715973,
      "learning_rate": 2.9787001240061274e-05,
      "loss": 0.0038,
      "step": 27710
    },
    {
      "epoch": 2.022029323801882,
      "grad_norm": 0.20545655488967896,
      "learning_rate": 2.977970676198118e-05,
      "loss": 0.0048,
      "step": 27720
    },
    {
      "epoch": 2.022758771609891,
      "grad_norm": 0.1441754549741745,
      "learning_rate": 2.9772412283901093e-05,
      "loss": 0.003,
      "step": 27730
    },
    {
      "epoch": 2.0234882194179007,
      "grad_norm": 0.43596699833869934,
      "learning_rate": 2.9765117805820997e-05,
      "loss": 0.0036,
      "step": 27740
    },
    {
      "epoch": 2.02421766722591,
      "grad_norm": 0.029488619416952133,
      "learning_rate": 2.97578233277409e-05,
      "loss": 0.0038,
      "step": 27750
    },
    {
      "epoch": 2.0249471150339193,
      "grad_norm": 0.04971620813012123,
      "learning_rate": 2.975052884966081e-05,
      "loss": 0.0035,
      "step": 27760
    },
    {
      "epoch": 2.025676562841929,
      "grad_norm": 0.34632182121276855,
      "learning_rate": 2.9743234371580713e-05,
      "loss": 0.0041,
      "step": 27770
    },
    {
      "epoch": 2.026406010649938,
      "grad_norm": 0.5194981098175049,
      "learning_rate": 2.973593989350062e-05,
      "loss": 0.002,
      "step": 27780
    },
    {
      "epoch": 2.0271354584579475,
      "grad_norm": 0.3740497827529907,
      "learning_rate": 2.972864541542053e-05,
      "loss": 0.0035,
      "step": 27790
    },
    {
      "epoch": 2.0278649062659566,
      "grad_norm": 0.7858017683029175,
      "learning_rate": 2.9721350937340435e-05,
      "loss": 0.0039,
      "step": 27800
    },
    {
      "epoch": 2.028594354073966,
      "grad_norm": 0.2307216078042984,
      "learning_rate": 2.9714056459260343e-05,
      "loss": 0.0046,
      "step": 27810
    },
    {
      "epoch": 2.0293238018819753,
      "grad_norm": 0.17315678298473358,
      "learning_rate": 2.9706761981180247e-05,
      "loss": 0.003,
      "step": 27820
    },
    {
      "epoch": 2.030053249689985,
      "grad_norm": 0.05848461389541626,
      "learning_rate": 2.9699467503100154e-05,
      "loss": 0.0036,
      "step": 27830
    },
    {
      "epoch": 2.030782697497994,
      "grad_norm": 0.2882062494754791,
      "learning_rate": 2.969217302502006e-05,
      "loss": 0.0045,
      "step": 27840
    },
    {
      "epoch": 2.0315121453060034,
      "grad_norm": 0.25992637872695923,
      "learning_rate": 2.968487854693997e-05,
      "loss": 0.0039,
      "step": 27850
    },
    {
      "epoch": 2.0322415931140125,
      "grad_norm": 0.030161244794726372,
      "learning_rate": 2.9677584068859877e-05,
      "loss": 0.0031,
      "step": 27860
    },
    {
      "epoch": 2.032971040922022,
      "grad_norm": 0.08679885417222977,
      "learning_rate": 2.967028959077978e-05,
      "loss": 0.0034,
      "step": 27870
    },
    {
      "epoch": 2.033700488730031,
      "grad_norm": 0.2879813313484192,
      "learning_rate": 2.966299511269969e-05,
      "loss": 0.0032,
      "step": 27880
    },
    {
      "epoch": 2.0344299365380407,
      "grad_norm": 0.2591875195503235,
      "learning_rate": 2.9655700634619593e-05,
      "loss": 0.0044,
      "step": 27890
    },
    {
      "epoch": 2.0351593843460503,
      "grad_norm": 0.20739898085594177,
      "learning_rate": 2.96484061565395e-05,
      "loss": 0.0046,
      "step": 27900
    },
    {
      "epoch": 2.0358888321540594,
      "grad_norm": 0.11612509936094284,
      "learning_rate": 2.964111167845941e-05,
      "loss": 0.0036,
      "step": 27910
    },
    {
      "epoch": 2.036618279962069,
      "grad_norm": 0.032576173543930054,
      "learning_rate": 2.9633817200379315e-05,
      "loss": 0.0043,
      "step": 27920
    },
    {
      "epoch": 2.037347727770078,
      "grad_norm": 0.2021891474723816,
      "learning_rate": 2.9626522722299223e-05,
      "loss": 0.0035,
      "step": 27930
    },
    {
      "epoch": 2.0380771755780875,
      "grad_norm": 0.576312780380249,
      "learning_rate": 2.9619228244219127e-05,
      "loss": 0.0049,
      "step": 27940
    },
    {
      "epoch": 2.0388066233860966,
      "grad_norm": 0.11827081441879272,
      "learning_rate": 2.961193376613903e-05,
      "loss": 0.0047,
      "step": 27950
    },
    {
      "epoch": 2.039536071194106,
      "grad_norm": 0.34640878438949585,
      "learning_rate": 2.960463928805894e-05,
      "loss": 0.0056,
      "step": 27960
    },
    {
      "epoch": 2.0402655190021153,
      "grad_norm": 0.14406751096248627,
      "learning_rate": 2.959734480997885e-05,
      "loss": 0.0034,
      "step": 27970
    },
    {
      "epoch": 2.040994966810125,
      "grad_norm": 0.09764759987592697,
      "learning_rate": 2.9590050331898754e-05,
      "loss": 0.0041,
      "step": 27980
    },
    {
      "epoch": 2.041724414618134,
      "grad_norm": 0.23113907873630524,
      "learning_rate": 2.958275585381866e-05,
      "loss": 0.0045,
      "step": 27990
    },
    {
      "epoch": 2.0424538624261435,
      "grad_norm": 0.024286789819598198,
      "learning_rate": 2.9575461375738565e-05,
      "loss": 0.0039,
      "step": 28000
    },
    {
      "epoch": 2.0431833102341526,
      "grad_norm": 0.10958443582057953,
      "learning_rate": 2.9568166897658473e-05,
      "loss": 0.0041,
      "step": 28010
    },
    {
      "epoch": 2.043912758042162,
      "grad_norm": 0.1565302312374115,
      "learning_rate": 2.9560872419578377e-05,
      "loss": 0.0039,
      "step": 28020
    },
    {
      "epoch": 2.044642205850171,
      "grad_norm": 0.4436435103416443,
      "learning_rate": 2.9553577941498288e-05,
      "loss": 0.0039,
      "step": 28030
    },
    {
      "epoch": 2.0453716536581807,
      "grad_norm": 0.1065121740102768,
      "learning_rate": 2.9546283463418196e-05,
      "loss": 0.0039,
      "step": 28040
    },
    {
      "epoch": 2.0461011014661903,
      "grad_norm": 0.6563064455986023,
      "learning_rate": 2.95389889853381e-05,
      "loss": 0.0036,
      "step": 28050
    },
    {
      "epoch": 2.0468305492741994,
      "grad_norm": 0.346464067697525,
      "learning_rate": 2.9531694507258007e-05,
      "loss": 0.0033,
      "step": 28060
    },
    {
      "epoch": 2.047559997082209,
      "grad_norm": 0.029639873653650284,
      "learning_rate": 2.952440002917791e-05,
      "loss": 0.0046,
      "step": 28070
    },
    {
      "epoch": 2.048289444890218,
      "grad_norm": 0.12191402167081833,
      "learning_rate": 2.951710555109782e-05,
      "loss": 0.0049,
      "step": 28080
    },
    {
      "epoch": 2.0490188926982276,
      "grad_norm": 0.17287637293338776,
      "learning_rate": 2.950981107301773e-05,
      "loss": 0.0045,
      "step": 28090
    },
    {
      "epoch": 2.0497483405062367,
      "grad_norm": 0.2047497034072876,
      "learning_rate": 2.9502516594937634e-05,
      "loss": 0.0064,
      "step": 28100
    },
    {
      "epoch": 2.050477788314246,
      "grad_norm": 0.3456650674343109,
      "learning_rate": 2.949522211685754e-05,
      "loss": 0.003,
      "step": 28110
    },
    {
      "epoch": 2.0512072361222553,
      "grad_norm": 0.11632567644119263,
      "learning_rate": 2.9487927638777446e-05,
      "loss": 0.0041,
      "step": 28120
    },
    {
      "epoch": 2.051936683930265,
      "grad_norm": 0.11623147130012512,
      "learning_rate": 2.9480633160697353e-05,
      "loss": 0.0041,
      "step": 28130
    },
    {
      "epoch": 2.052666131738274,
      "grad_norm": 0.029847873374819756,
      "learning_rate": 2.9473338682617257e-05,
      "loss": 0.0033,
      "step": 28140
    },
    {
      "epoch": 2.0533955795462835,
      "grad_norm": 0.1486358791589737,
      "learning_rate": 2.9466044204537168e-05,
      "loss": 0.0056,
      "step": 28150
    },
    {
      "epoch": 2.0541250273542926,
      "grad_norm": 0.06973957270383835,
      "learning_rate": 2.9458749726457076e-05,
      "loss": 0.0042,
      "step": 28160
    },
    {
      "epoch": 2.054854475162302,
      "grad_norm": 0.06740383803844452,
      "learning_rate": 2.945145524837698e-05,
      "loss": 0.0044,
      "step": 28170
    },
    {
      "epoch": 2.0555839229703117,
      "grad_norm": 0.27402517199516296,
      "learning_rate": 2.9444160770296887e-05,
      "loss": 0.0046,
      "step": 28180
    },
    {
      "epoch": 2.0563133707783208,
      "grad_norm": 0.1731262058019638,
      "learning_rate": 2.943686629221679e-05,
      "loss": 0.0047,
      "step": 28190
    },
    {
      "epoch": 2.0570428185863303,
      "grad_norm": 0.34655511379241943,
      "learning_rate": 2.9429571814136696e-05,
      "loss": 0.0032,
      "step": 28200
    },
    {
      "epoch": 2.0577722663943394,
      "grad_norm": 0.27338674664497375,
      "learning_rate": 2.942227733605661e-05,
      "loss": 0.0043,
      "step": 28210
    },
    {
      "epoch": 2.058501714202349,
      "grad_norm": 0.14379695057868958,
      "learning_rate": 2.9414982857976514e-05,
      "loss": 0.0054,
      "step": 28220
    },
    {
      "epoch": 2.059231162010358,
      "grad_norm": 0.030507098883390427,
      "learning_rate": 2.940768837989642e-05,
      "loss": 0.0052,
      "step": 28230
    },
    {
      "epoch": 2.0599606098183676,
      "grad_norm": 0.202015221118927,
      "learning_rate": 2.9400393901816326e-05,
      "loss": 0.0046,
      "step": 28240
    },
    {
      "epoch": 2.0606900576263767,
      "grad_norm": 0.35327956080436707,
      "learning_rate": 2.939309942373623e-05,
      "loss": 0.0028,
      "step": 28250
    },
    {
      "epoch": 2.0614195054343862,
      "grad_norm": 0.46131864190101624,
      "learning_rate": 2.938580494565614e-05,
      "loss": 0.0043,
      "step": 28260
    },
    {
      "epoch": 2.0621489532423953,
      "grad_norm": 0.23048320412635803,
      "learning_rate": 2.937851046757605e-05,
      "loss": 0.0046,
      "step": 28270
    },
    {
      "epoch": 2.062878401050405,
      "grad_norm": 0.088935986161232,
      "learning_rate": 2.9371215989495953e-05,
      "loss": 0.0039,
      "step": 28280
    },
    {
      "epoch": 2.063607848858414,
      "grad_norm": 0.47752144932746887,
      "learning_rate": 2.936392151141586e-05,
      "loss": 0.0029,
      "step": 28290
    },
    {
      "epoch": 2.0643372966664235,
      "grad_norm": 0.6337229013442993,
      "learning_rate": 2.9356627033335764e-05,
      "loss": 0.0055,
      "step": 28300
    },
    {
      "epoch": 2.065066744474433,
      "grad_norm": 0.455150306224823,
      "learning_rate": 2.9349332555255672e-05,
      "loss": 0.0041,
      "step": 28310
    },
    {
      "epoch": 2.065796192282442,
      "grad_norm": 0.19348526000976562,
      "learning_rate": 2.9342038077175583e-05,
      "loss": 0.0061,
      "step": 28320
    },
    {
      "epoch": 2.0665256400904517,
      "grad_norm": 0.02982376329600811,
      "learning_rate": 2.9334743599095487e-05,
      "loss": 0.0034,
      "step": 28330
    },
    {
      "epoch": 2.067255087898461,
      "grad_norm": 0.14544987678527832,
      "learning_rate": 2.9327449121015394e-05,
      "loss": 0.0038,
      "step": 28340
    },
    {
      "epoch": 2.0679845357064703,
      "grad_norm": 0.08780447393655777,
      "learning_rate": 2.93201546429353e-05,
      "loss": 0.0026,
      "step": 28350
    },
    {
      "epoch": 2.0687139835144794,
      "grad_norm": 0.17284248769283295,
      "learning_rate": 2.9312860164855206e-05,
      "loss": 0.0038,
      "step": 28360
    },
    {
      "epoch": 2.069443431322489,
      "grad_norm": 0.28803908824920654,
      "learning_rate": 2.930556568677511e-05,
      "loss": 0.0054,
      "step": 28370
    },
    {
      "epoch": 2.070172879130498,
      "grad_norm": 0.2032368779182434,
      "learning_rate": 2.929827120869502e-05,
      "loss": 0.0046,
      "step": 28380
    },
    {
      "epoch": 2.0709023269385076,
      "grad_norm": 0.346348375082016,
      "learning_rate": 2.929097673061493e-05,
      "loss": 0.0035,
      "step": 28390
    },
    {
      "epoch": 2.0716317747465167,
      "grad_norm": 0.13345111906528473,
      "learning_rate": 2.9283682252534833e-05,
      "loss": 0.0039,
      "step": 28400
    },
    {
      "epoch": 2.0723612225545263,
      "grad_norm": 0.12035389244556427,
      "learning_rate": 2.927638777445474e-05,
      "loss": 0.0029,
      "step": 28410
    },
    {
      "epoch": 2.0730906703625354,
      "grad_norm": 0.11565842479467392,
      "learning_rate": 2.9269093296374644e-05,
      "loss": 0.0055,
      "step": 28420
    },
    {
      "epoch": 2.073820118170545,
      "grad_norm": 0.2302960604429245,
      "learning_rate": 2.926179881829455e-05,
      "loss": 0.0044,
      "step": 28430
    },
    {
      "epoch": 2.0745495659785544,
      "grad_norm": 0.26146674156188965,
      "learning_rate": 2.9254504340214463e-05,
      "loss": 0.0046,
      "step": 28440
    },
    {
      "epoch": 2.0752790137865635,
      "grad_norm": 0.2877991497516632,
      "learning_rate": 2.9247209862134367e-05,
      "loss": 0.0038,
      "step": 28450
    },
    {
      "epoch": 2.076008461594573,
      "grad_norm": 0.057714711874723434,
      "learning_rate": 2.923991538405427e-05,
      "loss": 0.0032,
      "step": 28460
    },
    {
      "epoch": 2.076737909402582,
      "grad_norm": 0.38670605421066284,
      "learning_rate": 2.923262090597418e-05,
      "loss": 0.005,
      "step": 28470
    },
    {
      "epoch": 2.0774673572105917,
      "grad_norm": 0.0869104266166687,
      "learning_rate": 2.9225326427894083e-05,
      "loss": 0.005,
      "step": 28480
    },
    {
      "epoch": 2.078196805018601,
      "grad_norm": 0.6039042472839355,
      "learning_rate": 2.921803194981399e-05,
      "loss": 0.0044,
      "step": 28490
    },
    {
      "epoch": 2.0789262528266104,
      "grad_norm": 0.05781722441315651,
      "learning_rate": 2.92107374717339e-05,
      "loss": 0.0031,
      "step": 28500
    },
    {
      "epoch": 2.0796557006346195,
      "grad_norm": 0.057693000882864,
      "learning_rate": 2.9203442993653805e-05,
      "loss": 0.0043,
      "step": 28510
    },
    {
      "epoch": 2.080385148442629,
      "grad_norm": 0.23038171231746674,
      "learning_rate": 2.9196148515573713e-05,
      "loss": 0.0043,
      "step": 28520
    },
    {
      "epoch": 2.081114596250638,
      "grad_norm": 0.14423169195652008,
      "learning_rate": 2.9188854037493617e-05,
      "loss": 0.0039,
      "step": 28530
    },
    {
      "epoch": 2.0818440440586476,
      "grad_norm": 0.05887762829661369,
      "learning_rate": 2.9181559559413525e-05,
      "loss": 0.0036,
      "step": 28540
    },
    {
      "epoch": 2.0825734918666567,
      "grad_norm": 0.0894433930516243,
      "learning_rate": 2.917426508133343e-05,
      "loss": 0.0036,
      "step": 28550
    },
    {
      "epoch": 2.0833029396746663,
      "grad_norm": 0.1230635941028595,
      "learning_rate": 2.916697060325334e-05,
      "loss": 0.0039,
      "step": 28560
    },
    {
      "epoch": 2.084032387482676,
      "grad_norm": 0.288394957780838,
      "learning_rate": 2.9159676125173247e-05,
      "loss": 0.0038,
      "step": 28570
    },
    {
      "epoch": 2.084761835290685,
      "grad_norm": 0.2909059524536133,
      "learning_rate": 2.915238164709315e-05,
      "loss": 0.0048,
      "step": 28580
    },
    {
      "epoch": 2.0854912830986945,
      "grad_norm": 0.10605504363775253,
      "learning_rate": 2.914508716901306e-05,
      "loss": 0.0043,
      "step": 28590
    },
    {
      "epoch": 2.0862207309067036,
      "grad_norm": 0.2301027923822403,
      "learning_rate": 2.9137792690932963e-05,
      "loss": 0.0033,
      "step": 28600
    },
    {
      "epoch": 2.086950178714713,
      "grad_norm": 0.11577671766281128,
      "learning_rate": 2.913049821285287e-05,
      "loss": 0.0033,
      "step": 28610
    },
    {
      "epoch": 2.087679626522722,
      "grad_norm": 0.34909939765930176,
      "learning_rate": 2.912320373477278e-05,
      "loss": 0.0052,
      "step": 28620
    },
    {
      "epoch": 2.0884090743307318,
      "grad_norm": 0.14444176852703094,
      "learning_rate": 2.9115909256692686e-05,
      "loss": 0.003,
      "step": 28630
    },
    {
      "epoch": 2.089138522138741,
      "grad_norm": 0.2604053020477295,
      "learning_rate": 2.9108614778612593e-05,
      "loss": 0.0049,
      "step": 28640
    },
    {
      "epoch": 2.0898679699467504,
      "grad_norm": 0.11508623510599136,
      "learning_rate": 2.9101320300532497e-05,
      "loss": 0.0044,
      "step": 28650
    },
    {
      "epoch": 2.0905974177547595,
      "grad_norm": 0.05820272117853165,
      "learning_rate": 2.9094025822452405e-05,
      "loss": 0.0043,
      "step": 28660
    },
    {
      "epoch": 2.091326865562769,
      "grad_norm": 0.1024436429142952,
      "learning_rate": 2.908673134437231e-05,
      "loss": 0.005,
      "step": 28670
    },
    {
      "epoch": 2.092056313370778,
      "grad_norm": 0.040014851838350296,
      "learning_rate": 2.907943686629222e-05,
      "loss": 0.0047,
      "step": 28680
    },
    {
      "epoch": 2.0927857611787877,
      "grad_norm": 0.28795182704925537,
      "learning_rate": 2.9072142388212127e-05,
      "loss": 0.0031,
      "step": 28690
    },
    {
      "epoch": 2.0935152089867968,
      "grad_norm": 0.11277953535318375,
      "learning_rate": 2.906484791013203e-05,
      "loss": 0.0036,
      "step": 28700
    },
    {
      "epoch": 2.0942446567948063,
      "grad_norm": 0.4393148720264435,
      "learning_rate": 2.9057553432051936e-05,
      "loss": 0.0038,
      "step": 28710
    },
    {
      "epoch": 2.094974104602816,
      "grad_norm": 0.08659835159778595,
      "learning_rate": 2.9050258953971843e-05,
      "loss": 0.0051,
      "step": 28720
    },
    {
      "epoch": 2.095703552410825,
      "grad_norm": 0.006564442999660969,
      "learning_rate": 2.9042964475891754e-05,
      "loss": 0.0031,
      "step": 28730
    },
    {
      "epoch": 2.0964330002188345,
      "grad_norm": 0.3186986744403839,
      "learning_rate": 2.903566999781166e-05,
      "loss": 0.0048,
      "step": 28740
    },
    {
      "epoch": 2.0971624480268436,
      "grad_norm": 0.489154577255249,
      "learning_rate": 2.9028375519731566e-05,
      "loss": 0.003,
      "step": 28750
    },
    {
      "epoch": 2.097891895834853,
      "grad_norm": 0.2303365021944046,
      "learning_rate": 2.902108104165147e-05,
      "loss": 0.0046,
      "step": 28760
    },
    {
      "epoch": 2.0986213436428622,
      "grad_norm": 0.17324717342853546,
      "learning_rate": 2.9013786563571378e-05,
      "loss": 0.0035,
      "step": 28770
    },
    {
      "epoch": 2.099350791450872,
      "grad_norm": 0.11900544166564941,
      "learning_rate": 2.900649208549128e-05,
      "loss": 0.0033,
      "step": 28780
    },
    {
      "epoch": 2.100080239258881,
      "grad_norm": 0.46816307306289673,
      "learning_rate": 2.8999197607411193e-05,
      "loss": 0.0028,
      "step": 28790
    },
    {
      "epoch": 2.1008096870668904,
      "grad_norm": 0.2302556335926056,
      "learning_rate": 2.89919031293311e-05,
      "loss": 0.0035,
      "step": 28800
    },
    {
      "epoch": 2.1015391348748995,
      "grad_norm": 0.17303821444511414,
      "learning_rate": 2.8984608651251004e-05,
      "loss": 0.0044,
      "step": 28810
    },
    {
      "epoch": 2.102268582682909,
      "grad_norm": 0.05924031138420105,
      "learning_rate": 2.8977314173170912e-05,
      "loss": 0.0045,
      "step": 28820
    },
    {
      "epoch": 2.1029980304909186,
      "grad_norm": 0.1911303550004959,
      "learning_rate": 2.8970019695090816e-05,
      "loss": 0.0051,
      "step": 28830
    },
    {
      "epoch": 2.1037274782989277,
      "grad_norm": 0.29281991720199585,
      "learning_rate": 2.8962725217010723e-05,
      "loss": 0.0041,
      "step": 28840
    },
    {
      "epoch": 2.1044569261069372,
      "grad_norm": 0.09647078812122345,
      "learning_rate": 2.8955430738930634e-05,
      "loss": 0.0038,
      "step": 28850
    },
    {
      "epoch": 2.1051863739149463,
      "grad_norm": 0.08757256716489792,
      "learning_rate": 2.894813626085054e-05,
      "loss": 0.0026,
      "step": 28860
    },
    {
      "epoch": 2.105915821722956,
      "grad_norm": 0.22988127171993256,
      "learning_rate": 2.8940841782770446e-05,
      "loss": 0.0038,
      "step": 28870
    },
    {
      "epoch": 2.106645269530965,
      "grad_norm": 0.01498937327414751,
      "learning_rate": 2.893354730469035e-05,
      "loss": 0.0022,
      "step": 28880
    },
    {
      "epoch": 2.1073747173389745,
      "grad_norm": 0.03041236661374569,
      "learning_rate": 2.8926252826610258e-05,
      "loss": 0.0023,
      "step": 28890
    },
    {
      "epoch": 2.1081041651469836,
      "grad_norm": 0.17253679037094116,
      "learning_rate": 2.8918958348530162e-05,
      "loss": 0.004,
      "step": 28900
    },
    {
      "epoch": 2.108833612954993,
      "grad_norm": 0.11633652448654175,
      "learning_rate": 2.8911663870450073e-05,
      "loss": 0.0027,
      "step": 28910
    },
    {
      "epoch": 2.1095630607630023,
      "grad_norm": 0.2113385945558548,
      "learning_rate": 2.890436939236998e-05,
      "loss": 0.0058,
      "step": 28920
    },
    {
      "epoch": 2.110292508571012,
      "grad_norm": 0.15197810530662537,
      "learning_rate": 2.8897074914289884e-05,
      "loss": 0.005,
      "step": 28930
    },
    {
      "epoch": 2.111021956379021,
      "grad_norm": 0.23062889277935028,
      "learning_rate": 2.888978043620979e-05,
      "loss": 0.004,
      "step": 28940
    },
    {
      "epoch": 2.1117514041870304,
      "grad_norm": 0.05770313739776611,
      "learning_rate": 2.8882485958129696e-05,
      "loss": 0.0043,
      "step": 28950
    },
    {
      "epoch": 2.1124808519950395,
      "grad_norm": 0.1437874138355255,
      "learning_rate": 2.88751914800496e-05,
      "loss": 0.0037,
      "step": 28960
    },
    {
      "epoch": 2.113210299803049,
      "grad_norm": 0.11510714143514633,
      "learning_rate": 2.886789700196951e-05,
      "loss": 0.0033,
      "step": 28970
    },
    {
      "epoch": 2.1139397476110586,
      "grad_norm": 0.34501200914382935,
      "learning_rate": 2.886060252388942e-05,
      "loss": 0.0055,
      "step": 28980
    },
    {
      "epoch": 2.1146691954190677,
      "grad_norm": 0.25858747959136963,
      "learning_rate": 2.8853308045809323e-05,
      "loss": 0.004,
      "step": 28990
    },
    {
      "epoch": 2.1153986432270773,
      "grad_norm": 0.08682207763195038,
      "learning_rate": 2.884601356772923e-05,
      "loss": 0.0041,
      "step": 29000
    },
    {
      "epoch": 2.1161280910350864,
      "grad_norm": 0.10038736462593079,
      "learning_rate": 2.8838719089649135e-05,
      "loss": 0.004,
      "step": 29010
    },
    {
      "epoch": 2.116857538843096,
      "grad_norm": 0.17271506786346436,
      "learning_rate": 2.8831424611569042e-05,
      "loss": 0.0048,
      "step": 29020
    },
    {
      "epoch": 2.117586986651105,
      "grad_norm": 0.28829479217529297,
      "learning_rate": 2.8824130133488953e-05,
      "loss": 0.0031,
      "step": 29030
    },
    {
      "epoch": 2.1183164344591146,
      "grad_norm": 0.02915133535861969,
      "learning_rate": 2.8816835655408857e-05,
      "loss": 0.0031,
      "step": 29040
    },
    {
      "epoch": 2.1190458822671236,
      "grad_norm": 0.11612482368946075,
      "learning_rate": 2.8809541177328765e-05,
      "loss": 0.0042,
      "step": 29050
    },
    {
      "epoch": 2.119775330075133,
      "grad_norm": 0.298918217420578,
      "learning_rate": 2.880224669924867e-05,
      "loss": 0.0037,
      "step": 29060
    },
    {
      "epoch": 2.1205047778831423,
      "grad_norm": 0.556774377822876,
      "learning_rate": 2.8794952221168576e-05,
      "loss": 0.0039,
      "step": 29070
    },
    {
      "epoch": 2.121234225691152,
      "grad_norm": 0.5564867854118347,
      "learning_rate": 2.878765774308848e-05,
      "loss": 0.0035,
      "step": 29080
    },
    {
      "epoch": 2.121963673499161,
      "grad_norm": 0.17105042934417725,
      "learning_rate": 2.878036326500839e-05,
      "loss": 0.0039,
      "step": 29090
    },
    {
      "epoch": 2.1226931213071705,
      "grad_norm": 0.2672194540500641,
      "learning_rate": 2.87730687869283e-05,
      "loss": 0.003,
      "step": 29100
    },
    {
      "epoch": 2.12342256911518,
      "grad_norm": 0.23106519877910614,
      "learning_rate": 2.8765774308848203e-05,
      "loss": 0.0041,
      "step": 29110
    },
    {
      "epoch": 2.124152016923189,
      "grad_norm": 0.14509563148021698,
      "learning_rate": 2.875847983076811e-05,
      "loss": 0.0027,
      "step": 29120
    },
    {
      "epoch": 2.1248814647311987,
      "grad_norm": 0.5464026927947998,
      "learning_rate": 2.8751185352688015e-05,
      "loss": 0.0053,
      "step": 29130
    },
    {
      "epoch": 2.1256109125392078,
      "grad_norm": 0.20123277604579926,
      "learning_rate": 2.874389087460792e-05,
      "loss": 0.0046,
      "step": 29140
    },
    {
      "epoch": 2.1263403603472173,
      "grad_norm": 0.03153705596923828,
      "learning_rate": 2.8736596396527833e-05,
      "loss": 0.0039,
      "step": 29150
    },
    {
      "epoch": 2.1270698081552264,
      "grad_norm": 0.11515337973833084,
      "learning_rate": 2.8729301918447737e-05,
      "loss": 0.0042,
      "step": 29160
    },
    {
      "epoch": 2.127799255963236,
      "grad_norm": 0.187640979886055,
      "learning_rate": 2.872200744036764e-05,
      "loss": 0.0029,
      "step": 29170
    },
    {
      "epoch": 2.128528703771245,
      "grad_norm": 0.3735434412956238,
      "learning_rate": 2.871471296228755e-05,
      "loss": 0.0054,
      "step": 29180
    },
    {
      "epoch": 2.1292581515792546,
      "grad_norm": 0.20921140909194946,
      "learning_rate": 2.8707418484207453e-05,
      "loss": 0.0037,
      "step": 29190
    },
    {
      "epoch": 2.1299875993872637,
      "grad_norm": 0.11583301424980164,
      "learning_rate": 2.8700124006127367e-05,
      "loss": 0.0047,
      "step": 29200
    },
    {
      "epoch": 2.130717047195273,
      "grad_norm": 0.5056012272834778,
      "learning_rate": 2.869282952804727e-05,
      "loss": 0.0029,
      "step": 29210
    },
    {
      "epoch": 2.1314464950032823,
      "grad_norm": 0.14429537951946259,
      "learning_rate": 2.8685535049967176e-05,
      "loss": 0.0035,
      "step": 29220
    },
    {
      "epoch": 2.132175942811292,
      "grad_norm": 0.26748594641685486,
      "learning_rate": 2.8678240571887083e-05,
      "loss": 0.0039,
      "step": 29230
    },
    {
      "epoch": 2.1329053906193014,
      "grad_norm": 0.4601248800754547,
      "learning_rate": 2.8670946093806987e-05,
      "loss": 0.0021,
      "step": 29240
    },
    {
      "epoch": 2.1336348384273105,
      "grad_norm": 0.31584975123405457,
      "learning_rate": 2.8663651615726895e-05,
      "loss": 0.0035,
      "step": 29250
    },
    {
      "epoch": 2.13436428623532,
      "grad_norm": 0.08695702999830246,
      "learning_rate": 2.8656357137646806e-05,
      "loss": 0.0055,
      "step": 29260
    },
    {
      "epoch": 2.135093734043329,
      "grad_norm": 0.0835162028670311,
      "learning_rate": 2.864906265956671e-05,
      "loss": 0.0044,
      "step": 29270
    },
    {
      "epoch": 2.1358231818513387,
      "grad_norm": 0.46601712703704834,
      "learning_rate": 2.8641768181486617e-05,
      "loss": 0.0032,
      "step": 29280
    },
    {
      "epoch": 2.136552629659348,
      "grad_norm": 0.05878610536456108,
      "learning_rate": 2.863447370340652e-05,
      "loss": 0.0041,
      "step": 29290
    },
    {
      "epoch": 2.1372820774673573,
      "grad_norm": 0.1436106264591217,
      "learning_rate": 2.862717922532643e-05,
      "loss": 0.0035,
      "step": 29300
    },
    {
      "epoch": 2.1380115252753664,
      "grad_norm": 0.11861125379800797,
      "learning_rate": 2.8619884747246333e-05,
      "loss": 0.0041,
      "step": 29310
    },
    {
      "epoch": 2.138740973083376,
      "grad_norm": 0.14446167647838593,
      "learning_rate": 2.8612590269166244e-05,
      "loss": 0.0031,
      "step": 29320
    },
    {
      "epoch": 2.139470420891385,
      "grad_norm": 0.06875236332416534,
      "learning_rate": 2.8605295791086152e-05,
      "loss": 0.0042,
      "step": 29330
    },
    {
      "epoch": 2.1401998686993946,
      "grad_norm": 0.058524105697870255,
      "learning_rate": 2.8598001313006056e-05,
      "loss": 0.0049,
      "step": 29340
    },
    {
      "epoch": 2.1409293165074037,
      "grad_norm": 0.15056103467941284,
      "learning_rate": 2.8590706834925963e-05,
      "loss": 0.004,
      "step": 29350
    },
    {
      "epoch": 2.1416587643154132,
      "grad_norm": 0.14373794198036194,
      "learning_rate": 2.8583412356845868e-05,
      "loss": 0.0057,
      "step": 29360
    },
    {
      "epoch": 2.1423882121234223,
      "grad_norm": 0.6017428040504456,
      "learning_rate": 2.8576117878765775e-05,
      "loss": 0.0047,
      "step": 29370
    },
    {
      "epoch": 2.143117659931432,
      "grad_norm": 0.14586544036865234,
      "learning_rate": 2.8568823400685686e-05,
      "loss": 0.0032,
      "step": 29380
    },
    {
      "epoch": 2.1438471077394414,
      "grad_norm": 0.16203923523426056,
      "learning_rate": 2.856152892260559e-05,
      "loss": 0.0037,
      "step": 29390
    },
    {
      "epoch": 2.1445765555474505,
      "grad_norm": 0.17288289964199066,
      "learning_rate": 2.8554234444525498e-05,
      "loss": 0.003,
      "step": 29400
    },
    {
      "epoch": 2.14530600335546,
      "grad_norm": 0.08626486361026764,
      "learning_rate": 2.8546939966445402e-05,
      "loss": 0.0028,
      "step": 29410
    },
    {
      "epoch": 2.146035451163469,
      "grad_norm": 0.11636918783187866,
      "learning_rate": 2.8539645488365306e-05,
      "loss": 0.003,
      "step": 29420
    },
    {
      "epoch": 2.1467648989714787,
      "grad_norm": 0.058108583092689514,
      "learning_rate": 2.8532351010285214e-05,
      "loss": 0.0049,
      "step": 29430
    },
    {
      "epoch": 2.147494346779488,
      "grad_norm": 0.2598956227302551,
      "learning_rate": 2.8525056532205124e-05,
      "loss": 0.0035,
      "step": 29440
    },
    {
      "epoch": 2.1482237945874973,
      "grad_norm": 0.27096325159072876,
      "learning_rate": 2.851776205412503e-05,
      "loss": 0.0035,
      "step": 29450
    },
    {
      "epoch": 2.1489532423955064,
      "grad_norm": 0.35154736042022705,
      "learning_rate": 2.8510467576044936e-05,
      "loss": 0.0038,
      "step": 29460
    },
    {
      "epoch": 2.149682690203516,
      "grad_norm": 0.017173022031784058,
      "learning_rate": 2.850317309796484e-05,
      "loss": 0.005,
      "step": 29470
    },
    {
      "epoch": 2.150412138011525,
      "grad_norm": 0.2101891040802002,
      "learning_rate": 2.8495878619884748e-05,
      "loss": 0.0028,
      "step": 29480
    },
    {
      "epoch": 2.1511415858195346,
      "grad_norm": 0.23015739023685455,
      "learning_rate": 2.8488584141804652e-05,
      "loss": 0.0041,
      "step": 29490
    },
    {
      "epoch": 2.151871033627544,
      "grad_norm": 0.05820651352405548,
      "learning_rate": 2.8481289663724563e-05,
      "loss": 0.0047,
      "step": 29500
    },
    {
      "epoch": 2.1526004814355533,
      "grad_norm": 0.3448074758052826,
      "learning_rate": 2.847399518564447e-05,
      "loss": 0.0033,
      "step": 29510
    },
    {
      "epoch": 2.153329929243563,
      "grad_norm": 0.2950473725795746,
      "learning_rate": 2.8466700707564374e-05,
      "loss": 0.0045,
      "step": 29520
    },
    {
      "epoch": 2.154059377051572,
      "grad_norm": 0.3310889005661011,
      "learning_rate": 2.8459406229484282e-05,
      "loss": 0.0042,
      "step": 29530
    },
    {
      "epoch": 2.1547888248595815,
      "grad_norm": 0.2600201368331909,
      "learning_rate": 2.8452111751404186e-05,
      "loss": 0.0036,
      "step": 29540
    },
    {
      "epoch": 2.1555182726675906,
      "grad_norm": 0.46009451150894165,
      "learning_rate": 2.8444817273324094e-05,
      "loss": 0.0047,
      "step": 29550
    },
    {
      "epoch": 2.1562477204756,
      "grad_norm": 0.05896855145692825,
      "learning_rate": 2.8437522795244005e-05,
      "loss": 0.0042,
      "step": 29560
    },
    {
      "epoch": 2.156977168283609,
      "grad_norm": 0.20211191475391388,
      "learning_rate": 2.843022831716391e-05,
      "loss": 0.0038,
      "step": 29570
    },
    {
      "epoch": 2.1577066160916187,
      "grad_norm": 0.2305392473936081,
      "learning_rate": 2.8422933839083816e-05,
      "loss": 0.0036,
      "step": 29580
    },
    {
      "epoch": 2.158436063899628,
      "grad_norm": 0.2015361785888672,
      "learning_rate": 2.841563936100372e-05,
      "loss": 0.0046,
      "step": 29590
    },
    {
      "epoch": 2.1591655117076374,
      "grad_norm": 0.316475510597229,
      "learning_rate": 2.8408344882923628e-05,
      "loss": 0.0045,
      "step": 29600
    },
    {
      "epoch": 2.1598949595156465,
      "grad_norm": 0.11598746478557587,
      "learning_rate": 2.8401050404843532e-05,
      "loss": 0.0034,
      "step": 29610
    },
    {
      "epoch": 2.160624407323656,
      "grad_norm": 0.6329478621482849,
      "learning_rate": 2.8393755926763443e-05,
      "loss": 0.0039,
      "step": 29620
    },
    {
      "epoch": 2.161353855131665,
      "grad_norm": 0.07177771627902985,
      "learning_rate": 2.838646144868335e-05,
      "loss": 0.0038,
      "step": 29630
    },
    {
      "epoch": 2.1620833029396747,
      "grad_norm": 0.1900191456079483,
      "learning_rate": 2.8379166970603255e-05,
      "loss": 0.0054,
      "step": 29640
    },
    {
      "epoch": 2.162812750747684,
      "grad_norm": 0.5303187966346741,
      "learning_rate": 2.837187249252316e-05,
      "loss": 0.0048,
      "step": 29650
    },
    {
      "epoch": 2.1635421985556933,
      "grad_norm": 0.17754459381103516,
      "learning_rate": 2.8364578014443066e-05,
      "loss": 0.0042,
      "step": 29660
    },
    {
      "epoch": 2.164271646363703,
      "grad_norm": 0.14402812719345093,
      "learning_rate": 2.835728353636297e-05,
      "loss": 0.0043,
      "step": 29670
    },
    {
      "epoch": 2.165001094171712,
      "grad_norm": 0.08737435936927795,
      "learning_rate": 2.834998905828288e-05,
      "loss": 0.0046,
      "step": 29680
    },
    {
      "epoch": 2.1657305419797215,
      "grad_norm": 0.17317287623882294,
      "learning_rate": 2.834269458020279e-05,
      "loss": 0.004,
      "step": 29690
    },
    {
      "epoch": 2.1664599897877306,
      "grad_norm": 0.030917096883058548,
      "learning_rate": 2.8335400102122693e-05,
      "loss": 0.0055,
      "step": 29700
    },
    {
      "epoch": 2.16718943759574,
      "grad_norm": 0.011081653647124767,
      "learning_rate": 2.83281056240426e-05,
      "loss": 0.0033,
      "step": 29710
    },
    {
      "epoch": 2.167918885403749,
      "grad_norm": 0.1769636869430542,
      "learning_rate": 2.8320811145962505e-05,
      "loss": 0.0049,
      "step": 29720
    },
    {
      "epoch": 2.1686483332117588,
      "grad_norm": 0.3743854761123657,
      "learning_rate": 2.8313516667882416e-05,
      "loss": 0.0037,
      "step": 29730
    },
    {
      "epoch": 2.169377781019768,
      "grad_norm": 0.14473295211791992,
      "learning_rate": 2.8306222189802323e-05,
      "loss": 0.0055,
      "step": 29740
    },
    {
      "epoch": 2.1701072288277774,
      "grad_norm": 0.2305273562669754,
      "learning_rate": 2.8298927711722227e-05,
      "loss": 0.0058,
      "step": 29750
    },
    {
      "epoch": 2.170836676635787,
      "grad_norm": 0.316610723733902,
      "learning_rate": 2.8291633233642135e-05,
      "loss": 0.0032,
      "step": 29760
    },
    {
      "epoch": 2.171566124443796,
      "grad_norm": 0.10719382017850876,
      "learning_rate": 2.828433875556204e-05,
      "loss": 0.0051,
      "step": 29770
    },
    {
      "epoch": 2.1722955722518056,
      "grad_norm": 0.46771466732025146,
      "learning_rate": 2.8277044277481947e-05,
      "loss": 0.0038,
      "step": 29780
    },
    {
      "epoch": 2.1730250200598147,
      "grad_norm": 0.3174128830432892,
      "learning_rate": 2.8269749799401857e-05,
      "loss": 0.0048,
      "step": 29790
    },
    {
      "epoch": 2.1737544678678242,
      "grad_norm": 0.3470988869667053,
      "learning_rate": 2.826245532132176e-05,
      "loss": 0.0037,
      "step": 29800
    },
    {
      "epoch": 2.1744839156758333,
      "grad_norm": 0.14431071281433105,
      "learning_rate": 2.825516084324167e-05,
      "loss": 0.004,
      "step": 29810
    },
    {
      "epoch": 2.175213363483843,
      "grad_norm": 0.17268691956996918,
      "learning_rate": 2.8247866365161573e-05,
      "loss": 0.0043,
      "step": 29820
    },
    {
      "epoch": 2.175942811291852,
      "grad_norm": 0.030108116567134857,
      "learning_rate": 2.824057188708148e-05,
      "loss": 0.0044,
      "step": 29830
    },
    {
      "epoch": 2.1766722590998615,
      "grad_norm": 0.2007080614566803,
      "learning_rate": 2.8233277409001385e-05,
      "loss": 0.0039,
      "step": 29840
    },
    {
      "epoch": 2.1774017069078706,
      "grad_norm": 0.1172480434179306,
      "learning_rate": 2.8225982930921296e-05,
      "loss": 0.004,
      "step": 29850
    },
    {
      "epoch": 2.17813115471588,
      "grad_norm": 0.40317803621292114,
      "learning_rate": 2.8218688452841203e-05,
      "loss": 0.0028,
      "step": 29860
    },
    {
      "epoch": 2.1788606025238892,
      "grad_norm": 0.17319518327713013,
      "learning_rate": 2.8211393974761108e-05,
      "loss": 0.0052,
      "step": 29870
    },
    {
      "epoch": 2.179590050331899,
      "grad_norm": 0.3454832434654236,
      "learning_rate": 2.8204099496681015e-05,
      "loss": 0.0039,
      "step": 29880
    },
    {
      "epoch": 2.180319498139908,
      "grad_norm": 0.058595675975084305,
      "learning_rate": 2.819680501860092e-05,
      "loss": 0.0045,
      "step": 29890
    },
    {
      "epoch": 2.1810489459479174,
      "grad_norm": 0.058268025517463684,
      "learning_rate": 2.8189510540520823e-05,
      "loss": 0.004,
      "step": 29900
    },
    {
      "epoch": 2.181778393755927,
      "grad_norm": 0.3460111916065216,
      "learning_rate": 2.8182216062440738e-05,
      "loss": 0.0033,
      "step": 29910
    },
    {
      "epoch": 2.182507841563936,
      "grad_norm": 0.11619649082422256,
      "learning_rate": 2.8174921584360642e-05,
      "loss": 0.0043,
      "step": 29920
    },
    {
      "epoch": 2.1832372893719456,
      "grad_norm": 0.15114299952983856,
      "learning_rate": 2.8167627106280546e-05,
      "loss": 0.0031,
      "step": 29930
    },
    {
      "epoch": 2.1839667371799547,
      "grad_norm": 0.008870158344507217,
      "learning_rate": 2.8160332628200453e-05,
      "loss": 0.0057,
      "step": 29940
    },
    {
      "epoch": 2.1846961849879643,
      "grad_norm": 0.2012377679347992,
      "learning_rate": 2.8153038150120358e-05,
      "loss": 0.0041,
      "step": 29950
    },
    {
      "epoch": 2.1854256327959733,
      "grad_norm": 0.12731531262397766,
      "learning_rate": 2.8145743672040265e-05,
      "loss": 0.003,
      "step": 29960
    },
    {
      "epoch": 2.186155080603983,
      "grad_norm": 0.01138163823634386,
      "learning_rate": 2.8138449193960176e-05,
      "loss": 0.004,
      "step": 29970
    },
    {
      "epoch": 2.186884528411992,
      "grad_norm": 0.2939075231552124,
      "learning_rate": 2.813115471588008e-05,
      "loss": 0.0035,
      "step": 29980
    },
    {
      "epoch": 2.1876139762200015,
      "grad_norm": 0.23103724420070648,
      "learning_rate": 2.8123860237799988e-05,
      "loss": 0.0041,
      "step": 29990
    },
    {
      "epoch": 2.1883434240280106,
      "grad_norm": 0.5925508141517639,
      "learning_rate": 2.8116565759719892e-05,
      "loss": 0.0041,
      "step": 30000
    },
    {
      "epoch": 2.18907287183602,
      "grad_norm": 0.20121407508850098,
      "learning_rate": 2.81092712816398e-05,
      "loss": 0.0029,
      "step": 30010
    },
    {
      "epoch": 2.1898023196440293,
      "grad_norm": 0.3744807541370392,
      "learning_rate": 2.8101976803559704e-05,
      "loss": 0.0042,
      "step": 30020
    },
    {
      "epoch": 2.190531767452039,
      "grad_norm": 0.27545005083084106,
      "learning_rate": 2.8094682325479614e-05,
      "loss": 0.0053,
      "step": 30030
    },
    {
      "epoch": 2.191261215260048,
      "grad_norm": 0.030221981927752495,
      "learning_rate": 2.8087387847399522e-05,
      "loss": 0.0032,
      "step": 30040
    },
    {
      "epoch": 2.1919906630680575,
      "grad_norm": 0.11513630300760269,
      "learning_rate": 2.8080093369319426e-05,
      "loss": 0.0035,
      "step": 30050
    },
    {
      "epoch": 2.192720110876067,
      "grad_norm": 0.1734815388917923,
      "learning_rate": 2.8072798891239334e-05,
      "loss": 0.0029,
      "step": 30060
    },
    {
      "epoch": 2.193449558684076,
      "grad_norm": 0.10991507768630981,
      "learning_rate": 2.8065504413159238e-05,
      "loss": 0.0038,
      "step": 30070
    },
    {
      "epoch": 2.1941790064920856,
      "grad_norm": 0.3110288381576538,
      "learning_rate": 2.8058209935079145e-05,
      "loss": 0.0039,
      "step": 30080
    },
    {
      "epoch": 2.1949084543000947,
      "grad_norm": 0.37317341566085815,
      "learning_rate": 2.8050915456999056e-05,
      "loss": 0.0035,
      "step": 30090
    },
    {
      "epoch": 2.1956379021081043,
      "grad_norm": 0.06048712506890297,
      "learning_rate": 2.804362097891896e-05,
      "loss": 0.0036,
      "step": 30100
    },
    {
      "epoch": 2.1963673499161134,
      "grad_norm": 0.1931534707546234,
      "learning_rate": 2.8036326500838868e-05,
      "loss": 0.004,
      "step": 30110
    },
    {
      "epoch": 2.197096797724123,
      "grad_norm": 0.09210547059774399,
      "learning_rate": 2.8029032022758772e-05,
      "loss": 0.0036,
      "step": 30120
    },
    {
      "epoch": 2.197826245532132,
      "grad_norm": 0.10092554241418839,
      "learning_rate": 2.8021737544678676e-05,
      "loss": 0.0034,
      "step": 30130
    },
    {
      "epoch": 2.1985556933401416,
      "grad_norm": 0.20157568156719208,
      "learning_rate": 2.8014443066598584e-05,
      "loss": 0.0054,
      "step": 30140
    },
    {
      "epoch": 2.1992851411481507,
      "grad_norm": 0.5327950716018677,
      "learning_rate": 2.8007148588518495e-05,
      "loss": 0.0039,
      "step": 30150
    },
    {
      "epoch": 2.20001458895616,
      "grad_norm": 0.03193594887852669,
      "learning_rate": 2.79998541104384e-05,
      "loss": 0.0037,
      "step": 30160
    },
    {
      "epoch": 2.2007440367641697,
      "grad_norm": 0.11650703102350235,
      "learning_rate": 2.7992559632358306e-05,
      "loss": 0.0045,
      "step": 30170
    },
    {
      "epoch": 2.201473484572179,
      "grad_norm": 0.17365047335624695,
      "learning_rate": 2.798526515427821e-05,
      "loss": 0.005,
      "step": 30180
    },
    {
      "epoch": 2.2022029323801884,
      "grad_norm": 0.12464200705289841,
      "learning_rate": 2.7977970676198118e-05,
      "loss": 0.0038,
      "step": 30190
    },
    {
      "epoch": 2.2029323801881975,
      "grad_norm": 0.05825464427471161,
      "learning_rate": 2.797067619811803e-05,
      "loss": 0.0039,
      "step": 30200
    },
    {
      "epoch": 2.203661827996207,
      "grad_norm": 0.11502986401319504,
      "learning_rate": 2.7963381720037933e-05,
      "loss": 0.0037,
      "step": 30210
    },
    {
      "epoch": 2.204391275804216,
      "grad_norm": 0.2021416425704956,
      "learning_rate": 2.795608724195784e-05,
      "loss": 0.0039,
      "step": 30220
    },
    {
      "epoch": 2.2051207236122257,
      "grad_norm": 0.08647452294826508,
      "learning_rate": 2.7948792763877745e-05,
      "loss": 0.0046,
      "step": 30230
    },
    {
      "epoch": 2.2058501714202348,
      "grad_norm": 0.17277052998542786,
      "learning_rate": 2.7941498285797652e-05,
      "loss": 0.0029,
      "step": 30240
    },
    {
      "epoch": 2.2065796192282443,
      "grad_norm": 0.1703389286994934,
      "learning_rate": 2.7934203807717556e-05,
      "loss": 0.0043,
      "step": 30250
    },
    {
      "epoch": 2.2073090670362534,
      "grad_norm": 0.09104590117931366,
      "learning_rate": 2.7926909329637467e-05,
      "loss": 0.0041,
      "step": 30260
    },
    {
      "epoch": 2.208038514844263,
      "grad_norm": 0.3663511872291565,
      "learning_rate": 2.7919614851557375e-05,
      "loss": 0.005,
      "step": 30270
    },
    {
      "epoch": 2.208767962652272,
      "grad_norm": 0.02989627793431282,
      "learning_rate": 2.791232037347728e-05,
      "loss": 0.003,
      "step": 30280
    },
    {
      "epoch": 2.2094974104602816,
      "grad_norm": 0.631974458694458,
      "learning_rate": 2.7905025895397187e-05,
      "loss": 0.003,
      "step": 30290
    },
    {
      "epoch": 2.2102268582682907,
      "grad_norm": 0.4880778193473816,
      "learning_rate": 2.789773141731709e-05,
      "loss": 0.0027,
      "step": 30300
    },
    {
      "epoch": 2.2109563060763002,
      "grad_norm": 0.169864222407341,
      "learning_rate": 2.7890436939236998e-05,
      "loss": 0.0036,
      "step": 30310
    },
    {
      "epoch": 2.2116857538843098,
      "grad_norm": 0.2361183613538742,
      "learning_rate": 2.788314246115691e-05,
      "loss": 0.0046,
      "step": 30320
    },
    {
      "epoch": 2.212415201692319,
      "grad_norm": 0.08664975315332413,
      "learning_rate": 2.7875847983076813e-05,
      "loss": 0.0014,
      "step": 30330
    },
    {
      "epoch": 2.2131446495003284,
      "grad_norm": 0.11499586701393127,
      "learning_rate": 2.786855350499672e-05,
      "loss": 0.0027,
      "step": 30340
    },
    {
      "epoch": 2.2138740973083375,
      "grad_norm": 0.1156969666481018,
      "learning_rate": 2.7861259026916625e-05,
      "loss": 0.0052,
      "step": 30350
    },
    {
      "epoch": 2.214603545116347,
      "grad_norm": 0.14402085542678833,
      "learning_rate": 2.7853964548836532e-05,
      "loss": 0.0049,
      "step": 30360
    },
    {
      "epoch": 2.215332992924356,
      "grad_norm": 0.17578867077827454,
      "learning_rate": 2.7846670070756437e-05,
      "loss": 0.0044,
      "step": 30370
    },
    {
      "epoch": 2.2160624407323657,
      "grad_norm": 0.05862623453140259,
      "learning_rate": 2.7839375592676348e-05,
      "loss": 0.0029,
      "step": 30380
    },
    {
      "epoch": 2.216791888540375,
      "grad_norm": 0.4540103077888489,
      "learning_rate": 2.7832081114596255e-05,
      "loss": 0.0039,
      "step": 30390
    },
    {
      "epoch": 2.2175213363483843,
      "grad_norm": 0.32603734731674194,
      "learning_rate": 2.782478663651616e-05,
      "loss": 0.0049,
      "step": 30400
    },
    {
      "epoch": 2.2182507841563934,
      "grad_norm": 0.11536984145641327,
      "learning_rate": 2.7817492158436063e-05,
      "loss": 0.0032,
      "step": 30410
    },
    {
      "epoch": 2.218980231964403,
      "grad_norm": 0.3324277400970459,
      "learning_rate": 2.781019768035597e-05,
      "loss": 0.0036,
      "step": 30420
    },
    {
      "epoch": 2.2197096797724125,
      "grad_norm": 0.2728694677352905,
      "learning_rate": 2.7802903202275875e-05,
      "loss": 0.0029,
      "step": 30430
    },
    {
      "epoch": 2.2204391275804216,
      "grad_norm": 0.3234037160873413,
      "learning_rate": 2.7795608724195786e-05,
      "loss": 0.0049,
      "step": 30440
    },
    {
      "epoch": 2.221168575388431,
      "grad_norm": 0.5181474685668945,
      "learning_rate": 2.7788314246115693e-05,
      "loss": 0.0039,
      "step": 30450
    },
    {
      "epoch": 2.2218980231964403,
      "grad_norm": 0.7470585703849792,
      "learning_rate": 2.7781019768035598e-05,
      "loss": 0.0034,
      "step": 30460
    },
    {
      "epoch": 2.22262747100445,
      "grad_norm": 0.02952307090163231,
      "learning_rate": 2.7773725289955505e-05,
      "loss": 0.0031,
      "step": 30470
    },
    {
      "epoch": 2.223356918812459,
      "grad_norm": 0.11607105284929276,
      "learning_rate": 2.776643081187541e-05,
      "loss": 0.0045,
      "step": 30480
    },
    {
      "epoch": 2.2240863666204684,
      "grad_norm": 0.2878938615322113,
      "learning_rate": 2.7759136333795317e-05,
      "loss": 0.0045,
      "step": 30490
    },
    {
      "epoch": 2.2248158144284775,
      "grad_norm": 0.029003171250224113,
      "learning_rate": 2.7751841855715228e-05,
      "loss": 0.0046,
      "step": 30500
    },
    {
      "epoch": 2.225545262236487,
      "grad_norm": 0.23034259676933289,
      "learning_rate": 2.7744547377635132e-05,
      "loss": 0.0051,
      "step": 30510
    },
    {
      "epoch": 2.226274710044496,
      "grad_norm": 0.007136626169085503,
      "learning_rate": 2.773725289955504e-05,
      "loss": 0.0047,
      "step": 30520
    },
    {
      "epoch": 2.2270041578525057,
      "grad_norm": 0.14978034794330597,
      "learning_rate": 2.7729958421474944e-05,
      "loss": 0.0038,
      "step": 30530
    },
    {
      "epoch": 2.227733605660515,
      "grad_norm": 0.36148056387901306,
      "learning_rate": 2.772266394339485e-05,
      "loss": 0.0036,
      "step": 30540
    },
    {
      "epoch": 2.2284630534685244,
      "grad_norm": 0.25869542360305786,
      "learning_rate": 2.7715369465314755e-05,
      "loss": 0.0034,
      "step": 30550
    },
    {
      "epoch": 2.2291925012765335,
      "grad_norm": 0.5754086375236511,
      "learning_rate": 2.7708074987234666e-05,
      "loss": 0.0025,
      "step": 30560
    },
    {
      "epoch": 2.229921949084543,
      "grad_norm": 0.5170984864234924,
      "learning_rate": 2.7700780509154574e-05,
      "loss": 0.0036,
      "step": 30570
    },
    {
      "epoch": 2.2306513968925525,
      "grad_norm": 0.5871835947036743,
      "learning_rate": 2.7693486031074478e-05,
      "loss": 0.0037,
      "step": 30580
    },
    {
      "epoch": 2.2313808447005616,
      "grad_norm": 0.14457419514656067,
      "learning_rate": 2.7686191552994385e-05,
      "loss": 0.0032,
      "step": 30590
    },
    {
      "epoch": 2.232110292508571,
      "grad_norm": 0.15874342620372772,
      "learning_rate": 2.767889707491429e-05,
      "loss": 0.0028,
      "step": 30600
    },
    {
      "epoch": 2.2328397403165803,
      "grad_norm": 0.17112937569618225,
      "learning_rate": 2.7671602596834194e-05,
      "loss": 0.0047,
      "step": 30610
    },
    {
      "epoch": 2.23356918812459,
      "grad_norm": 0.54632967710495,
      "learning_rate": 2.7664308118754108e-05,
      "loss": 0.0044,
      "step": 30620
    },
    {
      "epoch": 2.234298635932599,
      "grad_norm": 0.11565528064966202,
      "learning_rate": 2.7657013640674012e-05,
      "loss": 0.003,
      "step": 30630
    },
    {
      "epoch": 2.2350280837406085,
      "grad_norm": 0.0866822600364685,
      "learning_rate": 2.7649719162593916e-05,
      "loss": 0.0028,
      "step": 30640
    },
    {
      "epoch": 2.2357575315486176,
      "grad_norm": 0.057361871004104614,
      "learning_rate": 2.7642424684513824e-05,
      "loss": 0.0027,
      "step": 30650
    },
    {
      "epoch": 2.236486979356627,
      "grad_norm": 0.02959338389337063,
      "learning_rate": 2.7635130206433728e-05,
      "loss": 0.0042,
      "step": 30660
    },
    {
      "epoch": 2.237216427164636,
      "grad_norm": 0.11510361731052399,
      "learning_rate": 2.7627835728353635e-05,
      "loss": 0.0042,
      "step": 30670
    },
    {
      "epoch": 2.2379458749726457,
      "grad_norm": 0.06000427156686783,
      "learning_rate": 2.7620541250273546e-05,
      "loss": 0.0038,
      "step": 30680
    },
    {
      "epoch": 2.238675322780655,
      "grad_norm": 0.40625324845314026,
      "learning_rate": 2.761324677219345e-05,
      "loss": 0.0046,
      "step": 30690
    },
    {
      "epoch": 2.2394047705886644,
      "grad_norm": 0.05014197900891304,
      "learning_rate": 2.7605952294113358e-05,
      "loss": 0.0033,
      "step": 30700
    },
    {
      "epoch": 2.2401342183966735,
      "grad_norm": 0.06311890482902527,
      "learning_rate": 2.7598657816033262e-05,
      "loss": 0.0027,
      "step": 30710
    },
    {
      "epoch": 2.240863666204683,
      "grad_norm": 0.4733982980251312,
      "learning_rate": 2.759136333795317e-05,
      "loss": 0.0034,
      "step": 30720
    },
    {
      "epoch": 2.2415931140126926,
      "grad_norm": 0.03648212179541588,
      "learning_rate": 2.758406885987308e-05,
      "loss": 0.0036,
      "step": 30730
    },
    {
      "epoch": 2.2423225618207017,
      "grad_norm": 0.1179218590259552,
      "learning_rate": 2.7576774381792985e-05,
      "loss": 0.0043,
      "step": 30740
    },
    {
      "epoch": 2.243052009628711,
      "grad_norm": 0.3449418246746063,
      "learning_rate": 2.7569479903712892e-05,
      "loss": 0.0039,
      "step": 30750
    },
    {
      "epoch": 2.2437814574367203,
      "grad_norm": 0.6933274269104004,
      "learning_rate": 2.7562185425632796e-05,
      "loss": 0.0055,
      "step": 30760
    },
    {
      "epoch": 2.24451090524473,
      "grad_norm": 0.2303883582353592,
      "learning_rate": 2.7554890947552704e-05,
      "loss": 0.0043,
      "step": 30770
    },
    {
      "epoch": 2.245240353052739,
      "grad_norm": 0.1728445589542389,
      "learning_rate": 2.7547596469472608e-05,
      "loss": 0.0048,
      "step": 30780
    },
    {
      "epoch": 2.2459698008607485,
      "grad_norm": 0.05755600705742836,
      "learning_rate": 2.754030199139252e-05,
      "loss": 0.0044,
      "step": 30790
    },
    {
      "epoch": 2.2466992486687576,
      "grad_norm": 0.05779610201716423,
      "learning_rate": 2.7533007513312427e-05,
      "loss": 0.004,
      "step": 30800
    },
    {
      "epoch": 2.247428696476767,
      "grad_norm": 0.05767324939370155,
      "learning_rate": 2.752571303523233e-05,
      "loss": 0.0035,
      "step": 30810
    },
    {
      "epoch": 2.2481581442847762,
      "grad_norm": 0.05877180024981499,
      "learning_rate": 2.7518418557152238e-05,
      "loss": 0.0049,
      "step": 30820
    },
    {
      "epoch": 2.2488875920927858,
      "grad_norm": 0.2599773406982422,
      "learning_rate": 2.7511124079072142e-05,
      "loss": 0.0046,
      "step": 30830
    },
    {
      "epoch": 2.2496170399007953,
      "grad_norm": 0.08690431714057922,
      "learning_rate": 2.750382960099205e-05,
      "loss": 0.0045,
      "step": 30840
    },
    {
      "epoch": 2.2503464877088044,
      "grad_norm": 0.012628911063075066,
      "learning_rate": 2.749653512291196e-05,
      "loss": 0.0026,
      "step": 30850
    },
    {
      "epoch": 2.251075935516814,
      "grad_norm": 0.42276057600975037,
      "learning_rate": 2.7489240644831865e-05,
      "loss": 0.0029,
      "step": 30860
    },
    {
      "epoch": 2.251805383324823,
      "grad_norm": 0.7235857844352722,
      "learning_rate": 2.7481946166751772e-05,
      "loss": 0.004,
      "step": 30870
    },
    {
      "epoch": 2.2525348311328326,
      "grad_norm": 0.1724712997674942,
      "learning_rate": 2.7474651688671677e-05,
      "loss": 0.005,
      "step": 30880
    },
    {
      "epoch": 2.2532642789408417,
      "grad_norm": 0.46082502603530884,
      "learning_rate": 2.746735721059158e-05,
      "loss": 0.0042,
      "step": 30890
    },
    {
      "epoch": 2.2539937267488512,
      "grad_norm": 0.14378203451633453,
      "learning_rate": 2.7460062732511488e-05,
      "loss": 0.0038,
      "step": 30900
    },
    {
      "epoch": 2.2547231745568603,
      "grad_norm": 0.143532857298851,
      "learning_rate": 2.74527682544314e-05,
      "loss": 0.0041,
      "step": 30910
    },
    {
      "epoch": 2.25545262236487,
      "grad_norm": 0.3744139075279236,
      "learning_rate": 2.7445473776351303e-05,
      "loss": 0.0041,
      "step": 30920
    },
    {
      "epoch": 2.256182070172879,
      "grad_norm": 0.11466246098279953,
      "learning_rate": 2.743817929827121e-05,
      "loss": 0.0044,
      "step": 30930
    },
    {
      "epoch": 2.2569115179808885,
      "grad_norm": 0.48830005526542664,
      "learning_rate": 2.7430884820191115e-05,
      "loss": 0.0033,
      "step": 30940
    },
    {
      "epoch": 2.2576409657888976,
      "grad_norm": 0.23035651445388794,
      "learning_rate": 2.7423590342111023e-05,
      "loss": 0.0033,
      "step": 30950
    },
    {
      "epoch": 2.258370413596907,
      "grad_norm": 0.09833715856075287,
      "learning_rate": 2.7416295864030927e-05,
      "loss": 0.0041,
      "step": 30960
    },
    {
      "epoch": 2.2590998614049163,
      "grad_norm": 0.17283394932746887,
      "learning_rate": 2.7409001385950838e-05,
      "loss": 0.0032,
      "step": 30970
    },
    {
      "epoch": 2.259829309212926,
      "grad_norm": 0.08775244653224945,
      "learning_rate": 2.7401706907870745e-05,
      "loss": 0.0026,
      "step": 30980
    },
    {
      "epoch": 2.2605587570209353,
      "grad_norm": 0.05784034729003906,
      "learning_rate": 2.739441242979065e-05,
      "loss": 0.0047,
      "step": 30990
    },
    {
      "epoch": 2.2612882048289444,
      "grad_norm": 0.17265133559703827,
      "learning_rate": 2.7387117951710557e-05,
      "loss": 0.0038,
      "step": 31000
    },
    {
      "epoch": 2.262017652636954,
      "grad_norm": 0.2940736413002014,
      "learning_rate": 2.737982347363046e-05,
      "loss": 0.0045,
      "step": 31010
    },
    {
      "epoch": 2.262747100444963,
      "grad_norm": 0.0587545707821846,
      "learning_rate": 2.737252899555037e-05,
      "loss": 0.0039,
      "step": 31020
    },
    {
      "epoch": 2.2634765482529726,
      "grad_norm": 0.14367690682411194,
      "learning_rate": 2.736523451747028e-05,
      "loss": 0.0048,
      "step": 31030
    },
    {
      "epoch": 2.2642059960609817,
      "grad_norm": 0.09387518465518951,
      "learning_rate": 2.7357940039390184e-05,
      "loss": 0.0043,
      "step": 31040
    },
    {
      "epoch": 2.2649354438689913,
      "grad_norm": 0.2992144823074341,
      "learning_rate": 2.735064556131009e-05,
      "loss": 0.0036,
      "step": 31050
    },
    {
      "epoch": 2.2656648916770004,
      "grad_norm": 0.40310466289520264,
      "learning_rate": 2.7343351083229995e-05,
      "loss": 0.0035,
      "step": 31060
    },
    {
      "epoch": 2.26639433948501,
      "grad_norm": 0.029890159144997597,
      "learning_rate": 2.7336056605149903e-05,
      "loss": 0.0032,
      "step": 31070
    },
    {
      "epoch": 2.267123787293019,
      "grad_norm": 0.05782390013337135,
      "learning_rate": 2.7328762127069807e-05,
      "loss": 0.0035,
      "step": 31080
    },
    {
      "epoch": 2.2678532351010285,
      "grad_norm": 0.11584525555372238,
      "learning_rate": 2.7321467648989718e-05,
      "loss": 0.0031,
      "step": 31090
    },
    {
      "epoch": 2.268582682909038,
      "grad_norm": 0.058411478996276855,
      "learning_rate": 2.7314173170909625e-05,
      "loss": 0.0029,
      "step": 31100
    },
    {
      "epoch": 2.269312130717047,
      "grad_norm": 0.07590945065021515,
      "learning_rate": 2.730687869282953e-05,
      "loss": 0.0036,
      "step": 31110
    },
    {
      "epoch": 2.2700415785250567,
      "grad_norm": 0.21500977873802185,
      "learning_rate": 2.7299584214749434e-05,
      "loss": 0.0023,
      "step": 31120
    },
    {
      "epoch": 2.270771026333066,
      "grad_norm": 0.27984413504600525,
      "learning_rate": 2.729228973666934e-05,
      "loss": 0.0034,
      "step": 31130
    },
    {
      "epoch": 2.2715004741410754,
      "grad_norm": 0.23085655272006989,
      "learning_rate": 2.7284995258589245e-05,
      "loss": 0.0037,
      "step": 31140
    },
    {
      "epoch": 2.2722299219490845,
      "grad_norm": 0.23904192447662354,
      "learning_rate": 2.7277700780509156e-05,
      "loss": 0.0025,
      "step": 31150
    },
    {
      "epoch": 2.272959369757094,
      "grad_norm": 0.35739973187446594,
      "learning_rate": 2.7270406302429064e-05,
      "loss": 0.0058,
      "step": 31160
    },
    {
      "epoch": 2.273688817565103,
      "grad_norm": 0.25321581959724426,
      "learning_rate": 2.7263111824348968e-05,
      "loss": 0.0042,
      "step": 31170
    },
    {
      "epoch": 2.2744182653731126,
      "grad_norm": 0.40304550528526306,
      "learning_rate": 2.7255817346268875e-05,
      "loss": 0.0026,
      "step": 31180
    },
    {
      "epoch": 2.2751477131811217,
      "grad_norm": 0.03313526138663292,
      "learning_rate": 2.724852286818878e-05,
      "loss": 0.0042,
      "step": 31190
    },
    {
      "epoch": 2.2758771609891313,
      "grad_norm": 0.3160220682621002,
      "learning_rate": 2.724122839010869e-05,
      "loss": 0.0051,
      "step": 31200
    },
    {
      "epoch": 2.2766066087971404,
      "grad_norm": 0.3730841875076294,
      "learning_rate": 2.7233933912028598e-05,
      "loss": 0.0035,
      "step": 31210
    },
    {
      "epoch": 2.27733605660515,
      "grad_norm": 0.43167757987976074,
      "learning_rate": 2.7226639433948502e-05,
      "loss": 0.0041,
      "step": 31220
    },
    {
      "epoch": 2.278065504413159,
      "grad_norm": 0.2587088644504547,
      "learning_rate": 2.721934495586841e-05,
      "loss": 0.0049,
      "step": 31230
    },
    {
      "epoch": 2.2787949522211686,
      "grad_norm": 0.29681000113487244,
      "learning_rate": 2.7212050477788314e-05,
      "loss": 0.0028,
      "step": 31240
    },
    {
      "epoch": 2.279524400029178,
      "grad_norm": 0.5859020352363586,
      "learning_rate": 2.720475599970822e-05,
      "loss": 0.0046,
      "step": 31250
    },
    {
      "epoch": 2.280253847837187,
      "grad_norm": 0.031104639172554016,
      "learning_rate": 2.7197461521628132e-05,
      "loss": 0.0037,
      "step": 31260
    },
    {
      "epoch": 2.2809832956451968,
      "grad_norm": 0.1156144067645073,
      "learning_rate": 2.7190167043548036e-05,
      "loss": 0.0027,
      "step": 31270
    },
    {
      "epoch": 2.281712743453206,
      "grad_norm": 0.17290833592414856,
      "learning_rate": 2.7182872565467944e-05,
      "loss": 0.0029,
      "step": 31280
    },
    {
      "epoch": 2.2824421912612154,
      "grad_norm": 0.1154855415225029,
      "learning_rate": 2.7175578087387848e-05,
      "loss": 0.0028,
      "step": 31290
    },
    {
      "epoch": 2.2831716390692245,
      "grad_norm": 0.2023213654756546,
      "learning_rate": 2.7168283609307756e-05,
      "loss": 0.0034,
      "step": 31300
    },
    {
      "epoch": 2.283901086877234,
      "grad_norm": 0.2020500749349594,
      "learning_rate": 2.716098913122766e-05,
      "loss": 0.0038,
      "step": 31310
    },
    {
      "epoch": 2.284630534685243,
      "grad_norm": 0.11540401726961136,
      "learning_rate": 2.715369465314757e-05,
      "loss": 0.0049,
      "step": 31320
    },
    {
      "epoch": 2.2853599824932527,
      "grad_norm": 0.23021839559078217,
      "learning_rate": 2.7146400175067478e-05,
      "loss": 0.0028,
      "step": 31330
    },
    {
      "epoch": 2.2860894303012618,
      "grad_norm": 0.4923916459083557,
      "learning_rate": 2.7139105696987382e-05,
      "loss": 0.0048,
      "step": 31340
    },
    {
      "epoch": 2.2868188781092713,
      "grad_norm": 0.3281371593475342,
      "learning_rate": 2.713181121890729e-05,
      "loss": 0.0043,
      "step": 31350
    },
    {
      "epoch": 2.287548325917281,
      "grad_norm": 0.25972992181777954,
      "learning_rate": 2.7124516740827194e-05,
      "loss": 0.0035,
      "step": 31360
    },
    {
      "epoch": 2.28827777372529,
      "grad_norm": 0.17271871864795685,
      "learning_rate": 2.7117222262747098e-05,
      "loss": 0.0039,
      "step": 31370
    },
    {
      "epoch": 2.289007221533299,
      "grad_norm": 0.5183369517326355,
      "learning_rate": 2.7109927784667012e-05,
      "loss": 0.0026,
      "step": 31380
    },
    {
      "epoch": 2.2897366693413086,
      "grad_norm": 0.23013836145401,
      "learning_rate": 2.7102633306586917e-05,
      "loss": 0.005,
      "step": 31390
    },
    {
      "epoch": 2.290466117149318,
      "grad_norm": 0.1157056987285614,
      "learning_rate": 2.709533882850682e-05,
      "loss": 0.0038,
      "step": 31400
    },
    {
      "epoch": 2.2911955649573272,
      "grad_norm": 0.2629299461841583,
      "learning_rate": 2.7088044350426728e-05,
      "loss": 0.0026,
      "step": 31410
    },
    {
      "epoch": 2.2919250127653368,
      "grad_norm": 0.058950625360012054,
      "learning_rate": 2.7080749872346632e-05,
      "loss": 0.0043,
      "step": 31420
    },
    {
      "epoch": 2.292654460573346,
      "grad_norm": 0.05986505374312401,
      "learning_rate": 2.707345539426654e-05,
      "loss": 0.0025,
      "step": 31430
    },
    {
      "epoch": 2.2933839083813554,
      "grad_norm": 0.031477879732847214,
      "learning_rate": 2.706616091618645e-05,
      "loss": 0.0038,
      "step": 31440
    },
    {
      "epoch": 2.2941133561893645,
      "grad_norm": 0.029751978814601898,
      "learning_rate": 2.7058866438106355e-05,
      "loss": 0.0035,
      "step": 31450
    },
    {
      "epoch": 2.294842803997374,
      "grad_norm": 0.0604587122797966,
      "learning_rate": 2.7051571960026263e-05,
      "loss": 0.0043,
      "step": 31460
    },
    {
      "epoch": 2.295572251805383,
      "grad_norm": 0.28777894377708435,
      "learning_rate": 2.7044277481946167e-05,
      "loss": 0.0042,
      "step": 31470
    },
    {
      "epoch": 2.2963016996133927,
      "grad_norm": 0.029182469472289085,
      "learning_rate": 2.7036983003866074e-05,
      "loss": 0.0031,
      "step": 31480
    },
    {
      "epoch": 2.297031147421402,
      "grad_norm": 0.27466270327568054,
      "learning_rate": 2.702968852578598e-05,
      "loss": 0.0037,
      "step": 31490
    },
    {
      "epoch": 2.2977605952294113,
      "grad_norm": 0.030523410066962242,
      "learning_rate": 2.702239404770589e-05,
      "loss": 0.0039,
      "step": 31500
    },
    {
      "epoch": 2.298490043037421,
      "grad_norm": 0.31593063473701477,
      "learning_rate": 2.7015099569625797e-05,
      "loss": 0.0037,
      "step": 31510
    },
    {
      "epoch": 2.29921949084543,
      "grad_norm": 0.5571824908256531,
      "learning_rate": 2.70078050915457e-05,
      "loss": 0.0028,
      "step": 31520
    },
    {
      "epoch": 2.2999489386534395,
      "grad_norm": 0.03094727173447609,
      "learning_rate": 2.700051061346561e-05,
      "loss": 0.0051,
      "step": 31530
    },
    {
      "epoch": 2.3006783864614486,
      "grad_norm": 0.41412317752838135,
      "learning_rate": 2.6993216135385513e-05,
      "loss": 0.0038,
      "step": 31540
    },
    {
      "epoch": 2.301407834269458,
      "grad_norm": 0.2588624060153961,
      "learning_rate": 2.698592165730542e-05,
      "loss": 0.003,
      "step": 31550
    },
    {
      "epoch": 2.3021372820774673,
      "grad_norm": 0.17231832444667816,
      "learning_rate": 2.697862717922533e-05,
      "loss": 0.0036,
      "step": 31560
    },
    {
      "epoch": 2.302866729885477,
      "grad_norm": 0.3381898105144501,
      "learning_rate": 2.6971332701145235e-05,
      "loss": 0.0032,
      "step": 31570
    },
    {
      "epoch": 2.303596177693486,
      "grad_norm": 0.007709229364991188,
      "learning_rate": 2.6964038223065143e-05,
      "loss": 0.0041,
      "step": 31580
    },
    {
      "epoch": 2.3043256255014954,
      "grad_norm": 0.05958038941025734,
      "learning_rate": 2.6956743744985047e-05,
      "loss": 0.0044,
      "step": 31590
    },
    {
      "epoch": 2.3050550733095045,
      "grad_norm": 0.07560036331415176,
      "learning_rate": 2.694944926690495e-05,
      "loss": 0.003,
      "step": 31600
    },
    {
      "epoch": 2.305784521117514,
      "grad_norm": 0.0301558468490839,
      "learning_rate": 2.694215478882486e-05,
      "loss": 0.0039,
      "step": 31610
    },
    {
      "epoch": 2.3065139689255236,
      "grad_norm": 0.17223016917705536,
      "learning_rate": 2.693486031074477e-05,
      "loss": 0.0039,
      "step": 31620
    },
    {
      "epoch": 2.3072434167335327,
      "grad_norm": 0.11972688138484955,
      "learning_rate": 2.6927565832664674e-05,
      "loss": 0.0037,
      "step": 31630
    },
    {
      "epoch": 2.307972864541542,
      "grad_norm": 0.34483179450035095,
      "learning_rate": 2.692027135458458e-05,
      "loss": 0.0035,
      "step": 31640
    },
    {
      "epoch": 2.3087023123495514,
      "grad_norm": 0.027171283960342407,
      "learning_rate": 2.6912976876504485e-05,
      "loss": 0.0039,
      "step": 31650
    },
    {
      "epoch": 2.309431760157561,
      "grad_norm": 0.1728644222021103,
      "learning_rate": 2.6905682398424393e-05,
      "loss": 0.0035,
      "step": 31660
    },
    {
      "epoch": 2.31016120796557,
      "grad_norm": 0.1722148209810257,
      "learning_rate": 2.6898387920344297e-05,
      "loss": 0.0038,
      "step": 31670
    },
    {
      "epoch": 2.3108906557735795,
      "grad_norm": 0.2586568295955658,
      "learning_rate": 2.6891093442264208e-05,
      "loss": 0.003,
      "step": 31680
    },
    {
      "epoch": 2.3116201035815886,
      "grad_norm": 0.2880432605743408,
      "learning_rate": 2.6883798964184115e-05,
      "loss": 0.0031,
      "step": 31690
    },
    {
      "epoch": 2.312349551389598,
      "grad_norm": 0.4335869252681732,
      "learning_rate": 2.687650448610402e-05,
      "loss": 0.0037,
      "step": 31700
    },
    {
      "epoch": 2.3130789991976073,
      "grad_norm": 0.08608467131853104,
      "learning_rate": 2.6869210008023927e-05,
      "loss": 0.0045,
      "step": 31710
    },
    {
      "epoch": 2.313808447005617,
      "grad_norm": 0.32081565260887146,
      "learning_rate": 2.686191552994383e-05,
      "loss": 0.0044,
      "step": 31720
    },
    {
      "epoch": 2.314537894813626,
      "grad_norm": 0.0575665645301342,
      "learning_rate": 2.6854621051863742e-05,
      "loss": 0.0026,
      "step": 31730
    },
    {
      "epoch": 2.3152673426216355,
      "grad_norm": 0.08727710694074631,
      "learning_rate": 2.684732657378365e-05,
      "loss": 0.0042,
      "step": 31740
    },
    {
      "epoch": 2.3159967904296446,
      "grad_norm": 0.4225137233734131,
      "learning_rate": 2.6840032095703554e-05,
      "loss": 0.0049,
      "step": 31750
    },
    {
      "epoch": 2.316726238237654,
      "grad_norm": 0.11610889434814453,
      "learning_rate": 2.683273761762346e-05,
      "loss": 0.0039,
      "step": 31760
    },
    {
      "epoch": 2.3174556860456637,
      "grad_norm": 0.08720499277114868,
      "learning_rate": 2.6825443139543365e-05,
      "loss": 0.0043,
      "step": 31770
    },
    {
      "epoch": 2.3181851338536728,
      "grad_norm": 0.23036926984786987,
      "learning_rate": 2.6818148661463273e-05,
      "loss": 0.0035,
      "step": 31780
    },
    {
      "epoch": 2.3189145816616823,
      "grad_norm": 0.34475943446159363,
      "learning_rate": 2.6810854183383184e-05,
      "loss": 0.0036,
      "step": 31790
    },
    {
      "epoch": 2.3196440294696914,
      "grad_norm": 0.12301349639892578,
      "learning_rate": 2.6803559705303088e-05,
      "loss": 0.0034,
      "step": 31800
    },
    {
      "epoch": 2.320373477277701,
      "grad_norm": 0.058239638805389404,
      "learning_rate": 2.6796265227222996e-05,
      "loss": 0.0029,
      "step": 31810
    },
    {
      "epoch": 2.32110292508571,
      "grad_norm": 0.23014388978481293,
      "learning_rate": 2.67889707491429e-05,
      "loss": 0.0038,
      "step": 31820
    },
    {
      "epoch": 2.3218323728937196,
      "grad_norm": 0.07117262482643127,
      "learning_rate": 2.6781676271062804e-05,
      "loss": 0.003,
      "step": 31830
    },
    {
      "epoch": 2.3225618207017287,
      "grad_norm": 0.09743870794773102,
      "learning_rate": 2.677438179298271e-05,
      "loss": 0.0039,
      "step": 31840
    },
    {
      "epoch": 2.323291268509738,
      "grad_norm": 0.2877333164215088,
      "learning_rate": 2.6767087314902622e-05,
      "loss": 0.0046,
      "step": 31850
    },
    {
      "epoch": 2.3240207163177473,
      "grad_norm": 0.3526868224143982,
      "learning_rate": 2.675979283682253e-05,
      "loss": 0.0042,
      "step": 31860
    },
    {
      "epoch": 2.324750164125757,
      "grad_norm": 0.430084228515625,
      "learning_rate": 2.6752498358742434e-05,
      "loss": 0.0028,
      "step": 31870
    },
    {
      "epoch": 2.325479611933766,
      "grad_norm": 0.20153634250164032,
      "learning_rate": 2.6745203880662338e-05,
      "loss": 0.0052,
      "step": 31880
    },
    {
      "epoch": 2.3262090597417755,
      "grad_norm": 0.37652552127838135,
      "learning_rate": 2.6737909402582246e-05,
      "loss": 0.0033,
      "step": 31890
    },
    {
      "epoch": 2.3269385075497846,
      "grad_norm": 0.08721397072076797,
      "learning_rate": 2.673061492450215e-05,
      "loss": 0.0036,
      "step": 31900
    },
    {
      "epoch": 2.327667955357794,
      "grad_norm": 0.17250573635101318,
      "learning_rate": 2.672332044642206e-05,
      "loss": 0.0032,
      "step": 31910
    },
    {
      "epoch": 2.3283974031658037,
      "grad_norm": 0.1645490825176239,
      "learning_rate": 2.6716025968341968e-05,
      "loss": 0.0044,
      "step": 31920
    },
    {
      "epoch": 2.329126850973813,
      "grad_norm": 0.030297115445137024,
      "learning_rate": 2.6708731490261872e-05,
      "loss": 0.0029,
      "step": 31930
    },
    {
      "epoch": 2.3298562987818223,
      "grad_norm": 0.6688588857650757,
      "learning_rate": 2.670143701218178e-05,
      "loss": 0.0042,
      "step": 31940
    },
    {
      "epoch": 2.3305857465898314,
      "grad_norm": 0.10767756402492523,
      "learning_rate": 2.6694142534101684e-05,
      "loss": 0.0042,
      "step": 31950
    },
    {
      "epoch": 2.331315194397841,
      "grad_norm": 0.08651814609766006,
      "learning_rate": 2.668684805602159e-05,
      "loss": 0.005,
      "step": 31960
    },
    {
      "epoch": 2.33204464220585,
      "grad_norm": 0.05974946171045303,
      "learning_rate": 2.6679553577941502e-05,
      "loss": 0.0041,
      "step": 31970
    },
    {
      "epoch": 2.3327740900138596,
      "grad_norm": 0.6246164441108704,
      "learning_rate": 2.6672259099861407e-05,
      "loss": 0.0037,
      "step": 31980
    },
    {
      "epoch": 2.3335035378218687,
      "grad_norm": 0.21778422594070435,
      "learning_rate": 2.6664964621781314e-05,
      "loss": 0.0037,
      "step": 31990
    },
    {
      "epoch": 2.3342329856298782,
      "grad_norm": 0.11473529785871506,
      "learning_rate": 2.665767014370122e-05,
      "loss": 0.0038,
      "step": 32000
    },
    {
      "epoch": 2.3349624334378873,
      "grad_norm": 0.31258583068847656,
      "learning_rate": 2.6650375665621126e-05,
      "loss": 0.0051,
      "step": 32010
    },
    {
      "epoch": 2.335691881245897,
      "grad_norm": 0.26614564657211304,
      "learning_rate": 2.664308118754103e-05,
      "loss": 0.0049,
      "step": 32020
    },
    {
      "epoch": 2.3364213290539064,
      "grad_norm": 0.39760953187942505,
      "learning_rate": 2.663578670946094e-05,
      "loss": 0.0053,
      "step": 32030
    },
    {
      "epoch": 2.3371507768619155,
      "grad_norm": 0.172036275267601,
      "learning_rate": 2.662849223138085e-05,
      "loss": 0.0044,
      "step": 32040
    },
    {
      "epoch": 2.3378802246699246,
      "grad_norm": 0.11511052399873734,
      "learning_rate": 2.6621197753300753e-05,
      "loss": 0.0034,
      "step": 32050
    },
    {
      "epoch": 2.338609672477934,
      "grad_norm": 0.17366738617420197,
      "learning_rate": 2.661390327522066e-05,
      "loss": 0.0028,
      "step": 32060
    },
    {
      "epoch": 2.3393391202859437,
      "grad_norm": 0.09372799098491669,
      "learning_rate": 2.6606608797140564e-05,
      "loss": 0.0045,
      "step": 32070
    },
    {
      "epoch": 2.340068568093953,
      "grad_norm": 0.2301117479801178,
      "learning_rate": 2.659931431906047e-05,
      "loss": 0.0038,
      "step": 32080
    },
    {
      "epoch": 2.3407980159019623,
      "grad_norm": 0.11548182368278503,
      "learning_rate": 2.6592019840980383e-05,
      "loss": 0.0031,
      "step": 32090
    },
    {
      "epoch": 2.3415274637099714,
      "grad_norm": 0.08736328035593033,
      "learning_rate": 2.6584725362900287e-05,
      "loss": 0.0042,
      "step": 32100
    },
    {
      "epoch": 2.342256911517981,
      "grad_norm": 0.09911453723907471,
      "learning_rate": 2.657743088482019e-05,
      "loss": 0.0031,
      "step": 32110
    },
    {
      "epoch": 2.34298635932599,
      "grad_norm": 0.2886136472225189,
      "learning_rate": 2.65701364067401e-05,
      "loss": 0.0034,
      "step": 32120
    },
    {
      "epoch": 2.3437158071339996,
      "grad_norm": 0.143654927611351,
      "learning_rate": 2.6562841928660003e-05,
      "loss": 0.0029,
      "step": 32130
    },
    {
      "epoch": 2.3444452549420087,
      "grad_norm": 0.2591693699359894,
      "learning_rate": 2.655554745057991e-05,
      "loss": 0.0031,
      "step": 32140
    },
    {
      "epoch": 2.3451747027500183,
      "grad_norm": 0.11537115275859833,
      "learning_rate": 2.654825297249982e-05,
      "loss": 0.0032,
      "step": 32150
    },
    {
      "epoch": 2.3459041505580274,
      "grad_norm": 0.05793391168117523,
      "learning_rate": 2.6540958494419725e-05,
      "loss": 0.0042,
      "step": 32160
    },
    {
      "epoch": 2.346633598366037,
      "grad_norm": 0.2301153987646103,
      "learning_rate": 2.6533664016339633e-05,
      "loss": 0.005,
      "step": 32170
    },
    {
      "epoch": 2.3473630461740465,
      "grad_norm": 0.08697507530450821,
      "learning_rate": 2.6526369538259537e-05,
      "loss": 0.0056,
      "step": 32180
    },
    {
      "epoch": 2.3480924939820556,
      "grad_norm": 0.11493146419525146,
      "learning_rate": 2.6519075060179444e-05,
      "loss": 0.0043,
      "step": 32190
    },
    {
      "epoch": 2.348821941790065,
      "grad_norm": 0.2910679280757904,
      "learning_rate": 2.6511780582099355e-05,
      "loss": 0.0025,
      "step": 32200
    },
    {
      "epoch": 2.349551389598074,
      "grad_norm": 0.13073888421058655,
      "learning_rate": 2.650448610401926e-05,
      "loss": 0.0043,
      "step": 32210
    },
    {
      "epoch": 2.3502808374060837,
      "grad_norm": 0.1444985568523407,
      "learning_rate": 2.6497191625939167e-05,
      "loss": 0.003,
      "step": 32220
    },
    {
      "epoch": 2.351010285214093,
      "grad_norm": 0.449012815952301,
      "learning_rate": 2.648989714785907e-05,
      "loss": 0.0046,
      "step": 32230
    },
    {
      "epoch": 2.3517397330221024,
      "grad_norm": 0.058450713753700256,
      "learning_rate": 2.648260266977898e-05,
      "loss": 0.0043,
      "step": 32240
    },
    {
      "epoch": 2.3524691808301115,
      "grad_norm": 0.0583108514547348,
      "learning_rate": 2.6475308191698883e-05,
      "loss": 0.0032,
      "step": 32250
    },
    {
      "epoch": 2.353198628638121,
      "grad_norm": 0.37734416127204895,
      "learning_rate": 2.6468013713618794e-05,
      "loss": 0.0029,
      "step": 32260
    },
    {
      "epoch": 2.35392807644613,
      "grad_norm": 0.32241398096084595,
      "learning_rate": 2.64607192355387e-05,
      "loss": 0.0032,
      "step": 32270
    },
    {
      "epoch": 2.3546575242541397,
      "grad_norm": 0.06302321702241898,
      "learning_rate": 2.6453424757458605e-05,
      "loss": 0.0043,
      "step": 32280
    },
    {
      "epoch": 2.355386972062149,
      "grad_norm": 0.2297213226556778,
      "learning_rate": 2.6446130279378513e-05,
      "loss": 0.0039,
      "step": 32290
    },
    {
      "epoch": 2.3561164198701583,
      "grad_norm": 0.1728823184967041,
      "learning_rate": 2.6438835801298417e-05,
      "loss": 0.003,
      "step": 32300
    },
    {
      "epoch": 2.3568458676781674,
      "grad_norm": 0.2887577414512634,
      "learning_rate": 2.643154132321832e-05,
      "loss": 0.0043,
      "step": 32310
    },
    {
      "epoch": 2.357575315486177,
      "grad_norm": 0.3463764786720276,
      "learning_rate": 2.6424246845138236e-05,
      "loss": 0.0046,
      "step": 32320
    },
    {
      "epoch": 2.3583047632941865,
      "grad_norm": 0.09750580787658691,
      "learning_rate": 2.641695236705814e-05,
      "loss": 0.0045,
      "step": 32330
    },
    {
      "epoch": 2.3590342111021956,
      "grad_norm": 0.23054075241088867,
      "learning_rate": 2.6409657888978044e-05,
      "loss": 0.0037,
      "step": 32340
    },
    {
      "epoch": 2.359763658910205,
      "grad_norm": 0.14457467198371887,
      "learning_rate": 2.640236341089795e-05,
      "loss": 0.0051,
      "step": 32350
    },
    {
      "epoch": 2.360493106718214,
      "grad_norm": 0.5474276542663574,
      "learning_rate": 2.6395068932817856e-05,
      "loss": 0.005,
      "step": 32360
    },
    {
      "epoch": 2.3612225545262238,
      "grad_norm": 0.13457387685775757,
      "learning_rate": 2.6387774454737763e-05,
      "loss": 0.0035,
      "step": 32370
    },
    {
      "epoch": 2.361952002334233,
      "grad_norm": 0.48933902382850647,
      "learning_rate": 2.6380479976657674e-05,
      "loss": 0.0041,
      "step": 32380
    },
    {
      "epoch": 2.3626814501422424,
      "grad_norm": 0.25944873690605164,
      "learning_rate": 2.6373185498577578e-05,
      "loss": 0.0043,
      "step": 32390
    },
    {
      "epoch": 2.3634108979502515,
      "grad_norm": 0.4587101936340332,
      "learning_rate": 2.6365891020497486e-05,
      "loss": 0.0037,
      "step": 32400
    },
    {
      "epoch": 2.364140345758261,
      "grad_norm": 0.20097549259662628,
      "learning_rate": 2.635859654241739e-05,
      "loss": 0.0039,
      "step": 32410
    },
    {
      "epoch": 2.36486979356627,
      "grad_norm": 0.15384294092655182,
      "learning_rate": 2.6351302064337297e-05,
      "loss": 0.0044,
      "step": 32420
    },
    {
      "epoch": 2.3655992413742797,
      "grad_norm": 0.33152517676353455,
      "learning_rate": 2.63440075862572e-05,
      "loss": 0.0028,
      "step": 32430
    },
    {
      "epoch": 2.3663286891822892,
      "grad_norm": 0.033403489738702774,
      "learning_rate": 2.6336713108177112e-05,
      "loss": 0.0028,
      "step": 32440
    },
    {
      "epoch": 2.3670581369902983,
      "grad_norm": 0.11554977297782898,
      "learning_rate": 2.632941863009702e-05,
      "loss": 0.0055,
      "step": 32450
    },
    {
      "epoch": 2.367787584798308,
      "grad_norm": 0.5754165053367615,
      "learning_rate": 2.6322124152016924e-05,
      "loss": 0.0048,
      "step": 32460
    },
    {
      "epoch": 2.368517032606317,
      "grad_norm": 0.2882848381996155,
      "learning_rate": 2.631482967393683e-05,
      "loss": 0.0036,
      "step": 32470
    },
    {
      "epoch": 2.3692464804143265,
      "grad_norm": 0.11640691757202148,
      "learning_rate": 2.6307535195856736e-05,
      "loss": 0.0025,
      "step": 32480
    },
    {
      "epoch": 2.3699759282223356,
      "grad_norm": 0.3170035481452942,
      "learning_rate": 2.6300240717776643e-05,
      "loss": 0.0034,
      "step": 32490
    },
    {
      "epoch": 2.370705376030345,
      "grad_norm": 0.1720535010099411,
      "learning_rate": 2.6292946239696554e-05,
      "loss": 0.0023,
      "step": 32500
    },
    {
      "epoch": 2.3714348238383542,
      "grad_norm": 0.34540390968322754,
      "learning_rate": 2.6285651761616458e-05,
      "loss": 0.004,
      "step": 32510
    },
    {
      "epoch": 2.372164271646364,
      "grad_norm": 0.25884583592414856,
      "learning_rate": 2.6278357283536366e-05,
      "loss": 0.0036,
      "step": 32520
    },
    {
      "epoch": 2.372893719454373,
      "grad_norm": 0.20233899354934692,
      "learning_rate": 2.627106280545627e-05,
      "loss": 0.0048,
      "step": 32530
    },
    {
      "epoch": 2.3736231672623824,
      "grad_norm": 0.010209716856479645,
      "learning_rate": 2.6263768327376177e-05,
      "loss": 0.0024,
      "step": 32540
    },
    {
      "epoch": 2.3743526150703915,
      "grad_norm": 0.2670191824436188,
      "learning_rate": 2.625647384929608e-05,
      "loss": 0.0049,
      "step": 32550
    },
    {
      "epoch": 2.375082062878401,
      "grad_norm": 0.17255480587482452,
      "learning_rate": 2.6249179371215993e-05,
      "loss": 0.0046,
      "step": 32560
    },
    {
      "epoch": 2.37581151068641,
      "grad_norm": 0.5548770427703857,
      "learning_rate": 2.62418848931359e-05,
      "loss": 0.0047,
      "step": 32570
    },
    {
      "epoch": 2.3765409584944197,
      "grad_norm": 0.057801589369773865,
      "learning_rate": 2.6234590415055804e-05,
      "loss": 0.004,
      "step": 32580
    },
    {
      "epoch": 2.3772704063024293,
      "grad_norm": 0.6896505355834961,
      "learning_rate": 2.622729593697571e-05,
      "loss": 0.0047,
      "step": 32590
    },
    {
      "epoch": 2.3779998541104383,
      "grad_norm": 0.2586390972137451,
      "learning_rate": 2.6220001458895616e-05,
      "loss": 0.0036,
      "step": 32600
    },
    {
      "epoch": 2.378729301918448,
      "grad_norm": 0.007589659187942743,
      "learning_rate": 2.621270698081552e-05,
      "loss": 0.0034,
      "step": 32610
    },
    {
      "epoch": 2.379458749726457,
      "grad_norm": 0.2022995501756668,
      "learning_rate": 2.620541250273543e-05,
      "loss": 0.0032,
      "step": 32620
    },
    {
      "epoch": 2.3801881975344665,
      "grad_norm": 0.08729279786348343,
      "learning_rate": 2.619811802465534e-05,
      "loss": 0.0041,
      "step": 32630
    },
    {
      "epoch": 2.3809176453424756,
      "grad_norm": 0.00888009276241064,
      "learning_rate": 2.6190823546575243e-05,
      "loss": 0.003,
      "step": 32640
    },
    {
      "epoch": 2.381647093150485,
      "grad_norm": 0.11497880518436432,
      "learning_rate": 2.618352906849515e-05,
      "loss": 0.005,
      "step": 32650
    },
    {
      "epoch": 2.3823765409584943,
      "grad_norm": 0.08675645291805267,
      "learning_rate": 2.6176234590415054e-05,
      "loss": 0.0047,
      "step": 32660
    },
    {
      "epoch": 2.383105988766504,
      "grad_norm": 0.2297247350215912,
      "learning_rate": 2.6168940112334965e-05,
      "loss": 0.004,
      "step": 32670
    },
    {
      "epoch": 2.383835436574513,
      "grad_norm": 0.08733002096414566,
      "learning_rate": 2.6161645634254873e-05,
      "loss": 0.0057,
      "step": 32680
    },
    {
      "epoch": 2.3845648843825225,
      "grad_norm": 0.08665992319583893,
      "learning_rate": 2.6154351156174777e-05,
      "loss": 0.0034,
      "step": 32690
    },
    {
      "epoch": 2.385294332190532,
      "grad_norm": 0.1723787784576416,
      "learning_rate": 2.6147056678094684e-05,
      "loss": 0.0054,
      "step": 32700
    },
    {
      "epoch": 2.386023779998541,
      "grad_norm": 0.031028179451823235,
      "learning_rate": 2.613976220001459e-05,
      "loss": 0.0038,
      "step": 32710
    },
    {
      "epoch": 2.38675322780655,
      "grad_norm": 0.3167301416397095,
      "learning_rate": 2.6132467721934496e-05,
      "loss": 0.0034,
      "step": 32720
    },
    {
      "epoch": 2.3874826756145597,
      "grad_norm": 0.28768977522850037,
      "learning_rate": 2.6125173243854407e-05,
      "loss": 0.0045,
      "step": 32730
    },
    {
      "epoch": 2.3882121234225693,
      "grad_norm": 0.0824870690703392,
      "learning_rate": 2.611787876577431e-05,
      "loss": 0.0039,
      "step": 32740
    },
    {
      "epoch": 2.3889415712305784,
      "grad_norm": 0.1440601497888565,
      "learning_rate": 2.611058428769422e-05,
      "loss": 0.0046,
      "step": 32750
    },
    {
      "epoch": 2.389671019038588,
      "grad_norm": 0.20175234973430634,
      "learning_rate": 2.6103289809614123e-05,
      "loss": 0.0035,
      "step": 32760
    },
    {
      "epoch": 2.390400466846597,
      "grad_norm": 0.37321633100509644,
      "learning_rate": 2.609599533153403e-05,
      "loss": 0.0048,
      "step": 32770
    },
    {
      "epoch": 2.3911299146546066,
      "grad_norm": 0.31579241156578064,
      "learning_rate": 2.6088700853453934e-05,
      "loss": 0.0036,
      "step": 32780
    },
    {
      "epoch": 2.3918593624626157,
      "grad_norm": 0.05765710398554802,
      "learning_rate": 2.6081406375373845e-05,
      "loss": 0.0045,
      "step": 32790
    },
    {
      "epoch": 2.392588810270625,
      "grad_norm": 0.3453536331653595,
      "learning_rate": 2.6074111897293753e-05,
      "loss": 0.0044,
      "step": 32800
    },
    {
      "epoch": 2.3933182580786343,
      "grad_norm": 0.087152399122715,
      "learning_rate": 2.6066817419213657e-05,
      "loss": 0.0037,
      "step": 32810
    },
    {
      "epoch": 2.394047705886644,
      "grad_norm": 0.14400626718997955,
      "learning_rate": 2.605952294113356e-05,
      "loss": 0.0055,
      "step": 32820
    },
    {
      "epoch": 2.394777153694653,
      "grad_norm": 0.34458574652671814,
      "learning_rate": 2.605222846305347e-05,
      "loss": 0.0044,
      "step": 32830
    },
    {
      "epoch": 2.3955066015026625,
      "grad_norm": 0.007272602058947086,
      "learning_rate": 2.6044933984973373e-05,
      "loss": 0.0037,
      "step": 32840
    },
    {
      "epoch": 2.396236049310672,
      "grad_norm": 0.17861288785934448,
      "learning_rate": 2.6037639506893284e-05,
      "loss": 0.004,
      "step": 32850
    },
    {
      "epoch": 2.396965497118681,
      "grad_norm": 0.18518750369548798,
      "learning_rate": 2.603034502881319e-05,
      "loss": 0.0049,
      "step": 32860
    },
    {
      "epoch": 2.3976949449266907,
      "grad_norm": 0.5182965993881226,
      "learning_rate": 2.6023050550733095e-05,
      "loss": 0.0065,
      "step": 32870
    },
    {
      "epoch": 2.3984243927346998,
      "grad_norm": 0.08641699701547623,
      "learning_rate": 2.6015756072653003e-05,
      "loss": 0.0051,
      "step": 32880
    },
    {
      "epoch": 2.3991538405427093,
      "grad_norm": 0.08752138912677765,
      "learning_rate": 2.6008461594572907e-05,
      "loss": 0.0038,
      "step": 32890
    },
    {
      "epoch": 2.3998832883507184,
      "grad_norm": 0.3739613890647888,
      "learning_rate": 2.6001167116492815e-05,
      "loss": 0.0029,
      "step": 32900
    },
    {
      "epoch": 2.400612736158728,
      "grad_norm": 0.11677657812833786,
      "learning_rate": 2.5993872638412726e-05,
      "loss": 0.0035,
      "step": 32910
    },
    {
      "epoch": 2.401342183966737,
      "grad_norm": 0.1448701173067093,
      "learning_rate": 2.598657816033263e-05,
      "loss": 0.0031,
      "step": 32920
    },
    {
      "epoch": 2.4020716317747466,
      "grad_norm": 0.518295407295227,
      "learning_rate": 2.5979283682252537e-05,
      "loss": 0.004,
      "step": 32930
    },
    {
      "epoch": 2.4028010795827557,
      "grad_norm": 0.1897246390581131,
      "learning_rate": 2.597198920417244e-05,
      "loss": 0.0032,
      "step": 32940
    },
    {
      "epoch": 2.4035305273907652,
      "grad_norm": 0.03834543749690056,
      "learning_rate": 2.596469472609235e-05,
      "loss": 0.005,
      "step": 32950
    },
    {
      "epoch": 2.4042599751987748,
      "grad_norm": 0.08636945486068726,
      "learning_rate": 2.5957400248012253e-05,
      "loss": 0.0066,
      "step": 32960
    },
    {
      "epoch": 2.404989423006784,
      "grad_norm": 0.1152353510260582,
      "learning_rate": 2.5950105769932164e-05,
      "loss": 0.0044,
      "step": 32970
    },
    {
      "epoch": 2.405718870814793,
      "grad_norm": 0.31733614206314087,
      "learning_rate": 2.594281129185207e-05,
      "loss": 0.0042,
      "step": 32980
    },
    {
      "epoch": 2.4064483186228025,
      "grad_norm": 0.6330153346061707,
      "learning_rate": 2.5935516813771976e-05,
      "loss": 0.0025,
      "step": 32990
    },
    {
      "epoch": 2.407177766430812,
      "grad_norm": 0.1731797605752945,
      "learning_rate": 2.5928222335691883e-05,
      "loss": 0.003,
      "step": 33000
    },
    {
      "epoch": 2.407907214238821,
      "grad_norm": 0.08671941608190536,
      "learning_rate": 2.5920927857611787e-05,
      "loss": 0.0035,
      "step": 33010
    },
    {
      "epoch": 2.4086366620468307,
      "grad_norm": 0.315865695476532,
      "learning_rate": 2.5913633379531695e-05,
      "loss": 0.0025,
      "step": 33020
    },
    {
      "epoch": 2.40936610985484,
      "grad_norm": 0.041057709604501724,
      "learning_rate": 2.5906338901451606e-05,
      "loss": 0.0039,
      "step": 33030
    },
    {
      "epoch": 2.4100955576628493,
      "grad_norm": 0.9125465154647827,
      "learning_rate": 2.589904442337151e-05,
      "loss": 0.0052,
      "step": 33040
    },
    {
      "epoch": 2.4108250054708584,
      "grad_norm": 0.029705842956900597,
      "learning_rate": 2.5891749945291417e-05,
      "loss": 0.0052,
      "step": 33050
    },
    {
      "epoch": 2.411554453278868,
      "grad_norm": 0.34434717893600464,
      "learning_rate": 2.588445546721132e-05,
      "loss": 0.0031,
      "step": 33060
    },
    {
      "epoch": 2.412283901086877,
      "grad_norm": 0.2590595483779907,
      "learning_rate": 2.5877160989131226e-05,
      "loss": 0.0037,
      "step": 33070
    },
    {
      "epoch": 2.4130133488948866,
      "grad_norm": 0.057536158710718155,
      "learning_rate": 2.5869866511051133e-05,
      "loss": 0.0029,
      "step": 33080
    },
    {
      "epoch": 2.4137427967028957,
      "grad_norm": 0.2420562505722046,
      "learning_rate": 2.5862572032971044e-05,
      "loss": 0.0034,
      "step": 33090
    },
    {
      "epoch": 2.4144722445109053,
      "grad_norm": 0.4154306948184967,
      "learning_rate": 2.585527755489095e-05,
      "loss": 0.0034,
      "step": 33100
    },
    {
      "epoch": 2.415201692318915,
      "grad_norm": 0.29035258293151855,
      "learning_rate": 2.5847983076810856e-05,
      "loss": 0.0042,
      "step": 33110
    },
    {
      "epoch": 2.415931140126924,
      "grad_norm": 0.23612771928310394,
      "learning_rate": 2.584068859873076e-05,
      "loss": 0.004,
      "step": 33120
    },
    {
      "epoch": 2.4166605879349334,
      "grad_norm": 0.20121516287326813,
      "learning_rate": 2.5833394120650668e-05,
      "loss": 0.0034,
      "step": 33130
    },
    {
      "epoch": 2.4173900357429425,
      "grad_norm": 0.27400580048561096,
      "learning_rate": 2.582609964257057e-05,
      "loss": 0.0039,
      "step": 33140
    },
    {
      "epoch": 2.418119483550952,
      "grad_norm": 0.1707931011915207,
      "learning_rate": 2.5818805164490483e-05,
      "loss": 0.0043,
      "step": 33150
    },
    {
      "epoch": 2.418848931358961,
      "grad_norm": 0.029184790328145027,
      "learning_rate": 2.581151068641039e-05,
      "loss": 0.0039,
      "step": 33160
    },
    {
      "epoch": 2.4195783791669707,
      "grad_norm": 0.22917763888835907,
      "learning_rate": 2.5804216208330294e-05,
      "loss": 0.0051,
      "step": 33170
    },
    {
      "epoch": 2.42030782697498,
      "grad_norm": 0.311815470457077,
      "learning_rate": 2.5796921730250202e-05,
      "loss": 0.004,
      "step": 33180
    },
    {
      "epoch": 2.4210372747829894,
      "grad_norm": 0.08955725282430649,
      "learning_rate": 2.5789627252170106e-05,
      "loss": 0.0038,
      "step": 33190
    },
    {
      "epoch": 2.4217667225909985,
      "grad_norm": 0.0310315303504467,
      "learning_rate": 2.5782332774090017e-05,
      "loss": 0.0042,
      "step": 33200
    },
    {
      "epoch": 2.422496170399008,
      "grad_norm": 0.1437463015317917,
      "learning_rate": 2.5775038296009924e-05,
      "loss": 0.0038,
      "step": 33210
    },
    {
      "epoch": 2.423225618207017,
      "grad_norm": 0.02977973036468029,
      "learning_rate": 2.576774381792983e-05,
      "loss": 0.0033,
      "step": 33220
    },
    {
      "epoch": 2.4239550660150266,
      "grad_norm": 0.009189545176923275,
      "learning_rate": 2.5760449339849736e-05,
      "loss": 0.0049,
      "step": 33230
    },
    {
      "epoch": 2.4246845138230357,
      "grad_norm": 0.1722036451101303,
      "learning_rate": 2.575315486176964e-05,
      "loss": 0.0038,
      "step": 33240
    },
    {
      "epoch": 2.4254139616310453,
      "grad_norm": 0.2871185541152954,
      "learning_rate": 2.5745860383689548e-05,
      "loss": 0.0031,
      "step": 33250
    },
    {
      "epoch": 2.426143409439055,
      "grad_norm": 0.2599850296974182,
      "learning_rate": 2.573856590560946e-05,
      "loss": 0.0037,
      "step": 33260
    },
    {
      "epoch": 2.426872857247064,
      "grad_norm": 0.25263142585754395,
      "learning_rate": 2.5731271427529363e-05,
      "loss": 0.0032,
      "step": 33270
    },
    {
      "epoch": 2.4276023050550735,
      "grad_norm": 0.20711052417755127,
      "learning_rate": 2.572397694944927e-05,
      "loss": 0.005,
      "step": 33280
    },
    {
      "epoch": 2.4283317528630826,
      "grad_norm": 0.30510321259498596,
      "learning_rate": 2.5716682471369174e-05,
      "loss": 0.005,
      "step": 33290
    },
    {
      "epoch": 2.429061200671092,
      "grad_norm": 0.012873100116848946,
      "learning_rate": 2.570938799328908e-05,
      "loss": 0.003,
      "step": 33300
    },
    {
      "epoch": 2.429790648479101,
      "grad_norm": 0.3163989782333374,
      "learning_rate": 2.5702093515208986e-05,
      "loss": 0.0037,
      "step": 33310
    },
    {
      "epoch": 2.4305200962871107,
      "grad_norm": 0.20153386890888214,
      "learning_rate": 2.5694799037128897e-05,
      "loss": 0.0042,
      "step": 33320
    },
    {
      "epoch": 2.43124954409512,
      "grad_norm": 0.30301040410995483,
      "learning_rate": 2.56875045590488e-05,
      "loss": 0.0033,
      "step": 33330
    },
    {
      "epoch": 2.4319789919031294,
      "grad_norm": 0.16751155257225037,
      "learning_rate": 2.568021008096871e-05,
      "loss": 0.0026,
      "step": 33340
    },
    {
      "epoch": 2.4327084397111385,
      "grad_norm": 0.07872242480516434,
      "learning_rate": 2.5672915602888613e-05,
      "loss": 0.0027,
      "step": 33350
    },
    {
      "epoch": 2.433437887519148,
      "grad_norm": 0.030421683564782143,
      "learning_rate": 2.566562112480852e-05,
      "loss": 0.0043,
      "step": 33360
    },
    {
      "epoch": 2.4341673353271576,
      "grad_norm": 0.11511930078268051,
      "learning_rate": 2.5658326646728425e-05,
      "loss": 0.004,
      "step": 33370
    },
    {
      "epoch": 2.4348967831351667,
      "grad_norm": 0.08756432682275772,
      "learning_rate": 2.5651032168648335e-05,
      "loss": 0.0041,
      "step": 33380
    },
    {
      "epoch": 2.435626230943176,
      "grad_norm": 0.4360087811946869,
      "learning_rate": 2.5643737690568243e-05,
      "loss": 0.0038,
      "step": 33390
    },
    {
      "epoch": 2.4363556787511853,
      "grad_norm": 0.1724858283996582,
      "learning_rate": 2.5636443212488147e-05,
      "loss": 0.0043,
      "step": 33400
    },
    {
      "epoch": 2.437085126559195,
      "grad_norm": 0.19533953070640564,
      "learning_rate": 2.5629148734408055e-05,
      "loss": 0.0038,
      "step": 33410
    },
    {
      "epoch": 2.437814574367204,
      "grad_norm": 0.5178852081298828,
      "learning_rate": 2.562185425632796e-05,
      "loss": 0.0022,
      "step": 33420
    },
    {
      "epoch": 2.4385440221752135,
      "grad_norm": 0.14452870190143585,
      "learning_rate": 2.5614559778247866e-05,
      "loss": 0.0043,
      "step": 33430
    },
    {
      "epoch": 2.4392734699832226,
      "grad_norm": 0.2648766040802002,
      "learning_rate": 2.5607265300167777e-05,
      "loss": 0.0053,
      "step": 33440
    },
    {
      "epoch": 2.440002917791232,
      "grad_norm": 0.28822362422943115,
      "learning_rate": 2.559997082208768e-05,
      "loss": 0.0037,
      "step": 33450
    },
    {
      "epoch": 2.4407323655992412,
      "grad_norm": 0.23113244771957397,
      "learning_rate": 2.559267634400759e-05,
      "loss": 0.0039,
      "step": 33460
    },
    {
      "epoch": 2.4414618134072508,
      "grad_norm": 0.03181342035531998,
      "learning_rate": 2.5585381865927493e-05,
      "loss": 0.0045,
      "step": 33470
    },
    {
      "epoch": 2.44219126121526,
      "grad_norm": 0.25897839665412903,
      "learning_rate": 2.55780873878474e-05,
      "loss": 0.0043,
      "step": 33480
    },
    {
      "epoch": 2.4429207090232694,
      "grad_norm": 0.3739495277404785,
      "learning_rate": 2.5570792909767305e-05,
      "loss": 0.005,
      "step": 33490
    },
    {
      "epoch": 2.4436501568312785,
      "grad_norm": 0.37251532077789307,
      "learning_rate": 2.5563498431687216e-05,
      "loss": 0.0055,
      "step": 33500
    },
    {
      "epoch": 2.444379604639288,
      "grad_norm": 0.29017868638038635,
      "learning_rate": 2.5556203953607123e-05,
      "loss": 0.0052,
      "step": 33510
    },
    {
      "epoch": 2.4451090524472976,
      "grad_norm": 0.1737610101699829,
      "learning_rate": 2.5548909475527027e-05,
      "loss": 0.004,
      "step": 33520
    },
    {
      "epoch": 2.4458385002553067,
      "grad_norm": 0.007158985361456871,
      "learning_rate": 2.5541614997446935e-05,
      "loss": 0.0044,
      "step": 33530
    },
    {
      "epoch": 2.4465679480633162,
      "grad_norm": 0.20142701268196106,
      "learning_rate": 2.553432051936684e-05,
      "loss": 0.0042,
      "step": 33540
    },
    {
      "epoch": 2.4472973958713253,
      "grad_norm": 0.05822352319955826,
      "learning_rate": 2.5527026041286743e-05,
      "loss": 0.0045,
      "step": 33550
    },
    {
      "epoch": 2.448026843679335,
      "grad_norm": 0.23084591329097748,
      "learning_rate": 2.5519731563206657e-05,
      "loss": 0.0036,
      "step": 33560
    },
    {
      "epoch": 2.448756291487344,
      "grad_norm": 0.3737172782421112,
      "learning_rate": 2.551243708512656e-05,
      "loss": 0.0038,
      "step": 33570
    },
    {
      "epoch": 2.4494857392953535,
      "grad_norm": 0.37454283237457275,
      "learning_rate": 2.5505142607046466e-05,
      "loss": 0.0032,
      "step": 33580
    },
    {
      "epoch": 2.4502151871033626,
      "grad_norm": 0.1683938056230545,
      "learning_rate": 2.5497848128966373e-05,
      "loss": 0.0046,
      "step": 33590
    },
    {
      "epoch": 2.450944634911372,
      "grad_norm": 0.1734393686056137,
      "learning_rate": 2.5490553650886277e-05,
      "loss": 0.003,
      "step": 33600
    },
    {
      "epoch": 2.4516740827193813,
      "grad_norm": 0.03150384500622749,
      "learning_rate": 2.5483259172806185e-05,
      "loss": 0.0044,
      "step": 33610
    },
    {
      "epoch": 2.452403530527391,
      "grad_norm": 0.0866350531578064,
      "learning_rate": 2.5475964694726096e-05,
      "loss": 0.0037,
      "step": 33620
    },
    {
      "epoch": 2.4531329783354003,
      "grad_norm": 0.058511726558208466,
      "learning_rate": 2.5468670216646e-05,
      "loss": 0.0034,
      "step": 33630
    },
    {
      "epoch": 2.4538624261434094,
      "grad_norm": 0.08693551272153854,
      "learning_rate": 2.5461375738565908e-05,
      "loss": 0.0024,
      "step": 33640
    },
    {
      "epoch": 2.4545918739514185,
      "grad_norm": 0.11616519838571548,
      "learning_rate": 2.545408126048581e-05,
      "loss": 0.0039,
      "step": 33650
    },
    {
      "epoch": 2.455321321759428,
      "grad_norm": 0.1594879925251007,
      "learning_rate": 2.544678678240572e-05,
      "loss": 0.005,
      "step": 33660
    },
    {
      "epoch": 2.4560507695674376,
      "grad_norm": 0.2993178367614746,
      "learning_rate": 2.543949230432563e-05,
      "loss": 0.0026,
      "step": 33670
    },
    {
      "epoch": 2.4567802173754467,
      "grad_norm": 0.05867975577712059,
      "learning_rate": 2.5432197826245534e-05,
      "loss": 0.0035,
      "step": 33680
    },
    {
      "epoch": 2.4575096651834563,
      "grad_norm": 0.3853279948234558,
      "learning_rate": 2.5424903348165442e-05,
      "loss": 0.0041,
      "step": 33690
    },
    {
      "epoch": 2.4582391129914654,
      "grad_norm": 0.26000872254371643,
      "learning_rate": 2.5417608870085346e-05,
      "loss": 0.0044,
      "step": 33700
    },
    {
      "epoch": 2.458968560799475,
      "grad_norm": 0.030194468796253204,
      "learning_rate": 2.5410314392005253e-05,
      "loss": 0.0029,
      "step": 33710
    },
    {
      "epoch": 2.459698008607484,
      "grad_norm": 0.02983795292675495,
      "learning_rate": 2.5403019913925158e-05,
      "loss": 0.0045,
      "step": 33720
    },
    {
      "epoch": 2.4604274564154935,
      "grad_norm": 0.11576437205076218,
      "learning_rate": 2.539572543584507e-05,
      "loss": 0.0035,
      "step": 33730
    },
    {
      "epoch": 2.4611569042235026,
      "grad_norm": 0.1725846230983734,
      "learning_rate": 2.5388430957764976e-05,
      "loss": 0.0035,
      "step": 33740
    },
    {
      "epoch": 2.461886352031512,
      "grad_norm": 0.3165983557701111,
      "learning_rate": 2.538113647968488e-05,
      "loss": 0.0033,
      "step": 33750
    },
    {
      "epoch": 2.4626157998395213,
      "grad_norm": 0.25929686427116394,
      "learning_rate": 2.5373842001604788e-05,
      "loss": 0.0047,
      "step": 33760
    },
    {
      "epoch": 2.463345247647531,
      "grad_norm": 0.20122593641281128,
      "learning_rate": 2.5366547523524692e-05,
      "loss": 0.0053,
      "step": 33770
    },
    {
      "epoch": 2.4640746954555404,
      "grad_norm": 0.44776588678359985,
      "learning_rate": 2.5359253045444596e-05,
      "loss": 0.0049,
      "step": 33780
    },
    {
      "epoch": 2.4648041432635495,
      "grad_norm": 0.14984898269176483,
      "learning_rate": 2.535195856736451e-05,
      "loss": 0.0047,
      "step": 33790
    },
    {
      "epoch": 2.465533591071559,
      "grad_norm": 0.08765862137079239,
      "learning_rate": 2.5344664089284414e-05,
      "loss": 0.0036,
      "step": 33800
    },
    {
      "epoch": 2.466263038879568,
      "grad_norm": 0.05829519033432007,
      "learning_rate": 2.533736961120432e-05,
      "loss": 0.003,
      "step": 33810
    },
    {
      "epoch": 2.4669924866875776,
      "grad_norm": 0.05807153880596161,
      "learning_rate": 2.5330075133124226e-05,
      "loss": 0.0044,
      "step": 33820
    },
    {
      "epoch": 2.4677219344955867,
      "grad_norm": 0.20074822008609772,
      "learning_rate": 2.532278065504413e-05,
      "loss": 0.003,
      "step": 33830
    },
    {
      "epoch": 2.4684513823035963,
      "grad_norm": 0.3518165647983551,
      "learning_rate": 2.5315486176964038e-05,
      "loss": 0.0039,
      "step": 33840
    },
    {
      "epoch": 2.4691808301116054,
      "grad_norm": 0.23202109336853027,
      "learning_rate": 2.530819169888395e-05,
      "loss": 0.0042,
      "step": 33850
    },
    {
      "epoch": 2.469910277919615,
      "grad_norm": 0.11499252915382385,
      "learning_rate": 2.5300897220803853e-05,
      "loss": 0.0038,
      "step": 33860
    },
    {
      "epoch": 2.470639725727624,
      "grad_norm": 0.08697124570608139,
      "learning_rate": 2.529360274272376e-05,
      "loss": 0.0048,
      "step": 33870
    },
    {
      "epoch": 2.4713691735356336,
      "grad_norm": 0.05959688872098923,
      "learning_rate": 2.5286308264643665e-05,
      "loss": 0.0032,
      "step": 33880
    },
    {
      "epoch": 2.472098621343643,
      "grad_norm": 0.05809759721159935,
      "learning_rate": 2.5279013786563572e-05,
      "loss": 0.0034,
      "step": 33890
    },
    {
      "epoch": 2.472828069151652,
      "grad_norm": 0.030434532091021538,
      "learning_rate": 2.5271719308483476e-05,
      "loss": 0.0042,
      "step": 33900
    },
    {
      "epoch": 2.4735575169596613,
      "grad_norm": 0.1724151223897934,
      "learning_rate": 2.5264424830403387e-05,
      "loss": 0.004,
      "step": 33910
    },
    {
      "epoch": 2.474286964767671,
      "grad_norm": 0.06262775510549545,
      "learning_rate": 2.5257130352323295e-05,
      "loss": 0.0038,
      "step": 33920
    },
    {
      "epoch": 2.4750164125756804,
      "grad_norm": 0.17552302777767181,
      "learning_rate": 2.52498358742432e-05,
      "loss": 0.0046,
      "step": 33930
    },
    {
      "epoch": 2.4757458603836895,
      "grad_norm": 0.6871853470802307,
      "learning_rate": 2.5242541396163106e-05,
      "loss": 0.0039,
      "step": 33940
    },
    {
      "epoch": 2.476475308191699,
      "grad_norm": 0.05876774340867996,
      "learning_rate": 2.523524691808301e-05,
      "loss": 0.0033,
      "step": 33950
    },
    {
      "epoch": 2.477204755999708,
      "grad_norm": 0.033586885780096054,
      "learning_rate": 2.5227952440002918e-05,
      "loss": 0.003,
      "step": 33960
    },
    {
      "epoch": 2.4779342038077177,
      "grad_norm": 0.11535652726888657,
      "learning_rate": 2.522065796192283e-05,
      "loss": 0.0031,
      "step": 33970
    },
    {
      "epoch": 2.4786636516157268,
      "grad_norm": 0.11189189553260803,
      "learning_rate": 2.5213363483842733e-05,
      "loss": 0.0034,
      "step": 33980
    },
    {
      "epoch": 2.4793930994237363,
      "grad_norm": 0.031074661761522293,
      "learning_rate": 2.520606900576264e-05,
      "loss": 0.0032,
      "step": 33990
    },
    {
      "epoch": 2.4801225472317454,
      "grad_norm": 0.28786492347717285,
      "learning_rate": 2.5198774527682545e-05,
      "loss": 0.0036,
      "step": 34000
    },
    {
      "epoch": 2.480851995039755,
      "grad_norm": 0.17201045155525208,
      "learning_rate": 2.5191480049602452e-05,
      "loss": 0.0043,
      "step": 34010
    },
    {
      "epoch": 2.481581442847764,
      "grad_norm": 0.277811199426651,
      "learning_rate": 2.5184185571522356e-05,
      "loss": 0.0037,
      "step": 34020
    },
    {
      "epoch": 2.4823108906557736,
      "grad_norm": 0.030123336240649223,
      "learning_rate": 2.5176891093442267e-05,
      "loss": 0.0022,
      "step": 34030
    },
    {
      "epoch": 2.483040338463783,
      "grad_norm": 0.20479921996593475,
      "learning_rate": 2.5169596615362175e-05,
      "loss": 0.004,
      "step": 34040
    },
    {
      "epoch": 2.4837697862717922,
      "grad_norm": 0.06557180732488632,
      "learning_rate": 2.516230213728208e-05,
      "loss": 0.0052,
      "step": 34050
    },
    {
      "epoch": 2.4844992340798018,
      "grad_norm": 0.17589275538921356,
      "learning_rate": 2.5155007659201983e-05,
      "loss": 0.0036,
      "step": 34060
    },
    {
      "epoch": 2.485228681887811,
      "grad_norm": 0.392863929271698,
      "learning_rate": 2.514771318112189e-05,
      "loss": 0.0042,
      "step": 34070
    },
    {
      "epoch": 2.4859581296958204,
      "grad_norm": 0.2943461537361145,
      "learning_rate": 2.5140418703041795e-05,
      "loss": 0.0026,
      "step": 34080
    },
    {
      "epoch": 2.4866875775038295,
      "grad_norm": 0.20170122385025024,
      "learning_rate": 2.5133124224961706e-05,
      "loss": 0.0039,
      "step": 34090
    },
    {
      "epoch": 2.487417025311839,
      "grad_norm": 0.05801166594028473,
      "learning_rate": 2.5125829746881613e-05,
      "loss": 0.0051,
      "step": 34100
    },
    {
      "epoch": 2.488146473119848,
      "grad_norm": 0.05793805792927742,
      "learning_rate": 2.5118535268801517e-05,
      "loss": 0.0027,
      "step": 34110
    },
    {
      "epoch": 2.4888759209278577,
      "grad_norm": 0.031239908188581467,
      "learning_rate": 2.5111240790721425e-05,
      "loss": 0.0038,
      "step": 34120
    },
    {
      "epoch": 2.489605368735867,
      "grad_norm": 0.11804118752479553,
      "learning_rate": 2.510394631264133e-05,
      "loss": 0.0024,
      "step": 34130
    },
    {
      "epoch": 2.4903348165438763,
      "grad_norm": 0.13964508473873138,
      "learning_rate": 2.5096651834561237e-05,
      "loss": 0.0032,
      "step": 34140
    },
    {
      "epoch": 2.4910642643518854,
      "grad_norm": 0.23075778782367706,
      "learning_rate": 2.5089357356481148e-05,
      "loss": 0.0046,
      "step": 34150
    },
    {
      "epoch": 2.491793712159895,
      "grad_norm": 0.20140951871871948,
      "learning_rate": 2.508206287840105e-05,
      "loss": 0.0045,
      "step": 34160
    },
    {
      "epoch": 2.492523159967904,
      "grad_norm": 0.058724381029605865,
      "learning_rate": 2.507476840032096e-05,
      "loss": 0.0032,
      "step": 34170
    },
    {
      "epoch": 2.4932526077759136,
      "grad_norm": 0.17288413643836975,
      "learning_rate": 2.5067473922240863e-05,
      "loss": 0.0029,
      "step": 34180
    },
    {
      "epoch": 2.493982055583923,
      "grad_norm": 0.5001919865608215,
      "learning_rate": 2.506017944416077e-05,
      "loss": 0.0027,
      "step": 34190
    },
    {
      "epoch": 2.4947115033919323,
      "grad_norm": 0.0650254487991333,
      "learning_rate": 2.5052884966080682e-05,
      "loss": 0.0034,
      "step": 34200
    },
    {
      "epoch": 2.495440951199942,
      "grad_norm": 0.5355167388916016,
      "learning_rate": 2.5045590488000586e-05,
      "loss": 0.0051,
      "step": 34210
    },
    {
      "epoch": 2.496170399007951,
      "grad_norm": 0.03026147000491619,
      "learning_rate": 2.5038296009920493e-05,
      "loss": 0.0042,
      "step": 34220
    },
    {
      "epoch": 2.4968998468159604,
      "grad_norm": 0.5618773102760315,
      "learning_rate": 2.5031001531840398e-05,
      "loss": 0.0036,
      "step": 34230
    },
    {
      "epoch": 2.4976292946239695,
      "grad_norm": 0.40271028876304626,
      "learning_rate": 2.5023707053760305e-05,
      "loss": 0.0031,
      "step": 34240
    },
    {
      "epoch": 2.498358742431979,
      "grad_norm": 0.2321578711271286,
      "learning_rate": 2.501641257568021e-05,
      "loss": 0.004,
      "step": 34250
    },
    {
      "epoch": 2.499088190239988,
      "grad_norm": 0.11542603373527527,
      "learning_rate": 2.500911809760012e-05,
      "loss": 0.0033,
      "step": 34260
    },
    {
      "epoch": 2.4998176380479977,
      "grad_norm": 0.3868708312511444,
      "learning_rate": 2.5001823619520028e-05,
      "loss": 0.0042,
      "step": 34270
    },
    {
      "epoch": 2.500547085856007,
      "grad_norm": 0.3161078095436096,
      "learning_rate": 2.4994529141439932e-05,
      "loss": 0.0043,
      "step": 34280
    },
    {
      "epoch": 2.5012765336640164,
      "grad_norm": 0.08728386461734772,
      "learning_rate": 2.4987234663359836e-05,
      "loss": 0.0042,
      "step": 34290
    },
    {
      "epoch": 2.502005981472026,
      "grad_norm": 0.2107476443052292,
      "learning_rate": 2.4979940185279744e-05,
      "loss": 0.0043,
      "step": 34300
    },
    {
      "epoch": 2.502735429280035,
      "grad_norm": 0.09135837852954865,
      "learning_rate": 2.497264570719965e-05,
      "loss": 0.003,
      "step": 34310
    },
    {
      "epoch": 2.503464877088044,
      "grad_norm": 0.17391999065876007,
      "learning_rate": 2.496535122911956e-05,
      "loss": 0.0038,
      "step": 34320
    },
    {
      "epoch": 2.5041943248960536,
      "grad_norm": 0.23033533990383148,
      "learning_rate": 2.4958056751039463e-05,
      "loss": 0.0036,
      "step": 34330
    },
    {
      "epoch": 2.504923772704063,
      "grad_norm": 0.0088706836104393,
      "learning_rate": 2.495076227295937e-05,
      "loss": 0.0038,
      "step": 34340
    },
    {
      "epoch": 2.5056532205120723,
      "grad_norm": 0.05954466387629509,
      "learning_rate": 2.4943467794879278e-05,
      "loss": 0.0042,
      "step": 34350
    },
    {
      "epoch": 2.506382668320082,
      "grad_norm": 0.17245042324066162,
      "learning_rate": 2.4936173316799182e-05,
      "loss": 0.0049,
      "step": 34360
    },
    {
      "epoch": 2.507112116128091,
      "grad_norm": 0.20151135325431824,
      "learning_rate": 2.4928878838719093e-05,
      "loss": 0.0037,
      "step": 34370
    },
    {
      "epoch": 2.5078415639361005,
      "grad_norm": 0.28835874795913696,
      "learning_rate": 2.4921584360638997e-05,
      "loss": 0.0051,
      "step": 34380
    },
    {
      "epoch": 2.5085710117441096,
      "grad_norm": 0.02911430411040783,
      "learning_rate": 2.49142898825589e-05,
      "loss": 0.0031,
      "step": 34390
    },
    {
      "epoch": 2.509300459552119,
      "grad_norm": 0.08622265607118607,
      "learning_rate": 2.4906995404478812e-05,
      "loss": 0.004,
      "step": 34400
    },
    {
      "epoch": 2.5100299073601287,
      "grad_norm": 0.43088698387145996,
      "learning_rate": 2.4899700926398716e-05,
      "loss": 0.0038,
      "step": 34410
    },
    {
      "epoch": 2.5107593551681378,
      "grad_norm": 0.5767883062362671,
      "learning_rate": 2.4892406448318624e-05,
      "loss": 0.0034,
      "step": 34420
    },
    {
      "epoch": 2.511488802976147,
      "grad_norm": 0.031073592603206635,
      "learning_rate": 2.488511197023853e-05,
      "loss": 0.0038,
      "step": 34430
    },
    {
      "epoch": 2.5122182507841564,
      "grad_norm": 0.11479564011096954,
      "learning_rate": 2.4877817492158435e-05,
      "loss": 0.0036,
      "step": 34440
    },
    {
      "epoch": 2.512947698592166,
      "grad_norm": 0.22981658577919006,
      "learning_rate": 2.4870523014078346e-05,
      "loss": 0.0031,
      "step": 34450
    },
    {
      "epoch": 2.513677146400175,
      "grad_norm": 0.11552311480045319,
      "learning_rate": 2.486322853599825e-05,
      "loss": 0.0026,
      "step": 34460
    },
    {
      "epoch": 2.514406594208184,
      "grad_norm": 0.25872138142585754,
      "learning_rate": 2.4855934057918158e-05,
      "loss": 0.0034,
      "step": 34470
    },
    {
      "epoch": 2.5151360420161937,
      "grad_norm": 0.05833394452929497,
      "learning_rate": 2.4848639579838066e-05,
      "loss": 0.003,
      "step": 34480
    },
    {
      "epoch": 2.515865489824203,
      "grad_norm": 0.03720327466726303,
      "learning_rate": 2.484134510175797e-05,
      "loss": 0.0028,
      "step": 34490
    },
    {
      "epoch": 2.5165949376322123,
      "grad_norm": 0.3457941710948944,
      "learning_rate": 2.4834050623677877e-05,
      "loss": 0.0024,
      "step": 34500
    },
    {
      "epoch": 2.517324385440222,
      "grad_norm": 0.17364980280399323,
      "learning_rate": 2.4826756145597785e-05,
      "loss": 0.0033,
      "step": 34510
    },
    {
      "epoch": 2.518053833248231,
      "grad_norm": 0.34532639384269714,
      "learning_rate": 2.481946166751769e-05,
      "loss": 0.0041,
      "step": 34520
    },
    {
      "epoch": 2.5187832810562405,
      "grad_norm": 0.027960490435361862,
      "learning_rate": 2.4812167189437596e-05,
      "loss": 0.0032,
      "step": 34530
    },
    {
      "epoch": 2.5195127288642496,
      "grad_norm": 0.5108686685562134,
      "learning_rate": 2.4804872711357504e-05,
      "loss": 0.0035,
      "step": 34540
    },
    {
      "epoch": 2.520242176672259,
      "grad_norm": 0.0311589278280735,
      "learning_rate": 2.479757823327741e-05,
      "loss": 0.0029,
      "step": 34550
    },
    {
      "epoch": 2.5209716244802687,
      "grad_norm": 0.0303790345788002,
      "learning_rate": 2.4790283755197316e-05,
      "loss": 0.0054,
      "step": 34560
    },
    {
      "epoch": 2.521701072288278,
      "grad_norm": 0.4717235565185547,
      "learning_rate": 2.4782989277117223e-05,
      "loss": 0.0047,
      "step": 34570
    },
    {
      "epoch": 2.522430520096287,
      "grad_norm": 0.17331768572330475,
      "learning_rate": 2.477569479903713e-05,
      "loss": 0.0035,
      "step": 34580
    },
    {
      "epoch": 2.5231599679042964,
      "grad_norm": 0.41494742035865784,
      "learning_rate": 2.4768400320957035e-05,
      "loss": 0.0041,
      "step": 34590
    },
    {
      "epoch": 2.523889415712306,
      "grad_norm": 0.09467640519142151,
      "learning_rate": 2.4761105842876946e-05,
      "loss": 0.0035,
      "step": 34600
    },
    {
      "epoch": 2.524618863520315,
      "grad_norm": 0.2294706255197525,
      "learning_rate": 2.475381136479685e-05,
      "loss": 0.0041,
      "step": 34610
    },
    {
      "epoch": 2.5253483113283246,
      "grad_norm": 0.059040892869234085,
      "learning_rate": 2.4746516886716757e-05,
      "loss": 0.0045,
      "step": 34620
    },
    {
      "epoch": 2.5260777591363337,
      "grad_norm": 0.14410410821437836,
      "learning_rate": 2.4739222408636665e-05,
      "loss": 0.0033,
      "step": 34630
    },
    {
      "epoch": 2.5268072069443432,
      "grad_norm": 0.17318814992904663,
      "learning_rate": 2.473192793055657e-05,
      "loss": 0.0018,
      "step": 34640
    },
    {
      "epoch": 2.5275366547523523,
      "grad_norm": 0.2873505651950836,
      "learning_rate": 2.4724633452476477e-05,
      "loss": 0.0041,
      "step": 34650
    },
    {
      "epoch": 2.528266102560362,
      "grad_norm": 0.114778533577919,
      "learning_rate": 2.4717338974396384e-05,
      "loss": 0.0033,
      "step": 34660
    },
    {
      "epoch": 2.528995550368371,
      "grad_norm": 0.08586287498474121,
      "learning_rate": 2.4710044496316288e-05,
      "loss": 0.0026,
      "step": 34670
    },
    {
      "epoch": 2.5297249981763805,
      "grad_norm": 0.03148060664534569,
      "learning_rate": 2.4702750018236196e-05,
      "loss": 0.0031,
      "step": 34680
    },
    {
      "epoch": 2.5304544459843896,
      "grad_norm": 0.03224931284785271,
      "learning_rate": 2.4695455540156103e-05,
      "loss": 0.0039,
      "step": 34690
    },
    {
      "epoch": 2.531183893792399,
      "grad_norm": 0.34399551153182983,
      "learning_rate": 2.468816106207601e-05,
      "loss": 0.0048,
      "step": 34700
    },
    {
      "epoch": 2.5319133416004087,
      "grad_norm": 0.4883511960506439,
      "learning_rate": 2.4680866583995915e-05,
      "loss": 0.0024,
      "step": 34710
    },
    {
      "epoch": 2.532642789408418,
      "grad_norm": 0.4305992126464844,
      "learning_rate": 2.4673572105915823e-05,
      "loss": 0.0031,
      "step": 34720
    },
    {
      "epoch": 2.533372237216427,
      "grad_norm": 0.3740037679672241,
      "learning_rate": 2.466627762783573e-05,
      "loss": 0.0026,
      "step": 34730
    },
    {
      "epoch": 2.5341016850244364,
      "grad_norm": 0.4067528247833252,
      "learning_rate": 2.4658983149755634e-05,
      "loss": 0.0032,
      "step": 34740
    },
    {
      "epoch": 2.534831132832446,
      "grad_norm": 0.05875786021351814,
      "learning_rate": 2.4651688671675545e-05,
      "loss": 0.0038,
      "step": 34750
    },
    {
      "epoch": 2.535560580640455,
      "grad_norm": 0.030342353507876396,
      "learning_rate": 2.464439419359545e-05,
      "loss": 0.0025,
      "step": 34760
    },
    {
      "epoch": 2.5362900284484646,
      "grad_norm": 0.25918692350387573,
      "learning_rate": 2.4637099715515353e-05,
      "loss": 0.0035,
      "step": 34770
    },
    {
      "epoch": 2.5370194762564737,
      "grad_norm": 0.14532053470611572,
      "learning_rate": 2.4629805237435264e-05,
      "loss": 0.0027,
      "step": 34780
    },
    {
      "epoch": 2.5377489240644833,
      "grad_norm": 0.6892228722572327,
      "learning_rate": 2.462251075935517e-05,
      "loss": 0.0039,
      "step": 34790
    },
    {
      "epoch": 2.5384783718724924,
      "grad_norm": 0.260550320148468,
      "learning_rate": 2.4615216281275076e-05,
      "loss": 0.0033,
      "step": 34800
    },
    {
      "epoch": 2.539207819680502,
      "grad_norm": 0.17468678951263428,
      "learning_rate": 2.4607921803194983e-05,
      "loss": 0.0025,
      "step": 34810
    },
    {
      "epoch": 2.5399372674885115,
      "grad_norm": 0.4342251420021057,
      "learning_rate": 2.4600627325114888e-05,
      "loss": 0.0036,
      "step": 34820
    },
    {
      "epoch": 2.5406667152965206,
      "grad_norm": 0.2297985851764679,
      "learning_rate": 2.4593332847034795e-05,
      "loss": 0.0033,
      "step": 34830
    },
    {
      "epoch": 2.5413961631045296,
      "grad_norm": 0.2600783109664917,
      "learning_rate": 2.4586038368954703e-05,
      "loss": 0.0033,
      "step": 34840
    },
    {
      "epoch": 2.542125610912539,
      "grad_norm": 0.3476591408252716,
      "learning_rate": 2.457874389087461e-05,
      "loss": 0.0035,
      "step": 34850
    },
    {
      "epoch": 2.5428550587205487,
      "grad_norm": 0.23010265827178955,
      "learning_rate": 2.4571449412794514e-05,
      "loss": 0.0045,
      "step": 34860
    },
    {
      "epoch": 2.543584506528558,
      "grad_norm": 0.03362555056810379,
      "learning_rate": 2.4564154934714422e-05,
      "loss": 0.004,
      "step": 34870
    },
    {
      "epoch": 2.5443139543365674,
      "grad_norm": 0.14619293808937073,
      "learning_rate": 2.455686045663433e-05,
      "loss": 0.0031,
      "step": 34880
    },
    {
      "epoch": 2.5450434021445765,
      "grad_norm": 0.20148169994354248,
      "learning_rate": 2.4549565978554234e-05,
      "loss": 0.0047,
      "step": 34890
    },
    {
      "epoch": 2.545772849952586,
      "grad_norm": 0.5464010834693909,
      "learning_rate": 2.454227150047414e-05,
      "loss": 0.0035,
      "step": 34900
    },
    {
      "epoch": 2.546502297760595,
      "grad_norm": 0.20216909050941467,
      "learning_rate": 2.453497702239405e-05,
      "loss": 0.004,
      "step": 34910
    },
    {
      "epoch": 2.5472317455686047,
      "grad_norm": 0.17277716100215912,
      "learning_rate": 2.4527682544313956e-05,
      "loss": 0.0034,
      "step": 34920
    },
    {
      "epoch": 2.5479611933766138,
      "grad_norm": 0.04325210303068161,
      "learning_rate": 2.4520388066233864e-05,
      "loss": 0.0041,
      "step": 34930
    },
    {
      "epoch": 2.5486906411846233,
      "grad_norm": 0.11536891758441925,
      "learning_rate": 2.4513093588153768e-05,
      "loss": 0.0032,
      "step": 34940
    },
    {
      "epoch": 2.5494200889926324,
      "grad_norm": 0.23202815651893616,
      "learning_rate": 2.4505799110073675e-05,
      "loss": 0.0031,
      "step": 34950
    },
    {
      "epoch": 2.550149536800642,
      "grad_norm": 0.1727246642112732,
      "learning_rate": 2.4498504631993583e-05,
      "loss": 0.0041,
      "step": 34960
    },
    {
      "epoch": 2.5508789846086515,
      "grad_norm": 0.43140119314193726,
      "learning_rate": 2.4491210153913487e-05,
      "loss": 0.0022,
      "step": 34970
    },
    {
      "epoch": 2.5516084324166606,
      "grad_norm": 0.2586091160774231,
      "learning_rate": 2.4483915675833398e-05,
      "loss": 0.005,
      "step": 34980
    },
    {
      "epoch": 2.5523378802246697,
      "grad_norm": 0.09101922810077667,
      "learning_rate": 2.4476621197753302e-05,
      "loss": 0.0035,
      "step": 34990
    },
    {
      "epoch": 2.553067328032679,
      "grad_norm": 0.012501385994255543,
      "learning_rate": 2.4469326719673206e-05,
      "loss": 0.003,
      "step": 35000
    },
    {
      "epoch": 2.5537967758406888,
      "grad_norm": 0.4003562033176422,
      "learning_rate": 2.4462032241593117e-05,
      "loss": 0.0031,
      "step": 35010
    },
    {
      "epoch": 2.554526223648698,
      "grad_norm": 0.2309284508228302,
      "learning_rate": 2.445473776351302e-05,
      "loss": 0.0047,
      "step": 35020
    },
    {
      "epoch": 2.5552556714567074,
      "grad_norm": 0.14507120847702026,
      "learning_rate": 2.444744328543293e-05,
      "loss": 0.0022,
      "step": 35030
    },
    {
      "epoch": 2.5559851192647165,
      "grad_norm": 0.3454667925834656,
      "learning_rate": 2.4440148807352836e-05,
      "loss": 0.004,
      "step": 35040
    },
    {
      "epoch": 2.556714567072726,
      "grad_norm": 0.4022579789161682,
      "learning_rate": 2.443285432927274e-05,
      "loss": 0.0038,
      "step": 35050
    },
    {
      "epoch": 2.557444014880735,
      "grad_norm": 0.032205529510974884,
      "learning_rate": 2.4425559851192648e-05,
      "loss": 0.0034,
      "step": 35060
    },
    {
      "epoch": 2.5581734626887447,
      "grad_norm": 0.006701588165014982,
      "learning_rate": 2.4418265373112556e-05,
      "loss": 0.0038,
      "step": 35070
    },
    {
      "epoch": 2.5589029104967542,
      "grad_norm": 0.10721292346715927,
      "learning_rate": 2.4410970895032463e-05,
      "loss": 0.0047,
      "step": 35080
    },
    {
      "epoch": 2.5596323583047633,
      "grad_norm": 0.25992465019226074,
      "learning_rate": 2.4403676416952367e-05,
      "loss": 0.0035,
      "step": 35090
    },
    {
      "epoch": 2.5603618061127724,
      "grad_norm": 0.431831419467926,
      "learning_rate": 2.4396381938872275e-05,
      "loss": 0.0039,
      "step": 35100
    },
    {
      "epoch": 2.561091253920782,
      "grad_norm": 0.48168689012527466,
      "learning_rate": 2.4389087460792182e-05,
      "loss": 0.0045,
      "step": 35110
    },
    {
      "epoch": 2.5618207017287915,
      "grad_norm": 0.17624585330486298,
      "learning_rate": 2.4381792982712086e-05,
      "loss": 0.004,
      "step": 35120
    },
    {
      "epoch": 2.5625501495368006,
      "grad_norm": 0.008663864806294441,
      "learning_rate": 2.4374498504631997e-05,
      "loss": 0.0041,
      "step": 35130
    },
    {
      "epoch": 2.5632795973448097,
      "grad_norm": 0.2874046862125397,
      "learning_rate": 2.43672040265519e-05,
      "loss": 0.0035,
      "step": 35140
    },
    {
      "epoch": 2.5640090451528192,
      "grad_norm": 0.43838033080101013,
      "learning_rate": 2.4359909548471806e-05,
      "loss": 0.0034,
      "step": 35150
    },
    {
      "epoch": 2.564738492960829,
      "grad_norm": 0.6535979509353638,
      "learning_rate": 2.4352615070391717e-05,
      "loss": 0.0035,
      "step": 35160
    },
    {
      "epoch": 2.565467940768838,
      "grad_norm": 0.23036789894104004,
      "learning_rate": 2.434532059231162e-05,
      "loss": 0.0032,
      "step": 35170
    },
    {
      "epoch": 2.5661973885768474,
      "grad_norm": 0.010036489926278591,
      "learning_rate": 2.4338026114231528e-05,
      "loss": 0.004,
      "step": 35180
    },
    {
      "epoch": 2.5669268363848565,
      "grad_norm": 0.031735677272081375,
      "learning_rate": 2.4330731636151436e-05,
      "loss": 0.0041,
      "step": 35190
    },
    {
      "epoch": 2.567656284192866,
      "grad_norm": 0.45973318815231323,
      "learning_rate": 2.432343715807134e-05,
      "loss": 0.0035,
      "step": 35200
    },
    {
      "epoch": 2.568385732000875,
      "grad_norm": 0.3170524537563324,
      "learning_rate": 2.4316142679991247e-05,
      "loss": 0.0039,
      "step": 35210
    },
    {
      "epoch": 2.5691151798088847,
      "grad_norm": 0.2893056273460388,
      "learning_rate": 2.4308848201911155e-05,
      "loss": 0.0041,
      "step": 35220
    },
    {
      "epoch": 2.5698446276168943,
      "grad_norm": 0.6992989182472229,
      "learning_rate": 2.4301553723831062e-05,
      "loss": 0.0036,
      "step": 35230
    },
    {
      "epoch": 2.5705740754249033,
      "grad_norm": 0.30012354254722595,
      "learning_rate": 2.4294259245750967e-05,
      "loss": 0.0029,
      "step": 35240
    },
    {
      "epoch": 2.5713035232329124,
      "grad_norm": 0.0705789253115654,
      "learning_rate": 2.4286964767670874e-05,
      "loss": 0.0034,
      "step": 35250
    },
    {
      "epoch": 2.572032971040922,
      "grad_norm": 0.013557719998061657,
      "learning_rate": 2.427967028959078e-05,
      "loss": 0.0043,
      "step": 35260
    },
    {
      "epoch": 2.5727624188489315,
      "grad_norm": 0.2012203186750412,
      "learning_rate": 2.4272375811510686e-05,
      "loss": 0.0035,
      "step": 35270
    },
    {
      "epoch": 2.5734918666569406,
      "grad_norm": 0.029960710555315018,
      "learning_rate": 2.4265081333430593e-05,
      "loss": 0.0034,
      "step": 35280
    },
    {
      "epoch": 2.57422131446495,
      "grad_norm": 0.4600645899772644,
      "learning_rate": 2.42577868553505e-05,
      "loss": 0.0033,
      "step": 35290
    },
    {
      "epoch": 2.5749507622729593,
      "grad_norm": 0.14447830617427826,
      "learning_rate": 2.4250492377270405e-05,
      "loss": 0.0035,
      "step": 35300
    },
    {
      "epoch": 2.575680210080969,
      "grad_norm": 0.28803348541259766,
      "learning_rate": 2.4243197899190316e-05,
      "loss": 0.0038,
      "step": 35310
    },
    {
      "epoch": 2.576409657888978,
      "grad_norm": 0.031032070517539978,
      "learning_rate": 2.423590342111022e-05,
      "loss": 0.0024,
      "step": 35320
    },
    {
      "epoch": 2.5771391056969875,
      "grad_norm": 0.7272587418556213,
      "learning_rate": 2.4228608943030128e-05,
      "loss": 0.0037,
      "step": 35330
    },
    {
      "epoch": 2.5778685535049966,
      "grad_norm": 0.1879374384880066,
      "learning_rate": 2.4221314464950035e-05,
      "loss": 0.004,
      "step": 35340
    },
    {
      "epoch": 2.578598001313006,
      "grad_norm": 0.37333598732948303,
      "learning_rate": 2.421401998686994e-05,
      "loss": 0.0032,
      "step": 35350
    },
    {
      "epoch": 2.579327449121015,
      "grad_norm": 0.22920498251914978,
      "learning_rate": 2.4206725508789847e-05,
      "loss": 0.0031,
      "step": 35360
    },
    {
      "epoch": 2.5800568969290247,
      "grad_norm": 0.036162119358778,
      "learning_rate": 2.4199431030709754e-05,
      "loss": 0.0035,
      "step": 35370
    },
    {
      "epoch": 2.5807863447370343,
      "grad_norm": 0.20931483805179596,
      "learning_rate": 2.419213655262966e-05,
      "loss": 0.0034,
      "step": 35380
    },
    {
      "epoch": 2.5815157925450434,
      "grad_norm": 0.11422361433506012,
      "learning_rate": 2.418484207454957e-05,
      "loss": 0.0032,
      "step": 35390
    },
    {
      "epoch": 2.5822452403530525,
      "grad_norm": 0.030564287677407265,
      "learning_rate": 2.4177547596469474e-05,
      "loss": 0.0034,
      "step": 35400
    },
    {
      "epoch": 2.582974688161062,
      "grad_norm": 0.2578476667404175,
      "learning_rate": 2.417025311838938e-05,
      "loss": 0.0024,
      "step": 35410
    },
    {
      "epoch": 2.5837041359690716,
      "grad_norm": 0.31593286991119385,
      "learning_rate": 2.416295864030929e-05,
      "loss": 0.0029,
      "step": 35420
    },
    {
      "epoch": 2.5844335837770807,
      "grad_norm": 0.05883483588695526,
      "learning_rate": 2.4155664162229193e-05,
      "loss": 0.0045,
      "step": 35430
    },
    {
      "epoch": 2.58516303158509,
      "grad_norm": 0.2015426903963089,
      "learning_rate": 2.41483696841491e-05,
      "loss": 0.003,
      "step": 35440
    },
    {
      "epoch": 2.5858924793930993,
      "grad_norm": 0.11532946676015854,
      "learning_rate": 2.4141075206069008e-05,
      "loss": 0.0051,
      "step": 35450
    },
    {
      "epoch": 2.586621927201109,
      "grad_norm": 0.16744770109653473,
      "learning_rate": 2.4133780727988915e-05,
      "loss": 0.004,
      "step": 35460
    },
    {
      "epoch": 2.587351375009118,
      "grad_norm": 0.007866805419325829,
      "learning_rate": 2.412648624990882e-05,
      "loss": 0.0024,
      "step": 35470
    },
    {
      "epoch": 2.5880808228171275,
      "grad_norm": 0.47487878799438477,
      "learning_rate": 2.4119191771828727e-05,
      "loss": 0.0031,
      "step": 35480
    },
    {
      "epoch": 2.588810270625137,
      "grad_norm": 0.05778196081519127,
      "learning_rate": 2.4111897293748635e-05,
      "loss": 0.0034,
      "step": 35490
    },
    {
      "epoch": 2.589539718433146,
      "grad_norm": 0.3159482181072235,
      "learning_rate": 2.410460281566854e-05,
      "loss": 0.0034,
      "step": 35500
    },
    {
      "epoch": 2.590269166241155,
      "grad_norm": 0.20321716368198395,
      "learning_rate": 2.4097308337588446e-05,
      "loss": 0.005,
      "step": 35510
    },
    {
      "epoch": 2.5909986140491648,
      "grad_norm": 0.00926893763244152,
      "learning_rate": 2.4090013859508354e-05,
      "loss": 0.0028,
      "step": 35520
    },
    {
      "epoch": 2.5917280618571743,
      "grad_norm": 0.2012089043855667,
      "learning_rate": 2.4082719381428258e-05,
      "loss": 0.0037,
      "step": 35530
    },
    {
      "epoch": 2.5924575096651834,
      "grad_norm": 0.42592599987983704,
      "learning_rate": 2.407542490334817e-05,
      "loss": 0.0033,
      "step": 35540
    },
    {
      "epoch": 2.593186957473193,
      "grad_norm": 0.05899028480052948,
      "learning_rate": 2.4068130425268073e-05,
      "loss": 0.0034,
      "step": 35550
    },
    {
      "epoch": 2.593916405281202,
      "grad_norm": 0.3456030488014221,
      "learning_rate": 2.406083594718798e-05,
      "loss": 0.0028,
      "step": 35560
    },
    {
      "epoch": 2.5946458530892116,
      "grad_norm": 0.3169478178024292,
      "learning_rate": 2.4053541469107888e-05,
      "loss": 0.0037,
      "step": 35570
    },
    {
      "epoch": 2.5953753008972207,
      "grad_norm": 0.04073896259069443,
      "learning_rate": 2.4046246991027792e-05,
      "loss": 0.0039,
      "step": 35580
    },
    {
      "epoch": 2.5961047487052302,
      "grad_norm": 0.029268916696310043,
      "learning_rate": 2.40389525129477e-05,
      "loss": 0.0033,
      "step": 35590
    },
    {
      "epoch": 2.5968341965132393,
      "grad_norm": 0.058744680136442184,
      "learning_rate": 2.4031658034867607e-05,
      "loss": 0.0032,
      "step": 35600
    },
    {
      "epoch": 2.597563644321249,
      "grad_norm": 0.48334261775016785,
      "learning_rate": 2.402436355678751e-05,
      "loss": 0.0061,
      "step": 35610
    },
    {
      "epoch": 2.598293092129258,
      "grad_norm": 0.2874722182750702,
      "learning_rate": 2.401706907870742e-05,
      "loss": 0.0022,
      "step": 35620
    },
    {
      "epoch": 2.5990225399372675,
      "grad_norm": 0.2872573435306549,
      "learning_rate": 2.4009774600627326e-05,
      "loss": 0.0035,
      "step": 35630
    },
    {
      "epoch": 2.599751987745277,
      "grad_norm": 0.4022567570209503,
      "learning_rate": 2.4002480122547234e-05,
      "loss": 0.004,
      "step": 35640
    },
    {
      "epoch": 2.600481435553286,
      "grad_norm": 0.009324266575276852,
      "learning_rate": 2.3995185644467138e-05,
      "loss": 0.0051,
      "step": 35650
    },
    {
      "epoch": 2.6012108833612952,
      "grad_norm": 0.05862794816493988,
      "learning_rate": 2.3987891166387046e-05,
      "loss": 0.004,
      "step": 35660
    },
    {
      "epoch": 2.601940331169305,
      "grad_norm": 0.019787346944212914,
      "learning_rate": 2.3980596688306953e-05,
      "loss": 0.0022,
      "step": 35670
    },
    {
      "epoch": 2.6026697789773143,
      "grad_norm": 0.5148470997810364,
      "learning_rate": 2.3973302210226857e-05,
      "loss": 0.0038,
      "step": 35680
    },
    {
      "epoch": 2.6033992267853234,
      "grad_norm": 0.02990591898560524,
      "learning_rate": 2.3966007732146768e-05,
      "loss": 0.0036,
      "step": 35690
    },
    {
      "epoch": 2.604128674593333,
      "grad_norm": 0.3161134123802185,
      "learning_rate": 2.3958713254066672e-05,
      "loss": 0.0037,
      "step": 35700
    },
    {
      "epoch": 2.604858122401342,
      "grad_norm": 0.23040956258773804,
      "learning_rate": 2.395141877598658e-05,
      "loss": 0.0014,
      "step": 35710
    },
    {
      "epoch": 2.6055875702093516,
      "grad_norm": 0.374140202999115,
      "learning_rate": 2.3944124297906487e-05,
      "loss": 0.0032,
      "step": 35720
    },
    {
      "epoch": 2.6063170180173607,
      "grad_norm": 0.07631944119930267,
      "learning_rate": 2.393682981982639e-05,
      "loss": 0.0049,
      "step": 35730
    },
    {
      "epoch": 2.6070464658253703,
      "grad_norm": 0.05789162591099739,
      "learning_rate": 2.39295353417463e-05,
      "loss": 0.0055,
      "step": 35740
    },
    {
      "epoch": 2.60777591363338,
      "grad_norm": 0.17237108945846558,
      "learning_rate": 2.3922240863666207e-05,
      "loss": 0.0042,
      "step": 35750
    },
    {
      "epoch": 2.608505361441389,
      "grad_norm": 0.29674458503723145,
      "learning_rate": 2.391494638558611e-05,
      "loss": 0.0042,
      "step": 35760
    },
    {
      "epoch": 2.609234809249398,
      "grad_norm": 0.28868240118026733,
      "learning_rate": 2.3907651907506018e-05,
      "loss": 0.002,
      "step": 35770
    },
    {
      "epoch": 2.6099642570574075,
      "grad_norm": 0.4520268142223358,
      "learning_rate": 2.3900357429425926e-05,
      "loss": 0.0034,
      "step": 35780
    },
    {
      "epoch": 2.610693704865417,
      "grad_norm": 0.11633840203285217,
      "learning_rate": 2.3893062951345833e-05,
      "loss": 0.0025,
      "step": 35790
    },
    {
      "epoch": 2.611423152673426,
      "grad_norm": 0.03227444365620613,
      "learning_rate": 2.3885768473265737e-05,
      "loss": 0.0037,
      "step": 35800
    },
    {
      "epoch": 2.6121526004814357,
      "grad_norm": 0.2876512408256531,
      "learning_rate": 2.3878473995185645e-05,
      "loss": 0.0031,
      "step": 35810
    },
    {
      "epoch": 2.612882048289445,
      "grad_norm": 0.08624016493558884,
      "learning_rate": 2.3871179517105553e-05,
      "loss": 0.0028,
      "step": 35820
    },
    {
      "epoch": 2.6136114960974544,
      "grad_norm": 0.05797674134373665,
      "learning_rate": 2.3863885039025457e-05,
      "loss": 0.0029,
      "step": 35830
    },
    {
      "epoch": 2.6143409439054635,
      "grad_norm": 0.39886486530303955,
      "learning_rate": 2.3856590560945368e-05,
      "loss": 0.0026,
      "step": 35840
    },
    {
      "epoch": 2.615070391713473,
      "grad_norm": 0.31649520993232727,
      "learning_rate": 2.3849296082865272e-05,
      "loss": 0.0024,
      "step": 35850
    },
    {
      "epoch": 2.615799839521482,
      "grad_norm": 0.3441745638847351,
      "learning_rate": 2.3842001604785176e-05,
      "loss": 0.0048,
      "step": 35860
    },
    {
      "epoch": 2.6165292873294916,
      "grad_norm": 0.006108757574111223,
      "learning_rate": 2.3834707126705087e-05,
      "loss": 0.0028,
      "step": 35870
    },
    {
      "epoch": 2.6172587351375007,
      "grad_norm": 0.1440218687057495,
      "learning_rate": 2.382741264862499e-05,
      "loss": 0.0044,
      "step": 35880
    },
    {
      "epoch": 2.6179881829455103,
      "grad_norm": 0.3740435838699341,
      "learning_rate": 2.38201181705449e-05,
      "loss": 0.0027,
      "step": 35890
    },
    {
      "epoch": 2.61871763075352,
      "grad_norm": 0.39437931776046753,
      "learning_rate": 2.3812823692464806e-05,
      "loss": 0.0036,
      "step": 35900
    },
    {
      "epoch": 2.619447078561529,
      "grad_norm": 0.33421972393989563,
      "learning_rate": 2.380552921438471e-05,
      "loss": 0.0047,
      "step": 35910
    },
    {
      "epoch": 2.620176526369538,
      "grad_norm": 0.14384163916110992,
      "learning_rate": 2.379823473630462e-05,
      "loss": 0.0041,
      "step": 35920
    },
    {
      "epoch": 2.6209059741775476,
      "grad_norm": 0.14480340480804443,
      "learning_rate": 2.3790940258224525e-05,
      "loss": 0.0045,
      "step": 35930
    },
    {
      "epoch": 2.621635421985557,
      "grad_norm": 0.031224248930811882,
      "learning_rate": 2.3783645780144433e-05,
      "loss": 0.0033,
      "step": 35940
    },
    {
      "epoch": 2.622364869793566,
      "grad_norm": 0.2886087894439697,
      "learning_rate": 2.377635130206434e-05,
      "loss": 0.0056,
      "step": 35950
    },
    {
      "epoch": 2.6230943176015757,
      "grad_norm": 0.058495860546827316,
      "learning_rate": 2.3769056823984244e-05,
      "loss": 0.0039,
      "step": 35960
    },
    {
      "epoch": 2.623823765409585,
      "grad_norm": 0.23038749396800995,
      "learning_rate": 2.3761762345904152e-05,
      "loss": 0.0028,
      "step": 35970
    },
    {
      "epoch": 2.6245532132175944,
      "grad_norm": 0.229812353849411,
      "learning_rate": 2.375446786782406e-05,
      "loss": 0.0038,
      "step": 35980
    },
    {
      "epoch": 2.6252826610256035,
      "grad_norm": 0.07969151437282562,
      "learning_rate": 2.3747173389743964e-05,
      "loss": 0.0055,
      "step": 35990
    },
    {
      "epoch": 2.626012108833613,
      "grad_norm": 0.20217475295066833,
      "learning_rate": 2.373987891166387e-05,
      "loss": 0.0025,
      "step": 36000
    },
    {
      "epoch": 2.6267415566416226,
      "grad_norm": 0.05843234062194824,
      "learning_rate": 2.373258443358378e-05,
      "loss": 0.0028,
      "step": 36010
    },
    {
      "epoch": 2.6274710044496317,
      "grad_norm": 0.19799049198627472,
      "learning_rate": 2.3725289955503686e-05,
      "loss": 0.0035,
      "step": 36020
    },
    {
      "epoch": 2.6282004522576408,
      "grad_norm": 0.03141187131404877,
      "learning_rate": 2.371799547742359e-05,
      "loss": 0.0035,
      "step": 36030
    },
    {
      "epoch": 2.6289299000656503,
      "grad_norm": 0.11552642285823822,
      "learning_rate": 2.3710700999343498e-05,
      "loss": 0.0032,
      "step": 36040
    },
    {
      "epoch": 2.62965934787366,
      "grad_norm": 0.1439184993505478,
      "learning_rate": 2.3703406521263405e-05,
      "loss": 0.0036,
      "step": 36050
    },
    {
      "epoch": 2.630388795681669,
      "grad_norm": 0.28799793124198914,
      "learning_rate": 2.369611204318331e-05,
      "loss": 0.0031,
      "step": 36060
    },
    {
      "epoch": 2.631118243489678,
      "grad_norm": 0.11545024067163467,
      "learning_rate": 2.368881756510322e-05,
      "loss": 0.002,
      "step": 36070
    },
    {
      "epoch": 2.6318476912976876,
      "grad_norm": 0.17235800623893738,
      "learning_rate": 2.3681523087023125e-05,
      "loss": 0.0025,
      "step": 36080
    },
    {
      "epoch": 2.632577139105697,
      "grad_norm": 0.14710314571857452,
      "learning_rate": 2.367422860894303e-05,
      "loss": 0.0034,
      "step": 36090
    },
    {
      "epoch": 2.6333065869137062,
      "grad_norm": 0.23260317742824554,
      "learning_rate": 2.366693413086294e-05,
      "loss": 0.0038,
      "step": 36100
    },
    {
      "epoch": 2.6340360347217158,
      "grad_norm": 0.03486083820462227,
      "learning_rate": 2.3659639652782844e-05,
      "loss": 0.0036,
      "step": 36110
    },
    {
      "epoch": 2.634765482529725,
      "grad_norm": 0.010619488544762135,
      "learning_rate": 2.365234517470275e-05,
      "loss": 0.0032,
      "step": 36120
    },
    {
      "epoch": 2.6354949303377344,
      "grad_norm": 0.8768095970153809,
      "learning_rate": 2.364505069662266e-05,
      "loss": 0.0037,
      "step": 36130
    },
    {
      "epoch": 2.6362243781457435,
      "grad_norm": 0.2598465383052826,
      "learning_rate": 2.3637756218542563e-05,
      "loss": 0.0038,
      "step": 36140
    },
    {
      "epoch": 2.636953825953753,
      "grad_norm": 0.23035681247711182,
      "learning_rate": 2.363046174046247e-05,
      "loss": 0.0039,
      "step": 36150
    },
    {
      "epoch": 2.6376832737617626,
      "grad_norm": 0.05824751406908035,
      "learning_rate": 2.3623167262382378e-05,
      "loss": 0.0029,
      "step": 36160
    },
    {
      "epoch": 2.6384127215697717,
      "grad_norm": 0.1725378781557083,
      "learning_rate": 2.3615872784302286e-05,
      "loss": 0.0031,
      "step": 36170
    },
    {
      "epoch": 2.639142169377781,
      "grad_norm": 0.11556009203195572,
      "learning_rate": 2.360857830622219e-05,
      "loss": 0.0024,
      "step": 36180
    },
    {
      "epoch": 2.6398716171857903,
      "grad_norm": 0.3452978730201721,
      "learning_rate": 2.3601283828142097e-05,
      "loss": 0.0029,
      "step": 36190
    },
    {
      "epoch": 2.6406010649938,
      "grad_norm": 0.17553189396858215,
      "learning_rate": 2.3593989350062005e-05,
      "loss": 0.0027,
      "step": 36200
    },
    {
      "epoch": 2.641330512801809,
      "grad_norm": 0.17224429547786713,
      "learning_rate": 2.358669487198191e-05,
      "loss": 0.0045,
      "step": 36210
    },
    {
      "epoch": 2.6420599606098185,
      "grad_norm": 0.09116923809051514,
      "learning_rate": 2.357940039390182e-05,
      "loss": 0.0028,
      "step": 36220
    },
    {
      "epoch": 2.6427894084178276,
      "grad_norm": 0.3658011555671692,
      "learning_rate": 2.3572105915821724e-05,
      "loss": 0.004,
      "step": 36230
    },
    {
      "epoch": 2.643518856225837,
      "grad_norm": 0.055483125150203705,
      "learning_rate": 2.3564811437741628e-05,
      "loss": 0.0034,
      "step": 36240
    },
    {
      "epoch": 2.6442483040338463,
      "grad_norm": 0.39818957448005676,
      "learning_rate": 2.355751695966154e-05,
      "loss": 0.0037,
      "step": 36250
    },
    {
      "epoch": 2.644977751841856,
      "grad_norm": 0.3123355209827423,
      "learning_rate": 2.3550222481581443e-05,
      "loss": 0.0036,
      "step": 36260
    },
    {
      "epoch": 2.645707199649865,
      "grad_norm": 0.17315468192100525,
      "learning_rate": 2.354292800350135e-05,
      "loss": 0.0026,
      "step": 36270
    },
    {
      "epoch": 2.6464366474578744,
      "grad_norm": 0.08845487982034683,
      "learning_rate": 2.3535633525421258e-05,
      "loss": 0.003,
      "step": 36280
    },
    {
      "epoch": 2.6471660952658835,
      "grad_norm": 0.15506473183631897,
      "learning_rate": 2.3528339047341162e-05,
      "loss": 0.0036,
      "step": 36290
    },
    {
      "epoch": 2.647895543073893,
      "grad_norm": 0.29195675253868103,
      "learning_rate": 2.352104456926107e-05,
      "loss": 0.0029,
      "step": 36300
    },
    {
      "epoch": 2.6486249908819026,
      "grad_norm": 0.22958272695541382,
      "learning_rate": 2.3513750091180977e-05,
      "loss": 0.0026,
      "step": 36310
    },
    {
      "epoch": 2.6493544386899117,
      "grad_norm": 0.2691768407821655,
      "learning_rate": 2.3506455613100885e-05,
      "loss": 0.0027,
      "step": 36320
    },
    {
      "epoch": 2.650083886497921,
      "grad_norm": 0.2882085144519806,
      "learning_rate": 2.349916113502079e-05,
      "loss": 0.0024,
      "step": 36330
    },
    {
      "epoch": 2.6508133343059304,
      "grad_norm": 0.08599375933408737,
      "learning_rate": 2.3491866656940697e-05,
      "loss": 0.0044,
      "step": 36340
    },
    {
      "epoch": 2.65154278211394,
      "grad_norm": 0.20158128440380096,
      "learning_rate": 2.3484572178860604e-05,
      "loss": 0.0038,
      "step": 36350
    },
    {
      "epoch": 2.652272229921949,
      "grad_norm": 0.14370597898960114,
      "learning_rate": 2.347727770078051e-05,
      "loss": 0.003,
      "step": 36360
    },
    {
      "epoch": 2.6530016777299585,
      "grad_norm": 0.20463784039020538,
      "learning_rate": 2.3469983222700416e-05,
      "loss": 0.0039,
      "step": 36370
    },
    {
      "epoch": 2.6537311255379676,
      "grad_norm": 0.05774099379777908,
      "learning_rate": 2.3462688744620323e-05,
      "loss": 0.0029,
      "step": 36380
    },
    {
      "epoch": 2.654460573345977,
      "grad_norm": 0.20118887722492218,
      "learning_rate": 2.345539426654023e-05,
      "loss": 0.0048,
      "step": 36390
    },
    {
      "epoch": 2.6551900211539863,
      "grad_norm": 0.4022676646709442,
      "learning_rate": 2.344809978846014e-05,
      "loss": 0.003,
      "step": 36400
    },
    {
      "epoch": 2.655919468961996,
      "grad_norm": 0.18508121371269226,
      "learning_rate": 2.3440805310380043e-05,
      "loss": 0.0032,
      "step": 36410
    },
    {
      "epoch": 2.6566489167700054,
      "grad_norm": 0.22228065133094788,
      "learning_rate": 2.343351083229995e-05,
      "loss": 0.0037,
      "step": 36420
    },
    {
      "epoch": 2.6573783645780145,
      "grad_norm": 0.11550724506378174,
      "learning_rate": 2.3426216354219858e-05,
      "loss": 0.0037,
      "step": 36430
    },
    {
      "epoch": 2.6581078123860236,
      "grad_norm": 0.3448299169540405,
      "learning_rate": 2.3418921876139762e-05,
      "loss": 0.0033,
      "step": 36440
    },
    {
      "epoch": 2.658837260194033,
      "grad_norm": 0.009767977520823479,
      "learning_rate": 2.3411627398059673e-05,
      "loss": 0.0049,
      "step": 36450
    },
    {
      "epoch": 2.6595667080020426,
      "grad_norm": 0.30251097679138184,
      "learning_rate": 2.3404332919979577e-05,
      "loss": 0.0044,
      "step": 36460
    },
    {
      "epoch": 2.6602961558100517,
      "grad_norm": 0.029688414186239243,
      "learning_rate": 2.339703844189948e-05,
      "loss": 0.0041,
      "step": 36470
    },
    {
      "epoch": 2.6610256036180613,
      "grad_norm": 0.03011172264814377,
      "learning_rate": 2.3389743963819392e-05,
      "loss": 0.0035,
      "step": 36480
    },
    {
      "epoch": 2.6617550514260704,
      "grad_norm": 0.05946836993098259,
      "learning_rate": 2.3382449485739296e-05,
      "loss": 0.0036,
      "step": 36490
    },
    {
      "epoch": 2.66248449923408,
      "grad_norm": 0.17384198307991028,
      "learning_rate": 2.3375155007659204e-05,
      "loss": 0.004,
      "step": 36500
    },
    {
      "epoch": 2.663213947042089,
      "grad_norm": 0.11575353145599365,
      "learning_rate": 2.336786052957911e-05,
      "loss": 0.0035,
      "step": 36510
    },
    {
      "epoch": 2.6639433948500986,
      "grad_norm": 0.41166868805885315,
      "learning_rate": 2.3360566051499015e-05,
      "loss": 0.003,
      "step": 36520
    },
    {
      "epoch": 2.6646728426581077,
      "grad_norm": 0.06704182922840118,
      "learning_rate": 2.3353271573418923e-05,
      "loss": 0.0037,
      "step": 36530
    },
    {
      "epoch": 2.665402290466117,
      "grad_norm": 0.1436116248369217,
      "learning_rate": 2.334597709533883e-05,
      "loss": 0.0026,
      "step": 36540
    },
    {
      "epoch": 2.6661317382741263,
      "grad_norm": 0.04948084056377411,
      "learning_rate": 2.3338682617258738e-05,
      "loss": 0.0044,
      "step": 36550
    },
    {
      "epoch": 2.666861186082136,
      "grad_norm": 0.11513408273458481,
      "learning_rate": 2.3331388139178642e-05,
      "loss": 0.0033,
      "step": 36560
    },
    {
      "epoch": 2.6675906338901454,
      "grad_norm": 0.144401416182518,
      "learning_rate": 2.332409366109855e-05,
      "loss": 0.0039,
      "step": 36570
    },
    {
      "epoch": 2.6683200816981545,
      "grad_norm": 0.06034613773226738,
      "learning_rate": 2.3316799183018457e-05,
      "loss": 0.0034,
      "step": 36580
    },
    {
      "epoch": 2.6690495295061636,
      "grad_norm": 0.08114214986562729,
      "learning_rate": 2.330950470493836e-05,
      "loss": 0.0029,
      "step": 36590
    },
    {
      "epoch": 2.669778977314173,
      "grad_norm": 0.08742214739322662,
      "learning_rate": 2.330221022685827e-05,
      "loss": 0.003,
      "step": 36600
    },
    {
      "epoch": 2.6705084251221827,
      "grad_norm": 0.38426488637924194,
      "learning_rate": 2.3294915748778176e-05,
      "loss": 0.004,
      "step": 36610
    },
    {
      "epoch": 2.6712378729301918,
      "grad_norm": 0.32398346066474915,
      "learning_rate": 2.328762127069808e-05,
      "loss": 0.0034,
      "step": 36620
    },
    {
      "epoch": 2.6719673207382013,
      "grad_norm": 0.17182452976703644,
      "learning_rate": 2.328032679261799e-05,
      "loss": 0.0046,
      "step": 36630
    },
    {
      "epoch": 2.6726967685462104,
      "grad_norm": 0.7972398400306702,
      "learning_rate": 2.3273032314537895e-05,
      "loss": 0.0027,
      "step": 36640
    },
    {
      "epoch": 2.67342621635422,
      "grad_norm": 0.3635737895965576,
      "learning_rate": 2.3265737836457803e-05,
      "loss": 0.0042,
      "step": 36650
    },
    {
      "epoch": 2.674155664162229,
      "grad_norm": 0.4612743556499481,
      "learning_rate": 2.325844335837771e-05,
      "loss": 0.0048,
      "step": 36660
    },
    {
      "epoch": 2.6748851119702386,
      "grad_norm": 0.641923725605011,
      "learning_rate": 2.3251148880297615e-05,
      "loss": 0.0039,
      "step": 36670
    },
    {
      "epoch": 2.675614559778248,
      "grad_norm": 0.030706971883773804,
      "learning_rate": 2.3243854402217522e-05,
      "loss": 0.0025,
      "step": 36680
    },
    {
      "epoch": 2.6763440075862572,
      "grad_norm": 0.22990074753761292,
      "learning_rate": 2.323655992413743e-05,
      "loss": 0.003,
      "step": 36690
    },
    {
      "epoch": 2.6770734553942663,
      "grad_norm": 0.02753717452287674,
      "learning_rate": 2.3229265446057337e-05,
      "loss": 0.0041,
      "step": 36700
    },
    {
      "epoch": 2.677802903202276,
      "grad_norm": 0.21704697608947754,
      "learning_rate": 2.322197096797724e-05,
      "loss": 0.0043,
      "step": 36710
    },
    {
      "epoch": 2.6785323510102854,
      "grad_norm": 0.290313184261322,
      "learning_rate": 2.321467648989715e-05,
      "loss": 0.004,
      "step": 36720
    },
    {
      "epoch": 2.6792617988182945,
      "grad_norm": 0.033250533044338226,
      "learning_rate": 2.3207382011817056e-05,
      "loss": 0.0041,
      "step": 36730
    },
    {
      "epoch": 2.6799912466263036,
      "grad_norm": 0.12821418046951294,
      "learning_rate": 2.320008753373696e-05,
      "loss": 0.0035,
      "step": 36740
    },
    {
      "epoch": 2.680720694434313,
      "grad_norm": 0.1149471253156662,
      "learning_rate": 2.3192793055656868e-05,
      "loss": 0.0026,
      "step": 36750
    },
    {
      "epoch": 2.6814501422423227,
      "grad_norm": 0.017579108476638794,
      "learning_rate": 2.3185498577576776e-05,
      "loss": 0.0042,
      "step": 36760
    },
    {
      "epoch": 2.682179590050332,
      "grad_norm": 0.11461476236581802,
      "learning_rate": 2.317820409949668e-05,
      "loss": 0.0026,
      "step": 36770
    },
    {
      "epoch": 2.6829090378583413,
      "grad_norm": 0.17372171580791473,
      "learning_rate": 2.317090962141659e-05,
      "loss": 0.0029,
      "step": 36780
    },
    {
      "epoch": 2.6836384856663504,
      "grad_norm": 0.08677934110164642,
      "learning_rate": 2.3163615143336495e-05,
      "loss": 0.0034,
      "step": 36790
    },
    {
      "epoch": 2.68436793347436,
      "grad_norm": 0.26789286732673645,
      "learning_rate": 2.3156320665256402e-05,
      "loss": 0.0045,
      "step": 36800
    },
    {
      "epoch": 2.685097381282369,
      "grad_norm": 0.43466097116470337,
      "learning_rate": 2.314902618717631e-05,
      "loss": 0.0029,
      "step": 36810
    },
    {
      "epoch": 2.6858268290903786,
      "grad_norm": 0.23061025142669678,
      "learning_rate": 2.3141731709096214e-05,
      "loss": 0.0032,
      "step": 36820
    },
    {
      "epoch": 2.686556276898388,
      "grad_norm": 0.3803023397922516,
      "learning_rate": 2.313443723101612e-05,
      "loss": 0.0037,
      "step": 36830
    },
    {
      "epoch": 2.6872857247063973,
      "grad_norm": 0.11570670455694199,
      "learning_rate": 2.312714275293603e-05,
      "loss": 0.0029,
      "step": 36840
    },
    {
      "epoch": 2.6880151725144064,
      "grad_norm": 0.11532960832118988,
      "learning_rate": 2.3119848274855933e-05,
      "loss": 0.004,
      "step": 36850
    },
    {
      "epoch": 2.688744620322416,
      "grad_norm": 0.08626246452331543,
      "learning_rate": 2.311255379677584e-05,
      "loss": 0.0034,
      "step": 36860
    },
    {
      "epoch": 2.6894740681304254,
      "grad_norm": 0.2003994584083557,
      "learning_rate": 2.310525931869575e-05,
      "loss": 0.0032,
      "step": 36870
    },
    {
      "epoch": 2.6902035159384345,
      "grad_norm": 0.28736716508865356,
      "learning_rate": 2.3097964840615656e-05,
      "loss": 0.0036,
      "step": 36880
    },
    {
      "epoch": 2.690932963746444,
      "grad_norm": 0.03191089257597923,
      "learning_rate": 2.3090670362535563e-05,
      "loss": 0.0034,
      "step": 36890
    },
    {
      "epoch": 2.691662411554453,
      "grad_norm": 0.20222073793411255,
      "learning_rate": 2.3083375884455468e-05,
      "loss": 0.0032,
      "step": 36900
    },
    {
      "epoch": 2.6923918593624627,
      "grad_norm": 0.31594333052635193,
      "learning_rate": 2.3076081406375375e-05,
      "loss": 0.0026,
      "step": 36910
    },
    {
      "epoch": 2.693121307170472,
      "grad_norm": 0.3421640992164612,
      "learning_rate": 2.3068786928295283e-05,
      "loss": 0.0035,
      "step": 36920
    },
    {
      "epoch": 2.6938507549784814,
      "grad_norm": 0.08650368452072144,
      "learning_rate": 2.306149245021519e-05,
      "loss": 0.0044,
      "step": 36930
    },
    {
      "epoch": 2.6945802027864905,
      "grad_norm": 0.03297622129321098,
      "learning_rate": 2.3054197972135094e-05,
      "loss": 0.0043,
      "step": 36940
    },
    {
      "epoch": 2.6953096505945,
      "grad_norm": 0.23637491464614868,
      "learning_rate": 2.3046903494055002e-05,
      "loss": 0.0026,
      "step": 36950
    },
    {
      "epoch": 2.696039098402509,
      "grad_norm": 0.40520405769348145,
      "learning_rate": 2.303960901597491e-05,
      "loss": 0.0031,
      "step": 36960
    },
    {
      "epoch": 2.6967685462105186,
      "grad_norm": 0.1499408334493637,
      "learning_rate": 2.3032314537894813e-05,
      "loss": 0.0034,
      "step": 36970
    },
    {
      "epoch": 2.697497994018528,
      "grad_norm": 0.35157284140586853,
      "learning_rate": 2.302502005981472e-05,
      "loss": 0.0036,
      "step": 36980
    },
    {
      "epoch": 2.6982274418265373,
      "grad_norm": 0.05787445604801178,
      "learning_rate": 2.301772558173463e-05,
      "loss": 0.0047,
      "step": 36990
    },
    {
      "epoch": 2.6989568896345464,
      "grad_norm": 0.30026888847351074,
      "learning_rate": 2.3010431103654533e-05,
      "loss": 0.0042,
      "step": 37000
    },
    {
      "epoch": 2.699686337442556,
      "grad_norm": 0.29659950733184814,
      "learning_rate": 2.3003136625574444e-05,
      "loss": 0.0034,
      "step": 37010
    },
    {
      "epoch": 2.7004157852505655,
      "grad_norm": 0.08744218945503235,
      "learning_rate": 2.2995842147494348e-05,
      "loss": 0.0026,
      "step": 37020
    },
    {
      "epoch": 2.7011452330585746,
      "grad_norm": 0.25965699553489685,
      "learning_rate": 2.2988547669414255e-05,
      "loss": 0.0055,
      "step": 37030
    },
    {
      "epoch": 2.701874680866584,
      "grad_norm": 0.21172012388706207,
      "learning_rate": 2.2981253191334163e-05,
      "loss": 0.0043,
      "step": 37040
    },
    {
      "epoch": 2.702604128674593,
      "grad_norm": 0.11558779329061508,
      "learning_rate": 2.2973958713254067e-05,
      "loss": 0.0048,
      "step": 37050
    },
    {
      "epoch": 2.7033335764826028,
      "grad_norm": 0.37494757771492004,
      "learning_rate": 2.2966664235173974e-05,
      "loss": 0.0034,
      "step": 37060
    },
    {
      "epoch": 2.704063024290612,
      "grad_norm": 0.14462785422801971,
      "learning_rate": 2.2959369757093882e-05,
      "loss": 0.0028,
      "step": 37070
    },
    {
      "epoch": 2.7047924720986214,
      "grad_norm": 0.08672377467155457,
      "learning_rate": 2.2952075279013786e-05,
      "loss": 0.0027,
      "step": 37080
    },
    {
      "epoch": 2.705521919906631,
      "grad_norm": 0.11534201353788376,
      "learning_rate": 2.2944780800933694e-05,
      "loss": 0.0027,
      "step": 37090
    },
    {
      "epoch": 2.70625136771464,
      "grad_norm": 0.23971439898014069,
      "learning_rate": 2.29374863228536e-05,
      "loss": 0.0033,
      "step": 37100
    },
    {
      "epoch": 2.706980815522649,
      "grad_norm": 0.04617708548903465,
      "learning_rate": 2.293019184477351e-05,
      "loss": 0.0034,
      "step": 37110
    },
    {
      "epoch": 2.7077102633306587,
      "grad_norm": 0.0866238996386528,
      "learning_rate": 2.2922897366693413e-05,
      "loss": 0.0025,
      "step": 37120
    },
    {
      "epoch": 2.708439711138668,
      "grad_norm": 0.7651078104972839,
      "learning_rate": 2.291560288861332e-05,
      "loss": 0.0028,
      "step": 37130
    },
    {
      "epoch": 2.7091691589466773,
      "grad_norm": 0.37481871247291565,
      "learning_rate": 2.2908308410533228e-05,
      "loss": 0.0042,
      "step": 37140
    },
    {
      "epoch": 2.709898606754687,
      "grad_norm": 0.17305921018123627,
      "learning_rate": 2.2901013932453132e-05,
      "loss": 0.0039,
      "step": 37150
    },
    {
      "epoch": 2.710628054562696,
      "grad_norm": 0.010191752575337887,
      "learning_rate": 2.2893719454373043e-05,
      "loss": 0.0033,
      "step": 37160
    },
    {
      "epoch": 2.7113575023707055,
      "grad_norm": 0.10613813251256943,
      "learning_rate": 2.2886424976292947e-05,
      "loss": 0.0042,
      "step": 37170
    },
    {
      "epoch": 2.7120869501787146,
      "grad_norm": 0.05935342609882355,
      "learning_rate": 2.287913049821285e-05,
      "loss": 0.0037,
      "step": 37180
    },
    {
      "epoch": 2.712816397986724,
      "grad_norm": 0.03235333040356636,
      "learning_rate": 2.2871836020132762e-05,
      "loss": 0.002,
      "step": 37190
    },
    {
      "epoch": 2.7135458457947332,
      "grad_norm": 0.030913839116692543,
      "learning_rate": 2.2864541542052666e-05,
      "loss": 0.0038,
      "step": 37200
    },
    {
      "epoch": 2.7142752936027428,
      "grad_norm": 0.34488818049430847,
      "learning_rate": 2.2857247063972574e-05,
      "loss": 0.0027,
      "step": 37210
    },
    {
      "epoch": 2.715004741410752,
      "grad_norm": 0.08693139255046844,
      "learning_rate": 2.284995258589248e-05,
      "loss": 0.0037,
      "step": 37220
    },
    {
      "epoch": 2.7157341892187614,
      "grad_norm": 0.08713261038064957,
      "learning_rate": 2.2842658107812386e-05,
      "loss": 0.0031,
      "step": 37230
    },
    {
      "epoch": 2.716463637026771,
      "grad_norm": 0.030227189883589745,
      "learning_rate": 2.2835363629732293e-05,
      "loss": 0.003,
      "step": 37240
    },
    {
      "epoch": 2.71719308483478,
      "grad_norm": 0.6174674034118652,
      "learning_rate": 2.28280691516522e-05,
      "loss": 0.004,
      "step": 37250
    },
    {
      "epoch": 2.717922532642789,
      "grad_norm": 0.14902545511722565,
      "learning_rate": 2.2820774673572108e-05,
      "loss": 0.0029,
      "step": 37260
    },
    {
      "epoch": 2.7186519804507987,
      "grad_norm": 0.11536184698343277,
      "learning_rate": 2.2813480195492012e-05,
      "loss": 0.0034,
      "step": 37270
    },
    {
      "epoch": 2.7193814282588082,
      "grad_norm": 0.05796568840742111,
      "learning_rate": 2.280618571741192e-05,
      "loss": 0.0033,
      "step": 37280
    },
    {
      "epoch": 2.7201108760668173,
      "grad_norm": 0.11459394544363022,
      "learning_rate": 2.2798891239331827e-05,
      "loss": 0.0042,
      "step": 37290
    },
    {
      "epoch": 2.720840323874827,
      "grad_norm": 0.3460277020931244,
      "learning_rate": 2.279159676125173e-05,
      "loss": 0.0051,
      "step": 37300
    },
    {
      "epoch": 2.721569771682836,
      "grad_norm": 0.1435166597366333,
      "learning_rate": 2.2784302283171642e-05,
      "loss": 0.0045,
      "step": 37310
    },
    {
      "epoch": 2.7222992194908455,
      "grad_norm": 0.2924249768257141,
      "learning_rate": 2.2777007805091547e-05,
      "loss": 0.0033,
      "step": 37320
    },
    {
      "epoch": 2.7230286672988546,
      "grad_norm": 0.23096178472042084,
      "learning_rate": 2.276971332701145e-05,
      "loss": 0.0038,
      "step": 37330
    },
    {
      "epoch": 2.723758115106864,
      "grad_norm": 0.4025668501853943,
      "learning_rate": 2.276241884893136e-05,
      "loss": 0.0039,
      "step": 37340
    },
    {
      "epoch": 2.7244875629148737,
      "grad_norm": 0.4317835867404938,
      "learning_rate": 2.2755124370851266e-05,
      "loss": 0.0035,
      "step": 37350
    },
    {
      "epoch": 2.725217010722883,
      "grad_norm": 0.23005634546279907,
      "learning_rate": 2.2747829892771173e-05,
      "loss": 0.0042,
      "step": 37360
    },
    {
      "epoch": 2.725946458530892,
      "grad_norm": 0.01070050522685051,
      "learning_rate": 2.274053541469108e-05,
      "loss": 0.0041,
      "step": 37370
    },
    {
      "epoch": 2.7266759063389014,
      "grad_norm": 0.6223515868186951,
      "learning_rate": 2.2733240936610985e-05,
      "loss": 0.0028,
      "step": 37380
    },
    {
      "epoch": 2.727405354146911,
      "grad_norm": 0.07888337224721909,
      "learning_rate": 2.2725946458530896e-05,
      "loss": 0.0036,
      "step": 37390
    },
    {
      "epoch": 2.72813480195492,
      "grad_norm": 0.2881467342376709,
      "learning_rate": 2.27186519804508e-05,
      "loss": 0.0031,
      "step": 37400
    },
    {
      "epoch": 2.7288642497629296,
      "grad_norm": 0.3463856279850006,
      "learning_rate": 2.2711357502370708e-05,
      "loss": 0.0031,
      "step": 37410
    },
    {
      "epoch": 2.7295936975709387,
      "grad_norm": 0.17268578708171844,
      "learning_rate": 2.2704063024290615e-05,
      "loss": 0.0032,
      "step": 37420
    },
    {
      "epoch": 2.7303231453789483,
      "grad_norm": 0.25956085324287415,
      "learning_rate": 2.269676854621052e-05,
      "loss": 0.0031,
      "step": 37430
    },
    {
      "epoch": 2.7310525931869574,
      "grad_norm": 0.08797290176153183,
      "learning_rate": 2.2689474068130427e-05,
      "loss": 0.0038,
      "step": 37440
    },
    {
      "epoch": 2.731782040994967,
      "grad_norm": 0.18305769562721252,
      "learning_rate": 2.2682179590050334e-05,
      "loss": 0.0034,
      "step": 37450
    },
    {
      "epoch": 2.732511488802976,
      "grad_norm": 0.09432398527860641,
      "learning_rate": 2.267488511197024e-05,
      "loss": 0.0032,
      "step": 37460
    },
    {
      "epoch": 2.7332409366109855,
      "grad_norm": 0.4338790476322174,
      "learning_rate": 2.2667590633890146e-05,
      "loss": 0.0042,
      "step": 37470
    },
    {
      "epoch": 2.7339703844189946,
      "grad_norm": 0.10161013901233673,
      "learning_rate": 2.2660296155810053e-05,
      "loss": 0.0036,
      "step": 37480
    },
    {
      "epoch": 2.734699832227004,
      "grad_norm": 0.8306877017021179,
      "learning_rate": 2.265300167772996e-05,
      "loss": 0.004,
      "step": 37490
    },
    {
      "epoch": 2.7354292800350137,
      "grad_norm": 0.26316264271736145,
      "learning_rate": 2.2645707199649865e-05,
      "loss": 0.0042,
      "step": 37500
    },
    {
      "epoch": 2.736158727843023,
      "grad_norm": 0.7344560623168945,
      "learning_rate": 2.2638412721569773e-05,
      "loss": 0.0035,
      "step": 37510
    },
    {
      "epoch": 2.736888175651032,
      "grad_norm": 0.23659159243106842,
      "learning_rate": 2.263111824348968e-05,
      "loss": 0.0039,
      "step": 37520
    },
    {
      "epoch": 2.7376176234590415,
      "grad_norm": 0.1735096424818039,
      "learning_rate": 2.2623823765409584e-05,
      "loss": 0.0025,
      "step": 37530
    },
    {
      "epoch": 2.738347071267051,
      "grad_norm": 0.8695971965789795,
      "learning_rate": 2.2616529287329495e-05,
      "loss": 0.0041,
      "step": 37540
    },
    {
      "epoch": 2.73907651907506,
      "grad_norm": 0.05778428539633751,
      "learning_rate": 2.26092348092494e-05,
      "loss": 0.0036,
      "step": 37550
    },
    {
      "epoch": 2.7398059668830697,
      "grad_norm": 0.058480728417634964,
      "learning_rate": 2.2601940331169304e-05,
      "loss": 0.004,
      "step": 37560
    },
    {
      "epoch": 2.7405354146910788,
      "grad_norm": 0.013990451581776142,
      "learning_rate": 2.2594645853089214e-05,
      "loss": 0.0027,
      "step": 37570
    },
    {
      "epoch": 2.7412648624990883,
      "grad_norm": 0.1152891218662262,
      "learning_rate": 2.258735137500912e-05,
      "loss": 0.0036,
      "step": 37580
    },
    {
      "epoch": 2.7419943103070974,
      "grad_norm": 0.007758257444947958,
      "learning_rate": 2.2580056896929026e-05,
      "loss": 0.0032,
      "step": 37590
    },
    {
      "epoch": 2.742723758115107,
      "grad_norm": 0.20145419239997864,
      "learning_rate": 2.2572762418848934e-05,
      "loss": 0.0043,
      "step": 37600
    },
    {
      "epoch": 2.7434532059231165,
      "grad_norm": 0.030773764476180077,
      "learning_rate": 2.2565467940768838e-05,
      "loss": 0.0032,
      "step": 37610
    },
    {
      "epoch": 2.7441826537311256,
      "grad_norm": 0.22971908748149872,
      "learning_rate": 2.2558173462688745e-05,
      "loss": 0.0041,
      "step": 37620
    },
    {
      "epoch": 2.7449121015391347,
      "grad_norm": 0.28814661502838135,
      "learning_rate": 2.2550878984608653e-05,
      "loss": 0.004,
      "step": 37630
    },
    {
      "epoch": 2.745641549347144,
      "grad_norm": 0.11534583568572998,
      "learning_rate": 2.254358450652856e-05,
      "loss": 0.0047,
      "step": 37640
    },
    {
      "epoch": 2.7463709971551538,
      "grad_norm": 0.25879380106925964,
      "learning_rate": 2.2536290028448465e-05,
      "loss": 0.0033,
      "step": 37650
    },
    {
      "epoch": 2.747100444963163,
      "grad_norm": 0.09771774709224701,
      "learning_rate": 2.2528995550368372e-05,
      "loss": 0.0044,
      "step": 37660
    },
    {
      "epoch": 2.747829892771172,
      "grad_norm": 0.11535174399614334,
      "learning_rate": 2.252170107228828e-05,
      "loss": 0.0025,
      "step": 37670
    },
    {
      "epoch": 2.7485593405791815,
      "grad_norm": 0.18039031326770782,
      "learning_rate": 2.2514406594208184e-05,
      "loss": 0.0037,
      "step": 37680
    },
    {
      "epoch": 2.749288788387191,
      "grad_norm": 0.14470286667346954,
      "learning_rate": 2.250711211612809e-05,
      "loss": 0.0035,
      "step": 37690
    },
    {
      "epoch": 2.7500182361952,
      "grad_norm": 0.14499428868293762,
      "learning_rate": 2.2499817638048e-05,
      "loss": 0.0051,
      "step": 37700
    },
    {
      "epoch": 2.7507476840032097,
      "grad_norm": 0.14378388226032257,
      "learning_rate": 2.2492523159967903e-05,
      "loss": 0.0031,
      "step": 37710
    },
    {
      "epoch": 2.751477131811219,
      "grad_norm": 0.08717761933803558,
      "learning_rate": 2.2485228681887814e-05,
      "loss": 0.0032,
      "step": 37720
    },
    {
      "epoch": 2.7522065796192283,
      "grad_norm": 0.06580769270658493,
      "learning_rate": 2.2477934203807718e-05,
      "loss": 0.0045,
      "step": 37730
    },
    {
      "epoch": 2.7529360274272374,
      "grad_norm": 0.34529149532318115,
      "learning_rate": 2.2470639725727625e-05,
      "loss": 0.0061,
      "step": 37740
    },
    {
      "epoch": 2.753665475235247,
      "grad_norm": 0.08806971460580826,
      "learning_rate": 2.2463345247647533e-05,
      "loss": 0.0046,
      "step": 37750
    },
    {
      "epoch": 2.7543949230432565,
      "grad_norm": 0.08623731881380081,
      "learning_rate": 2.2456050769567437e-05,
      "loss": 0.0041,
      "step": 37760
    },
    {
      "epoch": 2.7551243708512656,
      "grad_norm": 0.05844568833708763,
      "learning_rate": 2.2448756291487345e-05,
      "loss": 0.0024,
      "step": 37770
    },
    {
      "epoch": 2.7558538186592747,
      "grad_norm": 0.31693413853645325,
      "learning_rate": 2.2441461813407252e-05,
      "loss": 0.0036,
      "step": 37780
    },
    {
      "epoch": 2.7565832664672842,
      "grad_norm": 0.03773808106780052,
      "learning_rate": 2.243416733532716e-05,
      "loss": 0.0028,
      "step": 37790
    },
    {
      "epoch": 2.757312714275294,
      "grad_norm": 0.26363423466682434,
      "learning_rate": 2.2426872857247064e-05,
      "loss": 0.0026,
      "step": 37800
    },
    {
      "epoch": 2.758042162083303,
      "grad_norm": 0.4812571108341217,
      "learning_rate": 2.241957837916697e-05,
      "loss": 0.0033,
      "step": 37810
    },
    {
      "epoch": 2.7587716098913124,
      "grad_norm": 0.10888057202100754,
      "learning_rate": 2.241228390108688e-05,
      "loss": 0.0045,
      "step": 37820
    },
    {
      "epoch": 2.7595010576993215,
      "grad_norm": 0.02978716790676117,
      "learning_rate": 2.2404989423006783e-05,
      "loss": 0.0031,
      "step": 37830
    },
    {
      "epoch": 2.760230505507331,
      "grad_norm": 0.08734766393899918,
      "learning_rate": 2.239769494492669e-05,
      "loss": 0.0032,
      "step": 37840
    },
    {
      "epoch": 2.76095995331534,
      "grad_norm": 0.43016570806503296,
      "learning_rate": 2.2390400466846598e-05,
      "loss": 0.0034,
      "step": 37850
    },
    {
      "epoch": 2.7616894011233497,
      "grad_norm": 0.47558465600013733,
      "learning_rate": 2.2383105988766502e-05,
      "loss": 0.0026,
      "step": 37860
    },
    {
      "epoch": 2.762418848931359,
      "grad_norm": 0.13335996866226196,
      "learning_rate": 2.2375811510686413e-05,
      "loss": 0.0033,
      "step": 37870
    },
    {
      "epoch": 2.7631482967393683,
      "grad_norm": 0.08692620694637299,
      "learning_rate": 2.2368517032606317e-05,
      "loss": 0.004,
      "step": 37880
    },
    {
      "epoch": 2.7638777445473774,
      "grad_norm": 0.5999047756195068,
      "learning_rate": 2.2361222554526225e-05,
      "loss": 0.0046,
      "step": 37890
    },
    {
      "epoch": 2.764607192355387,
      "grad_norm": 0.14333151280879974,
      "learning_rate": 2.2353928076446132e-05,
      "loss": 0.003,
      "step": 37900
    },
    {
      "epoch": 2.7653366401633965,
      "grad_norm": 0.23057308793067932,
      "learning_rate": 2.2346633598366037e-05,
      "loss": 0.0051,
      "step": 37910
    },
    {
      "epoch": 2.7660660879714056,
      "grad_norm": 0.17340531945228577,
      "learning_rate": 2.2339339120285947e-05,
      "loss": 0.0028,
      "step": 37920
    },
    {
      "epoch": 2.7667955357794147,
      "grad_norm": 0.08621499687433243,
      "learning_rate": 2.233204464220585e-05,
      "loss": 0.0026,
      "step": 37930
    },
    {
      "epoch": 2.7675249835874243,
      "grad_norm": 0.058321867138147354,
      "learning_rate": 2.2324750164125756e-05,
      "loss": 0.0034,
      "step": 37940
    },
    {
      "epoch": 2.768254431395434,
      "grad_norm": 0.3460210859775543,
      "learning_rate": 2.2317455686045667e-05,
      "loss": 0.003,
      "step": 37950
    },
    {
      "epoch": 2.768983879203443,
      "grad_norm": 0.2583357095718384,
      "learning_rate": 2.231016120796557e-05,
      "loss": 0.0028,
      "step": 37960
    },
    {
      "epoch": 2.7697133270114525,
      "grad_norm": 0.23071198165416718,
      "learning_rate": 2.230286672988548e-05,
      "loss": 0.0043,
      "step": 37970
    },
    {
      "epoch": 2.7704427748194616,
      "grad_norm": 0.5585180521011353,
      "learning_rate": 2.2295572251805386e-05,
      "loss": 0.004,
      "step": 37980
    },
    {
      "epoch": 2.771172222627471,
      "grad_norm": 0.007981190457940102,
      "learning_rate": 2.228827777372529e-05,
      "loss": 0.0032,
      "step": 37990
    },
    {
      "epoch": 2.77190167043548,
      "grad_norm": 0.08562039583921432,
      "learning_rate": 2.2280983295645198e-05,
      "loss": 0.002,
      "step": 38000
    },
    {
      "epoch": 2.7726311182434897,
      "grad_norm": 0.20125451683998108,
      "learning_rate": 2.2273688817565105e-05,
      "loss": 0.0037,
      "step": 38010
    },
    {
      "epoch": 2.7733605660514993,
      "grad_norm": 0.11563955247402191,
      "learning_rate": 2.2266394339485013e-05,
      "loss": 0.0036,
      "step": 38020
    },
    {
      "epoch": 2.7740900138595084,
      "grad_norm": 0.2018446922302246,
      "learning_rate": 2.2259099861404917e-05,
      "loss": 0.0029,
      "step": 38030
    },
    {
      "epoch": 2.7748194616675175,
      "grad_norm": 0.14512769877910614,
      "learning_rate": 2.2251805383324824e-05,
      "loss": 0.0035,
      "step": 38040
    },
    {
      "epoch": 2.775548909475527,
      "grad_norm": 0.05858546122908592,
      "learning_rate": 2.2244510905244732e-05,
      "loss": 0.0038,
      "step": 38050
    },
    {
      "epoch": 2.7762783572835366,
      "grad_norm": 0.0887819156050682,
      "learning_rate": 2.2237216427164636e-05,
      "loss": 0.0026,
      "step": 38060
    },
    {
      "epoch": 2.7770078050915457,
      "grad_norm": 0.029199302196502686,
      "learning_rate": 2.2229921949084543e-05,
      "loss": 0.0027,
      "step": 38070
    },
    {
      "epoch": 2.777737252899555,
      "grad_norm": 0.058360885828733444,
      "learning_rate": 2.222262747100445e-05,
      "loss": 0.0034,
      "step": 38080
    },
    {
      "epoch": 2.7784667007075643,
      "grad_norm": 0.22998127341270447,
      "learning_rate": 2.2215332992924355e-05,
      "loss": 0.0044,
      "step": 38090
    },
    {
      "epoch": 2.779196148515574,
      "grad_norm": 0.11620683968067169,
      "learning_rate": 2.2208038514844266e-05,
      "loss": 0.0037,
      "step": 38100
    },
    {
      "epoch": 2.779925596323583,
      "grad_norm": 0.2886746823787689,
      "learning_rate": 2.220074403676417e-05,
      "loss": 0.0042,
      "step": 38110
    },
    {
      "epoch": 2.7806550441315925,
      "grad_norm": 0.008798116818070412,
      "learning_rate": 2.2193449558684078e-05,
      "loss": 0.0035,
      "step": 38120
    },
    {
      "epoch": 2.7813844919396016,
      "grad_norm": 0.2762945592403412,
      "learning_rate": 2.2186155080603985e-05,
      "loss": 0.0036,
      "step": 38130
    },
    {
      "epoch": 2.782113939747611,
      "grad_norm": 0.2308698445558548,
      "learning_rate": 2.217886060252389e-05,
      "loss": 0.0028,
      "step": 38140
    },
    {
      "epoch": 2.78284338755562,
      "grad_norm": 0.08611169457435608,
      "learning_rate": 2.2171566124443797e-05,
      "loss": 0.0028,
      "step": 38150
    },
    {
      "epoch": 2.7835728353636298,
      "grad_norm": 0.11617208272218704,
      "learning_rate": 2.2164271646363704e-05,
      "loss": 0.0037,
      "step": 38160
    },
    {
      "epoch": 2.7843022831716393,
      "grad_norm": 0.4886515438556671,
      "learning_rate": 2.215697716828361e-05,
      "loss": 0.0036,
      "step": 38170
    },
    {
      "epoch": 2.7850317309796484,
      "grad_norm": 0.013155109249055386,
      "learning_rate": 2.2149682690203516e-05,
      "loss": 0.0036,
      "step": 38180
    },
    {
      "epoch": 2.7857611787876575,
      "grad_norm": 0.46003469824790955,
      "learning_rate": 2.2142388212123424e-05,
      "loss": 0.0037,
      "step": 38190
    },
    {
      "epoch": 2.786490626595667,
      "grad_norm": 0.43160808086395264,
      "learning_rate": 2.213509373404333e-05,
      "loss": 0.0041,
      "step": 38200
    },
    {
      "epoch": 2.7872200744036766,
      "grad_norm": 0.2011691778898239,
      "learning_rate": 2.2127799255963235e-05,
      "loss": 0.0027,
      "step": 38210
    },
    {
      "epoch": 2.7879495222116857,
      "grad_norm": 0.259179025888443,
      "learning_rate": 2.2120504777883143e-05,
      "loss": 0.0015,
      "step": 38220
    },
    {
      "epoch": 2.7886789700196952,
      "grad_norm": 0.17288550734519958,
      "learning_rate": 2.211321029980305e-05,
      "loss": 0.004,
      "step": 38230
    },
    {
      "epoch": 2.7894084178277043,
      "grad_norm": 0.37433135509490967,
      "learning_rate": 2.2105915821722955e-05,
      "loss": 0.0022,
      "step": 38240
    },
    {
      "epoch": 2.790137865635714,
      "grad_norm": 0.28808721899986267,
      "learning_rate": 2.2098621343642865e-05,
      "loss": 0.0034,
      "step": 38250
    },
    {
      "epoch": 2.790867313443723,
      "grad_norm": 0.3451196849346161,
      "learning_rate": 2.209132686556277e-05,
      "loss": 0.0031,
      "step": 38260
    },
    {
      "epoch": 2.7915967612517325,
      "grad_norm": 0.14463531970977783,
      "learning_rate": 2.2084032387482674e-05,
      "loss": 0.0038,
      "step": 38270
    },
    {
      "epoch": 2.792326209059742,
      "grad_norm": 0.6446895599365234,
      "learning_rate": 2.2076737909402585e-05,
      "loss": 0.0037,
      "step": 38280
    },
    {
      "epoch": 2.793055656867751,
      "grad_norm": 0.11513049155473709,
      "learning_rate": 2.206944343132249e-05,
      "loss": 0.0037,
      "step": 38290
    },
    {
      "epoch": 2.7937851046757602,
      "grad_norm": 0.06038951501250267,
      "learning_rate": 2.2062148953242396e-05,
      "loss": 0.0029,
      "step": 38300
    },
    {
      "epoch": 2.79451455248377,
      "grad_norm": 0.13732768595218658,
      "learning_rate": 2.2054854475162304e-05,
      "loss": 0.0044,
      "step": 38310
    },
    {
      "epoch": 2.7952440002917793,
      "grad_norm": 0.20143428444862366,
      "learning_rate": 2.2047559997082208e-05,
      "loss": 0.0041,
      "step": 38320
    },
    {
      "epoch": 2.7959734480997884,
      "grad_norm": 0.11411510407924652,
      "learning_rate": 2.2040265519002116e-05,
      "loss": 0.0024,
      "step": 38330
    },
    {
      "epoch": 2.7967028959077975,
      "grad_norm": 0.3029661476612091,
      "learning_rate": 2.2032971040922023e-05,
      "loss": 0.0026,
      "step": 38340
    },
    {
      "epoch": 2.797432343715807,
      "grad_norm": 0.20650185644626617,
      "learning_rate": 2.202567656284193e-05,
      "loss": 0.004,
      "step": 38350
    },
    {
      "epoch": 2.7981617915238166,
      "grad_norm": 0.12032546103000641,
      "learning_rate": 2.2018382084761838e-05,
      "loss": 0.0037,
      "step": 38360
    },
    {
      "epoch": 2.7988912393318257,
      "grad_norm": 0.2010204941034317,
      "learning_rate": 2.2011087606681742e-05,
      "loss": 0.004,
      "step": 38370
    },
    {
      "epoch": 2.7996206871398353,
      "grad_norm": 0.0628155916929245,
      "learning_rate": 2.200379312860165e-05,
      "loss": 0.0024,
      "step": 38380
    },
    {
      "epoch": 2.8003501349478443,
      "grad_norm": 0.029899613931775093,
      "learning_rate": 2.1996498650521557e-05,
      "loss": 0.0037,
      "step": 38390
    },
    {
      "epoch": 2.801079582755854,
      "grad_norm": 0.030308982357382774,
      "learning_rate": 2.1989204172441465e-05,
      "loss": 0.003,
      "step": 38400
    },
    {
      "epoch": 2.801809030563863,
      "grad_norm": 0.05837944522500038,
      "learning_rate": 2.198190969436137e-05,
      "loss": 0.003,
      "step": 38410
    },
    {
      "epoch": 2.8025384783718725,
      "grad_norm": 0.3110610544681549,
      "learning_rate": 2.1974615216281277e-05,
      "loss": 0.0035,
      "step": 38420
    },
    {
      "epoch": 2.803267926179882,
      "grad_norm": 0.07398983091115952,
      "learning_rate": 2.1967320738201184e-05,
      "loss": 0.004,
      "step": 38430
    },
    {
      "epoch": 2.803997373987891,
      "grad_norm": 0.25909319519996643,
      "learning_rate": 2.1960026260121088e-05,
      "loss": 0.0044,
      "step": 38440
    },
    {
      "epoch": 2.8047268217959003,
      "grad_norm": 0.03920741751790047,
      "learning_rate": 2.1952731782040996e-05,
      "loss": 0.0043,
      "step": 38450
    },
    {
      "epoch": 2.80545626960391,
      "grad_norm": 0.5448752641677856,
      "learning_rate": 2.1945437303960903e-05,
      "loss": 0.002,
      "step": 38460
    },
    {
      "epoch": 2.8061857174119194,
      "grad_norm": 0.23006834089756012,
      "learning_rate": 2.1938142825880807e-05,
      "loss": 0.0033,
      "step": 38470
    },
    {
      "epoch": 2.8069151652199285,
      "grad_norm": 0.030672065913677216,
      "learning_rate": 2.193084834780072e-05,
      "loss": 0.0034,
      "step": 38480
    },
    {
      "epoch": 2.807644613027938,
      "grad_norm": 0.3687920570373535,
      "learning_rate": 2.1923553869720622e-05,
      "loss": 0.0033,
      "step": 38490
    },
    {
      "epoch": 2.808374060835947,
      "grad_norm": 0.11560213565826416,
      "learning_rate": 2.191625939164053e-05,
      "loss": 0.0038,
      "step": 38500
    },
    {
      "epoch": 2.8091035086439566,
      "grad_norm": 0.17218635976314545,
      "learning_rate": 2.1908964913560438e-05,
      "loss": 0.0025,
      "step": 38510
    },
    {
      "epoch": 2.8098329564519657,
      "grad_norm": 0.2310630977153778,
      "learning_rate": 2.190167043548034e-05,
      "loss": 0.0027,
      "step": 38520
    },
    {
      "epoch": 2.8105624042599753,
      "grad_norm": 0.23009365797042847,
      "learning_rate": 2.189437595740025e-05,
      "loss": 0.0027,
      "step": 38530
    },
    {
      "epoch": 2.8112918520679844,
      "grad_norm": 0.4035993814468384,
      "learning_rate": 2.1887081479320157e-05,
      "loss": 0.0041,
      "step": 38540
    },
    {
      "epoch": 2.812021299875994,
      "grad_norm": 0.3456422686576843,
      "learning_rate": 2.187978700124006e-05,
      "loss": 0.0034,
      "step": 38550
    },
    {
      "epoch": 2.812750747684003,
      "grad_norm": 0.2303696870803833,
      "learning_rate": 2.187249252315997e-05,
      "loss": 0.0037,
      "step": 38560
    },
    {
      "epoch": 2.8134801954920126,
      "grad_norm": 0.28788644075393677,
      "learning_rate": 2.1865198045079876e-05,
      "loss": 0.0049,
      "step": 38570
    },
    {
      "epoch": 2.814209643300022,
      "grad_norm": 0.4923284351825714,
      "learning_rate": 2.1857903566999783e-05,
      "loss": 0.0035,
      "step": 38580
    },
    {
      "epoch": 2.814939091108031,
      "grad_norm": 0.23120956122875214,
      "learning_rate": 2.1850609088919688e-05,
      "loss": 0.0035,
      "step": 38590
    },
    {
      "epoch": 2.8156685389160403,
      "grad_norm": 0.3520658314228058,
      "learning_rate": 2.1843314610839595e-05,
      "loss": 0.0036,
      "step": 38600
    },
    {
      "epoch": 2.81639798672405,
      "grad_norm": 0.20505906641483307,
      "learning_rate": 2.1836020132759503e-05,
      "loss": 0.0034,
      "step": 38610
    },
    {
      "epoch": 2.8171274345320594,
      "grad_norm": 0.22983595728874207,
      "learning_rate": 2.1828725654679407e-05,
      "loss": 0.0038,
      "step": 38620
    },
    {
      "epoch": 2.8178568823400685,
      "grad_norm": 0.0211715716868639,
      "learning_rate": 2.1821431176599318e-05,
      "loss": 0.0042,
      "step": 38630
    },
    {
      "epoch": 2.818586330148078,
      "grad_norm": 0.12773552536964417,
      "learning_rate": 2.1814136698519222e-05,
      "loss": 0.0029,
      "step": 38640
    },
    {
      "epoch": 2.819315777956087,
      "grad_norm": 0.14374610781669617,
      "learning_rate": 2.1806842220439126e-05,
      "loss": 0.0031,
      "step": 38650
    },
    {
      "epoch": 2.8200452257640967,
      "grad_norm": 0.0590130053460598,
      "learning_rate": 2.1799547742359037e-05,
      "loss": 0.0037,
      "step": 38660
    },
    {
      "epoch": 2.8207746735721058,
      "grad_norm": 0.4322206974029541,
      "learning_rate": 2.179225326427894e-05,
      "loss": 0.0033,
      "step": 38670
    },
    {
      "epoch": 2.8215041213801153,
      "grad_norm": 0.17271417379379272,
      "learning_rate": 2.178495878619885e-05,
      "loss": 0.0046,
      "step": 38680
    },
    {
      "epoch": 2.822233569188125,
      "grad_norm": 0.058178387582302094,
      "learning_rate": 2.1777664308118756e-05,
      "loss": 0.003,
      "step": 38690
    },
    {
      "epoch": 2.822963016996134,
      "grad_norm": 0.42064031958580017,
      "learning_rate": 2.177036983003866e-05,
      "loss": 0.0043,
      "step": 38700
    },
    {
      "epoch": 2.823692464804143,
      "grad_norm": 0.11567343026399612,
      "learning_rate": 2.1763075351958568e-05,
      "loss": 0.0029,
      "step": 38710
    },
    {
      "epoch": 2.8244219126121526,
      "grad_norm": 0.061213091015815735,
      "learning_rate": 2.1755780873878475e-05,
      "loss": 0.0038,
      "step": 38720
    },
    {
      "epoch": 2.825151360420162,
      "grad_norm": 0.2603943645954132,
      "learning_rate": 2.1748486395798383e-05,
      "loss": 0.0031,
      "step": 38730
    },
    {
      "epoch": 2.8258808082281712,
      "grad_norm": 0.030200228095054626,
      "learning_rate": 2.1741191917718287e-05,
      "loss": 0.004,
      "step": 38740
    },
    {
      "epoch": 2.8266102560361808,
      "grad_norm": 0.11523504555225372,
      "learning_rate": 2.1733897439638195e-05,
      "loss": 0.0038,
      "step": 38750
    },
    {
      "epoch": 2.82733970384419,
      "grad_norm": 0.340943843126297,
      "learning_rate": 2.1726602961558102e-05,
      "loss": 0.0036,
      "step": 38760
    },
    {
      "epoch": 2.8280691516521994,
      "grad_norm": 0.07157017290592194,
      "learning_rate": 2.1719308483478006e-05,
      "loss": 0.0043,
      "step": 38770
    },
    {
      "epoch": 2.8287985994602085,
      "grad_norm": 0.2014680951833725,
      "learning_rate": 2.1712014005397914e-05,
      "loss": 0.0044,
      "step": 38780
    },
    {
      "epoch": 2.829528047268218,
      "grad_norm": 0.27928411960601807,
      "learning_rate": 2.170471952731782e-05,
      "loss": 0.0024,
      "step": 38790
    },
    {
      "epoch": 2.830257495076227,
      "grad_norm": 0.14312370121479034,
      "learning_rate": 2.1697425049237725e-05,
      "loss": 0.0036,
      "step": 38800
    },
    {
      "epoch": 2.8309869428842367,
      "grad_norm": 0.31694790720939636,
      "learning_rate": 2.1690130571157636e-05,
      "loss": 0.0031,
      "step": 38810
    },
    {
      "epoch": 2.831716390692246,
      "grad_norm": 0.11588761955499649,
      "learning_rate": 2.168283609307754e-05,
      "loss": 0.0022,
      "step": 38820
    },
    {
      "epoch": 2.8324458385002553,
      "grad_norm": 0.01093287579715252,
      "learning_rate": 2.1675541614997448e-05,
      "loss": 0.0036,
      "step": 38830
    },
    {
      "epoch": 2.833175286308265,
      "grad_norm": 0.17329061031341553,
      "learning_rate": 2.1668247136917356e-05,
      "loss": 0.0041,
      "step": 38840
    },
    {
      "epoch": 2.833904734116274,
      "grad_norm": 0.18675431609153748,
      "learning_rate": 2.166095265883726e-05,
      "loss": 0.0039,
      "step": 38850
    },
    {
      "epoch": 2.834634181924283,
      "grad_norm": 0.460437148809433,
      "learning_rate": 2.165365818075717e-05,
      "loss": 0.0042,
      "step": 38860
    },
    {
      "epoch": 2.8353636297322926,
      "grad_norm": 0.11533281952142715,
      "learning_rate": 2.1646363702677075e-05,
      "loss": 0.0031,
      "step": 38870
    },
    {
      "epoch": 2.836093077540302,
      "grad_norm": 0.058070067316293716,
      "learning_rate": 2.1639069224596982e-05,
      "loss": 0.0033,
      "step": 38880
    },
    {
      "epoch": 2.8368225253483113,
      "grad_norm": 0.08682841062545776,
      "learning_rate": 2.163177474651689e-05,
      "loss": 0.004,
      "step": 38890
    },
    {
      "epoch": 2.837551973156321,
      "grad_norm": 0.17524509131908417,
      "learning_rate": 2.1624480268436794e-05,
      "loss": 0.0034,
      "step": 38900
    },
    {
      "epoch": 2.83828142096433,
      "grad_norm": 0.030085356906056404,
      "learning_rate": 2.16171857903567e-05,
      "loss": 0.0033,
      "step": 38910
    },
    {
      "epoch": 2.8390108687723394,
      "grad_norm": 0.3542415201663971,
      "learning_rate": 2.160989131227661e-05,
      "loss": 0.0028,
      "step": 38920
    },
    {
      "epoch": 2.8397403165803485,
      "grad_norm": 0.011177930980920792,
      "learning_rate": 2.1602596834196513e-05,
      "loss": 0.0038,
      "step": 38930
    },
    {
      "epoch": 2.840469764388358,
      "grad_norm": 0.23014132678508759,
      "learning_rate": 2.159530235611642e-05,
      "loss": 0.0043,
      "step": 38940
    },
    {
      "epoch": 2.8411992121963676,
      "grad_norm": 0.3876788318157196,
      "learning_rate": 2.1588007878036328e-05,
      "loss": 0.0036,
      "step": 38950
    },
    {
      "epoch": 2.8419286600043767,
      "grad_norm": 0.43139776587486267,
      "learning_rate": 2.1580713399956236e-05,
      "loss": 0.0034,
      "step": 38960
    },
    {
      "epoch": 2.842658107812386,
      "grad_norm": 0.22999799251556396,
      "learning_rate": 2.157341892187614e-05,
      "loss": 0.0042,
      "step": 38970
    },
    {
      "epoch": 2.8433875556203954,
      "grad_norm": 0.14404594898223877,
      "learning_rate": 2.1566124443796047e-05,
      "loss": 0.0028,
      "step": 38980
    },
    {
      "epoch": 2.844117003428405,
      "grad_norm": 0.10125076025724411,
      "learning_rate": 2.1558829965715955e-05,
      "loss": 0.0044,
      "step": 38990
    },
    {
      "epoch": 2.844846451236414,
      "grad_norm": 0.4600328505039215,
      "learning_rate": 2.155153548763586e-05,
      "loss": 0.0031,
      "step": 39000
    },
    {
      "epoch": 2.845575899044423,
      "grad_norm": 0.20156247913837433,
      "learning_rate": 2.154424100955577e-05,
      "loss": 0.004,
      "step": 39010
    },
    {
      "epoch": 2.8463053468524326,
      "grad_norm": 0.031081268563866615,
      "learning_rate": 2.1536946531475674e-05,
      "loss": 0.0029,
      "step": 39020
    },
    {
      "epoch": 2.847034794660442,
      "grad_norm": 0.22738783061504364,
      "learning_rate": 2.1529652053395578e-05,
      "loss": 0.0023,
      "step": 39030
    },
    {
      "epoch": 2.8477642424684513,
      "grad_norm": 0.05892590433359146,
      "learning_rate": 2.152235757531549e-05,
      "loss": 0.0043,
      "step": 39040
    },
    {
      "epoch": 2.848493690276461,
      "grad_norm": 0.5236731171607971,
      "learning_rate": 2.1515063097235393e-05,
      "loss": 0.0028,
      "step": 39050
    },
    {
      "epoch": 2.84922313808447,
      "grad_norm": 0.09125325083732605,
      "learning_rate": 2.15077686191553e-05,
      "loss": 0.0053,
      "step": 39060
    },
    {
      "epoch": 2.8499525858924795,
      "grad_norm": 0.1445411592721939,
      "learning_rate": 2.150047414107521e-05,
      "loss": 0.0019,
      "step": 39070
    },
    {
      "epoch": 2.8506820337004886,
      "grad_norm": 0.22984375059604645,
      "learning_rate": 2.1493179662995113e-05,
      "loss": 0.0029,
      "step": 39080
    },
    {
      "epoch": 2.851411481508498,
      "grad_norm": 0.48223909735679626,
      "learning_rate": 2.148588518491502e-05,
      "loss": 0.0032,
      "step": 39090
    },
    {
      "epoch": 2.8521409293165076,
      "grad_norm": 0.37339192628860474,
      "learning_rate": 2.1478590706834928e-05,
      "loss": 0.0021,
      "step": 39100
    },
    {
      "epoch": 2.8528703771245167,
      "grad_norm": 0.16843564808368683,
      "learning_rate": 2.1471296228754835e-05,
      "loss": 0.0057,
      "step": 39110
    },
    {
      "epoch": 2.853599824932526,
      "grad_norm": 0.14470236003398895,
      "learning_rate": 2.146400175067474e-05,
      "loss": 0.0032,
      "step": 39120
    },
    {
      "epoch": 2.8543292727405354,
      "grad_norm": 0.11559496074914932,
      "learning_rate": 2.1456707272594647e-05,
      "loss": 0.0033,
      "step": 39130
    },
    {
      "epoch": 2.855058720548545,
      "grad_norm": 0.011047731153666973,
      "learning_rate": 2.1449412794514554e-05,
      "loss": 0.0044,
      "step": 39140
    },
    {
      "epoch": 2.855788168356554,
      "grad_norm": 0.28849077224731445,
      "learning_rate": 2.144211831643446e-05,
      "loss": 0.0025,
      "step": 39150
    },
    {
      "epoch": 2.8565176161645636,
      "grad_norm": 0.17192339897155762,
      "learning_rate": 2.1434823838354366e-05,
      "loss": 0.0041,
      "step": 39160
    },
    {
      "epoch": 2.8572470639725727,
      "grad_norm": 0.24653704464435577,
      "learning_rate": 2.1427529360274274e-05,
      "loss": 0.0046,
      "step": 39170
    },
    {
      "epoch": 2.857976511780582,
      "grad_norm": 0.22967691719532013,
      "learning_rate": 2.1420234882194178e-05,
      "loss": 0.0033,
      "step": 39180
    },
    {
      "epoch": 2.8587059595885913,
      "grad_norm": 0.4566885232925415,
      "learning_rate": 2.141294040411409e-05,
      "loss": 0.0042,
      "step": 39190
    },
    {
      "epoch": 2.859435407396601,
      "grad_norm": 0.28705596923828125,
      "learning_rate": 2.1405645926033993e-05,
      "loss": 0.0024,
      "step": 39200
    },
    {
      "epoch": 2.86016485520461,
      "grad_norm": 0.032410360872745514,
      "learning_rate": 2.13983514479539e-05,
      "loss": 0.0041,
      "step": 39210
    },
    {
      "epoch": 2.8608943030126195,
      "grad_norm": 0.14492183923721313,
      "learning_rate": 2.1391056969873808e-05,
      "loss": 0.0033,
      "step": 39220
    },
    {
      "epoch": 2.8616237508206286,
      "grad_norm": 0.19901807606220245,
      "learning_rate": 2.1383762491793712e-05,
      "loss": 0.0038,
      "step": 39230
    },
    {
      "epoch": 2.862353198628638,
      "grad_norm": 0.4039568603038788,
      "learning_rate": 2.137646801371362e-05,
      "loss": 0.0042,
      "step": 39240
    },
    {
      "epoch": 2.8630826464366477,
      "grad_norm": 0.12526874244213104,
      "learning_rate": 2.1369173535633527e-05,
      "loss": 0.0039,
      "step": 39250
    },
    {
      "epoch": 2.8638120942446568,
      "grad_norm": 0.0590645968914032,
      "learning_rate": 2.136187905755343e-05,
      "loss": 0.0038,
      "step": 39260
    },
    {
      "epoch": 2.864541542052666,
      "grad_norm": 0.11573200672864914,
      "learning_rate": 2.135458457947334e-05,
      "loss": 0.0022,
      "step": 39270
    },
    {
      "epoch": 2.8652709898606754,
      "grad_norm": 0.4850960671901703,
      "learning_rate": 2.1347290101393246e-05,
      "loss": 0.0028,
      "step": 39280
    },
    {
      "epoch": 2.866000437668685,
      "grad_norm": 0.33672070503234863,
      "learning_rate": 2.1339995623313154e-05,
      "loss": 0.0038,
      "step": 39290
    },
    {
      "epoch": 2.866729885476694,
      "grad_norm": 0.3235633969306946,
      "learning_rate": 2.1332701145233058e-05,
      "loss": 0.0032,
      "step": 39300
    },
    {
      "epoch": 2.8674593332847036,
      "grad_norm": 0.14411723613739014,
      "learning_rate": 2.1325406667152965e-05,
      "loss": 0.0025,
      "step": 39310
    },
    {
      "epoch": 2.8681887810927127,
      "grad_norm": 0.20137347280979156,
      "learning_rate": 2.1318112189072873e-05,
      "loss": 0.003,
      "step": 39320
    },
    {
      "epoch": 2.8689182289007222,
      "grad_norm": 0.2007962018251419,
      "learning_rate": 2.1310817710992777e-05,
      "loss": 0.0041,
      "step": 39330
    },
    {
      "epoch": 2.8696476767087313,
      "grad_norm": 0.31370118260383606,
      "learning_rate": 2.1303523232912688e-05,
      "loss": 0.004,
      "step": 39340
    },
    {
      "epoch": 2.870377124516741,
      "grad_norm": 0.11505767703056335,
      "learning_rate": 2.1296228754832592e-05,
      "loss": 0.0041,
      "step": 39350
    },
    {
      "epoch": 2.8711065723247504,
      "grad_norm": 0.3920633792877197,
      "learning_rate": 2.12889342767525e-05,
      "loss": 0.0048,
      "step": 39360
    },
    {
      "epoch": 2.8718360201327595,
      "grad_norm": 0.17943643033504486,
      "learning_rate": 2.1281639798672407e-05,
      "loss": 0.0037,
      "step": 39370
    },
    {
      "epoch": 2.8725654679407686,
      "grad_norm": 0.14516356587409973,
      "learning_rate": 2.127434532059231e-05,
      "loss": 0.0029,
      "step": 39380
    },
    {
      "epoch": 2.873294915748778,
      "grad_norm": 0.05755085125565529,
      "learning_rate": 2.1267050842512222e-05,
      "loss": 0.0041,
      "step": 39390
    },
    {
      "epoch": 2.8740243635567877,
      "grad_norm": 0.4580205976963043,
      "learning_rate": 2.1259756364432126e-05,
      "loss": 0.0037,
      "step": 39400
    },
    {
      "epoch": 2.874753811364797,
      "grad_norm": 0.05813946574926376,
      "learning_rate": 2.125246188635203e-05,
      "loss": 0.0039,
      "step": 39410
    },
    {
      "epoch": 2.8754832591728063,
      "grad_norm": 0.4607483148574829,
      "learning_rate": 2.124516740827194e-05,
      "loss": 0.0039,
      "step": 39420
    },
    {
      "epoch": 2.8762127069808154,
      "grad_norm": 0.25949668884277344,
      "learning_rate": 2.1237872930191846e-05,
      "loss": 0.0031,
      "step": 39430
    },
    {
      "epoch": 2.876942154788825,
      "grad_norm": 0.31683802604675293,
      "learning_rate": 2.1230578452111753e-05,
      "loss": 0.0034,
      "step": 39440
    },
    {
      "epoch": 2.877671602596834,
      "grad_norm": 0.18073809146881104,
      "learning_rate": 2.122328397403166e-05,
      "loss": 0.0028,
      "step": 39450
    },
    {
      "epoch": 2.8784010504048436,
      "grad_norm": 0.3334941267967224,
      "learning_rate": 2.1215989495951565e-05,
      "loss": 0.0026,
      "step": 39460
    },
    {
      "epoch": 2.8791304982128527,
      "grad_norm": 0.43262195587158203,
      "learning_rate": 2.1208695017871472e-05,
      "loss": 0.0031,
      "step": 39470
    },
    {
      "epoch": 2.8798599460208623,
      "grad_norm": 0.14435212314128876,
      "learning_rate": 2.120140053979138e-05,
      "loss": 0.0037,
      "step": 39480
    },
    {
      "epoch": 2.8805893938288714,
      "grad_norm": 0.08584826439619064,
      "learning_rate": 2.1194106061711287e-05,
      "loss": 0.0032,
      "step": 39490
    },
    {
      "epoch": 2.881318841636881,
      "grad_norm": 0.058196380734443665,
      "learning_rate": 2.118681158363119e-05,
      "loss": 0.0037,
      "step": 39500
    },
    {
      "epoch": 2.8820482894448904,
      "grad_norm": 0.17410284280776978,
      "learning_rate": 2.11795171055511e-05,
      "loss": 0.0024,
      "step": 39510
    },
    {
      "epoch": 2.8827777372528995,
      "grad_norm": 0.6039130091667175,
      "learning_rate": 2.1172222627471007e-05,
      "loss": 0.0028,
      "step": 39520
    },
    {
      "epoch": 2.8835071850609086,
      "grad_norm": 0.28690287470817566,
      "learning_rate": 2.116492814939091e-05,
      "loss": 0.0025,
      "step": 39530
    },
    {
      "epoch": 2.884236632868918,
      "grad_norm": 0.6851975917816162,
      "learning_rate": 2.1157633671310818e-05,
      "loss": 0.0035,
      "step": 39540
    },
    {
      "epoch": 2.8849660806769277,
      "grad_norm": 0.3036670982837677,
      "learning_rate": 2.1150339193230726e-05,
      "loss": 0.0033,
      "step": 39550
    },
    {
      "epoch": 2.885695528484937,
      "grad_norm": 0.2295743077993393,
      "learning_rate": 2.114304471515063e-05,
      "loss": 0.0046,
      "step": 39560
    },
    {
      "epoch": 2.8864249762929464,
      "grad_norm": 0.408316045999527,
      "learning_rate": 2.113575023707054e-05,
      "loss": 0.0026,
      "step": 39570
    },
    {
      "epoch": 2.8871544241009555,
      "grad_norm": 0.36528846621513367,
      "learning_rate": 2.1128455758990445e-05,
      "loss": 0.0031,
      "step": 39580
    },
    {
      "epoch": 2.887883871908965,
      "grad_norm": 0.14182515442371368,
      "learning_rate": 2.1121161280910353e-05,
      "loss": 0.0031,
      "step": 39590
    },
    {
      "epoch": 2.888613319716974,
      "grad_norm": 0.3839305639266968,
      "learning_rate": 2.111386680283026e-05,
      "loss": 0.0054,
      "step": 39600
    },
    {
      "epoch": 2.8893427675249836,
      "grad_norm": 0.16927698254585266,
      "learning_rate": 2.1106572324750164e-05,
      "loss": 0.0036,
      "step": 39610
    },
    {
      "epoch": 2.890072215332993,
      "grad_norm": 0.17421141266822815,
      "learning_rate": 2.1099277846670072e-05,
      "loss": 0.0038,
      "step": 39620
    },
    {
      "epoch": 2.8908016631410023,
      "grad_norm": 0.05952459201216698,
      "learning_rate": 2.109198336858998e-05,
      "loss": 0.0035,
      "step": 39630
    },
    {
      "epoch": 2.8915311109490114,
      "grad_norm": 0.28864726424217224,
      "learning_rate": 2.1084688890509883e-05,
      "loss": 0.0056,
      "step": 39640
    },
    {
      "epoch": 2.892260558757021,
      "grad_norm": 0.031086698174476624,
      "learning_rate": 2.107739441242979e-05,
      "loss": 0.0032,
      "step": 39650
    },
    {
      "epoch": 2.8929900065650305,
      "grad_norm": 0.4303338825702667,
      "learning_rate": 2.10700999343497e-05,
      "loss": 0.0032,
      "step": 39660
    },
    {
      "epoch": 2.8937194543730396,
      "grad_norm": 0.33406829833984375,
      "learning_rate": 2.1062805456269606e-05,
      "loss": 0.0036,
      "step": 39670
    },
    {
      "epoch": 2.894448902181049,
      "grad_norm": 0.08813192695379257,
      "learning_rate": 2.105551097818951e-05,
      "loss": 0.0029,
      "step": 39680
    },
    {
      "epoch": 2.895178349989058,
      "grad_norm": 0.4602321684360504,
      "learning_rate": 2.1048216500109418e-05,
      "loss": 0.0028,
      "step": 39690
    },
    {
      "epoch": 2.8959077977970678,
      "grad_norm": 0.057857997715473175,
      "learning_rate": 2.1040922022029325e-05,
      "loss": 0.0038,
      "step": 39700
    },
    {
      "epoch": 2.896637245605077,
      "grad_norm": 0.2295941263437271,
      "learning_rate": 2.103362754394923e-05,
      "loss": 0.0046,
      "step": 39710
    },
    {
      "epoch": 2.8973666934130864,
      "grad_norm": 0.17290185391902924,
      "learning_rate": 2.102633306586914e-05,
      "loss": 0.0018,
      "step": 39720
    },
    {
      "epoch": 2.8980961412210955,
      "grad_norm": 0.2590360939502716,
      "learning_rate": 2.1019038587789044e-05,
      "loss": 0.0029,
      "step": 39730
    },
    {
      "epoch": 2.898825589029105,
      "grad_norm": 0.08672302961349487,
      "learning_rate": 2.101174410970895e-05,
      "loss": 0.0033,
      "step": 39740
    },
    {
      "epoch": 2.899555036837114,
      "grad_norm": 0.030549468472599983,
      "learning_rate": 2.100444963162886e-05,
      "loss": 0.0025,
      "step": 39750
    },
    {
      "epoch": 2.9002844846451237,
      "grad_norm": 0.23030228912830353,
      "learning_rate": 2.0997155153548764e-05,
      "loss": 0.0021,
      "step": 39760
    },
    {
      "epoch": 2.901013932453133,
      "grad_norm": 0.3432455062866211,
      "learning_rate": 2.098986067546867e-05,
      "loss": 0.0022,
      "step": 39770
    },
    {
      "epoch": 2.9017433802611423,
      "grad_norm": 0.2305772751569748,
      "learning_rate": 2.098256619738858e-05,
      "loss": 0.0048,
      "step": 39780
    },
    {
      "epoch": 2.9024728280691514,
      "grad_norm": 0.058779943734407425,
      "learning_rate": 2.0975271719308483e-05,
      "loss": 0.0039,
      "step": 39790
    },
    {
      "epoch": 2.903202275877161,
      "grad_norm": 0.4606393873691559,
      "learning_rate": 2.096797724122839e-05,
      "loss": 0.0036,
      "step": 39800
    },
    {
      "epoch": 2.9039317236851705,
      "grad_norm": 0.28916531801223755,
      "learning_rate": 2.0960682763148298e-05,
      "loss": 0.0031,
      "step": 39810
    },
    {
      "epoch": 2.9046611714931796,
      "grad_norm": 0.3158835172653198,
      "learning_rate": 2.0953388285068205e-05,
      "loss": 0.0039,
      "step": 39820
    },
    {
      "epoch": 2.905390619301189,
      "grad_norm": 0.08654282242059708,
      "learning_rate": 2.094609380698811e-05,
      "loss": 0.0045,
      "step": 39830
    },
    {
      "epoch": 2.9061200671091982,
      "grad_norm": 0.4686647355556488,
      "learning_rate": 2.0938799328908017e-05,
      "loss": 0.0036,
      "step": 39840
    },
    {
      "epoch": 2.9068495149172078,
      "grad_norm": 0.2372438758611679,
      "learning_rate": 2.0931504850827925e-05,
      "loss": 0.0032,
      "step": 39850
    },
    {
      "epoch": 2.907578962725217,
      "grad_norm": 0.09433378279209137,
      "learning_rate": 2.0924210372747832e-05,
      "loss": 0.0031,
      "step": 39860
    },
    {
      "epoch": 2.9083084105332264,
      "grad_norm": 0.03144195303320885,
      "learning_rate": 2.0916915894667736e-05,
      "loss": 0.0045,
      "step": 39870
    },
    {
      "epoch": 2.909037858341236,
      "grad_norm": 0.43089184165000916,
      "learning_rate": 2.0909621416587644e-05,
      "loss": 0.0034,
      "step": 39880
    },
    {
      "epoch": 2.909767306149245,
      "grad_norm": 0.37408214807510376,
      "learning_rate": 2.090232693850755e-05,
      "loss": 0.003,
      "step": 39890
    },
    {
      "epoch": 2.910496753957254,
      "grad_norm": 0.5657333731651306,
      "learning_rate": 2.089503246042746e-05,
      "loss": 0.0034,
      "step": 39900
    },
    {
      "epoch": 2.9112262017652637,
      "grad_norm": 0.4630286395549774,
      "learning_rate": 2.0887737982347363e-05,
      "loss": 0.0042,
      "step": 39910
    },
    {
      "epoch": 2.9119556495732732,
      "grad_norm": 0.28798213601112366,
      "learning_rate": 2.088044350426727e-05,
      "loss": 0.0026,
      "step": 39920
    },
    {
      "epoch": 2.9126850973812823,
      "grad_norm": 0.19416111707687378,
      "learning_rate": 2.0873149026187178e-05,
      "loss": 0.0041,
      "step": 39930
    },
    {
      "epoch": 2.9134145451892914,
      "grad_norm": 0.23036256432533264,
      "learning_rate": 2.0865854548107082e-05,
      "loss": 0.0028,
      "step": 39940
    },
    {
      "epoch": 2.914143992997301,
      "grad_norm": 0.14349161088466644,
      "learning_rate": 2.0858560070026993e-05,
      "loss": 0.0034,
      "step": 39950
    },
    {
      "epoch": 2.9148734408053105,
      "grad_norm": 0.23044012486934662,
      "learning_rate": 2.0851265591946897e-05,
      "loss": 0.0035,
      "step": 39960
    },
    {
      "epoch": 2.9156028886133196,
      "grad_norm": 0.11549840122461319,
      "learning_rate": 2.0843971113866805e-05,
      "loss": 0.0024,
      "step": 39970
    },
    {
      "epoch": 2.916332336421329,
      "grad_norm": 0.15479575097560883,
      "learning_rate": 2.0836676635786712e-05,
      "loss": 0.0043,
      "step": 39980
    },
    {
      "epoch": 2.9170617842293383,
      "grad_norm": 0.08691834658384323,
      "learning_rate": 2.0829382157706616e-05,
      "loss": 0.0025,
      "step": 39990
    },
    {
      "epoch": 2.917791232037348,
      "grad_norm": 0.3458791971206665,
      "learning_rate": 2.0822087679626524e-05,
      "loss": 0.0031,
      "step": 40000
    },
    {
      "epoch": 2.918520679845357,
      "grad_norm": 0.37366783618927,
      "learning_rate": 2.081479320154643e-05,
      "loss": 0.0032,
      "step": 40010
    },
    {
      "epoch": 2.9192501276533664,
      "grad_norm": 0.6126693487167358,
      "learning_rate": 2.0807498723466336e-05,
      "loss": 0.0027,
      "step": 40020
    },
    {
      "epoch": 2.919979575461376,
      "grad_norm": 0.287519246339798,
      "learning_rate": 2.0800204245386243e-05,
      "loss": 0.0033,
      "step": 40030
    },
    {
      "epoch": 2.920709023269385,
      "grad_norm": 0.057990316301584244,
      "learning_rate": 2.079290976730615e-05,
      "loss": 0.0036,
      "step": 40040
    },
    {
      "epoch": 2.921438471077394,
      "grad_norm": 0.4089018702507019,
      "learning_rate": 2.0785615289226058e-05,
      "loss": 0.0035,
      "step": 40050
    },
    {
      "epoch": 2.9221679188854037,
      "grad_norm": 0.014112325385212898,
      "learning_rate": 2.0778320811145962e-05,
      "loss": 0.0031,
      "step": 40060
    },
    {
      "epoch": 2.9228973666934133,
      "grad_norm": 0.551555871963501,
      "learning_rate": 2.077102633306587e-05,
      "loss": 0.0022,
      "step": 40070
    },
    {
      "epoch": 2.9236268145014224,
      "grad_norm": 0.34523195028305054,
      "learning_rate": 2.0763731854985777e-05,
      "loss": 0.0039,
      "step": 40080
    },
    {
      "epoch": 2.924356262309432,
      "grad_norm": 0.536238431930542,
      "learning_rate": 2.075643737690568e-05,
      "loss": 0.0026,
      "step": 40090
    },
    {
      "epoch": 2.925085710117441,
      "grad_norm": 0.030806133523583412,
      "learning_rate": 2.0749142898825593e-05,
      "loss": 0.0024,
      "step": 40100
    },
    {
      "epoch": 2.9258151579254505,
      "grad_norm": 0.3164689838886261,
      "learning_rate": 2.0741848420745497e-05,
      "loss": 0.003,
      "step": 40110
    },
    {
      "epoch": 2.9265446057334596,
      "grad_norm": 0.20452189445495605,
      "learning_rate": 2.07345539426654e-05,
      "loss": 0.0035,
      "step": 40120
    },
    {
      "epoch": 2.927274053541469,
      "grad_norm": 0.3709617257118225,
      "learning_rate": 2.0727259464585312e-05,
      "loss": 0.0036,
      "step": 40130
    },
    {
      "epoch": 2.9280035013494783,
      "grad_norm": 0.07432479411363602,
      "learning_rate": 2.0719964986505216e-05,
      "loss": 0.0035,
      "step": 40140
    },
    {
      "epoch": 2.928732949157488,
      "grad_norm": 0.05867082625627518,
      "learning_rate": 2.0712670508425123e-05,
      "loss": 0.0035,
      "step": 40150
    },
    {
      "epoch": 2.929462396965497,
      "grad_norm": 0.19067302346229553,
      "learning_rate": 2.070537603034503e-05,
      "loss": 0.0039,
      "step": 40160
    },
    {
      "epoch": 2.9301918447735065,
      "grad_norm": 0.3455098867416382,
      "learning_rate": 2.0698081552264935e-05,
      "loss": 0.0033,
      "step": 40170
    },
    {
      "epoch": 2.930921292581516,
      "grad_norm": 0.870089054107666,
      "learning_rate": 2.0690787074184843e-05,
      "loss": 0.0026,
      "step": 40180
    },
    {
      "epoch": 2.931650740389525,
      "grad_norm": 0.5077608823776245,
      "learning_rate": 2.068349259610475e-05,
      "loss": 0.004,
      "step": 40190
    },
    {
      "epoch": 2.932380188197534,
      "grad_norm": 0.114818274974823,
      "learning_rate": 2.0676198118024658e-05,
      "loss": 0.0028,
      "step": 40200
    },
    {
      "epoch": 2.9331096360055438,
      "grad_norm": 0.31558582186698914,
      "learning_rate": 2.0668903639944562e-05,
      "loss": 0.0029,
      "step": 40210
    },
    {
      "epoch": 2.9338390838135533,
      "grad_norm": 0.4325110614299774,
      "learning_rate": 2.066160916186447e-05,
      "loss": 0.0034,
      "step": 40220
    },
    {
      "epoch": 2.9345685316215624,
      "grad_norm": 0.029394851997494698,
      "learning_rate": 2.0654314683784377e-05,
      "loss": 0.0027,
      "step": 40230
    },
    {
      "epoch": 2.935297979429572,
      "grad_norm": 0.010622716508805752,
      "learning_rate": 2.064702020570428e-05,
      "loss": 0.0031,
      "step": 40240
    },
    {
      "epoch": 2.936027427237581,
      "grad_norm": 0.059305980801582336,
      "learning_rate": 2.063972572762419e-05,
      "loss": 0.005,
      "step": 40250
    },
    {
      "epoch": 2.9367568750455906,
      "grad_norm": 0.08657258003950119,
      "learning_rate": 2.0632431249544096e-05,
      "loss": 0.0029,
      "step": 40260
    },
    {
      "epoch": 2.9374863228535997,
      "grad_norm": 0.058472540229558945,
      "learning_rate": 2.0625136771464e-05,
      "loss": 0.0036,
      "step": 40270
    },
    {
      "epoch": 2.938215770661609,
      "grad_norm": 0.2589092254638672,
      "learning_rate": 2.061784229338391e-05,
      "loss": 0.0034,
      "step": 40280
    },
    {
      "epoch": 2.9389452184696188,
      "grad_norm": 0.11571486294269562,
      "learning_rate": 2.0610547815303815e-05,
      "loss": 0.0038,
      "step": 40290
    },
    {
      "epoch": 2.939674666277628,
      "grad_norm": 0.17256474494934082,
      "learning_rate": 2.0603253337223723e-05,
      "loss": 0.0032,
      "step": 40300
    },
    {
      "epoch": 2.940404114085637,
      "grad_norm": 0.08627816289663315,
      "learning_rate": 2.059595885914363e-05,
      "loss": 0.003,
      "step": 40310
    },
    {
      "epoch": 2.9411335618936465,
      "grad_norm": 0.029087617993354797,
      "learning_rate": 2.0588664381063534e-05,
      "loss": 0.0033,
      "step": 40320
    },
    {
      "epoch": 2.941863009701656,
      "grad_norm": 0.2594449818134308,
      "learning_rate": 2.0581369902983442e-05,
      "loss": 0.0037,
      "step": 40330
    },
    {
      "epoch": 2.942592457509665,
      "grad_norm": 0.3742711544036865,
      "learning_rate": 2.057407542490335e-05,
      "loss": 0.0046,
      "step": 40340
    },
    {
      "epoch": 2.9433219053176747,
      "grad_norm": 0.4307958483695984,
      "learning_rate": 2.0566780946823254e-05,
      "loss": 0.0025,
      "step": 40350
    },
    {
      "epoch": 2.944051353125684,
      "grad_norm": 0.20200081169605255,
      "learning_rate": 2.0559486468743165e-05,
      "loss": 0.0039,
      "step": 40360
    },
    {
      "epoch": 2.9447808009336933,
      "grad_norm": 0.5249596238136292,
      "learning_rate": 2.055219199066307e-05,
      "loss": 0.0038,
      "step": 40370
    },
    {
      "epoch": 2.9455102487417024,
      "grad_norm": 0.12355193495750427,
      "learning_rate": 2.0544897512582976e-05,
      "loss": 0.0031,
      "step": 40380
    },
    {
      "epoch": 2.946239696549712,
      "grad_norm": 0.5463963747024536,
      "learning_rate": 2.0537603034502884e-05,
      "loss": 0.0038,
      "step": 40390
    },
    {
      "epoch": 2.946969144357721,
      "grad_norm": 0.14413632452487946,
      "learning_rate": 2.0530308556422788e-05,
      "loss": 0.003,
      "step": 40400
    },
    {
      "epoch": 2.9476985921657306,
      "grad_norm": 0.08668522536754608,
      "learning_rate": 2.0523014078342695e-05,
      "loss": 0.0032,
      "step": 40410
    },
    {
      "epoch": 2.9484280399737397,
      "grad_norm": 0.3476068675518036,
      "learning_rate": 2.0515719600262603e-05,
      "loss": 0.0041,
      "step": 40420
    },
    {
      "epoch": 2.9491574877817492,
      "grad_norm": 0.4505540132522583,
      "learning_rate": 2.050842512218251e-05,
      "loss": 0.0027,
      "step": 40430
    },
    {
      "epoch": 2.949886935589759,
      "grad_norm": 0.20786750316619873,
      "learning_rate": 2.0501130644102415e-05,
      "loss": 0.0032,
      "step": 40440
    },
    {
      "epoch": 2.950616383397768,
      "grad_norm": 0.08916570246219635,
      "learning_rate": 2.0493836166022322e-05,
      "loss": 0.003,
      "step": 40450
    },
    {
      "epoch": 2.951345831205777,
      "grad_norm": 0.17363908886909485,
      "learning_rate": 2.048654168794223e-05,
      "loss": 0.0024,
      "step": 40460
    },
    {
      "epoch": 2.9520752790137865,
      "grad_norm": 0.3274831175804138,
      "learning_rate": 2.0479247209862134e-05,
      "loss": 0.0043,
      "step": 40470
    },
    {
      "epoch": 2.952804726821796,
      "grad_norm": 0.22928988933563232,
      "learning_rate": 2.0471952731782045e-05,
      "loss": 0.0036,
      "step": 40480
    },
    {
      "epoch": 2.953534174629805,
      "grad_norm": 0.11725463718175888,
      "learning_rate": 2.046465825370195e-05,
      "loss": 0.003,
      "step": 40490
    },
    {
      "epoch": 2.9542636224378147,
      "grad_norm": 0.030769990757107735,
      "learning_rate": 2.0457363775621853e-05,
      "loss": 0.0038,
      "step": 40500
    },
    {
      "epoch": 2.954993070245824,
      "grad_norm": 0.14369699358940125,
      "learning_rate": 2.0450069297541764e-05,
      "loss": 0.0041,
      "step": 40510
    },
    {
      "epoch": 2.9557225180538333,
      "grad_norm": 0.1724299043416977,
      "learning_rate": 2.0442774819461668e-05,
      "loss": 0.0029,
      "step": 40520
    },
    {
      "epoch": 2.9564519658618424,
      "grad_norm": 0.008688360452651978,
      "learning_rate": 2.0435480341381576e-05,
      "loss": 0.0028,
      "step": 40530
    },
    {
      "epoch": 2.957181413669852,
      "grad_norm": 0.20870289206504822,
      "learning_rate": 2.0428185863301483e-05,
      "loss": 0.0028,
      "step": 40540
    },
    {
      "epoch": 2.9579108614778615,
      "grad_norm": 0.030014120042324066,
      "learning_rate": 2.0420891385221387e-05,
      "loss": 0.0035,
      "step": 40550
    },
    {
      "epoch": 2.9586403092858706,
      "grad_norm": 0.23014391958713531,
      "learning_rate": 2.0413596907141295e-05,
      "loss": 0.004,
      "step": 40560
    },
    {
      "epoch": 2.9593697570938797,
      "grad_norm": 0.10521356016397476,
      "learning_rate": 2.0406302429061202e-05,
      "loss": 0.0048,
      "step": 40570
    },
    {
      "epoch": 2.9600992049018893,
      "grad_norm": 0.40092933177948,
      "learning_rate": 2.039900795098111e-05,
      "loss": 0.0032,
      "step": 40580
    },
    {
      "epoch": 2.960828652709899,
      "grad_norm": 0.2362082451581955,
      "learning_rate": 2.0391713472901014e-05,
      "loss": 0.004,
      "step": 40590
    },
    {
      "epoch": 2.961558100517908,
      "grad_norm": 0.05870310217142105,
      "learning_rate": 2.038441899482092e-05,
      "loss": 0.0043,
      "step": 40600
    },
    {
      "epoch": 2.962287548325917,
      "grad_norm": 0.029864907264709473,
      "learning_rate": 2.037712451674083e-05,
      "loss": 0.0023,
      "step": 40610
    },
    {
      "epoch": 2.9630169961339266,
      "grad_norm": 0.030114784836769104,
      "learning_rate": 2.0369830038660733e-05,
      "loss": 0.0027,
      "step": 40620
    },
    {
      "epoch": 2.963746443941936,
      "grad_norm": 0.08847654610872269,
      "learning_rate": 2.036253556058064e-05,
      "loss": 0.0033,
      "step": 40630
    },
    {
      "epoch": 2.964475891749945,
      "grad_norm": 0.17367932200431824,
      "learning_rate": 2.0355241082500548e-05,
      "loss": 0.0032,
      "step": 40640
    },
    {
      "epoch": 2.9652053395579547,
      "grad_norm": 0.4145319163799286,
      "learning_rate": 2.0347946604420452e-05,
      "loss": 0.0029,
      "step": 40650
    },
    {
      "epoch": 2.965934787365964,
      "grad_norm": 0.2004997581243515,
      "learning_rate": 2.0340652126340363e-05,
      "loss": 0.0036,
      "step": 40660
    },
    {
      "epoch": 2.9666642351739734,
      "grad_norm": 0.08726205676794052,
      "learning_rate": 2.0333357648260267e-05,
      "loss": 0.0038,
      "step": 40670
    },
    {
      "epoch": 2.9673936829819825,
      "grad_norm": 0.1151869148015976,
      "learning_rate": 2.0326063170180175e-05,
      "loss": 0.004,
      "step": 40680
    },
    {
      "epoch": 2.968123130789992,
      "grad_norm": 0.44436806440353394,
      "learning_rate": 2.0318768692100083e-05,
      "loss": 0.0049,
      "step": 40690
    },
    {
      "epoch": 2.9688525785980016,
      "grad_norm": 0.3457791209220886,
      "learning_rate": 2.0311474214019987e-05,
      "loss": 0.0027,
      "step": 40700
    },
    {
      "epoch": 2.9695820264060107,
      "grad_norm": 0.058946579694747925,
      "learning_rate": 2.0304179735939894e-05,
      "loss": 0.0032,
      "step": 40710
    },
    {
      "epoch": 2.9703114742140198,
      "grad_norm": 0.3173607885837555,
      "learning_rate": 2.0296885257859802e-05,
      "loss": 0.0022,
      "step": 40720
    },
    {
      "epoch": 2.9710409220220293,
      "grad_norm": 0.34601491689682007,
      "learning_rate": 2.0289590779779706e-05,
      "loss": 0.004,
      "step": 40730
    },
    {
      "epoch": 2.971770369830039,
      "grad_norm": 0.2703731656074524,
      "learning_rate": 2.0282296301699613e-05,
      "loss": 0.0042,
      "step": 40740
    },
    {
      "epoch": 2.972499817638048,
      "grad_norm": 0.02976473607122898,
      "learning_rate": 2.027500182361952e-05,
      "loss": 0.0024,
      "step": 40750
    },
    {
      "epoch": 2.9732292654460575,
      "grad_norm": 0.11489012092351913,
      "learning_rate": 2.026770734553943e-05,
      "loss": 0.0034,
      "step": 40760
    },
    {
      "epoch": 2.9739587132540666,
      "grad_norm": 0.11506820470094681,
      "learning_rate": 2.0260412867459333e-05,
      "loss": 0.0034,
      "step": 40770
    },
    {
      "epoch": 2.974688161062076,
      "grad_norm": 0.058796945959329605,
      "learning_rate": 2.025311838937924e-05,
      "loss": 0.0041,
      "step": 40780
    },
    {
      "epoch": 2.975417608870085,
      "grad_norm": 0.7788800597190857,
      "learning_rate": 2.0245823911299148e-05,
      "loss": 0.0036,
      "step": 40790
    },
    {
      "epoch": 2.9761470566780948,
      "grad_norm": 0.11981210112571716,
      "learning_rate": 2.0238529433219052e-05,
      "loss": 0.003,
      "step": 40800
    },
    {
      "epoch": 2.976876504486104,
      "grad_norm": 0.1571403294801712,
      "learning_rate": 2.0231234955138963e-05,
      "loss": 0.0046,
      "step": 40810
    },
    {
      "epoch": 2.9776059522941134,
      "grad_norm": 0.2299855351448059,
      "learning_rate": 2.0223940477058867e-05,
      "loss": 0.0046,
      "step": 40820
    },
    {
      "epoch": 2.9783354001021225,
      "grad_norm": 0.20453312993049622,
      "learning_rate": 2.021664599897877e-05,
      "loss": 0.0039,
      "step": 40830
    },
    {
      "epoch": 2.979064847910132,
      "grad_norm": 0.374288409948349,
      "learning_rate": 2.0209351520898682e-05,
      "loss": 0.0041,
      "step": 40840
    },
    {
      "epoch": 2.9797942957181416,
      "grad_norm": 0.13107813894748688,
      "learning_rate": 2.0202057042818586e-05,
      "loss": 0.0032,
      "step": 40850
    },
    {
      "epoch": 2.9805237435261507,
      "grad_norm": 0.031095758080482483,
      "learning_rate": 2.0194762564738494e-05,
      "loss": 0.003,
      "step": 40860
    },
    {
      "epoch": 2.98125319133416,
      "grad_norm": 0.00971283484250307,
      "learning_rate": 2.01874680866584e-05,
      "loss": 0.0036,
      "step": 40870
    },
    {
      "epoch": 2.9819826391421693,
      "grad_norm": 0.25909388065338135,
      "learning_rate": 2.0180173608578305e-05,
      "loss": 0.0022,
      "step": 40880
    },
    {
      "epoch": 2.982712086950179,
      "grad_norm": 0.3672104775905609,
      "learning_rate": 2.0172879130498216e-05,
      "loss": 0.0024,
      "step": 40890
    },
    {
      "epoch": 2.983441534758188,
      "grad_norm": 0.2295602560043335,
      "learning_rate": 2.016558465241812e-05,
      "loss": 0.0025,
      "step": 40900
    },
    {
      "epoch": 2.9841709825661975,
      "grad_norm": 0.5496705770492554,
      "learning_rate": 2.0158290174338028e-05,
      "loss": 0.0032,
      "step": 40910
    },
    {
      "epoch": 2.9849004303742066,
      "grad_norm": 0.22478151321411133,
      "learning_rate": 2.0150995696257935e-05,
      "loss": 0.0032,
      "step": 40920
    },
    {
      "epoch": 2.985629878182216,
      "grad_norm": 0.28729015588760376,
      "learning_rate": 2.014370121817784e-05,
      "loss": 0.003,
      "step": 40930
    },
    {
      "epoch": 2.9863593259902252,
      "grad_norm": 0.5116029977798462,
      "learning_rate": 2.0136406740097747e-05,
      "loss": 0.0053,
      "step": 40940
    },
    {
      "epoch": 2.987088773798235,
      "grad_norm": 0.007614004425704479,
      "learning_rate": 2.0129112262017655e-05,
      "loss": 0.0024,
      "step": 40950
    },
    {
      "epoch": 2.9878182216062443,
      "grad_norm": 0.14300976693630219,
      "learning_rate": 2.012181778393756e-05,
      "loss": 0.0026,
      "step": 40960
    },
    {
      "epoch": 2.9885476694142534,
      "grad_norm": 0.12355807423591614,
      "learning_rate": 2.0114523305857466e-05,
      "loss": 0.0025,
      "step": 40970
    },
    {
      "epoch": 2.9892771172222625,
      "grad_norm": 0.08661454916000366,
      "learning_rate": 2.0107228827777374e-05,
      "loss": 0.0021,
      "step": 40980
    },
    {
      "epoch": 2.990006565030272,
      "grad_norm": 0.08767873793840408,
      "learning_rate": 2.009993434969728e-05,
      "loss": 0.0033,
      "step": 40990
    },
    {
      "epoch": 2.9907360128382816,
      "grad_norm": 0.37463080883026123,
      "learning_rate": 2.0092639871617185e-05,
      "loss": 0.005,
      "step": 41000
    },
    {
      "epoch": 2.9914654606462907,
      "grad_norm": 0.05852930247783661,
      "learning_rate": 2.0085345393537093e-05,
      "loss": 0.0041,
      "step": 41010
    },
    {
      "epoch": 2.9921949084543003,
      "grad_norm": 0.030895542353391647,
      "learning_rate": 2.0078050915457e-05,
      "loss": 0.0023,
      "step": 41020
    },
    {
      "epoch": 2.9929243562623093,
      "grad_norm": 0.08923187106847763,
      "learning_rate": 2.0070756437376905e-05,
      "loss": 0.0025,
      "step": 41030
    },
    {
      "epoch": 2.993653804070319,
      "grad_norm": 0.22954632341861725,
      "learning_rate": 2.0063461959296816e-05,
      "loss": 0.0032,
      "step": 41040
    },
    {
      "epoch": 2.994383251878328,
      "grad_norm": 0.09172585606575012,
      "learning_rate": 2.005616748121672e-05,
      "loss": 0.0047,
      "step": 41050
    },
    {
      "epoch": 2.9951126996863375,
      "grad_norm": 0.26114463806152344,
      "learning_rate": 2.0048873003136627e-05,
      "loss": 0.0024,
      "step": 41060
    },
    {
      "epoch": 2.9958421474943466,
      "grad_norm": 0.6327707767486572,
      "learning_rate": 2.0041578525056535e-05,
      "loss": 0.0031,
      "step": 41070
    },
    {
      "epoch": 2.996571595302356,
      "grad_norm": 0.23021191358566284,
      "learning_rate": 2.003428404697644e-05,
      "loss": 0.0034,
      "step": 41080
    },
    {
      "epoch": 2.9973010431103653,
      "grad_norm": 0.23413819074630737,
      "learning_rate": 2.0026989568896346e-05,
      "loss": 0.0042,
      "step": 41090
    },
    {
      "epoch": 2.998030490918375,
      "grad_norm": 0.17737753689289093,
      "learning_rate": 2.0019695090816254e-05,
      "loss": 0.0033,
      "step": 41100
    },
    {
      "epoch": 2.9987599387263844,
      "grad_norm": 0.17278099060058594,
      "learning_rate": 2.0012400612736158e-05,
      "loss": 0.0045,
      "step": 41110
    },
    {
      "epoch": 2.9994893865343935,
      "grad_norm": 0.17105181515216827,
      "learning_rate": 2.0005106134656066e-05,
      "loss": 0.0048,
      "step": 41120
    },
    {
      "epoch": 3.0,
      "eval_loss": 0.0034337386023253202,
      "eval_runtime": 113.7115,
      "eval_samples_per_second": 1229.216,
      "eval_steps_per_second": 30.736,
      "step": 41127
    },
    {
      "epoch": 3.000218834342403,
      "grad_norm": 0.03121889755129814,
      "learning_rate": 1.9997811656575973e-05,
      "loss": 0.0034,
      "step": 41130
    },
    {
      "epoch": 3.000948282150412,
      "grad_norm": 0.10910124331712723,
      "learning_rate": 1.999051717849588e-05,
      "loss": 0.0041,
      "step": 41140
    },
    {
      "epoch": 3.0016777299584216,
      "grad_norm": 0.2589733302593231,
      "learning_rate": 1.9983222700415785e-05,
      "loss": 0.0029,
      "step": 41150
    },
    {
      "epoch": 3.0024071777664307,
      "grad_norm": 0.08652739971876144,
      "learning_rate": 1.9975928222335692e-05,
      "loss": 0.0037,
      "step": 41160
    },
    {
      "epoch": 3.0031366255744403,
      "grad_norm": 0.08705448359251022,
      "learning_rate": 1.99686337442556e-05,
      "loss": 0.0036,
      "step": 41170
    },
    {
      "epoch": 3.0038660733824494,
      "grad_norm": 0.22767654061317444,
      "learning_rate": 1.9961339266175504e-05,
      "loss": 0.0045,
      "step": 41180
    },
    {
      "epoch": 3.004595521190459,
      "grad_norm": 0.17310458421707153,
      "learning_rate": 1.9954044788095415e-05,
      "loss": 0.0033,
      "step": 41190
    },
    {
      "epoch": 3.005324968998468,
      "grad_norm": 0.03052341379225254,
      "learning_rate": 1.994675031001532e-05,
      "loss": 0.0029,
      "step": 41200
    },
    {
      "epoch": 3.0060544168064776,
      "grad_norm": 0.11464084684848785,
      "learning_rate": 1.9939455831935223e-05,
      "loss": 0.0038,
      "step": 41210
    },
    {
      "epoch": 3.0067838646144867,
      "grad_norm": 0.0862850770354271,
      "learning_rate": 1.9932161353855134e-05,
      "loss": 0.0044,
      "step": 41220
    },
    {
      "epoch": 3.007513312422496,
      "grad_norm": 0.05894572660326958,
      "learning_rate": 1.992486687577504e-05,
      "loss": 0.0039,
      "step": 41230
    },
    {
      "epoch": 3.0082427602305053,
      "grad_norm": 0.02053792029619217,
      "learning_rate": 1.9917572397694946e-05,
      "loss": 0.003,
      "step": 41240
    },
    {
      "epoch": 3.008972208038515,
      "grad_norm": 0.4593345522880554,
      "learning_rate": 1.9910277919614853e-05,
      "loss": 0.0045,
      "step": 41250
    },
    {
      "epoch": 3.0097016558465244,
      "grad_norm": 0.1740901917219162,
      "learning_rate": 1.9902983441534758e-05,
      "loss": 0.0035,
      "step": 41260
    },
    {
      "epoch": 3.0104311036545335,
      "grad_norm": 0.17305971682071686,
      "learning_rate": 1.9895688963454665e-05,
      "loss": 0.0029,
      "step": 41270
    },
    {
      "epoch": 3.011160551462543,
      "grad_norm": 0.23425820469856262,
      "learning_rate": 1.9888394485374573e-05,
      "loss": 0.0032,
      "step": 41280
    },
    {
      "epoch": 3.011889999270552,
      "grad_norm": 0.2109733521938324,
      "learning_rate": 1.988110000729448e-05,
      "loss": 0.0047,
      "step": 41290
    },
    {
      "epoch": 3.0126194470785617,
      "grad_norm": 0.029205046594142914,
      "learning_rate": 1.9873805529214384e-05,
      "loss": 0.0031,
      "step": 41300
    },
    {
      "epoch": 3.0133488948865708,
      "grad_norm": 0.1147242859005928,
      "learning_rate": 1.9866511051134292e-05,
      "loss": 0.0025,
      "step": 41310
    },
    {
      "epoch": 3.0140783426945803,
      "grad_norm": 0.2886972725391388,
      "learning_rate": 1.98592165730542e-05,
      "loss": 0.0036,
      "step": 41320
    },
    {
      "epoch": 3.0148077905025894,
      "grad_norm": 0.08653099834918976,
      "learning_rate": 1.9851922094974107e-05,
      "loss": 0.0035,
      "step": 41330
    },
    {
      "epoch": 3.015537238310599,
      "grad_norm": 0.2087678760290146,
      "learning_rate": 1.984462761689401e-05,
      "loss": 0.0028,
      "step": 41340
    },
    {
      "epoch": 3.016266686118608,
      "grad_norm": 0.23084469139575958,
      "learning_rate": 1.983733313881392e-05,
      "loss": 0.0036,
      "step": 41350
    },
    {
      "epoch": 3.0169961339266176,
      "grad_norm": 0.1753501445055008,
      "learning_rate": 1.9830038660733826e-05,
      "loss": 0.005,
      "step": 41360
    },
    {
      "epoch": 3.0177255817346267,
      "grad_norm": 0.17196841537952423,
      "learning_rate": 1.9822744182653734e-05,
      "loss": 0.0026,
      "step": 41370
    },
    {
      "epoch": 3.0184550295426362,
      "grad_norm": 0.42259567975997925,
      "learning_rate": 1.9815449704573638e-05,
      "loss": 0.0027,
      "step": 41380
    },
    {
      "epoch": 3.0191844773506458,
      "grad_norm": 0.08976924419403076,
      "learning_rate": 1.9808155226493545e-05,
      "loss": 0.0042,
      "step": 41390
    },
    {
      "epoch": 3.019913925158655,
      "grad_norm": 0.5086036920547485,
      "learning_rate": 1.9800860748413453e-05,
      "loss": 0.0058,
      "step": 41400
    },
    {
      "epoch": 3.0206433729666644,
      "grad_norm": 0.030288225039839745,
      "learning_rate": 1.9793566270333357e-05,
      "loss": 0.0036,
      "step": 41410
    },
    {
      "epoch": 3.0213728207746735,
      "grad_norm": 0.5567982196807861,
      "learning_rate": 1.9786271792253268e-05,
      "loss": 0.0038,
      "step": 41420
    },
    {
      "epoch": 3.022102268582683,
      "grad_norm": 0.2921654284000397,
      "learning_rate": 1.9778977314173172e-05,
      "loss": 0.0049,
      "step": 41430
    },
    {
      "epoch": 3.022831716390692,
      "grad_norm": 0.32432252168655396,
      "learning_rate": 1.9771682836093076e-05,
      "loss": 0.003,
      "step": 41440
    },
    {
      "epoch": 3.0235611641987017,
      "grad_norm": 0.2881070673465729,
      "learning_rate": 1.9764388358012987e-05,
      "loss": 0.0027,
      "step": 41450
    },
    {
      "epoch": 3.024290612006711,
      "grad_norm": 0.23084662854671478,
      "learning_rate": 1.975709387993289e-05,
      "loss": 0.0032,
      "step": 41460
    },
    {
      "epoch": 3.0250200598147203,
      "grad_norm": 0.636309802532196,
      "learning_rate": 1.97497994018528e-05,
      "loss": 0.0033,
      "step": 41470
    },
    {
      "epoch": 3.0257495076227294,
      "grad_norm": 0.144810289144516,
      "learning_rate": 1.9742504923772706e-05,
      "loss": 0.0032,
      "step": 41480
    },
    {
      "epoch": 3.026478955430739,
      "grad_norm": 0.3741816580295563,
      "learning_rate": 1.973521044569261e-05,
      "loss": 0.0047,
      "step": 41490
    },
    {
      "epoch": 3.027208403238748,
      "grad_norm": 0.0297507606446743,
      "learning_rate": 1.9727915967612518e-05,
      "loss": 0.0032,
      "step": 41500
    },
    {
      "epoch": 3.0279378510467576,
      "grad_norm": 0.1724494844675064,
      "learning_rate": 1.9720621489532425e-05,
      "loss": 0.0034,
      "step": 41510
    },
    {
      "epoch": 3.028667298854767,
      "grad_norm": 0.335311621427536,
      "learning_rate": 1.9713327011452333e-05,
      "loss": 0.0041,
      "step": 41520
    },
    {
      "epoch": 3.0293967466627763,
      "grad_norm": 0.06422292441129684,
      "learning_rate": 1.9706032533372237e-05,
      "loss": 0.0034,
      "step": 41530
    },
    {
      "epoch": 3.030126194470786,
      "grad_norm": 0.5174617171287537,
      "learning_rate": 1.9698738055292145e-05,
      "loss": 0.003,
      "step": 41540
    },
    {
      "epoch": 3.030855642278795,
      "grad_norm": 0.031908947974443436,
      "learning_rate": 1.9691443577212052e-05,
      "loss": 0.0024,
      "step": 41550
    },
    {
      "epoch": 3.0315850900868044,
      "grad_norm": 0.3160710036754608,
      "learning_rate": 1.9684149099131956e-05,
      "loss": 0.0027,
      "step": 41560
    },
    {
      "epoch": 3.0323145378948135,
      "grad_norm": 0.029286034405231476,
      "learning_rate": 1.9676854621051867e-05,
      "loss": 0.0036,
      "step": 41570
    },
    {
      "epoch": 3.033043985702823,
      "grad_norm": 0.41241785883903503,
      "learning_rate": 1.966956014297177e-05,
      "loss": 0.003,
      "step": 41580
    },
    {
      "epoch": 3.033773433510832,
      "grad_norm": 0.2299778312444687,
      "learning_rate": 1.9662265664891676e-05,
      "loss": 0.0039,
      "step": 41590
    },
    {
      "epoch": 3.0345028813188417,
      "grad_norm": 0.17296399176120758,
      "learning_rate": 1.9654971186811586e-05,
      "loss": 0.0037,
      "step": 41600
    },
    {
      "epoch": 3.035232329126851,
      "grad_norm": 0.058196838945150375,
      "learning_rate": 1.964767670873149e-05,
      "loss": 0.004,
      "step": 41610
    },
    {
      "epoch": 3.0359617769348604,
      "grad_norm": 0.547436535358429,
      "learning_rate": 1.9640382230651398e-05,
      "loss": 0.0042,
      "step": 41620
    },
    {
      "epoch": 3.0366912247428695,
      "grad_norm": 0.08856212347745895,
      "learning_rate": 1.9633087752571306e-05,
      "loss": 0.0036,
      "step": 41630
    },
    {
      "epoch": 3.037420672550879,
      "grad_norm": 0.16357116401195526,
      "learning_rate": 1.962579327449121e-05,
      "loss": 0.0035,
      "step": 41640
    },
    {
      "epoch": 3.0381501203588885,
      "grad_norm": 0.028834452852606773,
      "learning_rate": 1.9618498796411117e-05,
      "loss": 0.0029,
      "step": 41650
    },
    {
      "epoch": 3.0388795681668976,
      "grad_norm": 0.550199031829834,
      "learning_rate": 1.9611204318331025e-05,
      "loss": 0.0046,
      "step": 41660
    },
    {
      "epoch": 3.039609015974907,
      "grad_norm": 0.17319002747535706,
      "learning_rate": 1.9603909840250932e-05,
      "loss": 0.0047,
      "step": 41670
    },
    {
      "epoch": 3.0403384637829163,
      "grad_norm": 0.3685583472251892,
      "learning_rate": 1.9596615362170837e-05,
      "loss": 0.0035,
      "step": 41680
    },
    {
      "epoch": 3.041067911590926,
      "grad_norm": 0.3619145452976227,
      "learning_rate": 1.9589320884090744e-05,
      "loss": 0.0037,
      "step": 41690
    },
    {
      "epoch": 3.041797359398935,
      "grad_norm": 0.08640631288290024,
      "learning_rate": 1.958202640601065e-05,
      "loss": 0.0032,
      "step": 41700
    },
    {
      "epoch": 3.0425268072069445,
      "grad_norm": 0.11681971698999405,
      "learning_rate": 1.9574731927930556e-05,
      "loss": 0.0032,
      "step": 41710
    },
    {
      "epoch": 3.0432562550149536,
      "grad_norm": 0.057551756501197815,
      "learning_rate": 1.9567437449850463e-05,
      "loss": 0.0041,
      "step": 41720
    },
    {
      "epoch": 3.043985702822963,
      "grad_norm": 0.05988667160272598,
      "learning_rate": 1.956014297177037e-05,
      "loss": 0.0025,
      "step": 41730
    },
    {
      "epoch": 3.044715150630972,
      "grad_norm": 0.24045783281326294,
      "learning_rate": 1.9552848493690275e-05,
      "loss": 0.0058,
      "step": 41740
    },
    {
      "epoch": 3.0454445984389817,
      "grad_norm": 0.3456573486328125,
      "learning_rate": 1.9545554015610186e-05,
      "loss": 0.0036,
      "step": 41750
    },
    {
      "epoch": 3.046174046246991,
      "grad_norm": 0.3823468089103699,
      "learning_rate": 1.953825953753009e-05,
      "loss": 0.0033,
      "step": 41760
    },
    {
      "epoch": 3.0469034940550004,
      "grad_norm": 0.23011885583400726,
      "learning_rate": 1.9530965059449998e-05,
      "loss": 0.0039,
      "step": 41770
    },
    {
      "epoch": 3.04763294186301,
      "grad_norm": 0.20243558287620544,
      "learning_rate": 1.9523670581369905e-05,
      "loss": 0.003,
      "step": 41780
    },
    {
      "epoch": 3.048362389671019,
      "grad_norm": 0.2506927251815796,
      "learning_rate": 1.951637610328981e-05,
      "loss": 0.0034,
      "step": 41790
    },
    {
      "epoch": 3.0490918374790286,
      "grad_norm": 0.4603695869445801,
      "learning_rate": 1.9509081625209717e-05,
      "loss": 0.0038,
      "step": 41800
    },
    {
      "epoch": 3.0498212852870377,
      "grad_norm": 0.373781681060791,
      "learning_rate": 1.9501787147129624e-05,
      "loss": 0.0032,
      "step": 41810
    },
    {
      "epoch": 3.050550733095047,
      "grad_norm": 0.31332504749298096,
      "learning_rate": 1.949449266904953e-05,
      "loss": 0.0031,
      "step": 41820
    },
    {
      "epoch": 3.0512801809030563,
      "grad_norm": 0.11389686912298203,
      "learning_rate": 1.948719819096944e-05,
      "loss": 0.0031,
      "step": 41830
    },
    {
      "epoch": 3.052009628711066,
      "grad_norm": 0.6611403226852417,
      "learning_rate": 1.9479903712889343e-05,
      "loss": 0.0031,
      "step": 41840
    },
    {
      "epoch": 3.052739076519075,
      "grad_norm": 0.1713503897190094,
      "learning_rate": 1.947260923480925e-05,
      "loss": 0.0038,
      "step": 41850
    },
    {
      "epoch": 3.0534685243270845,
      "grad_norm": 0.33389291167259216,
      "learning_rate": 1.946531475672916e-05,
      "loss": 0.0037,
      "step": 41860
    },
    {
      "epoch": 3.0541979721350936,
      "grad_norm": 0.14662234485149384,
      "learning_rate": 1.9458020278649063e-05,
      "loss": 0.0037,
      "step": 41870
    },
    {
      "epoch": 3.054927419943103,
      "grad_norm": 0.06533052027225494,
      "learning_rate": 1.945072580056897e-05,
      "loss": 0.0033,
      "step": 41880
    },
    {
      "epoch": 3.0556568677511122,
      "grad_norm": 0.09976879507303238,
      "learning_rate": 1.9443431322488878e-05,
      "loss": 0.0027,
      "step": 41890
    },
    {
      "epoch": 3.0563863155591218,
      "grad_norm": 0.2291363924741745,
      "learning_rate": 1.9436136844408785e-05,
      "loss": 0.004,
      "step": 41900
    },
    {
      "epoch": 3.057115763367131,
      "grad_norm": 0.43192946910858154,
      "learning_rate": 1.942884236632869e-05,
      "loss": 0.0032,
      "step": 41910
    },
    {
      "epoch": 3.0578452111751404,
      "grad_norm": 0.6758784055709839,
      "learning_rate": 1.9421547888248597e-05,
      "loss": 0.0029,
      "step": 41920
    },
    {
      "epoch": 3.05857465898315,
      "grad_norm": 0.14433442056179047,
      "learning_rate": 1.9414253410168504e-05,
      "loss": 0.003,
      "step": 41930
    },
    {
      "epoch": 3.059304106791159,
      "grad_norm": 0.20207640528678894,
      "learning_rate": 1.940695893208841e-05,
      "loss": 0.004,
      "step": 41940
    },
    {
      "epoch": 3.0600335545991686,
      "grad_norm": 0.2627861201763153,
      "learning_rate": 1.9399664454008316e-05,
      "loss": 0.0036,
      "step": 41950
    },
    {
      "epoch": 3.0607630024071777,
      "grad_norm": 0.008649605326354504,
      "learning_rate": 1.9392369975928224e-05,
      "loss": 0.0039,
      "step": 41960
    },
    {
      "epoch": 3.0614924502151872,
      "grad_norm": 0.17912417650222778,
      "learning_rate": 1.9385075497848128e-05,
      "loss": 0.0047,
      "step": 41970
    },
    {
      "epoch": 3.0622218980231963,
      "grad_norm": 0.11520060151815414,
      "learning_rate": 1.937778101976804e-05,
      "loss": 0.003,
      "step": 41980
    },
    {
      "epoch": 3.062951345831206,
      "grad_norm": 0.35212984681129456,
      "learning_rate": 1.9370486541687943e-05,
      "loss": 0.0037,
      "step": 41990
    },
    {
      "epoch": 3.063680793639215,
      "grad_norm": 0.05974644422531128,
      "learning_rate": 1.936319206360785e-05,
      "loss": 0.0023,
      "step": 42000
    },
    {
      "epoch": 3.0644102414472245,
      "grad_norm": 0.2864694893360138,
      "learning_rate": 1.9355897585527758e-05,
      "loss": 0.004,
      "step": 42010
    },
    {
      "epoch": 3.0651396892552336,
      "grad_norm": 0.2875884175300598,
      "learning_rate": 1.9348603107447662e-05,
      "loss": 0.0037,
      "step": 42020
    },
    {
      "epoch": 3.065869137063243,
      "grad_norm": 0.14429929852485657,
      "learning_rate": 1.934130862936757e-05,
      "loss": 0.0028,
      "step": 42030
    },
    {
      "epoch": 3.0665985848712523,
      "grad_norm": 0.3449968099594116,
      "learning_rate": 1.9334014151287477e-05,
      "loss": 0.0036,
      "step": 42040
    },
    {
      "epoch": 3.067328032679262,
      "grad_norm": 0.4355792701244354,
      "learning_rate": 1.9326719673207385e-05,
      "loss": 0.0026,
      "step": 42050
    },
    {
      "epoch": 3.0680574804872713,
      "grad_norm": 0.2873852252960205,
      "learning_rate": 1.931942519512729e-05,
      "loss": 0.0041,
      "step": 42060
    },
    {
      "epoch": 3.0687869282952804,
      "grad_norm": 0.2597251832485199,
      "learning_rate": 1.9312130717047196e-05,
      "loss": 0.0031,
      "step": 42070
    },
    {
      "epoch": 3.06951637610329,
      "grad_norm": 0.03925158083438873,
      "learning_rate": 1.9304836238967104e-05,
      "loss": 0.0019,
      "step": 42080
    },
    {
      "epoch": 3.070245823911299,
      "grad_norm": 0.48447391390800476,
      "learning_rate": 1.9297541760887008e-05,
      "loss": 0.0024,
      "step": 42090
    },
    {
      "epoch": 3.0709752717193086,
      "grad_norm": 0.26504451036453247,
      "learning_rate": 1.9290247282806916e-05,
      "loss": 0.0024,
      "step": 42100
    },
    {
      "epoch": 3.0717047195273177,
      "grad_norm": 0.056393031030893326,
      "learning_rate": 1.9282952804726823e-05,
      "loss": 0.0044,
      "step": 42110
    },
    {
      "epoch": 3.0724341673353273,
      "grad_norm": 0.1724780797958374,
      "learning_rate": 1.9275658326646727e-05,
      "loss": 0.0037,
      "step": 42120
    },
    {
      "epoch": 3.0731636151433364,
      "grad_norm": 0.23072417080402374,
      "learning_rate": 1.9268363848566638e-05,
      "loss": 0.0025,
      "step": 42130
    },
    {
      "epoch": 3.073893062951346,
      "grad_norm": 0.03067239746451378,
      "learning_rate": 1.9261069370486542e-05,
      "loss": 0.0032,
      "step": 42140
    },
    {
      "epoch": 3.074622510759355,
      "grad_norm": 0.14475268125534058,
      "learning_rate": 1.925377489240645e-05,
      "loss": 0.0026,
      "step": 42150
    },
    {
      "epoch": 3.0753519585673645,
      "grad_norm": 0.6769121289253235,
      "learning_rate": 1.9246480414326357e-05,
      "loss": 0.0042,
      "step": 42160
    },
    {
      "epoch": 3.0760814063753736,
      "grad_norm": 0.029468359425663948,
      "learning_rate": 1.923918593624626e-05,
      "loss": 0.0042,
      "step": 42170
    },
    {
      "epoch": 3.076810854183383,
      "grad_norm": 0.11687947809696198,
      "learning_rate": 1.923189145816617e-05,
      "loss": 0.0049,
      "step": 42180
    },
    {
      "epoch": 3.0775403019913927,
      "grad_norm": 0.23015476763248444,
      "learning_rate": 1.9224596980086077e-05,
      "loss": 0.0031,
      "step": 42190
    },
    {
      "epoch": 3.078269749799402,
      "grad_norm": 0.2881939709186554,
      "learning_rate": 1.921730250200598e-05,
      "loss": 0.0029,
      "step": 42200
    },
    {
      "epoch": 3.0789991976074114,
      "grad_norm": 0.05746069177985191,
      "learning_rate": 1.9210008023925888e-05,
      "loss": 0.0045,
      "step": 42210
    },
    {
      "epoch": 3.0797286454154205,
      "grad_norm": 0.3456168472766876,
      "learning_rate": 1.9202713545845796e-05,
      "loss": 0.0035,
      "step": 42220
    },
    {
      "epoch": 3.08045809322343,
      "grad_norm": 0.2602238059043884,
      "learning_rate": 1.9195419067765703e-05,
      "loss": 0.0043,
      "step": 42230
    },
    {
      "epoch": 3.081187541031439,
      "grad_norm": 0.20259156823158264,
      "learning_rate": 1.9188124589685607e-05,
      "loss": 0.004,
      "step": 42240
    },
    {
      "epoch": 3.0819169888394486,
      "grad_norm": 0.08899777382612228,
      "learning_rate": 1.9180830111605515e-05,
      "loss": 0.0038,
      "step": 42250
    },
    {
      "epoch": 3.0826464366474577,
      "grad_norm": 0.14397373795509338,
      "learning_rate": 1.9173535633525422e-05,
      "loss": 0.0033,
      "step": 42260
    },
    {
      "epoch": 3.0833758844554673,
      "grad_norm": 0.20158453285694122,
      "learning_rate": 1.9166241155445327e-05,
      "loss": 0.0039,
      "step": 42270
    },
    {
      "epoch": 3.0841053322634764,
      "grad_norm": 0.25869593024253845,
      "learning_rate": 1.9158946677365238e-05,
      "loss": 0.002,
      "step": 42280
    },
    {
      "epoch": 3.084834780071486,
      "grad_norm": 0.17309294641017914,
      "learning_rate": 1.915165219928514e-05,
      "loss": 0.0039,
      "step": 42290
    },
    {
      "epoch": 3.085564227879495,
      "grad_norm": 0.4028266370296478,
      "learning_rate": 1.9144357721205046e-05,
      "loss": 0.0031,
      "step": 42300
    },
    {
      "epoch": 3.0862936756875046,
      "grad_norm": 0.08770791441202164,
      "learning_rate": 1.9137063243124957e-05,
      "loss": 0.0031,
      "step": 42310
    },
    {
      "epoch": 3.087023123495514,
      "grad_norm": 0.17275872826576233,
      "learning_rate": 1.912976876504486e-05,
      "loss": 0.0046,
      "step": 42320
    },
    {
      "epoch": 3.087752571303523,
      "grad_norm": 0.2308076173067093,
      "learning_rate": 1.912247428696477e-05,
      "loss": 0.0031,
      "step": 42330
    },
    {
      "epoch": 3.0884820191115328,
      "grad_norm": 0.4876803457736969,
      "learning_rate": 1.9115179808884676e-05,
      "loss": 0.003,
      "step": 42340
    },
    {
      "epoch": 3.089211466919542,
      "grad_norm": 0.5463361740112305,
      "learning_rate": 1.910788533080458e-05,
      "loss": 0.0025,
      "step": 42350
    },
    {
      "epoch": 3.0899409147275514,
      "grad_norm": 0.14393350481987,
      "learning_rate": 1.910059085272449e-05,
      "loss": 0.0021,
      "step": 42360
    },
    {
      "epoch": 3.0906703625355605,
      "grad_norm": 0.5458030104637146,
      "learning_rate": 1.9093296374644395e-05,
      "loss": 0.002,
      "step": 42370
    },
    {
      "epoch": 3.09139981034357,
      "grad_norm": 0.08666029572486877,
      "learning_rate": 1.9086001896564303e-05,
      "loss": 0.0035,
      "step": 42380
    },
    {
      "epoch": 3.092129258151579,
      "grad_norm": 0.28677070140838623,
      "learning_rate": 1.907870741848421e-05,
      "loss": 0.0029,
      "step": 42390
    },
    {
      "epoch": 3.0928587059595887,
      "grad_norm": 0.43215808272361755,
      "learning_rate": 1.9071412940404114e-05,
      "loss": 0.0034,
      "step": 42400
    },
    {
      "epoch": 3.0935881537675978,
      "grad_norm": 0.1167069599032402,
      "learning_rate": 1.9064118462324022e-05,
      "loss": 0.0041,
      "step": 42410
    },
    {
      "epoch": 3.0943176015756073,
      "grad_norm": 0.258794903755188,
      "learning_rate": 1.905682398424393e-05,
      "loss": 0.0036,
      "step": 42420
    },
    {
      "epoch": 3.0950470493836164,
      "grad_norm": 0.35861799120903015,
      "learning_rate": 1.9049529506163834e-05,
      "loss": 0.0032,
      "step": 42430
    },
    {
      "epoch": 3.095776497191626,
      "grad_norm": 0.2882767617702484,
      "learning_rate": 1.904223502808374e-05,
      "loss": 0.0032,
      "step": 42440
    },
    {
      "epoch": 3.0965059449996355,
      "grad_norm": 0.43126553297042847,
      "learning_rate": 1.903494055000365e-05,
      "loss": 0.003,
      "step": 42450
    },
    {
      "epoch": 3.0972353928076446,
      "grad_norm": 0.34653186798095703,
      "learning_rate": 1.9027646071923556e-05,
      "loss": 0.0059,
      "step": 42460
    },
    {
      "epoch": 3.097964840615654,
      "grad_norm": 0.05997646227478981,
      "learning_rate": 1.902035159384346e-05,
      "loss": 0.0023,
      "step": 42470
    },
    {
      "epoch": 3.0986942884236632,
      "grad_norm": 0.35499638319015503,
      "learning_rate": 1.9013057115763368e-05,
      "loss": 0.0038,
      "step": 42480
    },
    {
      "epoch": 3.0994237362316728,
      "grad_norm": 0.3441929817199707,
      "learning_rate": 1.9005762637683275e-05,
      "loss": 0.0023,
      "step": 42490
    },
    {
      "epoch": 3.100153184039682,
      "grad_norm": 0.030796758830547333,
      "learning_rate": 1.899846815960318e-05,
      "loss": 0.0043,
      "step": 42500
    },
    {
      "epoch": 3.1008826318476914,
      "grad_norm": 0.3732203245162964,
      "learning_rate": 1.899117368152309e-05,
      "loss": 0.0024,
      "step": 42510
    },
    {
      "epoch": 3.1016120796557005,
      "grad_norm": 0.058588482439517975,
      "learning_rate": 1.8983879203442995e-05,
      "loss": 0.0032,
      "step": 42520
    },
    {
      "epoch": 3.10234152746371,
      "grad_norm": 0.09410145878791809,
      "learning_rate": 1.89765847253629e-05,
      "loss": 0.0049,
      "step": 42530
    },
    {
      "epoch": 3.103070975271719,
      "grad_norm": 0.2351209670305252,
      "learning_rate": 1.896929024728281e-05,
      "loss": 0.0045,
      "step": 42540
    },
    {
      "epoch": 3.1038004230797287,
      "grad_norm": 0.1522584706544876,
      "learning_rate": 1.8961995769202714e-05,
      "loss": 0.0041,
      "step": 42550
    },
    {
      "epoch": 3.104529870887738,
      "grad_norm": 0.15433518588542938,
      "learning_rate": 1.895470129112262e-05,
      "loss": 0.0035,
      "step": 42560
    },
    {
      "epoch": 3.1052593186957473,
      "grad_norm": 0.34649384021759033,
      "learning_rate": 1.894740681304253e-05,
      "loss": 0.0019,
      "step": 42570
    },
    {
      "epoch": 3.1059887665037564,
      "grad_norm": 0.08962845057249069,
      "learning_rate": 1.8940112334962433e-05,
      "loss": 0.0032,
      "step": 42580
    },
    {
      "epoch": 3.106718214311766,
      "grad_norm": 0.0082605741918087,
      "learning_rate": 1.893281785688234e-05,
      "loss": 0.0036,
      "step": 42590
    },
    {
      "epoch": 3.1074476621197755,
      "grad_norm": 0.2303665280342102,
      "learning_rate": 1.8925523378802248e-05,
      "loss": 0.0027,
      "step": 42600
    },
    {
      "epoch": 3.1081771099277846,
      "grad_norm": 0.7612071633338928,
      "learning_rate": 1.8918228900722156e-05,
      "loss": 0.0037,
      "step": 42610
    },
    {
      "epoch": 3.108906557735794,
      "grad_norm": 0.08680443465709686,
      "learning_rate": 1.891093442264206e-05,
      "loss": 0.0041,
      "step": 42620
    },
    {
      "epoch": 3.1096360055438033,
      "grad_norm": 0.17409320175647736,
      "learning_rate": 1.8903639944561967e-05,
      "loss": 0.0036,
      "step": 42630
    },
    {
      "epoch": 3.110365453351813,
      "grad_norm": 0.029997745528817177,
      "learning_rate": 1.8896345466481875e-05,
      "loss": 0.0036,
      "step": 42640
    },
    {
      "epoch": 3.111094901159822,
      "grad_norm": 0.05948098003864288,
      "learning_rate": 1.888905098840178e-05,
      "loss": 0.003,
      "step": 42650
    },
    {
      "epoch": 3.1118243489678314,
      "grad_norm": 0.18180443346500397,
      "learning_rate": 1.888175651032169e-05,
      "loss": 0.0035,
      "step": 42660
    },
    {
      "epoch": 3.1125537967758405,
      "grad_norm": 0.3066190481185913,
      "learning_rate": 1.8874462032241594e-05,
      "loss": 0.0026,
      "step": 42670
    },
    {
      "epoch": 3.11328324458385,
      "grad_norm": 0.6939188838005066,
      "learning_rate": 1.8867167554161498e-05,
      "loss": 0.0044,
      "step": 42680
    },
    {
      "epoch": 3.114012692391859,
      "grad_norm": 0.34490758180618286,
      "learning_rate": 1.885987307608141e-05,
      "loss": 0.0031,
      "step": 42690
    },
    {
      "epoch": 3.1147421401998687,
      "grad_norm": 0.2102961242198944,
      "learning_rate": 1.8852578598001313e-05,
      "loss": 0.003,
      "step": 42700
    },
    {
      "epoch": 3.115471588007878,
      "grad_norm": 0.31730717420578003,
      "learning_rate": 1.884528411992122e-05,
      "loss": 0.0045,
      "step": 42710
    },
    {
      "epoch": 3.1162010358158874,
      "grad_norm": 0.28830012679100037,
      "learning_rate": 1.8837989641841128e-05,
      "loss": 0.0024,
      "step": 42720
    },
    {
      "epoch": 3.116930483623897,
      "grad_norm": 0.40333861112594604,
      "learning_rate": 1.8830695163761032e-05,
      "loss": 0.0046,
      "step": 42730
    },
    {
      "epoch": 3.117659931431906,
      "grad_norm": 0.05976436659693718,
      "learning_rate": 1.882340068568094e-05,
      "loss": 0.0032,
      "step": 42740
    },
    {
      "epoch": 3.1183893792399155,
      "grad_norm": 0.43638503551483154,
      "learning_rate": 1.8816106207600847e-05,
      "loss": 0.0035,
      "step": 42750
    },
    {
      "epoch": 3.1191188270479246,
      "grad_norm": 0.14348243176937103,
      "learning_rate": 1.8808811729520755e-05,
      "loss": 0.0028,
      "step": 42760
    },
    {
      "epoch": 3.119848274855934,
      "grad_norm": 0.3461986482143402,
      "learning_rate": 1.880151725144066e-05,
      "loss": 0.0034,
      "step": 42770
    },
    {
      "epoch": 3.1205777226639433,
      "grad_norm": 0.43468207120895386,
      "learning_rate": 1.8794222773360567e-05,
      "loss": 0.0043,
      "step": 42780
    },
    {
      "epoch": 3.121307170471953,
      "grad_norm": 0.17113305628299713,
      "learning_rate": 1.8786928295280474e-05,
      "loss": 0.0049,
      "step": 42790
    },
    {
      "epoch": 3.122036618279962,
      "grad_norm": 0.4980848431587219,
      "learning_rate": 1.8779633817200378e-05,
      "loss": 0.0032,
      "step": 42800
    },
    {
      "epoch": 3.1227660660879715,
      "grad_norm": 0.4534868001937866,
      "learning_rate": 1.8772339339120286e-05,
      "loss": 0.0056,
      "step": 42810
    },
    {
      "epoch": 3.1234955138959806,
      "grad_norm": 0.36102768778800964,
      "learning_rate": 1.8765044861040193e-05,
      "loss": 0.0035,
      "step": 42820
    },
    {
      "epoch": 3.12422496170399,
      "grad_norm": 0.2040763646364212,
      "learning_rate": 1.87577503829601e-05,
      "loss": 0.0028,
      "step": 42830
    },
    {
      "epoch": 3.124954409511999,
      "grad_norm": 0.37767109274864197,
      "learning_rate": 1.875045590488001e-05,
      "loss": 0.0026,
      "step": 42840
    },
    {
      "epoch": 3.1256838573200088,
      "grad_norm": 0.0882585272192955,
      "learning_rate": 1.8743161426799913e-05,
      "loss": 0.0043,
      "step": 42850
    },
    {
      "epoch": 3.1264133051280183,
      "grad_norm": 0.4821017384529114,
      "learning_rate": 1.873586694871982e-05,
      "loss": 0.0029,
      "step": 42860
    },
    {
      "epoch": 3.1271427529360274,
      "grad_norm": 0.058468494564294815,
      "learning_rate": 1.8728572470639728e-05,
      "loss": 0.0034,
      "step": 42870
    },
    {
      "epoch": 3.127872200744037,
      "grad_norm": 0.12074275314807892,
      "learning_rate": 1.8721277992559632e-05,
      "loss": 0.0037,
      "step": 42880
    },
    {
      "epoch": 3.128601648552046,
      "grad_norm": 0.05818662419915199,
      "learning_rate": 1.8713983514479543e-05,
      "loss": 0.0039,
      "step": 42890
    },
    {
      "epoch": 3.1293310963600556,
      "grad_norm": 0.12644389271736145,
      "learning_rate": 1.8706689036399447e-05,
      "loss": 0.004,
      "step": 42900
    },
    {
      "epoch": 3.1300605441680647,
      "grad_norm": 0.05826297774910927,
      "learning_rate": 1.869939455831935e-05,
      "loss": 0.0027,
      "step": 42910
    },
    {
      "epoch": 3.130789991976074,
      "grad_norm": 0.14346231520175934,
      "learning_rate": 1.8692100080239262e-05,
      "loss": 0.004,
      "step": 42920
    },
    {
      "epoch": 3.1315194397840833,
      "grad_norm": 0.14487911760807037,
      "learning_rate": 1.8684805602159166e-05,
      "loss": 0.0028,
      "step": 42930
    },
    {
      "epoch": 3.132248887592093,
      "grad_norm": 0.09515053778886795,
      "learning_rate": 1.8677511124079074e-05,
      "loss": 0.0025,
      "step": 42940
    },
    {
      "epoch": 3.132978335400102,
      "grad_norm": 0.32710495591163635,
      "learning_rate": 1.867021664599898e-05,
      "loss": 0.0026,
      "step": 42950
    },
    {
      "epoch": 3.1337077832081115,
      "grad_norm": 0.49998724460601807,
      "learning_rate": 1.8662922167918885e-05,
      "loss": 0.0026,
      "step": 42960
    },
    {
      "epoch": 3.1344372310161206,
      "grad_norm": 0.144449383020401,
      "learning_rate": 1.8655627689838793e-05,
      "loss": 0.0031,
      "step": 42970
    },
    {
      "epoch": 3.13516667882413,
      "grad_norm": 0.0909738764166832,
      "learning_rate": 1.86483332117587e-05,
      "loss": 0.0021,
      "step": 42980
    },
    {
      "epoch": 3.1358961266321392,
      "grad_norm": 0.11538130789995193,
      "learning_rate": 1.8641038733678608e-05,
      "loss": 0.0037,
      "step": 42990
    },
    {
      "epoch": 3.136625574440149,
      "grad_norm": 0.31620320677757263,
      "learning_rate": 1.8633744255598512e-05,
      "loss": 0.0046,
      "step": 43000
    },
    {
      "epoch": 3.1373550222481583,
      "grad_norm": 0.11498244106769562,
      "learning_rate": 1.862644977751842e-05,
      "loss": 0.004,
      "step": 43010
    },
    {
      "epoch": 3.1380844700561674,
      "grad_norm": 0.28847044706344604,
      "learning_rate": 1.8619155299438327e-05,
      "loss": 0.003,
      "step": 43020
    },
    {
      "epoch": 3.138813917864177,
      "grad_norm": 0.30573463439941406,
      "learning_rate": 1.861186082135823e-05,
      "loss": 0.0048,
      "step": 43030
    },
    {
      "epoch": 3.139543365672186,
      "grad_norm": 0.46118682622909546,
      "learning_rate": 1.860456634327814e-05,
      "loss": 0.0028,
      "step": 43040
    },
    {
      "epoch": 3.1402728134801956,
      "grad_norm": 0.7157125473022461,
      "learning_rate": 1.8597271865198046e-05,
      "loss": 0.0038,
      "step": 43050
    },
    {
      "epoch": 3.1410022612882047,
      "grad_norm": 0.3171987235546112,
      "learning_rate": 1.858997738711795e-05,
      "loss": 0.0035,
      "step": 43060
    },
    {
      "epoch": 3.1417317090962142,
      "grad_norm": 0.2878261208534241,
      "learning_rate": 1.858268290903786e-05,
      "loss": 0.0046,
      "step": 43070
    },
    {
      "epoch": 3.1424611569042233,
      "grad_norm": 0.24042540788650513,
      "learning_rate": 1.8575388430957765e-05,
      "loss": 0.0038,
      "step": 43080
    },
    {
      "epoch": 3.143190604712233,
      "grad_norm": 0.3519401550292969,
      "learning_rate": 1.8568093952877673e-05,
      "loss": 0.0035,
      "step": 43090
    },
    {
      "epoch": 3.143920052520242,
      "grad_norm": 0.20224826037883759,
      "learning_rate": 1.856079947479758e-05,
      "loss": 0.0031,
      "step": 43100
    },
    {
      "epoch": 3.1446495003282515,
      "grad_norm": 1.025373101234436,
      "learning_rate": 1.8553504996717485e-05,
      "loss": 0.0021,
      "step": 43110
    },
    {
      "epoch": 3.145378948136261,
      "grad_norm": 0.40288081765174866,
      "learning_rate": 1.8546210518637392e-05,
      "loss": 0.0035,
      "step": 43120
    },
    {
      "epoch": 3.14610839594427,
      "grad_norm": 0.23094406723976135,
      "learning_rate": 1.85389160405573e-05,
      "loss": 0.0024,
      "step": 43130
    },
    {
      "epoch": 3.1468378437522797,
      "grad_norm": 0.14455555379390717,
      "learning_rate": 1.8531621562477207e-05,
      "loss": 0.0029,
      "step": 43140
    },
    {
      "epoch": 3.147567291560289,
      "grad_norm": 0.11578673124313354,
      "learning_rate": 1.852432708439711e-05,
      "loss": 0.0031,
      "step": 43150
    },
    {
      "epoch": 3.1482967393682983,
      "grad_norm": 0.033988289535045624,
      "learning_rate": 1.851703260631702e-05,
      "loss": 0.0031,
      "step": 43160
    },
    {
      "epoch": 3.1490261871763074,
      "grad_norm": 0.2306361198425293,
      "learning_rate": 1.8509738128236926e-05,
      "loss": 0.0032,
      "step": 43170
    },
    {
      "epoch": 3.149755634984317,
      "grad_norm": 0.8285655975341797,
      "learning_rate": 1.850244365015683e-05,
      "loss": 0.0029,
      "step": 43180
    },
    {
      "epoch": 3.150485082792326,
      "grad_norm": 0.05857059732079506,
      "learning_rate": 1.8495149172076738e-05,
      "loss": 0.0037,
      "step": 43190
    },
    {
      "epoch": 3.1512145306003356,
      "grad_norm": 0.4024655520915985,
      "learning_rate": 1.8487854693996646e-05,
      "loss": 0.0032,
      "step": 43200
    },
    {
      "epoch": 3.1519439784083447,
      "grad_norm": 0.4463173747062683,
      "learning_rate": 1.848056021591655e-05,
      "loss": 0.0033,
      "step": 43210
    },
    {
      "epoch": 3.1526734262163543,
      "grad_norm": 0.209110826253891,
      "learning_rate": 1.847326573783646e-05,
      "loss": 0.004,
      "step": 43220
    },
    {
      "epoch": 3.1534028740243634,
      "grad_norm": 0.14455965161323547,
      "learning_rate": 1.8465971259756365e-05,
      "loss": 0.0031,
      "step": 43230
    },
    {
      "epoch": 3.154132321832373,
      "grad_norm": 0.14345598220825195,
      "learning_rate": 1.8458676781676272e-05,
      "loss": 0.0036,
      "step": 43240
    },
    {
      "epoch": 3.154861769640382,
      "grad_norm": 0.08742130547761917,
      "learning_rate": 1.845138230359618e-05,
      "loss": 0.0041,
      "step": 43250
    },
    {
      "epoch": 3.1555912174483915,
      "grad_norm": 0.2598145008087158,
      "learning_rate": 1.8444087825516084e-05,
      "loss": 0.0033,
      "step": 43260
    },
    {
      "epoch": 3.156320665256401,
      "grad_norm": 0.14332976937294006,
      "learning_rate": 1.843679334743599e-05,
      "loss": 0.0029,
      "step": 43270
    },
    {
      "epoch": 3.15705011306441,
      "grad_norm": 0.03351927921175957,
      "learning_rate": 1.84294988693559e-05,
      "loss": 0.0048,
      "step": 43280
    },
    {
      "epoch": 3.1577795608724197,
      "grad_norm": 0.14433450996875763,
      "learning_rate": 1.8422204391275803e-05,
      "loss": 0.0032,
      "step": 43290
    },
    {
      "epoch": 3.158509008680429,
      "grad_norm": 0.14494390785694122,
      "learning_rate": 1.841490991319571e-05,
      "loss": 0.0026,
      "step": 43300
    },
    {
      "epoch": 3.1592384564884384,
      "grad_norm": 0.11556613445281982,
      "learning_rate": 1.8407615435115618e-05,
      "loss": 0.0023,
      "step": 43310
    },
    {
      "epoch": 3.1599679042964475,
      "grad_norm": 0.2641492486000061,
      "learning_rate": 1.8400320957035526e-05,
      "loss": 0.0037,
      "step": 43320
    },
    {
      "epoch": 3.160697352104457,
      "grad_norm": 0.33684757351875305,
      "learning_rate": 1.8393026478955433e-05,
      "loss": 0.0037,
      "step": 43330
    },
    {
      "epoch": 3.161426799912466,
      "grad_norm": 0.08889646083116531,
      "learning_rate": 1.8385732000875337e-05,
      "loss": 0.003,
      "step": 43340
    },
    {
      "epoch": 3.1621562477204757,
      "grad_norm": 0.25472086668014526,
      "learning_rate": 1.8378437522795245e-05,
      "loss": 0.0048,
      "step": 43350
    },
    {
      "epoch": 3.1628856955284848,
      "grad_norm": 0.345894455909729,
      "learning_rate": 1.8371143044715152e-05,
      "loss": 0.0034,
      "step": 43360
    },
    {
      "epoch": 3.1636151433364943,
      "grad_norm": 0.31524738669395447,
      "learning_rate": 1.836384856663506e-05,
      "loss": 0.0034,
      "step": 43370
    },
    {
      "epoch": 3.164344591144504,
      "grad_norm": 0.25255870819091797,
      "learning_rate": 1.8356554088554964e-05,
      "loss": 0.003,
      "step": 43380
    },
    {
      "epoch": 3.165074038952513,
      "grad_norm": 0.1444062739610672,
      "learning_rate": 1.8349259610474872e-05,
      "loss": 0.004,
      "step": 43390
    },
    {
      "epoch": 3.1658034867605225,
      "grad_norm": 0.23089808225631714,
      "learning_rate": 1.834196513239478e-05,
      "loss": 0.0039,
      "step": 43400
    },
    {
      "epoch": 3.1665329345685316,
      "grad_norm": 0.14420020580291748,
      "learning_rate": 1.8334670654314683e-05,
      "loss": 0.0038,
      "step": 43410
    },
    {
      "epoch": 3.167262382376541,
      "grad_norm": 0.17419463396072388,
      "learning_rate": 1.832737617623459e-05,
      "loss": 0.0034,
      "step": 43420
    },
    {
      "epoch": 3.16799183018455,
      "grad_norm": 0.05827225372195244,
      "learning_rate": 1.83200816981545e-05,
      "loss": 0.0024,
      "step": 43430
    },
    {
      "epoch": 3.1687212779925598,
      "grad_norm": 0.3752876818180084,
      "learning_rate": 1.8312787220074403e-05,
      "loss": 0.0032,
      "step": 43440
    },
    {
      "epoch": 3.169450725800569,
      "grad_norm": 0.3954034745693207,
      "learning_rate": 1.8305492741994313e-05,
      "loss": 0.0025,
      "step": 43450
    },
    {
      "epoch": 3.1701801736085784,
      "grad_norm": 0.05805633217096329,
      "learning_rate": 1.8298198263914218e-05,
      "loss": 0.0045,
      "step": 43460
    },
    {
      "epoch": 3.1709096214165875,
      "grad_norm": 0.08896161615848541,
      "learning_rate": 1.8290903785834125e-05,
      "loss": 0.0041,
      "step": 43470
    },
    {
      "epoch": 3.171639069224597,
      "grad_norm": 0.39982733130455017,
      "learning_rate": 1.8283609307754033e-05,
      "loss": 0.0031,
      "step": 43480
    },
    {
      "epoch": 3.172368517032606,
      "grad_norm": 0.09369688481092453,
      "learning_rate": 1.8276314829673937e-05,
      "loss": 0.003,
      "step": 43490
    },
    {
      "epoch": 3.1730979648406157,
      "grad_norm": 0.3467877507209778,
      "learning_rate": 1.8269020351593844e-05,
      "loss": 0.0035,
      "step": 43500
    },
    {
      "epoch": 3.173827412648625,
      "grad_norm": 0.2591893672943115,
      "learning_rate": 1.8261725873513752e-05,
      "loss": 0.003,
      "step": 43510
    },
    {
      "epoch": 3.1745568604566343,
      "grad_norm": 0.11642035841941833,
      "learning_rate": 1.8254431395433656e-05,
      "loss": 0.0027,
      "step": 43520
    },
    {
      "epoch": 3.175286308264644,
      "grad_norm": 0.20120374858379364,
      "learning_rate": 1.8247136917353564e-05,
      "loss": 0.0036,
      "step": 43530
    },
    {
      "epoch": 3.176015756072653,
      "grad_norm": 0.2030506432056427,
      "learning_rate": 1.823984243927347e-05,
      "loss": 0.0037,
      "step": 43540
    },
    {
      "epoch": 3.1767452038806625,
      "grad_norm": 0.5364950299263,
      "learning_rate": 1.823254796119338e-05,
      "loss": 0.0025,
      "step": 43550
    },
    {
      "epoch": 3.1774746516886716,
      "grad_norm": 0.029667239636182785,
      "learning_rate": 1.8225253483113283e-05,
      "loss": 0.0034,
      "step": 43560
    },
    {
      "epoch": 3.178204099496681,
      "grad_norm": 0.20183511078357697,
      "learning_rate": 1.821795900503319e-05,
      "loss": 0.0028,
      "step": 43570
    },
    {
      "epoch": 3.1789335473046902,
      "grad_norm": 0.05846748128533363,
      "learning_rate": 1.8210664526953098e-05,
      "loss": 0.0023,
      "step": 43580
    },
    {
      "epoch": 3.1796629951127,
      "grad_norm": 0.1161162331700325,
      "learning_rate": 1.8203370048873002e-05,
      "loss": 0.004,
      "step": 43590
    },
    {
      "epoch": 3.180392442920709,
      "grad_norm": 0.2881999611854553,
      "learning_rate": 1.8196075570792913e-05,
      "loss": 0.0039,
      "step": 43600
    },
    {
      "epoch": 3.1811218907287184,
      "grad_norm": 0.2300565391778946,
      "learning_rate": 1.8188781092712817e-05,
      "loss": 0.0027,
      "step": 43610
    },
    {
      "epoch": 3.1818513385367275,
      "grad_norm": 0.2970811724662781,
      "learning_rate": 1.818148661463272e-05,
      "loss": 0.0029,
      "step": 43620
    },
    {
      "epoch": 3.182580786344737,
      "grad_norm": 0.28930819034576416,
      "learning_rate": 1.8174192136552632e-05,
      "loss": 0.0025,
      "step": 43630
    },
    {
      "epoch": 3.183310234152746,
      "grad_norm": 0.05868949368596077,
      "learning_rate": 1.8166897658472536e-05,
      "loss": 0.0036,
      "step": 43640
    },
    {
      "epoch": 3.1840396819607557,
      "grad_norm": 0.1731300801038742,
      "learning_rate": 1.8159603180392444e-05,
      "loss": 0.0031,
      "step": 43650
    },
    {
      "epoch": 3.1847691297687653,
      "grad_norm": 0.1444202959537506,
      "learning_rate": 1.815230870231235e-05,
      "loss": 0.0041,
      "step": 43660
    },
    {
      "epoch": 3.1854985775767743,
      "grad_norm": 0.28320881724357605,
      "learning_rate": 1.8145014224232255e-05,
      "loss": 0.0043,
      "step": 43670
    },
    {
      "epoch": 3.186228025384784,
      "grad_norm": 0.014303040690720081,
      "learning_rate": 1.8137719746152163e-05,
      "loss": 0.003,
      "step": 43680
    },
    {
      "epoch": 3.186957473192793,
      "grad_norm": 0.23101356625556946,
      "learning_rate": 1.813042526807207e-05,
      "loss": 0.0029,
      "step": 43690
    },
    {
      "epoch": 3.1876869210008025,
      "grad_norm": 0.11898777633905411,
      "learning_rate": 1.8123130789991978e-05,
      "loss": 0.0036,
      "step": 43700
    },
    {
      "epoch": 3.1884163688088116,
      "grad_norm": 0.14754419028759003,
      "learning_rate": 1.8115836311911882e-05,
      "loss": 0.0024,
      "step": 43710
    },
    {
      "epoch": 3.189145816616821,
      "grad_norm": 0.32628047466278076,
      "learning_rate": 1.810854183383179e-05,
      "loss": 0.0026,
      "step": 43720
    },
    {
      "epoch": 3.1898752644248303,
      "grad_norm": 0.403860479593277,
      "learning_rate": 1.8101247355751697e-05,
      "loss": 0.0039,
      "step": 43730
    },
    {
      "epoch": 3.19060471223284,
      "grad_norm": 0.2018454372882843,
      "learning_rate": 1.80939528776716e-05,
      "loss": 0.004,
      "step": 43740
    },
    {
      "epoch": 3.191334160040849,
      "grad_norm": 0.4314979016780853,
      "learning_rate": 1.8086658399591512e-05,
      "loss": 0.0023,
      "step": 43750
    },
    {
      "epoch": 3.1920636078488585,
      "grad_norm": 0.355406254529953,
      "learning_rate": 1.8079363921511416e-05,
      "loss": 0.0031,
      "step": 43760
    },
    {
      "epoch": 3.1927930556568676,
      "grad_norm": 0.06042161583900452,
      "learning_rate": 1.807206944343132e-05,
      "loss": 0.0056,
      "step": 43770
    },
    {
      "epoch": 3.193522503464877,
      "grad_norm": 0.29968374967575073,
      "learning_rate": 1.806477496535123e-05,
      "loss": 0.0045,
      "step": 43780
    },
    {
      "epoch": 3.1942519512728866,
      "grad_norm": 0.0600527748465538,
      "learning_rate": 1.8057480487271136e-05,
      "loss": 0.0024,
      "step": 43790
    },
    {
      "epoch": 3.1949813990808957,
      "grad_norm": 0.04529654607176781,
      "learning_rate": 1.8050186009191043e-05,
      "loss": 0.0031,
      "step": 43800
    },
    {
      "epoch": 3.1957108468889053,
      "grad_norm": 0.23486170172691345,
      "learning_rate": 1.804289153111095e-05,
      "loss": 0.005,
      "step": 43810
    },
    {
      "epoch": 3.1964402946969144,
      "grad_norm": 0.22075946629047394,
      "learning_rate": 1.8035597053030855e-05,
      "loss": 0.0021,
      "step": 43820
    },
    {
      "epoch": 3.197169742504924,
      "grad_norm": 0.20068477094173431,
      "learning_rate": 1.8028302574950766e-05,
      "loss": 0.0038,
      "step": 43830
    },
    {
      "epoch": 3.197899190312933,
      "grad_norm": 0.20248165726661682,
      "learning_rate": 1.802100809687067e-05,
      "loss": 0.0029,
      "step": 43840
    },
    {
      "epoch": 3.1986286381209426,
      "grad_norm": 0.17414341866970062,
      "learning_rate": 1.8013713618790577e-05,
      "loss": 0.0039,
      "step": 43850
    },
    {
      "epoch": 3.1993580859289517,
      "grad_norm": 0.169845849275589,
      "learning_rate": 1.8006419140710485e-05,
      "loss": 0.0032,
      "step": 43860
    },
    {
      "epoch": 3.200087533736961,
      "grad_norm": 0.35008957982063293,
      "learning_rate": 1.799912466263039e-05,
      "loss": 0.0031,
      "step": 43870
    },
    {
      "epoch": 3.2008169815449703,
      "grad_norm": 0.058566123247146606,
      "learning_rate": 1.7991830184550297e-05,
      "loss": 0.0037,
      "step": 43880
    },
    {
      "epoch": 3.20154642935298,
      "grad_norm": 0.42363032698631287,
      "learning_rate": 1.7984535706470204e-05,
      "loss": 0.0041,
      "step": 43890
    },
    {
      "epoch": 3.202275877160989,
      "grad_norm": 0.603989839553833,
      "learning_rate": 1.7977241228390108e-05,
      "loss": 0.0035,
      "step": 43900
    },
    {
      "epoch": 3.2030053249689985,
      "grad_norm": 0.20156364142894745,
      "learning_rate": 1.7969946750310016e-05,
      "loss": 0.003,
      "step": 43910
    },
    {
      "epoch": 3.2037347727770076,
      "grad_norm": 0.2300671935081482,
      "learning_rate": 1.7962652272229923e-05,
      "loss": 0.0033,
      "step": 43920
    },
    {
      "epoch": 3.204464220585017,
      "grad_norm": 0.28771695494651794,
      "learning_rate": 1.795535779414983e-05,
      "loss": 0.0025,
      "step": 43930
    },
    {
      "epoch": 3.2051936683930267,
      "grad_norm": 0.05899748206138611,
      "learning_rate": 1.7948063316069735e-05,
      "loss": 0.0031,
      "step": 43940
    },
    {
      "epoch": 3.2059231162010358,
      "grad_norm": 0.20213522017002106,
      "learning_rate": 1.7940768837989643e-05,
      "loss": 0.0035,
      "step": 43950
    },
    {
      "epoch": 3.2066525640090453,
      "grad_norm": 0.05912112444639206,
      "learning_rate": 1.793347435990955e-05,
      "loss": 0.0025,
      "step": 43960
    },
    {
      "epoch": 3.2073820118170544,
      "grad_norm": 0.5371269583702087,
      "learning_rate": 1.7926179881829454e-05,
      "loss": 0.0029,
      "step": 43970
    },
    {
      "epoch": 3.208111459625064,
      "grad_norm": 0.045369330793619156,
      "learning_rate": 1.7918885403749365e-05,
      "loss": 0.0039,
      "step": 43980
    },
    {
      "epoch": 3.208840907433073,
      "grad_norm": 0.2896155118942261,
      "learning_rate": 1.791159092566927e-05,
      "loss": 0.0059,
      "step": 43990
    },
    {
      "epoch": 3.2095703552410826,
      "grad_norm": 0.2013966292142868,
      "learning_rate": 1.7904296447589173e-05,
      "loss": 0.0032,
      "step": 44000
    },
    {
      "epoch": 3.2102998030490917,
      "grad_norm": 0.11573736369609833,
      "learning_rate": 1.7897001969509084e-05,
      "loss": 0.0023,
      "step": 44010
    },
    {
      "epoch": 3.2110292508571012,
      "grad_norm": 0.11514413356781006,
      "learning_rate": 1.788970749142899e-05,
      "loss": 0.0034,
      "step": 44020
    },
    {
      "epoch": 3.2117586986651103,
      "grad_norm": 0.23400773108005524,
      "learning_rate": 1.7882413013348896e-05,
      "loss": 0.0029,
      "step": 44030
    },
    {
      "epoch": 3.21248814647312,
      "grad_norm": 0.1732981652021408,
      "learning_rate": 1.7875118535268804e-05,
      "loss": 0.0037,
      "step": 44040
    },
    {
      "epoch": 3.2132175942811294,
      "grad_norm": 0.05958230793476105,
      "learning_rate": 1.7867824057188708e-05,
      "loss": 0.0022,
      "step": 44050
    },
    {
      "epoch": 3.2139470420891385,
      "grad_norm": 0.23105396330356598,
      "learning_rate": 1.7860529579108615e-05,
      "loss": 0.0024,
      "step": 44060
    },
    {
      "epoch": 3.214676489897148,
      "grad_norm": 0.14440658688545227,
      "learning_rate": 1.7853235101028523e-05,
      "loss": 0.0036,
      "step": 44070
    },
    {
      "epoch": 3.215405937705157,
      "grad_norm": 0.029871458187699318,
      "learning_rate": 1.784594062294843e-05,
      "loss": 0.0035,
      "step": 44080
    },
    {
      "epoch": 3.2161353855131667,
      "grad_norm": 0.4397750496864319,
      "learning_rate": 1.7838646144868334e-05,
      "loss": 0.0038,
      "step": 44090
    },
    {
      "epoch": 3.216864833321176,
      "grad_norm": 0.28706809878349304,
      "learning_rate": 1.7831351666788242e-05,
      "loss": 0.0027,
      "step": 44100
    },
    {
      "epoch": 3.2175942811291853,
      "grad_norm": 0.46622592210769653,
      "learning_rate": 1.782405718870815e-05,
      "loss": 0.0034,
      "step": 44110
    },
    {
      "epoch": 3.2183237289371944,
      "grad_norm": 0.14476491510868073,
      "learning_rate": 1.7816762710628054e-05,
      "loss": 0.0019,
      "step": 44120
    },
    {
      "epoch": 3.219053176745204,
      "grad_norm": 0.2593085467815399,
      "learning_rate": 1.780946823254796e-05,
      "loss": 0.0039,
      "step": 44130
    },
    {
      "epoch": 3.219782624553213,
      "grad_norm": 0.0594540499150753,
      "learning_rate": 1.780217375446787e-05,
      "loss": 0.0034,
      "step": 44140
    },
    {
      "epoch": 3.2205120723612226,
      "grad_norm": 0.05859723314642906,
      "learning_rate": 1.7794879276387773e-05,
      "loss": 0.003,
      "step": 44150
    },
    {
      "epoch": 3.2212415201692317,
      "grad_norm": 0.2624209523200989,
      "learning_rate": 1.7787584798307684e-05,
      "loss": 0.0025,
      "step": 44160
    },
    {
      "epoch": 3.2219709679772413,
      "grad_norm": 0.28899282217025757,
      "learning_rate": 1.7780290320227588e-05,
      "loss": 0.0025,
      "step": 44170
    },
    {
      "epoch": 3.2227004157852503,
      "grad_norm": 0.08659347891807556,
      "learning_rate": 1.7772995842147495e-05,
      "loss": 0.0025,
      "step": 44180
    },
    {
      "epoch": 3.22342986359326,
      "grad_norm": 0.11556358635425568,
      "learning_rate": 1.7765701364067403e-05,
      "loss": 0.0041,
      "step": 44190
    },
    {
      "epoch": 3.2241593114012694,
      "grad_norm": 0.05974087864160538,
      "learning_rate": 1.7758406885987307e-05,
      "loss": 0.0034,
      "step": 44200
    },
    {
      "epoch": 3.2248887592092785,
      "grad_norm": 0.1440446823835373,
      "learning_rate": 1.7751112407907215e-05,
      "loss": 0.0036,
      "step": 44210
    },
    {
      "epoch": 3.225618207017288,
      "grad_norm": 0.030085410922765732,
      "learning_rate": 1.7743817929827122e-05,
      "loss": 0.0029,
      "step": 44220
    },
    {
      "epoch": 3.226347654825297,
      "grad_norm": 0.03289405256509781,
      "learning_rate": 1.773652345174703e-05,
      "loss": 0.0039,
      "step": 44230
    },
    {
      "epoch": 3.2270771026333067,
      "grad_norm": 0.2880078852176666,
      "learning_rate": 1.7729228973666934e-05,
      "loss": 0.0034,
      "step": 44240
    },
    {
      "epoch": 3.227806550441316,
      "grad_norm": 0.08711126446723938,
      "learning_rate": 1.772193449558684e-05,
      "loss": 0.0035,
      "step": 44250
    },
    {
      "epoch": 3.2285359982493254,
      "grad_norm": 0.3094808757305145,
      "learning_rate": 1.771464001750675e-05,
      "loss": 0.0045,
      "step": 44260
    },
    {
      "epoch": 3.2292654460573345,
      "grad_norm": 0.13652829825878143,
      "learning_rate": 1.7707345539426653e-05,
      "loss": 0.0025,
      "step": 44270
    },
    {
      "epoch": 3.229994893865344,
      "grad_norm": 0.08640267699956894,
      "learning_rate": 1.770005106134656e-05,
      "loss": 0.0026,
      "step": 44280
    },
    {
      "epoch": 3.230724341673353,
      "grad_norm": 0.11586716771125793,
      "learning_rate": 1.7692756583266468e-05,
      "loss": 0.0031,
      "step": 44290
    },
    {
      "epoch": 3.2314537894813626,
      "grad_norm": 0.34689050912857056,
      "learning_rate": 1.7685462105186376e-05,
      "loss": 0.0034,
      "step": 44300
    },
    {
      "epoch": 3.232183237289372,
      "grad_norm": 0.38772445917129517,
      "learning_rate": 1.7678167627106283e-05,
      "loss": 0.0048,
      "step": 44310
    },
    {
      "epoch": 3.2329126850973813,
      "grad_norm": 0.4606318771839142,
      "learning_rate": 1.7670873149026187e-05,
      "loss": 0.0033,
      "step": 44320
    },
    {
      "epoch": 3.233642132905391,
      "grad_norm": 0.29449835419654846,
      "learning_rate": 1.7663578670946095e-05,
      "loss": 0.0029,
      "step": 44330
    },
    {
      "epoch": 3.2343715807134,
      "grad_norm": 0.09228719770908356,
      "learning_rate": 1.7656284192866002e-05,
      "loss": 0.0026,
      "step": 44340
    },
    {
      "epoch": 3.2351010285214095,
      "grad_norm": 0.2015015333890915,
      "learning_rate": 1.7648989714785906e-05,
      "loss": 0.0023,
      "step": 44350
    },
    {
      "epoch": 3.2358304763294186,
      "grad_norm": 0.27188625931739807,
      "learning_rate": 1.7641695236705817e-05,
      "loss": 0.0034,
      "step": 44360
    },
    {
      "epoch": 3.236559924137428,
      "grad_norm": 0.3174152076244354,
      "learning_rate": 1.763440075862572e-05,
      "loss": 0.0029,
      "step": 44370
    },
    {
      "epoch": 3.237289371945437,
      "grad_norm": 0.3289763033390045,
      "learning_rate": 1.7627106280545626e-05,
      "loss": 0.0034,
      "step": 44380
    },
    {
      "epoch": 3.2380188197534467,
      "grad_norm": 0.34536078572273254,
      "learning_rate": 1.7619811802465537e-05,
      "loss": 0.0029,
      "step": 44390
    },
    {
      "epoch": 3.238748267561456,
      "grad_norm": 0.3740411698818207,
      "learning_rate": 1.761251732438544e-05,
      "loss": 0.0036,
      "step": 44400
    },
    {
      "epoch": 3.2394777153694654,
      "grad_norm": 0.2302248477935791,
      "learning_rate": 1.7605222846305348e-05,
      "loss": 0.0024,
      "step": 44410
    },
    {
      "epoch": 3.2402071631774745,
      "grad_norm": 0.5548515319824219,
      "learning_rate": 1.7597928368225256e-05,
      "loss": 0.0048,
      "step": 44420
    },
    {
      "epoch": 3.240936610985484,
      "grad_norm": 0.651060163974762,
      "learning_rate": 1.759063389014516e-05,
      "loss": 0.0033,
      "step": 44430
    },
    {
      "epoch": 3.241666058793493,
      "grad_norm": 0.3458389937877655,
      "learning_rate": 1.7583339412065067e-05,
      "loss": 0.0041,
      "step": 44440
    },
    {
      "epoch": 3.2423955066015027,
      "grad_norm": 0.22985833883285522,
      "learning_rate": 1.7576044933984975e-05,
      "loss": 0.0038,
      "step": 44450
    },
    {
      "epoch": 3.243124954409512,
      "grad_norm": 0.11585010588169098,
      "learning_rate": 1.7568750455904883e-05,
      "loss": 0.0025,
      "step": 44460
    },
    {
      "epoch": 3.2438544022175213,
      "grad_norm": 0.1443437784910202,
      "learning_rate": 1.7561455977824787e-05,
      "loss": 0.0037,
      "step": 44470
    },
    {
      "epoch": 3.244583850025531,
      "grad_norm": 0.029518837109208107,
      "learning_rate": 1.7554161499744694e-05,
      "loss": 0.0019,
      "step": 44480
    },
    {
      "epoch": 3.24531329783354,
      "grad_norm": 0.1756111979484558,
      "learning_rate": 1.7546867021664602e-05,
      "loss": 0.0038,
      "step": 44490
    },
    {
      "epoch": 3.2460427456415495,
      "grad_norm": 0.24378612637519836,
      "learning_rate": 1.7539572543584506e-05,
      "loss": 0.0035,
      "step": 44500
    },
    {
      "epoch": 3.2467721934495586,
      "grad_norm": 0.008087312802672386,
      "learning_rate": 1.7532278065504413e-05,
      "loss": 0.0036,
      "step": 44510
    },
    {
      "epoch": 3.247501641257568,
      "grad_norm": 0.40468674898147583,
      "learning_rate": 1.752498358742432e-05,
      "loss": 0.0044,
      "step": 44520
    },
    {
      "epoch": 3.2482310890655772,
      "grad_norm": 0.2882999777793884,
      "learning_rate": 1.7517689109344225e-05,
      "loss": 0.0033,
      "step": 44530
    },
    {
      "epoch": 3.2489605368735868,
      "grad_norm": 0.14427176117897034,
      "learning_rate": 1.7510394631264136e-05,
      "loss": 0.0035,
      "step": 44540
    },
    {
      "epoch": 3.249689984681596,
      "grad_norm": 0.08885654807090759,
      "learning_rate": 1.750310015318404e-05,
      "loss": 0.003,
      "step": 44550
    },
    {
      "epoch": 3.2504194324896054,
      "grad_norm": 0.41823410987854004,
      "learning_rate": 1.7495805675103948e-05,
      "loss": 0.0045,
      "step": 44560
    },
    {
      "epoch": 3.251148880297615,
      "grad_norm": 0.4918121099472046,
      "learning_rate": 1.7488511197023855e-05,
      "loss": 0.0036,
      "step": 44570
    },
    {
      "epoch": 3.251878328105624,
      "grad_norm": 0.2585802674293518,
      "learning_rate": 1.748121671894376e-05,
      "loss": 0.0045,
      "step": 44580
    },
    {
      "epoch": 3.252607775913633,
      "grad_norm": 0.06750739365816116,
      "learning_rate": 1.7473922240863667e-05,
      "loss": 0.0028,
      "step": 44590
    },
    {
      "epoch": 3.2533372237216427,
      "grad_norm": 0.4028123915195465,
      "learning_rate": 1.7466627762783574e-05,
      "loss": 0.0036,
      "step": 44600
    },
    {
      "epoch": 3.2540666715296522,
      "grad_norm": 0.08773577958345413,
      "learning_rate": 1.745933328470348e-05,
      "loss": 0.0038,
      "step": 44610
    },
    {
      "epoch": 3.2547961193376613,
      "grad_norm": 0.3775865435600281,
      "learning_rate": 1.7452038806623386e-05,
      "loss": 0.0019,
      "step": 44620
    },
    {
      "epoch": 3.255525567145671,
      "grad_norm": 0.11569273471832275,
      "learning_rate": 1.7444744328543294e-05,
      "loss": 0.0022,
      "step": 44630
    },
    {
      "epoch": 3.25625501495368,
      "grad_norm": 0.08691106736660004,
      "learning_rate": 1.74374498504632e-05,
      "loss": 0.0046,
      "step": 44640
    },
    {
      "epoch": 3.2569844627616895,
      "grad_norm": 0.17390161752700806,
      "learning_rate": 1.7430155372383105e-05,
      "loss": 0.0031,
      "step": 44650
    },
    {
      "epoch": 3.2577139105696986,
      "grad_norm": 0.03143366053700447,
      "learning_rate": 1.7422860894303013e-05,
      "loss": 0.0033,
      "step": 44660
    },
    {
      "epoch": 3.258443358377708,
      "grad_norm": 0.23078900575637817,
      "learning_rate": 1.741556641622292e-05,
      "loss": 0.005,
      "step": 44670
    },
    {
      "epoch": 3.2591728061857173,
      "grad_norm": 0.06522753089666367,
      "learning_rate": 1.7408271938142824e-05,
      "loss": 0.0034,
      "step": 44680
    },
    {
      "epoch": 3.259902253993727,
      "grad_norm": 0.2170381098985672,
      "learning_rate": 1.7400977460062735e-05,
      "loss": 0.0034,
      "step": 44690
    },
    {
      "epoch": 3.260631701801736,
      "grad_norm": 0.030501730740070343,
      "learning_rate": 1.739368298198264e-05,
      "loss": 0.0046,
      "step": 44700
    },
    {
      "epoch": 3.2613611496097454,
      "grad_norm": 0.08836357295513153,
      "learning_rate": 1.7386388503902544e-05,
      "loss": 0.0029,
      "step": 44710
    },
    {
      "epoch": 3.262090597417755,
      "grad_norm": 0.2077476680278778,
      "learning_rate": 1.7379094025822455e-05,
      "loss": 0.004,
      "step": 44720
    },
    {
      "epoch": 3.262820045225764,
      "grad_norm": 0.11513034254312515,
      "learning_rate": 1.737179954774236e-05,
      "loss": 0.0029,
      "step": 44730
    },
    {
      "epoch": 3.2635494930337736,
      "grad_norm": 0.020251687616109848,
      "learning_rate": 1.7364505069662266e-05,
      "loss": 0.0032,
      "step": 44740
    },
    {
      "epoch": 3.2642789408417827,
      "grad_norm": 0.11609270423650742,
      "learning_rate": 1.7357210591582174e-05,
      "loss": 0.0042,
      "step": 44750
    },
    {
      "epoch": 3.2650083886497923,
      "grad_norm": 0.0313996747136116,
      "learning_rate": 1.7349916113502078e-05,
      "loss": 0.0034,
      "step": 44760
    },
    {
      "epoch": 3.2657378364578014,
      "grad_norm": 0.11588580906391144,
      "learning_rate": 1.7342621635421985e-05,
      "loss": 0.0039,
      "step": 44770
    },
    {
      "epoch": 3.266467284265811,
      "grad_norm": 0.10094400495290756,
      "learning_rate": 1.7335327157341893e-05,
      "loss": 0.0037,
      "step": 44780
    },
    {
      "epoch": 3.26719673207382,
      "grad_norm": 0.1734025478363037,
      "learning_rate": 1.73280326792618e-05,
      "loss": 0.0033,
      "step": 44790
    },
    {
      "epoch": 3.2679261798818295,
      "grad_norm": 0.11622357368469238,
      "learning_rate": 1.7320738201181708e-05,
      "loss": 0.0026,
      "step": 44800
    },
    {
      "epoch": 3.2686556276898386,
      "grad_norm": 0.2590770721435547,
      "learning_rate": 1.7313443723101612e-05,
      "loss": 0.004,
      "step": 44810
    },
    {
      "epoch": 3.269385075497848,
      "grad_norm": 0.012070421129465103,
      "learning_rate": 1.730614924502152e-05,
      "loss": 0.0029,
      "step": 44820
    },
    {
      "epoch": 3.2701145233058573,
      "grad_norm": 0.2867954969406128,
      "learning_rate": 1.7298854766941427e-05,
      "loss": 0.0035,
      "step": 44830
    },
    {
      "epoch": 3.270843971113867,
      "grad_norm": 0.18290071189403534,
      "learning_rate": 1.7291560288861335e-05,
      "loss": 0.0036,
      "step": 44840
    },
    {
      "epoch": 3.271573418921876,
      "grad_norm": 0.17842094600200653,
      "learning_rate": 1.728426581078124e-05,
      "loss": 0.0034,
      "step": 44850
    },
    {
      "epoch": 3.2723028667298855,
      "grad_norm": 0.19719968736171722,
      "learning_rate": 1.7276971332701146e-05,
      "loss": 0.0038,
      "step": 44860
    },
    {
      "epoch": 3.273032314537895,
      "grad_norm": 0.11532542109489441,
      "learning_rate": 1.7269676854621054e-05,
      "loss": 0.0035,
      "step": 44870
    },
    {
      "epoch": 3.273761762345904,
      "grad_norm": 0.11583807319402695,
      "learning_rate": 1.7262382376540958e-05,
      "loss": 0.0044,
      "step": 44880
    },
    {
      "epoch": 3.2744912101539136,
      "grad_norm": 0.1453276425600052,
      "learning_rate": 1.7255087898460866e-05,
      "loss": 0.0029,
      "step": 44890
    },
    {
      "epoch": 3.2752206579619227,
      "grad_norm": 0.49439242482185364,
      "learning_rate": 1.7247793420380773e-05,
      "loss": 0.0041,
      "step": 44900
    },
    {
      "epoch": 3.2759501057699323,
      "grad_norm": 0.2163579910993576,
      "learning_rate": 1.7240498942300677e-05,
      "loss": 0.004,
      "step": 44910
    },
    {
      "epoch": 3.2766795535779414,
      "grad_norm": 0.15464983880519867,
      "learning_rate": 1.7233204464220588e-05,
      "loss": 0.0028,
      "step": 44920
    },
    {
      "epoch": 3.277409001385951,
      "grad_norm": 0.11493434756994247,
      "learning_rate": 1.7225909986140492e-05,
      "loss": 0.0031,
      "step": 44930
    },
    {
      "epoch": 3.27813844919396,
      "grad_norm": 0.11769671738147736,
      "learning_rate": 1.72186155080604e-05,
      "loss": 0.002,
      "step": 44940
    },
    {
      "epoch": 3.2788678970019696,
      "grad_norm": 0.23812925815582275,
      "learning_rate": 1.7211321029980307e-05,
      "loss": 0.003,
      "step": 44950
    },
    {
      "epoch": 3.2795973448099787,
      "grad_norm": 0.14397980272769928,
      "learning_rate": 1.720402655190021e-05,
      "loss": 0.0037,
      "step": 44960
    },
    {
      "epoch": 3.280326792617988,
      "grad_norm": 0.5895074009895325,
      "learning_rate": 1.719673207382012e-05,
      "loss": 0.0055,
      "step": 44970
    },
    {
      "epoch": 3.2810562404259977,
      "grad_norm": 0.25174131989479065,
      "learning_rate": 1.7189437595740027e-05,
      "loss": 0.0039,
      "step": 44980
    },
    {
      "epoch": 3.281785688234007,
      "grad_norm": 0.5911660194396973,
      "learning_rate": 1.718214311765993e-05,
      "loss": 0.0042,
      "step": 44990
    },
    {
      "epoch": 3.282515136042016,
      "grad_norm": 0.14368285238742828,
      "learning_rate": 1.717484863957984e-05,
      "loss": 0.0042,
      "step": 45000
    },
    {
      "epoch": 3.2832445838500255,
      "grad_norm": 0.058447256684303284,
      "learning_rate": 1.7167554161499746e-05,
      "loss": 0.0034,
      "step": 45010
    },
    {
      "epoch": 3.283974031658035,
      "grad_norm": 0.5523756146430969,
      "learning_rate": 1.7160259683419653e-05,
      "loss": 0.0041,
      "step": 45020
    },
    {
      "epoch": 3.284703479466044,
      "grad_norm": 0.05852905288338661,
      "learning_rate": 1.7152965205339558e-05,
      "loss": 0.0027,
      "step": 45030
    },
    {
      "epoch": 3.2854329272740537,
      "grad_norm": 0.31737610697746277,
      "learning_rate": 1.7145670727259465e-05,
      "loss": 0.004,
      "step": 45040
    },
    {
      "epoch": 3.2861623750820628,
      "grad_norm": 0.01197432167828083,
      "learning_rate": 1.7138376249179373e-05,
      "loss": 0.0031,
      "step": 45050
    },
    {
      "epoch": 3.2868918228900723,
      "grad_norm": 0.11525437980890274,
      "learning_rate": 1.7131081771099277e-05,
      "loss": 0.0025,
      "step": 45060
    },
    {
      "epoch": 3.2876212706980814,
      "grad_norm": 0.3737480342388153,
      "learning_rate": 1.7123787293019188e-05,
      "loss": 0.0036,
      "step": 45070
    },
    {
      "epoch": 3.288350718506091,
      "grad_norm": 0.1724233329296112,
      "learning_rate": 1.7116492814939092e-05,
      "loss": 0.004,
      "step": 45080
    },
    {
      "epoch": 3.2890801663141,
      "grad_norm": 0.05936509370803833,
      "learning_rate": 1.7109198336858996e-05,
      "loss": 0.0035,
      "step": 45090
    },
    {
      "epoch": 3.2898096141221096,
      "grad_norm": 0.1221347376704216,
      "learning_rate": 1.7101903858778907e-05,
      "loss": 0.0028,
      "step": 45100
    },
    {
      "epoch": 3.2905390619301187,
      "grad_norm": 0.05782554671168327,
      "learning_rate": 1.709460938069881e-05,
      "loss": 0.003,
      "step": 45110
    },
    {
      "epoch": 3.2912685097381282,
      "grad_norm": 0.20216810703277588,
      "learning_rate": 1.708731490261872e-05,
      "loss": 0.0037,
      "step": 45120
    },
    {
      "epoch": 3.2919979575461378,
      "grad_norm": 0.14518235623836517,
      "learning_rate": 1.7080020424538626e-05,
      "loss": 0.0028,
      "step": 45130
    },
    {
      "epoch": 3.292727405354147,
      "grad_norm": 0.22990542650222778,
      "learning_rate": 1.707272594645853e-05,
      "loss": 0.0035,
      "step": 45140
    },
    {
      "epoch": 3.2934568531621564,
      "grad_norm": 0.31699123978614807,
      "learning_rate": 1.7065431468378438e-05,
      "loss": 0.0033,
      "step": 45150
    },
    {
      "epoch": 3.2941863009701655,
      "grad_norm": 0.057803090661764145,
      "learning_rate": 1.7058136990298345e-05,
      "loss": 0.003,
      "step": 45160
    },
    {
      "epoch": 3.294915748778175,
      "grad_norm": 0.057337064296007156,
      "learning_rate": 1.7050842512218253e-05,
      "loss": 0.0025,
      "step": 45170
    },
    {
      "epoch": 3.295645196586184,
      "grad_norm": 0.10268483310937881,
      "learning_rate": 1.7043548034138157e-05,
      "loss": 0.0028,
      "step": 45180
    },
    {
      "epoch": 3.2963746443941937,
      "grad_norm": 0.14366628229618073,
      "learning_rate": 1.7036253556058064e-05,
      "loss": 0.0024,
      "step": 45190
    },
    {
      "epoch": 3.297104092202203,
      "grad_norm": 0.009236243553459644,
      "learning_rate": 1.7028959077977972e-05,
      "loss": 0.0026,
      "step": 45200
    },
    {
      "epoch": 3.2978335400102123,
      "grad_norm": 0.08719795942306519,
      "learning_rate": 1.7021664599897876e-05,
      "loss": 0.005,
      "step": 45210
    },
    {
      "epoch": 3.2985629878182214,
      "grad_norm": 1.4037680625915527,
      "learning_rate": 1.7014370121817784e-05,
      "loss": 0.0034,
      "step": 45220
    },
    {
      "epoch": 3.299292435626231,
      "grad_norm": 0.14970873296260834,
      "learning_rate": 1.700707564373769e-05,
      "loss": 0.0036,
      "step": 45230
    },
    {
      "epoch": 3.3000218834342405,
      "grad_norm": 0.084405317902565,
      "learning_rate": 1.6999781165657595e-05,
      "loss": 0.0026,
      "step": 45240
    },
    {
      "epoch": 3.3007513312422496,
      "grad_norm": 0.2109033465385437,
      "learning_rate": 1.6992486687577506e-05,
      "loss": 0.0025,
      "step": 45250
    },
    {
      "epoch": 3.3014807790502587,
      "grad_norm": 0.25988417863845825,
      "learning_rate": 1.698519220949741e-05,
      "loss": 0.0029,
      "step": 45260
    },
    {
      "epoch": 3.3022102268582683,
      "grad_norm": 0.058894094079732895,
      "learning_rate": 1.6977897731417318e-05,
      "loss": 0.002,
      "step": 45270
    },
    {
      "epoch": 3.302939674666278,
      "grad_norm": 0.3456777334213257,
      "learning_rate": 1.6970603253337225e-05,
      "loss": 0.004,
      "step": 45280
    },
    {
      "epoch": 3.303669122474287,
      "grad_norm": 0.1441442221403122,
      "learning_rate": 1.696330877525713e-05,
      "loss": 0.0025,
      "step": 45290
    },
    {
      "epoch": 3.3043985702822964,
      "grad_norm": 0.14382074773311615,
      "learning_rate": 1.695601429717704e-05,
      "loss": 0.0038,
      "step": 45300
    },
    {
      "epoch": 3.3051280180903055,
      "grad_norm": 0.3243611454963684,
      "learning_rate": 1.6948719819096945e-05,
      "loss": 0.0029,
      "step": 45310
    },
    {
      "epoch": 3.305857465898315,
      "grad_norm": 0.1148473396897316,
      "learning_rate": 1.6941425341016852e-05,
      "loss": 0.0028,
      "step": 45320
    },
    {
      "epoch": 3.306586913706324,
      "grad_norm": 0.37421470880508423,
      "learning_rate": 1.693413086293676e-05,
      "loss": 0.0035,
      "step": 45330
    },
    {
      "epoch": 3.3073163615143337,
      "grad_norm": 0.25941571593284607,
      "learning_rate": 1.6926836384856664e-05,
      "loss": 0.0049,
      "step": 45340
    },
    {
      "epoch": 3.308045809322343,
      "grad_norm": 0.08709019422531128,
      "learning_rate": 1.691954190677657e-05,
      "loss": 0.0021,
      "step": 45350
    },
    {
      "epoch": 3.3087752571303524,
      "grad_norm": 0.2679094076156616,
      "learning_rate": 1.691224742869648e-05,
      "loss": 0.0043,
      "step": 45360
    },
    {
      "epoch": 3.3095047049383615,
      "grad_norm": 0.2596607506275177,
      "learning_rate": 1.6904952950616383e-05,
      "loss": 0.0039,
      "step": 45370
    },
    {
      "epoch": 3.310234152746371,
      "grad_norm": 0.11588273197412491,
      "learning_rate": 1.689765847253629e-05,
      "loss": 0.0032,
      "step": 45380
    },
    {
      "epoch": 3.3109636005543805,
      "grad_norm": 0.11463376879692078,
      "learning_rate": 1.6890363994456198e-05,
      "loss": 0.0028,
      "step": 45390
    },
    {
      "epoch": 3.3116930483623896,
      "grad_norm": 0.029927851632237434,
      "learning_rate": 1.6883069516376106e-05,
      "loss": 0.0029,
      "step": 45400
    },
    {
      "epoch": 3.312422496170399,
      "grad_norm": 0.14424775540828705,
      "learning_rate": 1.687577503829601e-05,
      "loss": 0.0039,
      "step": 45410
    },
    {
      "epoch": 3.3131519439784083,
      "grad_norm": 0.058532264083623886,
      "learning_rate": 1.6868480560215917e-05,
      "loss": 0.0027,
      "step": 45420
    },
    {
      "epoch": 3.313881391786418,
      "grad_norm": 0.17321361601352692,
      "learning_rate": 1.6861186082135825e-05,
      "loss": 0.0023,
      "step": 45430
    },
    {
      "epoch": 3.314610839594427,
      "grad_norm": 0.0860307589173317,
      "learning_rate": 1.685389160405573e-05,
      "loss": 0.0029,
      "step": 45440
    },
    {
      "epoch": 3.3153402874024365,
      "grad_norm": 0.019130023196339607,
      "learning_rate": 1.684659712597564e-05,
      "loss": 0.003,
      "step": 45450
    },
    {
      "epoch": 3.3160697352104456,
      "grad_norm": 0.2689351737499237,
      "learning_rate": 1.6839302647895544e-05,
      "loss": 0.003,
      "step": 45460
    },
    {
      "epoch": 3.316799183018455,
      "grad_norm": 0.18927334249019623,
      "learning_rate": 1.6832008169815448e-05,
      "loss": 0.0035,
      "step": 45470
    },
    {
      "epoch": 3.317528630826464,
      "grad_norm": 0.11544481664896011,
      "learning_rate": 1.682471369173536e-05,
      "loss": 0.0028,
      "step": 45480
    },
    {
      "epoch": 3.3182580786344738,
      "grad_norm": 0.17641226947307587,
      "learning_rate": 1.6817419213655263e-05,
      "loss": 0.0033,
      "step": 45490
    },
    {
      "epoch": 3.318987526442483,
      "grad_norm": 0.17237995564937592,
      "learning_rate": 1.681012473557517e-05,
      "loss": 0.0039,
      "step": 45500
    },
    {
      "epoch": 3.3197169742504924,
      "grad_norm": 0.03165029361844063,
      "learning_rate": 1.680283025749508e-05,
      "loss": 0.0037,
      "step": 45510
    },
    {
      "epoch": 3.3204464220585015,
      "grad_norm": 0.22970595955848694,
      "learning_rate": 1.6795535779414982e-05,
      "loss": 0.0042,
      "step": 45520
    },
    {
      "epoch": 3.321175869866511,
      "grad_norm": 0.25862857699394226,
      "learning_rate": 1.678824130133489e-05,
      "loss": 0.0026,
      "step": 45530
    },
    {
      "epoch": 3.3219053176745206,
      "grad_norm": 0.11432656645774841,
      "learning_rate": 1.6780946823254798e-05,
      "loss": 0.0042,
      "step": 45540
    },
    {
      "epoch": 3.3226347654825297,
      "grad_norm": 0.11499615758657455,
      "learning_rate": 1.6773652345174705e-05,
      "loss": 0.004,
      "step": 45550
    },
    {
      "epoch": 3.323364213290539,
      "grad_norm": 0.30265045166015625,
      "learning_rate": 1.676635786709461e-05,
      "loss": 0.0027,
      "step": 45560
    },
    {
      "epoch": 3.3240936610985483,
      "grad_norm": 0.08729953318834305,
      "learning_rate": 1.6759063389014517e-05,
      "loss": 0.0039,
      "step": 45570
    },
    {
      "epoch": 3.324823108906558,
      "grad_norm": 0.08654709905385971,
      "learning_rate": 1.6751768910934424e-05,
      "loss": 0.0034,
      "step": 45580
    },
    {
      "epoch": 3.325552556714567,
      "grad_norm": 0.2900397777557373,
      "learning_rate": 1.674447443285433e-05,
      "loss": 0.0042,
      "step": 45590
    },
    {
      "epoch": 3.3262820045225765,
      "grad_norm": 0.17486372590065002,
      "learning_rate": 1.6737179954774236e-05,
      "loss": 0.0034,
      "step": 45600
    },
    {
      "epoch": 3.3270114523305856,
      "grad_norm": 0.029925474897027016,
      "learning_rate": 1.6729885476694143e-05,
      "loss": 0.004,
      "step": 45610
    },
    {
      "epoch": 3.327740900138595,
      "grad_norm": 0.0863218605518341,
      "learning_rate": 1.6722590998614048e-05,
      "loss": 0.0036,
      "step": 45620
    },
    {
      "epoch": 3.3284703479466042,
      "grad_norm": 0.260097473859787,
      "learning_rate": 1.671529652053396e-05,
      "loss": 0.0029,
      "step": 45630
    },
    {
      "epoch": 3.3291997957546138,
      "grad_norm": 0.031142927706241608,
      "learning_rate": 1.6708002042453863e-05,
      "loss": 0.0032,
      "step": 45640
    },
    {
      "epoch": 3.3299292435626233,
      "grad_norm": 0.1213516965508461,
      "learning_rate": 1.670070756437377e-05,
      "loss": 0.003,
      "step": 45650
    },
    {
      "epoch": 3.3306586913706324,
      "grad_norm": 0.1154540553689003,
      "learning_rate": 1.6693413086293678e-05,
      "loss": 0.0031,
      "step": 45660
    },
    {
      "epoch": 3.331388139178642,
      "grad_norm": 0.4424947500228882,
      "learning_rate": 1.6686118608213582e-05,
      "loss": 0.0038,
      "step": 45670
    },
    {
      "epoch": 3.332117586986651,
      "grad_norm": 0.030003024265170097,
      "learning_rate": 1.667882413013349e-05,
      "loss": 0.0031,
      "step": 45680
    },
    {
      "epoch": 3.3328470347946606,
      "grad_norm": 0.231308251619339,
      "learning_rate": 1.6671529652053397e-05,
      "loss": 0.0029,
      "step": 45690
    },
    {
      "epoch": 3.3335764826026697,
      "grad_norm": 0.41357022523880005,
      "learning_rate": 1.66642351739733e-05,
      "loss": 0.004,
      "step": 45700
    },
    {
      "epoch": 3.3343059304106792,
      "grad_norm": 0.0586216039955616,
      "learning_rate": 1.665694069589321e-05,
      "loss": 0.0035,
      "step": 45710
    },
    {
      "epoch": 3.3350353782186883,
      "grad_norm": 0.34631451964378357,
      "learning_rate": 1.6649646217813116e-05,
      "loss": 0.0022,
      "step": 45720
    },
    {
      "epoch": 3.335764826026698,
      "grad_norm": 0.12219215929508209,
      "learning_rate": 1.6642351739733024e-05,
      "loss": 0.0041,
      "step": 45730
    },
    {
      "epoch": 3.336494273834707,
      "grad_norm": 0.12051250040531158,
      "learning_rate": 1.6635057261652928e-05,
      "loss": 0.0046,
      "step": 45740
    },
    {
      "epoch": 3.3372237216427165,
      "grad_norm": 0.23115979135036469,
      "learning_rate": 1.6627762783572835e-05,
      "loss": 0.0034,
      "step": 45750
    },
    {
      "epoch": 3.3379531694507256,
      "grad_norm": 0.15367485582828522,
      "learning_rate": 1.6620468305492743e-05,
      "loss": 0.0029,
      "step": 45760
    },
    {
      "epoch": 3.338682617258735,
      "grad_norm": 0.051833704113960266,
      "learning_rate": 1.6613173827412647e-05,
      "loss": 0.003,
      "step": 45770
    },
    {
      "epoch": 3.3394120650667443,
      "grad_norm": 0.029687710106372833,
      "learning_rate": 1.6605879349332558e-05,
      "loss": 0.0027,
      "step": 45780
    },
    {
      "epoch": 3.340141512874754,
      "grad_norm": 0.2822055220603943,
      "learning_rate": 1.6598584871252462e-05,
      "loss": 0.0035,
      "step": 45790
    },
    {
      "epoch": 3.3408709606827633,
      "grad_norm": 0.42349955439567566,
      "learning_rate": 1.659129039317237e-05,
      "loss": 0.0041,
      "step": 45800
    },
    {
      "epoch": 3.3416004084907724,
      "grad_norm": 0.08804943412542343,
      "learning_rate": 1.6583995915092277e-05,
      "loss": 0.0015,
      "step": 45810
    },
    {
      "epoch": 3.342329856298782,
      "grad_norm": 0.08697336912155151,
      "learning_rate": 1.657670143701218e-05,
      "loss": 0.0031,
      "step": 45820
    },
    {
      "epoch": 3.343059304106791,
      "grad_norm": 0.23013314604759216,
      "learning_rate": 1.6569406958932092e-05,
      "loss": 0.0046,
      "step": 45830
    },
    {
      "epoch": 3.3437887519148006,
      "grad_norm": 0.21150794625282288,
      "learning_rate": 1.6562112480851996e-05,
      "loss": 0.0025,
      "step": 45840
    },
    {
      "epoch": 3.3445181997228097,
      "grad_norm": 0.08710290491580963,
      "learning_rate": 1.65548180027719e-05,
      "loss": 0.0029,
      "step": 45850
    },
    {
      "epoch": 3.3452476475308193,
      "grad_norm": 0.18221986293792725,
      "learning_rate": 1.654752352469181e-05,
      "loss": 0.0041,
      "step": 45860
    },
    {
      "epoch": 3.3459770953388284,
      "grad_norm": 0.2981944978237152,
      "learning_rate": 1.6540229046611716e-05,
      "loss": 0.003,
      "step": 45870
    },
    {
      "epoch": 3.346706543146838,
      "grad_norm": 0.19584667682647705,
      "learning_rate": 1.6532934568531623e-05,
      "loss": 0.0034,
      "step": 45880
    },
    {
      "epoch": 3.347435990954847,
      "grad_norm": 0.23081402480602264,
      "learning_rate": 1.652564009045153e-05,
      "loss": 0.0033,
      "step": 45890
    },
    {
      "epoch": 3.3481654387628565,
      "grad_norm": 0.04668630287051201,
      "learning_rate": 1.6518345612371435e-05,
      "loss": 0.0029,
      "step": 45900
    },
    {
      "epoch": 3.348894886570866,
      "grad_norm": 0.030211802572011948,
      "learning_rate": 1.6511051134291342e-05,
      "loss": 0.0032,
      "step": 45910
    },
    {
      "epoch": 3.349624334378875,
      "grad_norm": 0.06176447123289108,
      "learning_rate": 1.650375665621125e-05,
      "loss": 0.0039,
      "step": 45920
    },
    {
      "epoch": 3.3503537821868843,
      "grad_norm": 0.3637036979198456,
      "learning_rate": 1.6496462178131157e-05,
      "loss": 0.0047,
      "step": 45930
    },
    {
      "epoch": 3.351083229994894,
      "grad_norm": 0.061050042510032654,
      "learning_rate": 1.648916770005106e-05,
      "loss": 0.0044,
      "step": 45940
    },
    {
      "epoch": 3.3518126778029034,
      "grad_norm": 0.0934797003865242,
      "learning_rate": 1.648187322197097e-05,
      "loss": 0.0042,
      "step": 45950
    },
    {
      "epoch": 3.3525421256109125,
      "grad_norm": 0.08791665732860565,
      "learning_rate": 1.6474578743890876e-05,
      "loss": 0.004,
      "step": 45960
    },
    {
      "epoch": 3.353271573418922,
      "grad_norm": 0.37441831827163696,
      "learning_rate": 1.646728426581078e-05,
      "loss": 0.0032,
      "step": 45970
    },
    {
      "epoch": 3.354001021226931,
      "grad_norm": 0.2878682017326355,
      "learning_rate": 1.6459989787730688e-05,
      "loss": 0.0029,
      "step": 45980
    },
    {
      "epoch": 3.3547304690349407,
      "grad_norm": 0.29610130190849304,
      "learning_rate": 1.6452695309650596e-05,
      "loss": 0.0027,
      "step": 45990
    },
    {
      "epoch": 3.3554599168429498,
      "grad_norm": 0.1729845404624939,
      "learning_rate": 1.64454008315705e-05,
      "loss": 0.0042,
      "step": 46000
    },
    {
      "epoch": 3.3561893646509593,
      "grad_norm": 0.2637956142425537,
      "learning_rate": 1.643810635349041e-05,
      "loss": 0.0035,
      "step": 46010
    },
    {
      "epoch": 3.3569188124589684,
      "grad_norm": 0.1441439688205719,
      "learning_rate": 1.6430811875410315e-05,
      "loss": 0.0024,
      "step": 46020
    },
    {
      "epoch": 3.357648260266978,
      "grad_norm": 0.17220866680145264,
      "learning_rate": 1.6423517397330222e-05,
      "loss": 0.0032,
      "step": 46030
    },
    {
      "epoch": 3.358377708074987,
      "grad_norm": 0.1457078456878662,
      "learning_rate": 1.641622291925013e-05,
      "loss": 0.0032,
      "step": 46040
    },
    {
      "epoch": 3.3591071558829966,
      "grad_norm": 0.03352482616901398,
      "learning_rate": 1.6408928441170034e-05,
      "loss": 0.0034,
      "step": 46050
    },
    {
      "epoch": 3.359836603691006,
      "grad_norm": 0.06929564476013184,
      "learning_rate": 1.640163396308994e-05,
      "loss": 0.003,
      "step": 46060
    },
    {
      "epoch": 3.360566051499015,
      "grad_norm": 0.2768731713294983,
      "learning_rate": 1.639433948500985e-05,
      "loss": 0.0033,
      "step": 46070
    },
    {
      "epoch": 3.3612954993070248,
      "grad_norm": 0.195235937833786,
      "learning_rate": 1.6387045006929753e-05,
      "loss": 0.0028,
      "step": 46080
    },
    {
      "epoch": 3.362024947115034,
      "grad_norm": 0.2312813401222229,
      "learning_rate": 1.637975052884966e-05,
      "loss": 0.0039,
      "step": 46090
    },
    {
      "epoch": 3.3627543949230434,
      "grad_norm": 0.05895897001028061,
      "learning_rate": 1.637245605076957e-05,
      "loss": 0.0024,
      "step": 46100
    },
    {
      "epoch": 3.3634838427310525,
      "grad_norm": 0.144447922706604,
      "learning_rate": 1.6365161572689476e-05,
      "loss": 0.0036,
      "step": 46110
    },
    {
      "epoch": 3.364213290539062,
      "grad_norm": 0.37722206115722656,
      "learning_rate": 1.635786709460938e-05,
      "loss": 0.004,
      "step": 46120
    },
    {
      "epoch": 3.364942738347071,
      "grad_norm": 0.29947957396507263,
      "learning_rate": 1.6350572616529288e-05,
      "loss": 0.0033,
      "step": 46130
    },
    {
      "epoch": 3.3656721861550807,
      "grad_norm": 0.28797057271003723,
      "learning_rate": 1.6343278138449195e-05,
      "loss": 0.0029,
      "step": 46140
    },
    {
      "epoch": 3.36640163396309,
      "grad_norm": 0.15993760526180267,
      "learning_rate": 1.63359836603691e-05,
      "loss": 0.0033,
      "step": 46150
    },
    {
      "epoch": 3.3671310817710993,
      "grad_norm": 0.11837968230247498,
      "learning_rate": 1.632868918228901e-05,
      "loss": 0.0031,
      "step": 46160
    },
    {
      "epoch": 3.367860529579109,
      "grad_norm": 0.008604995906352997,
      "learning_rate": 1.6321394704208914e-05,
      "loss": 0.0031,
      "step": 46170
    },
    {
      "epoch": 3.368589977387118,
      "grad_norm": 0.057991284877061844,
      "learning_rate": 1.631410022612882e-05,
      "loss": 0.0042,
      "step": 46180
    },
    {
      "epoch": 3.369319425195127,
      "grad_norm": 0.25977352261543274,
      "learning_rate": 1.630680574804873e-05,
      "loss": 0.0043,
      "step": 46190
    },
    {
      "epoch": 3.3700488730031366,
      "grad_norm": 0.31244540214538574,
      "learning_rate": 1.6299511269968634e-05,
      "loss": 0.003,
      "step": 46200
    },
    {
      "epoch": 3.370778320811146,
      "grad_norm": 0.17274458706378937,
      "learning_rate": 1.629221679188854e-05,
      "loss": 0.0025,
      "step": 46210
    },
    {
      "epoch": 3.3715077686191552,
      "grad_norm": 0.2593713104724884,
      "learning_rate": 1.628492231380845e-05,
      "loss": 0.0038,
      "step": 46220
    },
    {
      "epoch": 3.372237216427165,
      "grad_norm": 0.11600102484226227,
      "learning_rate": 1.6277627835728353e-05,
      "loss": 0.0023,
      "step": 46230
    },
    {
      "epoch": 3.372966664235174,
      "grad_norm": 0.0576578825712204,
      "learning_rate": 1.627033335764826e-05,
      "loss": 0.0035,
      "step": 46240
    },
    {
      "epoch": 3.3736961120431834,
      "grad_norm": 0.2367430180311203,
      "learning_rate": 1.6263038879568168e-05,
      "loss": 0.0025,
      "step": 46250
    },
    {
      "epoch": 3.3744255598511925,
      "grad_norm": 0.08239679038524628,
      "learning_rate": 1.6255744401488075e-05,
      "loss": 0.0034,
      "step": 46260
    },
    {
      "epoch": 3.375155007659202,
      "grad_norm": 0.23137706518173218,
      "learning_rate": 1.624844992340798e-05,
      "loss": 0.0052,
      "step": 46270
    },
    {
      "epoch": 3.375884455467211,
      "grad_norm": 0.11778896301984787,
      "learning_rate": 1.6241155445327887e-05,
      "loss": 0.0034,
      "step": 46280
    },
    {
      "epoch": 3.3766139032752207,
      "grad_norm": 0.3080469071865082,
      "learning_rate": 1.6233860967247794e-05,
      "loss": 0.0039,
      "step": 46290
    },
    {
      "epoch": 3.37734335108323,
      "grad_norm": 0.030281752347946167,
      "learning_rate": 1.6226566489167702e-05,
      "loss": 0.0024,
      "step": 46300
    },
    {
      "epoch": 3.3780727988912393,
      "grad_norm": 0.012140486389398575,
      "learning_rate": 1.6219272011087606e-05,
      "loss": 0.0035,
      "step": 46310
    },
    {
      "epoch": 3.378802246699249,
      "grad_norm": 0.08835542947053909,
      "learning_rate": 1.6211977533007514e-05,
      "loss": 0.0026,
      "step": 46320
    },
    {
      "epoch": 3.379531694507258,
      "grad_norm": 0.14344029128551483,
      "learning_rate": 1.620468305492742e-05,
      "loss": 0.0036,
      "step": 46330
    },
    {
      "epoch": 3.3802611423152675,
      "grad_norm": 0.23042555153369904,
      "learning_rate": 1.619738857684733e-05,
      "loss": 0.0043,
      "step": 46340
    },
    {
      "epoch": 3.3809905901232766,
      "grad_norm": 0.3460334241390228,
      "learning_rate": 1.6190094098767233e-05,
      "loss": 0.004,
      "step": 46350
    },
    {
      "epoch": 3.381720037931286,
      "grad_norm": 0.03092900663614273,
      "learning_rate": 1.618279962068714e-05,
      "loss": 0.0034,
      "step": 46360
    },
    {
      "epoch": 3.3824494857392953,
      "grad_norm": 0.3799659013748169,
      "learning_rate": 1.6175505142607048e-05,
      "loss": 0.0033,
      "step": 46370
    },
    {
      "epoch": 3.383178933547305,
      "grad_norm": 0.08915316313505173,
      "learning_rate": 1.6168210664526952e-05,
      "loss": 0.0025,
      "step": 46380
    },
    {
      "epoch": 3.383908381355314,
      "grad_norm": 0.2301526814699173,
      "learning_rate": 1.6160916186446863e-05,
      "loss": 0.003,
      "step": 46390
    },
    {
      "epoch": 3.3846378291633235,
      "grad_norm": 0.08626898378133774,
      "learning_rate": 1.6153621708366767e-05,
      "loss": 0.0034,
      "step": 46400
    },
    {
      "epoch": 3.3853672769713326,
      "grad_norm": 0.11633425205945969,
      "learning_rate": 1.6146327230286675e-05,
      "loss": 0.0035,
      "step": 46410
    },
    {
      "epoch": 3.386096724779342,
      "grad_norm": 0.1719592809677124,
      "learning_rate": 1.6139032752206582e-05,
      "loss": 0.0034,
      "step": 46420
    },
    {
      "epoch": 3.386826172587351,
      "grad_norm": 0.05832625925540924,
      "learning_rate": 1.6131738274126486e-05,
      "loss": 0.003,
      "step": 46430
    },
    {
      "epoch": 3.3875556203953607,
      "grad_norm": 0.1437574028968811,
      "learning_rate": 1.6124443796046394e-05,
      "loss": 0.0037,
      "step": 46440
    },
    {
      "epoch": 3.38828506820337,
      "grad_norm": 0.2874388098716736,
      "learning_rate": 1.61171493179663e-05,
      "loss": 0.0026,
      "step": 46450
    },
    {
      "epoch": 3.3890145160113794,
      "grad_norm": 0.10266506671905518,
      "learning_rate": 1.6109854839886206e-05,
      "loss": 0.0021,
      "step": 46460
    },
    {
      "epoch": 3.389743963819389,
      "grad_norm": 0.148928701877594,
      "learning_rate": 1.6102560361806113e-05,
      "loss": 0.0034,
      "step": 46470
    },
    {
      "epoch": 3.390473411627398,
      "grad_norm": 0.25926724076271057,
      "learning_rate": 1.609526588372602e-05,
      "loss": 0.0028,
      "step": 46480
    },
    {
      "epoch": 3.3912028594354076,
      "grad_norm": 0.23021501302719116,
      "learning_rate": 1.6087971405645928e-05,
      "loss": 0.0031,
      "step": 46490
    },
    {
      "epoch": 3.3919323072434167,
      "grad_norm": 0.05881062150001526,
      "learning_rate": 1.6080676927565832e-05,
      "loss": 0.0043,
      "step": 46500
    },
    {
      "epoch": 3.392661755051426,
      "grad_norm": 0.07950397580862045,
      "learning_rate": 1.607338244948574e-05,
      "loss": 0.0027,
      "step": 46510
    },
    {
      "epoch": 3.3933912028594353,
      "grad_norm": 0.28716403245925903,
      "learning_rate": 1.6066087971405647e-05,
      "loss": 0.0027,
      "step": 46520
    },
    {
      "epoch": 3.394120650667445,
      "grad_norm": 0.23589447140693665,
      "learning_rate": 1.605879349332555e-05,
      "loss": 0.0019,
      "step": 46530
    },
    {
      "epoch": 3.394850098475454,
      "grad_norm": 0.08605573326349258,
      "learning_rate": 1.6051499015245462e-05,
      "loss": 0.0032,
      "step": 46540
    },
    {
      "epoch": 3.3955795462834635,
      "grad_norm": 0.016556577757000923,
      "learning_rate": 1.6044204537165367e-05,
      "loss": 0.0033,
      "step": 46550
    },
    {
      "epoch": 3.3963089940914726,
      "grad_norm": 0.0914992243051529,
      "learning_rate": 1.603691005908527e-05,
      "loss": 0.0034,
      "step": 46560
    },
    {
      "epoch": 3.397038441899482,
      "grad_norm": 0.11571047455072403,
      "learning_rate": 1.602961558100518e-05,
      "loss": 0.0027,
      "step": 46570
    },
    {
      "epoch": 3.3977678897074917,
      "grad_norm": 0.086944580078125,
      "learning_rate": 1.6022321102925086e-05,
      "loss": 0.0031,
      "step": 46580
    },
    {
      "epoch": 3.3984973375155008,
      "grad_norm": 0.2300024926662445,
      "learning_rate": 1.6015026624844993e-05,
      "loss": 0.0032,
      "step": 46590
    },
    {
      "epoch": 3.39922678532351,
      "grad_norm": 0.17766232788562775,
      "learning_rate": 1.60077321467649e-05,
      "loss": 0.0036,
      "step": 46600
    },
    {
      "epoch": 3.3999562331315194,
      "grad_norm": 0.547955334186554,
      "learning_rate": 1.6000437668684805e-05,
      "loss": 0.0035,
      "step": 46610
    },
    {
      "epoch": 3.400685680939529,
      "grad_norm": 0.46080365777015686,
      "learning_rate": 1.5993143190604712e-05,
      "loss": 0.003,
      "step": 46620
    },
    {
      "epoch": 3.401415128747538,
      "grad_norm": 0.058200955390930176,
      "learning_rate": 1.598584871252462e-05,
      "loss": 0.0027,
      "step": 46630
    },
    {
      "epoch": 3.4021445765555476,
      "grad_norm": 0.05915624275803566,
      "learning_rate": 1.5978554234444528e-05,
      "loss": 0.0029,
      "step": 46640
    },
    {
      "epoch": 3.4028740243635567,
      "grad_norm": 0.20707374811172485,
      "learning_rate": 1.597125975636443e-05,
      "loss": 0.0035,
      "step": 46650
    },
    {
      "epoch": 3.4036034721715662,
      "grad_norm": 0.0598437637090683,
      "learning_rate": 1.596396527828434e-05,
      "loss": 0.0023,
      "step": 46660
    },
    {
      "epoch": 3.4043329199795753,
      "grad_norm": 0.34649860858917236,
      "learning_rate": 1.5956670800204247e-05,
      "loss": 0.0035,
      "step": 46670
    },
    {
      "epoch": 3.405062367787585,
      "grad_norm": 0.11713418364524841,
      "learning_rate": 1.594937632212415e-05,
      "loss": 0.0032,
      "step": 46680
    },
    {
      "epoch": 3.405791815595594,
      "grad_norm": 0.17315328121185303,
      "learning_rate": 1.594208184404406e-05,
      "loss": 0.0033,
      "step": 46690
    },
    {
      "epoch": 3.4065212634036035,
      "grad_norm": 0.11639807373285294,
      "learning_rate": 1.5934787365963966e-05,
      "loss": 0.0043,
      "step": 46700
    },
    {
      "epoch": 3.4072507112116126,
      "grad_norm": 0.14479053020477295,
      "learning_rate": 1.592749288788387e-05,
      "loss": 0.0029,
      "step": 46710
    },
    {
      "epoch": 3.407980159019622,
      "grad_norm": 0.31711074709892273,
      "learning_rate": 1.592019840980378e-05,
      "loss": 0.0029,
      "step": 46720
    },
    {
      "epoch": 3.4087096068276317,
      "grad_norm": 0.4035722613334656,
      "learning_rate": 1.5912903931723685e-05,
      "loss": 0.0043,
      "step": 46730
    },
    {
      "epoch": 3.409439054635641,
      "grad_norm": 0.08793767541646957,
      "learning_rate": 1.5905609453643593e-05,
      "loss": 0.0038,
      "step": 46740
    },
    {
      "epoch": 3.4101685024436503,
      "grad_norm": 0.07737628370523453,
      "learning_rate": 1.58983149755635e-05,
      "loss": 0.0025,
      "step": 46750
    },
    {
      "epoch": 3.4108979502516594,
      "grad_norm": 0.1799316555261612,
      "learning_rate": 1.5891020497483404e-05,
      "loss": 0.0034,
      "step": 46760
    },
    {
      "epoch": 3.411627398059669,
      "grad_norm": 0.1673336923122406,
      "learning_rate": 1.5883726019403315e-05,
      "loss": 0.0051,
      "step": 46770
    },
    {
      "epoch": 3.412356845867678,
      "grad_norm": 0.17233556509017944,
      "learning_rate": 1.587643154132322e-05,
      "loss": 0.0034,
      "step": 46780
    },
    {
      "epoch": 3.4130862936756876,
      "grad_norm": 0.4034458100795746,
      "learning_rate": 1.5869137063243124e-05,
      "loss": 0.0031,
      "step": 46790
    },
    {
      "epoch": 3.4138157414836967,
      "grad_norm": 0.11523406207561493,
      "learning_rate": 1.5861842585163034e-05,
      "loss": 0.0037,
      "step": 46800
    },
    {
      "epoch": 3.4145451892917063,
      "grad_norm": 0.28791549801826477,
      "learning_rate": 1.585454810708294e-05,
      "loss": 0.0031,
      "step": 46810
    },
    {
      "epoch": 3.4152746370997153,
      "grad_norm": 0.05870890989899635,
      "learning_rate": 1.5847253629002846e-05,
      "loss": 0.0026,
      "step": 46820
    },
    {
      "epoch": 3.416004084907725,
      "grad_norm": 0.23129329085350037,
      "learning_rate": 1.5839959150922754e-05,
      "loss": 0.0033,
      "step": 46830
    },
    {
      "epoch": 3.4167335327157344,
      "grad_norm": 0.20982412993907928,
      "learning_rate": 1.5832664672842658e-05,
      "loss": 0.0033,
      "step": 46840
    },
    {
      "epoch": 3.4174629805237435,
      "grad_norm": 0.173599511384964,
      "learning_rate": 1.5825370194762565e-05,
      "loss": 0.0026,
      "step": 46850
    },
    {
      "epoch": 3.4181924283317526,
      "grad_norm": 0.11508964002132416,
      "learning_rate": 1.5818075716682473e-05,
      "loss": 0.0036,
      "step": 46860
    },
    {
      "epoch": 3.418921876139762,
      "grad_norm": 0.009226759895682335,
      "learning_rate": 1.581078123860238e-05,
      "loss": 0.0033,
      "step": 46870
    },
    {
      "epoch": 3.4196513239477717,
      "grad_norm": 0.20208944380283356,
      "learning_rate": 1.5803486760522285e-05,
      "loss": 0.0019,
      "step": 46880
    },
    {
      "epoch": 3.420380771755781,
      "grad_norm": 0.23001380264759064,
      "learning_rate": 1.5796192282442192e-05,
      "loss": 0.0024,
      "step": 46890
    },
    {
      "epoch": 3.4211102195637904,
      "grad_norm": 0.02920481190085411,
      "learning_rate": 1.57888978043621e-05,
      "loss": 0.0043,
      "step": 46900
    },
    {
      "epoch": 3.4218396673717995,
      "grad_norm": 0.030369358137249947,
      "learning_rate": 1.5781603326282004e-05,
      "loss": 0.0024,
      "step": 46910
    },
    {
      "epoch": 3.422569115179809,
      "grad_norm": 0.005782342981547117,
      "learning_rate": 1.5774308848201915e-05,
      "loss": 0.0034,
      "step": 46920
    },
    {
      "epoch": 3.423298562987818,
      "grad_norm": 0.2473888099193573,
      "learning_rate": 1.576701437012182e-05,
      "loss": 0.0038,
      "step": 46930
    },
    {
      "epoch": 3.4240280107958276,
      "grad_norm": 0.08725491911172867,
      "learning_rate": 1.5759719892041723e-05,
      "loss": 0.0032,
      "step": 46940
    },
    {
      "epoch": 3.4247574586038367,
      "grad_norm": 0.0864398255944252,
      "learning_rate": 1.5752425413961634e-05,
      "loss": 0.004,
      "step": 46950
    },
    {
      "epoch": 3.4254869064118463,
      "grad_norm": 0.25500571727752686,
      "learning_rate": 1.5745130935881538e-05,
      "loss": 0.0017,
      "step": 46960
    },
    {
      "epoch": 3.4262163542198554,
      "grad_norm": 0.2639563977718353,
      "learning_rate": 1.5737836457801446e-05,
      "loss": 0.0032,
      "step": 46970
    },
    {
      "epoch": 3.426945802027865,
      "grad_norm": 0.11609416455030441,
      "learning_rate": 1.5730541979721353e-05,
      "loss": 0.0023,
      "step": 46980
    },
    {
      "epoch": 3.4276752498358745,
      "grad_norm": 0.1652490198612213,
      "learning_rate": 1.5723247501641257e-05,
      "loss": 0.0039,
      "step": 46990
    },
    {
      "epoch": 3.4284046976438836,
      "grad_norm": 0.030476143583655357,
      "learning_rate": 1.5715953023561165e-05,
      "loss": 0.0028,
      "step": 47000
    },
    {
      "epoch": 3.429134145451893,
      "grad_norm": 0.31734904646873474,
      "learning_rate": 1.5708658545481072e-05,
      "loss": 0.002,
      "step": 47010
    },
    {
      "epoch": 3.429863593259902,
      "grad_norm": 0.05826658755540848,
      "learning_rate": 1.570136406740098e-05,
      "loss": 0.0039,
      "step": 47020
    },
    {
      "epoch": 3.4305930410679117,
      "grad_norm": 0.1432512402534485,
      "learning_rate": 1.5694069589320884e-05,
      "loss": 0.0034,
      "step": 47030
    },
    {
      "epoch": 3.431322488875921,
      "grad_norm": 0.20444168150424957,
      "learning_rate": 1.568677511124079e-05,
      "loss": 0.0031,
      "step": 47040
    },
    {
      "epoch": 3.4320519366839304,
      "grad_norm": 0.060023847967386246,
      "learning_rate": 1.56794806331607e-05,
      "loss": 0.0035,
      "step": 47050
    },
    {
      "epoch": 3.4327813844919395,
      "grad_norm": 0.030097490176558495,
      "learning_rate": 1.5672186155080603e-05,
      "loss": 0.0038,
      "step": 47060
    },
    {
      "epoch": 3.433510832299949,
      "grad_norm": 0.5757334232330322,
      "learning_rate": 1.566489167700051e-05,
      "loss": 0.0035,
      "step": 47070
    },
    {
      "epoch": 3.434240280107958,
      "grad_norm": 0.11537040024995804,
      "learning_rate": 1.5657597198920418e-05,
      "loss": 0.0036,
      "step": 47080
    },
    {
      "epoch": 3.4349697279159677,
      "grad_norm": 0.01042862981557846,
      "learning_rate": 1.5650302720840322e-05,
      "loss": 0.0021,
      "step": 47090
    },
    {
      "epoch": 3.4356991757239768,
      "grad_norm": 0.050259798765182495,
      "learning_rate": 1.5643008242760233e-05,
      "loss": 0.0033,
      "step": 47100
    },
    {
      "epoch": 3.4364286235319863,
      "grad_norm": 0.029658425599336624,
      "learning_rate": 1.5635713764680137e-05,
      "loss": 0.0025,
      "step": 47110
    },
    {
      "epoch": 3.4371580713399954,
      "grad_norm": 0.20859237015247345,
      "learning_rate": 1.5628419286600045e-05,
      "loss": 0.0032,
      "step": 47120
    },
    {
      "epoch": 3.437887519148005,
      "grad_norm": 0.346526563167572,
      "learning_rate": 1.5621124808519952e-05,
      "loss": 0.003,
      "step": 47130
    },
    {
      "epoch": 3.4386169669560145,
      "grad_norm": 0.051598403602838516,
      "learning_rate": 1.5613830330439857e-05,
      "loss": 0.0038,
      "step": 47140
    },
    {
      "epoch": 3.4393464147640236,
      "grad_norm": 0.28795406222343445,
      "learning_rate": 1.5606535852359764e-05,
      "loss": 0.0019,
      "step": 47150
    },
    {
      "epoch": 3.440075862572033,
      "grad_norm": 0.4573104977607727,
      "learning_rate": 1.559924137427967e-05,
      "loss": 0.0042,
      "step": 47160
    },
    {
      "epoch": 3.4408053103800422,
      "grad_norm": 0.3746865391731262,
      "learning_rate": 1.5591946896199576e-05,
      "loss": 0.004,
      "step": 47170
    },
    {
      "epoch": 3.4415347581880518,
      "grad_norm": 0.1449778527021408,
      "learning_rate": 1.5584652418119483e-05,
      "loss": 0.0023,
      "step": 47180
    },
    {
      "epoch": 3.442264205996061,
      "grad_norm": 0.08206718415021896,
      "learning_rate": 1.557735794003939e-05,
      "loss": 0.0037,
      "step": 47190
    },
    {
      "epoch": 3.4429936538040704,
      "grad_norm": 0.08927052468061447,
      "learning_rate": 1.55700634619593e-05,
      "loss": 0.0029,
      "step": 47200
    },
    {
      "epoch": 3.4437231016120795,
      "grad_norm": 0.057733092457056046,
      "learning_rate": 1.5562768983879203e-05,
      "loss": 0.0037,
      "step": 47210
    },
    {
      "epoch": 3.444452549420089,
      "grad_norm": 0.23094213008880615,
      "learning_rate": 1.555547450579911e-05,
      "loss": 0.0031,
      "step": 47220
    },
    {
      "epoch": 3.445181997228098,
      "grad_norm": 0.1474970281124115,
      "learning_rate": 1.5548180027719018e-05,
      "loss": 0.0022,
      "step": 47230
    },
    {
      "epoch": 3.4459114450361077,
      "grad_norm": 0.26117607951164246,
      "learning_rate": 1.5540885549638922e-05,
      "loss": 0.0041,
      "step": 47240
    },
    {
      "epoch": 3.4466408928441172,
      "grad_norm": 0.4330780506134033,
      "learning_rate": 1.5533591071558833e-05,
      "loss": 0.0027,
      "step": 47250
    },
    {
      "epoch": 3.4473703406521263,
      "grad_norm": 0.2594391703605652,
      "learning_rate": 1.5526296593478737e-05,
      "loss": 0.0034,
      "step": 47260
    },
    {
      "epoch": 3.4480997884601354,
      "grad_norm": 0.1447993963956833,
      "learning_rate": 1.5519002115398644e-05,
      "loss": 0.0025,
      "step": 47270
    },
    {
      "epoch": 3.448829236268145,
      "grad_norm": 0.14504395425319672,
      "learning_rate": 1.5511707637318552e-05,
      "loss": 0.004,
      "step": 47280
    },
    {
      "epoch": 3.4495586840761545,
      "grad_norm": 0.22962243854999542,
      "learning_rate": 1.5504413159238456e-05,
      "loss": 0.0029,
      "step": 47290
    },
    {
      "epoch": 3.4502881318841636,
      "grad_norm": 0.14458948373794556,
      "learning_rate": 1.5497118681158364e-05,
      "loss": 0.0034,
      "step": 47300
    },
    {
      "epoch": 3.451017579692173,
      "grad_norm": 0.2582564353942871,
      "learning_rate": 1.548982420307827e-05,
      "loss": 0.004,
      "step": 47310
    },
    {
      "epoch": 3.4517470275001823,
      "grad_norm": 0.10543873906135559,
      "learning_rate": 1.5482529724998175e-05,
      "loss": 0.0039,
      "step": 47320
    },
    {
      "epoch": 3.452476475308192,
      "grad_norm": 0.12598204612731934,
      "learning_rate": 1.5475235246918086e-05,
      "loss": 0.003,
      "step": 47330
    },
    {
      "epoch": 3.453205923116201,
      "grad_norm": 0.1456126868724823,
      "learning_rate": 1.546794076883799e-05,
      "loss": 0.0019,
      "step": 47340
    },
    {
      "epoch": 3.4539353709242104,
      "grad_norm": 0.12247969210147858,
      "learning_rate": 1.5460646290757898e-05,
      "loss": 0.0026,
      "step": 47350
    },
    {
      "epoch": 3.4546648187322195,
      "grad_norm": 0.20706740021705627,
      "learning_rate": 1.5453351812677805e-05,
      "loss": 0.0028,
      "step": 47360
    },
    {
      "epoch": 3.455394266540229,
      "grad_norm": 0.38418835401535034,
      "learning_rate": 1.544605733459771e-05,
      "loss": 0.0047,
      "step": 47370
    },
    {
      "epoch": 3.456123714348238,
      "grad_norm": 0.23529015481472015,
      "learning_rate": 1.5438762856517617e-05,
      "loss": 0.0031,
      "step": 47380
    },
    {
      "epoch": 3.4568531621562477,
      "grad_norm": 0.5431220531463623,
      "learning_rate": 1.5431468378437525e-05,
      "loss": 0.0046,
      "step": 47390
    },
    {
      "epoch": 3.4575826099642573,
      "grad_norm": 0.14692045748233795,
      "learning_rate": 1.5424173900357432e-05,
      "loss": 0.0038,
      "step": 47400
    },
    {
      "epoch": 3.4583120577722664,
      "grad_norm": 0.15660737454891205,
      "learning_rate": 1.5416879422277336e-05,
      "loss": 0.0043,
      "step": 47410
    },
    {
      "epoch": 3.459041505580276,
      "grad_norm": 0.2881801128387451,
      "learning_rate": 1.5409584944197244e-05,
      "loss": 0.0023,
      "step": 47420
    },
    {
      "epoch": 3.459770953388285,
      "grad_norm": 0.03035656176507473,
      "learning_rate": 1.540229046611715e-05,
      "loss": 0.0047,
      "step": 47430
    },
    {
      "epoch": 3.4605004011962945,
      "grad_norm": 0.2763254940509796,
      "learning_rate": 1.5394995988037055e-05,
      "loss": 0.0031,
      "step": 47440
    },
    {
      "epoch": 3.4612298490043036,
      "grad_norm": 0.3163033723831177,
      "learning_rate": 1.5387701509956963e-05,
      "loss": 0.0029,
      "step": 47450
    },
    {
      "epoch": 3.461959296812313,
      "grad_norm": 0.3179391622543335,
      "learning_rate": 1.538040703187687e-05,
      "loss": 0.0026,
      "step": 47460
    },
    {
      "epoch": 3.4626887446203223,
      "grad_norm": 0.14416281878948212,
      "learning_rate": 1.5373112553796775e-05,
      "loss": 0.0028,
      "step": 47470
    },
    {
      "epoch": 3.463418192428332,
      "grad_norm": 0.17417532205581665,
      "learning_rate": 1.5365818075716686e-05,
      "loss": 0.003,
      "step": 47480
    },
    {
      "epoch": 3.464147640236341,
      "grad_norm": 0.18263275921344757,
      "learning_rate": 1.535852359763659e-05,
      "loss": 0.0025,
      "step": 47490
    },
    {
      "epoch": 3.4648770880443505,
      "grad_norm": 0.01614527776837349,
      "learning_rate": 1.5351229119556497e-05,
      "loss": 0.003,
      "step": 47500
    },
    {
      "epoch": 3.46560653585236,
      "grad_norm": 0.14401519298553467,
      "learning_rate": 1.5343934641476405e-05,
      "loss": 0.003,
      "step": 47510
    },
    {
      "epoch": 3.466335983660369,
      "grad_norm": 0.05919872224330902,
      "learning_rate": 1.533664016339631e-05,
      "loss": 0.0025,
      "step": 47520
    },
    {
      "epoch": 3.467065431468378,
      "grad_norm": 0.008237582631409168,
      "learning_rate": 1.5329345685316216e-05,
      "loss": 0.0043,
      "step": 47530
    },
    {
      "epoch": 3.4677948792763877,
      "grad_norm": 0.23122459650039673,
      "learning_rate": 1.5322051207236124e-05,
      "loss": 0.0036,
      "step": 47540
    },
    {
      "epoch": 3.4685243270843973,
      "grad_norm": 0.014408683404326439,
      "learning_rate": 1.5314756729156028e-05,
      "loss": 0.0024,
      "step": 47550
    },
    {
      "epoch": 3.4692537748924064,
      "grad_norm": 0.5050050020217896,
      "learning_rate": 1.5307462251075936e-05,
      "loss": 0.0036,
      "step": 47560
    },
    {
      "epoch": 3.469983222700416,
      "grad_norm": 0.03280431404709816,
      "learning_rate": 1.5300167772995843e-05,
      "loss": 0.004,
      "step": 47570
    },
    {
      "epoch": 3.470712670508425,
      "grad_norm": 0.05774618312716484,
      "learning_rate": 1.529287329491575e-05,
      "loss": 0.0024,
      "step": 47580
    },
    {
      "epoch": 3.4714421183164346,
      "grad_norm": 0.01738075725734234,
      "learning_rate": 1.5285578816835655e-05,
      "loss": 0.0025,
      "step": 47590
    },
    {
      "epoch": 3.4721715661244437,
      "grad_norm": 0.401665598154068,
      "learning_rate": 1.5278284338755562e-05,
      "loss": 0.0029,
      "step": 47600
    },
    {
      "epoch": 3.472901013932453,
      "grad_norm": 0.7164310812950134,
      "learning_rate": 1.527098986067547e-05,
      "loss": 0.0036,
      "step": 47610
    },
    {
      "epoch": 3.4736304617404623,
      "grad_norm": 0.12125498056411743,
      "learning_rate": 1.5263695382595374e-05,
      "loss": 0.0035,
      "step": 47620
    },
    {
      "epoch": 3.474359909548472,
      "grad_norm": 0.11582066118717194,
      "learning_rate": 1.5256400904515283e-05,
      "loss": 0.0048,
      "step": 47630
    },
    {
      "epoch": 3.475089357356481,
      "grad_norm": 0.1062108725309372,
      "learning_rate": 1.5249106426435189e-05,
      "loss": 0.0024,
      "step": 47640
    },
    {
      "epoch": 3.4758188051644905,
      "grad_norm": 0.1150323823094368,
      "learning_rate": 1.5241811948355095e-05,
      "loss": 0.0025,
      "step": 47650
    },
    {
      "epoch": 3.4765482529725,
      "grad_norm": 0.059103623032569885,
      "learning_rate": 1.5234517470275002e-05,
      "loss": 0.0033,
      "step": 47660
    },
    {
      "epoch": 3.477277700780509,
      "grad_norm": 0.4642660617828369,
      "learning_rate": 1.5227222992194908e-05,
      "loss": 0.003,
      "step": 47670
    },
    {
      "epoch": 3.4780071485885187,
      "grad_norm": 0.17484119534492493,
      "learning_rate": 1.5219928514114814e-05,
      "loss": 0.0027,
      "step": 47680
    },
    {
      "epoch": 3.4787365963965278,
      "grad_norm": 0.26315808296203613,
      "learning_rate": 1.5212634036034723e-05,
      "loss": 0.0034,
      "step": 47690
    },
    {
      "epoch": 3.4794660442045373,
      "grad_norm": 0.1166335791349411,
      "learning_rate": 1.520533955795463e-05,
      "loss": 0.0031,
      "step": 47700
    },
    {
      "epoch": 3.4801954920125464,
      "grad_norm": 0.3980126678943634,
      "learning_rate": 1.5198045079874535e-05,
      "loss": 0.0044,
      "step": 47710
    },
    {
      "epoch": 3.480924939820556,
      "grad_norm": 0.25981542468070984,
      "learning_rate": 1.5190750601794443e-05,
      "loss": 0.0036,
      "step": 47720
    },
    {
      "epoch": 3.481654387628565,
      "grad_norm": 0.2309577465057373,
      "learning_rate": 1.5183456123714348e-05,
      "loss": 0.004,
      "step": 47730
    },
    {
      "epoch": 3.4823838354365746,
      "grad_norm": 0.17264387011528015,
      "learning_rate": 1.5176161645634254e-05,
      "loss": 0.0027,
      "step": 47740
    },
    {
      "epoch": 3.4831132832445837,
      "grad_norm": 0.08702374249696732,
      "learning_rate": 1.5168867167554163e-05,
      "loss": 0.0033,
      "step": 47750
    },
    {
      "epoch": 3.4838427310525932,
      "grad_norm": 0.05815214663743973,
      "learning_rate": 1.5161572689474068e-05,
      "loss": 0.0029,
      "step": 47760
    },
    {
      "epoch": 3.4845721788606023,
      "grad_norm": 0.2880604863166809,
      "learning_rate": 1.5154278211393977e-05,
      "loss": 0.0038,
      "step": 47770
    },
    {
      "epoch": 3.485301626668612,
      "grad_norm": 0.05762093886733055,
      "learning_rate": 1.5146983733313883e-05,
      "loss": 0.0047,
      "step": 47780
    },
    {
      "epoch": 3.486031074476621,
      "grad_norm": 0.17349275946617126,
      "learning_rate": 1.5139689255233788e-05,
      "loss": 0.0023,
      "step": 47790
    },
    {
      "epoch": 3.4867605222846305,
      "grad_norm": 0.4307648837566376,
      "learning_rate": 1.5132394777153696e-05,
      "loss": 0.0039,
      "step": 47800
    },
    {
      "epoch": 3.48748997009264,
      "grad_norm": 0.25946342945098877,
      "learning_rate": 1.5125100299073602e-05,
      "loss": 0.0025,
      "step": 47810
    },
    {
      "epoch": 3.488219417900649,
      "grad_norm": 0.11472658067941666,
      "learning_rate": 1.5117805820993508e-05,
      "loss": 0.0027,
      "step": 47820
    },
    {
      "epoch": 3.4889488657086587,
      "grad_norm": 0.17250129580497742,
      "learning_rate": 1.5110511342913417e-05,
      "loss": 0.0023,
      "step": 47830
    },
    {
      "epoch": 3.489678313516668,
      "grad_norm": 0.008371349424123764,
      "learning_rate": 1.5103216864833323e-05,
      "loss": 0.0024,
      "step": 47840
    },
    {
      "epoch": 3.4904077613246773,
      "grad_norm": 0.03053361549973488,
      "learning_rate": 1.5095922386753229e-05,
      "loss": 0.0024,
      "step": 47850
    },
    {
      "epoch": 3.4911372091326864,
      "grad_norm": 0.11605744808912277,
      "learning_rate": 1.5088627908673136e-05,
      "loss": 0.0022,
      "step": 47860
    },
    {
      "epoch": 3.491866656940696,
      "grad_norm": 0.14381623268127441,
      "learning_rate": 1.5081333430593042e-05,
      "loss": 0.0016,
      "step": 47870
    },
    {
      "epoch": 3.492596104748705,
      "grad_norm": 0.11578469723463058,
      "learning_rate": 1.5074038952512948e-05,
      "loss": 0.0023,
      "step": 47880
    },
    {
      "epoch": 3.4933255525567146,
      "grad_norm": 0.4024948477745056,
      "learning_rate": 1.5066744474432857e-05,
      "loss": 0.003,
      "step": 47890
    },
    {
      "epoch": 3.4940550003647237,
      "grad_norm": 0.06514105200767517,
      "learning_rate": 1.5059449996352761e-05,
      "loss": 0.0031,
      "step": 47900
    },
    {
      "epoch": 3.4947844481727333,
      "grad_norm": 0.11543884873390198,
      "learning_rate": 1.5052155518272667e-05,
      "loss": 0.0025,
      "step": 47910
    },
    {
      "epoch": 3.495513895980743,
      "grad_norm": 0.08639860898256302,
      "learning_rate": 1.5044861040192576e-05,
      "loss": 0.0022,
      "step": 47920
    },
    {
      "epoch": 3.496243343788752,
      "grad_norm": 0.20228953659534454,
      "learning_rate": 1.5037566562112482e-05,
      "loss": 0.0033,
      "step": 47930
    },
    {
      "epoch": 3.4969727915967614,
      "grad_norm": 0.00953961443156004,
      "learning_rate": 1.5030272084032388e-05,
      "loss": 0.0024,
      "step": 47940
    },
    {
      "epoch": 3.4977022394047705,
      "grad_norm": 0.20237338542938232,
      "learning_rate": 1.5022977605952295e-05,
      "loss": 0.0034,
      "step": 47950
    },
    {
      "epoch": 3.49843168721278,
      "grad_norm": 0.31626248359680176,
      "learning_rate": 1.5015683127872201e-05,
      "loss": 0.0039,
      "step": 47960
    },
    {
      "epoch": 3.499161135020789,
      "grad_norm": 0.34782418608665466,
      "learning_rate": 1.5008388649792107e-05,
      "loss": 0.0021,
      "step": 47970
    },
    {
      "epoch": 3.4998905828287987,
      "grad_norm": 0.31681957840919495,
      "learning_rate": 1.5001094171712016e-05,
      "loss": 0.0023,
      "step": 47980
    },
    {
      "epoch": 3.500620030636808,
      "grad_norm": 0.3042509853839874,
      "learning_rate": 1.4993799693631922e-05,
      "loss": 0.0034,
      "step": 47990
    },
    {
      "epoch": 3.5013494784448174,
      "grad_norm": 0.11522727459669113,
      "learning_rate": 1.4986505215551826e-05,
      "loss": 0.0032,
      "step": 48000
    },
    {
      "epoch": 3.5020789262528265,
      "grad_norm": 0.11601383984088898,
      "learning_rate": 1.4979210737471735e-05,
      "loss": 0.0028,
      "step": 48010
    },
    {
      "epoch": 3.502808374060836,
      "grad_norm": 0.08720342069864273,
      "learning_rate": 1.4971916259391641e-05,
      "loss": 0.0024,
      "step": 48020
    },
    {
      "epoch": 3.5035378218688455,
      "grad_norm": 0.20303364098072052,
      "learning_rate": 1.4964621781311547e-05,
      "loss": 0.0034,
      "step": 48030
    },
    {
      "epoch": 3.5042672696768546,
      "grad_norm": 0.32287630438804626,
      "learning_rate": 1.4957327303231455e-05,
      "loss": 0.0027,
      "step": 48040
    },
    {
      "epoch": 3.5049967174848637,
      "grad_norm": 0.3179160952568054,
      "learning_rate": 1.495003282515136e-05,
      "loss": 0.0058,
      "step": 48050
    },
    {
      "epoch": 3.5057261652928733,
      "grad_norm": 0.08726520091295242,
      "learning_rate": 1.4942738347071266e-05,
      "loss": 0.0031,
      "step": 48060
    },
    {
      "epoch": 3.506455613100883,
      "grad_norm": 0.3183392286300659,
      "learning_rate": 1.4935443868991176e-05,
      "loss": 0.0034,
      "step": 48070
    },
    {
      "epoch": 3.507185060908892,
      "grad_norm": 0.12451278418302536,
      "learning_rate": 1.4928149390911081e-05,
      "loss": 0.0037,
      "step": 48080
    },
    {
      "epoch": 3.5079145087169015,
      "grad_norm": 0.23019500076770782,
      "learning_rate": 1.4920854912830987e-05,
      "loss": 0.0026,
      "step": 48090
    },
    {
      "epoch": 3.5086439565249106,
      "grad_norm": 0.03130459040403366,
      "learning_rate": 1.4913560434750895e-05,
      "loss": 0.0037,
      "step": 48100
    },
    {
      "epoch": 3.50937340433292,
      "grad_norm": 0.20526249706745148,
      "learning_rate": 1.49062659566708e-05,
      "loss": 0.0026,
      "step": 48110
    },
    {
      "epoch": 3.510102852140929,
      "grad_norm": 0.04406493157148361,
      "learning_rate": 1.4898971478590706e-05,
      "loss": 0.0045,
      "step": 48120
    },
    {
      "epoch": 3.5108322999489388,
      "grad_norm": 0.5190796852111816,
      "learning_rate": 1.4891677000510616e-05,
      "loss": 0.0037,
      "step": 48130
    },
    {
      "epoch": 3.511561747756948,
      "grad_norm": 0.11469803750514984,
      "learning_rate": 1.488438252243052e-05,
      "loss": 0.0037,
      "step": 48140
    },
    {
      "epoch": 3.5122911955649574,
      "grad_norm": 0.31457647681236267,
      "learning_rate": 1.4877088044350426e-05,
      "loss": 0.0035,
      "step": 48150
    },
    {
      "epoch": 3.5130206433729665,
      "grad_norm": 0.11590298265218735,
      "learning_rate": 1.4869793566270335e-05,
      "loss": 0.0026,
      "step": 48160
    },
    {
      "epoch": 3.513750091180976,
      "grad_norm": 0.11510194092988968,
      "learning_rate": 1.486249908819024e-05,
      "loss": 0.0028,
      "step": 48170
    },
    {
      "epoch": 3.5144795389889856,
      "grad_norm": 0.40782874822616577,
      "learning_rate": 1.4855204610110147e-05,
      "loss": 0.0025,
      "step": 48180
    },
    {
      "epoch": 3.5152089867969947,
      "grad_norm": 0.40467125177383423,
      "learning_rate": 1.4847910132030054e-05,
      "loss": 0.0038,
      "step": 48190
    },
    {
      "epoch": 3.5159384346050038,
      "grad_norm": 0.2578285336494446,
      "learning_rate": 1.484061565394996e-05,
      "loss": 0.0028,
      "step": 48200
    },
    {
      "epoch": 3.5166678824130133,
      "grad_norm": 0.2938980162143707,
      "learning_rate": 1.4833321175869866e-05,
      "loss": 0.0028,
      "step": 48210
    },
    {
      "epoch": 3.517397330221023,
      "grad_norm": 0.05949191004037857,
      "learning_rate": 1.4826026697789775e-05,
      "loss": 0.0029,
      "step": 48220
    },
    {
      "epoch": 3.518126778029032,
      "grad_norm": 0.05830378085374832,
      "learning_rate": 1.481873221970968e-05,
      "loss": 0.0031,
      "step": 48230
    },
    {
      "epoch": 3.5188562258370415,
      "grad_norm": 0.15192058682441711,
      "learning_rate": 1.4811437741629585e-05,
      "loss": 0.0039,
      "step": 48240
    },
    {
      "epoch": 3.5195856736450506,
      "grad_norm": 0.5182169079780579,
      "learning_rate": 1.4804143263549494e-05,
      "loss": 0.0024,
      "step": 48250
    },
    {
      "epoch": 3.52031512145306,
      "grad_norm": 0.14345818758010864,
      "learning_rate": 1.47968487854694e-05,
      "loss": 0.0022,
      "step": 48260
    },
    {
      "epoch": 3.5210445692610692,
      "grad_norm": 0.20329707860946655,
      "learning_rate": 1.4789554307389308e-05,
      "loss": 0.0029,
      "step": 48270
    },
    {
      "epoch": 3.5217740170690788,
      "grad_norm": 0.34439560770988464,
      "learning_rate": 1.4782259829309213e-05,
      "loss": 0.0024,
      "step": 48280
    },
    {
      "epoch": 3.5225034648770883,
      "grad_norm": 0.14374175667762756,
      "learning_rate": 1.477496535122912e-05,
      "loss": 0.0029,
      "step": 48290
    },
    {
      "epoch": 3.5232329126850974,
      "grad_norm": 0.22228631377220154,
      "learning_rate": 1.4767670873149028e-05,
      "loss": 0.0032,
      "step": 48300
    },
    {
      "epoch": 3.5239623604931065,
      "grad_norm": 0.02946307882666588,
      "learning_rate": 1.4760376395068934e-05,
      "loss": 0.0028,
      "step": 48310
    },
    {
      "epoch": 3.524691808301116,
      "grad_norm": 0.17367681860923767,
      "learning_rate": 1.475308191698884e-05,
      "loss": 0.0031,
      "step": 48320
    },
    {
      "epoch": 3.5254212561091256,
      "grad_norm": 0.2302972376346588,
      "learning_rate": 1.4745787438908748e-05,
      "loss": 0.0037,
      "step": 48330
    },
    {
      "epoch": 3.5261507039171347,
      "grad_norm": 0.4292566478252411,
      "learning_rate": 1.4738492960828653e-05,
      "loss": 0.0029,
      "step": 48340
    },
    {
      "epoch": 3.526880151725144,
      "grad_norm": 0.05884493514895439,
      "learning_rate": 1.473119848274856e-05,
      "loss": 0.0025,
      "step": 48350
    },
    {
      "epoch": 3.5276095995331533,
      "grad_norm": 0.324162095785141,
      "learning_rate": 1.4723904004668469e-05,
      "loss": 0.0025,
      "step": 48360
    },
    {
      "epoch": 3.528339047341163,
      "grad_norm": 0.08726303279399872,
      "learning_rate": 1.4716609526588374e-05,
      "loss": 0.0029,
      "step": 48370
    },
    {
      "epoch": 3.529068495149172,
      "grad_norm": 0.11594991385936737,
      "learning_rate": 1.4709315048508279e-05,
      "loss": 0.0038,
      "step": 48380
    },
    {
      "epoch": 3.5297979429571815,
      "grad_norm": 0.4959954023361206,
      "learning_rate": 1.4702020570428188e-05,
      "loss": 0.0043,
      "step": 48390
    },
    {
      "epoch": 3.5305273907651906,
      "grad_norm": 0.09118679910898209,
      "learning_rate": 1.4694726092348094e-05,
      "loss": 0.0023,
      "step": 48400
    },
    {
      "epoch": 3.5312568385732,
      "grad_norm": 0.4867976903915405,
      "learning_rate": 1.4687431614268e-05,
      "loss": 0.0034,
      "step": 48410
    },
    {
      "epoch": 3.5319862863812093,
      "grad_norm": 0.20208531618118286,
      "learning_rate": 1.4680137136187907e-05,
      "loss": 0.0045,
      "step": 48420
    },
    {
      "epoch": 3.532715734189219,
      "grad_norm": 0.13137973845005035,
      "learning_rate": 1.4672842658107813e-05,
      "loss": 0.0037,
      "step": 48430
    },
    {
      "epoch": 3.5334451819972283,
      "grad_norm": 0.4604334533214569,
      "learning_rate": 1.4665548180027719e-05,
      "loss": 0.0021,
      "step": 48440
    },
    {
      "epoch": 3.5341746298052374,
      "grad_norm": 0.31709548830986023,
      "learning_rate": 1.4658253701947628e-05,
      "loss": 0.0039,
      "step": 48450
    },
    {
      "epoch": 3.5349040776132465,
      "grad_norm": 0.43182626366615295,
      "learning_rate": 1.4650959223867534e-05,
      "loss": 0.003,
      "step": 48460
    },
    {
      "epoch": 3.535633525421256,
      "grad_norm": 0.4053162932395935,
      "learning_rate": 1.464366474578744e-05,
      "loss": 0.0025,
      "step": 48470
    },
    {
      "epoch": 3.5363629732292656,
      "grad_norm": 0.5484158992767334,
      "learning_rate": 1.4636370267707347e-05,
      "loss": 0.0032,
      "step": 48480
    },
    {
      "epoch": 3.5370924210372747,
      "grad_norm": 0.20335735380649567,
      "learning_rate": 1.4629075789627253e-05,
      "loss": 0.003,
      "step": 48490
    },
    {
      "epoch": 3.5378218688452843,
      "grad_norm": 0.3287632167339325,
      "learning_rate": 1.4621781311547159e-05,
      "loss": 0.0025,
      "step": 48500
    },
    {
      "epoch": 3.5385513166532934,
      "grad_norm": 0.2872917354106903,
      "learning_rate": 1.4614486833467066e-05,
      "loss": 0.0045,
      "step": 48510
    },
    {
      "epoch": 3.539280764461303,
      "grad_norm": 0.03034481406211853,
      "learning_rate": 1.4607192355386972e-05,
      "loss": 0.0035,
      "step": 48520
    },
    {
      "epoch": 3.540010212269312,
      "grad_norm": 0.5760929584503174,
      "learning_rate": 1.4599897877306878e-05,
      "loss": 0.0034,
      "step": 48530
    },
    {
      "epoch": 3.5407396600773215,
      "grad_norm": 0.059639886021614075,
      "learning_rate": 1.4592603399226787e-05,
      "loss": 0.0031,
      "step": 48540
    },
    {
      "epoch": 3.5414691078853306,
      "grad_norm": 0.47676151990890503,
      "learning_rate": 1.4585308921146693e-05,
      "loss": 0.0025,
      "step": 48550
    },
    {
      "epoch": 3.54219855569334,
      "grad_norm": 0.20239536464214325,
      "learning_rate": 1.4578014443066599e-05,
      "loss": 0.0035,
      "step": 48560
    },
    {
      "epoch": 3.5429280035013493,
      "grad_norm": 0.17939433455467224,
      "learning_rate": 1.4570719964986506e-05,
      "loss": 0.0029,
      "step": 48570
    },
    {
      "epoch": 3.543657451309359,
      "grad_norm": 0.0300675667822361,
      "learning_rate": 1.4563425486906412e-05,
      "loss": 0.0039,
      "step": 48580
    },
    {
      "epoch": 3.5443868991173684,
      "grad_norm": 0.08623852580785751,
      "learning_rate": 1.4556131008826318e-05,
      "loss": 0.0018,
      "step": 48590
    },
    {
      "epoch": 3.5451163469253775,
      "grad_norm": 0.14448271691799164,
      "learning_rate": 1.4548836530746227e-05,
      "loss": 0.0026,
      "step": 48600
    },
    {
      "epoch": 3.5458457947333866,
      "grad_norm": 0.23118089139461517,
      "learning_rate": 1.4541542052666133e-05,
      "loss": 0.0026,
      "step": 48610
    },
    {
      "epoch": 3.546575242541396,
      "grad_norm": 0.11534694582223892,
      "learning_rate": 1.4534247574586037e-05,
      "loss": 0.0028,
      "step": 48620
    },
    {
      "epoch": 3.5473046903494057,
      "grad_norm": 0.1506345123052597,
      "learning_rate": 1.4526953096505946e-05,
      "loss": 0.0031,
      "step": 48630
    },
    {
      "epoch": 3.5480341381574148,
      "grad_norm": 0.4028066098690033,
      "learning_rate": 1.4519658618425852e-05,
      "loss": 0.0036,
      "step": 48640
    },
    {
      "epoch": 3.5487635859654243,
      "grad_norm": 0.18371497094631195,
      "learning_rate": 1.4512364140345758e-05,
      "loss": 0.0046,
      "step": 48650
    },
    {
      "epoch": 3.5494930337734334,
      "grad_norm": 0.08814525604248047,
      "learning_rate": 1.4505069662265666e-05,
      "loss": 0.0025,
      "step": 48660
    },
    {
      "epoch": 3.550222481581443,
      "grad_norm": 0.07629073411226273,
      "learning_rate": 1.4497775184185571e-05,
      "loss": 0.0031,
      "step": 48670
    },
    {
      "epoch": 3.550951929389452,
      "grad_norm": 0.05831790342926979,
      "learning_rate": 1.4490480706105477e-05,
      "loss": 0.0031,
      "step": 48680
    },
    {
      "epoch": 3.5516813771974616,
      "grad_norm": 0.2596941292285919,
      "learning_rate": 1.4483186228025387e-05,
      "loss": 0.004,
      "step": 48690
    },
    {
      "epoch": 3.552410825005471,
      "grad_norm": 0.3462337553501129,
      "learning_rate": 1.4475891749945292e-05,
      "loss": 0.0032,
      "step": 48700
    },
    {
      "epoch": 3.55314027281348,
      "grad_norm": 0.1440224051475525,
      "learning_rate": 1.4468597271865198e-05,
      "loss": 0.0032,
      "step": 48710
    },
    {
      "epoch": 3.5538697206214893,
      "grad_norm": 0.176649272441864,
      "learning_rate": 1.4461302793785106e-05,
      "loss": 0.0034,
      "step": 48720
    },
    {
      "epoch": 3.554599168429499,
      "grad_norm": 0.08612662553787231,
      "learning_rate": 1.4454008315705012e-05,
      "loss": 0.0031,
      "step": 48730
    },
    {
      "epoch": 3.5553286162375084,
      "grad_norm": 0.16283246874809265,
      "learning_rate": 1.4446713837624917e-05,
      "loss": 0.0025,
      "step": 48740
    },
    {
      "epoch": 3.5560580640455175,
      "grad_norm": 0.035726483911275864,
      "learning_rate": 1.4439419359544825e-05,
      "loss": 0.003,
      "step": 48750
    },
    {
      "epoch": 3.556787511853527,
      "grad_norm": 0.40231847763061523,
      "learning_rate": 1.443212488146473e-05,
      "loss": 0.0031,
      "step": 48760
    },
    {
      "epoch": 3.557516959661536,
      "grad_norm": 0.03371058404445648,
      "learning_rate": 1.442483040338464e-05,
      "loss": 0.0036,
      "step": 48770
    },
    {
      "epoch": 3.5582464074695457,
      "grad_norm": 0.029602214694023132,
      "learning_rate": 1.4417535925304546e-05,
      "loss": 0.0022,
      "step": 48780
    },
    {
      "epoch": 3.558975855277555,
      "grad_norm": 0.1729833036661148,
      "learning_rate": 1.4410241447224452e-05,
      "loss": 0.0038,
      "step": 48790
    },
    {
      "epoch": 3.5597053030855643,
      "grad_norm": 0.027792971581220627,
      "learning_rate": 1.440294696914436e-05,
      "loss": 0.0029,
      "step": 48800
    },
    {
      "epoch": 3.5604347508935734,
      "grad_norm": 0.25959891080856323,
      "learning_rate": 1.4395652491064265e-05,
      "loss": 0.003,
      "step": 48810
    },
    {
      "epoch": 3.561164198701583,
      "grad_norm": 0.23151721060276031,
      "learning_rate": 1.4388358012984171e-05,
      "loss": 0.0029,
      "step": 48820
    },
    {
      "epoch": 3.561893646509592,
      "grad_norm": 0.05825396627187729,
      "learning_rate": 1.438106353490408e-05,
      "loss": 0.0026,
      "step": 48830
    },
    {
      "epoch": 3.5626230943176016,
      "grad_norm": 0.2019372135400772,
      "learning_rate": 1.4373769056823986e-05,
      "loss": 0.0025,
      "step": 48840
    },
    {
      "epoch": 3.563352542125611,
      "grad_norm": 0.37503454089164734,
      "learning_rate": 1.436647457874389e-05,
      "loss": 0.0024,
      "step": 48850
    },
    {
      "epoch": 3.5640819899336202,
      "grad_norm": 0.25910523533821106,
      "learning_rate": 1.43591801006638e-05,
      "loss": 0.0034,
      "step": 48860
    },
    {
      "epoch": 3.5648114377416293,
      "grad_norm": 0.15777923166751862,
      "learning_rate": 1.4351885622583705e-05,
      "loss": 0.0039,
      "step": 48870
    },
    {
      "epoch": 3.565540885549639,
      "grad_norm": 0.3379870057106018,
      "learning_rate": 1.4344591144503611e-05,
      "loss": 0.0036,
      "step": 48880
    },
    {
      "epoch": 3.5662703333576484,
      "grad_norm": 0.3561619222164154,
      "learning_rate": 1.4337296666423518e-05,
      "loss": 0.003,
      "step": 48890
    },
    {
      "epoch": 3.5669997811656575,
      "grad_norm": 0.07467479258775711,
      "learning_rate": 1.4330002188343424e-05,
      "loss": 0.0032,
      "step": 48900
    },
    {
      "epoch": 3.567729228973667,
      "grad_norm": 0.18437568843364716,
      "learning_rate": 1.432270771026333e-05,
      "loss": 0.0029,
      "step": 48910
    },
    {
      "epoch": 3.568458676781676,
      "grad_norm": 0.2372804582118988,
      "learning_rate": 1.431541323218324e-05,
      "loss": 0.0033,
      "step": 48920
    },
    {
      "epoch": 3.5691881245896857,
      "grad_norm": 0.0869005024433136,
      "learning_rate": 1.4308118754103145e-05,
      "loss": 0.0035,
      "step": 48930
    },
    {
      "epoch": 3.569917572397695,
      "grad_norm": 0.11618514358997345,
      "learning_rate": 1.4300824276023051e-05,
      "loss": 0.0042,
      "step": 48940
    },
    {
      "epoch": 3.5706470202057043,
      "grad_norm": 0.2594119906425476,
      "learning_rate": 1.4293529797942959e-05,
      "loss": 0.0042,
      "step": 48950
    },
    {
      "epoch": 3.571376468013714,
      "grad_norm": 0.4265563189983368,
      "learning_rate": 1.4286235319862864e-05,
      "loss": 0.0039,
      "step": 48960
    },
    {
      "epoch": 3.572105915821723,
      "grad_norm": 0.0956726148724556,
      "learning_rate": 1.427894084178277e-05,
      "loss": 0.0033,
      "step": 48970
    },
    {
      "epoch": 3.572835363629732,
      "grad_norm": 0.03015325404703617,
      "learning_rate": 1.427164636370268e-05,
      "loss": 0.0039,
      "step": 48980
    },
    {
      "epoch": 3.5735648114377416,
      "grad_norm": 0.3978058099746704,
      "learning_rate": 1.4264351885622584e-05,
      "loss": 0.0022,
      "step": 48990
    },
    {
      "epoch": 3.574294259245751,
      "grad_norm": 0.058077406138181686,
      "learning_rate": 1.425705740754249e-05,
      "loss": 0.0048,
      "step": 49000
    },
    {
      "epoch": 3.5750237070537603,
      "grad_norm": 0.05833803489804268,
      "learning_rate": 1.4249762929462399e-05,
      "loss": 0.0032,
      "step": 49010
    },
    {
      "epoch": 3.5757531548617694,
      "grad_norm": 0.014190878719091415,
      "learning_rate": 1.4242468451382305e-05,
      "loss": 0.0042,
      "step": 49020
    },
    {
      "epoch": 3.576482602669779,
      "grad_norm": 0.26940786838531494,
      "learning_rate": 1.423517397330221e-05,
      "loss": 0.0028,
      "step": 49030
    },
    {
      "epoch": 3.5772120504777885,
      "grad_norm": 0.35417285561561584,
      "learning_rate": 1.4227879495222118e-05,
      "loss": 0.0047,
      "step": 49040
    },
    {
      "epoch": 3.5779414982857976,
      "grad_norm": 0.2306131273508072,
      "learning_rate": 1.4220585017142024e-05,
      "loss": 0.0034,
      "step": 49050
    },
    {
      "epoch": 3.578670946093807,
      "grad_norm": 0.006967811845242977,
      "learning_rate": 1.421329053906193e-05,
      "loss": 0.0032,
      "step": 49060
    },
    {
      "epoch": 3.579400393901816,
      "grad_norm": 0.08770547807216644,
      "learning_rate": 1.4205996060981839e-05,
      "loss": 0.0032,
      "step": 49070
    },
    {
      "epoch": 3.5801298417098257,
      "grad_norm": 0.13221855461597443,
      "learning_rate": 1.4198701582901745e-05,
      "loss": 0.003,
      "step": 49080
    },
    {
      "epoch": 3.580859289517835,
      "grad_norm": 0.29017484188079834,
      "learning_rate": 1.4191407104821649e-05,
      "loss": 0.003,
      "step": 49090
    },
    {
      "epoch": 3.5815887373258444,
      "grad_norm": 0.8773019909858704,
      "learning_rate": 1.4184112626741558e-05,
      "loss": 0.0043,
      "step": 49100
    },
    {
      "epoch": 3.582318185133854,
      "grad_norm": 0.10273370146751404,
      "learning_rate": 1.4176818148661464e-05,
      "loss": 0.0042,
      "step": 49110
    },
    {
      "epoch": 3.583047632941863,
      "grad_norm": 0.3321492075920105,
      "learning_rate": 1.416952367058137e-05,
      "loss": 0.0026,
      "step": 49120
    },
    {
      "epoch": 3.583777080749872,
      "grad_norm": 0.2305990606546402,
      "learning_rate": 1.4162229192501277e-05,
      "loss": 0.0029,
      "step": 49130
    },
    {
      "epoch": 3.5845065285578817,
      "grad_norm": 0.17317894101142883,
      "learning_rate": 1.4154934714421183e-05,
      "loss": 0.0035,
      "step": 49140
    },
    {
      "epoch": 3.585235976365891,
      "grad_norm": 0.34618058800697327,
      "learning_rate": 1.4147640236341089e-05,
      "loss": 0.0034,
      "step": 49150
    },
    {
      "epoch": 3.5859654241739003,
      "grad_norm": 0.09579841792583466,
      "learning_rate": 1.4140345758260998e-05,
      "loss": 0.0039,
      "step": 49160
    },
    {
      "epoch": 3.58669487198191,
      "grad_norm": 0.28922316431999207,
      "learning_rate": 1.4133051280180904e-05,
      "loss": 0.002,
      "step": 49170
    },
    {
      "epoch": 3.587424319789919,
      "grad_norm": 0.3456474840641022,
      "learning_rate": 1.412575680210081e-05,
      "loss": 0.0019,
      "step": 49180
    },
    {
      "epoch": 3.5881537675979285,
      "grad_norm": 0.20107901096343994,
      "learning_rate": 1.4118462324020717e-05,
      "loss": 0.0034,
      "step": 49190
    },
    {
      "epoch": 3.5888832154059376,
      "grad_norm": 0.1738552451133728,
      "learning_rate": 1.4111167845940623e-05,
      "loss": 0.0035,
      "step": 49200
    },
    {
      "epoch": 3.589612663213947,
      "grad_norm": 0.0946761816740036,
      "learning_rate": 1.4103873367860529e-05,
      "loss": 0.0031,
      "step": 49210
    },
    {
      "epoch": 3.590342111021956,
      "grad_norm": 0.033209677785634995,
      "learning_rate": 1.4096578889780438e-05,
      "loss": 0.0027,
      "step": 49220
    },
    {
      "epoch": 3.5910715588299658,
      "grad_norm": 0.46537280082702637,
      "learning_rate": 1.4089284411700342e-05,
      "loss": 0.0029,
      "step": 49230
    },
    {
      "epoch": 3.591801006637975,
      "grad_norm": 0.17222219705581665,
      "learning_rate": 1.4081989933620248e-05,
      "loss": 0.0023,
      "step": 49240
    },
    {
      "epoch": 3.5925304544459844,
      "grad_norm": 0.030655067414045334,
      "learning_rate": 1.4074695455540157e-05,
      "loss": 0.0033,
      "step": 49250
    },
    {
      "epoch": 3.593259902253994,
      "grad_norm": 0.08677785843610764,
      "learning_rate": 1.4067400977460063e-05,
      "loss": 0.0023,
      "step": 49260
    },
    {
      "epoch": 3.593989350062003,
      "grad_norm": 0.05842520669102669,
      "learning_rate": 1.406010649937997e-05,
      "loss": 0.0032,
      "step": 49270
    },
    {
      "epoch": 3.594718797870012,
      "grad_norm": 0.6216345429420471,
      "learning_rate": 1.4052812021299877e-05,
      "loss": 0.005,
      "step": 49280
    },
    {
      "epoch": 3.5954482456780217,
      "grad_norm": 0.20258352160453796,
      "learning_rate": 1.4045517543219782e-05,
      "loss": 0.003,
      "step": 49290
    },
    {
      "epoch": 3.5961776934860312,
      "grad_norm": 0.11578960716724396,
      "learning_rate": 1.4038223065139692e-05,
      "loss": 0.0028,
      "step": 49300
    },
    {
      "epoch": 3.5969071412940403,
      "grad_norm": 0.010234863497316837,
      "learning_rate": 1.4030928587059597e-05,
      "loss": 0.0037,
      "step": 49310
    },
    {
      "epoch": 3.59763658910205,
      "grad_norm": 0.37492433190345764,
      "learning_rate": 1.4023634108979503e-05,
      "loss": 0.0027,
      "step": 49320
    },
    {
      "epoch": 3.598366036910059,
      "grad_norm": 0.08674758672714233,
      "learning_rate": 1.4016339630899411e-05,
      "loss": 0.002,
      "step": 49330
    },
    {
      "epoch": 3.5990954847180685,
      "grad_norm": 0.11981800943613052,
      "learning_rate": 1.4009045152819317e-05,
      "loss": 0.003,
      "step": 49340
    },
    {
      "epoch": 3.5998249325260776,
      "grad_norm": 0.1962011754512787,
      "learning_rate": 1.4001750674739223e-05,
      "loss": 0.0026,
      "step": 49350
    },
    {
      "epoch": 3.600554380334087,
      "grad_norm": 0.28918135166168213,
      "learning_rate": 1.399445619665913e-05,
      "loss": 0.003,
      "step": 49360
    },
    {
      "epoch": 3.6012838281420967,
      "grad_norm": 0.40315210819244385,
      "learning_rate": 1.3987161718579036e-05,
      "loss": 0.0029,
      "step": 49370
    },
    {
      "epoch": 3.602013275950106,
      "grad_norm": 0.058472223579883575,
      "learning_rate": 1.3979867240498942e-05,
      "loss": 0.0029,
      "step": 49380
    },
    {
      "epoch": 3.602742723758115,
      "grad_norm": 0.2880125939846039,
      "learning_rate": 1.3972572762418851e-05,
      "loss": 0.0043,
      "step": 49390
    },
    {
      "epoch": 3.6034721715661244,
      "grad_norm": 0.6482660174369812,
      "learning_rate": 1.3965278284338757e-05,
      "loss": 0.0042,
      "step": 49400
    },
    {
      "epoch": 3.604201619374134,
      "grad_norm": 0.1165374219417572,
      "learning_rate": 1.3957983806258663e-05,
      "loss": 0.0027,
      "step": 49410
    },
    {
      "epoch": 3.604931067182143,
      "grad_norm": 0.2676476836204529,
      "learning_rate": 1.395068932817857e-05,
      "loss": 0.0029,
      "step": 49420
    },
    {
      "epoch": 3.6056605149901526,
      "grad_norm": 0.6905155777931213,
      "learning_rate": 1.3943394850098476e-05,
      "loss": 0.0034,
      "step": 49430
    },
    {
      "epoch": 3.6063899627981617,
      "grad_norm": 0.20132996141910553,
      "learning_rate": 1.3936100372018382e-05,
      "loss": 0.0028,
      "step": 49440
    },
    {
      "epoch": 3.6071194106061713,
      "grad_norm": 0.03170003369450569,
      "learning_rate": 1.3928805893938291e-05,
      "loss": 0.0023,
      "step": 49450
    },
    {
      "epoch": 3.6078488584141803,
      "grad_norm": 0.4057522416114807,
      "learning_rate": 1.3921511415858197e-05,
      "loss": 0.0043,
      "step": 49460
    },
    {
      "epoch": 3.60857830622219,
      "grad_norm": 0.23048482835292816,
      "learning_rate": 1.3914216937778101e-05,
      "loss": 0.0026,
      "step": 49470
    },
    {
      "epoch": 3.609307754030199,
      "grad_norm": 0.13569869101047516,
      "learning_rate": 1.390692245969801e-05,
      "loss": 0.0027,
      "step": 49480
    },
    {
      "epoch": 3.6100372018382085,
      "grad_norm": 0.20900288224220276,
      "learning_rate": 1.3899627981617916e-05,
      "loss": 0.0021,
      "step": 49490
    },
    {
      "epoch": 3.6107666496462176,
      "grad_norm": 0.11784929782152176,
      "learning_rate": 1.3892333503537822e-05,
      "loss": 0.002,
      "step": 49500
    },
    {
      "epoch": 3.611496097454227,
      "grad_norm": 0.5475881099700928,
      "learning_rate": 1.388503902545773e-05,
      "loss": 0.0037,
      "step": 49510
    },
    {
      "epoch": 3.6122255452622367,
      "grad_norm": 0.2309223860502243,
      "learning_rate": 1.3877744547377635e-05,
      "loss": 0.0018,
      "step": 49520
    },
    {
      "epoch": 3.612954993070246,
      "grad_norm": 0.28741157054901123,
      "learning_rate": 1.3870450069297541e-05,
      "loss": 0.0035,
      "step": 49530
    },
    {
      "epoch": 3.613684440878255,
      "grad_norm": 0.1501803696155548,
      "learning_rate": 1.386315559121745e-05,
      "loss": 0.0035,
      "step": 49540
    },
    {
      "epoch": 3.6144138886862645,
      "grad_norm": 0.031593065708875656,
      "learning_rate": 1.3855861113137356e-05,
      "loss": 0.0033,
      "step": 49550
    },
    {
      "epoch": 3.615143336494274,
      "grad_norm": 0.45937642455101013,
      "learning_rate": 1.3848566635057262e-05,
      "loss": 0.0023,
      "step": 49560
    },
    {
      "epoch": 3.615872784302283,
      "grad_norm": 0.20292523503303528,
      "learning_rate": 1.384127215697717e-05,
      "loss": 0.003,
      "step": 49570
    },
    {
      "epoch": 3.6166022321102926,
      "grad_norm": 0.11535023897886276,
      "learning_rate": 1.3833977678897075e-05,
      "loss": 0.0027,
      "step": 49580
    },
    {
      "epoch": 3.6173316799183017,
      "grad_norm": 0.029874281957745552,
      "learning_rate": 1.3826683200816981e-05,
      "loss": 0.0031,
      "step": 49590
    },
    {
      "epoch": 3.6180611277263113,
      "grad_norm": 0.14497016370296478,
      "learning_rate": 1.3819388722736889e-05,
      "loss": 0.0038,
      "step": 49600
    },
    {
      "epoch": 3.6187905755343204,
      "grad_norm": 0.031008142977952957,
      "learning_rate": 1.3812094244656795e-05,
      "loss": 0.0034,
      "step": 49610
    },
    {
      "epoch": 3.61952002334233,
      "grad_norm": 0.11665042489767075,
      "learning_rate": 1.38047997665767e-05,
      "loss": 0.0024,
      "step": 49620
    },
    {
      "epoch": 3.6202494711503395,
      "grad_norm": 0.07631200551986694,
      "learning_rate": 1.379750528849661e-05,
      "loss": 0.003,
      "step": 49630
    },
    {
      "epoch": 3.6209789189583486,
      "grad_norm": 0.2770250141620636,
      "learning_rate": 1.3790210810416515e-05,
      "loss": 0.0031,
      "step": 49640
    },
    {
      "epoch": 3.6217083667663577,
      "grad_norm": 0.7131963968276978,
      "learning_rate": 1.3782916332336421e-05,
      "loss": 0.0036,
      "step": 49650
    },
    {
      "epoch": 3.622437814574367,
      "grad_norm": 0.3744991719722748,
      "learning_rate": 1.3775621854256329e-05,
      "loss": 0.0039,
      "step": 49660
    },
    {
      "epoch": 3.6231672623823767,
      "grad_norm": 0.255744606256485,
      "learning_rate": 1.3768327376176235e-05,
      "loss": 0.0026,
      "step": 49670
    },
    {
      "epoch": 3.623896710190386,
      "grad_norm": 0.35423481464385986,
      "learning_rate": 1.376103289809614e-05,
      "loss": 0.0024,
      "step": 49680
    },
    {
      "epoch": 3.624626157998395,
      "grad_norm": 0.2600298225879669,
      "learning_rate": 1.375373842001605e-05,
      "loss": 0.0033,
      "step": 49690
    },
    {
      "epoch": 3.6253556058064045,
      "grad_norm": 0.1189633458852768,
      "learning_rate": 1.3746443941935956e-05,
      "loss": 0.0031,
      "step": 49700
    },
    {
      "epoch": 3.626085053614414,
      "grad_norm": 0.2886042892932892,
      "learning_rate": 1.373914946385586e-05,
      "loss": 0.0036,
      "step": 49710
    },
    {
      "epoch": 3.626814501422423,
      "grad_norm": 0.11544115841388702,
      "learning_rate": 1.3731854985775769e-05,
      "loss": 0.0036,
      "step": 49720
    },
    {
      "epoch": 3.6275439492304327,
      "grad_norm": 0.03096153400838375,
      "learning_rate": 1.3724560507695675e-05,
      "loss": 0.0032,
      "step": 49730
    },
    {
      "epoch": 3.6282733970384418,
      "grad_norm": 0.0644461065530777,
      "learning_rate": 1.3717266029615582e-05,
      "loss": 0.0025,
      "step": 49740
    },
    {
      "epoch": 3.6290028448464513,
      "grad_norm": 0.08748046308755875,
      "learning_rate": 1.3709971551535488e-05,
      "loss": 0.0036,
      "step": 49750
    },
    {
      "epoch": 3.6297322926544604,
      "grad_norm": 0.03520338609814644,
      "learning_rate": 1.3702677073455394e-05,
      "loss": 0.0037,
      "step": 49760
    },
    {
      "epoch": 3.63046174046247,
      "grad_norm": 0.604783296585083,
      "learning_rate": 1.3695382595375303e-05,
      "loss": 0.0025,
      "step": 49770
    },
    {
      "epoch": 3.6311911882704795,
      "grad_norm": 0.011000271886587143,
      "learning_rate": 1.3688088117295209e-05,
      "loss": 0.0035,
      "step": 49780
    },
    {
      "epoch": 3.6319206360784886,
      "grad_norm": 0.17664676904678345,
      "learning_rate": 1.3680793639215115e-05,
      "loss": 0.0024,
      "step": 49790
    },
    {
      "epoch": 3.6326500838864977,
      "grad_norm": 0.3174937665462494,
      "learning_rate": 1.3673499161135022e-05,
      "loss": 0.0026,
      "step": 49800
    },
    {
      "epoch": 3.6333795316945072,
      "grad_norm": 0.10376006364822388,
      "learning_rate": 1.3666204683054928e-05,
      "loss": 0.0032,
      "step": 49810
    },
    {
      "epoch": 3.6341089795025168,
      "grad_norm": 0.08859798312187195,
      "learning_rate": 1.3658910204974834e-05,
      "loss": 0.0028,
      "step": 49820
    },
    {
      "epoch": 3.634838427310526,
      "grad_norm": 0.4922802448272705,
      "learning_rate": 1.3651615726894743e-05,
      "loss": 0.0024,
      "step": 49830
    },
    {
      "epoch": 3.6355678751185354,
      "grad_norm": 0.14481841027736664,
      "learning_rate": 1.3644321248814647e-05,
      "loss": 0.0032,
      "step": 49840
    },
    {
      "epoch": 3.6362973229265445,
      "grad_norm": 0.1327885091304779,
      "learning_rate": 1.3637026770734553e-05,
      "loss": 0.0019,
      "step": 49850
    },
    {
      "epoch": 3.637026770734554,
      "grad_norm": 0.08692310005426407,
      "learning_rate": 1.3629732292654463e-05,
      "loss": 0.004,
      "step": 49860
    },
    {
      "epoch": 3.637756218542563,
      "grad_norm": 0.0792788714170456,
      "learning_rate": 1.3622437814574368e-05,
      "loss": 0.0049,
      "step": 49870
    },
    {
      "epoch": 3.6384856663505727,
      "grad_norm": 0.34118831157684326,
      "learning_rate": 1.3615143336494274e-05,
      "loss": 0.0038,
      "step": 49880
    },
    {
      "epoch": 3.639215114158582,
      "grad_norm": 0.1731465458869934,
      "learning_rate": 1.3607848858414182e-05,
      "loss": 0.0032,
      "step": 49890
    },
    {
      "epoch": 3.6399445619665913,
      "grad_norm": 0.2642256021499634,
      "learning_rate": 1.3600554380334088e-05,
      "loss": 0.0031,
      "step": 49900
    },
    {
      "epoch": 3.6406740097746004,
      "grad_norm": 0.14518243074417114,
      "learning_rate": 1.3593259902253993e-05,
      "loss": 0.0038,
      "step": 49910
    },
    {
      "epoch": 3.64140345758261,
      "grad_norm": 0.2416851967573166,
      "learning_rate": 1.3585965424173903e-05,
      "loss": 0.0036,
      "step": 49920
    },
    {
      "epoch": 3.6421329053906195,
      "grad_norm": 0.03252167999744415,
      "learning_rate": 1.3578670946093808e-05,
      "loss": 0.0031,
      "step": 49930
    },
    {
      "epoch": 3.6428623531986286,
      "grad_norm": 0.2605116367340088,
      "learning_rate": 1.3571376468013714e-05,
      "loss": 0.0043,
      "step": 49940
    },
    {
      "epoch": 3.6435918010066377,
      "grad_norm": 0.25959163904190063,
      "learning_rate": 1.3564081989933622e-05,
      "loss": 0.0025,
      "step": 49950
    },
    {
      "epoch": 3.6443212488146473,
      "grad_norm": 0.08665298670530319,
      "learning_rate": 1.3556787511853528e-05,
      "loss": 0.0028,
      "step": 49960
    },
    {
      "epoch": 3.645050696622657,
      "grad_norm": 0.3743642270565033,
      "learning_rate": 1.3549493033773433e-05,
      "loss": 0.0033,
      "step": 49970
    },
    {
      "epoch": 3.645780144430666,
      "grad_norm": 0.060887157917022705,
      "learning_rate": 1.3542198555693341e-05,
      "loss": 0.0024,
      "step": 49980
    },
    {
      "epoch": 3.6465095922386754,
      "grad_norm": 0.4616144299507141,
      "learning_rate": 1.3534904077613247e-05,
      "loss": 0.0021,
      "step": 49990
    },
    {
      "epoch": 3.6472390400466845,
      "grad_norm": 0.17309816181659698,
      "learning_rate": 1.3527609599533153e-05,
      "loss": 0.0038,
      "step": 50000
    },
    {
      "epoch": 3.647968487854694,
      "grad_norm": 0.08875516802072525,
      "learning_rate": 1.3520315121453062e-05,
      "loss": 0.0041,
      "step": 50010
    },
    {
      "epoch": 3.648697935662703,
      "grad_norm": 0.08749700337648392,
      "learning_rate": 1.3513020643372968e-05,
      "loss": 0.003,
      "step": 50020
    },
    {
      "epoch": 3.6494273834707127,
      "grad_norm": 0.14894163608551025,
      "learning_rate": 1.3505726165292874e-05,
      "loss": 0.0046,
      "step": 50030
    },
    {
      "epoch": 3.6501568312787223,
      "grad_norm": 0.08709988743066788,
      "learning_rate": 1.3498431687212781e-05,
      "loss": 0.0032,
      "step": 50040
    },
    {
      "epoch": 3.6508862790867314,
      "grad_norm": 0.1431540548801422,
      "learning_rate": 1.3491137209132687e-05,
      "loss": 0.003,
      "step": 50050
    },
    {
      "epoch": 3.6516157268947405,
      "grad_norm": 0.05776534229516983,
      "learning_rate": 1.3483842731052593e-05,
      "loss": 0.0033,
      "step": 50060
    },
    {
      "epoch": 3.65234517470275,
      "grad_norm": 0.14442192018032074,
      "learning_rate": 1.3476548252972502e-05,
      "loss": 0.0037,
      "step": 50070
    },
    {
      "epoch": 3.6530746225107595,
      "grad_norm": 0.31735959649086,
      "learning_rate": 1.3469253774892406e-05,
      "loss": 0.0034,
      "step": 50080
    },
    {
      "epoch": 3.6538040703187686,
      "grad_norm": 0.05959711968898773,
      "learning_rate": 1.3461959296812312e-05,
      "loss": 0.0029,
      "step": 50090
    },
    {
      "epoch": 3.654533518126778,
      "grad_norm": 0.058802004903554916,
      "learning_rate": 1.3454664818732221e-05,
      "loss": 0.0026,
      "step": 50100
    },
    {
      "epoch": 3.6552629659347873,
      "grad_norm": 0.17326092720031738,
      "learning_rate": 1.3447370340652127e-05,
      "loss": 0.0033,
      "step": 50110
    },
    {
      "epoch": 3.655992413742797,
      "grad_norm": 0.17285092175006866,
      "learning_rate": 1.3440075862572033e-05,
      "loss": 0.0032,
      "step": 50120
    },
    {
      "epoch": 3.656721861550806,
      "grad_norm": 0.030731532722711563,
      "learning_rate": 1.343278138449194e-05,
      "loss": 0.0034,
      "step": 50130
    },
    {
      "epoch": 3.6574513093588155,
      "grad_norm": 0.09723763167858124,
      "learning_rate": 1.3425486906411846e-05,
      "loss": 0.0025,
      "step": 50140
    },
    {
      "epoch": 3.6581807571668246,
      "grad_norm": 0.008499536663293839,
      "learning_rate": 1.3418192428331752e-05,
      "loss": 0.0034,
      "step": 50150
    },
    {
      "epoch": 3.658910204974834,
      "grad_norm": 0.05861574411392212,
      "learning_rate": 1.3410897950251661e-05,
      "loss": 0.0027,
      "step": 50160
    },
    {
      "epoch": 3.659639652782843,
      "grad_norm": 0.14573940634727478,
      "learning_rate": 1.3403603472171567e-05,
      "loss": 0.0044,
      "step": 50170
    },
    {
      "epoch": 3.6603691005908527,
      "grad_norm": 0.34532225131988525,
      "learning_rate": 1.3396308994091471e-05,
      "loss": 0.0026,
      "step": 50180
    },
    {
      "epoch": 3.6610985483988623,
      "grad_norm": 0.08718742430210114,
      "learning_rate": 1.338901451601138e-05,
      "loss": 0.0028,
      "step": 50190
    },
    {
      "epoch": 3.6618279962068714,
      "grad_norm": 0.233742818236351,
      "learning_rate": 1.3381720037931286e-05,
      "loss": 0.0028,
      "step": 50200
    },
    {
      "epoch": 3.6625574440148805,
      "grad_norm": 0.46131637692451477,
      "learning_rate": 1.3374425559851192e-05,
      "loss": 0.0029,
      "step": 50210
    },
    {
      "epoch": 3.66328689182289,
      "grad_norm": 0.11487902700901031,
      "learning_rate": 1.33671310817711e-05,
      "loss": 0.0039,
      "step": 50220
    },
    {
      "epoch": 3.6640163396308996,
      "grad_norm": 0.3747704029083252,
      "learning_rate": 1.3359836603691006e-05,
      "loss": 0.0037,
      "step": 50230
    },
    {
      "epoch": 3.6647457874389087,
      "grad_norm": 0.03315585106611252,
      "learning_rate": 1.3352542125610915e-05,
      "loss": 0.0031,
      "step": 50240
    },
    {
      "epoch": 3.665475235246918,
      "grad_norm": 0.23582012951374054,
      "learning_rate": 1.334524764753082e-05,
      "loss": 0.0025,
      "step": 50250
    },
    {
      "epoch": 3.6662046830549273,
      "grad_norm": 0.26406458020210266,
      "learning_rate": 1.3337953169450726e-05,
      "loss": 0.0034,
      "step": 50260
    },
    {
      "epoch": 3.666934130862937,
      "grad_norm": 0.13194169104099274,
      "learning_rate": 1.3330658691370634e-05,
      "loss": 0.0032,
      "step": 50270
    },
    {
      "epoch": 3.667663578670946,
      "grad_norm": 0.0584646612405777,
      "learning_rate": 1.332336421329054e-05,
      "loss": 0.0026,
      "step": 50280
    },
    {
      "epoch": 3.6683930264789555,
      "grad_norm": 0.11666817963123322,
      "learning_rate": 1.3316069735210446e-05,
      "loss": 0.0017,
      "step": 50290
    },
    {
      "epoch": 3.669122474286965,
      "grad_norm": 0.28838974237442017,
      "learning_rate": 1.3308775257130355e-05,
      "loss": 0.0036,
      "step": 50300
    },
    {
      "epoch": 3.669851922094974,
      "grad_norm": 0.300017774105072,
      "learning_rate": 1.330148077905026e-05,
      "loss": 0.0023,
      "step": 50310
    },
    {
      "epoch": 3.6705813699029832,
      "grad_norm": 0.11577383428812027,
      "learning_rate": 1.3294186300970165e-05,
      "loss": 0.0037,
      "step": 50320
    },
    {
      "epoch": 3.6713108177109928,
      "grad_norm": 0.059140633791685104,
      "learning_rate": 1.3286891822890074e-05,
      "loss": 0.0018,
      "step": 50330
    },
    {
      "epoch": 3.6720402655190023,
      "grad_norm": 0.1446903496980667,
      "learning_rate": 1.327959734480998e-05,
      "loss": 0.0031,
      "step": 50340
    },
    {
      "epoch": 3.6727697133270114,
      "grad_norm": 0.17532342672348022,
      "learning_rate": 1.3272302866729886e-05,
      "loss": 0.0037,
      "step": 50350
    },
    {
      "epoch": 3.673499161135021,
      "grad_norm": 0.11493845283985138,
      "learning_rate": 1.3265008388649793e-05,
      "loss": 0.0037,
      "step": 50360
    },
    {
      "epoch": 3.67422860894303,
      "grad_norm": 0.07037577778100967,
      "learning_rate": 1.3257713910569699e-05,
      "loss": 0.0041,
      "step": 50370
    },
    {
      "epoch": 3.6749580567510396,
      "grad_norm": 0.08822787553071976,
      "learning_rate": 1.3250419432489605e-05,
      "loss": 0.0036,
      "step": 50380
    },
    {
      "epoch": 3.6756875045590487,
      "grad_norm": 0.23349212110042572,
      "learning_rate": 1.3243124954409514e-05,
      "loss": 0.0032,
      "step": 50390
    },
    {
      "epoch": 3.6764169523670582,
      "grad_norm": 0.11849687993526459,
      "learning_rate": 1.323583047632942e-05,
      "loss": 0.0028,
      "step": 50400
    },
    {
      "epoch": 3.6771464001750673,
      "grad_norm": 0.20254139602184296,
      "learning_rate": 1.3228535998249326e-05,
      "loss": 0.0031,
      "step": 50410
    },
    {
      "epoch": 3.677875847983077,
      "grad_norm": 0.14668333530426025,
      "learning_rate": 1.3221241520169233e-05,
      "loss": 0.0025,
      "step": 50420
    },
    {
      "epoch": 3.678605295791086,
      "grad_norm": 0.011826594360172749,
      "learning_rate": 1.321394704208914e-05,
      "loss": 0.0039,
      "step": 50430
    },
    {
      "epoch": 3.6793347435990955,
      "grad_norm": 0.058429230004549026,
      "learning_rate": 1.3206652564009045e-05,
      "loss": 0.0038,
      "step": 50440
    },
    {
      "epoch": 3.680064191407105,
      "grad_norm": 0.08805018663406372,
      "learning_rate": 1.3199358085928953e-05,
      "loss": 0.0033,
      "step": 50450
    },
    {
      "epoch": 3.680793639215114,
      "grad_norm": 0.008039255626499653,
      "learning_rate": 1.3192063607848858e-05,
      "loss": 0.0036,
      "step": 50460
    },
    {
      "epoch": 3.6815230870231233,
      "grad_norm": 0.2593192756175995,
      "learning_rate": 1.3184769129768764e-05,
      "loss": 0.0022,
      "step": 50470
    },
    {
      "epoch": 3.682252534831133,
      "grad_norm": 0.5715640187263489,
      "learning_rate": 1.3177474651688673e-05,
      "loss": 0.0031,
      "step": 50480
    },
    {
      "epoch": 3.6829819826391423,
      "grad_norm": 0.24318192899227142,
      "learning_rate": 1.317018017360858e-05,
      "loss": 0.0028,
      "step": 50490
    },
    {
      "epoch": 3.6837114304471514,
      "grad_norm": 0.02930362895131111,
      "learning_rate": 1.3162885695528485e-05,
      "loss": 0.0025,
      "step": 50500
    },
    {
      "epoch": 3.684440878255161,
      "grad_norm": 0.20280666649341583,
      "learning_rate": 1.3155591217448393e-05,
      "loss": 0.0032,
      "step": 50510
    },
    {
      "epoch": 3.68517032606317,
      "grad_norm": 0.2993532419204712,
      "learning_rate": 1.3148296739368298e-05,
      "loss": 0.0038,
      "step": 50520
    },
    {
      "epoch": 3.6858997738711796,
      "grad_norm": 0.14934702217578888,
      "learning_rate": 1.3141002261288204e-05,
      "loss": 0.0036,
      "step": 50530
    },
    {
      "epoch": 3.6866292216791887,
      "grad_norm": 0.17530794441699982,
      "learning_rate": 1.3133707783208114e-05,
      "loss": 0.0021,
      "step": 50540
    },
    {
      "epoch": 3.6873586694871983,
      "grad_norm": 0.4616137444972992,
      "learning_rate": 1.312641330512802e-05,
      "loss": 0.004,
      "step": 50550
    },
    {
      "epoch": 3.688088117295208,
      "grad_norm": 0.08794491738080978,
      "learning_rate": 1.3119118827047924e-05,
      "loss": 0.0022,
      "step": 50560
    },
    {
      "epoch": 3.688817565103217,
      "grad_norm": 0.4868829548358917,
      "learning_rate": 1.3111824348967833e-05,
      "loss": 0.0025,
      "step": 50570
    },
    {
      "epoch": 3.689547012911226,
      "grad_norm": 0.5470702648162842,
      "learning_rate": 1.3104529870887739e-05,
      "loss": 0.0027,
      "step": 50580
    },
    {
      "epoch": 3.6902764607192355,
      "grad_norm": 0.6199498772621155,
      "learning_rate": 1.3097235392807644e-05,
      "loss": 0.0034,
      "step": 50590
    },
    {
      "epoch": 3.691005908527245,
      "grad_norm": 0.2037942260503769,
      "learning_rate": 1.3089940914727552e-05,
      "loss": 0.0044,
      "step": 50600
    },
    {
      "epoch": 3.691735356335254,
      "grad_norm": 0.11686207354068756,
      "learning_rate": 1.3082646436647458e-05,
      "loss": 0.0031,
      "step": 50610
    },
    {
      "epoch": 3.6924648041432633,
      "grad_norm": 0.2020886391401291,
      "learning_rate": 1.3075351958567364e-05,
      "loss": 0.0037,
      "step": 50620
    },
    {
      "epoch": 3.693194251951273,
      "grad_norm": 0.05933595448732376,
      "learning_rate": 1.3068057480487273e-05,
      "loss": 0.0037,
      "step": 50630
    },
    {
      "epoch": 3.6939236997592824,
      "grad_norm": 0.35777580738067627,
      "learning_rate": 1.3060763002407179e-05,
      "loss": 0.0034,
      "step": 50640
    },
    {
      "epoch": 3.6946531475672915,
      "grad_norm": 0.031057249754667282,
      "learning_rate": 1.3053468524327085e-05,
      "loss": 0.0036,
      "step": 50650
    },
    {
      "epoch": 3.695382595375301,
      "grad_norm": 0.34150230884552,
      "learning_rate": 1.3046174046246992e-05,
      "loss": 0.0026,
      "step": 50660
    },
    {
      "epoch": 3.69611204318331,
      "grad_norm": 0.27557072043418884,
      "learning_rate": 1.3038879568166898e-05,
      "loss": 0.0031,
      "step": 50670
    },
    {
      "epoch": 3.6968414909913196,
      "grad_norm": 0.05942942574620247,
      "learning_rate": 1.3031585090086804e-05,
      "loss": 0.0038,
      "step": 50680
    },
    {
      "epoch": 3.6975709387993287,
      "grad_norm": 0.05042377859354019,
      "learning_rate": 1.3024290612006711e-05,
      "loss": 0.0042,
      "step": 50690
    },
    {
      "epoch": 3.6983003866073383,
      "grad_norm": 0.06888037919998169,
      "learning_rate": 1.3016996133926617e-05,
      "loss": 0.0044,
      "step": 50700
    },
    {
      "epoch": 3.699029834415348,
      "grad_norm": 0.2602033019065857,
      "learning_rate": 1.3009701655846523e-05,
      "loss": 0.0038,
      "step": 50710
    },
    {
      "epoch": 3.699759282223357,
      "grad_norm": 0.2013099491596222,
      "learning_rate": 1.3002407177766432e-05,
      "loss": 0.0025,
      "step": 50720
    },
    {
      "epoch": 3.700488730031366,
      "grad_norm": 0.05776213854551315,
      "learning_rate": 1.2995112699686338e-05,
      "loss": 0.0023,
      "step": 50730
    },
    {
      "epoch": 3.7012181778393756,
      "grad_norm": 0.0583430714905262,
      "learning_rate": 1.2987818221606246e-05,
      "loss": 0.0022,
      "step": 50740
    },
    {
      "epoch": 3.701947625647385,
      "grad_norm": 0.05945954844355583,
      "learning_rate": 1.2980523743526151e-05,
      "loss": 0.0031,
      "step": 50750
    },
    {
      "epoch": 3.702677073455394,
      "grad_norm": 0.05954529345035553,
      "learning_rate": 1.2973229265446057e-05,
      "loss": 0.0035,
      "step": 50760
    },
    {
      "epoch": 3.7034065212634038,
      "grad_norm": 0.17234903573989868,
      "learning_rate": 1.2965934787365966e-05,
      "loss": 0.0023,
      "step": 50770
    },
    {
      "epoch": 3.704135969071413,
      "grad_norm": 0.03151935338973999,
      "learning_rate": 1.2958640309285872e-05,
      "loss": 0.0027,
      "step": 50780
    },
    {
      "epoch": 3.7048654168794224,
      "grad_norm": 0.37558794021606445,
      "learning_rate": 1.2951345831205778e-05,
      "loss": 0.0026,
      "step": 50790
    },
    {
      "epoch": 3.7055948646874315,
      "grad_norm": 0.17239418625831604,
      "learning_rate": 1.2944051353125686e-05,
      "loss": 0.0025,
      "step": 50800
    },
    {
      "epoch": 3.706324312495441,
      "grad_norm": 0.5983307957649231,
      "learning_rate": 1.2936756875045591e-05,
      "loss": 0.0052,
      "step": 50810
    },
    {
      "epoch": 3.70705376030345,
      "grad_norm": 0.2598423957824707,
      "learning_rate": 1.2929462396965497e-05,
      "loss": 0.0029,
      "step": 50820
    },
    {
      "epoch": 3.7077832081114597,
      "grad_norm": 0.33331817388534546,
      "learning_rate": 1.2922167918885405e-05,
      "loss": 0.0041,
      "step": 50830
    },
    {
      "epoch": 3.7085126559194688,
      "grad_norm": 0.5180053114891052,
      "learning_rate": 1.291487344080531e-05,
      "loss": 0.0027,
      "step": 50840
    },
    {
      "epoch": 3.7092421037274783,
      "grad_norm": 0.2510845959186554,
      "learning_rate": 1.2907578962725216e-05,
      "loss": 0.0033,
      "step": 50850
    },
    {
      "epoch": 3.709971551535488,
      "grad_norm": 0.11658594757318497,
      "learning_rate": 1.2900284484645126e-05,
      "loss": 0.004,
      "step": 50860
    },
    {
      "epoch": 3.710700999343497,
      "grad_norm": 0.11597935855388641,
      "learning_rate": 1.2892990006565032e-05,
      "loss": 0.0032,
      "step": 50870
    },
    {
      "epoch": 3.711430447151506,
      "grad_norm": 0.37627798318862915,
      "learning_rate": 1.2885695528484937e-05,
      "loss": 0.0028,
      "step": 50880
    },
    {
      "epoch": 3.7121598949595156,
      "grad_norm": 0.5167291164398193,
      "learning_rate": 1.2878401050404845e-05,
      "loss": 0.0028,
      "step": 50890
    },
    {
      "epoch": 3.712889342767525,
      "grad_norm": 0.445634126663208,
      "learning_rate": 1.287110657232475e-05,
      "loss": 0.0031,
      "step": 50900
    },
    {
      "epoch": 3.7136187905755342,
      "grad_norm": 0.3375585079193115,
      "learning_rate": 1.2863812094244657e-05,
      "loss": 0.0023,
      "step": 50910
    },
    {
      "epoch": 3.7143482383835438,
      "grad_norm": 0.03056374005973339,
      "learning_rate": 1.2856517616164566e-05,
      "loss": 0.002,
      "step": 50920
    },
    {
      "epoch": 3.715077686191553,
      "grad_norm": 0.4047352075576782,
      "learning_rate": 1.284922313808447e-05,
      "loss": 0.0025,
      "step": 50930
    },
    {
      "epoch": 3.7158071339995624,
      "grad_norm": 0.22979046404361725,
      "learning_rate": 1.2841928660004376e-05,
      "loss": 0.0029,
      "step": 50940
    },
    {
      "epoch": 3.7165365818075715,
      "grad_norm": 0.030080797150731087,
      "learning_rate": 1.2834634181924285e-05,
      "loss": 0.0035,
      "step": 50950
    },
    {
      "epoch": 3.717266029615581,
      "grad_norm": 0.1726980358362198,
      "learning_rate": 1.2827339703844191e-05,
      "loss": 0.0034,
      "step": 50960
    },
    {
      "epoch": 3.7179954774235906,
      "grad_norm": 0.030570030212402344,
      "learning_rate": 1.2820045225764097e-05,
      "loss": 0.003,
      "step": 50970
    },
    {
      "epoch": 3.7187249252315997,
      "grad_norm": 0.031779468059539795,
      "learning_rate": 1.2812750747684004e-05,
      "loss": 0.0034,
      "step": 50980
    },
    {
      "epoch": 3.719454373039609,
      "grad_norm": 0.6505278944969177,
      "learning_rate": 1.280545626960391e-05,
      "loss": 0.0031,
      "step": 50990
    },
    {
      "epoch": 3.7201838208476183,
      "grad_norm": 0.15418922901153564,
      "learning_rate": 1.2798161791523816e-05,
      "loss": 0.0025,
      "step": 51000
    },
    {
      "epoch": 3.720913268655628,
      "grad_norm": 0.06215361878275871,
      "learning_rate": 1.2790867313443725e-05,
      "loss": 0.0022,
      "step": 51010
    },
    {
      "epoch": 3.721642716463637,
      "grad_norm": 0.14421097934246063,
      "learning_rate": 1.2783572835363631e-05,
      "loss": 0.0023,
      "step": 51020
    },
    {
      "epoch": 3.7223721642716465,
      "grad_norm": 0.3172408640384674,
      "learning_rate": 1.2776278357283537e-05,
      "loss": 0.0033,
      "step": 51030
    },
    {
      "epoch": 3.7231016120796556,
      "grad_norm": 0.4972105026245117,
      "learning_rate": 1.2768983879203444e-05,
      "loss": 0.0027,
      "step": 51040
    },
    {
      "epoch": 3.723831059887665,
      "grad_norm": 0.22963371872901917,
      "learning_rate": 1.276168940112335e-05,
      "loss": 0.0018,
      "step": 51050
    },
    {
      "epoch": 3.7245605076956743,
      "grad_norm": 0.4015294015407562,
      "learning_rate": 1.2754394923043256e-05,
      "loss": 0.0042,
      "step": 51060
    },
    {
      "epoch": 3.725289955503684,
      "grad_norm": 0.28805699944496155,
      "learning_rate": 1.2747100444963164e-05,
      "loss": 0.0028,
      "step": 51070
    },
    {
      "epoch": 3.726019403311693,
      "grad_norm": 0.259296715259552,
      "learning_rate": 1.273980596688307e-05,
      "loss": 0.0029,
      "step": 51080
    },
    {
      "epoch": 3.7267488511197024,
      "grad_norm": 0.11570461839437485,
      "learning_rate": 1.2732511488802975e-05,
      "loss": 0.0025,
      "step": 51090
    },
    {
      "epoch": 3.7274782989277115,
      "grad_norm": 0.20145733654499054,
      "learning_rate": 1.2725217010722884e-05,
      "loss": 0.0033,
      "step": 51100
    },
    {
      "epoch": 3.728207746735721,
      "grad_norm": 0.06411907821893692,
      "learning_rate": 1.271792253264279e-05,
      "loss": 0.0025,
      "step": 51110
    },
    {
      "epoch": 3.7289371945437306,
      "grad_norm": 0.31690043210983276,
      "learning_rate": 1.2710628054562696e-05,
      "loss": 0.0023,
      "step": 51120
    },
    {
      "epoch": 3.7296666423517397,
      "grad_norm": 0.34560441970825195,
      "learning_rate": 1.2703333576482604e-05,
      "loss": 0.0018,
      "step": 51130
    },
    {
      "epoch": 3.730396090159749,
      "grad_norm": 0.6213259100914001,
      "learning_rate": 1.269603909840251e-05,
      "loss": 0.0031,
      "step": 51140
    },
    {
      "epoch": 3.7311255379677584,
      "grad_norm": 0.3175532817840576,
      "learning_rate": 1.2688744620322415e-05,
      "loss": 0.002,
      "step": 51150
    },
    {
      "epoch": 3.731854985775768,
      "grad_norm": 0.17369887232780457,
      "learning_rate": 1.2681450142242325e-05,
      "loss": 0.0017,
      "step": 51160
    },
    {
      "epoch": 3.732584433583777,
      "grad_norm": 0.08692602813243866,
      "learning_rate": 1.2674155664162229e-05,
      "loss": 0.0029,
      "step": 51170
    },
    {
      "epoch": 3.7333138813917865,
      "grad_norm": 0.03130584582686424,
      "learning_rate": 1.2666861186082134e-05,
      "loss": 0.0026,
      "step": 51180
    },
    {
      "epoch": 3.7340433291997956,
      "grad_norm": 0.14439000189304352,
      "learning_rate": 1.2659566708002044e-05,
      "loss": 0.0034,
      "step": 51190
    },
    {
      "epoch": 3.734772777007805,
      "grad_norm": 0.17481166124343872,
      "learning_rate": 1.265227222992195e-05,
      "loss": 0.0038,
      "step": 51200
    },
    {
      "epoch": 3.7355022248158143,
      "grad_norm": 0.23641809821128845,
      "learning_rate": 1.2644977751841855e-05,
      "loss": 0.0029,
      "step": 51210
    },
    {
      "epoch": 3.736231672623824,
      "grad_norm": 0.17385558784008026,
      "learning_rate": 1.2637683273761763e-05,
      "loss": 0.0041,
      "step": 51220
    },
    {
      "epoch": 3.7369611204318334,
      "grad_norm": 0.15426811575889587,
      "learning_rate": 1.2630388795681669e-05,
      "loss": 0.0033,
      "step": 51230
    },
    {
      "epoch": 3.7376905682398425,
      "grad_norm": 0.11636213958263397,
      "learning_rate": 1.2623094317601578e-05,
      "loss": 0.0025,
      "step": 51240
    },
    {
      "epoch": 3.7384200160478516,
      "grad_norm": 0.12234971672296524,
      "learning_rate": 1.2615799839521484e-05,
      "loss": 0.0034,
      "step": 51250
    },
    {
      "epoch": 3.739149463855861,
      "grad_norm": 0.3752410411834717,
      "learning_rate": 1.260850536144139e-05,
      "loss": 0.0029,
      "step": 51260
    },
    {
      "epoch": 3.7398789116638707,
      "grad_norm": 0.4588884115219116,
      "learning_rate": 1.2601210883361297e-05,
      "loss": 0.0039,
      "step": 51270
    },
    {
      "epoch": 3.7406083594718798,
      "grad_norm": 0.20701557397842407,
      "learning_rate": 1.2593916405281203e-05,
      "loss": 0.0037,
      "step": 51280
    },
    {
      "epoch": 3.741337807279889,
      "grad_norm": 0.3803274929523468,
      "learning_rate": 1.2586621927201109e-05,
      "loss": 0.0028,
      "step": 51290
    },
    {
      "epoch": 3.7420672550878984,
      "grad_norm": 0.0874059796333313,
      "learning_rate": 1.2579327449121018e-05,
      "loss": 0.0028,
      "step": 51300
    },
    {
      "epoch": 3.742796702895908,
      "grad_norm": 0.37524208426475525,
      "learning_rate": 1.2572032971040922e-05,
      "loss": 0.0025,
      "step": 51310
    },
    {
      "epoch": 3.743526150703917,
      "grad_norm": 0.3595297038555145,
      "learning_rate": 1.2564738492960828e-05,
      "loss": 0.0024,
      "step": 51320
    },
    {
      "epoch": 3.7442555985119266,
      "grad_norm": 0.3723844885826111,
      "learning_rate": 1.2557444014880737e-05,
      "loss": 0.0032,
      "step": 51330
    },
    {
      "epoch": 3.7449850463199357,
      "grad_norm": 0.38477709889411926,
      "learning_rate": 1.2550149536800643e-05,
      "loss": 0.0032,
      "step": 51340
    },
    {
      "epoch": 3.745714494127945,
      "grad_norm": 0.3568214178085327,
      "learning_rate": 1.2542855058720549e-05,
      "loss": 0.0029,
      "step": 51350
    },
    {
      "epoch": 3.7464439419359543,
      "grad_norm": 0.10762155055999756,
      "learning_rate": 1.2535560580640456e-05,
      "loss": 0.0036,
      "step": 51360
    },
    {
      "epoch": 3.747173389743964,
      "grad_norm": 0.02976633422076702,
      "learning_rate": 1.2528266102560362e-05,
      "loss": 0.0029,
      "step": 51370
    },
    {
      "epoch": 3.7479028375519734,
      "grad_norm": 0.058914825320243835,
      "learning_rate": 1.2520971624480268e-05,
      "loss": 0.0029,
      "step": 51380
    },
    {
      "epoch": 3.7486322853599825,
      "grad_norm": 0.2888394594192505,
      "learning_rate": 1.2513677146400177e-05,
      "loss": 0.0029,
      "step": 51390
    },
    {
      "epoch": 3.7493617331679916,
      "grad_norm": 0.25988614559173584,
      "learning_rate": 1.2506382668320083e-05,
      "loss": 0.0033,
      "step": 51400
    },
    {
      "epoch": 3.750091180976001,
      "grad_norm": 0.03058023564517498,
      "learning_rate": 1.2499088190239989e-05,
      "loss": 0.0029,
      "step": 51410
    },
    {
      "epoch": 3.7508206287840107,
      "grad_norm": 0.03049744851887226,
      "learning_rate": 1.2491793712159895e-05,
      "loss": 0.0038,
      "step": 51420
    },
    {
      "epoch": 3.7515500765920198,
      "grad_norm": 0.6472635269165039,
      "learning_rate": 1.2484499234079802e-05,
      "loss": 0.0032,
      "step": 51430
    },
    {
      "epoch": 3.7522795244000293,
      "grad_norm": 0.2889302670955658,
      "learning_rate": 1.247720475599971e-05,
      "loss": 0.0025,
      "step": 51440
    },
    {
      "epoch": 3.7530089722080384,
      "grad_norm": 0.3459266126155853,
      "learning_rate": 1.2469910277919616e-05,
      "loss": 0.002,
      "step": 51450
    },
    {
      "epoch": 3.753738420016048,
      "grad_norm": 0.0889425054192543,
      "learning_rate": 1.2462615799839522e-05,
      "loss": 0.0038,
      "step": 51460
    },
    {
      "epoch": 3.754467867824057,
      "grad_norm": 0.08890266716480255,
      "learning_rate": 1.2455321321759429e-05,
      "loss": 0.0044,
      "step": 51470
    },
    {
      "epoch": 3.7551973156320666,
      "grad_norm": 0.31776097416877747,
      "learning_rate": 1.2448026843679335e-05,
      "loss": 0.0025,
      "step": 51480
    },
    {
      "epoch": 3.7559267634400757,
      "grad_norm": 0.40378233790397644,
      "learning_rate": 1.2440732365599243e-05,
      "loss": 0.003,
      "step": 51490
    },
    {
      "epoch": 3.7566562112480852,
      "grad_norm": 0.18013648688793182,
      "learning_rate": 1.2433437887519148e-05,
      "loss": 0.0022,
      "step": 51500
    },
    {
      "epoch": 3.7573856590560943,
      "grad_norm": 0.20907801389694214,
      "learning_rate": 1.2426143409439054e-05,
      "loss": 0.004,
      "step": 51510
    },
    {
      "epoch": 3.758115106864104,
      "grad_norm": 0.24511399865150452,
      "learning_rate": 1.2418848931358962e-05,
      "loss": 0.0022,
      "step": 51520
    },
    {
      "epoch": 3.7588445546721134,
      "grad_norm": 0.05738585814833641,
      "learning_rate": 1.241155445327887e-05,
      "loss": 0.0034,
      "step": 51530
    },
    {
      "epoch": 3.7595740024801225,
      "grad_norm": 0.1441567838191986,
      "learning_rate": 1.2404259975198775e-05,
      "loss": 0.0032,
      "step": 51540
    },
    {
      "epoch": 3.7603034502881316,
      "grad_norm": 0.2055296003818512,
      "learning_rate": 1.2396965497118681e-05,
      "loss": 0.0028,
      "step": 51550
    },
    {
      "epoch": 3.761032898096141,
      "grad_norm": 0.031982921063899994,
      "learning_rate": 1.2389671019038588e-05,
      "loss": 0.0031,
      "step": 51560
    },
    {
      "epoch": 3.7617623459041507,
      "grad_norm": 0.1311614215373993,
      "learning_rate": 1.2382376540958494e-05,
      "loss": 0.0041,
      "step": 51570
    },
    {
      "epoch": 3.76249179371216,
      "grad_norm": 0.20220333337783813,
      "learning_rate": 1.2375082062878402e-05,
      "loss": 0.0017,
      "step": 51580
    },
    {
      "epoch": 3.7632212415201693,
      "grad_norm": 0.37453752756118774,
      "learning_rate": 1.236778758479831e-05,
      "loss": 0.0026,
      "step": 51590
    },
    {
      "epoch": 3.7639506893281784,
      "grad_norm": 0.1471177041530609,
      "learning_rate": 1.2360493106718215e-05,
      "loss": 0.004,
      "step": 51600
    },
    {
      "epoch": 3.764680137136188,
      "grad_norm": 0.4033327102661133,
      "learning_rate": 1.2353198628638121e-05,
      "loss": 0.0044,
      "step": 51610
    },
    {
      "epoch": 3.765409584944197,
      "grad_norm": 0.37912431359291077,
      "learning_rate": 1.2345904150558029e-05,
      "loss": 0.003,
      "step": 51620
    },
    {
      "epoch": 3.7661390327522066,
      "grad_norm": 0.08760102838277817,
      "learning_rate": 1.2338609672477936e-05,
      "loss": 0.0028,
      "step": 51630
    },
    {
      "epoch": 3.766868480560216,
      "grad_norm": 0.17331182956695557,
      "learning_rate": 1.2331315194397842e-05,
      "loss": 0.0019,
      "step": 51640
    },
    {
      "epoch": 3.7675979283682253,
      "grad_norm": 0.3664051294326782,
      "learning_rate": 1.2324020716317748e-05,
      "loss": 0.0027,
      "step": 51650
    },
    {
      "epoch": 3.7683273761762344,
      "grad_norm": 0.058334965258836746,
      "learning_rate": 1.2316726238237655e-05,
      "loss": 0.0028,
      "step": 51660
    },
    {
      "epoch": 3.769056823984244,
      "grad_norm": 0.11549599468708038,
      "learning_rate": 1.2309431760157561e-05,
      "loss": 0.0025,
      "step": 51670
    },
    {
      "epoch": 3.7697862717922535,
      "grad_norm": 0.11900130659341812,
      "learning_rate": 1.2302137282077469e-05,
      "loss": 0.003,
      "step": 51680
    },
    {
      "epoch": 3.7705157196002625,
      "grad_norm": 0.31780415773391724,
      "learning_rate": 1.2294842803997374e-05,
      "loss": 0.0039,
      "step": 51690
    },
    {
      "epoch": 3.771245167408272,
      "grad_norm": 0.02342567965388298,
      "learning_rate": 1.228754832591728e-05,
      "loss": 0.003,
      "step": 51700
    },
    {
      "epoch": 3.771974615216281,
      "grad_norm": 0.029155168682336807,
      "learning_rate": 1.2280253847837188e-05,
      "loss": 0.0022,
      "step": 51710
    },
    {
      "epoch": 3.7727040630242907,
      "grad_norm": 0.016900910064578056,
      "learning_rate": 1.2272959369757095e-05,
      "loss": 0.0038,
      "step": 51720
    },
    {
      "epoch": 3.7734335108323,
      "grad_norm": 0.2598862946033478,
      "learning_rate": 1.2265664891677001e-05,
      "loss": 0.0029,
      "step": 51730
    },
    {
      "epoch": 3.7741629586403094,
      "grad_norm": 0.05718604847788811,
      "learning_rate": 1.2258370413596907e-05,
      "loss": 0.0028,
      "step": 51740
    },
    {
      "epoch": 3.7748924064483185,
      "grad_norm": 0.31651583313941956,
      "learning_rate": 1.2251075935516815e-05,
      "loss": 0.0036,
      "step": 51750
    },
    {
      "epoch": 3.775621854256328,
      "grad_norm": 0.2018692046403885,
      "learning_rate": 1.224378145743672e-05,
      "loss": 0.0032,
      "step": 51760
    },
    {
      "epoch": 3.776351302064337,
      "grad_norm": 0.05957181379199028,
      "learning_rate": 1.2236486979356628e-05,
      "loss": 0.0043,
      "step": 51770
    },
    {
      "epoch": 3.7770807498723467,
      "grad_norm": 0.334721177816391,
      "learning_rate": 1.2229192501276534e-05,
      "loss": 0.0041,
      "step": 51780
    },
    {
      "epoch": 3.777810197680356,
      "grad_norm": 0.16976603865623474,
      "learning_rate": 1.222189802319644e-05,
      "loss": 0.0039,
      "step": 51790
    },
    {
      "epoch": 3.7785396454883653,
      "grad_norm": 0.23106591403484344,
      "learning_rate": 1.2214603545116347e-05,
      "loss": 0.0021,
      "step": 51800
    },
    {
      "epoch": 3.7792690932963744,
      "grad_norm": 0.3462814390659332,
      "learning_rate": 1.2207309067036255e-05,
      "loss": 0.0033,
      "step": 51810
    },
    {
      "epoch": 3.779998541104384,
      "grad_norm": 0.5193549990653992,
      "learning_rate": 1.220001458895616e-05,
      "loss": 0.004,
      "step": 51820
    },
    {
      "epoch": 3.7807279889123935,
      "grad_norm": 0.4039783775806427,
      "learning_rate": 1.2192720110876068e-05,
      "loss": 0.0028,
      "step": 51830
    },
    {
      "epoch": 3.7814574367204026,
      "grad_norm": 0.21045131981372833,
      "learning_rate": 1.2185425632795974e-05,
      "loss": 0.0032,
      "step": 51840
    },
    {
      "epoch": 3.782186884528412,
      "grad_norm": 0.17230729758739471,
      "learning_rate": 1.2178131154715881e-05,
      "loss": 0.0025,
      "step": 51850
    },
    {
      "epoch": 3.782916332336421,
      "grad_norm": 0.03129250556230545,
      "learning_rate": 1.2170836676635787e-05,
      "loss": 0.0027,
      "step": 51860
    },
    {
      "epoch": 3.7836457801444308,
      "grad_norm": 0.11607121676206589,
      "learning_rate": 1.2163542198555695e-05,
      "loss": 0.0029,
      "step": 51870
    },
    {
      "epoch": 3.78437522795244,
      "grad_norm": 0.14403961598873138,
      "learning_rate": 1.21562477204756e-05,
      "loss": 0.004,
      "step": 51880
    },
    {
      "epoch": 3.7851046757604494,
      "grad_norm": 0.1183667704463005,
      "learning_rate": 1.2148953242395506e-05,
      "loss": 0.0034,
      "step": 51890
    },
    {
      "epoch": 3.785834123568459,
      "grad_norm": 0.13083088397979736,
      "learning_rate": 1.2141658764315414e-05,
      "loss": 0.0023,
      "step": 51900
    },
    {
      "epoch": 3.786563571376468,
      "grad_norm": 0.12489284574985504,
      "learning_rate": 1.2134364286235321e-05,
      "loss": 0.004,
      "step": 51910
    },
    {
      "epoch": 3.787293019184477,
      "grad_norm": 0.02979307435452938,
      "learning_rate": 1.2127069808155227e-05,
      "loss": 0.0029,
      "step": 51920
    },
    {
      "epoch": 3.7880224669924867,
      "grad_norm": 0.41718482971191406,
      "learning_rate": 1.2119775330075133e-05,
      "loss": 0.0025,
      "step": 51930
    },
    {
      "epoch": 3.7887519148004962,
      "grad_norm": 0.11581573635339737,
      "learning_rate": 1.211248085199504e-05,
      "loss": 0.0029,
      "step": 51940
    },
    {
      "epoch": 3.7894813626085053,
      "grad_norm": 0.13994359970092773,
      "learning_rate": 1.2105186373914947e-05,
      "loss": 0.0024,
      "step": 51950
    },
    {
      "epoch": 3.790210810416515,
      "grad_norm": 0.34289345145225525,
      "learning_rate": 1.2097891895834854e-05,
      "loss": 0.0024,
      "step": 51960
    },
    {
      "epoch": 3.790940258224524,
      "grad_norm": 0.31645700335502625,
      "learning_rate": 1.209059741775476e-05,
      "loss": 0.0021,
      "step": 51970
    },
    {
      "epoch": 3.7916697060325335,
      "grad_norm": 0.057357434183359146,
      "learning_rate": 1.2083302939674666e-05,
      "loss": 0.0021,
      "step": 51980
    },
    {
      "epoch": 3.7923991538405426,
      "grad_norm": 0.46165502071380615,
      "learning_rate": 1.2076008461594573e-05,
      "loss": 0.0042,
      "step": 51990
    },
    {
      "epoch": 3.793128601648552,
      "grad_norm": 0.3174808919429779,
      "learning_rate": 1.206871398351448e-05,
      "loss": 0.0033,
      "step": 52000
    },
    {
      "epoch": 3.7938580494565612,
      "grad_norm": 0.11537785083055496,
      "learning_rate": 1.2061419505434387e-05,
      "loss": 0.0031,
      "step": 52010
    },
    {
      "epoch": 3.794587497264571,
      "grad_norm": 0.1533711701631546,
      "learning_rate": 1.2054125027354292e-05,
      "loss": 0.0028,
      "step": 52020
    },
    {
      "epoch": 3.79531694507258,
      "grad_norm": 0.6923879384994507,
      "learning_rate": 1.20468305492742e-05,
      "loss": 0.0034,
      "step": 52030
    },
    {
      "epoch": 3.7960463928805894,
      "grad_norm": 0.06379204988479614,
      "learning_rate": 1.2039536071194106e-05,
      "loss": 0.0039,
      "step": 52040
    },
    {
      "epoch": 3.796775840688599,
      "grad_norm": 0.17326956987380981,
      "learning_rate": 1.2032241593114013e-05,
      "loss": 0.0024,
      "step": 52050
    },
    {
      "epoch": 3.797505288496608,
      "grad_norm": 0.17709749937057495,
      "learning_rate": 1.2024947115033921e-05,
      "loss": 0.0033,
      "step": 52060
    },
    {
      "epoch": 3.798234736304617,
      "grad_norm": 0.2305024117231369,
      "learning_rate": 1.2017652636953825e-05,
      "loss": 0.0036,
      "step": 52070
    },
    {
      "epoch": 3.7989641841126267,
      "grad_norm": 0.04250849038362503,
      "learning_rate": 1.2010358158873733e-05,
      "loss": 0.0025,
      "step": 52080
    },
    {
      "epoch": 3.7996936319206362,
      "grad_norm": 0.17255766689777374,
      "learning_rate": 1.200306368079364e-05,
      "loss": 0.0039,
      "step": 52090
    },
    {
      "epoch": 3.8004230797286453,
      "grad_norm": 0.17421026527881622,
      "learning_rate": 1.1995769202713548e-05,
      "loss": 0.0035,
      "step": 52100
    },
    {
      "epoch": 3.801152527536655,
      "grad_norm": 0.4072267413139343,
      "learning_rate": 1.1988474724633453e-05,
      "loss": 0.0026,
      "step": 52110
    },
    {
      "epoch": 3.801881975344664,
      "grad_norm": 0.1885260045528412,
      "learning_rate": 1.198118024655336e-05,
      "loss": 0.002,
      "step": 52120
    },
    {
      "epoch": 3.8026114231526735,
      "grad_norm": 0.4619144797325134,
      "learning_rate": 1.1973885768473267e-05,
      "loss": 0.0038,
      "step": 52130
    },
    {
      "epoch": 3.8033408709606826,
      "grad_norm": 0.2299410104751587,
      "learning_rate": 1.1966591290393173e-05,
      "loss": 0.0032,
      "step": 52140
    },
    {
      "epoch": 3.804070318768692,
      "grad_norm": 0.5536699295043945,
      "learning_rate": 1.195929681231308e-05,
      "loss": 0.0026,
      "step": 52150
    },
    {
      "epoch": 3.8047997665767017,
      "grad_norm": 0.5198777914047241,
      "learning_rate": 1.1952002334232986e-05,
      "loss": 0.0019,
      "step": 52160
    },
    {
      "epoch": 3.805529214384711,
      "grad_norm": 0.11589793860912323,
      "learning_rate": 1.1944707856152892e-05,
      "loss": 0.0036,
      "step": 52170
    },
    {
      "epoch": 3.80625866219272,
      "grad_norm": 0.11455277353525162,
      "learning_rate": 1.19374133780728e-05,
      "loss": 0.0036,
      "step": 52180
    },
    {
      "epoch": 3.8069881100007295,
      "grad_norm": 0.11507008224725723,
      "learning_rate": 1.1930118899992707e-05,
      "loss": 0.0024,
      "step": 52190
    },
    {
      "epoch": 3.807717557808739,
      "grad_norm": 0.28348568081855774,
      "learning_rate": 1.1922824421912613e-05,
      "loss": 0.0032,
      "step": 52200
    },
    {
      "epoch": 3.808447005616748,
      "grad_norm": 0.17262156307697296,
      "learning_rate": 1.1915529943832519e-05,
      "loss": 0.0018,
      "step": 52210
    },
    {
      "epoch": 3.809176453424757,
      "grad_norm": 0.009419428184628487,
      "learning_rate": 1.1908235465752426e-05,
      "loss": 0.0024,
      "step": 52220
    },
    {
      "epoch": 3.8099059012327667,
      "grad_norm": 0.12158156931400299,
      "learning_rate": 1.1900940987672332e-05,
      "loss": 0.004,
      "step": 52230
    },
    {
      "epoch": 3.8106353490407763,
      "grad_norm": 0.011811881326138973,
      "learning_rate": 1.189364650959224e-05,
      "loss": 0.0025,
      "step": 52240
    },
    {
      "epoch": 3.8113647968487854,
      "grad_norm": 0.05862632021307945,
      "learning_rate": 1.1886352031512147e-05,
      "loss": 0.0025,
      "step": 52250
    },
    {
      "epoch": 3.812094244656795,
      "grad_norm": 0.17055745422840118,
      "learning_rate": 1.1879057553432051e-05,
      "loss": 0.0022,
      "step": 52260
    },
    {
      "epoch": 3.812823692464804,
      "grad_norm": 0.172183096408844,
      "learning_rate": 1.1871763075351959e-05,
      "loss": 0.0038,
      "step": 52270
    },
    {
      "epoch": 3.8135531402728136,
      "grad_norm": 0.12448643893003464,
      "learning_rate": 1.1864468597271866e-05,
      "loss": 0.0034,
      "step": 52280
    },
    {
      "epoch": 3.8142825880808227,
      "grad_norm": 0.14488482475280762,
      "learning_rate": 1.1857174119191772e-05,
      "loss": 0.0039,
      "step": 52290
    },
    {
      "epoch": 3.815012035888832,
      "grad_norm": 0.07849044352769852,
      "learning_rate": 1.184987964111168e-05,
      "loss": 0.0033,
      "step": 52300
    },
    {
      "epoch": 3.8157414836968417,
      "grad_norm": 0.028008388355374336,
      "learning_rate": 1.1842585163031585e-05,
      "loss": 0.0029,
      "step": 52310
    },
    {
      "epoch": 3.816470931504851,
      "grad_norm": 0.4079103171825409,
      "learning_rate": 1.1835290684951491e-05,
      "loss": 0.0028,
      "step": 52320
    },
    {
      "epoch": 3.81720037931286,
      "grad_norm": 0.1779048591852188,
      "learning_rate": 1.1827996206871399e-05,
      "loss": 0.0023,
      "step": 52330
    },
    {
      "epoch": 3.8179298271208695,
      "grad_norm": 0.4506000280380249,
      "learning_rate": 1.1820701728791306e-05,
      "loss": 0.0047,
      "step": 52340
    },
    {
      "epoch": 3.818659274928879,
      "grad_norm": 0.28962215781211853,
      "learning_rate": 1.1813407250711212e-05,
      "loss": 0.0028,
      "step": 52350
    },
    {
      "epoch": 3.819388722736888,
      "grad_norm": 0.2888014614582062,
      "learning_rate": 1.1806112772631118e-05,
      "loss": 0.0022,
      "step": 52360
    },
    {
      "epoch": 3.8201181705448977,
      "grad_norm": 0.2601357400417328,
      "learning_rate": 1.1798818294551026e-05,
      "loss": 0.0023,
      "step": 52370
    },
    {
      "epoch": 3.8208476183529068,
      "grad_norm": 0.4329693615436554,
      "learning_rate": 1.1791523816470933e-05,
      "loss": 0.003,
      "step": 52380
    },
    {
      "epoch": 3.8215770661609163,
      "grad_norm": 0.11557252705097198,
      "learning_rate": 1.1784229338390839e-05,
      "loss": 0.0029,
      "step": 52390
    },
    {
      "epoch": 3.8223065139689254,
      "grad_norm": 0.17385929822921753,
      "learning_rate": 1.1776934860310745e-05,
      "loss": 0.0028,
      "step": 52400
    },
    {
      "epoch": 3.823035961776935,
      "grad_norm": 0.08681048452854156,
      "learning_rate": 1.1769640382230652e-05,
      "loss": 0.0022,
      "step": 52410
    },
    {
      "epoch": 3.823765409584944,
      "grad_norm": 0.2882719337940216,
      "learning_rate": 1.1762345904150558e-05,
      "loss": 0.0015,
      "step": 52420
    },
    {
      "epoch": 3.8244948573929536,
      "grad_norm": 0.3472438156604767,
      "learning_rate": 1.1755051426070466e-05,
      "loss": 0.003,
      "step": 52430
    },
    {
      "epoch": 3.8252243052009627,
      "grad_norm": 0.05834553390741348,
      "learning_rate": 1.1747756947990373e-05,
      "loss": 0.0037,
      "step": 52440
    },
    {
      "epoch": 3.8259537530089722,
      "grad_norm": 0.01671750284731388,
      "learning_rate": 1.1740462469910277e-05,
      "loss": 0.003,
      "step": 52450
    },
    {
      "epoch": 3.8266832008169818,
      "grad_norm": 0.09645593911409378,
      "learning_rate": 1.1733167991830185e-05,
      "loss": 0.0028,
      "step": 52460
    },
    {
      "epoch": 3.827412648624991,
      "grad_norm": 0.29000040888786316,
      "learning_rate": 1.1725873513750092e-05,
      "loss": 0.003,
      "step": 52470
    },
    {
      "epoch": 3.828142096433,
      "grad_norm": 0.7196242213249207,
      "learning_rate": 1.1718579035669998e-05,
      "loss": 0.0031,
      "step": 52480
    },
    {
      "epoch": 3.8288715442410095,
      "grad_norm": 0.08646278083324432,
      "learning_rate": 1.1711284557589906e-05,
      "loss": 0.0033,
      "step": 52490
    },
    {
      "epoch": 3.829600992049019,
      "grad_norm": 0.08673104643821716,
      "learning_rate": 1.1703990079509812e-05,
      "loss": 0.0043,
      "step": 52500
    },
    {
      "epoch": 3.830330439857028,
      "grad_norm": 0.20550400018692017,
      "learning_rate": 1.1696695601429717e-05,
      "loss": 0.0035,
      "step": 52510
    },
    {
      "epoch": 3.8310598876650377,
      "grad_norm": 0.14395977556705475,
      "learning_rate": 1.1689401123349625e-05,
      "loss": 0.0016,
      "step": 52520
    },
    {
      "epoch": 3.831789335473047,
      "grad_norm": 0.029709458351135254,
      "learning_rate": 1.1682106645269532e-05,
      "loss": 0.0032,
      "step": 52530
    },
    {
      "epoch": 3.8325187832810563,
      "grad_norm": 0.2889719605445862,
      "learning_rate": 1.1674812167189438e-05,
      "loss": 0.0039,
      "step": 52540
    },
    {
      "epoch": 3.8332482310890654,
      "grad_norm": 0.23035955429077148,
      "learning_rate": 1.1667517689109344e-05,
      "loss": 0.0024,
      "step": 52550
    },
    {
      "epoch": 3.833977678897075,
      "grad_norm": 0.0587242916226387,
      "learning_rate": 1.1660223211029252e-05,
      "loss": 0.0031,
      "step": 52560
    },
    {
      "epoch": 3.8347071267050845,
      "grad_norm": 0.2821747362613678,
      "learning_rate": 1.1652928732949157e-05,
      "loss": 0.0023,
      "step": 52570
    },
    {
      "epoch": 3.8354365745130936,
      "grad_norm": 0.20154164731502533,
      "learning_rate": 1.1645634254869065e-05,
      "loss": 0.0039,
      "step": 52580
    },
    {
      "epoch": 3.8361660223211027,
      "grad_norm": 0.14480097591876984,
      "learning_rate": 1.1638339776788971e-05,
      "loss": 0.0024,
      "step": 52590
    },
    {
      "epoch": 3.8368954701291123,
      "grad_norm": 0.3701538145542145,
      "learning_rate": 1.1631045298708878e-05,
      "loss": 0.0037,
      "step": 52600
    },
    {
      "epoch": 3.837624917937122,
      "grad_norm": 0.057222459465265274,
      "learning_rate": 1.1623750820628784e-05,
      "loss": 0.0027,
      "step": 52610
    },
    {
      "epoch": 3.838354365745131,
      "grad_norm": 0.029027948155999184,
      "learning_rate": 1.1616456342548692e-05,
      "loss": 0.0025,
      "step": 52620
    },
    {
      "epoch": 3.8390838135531404,
      "grad_norm": 0.33024710416793823,
      "learning_rate": 1.16091618644686e-05,
      "loss": 0.0027,
      "step": 52630
    },
    {
      "epoch": 3.8398132613611495,
      "grad_norm": 0.1168268546462059,
      "learning_rate": 1.1601867386388503e-05,
      "loss": 0.0032,
      "step": 52640
    },
    {
      "epoch": 3.840542709169159,
      "grad_norm": 0.06480436772108078,
      "learning_rate": 1.1594572908308411e-05,
      "loss": 0.0036,
      "step": 52650
    },
    {
      "epoch": 3.841272156977168,
      "grad_norm": 0.08897843956947327,
      "learning_rate": 1.1587278430228318e-05,
      "loss": 0.0031,
      "step": 52660
    },
    {
      "epoch": 3.8420016047851777,
      "grad_norm": 0.03720191866159439,
      "learning_rate": 1.1579983952148224e-05,
      "loss": 0.0027,
      "step": 52670
    },
    {
      "epoch": 3.842731052593187,
      "grad_norm": 0.17232942581176758,
      "learning_rate": 1.1572689474068132e-05,
      "loss": 0.0031,
      "step": 52680
    },
    {
      "epoch": 3.8434605004011964,
      "grad_norm": 0.23672796785831451,
      "learning_rate": 1.1565394995988038e-05,
      "loss": 0.0026,
      "step": 52690
    },
    {
      "epoch": 3.8441899482092055,
      "grad_norm": 0.23309029638767242,
      "learning_rate": 1.1558100517907944e-05,
      "loss": 0.0039,
      "step": 52700
    },
    {
      "epoch": 3.844919396017215,
      "grad_norm": 0.4883504807949066,
      "learning_rate": 1.1550806039827851e-05,
      "loss": 0.003,
      "step": 52710
    },
    {
      "epoch": 3.8456488438252245,
      "grad_norm": 0.058530181646347046,
      "learning_rate": 1.1543511561747759e-05,
      "loss": 0.0031,
      "step": 52720
    },
    {
      "epoch": 3.8463782916332336,
      "grad_norm": 0.061220940202474594,
      "learning_rate": 1.1536217083667664e-05,
      "loss": 0.0032,
      "step": 52730
    },
    {
      "epoch": 3.8471077394412427,
      "grad_norm": 0.14374612271785736,
      "learning_rate": 1.152892260558757e-05,
      "loss": 0.0028,
      "step": 52740
    },
    {
      "epoch": 3.8478371872492523,
      "grad_norm": 0.030165553092956543,
      "learning_rate": 1.1521628127507478e-05,
      "loss": 0.0025,
      "step": 52750
    },
    {
      "epoch": 3.848566635057262,
      "grad_norm": 0.43321266770362854,
      "learning_rate": 1.1514333649427384e-05,
      "loss": 0.0036,
      "step": 52760
    },
    {
      "epoch": 3.849296082865271,
      "grad_norm": 0.026777761057019234,
      "learning_rate": 1.1507039171347291e-05,
      "loss": 0.0039,
      "step": 52770
    },
    {
      "epoch": 3.8500255306732805,
      "grad_norm": 0.03497779369354248,
      "learning_rate": 1.1499744693267197e-05,
      "loss": 0.002,
      "step": 52780
    },
    {
      "epoch": 3.8507549784812896,
      "grad_norm": 0.05839928984642029,
      "learning_rate": 1.1492450215187103e-05,
      "loss": 0.0023,
      "step": 52790
    },
    {
      "epoch": 3.851484426289299,
      "grad_norm": 0.6342860460281372,
      "learning_rate": 1.148515573710701e-05,
      "loss": 0.0022,
      "step": 52800
    },
    {
      "epoch": 3.852213874097308,
      "grad_norm": 0.12122360616922379,
      "learning_rate": 1.1477861259026918e-05,
      "loss": 0.003,
      "step": 52810
    },
    {
      "epoch": 3.8529433219053177,
      "grad_norm": 0.23057636618614197,
      "learning_rate": 1.1470566780946824e-05,
      "loss": 0.0032,
      "step": 52820
    },
    {
      "epoch": 3.8536727697133273,
      "grad_norm": 0.031141992658376694,
      "learning_rate": 1.146327230286673e-05,
      "loss": 0.0029,
      "step": 52830
    },
    {
      "epoch": 3.8544022175213364,
      "grad_norm": 0.0926847755908966,
      "learning_rate": 1.1455977824786637e-05,
      "loss": 0.0037,
      "step": 52840
    },
    {
      "epoch": 3.8551316653293455,
      "grad_norm": 0.30419522523880005,
      "learning_rate": 1.1448683346706545e-05,
      "loss": 0.0035,
      "step": 52850
    },
    {
      "epoch": 3.855861113137355,
      "grad_norm": 0.1443895846605301,
      "learning_rate": 1.144138886862645e-05,
      "loss": 0.0018,
      "step": 52860
    },
    {
      "epoch": 3.8565905609453646,
      "grad_norm": 0.28832876682281494,
      "learning_rate": 1.1434094390546356e-05,
      "loss": 0.0027,
      "step": 52870
    },
    {
      "epoch": 3.8573200087533737,
      "grad_norm": 0.23012396693229675,
      "learning_rate": 1.1426799912466264e-05,
      "loss": 0.0024,
      "step": 52880
    },
    {
      "epoch": 3.8580494565613828,
      "grad_norm": 0.316952645778656,
      "learning_rate": 1.141950543438617e-05,
      "loss": 0.0035,
      "step": 52890
    },
    {
      "epoch": 3.8587789043693923,
      "grad_norm": 0.15081830322742462,
      "learning_rate": 1.1412210956306077e-05,
      "loss": 0.0018,
      "step": 52900
    },
    {
      "epoch": 3.859508352177402,
      "grad_norm": 0.08708226680755615,
      "learning_rate": 1.1404916478225985e-05,
      "loss": 0.0026,
      "step": 52910
    },
    {
      "epoch": 3.860237799985411,
      "grad_norm": 0.03058825433254242,
      "learning_rate": 1.139762200014589e-05,
      "loss": 0.0028,
      "step": 52920
    },
    {
      "epoch": 3.8609672477934205,
      "grad_norm": 0.3173845708370209,
      "learning_rate": 1.1390327522065796e-05,
      "loss": 0.0028,
      "step": 52930
    },
    {
      "epoch": 3.8616966956014296,
      "grad_norm": 0.3448375463485718,
      "learning_rate": 1.1383033043985704e-05,
      "loss": 0.0034,
      "step": 52940
    },
    {
      "epoch": 3.862426143409439,
      "grad_norm": 0.34636983275413513,
      "learning_rate": 1.137573856590561e-05,
      "loss": 0.004,
      "step": 52950
    },
    {
      "epoch": 3.8631555912174482,
      "grad_norm": 0.40387704968452454,
      "learning_rate": 1.1368444087825517e-05,
      "loss": 0.0026,
      "step": 52960
    },
    {
      "epoch": 3.8638850390254578,
      "grad_norm": 0.2917691469192505,
      "learning_rate": 1.1361149609745423e-05,
      "loss": 0.0029,
      "step": 52970
    },
    {
      "epoch": 3.8646144868334673,
      "grad_norm": 0.22067229449748993,
      "learning_rate": 1.1353855131665329e-05,
      "loss": 0.0043,
      "step": 52980
    },
    {
      "epoch": 3.8653439346414764,
      "grad_norm": 0.23120306432247162,
      "learning_rate": 1.1346560653585236e-05,
      "loss": 0.0044,
      "step": 52990
    },
    {
      "epoch": 3.8660733824494855,
      "grad_norm": 0.05783648416399956,
      "learning_rate": 1.1339266175505144e-05,
      "loss": 0.0021,
      "step": 53000
    },
    {
      "epoch": 3.866802830257495,
      "grad_norm": 0.28106892108917236,
      "learning_rate": 1.133197169742505e-05,
      "loss": 0.0034,
      "step": 53010
    },
    {
      "epoch": 3.8675322780655046,
      "grad_norm": 0.37517762184143066,
      "learning_rate": 1.1324677219344956e-05,
      "loss": 0.0031,
      "step": 53020
    },
    {
      "epoch": 3.8682617258735137,
      "grad_norm": 0.22980713844299316,
      "learning_rate": 1.1317382741264863e-05,
      "loss": 0.0028,
      "step": 53030
    },
    {
      "epoch": 3.8689911736815232,
      "grad_norm": 0.12527009844779968,
      "learning_rate": 1.1310088263184769e-05,
      "loss": 0.0031,
      "step": 53040
    },
    {
      "epoch": 3.8697206214895323,
      "grad_norm": 0.11508350819349289,
      "learning_rate": 1.1302793785104677e-05,
      "loss": 0.0021,
      "step": 53050
    },
    {
      "epoch": 3.870450069297542,
      "grad_norm": 0.11487387120723724,
      "learning_rate": 1.1295499307024582e-05,
      "loss": 0.0037,
      "step": 53060
    },
    {
      "epoch": 3.871179517105551,
      "grad_norm": 0.2182881236076355,
      "learning_rate": 1.1288204828944488e-05,
      "loss": 0.0025,
      "step": 53070
    },
    {
      "epoch": 3.8719089649135605,
      "grad_norm": 0.12352271378040314,
      "learning_rate": 1.1280910350864396e-05,
      "loss": 0.0032,
      "step": 53080
    },
    {
      "epoch": 3.8726384127215696,
      "grad_norm": 0.2620920240879059,
      "learning_rate": 1.1273615872784303e-05,
      "loss": 0.0023,
      "step": 53090
    },
    {
      "epoch": 3.873367860529579,
      "grad_norm": 0.10438451915979385,
      "learning_rate": 1.126632139470421e-05,
      "loss": 0.0029,
      "step": 53100
    },
    {
      "epoch": 3.8740973083375883,
      "grad_norm": 0.12503623962402344,
      "learning_rate": 1.1259026916624115e-05,
      "loss": 0.0034,
      "step": 53110
    },
    {
      "epoch": 3.874826756145598,
      "grad_norm": 0.6867979764938354,
      "learning_rate": 1.1251732438544023e-05,
      "loss": 0.0031,
      "step": 53120
    },
    {
      "epoch": 3.8755562039536073,
      "grad_norm": 0.058869246393442154,
      "learning_rate": 1.124443796046393e-05,
      "loss": 0.004,
      "step": 53130
    },
    {
      "epoch": 3.8762856517616164,
      "grad_norm": 0.25978705286979675,
      "learning_rate": 1.1237143482383836e-05,
      "loss": 0.0026,
      "step": 53140
    },
    {
      "epoch": 3.8770150995696255,
      "grad_norm": 0.17303231358528137,
      "learning_rate": 1.1229849004303743e-05,
      "loss": 0.004,
      "step": 53150
    },
    {
      "epoch": 3.877744547377635,
      "grad_norm": 0.20083679258823395,
      "learning_rate": 1.122255452622365e-05,
      "loss": 0.0029,
      "step": 53160
    },
    {
      "epoch": 3.8784739951856446,
      "grad_norm": 0.35545429587364197,
      "learning_rate": 1.1215260048143555e-05,
      "loss": 0.002,
      "step": 53170
    },
    {
      "epoch": 3.8792034429936537,
      "grad_norm": 0.31332096457481384,
      "learning_rate": 1.1207965570063463e-05,
      "loss": 0.0029,
      "step": 53180
    },
    {
      "epoch": 3.8799328908016633,
      "grad_norm": 0.31101396679878235,
      "learning_rate": 1.120067109198337e-05,
      "loss": 0.0036,
      "step": 53190
    },
    {
      "epoch": 3.8806623386096724,
      "grad_norm": 0.03888394683599472,
      "learning_rate": 1.1193376613903276e-05,
      "loss": 0.0015,
      "step": 53200
    },
    {
      "epoch": 3.881391786417682,
      "grad_norm": 0.10872495919466019,
      "learning_rate": 1.1186082135823182e-05,
      "loss": 0.0032,
      "step": 53210
    },
    {
      "epoch": 3.882121234225691,
      "grad_norm": 0.2020133137702942,
      "learning_rate": 1.117878765774309e-05,
      "loss": 0.0028,
      "step": 53220
    },
    {
      "epoch": 3.8828506820337005,
      "grad_norm": 0.008958651684224606,
      "learning_rate": 1.1171493179662995e-05,
      "loss": 0.0023,
      "step": 53230
    },
    {
      "epoch": 3.88358012984171,
      "grad_norm": 0.04841044917702675,
      "learning_rate": 1.1164198701582903e-05,
      "loss": 0.0029,
      "step": 53240
    },
    {
      "epoch": 3.884309577649719,
      "grad_norm": 0.15583693981170654,
      "learning_rate": 1.1156904223502809e-05,
      "loss": 0.0039,
      "step": 53250
    },
    {
      "epoch": 3.8850390254577283,
      "grad_norm": 0.08077395707368851,
      "learning_rate": 1.1149609745422714e-05,
      "loss": 0.0033,
      "step": 53260
    },
    {
      "epoch": 3.885768473265738,
      "grad_norm": 0.17375048995018005,
      "learning_rate": 1.1142315267342622e-05,
      "loss": 0.0024,
      "step": 53270
    },
    {
      "epoch": 3.8864979210737474,
      "grad_norm": 0.25989675521850586,
      "learning_rate": 1.113502078926253e-05,
      "loss": 0.0034,
      "step": 53280
    },
    {
      "epoch": 3.8872273688817565,
      "grad_norm": 0.11535762995481491,
      "learning_rate": 1.1127726311182435e-05,
      "loss": 0.0027,
      "step": 53290
    },
    {
      "epoch": 3.887956816689766,
      "grad_norm": 0.28769123554229736,
      "learning_rate": 1.1120431833102341e-05,
      "loss": 0.0021,
      "step": 53300
    },
    {
      "epoch": 3.888686264497775,
      "grad_norm": 0.20088578760623932,
      "learning_rate": 1.1113137355022249e-05,
      "loss": 0.0035,
      "step": 53310
    },
    {
      "epoch": 3.8894157123057846,
      "grad_norm": 0.14415472745895386,
      "learning_rate": 1.1105842876942154e-05,
      "loss": 0.0024,
      "step": 53320
    },
    {
      "epoch": 3.8901451601137937,
      "grad_norm": 0.1730269491672516,
      "learning_rate": 1.1098548398862062e-05,
      "loss": 0.003,
      "step": 53330
    },
    {
      "epoch": 3.8908746079218033,
      "grad_norm": 0.17373964190483093,
      "learning_rate": 1.109125392078197e-05,
      "loss": 0.0041,
      "step": 53340
    },
    {
      "epoch": 3.8916040557298124,
      "grad_norm": 0.4856293201446533,
      "learning_rate": 1.1083959442701875e-05,
      "loss": 0.0033,
      "step": 53350
    },
    {
      "epoch": 3.892333503537822,
      "grad_norm": 0.11556331068277359,
      "learning_rate": 1.1076664964621781e-05,
      "loss": 0.0016,
      "step": 53360
    },
    {
      "epoch": 3.893062951345831,
      "grad_norm": 0.2271941900253296,
      "learning_rate": 1.1069370486541689e-05,
      "loss": 0.0034,
      "step": 53370
    },
    {
      "epoch": 3.8937923991538406,
      "grad_norm": 0.1150379478931427,
      "learning_rate": 1.1062076008461596e-05,
      "loss": 0.0042,
      "step": 53380
    },
    {
      "epoch": 3.89452184696185,
      "grad_norm": 0.15131668746471405,
      "learning_rate": 1.1054781530381502e-05,
      "loss": 0.0044,
      "step": 53390
    },
    {
      "epoch": 3.895251294769859,
      "grad_norm": 0.49293169379234314,
      "learning_rate": 1.1047487052301408e-05,
      "loss": 0.0026,
      "step": 53400
    },
    {
      "epoch": 3.8959807425778683,
      "grad_norm": 0.17245039343833923,
      "learning_rate": 1.1040192574221315e-05,
      "loss": 0.0021,
      "step": 53410
    },
    {
      "epoch": 3.896710190385878,
      "grad_norm": 0.1451694220304489,
      "learning_rate": 1.1032898096141221e-05,
      "loss": 0.0023,
      "step": 53420
    },
    {
      "epoch": 3.8974396381938874,
      "grad_norm": 0.31373652815818787,
      "learning_rate": 1.1025603618061129e-05,
      "loss": 0.0038,
      "step": 53430
    },
    {
      "epoch": 3.8981690860018965,
      "grad_norm": 0.05795138701796532,
      "learning_rate": 1.1018309139981035e-05,
      "loss": 0.0024,
      "step": 53440
    },
    {
      "epoch": 3.898898533809906,
      "grad_norm": 0.12395577132701874,
      "learning_rate": 1.101101466190094e-05,
      "loss": 0.0028,
      "step": 53450
    },
    {
      "epoch": 3.899627981617915,
      "grad_norm": 0.20614728331565857,
      "learning_rate": 1.1003720183820848e-05,
      "loss": 0.0027,
      "step": 53460
    },
    {
      "epoch": 3.9003574294259247,
      "grad_norm": 0.015103877522051334,
      "learning_rate": 1.0996425705740756e-05,
      "loss": 0.0038,
      "step": 53470
    },
    {
      "epoch": 3.9010868772339338,
      "grad_norm": 0.6180058717727661,
      "learning_rate": 1.0989131227660661e-05,
      "loss": 0.0028,
      "step": 53480
    },
    {
      "epoch": 3.9018163250419433,
      "grad_norm": 0.23042336106300354,
      "learning_rate": 1.0981836749580567e-05,
      "loss": 0.0035,
      "step": 53490
    },
    {
      "epoch": 3.902545772849953,
      "grad_norm": 0.16435378789901733,
      "learning_rate": 1.0974542271500475e-05,
      "loss": 0.0023,
      "step": 53500
    },
    {
      "epoch": 3.903275220657962,
      "grad_norm": 0.08862262964248657,
      "learning_rate": 1.096724779342038e-05,
      "loss": 0.0023,
      "step": 53510
    },
    {
      "epoch": 3.904004668465971,
      "grad_norm": 0.2020619958639145,
      "learning_rate": 1.0959953315340288e-05,
      "loss": 0.0027,
      "step": 53520
    },
    {
      "epoch": 3.9047341162739806,
      "grad_norm": 0.030625486746430397,
      "learning_rate": 1.0952658837260196e-05,
      "loss": 0.0032,
      "step": 53530
    },
    {
      "epoch": 3.90546356408199,
      "grad_norm": 0.6258082985877991,
      "learning_rate": 1.09453643591801e-05,
      "loss": 0.0024,
      "step": 53540
    },
    {
      "epoch": 3.9061930118899992,
      "grad_norm": 0.31964606046676636,
      "learning_rate": 1.0938069881100007e-05,
      "loss": 0.0046,
      "step": 53550
    },
    {
      "epoch": 3.9069224596980083,
      "grad_norm": 0.17310239374637604,
      "learning_rate": 1.0930775403019915e-05,
      "loss": 0.0024,
      "step": 53560
    },
    {
      "epoch": 3.907651907506018,
      "grad_norm": 0.08827506750822067,
      "learning_rate": 1.092348092493982e-05,
      "loss": 0.002,
      "step": 53570
    },
    {
      "epoch": 3.9083813553140274,
      "grad_norm": 0.008313200436532497,
      "learning_rate": 1.0916186446859728e-05,
      "loss": 0.0042,
      "step": 53580
    },
    {
      "epoch": 3.9091108031220365,
      "grad_norm": 0.144113227725029,
      "learning_rate": 1.0908891968779634e-05,
      "loss": 0.0022,
      "step": 53590
    },
    {
      "epoch": 3.909840250930046,
      "grad_norm": 0.02942521683871746,
      "learning_rate": 1.0901597490699542e-05,
      "loss": 0.0037,
      "step": 53600
    },
    {
      "epoch": 3.910569698738055,
      "grad_norm": 0.14019721746444702,
      "learning_rate": 1.0894303012619447e-05,
      "loss": 0.002,
      "step": 53610
    },
    {
      "epoch": 3.9112991465460647,
      "grad_norm": 0.1403236985206604,
      "learning_rate": 1.0887008534539355e-05,
      "loss": 0.0026,
      "step": 53620
    },
    {
      "epoch": 3.912028594354074,
      "grad_norm": 0.3538992404937744,
      "learning_rate": 1.087971405645926e-05,
      "loss": 0.0041,
      "step": 53630
    },
    {
      "epoch": 3.9127580421620833,
      "grad_norm": 0.2365971952676773,
      "learning_rate": 1.0872419578379167e-05,
      "loss": 0.0031,
      "step": 53640
    },
    {
      "epoch": 3.913487489970093,
      "grad_norm": 0.5287317633628845,
      "learning_rate": 1.0865125100299074e-05,
      "loss": 0.0033,
      "step": 53650
    },
    {
      "epoch": 3.914216937778102,
      "grad_norm": 0.2686346769332886,
      "learning_rate": 1.0857830622218982e-05,
      "loss": 0.0027,
      "step": 53660
    },
    {
      "epoch": 3.914946385586111,
      "grad_norm": 0.17586977779865265,
      "learning_rate": 1.0850536144138888e-05,
      "loss": 0.0027,
      "step": 53670
    },
    {
      "epoch": 3.9156758333941206,
      "grad_norm": 0.4089534282684326,
      "learning_rate": 1.0843241666058793e-05,
      "loss": 0.0031,
      "step": 53680
    },
    {
      "epoch": 3.91640528120213,
      "grad_norm": 0.2297404408454895,
      "learning_rate": 1.0835947187978701e-05,
      "loss": 0.0025,
      "step": 53690
    },
    {
      "epoch": 3.9171347290101393,
      "grad_norm": 0.23116683959960938,
      "learning_rate": 1.0828652709898607e-05,
      "loss": 0.0029,
      "step": 53700
    },
    {
      "epoch": 3.917864176818149,
      "grad_norm": 0.17313773930072784,
      "learning_rate": 1.0821358231818514e-05,
      "loss": 0.0026,
      "step": 53710
    },
    {
      "epoch": 3.918593624626158,
      "grad_norm": 0.10458225756883621,
      "learning_rate": 1.0814063753738422e-05,
      "loss": 0.0031,
      "step": 53720
    },
    {
      "epoch": 3.9193230724341674,
      "grad_norm": 0.11579367518424988,
      "learning_rate": 1.0806769275658326e-05,
      "loss": 0.0038,
      "step": 53730
    },
    {
      "epoch": 3.9200525202421765,
      "grad_norm": 0.036031611263751984,
      "learning_rate": 1.0799474797578233e-05,
      "loss": 0.0034,
      "step": 53740
    },
    {
      "epoch": 3.920781968050186,
      "grad_norm": 0.23185686767101288,
      "learning_rate": 1.0792180319498141e-05,
      "loss": 0.0034,
      "step": 53750
    },
    {
      "epoch": 3.921511415858195,
      "grad_norm": 0.008054560981690884,
      "learning_rate": 1.0784885841418047e-05,
      "loss": 0.0032,
      "step": 53760
    },
    {
      "epoch": 3.9222408636662047,
      "grad_norm": 0.030606437474489212,
      "learning_rate": 1.0777591363337954e-05,
      "loss": 0.0033,
      "step": 53770
    },
    {
      "epoch": 3.922970311474214,
      "grad_norm": 0.49008575081825256,
      "learning_rate": 1.077029688525786e-05,
      "loss": 0.0033,
      "step": 53780
    },
    {
      "epoch": 3.9236997592822234,
      "grad_norm": 0.36877909302711487,
      "learning_rate": 1.0763002407177766e-05,
      "loss": 0.0031,
      "step": 53790
    },
    {
      "epoch": 3.924429207090233,
      "grad_norm": 0.4044046700000763,
      "learning_rate": 1.0755707929097674e-05,
      "loss": 0.0025,
      "step": 53800
    },
    {
      "epoch": 3.925158654898242,
      "grad_norm": 0.23099784553050995,
      "learning_rate": 1.0748413451017581e-05,
      "loss": 0.0031,
      "step": 53810
    },
    {
      "epoch": 3.925888102706251,
      "grad_norm": 0.20542378723621368,
      "learning_rate": 1.0741118972937487e-05,
      "loss": 0.0036,
      "step": 53820
    },
    {
      "epoch": 3.9266175505142606,
      "grad_norm": 0.5471606254577637,
      "learning_rate": 1.0733824494857393e-05,
      "loss": 0.0031,
      "step": 53830
    },
    {
      "epoch": 3.92734699832227,
      "grad_norm": 0.3471772074699402,
      "learning_rate": 1.07265300167773e-05,
      "loss": 0.0035,
      "step": 53840
    },
    {
      "epoch": 3.9280764461302793,
      "grad_norm": 0.08809375762939453,
      "learning_rate": 1.0719235538697208e-05,
      "loss": 0.0026,
      "step": 53850
    },
    {
      "epoch": 3.928805893938289,
      "grad_norm": 0.42162296175956726,
      "learning_rate": 1.0711941060617114e-05,
      "loss": 0.003,
      "step": 53860
    },
    {
      "epoch": 3.929535341746298,
      "grad_norm": 0.41608819365501404,
      "learning_rate": 1.070464658253702e-05,
      "loss": 0.0026,
      "step": 53870
    },
    {
      "epoch": 3.9302647895543075,
      "grad_norm": 0.1162341833114624,
      "learning_rate": 1.0697352104456927e-05,
      "loss": 0.003,
      "step": 53880
    },
    {
      "epoch": 3.9309942373623166,
      "grad_norm": 0.058791883289813995,
      "learning_rate": 1.0690057626376833e-05,
      "loss": 0.0034,
      "step": 53890
    },
    {
      "epoch": 3.931723685170326,
      "grad_norm": 0.14537079632282257,
      "learning_rate": 1.068276314829674e-05,
      "loss": 0.0031,
      "step": 53900
    },
    {
      "epoch": 3.9324531329783357,
      "grad_norm": 0.015543133020401001,
      "learning_rate": 1.0675468670216646e-05,
      "loss": 0.0023,
      "step": 53910
    },
    {
      "epoch": 3.9331825807863448,
      "grad_norm": 0.09517145156860352,
      "learning_rate": 1.0668174192136552e-05,
      "loss": 0.0035,
      "step": 53920
    },
    {
      "epoch": 3.933912028594354,
      "grad_norm": 0.1779780089855194,
      "learning_rate": 1.066087971405646e-05,
      "loss": 0.0039,
      "step": 53930
    },
    {
      "epoch": 3.9346414764023634,
      "grad_norm": 0.3642221689224243,
      "learning_rate": 1.0653585235976367e-05,
      "loss": 0.0022,
      "step": 53940
    },
    {
      "epoch": 3.935370924210373,
      "grad_norm": 0.5286253094673157,
      "learning_rate": 1.0646290757896273e-05,
      "loss": 0.0029,
      "step": 53950
    },
    {
      "epoch": 3.936100372018382,
      "grad_norm": 0.5662404298782349,
      "learning_rate": 1.063899627981618e-05,
      "loss": 0.0027,
      "step": 53960
    },
    {
      "epoch": 3.9368298198263916,
      "grad_norm": 0.3748440742492676,
      "learning_rate": 1.0631701801736086e-05,
      "loss": 0.0038,
      "step": 53970
    },
    {
      "epoch": 3.9375592676344007,
      "grad_norm": 0.14438731968402863,
      "learning_rate": 1.0624407323655992e-05,
      "loss": 0.0025,
      "step": 53980
    },
    {
      "epoch": 3.93828871544241,
      "grad_norm": 0.0226365365087986,
      "learning_rate": 1.06171128455759e-05,
      "loss": 0.0019,
      "step": 53990
    },
    {
      "epoch": 3.9390181632504193,
      "grad_norm": 0.06402893364429474,
      "learning_rate": 1.0609818367495807e-05,
      "loss": 0.0038,
      "step": 54000
    },
    {
      "epoch": 3.939747611058429,
      "grad_norm": 0.25912779569625854,
      "learning_rate": 1.0602523889415713e-05,
      "loss": 0.0032,
      "step": 54010
    },
    {
      "epoch": 3.940477058866438,
      "grad_norm": 0.11624481528997421,
      "learning_rate": 1.0595229411335619e-05,
      "loss": 0.003,
      "step": 54020
    },
    {
      "epoch": 3.9412065066744475,
      "grad_norm": 0.27090486884117126,
      "learning_rate": 1.0587934933255526e-05,
      "loss": 0.0021,
      "step": 54030
    },
    {
      "epoch": 3.9419359544824566,
      "grad_norm": 0.5996356010437012,
      "learning_rate": 1.0580640455175432e-05,
      "loss": 0.0032,
      "step": 54040
    },
    {
      "epoch": 3.942665402290466,
      "grad_norm": 0.28851810097694397,
      "learning_rate": 1.057334597709534e-05,
      "loss": 0.0037,
      "step": 54050
    },
    {
      "epoch": 3.9433948500984757,
      "grad_norm": 0.03940539434552193,
      "learning_rate": 1.0566051499015246e-05,
      "loss": 0.0041,
      "step": 54060
    },
    {
      "epoch": 3.9441242979064848,
      "grad_norm": 0.14441069960594177,
      "learning_rate": 1.0558757020935153e-05,
      "loss": 0.0034,
      "step": 54070
    },
    {
      "epoch": 3.944853745714494,
      "grad_norm": 0.4196541905403137,
      "learning_rate": 1.0551462542855059e-05,
      "loss": 0.0027,
      "step": 54080
    },
    {
      "epoch": 3.9455831935225034,
      "grad_norm": 0.058286260813474655,
      "learning_rate": 1.0544168064774967e-05,
      "loss": 0.0031,
      "step": 54090
    },
    {
      "epoch": 3.946312641330513,
      "grad_norm": 0.14427797496318817,
      "learning_rate": 1.0536873586694872e-05,
      "loss": 0.0025,
      "step": 54100
    },
    {
      "epoch": 3.947042089138522,
      "grad_norm": 0.058194246143102646,
      "learning_rate": 1.0529579108614778e-05,
      "loss": 0.0026,
      "step": 54110
    },
    {
      "epoch": 3.9477715369465316,
      "grad_norm": 0.06451432406902313,
      "learning_rate": 1.0522284630534686e-05,
      "loss": 0.0029,
      "step": 54120
    },
    {
      "epoch": 3.9485009847545407,
      "grad_norm": 0.44021958112716675,
      "learning_rate": 1.0514990152454593e-05,
      "loss": 0.0032,
      "step": 54130
    },
    {
      "epoch": 3.9492304325625502,
      "grad_norm": 0.057399358600378036,
      "learning_rate": 1.0507695674374499e-05,
      "loss": 0.0036,
      "step": 54140
    },
    {
      "epoch": 3.9499598803705593,
      "grad_norm": 0.058642495423555374,
      "learning_rate": 1.0500401196294405e-05,
      "loss": 0.0023,
      "step": 54150
    },
    {
      "epoch": 3.950689328178569,
      "grad_norm": 0.5305324196815491,
      "learning_rate": 1.0493106718214312e-05,
      "loss": 0.0033,
      "step": 54160
    },
    {
      "epoch": 3.9514187759865784,
      "grad_norm": 0.172410249710083,
      "learning_rate": 1.0485812240134218e-05,
      "loss": 0.0035,
      "step": 54170
    },
    {
      "epoch": 3.9521482237945875,
      "grad_norm": 0.02996394969522953,
      "learning_rate": 1.0478517762054126e-05,
      "loss": 0.0031,
      "step": 54180
    },
    {
      "epoch": 3.9528776716025966,
      "grad_norm": 0.12471748888492584,
      "learning_rate": 1.0471223283974033e-05,
      "loss": 0.0029,
      "step": 54190
    },
    {
      "epoch": 3.953607119410606,
      "grad_norm": 0.059419963508844376,
      "learning_rate": 1.0463928805893937e-05,
      "loss": 0.003,
      "step": 54200
    },
    {
      "epoch": 3.9543365672186157,
      "grad_norm": 0.5156973004341125,
      "learning_rate": 1.0456634327813845e-05,
      "loss": 0.0026,
      "step": 54210
    },
    {
      "epoch": 3.955066015026625,
      "grad_norm": 0.17395052313804626,
      "learning_rate": 1.0449339849733753e-05,
      "loss": 0.0019,
      "step": 54220
    },
    {
      "epoch": 3.9557954628346343,
      "grad_norm": 0.23053325712680817,
      "learning_rate": 1.0442045371653658e-05,
      "loss": 0.0036,
      "step": 54230
    },
    {
      "epoch": 3.9565249106426434,
      "grad_norm": 0.11611518263816833,
      "learning_rate": 1.0434750893573566e-05,
      "loss": 0.0031,
      "step": 54240
    },
    {
      "epoch": 3.957254358450653,
      "grad_norm": 0.4042712450027466,
      "learning_rate": 1.0427456415493472e-05,
      "loss": 0.0015,
      "step": 54250
    },
    {
      "epoch": 3.957983806258662,
      "grad_norm": 0.16050808131694794,
      "learning_rate": 1.0420161937413378e-05,
      "loss": 0.0025,
      "step": 54260
    },
    {
      "epoch": 3.9587132540666716,
      "grad_norm": 0.431521475315094,
      "learning_rate": 1.0412867459333285e-05,
      "loss": 0.0036,
      "step": 54270
    },
    {
      "epoch": 3.9594427018746807,
      "grad_norm": 0.116208516061306,
      "learning_rate": 1.0405572981253193e-05,
      "loss": 0.0017,
      "step": 54280
    },
    {
      "epoch": 3.9601721496826903,
      "grad_norm": 0.34839439392089844,
      "learning_rate": 1.0398278503173098e-05,
      "loss": 0.0025,
      "step": 54290
    },
    {
      "epoch": 3.9609015974906994,
      "grad_norm": 0.1443721503019333,
      "learning_rate": 1.0390984025093004e-05,
      "loss": 0.0037,
      "step": 54300
    },
    {
      "epoch": 3.961631045298709,
      "grad_norm": 0.2598039209842682,
      "learning_rate": 1.0383689547012912e-05,
      "loss": 0.0034,
      "step": 54310
    },
    {
      "epoch": 3.9623604931067185,
      "grad_norm": 0.012576178647577763,
      "learning_rate": 1.037639506893282e-05,
      "loss": 0.0026,
      "step": 54320
    },
    {
      "epoch": 3.9630899409147275,
      "grad_norm": 0.18214812874794006,
      "learning_rate": 1.0369100590852725e-05,
      "loss": 0.0035,
      "step": 54330
    },
    {
      "epoch": 3.9638193887227366,
      "grad_norm": 0.2833908200263977,
      "learning_rate": 1.0361806112772631e-05,
      "loss": 0.0034,
      "step": 54340
    },
    {
      "epoch": 3.964548836530746,
      "grad_norm": 0.030829906463623047,
      "learning_rate": 1.0354511634692539e-05,
      "loss": 0.0024,
      "step": 54350
    },
    {
      "epoch": 3.9652782843387557,
      "grad_norm": 0.14403381943702698,
      "learning_rate": 1.0347217156612444e-05,
      "loss": 0.0021,
      "step": 54360
    },
    {
      "epoch": 3.966007732146765,
      "grad_norm": 0.28768855333328247,
      "learning_rate": 1.0339922678532352e-05,
      "loss": 0.0018,
      "step": 54370
    },
    {
      "epoch": 3.9667371799547744,
      "grad_norm": 0.05736716464161873,
      "learning_rate": 1.033262820045226e-05,
      "loss": 0.0031,
      "step": 54380
    },
    {
      "epoch": 3.9674666277627835,
      "grad_norm": 0.37417563796043396,
      "learning_rate": 1.0325333722372164e-05,
      "loss": 0.0024,
      "step": 54390
    },
    {
      "epoch": 3.968196075570793,
      "grad_norm": 0.3177315294742584,
      "learning_rate": 1.0318039244292071e-05,
      "loss": 0.0024,
      "step": 54400
    },
    {
      "epoch": 3.968925523378802,
      "grad_norm": 0.09943442791700363,
      "learning_rate": 1.0310744766211979e-05,
      "loss": 0.0031,
      "step": 54410
    },
    {
      "epoch": 3.9696549711868117,
      "grad_norm": 0.25945064425468445,
      "learning_rate": 1.0303450288131885e-05,
      "loss": 0.0023,
      "step": 54420
    },
    {
      "epoch": 3.970384418994821,
      "grad_norm": 0.14600695669651031,
      "learning_rate": 1.0296155810051792e-05,
      "loss": 0.0033,
      "step": 54430
    },
    {
      "epoch": 3.9711138668028303,
      "grad_norm": 0.2878303527832031,
      "learning_rate": 1.0288861331971698e-05,
      "loss": 0.0037,
      "step": 54440
    },
    {
      "epoch": 3.9718433146108394,
      "grad_norm": 0.14412632584571838,
      "learning_rate": 1.0281566853891604e-05,
      "loss": 0.0033,
      "step": 54450
    },
    {
      "epoch": 3.972572762418849,
      "grad_norm": 0.08746519684791565,
      "learning_rate": 1.0274272375811511e-05,
      "loss": 0.0021,
      "step": 54460
    },
    {
      "epoch": 3.9733022102268585,
      "grad_norm": 0.4709595739841461,
      "learning_rate": 1.0266977897731419e-05,
      "loss": 0.0036,
      "step": 54470
    },
    {
      "epoch": 3.9740316580348676,
      "grad_norm": 0.030903352424502373,
      "learning_rate": 1.0259683419651325e-05,
      "loss": 0.0028,
      "step": 54480
    },
    {
      "epoch": 3.9747611058428767,
      "grad_norm": 0.20230641961097717,
      "learning_rate": 1.025238894157123e-05,
      "loss": 0.0033,
      "step": 54490
    },
    {
      "epoch": 3.975490553650886,
      "grad_norm": 0.009206071496009827,
      "learning_rate": 1.0245094463491138e-05,
      "loss": 0.0027,
      "step": 54500
    },
    {
      "epoch": 3.9762200014588958,
      "grad_norm": 0.3893791437149048,
      "learning_rate": 1.0237799985411044e-05,
      "loss": 0.0035,
      "step": 54510
    },
    {
      "epoch": 3.976949449266905,
      "grad_norm": 0.2331489771604538,
      "learning_rate": 1.0230505507330951e-05,
      "loss": 0.0036,
      "step": 54520
    },
    {
      "epoch": 3.9776788970749144,
      "grad_norm": 0.03149169683456421,
      "learning_rate": 1.0223211029250857e-05,
      "loss": 0.0025,
      "step": 54530
    },
    {
      "epoch": 3.9784083448829235,
      "grad_norm": 0.2671554386615753,
      "learning_rate": 1.0215916551170763e-05,
      "loss": 0.0033,
      "step": 54540
    },
    {
      "epoch": 3.979137792690933,
      "grad_norm": 0.059042178094387054,
      "learning_rate": 1.020862207309067e-05,
      "loss": 0.0026,
      "step": 54550
    },
    {
      "epoch": 3.979867240498942,
      "grad_norm": 0.37479522824287415,
      "learning_rate": 1.0201327595010578e-05,
      "loss": 0.002,
      "step": 54560
    },
    {
      "epoch": 3.9805966883069517,
      "grad_norm": 0.17238351702690125,
      "learning_rate": 1.0194033116930486e-05,
      "loss": 0.0021,
      "step": 54570
    },
    {
      "epoch": 3.9813261361149612,
      "grad_norm": 0.08736003935337067,
      "learning_rate": 1.018673863885039e-05,
      "loss": 0.0034,
      "step": 54580
    },
    {
      "epoch": 3.9820555839229703,
      "grad_norm": 0.34549927711486816,
      "learning_rate": 1.0179444160770297e-05,
      "loss": 0.0019,
      "step": 54590
    },
    {
      "epoch": 3.9827850317309794,
      "grad_norm": 0.08689834177494049,
      "learning_rate": 1.0172149682690205e-05,
      "loss": 0.0027,
      "step": 54600
    },
    {
      "epoch": 3.983514479538989,
      "grad_norm": 0.08559031784534454,
      "learning_rate": 1.016485520461011e-05,
      "loss": 0.0049,
      "step": 54610
    },
    {
      "epoch": 3.9842439273469985,
      "grad_norm": 0.05935749411582947,
      "learning_rate": 1.0157560726530018e-05,
      "loss": 0.0041,
      "step": 54620
    },
    {
      "epoch": 3.9849733751550076,
      "grad_norm": 0.2611396014690399,
      "learning_rate": 1.0150266248449924e-05,
      "loss": 0.0032,
      "step": 54630
    },
    {
      "epoch": 3.985702822963017,
      "grad_norm": 0.16041310131549835,
      "learning_rate": 1.014297177036983e-05,
      "loss": 0.0022,
      "step": 54640
    },
    {
      "epoch": 3.9864322707710262,
      "grad_norm": 0.2896059453487396,
      "learning_rate": 1.0135677292289737e-05,
      "loss": 0.0027,
      "step": 54650
    },
    {
      "epoch": 3.987161718579036,
      "grad_norm": 0.05957651138305664,
      "learning_rate": 1.0128382814209645e-05,
      "loss": 0.0031,
      "step": 54660
    },
    {
      "epoch": 3.987891166387045,
      "grad_norm": 0.21029867231845856,
      "learning_rate": 1.012108833612955e-05,
      "loss": 0.0028,
      "step": 54670
    },
    {
      "epoch": 3.9886206141950544,
      "grad_norm": 0.11481432616710663,
      "learning_rate": 1.0113793858049457e-05,
      "loss": 0.0037,
      "step": 54680
    },
    {
      "epoch": 3.9893500620030635,
      "grad_norm": 0.2644074261188507,
      "learning_rate": 1.0106499379969364e-05,
      "loss": 0.003,
      "step": 54690
    },
    {
      "epoch": 3.990079509811073,
      "grad_norm": 0.23134680092334747,
      "learning_rate": 1.009920490188927e-05,
      "loss": 0.0021,
      "step": 54700
    },
    {
      "epoch": 3.990808957619082,
      "grad_norm": 0.008163423277437687,
      "learning_rate": 1.0091910423809177e-05,
      "loss": 0.0039,
      "step": 54710
    },
    {
      "epoch": 3.9915384054270917,
      "grad_norm": 0.0348556712269783,
      "learning_rate": 1.0084615945729083e-05,
      "loss": 0.0034,
      "step": 54720
    },
    {
      "epoch": 3.9922678532351012,
      "grad_norm": 0.08791706711053848,
      "learning_rate": 1.0077321467648989e-05,
      "loss": 0.0023,
      "step": 54730
    },
    {
      "epoch": 3.9929973010431103,
      "grad_norm": 0.03200637176632881,
      "learning_rate": 1.0070026989568897e-05,
      "loss": 0.003,
      "step": 54740
    },
    {
      "epoch": 3.9937267488511194,
      "grad_norm": 0.17332229018211365,
      "learning_rate": 1.0062732511488804e-05,
      "loss": 0.0025,
      "step": 54750
    },
    {
      "epoch": 3.994456196659129,
      "grad_norm": 0.6806979179382324,
      "learning_rate": 1.005543803340871e-05,
      "loss": 0.0031,
      "step": 54760
    },
    {
      "epoch": 3.9951856444671385,
      "grad_norm": 0.2896176874637604,
      "learning_rate": 1.0048143555328616e-05,
      "loss": 0.0034,
      "step": 54770
    },
    {
      "epoch": 3.9959150922751476,
      "grad_norm": 0.20238648355007172,
      "learning_rate": 1.0040849077248523e-05,
      "loss": 0.0034,
      "step": 54780
    },
    {
      "epoch": 3.996644540083157,
      "grad_norm": 0.47395700216293335,
      "learning_rate": 1.003355459916843e-05,
      "loss": 0.0031,
      "step": 54790
    },
    {
      "epoch": 3.9973739878911663,
      "grad_norm": 0.05883612856268883,
      "learning_rate": 1.0026260121088337e-05,
      "loss": 0.0027,
      "step": 54800
    },
    {
      "epoch": 3.998103435699176,
      "grad_norm": 0.19701798260211945,
      "learning_rate": 1.0018965643008244e-05,
      "loss": 0.0032,
      "step": 54810
    },
    {
      "epoch": 3.998832883507185,
      "grad_norm": 0.029724420979619026,
      "learning_rate": 1.001167116492815e-05,
      "loss": 0.0019,
      "step": 54820
    },
    {
      "epoch": 3.9995623313151945,
      "grad_norm": 0.08939934521913528,
      "learning_rate": 1.0004376686848056e-05,
      "loss": 0.0023,
      "step": 54830
    },
    {
      "epoch": 4.0,
      "eval_loss": 0.003013582667335868,
      "eval_runtime": 121.4366,
      "eval_samples_per_second": 1151.02,
      "eval_steps_per_second": 28.78,
      "step": 54836
    },
    {
      "epoch": 4.000291779123204,
      "grad_norm": 0.2022276371717453,
      "learning_rate": 9.997082208767963e-06,
      "loss": 0.0042,
      "step": 54840
    },
    {
      "epoch": 4.001021226931213,
      "grad_norm": 0.4341629147529602,
      "learning_rate": 9.989787730687871e-06,
      "loss": 0.0032,
      "step": 54850
    },
    {
      "epoch": 4.001750674739222,
      "grad_norm": 0.5241408348083496,
      "learning_rate": 9.982493252607777e-06,
      "loss": 0.003,
      "step": 54860
    },
    {
      "epoch": 4.002480122547232,
      "grad_norm": 0.10354064404964447,
      "learning_rate": 9.975198774527683e-06,
      "loss": 0.0026,
      "step": 54870
    },
    {
      "epoch": 4.003209570355241,
      "grad_norm": 0.12383738160133362,
      "learning_rate": 9.96790429644759e-06,
      "loss": 0.0026,
      "step": 54880
    },
    {
      "epoch": 4.00393901816325,
      "grad_norm": 0.01428354810923338,
      "learning_rate": 9.960609818367496e-06,
      "loss": 0.0034,
      "step": 54890
    },
    {
      "epoch": 4.0046684659712595,
      "grad_norm": 0.0585518479347229,
      "learning_rate": 9.953315340287404e-06,
      "loss": 0.0016,
      "step": 54900
    },
    {
      "epoch": 4.0053979137792695,
      "grad_norm": 0.17776042222976685,
      "learning_rate": 9.94602086220731e-06,
      "loss": 0.0033,
      "step": 54910
    },
    {
      "epoch": 4.006127361587279,
      "grad_norm": 0.20251552760601044,
      "learning_rate": 9.938726384127215e-06,
      "loss": 0.0041,
      "step": 54920
    },
    {
      "epoch": 4.006856809395288,
      "grad_norm": 0.1729293167591095,
      "learning_rate": 9.931431906047123e-06,
      "loss": 0.0023,
      "step": 54930
    },
    {
      "epoch": 4.007586257203297,
      "grad_norm": 0.1885940432548523,
      "learning_rate": 9.92413742796703e-06,
      "loss": 0.0032,
      "step": 54940
    },
    {
      "epoch": 4.008315705011307,
      "grad_norm": 0.03049452044069767,
      "learning_rate": 9.916842949886936e-06,
      "loss": 0.0035,
      "step": 54950
    },
    {
      "epoch": 4.009045152819316,
      "grad_norm": 0.3040764331817627,
      "learning_rate": 9.909548471806842e-06,
      "loss": 0.003,
      "step": 54960
    },
    {
      "epoch": 4.009774600627325,
      "grad_norm": 0.1743478775024414,
      "learning_rate": 9.90225399372675e-06,
      "loss": 0.0022,
      "step": 54970
    },
    {
      "epoch": 4.010504048435334,
      "grad_norm": 0.4132836163043976,
      "learning_rate": 9.894959515646655e-06,
      "loss": 0.0036,
      "step": 54980
    },
    {
      "epoch": 4.011233496243344,
      "grad_norm": 0.12665437161922455,
      "learning_rate": 9.887665037566563e-06,
      "loss": 0.003,
      "step": 54990
    },
    {
      "epoch": 4.011962944051353,
      "grad_norm": 0.06178665533661842,
      "learning_rate": 9.880370559486469e-06,
      "loss": 0.004,
      "step": 55000
    },
    {
      "epoch": 4.012692391859362,
      "grad_norm": 0.20263996720314026,
      "learning_rate": 9.873076081406375e-06,
      "loss": 0.003,
      "step": 55010
    },
    {
      "epoch": 4.013421839667372,
      "grad_norm": 0.05721854791045189,
      "learning_rate": 9.865781603326282e-06,
      "loss": 0.0031,
      "step": 55020
    },
    {
      "epoch": 4.014151287475381,
      "grad_norm": 0.2070610076189041,
      "learning_rate": 9.85848712524619e-06,
      "loss": 0.0019,
      "step": 55030
    },
    {
      "epoch": 4.01488073528339,
      "grad_norm": 0.16492144763469696,
      "learning_rate": 9.851192647166095e-06,
      "loss": 0.0029,
      "step": 55040
    },
    {
      "epoch": 4.0156101830913995,
      "grad_norm": 0.008651516400277615,
      "learning_rate": 9.843898169086003e-06,
      "loss": 0.0029,
      "step": 55050
    },
    {
      "epoch": 4.0163396308994095,
      "grad_norm": 0.14440089464187622,
      "learning_rate": 9.836603691005909e-06,
      "loss": 0.0028,
      "step": 55060
    },
    {
      "epoch": 4.017069078707419,
      "grad_norm": 0.17276354134082794,
      "learning_rate": 9.829309212925816e-06,
      "loss": 0.002,
      "step": 55070
    },
    {
      "epoch": 4.017798526515428,
      "grad_norm": 0.28818875551223755,
      "learning_rate": 9.822014734845722e-06,
      "loss": 0.0038,
      "step": 55080
    },
    {
      "epoch": 4.018527974323437,
      "grad_norm": 0.0862518697977066,
      "learning_rate": 9.81472025676563e-06,
      "loss": 0.0036,
      "step": 55090
    },
    {
      "epoch": 4.019257422131447,
      "grad_norm": 0.0607263445854187,
      "learning_rate": 9.807425778685536e-06,
      "loss": 0.0023,
      "step": 55100
    },
    {
      "epoch": 4.019986869939456,
      "grad_norm": 0.08645176887512207,
      "learning_rate": 9.800131300605441e-06,
      "loss": 0.0031,
      "step": 55110
    },
    {
      "epoch": 4.020716317747465,
      "grad_norm": 0.07695932686328888,
      "learning_rate": 9.792836822525349e-06,
      "loss": 0.0033,
      "step": 55120
    },
    {
      "epoch": 4.021445765555475,
      "grad_norm": 0.011749647557735443,
      "learning_rate": 9.785542344445256e-06,
      "loss": 0.0031,
      "step": 55130
    },
    {
      "epoch": 4.022175213363484,
      "grad_norm": 0.1437278538942337,
      "learning_rate": 9.778247866365162e-06,
      "loss": 0.0026,
      "step": 55140
    },
    {
      "epoch": 4.022904661171493,
      "grad_norm": 0.08847509324550629,
      "learning_rate": 9.770953388285068e-06,
      "loss": 0.0019,
      "step": 55150
    },
    {
      "epoch": 4.023634108979502,
      "grad_norm": 0.17705118656158447,
      "learning_rate": 9.763658910204976e-06,
      "loss": 0.0031,
      "step": 55160
    },
    {
      "epoch": 4.024363556787512,
      "grad_norm": 0.08862177282571793,
      "learning_rate": 9.756364432124881e-06,
      "loss": 0.0037,
      "step": 55170
    },
    {
      "epoch": 4.025093004595521,
      "grad_norm": 0.034461311995983124,
      "learning_rate": 9.749069954044789e-06,
      "loss": 0.0037,
      "step": 55180
    },
    {
      "epoch": 4.02582245240353,
      "grad_norm": 0.029278665781021118,
      "learning_rate": 9.741775475964695e-06,
      "loss": 0.0023,
      "step": 55190
    },
    {
      "epoch": 4.0265519002115395,
      "grad_norm": 0.016339285299181938,
      "learning_rate": 9.7344809978846e-06,
      "loss": 0.002,
      "step": 55200
    },
    {
      "epoch": 4.0272813480195495,
      "grad_norm": 0.09691158682107925,
      "learning_rate": 9.727186519804508e-06,
      "loss": 0.0023,
      "step": 55210
    },
    {
      "epoch": 4.028010795827559,
      "grad_norm": 0.11617979407310486,
      "learning_rate": 9.719892041724416e-06,
      "loss": 0.0035,
      "step": 55220
    },
    {
      "epoch": 4.028740243635568,
      "grad_norm": 0.030658353120088577,
      "learning_rate": 9.712597563644322e-06,
      "loss": 0.0032,
      "step": 55230
    },
    {
      "epoch": 4.029469691443577,
      "grad_norm": 0.11486543715000153,
      "learning_rate": 9.705303085564227e-06,
      "loss": 0.0023,
      "step": 55240
    },
    {
      "epoch": 4.030199139251587,
      "grad_norm": 0.16568058729171753,
      "learning_rate": 9.698008607484135e-06,
      "loss": 0.0024,
      "step": 55250
    },
    {
      "epoch": 4.030928587059596,
      "grad_norm": 0.20149096846580505,
      "learning_rate": 9.69071412940404e-06,
      "loss": 0.0029,
      "step": 55260
    },
    {
      "epoch": 4.031658034867605,
      "grad_norm": 0.14947611093521118,
      "learning_rate": 9.683419651323948e-06,
      "loss": 0.0027,
      "step": 55270
    },
    {
      "epoch": 4.032387482675615,
      "grad_norm": 0.3963557779788971,
      "learning_rate": 9.676125173243856e-06,
      "loss": 0.0032,
      "step": 55280
    },
    {
      "epoch": 4.033116930483624,
      "grad_norm": 0.23036803305149078,
      "learning_rate": 9.66883069516376e-06,
      "loss": 0.0029,
      "step": 55290
    },
    {
      "epoch": 4.033846378291633,
      "grad_norm": 0.07963870465755463,
      "learning_rate": 9.661536217083668e-06,
      "loss": 0.0032,
      "step": 55300
    },
    {
      "epoch": 4.034575826099642,
      "grad_norm": 0.17615079879760742,
      "learning_rate": 9.654241739003575e-06,
      "loss": 0.0024,
      "step": 55310
    },
    {
      "epoch": 4.035305273907652,
      "grad_norm": 0.14512130618095398,
      "learning_rate": 9.646947260923483e-06,
      "loss": 0.0028,
      "step": 55320
    },
    {
      "epoch": 4.036034721715661,
      "grad_norm": 0.5405271053314209,
      "learning_rate": 9.639652782843388e-06,
      "loss": 0.0025,
      "step": 55330
    },
    {
      "epoch": 4.0367641695236705,
      "grad_norm": 0.2593582570552826,
      "learning_rate": 9.632358304763294e-06,
      "loss": 0.0022,
      "step": 55340
    },
    {
      "epoch": 4.0374936173316796,
      "grad_norm": 0.009368101134896278,
      "learning_rate": 9.625063826683202e-06,
      "loss": 0.0027,
      "step": 55350
    },
    {
      "epoch": 4.0382230651396895,
      "grad_norm": 0.12239042669534683,
      "learning_rate": 9.617769348603108e-06,
      "loss": 0.0033,
      "step": 55360
    },
    {
      "epoch": 4.038952512947699,
      "grad_norm": 0.13858406245708466,
      "learning_rate": 9.610474870523015e-06,
      "loss": 0.0024,
      "step": 55370
    },
    {
      "epoch": 4.039681960755708,
      "grad_norm": 0.37692826986312866,
      "learning_rate": 9.603180392442921e-06,
      "loss": 0.0026,
      "step": 55380
    },
    {
      "epoch": 4.040411408563717,
      "grad_norm": 0.2077379822731018,
      "learning_rate": 9.595885914362827e-06,
      "loss": 0.002,
      "step": 55390
    },
    {
      "epoch": 4.041140856371727,
      "grad_norm": 0.039683472365140915,
      "learning_rate": 9.588591436282734e-06,
      "loss": 0.002,
      "step": 55400
    },
    {
      "epoch": 4.041870304179736,
      "grad_norm": 0.1807437539100647,
      "learning_rate": 9.581296958202642e-06,
      "loss": 0.0031,
      "step": 55410
    },
    {
      "epoch": 4.042599751987745,
      "grad_norm": 0.014985191635787487,
      "learning_rate": 9.574002480122548e-06,
      "loss": 0.0028,
      "step": 55420
    },
    {
      "epoch": 4.043329199795755,
      "grad_norm": 0.26659831404685974,
      "learning_rate": 9.566708002042454e-06,
      "loss": 0.004,
      "step": 55430
    },
    {
      "epoch": 4.044058647603764,
      "grad_norm": 0.5663745999336243,
      "learning_rate": 9.559413523962361e-06,
      "loss": 0.0032,
      "step": 55440
    },
    {
      "epoch": 4.044788095411773,
      "grad_norm": 0.34524837136268616,
      "learning_rate": 9.552119045882267e-06,
      "loss": 0.003,
      "step": 55450
    },
    {
      "epoch": 4.045517543219782,
      "grad_norm": 0.24299956858158112,
      "learning_rate": 9.544824567802174e-06,
      "loss": 0.0044,
      "step": 55460
    },
    {
      "epoch": 4.046246991027792,
      "grad_norm": 0.3464924991130829,
      "learning_rate": 9.537530089722082e-06,
      "loss": 0.0029,
      "step": 55470
    },
    {
      "epoch": 4.046976438835801,
      "grad_norm": 0.23094908893108368,
      "learning_rate": 9.530235611641986e-06,
      "loss": 0.0042,
      "step": 55480
    },
    {
      "epoch": 4.0477058866438105,
      "grad_norm": 0.15183000266551971,
      "learning_rate": 9.522941133561894e-06,
      "loss": 0.0029,
      "step": 55490
    },
    {
      "epoch": 4.04843533445182,
      "grad_norm": 0.14382635056972504,
      "learning_rate": 9.515646655481801e-06,
      "loss": 0.0023,
      "step": 55500
    },
    {
      "epoch": 4.04916478225983,
      "grad_norm": 0.057817503809928894,
      "learning_rate": 9.508352177401707e-06,
      "loss": 0.0037,
      "step": 55510
    },
    {
      "epoch": 4.049894230067839,
      "grad_norm": 0.23005957901477814,
      "learning_rate": 9.501057699321615e-06,
      "loss": 0.0027,
      "step": 55520
    },
    {
      "epoch": 4.050623677875848,
      "grad_norm": 0.08808871358633041,
      "learning_rate": 9.49376322124152e-06,
      "loss": 0.0028,
      "step": 55530
    },
    {
      "epoch": 4.051353125683858,
      "grad_norm": 0.3166678249835968,
      "learning_rate": 9.486468743161426e-06,
      "loss": 0.0034,
      "step": 55540
    },
    {
      "epoch": 4.052082573491867,
      "grad_norm": 0.1644495278596878,
      "learning_rate": 9.479174265081334e-06,
      "loss": 0.0027,
      "step": 55550
    },
    {
      "epoch": 4.052812021299876,
      "grad_norm": 0.33398985862731934,
      "learning_rate": 9.471879787001241e-06,
      "loss": 0.0029,
      "step": 55560
    },
    {
      "epoch": 4.053541469107885,
      "grad_norm": 0.28912022709846497,
      "learning_rate": 9.464585308921147e-06,
      "loss": 0.0041,
      "step": 55570
    },
    {
      "epoch": 4.054270916915895,
      "grad_norm": 0.05996304750442505,
      "learning_rate": 9.457290830841053e-06,
      "loss": 0.0033,
      "step": 55580
    },
    {
      "epoch": 4.055000364723904,
      "grad_norm": 0.1717170625925064,
      "learning_rate": 9.44999635276096e-06,
      "loss": 0.0032,
      "step": 55590
    },
    {
      "epoch": 4.055729812531913,
      "grad_norm": 0.1730133444070816,
      "learning_rate": 9.442701874680868e-06,
      "loss": 0.0016,
      "step": 55600
    },
    {
      "epoch": 4.056459260339922,
      "grad_norm": 0.086611807346344,
      "learning_rate": 9.435407396600774e-06,
      "loss": 0.0023,
      "step": 55610
    },
    {
      "epoch": 4.057188708147932,
      "grad_norm": 0.3751082718372345,
      "learning_rate": 9.42811291852068e-06,
      "loss": 0.0045,
      "step": 55620
    },
    {
      "epoch": 4.057918155955941,
      "grad_norm": 0.08917591720819473,
      "learning_rate": 9.420818440440587e-06,
      "loss": 0.0025,
      "step": 55630
    },
    {
      "epoch": 4.0586476037639505,
      "grad_norm": 0.172908216714859,
      "learning_rate": 9.413523962360493e-06,
      "loss": 0.0034,
      "step": 55640
    },
    {
      "epoch": 4.05937705157196,
      "grad_norm": 0.07388950139284134,
      "learning_rate": 9.4062294842804e-06,
      "loss": 0.0016,
      "step": 55650
    },
    {
      "epoch": 4.06010649937997,
      "grad_norm": 0.03126257658004761,
      "learning_rate": 9.398935006200308e-06,
      "loss": 0.0032,
      "step": 55660
    },
    {
      "epoch": 4.060835947187979,
      "grad_norm": 0.2305612862110138,
      "learning_rate": 9.391640528120212e-06,
      "loss": 0.0028,
      "step": 55670
    },
    {
      "epoch": 4.061565394995988,
      "grad_norm": 0.23058028519153595,
      "learning_rate": 9.38434605004012e-06,
      "loss": 0.0031,
      "step": 55680
    },
    {
      "epoch": 4.062294842803998,
      "grad_norm": 0.5550901889801025,
      "learning_rate": 9.377051571960027e-06,
      "loss": 0.0022,
      "step": 55690
    },
    {
      "epoch": 4.063024290612007,
      "grad_norm": 0.40190738439559937,
      "learning_rate": 9.369757093879933e-06,
      "loss": 0.0031,
      "step": 55700
    },
    {
      "epoch": 4.063753738420016,
      "grad_norm": 0.030857965350151062,
      "learning_rate": 9.36246261579984e-06,
      "loss": 0.0023,
      "step": 55710
    },
    {
      "epoch": 4.064483186228025,
      "grad_norm": 0.058191388845443726,
      "learning_rate": 9.355168137719747e-06,
      "loss": 0.0034,
      "step": 55720
    },
    {
      "epoch": 4.065212634036035,
      "grad_norm": 0.05854365602135658,
      "learning_rate": 9.347873659639652e-06,
      "loss": 0.0025,
      "step": 55730
    },
    {
      "epoch": 4.065942081844044,
      "grad_norm": 0.36465752124786377,
      "learning_rate": 9.34057918155956e-06,
      "loss": 0.0029,
      "step": 55740
    },
    {
      "epoch": 4.066671529652053,
      "grad_norm": 0.2395491898059845,
      "learning_rate": 9.333284703479467e-06,
      "loss": 0.0029,
      "step": 55750
    },
    {
      "epoch": 4.067400977460062,
      "grad_norm": 0.24481628835201263,
      "learning_rate": 9.325990225399373e-06,
      "loss": 0.0026,
      "step": 55760
    },
    {
      "epoch": 4.068130425268072,
      "grad_norm": 0.03099861368536949,
      "learning_rate": 9.318695747319279e-06,
      "loss": 0.0031,
      "step": 55770
    },
    {
      "epoch": 4.068859873076081,
      "grad_norm": 0.07607723772525787,
      "learning_rate": 9.311401269239187e-06,
      "loss": 0.0043,
      "step": 55780
    },
    {
      "epoch": 4.0695893208840905,
      "grad_norm": 0.2661152780056,
      "learning_rate": 9.304106791159092e-06,
      "loss": 0.0013,
      "step": 55790
    },
    {
      "epoch": 4.0703187686921005,
      "grad_norm": 0.13136567175388336,
      "learning_rate": 9.296812313079e-06,
      "loss": 0.0024,
      "step": 55800
    },
    {
      "epoch": 4.07104821650011,
      "grad_norm": 0.17438474297523499,
      "learning_rate": 9.289517834998906e-06,
      "loss": 0.0023,
      "step": 55810
    },
    {
      "epoch": 4.071777664308119,
      "grad_norm": 0.37463313341140747,
      "learning_rate": 9.282223356918813e-06,
      "loss": 0.004,
      "step": 55820
    },
    {
      "epoch": 4.072507112116128,
      "grad_norm": 0.1462702453136444,
      "learning_rate": 9.27492887883872e-06,
      "loss": 0.0039,
      "step": 55830
    },
    {
      "epoch": 4.073236559924138,
      "grad_norm": 0.5484058856964111,
      "learning_rate": 9.267634400758627e-06,
      "loss": 0.0033,
      "step": 55840
    },
    {
      "epoch": 4.073966007732147,
      "grad_norm": 0.34919479489326477,
      "learning_rate": 9.260339922678534e-06,
      "loss": 0.0041,
      "step": 55850
    },
    {
      "epoch": 4.074695455540156,
      "grad_norm": 0.443385511636734,
      "learning_rate": 9.253045444598438e-06,
      "loss": 0.0035,
      "step": 55860
    },
    {
      "epoch": 4.075424903348165,
      "grad_norm": 0.34945663809776306,
      "learning_rate": 9.245750966518346e-06,
      "loss": 0.0047,
      "step": 55870
    },
    {
      "epoch": 4.076154351156175,
      "grad_norm": 0.011175306513905525,
      "learning_rate": 9.238456488438253e-06,
      "loss": 0.0031,
      "step": 55880
    },
    {
      "epoch": 4.076883798964184,
      "grad_norm": 0.05851685628294945,
      "learning_rate": 9.23116201035816e-06,
      "loss": 0.0032,
      "step": 55890
    },
    {
      "epoch": 4.077613246772193,
      "grad_norm": 0.20454351603984833,
      "learning_rate": 9.223867532278067e-06,
      "loss": 0.0037,
      "step": 55900
    },
    {
      "epoch": 4.078342694580202,
      "grad_norm": 0.14525474607944489,
      "learning_rate": 9.216573054197973e-06,
      "loss": 0.0027,
      "step": 55910
    },
    {
      "epoch": 4.079072142388212,
      "grad_norm": 0.14657631516456604,
      "learning_rate": 9.209278576117878e-06,
      "loss": 0.0033,
      "step": 55920
    },
    {
      "epoch": 4.0798015901962215,
      "grad_norm": 0.43907344341278076,
      "learning_rate": 9.201984098037786e-06,
      "loss": 0.0037,
      "step": 55930
    },
    {
      "epoch": 4.080531038004231,
      "grad_norm": 0.2313753068447113,
      "learning_rate": 9.194689619957694e-06,
      "loss": 0.0018,
      "step": 55940
    },
    {
      "epoch": 4.0812604858122405,
      "grad_norm": 0.2611898183822632,
      "learning_rate": 9.1873951418776e-06,
      "loss": 0.0035,
      "step": 55950
    },
    {
      "epoch": 4.08198993362025,
      "grad_norm": 0.31151512265205383,
      "learning_rate": 9.180100663797505e-06,
      "loss": 0.0034,
      "step": 55960
    },
    {
      "epoch": 4.082719381428259,
      "grad_norm": 0.060889068990945816,
      "learning_rate": 9.172806185717413e-06,
      "loss": 0.0035,
      "step": 55970
    },
    {
      "epoch": 4.083448829236268,
      "grad_norm": 0.11531427502632141,
      "learning_rate": 9.165511707637319e-06,
      "loss": 0.0026,
      "step": 55980
    },
    {
      "epoch": 4.084178277044278,
      "grad_norm": 0.3482748866081238,
      "learning_rate": 9.158217229557226e-06,
      "loss": 0.0044,
      "step": 55990
    },
    {
      "epoch": 4.084907724852287,
      "grad_norm": 0.144897922873497,
      "learning_rate": 9.150922751477132e-06,
      "loss": 0.003,
      "step": 56000
    },
    {
      "epoch": 4.085637172660296,
      "grad_norm": 0.2010495364665985,
      "learning_rate": 9.143628273397038e-06,
      "loss": 0.0036,
      "step": 56010
    },
    {
      "epoch": 4.086366620468305,
      "grad_norm": 0.05953441560268402,
      "learning_rate": 9.136333795316945e-06,
      "loss": 0.0029,
      "step": 56020
    },
    {
      "epoch": 4.087096068276315,
      "grad_norm": 0.2009611278772354,
      "learning_rate": 9.129039317236853e-06,
      "loss": 0.0033,
      "step": 56030
    },
    {
      "epoch": 4.087825516084324,
      "grad_norm": 0.20169232785701752,
      "learning_rate": 9.121744839156759e-06,
      "loss": 0.002,
      "step": 56040
    },
    {
      "epoch": 4.088554963892333,
      "grad_norm": 0.23084305226802826,
      "learning_rate": 9.114450361076665e-06,
      "loss": 0.0029,
      "step": 56050
    },
    {
      "epoch": 4.089284411700342,
      "grad_norm": 0.17326787114143372,
      "learning_rate": 9.107155882996572e-06,
      "loss": 0.0045,
      "step": 56060
    },
    {
      "epoch": 4.090013859508352,
      "grad_norm": 0.0874827429652214,
      "learning_rate": 9.09986140491648e-06,
      "loss": 0.0026,
      "step": 56070
    },
    {
      "epoch": 4.0907433073163615,
      "grad_norm": 0.5151600241661072,
      "learning_rate": 9.092566926836385e-06,
      "loss": 0.0024,
      "step": 56080
    },
    {
      "epoch": 4.091472755124371,
      "grad_norm": 0.36941906809806824,
      "learning_rate": 9.085272448756291e-06,
      "loss": 0.002,
      "step": 56090
    },
    {
      "epoch": 4.092202202932381,
      "grad_norm": 0.05888587236404419,
      "learning_rate": 9.077977970676199e-06,
      "loss": 0.0021,
      "step": 56100
    },
    {
      "epoch": 4.09293165074039,
      "grad_norm": 0.14492812752723694,
      "learning_rate": 9.070683492596105e-06,
      "loss": 0.0036,
      "step": 56110
    },
    {
      "epoch": 4.093661098548399,
      "grad_norm": 0.22996516525745392,
      "learning_rate": 9.063389014516012e-06,
      "loss": 0.0022,
      "step": 56120
    },
    {
      "epoch": 4.094390546356408,
      "grad_norm": 0.14559151232242584,
      "learning_rate": 9.05609453643592e-06,
      "loss": 0.0033,
      "step": 56130
    },
    {
      "epoch": 4.095119994164418,
      "grad_norm": 0.14607636630535126,
      "learning_rate": 9.048800058355825e-06,
      "loss": 0.003,
      "step": 56140
    },
    {
      "epoch": 4.095849441972427,
      "grad_norm": 0.05809897556900978,
      "learning_rate": 9.041505580275731e-06,
      "loss": 0.0024,
      "step": 56150
    },
    {
      "epoch": 4.096578889780436,
      "grad_norm": 0.08729252219200134,
      "learning_rate": 9.034211102195639e-06,
      "loss": 0.0024,
      "step": 56160
    },
    {
      "epoch": 4.097308337588445,
      "grad_norm": 0.11612244695425034,
      "learning_rate": 9.026916624115545e-06,
      "loss": 0.0037,
      "step": 56170
    },
    {
      "epoch": 4.098037785396455,
      "grad_norm": 0.3747634291648865,
      "learning_rate": 9.019622146035452e-06,
      "loss": 0.0022,
      "step": 56180
    },
    {
      "epoch": 4.098767233204464,
      "grad_norm": 0.009445038624107838,
      "learning_rate": 9.012327667955358e-06,
      "loss": 0.0043,
      "step": 56190
    },
    {
      "epoch": 4.099496681012473,
      "grad_norm": 0.1306476593017578,
      "learning_rate": 9.005033189875264e-06,
      "loss": 0.0025,
      "step": 56200
    },
    {
      "epoch": 4.100226128820483,
      "grad_norm": 0.44421619176864624,
      "learning_rate": 8.997738711795171e-06,
      "loss": 0.0025,
      "step": 56210
    },
    {
      "epoch": 4.100955576628492,
      "grad_norm": 0.030430234968662262,
      "learning_rate": 8.990444233715079e-06,
      "loss": 0.002,
      "step": 56220
    },
    {
      "epoch": 4.1016850244365015,
      "grad_norm": 0.40939846634864807,
      "learning_rate": 8.983149755634985e-06,
      "loss": 0.0027,
      "step": 56230
    },
    {
      "epoch": 4.102414472244511,
      "grad_norm": 0.2458253800868988,
      "learning_rate": 8.97585527755489e-06,
      "loss": 0.0031,
      "step": 56240
    },
    {
      "epoch": 4.103143920052521,
      "grad_norm": 0.2876032888889313,
      "learning_rate": 8.968560799474798e-06,
      "loss": 0.0029,
      "step": 56250
    },
    {
      "epoch": 4.10387336786053,
      "grad_norm": 0.34709277749061584,
      "learning_rate": 8.961266321394704e-06,
      "loss": 0.0032,
      "step": 56260
    },
    {
      "epoch": 4.104602815668539,
      "grad_norm": 0.40502965450286865,
      "learning_rate": 8.953971843314612e-06,
      "loss": 0.0025,
      "step": 56270
    },
    {
      "epoch": 4.105332263476548,
      "grad_norm": 0.06544195860624313,
      "learning_rate": 8.946677365234517e-06,
      "loss": 0.0023,
      "step": 56280
    },
    {
      "epoch": 4.106061711284558,
      "grad_norm": 0.25825777649879456,
      "learning_rate": 8.939382887154423e-06,
      "loss": 0.0029,
      "step": 56290
    },
    {
      "epoch": 4.106791159092567,
      "grad_norm": 0.4274396598339081,
      "learning_rate": 8.93208840907433e-06,
      "loss": 0.0031,
      "step": 56300
    },
    {
      "epoch": 4.107520606900576,
      "grad_norm": 0.014817164279520512,
      "learning_rate": 8.924793930994238e-06,
      "loss": 0.0038,
      "step": 56310
    },
    {
      "epoch": 4.108250054708585,
      "grad_norm": 0.2973007559776306,
      "learning_rate": 8.917499452914146e-06,
      "loss": 0.0043,
      "step": 56320
    },
    {
      "epoch": 4.108979502516595,
      "grad_norm": 0.3183368444442749,
      "learning_rate": 8.91020497483405e-06,
      "loss": 0.0028,
      "step": 56330
    },
    {
      "epoch": 4.109708950324604,
      "grad_norm": 0.14431172609329224,
      "learning_rate": 8.902910496753957e-06,
      "loss": 0.0038,
      "step": 56340
    },
    {
      "epoch": 4.110438398132613,
      "grad_norm": 0.1732623130083084,
      "learning_rate": 8.895616018673865e-06,
      "loss": 0.0023,
      "step": 56350
    },
    {
      "epoch": 4.111167845940623,
      "grad_norm": 0.17449721693992615,
      "learning_rate": 8.88832154059377e-06,
      "loss": 0.002,
      "step": 56360
    },
    {
      "epoch": 4.111897293748632,
      "grad_norm": 0.14400599896907806,
      "learning_rate": 8.881027062513678e-06,
      "loss": 0.0032,
      "step": 56370
    },
    {
      "epoch": 4.1126267415566415,
      "grad_norm": 0.371900737285614,
      "learning_rate": 8.873732584433584e-06,
      "loss": 0.0025,
      "step": 56380
    },
    {
      "epoch": 4.113356189364651,
      "grad_norm": 0.08711554110050201,
      "learning_rate": 8.86643810635349e-06,
      "loss": 0.0038,
      "step": 56390
    },
    {
      "epoch": 4.114085637172661,
      "grad_norm": 0.37599655985832214,
      "learning_rate": 8.859143628273398e-06,
      "loss": 0.0025,
      "step": 56400
    },
    {
      "epoch": 4.11481508498067,
      "grad_norm": 0.6373112201690674,
      "learning_rate": 8.851849150193305e-06,
      "loss": 0.0036,
      "step": 56410
    },
    {
      "epoch": 4.115544532788679,
      "grad_norm": 0.6020138263702393,
      "learning_rate": 8.844554672113211e-06,
      "loss": 0.0026,
      "step": 56420
    },
    {
      "epoch": 4.116273980596688,
      "grad_norm": 0.009559152647852898,
      "learning_rate": 8.837260194033117e-06,
      "loss": 0.0023,
      "step": 56430
    },
    {
      "epoch": 4.117003428404698,
      "grad_norm": 0.06004033237695694,
      "learning_rate": 8.829965715953024e-06,
      "loss": 0.0023,
      "step": 56440
    },
    {
      "epoch": 4.117732876212707,
      "grad_norm": 0.5412636995315552,
      "learning_rate": 8.82267123787293e-06,
      "loss": 0.0029,
      "step": 56450
    },
    {
      "epoch": 4.118462324020716,
      "grad_norm": 0.2870820462703705,
      "learning_rate": 8.815376759792838e-06,
      "loss": 0.0031,
      "step": 56460
    },
    {
      "epoch": 4.119191771828726,
      "grad_norm": 0.4052266776561737,
      "learning_rate": 8.808082281712743e-06,
      "loss": 0.0026,
      "step": 56470
    },
    {
      "epoch": 4.119921219636735,
      "grad_norm": 0.14393995702266693,
      "learning_rate": 8.80078780363265e-06,
      "loss": 0.0029,
      "step": 56480
    },
    {
      "epoch": 4.120650667444744,
      "grad_norm": 0.2642281949520111,
      "learning_rate": 8.793493325552557e-06,
      "loss": 0.003,
      "step": 56490
    },
    {
      "epoch": 4.121380115252753,
      "grad_norm": 0.40055111050605774,
      "learning_rate": 8.786198847472464e-06,
      "loss": 0.0029,
      "step": 56500
    },
    {
      "epoch": 4.122109563060763,
      "grad_norm": 0.2878507673740387,
      "learning_rate": 8.77890436939237e-06,
      "loss": 0.0031,
      "step": 56510
    },
    {
      "epoch": 4.1228390108687725,
      "grad_norm": 0.4006117880344391,
      "learning_rate": 8.771609891312276e-06,
      "loss": 0.002,
      "step": 56520
    },
    {
      "epoch": 4.123568458676782,
      "grad_norm": 0.27241548895835876,
      "learning_rate": 8.764315413232184e-06,
      "loss": 0.0028,
      "step": 56530
    },
    {
      "epoch": 4.124297906484791,
      "grad_norm": 0.16875983774662018,
      "learning_rate": 8.75702093515209e-06,
      "loss": 0.003,
      "step": 56540
    },
    {
      "epoch": 4.125027354292801,
      "grad_norm": 0.3175920844078064,
      "learning_rate": 8.749726457071997e-06,
      "loss": 0.0039,
      "step": 56550
    },
    {
      "epoch": 4.12575680210081,
      "grad_norm": 0.20299650728702545,
      "learning_rate": 8.742431978991904e-06,
      "loss": 0.0032,
      "step": 56560
    },
    {
      "epoch": 4.126486249908819,
      "grad_norm": 0.17303699254989624,
      "learning_rate": 8.73513750091181e-06,
      "loss": 0.0033,
      "step": 56570
    },
    {
      "epoch": 4.127215697716828,
      "grad_norm": 0.14534461498260498,
      "learning_rate": 8.727843022831716e-06,
      "loss": 0.0045,
      "step": 56580
    },
    {
      "epoch": 4.127945145524838,
      "grad_norm": 0.41148707270622253,
      "learning_rate": 8.720548544751624e-06,
      "loss": 0.0037,
      "step": 56590
    },
    {
      "epoch": 4.128674593332847,
      "grad_norm": 0.46154123544692993,
      "learning_rate": 8.713254066671531e-06,
      "loss": 0.0036,
      "step": 56600
    },
    {
      "epoch": 4.129404041140856,
      "grad_norm": 0.24402499198913574,
      "learning_rate": 8.705959588591437e-06,
      "loss": 0.0024,
      "step": 56610
    },
    {
      "epoch": 4.130133488948866,
      "grad_norm": 0.23289421200752258,
      "learning_rate": 8.698665110511343e-06,
      "loss": 0.0024,
      "step": 56620
    },
    {
      "epoch": 4.130862936756875,
      "grad_norm": 0.3448908030986786,
      "learning_rate": 8.69137063243125e-06,
      "loss": 0.003,
      "step": 56630
    },
    {
      "epoch": 4.131592384564884,
      "grad_norm": 0.28779730200767517,
      "learning_rate": 8.684076154351156e-06,
      "loss": 0.0025,
      "step": 56640
    },
    {
      "epoch": 4.132321832372893,
      "grad_norm": 0.11615946143865585,
      "learning_rate": 8.676781676271064e-06,
      "loss": 0.0029,
      "step": 56650
    },
    {
      "epoch": 4.133051280180903,
      "grad_norm": 0.3227686882019043,
      "learning_rate": 8.66948719819097e-06,
      "loss": 0.0028,
      "step": 56660
    },
    {
      "epoch": 4.1337807279889125,
      "grad_norm": 0.6020576357841492,
      "learning_rate": 8.662192720110875e-06,
      "loss": 0.0043,
      "step": 56670
    },
    {
      "epoch": 4.134510175796922,
      "grad_norm": 0.1438896358013153,
      "learning_rate": 8.654898242030783e-06,
      "loss": 0.0031,
      "step": 56680
    },
    {
      "epoch": 4.135239623604931,
      "grad_norm": 0.14431248605251312,
      "learning_rate": 8.64760376395069e-06,
      "loss": 0.0042,
      "step": 56690
    },
    {
      "epoch": 4.135969071412941,
      "grad_norm": 0.032219428569078445,
      "learning_rate": 8.640309285870596e-06,
      "loss": 0.0031,
      "step": 56700
    },
    {
      "epoch": 4.13669851922095,
      "grad_norm": 0.4050164222717285,
      "learning_rate": 8.633014807790502e-06,
      "loss": 0.0026,
      "step": 56710
    },
    {
      "epoch": 4.137427967028959,
      "grad_norm": 0.2769186794757843,
      "learning_rate": 8.62572032971041e-06,
      "loss": 0.0024,
      "step": 56720
    },
    {
      "epoch": 4.138157414836968,
      "grad_norm": 0.35020342469215393,
      "learning_rate": 8.618425851630316e-06,
      "loss": 0.0037,
      "step": 56730
    },
    {
      "epoch": 4.138886862644978,
      "grad_norm": 0.3631666302680969,
      "learning_rate": 8.611131373550223e-06,
      "loss": 0.0028,
      "step": 56740
    },
    {
      "epoch": 4.139616310452987,
      "grad_norm": 0.17120876908302307,
      "learning_rate": 8.60383689547013e-06,
      "loss": 0.003,
      "step": 56750
    },
    {
      "epoch": 4.140345758260996,
      "grad_norm": 0.144994854927063,
      "learning_rate": 8.596542417390035e-06,
      "loss": 0.0029,
      "step": 56760
    },
    {
      "epoch": 4.141075206069006,
      "grad_norm": 0.05961793661117554,
      "learning_rate": 8.589247939309942e-06,
      "loss": 0.0025,
      "step": 56770
    },
    {
      "epoch": 4.141804653877015,
      "grad_norm": 0.2305005043745041,
      "learning_rate": 8.58195346122985e-06,
      "loss": 0.0022,
      "step": 56780
    },
    {
      "epoch": 4.142534101685024,
      "grad_norm": 0.05875121429562569,
      "learning_rate": 8.574658983149756e-06,
      "loss": 0.0028,
      "step": 56790
    },
    {
      "epoch": 4.143263549493033,
      "grad_norm": 0.20239122211933136,
      "learning_rate": 8.567364505069663e-06,
      "loss": 0.004,
      "step": 56800
    },
    {
      "epoch": 4.143992997301043,
      "grad_norm": 0.05891384556889534,
      "learning_rate": 8.560070026989569e-06,
      "loss": 0.0039,
      "step": 56810
    },
    {
      "epoch": 4.1447224451090525,
      "grad_norm": 0.012974261306226254,
      "learning_rate": 8.552775548909477e-06,
      "loss": 0.0021,
      "step": 56820
    },
    {
      "epoch": 4.145451892917062,
      "grad_norm": 0.09824623167514801,
      "learning_rate": 8.545481070829382e-06,
      "loss": 0.0025,
      "step": 56830
    },
    {
      "epoch": 4.146181340725071,
      "grad_norm": 0.11875667423009872,
      "learning_rate": 8.53818659274929e-06,
      "loss": 0.0034,
      "step": 56840
    },
    {
      "epoch": 4.146910788533081,
      "grad_norm": 0.11552129685878754,
      "learning_rate": 8.530892114669196e-06,
      "loss": 0.0034,
      "step": 56850
    },
    {
      "epoch": 4.14764023634109,
      "grad_norm": 0.156662255525589,
      "learning_rate": 8.523597636589102e-06,
      "loss": 0.0031,
      "step": 56860
    },
    {
      "epoch": 4.148369684149099,
      "grad_norm": 0.2018372267484665,
      "learning_rate": 8.516303158509009e-06,
      "loss": 0.0024,
      "step": 56870
    },
    {
      "epoch": 4.149099131957109,
      "grad_norm": 0.29066580533981323,
      "learning_rate": 8.509008680428917e-06,
      "loss": 0.0036,
      "step": 56880
    },
    {
      "epoch": 4.149828579765118,
      "grad_norm": 0.057811301201581955,
      "learning_rate": 8.501714202348822e-06,
      "loss": 0.0034,
      "step": 56890
    },
    {
      "epoch": 4.150558027573127,
      "grad_norm": 0.11519291996955872,
      "learning_rate": 8.494419724268728e-06,
      "loss": 0.004,
      "step": 56900
    },
    {
      "epoch": 4.151287475381136,
      "grad_norm": 0.11599627882242203,
      "learning_rate": 8.487125246188636e-06,
      "loss": 0.003,
      "step": 56910
    },
    {
      "epoch": 4.152016923189146,
      "grad_norm": 0.012139653787016869,
      "learning_rate": 8.479830768108542e-06,
      "loss": 0.0033,
      "step": 56920
    },
    {
      "epoch": 4.152746370997155,
      "grad_norm": 0.5497626662254333,
      "learning_rate": 8.47253629002845e-06,
      "loss": 0.0031,
      "step": 56930
    },
    {
      "epoch": 4.153475818805164,
      "grad_norm": 0.17363415658473969,
      "learning_rate": 8.465241811948357e-06,
      "loss": 0.0038,
      "step": 56940
    },
    {
      "epoch": 4.1542052666131735,
      "grad_norm": 0.14434675872325897,
      "learning_rate": 8.457947333868261e-06,
      "loss": 0.0028,
      "step": 56950
    },
    {
      "epoch": 4.1549347144211835,
      "grad_norm": 0.059370383620262146,
      "learning_rate": 8.450652855788168e-06,
      "loss": 0.0041,
      "step": 56960
    },
    {
      "epoch": 4.1556641622291925,
      "grad_norm": 0.20946428179740906,
      "learning_rate": 8.443358377708076e-06,
      "loss": 0.0025,
      "step": 56970
    },
    {
      "epoch": 4.156393610037202,
      "grad_norm": 0.7189755439758301,
      "learning_rate": 8.436063899627982e-06,
      "loss": 0.0025,
      "step": 56980
    },
    {
      "epoch": 4.157123057845211,
      "grad_norm": 0.09138922393321991,
      "learning_rate": 8.42876942154789e-06,
      "loss": 0.0027,
      "step": 56990
    },
    {
      "epoch": 4.157852505653221,
      "grad_norm": 0.1159772202372551,
      "learning_rate": 8.421474943467795e-06,
      "loss": 0.0018,
      "step": 57000
    },
    {
      "epoch": 4.15858195346123,
      "grad_norm": 0.34574711322784424,
      "learning_rate": 8.414180465387701e-06,
      "loss": 0.0041,
      "step": 57010
    },
    {
      "epoch": 4.159311401269239,
      "grad_norm": 0.11708224564790726,
      "learning_rate": 8.406885987307609e-06,
      "loss": 0.0034,
      "step": 57020
    },
    {
      "epoch": 4.160040849077249,
      "grad_norm": 0.14547698199748993,
      "learning_rate": 8.399591509227516e-06,
      "loss": 0.0039,
      "step": 57030
    },
    {
      "epoch": 4.160770296885258,
      "grad_norm": 0.11605875939130783,
      "learning_rate": 8.392297031147422e-06,
      "loss": 0.0036,
      "step": 57040
    },
    {
      "epoch": 4.161499744693267,
      "grad_norm": 0.3547287583351135,
      "learning_rate": 8.385002553067328e-06,
      "loss": 0.0029,
      "step": 57050
    },
    {
      "epoch": 4.162229192501276,
      "grad_norm": 0.26361748576164246,
      "learning_rate": 8.377708074987235e-06,
      "loss": 0.0022,
      "step": 57060
    },
    {
      "epoch": 4.162958640309286,
      "grad_norm": 0.17207485437393188,
      "learning_rate": 8.370413596907143e-06,
      "loss": 0.0026,
      "step": 57070
    },
    {
      "epoch": 4.163688088117295,
      "grad_norm": 0.14478516578674316,
      "learning_rate": 8.363119118827049e-06,
      "loss": 0.0016,
      "step": 57080
    },
    {
      "epoch": 4.164417535925304,
      "grad_norm": 0.1442583054304123,
      "learning_rate": 8.355824640746954e-06,
      "loss": 0.0028,
      "step": 57090
    },
    {
      "epoch": 4.1651469837333135,
      "grad_norm": 0.05870145931839943,
      "learning_rate": 8.348530162666862e-06,
      "loss": 0.0029,
      "step": 57100
    },
    {
      "epoch": 4.1658764315413235,
      "grad_norm": 0.0415053591132164,
      "learning_rate": 8.341235684586768e-06,
      "loss": 0.0023,
      "step": 57110
    },
    {
      "epoch": 4.166605879349333,
      "grad_norm": 0.40691983699798584,
      "learning_rate": 8.333941206506675e-06,
      "loss": 0.003,
      "step": 57120
    },
    {
      "epoch": 4.167335327157342,
      "grad_norm": 0.11499953269958496,
      "learning_rate": 8.326646728426581e-06,
      "loss": 0.0029,
      "step": 57130
    },
    {
      "epoch": 4.168064774965352,
      "grad_norm": 0.11454745382070541,
      "learning_rate": 8.319352250346487e-06,
      "loss": 0.0038,
      "step": 57140
    },
    {
      "epoch": 4.168794222773361,
      "grad_norm": 0.01357998512685299,
      "learning_rate": 8.312057772266395e-06,
      "loss": 0.0029,
      "step": 57150
    },
    {
      "epoch": 4.16952367058137,
      "grad_norm": 0.20306715369224548,
      "learning_rate": 8.304763294186302e-06,
      "loss": 0.0023,
      "step": 57160
    },
    {
      "epoch": 4.170253118389379,
      "grad_norm": 0.08700039982795715,
      "learning_rate": 8.297468816106208e-06,
      "loss": 0.0034,
      "step": 57170
    },
    {
      "epoch": 4.170982566197389,
      "grad_norm": 0.08743730932474136,
      "learning_rate": 8.290174338026115e-06,
      "loss": 0.0023,
      "step": 57180
    },
    {
      "epoch": 4.171712014005398,
      "grad_norm": 0.17359063029289246,
      "learning_rate": 8.282879859946021e-06,
      "loss": 0.0037,
      "step": 57190
    },
    {
      "epoch": 4.172441461813407,
      "grad_norm": 0.17247240245342255,
      "learning_rate": 8.275585381865927e-06,
      "loss": 0.0034,
      "step": 57200
    },
    {
      "epoch": 4.173170909621416,
      "grad_norm": 0.6320165991783142,
      "learning_rate": 8.268290903785835e-06,
      "loss": 0.0032,
      "step": 57210
    },
    {
      "epoch": 4.173900357429426,
      "grad_norm": 0.4496201276779175,
      "learning_rate": 8.260996425705742e-06,
      "loss": 0.0029,
      "step": 57220
    },
    {
      "epoch": 4.174629805237435,
      "grad_norm": 0.4620037376880646,
      "learning_rate": 8.253701947625648e-06,
      "loss": 0.0025,
      "step": 57230
    },
    {
      "epoch": 4.175359253045444,
      "grad_norm": 0.05937774479389191,
      "learning_rate": 8.246407469545554e-06,
      "loss": 0.003,
      "step": 57240
    },
    {
      "epoch": 4.1760887008534535,
      "grad_norm": 0.032664187252521515,
      "learning_rate": 8.239112991465461e-06,
      "loss": 0.003,
      "step": 57250
    },
    {
      "epoch": 4.1768181486614635,
      "grad_norm": 0.2601687014102936,
      "learning_rate": 8.231818513385367e-06,
      "loss": 0.0017,
      "step": 57260
    },
    {
      "epoch": 4.177547596469473,
      "grad_norm": 0.058308426290750504,
      "learning_rate": 8.224524035305275e-06,
      "loss": 0.0027,
      "step": 57270
    },
    {
      "epoch": 4.178277044277482,
      "grad_norm": 0.3749268054962158,
      "learning_rate": 8.21722955722518e-06,
      "loss": 0.0029,
      "step": 57280
    },
    {
      "epoch": 4.179006492085492,
      "grad_norm": 0.4043336510658264,
      "learning_rate": 8.209935079145088e-06,
      "loss": 0.0033,
      "step": 57290
    },
    {
      "epoch": 4.179735939893501,
      "grad_norm": 0.2028016746044159,
      "learning_rate": 8.202640601064994e-06,
      "loss": 0.0024,
      "step": 57300
    },
    {
      "epoch": 4.18046538770151,
      "grad_norm": 0.26032042503356934,
      "learning_rate": 8.195346122984901e-06,
      "loss": 0.0026,
      "step": 57310
    },
    {
      "epoch": 4.181194835509519,
      "grad_norm": 0.18970175087451935,
      "learning_rate": 8.188051644904807e-06,
      "loss": 0.003,
      "step": 57320
    },
    {
      "epoch": 4.181924283317529,
      "grad_norm": 0.6047523021697998,
      "learning_rate": 8.180757166824713e-06,
      "loss": 0.0023,
      "step": 57330
    },
    {
      "epoch": 4.182653731125538,
      "grad_norm": 0.11569331586360931,
      "learning_rate": 8.17346268874462e-06,
      "loss": 0.002,
      "step": 57340
    },
    {
      "epoch": 4.183383178933547,
      "grad_norm": 0.11638345569372177,
      "learning_rate": 8.166168210664528e-06,
      "loss": 0.0034,
      "step": 57350
    },
    {
      "epoch": 4.184112626741556,
      "grad_norm": 0.14447307586669922,
      "learning_rate": 8.158873732584434e-06,
      "loss": 0.0027,
      "step": 57360
    },
    {
      "epoch": 4.184842074549566,
      "grad_norm": 0.029619744047522545,
      "learning_rate": 8.15157925450434e-06,
      "loss": 0.0033,
      "step": 57370
    },
    {
      "epoch": 4.185571522357575,
      "grad_norm": 0.26053154468536377,
      "learning_rate": 8.144284776424247e-06,
      "loss": 0.0017,
      "step": 57380
    },
    {
      "epoch": 4.1863009701655844,
      "grad_norm": 0.08775432407855988,
      "learning_rate": 8.136990298344153e-06,
      "loss": 0.0016,
      "step": 57390
    },
    {
      "epoch": 4.1870304179735935,
      "grad_norm": 0.23681825399398804,
      "learning_rate": 8.12969582026406e-06,
      "loss": 0.0031,
      "step": 57400
    },
    {
      "epoch": 4.1877598657816035,
      "grad_norm": 0.11511379480361938,
      "learning_rate": 8.122401342183968e-06,
      "loss": 0.0032,
      "step": 57410
    },
    {
      "epoch": 4.188489313589613,
      "grad_norm": 0.40256467461586,
      "learning_rate": 8.115106864103872e-06,
      "loss": 0.0041,
      "step": 57420
    },
    {
      "epoch": 4.189218761397622,
      "grad_norm": 0.06976902484893799,
      "learning_rate": 8.10781238602378e-06,
      "loss": 0.003,
      "step": 57430
    },
    {
      "epoch": 4.189948209205632,
      "grad_norm": 0.015590757131576538,
      "learning_rate": 8.100517907943687e-06,
      "loss": 0.0036,
      "step": 57440
    },
    {
      "epoch": 4.190677657013641,
      "grad_norm": 0.18631990253925323,
      "learning_rate": 8.093223429863593e-06,
      "loss": 0.003,
      "step": 57450
    },
    {
      "epoch": 4.19140710482165,
      "grad_norm": 0.20399396121501923,
      "learning_rate": 8.085928951783501e-06,
      "loss": 0.0028,
      "step": 57460
    },
    {
      "epoch": 4.192136552629659,
      "grad_norm": 0.3182131052017212,
      "learning_rate": 8.078634473703407e-06,
      "loss": 0.0037,
      "step": 57470
    },
    {
      "epoch": 4.192866000437669,
      "grad_norm": 0.1881696730852127,
      "learning_rate": 8.071339995623313e-06,
      "loss": 0.0032,
      "step": 57480
    },
    {
      "epoch": 4.193595448245678,
      "grad_norm": 0.1454550176858902,
      "learning_rate": 8.06404551754322e-06,
      "loss": 0.0025,
      "step": 57490
    },
    {
      "epoch": 4.194324896053687,
      "grad_norm": 0.11611969023942947,
      "learning_rate": 8.056751039463128e-06,
      "loss": 0.0029,
      "step": 57500
    },
    {
      "epoch": 4.195054343861696,
      "grad_norm": 0.059022318571805954,
      "learning_rate": 8.049456561383033e-06,
      "loss": 0.0042,
      "step": 57510
    },
    {
      "epoch": 4.195783791669706,
      "grad_norm": 0.2014492154121399,
      "learning_rate": 8.04216208330294e-06,
      "loss": 0.0018,
      "step": 57520
    },
    {
      "epoch": 4.196513239477715,
      "grad_norm": 0.1722908318042755,
      "learning_rate": 8.034867605222847e-06,
      "loss": 0.0027,
      "step": 57530
    },
    {
      "epoch": 4.1972426872857245,
      "grad_norm": 0.0877622440457344,
      "learning_rate": 8.027573127142754e-06,
      "loss": 0.0034,
      "step": 57540
    },
    {
      "epoch": 4.1979721350937345,
      "grad_norm": 0.1992713212966919,
      "learning_rate": 8.02027864906266e-06,
      "loss": 0.0028,
      "step": 57550
    },
    {
      "epoch": 4.198701582901744,
      "grad_norm": 0.3507419228553772,
      "learning_rate": 8.012984170982566e-06,
      "loss": 0.0014,
      "step": 57560
    },
    {
      "epoch": 4.199431030709753,
      "grad_norm": 0.18316903710365295,
      "learning_rate": 8.005689692902474e-06,
      "loss": 0.0023,
      "step": 57570
    },
    {
      "epoch": 4.200160478517762,
      "grad_norm": 0.4560726284980774,
      "learning_rate": 7.99839521482238e-06,
      "loss": 0.0032,
      "step": 57580
    },
    {
      "epoch": 4.200889926325772,
      "grad_norm": 0.18061165511608124,
      "learning_rate": 7.991100736742287e-06,
      "loss": 0.0039,
      "step": 57590
    },
    {
      "epoch": 4.201619374133781,
      "grad_norm": 0.2831539511680603,
      "learning_rate": 7.983806258662194e-06,
      "loss": 0.0037,
      "step": 57600
    },
    {
      "epoch": 4.20234882194179,
      "grad_norm": 0.1018386036157608,
      "learning_rate": 7.976511780582099e-06,
      "loss": 0.0029,
      "step": 57610
    },
    {
      "epoch": 4.203078269749799,
      "grad_norm": 0.22979725897312164,
      "learning_rate": 7.969217302502006e-06,
      "loss": 0.003,
      "step": 57620
    },
    {
      "epoch": 4.203807717557809,
      "grad_norm": 0.058684177696704865,
      "learning_rate": 7.961922824421914e-06,
      "loss": 0.0041,
      "step": 57630
    },
    {
      "epoch": 4.204537165365818,
      "grad_norm": 0.11826317757368088,
      "learning_rate": 7.95462834634182e-06,
      "loss": 0.0025,
      "step": 57640
    },
    {
      "epoch": 4.205266613173827,
      "grad_norm": 0.2761116325855255,
      "learning_rate": 7.947333868261727e-06,
      "loss": 0.0022,
      "step": 57650
    },
    {
      "epoch": 4.205996060981837,
      "grad_norm": 0.20268991589546204,
      "learning_rate": 7.940039390181633e-06,
      "loss": 0.0018,
      "step": 57660
    },
    {
      "epoch": 4.206725508789846,
      "grad_norm": 0.26308655738830566,
      "learning_rate": 7.932744912101539e-06,
      "loss": 0.0027,
      "step": 57670
    },
    {
      "epoch": 4.207454956597855,
      "grad_norm": 0.04235897958278656,
      "learning_rate": 7.925450434021446e-06,
      "loss": 0.0025,
      "step": 57680
    },
    {
      "epoch": 4.2081844044058645,
      "grad_norm": 0.11591960489749908,
      "learning_rate": 7.918155955941354e-06,
      "loss": 0.0038,
      "step": 57690
    },
    {
      "epoch": 4.2089138522138745,
      "grad_norm": 0.28892579674720764,
      "learning_rate": 7.91086147786126e-06,
      "loss": 0.0027,
      "step": 57700
    },
    {
      "epoch": 4.209643300021884,
      "grad_norm": 0.029183613136410713,
      "learning_rate": 7.903566999781165e-06,
      "loss": 0.0028,
      "step": 57710
    },
    {
      "epoch": 4.210372747829893,
      "grad_norm": 0.02992848865687847,
      "learning_rate": 7.896272521701073e-06,
      "loss": 0.0048,
      "step": 57720
    },
    {
      "epoch": 4.211102195637902,
      "grad_norm": 0.17097917199134827,
      "learning_rate": 7.888978043620979e-06,
      "loss": 0.0026,
      "step": 57730
    },
    {
      "epoch": 4.211831643445912,
      "grad_norm": 0.11648224294185638,
      "learning_rate": 7.881683565540886e-06,
      "loss": 0.0026,
      "step": 57740
    },
    {
      "epoch": 4.212561091253921,
      "grad_norm": 0.20698674023151398,
      "learning_rate": 7.874389087460792e-06,
      "loss": 0.0034,
      "step": 57750
    },
    {
      "epoch": 4.21329053906193,
      "grad_norm": 0.3724806010723114,
      "learning_rate": 7.867094609380698e-06,
      "loss": 0.004,
      "step": 57760
    },
    {
      "epoch": 4.214019986869939,
      "grad_norm": 0.3618522882461548,
      "learning_rate": 7.859800131300605e-06,
      "loss": 0.0026,
      "step": 57770
    },
    {
      "epoch": 4.214749434677949,
      "grad_norm": 0.43380609154701233,
      "learning_rate": 7.852505653220513e-06,
      "loss": 0.0038,
      "step": 57780
    },
    {
      "epoch": 4.215478882485958,
      "grad_norm": 0.03817356750369072,
      "learning_rate": 7.84521117514042e-06,
      "loss": 0.0033,
      "step": 57790
    },
    {
      "epoch": 4.216208330293967,
      "grad_norm": 0.14903385937213898,
      "learning_rate": 7.837916697060325e-06,
      "loss": 0.0029,
      "step": 57800
    },
    {
      "epoch": 4.216937778101977,
      "grad_norm": 0.5468435287475586,
      "learning_rate": 7.830622218980232e-06,
      "loss": 0.0026,
      "step": 57810
    },
    {
      "epoch": 4.217667225909986,
      "grad_norm": 0.17451521754264832,
      "learning_rate": 7.82332774090014e-06,
      "loss": 0.0024,
      "step": 57820
    },
    {
      "epoch": 4.218396673717995,
      "grad_norm": 0.20597843825817108,
      "learning_rate": 7.816033262820046e-06,
      "loss": 0.0025,
      "step": 57830
    },
    {
      "epoch": 4.2191261215260045,
      "grad_norm": 0.031307775527238846,
      "learning_rate": 7.808738784739953e-06,
      "loss": 0.0023,
      "step": 57840
    },
    {
      "epoch": 4.2198555693340145,
      "grad_norm": 0.11581412702798843,
      "learning_rate": 7.801444306659859e-06,
      "loss": 0.0024,
      "step": 57850
    },
    {
      "epoch": 4.220585017142024,
      "grad_norm": 0.3452245593070984,
      "learning_rate": 7.794149828579765e-06,
      "loss": 0.0029,
      "step": 57860
    },
    {
      "epoch": 4.221314464950033,
      "grad_norm": 0.2815372943878174,
      "learning_rate": 7.786855350499672e-06,
      "loss": 0.0033,
      "step": 57870
    },
    {
      "epoch": 4.222043912758042,
      "grad_norm": 0.030418403446674347,
      "learning_rate": 7.77956087241958e-06,
      "loss": 0.003,
      "step": 57880
    },
    {
      "epoch": 4.222773360566052,
      "grad_norm": 0.1757896989583969,
      "learning_rate": 7.772266394339486e-06,
      "loss": 0.0031,
      "step": 57890
    },
    {
      "epoch": 4.223502808374061,
      "grad_norm": 0.0543728731572628,
      "learning_rate": 7.764971916259392e-06,
      "loss": 0.0026,
      "step": 57900
    },
    {
      "epoch": 4.22423225618207,
      "grad_norm": 0.2591463029384613,
      "learning_rate": 7.757677438179299e-06,
      "loss": 0.0027,
      "step": 57910
    },
    {
      "epoch": 4.224961703990079,
      "grad_norm": 0.23717181384563446,
      "learning_rate": 7.750382960099205e-06,
      "loss": 0.0033,
      "step": 57920
    },
    {
      "epoch": 4.225691151798089,
      "grad_norm": 0.25931406021118164,
      "learning_rate": 7.743088482019112e-06,
      "loss": 0.0032,
      "step": 57930
    },
    {
      "epoch": 4.226420599606098,
      "grad_norm": 0.23090998828411102,
      "learning_rate": 7.735794003939018e-06,
      "loss": 0.0021,
      "step": 57940
    },
    {
      "epoch": 4.227150047414107,
      "grad_norm": 0.24314996600151062,
      "learning_rate": 7.728499525858924e-06,
      "loss": 0.0039,
      "step": 57950
    },
    {
      "epoch": 4.227879495222117,
      "grad_norm": 0.2609405219554901,
      "learning_rate": 7.721205047778832e-06,
      "loss": 0.0026,
      "step": 57960
    },
    {
      "epoch": 4.228608943030126,
      "grad_norm": 0.4896489083766937,
      "learning_rate": 7.713910569698739e-06,
      "loss": 0.0026,
      "step": 57970
    },
    {
      "epoch": 4.2293383908381355,
      "grad_norm": 0.2586435079574585,
      "learning_rate": 7.706616091618645e-06,
      "loss": 0.0055,
      "step": 57980
    },
    {
      "epoch": 4.2300678386461446,
      "grad_norm": 0.11222952604293823,
      "learning_rate": 7.69932161353855e-06,
      "loss": 0.0033,
      "step": 57990
    },
    {
      "epoch": 4.2307972864541545,
      "grad_norm": 0.11597053706645966,
      "learning_rate": 7.692027135458458e-06,
      "loss": 0.003,
      "step": 58000
    },
    {
      "epoch": 4.231526734262164,
      "grad_norm": 0.08595950901508331,
      "learning_rate": 7.684732657378364e-06,
      "loss": 0.003,
      "step": 58010
    },
    {
      "epoch": 4.232256182070173,
      "grad_norm": 0.5606991648674011,
      "learning_rate": 7.677438179298272e-06,
      "loss": 0.0033,
      "step": 58020
    },
    {
      "epoch": 4.232985629878182,
      "grad_norm": 0.11630818247795105,
      "learning_rate": 7.67014370121818e-06,
      "loss": 0.0037,
      "step": 58030
    },
    {
      "epoch": 4.233715077686192,
      "grad_norm": 0.02964681386947632,
      "learning_rate": 7.662849223138085e-06,
      "loss": 0.0041,
      "step": 58040
    },
    {
      "epoch": 4.234444525494201,
      "grad_norm": 0.4620809257030487,
      "learning_rate": 7.655554745057991e-06,
      "loss": 0.0025,
      "step": 58050
    },
    {
      "epoch": 4.23517397330221,
      "grad_norm": 0.41333967447280884,
      "learning_rate": 7.648260266977898e-06,
      "loss": 0.0035,
      "step": 58060
    },
    {
      "epoch": 4.235903421110219,
      "grad_norm": 0.19839635491371155,
      "learning_rate": 7.640965788897806e-06,
      "loss": 0.0029,
      "step": 58070
    },
    {
      "epoch": 4.236632868918229,
      "grad_norm": 0.20184846222400665,
      "learning_rate": 7.633671310817712e-06,
      "loss": 0.0035,
      "step": 58080
    },
    {
      "epoch": 4.237362316726238,
      "grad_norm": 0.14368364214897156,
      "learning_rate": 7.6263768327376185e-06,
      "loss": 0.003,
      "step": 58090
    },
    {
      "epoch": 4.238091764534247,
      "grad_norm": 0.0949549600481987,
      "learning_rate": 7.619082354657525e-06,
      "loss": 0.0024,
      "step": 58100
    },
    {
      "epoch": 4.238821212342257,
      "grad_norm": 0.11613203585147858,
      "learning_rate": 7.611787876577431e-06,
      "loss": 0.0032,
      "step": 58110
    },
    {
      "epoch": 4.239550660150266,
      "grad_norm": 0.05919788405299187,
      "learning_rate": 7.604493398497338e-06,
      "loss": 0.003,
      "step": 58120
    },
    {
      "epoch": 4.2402801079582755,
      "grad_norm": 0.463010311126709,
      "learning_rate": 7.597198920417245e-06,
      "loss": 0.003,
      "step": 58130
    },
    {
      "epoch": 4.241009555766285,
      "grad_norm": 0.11559193581342697,
      "learning_rate": 7.589904442337151e-06,
      "loss": 0.0029,
      "step": 58140
    },
    {
      "epoch": 4.241739003574295,
      "grad_norm": 0.05817754939198494,
      "learning_rate": 7.582609964257058e-06,
      "loss": 0.0041,
      "step": 58150
    },
    {
      "epoch": 4.242468451382304,
      "grad_norm": 0.4024377167224884,
      "learning_rate": 7.5753154861769644e-06,
      "loss": 0.0034,
      "step": 58160
    },
    {
      "epoch": 4.243197899190313,
      "grad_norm": 0.14420560002326965,
      "learning_rate": 7.56802100809687e-06,
      "loss": 0.0028,
      "step": 58170
    },
    {
      "epoch": 4.243927346998322,
      "grad_norm": 0.2377844750881195,
      "learning_rate": 7.560726530016778e-06,
      "loss": 0.0036,
      "step": 58180
    },
    {
      "epoch": 4.244656794806332,
      "grad_norm": 0.25939297676086426,
      "learning_rate": 7.5534320519366845e-06,
      "loss": 0.004,
      "step": 58190
    },
    {
      "epoch": 4.245386242614341,
      "grad_norm": 0.2014530897140503,
      "learning_rate": 7.54613757385659e-06,
      "loss": 0.0036,
      "step": 58200
    },
    {
      "epoch": 4.24611569042235,
      "grad_norm": 0.28847557306289673,
      "learning_rate": 7.538843095776498e-06,
      "loss": 0.0025,
      "step": 58210
    },
    {
      "epoch": 4.24684513823036,
      "grad_norm": 0.03268679976463318,
      "learning_rate": 7.5315486176964045e-06,
      "loss": 0.0021,
      "step": 58220
    },
    {
      "epoch": 4.247574586038369,
      "grad_norm": 0.33442774415016174,
      "learning_rate": 7.52425413961631e-06,
      "loss": 0.0035,
      "step": 58230
    },
    {
      "epoch": 4.248304033846378,
      "grad_norm": 0.3410550057888031,
      "learning_rate": 7.516959661536217e-06,
      "loss": 0.0029,
      "step": 58240
    },
    {
      "epoch": 4.249033481654387,
      "grad_norm": 0.01511083822697401,
      "learning_rate": 7.5096651834561246e-06,
      "loss": 0.0027,
      "step": 58250
    },
    {
      "epoch": 4.249762929462397,
      "grad_norm": 0.058197490870952606,
      "learning_rate": 7.50237070537603e-06,
      "loss": 0.0034,
      "step": 58260
    },
    {
      "epoch": 4.250492377270406,
      "grad_norm": 0.05856930464506149,
      "learning_rate": 7.495076227295937e-06,
      "loss": 0.0021,
      "step": 58270
    },
    {
      "epoch": 4.2512218250784155,
      "grad_norm": 0.5467879176139832,
      "learning_rate": 7.487781749215844e-06,
      "loss": 0.0025,
      "step": 58280
    },
    {
      "epoch": 4.251951272886425,
      "grad_norm": 0.3070272207260132,
      "learning_rate": 7.480487271135751e-06,
      "loss": 0.0039,
      "step": 58290
    },
    {
      "epoch": 4.252680720694435,
      "grad_norm": 0.0870646983385086,
      "learning_rate": 7.473192793055657e-06,
      "loss": 0.0029,
      "step": 58300
    },
    {
      "epoch": 4.253410168502444,
      "grad_norm": 0.058549974113702774,
      "learning_rate": 7.465898314975564e-06,
      "loss": 0.0035,
      "step": 58310
    },
    {
      "epoch": 4.254139616310453,
      "grad_norm": 0.20087282359600067,
      "learning_rate": 7.458603836895471e-06,
      "loss": 0.0027,
      "step": 58320
    },
    {
      "epoch": 4.254869064118463,
      "grad_norm": 0.030167313292622566,
      "learning_rate": 7.451309358815377e-06,
      "loss": 0.0024,
      "step": 58330
    },
    {
      "epoch": 4.255598511926472,
      "grad_norm": 0.47960180044174194,
      "learning_rate": 7.444014880735284e-06,
      "loss": 0.004,
      "step": 58340
    },
    {
      "epoch": 4.256327959734481,
      "grad_norm": 0.23028664290905,
      "learning_rate": 7.4367204026551906e-06,
      "loss": 0.0022,
      "step": 58350
    },
    {
      "epoch": 4.25705740754249,
      "grad_norm": 0.2378786951303482,
      "learning_rate": 7.429425924575096e-06,
      "loss": 0.0028,
      "step": 58360
    },
    {
      "epoch": 4.2577868553505,
      "grad_norm": 0.38741251826286316,
      "learning_rate": 7.422131446495004e-06,
      "loss": 0.0038,
      "step": 58370
    },
    {
      "epoch": 4.258516303158509,
      "grad_norm": 0.18469473719596863,
      "learning_rate": 7.414836968414911e-06,
      "loss": 0.0016,
      "step": 58380
    },
    {
      "epoch": 4.259245750966518,
      "grad_norm": 0.4101583659648895,
      "learning_rate": 7.4075424903348164e-06,
      "loss": 0.0022,
      "step": 58390
    },
    {
      "epoch": 4.259975198774527,
      "grad_norm": 0.15434633195400238,
      "learning_rate": 7.400248012254723e-06,
      "loss": 0.0025,
      "step": 58400
    },
    {
      "epoch": 4.260704646582537,
      "grad_norm": 0.17323902249336243,
      "learning_rate": 7.392953534174631e-06,
      "loss": 0.0013,
      "step": 58410
    },
    {
      "epoch": 4.261434094390546,
      "grad_norm": 0.03131881356239319,
      "learning_rate": 7.3856590560945365e-06,
      "loss": 0.0031,
      "step": 58420
    },
    {
      "epoch": 4.2621635421985555,
      "grad_norm": 0.08813982456922531,
      "learning_rate": 7.378364578014443e-06,
      "loss": 0.0031,
      "step": 58430
    },
    {
      "epoch": 4.262892990006565,
      "grad_norm": 0.1472177356481552,
      "learning_rate": 7.371070099934351e-06,
      "loss": 0.0027,
      "step": 58440
    },
    {
      "epoch": 4.263622437814575,
      "grad_norm": 0.1157977432012558,
      "learning_rate": 7.3637756218542565e-06,
      "loss": 0.0036,
      "step": 58450
    },
    {
      "epoch": 4.264351885622584,
      "grad_norm": 0.0606512650847435,
      "learning_rate": 7.356481143774163e-06,
      "loss": 0.0027,
      "step": 58460
    },
    {
      "epoch": 4.265081333430593,
      "grad_norm": 0.1158367246389389,
      "learning_rate": 7.34918666569407e-06,
      "loss": 0.0021,
      "step": 58470
    },
    {
      "epoch": 4.265810781238603,
      "grad_norm": 0.23113776743412018,
      "learning_rate": 7.341892187613976e-06,
      "loss": 0.0028,
      "step": 58480
    },
    {
      "epoch": 4.266540229046612,
      "grad_norm": 0.29030364751815796,
      "learning_rate": 7.334597709533883e-06,
      "loss": 0.0021,
      "step": 58490
    },
    {
      "epoch": 4.267269676854621,
      "grad_norm": 0.14484058320522308,
      "learning_rate": 7.32730323145379e-06,
      "loss": 0.0026,
      "step": 58500
    },
    {
      "epoch": 4.26799912466263,
      "grad_norm": 0.5105215311050415,
      "learning_rate": 7.320008753373696e-06,
      "loss": 0.0028,
      "step": 58510
    },
    {
      "epoch": 4.26872857247064,
      "grad_norm": 0.09238123148679733,
      "learning_rate": 7.3127142752936025e-06,
      "loss": 0.0028,
      "step": 58520
    },
    {
      "epoch": 4.269458020278649,
      "grad_norm": 0.032232873141765594,
      "learning_rate": 7.30541979721351e-06,
      "loss": 0.0028,
      "step": 58530
    },
    {
      "epoch": 4.270187468086658,
      "grad_norm": 0.058213625103235245,
      "learning_rate": 7.298125319133417e-06,
      "loss": 0.0023,
      "step": 58540
    },
    {
      "epoch": 4.270916915894667,
      "grad_norm": 0.2008293867111206,
      "learning_rate": 7.2908308410533225e-06,
      "loss": 0.0037,
      "step": 58550
    },
    {
      "epoch": 4.271646363702677,
      "grad_norm": 0.2933334410190582,
      "learning_rate": 7.28353636297323e-06,
      "loss": 0.0026,
      "step": 58560
    },
    {
      "epoch": 4.2723758115106865,
      "grad_norm": 0.010208085179328918,
      "learning_rate": 7.276241884893137e-06,
      "loss": 0.0023,
      "step": 58570
    },
    {
      "epoch": 4.273105259318696,
      "grad_norm": 0.20753039419651031,
      "learning_rate": 7.2689474068130426e-06,
      "loss": 0.0024,
      "step": 58580
    },
    {
      "epoch": 4.273834707126705,
      "grad_norm": 0.24142290651798248,
      "learning_rate": 7.261652928732949e-06,
      "loss": 0.0028,
      "step": 58590
    },
    {
      "epoch": 4.274564154934715,
      "grad_norm": 0.029909329488873482,
      "learning_rate": 7.254358450652857e-06,
      "loss": 0.0022,
      "step": 58600
    },
    {
      "epoch": 4.275293602742724,
      "grad_norm": 0.31858745217323303,
      "learning_rate": 7.247063972572763e-06,
      "loss": 0.002,
      "step": 58610
    },
    {
      "epoch": 4.276023050550733,
      "grad_norm": 0.4038362205028534,
      "learning_rate": 7.239769494492669e-06,
      "loss": 0.0031,
      "step": 58620
    },
    {
      "epoch": 4.276752498358743,
      "grad_norm": 0.11351801455020905,
      "learning_rate": 7.232475016412577e-06,
      "loss": 0.0033,
      "step": 58630
    },
    {
      "epoch": 4.277481946166752,
      "grad_norm": 0.11660896241664886,
      "learning_rate": 7.225180538332482e-06,
      "loss": 0.0024,
      "step": 58640
    },
    {
      "epoch": 4.278211393974761,
      "grad_norm": 0.05045638233423233,
      "learning_rate": 7.217886060252389e-06,
      "loss": 0.0029,
      "step": 58650
    },
    {
      "epoch": 4.27894084178277,
      "grad_norm": 0.1734081506729126,
      "learning_rate": 7.210591582172296e-06,
      "loss": 0.0033,
      "step": 58660
    },
    {
      "epoch": 4.27967028959078,
      "grad_norm": 0.11669305711984634,
      "learning_rate": 7.203297104092202e-06,
      "loss": 0.0034,
      "step": 58670
    },
    {
      "epoch": 4.280399737398789,
      "grad_norm": 0.4693070650100708,
      "learning_rate": 7.196002626012109e-06,
      "loss": 0.0021,
      "step": 58680
    },
    {
      "epoch": 4.281129185206798,
      "grad_norm": 0.09360881894826889,
      "learning_rate": 7.188708147932016e-06,
      "loss": 0.0029,
      "step": 58690
    },
    {
      "epoch": 4.281858633014807,
      "grad_norm": 0.23092132806777954,
      "learning_rate": 7.181413669851922e-06,
      "loss": 0.0028,
      "step": 58700
    },
    {
      "epoch": 4.282588080822817,
      "grad_norm": 0.31706491112709045,
      "learning_rate": 7.174119191771829e-06,
      "loss": 0.002,
      "step": 58710
    },
    {
      "epoch": 4.2833175286308265,
      "grad_norm": 0.03217344358563423,
      "learning_rate": 7.166824713691736e-06,
      "loss": 0.0041,
      "step": 58720
    },
    {
      "epoch": 4.284046976438836,
      "grad_norm": 0.05842702463269234,
      "learning_rate": 7.159530235611642e-06,
      "loss": 0.0024,
      "step": 58730
    },
    {
      "epoch": 4.284776424246845,
      "grad_norm": 0.2011154741048813,
      "learning_rate": 7.152235757531549e-06,
      "loss": 0.0033,
      "step": 58740
    },
    {
      "epoch": 4.285505872054855,
      "grad_norm": 0.3176039159297943,
      "learning_rate": 7.144941279451456e-06,
      "loss": 0.0029,
      "step": 58750
    },
    {
      "epoch": 4.286235319862864,
      "grad_norm": 0.08661265671253204,
      "learning_rate": 7.137646801371361e-06,
      "loss": 0.0031,
      "step": 58760
    },
    {
      "epoch": 4.286964767670873,
      "grad_norm": 0.4025450348854065,
      "learning_rate": 7.130352323291269e-06,
      "loss": 0.0026,
      "step": 58770
    },
    {
      "epoch": 4.287694215478883,
      "grad_norm": 0.11587291955947876,
      "learning_rate": 7.123057845211175e-06,
      "loss": 0.0024,
      "step": 58780
    },
    {
      "epoch": 4.288423663286892,
      "grad_norm": 0.7106338739395142,
      "learning_rate": 7.115763367131083e-06,
      "loss": 0.004,
      "step": 58790
    },
    {
      "epoch": 4.289153111094901,
      "grad_norm": 0.08726262301206589,
      "learning_rate": 7.108468889050989e-06,
      "loss": 0.0034,
      "step": 58800
    },
    {
      "epoch": 4.28988255890291,
      "grad_norm": 0.07833464443683624,
      "learning_rate": 7.1011744109708954e-06,
      "loss": 0.0028,
      "step": 58810
    },
    {
      "epoch": 4.29061200671092,
      "grad_norm": 0.2879183292388916,
      "learning_rate": 7.093879932890803e-06,
      "loss": 0.0043,
      "step": 58820
    },
    {
      "epoch": 4.291341454518929,
      "grad_norm": 0.1735290139913559,
      "learning_rate": 7.086585454810708e-06,
      "loss": 0.0039,
      "step": 58830
    },
    {
      "epoch": 4.292070902326938,
      "grad_norm": 0.03255090117454529,
      "learning_rate": 7.0792909767306155e-06,
      "loss": 0.002,
      "step": 58840
    },
    {
      "epoch": 4.292800350134947,
      "grad_norm": 0.17259596288204193,
      "learning_rate": 7.071996498650522e-06,
      "loss": 0.0031,
      "step": 58850
    },
    {
      "epoch": 4.293529797942957,
      "grad_norm": 0.23120592534542084,
      "learning_rate": 7.064702020570428e-06,
      "loss": 0.0038,
      "step": 58860
    },
    {
      "epoch": 4.2942592457509665,
      "grad_norm": 0.03206424415111542,
      "learning_rate": 7.0574075424903355e-06,
      "loss": 0.0024,
      "step": 58870
    },
    {
      "epoch": 4.294988693558976,
      "grad_norm": 0.3478439152240753,
      "learning_rate": 7.050113064410242e-06,
      "loss": 0.0024,
      "step": 58880
    },
    {
      "epoch": 4.295718141366986,
      "grad_norm": 0.029752174392342567,
      "learning_rate": 7.042818586330148e-06,
      "loss": 0.0029,
      "step": 58890
    },
    {
      "epoch": 4.296447589174995,
      "grad_norm": 0.5162734985351562,
      "learning_rate": 7.035524108250055e-06,
      "loss": 0.0032,
      "step": 58900
    },
    {
      "epoch": 4.297177036983004,
      "grad_norm": 0.08984719961881638,
      "learning_rate": 7.028229630169962e-06,
      "loss": 0.002,
      "step": 58910
    },
    {
      "epoch": 4.297906484791013,
      "grad_norm": 0.05903252214193344,
      "learning_rate": 7.020935152089868e-06,
      "loss": 0.0032,
      "step": 58920
    },
    {
      "epoch": 4.298635932599023,
      "grad_norm": 0.2898765206336975,
      "learning_rate": 7.013640674009775e-06,
      "loss": 0.0043,
      "step": 58930
    },
    {
      "epoch": 4.299365380407032,
      "grad_norm": 0.37611109018325806,
      "learning_rate": 7.006346195929682e-06,
      "loss": 0.0031,
      "step": 58940
    },
    {
      "epoch": 4.300094828215041,
      "grad_norm": 0.12872503697872162,
      "learning_rate": 6.999051717849587e-06,
      "loss": 0.0025,
      "step": 58950
    },
    {
      "epoch": 4.30082427602305,
      "grad_norm": 0.3499038815498352,
      "learning_rate": 6.991757239769495e-06,
      "loss": 0.0021,
      "step": 58960
    },
    {
      "epoch": 4.30155372383106,
      "grad_norm": 0.2589591443538666,
      "learning_rate": 6.9844627616894015e-06,
      "loss": 0.004,
      "step": 58970
    },
    {
      "epoch": 4.302283171639069,
      "grad_norm": 0.0912201777100563,
      "learning_rate": 6.977168283609307e-06,
      "loss": 0.0026,
      "step": 58980
    },
    {
      "epoch": 4.303012619447078,
      "grad_norm": 0.32886767387390137,
      "learning_rate": 6.969873805529215e-06,
      "loss": 0.0019,
      "step": 58990
    },
    {
      "epoch": 4.303742067255088,
      "grad_norm": 0.08910726010799408,
      "learning_rate": 6.9625793274491216e-06,
      "loss": 0.0022,
      "step": 59000
    },
    {
      "epoch": 4.304471515063097,
      "grad_norm": 0.14477090537548065,
      "learning_rate": 6.955284849369027e-06,
      "loss": 0.0031,
      "step": 59010
    },
    {
      "epoch": 4.3052009628711065,
      "grad_norm": 0.6043778657913208,
      "learning_rate": 6.947990371288934e-06,
      "loss": 0.0023,
      "step": 59020
    },
    {
      "epoch": 4.305930410679116,
      "grad_norm": 0.3272370398044586,
      "learning_rate": 6.940695893208842e-06,
      "loss": 0.0031,
      "step": 59030
    },
    {
      "epoch": 4.306659858487126,
      "grad_norm": 0.23134401440620422,
      "learning_rate": 6.933401415128748e-06,
      "loss": 0.0032,
      "step": 59040
    },
    {
      "epoch": 4.307389306295135,
      "grad_norm": 0.42189425230026245,
      "learning_rate": 6.926106937048654e-06,
      "loss": 0.0043,
      "step": 59050
    },
    {
      "epoch": 4.308118754103144,
      "grad_norm": 0.1834275722503662,
      "learning_rate": 6.918812458968562e-06,
      "loss": 0.0023,
      "step": 59060
    },
    {
      "epoch": 4.308848201911153,
      "grad_norm": 0.43078234791755676,
      "learning_rate": 6.911517980888468e-06,
      "loss": 0.0039,
      "step": 59070
    },
    {
      "epoch": 4.309577649719163,
      "grad_norm": 0.318004846572876,
      "learning_rate": 6.904223502808374e-06,
      "loss": 0.002,
      "step": 59080
    },
    {
      "epoch": 4.310307097527172,
      "grad_norm": 0.3347149193286896,
      "learning_rate": 6.896929024728281e-06,
      "loss": 0.004,
      "step": 59090
    },
    {
      "epoch": 4.311036545335181,
      "grad_norm": 0.14473631978034973,
      "learning_rate": 6.889634546648188e-06,
      "loss": 0.0024,
      "step": 59100
    },
    {
      "epoch": 4.31176599314319,
      "grad_norm": 0.12946893274784088,
      "learning_rate": 6.882340068568094e-06,
      "loss": 0.0023,
      "step": 59110
    },
    {
      "epoch": 4.3124954409512,
      "grad_norm": 0.17405450344085693,
      "learning_rate": 6.875045590488001e-06,
      "loss": 0.0035,
      "step": 59120
    },
    {
      "epoch": 4.313224888759209,
      "grad_norm": 0.030714549124240875,
      "learning_rate": 6.8677511124079084e-06,
      "loss": 0.0021,
      "step": 59130
    },
    {
      "epoch": 4.313954336567218,
      "grad_norm": 0.20739562809467316,
      "learning_rate": 6.8604566343278134e-06,
      "loss": 0.0026,
      "step": 59140
    },
    {
      "epoch": 4.314683784375228,
      "grad_norm": 0.14116552472114563,
      "learning_rate": 6.853162156247721e-06,
      "loss": 0.0025,
      "step": 59150
    },
    {
      "epoch": 4.3154132321832375,
      "grad_norm": 0.1732115000486374,
      "learning_rate": 6.845867678167628e-06,
      "loss": 0.0033,
      "step": 59160
    },
    {
      "epoch": 4.316142679991247,
      "grad_norm": 0.10898618400096893,
      "learning_rate": 6.8385732000875335e-06,
      "loss": 0.0022,
      "step": 59170
    },
    {
      "epoch": 4.316872127799256,
      "grad_norm": 0.1740466207265854,
      "learning_rate": 6.831278722007441e-06,
      "loss": 0.0036,
      "step": 59180
    },
    {
      "epoch": 4.317601575607266,
      "grad_norm": 0.029007438570261,
      "learning_rate": 6.823984243927348e-06,
      "loss": 0.0033,
      "step": 59190
    },
    {
      "epoch": 4.318331023415275,
      "grad_norm": 0.030635317787528038,
      "learning_rate": 6.8166897658472535e-06,
      "loss": 0.0028,
      "step": 59200
    },
    {
      "epoch": 4.319060471223284,
      "grad_norm": 0.02188515104353428,
      "learning_rate": 6.80939528776716e-06,
      "loss": 0.003,
      "step": 59210
    },
    {
      "epoch": 4.319789919031293,
      "grad_norm": 0.5196642875671387,
      "learning_rate": 6.802100809687068e-06,
      "loss": 0.0024,
      "step": 59220
    },
    {
      "epoch": 4.320519366839303,
      "grad_norm": 0.6607202887535095,
      "learning_rate": 6.7948063316069736e-06,
      "loss": 0.0033,
      "step": 59230
    },
    {
      "epoch": 4.321248814647312,
      "grad_norm": 0.2016766220331192,
      "learning_rate": 6.78751185352688e-06,
      "loss": 0.0018,
      "step": 59240
    },
    {
      "epoch": 4.321978262455321,
      "grad_norm": 0.059756211936473846,
      "learning_rate": 6.780217375446788e-06,
      "loss": 0.0022,
      "step": 59250
    },
    {
      "epoch": 4.32270771026333,
      "grad_norm": 0.46078771352767944,
      "learning_rate": 6.772922897366693e-06,
      "loss": 0.0049,
      "step": 59260
    },
    {
      "epoch": 4.32343715807134,
      "grad_norm": 0.5233926177024841,
      "learning_rate": 6.7656284192866e-06,
      "loss": 0.0022,
      "step": 59270
    },
    {
      "epoch": 4.324166605879349,
      "grad_norm": 0.08678879588842392,
      "learning_rate": 6.758333941206507e-06,
      "loss": 0.0022,
      "step": 59280
    },
    {
      "epoch": 4.324896053687358,
      "grad_norm": 0.08771265298128128,
      "learning_rate": 6.7510394631264145e-06,
      "loss": 0.0029,
      "step": 59290
    },
    {
      "epoch": 4.325625501495368,
      "grad_norm": 0.2020980268716812,
      "learning_rate": 6.74374498504632e-06,
      "loss": 0.0018,
      "step": 59300
    },
    {
      "epoch": 4.3263549493033775,
      "grad_norm": 0.5482187867164612,
      "learning_rate": 6.736450506966227e-06,
      "loss": 0.0031,
      "step": 59310
    },
    {
      "epoch": 4.327084397111387,
      "grad_norm": 0.2324446588754654,
      "learning_rate": 6.729156028886134e-06,
      "loss": 0.0028,
      "step": 59320
    },
    {
      "epoch": 4.327813844919396,
      "grad_norm": 0.1442297101020813,
      "learning_rate": 6.7218615508060396e-06,
      "loss": 0.0032,
      "step": 59330
    },
    {
      "epoch": 4.328543292727406,
      "grad_norm": 0.11860022693872452,
      "learning_rate": 6.714567072725947e-06,
      "loss": 0.002,
      "step": 59340
    },
    {
      "epoch": 4.329272740535415,
      "grad_norm": 0.31776827573776245,
      "learning_rate": 6.707272594645854e-06,
      "loss": 0.002,
      "step": 59350
    },
    {
      "epoch": 4.330002188343424,
      "grad_norm": 0.4529571831226349,
      "learning_rate": 6.69997811656576e-06,
      "loss": 0.0028,
      "step": 59360
    },
    {
      "epoch": 4.330731636151433,
      "grad_norm": 0.11567675322294235,
      "learning_rate": 6.692683638485666e-06,
      "loss": 0.0036,
      "step": 59370
    },
    {
      "epoch": 4.331461083959443,
      "grad_norm": 0.0295583363622427,
      "learning_rate": 6.685389160405574e-06,
      "loss": 0.0034,
      "step": 59380
    },
    {
      "epoch": 4.332190531767452,
      "grad_norm": 0.12408432364463806,
      "learning_rate": 6.67809468232548e-06,
      "loss": 0.0022,
      "step": 59390
    },
    {
      "epoch": 4.332919979575461,
      "grad_norm": 0.2025844156742096,
      "learning_rate": 6.670800204245386e-06,
      "loss": 0.0037,
      "step": 59400
    },
    {
      "epoch": 4.33364942738347,
      "grad_norm": 0.06243215873837471,
      "learning_rate": 6.663505726165294e-06,
      "loss": 0.0028,
      "step": 59410
    },
    {
      "epoch": 4.33437887519148,
      "grad_norm": 0.08716525882482529,
      "learning_rate": 6.6562112480852e-06,
      "loss": 0.0023,
      "step": 59420
    },
    {
      "epoch": 4.335108322999489,
      "grad_norm": 0.23841740190982819,
      "learning_rate": 6.648916770005106e-06,
      "loss": 0.003,
      "step": 59430
    },
    {
      "epoch": 4.335837770807498,
      "grad_norm": 0.00803682953119278,
      "learning_rate": 6.641622291925013e-06,
      "loss": 0.0016,
      "step": 59440
    },
    {
      "epoch": 4.336567218615508,
      "grad_norm": 0.05838576331734657,
      "learning_rate": 6.634327813844919e-06,
      "loss": 0.0017,
      "step": 59450
    },
    {
      "epoch": 4.3372966664235175,
      "grad_norm": 0.3479974567890167,
      "learning_rate": 6.6270333357648264e-06,
      "loss": 0.0026,
      "step": 59460
    },
    {
      "epoch": 4.338026114231527,
      "grad_norm": 0.3205866813659668,
      "learning_rate": 6.619738857684733e-06,
      "loss": 0.0023,
      "step": 59470
    },
    {
      "epoch": 4.338755562039536,
      "grad_norm": 0.1959279179573059,
      "learning_rate": 6.612444379604639e-06,
      "loss": 0.0031,
      "step": 59480
    },
    {
      "epoch": 4.339485009847546,
      "grad_norm": 0.00813999306410551,
      "learning_rate": 6.605149901524546e-06,
      "loss": 0.003,
      "step": 59490
    },
    {
      "epoch": 4.340214457655555,
      "grad_norm": 0.3287332355976105,
      "learning_rate": 6.597855423444453e-06,
      "loss": 0.0032,
      "step": 59500
    },
    {
      "epoch": 4.340943905463564,
      "grad_norm": 0.05843129754066467,
      "learning_rate": 6.590560945364359e-06,
      "loss": 0.0032,
      "step": 59510
    },
    {
      "epoch": 4.341673353271574,
      "grad_norm": 0.34310027956962585,
      "learning_rate": 6.583266467284266e-06,
      "loss": 0.0023,
      "step": 59520
    },
    {
      "epoch": 4.342402801079583,
      "grad_norm": 0.020864078775048256,
      "learning_rate": 6.575971989204173e-06,
      "loss": 0.0034,
      "step": 59530
    },
    {
      "epoch": 4.343132248887592,
      "grad_norm": 0.06873368471860886,
      "learning_rate": 6.56867751112408e-06,
      "loss": 0.0033,
      "step": 59540
    },
    {
      "epoch": 4.343861696695601,
      "grad_norm": 0.14440865814685822,
      "learning_rate": 6.561383033043986e-06,
      "loss": 0.0028,
      "step": 59550
    },
    {
      "epoch": 4.344591144503611,
      "grad_norm": 0.4038660526275635,
      "learning_rate": 6.554088554963892e-06,
      "loss": 0.0029,
      "step": 59560
    },
    {
      "epoch": 4.34532059231162,
      "grad_norm": 0.14434131979942322,
      "learning_rate": 6.5467940768838e-06,
      "loss": 0.003,
      "step": 59570
    },
    {
      "epoch": 4.346050040119629,
      "grad_norm": 0.11543576419353485,
      "learning_rate": 6.539499598803706e-06,
      "loss": 0.002,
      "step": 59580
    },
    {
      "epoch": 4.3467794879276385,
      "grad_norm": 0.2908731698989868,
      "learning_rate": 6.5322051207236125e-06,
      "loss": 0.0028,
      "step": 59590
    },
    {
      "epoch": 4.3475089357356484,
      "grad_norm": 0.026211068034172058,
      "learning_rate": 6.52491064264352e-06,
      "loss": 0.0021,
      "step": 59600
    },
    {
      "epoch": 4.3482383835436575,
      "grad_norm": 0.03760716691613197,
      "learning_rate": 6.517616164563425e-06,
      "loss": 0.0032,
      "step": 59610
    },
    {
      "epoch": 4.348967831351667,
      "grad_norm": 0.18886902928352356,
      "learning_rate": 6.5103216864833325e-06,
      "loss": 0.0019,
      "step": 59620
    },
    {
      "epoch": 4.349697279159676,
      "grad_norm": 0.11676992475986481,
      "learning_rate": 6.503027208403239e-06,
      "loss": 0.0024,
      "step": 59630
    },
    {
      "epoch": 4.350426726967686,
      "grad_norm": 0.5634152293205261,
      "learning_rate": 6.495732730323145e-06,
      "loss": 0.0019,
      "step": 59640
    },
    {
      "epoch": 4.351156174775695,
      "grad_norm": 0.1639288067817688,
      "learning_rate": 6.4884382522430526e-06,
      "loss": 0.0043,
      "step": 59650
    },
    {
      "epoch": 4.351885622583704,
      "grad_norm": 0.3461129665374756,
      "learning_rate": 6.481143774162959e-06,
      "loss": 0.003,
      "step": 59660
    },
    {
      "epoch": 4.352615070391714,
      "grad_norm": 0.17454247176647186,
      "learning_rate": 6.473849296082865e-06,
      "loss": 0.0037,
      "step": 59670
    },
    {
      "epoch": 4.353344518199723,
      "grad_norm": 0.19344750046730042,
      "learning_rate": 6.466554818002772e-06,
      "loss": 0.0023,
      "step": 59680
    },
    {
      "epoch": 4.354073966007732,
      "grad_norm": 0.11678251624107361,
      "learning_rate": 6.459260339922679e-06,
      "loss": 0.0036,
      "step": 59690
    },
    {
      "epoch": 4.354803413815741,
      "grad_norm": 0.31720611453056335,
      "learning_rate": 6.451965861842585e-06,
      "loss": 0.0032,
      "step": 59700
    },
    {
      "epoch": 4.355532861623751,
      "grad_norm": 0.2313781976699829,
      "learning_rate": 6.444671383762492e-06,
      "loss": 0.0039,
      "step": 59710
    },
    {
      "epoch": 4.35626230943176,
      "grad_norm": 0.14406998455524445,
      "learning_rate": 6.437376905682399e-06,
      "loss": 0.0034,
      "step": 59720
    },
    {
      "epoch": 4.356991757239769,
      "grad_norm": 0.42178696393966675,
      "learning_rate": 6.430082427602304e-06,
      "loss": 0.0027,
      "step": 59730
    },
    {
      "epoch": 4.3577212050477785,
      "grad_norm": 0.16760964691638947,
      "learning_rate": 6.422787949522212e-06,
      "loss": 0.002,
      "step": 59740
    },
    {
      "epoch": 4.3584506528557885,
      "grad_norm": 0.18905247747898102,
      "learning_rate": 6.4154934714421185e-06,
      "loss": 0.0025,
      "step": 59750
    },
    {
      "epoch": 4.359180100663798,
      "grad_norm": 0.029646003618836403,
      "learning_rate": 6.408198993362024e-06,
      "loss": 0.0033,
      "step": 59760
    },
    {
      "epoch": 4.359909548471807,
      "grad_norm": 0.009589415043592453,
      "learning_rate": 6.400904515281932e-06,
      "loss": 0.0029,
      "step": 59770
    },
    {
      "epoch": 4.360638996279816,
      "grad_norm": 0.2901574373245239,
      "learning_rate": 6.393610037201839e-06,
      "loss": 0.0031,
      "step": 59780
    },
    {
      "epoch": 4.361368444087826,
      "grad_norm": 0.1482754945755005,
      "learning_rate": 6.386315559121746e-06,
      "loss": 0.003,
      "step": 59790
    },
    {
      "epoch": 4.362097891895835,
      "grad_norm": 0.11547151952981949,
      "learning_rate": 6.379021081041651e-06,
      "loss": 0.003,
      "step": 59800
    },
    {
      "epoch": 4.362827339703844,
      "grad_norm": 0.12892289459705353,
      "learning_rate": 6.371726602961559e-06,
      "loss": 0.0027,
      "step": 59810
    },
    {
      "epoch": 4.363556787511854,
      "grad_norm": 0.17360663414001465,
      "learning_rate": 6.364432124881465e-06,
      "loss": 0.0032,
      "step": 59820
    },
    {
      "epoch": 4.364286235319863,
      "grad_norm": 0.08747906237840652,
      "learning_rate": 6.357137646801371e-06,
      "loss": 0.0027,
      "step": 59830
    },
    {
      "epoch": 4.365015683127872,
      "grad_norm": 0.11621646583080292,
      "learning_rate": 6.349843168721279e-06,
      "loss": 0.002,
      "step": 59840
    },
    {
      "epoch": 4.365745130935881,
      "grad_norm": 0.20246702432632446,
      "learning_rate": 6.342548690641185e-06,
      "loss": 0.0025,
      "step": 59850
    },
    {
      "epoch": 4.366474578743891,
      "grad_norm": 0.14472095668315887,
      "learning_rate": 6.335254212561091e-06,
      "loss": 0.0029,
      "step": 59860
    },
    {
      "epoch": 4.3672040265519,
      "grad_norm": 0.08685982972383499,
      "learning_rate": 6.327959734480998e-06,
      "loss": 0.0037,
      "step": 59870
    },
    {
      "epoch": 4.367933474359909,
      "grad_norm": 0.1102181226015091,
      "learning_rate": 6.320665256400905e-06,
      "loss": 0.0024,
      "step": 59880
    },
    {
      "epoch": 4.3686629221679185,
      "grad_norm": 0.14607368409633636,
      "learning_rate": 6.313370778320811e-06,
      "loss": 0.0021,
      "step": 59890
    },
    {
      "epoch": 4.3693923699759285,
      "grad_norm": 0.14576487243175507,
      "learning_rate": 6.306076300240718e-06,
      "loss": 0.0027,
      "step": 59900
    },
    {
      "epoch": 4.370121817783938,
      "grad_norm": 0.14436429738998413,
      "learning_rate": 6.2987818221606255e-06,
      "loss": 0.0029,
      "step": 59910
    },
    {
      "epoch": 4.370851265591947,
      "grad_norm": 0.05776157230138779,
      "learning_rate": 6.2914873440805305e-06,
      "loss": 0.0033,
      "step": 59920
    },
    {
      "epoch": 4.371580713399956,
      "grad_norm": 0.172577366232872,
      "learning_rate": 6.284192866000438e-06,
      "loss": 0.0034,
      "step": 59930
    },
    {
      "epoch": 4.372310161207966,
      "grad_norm": 0.062084075063467026,
      "learning_rate": 6.276898387920345e-06,
      "loss": 0.0023,
      "step": 59940
    },
    {
      "epoch": 4.373039609015975,
      "grad_norm": 0.14936771988868713,
      "learning_rate": 6.2696039098402505e-06,
      "loss": 0.0031,
      "step": 59950
    },
    {
      "epoch": 4.373769056823984,
      "grad_norm": 0.08715716749429703,
      "learning_rate": 6.262309431760158e-06,
      "loss": 0.0038,
      "step": 59960
    },
    {
      "epoch": 4.374498504631994,
      "grad_norm": 0.14452992379665375,
      "learning_rate": 6.255014953680065e-06,
      "loss": 0.0027,
      "step": 59970
    },
    {
      "epoch": 4.375227952440003,
      "grad_norm": 0.034533556550741196,
      "learning_rate": 6.247720475599971e-06,
      "loss": 0.0029,
      "step": 59980
    },
    {
      "epoch": 4.375957400248012,
      "grad_norm": 0.03991653025150299,
      "learning_rate": 6.240425997519877e-06,
      "loss": 0.0026,
      "step": 59990
    },
    {
      "epoch": 4.376686848056021,
      "grad_norm": 0.2743054926395416,
      "learning_rate": 6.233131519439785e-06,
      "loss": 0.0044,
      "step": 60000
    },
    {
      "epoch": 4.377416295864031,
      "grad_norm": 0.26498404145240784,
      "learning_rate": 6.225837041359691e-06,
      "loss": 0.0031,
      "step": 60010
    },
    {
      "epoch": 4.37814574367204,
      "grad_norm": 0.11790316551923752,
      "learning_rate": 6.218542563279597e-06,
      "loss": 0.0031,
      "step": 60020
    },
    {
      "epoch": 4.3788751914800494,
      "grad_norm": 0.1165044978260994,
      "learning_rate": 6.211248085199505e-06,
      "loss": 0.0031,
      "step": 60030
    },
    {
      "epoch": 4.3796046392880585,
      "grad_norm": 0.1756397932767868,
      "learning_rate": 6.203953607119411e-06,
      "loss": 0.002,
      "step": 60040
    },
    {
      "epoch": 4.3803340870960685,
      "grad_norm": 0.16575118899345398,
      "learning_rate": 6.196659129039317e-06,
      "loss": 0.0028,
      "step": 60050
    },
    {
      "epoch": 4.381063534904078,
      "grad_norm": 0.32766661047935486,
      "learning_rate": 6.189364650959224e-06,
      "loss": 0.0038,
      "step": 60060
    },
    {
      "epoch": 4.381792982712087,
      "grad_norm": 0.14604996144771576,
      "learning_rate": 6.182070172879131e-06,
      "loss": 0.0022,
      "step": 60070
    },
    {
      "epoch": 4.382522430520096,
      "grad_norm": 0.3458386957645416,
      "learning_rate": 6.174775694799037e-06,
      "loss": 0.0032,
      "step": 60080
    },
    {
      "epoch": 4.383251878328106,
      "grad_norm": 0.28944525122642517,
      "learning_rate": 6.167481216718944e-06,
      "loss": 0.0033,
      "step": 60090
    },
    {
      "epoch": 4.383981326136115,
      "grad_norm": 0.011436160653829575,
      "learning_rate": 6.160186738638851e-06,
      "loss": 0.0023,
      "step": 60100
    },
    {
      "epoch": 4.384710773944124,
      "grad_norm": 0.1871827095746994,
      "learning_rate": 6.1528922605587574e-06,
      "loss": 0.0019,
      "step": 60110
    },
    {
      "epoch": 4.385440221752134,
      "grad_norm": 0.173769012093544,
      "learning_rate": 6.145597782478664e-06,
      "loss": 0.0017,
      "step": 60120
    },
    {
      "epoch": 4.386169669560143,
      "grad_norm": 0.05791439861059189,
      "learning_rate": 6.13830330439857e-06,
      "loss": 0.0033,
      "step": 60130
    },
    {
      "epoch": 4.386899117368152,
      "grad_norm": 0.3471255600452423,
      "learning_rate": 6.1310088263184775e-06,
      "loss": 0.0033,
      "step": 60140
    },
    {
      "epoch": 4.387628565176161,
      "grad_norm": 0.23237857222557068,
      "learning_rate": 6.123714348238384e-06,
      "loss": 0.0028,
      "step": 60150
    },
    {
      "epoch": 4.388358012984171,
      "grad_norm": 0.03159860149025917,
      "learning_rate": 6.11641987015829e-06,
      "loss": 0.0034,
      "step": 60160
    },
    {
      "epoch": 4.38908746079218,
      "grad_norm": 0.11585616320371628,
      "learning_rate": 6.1091253920781975e-06,
      "loss": 0.0031,
      "step": 60170
    },
    {
      "epoch": 4.3898169086001895,
      "grad_norm": 0.27207157015800476,
      "learning_rate": 6.101830913998103e-06,
      "loss": 0.0023,
      "step": 60180
    },
    {
      "epoch": 4.3905463564081995,
      "grad_norm": 0.03190712630748749,
      "learning_rate": 6.09453643591801e-06,
      "loss": 0.0026,
      "step": 60190
    },
    {
      "epoch": 4.3912758042162086,
      "grad_norm": 0.9566428065299988,
      "learning_rate": 6.087241957837917e-06,
      "loss": 0.0032,
      "step": 60200
    },
    {
      "epoch": 4.392005252024218,
      "grad_norm": 0.34697917103767395,
      "learning_rate": 6.079947479757823e-06,
      "loss": 0.0038,
      "step": 60210
    },
    {
      "epoch": 4.392734699832227,
      "grad_norm": 0.1169247031211853,
      "learning_rate": 6.072653001677731e-06,
      "loss": 0.0034,
      "step": 60220
    },
    {
      "epoch": 4.393464147640237,
      "grad_norm": 0.18331408500671387,
      "learning_rate": 6.065358523597637e-06,
      "loss": 0.0023,
      "step": 60230
    },
    {
      "epoch": 4.394193595448246,
      "grad_norm": 0.2011159211397171,
      "learning_rate": 6.0580640455175435e-06,
      "loss": 0.0022,
      "step": 60240
    },
    {
      "epoch": 4.394923043256255,
      "grad_norm": 0.21253573894500732,
      "learning_rate": 6.05076956743745e-06,
      "loss": 0.0032,
      "step": 60250
    },
    {
      "epoch": 4.395652491064264,
      "grad_norm": 0.2019350379705429,
      "learning_rate": 6.043475089357357e-06,
      "loss": 0.0034,
      "step": 60260
    },
    {
      "epoch": 4.396381938872274,
      "grad_norm": 0.3472343385219574,
      "learning_rate": 6.0361806112772635e-06,
      "loss": 0.003,
      "step": 60270
    },
    {
      "epoch": 4.397111386680283,
      "grad_norm": 0.05851206183433533,
      "learning_rate": 6.02888613319717e-06,
      "loss": 0.0026,
      "step": 60280
    },
    {
      "epoch": 4.397840834488292,
      "grad_norm": 0.2020198553800583,
      "learning_rate": 6.021591655117077e-06,
      "loss": 0.004,
      "step": 60290
    },
    {
      "epoch": 4.398570282296301,
      "grad_norm": 0.031223753467202187,
      "learning_rate": 6.014297177036983e-06,
      "loss": 0.0022,
      "step": 60300
    },
    {
      "epoch": 4.399299730104311,
      "grad_norm": 0.20551542937755585,
      "learning_rate": 6.00700269895689e-06,
      "loss": 0.0016,
      "step": 60310
    },
    {
      "epoch": 4.40002917791232,
      "grad_norm": 0.3640810251235962,
      "learning_rate": 5.999708220876796e-06,
      "loss": 0.003,
      "step": 60320
    },
    {
      "epoch": 4.4007586257203295,
      "grad_norm": 0.11981269717216492,
      "learning_rate": 5.992413742796704e-06,
      "loss": 0.002,
      "step": 60330
    },
    {
      "epoch": 4.4014880735283395,
      "grad_norm": 0.06072889640927315,
      "learning_rate": 5.98511926471661e-06,
      "loss": 0.0042,
      "step": 60340
    },
    {
      "epoch": 4.402217521336349,
      "grad_norm": 0.23234805464744568,
      "learning_rate": 5.977824786636516e-06,
      "loss": 0.003,
      "step": 60350
    },
    {
      "epoch": 4.402946969144358,
      "grad_norm": 0.17741379141807556,
      "learning_rate": 5.970530308556424e-06,
      "loss": 0.0018,
      "step": 60360
    },
    {
      "epoch": 4.403676416952367,
      "grad_norm": 0.2037563920021057,
      "learning_rate": 5.9632358304763295e-06,
      "loss": 0.004,
      "step": 60370
    },
    {
      "epoch": 4.404405864760377,
      "grad_norm": 0.20284993946552277,
      "learning_rate": 5.955941352396236e-06,
      "loss": 0.0039,
      "step": 60380
    },
    {
      "epoch": 4.405135312568386,
      "grad_norm": 0.11509979516267776,
      "learning_rate": 5.948646874316143e-06,
      "loss": 0.0028,
      "step": 60390
    },
    {
      "epoch": 4.405864760376395,
      "grad_norm": 0.351240336894989,
      "learning_rate": 5.9413523962360495e-06,
      "loss": 0.0024,
      "step": 60400
    },
    {
      "epoch": 4.406594208184404,
      "grad_norm": 0.058126065880060196,
      "learning_rate": 5.934057918155956e-06,
      "loss": 0.0031,
      "step": 60410
    },
    {
      "epoch": 4.407323655992414,
      "grad_norm": 0.14415770769119263,
      "learning_rate": 5.926763440075863e-06,
      "loss": 0.0026,
      "step": 60420
    },
    {
      "epoch": 4.408053103800423,
      "grad_norm": 0.29058805108070374,
      "learning_rate": 5.91946896199577e-06,
      "loss": 0.0033,
      "step": 60430
    },
    {
      "epoch": 4.408782551608432,
      "grad_norm": 0.16150535643100739,
      "learning_rate": 5.9121744839156754e-06,
      "loss": 0.0025,
      "step": 60440
    },
    {
      "epoch": 4.409511999416441,
      "grad_norm": 0.2530948519706726,
      "learning_rate": 5.904880005835583e-06,
      "loss": 0.0038,
      "step": 60450
    },
    {
      "epoch": 4.410241447224451,
      "grad_norm": 0.11496654897928238,
      "learning_rate": 5.89758552775549e-06,
      "loss": 0.0034,
      "step": 60460
    },
    {
      "epoch": 4.41097089503246,
      "grad_norm": 0.13716311752796173,
      "learning_rate": 5.890291049675396e-06,
      "loss": 0.0026,
      "step": 60470
    },
    {
      "epoch": 4.4117003428404695,
      "grad_norm": 0.2316960096359253,
      "learning_rate": 5.882996571595303e-06,
      "loss": 0.0028,
      "step": 60480
    },
    {
      "epoch": 4.4124297906484795,
      "grad_norm": 0.0796712189912796,
      "learning_rate": 5.875702093515209e-06,
      "loss": 0.0022,
      "step": 60490
    },
    {
      "epoch": 4.413159238456489,
      "grad_norm": 0.5477271676063538,
      "learning_rate": 5.868407615435116e-06,
      "loss": 0.0025,
      "step": 60500
    },
    {
      "epoch": 4.413888686264498,
      "grad_norm": 0.17432904243469238,
      "learning_rate": 5.861113137355022e-06,
      "loss": 0.0032,
      "step": 60510
    },
    {
      "epoch": 4.414618134072507,
      "grad_norm": 0.05864647403359413,
      "learning_rate": 5.853818659274929e-06,
      "loss": 0.0031,
      "step": 60520
    },
    {
      "epoch": 4.415347581880517,
      "grad_norm": 0.20277175307273865,
      "learning_rate": 5.8465241811948356e-06,
      "loss": 0.0036,
      "step": 60530
    },
    {
      "epoch": 4.416077029688526,
      "grad_norm": 0.14450739324092865,
      "learning_rate": 5.839229703114742e-06,
      "loss": 0.0034,
      "step": 60540
    },
    {
      "epoch": 4.416806477496535,
      "grad_norm": 0.1732955425977707,
      "learning_rate": 5.831935225034649e-06,
      "loss": 0.0024,
      "step": 60550
    },
    {
      "epoch": 4.417535925304544,
      "grad_norm": 0.11820077151060104,
      "learning_rate": 5.824640746954556e-06,
      "loss": 0.0022,
      "step": 60560
    },
    {
      "epoch": 4.418265373112554,
      "grad_norm": 0.08966919034719467,
      "learning_rate": 5.817346268874462e-06,
      "loss": 0.0046,
      "step": 60570
    },
    {
      "epoch": 4.418994820920563,
      "grad_norm": 0.2247183471918106,
      "learning_rate": 5.810051790794369e-06,
      "loss": 0.0029,
      "step": 60580
    },
    {
      "epoch": 4.419724268728572,
      "grad_norm": 0.22176557779312134,
      "learning_rate": 5.802757312714276e-06,
      "loss": 0.0026,
      "step": 60590
    },
    {
      "epoch": 4.420453716536581,
      "grad_norm": 0.39122018218040466,
      "learning_rate": 5.795462834634182e-06,
      "loss": 0.0043,
      "step": 60600
    },
    {
      "epoch": 4.421183164344591,
      "grad_norm": 0.23172494769096375,
      "learning_rate": 5.788168356554089e-06,
      "loss": 0.0032,
      "step": 60610
    },
    {
      "epoch": 4.4219126121526005,
      "grad_norm": 0.06166966259479523,
      "learning_rate": 5.780873878473996e-06,
      "loss": 0.0035,
      "step": 60620
    },
    {
      "epoch": 4.4226420599606096,
      "grad_norm": 0.35464516282081604,
      "learning_rate": 5.7735794003939016e-06,
      "loss": 0.0027,
      "step": 60630
    },
    {
      "epoch": 4.4233715077686195,
      "grad_norm": 0.009806179441511631,
      "learning_rate": 5.766284922313809e-06,
      "loss": 0.0024,
      "step": 60640
    },
    {
      "epoch": 4.424100955576629,
      "grad_norm": 0.25895023345947266,
      "learning_rate": 5.758990444233715e-06,
      "loss": 0.0032,
      "step": 60650
    },
    {
      "epoch": 4.424830403384638,
      "grad_norm": 0.057617250829935074,
      "learning_rate": 5.751695966153622e-06,
      "loss": 0.0028,
      "step": 60660
    },
    {
      "epoch": 4.425559851192647,
      "grad_norm": 0.1743541806936264,
      "learning_rate": 5.744401488073529e-06,
      "loss": 0.0023,
      "step": 60670
    },
    {
      "epoch": 4.426289299000657,
      "grad_norm": 0.05936282128095627,
      "learning_rate": 5.737107009993435e-06,
      "loss": 0.003,
      "step": 60680
    },
    {
      "epoch": 4.427018746808666,
      "grad_norm": 0.2014264613389969,
      "learning_rate": 5.7298125319133425e-06,
      "loss": 0.0022,
      "step": 60690
    },
    {
      "epoch": 4.427748194616675,
      "grad_norm": 0.1809101104736328,
      "learning_rate": 5.722518053833248e-06,
      "loss": 0.0025,
      "step": 60700
    },
    {
      "epoch": 4.428477642424684,
      "grad_norm": 0.13998296856880188,
      "learning_rate": 5.715223575753155e-06,
      "loss": 0.0043,
      "step": 60710
    },
    {
      "epoch": 4.429207090232694,
      "grad_norm": 0.029712047427892685,
      "learning_rate": 5.707929097673062e-06,
      "loss": 0.0022,
      "step": 60720
    },
    {
      "epoch": 4.429936538040703,
      "grad_norm": 0.6985716223716736,
      "learning_rate": 5.700634619592968e-06,
      "loss": 0.0027,
      "step": 60730
    },
    {
      "epoch": 4.430665985848712,
      "grad_norm": 0.03125575929880142,
      "learning_rate": 5.693340141512875e-06,
      "loss": 0.0027,
      "step": 60740
    },
    {
      "epoch": 4.431395433656721,
      "grad_norm": 0.19102725386619568,
      "learning_rate": 5.686045663432782e-06,
      "loss": 0.0029,
      "step": 60750
    },
    {
      "epoch": 4.432124881464731,
      "grad_norm": 0.10729765892028809,
      "learning_rate": 5.6787511853526884e-06,
      "loss": 0.0026,
      "step": 60760
    },
    {
      "epoch": 4.4328543292727405,
      "grad_norm": 0.36518627405166626,
      "learning_rate": 5.671456707272594e-06,
      "loss": 0.0026,
      "step": 60770
    },
    {
      "epoch": 4.43358377708075,
      "grad_norm": 0.44337865710258484,
      "learning_rate": 5.664162229192502e-06,
      "loss": 0.0027,
      "step": 60780
    },
    {
      "epoch": 4.43431322488876,
      "grad_norm": 0.03471742197871208,
      "learning_rate": 5.6568677511124085e-06,
      "loss": 0.0046,
      "step": 60790
    },
    {
      "epoch": 4.435042672696769,
      "grad_norm": 0.3516608774662018,
      "learning_rate": 5.649573273032314e-06,
      "loss": 0.0049,
      "step": 60800
    },
    {
      "epoch": 4.435772120504778,
      "grad_norm": 0.029821790754795074,
      "learning_rate": 5.642278794952222e-06,
      "loss": 0.0028,
      "step": 60810
    },
    {
      "epoch": 4.436501568312787,
      "grad_norm": 0.19154107570648193,
      "learning_rate": 5.634984316872128e-06,
      "loss": 0.0042,
      "step": 60820
    },
    {
      "epoch": 4.437231016120797,
      "grad_norm": 0.14443153142929077,
      "learning_rate": 5.627689838792035e-06,
      "loss": 0.004,
      "step": 60830
    },
    {
      "epoch": 4.437960463928806,
      "grad_norm": 0.6340138912200928,
      "learning_rate": 5.620395360711941e-06,
      "loss": 0.0029,
      "step": 60840
    },
    {
      "epoch": 4.438689911736815,
      "grad_norm": 0.06017778813838959,
      "learning_rate": 5.613100882631848e-06,
      "loss": 0.0024,
      "step": 60850
    },
    {
      "epoch": 4.439419359544825,
      "grad_norm": 0.17301978170871735,
      "learning_rate": 5.605806404551755e-06,
      "loss": 0.0019,
      "step": 60860
    },
    {
      "epoch": 4.440148807352834,
      "grad_norm": 0.08769601583480835,
      "learning_rate": 5.598511926471661e-06,
      "loss": 0.0023,
      "step": 60870
    },
    {
      "epoch": 4.440878255160843,
      "grad_norm": 0.02996312454342842,
      "learning_rate": 5.591217448391568e-06,
      "loss": 0.0032,
      "step": 60880
    },
    {
      "epoch": 4.441607702968852,
      "grad_norm": 0.3664982318878174,
      "learning_rate": 5.5839229703114745e-06,
      "loss": 0.0028,
      "step": 60890
    },
    {
      "epoch": 4.442337150776862,
      "grad_norm": 0.10209297388792038,
      "learning_rate": 5.576628492231381e-06,
      "loss": 0.0024,
      "step": 60900
    },
    {
      "epoch": 4.443066598584871,
      "grad_norm": 0.14443933963775635,
      "learning_rate": 5.569334014151288e-06,
      "loss": 0.0026,
      "step": 60910
    },
    {
      "epoch": 4.4437960463928805,
      "grad_norm": 0.14836224913597107,
      "learning_rate": 5.5620395360711945e-06,
      "loss": 0.0028,
      "step": 60920
    },
    {
      "epoch": 4.44452549420089,
      "grad_norm": 0.11488819867372513,
      "learning_rate": 5.554745057991101e-06,
      "loss": 0.003,
      "step": 60930
    },
    {
      "epoch": 4.4452549420089,
      "grad_norm": 0.6060130596160889,
      "learning_rate": 5.547450579911008e-06,
      "loss": 0.0014,
      "step": 60940
    },
    {
      "epoch": 4.445984389816909,
      "grad_norm": 0.3756939768791199,
      "learning_rate": 5.5401561018309146e-06,
      "loss": 0.0022,
      "step": 60950
    },
    {
      "epoch": 4.446713837624918,
      "grad_norm": 0.4127417206764221,
      "learning_rate": 5.53286162375082e-06,
      "loss": 0.0034,
      "step": 60960
    },
    {
      "epoch": 4.447443285432927,
      "grad_norm": 0.6284475326538086,
      "learning_rate": 5.525567145670728e-06,
      "loss": 0.0029,
      "step": 60970
    },
    {
      "epoch": 4.448172733240937,
      "grad_norm": 0.23155497014522552,
      "learning_rate": 5.518272667590634e-06,
      "loss": 0.0039,
      "step": 60980
    },
    {
      "epoch": 4.448902181048946,
      "grad_norm": 0.06001003831624985,
      "learning_rate": 5.5109781895105404e-06,
      "loss": 0.0036,
      "step": 60990
    },
    {
      "epoch": 4.449631628856955,
      "grad_norm": 0.1741417646408081,
      "learning_rate": 5.503683711430448e-06,
      "loss": 0.0026,
      "step": 61000
    },
    {
      "epoch": 4.450361076664965,
      "grad_norm": 0.012860283255577087,
      "learning_rate": 5.496389233350354e-06,
      "loss": 0.0027,
      "step": 61010
    },
    {
      "epoch": 4.451090524472974,
      "grad_norm": 0.32972490787506104,
      "learning_rate": 5.4890947552702605e-06,
      "loss": 0.0046,
      "step": 61020
    },
    {
      "epoch": 4.451819972280983,
      "grad_norm": 0.06508050113916397,
      "learning_rate": 5.481800277190167e-06,
      "loss": 0.0034,
      "step": 61030
    },
    {
      "epoch": 4.452549420088992,
      "grad_norm": 0.012333435006439686,
      "learning_rate": 5.474505799110074e-06,
      "loss": 0.0028,
      "step": 61040
    },
    {
      "epoch": 4.453278867897002,
      "grad_norm": 0.059846073389053345,
      "learning_rate": 5.4672113210299805e-06,
      "loss": 0.0022,
      "step": 61050
    },
    {
      "epoch": 4.454008315705011,
      "grad_norm": 0.20217032730579376,
      "learning_rate": 5.459916842949887e-06,
      "loss": 0.0039,
      "step": 61060
    },
    {
      "epoch": 4.4547377635130205,
      "grad_norm": 0.26013675332069397,
      "learning_rate": 5.452622364869794e-06,
      "loss": 0.0026,
      "step": 61070
    },
    {
      "epoch": 4.45546721132103,
      "grad_norm": 0.059973154217004776,
      "learning_rate": 5.445327886789701e-06,
      "loss": 0.0027,
      "step": 61080
    },
    {
      "epoch": 4.45619665912904,
      "grad_norm": 0.030974512919783592,
      "learning_rate": 5.438033408709607e-06,
      "loss": 0.002,
      "step": 61090
    },
    {
      "epoch": 4.456926106937049,
      "grad_norm": 0.11575312912464142,
      "learning_rate": 5.430738930629513e-06,
      "loss": 0.0031,
      "step": 61100
    },
    {
      "epoch": 4.457655554745058,
      "grad_norm": 0.7764972448348999,
      "learning_rate": 5.423444452549421e-06,
      "loss": 0.0024,
      "step": 61110
    },
    {
      "epoch": 4.458385002553067,
      "grad_norm": 0.14495548605918884,
      "learning_rate": 5.416149974469327e-06,
      "loss": 0.0037,
      "step": 61120
    },
    {
      "epoch": 4.459114450361077,
      "grad_norm": 0.11629921197891235,
      "learning_rate": 5.408855496389233e-06,
      "loss": 0.0025,
      "step": 61130
    },
    {
      "epoch": 4.459843898169086,
      "grad_norm": 0.059944480657577515,
      "learning_rate": 5.401561018309141e-06,
      "loss": 0.0025,
      "step": 61140
    },
    {
      "epoch": 4.460573345977095,
      "grad_norm": 0.013097654096782207,
      "learning_rate": 5.3942665402290465e-06,
      "loss": 0.0026,
      "step": 61150
    },
    {
      "epoch": 4.461302793785105,
      "grad_norm": 0.20542655885219574,
      "learning_rate": 5.386972062148953e-06,
      "loss": 0.0061,
      "step": 61160
    },
    {
      "epoch": 4.462032241593114,
      "grad_norm": 0.34618979692459106,
      "learning_rate": 5.37967758406886e-06,
      "loss": 0.0023,
      "step": 61170
    },
    {
      "epoch": 4.462761689401123,
      "grad_norm": 0.20230452716350555,
      "learning_rate": 5.3723831059887666e-06,
      "loss": 0.0035,
      "step": 61180
    },
    {
      "epoch": 4.463491137209132,
      "grad_norm": 0.29645806550979614,
      "learning_rate": 5.365088627908674e-06,
      "loss": 0.0024,
      "step": 61190
    },
    {
      "epoch": 4.464220585017142,
      "grad_norm": 0.11487404257059097,
      "learning_rate": 5.35779414982858e-06,
      "loss": 0.0032,
      "step": 61200
    },
    {
      "epoch": 4.4649500328251515,
      "grad_norm": 0.20221540331840515,
      "learning_rate": 5.350499671748487e-06,
      "loss": 0.0037,
      "step": 61210
    },
    {
      "epoch": 4.465679480633161,
      "grad_norm": 0.1428414136171341,
      "learning_rate": 5.343205193668393e-06,
      "loss": 0.0024,
      "step": 61220
    },
    {
      "epoch": 4.46640892844117,
      "grad_norm": 0.033237483352422714,
      "learning_rate": 5.3359107155883e-06,
      "loss": 0.0022,
      "step": 61230
    },
    {
      "epoch": 4.46713837624918,
      "grad_norm": 0.08699260652065277,
      "learning_rate": 5.328616237508207e-06,
      "loss": 0.0024,
      "step": 61240
    },
    {
      "epoch": 4.467867824057189,
      "grad_norm": 0.1728915423154831,
      "learning_rate": 5.321321759428113e-06,
      "loss": 0.0025,
      "step": 61250
    },
    {
      "epoch": 4.468597271865198,
      "grad_norm": 0.03388839587569237,
      "learning_rate": 5.31402728134802e-06,
      "loss": 0.0031,
      "step": 61260
    },
    {
      "epoch": 4.469326719673207,
      "grad_norm": 0.06790909171104431,
      "learning_rate": 5.306732803267926e-06,
      "loss": 0.0037,
      "step": 61270
    },
    {
      "epoch": 4.470056167481217,
      "grad_norm": 0.46192362904548645,
      "learning_rate": 5.299438325187833e-06,
      "loss": 0.0035,
      "step": 61280
    },
    {
      "epoch": 4.470785615289226,
      "grad_norm": 0.145421102643013,
      "learning_rate": 5.292143847107739e-06,
      "loss": 0.0034,
      "step": 61290
    },
    {
      "epoch": 4.471515063097235,
      "grad_norm": 0.17807580530643463,
      "learning_rate": 5.284849369027646e-06,
      "loss": 0.0037,
      "step": 61300
    },
    {
      "epoch": 4.472244510905245,
      "grad_norm": 0.17353308200836182,
      "learning_rate": 5.2775548909475535e-06,
      "loss": 0.0029,
      "step": 61310
    },
    {
      "epoch": 4.472973958713254,
      "grad_norm": 0.2745491862297058,
      "learning_rate": 5.270260412867459e-06,
      "loss": 0.004,
      "step": 61320
    },
    {
      "epoch": 4.473703406521263,
      "grad_norm": 0.40468156337738037,
      "learning_rate": 5.262965934787367e-06,
      "loss": 0.0032,
      "step": 61330
    },
    {
      "epoch": 4.474432854329272,
      "grad_norm": 0.12008652091026306,
      "learning_rate": 5.255671456707273e-06,
      "loss": 0.0028,
      "step": 61340
    },
    {
      "epoch": 4.475162302137282,
      "grad_norm": 0.0878428965806961,
      "learning_rate": 5.248376978627179e-06,
      "loss": 0.0032,
      "step": 61350
    },
    {
      "epoch": 4.4758917499452915,
      "grad_norm": 0.030269751325249672,
      "learning_rate": 5.241082500547086e-06,
      "loss": 0.0022,
      "step": 61360
    },
    {
      "epoch": 4.476621197753301,
      "grad_norm": 0.011003607884049416,
      "learning_rate": 5.233788022466993e-06,
      "loss": 0.0028,
      "step": 61370
    },
    {
      "epoch": 4.47735064556131,
      "grad_norm": 0.6810420751571655,
      "learning_rate": 5.226493544386899e-06,
      "loss": 0.0036,
      "step": 61380
    },
    {
      "epoch": 4.47808009336932,
      "grad_norm": 0.1264016181230545,
      "learning_rate": 5.219199066306806e-06,
      "loss": 0.0029,
      "step": 61390
    },
    {
      "epoch": 4.478809541177329,
      "grad_norm": 0.23284828662872314,
      "learning_rate": 5.211904588226713e-06,
      "loss": 0.0035,
      "step": 61400
    },
    {
      "epoch": 4.479538988985338,
      "grad_norm": 1.0287858247756958,
      "learning_rate": 5.204610110146619e-06,
      "loss": 0.0025,
      "step": 61410
    },
    {
      "epoch": 4.480268436793347,
      "grad_norm": 0.2599368393421173,
      "learning_rate": 5.197315632066526e-06,
      "loss": 0.0025,
      "step": 61420
    },
    {
      "epoch": 4.480997884601357,
      "grad_norm": 0.20127959549427032,
      "learning_rate": 5.190021153986433e-06,
      "loss": 0.0021,
      "step": 61430
    },
    {
      "epoch": 4.481727332409366,
      "grad_norm": 0.08698870241641998,
      "learning_rate": 5.1827266759063395e-06,
      "loss": 0.0032,
      "step": 61440
    },
    {
      "epoch": 4.482456780217375,
      "grad_norm": 0.057416804134845734,
      "learning_rate": 5.175432197826246e-06,
      "loss": 0.0027,
      "step": 61450
    },
    {
      "epoch": 4.483186228025385,
      "grad_norm": 0.1867937296628952,
      "learning_rate": 5.168137719746152e-06,
      "loss": 0.0024,
      "step": 61460
    },
    {
      "epoch": 4.483915675833394,
      "grad_norm": 0.099496990442276,
      "learning_rate": 5.1608432416660595e-06,
      "loss": 0.004,
      "step": 61470
    },
    {
      "epoch": 4.484645123641403,
      "grad_norm": 0.04941307753324509,
      "learning_rate": 5.153548763585965e-06,
      "loss": 0.0035,
      "step": 61480
    },
    {
      "epoch": 4.485374571449412,
      "grad_norm": 0.037081751972436905,
      "learning_rate": 5.146254285505872e-06,
      "loss": 0.003,
      "step": 61490
    },
    {
      "epoch": 4.486104019257422,
      "grad_norm": 0.06060834974050522,
      "learning_rate": 5.138959807425779e-06,
      "loss": 0.0024,
      "step": 61500
    },
    {
      "epoch": 4.4868334670654315,
      "grad_norm": 0.11555580049753189,
      "learning_rate": 5.131665329345685e-06,
      "loss": 0.0037,
      "step": 61510
    },
    {
      "epoch": 4.487562914873441,
      "grad_norm": 0.17571163177490234,
      "learning_rate": 5.124370851265592e-06,
      "loss": 0.0032,
      "step": 61520
    },
    {
      "epoch": 4.488292362681451,
      "grad_norm": 0.1730407327413559,
      "learning_rate": 5.117076373185499e-06,
      "loss": 0.0039,
      "step": 61530
    },
    {
      "epoch": 4.48902181048946,
      "grad_norm": 0.010179504752159119,
      "learning_rate": 5.1097818951054055e-06,
      "loss": 0.003,
      "step": 61540
    },
    {
      "epoch": 4.489751258297469,
      "grad_norm": 0.010093756951391697,
      "learning_rate": 5.102487417025312e-06,
      "loss": 0.0025,
      "step": 61550
    },
    {
      "epoch": 4.490480706105478,
      "grad_norm": 0.37407177686691284,
      "learning_rate": 5.095192938945219e-06,
      "loss": 0.0018,
      "step": 61560
    },
    {
      "epoch": 4.491210153913488,
      "grad_norm": 0.23054830729961395,
      "learning_rate": 5.0878984608651255e-06,
      "loss": 0.0034,
      "step": 61570
    },
    {
      "epoch": 4.491939601721497,
      "grad_norm": 0.05844097211956978,
      "learning_rate": 5.080603982785032e-06,
      "loss": 0.0031,
      "step": 61580
    },
    {
      "epoch": 4.492669049529506,
      "grad_norm": 0.26034167408943176,
      "learning_rate": 5.073309504704939e-06,
      "loss": 0.0022,
      "step": 61590
    },
    {
      "epoch": 4.493398497337515,
      "grad_norm": 0.40483957529067993,
      "learning_rate": 5.066015026624845e-06,
      "loss": 0.0044,
      "step": 61600
    },
    {
      "epoch": 4.494127945145525,
      "grad_norm": 0.29583197832107544,
      "learning_rate": 5.058720548544752e-06,
      "loss": 0.0029,
      "step": 61610
    },
    {
      "epoch": 4.494857392953534,
      "grad_norm": 0.18762704730033875,
      "learning_rate": 5.051426070464658e-06,
      "loss": 0.0025,
      "step": 61620
    },
    {
      "epoch": 4.495586840761543,
      "grad_norm": 0.030992522835731506,
      "learning_rate": 5.044131592384565e-06,
      "loss": 0.0042,
      "step": 61630
    },
    {
      "epoch": 4.4963162885695525,
      "grad_norm": 0.20125146210193634,
      "learning_rate": 5.036837114304472e-06,
      "loss": 0.0027,
      "step": 61640
    },
    {
      "epoch": 4.497045736377562,
      "grad_norm": 0.26028376817703247,
      "learning_rate": 5.029542636224378e-06,
      "loss": 0.0028,
      "step": 61650
    },
    {
      "epoch": 4.4977751841855715,
      "grad_norm": 0.4081568419933319,
      "learning_rate": 5.022248158144285e-06,
      "loss": 0.0026,
      "step": 61660
    },
    {
      "epoch": 4.498504631993581,
      "grad_norm": 0.14864110946655273,
      "learning_rate": 5.0149536800641915e-06,
      "loss": 0.0023,
      "step": 61670
    },
    {
      "epoch": 4.499234079801591,
      "grad_norm": 0.15402746200561523,
      "learning_rate": 5.007659201984098e-06,
      "loss": 0.0025,
      "step": 61680
    },
    {
      "epoch": 4.4999635276096,
      "grad_norm": 0.10496523231267929,
      "learning_rate": 5.000364723904005e-06,
      "loss": 0.0028,
      "step": 61690
    },
    {
      "epoch": 4.500692975417609,
      "grad_norm": 0.3229735195636749,
      "learning_rate": 4.9930702458239115e-06,
      "loss": 0.0019,
      "step": 61700
    },
    {
      "epoch": 4.501422423225618,
      "grad_norm": 0.2329135537147522,
      "learning_rate": 4.985775767743818e-06,
      "loss": 0.0028,
      "step": 61710
    },
    {
      "epoch": 4.502151871033628,
      "grad_norm": 0.3230323791503906,
      "learning_rate": 4.978481289663725e-06,
      "loss": 0.0035,
      "step": 61720
    },
    {
      "epoch": 4.502881318841637,
      "grad_norm": 0.34007734060287476,
      "learning_rate": 4.971186811583632e-06,
      "loss": 0.0025,
      "step": 61730
    },
    {
      "epoch": 4.503610766649646,
      "grad_norm": 0.28885382413864136,
      "learning_rate": 4.9638923335035374e-06,
      "loss": 0.0036,
      "step": 61740
    },
    {
      "epoch": 4.504340214457655,
      "grad_norm": 0.08866801857948303,
      "learning_rate": 4.956597855423445e-06,
      "loss": 0.0023,
      "step": 61750
    },
    {
      "epoch": 4.505069662265665,
      "grad_norm": 0.19667239487171173,
      "learning_rate": 4.949303377343352e-06,
      "loss": 0.0028,
      "step": 61760
    },
    {
      "epoch": 4.505799110073674,
      "grad_norm": 0.15193627774715424,
      "learning_rate": 4.9420088992632575e-06,
      "loss": 0.0027,
      "step": 61770
    },
    {
      "epoch": 4.506528557881683,
      "grad_norm": 0.01612578146159649,
      "learning_rate": 4.934714421183165e-06,
      "loss": 0.0035,
      "step": 61780
    },
    {
      "epoch": 4.5072580056896925,
      "grad_norm": 0.18626971542835236,
      "learning_rate": 4.927419943103071e-06,
      "loss": 0.0031,
      "step": 61790
    },
    {
      "epoch": 4.5079874534977025,
      "grad_norm": 0.059590164572000504,
      "learning_rate": 4.9201254650229775e-06,
      "loss": 0.0017,
      "step": 61800
    },
    {
      "epoch": 4.508716901305712,
      "grad_norm": 0.12154707312583923,
      "learning_rate": 4.912830986942884e-06,
      "loss": 0.0024,
      "step": 61810
    },
    {
      "epoch": 4.509446349113721,
      "grad_norm": 0.20129452645778656,
      "learning_rate": 4.905536508862791e-06,
      "loss": 0.0029,
      "step": 61820
    },
    {
      "epoch": 4.510175796921731,
      "grad_norm": 0.3443017899990082,
      "learning_rate": 4.8982420307826984e-06,
      "loss": 0.0024,
      "step": 61830
    },
    {
      "epoch": 4.51090524472974,
      "grad_norm": 0.16454805433750153,
      "learning_rate": 4.890947552702604e-06,
      "loss": 0.0023,
      "step": 61840
    },
    {
      "epoch": 4.511634692537749,
      "grad_norm": 0.3462715744972229,
      "learning_rate": 4.883653074622511e-06,
      "loss": 0.004,
      "step": 61850
    },
    {
      "epoch": 4.512364140345758,
      "grad_norm": 0.4325999915599823,
      "learning_rate": 4.876358596542418e-06,
      "loss": 0.0029,
      "step": 61860
    },
    {
      "epoch": 4.513093588153768,
      "grad_norm": 0.20939962565898895,
      "learning_rate": 4.869064118462324e-06,
      "loss": 0.0029,
      "step": 61870
    },
    {
      "epoch": 4.513823035961777,
      "grad_norm": 0.1446649432182312,
      "learning_rate": 4.861769640382231e-06,
      "loss": 0.0034,
      "step": 61880
    },
    {
      "epoch": 4.514552483769786,
      "grad_norm": 0.03065425157546997,
      "learning_rate": 4.854475162302138e-06,
      "loss": 0.0031,
      "step": 61890
    },
    {
      "epoch": 4.515281931577795,
      "grad_norm": 0.2310192734003067,
      "learning_rate": 4.847180684222044e-06,
      "loss": 0.0035,
      "step": 61900
    },
    {
      "epoch": 4.516011379385805,
      "grad_norm": 0.5196675062179565,
      "learning_rate": 4.83988620614195e-06,
      "loss": 0.0038,
      "step": 61910
    },
    {
      "epoch": 4.516740827193814,
      "grad_norm": 0.202551931142807,
      "learning_rate": 4.832591728061858e-06,
      "loss": 0.003,
      "step": 61920
    },
    {
      "epoch": 4.517470275001823,
      "grad_norm": 0.11507762968540192,
      "learning_rate": 4.8252972499817636e-06,
      "loss": 0.0038,
      "step": 61930
    },
    {
      "epoch": 4.5181997228098325,
      "grad_norm": 0.21838146448135376,
      "learning_rate": 4.818002771901671e-06,
      "loss": 0.0028,
      "step": 61940
    },
    {
      "epoch": 4.5189291706178425,
      "grad_norm": 0.17464733123779297,
      "learning_rate": 4.810708293821578e-06,
      "loss": 0.0036,
      "step": 61950
    },
    {
      "epoch": 4.519658618425852,
      "grad_norm": 0.20408502221107483,
      "learning_rate": 4.803413815741484e-06,
      "loss": 0.0033,
      "step": 61960
    },
    {
      "epoch": 4.520388066233861,
      "grad_norm": 0.08668337762355804,
      "learning_rate": 4.796119337661391e-06,
      "loss": 0.0028,
      "step": 61970
    },
    {
      "epoch": 4.521117514041871,
      "grad_norm": 0.11579496413469315,
      "learning_rate": 4.788824859581297e-06,
      "loss": 0.0022,
      "step": 61980
    },
    {
      "epoch": 4.52184696184988,
      "grad_norm": 0.3458399772644043,
      "learning_rate": 4.781530381501204e-06,
      "loss": 0.003,
      "step": 61990
    },
    {
      "epoch": 4.522576409657889,
      "grad_norm": 0.06649184972047806,
      "learning_rate": 4.77423590342111e-06,
      "loss": 0.0043,
      "step": 62000
    },
    {
      "epoch": 4.523305857465898,
      "grad_norm": 0.3184908330440521,
      "learning_rate": 4.766941425341017e-06,
      "loss": 0.0024,
      "step": 62010
    },
    {
      "epoch": 4.524035305273908,
      "grad_norm": 0.2906593978404999,
      "learning_rate": 4.759646947260924e-06,
      "loss": 0.0021,
      "step": 62020
    },
    {
      "epoch": 4.524764753081917,
      "grad_norm": 0.060059234499931335,
      "learning_rate": 4.75235246918083e-06,
      "loss": 0.0023,
      "step": 62030
    },
    {
      "epoch": 4.525494200889926,
      "grad_norm": 0.17978011071681976,
      "learning_rate": 4.745057991100737e-06,
      "loss": 0.0036,
      "step": 62040
    },
    {
      "epoch": 4.526223648697936,
      "grad_norm": 0.008378886617720127,
      "learning_rate": 4.737763513020644e-06,
      "loss": 0.0021,
      "step": 62050
    },
    {
      "epoch": 4.526953096505945,
      "grad_norm": 0.03087025322020054,
      "learning_rate": 4.7304690349405504e-06,
      "loss": 0.0021,
      "step": 62060
    },
    {
      "epoch": 4.527682544313954,
      "grad_norm": 0.2616634666919708,
      "learning_rate": 4.723174556860457e-06,
      "loss": 0.0029,
      "step": 62070
    },
    {
      "epoch": 4.528411992121963,
      "grad_norm": 0.030385160818696022,
      "learning_rate": 4.715880078780364e-06,
      "loss": 0.0024,
      "step": 62080
    },
    {
      "epoch": 4.5291414399299725,
      "grad_norm": 0.03067759796977043,
      "learning_rate": 4.7085856007002705e-06,
      "loss": 0.0019,
      "step": 62090
    },
    {
      "epoch": 4.5298708877379825,
      "grad_norm": 0.07247443497180939,
      "learning_rate": 4.701291122620176e-06,
      "loss": 0.0026,
      "step": 62100
    },
    {
      "epoch": 4.530600335545992,
      "grad_norm": 0.5261245965957642,
      "learning_rate": 4.693996644540084e-06,
      "loss": 0.0031,
      "step": 62110
    },
    {
      "epoch": 4.531329783354001,
      "grad_norm": 0.2309042364358902,
      "learning_rate": 4.68670216645999e-06,
      "loss": 0.0016,
      "step": 62120
    },
    {
      "epoch": 4.532059231162011,
      "grad_norm": 0.14767351746559143,
      "learning_rate": 4.679407688379896e-06,
      "loss": 0.0036,
      "step": 62130
    },
    {
      "epoch": 4.53278867897002,
      "grad_norm": 0.346123605966568,
      "learning_rate": 4.672113210299803e-06,
      "loss": 0.0028,
      "step": 62140
    },
    {
      "epoch": 4.533518126778029,
      "grad_norm": 0.2874910831451416,
      "learning_rate": 4.66481873221971e-06,
      "loss": 0.0033,
      "step": 62150
    },
    {
      "epoch": 4.534247574586038,
      "grad_norm": 0.34565234184265137,
      "learning_rate": 4.657524254139616e-06,
      "loss": 0.0038,
      "step": 62160
    },
    {
      "epoch": 4.534977022394048,
      "grad_norm": 0.061111461371183395,
      "learning_rate": 4.650229776059523e-06,
      "loss": 0.0041,
      "step": 62170
    },
    {
      "epoch": 4.535706470202057,
      "grad_norm": 0.17422017455101013,
      "learning_rate": 4.64293529797943e-06,
      "loss": 0.0027,
      "step": 62180
    },
    {
      "epoch": 4.536435918010066,
      "grad_norm": 0.009266674518585205,
      "learning_rate": 4.6356408198993365e-06,
      "loss": 0.0029,
      "step": 62190
    },
    {
      "epoch": 4.537165365818076,
      "grad_norm": 0.029892249032855034,
      "learning_rate": 4.628346341819243e-06,
      "loss": 0.0027,
      "step": 62200
    },
    {
      "epoch": 4.537894813626085,
      "grad_norm": 0.011866573244333267,
      "learning_rate": 4.62105186373915e-06,
      "loss": 0.0036,
      "step": 62210
    },
    {
      "epoch": 4.538624261434094,
      "grad_norm": 0.17284469306468964,
      "learning_rate": 4.6137573856590565e-06,
      "loss": 0.0045,
      "step": 62220
    },
    {
      "epoch": 4.5393537092421035,
      "grad_norm": 0.20322759449481964,
      "learning_rate": 4.606462907578963e-06,
      "loss": 0.003,
      "step": 62230
    },
    {
      "epoch": 4.5400831570501134,
      "grad_norm": 0.058333978056907654,
      "learning_rate": 4.599168429498869e-06,
      "loss": 0.0031,
      "step": 62240
    },
    {
      "epoch": 4.5408126048581225,
      "grad_norm": 0.24120984971523285,
      "learning_rate": 4.5918739514187766e-06,
      "loss": 0.0036,
      "step": 62250
    },
    {
      "epoch": 4.541542052666132,
      "grad_norm": 0.20411871373653412,
      "learning_rate": 4.584579473338682e-06,
      "loss": 0.0034,
      "step": 62260
    },
    {
      "epoch": 4.542271500474141,
      "grad_norm": 0.11631946265697479,
      "learning_rate": 4.577284995258589e-06,
      "loss": 0.0022,
      "step": 62270
    },
    {
      "epoch": 4.543000948282151,
      "grad_norm": 0.11718636751174927,
      "learning_rate": 4.569990517178497e-06,
      "loss": 0.0027,
      "step": 62280
    },
    {
      "epoch": 4.54373039609016,
      "grad_norm": 0.09092135727405548,
      "learning_rate": 4.5626960390984024e-06,
      "loss": 0.0025,
      "step": 62290
    },
    {
      "epoch": 4.544459843898169,
      "grad_norm": 0.1727958768606186,
      "learning_rate": 4.55540156101831e-06,
      "loss": 0.0023,
      "step": 62300
    },
    {
      "epoch": 4.545189291706178,
      "grad_norm": 0.46586892008781433,
      "learning_rate": 4.548107082938216e-06,
      "loss": 0.0039,
      "step": 62310
    },
    {
      "epoch": 4.545918739514188,
      "grad_norm": 0.17347727715969086,
      "learning_rate": 4.5408126048581225e-06,
      "loss": 0.0036,
      "step": 62320
    },
    {
      "epoch": 4.546648187322197,
      "grad_norm": 0.03366726264357567,
      "learning_rate": 4.533518126778029e-06,
      "loss": 0.0038,
      "step": 62330
    },
    {
      "epoch": 4.547377635130206,
      "grad_norm": 0.2881706655025482,
      "learning_rate": 4.526223648697936e-06,
      "loss": 0.0016,
      "step": 62340
    },
    {
      "epoch": 4.548107082938216,
      "grad_norm": 0.2598467171192169,
      "learning_rate": 4.5189291706178425e-06,
      "loss": 0.0038,
      "step": 62350
    },
    {
      "epoch": 4.548836530746225,
      "grad_norm": 0.17379510402679443,
      "learning_rate": 4.511634692537749e-06,
      "loss": 0.0033,
      "step": 62360
    },
    {
      "epoch": 4.549565978554234,
      "grad_norm": 0.28908103704452515,
      "learning_rate": 4.504340214457656e-06,
      "loss": 0.003,
      "step": 62370
    },
    {
      "epoch": 4.5502954263622435,
      "grad_norm": 0.14308962225914001,
      "learning_rate": 4.497045736377562e-06,
      "loss": 0.0025,
      "step": 62380
    },
    {
      "epoch": 4.5510248741702535,
      "grad_norm": 0.26598861813545227,
      "learning_rate": 4.489751258297469e-06,
      "loss": 0.0021,
      "step": 62390
    },
    {
      "epoch": 4.551754321978263,
      "grad_norm": 0.02217177487909794,
      "learning_rate": 4.482456780217376e-06,
      "loss": 0.0022,
      "step": 62400
    },
    {
      "epoch": 4.552483769786272,
      "grad_norm": 0.20366492867469788,
      "learning_rate": 4.475162302137282e-06,
      "loss": 0.0021,
      "step": 62410
    },
    {
      "epoch": 4.553213217594281,
      "grad_norm": 0.00816980842500925,
      "learning_rate": 4.467867824057189e-06,
      "loss": 0.0026,
      "step": 62420
    },
    {
      "epoch": 4.553942665402291,
      "grad_norm": 0.2893540859222412,
      "learning_rate": 4.460573345977095e-06,
      "loss": 0.0027,
      "step": 62430
    },
    {
      "epoch": 4.5546721132103,
      "grad_norm": 0.25969138741493225,
      "learning_rate": 4.453278867897003e-06,
      "loss": 0.003,
      "step": 62440
    },
    {
      "epoch": 4.555401561018309,
      "grad_norm": 0.34535712003707886,
      "learning_rate": 4.4459843898169085e-06,
      "loss": 0.0025,
      "step": 62450
    },
    {
      "epoch": 4.556131008826318,
      "grad_norm": 0.11493023484945297,
      "learning_rate": 4.438689911736815e-06,
      "loss": 0.0034,
      "step": 62460
    },
    {
      "epoch": 4.556860456634328,
      "grad_norm": 0.11638516187667847,
      "learning_rate": 4.431395433656723e-06,
      "loss": 0.0032,
      "step": 62470
    },
    {
      "epoch": 4.557589904442337,
      "grad_norm": 0.3461917042732239,
      "learning_rate": 4.424100955576629e-06,
      "loss": 0.0017,
      "step": 62480
    },
    {
      "epoch": 4.558319352250346,
      "grad_norm": 0.6676681041717529,
      "learning_rate": 4.416806477496535e-06,
      "loss": 0.0029,
      "step": 62490
    },
    {
      "epoch": 4.559048800058356,
      "grad_norm": 0.06068772077560425,
      "learning_rate": 4.409511999416442e-06,
      "loss": 0.0016,
      "step": 62500
    },
    {
      "epoch": 4.559778247866365,
      "grad_norm": 0.34594056010246277,
      "learning_rate": 4.402217521336349e-06,
      "loss": 0.0029,
      "step": 62510
    },
    {
      "epoch": 4.560507695674374,
      "grad_norm": 0.14423492550849915,
      "learning_rate": 4.394923043256255e-06,
      "loss": 0.0026,
      "step": 62520
    },
    {
      "epoch": 4.5612371434823835,
      "grad_norm": 0.029966147616505623,
      "learning_rate": 4.387628565176162e-06,
      "loss": 0.0025,
      "step": 62530
    },
    {
      "epoch": 4.5619665912903935,
      "grad_norm": 0.17248938977718353,
      "learning_rate": 4.380334087096069e-06,
      "loss": 0.0028,
      "step": 62540
    },
    {
      "epoch": 4.562696039098403,
      "grad_norm": 0.4041289687156677,
      "learning_rate": 4.373039609015975e-06,
      "loss": 0.0031,
      "step": 62550
    },
    {
      "epoch": 4.563425486906412,
      "grad_norm": 0.00824438501149416,
      "learning_rate": 4.365745130935882e-06,
      "loss": 0.0024,
      "step": 62560
    },
    {
      "epoch": 4.564154934714421,
      "grad_norm": 0.10600876063108444,
      "learning_rate": 4.358450652855788e-06,
      "loss": 0.0039,
      "step": 62570
    },
    {
      "epoch": 4.564884382522431,
      "grad_norm": 0.05977241322398186,
      "learning_rate": 4.351156174775695e-06,
      "loss": 0.0029,
      "step": 62580
    },
    {
      "epoch": 4.56561383033044,
      "grad_norm": 0.3544616401195526,
      "learning_rate": 4.343861696695602e-06,
      "loss": 0.003,
      "step": 62590
    },
    {
      "epoch": 4.566343278138449,
      "grad_norm": 0.10520585626363754,
      "learning_rate": 4.336567218615508e-06,
      "loss": 0.0021,
      "step": 62600
    },
    {
      "epoch": 4.567072725946458,
      "grad_norm": 0.23108325898647308,
      "learning_rate": 4.3292727405354155e-06,
      "loss": 0.0029,
      "step": 62610
    },
    {
      "epoch": 4.567802173754468,
      "grad_norm": 0.10811301320791245,
      "learning_rate": 4.321978262455321e-06,
      "loss": 0.0029,
      "step": 62620
    },
    {
      "epoch": 4.568531621562477,
      "grad_norm": 0.18318577110767365,
      "learning_rate": 4.314683784375228e-06,
      "loss": 0.0039,
      "step": 62630
    },
    {
      "epoch": 4.569261069370486,
      "grad_norm": 0.11266880482435226,
      "learning_rate": 4.307389306295135e-06,
      "loss": 0.0026,
      "step": 62640
    },
    {
      "epoch": 4.569990517178496,
      "grad_norm": 0.3466740548610687,
      "learning_rate": 4.300094828215041e-06,
      "loss": 0.0026,
      "step": 62650
    },
    {
      "epoch": 4.570719964986505,
      "grad_norm": 0.2709999978542328,
      "learning_rate": 4.292800350134948e-06,
      "loss": 0.0018,
      "step": 62660
    },
    {
      "epoch": 4.5714494127945144,
      "grad_norm": 0.11978436261415482,
      "learning_rate": 4.285505872054855e-06,
      "loss": 0.003,
      "step": 62670
    },
    {
      "epoch": 4.5721788606025235,
      "grad_norm": 0.16148409247398376,
      "learning_rate": 4.278211393974761e-06,
      "loss": 0.0027,
      "step": 62680
    },
    {
      "epoch": 4.5729083084105335,
      "grad_norm": 0.2591034173965454,
      "learning_rate": 4.270916915894668e-06,
      "loss": 0.0023,
      "step": 62690
    },
    {
      "epoch": 4.573637756218543,
      "grad_norm": 0.26395460963249207,
      "learning_rate": 4.263622437814575e-06,
      "loss": 0.003,
      "step": 62700
    },
    {
      "epoch": 4.574367204026552,
      "grad_norm": 0.2033860981464386,
      "learning_rate": 4.256327959734481e-06,
      "loss": 0.0029,
      "step": 62710
    },
    {
      "epoch": 4.575096651834562,
      "grad_norm": 0.20519427955150604,
      "learning_rate": 4.249033481654388e-06,
      "loss": 0.0024,
      "step": 62720
    },
    {
      "epoch": 4.575826099642571,
      "grad_norm": 0.08693614602088928,
      "learning_rate": 4.241739003574295e-06,
      "loss": 0.0029,
      "step": 62730
    },
    {
      "epoch": 4.57655554745058,
      "grad_norm": 0.03146686032414436,
      "learning_rate": 4.234444525494201e-06,
      "loss": 0.0027,
      "step": 62740
    },
    {
      "epoch": 4.577284995258589,
      "grad_norm": 0.09031091630458832,
      "learning_rate": 4.227150047414108e-06,
      "loss": 0.0021,
      "step": 62750
    },
    {
      "epoch": 4.578014443066598,
      "grad_norm": 0.02975582517683506,
      "learning_rate": 4.219855569334014e-06,
      "loss": 0.0021,
      "step": 62760
    },
    {
      "epoch": 4.578743890874608,
      "grad_norm": 0.2824820578098297,
      "learning_rate": 4.212561091253921e-06,
      "loss": 0.0018,
      "step": 62770
    },
    {
      "epoch": 4.579473338682617,
      "grad_norm": 0.0587947741150856,
      "learning_rate": 4.205266613173827e-06,
      "loss": 0.0031,
      "step": 62780
    },
    {
      "epoch": 4.580202786490626,
      "grad_norm": 0.11679474264383316,
      "learning_rate": 4.197972135093734e-06,
      "loss": 0.0025,
      "step": 62790
    },
    {
      "epoch": 4.580932234298636,
      "grad_norm": 0.11654435843229294,
      "learning_rate": 4.190677657013642e-06,
      "loss": 0.0037,
      "step": 62800
    },
    {
      "epoch": 4.581661682106645,
      "grad_norm": 0.032495662569999695,
      "learning_rate": 4.183383178933547e-06,
      "loss": 0.0025,
      "step": 62810
    },
    {
      "epoch": 4.5823911299146545,
      "grad_norm": 0.23086944222450256,
      "learning_rate": 4.176088700853454e-06,
      "loss": 0.0026,
      "step": 62820
    },
    {
      "epoch": 4.583120577722664,
      "grad_norm": 0.18668977916240692,
      "learning_rate": 4.168794222773361e-06,
      "loss": 0.0035,
      "step": 62830
    },
    {
      "epoch": 4.5838500255306736,
      "grad_norm": 0.146146759390831,
      "learning_rate": 4.1614997446932675e-06,
      "loss": 0.002,
      "step": 62840
    },
    {
      "epoch": 4.584579473338683,
      "grad_norm": 0.28811076283454895,
      "learning_rate": 4.154205266613174e-06,
      "loss": 0.0021,
      "step": 62850
    },
    {
      "epoch": 4.585308921146692,
      "grad_norm": 0.1442268043756485,
      "learning_rate": 4.146910788533081e-06,
      "loss": 0.0045,
      "step": 62860
    },
    {
      "epoch": 4.586038368954702,
      "grad_norm": 0.08723149448633194,
      "learning_rate": 4.1396163104529875e-06,
      "loss": 0.0031,
      "step": 62870
    },
    {
      "epoch": 4.586767816762711,
      "grad_norm": 0.2991972863674164,
      "learning_rate": 4.132321832372893e-06,
      "loss": 0.0026,
      "step": 62880
    },
    {
      "epoch": 4.58749726457072,
      "grad_norm": 0.31743940711021423,
      "learning_rate": 4.125027354292801e-06,
      "loss": 0.0033,
      "step": 62890
    },
    {
      "epoch": 4.588226712378729,
      "grad_norm": 0.23022112250328064,
      "learning_rate": 4.117732876212707e-06,
      "loss": 0.0024,
      "step": 62900
    },
    {
      "epoch": 4.588956160186739,
      "grad_norm": 0.16958728432655334,
      "learning_rate": 4.110438398132613e-06,
      "loss": 0.0026,
      "step": 62910
    },
    {
      "epoch": 4.589685607994748,
      "grad_norm": 0.030206624418497086,
      "learning_rate": 4.103143920052521e-06,
      "loss": 0.003,
      "step": 62920
    },
    {
      "epoch": 4.590415055802757,
      "grad_norm": 0.17375768721103668,
      "learning_rate": 4.095849441972427e-06,
      "loss": 0.0018,
      "step": 62930
    },
    {
      "epoch": 4.591144503610766,
      "grad_norm": 0.03610319271683693,
      "learning_rate": 4.088554963892334e-06,
      "loss": 0.0022,
      "step": 62940
    },
    {
      "epoch": 4.591873951418776,
      "grad_norm": 0.011123349890112877,
      "learning_rate": 4.08126048581224e-06,
      "loss": 0.0021,
      "step": 62950
    },
    {
      "epoch": 4.592603399226785,
      "grad_norm": 0.05784530192613602,
      "learning_rate": 4.073966007732147e-06,
      "loss": 0.0027,
      "step": 62960
    },
    {
      "epoch": 4.5933328470347945,
      "grad_norm": 0.23109152913093567,
      "learning_rate": 4.0666715296520535e-06,
      "loss": 0.0036,
      "step": 62970
    },
    {
      "epoch": 4.594062294842804,
      "grad_norm": 0.03296622261404991,
      "learning_rate": 4.05937705157196e-06,
      "loss": 0.002,
      "step": 62980
    },
    {
      "epoch": 4.594791742650814,
      "grad_norm": 0.17267882823944092,
      "learning_rate": 4.052082573491867e-06,
      "loss": 0.0025,
      "step": 62990
    },
    {
      "epoch": 4.595521190458823,
      "grad_norm": 0.20584669709205627,
      "learning_rate": 4.0447880954117735e-06,
      "loss": 0.0022,
      "step": 63000
    },
    {
      "epoch": 4.596250638266832,
      "grad_norm": 0.30554062128067017,
      "learning_rate": 4.03749361733168e-06,
      "loss": 0.0032,
      "step": 63010
    },
    {
      "epoch": 4.596980086074842,
      "grad_norm": 0.13640819489955902,
      "learning_rate": 4.030199139251586e-06,
      "loss": 0.0025,
      "step": 63020
    },
    {
      "epoch": 4.597709533882851,
      "grad_norm": 0.26408320665359497,
      "learning_rate": 4.022904661171494e-06,
      "loss": 0.0031,
      "step": 63030
    },
    {
      "epoch": 4.59843898169086,
      "grad_norm": 0.21461358666419983,
      "learning_rate": 4.0156101830914e-06,
      "loss": 0.0029,
      "step": 63040
    },
    {
      "epoch": 4.599168429498869,
      "grad_norm": 0.3719329535961151,
      "learning_rate": 4.008315705011307e-06,
      "loss": 0.003,
      "step": 63050
    },
    {
      "epoch": 4.599897877306879,
      "grad_norm": 0.375190794467926,
      "learning_rate": 4.001021226931214e-06,
      "loss": 0.0024,
      "step": 63060
    },
    {
      "epoch": 4.600627325114888,
      "grad_norm": 0.13732720911502838,
      "learning_rate": 3.9937267488511195e-06,
      "loss": 0.0029,
      "step": 63070
    },
    {
      "epoch": 4.601356772922897,
      "grad_norm": 0.2888718843460083,
      "learning_rate": 3.986432270771027e-06,
      "loss": 0.003,
      "step": 63080
    },
    {
      "epoch": 4.602086220730906,
      "grad_norm": 0.05845746397972107,
      "learning_rate": 3.979137792690933e-06,
      "loss": 0.0025,
      "step": 63090
    },
    {
      "epoch": 4.602815668538916,
      "grad_norm": 0.4712893068790436,
      "learning_rate": 3.9718433146108395e-06,
      "loss": 0.0037,
      "step": 63100
    },
    {
      "epoch": 4.603545116346925,
      "grad_norm": 0.21557451784610748,
      "learning_rate": 3.964548836530746e-06,
      "loss": 0.0022,
      "step": 63110
    },
    {
      "epoch": 4.6042745641549345,
      "grad_norm": 0.5806098580360413,
      "learning_rate": 3.957254358450653e-06,
      "loss": 0.0023,
      "step": 63120
    },
    {
      "epoch": 4.605004011962944,
      "grad_norm": 0.08619607985019684,
      "learning_rate": 3.94995988037056e-06,
      "loss": 0.0019,
      "step": 63130
    },
    {
      "epoch": 4.605733459770954,
      "grad_norm": 0.23064367473125458,
      "learning_rate": 3.942665402290466e-06,
      "loss": 0.0033,
      "step": 63140
    },
    {
      "epoch": 4.606462907578963,
      "grad_norm": 0.14459693431854248,
      "learning_rate": 3.935370924210373e-06,
      "loss": 0.0024,
      "step": 63150
    },
    {
      "epoch": 4.607192355386972,
      "grad_norm": 0.1448252946138382,
      "learning_rate": 3.92807644613028e-06,
      "loss": 0.0026,
      "step": 63160
    },
    {
      "epoch": 4.607921803194982,
      "grad_norm": 0.12685087323188782,
      "learning_rate": 3.920781968050186e-06,
      "loss": 0.0029,
      "step": 63170
    },
    {
      "epoch": 4.608651251002991,
      "grad_norm": 0.26391786336898804,
      "learning_rate": 3.913487489970093e-06,
      "loss": 0.0042,
      "step": 63180
    },
    {
      "epoch": 4.609380698811,
      "grad_norm": 0.10090283304452896,
      "learning_rate": 3.90619301189e-06,
      "loss": 0.0025,
      "step": 63190
    },
    {
      "epoch": 4.610110146619009,
      "grad_norm": 0.05789435654878616,
      "learning_rate": 3.898898533809906e-06,
      "loss": 0.0026,
      "step": 63200
    },
    {
      "epoch": 4.610839594427019,
      "grad_norm": 0.17308884859085083,
      "learning_rate": 3.891604055729812e-06,
      "loss": 0.0025,
      "step": 63210
    },
    {
      "epoch": 4.611569042235028,
      "grad_norm": 0.2870166301727295,
      "learning_rate": 3.88430957764972e-06,
      "loss": 0.0022,
      "step": 63220
    },
    {
      "epoch": 4.612298490043037,
      "grad_norm": 0.1455317735671997,
      "learning_rate": 3.8770150995696256e-06,
      "loss": 0.0026,
      "step": 63230
    },
    {
      "epoch": 4.613027937851047,
      "grad_norm": 0.08714218437671661,
      "learning_rate": 3.869720621489532e-06,
      "loss": 0.0021,
      "step": 63240
    },
    {
      "epoch": 4.613757385659056,
      "grad_norm": 0.08704490959644318,
      "learning_rate": 3.86242614340944e-06,
      "loss": 0.0026,
      "step": 63250
    },
    {
      "epoch": 4.6144868334670655,
      "grad_norm": 0.6270487308502197,
      "learning_rate": 3.855131665329346e-06,
      "loss": 0.0027,
      "step": 63260
    },
    {
      "epoch": 4.6152162812750746,
      "grad_norm": 0.23112882673740387,
      "learning_rate": 3.847837187249252e-06,
      "loss": 0.0021,
      "step": 63270
    },
    {
      "epoch": 4.615945729083084,
      "grad_norm": 0.10262758284807205,
      "learning_rate": 3.840542709169159e-06,
      "loss": 0.0033,
      "step": 63280
    },
    {
      "epoch": 4.616675176891094,
      "grad_norm": 0.070772185921669,
      "learning_rate": 3.833248231089066e-06,
      "loss": 0.0017,
      "step": 63290
    },
    {
      "epoch": 4.617404624699103,
      "grad_norm": 0.18840962648391724,
      "learning_rate": 3.825953753008972e-06,
      "loss": 0.003,
      "step": 63300
    },
    {
      "epoch": 4.618134072507112,
      "grad_norm": 0.07004400342702866,
      "learning_rate": 3.818659274928879e-06,
      "loss": 0.0036,
      "step": 63310
    },
    {
      "epoch": 4.618863520315122,
      "grad_norm": 0.1409449577331543,
      "learning_rate": 3.8113647968487853e-06,
      "loss": 0.0027,
      "step": 63320
    },
    {
      "epoch": 4.619592968123131,
      "grad_norm": 0.36650586128234863,
      "learning_rate": 3.8040703187686924e-06,
      "loss": 0.0024,
      "step": 63330
    },
    {
      "epoch": 4.62032241593114,
      "grad_norm": 0.08841992914676666,
      "learning_rate": 3.796775840688599e-06,
      "loss": 0.0023,
      "step": 63340
    },
    {
      "epoch": 4.621051863739149,
      "grad_norm": 0.05928587168455124,
      "learning_rate": 3.7894813626085053e-06,
      "loss": 0.003,
      "step": 63350
    },
    {
      "epoch": 4.621781311547159,
      "grad_norm": 0.05471951141953468,
      "learning_rate": 3.7821868845284124e-06,
      "loss": 0.0019,
      "step": 63360
    },
    {
      "epoch": 4.622510759355168,
      "grad_norm": 0.08935092389583588,
      "learning_rate": 3.7748924064483187e-06,
      "loss": 0.0029,
      "step": 63370
    },
    {
      "epoch": 4.623240207163177,
      "grad_norm": 0.07580451667308807,
      "learning_rate": 3.767597928368225e-06,
      "loss": 0.0031,
      "step": 63380
    },
    {
      "epoch": 4.623969654971187,
      "grad_norm": 0.05877266079187393,
      "learning_rate": 3.760303450288132e-06,
      "loss": 0.0035,
      "step": 63390
    },
    {
      "epoch": 4.624699102779196,
      "grad_norm": 0.0301845520734787,
      "learning_rate": 3.7530089722080387e-06,
      "loss": 0.0026,
      "step": 63400
    },
    {
      "epoch": 4.6254285505872055,
      "grad_norm": 0.03040994703769684,
      "learning_rate": 3.745714494127945e-06,
      "loss": 0.0032,
      "step": 63410
    },
    {
      "epoch": 4.626157998395215,
      "grad_norm": 0.1725027710199356,
      "learning_rate": 3.738420016047852e-06,
      "loss": 0.0028,
      "step": 63420
    },
    {
      "epoch": 4.626887446203224,
      "grad_norm": 0.24497032165527344,
      "learning_rate": 3.7311255379677584e-06,
      "loss": 0.003,
      "step": 63430
    },
    {
      "epoch": 4.627616894011234,
      "grad_norm": 0.37436768412590027,
      "learning_rate": 3.7238310598876655e-06,
      "loss": 0.0027,
      "step": 63440
    },
    {
      "epoch": 4.628346341819243,
      "grad_norm": 0.11501698940992355,
      "learning_rate": 3.7165365818075717e-06,
      "loss": 0.002,
      "step": 63450
    },
    {
      "epoch": 4.629075789627252,
      "grad_norm": 0.14954113960266113,
      "learning_rate": 3.7092421037274784e-06,
      "loss": 0.0027,
      "step": 63460
    },
    {
      "epoch": 4.629805237435262,
      "grad_norm": 0.18267400562763214,
      "learning_rate": 3.7019476256473855e-06,
      "loss": 0.0024,
      "step": 63470
    },
    {
      "epoch": 4.630534685243271,
      "grad_norm": 0.11887966841459274,
      "learning_rate": 3.6946531475672918e-06,
      "loss": 0.0029,
      "step": 63480
    },
    {
      "epoch": 4.63126413305128,
      "grad_norm": 0.017416244372725487,
      "learning_rate": 3.687358669487198e-06,
      "loss": 0.0031,
      "step": 63490
    },
    {
      "epoch": 4.631993580859289,
      "grad_norm": 0.05928819626569748,
      "learning_rate": 3.680064191407105e-06,
      "loss": 0.0037,
      "step": 63500
    },
    {
      "epoch": 4.632723028667299,
      "grad_norm": 0.17438560724258423,
      "learning_rate": 3.6727697133270114e-06,
      "loss": 0.0033,
      "step": 63510
    },
    {
      "epoch": 4.633452476475308,
      "grad_norm": 0.2805712819099426,
      "learning_rate": 3.665475235246918e-06,
      "loss": 0.0018,
      "step": 63520
    },
    {
      "epoch": 4.634181924283317,
      "grad_norm": 0.30073782801628113,
      "learning_rate": 3.658180757166825e-06,
      "loss": 0.0026,
      "step": 63530
    },
    {
      "epoch": 4.634911372091327,
      "grad_norm": 0.08728814870119095,
      "learning_rate": 3.6508862790867315e-06,
      "loss": 0.0046,
      "step": 63540
    },
    {
      "epoch": 4.635640819899336,
      "grad_norm": 0.0311910230666399,
      "learning_rate": 3.6435918010066386e-06,
      "loss": 0.0035,
      "step": 63550
    },
    {
      "epoch": 4.6363702677073455,
      "grad_norm": 0.28317955136299133,
      "learning_rate": 3.636297322926545e-06,
      "loss": 0.0025,
      "step": 63560
    },
    {
      "epoch": 4.637099715515355,
      "grad_norm": 0.1730758249759674,
      "learning_rate": 3.629002844846451e-06,
      "loss": 0.0024,
      "step": 63570
    },
    {
      "epoch": 4.637829163323365,
      "grad_norm": 0.26540422439575195,
      "learning_rate": 3.621708366766358e-06,
      "loss": 0.0036,
      "step": 63580
    },
    {
      "epoch": 4.638558611131374,
      "grad_norm": 0.1158311739563942,
      "learning_rate": 3.614413888686265e-06,
      "loss": 0.0024,
      "step": 63590
    },
    {
      "epoch": 4.639288058939383,
      "grad_norm": 0.2886790931224823,
      "learning_rate": 3.607119410606171e-06,
      "loss": 0.0037,
      "step": 63600
    },
    {
      "epoch": 4.640017506747392,
      "grad_norm": 0.05966994911432266,
      "learning_rate": 3.5998249325260782e-06,
      "loss": 0.0023,
      "step": 63610
    },
    {
      "epoch": 4.640746954555402,
      "grad_norm": 0.08637858927249908,
      "learning_rate": 3.5925304544459845e-06,
      "loss": 0.0034,
      "step": 63620
    },
    {
      "epoch": 4.641476402363411,
      "grad_norm": 0.17255881428718567,
      "learning_rate": 3.5852359763658908e-06,
      "loss": 0.0034,
      "step": 63630
    },
    {
      "epoch": 4.64220585017142,
      "grad_norm": 0.05881885439157486,
      "learning_rate": 3.577941498285798e-06,
      "loss": 0.0029,
      "step": 63640
    },
    {
      "epoch": 4.642935297979429,
      "grad_norm": 0.024006163701415062,
      "learning_rate": 3.5706470202057045e-06,
      "loss": 0.0021,
      "step": 63650
    },
    {
      "epoch": 4.643664745787439,
      "grad_norm": 0.08718539029359818,
      "learning_rate": 3.5633525421256112e-06,
      "loss": 0.0018,
      "step": 63660
    },
    {
      "epoch": 4.644394193595448,
      "grad_norm": 0.21429969370365143,
      "learning_rate": 3.556058064045518e-06,
      "loss": 0.0032,
      "step": 63670
    },
    {
      "epoch": 4.645123641403457,
      "grad_norm": 0.17309342324733734,
      "learning_rate": 3.548763585965424e-06,
      "loss": 0.0037,
      "step": 63680
    },
    {
      "epoch": 4.645853089211467,
      "grad_norm": 0.4803803265094757,
      "learning_rate": 3.5414691078853313e-06,
      "loss": 0.0031,
      "step": 63690
    },
    {
      "epoch": 4.646582537019476,
      "grad_norm": 0.2879101634025574,
      "learning_rate": 3.5341746298052375e-06,
      "loss": 0.0031,
      "step": 63700
    },
    {
      "epoch": 4.6473119848274855,
      "grad_norm": 0.05807720497250557,
      "learning_rate": 3.5268801517251442e-06,
      "loss": 0.0028,
      "step": 63710
    },
    {
      "epoch": 4.648041432635495,
      "grad_norm": 0.08718141168355942,
      "learning_rate": 3.519585673645051e-06,
      "loss": 0.0027,
      "step": 63720
    },
    {
      "epoch": 4.648770880443505,
      "grad_norm": 0.14413513243198395,
      "learning_rate": 3.5122911955649576e-06,
      "loss": 0.0034,
      "step": 63730
    },
    {
      "epoch": 4.649500328251514,
      "grad_norm": 0.06622522324323654,
      "learning_rate": 3.504996717484864e-06,
      "loss": 0.0032,
      "step": 63740
    },
    {
      "epoch": 4.650229776059523,
      "grad_norm": 0.05895905941724777,
      "learning_rate": 3.497702239404771e-06,
      "loss": 0.0021,
      "step": 63750
    },
    {
      "epoch": 4.650959223867532,
      "grad_norm": 0.006156998220831156,
      "learning_rate": 3.4904077613246772e-06,
      "loss": 0.003,
      "step": 63760
    },
    {
      "epoch": 4.651688671675542,
      "grad_norm": 0.0108893858268857,
      "learning_rate": 3.483113283244584e-06,
      "loss": 0.0039,
      "step": 63770
    },
    {
      "epoch": 4.652418119483551,
      "grad_norm": 0.00989159569144249,
      "learning_rate": 3.4758188051644906e-06,
      "loss": 0.0028,
      "step": 63780
    },
    {
      "epoch": 4.65314756729156,
      "grad_norm": 0.11638232320547104,
      "learning_rate": 3.4685243270843973e-06,
      "loss": 0.0028,
      "step": 63790
    },
    {
      "epoch": 4.653877015099569,
      "grad_norm": 0.08668865263462067,
      "learning_rate": 3.4612298490043044e-06,
      "loss": 0.0037,
      "step": 63800
    },
    {
      "epoch": 4.654606462907579,
      "grad_norm": 0.25967922806739807,
      "learning_rate": 3.4539353709242106e-06,
      "loss": 0.0026,
      "step": 63810
    },
    {
      "epoch": 4.655335910715588,
      "grad_norm": 0.11586245149374008,
      "learning_rate": 3.446640892844117e-06,
      "loss": 0.0022,
      "step": 63820
    },
    {
      "epoch": 4.656065358523597,
      "grad_norm": 0.11514322459697723,
      "learning_rate": 3.439346414764024e-06,
      "loss": 0.0024,
      "step": 63830
    },
    {
      "epoch": 4.656794806331607,
      "grad_norm": 0.15434177219867706,
      "learning_rate": 3.4320519366839303e-06,
      "loss": 0.0024,
      "step": 63840
    },
    {
      "epoch": 4.6575242541396165,
      "grad_norm": 0.27097880840301514,
      "learning_rate": 3.424757458603837e-06,
      "loss": 0.004,
      "step": 63850
    },
    {
      "epoch": 4.658253701947626,
      "grad_norm": 0.5255652070045471,
      "learning_rate": 3.417462980523744e-06,
      "loss": 0.0027,
      "step": 63860
    },
    {
      "epoch": 4.658983149755635,
      "grad_norm": 0.2321012318134308,
      "learning_rate": 3.4101685024436503e-06,
      "loss": 0.0029,
      "step": 63870
    },
    {
      "epoch": 4.659712597563645,
      "grad_norm": 0.20371539890766144,
      "learning_rate": 3.4028740243635566e-06,
      "loss": 0.0036,
      "step": 63880
    },
    {
      "epoch": 4.660442045371654,
      "grad_norm": 0.060488734394311905,
      "learning_rate": 3.3955795462834637e-06,
      "loss": 0.0029,
      "step": 63890
    },
    {
      "epoch": 4.661171493179663,
      "grad_norm": 0.08787526190280914,
      "learning_rate": 3.38828506820337e-06,
      "loss": 0.0022,
      "step": 63900
    },
    {
      "epoch": 4.661900940987673,
      "grad_norm": 0.11626771092414856,
      "learning_rate": 3.380990590123277e-06,
      "loss": 0.0033,
      "step": 63910
    },
    {
      "epoch": 4.662630388795682,
      "grad_norm": 0.03231106698513031,
      "learning_rate": 3.3736961120431837e-06,
      "loss": 0.0022,
      "step": 63920
    },
    {
      "epoch": 4.663359836603691,
      "grad_norm": 0.3030847907066345,
      "learning_rate": 3.36640163396309e-06,
      "loss": 0.0027,
      "step": 63930
    },
    {
      "epoch": 4.6640892844117,
      "grad_norm": 0.030817868188023567,
      "learning_rate": 3.359107155882997e-06,
      "loss": 0.0023,
      "step": 63940
    },
    {
      "epoch": 4.664818732219709,
      "grad_norm": 0.012037922628223896,
      "learning_rate": 3.3518126778029033e-06,
      "loss": 0.002,
      "step": 63950
    },
    {
      "epoch": 4.665548180027719,
      "grad_norm": 0.23108163475990295,
      "learning_rate": 3.3445181997228096e-06,
      "loss": 0.003,
      "step": 63960
    },
    {
      "epoch": 4.666277627835728,
      "grad_norm": 0.14548362791538239,
      "learning_rate": 3.3372237216427167e-06,
      "loss": 0.0029,
      "step": 63970
    },
    {
      "epoch": 4.667007075643737,
      "grad_norm": 0.11714960634708405,
      "learning_rate": 3.3299292435626234e-06,
      "loss": 0.0034,
      "step": 63980
    },
    {
      "epoch": 4.667736523451747,
      "grad_norm": 0.11616260558366776,
      "learning_rate": 3.3226347654825297e-06,
      "loss": 0.0023,
      "step": 63990
    },
    {
      "epoch": 4.6684659712597565,
      "grad_norm": 0.011778666637837887,
      "learning_rate": 3.3153402874024368e-06,
      "loss": 0.0021,
      "step": 64000
    },
    {
      "epoch": 4.669195419067766,
      "grad_norm": 0.02443341165781021,
      "learning_rate": 3.308045809322343e-06,
      "loss": 0.0029,
      "step": 64010
    },
    {
      "epoch": 4.669924866875775,
      "grad_norm": 0.061420686542987823,
      "learning_rate": 3.3007513312422493e-06,
      "loss": 0.0028,
      "step": 64020
    },
    {
      "epoch": 4.670654314683785,
      "grad_norm": 0.08776954561471939,
      "learning_rate": 3.2934568531621564e-06,
      "loss": 0.0027,
      "step": 64030
    },
    {
      "epoch": 4.671383762491794,
      "grad_norm": 0.11949016898870468,
      "learning_rate": 3.286162375082063e-06,
      "loss": 0.0024,
      "step": 64040
    },
    {
      "epoch": 4.672113210299803,
      "grad_norm": 0.05927841365337372,
      "learning_rate": 3.27886789700197e-06,
      "loss": 0.0019,
      "step": 64050
    },
    {
      "epoch": 4.672842658107813,
      "grad_norm": 0.4803396761417389,
      "learning_rate": 3.2715734189218764e-06,
      "loss": 0.0034,
      "step": 64060
    },
    {
      "epoch": 4.673572105915822,
      "grad_norm": 0.4032604992389679,
      "learning_rate": 3.2642789408417827e-06,
      "loss": 0.0031,
      "step": 64070
    },
    {
      "epoch": 4.674301553723831,
      "grad_norm": 0.37549594044685364,
      "learning_rate": 3.25698446276169e-06,
      "loss": 0.0031,
      "step": 64080
    },
    {
      "epoch": 4.67503100153184,
      "grad_norm": 0.27402427792549133,
      "learning_rate": 3.249689984681596e-06,
      "loss": 0.0029,
      "step": 64090
    },
    {
      "epoch": 4.675760449339849,
      "grad_norm": 0.11556950211524963,
      "learning_rate": 3.2423955066015027e-06,
      "loss": 0.0018,
      "step": 64100
    },
    {
      "epoch": 4.676489897147859,
      "grad_norm": 0.11480624228715897,
      "learning_rate": 3.23510102852141e-06,
      "loss": 0.0026,
      "step": 64110
    },
    {
      "epoch": 4.677219344955868,
      "grad_norm": 0.24215658009052277,
      "learning_rate": 3.227806550441316e-06,
      "loss": 0.0025,
      "step": 64120
    },
    {
      "epoch": 4.677948792763877,
      "grad_norm": 0.5146913528442383,
      "learning_rate": 3.2205120723612224e-06,
      "loss": 0.0029,
      "step": 64130
    },
    {
      "epoch": 4.678678240571887,
      "grad_norm": 0.22968213260173798,
      "learning_rate": 3.2132175942811295e-06,
      "loss": 0.0035,
      "step": 64140
    },
    {
      "epoch": 4.6794076883798965,
      "grad_norm": 0.26093557476997375,
      "learning_rate": 3.2059231162010357e-06,
      "loss": 0.0029,
      "step": 64150
    },
    {
      "epoch": 4.680137136187906,
      "grad_norm": 0.317903995513916,
      "learning_rate": 3.198628638120943e-06,
      "loss": 0.0028,
      "step": 64160
    },
    {
      "epoch": 4.680866583995915,
      "grad_norm": 0.4097200930118561,
      "learning_rate": 3.1913341600408495e-06,
      "loss": 0.0021,
      "step": 64170
    },
    {
      "epoch": 4.681596031803925,
      "grad_norm": 0.11665047705173492,
      "learning_rate": 3.1840396819607558e-06,
      "loss": 0.0019,
      "step": 64180
    },
    {
      "epoch": 4.682325479611934,
      "grad_norm": 0.3736554682254791,
      "learning_rate": 3.176745203880663e-06,
      "loss": 0.0028,
      "step": 64190
    },
    {
      "epoch": 4.683054927419943,
      "grad_norm": 0.6363946795463562,
      "learning_rate": 3.169450725800569e-06,
      "loss": 0.002,
      "step": 64200
    },
    {
      "epoch": 4.683784375227953,
      "grad_norm": 0.2025005966424942,
      "learning_rate": 3.1621562477204754e-06,
      "loss": 0.0034,
      "step": 64210
    },
    {
      "epoch": 4.684513823035962,
      "grad_norm": 0.2897002100944519,
      "learning_rate": 3.1548617696403825e-06,
      "loss": 0.0029,
      "step": 64220
    },
    {
      "epoch": 4.685243270843971,
      "grad_norm": 0.4820285141468048,
      "learning_rate": 3.147567291560289e-06,
      "loss": 0.0022,
      "step": 64230
    },
    {
      "epoch": 4.68597271865198,
      "grad_norm": 0.5021612048149109,
      "learning_rate": 3.1402728134801955e-06,
      "loss": 0.0023,
      "step": 64240
    },
    {
      "epoch": 4.68670216645999,
      "grad_norm": 0.30390289425849915,
      "learning_rate": 3.1329783354001026e-06,
      "loss": 0.0027,
      "step": 64250
    },
    {
      "epoch": 4.687431614267999,
      "grad_norm": 0.15236710011959076,
      "learning_rate": 3.125683857320009e-06,
      "loss": 0.0031,
      "step": 64260
    },
    {
      "epoch": 4.688161062076008,
      "grad_norm": 0.030151357874274254,
      "learning_rate": 3.1183893792399155e-06,
      "loss": 0.0024,
      "step": 64270
    },
    {
      "epoch": 4.6888905098840175,
      "grad_norm": 0.09711473435163498,
      "learning_rate": 3.111094901159822e-06,
      "loss": 0.0035,
      "step": 64280
    },
    {
      "epoch": 4.689619957692027,
      "grad_norm": 0.0654524639248848,
      "learning_rate": 3.1038004230797284e-06,
      "loss": 0.0025,
      "step": 64290
    },
    {
      "epoch": 4.6903494055000365,
      "grad_norm": 0.32204926013946533,
      "learning_rate": 3.0965059449996356e-06,
      "loss": 0.0025,
      "step": 64300
    },
    {
      "epoch": 4.691078853308046,
      "grad_norm": 0.20251120626926422,
      "learning_rate": 3.0892114669195422e-06,
      "loss": 0.003,
      "step": 64310
    },
    {
      "epoch": 4.691808301116055,
      "grad_norm": 0.17372749745845795,
      "learning_rate": 3.081916988839449e-06,
      "loss": 0.0027,
      "step": 64320
    },
    {
      "epoch": 4.692537748924065,
      "grad_norm": 0.14941643178462982,
      "learning_rate": 3.074622510759355e-06,
      "loss": 0.0027,
      "step": 64330
    },
    {
      "epoch": 4.693267196732074,
      "grad_norm": 0.4327089190483093,
      "learning_rate": 3.067328032679262e-06,
      "loss": 0.002,
      "step": 64340
    },
    {
      "epoch": 4.693996644540083,
      "grad_norm": 0.08608415722846985,
      "learning_rate": 3.0600335545991685e-06,
      "loss": 0.0027,
      "step": 64350
    },
    {
      "epoch": 4.694726092348093,
      "grad_norm": 0.0299140103161335,
      "learning_rate": 3.0527390765190752e-06,
      "loss": 0.003,
      "step": 64360
    },
    {
      "epoch": 4.695455540156102,
      "grad_norm": 0.059167008846998215,
      "learning_rate": 3.045444598438982e-06,
      "loss": 0.0024,
      "step": 64370
    },
    {
      "epoch": 4.696184987964111,
      "grad_norm": 0.1456911265850067,
      "learning_rate": 3.0381501203588886e-06,
      "loss": 0.0025,
      "step": 64380
    },
    {
      "epoch": 4.69691443577212,
      "grad_norm": 0.20184443891048431,
      "learning_rate": 3.0308556422787953e-06,
      "loss": 0.0027,
      "step": 64390
    },
    {
      "epoch": 4.69764388358013,
      "grad_norm": 0.05783512815833092,
      "learning_rate": 3.0235611641987015e-06,
      "loss": 0.0027,
      "step": 64400
    },
    {
      "epoch": 4.698373331388139,
      "grad_norm": 0.08633776754140854,
      "learning_rate": 3.0162666861186082e-06,
      "loss": 0.0029,
      "step": 64410
    },
    {
      "epoch": 4.699102779196148,
      "grad_norm": 0.02993452362716198,
      "learning_rate": 3.008972208038515e-06,
      "loss": 0.0041,
      "step": 64420
    },
    {
      "epoch": 4.6998322270041575,
      "grad_norm": 0.20377542078495026,
      "learning_rate": 3.0016777299584216e-06,
      "loss": 0.0036,
      "step": 64430
    },
    {
      "epoch": 4.7005616748121675,
      "grad_norm": 0.06122782453894615,
      "learning_rate": 2.9943832518783283e-06,
      "loss": 0.003,
      "step": 64440
    },
    {
      "epoch": 4.701291122620177,
      "grad_norm": 0.14152692258358002,
      "learning_rate": 2.987088773798235e-06,
      "loss": 0.003,
      "step": 64450
    },
    {
      "epoch": 4.702020570428186,
      "grad_norm": 0.032277222722768784,
      "learning_rate": 2.9797942957181416e-06,
      "loss": 0.0022,
      "step": 64460
    },
    {
      "epoch": 4.702750018236195,
      "grad_norm": 0.07178517431020737,
      "learning_rate": 2.972499817638048e-06,
      "loss": 0.0033,
      "step": 64470
    },
    {
      "epoch": 4.703479466044205,
      "grad_norm": 0.11669929325580597,
      "learning_rate": 2.9652053395579546e-06,
      "loss": 0.0032,
      "step": 64480
    },
    {
      "epoch": 4.704208913852214,
      "grad_norm": 0.06395085155963898,
      "learning_rate": 2.9579108614778613e-06,
      "loss": 0.0032,
      "step": 64490
    },
    {
      "epoch": 4.704938361660223,
      "grad_norm": 0.1276988536119461,
      "learning_rate": 2.9506163833977684e-06,
      "loss": 0.0043,
      "step": 64500
    },
    {
      "epoch": 4.705667809468233,
      "grad_norm": 0.010280708782374859,
      "learning_rate": 2.9433219053176746e-06,
      "loss": 0.0026,
      "step": 64510
    },
    {
      "epoch": 4.706397257276242,
      "grad_norm": 0.2033333033323288,
      "learning_rate": 2.9360274272375813e-06,
      "loss": 0.0028,
      "step": 64520
    },
    {
      "epoch": 4.707126705084251,
      "grad_norm": 0.1448623090982437,
      "learning_rate": 2.928732949157488e-06,
      "loss": 0.0022,
      "step": 64530
    },
    {
      "epoch": 4.70785615289226,
      "grad_norm": 0.029468532651662827,
      "learning_rate": 2.9214384710773942e-06,
      "loss": 0.0028,
      "step": 64540
    },
    {
      "epoch": 4.70858560070027,
      "grad_norm": 0.013387925922870636,
      "learning_rate": 2.914143992997301e-06,
      "loss": 0.0036,
      "step": 64550
    },
    {
      "epoch": 4.709315048508279,
      "grad_norm": 0.3786948025226593,
      "learning_rate": 2.906849514917208e-06,
      "loss": 0.0021,
      "step": 64560
    },
    {
      "epoch": 4.710044496316288,
      "grad_norm": 0.057816606014966965,
      "learning_rate": 2.8995550368371147e-06,
      "loss": 0.0024,
      "step": 64570
    },
    {
      "epoch": 4.710773944124298,
      "grad_norm": 0.05944092199206352,
      "learning_rate": 2.892260558757021e-06,
      "loss": 0.0028,
      "step": 64580
    },
    {
      "epoch": 4.7115033919323075,
      "grad_norm": 0.3207562565803528,
      "learning_rate": 2.8849660806769277e-06,
      "loss": 0.0021,
      "step": 64590
    },
    {
      "epoch": 4.712232839740317,
      "grad_norm": 0.08746025711297989,
      "learning_rate": 2.8776716025968343e-06,
      "loss": 0.002,
      "step": 64600
    },
    {
      "epoch": 4.712962287548326,
      "grad_norm": 0.43219926953315735,
      "learning_rate": 2.8703771245167406e-06,
      "loss": 0.0032,
      "step": 64610
    },
    {
      "epoch": 4.713691735356335,
      "grad_norm": 0.17331776022911072,
      "learning_rate": 2.8630826464366477e-06,
      "loss": 0.0031,
      "step": 64620
    },
    {
      "epoch": 4.714421183164345,
      "grad_norm": 0.11615592986345291,
      "learning_rate": 2.8557881683565544e-06,
      "loss": 0.0021,
      "step": 64630
    },
    {
      "epoch": 4.715150630972354,
      "grad_norm": 0.1626284271478653,
      "learning_rate": 2.848493690276461e-06,
      "loss": 0.0015,
      "step": 64640
    },
    {
      "epoch": 4.715880078780363,
      "grad_norm": 0.058529507368803024,
      "learning_rate": 2.8411992121963673e-06,
      "loss": 0.0022,
      "step": 64650
    },
    {
      "epoch": 4.716609526588373,
      "grad_norm": 0.06134558096528053,
      "learning_rate": 2.833904734116274e-06,
      "loss": 0.0042,
      "step": 64660
    },
    {
      "epoch": 4.717338974396382,
      "grad_norm": 0.12270733714103699,
      "learning_rate": 2.8266102560361807e-06,
      "loss": 0.0024,
      "step": 64670
    },
    {
      "epoch": 4.718068422204391,
      "grad_norm": 0.08904310315847397,
      "learning_rate": 2.8193157779560874e-06,
      "loss": 0.0022,
      "step": 64680
    },
    {
      "epoch": 4.7187978700124,
      "grad_norm": 0.0969448983669281,
      "learning_rate": 2.812021299875994e-06,
      "loss": 0.0019,
      "step": 64690
    },
    {
      "epoch": 4.71952731782041,
      "grad_norm": 0.08797168731689453,
      "learning_rate": 2.8047268217959007e-06,
      "loss": 0.0035,
      "step": 64700
    },
    {
      "epoch": 4.720256765628419,
      "grad_norm": 0.29503288865089417,
      "learning_rate": 2.7974323437158074e-06,
      "loss": 0.0024,
      "step": 64710
    },
    {
      "epoch": 4.720986213436428,
      "grad_norm": 0.08767781406641006,
      "learning_rate": 2.7901378656357137e-06,
      "loss": 0.0027,
      "step": 64720
    },
    {
      "epoch": 4.721715661244438,
      "grad_norm": 0.1167185977101326,
      "learning_rate": 2.7828433875556204e-06,
      "loss": 0.0036,
      "step": 64730
    },
    {
      "epoch": 4.7224451090524475,
      "grad_norm": 0.31718015670776367,
      "learning_rate": 2.775548909475527e-06,
      "loss": 0.0036,
      "step": 64740
    },
    {
      "epoch": 4.723174556860457,
      "grad_norm": 0.37602418661117554,
      "learning_rate": 2.7682544313954337e-06,
      "loss": 0.0024,
      "step": 64750
    },
    {
      "epoch": 4.723904004668466,
      "grad_norm": 0.13975438475608826,
      "learning_rate": 2.7609599533153404e-06,
      "loss": 0.0033,
      "step": 64760
    },
    {
      "epoch": 4.724633452476475,
      "grad_norm": 0.19052210450172424,
      "learning_rate": 2.753665475235247e-06,
      "loss": 0.0023,
      "step": 64770
    },
    {
      "epoch": 4.725362900284485,
      "grad_norm": 0.08716884255409241,
      "learning_rate": 2.746370997155154e-06,
      "loss": 0.003,
      "step": 64780
    },
    {
      "epoch": 4.726092348092494,
      "grad_norm": 0.24891039729118347,
      "learning_rate": 2.73907651907506e-06,
      "loss": 0.0036,
      "step": 64790
    },
    {
      "epoch": 4.726821795900503,
      "grad_norm": 0.20902852714061737,
      "learning_rate": 2.7317820409949667e-06,
      "loss": 0.0022,
      "step": 64800
    },
    {
      "epoch": 4.727551243708513,
      "grad_norm": 0.1474102884531021,
      "learning_rate": 2.7244875629148734e-06,
      "loss": 0.0035,
      "step": 64810
    },
    {
      "epoch": 4.728280691516522,
      "grad_norm": 0.17384129762649536,
      "learning_rate": 2.7171930848347805e-06,
      "loss": 0.0028,
      "step": 64820
    },
    {
      "epoch": 4.729010139324531,
      "grad_norm": 0.4038257300853729,
      "learning_rate": 2.7098986067546868e-06,
      "loss": 0.0026,
      "step": 64830
    },
    {
      "epoch": 4.72973958713254,
      "grad_norm": 0.173397034406662,
      "learning_rate": 2.7026041286745935e-06,
      "loss": 0.003,
      "step": 64840
    },
    {
      "epoch": 4.73046903494055,
      "grad_norm": 0.08741694688796997,
      "learning_rate": 2.6953096505945e-06,
      "loss": 0.0039,
      "step": 64850
    },
    {
      "epoch": 4.731198482748559,
      "grad_norm": 0.12272453308105469,
      "learning_rate": 2.6880151725144064e-06,
      "loss": 0.0032,
      "step": 64860
    },
    {
      "epoch": 4.7319279305565685,
      "grad_norm": 0.05755725875496864,
      "learning_rate": 2.680720694434313e-06,
      "loss": 0.0022,
      "step": 64870
    },
    {
      "epoch": 4.7326573783645784,
      "grad_norm": 0.2325666844844818,
      "learning_rate": 2.67342621635422e-06,
      "loss": 0.0023,
      "step": 64880
    },
    {
      "epoch": 4.7333868261725875,
      "grad_norm": 0.3923434019088745,
      "learning_rate": 2.666131738274127e-06,
      "loss": 0.0025,
      "step": 64890
    },
    {
      "epoch": 4.734116273980597,
      "grad_norm": 0.11579323559999466,
      "learning_rate": 2.658837260194033e-06,
      "loss": 0.0012,
      "step": 64900
    },
    {
      "epoch": 4.734845721788606,
      "grad_norm": 0.08723018318414688,
      "learning_rate": 2.65154278211394e-06,
      "loss": 0.0017,
      "step": 64910
    },
    {
      "epoch": 4.735575169596616,
      "grad_norm": 0.1288234293460846,
      "learning_rate": 2.6442483040338465e-06,
      "loss": 0.0025,
      "step": 64920
    },
    {
      "epoch": 4.736304617404625,
      "grad_norm": 0.1160978153347969,
      "learning_rate": 2.636953825953753e-06,
      "loss": 0.0033,
      "step": 64930
    },
    {
      "epoch": 4.737034065212634,
      "grad_norm": 0.3548144996166229,
      "learning_rate": 2.62965934787366e-06,
      "loss": 0.0034,
      "step": 64940
    },
    {
      "epoch": 4.737763513020643,
      "grad_norm": 0.4783276617527008,
      "learning_rate": 2.6223648697935666e-06,
      "loss": 0.002,
      "step": 64950
    },
    {
      "epoch": 4.738492960828653,
      "grad_norm": 0.1693001538515091,
      "learning_rate": 2.6150703917134732e-06,
      "loss": 0.0027,
      "step": 64960
    },
    {
      "epoch": 4.739222408636662,
      "grad_norm": 0.7192457914352417,
      "learning_rate": 2.6077759136333795e-06,
      "loss": 0.0037,
      "step": 64970
    },
    {
      "epoch": 4.739951856444671,
      "grad_norm": 0.7070964574813843,
      "learning_rate": 2.600481435553286e-06,
      "loss": 0.0024,
      "step": 64980
    },
    {
      "epoch": 4.74068130425268,
      "grad_norm": 0.18424075841903687,
      "learning_rate": 2.593186957473193e-06,
      "loss": 0.0022,
      "step": 64990
    },
    {
      "epoch": 4.74141075206069,
      "grad_norm": 0.26620572805404663,
      "learning_rate": 2.5858924793930995e-06,
      "loss": 0.0027,
      "step": 65000
    },
    {
      "epoch": 4.742140199868699,
      "grad_norm": 0.08775734156370163,
      "learning_rate": 2.5785980013130062e-06,
      "loss": 0.0045,
      "step": 65010
    },
    {
      "epoch": 4.7428696476767085,
      "grad_norm": 0.37569040060043335,
      "learning_rate": 2.571303523232913e-06,
      "loss": 0.0022,
      "step": 65020
    },
    {
      "epoch": 4.7435990954847185,
      "grad_norm": 0.019958138465881348,
      "learning_rate": 2.5640090451528196e-06,
      "loss": 0.003,
      "step": 65030
    },
    {
      "epoch": 4.744328543292728,
      "grad_norm": 0.05836750939488411,
      "learning_rate": 2.556714567072726e-06,
      "loss": 0.0026,
      "step": 65040
    },
    {
      "epoch": 4.745057991100737,
      "grad_norm": 0.20300397276878357,
      "learning_rate": 2.5494200889926325e-06,
      "loss": 0.0038,
      "step": 65050
    },
    {
      "epoch": 4.745787438908746,
      "grad_norm": 0.011010287329554558,
      "learning_rate": 2.5421256109125392e-06,
      "loss": 0.0034,
      "step": 65060
    },
    {
      "epoch": 4.746516886716756,
      "grad_norm": 0.08721126616001129,
      "learning_rate": 2.534831132832446e-06,
      "loss": 0.0023,
      "step": 65070
    },
    {
      "epoch": 4.747246334524765,
      "grad_norm": 0.08808142691850662,
      "learning_rate": 2.5275366547523526e-06,
      "loss": 0.002,
      "step": 65080
    },
    {
      "epoch": 4.747975782332774,
      "grad_norm": 0.058230914175510406,
      "learning_rate": 2.5202421766722593e-06,
      "loss": 0.0024,
      "step": 65090
    },
    {
      "epoch": 4.748705230140783,
      "grad_norm": 0.1154438927769661,
      "learning_rate": 2.512947698592166e-06,
      "loss": 0.0022,
      "step": 65100
    },
    {
      "epoch": 4.749434677948793,
      "grad_norm": 0.08884128928184509,
      "learning_rate": 2.505653220512072e-06,
      "loss": 0.0034,
      "step": 65110
    },
    {
      "epoch": 4.750164125756802,
      "grad_norm": 0.40893468260765076,
      "learning_rate": 2.498358742431979e-06,
      "loss": 0.0027,
      "step": 65120
    },
    {
      "epoch": 4.750893573564811,
      "grad_norm": 0.20570114254951477,
      "learning_rate": 2.4910642643518856e-06,
      "loss": 0.002,
      "step": 65130
    },
    {
      "epoch": 4.75162302137282,
      "grad_norm": 0.05900006741285324,
      "learning_rate": 2.4837697862717927e-06,
      "loss": 0.0025,
      "step": 65140
    },
    {
      "epoch": 4.75235246918083,
      "grad_norm": 0.05953827500343323,
      "learning_rate": 2.476475308191699e-06,
      "loss": 0.0026,
      "step": 65150
    },
    {
      "epoch": 4.753081916988839,
      "grad_norm": 0.21628282964229584,
      "learning_rate": 2.4691808301116056e-06,
      "loss": 0.003,
      "step": 65160
    },
    {
      "epoch": 4.7538113647968485,
      "grad_norm": 0.07208959758281708,
      "learning_rate": 2.4618863520315123e-06,
      "loss": 0.003,
      "step": 65170
    },
    {
      "epoch": 4.7545408126048585,
      "grad_norm": 0.08685870468616486,
      "learning_rate": 2.454591873951419e-06,
      "loss": 0.0029,
      "step": 65180
    },
    {
      "epoch": 4.755270260412868,
      "grad_norm": 0.03245435655117035,
      "learning_rate": 2.4472973958713252e-06,
      "loss": 0.0024,
      "step": 65190
    },
    {
      "epoch": 4.755999708220877,
      "grad_norm": 0.03810649737715721,
      "learning_rate": 2.4400029177912324e-06,
      "loss": 0.002,
      "step": 65200
    },
    {
      "epoch": 4.756729156028886,
      "grad_norm": 0.15270966291427612,
      "learning_rate": 2.432708439711139e-06,
      "loss": 0.0033,
      "step": 65210
    },
    {
      "epoch": 4.757458603836896,
      "grad_norm": 0.08691379427909851,
      "learning_rate": 2.4254139616310453e-06,
      "loss": 0.0032,
      "step": 65220
    },
    {
      "epoch": 4.758188051644905,
      "grad_norm": 0.08773541450500488,
      "learning_rate": 2.418119483550952e-06,
      "loss": 0.0032,
      "step": 65230
    },
    {
      "epoch": 4.758917499452914,
      "grad_norm": 0.03049173206090927,
      "learning_rate": 2.4108250054708587e-06,
      "loss": 0.0029,
      "step": 65240
    },
    {
      "epoch": 4.759646947260924,
      "grad_norm": 0.11823076754808426,
      "learning_rate": 2.4035305273907653e-06,
      "loss": 0.0025,
      "step": 65250
    },
    {
      "epoch": 4.760376395068933,
      "grad_norm": 0.11249781399965286,
      "learning_rate": 2.396236049310672e-06,
      "loss": 0.0029,
      "step": 65260
    },
    {
      "epoch": 4.761105842876942,
      "grad_norm": 0.1752413958311081,
      "learning_rate": 2.3889415712305787e-06,
      "loss": 0.0032,
      "step": 65270
    },
    {
      "epoch": 4.761835290684951,
      "grad_norm": 0.20231373608112335,
      "learning_rate": 2.3816470931504854e-06,
      "loss": 0.0019,
      "step": 65280
    },
    {
      "epoch": 4.76256473849296,
      "grad_norm": 0.14437954127788544,
      "learning_rate": 2.3743526150703917e-06,
      "loss": 0.0017,
      "step": 65290
    },
    {
      "epoch": 4.76329418630097,
      "grad_norm": 0.055669575929641724,
      "learning_rate": 2.3670581369902983e-06,
      "loss": 0.0026,
      "step": 65300
    },
    {
      "epoch": 4.764023634108979,
      "grad_norm": 0.030261987820267677,
      "learning_rate": 2.359763658910205e-06,
      "loss": 0.0028,
      "step": 65310
    },
    {
      "epoch": 4.7647530819169885,
      "grad_norm": 0.09423480927944183,
      "learning_rate": 2.3524691808301117e-06,
      "loss": 0.0039,
      "step": 65320
    },
    {
      "epoch": 4.7654825297249985,
      "grad_norm": 0.19802698493003845,
      "learning_rate": 2.3451747027500184e-06,
      "loss": 0.0023,
      "step": 65330
    },
    {
      "epoch": 4.766211977533008,
      "grad_norm": 0.5838102102279663,
      "learning_rate": 2.337880224669925e-06,
      "loss": 0.003,
      "step": 65340
    },
    {
      "epoch": 4.766941425341017,
      "grad_norm": 0.17420418560504913,
      "learning_rate": 2.3305857465898318e-06,
      "loss": 0.0035,
      "step": 65350
    },
    {
      "epoch": 4.767670873149026,
      "grad_norm": 0.20285941660404205,
      "learning_rate": 2.3232912685097384e-06,
      "loss": 0.0036,
      "step": 65360
    },
    {
      "epoch": 4.768400320957036,
      "grad_norm": 0.11569356918334961,
      "learning_rate": 2.3159967904296447e-06,
      "loss": 0.0021,
      "step": 65370
    },
    {
      "epoch": 4.769129768765045,
      "grad_norm": 0.08696377277374268,
      "learning_rate": 2.3087023123495514e-06,
      "loss": 0.0031,
      "step": 65380
    },
    {
      "epoch": 4.769859216573054,
      "grad_norm": 0.14362792670726776,
      "learning_rate": 2.301407834269458e-06,
      "loss": 0.0045,
      "step": 65390
    },
    {
      "epoch": 4.770588664381064,
      "grad_norm": 0.031188935041427612,
      "learning_rate": 2.2941133561893647e-06,
      "loss": 0.0029,
      "step": 65400
    },
    {
      "epoch": 4.771318112189073,
      "grad_norm": 0.1851307898759842,
      "learning_rate": 2.2868188781092714e-06,
      "loss": 0.0022,
      "step": 65410
    },
    {
      "epoch": 4.772047559997082,
      "grad_norm": 0.014204103499650955,
      "learning_rate": 2.279524400029178e-06,
      "loss": 0.0027,
      "step": 65420
    },
    {
      "epoch": 4.772777007805091,
      "grad_norm": 0.3192077875137329,
      "learning_rate": 2.272229921949085e-06,
      "loss": 0.0027,
      "step": 65430
    },
    {
      "epoch": 4.7735064556131,
      "grad_norm": 0.08648889511823654,
      "learning_rate": 2.264935443868991e-06,
      "loss": 0.0031,
      "step": 65440
    },
    {
      "epoch": 4.77423590342111,
      "grad_norm": 0.21127241849899292,
      "learning_rate": 2.2576409657888977e-06,
      "loss": 0.0033,
      "step": 65450
    },
    {
      "epoch": 4.7749653512291195,
      "grad_norm": 0.012540983967483044,
      "learning_rate": 2.250346487708805e-06,
      "loss": 0.0023,
      "step": 65460
    },
    {
      "epoch": 4.775694799037129,
      "grad_norm": 0.2891925871372223,
      "learning_rate": 2.243052009628711e-06,
      "loss": 0.0016,
      "step": 65470
    },
    {
      "epoch": 4.7764242468451386,
      "grad_norm": 0.4672524333000183,
      "learning_rate": 2.2357575315486178e-06,
      "loss": 0.0033,
      "step": 65480
    },
    {
      "epoch": 4.777153694653148,
      "grad_norm": 0.24896778166294098,
      "learning_rate": 2.2284630534685245e-06,
      "loss": 0.0038,
      "step": 65490
    },
    {
      "epoch": 4.777883142461157,
      "grad_norm": 0.20314384996891022,
      "learning_rate": 2.221168575388431e-06,
      "loss": 0.0033,
      "step": 65500
    },
    {
      "epoch": 4.778612590269166,
      "grad_norm": 0.16613604128360748,
      "learning_rate": 2.2138740973083374e-06,
      "loss": 0.0029,
      "step": 65510
    },
    {
      "epoch": 4.779342038077176,
      "grad_norm": 0.11496816575527191,
      "learning_rate": 2.2065796192282445e-06,
      "loss": 0.0024,
      "step": 65520
    },
    {
      "epoch": 4.780071485885185,
      "grad_norm": 0.20214185118675232,
      "learning_rate": 2.199285141148151e-06,
      "loss": 0.0018,
      "step": 65530
    },
    {
      "epoch": 4.780800933693194,
      "grad_norm": 0.34544938802719116,
      "learning_rate": 2.1919906630680575e-06,
      "loss": 0.0034,
      "step": 65540
    },
    {
      "epoch": 4.781530381501204,
      "grad_norm": 0.058672599494457245,
      "learning_rate": 2.184696184987964e-06,
      "loss": 0.0027,
      "step": 65550
    },
    {
      "epoch": 4.782259829309213,
      "grad_norm": 0.08912760019302368,
      "learning_rate": 2.177401706907871e-06,
      "loss": 0.0022,
      "step": 65560
    },
    {
      "epoch": 4.782989277117222,
      "grad_norm": 0.061362374573946,
      "learning_rate": 2.1701072288277775e-06,
      "loss": 0.0033,
      "step": 65570
    },
    {
      "epoch": 4.783718724925231,
      "grad_norm": 0.08111440390348434,
      "learning_rate": 2.162812750747684e-06,
      "loss": 0.003,
      "step": 65580
    },
    {
      "epoch": 4.784448172733241,
      "grad_norm": 0.20827116072177887,
      "learning_rate": 2.155518272667591e-06,
      "loss": 0.0024,
      "step": 65590
    },
    {
      "epoch": 4.78517762054125,
      "grad_norm": 0.10532651096582413,
      "learning_rate": 2.1482237945874976e-06,
      "loss": 0.0024,
      "step": 65600
    },
    {
      "epoch": 4.7859070683492595,
      "grad_norm": 0.14328411221504211,
      "learning_rate": 2.1409293165074042e-06,
      "loss": 0.0015,
      "step": 65610
    },
    {
      "epoch": 4.786636516157269,
      "grad_norm": 0.4052937924861908,
      "learning_rate": 2.1336348384273105e-06,
      "loss": 0.0029,
      "step": 65620
    },
    {
      "epoch": 4.787365963965279,
      "grad_norm": 0.2604224383831024,
      "learning_rate": 2.126340360347217e-06,
      "loss": 0.0021,
      "step": 65630
    },
    {
      "epoch": 4.788095411773288,
      "grad_norm": 0.015777423977851868,
      "learning_rate": 2.119045882267124e-06,
      "loss": 0.0027,
      "step": 65640
    },
    {
      "epoch": 4.788824859581297,
      "grad_norm": 0.2327825129032135,
      "learning_rate": 2.1117514041870305e-06,
      "loss": 0.0019,
      "step": 65650
    },
    {
      "epoch": 4.789554307389306,
      "grad_norm": 0.29014351963996887,
      "learning_rate": 2.1044569261069372e-06,
      "loss": 0.0023,
      "step": 65660
    },
    {
      "epoch": 4.790283755197316,
      "grad_norm": 0.14847323298454285,
      "learning_rate": 2.097162448026844e-06,
      "loss": 0.0024,
      "step": 65670
    },
    {
      "epoch": 4.791013203005325,
      "grad_norm": 0.1466735452413559,
      "learning_rate": 2.0898679699467506e-06,
      "loss": 0.0021,
      "step": 65680
    },
    {
      "epoch": 4.791742650813334,
      "grad_norm": 0.17933115363121033,
      "learning_rate": 2.082573491866657e-06,
      "loss": 0.0022,
      "step": 65690
    },
    {
      "epoch": 4.792472098621344,
      "grad_norm": 0.3168509602546692,
      "learning_rate": 2.0752790137865635e-06,
      "loss": 0.0027,
      "step": 65700
    },
    {
      "epoch": 4.793201546429353,
      "grad_norm": 0.20481044054031372,
      "learning_rate": 2.0679845357064702e-06,
      "loss": 0.0031,
      "step": 65710
    },
    {
      "epoch": 4.793930994237362,
      "grad_norm": 0.2597043812274933,
      "learning_rate": 2.060690057626377e-06,
      "loss": 0.0019,
      "step": 65720
    },
    {
      "epoch": 4.794660442045371,
      "grad_norm": 0.08363721519708633,
      "learning_rate": 2.0533955795462836e-06,
      "loss": 0.0037,
      "step": 65730
    },
    {
      "epoch": 4.795389889853381,
      "grad_norm": 0.08638323843479156,
      "learning_rate": 2.0461011014661903e-06,
      "loss": 0.0029,
      "step": 65740
    },
    {
      "epoch": 4.79611933766139,
      "grad_norm": 0.06068987026810646,
      "learning_rate": 2.038806623386097e-06,
      "loss": 0.0021,
      "step": 65750
    },
    {
      "epoch": 4.7968487854693995,
      "grad_norm": 0.3562321364879608,
      "learning_rate": 2.031512145306003e-06,
      "loss": 0.0024,
      "step": 65760
    },
    {
      "epoch": 4.797578233277409,
      "grad_norm": 0.48535552620887756,
      "learning_rate": 2.02421766722591e-06,
      "loss": 0.0025,
      "step": 65770
    },
    {
      "epoch": 4.798307681085419,
      "grad_norm": 0.19934244453907013,
      "learning_rate": 2.016923189145817e-06,
      "loss": 0.003,
      "step": 65780
    },
    {
      "epoch": 4.799037128893428,
      "grad_norm": 0.03238502889871597,
      "learning_rate": 2.0096287110657233e-06,
      "loss": 0.0019,
      "step": 65790
    },
    {
      "epoch": 4.799766576701437,
      "grad_norm": 0.03044009394943714,
      "learning_rate": 2.00233423298563e-06,
      "loss": 0.0022,
      "step": 65800
    },
    {
      "epoch": 4.800496024509446,
      "grad_norm": 0.17420648038387299,
      "learning_rate": 1.9950397549055366e-06,
      "loss": 0.0025,
      "step": 65810
    },
    {
      "epoch": 4.801225472317456,
      "grad_norm": 0.20222701132297516,
      "learning_rate": 1.9877452768254433e-06,
      "loss": 0.0021,
      "step": 65820
    },
    {
      "epoch": 4.801954920125465,
      "grad_norm": 0.44583451747894287,
      "learning_rate": 1.9804507987453496e-06,
      "loss": 0.0034,
      "step": 65830
    },
    {
      "epoch": 4.802684367933474,
      "grad_norm": 0.4903833866119385,
      "learning_rate": 1.9731563206652567e-06,
      "loss": 0.003,
      "step": 65840
    },
    {
      "epoch": 4.803413815741484,
      "grad_norm": 0.31789836287498474,
      "learning_rate": 1.9658618425851634e-06,
      "loss": 0.0028,
      "step": 65850
    },
    {
      "epoch": 4.804143263549493,
      "grad_norm": 0.03614671155810356,
      "learning_rate": 1.95856736450507e-06,
      "loss": 0.0018,
      "step": 65860
    },
    {
      "epoch": 4.804872711357502,
      "grad_norm": 0.46081095933914185,
      "learning_rate": 1.9512728864249763e-06,
      "loss": 0.003,
      "step": 65870
    },
    {
      "epoch": 4.805602159165511,
      "grad_norm": 0.23104332387447357,
      "learning_rate": 1.943978408344883e-06,
      "loss": 0.0025,
      "step": 65880
    },
    {
      "epoch": 4.806331606973521,
      "grad_norm": 0.20190246403217316,
      "learning_rate": 1.9366839302647897e-06,
      "loss": 0.0029,
      "step": 65890
    },
    {
      "epoch": 4.8070610547815305,
      "grad_norm": 0.20642971992492676,
      "learning_rate": 1.929389452184696e-06,
      "loss": 0.0037,
      "step": 65900
    },
    {
      "epoch": 4.8077905025895395,
      "grad_norm": 0.030814161524176598,
      "learning_rate": 1.922094974104603e-06,
      "loss": 0.0022,
      "step": 65910
    },
    {
      "epoch": 4.8085199503975495,
      "grad_norm": 0.14476120471954346,
      "learning_rate": 1.9148004960245097e-06,
      "loss": 0.0032,
      "step": 65920
    },
    {
      "epoch": 4.809249398205559,
      "grad_norm": 0.012321037240326405,
      "learning_rate": 1.9075060179444164e-06,
      "loss": 0.0023,
      "step": 65930
    },
    {
      "epoch": 4.809978846013568,
      "grad_norm": 0.28152382373809814,
      "learning_rate": 1.9002115398643227e-06,
      "loss": 0.0038,
      "step": 65940
    },
    {
      "epoch": 4.810708293821577,
      "grad_norm": 0.06585004925727844,
      "learning_rate": 1.8929170617842293e-06,
      "loss": 0.0031,
      "step": 65950
    },
    {
      "epoch": 4.811437741629586,
      "grad_norm": 0.2339930534362793,
      "learning_rate": 1.8856225837041362e-06,
      "loss": 0.0024,
      "step": 65960
    },
    {
      "epoch": 4.812167189437596,
      "grad_norm": 0.07788903266191483,
      "learning_rate": 1.8783281056240425e-06,
      "loss": 0.0032,
      "step": 65970
    },
    {
      "epoch": 4.812896637245605,
      "grad_norm": 0.042091771960258484,
      "learning_rate": 1.8710336275439492e-06,
      "loss": 0.0015,
      "step": 65980
    },
    {
      "epoch": 4.813626085053614,
      "grad_norm": 0.05700279399752617,
      "learning_rate": 1.863739149463856e-06,
      "loss": 0.0023,
      "step": 65990
    },
    {
      "epoch": 4.814355532861624,
      "grad_norm": 0.08688201010227203,
      "learning_rate": 1.8564446713837628e-06,
      "loss": 0.0023,
      "step": 66000
    },
    {
      "epoch": 4.815084980669633,
      "grad_norm": 0.1751883178949356,
      "learning_rate": 1.849150193303669e-06,
      "loss": 0.0024,
      "step": 66010
    },
    {
      "epoch": 4.815814428477642,
      "grad_norm": 0.14463292062282562,
      "learning_rate": 1.841855715223576e-06,
      "loss": 0.0023,
      "step": 66020
    },
    {
      "epoch": 4.816543876285651,
      "grad_norm": 0.22998826205730438,
      "learning_rate": 1.8345612371434826e-06,
      "loss": 0.0025,
      "step": 66030
    },
    {
      "epoch": 4.817273324093661,
      "grad_norm": 0.03218068554997444,
      "learning_rate": 1.8272667590633893e-06,
      "loss": 0.0026,
      "step": 66040
    },
    {
      "epoch": 4.8180027719016705,
      "grad_norm": 0.20329692959785461,
      "learning_rate": 1.8199722809832957e-06,
      "loss": 0.0019,
      "step": 66050
    },
    {
      "epoch": 4.81873221970968,
      "grad_norm": 0.029303112998604774,
      "learning_rate": 1.8126778029032024e-06,
      "loss": 0.0029,
      "step": 66060
    },
    {
      "epoch": 4.81946166751769,
      "grad_norm": 0.11115793883800507,
      "learning_rate": 1.8053833248231091e-06,
      "loss": 0.0015,
      "step": 66070
    },
    {
      "epoch": 4.820191115325699,
      "grad_norm": 0.033109813928604126,
      "learning_rate": 1.7980888467430156e-06,
      "loss": 0.0021,
      "step": 66080
    },
    {
      "epoch": 4.820920563133708,
      "grad_norm": 0.029262207448482513,
      "learning_rate": 1.7907943686629223e-06,
      "loss": 0.0028,
      "step": 66090
    },
    {
      "epoch": 4.821650010941717,
      "grad_norm": 0.11613588035106659,
      "learning_rate": 1.783499890582829e-06,
      "loss": 0.0023,
      "step": 66100
    },
    {
      "epoch": 4.822379458749727,
      "grad_norm": 0.345826119184494,
      "learning_rate": 1.7762054125027356e-06,
      "loss": 0.0018,
      "step": 66110
    },
    {
      "epoch": 4.823108906557736,
      "grad_norm": 0.7053156495094299,
      "learning_rate": 1.768910934422642e-06,
      "loss": 0.0028,
      "step": 66120
    },
    {
      "epoch": 4.823838354365745,
      "grad_norm": 0.21991907060146332,
      "learning_rate": 1.7616164563425488e-06,
      "loss": 0.0028,
      "step": 66130
    },
    {
      "epoch": 4.824567802173754,
      "grad_norm": 0.0646166279911995,
      "learning_rate": 1.7543219782624555e-06,
      "loss": 0.0014,
      "step": 66140
    },
    {
      "epoch": 4.825297249981764,
      "grad_norm": 0.1286315768957138,
      "learning_rate": 1.747027500182362e-06,
      "loss": 0.0021,
      "step": 66150
    },
    {
      "epoch": 4.826026697789773,
      "grad_norm": 0.032220445573329926,
      "learning_rate": 1.7397330221022686e-06,
      "loss": 0.0034,
      "step": 66160
    },
    {
      "epoch": 4.826756145597782,
      "grad_norm": 0.3175390958786011,
      "learning_rate": 1.7324385440221753e-06,
      "loss": 0.0032,
      "step": 66170
    },
    {
      "epoch": 4.827485593405791,
      "grad_norm": 0.4034355580806732,
      "learning_rate": 1.725144065942082e-06,
      "loss": 0.0032,
      "step": 66180
    },
    {
      "epoch": 4.828215041213801,
      "grad_norm": 0.14452950656414032,
      "learning_rate": 1.7178495878619885e-06,
      "loss": 0.0026,
      "step": 66190
    },
    {
      "epoch": 4.8289444890218105,
      "grad_norm": 0.11658897995948792,
      "learning_rate": 1.7105551097818951e-06,
      "loss": 0.0025,
      "step": 66200
    },
    {
      "epoch": 4.82967393682982,
      "grad_norm": 0.03177445009350777,
      "learning_rate": 1.7032606317018018e-06,
      "loss": 0.0022,
      "step": 66210
    },
    {
      "epoch": 4.83040338463783,
      "grad_norm": 0.17279785871505737,
      "learning_rate": 1.6959661536217083e-06,
      "loss": 0.0026,
      "step": 66220
    },
    {
      "epoch": 4.831132832445839,
      "grad_norm": 0.07803288102149963,
      "learning_rate": 1.688671675541615e-06,
      "loss": 0.0025,
      "step": 66230
    },
    {
      "epoch": 4.831862280253848,
      "grad_norm": 0.173797145485878,
      "learning_rate": 1.6813771974615217e-06,
      "loss": 0.0026,
      "step": 66240
    },
    {
      "epoch": 4.832591728061857,
      "grad_norm": 0.05830162391066551,
      "learning_rate": 1.6740827193814286e-06,
      "loss": 0.0027,
      "step": 66250
    },
    {
      "epoch": 4.833321175869867,
      "grad_norm": 0.1441032886505127,
      "learning_rate": 1.6667882413013348e-06,
      "loss": 0.0041,
      "step": 66260
    },
    {
      "epoch": 4.834050623677876,
      "grad_norm": 0.05911747366189957,
      "learning_rate": 1.6594937632212415e-06,
      "loss": 0.0035,
      "step": 66270
    },
    {
      "epoch": 4.834780071485885,
      "grad_norm": 0.28679701685905457,
      "learning_rate": 1.6521992851411484e-06,
      "loss": 0.0033,
      "step": 66280
    },
    {
      "epoch": 4.835509519293894,
      "grad_norm": 0.08819112181663513,
      "learning_rate": 1.644904807061055e-06,
      "loss": 0.0044,
      "step": 66290
    },
    {
      "epoch": 4.836238967101904,
      "grad_norm": 0.03149206563830376,
      "learning_rate": 1.6376103289809613e-06,
      "loss": 0.0033,
      "step": 66300
    },
    {
      "epoch": 4.836968414909913,
      "grad_norm": 0.522841215133667,
      "learning_rate": 1.6303158509008682e-06,
      "loss": 0.003,
      "step": 66310
    },
    {
      "epoch": 4.837697862717922,
      "grad_norm": 0.08987785130739212,
      "learning_rate": 1.623021372820775e-06,
      "loss": 0.0021,
      "step": 66320
    },
    {
      "epoch": 4.8384273105259314,
      "grad_norm": 0.06629406660795212,
      "learning_rate": 1.6157268947406812e-06,
      "loss": 0.0026,
      "step": 66330
    },
    {
      "epoch": 4.839156758333941,
      "grad_norm": 0.21050341427326202,
      "learning_rate": 1.608432416660588e-06,
      "loss": 0.0016,
      "step": 66340
    },
    {
      "epoch": 4.8398862061419505,
      "grad_norm": 0.029964817687869072,
      "learning_rate": 1.6011379385804947e-06,
      "loss": 0.0027,
      "step": 66350
    },
    {
      "epoch": 4.84061565394996,
      "grad_norm": 0.11558865010738373,
      "learning_rate": 1.5938434605004014e-06,
      "loss": 0.0025,
      "step": 66360
    },
    {
      "epoch": 4.84134510175797,
      "grad_norm": 0.02982831932604313,
      "learning_rate": 1.586548982420308e-06,
      "loss": 0.0023,
      "step": 66370
    },
    {
      "epoch": 4.842074549565979,
      "grad_norm": 0.3227890729904175,
      "learning_rate": 1.5792545043402146e-06,
      "loss": 0.0034,
      "step": 66380
    },
    {
      "epoch": 4.842803997373988,
      "grad_norm": 0.348588228225708,
      "learning_rate": 1.5719600262601213e-06,
      "loss": 0.0029,
      "step": 66390
    },
    {
      "epoch": 4.843533445181997,
      "grad_norm": 0.31676286458969116,
      "learning_rate": 1.5646655481800277e-06,
      "loss": 0.0027,
      "step": 66400
    },
    {
      "epoch": 4.844262892990007,
      "grad_norm": 0.16245515644550323,
      "learning_rate": 1.5573710700999344e-06,
      "loss": 0.0026,
      "step": 66410
    },
    {
      "epoch": 4.844992340798016,
      "grad_norm": 0.20275989174842834,
      "learning_rate": 1.550076592019841e-06,
      "loss": 0.0028,
      "step": 66420
    },
    {
      "epoch": 4.845721788606025,
      "grad_norm": 0.2317713052034378,
      "learning_rate": 1.5427821139397476e-06,
      "loss": 0.0031,
      "step": 66430
    },
    {
      "epoch": 4.846451236414034,
      "grad_norm": 0.11589421331882477,
      "learning_rate": 1.5354876358596545e-06,
      "loss": 0.0027,
      "step": 66440
    },
    {
      "epoch": 4.847180684222044,
      "grad_norm": 0.4611612856388092,
      "learning_rate": 1.528193157779561e-06,
      "loss": 0.0025,
      "step": 66450
    },
    {
      "epoch": 4.847910132030053,
      "grad_norm": 0.02964652143418789,
      "learning_rate": 1.5208986796994676e-06,
      "loss": 0.0024,
      "step": 66460
    },
    {
      "epoch": 4.848639579838062,
      "grad_norm": 0.03220560774207115,
      "learning_rate": 1.5136042016193743e-06,
      "loss": 0.0023,
      "step": 66470
    },
    {
      "epoch": 4.8493690276460715,
      "grad_norm": 0.11827509850263596,
      "learning_rate": 1.5063097235392808e-06,
      "loss": 0.0037,
      "step": 66480
    },
    {
      "epoch": 4.8500984754540815,
      "grad_norm": 0.38302743434906006,
      "learning_rate": 1.4990152454591875e-06,
      "loss": 0.0041,
      "step": 66490
    },
    {
      "epoch": 4.850827923262091,
      "grad_norm": 0.0596192292869091,
      "learning_rate": 1.4917207673790941e-06,
      "loss": 0.0029,
      "step": 66500
    },
    {
      "epoch": 4.8515573710701,
      "grad_norm": 0.030292486771941185,
      "learning_rate": 1.4844262892990008e-06,
      "loss": 0.002,
      "step": 66510
    },
    {
      "epoch": 4.85228681887811,
      "grad_norm": 0.1439523845911026,
      "learning_rate": 1.4771318112189073e-06,
      "loss": 0.002,
      "step": 66520
    },
    {
      "epoch": 4.853016266686119,
      "grad_norm": 0.08762087672948837,
      "learning_rate": 1.469837333138814e-06,
      "loss": 0.0023,
      "step": 66530
    },
    {
      "epoch": 4.853745714494128,
      "grad_norm": 0.03066510148346424,
      "learning_rate": 1.4625428550587207e-06,
      "loss": 0.0032,
      "step": 66540
    },
    {
      "epoch": 4.854475162302137,
      "grad_norm": 0.3458370268344879,
      "learning_rate": 1.4552483769786273e-06,
      "loss": 0.0037,
      "step": 66550
    },
    {
      "epoch": 4.855204610110147,
      "grad_norm": 0.17289912700653076,
      "learning_rate": 1.4479538988985338e-06,
      "loss": 0.0022,
      "step": 66560
    },
    {
      "epoch": 4.855934057918156,
      "grad_norm": 0.1729332059621811,
      "learning_rate": 1.4406594208184405e-06,
      "loss": 0.0028,
      "step": 66570
    },
    {
      "epoch": 4.856663505726165,
      "grad_norm": 0.40419021248817444,
      "learning_rate": 1.4333649427383472e-06,
      "loss": 0.002,
      "step": 66580
    },
    {
      "epoch": 4.857392953534175,
      "grad_norm": 0.2608414590358734,
      "learning_rate": 1.4260704646582537e-06,
      "loss": 0.0023,
      "step": 66590
    },
    {
      "epoch": 4.858122401342184,
      "grad_norm": 0.030512122437357903,
      "learning_rate": 1.4187759865781605e-06,
      "loss": 0.0025,
      "step": 66600
    },
    {
      "epoch": 4.858851849150193,
      "grad_norm": 0.38228994607925415,
      "learning_rate": 1.411481508498067e-06,
      "loss": 0.0033,
      "step": 66610
    },
    {
      "epoch": 4.859581296958202,
      "grad_norm": 0.21377529203891754,
      "learning_rate": 1.4041870304179737e-06,
      "loss": 0.0023,
      "step": 66620
    },
    {
      "epoch": 4.8603107447662115,
      "grad_norm": 0.05909065529704094,
      "learning_rate": 1.3968925523378804e-06,
      "loss": 0.0026,
      "step": 66630
    },
    {
      "epoch": 4.8610401925742215,
      "grad_norm": 0.3169448673725128,
      "learning_rate": 1.3895980742577869e-06,
      "loss": 0.0024,
      "step": 66640
    },
    {
      "epoch": 4.861769640382231,
      "grad_norm": 0.2891356945037842,
      "learning_rate": 1.3823035961776935e-06,
      "loss": 0.0031,
      "step": 66650
    },
    {
      "epoch": 4.86249908819024,
      "grad_norm": 0.1488666534423828,
      "learning_rate": 1.3750091180976002e-06,
      "loss": 0.0047,
      "step": 66660
    },
    {
      "epoch": 4.86322853599825,
      "grad_norm": 0.21691811084747314,
      "learning_rate": 1.367714640017507e-06,
      "loss": 0.0038,
      "step": 66670
    },
    {
      "epoch": 4.863957983806259,
      "grad_norm": 0.33535197377204895,
      "learning_rate": 1.3604201619374134e-06,
      "loss": 0.0022,
      "step": 66680
    },
    {
      "epoch": 4.864687431614268,
      "grad_norm": 0.09070795774459839,
      "learning_rate": 1.35312568385732e-06,
      "loss": 0.0045,
      "step": 66690
    },
    {
      "epoch": 4.865416879422277,
      "grad_norm": 0.11632278561592102,
      "learning_rate": 1.3458312057772267e-06,
      "loss": 0.0026,
      "step": 66700
    },
    {
      "epoch": 4.866146327230287,
      "grad_norm": 0.14481084048748016,
      "learning_rate": 1.3385367276971334e-06,
      "loss": 0.0032,
      "step": 66710
    },
    {
      "epoch": 4.866875775038296,
      "grad_norm": 0.4615119695663452,
      "learning_rate": 1.33124224961704e-06,
      "loss": 0.0028,
      "step": 66720
    },
    {
      "epoch": 4.867605222846305,
      "grad_norm": 0.28844571113586426,
      "learning_rate": 1.3239477715369466e-06,
      "loss": 0.0029,
      "step": 66730
    },
    {
      "epoch": 4.868334670654315,
      "grad_norm": 0.20226670801639557,
      "learning_rate": 1.3166532934568533e-06,
      "loss": 0.004,
      "step": 66740
    },
    {
      "epoch": 4.869064118462324,
      "grad_norm": 0.09293975681066513,
      "learning_rate": 1.3093588153767597e-06,
      "loss": 0.0027,
      "step": 66750
    },
    {
      "epoch": 4.869793566270333,
      "grad_norm": 0.23145508766174316,
      "learning_rate": 1.3020643372966666e-06,
      "loss": 0.0025,
      "step": 66760
    },
    {
      "epoch": 4.870523014078342,
      "grad_norm": 0.288793683052063,
      "learning_rate": 1.294769859216573e-06,
      "loss": 0.0016,
      "step": 66770
    },
    {
      "epoch": 4.871252461886352,
      "grad_norm": 0.23501409590244293,
      "learning_rate": 1.2874753811364798e-06,
      "loss": 0.0035,
      "step": 66780
    },
    {
      "epoch": 4.8719819096943615,
      "grad_norm": 0.030309069901704788,
      "learning_rate": 1.2801809030563865e-06,
      "loss": 0.0028,
      "step": 66790
    },
    {
      "epoch": 4.872711357502371,
      "grad_norm": 0.03102952614426613,
      "learning_rate": 1.2728864249762931e-06,
      "loss": 0.0032,
      "step": 66800
    },
    {
      "epoch": 4.87344080531038,
      "grad_norm": 0.2902212142944336,
      "learning_rate": 1.2655919468961996e-06,
      "loss": 0.0024,
      "step": 66810
    },
    {
      "epoch": 4.87417025311839,
      "grad_norm": 0.05837758630514145,
      "learning_rate": 1.258297468816106e-06,
      "loss": 0.0029,
      "step": 66820
    },
    {
      "epoch": 4.874899700926399,
      "grad_norm": 0.23096133768558502,
      "learning_rate": 1.251002990736013e-06,
      "loss": 0.0028,
      "step": 66830
    },
    {
      "epoch": 4.875629148734408,
      "grad_norm": 0.1149129718542099,
      "learning_rate": 1.2437085126559195e-06,
      "loss": 0.0044,
      "step": 66840
    },
    {
      "epoch": 4.876358596542417,
      "grad_norm": 0.21966487169265747,
      "learning_rate": 1.2364140345758261e-06,
      "loss": 0.002,
      "step": 66850
    },
    {
      "epoch": 4.877088044350427,
      "grad_norm": 0.4334220290184021,
      "learning_rate": 1.2291195564957328e-06,
      "loss": 0.0024,
      "step": 66860
    },
    {
      "epoch": 4.877817492158436,
      "grad_norm": 0.08719580620527267,
      "learning_rate": 1.2218250784156395e-06,
      "loss": 0.002,
      "step": 66870
    },
    {
      "epoch": 4.878546939966445,
      "grad_norm": 0.259809672832489,
      "learning_rate": 1.214530600335546e-06,
      "loss": 0.0022,
      "step": 66880
    },
    {
      "epoch": 4.879276387774455,
      "grad_norm": 0.37664851546287537,
      "learning_rate": 1.2072361222554527e-06,
      "loss": 0.0021,
      "step": 66890
    },
    {
      "epoch": 4.880005835582464,
      "grad_norm": 0.05887357518076897,
      "learning_rate": 1.1999416441753593e-06,
      "loss": 0.0022,
      "step": 66900
    },
    {
      "epoch": 4.880735283390473,
      "grad_norm": 0.2018517106771469,
      "learning_rate": 1.1926471660952658e-06,
      "loss": 0.0028,
      "step": 66910
    },
    {
      "epoch": 4.8814647311984825,
      "grad_norm": 0.31879037618637085,
      "learning_rate": 1.1853526880151725e-06,
      "loss": 0.0021,
      "step": 66920
    },
    {
      "epoch": 4.882194179006492,
      "grad_norm": 0.5667607188224792,
      "learning_rate": 1.1780582099350792e-06,
      "loss": 0.003,
      "step": 66930
    },
    {
      "epoch": 4.8829236268145015,
      "grad_norm": 0.05887964740395546,
      "learning_rate": 1.1707637318549859e-06,
      "loss": 0.0017,
      "step": 66940
    },
    {
      "epoch": 4.883653074622511,
      "grad_norm": 0.14376282691955566,
      "learning_rate": 1.1634692537748923e-06,
      "loss": 0.002,
      "step": 66950
    },
    {
      "epoch": 4.88438252243052,
      "grad_norm": 0.13090001046657562,
      "learning_rate": 1.1561747756947992e-06,
      "loss": 0.0021,
      "step": 66960
    },
    {
      "epoch": 4.88511197023853,
      "grad_norm": 0.12220336496829987,
      "learning_rate": 1.1488802976147057e-06,
      "loss": 0.0023,
      "step": 66970
    },
    {
      "epoch": 4.885841418046539,
      "grad_norm": 0.144324392080307,
      "learning_rate": 1.1415858195346122e-06,
      "loss": 0.0029,
      "step": 66980
    },
    {
      "epoch": 4.886570865854548,
      "grad_norm": 0.17287687957286835,
      "learning_rate": 1.134291341454519e-06,
      "loss": 0.0031,
      "step": 66990
    },
    {
      "epoch": 4.887300313662557,
      "grad_norm": 0.17304541170597076,
      "learning_rate": 1.1269968633744255e-06,
      "loss": 0.0026,
      "step": 67000
    },
    {
      "epoch": 4.888029761470567,
      "grad_norm": 0.4344649910926819,
      "learning_rate": 1.1197023852943322e-06,
      "loss": 0.0022,
      "step": 67010
    },
    {
      "epoch": 4.888759209278576,
      "grad_norm": 0.17647995054721832,
      "learning_rate": 1.112407907214239e-06,
      "loss": 0.0036,
      "step": 67020
    },
    {
      "epoch": 4.889488657086585,
      "grad_norm": 0.20179475843906403,
      "learning_rate": 1.1051134291341456e-06,
      "loss": 0.0033,
      "step": 67030
    },
    {
      "epoch": 4.890218104894595,
      "grad_norm": 0.3037818372249603,
      "learning_rate": 1.097818951054052e-06,
      "loss": 0.0024,
      "step": 67040
    },
    {
      "epoch": 4.890947552702604,
      "grad_norm": 0.10544295608997345,
      "learning_rate": 1.0905244729739587e-06,
      "loss": 0.0028,
      "step": 67050
    },
    {
      "epoch": 4.891677000510613,
      "grad_norm": 0.2954154908657074,
      "learning_rate": 1.0832299948938654e-06,
      "loss": 0.0025,
      "step": 67060
    },
    {
      "epoch": 4.8924064483186225,
      "grad_norm": 0.03994789347052574,
      "learning_rate": 1.0759355168137719e-06,
      "loss": 0.0029,
      "step": 67070
    },
    {
      "epoch": 4.8931358961266325,
      "grad_norm": 0.010249725542962551,
      "learning_rate": 1.0686410387336786e-06,
      "loss": 0.0027,
      "step": 67080
    },
    {
      "epoch": 4.893865343934642,
      "grad_norm": 0.31994205713272095,
      "learning_rate": 1.0613465606535853e-06,
      "loss": 0.0026,
      "step": 67090
    },
    {
      "epoch": 4.894594791742651,
      "grad_norm": 0.2304588407278061,
      "learning_rate": 1.054052082573492e-06,
      "loss": 0.003,
      "step": 67100
    },
    {
      "epoch": 4.89532423955066,
      "grad_norm": 0.17296265065670013,
      "learning_rate": 1.0467576044933984e-06,
      "loss": 0.0023,
      "step": 67110
    },
    {
      "epoch": 4.89605368735867,
      "grad_norm": 0.22353452444076538,
      "learning_rate": 1.0394631264133053e-06,
      "loss": 0.0028,
      "step": 67120
    },
    {
      "epoch": 4.896783135166679,
      "grad_norm": 0.28882697224617004,
      "learning_rate": 1.0321686483332118e-06,
      "loss": 0.0034,
      "step": 67130
    },
    {
      "epoch": 4.897512582974688,
      "grad_norm": 0.1462077498435974,
      "learning_rate": 1.0248741702531185e-06,
      "loss": 0.004,
      "step": 67140
    },
    {
      "epoch": 4.898242030782697,
      "grad_norm": 0.25956442952156067,
      "learning_rate": 1.0175796921730251e-06,
      "loss": 0.0031,
      "step": 67150
    },
    {
      "epoch": 4.898971478590707,
      "grad_norm": 0.2263372391462326,
      "learning_rate": 1.0102852140929316e-06,
      "loss": 0.0029,
      "step": 67160
    },
    {
      "epoch": 4.899700926398716,
      "grad_norm": 0.08703380823135376,
      "learning_rate": 1.0029907360128383e-06,
      "loss": 0.002,
      "step": 67170
    },
    {
      "epoch": 4.900430374206725,
      "grad_norm": 0.09203971922397614,
      "learning_rate": 9.95696257932745e-07,
      "loss": 0.0025,
      "step": 67180
    },
    {
      "epoch": 4.901159822014735,
      "grad_norm": 0.20165294408798218,
      "learning_rate": 9.884017798526517e-07,
      "loss": 0.0032,
      "step": 67190
    },
    {
      "epoch": 4.901889269822744,
      "grad_norm": 0.08858960121870041,
      "learning_rate": 9.811073017725581e-07,
      "loss": 0.0028,
      "step": 67200
    },
    {
      "epoch": 4.902618717630753,
      "grad_norm": 0.024245018139481544,
      "learning_rate": 9.738128236924648e-07,
      "loss": 0.0031,
      "step": 67210
    },
    {
      "epoch": 4.9033481654387625,
      "grad_norm": 0.20897769927978516,
      "learning_rate": 9.665183456123715e-07,
      "loss": 0.0041,
      "step": 67220
    },
    {
      "epoch": 4.9040776132467725,
      "grad_norm": 0.4308926463127136,
      "learning_rate": 9.59223867532278e-07,
      "loss": 0.0031,
      "step": 67230
    },
    {
      "epoch": 4.904807061054782,
      "grad_norm": 0.20281508564949036,
      "learning_rate": 9.519293894521848e-07,
      "loss": 0.0018,
      "step": 67240
    },
    {
      "epoch": 4.905536508862791,
      "grad_norm": 0.23225633800029755,
      "learning_rate": 9.446349113720913e-07,
      "loss": 0.0037,
      "step": 67250
    },
    {
      "epoch": 4.906265956670801,
      "grad_norm": 0.058190807700157166,
      "learning_rate": 9.37340433291998e-07,
      "loss": 0.0025,
      "step": 67260
    },
    {
      "epoch": 4.90699540447881,
      "grad_norm": 0.013699021190404892,
      "learning_rate": 9.300459552119046e-07,
      "loss": 0.0032,
      "step": 67270
    },
    {
      "epoch": 4.907724852286819,
      "grad_norm": 0.14709052443504333,
      "learning_rate": 9.227514771318113e-07,
      "loss": 0.0037,
      "step": 67280
    },
    {
      "epoch": 4.908454300094828,
      "grad_norm": 0.1175122931599617,
      "learning_rate": 9.154569990517179e-07,
      "loss": 0.0026,
      "step": 67290
    },
    {
      "epoch": 4.909183747902837,
      "grad_norm": 0.11686907708644867,
      "learning_rate": 9.081625209716246e-07,
      "loss": 0.0026,
      "step": 67300
    },
    {
      "epoch": 4.909913195710847,
      "grad_norm": 0.49084845185279846,
      "learning_rate": 9.008680428915311e-07,
      "loss": 0.0029,
      "step": 67310
    },
    {
      "epoch": 4.910642643518856,
      "grad_norm": 0.03067830763757229,
      "learning_rate": 8.935735648114377e-07,
      "loss": 0.0031,
      "step": 67320
    },
    {
      "epoch": 4.911372091326865,
      "grad_norm": 0.4350397288799286,
      "learning_rate": 8.862790867313444e-07,
      "loss": 0.0027,
      "step": 67330
    },
    {
      "epoch": 4.912101539134875,
      "grad_norm": 0.015542068518698215,
      "learning_rate": 8.78984608651251e-07,
      "loss": 0.0029,
      "step": 67340
    },
    {
      "epoch": 4.912830986942884,
      "grad_norm": 0.17415596544742584,
      "learning_rate": 8.716901305711577e-07,
      "loss": 0.0028,
      "step": 67350
    },
    {
      "epoch": 4.913560434750893,
      "grad_norm": 0.08596821129322052,
      "learning_rate": 8.643956524910642e-07,
      "loss": 0.0035,
      "step": 67360
    },
    {
      "epoch": 4.9142898825589025,
      "grad_norm": 0.08640249073505402,
      "learning_rate": 8.57101174410971e-07,
      "loss": 0.0023,
      "step": 67370
    },
    {
      "epoch": 4.9150193303669125,
      "grad_norm": 0.20297451317310333,
      "learning_rate": 8.498066963308776e-07,
      "loss": 0.0026,
      "step": 67380
    },
    {
      "epoch": 4.915748778174922,
      "grad_norm": 0.32257282733917236,
      "learning_rate": 8.425122182507843e-07,
      "loss": 0.0027,
      "step": 67390
    },
    {
      "epoch": 4.916478225982931,
      "grad_norm": 0.40538346767425537,
      "learning_rate": 8.352177401706908e-07,
      "loss": 0.003,
      "step": 67400
    },
    {
      "epoch": 4.917207673790941,
      "grad_norm": 0.2373233586549759,
      "learning_rate": 8.279232620905974e-07,
      "loss": 0.0029,
      "step": 67410
    },
    {
      "epoch": 4.91793712159895,
      "grad_norm": 0.17332005500793457,
      "learning_rate": 8.206287840105041e-07,
      "loss": 0.0023,
      "step": 67420
    },
    {
      "epoch": 4.918666569406959,
      "grad_norm": 0.26126939058303833,
      "learning_rate": 8.133343059304107e-07,
      "loss": 0.0018,
      "step": 67430
    },
    {
      "epoch": 4.919396017214968,
      "grad_norm": 0.44810327887535095,
      "learning_rate": 8.060398278503174e-07,
      "loss": 0.0029,
      "step": 67440
    },
    {
      "epoch": 4.920125465022978,
      "grad_norm": 0.17609642446041107,
      "learning_rate": 7.987453497702239e-07,
      "loss": 0.0025,
      "step": 67450
    },
    {
      "epoch": 4.920854912830987,
      "grad_norm": 0.14401604235172272,
      "learning_rate": 7.914508716901306e-07,
      "loss": 0.0024,
      "step": 67460
    },
    {
      "epoch": 4.921584360638996,
      "grad_norm": 0.23362129926681519,
      "learning_rate": 7.841563936100372e-07,
      "loss": 0.0024,
      "step": 67470
    },
    {
      "epoch": 4.922313808447005,
      "grad_norm": 0.1297193467617035,
      "learning_rate": 7.768619155299439e-07,
      "loss": 0.003,
      "step": 67480
    },
    {
      "epoch": 4.923043256255015,
      "grad_norm": 0.11665133386850357,
      "learning_rate": 7.695674374498505e-07,
      "loss": 0.0029,
      "step": 67490
    },
    {
      "epoch": 4.923772704063024,
      "grad_norm": 0.14411751925945282,
      "learning_rate": 7.622729593697571e-07,
      "loss": 0.0028,
      "step": 67500
    },
    {
      "epoch": 4.9245021518710335,
      "grad_norm": 0.2882433831691742,
      "learning_rate": 7.549784812896638e-07,
      "loss": 0.0026,
      "step": 67510
    },
    {
      "epoch": 4.925231599679043,
      "grad_norm": 0.23048679530620575,
      "learning_rate": 7.476840032095704e-07,
      "loss": 0.0035,
      "step": 67520
    },
    {
      "epoch": 4.9259610474870525,
      "grad_norm": 0.05849749967455864,
      "learning_rate": 7.40389525129477e-07,
      "loss": 0.0023,
      "step": 67530
    },
    {
      "epoch": 4.926690495295062,
      "grad_norm": 0.16137723624706268,
      "learning_rate": 7.330950470493837e-07,
      "loss": 0.0017,
      "step": 67540
    },
    {
      "epoch": 4.927419943103071,
      "grad_norm": 0.1741369515657425,
      "learning_rate": 7.258005689692902e-07,
      "loss": 0.0027,
      "step": 67550
    },
    {
      "epoch": 4.928149390911081,
      "grad_norm": 0.08704258501529694,
      "learning_rate": 7.185060908891969e-07,
      "loss": 0.0046,
      "step": 67560
    },
    {
      "epoch": 4.92887883871909,
      "grad_norm": 0.21571031212806702,
      "learning_rate": 7.112116128091035e-07,
      "loss": 0.0026,
      "step": 67570
    },
    {
      "epoch": 4.929608286527099,
      "grad_norm": 0.40451231598854065,
      "learning_rate": 7.039171347290102e-07,
      "loss": 0.0026,
      "step": 67580
    },
    {
      "epoch": 4.930337734335108,
      "grad_norm": 0.2897837460041046,
      "learning_rate": 6.966226566489169e-07,
      "loss": 0.0028,
      "step": 67590
    },
    {
      "epoch": 4.931067182143118,
      "grad_norm": 0.05996344983577728,
      "learning_rate": 6.893281785688234e-07,
      "loss": 0.0024,
      "step": 67600
    },
    {
      "epoch": 4.931796629951127,
      "grad_norm": 0.05856006219983101,
      "learning_rate": 6.820337004887301e-07,
      "loss": 0.0036,
      "step": 67610
    },
    {
      "epoch": 4.932526077759136,
      "grad_norm": 0.16110756993293762,
      "learning_rate": 6.747392224086367e-07,
      "loss": 0.0022,
      "step": 67620
    },
    {
      "epoch": 4.933255525567145,
      "grad_norm": 0.11623111367225647,
      "learning_rate": 6.674447443285433e-07,
      "loss": 0.0024,
      "step": 67630
    },
    {
      "epoch": 4.933984973375155,
      "grad_norm": 0.49997198581695557,
      "learning_rate": 6.6015026624845e-07,
      "loss": 0.0031,
      "step": 67640
    },
    {
      "epoch": 4.934714421183164,
      "grad_norm": 0.12189134955406189,
      "learning_rate": 6.528557881683565e-07,
      "loss": 0.0022,
      "step": 67650
    },
    {
      "epoch": 4.9354438689911735,
      "grad_norm": 0.20319510996341705,
      "learning_rate": 6.455613100882632e-07,
      "loss": 0.0029,
      "step": 67660
    },
    {
      "epoch": 4.936173316799183,
      "grad_norm": 0.10664347559213638,
      "learning_rate": 6.382668320081699e-07,
      "loss": 0.0014,
      "step": 67670
    },
    {
      "epoch": 4.936902764607193,
      "grad_norm": 0.3165130913257599,
      "learning_rate": 6.309723539280765e-07,
      "loss": 0.0026,
      "step": 67680
    },
    {
      "epoch": 4.937632212415202,
      "grad_norm": 0.03589800000190735,
      "learning_rate": 6.236778758479832e-07,
      "loss": 0.0036,
      "step": 67690
    },
    {
      "epoch": 4.938361660223211,
      "grad_norm": 0.28188204765319824,
      "learning_rate": 6.163833977678897e-07,
      "loss": 0.0045,
      "step": 67700
    },
    {
      "epoch": 4.939091108031221,
      "grad_norm": 0.08662902563810349,
      "learning_rate": 6.090889196877963e-07,
      "loss": 0.0028,
      "step": 67710
    },
    {
      "epoch": 4.93982055583923,
      "grad_norm": 0.14478006958961487,
      "learning_rate": 6.01794441607703e-07,
      "loss": 0.0016,
      "step": 67720
    },
    {
      "epoch": 4.940550003647239,
      "grad_norm": 0.2900651693344116,
      "learning_rate": 5.944999635276096e-07,
      "loss": 0.003,
      "step": 67730
    },
    {
      "epoch": 4.941279451455248,
      "grad_norm": 0.0576542392373085,
      "learning_rate": 5.872054854475163e-07,
      "loss": 0.0029,
      "step": 67740
    },
    {
      "epoch": 4.942008899263258,
      "grad_norm": 0.2288110852241516,
      "learning_rate": 5.799110073674229e-07,
      "loss": 0.0038,
      "step": 67750
    },
    {
      "epoch": 4.942738347071267,
      "grad_norm": 0.143389031291008,
      "learning_rate": 5.726165292873295e-07,
      "loss": 0.0031,
      "step": 67760
    },
    {
      "epoch": 4.943467794879276,
      "grad_norm": 0.08662796020507812,
      "learning_rate": 5.653220512072362e-07,
      "loss": 0.0021,
      "step": 67770
    },
    {
      "epoch": 4.944197242687286,
      "grad_norm": 0.09470526874065399,
      "learning_rate": 5.580275731271428e-07,
      "loss": 0.003,
      "step": 67780
    },
    {
      "epoch": 4.944926690495295,
      "grad_norm": 0.14482609927654266,
      "learning_rate": 5.507330950470494e-07,
      "loss": 0.0037,
      "step": 67790
    },
    {
      "epoch": 4.945656138303304,
      "grad_norm": 0.05811545252799988,
      "learning_rate": 5.43438616966956e-07,
      "loss": 0.0021,
      "step": 67800
    },
    {
      "epoch": 4.9463855861113135,
      "grad_norm": 0.11558336019515991,
      "learning_rate": 5.361441388868626e-07,
      "loss": 0.0024,
      "step": 67810
    },
    {
      "epoch": 4.947115033919323,
      "grad_norm": 0.11727138608694077,
      "learning_rate": 5.288496608067693e-07,
      "loss": 0.0021,
      "step": 67820
    },
    {
      "epoch": 4.947844481727333,
      "grad_norm": 0.3727273941040039,
      "learning_rate": 5.21555182726676e-07,
      "loss": 0.0026,
      "step": 67830
    },
    {
      "epoch": 4.948573929535342,
      "grad_norm": 0.2006465196609497,
      "learning_rate": 5.142607046465826e-07,
      "loss": 0.0019,
      "step": 67840
    },
    {
      "epoch": 4.949303377343351,
      "grad_norm": 0.0881546288728714,
      "learning_rate": 5.069662265664892e-07,
      "loss": 0.0026,
      "step": 67850
    },
    {
      "epoch": 4.950032825151361,
      "grad_norm": 0.09900890290737152,
      "learning_rate": 4.996717484863958e-07,
      "loss": 0.0027,
      "step": 67860
    },
    {
      "epoch": 4.95076227295937,
      "grad_norm": 0.20299050211906433,
      "learning_rate": 4.923772704063024e-07,
      "loss": 0.0024,
      "step": 67870
    },
    {
      "epoch": 4.951491720767379,
      "grad_norm": 0.08790910243988037,
      "learning_rate": 4.850827923262091e-07,
      "loss": 0.0029,
      "step": 67880
    },
    {
      "epoch": 4.952221168575388,
      "grad_norm": 0.14416810870170593,
      "learning_rate": 4.777883142461157e-07,
      "loss": 0.0031,
      "step": 67890
    },
    {
      "epoch": 4.952950616383398,
      "grad_norm": 0.3178815245628357,
      "learning_rate": 4.7049383616602234e-07,
      "loss": 0.0026,
      "step": 67900
    },
    {
      "epoch": 4.953680064191407,
      "grad_norm": 0.11234284937381744,
      "learning_rate": 4.6319935808592897e-07,
      "loss": 0.0032,
      "step": 67910
    },
    {
      "epoch": 4.954409511999416,
      "grad_norm": 0.1036088690161705,
      "learning_rate": 4.559048800058356e-07,
      "loss": 0.0024,
      "step": 67920
    },
    {
      "epoch": 4.955138959807426,
      "grad_norm": 0.03052430786192417,
      "learning_rate": 4.486104019257423e-07,
      "loss": 0.0033,
      "step": 67930
    },
    {
      "epoch": 4.955868407615435,
      "grad_norm": 0.14453138411045074,
      "learning_rate": 4.413159238456489e-07,
      "loss": 0.003,
      "step": 67940
    },
    {
      "epoch": 4.956597855423444,
      "grad_norm": 0.008245198056101799,
      "learning_rate": 4.3402144576555554e-07,
      "loss": 0.0035,
      "step": 67950
    },
    {
      "epoch": 4.9573273032314535,
      "grad_norm": 0.058730583637952805,
      "learning_rate": 4.2672696768546207e-07,
      "loss": 0.0025,
      "step": 67960
    },
    {
      "epoch": 4.958056751039463,
      "grad_norm": 0.28809574246406555,
      "learning_rate": 4.1943248960536875e-07,
      "loss": 0.0029,
      "step": 67970
    },
    {
      "epoch": 4.958786198847473,
      "grad_norm": 0.37426429986953735,
      "learning_rate": 4.121380115252754e-07,
      "loss": 0.0014,
      "step": 67980
    },
    {
      "epoch": 4.959515646655482,
      "grad_norm": 0.2489788979291916,
      "learning_rate": 4.04843533445182e-07,
      "loss": 0.0029,
      "step": 67990
    },
    {
      "epoch": 4.960245094463491,
      "grad_norm": 0.029526986181735992,
      "learning_rate": 3.9754905536508864e-07,
      "loss": 0.0031,
      "step": 68000
    },
    {
      "epoch": 4.960974542271501,
      "grad_norm": 0.0890490859746933,
      "learning_rate": 3.9025457728499527e-07,
      "loss": 0.0032,
      "step": 68010
    },
    {
      "epoch": 4.96170399007951,
      "grad_norm": 0.1751732975244522,
      "learning_rate": 3.829600992049019e-07,
      "loss": 0.0027,
      "step": 68020
    },
    {
      "epoch": 4.962433437887519,
      "grad_norm": 0.1583465188741684,
      "learning_rate": 3.7566562112480853e-07,
      "loss": 0.0026,
      "step": 68030
    },
    {
      "epoch": 4.963162885695528,
      "grad_norm": 0.2912502884864807,
      "learning_rate": 3.6837114304471516e-07,
      "loss": 0.0018,
      "step": 68040
    },
    {
      "epoch": 4.963892333503538,
      "grad_norm": 0.11565548926591873,
      "learning_rate": 3.610766649646218e-07,
      "loss": 0.0035,
      "step": 68050
    },
    {
      "epoch": 4.964621781311547,
      "grad_norm": 0.2591336965560913,
      "learning_rate": 3.537821868845284e-07,
      "loss": 0.0022,
      "step": 68060
    },
    {
      "epoch": 4.965351229119556,
      "grad_norm": 0.1969623863697052,
      "learning_rate": 3.4648770880443505e-07,
      "loss": 0.0033,
      "step": 68070
    },
    {
      "epoch": 4.966080676927566,
      "grad_norm": 0.05917865037918091,
      "learning_rate": 3.391932307243417e-07,
      "loss": 0.0026,
      "step": 68080
    },
    {
      "epoch": 4.966810124735575,
      "grad_norm": 0.014020988717675209,
      "learning_rate": 3.318987526442483e-07,
      "loss": 0.0022,
      "step": 68090
    },
    {
      "epoch": 4.9675395725435845,
      "grad_norm": 0.017609886825084686,
      "learning_rate": 3.2460427456415494e-07,
      "loss": 0.002,
      "step": 68100
    },
    {
      "epoch": 4.968269020351594,
      "grad_norm": 0.03331364691257477,
      "learning_rate": 3.1730979648406157e-07,
      "loss": 0.0023,
      "step": 68110
    },
    {
      "epoch": 4.9689984681596036,
      "grad_norm": 0.012989208102226257,
      "learning_rate": 3.100153184039682e-07,
      "loss": 0.0033,
      "step": 68120
    },
    {
      "epoch": 4.969727915967613,
      "grad_norm": 0.1451716274023056,
      "learning_rate": 3.0272084032387483e-07,
      "loss": 0.0023,
      "step": 68130
    },
    {
      "epoch": 4.970457363775622,
      "grad_norm": 0.18099446594715118,
      "learning_rate": 2.954263622437815e-07,
      "loss": 0.0021,
      "step": 68140
    },
    {
      "epoch": 4.971186811583631,
      "grad_norm": 0.24452310800552368,
      "learning_rate": 2.881318841636881e-07,
      "loss": 0.0023,
      "step": 68150
    },
    {
      "epoch": 4.971916259391641,
      "grad_norm": 0.2601223587989807,
      "learning_rate": 2.808374060835947e-07,
      "loss": 0.0031,
      "step": 68160
    },
    {
      "epoch": 4.97264570719965,
      "grad_norm": 0.20152100920677185,
      "learning_rate": 2.7354292800350135e-07,
      "loss": 0.0035,
      "step": 68170
    },
    {
      "epoch": 4.973375155007659,
      "grad_norm": 0.04543783515691757,
      "learning_rate": 2.6624844992340803e-07,
      "loss": 0.0026,
      "step": 68180
    },
    {
      "epoch": 4.974104602815668,
      "grad_norm": 0.20339329540729523,
      "learning_rate": 2.589539718433146e-07,
      "loss": 0.003,
      "step": 68190
    },
    {
      "epoch": 4.974834050623678,
      "grad_norm": 0.030466197058558464,
      "learning_rate": 2.5165949376322124e-07,
      "loss": 0.0031,
      "step": 68200
    },
    {
      "epoch": 4.975563498431687,
      "grad_norm": 0.08779238164424896,
      "learning_rate": 2.4436501568312787e-07,
      "loss": 0.0027,
      "step": 68210
    },
    {
      "epoch": 4.976292946239696,
      "grad_norm": 0.05853479728102684,
      "learning_rate": 2.3707053760303453e-07,
      "loss": 0.0023,
      "step": 68220
    },
    {
      "epoch": 4.977022394047706,
      "grad_norm": 0.01829369366168976,
      "learning_rate": 2.2977605952294113e-07,
      "loss": 0.0022,
      "step": 68230
    },
    {
      "epoch": 4.977751841855715,
      "grad_norm": 0.2774141728878021,
      "learning_rate": 2.2248158144284776e-07,
      "loss": 0.003,
      "step": 68240
    },
    {
      "epoch": 4.9784812896637245,
      "grad_norm": 0.38274985551834106,
      "learning_rate": 2.1518710336275442e-07,
      "loss": 0.0021,
      "step": 68250
    },
    {
      "epoch": 4.979210737471734,
      "grad_norm": 0.11527803540229797,
      "learning_rate": 2.0789262528266105e-07,
      "loss": 0.0022,
      "step": 68260
    },
    {
      "epoch": 4.979940185279744,
      "grad_norm": 0.11507335305213928,
      "learning_rate": 2.0059814720256765e-07,
      "loss": 0.003,
      "step": 68270
    },
    {
      "epoch": 4.980669633087753,
      "grad_norm": 0.2874169945716858,
      "learning_rate": 1.9330366912247428e-07,
      "loss": 0.0035,
      "step": 68280
    },
    {
      "epoch": 4.981399080895762,
      "grad_norm": 0.09467899799346924,
      "learning_rate": 1.8600919104238094e-07,
      "loss": 0.0036,
      "step": 68290
    },
    {
      "epoch": 4.982128528703771,
      "grad_norm": 0.08808223158121109,
      "learning_rate": 1.7871471296228757e-07,
      "loss": 0.0027,
      "step": 68300
    },
    {
      "epoch": 4.982857976511781,
      "grad_norm": 0.6196205019950867,
      "learning_rate": 1.714202348821942e-07,
      "loss": 0.0031,
      "step": 68310
    },
    {
      "epoch": 4.98358742431979,
      "grad_norm": 0.00960896722972393,
      "learning_rate": 1.6412575680210083e-07,
      "loss": 0.0037,
      "step": 68320
    },
    {
      "epoch": 4.984316872127799,
      "grad_norm": 0.04386318102478981,
      "learning_rate": 1.5683127872200746e-07,
      "loss": 0.0031,
      "step": 68330
    },
    {
      "epoch": 4.985046319935808,
      "grad_norm": 0.08884594589471817,
      "learning_rate": 1.4953680064191409e-07,
      "loss": 0.0017,
      "step": 68340
    },
    {
      "epoch": 4.985775767743818,
      "grad_norm": 0.08807793259620667,
      "learning_rate": 1.4224232256182072e-07,
      "loss": 0.0028,
      "step": 68350
    },
    {
      "epoch": 4.986505215551827,
      "grad_norm": 0.28909510374069214,
      "learning_rate": 1.3494784448172735e-07,
      "loss": 0.0029,
      "step": 68360
    },
    {
      "epoch": 4.987234663359836,
      "grad_norm": 0.1737876534461975,
      "learning_rate": 1.2765336640163398e-07,
      "loss": 0.0037,
      "step": 68370
    },
    {
      "epoch": 4.987964111167846,
      "grad_norm": 0.5889332890510559,
      "learning_rate": 1.203588883215406e-07,
      "loss": 0.003,
      "step": 68380
    },
    {
      "epoch": 4.988693558975855,
      "grad_norm": 0.26994138956069946,
      "learning_rate": 1.1306441024144722e-07,
      "loss": 0.0022,
      "step": 68390
    },
    {
      "epoch": 4.9894230067838645,
      "grad_norm": 0.25402429699897766,
      "learning_rate": 1.0576993216135387e-07,
      "loss": 0.0021,
      "step": 68400
    },
    {
      "epoch": 4.990152454591874,
      "grad_norm": 0.40590426325798035,
      "learning_rate": 9.847545408126048e-08,
      "loss": 0.002,
      "step": 68410
    },
    {
      "epoch": 4.990881902399884,
      "grad_norm": 0.04042590409517288,
      "learning_rate": 9.118097600116713e-08,
      "loss": 0.0022,
      "step": 68420
    },
    {
      "epoch": 4.991611350207893,
      "grad_norm": 0.07337258756160736,
      "learning_rate": 8.388649792107376e-08,
      "loss": 0.0019,
      "step": 68430
    },
    {
      "epoch": 4.992340798015902,
      "grad_norm": 0.5035762190818787,
      "learning_rate": 7.659201984098039e-08,
      "loss": 0.0038,
      "step": 68440
    },
    {
      "epoch": 4.993070245823912,
      "grad_norm": 0.3175704777240753,
      "learning_rate": 6.929754176088702e-08,
      "loss": 0.0028,
      "step": 68450
    },
    {
      "epoch": 4.993799693631921,
      "grad_norm": 0.03816130757331848,
      "learning_rate": 6.200306368079365e-08,
      "loss": 0.0028,
      "step": 68460
    },
    {
      "epoch": 4.99452914143993,
      "grad_norm": 0.0612899549305439,
      "learning_rate": 5.470858560070027e-08,
      "loss": 0.0028,
      "step": 68470
    },
    {
      "epoch": 4.995258589247939,
      "grad_norm": 0.04691777378320694,
      "learning_rate": 4.74141075206069e-08,
      "loss": 0.0025,
      "step": 68480
    },
    {
      "epoch": 4.995988037055948,
      "grad_norm": 0.10393456369638443,
      "learning_rate": 4.011962944051353e-08,
      "loss": 0.0022,
      "step": 68490
    },
    {
      "epoch": 4.996717484863958,
      "grad_norm": 0.06124553829431534,
      "learning_rate": 3.282515136042016e-08,
      "loss": 0.0021,
      "step": 68500
    }
  ],
  "logging_steps": 10,
  "max_steps": 68545,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 0.0,
  "train_batch_size": 40,
  "trial_name": null,
  "trial_params": null
}
