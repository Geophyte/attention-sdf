{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 9.941121256079871,
  "eval_steps": 500,
  "global_step": 116500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0008533151292772421,
      "grad_norm": 0.34355127811431885,
      "learning_rate": 4.999573342435362e-05,
      "loss": 0.0108,
      "step": 10
    },
    {
      "epoch": 0.0017066302585544842,
      "grad_norm": 0.9027493000030518,
      "learning_rate": 4.999146684870723e-05,
      "loss": 0.0078,
      "step": 20
    },
    {
      "epoch": 0.0025599453878317265,
      "grad_norm": 0.7875605821609497,
      "learning_rate": 4.998720027306084e-05,
      "loss": 0.0064,
      "step": 30
    },
    {
      "epoch": 0.0034132605171089685,
      "grad_norm": 0.11942391842603683,
      "learning_rate": 4.998293369741446e-05,
      "loss": 0.0062,
      "step": 40
    },
    {
      "epoch": 0.00426657564638621,
      "grad_norm": 0.4873679578304291,
      "learning_rate": 4.997866712176807e-05,
      "loss": 0.0069,
      "step": 50
    },
    {
      "epoch": 0.005119890775663453,
      "grad_norm": 0.6002193689346313,
      "learning_rate": 4.997440054612169e-05,
      "loss": 0.0076,
      "step": 60
    },
    {
      "epoch": 0.005973205904940695,
      "grad_norm": 0.33612123131752014,
      "learning_rate": 4.9970133970475295e-05,
      "loss": 0.0052,
      "step": 70
    },
    {
      "epoch": 0.006826521034217937,
      "grad_norm": 0.1183251217007637,
      "learning_rate": 4.9965867394828916e-05,
      "loss": 0.0075,
      "step": 80
    },
    {
      "epoch": 0.007679836163495179,
      "grad_norm": 0.030841905623674393,
      "learning_rate": 4.9961600819182524e-05,
      "loss": 0.0055,
      "step": 90
    },
    {
      "epoch": 0.00853315129277242,
      "grad_norm": 0.05888752639293671,
      "learning_rate": 4.995733424353614e-05,
      "loss": 0.0075,
      "step": 100
    },
    {
      "epoch": 0.009386466422049662,
      "grad_norm": 0.10030746459960938,
      "learning_rate": 4.995306766788975e-05,
      "loss": 0.0057,
      "step": 110
    },
    {
      "epoch": 0.010239781551326906,
      "grad_norm": 0.11985316127538681,
      "learning_rate": 4.9948801092243367e-05,
      "loss": 0.0074,
      "step": 120
    },
    {
      "epoch": 0.011093096680604148,
      "grad_norm": 0.05634342133998871,
      "learning_rate": 4.994453451659698e-05,
      "loss": 0.0068,
      "step": 130
    },
    {
      "epoch": 0.01194641180988139,
      "grad_norm": 0.3080562353134155,
      "learning_rate": 4.9940267940950595e-05,
      "loss": 0.007,
      "step": 140
    },
    {
      "epoch": 0.012799726939158632,
      "grad_norm": 0.15403077006340027,
      "learning_rate": 4.993600136530421e-05,
      "loss": 0.0063,
      "step": 150
    },
    {
      "epoch": 0.013653042068435874,
      "grad_norm": 0.15178123116493225,
      "learning_rate": 4.9931734789657823e-05,
      "loss": 0.0058,
      "step": 160
    },
    {
      "epoch": 0.014506357197713116,
      "grad_norm": 0.4131828546524048,
      "learning_rate": 4.992746821401144e-05,
      "loss": 0.007,
      "step": 170
    },
    {
      "epoch": 0.015359672326990358,
      "grad_norm": 0.5644388198852539,
      "learning_rate": 4.992320163836505e-05,
      "loss": 0.0079,
      "step": 180
    },
    {
      "epoch": 0.016212987456267598,
      "grad_norm": 0.37712791562080383,
      "learning_rate": 4.9918935062718666e-05,
      "loss": 0.006,
      "step": 190
    },
    {
      "epoch": 0.01706630258554484,
      "grad_norm": 0.4883284568786621,
      "learning_rate": 4.991466848707228e-05,
      "loss": 0.0058,
      "step": 200
    },
    {
      "epoch": 0.017919617714822082,
      "grad_norm": 0.0789308249950409,
      "learning_rate": 4.9910401911425895e-05,
      "loss": 0.0069,
      "step": 210
    },
    {
      "epoch": 0.018772932844099324,
      "grad_norm": 0.3400109112262726,
      "learning_rate": 4.990613533577951e-05,
      "loss": 0.0067,
      "step": 220
    },
    {
      "epoch": 0.019626247973376566,
      "grad_norm": 0.18785357475280762,
      "learning_rate": 4.9901868760133116e-05,
      "loss": 0.0073,
      "step": 230
    },
    {
      "epoch": 0.020479563102653812,
      "grad_norm": 0.11906414479017258,
      "learning_rate": 4.989760218448674e-05,
      "loss": 0.0077,
      "step": 240
    },
    {
      "epoch": 0.021332878231931054,
      "grad_norm": 0.09551531821489334,
      "learning_rate": 4.9893335608840345e-05,
      "loss": 0.0068,
      "step": 250
    },
    {
      "epoch": 0.022186193361208296,
      "grad_norm": 0.48716217279434204,
      "learning_rate": 4.9889069033193966e-05,
      "loss": 0.0054,
      "step": 260
    },
    {
      "epoch": 0.023039508490485538,
      "grad_norm": 0.5982258915901184,
      "learning_rate": 4.988480245754757e-05,
      "loss": 0.0063,
      "step": 270
    },
    {
      "epoch": 0.02389282361976278,
      "grad_norm": 0.22907276451587677,
      "learning_rate": 4.988053588190119e-05,
      "loss": 0.006,
      "step": 280
    },
    {
      "epoch": 0.024746138749040022,
      "grad_norm": 0.4883180260658264,
      "learning_rate": 4.98762693062548e-05,
      "loss": 0.0056,
      "step": 290
    },
    {
      "epoch": 0.025599453878317264,
      "grad_norm": 0.04522288590669632,
      "learning_rate": 4.9872002730608416e-05,
      "loss": 0.0055,
      "step": 300
    },
    {
      "epoch": 0.026452769007594506,
      "grad_norm": 0.3416095972061157,
      "learning_rate": 4.986773615496203e-05,
      "loss": 0.0072,
      "step": 310
    },
    {
      "epoch": 0.027306084136871748,
      "grad_norm": 0.3757609724998474,
      "learning_rate": 4.9863469579315645e-05,
      "loss": 0.005,
      "step": 320
    },
    {
      "epoch": 0.02815939926614899,
      "grad_norm": 0.4882664084434509,
      "learning_rate": 4.985920300366926e-05,
      "loss": 0.0065,
      "step": 330
    },
    {
      "epoch": 0.029012714395426232,
      "grad_norm": 0.5996049046516418,
      "learning_rate": 4.9854936428022866e-05,
      "loss": 0.006,
      "step": 340
    },
    {
      "epoch": 0.029866029524703474,
      "grad_norm": 0.1134667620062828,
      "learning_rate": 4.985066985237649e-05,
      "loss": 0.0062,
      "step": 350
    },
    {
      "epoch": 0.030719344653980716,
      "grad_norm": 0.11558807641267776,
      "learning_rate": 4.9846403276730095e-05,
      "loss": 0.0077,
      "step": 360
    },
    {
      "epoch": 0.031572659783257954,
      "grad_norm": 0.15277080237865448,
      "learning_rate": 4.9842136701083716e-05,
      "loss": 0.0059,
      "step": 370
    },
    {
      "epoch": 0.032425974912535196,
      "grad_norm": 0.3373357653617859,
      "learning_rate": 4.983787012543732e-05,
      "loss": 0.0078,
      "step": 380
    },
    {
      "epoch": 0.03327929004181244,
      "grad_norm": 0.15634740889072418,
      "learning_rate": 4.9833603549790944e-05,
      "loss": 0.006,
      "step": 390
    },
    {
      "epoch": 0.03413260517108968,
      "grad_norm": 0.22510915994644165,
      "learning_rate": 4.982933697414455e-05,
      "loss": 0.0066,
      "step": 400
    },
    {
      "epoch": 0.03498592030036692,
      "grad_norm": 0.30093178153038025,
      "learning_rate": 4.9825070398498166e-05,
      "loss": 0.0055,
      "step": 410
    },
    {
      "epoch": 0.035839235429644165,
      "grad_norm": 0.3043505847454071,
      "learning_rate": 4.982080382285178e-05,
      "loss": 0.0059,
      "step": 420
    },
    {
      "epoch": 0.03669255055892141,
      "grad_norm": 0.5626343488693237,
      "learning_rate": 4.9816537247205394e-05,
      "loss": 0.0065,
      "step": 430
    },
    {
      "epoch": 0.03754586568819865,
      "grad_norm": 0.5995192527770996,
      "learning_rate": 4.981227067155901e-05,
      "loss": 0.0066,
      "step": 440
    },
    {
      "epoch": 0.03839918081747589,
      "grad_norm": 0.1911434829235077,
      "learning_rate": 4.980800409591262e-05,
      "loss": 0.0062,
      "step": 450
    },
    {
      "epoch": 0.03925249594675313,
      "grad_norm": 0.262758731842041,
      "learning_rate": 4.980373752026624e-05,
      "loss": 0.0058,
      "step": 460
    },
    {
      "epoch": 0.040105811076030375,
      "grad_norm": 0.1900196075439453,
      "learning_rate": 4.979947094461985e-05,
      "loss": 0.0062,
      "step": 470
    },
    {
      "epoch": 0.040959126205307624,
      "grad_norm": 0.05886987969279289,
      "learning_rate": 4.9795204368973466e-05,
      "loss": 0.0074,
      "step": 480
    },
    {
      "epoch": 0.041812441334584866,
      "grad_norm": 0.1154077798128128,
      "learning_rate": 4.979093779332708e-05,
      "loss": 0.0062,
      "step": 490
    },
    {
      "epoch": 0.04266575646386211,
      "grad_norm": 0.4881272315979004,
      "learning_rate": 4.9786671217680694e-05,
      "loss": 0.0056,
      "step": 500
    },
    {
      "epoch": 0.04351907159313935,
      "grad_norm": 0.1866145133972168,
      "learning_rate": 4.978240464203431e-05,
      "loss": 0.0063,
      "step": 510
    },
    {
      "epoch": 0.04437238672241659,
      "grad_norm": 0.042993444949388504,
      "learning_rate": 4.977813806638792e-05,
      "loss": 0.006,
      "step": 520
    },
    {
      "epoch": 0.045225701851693834,
      "grad_norm": 0.5606604218482971,
      "learning_rate": 4.977387149074154e-05,
      "loss": 0.0064,
      "step": 530
    },
    {
      "epoch": 0.046079016980971076,
      "grad_norm": 0.05948610231280327,
      "learning_rate": 4.9769604915095144e-05,
      "loss": 0.0057,
      "step": 540
    },
    {
      "epoch": 0.04693233211024832,
      "grad_norm": 0.1901971399784088,
      "learning_rate": 4.976533833944876e-05,
      "loss": 0.0073,
      "step": 550
    },
    {
      "epoch": 0.04778564723952556,
      "grad_norm": 0.1884048730134964,
      "learning_rate": 4.976107176380237e-05,
      "loss": 0.006,
      "step": 560
    },
    {
      "epoch": 0.0486389623688028,
      "grad_norm": 0.2978346347808838,
      "learning_rate": 4.975680518815599e-05,
      "loss": 0.0056,
      "step": 570
    },
    {
      "epoch": 0.049492277498080044,
      "grad_norm": 0.262536883354187,
      "learning_rate": 4.97525386125096e-05,
      "loss": 0.0057,
      "step": 580
    },
    {
      "epoch": 0.050345592627357286,
      "grad_norm": 0.30016210675239563,
      "learning_rate": 4.9748272036863216e-05,
      "loss": 0.0072,
      "step": 590
    },
    {
      "epoch": 0.05119890775663453,
      "grad_norm": 0.2632922828197479,
      "learning_rate": 4.974400546121683e-05,
      "loss": 0.0075,
      "step": 600
    },
    {
      "epoch": 0.05205222288591177,
      "grad_norm": 0.2253209948539734,
      "learning_rate": 4.9739738885570444e-05,
      "loss": 0.0077,
      "step": 610
    },
    {
      "epoch": 0.05290553801518901,
      "grad_norm": 0.2246895283460617,
      "learning_rate": 4.973547230992406e-05,
      "loss": 0.0048,
      "step": 620
    },
    {
      "epoch": 0.053758853144466254,
      "grad_norm": 0.2620575428009033,
      "learning_rate": 4.973120573427767e-05,
      "loss": 0.0054,
      "step": 630
    },
    {
      "epoch": 0.054612168273743496,
      "grad_norm": 0.08522985875606537,
      "learning_rate": 4.972693915863129e-05,
      "loss": 0.0057,
      "step": 640
    },
    {
      "epoch": 0.05546548340302074,
      "grad_norm": 0.33647629618644714,
      "learning_rate": 4.9722672582984894e-05,
      "loss": 0.0072,
      "step": 650
    },
    {
      "epoch": 0.05631879853229798,
      "grad_norm": 0.22455012798309326,
      "learning_rate": 4.9718406007338515e-05,
      "loss": 0.0077,
      "step": 660
    },
    {
      "epoch": 0.05717211366157522,
      "grad_norm": 0.11207180470228195,
      "learning_rate": 4.971413943169212e-05,
      "loss": 0.0056,
      "step": 670
    },
    {
      "epoch": 0.058025428790852464,
      "grad_norm": 0.30075404047966003,
      "learning_rate": 4.9709872856045744e-05,
      "loss": 0.0058,
      "step": 680
    },
    {
      "epoch": 0.058878743920129706,
      "grad_norm": 0.030573366209864616,
      "learning_rate": 4.970560628039935e-05,
      "loss": 0.0064,
      "step": 690
    },
    {
      "epoch": 0.05973205904940695,
      "grad_norm": 0.058747027069330215,
      "learning_rate": 4.970133970475297e-05,
      "loss": 0.0062,
      "step": 700
    },
    {
      "epoch": 0.06058537417868419,
      "grad_norm": 0.33511629700660706,
      "learning_rate": 4.969707312910658e-05,
      "loss": 0.0065,
      "step": 710
    },
    {
      "epoch": 0.06143868930796143,
      "grad_norm": 0.3002374470233917,
      "learning_rate": 4.9692806553460194e-05,
      "loss": 0.0061,
      "step": 720
    },
    {
      "epoch": 0.062292004437238674,
      "grad_norm": 0.044203635305166245,
      "learning_rate": 4.968853997781381e-05,
      "loss": 0.0069,
      "step": 730
    },
    {
      "epoch": 0.06314531956651591,
      "grad_norm": 0.336438924074173,
      "learning_rate": 4.968427340216742e-05,
      "loss": 0.0058,
      "step": 740
    },
    {
      "epoch": 0.06399863469579316,
      "grad_norm": 0.052225448191165924,
      "learning_rate": 4.9680006826521037e-05,
      "loss": 0.0076,
      "step": 750
    },
    {
      "epoch": 0.06485194982507039,
      "grad_norm": 0.18757084012031555,
      "learning_rate": 4.967574025087465e-05,
      "loss": 0.0057,
      "step": 760
    },
    {
      "epoch": 0.06570526495434764,
      "grad_norm": 0.4154655337333679,
      "learning_rate": 4.9671473675228265e-05,
      "loss": 0.0059,
      "step": 770
    },
    {
      "epoch": 0.06655858008362488,
      "grad_norm": 0.11467088013887405,
      "learning_rate": 4.966720709958188e-05,
      "loss": 0.0069,
      "step": 780
    },
    {
      "epoch": 0.06741189521290213,
      "grad_norm": 0.5961597561836243,
      "learning_rate": 4.9662940523935494e-05,
      "loss": 0.0063,
      "step": 790
    },
    {
      "epoch": 0.06826521034217936,
      "grad_norm": 0.07956134527921677,
      "learning_rate": 4.96586739482891e-05,
      "loss": 0.0064,
      "step": 800
    },
    {
      "epoch": 0.06911852547145661,
      "grad_norm": 0.18716174364089966,
      "learning_rate": 4.965440737264272e-05,
      "loss": 0.0068,
      "step": 810
    },
    {
      "epoch": 0.06997184060073385,
      "grad_norm": 0.261090487241745,
      "learning_rate": 4.965014079699633e-05,
      "loss": 0.0068,
      "step": 820
    },
    {
      "epoch": 0.0708251557300111,
      "grad_norm": 0.11287019401788712,
      "learning_rate": 4.964587422134995e-05,
      "loss": 0.006,
      "step": 830
    },
    {
      "epoch": 0.07167847085928833,
      "grad_norm": 0.3364337980747223,
      "learning_rate": 4.964160764570356e-05,
      "loss": 0.0069,
      "step": 840
    },
    {
      "epoch": 0.07253178598856558,
      "grad_norm": 0.3731653690338135,
      "learning_rate": 4.963734107005717e-05,
      "loss": 0.0063,
      "step": 850
    },
    {
      "epoch": 0.07338510111784281,
      "grad_norm": 0.2238192856311798,
      "learning_rate": 4.9633074494410786e-05,
      "loss": 0.0055,
      "step": 860
    },
    {
      "epoch": 0.07423841624712006,
      "grad_norm": 0.07813118398189545,
      "learning_rate": 4.96288079187644e-05,
      "loss": 0.0079,
      "step": 870
    },
    {
      "epoch": 0.0750917313763973,
      "grad_norm": 0.59633469581604,
      "learning_rate": 4.9624541343118015e-05,
      "loss": 0.0057,
      "step": 880
    },
    {
      "epoch": 0.07594504650567455,
      "grad_norm": 0.06522534042596817,
      "learning_rate": 4.962027476747163e-05,
      "loss": 0.0063,
      "step": 890
    },
    {
      "epoch": 0.07679836163495178,
      "grad_norm": 0.11297794431447983,
      "learning_rate": 4.9616008191825243e-05,
      "loss": 0.0067,
      "step": 900
    },
    {
      "epoch": 0.07765167676422903,
      "grad_norm": 0.30062752962112427,
      "learning_rate": 4.961174161617886e-05,
      "loss": 0.0047,
      "step": 910
    },
    {
      "epoch": 0.07850499189350627,
      "grad_norm": 0.3356108069419861,
      "learning_rate": 4.960747504053247e-05,
      "loss": 0.0071,
      "step": 920
    },
    {
      "epoch": 0.07935830702278351,
      "grad_norm": 0.5946621298789978,
      "learning_rate": 4.9603208464886086e-05,
      "loss": 0.006,
      "step": 930
    },
    {
      "epoch": 0.08021162215206075,
      "grad_norm": 0.3745056092739105,
      "learning_rate": 4.95989418892397e-05,
      "loss": 0.0074,
      "step": 940
    },
    {
      "epoch": 0.081064937281338,
      "grad_norm": 0.5573672652244568,
      "learning_rate": 4.9594675313593315e-05,
      "loss": 0.0061,
      "step": 950
    },
    {
      "epoch": 0.08191825241061525,
      "grad_norm": 0.5938632488250732,
      "learning_rate": 4.959040873794692e-05,
      "loss": 0.0052,
      "step": 960
    },
    {
      "epoch": 0.08277156753989248,
      "grad_norm": 0.04761289060115814,
      "learning_rate": 4.958614216230054e-05,
      "loss": 0.0053,
      "step": 970
    },
    {
      "epoch": 0.08362488266916973,
      "grad_norm": 0.5198780298233032,
      "learning_rate": 4.958187558665415e-05,
      "loss": 0.0068,
      "step": 980
    },
    {
      "epoch": 0.08447819779844697,
      "grad_norm": 0.2620069980621338,
      "learning_rate": 4.957760901100777e-05,
      "loss": 0.0063,
      "step": 990
    },
    {
      "epoch": 0.08533151292772422,
      "grad_norm": 0.1118960753083229,
      "learning_rate": 4.957334243536138e-05,
      "loss": 0.0069,
      "step": 1000
    },
    {
      "epoch": 0.08618482805700145,
      "grad_norm": 0.07908407598733902,
      "learning_rate": 4.9569075859715e-05,
      "loss": 0.0051,
      "step": 1010
    },
    {
      "epoch": 0.0870381431862787,
      "grad_norm": 0.7049512267112732,
      "learning_rate": 4.956480928406861e-05,
      "loss": 0.0055,
      "step": 1020
    },
    {
      "epoch": 0.08789145831555593,
      "grad_norm": 0.37323713302612305,
      "learning_rate": 4.956054270842222e-05,
      "loss": 0.0051,
      "step": 1030
    },
    {
      "epoch": 0.08874477344483318,
      "grad_norm": 0.44767287373542786,
      "learning_rate": 4.9556276132775836e-05,
      "loss": 0.0059,
      "step": 1040
    },
    {
      "epoch": 0.08959808857411042,
      "grad_norm": 0.07866261154413223,
      "learning_rate": 4.955200955712945e-05,
      "loss": 0.0085,
      "step": 1050
    },
    {
      "epoch": 0.09045140370338767,
      "grad_norm": 0.4830535054206848,
      "learning_rate": 4.9547742981483065e-05,
      "loss": 0.0053,
      "step": 1060
    },
    {
      "epoch": 0.0913047188326649,
      "grad_norm": 0.07626494020223618,
      "learning_rate": 4.954347640583667e-05,
      "loss": 0.006,
      "step": 1070
    },
    {
      "epoch": 0.09215803396194215,
      "grad_norm": 0.5561143755912781,
      "learning_rate": 4.953920983019029e-05,
      "loss": 0.006,
      "step": 1080
    },
    {
      "epoch": 0.09301134909121939,
      "grad_norm": 0.44457074999809265,
      "learning_rate": 4.95349432545439e-05,
      "loss": 0.0065,
      "step": 1090
    },
    {
      "epoch": 0.09386466422049664,
      "grad_norm": 0.33478304743766785,
      "learning_rate": 4.953067667889752e-05,
      "loss": 0.0062,
      "step": 1100
    },
    {
      "epoch": 0.09471797934977387,
      "grad_norm": 0.029714597389101982,
      "learning_rate": 4.952641010325113e-05,
      "loss": 0.0075,
      "step": 1110
    },
    {
      "epoch": 0.09557129447905112,
      "grad_norm": 0.15145573019981384,
      "learning_rate": 4.952214352760475e-05,
      "loss": 0.0053,
      "step": 1120
    },
    {
      "epoch": 0.09642460960832835,
      "grad_norm": 0.04010770097374916,
      "learning_rate": 4.951787695195836e-05,
      "loss": 0.0086,
      "step": 1130
    },
    {
      "epoch": 0.0972779247376056,
      "grad_norm": 0.8516491055488586,
      "learning_rate": 4.951361037631198e-05,
      "loss": 0.0055,
      "step": 1140
    },
    {
      "epoch": 0.09813123986688284,
      "grad_norm": 0.2597883343696594,
      "learning_rate": 4.9509343800665586e-05,
      "loss": 0.007,
      "step": 1150
    },
    {
      "epoch": 0.09898455499616009,
      "grad_norm": 0.2618105411529541,
      "learning_rate": 4.95050772250192e-05,
      "loss": 0.0054,
      "step": 1160
    },
    {
      "epoch": 0.09983787012543732,
      "grad_norm": 0.05342094227671623,
      "learning_rate": 4.9500810649372814e-05,
      "loss": 0.005,
      "step": 1170
    },
    {
      "epoch": 0.10069118525471457,
      "grad_norm": 0.22391895949840546,
      "learning_rate": 4.949654407372643e-05,
      "loss": 0.0052,
      "step": 1180
    },
    {
      "epoch": 0.1015445003839918,
      "grad_norm": 0.409286230802536,
      "learning_rate": 4.949227749808004e-05,
      "loss": 0.0063,
      "step": 1190
    },
    {
      "epoch": 0.10239781551326906,
      "grad_norm": 0.150611013174057,
      "learning_rate": 4.948801092243366e-05,
      "loss": 0.0067,
      "step": 1200
    },
    {
      "epoch": 0.10325113064254629,
      "grad_norm": 0.18816877901554108,
      "learning_rate": 4.948374434678727e-05,
      "loss": 0.0056,
      "step": 1210
    },
    {
      "epoch": 0.10410444577182354,
      "grad_norm": 0.48125672340393066,
      "learning_rate": 4.9479477771140886e-05,
      "loss": 0.0054,
      "step": 1220
    },
    {
      "epoch": 0.10495776090110077,
      "grad_norm": 0.3710360825061798,
      "learning_rate": 4.94752111954945e-05,
      "loss": 0.0064,
      "step": 1230
    },
    {
      "epoch": 0.10581107603037802,
      "grad_norm": 0.15059727430343628,
      "learning_rate": 4.9470944619848114e-05,
      "loss": 0.0054,
      "step": 1240
    },
    {
      "epoch": 0.10666439115965526,
      "grad_norm": 0.3740711510181427,
      "learning_rate": 4.946667804420173e-05,
      "loss": 0.0074,
      "step": 1250
    },
    {
      "epoch": 0.10751770628893251,
      "grad_norm": 0.18643102049827576,
      "learning_rate": 4.946241146855534e-05,
      "loss": 0.0055,
      "step": 1260
    },
    {
      "epoch": 0.10837102141820974,
      "grad_norm": 0.553862988948822,
      "learning_rate": 4.945814489290895e-05,
      "loss": 0.0066,
      "step": 1270
    },
    {
      "epoch": 0.10922433654748699,
      "grad_norm": 0.1487523317337036,
      "learning_rate": 4.945387831726257e-05,
      "loss": 0.0063,
      "step": 1280
    },
    {
      "epoch": 0.11007765167676423,
      "grad_norm": 0.6290155649185181,
      "learning_rate": 4.944961174161618e-05,
      "loss": 0.0063,
      "step": 1290
    },
    {
      "epoch": 0.11093096680604148,
      "grad_norm": 0.5553596019744873,
      "learning_rate": 4.94453451659698e-05,
      "loss": 0.0058,
      "step": 1300
    },
    {
      "epoch": 0.11178428193531871,
      "grad_norm": 0.04576545208692551,
      "learning_rate": 4.944107859032341e-05,
      "loss": 0.0053,
      "step": 1310
    },
    {
      "epoch": 0.11263759706459596,
      "grad_norm": 0.07595498114824295,
      "learning_rate": 4.943681201467703e-05,
      "loss": 0.006,
      "step": 1320
    },
    {
      "epoch": 0.1134909121938732,
      "grad_norm": 0.11655478924512863,
      "learning_rate": 4.9432545439030635e-05,
      "loss": 0.005,
      "step": 1330
    },
    {
      "epoch": 0.11434422732315044,
      "grad_norm": 0.033425550907850266,
      "learning_rate": 4.942827886338425e-05,
      "loss": 0.0079,
      "step": 1340
    },
    {
      "epoch": 0.11519754245242768,
      "grad_norm": 0.5915949940681458,
      "learning_rate": 4.9424012287737864e-05,
      "loss": 0.0067,
      "step": 1350
    },
    {
      "epoch": 0.11605085758170493,
      "grad_norm": 0.047500740736722946,
      "learning_rate": 4.941974571209148e-05,
      "loss": 0.0059,
      "step": 1360
    },
    {
      "epoch": 0.11690417271098216,
      "grad_norm": 0.2950483560562134,
      "learning_rate": 4.941547913644509e-05,
      "loss": 0.0056,
      "step": 1370
    },
    {
      "epoch": 0.11775748784025941,
      "grad_norm": 0.33484482765197754,
      "learning_rate": 4.94112125607987e-05,
      "loss": 0.0063,
      "step": 1380
    },
    {
      "epoch": 0.11861080296953665,
      "grad_norm": 0.04552324488759041,
      "learning_rate": 4.940694598515232e-05,
      "loss": 0.0078,
      "step": 1390
    },
    {
      "epoch": 0.1194641180988139,
      "grad_norm": 0.15160943567752838,
      "learning_rate": 4.940267940950593e-05,
      "loss": 0.0069,
      "step": 1400
    },
    {
      "epoch": 0.12031743322809113,
      "grad_norm": 0.25930726528167725,
      "learning_rate": 4.939841283385955e-05,
      "loss": 0.0057,
      "step": 1410
    },
    {
      "epoch": 0.12117074835736838,
      "grad_norm": 0.04046932980418205,
      "learning_rate": 4.939414625821316e-05,
      "loss": 0.0066,
      "step": 1420
    },
    {
      "epoch": 0.12202406348664561,
      "grad_norm": 0.554793655872345,
      "learning_rate": 4.938987968256678e-05,
      "loss": 0.0071,
      "step": 1430
    },
    {
      "epoch": 0.12287737861592286,
      "grad_norm": 0.3333909213542938,
      "learning_rate": 4.9385613106920385e-05,
      "loss": 0.0061,
      "step": 1440
    },
    {
      "epoch": 0.1237306937452001,
      "grad_norm": 0.5920169353485107,
      "learning_rate": 4.9381346531274006e-05,
      "loss": 0.006,
      "step": 1450
    },
    {
      "epoch": 0.12458400887447735,
      "grad_norm": 0.33361896872520447,
      "learning_rate": 4.9377079955627614e-05,
      "loss": 0.0077,
      "step": 1460
    },
    {
      "epoch": 0.1254373240037546,
      "grad_norm": 0.4449932277202606,
      "learning_rate": 4.937281337998123e-05,
      "loss": 0.0061,
      "step": 1470
    },
    {
      "epoch": 0.12629063913303182,
      "grad_norm": 0.1867167055606842,
      "learning_rate": 4.936854680433484e-05,
      "loss": 0.0074,
      "step": 1480
    },
    {
      "epoch": 0.12714395426230907,
      "grad_norm": 0.15481625497341156,
      "learning_rate": 4.9364280228688457e-05,
      "loss": 0.0058,
      "step": 1490
    },
    {
      "epoch": 0.12799726939158632,
      "grad_norm": 0.07433164119720459,
      "learning_rate": 4.936001365304207e-05,
      "loss": 0.0066,
      "step": 1500
    },
    {
      "epoch": 0.12885058452086356,
      "grad_norm": 0.40552279353141785,
      "learning_rate": 4.9355747077395685e-05,
      "loss": 0.0064,
      "step": 1510
    },
    {
      "epoch": 0.12970389965014079,
      "grad_norm": 0.2218884527683258,
      "learning_rate": 4.93514805017493e-05,
      "loss": 0.0087,
      "step": 1520
    },
    {
      "epoch": 0.13055721477941803,
      "grad_norm": 0.18718212842941284,
      "learning_rate": 4.9347213926102914e-05,
      "loss": 0.0053,
      "step": 1530
    },
    {
      "epoch": 0.13141052990869528,
      "grad_norm": 0.4795038402080536,
      "learning_rate": 4.934294735045653e-05,
      "loss": 0.0072,
      "step": 1540
    },
    {
      "epoch": 0.13226384503797253,
      "grad_norm": 0.2244158834218979,
      "learning_rate": 4.933868077481014e-05,
      "loss": 0.0052,
      "step": 1550
    },
    {
      "epoch": 0.13311716016724975,
      "grad_norm": 0.2595379650592804,
      "learning_rate": 4.9334414199163756e-05,
      "loss": 0.0063,
      "step": 1560
    },
    {
      "epoch": 0.133970475296527,
      "grad_norm": 0.18631969392299652,
      "learning_rate": 4.933014762351737e-05,
      "loss": 0.0064,
      "step": 1570
    },
    {
      "epoch": 0.13482379042580425,
      "grad_norm": 0.37008583545684814,
      "learning_rate": 4.932588104787098e-05,
      "loss": 0.0072,
      "step": 1580
    },
    {
      "epoch": 0.1356771055550815,
      "grad_norm": 0.15249912440776825,
      "learning_rate": 4.93216144722246e-05,
      "loss": 0.0057,
      "step": 1590
    },
    {
      "epoch": 0.13653042068435872,
      "grad_norm": 0.034714363515377045,
      "learning_rate": 4.9317347896578206e-05,
      "loss": 0.0051,
      "step": 1600
    },
    {
      "epoch": 0.13738373581363597,
      "grad_norm": 0.15036138892173767,
      "learning_rate": 4.931308132093182e-05,
      "loss": 0.0059,
      "step": 1610
    },
    {
      "epoch": 0.13823705094291322,
      "grad_norm": 0.1116965040564537,
      "learning_rate": 4.9308814745285435e-05,
      "loss": 0.0068,
      "step": 1620
    },
    {
      "epoch": 0.13909036607219047,
      "grad_norm": 0.33231332898139954,
      "learning_rate": 4.930454816963905e-05,
      "loss": 0.0056,
      "step": 1630
    },
    {
      "epoch": 0.1399436812014677,
      "grad_norm": 0.07961486279964447,
      "learning_rate": 4.930028159399266e-05,
      "loss": 0.0066,
      "step": 1640
    },
    {
      "epoch": 0.14079699633074494,
      "grad_norm": 0.3329172432422638,
      "learning_rate": 4.929601501834628e-05,
      "loss": 0.0066,
      "step": 1650
    },
    {
      "epoch": 0.1416503114600222,
      "grad_norm": 0.2588578164577484,
      "learning_rate": 4.929174844269989e-05,
      "loss": 0.0058,
      "step": 1660
    },
    {
      "epoch": 0.14250362658929944,
      "grad_norm": 0.2576874792575836,
      "learning_rate": 4.9287481867053506e-05,
      "loss": 0.0061,
      "step": 1670
    },
    {
      "epoch": 0.14335694171857666,
      "grad_norm": 0.046981245279312134,
      "learning_rate": 4.928321529140712e-05,
      "loss": 0.0055,
      "step": 1680
    },
    {
      "epoch": 0.1442102568478539,
      "grad_norm": 0.07894691824913025,
      "learning_rate": 4.927894871576073e-05,
      "loss": 0.0065,
      "step": 1690
    },
    {
      "epoch": 0.14506357197713116,
      "grad_norm": 0.04752352833747864,
      "learning_rate": 4.927468214011435e-05,
      "loss": 0.0062,
      "step": 1700
    },
    {
      "epoch": 0.1459168871064084,
      "grad_norm": 0.18448904156684875,
      "learning_rate": 4.9270415564467956e-05,
      "loss": 0.0049,
      "step": 1710
    },
    {
      "epoch": 0.14677020223568563,
      "grad_norm": 0.04108426347374916,
      "learning_rate": 4.926614898882158e-05,
      "loss": 0.0061,
      "step": 1720
    },
    {
      "epoch": 0.14762351736496288,
      "grad_norm": 0.4057473838329315,
      "learning_rate": 4.9261882413175185e-05,
      "loss": 0.0068,
      "step": 1730
    },
    {
      "epoch": 0.14847683249424012,
      "grad_norm": 0.29691725969314575,
      "learning_rate": 4.9257615837528806e-05,
      "loss": 0.0047,
      "step": 1740
    },
    {
      "epoch": 0.14933014762351737,
      "grad_norm": 0.4809638261795044,
      "learning_rate": 4.925334926188241e-05,
      "loss": 0.007,
      "step": 1750
    },
    {
      "epoch": 0.1501834627527946,
      "grad_norm": 0.11114314198493958,
      "learning_rate": 4.9249082686236034e-05,
      "loss": 0.0059,
      "step": 1760
    },
    {
      "epoch": 0.15103677788207184,
      "grad_norm": 0.02013089880347252,
      "learning_rate": 4.924481611058964e-05,
      "loss": 0.0068,
      "step": 1770
    },
    {
      "epoch": 0.1518900930113491,
      "grad_norm": 0.14958475530147552,
      "learning_rate": 4.9240549534943256e-05,
      "loss": 0.0078,
      "step": 1780
    },
    {
      "epoch": 0.15274340814062634,
      "grad_norm": 0.14813542366027832,
      "learning_rate": 4.923628295929687e-05,
      "loss": 0.0054,
      "step": 1790
    },
    {
      "epoch": 0.15359672326990356,
      "grad_norm": 0.47914284467697144,
      "learning_rate": 4.9232016383650484e-05,
      "loss": 0.0053,
      "step": 1800
    },
    {
      "epoch": 0.1544500383991808,
      "grad_norm": 0.3335843086242676,
      "learning_rate": 4.92277498080041e-05,
      "loss": 0.0057,
      "step": 1810
    },
    {
      "epoch": 0.15530335352845806,
      "grad_norm": 0.14989221096038818,
      "learning_rate": 4.922348323235771e-05,
      "loss": 0.0053,
      "step": 1820
    },
    {
      "epoch": 0.1561566686577353,
      "grad_norm": 0.3321378231048584,
      "learning_rate": 4.921921665671133e-05,
      "loss": 0.0064,
      "step": 1830
    },
    {
      "epoch": 0.15700998378701253,
      "grad_norm": 0.07618944346904755,
      "learning_rate": 4.921495008106494e-05,
      "loss": 0.0073,
      "step": 1840
    },
    {
      "epoch": 0.15786329891628978,
      "grad_norm": 0.07892133295536041,
      "learning_rate": 4.9210683505418556e-05,
      "loss": 0.0056,
      "step": 1850
    },
    {
      "epoch": 0.15871661404556703,
      "grad_norm": 0.11663878709077835,
      "learning_rate": 4.920641692977217e-05,
      "loss": 0.0054,
      "step": 1860
    },
    {
      "epoch": 0.15956992917484428,
      "grad_norm": 0.26017239689826965,
      "learning_rate": 4.9202150354125784e-05,
      "loss": 0.0059,
      "step": 1870
    },
    {
      "epoch": 0.1604232443041215,
      "grad_norm": 0.22343160212039948,
      "learning_rate": 4.919788377847939e-05,
      "loss": 0.0061,
      "step": 1880
    },
    {
      "epoch": 0.16127655943339875,
      "grad_norm": 0.5527215003967285,
      "learning_rate": 4.9193617202833006e-05,
      "loss": 0.0062,
      "step": 1890
    },
    {
      "epoch": 0.162129874562676,
      "grad_norm": 0.4066004455089569,
      "learning_rate": 4.918935062718662e-05,
      "loss": 0.0053,
      "step": 1900
    },
    {
      "epoch": 0.16298318969195325,
      "grad_norm": 0.36941349506378174,
      "learning_rate": 4.9185084051540234e-05,
      "loss": 0.0061,
      "step": 1910
    },
    {
      "epoch": 0.1638365048212305,
      "grad_norm": 0.33040764927864075,
      "learning_rate": 4.918081747589385e-05,
      "loss": 0.0056,
      "step": 1920
    },
    {
      "epoch": 0.16468981995050772,
      "grad_norm": 0.038795195519924164,
      "learning_rate": 4.917655090024746e-05,
      "loss": 0.0059,
      "step": 1930
    },
    {
      "epoch": 0.16554313507978496,
      "grad_norm": 0.4422627091407776,
      "learning_rate": 4.917228432460108e-05,
      "loss": 0.0059,
      "step": 1940
    },
    {
      "epoch": 0.1663964502090622,
      "grad_norm": 0.04295457899570465,
      "learning_rate": 4.916801774895469e-05,
      "loss": 0.008,
      "step": 1950
    },
    {
      "epoch": 0.16724976533833946,
      "grad_norm": 0.11205300688743591,
      "learning_rate": 4.9163751173308306e-05,
      "loss": 0.005,
      "step": 1960
    },
    {
      "epoch": 0.16810308046761668,
      "grad_norm": 0.03947945311665535,
      "learning_rate": 4.915948459766192e-05,
      "loss": 0.0073,
      "step": 1970
    },
    {
      "epoch": 0.16895639559689393,
      "grad_norm": 0.1485765129327774,
      "learning_rate": 4.9155218022015534e-05,
      "loss": 0.005,
      "step": 1980
    },
    {
      "epoch": 0.16980971072617118,
      "grad_norm": 0.2585897147655487,
      "learning_rate": 4.915095144636915e-05,
      "loss": 0.0059,
      "step": 1990
    },
    {
      "epoch": 0.17066302585544843,
      "grad_norm": 0.5529884099960327,
      "learning_rate": 4.9146684870722756e-05,
      "loss": 0.0064,
      "step": 2000
    },
    {
      "epoch": 0.17151634098472565,
      "grad_norm": 0.07498890906572342,
      "learning_rate": 4.914241829507638e-05,
      "loss": 0.0059,
      "step": 2010
    },
    {
      "epoch": 0.1723696561140029,
      "grad_norm": 0.04471011087298393,
      "learning_rate": 4.9138151719429984e-05,
      "loss": 0.0064,
      "step": 2020
    },
    {
      "epoch": 0.17322297124328015,
      "grad_norm": 0.07784681022167206,
      "learning_rate": 4.9133885143783605e-05,
      "loss": 0.0071,
      "step": 2030
    },
    {
      "epoch": 0.1740762863725574,
      "grad_norm": 0.07776886224746704,
      "learning_rate": 4.912961856813721e-05,
      "loss": 0.0063,
      "step": 2040
    },
    {
      "epoch": 0.17492960150183462,
      "grad_norm": 0.22233441472053528,
      "learning_rate": 4.9125351992490834e-05,
      "loss": 0.0054,
      "step": 2050
    },
    {
      "epoch": 0.17578291663111187,
      "grad_norm": 0.5892432928085327,
      "learning_rate": 4.912108541684444e-05,
      "loss": 0.0062,
      "step": 2060
    },
    {
      "epoch": 0.17663623176038912,
      "grad_norm": 0.5903258919715881,
      "learning_rate": 4.911681884119806e-05,
      "loss": 0.0066,
      "step": 2070
    },
    {
      "epoch": 0.17748954688966637,
      "grad_norm": 0.11087977886199951,
      "learning_rate": 4.911255226555167e-05,
      "loss": 0.0049,
      "step": 2080
    },
    {
      "epoch": 0.1783428620189436,
      "grad_norm": 0.47914233803749084,
      "learning_rate": 4.9108285689905284e-05,
      "loss": 0.0074,
      "step": 2090
    },
    {
      "epoch": 0.17919617714822084,
      "grad_norm": 0.6636866331100464,
      "learning_rate": 4.91040191142589e-05,
      "loss": 0.0054,
      "step": 2100
    },
    {
      "epoch": 0.18004949227749809,
      "grad_norm": 0.07574359327554703,
      "learning_rate": 4.909975253861251e-05,
      "loss": 0.0056,
      "step": 2110
    },
    {
      "epoch": 0.18090280740677533,
      "grad_norm": 0.4413614571094513,
      "learning_rate": 4.909548596296613e-05,
      "loss": 0.0054,
      "step": 2120
    },
    {
      "epoch": 0.18175612253605256,
      "grad_norm": 0.14981912076473236,
      "learning_rate": 4.9091219387319734e-05,
      "loss": 0.0067,
      "step": 2130
    },
    {
      "epoch": 0.1826094376653298,
      "grad_norm": 0.07573284953832626,
      "learning_rate": 4.9086952811673355e-05,
      "loss": 0.008,
      "step": 2140
    },
    {
      "epoch": 0.18346275279460705,
      "grad_norm": 0.29478156566619873,
      "learning_rate": 4.908268623602696e-05,
      "loss": 0.0059,
      "step": 2150
    },
    {
      "epoch": 0.1843160679238843,
      "grad_norm": 0.36811530590057373,
      "learning_rate": 4.9078419660380584e-05,
      "loss": 0.0048,
      "step": 2160
    },
    {
      "epoch": 0.18516938305316152,
      "grad_norm": 0.4426199793815613,
      "learning_rate": 4.907415308473419e-05,
      "loss": 0.0076,
      "step": 2170
    },
    {
      "epoch": 0.18602269818243877,
      "grad_norm": 0.11283755302429199,
      "learning_rate": 4.906988650908781e-05,
      "loss": 0.0069,
      "step": 2180
    },
    {
      "epoch": 0.18687601331171602,
      "grad_norm": 0.3321252167224884,
      "learning_rate": 4.906561993344142e-05,
      "loss": 0.0059,
      "step": 2190
    },
    {
      "epoch": 0.18772932844099327,
      "grad_norm": 0.25742170214653015,
      "learning_rate": 4.9061353357795034e-05,
      "loss": 0.0058,
      "step": 2200
    },
    {
      "epoch": 0.1885826435702705,
      "grad_norm": 0.08397803455591202,
      "learning_rate": 4.905708678214865e-05,
      "loss": 0.0067,
      "step": 2210
    },
    {
      "epoch": 0.18943595869954774,
      "grad_norm": 0.5163476467132568,
      "learning_rate": 4.905282020650226e-05,
      "loss": 0.0063,
      "step": 2220
    },
    {
      "epoch": 0.190289273828825,
      "grad_norm": 0.48050543665885925,
      "learning_rate": 4.9048553630855876e-05,
      "loss": 0.005,
      "step": 2230
    },
    {
      "epoch": 0.19114258895810224,
      "grad_norm": 0.18544307351112366,
      "learning_rate": 4.904428705520949e-05,
      "loss": 0.0069,
      "step": 2240
    },
    {
      "epoch": 0.19199590408737946,
      "grad_norm": 0.3353044390678406,
      "learning_rate": 4.9040020479563105e-05,
      "loss": 0.0058,
      "step": 2250
    },
    {
      "epoch": 0.1928492192166567,
      "grad_norm": 0.11643318831920624,
      "learning_rate": 4.903575390391672e-05,
      "loss": 0.0064,
      "step": 2260
    },
    {
      "epoch": 0.19370253434593396,
      "grad_norm": 0.29744139313697815,
      "learning_rate": 4.9031487328270333e-05,
      "loss": 0.0074,
      "step": 2270
    },
    {
      "epoch": 0.1945558494752112,
      "grad_norm": 0.47851404547691345,
      "learning_rate": 4.902722075262395e-05,
      "loss": 0.0048,
      "step": 2280
    },
    {
      "epoch": 0.19540916460448843,
      "grad_norm": 0.44211310148239136,
      "learning_rate": 4.902295417697756e-05,
      "loss": 0.0067,
      "step": 2290
    },
    {
      "epoch": 0.19626247973376568,
      "grad_norm": 0.25934863090515137,
      "learning_rate": 4.9018687601331176e-05,
      "loss": 0.0052,
      "step": 2300
    },
    {
      "epoch": 0.19711579486304293,
      "grad_norm": 0.1119021475315094,
      "learning_rate": 4.9014421025684784e-05,
      "loss": 0.0056,
      "step": 2310
    },
    {
      "epoch": 0.19796910999232017,
      "grad_norm": 0.7378081679344177,
      "learning_rate": 4.9010154450038405e-05,
      "loss": 0.006,
      "step": 2320
    },
    {
      "epoch": 0.1988224251215974,
      "grad_norm": 0.11691968888044357,
      "learning_rate": 4.900588787439201e-05,
      "loss": 0.006,
      "step": 2330
    },
    {
      "epoch": 0.19967574025087464,
      "grad_norm": 0.5557626485824585,
      "learning_rate": 4.900162129874563e-05,
      "loss": 0.0062,
      "step": 2340
    },
    {
      "epoch": 0.2005290553801519,
      "grad_norm": 0.15152136981487274,
      "learning_rate": 4.899735472309924e-05,
      "loss": 0.0053,
      "step": 2350
    },
    {
      "epoch": 0.20138237050942914,
      "grad_norm": 0.25964775681495667,
      "learning_rate": 4.899308814745286e-05,
      "loss": 0.0059,
      "step": 2360
    },
    {
      "epoch": 0.20223568563870636,
      "grad_norm": 0.042548779398202896,
      "learning_rate": 4.898882157180647e-05,
      "loss": 0.0068,
      "step": 2370
    },
    {
      "epoch": 0.2030890007679836,
      "grad_norm": 0.15751932561397552,
      "learning_rate": 4.898455499616009e-05,
      "loss": 0.0052,
      "step": 2380
    },
    {
      "epoch": 0.20394231589726086,
      "grad_norm": 0.048012278974056244,
      "learning_rate": 4.89802884205137e-05,
      "loss": 0.0061,
      "step": 2390
    },
    {
      "epoch": 0.2047956310265381,
      "grad_norm": 0.08696090430021286,
      "learning_rate": 4.897602184486731e-05,
      "loss": 0.0064,
      "step": 2400
    },
    {
      "epoch": 0.20564894615581533,
      "grad_norm": 0.04010291025042534,
      "learning_rate": 4.8971755269220926e-05,
      "loss": 0.0061,
      "step": 2410
    },
    {
      "epoch": 0.20650226128509258,
      "grad_norm": 0.1557874083518982,
      "learning_rate": 4.896748869357454e-05,
      "loss": 0.007,
      "step": 2420
    },
    {
      "epoch": 0.20735557641436983,
      "grad_norm": 0.2613932192325592,
      "learning_rate": 4.8963222117928155e-05,
      "loss": 0.0077,
      "step": 2430
    },
    {
      "epoch": 0.20820889154364708,
      "grad_norm": 0.1868278980255127,
      "learning_rate": 4.895895554228176e-05,
      "loss": 0.0069,
      "step": 2440
    },
    {
      "epoch": 0.2090622066729243,
      "grad_norm": 0.5610805749893188,
      "learning_rate": 4.895468896663538e-05,
      "loss": 0.0056,
      "step": 2450
    },
    {
      "epoch": 0.20991552180220155,
      "grad_norm": 0.14987421035766602,
      "learning_rate": 4.895042239098899e-05,
      "loss": 0.0068,
      "step": 2460
    },
    {
      "epoch": 0.2107688369314788,
      "grad_norm": 0.08613944053649902,
      "learning_rate": 4.894615581534261e-05,
      "loss": 0.0041,
      "step": 2470
    },
    {
      "epoch": 0.21162215206075605,
      "grad_norm": 0.1173015683889389,
      "learning_rate": 4.894188923969622e-05,
      "loss": 0.0062,
      "step": 2480
    },
    {
      "epoch": 0.21247546719003327,
      "grad_norm": 0.11663977801799774,
      "learning_rate": 4.893762266404984e-05,
      "loss": 0.005,
      "step": 2490
    },
    {
      "epoch": 0.21332878231931052,
      "grad_norm": 0.5947047472000122,
      "learning_rate": 4.893335608840345e-05,
      "loss": 0.0069,
      "step": 2500
    },
    {
      "epoch": 0.21418209744858777,
      "grad_norm": 0.06498119980096817,
      "learning_rate": 4.892908951275706e-05,
      "loss": 0.0037,
      "step": 2510
    },
    {
      "epoch": 0.21503541257786501,
      "grad_norm": 0.18954235315322876,
      "learning_rate": 4.8924822937110676e-05,
      "loss": 0.0049,
      "step": 2520
    },
    {
      "epoch": 0.21588872770714224,
      "grad_norm": 0.3154706060886383,
      "learning_rate": 4.892055636146429e-05,
      "loss": 0.0049,
      "step": 2530
    },
    {
      "epoch": 0.21674204283641949,
      "grad_norm": 0.056188952177762985,
      "learning_rate": 4.8916289785817904e-05,
      "loss": 0.0054,
      "step": 2540
    },
    {
      "epoch": 0.21759535796569673,
      "grad_norm": 0.15888270735740662,
      "learning_rate": 4.891202321017152e-05,
      "loss": 0.0052,
      "step": 2550
    },
    {
      "epoch": 0.21844867309497398,
      "grad_norm": 0.04777693375945091,
      "learning_rate": 4.890775663452513e-05,
      "loss": 0.005,
      "step": 2560
    },
    {
      "epoch": 0.2193019882242512,
      "grad_norm": 0.45002856850624084,
      "learning_rate": 4.890349005887875e-05,
      "loss": 0.0053,
      "step": 2570
    },
    {
      "epoch": 0.22015530335352845,
      "grad_norm": 0.18479058146476746,
      "learning_rate": 4.889922348323236e-05,
      "loss": 0.0049,
      "step": 2580
    },
    {
      "epoch": 0.2210086184828057,
      "grad_norm": 0.2598477005958557,
      "learning_rate": 4.8894956907585976e-05,
      "loss": 0.0068,
      "step": 2590
    },
    {
      "epoch": 0.22186193361208295,
      "grad_norm": 0.7388324737548828,
      "learning_rate": 4.889069033193959e-05,
      "loss": 0.0052,
      "step": 2600
    },
    {
      "epoch": 0.22271524874136017,
      "grad_norm": 0.08881373703479767,
      "learning_rate": 4.8886423756293204e-05,
      "loss": 0.0053,
      "step": 2610
    },
    {
      "epoch": 0.22356856387063742,
      "grad_norm": 0.063680000603199,
      "learning_rate": 4.888215718064681e-05,
      "loss": 0.0042,
      "step": 2620
    },
    {
      "epoch": 0.22442187899991467,
      "grad_norm": 0.44465816020965576,
      "learning_rate": 4.887789060500043e-05,
      "loss": 0.0049,
      "step": 2630
    },
    {
      "epoch": 0.22527519412919192,
      "grad_norm": 0.29737013578414917,
      "learning_rate": 4.887362402935404e-05,
      "loss": 0.0041,
      "step": 2640
    },
    {
      "epoch": 0.22612850925846914,
      "grad_norm": 0.2602073848247528,
      "learning_rate": 4.886935745370766e-05,
      "loss": 0.0053,
      "step": 2650
    },
    {
      "epoch": 0.2269818243877464,
      "grad_norm": 0.16911914944648743,
      "learning_rate": 4.886509087806127e-05,
      "loss": 0.0054,
      "step": 2660
    },
    {
      "epoch": 0.22783513951702364,
      "grad_norm": 0.22674739360809326,
      "learning_rate": 4.886082430241488e-05,
      "loss": 0.0065,
      "step": 2670
    },
    {
      "epoch": 0.2286884546463009,
      "grad_norm": 0.4658089876174927,
      "learning_rate": 4.88565577267685e-05,
      "loss": 0.0055,
      "step": 2680
    },
    {
      "epoch": 0.2295417697755781,
      "grad_norm": 0.06204497069120407,
      "learning_rate": 4.885229115112211e-05,
      "loss": 0.0048,
      "step": 2690
    },
    {
      "epoch": 0.23039508490485536,
      "grad_norm": 0.2675286531448364,
      "learning_rate": 4.8848024575475725e-05,
      "loss": 0.0048,
      "step": 2700
    },
    {
      "epoch": 0.2312484000341326,
      "grad_norm": 0.30652672052383423,
      "learning_rate": 4.884375799982934e-05,
      "loss": 0.0058,
      "step": 2710
    },
    {
      "epoch": 0.23210171516340986,
      "grad_norm": 0.17138350009918213,
      "learning_rate": 4.8839491424182954e-05,
      "loss": 0.0048,
      "step": 2720
    },
    {
      "epoch": 0.23295503029268708,
      "grad_norm": 0.1482267826795578,
      "learning_rate": 4.883522484853657e-05,
      "loss": 0.0053,
      "step": 2730
    },
    {
      "epoch": 0.23380834542196433,
      "grad_norm": 0.05579107254743576,
      "learning_rate": 4.883095827289018e-05,
      "loss": 0.0043,
      "step": 2740
    },
    {
      "epoch": 0.23466166055124157,
      "grad_norm": 0.20605361461639404,
      "learning_rate": 4.882669169724379e-05,
      "loss": 0.0061,
      "step": 2750
    },
    {
      "epoch": 0.23551497568051882,
      "grad_norm": 0.7058544754981995,
      "learning_rate": 4.882242512159741e-05,
      "loss": 0.0056,
      "step": 2760
    },
    {
      "epoch": 0.23636829080979604,
      "grad_norm": 0.15483109652996063,
      "learning_rate": 4.881815854595102e-05,
      "loss": 0.0054,
      "step": 2770
    },
    {
      "epoch": 0.2372216059390733,
      "grad_norm": 0.32235240936279297,
      "learning_rate": 4.881389197030464e-05,
      "loss": 0.007,
      "step": 2780
    },
    {
      "epoch": 0.23807492106835054,
      "grad_norm": 0.19694934785366058,
      "learning_rate": 4.880962539465825e-05,
      "loss": 0.0065,
      "step": 2790
    },
    {
      "epoch": 0.2389282361976278,
      "grad_norm": 0.1381269246339798,
      "learning_rate": 4.880535881901187e-05,
      "loss": 0.0063,
      "step": 2800
    },
    {
      "epoch": 0.239781551326905,
      "grad_norm": 0.4514378309249878,
      "learning_rate": 4.8801092243365475e-05,
      "loss": 0.0062,
      "step": 2810
    },
    {
      "epoch": 0.24063486645618226,
      "grad_norm": 0.2869134843349457,
      "learning_rate": 4.879682566771909e-05,
      "loss": 0.0046,
      "step": 2820
    },
    {
      "epoch": 0.2414881815854595,
      "grad_norm": 0.22893871366977692,
      "learning_rate": 4.8792559092072704e-05,
      "loss": 0.0048,
      "step": 2830
    },
    {
      "epoch": 0.24234149671473676,
      "grad_norm": 0.05915604159235954,
      "learning_rate": 4.878829251642632e-05,
      "loss": 0.0046,
      "step": 2840
    },
    {
      "epoch": 0.24319481184401398,
      "grad_norm": 0.07047247886657715,
      "learning_rate": 4.878402594077993e-05,
      "loss": 0.0047,
      "step": 2850
    },
    {
      "epoch": 0.24404812697329123,
      "grad_norm": 0.4311204254627228,
      "learning_rate": 4.8779759365133547e-05,
      "loss": 0.0045,
      "step": 2860
    },
    {
      "epoch": 0.24490144210256848,
      "grad_norm": 0.2971769869327545,
      "learning_rate": 4.877549278948716e-05,
      "loss": 0.0045,
      "step": 2870
    },
    {
      "epoch": 0.24575475723184573,
      "grad_norm": 0.3581906855106354,
      "learning_rate": 4.8771226213840775e-05,
      "loss": 0.0053,
      "step": 2880
    },
    {
      "epoch": 0.24660807236112298,
      "grad_norm": 0.10268084704875946,
      "learning_rate": 4.876695963819439e-05,
      "loss": 0.0047,
      "step": 2890
    },
    {
      "epoch": 0.2474613874904002,
      "grad_norm": 0.05854281410574913,
      "learning_rate": 4.8762693062548004e-05,
      "loss": 0.0061,
      "step": 2900
    },
    {
      "epoch": 0.24831470261967745,
      "grad_norm": 0.43057742714881897,
      "learning_rate": 4.875842648690162e-05,
      "loss": 0.0045,
      "step": 2910
    },
    {
      "epoch": 0.2491680177489547,
      "grad_norm": 0.41559138894081116,
      "learning_rate": 4.875415991125523e-05,
      "loss": 0.006,
      "step": 2920
    },
    {
      "epoch": 0.2500213328782319,
      "grad_norm": 0.3901546001434326,
      "learning_rate": 4.874989333560884e-05,
      "loss": 0.005,
      "step": 2930
    },
    {
      "epoch": 0.2508746480075092,
      "grad_norm": 0.22533546388149261,
      "learning_rate": 4.8745626759962454e-05,
      "loss": 0.0055,
      "step": 2940
    },
    {
      "epoch": 0.2517279631367864,
      "grad_norm": 0.5412392020225525,
      "learning_rate": 4.874136018431607e-05,
      "loss": 0.0043,
      "step": 2950
    },
    {
      "epoch": 0.25258127826606364,
      "grad_norm": 0.055818822234869,
      "learning_rate": 4.873709360866968e-05,
      "loss": 0.0047,
      "step": 2960
    },
    {
      "epoch": 0.2534345933953409,
      "grad_norm": 0.6512067317962646,
      "learning_rate": 4.8732827033023296e-05,
      "loss": 0.0042,
      "step": 2970
    },
    {
      "epoch": 0.25428790852461813,
      "grad_norm": 0.08051064610481262,
      "learning_rate": 4.872856045737691e-05,
      "loss": 0.0039,
      "step": 2980
    },
    {
      "epoch": 0.2551412236538954,
      "grad_norm": 0.13991129398345947,
      "learning_rate": 4.8724293881730525e-05,
      "loss": 0.0051,
      "step": 2990
    },
    {
      "epoch": 0.25599453878317263,
      "grad_norm": 0.46468448638916016,
      "learning_rate": 4.872002730608414e-05,
      "loss": 0.0056,
      "step": 3000
    },
    {
      "epoch": 0.25684785391244985,
      "grad_norm": 0.3048836588859558,
      "learning_rate": 4.8715760730437753e-05,
      "loss": 0.0042,
      "step": 3010
    },
    {
      "epoch": 0.25770116904172713,
      "grad_norm": 0.13104687631130219,
      "learning_rate": 4.871149415479137e-05,
      "loss": 0.0053,
      "step": 3020
    },
    {
      "epoch": 0.25855448417100435,
      "grad_norm": 0.22679126262664795,
      "learning_rate": 4.870722757914498e-05,
      "loss": 0.0058,
      "step": 3030
    },
    {
      "epoch": 0.25940779930028157,
      "grad_norm": 0.2963588833808899,
      "learning_rate": 4.8702961003498596e-05,
      "loss": 0.0044,
      "step": 3040
    },
    {
      "epoch": 0.26026111442955885,
      "grad_norm": 0.44312578439712524,
      "learning_rate": 4.869869442785221e-05,
      "loss": 0.0053,
      "step": 3050
    },
    {
      "epoch": 0.26111442955883607,
      "grad_norm": 0.1135612353682518,
      "learning_rate": 4.869442785220582e-05,
      "loss": 0.0062,
      "step": 3060
    },
    {
      "epoch": 0.26196774468811335,
      "grad_norm": 0.041722409427165985,
      "learning_rate": 4.869016127655944e-05,
      "loss": 0.0059,
      "step": 3070
    },
    {
      "epoch": 0.26282105981739057,
      "grad_norm": 0.08276774734258652,
      "learning_rate": 4.8685894700913046e-05,
      "loss": 0.0052,
      "step": 3080
    },
    {
      "epoch": 0.2636743749466678,
      "grad_norm": 0.30103805661201477,
      "learning_rate": 4.868162812526667e-05,
      "loss": 0.0054,
      "step": 3090
    },
    {
      "epoch": 0.26452769007594507,
      "grad_norm": 0.38985392451286316,
      "learning_rate": 4.8677361549620275e-05,
      "loss": 0.005,
      "step": 3100
    },
    {
      "epoch": 0.2653810052052223,
      "grad_norm": 0.44582289457321167,
      "learning_rate": 4.8673094973973896e-05,
      "loss": 0.0062,
      "step": 3110
    },
    {
      "epoch": 0.2662343203344995,
      "grad_norm": 0.07507303357124329,
      "learning_rate": 4.86688283983275e-05,
      "loss": 0.0046,
      "step": 3120
    },
    {
      "epoch": 0.2670876354637768,
      "grad_norm": 0.10234373062849045,
      "learning_rate": 4.866456182268112e-05,
      "loss": 0.0041,
      "step": 3130
    },
    {
      "epoch": 0.267940950593054,
      "grad_norm": 0.1567080020904541,
      "learning_rate": 4.866029524703473e-05,
      "loss": 0.005,
      "step": 3140
    },
    {
      "epoch": 0.2687942657223313,
      "grad_norm": 0.1102440282702446,
      "learning_rate": 4.8656028671388346e-05,
      "loss": 0.0061,
      "step": 3150
    },
    {
      "epoch": 0.2696475808516085,
      "grad_norm": 0.059898726642131805,
      "learning_rate": 4.865176209574196e-05,
      "loss": 0.0061,
      "step": 3160
    },
    {
      "epoch": 0.2705008959808857,
      "grad_norm": 0.05129680410027504,
      "learning_rate": 4.8647495520095574e-05,
      "loss": 0.0056,
      "step": 3170
    },
    {
      "epoch": 0.271354211110163,
      "grad_norm": 0.0946720689535141,
      "learning_rate": 4.864322894444919e-05,
      "loss": 0.0042,
      "step": 3180
    },
    {
      "epoch": 0.2722075262394402,
      "grad_norm": 0.19198431074619293,
      "learning_rate": 4.8638962368802796e-05,
      "loss": 0.0041,
      "step": 3190
    },
    {
      "epoch": 0.27306084136871744,
      "grad_norm": 0.07006765156984329,
      "learning_rate": 4.863469579315642e-05,
      "loss": 0.0043,
      "step": 3200
    },
    {
      "epoch": 0.2739141564979947,
      "grad_norm": 0.0605781264603138,
      "learning_rate": 4.8630429217510025e-05,
      "loss": 0.0053,
      "step": 3210
    },
    {
      "epoch": 0.27476747162727194,
      "grad_norm": 0.33873626589775085,
      "learning_rate": 4.8626162641863646e-05,
      "loss": 0.0045,
      "step": 3220
    },
    {
      "epoch": 0.2756207867565492,
      "grad_norm": 0.22442156076431274,
      "learning_rate": 4.862189606621725e-05,
      "loss": 0.0047,
      "step": 3230
    },
    {
      "epoch": 0.27647410188582644,
      "grad_norm": 0.1893928050994873,
      "learning_rate": 4.861762949057087e-05,
      "loss": 0.006,
      "step": 3240
    },
    {
      "epoch": 0.27732741701510366,
      "grad_norm": 0.4265751540660858,
      "learning_rate": 4.861336291492448e-05,
      "loss": 0.0047,
      "step": 3250
    },
    {
      "epoch": 0.27818073214438094,
      "grad_norm": 0.23066319525241852,
      "learning_rate": 4.8609096339278096e-05,
      "loss": 0.0047,
      "step": 3260
    },
    {
      "epoch": 0.27903404727365816,
      "grad_norm": 0.19342565536499023,
      "learning_rate": 4.860482976363171e-05,
      "loss": 0.0046,
      "step": 3270
    },
    {
      "epoch": 0.2798873624029354,
      "grad_norm": 0.18401911854743958,
      "learning_rate": 4.8600563187985324e-05,
      "loss": 0.0053,
      "step": 3280
    },
    {
      "epoch": 0.28074067753221266,
      "grad_norm": 0.01783049665391445,
      "learning_rate": 4.859629661233894e-05,
      "loss": 0.005,
      "step": 3290
    },
    {
      "epoch": 0.2815939926614899,
      "grad_norm": 0.08047325164079666,
      "learning_rate": 4.859203003669255e-05,
      "loss": 0.006,
      "step": 3300
    },
    {
      "epoch": 0.28244730779076715,
      "grad_norm": 0.11382411420345306,
      "learning_rate": 4.858776346104617e-05,
      "loss": 0.0047,
      "step": 3310
    },
    {
      "epoch": 0.2833006229200444,
      "grad_norm": 0.3341955840587616,
      "learning_rate": 4.858349688539978e-05,
      "loss": 0.0051,
      "step": 3320
    },
    {
      "epoch": 0.2841539380493216,
      "grad_norm": 0.4147754907608032,
      "learning_rate": 4.8579230309753396e-05,
      "loss": 0.0063,
      "step": 3330
    },
    {
      "epoch": 0.2850072531785989,
      "grad_norm": 0.1198144480586052,
      "learning_rate": 4.857496373410701e-05,
      "loss": 0.0055,
      "step": 3340
    },
    {
      "epoch": 0.2858605683078761,
      "grad_norm": 0.4681989848613739,
      "learning_rate": 4.8570697158460624e-05,
      "loss": 0.0049,
      "step": 3350
    },
    {
      "epoch": 0.2867138834371533,
      "grad_norm": 0.19003237783908844,
      "learning_rate": 4.856643058281424e-05,
      "loss": 0.0048,
      "step": 3360
    },
    {
      "epoch": 0.2875671985664306,
      "grad_norm": 0.12863774597644806,
      "learning_rate": 4.8562164007167846e-05,
      "loss": 0.0047,
      "step": 3370
    },
    {
      "epoch": 0.2884205136957078,
      "grad_norm": 0.22156983613967896,
      "learning_rate": 4.855789743152147e-05,
      "loss": 0.0049,
      "step": 3380
    },
    {
      "epoch": 0.2892738288249851,
      "grad_norm": 0.04082497954368591,
      "learning_rate": 4.8553630855875074e-05,
      "loss": 0.005,
      "step": 3390
    },
    {
      "epoch": 0.2901271439542623,
      "grad_norm": 0.020978709682822227,
      "learning_rate": 4.8549364280228695e-05,
      "loss": 0.0048,
      "step": 3400
    },
    {
      "epoch": 0.29098045908353953,
      "grad_norm": 0.24289539456367493,
      "learning_rate": 4.85450977045823e-05,
      "loss": 0.004,
      "step": 3410
    },
    {
      "epoch": 0.2918337742128168,
      "grad_norm": 0.20600730180740356,
      "learning_rate": 4.8540831128935924e-05,
      "loss": 0.005,
      "step": 3420
    },
    {
      "epoch": 0.29268708934209403,
      "grad_norm": 0.07801754027605057,
      "learning_rate": 4.853656455328953e-05,
      "loss": 0.0051,
      "step": 3430
    },
    {
      "epoch": 0.29354040447137125,
      "grad_norm": 0.07512784004211426,
      "learning_rate": 4.8532297977643145e-05,
      "loss": 0.0041,
      "step": 3440
    },
    {
      "epoch": 0.29439371960064853,
      "grad_norm": 0.37569180130958557,
      "learning_rate": 4.852803140199676e-05,
      "loss": 0.0056,
      "step": 3450
    },
    {
      "epoch": 0.29524703472992575,
      "grad_norm": 0.3380529284477234,
      "learning_rate": 4.8523764826350374e-05,
      "loss": 0.0051,
      "step": 3460
    },
    {
      "epoch": 0.296100349859203,
      "grad_norm": 0.4307456314563751,
      "learning_rate": 4.851949825070399e-05,
      "loss": 0.0052,
      "step": 3470
    },
    {
      "epoch": 0.29695366498848025,
      "grad_norm": 0.5291760563850403,
      "learning_rate": 4.8515231675057596e-05,
      "loss": 0.0048,
      "step": 3480
    },
    {
      "epoch": 0.29780698011775747,
      "grad_norm": 0.21273085474967957,
      "learning_rate": 4.851096509941122e-05,
      "loss": 0.0049,
      "step": 3490
    },
    {
      "epoch": 0.29866029524703475,
      "grad_norm": 0.6341646909713745,
      "learning_rate": 4.8506698523764824e-05,
      "loss": 0.0046,
      "step": 3500
    },
    {
      "epoch": 0.29951361037631197,
      "grad_norm": 0.12605534493923187,
      "learning_rate": 4.8502431948118445e-05,
      "loss": 0.0057,
      "step": 3510
    },
    {
      "epoch": 0.3003669255055892,
      "grad_norm": 0.18624253571033478,
      "learning_rate": 4.849816537247205e-05,
      "loss": 0.0055,
      "step": 3520
    },
    {
      "epoch": 0.30122024063486647,
      "grad_norm": 0.07618717849254608,
      "learning_rate": 4.8493898796825674e-05,
      "loss": 0.0043,
      "step": 3530
    },
    {
      "epoch": 0.3020735557641437,
      "grad_norm": 0.032020725309848785,
      "learning_rate": 4.848963222117928e-05,
      "loss": 0.006,
      "step": 3540
    },
    {
      "epoch": 0.30292687089342096,
      "grad_norm": 0.02036444842815399,
      "learning_rate": 4.8485365645532895e-05,
      "loss": 0.0041,
      "step": 3550
    },
    {
      "epoch": 0.3037801860226982,
      "grad_norm": 0.08148143440485,
      "learning_rate": 4.848109906988651e-05,
      "loss": 0.0056,
      "step": 3560
    },
    {
      "epoch": 0.3046335011519754,
      "grad_norm": 0.2296961396932602,
      "learning_rate": 4.8476832494240124e-05,
      "loss": 0.0054,
      "step": 3570
    },
    {
      "epoch": 0.3054868162812527,
      "grad_norm": 0.26376327872276306,
      "learning_rate": 4.847256591859374e-05,
      "loss": 0.0058,
      "step": 3580
    },
    {
      "epoch": 0.3063401314105299,
      "grad_norm": 0.11906424164772034,
      "learning_rate": 4.846829934294735e-05,
      "loss": 0.0049,
      "step": 3590
    },
    {
      "epoch": 0.3071934465398071,
      "grad_norm": 0.15706947445869446,
      "learning_rate": 4.8464032767300967e-05,
      "loss": 0.0048,
      "step": 3600
    },
    {
      "epoch": 0.3080467616690844,
      "grad_norm": 0.04363170638680458,
      "learning_rate": 4.845976619165458e-05,
      "loss": 0.0053,
      "step": 3610
    },
    {
      "epoch": 0.3089000767983616,
      "grad_norm": 0.4431833028793335,
      "learning_rate": 4.8455499616008195e-05,
      "loss": 0.0045,
      "step": 3620
    },
    {
      "epoch": 0.3097533919276389,
      "grad_norm": 0.2101462483406067,
      "learning_rate": 4.845123304036181e-05,
      "loss": 0.0049,
      "step": 3630
    },
    {
      "epoch": 0.3106067070569161,
      "grad_norm": 0.12634426355361938,
      "learning_rate": 4.8446966464715423e-05,
      "loss": 0.0057,
      "step": 3640
    },
    {
      "epoch": 0.31146002218619334,
      "grad_norm": 0.09913063049316406,
      "learning_rate": 4.844269988906904e-05,
      "loss": 0.0063,
      "step": 3650
    },
    {
      "epoch": 0.3123133373154706,
      "grad_norm": 0.1293351650238037,
      "learning_rate": 4.843843331342265e-05,
      "loss": 0.0055,
      "step": 3660
    },
    {
      "epoch": 0.31316665244474784,
      "grad_norm": 0.17557759582996368,
      "learning_rate": 4.8434166737776266e-05,
      "loss": 0.0045,
      "step": 3670
    },
    {
      "epoch": 0.31401996757402506,
      "grad_norm": 0.18946240842342377,
      "learning_rate": 4.8429900162129874e-05,
      "loss": 0.0055,
      "step": 3680
    },
    {
      "epoch": 0.31487328270330234,
      "grad_norm": 0.1219232976436615,
      "learning_rate": 4.8425633586483495e-05,
      "loss": 0.0058,
      "step": 3690
    },
    {
      "epoch": 0.31572659783257956,
      "grad_norm": 0.2651596665382385,
      "learning_rate": 4.84213670108371e-05,
      "loss": 0.0051,
      "step": 3700
    },
    {
      "epoch": 0.31657991296185684,
      "grad_norm": 0.19094474613666534,
      "learning_rate": 4.841710043519072e-05,
      "loss": 0.0035,
      "step": 3710
    },
    {
      "epoch": 0.31743322809113406,
      "grad_norm": 0.1700315922498703,
      "learning_rate": 4.841283385954433e-05,
      "loss": 0.0039,
      "step": 3720
    },
    {
      "epoch": 0.3182865432204113,
      "grad_norm": 0.14836029708385468,
      "learning_rate": 4.8408567283897945e-05,
      "loss": 0.0051,
      "step": 3730
    },
    {
      "epoch": 0.31913985834968855,
      "grad_norm": 0.3482681214809418,
      "learning_rate": 4.840430070825156e-05,
      "loss": 0.0048,
      "step": 3740
    },
    {
      "epoch": 0.3199931734789658,
      "grad_norm": 0.17238913476467133,
      "learning_rate": 4.840003413260517e-05,
      "loss": 0.0052,
      "step": 3750
    },
    {
      "epoch": 0.320846488608243,
      "grad_norm": 0.2840009331703186,
      "learning_rate": 4.839576755695879e-05,
      "loss": 0.0045,
      "step": 3760
    },
    {
      "epoch": 0.3216998037375203,
      "grad_norm": 0.11210248619318008,
      "learning_rate": 4.83915009813124e-05,
      "loss": 0.0055,
      "step": 3770
    },
    {
      "epoch": 0.3225531188667975,
      "grad_norm": 0.1950109601020813,
      "learning_rate": 4.8387234405666016e-05,
      "loss": 0.0045,
      "step": 3780
    },
    {
      "epoch": 0.32340643399607477,
      "grad_norm": 0.43069353699684143,
      "learning_rate": 4.8382967830019624e-05,
      "loss": 0.0046,
      "step": 3790
    },
    {
      "epoch": 0.324259749125352,
      "grad_norm": 0.0624343641102314,
      "learning_rate": 4.8378701254373245e-05,
      "loss": 0.0053,
      "step": 3800
    },
    {
      "epoch": 0.3251130642546292,
      "grad_norm": 0.4141106903553009,
      "learning_rate": 4.837443467872685e-05,
      "loss": 0.0051,
      "step": 3810
    },
    {
      "epoch": 0.3259663793839065,
      "grad_norm": 0.37685346603393555,
      "learning_rate": 4.837016810308047e-05,
      "loss": 0.005,
      "step": 3820
    },
    {
      "epoch": 0.3268196945131837,
      "grad_norm": 0.731157124042511,
      "learning_rate": 4.836590152743408e-05,
      "loss": 0.0048,
      "step": 3830
    },
    {
      "epoch": 0.327673009642461,
      "grad_norm": 0.3199024200439453,
      "learning_rate": 4.83616349517877e-05,
      "loss": 0.0044,
      "step": 3840
    },
    {
      "epoch": 0.3285263247717382,
      "grad_norm": 0.3951414227485657,
      "learning_rate": 4.835736837614131e-05,
      "loss": 0.0047,
      "step": 3850
    },
    {
      "epoch": 0.32937963990101543,
      "grad_norm": 0.05474597215652466,
      "learning_rate": 4.835310180049492e-05,
      "loss": 0.0047,
      "step": 3860
    },
    {
      "epoch": 0.3302329550302927,
      "grad_norm": 0.152777299284935,
      "learning_rate": 4.834883522484854e-05,
      "loss": 0.0058,
      "step": 3870
    },
    {
      "epoch": 0.33108627015956993,
      "grad_norm": 0.3081061840057373,
      "learning_rate": 4.834456864920215e-05,
      "loss": 0.0047,
      "step": 3880
    },
    {
      "epoch": 0.33193958528884715,
      "grad_norm": 0.2458105981349945,
      "learning_rate": 4.8340302073555766e-05,
      "loss": 0.0055,
      "step": 3890
    },
    {
      "epoch": 0.3327929004181244,
      "grad_norm": 0.174338236451149,
      "learning_rate": 4.833603549790938e-05,
      "loss": 0.0045,
      "step": 3900
    },
    {
      "epoch": 0.33364621554740165,
      "grad_norm": 0.3983630836009979,
      "learning_rate": 4.8331768922262994e-05,
      "loss": 0.006,
      "step": 3910
    },
    {
      "epoch": 0.3344995306766789,
      "grad_norm": 0.4867873787879944,
      "learning_rate": 4.832750234661661e-05,
      "loss": 0.0046,
      "step": 3920
    },
    {
      "epoch": 0.33535284580595615,
      "grad_norm": 0.3398711383342743,
      "learning_rate": 4.832323577097022e-05,
      "loss": 0.0051,
      "step": 3930
    },
    {
      "epoch": 0.33620616093523337,
      "grad_norm": 0.11771029233932495,
      "learning_rate": 4.831896919532384e-05,
      "loss": 0.0064,
      "step": 3940
    },
    {
      "epoch": 0.33705947606451064,
      "grad_norm": 0.3963037133216858,
      "learning_rate": 4.831470261967745e-05,
      "loss": 0.0051,
      "step": 3950
    },
    {
      "epoch": 0.33791279119378786,
      "grad_norm": 0.28083983063697815,
      "learning_rate": 4.8310436044031066e-05,
      "loss": 0.0043,
      "step": 3960
    },
    {
      "epoch": 0.3387661063230651,
      "grad_norm": 0.1587030291557312,
      "learning_rate": 4.830616946838468e-05,
      "loss": 0.005,
      "step": 3970
    },
    {
      "epoch": 0.33961942145234236,
      "grad_norm": 0.13044209778308868,
      "learning_rate": 4.8301902892738294e-05,
      "loss": 0.0041,
      "step": 3980
    },
    {
      "epoch": 0.3404727365816196,
      "grad_norm": 0.4664531946182251,
      "learning_rate": 4.82976363170919e-05,
      "loss": 0.0053,
      "step": 3990
    },
    {
      "epoch": 0.34132605171089686,
      "grad_norm": 0.10213842242956161,
      "learning_rate": 4.8293369741445516e-05,
      "loss": 0.0053,
      "step": 4000
    },
    {
      "epoch": 0.3421793668401741,
      "grad_norm": 0.20680971443653107,
      "learning_rate": 4.828910316579913e-05,
      "loss": 0.0047,
      "step": 4010
    },
    {
      "epoch": 0.3430326819694513,
      "grad_norm": 0.20545357465744019,
      "learning_rate": 4.8284836590152744e-05,
      "loss": 0.0046,
      "step": 4020
    },
    {
      "epoch": 0.3438859970987286,
      "grad_norm": 0.09333395212888718,
      "learning_rate": 4.828057001450636e-05,
      "loss": 0.0041,
      "step": 4030
    },
    {
      "epoch": 0.3447393122280058,
      "grad_norm": 0.16328580677509308,
      "learning_rate": 4.827630343885997e-05,
      "loss": 0.0031,
      "step": 4040
    },
    {
      "epoch": 0.345592627357283,
      "grad_norm": 0.4687430262565613,
      "learning_rate": 4.827203686321359e-05,
      "loss": 0.0058,
      "step": 4050
    },
    {
      "epoch": 0.3464459424865603,
      "grad_norm": 0.10938455909490585,
      "learning_rate": 4.82677702875672e-05,
      "loss": 0.0049,
      "step": 4060
    },
    {
      "epoch": 0.3472992576158375,
      "grad_norm": 0.41273123025894165,
      "learning_rate": 4.8263503711920816e-05,
      "loss": 0.0042,
      "step": 4070
    },
    {
      "epoch": 0.3481525727451148,
      "grad_norm": 0.07075265794992447,
      "learning_rate": 4.825923713627443e-05,
      "loss": 0.0048,
      "step": 4080
    },
    {
      "epoch": 0.349005887874392,
      "grad_norm": 0.3847271203994751,
      "learning_rate": 4.8254970560628044e-05,
      "loss": 0.0042,
      "step": 4090
    },
    {
      "epoch": 0.34985920300366924,
      "grad_norm": 0.10659252852201462,
      "learning_rate": 4.825070398498165e-05,
      "loss": 0.0049,
      "step": 4100
    },
    {
      "epoch": 0.3507125181329465,
      "grad_norm": 0.7829042077064514,
      "learning_rate": 4.824643740933527e-05,
      "loss": 0.0044,
      "step": 4110
    },
    {
      "epoch": 0.35156583326222374,
      "grad_norm": 0.13299380242824554,
      "learning_rate": 4.824217083368888e-05,
      "loss": 0.005,
      "step": 4120
    },
    {
      "epoch": 0.35241914839150096,
      "grad_norm": 0.32111915946006775,
      "learning_rate": 4.82379042580425e-05,
      "loss": 0.0045,
      "step": 4130
    },
    {
      "epoch": 0.35327246352077823,
      "grad_norm": 0.17243079841136932,
      "learning_rate": 4.823363768239611e-05,
      "loss": 0.0052,
      "step": 4140
    },
    {
      "epoch": 0.35412577865005546,
      "grad_norm": 0.4292236864566803,
      "learning_rate": 4.822937110674973e-05,
      "loss": 0.0043,
      "step": 4150
    },
    {
      "epoch": 0.35497909377933273,
      "grad_norm": 0.22456321120262146,
      "learning_rate": 4.822510453110334e-05,
      "loss": 0.0049,
      "step": 4160
    },
    {
      "epoch": 0.35583240890860995,
      "grad_norm": 0.4096824824810028,
      "learning_rate": 4.822083795545695e-05,
      "loss": 0.0055,
      "step": 4170
    },
    {
      "epoch": 0.3566857240378872,
      "grad_norm": 0.4448093771934509,
      "learning_rate": 4.8216571379810565e-05,
      "loss": 0.0046,
      "step": 4180
    },
    {
      "epoch": 0.35753903916716445,
      "grad_norm": 0.09848224371671677,
      "learning_rate": 4.821230480416418e-05,
      "loss": 0.0049,
      "step": 4190
    },
    {
      "epoch": 0.3583923542964417,
      "grad_norm": 0.0769910141825676,
      "learning_rate": 4.8208038228517794e-05,
      "loss": 0.0043,
      "step": 4200
    },
    {
      "epoch": 0.3592456694257189,
      "grad_norm": 0.2108234465122223,
      "learning_rate": 4.820377165287141e-05,
      "loss": 0.0028,
      "step": 4210
    },
    {
      "epoch": 0.36009898455499617,
      "grad_norm": 0.0466284416615963,
      "learning_rate": 4.819950507722502e-05,
      "loss": 0.004,
      "step": 4220
    },
    {
      "epoch": 0.3609522996842734,
      "grad_norm": 0.3827846646308899,
      "learning_rate": 4.8195238501578637e-05,
      "loss": 0.0039,
      "step": 4230
    },
    {
      "epoch": 0.36180561481355067,
      "grad_norm": 0.5303773283958435,
      "learning_rate": 4.819097192593225e-05,
      "loss": 0.0069,
      "step": 4240
    },
    {
      "epoch": 0.3626589299428279,
      "grad_norm": 0.07671845704317093,
      "learning_rate": 4.8186705350285865e-05,
      "loss": 0.0047,
      "step": 4250
    },
    {
      "epoch": 0.3635122450721051,
      "grad_norm": 0.06746018677949905,
      "learning_rate": 4.818243877463948e-05,
      "loss": 0.0054,
      "step": 4260
    },
    {
      "epoch": 0.3643655602013824,
      "grad_norm": 0.19328492879867554,
      "learning_rate": 4.817817219899309e-05,
      "loss": 0.0058,
      "step": 4270
    },
    {
      "epoch": 0.3652188753306596,
      "grad_norm": 0.05523890629410744,
      "learning_rate": 4.817390562334671e-05,
      "loss": 0.0045,
      "step": 4280
    },
    {
      "epoch": 0.36607219045993683,
      "grad_norm": 0.4329968988895416,
      "learning_rate": 4.8169639047700315e-05,
      "loss": 0.0052,
      "step": 4290
    },
    {
      "epoch": 0.3669255055892141,
      "grad_norm": 0.3409622609615326,
      "learning_rate": 4.816537247205393e-05,
      "loss": 0.004,
      "step": 4300
    },
    {
      "epoch": 0.36777882071849133,
      "grad_norm": 0.15399013459682465,
      "learning_rate": 4.8161105896407544e-05,
      "loss": 0.0048,
      "step": 4310
    },
    {
      "epoch": 0.3686321358477686,
      "grad_norm": 0.07695738971233368,
      "learning_rate": 4.815683932076116e-05,
      "loss": 0.0064,
      "step": 4320
    },
    {
      "epoch": 0.3694854509770458,
      "grad_norm": 0.5466035604476929,
      "learning_rate": 4.815257274511477e-05,
      "loss": 0.0047,
      "step": 4330
    },
    {
      "epoch": 0.37033876610632305,
      "grad_norm": 0.12172828614711761,
      "learning_rate": 4.8148306169468386e-05,
      "loss": 0.0048,
      "step": 4340
    },
    {
      "epoch": 0.3711920812356003,
      "grad_norm": 0.25916728377342224,
      "learning_rate": 4.8144039593822e-05,
      "loss": 0.0048,
      "step": 4350
    },
    {
      "epoch": 0.37204539636487755,
      "grad_norm": 0.15089420974254608,
      "learning_rate": 4.8139773018175615e-05,
      "loss": 0.0051,
      "step": 4360
    },
    {
      "epoch": 0.37289871149415477,
      "grad_norm": 0.6726345419883728,
      "learning_rate": 4.813550644252923e-05,
      "loss": 0.0043,
      "step": 4370
    },
    {
      "epoch": 0.37375202662343204,
      "grad_norm": 0.5246196389198303,
      "learning_rate": 4.8131239866882843e-05,
      "loss": 0.0042,
      "step": 4380
    },
    {
      "epoch": 0.37460534175270926,
      "grad_norm": 0.4115723669528961,
      "learning_rate": 4.812697329123646e-05,
      "loss": 0.0048,
      "step": 4390
    },
    {
      "epoch": 0.37545865688198654,
      "grad_norm": 0.06296296417713165,
      "learning_rate": 4.812270671559007e-05,
      "loss": 0.0052,
      "step": 4400
    },
    {
      "epoch": 0.37631197201126376,
      "grad_norm": 0.03648709878325462,
      "learning_rate": 4.811844013994368e-05,
      "loss": 0.0043,
      "step": 4410
    },
    {
      "epoch": 0.377165287140541,
      "grad_norm": 0.1938619166612625,
      "learning_rate": 4.81141735642973e-05,
      "loss": 0.0049,
      "step": 4420
    },
    {
      "epoch": 0.37801860226981826,
      "grad_norm": 0.7054511904716492,
      "learning_rate": 4.810990698865091e-05,
      "loss": 0.0051,
      "step": 4430
    },
    {
      "epoch": 0.3788719173990955,
      "grad_norm": 0.14817507565021515,
      "learning_rate": 4.810564041300453e-05,
      "loss": 0.0055,
      "step": 4440
    },
    {
      "epoch": 0.3797252325283727,
      "grad_norm": 0.6153182983398438,
      "learning_rate": 4.8101373837358136e-05,
      "loss": 0.0047,
      "step": 4450
    },
    {
      "epoch": 0.38057854765765,
      "grad_norm": 0.09571273624897003,
      "learning_rate": 4.809710726171176e-05,
      "loss": 0.0053,
      "step": 4460
    },
    {
      "epoch": 0.3814318627869272,
      "grad_norm": 0.4534665048122406,
      "learning_rate": 4.8092840686065365e-05,
      "loss": 0.0044,
      "step": 4470
    },
    {
      "epoch": 0.3822851779162045,
      "grad_norm": 0.4253762662410736,
      "learning_rate": 4.808857411041898e-05,
      "loss": 0.0043,
      "step": 4480
    },
    {
      "epoch": 0.3831384930454817,
      "grad_norm": 0.5220872163772583,
      "learning_rate": 4.808430753477259e-05,
      "loss": 0.0043,
      "step": 4490
    },
    {
      "epoch": 0.3839918081747589,
      "grad_norm": 0.5089313387870789,
      "learning_rate": 4.808004095912621e-05,
      "loss": 0.0043,
      "step": 4500
    },
    {
      "epoch": 0.3848451233040362,
      "grad_norm": 0.44943785667419434,
      "learning_rate": 4.807577438347982e-05,
      "loss": 0.0058,
      "step": 4510
    },
    {
      "epoch": 0.3856984384333134,
      "grad_norm": 0.15053297579288483,
      "learning_rate": 4.807150780783343e-05,
      "loss": 0.0049,
      "step": 4520
    },
    {
      "epoch": 0.38655175356259064,
      "grad_norm": 0.22062352299690247,
      "learning_rate": 4.806724123218705e-05,
      "loss": 0.0043,
      "step": 4530
    },
    {
      "epoch": 0.3874050686918679,
      "grad_norm": 0.2985435128211975,
      "learning_rate": 4.806297465654066e-05,
      "loss": 0.0055,
      "step": 4540
    },
    {
      "epoch": 0.38825838382114514,
      "grad_norm": 0.10361246764659882,
      "learning_rate": 4.805870808089428e-05,
      "loss": 0.0045,
      "step": 4550
    },
    {
      "epoch": 0.3891116989504224,
      "grad_norm": 0.23197969794273376,
      "learning_rate": 4.8054441505247886e-05,
      "loss": 0.0044,
      "step": 4560
    },
    {
      "epoch": 0.38996501407969963,
      "grad_norm": 0.31933337450027466,
      "learning_rate": 4.805017492960151e-05,
      "loss": 0.0058,
      "step": 4570
    },
    {
      "epoch": 0.39081832920897686,
      "grad_norm": 0.08994756639003754,
      "learning_rate": 4.8045908353955115e-05,
      "loss": 0.0052,
      "step": 4580
    },
    {
      "epoch": 0.39167164433825413,
      "grad_norm": 0.03008028119802475,
      "learning_rate": 4.8041641778308736e-05,
      "loss": 0.0066,
      "step": 4590
    },
    {
      "epoch": 0.39252495946753135,
      "grad_norm": 0.13231007754802704,
      "learning_rate": 4.803737520266234e-05,
      "loss": 0.0044,
      "step": 4600
    },
    {
      "epoch": 0.3933782745968086,
      "grad_norm": 0.0907195433974266,
      "learning_rate": 4.803310862701596e-05,
      "loss": 0.0058,
      "step": 4610
    },
    {
      "epoch": 0.39423158972608585,
      "grad_norm": 0.35242363810539246,
      "learning_rate": 4.802884205136957e-05,
      "loss": 0.0036,
      "step": 4620
    },
    {
      "epoch": 0.3950849048553631,
      "grad_norm": 0.11424683779478073,
      "learning_rate": 4.8024575475723186e-05,
      "loss": 0.0046,
      "step": 4630
    },
    {
      "epoch": 0.39593821998464035,
      "grad_norm": 0.3762092888355255,
      "learning_rate": 4.80203089000768e-05,
      "loss": 0.0058,
      "step": 4640
    },
    {
      "epoch": 0.39679153511391757,
      "grad_norm": 0.20346689224243164,
      "learning_rate": 4.8016042324430414e-05,
      "loss": 0.0054,
      "step": 4650
    },
    {
      "epoch": 0.3976448502431948,
      "grad_norm": 0.37712013721466064,
      "learning_rate": 4.801177574878403e-05,
      "loss": 0.0059,
      "step": 4660
    },
    {
      "epoch": 0.39849816537247207,
      "grad_norm": 0.1360691785812378,
      "learning_rate": 4.800750917313764e-05,
      "loss": 0.0049,
      "step": 4670
    },
    {
      "epoch": 0.3993514805017493,
      "grad_norm": 0.029118821024894714,
      "learning_rate": 4.800324259749126e-05,
      "loss": 0.0053,
      "step": 4680
    },
    {
      "epoch": 0.4002047956310265,
      "grad_norm": 0.10856497287750244,
      "learning_rate": 4.799897602184487e-05,
      "loss": 0.005,
      "step": 4690
    },
    {
      "epoch": 0.4010581107603038,
      "grad_norm": 0.3570106327533722,
      "learning_rate": 4.7994709446198486e-05,
      "loss": 0.0047,
      "step": 4700
    },
    {
      "epoch": 0.401911425889581,
      "grad_norm": 0.4489913880825043,
      "learning_rate": 4.79904428705521e-05,
      "loss": 0.0036,
      "step": 4710
    },
    {
      "epoch": 0.4027647410188583,
      "grad_norm": 0.2111768275499344,
      "learning_rate": 4.798617629490571e-05,
      "loss": 0.0035,
      "step": 4720
    },
    {
      "epoch": 0.4036180561481355,
      "grad_norm": 0.2617635428905487,
      "learning_rate": 4.798190971925933e-05,
      "loss": 0.0051,
      "step": 4730
    },
    {
      "epoch": 0.40447137127741273,
      "grad_norm": 0.16670481860637665,
      "learning_rate": 4.7977643143612936e-05,
      "loss": 0.0037,
      "step": 4740
    },
    {
      "epoch": 0.40532468640669,
      "grad_norm": 0.3272135853767395,
      "learning_rate": 4.797337656796656e-05,
      "loss": 0.0043,
      "step": 4750
    },
    {
      "epoch": 0.4061780015359672,
      "grad_norm": 0.09446470439434052,
      "learning_rate": 4.7969109992320164e-05,
      "loss": 0.0046,
      "step": 4760
    },
    {
      "epoch": 0.4070313166652445,
      "grad_norm": 0.6936911940574646,
      "learning_rate": 4.7964843416673785e-05,
      "loss": 0.0052,
      "step": 4770
    },
    {
      "epoch": 0.4078846317945217,
      "grad_norm": 0.062120866030454636,
      "learning_rate": 4.796057684102739e-05,
      "loss": 0.0047,
      "step": 4780
    },
    {
      "epoch": 0.40873794692379894,
      "grad_norm": 0.4843233823776245,
      "learning_rate": 4.795631026538101e-05,
      "loss": 0.005,
      "step": 4790
    },
    {
      "epoch": 0.4095912620530762,
      "grad_norm": 0.5394333004951477,
      "learning_rate": 4.795204368973462e-05,
      "loss": 0.0057,
      "step": 4800
    },
    {
      "epoch": 0.41044457718235344,
      "grad_norm": 0.6556439399719238,
      "learning_rate": 4.7947777114088235e-05,
      "loss": 0.004,
      "step": 4810
    },
    {
      "epoch": 0.41129789231163066,
      "grad_norm": 0.6116889715194702,
      "learning_rate": 4.794351053844185e-05,
      "loss": 0.005,
      "step": 4820
    },
    {
      "epoch": 0.41215120744090794,
      "grad_norm": 0.39630383253097534,
      "learning_rate": 4.793924396279546e-05,
      "loss": 0.0043,
      "step": 4830
    },
    {
      "epoch": 0.41300452257018516,
      "grad_norm": 0.21151787042617798,
      "learning_rate": 4.793497738714908e-05,
      "loss": 0.0041,
      "step": 4840
    },
    {
      "epoch": 0.41385783769946244,
      "grad_norm": 0.068543441593647,
      "learning_rate": 4.7930710811502686e-05,
      "loss": 0.0042,
      "step": 4850
    },
    {
      "epoch": 0.41471115282873966,
      "grad_norm": 0.5208516716957092,
      "learning_rate": 4.792644423585631e-05,
      "loss": 0.0052,
      "step": 4860
    },
    {
      "epoch": 0.4155644679580169,
      "grad_norm": 0.2825268507003784,
      "learning_rate": 4.7922177660209914e-05,
      "loss": 0.0054,
      "step": 4870
    },
    {
      "epoch": 0.41641778308729416,
      "grad_norm": 0.14130210876464844,
      "learning_rate": 4.7917911084563535e-05,
      "loss": 0.0053,
      "step": 4880
    },
    {
      "epoch": 0.4172710982165714,
      "grad_norm": 0.1485150158405304,
      "learning_rate": 4.791364450891714e-05,
      "loss": 0.0042,
      "step": 4890
    },
    {
      "epoch": 0.4181244133458486,
      "grad_norm": 0.12407929450273514,
      "learning_rate": 4.7909377933270764e-05,
      "loss": 0.005,
      "step": 4900
    },
    {
      "epoch": 0.4189777284751259,
      "grad_norm": 0.3075268864631653,
      "learning_rate": 4.790511135762437e-05,
      "loss": 0.0037,
      "step": 4910
    },
    {
      "epoch": 0.4198310436044031,
      "grad_norm": 0.057373255491256714,
      "learning_rate": 4.7900844781977985e-05,
      "loss": 0.004,
      "step": 4920
    },
    {
      "epoch": 0.4206843587336804,
      "grad_norm": 0.12952642142772675,
      "learning_rate": 4.78965782063316e-05,
      "loss": 0.0043,
      "step": 4930
    },
    {
      "epoch": 0.4215376738629576,
      "grad_norm": 0.13051851093769073,
      "learning_rate": 4.7892311630685214e-05,
      "loss": 0.0046,
      "step": 4940
    },
    {
      "epoch": 0.4223909889922348,
      "grad_norm": 0.34248048067092896,
      "learning_rate": 4.788804505503883e-05,
      "loss": 0.0049,
      "step": 4950
    },
    {
      "epoch": 0.4232443041215121,
      "grad_norm": 0.2775619924068451,
      "learning_rate": 4.788377847939244e-05,
      "loss": 0.0044,
      "step": 4960
    },
    {
      "epoch": 0.4240976192507893,
      "grad_norm": 0.04834968224167824,
      "learning_rate": 4.7879511903746057e-05,
      "loss": 0.004,
      "step": 4970
    },
    {
      "epoch": 0.42495093438006654,
      "grad_norm": 0.07992920279502869,
      "learning_rate": 4.787524532809967e-05,
      "loss": 0.0048,
      "step": 4980
    },
    {
      "epoch": 0.4258042495093438,
      "grad_norm": 0.051237381994724274,
      "learning_rate": 4.7870978752453285e-05,
      "loss": 0.0043,
      "step": 4990
    },
    {
      "epoch": 0.42665756463862103,
      "grad_norm": 0.48774391412734985,
      "learning_rate": 4.78667121768069e-05,
      "loss": 0.0054,
      "step": 5000
    },
    {
      "epoch": 0.4275108797678983,
      "grad_norm": 0.29585906863212585,
      "learning_rate": 4.7862445601160514e-05,
      "loss": 0.0039,
      "step": 5010
    },
    {
      "epoch": 0.42836419489717553,
      "grad_norm": 0.5559002161026001,
      "learning_rate": 4.785817902551413e-05,
      "loss": 0.0053,
      "step": 5020
    },
    {
      "epoch": 0.42921751002645275,
      "grad_norm": 0.1312543898820877,
      "learning_rate": 4.7853912449867735e-05,
      "loss": 0.0047,
      "step": 5030
    },
    {
      "epoch": 0.43007082515573003,
      "grad_norm": 0.2851257026195526,
      "learning_rate": 4.7849645874221356e-05,
      "loss": 0.0038,
      "step": 5040
    },
    {
      "epoch": 0.43092414028500725,
      "grad_norm": 0.08311542868614197,
      "learning_rate": 4.7845379298574964e-05,
      "loss": 0.0045,
      "step": 5050
    },
    {
      "epoch": 0.4317774554142845,
      "grad_norm": 0.04180385544896126,
      "learning_rate": 4.784111272292858e-05,
      "loss": 0.0051,
      "step": 5060
    },
    {
      "epoch": 0.43263077054356175,
      "grad_norm": 0.7833151817321777,
      "learning_rate": 4.783684614728219e-05,
      "loss": 0.0038,
      "step": 5070
    },
    {
      "epoch": 0.43348408567283897,
      "grad_norm": 0.2977565824985504,
      "learning_rate": 4.7832579571635806e-05,
      "loss": 0.0049,
      "step": 5080
    },
    {
      "epoch": 0.43433740080211625,
      "grad_norm": 0.15113595128059387,
      "learning_rate": 4.782831299598942e-05,
      "loss": 0.0055,
      "step": 5090
    },
    {
      "epoch": 0.43519071593139347,
      "grad_norm": 0.030411330983042717,
      "learning_rate": 4.7824046420343035e-05,
      "loss": 0.004,
      "step": 5100
    },
    {
      "epoch": 0.4360440310606707,
      "grad_norm": 0.045467931777238846,
      "learning_rate": 4.781977984469665e-05,
      "loss": 0.0049,
      "step": 5110
    },
    {
      "epoch": 0.43689734618994797,
      "grad_norm": 0.3595990538597107,
      "learning_rate": 4.781551326905026e-05,
      "loss": 0.004,
      "step": 5120
    },
    {
      "epoch": 0.4377506613192252,
      "grad_norm": 0.5212698578834534,
      "learning_rate": 4.781124669340388e-05,
      "loss": 0.0051,
      "step": 5130
    },
    {
      "epoch": 0.4386039764485024,
      "grad_norm": 0.18936218321323395,
      "learning_rate": 4.7806980117757485e-05,
      "loss": 0.0051,
      "step": 5140
    },
    {
      "epoch": 0.4394572915777797,
      "grad_norm": 0.276746928691864,
      "learning_rate": 4.7802713542111106e-05,
      "loss": 0.0045,
      "step": 5150
    },
    {
      "epoch": 0.4403106067070569,
      "grad_norm": 0.3532828688621521,
      "learning_rate": 4.7798446966464714e-05,
      "loss": 0.0047,
      "step": 5160
    },
    {
      "epoch": 0.4411639218363342,
      "grad_norm": 0.2090039700269699,
      "learning_rate": 4.7794180390818335e-05,
      "loss": 0.0049,
      "step": 5170
    },
    {
      "epoch": 0.4420172369656114,
      "grad_norm": 0.4134731590747833,
      "learning_rate": 4.778991381517194e-05,
      "loss": 0.0046,
      "step": 5180
    },
    {
      "epoch": 0.4428705520948886,
      "grad_norm": 0.09987664967775345,
      "learning_rate": 4.778564723952556e-05,
      "loss": 0.0051,
      "step": 5190
    },
    {
      "epoch": 0.4437238672241659,
      "grad_norm": 0.18711735308170319,
      "learning_rate": 4.778138066387917e-05,
      "loss": 0.0049,
      "step": 5200
    },
    {
      "epoch": 0.4445771823534431,
      "grad_norm": 0.33988165855407715,
      "learning_rate": 4.777711408823279e-05,
      "loss": 0.0027,
      "step": 5210
    },
    {
      "epoch": 0.44543049748272034,
      "grad_norm": 0.046124644577503204,
      "learning_rate": 4.77728475125864e-05,
      "loss": 0.0052,
      "step": 5220
    },
    {
      "epoch": 0.4462838126119976,
      "grad_norm": 0.5761829018592834,
      "learning_rate": 4.776858093694001e-05,
      "loss": 0.0053,
      "step": 5230
    },
    {
      "epoch": 0.44713712774127484,
      "grad_norm": 0.37536320090293884,
      "learning_rate": 4.776431436129363e-05,
      "loss": 0.0053,
      "step": 5240
    },
    {
      "epoch": 0.4479904428705521,
      "grad_norm": 0.34022316336631775,
      "learning_rate": 4.776004778564724e-05,
      "loss": 0.0041,
      "step": 5250
    },
    {
      "epoch": 0.44884375799982934,
      "grad_norm": 0.18920457363128662,
      "learning_rate": 4.7755781210000856e-05,
      "loss": 0.0037,
      "step": 5260
    },
    {
      "epoch": 0.44969707312910656,
      "grad_norm": 0.0993727445602417,
      "learning_rate": 4.775151463435447e-05,
      "loss": 0.0039,
      "step": 5270
    },
    {
      "epoch": 0.45055038825838384,
      "grad_norm": 0.13404016196727753,
      "learning_rate": 4.7747248058708084e-05,
      "loss": 0.0053,
      "step": 5280
    },
    {
      "epoch": 0.45140370338766106,
      "grad_norm": 0.10360486805438995,
      "learning_rate": 4.77429814830617e-05,
      "loss": 0.0037,
      "step": 5290
    },
    {
      "epoch": 0.4522570185169383,
      "grad_norm": 0.15445277094841003,
      "learning_rate": 4.773871490741531e-05,
      "loss": 0.0046,
      "step": 5300
    },
    {
      "epoch": 0.45311033364621556,
      "grad_norm": 0.035882167518138885,
      "learning_rate": 4.773444833176893e-05,
      "loss": 0.004,
      "step": 5310
    },
    {
      "epoch": 0.4539636487754928,
      "grad_norm": 0.12119544297456741,
      "learning_rate": 4.773018175612254e-05,
      "loss": 0.0043,
      "step": 5320
    },
    {
      "epoch": 0.45481696390477006,
      "grad_norm": 0.037685468792915344,
      "learning_rate": 4.772591518047615e-05,
      "loss": 0.0052,
      "step": 5330
    },
    {
      "epoch": 0.4556702790340473,
      "grad_norm": 0.1527189314365387,
      "learning_rate": 4.772164860482976e-05,
      "loss": 0.0043,
      "step": 5340
    },
    {
      "epoch": 0.4565235941633245,
      "grad_norm": 0.4233359694480896,
      "learning_rate": 4.771738202918338e-05,
      "loss": 0.0047,
      "step": 5350
    },
    {
      "epoch": 0.4573769092926018,
      "grad_norm": 0.4202529191970825,
      "learning_rate": 4.771311545353699e-05,
      "loss": 0.0061,
      "step": 5360
    },
    {
      "epoch": 0.458230224421879,
      "grad_norm": 0.4239185154438019,
      "learning_rate": 4.7708848877890606e-05,
      "loss": 0.0046,
      "step": 5370
    },
    {
      "epoch": 0.4590835395511562,
      "grad_norm": 0.33698418736457825,
      "learning_rate": 4.770458230224422e-05,
      "loss": 0.0046,
      "step": 5380
    },
    {
      "epoch": 0.4599368546804335,
      "grad_norm": 0.26283249258995056,
      "learning_rate": 4.7700315726597834e-05,
      "loss": 0.005,
      "step": 5390
    },
    {
      "epoch": 0.4607901698097107,
      "grad_norm": 0.1877535730600357,
      "learning_rate": 4.769604915095145e-05,
      "loss": 0.0053,
      "step": 5400
    },
    {
      "epoch": 0.461643484938988,
      "grad_norm": 0.48408859968185425,
      "learning_rate": 4.769178257530506e-05,
      "loss": 0.0044,
      "step": 5410
    },
    {
      "epoch": 0.4624968000682652,
      "grad_norm": 0.2831212878227234,
      "learning_rate": 4.768751599965868e-05,
      "loss": 0.004,
      "step": 5420
    },
    {
      "epoch": 0.46335011519754243,
      "grad_norm": 0.17753015458583832,
      "learning_rate": 4.768324942401229e-05,
      "loss": 0.0046,
      "step": 5430
    },
    {
      "epoch": 0.4642034303268197,
      "grad_norm": 0.298159658908844,
      "learning_rate": 4.7678982848365906e-05,
      "loss": 0.0043,
      "step": 5440
    },
    {
      "epoch": 0.46505674545609693,
      "grad_norm": 0.09671822935342789,
      "learning_rate": 4.767471627271951e-05,
      "loss": 0.0039,
      "step": 5450
    },
    {
      "epoch": 0.46591006058537415,
      "grad_norm": 0.05959311127662659,
      "learning_rate": 4.7670449697073134e-05,
      "loss": 0.0029,
      "step": 5460
    },
    {
      "epoch": 0.46676337571465143,
      "grad_norm": 0.4718354046344757,
      "learning_rate": 4.766618312142674e-05,
      "loss": 0.0041,
      "step": 5470
    },
    {
      "epoch": 0.46761669084392865,
      "grad_norm": 0.24762694537639618,
      "learning_rate": 4.766191654578036e-05,
      "loss": 0.0044,
      "step": 5480
    },
    {
      "epoch": 0.4684700059732059,
      "grad_norm": 0.15230341255664825,
      "learning_rate": 4.765764997013397e-05,
      "loss": 0.004,
      "step": 5490
    },
    {
      "epoch": 0.46932332110248315,
      "grad_norm": 0.09572999179363251,
      "learning_rate": 4.765338339448759e-05,
      "loss": 0.006,
      "step": 5500
    },
    {
      "epoch": 0.47017663623176037,
      "grad_norm": 0.07494502514600754,
      "learning_rate": 4.76491168188412e-05,
      "loss": 0.0039,
      "step": 5510
    },
    {
      "epoch": 0.47102995136103765,
      "grad_norm": 0.4621395766735077,
      "learning_rate": 4.764485024319482e-05,
      "loss": 0.0041,
      "step": 5520
    },
    {
      "epoch": 0.47188326649031487,
      "grad_norm": 0.7238370180130005,
      "learning_rate": 4.764058366754843e-05,
      "loss": 0.0044,
      "step": 5530
    },
    {
      "epoch": 0.4727365816195921,
      "grad_norm": 0.18885354697704315,
      "learning_rate": 4.763631709190204e-05,
      "loss": 0.0048,
      "step": 5540
    },
    {
      "epoch": 0.47358989674886937,
      "grad_norm": 0.3819968104362488,
      "learning_rate": 4.7632050516255655e-05,
      "loss": 0.0048,
      "step": 5550
    },
    {
      "epoch": 0.4744432118781466,
      "grad_norm": 0.03177971765398979,
      "learning_rate": 4.762778394060927e-05,
      "loss": 0.0035,
      "step": 5560
    },
    {
      "epoch": 0.47529652700742386,
      "grad_norm": 0.24739642441272736,
      "learning_rate": 4.7623517364962884e-05,
      "loss": 0.0034,
      "step": 5570
    },
    {
      "epoch": 0.4761498421367011,
      "grad_norm": 0.3018574118614197,
      "learning_rate": 4.76192507893165e-05,
      "loss": 0.0045,
      "step": 5580
    },
    {
      "epoch": 0.4770031572659783,
      "grad_norm": 0.7108163237571716,
      "learning_rate": 4.761498421367011e-05,
      "loss": 0.0045,
      "step": 5590
    },
    {
      "epoch": 0.4778564723952556,
      "grad_norm": 0.1568165421485901,
      "learning_rate": 4.761071763802372e-05,
      "loss": 0.004,
      "step": 5600
    },
    {
      "epoch": 0.4787097875245328,
      "grad_norm": 0.0783669501543045,
      "learning_rate": 4.760645106237734e-05,
      "loss": 0.0056,
      "step": 5610
    },
    {
      "epoch": 0.47956310265381,
      "grad_norm": 0.5080082416534424,
      "learning_rate": 4.760218448673095e-05,
      "loss": 0.0055,
      "step": 5620
    },
    {
      "epoch": 0.4804164177830873,
      "grad_norm": 0.11217627674341202,
      "learning_rate": 4.759791791108457e-05,
      "loss": 0.0032,
      "step": 5630
    },
    {
      "epoch": 0.4812697329123645,
      "grad_norm": 0.20624735951423645,
      "learning_rate": 4.759365133543818e-05,
      "loss": 0.0041,
      "step": 5640
    },
    {
      "epoch": 0.4821230480416418,
      "grad_norm": 0.2455212026834488,
      "learning_rate": 4.758938475979179e-05,
      "loss": 0.0043,
      "step": 5650
    },
    {
      "epoch": 0.482976363170919,
      "grad_norm": 0.30081820487976074,
      "learning_rate": 4.7585118184145405e-05,
      "loss": 0.0039,
      "step": 5660
    },
    {
      "epoch": 0.48382967830019624,
      "grad_norm": 0.5403027534484863,
      "learning_rate": 4.758085160849902e-05,
      "loss": 0.0047,
      "step": 5670
    },
    {
      "epoch": 0.4846829934294735,
      "grad_norm": 0.10012221336364746,
      "learning_rate": 4.7576585032852634e-05,
      "loss": 0.0046,
      "step": 5680
    },
    {
      "epoch": 0.48553630855875074,
      "grad_norm": 0.348355770111084,
      "learning_rate": 4.757231845720625e-05,
      "loss": 0.004,
      "step": 5690
    },
    {
      "epoch": 0.48638962368802796,
      "grad_norm": 0.32510948181152344,
      "learning_rate": 4.756805188155986e-05,
      "loss": 0.0041,
      "step": 5700
    },
    {
      "epoch": 0.48724293881730524,
      "grad_norm": 0.21076013147830963,
      "learning_rate": 4.7563785305913476e-05,
      "loss": 0.0048,
      "step": 5710
    },
    {
      "epoch": 0.48809625394658246,
      "grad_norm": 0.280565083026886,
      "learning_rate": 4.755951873026709e-05,
      "loss": 0.004,
      "step": 5720
    },
    {
      "epoch": 0.48894956907585974,
      "grad_norm": 0.5043237805366516,
      "learning_rate": 4.7555252154620705e-05,
      "loss": 0.0037,
      "step": 5730
    },
    {
      "epoch": 0.48980288420513696,
      "grad_norm": 0.1859724521636963,
      "learning_rate": 4.755098557897432e-05,
      "loss": 0.0044,
      "step": 5740
    },
    {
      "epoch": 0.4906561993344142,
      "grad_norm": 0.1482531875371933,
      "learning_rate": 4.7546719003327933e-05,
      "loss": 0.004,
      "step": 5750
    },
    {
      "epoch": 0.49150951446369145,
      "grad_norm": 0.33867570757865906,
      "learning_rate": 4.754245242768154e-05,
      "loss": 0.0048,
      "step": 5760
    },
    {
      "epoch": 0.4923628295929687,
      "grad_norm": 0.613248348236084,
      "learning_rate": 4.753818585203516e-05,
      "loss": 0.0041,
      "step": 5770
    },
    {
      "epoch": 0.49321614472224595,
      "grad_norm": 0.12497621774673462,
      "learning_rate": 4.753391927638877e-05,
      "loss": 0.0051,
      "step": 5780
    },
    {
      "epoch": 0.4940694598515232,
      "grad_norm": 0.7362649440765381,
      "learning_rate": 4.752965270074239e-05,
      "loss": 0.0044,
      "step": 5790
    },
    {
      "epoch": 0.4949227749808004,
      "grad_norm": 0.14088933169841766,
      "learning_rate": 4.7525386125096e-05,
      "loss": 0.0046,
      "step": 5800
    },
    {
      "epoch": 0.49577609011007767,
      "grad_norm": 0.25071981549263,
      "learning_rate": 4.752111954944962e-05,
      "loss": 0.0048,
      "step": 5810
    },
    {
      "epoch": 0.4966294052393549,
      "grad_norm": 0.0658014640212059,
      "learning_rate": 4.7516852973803226e-05,
      "loss": 0.0049,
      "step": 5820
    },
    {
      "epoch": 0.4974827203686321,
      "grad_norm": 0.07674822956323624,
      "learning_rate": 4.751258639815685e-05,
      "loss": 0.0041,
      "step": 5830
    },
    {
      "epoch": 0.4983360354979094,
      "grad_norm": 0.060499947518110275,
      "learning_rate": 4.7508319822510455e-05,
      "loss": 0.0047,
      "step": 5840
    },
    {
      "epoch": 0.4991893506271866,
      "grad_norm": 0.050518352538347244,
      "learning_rate": 4.750405324686407e-05,
      "loss": 0.0047,
      "step": 5850
    },
    {
      "epoch": 0.5000426657564638,
      "grad_norm": 0.29700541496276855,
      "learning_rate": 4.749978667121768e-05,
      "loss": 0.0032,
      "step": 5860
    },
    {
      "epoch": 0.500895980885741,
      "grad_norm": 0.08132275938987732,
      "learning_rate": 4.74955200955713e-05,
      "loss": 0.0048,
      "step": 5870
    },
    {
      "epoch": 0.5017492960150184,
      "grad_norm": 0.17034520208835602,
      "learning_rate": 4.749125351992491e-05,
      "loss": 0.0035,
      "step": 5880
    },
    {
      "epoch": 0.5026026111442956,
      "grad_norm": 0.02347102388739586,
      "learning_rate": 4.748698694427852e-05,
      "loss": 0.0038,
      "step": 5890
    },
    {
      "epoch": 0.5034559262735728,
      "grad_norm": 0.22717586159706116,
      "learning_rate": 4.748272036863214e-05,
      "loss": 0.0038,
      "step": 5900
    },
    {
      "epoch": 0.50430924140285,
      "grad_norm": 0.2225479632616043,
      "learning_rate": 4.747845379298575e-05,
      "loss": 0.004,
      "step": 5910
    },
    {
      "epoch": 0.5051625565321273,
      "grad_norm": 0.24435895681381226,
      "learning_rate": 4.747418721733937e-05,
      "loss": 0.0042,
      "step": 5920
    },
    {
      "epoch": 0.5060158716614046,
      "grad_norm": 0.3027813136577606,
      "learning_rate": 4.7469920641692976e-05,
      "loss": 0.0045,
      "step": 5930
    },
    {
      "epoch": 0.5068691867906818,
      "grad_norm": 0.06016582250595093,
      "learning_rate": 4.74656540660466e-05,
      "loss": 0.0052,
      "step": 5940
    },
    {
      "epoch": 0.507722501919959,
      "grad_norm": 0.4505399465560913,
      "learning_rate": 4.7461387490400205e-05,
      "loss": 0.0037,
      "step": 5950
    },
    {
      "epoch": 0.5085758170492363,
      "grad_norm": 0.23265723884105682,
      "learning_rate": 4.745712091475382e-05,
      "loss": 0.0043,
      "step": 5960
    },
    {
      "epoch": 0.5094291321785135,
      "grad_norm": 0.08335218578577042,
      "learning_rate": 4.745285433910743e-05,
      "loss": 0.003,
      "step": 5970
    },
    {
      "epoch": 0.5102824473077908,
      "grad_norm": 0.15914684534072876,
      "learning_rate": 4.744858776346105e-05,
      "loss": 0.0043,
      "step": 5980
    },
    {
      "epoch": 0.511135762437068,
      "grad_norm": 0.046771567314863205,
      "learning_rate": 4.744432118781466e-05,
      "loss": 0.0025,
      "step": 5990
    },
    {
      "epoch": 0.5119890775663453,
      "grad_norm": 0.17324984073638916,
      "learning_rate": 4.7440054612168276e-05,
      "loss": 0.0037,
      "step": 6000
    },
    {
      "epoch": 0.5128423926956225,
      "grad_norm": 0.4206407964229584,
      "learning_rate": 4.743578803652189e-05,
      "loss": 0.0042,
      "step": 6010
    },
    {
      "epoch": 0.5136957078248997,
      "grad_norm": 0.17154479026794434,
      "learning_rate": 4.7431521460875504e-05,
      "loss": 0.0041,
      "step": 6020
    },
    {
      "epoch": 0.5145490229541769,
      "grad_norm": 0.10122576355934143,
      "learning_rate": 4.742725488522912e-05,
      "loss": 0.0044,
      "step": 6030
    },
    {
      "epoch": 0.5154023380834543,
      "grad_norm": 0.13222865760326385,
      "learning_rate": 4.742298830958273e-05,
      "loss": 0.0035,
      "step": 6040
    },
    {
      "epoch": 0.5162556532127315,
      "grad_norm": 0.1458231508731842,
      "learning_rate": 4.741872173393635e-05,
      "loss": 0.0036,
      "step": 6050
    },
    {
      "epoch": 0.5171089683420087,
      "grad_norm": 0.15124154090881348,
      "learning_rate": 4.741445515828996e-05,
      "loss": 0.0054,
      "step": 6060
    },
    {
      "epoch": 0.5179622834712859,
      "grad_norm": 0.2260625958442688,
      "learning_rate": 4.741018858264357e-05,
      "loss": 0.0048,
      "step": 6070
    },
    {
      "epoch": 0.5188155986005631,
      "grad_norm": 0.25029852986335754,
      "learning_rate": 4.740592200699719e-05,
      "loss": 0.0038,
      "step": 6080
    },
    {
      "epoch": 0.5196689137298405,
      "grad_norm": 0.45776602625846863,
      "learning_rate": 4.74016554313508e-05,
      "loss": 0.0036,
      "step": 6090
    },
    {
      "epoch": 0.5205222288591177,
      "grad_norm": 0.41241976618766785,
      "learning_rate": 4.739738885570442e-05,
      "loss": 0.0038,
      "step": 6100
    },
    {
      "epoch": 0.5213755439883949,
      "grad_norm": 0.1187262013554573,
      "learning_rate": 4.7393122280058026e-05,
      "loss": 0.0044,
      "step": 6110
    },
    {
      "epoch": 0.5222288591176721,
      "grad_norm": 0.06380145251750946,
      "learning_rate": 4.738885570441164e-05,
      "loss": 0.0034,
      "step": 6120
    },
    {
      "epoch": 0.5230821742469494,
      "grad_norm": 0.26143667101860046,
      "learning_rate": 4.7384589128765254e-05,
      "loss": 0.0036,
      "step": 6130
    },
    {
      "epoch": 0.5239354893762267,
      "grad_norm": 0.19015775620937347,
      "learning_rate": 4.738032255311887e-05,
      "loss": 0.0047,
      "step": 6140
    },
    {
      "epoch": 0.5247888045055039,
      "grad_norm": 0.08350811153650284,
      "learning_rate": 4.737605597747248e-05,
      "loss": 0.0044,
      "step": 6150
    },
    {
      "epoch": 0.5256421196347811,
      "grad_norm": 0.35934704542160034,
      "learning_rate": 4.73717894018261e-05,
      "loss": 0.0049,
      "step": 6160
    },
    {
      "epoch": 0.5264954347640584,
      "grad_norm": 0.16917718946933746,
      "learning_rate": 4.736752282617971e-05,
      "loss": 0.0049,
      "step": 6170
    },
    {
      "epoch": 0.5273487498933356,
      "grad_norm": 0.540742039680481,
      "learning_rate": 4.7363256250533325e-05,
      "loss": 0.0051,
      "step": 6180
    },
    {
      "epoch": 0.5282020650226128,
      "grad_norm": 0.43878641724586487,
      "learning_rate": 4.735898967488694e-05,
      "loss": 0.004,
      "step": 6190
    },
    {
      "epoch": 0.5290553801518901,
      "grad_norm": 0.16877692937850952,
      "learning_rate": 4.735472309924055e-05,
      "loss": 0.0039,
      "step": 6200
    },
    {
      "epoch": 0.5299086952811674,
      "grad_norm": 0.029533570632338524,
      "learning_rate": 4.735045652359417e-05,
      "loss": 0.0049,
      "step": 6210
    },
    {
      "epoch": 0.5307620104104446,
      "grad_norm": 0.1347476840019226,
      "learning_rate": 4.7346189947947776e-05,
      "loss": 0.0037,
      "step": 6220
    },
    {
      "epoch": 0.5316153255397218,
      "grad_norm": 0.37958428263664246,
      "learning_rate": 4.73419233723014e-05,
      "loss": 0.0039,
      "step": 6230
    },
    {
      "epoch": 0.532468640668999,
      "grad_norm": 0.30777496099472046,
      "learning_rate": 4.7337656796655004e-05,
      "loss": 0.0042,
      "step": 6240
    },
    {
      "epoch": 0.5333219557982763,
      "grad_norm": 0.283246248960495,
      "learning_rate": 4.7333390221008625e-05,
      "loss": 0.0058,
      "step": 6250
    },
    {
      "epoch": 0.5341752709275536,
      "grad_norm": 0.04751606658101082,
      "learning_rate": 4.732912364536223e-05,
      "loss": 0.0044,
      "step": 6260
    },
    {
      "epoch": 0.5350285860568308,
      "grad_norm": 0.06332068145275116,
      "learning_rate": 4.732485706971585e-05,
      "loss": 0.0043,
      "step": 6270
    },
    {
      "epoch": 0.535881901186108,
      "grad_norm": 0.18376809358596802,
      "learning_rate": 4.732059049406946e-05,
      "loss": 0.0047,
      "step": 6280
    },
    {
      "epoch": 0.5367352163153852,
      "grad_norm": 0.17563970386981964,
      "learning_rate": 4.7316323918423075e-05,
      "loss": 0.0045,
      "step": 6290
    },
    {
      "epoch": 0.5375885314446626,
      "grad_norm": 0.1689177006483078,
      "learning_rate": 4.731205734277669e-05,
      "loss": 0.0035,
      "step": 6300
    },
    {
      "epoch": 0.5384418465739398,
      "grad_norm": 0.07878007739782333,
      "learning_rate": 4.7307790767130304e-05,
      "loss": 0.0043,
      "step": 6310
    },
    {
      "epoch": 0.539295161703217,
      "grad_norm": 0.1880618780851364,
      "learning_rate": 4.730352419148392e-05,
      "loss": 0.0026,
      "step": 6320
    },
    {
      "epoch": 0.5401484768324942,
      "grad_norm": 0.2345394641160965,
      "learning_rate": 4.729925761583753e-05,
      "loss": 0.0032,
      "step": 6330
    },
    {
      "epoch": 0.5410017919617714,
      "grad_norm": 0.030957920476794243,
      "learning_rate": 4.7294991040191147e-05,
      "loss": 0.0036,
      "step": 6340
    },
    {
      "epoch": 0.5418551070910487,
      "grad_norm": 0.040300555527210236,
      "learning_rate": 4.729072446454476e-05,
      "loss": 0.0048,
      "step": 6350
    },
    {
      "epoch": 0.542708422220326,
      "grad_norm": 0.23226486146450043,
      "learning_rate": 4.7286457888898375e-05,
      "loss": 0.005,
      "step": 6360
    },
    {
      "epoch": 0.5435617373496032,
      "grad_norm": 0.09602338075637817,
      "learning_rate": 4.728219131325199e-05,
      "loss": 0.0036,
      "step": 6370
    },
    {
      "epoch": 0.5444150524788804,
      "grad_norm": 0.1849222034215927,
      "learning_rate": 4.72779247376056e-05,
      "loss": 0.0035,
      "step": 6380
    },
    {
      "epoch": 0.5452683676081577,
      "grad_norm": 0.04368725046515465,
      "learning_rate": 4.727365816195921e-05,
      "loss": 0.0036,
      "step": 6390
    },
    {
      "epoch": 0.5461216827374349,
      "grad_norm": 0.044458676129579544,
      "learning_rate": 4.7269391586312825e-05,
      "loss": 0.004,
      "step": 6400
    },
    {
      "epoch": 0.5469749978667122,
      "grad_norm": 0.13967688381671906,
      "learning_rate": 4.726512501066644e-05,
      "loss": 0.0031,
      "step": 6410
    },
    {
      "epoch": 0.5478283129959894,
      "grad_norm": 0.3804903030395508,
      "learning_rate": 4.7260858435020054e-05,
      "loss": 0.0039,
      "step": 6420
    },
    {
      "epoch": 0.5486816281252667,
      "grad_norm": 0.40735775232315063,
      "learning_rate": 4.725659185937367e-05,
      "loss": 0.0043,
      "step": 6430
    },
    {
      "epoch": 0.5495349432545439,
      "grad_norm": 0.25087130069732666,
      "learning_rate": 4.725232528372728e-05,
      "loss": 0.0043,
      "step": 6440
    },
    {
      "epoch": 0.5503882583838211,
      "grad_norm": 0.11545318365097046,
      "learning_rate": 4.7248058708080896e-05,
      "loss": 0.0054,
      "step": 6450
    },
    {
      "epoch": 0.5512415735130984,
      "grad_norm": 0.07574789971113205,
      "learning_rate": 4.724379213243451e-05,
      "loss": 0.0051,
      "step": 6460
    },
    {
      "epoch": 0.5520948886423757,
      "grad_norm": 0.04849560186266899,
      "learning_rate": 4.7239525556788125e-05,
      "loss": 0.0048,
      "step": 6470
    },
    {
      "epoch": 0.5529482037716529,
      "grad_norm": 0.05962982028722763,
      "learning_rate": 4.723525898114174e-05,
      "loss": 0.0031,
      "step": 6480
    },
    {
      "epoch": 0.5538015189009301,
      "grad_norm": 0.05719718709588051,
      "learning_rate": 4.7230992405495353e-05,
      "loss": 0.006,
      "step": 6490
    },
    {
      "epoch": 0.5546548340302073,
      "grad_norm": 0.08081202208995819,
      "learning_rate": 4.722672582984897e-05,
      "loss": 0.0038,
      "step": 6500
    },
    {
      "epoch": 0.5555081491594845,
      "grad_norm": 0.0994424894452095,
      "learning_rate": 4.7222459254202575e-05,
      "loss": 0.0047,
      "step": 6510
    },
    {
      "epoch": 0.5563614642887619,
      "grad_norm": 0.15781570971012115,
      "learning_rate": 4.7218192678556196e-05,
      "loss": 0.0045,
      "step": 6520
    },
    {
      "epoch": 0.5572147794180391,
      "grad_norm": 0.22698509693145752,
      "learning_rate": 4.7213926102909804e-05,
      "loss": 0.0038,
      "step": 6530
    },
    {
      "epoch": 0.5580680945473163,
      "grad_norm": 0.23631131649017334,
      "learning_rate": 4.7209659527263425e-05,
      "loss": 0.0043,
      "step": 6540
    },
    {
      "epoch": 0.5589214096765935,
      "grad_norm": 0.15513180196285248,
      "learning_rate": 4.720539295161703e-05,
      "loss": 0.0039,
      "step": 6550
    },
    {
      "epoch": 0.5597747248058708,
      "grad_norm": 0.11882035434246063,
      "learning_rate": 4.720112637597065e-05,
      "loss": 0.0039,
      "step": 6560
    },
    {
      "epoch": 0.5606280399351481,
      "grad_norm": 0.2881661355495453,
      "learning_rate": 4.719685980032426e-05,
      "loss": 0.0035,
      "step": 6570
    },
    {
      "epoch": 0.5614813550644253,
      "grad_norm": 0.3336898982524872,
      "learning_rate": 4.7192593224677875e-05,
      "loss": 0.0034,
      "step": 6580
    },
    {
      "epoch": 0.5623346701937025,
      "grad_norm": 0.2773219347000122,
      "learning_rate": 4.718832664903149e-05,
      "loss": 0.0042,
      "step": 6590
    },
    {
      "epoch": 0.5631879853229798,
      "grad_norm": 0.30315202474594116,
      "learning_rate": 4.71840600733851e-05,
      "loss": 0.0036,
      "step": 6600
    },
    {
      "epoch": 0.564041300452257,
      "grad_norm": 0.04550611227750778,
      "learning_rate": 4.717979349773872e-05,
      "loss": 0.0034,
      "step": 6610
    },
    {
      "epoch": 0.5648946155815343,
      "grad_norm": 0.08701168745756149,
      "learning_rate": 4.717552692209233e-05,
      "loss": 0.0053,
      "step": 6620
    },
    {
      "epoch": 0.5657479307108115,
      "grad_norm": 0.09713093936443329,
      "learning_rate": 4.7171260346445946e-05,
      "loss": 0.004,
      "step": 6630
    },
    {
      "epoch": 0.5666012458400888,
      "grad_norm": 0.1489013433456421,
      "learning_rate": 4.716699377079956e-05,
      "loss": 0.0034,
      "step": 6640
    },
    {
      "epoch": 0.567454560969366,
      "grad_norm": 0.18136483430862427,
      "learning_rate": 4.7162727195153174e-05,
      "loss": 0.0034,
      "step": 6650
    },
    {
      "epoch": 0.5683078760986432,
      "grad_norm": 0.43739748001098633,
      "learning_rate": 4.715846061950678e-05,
      "loss": 0.0028,
      "step": 6660
    },
    {
      "epoch": 0.5691611912279205,
      "grad_norm": 0.28572139143943787,
      "learning_rate": 4.71541940438604e-05,
      "loss": 0.0035,
      "step": 6670
    },
    {
      "epoch": 0.5700145063571977,
      "grad_norm": 0.17035165429115295,
      "learning_rate": 4.714992746821401e-05,
      "loss": 0.0031,
      "step": 6680
    },
    {
      "epoch": 0.570867821486475,
      "grad_norm": 0.29924288392066956,
      "learning_rate": 4.7145660892567625e-05,
      "loss": 0.0035,
      "step": 6690
    },
    {
      "epoch": 0.5717211366157522,
      "grad_norm": 0.18784049153327942,
      "learning_rate": 4.714139431692124e-05,
      "loss": 0.0042,
      "step": 6700
    },
    {
      "epoch": 0.5725744517450294,
      "grad_norm": 0.034064359962940216,
      "learning_rate": 4.713712774127485e-05,
      "loss": 0.004,
      "step": 6710
    },
    {
      "epoch": 0.5734277668743066,
      "grad_norm": 0.260776162147522,
      "learning_rate": 4.713286116562847e-05,
      "loss": 0.0039,
      "step": 6720
    },
    {
      "epoch": 0.574281082003584,
      "grad_norm": 0.17153187096118927,
      "learning_rate": 4.712859458998208e-05,
      "loss": 0.0037,
      "step": 6730
    },
    {
      "epoch": 0.5751343971328612,
      "grad_norm": 0.48323318362236023,
      "learning_rate": 4.7124328014335696e-05,
      "loss": 0.0044,
      "step": 6740
    },
    {
      "epoch": 0.5759877122621384,
      "grad_norm": 0.20905999839305878,
      "learning_rate": 4.712006143868931e-05,
      "loss": 0.0037,
      "step": 6750
    },
    {
      "epoch": 0.5768410273914156,
      "grad_norm": 0.032951243221759796,
      "learning_rate": 4.7115794863042924e-05,
      "loss": 0.0029,
      "step": 6760
    },
    {
      "epoch": 0.5776943425206928,
      "grad_norm": 0.19362285733222961,
      "learning_rate": 4.711152828739654e-05,
      "loss": 0.0046,
      "step": 6770
    },
    {
      "epoch": 0.5785476576499702,
      "grad_norm": 0.33304673433303833,
      "learning_rate": 4.710726171175015e-05,
      "loss": 0.0043,
      "step": 6780
    },
    {
      "epoch": 0.5794009727792474,
      "grad_norm": 0.0989266037940979,
      "learning_rate": 4.710299513610377e-05,
      "loss": 0.0038,
      "step": 6790
    },
    {
      "epoch": 0.5802542879085246,
      "grad_norm": 0.14090915024280548,
      "learning_rate": 4.709872856045738e-05,
      "loss": 0.0041,
      "step": 6800
    },
    {
      "epoch": 0.5811076030378018,
      "grad_norm": 0.0794731006026268,
      "learning_rate": 4.7094461984810996e-05,
      "loss": 0.0029,
      "step": 6810
    },
    {
      "epoch": 0.5819609181670791,
      "grad_norm": 0.4311334490776062,
      "learning_rate": 4.70901954091646e-05,
      "loss": 0.0043,
      "step": 6820
    },
    {
      "epoch": 0.5828142332963564,
      "grad_norm": 0.6180003881454468,
      "learning_rate": 4.7085928833518224e-05,
      "loss": 0.0045,
      "step": 6830
    },
    {
      "epoch": 0.5836675484256336,
      "grad_norm": 0.12616761028766632,
      "learning_rate": 4.708166225787183e-05,
      "loss": 0.0042,
      "step": 6840
    },
    {
      "epoch": 0.5845208635549108,
      "grad_norm": 0.7111261487007141,
      "learning_rate": 4.707739568222545e-05,
      "loss": 0.0043,
      "step": 6850
    },
    {
      "epoch": 0.5853741786841881,
      "grad_norm": 0.6316601037979126,
      "learning_rate": 4.707312910657906e-05,
      "loss": 0.0027,
      "step": 6860
    },
    {
      "epoch": 0.5862274938134653,
      "grad_norm": 0.12662336230278015,
      "learning_rate": 4.706886253093268e-05,
      "loss": 0.0035,
      "step": 6870
    },
    {
      "epoch": 0.5870808089427425,
      "grad_norm": 0.5408737659454346,
      "learning_rate": 4.706459595528629e-05,
      "loss": 0.004,
      "step": 6880
    },
    {
      "epoch": 0.5879341240720198,
      "grad_norm": 0.5559699535369873,
      "learning_rate": 4.70603293796399e-05,
      "loss": 0.0034,
      "step": 6890
    },
    {
      "epoch": 0.5887874392012971,
      "grad_norm": 0.15361297130584717,
      "learning_rate": 4.705606280399352e-05,
      "loss": 0.0033,
      "step": 6900
    },
    {
      "epoch": 0.5896407543305743,
      "grad_norm": 0.04616882652044296,
      "learning_rate": 4.705179622834713e-05,
      "loss": 0.0034,
      "step": 6910
    },
    {
      "epoch": 0.5904940694598515,
      "grad_norm": 0.042628176510334015,
      "learning_rate": 4.7047529652700745e-05,
      "loss": 0.0031,
      "step": 6920
    },
    {
      "epoch": 0.5913473845891287,
      "grad_norm": 0.2592240571975708,
      "learning_rate": 4.704326307705435e-05,
      "loss": 0.0033,
      "step": 6930
    },
    {
      "epoch": 0.592200699718406,
      "grad_norm": 0.4547094404697418,
      "learning_rate": 4.7038996501407974e-05,
      "loss": 0.0046,
      "step": 6940
    },
    {
      "epoch": 0.5930540148476833,
      "grad_norm": 0.38910314440727234,
      "learning_rate": 4.703472992576158e-05,
      "loss": 0.0035,
      "step": 6950
    },
    {
      "epoch": 0.5939073299769605,
      "grad_norm": 0.33873364329338074,
      "learning_rate": 4.70304633501152e-05,
      "loss": 0.0044,
      "step": 6960
    },
    {
      "epoch": 0.5947606451062377,
      "grad_norm": 0.42478641867637634,
      "learning_rate": 4.702619677446881e-05,
      "loss": 0.0038,
      "step": 6970
    },
    {
      "epoch": 0.5956139602355149,
      "grad_norm": 0.24073439836502075,
      "learning_rate": 4.702193019882243e-05,
      "loss": 0.004,
      "step": 6980
    },
    {
      "epoch": 0.5964672753647923,
      "grad_norm": 0.3006742298603058,
      "learning_rate": 4.701766362317604e-05,
      "loss": 0.0046,
      "step": 6990
    },
    {
      "epoch": 0.5973205904940695,
      "grad_norm": 0.12627895176410675,
      "learning_rate": 4.701339704752965e-05,
      "loss": 0.004,
      "step": 7000
    },
    {
      "epoch": 0.5981739056233467,
      "grad_norm": 0.16774630546569824,
      "learning_rate": 4.700913047188327e-05,
      "loss": 0.0036,
      "step": 7010
    },
    {
      "epoch": 0.5990272207526239,
      "grad_norm": 0.16366828978061676,
      "learning_rate": 4.700486389623688e-05,
      "loss": 0.004,
      "step": 7020
    },
    {
      "epoch": 0.5998805358819012,
      "grad_norm": 0.22311975061893463,
      "learning_rate": 4.7000597320590495e-05,
      "loss": 0.0043,
      "step": 7030
    },
    {
      "epoch": 0.6007338510111784,
      "grad_norm": 0.08040177822113037,
      "learning_rate": 4.699633074494411e-05,
      "loss": 0.005,
      "step": 7040
    },
    {
      "epoch": 0.6015871661404557,
      "grad_norm": 0.2634868621826172,
      "learning_rate": 4.6992064169297724e-05,
      "loss": 0.0036,
      "step": 7050
    },
    {
      "epoch": 0.6024404812697329,
      "grad_norm": 0.06594669073820114,
      "learning_rate": 4.698779759365134e-05,
      "loss": 0.0035,
      "step": 7060
    },
    {
      "epoch": 0.6032937963990102,
      "grad_norm": 0.23919546604156494,
      "learning_rate": 4.698353101800495e-05,
      "loss": 0.0035,
      "step": 7070
    },
    {
      "epoch": 0.6041471115282874,
      "grad_norm": 0.03203090652823448,
      "learning_rate": 4.6979264442358567e-05,
      "loss": 0.0033,
      "step": 7080
    },
    {
      "epoch": 0.6050004266575646,
      "grad_norm": 0.33398786187171936,
      "learning_rate": 4.697499786671218e-05,
      "loss": 0.0051,
      "step": 7090
    },
    {
      "epoch": 0.6058537417868419,
      "grad_norm": 0.34971436858177185,
      "learning_rate": 4.6970731291065795e-05,
      "loss": 0.003,
      "step": 7100
    },
    {
      "epoch": 0.6067070569161191,
      "grad_norm": 0.2195439636707306,
      "learning_rate": 4.696646471541941e-05,
      "loss": 0.0036,
      "step": 7110
    },
    {
      "epoch": 0.6075603720453964,
      "grad_norm": 0.11074738204479218,
      "learning_rate": 4.6962198139773023e-05,
      "loss": 0.0033,
      "step": 7120
    },
    {
      "epoch": 0.6084136871746736,
      "grad_norm": 0.47500622272491455,
      "learning_rate": 4.695793156412663e-05,
      "loss": 0.0035,
      "step": 7130
    },
    {
      "epoch": 0.6092670023039508,
      "grad_norm": 0.2503296136856079,
      "learning_rate": 4.695366498848025e-05,
      "loss": 0.0044,
      "step": 7140
    },
    {
      "epoch": 0.6101203174332281,
      "grad_norm": 0.02976655587553978,
      "learning_rate": 4.694939841283386e-05,
      "loss": 0.0034,
      "step": 7150
    },
    {
      "epoch": 0.6109736325625054,
      "grad_norm": 0.1245943084359169,
      "learning_rate": 4.694513183718748e-05,
      "loss": 0.0047,
      "step": 7160
    },
    {
      "epoch": 0.6118269476917826,
      "grad_norm": 0.47849661111831665,
      "learning_rate": 4.694086526154109e-05,
      "loss": 0.0045,
      "step": 7170
    },
    {
      "epoch": 0.6126802628210598,
      "grad_norm": 0.18754889070987701,
      "learning_rate": 4.69365986858947e-05,
      "loss": 0.0036,
      "step": 7180
    },
    {
      "epoch": 0.613533577950337,
      "grad_norm": 0.1537903994321823,
      "learning_rate": 4.6932332110248316e-05,
      "loss": 0.0045,
      "step": 7190
    },
    {
      "epoch": 0.6143868930796142,
      "grad_norm": 0.2235882580280304,
      "learning_rate": 4.692806553460193e-05,
      "loss": 0.0037,
      "step": 7200
    },
    {
      "epoch": 0.6152402082088916,
      "grad_norm": 0.11296848207712173,
      "learning_rate": 4.6923798958955545e-05,
      "loss": 0.0032,
      "step": 7210
    },
    {
      "epoch": 0.6160935233381688,
      "grad_norm": 0.279791921377182,
      "learning_rate": 4.691953238330916e-05,
      "loss": 0.0035,
      "step": 7220
    },
    {
      "epoch": 0.616946838467446,
      "grad_norm": 0.07702804356813431,
      "learning_rate": 4.691526580766277e-05,
      "loss": 0.0041,
      "step": 7230
    },
    {
      "epoch": 0.6178001535967232,
      "grad_norm": 0.16769631206989288,
      "learning_rate": 4.691099923201638e-05,
      "loss": 0.0039,
      "step": 7240
    },
    {
      "epoch": 0.6186534687260005,
      "grad_norm": 0.2623869776725769,
      "learning_rate": 4.690673265637e-05,
      "loss": 0.0043,
      "step": 7250
    },
    {
      "epoch": 0.6195067838552778,
      "grad_norm": 0.4750473201274872,
      "learning_rate": 4.690246608072361e-05,
      "loss": 0.0044,
      "step": 7260
    },
    {
      "epoch": 0.620360098984555,
      "grad_norm": 0.07277020066976547,
      "learning_rate": 4.689819950507723e-05,
      "loss": 0.0042,
      "step": 7270
    },
    {
      "epoch": 0.6212134141138322,
      "grad_norm": 0.2664332687854767,
      "learning_rate": 4.689393292943084e-05,
      "loss": 0.0034,
      "step": 7280
    },
    {
      "epoch": 0.6220667292431095,
      "grad_norm": 0.09664677083492279,
      "learning_rate": 4.688966635378446e-05,
      "loss": 0.0045,
      "step": 7290
    },
    {
      "epoch": 0.6229200443723867,
      "grad_norm": 0.23959244787693024,
      "learning_rate": 4.6885399778138066e-05,
      "loss": 0.0039,
      "step": 7300
    },
    {
      "epoch": 0.623773359501664,
      "grad_norm": 0.19030797481536865,
      "learning_rate": 4.688113320249168e-05,
      "loss": 0.0039,
      "step": 7310
    },
    {
      "epoch": 0.6246266746309412,
      "grad_norm": 0.062347203493118286,
      "learning_rate": 4.6876866626845295e-05,
      "loss": 0.004,
      "step": 7320
    },
    {
      "epoch": 0.6254799897602185,
      "grad_norm": 0.3839757442474365,
      "learning_rate": 4.687260005119891e-05,
      "loss": 0.0041,
      "step": 7330
    },
    {
      "epoch": 0.6263333048894957,
      "grad_norm": 0.26602718234062195,
      "learning_rate": 4.686833347555252e-05,
      "loss": 0.0031,
      "step": 7340
    },
    {
      "epoch": 0.6271866200187729,
      "grad_norm": 0.08641517162322998,
      "learning_rate": 4.686406689990614e-05,
      "loss": 0.0036,
      "step": 7350
    },
    {
      "epoch": 0.6280399351480501,
      "grad_norm": 0.189180389046669,
      "learning_rate": 4.685980032425975e-05,
      "loss": 0.0038,
      "step": 7360
    },
    {
      "epoch": 0.6288932502773275,
      "grad_norm": 0.26682785153388977,
      "learning_rate": 4.6855533748613366e-05,
      "loss": 0.0039,
      "step": 7370
    },
    {
      "epoch": 0.6297465654066047,
      "grad_norm": 0.13408660888671875,
      "learning_rate": 4.685126717296698e-05,
      "loss": 0.0039,
      "step": 7380
    },
    {
      "epoch": 0.6305998805358819,
      "grad_norm": 0.052468571811914444,
      "learning_rate": 4.6847000597320594e-05,
      "loss": 0.0035,
      "step": 7390
    },
    {
      "epoch": 0.6314531956651591,
      "grad_norm": 0.4306472837924957,
      "learning_rate": 4.684273402167421e-05,
      "loss": 0.0026,
      "step": 7400
    },
    {
      "epoch": 0.6323065107944363,
      "grad_norm": 0.3059605062007904,
      "learning_rate": 4.683846744602782e-05,
      "loss": 0.0044,
      "step": 7410
    },
    {
      "epoch": 0.6331598259237137,
      "grad_norm": 0.17698031663894653,
      "learning_rate": 4.683420087038144e-05,
      "loss": 0.0032,
      "step": 7420
    },
    {
      "epoch": 0.6340131410529909,
      "grad_norm": 0.3816307783126831,
      "learning_rate": 4.682993429473505e-05,
      "loss": 0.0042,
      "step": 7430
    },
    {
      "epoch": 0.6348664561822681,
      "grad_norm": 0.15612125396728516,
      "learning_rate": 4.682566771908866e-05,
      "loss": 0.0041,
      "step": 7440
    },
    {
      "epoch": 0.6357197713115453,
      "grad_norm": 0.3723587691783905,
      "learning_rate": 4.682140114344227e-05,
      "loss": 0.0038,
      "step": 7450
    },
    {
      "epoch": 0.6365730864408226,
      "grad_norm": 0.3527146279811859,
      "learning_rate": 4.681713456779589e-05,
      "loss": 0.0052,
      "step": 7460
    },
    {
      "epoch": 0.6374264015700999,
      "grad_norm": 0.39889079332351685,
      "learning_rate": 4.68128679921495e-05,
      "loss": 0.0031,
      "step": 7470
    },
    {
      "epoch": 0.6382797166993771,
      "grad_norm": 0.3248104751110077,
      "learning_rate": 4.6808601416503116e-05,
      "loss": 0.0027,
      "step": 7480
    },
    {
      "epoch": 0.6391330318286543,
      "grad_norm": 0.06373067945241928,
      "learning_rate": 4.680433484085673e-05,
      "loss": 0.0031,
      "step": 7490
    },
    {
      "epoch": 0.6399863469579316,
      "grad_norm": 0.11955729871988297,
      "learning_rate": 4.6800068265210344e-05,
      "loss": 0.0032,
      "step": 7500
    },
    {
      "epoch": 0.6408396620872088,
      "grad_norm": 0.059795308858156204,
      "learning_rate": 4.679580168956396e-05,
      "loss": 0.0046,
      "step": 7510
    },
    {
      "epoch": 0.641692977216486,
      "grad_norm": 0.10804817825555801,
      "learning_rate": 4.679153511391757e-05,
      "loss": 0.0031,
      "step": 7520
    },
    {
      "epoch": 0.6425462923457633,
      "grad_norm": 0.1427420973777771,
      "learning_rate": 4.678726853827119e-05,
      "loss": 0.0042,
      "step": 7530
    },
    {
      "epoch": 0.6433996074750405,
      "grad_norm": 0.17192025482654572,
      "learning_rate": 4.67830019626248e-05,
      "loss": 0.0032,
      "step": 7540
    },
    {
      "epoch": 0.6442529226043178,
      "grad_norm": 0.09313280135393143,
      "learning_rate": 4.677873538697841e-05,
      "loss": 0.0039,
      "step": 7550
    },
    {
      "epoch": 0.645106237733595,
      "grad_norm": 0.21566785871982574,
      "learning_rate": 4.677446881133203e-05,
      "loss": 0.004,
      "step": 7560
    },
    {
      "epoch": 0.6459595528628722,
      "grad_norm": 0.4246355891227722,
      "learning_rate": 4.677020223568564e-05,
      "loss": 0.004,
      "step": 7570
    },
    {
      "epoch": 0.6468128679921495,
      "grad_norm": 0.21121545135974884,
      "learning_rate": 4.676593566003926e-05,
      "loss": 0.0038,
      "step": 7580
    },
    {
      "epoch": 0.6476661831214268,
      "grad_norm": 0.151554673910141,
      "learning_rate": 4.6761669084392866e-05,
      "loss": 0.0042,
      "step": 7590
    },
    {
      "epoch": 0.648519498250704,
      "grad_norm": 0.13378846645355225,
      "learning_rate": 4.675740250874649e-05,
      "loss": 0.0027,
      "step": 7600
    },
    {
      "epoch": 0.6493728133799812,
      "grad_norm": 0.2772199809551239,
      "learning_rate": 4.6753135933100094e-05,
      "loss": 0.0043,
      "step": 7610
    },
    {
      "epoch": 0.6502261285092584,
      "grad_norm": 0.05528172478079796,
      "learning_rate": 4.674886935745371e-05,
      "loss": 0.0036,
      "step": 7620
    },
    {
      "epoch": 0.6510794436385358,
      "grad_norm": 0.3923366069793701,
      "learning_rate": 4.674460278180732e-05,
      "loss": 0.004,
      "step": 7630
    },
    {
      "epoch": 0.651932758767813,
      "grad_norm": 0.03394687920808792,
      "learning_rate": 4.674033620616094e-05,
      "loss": 0.0037,
      "step": 7640
    },
    {
      "epoch": 0.6527860738970902,
      "grad_norm": 0.15877431631088257,
      "learning_rate": 4.673606963051455e-05,
      "loss": 0.0042,
      "step": 7650
    },
    {
      "epoch": 0.6536393890263674,
      "grad_norm": 0.4904797375202179,
      "learning_rate": 4.6731803054868165e-05,
      "loss": 0.0045,
      "step": 7660
    },
    {
      "epoch": 0.6544927041556446,
      "grad_norm": 0.37532269954681396,
      "learning_rate": 4.672753647922178e-05,
      "loss": 0.0031,
      "step": 7670
    },
    {
      "epoch": 0.655346019284922,
      "grad_norm": 0.09669218957424164,
      "learning_rate": 4.6723269903575394e-05,
      "loss": 0.0042,
      "step": 7680
    },
    {
      "epoch": 0.6561993344141992,
      "grad_norm": 0.06336066871881485,
      "learning_rate": 4.671900332792901e-05,
      "loss": 0.004,
      "step": 7690
    },
    {
      "epoch": 0.6570526495434764,
      "grad_norm": 0.5592917203903198,
      "learning_rate": 4.671473675228262e-05,
      "loss": 0.0035,
      "step": 7700
    },
    {
      "epoch": 0.6579059646727536,
      "grad_norm": 0.04823474586009979,
      "learning_rate": 4.6710470176636237e-05,
      "loss": 0.0033,
      "step": 7710
    },
    {
      "epoch": 0.6587592798020309,
      "grad_norm": 0.0652700662612915,
      "learning_rate": 4.6706203600989844e-05,
      "loss": 0.0033,
      "step": 7720
    },
    {
      "epoch": 0.6596125949313081,
      "grad_norm": 0.04753413423895836,
      "learning_rate": 4.6701937025343465e-05,
      "loss": 0.0032,
      "step": 7730
    },
    {
      "epoch": 0.6604659100605854,
      "grad_norm": 0.09683039784431458,
      "learning_rate": 4.669767044969707e-05,
      "loss": 0.0039,
      "step": 7740
    },
    {
      "epoch": 0.6613192251898626,
      "grad_norm": 0.4980013966560364,
      "learning_rate": 4.669340387405069e-05,
      "loss": 0.0046,
      "step": 7750
    },
    {
      "epoch": 0.6621725403191399,
      "grad_norm": 0.1583588421344757,
      "learning_rate": 4.66891372984043e-05,
      "loss": 0.0042,
      "step": 7760
    },
    {
      "epoch": 0.6630258554484171,
      "grad_norm": 0.3340182602405548,
      "learning_rate": 4.6684870722757915e-05,
      "loss": 0.0041,
      "step": 7770
    },
    {
      "epoch": 0.6638791705776943,
      "grad_norm": 0.06445292383432388,
      "learning_rate": 4.668060414711153e-05,
      "loss": 0.0026,
      "step": 7780
    },
    {
      "epoch": 0.6647324857069716,
      "grad_norm": 0.07957354933023453,
      "learning_rate": 4.6676337571465144e-05,
      "loss": 0.003,
      "step": 7790
    },
    {
      "epoch": 0.6655858008362489,
      "grad_norm": 0.23762483894824982,
      "learning_rate": 4.667207099581876e-05,
      "loss": 0.0038,
      "step": 7800
    },
    {
      "epoch": 0.6664391159655261,
      "grad_norm": 0.026082808151841164,
      "learning_rate": 4.666780442017237e-05,
      "loss": 0.0041,
      "step": 7810
    },
    {
      "epoch": 0.6672924310948033,
      "grad_norm": 0.45422157645225525,
      "learning_rate": 4.6663537844525986e-05,
      "loss": 0.0032,
      "step": 7820
    },
    {
      "epoch": 0.6681457462240805,
      "grad_norm": 0.24277447164058685,
      "learning_rate": 4.66592712688796e-05,
      "loss": 0.005,
      "step": 7830
    },
    {
      "epoch": 0.6689990613533578,
      "grad_norm": 0.3043777644634247,
      "learning_rate": 4.6655004693233215e-05,
      "loss": 0.0037,
      "step": 7840
    },
    {
      "epoch": 0.6698523764826351,
      "grad_norm": 0.2287355214357376,
      "learning_rate": 4.665073811758683e-05,
      "loss": 0.0037,
      "step": 7850
    },
    {
      "epoch": 0.6707056916119123,
      "grad_norm": 0.46495896577835083,
      "learning_rate": 4.664647154194044e-05,
      "loss": 0.0032,
      "step": 7860
    },
    {
      "epoch": 0.6715590067411895,
      "grad_norm": 0.1473894715309143,
      "learning_rate": 4.664220496629406e-05,
      "loss": 0.0044,
      "step": 7870
    },
    {
      "epoch": 0.6724123218704667,
      "grad_norm": 0.31909462809562683,
      "learning_rate": 4.6637938390647665e-05,
      "loss": 0.0036,
      "step": 7880
    },
    {
      "epoch": 0.673265636999744,
      "grad_norm": 0.36967915296554565,
      "learning_rate": 4.6633671815001286e-05,
      "loss": 0.0042,
      "step": 7890
    },
    {
      "epoch": 0.6741189521290213,
      "grad_norm": 0.14535968005657196,
      "learning_rate": 4.6629405239354894e-05,
      "loss": 0.0047,
      "step": 7900
    },
    {
      "epoch": 0.6749722672582985,
      "grad_norm": 0.027383260428905487,
      "learning_rate": 4.6625138663708515e-05,
      "loss": 0.004,
      "step": 7910
    },
    {
      "epoch": 0.6758255823875757,
      "grad_norm": 0.10209965705871582,
      "learning_rate": 4.662087208806212e-05,
      "loss": 0.0033,
      "step": 7920
    },
    {
      "epoch": 0.676678897516853,
      "grad_norm": 0.2835216224193573,
      "learning_rate": 4.6616605512415736e-05,
      "loss": 0.0035,
      "step": 7930
    },
    {
      "epoch": 0.6775322126461302,
      "grad_norm": 0.031649429351091385,
      "learning_rate": 4.661233893676935e-05,
      "loss": 0.0039,
      "step": 7940
    },
    {
      "epoch": 0.6783855277754075,
      "grad_norm": 0.028967155143618584,
      "learning_rate": 4.6608072361122965e-05,
      "loss": 0.0045,
      "step": 7950
    },
    {
      "epoch": 0.6792388429046847,
      "grad_norm": 0.2969885766506195,
      "learning_rate": 4.660380578547658e-05,
      "loss": 0.0033,
      "step": 7960
    },
    {
      "epoch": 0.680092158033962,
      "grad_norm": 0.6065492033958435,
      "learning_rate": 4.659953920983019e-05,
      "loss": 0.0031,
      "step": 7970
    },
    {
      "epoch": 0.6809454731632392,
      "grad_norm": 0.271342396736145,
      "learning_rate": 4.659527263418381e-05,
      "loss": 0.0034,
      "step": 7980
    },
    {
      "epoch": 0.6817987882925164,
      "grad_norm": 0.1745172142982483,
      "learning_rate": 4.6591006058537415e-05,
      "loss": 0.0043,
      "step": 7990
    },
    {
      "epoch": 0.6826521034217937,
      "grad_norm": 0.20614442229270935,
      "learning_rate": 4.6586739482891036e-05,
      "loss": 0.0042,
      "step": 8000
    },
    {
      "epoch": 0.6835054185510709,
      "grad_norm": 0.2512502372264862,
      "learning_rate": 4.6582472907244643e-05,
      "loss": 0.0048,
      "step": 8010
    },
    {
      "epoch": 0.6843587336803482,
      "grad_norm": 0.5080313682556152,
      "learning_rate": 4.6578206331598265e-05,
      "loss": 0.0045,
      "step": 8020
    },
    {
      "epoch": 0.6852120488096254,
      "grad_norm": 0.596216082572937,
      "learning_rate": 4.657393975595187e-05,
      "loss": 0.0039,
      "step": 8030
    },
    {
      "epoch": 0.6860653639389026,
      "grad_norm": 0.26205334067344666,
      "learning_rate": 4.656967318030549e-05,
      "loss": 0.0041,
      "step": 8040
    },
    {
      "epoch": 0.6869186790681798,
      "grad_norm": 0.10005249083042145,
      "learning_rate": 4.65654066046591e-05,
      "loss": 0.0033,
      "step": 8050
    },
    {
      "epoch": 0.6877719941974572,
      "grad_norm": 0.20904944837093353,
      "learning_rate": 4.6561140029012715e-05,
      "loss": 0.0046,
      "step": 8060
    },
    {
      "epoch": 0.6886253093267344,
      "grad_norm": 0.37677812576293945,
      "learning_rate": 4.655687345336633e-05,
      "loss": 0.0035,
      "step": 8070
    },
    {
      "epoch": 0.6894786244560116,
      "grad_norm": 0.41817277669906616,
      "learning_rate": 4.655260687771994e-05,
      "loss": 0.003,
      "step": 8080
    },
    {
      "epoch": 0.6903319395852888,
      "grad_norm": 0.1557673215866089,
      "learning_rate": 4.654834030207356e-05,
      "loss": 0.0039,
      "step": 8090
    },
    {
      "epoch": 0.691185254714566,
      "grad_norm": 0.2584378123283386,
      "learning_rate": 4.654407372642717e-05,
      "loss": 0.0032,
      "step": 8100
    },
    {
      "epoch": 0.6920385698438434,
      "grad_norm": 0.2604772746562958,
      "learning_rate": 4.6539807150780786e-05,
      "loss": 0.0034,
      "step": 8110
    },
    {
      "epoch": 0.6928918849731206,
      "grad_norm": 0.21065299212932587,
      "learning_rate": 4.65355405751344e-05,
      "loss": 0.0037,
      "step": 8120
    },
    {
      "epoch": 0.6937452001023978,
      "grad_norm": 0.1517592817544937,
      "learning_rate": 4.6531273999488014e-05,
      "loss": 0.0039,
      "step": 8130
    },
    {
      "epoch": 0.694598515231675,
      "grad_norm": 0.08278079330921173,
      "learning_rate": 4.652700742384163e-05,
      "loss": 0.0038,
      "step": 8140
    },
    {
      "epoch": 0.6954518303609523,
      "grad_norm": 0.24177853763103485,
      "learning_rate": 4.652274084819524e-05,
      "loss": 0.0038,
      "step": 8150
    },
    {
      "epoch": 0.6963051454902296,
      "grad_norm": 0.07492062449455261,
      "learning_rate": 4.651847427254886e-05,
      "loss": 0.0039,
      "step": 8160
    },
    {
      "epoch": 0.6971584606195068,
      "grad_norm": 0.06399162113666534,
      "learning_rate": 4.6514207696902465e-05,
      "loss": 0.0038,
      "step": 8170
    },
    {
      "epoch": 0.698011775748784,
      "grad_norm": 0.262932151556015,
      "learning_rate": 4.6509941121256086e-05,
      "loss": 0.0044,
      "step": 8180
    },
    {
      "epoch": 0.6988650908780613,
      "grad_norm": 0.0470849834382534,
      "learning_rate": 4.650567454560969e-05,
      "loss": 0.0037,
      "step": 8190
    },
    {
      "epoch": 0.6997184060073385,
      "grad_norm": 0.4101414978504181,
      "learning_rate": 4.6501407969963314e-05,
      "loss": 0.0039,
      "step": 8200
    },
    {
      "epoch": 0.7005717211366157,
      "grad_norm": 0.3729339838027954,
      "learning_rate": 4.649714139431692e-05,
      "loss": 0.0035,
      "step": 8210
    },
    {
      "epoch": 0.701425036265893,
      "grad_norm": 0.2984303832054138,
      "learning_rate": 4.649287481867054e-05,
      "loss": 0.0033,
      "step": 8220
    },
    {
      "epoch": 0.7022783513951703,
      "grad_norm": 0.45553937554359436,
      "learning_rate": 4.648860824302415e-05,
      "loss": 0.0031,
      "step": 8230
    },
    {
      "epoch": 0.7031316665244475,
      "grad_norm": 0.3120640218257904,
      "learning_rate": 4.6484341667377764e-05,
      "loss": 0.0032,
      "step": 8240
    },
    {
      "epoch": 0.7039849816537247,
      "grad_norm": 0.4170812964439392,
      "learning_rate": 4.648007509173138e-05,
      "loss": 0.004,
      "step": 8250
    },
    {
      "epoch": 0.7048382967830019,
      "grad_norm": 0.022134611383080482,
      "learning_rate": 4.647580851608499e-05,
      "loss": 0.0036,
      "step": 8260
    },
    {
      "epoch": 0.7056916119122792,
      "grad_norm": 0.021270766854286194,
      "learning_rate": 4.647154194043861e-05,
      "loss": 0.0041,
      "step": 8270
    },
    {
      "epoch": 0.7065449270415565,
      "grad_norm": 0.09520629793405533,
      "learning_rate": 4.6467275364792214e-05,
      "loss": 0.0039,
      "step": 8280
    },
    {
      "epoch": 0.7073982421708337,
      "grad_norm": 0.28022676706314087,
      "learning_rate": 4.6463008789145835e-05,
      "loss": 0.0028,
      "step": 8290
    },
    {
      "epoch": 0.7082515573001109,
      "grad_norm": 0.22231045365333557,
      "learning_rate": 4.645874221349944e-05,
      "loss": 0.0033,
      "step": 8300
    },
    {
      "epoch": 0.7091048724293881,
      "grad_norm": 0.2439490109682083,
      "learning_rate": 4.6454475637853064e-05,
      "loss": 0.0026,
      "step": 8310
    },
    {
      "epoch": 0.7099581875586655,
      "grad_norm": 0.32170310616493225,
      "learning_rate": 4.645020906220667e-05,
      "loss": 0.0041,
      "step": 8320
    },
    {
      "epoch": 0.7108115026879427,
      "grad_norm": 0.3040536940097809,
      "learning_rate": 4.644594248656029e-05,
      "loss": 0.004,
      "step": 8330
    },
    {
      "epoch": 0.7116648178172199,
      "grad_norm": 0.2667374312877655,
      "learning_rate": 4.64416759109139e-05,
      "loss": 0.0037,
      "step": 8340
    },
    {
      "epoch": 0.7125181329464971,
      "grad_norm": 0.04776955395936966,
      "learning_rate": 4.643740933526752e-05,
      "loss": 0.0042,
      "step": 8350
    },
    {
      "epoch": 0.7133714480757744,
      "grad_norm": 0.1191667765378952,
      "learning_rate": 4.643314275962113e-05,
      "loss": 0.0031,
      "step": 8360
    },
    {
      "epoch": 0.7142247632050516,
      "grad_norm": 0.057019803673028946,
      "learning_rate": 4.642887618397474e-05,
      "loss": 0.0035,
      "step": 8370
    },
    {
      "epoch": 0.7150780783343289,
      "grad_norm": 0.3372303545475006,
      "learning_rate": 4.642460960832836e-05,
      "loss": 0.0029,
      "step": 8380
    },
    {
      "epoch": 0.7159313934636061,
      "grad_norm": 0.3351246416568756,
      "learning_rate": 4.642034303268197e-05,
      "loss": 0.0044,
      "step": 8390
    },
    {
      "epoch": 0.7167847085928833,
      "grad_norm": 0.14531494677066803,
      "learning_rate": 4.6416076457035585e-05,
      "loss": 0.0027,
      "step": 8400
    },
    {
      "epoch": 0.7176380237221606,
      "grad_norm": 0.3050929307937622,
      "learning_rate": 4.64118098813892e-05,
      "loss": 0.0041,
      "step": 8410
    },
    {
      "epoch": 0.7184913388514378,
      "grad_norm": 0.521757185459137,
      "learning_rate": 4.6407543305742814e-05,
      "loss": 0.0034,
      "step": 8420
    },
    {
      "epoch": 0.7193446539807151,
      "grad_norm": 0.24357527494430542,
      "learning_rate": 4.640327673009643e-05,
      "loss": 0.0027,
      "step": 8430
    },
    {
      "epoch": 0.7201979691099923,
      "grad_norm": 0.1805105060338974,
      "learning_rate": 4.639901015445004e-05,
      "loss": 0.0028,
      "step": 8440
    },
    {
      "epoch": 0.7210512842392696,
      "grad_norm": 0.08806339651346207,
      "learning_rate": 4.6394743578803657e-05,
      "loss": 0.0042,
      "step": 8450
    },
    {
      "epoch": 0.7219045993685468,
      "grad_norm": 0.22420582175254822,
      "learning_rate": 4.639047700315727e-05,
      "loss": 0.0038,
      "step": 8460
    },
    {
      "epoch": 0.722757914497824,
      "grad_norm": 0.27887213230133057,
      "learning_rate": 4.6386210427510885e-05,
      "loss": 0.0038,
      "step": 8470
    },
    {
      "epoch": 0.7236112296271013,
      "grad_norm": 0.4312970042228699,
      "learning_rate": 4.638194385186449e-05,
      "loss": 0.0028,
      "step": 8480
    },
    {
      "epoch": 0.7244645447563786,
      "grad_norm": 0.11203993111848831,
      "learning_rate": 4.6377677276218114e-05,
      "loss": 0.0032,
      "step": 8490
    },
    {
      "epoch": 0.7253178598856558,
      "grad_norm": 0.2454511523246765,
      "learning_rate": 4.637341070057172e-05,
      "loss": 0.0028,
      "step": 8500
    },
    {
      "epoch": 0.726171175014933,
      "grad_norm": 0.5161916017532349,
      "learning_rate": 4.6369144124925335e-05,
      "loss": 0.0029,
      "step": 8510
    },
    {
      "epoch": 0.7270244901442102,
      "grad_norm": 0.28439319133758545,
      "learning_rate": 4.636487754927895e-05,
      "loss": 0.0033,
      "step": 8520
    },
    {
      "epoch": 0.7278778052734874,
      "grad_norm": 0.3745151460170746,
      "learning_rate": 4.6360610973632564e-05,
      "loss": 0.0031,
      "step": 8530
    },
    {
      "epoch": 0.7287311204027648,
      "grad_norm": 0.11022216826677322,
      "learning_rate": 4.635634439798618e-05,
      "loss": 0.0038,
      "step": 8540
    },
    {
      "epoch": 0.729584435532042,
      "grad_norm": 0.619392991065979,
      "learning_rate": 4.635207782233979e-05,
      "loss": 0.0038,
      "step": 8550
    },
    {
      "epoch": 0.7304377506613192,
      "grad_norm": 0.22306518256664276,
      "learning_rate": 4.6347811246693406e-05,
      "loss": 0.0032,
      "step": 8560
    },
    {
      "epoch": 0.7312910657905964,
      "grad_norm": 0.24860252439975739,
      "learning_rate": 4.634354467104702e-05,
      "loss": 0.003,
      "step": 8570
    },
    {
      "epoch": 0.7321443809198737,
      "grad_norm": 0.18698355555534363,
      "learning_rate": 4.6339278095400635e-05,
      "loss": 0.004,
      "step": 8580
    },
    {
      "epoch": 0.732997696049151,
      "grad_norm": 0.0492069348692894,
      "learning_rate": 4.633501151975424e-05,
      "loss": 0.0025,
      "step": 8590
    },
    {
      "epoch": 0.7338510111784282,
      "grad_norm": 0.0391613133251667,
      "learning_rate": 4.633074494410786e-05,
      "loss": 0.0031,
      "step": 8600
    },
    {
      "epoch": 0.7347043263077054,
      "grad_norm": 0.29913389682769775,
      "learning_rate": 4.632647836846147e-05,
      "loss": 0.0025,
      "step": 8610
    },
    {
      "epoch": 0.7355576414369827,
      "grad_norm": 0.15941594541072845,
      "learning_rate": 4.632221179281509e-05,
      "loss": 0.0038,
      "step": 8620
    },
    {
      "epoch": 0.7364109565662599,
      "grad_norm": 0.09774989634752274,
      "learning_rate": 4.63179452171687e-05,
      "loss": 0.0039,
      "step": 8630
    },
    {
      "epoch": 0.7372642716955372,
      "grad_norm": 0.21234232187271118,
      "learning_rate": 4.631367864152232e-05,
      "loss": 0.004,
      "step": 8640
    },
    {
      "epoch": 0.7381175868248144,
      "grad_norm": 0.08365350216627121,
      "learning_rate": 4.630941206587593e-05,
      "loss": 0.0045,
      "step": 8650
    },
    {
      "epoch": 0.7389709019540917,
      "grad_norm": 0.32793498039245605,
      "learning_rate": 4.630514549022955e-05,
      "loss": 0.0027,
      "step": 8660
    },
    {
      "epoch": 0.7398242170833689,
      "grad_norm": 0.09486900269985199,
      "learning_rate": 4.6300878914583156e-05,
      "loss": 0.0036,
      "step": 8670
    },
    {
      "epoch": 0.7406775322126461,
      "grad_norm": 0.2581457197666168,
      "learning_rate": 4.629661233893677e-05,
      "loss": 0.0049,
      "step": 8680
    },
    {
      "epoch": 0.7415308473419234,
      "grad_norm": 0.031104987487196922,
      "learning_rate": 4.6292345763290385e-05,
      "loss": 0.0029,
      "step": 8690
    },
    {
      "epoch": 0.7423841624712006,
      "grad_norm": 0.1489374339580536,
      "learning_rate": 4.6288079187644e-05,
      "loss": 0.0031,
      "step": 8700
    },
    {
      "epoch": 0.7432374776004779,
      "grad_norm": 0.05959672853350639,
      "learning_rate": 4.628381261199761e-05,
      "loss": 0.0039,
      "step": 8710
    },
    {
      "epoch": 0.7440907927297551,
      "grad_norm": 0.6518118381500244,
      "learning_rate": 4.627954603635123e-05,
      "loss": 0.003,
      "step": 8720
    },
    {
      "epoch": 0.7449441078590323,
      "grad_norm": 0.7816880345344543,
      "learning_rate": 4.627527946070484e-05,
      "loss": 0.0036,
      "step": 8730
    },
    {
      "epoch": 0.7457974229883095,
      "grad_norm": 0.046478964388370514,
      "learning_rate": 4.6271012885058456e-05,
      "loss": 0.0032,
      "step": 8740
    },
    {
      "epoch": 0.7466507381175869,
      "grad_norm": 0.2095300853252411,
      "learning_rate": 4.626674630941207e-05,
      "loss": 0.0032,
      "step": 8750
    },
    {
      "epoch": 0.7475040532468641,
      "grad_norm": 0.26070141792297363,
      "learning_rate": 4.6262479733765684e-05,
      "loss": 0.0034,
      "step": 8760
    },
    {
      "epoch": 0.7483573683761413,
      "grad_norm": 0.29600661993026733,
      "learning_rate": 4.62582131581193e-05,
      "loss": 0.0036,
      "step": 8770
    },
    {
      "epoch": 0.7492106835054185,
      "grad_norm": 0.39134228229522705,
      "learning_rate": 4.6253946582472906e-05,
      "loss": 0.0032,
      "step": 8780
    },
    {
      "epoch": 0.7500639986346957,
      "grad_norm": 0.2513757050037384,
      "learning_rate": 4.624968000682652e-05,
      "loss": 0.0032,
      "step": 8790
    },
    {
      "epoch": 0.7509173137639731,
      "grad_norm": 0.39378952980041504,
      "learning_rate": 4.6245413431180135e-05,
      "loss": 0.0037,
      "step": 8800
    },
    {
      "epoch": 0.7517706288932503,
      "grad_norm": 0.1875075101852417,
      "learning_rate": 4.624114685553375e-05,
      "loss": 0.0036,
      "step": 8810
    },
    {
      "epoch": 0.7526239440225275,
      "grad_norm": 0.3001789450645447,
      "learning_rate": 4.623688027988736e-05,
      "loss": 0.0035,
      "step": 8820
    },
    {
      "epoch": 0.7534772591518047,
      "grad_norm": 0.35839781165122986,
      "learning_rate": 4.623261370424098e-05,
      "loss": 0.0046,
      "step": 8830
    },
    {
      "epoch": 0.754330574281082,
      "grad_norm": 0.2943916320800781,
      "learning_rate": 4.622834712859459e-05,
      "loss": 0.0027,
      "step": 8840
    },
    {
      "epoch": 0.7551838894103593,
      "grad_norm": 0.19286587834358215,
      "learning_rate": 4.6224080552948206e-05,
      "loss": 0.0039,
      "step": 8850
    },
    {
      "epoch": 0.7560372045396365,
      "grad_norm": 0.4426158666610718,
      "learning_rate": 4.621981397730182e-05,
      "loss": 0.0033,
      "step": 8860
    },
    {
      "epoch": 0.7568905196689137,
      "grad_norm": 0.3534751832485199,
      "learning_rate": 4.6215547401655434e-05,
      "loss": 0.0033,
      "step": 8870
    },
    {
      "epoch": 0.757743834798191,
      "grad_norm": 0.11452507972717285,
      "learning_rate": 4.621128082600905e-05,
      "loss": 0.0029,
      "step": 8880
    },
    {
      "epoch": 0.7585971499274682,
      "grad_norm": 0.13714562356472015,
      "learning_rate": 4.620701425036266e-05,
      "loss": 0.0034,
      "step": 8890
    },
    {
      "epoch": 0.7594504650567454,
      "grad_norm": 0.13717558979988098,
      "learning_rate": 4.620274767471627e-05,
      "loss": 0.0033,
      "step": 8900
    },
    {
      "epoch": 0.7603037801860227,
      "grad_norm": 0.07239370793104172,
      "learning_rate": 4.619848109906989e-05,
      "loss": 0.0046,
      "step": 8910
    },
    {
      "epoch": 0.7611570953153,
      "grad_norm": 0.0329640656709671,
      "learning_rate": 4.61942145234235e-05,
      "loss": 0.0028,
      "step": 8920
    },
    {
      "epoch": 0.7620104104445772,
      "grad_norm": 0.2744745910167694,
      "learning_rate": 4.618994794777712e-05,
      "loss": 0.0048,
      "step": 8930
    },
    {
      "epoch": 0.7628637255738544,
      "grad_norm": 0.064592644572258,
      "learning_rate": 4.618568137213073e-05,
      "loss": 0.003,
      "step": 8940
    },
    {
      "epoch": 0.7637170407031316,
      "grad_norm": 0.3111487925052643,
      "learning_rate": 4.618141479648435e-05,
      "loss": 0.0041,
      "step": 8950
    },
    {
      "epoch": 0.764570355832409,
      "grad_norm": 0.4763140082359314,
      "learning_rate": 4.6177148220837956e-05,
      "loss": 0.0033,
      "step": 8960
    },
    {
      "epoch": 0.7654236709616862,
      "grad_norm": 0.2276623398065567,
      "learning_rate": 4.617288164519158e-05,
      "loss": 0.0027,
      "step": 8970
    },
    {
      "epoch": 0.7662769860909634,
      "grad_norm": 0.3600537180900574,
      "learning_rate": 4.6168615069545184e-05,
      "loss": 0.0036,
      "step": 8980
    },
    {
      "epoch": 0.7671303012202406,
      "grad_norm": 0.11426480859518051,
      "learning_rate": 4.61643484938988e-05,
      "loss": 0.0025,
      "step": 8990
    },
    {
      "epoch": 0.7679836163495178,
      "grad_norm": 0.47402849793434143,
      "learning_rate": 4.616008191825241e-05,
      "loss": 0.0034,
      "step": 9000
    },
    {
      "epoch": 0.7688369314787952,
      "grad_norm": 0.18904289603233337,
      "learning_rate": 4.615581534260603e-05,
      "loss": 0.0037,
      "step": 9010
    },
    {
      "epoch": 0.7696902466080724,
      "grad_norm": 0.04320327937602997,
      "learning_rate": 4.615154876695964e-05,
      "loss": 0.003,
      "step": 9020
    },
    {
      "epoch": 0.7705435617373496,
      "grad_norm": 0.5426454544067383,
      "learning_rate": 4.6147282191313255e-05,
      "loss": 0.0038,
      "step": 9030
    },
    {
      "epoch": 0.7713968768666268,
      "grad_norm": 0.06021321192383766,
      "learning_rate": 4.614301561566687e-05,
      "loss": 0.0026,
      "step": 9040
    },
    {
      "epoch": 0.7722501919959041,
      "grad_norm": 0.20190373063087463,
      "learning_rate": 4.613874904002048e-05,
      "loss": 0.0033,
      "step": 9050
    },
    {
      "epoch": 0.7731035071251813,
      "grad_norm": 0.24656683206558228,
      "learning_rate": 4.61344824643741e-05,
      "loss": 0.0023,
      "step": 9060
    },
    {
      "epoch": 0.7739568222544586,
      "grad_norm": 0.1370372176170349,
      "learning_rate": 4.6130215888727706e-05,
      "loss": 0.0046,
      "step": 9070
    },
    {
      "epoch": 0.7748101373837358,
      "grad_norm": 0.06195208802819252,
      "learning_rate": 4.612594931308133e-05,
      "loss": 0.0031,
      "step": 9080
    },
    {
      "epoch": 0.775663452513013,
      "grad_norm": 0.11843223869800568,
      "learning_rate": 4.6121682737434934e-05,
      "loss": 0.0042,
      "step": 9090
    },
    {
      "epoch": 0.7765167676422903,
      "grad_norm": 0.15365608036518097,
      "learning_rate": 4.611741616178855e-05,
      "loss": 0.003,
      "step": 9100
    },
    {
      "epoch": 0.7773700827715675,
      "grad_norm": 0.20611533522605896,
      "learning_rate": 4.611314958614216e-05,
      "loss": 0.0033,
      "step": 9110
    },
    {
      "epoch": 0.7782233979008448,
      "grad_norm": 0.2956262230873108,
      "learning_rate": 4.610888301049578e-05,
      "loss": 0.0024,
      "step": 9120
    },
    {
      "epoch": 0.779076713030122,
      "grad_norm": 0.3543139696121216,
      "learning_rate": 4.610461643484939e-05,
      "loss": 0.003,
      "step": 9130
    },
    {
      "epoch": 0.7799300281593993,
      "grad_norm": 0.4966956675052643,
      "learning_rate": 4.6100349859203005e-05,
      "loss": 0.0031,
      "step": 9140
    },
    {
      "epoch": 0.7807833432886765,
      "grad_norm": 0.20884767174720764,
      "learning_rate": 4.609608328355662e-05,
      "loss": 0.0034,
      "step": 9150
    },
    {
      "epoch": 0.7816366584179537,
      "grad_norm": 0.13352075219154358,
      "learning_rate": 4.6091816707910234e-05,
      "loss": 0.0033,
      "step": 9160
    },
    {
      "epoch": 0.782489973547231,
      "grad_norm": 0.3330055773258209,
      "learning_rate": 4.608755013226385e-05,
      "loss": 0.0037,
      "step": 9170
    },
    {
      "epoch": 0.7833432886765083,
      "grad_norm": 0.22473494708538055,
      "learning_rate": 4.608328355661746e-05,
      "loss": 0.0035,
      "step": 9180
    },
    {
      "epoch": 0.7841966038057855,
      "grad_norm": 0.12146397680044174,
      "learning_rate": 4.6079016980971076e-05,
      "loss": 0.0035,
      "step": 9190
    },
    {
      "epoch": 0.7850499189350627,
      "grad_norm": 0.16721147298812866,
      "learning_rate": 4.607475040532469e-05,
      "loss": 0.0032,
      "step": 9200
    },
    {
      "epoch": 0.7859032340643399,
      "grad_norm": 0.1543661653995514,
      "learning_rate": 4.60704838296783e-05,
      "loss": 0.0026,
      "step": 9210
    },
    {
      "epoch": 0.7867565491936171,
      "grad_norm": 0.30213260650634766,
      "learning_rate": 4.606621725403192e-05,
      "loss": 0.0035,
      "step": 9220
    },
    {
      "epoch": 0.7876098643228945,
      "grad_norm": 0.18259470164775848,
      "learning_rate": 4.606195067838553e-05,
      "loss": 0.003,
      "step": 9230
    },
    {
      "epoch": 0.7884631794521717,
      "grad_norm": 0.27755844593048096,
      "learning_rate": 4.605768410273915e-05,
      "loss": 0.0035,
      "step": 9240
    },
    {
      "epoch": 0.7893164945814489,
      "grad_norm": 0.09201206266880035,
      "learning_rate": 4.6053417527092755e-05,
      "loss": 0.0028,
      "step": 9250
    },
    {
      "epoch": 0.7901698097107261,
      "grad_norm": 0.2649764120578766,
      "learning_rate": 4.6049150951446376e-05,
      "loss": 0.0028,
      "step": 9260
    },
    {
      "epoch": 0.7910231248400034,
      "grad_norm": 0.0677357167005539,
      "learning_rate": 4.6044884375799984e-05,
      "loss": 0.0032,
      "step": 9270
    },
    {
      "epoch": 0.7918764399692807,
      "grad_norm": 0.3013225793838501,
      "learning_rate": 4.6040617800153605e-05,
      "loss": 0.0038,
      "step": 9280
    },
    {
      "epoch": 0.7927297550985579,
      "grad_norm": 0.2660791873931885,
      "learning_rate": 4.603635122450721e-05,
      "loss": 0.0035,
      "step": 9290
    },
    {
      "epoch": 0.7935830702278351,
      "grad_norm": 0.15842527151107788,
      "learning_rate": 4.6032084648860826e-05,
      "loss": 0.0037,
      "step": 9300
    },
    {
      "epoch": 0.7944363853571124,
      "grad_norm": 0.5449615716934204,
      "learning_rate": 4.602781807321444e-05,
      "loss": 0.0027,
      "step": 9310
    },
    {
      "epoch": 0.7952897004863896,
      "grad_norm": 0.0775565505027771,
      "learning_rate": 4.6023551497568055e-05,
      "loss": 0.0031,
      "step": 9320
    },
    {
      "epoch": 0.7961430156156669,
      "grad_norm": 0.4275558888912201,
      "learning_rate": 4.601928492192167e-05,
      "loss": 0.0039,
      "step": 9330
    },
    {
      "epoch": 0.7969963307449441,
      "grad_norm": 0.6404072046279907,
      "learning_rate": 4.6015018346275277e-05,
      "loss": 0.0039,
      "step": 9340
    },
    {
      "epoch": 0.7978496458742214,
      "grad_norm": 0.32153114676475525,
      "learning_rate": 4.60107517706289e-05,
      "loss": 0.0032,
      "step": 9350
    },
    {
      "epoch": 0.7987029610034986,
      "grad_norm": 0.4016628563404083,
      "learning_rate": 4.6006485194982505e-05,
      "loss": 0.0033,
      "step": 9360
    },
    {
      "epoch": 0.7995562761327758,
      "grad_norm": 0.09608493000268936,
      "learning_rate": 4.6002218619336126e-05,
      "loss": 0.0033,
      "step": 9370
    },
    {
      "epoch": 0.800409591262053,
      "grad_norm": 0.14725758135318756,
      "learning_rate": 4.5997952043689734e-05,
      "loss": 0.0038,
      "step": 9380
    },
    {
      "epoch": 0.8012629063913304,
      "grad_norm": 0.21085794270038605,
      "learning_rate": 4.5993685468043355e-05,
      "loss": 0.0029,
      "step": 9390
    },
    {
      "epoch": 0.8021162215206076,
      "grad_norm": 0.5975650548934937,
      "learning_rate": 4.598941889239696e-05,
      "loss": 0.0025,
      "step": 9400
    },
    {
      "epoch": 0.8029695366498848,
      "grad_norm": 0.7963377237319946,
      "learning_rate": 4.5985152316750576e-05,
      "loss": 0.0044,
      "step": 9410
    },
    {
      "epoch": 0.803822851779162,
      "grad_norm": 0.4901553988456726,
      "learning_rate": 4.598088574110419e-05,
      "loss": 0.003,
      "step": 9420
    },
    {
      "epoch": 0.8046761669084392,
      "grad_norm": 0.34717777371406555,
      "learning_rate": 4.5976619165457805e-05,
      "loss": 0.0039,
      "step": 9430
    },
    {
      "epoch": 0.8055294820377166,
      "grad_norm": 0.2185870260000229,
      "learning_rate": 4.597235258981142e-05,
      "loss": 0.0027,
      "step": 9440
    },
    {
      "epoch": 0.8063827971669938,
      "grad_norm": 0.14112426340579987,
      "learning_rate": 4.596808601416503e-05,
      "loss": 0.0032,
      "step": 9450
    },
    {
      "epoch": 0.807236112296271,
      "grad_norm": 0.44571593403816223,
      "learning_rate": 4.596381943851865e-05,
      "loss": 0.0028,
      "step": 9460
    },
    {
      "epoch": 0.8080894274255482,
      "grad_norm": 0.17472834885120392,
      "learning_rate": 4.595955286287226e-05,
      "loss": 0.0024,
      "step": 9470
    },
    {
      "epoch": 0.8089427425548255,
      "grad_norm": 0.13247375190258026,
      "learning_rate": 4.5955286287225876e-05,
      "loss": 0.0028,
      "step": 9480
    },
    {
      "epoch": 0.8097960576841028,
      "grad_norm": 0.14474523067474365,
      "learning_rate": 4.595101971157949e-05,
      "loss": 0.0033,
      "step": 9490
    },
    {
      "epoch": 0.81064937281338,
      "grad_norm": 0.11449657380580902,
      "learning_rate": 4.5946753135933104e-05,
      "loss": 0.003,
      "step": 9500
    },
    {
      "epoch": 0.8115026879426572,
      "grad_norm": 0.08078256994485855,
      "learning_rate": 4.594248656028672e-05,
      "loss": 0.003,
      "step": 9510
    },
    {
      "epoch": 0.8123560030719345,
      "grad_norm": 0.09649340063333511,
      "learning_rate": 4.5938219984640326e-05,
      "loss": 0.0035,
      "step": 9520
    },
    {
      "epoch": 0.8132093182012117,
      "grad_norm": 0.26352402567863464,
      "learning_rate": 4.593395340899395e-05,
      "loss": 0.0031,
      "step": 9530
    },
    {
      "epoch": 0.814062633330489,
      "grad_norm": 0.2721600830554962,
      "learning_rate": 4.5929686833347555e-05,
      "loss": 0.0025,
      "step": 9540
    },
    {
      "epoch": 0.8149159484597662,
      "grad_norm": 0.020785745233297348,
      "learning_rate": 4.5925420257701176e-05,
      "loss": 0.0038,
      "step": 9550
    },
    {
      "epoch": 0.8157692635890434,
      "grad_norm": 0.04097887501120567,
      "learning_rate": 4.592115368205478e-05,
      "loss": 0.0029,
      "step": 9560
    },
    {
      "epoch": 0.8166225787183207,
      "grad_norm": 0.23850278556346893,
      "learning_rate": 4.59168871064084e-05,
      "loss": 0.0033,
      "step": 9570
    },
    {
      "epoch": 0.8174758938475979,
      "grad_norm": 0.21424797177314758,
      "learning_rate": 4.591262053076201e-05,
      "loss": 0.0037,
      "step": 9580
    },
    {
      "epoch": 0.8183292089768751,
      "grad_norm": 0.09808530658483505,
      "learning_rate": 4.5908353955115626e-05,
      "loss": 0.0029,
      "step": 9590
    },
    {
      "epoch": 0.8191825241061524,
      "grad_norm": 0.28454214334487915,
      "learning_rate": 4.590408737946924e-05,
      "loss": 0.0036,
      "step": 9600
    },
    {
      "epoch": 0.8200358392354297,
      "grad_norm": 0.1344449669122696,
      "learning_rate": 4.5899820803822854e-05,
      "loss": 0.003,
      "step": 9610
    },
    {
      "epoch": 0.8208891543647069,
      "grad_norm": 0.3242162764072418,
      "learning_rate": 4.589555422817647e-05,
      "loss": 0.0043,
      "step": 9620
    },
    {
      "epoch": 0.8217424694939841,
      "grad_norm": 0.5917317271232605,
      "learning_rate": 4.589128765253008e-05,
      "loss": 0.0043,
      "step": 9630
    },
    {
      "epoch": 0.8225957846232613,
      "grad_norm": 0.06118399649858475,
      "learning_rate": 4.58870210768837e-05,
      "loss": 0.0039,
      "step": 9640
    },
    {
      "epoch": 0.8234490997525387,
      "grad_norm": 0.6575530767440796,
      "learning_rate": 4.5882754501237304e-05,
      "loss": 0.0042,
      "step": 9650
    },
    {
      "epoch": 0.8243024148818159,
      "grad_norm": 0.28307607769966125,
      "learning_rate": 4.5878487925590925e-05,
      "loss": 0.0031,
      "step": 9660
    },
    {
      "epoch": 0.8251557300110931,
      "grad_norm": 0.19690890610218048,
      "learning_rate": 4.587422134994453e-05,
      "loss": 0.0029,
      "step": 9670
    },
    {
      "epoch": 0.8260090451403703,
      "grad_norm": 0.14864365756511688,
      "learning_rate": 4.5869954774298154e-05,
      "loss": 0.0025,
      "step": 9680
    },
    {
      "epoch": 0.8268623602696475,
      "grad_norm": 0.08105482906103134,
      "learning_rate": 4.586568819865176e-05,
      "loss": 0.0023,
      "step": 9690
    },
    {
      "epoch": 0.8277156753989249,
      "grad_norm": 0.48080316185951233,
      "learning_rate": 4.586142162300538e-05,
      "loss": 0.0051,
      "step": 9700
    },
    {
      "epoch": 0.8285689905282021,
      "grad_norm": 0.35792261362075806,
      "learning_rate": 4.585715504735899e-05,
      "loss": 0.0036,
      "step": 9710
    },
    {
      "epoch": 0.8294223056574793,
      "grad_norm": 0.051055219024419785,
      "learning_rate": 4.5852888471712604e-05,
      "loss": 0.0028,
      "step": 9720
    },
    {
      "epoch": 0.8302756207867565,
      "grad_norm": 0.07738877087831497,
      "learning_rate": 4.584862189606622e-05,
      "loss": 0.0034,
      "step": 9730
    },
    {
      "epoch": 0.8311289359160338,
      "grad_norm": 0.04368515685200691,
      "learning_rate": 4.584435532041983e-05,
      "loss": 0.0045,
      "step": 9740
    },
    {
      "epoch": 0.831982251045311,
      "grad_norm": 0.04444872587919235,
      "learning_rate": 4.584008874477345e-05,
      "loss": 0.004,
      "step": 9750
    },
    {
      "epoch": 0.8328355661745883,
      "grad_norm": 0.3941788077354431,
      "learning_rate": 4.583582216912706e-05,
      "loss": 0.0039,
      "step": 9760
    },
    {
      "epoch": 0.8336888813038655,
      "grad_norm": 0.18226182460784912,
      "learning_rate": 4.5831555593480675e-05,
      "loss": 0.003,
      "step": 9770
    },
    {
      "epoch": 0.8345421964331428,
      "grad_norm": 0.18297669291496277,
      "learning_rate": 4.582728901783429e-05,
      "loss": 0.0033,
      "step": 9780
    },
    {
      "epoch": 0.83539551156242,
      "grad_norm": 0.3652876317501068,
      "learning_rate": 4.5823022442187904e-05,
      "loss": 0.0026,
      "step": 9790
    },
    {
      "epoch": 0.8362488266916972,
      "grad_norm": 0.11807452142238617,
      "learning_rate": 4.581875586654152e-05,
      "loss": 0.0031,
      "step": 9800
    },
    {
      "epoch": 0.8371021418209745,
      "grad_norm": 0.10875854641199112,
      "learning_rate": 4.581448929089513e-05,
      "loss": 0.0032,
      "step": 9810
    },
    {
      "epoch": 0.8379554569502518,
      "grad_norm": 0.310169517993927,
      "learning_rate": 4.5810222715248747e-05,
      "loss": 0.0029,
      "step": 9820
    },
    {
      "epoch": 0.838808772079529,
      "grad_norm": 0.4737568497657776,
      "learning_rate": 4.5805956139602354e-05,
      "loss": 0.0041,
      "step": 9830
    },
    {
      "epoch": 0.8396620872088062,
      "grad_norm": 0.25966665148735046,
      "learning_rate": 4.580168956395597e-05,
      "loss": 0.0031,
      "step": 9840
    },
    {
      "epoch": 0.8405154023380834,
      "grad_norm": 0.5262824892997742,
      "learning_rate": 4.579742298830958e-05,
      "loss": 0.0035,
      "step": 9850
    },
    {
      "epoch": 0.8413687174673607,
      "grad_norm": 0.22859251499176025,
      "learning_rate": 4.57931564126632e-05,
      "loss": 0.0028,
      "step": 9860
    },
    {
      "epoch": 0.842222032596638,
      "grad_norm": 0.4509868621826172,
      "learning_rate": 4.578888983701681e-05,
      "loss": 0.0033,
      "step": 9870
    },
    {
      "epoch": 0.8430753477259152,
      "grad_norm": 0.31740403175354004,
      "learning_rate": 4.5784623261370425e-05,
      "loss": 0.0032,
      "step": 9880
    },
    {
      "epoch": 0.8439286628551924,
      "grad_norm": 0.2549532651901245,
      "learning_rate": 4.578035668572404e-05,
      "loss": 0.0033,
      "step": 9890
    },
    {
      "epoch": 0.8447819779844696,
      "grad_norm": 0.17402592301368713,
      "learning_rate": 4.5776090110077654e-05,
      "loss": 0.0025,
      "step": 9900
    },
    {
      "epoch": 0.8456352931137469,
      "grad_norm": 0.46972960233688354,
      "learning_rate": 4.577182353443127e-05,
      "loss": 0.0034,
      "step": 9910
    },
    {
      "epoch": 0.8464886082430242,
      "grad_norm": 0.06877051293849945,
      "learning_rate": 4.576755695878488e-05,
      "loss": 0.0045,
      "step": 9920
    },
    {
      "epoch": 0.8473419233723014,
      "grad_norm": 0.26465126872062683,
      "learning_rate": 4.5763290383138496e-05,
      "loss": 0.0027,
      "step": 9930
    },
    {
      "epoch": 0.8481952385015786,
      "grad_norm": 0.12927542626857758,
      "learning_rate": 4.575902380749211e-05,
      "loss": 0.004,
      "step": 9940
    },
    {
      "epoch": 0.8490485536308559,
      "grad_norm": 0.48098018765449524,
      "learning_rate": 4.5754757231845725e-05,
      "loss": 0.0026,
      "step": 9950
    },
    {
      "epoch": 0.8499018687601331,
      "grad_norm": 0.2296554297208786,
      "learning_rate": 4.575049065619933e-05,
      "loss": 0.0029,
      "step": 9960
    },
    {
      "epoch": 0.8507551838894104,
      "grad_norm": 0.33656540513038635,
      "learning_rate": 4.5746224080552953e-05,
      "loss": 0.0026,
      "step": 9970
    },
    {
      "epoch": 0.8516084990186876,
      "grad_norm": 0.220107764005661,
      "learning_rate": 4.574195750490656e-05,
      "loss": 0.0035,
      "step": 9980
    },
    {
      "epoch": 0.8524618141479648,
      "grad_norm": 0.09360573440790176,
      "learning_rate": 4.573769092926018e-05,
      "loss": 0.0037,
      "step": 9990
    },
    {
      "epoch": 0.8533151292772421,
      "grad_norm": 0.39502817392349243,
      "learning_rate": 4.573342435361379e-05,
      "loss": 0.0033,
      "step": 10000
    },
    {
      "epoch": 0.8541684444065193,
      "grad_norm": 0.06087895482778549,
      "learning_rate": 4.572915777796741e-05,
      "loss": 0.0037,
      "step": 10010
    },
    {
      "epoch": 0.8550217595357966,
      "grad_norm": 0.105289988219738,
      "learning_rate": 4.572489120232102e-05,
      "loss": 0.0028,
      "step": 10020
    },
    {
      "epoch": 0.8558750746650738,
      "grad_norm": 0.3592108488082886,
      "learning_rate": 4.572062462667463e-05,
      "loss": 0.0033,
      "step": 10030
    },
    {
      "epoch": 0.8567283897943511,
      "grad_norm": 0.050791364163160324,
      "learning_rate": 4.5716358051028246e-05,
      "loss": 0.0029,
      "step": 10040
    },
    {
      "epoch": 0.8575817049236283,
      "grad_norm": 0.04187116026878357,
      "learning_rate": 4.571209147538186e-05,
      "loss": 0.0024,
      "step": 10050
    },
    {
      "epoch": 0.8584350200529055,
      "grad_norm": 0.2590446472167969,
      "learning_rate": 4.5707824899735475e-05,
      "loss": 0.0027,
      "step": 10060
    },
    {
      "epoch": 0.8592883351821827,
      "grad_norm": 0.09026863425970078,
      "learning_rate": 4.570355832408909e-05,
      "loss": 0.003,
      "step": 10070
    },
    {
      "epoch": 0.8601416503114601,
      "grad_norm": 0.09892181307077408,
      "learning_rate": 4.56992917484427e-05,
      "loss": 0.0027,
      "step": 10080
    },
    {
      "epoch": 0.8609949654407373,
      "grad_norm": 0.22783935070037842,
      "learning_rate": 4.569502517279632e-05,
      "loss": 0.0034,
      "step": 10090
    },
    {
      "epoch": 0.8618482805700145,
      "grad_norm": 0.4875698983669281,
      "learning_rate": 4.569075859714993e-05,
      "loss": 0.0032,
      "step": 10100
    },
    {
      "epoch": 0.8627015956992917,
      "grad_norm": 0.18993043899536133,
      "learning_rate": 4.568649202150354e-05,
      "loss": 0.0028,
      "step": 10110
    },
    {
      "epoch": 0.863554910828569,
      "grad_norm": 0.08336753398180008,
      "learning_rate": 4.568222544585716e-05,
      "loss": 0.0039,
      "step": 10120
    },
    {
      "epoch": 0.8644082259578463,
      "grad_norm": 0.22943109273910522,
      "learning_rate": 4.567795887021077e-05,
      "loss": 0.0032,
      "step": 10130
    },
    {
      "epoch": 0.8652615410871235,
      "grad_norm": 0.5451610088348389,
      "learning_rate": 4.567369229456438e-05,
      "loss": 0.0035,
      "step": 10140
    },
    {
      "epoch": 0.8661148562164007,
      "grad_norm": 0.03967297449707985,
      "learning_rate": 4.5669425718917996e-05,
      "loss": 0.0038,
      "step": 10150
    },
    {
      "epoch": 0.8669681713456779,
      "grad_norm": 0.32457780838012695,
      "learning_rate": 4.566515914327161e-05,
      "loss": 0.0035,
      "step": 10160
    },
    {
      "epoch": 0.8678214864749552,
      "grad_norm": 0.18226666748523712,
      "learning_rate": 4.5660892567625225e-05,
      "loss": 0.0037,
      "step": 10170
    },
    {
      "epoch": 0.8686748016042325,
      "grad_norm": 0.24515895545482635,
      "learning_rate": 4.565662599197884e-05,
      "loss": 0.0032,
      "step": 10180
    },
    {
      "epoch": 0.8695281167335097,
      "grad_norm": 0.21631115674972534,
      "learning_rate": 4.565235941633245e-05,
      "loss": 0.0037,
      "step": 10190
    },
    {
      "epoch": 0.8703814318627869,
      "grad_norm": 0.04495805874466896,
      "learning_rate": 4.564809284068607e-05,
      "loss": 0.0031,
      "step": 10200
    },
    {
      "epoch": 0.8712347469920642,
      "grad_norm": 0.4690610468387604,
      "learning_rate": 4.564382626503968e-05,
      "loss": 0.0024,
      "step": 10210
    },
    {
      "epoch": 0.8720880621213414,
      "grad_norm": 0.34464341402053833,
      "learning_rate": 4.5639559689393296e-05,
      "loss": 0.0025,
      "step": 10220
    },
    {
      "epoch": 0.8729413772506186,
      "grad_norm": 0.037231579422950745,
      "learning_rate": 4.563529311374691e-05,
      "loss": 0.0034,
      "step": 10230
    },
    {
      "epoch": 0.8737946923798959,
      "grad_norm": 0.2072545886039734,
      "learning_rate": 4.5631026538100524e-05,
      "loss": 0.0031,
      "step": 10240
    },
    {
      "epoch": 0.8746480075091732,
      "grad_norm": 0.09906773269176483,
      "learning_rate": 4.562675996245414e-05,
      "loss": 0.0037,
      "step": 10250
    },
    {
      "epoch": 0.8755013226384504,
      "grad_norm": 0.2476915717124939,
      "learning_rate": 4.562249338680775e-05,
      "loss": 0.003,
      "step": 10260
    },
    {
      "epoch": 0.8763546377677276,
      "grad_norm": 0.30445602536201477,
      "learning_rate": 4.561822681116136e-05,
      "loss": 0.0028,
      "step": 10270
    },
    {
      "epoch": 0.8772079528970048,
      "grad_norm": 0.06430807709693909,
      "learning_rate": 4.561396023551498e-05,
      "loss": 0.0034,
      "step": 10280
    },
    {
      "epoch": 0.8780612680262821,
      "grad_norm": 0.33756759762763977,
      "learning_rate": 4.560969365986859e-05,
      "loss": 0.0035,
      "step": 10290
    },
    {
      "epoch": 0.8789145831555594,
      "grad_norm": 0.17660802602767944,
      "learning_rate": 4.560542708422221e-05,
      "loss": 0.0034,
      "step": 10300
    },
    {
      "epoch": 0.8797678982848366,
      "grad_norm": 0.34462764859199524,
      "learning_rate": 4.560116050857582e-05,
      "loss": 0.0032,
      "step": 10310
    },
    {
      "epoch": 0.8806212134141138,
      "grad_norm": 0.1771998256444931,
      "learning_rate": 4.559689393292944e-05,
      "loss": 0.0033,
      "step": 10320
    },
    {
      "epoch": 0.881474528543391,
      "grad_norm": 0.1335190385580063,
      "learning_rate": 4.5592627357283046e-05,
      "loss": 0.0033,
      "step": 10330
    },
    {
      "epoch": 0.8823278436726684,
      "grad_norm": 0.3985356390476227,
      "learning_rate": 4.558836078163666e-05,
      "loss": 0.0029,
      "step": 10340
    },
    {
      "epoch": 0.8831811588019456,
      "grad_norm": 0.031507983803749084,
      "learning_rate": 4.5584094205990274e-05,
      "loss": 0.0031,
      "step": 10350
    },
    {
      "epoch": 0.8840344739312228,
      "grad_norm": 0.20402660965919495,
      "learning_rate": 4.557982763034389e-05,
      "loss": 0.0026,
      "step": 10360
    },
    {
      "epoch": 0.8848877890605,
      "grad_norm": 0.4293755292892456,
      "learning_rate": 4.55755610546975e-05,
      "loss": 0.0036,
      "step": 10370
    },
    {
      "epoch": 0.8857411041897773,
      "grad_norm": 0.05320950970053673,
      "learning_rate": 4.557129447905111e-05,
      "loss": 0.0026,
      "step": 10380
    },
    {
      "epoch": 0.8865944193190545,
      "grad_norm": 0.49045369029045105,
      "learning_rate": 4.556702790340473e-05,
      "loss": 0.0026,
      "step": 10390
    },
    {
      "epoch": 0.8874477344483318,
      "grad_norm": 0.37988194823265076,
      "learning_rate": 4.556276132775834e-05,
      "loss": 0.0031,
      "step": 10400
    },
    {
      "epoch": 0.888301049577609,
      "grad_norm": 0.0587620809674263,
      "learning_rate": 4.555849475211196e-05,
      "loss": 0.003,
      "step": 10410
    },
    {
      "epoch": 0.8891543647068862,
      "grad_norm": 0.5519148111343384,
      "learning_rate": 4.555422817646557e-05,
      "loss": 0.004,
      "step": 10420
    },
    {
      "epoch": 0.8900076798361635,
      "grad_norm": 0.22462905943393707,
      "learning_rate": 4.554996160081919e-05,
      "loss": 0.0026,
      "step": 10430
    },
    {
      "epoch": 0.8908609949654407,
      "grad_norm": 0.21208594739437103,
      "learning_rate": 4.5545695025172796e-05,
      "loss": 0.0032,
      "step": 10440
    },
    {
      "epoch": 0.891714310094718,
      "grad_norm": 0.1827407032251358,
      "learning_rate": 4.554142844952641e-05,
      "loss": 0.0033,
      "step": 10450
    },
    {
      "epoch": 0.8925676252239952,
      "grad_norm": 0.12516137957572937,
      "learning_rate": 4.5537161873880024e-05,
      "loss": 0.0043,
      "step": 10460
    },
    {
      "epoch": 0.8934209403532725,
      "grad_norm": 0.13662326335906982,
      "learning_rate": 4.553289529823364e-05,
      "loss": 0.0033,
      "step": 10470
    },
    {
      "epoch": 0.8942742554825497,
      "grad_norm": 0.3424503207206726,
      "learning_rate": 4.552862872258725e-05,
      "loss": 0.0027,
      "step": 10480
    },
    {
      "epoch": 0.8951275706118269,
      "grad_norm": 0.3172309994697571,
      "learning_rate": 4.552436214694087e-05,
      "loss": 0.0027,
      "step": 10490
    },
    {
      "epoch": 0.8959808857411042,
      "grad_norm": 0.24211515486240387,
      "learning_rate": 4.552009557129448e-05,
      "loss": 0.0039,
      "step": 10500
    },
    {
      "epoch": 0.8968342008703815,
      "grad_norm": 0.23450350761413574,
      "learning_rate": 4.5515828995648095e-05,
      "loss": 0.0039,
      "step": 10510
    },
    {
      "epoch": 0.8976875159996587,
      "grad_norm": 0.2302308976650238,
      "learning_rate": 4.551156242000171e-05,
      "loss": 0.0033,
      "step": 10520
    },
    {
      "epoch": 0.8985408311289359,
      "grad_norm": 0.4905610978603363,
      "learning_rate": 4.5507295844355324e-05,
      "loss": 0.0031,
      "step": 10530
    },
    {
      "epoch": 0.8993941462582131,
      "grad_norm": 0.227244034409523,
      "learning_rate": 4.550302926870894e-05,
      "loss": 0.0031,
      "step": 10540
    },
    {
      "epoch": 0.9002474613874905,
      "grad_norm": 0.047300443053245544,
      "learning_rate": 4.549876269306255e-05,
      "loss": 0.0029,
      "step": 10550
    },
    {
      "epoch": 0.9011007765167677,
      "grad_norm": 0.06079273298382759,
      "learning_rate": 4.5494496117416167e-05,
      "loss": 0.0031,
      "step": 10560
    },
    {
      "epoch": 0.9019540916460449,
      "grad_norm": 0.36953726410865784,
      "learning_rate": 4.549022954176978e-05,
      "loss": 0.0027,
      "step": 10570
    },
    {
      "epoch": 0.9028074067753221,
      "grad_norm": 0.15317212045192719,
      "learning_rate": 4.548596296612339e-05,
      "loss": 0.0042,
      "step": 10580
    },
    {
      "epoch": 0.9036607219045993,
      "grad_norm": 0.10551023483276367,
      "learning_rate": 4.548169639047701e-05,
      "loss": 0.0032,
      "step": 10590
    },
    {
      "epoch": 0.9045140370338766,
      "grad_norm": 0.4567085802555084,
      "learning_rate": 4.547742981483062e-05,
      "loss": 0.0036,
      "step": 10600
    },
    {
      "epoch": 0.9053673521631539,
      "grad_norm": 0.27328288555145264,
      "learning_rate": 4.547316323918424e-05,
      "loss": 0.0042,
      "step": 10610
    },
    {
      "epoch": 0.9062206672924311,
      "grad_norm": 0.31223970651626587,
      "learning_rate": 4.5468896663537845e-05,
      "loss": 0.003,
      "step": 10620
    },
    {
      "epoch": 0.9070739824217083,
      "grad_norm": 0.17130440473556519,
      "learning_rate": 4.546463008789146e-05,
      "loss": 0.0038,
      "step": 10630
    },
    {
      "epoch": 0.9079272975509856,
      "grad_norm": 0.14118953049182892,
      "learning_rate": 4.5460363512245074e-05,
      "loss": 0.0036,
      "step": 10640
    },
    {
      "epoch": 0.9087806126802628,
      "grad_norm": 0.06822015345096588,
      "learning_rate": 4.545609693659869e-05,
      "loss": 0.0038,
      "step": 10650
    },
    {
      "epoch": 0.9096339278095401,
      "grad_norm": 0.06283305585384369,
      "learning_rate": 4.54518303609523e-05,
      "loss": 0.0027,
      "step": 10660
    },
    {
      "epoch": 0.9104872429388173,
      "grad_norm": 0.43169769644737244,
      "learning_rate": 4.5447563785305916e-05,
      "loss": 0.0035,
      "step": 10670
    },
    {
      "epoch": 0.9113405580680946,
      "grad_norm": 0.0464974120259285,
      "learning_rate": 4.544329720965953e-05,
      "loss": 0.0032,
      "step": 10680
    },
    {
      "epoch": 0.9121938731973718,
      "grad_norm": 0.05397060140967369,
      "learning_rate": 4.543903063401314e-05,
      "loss": 0.0035,
      "step": 10690
    },
    {
      "epoch": 0.913047188326649,
      "grad_norm": 0.4770796000957489,
      "learning_rate": 4.543476405836676e-05,
      "loss": 0.0037,
      "step": 10700
    },
    {
      "epoch": 0.9139005034559263,
      "grad_norm": 0.1826961785554886,
      "learning_rate": 4.5430497482720367e-05,
      "loss": 0.0031,
      "step": 10710
    },
    {
      "epoch": 0.9147538185852035,
      "grad_norm": 0.720179557800293,
      "learning_rate": 4.542623090707399e-05,
      "loss": 0.0033,
      "step": 10720
    },
    {
      "epoch": 0.9156071337144808,
      "grad_norm": 0.2647899091243744,
      "learning_rate": 4.5421964331427595e-05,
      "loss": 0.003,
      "step": 10730
    },
    {
      "epoch": 0.916460448843758,
      "grad_norm": 0.28205016255378723,
      "learning_rate": 4.5417697755781216e-05,
      "loss": 0.0031,
      "step": 10740
    },
    {
      "epoch": 0.9173137639730352,
      "grad_norm": 0.24583417177200317,
      "learning_rate": 4.5413431180134824e-05,
      "loss": 0.0037,
      "step": 10750
    },
    {
      "epoch": 0.9181670791023124,
      "grad_norm": 0.307218998670578,
      "learning_rate": 4.540916460448844e-05,
      "loss": 0.0033,
      "step": 10760
    },
    {
      "epoch": 0.9190203942315898,
      "grad_norm": 0.24947628378868103,
      "learning_rate": 4.540489802884205e-05,
      "loss": 0.0035,
      "step": 10770
    },
    {
      "epoch": 0.919873709360867,
      "grad_norm": 0.08306113630533218,
      "learning_rate": 4.5400631453195666e-05,
      "loss": 0.0032,
      "step": 10780
    },
    {
      "epoch": 0.9207270244901442,
      "grad_norm": 0.24347519874572754,
      "learning_rate": 4.539636487754928e-05,
      "loss": 0.0028,
      "step": 10790
    },
    {
      "epoch": 0.9215803396194214,
      "grad_norm": 0.5392529368400574,
      "learning_rate": 4.5392098301902895e-05,
      "loss": 0.0031,
      "step": 10800
    },
    {
      "epoch": 0.9224336547486987,
      "grad_norm": 0.513107419013977,
      "learning_rate": 4.538783172625651e-05,
      "loss": 0.0028,
      "step": 10810
    },
    {
      "epoch": 0.923286969877976,
      "grad_norm": 0.20388391613960266,
      "learning_rate": 4.538356515061012e-05,
      "loss": 0.0031,
      "step": 10820
    },
    {
      "epoch": 0.9241402850072532,
      "grad_norm": 0.19782263040542603,
      "learning_rate": 4.537929857496374e-05,
      "loss": 0.0031,
      "step": 10830
    },
    {
      "epoch": 0.9249936001365304,
      "grad_norm": 0.06738581508398056,
      "learning_rate": 4.537503199931735e-05,
      "loss": 0.0031,
      "step": 10840
    },
    {
      "epoch": 0.9258469152658076,
      "grad_norm": 0.6031497120857239,
      "learning_rate": 4.5370765423670966e-05,
      "loss": 0.0028,
      "step": 10850
    },
    {
      "epoch": 0.9267002303950849,
      "grad_norm": 0.11359168589115143,
      "learning_rate": 4.536649884802458e-05,
      "loss": 0.002,
      "step": 10860
    },
    {
      "epoch": 0.9275535455243622,
      "grad_norm": 0.3764949142932892,
      "learning_rate": 4.5362232272378194e-05,
      "loss": 0.0038,
      "step": 10870
    },
    {
      "epoch": 0.9284068606536394,
      "grad_norm": 0.6039444208145142,
      "learning_rate": 4.535796569673181e-05,
      "loss": 0.0038,
      "step": 10880
    },
    {
      "epoch": 0.9292601757829166,
      "grad_norm": 0.09970921277999878,
      "learning_rate": 4.5353699121085416e-05,
      "loss": 0.0032,
      "step": 10890
    },
    {
      "epoch": 0.9301134909121939,
      "grad_norm": 0.2578273117542267,
      "learning_rate": 4.534943254543903e-05,
      "loss": 0.0027,
      "step": 10900
    },
    {
      "epoch": 0.9309668060414711,
      "grad_norm": 0.1489282250404358,
      "learning_rate": 4.5345165969792645e-05,
      "loss": 0.0028,
      "step": 10910
    },
    {
      "epoch": 0.9318201211707483,
      "grad_norm": 0.437894731760025,
      "learning_rate": 4.534089939414626e-05,
      "loss": 0.0031,
      "step": 10920
    },
    {
      "epoch": 0.9326734363000256,
      "grad_norm": 0.4569793939590454,
      "learning_rate": 4.533663281849987e-05,
      "loss": 0.0027,
      "step": 10930
    },
    {
      "epoch": 0.9335267514293029,
      "grad_norm": 0.6747804880142212,
      "learning_rate": 4.533236624285349e-05,
      "loss": 0.0045,
      "step": 10940
    },
    {
      "epoch": 0.9343800665585801,
      "grad_norm": 0.14362117648124695,
      "learning_rate": 4.53280996672071e-05,
      "loss": 0.0029,
      "step": 10950
    },
    {
      "epoch": 0.9352333816878573,
      "grad_norm": 0.23278993368148804,
      "learning_rate": 4.5323833091560716e-05,
      "loss": 0.0032,
      "step": 10960
    },
    {
      "epoch": 0.9360866968171345,
      "grad_norm": 0.0699036568403244,
      "learning_rate": 4.531956651591433e-05,
      "loss": 0.0044,
      "step": 10970
    },
    {
      "epoch": 0.9369400119464119,
      "grad_norm": 0.24773959815502167,
      "learning_rate": 4.5315299940267944e-05,
      "loss": 0.0031,
      "step": 10980
    },
    {
      "epoch": 0.9377933270756891,
      "grad_norm": 0.490202933549881,
      "learning_rate": 4.531103336462156e-05,
      "loss": 0.004,
      "step": 10990
    },
    {
      "epoch": 0.9386466422049663,
      "grad_norm": 0.4537030756473541,
      "learning_rate": 4.5306766788975166e-05,
      "loss": 0.0031,
      "step": 11000
    },
    {
      "epoch": 0.9394999573342435,
      "grad_norm": 0.3069111704826355,
      "learning_rate": 4.530250021332879e-05,
      "loss": 0.0035,
      "step": 11010
    },
    {
      "epoch": 0.9403532724635207,
      "grad_norm": 0.33474093675613403,
      "learning_rate": 4.5298233637682394e-05,
      "loss": 0.0033,
      "step": 11020
    },
    {
      "epoch": 0.9412065875927981,
      "grad_norm": 0.14644388854503632,
      "learning_rate": 4.5293967062036016e-05,
      "loss": 0.0032,
      "step": 11030
    },
    {
      "epoch": 0.9420599027220753,
      "grad_norm": 0.10380420088768005,
      "learning_rate": 4.528970048638962e-05,
      "loss": 0.0026,
      "step": 11040
    },
    {
      "epoch": 0.9429132178513525,
      "grad_norm": 0.029854636639356613,
      "learning_rate": 4.5285433910743244e-05,
      "loss": 0.0036,
      "step": 11050
    },
    {
      "epoch": 0.9437665329806297,
      "grad_norm": 0.3630503714084625,
      "learning_rate": 4.528116733509685e-05,
      "loss": 0.0034,
      "step": 11060
    },
    {
      "epoch": 0.944619848109907,
      "grad_norm": 0.4011693596839905,
      "learning_rate": 4.5276900759450466e-05,
      "loss": 0.0036,
      "step": 11070
    },
    {
      "epoch": 0.9454731632391842,
      "grad_norm": 0.13872477412223816,
      "learning_rate": 4.527263418380408e-05,
      "loss": 0.0028,
      "step": 11080
    },
    {
      "epoch": 0.9463264783684615,
      "grad_norm": 0.10186072438955307,
      "learning_rate": 4.5268367608157694e-05,
      "loss": 0.003,
      "step": 11090
    },
    {
      "epoch": 0.9471797934977387,
      "grad_norm": 0.26930734515190125,
      "learning_rate": 4.526410103251131e-05,
      "loss": 0.0029,
      "step": 11100
    },
    {
      "epoch": 0.948033108627016,
      "grad_norm": 0.2541986107826233,
      "learning_rate": 4.525983445686492e-05,
      "loss": 0.0027,
      "step": 11110
    },
    {
      "epoch": 0.9488864237562932,
      "grad_norm": 0.17565196752548218,
      "learning_rate": 4.525556788121854e-05,
      "loss": 0.0033,
      "step": 11120
    },
    {
      "epoch": 0.9497397388855704,
      "grad_norm": 0.7183580994606018,
      "learning_rate": 4.525130130557215e-05,
      "loss": 0.0035,
      "step": 11130
    },
    {
      "epoch": 0.9505930540148477,
      "grad_norm": 0.45313379168510437,
      "learning_rate": 4.5247034729925765e-05,
      "loss": 0.0027,
      "step": 11140
    },
    {
      "epoch": 0.951446369144125,
      "grad_norm": 0.16437560319900513,
      "learning_rate": 4.524276815427938e-05,
      "loss": 0.0027,
      "step": 11150
    },
    {
      "epoch": 0.9522996842734022,
      "grad_norm": 0.05664006248116493,
      "learning_rate": 4.5238501578632994e-05,
      "loss": 0.0032,
      "step": 11160
    },
    {
      "epoch": 0.9531529994026794,
      "grad_norm": 0.5910152792930603,
      "learning_rate": 4.52342350029866e-05,
      "loss": 0.0034,
      "step": 11170
    },
    {
      "epoch": 0.9540063145319566,
      "grad_norm": 0.07037954777479172,
      "learning_rate": 4.522996842734022e-05,
      "loss": 0.0035,
      "step": 11180
    },
    {
      "epoch": 0.9548596296612339,
      "grad_norm": 0.11435192823410034,
      "learning_rate": 4.522570185169383e-05,
      "loss": 0.0037,
      "step": 11190
    },
    {
      "epoch": 0.9557129447905112,
      "grad_norm": 0.048159267753362656,
      "learning_rate": 4.5221435276047444e-05,
      "loss": 0.0031,
      "step": 11200
    },
    {
      "epoch": 0.9565662599197884,
      "grad_norm": 0.4721883535385132,
      "learning_rate": 4.521716870040106e-05,
      "loss": 0.003,
      "step": 11210
    },
    {
      "epoch": 0.9574195750490656,
      "grad_norm": 0.2299100011587143,
      "learning_rate": 4.521290212475467e-05,
      "loss": 0.0035,
      "step": 11220
    },
    {
      "epoch": 0.9582728901783428,
      "grad_norm": 0.4362157881259918,
      "learning_rate": 4.520863554910829e-05,
      "loss": 0.0022,
      "step": 11230
    },
    {
      "epoch": 0.95912620530762,
      "grad_norm": 0.35629206895828247,
      "learning_rate": 4.52043689734619e-05,
      "loss": 0.0037,
      "step": 11240
    },
    {
      "epoch": 0.9599795204368974,
      "grad_norm": 0.33406758308410645,
      "learning_rate": 4.5200102397815515e-05,
      "loss": 0.0031,
      "step": 11250
    },
    {
      "epoch": 0.9608328355661746,
      "grad_norm": 0.10011441260576248,
      "learning_rate": 4.519583582216913e-05,
      "loss": 0.0028,
      "step": 11260
    },
    {
      "epoch": 0.9616861506954518,
      "grad_norm": 0.38609951734542847,
      "learning_rate": 4.5191569246522744e-05,
      "loss": 0.0032,
      "step": 11270
    },
    {
      "epoch": 0.962539465824729,
      "grad_norm": 0.2745248079299927,
      "learning_rate": 4.518730267087636e-05,
      "loss": 0.003,
      "step": 11280
    },
    {
      "epoch": 0.9633927809540063,
      "grad_norm": 0.17124418914318085,
      "learning_rate": 4.518303609522997e-05,
      "loss": 0.0029,
      "step": 11290
    },
    {
      "epoch": 0.9642460960832836,
      "grad_norm": 0.5821139812469482,
      "learning_rate": 4.5178769519583586e-05,
      "loss": 0.0029,
      "step": 11300
    },
    {
      "epoch": 0.9650994112125608,
      "grad_norm": 0.40064412355422974,
      "learning_rate": 4.5174502943937194e-05,
      "loss": 0.003,
      "step": 11310
    },
    {
      "epoch": 0.965952726341838,
      "grad_norm": 0.13218973577022552,
      "learning_rate": 4.5170236368290815e-05,
      "loss": 0.0032,
      "step": 11320
    },
    {
      "epoch": 0.9668060414711153,
      "grad_norm": 0.30841633677482605,
      "learning_rate": 4.516596979264442e-05,
      "loss": 0.0027,
      "step": 11330
    },
    {
      "epoch": 0.9676593566003925,
      "grad_norm": 0.15719470381736755,
      "learning_rate": 4.5161703216998043e-05,
      "loss": 0.0026,
      "step": 11340
    },
    {
      "epoch": 0.9685126717296698,
      "grad_norm": 0.14440838992595673,
      "learning_rate": 4.515743664135165e-05,
      "loss": 0.0036,
      "step": 11350
    },
    {
      "epoch": 0.969365986858947,
      "grad_norm": 0.26996755599975586,
      "learning_rate": 4.515317006570527e-05,
      "loss": 0.0047,
      "step": 11360
    },
    {
      "epoch": 0.9702193019882243,
      "grad_norm": 0.3762552738189697,
      "learning_rate": 4.514890349005888e-05,
      "loss": 0.0023,
      "step": 11370
    },
    {
      "epoch": 0.9710726171175015,
      "grad_norm": 0.18212594091892242,
      "learning_rate": 4.5144636914412494e-05,
      "loss": 0.0032,
      "step": 11380
    },
    {
      "epoch": 0.9719259322467787,
      "grad_norm": 0.2727809548377991,
      "learning_rate": 4.514037033876611e-05,
      "loss": 0.0028,
      "step": 11390
    },
    {
      "epoch": 0.9727792473760559,
      "grad_norm": 0.13022838532924652,
      "learning_rate": 4.513610376311972e-05,
      "loss": 0.0028,
      "step": 11400
    },
    {
      "epoch": 0.9736325625053333,
      "grad_norm": 0.31974533200263977,
      "learning_rate": 4.5131837187473336e-05,
      "loss": 0.003,
      "step": 11410
    },
    {
      "epoch": 0.9744858776346105,
      "grad_norm": 0.3033505976200104,
      "learning_rate": 4.512757061182695e-05,
      "loss": 0.0028,
      "step": 11420
    },
    {
      "epoch": 0.9753391927638877,
      "grad_norm": 0.6769974231719971,
      "learning_rate": 4.5123304036180565e-05,
      "loss": 0.0027,
      "step": 11430
    },
    {
      "epoch": 0.9761925078931649,
      "grad_norm": 0.17705439031124115,
      "learning_rate": 4.511903746053417e-05,
      "loss": 0.0036,
      "step": 11440
    },
    {
      "epoch": 0.9770458230224421,
      "grad_norm": 0.27396127581596375,
      "learning_rate": 4.511477088488779e-05,
      "loss": 0.003,
      "step": 11450
    },
    {
      "epoch": 0.9778991381517195,
      "grad_norm": 0.527927041053772,
      "learning_rate": 4.51105043092414e-05,
      "loss": 0.0027,
      "step": 11460
    },
    {
      "epoch": 0.9787524532809967,
      "grad_norm": 0.2392527461051941,
      "learning_rate": 4.510623773359502e-05,
      "loss": 0.0032,
      "step": 11470
    },
    {
      "epoch": 0.9796057684102739,
      "grad_norm": 0.3017262816429138,
      "learning_rate": 4.510197115794863e-05,
      "loss": 0.0034,
      "step": 11480
    },
    {
      "epoch": 0.9804590835395511,
      "grad_norm": 0.3047872483730316,
      "learning_rate": 4.509770458230225e-05,
      "loss": 0.0029,
      "step": 11490
    },
    {
      "epoch": 0.9813123986688284,
      "grad_norm": 0.127914160490036,
      "learning_rate": 4.509343800665586e-05,
      "loss": 0.0036,
      "step": 11500
    },
    {
      "epoch": 0.9821657137981057,
      "grad_norm": 0.09836770594120026,
      "learning_rate": 4.508917143100947e-05,
      "loss": 0.0032,
      "step": 11510
    },
    {
      "epoch": 0.9830190289273829,
      "grad_norm": 0.3248438239097595,
      "learning_rate": 4.5084904855363086e-05,
      "loss": 0.0034,
      "step": 11520
    },
    {
      "epoch": 0.9838723440566601,
      "grad_norm": 0.15007059276103973,
      "learning_rate": 4.50806382797167e-05,
      "loss": 0.0035,
      "step": 11530
    },
    {
      "epoch": 0.9847256591859374,
      "grad_norm": 0.2840796113014221,
      "learning_rate": 4.5076371704070315e-05,
      "loss": 0.0039,
      "step": 11540
    },
    {
      "epoch": 0.9855789743152146,
      "grad_norm": 0.16914460062980652,
      "learning_rate": 4.507210512842393e-05,
      "loss": 0.0027,
      "step": 11550
    },
    {
      "epoch": 0.9864322894444919,
      "grad_norm": 0.18865959346294403,
      "learning_rate": 4.506783855277754e-05,
      "loss": 0.0037,
      "step": 11560
    },
    {
      "epoch": 0.9872856045737691,
      "grad_norm": 0.36441588401794434,
      "learning_rate": 4.506357197713116e-05,
      "loss": 0.0035,
      "step": 11570
    },
    {
      "epoch": 0.9881389197030463,
      "grad_norm": 0.22939740121364594,
      "learning_rate": 4.505930540148477e-05,
      "loss": 0.0028,
      "step": 11580
    },
    {
      "epoch": 0.9889922348323236,
      "grad_norm": 0.17055730521678925,
      "learning_rate": 4.5055038825838386e-05,
      "loss": 0.0027,
      "step": 11590
    },
    {
      "epoch": 0.9898455499616008,
      "grad_norm": 0.07763482630252838,
      "learning_rate": 4.5050772250192e-05,
      "loss": 0.0029,
      "step": 11600
    },
    {
      "epoch": 0.990698865090878,
      "grad_norm": 0.053313225507736206,
      "learning_rate": 4.5046505674545614e-05,
      "loss": 0.0024,
      "step": 11610
    },
    {
      "epoch": 0.9915521802201553,
      "grad_norm": 0.3305577337741852,
      "learning_rate": 4.504223909889922e-05,
      "loss": 0.0022,
      "step": 11620
    },
    {
      "epoch": 0.9924054953494326,
      "grad_norm": 0.40787941217422485,
      "learning_rate": 4.503797252325284e-05,
      "loss": 0.0034,
      "step": 11630
    },
    {
      "epoch": 0.9932588104787098,
      "grad_norm": 0.3778128921985626,
      "learning_rate": 4.503370594760645e-05,
      "loss": 0.0037,
      "step": 11640
    },
    {
      "epoch": 0.994112125607987,
      "grad_norm": 0.3916579782962799,
      "learning_rate": 4.502943937196007e-05,
      "loss": 0.0029,
      "step": 11650
    },
    {
      "epoch": 0.9949654407372642,
      "grad_norm": 0.12727856636047363,
      "learning_rate": 4.502517279631368e-05,
      "loss": 0.0035,
      "step": 11660
    },
    {
      "epoch": 0.9958187558665416,
      "grad_norm": 0.20661015808582306,
      "learning_rate": 4.50209062206673e-05,
      "loss": 0.0031,
      "step": 11670
    },
    {
      "epoch": 0.9966720709958188,
      "grad_norm": 0.2999899387359619,
      "learning_rate": 4.501663964502091e-05,
      "loss": 0.0025,
      "step": 11680
    },
    {
      "epoch": 0.997525386125096,
      "grad_norm": 0.07752306759357452,
      "learning_rate": 4.501237306937452e-05,
      "loss": 0.0032,
      "step": 11690
    },
    {
      "epoch": 0.9983787012543732,
      "grad_norm": 0.11576090008020401,
      "learning_rate": 4.5008106493728136e-05,
      "loss": 0.0035,
      "step": 11700
    },
    {
      "epoch": 0.9992320163836504,
      "grad_norm": 0.06428235024213791,
      "learning_rate": 4.500383991808175e-05,
      "loss": 0.0036,
      "step": 11710
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.003118994180113077,
      "eval_runtime": 98.3995,
      "eval_samples_per_second": 1524.398,
      "eval_steps_per_second": 23.821,
      "step": 11719
    },
    {
      "epoch": 1.0000853315129277,
      "grad_norm": 0.046507928520441055,
      "learning_rate": 4.4999573342435364e-05,
      "loss": 0.0032,
      "step": 11720
    },
    {
      "epoch": 1.000938646642205,
      "grad_norm": 0.27737534046173096,
      "learning_rate": 4.499530676678897e-05,
      "loss": 0.0031,
      "step": 11730
    },
    {
      "epoch": 1.001791961771482,
      "grad_norm": 0.19756516814231873,
      "learning_rate": 4.499104019114259e-05,
      "loss": 0.0031,
      "step": 11740
    },
    {
      "epoch": 1.0026452769007594,
      "grad_norm": 0.1946389079093933,
      "learning_rate": 4.49867736154962e-05,
      "loss": 0.0033,
      "step": 11750
    },
    {
      "epoch": 1.0034985920300368,
      "grad_norm": 0.1391858011484146,
      "learning_rate": 4.498250703984982e-05,
      "loss": 0.0031,
      "step": 11760
    },
    {
      "epoch": 1.0043519071593139,
      "grad_norm": 0.31913432478904724,
      "learning_rate": 4.497824046420343e-05,
      "loss": 0.0029,
      "step": 11770
    },
    {
      "epoch": 1.0052052222885912,
      "grad_norm": 0.4175320565700531,
      "learning_rate": 4.497397388855705e-05,
      "loss": 0.0032,
      "step": 11780
    },
    {
      "epoch": 1.0060585374178683,
      "grad_norm": 0.681201696395874,
      "learning_rate": 4.496970731291066e-05,
      "loss": 0.0029,
      "step": 11790
    },
    {
      "epoch": 1.0069118525471457,
      "grad_norm": 0.11444726586341858,
      "learning_rate": 4.496544073726428e-05,
      "loss": 0.0036,
      "step": 11800
    },
    {
      "epoch": 1.007765167676423,
      "grad_norm": 0.4716140627861023,
      "learning_rate": 4.4961174161617886e-05,
      "loss": 0.0039,
      "step": 11810
    },
    {
      "epoch": 1.0086184828057,
      "grad_norm": 0.4342923164367676,
      "learning_rate": 4.49569075859715e-05,
      "loss": 0.0036,
      "step": 11820
    },
    {
      "epoch": 1.0094717979349774,
      "grad_norm": 0.029151100665330887,
      "learning_rate": 4.4952641010325114e-05,
      "loss": 0.0033,
      "step": 11830
    },
    {
      "epoch": 1.0103251130642545,
      "grad_norm": 0.1230509951710701,
      "learning_rate": 4.494837443467873e-05,
      "loss": 0.0019,
      "step": 11840
    },
    {
      "epoch": 1.0111784281935319,
      "grad_norm": 0.029362397268414497,
      "learning_rate": 4.494410785903234e-05,
      "loss": 0.0036,
      "step": 11850
    },
    {
      "epoch": 1.0120317433228092,
      "grad_norm": 0.4974459409713745,
      "learning_rate": 4.493984128338596e-05,
      "loss": 0.0028,
      "step": 11860
    },
    {
      "epoch": 1.0128850584520863,
      "grad_norm": 0.5280887484550476,
      "learning_rate": 4.493557470773957e-05,
      "loss": 0.0029,
      "step": 11870
    },
    {
      "epoch": 1.0137383735813636,
      "grad_norm": 0.3249521553516388,
      "learning_rate": 4.4931308132093185e-05,
      "loss": 0.0027,
      "step": 11880
    },
    {
      "epoch": 1.0145916887106408,
      "grad_norm": 0.45622262358665466,
      "learning_rate": 4.49270415564468e-05,
      "loss": 0.0036,
      "step": 11890
    },
    {
      "epoch": 1.015445003839918,
      "grad_norm": 0.06538545340299606,
      "learning_rate": 4.4922774980800414e-05,
      "loss": 0.0028,
      "step": 11900
    },
    {
      "epoch": 1.0162983189691954,
      "grad_norm": 0.23431138694286346,
      "learning_rate": 4.491850840515403e-05,
      "loss": 0.0026,
      "step": 11910
    },
    {
      "epoch": 1.0171516340984725,
      "grad_norm": 0.2099892795085907,
      "learning_rate": 4.491424182950764e-05,
      "loss": 0.0024,
      "step": 11920
    },
    {
      "epoch": 1.0180049492277499,
      "grad_norm": 0.1645902693271637,
      "learning_rate": 4.490997525386125e-05,
      "loss": 0.003,
      "step": 11930
    },
    {
      "epoch": 1.018858264357027,
      "grad_norm": 0.07988519221544266,
      "learning_rate": 4.490570867821487e-05,
      "loss": 0.0029,
      "step": 11940
    },
    {
      "epoch": 1.0197115794863043,
      "grad_norm": 0.2553732097148895,
      "learning_rate": 4.490144210256848e-05,
      "loss": 0.0037,
      "step": 11950
    },
    {
      "epoch": 1.0205648946155816,
      "grad_norm": 0.09611618518829346,
      "learning_rate": 4.489717552692209e-05,
      "loss": 0.0022,
      "step": 11960
    },
    {
      "epoch": 1.0214182097448588,
      "grad_norm": 0.3978644013404846,
      "learning_rate": 4.489290895127571e-05,
      "loss": 0.003,
      "step": 11970
    },
    {
      "epoch": 1.022271524874136,
      "grad_norm": 0.32914048433303833,
      "learning_rate": 4.488864237562932e-05,
      "loss": 0.0028,
      "step": 11980
    },
    {
      "epoch": 1.0231248400034132,
      "grad_norm": 0.7409831881523132,
      "learning_rate": 4.4884375799982935e-05,
      "loss": 0.0022,
      "step": 11990
    },
    {
      "epoch": 1.0239781551326905,
      "grad_norm": 0.6510174870491028,
      "learning_rate": 4.488010922433655e-05,
      "loss": 0.0039,
      "step": 12000
    },
    {
      "epoch": 1.0248314702619676,
      "grad_norm": 0.5375770330429077,
      "learning_rate": 4.4875842648690164e-05,
      "loss": 0.0024,
      "step": 12010
    },
    {
      "epoch": 1.025684785391245,
      "grad_norm": 0.2286987155675888,
      "learning_rate": 4.487157607304378e-05,
      "loss": 0.0027,
      "step": 12020
    },
    {
      "epoch": 1.0265381005205223,
      "grad_norm": 0.1100560799241066,
      "learning_rate": 4.486730949739739e-05,
      "loss": 0.0028,
      "step": 12030
    },
    {
      "epoch": 1.0273914156497994,
      "grad_norm": 0.1919807493686676,
      "learning_rate": 4.4863042921751e-05,
      "loss": 0.0034,
      "step": 12040
    },
    {
      "epoch": 1.0282447307790767,
      "grad_norm": 0.2703152894973755,
      "learning_rate": 4.485877634610462e-05,
      "loss": 0.0021,
      "step": 12050
    },
    {
      "epoch": 1.0290980459083539,
      "grad_norm": 0.20509633421897888,
      "learning_rate": 4.485450977045823e-05,
      "loss": 0.0024,
      "step": 12060
    },
    {
      "epoch": 1.0299513610376312,
      "grad_norm": 0.05280984938144684,
      "learning_rate": 4.485024319481185e-05,
      "loss": 0.0028,
      "step": 12070
    },
    {
      "epoch": 1.0308046761669085,
      "grad_norm": 0.029679061844944954,
      "learning_rate": 4.4845976619165457e-05,
      "loss": 0.0036,
      "step": 12080
    },
    {
      "epoch": 1.0316579912961856,
      "grad_norm": 0.25168082118034363,
      "learning_rate": 4.484171004351908e-05,
      "loss": 0.003,
      "step": 12090
    },
    {
      "epoch": 1.032511306425463,
      "grad_norm": 0.047820575535297394,
      "learning_rate": 4.4837443467872685e-05,
      "loss": 0.0022,
      "step": 12100
    },
    {
      "epoch": 1.03336462155474,
      "grad_norm": 0.32684460282325745,
      "learning_rate": 4.4833176892226306e-05,
      "loss": 0.0027,
      "step": 12110
    },
    {
      "epoch": 1.0342179366840174,
      "grad_norm": 0.050416458398103714,
      "learning_rate": 4.4828910316579914e-05,
      "loss": 0.0025,
      "step": 12120
    },
    {
      "epoch": 1.0350712518132947,
      "grad_norm": 0.11793949455022812,
      "learning_rate": 4.482464374093353e-05,
      "loss": 0.0024,
      "step": 12130
    },
    {
      "epoch": 1.0359245669425718,
      "grad_norm": 0.04513496160507202,
      "learning_rate": 4.482037716528714e-05,
      "loss": 0.0028,
      "step": 12140
    },
    {
      "epoch": 1.0367778820718492,
      "grad_norm": 0.15610601007938385,
      "learning_rate": 4.4816110589640756e-05,
      "loss": 0.0036,
      "step": 12150
    },
    {
      "epoch": 1.0376311972011263,
      "grad_norm": 0.36273348331451416,
      "learning_rate": 4.481184401399437e-05,
      "loss": 0.0034,
      "step": 12160
    },
    {
      "epoch": 1.0384845123304036,
      "grad_norm": 0.2442680448293686,
      "learning_rate": 4.4807577438347985e-05,
      "loss": 0.0038,
      "step": 12170
    },
    {
      "epoch": 1.039337827459681,
      "grad_norm": 0.2542952299118042,
      "learning_rate": 4.48033108627016e-05,
      "loss": 0.0026,
      "step": 12180
    },
    {
      "epoch": 1.040191142588958,
      "grad_norm": 0.2144174873828888,
      "learning_rate": 4.479904428705521e-05,
      "loss": 0.0038,
      "step": 12190
    },
    {
      "epoch": 1.0410444577182354,
      "grad_norm": 0.28908002376556396,
      "learning_rate": 4.479477771140883e-05,
      "loss": 0.0024,
      "step": 12200
    },
    {
      "epoch": 1.0418977728475125,
      "grad_norm": 0.21301719546318054,
      "learning_rate": 4.479051113576244e-05,
      "loss": 0.0032,
      "step": 12210
    },
    {
      "epoch": 1.0427510879767898,
      "grad_norm": 0.10904511064291,
      "learning_rate": 4.4786244560116056e-05,
      "loss": 0.0037,
      "step": 12220
    },
    {
      "epoch": 1.0436044031060672,
      "grad_norm": 0.5826324820518494,
      "learning_rate": 4.4781977984469663e-05,
      "loss": 0.0033,
      "step": 12230
    },
    {
      "epoch": 1.0444577182353443,
      "grad_norm": 0.21094825863838196,
      "learning_rate": 4.477771140882328e-05,
      "loss": 0.0033,
      "step": 12240
    },
    {
      "epoch": 1.0453110333646216,
      "grad_norm": 0.1682911366224289,
      "learning_rate": 4.477344483317689e-05,
      "loss": 0.0027,
      "step": 12250
    },
    {
      "epoch": 1.0461643484938987,
      "grad_norm": 0.21254749596118927,
      "learning_rate": 4.4769178257530506e-05,
      "loss": 0.0038,
      "step": 12260
    },
    {
      "epoch": 1.047017663623176,
      "grad_norm": 0.13316774368286133,
      "learning_rate": 4.476491168188412e-05,
      "loss": 0.0026,
      "step": 12270
    },
    {
      "epoch": 1.0478709787524534,
      "grad_norm": 0.17544178664684296,
      "learning_rate": 4.4760645106237735e-05,
      "loss": 0.0025,
      "step": 12280
    },
    {
      "epoch": 1.0487242938817305,
      "grad_norm": 0.15907268226146698,
      "learning_rate": 4.475637853059135e-05,
      "loss": 0.0041,
      "step": 12290
    },
    {
      "epoch": 1.0495776090110078,
      "grad_norm": 0.44037723541259766,
      "learning_rate": 4.475211195494496e-05,
      "loss": 0.0031,
      "step": 12300
    },
    {
      "epoch": 1.050430924140285,
      "grad_norm": 0.7293749451637268,
      "learning_rate": 4.474784537929858e-05,
      "loss": 0.0027,
      "step": 12310
    },
    {
      "epoch": 1.0512842392695623,
      "grad_norm": 0.15840500593185425,
      "learning_rate": 4.474357880365219e-05,
      "loss": 0.0023,
      "step": 12320
    },
    {
      "epoch": 1.0521375543988394,
      "grad_norm": 0.044305719435214996,
      "learning_rate": 4.4739312228005806e-05,
      "loss": 0.0042,
      "step": 12330
    },
    {
      "epoch": 1.0529908695281167,
      "grad_norm": 0.060780905187129974,
      "learning_rate": 4.473504565235942e-05,
      "loss": 0.0023,
      "step": 12340
    },
    {
      "epoch": 1.053844184657394,
      "grad_norm": 0.02466784603893757,
      "learning_rate": 4.473077907671303e-05,
      "loss": 0.0033,
      "step": 12350
    },
    {
      "epoch": 1.0546974997866712,
      "grad_norm": 0.23111750185489655,
      "learning_rate": 4.472651250106665e-05,
      "loss": 0.0034,
      "step": 12360
    },
    {
      "epoch": 1.0555508149159485,
      "grad_norm": 0.17874372005462646,
      "learning_rate": 4.4722245925420256e-05,
      "loss": 0.003,
      "step": 12370
    },
    {
      "epoch": 1.0564041300452256,
      "grad_norm": 0.1927119344472885,
      "learning_rate": 4.471797934977388e-05,
      "loss": 0.0035,
      "step": 12380
    },
    {
      "epoch": 1.057257445174503,
      "grad_norm": 0.06365590542554855,
      "learning_rate": 4.4713712774127485e-05,
      "loss": 0.0028,
      "step": 12390
    },
    {
      "epoch": 1.0581107603037803,
      "grad_norm": 0.29089871048927307,
      "learning_rate": 4.4709446198481106e-05,
      "loss": 0.0035,
      "step": 12400
    },
    {
      "epoch": 1.0589640754330574,
      "grad_norm": 0.23191264271736145,
      "learning_rate": 4.470517962283471e-05,
      "loss": 0.0026,
      "step": 12410
    },
    {
      "epoch": 1.0598173905623347,
      "grad_norm": 0.08126688748598099,
      "learning_rate": 4.4700913047188334e-05,
      "loss": 0.003,
      "step": 12420
    },
    {
      "epoch": 1.0606707056916118,
      "grad_norm": 0.11027131229639053,
      "learning_rate": 4.469664647154194e-05,
      "loss": 0.003,
      "step": 12430
    },
    {
      "epoch": 1.0615240208208891,
      "grad_norm": 0.6305331587791443,
      "learning_rate": 4.4692379895895556e-05,
      "loss": 0.0037,
      "step": 12440
    },
    {
      "epoch": 1.0623773359501665,
      "grad_norm": 0.6518851518630981,
      "learning_rate": 4.468811332024917e-05,
      "loss": 0.0029,
      "step": 12450
    },
    {
      "epoch": 1.0632306510794436,
      "grad_norm": 0.23070791363716125,
      "learning_rate": 4.4683846744602784e-05,
      "loss": 0.0036,
      "step": 12460
    },
    {
      "epoch": 1.064083966208721,
      "grad_norm": 0.27058228850364685,
      "learning_rate": 4.46795801689564e-05,
      "loss": 0.0032,
      "step": 12470
    },
    {
      "epoch": 1.064937281337998,
      "grad_norm": 0.18930494785308838,
      "learning_rate": 4.467531359331001e-05,
      "loss": 0.0026,
      "step": 12480
    },
    {
      "epoch": 1.0657905964672754,
      "grad_norm": 0.39905908703804016,
      "learning_rate": 4.467104701766363e-05,
      "loss": 0.0042,
      "step": 12490
    },
    {
      "epoch": 1.0666439115965527,
      "grad_norm": 0.04870467260479927,
      "learning_rate": 4.4666780442017234e-05,
      "loss": 0.0027,
      "step": 12500
    },
    {
      "epoch": 1.0674972267258298,
      "grad_norm": 0.09684931486845016,
      "learning_rate": 4.4662513866370855e-05,
      "loss": 0.0028,
      "step": 12510
    },
    {
      "epoch": 1.0683505418551071,
      "grad_norm": 0.05983244627714157,
      "learning_rate": 4.465824729072446e-05,
      "loss": 0.0033,
      "step": 12520
    },
    {
      "epoch": 1.0692038569843842,
      "grad_norm": 0.13712890446186066,
      "learning_rate": 4.4653980715078084e-05,
      "loss": 0.0028,
      "step": 12530
    },
    {
      "epoch": 1.0700571721136616,
      "grad_norm": 0.2621381878852844,
      "learning_rate": 4.464971413943169e-05,
      "loss": 0.0036,
      "step": 12540
    },
    {
      "epoch": 1.070910487242939,
      "grad_norm": 0.1427268236875534,
      "learning_rate": 4.4645447563785306e-05,
      "loss": 0.003,
      "step": 12550
    },
    {
      "epoch": 1.071763802372216,
      "grad_norm": 0.18679045140743256,
      "learning_rate": 4.464118098813892e-05,
      "loss": 0.0033,
      "step": 12560
    },
    {
      "epoch": 1.0726171175014934,
      "grad_norm": 0.3428846001625061,
      "learning_rate": 4.4636914412492534e-05,
      "loss": 0.0034,
      "step": 12570
    },
    {
      "epoch": 1.0734704326307705,
      "grad_norm": 0.11348099261522293,
      "learning_rate": 4.463264783684615e-05,
      "loss": 0.003,
      "step": 12580
    },
    {
      "epoch": 1.0743237477600478,
      "grad_norm": 0.23258201777935028,
      "learning_rate": 4.462838126119976e-05,
      "loss": 0.0043,
      "step": 12590
    },
    {
      "epoch": 1.0751770628893251,
      "grad_norm": 0.24703878164291382,
      "learning_rate": 4.462411468555338e-05,
      "loss": 0.0042,
      "step": 12600
    },
    {
      "epoch": 1.0760303780186022,
      "grad_norm": 0.2219039350748062,
      "learning_rate": 4.461984810990699e-05,
      "loss": 0.0028,
      "step": 12610
    },
    {
      "epoch": 1.0768836931478796,
      "grad_norm": 0.27375343441963196,
      "learning_rate": 4.4615581534260605e-05,
      "loss": 0.003,
      "step": 12620
    },
    {
      "epoch": 1.0777370082771567,
      "grad_norm": 0.15618294477462769,
      "learning_rate": 4.461131495861422e-05,
      "loss": 0.0031,
      "step": 12630
    },
    {
      "epoch": 1.078590323406434,
      "grad_norm": 0.09637480229139328,
      "learning_rate": 4.4607048382967834e-05,
      "loss": 0.0026,
      "step": 12640
    },
    {
      "epoch": 1.0794436385357113,
      "grad_norm": 0.0629708543419838,
      "learning_rate": 4.460278180732145e-05,
      "loss": 0.0033,
      "step": 12650
    },
    {
      "epoch": 1.0802969536649885,
      "grad_norm": 0.05907058343291283,
      "learning_rate": 4.4598515231675055e-05,
      "loss": 0.0025,
      "step": 12660
    },
    {
      "epoch": 1.0811502687942658,
      "grad_norm": 0.8772159814834595,
      "learning_rate": 4.4594248656028676e-05,
      "loss": 0.0029,
      "step": 12670
    },
    {
      "epoch": 1.082003583923543,
      "grad_norm": 0.3656890392303467,
      "learning_rate": 4.4589982080382284e-05,
      "loss": 0.0027,
      "step": 12680
    },
    {
      "epoch": 1.0828568990528202,
      "grad_norm": 0.19671639800071716,
      "learning_rate": 4.4585715504735905e-05,
      "loss": 0.0034,
      "step": 12690
    },
    {
      "epoch": 1.0837102141820973,
      "grad_norm": 0.10595814138650894,
      "learning_rate": 4.458144892908951e-05,
      "loss": 0.0033,
      "step": 12700
    },
    {
      "epoch": 1.0845635293113747,
      "grad_norm": 0.042267683893442154,
      "learning_rate": 4.4577182353443133e-05,
      "loss": 0.0035,
      "step": 12710
    },
    {
      "epoch": 1.085416844440652,
      "grad_norm": 0.7073187232017517,
      "learning_rate": 4.457291577779674e-05,
      "loss": 0.0041,
      "step": 12720
    },
    {
      "epoch": 1.0862701595699291,
      "grad_norm": 0.19084621965885162,
      "learning_rate": 4.456864920215036e-05,
      "loss": 0.0029,
      "step": 12730
    },
    {
      "epoch": 1.0871234746992064,
      "grad_norm": 0.38128799200057983,
      "learning_rate": 4.456438262650397e-05,
      "loss": 0.0033,
      "step": 12740
    },
    {
      "epoch": 1.0879767898284836,
      "grad_norm": 0.20335806906223297,
      "learning_rate": 4.4560116050857584e-05,
      "loss": 0.0027,
      "step": 12750
    },
    {
      "epoch": 1.088830104957761,
      "grad_norm": 0.5002757906913757,
      "learning_rate": 4.45558494752112e-05,
      "loss": 0.0032,
      "step": 12760
    },
    {
      "epoch": 1.0896834200870382,
      "grad_norm": 0.07382841408252716,
      "learning_rate": 4.455158289956481e-05,
      "loss": 0.0036,
      "step": 12770
    },
    {
      "epoch": 1.0905367352163153,
      "grad_norm": 0.163938969373703,
      "learning_rate": 4.4547316323918426e-05,
      "loss": 0.004,
      "step": 12780
    },
    {
      "epoch": 1.0913900503455927,
      "grad_norm": 0.599788248538971,
      "learning_rate": 4.4543049748272034e-05,
      "loss": 0.0031,
      "step": 12790
    },
    {
      "epoch": 1.0922433654748698,
      "grad_norm": 0.28071129322052,
      "learning_rate": 4.4538783172625655e-05,
      "loss": 0.0026,
      "step": 12800
    },
    {
      "epoch": 1.093096680604147,
      "grad_norm": 0.1570519208908081,
      "learning_rate": 4.453451659697926e-05,
      "loss": 0.004,
      "step": 12810
    },
    {
      "epoch": 1.0939499957334244,
      "grad_norm": 0.5572026968002319,
      "learning_rate": 4.453025002133288e-05,
      "loss": 0.003,
      "step": 12820
    },
    {
      "epoch": 1.0948033108627016,
      "grad_norm": 0.18059657514095306,
      "learning_rate": 4.452598344568649e-05,
      "loss": 0.0035,
      "step": 12830
    },
    {
      "epoch": 1.0956566259919789,
      "grad_norm": 0.20990175008773804,
      "learning_rate": 4.452171687004011e-05,
      "loss": 0.0021,
      "step": 12840
    },
    {
      "epoch": 1.096509941121256,
      "grad_norm": 0.03765907883644104,
      "learning_rate": 4.451745029439372e-05,
      "loss": 0.0039,
      "step": 12850
    },
    {
      "epoch": 1.0973632562505333,
      "grad_norm": 0.17375721037387848,
      "learning_rate": 4.4513183718747334e-05,
      "loss": 0.0036,
      "step": 12860
    },
    {
      "epoch": 1.0982165713798107,
      "grad_norm": 0.14288094639778137,
      "learning_rate": 4.450891714310095e-05,
      "loss": 0.0033,
      "step": 12870
    },
    {
      "epoch": 1.0990698865090878,
      "grad_norm": 0.1551017165184021,
      "learning_rate": 4.450465056745456e-05,
      "loss": 0.0028,
      "step": 12880
    },
    {
      "epoch": 1.099923201638365,
      "grad_norm": 0.12944039702415466,
      "learning_rate": 4.4500383991808176e-05,
      "loss": 0.003,
      "step": 12890
    },
    {
      "epoch": 1.1007765167676422,
      "grad_norm": 0.17452919483184814,
      "learning_rate": 4.449611741616179e-05,
      "loss": 0.0026,
      "step": 12900
    },
    {
      "epoch": 1.1016298318969195,
      "grad_norm": 0.29156985878944397,
      "learning_rate": 4.4491850840515405e-05,
      "loss": 0.0029,
      "step": 12910
    },
    {
      "epoch": 1.1024831470261969,
      "grad_norm": 0.1936473399400711,
      "learning_rate": 4.448758426486902e-05,
      "loss": 0.003,
      "step": 12920
    },
    {
      "epoch": 1.103336462155474,
      "grad_norm": 0.5252388715744019,
      "learning_rate": 4.448331768922263e-05,
      "loss": 0.0039,
      "step": 12930
    },
    {
      "epoch": 1.1041897772847513,
      "grad_norm": 0.25782182812690735,
      "learning_rate": 4.447905111357625e-05,
      "loss": 0.0028,
      "step": 12940
    },
    {
      "epoch": 1.1050430924140284,
      "grad_norm": 0.15474340319633484,
      "learning_rate": 4.447478453792986e-05,
      "loss": 0.0038,
      "step": 12950
    },
    {
      "epoch": 1.1058964075433058,
      "grad_norm": 0.22392117977142334,
      "learning_rate": 4.4470517962283476e-05,
      "loss": 0.0034,
      "step": 12960
    },
    {
      "epoch": 1.1067497226725829,
      "grad_norm": 0.2776899039745331,
      "learning_rate": 4.4466251386637083e-05,
      "loss": 0.0035,
      "step": 12970
    },
    {
      "epoch": 1.1076030378018602,
      "grad_norm": 0.3393172323703766,
      "learning_rate": 4.4461984810990704e-05,
      "loss": 0.0036,
      "step": 12980
    },
    {
      "epoch": 1.1084563529311375,
      "grad_norm": 0.09948066622018814,
      "learning_rate": 4.445771823534431e-05,
      "loss": 0.0032,
      "step": 12990
    },
    {
      "epoch": 1.1093096680604146,
      "grad_norm": 0.6525465250015259,
      "learning_rate": 4.445345165969793e-05,
      "loss": 0.0025,
      "step": 13000
    },
    {
      "epoch": 1.110162983189692,
      "grad_norm": 0.20898230373859406,
      "learning_rate": 4.444918508405154e-05,
      "loss": 0.0029,
      "step": 13010
    },
    {
      "epoch": 1.1110162983189693,
      "grad_norm": 0.5055158138275146,
      "learning_rate": 4.444491850840516e-05,
      "loss": 0.0037,
      "step": 13020
    },
    {
      "epoch": 1.1118696134482464,
      "grad_norm": 0.3941309452056885,
      "learning_rate": 4.444065193275877e-05,
      "loss": 0.0029,
      "step": 13030
    },
    {
      "epoch": 1.1127229285775238,
      "grad_norm": 0.20731158554553986,
      "learning_rate": 4.443638535711238e-05,
      "loss": 0.0038,
      "step": 13040
    },
    {
      "epoch": 1.1135762437068009,
      "grad_norm": 0.40908578038215637,
      "learning_rate": 4.4432118781466e-05,
      "loss": 0.0036,
      "step": 13050
    },
    {
      "epoch": 1.1144295588360782,
      "grad_norm": 0.15906861424446106,
      "learning_rate": 4.442785220581961e-05,
      "loss": 0.0024,
      "step": 13060
    },
    {
      "epoch": 1.1152828739653553,
      "grad_norm": 0.17234095931053162,
      "learning_rate": 4.4423585630173226e-05,
      "loss": 0.0022,
      "step": 13070
    },
    {
      "epoch": 1.1161361890946326,
      "grad_norm": 0.17666614055633545,
      "learning_rate": 4.441931905452684e-05,
      "loss": 0.0024,
      "step": 13080
    },
    {
      "epoch": 1.11698950422391,
      "grad_norm": 0.1809166967868805,
      "learning_rate": 4.4415052478880454e-05,
      "loss": 0.0032,
      "step": 13090
    },
    {
      "epoch": 1.117842819353187,
      "grad_norm": 0.1954115778207779,
      "learning_rate": 4.441078590323406e-05,
      "loss": 0.0032,
      "step": 13100
    },
    {
      "epoch": 1.1186961344824644,
      "grad_norm": 0.10353563725948334,
      "learning_rate": 4.440651932758768e-05,
      "loss": 0.0027,
      "step": 13110
    },
    {
      "epoch": 1.1195494496117415,
      "grad_norm": 0.703877329826355,
      "learning_rate": 4.440225275194129e-05,
      "loss": 0.0031,
      "step": 13120
    },
    {
      "epoch": 1.1204027647410189,
      "grad_norm": 0.042494405061006546,
      "learning_rate": 4.439798617629491e-05,
      "loss": 0.003,
      "step": 13130
    },
    {
      "epoch": 1.1212560798702962,
      "grad_norm": 0.07429956644773483,
      "learning_rate": 4.439371960064852e-05,
      "loss": 0.0031,
      "step": 13140
    },
    {
      "epoch": 1.1221093949995733,
      "grad_norm": 0.050077617168426514,
      "learning_rate": 4.438945302500214e-05,
      "loss": 0.0025,
      "step": 13150
    },
    {
      "epoch": 1.1229627101288506,
      "grad_norm": 0.06239927560091019,
      "learning_rate": 4.438518644935575e-05,
      "loss": 0.0028,
      "step": 13160
    },
    {
      "epoch": 1.1238160252581277,
      "grad_norm": 0.2333483248949051,
      "learning_rate": 4.438091987370936e-05,
      "loss": 0.0033,
      "step": 13170
    },
    {
      "epoch": 1.124669340387405,
      "grad_norm": 0.05073276534676552,
      "learning_rate": 4.4376653298062976e-05,
      "loss": 0.0033,
      "step": 13180
    },
    {
      "epoch": 1.1255226555166824,
      "grad_norm": 0.12458555400371552,
      "learning_rate": 4.437238672241659e-05,
      "loss": 0.0035,
      "step": 13190
    },
    {
      "epoch": 1.1263759706459595,
      "grad_norm": 0.031267303973436356,
      "learning_rate": 4.4368120146770204e-05,
      "loss": 0.0025,
      "step": 13200
    },
    {
      "epoch": 1.1272292857752368,
      "grad_norm": 0.18907412886619568,
      "learning_rate": 4.436385357112382e-05,
      "loss": 0.0031,
      "step": 13210
    },
    {
      "epoch": 1.128082600904514,
      "grad_norm": 0.12081962823867798,
      "learning_rate": 4.435958699547743e-05,
      "loss": 0.0027,
      "step": 13220
    },
    {
      "epoch": 1.1289359160337913,
      "grad_norm": 0.14605389535427094,
      "learning_rate": 4.435532041983105e-05,
      "loss": 0.0038,
      "step": 13230
    },
    {
      "epoch": 1.1297892311630684,
      "grad_norm": 0.14932340383529663,
      "learning_rate": 4.435105384418466e-05,
      "loss": 0.0026,
      "step": 13240
    },
    {
      "epoch": 1.1306425462923457,
      "grad_norm": 0.3109530210494995,
      "learning_rate": 4.4346787268538275e-05,
      "loss": 0.0024,
      "step": 13250
    },
    {
      "epoch": 1.131495861421623,
      "grad_norm": 0.36673271656036377,
      "learning_rate": 4.434252069289189e-05,
      "loss": 0.0025,
      "step": 13260
    },
    {
      "epoch": 1.1323491765509002,
      "grad_norm": 0.1682875007390976,
      "learning_rate": 4.4338254117245504e-05,
      "loss": 0.0033,
      "step": 13270
    },
    {
      "epoch": 1.1332024916801775,
      "grad_norm": 0.3290872573852539,
      "learning_rate": 4.433398754159911e-05,
      "loss": 0.0027,
      "step": 13280
    },
    {
      "epoch": 1.1340558068094548,
      "grad_norm": 0.2735740542411804,
      "learning_rate": 4.4329720965952726e-05,
      "loss": 0.0024,
      "step": 13290
    },
    {
      "epoch": 1.134909121938732,
      "grad_norm": 0.11884678155183792,
      "learning_rate": 4.432545439030634e-05,
      "loss": 0.0029,
      "step": 13300
    },
    {
      "epoch": 1.1357624370680093,
      "grad_norm": 0.44375938177108765,
      "learning_rate": 4.4321187814659954e-05,
      "loss": 0.0033,
      "step": 13310
    },
    {
      "epoch": 1.1366157521972864,
      "grad_norm": 0.32444047927856445,
      "learning_rate": 4.431692123901357e-05,
      "loss": 0.0031,
      "step": 13320
    },
    {
      "epoch": 1.1374690673265637,
      "grad_norm": 0.09699253737926483,
      "learning_rate": 4.431265466336718e-05,
      "loss": 0.0026,
      "step": 13330
    },
    {
      "epoch": 1.1383223824558408,
      "grad_norm": 0.05033628270030022,
      "learning_rate": 4.43083880877208e-05,
      "loss": 0.0034,
      "step": 13340
    },
    {
      "epoch": 1.1391756975851182,
      "grad_norm": 0.21573995053768158,
      "learning_rate": 4.430412151207441e-05,
      "loss": 0.002,
      "step": 13350
    },
    {
      "epoch": 1.1400290127143955,
      "grad_norm": 0.47509971261024475,
      "learning_rate": 4.4299854936428025e-05,
      "loss": 0.0032,
      "step": 13360
    },
    {
      "epoch": 1.1408823278436726,
      "grad_norm": 0.40932729840278625,
      "learning_rate": 4.429558836078164e-05,
      "loss": 0.0031,
      "step": 13370
    },
    {
      "epoch": 1.14173564297295,
      "grad_norm": 0.26226407289505005,
      "learning_rate": 4.4291321785135254e-05,
      "loss": 0.0029,
      "step": 13380
    },
    {
      "epoch": 1.1425889581022273,
      "grad_norm": 0.24943384528160095,
      "learning_rate": 4.428705520948887e-05,
      "loss": 0.0028,
      "step": 13390
    },
    {
      "epoch": 1.1434422732315044,
      "grad_norm": 0.3532187044620514,
      "learning_rate": 4.428278863384248e-05,
      "loss": 0.0033,
      "step": 13400
    },
    {
      "epoch": 1.1442955883607817,
      "grad_norm": 0.2026917189359665,
      "learning_rate": 4.427852205819609e-05,
      "loss": 0.0027,
      "step": 13410
    },
    {
      "epoch": 1.1451489034900588,
      "grad_norm": 0.057282134890556335,
      "learning_rate": 4.427425548254971e-05,
      "loss": 0.0035,
      "step": 13420
    },
    {
      "epoch": 1.1460022186193362,
      "grad_norm": 0.0940905511379242,
      "learning_rate": 4.426998890690332e-05,
      "loss": 0.0023,
      "step": 13430
    },
    {
      "epoch": 1.1468555337486133,
      "grad_norm": 0.03776143491268158,
      "learning_rate": 4.426572233125694e-05,
      "loss": 0.0027,
      "step": 13440
    },
    {
      "epoch": 1.1477088488778906,
      "grad_norm": 0.27950534224510193,
      "learning_rate": 4.426145575561055e-05,
      "loss": 0.003,
      "step": 13450
    },
    {
      "epoch": 1.148562164007168,
      "grad_norm": 0.1918889731168747,
      "learning_rate": 4.425718917996417e-05,
      "loss": 0.0035,
      "step": 13460
    },
    {
      "epoch": 1.149415479136445,
      "grad_norm": 0.3008778691291809,
      "learning_rate": 4.4252922604317775e-05,
      "loss": 0.0036,
      "step": 13470
    },
    {
      "epoch": 1.1502687942657224,
      "grad_norm": 0.14453023672103882,
      "learning_rate": 4.424865602867139e-05,
      "loss": 0.0033,
      "step": 13480
    },
    {
      "epoch": 1.1511221093949995,
      "grad_norm": 0.08214112371206284,
      "learning_rate": 4.4244389453025004e-05,
      "loss": 0.0026,
      "step": 13490
    },
    {
      "epoch": 1.1519754245242768,
      "grad_norm": 0.4580911099910736,
      "learning_rate": 4.424012287737862e-05,
      "loss": 0.0025,
      "step": 13500
    },
    {
      "epoch": 1.1528287396535541,
      "grad_norm": 0.36611297726631165,
      "learning_rate": 4.423585630173223e-05,
      "loss": 0.0032,
      "step": 13510
    },
    {
      "epoch": 1.1536820547828313,
      "grad_norm": 0.34692248702049255,
      "learning_rate": 4.4231589726085846e-05,
      "loss": 0.003,
      "step": 13520
    },
    {
      "epoch": 1.1545353699121086,
      "grad_norm": 0.19621846079826355,
      "learning_rate": 4.422732315043946e-05,
      "loss": 0.002,
      "step": 13530
    },
    {
      "epoch": 1.1553886850413857,
      "grad_norm": 0.0796525701880455,
      "learning_rate": 4.4223056574793075e-05,
      "loss": 0.0036,
      "step": 13540
    },
    {
      "epoch": 1.156242000170663,
      "grad_norm": 0.08570519834756851,
      "learning_rate": 4.421878999914669e-05,
      "loss": 0.003,
      "step": 13550
    },
    {
      "epoch": 1.1570953152999404,
      "grad_norm": 0.08240792155265808,
      "learning_rate": 4.4214523423500297e-05,
      "loss": 0.0027,
      "step": 13560
    },
    {
      "epoch": 1.1579486304292175,
      "grad_norm": 0.06473523378372192,
      "learning_rate": 4.421025684785392e-05,
      "loss": 0.003,
      "step": 13570
    },
    {
      "epoch": 1.1588019455584948,
      "grad_norm": 0.252937376499176,
      "learning_rate": 4.4205990272207525e-05,
      "loss": 0.003,
      "step": 13580
    },
    {
      "epoch": 1.159655260687772,
      "grad_norm": 0.1719479113817215,
      "learning_rate": 4.420172369656114e-05,
      "loss": 0.0022,
      "step": 13590
    },
    {
      "epoch": 1.1605085758170492,
      "grad_norm": 0.26264533400535583,
      "learning_rate": 4.4197457120914753e-05,
      "loss": 0.0029,
      "step": 13600
    },
    {
      "epoch": 1.1613618909463264,
      "grad_norm": 0.2500811219215393,
      "learning_rate": 4.419319054526837e-05,
      "loss": 0.0027,
      "step": 13610
    },
    {
      "epoch": 1.1622152060756037,
      "grad_norm": 0.08902499079704285,
      "learning_rate": 4.418892396962198e-05,
      "loss": 0.0027,
      "step": 13620
    },
    {
      "epoch": 1.163068521204881,
      "grad_norm": 0.3407689332962036,
      "learning_rate": 4.4184657393975596e-05,
      "loss": 0.003,
      "step": 13630
    },
    {
      "epoch": 1.1639218363341581,
      "grad_norm": 0.06090567633509636,
      "learning_rate": 4.418039081832921e-05,
      "loss": 0.0028,
      "step": 13640
    },
    {
      "epoch": 1.1647751514634355,
      "grad_norm": 0.04701274633407593,
      "learning_rate": 4.4176124242682825e-05,
      "loss": 0.0026,
      "step": 13650
    },
    {
      "epoch": 1.1656284665927128,
      "grad_norm": 0.06116693839430809,
      "learning_rate": 4.417185766703644e-05,
      "loss": 0.0027,
      "step": 13660
    },
    {
      "epoch": 1.16648178172199,
      "grad_norm": 0.04314538091421127,
      "learning_rate": 4.416759109139005e-05,
      "loss": 0.0028,
      "step": 13670
    },
    {
      "epoch": 1.1673350968512672,
      "grad_norm": 0.04388077184557915,
      "learning_rate": 4.416332451574367e-05,
      "loss": 0.0025,
      "step": 13680
    },
    {
      "epoch": 1.1681884119805444,
      "grad_norm": 0.06525284051895142,
      "learning_rate": 4.415905794009728e-05,
      "loss": 0.0028,
      "step": 13690
    },
    {
      "epoch": 1.1690417271098217,
      "grad_norm": 0.33959221839904785,
      "learning_rate": 4.4154791364450896e-05,
      "loss": 0.0023,
      "step": 13700
    },
    {
      "epoch": 1.1698950422390988,
      "grad_norm": 0.03297112509608269,
      "learning_rate": 4.415052478880451e-05,
      "loss": 0.0023,
      "step": 13710
    },
    {
      "epoch": 1.1707483573683761,
      "grad_norm": 0.17092180252075195,
      "learning_rate": 4.414625821315812e-05,
      "loss": 0.0027,
      "step": 13720
    },
    {
      "epoch": 1.1716016724976535,
      "grad_norm": 0.32829418778419495,
      "learning_rate": 4.414199163751174e-05,
      "loss": 0.0032,
      "step": 13730
    },
    {
      "epoch": 1.1724549876269306,
      "grad_norm": 0.15690013766288757,
      "learning_rate": 4.4137725061865346e-05,
      "loss": 0.0032,
      "step": 13740
    },
    {
      "epoch": 1.173308302756208,
      "grad_norm": 0.2498679757118225,
      "learning_rate": 4.413345848621897e-05,
      "loss": 0.0029,
      "step": 13750
    },
    {
      "epoch": 1.1741616178854852,
      "grad_norm": 0.31353458762168884,
      "learning_rate": 4.4129191910572575e-05,
      "loss": 0.0036,
      "step": 13760
    },
    {
      "epoch": 1.1750149330147623,
      "grad_norm": 0.0713975802063942,
      "learning_rate": 4.4124925334926196e-05,
      "loss": 0.0044,
      "step": 13770
    },
    {
      "epoch": 1.1758682481440397,
      "grad_norm": 0.0818907767534256,
      "learning_rate": 4.41206587592798e-05,
      "loss": 0.0027,
      "step": 13780
    },
    {
      "epoch": 1.1767215632733168,
      "grad_norm": 0.09414210170507431,
      "learning_rate": 4.411639218363342e-05,
      "loss": 0.0039,
      "step": 13790
    },
    {
      "epoch": 1.1775748784025941,
      "grad_norm": 0.10259353369474411,
      "learning_rate": 4.411212560798703e-05,
      "loss": 0.0032,
      "step": 13800
    },
    {
      "epoch": 1.1784281935318712,
      "grad_norm": 0.0826849639415741,
      "learning_rate": 4.4107859032340646e-05,
      "loss": 0.0027,
      "step": 13810
    },
    {
      "epoch": 1.1792815086611486,
      "grad_norm": 0.5485720038414001,
      "learning_rate": 4.410359245669426e-05,
      "loss": 0.0024,
      "step": 13820
    },
    {
      "epoch": 1.180134823790426,
      "grad_norm": 0.15617544949054718,
      "learning_rate": 4.409932588104787e-05,
      "loss": 0.0034,
      "step": 13830
    },
    {
      "epoch": 1.180988138919703,
      "grad_norm": 0.1130758672952652,
      "learning_rate": 4.409505930540149e-05,
      "loss": 0.0042,
      "step": 13840
    },
    {
      "epoch": 1.1818414540489803,
      "grad_norm": 0.07373357564210892,
      "learning_rate": 4.4090792729755096e-05,
      "loss": 0.0033,
      "step": 13850
    },
    {
      "epoch": 1.1826947691782574,
      "grad_norm": 0.24951153993606567,
      "learning_rate": 4.408652615410872e-05,
      "loss": 0.0028,
      "step": 13860
    },
    {
      "epoch": 1.1835480843075348,
      "grad_norm": 0.1533653885126114,
      "learning_rate": 4.4082259578462324e-05,
      "loss": 0.0024,
      "step": 13870
    },
    {
      "epoch": 1.184401399436812,
      "grad_norm": 0.40496522188186646,
      "learning_rate": 4.4077993002815945e-05,
      "loss": 0.0031,
      "step": 13880
    },
    {
      "epoch": 1.1852547145660892,
      "grad_norm": 0.32575926184654236,
      "learning_rate": 4.407372642716955e-05,
      "loss": 0.0034,
      "step": 13890
    },
    {
      "epoch": 1.1861080296953666,
      "grad_norm": 0.11386416852474213,
      "learning_rate": 4.406945985152317e-05,
      "loss": 0.0032,
      "step": 13900
    },
    {
      "epoch": 1.1869613448246437,
      "grad_norm": 0.3257244825363159,
      "learning_rate": 4.406519327587678e-05,
      "loss": 0.0028,
      "step": 13910
    },
    {
      "epoch": 1.187814659953921,
      "grad_norm": 0.32481035590171814,
      "learning_rate": 4.4060926700230396e-05,
      "loss": 0.0028,
      "step": 13920
    },
    {
      "epoch": 1.1886679750831983,
      "grad_norm": 0.18118904531002045,
      "learning_rate": 4.405666012458401e-05,
      "loss": 0.0041,
      "step": 13930
    },
    {
      "epoch": 1.1895212902124754,
      "grad_norm": 0.2113005518913269,
      "learning_rate": 4.4052393548937624e-05,
      "loss": 0.0028,
      "step": 13940
    },
    {
      "epoch": 1.1903746053417528,
      "grad_norm": 0.2290678173303604,
      "learning_rate": 4.404812697329124e-05,
      "loss": 0.0029,
      "step": 13950
    },
    {
      "epoch": 1.1912279204710299,
      "grad_norm": 0.07419873774051666,
      "learning_rate": 4.404386039764485e-05,
      "loss": 0.0034,
      "step": 13960
    },
    {
      "epoch": 1.1920812356003072,
      "grad_norm": 0.9586221575737,
      "learning_rate": 4.403959382199847e-05,
      "loss": 0.0034,
      "step": 13970
    },
    {
      "epoch": 1.1929345507295843,
      "grad_norm": 0.14036786556243896,
      "learning_rate": 4.403532724635208e-05,
      "loss": 0.0033,
      "step": 13980
    },
    {
      "epoch": 1.1937878658588617,
      "grad_norm": 0.13949601352214813,
      "learning_rate": 4.4031060670705695e-05,
      "loss": 0.0024,
      "step": 13990
    },
    {
      "epoch": 1.194641180988139,
      "grad_norm": 0.10522779822349548,
      "learning_rate": 4.402679409505931e-05,
      "loss": 0.003,
      "step": 14000
    },
    {
      "epoch": 1.195494496117416,
      "grad_norm": 0.16881676018238068,
      "learning_rate": 4.4022527519412924e-05,
      "loss": 0.0024,
      "step": 14010
    },
    {
      "epoch": 1.1963478112466934,
      "grad_norm": 0.388971209526062,
      "learning_rate": 4.401826094376654e-05,
      "loss": 0.0026,
      "step": 14020
    },
    {
      "epoch": 1.1972011263759708,
      "grad_norm": 0.1622968167066574,
      "learning_rate": 4.4013994368120146e-05,
      "loss": 0.0032,
      "step": 14030
    },
    {
      "epoch": 1.1980544415052479,
      "grad_norm": 0.6493930816650391,
      "learning_rate": 4.4009727792473767e-05,
      "loss": 0.0027,
      "step": 14040
    },
    {
      "epoch": 1.1989077566345252,
      "grad_norm": 0.13330888748168945,
      "learning_rate": 4.4005461216827374e-05,
      "loss": 0.0028,
      "step": 14050
    },
    {
      "epoch": 1.1997610717638023,
      "grad_norm": 0.25296011567115784,
      "learning_rate": 4.4001194641180995e-05,
      "loss": 0.0027,
      "step": 14060
    },
    {
      "epoch": 1.2006143868930796,
      "grad_norm": 0.3333539366722107,
      "learning_rate": 4.39969280655346e-05,
      "loss": 0.0036,
      "step": 14070
    },
    {
      "epoch": 1.2014677020223568,
      "grad_norm": 0.21646544337272644,
      "learning_rate": 4.3992661489888223e-05,
      "loss": 0.0032,
      "step": 14080
    },
    {
      "epoch": 1.202321017151634,
      "grad_norm": 0.32980477809906006,
      "learning_rate": 4.398839491424183e-05,
      "loss": 0.0026,
      "step": 14090
    },
    {
      "epoch": 1.2031743322809114,
      "grad_norm": 0.5999011993408203,
      "learning_rate": 4.3984128338595445e-05,
      "loss": 0.0022,
      "step": 14100
    },
    {
      "epoch": 1.2040276474101885,
      "grad_norm": 0.32692718505859375,
      "learning_rate": 4.397986176294906e-05,
      "loss": 0.0029,
      "step": 14110
    },
    {
      "epoch": 1.2048809625394659,
      "grad_norm": 0.166701078414917,
      "learning_rate": 4.3975595187302674e-05,
      "loss": 0.0037,
      "step": 14120
    },
    {
      "epoch": 1.205734277668743,
      "grad_norm": 0.3810821771621704,
      "learning_rate": 4.397132861165629e-05,
      "loss": 0.003,
      "step": 14130
    },
    {
      "epoch": 1.2065875927980203,
      "grad_norm": 0.3403324782848358,
      "learning_rate": 4.3967062036009895e-05,
      "loss": 0.0036,
      "step": 14140
    },
    {
      "epoch": 1.2074409079272976,
      "grad_norm": 0.2961108982563019,
      "learning_rate": 4.3962795460363516e-05,
      "loss": 0.0037,
      "step": 14150
    },
    {
      "epoch": 1.2082942230565747,
      "grad_norm": 0.34503352642059326,
      "learning_rate": 4.3958528884717124e-05,
      "loss": 0.0027,
      "step": 14160
    },
    {
      "epoch": 1.209147538185852,
      "grad_norm": 0.31105926632881165,
      "learning_rate": 4.3954262309070745e-05,
      "loss": 0.0031,
      "step": 14170
    },
    {
      "epoch": 1.2100008533151292,
      "grad_norm": 0.445301353931427,
      "learning_rate": 4.394999573342435e-05,
      "loss": 0.0029,
      "step": 14180
    },
    {
      "epoch": 1.2108541684444065,
      "grad_norm": 0.24631819128990173,
      "learning_rate": 4.394572915777797e-05,
      "loss": 0.0024,
      "step": 14190
    },
    {
      "epoch": 1.2117074835736839,
      "grad_norm": 0.3374902904033661,
      "learning_rate": 4.394146258213158e-05,
      "loss": 0.004,
      "step": 14200
    },
    {
      "epoch": 1.212560798702961,
      "grad_norm": 0.18710725009441376,
      "learning_rate": 4.3937196006485195e-05,
      "loss": 0.0033,
      "step": 14210
    },
    {
      "epoch": 1.2134141138322383,
      "grad_norm": 0.2894152104854584,
      "learning_rate": 4.393292943083881e-05,
      "loss": 0.0032,
      "step": 14220
    },
    {
      "epoch": 1.2142674289615154,
      "grad_norm": 0.511513888835907,
      "learning_rate": 4.3928662855192424e-05,
      "loss": 0.0034,
      "step": 14230
    },
    {
      "epoch": 1.2151207440907927,
      "grad_norm": 0.23368024826049805,
      "learning_rate": 4.392439627954604e-05,
      "loss": 0.0028,
      "step": 14240
    },
    {
      "epoch": 1.2159740592200698,
      "grad_norm": 0.4994456470012665,
      "learning_rate": 4.392012970389965e-05,
      "loss": 0.0036,
      "step": 14250
    },
    {
      "epoch": 1.2168273743493472,
      "grad_norm": 0.2403544783592224,
      "learning_rate": 4.3915863128253266e-05,
      "loss": 0.0037,
      "step": 14260
    },
    {
      "epoch": 1.2176806894786245,
      "grad_norm": 0.11409977078437805,
      "learning_rate": 4.391159655260688e-05,
      "loss": 0.0028,
      "step": 14270
    },
    {
      "epoch": 1.2185340046079016,
      "grad_norm": 0.04913870617747307,
      "learning_rate": 4.3907329976960495e-05,
      "loss": 0.0031,
      "step": 14280
    },
    {
      "epoch": 1.219387319737179,
      "grad_norm": 0.10125232487916946,
      "learning_rate": 4.390306340131411e-05,
      "loss": 0.0028,
      "step": 14290
    },
    {
      "epoch": 1.2202406348664563,
      "grad_norm": 0.3405252695083618,
      "learning_rate": 4.389879682566772e-05,
      "loss": 0.0029,
      "step": 14300
    },
    {
      "epoch": 1.2210939499957334,
      "grad_norm": 0.21154864132404327,
      "learning_rate": 4.389453025002134e-05,
      "loss": 0.0024,
      "step": 14310
    },
    {
      "epoch": 1.2219472651250107,
      "grad_norm": 0.3361460268497467,
      "learning_rate": 4.389026367437495e-05,
      "loss": 0.0025,
      "step": 14320
    },
    {
      "epoch": 1.2228005802542878,
      "grad_norm": 0.22382450103759766,
      "learning_rate": 4.3885997098728566e-05,
      "loss": 0.0029,
      "step": 14330
    },
    {
      "epoch": 1.2236538953835652,
      "grad_norm": 0.13557098805904388,
      "learning_rate": 4.3881730523082173e-05,
      "loss": 0.0028,
      "step": 14340
    },
    {
      "epoch": 1.2245072105128423,
      "grad_norm": 0.12991857528686523,
      "learning_rate": 4.387746394743579e-05,
      "loss": 0.003,
      "step": 14350
    },
    {
      "epoch": 1.2253605256421196,
      "grad_norm": 0.24914728105068207,
      "learning_rate": 4.38731973717894e-05,
      "loss": 0.003,
      "step": 14360
    },
    {
      "epoch": 1.226213840771397,
      "grad_norm": 0.5134444832801819,
      "learning_rate": 4.3868930796143016e-05,
      "loss": 0.0034,
      "step": 14370
    },
    {
      "epoch": 1.227067155900674,
      "grad_norm": 0.07891566306352615,
      "learning_rate": 4.386466422049663e-05,
      "loss": 0.0031,
      "step": 14380
    },
    {
      "epoch": 1.2279204710299514,
      "grad_norm": 0.6234760284423828,
      "learning_rate": 4.3860397644850245e-05,
      "loss": 0.0035,
      "step": 14390
    },
    {
      "epoch": 1.2287737861592287,
      "grad_norm": 0.40446650981903076,
      "learning_rate": 4.385613106920386e-05,
      "loss": 0.0029,
      "step": 14400
    },
    {
      "epoch": 1.2296271012885058,
      "grad_norm": 0.32661113142967224,
      "learning_rate": 4.385186449355747e-05,
      "loss": 0.003,
      "step": 14410
    },
    {
      "epoch": 1.2304804164177832,
      "grad_norm": 0.10909494757652283,
      "learning_rate": 4.384759791791109e-05,
      "loss": 0.003,
      "step": 14420
    },
    {
      "epoch": 1.2313337315470603,
      "grad_norm": 0.20459632575511932,
      "learning_rate": 4.38433313422647e-05,
      "loss": 0.0036,
      "step": 14430
    },
    {
      "epoch": 1.2321870466763376,
      "grad_norm": 0.24721761047840118,
      "learning_rate": 4.3839064766618316e-05,
      "loss": 0.0034,
      "step": 14440
    },
    {
      "epoch": 1.2330403618056147,
      "grad_norm": 0.07688786089420319,
      "learning_rate": 4.383479819097192e-05,
      "loss": 0.0026,
      "step": 14450
    },
    {
      "epoch": 1.233893676934892,
      "grad_norm": 0.274636447429657,
      "learning_rate": 4.3830531615325544e-05,
      "loss": 0.0028,
      "step": 14460
    },
    {
      "epoch": 1.2347469920641694,
      "grad_norm": 0.0723145455121994,
      "learning_rate": 4.382626503967915e-05,
      "loss": 0.003,
      "step": 14470
    },
    {
      "epoch": 1.2356003071934465,
      "grad_norm": 0.03791232779622078,
      "learning_rate": 4.382199846403277e-05,
      "loss": 0.003,
      "step": 14480
    },
    {
      "epoch": 1.2364536223227238,
      "grad_norm": 0.4310857951641083,
      "learning_rate": 4.381773188838638e-05,
      "loss": 0.0026,
      "step": 14490
    },
    {
      "epoch": 1.237306937452001,
      "grad_norm": 0.561138391494751,
      "learning_rate": 4.381346531274e-05,
      "loss": 0.0036,
      "step": 14500
    },
    {
      "epoch": 1.2381602525812783,
      "grad_norm": 0.6734718680381775,
      "learning_rate": 4.380919873709361e-05,
      "loss": 0.0039,
      "step": 14510
    },
    {
      "epoch": 1.2390135677105556,
      "grad_norm": 0.17256730794906616,
      "learning_rate": 4.380493216144722e-05,
      "loss": 0.0024,
      "step": 14520
    },
    {
      "epoch": 1.2398668828398327,
      "grad_norm": 0.4408535063266754,
      "learning_rate": 4.380066558580084e-05,
      "loss": 0.0022,
      "step": 14530
    },
    {
      "epoch": 1.24072019796911,
      "grad_norm": 0.3084091246128082,
      "learning_rate": 4.379639901015445e-05,
      "loss": 0.0038,
      "step": 14540
    },
    {
      "epoch": 1.2415735130983871,
      "grad_norm": 0.48568785190582275,
      "learning_rate": 4.3792132434508066e-05,
      "loss": 0.003,
      "step": 14550
    },
    {
      "epoch": 1.2424268282276645,
      "grad_norm": 0.31161412596702576,
      "learning_rate": 4.378786585886168e-05,
      "loss": 0.003,
      "step": 14560
    },
    {
      "epoch": 1.2432801433569418,
      "grad_norm": 0.1970246285200119,
      "learning_rate": 4.3783599283215294e-05,
      "loss": 0.003,
      "step": 14570
    },
    {
      "epoch": 1.244133458486219,
      "grad_norm": 0.06224362924695015,
      "learning_rate": 4.377933270756891e-05,
      "loss": 0.003,
      "step": 14580
    },
    {
      "epoch": 1.2449867736154963,
      "grad_norm": 0.7439885139465332,
      "learning_rate": 4.377506613192252e-05,
      "loss": 0.0027,
      "step": 14590
    },
    {
      "epoch": 1.2458400887447734,
      "grad_norm": 0.5701931715011597,
      "learning_rate": 4.377079955627614e-05,
      "loss": 0.0023,
      "step": 14600
    },
    {
      "epoch": 1.2466934038740507,
      "grad_norm": 0.07359807938337326,
      "learning_rate": 4.376653298062975e-05,
      "loss": 0.0031,
      "step": 14610
    },
    {
      "epoch": 1.2475467190033278,
      "grad_norm": 0.3484101891517639,
      "learning_rate": 4.376226640498336e-05,
      "loss": 0.0029,
      "step": 14620
    },
    {
      "epoch": 1.2484000341326051,
      "grad_norm": 0.10524679720401764,
      "learning_rate": 4.375799982933698e-05,
      "loss": 0.0025,
      "step": 14630
    },
    {
      "epoch": 1.2492533492618825,
      "grad_norm": 0.12125441431999207,
      "learning_rate": 4.375373325369059e-05,
      "loss": 0.0037,
      "step": 14640
    },
    {
      "epoch": 1.2501066643911596,
      "grad_norm": 0.1187068372964859,
      "learning_rate": 4.37494666780442e-05,
      "loss": 0.0022,
      "step": 14650
    },
    {
      "epoch": 1.250959979520437,
      "grad_norm": 0.0738058090209961,
      "learning_rate": 4.3745200102397816e-05,
      "loss": 0.0036,
      "step": 14660
    },
    {
      "epoch": 1.2518132946497142,
      "grad_norm": 0.19827201962471008,
      "learning_rate": 4.374093352675143e-05,
      "loss": 0.0024,
      "step": 14670
    },
    {
      "epoch": 1.2526666097789914,
      "grad_norm": 0.15042807161808014,
      "learning_rate": 4.3736666951105044e-05,
      "loss": 0.0033,
      "step": 14680
    },
    {
      "epoch": 1.2535199249082687,
      "grad_norm": 0.1963975429534912,
      "learning_rate": 4.373240037545866e-05,
      "loss": 0.0025,
      "step": 14690
    },
    {
      "epoch": 1.2543732400375458,
      "grad_norm": 0.21886307001113892,
      "learning_rate": 4.372813379981227e-05,
      "loss": 0.0032,
      "step": 14700
    },
    {
      "epoch": 1.2552265551668231,
      "grad_norm": 0.06302603334188461,
      "learning_rate": 4.372386722416589e-05,
      "loss": 0.0033,
      "step": 14710
    },
    {
      "epoch": 1.2560798702961002,
      "grad_norm": 0.2718091905117035,
      "learning_rate": 4.37196006485195e-05,
      "loss": 0.0035,
      "step": 14720
    },
    {
      "epoch": 1.2569331854253776,
      "grad_norm": 0.5380820035934448,
      "learning_rate": 4.3715334072873115e-05,
      "loss": 0.0032,
      "step": 14730
    },
    {
      "epoch": 1.257786500554655,
      "grad_norm": 0.16040527820587158,
      "learning_rate": 4.371106749722673e-05,
      "loss": 0.0021,
      "step": 14740
    },
    {
      "epoch": 1.258639815683932,
      "grad_norm": 0.13171939551830292,
      "learning_rate": 4.3706800921580344e-05,
      "loss": 0.0027,
      "step": 14750
    },
    {
      "epoch": 1.2594931308132093,
      "grad_norm": 0.06165336072444916,
      "learning_rate": 4.370253434593395e-05,
      "loss": 0.002,
      "step": 14760
    },
    {
      "epoch": 1.2603464459424867,
      "grad_norm": 0.4725378155708313,
      "learning_rate": 4.369826777028757e-05,
      "loss": 0.0026,
      "step": 14770
    },
    {
      "epoch": 1.2611997610717638,
      "grad_norm": 0.4525996446609497,
      "learning_rate": 4.369400119464118e-05,
      "loss": 0.0027,
      "step": 14780
    },
    {
      "epoch": 1.2620530762010411,
      "grad_norm": 0.06712797284126282,
      "learning_rate": 4.36897346189948e-05,
      "loss": 0.0031,
      "step": 14790
    },
    {
      "epoch": 1.2629063913303182,
      "grad_norm": 0.2893374264240265,
      "learning_rate": 4.368546804334841e-05,
      "loss": 0.0033,
      "step": 14800
    },
    {
      "epoch": 1.2637597064595956,
      "grad_norm": 0.42759448289871216,
      "learning_rate": 4.368120146770203e-05,
      "loss": 0.0024,
      "step": 14810
    },
    {
      "epoch": 1.2646130215888727,
      "grad_norm": 0.4099324345588684,
      "learning_rate": 4.367693489205564e-05,
      "loss": 0.0035,
      "step": 14820
    },
    {
      "epoch": 1.26546633671815,
      "grad_norm": 0.2801176607608795,
      "learning_rate": 4.367266831640925e-05,
      "loss": 0.0035,
      "step": 14830
    },
    {
      "epoch": 1.2663196518474273,
      "grad_norm": 0.3436216413974762,
      "learning_rate": 4.3668401740762865e-05,
      "loss": 0.0022,
      "step": 14840
    },
    {
      "epoch": 1.2671729669767045,
      "grad_norm": 0.1521906554698944,
      "learning_rate": 4.366413516511648e-05,
      "loss": 0.0042,
      "step": 14850
    },
    {
      "epoch": 1.2680262821059818,
      "grad_norm": 0.342471718788147,
      "learning_rate": 4.3659868589470094e-05,
      "loss": 0.0029,
      "step": 14860
    },
    {
      "epoch": 1.2688795972352591,
      "grad_norm": 0.27544504404067993,
      "learning_rate": 4.365560201382371e-05,
      "loss": 0.0025,
      "step": 14870
    },
    {
      "epoch": 1.2697329123645362,
      "grad_norm": 0.13304860889911652,
      "learning_rate": 4.365133543817732e-05,
      "loss": 0.0034,
      "step": 14880
    },
    {
      "epoch": 1.2705862274938133,
      "grad_norm": 0.12435832619667053,
      "learning_rate": 4.364706886253093e-05,
      "loss": 0.0038,
      "step": 14890
    },
    {
      "epoch": 1.2714395426230907,
      "grad_norm": 0.5184258818626404,
      "learning_rate": 4.364280228688455e-05,
      "loss": 0.0028,
      "step": 14900
    },
    {
      "epoch": 1.272292857752368,
      "grad_norm": 0.04795325547456741,
      "learning_rate": 4.363853571123816e-05,
      "loss": 0.002,
      "step": 14910
    },
    {
      "epoch": 1.273146172881645,
      "grad_norm": 0.060610927641391754,
      "learning_rate": 4.363426913559178e-05,
      "loss": 0.0032,
      "step": 14920
    },
    {
      "epoch": 1.2739994880109224,
      "grad_norm": 0.2024581879377365,
      "learning_rate": 4.3630002559945387e-05,
      "loss": 0.003,
      "step": 14930
    },
    {
      "epoch": 1.2748528031401998,
      "grad_norm": 0.07937285304069519,
      "learning_rate": 4.362573598429901e-05,
      "loss": 0.0031,
      "step": 14940
    },
    {
      "epoch": 1.2757061182694769,
      "grad_norm": 0.32471922039985657,
      "learning_rate": 4.3621469408652615e-05,
      "loss": 0.0023,
      "step": 14950
    },
    {
      "epoch": 1.2765594333987542,
      "grad_norm": 0.36481720209121704,
      "learning_rate": 4.361720283300623e-05,
      "loss": 0.0026,
      "step": 14960
    },
    {
      "epoch": 1.2774127485280313,
      "grad_norm": 0.13865065574645996,
      "learning_rate": 4.3612936257359843e-05,
      "loss": 0.0033,
      "step": 14970
    },
    {
      "epoch": 1.2782660636573087,
      "grad_norm": 0.13556796312332153,
      "learning_rate": 4.360866968171346e-05,
      "loss": 0.0032,
      "step": 14980
    },
    {
      "epoch": 1.2791193787865858,
      "grad_norm": 0.03259274736046791,
      "learning_rate": 4.360440310606707e-05,
      "loss": 0.0029,
      "step": 14990
    },
    {
      "epoch": 1.279972693915863,
      "grad_norm": 0.20887687802314758,
      "learning_rate": 4.3600136530420686e-05,
      "loss": 0.0031,
      "step": 15000
    },
    {
      "epoch": 1.2808260090451404,
      "grad_norm": 0.15606969594955444,
      "learning_rate": 4.35958699547743e-05,
      "loss": 0.0034,
      "step": 15010
    },
    {
      "epoch": 1.2816793241744175,
      "grad_norm": 0.08093494921922684,
      "learning_rate": 4.3591603379127915e-05,
      "loss": 0.0032,
      "step": 15020
    },
    {
      "epoch": 1.2825326393036949,
      "grad_norm": 0.22693493962287903,
      "learning_rate": 4.358733680348153e-05,
      "loss": 0.0036,
      "step": 15030
    },
    {
      "epoch": 1.2833859544329722,
      "grad_norm": 0.11457355320453644,
      "learning_rate": 4.358307022783514e-05,
      "loss": 0.0028,
      "step": 15040
    },
    {
      "epoch": 1.2842392695622493,
      "grad_norm": 0.40186038613319397,
      "learning_rate": 4.357880365218876e-05,
      "loss": 0.0022,
      "step": 15050
    },
    {
      "epoch": 1.2850925846915267,
      "grad_norm": 0.4778737723827362,
      "learning_rate": 4.357453707654237e-05,
      "loss": 0.0026,
      "step": 15060
    },
    {
      "epoch": 1.2859458998208038,
      "grad_norm": 0.2809317111968994,
      "learning_rate": 4.357027050089598e-05,
      "loss": 0.002,
      "step": 15070
    },
    {
      "epoch": 1.286799214950081,
      "grad_norm": 0.389519602060318,
      "learning_rate": 4.35660039252496e-05,
      "loss": 0.0031,
      "step": 15080
    },
    {
      "epoch": 1.2876525300793582,
      "grad_norm": 0.0317680686712265,
      "learning_rate": 4.356173734960321e-05,
      "loss": 0.0032,
      "step": 15090
    },
    {
      "epoch": 1.2885058452086355,
      "grad_norm": 0.06550952792167664,
      "learning_rate": 4.355747077395683e-05,
      "loss": 0.003,
      "step": 15100
    },
    {
      "epoch": 1.2893591603379129,
      "grad_norm": 0.13566169142723083,
      "learning_rate": 4.3553204198310436e-05,
      "loss": 0.0025,
      "step": 15110
    },
    {
      "epoch": 1.29021247546719,
      "grad_norm": 0.28938454389572144,
      "learning_rate": 4.354893762266406e-05,
      "loss": 0.0029,
      "step": 15120
    },
    {
      "epoch": 1.2910657905964673,
      "grad_norm": 0.0629083439707756,
      "learning_rate": 4.3544671047017665e-05,
      "loss": 0.0023,
      "step": 15130
    },
    {
      "epoch": 1.2919191057257446,
      "grad_norm": 0.21185645461082458,
      "learning_rate": 4.354040447137128e-05,
      "loss": 0.0033,
      "step": 15140
    },
    {
      "epoch": 1.2927724208550218,
      "grad_norm": 0.09785494953393936,
      "learning_rate": 4.353613789572489e-05,
      "loss": 0.003,
      "step": 15150
    },
    {
      "epoch": 1.2936257359842989,
      "grad_norm": 0.5081672668457031,
      "learning_rate": 4.353187132007851e-05,
      "loss": 0.0032,
      "step": 15160
    },
    {
      "epoch": 1.2944790511135762,
      "grad_norm": 0.6096623539924622,
      "learning_rate": 4.352760474443212e-05,
      "loss": 0.0031,
      "step": 15170
    },
    {
      "epoch": 1.2953323662428535,
      "grad_norm": 0.32679736614227295,
      "learning_rate": 4.352333816878573e-05,
      "loss": 0.0021,
      "step": 15180
    },
    {
      "epoch": 1.2961856813721306,
      "grad_norm": 0.4586354196071625,
      "learning_rate": 4.351907159313935e-05,
      "loss": 0.0028,
      "step": 15190
    },
    {
      "epoch": 1.297038996501408,
      "grad_norm": 0.30667421221733093,
      "learning_rate": 4.351480501749296e-05,
      "loss": 0.0032,
      "step": 15200
    },
    {
      "epoch": 1.2978923116306853,
      "grad_norm": 0.2932053804397583,
      "learning_rate": 4.351053844184658e-05,
      "loss": 0.0033,
      "step": 15210
    },
    {
      "epoch": 1.2987456267599624,
      "grad_norm": 0.29093116521835327,
      "learning_rate": 4.3506271866200186e-05,
      "loss": 0.0024,
      "step": 15220
    },
    {
      "epoch": 1.2995989418892397,
      "grad_norm": 0.15235301852226257,
      "learning_rate": 4.350200529055381e-05,
      "loss": 0.0033,
      "step": 15230
    },
    {
      "epoch": 1.3004522570185169,
      "grad_norm": 0.08138508349657059,
      "learning_rate": 4.3497738714907414e-05,
      "loss": 0.0026,
      "step": 15240
    },
    {
      "epoch": 1.3013055721477942,
      "grad_norm": 0.4948568642139435,
      "learning_rate": 4.3493472139261035e-05,
      "loss": 0.0036,
      "step": 15250
    },
    {
      "epoch": 1.3021588872770713,
      "grad_norm": 0.4038333296775818,
      "learning_rate": 4.348920556361464e-05,
      "loss": 0.0024,
      "step": 15260
    },
    {
      "epoch": 1.3030122024063486,
      "grad_norm": 0.19045406579971313,
      "learning_rate": 4.348493898796826e-05,
      "loss": 0.0026,
      "step": 15270
    },
    {
      "epoch": 1.303865517535626,
      "grad_norm": 0.2852954566478729,
      "learning_rate": 4.348067241232187e-05,
      "loss": 0.0029,
      "step": 15280
    },
    {
      "epoch": 1.304718832664903,
      "grad_norm": 0.131112739443779,
      "learning_rate": 4.3476405836675486e-05,
      "loss": 0.0025,
      "step": 15290
    },
    {
      "epoch": 1.3055721477941804,
      "grad_norm": 0.40298616886138916,
      "learning_rate": 4.34721392610291e-05,
      "loss": 0.0026,
      "step": 15300
    },
    {
      "epoch": 1.3064254629234577,
      "grad_norm": 0.3625205457210541,
      "learning_rate": 4.3467872685382714e-05,
      "loss": 0.0033,
      "step": 15310
    },
    {
      "epoch": 1.3072787780527348,
      "grad_norm": 0.05190883204340935,
      "learning_rate": 4.346360610973633e-05,
      "loss": 0.0039,
      "step": 15320
    },
    {
      "epoch": 1.3081320931820122,
      "grad_norm": 0.1573052853345871,
      "learning_rate": 4.345933953408994e-05,
      "loss": 0.0034,
      "step": 15330
    },
    {
      "epoch": 1.3089854083112893,
      "grad_norm": 0.40070220828056335,
      "learning_rate": 4.345507295844356e-05,
      "loss": 0.0025,
      "step": 15340
    },
    {
      "epoch": 1.3098387234405666,
      "grad_norm": 0.3660488426685333,
      "learning_rate": 4.345080638279717e-05,
      "loss": 0.0028,
      "step": 15350
    },
    {
      "epoch": 1.3106920385698437,
      "grad_norm": 0.20127621293067932,
      "learning_rate": 4.3446539807150785e-05,
      "loss": 0.0026,
      "step": 15360
    },
    {
      "epoch": 1.311545353699121,
      "grad_norm": 0.3482612073421478,
      "learning_rate": 4.34422732315044e-05,
      "loss": 0.0027,
      "step": 15370
    },
    {
      "epoch": 1.3123986688283984,
      "grad_norm": 0.033124007284641266,
      "learning_rate": 4.343800665585801e-05,
      "loss": 0.0026,
      "step": 15380
    },
    {
      "epoch": 1.3132519839576755,
      "grad_norm": 0.25150132179260254,
      "learning_rate": 4.343374008021163e-05,
      "loss": 0.0034,
      "step": 15390
    },
    {
      "epoch": 1.3141052990869528,
      "grad_norm": 0.3509817123413086,
      "learning_rate": 4.3429473504565236e-05,
      "loss": 0.0032,
      "step": 15400
    },
    {
      "epoch": 1.3149586142162302,
      "grad_norm": 0.15410201251506805,
      "learning_rate": 4.3425206928918857e-05,
      "loss": 0.0027,
      "step": 15410
    },
    {
      "epoch": 1.3158119293455073,
      "grad_norm": 0.2672242522239685,
      "learning_rate": 4.3420940353272464e-05,
      "loss": 0.0026,
      "step": 15420
    },
    {
      "epoch": 1.3166652444747846,
      "grad_norm": 0.34639427065849304,
      "learning_rate": 4.341667377762608e-05,
      "loss": 0.0021,
      "step": 15430
    },
    {
      "epoch": 1.3175185596040617,
      "grad_norm": 0.17191925644874573,
      "learning_rate": 4.341240720197969e-05,
      "loss": 0.0024,
      "step": 15440
    },
    {
      "epoch": 1.318371874733339,
      "grad_norm": 0.4721066355705261,
      "learning_rate": 4.340814062633331e-05,
      "loss": 0.0035,
      "step": 15450
    },
    {
      "epoch": 1.3192251898626162,
      "grad_norm": 0.39559388160705566,
      "learning_rate": 4.340387405068692e-05,
      "loss": 0.0036,
      "step": 15460
    },
    {
      "epoch": 1.3200785049918935,
      "grad_norm": 0.2610773742198944,
      "learning_rate": 4.3399607475040535e-05,
      "loss": 0.0024,
      "step": 15470
    },
    {
      "epoch": 1.3209318201211708,
      "grad_norm": 0.1422930210828781,
      "learning_rate": 4.339534089939415e-05,
      "loss": 0.003,
      "step": 15480
    },
    {
      "epoch": 1.321785135250448,
      "grad_norm": 0.2824217975139618,
      "learning_rate": 4.339107432374776e-05,
      "loss": 0.0033,
      "step": 15490
    },
    {
      "epoch": 1.3226384503797253,
      "grad_norm": 0.11714977025985718,
      "learning_rate": 4.338680774810138e-05,
      "loss": 0.0028,
      "step": 15500
    },
    {
      "epoch": 1.3234917655090026,
      "grad_norm": 0.04727953299880028,
      "learning_rate": 4.3382541172454985e-05,
      "loss": 0.0034,
      "step": 15510
    },
    {
      "epoch": 1.3243450806382797,
      "grad_norm": 0.6251341700553894,
      "learning_rate": 4.3378274596808606e-05,
      "loss": 0.004,
      "step": 15520
    },
    {
      "epoch": 1.3251983957675568,
      "grad_norm": 0.4014124870300293,
      "learning_rate": 4.3374008021162214e-05,
      "loss": 0.0033,
      "step": 15530
    },
    {
      "epoch": 1.3260517108968342,
      "grad_norm": 0.3453139364719391,
      "learning_rate": 4.3369741445515835e-05,
      "loss": 0.0029,
      "step": 15540
    },
    {
      "epoch": 1.3269050260261115,
      "grad_norm": 0.0701218917965889,
      "learning_rate": 4.336547486986944e-05,
      "loss": 0.0033,
      "step": 15550
    },
    {
      "epoch": 1.3277583411553886,
      "grad_norm": 0.4797561764717102,
      "learning_rate": 4.336120829422306e-05,
      "loss": 0.003,
      "step": 15560
    },
    {
      "epoch": 1.328611656284666,
      "grad_norm": 0.2754811942577362,
      "learning_rate": 4.335694171857667e-05,
      "loss": 0.0041,
      "step": 15570
    },
    {
      "epoch": 1.3294649714139433,
      "grad_norm": 0.6652877926826477,
      "learning_rate": 4.3352675142930285e-05,
      "loss": 0.0037,
      "step": 15580
    },
    {
      "epoch": 1.3303182865432204,
      "grad_norm": 0.4378778040409088,
      "learning_rate": 4.33484085672839e-05,
      "loss": 0.0023,
      "step": 15590
    },
    {
      "epoch": 1.3311716016724977,
      "grad_norm": 0.16868014633655548,
      "learning_rate": 4.3344141991637514e-05,
      "loss": 0.0031,
      "step": 15600
    },
    {
      "epoch": 1.3320249168017748,
      "grad_norm": 0.04912859946489334,
      "learning_rate": 4.333987541599113e-05,
      "loss": 0.0033,
      "step": 15610
    },
    {
      "epoch": 1.3328782319310521,
      "grad_norm": 0.12086796015501022,
      "learning_rate": 4.333560884034474e-05,
      "loss": 0.0026,
      "step": 15620
    },
    {
      "epoch": 1.3337315470603293,
      "grad_norm": 0.024745790287852287,
      "learning_rate": 4.3331342264698356e-05,
      "loss": 0.0023,
      "step": 15630
    },
    {
      "epoch": 1.3345848621896066,
      "grad_norm": 0.1276233196258545,
      "learning_rate": 4.332707568905197e-05,
      "loss": 0.003,
      "step": 15640
    },
    {
      "epoch": 1.335438177318884,
      "grad_norm": 0.08569376915693283,
      "learning_rate": 4.3322809113405585e-05,
      "loss": 0.0022,
      "step": 15650
    },
    {
      "epoch": 1.336291492448161,
      "grad_norm": 0.19668033719062805,
      "learning_rate": 4.33185425377592e-05,
      "loss": 0.0032,
      "step": 15660
    },
    {
      "epoch": 1.3371448075774384,
      "grad_norm": 0.18679721653461456,
      "learning_rate": 4.331427596211281e-05,
      "loss": 0.0022,
      "step": 15670
    },
    {
      "epoch": 1.3379981227067157,
      "grad_norm": 0.45614656805992126,
      "learning_rate": 4.331000938646642e-05,
      "loss": 0.0028,
      "step": 15680
    },
    {
      "epoch": 1.3388514378359928,
      "grad_norm": 0.33072590827941895,
      "learning_rate": 4.3305742810820035e-05,
      "loss": 0.0024,
      "step": 15690
    },
    {
      "epoch": 1.3397047529652701,
      "grad_norm": 0.0782758817076683,
      "learning_rate": 4.330147623517365e-05,
      "loss": 0.0028,
      "step": 15700
    },
    {
      "epoch": 1.3405580680945473,
      "grad_norm": 0.34867173433303833,
      "learning_rate": 4.3297209659527263e-05,
      "loss": 0.0031,
      "step": 15710
    },
    {
      "epoch": 1.3414113832238246,
      "grad_norm": 0.20890571177005768,
      "learning_rate": 4.329294308388088e-05,
      "loss": 0.0026,
      "step": 15720
    },
    {
      "epoch": 1.3422646983531017,
      "grad_norm": 0.43547070026397705,
      "learning_rate": 4.328867650823449e-05,
      "loss": 0.0026,
      "step": 15730
    },
    {
      "epoch": 1.343118013482379,
      "grad_norm": 0.09848375618457794,
      "learning_rate": 4.3284409932588106e-05,
      "loss": 0.0024,
      "step": 15740
    },
    {
      "epoch": 1.3439713286116564,
      "grad_norm": 0.31503695249557495,
      "learning_rate": 4.328014335694172e-05,
      "loss": 0.0032,
      "step": 15750
    },
    {
      "epoch": 1.3448246437409335,
      "grad_norm": 0.3619535565376282,
      "learning_rate": 4.3275876781295335e-05,
      "loss": 0.0027,
      "step": 15760
    },
    {
      "epoch": 1.3456779588702108,
      "grad_norm": 0.14027667045593262,
      "learning_rate": 4.327161020564895e-05,
      "loss": 0.0034,
      "step": 15770
    },
    {
      "epoch": 1.3465312739994881,
      "grad_norm": 0.08057738840579987,
      "learning_rate": 4.326734363000256e-05,
      "loss": 0.0034,
      "step": 15780
    },
    {
      "epoch": 1.3473845891287652,
      "grad_norm": 0.7091322541236877,
      "learning_rate": 4.326307705435618e-05,
      "loss": 0.0027,
      "step": 15790
    },
    {
      "epoch": 1.3482379042580426,
      "grad_norm": 0.06665310263633728,
      "learning_rate": 4.3258810478709785e-05,
      "loss": 0.0038,
      "step": 15800
    },
    {
      "epoch": 1.3490912193873197,
      "grad_norm": 0.15353581309318542,
      "learning_rate": 4.3254543903063406e-05,
      "loss": 0.0031,
      "step": 15810
    },
    {
      "epoch": 1.349944534516597,
      "grad_norm": 0.289035439491272,
      "learning_rate": 4.325027732741701e-05,
      "loss": 0.0027,
      "step": 15820
    },
    {
      "epoch": 1.3507978496458741,
      "grad_norm": 0.23619844019412994,
      "learning_rate": 4.3246010751770634e-05,
      "loss": 0.0032,
      "step": 15830
    },
    {
      "epoch": 1.3516511647751515,
      "grad_norm": 0.5088702440261841,
      "learning_rate": 4.324174417612424e-05,
      "loss": 0.0022,
      "step": 15840
    },
    {
      "epoch": 1.3525044799044288,
      "grad_norm": 0.18542759120464325,
      "learning_rate": 4.323747760047786e-05,
      "loss": 0.0034,
      "step": 15850
    },
    {
      "epoch": 1.353357795033706,
      "grad_norm": 0.19495250284671783,
      "learning_rate": 4.323321102483147e-05,
      "loss": 0.0035,
      "step": 15860
    },
    {
      "epoch": 1.3542111101629832,
      "grad_norm": 0.2616313099861145,
      "learning_rate": 4.322894444918509e-05,
      "loss": 0.0034,
      "step": 15870
    },
    {
      "epoch": 1.3550644252922606,
      "grad_norm": 0.3438170850276947,
      "learning_rate": 4.32246778735387e-05,
      "loss": 0.0024,
      "step": 15880
    },
    {
      "epoch": 1.3559177404215377,
      "grad_norm": 0.183317631483078,
      "learning_rate": 4.322041129789231e-05,
      "loss": 0.0029,
      "step": 15890
    },
    {
      "epoch": 1.3567710555508148,
      "grad_norm": 0.10403565317392349,
      "learning_rate": 4.321614472224593e-05,
      "loss": 0.0035,
      "step": 15900
    },
    {
      "epoch": 1.3576243706800921,
      "grad_norm": 0.4807734489440918,
      "learning_rate": 4.321187814659954e-05,
      "loss": 0.0035,
      "step": 15910
    },
    {
      "epoch": 1.3584776858093695,
      "grad_norm": 0.11372264474630356,
      "learning_rate": 4.3207611570953156e-05,
      "loss": 0.0028,
      "step": 15920
    },
    {
      "epoch": 1.3593310009386466,
      "grad_norm": 0.18820713460445404,
      "learning_rate": 4.320334499530677e-05,
      "loss": 0.003,
      "step": 15930
    },
    {
      "epoch": 1.360184316067924,
      "grad_norm": 0.20154106616973877,
      "learning_rate": 4.3199078419660384e-05,
      "loss": 0.0031,
      "step": 15940
    },
    {
      "epoch": 1.3610376311972012,
      "grad_norm": 0.22213441133499146,
      "learning_rate": 4.319481184401399e-05,
      "loss": 0.0027,
      "step": 15950
    },
    {
      "epoch": 1.3618909463264783,
      "grad_norm": 0.3232560157775879,
      "learning_rate": 4.319054526836761e-05,
      "loss": 0.0028,
      "step": 15960
    },
    {
      "epoch": 1.3627442614557557,
      "grad_norm": 0.3746342062950134,
      "learning_rate": 4.318627869272122e-05,
      "loss": 0.0018,
      "step": 15970
    },
    {
      "epoch": 1.3635975765850328,
      "grad_norm": 0.10598566383123398,
      "learning_rate": 4.318201211707484e-05,
      "loss": 0.002,
      "step": 15980
    },
    {
      "epoch": 1.36445089171431,
      "grad_norm": 0.17879818379878998,
      "learning_rate": 4.317774554142845e-05,
      "loss": 0.0031,
      "step": 15990
    },
    {
      "epoch": 1.3653042068435872,
      "grad_norm": 0.11825121939182281,
      "learning_rate": 4.317347896578206e-05,
      "loss": 0.0036,
      "step": 16000
    },
    {
      "epoch": 1.3661575219728646,
      "grad_norm": 0.46919453144073486,
      "learning_rate": 4.316921239013568e-05,
      "loss": 0.002,
      "step": 16010
    },
    {
      "epoch": 1.3670108371021419,
      "grad_norm": 0.2167435884475708,
      "learning_rate": 4.316494581448929e-05,
      "loss": 0.0027,
      "step": 16020
    },
    {
      "epoch": 1.367864152231419,
      "grad_norm": 0.3062671720981598,
      "learning_rate": 4.3160679238842906e-05,
      "loss": 0.0021,
      "step": 16030
    },
    {
      "epoch": 1.3687174673606963,
      "grad_norm": 0.41798660159111023,
      "learning_rate": 4.315641266319652e-05,
      "loss": 0.0022,
      "step": 16040
    },
    {
      "epoch": 1.3695707824899737,
      "grad_norm": 0.09912417083978653,
      "learning_rate": 4.3152146087550134e-05,
      "loss": 0.0021,
      "step": 16050
    },
    {
      "epoch": 1.3704240976192508,
      "grad_norm": 0.0974767729640007,
      "learning_rate": 4.314787951190375e-05,
      "loss": 0.0032,
      "step": 16060
    },
    {
      "epoch": 1.371277412748528,
      "grad_norm": 0.03183170408010483,
      "learning_rate": 4.314361293625736e-05,
      "loss": 0.0026,
      "step": 16070
    },
    {
      "epoch": 1.3721307278778052,
      "grad_norm": 0.10505257546901703,
      "learning_rate": 4.313934636061098e-05,
      "loss": 0.0026,
      "step": 16080
    },
    {
      "epoch": 1.3729840430070825,
      "grad_norm": 0.05235219746828079,
      "learning_rate": 4.313507978496459e-05,
      "loss": 0.003,
      "step": 16090
    },
    {
      "epoch": 1.3738373581363597,
      "grad_norm": 0.22400005161762238,
      "learning_rate": 4.3130813209318205e-05,
      "loss": 0.0024,
      "step": 16100
    },
    {
      "epoch": 1.374690673265637,
      "grad_norm": 0.35165008902549744,
      "learning_rate": 4.312654663367181e-05,
      "loss": 0.0028,
      "step": 16110
    },
    {
      "epoch": 1.3755439883949143,
      "grad_norm": 0.04842572659254074,
      "learning_rate": 4.3122280058025434e-05,
      "loss": 0.0029,
      "step": 16120
    },
    {
      "epoch": 1.3763973035241914,
      "grad_norm": 0.06293254345655441,
      "learning_rate": 4.311801348237904e-05,
      "loss": 0.0023,
      "step": 16130
    },
    {
      "epoch": 1.3772506186534688,
      "grad_norm": 0.14839299023151398,
      "learning_rate": 4.311374690673266e-05,
      "loss": 0.0025,
      "step": 16140
    },
    {
      "epoch": 1.378103933782746,
      "grad_norm": 0.059402190148830414,
      "learning_rate": 4.310948033108627e-05,
      "loss": 0.0025,
      "step": 16150
    },
    {
      "epoch": 1.3789572489120232,
      "grad_norm": 0.2554725408554077,
      "learning_rate": 4.310521375543989e-05,
      "loss": 0.0024,
      "step": 16160
    },
    {
      "epoch": 1.3798105640413003,
      "grad_norm": 0.24408213794231415,
      "learning_rate": 4.31009471797935e-05,
      "loss": 0.0034,
      "step": 16170
    },
    {
      "epoch": 1.3806638791705776,
      "grad_norm": 0.14247950911521912,
      "learning_rate": 4.309668060414712e-05,
      "loss": 0.003,
      "step": 16180
    },
    {
      "epoch": 1.381517194299855,
      "grad_norm": 0.1364666372537613,
      "learning_rate": 4.309241402850073e-05,
      "loss": 0.0024,
      "step": 16190
    },
    {
      "epoch": 1.382370509429132,
      "grad_norm": 0.047718510031700134,
      "learning_rate": 4.308814745285434e-05,
      "loss": 0.0024,
      "step": 16200
    },
    {
      "epoch": 1.3832238245584094,
      "grad_norm": 0.2858675420284271,
      "learning_rate": 4.3083880877207955e-05,
      "loss": 0.0038,
      "step": 16210
    },
    {
      "epoch": 1.3840771396876868,
      "grad_norm": 0.18044839799404144,
      "learning_rate": 4.307961430156157e-05,
      "loss": 0.0035,
      "step": 16220
    },
    {
      "epoch": 1.3849304548169639,
      "grad_norm": 0.09457124024629593,
      "learning_rate": 4.3075347725915184e-05,
      "loss": 0.0032,
      "step": 16230
    },
    {
      "epoch": 1.3857837699462412,
      "grad_norm": 0.33928075432777405,
      "learning_rate": 4.307108115026879e-05,
      "loss": 0.0029,
      "step": 16240
    },
    {
      "epoch": 1.3866370850755185,
      "grad_norm": 0.32234612107276917,
      "learning_rate": 4.306681457462241e-05,
      "loss": 0.0023,
      "step": 16250
    },
    {
      "epoch": 1.3874904002047956,
      "grad_norm": 0.07177380472421646,
      "learning_rate": 4.306254799897602e-05,
      "loss": 0.0032,
      "step": 16260
    },
    {
      "epoch": 1.3883437153340727,
      "grad_norm": 0.19751812517642975,
      "learning_rate": 4.305828142332964e-05,
      "loss": 0.0028,
      "step": 16270
    },
    {
      "epoch": 1.38919703046335,
      "grad_norm": 0.034163422882556915,
      "learning_rate": 4.305401484768325e-05,
      "loss": 0.003,
      "step": 16280
    },
    {
      "epoch": 1.3900503455926274,
      "grad_norm": 0.07839657366275787,
      "learning_rate": 4.304974827203687e-05,
      "loss": 0.0035,
      "step": 16290
    },
    {
      "epoch": 1.3909036607219045,
      "grad_norm": 0.30251485109329224,
      "learning_rate": 4.3045481696390477e-05,
      "loss": 0.0025,
      "step": 16300
    },
    {
      "epoch": 1.3917569758511819,
      "grad_norm": 0.3110380470752716,
      "learning_rate": 4.304121512074409e-05,
      "loss": 0.0024,
      "step": 16310
    },
    {
      "epoch": 1.3926102909804592,
      "grad_norm": 0.04939507693052292,
      "learning_rate": 4.3036948545097705e-05,
      "loss": 0.0029,
      "step": 16320
    },
    {
      "epoch": 1.3934636061097363,
      "grad_norm": 0.3363860845565796,
      "learning_rate": 4.303268196945132e-05,
      "loss": 0.0019,
      "step": 16330
    },
    {
      "epoch": 1.3943169212390136,
      "grad_norm": 0.19099381566047668,
      "learning_rate": 4.3028415393804934e-05,
      "loss": 0.0028,
      "step": 16340
    },
    {
      "epoch": 1.3951702363682907,
      "grad_norm": 0.32987070083618164,
      "learning_rate": 4.302414881815855e-05,
      "loss": 0.0027,
      "step": 16350
    },
    {
      "epoch": 1.396023551497568,
      "grad_norm": 0.37491828203201294,
      "learning_rate": 4.301988224251216e-05,
      "loss": 0.0027,
      "step": 16360
    },
    {
      "epoch": 1.3968768666268452,
      "grad_norm": 0.21456755697727203,
      "learning_rate": 4.3015615666865776e-05,
      "loss": 0.0021,
      "step": 16370
    },
    {
      "epoch": 1.3977301817561225,
      "grad_norm": 0.06558141857385635,
      "learning_rate": 4.301134909121939e-05,
      "loss": 0.0023,
      "step": 16380
    },
    {
      "epoch": 1.3985834968853998,
      "grad_norm": 0.3523654341697693,
      "learning_rate": 4.3007082515573005e-05,
      "loss": 0.0032,
      "step": 16390
    },
    {
      "epoch": 1.399436812014677,
      "grad_norm": 0.08854939043521881,
      "learning_rate": 4.300281593992662e-05,
      "loss": 0.0032,
      "step": 16400
    },
    {
      "epoch": 1.4002901271439543,
      "grad_norm": 0.19595873355865479,
      "learning_rate": 4.299854936428023e-05,
      "loss": 0.0029,
      "step": 16410
    },
    {
      "epoch": 1.4011434422732316,
      "grad_norm": 0.30771470069885254,
      "learning_rate": 4.299428278863384e-05,
      "loss": 0.0029,
      "step": 16420
    },
    {
      "epoch": 1.4019967574025087,
      "grad_norm": 0.3233889639377594,
      "learning_rate": 4.299001621298746e-05,
      "loss": 0.0034,
      "step": 16430
    },
    {
      "epoch": 1.402850072531786,
      "grad_norm": 0.0712391808629036,
      "learning_rate": 4.298574963734107e-05,
      "loss": 0.0028,
      "step": 16440
    },
    {
      "epoch": 1.4037033876610632,
      "grad_norm": 0.14320175349712372,
      "learning_rate": 4.298148306169469e-05,
      "loss": 0.0033,
      "step": 16450
    },
    {
      "epoch": 1.4045567027903405,
      "grad_norm": 0.18383049964904785,
      "learning_rate": 4.29772164860483e-05,
      "loss": 0.0029,
      "step": 16460
    },
    {
      "epoch": 1.4054100179196176,
      "grad_norm": 0.3855149745941162,
      "learning_rate": 4.297294991040192e-05,
      "loss": 0.0029,
      "step": 16470
    },
    {
      "epoch": 1.406263333048895,
      "grad_norm": 0.47901883721351624,
      "learning_rate": 4.2968683334755526e-05,
      "loss": 0.003,
      "step": 16480
    },
    {
      "epoch": 1.4071166481781723,
      "grad_norm": 0.021634798496961594,
      "learning_rate": 4.296441675910914e-05,
      "loss": 0.003,
      "step": 16490
    },
    {
      "epoch": 1.4079699633074494,
      "grad_norm": 0.07875561714172363,
      "learning_rate": 4.2960150183462755e-05,
      "loss": 0.0028,
      "step": 16500
    },
    {
      "epoch": 1.4088232784367267,
      "grad_norm": 0.14603282511234283,
      "learning_rate": 4.295588360781637e-05,
      "loss": 0.0031,
      "step": 16510
    },
    {
      "epoch": 1.409676593566004,
      "grad_norm": 0.0932074710726738,
      "learning_rate": 4.295161703216998e-05,
      "loss": 0.0026,
      "step": 16520
    },
    {
      "epoch": 1.4105299086952812,
      "grad_norm": 0.19085918366909027,
      "learning_rate": 4.29473504565236e-05,
      "loss": 0.0028,
      "step": 16530
    },
    {
      "epoch": 1.4113832238245583,
      "grad_norm": 0.33497148752212524,
      "learning_rate": 4.294308388087721e-05,
      "loss": 0.0034,
      "step": 16540
    },
    {
      "epoch": 1.4122365389538356,
      "grad_norm": 0.2584991753101349,
      "learning_rate": 4.293881730523082e-05,
      "loss": 0.0031,
      "step": 16550
    },
    {
      "epoch": 1.413089854083113,
      "grad_norm": 0.34623807668685913,
      "learning_rate": 4.293455072958444e-05,
      "loss": 0.0022,
      "step": 16560
    },
    {
      "epoch": 1.41394316921239,
      "grad_norm": 0.2610868513584137,
      "learning_rate": 4.293028415393805e-05,
      "loss": 0.0027,
      "step": 16570
    },
    {
      "epoch": 1.4147964843416674,
      "grad_norm": 0.2942574918270111,
      "learning_rate": 4.292601757829167e-05,
      "loss": 0.0024,
      "step": 16580
    },
    {
      "epoch": 1.4156497994709447,
      "grad_norm": 0.1431732177734375,
      "learning_rate": 4.2921751002645276e-05,
      "loss": 0.0039,
      "step": 16590
    },
    {
      "epoch": 1.4165031146002218,
      "grad_norm": 0.18401934206485748,
      "learning_rate": 4.29174844269989e-05,
      "loss": 0.0023,
      "step": 16600
    },
    {
      "epoch": 1.4173564297294992,
      "grad_norm": 0.10113279521465302,
      "learning_rate": 4.2913217851352504e-05,
      "loss": 0.0025,
      "step": 16610
    },
    {
      "epoch": 1.4182097448587763,
      "grad_norm": 0.23449131846427917,
      "learning_rate": 4.290895127570612e-05,
      "loss": 0.003,
      "step": 16620
    },
    {
      "epoch": 1.4190630599880536,
      "grad_norm": 0.23541712760925293,
      "learning_rate": 4.290468470005973e-05,
      "loss": 0.0024,
      "step": 16630
    },
    {
      "epoch": 1.4199163751173307,
      "grad_norm": 0.04435926303267479,
      "learning_rate": 4.290041812441335e-05,
      "loss": 0.0033,
      "step": 16640
    },
    {
      "epoch": 1.420769690246608,
      "grad_norm": 0.5489956736564636,
      "learning_rate": 4.289615154876696e-05,
      "loss": 0.0031,
      "step": 16650
    },
    {
      "epoch": 1.4216230053758854,
      "grad_norm": 0.1928596794605255,
      "learning_rate": 4.2891884973120576e-05,
      "loss": 0.0028,
      "step": 16660
    },
    {
      "epoch": 1.4224763205051625,
      "grad_norm": 0.13750451803207397,
      "learning_rate": 4.288761839747419e-05,
      "loss": 0.0037,
      "step": 16670
    },
    {
      "epoch": 1.4233296356344398,
      "grad_norm": 0.035796791315078735,
      "learning_rate": 4.2883351821827804e-05,
      "loss": 0.0027,
      "step": 16680
    },
    {
      "epoch": 1.4241829507637171,
      "grad_norm": 0.15208886563777924,
      "learning_rate": 4.287908524618142e-05,
      "loss": 0.0041,
      "step": 16690
    },
    {
      "epoch": 1.4250362658929943,
      "grad_norm": 0.16881142556667328,
      "learning_rate": 4.287481867053503e-05,
      "loss": 0.0029,
      "step": 16700
    },
    {
      "epoch": 1.4258895810222716,
      "grad_norm": 0.04844345897436142,
      "learning_rate": 4.287055209488865e-05,
      "loss": 0.0029,
      "step": 16710
    },
    {
      "epoch": 1.4267428961515487,
      "grad_norm": 0.13238878548145294,
      "learning_rate": 4.286628551924226e-05,
      "loss": 0.0032,
      "step": 16720
    },
    {
      "epoch": 1.427596211280826,
      "grad_norm": 0.5120838284492493,
      "learning_rate": 4.286201894359587e-05,
      "loss": 0.0026,
      "step": 16730
    },
    {
      "epoch": 1.4284495264101031,
      "grad_norm": 0.08032878488302231,
      "learning_rate": 4.285775236794949e-05,
      "loss": 0.0024,
      "step": 16740
    },
    {
      "epoch": 1.4293028415393805,
      "grad_norm": 0.2720405161380768,
      "learning_rate": 4.28534857923031e-05,
      "loss": 0.0036,
      "step": 16750
    },
    {
      "epoch": 1.4301561566686578,
      "grad_norm": 0.041895635426044464,
      "learning_rate": 4.284921921665671e-05,
      "loss": 0.0027,
      "step": 16760
    },
    {
      "epoch": 1.431009471797935,
      "grad_norm": 0.07364083081483841,
      "learning_rate": 4.2844952641010326e-05,
      "loss": 0.003,
      "step": 16770
    },
    {
      "epoch": 1.4318627869272122,
      "grad_norm": 0.11266332864761353,
      "learning_rate": 4.284068606536394e-05,
      "loss": 0.0033,
      "step": 16780
    },
    {
      "epoch": 1.4327161020564896,
      "grad_norm": 0.05032904073596001,
      "learning_rate": 4.2836419489717554e-05,
      "loss": 0.0032,
      "step": 16790
    },
    {
      "epoch": 1.4335694171857667,
      "grad_norm": 0.1509462594985962,
      "learning_rate": 4.283215291407117e-05,
      "loss": 0.0032,
      "step": 16800
    },
    {
      "epoch": 1.434422732315044,
      "grad_norm": 0.34234580397605896,
      "learning_rate": 4.282788633842478e-05,
      "loss": 0.0034,
      "step": 16810
    },
    {
      "epoch": 1.4352760474443211,
      "grad_norm": 0.19724537432193756,
      "learning_rate": 4.28236197627784e-05,
      "loss": 0.0028,
      "step": 16820
    },
    {
      "epoch": 1.4361293625735985,
      "grad_norm": 0.21282890439033508,
      "learning_rate": 4.281935318713201e-05,
      "loss": 0.0026,
      "step": 16830
    },
    {
      "epoch": 1.4369826777028756,
      "grad_norm": 0.09431837499141693,
      "learning_rate": 4.2815086611485625e-05,
      "loss": 0.0028,
      "step": 16840
    },
    {
      "epoch": 1.437835992832153,
      "grad_norm": 0.21152867376804352,
      "learning_rate": 4.281082003583924e-05,
      "loss": 0.003,
      "step": 16850
    },
    {
      "epoch": 1.4386893079614302,
      "grad_norm": 0.17766347527503967,
      "learning_rate": 4.280655346019285e-05,
      "loss": 0.0025,
      "step": 16860
    },
    {
      "epoch": 1.4395426230907074,
      "grad_norm": 0.5741649866104126,
      "learning_rate": 4.280228688454647e-05,
      "loss": 0.0025,
      "step": 16870
    },
    {
      "epoch": 1.4403959382199847,
      "grad_norm": 0.159568190574646,
      "learning_rate": 4.2798020308900075e-05,
      "loss": 0.0028,
      "step": 16880
    },
    {
      "epoch": 1.441249253349262,
      "grad_norm": 0.04434671998023987,
      "learning_rate": 4.2793753733253696e-05,
      "loss": 0.003,
      "step": 16890
    },
    {
      "epoch": 1.4421025684785391,
      "grad_norm": 0.31850162148475647,
      "learning_rate": 4.2789487157607304e-05,
      "loss": 0.0024,
      "step": 16900
    },
    {
      "epoch": 1.4429558836078162,
      "grad_norm": 0.4574190378189087,
      "learning_rate": 4.2785220581960925e-05,
      "loss": 0.0022,
      "step": 16910
    },
    {
      "epoch": 1.4438091987370936,
      "grad_norm": 0.12125670164823532,
      "learning_rate": 4.278095400631453e-05,
      "loss": 0.0027,
      "step": 16920
    },
    {
      "epoch": 1.444662513866371,
      "grad_norm": 0.20829667150974274,
      "learning_rate": 4.277668743066815e-05,
      "loss": 0.0031,
      "step": 16930
    },
    {
      "epoch": 1.445515828995648,
      "grad_norm": 0.3485696315765381,
      "learning_rate": 4.277242085502176e-05,
      "loss": 0.0029,
      "step": 16940
    },
    {
      "epoch": 1.4463691441249253,
      "grad_norm": 0.287306010723114,
      "learning_rate": 4.2768154279375375e-05,
      "loss": 0.0036,
      "step": 16950
    },
    {
      "epoch": 1.4472224592542027,
      "grad_norm": 0.12177999317646027,
      "learning_rate": 4.276388770372899e-05,
      "loss": 0.0024,
      "step": 16960
    },
    {
      "epoch": 1.4480757743834798,
      "grad_norm": 0.2181660681962967,
      "learning_rate": 4.2759621128082604e-05,
      "loss": 0.0026,
      "step": 16970
    },
    {
      "epoch": 1.4489290895127571,
      "grad_norm": 0.16767722368240356,
      "learning_rate": 4.275535455243622e-05,
      "loss": 0.0031,
      "step": 16980
    },
    {
      "epoch": 1.4497824046420342,
      "grad_norm": 0.25396326184272766,
      "learning_rate": 4.275108797678983e-05,
      "loss": 0.003,
      "step": 16990
    },
    {
      "epoch": 1.4506357197713116,
      "grad_norm": 0.48182976245880127,
      "learning_rate": 4.2746821401143446e-05,
      "loss": 0.0034,
      "step": 17000
    },
    {
      "epoch": 1.4514890349005887,
      "grad_norm": 0.34857645630836487,
      "learning_rate": 4.2742554825497054e-05,
      "loss": 0.0034,
      "step": 17010
    },
    {
      "epoch": 1.452342350029866,
      "grad_norm": 0.2523212730884552,
      "learning_rate": 4.2738288249850675e-05,
      "loss": 0.0031,
      "step": 17020
    },
    {
      "epoch": 1.4531956651591433,
      "grad_norm": 0.36754152178764343,
      "learning_rate": 4.273402167420428e-05,
      "loss": 0.0031,
      "step": 17030
    },
    {
      "epoch": 1.4540489802884204,
      "grad_norm": 0.06288672238588333,
      "learning_rate": 4.2729755098557897e-05,
      "loss": 0.0029,
      "step": 17040
    },
    {
      "epoch": 1.4549022954176978,
      "grad_norm": 0.5534070134162903,
      "learning_rate": 4.272548852291151e-05,
      "loss": 0.0029,
      "step": 17050
    },
    {
      "epoch": 1.455755610546975,
      "grad_norm": 0.1197080984711647,
      "learning_rate": 4.2721221947265125e-05,
      "loss": 0.0034,
      "step": 17060
    },
    {
      "epoch": 1.4566089256762522,
      "grad_norm": 0.1545172929763794,
      "learning_rate": 4.271695537161874e-05,
      "loss": 0.0034,
      "step": 17070
    },
    {
      "epoch": 1.4574622408055296,
      "grad_norm": 0.05376257747411728,
      "learning_rate": 4.2712688795972353e-05,
      "loss": 0.0027,
      "step": 17080
    },
    {
      "epoch": 1.4583155559348067,
      "grad_norm": 0.2674011290073395,
      "learning_rate": 4.270842222032597e-05,
      "loss": 0.0027,
      "step": 17090
    },
    {
      "epoch": 1.459168871064084,
      "grad_norm": 0.23787060379981995,
      "learning_rate": 4.270415564467958e-05,
      "loss": 0.003,
      "step": 17100
    },
    {
      "epoch": 1.460022186193361,
      "grad_norm": 0.20676401257514954,
      "learning_rate": 4.2699889069033196e-05,
      "loss": 0.003,
      "step": 17110
    },
    {
      "epoch": 1.4608755013226384,
      "grad_norm": 0.06995990127325058,
      "learning_rate": 4.269562249338681e-05,
      "loss": 0.0033,
      "step": 17120
    },
    {
      "epoch": 1.4617288164519158,
      "grad_norm": 0.31381380558013916,
      "learning_rate": 4.2691355917740425e-05,
      "loss": 0.0036,
      "step": 17130
    },
    {
      "epoch": 1.4625821315811929,
      "grad_norm": 0.3219074010848999,
      "learning_rate": 4.268708934209404e-05,
      "loss": 0.0037,
      "step": 17140
    },
    {
      "epoch": 1.4634354467104702,
      "grad_norm": 0.16362035274505615,
      "learning_rate": 4.268282276644765e-05,
      "loss": 0.0033,
      "step": 17150
    },
    {
      "epoch": 1.4642887618397475,
      "grad_norm": 0.1523607224225998,
      "learning_rate": 4.267855619080127e-05,
      "loss": 0.0029,
      "step": 17160
    },
    {
      "epoch": 1.4651420769690247,
      "grad_norm": 0.19079330563545227,
      "learning_rate": 4.2674289615154875e-05,
      "loss": 0.0027,
      "step": 17170
    },
    {
      "epoch": 1.465995392098302,
      "grad_norm": 0.42245885729789734,
      "learning_rate": 4.2670023039508496e-05,
      "loss": 0.0035,
      "step": 17180
    },
    {
      "epoch": 1.466848707227579,
      "grad_norm": 0.39363694190979004,
      "learning_rate": 4.26657564638621e-05,
      "loss": 0.004,
      "step": 17190
    },
    {
      "epoch": 1.4677020223568564,
      "grad_norm": 0.24653267860412598,
      "learning_rate": 4.2661489888215724e-05,
      "loss": 0.0034,
      "step": 17200
    },
    {
      "epoch": 1.4685553374861335,
      "grad_norm": 0.2762913405895233,
      "learning_rate": 4.265722331256933e-05,
      "loss": 0.0032,
      "step": 17210
    },
    {
      "epoch": 1.4694086526154109,
      "grad_norm": 0.2677510678768158,
      "learning_rate": 4.265295673692295e-05,
      "loss": 0.0039,
      "step": 17220
    },
    {
      "epoch": 1.4702619677446882,
      "grad_norm": 0.21640552580356598,
      "learning_rate": 4.264869016127656e-05,
      "loss": 0.0036,
      "step": 17230
    },
    {
      "epoch": 1.4711152828739653,
      "grad_norm": 0.04439833015203476,
      "learning_rate": 4.2644423585630175e-05,
      "loss": 0.0033,
      "step": 17240
    },
    {
      "epoch": 1.4719685980032426,
      "grad_norm": 0.12007811665534973,
      "learning_rate": 4.264015700998379e-05,
      "loss": 0.0023,
      "step": 17250
    },
    {
      "epoch": 1.47282191313252,
      "grad_norm": 0.4749630093574524,
      "learning_rate": 4.26358904343374e-05,
      "loss": 0.0027,
      "step": 17260
    },
    {
      "epoch": 1.473675228261797,
      "grad_norm": 0.13681674003601074,
      "learning_rate": 4.263162385869102e-05,
      "loss": 0.0024,
      "step": 17270
    },
    {
      "epoch": 1.4745285433910742,
      "grad_norm": 0.03917370364069939,
      "learning_rate": 4.2627357283044625e-05,
      "loss": 0.0026,
      "step": 17280
    },
    {
      "epoch": 1.4753818585203515,
      "grad_norm": 0.22867172956466675,
      "learning_rate": 4.2623090707398246e-05,
      "loss": 0.0018,
      "step": 17290
    },
    {
      "epoch": 1.4762351736496289,
      "grad_norm": 0.15333810448646545,
      "learning_rate": 4.261882413175185e-05,
      "loss": 0.0022,
      "step": 17300
    },
    {
      "epoch": 1.477088488778906,
      "grad_norm": 0.0619833879172802,
      "learning_rate": 4.2614557556105474e-05,
      "loss": 0.0032,
      "step": 17310
    },
    {
      "epoch": 1.4779418039081833,
      "grad_norm": 0.1912773847579956,
      "learning_rate": 4.261029098045908e-05,
      "loss": 0.0033,
      "step": 17320
    },
    {
      "epoch": 1.4787951190374606,
      "grad_norm": 0.08166235685348511,
      "learning_rate": 4.26060244048127e-05,
      "loss": 0.0021,
      "step": 17330
    },
    {
      "epoch": 1.4796484341667377,
      "grad_norm": 0.09495627880096436,
      "learning_rate": 4.260175782916631e-05,
      "loss": 0.0039,
      "step": 17340
    },
    {
      "epoch": 1.480501749296015,
      "grad_norm": 0.08297879248857498,
      "learning_rate": 4.2597491253519924e-05,
      "loss": 0.0027,
      "step": 17350
    },
    {
      "epoch": 1.4813550644252922,
      "grad_norm": 0.05172676220536232,
      "learning_rate": 4.259322467787354e-05,
      "loss": 0.0028,
      "step": 17360
    },
    {
      "epoch": 1.4822083795545695,
      "grad_norm": 0.554282546043396,
      "learning_rate": 4.258895810222715e-05,
      "loss": 0.0032,
      "step": 17370
    },
    {
      "epoch": 1.4830616946838466,
      "grad_norm": 0.957487165927887,
      "learning_rate": 4.258469152658077e-05,
      "loss": 0.0031,
      "step": 17380
    },
    {
      "epoch": 1.483915009813124,
      "grad_norm": 0.5921086072921753,
      "learning_rate": 4.258042495093438e-05,
      "loss": 0.0046,
      "step": 17390
    },
    {
      "epoch": 1.4847683249424013,
      "grad_norm": 0.40211349725723267,
      "learning_rate": 4.2576158375287996e-05,
      "loss": 0.0025,
      "step": 17400
    },
    {
      "epoch": 1.4856216400716784,
      "grad_norm": 0.3033069372177124,
      "learning_rate": 4.257189179964161e-05,
      "loss": 0.0034,
      "step": 17410
    },
    {
      "epoch": 1.4864749552009557,
      "grad_norm": 0.23463355004787445,
      "learning_rate": 4.2567625223995224e-05,
      "loss": 0.0034,
      "step": 17420
    },
    {
      "epoch": 1.487328270330233,
      "grad_norm": 0.19933439791202545,
      "learning_rate": 4.256335864834884e-05,
      "loss": 0.0029,
      "step": 17430
    },
    {
      "epoch": 1.4881815854595102,
      "grad_norm": 0.34881457686424255,
      "learning_rate": 4.255909207270245e-05,
      "loss": 0.0028,
      "step": 17440
    },
    {
      "epoch": 1.4890349005887875,
      "grad_norm": 0.2791604995727539,
      "learning_rate": 4.255482549705607e-05,
      "loss": 0.0032,
      "step": 17450
    },
    {
      "epoch": 1.4898882157180646,
      "grad_norm": 0.2279731184244156,
      "learning_rate": 4.255055892140968e-05,
      "loss": 0.002,
      "step": 17460
    },
    {
      "epoch": 1.490741530847342,
      "grad_norm": 0.24302083253860474,
      "learning_rate": 4.2546292345763295e-05,
      "loss": 0.0023,
      "step": 17470
    },
    {
      "epoch": 1.491594845976619,
      "grad_norm": 0.042716387659311295,
      "learning_rate": 4.25420257701169e-05,
      "loss": 0.0035,
      "step": 17480
    },
    {
      "epoch": 1.4924481611058964,
      "grad_norm": 0.2578090727329254,
      "learning_rate": 4.2537759194470524e-05,
      "loss": 0.0028,
      "step": 17490
    },
    {
      "epoch": 1.4933014762351737,
      "grad_norm": 0.14207281172275543,
      "learning_rate": 4.253349261882413e-05,
      "loss": 0.0025,
      "step": 17500
    },
    {
      "epoch": 1.4941547913644508,
      "grad_norm": 0.06299851834774017,
      "learning_rate": 4.252922604317775e-05,
      "loss": 0.0025,
      "step": 17510
    },
    {
      "epoch": 1.4950081064937282,
      "grad_norm": 0.12317419052124023,
      "learning_rate": 4.252495946753136e-05,
      "loss": 0.0027,
      "step": 17520
    },
    {
      "epoch": 1.4958614216230055,
      "grad_norm": 0.2673961818218231,
      "learning_rate": 4.252069289188498e-05,
      "loss": 0.0029,
      "step": 17530
    },
    {
      "epoch": 1.4967147367522826,
      "grad_norm": 0.20648768544197083,
      "learning_rate": 4.251642631623859e-05,
      "loss": 0.0031,
      "step": 17540
    },
    {
      "epoch": 1.4975680518815597,
      "grad_norm": 0.34073543548583984,
      "learning_rate": 4.25121597405922e-05,
      "loss": 0.0029,
      "step": 17550
    },
    {
      "epoch": 1.498421367010837,
      "grad_norm": 0.25444483757019043,
      "learning_rate": 4.250789316494582e-05,
      "loss": 0.0029,
      "step": 17560
    },
    {
      "epoch": 1.4992746821401144,
      "grad_norm": 0.22711129486560822,
      "learning_rate": 4.250362658929943e-05,
      "loss": 0.003,
      "step": 17570
    },
    {
      "epoch": 1.5001279972693915,
      "grad_norm": 0.35068824887275696,
      "learning_rate": 4.2499360013653045e-05,
      "loss": 0.0033,
      "step": 17580
    },
    {
      "epoch": 1.5009813123986688,
      "grad_norm": 0.3087758421897888,
      "learning_rate": 4.249509343800665e-05,
      "loss": 0.002,
      "step": 17590
    },
    {
      "epoch": 1.5018346275279462,
      "grad_norm": 0.44588181376457214,
      "learning_rate": 4.2490826862360274e-05,
      "loss": 0.0032,
      "step": 17600
    },
    {
      "epoch": 1.5026879426572233,
      "grad_norm": 0.0710127204656601,
      "learning_rate": 4.248656028671388e-05,
      "loss": 0.0026,
      "step": 17610
    },
    {
      "epoch": 1.5035412577865006,
      "grad_norm": 0.2854712903499603,
      "learning_rate": 4.24822937110675e-05,
      "loss": 0.003,
      "step": 17620
    },
    {
      "epoch": 1.504394572915778,
      "grad_norm": 0.255272775888443,
      "learning_rate": 4.247802713542111e-05,
      "loss": 0.0022,
      "step": 17630
    },
    {
      "epoch": 1.505247888045055,
      "grad_norm": 0.12038815766572952,
      "learning_rate": 4.247376055977473e-05,
      "loss": 0.002,
      "step": 17640
    },
    {
      "epoch": 1.5061012031743322,
      "grad_norm": 0.08419247716665268,
      "learning_rate": 4.246949398412834e-05,
      "loss": 0.0025,
      "step": 17650
    },
    {
      "epoch": 1.5069545183036095,
      "grad_norm": 0.09181364625692368,
      "learning_rate": 4.246522740848195e-05,
      "loss": 0.0024,
      "step": 17660
    },
    {
      "epoch": 1.5078078334328868,
      "grad_norm": 0.22875317931175232,
      "learning_rate": 4.2460960832835567e-05,
      "loss": 0.0028,
      "step": 17670
    },
    {
      "epoch": 1.508661148562164,
      "grad_norm": 0.2525213956832886,
      "learning_rate": 4.245669425718918e-05,
      "loss": 0.003,
      "step": 17680
    },
    {
      "epoch": 1.5095144636914413,
      "grad_norm": 0.20775510370731354,
      "learning_rate": 4.2452427681542795e-05,
      "loss": 0.0027,
      "step": 17690
    },
    {
      "epoch": 1.5103677788207186,
      "grad_norm": 0.215221107006073,
      "learning_rate": 4.244816110589641e-05,
      "loss": 0.0026,
      "step": 17700
    },
    {
      "epoch": 1.5112210939499957,
      "grad_norm": 0.21693062782287598,
      "learning_rate": 4.2443894530250024e-05,
      "loss": 0.003,
      "step": 17710
    },
    {
      "epoch": 1.5120744090792728,
      "grad_norm": 0.4370914697647095,
      "learning_rate": 4.243962795460364e-05,
      "loss": 0.0028,
      "step": 17720
    },
    {
      "epoch": 1.5129277242085504,
      "grad_norm": 0.2328648567199707,
      "learning_rate": 4.243536137895725e-05,
      "loss": 0.004,
      "step": 17730
    },
    {
      "epoch": 1.5137810393378275,
      "grad_norm": 0.11914791166782379,
      "learning_rate": 4.2431094803310866e-05,
      "loss": 0.0026,
      "step": 17740
    },
    {
      "epoch": 1.5146343544671046,
      "grad_norm": 0.073097825050354,
      "learning_rate": 4.242682822766448e-05,
      "loss": 0.0031,
      "step": 17750
    },
    {
      "epoch": 1.515487669596382,
      "grad_norm": 0.043990444391965866,
      "learning_rate": 4.2422561652018095e-05,
      "loss": 0.0027,
      "step": 17760
    },
    {
      "epoch": 1.5163409847256593,
      "grad_norm": 0.32410189509391785,
      "learning_rate": 4.241829507637171e-05,
      "loss": 0.0025,
      "step": 17770
    },
    {
      "epoch": 1.5171942998549364,
      "grad_norm": 0.7435048222541809,
      "learning_rate": 4.241402850072532e-05,
      "loss": 0.0023,
      "step": 17780
    },
    {
      "epoch": 1.5180476149842137,
      "grad_norm": 0.07908130437135696,
      "learning_rate": 4.240976192507893e-05,
      "loss": 0.0027,
      "step": 17790
    },
    {
      "epoch": 1.518900930113491,
      "grad_norm": 0.3856129050254822,
      "learning_rate": 4.240549534943255e-05,
      "loss": 0.0029,
      "step": 17800
    },
    {
      "epoch": 1.5197542452427681,
      "grad_norm": 0.08402644842863083,
      "learning_rate": 4.240122877378616e-05,
      "loss": 0.0031,
      "step": 17810
    },
    {
      "epoch": 1.5206075603720453,
      "grad_norm": 0.042260169982910156,
      "learning_rate": 4.2396962198139773e-05,
      "loss": 0.0029,
      "step": 17820
    },
    {
      "epoch": 1.5214608755013226,
      "grad_norm": 0.200343057513237,
      "learning_rate": 4.239269562249339e-05,
      "loss": 0.003,
      "step": 17830
    },
    {
      "epoch": 1.5223141906306,
      "grad_norm": 0.5729073286056519,
      "learning_rate": 4.2388429046847e-05,
      "loss": 0.0025,
      "step": 17840
    },
    {
      "epoch": 1.523167505759877,
      "grad_norm": 0.20864389836788177,
      "learning_rate": 4.2384162471200616e-05,
      "loss": 0.0029,
      "step": 17850
    },
    {
      "epoch": 1.5240208208891544,
      "grad_norm": 0.322223961353302,
      "learning_rate": 4.237989589555423e-05,
      "loss": 0.003,
      "step": 17860
    },
    {
      "epoch": 1.5248741360184317,
      "grad_norm": 0.19620496034622192,
      "learning_rate": 4.2375629319907845e-05,
      "loss": 0.0024,
      "step": 17870
    },
    {
      "epoch": 1.5257274511477088,
      "grad_norm": 0.25109660625457764,
      "learning_rate": 4.237136274426146e-05,
      "loss": 0.0027,
      "step": 17880
    },
    {
      "epoch": 1.5265807662769861,
      "grad_norm": 0.13175126910209656,
      "learning_rate": 4.236709616861507e-05,
      "loss": 0.0024,
      "step": 17890
    },
    {
      "epoch": 1.5274340814062635,
      "grad_norm": 0.13566476106643677,
      "learning_rate": 4.236282959296868e-05,
      "loss": 0.0027,
      "step": 17900
    },
    {
      "epoch": 1.5282873965355406,
      "grad_norm": 0.06320097297430038,
      "learning_rate": 4.23585630173223e-05,
      "loss": 0.0029,
      "step": 17910
    },
    {
      "epoch": 1.5291407116648177,
      "grad_norm": 0.15800607204437256,
      "learning_rate": 4.235429644167591e-05,
      "loss": 0.0029,
      "step": 17920
    },
    {
      "epoch": 1.529994026794095,
      "grad_norm": 0.4221324026584625,
      "learning_rate": 4.235002986602953e-05,
      "loss": 0.0031,
      "step": 17930
    },
    {
      "epoch": 1.5308473419233724,
      "grad_norm": 0.08402609080076218,
      "learning_rate": 4.234576329038314e-05,
      "loss": 0.0022,
      "step": 17940
    },
    {
      "epoch": 1.5317006570526495,
      "grad_norm": 0.3106747269630432,
      "learning_rate": 4.234149671473676e-05,
      "loss": 0.0029,
      "step": 17950
    },
    {
      "epoch": 1.5325539721819268,
      "grad_norm": 0.0365852490067482,
      "learning_rate": 4.2337230139090366e-05,
      "loss": 0.0025,
      "step": 17960
    },
    {
      "epoch": 1.5334072873112041,
      "grad_norm": 0.1300981491804123,
      "learning_rate": 4.233296356344398e-05,
      "loss": 0.0035,
      "step": 17970
    },
    {
      "epoch": 1.5342606024404812,
      "grad_norm": 0.43036162853240967,
      "learning_rate": 4.2328696987797594e-05,
      "loss": 0.0029,
      "step": 17980
    },
    {
      "epoch": 1.5351139175697583,
      "grad_norm": 0.18915024399757385,
      "learning_rate": 4.232443041215121e-05,
      "loss": 0.0028,
      "step": 17990
    },
    {
      "epoch": 1.535967232699036,
      "grad_norm": 0.10197029262781143,
      "learning_rate": 4.232016383650482e-05,
      "loss": 0.0028,
      "step": 18000
    },
    {
      "epoch": 1.536820547828313,
      "grad_norm": 0.16244959831237793,
      "learning_rate": 4.231589726085844e-05,
      "loss": 0.0027,
      "step": 18010
    },
    {
      "epoch": 1.5376738629575901,
      "grad_norm": 0.2196500152349472,
      "learning_rate": 4.231163068521205e-05,
      "loss": 0.0026,
      "step": 18020
    },
    {
      "epoch": 1.5385271780868675,
      "grad_norm": 0.3554824888706207,
      "learning_rate": 4.2307364109565666e-05,
      "loss": 0.0025,
      "step": 18030
    },
    {
      "epoch": 1.5393804932161448,
      "grad_norm": 0.09954000264406204,
      "learning_rate": 4.230309753391928e-05,
      "loss": 0.0026,
      "step": 18040
    },
    {
      "epoch": 1.540233808345422,
      "grad_norm": 0.21749615669250488,
      "learning_rate": 4.2298830958272894e-05,
      "loss": 0.0031,
      "step": 18050
    },
    {
      "epoch": 1.5410871234746992,
      "grad_norm": 0.03822702541947365,
      "learning_rate": 4.229456438262651e-05,
      "loss": 0.0029,
      "step": 18060
    },
    {
      "epoch": 1.5419404386039766,
      "grad_norm": 0.43627575039863586,
      "learning_rate": 4.229029780698012e-05,
      "loss": 0.0025,
      "step": 18070
    },
    {
      "epoch": 1.5427937537332537,
      "grad_norm": 0.18724806606769562,
      "learning_rate": 4.228603123133374e-05,
      "loss": 0.0024,
      "step": 18080
    },
    {
      "epoch": 1.5436470688625308,
      "grad_norm": 0.07617633789777756,
      "learning_rate": 4.2281764655687344e-05,
      "loss": 0.0028,
      "step": 18090
    },
    {
      "epoch": 1.5445003839918083,
      "grad_norm": 0.23486678302288055,
      "learning_rate": 4.227749808004096e-05,
      "loss": 0.0028,
      "step": 18100
    },
    {
      "epoch": 1.5453536991210854,
      "grad_norm": 0.11411042511463165,
      "learning_rate": 4.227323150439457e-05,
      "loss": 0.0025,
      "step": 18110
    },
    {
      "epoch": 1.5462070142503626,
      "grad_norm": 0.03162700682878494,
      "learning_rate": 4.226896492874819e-05,
      "loss": 0.0025,
      "step": 18120
    },
    {
      "epoch": 1.5470603293796399,
      "grad_norm": 0.11590521782636642,
      "learning_rate": 4.22646983531018e-05,
      "loss": 0.0025,
      "step": 18130
    },
    {
      "epoch": 1.5479136445089172,
      "grad_norm": 0.14850641787052155,
      "learning_rate": 4.2260431777455416e-05,
      "loss": 0.003,
      "step": 18140
    },
    {
      "epoch": 1.5487669596381943,
      "grad_norm": 0.19554051756858826,
      "learning_rate": 4.225616520180903e-05,
      "loss": 0.0026,
      "step": 18150
    },
    {
      "epoch": 1.5496202747674717,
      "grad_norm": 0.135139599442482,
      "learning_rate": 4.2251898626162644e-05,
      "loss": 0.0037,
      "step": 18160
    },
    {
      "epoch": 1.550473589896749,
      "grad_norm": 0.31938284635543823,
      "learning_rate": 4.224763205051626e-05,
      "loss": 0.0024,
      "step": 18170
    },
    {
      "epoch": 1.551326905026026,
      "grad_norm": 0.12712064385414124,
      "learning_rate": 4.224336547486987e-05,
      "loss": 0.0022,
      "step": 18180
    },
    {
      "epoch": 1.5521802201553032,
      "grad_norm": 0.2438051849603653,
      "learning_rate": 4.223909889922349e-05,
      "loss": 0.0023,
      "step": 18190
    },
    {
      "epoch": 1.5530335352845805,
      "grad_norm": 0.19452568888664246,
      "learning_rate": 4.22348323235771e-05,
      "loss": 0.002,
      "step": 18200
    },
    {
      "epoch": 1.5538868504138579,
      "grad_norm": 0.04764252528548241,
      "learning_rate": 4.223056574793071e-05,
      "loss": 0.0026,
      "step": 18210
    },
    {
      "epoch": 1.554740165543135,
      "grad_norm": 0.07293015718460083,
      "learning_rate": 4.222629917228433e-05,
      "loss": 0.0021,
      "step": 18220
    },
    {
      "epoch": 1.5555934806724123,
      "grad_norm": 0.10480985045433044,
      "learning_rate": 4.222203259663794e-05,
      "loss": 0.0027,
      "step": 18230
    },
    {
      "epoch": 1.5564467958016897,
      "grad_norm": 0.520325779914856,
      "learning_rate": 4.221776602099156e-05,
      "loss": 0.0024,
      "step": 18240
    },
    {
      "epoch": 1.5573001109309668,
      "grad_norm": 0.4039614796638489,
      "learning_rate": 4.2213499445345165e-05,
      "loss": 0.003,
      "step": 18250
    },
    {
      "epoch": 1.558153426060244,
      "grad_norm": 0.3779686689376831,
      "learning_rate": 4.2209232869698786e-05,
      "loss": 0.0029,
      "step": 18260
    },
    {
      "epoch": 1.5590067411895214,
      "grad_norm": 0.03912217170000076,
      "learning_rate": 4.2204966294052394e-05,
      "loss": 0.0028,
      "step": 18270
    },
    {
      "epoch": 1.5598600563187985,
      "grad_norm": 0.12231213599443436,
      "learning_rate": 4.220069971840601e-05,
      "loss": 0.0025,
      "step": 18280
    },
    {
      "epoch": 1.5607133714480756,
      "grad_norm": 0.15457764267921448,
      "learning_rate": 4.219643314275962e-05,
      "loss": 0.0024,
      "step": 18290
    },
    {
      "epoch": 1.561566686577353,
      "grad_norm": 0.5578352212905884,
      "learning_rate": 4.219216656711324e-05,
      "loss": 0.0022,
      "step": 18300
    },
    {
      "epoch": 1.5624200017066303,
      "grad_norm": 0.4428378641605377,
      "learning_rate": 4.218789999146685e-05,
      "loss": 0.0022,
      "step": 18310
    },
    {
      "epoch": 1.5632733168359074,
      "grad_norm": 0.17959895730018616,
      "learning_rate": 4.2183633415820465e-05,
      "loss": 0.0033,
      "step": 18320
    },
    {
      "epoch": 1.5641266319651848,
      "grad_norm": 0.34378138184547424,
      "learning_rate": 4.217936684017408e-05,
      "loss": 0.0038,
      "step": 18330
    },
    {
      "epoch": 1.564979947094462,
      "grad_norm": 0.1026775911450386,
      "learning_rate": 4.217510026452769e-05,
      "loss": 0.0033,
      "step": 18340
    },
    {
      "epoch": 1.5658332622237392,
      "grad_norm": 0.05870556831359863,
      "learning_rate": 4.217083368888131e-05,
      "loss": 0.0026,
      "step": 18350
    },
    {
      "epoch": 1.5666865773530163,
      "grad_norm": 0.05174800381064415,
      "learning_rate": 4.2166567113234915e-05,
      "loss": 0.0026,
      "step": 18360
    },
    {
      "epoch": 1.5675398924822939,
      "grad_norm": 0.10067912936210632,
      "learning_rate": 4.2162300537588536e-05,
      "loss": 0.0029,
      "step": 18370
    },
    {
      "epoch": 1.568393207611571,
      "grad_norm": 0.06283105164766312,
      "learning_rate": 4.2158033961942144e-05,
      "loss": 0.0031,
      "step": 18380
    },
    {
      "epoch": 1.569246522740848,
      "grad_norm": 0.09796381741762161,
      "learning_rate": 4.2153767386295765e-05,
      "loss": 0.0025,
      "step": 18390
    },
    {
      "epoch": 1.5700998378701254,
      "grad_norm": 0.06163403019309044,
      "learning_rate": 4.214950081064937e-05,
      "loss": 0.0023,
      "step": 18400
    },
    {
      "epoch": 1.5709531529994027,
      "grad_norm": 0.11460446566343307,
      "learning_rate": 4.2145234235002987e-05,
      "loss": 0.0022,
      "step": 18410
    },
    {
      "epoch": 1.5718064681286799,
      "grad_norm": 0.029239417985081673,
      "learning_rate": 4.21409676593566e-05,
      "loss": 0.0025,
      "step": 18420
    },
    {
      "epoch": 1.5726597832579572,
      "grad_norm": 0.045590318739414215,
      "learning_rate": 4.2136701083710215e-05,
      "loss": 0.0026,
      "step": 18430
    },
    {
      "epoch": 1.5735130983872345,
      "grad_norm": 0.499186247587204,
      "learning_rate": 4.213243450806383e-05,
      "loss": 0.0024,
      "step": 18440
    },
    {
      "epoch": 1.5743664135165116,
      "grad_norm": 0.2552550733089447,
      "learning_rate": 4.2128167932417443e-05,
      "loss": 0.0027,
      "step": 18450
    },
    {
      "epoch": 1.5752197286457887,
      "grad_norm": 0.22373218834400177,
      "learning_rate": 4.212390135677106e-05,
      "loss": 0.0027,
      "step": 18460
    },
    {
      "epoch": 1.5760730437750663,
      "grad_norm": 0.08593806624412537,
      "learning_rate": 4.211963478112467e-05,
      "loss": 0.0033,
      "step": 18470
    },
    {
      "epoch": 1.5769263589043434,
      "grad_norm": 0.45311397314071655,
      "learning_rate": 4.2115368205478286e-05,
      "loss": 0.0029,
      "step": 18480
    },
    {
      "epoch": 1.5777796740336205,
      "grad_norm": 0.37637829780578613,
      "learning_rate": 4.21111016298319e-05,
      "loss": 0.0027,
      "step": 18490
    },
    {
      "epoch": 1.5786329891628978,
      "grad_norm": 0.1283905804157257,
      "learning_rate": 4.2106835054185515e-05,
      "loss": 0.0031,
      "step": 18500
    },
    {
      "epoch": 1.5794863042921752,
      "grad_norm": 0.11199040710926056,
      "learning_rate": 4.210256847853913e-05,
      "loss": 0.0037,
      "step": 18510
    },
    {
      "epoch": 1.5803396194214523,
      "grad_norm": 0.07895517349243164,
      "learning_rate": 4.2098301902892736e-05,
      "loss": 0.0026,
      "step": 18520
    },
    {
      "epoch": 1.5811929345507296,
      "grad_norm": 0.4738202393054962,
      "learning_rate": 4.209403532724636e-05,
      "loss": 0.0026,
      "step": 18530
    },
    {
      "epoch": 1.582046249680007,
      "grad_norm": 0.28154897689819336,
      "learning_rate": 4.2089768751599965e-05,
      "loss": 0.0025,
      "step": 18540
    },
    {
      "epoch": 1.582899564809284,
      "grad_norm": 0.11413423717021942,
      "learning_rate": 4.2085502175953586e-05,
      "loss": 0.0026,
      "step": 18550
    },
    {
      "epoch": 1.5837528799385612,
      "grad_norm": 0.5785143971443176,
      "learning_rate": 4.208123560030719e-05,
      "loss": 0.0036,
      "step": 18560
    },
    {
      "epoch": 1.5846061950678385,
      "grad_norm": 0.26670536398887634,
      "learning_rate": 4.2076969024660814e-05,
      "loss": 0.003,
      "step": 18570
    },
    {
      "epoch": 1.5854595101971158,
      "grad_norm": 0.07501576095819473,
      "learning_rate": 4.207270244901442e-05,
      "loss": 0.0024,
      "step": 18580
    },
    {
      "epoch": 1.586312825326393,
      "grad_norm": 0.3279792368412018,
      "learning_rate": 4.206843587336804e-05,
      "loss": 0.0024,
      "step": 18590
    },
    {
      "epoch": 1.5871661404556703,
      "grad_norm": 0.049628641456365585,
      "learning_rate": 4.206416929772165e-05,
      "loss": 0.0034,
      "step": 18600
    },
    {
      "epoch": 1.5880194555849476,
      "grad_norm": 0.2847850024700165,
      "learning_rate": 4.2059902722075265e-05,
      "loss": 0.0018,
      "step": 18610
    },
    {
      "epoch": 1.5888727707142247,
      "grad_norm": 0.05799677222967148,
      "learning_rate": 4.205563614642888e-05,
      "loss": 0.0031,
      "step": 18620
    },
    {
      "epoch": 1.589726085843502,
      "grad_norm": 0.2512923777103424,
      "learning_rate": 4.2051369570782486e-05,
      "loss": 0.003,
      "step": 18630
    },
    {
      "epoch": 1.5905794009727794,
      "grad_norm": 0.05461672320961952,
      "learning_rate": 4.204710299513611e-05,
      "loss": 0.0024,
      "step": 18640
    },
    {
      "epoch": 1.5914327161020565,
      "grad_norm": 0.21156150102615356,
      "learning_rate": 4.2042836419489715e-05,
      "loss": 0.0025,
      "step": 18650
    },
    {
      "epoch": 1.5922860312313336,
      "grad_norm": 0.29448312520980835,
      "learning_rate": 4.2038569843843336e-05,
      "loss": 0.0032,
      "step": 18660
    },
    {
      "epoch": 1.593139346360611,
      "grad_norm": 0.37431368231773376,
      "learning_rate": 4.203430326819694e-05,
      "loss": 0.0019,
      "step": 18670
    },
    {
      "epoch": 1.5939926614898883,
      "grad_norm": 0.13829922676086426,
      "learning_rate": 4.2030036692550564e-05,
      "loss": 0.0029,
      "step": 18680
    },
    {
      "epoch": 1.5948459766191654,
      "grad_norm": 0.6049257516860962,
      "learning_rate": 4.202577011690417e-05,
      "loss": 0.0028,
      "step": 18690
    },
    {
      "epoch": 1.5956992917484427,
      "grad_norm": 0.4954293668270111,
      "learning_rate": 4.202150354125779e-05,
      "loss": 0.0028,
      "step": 18700
    },
    {
      "epoch": 1.59655260687772,
      "grad_norm": 0.4135476350784302,
      "learning_rate": 4.20172369656114e-05,
      "loss": 0.0024,
      "step": 18710
    },
    {
      "epoch": 1.5974059220069972,
      "grad_norm": 0.1271589994430542,
      "learning_rate": 4.2012970389965014e-05,
      "loss": 0.0026,
      "step": 18720
    },
    {
      "epoch": 1.5982592371362743,
      "grad_norm": 0.08763802796602249,
      "learning_rate": 4.200870381431863e-05,
      "loss": 0.0027,
      "step": 18730
    },
    {
      "epoch": 1.5991125522655518,
      "grad_norm": 0.2879622280597687,
      "learning_rate": 4.200443723867224e-05,
      "loss": 0.0029,
      "step": 18740
    },
    {
      "epoch": 1.599965867394829,
      "grad_norm": 0.21247750520706177,
      "learning_rate": 4.200017066302586e-05,
      "loss": 0.0027,
      "step": 18750
    },
    {
      "epoch": 1.600819182524106,
      "grad_norm": 0.026990678161382675,
      "learning_rate": 4.199590408737947e-05,
      "loss": 0.0029,
      "step": 18760
    },
    {
      "epoch": 1.6016724976533834,
      "grad_norm": 0.19734181463718414,
      "learning_rate": 4.1991637511733086e-05,
      "loss": 0.0031,
      "step": 18770
    },
    {
      "epoch": 1.6025258127826607,
      "grad_norm": 0.23093955218791962,
      "learning_rate": 4.19873709360867e-05,
      "loss": 0.003,
      "step": 18780
    },
    {
      "epoch": 1.6033791279119378,
      "grad_norm": 0.489876925945282,
      "learning_rate": 4.1983104360440314e-05,
      "loss": 0.0023,
      "step": 18790
    },
    {
      "epoch": 1.6042324430412152,
      "grad_norm": 0.05065760761499405,
      "learning_rate": 4.197883778479393e-05,
      "loss": 0.0028,
      "step": 18800
    },
    {
      "epoch": 1.6050857581704925,
      "grad_norm": 0.39394620060920715,
      "learning_rate": 4.197457120914754e-05,
      "loss": 0.0019,
      "step": 18810
    },
    {
      "epoch": 1.6059390732997696,
      "grad_norm": 0.07935423403978348,
      "learning_rate": 4.197030463350116e-05,
      "loss": 0.0028,
      "step": 18820
    },
    {
      "epoch": 1.6067923884290467,
      "grad_norm": 0.5756520628929138,
      "learning_rate": 4.1966038057854764e-05,
      "loss": 0.0023,
      "step": 18830
    },
    {
      "epoch": 1.607645703558324,
      "grad_norm": 0.5431109666824341,
      "learning_rate": 4.1961771482208385e-05,
      "loss": 0.0031,
      "step": 18840
    },
    {
      "epoch": 1.6084990186876014,
      "grad_norm": 0.27356940507888794,
      "learning_rate": 4.195750490656199e-05,
      "loss": 0.0027,
      "step": 18850
    },
    {
      "epoch": 1.6093523338168785,
      "grad_norm": 0.1582256406545639,
      "learning_rate": 4.1953238330915614e-05,
      "loss": 0.0027,
      "step": 18860
    },
    {
      "epoch": 1.6102056489461558,
      "grad_norm": 0.07643963396549225,
      "learning_rate": 4.194897175526922e-05,
      "loss": 0.003,
      "step": 18870
    },
    {
      "epoch": 1.6110589640754331,
      "grad_norm": 0.2698362469673157,
      "learning_rate": 4.1944705179622836e-05,
      "loss": 0.0033,
      "step": 18880
    },
    {
      "epoch": 1.6119122792047103,
      "grad_norm": 0.11533413827419281,
      "learning_rate": 4.194043860397645e-05,
      "loss": 0.0022,
      "step": 18890
    },
    {
      "epoch": 1.6127655943339876,
      "grad_norm": 0.36272019147872925,
      "learning_rate": 4.1936172028330064e-05,
      "loss": 0.0028,
      "step": 18900
    },
    {
      "epoch": 1.613618909463265,
      "grad_norm": 0.2889067828655243,
      "learning_rate": 4.193190545268368e-05,
      "loss": 0.0023,
      "step": 18910
    },
    {
      "epoch": 1.614472224592542,
      "grad_norm": 0.4340271055698395,
      "learning_rate": 4.192763887703729e-05,
      "loss": 0.003,
      "step": 18920
    },
    {
      "epoch": 1.6153255397218191,
      "grad_norm": 0.33873865008354187,
      "learning_rate": 4.192337230139091e-05,
      "loss": 0.0026,
      "step": 18930
    },
    {
      "epoch": 1.6161788548510965,
      "grad_norm": 0.20365090668201447,
      "learning_rate": 4.1919105725744514e-05,
      "loss": 0.0027,
      "step": 18940
    },
    {
      "epoch": 1.6170321699803738,
      "grad_norm": 0.2410995066165924,
      "learning_rate": 4.1914839150098135e-05,
      "loss": 0.0029,
      "step": 18950
    },
    {
      "epoch": 1.617885485109651,
      "grad_norm": 0.11913536489009857,
      "learning_rate": 4.191057257445174e-05,
      "loss": 0.0021,
      "step": 18960
    },
    {
      "epoch": 1.6187388002389282,
      "grad_norm": 0.23133426904678345,
      "learning_rate": 4.1906305998805364e-05,
      "loss": 0.0029,
      "step": 18970
    },
    {
      "epoch": 1.6195921153682056,
      "grad_norm": 0.7244541645050049,
      "learning_rate": 4.190203942315897e-05,
      "loss": 0.0033,
      "step": 18980
    },
    {
      "epoch": 1.6204454304974827,
      "grad_norm": 0.4326417148113251,
      "learning_rate": 4.189777284751259e-05,
      "loss": 0.0027,
      "step": 18990
    },
    {
      "epoch": 1.6212987456267598,
      "grad_norm": 0.19723628461360931,
      "learning_rate": 4.18935062718662e-05,
      "loss": 0.0022,
      "step": 19000
    },
    {
      "epoch": 1.6221520607560374,
      "grad_norm": 0.4552307426929474,
      "learning_rate": 4.188923969621982e-05,
      "loss": 0.0024,
      "step": 19010
    },
    {
      "epoch": 1.6230053758853145,
      "grad_norm": 0.49181151390075684,
      "learning_rate": 4.188497312057343e-05,
      "loss": 0.0022,
      "step": 19020
    },
    {
      "epoch": 1.6238586910145916,
      "grad_norm": 0.45919927954673767,
      "learning_rate": 4.188070654492704e-05,
      "loss": 0.0023,
      "step": 19030
    },
    {
      "epoch": 1.624712006143869,
      "grad_norm": 0.26027175784111023,
      "learning_rate": 4.1876439969280657e-05,
      "loss": 0.0026,
      "step": 19040
    },
    {
      "epoch": 1.6255653212731462,
      "grad_norm": 0.3832004964351654,
      "learning_rate": 4.187217339363427e-05,
      "loss": 0.0021,
      "step": 19050
    },
    {
      "epoch": 1.6264186364024233,
      "grad_norm": 0.356785386800766,
      "learning_rate": 4.1867906817987885e-05,
      "loss": 0.0029,
      "step": 19060
    },
    {
      "epoch": 1.6272719515317007,
      "grad_norm": 0.1754761040210724,
      "learning_rate": 4.18636402423415e-05,
      "loss": 0.0029,
      "step": 19070
    },
    {
      "epoch": 1.628125266660978,
      "grad_norm": 0.1337430775165558,
      "learning_rate": 4.1859373666695114e-05,
      "loss": 0.0028,
      "step": 19080
    },
    {
      "epoch": 1.6289785817902551,
      "grad_norm": 0.43927663564682007,
      "learning_rate": 4.185510709104873e-05,
      "loss": 0.0037,
      "step": 19090
    },
    {
      "epoch": 1.6298318969195322,
      "grad_norm": 0.05337725952267647,
      "learning_rate": 4.185084051540234e-05,
      "loss": 0.0034,
      "step": 19100
    },
    {
      "epoch": 1.6306852120488098,
      "grad_norm": 0.25315460562705994,
      "learning_rate": 4.1846573939755956e-05,
      "loss": 0.0025,
      "step": 19110
    },
    {
      "epoch": 1.631538527178087,
      "grad_norm": 0.029861928895115852,
      "learning_rate": 4.184230736410957e-05,
      "loss": 0.0022,
      "step": 19120
    },
    {
      "epoch": 1.632391842307364,
      "grad_norm": 0.20842671394348145,
      "learning_rate": 4.1838040788463185e-05,
      "loss": 0.0028,
      "step": 19130
    },
    {
      "epoch": 1.6332451574366413,
      "grad_norm": 0.23918785154819489,
      "learning_rate": 4.183377421281679e-05,
      "loss": 0.0028,
      "step": 19140
    },
    {
      "epoch": 1.6340984725659187,
      "grad_norm": 0.0676768347620964,
      "learning_rate": 4.1829507637170406e-05,
      "loss": 0.0019,
      "step": 19150
    },
    {
      "epoch": 1.6349517876951958,
      "grad_norm": 0.43583840131759644,
      "learning_rate": 4.182524106152402e-05,
      "loss": 0.0031,
      "step": 19160
    },
    {
      "epoch": 1.6358051028244731,
      "grad_norm": 0.3463329076766968,
      "learning_rate": 4.1820974485877635e-05,
      "loss": 0.0032,
      "step": 19170
    },
    {
      "epoch": 1.6366584179537504,
      "grad_norm": 0.2616453766822815,
      "learning_rate": 4.181670791023125e-05,
      "loss": 0.0021,
      "step": 19180
    },
    {
      "epoch": 1.6375117330830276,
      "grad_norm": 0.14232690632343292,
      "learning_rate": 4.1812441334584863e-05,
      "loss": 0.003,
      "step": 19190
    },
    {
      "epoch": 1.6383650482123047,
      "grad_norm": 0.152528777718544,
      "learning_rate": 4.180817475893848e-05,
      "loss": 0.0021,
      "step": 19200
    },
    {
      "epoch": 1.639218363341582,
      "grad_norm": 0.19422844052314758,
      "learning_rate": 4.180390818329209e-05,
      "loss": 0.0025,
      "step": 19210
    },
    {
      "epoch": 1.6400716784708593,
      "grad_norm": 0.21305839717388153,
      "learning_rate": 4.1799641607645706e-05,
      "loss": 0.0029,
      "step": 19220
    },
    {
      "epoch": 1.6409249936001364,
      "grad_norm": 0.11909380555152893,
      "learning_rate": 4.179537503199932e-05,
      "loss": 0.0027,
      "step": 19230
    },
    {
      "epoch": 1.6417783087294138,
      "grad_norm": 0.04559991508722305,
      "learning_rate": 4.1791108456352935e-05,
      "loss": 0.0027,
      "step": 19240
    },
    {
      "epoch": 1.642631623858691,
      "grad_norm": 0.5156053900718689,
      "learning_rate": 4.178684188070654e-05,
      "loss": 0.0029,
      "step": 19250
    },
    {
      "epoch": 1.6434849389879682,
      "grad_norm": 0.4668394923210144,
      "learning_rate": 4.178257530506016e-05,
      "loss": 0.0028,
      "step": 19260
    },
    {
      "epoch": 1.6443382541172455,
      "grad_norm": 0.1692160964012146,
      "learning_rate": 4.177830872941377e-05,
      "loss": 0.0036,
      "step": 19270
    },
    {
      "epoch": 1.6451915692465229,
      "grad_norm": 0.2659740746021271,
      "learning_rate": 4.177404215376739e-05,
      "loss": 0.0025,
      "step": 19280
    },
    {
      "epoch": 1.6460448843758,
      "grad_norm": 0.22050796449184418,
      "learning_rate": 4.1769775578121e-05,
      "loss": 0.0024,
      "step": 19290
    },
    {
      "epoch": 1.646898199505077,
      "grad_norm": 0.06409145891666412,
      "learning_rate": 4.176550900247462e-05,
      "loss": 0.0041,
      "step": 19300
    },
    {
      "epoch": 1.6477515146343544,
      "grad_norm": 0.1733192503452301,
      "learning_rate": 4.176124242682823e-05,
      "loss": 0.0027,
      "step": 19310
    },
    {
      "epoch": 1.6486048297636318,
      "grad_norm": 0.2123371660709381,
      "learning_rate": 4.175697585118185e-05,
      "loss": 0.0035,
      "step": 19320
    },
    {
      "epoch": 1.6494581448929089,
      "grad_norm": 0.34669995307922363,
      "learning_rate": 4.1752709275535456e-05,
      "loss": 0.0027,
      "step": 19330
    },
    {
      "epoch": 1.6503114600221862,
      "grad_norm": 0.30524468421936035,
      "learning_rate": 4.174844269988907e-05,
      "loss": 0.0037,
      "step": 19340
    },
    {
      "epoch": 1.6511647751514635,
      "grad_norm": 0.2708803713321686,
      "learning_rate": 4.1744176124242685e-05,
      "loss": 0.0026,
      "step": 19350
    },
    {
      "epoch": 1.6520180902807406,
      "grad_norm": 0.09964596480131149,
      "learning_rate": 4.17399095485963e-05,
      "loss": 0.0021,
      "step": 19360
    },
    {
      "epoch": 1.6528714054100178,
      "grad_norm": 0.08351495116949081,
      "learning_rate": 4.173564297294991e-05,
      "loss": 0.0025,
      "step": 19370
    },
    {
      "epoch": 1.6537247205392953,
      "grad_norm": 0.08001045137643814,
      "learning_rate": 4.173137639730353e-05,
      "loss": 0.0032,
      "step": 19380
    },
    {
      "epoch": 1.6545780356685724,
      "grad_norm": 0.1747719943523407,
      "learning_rate": 4.172710982165714e-05,
      "loss": 0.0024,
      "step": 19390
    },
    {
      "epoch": 1.6554313507978495,
      "grad_norm": 0.132535919547081,
      "learning_rate": 4.172284324601075e-05,
      "loss": 0.0028,
      "step": 19400
    },
    {
      "epoch": 1.6562846659271269,
      "grad_norm": 0.08416654169559479,
      "learning_rate": 4.171857667036437e-05,
      "loss": 0.003,
      "step": 19410
    },
    {
      "epoch": 1.6571379810564042,
      "grad_norm": 0.16559571027755737,
      "learning_rate": 4.171431009471798e-05,
      "loss": 0.0026,
      "step": 19420
    },
    {
      "epoch": 1.6579912961856813,
      "grad_norm": 0.03982306271791458,
      "learning_rate": 4.17100435190716e-05,
      "loss": 0.0026,
      "step": 19430
    },
    {
      "epoch": 1.6588446113149586,
      "grad_norm": 0.24939267337322235,
      "learning_rate": 4.1705776943425206e-05,
      "loss": 0.0034,
      "step": 19440
    },
    {
      "epoch": 1.659697926444236,
      "grad_norm": 0.05754384398460388,
      "learning_rate": 4.170151036777882e-05,
      "loss": 0.0036,
      "step": 19450
    },
    {
      "epoch": 1.660551241573513,
      "grad_norm": 0.085391104221344,
      "learning_rate": 4.1697243792132434e-05,
      "loss": 0.0026,
      "step": 19460
    },
    {
      "epoch": 1.6614045567027902,
      "grad_norm": 0.30248141288757324,
      "learning_rate": 4.169297721648605e-05,
      "loss": 0.0027,
      "step": 19470
    },
    {
      "epoch": 1.6622578718320677,
      "grad_norm": 0.18966923654079437,
      "learning_rate": 4.168871064083966e-05,
      "loss": 0.0029,
      "step": 19480
    },
    {
      "epoch": 1.6631111869613449,
      "grad_norm": 0.11543188244104385,
      "learning_rate": 4.168444406519328e-05,
      "loss": 0.0021,
      "step": 19490
    },
    {
      "epoch": 1.663964502090622,
      "grad_norm": 0.07910092920064926,
      "learning_rate": 4.168017748954689e-05,
      "loss": 0.0022,
      "step": 19500
    },
    {
      "epoch": 1.6648178172198993,
      "grad_norm": 0.17599986493587494,
      "learning_rate": 4.1675910913900506e-05,
      "loss": 0.0028,
      "step": 19510
    },
    {
      "epoch": 1.6656711323491766,
      "grad_norm": 0.40880143642425537,
      "learning_rate": 4.167164433825412e-05,
      "loss": 0.0028,
      "step": 19520
    },
    {
      "epoch": 1.6665244474784537,
      "grad_norm": 0.08255945146083832,
      "learning_rate": 4.1667377762607734e-05,
      "loss": 0.0029,
      "step": 19530
    },
    {
      "epoch": 1.667377762607731,
      "grad_norm": 0.3397742807865143,
      "learning_rate": 4.166311118696135e-05,
      "loss": 0.0026,
      "step": 19540
    },
    {
      "epoch": 1.6682310777370084,
      "grad_norm": 0.2056998908519745,
      "learning_rate": 4.165884461131496e-05,
      "loss": 0.0031,
      "step": 19550
    },
    {
      "epoch": 1.6690843928662855,
      "grad_norm": 0.36741578578948975,
      "learning_rate": 4.165457803566857e-05,
      "loss": 0.0026,
      "step": 19560
    },
    {
      "epoch": 1.6699377079955626,
      "grad_norm": 0.23591524362564087,
      "learning_rate": 4.165031146002219e-05,
      "loss": 0.0034,
      "step": 19570
    },
    {
      "epoch": 1.67079102312484,
      "grad_norm": 0.2726489007472992,
      "learning_rate": 4.16460448843758e-05,
      "loss": 0.0028,
      "step": 19580
    },
    {
      "epoch": 1.6716443382541173,
      "grad_norm": 0.17130999267101288,
      "learning_rate": 4.164177830872942e-05,
      "loss": 0.0031,
      "step": 19590
    },
    {
      "epoch": 1.6724976533833944,
      "grad_norm": 0.21887516975402832,
      "learning_rate": 4.163751173308303e-05,
      "loss": 0.0027,
      "step": 19600
    },
    {
      "epoch": 1.6733509685126717,
      "grad_norm": 0.3138228952884674,
      "learning_rate": 4.163324515743665e-05,
      "loss": 0.0036,
      "step": 19610
    },
    {
      "epoch": 1.674204283641949,
      "grad_norm": 0.10118251293897629,
      "learning_rate": 4.1628978581790255e-05,
      "loss": 0.0024,
      "step": 19620
    },
    {
      "epoch": 1.6750575987712262,
      "grad_norm": 0.130545511841774,
      "learning_rate": 4.1624712006143876e-05,
      "loss": 0.0027,
      "step": 19630
    },
    {
      "epoch": 1.6759109139005035,
      "grad_norm": 0.37839674949645996,
      "learning_rate": 4.1620445430497484e-05,
      "loss": 0.0031,
      "step": 19640
    },
    {
      "epoch": 1.6767642290297808,
      "grad_norm": 0.5491481423377991,
      "learning_rate": 4.16161788548511e-05,
      "loss": 0.0039,
      "step": 19650
    },
    {
      "epoch": 1.677617544159058,
      "grad_norm": 0.13112547993659973,
      "learning_rate": 4.161191227920471e-05,
      "loss": 0.0021,
      "step": 19660
    },
    {
      "epoch": 1.678470859288335,
      "grad_norm": 0.19338546693325043,
      "learning_rate": 4.160764570355833e-05,
      "loss": 0.0027,
      "step": 19670
    },
    {
      "epoch": 1.6793241744176124,
      "grad_norm": 0.4724906086921692,
      "learning_rate": 4.160337912791194e-05,
      "loss": 0.0022,
      "step": 19680
    },
    {
      "epoch": 1.6801774895468897,
      "grad_norm": 0.3603273332118988,
      "learning_rate": 4.159911255226555e-05,
      "loss": 0.0031,
      "step": 19690
    },
    {
      "epoch": 1.6810308046761668,
      "grad_norm": 0.26888129115104675,
      "learning_rate": 4.159484597661917e-05,
      "loss": 0.0028,
      "step": 19700
    },
    {
      "epoch": 1.6818841198054442,
      "grad_norm": 0.20737603306770325,
      "learning_rate": 4.159057940097278e-05,
      "loss": 0.0022,
      "step": 19710
    },
    {
      "epoch": 1.6827374349347215,
      "grad_norm": 0.19066022336483002,
      "learning_rate": 4.15863128253264e-05,
      "loss": 0.0021,
      "step": 19720
    },
    {
      "epoch": 1.6835907500639986,
      "grad_norm": 0.06777364015579224,
      "learning_rate": 4.1582046249680005e-05,
      "loss": 0.003,
      "step": 19730
    },
    {
      "epoch": 1.6844440651932757,
      "grad_norm": 0.21784910559654236,
      "learning_rate": 4.1577779674033626e-05,
      "loss": 0.003,
      "step": 19740
    },
    {
      "epoch": 1.6852973803225533,
      "grad_norm": 0.18130895495414734,
      "learning_rate": 4.1573513098387234e-05,
      "loss": 0.0025,
      "step": 19750
    },
    {
      "epoch": 1.6861506954518304,
      "grad_norm": 0.08920169621706009,
      "learning_rate": 4.156924652274085e-05,
      "loss": 0.002,
      "step": 19760
    },
    {
      "epoch": 1.6870040105811075,
      "grad_norm": 0.34404826164245605,
      "learning_rate": 4.156497994709446e-05,
      "loss": 0.0025,
      "step": 19770
    },
    {
      "epoch": 1.6878573257103848,
      "grad_norm": 0.23438338935375214,
      "learning_rate": 4.1560713371448077e-05,
      "loss": 0.0024,
      "step": 19780
    },
    {
      "epoch": 1.6887106408396622,
      "grad_norm": 0.05589677765965462,
      "learning_rate": 4.155644679580169e-05,
      "loss": 0.0028,
      "step": 19790
    },
    {
      "epoch": 1.6895639559689393,
      "grad_norm": 0.10322345793247223,
      "learning_rate": 4.1552180220155305e-05,
      "loss": 0.002,
      "step": 19800
    },
    {
      "epoch": 1.6904172710982166,
      "grad_norm": 0.0394856259226799,
      "learning_rate": 4.154791364450892e-05,
      "loss": 0.0019,
      "step": 19810
    },
    {
      "epoch": 1.691270586227494,
      "grad_norm": 0.36808013916015625,
      "learning_rate": 4.1543647068862534e-05,
      "loss": 0.003,
      "step": 19820
    },
    {
      "epoch": 1.692123901356771,
      "grad_norm": 0.24594198167324066,
      "learning_rate": 4.153938049321615e-05,
      "loss": 0.0021,
      "step": 19830
    },
    {
      "epoch": 1.6929772164860482,
      "grad_norm": 0.4092012643814087,
      "learning_rate": 4.153511391756976e-05,
      "loss": 0.0034,
      "step": 19840
    },
    {
      "epoch": 1.6938305316153255,
      "grad_norm": 0.05954425781965256,
      "learning_rate": 4.1530847341923376e-05,
      "loss": 0.0022,
      "step": 19850
    },
    {
      "epoch": 1.6946838467446028,
      "grad_norm": 0.23006556928157806,
      "learning_rate": 4.152658076627699e-05,
      "loss": 0.0033,
      "step": 19860
    },
    {
      "epoch": 1.69553716187388,
      "grad_norm": 0.5250258445739746,
      "learning_rate": 4.15223141906306e-05,
      "loss": 0.0039,
      "step": 19870
    },
    {
      "epoch": 1.6963904770031573,
      "grad_norm": 0.14013203978538513,
      "learning_rate": 4.151804761498422e-05,
      "loss": 0.0035,
      "step": 19880
    },
    {
      "epoch": 1.6972437921324346,
      "grad_norm": 0.2234380841255188,
      "learning_rate": 4.1513781039337826e-05,
      "loss": 0.0029,
      "step": 19890
    },
    {
      "epoch": 1.6980971072617117,
      "grad_norm": 0.2289230078458786,
      "learning_rate": 4.150951446369145e-05,
      "loss": 0.0026,
      "step": 19900
    },
    {
      "epoch": 1.698950422390989,
      "grad_norm": 0.08169101923704147,
      "learning_rate": 4.1505247888045055e-05,
      "loss": 0.0031,
      "step": 19910
    },
    {
      "epoch": 1.6998037375202664,
      "grad_norm": 0.1398835927248001,
      "learning_rate": 4.1500981312398676e-05,
      "loss": 0.0025,
      "step": 19920
    },
    {
      "epoch": 1.7006570526495435,
      "grad_norm": 0.04584697261452675,
      "learning_rate": 4.1496714736752283e-05,
      "loss": 0.0033,
      "step": 19930
    },
    {
      "epoch": 1.7015103677788206,
      "grad_norm": 0.037427134811878204,
      "learning_rate": 4.14924481611059e-05,
      "loss": 0.0027,
      "step": 19940
    },
    {
      "epoch": 1.702363682908098,
      "grad_norm": 0.18752135336399078,
      "learning_rate": 4.148818158545951e-05,
      "loss": 0.003,
      "step": 19950
    },
    {
      "epoch": 1.7032169980373753,
      "grad_norm": 0.09158193320035934,
      "learning_rate": 4.1483915009813126e-05,
      "loss": 0.0024,
      "step": 19960
    },
    {
      "epoch": 1.7040703131666524,
      "grad_norm": 0.5669013261795044,
      "learning_rate": 4.147964843416674e-05,
      "loss": 0.0024,
      "step": 19970
    },
    {
      "epoch": 1.7049236282959297,
      "grad_norm": 0.7275865077972412,
      "learning_rate": 4.1475381858520355e-05,
      "loss": 0.0032,
      "step": 19980
    },
    {
      "epoch": 1.705776943425207,
      "grad_norm": 0.26377421617507935,
      "learning_rate": 4.147111528287397e-05,
      "loss": 0.003,
      "step": 19990
    },
    {
      "epoch": 1.7066302585544841,
      "grad_norm": 0.13433046638965607,
      "learning_rate": 4.1466848707227576e-05,
      "loss": 0.0032,
      "step": 20000
    },
    {
      "epoch": 1.7074835736837615,
      "grad_norm": 0.17226582765579224,
      "learning_rate": 4.14625821315812e-05,
      "loss": 0.0028,
      "step": 20010
    },
    {
      "epoch": 1.7083368888130388,
      "grad_norm": 0.09626933187246323,
      "learning_rate": 4.1458315555934805e-05,
      "loss": 0.003,
      "step": 20020
    },
    {
      "epoch": 1.709190203942316,
      "grad_norm": 0.1120622530579567,
      "learning_rate": 4.1454048980288426e-05,
      "loss": 0.0032,
      "step": 20030
    },
    {
      "epoch": 1.710043519071593,
      "grad_norm": 0.12771408259868622,
      "learning_rate": 4.144978240464203e-05,
      "loss": 0.0025,
      "step": 20040
    },
    {
      "epoch": 1.7108968342008704,
      "grad_norm": 0.17675986886024475,
      "learning_rate": 4.1445515828995654e-05,
      "loss": 0.0026,
      "step": 20050
    },
    {
      "epoch": 1.7117501493301477,
      "grad_norm": 0.22489877045154572,
      "learning_rate": 4.144124925334926e-05,
      "loss": 0.0023,
      "step": 20060
    },
    {
      "epoch": 1.7126034644594248,
      "grad_norm": 0.05571866035461426,
      "learning_rate": 4.1436982677702876e-05,
      "loss": 0.0029,
      "step": 20070
    },
    {
      "epoch": 1.7134567795887021,
      "grad_norm": 0.22467975318431854,
      "learning_rate": 4.143271610205649e-05,
      "loss": 0.0022,
      "step": 20080
    },
    {
      "epoch": 1.7143100947179795,
      "grad_norm": 0.16801251471042633,
      "learning_rate": 4.1428449526410104e-05,
      "loss": 0.0026,
      "step": 20090
    },
    {
      "epoch": 1.7151634098472566,
      "grad_norm": 0.29232698678970337,
      "learning_rate": 4.142418295076372e-05,
      "loss": 0.0025,
      "step": 20100
    },
    {
      "epoch": 1.7160167249765337,
      "grad_norm": 0.2725207209587097,
      "learning_rate": 4.141991637511733e-05,
      "loss": 0.0029,
      "step": 20110
    },
    {
      "epoch": 1.7168700401058112,
      "grad_norm": 0.0820094645023346,
      "learning_rate": 4.141564979947095e-05,
      "loss": 0.0026,
      "step": 20120
    },
    {
      "epoch": 1.7177233552350883,
      "grad_norm": 0.12082009762525558,
      "learning_rate": 4.141138322382456e-05,
      "loss": 0.0027,
      "step": 20130
    },
    {
      "epoch": 1.7185766703643655,
      "grad_norm": 0.13336925208568573,
      "learning_rate": 4.1407116648178176e-05,
      "loss": 0.0025,
      "step": 20140
    },
    {
      "epoch": 1.7194299854936428,
      "grad_norm": 0.3103855550289154,
      "learning_rate": 4.140285007253179e-05,
      "loss": 0.0029,
      "step": 20150
    },
    {
      "epoch": 1.7202833006229201,
      "grad_norm": 0.18865691125392914,
      "learning_rate": 4.1398583496885404e-05,
      "loss": 0.0032,
      "step": 20160
    },
    {
      "epoch": 1.7211366157521972,
      "grad_norm": 0.11171641945838928,
      "learning_rate": 4.139431692123902e-05,
      "loss": 0.0032,
      "step": 20170
    },
    {
      "epoch": 1.7219899308814746,
      "grad_norm": 0.37064558267593384,
      "learning_rate": 4.1390050345592626e-05,
      "loss": 0.0027,
      "step": 20180
    },
    {
      "epoch": 1.722843246010752,
      "grad_norm": 0.155062735080719,
      "learning_rate": 4.138578376994625e-05,
      "loss": 0.0029,
      "step": 20190
    },
    {
      "epoch": 1.723696561140029,
      "grad_norm": 0.06096242368221283,
      "learning_rate": 4.1381517194299854e-05,
      "loss": 0.0033,
      "step": 20200
    },
    {
      "epoch": 1.7245498762693061,
      "grad_norm": 0.2741490602493286,
      "learning_rate": 4.137725061865347e-05,
      "loss": 0.003,
      "step": 20210
    },
    {
      "epoch": 1.7254031913985834,
      "grad_norm": 0.2078661322593689,
      "learning_rate": 4.137298404300708e-05,
      "loss": 0.0028,
      "step": 20220
    },
    {
      "epoch": 1.7262565065278608,
      "grad_norm": 0.1927250325679779,
      "learning_rate": 4.13687174673607e-05,
      "loss": 0.0034,
      "step": 20230
    },
    {
      "epoch": 1.727109821657138,
      "grad_norm": 0.3055374324321747,
      "learning_rate": 4.136445089171431e-05,
      "loss": 0.0034,
      "step": 20240
    },
    {
      "epoch": 1.7279631367864152,
      "grad_norm": 0.1585148274898529,
      "learning_rate": 4.1360184316067926e-05,
      "loss": 0.0022,
      "step": 20250
    },
    {
      "epoch": 1.7288164519156926,
      "grad_norm": 0.6058725118637085,
      "learning_rate": 4.135591774042154e-05,
      "loss": 0.0029,
      "step": 20260
    },
    {
      "epoch": 1.7296697670449697,
      "grad_norm": 0.06608614325523376,
      "learning_rate": 4.1351651164775154e-05,
      "loss": 0.0029,
      "step": 20270
    },
    {
      "epoch": 1.730523082174247,
      "grad_norm": 0.025706345215439796,
      "learning_rate": 4.134738458912877e-05,
      "loss": 0.0028,
      "step": 20280
    },
    {
      "epoch": 1.7313763973035243,
      "grad_norm": 0.2849629521369934,
      "learning_rate": 4.134311801348238e-05,
      "loss": 0.0027,
      "step": 20290
    },
    {
      "epoch": 1.7322297124328014,
      "grad_norm": 0.2363666594028473,
      "learning_rate": 4.1338851437836e-05,
      "loss": 0.0029,
      "step": 20300
    },
    {
      "epoch": 1.7330830275620785,
      "grad_norm": 0.5064858198165894,
      "learning_rate": 4.1334584862189604e-05,
      "loss": 0.0032,
      "step": 20310
    },
    {
      "epoch": 1.7339363426913559,
      "grad_norm": 0.5246508121490479,
      "learning_rate": 4.1330318286543225e-05,
      "loss": 0.0026,
      "step": 20320
    },
    {
      "epoch": 1.7347896578206332,
      "grad_norm": 0.0491519533097744,
      "learning_rate": 4.132605171089683e-05,
      "loss": 0.0024,
      "step": 20330
    },
    {
      "epoch": 1.7356429729499103,
      "grad_norm": 0.42187145352363586,
      "learning_rate": 4.1321785135250454e-05,
      "loss": 0.0032,
      "step": 20340
    },
    {
      "epoch": 1.7364962880791877,
      "grad_norm": 0.2487567812204361,
      "learning_rate": 4.131751855960406e-05,
      "loss": 0.0032,
      "step": 20350
    },
    {
      "epoch": 1.737349603208465,
      "grad_norm": 0.21367819607257843,
      "learning_rate": 4.131325198395768e-05,
      "loss": 0.0028,
      "step": 20360
    },
    {
      "epoch": 1.738202918337742,
      "grad_norm": 0.22955329716205597,
      "learning_rate": 4.130898540831129e-05,
      "loss": 0.0025,
      "step": 20370
    },
    {
      "epoch": 1.7390562334670192,
      "grad_norm": 0.13967019319534302,
      "learning_rate": 4.1304718832664904e-05,
      "loss": 0.0027,
      "step": 20380
    },
    {
      "epoch": 1.7399095485962968,
      "grad_norm": 0.25550252199172974,
      "learning_rate": 4.130045225701852e-05,
      "loss": 0.0027,
      "step": 20390
    },
    {
      "epoch": 1.7407628637255739,
      "grad_norm": 0.32369959354400635,
      "learning_rate": 4.129618568137213e-05,
      "loss": 0.0031,
      "step": 20400
    },
    {
      "epoch": 1.741616178854851,
      "grad_norm": 0.17255333065986633,
      "learning_rate": 4.129191910572575e-05,
      "loss": 0.0027,
      "step": 20410
    },
    {
      "epoch": 1.7424694939841283,
      "grad_norm": 0.02644987590610981,
      "learning_rate": 4.128765253007936e-05,
      "loss": 0.0031,
      "step": 20420
    },
    {
      "epoch": 1.7433228091134056,
      "grad_norm": 0.16618719696998596,
      "learning_rate": 4.1283385954432975e-05,
      "loss": 0.0023,
      "step": 20430
    },
    {
      "epoch": 1.7441761242426828,
      "grad_norm": 0.3382112681865692,
      "learning_rate": 4.127911937878659e-05,
      "loss": 0.0024,
      "step": 20440
    },
    {
      "epoch": 1.74502943937196,
      "grad_norm": 0.4292113482952118,
      "learning_rate": 4.1274852803140204e-05,
      "loss": 0.0028,
      "step": 20450
    },
    {
      "epoch": 1.7458827545012374,
      "grad_norm": 0.06728757917881012,
      "learning_rate": 4.127058622749382e-05,
      "loss": 0.0031,
      "step": 20460
    },
    {
      "epoch": 1.7467360696305145,
      "grad_norm": 0.05721227824687958,
      "learning_rate": 4.126631965184743e-05,
      "loss": 0.0024,
      "step": 20470
    },
    {
      "epoch": 1.7475893847597916,
      "grad_norm": 0.710525631904602,
      "learning_rate": 4.126205307620104e-05,
      "loss": 0.0025,
      "step": 20480
    },
    {
      "epoch": 1.7484426998890692,
      "grad_norm": 0.6212291717529297,
      "learning_rate": 4.1257786500554654e-05,
      "loss": 0.0029,
      "step": 20490
    },
    {
      "epoch": 1.7492960150183463,
      "grad_norm": 0.169620543718338,
      "learning_rate": 4.125351992490827e-05,
      "loss": 0.0028,
      "step": 20500
    },
    {
      "epoch": 1.7501493301476234,
      "grad_norm": 0.15548689663410187,
      "learning_rate": 4.124925334926188e-05,
      "loss": 0.0016,
      "step": 20510
    },
    {
      "epoch": 1.7510026452769007,
      "grad_norm": 0.152350053191185,
      "learning_rate": 4.1244986773615497e-05,
      "loss": 0.0025,
      "step": 20520
    },
    {
      "epoch": 1.751855960406178,
      "grad_norm": 0.21094609797000885,
      "learning_rate": 4.124072019796911e-05,
      "loss": 0.0022,
      "step": 20530
    },
    {
      "epoch": 1.7527092755354552,
      "grad_norm": 0.28235265612602234,
      "learning_rate": 4.1236453622322725e-05,
      "loss": 0.0021,
      "step": 20540
    },
    {
      "epoch": 1.7535625906647325,
      "grad_norm": 0.11168445646762848,
      "learning_rate": 4.123218704667634e-05,
      "loss": 0.0027,
      "step": 20550
    },
    {
      "epoch": 1.7544159057940099,
      "grad_norm": 0.09916260838508606,
      "learning_rate": 4.1227920471029953e-05,
      "loss": 0.0019,
      "step": 20560
    },
    {
      "epoch": 1.755269220923287,
      "grad_norm": 0.0757996216416359,
      "learning_rate": 4.122365389538357e-05,
      "loss": 0.0029,
      "step": 20570
    },
    {
      "epoch": 1.756122536052564,
      "grad_norm": 0.49881041049957275,
      "learning_rate": 4.121938731973718e-05,
      "loss": 0.0026,
      "step": 20580
    },
    {
      "epoch": 1.7569758511818414,
      "grad_norm": 0.049698684364557266,
      "learning_rate": 4.1215120744090796e-05,
      "loss": 0.0029,
      "step": 20590
    },
    {
      "epoch": 1.7578291663111187,
      "grad_norm": 0.04867559298872948,
      "learning_rate": 4.121085416844441e-05,
      "loss": 0.002,
      "step": 20600
    },
    {
      "epoch": 1.7586824814403959,
      "grad_norm": 0.2620455026626587,
      "learning_rate": 4.1206587592798025e-05,
      "loss": 0.0032,
      "step": 20610
    },
    {
      "epoch": 1.7595357965696732,
      "grad_norm": 0.48339542746543884,
      "learning_rate": 4.120232101715163e-05,
      "loss": 0.0024,
      "step": 20620
    },
    {
      "epoch": 1.7603891116989505,
      "grad_norm": 0.3595789968967438,
      "learning_rate": 4.119805444150525e-05,
      "loss": 0.0028,
      "step": 20630
    },
    {
      "epoch": 1.7612424268282276,
      "grad_norm": 0.3792823553085327,
      "learning_rate": 4.119378786585886e-05,
      "loss": 0.0031,
      "step": 20640
    },
    {
      "epoch": 1.762095741957505,
      "grad_norm": 0.3022249937057495,
      "learning_rate": 4.118952129021248e-05,
      "loss": 0.0026,
      "step": 20650
    },
    {
      "epoch": 1.7629490570867823,
      "grad_norm": 0.5880699753761292,
      "learning_rate": 4.118525471456609e-05,
      "loss": 0.0028,
      "step": 20660
    },
    {
      "epoch": 1.7638023722160594,
      "grad_norm": 0.4375092685222626,
      "learning_rate": 4.118098813891971e-05,
      "loss": 0.0022,
      "step": 20670
    },
    {
      "epoch": 1.7646556873453365,
      "grad_norm": 0.03743778169155121,
      "learning_rate": 4.117672156327332e-05,
      "loss": 0.003,
      "step": 20680
    },
    {
      "epoch": 1.7655090024746138,
      "grad_norm": 0.11561085283756256,
      "learning_rate": 4.117245498762693e-05,
      "loss": 0.0027,
      "step": 20690
    },
    {
      "epoch": 1.7663623176038912,
      "grad_norm": 0.032343801110982895,
      "learning_rate": 4.1168188411980546e-05,
      "loss": 0.0025,
      "step": 20700
    },
    {
      "epoch": 1.7672156327331683,
      "grad_norm": 0.26356905698776245,
      "learning_rate": 4.116392183633416e-05,
      "loss": 0.0034,
      "step": 20710
    },
    {
      "epoch": 1.7680689478624456,
      "grad_norm": 0.13267415761947632,
      "learning_rate": 4.1159655260687775e-05,
      "loss": 0.0026,
      "step": 20720
    },
    {
      "epoch": 1.768922262991723,
      "grad_norm": 0.22705921530723572,
      "learning_rate": 4.115538868504138e-05,
      "loss": 0.002,
      "step": 20730
    },
    {
      "epoch": 1.769775578121,
      "grad_norm": 0.04821775108575821,
      "learning_rate": 4.1151122109395e-05,
      "loss": 0.0024,
      "step": 20740
    },
    {
      "epoch": 1.7706288932502772,
      "grad_norm": 0.17241732776165009,
      "learning_rate": 4.114685553374861e-05,
      "loss": 0.0027,
      "step": 20750
    },
    {
      "epoch": 1.7714822083795547,
      "grad_norm": 0.09714466333389282,
      "learning_rate": 4.114258895810223e-05,
      "loss": 0.003,
      "step": 20760
    },
    {
      "epoch": 1.7723355235088318,
      "grad_norm": 0.22902943193912506,
      "learning_rate": 4.113832238245584e-05,
      "loss": 0.0034,
      "step": 20770
    },
    {
      "epoch": 1.773188838638109,
      "grad_norm": 0.06420309841632843,
      "learning_rate": 4.113405580680946e-05,
      "loss": 0.0029,
      "step": 20780
    },
    {
      "epoch": 1.7740421537673863,
      "grad_norm": 0.09985855221748352,
      "learning_rate": 4.112978923116307e-05,
      "loss": 0.0026,
      "step": 20790
    },
    {
      "epoch": 1.7748954688966636,
      "grad_norm": 0.305224746465683,
      "learning_rate": 4.112552265551668e-05,
      "loss": 0.0024,
      "step": 20800
    },
    {
      "epoch": 1.7757487840259407,
      "grad_norm": 0.3031017780303955,
      "learning_rate": 4.1121256079870296e-05,
      "loss": 0.0033,
      "step": 20810
    },
    {
      "epoch": 1.776602099155218,
      "grad_norm": 0.06386210024356842,
      "learning_rate": 4.111698950422391e-05,
      "loss": 0.0032,
      "step": 20820
    },
    {
      "epoch": 1.7774554142844954,
      "grad_norm": 0.09739682823419571,
      "learning_rate": 4.1112722928577524e-05,
      "loss": 0.0031,
      "step": 20830
    },
    {
      "epoch": 1.7783087294137725,
      "grad_norm": 0.03351161628961563,
      "learning_rate": 4.110845635293114e-05,
      "loss": 0.0028,
      "step": 20840
    },
    {
      "epoch": 1.7791620445430496,
      "grad_norm": 0.19678352773189545,
      "learning_rate": 4.110418977728475e-05,
      "loss": 0.0029,
      "step": 20850
    },
    {
      "epoch": 1.780015359672327,
      "grad_norm": 0.21207499504089355,
      "learning_rate": 4.109992320163837e-05,
      "loss": 0.0025,
      "step": 20860
    },
    {
      "epoch": 1.7808686748016043,
      "grad_norm": 0.23348455131053925,
      "learning_rate": 4.109565662599198e-05,
      "loss": 0.0024,
      "step": 20870
    },
    {
      "epoch": 1.7817219899308814,
      "grad_norm": 0.13953948020935059,
      "learning_rate": 4.1091390050345596e-05,
      "loss": 0.0028,
      "step": 20880
    },
    {
      "epoch": 1.7825753050601587,
      "grad_norm": 0.4402208924293518,
      "learning_rate": 4.108712347469921e-05,
      "loss": 0.002,
      "step": 20890
    },
    {
      "epoch": 1.783428620189436,
      "grad_norm": 0.36428144574165344,
      "learning_rate": 4.1082856899052824e-05,
      "loss": 0.0029,
      "step": 20900
    },
    {
      "epoch": 1.7842819353187132,
      "grad_norm": 0.5789238810539246,
      "learning_rate": 4.107859032340644e-05,
      "loss": 0.0027,
      "step": 20910
    },
    {
      "epoch": 1.7851352504479905,
      "grad_norm": 0.5110647082328796,
      "learning_rate": 4.107432374776005e-05,
      "loss": 0.0033,
      "step": 20920
    },
    {
      "epoch": 1.7859885655772678,
      "grad_norm": 0.1758824586868286,
      "learning_rate": 4.107005717211366e-05,
      "loss": 0.0025,
      "step": 20930
    },
    {
      "epoch": 1.786841880706545,
      "grad_norm": 0.30972152948379517,
      "learning_rate": 4.106579059646728e-05,
      "loss": 0.0021,
      "step": 20940
    },
    {
      "epoch": 1.787695195835822,
      "grad_norm": 0.051052939146757126,
      "learning_rate": 4.106152402082089e-05,
      "loss": 0.0022,
      "step": 20950
    },
    {
      "epoch": 1.7885485109650994,
      "grad_norm": 0.3224847912788391,
      "learning_rate": 4.105725744517451e-05,
      "loss": 0.0037,
      "step": 20960
    },
    {
      "epoch": 1.7894018260943767,
      "grad_norm": 0.3122216761112213,
      "learning_rate": 4.105299086952812e-05,
      "loss": 0.0019,
      "step": 20970
    },
    {
      "epoch": 1.7902551412236538,
      "grad_norm": 0.2652493417263031,
      "learning_rate": 4.104872429388174e-05,
      "loss": 0.0024,
      "step": 20980
    },
    {
      "epoch": 1.7911084563529311,
      "grad_norm": 0.12153298407793045,
      "learning_rate": 4.1044457718235346e-05,
      "loss": 0.0029,
      "step": 20990
    },
    {
      "epoch": 1.7919617714822085,
      "grad_norm": 0.28599533438682556,
      "learning_rate": 4.104019114258896e-05,
      "loss": 0.0025,
      "step": 21000
    },
    {
      "epoch": 1.7928150866114856,
      "grad_norm": 0.1411784291267395,
      "learning_rate": 4.1035924566942574e-05,
      "loss": 0.0023,
      "step": 21010
    },
    {
      "epoch": 1.793668401740763,
      "grad_norm": 0.07047651708126068,
      "learning_rate": 4.103165799129619e-05,
      "loss": 0.0025,
      "step": 21020
    },
    {
      "epoch": 1.7945217168700403,
      "grad_norm": 0.17079640924930573,
      "learning_rate": 4.10273914156498e-05,
      "loss": 0.0019,
      "step": 21030
    },
    {
      "epoch": 1.7953750319993174,
      "grad_norm": 0.05560138449072838,
      "learning_rate": 4.102312484000341e-05,
      "loss": 0.0031,
      "step": 21040
    },
    {
      "epoch": 1.7962283471285945,
      "grad_norm": 0.15373171865940094,
      "learning_rate": 4.101885826435703e-05,
      "loss": 0.0026,
      "step": 21050
    },
    {
      "epoch": 1.7970816622578718,
      "grad_norm": 0.2554497718811035,
      "learning_rate": 4.101459168871064e-05,
      "loss": 0.0027,
      "step": 21060
    },
    {
      "epoch": 1.7979349773871491,
      "grad_norm": 0.14300121366977692,
      "learning_rate": 4.101032511306426e-05,
      "loss": 0.0025,
      "step": 21070
    },
    {
      "epoch": 1.7987882925164262,
      "grad_norm": 0.2407689392566681,
      "learning_rate": 4.100605853741787e-05,
      "loss": 0.0021,
      "step": 21080
    },
    {
      "epoch": 1.7996416076457036,
      "grad_norm": 0.08055231720209122,
      "learning_rate": 4.100179196177149e-05,
      "loss": 0.002,
      "step": 21090
    },
    {
      "epoch": 1.800494922774981,
      "grad_norm": 0.4559766352176666,
      "learning_rate": 4.0997525386125095e-05,
      "loss": 0.0035,
      "step": 21100
    },
    {
      "epoch": 1.801348237904258,
      "grad_norm": 0.3052937388420105,
      "learning_rate": 4.099325881047871e-05,
      "loss": 0.0024,
      "step": 21110
    },
    {
      "epoch": 1.8022015530335351,
      "grad_norm": 0.19776704907417297,
      "learning_rate": 4.0988992234832324e-05,
      "loss": 0.0024,
      "step": 21120
    },
    {
      "epoch": 1.8030548681628127,
      "grad_norm": 0.39320462942123413,
      "learning_rate": 4.098472565918594e-05,
      "loss": 0.0024,
      "step": 21130
    },
    {
      "epoch": 1.8039081832920898,
      "grad_norm": 0.31303390860557556,
      "learning_rate": 4.098045908353955e-05,
      "loss": 0.0026,
      "step": 21140
    },
    {
      "epoch": 1.804761498421367,
      "grad_norm": 0.269474059343338,
      "learning_rate": 4.0976192507893167e-05,
      "loss": 0.0032,
      "step": 21150
    },
    {
      "epoch": 1.8056148135506442,
      "grad_norm": 0.15249021351337433,
      "learning_rate": 4.097192593224678e-05,
      "loss": 0.0024,
      "step": 21160
    },
    {
      "epoch": 1.8064681286799216,
      "grad_norm": 0.14454622566699982,
      "learning_rate": 4.0967659356600395e-05,
      "loss": 0.0027,
      "step": 21170
    },
    {
      "epoch": 1.8073214438091987,
      "grad_norm": 0.1801224648952484,
      "learning_rate": 4.096339278095401e-05,
      "loss": 0.0026,
      "step": 21180
    },
    {
      "epoch": 1.808174758938476,
      "grad_norm": 0.2841680943965912,
      "learning_rate": 4.0959126205307624e-05,
      "loss": 0.0021,
      "step": 21190
    },
    {
      "epoch": 1.8090280740677533,
      "grad_norm": 0.08211823552846909,
      "learning_rate": 4.095485962966124e-05,
      "loss": 0.003,
      "step": 21200
    },
    {
      "epoch": 1.8098813891970305,
      "grad_norm": 0.32905182242393494,
      "learning_rate": 4.095059305401485e-05,
      "loss": 0.0026,
      "step": 21210
    },
    {
      "epoch": 1.8107347043263076,
      "grad_norm": 0.3472432792186737,
      "learning_rate": 4.0946326478368466e-05,
      "loss": 0.0031,
      "step": 21220
    },
    {
      "epoch": 1.811588019455585,
      "grad_norm": 0.08029112964868546,
      "learning_rate": 4.094205990272208e-05,
      "loss": 0.0027,
      "step": 21230
    },
    {
      "epoch": 1.8124413345848622,
      "grad_norm": 0.6753330826759338,
      "learning_rate": 4.093779332707569e-05,
      "loss": 0.0027,
      "step": 21240
    },
    {
      "epoch": 1.8132946497141393,
      "grad_norm": 0.13938632607460022,
      "learning_rate": 4.093352675142931e-05,
      "loss": 0.0018,
      "step": 21250
    },
    {
      "epoch": 1.8141479648434167,
      "grad_norm": 0.22860616445541382,
      "learning_rate": 4.0929260175782916e-05,
      "loss": 0.002,
      "step": 21260
    },
    {
      "epoch": 1.815001279972694,
      "grad_norm": 0.036074213683605194,
      "learning_rate": 4.092499360013653e-05,
      "loss": 0.0028,
      "step": 21270
    },
    {
      "epoch": 1.8158545951019711,
      "grad_norm": 0.24442745745182037,
      "learning_rate": 4.0920727024490145e-05,
      "loss": 0.0023,
      "step": 21280
    },
    {
      "epoch": 1.8167079102312484,
      "grad_norm": 0.18890543282032013,
      "learning_rate": 4.091646044884376e-05,
      "loss": 0.0026,
      "step": 21290
    },
    {
      "epoch": 1.8175612253605258,
      "grad_norm": 0.04132377356290817,
      "learning_rate": 4.0912193873197373e-05,
      "loss": 0.0022,
      "step": 21300
    },
    {
      "epoch": 1.8184145404898029,
      "grad_norm": 0.16973334550857544,
      "learning_rate": 4.090792729755099e-05,
      "loss": 0.0025,
      "step": 21310
    },
    {
      "epoch": 1.81926785561908,
      "grad_norm": 0.04607093334197998,
      "learning_rate": 4.09036607219046e-05,
      "loss": 0.0031,
      "step": 21320
    },
    {
      "epoch": 1.8201211707483573,
      "grad_norm": 0.18285693228244781,
      "learning_rate": 4.0899394146258216e-05,
      "loss": 0.0019,
      "step": 21330
    },
    {
      "epoch": 1.8209744858776347,
      "grad_norm": 0.4030744433403015,
      "learning_rate": 4.089512757061183e-05,
      "loss": 0.0026,
      "step": 21340
    },
    {
      "epoch": 1.8218278010069118,
      "grad_norm": 0.13654670119285583,
      "learning_rate": 4.089086099496544e-05,
      "loss": 0.0023,
      "step": 21350
    },
    {
      "epoch": 1.822681116136189,
      "grad_norm": 0.05775308236479759,
      "learning_rate": 4.088659441931906e-05,
      "loss": 0.0028,
      "step": 21360
    },
    {
      "epoch": 1.8235344312654664,
      "grad_norm": 0.13686054944992065,
      "learning_rate": 4.0882327843672666e-05,
      "loss": 0.003,
      "step": 21370
    },
    {
      "epoch": 1.8243877463947435,
      "grad_norm": 0.20097430050373077,
      "learning_rate": 4.087806126802629e-05,
      "loss": 0.0023,
      "step": 21380
    },
    {
      "epoch": 1.8252410615240207,
      "grad_norm": 0.30745986104011536,
      "learning_rate": 4.0873794692379895e-05,
      "loss": 0.0027,
      "step": 21390
    },
    {
      "epoch": 1.8260943766532982,
      "grad_norm": 0.35023000836372375,
      "learning_rate": 4.0869528116733516e-05,
      "loss": 0.0019,
      "step": 21400
    },
    {
      "epoch": 1.8269476917825753,
      "grad_norm": 0.2684769928455353,
      "learning_rate": 4.086526154108712e-05,
      "loss": 0.0021,
      "step": 21410
    },
    {
      "epoch": 1.8278010069118524,
      "grad_norm": 0.3722997307777405,
      "learning_rate": 4.086099496544074e-05,
      "loss": 0.0024,
      "step": 21420
    },
    {
      "epoch": 1.8286543220411298,
      "grad_norm": 0.10822030901908875,
      "learning_rate": 4.085672838979435e-05,
      "loss": 0.0021,
      "step": 21430
    },
    {
      "epoch": 1.829507637170407,
      "grad_norm": 0.1132109984755516,
      "learning_rate": 4.0852461814147966e-05,
      "loss": 0.0038,
      "step": 21440
    },
    {
      "epoch": 1.8303609522996842,
      "grad_norm": 0.2279287874698639,
      "learning_rate": 4.084819523850158e-05,
      "loss": 0.0025,
      "step": 21450
    },
    {
      "epoch": 1.8312142674289615,
      "grad_norm": 0.2935297191143036,
      "learning_rate": 4.0843928662855195e-05,
      "loss": 0.0026,
      "step": 21460
    },
    {
      "epoch": 1.8320675825582389,
      "grad_norm": 0.10075902193784714,
      "learning_rate": 4.083966208720881e-05,
      "loss": 0.0035,
      "step": 21470
    },
    {
      "epoch": 1.832920897687516,
      "grad_norm": 0.28469428420066833,
      "learning_rate": 4.083539551156242e-05,
      "loss": 0.0033,
      "step": 21480
    },
    {
      "epoch": 1.833774212816793,
      "grad_norm": 0.4811893701553345,
      "learning_rate": 4.083112893591604e-05,
      "loss": 0.0028,
      "step": 21490
    },
    {
      "epoch": 1.8346275279460706,
      "grad_norm": 0.0605478510260582,
      "learning_rate": 4.082686236026965e-05,
      "loss": 0.0033,
      "step": 21500
    },
    {
      "epoch": 1.8354808430753478,
      "grad_norm": 0.14549745619297028,
      "learning_rate": 4.0822595784623266e-05,
      "loss": 0.0026,
      "step": 21510
    },
    {
      "epoch": 1.8363341582046249,
      "grad_norm": 0.18787305057048798,
      "learning_rate": 4.081832920897688e-05,
      "loss": 0.0032,
      "step": 21520
    },
    {
      "epoch": 1.8371874733339022,
      "grad_norm": 0.2088257521390915,
      "learning_rate": 4.0814062633330494e-05,
      "loss": 0.0027,
      "step": 21530
    },
    {
      "epoch": 1.8380407884631795,
      "grad_norm": 0.09728162735700607,
      "learning_rate": 4.08097960576841e-05,
      "loss": 0.0029,
      "step": 21540
    },
    {
      "epoch": 1.8388941035924566,
      "grad_norm": 0.3577105402946472,
      "learning_rate": 4.0805529482037716e-05,
      "loss": 0.003,
      "step": 21550
    },
    {
      "epoch": 1.839747418721734,
      "grad_norm": 0.3415679633617401,
      "learning_rate": 4.080126290639133e-05,
      "loss": 0.0025,
      "step": 21560
    },
    {
      "epoch": 1.8406007338510113,
      "grad_norm": 0.5319775938987732,
      "learning_rate": 4.0796996330744944e-05,
      "loss": 0.0034,
      "step": 21570
    },
    {
      "epoch": 1.8414540489802884,
      "grad_norm": 0.39759522676467896,
      "learning_rate": 4.079272975509856e-05,
      "loss": 0.0022,
      "step": 21580
    },
    {
      "epoch": 1.8423073641095655,
      "grad_norm": 0.13641686737537384,
      "learning_rate": 4.078846317945217e-05,
      "loss": 0.0032,
      "step": 21590
    },
    {
      "epoch": 1.8431606792388429,
      "grad_norm": 0.14832279086112976,
      "learning_rate": 4.078419660380579e-05,
      "loss": 0.0033,
      "step": 21600
    },
    {
      "epoch": 1.8440139943681202,
      "grad_norm": 0.2528736889362335,
      "learning_rate": 4.07799300281594e-05,
      "loss": 0.0029,
      "step": 21610
    },
    {
      "epoch": 1.8448673094973973,
      "grad_norm": 0.1986217200756073,
      "learning_rate": 4.0775663452513016e-05,
      "loss": 0.0026,
      "step": 21620
    },
    {
      "epoch": 1.8457206246266746,
      "grad_norm": 0.11885346472263336,
      "learning_rate": 4.077139687686663e-05,
      "loss": 0.0026,
      "step": 21630
    },
    {
      "epoch": 1.846573939755952,
      "grad_norm": 0.23865805566310883,
      "learning_rate": 4.0767130301220244e-05,
      "loss": 0.0029,
      "step": 21640
    },
    {
      "epoch": 1.847427254885229,
      "grad_norm": 0.279803067445755,
      "learning_rate": 4.076286372557386e-05,
      "loss": 0.0031,
      "step": 21650
    },
    {
      "epoch": 1.8482805700145064,
      "grad_norm": 0.24574795365333557,
      "learning_rate": 4.0758597149927466e-05,
      "loss": 0.003,
      "step": 21660
    },
    {
      "epoch": 1.8491338851437837,
      "grad_norm": 0.188649520277977,
      "learning_rate": 4.075433057428109e-05,
      "loss": 0.003,
      "step": 21670
    },
    {
      "epoch": 1.8499872002730609,
      "grad_norm": 0.3573985993862152,
      "learning_rate": 4.0750063998634694e-05,
      "loss": 0.0027,
      "step": 21680
    },
    {
      "epoch": 1.850840515402338,
      "grad_norm": 0.06490060687065125,
      "learning_rate": 4.0745797422988315e-05,
      "loss": 0.0029,
      "step": 21690
    },
    {
      "epoch": 1.8516938305316153,
      "grad_norm": 0.36178991198539734,
      "learning_rate": 4.074153084734192e-05,
      "loss": 0.0033,
      "step": 21700
    },
    {
      "epoch": 1.8525471456608926,
      "grad_norm": 0.060934051871299744,
      "learning_rate": 4.0737264271695544e-05,
      "loss": 0.0025,
      "step": 21710
    },
    {
      "epoch": 1.8534004607901697,
      "grad_norm": 0.14934061467647552,
      "learning_rate": 4.073299769604915e-05,
      "loss": 0.0029,
      "step": 21720
    },
    {
      "epoch": 1.854253775919447,
      "grad_norm": 0.5159138441085815,
      "learning_rate": 4.0728731120402765e-05,
      "loss": 0.0024,
      "step": 21730
    },
    {
      "epoch": 1.8551070910487244,
      "grad_norm": 0.08323691040277481,
      "learning_rate": 4.072446454475638e-05,
      "loss": 0.0033,
      "step": 21740
    },
    {
      "epoch": 1.8559604061780015,
      "grad_norm": 0.23277167975902557,
      "learning_rate": 4.0720197969109994e-05,
      "loss": 0.0021,
      "step": 21750
    },
    {
      "epoch": 1.8568137213072786,
      "grad_norm": 0.04589393362402916,
      "learning_rate": 4.071593139346361e-05,
      "loss": 0.0031,
      "step": 21760
    },
    {
      "epoch": 1.8576670364365562,
      "grad_norm": 0.21162275969982147,
      "learning_rate": 4.071166481781722e-05,
      "loss": 0.0027,
      "step": 21770
    },
    {
      "epoch": 1.8585203515658333,
      "grad_norm": 0.3035218119621277,
      "learning_rate": 4.070739824217084e-05,
      "loss": 0.0029,
      "step": 21780
    },
    {
      "epoch": 1.8593736666951104,
      "grad_norm": 0.30989503860473633,
      "learning_rate": 4.070313166652445e-05,
      "loss": 0.0039,
      "step": 21790
    },
    {
      "epoch": 1.8602269818243877,
      "grad_norm": 0.10383272916078568,
      "learning_rate": 4.0698865090878065e-05,
      "loss": 0.0023,
      "step": 21800
    },
    {
      "epoch": 1.861080296953665,
      "grad_norm": 0.11922230571508408,
      "learning_rate": 4.069459851523167e-05,
      "loss": 0.0029,
      "step": 21810
    },
    {
      "epoch": 1.8619336120829422,
      "grad_norm": 0.3270147442817688,
      "learning_rate": 4.0690331939585294e-05,
      "loss": 0.0034,
      "step": 21820
    },
    {
      "epoch": 1.8627869272122195,
      "grad_norm": 0.34581702947616577,
      "learning_rate": 4.06860653639389e-05,
      "loss": 0.0021,
      "step": 21830
    },
    {
      "epoch": 1.8636402423414968,
      "grad_norm": 0.31417185068130493,
      "learning_rate": 4.068179878829252e-05,
      "loss": 0.0032,
      "step": 21840
    },
    {
      "epoch": 1.864493557470774,
      "grad_norm": 0.2262207269668579,
      "learning_rate": 4.067753221264613e-05,
      "loss": 0.0029,
      "step": 21850
    },
    {
      "epoch": 1.865346872600051,
      "grad_norm": 0.08456641435623169,
      "learning_rate": 4.0673265636999744e-05,
      "loss": 0.0024,
      "step": 21860
    },
    {
      "epoch": 1.8662001877293284,
      "grad_norm": 0.15641950070858002,
      "learning_rate": 4.066899906135336e-05,
      "loss": 0.0028,
      "step": 21870
    },
    {
      "epoch": 1.8670535028586057,
      "grad_norm": 0.10270226746797562,
      "learning_rate": 4.066473248570697e-05,
      "loss": 0.0026,
      "step": 21880
    },
    {
      "epoch": 1.8679068179878828,
      "grad_norm": 0.09838605672121048,
      "learning_rate": 4.0660465910060587e-05,
      "loss": 0.0024,
      "step": 21890
    },
    {
      "epoch": 1.8687601331171602,
      "grad_norm": 0.09904802590608597,
      "learning_rate": 4.06561993344142e-05,
      "loss": 0.0021,
      "step": 21900
    },
    {
      "epoch": 1.8696134482464375,
      "grad_norm": 0.15001176297664642,
      "learning_rate": 4.0651932758767815e-05,
      "loss": 0.0037,
      "step": 21910
    },
    {
      "epoch": 1.8704667633757146,
      "grad_norm": 0.08615655452013016,
      "learning_rate": 4.064766618312143e-05,
      "loss": 0.0024,
      "step": 21920
    },
    {
      "epoch": 1.871320078504992,
      "grad_norm": 0.2919422388076782,
      "learning_rate": 4.0643399607475043e-05,
      "loss": 0.0019,
      "step": 21930
    },
    {
      "epoch": 1.8721733936342693,
      "grad_norm": 0.17804761230945587,
      "learning_rate": 4.063913303182866e-05,
      "loss": 0.0027,
      "step": 21940
    },
    {
      "epoch": 1.8730267087635464,
      "grad_norm": 0.4034501314163208,
      "learning_rate": 4.063486645618227e-05,
      "loss": 0.0026,
      "step": 21950
    },
    {
      "epoch": 1.8738800238928235,
      "grad_norm": 0.06690885126590729,
      "learning_rate": 4.0630599880535886e-05,
      "loss": 0.0028,
      "step": 21960
    },
    {
      "epoch": 1.8747333390221008,
      "grad_norm": 0.2620980441570282,
      "learning_rate": 4.0626333304889494e-05,
      "loss": 0.0028,
      "step": 21970
    },
    {
      "epoch": 1.8755866541513782,
      "grad_norm": 0.3848051130771637,
      "learning_rate": 4.0622066729243115e-05,
      "loss": 0.0023,
      "step": 21980
    },
    {
      "epoch": 1.8764399692806553,
      "grad_norm": 0.18630433082580566,
      "learning_rate": 4.061780015359672e-05,
      "loss": 0.0026,
      "step": 21990
    },
    {
      "epoch": 1.8772932844099326,
      "grad_norm": 0.07394646853208542,
      "learning_rate": 4.061353357795034e-05,
      "loss": 0.0034,
      "step": 22000
    },
    {
      "epoch": 1.87814659953921,
      "grad_norm": 0.2499244064092636,
      "learning_rate": 4.060926700230395e-05,
      "loss": 0.0024,
      "step": 22010
    },
    {
      "epoch": 1.878999914668487,
      "grad_norm": 0.5533259510993958,
      "learning_rate": 4.060500042665757e-05,
      "loss": 0.0036,
      "step": 22020
    },
    {
      "epoch": 1.8798532297977644,
      "grad_norm": 0.07988012582063675,
      "learning_rate": 4.060073385101118e-05,
      "loss": 0.0031,
      "step": 22030
    },
    {
      "epoch": 1.8807065449270417,
      "grad_norm": 0.3747006058692932,
      "learning_rate": 4.05964672753648e-05,
      "loss": 0.0035,
      "step": 22040
    },
    {
      "epoch": 1.8815598600563188,
      "grad_norm": 0.19169355928897858,
      "learning_rate": 4.059220069971841e-05,
      "loss": 0.0027,
      "step": 22050
    },
    {
      "epoch": 1.882413175185596,
      "grad_norm": 0.07927227020263672,
      "learning_rate": 4.058793412407202e-05,
      "loss": 0.0023,
      "step": 22060
    },
    {
      "epoch": 1.8832664903148733,
      "grad_norm": 0.31649935245513916,
      "learning_rate": 4.0583667548425636e-05,
      "loss": 0.003,
      "step": 22070
    },
    {
      "epoch": 1.8841198054441506,
      "grad_norm": 0.27374139428138733,
      "learning_rate": 4.0579400972779244e-05,
      "loss": 0.0028,
      "step": 22080
    },
    {
      "epoch": 1.8849731205734277,
      "grad_norm": 0.1964135468006134,
      "learning_rate": 4.0575134397132865e-05,
      "loss": 0.0023,
      "step": 22090
    },
    {
      "epoch": 1.885826435702705,
      "grad_norm": 0.15857017040252686,
      "learning_rate": 4.057086782148647e-05,
      "loss": 0.0031,
      "step": 22100
    },
    {
      "epoch": 1.8866797508319824,
      "grad_norm": 0.23883844912052155,
      "learning_rate": 4.056660124584009e-05,
      "loss": 0.0027,
      "step": 22110
    },
    {
      "epoch": 1.8875330659612595,
      "grad_norm": 0.2691260576248169,
      "learning_rate": 4.05623346701937e-05,
      "loss": 0.003,
      "step": 22120
    },
    {
      "epoch": 1.8883863810905366,
      "grad_norm": 0.07824398577213287,
      "learning_rate": 4.055806809454732e-05,
      "loss": 0.0017,
      "step": 22130
    },
    {
      "epoch": 1.8892396962198141,
      "grad_norm": 0.1161002665758133,
      "learning_rate": 4.055380151890093e-05,
      "loss": 0.0018,
      "step": 22140
    },
    {
      "epoch": 1.8900930113490912,
      "grad_norm": 0.2542146146297455,
      "learning_rate": 4.054953494325455e-05,
      "loss": 0.0026,
      "step": 22150
    },
    {
      "epoch": 1.8909463264783684,
      "grad_norm": 0.28463947772979736,
      "learning_rate": 4.054526836760816e-05,
      "loss": 0.0027,
      "step": 22160
    },
    {
      "epoch": 1.8917996416076457,
      "grad_norm": 0.404862642288208,
      "learning_rate": 4.054100179196177e-05,
      "loss": 0.0026,
      "step": 22170
    },
    {
      "epoch": 1.892652956736923,
      "grad_norm": 0.09712512791156769,
      "learning_rate": 4.0536735216315386e-05,
      "loss": 0.0025,
      "step": 22180
    },
    {
      "epoch": 1.8935062718662001,
      "grad_norm": 0.263282835483551,
      "learning_rate": 4.0532468640669e-05,
      "loss": 0.0034,
      "step": 22190
    },
    {
      "epoch": 1.8943595869954775,
      "grad_norm": 0.0979766771197319,
      "learning_rate": 4.0528202065022614e-05,
      "loss": 0.0025,
      "step": 22200
    },
    {
      "epoch": 1.8952129021247548,
      "grad_norm": 0.24216695129871368,
      "learning_rate": 4.052393548937623e-05,
      "loss": 0.0027,
      "step": 22210
    },
    {
      "epoch": 1.896066217254032,
      "grad_norm": 0.12165052443742752,
      "learning_rate": 4.051966891372984e-05,
      "loss": 0.0019,
      "step": 22220
    },
    {
      "epoch": 1.896919532383309,
      "grad_norm": 0.3723444640636444,
      "learning_rate": 4.051540233808346e-05,
      "loss": 0.0021,
      "step": 22230
    },
    {
      "epoch": 1.8977728475125863,
      "grad_norm": 0.23212814331054688,
      "learning_rate": 4.051113576243707e-05,
      "loss": 0.0028,
      "step": 22240
    },
    {
      "epoch": 1.8986261626418637,
      "grad_norm": 0.36743125319480896,
      "learning_rate": 4.0506869186790686e-05,
      "loss": 0.002,
      "step": 22250
    },
    {
      "epoch": 1.8994794777711408,
      "grad_norm": 0.4010532796382904,
      "learning_rate": 4.05026026111443e-05,
      "loss": 0.0022,
      "step": 22260
    },
    {
      "epoch": 1.9003327929004181,
      "grad_norm": 0.5782989263534546,
      "learning_rate": 4.0498336035497914e-05,
      "loss": 0.0023,
      "step": 22270
    },
    {
      "epoch": 1.9011861080296955,
      "grad_norm": 0.04179126024246216,
      "learning_rate": 4.049406945985152e-05,
      "loss": 0.0023,
      "step": 22280
    },
    {
      "epoch": 1.9020394231589726,
      "grad_norm": 0.19774945080280304,
      "learning_rate": 4.048980288420514e-05,
      "loss": 0.0028,
      "step": 22290
    },
    {
      "epoch": 1.90289273828825,
      "grad_norm": 0.05462956428527832,
      "learning_rate": 4.048553630855875e-05,
      "loss": 0.0023,
      "step": 22300
    },
    {
      "epoch": 1.9037460534175272,
      "grad_norm": 0.07988318800926208,
      "learning_rate": 4.048126973291237e-05,
      "loss": 0.0027,
      "step": 22310
    },
    {
      "epoch": 1.9045993685468043,
      "grad_norm": 0.21091817319393158,
      "learning_rate": 4.047700315726598e-05,
      "loss": 0.0021,
      "step": 22320
    },
    {
      "epoch": 1.9054526836760814,
      "grad_norm": 0.5141358375549316,
      "learning_rate": 4.047273658161959e-05,
      "loss": 0.0025,
      "step": 22330
    },
    {
      "epoch": 1.9063059988053588,
      "grad_norm": 0.5114700198173523,
      "learning_rate": 4.046847000597321e-05,
      "loss": 0.003,
      "step": 22340
    },
    {
      "epoch": 1.9071593139346361,
      "grad_norm": 0.49136924743652344,
      "learning_rate": 4.046420343032682e-05,
      "loss": 0.0022,
      "step": 22350
    },
    {
      "epoch": 1.9080126290639132,
      "grad_norm": 0.3044756054878235,
      "learning_rate": 4.0459936854680436e-05,
      "loss": 0.003,
      "step": 22360
    },
    {
      "epoch": 1.9088659441931906,
      "grad_norm": 0.28800198435783386,
      "learning_rate": 4.045567027903405e-05,
      "loss": 0.0021,
      "step": 22370
    },
    {
      "epoch": 1.9097192593224679,
      "grad_norm": 0.41332945227622986,
      "learning_rate": 4.0451403703387664e-05,
      "loss": 0.0023,
      "step": 22380
    },
    {
      "epoch": 1.910572574451745,
      "grad_norm": 0.29093536734580994,
      "learning_rate": 4.044713712774127e-05,
      "loss": 0.0032,
      "step": 22390
    },
    {
      "epoch": 1.911425889581022,
      "grad_norm": 0.17756842076778412,
      "learning_rate": 4.044287055209489e-05,
      "loss": 0.0033,
      "step": 22400
    },
    {
      "epoch": 1.9122792047102997,
      "grad_norm": 0.4691319167613983,
      "learning_rate": 4.04386039764485e-05,
      "loss": 0.0024,
      "step": 22410
    },
    {
      "epoch": 1.9131325198395768,
      "grad_norm": 0.1290944665670395,
      "learning_rate": 4.043433740080212e-05,
      "loss": 0.0028,
      "step": 22420
    },
    {
      "epoch": 1.9139858349688539,
      "grad_norm": 0.2338005006313324,
      "learning_rate": 4.043007082515573e-05,
      "loss": 0.0034,
      "step": 22430
    },
    {
      "epoch": 1.9148391500981312,
      "grad_norm": 0.04551105201244354,
      "learning_rate": 4.042580424950935e-05,
      "loss": 0.0028,
      "step": 22440
    },
    {
      "epoch": 1.9156924652274085,
      "grad_norm": 0.18542765080928802,
      "learning_rate": 4.042153767386296e-05,
      "loss": 0.0029,
      "step": 22450
    },
    {
      "epoch": 1.9165457803566857,
      "grad_norm": 0.2955295443534851,
      "learning_rate": 4.041727109821658e-05,
      "loss": 0.002,
      "step": 22460
    },
    {
      "epoch": 1.917399095485963,
      "grad_norm": 0.13716869056224823,
      "learning_rate": 4.0413004522570185e-05,
      "loss": 0.0019,
      "step": 22470
    },
    {
      "epoch": 1.9182524106152403,
      "grad_norm": 0.5877236127853394,
      "learning_rate": 4.04087379469238e-05,
      "loss": 0.0022,
      "step": 22480
    },
    {
      "epoch": 1.9191057257445174,
      "grad_norm": 0.33985456824302673,
      "learning_rate": 4.0404471371277414e-05,
      "loss": 0.0023,
      "step": 22490
    },
    {
      "epoch": 1.9199590408737945,
      "grad_norm": 0.089300736784935,
      "learning_rate": 4.040020479563103e-05,
      "loss": 0.0028,
      "step": 22500
    },
    {
      "epoch": 1.920812356003072,
      "grad_norm": 0.03572043403983116,
      "learning_rate": 4.039593821998464e-05,
      "loss": 0.0027,
      "step": 22510
    },
    {
      "epoch": 1.9216656711323492,
      "grad_norm": 0.048970647156238556,
      "learning_rate": 4.0391671644338257e-05,
      "loss": 0.0024,
      "step": 22520
    },
    {
      "epoch": 1.9225189862616263,
      "grad_norm": 0.15755823254585266,
      "learning_rate": 4.038740506869187e-05,
      "loss": 0.0026,
      "step": 22530
    },
    {
      "epoch": 1.9233723013909036,
      "grad_norm": 0.317817360162735,
      "learning_rate": 4.0383138493045485e-05,
      "loss": 0.0037,
      "step": 22540
    },
    {
      "epoch": 1.924225616520181,
      "grad_norm": 0.04867789149284363,
      "learning_rate": 4.03788719173991e-05,
      "loss": 0.0029,
      "step": 22550
    },
    {
      "epoch": 1.925078931649458,
      "grad_norm": 0.15585467219352722,
      "learning_rate": 4.0374605341752714e-05,
      "loss": 0.0026,
      "step": 22560
    },
    {
      "epoch": 1.9259322467787354,
      "grad_norm": 0.15416991710662842,
      "learning_rate": 4.037033876610633e-05,
      "loss": 0.0024,
      "step": 22570
    },
    {
      "epoch": 1.9267855619080128,
      "grad_norm": 0.18331269919872284,
      "learning_rate": 4.036607219045994e-05,
      "loss": 0.0027,
      "step": 22580
    },
    {
      "epoch": 1.9276388770372899,
      "grad_norm": 0.24736298620700836,
      "learning_rate": 4.036180561481355e-05,
      "loss": 0.0029,
      "step": 22590
    },
    {
      "epoch": 1.928492192166567,
      "grad_norm": 0.10156850516796112,
      "learning_rate": 4.0357539039167164e-05,
      "loss": 0.0031,
      "step": 22600
    },
    {
      "epoch": 1.9293455072958443,
      "grad_norm": 0.06051498278975487,
      "learning_rate": 4.035327246352078e-05,
      "loss": 0.0029,
      "step": 22610
    },
    {
      "epoch": 1.9301988224251216,
      "grad_norm": 0.3202367424964905,
      "learning_rate": 4.034900588787439e-05,
      "loss": 0.0021,
      "step": 22620
    },
    {
      "epoch": 1.9310521375543988,
      "grad_norm": 0.22678647935390472,
      "learning_rate": 4.0344739312228006e-05,
      "loss": 0.0027,
      "step": 22630
    },
    {
      "epoch": 1.931905452683676,
      "grad_norm": 0.20944634079933167,
      "learning_rate": 4.034047273658162e-05,
      "loss": 0.0029,
      "step": 22640
    },
    {
      "epoch": 1.9327587678129534,
      "grad_norm": 0.3399907350540161,
      "learning_rate": 4.0336206160935235e-05,
      "loss": 0.002,
      "step": 22650
    },
    {
      "epoch": 1.9336120829422305,
      "grad_norm": 0.3600316047668457,
      "learning_rate": 4.033193958528885e-05,
      "loss": 0.0027,
      "step": 22660
    },
    {
      "epoch": 1.9344653980715079,
      "grad_norm": 0.7040138244628906,
      "learning_rate": 4.0327673009642463e-05,
      "loss": 0.002,
      "step": 22670
    },
    {
      "epoch": 1.9353187132007852,
      "grad_norm": 0.2839853763580322,
      "learning_rate": 4.032340643399608e-05,
      "loss": 0.0039,
      "step": 22680
    },
    {
      "epoch": 1.9361720283300623,
      "grad_norm": 0.30047935247421265,
      "learning_rate": 4.031913985834969e-05,
      "loss": 0.0023,
      "step": 22690
    },
    {
      "epoch": 1.9370253434593394,
      "grad_norm": 0.2767000198364258,
      "learning_rate": 4.03148732827033e-05,
      "loss": 0.0025,
      "step": 22700
    },
    {
      "epoch": 1.9378786585886167,
      "grad_norm": 0.056715648621320724,
      "learning_rate": 4.031060670705692e-05,
      "loss": 0.003,
      "step": 22710
    },
    {
      "epoch": 1.938731973717894,
      "grad_norm": 0.06421932578086853,
      "learning_rate": 4.030634013141053e-05,
      "loss": 0.0019,
      "step": 22720
    },
    {
      "epoch": 1.9395852888471712,
      "grad_norm": 0.1442139744758606,
      "learning_rate": 4.030207355576415e-05,
      "loss": 0.0024,
      "step": 22730
    },
    {
      "epoch": 1.9404386039764485,
      "grad_norm": 0.15566127002239227,
      "learning_rate": 4.0297806980117756e-05,
      "loss": 0.0023,
      "step": 22740
    },
    {
      "epoch": 1.9412919191057258,
      "grad_norm": 0.18942850828170776,
      "learning_rate": 4.029354040447138e-05,
      "loss": 0.0023,
      "step": 22750
    },
    {
      "epoch": 1.942145234235003,
      "grad_norm": 0.39598697423934937,
      "learning_rate": 4.0289273828824985e-05,
      "loss": 0.0022,
      "step": 22760
    },
    {
      "epoch": 1.94299854936428,
      "grad_norm": 0.03169349581003189,
      "learning_rate": 4.0285007253178606e-05,
      "loss": 0.0026,
      "step": 22770
    },
    {
      "epoch": 1.9438518644935576,
      "grad_norm": 0.057690318673849106,
      "learning_rate": 4.028074067753221e-05,
      "loss": 0.0019,
      "step": 22780
    },
    {
      "epoch": 1.9447051796228347,
      "grad_norm": 0.13567185401916504,
      "learning_rate": 4.027647410188583e-05,
      "loss": 0.0024,
      "step": 22790
    },
    {
      "epoch": 1.9455584947521118,
      "grad_norm": 0.5164379477500916,
      "learning_rate": 4.027220752623944e-05,
      "loss": 0.0029,
      "step": 22800
    },
    {
      "epoch": 1.9464118098813892,
      "grad_norm": 0.31526997685432434,
      "learning_rate": 4.0267940950593056e-05,
      "loss": 0.0023,
      "step": 22810
    },
    {
      "epoch": 1.9472651250106665,
      "grad_norm": 0.07994671911001205,
      "learning_rate": 4.026367437494667e-05,
      "loss": 0.0029,
      "step": 22820
    },
    {
      "epoch": 1.9481184401399436,
      "grad_norm": 0.18862555921077728,
      "learning_rate": 4.0259407799300285e-05,
      "loss": 0.0028,
      "step": 22830
    },
    {
      "epoch": 1.948971755269221,
      "grad_norm": 0.15022572875022888,
      "learning_rate": 4.02551412236539e-05,
      "loss": 0.0022,
      "step": 22840
    },
    {
      "epoch": 1.9498250703984983,
      "grad_norm": 0.2681548595428467,
      "learning_rate": 4.025087464800751e-05,
      "loss": 0.0032,
      "step": 22850
    },
    {
      "epoch": 1.9506783855277754,
      "grad_norm": 0.04770100116729736,
      "learning_rate": 4.024660807236113e-05,
      "loss": 0.003,
      "step": 22860
    },
    {
      "epoch": 1.9515317006570525,
      "grad_norm": 0.24818862974643707,
      "learning_rate": 4.0242341496714735e-05,
      "loss": 0.0025,
      "step": 22870
    },
    {
      "epoch": 1.95238501578633,
      "grad_norm": 0.10383874177932739,
      "learning_rate": 4.0238074921068356e-05,
      "loss": 0.0023,
      "step": 22880
    },
    {
      "epoch": 1.9532383309156072,
      "grad_norm": 0.30875980854034424,
      "learning_rate": 4.023380834542196e-05,
      "loss": 0.0034,
      "step": 22890
    },
    {
      "epoch": 1.9540916460448843,
      "grad_norm": 0.3070788085460663,
      "learning_rate": 4.022954176977558e-05,
      "loss": 0.0021,
      "step": 22900
    },
    {
      "epoch": 1.9549449611741616,
      "grad_norm": 0.3782626986503601,
      "learning_rate": 4.022527519412919e-05,
      "loss": 0.0031,
      "step": 22910
    },
    {
      "epoch": 1.955798276303439,
      "grad_norm": 0.5342085957527161,
      "learning_rate": 4.0221008618482806e-05,
      "loss": 0.003,
      "step": 22920
    },
    {
      "epoch": 1.956651591432716,
      "grad_norm": 0.13605043292045593,
      "learning_rate": 4.021674204283642e-05,
      "loss": 0.0024,
      "step": 22930
    },
    {
      "epoch": 1.9575049065619934,
      "grad_norm": 0.3413543403148651,
      "learning_rate": 4.0212475467190034e-05,
      "loss": 0.0037,
      "step": 22940
    },
    {
      "epoch": 1.9583582216912707,
      "grad_norm": 0.5502533912658691,
      "learning_rate": 4.020820889154365e-05,
      "loss": 0.0022,
      "step": 22950
    },
    {
      "epoch": 1.9592115368205478,
      "grad_norm": 0.43074584007263184,
      "learning_rate": 4.020394231589726e-05,
      "loss": 0.002,
      "step": 22960
    },
    {
      "epoch": 1.960064851949825,
      "grad_norm": 0.0681428387761116,
      "learning_rate": 4.019967574025088e-05,
      "loss": 0.0027,
      "step": 22970
    },
    {
      "epoch": 1.9609181670791023,
      "grad_norm": 0.09752281755208969,
      "learning_rate": 4.019540916460449e-05,
      "loss": 0.0039,
      "step": 22980
    },
    {
      "epoch": 1.9617714822083796,
      "grad_norm": 0.2764738202095032,
      "learning_rate": 4.0191142588958106e-05,
      "loss": 0.0017,
      "step": 22990
    },
    {
      "epoch": 1.9626247973376567,
      "grad_norm": 0.47834962606430054,
      "learning_rate": 4.018687601331172e-05,
      "loss": 0.0024,
      "step": 23000
    },
    {
      "epoch": 1.963478112466934,
      "grad_norm": 0.047243572771549225,
      "learning_rate": 4.018260943766533e-05,
      "loss": 0.0024,
      "step": 23010
    },
    {
      "epoch": 1.9643314275962114,
      "grad_norm": 0.19495515525341034,
      "learning_rate": 4.017834286201895e-05,
      "loss": 0.0021,
      "step": 23020
    },
    {
      "epoch": 1.9651847427254885,
      "grad_norm": 0.20451609790325165,
      "learning_rate": 4.0174076286372556e-05,
      "loss": 0.0027,
      "step": 23030
    },
    {
      "epoch": 1.9660380578547658,
      "grad_norm": 0.4759208559989929,
      "learning_rate": 4.016980971072618e-05,
      "loss": 0.0031,
      "step": 23040
    },
    {
      "epoch": 1.9668913729840432,
      "grad_norm": 0.19147366285324097,
      "learning_rate": 4.0165543135079784e-05,
      "loss": 0.0033,
      "step": 23050
    },
    {
      "epoch": 1.9677446881133203,
      "grad_norm": 0.3778860569000244,
      "learning_rate": 4.0161276559433405e-05,
      "loss": 0.002,
      "step": 23060
    },
    {
      "epoch": 1.9685980032425974,
      "grad_norm": 0.06751224398612976,
      "learning_rate": 4.015700998378701e-05,
      "loss": 0.003,
      "step": 23070
    },
    {
      "epoch": 1.9694513183718747,
      "grad_norm": 0.06355593353509903,
      "learning_rate": 4.0152743408140634e-05,
      "loss": 0.0025,
      "step": 23080
    },
    {
      "epoch": 1.970304633501152,
      "grad_norm": 0.1123158186674118,
      "learning_rate": 4.014847683249424e-05,
      "loss": 0.0032,
      "step": 23090
    },
    {
      "epoch": 1.9711579486304291,
      "grad_norm": 0.08039261400699615,
      "learning_rate": 4.0144210256847855e-05,
      "loss": 0.0025,
      "step": 23100
    },
    {
      "epoch": 1.9720112637597065,
      "grad_norm": 0.06935599446296692,
      "learning_rate": 4.013994368120147e-05,
      "loss": 0.0022,
      "step": 23110
    },
    {
      "epoch": 1.9728645788889838,
      "grad_norm": 0.11820146441459656,
      "learning_rate": 4.0135677105555084e-05,
      "loss": 0.0024,
      "step": 23120
    },
    {
      "epoch": 1.973717894018261,
      "grad_norm": 0.23460248112678528,
      "learning_rate": 4.01314105299087e-05,
      "loss": 0.0033,
      "step": 23130
    },
    {
      "epoch": 1.974571209147538,
      "grad_norm": 0.19019490480422974,
      "learning_rate": 4.0127143954262306e-05,
      "loss": 0.0034,
      "step": 23140
    },
    {
      "epoch": 1.9754245242768156,
      "grad_norm": 0.06289675831794739,
      "learning_rate": 4.012287737861593e-05,
      "loss": 0.0026,
      "step": 23150
    },
    {
      "epoch": 1.9762778394060927,
      "grad_norm": 0.3978199362754822,
      "learning_rate": 4.0118610802969534e-05,
      "loss": 0.0027,
      "step": 23160
    },
    {
      "epoch": 1.9771311545353698,
      "grad_norm": 0.192361980676651,
      "learning_rate": 4.0114344227323155e-05,
      "loss": 0.0032,
      "step": 23170
    },
    {
      "epoch": 1.9779844696646471,
      "grad_norm": 0.19015660881996155,
      "learning_rate": 4.011007765167676e-05,
      "loss": 0.0027,
      "step": 23180
    },
    {
      "epoch": 1.9788377847939245,
      "grad_norm": 0.23941169679164886,
      "learning_rate": 4.0105811076030384e-05,
      "loss": 0.0029,
      "step": 23190
    },
    {
      "epoch": 1.9796910999232016,
      "grad_norm": 0.17408186197280884,
      "learning_rate": 4.010154450038399e-05,
      "loss": 0.0028,
      "step": 23200
    },
    {
      "epoch": 1.980544415052479,
      "grad_norm": 0.13559071719646454,
      "learning_rate": 4.0097277924737605e-05,
      "loss": 0.0022,
      "step": 23210
    },
    {
      "epoch": 1.9813977301817562,
      "grad_norm": 0.11999750137329102,
      "learning_rate": 4.009301134909122e-05,
      "loss": 0.0027,
      "step": 23220
    },
    {
      "epoch": 1.9822510453110334,
      "grad_norm": 0.07701840996742249,
      "learning_rate": 4.0088744773444834e-05,
      "loss": 0.0023,
      "step": 23230
    },
    {
      "epoch": 1.9831043604403105,
      "grad_norm": 0.18864993751049042,
      "learning_rate": 4.008447819779845e-05,
      "loss": 0.0025,
      "step": 23240
    },
    {
      "epoch": 1.9839576755695878,
      "grad_norm": 0.42341071367263794,
      "learning_rate": 4.008021162215206e-05,
      "loss": 0.0031,
      "step": 23250
    },
    {
      "epoch": 1.9848109906988651,
      "grad_norm": 0.11699815839529037,
      "learning_rate": 4.0075945046505677e-05,
      "loss": 0.003,
      "step": 23260
    },
    {
      "epoch": 1.9856643058281422,
      "grad_norm": 0.2700623571872711,
      "learning_rate": 4.007167847085929e-05,
      "loss": 0.0026,
      "step": 23270
    },
    {
      "epoch": 1.9865176209574196,
      "grad_norm": 0.08466315269470215,
      "learning_rate": 4.0067411895212905e-05,
      "loss": 0.0023,
      "step": 23280
    },
    {
      "epoch": 1.987370936086697,
      "grad_norm": 0.31908953189849854,
      "learning_rate": 4.006314531956652e-05,
      "loss": 0.0025,
      "step": 23290
    },
    {
      "epoch": 1.988224251215974,
      "grad_norm": 0.2586221992969513,
      "learning_rate": 4.0058878743920134e-05,
      "loss": 0.0027,
      "step": 23300
    },
    {
      "epoch": 1.9890775663452513,
      "grad_norm": 0.20803163945674896,
      "learning_rate": 4.005461216827375e-05,
      "loss": 0.0033,
      "step": 23310
    },
    {
      "epoch": 1.9899308814745287,
      "grad_norm": 0.04000192880630493,
      "learning_rate": 4.0050345592627355e-05,
      "loss": 0.0027,
      "step": 23320
    },
    {
      "epoch": 1.9907841966038058,
      "grad_norm": 0.22739817202091217,
      "learning_rate": 4.0046079016980976e-05,
      "loss": 0.0022,
      "step": 23330
    },
    {
      "epoch": 1.991637511733083,
      "grad_norm": 0.046713873744010925,
      "learning_rate": 4.0041812441334584e-05,
      "loss": 0.0023,
      "step": 23340
    },
    {
      "epoch": 1.9924908268623602,
      "grad_norm": 0.37196677923202515,
      "learning_rate": 4.0037545865688205e-05,
      "loss": 0.0024,
      "step": 23350
    },
    {
      "epoch": 1.9933441419916376,
      "grad_norm": 0.22920016944408417,
      "learning_rate": 4.003327929004181e-05,
      "loss": 0.0028,
      "step": 23360
    },
    {
      "epoch": 1.9941974571209147,
      "grad_norm": 0.20660310983657837,
      "learning_rate": 4.002901271439543e-05,
      "loss": 0.0025,
      "step": 23370
    },
    {
      "epoch": 1.995050772250192,
      "grad_norm": 0.2240714728832245,
      "learning_rate": 4.002474613874904e-05,
      "loss": 0.0025,
      "step": 23380
    },
    {
      "epoch": 1.9959040873794693,
      "grad_norm": 0.34940075874328613,
      "learning_rate": 4.0020479563102655e-05,
      "loss": 0.0029,
      "step": 23390
    },
    {
      "epoch": 1.9967574025087464,
      "grad_norm": 0.07669326663017273,
      "learning_rate": 4.001621298745627e-05,
      "loss": 0.0026,
      "step": 23400
    },
    {
      "epoch": 1.9976107176380236,
      "grad_norm": 0.16124042868614197,
      "learning_rate": 4.0011946411809883e-05,
      "loss": 0.0029,
      "step": 23410
    },
    {
      "epoch": 1.9984640327673011,
      "grad_norm": 0.1682194173336029,
      "learning_rate": 4.00076798361635e-05,
      "loss": 0.0027,
      "step": 23420
    },
    {
      "epoch": 1.9993173478965782,
      "grad_norm": 0.08761633187532425,
      "learning_rate": 4.000341326051711e-05,
      "loss": 0.0032,
      "step": 23430
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.002621446270495653,
      "eval_runtime": 103.0947,
      "eval_samples_per_second": 1454.973,
      "eval_steps_per_second": 22.736,
      "step": 23438
    },
    {
      "epoch": 2.0001706630258553,
      "grad_norm": 0.17209471762180328,
      "learning_rate": 3.9999146684870726e-05,
      "loss": 0.0023,
      "step": 23440
    },
    {
      "epoch": 2.001023978155133,
      "grad_norm": 0.1535900980234146,
      "learning_rate": 3.9994880109224334e-05,
      "loss": 0.0025,
      "step": 23450
    },
    {
      "epoch": 2.00187729328441,
      "grad_norm": 0.13433434069156647,
      "learning_rate": 3.9990613533577955e-05,
      "loss": 0.0027,
      "step": 23460
    },
    {
      "epoch": 2.002730608413687,
      "grad_norm": 0.02677236683666706,
      "learning_rate": 3.998634695793156e-05,
      "loss": 0.0035,
      "step": 23470
    },
    {
      "epoch": 2.003583923542964,
      "grad_norm": 0.3018716871738434,
      "learning_rate": 3.998208038228518e-05,
      "loss": 0.0028,
      "step": 23480
    },
    {
      "epoch": 2.0044372386722418,
      "grad_norm": 0.16853326559066772,
      "learning_rate": 3.997781380663879e-05,
      "loss": 0.0022,
      "step": 23490
    },
    {
      "epoch": 2.005290553801519,
      "grad_norm": 0.3556843101978302,
      "learning_rate": 3.997354723099241e-05,
      "loss": 0.0029,
      "step": 23500
    },
    {
      "epoch": 2.006143868930796,
      "grad_norm": 0.28045329451560974,
      "learning_rate": 3.996928065534602e-05,
      "loss": 0.0017,
      "step": 23510
    },
    {
      "epoch": 2.0069971840600735,
      "grad_norm": 0.2462218701839447,
      "learning_rate": 3.996501407969963e-05,
      "loss": 0.002,
      "step": 23520
    },
    {
      "epoch": 2.0078504991893507,
      "grad_norm": 0.30465635657310486,
      "learning_rate": 3.996074750405325e-05,
      "loss": 0.0026,
      "step": 23530
    },
    {
      "epoch": 2.0087038143186278,
      "grad_norm": 0.024169422686100006,
      "learning_rate": 3.995648092840686e-05,
      "loss": 0.0026,
      "step": 23540
    },
    {
      "epoch": 2.0095571294479053,
      "grad_norm": 0.03100314736366272,
      "learning_rate": 3.9952214352760476e-05,
      "loss": 0.0017,
      "step": 23550
    },
    {
      "epoch": 2.0104104445771824,
      "grad_norm": 0.18095912039279938,
      "learning_rate": 3.994794777711409e-05,
      "loss": 0.0017,
      "step": 23560
    },
    {
      "epoch": 2.0112637597064595,
      "grad_norm": 0.1020088866353035,
      "learning_rate": 3.9943681201467704e-05,
      "loss": 0.0029,
      "step": 23570
    },
    {
      "epoch": 2.0121170748357367,
      "grad_norm": 0.38701483607292175,
      "learning_rate": 3.993941462582132e-05,
      "loss": 0.0023,
      "step": 23580
    },
    {
      "epoch": 2.012970389965014,
      "grad_norm": 0.14068330824375153,
      "learning_rate": 3.993514805017493e-05,
      "loss": 0.0024,
      "step": 23590
    },
    {
      "epoch": 2.0138237050942913,
      "grad_norm": 0.1531076431274414,
      "learning_rate": 3.993088147452855e-05,
      "loss": 0.0018,
      "step": 23600
    },
    {
      "epoch": 2.0146770202235684,
      "grad_norm": 0.2497725486755371,
      "learning_rate": 3.992661489888216e-05,
      "loss": 0.0028,
      "step": 23610
    },
    {
      "epoch": 2.015530335352846,
      "grad_norm": 0.32918888330459595,
      "learning_rate": 3.9922348323235776e-05,
      "loss": 0.0023,
      "step": 23620
    },
    {
      "epoch": 2.016383650482123,
      "grad_norm": 0.1922101229429245,
      "learning_rate": 3.991808174758938e-05,
      "loss": 0.0022,
      "step": 23630
    },
    {
      "epoch": 2.0172369656114,
      "grad_norm": 0.10341023653745651,
      "learning_rate": 3.9913815171943004e-05,
      "loss": 0.003,
      "step": 23640
    },
    {
      "epoch": 2.0180902807406778,
      "grad_norm": 0.07981138676404953,
      "learning_rate": 3.990954859629661e-05,
      "loss": 0.0023,
      "step": 23650
    },
    {
      "epoch": 2.018943595869955,
      "grad_norm": 0.37412717938423157,
      "learning_rate": 3.9905282020650226e-05,
      "loss": 0.0023,
      "step": 23660
    },
    {
      "epoch": 2.019796910999232,
      "grad_norm": 0.35903438925743103,
      "learning_rate": 3.990101544500384e-05,
      "loss": 0.0022,
      "step": 23670
    },
    {
      "epoch": 2.020650226128509,
      "grad_norm": 0.3018074035644531,
      "learning_rate": 3.9896748869357454e-05,
      "loss": 0.0026,
      "step": 23680
    },
    {
      "epoch": 2.0215035412577866,
      "grad_norm": 0.5993210077285767,
      "learning_rate": 3.989248229371107e-05,
      "loss": 0.0034,
      "step": 23690
    },
    {
      "epoch": 2.0223568563870638,
      "grad_norm": 0.3126070499420166,
      "learning_rate": 3.988821571806468e-05,
      "loss": 0.0037,
      "step": 23700
    },
    {
      "epoch": 2.023210171516341,
      "grad_norm": 0.06174125894904137,
      "learning_rate": 3.98839491424183e-05,
      "loss": 0.0026,
      "step": 23710
    },
    {
      "epoch": 2.0240634866456184,
      "grad_norm": 0.110605388879776,
      "learning_rate": 3.987968256677191e-05,
      "loss": 0.0023,
      "step": 23720
    },
    {
      "epoch": 2.0249168017748955,
      "grad_norm": 0.2800757884979248,
      "learning_rate": 3.9875415991125526e-05,
      "loss": 0.0028,
      "step": 23730
    },
    {
      "epoch": 2.0257701169041726,
      "grad_norm": 0.12468980252742767,
      "learning_rate": 3.987114941547914e-05,
      "loss": 0.0017,
      "step": 23740
    },
    {
      "epoch": 2.0266234320334497,
      "grad_norm": 0.06268718838691711,
      "learning_rate": 3.9866882839832754e-05,
      "loss": 0.0032,
      "step": 23750
    },
    {
      "epoch": 2.0274767471627273,
      "grad_norm": 0.04323863610625267,
      "learning_rate": 3.986261626418636e-05,
      "loss": 0.0021,
      "step": 23760
    },
    {
      "epoch": 2.0283300622920044,
      "grad_norm": 0.2667594850063324,
      "learning_rate": 3.985834968853998e-05,
      "loss": 0.0026,
      "step": 23770
    },
    {
      "epoch": 2.0291833774212815,
      "grad_norm": 0.03408147022128105,
      "learning_rate": 3.985408311289359e-05,
      "loss": 0.0022,
      "step": 23780
    },
    {
      "epoch": 2.030036692550559,
      "grad_norm": 0.3869238495826721,
      "learning_rate": 3.984981653724721e-05,
      "loss": 0.0027,
      "step": 23790
    },
    {
      "epoch": 2.030890007679836,
      "grad_norm": 0.08921673893928528,
      "learning_rate": 3.984554996160082e-05,
      "loss": 0.0023,
      "step": 23800
    },
    {
      "epoch": 2.0317433228091133,
      "grad_norm": 0.18181395530700684,
      "learning_rate": 3.984128338595444e-05,
      "loss": 0.0035,
      "step": 23810
    },
    {
      "epoch": 2.032596637938391,
      "grad_norm": 0.03524201735854149,
      "learning_rate": 3.983701681030805e-05,
      "loss": 0.0025,
      "step": 23820
    },
    {
      "epoch": 2.033449953067668,
      "grad_norm": 0.44010987877845764,
      "learning_rate": 3.983275023466166e-05,
      "loss": 0.0027,
      "step": 23830
    },
    {
      "epoch": 2.034303268196945,
      "grad_norm": 0.08003819733858109,
      "learning_rate": 3.9828483659015275e-05,
      "loss": 0.0028,
      "step": 23840
    },
    {
      "epoch": 2.035156583326222,
      "grad_norm": 0.14923341572284698,
      "learning_rate": 3.982421708336889e-05,
      "loss": 0.0028,
      "step": 23850
    },
    {
      "epoch": 2.0360098984554997,
      "grad_norm": 0.3002939224243164,
      "learning_rate": 3.9819950507722504e-05,
      "loss": 0.0031,
      "step": 23860
    },
    {
      "epoch": 2.036863213584777,
      "grad_norm": 0.46043476462364197,
      "learning_rate": 3.981568393207612e-05,
      "loss": 0.0018,
      "step": 23870
    },
    {
      "epoch": 2.037716528714054,
      "grad_norm": 0.6740958094596863,
      "learning_rate": 3.981141735642973e-05,
      "loss": 0.0024,
      "step": 23880
    },
    {
      "epoch": 2.0385698438433315,
      "grad_norm": 0.1544133424758911,
      "learning_rate": 3.980715078078335e-05,
      "loss": 0.0025,
      "step": 23890
    },
    {
      "epoch": 2.0394231589726086,
      "grad_norm": 0.28364992141723633,
      "learning_rate": 3.980288420513696e-05,
      "loss": 0.003,
      "step": 23900
    },
    {
      "epoch": 2.0402764741018857,
      "grad_norm": 0.19047953188419342,
      "learning_rate": 3.9798617629490575e-05,
      "loss": 0.0022,
      "step": 23910
    },
    {
      "epoch": 2.0411297892311633,
      "grad_norm": 0.028982244431972504,
      "learning_rate": 3.979435105384419e-05,
      "loss": 0.002,
      "step": 23920
    },
    {
      "epoch": 2.0419831043604404,
      "grad_norm": 0.08994540572166443,
      "learning_rate": 3.97900844781978e-05,
      "loss": 0.0019,
      "step": 23930
    },
    {
      "epoch": 2.0428364194897175,
      "grad_norm": 0.16928762197494507,
      "learning_rate": 3.978581790255141e-05,
      "loss": 0.003,
      "step": 23940
    },
    {
      "epoch": 2.0436897346189946,
      "grad_norm": 0.11315134167671204,
      "learning_rate": 3.9781551326905025e-05,
      "loss": 0.0026,
      "step": 23950
    },
    {
      "epoch": 2.044543049748272,
      "grad_norm": 0.2288973033428192,
      "learning_rate": 3.977728475125864e-05,
      "loss": 0.0026,
      "step": 23960
    },
    {
      "epoch": 2.0453963648775493,
      "grad_norm": 0.09766663610935211,
      "learning_rate": 3.9773018175612254e-05,
      "loss": 0.0019,
      "step": 23970
    },
    {
      "epoch": 2.0462496800068264,
      "grad_norm": 0.23496611416339874,
      "learning_rate": 3.976875159996587e-05,
      "loss": 0.0031,
      "step": 23980
    },
    {
      "epoch": 2.047102995136104,
      "grad_norm": 0.19832172989845276,
      "learning_rate": 3.976448502431948e-05,
      "loss": 0.0033,
      "step": 23990
    },
    {
      "epoch": 2.047956310265381,
      "grad_norm": 0.3372206687927246,
      "learning_rate": 3.9760218448673097e-05,
      "loss": 0.0026,
      "step": 24000
    },
    {
      "epoch": 2.048809625394658,
      "grad_norm": 0.054487112909555435,
      "learning_rate": 3.975595187302671e-05,
      "loss": 0.0027,
      "step": 24010
    },
    {
      "epoch": 2.0496629405239353,
      "grad_norm": 0.20836783945560455,
      "learning_rate": 3.9751685297380325e-05,
      "loss": 0.0021,
      "step": 24020
    },
    {
      "epoch": 2.050516255653213,
      "grad_norm": 0.0752284899353981,
      "learning_rate": 3.974741872173394e-05,
      "loss": 0.0027,
      "step": 24030
    },
    {
      "epoch": 2.05136957078249,
      "grad_norm": 0.035406872630119324,
      "learning_rate": 3.9743152146087553e-05,
      "loss": 0.0022,
      "step": 24040
    },
    {
      "epoch": 2.052222885911767,
      "grad_norm": 0.25016605854034424,
      "learning_rate": 3.973888557044117e-05,
      "loss": 0.0035,
      "step": 24050
    },
    {
      "epoch": 2.0530762010410446,
      "grad_norm": 0.04107128083705902,
      "learning_rate": 3.973461899479478e-05,
      "loss": 0.0024,
      "step": 24060
    },
    {
      "epoch": 2.0539295161703217,
      "grad_norm": 0.02049635723233223,
      "learning_rate": 3.973035241914839e-05,
      "loss": 0.0022,
      "step": 24070
    },
    {
      "epoch": 2.054782831299599,
      "grad_norm": 0.06125469505786896,
      "learning_rate": 3.972608584350201e-05,
      "loss": 0.0024,
      "step": 24080
    },
    {
      "epoch": 2.0556361464288764,
      "grad_norm": 0.19246023893356323,
      "learning_rate": 3.972181926785562e-05,
      "loss": 0.0027,
      "step": 24090
    },
    {
      "epoch": 2.0564894615581535,
      "grad_norm": 0.3769417405128479,
      "learning_rate": 3.971755269220924e-05,
      "loss": 0.0024,
      "step": 24100
    },
    {
      "epoch": 2.0573427766874306,
      "grad_norm": 0.6061672568321228,
      "learning_rate": 3.9713286116562846e-05,
      "loss": 0.0018,
      "step": 24110
    },
    {
      "epoch": 2.0581960918167077,
      "grad_norm": 0.03655189275741577,
      "learning_rate": 3.970901954091647e-05,
      "loss": 0.0022,
      "step": 24120
    },
    {
      "epoch": 2.0590494069459853,
      "grad_norm": 0.29385852813720703,
      "learning_rate": 3.9704752965270075e-05,
      "loss": 0.0026,
      "step": 24130
    },
    {
      "epoch": 2.0599027220752624,
      "grad_norm": 0.169459730386734,
      "learning_rate": 3.970048638962369e-05,
      "loss": 0.0023,
      "step": 24140
    },
    {
      "epoch": 2.0607560372045395,
      "grad_norm": 0.2109047919511795,
      "learning_rate": 3.96962198139773e-05,
      "loss": 0.0024,
      "step": 24150
    },
    {
      "epoch": 2.061609352333817,
      "grad_norm": 0.08151111751794815,
      "learning_rate": 3.969195323833092e-05,
      "loss": 0.0023,
      "step": 24160
    },
    {
      "epoch": 2.062462667463094,
      "grad_norm": 0.03970769792795181,
      "learning_rate": 3.968768666268453e-05,
      "loss": 0.0026,
      "step": 24170
    },
    {
      "epoch": 2.0633159825923713,
      "grad_norm": 0.27670082449913025,
      "learning_rate": 3.9683420087038146e-05,
      "loss": 0.0032,
      "step": 24180
    },
    {
      "epoch": 2.064169297721649,
      "grad_norm": 0.03218230977654457,
      "learning_rate": 3.967915351139176e-05,
      "loss": 0.0027,
      "step": 24190
    },
    {
      "epoch": 2.065022612850926,
      "grad_norm": 0.48629826307296753,
      "learning_rate": 3.967488693574537e-05,
      "loss": 0.0021,
      "step": 24200
    },
    {
      "epoch": 2.065875927980203,
      "grad_norm": 0.11108583956956863,
      "learning_rate": 3.967062036009899e-05,
      "loss": 0.0026,
      "step": 24210
    },
    {
      "epoch": 2.06672924310948,
      "grad_norm": 0.16917037963867188,
      "learning_rate": 3.9666353784452596e-05,
      "loss": 0.0027,
      "step": 24220
    },
    {
      "epoch": 2.0675825582387577,
      "grad_norm": 0.21892480552196503,
      "learning_rate": 3.966208720880622e-05,
      "loss": 0.0026,
      "step": 24230
    },
    {
      "epoch": 2.068435873368035,
      "grad_norm": 0.32880666851997375,
      "learning_rate": 3.9657820633159825e-05,
      "loss": 0.0027,
      "step": 24240
    },
    {
      "epoch": 2.069289188497312,
      "grad_norm": 0.2080925852060318,
      "learning_rate": 3.965355405751344e-05,
      "loss": 0.0028,
      "step": 24250
    },
    {
      "epoch": 2.0701425036265895,
      "grad_norm": 0.4158293306827545,
      "learning_rate": 3.964928748186705e-05,
      "loss": 0.0021,
      "step": 24260
    },
    {
      "epoch": 2.0709958187558666,
      "grad_norm": 0.5676014423370361,
      "learning_rate": 3.964502090622067e-05,
      "loss": 0.0028,
      "step": 24270
    },
    {
      "epoch": 2.0718491338851437,
      "grad_norm": 0.06607862561941147,
      "learning_rate": 3.964075433057428e-05,
      "loss": 0.0024,
      "step": 24280
    },
    {
      "epoch": 2.072702449014421,
      "grad_norm": 0.21091236174106598,
      "learning_rate": 3.9636487754927896e-05,
      "loss": 0.0019,
      "step": 24290
    },
    {
      "epoch": 2.0735557641436984,
      "grad_norm": 0.09100987762212753,
      "learning_rate": 3.963222117928151e-05,
      "loss": 0.0025,
      "step": 24300
    },
    {
      "epoch": 2.0744090792729755,
      "grad_norm": 0.08323690295219421,
      "learning_rate": 3.9627954603635124e-05,
      "loss": 0.003,
      "step": 24310
    },
    {
      "epoch": 2.0752623944022526,
      "grad_norm": 0.17551065981388092,
      "learning_rate": 3.962368802798874e-05,
      "loss": 0.0021,
      "step": 24320
    },
    {
      "epoch": 2.07611570953153,
      "grad_norm": 0.09225965291261673,
      "learning_rate": 3.961942145234235e-05,
      "loss": 0.0026,
      "step": 24330
    },
    {
      "epoch": 2.0769690246608072,
      "grad_norm": 0.033505816012620926,
      "learning_rate": 3.961515487669597e-05,
      "loss": 0.0022,
      "step": 24340
    },
    {
      "epoch": 2.0778223397900843,
      "grad_norm": 0.032070696353912354,
      "learning_rate": 3.961088830104958e-05,
      "loss": 0.0027,
      "step": 24350
    },
    {
      "epoch": 2.078675654919362,
      "grad_norm": 0.2809906005859375,
      "learning_rate": 3.9606621725403196e-05,
      "loss": 0.0027,
      "step": 24360
    },
    {
      "epoch": 2.079528970048639,
      "grad_norm": 0.028199391439557076,
      "learning_rate": 3.960235514975681e-05,
      "loss": 0.0025,
      "step": 24370
    },
    {
      "epoch": 2.080382285177916,
      "grad_norm": 0.2794515788555145,
      "learning_rate": 3.959808857411042e-05,
      "loss": 0.0033,
      "step": 24380
    },
    {
      "epoch": 2.0812356003071932,
      "grad_norm": 0.05471394956111908,
      "learning_rate": 3.959382199846404e-05,
      "loss": 0.0023,
      "step": 24390
    },
    {
      "epoch": 2.082088915436471,
      "grad_norm": 0.5447207093238831,
      "learning_rate": 3.9589555422817646e-05,
      "loss": 0.002,
      "step": 24400
    },
    {
      "epoch": 2.082942230565748,
      "grad_norm": 0.1541115939617157,
      "learning_rate": 3.958528884717127e-05,
      "loss": 0.0025,
      "step": 24410
    },
    {
      "epoch": 2.083795545695025,
      "grad_norm": 0.1323901265859604,
      "learning_rate": 3.9581022271524874e-05,
      "loss": 0.0028,
      "step": 24420
    },
    {
      "epoch": 2.0846488608243026,
      "grad_norm": 0.2286713570356369,
      "learning_rate": 3.9576755695878495e-05,
      "loss": 0.0026,
      "step": 24430
    },
    {
      "epoch": 2.0855021759535797,
      "grad_norm": 0.4738865792751312,
      "learning_rate": 3.95724891202321e-05,
      "loss": 0.0027,
      "step": 24440
    },
    {
      "epoch": 2.086355491082857,
      "grad_norm": 0.35926514863967896,
      "learning_rate": 3.956822254458572e-05,
      "loss": 0.0028,
      "step": 24450
    },
    {
      "epoch": 2.0872088062121343,
      "grad_norm": 0.11690497398376465,
      "learning_rate": 3.956395596893933e-05,
      "loss": 0.0032,
      "step": 24460
    },
    {
      "epoch": 2.0880621213414114,
      "grad_norm": 0.07734929025173187,
      "learning_rate": 3.9559689393292946e-05,
      "loss": 0.002,
      "step": 24470
    },
    {
      "epoch": 2.0889154364706886,
      "grad_norm": 0.06296806037425995,
      "learning_rate": 3.955542281764656e-05,
      "loss": 0.0032,
      "step": 24480
    },
    {
      "epoch": 2.0897687515999657,
      "grad_norm": 0.15444150567054749,
      "learning_rate": 3.955115624200017e-05,
      "loss": 0.0031,
      "step": 24490
    },
    {
      "epoch": 2.0906220667292432,
      "grad_norm": 0.18857496976852417,
      "learning_rate": 3.954688966635379e-05,
      "loss": 0.0026,
      "step": 24500
    },
    {
      "epoch": 2.0914753818585203,
      "grad_norm": 0.04729035496711731,
      "learning_rate": 3.9542623090707396e-05,
      "loss": 0.0021,
      "step": 24510
    },
    {
      "epoch": 2.0923286969877974,
      "grad_norm": 0.11743167042732239,
      "learning_rate": 3.953835651506102e-05,
      "loss": 0.0026,
      "step": 24520
    },
    {
      "epoch": 2.093182012117075,
      "grad_norm": 0.42744138836860657,
      "learning_rate": 3.9534089939414624e-05,
      "loss": 0.0023,
      "step": 24530
    },
    {
      "epoch": 2.094035327246352,
      "grad_norm": 0.02711429074406624,
      "learning_rate": 3.9529823363768245e-05,
      "loss": 0.0036,
      "step": 24540
    },
    {
      "epoch": 2.094888642375629,
      "grad_norm": 0.20344072580337524,
      "learning_rate": 3.952555678812185e-05,
      "loss": 0.0021,
      "step": 24550
    },
    {
      "epoch": 2.0957419575049068,
      "grad_norm": 0.333812415599823,
      "learning_rate": 3.952129021247547e-05,
      "loss": 0.0029,
      "step": 24560
    },
    {
      "epoch": 2.096595272634184,
      "grad_norm": 0.05589538812637329,
      "learning_rate": 3.951702363682908e-05,
      "loss": 0.0024,
      "step": 24570
    },
    {
      "epoch": 2.097448587763461,
      "grad_norm": 0.24757623672485352,
      "learning_rate": 3.9512757061182695e-05,
      "loss": 0.0039,
      "step": 24580
    },
    {
      "epoch": 2.098301902892738,
      "grad_norm": 0.08063610643148422,
      "learning_rate": 3.950849048553631e-05,
      "loss": 0.0018,
      "step": 24590
    },
    {
      "epoch": 2.0991552180220157,
      "grad_norm": 0.07994690537452698,
      "learning_rate": 3.9504223909889924e-05,
      "loss": 0.0023,
      "step": 24600
    },
    {
      "epoch": 2.1000085331512928,
      "grad_norm": 0.16045531630516052,
      "learning_rate": 3.949995733424354e-05,
      "loss": 0.0024,
      "step": 24610
    },
    {
      "epoch": 2.10086184828057,
      "grad_norm": 0.20334142446517944,
      "learning_rate": 3.949569075859715e-05,
      "loss": 0.0022,
      "step": 24620
    },
    {
      "epoch": 2.1017151634098474,
      "grad_norm": 0.22154206037521362,
      "learning_rate": 3.9491424182950767e-05,
      "loss": 0.0023,
      "step": 24630
    },
    {
      "epoch": 2.1025684785391245,
      "grad_norm": 0.03092236816883087,
      "learning_rate": 3.948715760730438e-05,
      "loss": 0.0023,
      "step": 24640
    },
    {
      "epoch": 2.1034217936684017,
      "grad_norm": 0.26512181758880615,
      "learning_rate": 3.9482891031657995e-05,
      "loss": 0.0025,
      "step": 24650
    },
    {
      "epoch": 2.1042751087976788,
      "grad_norm": 0.15201051533222198,
      "learning_rate": 3.947862445601161e-05,
      "loss": 0.0034,
      "step": 24660
    },
    {
      "epoch": 2.1051284239269563,
      "grad_norm": 0.08026827126741409,
      "learning_rate": 3.9474357880365224e-05,
      "loss": 0.0034,
      "step": 24670
    },
    {
      "epoch": 2.1059817390562334,
      "grad_norm": 0.26492613554000854,
      "learning_rate": 3.947009130471884e-05,
      "loss": 0.0023,
      "step": 24680
    },
    {
      "epoch": 2.1068350541855105,
      "grad_norm": 0.06824968010187149,
      "learning_rate": 3.9465824729072445e-05,
      "loss": 0.0028,
      "step": 24690
    },
    {
      "epoch": 2.107688369314788,
      "grad_norm": 0.32094231247901917,
      "learning_rate": 3.9461558153426066e-05,
      "loss": 0.002,
      "step": 24700
    },
    {
      "epoch": 2.108541684444065,
      "grad_norm": 0.11400192230939865,
      "learning_rate": 3.9457291577779674e-05,
      "loss": 0.0018,
      "step": 24710
    },
    {
      "epoch": 2.1093949995733423,
      "grad_norm": 0.043666206300258636,
      "learning_rate": 3.945302500213329e-05,
      "loss": 0.0021,
      "step": 24720
    },
    {
      "epoch": 2.11024831470262,
      "grad_norm": 0.17288610339164734,
      "learning_rate": 3.94487584264869e-05,
      "loss": 0.0033,
      "step": 24730
    },
    {
      "epoch": 2.111101629831897,
      "grad_norm": 0.4403702914714813,
      "learning_rate": 3.9444491850840516e-05,
      "loss": 0.0031,
      "step": 24740
    },
    {
      "epoch": 2.111954944961174,
      "grad_norm": 0.13536685705184937,
      "learning_rate": 3.944022527519413e-05,
      "loss": 0.0033,
      "step": 24750
    },
    {
      "epoch": 2.112808260090451,
      "grad_norm": 0.12553420662879944,
      "learning_rate": 3.9435958699547745e-05,
      "loss": 0.0026,
      "step": 24760
    },
    {
      "epoch": 2.1136615752197287,
      "grad_norm": 0.3357568383216858,
      "learning_rate": 3.943169212390136e-05,
      "loss": 0.0026,
      "step": 24770
    },
    {
      "epoch": 2.114514890349006,
      "grad_norm": 0.26177075505256653,
      "learning_rate": 3.9427425548254973e-05,
      "loss": 0.0027,
      "step": 24780
    },
    {
      "epoch": 2.115368205478283,
      "grad_norm": 0.17436090111732483,
      "learning_rate": 3.942315897260859e-05,
      "loss": 0.002,
      "step": 24790
    },
    {
      "epoch": 2.1162215206075605,
      "grad_norm": 0.2787189185619354,
      "learning_rate": 3.9418892396962195e-05,
      "loss": 0.0038,
      "step": 24800
    },
    {
      "epoch": 2.1170748357368376,
      "grad_norm": 0.025692546740174294,
      "learning_rate": 3.9414625821315816e-05,
      "loss": 0.0023,
      "step": 24810
    },
    {
      "epoch": 2.1179281508661147,
      "grad_norm": 0.041085343807935715,
      "learning_rate": 3.9410359245669424e-05,
      "loss": 0.0029,
      "step": 24820
    },
    {
      "epoch": 2.1187814659953923,
      "grad_norm": 0.19844001531600952,
      "learning_rate": 3.9406092670023045e-05,
      "loss": 0.002,
      "step": 24830
    },
    {
      "epoch": 2.1196347811246694,
      "grad_norm": 0.15015289187431335,
      "learning_rate": 3.940182609437665e-05,
      "loss": 0.0031,
      "step": 24840
    },
    {
      "epoch": 2.1204880962539465,
      "grad_norm": 0.22698286175727844,
      "learning_rate": 3.939755951873027e-05,
      "loss": 0.0018,
      "step": 24850
    },
    {
      "epoch": 2.1213414113832236,
      "grad_norm": 0.08097460865974426,
      "learning_rate": 3.939329294308388e-05,
      "loss": 0.0019,
      "step": 24860
    },
    {
      "epoch": 2.122194726512501,
      "grad_norm": 0.034473173320293427,
      "learning_rate": 3.9389026367437495e-05,
      "loss": 0.0025,
      "step": 24870
    },
    {
      "epoch": 2.1230480416417783,
      "grad_norm": 0.14282549917697906,
      "learning_rate": 3.938475979179111e-05,
      "loss": 0.0022,
      "step": 24880
    },
    {
      "epoch": 2.1239013567710554,
      "grad_norm": 0.11551100015640259,
      "learning_rate": 3.938049321614472e-05,
      "loss": 0.0026,
      "step": 24890
    },
    {
      "epoch": 2.124754671900333,
      "grad_norm": 0.26547396183013916,
      "learning_rate": 3.937622664049834e-05,
      "loss": 0.0028,
      "step": 24900
    },
    {
      "epoch": 2.12560798702961,
      "grad_norm": 0.046877507120370865,
      "learning_rate": 3.937196006485195e-05,
      "loss": 0.0028,
      "step": 24910
    },
    {
      "epoch": 2.126461302158887,
      "grad_norm": 0.40409526228904724,
      "learning_rate": 3.9367693489205566e-05,
      "loss": 0.0034,
      "step": 24920
    },
    {
      "epoch": 2.1273146172881647,
      "grad_norm": 0.15379582345485687,
      "learning_rate": 3.936342691355918e-05,
      "loss": 0.0025,
      "step": 24930
    },
    {
      "epoch": 2.128167932417442,
      "grad_norm": 0.17232254147529602,
      "learning_rate": 3.9359160337912795e-05,
      "loss": 0.0021,
      "step": 24940
    },
    {
      "epoch": 2.129021247546719,
      "grad_norm": 0.26351863145828247,
      "learning_rate": 3.935489376226641e-05,
      "loss": 0.0023,
      "step": 24950
    },
    {
      "epoch": 2.129874562675996,
      "grad_norm": 0.06436482816934586,
      "learning_rate": 3.935062718662002e-05,
      "loss": 0.0017,
      "step": 24960
    },
    {
      "epoch": 2.1307278778052736,
      "grad_norm": 0.3445644974708557,
      "learning_rate": 3.934636061097364e-05,
      "loss": 0.0022,
      "step": 24970
    },
    {
      "epoch": 2.1315811929345507,
      "grad_norm": 0.32129421830177307,
      "learning_rate": 3.934209403532725e-05,
      "loss": 0.0027,
      "step": 24980
    },
    {
      "epoch": 2.132434508063828,
      "grad_norm": 0.060102008283138275,
      "learning_rate": 3.933782745968086e-05,
      "loss": 0.0025,
      "step": 24990
    },
    {
      "epoch": 2.1332878231931054,
      "grad_norm": 0.1611039638519287,
      "learning_rate": 3.933356088403447e-05,
      "loss": 0.0025,
      "step": 25000
    },
    {
      "epoch": 2.1341411383223825,
      "grad_norm": 0.12517565488815308,
      "learning_rate": 3.932929430838809e-05,
      "loss": 0.0026,
      "step": 25010
    },
    {
      "epoch": 2.1349944534516596,
      "grad_norm": 0.1953056901693344,
      "learning_rate": 3.93250277327417e-05,
      "loss": 0.0027,
      "step": 25020
    },
    {
      "epoch": 2.1358477685809367,
      "grad_norm": 0.21318893134593964,
      "learning_rate": 3.9320761157095316e-05,
      "loss": 0.0021,
      "step": 25030
    },
    {
      "epoch": 2.1367010837102143,
      "grad_norm": 0.2808837294578552,
      "learning_rate": 3.931649458144893e-05,
      "loss": 0.0034,
      "step": 25040
    },
    {
      "epoch": 2.1375543988394914,
      "grad_norm": 0.22230102121829987,
      "learning_rate": 3.9312228005802544e-05,
      "loss": 0.0023,
      "step": 25050
    },
    {
      "epoch": 2.1384077139687685,
      "grad_norm": 0.06594054400920868,
      "learning_rate": 3.930796143015616e-05,
      "loss": 0.0024,
      "step": 25060
    },
    {
      "epoch": 2.139261029098046,
      "grad_norm": 0.06724801659584045,
      "learning_rate": 3.930369485450977e-05,
      "loss": 0.0021,
      "step": 25070
    },
    {
      "epoch": 2.140114344227323,
      "grad_norm": 0.2459021359682083,
      "learning_rate": 3.929942827886339e-05,
      "loss": 0.0035,
      "step": 25080
    },
    {
      "epoch": 2.1409676593566003,
      "grad_norm": 0.11740429699420929,
      "learning_rate": 3.9295161703217e-05,
      "loss": 0.0023,
      "step": 25090
    },
    {
      "epoch": 2.141820974485878,
      "grad_norm": 0.1918615996837616,
      "learning_rate": 3.9290895127570616e-05,
      "loss": 0.0021,
      "step": 25100
    },
    {
      "epoch": 2.142674289615155,
      "grad_norm": 0.22545579075813293,
      "learning_rate": 3.928662855192422e-05,
      "loss": 0.0029,
      "step": 25110
    },
    {
      "epoch": 2.143527604744432,
      "grad_norm": 0.15658098459243774,
      "learning_rate": 3.9282361976277844e-05,
      "loss": 0.0025,
      "step": 25120
    },
    {
      "epoch": 2.144380919873709,
      "grad_norm": 0.09347007423639297,
      "learning_rate": 3.927809540063145e-05,
      "loss": 0.0018,
      "step": 25130
    },
    {
      "epoch": 2.1452342350029867,
      "grad_norm": 0.08010785281658173,
      "learning_rate": 3.927382882498507e-05,
      "loss": 0.003,
      "step": 25140
    },
    {
      "epoch": 2.146087550132264,
      "grad_norm": 0.33952245116233826,
      "learning_rate": 3.926956224933868e-05,
      "loss": 0.0021,
      "step": 25150
    },
    {
      "epoch": 2.146940865261541,
      "grad_norm": 0.2233433574438095,
      "learning_rate": 3.92652956736923e-05,
      "loss": 0.0029,
      "step": 25160
    },
    {
      "epoch": 2.1477941803908185,
      "grad_norm": 0.18217045068740845,
      "learning_rate": 3.926102909804591e-05,
      "loss": 0.0025,
      "step": 25170
    },
    {
      "epoch": 2.1486474955200956,
      "grad_norm": 0.28595370054244995,
      "learning_rate": 3.925676252239953e-05,
      "loss": 0.003,
      "step": 25180
    },
    {
      "epoch": 2.1495008106493727,
      "grad_norm": 0.09734417498111725,
      "learning_rate": 3.925249594675314e-05,
      "loss": 0.0024,
      "step": 25190
    },
    {
      "epoch": 2.1503541257786503,
      "grad_norm": 0.19564971327781677,
      "learning_rate": 3.924822937110675e-05,
      "loss": 0.0025,
      "step": 25200
    },
    {
      "epoch": 2.1512074409079274,
      "grad_norm": 0.1653367578983307,
      "learning_rate": 3.9243962795460365e-05,
      "loss": 0.0025,
      "step": 25210
    },
    {
      "epoch": 2.1520607560372045,
      "grad_norm": 0.24439500272274017,
      "learning_rate": 3.923969621981398e-05,
      "loss": 0.0027,
      "step": 25220
    },
    {
      "epoch": 2.1529140711664816,
      "grad_norm": 0.1593494713306427,
      "learning_rate": 3.9235429644167594e-05,
      "loss": 0.0023,
      "step": 25230
    },
    {
      "epoch": 2.153767386295759,
      "grad_norm": 0.5096539258956909,
      "learning_rate": 3.923116306852121e-05,
      "loss": 0.0029,
      "step": 25240
    },
    {
      "epoch": 2.1546207014250363,
      "grad_norm": 0.4697415232658386,
      "learning_rate": 3.922689649287482e-05,
      "loss": 0.0035,
      "step": 25250
    },
    {
      "epoch": 2.1554740165543134,
      "grad_norm": 0.2725336253643036,
      "learning_rate": 3.922262991722843e-05,
      "loss": 0.0036,
      "step": 25260
    },
    {
      "epoch": 2.156327331683591,
      "grad_norm": 0.17158162593841553,
      "learning_rate": 3.921836334158205e-05,
      "loss": 0.0027,
      "step": 25270
    },
    {
      "epoch": 2.157180646812868,
      "grad_norm": 0.26444897055625916,
      "learning_rate": 3.921409676593566e-05,
      "loss": 0.0022,
      "step": 25280
    },
    {
      "epoch": 2.158033961942145,
      "grad_norm": 0.4520084261894226,
      "learning_rate": 3.920983019028928e-05,
      "loss": 0.0022,
      "step": 25290
    },
    {
      "epoch": 2.1588872770714227,
      "grad_norm": 0.5320318937301636,
      "learning_rate": 3.920556361464289e-05,
      "loss": 0.0024,
      "step": 25300
    },
    {
      "epoch": 2.1597405922007,
      "grad_norm": 0.061291247606277466,
      "learning_rate": 3.92012970389965e-05,
      "loss": 0.0024,
      "step": 25310
    },
    {
      "epoch": 2.160593907329977,
      "grad_norm": 0.3223651051521301,
      "learning_rate": 3.9197030463350115e-05,
      "loss": 0.0021,
      "step": 25320
    },
    {
      "epoch": 2.161447222459254,
      "grad_norm": 0.3076014816761017,
      "learning_rate": 3.919276388770373e-05,
      "loss": 0.0028,
      "step": 25330
    },
    {
      "epoch": 2.1623005375885316,
      "grad_norm": 0.2466912418603897,
      "learning_rate": 3.9188497312057344e-05,
      "loss": 0.0031,
      "step": 25340
    },
    {
      "epoch": 2.1631538527178087,
      "grad_norm": 0.15234075486660004,
      "learning_rate": 3.918423073641096e-05,
      "loss": 0.0022,
      "step": 25350
    },
    {
      "epoch": 2.164007167847086,
      "grad_norm": 0.17686383426189423,
      "learning_rate": 3.917996416076457e-05,
      "loss": 0.003,
      "step": 25360
    },
    {
      "epoch": 2.1648604829763634,
      "grad_norm": 0.19073978066444397,
      "learning_rate": 3.9175697585118187e-05,
      "loss": 0.004,
      "step": 25370
    },
    {
      "epoch": 2.1657137981056405,
      "grad_norm": 0.1687583178281784,
      "learning_rate": 3.91714310094718e-05,
      "loss": 0.0026,
      "step": 25380
    },
    {
      "epoch": 2.1665671132349176,
      "grad_norm": 0.15940819680690765,
      "learning_rate": 3.9167164433825415e-05,
      "loss": 0.0025,
      "step": 25390
    },
    {
      "epoch": 2.1674204283641947,
      "grad_norm": 0.23177269101142883,
      "learning_rate": 3.916289785817903e-05,
      "loss": 0.0024,
      "step": 25400
    },
    {
      "epoch": 2.1682737434934722,
      "grad_norm": 0.21425430476665497,
      "learning_rate": 3.9158631282532643e-05,
      "loss": 0.002,
      "step": 25410
    },
    {
      "epoch": 2.1691270586227493,
      "grad_norm": 0.032222818583250046,
      "learning_rate": 3.915436470688625e-05,
      "loss": 0.0023,
      "step": 25420
    },
    {
      "epoch": 2.1699803737520265,
      "grad_norm": 0.41338497400283813,
      "learning_rate": 3.915009813123987e-05,
      "loss": 0.0021,
      "step": 25430
    },
    {
      "epoch": 2.170833688881304,
      "grad_norm": 0.1702302247285843,
      "learning_rate": 3.914583155559348e-05,
      "loss": 0.002,
      "step": 25440
    },
    {
      "epoch": 2.171687004010581,
      "grad_norm": 0.049437250941991806,
      "learning_rate": 3.91415649799471e-05,
      "loss": 0.0024,
      "step": 25450
    },
    {
      "epoch": 2.1725403191398582,
      "grad_norm": 0.2662544250488281,
      "learning_rate": 3.913729840430071e-05,
      "loss": 0.002,
      "step": 25460
    },
    {
      "epoch": 2.173393634269136,
      "grad_norm": 0.031980134546756744,
      "learning_rate": 3.913303182865433e-05,
      "loss": 0.0033,
      "step": 25470
    },
    {
      "epoch": 2.174246949398413,
      "grad_norm": 0.16688305139541626,
      "learning_rate": 3.9128765253007936e-05,
      "loss": 0.0025,
      "step": 25480
    },
    {
      "epoch": 2.17510026452769,
      "grad_norm": 0.1076669991016388,
      "learning_rate": 3.912449867736156e-05,
      "loss": 0.0024,
      "step": 25490
    },
    {
      "epoch": 2.175953579656967,
      "grad_norm": 0.43220776319503784,
      "learning_rate": 3.9120232101715165e-05,
      "loss": 0.0024,
      "step": 25500
    },
    {
      "epoch": 2.1768068947862447,
      "grad_norm": 0.2124844342470169,
      "learning_rate": 3.911596552606878e-05,
      "loss": 0.0024,
      "step": 25510
    },
    {
      "epoch": 2.177660209915522,
      "grad_norm": 0.12337884306907654,
      "learning_rate": 3.911169895042239e-05,
      "loss": 0.0027,
      "step": 25520
    },
    {
      "epoch": 2.178513525044799,
      "grad_norm": 0.13375303149223328,
      "learning_rate": 3.9107432374776e-05,
      "loss": 0.0024,
      "step": 25530
    },
    {
      "epoch": 2.1793668401740764,
      "grad_norm": 0.15119072794914246,
      "learning_rate": 3.910316579912962e-05,
      "loss": 0.0029,
      "step": 25540
    },
    {
      "epoch": 2.1802201553033536,
      "grad_norm": 0.15369462966918945,
      "learning_rate": 3.909889922348323e-05,
      "loss": 0.0022,
      "step": 25550
    },
    {
      "epoch": 2.1810734704326307,
      "grad_norm": 0.11695931106805801,
      "learning_rate": 3.909463264783685e-05,
      "loss": 0.0026,
      "step": 25560
    },
    {
      "epoch": 2.1819267855619078,
      "grad_norm": 0.27881279587745667,
      "learning_rate": 3.909036607219046e-05,
      "loss": 0.0025,
      "step": 25570
    },
    {
      "epoch": 2.1827801006911853,
      "grad_norm": 0.0762939304113388,
      "learning_rate": 3.908609949654408e-05,
      "loss": 0.0025,
      "step": 25580
    },
    {
      "epoch": 2.1836334158204624,
      "grad_norm": 0.2597726583480835,
      "learning_rate": 3.9081832920897686e-05,
      "loss": 0.0023,
      "step": 25590
    },
    {
      "epoch": 2.1844867309497396,
      "grad_norm": 0.0837753638625145,
      "learning_rate": 3.907756634525131e-05,
      "loss": 0.0025,
      "step": 25600
    },
    {
      "epoch": 2.185340046079017,
      "grad_norm": 0.5744689702987671,
      "learning_rate": 3.9073299769604915e-05,
      "loss": 0.0027,
      "step": 25610
    },
    {
      "epoch": 2.186193361208294,
      "grad_norm": 0.07810989022254944,
      "learning_rate": 3.906903319395853e-05,
      "loss": 0.0028,
      "step": 25620
    },
    {
      "epoch": 2.1870466763375713,
      "grad_norm": 0.2545970678329468,
      "learning_rate": 3.906476661831214e-05,
      "loss": 0.0026,
      "step": 25630
    },
    {
      "epoch": 2.187899991466849,
      "grad_norm": 0.11585482954978943,
      "learning_rate": 3.906050004266576e-05,
      "loss": 0.0029,
      "step": 25640
    },
    {
      "epoch": 2.188753306596126,
      "grad_norm": 0.23628711700439453,
      "learning_rate": 3.905623346701937e-05,
      "loss": 0.0023,
      "step": 25650
    },
    {
      "epoch": 2.189606621725403,
      "grad_norm": 0.20912779867649078,
      "learning_rate": 3.9051966891372986e-05,
      "loss": 0.002,
      "step": 25660
    },
    {
      "epoch": 2.1904599368546807,
      "grad_norm": 0.07853316515684128,
      "learning_rate": 3.90477003157266e-05,
      "loss": 0.003,
      "step": 25670
    },
    {
      "epoch": 2.1913132519839578,
      "grad_norm": 0.19311746954917908,
      "learning_rate": 3.9043433740080214e-05,
      "loss": 0.0021,
      "step": 25680
    },
    {
      "epoch": 2.192166567113235,
      "grad_norm": 0.18159541487693787,
      "learning_rate": 3.903916716443383e-05,
      "loss": 0.0023,
      "step": 25690
    },
    {
      "epoch": 2.193019882242512,
      "grad_norm": 0.0450776033103466,
      "learning_rate": 3.903490058878744e-05,
      "loss": 0.0022,
      "step": 25700
    },
    {
      "epoch": 2.1938731973717895,
      "grad_norm": 0.09193551540374756,
      "learning_rate": 3.903063401314106e-05,
      "loss": 0.0031,
      "step": 25710
    },
    {
      "epoch": 2.1947265125010667,
      "grad_norm": 0.2808816432952881,
      "learning_rate": 3.902636743749467e-05,
      "loss": 0.0022,
      "step": 25720
    },
    {
      "epoch": 2.1955798276303438,
      "grad_norm": 0.11679735034704208,
      "learning_rate": 3.902210086184828e-05,
      "loss": 0.0022,
      "step": 25730
    },
    {
      "epoch": 2.1964331427596213,
      "grad_norm": 0.3617652654647827,
      "learning_rate": 3.90178342862019e-05,
      "loss": 0.0023,
      "step": 25740
    },
    {
      "epoch": 2.1972864578888984,
      "grad_norm": 0.19253532588481903,
      "learning_rate": 3.901356771055551e-05,
      "loss": 0.0024,
      "step": 25750
    },
    {
      "epoch": 2.1981397730181755,
      "grad_norm": 0.05291706323623657,
      "learning_rate": 3.900930113490913e-05,
      "loss": 0.0025,
      "step": 25760
    },
    {
      "epoch": 2.1989930881474526,
      "grad_norm": 0.4058988392353058,
      "learning_rate": 3.9005034559262736e-05,
      "loss": 0.0029,
      "step": 25770
    },
    {
      "epoch": 2.19984640327673,
      "grad_norm": 0.04030052572488785,
      "learning_rate": 3.900076798361635e-05,
      "loss": 0.0022,
      "step": 25780
    },
    {
      "epoch": 2.2006997184060073,
      "grad_norm": 0.3387228548526764,
      "learning_rate": 3.8996501407969964e-05,
      "loss": 0.0019,
      "step": 25790
    },
    {
      "epoch": 2.2015530335352844,
      "grad_norm": 0.15301819145679474,
      "learning_rate": 3.899223483232358e-05,
      "loss": 0.0029,
      "step": 25800
    },
    {
      "epoch": 2.202406348664562,
      "grad_norm": 0.3346920311450958,
      "learning_rate": 3.898796825667719e-05,
      "loss": 0.0021,
      "step": 25810
    },
    {
      "epoch": 2.203259663793839,
      "grad_norm": 0.13682764768600464,
      "learning_rate": 3.898370168103081e-05,
      "loss": 0.0031,
      "step": 25820
    },
    {
      "epoch": 2.204112978923116,
      "grad_norm": 0.13408754765987396,
      "learning_rate": 3.897943510538442e-05,
      "loss": 0.0033,
      "step": 25830
    },
    {
      "epoch": 2.2049662940523937,
      "grad_norm": 0.265510618686676,
      "learning_rate": 3.897516852973803e-05,
      "loss": 0.0027,
      "step": 25840
    },
    {
      "epoch": 2.205819609181671,
      "grad_norm": 0.20625348389148712,
      "learning_rate": 3.897090195409165e-05,
      "loss": 0.0029,
      "step": 25850
    },
    {
      "epoch": 2.206672924310948,
      "grad_norm": 0.34025147557258606,
      "learning_rate": 3.896663537844526e-05,
      "loss": 0.0023,
      "step": 25860
    },
    {
      "epoch": 2.207526239440225,
      "grad_norm": 0.23995397984981537,
      "learning_rate": 3.896236880279888e-05,
      "loss": 0.0029,
      "step": 25870
    },
    {
      "epoch": 2.2083795545695026,
      "grad_norm": 0.2881415784358978,
      "learning_rate": 3.8958102227152486e-05,
      "loss": 0.0024,
      "step": 25880
    },
    {
      "epoch": 2.2092328696987797,
      "grad_norm": 0.2618837356567383,
      "learning_rate": 3.895383565150611e-05,
      "loss": 0.0029,
      "step": 25890
    },
    {
      "epoch": 2.210086184828057,
      "grad_norm": 0.0499829426407814,
      "learning_rate": 3.8949569075859714e-05,
      "loss": 0.0021,
      "step": 25900
    },
    {
      "epoch": 2.2109394999573344,
      "grad_norm": 0.06470750272274017,
      "learning_rate": 3.8945302500213335e-05,
      "loss": 0.0022,
      "step": 25910
    },
    {
      "epoch": 2.2117928150866115,
      "grad_norm": 0.06183671951293945,
      "learning_rate": 3.894103592456694e-05,
      "loss": 0.0029,
      "step": 25920
    },
    {
      "epoch": 2.2126461302158886,
      "grad_norm": 0.06680465489625931,
      "learning_rate": 3.893676934892056e-05,
      "loss": 0.0021,
      "step": 25930
    },
    {
      "epoch": 2.2134994453451657,
      "grad_norm": 0.04793619364500046,
      "learning_rate": 3.893250277327417e-05,
      "loss": 0.0021,
      "step": 25940
    },
    {
      "epoch": 2.2143527604744433,
      "grad_norm": 0.20633073151111603,
      "learning_rate": 3.8928236197627785e-05,
      "loss": 0.0024,
      "step": 25950
    },
    {
      "epoch": 2.2152060756037204,
      "grad_norm": 0.04733400419354439,
      "learning_rate": 3.89239696219814e-05,
      "loss": 0.0026,
      "step": 25960
    },
    {
      "epoch": 2.2160593907329975,
      "grad_norm": 0.12031880766153336,
      "learning_rate": 3.8919703046335014e-05,
      "loss": 0.0022,
      "step": 25970
    },
    {
      "epoch": 2.216912705862275,
      "grad_norm": 0.15400217473506927,
      "learning_rate": 3.891543647068863e-05,
      "loss": 0.0021,
      "step": 25980
    },
    {
      "epoch": 2.217766020991552,
      "grad_norm": 0.22468164563179016,
      "learning_rate": 3.891116989504224e-05,
      "loss": 0.0029,
      "step": 25990
    },
    {
      "epoch": 2.2186193361208293,
      "grad_norm": 0.4467962682247162,
      "learning_rate": 3.8906903319395857e-05,
      "loss": 0.0022,
      "step": 26000
    },
    {
      "epoch": 2.219472651250107,
      "grad_norm": 0.464984267950058,
      "learning_rate": 3.890263674374947e-05,
      "loss": 0.0025,
      "step": 26010
    },
    {
      "epoch": 2.220325966379384,
      "grad_norm": 0.256866991519928,
      "learning_rate": 3.8898370168103085e-05,
      "loss": 0.0027,
      "step": 26020
    },
    {
      "epoch": 2.221179281508661,
      "grad_norm": 0.29800376296043396,
      "learning_rate": 3.88941035924567e-05,
      "loss": 0.0022,
      "step": 26030
    },
    {
      "epoch": 2.2220325966379386,
      "grad_norm": 0.4140037000179291,
      "learning_rate": 3.888983701681031e-05,
      "loss": 0.0017,
      "step": 26040
    },
    {
      "epoch": 2.2228859117672157,
      "grad_norm": 0.18615242838859558,
      "learning_rate": 3.888557044116392e-05,
      "loss": 0.0024,
      "step": 26050
    },
    {
      "epoch": 2.223739226896493,
      "grad_norm": 0.29828670620918274,
      "learning_rate": 3.8881303865517535e-05,
      "loss": 0.0028,
      "step": 26060
    },
    {
      "epoch": 2.22459254202577,
      "grad_norm": 0.21560180187225342,
      "learning_rate": 3.887703728987115e-05,
      "loss": 0.0023,
      "step": 26070
    },
    {
      "epoch": 2.2254458571550475,
      "grad_norm": 0.09752742201089859,
      "learning_rate": 3.8872770714224764e-05,
      "loss": 0.0024,
      "step": 26080
    },
    {
      "epoch": 2.2262991722843246,
      "grad_norm": 0.18893328309059143,
      "learning_rate": 3.886850413857838e-05,
      "loss": 0.0026,
      "step": 26090
    },
    {
      "epoch": 2.2271524874136017,
      "grad_norm": 0.06685423851013184,
      "learning_rate": 3.886423756293199e-05,
      "loss": 0.0023,
      "step": 26100
    },
    {
      "epoch": 2.2280058025428793,
      "grad_norm": 0.18246746063232422,
      "learning_rate": 3.8859970987285606e-05,
      "loss": 0.0025,
      "step": 26110
    },
    {
      "epoch": 2.2288591176721564,
      "grad_norm": 0.11689624190330505,
      "learning_rate": 3.885570441163922e-05,
      "loss": 0.0027,
      "step": 26120
    },
    {
      "epoch": 2.2297124328014335,
      "grad_norm": 0.3186536133289337,
      "learning_rate": 3.8851437835992835e-05,
      "loss": 0.0023,
      "step": 26130
    },
    {
      "epoch": 2.2305657479307106,
      "grad_norm": 0.20960122346878052,
      "learning_rate": 3.884717126034645e-05,
      "loss": 0.003,
      "step": 26140
    },
    {
      "epoch": 2.231419063059988,
      "grad_norm": 0.23919156193733215,
      "learning_rate": 3.884290468470006e-05,
      "loss": 0.0017,
      "step": 26150
    },
    {
      "epoch": 2.2322723781892653,
      "grad_norm": 0.27862071990966797,
      "learning_rate": 3.883863810905368e-05,
      "loss": 0.0023,
      "step": 26160
    },
    {
      "epoch": 2.2331256933185424,
      "grad_norm": 0.14341264963150024,
      "learning_rate": 3.8834371533407285e-05,
      "loss": 0.0022,
      "step": 26170
    },
    {
      "epoch": 2.23397900844782,
      "grad_norm": 0.35706865787506104,
      "learning_rate": 3.8830104957760906e-05,
      "loss": 0.0023,
      "step": 26180
    },
    {
      "epoch": 2.234832323577097,
      "grad_norm": 0.19122016429901123,
      "learning_rate": 3.8825838382114514e-05,
      "loss": 0.0028,
      "step": 26190
    },
    {
      "epoch": 2.235685638706374,
      "grad_norm": 0.035789694637060165,
      "learning_rate": 3.8821571806468135e-05,
      "loss": 0.0024,
      "step": 26200
    },
    {
      "epoch": 2.2365389538356517,
      "grad_norm": 0.46348217129707336,
      "learning_rate": 3.881730523082174e-05,
      "loss": 0.0022,
      "step": 26210
    },
    {
      "epoch": 2.237392268964929,
      "grad_norm": 0.7515457272529602,
      "learning_rate": 3.881303865517536e-05,
      "loss": 0.0024,
      "step": 26220
    },
    {
      "epoch": 2.238245584094206,
      "grad_norm": 0.04608887806534767,
      "learning_rate": 3.880877207952897e-05,
      "loss": 0.0025,
      "step": 26230
    },
    {
      "epoch": 2.239098899223483,
      "grad_norm": 0.11686881631612778,
      "learning_rate": 3.8804505503882585e-05,
      "loss": 0.002,
      "step": 26240
    },
    {
      "epoch": 2.2399522143527606,
      "grad_norm": 0.17071682214736938,
      "learning_rate": 3.88002389282362e-05,
      "loss": 0.0023,
      "step": 26250
    },
    {
      "epoch": 2.2408055294820377,
      "grad_norm": 0.22262965142726898,
      "learning_rate": 3.879597235258981e-05,
      "loss": 0.003,
      "step": 26260
    },
    {
      "epoch": 2.241658844611315,
      "grad_norm": 0.0442439466714859,
      "learning_rate": 3.879170577694343e-05,
      "loss": 0.0021,
      "step": 26270
    },
    {
      "epoch": 2.2425121597405924,
      "grad_norm": 0.5764033794403076,
      "learning_rate": 3.878743920129704e-05,
      "loss": 0.0027,
      "step": 26280
    },
    {
      "epoch": 2.2433654748698695,
      "grad_norm": 0.20660629868507385,
      "learning_rate": 3.8783172625650656e-05,
      "loss": 0.002,
      "step": 26290
    },
    {
      "epoch": 2.2442187899991466,
      "grad_norm": 0.06885506212711334,
      "learning_rate": 3.877890605000427e-05,
      "loss": 0.0029,
      "step": 26300
    },
    {
      "epoch": 2.2450721051284237,
      "grad_norm": 0.17141367495059967,
      "learning_rate": 3.8774639474357885e-05,
      "loss": 0.0025,
      "step": 26310
    },
    {
      "epoch": 2.2459254202577013,
      "grad_norm": 0.11490955948829651,
      "learning_rate": 3.877037289871149e-05,
      "loss": 0.0026,
      "step": 26320
    },
    {
      "epoch": 2.2467787353869784,
      "grad_norm": 0.013826040551066399,
      "learning_rate": 3.876610632306511e-05,
      "loss": 0.0018,
      "step": 26330
    },
    {
      "epoch": 2.2476320505162555,
      "grad_norm": 0.06503221392631531,
      "learning_rate": 3.876183974741872e-05,
      "loss": 0.0026,
      "step": 26340
    },
    {
      "epoch": 2.248485365645533,
      "grad_norm": 0.16919265687465668,
      "learning_rate": 3.8757573171772335e-05,
      "loss": 0.0025,
      "step": 26350
    },
    {
      "epoch": 2.24933868077481,
      "grad_norm": 0.13524509966373444,
      "learning_rate": 3.875330659612595e-05,
      "loss": 0.0024,
      "step": 26360
    },
    {
      "epoch": 2.2501919959040872,
      "grad_norm": 0.2667609453201294,
      "learning_rate": 3.874904002047956e-05,
      "loss": 0.0021,
      "step": 26370
    },
    {
      "epoch": 2.251045311033365,
      "grad_norm": 0.224822536110878,
      "learning_rate": 3.874477344483318e-05,
      "loss": 0.0021,
      "step": 26380
    },
    {
      "epoch": 2.251898626162642,
      "grad_norm": 0.4699907600879669,
      "learning_rate": 3.874050686918679e-05,
      "loss": 0.0025,
      "step": 26390
    },
    {
      "epoch": 2.252751941291919,
      "grad_norm": 0.41223204135894775,
      "learning_rate": 3.8736240293540406e-05,
      "loss": 0.0023,
      "step": 26400
    },
    {
      "epoch": 2.2536052564211966,
      "grad_norm": 0.185930073261261,
      "learning_rate": 3.873197371789402e-05,
      "loss": 0.0026,
      "step": 26410
    },
    {
      "epoch": 2.2544585715504737,
      "grad_norm": 0.026278873905539513,
      "learning_rate": 3.8727707142247634e-05,
      "loss": 0.002,
      "step": 26420
    },
    {
      "epoch": 2.255311886679751,
      "grad_norm": 0.18688619136810303,
      "learning_rate": 3.872344056660125e-05,
      "loss": 0.0024,
      "step": 26430
    },
    {
      "epoch": 2.256165201809028,
      "grad_norm": 0.10258013010025024,
      "learning_rate": 3.871917399095486e-05,
      "loss": 0.0024,
      "step": 26440
    },
    {
      "epoch": 2.2570185169383055,
      "grad_norm": 0.2627406418323517,
      "learning_rate": 3.871490741530848e-05,
      "loss": 0.0025,
      "step": 26450
    },
    {
      "epoch": 2.2578718320675826,
      "grad_norm": 0.0537690706551075,
      "learning_rate": 3.8710640839662085e-05,
      "loss": 0.0024,
      "step": 26460
    },
    {
      "epoch": 2.2587251471968597,
      "grad_norm": 0.24832457304000854,
      "learning_rate": 3.8706374264015706e-05,
      "loss": 0.0023,
      "step": 26470
    },
    {
      "epoch": 2.259578462326137,
      "grad_norm": 0.4754282236099243,
      "learning_rate": 3.870210768836931e-05,
      "loss": 0.0026,
      "step": 26480
    },
    {
      "epoch": 2.2604317774554143,
      "grad_norm": 0.46647128462791443,
      "learning_rate": 3.8697841112722934e-05,
      "loss": 0.0016,
      "step": 26490
    },
    {
      "epoch": 2.2612850925846915,
      "grad_norm": 0.3923129141330719,
      "learning_rate": 3.869357453707654e-05,
      "loss": 0.0021,
      "step": 26500
    },
    {
      "epoch": 2.2621384077139686,
      "grad_norm": 0.1360618770122528,
      "learning_rate": 3.868930796143016e-05,
      "loss": 0.0025,
      "step": 26510
    },
    {
      "epoch": 2.262991722843246,
      "grad_norm": 0.25500020384788513,
      "learning_rate": 3.868504138578377e-05,
      "loss": 0.0019,
      "step": 26520
    },
    {
      "epoch": 2.2638450379725232,
      "grad_norm": 0.25595006346702576,
      "learning_rate": 3.868077481013739e-05,
      "loss": 0.002,
      "step": 26530
    },
    {
      "epoch": 2.2646983531018003,
      "grad_norm": 0.29285794496536255,
      "learning_rate": 3.8676508234491e-05,
      "loss": 0.0026,
      "step": 26540
    },
    {
      "epoch": 2.265551668231078,
      "grad_norm": 0.335189551115036,
      "learning_rate": 3.867224165884461e-05,
      "loss": 0.0034,
      "step": 26550
    },
    {
      "epoch": 2.266404983360355,
      "grad_norm": 0.018699489533901215,
      "learning_rate": 3.866797508319823e-05,
      "loss": 0.002,
      "step": 26560
    },
    {
      "epoch": 2.267258298489632,
      "grad_norm": 0.25118935108184814,
      "learning_rate": 3.866370850755184e-05,
      "loss": 0.0026,
      "step": 26570
    },
    {
      "epoch": 2.2681116136189097,
      "grad_norm": 0.06377290189266205,
      "learning_rate": 3.8659441931905455e-05,
      "loss": 0.0029,
      "step": 26580
    },
    {
      "epoch": 2.268964928748187,
      "grad_norm": 0.1887752264738083,
      "learning_rate": 3.865517535625906e-05,
      "loss": 0.0015,
      "step": 26590
    },
    {
      "epoch": 2.269818243877464,
      "grad_norm": 0.2604452073574066,
      "learning_rate": 3.8650908780612684e-05,
      "loss": 0.0018,
      "step": 26600
    },
    {
      "epoch": 2.270671559006741,
      "grad_norm": 0.2982063591480255,
      "learning_rate": 3.864664220496629e-05,
      "loss": 0.0022,
      "step": 26610
    },
    {
      "epoch": 2.2715248741360186,
      "grad_norm": 0.048840150237083435,
      "learning_rate": 3.864237562931991e-05,
      "loss": 0.0026,
      "step": 26620
    },
    {
      "epoch": 2.2723781892652957,
      "grad_norm": 0.4283585250377655,
      "learning_rate": 3.863810905367352e-05,
      "loss": 0.0019,
      "step": 26630
    },
    {
      "epoch": 2.2732315043945728,
      "grad_norm": 0.07929517328739166,
      "learning_rate": 3.863384247802714e-05,
      "loss": 0.0025,
      "step": 26640
    },
    {
      "epoch": 2.2740848195238503,
      "grad_norm": 0.30593204498291016,
      "learning_rate": 3.862957590238075e-05,
      "loss": 0.002,
      "step": 26650
    },
    {
      "epoch": 2.2749381346531274,
      "grad_norm": 0.04870638996362686,
      "learning_rate": 3.862530932673436e-05,
      "loss": 0.0026,
      "step": 26660
    },
    {
      "epoch": 2.2757914497824046,
      "grad_norm": 0.17664563655853271,
      "learning_rate": 3.862104275108798e-05,
      "loss": 0.0023,
      "step": 26670
    },
    {
      "epoch": 2.2766447649116817,
      "grad_norm": 0.5045215487480164,
      "learning_rate": 3.861677617544159e-05,
      "loss": 0.0023,
      "step": 26680
    },
    {
      "epoch": 2.277498080040959,
      "grad_norm": 0.31986913084983826,
      "learning_rate": 3.8612509599795205e-05,
      "loss": 0.0028,
      "step": 26690
    },
    {
      "epoch": 2.2783513951702363,
      "grad_norm": 0.2961275577545166,
      "learning_rate": 3.860824302414882e-05,
      "loss": 0.0019,
      "step": 26700
    },
    {
      "epoch": 2.2792047102995134,
      "grad_norm": 0.33689671754837036,
      "learning_rate": 3.8603976448502434e-05,
      "loss": 0.003,
      "step": 26710
    },
    {
      "epoch": 2.280058025428791,
      "grad_norm": 0.07901698350906372,
      "learning_rate": 3.859970987285605e-05,
      "loss": 0.002,
      "step": 26720
    },
    {
      "epoch": 2.280911340558068,
      "grad_norm": 0.2853209674358368,
      "learning_rate": 3.859544329720966e-05,
      "loss": 0.002,
      "step": 26730
    },
    {
      "epoch": 2.281764655687345,
      "grad_norm": 0.05496135354042053,
      "learning_rate": 3.8591176721563277e-05,
      "loss": 0.0029,
      "step": 26740
    },
    {
      "epoch": 2.2826179708166228,
      "grad_norm": 0.06530385464429855,
      "learning_rate": 3.858691014591689e-05,
      "loss": 0.0024,
      "step": 26750
    },
    {
      "epoch": 2.2834712859459,
      "grad_norm": 0.10337019711732864,
      "learning_rate": 3.8582643570270505e-05,
      "loss": 0.003,
      "step": 26760
    },
    {
      "epoch": 2.284324601075177,
      "grad_norm": 0.13319818675518036,
      "learning_rate": 3.857837699462411e-05,
      "loss": 0.0022,
      "step": 26770
    },
    {
      "epoch": 2.2851779162044545,
      "grad_norm": 0.03238488361239433,
      "learning_rate": 3.8574110418977734e-05,
      "loss": 0.0023,
      "step": 26780
    },
    {
      "epoch": 2.2860312313337317,
      "grad_norm": 0.39495232701301575,
      "learning_rate": 3.856984384333134e-05,
      "loss": 0.0025,
      "step": 26790
    },
    {
      "epoch": 2.2868845464630088,
      "grad_norm": 0.1891171783208847,
      "learning_rate": 3.856557726768496e-05,
      "loss": 0.0028,
      "step": 26800
    },
    {
      "epoch": 2.287737861592286,
      "grad_norm": 0.2347678691148758,
      "learning_rate": 3.856131069203857e-05,
      "loss": 0.0024,
      "step": 26810
    },
    {
      "epoch": 2.2885911767215634,
      "grad_norm": 0.1321430653333664,
      "learning_rate": 3.855704411639219e-05,
      "loss": 0.0021,
      "step": 26820
    },
    {
      "epoch": 2.2894444918508405,
      "grad_norm": 0.4521876573562622,
      "learning_rate": 3.85527775407458e-05,
      "loss": 0.0021,
      "step": 26830
    },
    {
      "epoch": 2.2902978069801176,
      "grad_norm": 0.40933606028556824,
      "learning_rate": 3.854851096509941e-05,
      "loss": 0.0019,
      "step": 26840
    },
    {
      "epoch": 2.2911511221093948,
      "grad_norm": 0.0340723991394043,
      "learning_rate": 3.8544244389453026e-05,
      "loss": 0.0021,
      "step": 26850
    },
    {
      "epoch": 2.2920044372386723,
      "grad_norm": 0.05154753103852272,
      "learning_rate": 3.853997781380664e-05,
      "loss": 0.0024,
      "step": 26860
    },
    {
      "epoch": 2.2928577523679494,
      "grad_norm": 0.26568034291267395,
      "learning_rate": 3.8535711238160255e-05,
      "loss": 0.0028,
      "step": 26870
    },
    {
      "epoch": 2.2937110674972265,
      "grad_norm": 0.07996243238449097,
      "learning_rate": 3.853144466251387e-05,
      "loss": 0.0026,
      "step": 26880
    },
    {
      "epoch": 2.294564382626504,
      "grad_norm": 0.3285110592842102,
      "learning_rate": 3.8527178086867483e-05,
      "loss": 0.0019,
      "step": 26890
    },
    {
      "epoch": 2.295417697755781,
      "grad_norm": 0.21083371341228485,
      "learning_rate": 3.852291151122109e-05,
      "loss": 0.0019,
      "step": 26900
    },
    {
      "epoch": 2.2962710128850583,
      "grad_norm": 0.04995127022266388,
      "learning_rate": 3.851864493557471e-05,
      "loss": 0.0023,
      "step": 26910
    },
    {
      "epoch": 2.297124328014336,
      "grad_norm": 0.15396051108837128,
      "learning_rate": 3.851437835992832e-05,
      "loss": 0.0024,
      "step": 26920
    },
    {
      "epoch": 2.297977643143613,
      "grad_norm": 0.11961161345243454,
      "learning_rate": 3.851011178428194e-05,
      "loss": 0.0017,
      "step": 26930
    },
    {
      "epoch": 2.29883095827289,
      "grad_norm": 0.031062567606568336,
      "learning_rate": 3.850584520863555e-05,
      "loss": 0.0023,
      "step": 26940
    },
    {
      "epoch": 2.2996842734021676,
      "grad_norm": 0.2210841178894043,
      "learning_rate": 3.850157863298917e-05,
      "loss": 0.0024,
      "step": 26950
    },
    {
      "epoch": 2.3005375885314447,
      "grad_norm": 0.24331073462963104,
      "learning_rate": 3.8497312057342776e-05,
      "loss": 0.003,
      "step": 26960
    },
    {
      "epoch": 2.301390903660722,
      "grad_norm": 0.1164378672838211,
      "learning_rate": 3.849304548169639e-05,
      "loss": 0.0016,
      "step": 26970
    },
    {
      "epoch": 2.302244218789999,
      "grad_norm": 0.06482340395450592,
      "learning_rate": 3.8488778906050005e-05,
      "loss": 0.0018,
      "step": 26980
    },
    {
      "epoch": 2.3030975339192765,
      "grad_norm": 0.1903638243675232,
      "learning_rate": 3.848451233040362e-05,
      "loss": 0.002,
      "step": 26990
    },
    {
      "epoch": 2.3039508490485536,
      "grad_norm": 0.32203418016433716,
      "learning_rate": 3.848024575475723e-05,
      "loss": 0.0022,
      "step": 27000
    },
    {
      "epoch": 2.3048041641778307,
      "grad_norm": 0.3101438879966736,
      "learning_rate": 3.847597917911085e-05,
      "loss": 0.003,
      "step": 27010
    },
    {
      "epoch": 2.3056574793071083,
      "grad_norm": 0.3377224802970886,
      "learning_rate": 3.847171260346446e-05,
      "loss": 0.0036,
      "step": 27020
    },
    {
      "epoch": 2.3065107944363854,
      "grad_norm": 0.08042033016681671,
      "learning_rate": 3.8467446027818076e-05,
      "loss": 0.0022,
      "step": 27030
    },
    {
      "epoch": 2.3073641095656625,
      "grad_norm": 0.08386994153261185,
      "learning_rate": 3.846317945217169e-05,
      "loss": 0.0019,
      "step": 27040
    },
    {
      "epoch": 2.3082174246949396,
      "grad_norm": 0.13667987287044525,
      "learning_rate": 3.8458912876525304e-05,
      "loss": 0.0021,
      "step": 27050
    },
    {
      "epoch": 2.309070739824217,
      "grad_norm": 0.12114083021879196,
      "learning_rate": 3.845464630087892e-05,
      "loss": 0.0026,
      "step": 27060
    },
    {
      "epoch": 2.3099240549534943,
      "grad_norm": 0.05572117865085602,
      "learning_rate": 3.845037972523253e-05,
      "loss": 0.0021,
      "step": 27070
    },
    {
      "epoch": 2.3107773700827714,
      "grad_norm": 0.09560031443834305,
      "learning_rate": 3.844611314958614e-05,
      "loss": 0.0016,
      "step": 27080
    },
    {
      "epoch": 2.311630685212049,
      "grad_norm": 0.338463693857193,
      "learning_rate": 3.844184657393976e-05,
      "loss": 0.0019,
      "step": 27090
    },
    {
      "epoch": 2.312484000341326,
      "grad_norm": 0.34240633249282837,
      "learning_rate": 3.843757999829337e-05,
      "loss": 0.0022,
      "step": 27100
    },
    {
      "epoch": 2.313337315470603,
      "grad_norm": 0.1476791501045227,
      "learning_rate": 3.843331342264698e-05,
      "loss": 0.0022,
      "step": 27110
    },
    {
      "epoch": 2.3141906305998807,
      "grad_norm": 0.11625001579523087,
      "learning_rate": 3.84290468470006e-05,
      "loss": 0.0027,
      "step": 27120
    },
    {
      "epoch": 2.315043945729158,
      "grad_norm": 0.1572050303220749,
      "learning_rate": 3.842478027135421e-05,
      "loss": 0.0025,
      "step": 27130
    },
    {
      "epoch": 2.315897260858435,
      "grad_norm": 0.30330392718315125,
      "learning_rate": 3.8420513695707826e-05,
      "loss": 0.0018,
      "step": 27140
    },
    {
      "epoch": 2.3167505759877125,
      "grad_norm": 0.13496480882167816,
      "learning_rate": 3.841624712006144e-05,
      "loss": 0.0026,
      "step": 27150
    },
    {
      "epoch": 2.3176038911169896,
      "grad_norm": 0.3201375901699066,
      "learning_rate": 3.8411980544415054e-05,
      "loss": 0.0027,
      "step": 27160
    },
    {
      "epoch": 2.3184572062462667,
      "grad_norm": 0.34332364797592163,
      "learning_rate": 3.840771396876867e-05,
      "loss": 0.0032,
      "step": 27170
    },
    {
      "epoch": 2.319310521375544,
      "grad_norm": 0.20787867903709412,
      "learning_rate": 3.840344739312228e-05,
      "loss": 0.0019,
      "step": 27180
    },
    {
      "epoch": 2.3201638365048214,
      "grad_norm": 0.22674398124217987,
      "learning_rate": 3.83991808174759e-05,
      "loss": 0.0029,
      "step": 27190
    },
    {
      "epoch": 2.3210171516340985,
      "grad_norm": 0.15221059322357178,
      "learning_rate": 3.839491424182951e-05,
      "loss": 0.0022,
      "step": 27200
    },
    {
      "epoch": 2.3218704667633756,
      "grad_norm": 0.26377296447753906,
      "learning_rate": 3.839064766618312e-05,
      "loss": 0.0025,
      "step": 27210
    },
    {
      "epoch": 2.3227237818926527,
      "grad_norm": 0.26137682795524597,
      "learning_rate": 3.838638109053674e-05,
      "loss": 0.0021,
      "step": 27220
    },
    {
      "epoch": 2.3235770970219303,
      "grad_norm": 0.17663003504276276,
      "learning_rate": 3.838211451489035e-05,
      "loss": 0.0023,
      "step": 27230
    },
    {
      "epoch": 2.3244304121512074,
      "grad_norm": 0.16943004727363586,
      "learning_rate": 3.837784793924397e-05,
      "loss": 0.002,
      "step": 27240
    },
    {
      "epoch": 2.3252837272804845,
      "grad_norm": 0.15012307465076447,
      "learning_rate": 3.8373581363597576e-05,
      "loss": 0.0025,
      "step": 27250
    },
    {
      "epoch": 2.326137042409762,
      "grad_norm": 0.05045690760016441,
      "learning_rate": 3.83693147879512e-05,
      "loss": 0.0028,
      "step": 27260
    },
    {
      "epoch": 2.326990357539039,
      "grad_norm": 0.21626363694667816,
      "learning_rate": 3.8365048212304804e-05,
      "loss": 0.0023,
      "step": 27270
    },
    {
      "epoch": 2.3278436726683163,
      "grad_norm": 0.03496650606393814,
      "learning_rate": 3.836078163665842e-05,
      "loss": 0.0016,
      "step": 27280
    },
    {
      "epoch": 2.328696987797594,
      "grad_norm": 0.4310784339904785,
      "learning_rate": 3.835651506101203e-05,
      "loss": 0.0022,
      "step": 27290
    },
    {
      "epoch": 2.329550302926871,
      "grad_norm": 0.5011935234069824,
      "learning_rate": 3.835224848536565e-05,
      "loss": 0.0021,
      "step": 27300
    },
    {
      "epoch": 2.330403618056148,
      "grad_norm": 0.33592498302459717,
      "learning_rate": 3.834798190971926e-05,
      "loss": 0.0027,
      "step": 27310
    },
    {
      "epoch": 2.3312569331854256,
      "grad_norm": 0.41111886501312256,
      "learning_rate": 3.8343715334072875e-05,
      "loss": 0.0023,
      "step": 27320
    },
    {
      "epoch": 2.3321102483147027,
      "grad_norm": 0.0629335418343544,
      "learning_rate": 3.833944875842649e-05,
      "loss": 0.0023,
      "step": 27330
    },
    {
      "epoch": 2.33296356344398,
      "grad_norm": 0.02607925422489643,
      "learning_rate": 3.8335182182780104e-05,
      "loss": 0.0025,
      "step": 27340
    },
    {
      "epoch": 2.333816878573257,
      "grad_norm": 0.26728105545043945,
      "learning_rate": 3.833091560713372e-05,
      "loss": 0.0019,
      "step": 27350
    },
    {
      "epoch": 2.3346701937025345,
      "grad_norm": 0.15354499220848083,
      "learning_rate": 3.832664903148733e-05,
      "loss": 0.0028,
      "step": 27360
    },
    {
      "epoch": 2.3355235088318116,
      "grad_norm": 0.1172037124633789,
      "learning_rate": 3.832238245584095e-05,
      "loss": 0.0026,
      "step": 27370
    },
    {
      "epoch": 2.3363768239610887,
      "grad_norm": 0.33670735359191895,
      "learning_rate": 3.8318115880194554e-05,
      "loss": 0.0017,
      "step": 27380
    },
    {
      "epoch": 2.3372301390903663,
      "grad_norm": 0.04461660608649254,
      "learning_rate": 3.831384930454817e-05,
      "loss": 0.0023,
      "step": 27390
    },
    {
      "epoch": 2.3380834542196434,
      "grad_norm": 0.06458587199449539,
      "learning_rate": 3.830958272890178e-05,
      "loss": 0.0025,
      "step": 27400
    },
    {
      "epoch": 2.3389367693489205,
      "grad_norm": 0.09857454895973206,
      "learning_rate": 3.83053161532554e-05,
      "loss": 0.0026,
      "step": 27410
    },
    {
      "epoch": 2.3397900844781976,
      "grad_norm": 0.17879347503185272,
      "learning_rate": 3.830104957760901e-05,
      "loss": 0.0025,
      "step": 27420
    },
    {
      "epoch": 2.340643399607475,
      "grad_norm": 0.12962575256824493,
      "learning_rate": 3.8296783001962625e-05,
      "loss": 0.0026,
      "step": 27430
    },
    {
      "epoch": 2.3414967147367522,
      "grad_norm": 0.17914600670337677,
      "learning_rate": 3.829251642631624e-05,
      "loss": 0.0024,
      "step": 27440
    },
    {
      "epoch": 2.3423500298660294,
      "grad_norm": 0.3000529110431671,
      "learning_rate": 3.8288249850669854e-05,
      "loss": 0.0024,
      "step": 27450
    },
    {
      "epoch": 2.343203344995307,
      "grad_norm": 0.19082508981227875,
      "learning_rate": 3.828398327502347e-05,
      "loss": 0.0025,
      "step": 27460
    },
    {
      "epoch": 2.344056660124584,
      "grad_norm": 0.31581616401672363,
      "learning_rate": 3.827971669937708e-05,
      "loss": 0.002,
      "step": 27470
    },
    {
      "epoch": 2.344909975253861,
      "grad_norm": 0.11608114838600159,
      "learning_rate": 3.8275450123730697e-05,
      "loss": 0.0021,
      "step": 27480
    },
    {
      "epoch": 2.3457632903831387,
      "grad_norm": 0.11869711428880692,
      "learning_rate": 3.827118354808431e-05,
      "loss": 0.0018,
      "step": 27490
    },
    {
      "epoch": 2.346616605512416,
      "grad_norm": 0.24442024528980255,
      "learning_rate": 3.8266916972437925e-05,
      "loss": 0.0029,
      "step": 27500
    },
    {
      "epoch": 2.347469920641693,
      "grad_norm": 0.19510817527770996,
      "learning_rate": 3.826265039679154e-05,
      "loss": 0.0021,
      "step": 27510
    },
    {
      "epoch": 2.3483232357709705,
      "grad_norm": 0.15749987959861755,
      "learning_rate": 3.825838382114515e-05,
      "loss": 0.0026,
      "step": 27520
    },
    {
      "epoch": 2.3491765509002476,
      "grad_norm": 0.04737067222595215,
      "learning_rate": 3.825411724549877e-05,
      "loss": 0.0018,
      "step": 27530
    },
    {
      "epoch": 2.3500298660295247,
      "grad_norm": 0.3625374734401703,
      "learning_rate": 3.8249850669852375e-05,
      "loss": 0.0031,
      "step": 27540
    },
    {
      "epoch": 2.350883181158802,
      "grad_norm": 0.03903045505285263,
      "learning_rate": 3.8245584094205996e-05,
      "loss": 0.0022,
      "step": 27550
    },
    {
      "epoch": 2.3517364962880793,
      "grad_norm": 0.14805079996585846,
      "learning_rate": 3.8241317518559604e-05,
      "loss": 0.002,
      "step": 27560
    },
    {
      "epoch": 2.3525898114173565,
      "grad_norm": 0.4368502199649811,
      "learning_rate": 3.8237050942913225e-05,
      "loss": 0.0027,
      "step": 27570
    },
    {
      "epoch": 2.3534431265466336,
      "grad_norm": 0.1394471675157547,
      "learning_rate": 3.823278436726683e-05,
      "loss": 0.003,
      "step": 27580
    },
    {
      "epoch": 2.3542964416759107,
      "grad_norm": 0.18553394079208374,
      "learning_rate": 3.8228517791620446e-05,
      "loss": 0.0024,
      "step": 27590
    },
    {
      "epoch": 2.3551497568051882,
      "grad_norm": 0.10248397290706635,
      "learning_rate": 3.822425121597406e-05,
      "loss": 0.0024,
      "step": 27600
    },
    {
      "epoch": 2.3560030719344653,
      "grad_norm": 0.0778321921825409,
      "learning_rate": 3.8219984640327675e-05,
      "loss": 0.0017,
      "step": 27610
    },
    {
      "epoch": 2.3568563870637425,
      "grad_norm": 0.33991867303848267,
      "learning_rate": 3.821571806468129e-05,
      "loss": 0.0022,
      "step": 27620
    },
    {
      "epoch": 2.35770970219302,
      "grad_norm": 0.09903638064861298,
      "learning_rate": 3.82114514890349e-05,
      "loss": 0.0023,
      "step": 27630
    },
    {
      "epoch": 2.358563017322297,
      "grad_norm": 0.03841100633144379,
      "learning_rate": 3.820718491338852e-05,
      "loss": 0.0023,
      "step": 27640
    },
    {
      "epoch": 2.3594163324515742,
      "grad_norm": 0.34828224778175354,
      "learning_rate": 3.8202918337742125e-05,
      "loss": 0.0022,
      "step": 27650
    },
    {
      "epoch": 2.360269647580852,
      "grad_norm": 0.058635469526052475,
      "learning_rate": 3.8198651762095746e-05,
      "loss": 0.0023,
      "step": 27660
    },
    {
      "epoch": 2.361122962710129,
      "grad_norm": 0.20700596272945404,
      "learning_rate": 3.8194385186449354e-05,
      "loss": 0.0024,
      "step": 27670
    },
    {
      "epoch": 2.361976277839406,
      "grad_norm": 0.09767183661460876,
      "learning_rate": 3.8190118610802975e-05,
      "loss": 0.0019,
      "step": 27680
    },
    {
      "epoch": 2.3628295929686836,
      "grad_norm": 0.30284279584884644,
      "learning_rate": 3.818585203515658e-05,
      "loss": 0.002,
      "step": 27690
    },
    {
      "epoch": 2.3636829080979607,
      "grad_norm": 0.031302183866500854,
      "learning_rate": 3.8181585459510196e-05,
      "loss": 0.0022,
      "step": 27700
    },
    {
      "epoch": 2.3645362232272378,
      "grad_norm": 0.34208643436431885,
      "learning_rate": 3.817731888386381e-05,
      "loss": 0.0019,
      "step": 27710
    },
    {
      "epoch": 2.365389538356515,
      "grad_norm": 0.04478836804628372,
      "learning_rate": 3.8173052308217425e-05,
      "loss": 0.0021,
      "step": 27720
    },
    {
      "epoch": 2.3662428534857924,
      "grad_norm": 0.44636988639831543,
      "learning_rate": 3.816878573257104e-05,
      "loss": 0.0019,
      "step": 27730
    },
    {
      "epoch": 2.3670961686150696,
      "grad_norm": 0.1222357377409935,
      "learning_rate": 3.816451915692465e-05,
      "loss": 0.0022,
      "step": 27740
    },
    {
      "epoch": 2.3679494837443467,
      "grad_norm": 0.5409729480743408,
      "learning_rate": 3.816025258127827e-05,
      "loss": 0.0024,
      "step": 27750
    },
    {
      "epoch": 2.368802798873624,
      "grad_norm": 0.08995018154382706,
      "learning_rate": 3.815598600563188e-05,
      "loss": 0.0021,
      "step": 27760
    },
    {
      "epoch": 2.3696561140029013,
      "grad_norm": 0.07199706137180328,
      "learning_rate": 3.8151719429985496e-05,
      "loss": 0.0026,
      "step": 27770
    },
    {
      "epoch": 2.3705094291321784,
      "grad_norm": 0.30144333839416504,
      "learning_rate": 3.814745285433911e-05,
      "loss": 0.0023,
      "step": 27780
    },
    {
      "epoch": 2.3713627442614555,
      "grad_norm": 0.5261293053627014,
      "learning_rate": 3.8143186278692724e-05,
      "loss": 0.0022,
      "step": 27790
    },
    {
      "epoch": 2.372216059390733,
      "grad_norm": 0.06413111835718155,
      "learning_rate": 3.813891970304634e-05,
      "loss": 0.0019,
      "step": 27800
    },
    {
      "epoch": 2.37306937452001,
      "grad_norm": 0.049310971051454544,
      "learning_rate": 3.813465312739995e-05,
      "loss": 0.002,
      "step": 27810
    },
    {
      "epoch": 2.3739226896492873,
      "grad_norm": 0.42395129799842834,
      "learning_rate": 3.813038655175357e-05,
      "loss": 0.0023,
      "step": 27820
    },
    {
      "epoch": 2.374776004778565,
      "grad_norm": 0.13294625282287598,
      "learning_rate": 3.8126119976107175e-05,
      "loss": 0.0017,
      "step": 27830
    },
    {
      "epoch": 2.375629319907842,
      "grad_norm": 0.06805736571550369,
      "learning_rate": 3.8121853400460796e-05,
      "loss": 0.0026,
      "step": 27840
    },
    {
      "epoch": 2.376482635037119,
      "grad_norm": 0.22668780386447906,
      "learning_rate": 3.81175868248144e-05,
      "loss": 0.0025,
      "step": 27850
    },
    {
      "epoch": 2.3773359501663966,
      "grad_norm": 0.022373143583536148,
      "learning_rate": 3.8113320249168024e-05,
      "loss": 0.0026,
      "step": 27860
    },
    {
      "epoch": 2.3781892652956738,
      "grad_norm": 0.5598987936973572,
      "learning_rate": 3.810905367352163e-05,
      "loss": 0.0021,
      "step": 27870
    },
    {
      "epoch": 2.379042580424951,
      "grad_norm": 0.1382228136062622,
      "learning_rate": 3.810478709787525e-05,
      "loss": 0.0025,
      "step": 27880
    },
    {
      "epoch": 2.3798958955542284,
      "grad_norm": 0.3545669913291931,
      "learning_rate": 3.810052052222886e-05,
      "loss": 0.002,
      "step": 27890
    },
    {
      "epoch": 2.3807492106835055,
      "grad_norm": 0.17163985967636108,
      "learning_rate": 3.8096253946582474e-05,
      "loss": 0.0027,
      "step": 27900
    },
    {
      "epoch": 2.3816025258127826,
      "grad_norm": 0.03652465343475342,
      "learning_rate": 3.809198737093609e-05,
      "loss": 0.003,
      "step": 27910
    },
    {
      "epoch": 2.3824558409420598,
      "grad_norm": 0.13242121040821075,
      "learning_rate": 3.80877207952897e-05,
      "loss": 0.0019,
      "step": 27920
    },
    {
      "epoch": 2.3833091560713373,
      "grad_norm": 0.07509037107229233,
      "learning_rate": 3.808345421964332e-05,
      "loss": 0.0017,
      "step": 27930
    },
    {
      "epoch": 2.3841624712006144,
      "grad_norm": 0.13014544546604156,
      "learning_rate": 3.8079187643996924e-05,
      "loss": 0.002,
      "step": 27940
    },
    {
      "epoch": 2.3850157863298915,
      "grad_norm": 0.2171444594860077,
      "learning_rate": 3.8074921068350546e-05,
      "loss": 0.0023,
      "step": 27950
    },
    {
      "epoch": 2.3858691014591686,
      "grad_norm": 0.24730968475341797,
      "learning_rate": 3.807065449270415e-05,
      "loss": 0.0026,
      "step": 27960
    },
    {
      "epoch": 2.386722416588446,
      "grad_norm": 0.06177316606044769,
      "learning_rate": 3.8066387917057774e-05,
      "loss": 0.0018,
      "step": 27970
    },
    {
      "epoch": 2.3875757317177233,
      "grad_norm": 0.30885788798332214,
      "learning_rate": 3.806212134141138e-05,
      "loss": 0.0029,
      "step": 27980
    },
    {
      "epoch": 2.3884290468470004,
      "grad_norm": 0.07714657485485077,
      "learning_rate": 3.8057854765765e-05,
      "loss": 0.0019,
      "step": 27990
    },
    {
      "epoch": 2.389282361976278,
      "grad_norm": 0.03932234272360802,
      "learning_rate": 3.805358819011861e-05,
      "loss": 0.002,
      "step": 28000
    },
    {
      "epoch": 2.390135677105555,
      "grad_norm": 0.21115879714488983,
      "learning_rate": 3.8049321614472224e-05,
      "loss": 0.002,
      "step": 28010
    },
    {
      "epoch": 2.390988992234832,
      "grad_norm": 0.2034466713666916,
      "learning_rate": 3.804505503882584e-05,
      "loss": 0.002,
      "step": 28020
    },
    {
      "epoch": 2.3918423073641097,
      "grad_norm": 0.3143330514431,
      "learning_rate": 3.804078846317945e-05,
      "loss": 0.0024,
      "step": 28030
    },
    {
      "epoch": 2.392695622493387,
      "grad_norm": 0.07734040915966034,
      "learning_rate": 3.803652188753307e-05,
      "loss": 0.0023,
      "step": 28040
    },
    {
      "epoch": 2.393548937622664,
      "grad_norm": 0.3725058436393738,
      "learning_rate": 3.803225531188668e-05,
      "loss": 0.0022,
      "step": 28050
    },
    {
      "epoch": 2.3944022527519415,
      "grad_norm": 0.1145525574684143,
      "learning_rate": 3.8027988736240295e-05,
      "loss": 0.0021,
      "step": 28060
    },
    {
      "epoch": 2.3952555678812186,
      "grad_norm": 0.06858613342046738,
      "learning_rate": 3.802372216059391e-05,
      "loss": 0.0028,
      "step": 28070
    },
    {
      "epoch": 2.3961088830104957,
      "grad_norm": 0.10295864939689636,
      "learning_rate": 3.8019455584947524e-05,
      "loss": 0.0025,
      "step": 28080
    },
    {
      "epoch": 2.396962198139773,
      "grad_norm": 0.16819679737091064,
      "learning_rate": 3.801518900930114e-05,
      "loss": 0.0027,
      "step": 28090
    },
    {
      "epoch": 2.3978155132690504,
      "grad_norm": 0.4545897841453552,
      "learning_rate": 3.801092243365475e-05,
      "loss": 0.0019,
      "step": 28100
    },
    {
      "epoch": 2.3986688283983275,
      "grad_norm": 0.10708700865507126,
      "learning_rate": 3.8006655858008367e-05,
      "loss": 0.002,
      "step": 28110
    },
    {
      "epoch": 2.3995221435276046,
      "grad_norm": 0.4063265323638916,
      "learning_rate": 3.800238928236198e-05,
      "loss": 0.0019,
      "step": 28120
    },
    {
      "epoch": 2.400375458656882,
      "grad_norm": 0.3216136693954468,
      "learning_rate": 3.7998122706715595e-05,
      "loss": 0.0027,
      "step": 28130
    },
    {
      "epoch": 2.4012287737861593,
      "grad_norm": 0.06066273897886276,
      "learning_rate": 3.79938561310692e-05,
      "loss": 0.0022,
      "step": 28140
    },
    {
      "epoch": 2.4020820889154364,
      "grad_norm": 0.03926296532154083,
      "learning_rate": 3.7989589555422824e-05,
      "loss": 0.0021,
      "step": 28150
    },
    {
      "epoch": 2.4029354040447135,
      "grad_norm": 0.07829215377569199,
      "learning_rate": 3.798532297977643e-05,
      "loss": 0.0018,
      "step": 28160
    },
    {
      "epoch": 2.403788719173991,
      "grad_norm": 0.22245605289936066,
      "learning_rate": 3.7981056404130045e-05,
      "loss": 0.0022,
      "step": 28170
    },
    {
      "epoch": 2.404642034303268,
      "grad_norm": 0.10444983094930649,
      "learning_rate": 3.797678982848366e-05,
      "loss": 0.0017,
      "step": 28180
    },
    {
      "epoch": 2.4054953494325453,
      "grad_norm": 0.46952682733535767,
      "learning_rate": 3.7972523252837274e-05,
      "loss": 0.0019,
      "step": 28190
    },
    {
      "epoch": 2.406348664561823,
      "grad_norm": 0.3964311480522156,
      "learning_rate": 3.796825667719089e-05,
      "loss": 0.0028,
      "step": 28200
    },
    {
      "epoch": 2.4072019796911,
      "grad_norm": 0.5177627205848694,
      "learning_rate": 3.79639901015445e-05,
      "loss": 0.0019,
      "step": 28210
    },
    {
      "epoch": 2.408055294820377,
      "grad_norm": 0.4549507200717926,
      "learning_rate": 3.7959723525898116e-05,
      "loss": 0.0018,
      "step": 28220
    },
    {
      "epoch": 2.4089086099496546,
      "grad_norm": 0.4527059495449066,
      "learning_rate": 3.795545695025173e-05,
      "loss": 0.002,
      "step": 28230
    },
    {
      "epoch": 2.4097619250789317,
      "grad_norm": 0.12903791666030884,
      "learning_rate": 3.7951190374605345e-05,
      "loss": 0.0027,
      "step": 28240
    },
    {
      "epoch": 2.410615240208209,
      "grad_norm": 0.4086553156375885,
      "learning_rate": 3.794692379895895e-05,
      "loss": 0.0017,
      "step": 28250
    },
    {
      "epoch": 2.411468555337486,
      "grad_norm": 0.07762927561998367,
      "learning_rate": 3.7942657223312573e-05,
      "loss": 0.0025,
      "step": 28260
    },
    {
      "epoch": 2.4123218704667635,
      "grad_norm": 0.30202516913414,
      "learning_rate": 3.793839064766618e-05,
      "loss": 0.0017,
      "step": 28270
    },
    {
      "epoch": 2.4131751855960406,
      "grad_norm": 0.5136763453483582,
      "learning_rate": 3.79341240720198e-05,
      "loss": 0.0024,
      "step": 28280
    },
    {
      "epoch": 2.4140285007253177,
      "grad_norm": 0.07327743619680405,
      "learning_rate": 3.792985749637341e-05,
      "loss": 0.002,
      "step": 28290
    },
    {
      "epoch": 2.4148818158545953,
      "grad_norm": 0.04513033479452133,
      "learning_rate": 3.792559092072703e-05,
      "loss": 0.0028,
      "step": 28300
    },
    {
      "epoch": 2.4157351309838724,
      "grad_norm": 0.0960562601685524,
      "learning_rate": 3.792132434508064e-05,
      "loss": 0.0021,
      "step": 28310
    },
    {
      "epoch": 2.4165884461131495,
      "grad_norm": 0.0577688030898571,
      "learning_rate": 3.791705776943425e-05,
      "loss": 0.0021,
      "step": 28320
    },
    {
      "epoch": 2.4174417612424266,
      "grad_norm": 0.1078423410654068,
      "learning_rate": 3.7912791193787866e-05,
      "loss": 0.0019,
      "step": 28330
    },
    {
      "epoch": 2.418295076371704,
      "grad_norm": 0.5196699500083923,
      "learning_rate": 3.790852461814148e-05,
      "loss": 0.0019,
      "step": 28340
    },
    {
      "epoch": 2.4191483915009813,
      "grad_norm": 0.20219802856445312,
      "learning_rate": 3.7904258042495095e-05,
      "loss": 0.0016,
      "step": 28350
    },
    {
      "epoch": 2.4200017066302584,
      "grad_norm": 0.27804797887802124,
      "learning_rate": 3.789999146684871e-05,
      "loss": 0.002,
      "step": 28360
    },
    {
      "epoch": 2.420855021759536,
      "grad_norm": 0.15042750537395477,
      "learning_rate": 3.789572489120232e-05,
      "loss": 0.0023,
      "step": 28370
    },
    {
      "epoch": 2.421708336888813,
      "grad_norm": 0.12134117633104324,
      "learning_rate": 3.789145831555594e-05,
      "loss": 0.0019,
      "step": 28380
    },
    {
      "epoch": 2.42256165201809,
      "grad_norm": 0.22093512117862701,
      "learning_rate": 3.788719173990955e-05,
      "loss": 0.0025,
      "step": 28390
    },
    {
      "epoch": 2.4234149671473677,
      "grad_norm": 0.1662173867225647,
      "learning_rate": 3.7882925164263166e-05,
      "loss": 0.0019,
      "step": 28400
    },
    {
      "epoch": 2.424268282276645,
      "grad_norm": 0.29690155386924744,
      "learning_rate": 3.787865858861678e-05,
      "loss": 0.0029,
      "step": 28410
    },
    {
      "epoch": 2.425121597405922,
      "grad_norm": 0.3586854636669159,
      "learning_rate": 3.7874392012970395e-05,
      "loss": 0.0022,
      "step": 28420
    },
    {
      "epoch": 2.4259749125351995,
      "grad_norm": 0.296391099691391,
      "learning_rate": 3.787012543732401e-05,
      "loss": 0.0021,
      "step": 28430
    },
    {
      "epoch": 2.4268282276644766,
      "grad_norm": 0.03336765989661217,
      "learning_rate": 3.7865858861677616e-05,
      "loss": 0.0015,
      "step": 28440
    },
    {
      "epoch": 2.4276815427937537,
      "grad_norm": 0.1343071460723877,
      "learning_rate": 3.786159228603123e-05,
      "loss": 0.0018,
      "step": 28450
    },
    {
      "epoch": 2.428534857923031,
      "grad_norm": 0.2093832939863205,
      "learning_rate": 3.7857325710384845e-05,
      "loss": 0.003,
      "step": 28460
    },
    {
      "epoch": 2.4293881730523084,
      "grad_norm": 0.21813109517097473,
      "learning_rate": 3.785305913473846e-05,
      "loss": 0.002,
      "step": 28470
    },
    {
      "epoch": 2.4302414881815855,
      "grad_norm": 0.3088276982307434,
      "learning_rate": 3.784879255909207e-05,
      "loss": 0.0024,
      "step": 28480
    },
    {
      "epoch": 2.4310948033108626,
      "grad_norm": 0.3218127191066742,
      "learning_rate": 3.784452598344569e-05,
      "loss": 0.0022,
      "step": 28490
    },
    {
      "epoch": 2.4319481184401397,
      "grad_norm": 0.36936670541763306,
      "learning_rate": 3.78402594077993e-05,
      "loss": 0.0024,
      "step": 28500
    },
    {
      "epoch": 2.4328014335694172,
      "grad_norm": 0.30383777618408203,
      "learning_rate": 3.7835992832152916e-05,
      "loss": 0.0022,
      "step": 28510
    },
    {
      "epoch": 2.4336547486986944,
      "grad_norm": 0.10271891951560974,
      "learning_rate": 3.783172625650653e-05,
      "loss": 0.0019,
      "step": 28520
    },
    {
      "epoch": 2.4345080638279715,
      "grad_norm": 0.20349620282649994,
      "learning_rate": 3.7827459680860144e-05,
      "loss": 0.002,
      "step": 28530
    },
    {
      "epoch": 2.435361378957249,
      "grad_norm": 0.301155686378479,
      "learning_rate": 3.782319310521376e-05,
      "loss": 0.0019,
      "step": 28540
    },
    {
      "epoch": 2.436214694086526,
      "grad_norm": 0.059229593724012375,
      "learning_rate": 3.781892652956737e-05,
      "loss": 0.0019,
      "step": 28550
    },
    {
      "epoch": 2.4370680092158032,
      "grad_norm": 0.08355780690908432,
      "learning_rate": 3.781465995392098e-05,
      "loss": 0.0015,
      "step": 28560
    },
    {
      "epoch": 2.437921324345081,
      "grad_norm": 0.16754426062107086,
      "learning_rate": 3.78103933782746e-05,
      "loss": 0.0014,
      "step": 28570
    },
    {
      "epoch": 2.438774639474358,
      "grad_norm": 0.04756222665309906,
      "learning_rate": 3.780612680262821e-05,
      "loss": 0.0021,
      "step": 28580
    },
    {
      "epoch": 2.439627954603635,
      "grad_norm": 0.4537409245967865,
      "learning_rate": 3.780186022698183e-05,
      "loss": 0.0026,
      "step": 28590
    },
    {
      "epoch": 2.4404812697329126,
      "grad_norm": 0.052081190049648285,
      "learning_rate": 3.779759365133544e-05,
      "loss": 0.0027,
      "step": 28600
    },
    {
      "epoch": 2.4413345848621897,
      "grad_norm": 0.6491227149963379,
      "learning_rate": 3.779332707568906e-05,
      "loss": 0.0023,
      "step": 28610
    },
    {
      "epoch": 2.442187899991467,
      "grad_norm": 0.24270859360694885,
      "learning_rate": 3.7789060500042666e-05,
      "loss": 0.0025,
      "step": 28620
    },
    {
      "epoch": 2.443041215120744,
      "grad_norm": 0.3629612326622009,
      "learning_rate": 3.778479392439629e-05,
      "loss": 0.0024,
      "step": 28630
    },
    {
      "epoch": 2.4438945302500215,
      "grad_norm": 0.19022490084171295,
      "learning_rate": 3.7780527348749894e-05,
      "loss": 0.0024,
      "step": 28640
    },
    {
      "epoch": 2.4447478453792986,
      "grad_norm": 0.06105520576238632,
      "learning_rate": 3.777626077310351e-05,
      "loss": 0.0025,
      "step": 28650
    },
    {
      "epoch": 2.4456011605085757,
      "grad_norm": 0.09659907966852188,
      "learning_rate": 3.777199419745712e-05,
      "loss": 0.0029,
      "step": 28660
    },
    {
      "epoch": 2.4464544756378532,
      "grad_norm": 0.03669864311814308,
      "learning_rate": 3.776772762181074e-05,
      "loss": 0.0022,
      "step": 28670
    },
    {
      "epoch": 2.4473077907671303,
      "grad_norm": 0.22775784134864807,
      "learning_rate": 3.776346104616435e-05,
      "loss": 0.0015,
      "step": 28680
    },
    {
      "epoch": 2.4481611058964075,
      "grad_norm": 0.12058483809232712,
      "learning_rate": 3.7759194470517965e-05,
      "loss": 0.0022,
      "step": 28690
    },
    {
      "epoch": 2.4490144210256846,
      "grad_norm": 0.06232067942619324,
      "learning_rate": 3.775492789487158e-05,
      "loss": 0.0026,
      "step": 28700
    },
    {
      "epoch": 2.449867736154962,
      "grad_norm": 0.04877572879195213,
      "learning_rate": 3.775066131922519e-05,
      "loss": 0.0021,
      "step": 28710
    },
    {
      "epoch": 2.4507210512842392,
      "grad_norm": 0.048878736793994904,
      "learning_rate": 3.774639474357881e-05,
      "loss": 0.0022,
      "step": 28720
    },
    {
      "epoch": 2.4515743664135163,
      "grad_norm": 0.023898879066109657,
      "learning_rate": 3.7742128167932416e-05,
      "loss": 0.0022,
      "step": 28730
    },
    {
      "epoch": 2.452427681542794,
      "grad_norm": 0.05971705913543701,
      "learning_rate": 3.773786159228604e-05,
      "loss": 0.0027,
      "step": 28740
    },
    {
      "epoch": 2.453280996672071,
      "grad_norm": 0.2496204972267151,
      "learning_rate": 3.7733595016639644e-05,
      "loss": 0.0018,
      "step": 28750
    },
    {
      "epoch": 2.454134311801348,
      "grad_norm": 0.045462049543857574,
      "learning_rate": 3.772932844099326e-05,
      "loss": 0.0024,
      "step": 28760
    },
    {
      "epoch": 2.4549876269306257,
      "grad_norm": 0.18710090219974518,
      "learning_rate": 3.772506186534687e-05,
      "loss": 0.0027,
      "step": 28770
    },
    {
      "epoch": 2.4558409420599028,
      "grad_norm": 0.13415373861789703,
      "learning_rate": 3.772079528970049e-05,
      "loss": 0.0019,
      "step": 28780
    },
    {
      "epoch": 2.45669425718918,
      "grad_norm": 0.044738758355379105,
      "learning_rate": 3.77165287140541e-05,
      "loss": 0.0017,
      "step": 28790
    },
    {
      "epoch": 2.4575475723184574,
      "grad_norm": 0.3142130374908447,
      "learning_rate": 3.7712262138407715e-05,
      "loss": 0.0022,
      "step": 28800
    },
    {
      "epoch": 2.4584008874477346,
      "grad_norm": 0.3367530107498169,
      "learning_rate": 3.770799556276133e-05,
      "loss": 0.0028,
      "step": 28810
    },
    {
      "epoch": 2.4592542025770117,
      "grad_norm": 0.04566708952188492,
      "learning_rate": 3.7703728987114944e-05,
      "loss": 0.0025,
      "step": 28820
    },
    {
      "epoch": 2.4601075177062888,
      "grad_norm": 0.35470911860466003,
      "learning_rate": 3.769946241146856e-05,
      "loss": 0.0029,
      "step": 28830
    },
    {
      "epoch": 2.4609608328355663,
      "grad_norm": 0.2843402624130249,
      "learning_rate": 3.769519583582217e-05,
      "loss": 0.0021,
      "step": 28840
    },
    {
      "epoch": 2.4618141479648434,
      "grad_norm": 0.06116320565342903,
      "learning_rate": 3.7690929260175787e-05,
      "loss": 0.0025,
      "step": 28850
    },
    {
      "epoch": 2.4626674630941205,
      "grad_norm": 0.0855535939335823,
      "learning_rate": 3.76866626845294e-05,
      "loss": 0.0026,
      "step": 28860
    },
    {
      "epoch": 2.4635207782233977,
      "grad_norm": 0.09718687832355499,
      "learning_rate": 3.768239610888301e-05,
      "loss": 0.0021,
      "step": 28870
    },
    {
      "epoch": 2.464374093352675,
      "grad_norm": 0.06183338537812233,
      "learning_rate": 3.767812953323663e-05,
      "loss": 0.0025,
      "step": 28880
    },
    {
      "epoch": 2.4652274084819523,
      "grad_norm": 0.5184547901153564,
      "learning_rate": 3.767386295759024e-05,
      "loss": 0.0024,
      "step": 28890
    },
    {
      "epoch": 2.4660807236112294,
      "grad_norm": 0.25117504596710205,
      "learning_rate": 3.766959638194386e-05,
      "loss": 0.0019,
      "step": 28900
    },
    {
      "epoch": 2.466934038740507,
      "grad_norm": 0.09251142293214798,
      "learning_rate": 3.7665329806297465e-05,
      "loss": 0.0024,
      "step": 28910
    },
    {
      "epoch": 2.467787353869784,
      "grad_norm": 0.07941772788763046,
      "learning_rate": 3.7661063230651086e-05,
      "loss": 0.0023,
      "step": 28920
    },
    {
      "epoch": 2.468640668999061,
      "grad_norm": 0.14947879314422607,
      "learning_rate": 3.7656796655004694e-05,
      "loss": 0.002,
      "step": 28930
    },
    {
      "epoch": 2.4694939841283388,
      "grad_norm": 0.17851100862026215,
      "learning_rate": 3.7652530079358315e-05,
      "loss": 0.0025,
      "step": 28940
    },
    {
      "epoch": 2.470347299257616,
      "grad_norm": 0.33341047167778015,
      "learning_rate": 3.764826350371192e-05,
      "loss": 0.0022,
      "step": 28950
    },
    {
      "epoch": 2.471200614386893,
      "grad_norm": 0.11761800199747086,
      "learning_rate": 3.7643996928065536e-05,
      "loss": 0.002,
      "step": 28960
    },
    {
      "epoch": 2.4720539295161705,
      "grad_norm": 0.23272493481636047,
      "learning_rate": 3.763973035241915e-05,
      "loss": 0.0025,
      "step": 28970
    },
    {
      "epoch": 2.4729072446454476,
      "grad_norm": 0.060428183525800705,
      "learning_rate": 3.763546377677276e-05,
      "loss": 0.0018,
      "step": 28980
    },
    {
      "epoch": 2.4737605597747248,
      "grad_norm": 0.04653133451938629,
      "learning_rate": 3.763119720112638e-05,
      "loss": 0.002,
      "step": 28990
    },
    {
      "epoch": 2.474613874904002,
      "grad_norm": 0.39961010217666626,
      "learning_rate": 3.7626930625479987e-05,
      "loss": 0.0026,
      "step": 29000
    },
    {
      "epoch": 2.4754671900332794,
      "grad_norm": 0.14961495995521545,
      "learning_rate": 3.762266404983361e-05,
      "loss": 0.0019,
      "step": 29010
    },
    {
      "epoch": 2.4763205051625565,
      "grad_norm": 0.21005111932754517,
      "learning_rate": 3.7618397474187215e-05,
      "loss": 0.0017,
      "step": 29020
    },
    {
      "epoch": 2.4771738202918336,
      "grad_norm": 0.0283658429980278,
      "learning_rate": 3.7614130898540836e-05,
      "loss": 0.002,
      "step": 29030
    },
    {
      "epoch": 2.478027135421111,
      "grad_norm": 0.03271662816405296,
      "learning_rate": 3.7609864322894444e-05,
      "loss": 0.0027,
      "step": 29040
    },
    {
      "epoch": 2.4788804505503883,
      "grad_norm": 0.4643169343471527,
      "learning_rate": 3.7605597747248065e-05,
      "loss": 0.0018,
      "step": 29050
    },
    {
      "epoch": 2.4797337656796654,
      "grad_norm": 0.09695649147033691,
      "learning_rate": 3.760133117160167e-05,
      "loss": 0.0018,
      "step": 29060
    },
    {
      "epoch": 2.4805870808089425,
      "grad_norm": 0.2857741713523865,
      "learning_rate": 3.7597064595955286e-05,
      "loss": 0.002,
      "step": 29070
    },
    {
      "epoch": 2.48144039593822,
      "grad_norm": 0.17164908349514008,
      "learning_rate": 3.75927980203089e-05,
      "loss": 0.0021,
      "step": 29080
    },
    {
      "epoch": 2.482293711067497,
      "grad_norm": 0.22442200779914856,
      "learning_rate": 3.7588531444662515e-05,
      "loss": 0.0027,
      "step": 29090
    },
    {
      "epoch": 2.4831470261967743,
      "grad_norm": 0.20688094198703766,
      "learning_rate": 3.758426486901613e-05,
      "loss": 0.0023,
      "step": 29100
    },
    {
      "epoch": 2.484000341326052,
      "grad_norm": 0.17986726760864258,
      "learning_rate": 3.757999829336974e-05,
      "loss": 0.0022,
      "step": 29110
    },
    {
      "epoch": 2.484853656455329,
      "grad_norm": 0.30115631222724915,
      "learning_rate": 3.757573171772336e-05,
      "loss": 0.0019,
      "step": 29120
    },
    {
      "epoch": 2.485706971584606,
      "grad_norm": 0.3355522155761719,
      "learning_rate": 3.757146514207697e-05,
      "loss": 0.0019,
      "step": 29130
    },
    {
      "epoch": 2.4865602867138836,
      "grad_norm": 0.37072721123695374,
      "learning_rate": 3.7567198566430586e-05,
      "loss": 0.0031,
      "step": 29140
    },
    {
      "epoch": 2.4874136018431607,
      "grad_norm": 0.21795706450939178,
      "learning_rate": 3.75629319907842e-05,
      "loss": 0.0022,
      "step": 29150
    },
    {
      "epoch": 2.488266916972438,
      "grad_norm": 0.17133967578411102,
      "learning_rate": 3.7558665415137814e-05,
      "loss": 0.0021,
      "step": 29160
    },
    {
      "epoch": 2.4891202321017154,
      "grad_norm": 0.23005899786949158,
      "learning_rate": 3.755439883949143e-05,
      "loss": 0.0028,
      "step": 29170
    },
    {
      "epoch": 2.4899735472309925,
      "grad_norm": 0.08129248768091202,
      "learning_rate": 3.7550132263845036e-05,
      "loss": 0.0018,
      "step": 29180
    },
    {
      "epoch": 2.4908268623602696,
      "grad_norm": 0.05169238522648811,
      "learning_rate": 3.754586568819866e-05,
      "loss": 0.002,
      "step": 29190
    },
    {
      "epoch": 2.4916801774895467,
      "grad_norm": 0.0466427356004715,
      "learning_rate": 3.7541599112552265e-05,
      "loss": 0.0025,
      "step": 29200
    },
    {
      "epoch": 2.4925334926188243,
      "grad_norm": 0.22515057027339935,
      "learning_rate": 3.7537332536905886e-05,
      "loss": 0.0022,
      "step": 29210
    },
    {
      "epoch": 2.4933868077481014,
      "grad_norm": 0.2327604442834854,
      "learning_rate": 3.753306596125949e-05,
      "loss": 0.0018,
      "step": 29220
    },
    {
      "epoch": 2.4942401228773785,
      "grad_norm": 0.19234663248062134,
      "learning_rate": 3.7528799385613114e-05,
      "loss": 0.0017,
      "step": 29230
    },
    {
      "epoch": 2.4950934380066556,
      "grad_norm": 0.2259056121110916,
      "learning_rate": 3.752453280996672e-05,
      "loss": 0.0021,
      "step": 29240
    },
    {
      "epoch": 2.495946753135933,
      "grad_norm": 0.2930487394332886,
      "learning_rate": 3.7520266234320336e-05,
      "loss": 0.0018,
      "step": 29250
    },
    {
      "epoch": 2.4968000682652103,
      "grad_norm": 0.2880510091781616,
      "learning_rate": 3.751599965867395e-05,
      "loss": 0.002,
      "step": 29260
    },
    {
      "epoch": 2.4976533833944874,
      "grad_norm": 0.19112281501293182,
      "learning_rate": 3.7511733083027564e-05,
      "loss": 0.0023,
      "step": 29270
    },
    {
      "epoch": 2.498506698523765,
      "grad_norm": 0.3374229371547699,
      "learning_rate": 3.750746650738118e-05,
      "loss": 0.0019,
      "step": 29280
    },
    {
      "epoch": 2.499360013653042,
      "grad_norm": 0.5198878049850464,
      "learning_rate": 3.7503199931734786e-05,
      "loss": 0.0017,
      "step": 29290
    },
    {
      "epoch": 2.500213328782319,
      "grad_norm": 0.09832500666379929,
      "learning_rate": 3.749893335608841e-05,
      "loss": 0.0031,
      "step": 29300
    },
    {
      "epoch": 2.5010666439115967,
      "grad_norm": 0.32050821185112,
      "learning_rate": 3.7494666780442015e-05,
      "loss": 0.0028,
      "step": 29310
    },
    {
      "epoch": 2.501919959040874,
      "grad_norm": 0.46943217515945435,
      "learning_rate": 3.7490400204795636e-05,
      "loss": 0.0023,
      "step": 29320
    },
    {
      "epoch": 2.502773274170151,
      "grad_norm": 0.13757602870464325,
      "learning_rate": 3.748613362914924e-05,
      "loss": 0.0023,
      "step": 29330
    },
    {
      "epoch": 2.5036265892994285,
      "grad_norm": 0.16677889227867126,
      "learning_rate": 3.7481867053502864e-05,
      "loss": 0.002,
      "step": 29340
    },
    {
      "epoch": 2.5044799044287056,
      "grad_norm": 0.18867376446723938,
      "learning_rate": 3.747760047785647e-05,
      "loss": 0.0016,
      "step": 29350
    },
    {
      "epoch": 2.5053332195579827,
      "grad_norm": 0.11965321004390717,
      "learning_rate": 3.747333390221009e-05,
      "loss": 0.0023,
      "step": 29360
    },
    {
      "epoch": 2.5061865346872603,
      "grad_norm": 0.19834086298942566,
      "learning_rate": 3.74690673265637e-05,
      "loss": 0.0014,
      "step": 29370
    },
    {
      "epoch": 2.5070398498165374,
      "grad_norm": 0.04289926588535309,
      "learning_rate": 3.7464800750917314e-05,
      "loss": 0.0023,
      "step": 29380
    },
    {
      "epoch": 2.5078931649458145,
      "grad_norm": 0.207076296210289,
      "learning_rate": 3.746053417527093e-05,
      "loss": 0.0022,
      "step": 29390
    },
    {
      "epoch": 2.5087464800750916,
      "grad_norm": 0.12880702316761017,
      "learning_rate": 3.745626759962454e-05,
      "loss": 0.0021,
      "step": 29400
    },
    {
      "epoch": 2.5095997952043687,
      "grad_norm": 0.15291638672351837,
      "learning_rate": 3.745200102397816e-05,
      "loss": 0.002,
      "step": 29410
    },
    {
      "epoch": 2.5104531103336463,
      "grad_norm": 0.12687870860099792,
      "learning_rate": 3.744773444833177e-05,
      "loss": 0.0025,
      "step": 29420
    },
    {
      "epoch": 2.5113064254629234,
      "grad_norm": 0.339670330286026,
      "learning_rate": 3.7443467872685385e-05,
      "loss": 0.0021,
      "step": 29430
    },
    {
      "epoch": 2.5121597405922005,
      "grad_norm": 0.06126803532242775,
      "learning_rate": 3.7439201297039e-05,
      "loss": 0.0025,
      "step": 29440
    },
    {
      "epoch": 2.513013055721478,
      "grad_norm": 0.05484486743807793,
      "learning_rate": 3.7434934721392614e-05,
      "loss": 0.0023,
      "step": 29450
    },
    {
      "epoch": 2.513866370850755,
      "grad_norm": 0.2052781879901886,
      "learning_rate": 3.743066814574623e-05,
      "loss": 0.002,
      "step": 29460
    },
    {
      "epoch": 2.5147196859800323,
      "grad_norm": 0.374489963054657,
      "learning_rate": 3.742640157009984e-05,
      "loss": 0.003,
      "step": 29470
    },
    {
      "epoch": 2.51557300110931,
      "grad_norm": 0.49072766304016113,
      "learning_rate": 3.742213499445346e-05,
      "loss": 0.0021,
      "step": 29480
    },
    {
      "epoch": 2.516426316238587,
      "grad_norm": 0.15010936558246613,
      "learning_rate": 3.7417868418807064e-05,
      "loss": 0.0028,
      "step": 29490
    },
    {
      "epoch": 2.517279631367864,
      "grad_norm": 0.42832931876182556,
      "learning_rate": 3.741360184316068e-05,
      "loss": 0.0019,
      "step": 29500
    },
    {
      "epoch": 2.5181329464971416,
      "grad_norm": 0.03017854504287243,
      "learning_rate": 3.740933526751429e-05,
      "loss": 0.0018,
      "step": 29510
    },
    {
      "epoch": 2.5189862616264187,
      "grad_norm": 0.04441428184509277,
      "learning_rate": 3.740506869186791e-05,
      "loss": 0.0017,
      "step": 29520
    },
    {
      "epoch": 2.519839576755696,
      "grad_norm": 0.09494016319513321,
      "learning_rate": 3.740080211622152e-05,
      "loss": 0.002,
      "step": 29530
    },
    {
      "epoch": 2.5206928918849734,
      "grad_norm": 0.12454220652580261,
      "learning_rate": 3.7396535540575135e-05,
      "loss": 0.0022,
      "step": 29540
    },
    {
      "epoch": 2.5215462070142505,
      "grad_norm": 0.4573149085044861,
      "learning_rate": 3.739226896492875e-05,
      "loss": 0.0022,
      "step": 29550
    },
    {
      "epoch": 2.5223995221435276,
      "grad_norm": 0.3855910301208496,
      "learning_rate": 3.7388002389282364e-05,
      "loss": 0.0021,
      "step": 29560
    },
    {
      "epoch": 2.5232528372728047,
      "grad_norm": 0.37992262840270996,
      "learning_rate": 3.738373581363598e-05,
      "loss": 0.0023,
      "step": 29570
    },
    {
      "epoch": 2.5241061524020822,
      "grad_norm": 0.1561577171087265,
      "learning_rate": 3.737946923798959e-05,
      "loss": 0.0021,
      "step": 29580
    },
    {
      "epoch": 2.5249594675313594,
      "grad_norm": 0.13689285516738892,
      "learning_rate": 3.7375202662343206e-05,
      "loss": 0.002,
      "step": 29590
    },
    {
      "epoch": 2.5258127826606365,
      "grad_norm": 0.3744323253631592,
      "learning_rate": 3.7370936086696814e-05,
      "loss": 0.0018,
      "step": 29600
    },
    {
      "epoch": 2.5266660977899136,
      "grad_norm": 0.03124585933983326,
      "learning_rate": 3.7366669511050435e-05,
      "loss": 0.0031,
      "step": 29610
    },
    {
      "epoch": 2.527519412919191,
      "grad_norm": 0.18595759570598602,
      "learning_rate": 3.736240293540404e-05,
      "loss": 0.0031,
      "step": 29620
    },
    {
      "epoch": 2.5283727280484682,
      "grad_norm": 0.11753900349140167,
      "learning_rate": 3.7358136359757663e-05,
      "loss": 0.0022,
      "step": 29630
    },
    {
      "epoch": 2.5292260431777454,
      "grad_norm": 0.5162431001663208,
      "learning_rate": 3.735386978411127e-05,
      "loss": 0.0018,
      "step": 29640
    },
    {
      "epoch": 2.530079358307023,
      "grad_norm": 0.15096502006053925,
      "learning_rate": 3.734960320846489e-05,
      "loss": 0.0032,
      "step": 29650
    },
    {
      "epoch": 2.5309326734363,
      "grad_norm": 0.461509644985199,
      "learning_rate": 3.73453366328185e-05,
      "loss": 0.0019,
      "step": 29660
    },
    {
      "epoch": 2.531785988565577,
      "grad_norm": 0.381377637386322,
      "learning_rate": 3.734107005717212e-05,
      "loss": 0.0022,
      "step": 29670
    },
    {
      "epoch": 2.5326393036948547,
      "grad_norm": 0.09880419820547104,
      "learning_rate": 3.733680348152573e-05,
      "loss": 0.0023,
      "step": 29680
    },
    {
      "epoch": 2.533492618824132,
      "grad_norm": 0.2520318329334259,
      "learning_rate": 3.733253690587934e-05,
      "loss": 0.0022,
      "step": 29690
    },
    {
      "epoch": 2.534345933953409,
      "grad_norm": 0.24404339492321014,
      "learning_rate": 3.7328270330232956e-05,
      "loss": 0.0023,
      "step": 29700
    },
    {
      "epoch": 2.5351992490826865,
      "grad_norm": 0.3152948319911957,
      "learning_rate": 3.732400375458657e-05,
      "loss": 0.0023,
      "step": 29710
    },
    {
      "epoch": 2.5360525642119636,
      "grad_norm": 0.3053516447544098,
      "learning_rate": 3.7319737178940185e-05,
      "loss": 0.0025,
      "step": 29720
    },
    {
      "epoch": 2.5369058793412407,
      "grad_norm": 0.1511477380990982,
      "learning_rate": 3.73154706032938e-05,
      "loss": 0.0016,
      "step": 29730
    },
    {
      "epoch": 2.5377591944705182,
      "grad_norm": 0.03330744802951813,
      "learning_rate": 3.731120402764741e-05,
      "loss": 0.002,
      "step": 29740
    },
    {
      "epoch": 2.5386125095997953,
      "grad_norm": 0.11784233152866364,
      "learning_rate": 3.730693745200103e-05,
      "loss": 0.0015,
      "step": 29750
    },
    {
      "epoch": 2.5394658247290725,
      "grad_norm": 0.06317910552024841,
      "learning_rate": 3.730267087635464e-05,
      "loss": 0.0018,
      "step": 29760
    },
    {
      "epoch": 2.5403191398583496,
      "grad_norm": 0.1457044631242752,
      "learning_rate": 3.729840430070825e-05,
      "loss": 0.0024,
      "step": 29770
    },
    {
      "epoch": 2.5411724549876267,
      "grad_norm": 0.07339620590209961,
      "learning_rate": 3.729413772506187e-05,
      "loss": 0.0028,
      "step": 29780
    },
    {
      "epoch": 2.5420257701169042,
      "grad_norm": 0.07755425572395325,
      "learning_rate": 3.728987114941548e-05,
      "loss": 0.002,
      "step": 29790
    },
    {
      "epoch": 2.5428790852461813,
      "grad_norm": 0.07255059480667114,
      "learning_rate": 3.728560457376909e-05,
      "loss": 0.0021,
      "step": 29800
    },
    {
      "epoch": 2.5437324003754584,
      "grad_norm": 0.2709294259548187,
      "learning_rate": 3.7281337998122706e-05,
      "loss": 0.0021,
      "step": 29810
    },
    {
      "epoch": 2.544585715504736,
      "grad_norm": 0.1418612003326416,
      "learning_rate": 3.727707142247632e-05,
      "loss": 0.0021,
      "step": 29820
    },
    {
      "epoch": 2.545439030634013,
      "grad_norm": 0.07721585035324097,
      "learning_rate": 3.7272804846829935e-05,
      "loss": 0.0024,
      "step": 29830
    },
    {
      "epoch": 2.54629234576329,
      "grad_norm": 0.03334592282772064,
      "learning_rate": 3.726853827118355e-05,
      "loss": 0.002,
      "step": 29840
    },
    {
      "epoch": 2.5471456608925678,
      "grad_norm": 0.2979518175125122,
      "learning_rate": 3.726427169553716e-05,
      "loss": 0.0021,
      "step": 29850
    },
    {
      "epoch": 2.547998976021845,
      "grad_norm": 0.43075788021087646,
      "learning_rate": 3.726000511989078e-05,
      "loss": 0.0021,
      "step": 29860
    },
    {
      "epoch": 2.548852291151122,
      "grad_norm": 0.12353360652923584,
      "learning_rate": 3.725573854424439e-05,
      "loss": 0.002,
      "step": 29870
    },
    {
      "epoch": 2.5497056062803996,
      "grad_norm": 0.17517629265785217,
      "learning_rate": 3.7251471968598006e-05,
      "loss": 0.0025,
      "step": 29880
    },
    {
      "epoch": 2.5505589214096767,
      "grad_norm": 0.22253218293190002,
      "learning_rate": 3.724720539295162e-05,
      "loss": 0.0019,
      "step": 29890
    },
    {
      "epoch": 2.5514122365389538,
      "grad_norm": 0.3777340054512024,
      "learning_rate": 3.7242938817305234e-05,
      "loss": 0.0016,
      "step": 29900
    },
    {
      "epoch": 2.5522655516682313,
      "grad_norm": 0.26105326414108276,
      "learning_rate": 3.723867224165884e-05,
      "loss": 0.002,
      "step": 29910
    },
    {
      "epoch": 2.5531188667975084,
      "grad_norm": 0.07794146239757538,
      "learning_rate": 3.723440566601246e-05,
      "loss": 0.0021,
      "step": 29920
    },
    {
      "epoch": 2.5539721819267855,
      "grad_norm": 0.13308244943618774,
      "learning_rate": 3.723013909036607e-05,
      "loss": 0.002,
      "step": 29930
    },
    {
      "epoch": 2.5548254970560627,
      "grad_norm": 0.04546000435948372,
      "learning_rate": 3.722587251471969e-05,
      "loss": 0.0022,
      "step": 29940
    },
    {
      "epoch": 2.55567881218534,
      "grad_norm": 0.03580425679683685,
      "learning_rate": 3.72216059390733e-05,
      "loss": 0.0018,
      "step": 29950
    },
    {
      "epoch": 2.5565321273146173,
      "grad_norm": 0.11421364545822144,
      "learning_rate": 3.721733936342692e-05,
      "loss": 0.0016,
      "step": 29960
    },
    {
      "epoch": 2.5573854424438944,
      "grad_norm": 0.18766218423843384,
      "learning_rate": 3.721307278778053e-05,
      "loss": 0.002,
      "step": 29970
    },
    {
      "epoch": 2.5582387575731715,
      "grad_norm": 0.07547822594642639,
      "learning_rate": 3.720880621213415e-05,
      "loss": 0.003,
      "step": 29980
    },
    {
      "epoch": 2.559092072702449,
      "grad_norm": 0.1900366097688675,
      "learning_rate": 3.7204539636487756e-05,
      "loss": 0.0018,
      "step": 29990
    },
    {
      "epoch": 2.559945387831726,
      "grad_norm": 0.1527690291404724,
      "learning_rate": 3.720027306084137e-05,
      "loss": 0.0025,
      "step": 30000
    },
    {
      "epoch": 2.5607987029610033,
      "grad_norm": 0.06062013655900955,
      "learning_rate": 3.7196006485194984e-05,
      "loss": 0.002,
      "step": 30010
    },
    {
      "epoch": 2.561652018090281,
      "grad_norm": 0.369419127702713,
      "learning_rate": 3.71917399095486e-05,
      "loss": 0.002,
      "step": 30020
    },
    {
      "epoch": 2.562505333219558,
      "grad_norm": 0.1518045961856842,
      "learning_rate": 3.718747333390221e-05,
      "loss": 0.0023,
      "step": 30030
    },
    {
      "epoch": 2.563358648348835,
      "grad_norm": 0.21702004969120026,
      "learning_rate": 3.718320675825582e-05,
      "loss": 0.002,
      "step": 30040
    },
    {
      "epoch": 2.5642119634781126,
      "grad_norm": 0.20254601538181305,
      "learning_rate": 3.717894018260944e-05,
      "loss": 0.002,
      "step": 30050
    },
    {
      "epoch": 2.5650652786073898,
      "grad_norm": 0.20527324080467224,
      "learning_rate": 3.717467360696305e-05,
      "loss": 0.0025,
      "step": 30060
    },
    {
      "epoch": 2.565918593736667,
      "grad_norm": 0.13539935648441315,
      "learning_rate": 3.717040703131667e-05,
      "loss": 0.0024,
      "step": 30070
    },
    {
      "epoch": 2.5667719088659444,
      "grad_norm": 0.11019863933324814,
      "learning_rate": 3.716614045567028e-05,
      "loss": 0.0022,
      "step": 30080
    },
    {
      "epoch": 2.5676252239952215,
      "grad_norm": 0.04680480435490608,
      "learning_rate": 3.71618738800239e-05,
      "loss": 0.0024,
      "step": 30090
    },
    {
      "epoch": 2.5684785391244986,
      "grad_norm": 0.11794717609882355,
      "learning_rate": 3.7157607304377506e-05,
      "loss": 0.0022,
      "step": 30100
    },
    {
      "epoch": 2.569331854253776,
      "grad_norm": 0.2895311415195465,
      "learning_rate": 3.715334072873112e-05,
      "loss": 0.0025,
      "step": 30110
    },
    {
      "epoch": 2.5701851693830533,
      "grad_norm": 0.034032054245471954,
      "learning_rate": 3.7149074153084734e-05,
      "loss": 0.0023,
      "step": 30120
    },
    {
      "epoch": 2.5710384845123304,
      "grad_norm": 0.3529505133628845,
      "learning_rate": 3.714480757743835e-05,
      "loss": 0.003,
      "step": 30130
    },
    {
      "epoch": 2.5718917996416075,
      "grad_norm": 0.14295285940170288,
      "learning_rate": 3.714054100179196e-05,
      "loss": 0.0016,
      "step": 30140
    },
    {
      "epoch": 2.5727451147708846,
      "grad_norm": 0.09210176020860672,
      "learning_rate": 3.713627442614558e-05,
      "loss": 0.0024,
      "step": 30150
    },
    {
      "epoch": 2.573598429900162,
      "grad_norm": 0.04439299926161766,
      "learning_rate": 3.713200785049919e-05,
      "loss": 0.0023,
      "step": 30160
    },
    {
      "epoch": 2.5744517450294393,
      "grad_norm": 0.15035691857337952,
      "learning_rate": 3.7127741274852805e-05,
      "loss": 0.0022,
      "step": 30170
    },
    {
      "epoch": 2.5753050601587164,
      "grad_norm": 0.40598878264427185,
      "learning_rate": 3.712347469920642e-05,
      "loss": 0.0019,
      "step": 30180
    },
    {
      "epoch": 2.576158375287994,
      "grad_norm": 0.08501161634922028,
      "learning_rate": 3.7119208123560034e-05,
      "loss": 0.0022,
      "step": 30190
    },
    {
      "epoch": 2.577011690417271,
      "grad_norm": 0.11454367637634277,
      "learning_rate": 3.711494154791365e-05,
      "loss": 0.002,
      "step": 30200
    },
    {
      "epoch": 2.577865005546548,
      "grad_norm": 0.08042756468057632,
      "learning_rate": 3.711067497226726e-05,
      "loss": 0.0016,
      "step": 30210
    },
    {
      "epoch": 2.5787183206758257,
      "grad_norm": 0.42586639523506165,
      "learning_rate": 3.710640839662087e-05,
      "loss": 0.002,
      "step": 30220
    },
    {
      "epoch": 2.579571635805103,
      "grad_norm": 0.043390728533267975,
      "learning_rate": 3.710214182097449e-05,
      "loss": 0.002,
      "step": 30230
    },
    {
      "epoch": 2.58042495093438,
      "grad_norm": 0.22944241762161255,
      "learning_rate": 3.70978752453281e-05,
      "loss": 0.0025,
      "step": 30240
    },
    {
      "epoch": 2.5812782660636575,
      "grad_norm": 0.1484193503856659,
      "learning_rate": 3.709360866968172e-05,
      "loss": 0.0022,
      "step": 30250
    },
    {
      "epoch": 2.5821315811929346,
      "grad_norm": 0.1547435075044632,
      "learning_rate": 3.708934209403533e-05,
      "loss": 0.0022,
      "step": 30260
    },
    {
      "epoch": 2.5829848963222117,
      "grad_norm": 0.1397351771593094,
      "learning_rate": 3.708507551838895e-05,
      "loss": 0.0019,
      "step": 30270
    },
    {
      "epoch": 2.5838382114514893,
      "grad_norm": 0.45817771553993225,
      "learning_rate": 3.7080808942742555e-05,
      "loss": 0.0028,
      "step": 30280
    },
    {
      "epoch": 2.5846915265807664,
      "grad_norm": 0.22210641205310822,
      "learning_rate": 3.7076542367096176e-05,
      "loss": 0.0018,
      "step": 30290
    },
    {
      "epoch": 2.5855448417100435,
      "grad_norm": 0.26295945048332214,
      "learning_rate": 3.7072275791449784e-05,
      "loss": 0.0027,
      "step": 30300
    },
    {
      "epoch": 2.5863981568393206,
      "grad_norm": 0.07749290764331818,
      "learning_rate": 3.70680092158034e-05,
      "loss": 0.0028,
      "step": 30310
    },
    {
      "epoch": 2.5872514719685977,
      "grad_norm": 0.13262833654880524,
      "learning_rate": 3.706374264015701e-05,
      "loss": 0.0021,
      "step": 30320
    },
    {
      "epoch": 2.5881047870978753,
      "grad_norm": 0.4553256332874298,
      "learning_rate": 3.7059476064510626e-05,
      "loss": 0.0021,
      "step": 30330
    },
    {
      "epoch": 2.5889581022271524,
      "grad_norm": 0.1852877140045166,
      "learning_rate": 3.705520948886424e-05,
      "loss": 0.0018,
      "step": 30340
    },
    {
      "epoch": 2.5898114173564295,
      "grad_norm": 0.22387537360191345,
      "learning_rate": 3.705094291321785e-05,
      "loss": 0.0022,
      "step": 30350
    },
    {
      "epoch": 2.590664732485707,
      "grad_norm": 0.15429158508777618,
      "learning_rate": 3.704667633757147e-05,
      "loss": 0.0028,
      "step": 30360
    },
    {
      "epoch": 2.591518047614984,
      "grad_norm": 0.13808466494083405,
      "learning_rate": 3.704240976192508e-05,
      "loss": 0.0022,
      "step": 30370
    },
    {
      "epoch": 2.5923713627442613,
      "grad_norm": 0.15242315828800201,
      "learning_rate": 3.70381431862787e-05,
      "loss": 0.002,
      "step": 30380
    },
    {
      "epoch": 2.593224677873539,
      "grad_norm": 0.15176382660865784,
      "learning_rate": 3.7033876610632305e-05,
      "loss": 0.0018,
      "step": 30390
    },
    {
      "epoch": 2.594077993002816,
      "grad_norm": 0.23124472796916962,
      "learning_rate": 3.7029610034985926e-05,
      "loss": 0.0021,
      "step": 30400
    },
    {
      "epoch": 2.594931308132093,
      "grad_norm": 0.1629449874162674,
      "learning_rate": 3.7025343459339534e-05,
      "loss": 0.0027,
      "step": 30410
    },
    {
      "epoch": 2.5957846232613706,
      "grad_norm": 0.24279405176639557,
      "learning_rate": 3.702107688369315e-05,
      "loss": 0.0023,
      "step": 30420
    },
    {
      "epoch": 2.5966379383906477,
      "grad_norm": 0.16969649493694305,
      "learning_rate": 3.701681030804676e-05,
      "loss": 0.0025,
      "step": 30430
    },
    {
      "epoch": 2.597491253519925,
      "grad_norm": 0.2448674589395523,
      "learning_rate": 3.7012543732400376e-05,
      "loss": 0.0019,
      "step": 30440
    },
    {
      "epoch": 2.5983445686492024,
      "grad_norm": 0.30524349212646484,
      "learning_rate": 3.700827715675399e-05,
      "loss": 0.0019,
      "step": 30450
    },
    {
      "epoch": 2.5991978837784795,
      "grad_norm": 0.6356967091560364,
      "learning_rate": 3.7004010581107605e-05,
      "loss": 0.0024,
      "step": 30460
    },
    {
      "epoch": 2.6000511989077566,
      "grad_norm": 0.15836898982524872,
      "learning_rate": 3.699974400546122e-05,
      "loss": 0.002,
      "step": 30470
    },
    {
      "epoch": 2.6009045140370337,
      "grad_norm": 0.43151339888572693,
      "learning_rate": 3.699547742981483e-05,
      "loss": 0.0019,
      "step": 30480
    },
    {
      "epoch": 2.6017578291663113,
      "grad_norm": 0.40867698192596436,
      "learning_rate": 3.699121085416845e-05,
      "loss": 0.0023,
      "step": 30490
    },
    {
      "epoch": 2.6026111442955884,
      "grad_norm": 0.10866468399763107,
      "learning_rate": 3.698694427852206e-05,
      "loss": 0.0019,
      "step": 30500
    },
    {
      "epoch": 2.6034644594248655,
      "grad_norm": 0.2742561995983124,
      "learning_rate": 3.6982677702875676e-05,
      "loss": 0.0027,
      "step": 30510
    },
    {
      "epoch": 2.6043177745541426,
      "grad_norm": 0.05038376897573471,
      "learning_rate": 3.697841112722929e-05,
      "loss": 0.0016,
      "step": 30520
    },
    {
      "epoch": 2.60517108968342,
      "grad_norm": 0.1516089141368866,
      "learning_rate": 3.69741445515829e-05,
      "loss": 0.002,
      "step": 30530
    },
    {
      "epoch": 2.6060244048126973,
      "grad_norm": 0.28696200251579285,
      "learning_rate": 3.696987797593652e-05,
      "loss": 0.0021,
      "step": 30540
    },
    {
      "epoch": 2.6068777199419744,
      "grad_norm": 0.47763797640800476,
      "learning_rate": 3.6965611400290126e-05,
      "loss": 0.0023,
      "step": 30550
    },
    {
      "epoch": 2.607731035071252,
      "grad_norm": 0.17188401520252228,
      "learning_rate": 3.696134482464374e-05,
      "loss": 0.0019,
      "step": 30560
    },
    {
      "epoch": 2.608584350200529,
      "grad_norm": 0.24443168938159943,
      "learning_rate": 3.6957078248997355e-05,
      "loss": 0.0018,
      "step": 30570
    },
    {
      "epoch": 2.609437665329806,
      "grad_norm": 0.2508050799369812,
      "learning_rate": 3.695281167335097e-05,
      "loss": 0.0023,
      "step": 30580
    },
    {
      "epoch": 2.6102909804590837,
      "grad_norm": 0.15218234062194824,
      "learning_rate": 3.694854509770458e-05,
      "loss": 0.0017,
      "step": 30590
    },
    {
      "epoch": 2.611144295588361,
      "grad_norm": 0.22058463096618652,
      "learning_rate": 3.69442785220582e-05,
      "loss": 0.0018,
      "step": 30600
    },
    {
      "epoch": 2.611997610717638,
      "grad_norm": 0.23724371194839478,
      "learning_rate": 3.694001194641181e-05,
      "loss": 0.0023,
      "step": 30610
    },
    {
      "epoch": 2.6128509258469155,
      "grad_norm": 0.3850390613079071,
      "learning_rate": 3.6935745370765426e-05,
      "loss": 0.0018,
      "step": 30620
    },
    {
      "epoch": 2.6137042409761926,
      "grad_norm": 0.3195424973964691,
      "learning_rate": 3.693147879511904e-05,
      "loss": 0.0019,
      "step": 30630
    },
    {
      "epoch": 2.6145575561054697,
      "grad_norm": 0.28876617550849915,
      "learning_rate": 3.6927212219472654e-05,
      "loss": 0.0021,
      "step": 30640
    },
    {
      "epoch": 2.6154108712347472,
      "grad_norm": 0.03669179603457451,
      "learning_rate": 3.692294564382627e-05,
      "loss": 0.0023,
      "step": 30650
    },
    {
      "epoch": 2.6162641863640244,
      "grad_norm": 0.3011868894100189,
      "learning_rate": 3.6918679068179876e-05,
      "loss": 0.002,
      "step": 30660
    },
    {
      "epoch": 2.6171175014933015,
      "grad_norm": 0.22571438550949097,
      "learning_rate": 3.69144124925335e-05,
      "loss": 0.0025,
      "step": 30670
    },
    {
      "epoch": 2.6179708166225786,
      "grad_norm": 0.33722296357154846,
      "learning_rate": 3.6910145916887105e-05,
      "loss": 0.0023,
      "step": 30680
    },
    {
      "epoch": 2.6188241317518557,
      "grad_norm": 0.2617095410823822,
      "learning_rate": 3.6905879341240726e-05,
      "loss": 0.0019,
      "step": 30690
    },
    {
      "epoch": 2.6196774468811332,
      "grad_norm": 0.5928771495819092,
      "learning_rate": 3.690161276559433e-05,
      "loss": 0.0021,
      "step": 30700
    },
    {
      "epoch": 2.6205307620104104,
      "grad_norm": 0.18880552053451538,
      "learning_rate": 3.6897346189947954e-05,
      "loss": 0.0021,
      "step": 30710
    },
    {
      "epoch": 2.6213840771396875,
      "grad_norm": 0.21032947301864624,
      "learning_rate": 3.689307961430156e-05,
      "loss": 0.0018,
      "step": 30720
    },
    {
      "epoch": 2.622237392268965,
      "grad_norm": 0.5889600515365601,
      "learning_rate": 3.6888813038655176e-05,
      "loss": 0.0029,
      "step": 30730
    },
    {
      "epoch": 2.623090707398242,
      "grad_norm": 0.2834030091762543,
      "learning_rate": 3.688454646300879e-05,
      "loss": 0.002,
      "step": 30740
    },
    {
      "epoch": 2.6239440225275192,
      "grad_norm": 0.2885831892490387,
      "learning_rate": 3.6880279887362404e-05,
      "loss": 0.0023,
      "step": 30750
    },
    {
      "epoch": 2.624797337656797,
      "grad_norm": 0.08329029381275177,
      "learning_rate": 3.687601331171602e-05,
      "loss": 0.0029,
      "step": 30760
    },
    {
      "epoch": 2.625650652786074,
      "grad_norm": 0.3213571608066559,
      "learning_rate": 3.687174673606963e-05,
      "loss": 0.0028,
      "step": 30770
    },
    {
      "epoch": 2.626503967915351,
      "grad_norm": 0.34511303901672363,
      "learning_rate": 3.686748016042325e-05,
      "loss": 0.0021,
      "step": 30780
    },
    {
      "epoch": 2.6273572830446286,
      "grad_norm": 0.12342334538698196,
      "learning_rate": 3.686321358477686e-05,
      "loss": 0.0033,
      "step": 30790
    },
    {
      "epoch": 2.6282105981739057,
      "grad_norm": 0.0822245180606842,
      "learning_rate": 3.6858947009130475e-05,
      "loss": 0.0028,
      "step": 30800
    },
    {
      "epoch": 2.629063913303183,
      "grad_norm": 0.09701092541217804,
      "learning_rate": 3.685468043348409e-05,
      "loss": 0.0021,
      "step": 30810
    },
    {
      "epoch": 2.6299172284324603,
      "grad_norm": 0.03432822227478027,
      "learning_rate": 3.6850413857837704e-05,
      "loss": 0.0021,
      "step": 30820
    },
    {
      "epoch": 2.6307705435617375,
      "grad_norm": 0.09295324981212616,
      "learning_rate": 3.684614728219131e-05,
      "loss": 0.002,
      "step": 30830
    },
    {
      "epoch": 2.6316238586910146,
      "grad_norm": 0.16582739353179932,
      "learning_rate": 3.6841880706544926e-05,
      "loss": 0.0022,
      "step": 30840
    },
    {
      "epoch": 2.6324771738202917,
      "grad_norm": 0.26963263750076294,
      "learning_rate": 3.683761413089854e-05,
      "loss": 0.002,
      "step": 30850
    },
    {
      "epoch": 2.6333304889495692,
      "grad_norm": 0.07557811588048935,
      "learning_rate": 3.6833347555252154e-05,
      "loss": 0.002,
      "step": 30860
    },
    {
      "epoch": 2.6341838040788463,
      "grad_norm": 0.05203375220298767,
      "learning_rate": 3.682908097960577e-05,
      "loss": 0.0021,
      "step": 30870
    },
    {
      "epoch": 2.6350371192081234,
      "grad_norm": 0.280875563621521,
      "learning_rate": 3.682481440395938e-05,
      "loss": 0.002,
      "step": 30880
    },
    {
      "epoch": 2.6358904343374006,
      "grad_norm": 0.36228328943252563,
      "learning_rate": 3.6820547828313e-05,
      "loss": 0.0025,
      "step": 30890
    },
    {
      "epoch": 2.636743749466678,
      "grad_norm": 0.4060232937335968,
      "learning_rate": 3.681628125266661e-05,
      "loss": 0.0024,
      "step": 30900
    },
    {
      "epoch": 2.637597064595955,
      "grad_norm": 0.2100408971309662,
      "learning_rate": 3.6812014677020225e-05,
      "loss": 0.0022,
      "step": 30910
    },
    {
      "epoch": 2.6384503797252323,
      "grad_norm": 0.4017184376716614,
      "learning_rate": 3.680774810137384e-05,
      "loss": 0.0026,
      "step": 30920
    },
    {
      "epoch": 2.63930369485451,
      "grad_norm": 0.048963721841573715,
      "learning_rate": 3.6803481525727454e-05,
      "loss": 0.0021,
      "step": 30930
    },
    {
      "epoch": 2.640157009983787,
      "grad_norm": 0.17528273165225983,
      "learning_rate": 3.679921495008107e-05,
      "loss": 0.0023,
      "step": 30940
    },
    {
      "epoch": 2.641010325113064,
      "grad_norm": 0.04843747243285179,
      "learning_rate": 3.679494837443468e-05,
      "loss": 0.0023,
      "step": 30950
    },
    {
      "epoch": 2.6418636402423417,
      "grad_norm": 0.25967568159103394,
      "learning_rate": 3.6790681798788297e-05,
      "loss": 0.002,
      "step": 30960
    },
    {
      "epoch": 2.6427169553716188,
      "grad_norm": 0.4398210048675537,
      "learning_rate": 3.6786415223141904e-05,
      "loss": 0.0015,
      "step": 30970
    },
    {
      "epoch": 2.643570270500896,
      "grad_norm": 0.24540908634662628,
      "learning_rate": 3.6782148647495525e-05,
      "loss": 0.0025,
      "step": 30980
    },
    {
      "epoch": 2.6444235856301734,
      "grad_norm": 0.39901095628738403,
      "learning_rate": 3.677788207184913e-05,
      "loss": 0.0019,
      "step": 30990
    },
    {
      "epoch": 2.6452769007594505,
      "grad_norm": 0.0961429551243782,
      "learning_rate": 3.6773615496202753e-05,
      "loss": 0.002,
      "step": 31000
    },
    {
      "epoch": 2.6461302158887277,
      "grad_norm": 0.11068091541528702,
      "learning_rate": 3.676934892055636e-05,
      "loss": 0.0022,
      "step": 31010
    },
    {
      "epoch": 2.646983531018005,
      "grad_norm": 0.02815650776028633,
      "learning_rate": 3.676508234490998e-05,
      "loss": 0.0019,
      "step": 31020
    },
    {
      "epoch": 2.6478368461472823,
      "grad_norm": 0.0694618746638298,
      "learning_rate": 3.676081576926359e-05,
      "loss": 0.0021,
      "step": 31030
    },
    {
      "epoch": 2.6486901612765594,
      "grad_norm": 0.23212552070617676,
      "learning_rate": 3.6756549193617204e-05,
      "loss": 0.0022,
      "step": 31040
    },
    {
      "epoch": 2.6495434764058365,
      "grad_norm": 0.10060377418994904,
      "learning_rate": 3.675228261797082e-05,
      "loss": 0.0021,
      "step": 31050
    },
    {
      "epoch": 2.6503967915351136,
      "grad_norm": 0.24174629151821136,
      "learning_rate": 3.674801604232443e-05,
      "loss": 0.0022,
      "step": 31060
    },
    {
      "epoch": 2.651250106664391,
      "grad_norm": 0.04210737347602844,
      "learning_rate": 3.6743749466678046e-05,
      "loss": 0.0016,
      "step": 31070
    },
    {
      "epoch": 2.6521034217936683,
      "grad_norm": 0.3015509247779846,
      "learning_rate": 3.673948289103166e-05,
      "loss": 0.0025,
      "step": 31080
    },
    {
      "epoch": 2.6529567369229454,
      "grad_norm": 0.24573440849781036,
      "learning_rate": 3.6735216315385275e-05,
      "loss": 0.0023,
      "step": 31090
    },
    {
      "epoch": 2.653810052052223,
      "grad_norm": 0.09053324162960052,
      "learning_rate": 3.673094973973888e-05,
      "loss": 0.0017,
      "step": 31100
    },
    {
      "epoch": 2.6546633671815,
      "grad_norm": 0.35338306427001953,
      "learning_rate": 3.67266831640925e-05,
      "loss": 0.0025,
      "step": 31110
    },
    {
      "epoch": 2.655516682310777,
      "grad_norm": 0.22908125817775726,
      "learning_rate": 3.672241658844611e-05,
      "loss": 0.002,
      "step": 31120
    },
    {
      "epoch": 2.6563699974400548,
      "grad_norm": 0.032737985253334045,
      "learning_rate": 3.671815001279973e-05,
      "loss": 0.0018,
      "step": 31130
    },
    {
      "epoch": 2.657223312569332,
      "grad_norm": 0.2088165432214737,
      "learning_rate": 3.671388343715334e-05,
      "loss": 0.0023,
      "step": 31140
    },
    {
      "epoch": 2.658076627698609,
      "grad_norm": 0.025533726438879967,
      "learning_rate": 3.6709616861506954e-05,
      "loss": 0.0024,
      "step": 31150
    },
    {
      "epoch": 2.6589299428278865,
      "grad_norm": 0.3314893841743469,
      "learning_rate": 3.670535028586057e-05,
      "loss": 0.0019,
      "step": 31160
    },
    {
      "epoch": 2.6597832579571636,
      "grad_norm": 0.10797014832496643,
      "learning_rate": 3.670108371021418e-05,
      "loss": 0.0023,
      "step": 31170
    },
    {
      "epoch": 2.6606365730864407,
      "grad_norm": 0.2837357223033905,
      "learning_rate": 3.6696817134567796e-05,
      "loss": 0.0025,
      "step": 31180
    },
    {
      "epoch": 2.6614898882157183,
      "grad_norm": 0.31737756729125977,
      "learning_rate": 3.669255055892141e-05,
      "loss": 0.0019,
      "step": 31190
    },
    {
      "epoch": 2.6623432033449954,
      "grad_norm": 0.14852504432201385,
      "learning_rate": 3.6688283983275025e-05,
      "loss": 0.002,
      "step": 31200
    },
    {
      "epoch": 2.6631965184742725,
      "grad_norm": 0.08246476948261261,
      "learning_rate": 3.668401740762864e-05,
      "loss": 0.002,
      "step": 31210
    },
    {
      "epoch": 2.6640498336035496,
      "grad_norm": 0.22973138093948364,
      "learning_rate": 3.667975083198225e-05,
      "loss": 0.0023,
      "step": 31220
    },
    {
      "epoch": 2.664903148732827,
      "grad_norm": 0.24281586706638336,
      "learning_rate": 3.667548425633587e-05,
      "loss": 0.002,
      "step": 31230
    },
    {
      "epoch": 2.6657564638621043,
      "grad_norm": 0.31019145250320435,
      "learning_rate": 3.667121768068948e-05,
      "loss": 0.002,
      "step": 31240
    },
    {
      "epoch": 2.6666097789913814,
      "grad_norm": 0.09808323532342911,
      "learning_rate": 3.6666951105043096e-05,
      "loss": 0.0016,
      "step": 31250
    },
    {
      "epoch": 2.6674630941206585,
      "grad_norm": 0.2425641417503357,
      "learning_rate": 3.666268452939671e-05,
      "loss": 0.002,
      "step": 31260
    },
    {
      "epoch": 2.668316409249936,
      "grad_norm": 0.03376193344593048,
      "learning_rate": 3.6658417953750324e-05,
      "loss": 0.0023,
      "step": 31270
    },
    {
      "epoch": 2.669169724379213,
      "grad_norm": 0.3399660289287567,
      "learning_rate": 3.665415137810393e-05,
      "loss": 0.0016,
      "step": 31280
    },
    {
      "epoch": 2.6700230395084903,
      "grad_norm": 0.13358664512634277,
      "learning_rate": 3.664988480245755e-05,
      "loss": 0.0024,
      "step": 31290
    },
    {
      "epoch": 2.670876354637768,
      "grad_norm": 0.27087220549583435,
      "learning_rate": 3.664561822681116e-05,
      "loss": 0.0024,
      "step": 31300
    },
    {
      "epoch": 2.671729669767045,
      "grad_norm": 0.11052675545215607,
      "learning_rate": 3.664135165116478e-05,
      "loss": 0.0019,
      "step": 31310
    },
    {
      "epoch": 2.672582984896322,
      "grad_norm": 0.15524248778820038,
      "learning_rate": 3.663708507551839e-05,
      "loss": 0.0019,
      "step": 31320
    },
    {
      "epoch": 2.6734363000255996,
      "grad_norm": 0.2090032994747162,
      "learning_rate": 3.663281849987201e-05,
      "loss": 0.0019,
      "step": 31330
    },
    {
      "epoch": 2.6742896151548767,
      "grad_norm": 0.03778679296374321,
      "learning_rate": 3.662855192422562e-05,
      "loss": 0.0022,
      "step": 31340
    },
    {
      "epoch": 2.675142930284154,
      "grad_norm": 0.14965476095676422,
      "learning_rate": 3.662428534857923e-05,
      "loss": 0.002,
      "step": 31350
    },
    {
      "epoch": 2.6759962454134314,
      "grad_norm": 0.16736888885498047,
      "learning_rate": 3.6620018772932846e-05,
      "loss": 0.0019,
      "step": 31360
    },
    {
      "epoch": 2.6768495605427085,
      "grad_norm": 0.1409880816936493,
      "learning_rate": 3.661575219728646e-05,
      "loss": 0.0022,
      "step": 31370
    },
    {
      "epoch": 2.6777028756719856,
      "grad_norm": 0.2875169813632965,
      "learning_rate": 3.6611485621640074e-05,
      "loss": 0.002,
      "step": 31380
    },
    {
      "epoch": 2.678556190801263,
      "grad_norm": 0.21431776881217957,
      "learning_rate": 3.660721904599368e-05,
      "loss": 0.0022,
      "step": 31390
    },
    {
      "epoch": 2.6794095059305403,
      "grad_norm": 0.06643915176391602,
      "learning_rate": 3.66029524703473e-05,
      "loss": 0.0022,
      "step": 31400
    },
    {
      "epoch": 2.6802628210598174,
      "grad_norm": 0.026630591601133347,
      "learning_rate": 3.659868589470091e-05,
      "loss": 0.0017,
      "step": 31410
    },
    {
      "epoch": 2.6811161361890945,
      "grad_norm": 0.17502018809318542,
      "learning_rate": 3.659441931905453e-05,
      "loss": 0.0023,
      "step": 31420
    },
    {
      "epoch": 2.6819694513183716,
      "grad_norm": 0.05712391808629036,
      "learning_rate": 3.659015274340814e-05,
      "loss": 0.0026,
      "step": 31430
    },
    {
      "epoch": 2.682822766447649,
      "grad_norm": 0.12084956467151642,
      "learning_rate": 3.658588616776176e-05,
      "loss": 0.0024,
      "step": 31440
    },
    {
      "epoch": 2.6836760815769263,
      "grad_norm": 0.3040507137775421,
      "learning_rate": 3.658161959211537e-05,
      "loss": 0.0021,
      "step": 31450
    },
    {
      "epoch": 2.6845293967062034,
      "grad_norm": 0.05384185537695885,
      "learning_rate": 3.657735301646898e-05,
      "loss": 0.0025,
      "step": 31460
    },
    {
      "epoch": 2.685382711835481,
      "grad_norm": 0.13222810626029968,
      "learning_rate": 3.6573086440822596e-05,
      "loss": 0.0021,
      "step": 31470
    },
    {
      "epoch": 2.686236026964758,
      "grad_norm": 0.3328022062778473,
      "learning_rate": 3.656881986517621e-05,
      "loss": 0.0022,
      "step": 31480
    },
    {
      "epoch": 2.687089342094035,
      "grad_norm": 0.42207056283950806,
      "learning_rate": 3.6564553289529824e-05,
      "loss": 0.0017,
      "step": 31490
    },
    {
      "epoch": 2.6879426572233127,
      "grad_norm": 0.29770177602767944,
      "learning_rate": 3.656028671388344e-05,
      "loss": 0.0019,
      "step": 31500
    },
    {
      "epoch": 2.68879597235259,
      "grad_norm": 0.44449615478515625,
      "learning_rate": 3.655602013823705e-05,
      "loss": 0.0024,
      "step": 31510
    },
    {
      "epoch": 2.689649287481867,
      "grad_norm": 0.0955158919095993,
      "learning_rate": 3.655175356259067e-05,
      "loss": 0.0015,
      "step": 31520
    },
    {
      "epoch": 2.6905026026111445,
      "grad_norm": 0.06164011359214783,
      "learning_rate": 3.654748698694428e-05,
      "loss": 0.0023,
      "step": 31530
    },
    {
      "epoch": 2.6913559177404216,
      "grad_norm": 0.21050477027893066,
      "learning_rate": 3.6543220411297895e-05,
      "loss": 0.0019,
      "step": 31540
    },
    {
      "epoch": 2.6922092328696987,
      "grad_norm": 0.2050565481185913,
      "learning_rate": 3.653895383565151e-05,
      "loss": 0.0024,
      "step": 31550
    },
    {
      "epoch": 2.6930625479989763,
      "grad_norm": 0.23264557123184204,
      "learning_rate": 3.6534687260005124e-05,
      "loss": 0.0022,
      "step": 31560
    },
    {
      "epoch": 2.6939158631282534,
      "grad_norm": 0.11190654337406158,
      "learning_rate": 3.653042068435874e-05,
      "loss": 0.0019,
      "step": 31570
    },
    {
      "epoch": 2.6947691782575305,
      "grad_norm": 0.18545015156269073,
      "learning_rate": 3.652615410871235e-05,
      "loss": 0.0018,
      "step": 31580
    },
    {
      "epoch": 2.6956224933868076,
      "grad_norm": 0.28109583258628845,
      "learning_rate": 3.652188753306596e-05,
      "loss": 0.0023,
      "step": 31590
    },
    {
      "epoch": 2.696475808516085,
      "grad_norm": 0.04365242272615433,
      "learning_rate": 3.651762095741958e-05,
      "loss": 0.0022,
      "step": 31600
    },
    {
      "epoch": 2.6973291236453623,
      "grad_norm": 0.06816670298576355,
      "learning_rate": 3.651335438177319e-05,
      "loss": 0.0015,
      "step": 31610
    },
    {
      "epoch": 2.6981824387746394,
      "grad_norm": 0.11902524530887604,
      "learning_rate": 3.650908780612681e-05,
      "loss": 0.0023,
      "step": 31620
    },
    {
      "epoch": 2.6990357539039165,
      "grad_norm": 0.21291692554950714,
      "learning_rate": 3.650482123048042e-05,
      "loss": 0.0023,
      "step": 31630
    },
    {
      "epoch": 2.699889069033194,
      "grad_norm": 0.26737740635871887,
      "learning_rate": 3.650055465483403e-05,
      "loss": 0.0016,
      "step": 31640
    },
    {
      "epoch": 2.700742384162471,
      "grad_norm": 0.4332433044910431,
      "learning_rate": 3.6496288079187645e-05,
      "loss": 0.0019,
      "step": 31650
    },
    {
      "epoch": 2.7015956992917483,
      "grad_norm": 0.48814359307289124,
      "learning_rate": 3.649202150354126e-05,
      "loss": 0.0021,
      "step": 31660
    },
    {
      "epoch": 2.702449014421026,
      "grad_norm": 0.26143553853034973,
      "learning_rate": 3.6487754927894874e-05,
      "loss": 0.0022,
      "step": 31670
    },
    {
      "epoch": 2.703302329550303,
      "grad_norm": 0.22698403894901276,
      "learning_rate": 3.648348835224849e-05,
      "loss": 0.0019,
      "step": 31680
    },
    {
      "epoch": 2.70415564467958,
      "grad_norm": 0.254971444606781,
      "learning_rate": 3.64792217766021e-05,
      "loss": 0.0017,
      "step": 31690
    },
    {
      "epoch": 2.7050089598088576,
      "grad_norm": 0.04534909501671791,
      "learning_rate": 3.647495520095571e-05,
      "loss": 0.0027,
      "step": 31700
    },
    {
      "epoch": 2.7058622749381347,
      "grad_norm": 0.1828507035970688,
      "learning_rate": 3.647068862530933e-05,
      "loss": 0.0017,
      "step": 31710
    },
    {
      "epoch": 2.706715590067412,
      "grad_norm": 0.4636617600917816,
      "learning_rate": 3.646642204966294e-05,
      "loss": 0.0023,
      "step": 31720
    },
    {
      "epoch": 2.7075689051966894,
      "grad_norm": 0.280636727809906,
      "learning_rate": 3.646215547401656e-05,
      "loss": 0.0021,
      "step": 31730
    },
    {
      "epoch": 2.7084222203259665,
      "grad_norm": 0.0949401706457138,
      "learning_rate": 3.645788889837017e-05,
      "loss": 0.0019,
      "step": 31740
    },
    {
      "epoch": 2.7092755354552436,
      "grad_norm": 0.4137852191925049,
      "learning_rate": 3.645362232272379e-05,
      "loss": 0.0018,
      "step": 31750
    },
    {
      "epoch": 2.710128850584521,
      "grad_norm": 0.2230755239725113,
      "learning_rate": 3.6449355747077395e-05,
      "loss": 0.0017,
      "step": 31760
    },
    {
      "epoch": 2.7109821657137982,
      "grad_norm": 0.25459927320480347,
      "learning_rate": 3.644508917143101e-05,
      "loss": 0.0022,
      "step": 31770
    },
    {
      "epoch": 2.7118354808430754,
      "grad_norm": 0.2077638804912567,
      "learning_rate": 3.6440822595784624e-05,
      "loss": 0.0022,
      "step": 31780
    },
    {
      "epoch": 2.7126887959723525,
      "grad_norm": 0.1350472867488861,
      "learning_rate": 3.643655602013824e-05,
      "loss": 0.0024,
      "step": 31790
    },
    {
      "epoch": 2.7135421111016296,
      "grad_norm": 0.356597363948822,
      "learning_rate": 3.643228944449185e-05,
      "loss": 0.002,
      "step": 31800
    },
    {
      "epoch": 2.714395426230907,
      "grad_norm": 0.27641403675079346,
      "learning_rate": 3.6428022868845466e-05,
      "loss": 0.002,
      "step": 31810
    },
    {
      "epoch": 2.7152487413601842,
      "grad_norm": 0.05792552977800369,
      "learning_rate": 3.642375629319908e-05,
      "loss": 0.0021,
      "step": 31820
    },
    {
      "epoch": 2.7161020564894613,
      "grad_norm": 0.04572669416666031,
      "learning_rate": 3.6419489717552695e-05,
      "loss": 0.0017,
      "step": 31830
    },
    {
      "epoch": 2.716955371618739,
      "grad_norm": 0.138325035572052,
      "learning_rate": 3.641522314190631e-05,
      "loss": 0.0019,
      "step": 31840
    },
    {
      "epoch": 2.717808686748016,
      "grad_norm": 0.10384064167737961,
      "learning_rate": 3.641095656625992e-05,
      "loss": 0.0025,
      "step": 31850
    },
    {
      "epoch": 2.718662001877293,
      "grad_norm": 0.1536339819431305,
      "learning_rate": 3.640668999061354e-05,
      "loss": 0.0018,
      "step": 31860
    },
    {
      "epoch": 2.7195153170065707,
      "grad_norm": 0.39140889048576355,
      "learning_rate": 3.640242341496715e-05,
      "loss": 0.0021,
      "step": 31870
    },
    {
      "epoch": 2.720368632135848,
      "grad_norm": 0.20535902678966522,
      "learning_rate": 3.6398156839320766e-05,
      "loss": 0.0029,
      "step": 31880
    },
    {
      "epoch": 2.721221947265125,
      "grad_norm": 0.2109576314687729,
      "learning_rate": 3.6393890263674373e-05,
      "loss": 0.002,
      "step": 31890
    },
    {
      "epoch": 2.7220752623944025,
      "grad_norm": 0.21451760828495026,
      "learning_rate": 3.638962368802799e-05,
      "loss": 0.0015,
      "step": 31900
    },
    {
      "epoch": 2.7229285775236796,
      "grad_norm": 0.033326368778944016,
      "learning_rate": 3.63853571123816e-05,
      "loss": 0.002,
      "step": 31910
    },
    {
      "epoch": 2.7237818926529567,
      "grad_norm": 0.20670472085475922,
      "learning_rate": 3.6381090536735216e-05,
      "loss": 0.0023,
      "step": 31920
    },
    {
      "epoch": 2.7246352077822342,
      "grad_norm": 0.4336731731891632,
      "learning_rate": 3.637682396108883e-05,
      "loss": 0.0021,
      "step": 31930
    },
    {
      "epoch": 2.7254885229115113,
      "grad_norm": 0.46449366211891174,
      "learning_rate": 3.6372557385442445e-05,
      "loss": 0.0026,
      "step": 31940
    },
    {
      "epoch": 2.7263418380407884,
      "grad_norm": 0.2627979516983032,
      "learning_rate": 3.636829080979606e-05,
      "loss": 0.0024,
      "step": 31950
    },
    {
      "epoch": 2.7271951531700656,
      "grad_norm": 0.20638374984264374,
      "learning_rate": 3.636402423414967e-05,
      "loss": 0.0019,
      "step": 31960
    },
    {
      "epoch": 2.728048468299343,
      "grad_norm": 0.04847220703959465,
      "learning_rate": 3.635975765850329e-05,
      "loss": 0.0022,
      "step": 31970
    },
    {
      "epoch": 2.72890178342862,
      "grad_norm": 0.2994235157966614,
      "learning_rate": 3.63554910828569e-05,
      "loss": 0.0019,
      "step": 31980
    },
    {
      "epoch": 2.7297550985578973,
      "grad_norm": 0.3273873031139374,
      "learning_rate": 3.6351224507210516e-05,
      "loss": 0.0031,
      "step": 31990
    },
    {
      "epoch": 2.7306084136871744,
      "grad_norm": 0.41231396794319153,
      "learning_rate": 3.634695793156413e-05,
      "loss": 0.0024,
      "step": 32000
    },
    {
      "epoch": 2.731461728816452,
      "grad_norm": 0.3115631937980652,
      "learning_rate": 3.634269135591774e-05,
      "loss": 0.0019,
      "step": 32010
    },
    {
      "epoch": 2.732315043945729,
      "grad_norm": 0.2061268836259842,
      "learning_rate": 3.633842478027136e-05,
      "loss": 0.0029,
      "step": 32020
    },
    {
      "epoch": 2.733168359075006,
      "grad_norm": 0.045712102204561234,
      "learning_rate": 3.6334158204624966e-05,
      "loss": 0.0025,
      "step": 32030
    },
    {
      "epoch": 2.7340216742042838,
      "grad_norm": 0.13170292973518372,
      "learning_rate": 3.632989162897859e-05,
      "loss": 0.0019,
      "step": 32040
    },
    {
      "epoch": 2.734874989333561,
      "grad_norm": 0.19714196026325226,
      "learning_rate": 3.6325625053332195e-05,
      "loss": 0.0025,
      "step": 32050
    },
    {
      "epoch": 2.735728304462838,
      "grad_norm": 0.32215288281440735,
      "learning_rate": 3.6321358477685816e-05,
      "loss": 0.0021,
      "step": 32060
    },
    {
      "epoch": 2.7365816195921155,
      "grad_norm": 0.11956728249788284,
      "learning_rate": 3.631709190203942e-05,
      "loss": 0.0019,
      "step": 32070
    },
    {
      "epoch": 2.7374349347213927,
      "grad_norm": 0.05814623460173607,
      "learning_rate": 3.6312825326393044e-05,
      "loss": 0.0021,
      "step": 32080
    },
    {
      "epoch": 2.7382882498506698,
      "grad_norm": 0.11364603787660599,
      "learning_rate": 3.630855875074665e-05,
      "loss": 0.0027,
      "step": 32090
    },
    {
      "epoch": 2.7391415649799473,
      "grad_norm": 0.24461624026298523,
      "learning_rate": 3.6304292175100266e-05,
      "loss": 0.0018,
      "step": 32100
    },
    {
      "epoch": 2.7399948801092244,
      "grad_norm": 0.21282510459423065,
      "learning_rate": 3.630002559945388e-05,
      "loss": 0.002,
      "step": 32110
    },
    {
      "epoch": 2.7408481952385015,
      "grad_norm": 0.2799340784549713,
      "learning_rate": 3.6295759023807494e-05,
      "loss": 0.0019,
      "step": 32120
    },
    {
      "epoch": 2.741701510367779,
      "grad_norm": 0.15281373262405396,
      "learning_rate": 3.629149244816111e-05,
      "loss": 0.0026,
      "step": 32130
    },
    {
      "epoch": 2.742554825497056,
      "grad_norm": 0.2710639536380768,
      "learning_rate": 3.628722587251472e-05,
      "loss": 0.0026,
      "step": 32140
    },
    {
      "epoch": 2.7434081406263333,
      "grad_norm": 0.18770810961723328,
      "learning_rate": 3.628295929686834e-05,
      "loss": 0.0023,
      "step": 32150
    },
    {
      "epoch": 2.7442614557556104,
      "grad_norm": 0.13084812462329865,
      "learning_rate": 3.6278692721221944e-05,
      "loss": 0.0019,
      "step": 32160
    },
    {
      "epoch": 2.7451147708848875,
      "grad_norm": 0.05015598610043526,
      "learning_rate": 3.6274426145575565e-05,
      "loss": 0.0021,
      "step": 32170
    },
    {
      "epoch": 2.745968086014165,
      "grad_norm": 0.22794532775878906,
      "learning_rate": 3.627015956992917e-05,
      "loss": 0.002,
      "step": 32180
    },
    {
      "epoch": 2.746821401143442,
      "grad_norm": 0.1871161013841629,
      "learning_rate": 3.6265892994282794e-05,
      "loss": 0.0019,
      "step": 32190
    },
    {
      "epoch": 2.7476747162727193,
      "grad_norm": 0.2435600459575653,
      "learning_rate": 3.62616264186364e-05,
      "loss": 0.0022,
      "step": 32200
    },
    {
      "epoch": 2.748528031401997,
      "grad_norm": 0.20971231162548065,
      "learning_rate": 3.6257359842990016e-05,
      "loss": 0.0019,
      "step": 32210
    },
    {
      "epoch": 2.749381346531274,
      "grad_norm": 0.1874067783355713,
      "learning_rate": 3.625309326734363e-05,
      "loss": 0.002,
      "step": 32220
    },
    {
      "epoch": 2.750234661660551,
      "grad_norm": 0.1883503794670105,
      "learning_rate": 3.6248826691697244e-05,
      "loss": 0.0016,
      "step": 32230
    },
    {
      "epoch": 2.7510879767898286,
      "grad_norm": 0.03294997289776802,
      "learning_rate": 3.624456011605086e-05,
      "loss": 0.0025,
      "step": 32240
    },
    {
      "epoch": 2.7519412919191057,
      "grad_norm": 0.24732771515846252,
      "learning_rate": 3.624029354040447e-05,
      "loss": 0.0021,
      "step": 32250
    },
    {
      "epoch": 2.752794607048383,
      "grad_norm": 0.23803415894508362,
      "learning_rate": 3.623602696475809e-05,
      "loss": 0.0024,
      "step": 32260
    },
    {
      "epoch": 2.7536479221776604,
      "grad_norm": 0.16735213994979858,
      "learning_rate": 3.62317603891117e-05,
      "loss": 0.0022,
      "step": 32270
    },
    {
      "epoch": 2.7545012373069375,
      "grad_norm": 0.03623295575380325,
      "learning_rate": 3.6227493813465315e-05,
      "loss": 0.0027,
      "step": 32280
    },
    {
      "epoch": 2.7553545524362146,
      "grad_norm": 0.49664366245269775,
      "learning_rate": 3.622322723781893e-05,
      "loss": 0.0018,
      "step": 32290
    },
    {
      "epoch": 2.756207867565492,
      "grad_norm": 0.11482219398021698,
      "learning_rate": 3.6218960662172544e-05,
      "loss": 0.0019,
      "step": 32300
    },
    {
      "epoch": 2.7570611826947693,
      "grad_norm": 0.11616470664739609,
      "learning_rate": 3.621469408652616e-05,
      "loss": 0.0026,
      "step": 32310
    },
    {
      "epoch": 2.7579144978240464,
      "grad_norm": 0.05296693369746208,
      "learning_rate": 3.6210427510879766e-05,
      "loss": 0.0024,
      "step": 32320
    },
    {
      "epoch": 2.7587678129533235,
      "grad_norm": 0.17876960337162018,
      "learning_rate": 3.6206160935233387e-05,
      "loss": 0.0024,
      "step": 32330
    },
    {
      "epoch": 2.7596211280826006,
      "grad_norm": 0.33304890990257263,
      "learning_rate": 3.6201894359586994e-05,
      "loss": 0.002,
      "step": 32340
    },
    {
      "epoch": 2.760474443211878,
      "grad_norm": 0.36966225504875183,
      "learning_rate": 3.6197627783940615e-05,
      "loss": 0.0024,
      "step": 32350
    },
    {
      "epoch": 2.7613277583411553,
      "grad_norm": 0.3358660340309143,
      "learning_rate": 3.619336120829422e-05,
      "loss": 0.0024,
      "step": 32360
    },
    {
      "epoch": 2.7621810734704324,
      "grad_norm": 0.20308823883533478,
      "learning_rate": 3.6189094632647844e-05,
      "loss": 0.002,
      "step": 32370
    },
    {
      "epoch": 2.76303438859971,
      "grad_norm": 0.08696902543306351,
      "learning_rate": 3.618482805700145e-05,
      "loss": 0.0021,
      "step": 32380
    },
    {
      "epoch": 2.763887703728987,
      "grad_norm": 0.13626062870025635,
      "learning_rate": 3.618056148135507e-05,
      "loss": 0.0021,
      "step": 32390
    },
    {
      "epoch": 2.764741018858264,
      "grad_norm": 0.33959200978279114,
      "learning_rate": 3.617629490570868e-05,
      "loss": 0.0019,
      "step": 32400
    },
    {
      "epoch": 2.7655943339875417,
      "grad_norm": 0.31655153632164,
      "learning_rate": 3.6172028330062294e-05,
      "loss": 0.0024,
      "step": 32410
    },
    {
      "epoch": 2.766447649116819,
      "grad_norm": 0.39175719022750854,
      "learning_rate": 3.616776175441591e-05,
      "loss": 0.0021,
      "step": 32420
    },
    {
      "epoch": 2.767300964246096,
      "grad_norm": 0.09275953471660614,
      "learning_rate": 3.6163495178769515e-05,
      "loss": 0.0022,
      "step": 32430
    },
    {
      "epoch": 2.7681542793753735,
      "grad_norm": 0.21061711013317108,
      "learning_rate": 3.6159228603123136e-05,
      "loss": 0.0025,
      "step": 32440
    },
    {
      "epoch": 2.7690075945046506,
      "grad_norm": 0.05155831575393677,
      "learning_rate": 3.6154962027476744e-05,
      "loss": 0.0018,
      "step": 32450
    },
    {
      "epoch": 2.7698609096339277,
      "grad_norm": 0.3794724643230438,
      "learning_rate": 3.6150695451830365e-05,
      "loss": 0.0025,
      "step": 32460
    },
    {
      "epoch": 2.7707142247632053,
      "grad_norm": 0.20923617482185364,
      "learning_rate": 3.614642887618397e-05,
      "loss": 0.0016,
      "step": 32470
    },
    {
      "epoch": 2.7715675398924824,
      "grad_norm": 0.06237319856882095,
      "learning_rate": 3.614216230053759e-05,
      "loss": 0.002,
      "step": 32480
    },
    {
      "epoch": 2.7724208550217595,
      "grad_norm": 0.10182175040245056,
      "learning_rate": 3.61378957248912e-05,
      "loss": 0.0024,
      "step": 32490
    },
    {
      "epoch": 2.773274170151037,
      "grad_norm": 0.153157576918602,
      "learning_rate": 3.613362914924482e-05,
      "loss": 0.0017,
      "step": 32500
    },
    {
      "epoch": 2.774127485280314,
      "grad_norm": 0.06984465569257736,
      "learning_rate": 3.612936257359843e-05,
      "loss": 0.0019,
      "step": 32510
    },
    {
      "epoch": 2.7749808004095913,
      "grad_norm": 0.2768237590789795,
      "learning_rate": 3.6125095997952044e-05,
      "loss": 0.0016,
      "step": 32520
    },
    {
      "epoch": 2.7758341155388684,
      "grad_norm": 0.04591358080506325,
      "learning_rate": 3.612082942230566e-05,
      "loss": 0.0019,
      "step": 32530
    },
    {
      "epoch": 2.7766874306681455,
      "grad_norm": 0.3924374580383301,
      "learning_rate": 3.611656284665927e-05,
      "loss": 0.002,
      "step": 32540
    },
    {
      "epoch": 2.777540745797423,
      "grad_norm": 0.11232956498861313,
      "learning_rate": 3.6112296271012886e-05,
      "loss": 0.0023,
      "step": 32550
    },
    {
      "epoch": 2.7783940609267,
      "grad_norm": 0.04782385379076004,
      "learning_rate": 3.61080296953665e-05,
      "loss": 0.0021,
      "step": 32560
    },
    {
      "epoch": 2.7792473760559773,
      "grad_norm": 0.09885502606630325,
      "learning_rate": 3.6103763119720115e-05,
      "loss": 0.0019,
      "step": 32570
    },
    {
      "epoch": 2.780100691185255,
      "grad_norm": 0.07742434740066528,
      "learning_rate": 3.609949654407373e-05,
      "loss": 0.0016,
      "step": 32580
    },
    {
      "epoch": 2.780954006314532,
      "grad_norm": 0.13381999731063843,
      "learning_rate": 3.609522996842734e-05,
      "loss": 0.0017,
      "step": 32590
    },
    {
      "epoch": 2.781807321443809,
      "grad_norm": 0.6268661618232727,
      "learning_rate": 3.609096339278096e-05,
      "loss": 0.0024,
      "step": 32600
    },
    {
      "epoch": 2.7826606365730866,
      "grad_norm": 0.7673866748809814,
      "learning_rate": 3.608669681713457e-05,
      "loss": 0.0016,
      "step": 32610
    },
    {
      "epoch": 2.7835139517023637,
      "grad_norm": 0.42939499020576477,
      "learning_rate": 3.6082430241488186e-05,
      "loss": 0.0022,
      "step": 32620
    },
    {
      "epoch": 2.784367266831641,
      "grad_norm": 0.3561205267906189,
      "learning_rate": 3.6078163665841793e-05,
      "loss": 0.0021,
      "step": 32630
    },
    {
      "epoch": 2.7852205819609184,
      "grad_norm": 0.21428634226322174,
      "learning_rate": 3.6073897090195414e-05,
      "loss": 0.0019,
      "step": 32640
    },
    {
      "epoch": 2.7860738970901955,
      "grad_norm": 0.2317487895488739,
      "learning_rate": 3.606963051454902e-05,
      "loss": 0.0019,
      "step": 32650
    },
    {
      "epoch": 2.7869272122194726,
      "grad_norm": 0.26346898078918457,
      "learning_rate": 3.606536393890264e-05,
      "loss": 0.0017,
      "step": 32660
    },
    {
      "epoch": 2.78778052734875,
      "grad_norm": 0.11607500165700912,
      "learning_rate": 3.606109736325625e-05,
      "loss": 0.002,
      "step": 32670
    },
    {
      "epoch": 2.7886338424780273,
      "grad_norm": 0.026075275614857674,
      "learning_rate": 3.605683078760987e-05,
      "loss": 0.0019,
      "step": 32680
    },
    {
      "epoch": 2.7894871576073044,
      "grad_norm": 0.2084313929080963,
      "learning_rate": 3.605256421196348e-05,
      "loss": 0.0016,
      "step": 32690
    },
    {
      "epoch": 2.7903404727365815,
      "grad_norm": 0.14988595247268677,
      "learning_rate": 3.604829763631709e-05,
      "loss": 0.0019,
      "step": 32700
    },
    {
      "epoch": 2.7911937878658586,
      "grad_norm": 0.19677133858203888,
      "learning_rate": 3.604403106067071e-05,
      "loss": 0.0024,
      "step": 32710
    },
    {
      "epoch": 2.792047102995136,
      "grad_norm": 0.21684664487838745,
      "learning_rate": 3.603976448502432e-05,
      "loss": 0.002,
      "step": 32720
    },
    {
      "epoch": 2.7929004181244133,
      "grad_norm": 0.1996513456106186,
      "learning_rate": 3.6035497909377936e-05,
      "loss": 0.0016,
      "step": 32730
    },
    {
      "epoch": 2.7937537332536904,
      "grad_norm": 0.2623108923435211,
      "learning_rate": 3.603123133373154e-05,
      "loss": 0.0018,
      "step": 32740
    },
    {
      "epoch": 2.794607048382968,
      "grad_norm": 0.42010292410850525,
      "learning_rate": 3.6026964758085164e-05,
      "loss": 0.002,
      "step": 32750
    },
    {
      "epoch": 2.795460363512245,
      "grad_norm": 0.2432180792093277,
      "learning_rate": 3.602269818243877e-05,
      "loss": 0.0021,
      "step": 32760
    },
    {
      "epoch": 2.796313678641522,
      "grad_norm": 0.054892007261514664,
      "learning_rate": 3.601843160679239e-05,
      "loss": 0.0019,
      "step": 32770
    },
    {
      "epoch": 2.7971669937707997,
      "grad_norm": 0.11570299416780472,
      "learning_rate": 3.6014165031146e-05,
      "loss": 0.0022,
      "step": 32780
    },
    {
      "epoch": 2.798020308900077,
      "grad_norm": 0.23522616922855377,
      "learning_rate": 3.600989845549962e-05,
      "loss": 0.0022,
      "step": 32790
    },
    {
      "epoch": 2.798873624029354,
      "grad_norm": 0.41401126980781555,
      "learning_rate": 3.600563187985323e-05,
      "loss": 0.0022,
      "step": 32800
    },
    {
      "epoch": 2.7997269391586315,
      "grad_norm": 0.19148340821266174,
      "learning_rate": 3.600136530420685e-05,
      "loss": 0.0028,
      "step": 32810
    },
    {
      "epoch": 2.8005802542879086,
      "grad_norm": 0.4691412150859833,
      "learning_rate": 3.599709872856046e-05,
      "loss": 0.0027,
      "step": 32820
    },
    {
      "epoch": 2.8014335694171857,
      "grad_norm": 0.2397068738937378,
      "learning_rate": 3.599283215291407e-05,
      "loss": 0.0029,
      "step": 32830
    },
    {
      "epoch": 2.8022868845464632,
      "grad_norm": 0.318806529045105,
      "learning_rate": 3.5988565577267686e-05,
      "loss": 0.0025,
      "step": 32840
    },
    {
      "epoch": 2.8031401996757404,
      "grad_norm": 0.21255357563495636,
      "learning_rate": 3.59842990016213e-05,
      "loss": 0.003,
      "step": 32850
    },
    {
      "epoch": 2.8039935148050175,
      "grad_norm": 0.2610970139503479,
      "learning_rate": 3.5980032425974914e-05,
      "loss": 0.0022,
      "step": 32860
    },
    {
      "epoch": 2.8048468299342946,
      "grad_norm": 0.16151374578475952,
      "learning_rate": 3.597576585032853e-05,
      "loss": 0.0025,
      "step": 32870
    },
    {
      "epoch": 2.805700145063572,
      "grad_norm": 0.26170825958251953,
      "learning_rate": 3.597149927468214e-05,
      "loss": 0.0021,
      "step": 32880
    },
    {
      "epoch": 2.8065534601928492,
      "grad_norm": 0.06610952317714691,
      "learning_rate": 3.596723269903576e-05,
      "loss": 0.0017,
      "step": 32890
    },
    {
      "epoch": 2.8074067753221263,
      "grad_norm": 0.23718498647212982,
      "learning_rate": 3.596296612338937e-05,
      "loss": 0.0022,
      "step": 32900
    },
    {
      "epoch": 2.8082600904514035,
      "grad_norm": 0.21945145726203918,
      "learning_rate": 3.5958699547742985e-05,
      "loss": 0.0024,
      "step": 32910
    },
    {
      "epoch": 2.809113405580681,
      "grad_norm": 0.08406853675842285,
      "learning_rate": 3.59544329720966e-05,
      "loss": 0.0018,
      "step": 32920
    },
    {
      "epoch": 2.809966720709958,
      "grad_norm": 0.04902980476617813,
      "learning_rate": 3.5950166396450214e-05,
      "loss": 0.002,
      "step": 32930
    },
    {
      "epoch": 2.8108200358392352,
      "grad_norm": 0.22931712865829468,
      "learning_rate": 3.594589982080382e-05,
      "loss": 0.0023,
      "step": 32940
    },
    {
      "epoch": 2.811673350968513,
      "grad_norm": 0.2424505650997162,
      "learning_rate": 3.594163324515744e-05,
      "loss": 0.0027,
      "step": 32950
    },
    {
      "epoch": 2.81252666609779,
      "grad_norm": 0.4122009575366974,
      "learning_rate": 3.593736666951105e-05,
      "loss": 0.0028,
      "step": 32960
    },
    {
      "epoch": 2.813379981227067,
      "grad_norm": 0.051283299922943115,
      "learning_rate": 3.5933100093864664e-05,
      "loss": 0.0025,
      "step": 32970
    },
    {
      "epoch": 2.8142332963563446,
      "grad_norm": 0.057537224143743515,
      "learning_rate": 3.592883351821828e-05,
      "loss": 0.0023,
      "step": 32980
    },
    {
      "epoch": 2.8150866114856217,
      "grad_norm": 0.2634236514568329,
      "learning_rate": 3.592456694257189e-05,
      "loss": 0.0023,
      "step": 32990
    },
    {
      "epoch": 2.815939926614899,
      "grad_norm": 0.5104678869247437,
      "learning_rate": 3.592030036692551e-05,
      "loss": 0.0016,
      "step": 33000
    },
    {
      "epoch": 2.8167932417441763,
      "grad_norm": 0.2949378788471222,
      "learning_rate": 3.591603379127912e-05,
      "loss": 0.002,
      "step": 33010
    },
    {
      "epoch": 2.8176465568734534,
      "grad_norm": 0.3699684739112854,
      "learning_rate": 3.5911767215632735e-05,
      "loss": 0.002,
      "step": 33020
    },
    {
      "epoch": 2.8184998720027306,
      "grad_norm": 0.07050330191850662,
      "learning_rate": 3.590750063998635e-05,
      "loss": 0.0023,
      "step": 33030
    },
    {
      "epoch": 2.819353187132008,
      "grad_norm": 0.18608030676841736,
      "learning_rate": 3.5903234064339964e-05,
      "loss": 0.0019,
      "step": 33040
    },
    {
      "epoch": 2.820206502261285,
      "grad_norm": 0.2419416606426239,
      "learning_rate": 3.589896748869357e-05,
      "loss": 0.0023,
      "step": 33050
    },
    {
      "epoch": 2.8210598173905623,
      "grad_norm": 0.33550772070884705,
      "learning_rate": 3.589470091304719e-05,
      "loss": 0.0024,
      "step": 33060
    },
    {
      "epoch": 2.8219131325198394,
      "grad_norm": 0.5771490335464478,
      "learning_rate": 3.58904343374008e-05,
      "loss": 0.0027,
      "step": 33070
    },
    {
      "epoch": 2.8227664476491166,
      "grad_norm": 0.06113136559724808,
      "learning_rate": 3.588616776175442e-05,
      "loss": 0.0019,
      "step": 33080
    },
    {
      "epoch": 2.823619762778394,
      "grad_norm": 0.3072361946105957,
      "learning_rate": 3.588190118610803e-05,
      "loss": 0.0023,
      "step": 33090
    },
    {
      "epoch": 2.824473077907671,
      "grad_norm": 0.30382731556892395,
      "learning_rate": 3.587763461046165e-05,
      "loss": 0.0021,
      "step": 33100
    },
    {
      "epoch": 2.8253263930369483,
      "grad_norm": 0.15142962336540222,
      "learning_rate": 3.587336803481526e-05,
      "loss": 0.0017,
      "step": 33110
    },
    {
      "epoch": 2.826179708166226,
      "grad_norm": 0.35414642095565796,
      "learning_rate": 3.586910145916888e-05,
      "loss": 0.0024,
      "step": 33120
    },
    {
      "epoch": 2.827033023295503,
      "grad_norm": 0.24269334971904755,
      "learning_rate": 3.5864834883522485e-05,
      "loss": 0.0021,
      "step": 33130
    },
    {
      "epoch": 2.82788633842478,
      "grad_norm": 0.06453685462474823,
      "learning_rate": 3.58605683078761e-05,
      "loss": 0.0023,
      "step": 33140
    },
    {
      "epoch": 2.8287396535540577,
      "grad_norm": 0.10436356067657471,
      "learning_rate": 3.5856301732229714e-05,
      "loss": 0.002,
      "step": 33150
    },
    {
      "epoch": 2.8295929686833348,
      "grad_norm": 0.08314159512519836,
      "learning_rate": 3.585203515658333e-05,
      "loss": 0.0016,
      "step": 33160
    },
    {
      "epoch": 2.830446283812612,
      "grad_norm": 0.0626765787601471,
      "learning_rate": 3.584776858093694e-05,
      "loss": 0.0021,
      "step": 33170
    },
    {
      "epoch": 2.8312995989418894,
      "grad_norm": 0.2611792981624603,
      "learning_rate": 3.5843502005290556e-05,
      "loss": 0.0025,
      "step": 33180
    },
    {
      "epoch": 2.8321529140711665,
      "grad_norm": 0.23931092023849487,
      "learning_rate": 3.583923542964417e-05,
      "loss": 0.0017,
      "step": 33190
    },
    {
      "epoch": 2.8330062292004436,
      "grad_norm": 0.1922214776277542,
      "learning_rate": 3.5834968853997785e-05,
      "loss": 0.0023,
      "step": 33200
    },
    {
      "epoch": 2.833859544329721,
      "grad_norm": 0.5441468358039856,
      "learning_rate": 3.58307022783514e-05,
      "loss": 0.0024,
      "step": 33210
    },
    {
      "epoch": 2.8347128594589983,
      "grad_norm": 0.09945598989725113,
      "learning_rate": 3.5826435702705007e-05,
      "loss": 0.0022,
      "step": 33220
    },
    {
      "epoch": 2.8355661745882754,
      "grad_norm": 0.1899404525756836,
      "learning_rate": 3.582216912705863e-05,
      "loss": 0.0016,
      "step": 33230
    },
    {
      "epoch": 2.8364194897175525,
      "grad_norm": 0.09411106258630753,
      "learning_rate": 3.5817902551412235e-05,
      "loss": 0.0021,
      "step": 33240
    },
    {
      "epoch": 2.83727280484683,
      "grad_norm": 0.19025136530399323,
      "learning_rate": 3.581363597576585e-05,
      "loss": 0.0024,
      "step": 33250
    },
    {
      "epoch": 2.838126119976107,
      "grad_norm": 0.15098324418067932,
      "learning_rate": 3.5809369400119464e-05,
      "loss": 0.002,
      "step": 33260
    },
    {
      "epoch": 2.8389794351053843,
      "grad_norm": 0.34228432178497314,
      "learning_rate": 3.580510282447308e-05,
      "loss": 0.0018,
      "step": 33270
    },
    {
      "epoch": 2.8398327502346614,
      "grad_norm": 0.07122663408517838,
      "learning_rate": 3.580083624882669e-05,
      "loss": 0.0017,
      "step": 33280
    },
    {
      "epoch": 2.840686065363939,
      "grad_norm": 0.09574289619922638,
      "learning_rate": 3.5796569673180306e-05,
      "loss": 0.0021,
      "step": 33290
    },
    {
      "epoch": 2.841539380493216,
      "grad_norm": 0.24453938007354736,
      "learning_rate": 3.579230309753392e-05,
      "loss": 0.0024,
      "step": 33300
    },
    {
      "epoch": 2.842392695622493,
      "grad_norm": 0.05557607114315033,
      "learning_rate": 3.5788036521887535e-05,
      "loss": 0.0025,
      "step": 33310
    },
    {
      "epoch": 2.8432460107517707,
      "grad_norm": 0.39848393201828003,
      "learning_rate": 3.578376994624115e-05,
      "loss": 0.0021,
      "step": 33320
    },
    {
      "epoch": 2.844099325881048,
      "grad_norm": 0.26195448637008667,
      "learning_rate": 3.577950337059476e-05,
      "loss": 0.0021,
      "step": 33330
    },
    {
      "epoch": 2.844952641010325,
      "grad_norm": 0.22086142003536224,
      "learning_rate": 3.577523679494838e-05,
      "loss": 0.0025,
      "step": 33340
    },
    {
      "epoch": 2.8458059561396025,
      "grad_norm": 0.04491619020700455,
      "learning_rate": 3.577097021930199e-05,
      "loss": 0.0017,
      "step": 33350
    },
    {
      "epoch": 2.8466592712688796,
      "grad_norm": 0.11259792745113373,
      "learning_rate": 3.57667036436556e-05,
      "loss": 0.002,
      "step": 33360
    },
    {
      "epoch": 2.8475125863981567,
      "grad_norm": 0.33163347840309143,
      "learning_rate": 3.576243706800922e-05,
      "loss": 0.0023,
      "step": 33370
    },
    {
      "epoch": 2.8483659015274343,
      "grad_norm": 0.5178037881851196,
      "learning_rate": 3.575817049236283e-05,
      "loss": 0.0017,
      "step": 33380
    },
    {
      "epoch": 2.8492192166567114,
      "grad_norm": 0.28058797121047974,
      "learning_rate": 3.575390391671645e-05,
      "loss": 0.0027,
      "step": 33390
    },
    {
      "epoch": 2.8500725317859885,
      "grad_norm": 0.0685412585735321,
      "learning_rate": 3.5749637341070056e-05,
      "loss": 0.002,
      "step": 33400
    },
    {
      "epoch": 2.850925846915266,
      "grad_norm": 0.2976551353931427,
      "learning_rate": 3.574537076542368e-05,
      "loss": 0.0017,
      "step": 33410
    },
    {
      "epoch": 2.851779162044543,
      "grad_norm": 0.31775057315826416,
      "learning_rate": 3.5741104189777285e-05,
      "loss": 0.0027,
      "step": 33420
    },
    {
      "epoch": 2.8526324771738203,
      "grad_norm": 0.2026459127664566,
      "learning_rate": 3.5736837614130906e-05,
      "loss": 0.0016,
      "step": 33430
    },
    {
      "epoch": 2.8534857923030974,
      "grad_norm": 0.25529274344444275,
      "learning_rate": 3.573257103848451e-05,
      "loss": 0.0014,
      "step": 33440
    },
    {
      "epoch": 2.8543391074323745,
      "grad_norm": 0.19136397540569305,
      "learning_rate": 3.572830446283813e-05,
      "loss": 0.0023,
      "step": 33450
    },
    {
      "epoch": 2.855192422561652,
      "grad_norm": 0.15268324315547943,
      "learning_rate": 3.572403788719174e-05,
      "loss": 0.0021,
      "step": 33460
    },
    {
      "epoch": 2.856045737690929,
      "grad_norm": 0.4321495294570923,
      "learning_rate": 3.5719771311545356e-05,
      "loss": 0.0022,
      "step": 33470
    },
    {
      "epoch": 2.8568990528202063,
      "grad_norm": 0.03622644767165184,
      "learning_rate": 3.571550473589897e-05,
      "loss": 0.0021,
      "step": 33480
    },
    {
      "epoch": 2.857752367949484,
      "grad_norm": 0.06052275002002716,
      "learning_rate": 3.571123816025258e-05,
      "loss": 0.0024,
      "step": 33490
    },
    {
      "epoch": 2.858605683078761,
      "grad_norm": 0.432271808385849,
      "learning_rate": 3.57069715846062e-05,
      "loss": 0.002,
      "step": 33500
    },
    {
      "epoch": 2.859458998208038,
      "grad_norm": 0.3683403730392456,
      "learning_rate": 3.5702705008959806e-05,
      "loss": 0.0025,
      "step": 33510
    },
    {
      "epoch": 2.8603123133373156,
      "grad_norm": 0.2453678995370865,
      "learning_rate": 3.569843843331343e-05,
      "loss": 0.0022,
      "step": 33520
    },
    {
      "epoch": 2.8611656284665927,
      "grad_norm": 0.17331472039222717,
      "learning_rate": 3.5694171857667034e-05,
      "loss": 0.0015,
      "step": 33530
    },
    {
      "epoch": 2.86201894359587,
      "grad_norm": 0.22532814741134644,
      "learning_rate": 3.5689905282020655e-05,
      "loss": 0.0024,
      "step": 33540
    },
    {
      "epoch": 2.8628722587251474,
      "grad_norm": 0.03561052307486534,
      "learning_rate": 3.568563870637426e-05,
      "loss": 0.0022,
      "step": 33550
    },
    {
      "epoch": 2.8637255738544245,
      "grad_norm": 0.15091335773468018,
      "learning_rate": 3.568137213072788e-05,
      "loss": 0.0022,
      "step": 33560
    },
    {
      "epoch": 2.8645788889837016,
      "grad_norm": 0.09337890893220901,
      "learning_rate": 3.567710555508149e-05,
      "loss": 0.0019,
      "step": 33570
    },
    {
      "epoch": 2.865432204112979,
      "grad_norm": 0.2940870225429535,
      "learning_rate": 3.5672838979435106e-05,
      "loss": 0.0019,
      "step": 33580
    },
    {
      "epoch": 2.8662855192422563,
      "grad_norm": 0.22197701036930084,
      "learning_rate": 3.566857240378872e-05,
      "loss": 0.0016,
      "step": 33590
    },
    {
      "epoch": 2.8671388343715334,
      "grad_norm": 0.3573295474052429,
      "learning_rate": 3.5664305828142334e-05,
      "loss": 0.0019,
      "step": 33600
    },
    {
      "epoch": 2.8679921495008105,
      "grad_norm": 0.09693445265293121,
      "learning_rate": 3.566003925249595e-05,
      "loss": 0.0021,
      "step": 33610
    },
    {
      "epoch": 2.868845464630088,
      "grad_norm": 0.04862347990274429,
      "learning_rate": 3.565577267684956e-05,
      "loss": 0.0021,
      "step": 33620
    },
    {
      "epoch": 2.869698779759365,
      "grad_norm": 0.19089443981647491,
      "learning_rate": 3.565150610120318e-05,
      "loss": 0.0022,
      "step": 33630
    },
    {
      "epoch": 2.8705520948886423,
      "grad_norm": 0.22262461483478546,
      "learning_rate": 3.564723952555679e-05,
      "loss": 0.002,
      "step": 33640
    },
    {
      "epoch": 2.8714054100179194,
      "grad_norm": 0.045105721801519394,
      "learning_rate": 3.5642972949910405e-05,
      "loss": 0.0018,
      "step": 33650
    },
    {
      "epoch": 2.872258725147197,
      "grad_norm": 0.1475418657064438,
      "learning_rate": 3.563870637426402e-05,
      "loss": 0.0016,
      "step": 33660
    },
    {
      "epoch": 2.873112040276474,
      "grad_norm": 0.1640263795852661,
      "learning_rate": 3.563443979861763e-05,
      "loss": 0.0032,
      "step": 33670
    },
    {
      "epoch": 2.873965355405751,
      "grad_norm": 0.2752533555030823,
      "learning_rate": 3.563017322297125e-05,
      "loss": 0.0019,
      "step": 33680
    },
    {
      "epoch": 2.8748186705350287,
      "grad_norm": 0.13197310268878937,
      "learning_rate": 3.5625906647324856e-05,
      "loss": 0.0017,
      "step": 33690
    },
    {
      "epoch": 2.875671985664306,
      "grad_norm": 0.10022523254156113,
      "learning_rate": 3.5621640071678477e-05,
      "loss": 0.0016,
      "step": 33700
    },
    {
      "epoch": 2.876525300793583,
      "grad_norm": 0.07857759296894073,
      "learning_rate": 3.5617373496032084e-05,
      "loss": 0.0017,
      "step": 33710
    },
    {
      "epoch": 2.8773786159228605,
      "grad_norm": 0.35234761238098145,
      "learning_rate": 3.5613106920385705e-05,
      "loss": 0.002,
      "step": 33720
    },
    {
      "epoch": 2.8782319310521376,
      "grad_norm": 0.4816477298736572,
      "learning_rate": 3.560884034473931e-05,
      "loss": 0.003,
      "step": 33730
    },
    {
      "epoch": 2.8790852461814147,
      "grad_norm": 0.5148094892501831,
      "learning_rate": 3.5604573769092934e-05,
      "loss": 0.0017,
      "step": 33740
    },
    {
      "epoch": 2.8799385613106923,
      "grad_norm": 0.1334298700094223,
      "learning_rate": 3.560030719344654e-05,
      "loss": 0.0021,
      "step": 33750
    },
    {
      "epoch": 2.8807918764399694,
      "grad_norm": 0.4494148790836334,
      "learning_rate": 3.5596040617800155e-05,
      "loss": 0.002,
      "step": 33760
    },
    {
      "epoch": 2.8816451915692465,
      "grad_norm": 0.27825844287872314,
      "learning_rate": 3.559177404215377e-05,
      "loss": 0.0019,
      "step": 33770
    },
    {
      "epoch": 2.882498506698524,
      "grad_norm": 0.24334721267223358,
      "learning_rate": 3.5587507466507384e-05,
      "loss": 0.0022,
      "step": 33780
    },
    {
      "epoch": 2.883351821827801,
      "grad_norm": 0.04857064411044121,
      "learning_rate": 3.5583240890861e-05,
      "loss": 0.0017,
      "step": 33790
    },
    {
      "epoch": 2.8842051369570783,
      "grad_norm": 0.23440620303153992,
      "learning_rate": 3.5578974315214605e-05,
      "loss": 0.0021,
      "step": 33800
    },
    {
      "epoch": 2.8850584520863554,
      "grad_norm": 0.2510845959186554,
      "learning_rate": 3.5574707739568226e-05,
      "loss": 0.0026,
      "step": 33810
    },
    {
      "epoch": 2.8859117672156325,
      "grad_norm": 0.3142370581626892,
      "learning_rate": 3.5570441163921834e-05,
      "loss": 0.0019,
      "step": 33820
    },
    {
      "epoch": 2.88676508234491,
      "grad_norm": 0.09892202168703079,
      "learning_rate": 3.5566174588275455e-05,
      "loss": 0.0017,
      "step": 33830
    },
    {
      "epoch": 2.887618397474187,
      "grad_norm": 0.27611345052719116,
      "learning_rate": 3.556190801262906e-05,
      "loss": 0.0027,
      "step": 33840
    },
    {
      "epoch": 2.8884717126034642,
      "grad_norm": 0.04982582479715347,
      "learning_rate": 3.5557641436982683e-05,
      "loss": 0.0017,
      "step": 33850
    },
    {
      "epoch": 2.889325027732742,
      "grad_norm": 0.24946890771389008,
      "learning_rate": 3.555337486133629e-05,
      "loss": 0.0018,
      "step": 33860
    },
    {
      "epoch": 2.890178342862019,
      "grad_norm": 0.41437816619873047,
      "learning_rate": 3.5549108285689905e-05,
      "loss": 0.0021,
      "step": 33870
    },
    {
      "epoch": 2.891031657991296,
      "grad_norm": 0.11762674897909164,
      "learning_rate": 3.554484171004352e-05,
      "loss": 0.0026,
      "step": 33880
    },
    {
      "epoch": 2.8918849731205736,
      "grad_norm": 0.3188667893409729,
      "learning_rate": 3.5540575134397134e-05,
      "loss": 0.0019,
      "step": 33890
    },
    {
      "epoch": 2.8927382882498507,
      "grad_norm": 0.4210544228553772,
      "learning_rate": 3.553630855875075e-05,
      "loss": 0.0018,
      "step": 33900
    },
    {
      "epoch": 2.893591603379128,
      "grad_norm": 0.2784811854362488,
      "learning_rate": 3.553204198310436e-05,
      "loss": 0.0019,
      "step": 33910
    },
    {
      "epoch": 2.8944449185084054,
      "grad_norm": 0.03708365187048912,
      "learning_rate": 3.5527775407457976e-05,
      "loss": 0.0018,
      "step": 33920
    },
    {
      "epoch": 2.8952982336376825,
      "grad_norm": 0.41118401288986206,
      "learning_rate": 3.552350883181159e-05,
      "loss": 0.0018,
      "step": 33930
    },
    {
      "epoch": 2.8961515487669596,
      "grad_norm": 0.1616067886352539,
      "learning_rate": 3.5519242256165205e-05,
      "loss": 0.0018,
      "step": 33940
    },
    {
      "epoch": 2.897004863896237,
      "grad_norm": 0.09752947837114334,
      "learning_rate": 3.551497568051882e-05,
      "loss": 0.0015,
      "step": 33950
    },
    {
      "epoch": 2.8978581790255142,
      "grad_norm": 0.5827706456184387,
      "learning_rate": 3.551070910487243e-05,
      "loss": 0.0019,
      "step": 33960
    },
    {
      "epoch": 2.8987114941547913,
      "grad_norm": 0.19906361401081085,
      "learning_rate": 3.550644252922605e-05,
      "loss": 0.0025,
      "step": 33970
    },
    {
      "epoch": 2.8995648092840685,
      "grad_norm": 0.18233786523342133,
      "learning_rate": 3.5502175953579655e-05,
      "loss": 0.0018,
      "step": 33980
    },
    {
      "epoch": 2.900418124413346,
      "grad_norm": 0.2548820674419403,
      "learning_rate": 3.5497909377933276e-05,
      "loss": 0.0023,
      "step": 33990
    },
    {
      "epoch": 2.901271439542623,
      "grad_norm": 0.48152557015419006,
      "learning_rate": 3.5493642802286883e-05,
      "loss": 0.0026,
      "step": 34000
    },
    {
      "epoch": 2.9021247546719002,
      "grad_norm": 0.41519272327423096,
      "learning_rate": 3.5489376226640504e-05,
      "loss": 0.0021,
      "step": 34010
    },
    {
      "epoch": 2.9029780698011773,
      "grad_norm": 0.44968852400779724,
      "learning_rate": 3.548510965099411e-05,
      "loss": 0.0017,
      "step": 34020
    },
    {
      "epoch": 2.903831384930455,
      "grad_norm": 0.05463599041104317,
      "learning_rate": 3.5480843075347726e-05,
      "loss": 0.002,
      "step": 34030
    },
    {
      "epoch": 2.904684700059732,
      "grad_norm": 0.1782679706811905,
      "learning_rate": 3.547657649970134e-05,
      "loss": 0.0017,
      "step": 34040
    },
    {
      "epoch": 2.905538015189009,
      "grad_norm": 0.2788650393486023,
      "learning_rate": 3.5472309924054955e-05,
      "loss": 0.0021,
      "step": 34050
    },
    {
      "epoch": 2.9063913303182867,
      "grad_norm": 0.20412516593933105,
      "learning_rate": 3.546804334840857e-05,
      "loss": 0.0019,
      "step": 34060
    },
    {
      "epoch": 2.907244645447564,
      "grad_norm": 0.31786614656448364,
      "learning_rate": 3.546377677276218e-05,
      "loss": 0.0024,
      "step": 34070
    },
    {
      "epoch": 2.908097960576841,
      "grad_norm": 0.2298940271139145,
      "learning_rate": 3.54595101971158e-05,
      "loss": 0.0021,
      "step": 34080
    },
    {
      "epoch": 2.9089512757061184,
      "grad_norm": 0.25049567222595215,
      "learning_rate": 3.545524362146941e-05,
      "loss": 0.0022,
      "step": 34090
    },
    {
      "epoch": 2.9098045908353956,
      "grad_norm": 0.06435388326644897,
      "learning_rate": 3.5450977045823026e-05,
      "loss": 0.0017,
      "step": 34100
    },
    {
      "epoch": 2.9106579059646727,
      "grad_norm": 0.1157149076461792,
      "learning_rate": 3.544671047017663e-05,
      "loss": 0.0017,
      "step": 34110
    },
    {
      "epoch": 2.91151122109395,
      "grad_norm": 0.2614472806453705,
      "learning_rate": 3.5442443894530254e-05,
      "loss": 0.002,
      "step": 34120
    },
    {
      "epoch": 2.9123645362232273,
      "grad_norm": 0.32401466369628906,
      "learning_rate": 3.543817731888386e-05,
      "loss": 0.0023,
      "step": 34130
    },
    {
      "epoch": 2.9132178513525044,
      "grad_norm": 0.18443623185157776,
      "learning_rate": 3.543391074323748e-05,
      "loss": 0.0022,
      "step": 34140
    },
    {
      "epoch": 2.914071166481782,
      "grad_norm": 0.2587604522705078,
      "learning_rate": 3.542964416759109e-05,
      "loss": 0.0023,
      "step": 34150
    },
    {
      "epoch": 2.914924481611059,
      "grad_norm": 0.1714034378528595,
      "learning_rate": 3.542537759194471e-05,
      "loss": 0.0018,
      "step": 34160
    },
    {
      "epoch": 2.915777796740336,
      "grad_norm": 0.20955953001976013,
      "learning_rate": 3.542111101629832e-05,
      "loss": 0.0018,
      "step": 34170
    },
    {
      "epoch": 2.9166311118696133,
      "grad_norm": 0.2077450454235077,
      "learning_rate": 3.541684444065193e-05,
      "loss": 0.0017,
      "step": 34180
    },
    {
      "epoch": 2.9174844269988904,
      "grad_norm": 0.32084399461746216,
      "learning_rate": 3.541257786500555e-05,
      "loss": 0.0019,
      "step": 34190
    },
    {
      "epoch": 2.918337742128168,
      "grad_norm": 0.1377367228269577,
      "learning_rate": 3.540831128935916e-05,
      "loss": 0.0023,
      "step": 34200
    },
    {
      "epoch": 2.919191057257445,
      "grad_norm": 0.1074843555688858,
      "learning_rate": 3.5404044713712776e-05,
      "loss": 0.0024,
      "step": 34210
    },
    {
      "epoch": 2.920044372386722,
      "grad_norm": 0.13180352747440338,
      "learning_rate": 3.539977813806639e-05,
      "loss": 0.0023,
      "step": 34220
    },
    {
      "epoch": 2.9208976875159998,
      "grad_norm": 0.22556811571121216,
      "learning_rate": 3.5395511562420004e-05,
      "loss": 0.0021,
      "step": 34230
    },
    {
      "epoch": 2.921751002645277,
      "grad_norm": 0.28374922275543213,
      "learning_rate": 3.539124498677362e-05,
      "loss": 0.0023,
      "step": 34240
    },
    {
      "epoch": 2.922604317774554,
      "grad_norm": 0.18928760290145874,
      "learning_rate": 3.538697841112723e-05,
      "loss": 0.002,
      "step": 34250
    },
    {
      "epoch": 2.9234576329038315,
      "grad_norm": 0.4685622453689575,
      "learning_rate": 3.538271183548085e-05,
      "loss": 0.0021,
      "step": 34260
    },
    {
      "epoch": 2.9243109480331086,
      "grad_norm": 0.2251940369606018,
      "learning_rate": 3.537844525983446e-05,
      "loss": 0.0023,
      "step": 34270
    },
    {
      "epoch": 2.9251642631623858,
      "grad_norm": 0.33669397234916687,
      "learning_rate": 3.5374178684188075e-05,
      "loss": 0.002,
      "step": 34280
    },
    {
      "epoch": 2.9260175782916633,
      "grad_norm": 0.09950271993875504,
      "learning_rate": 3.536991210854168e-05,
      "loss": 0.002,
      "step": 34290
    },
    {
      "epoch": 2.9268708934209404,
      "grad_norm": 0.1459389179944992,
      "learning_rate": 3.53656455328953e-05,
      "loss": 0.0022,
      "step": 34300
    },
    {
      "epoch": 2.9277242085502175,
      "grad_norm": 0.1150631234049797,
      "learning_rate": 3.536137895724891e-05,
      "loss": 0.0017,
      "step": 34310
    },
    {
      "epoch": 2.928577523679495,
      "grad_norm": 0.06875575333833694,
      "learning_rate": 3.5357112381602526e-05,
      "loss": 0.0017,
      "step": 34320
    },
    {
      "epoch": 2.929430838808772,
      "grad_norm": 0.1734337955713272,
      "learning_rate": 3.535284580595614e-05,
      "loss": 0.0028,
      "step": 34330
    },
    {
      "epoch": 2.9302841539380493,
      "grad_norm": 0.17293696105480194,
      "learning_rate": 3.5348579230309754e-05,
      "loss": 0.0016,
      "step": 34340
    },
    {
      "epoch": 2.9311374690673264,
      "grad_norm": 0.3684273064136505,
      "learning_rate": 3.534431265466337e-05,
      "loss": 0.0019,
      "step": 34350
    },
    {
      "epoch": 2.931990784196604,
      "grad_norm": 0.06097165495157242,
      "learning_rate": 3.534004607901698e-05,
      "loss": 0.0023,
      "step": 34360
    },
    {
      "epoch": 2.932844099325881,
      "grad_norm": 0.15279653668403625,
      "learning_rate": 3.53357795033706e-05,
      "loss": 0.0016,
      "step": 34370
    },
    {
      "epoch": 2.933697414455158,
      "grad_norm": 0.13819393515586853,
      "learning_rate": 3.533151292772421e-05,
      "loss": 0.0019,
      "step": 34380
    },
    {
      "epoch": 2.9345507295844353,
      "grad_norm": 0.19114388525485992,
      "learning_rate": 3.5327246352077825e-05,
      "loss": 0.0017,
      "step": 34390
    },
    {
      "epoch": 2.935404044713713,
      "grad_norm": 0.06036568060517311,
      "learning_rate": 3.532297977643144e-05,
      "loss": 0.0019,
      "step": 34400
    },
    {
      "epoch": 2.93625735984299,
      "grad_norm": 0.35808125138282776,
      "learning_rate": 3.5318713200785054e-05,
      "loss": 0.0022,
      "step": 34410
    },
    {
      "epoch": 2.937110674972267,
      "grad_norm": 0.1683337390422821,
      "learning_rate": 3.531444662513866e-05,
      "loss": 0.0018,
      "step": 34420
    },
    {
      "epoch": 2.9379639901015446,
      "grad_norm": 0.12146224081516266,
      "learning_rate": 3.531018004949228e-05,
      "loss": 0.0016,
      "step": 34430
    },
    {
      "epoch": 2.9388173052308217,
      "grad_norm": 0.2768751382827759,
      "learning_rate": 3.530591347384589e-05,
      "loss": 0.002,
      "step": 34440
    },
    {
      "epoch": 2.939670620360099,
      "grad_norm": 0.040157269686460495,
      "learning_rate": 3.530164689819951e-05,
      "loss": 0.0018,
      "step": 34450
    },
    {
      "epoch": 2.9405239354893764,
      "grad_norm": 0.08399897813796997,
      "learning_rate": 3.529738032255312e-05,
      "loss": 0.002,
      "step": 34460
    },
    {
      "epoch": 2.9413772506186535,
      "grad_norm": 0.24477794766426086,
      "learning_rate": 3.529311374690674e-05,
      "loss": 0.002,
      "step": 34470
    },
    {
      "epoch": 2.9422305657479306,
      "grad_norm": 0.4176274538040161,
      "learning_rate": 3.528884717126035e-05,
      "loss": 0.0024,
      "step": 34480
    },
    {
      "epoch": 2.943083880877208,
      "grad_norm": 0.06125732883810997,
      "learning_rate": 3.528458059561396e-05,
      "loss": 0.0018,
      "step": 34490
    },
    {
      "epoch": 2.9439371960064853,
      "grad_norm": 0.22849638760089874,
      "learning_rate": 3.5280314019967575e-05,
      "loss": 0.0022,
      "step": 34500
    },
    {
      "epoch": 2.9447905111357624,
      "grad_norm": 0.27872923016548157,
      "learning_rate": 3.527604744432119e-05,
      "loss": 0.0021,
      "step": 34510
    },
    {
      "epoch": 2.94564382626504,
      "grad_norm": 0.07821162045001984,
      "learning_rate": 3.5271780868674804e-05,
      "loss": 0.002,
      "step": 34520
    },
    {
      "epoch": 2.946497141394317,
      "grad_norm": 0.07985063642263412,
      "learning_rate": 3.526751429302842e-05,
      "loss": 0.0019,
      "step": 34530
    },
    {
      "epoch": 2.947350456523594,
      "grad_norm": 0.14885835349559784,
      "learning_rate": 3.526324771738203e-05,
      "loss": 0.0026,
      "step": 34540
    },
    {
      "epoch": 2.9482037716528713,
      "grad_norm": 0.1379907727241516,
      "learning_rate": 3.525898114173564e-05,
      "loss": 0.0016,
      "step": 34550
    },
    {
      "epoch": 2.9490570867821484,
      "grad_norm": 0.427958220243454,
      "learning_rate": 3.525471456608926e-05,
      "loss": 0.0022,
      "step": 34560
    },
    {
      "epoch": 2.949910401911426,
      "grad_norm": 0.10603628307580948,
      "learning_rate": 3.525044799044287e-05,
      "loss": 0.0023,
      "step": 34570
    },
    {
      "epoch": 2.950763717040703,
      "grad_norm": 0.13108336925506592,
      "learning_rate": 3.524618141479649e-05,
      "loss": 0.0017,
      "step": 34580
    },
    {
      "epoch": 2.95161703216998,
      "grad_norm": 0.15464970469474792,
      "learning_rate": 3.5241914839150097e-05,
      "loss": 0.0015,
      "step": 34590
    },
    {
      "epoch": 2.9524703472992577,
      "grad_norm": 0.26426422595977783,
      "learning_rate": 3.523764826350371e-05,
      "loss": 0.0022,
      "step": 34600
    },
    {
      "epoch": 2.953323662428535,
      "grad_norm": 0.03493277356028557,
      "learning_rate": 3.5233381687857325e-05,
      "loss": 0.0025,
      "step": 34610
    },
    {
      "epoch": 2.954176977557812,
      "grad_norm": 0.10008472949266434,
      "learning_rate": 3.522911511221094e-05,
      "loss": 0.002,
      "step": 34620
    },
    {
      "epoch": 2.9550302926870895,
      "grad_norm": 0.031083742156624794,
      "learning_rate": 3.5224848536564554e-05,
      "loss": 0.0021,
      "step": 34630
    },
    {
      "epoch": 2.9558836078163666,
      "grad_norm": 0.03679502010345459,
      "learning_rate": 3.522058196091817e-05,
      "loss": 0.0018,
      "step": 34640
    },
    {
      "epoch": 2.9567369229456437,
      "grad_norm": 0.15037231147289276,
      "learning_rate": 3.521631538527178e-05,
      "loss": 0.0022,
      "step": 34650
    },
    {
      "epoch": 2.9575902380749213,
      "grad_norm": 0.1849469095468521,
      "learning_rate": 3.5212048809625396e-05,
      "loss": 0.002,
      "step": 34660
    },
    {
      "epoch": 2.9584435532041984,
      "grad_norm": 0.2699553072452545,
      "learning_rate": 3.520778223397901e-05,
      "loss": 0.0018,
      "step": 34670
    },
    {
      "epoch": 2.9592968683334755,
      "grad_norm": 0.20851701498031616,
      "learning_rate": 3.5203515658332625e-05,
      "loss": 0.0022,
      "step": 34680
    },
    {
      "epoch": 2.960150183462753,
      "grad_norm": 0.24389885365962982,
      "learning_rate": 3.519924908268624e-05,
      "loss": 0.0025,
      "step": 34690
    },
    {
      "epoch": 2.96100349859203,
      "grad_norm": 0.3257530927658081,
      "learning_rate": 3.519498250703985e-05,
      "loss": 0.0024,
      "step": 34700
    },
    {
      "epoch": 2.9618568137213073,
      "grad_norm": 0.27317848801612854,
      "learning_rate": 3.519071593139347e-05,
      "loss": 0.0022,
      "step": 34710
    },
    {
      "epoch": 2.9627101288505844,
      "grad_norm": 0.28435811400413513,
      "learning_rate": 3.518644935574708e-05,
      "loss": 0.0015,
      "step": 34720
    },
    {
      "epoch": 2.9635634439798615,
      "grad_norm": 0.30112555623054504,
      "learning_rate": 3.518218278010069e-05,
      "loss": 0.0018,
      "step": 34730
    },
    {
      "epoch": 2.964416759109139,
      "grad_norm": 0.09053697437047958,
      "learning_rate": 3.517791620445431e-05,
      "loss": 0.0021,
      "step": 34740
    },
    {
      "epoch": 2.965270074238416,
      "grad_norm": 0.14555279910564423,
      "learning_rate": 3.517364962880792e-05,
      "loss": 0.0017,
      "step": 34750
    },
    {
      "epoch": 2.9661233893676933,
      "grad_norm": 0.633400022983551,
      "learning_rate": 3.516938305316154e-05,
      "loss": 0.0025,
      "step": 34760
    },
    {
      "epoch": 2.966976704496971,
      "grad_norm": 0.24125559628009796,
      "learning_rate": 3.5165116477515146e-05,
      "loss": 0.0022,
      "step": 34770
    },
    {
      "epoch": 2.967830019626248,
      "grad_norm": 0.1660529375076294,
      "learning_rate": 3.516084990186877e-05,
      "loss": 0.0023,
      "step": 34780
    },
    {
      "epoch": 2.968683334755525,
      "grad_norm": 0.08318564295768738,
      "learning_rate": 3.5156583326222375e-05,
      "loss": 0.0018,
      "step": 34790
    },
    {
      "epoch": 2.9695366498848026,
      "grad_norm": 0.11044847220182419,
      "learning_rate": 3.515231675057599e-05,
      "loss": 0.0023,
      "step": 34800
    },
    {
      "epoch": 2.9703899650140797,
      "grad_norm": 0.41228413581848145,
      "learning_rate": 3.51480501749296e-05,
      "loss": 0.0023,
      "step": 34810
    },
    {
      "epoch": 2.971243280143357,
      "grad_norm": 0.1380024254322052,
      "learning_rate": 3.514378359928322e-05,
      "loss": 0.0018,
      "step": 34820
    },
    {
      "epoch": 2.9720965952726344,
      "grad_norm": 0.4493650496006012,
      "learning_rate": 3.513951702363683e-05,
      "loss": 0.0016,
      "step": 34830
    },
    {
      "epoch": 2.9729499104019115,
      "grad_norm": 0.2375829666852951,
      "learning_rate": 3.513525044799044e-05,
      "loss": 0.002,
      "step": 34840
    },
    {
      "epoch": 2.9738032255311886,
      "grad_norm": 0.03396693617105484,
      "learning_rate": 3.513098387234406e-05,
      "loss": 0.0017,
      "step": 34850
    },
    {
      "epoch": 2.974656540660466,
      "grad_norm": 0.15169715881347656,
      "learning_rate": 3.512671729669767e-05,
      "loss": 0.002,
      "step": 34860
    },
    {
      "epoch": 2.9755098557897433,
      "grad_norm": 0.17187131941318512,
      "learning_rate": 3.512245072105129e-05,
      "loss": 0.0017,
      "step": 34870
    },
    {
      "epoch": 2.9763631709190204,
      "grad_norm": 0.22609005868434906,
      "learning_rate": 3.5118184145404896e-05,
      "loss": 0.002,
      "step": 34880
    },
    {
      "epoch": 2.9772164860482975,
      "grad_norm": 0.3495691418647766,
      "learning_rate": 3.511391756975852e-05,
      "loss": 0.0018,
      "step": 34890
    },
    {
      "epoch": 2.978069801177575,
      "grad_norm": 0.21343819797039032,
      "learning_rate": 3.5109650994112124e-05,
      "loss": 0.0017,
      "step": 34900
    },
    {
      "epoch": 2.978923116306852,
      "grad_norm": 0.024733977392315865,
      "learning_rate": 3.510538441846574e-05,
      "loss": 0.0024,
      "step": 34910
    },
    {
      "epoch": 2.9797764314361292,
      "grad_norm": 0.09590305387973785,
      "learning_rate": 3.510111784281935e-05,
      "loss": 0.003,
      "step": 34920
    },
    {
      "epoch": 2.9806297465654064,
      "grad_norm": 0.099063441157341,
      "learning_rate": 3.509685126717297e-05,
      "loss": 0.002,
      "step": 34930
    },
    {
      "epoch": 2.981483061694684,
      "grad_norm": 0.0627121776342392,
      "learning_rate": 3.509258469152658e-05,
      "loss": 0.0017,
      "step": 34940
    },
    {
      "epoch": 2.982336376823961,
      "grad_norm": 0.19196069240570068,
      "learning_rate": 3.5088318115880196e-05,
      "loss": 0.002,
      "step": 34950
    },
    {
      "epoch": 2.983189691953238,
      "grad_norm": 0.22300603985786438,
      "learning_rate": 3.508405154023381e-05,
      "loss": 0.0023,
      "step": 34960
    },
    {
      "epoch": 2.9840430070825157,
      "grad_norm": 0.4044744074344635,
      "learning_rate": 3.5079784964587424e-05,
      "loss": 0.0027,
      "step": 34970
    },
    {
      "epoch": 2.984896322211793,
      "grad_norm": 0.4001900851726532,
      "learning_rate": 3.507551838894104e-05,
      "loss": 0.0027,
      "step": 34980
    },
    {
      "epoch": 2.98574963734107,
      "grad_norm": 0.4444677531719208,
      "learning_rate": 3.507125181329465e-05,
      "loss": 0.0025,
      "step": 34990
    },
    {
      "epoch": 2.9866029524703475,
      "grad_norm": 0.3981612026691437,
      "learning_rate": 3.506698523764827e-05,
      "loss": 0.0025,
      "step": 35000
    },
    {
      "epoch": 2.9874562675996246,
      "grad_norm": 0.0752829983830452,
      "learning_rate": 3.506271866200188e-05,
      "loss": 0.0022,
      "step": 35010
    },
    {
      "epoch": 2.9883095827289017,
      "grad_norm": 0.13093388080596924,
      "learning_rate": 3.5058452086355495e-05,
      "loss": 0.0019,
      "step": 35020
    },
    {
      "epoch": 2.9891628978581792,
      "grad_norm": 0.28974923491477966,
      "learning_rate": 3.505418551070911e-05,
      "loss": 0.0016,
      "step": 35030
    },
    {
      "epoch": 2.9900162129874563,
      "grad_norm": 0.12958478927612305,
      "learning_rate": 3.504991893506272e-05,
      "loss": 0.0023,
      "step": 35040
    },
    {
      "epoch": 2.9908695281167335,
      "grad_norm": 0.4355553686618805,
      "learning_rate": 3.504565235941634e-05,
      "loss": 0.0016,
      "step": 35050
    },
    {
      "epoch": 2.991722843246011,
      "grad_norm": 0.1778954565525055,
      "learning_rate": 3.5041385783769946e-05,
      "loss": 0.002,
      "step": 35060
    },
    {
      "epoch": 2.992576158375288,
      "grad_norm": 0.23646993935108185,
      "learning_rate": 3.5037119208123567e-05,
      "loss": 0.0021,
      "step": 35070
    },
    {
      "epoch": 2.9934294735045652,
      "grad_norm": 0.13740912079811096,
      "learning_rate": 3.5032852632477174e-05,
      "loss": 0.0017,
      "step": 35080
    },
    {
      "epoch": 2.9942827886338423,
      "grad_norm": 0.25718316435813904,
      "learning_rate": 3.502858605683079e-05,
      "loss": 0.0022,
      "step": 35090
    },
    {
      "epoch": 2.9951361037631195,
      "grad_norm": 0.3385649621486664,
      "learning_rate": 3.50243194811844e-05,
      "loss": 0.0019,
      "step": 35100
    },
    {
      "epoch": 2.995989418892397,
      "grad_norm": 0.1882455050945282,
      "learning_rate": 3.502005290553802e-05,
      "loss": 0.0018,
      "step": 35110
    },
    {
      "epoch": 2.996842734021674,
      "grad_norm": 0.23598363995552063,
      "learning_rate": 3.501578632989163e-05,
      "loss": 0.0023,
      "step": 35120
    },
    {
      "epoch": 2.9976960491509512,
      "grad_norm": 0.11540213972330093,
      "learning_rate": 3.5011519754245245e-05,
      "loss": 0.0023,
      "step": 35130
    },
    {
      "epoch": 2.998549364280229,
      "grad_norm": 0.31521424651145935,
      "learning_rate": 3.500725317859886e-05,
      "loss": 0.002,
      "step": 35140
    },
    {
      "epoch": 2.999402679409506,
      "grad_norm": 0.07758353650569916,
      "learning_rate": 3.500298660295247e-05,
      "loss": 0.0018,
      "step": 35150
    },
    {
      "epoch": 3.0,
      "eval_loss": 0.002071832539513707,
      "eval_runtime": 98.2848,
      "eval_samples_per_second": 1526.177,
      "eval_steps_per_second": 23.849,
      "step": 35157
    },
    {
      "epoch": 3.000255994538783,
      "grad_norm": 0.17079675197601318,
      "learning_rate": 3.499872002730609e-05,
      "loss": 0.0026,
      "step": 35160
    },
    {
      "epoch": 3.0011093096680606,
      "grad_norm": 0.16091923415660858,
      "learning_rate": 3.4994453451659695e-05,
      "loss": 0.0017,
      "step": 35170
    },
    {
      "epoch": 3.0019626247973377,
      "grad_norm": 0.40460702776908875,
      "learning_rate": 3.4990186876013316e-05,
      "loss": 0.0018,
      "step": 35180
    },
    {
      "epoch": 3.0028159399266148,
      "grad_norm": 0.4370710551738739,
      "learning_rate": 3.4985920300366924e-05,
      "loss": 0.002,
      "step": 35190
    },
    {
      "epoch": 3.0036692550558923,
      "grad_norm": 0.19679684937000275,
      "learning_rate": 3.4981653724720545e-05,
      "loss": 0.0024,
      "step": 35200
    },
    {
      "epoch": 3.0045225701851694,
      "grad_norm": 0.24111050367355347,
      "learning_rate": 3.497738714907415e-05,
      "loss": 0.0022,
      "step": 35210
    },
    {
      "epoch": 3.0053758853144465,
      "grad_norm": 0.25863102078437805,
      "learning_rate": 3.4973120573427773e-05,
      "loss": 0.0017,
      "step": 35220
    },
    {
      "epoch": 3.0062292004437237,
      "grad_norm": 0.2026134729385376,
      "learning_rate": 3.496885399778138e-05,
      "loss": 0.0023,
      "step": 35230
    },
    {
      "epoch": 3.007082515573001,
      "grad_norm": 0.10245159268379211,
      "learning_rate": 3.4964587422134995e-05,
      "loss": 0.0022,
      "step": 35240
    },
    {
      "epoch": 3.0079358307022783,
      "grad_norm": 0.0628499835729599,
      "learning_rate": 3.496032084648861e-05,
      "loss": 0.0017,
      "step": 35250
    },
    {
      "epoch": 3.0087891458315554,
      "grad_norm": 0.04986588656902313,
      "learning_rate": 3.4956054270842224e-05,
      "loss": 0.0022,
      "step": 35260
    },
    {
      "epoch": 3.009642460960833,
      "grad_norm": 0.08763934671878815,
      "learning_rate": 3.495178769519584e-05,
      "loss": 0.0018,
      "step": 35270
    },
    {
      "epoch": 3.01049577609011,
      "grad_norm": 0.21765901148319244,
      "learning_rate": 3.494752111954945e-05,
      "loss": 0.0017,
      "step": 35280
    },
    {
      "epoch": 3.011349091219387,
      "grad_norm": 0.30040618777275085,
      "learning_rate": 3.4943254543903066e-05,
      "loss": 0.0018,
      "step": 35290
    },
    {
      "epoch": 3.0122024063486648,
      "grad_norm": 0.030269211158156395,
      "learning_rate": 3.493898796825668e-05,
      "loss": 0.0019,
      "step": 35300
    },
    {
      "epoch": 3.013055721477942,
      "grad_norm": 0.07291393727064133,
      "learning_rate": 3.4934721392610295e-05,
      "loss": 0.0023,
      "step": 35310
    },
    {
      "epoch": 3.013909036607219,
      "grad_norm": 0.3516088128089905,
      "learning_rate": 3.493045481696391e-05,
      "loss": 0.0016,
      "step": 35320
    },
    {
      "epoch": 3.014762351736496,
      "grad_norm": 0.15256613492965698,
      "learning_rate": 3.492618824131752e-05,
      "loss": 0.0019,
      "step": 35330
    },
    {
      "epoch": 3.0156156668657736,
      "grad_norm": 0.13504545390605927,
      "learning_rate": 3.492192166567114e-05,
      "loss": 0.0021,
      "step": 35340
    },
    {
      "epoch": 3.0164689819950508,
      "grad_norm": 0.2840922176837921,
      "learning_rate": 3.4917655090024745e-05,
      "loss": 0.0027,
      "step": 35350
    },
    {
      "epoch": 3.017322297124328,
      "grad_norm": 0.3025372326374054,
      "learning_rate": 3.491338851437836e-05,
      "loss": 0.0026,
      "step": 35360
    },
    {
      "epoch": 3.0181756122536054,
      "grad_norm": 0.17315040528774261,
      "learning_rate": 3.4909121938731973e-05,
      "loss": 0.0021,
      "step": 35370
    },
    {
      "epoch": 3.0190289273828825,
      "grad_norm": 0.2834444046020508,
      "learning_rate": 3.490485536308559e-05,
      "loss": 0.0018,
      "step": 35380
    },
    {
      "epoch": 3.0198822425121596,
      "grad_norm": 0.2504185736179352,
      "learning_rate": 3.49005887874392e-05,
      "loss": 0.0022,
      "step": 35390
    },
    {
      "epoch": 3.020735557641437,
      "grad_norm": 0.10279358923435211,
      "learning_rate": 3.4896322211792816e-05,
      "loss": 0.0018,
      "step": 35400
    },
    {
      "epoch": 3.0215888727707143,
      "grad_norm": 0.04138687998056412,
      "learning_rate": 3.489205563614643e-05,
      "loss": 0.0023,
      "step": 35410
    },
    {
      "epoch": 3.0224421878999914,
      "grad_norm": 0.05194498971104622,
      "learning_rate": 3.4887789060500045e-05,
      "loss": 0.0017,
      "step": 35420
    },
    {
      "epoch": 3.0232955030292685,
      "grad_norm": 0.4319237172603607,
      "learning_rate": 3.488352248485366e-05,
      "loss": 0.0025,
      "step": 35430
    },
    {
      "epoch": 3.024148818158546,
      "grad_norm": 0.46971142292022705,
      "learning_rate": 3.487925590920727e-05,
      "loss": 0.0024,
      "step": 35440
    },
    {
      "epoch": 3.025002133287823,
      "grad_norm": 0.13246019184589386,
      "learning_rate": 3.487498933356089e-05,
      "loss": 0.0018,
      "step": 35450
    },
    {
      "epoch": 3.0258554484171003,
      "grad_norm": 0.13375265896320343,
      "learning_rate": 3.4870722757914495e-05,
      "loss": 0.0024,
      "step": 35460
    },
    {
      "epoch": 3.026708763546378,
      "grad_norm": 0.4257650077342987,
      "learning_rate": 3.4866456182268116e-05,
      "loss": 0.0014,
      "step": 35470
    },
    {
      "epoch": 3.027562078675655,
      "grad_norm": 0.1730862259864807,
      "learning_rate": 3.486218960662172e-05,
      "loss": 0.0019,
      "step": 35480
    },
    {
      "epoch": 3.028415393804932,
      "grad_norm": 0.09681688249111176,
      "learning_rate": 3.4857923030975344e-05,
      "loss": 0.0022,
      "step": 35490
    },
    {
      "epoch": 3.029268708934209,
      "grad_norm": 0.29561474919319153,
      "learning_rate": 3.485365645532895e-05,
      "loss": 0.0022,
      "step": 35500
    },
    {
      "epoch": 3.0301220240634867,
      "grad_norm": 0.3574409484863281,
      "learning_rate": 3.484938987968257e-05,
      "loss": 0.0016,
      "step": 35510
    },
    {
      "epoch": 3.030975339192764,
      "grad_norm": 0.2735045552253723,
      "learning_rate": 3.484512330403618e-05,
      "loss": 0.0023,
      "step": 35520
    },
    {
      "epoch": 3.031828654322041,
      "grad_norm": 0.08017758280038834,
      "learning_rate": 3.48408567283898e-05,
      "loss": 0.0017,
      "step": 35530
    },
    {
      "epoch": 3.0326819694513185,
      "grad_norm": 0.522233247756958,
      "learning_rate": 3.483659015274341e-05,
      "loss": 0.0016,
      "step": 35540
    },
    {
      "epoch": 3.0335352845805956,
      "grad_norm": 0.0734759122133255,
      "learning_rate": 3.483232357709702e-05,
      "loss": 0.0021,
      "step": 35550
    },
    {
      "epoch": 3.0343885997098727,
      "grad_norm": 0.11628817766904831,
      "learning_rate": 3.482805700145064e-05,
      "loss": 0.0019,
      "step": 35560
    },
    {
      "epoch": 3.0352419148391503,
      "grad_norm": 0.05180290713906288,
      "learning_rate": 3.482379042580425e-05,
      "loss": 0.0024,
      "step": 35570
    },
    {
      "epoch": 3.0360952299684274,
      "grad_norm": 0.08113865554332733,
      "learning_rate": 3.4819523850157866e-05,
      "loss": 0.0015,
      "step": 35580
    },
    {
      "epoch": 3.0369485450977045,
      "grad_norm": 0.2130124717950821,
      "learning_rate": 3.481525727451148e-05,
      "loss": 0.0018,
      "step": 35590
    },
    {
      "epoch": 3.0378018602269816,
      "grad_norm": 0.052010778337717056,
      "learning_rate": 3.4810990698865094e-05,
      "loss": 0.002,
      "step": 35600
    },
    {
      "epoch": 3.038655175356259,
      "grad_norm": 0.059105727821588516,
      "learning_rate": 3.48067241232187e-05,
      "loss": 0.0018,
      "step": 35610
    },
    {
      "epoch": 3.0395084904855363,
      "grad_norm": 0.20005595684051514,
      "learning_rate": 3.480245754757232e-05,
      "loss": 0.0018,
      "step": 35620
    },
    {
      "epoch": 3.0403618056148134,
      "grad_norm": 0.04710795730352402,
      "learning_rate": 3.479819097192593e-05,
      "loss": 0.0022,
      "step": 35630
    },
    {
      "epoch": 3.041215120744091,
      "grad_norm": 0.06924446672201157,
      "learning_rate": 3.479392439627955e-05,
      "loss": 0.0019,
      "step": 35640
    },
    {
      "epoch": 3.042068435873368,
      "grad_norm": 0.1128639504313469,
      "learning_rate": 3.478965782063316e-05,
      "loss": 0.0022,
      "step": 35650
    },
    {
      "epoch": 3.042921751002645,
      "grad_norm": 0.3583645224571228,
      "learning_rate": 3.478539124498677e-05,
      "loss": 0.0026,
      "step": 35660
    },
    {
      "epoch": 3.0437750661319227,
      "grad_norm": 0.2633398771286011,
      "learning_rate": 3.478112466934039e-05,
      "loss": 0.0017,
      "step": 35670
    },
    {
      "epoch": 3.0446283812612,
      "grad_norm": 0.2081611305475235,
      "learning_rate": 3.4776858093694e-05,
      "loss": 0.0016,
      "step": 35680
    },
    {
      "epoch": 3.045481696390477,
      "grad_norm": 0.14015910029411316,
      "learning_rate": 3.4772591518047616e-05,
      "loss": 0.002,
      "step": 35690
    },
    {
      "epoch": 3.046335011519754,
      "grad_norm": 0.3744528293609619,
      "learning_rate": 3.476832494240123e-05,
      "loss": 0.0024,
      "step": 35700
    },
    {
      "epoch": 3.0471883266490316,
      "grad_norm": 0.1013999879360199,
      "learning_rate": 3.4764058366754844e-05,
      "loss": 0.0021,
      "step": 35710
    },
    {
      "epoch": 3.0480416417783087,
      "grad_norm": 0.17229196429252625,
      "learning_rate": 3.475979179110846e-05,
      "loss": 0.0018,
      "step": 35720
    },
    {
      "epoch": 3.048894956907586,
      "grad_norm": 0.3218538761138916,
      "learning_rate": 3.475552521546207e-05,
      "loss": 0.0021,
      "step": 35730
    },
    {
      "epoch": 3.0497482720368634,
      "grad_norm": 0.03504335135221481,
      "learning_rate": 3.475125863981569e-05,
      "loss": 0.002,
      "step": 35740
    },
    {
      "epoch": 3.0506015871661405,
      "grad_norm": 0.11480674892663956,
      "learning_rate": 3.47469920641693e-05,
      "loss": 0.0021,
      "step": 35750
    },
    {
      "epoch": 3.0514549022954176,
      "grad_norm": 0.13114725053310394,
      "learning_rate": 3.4742725488522915e-05,
      "loss": 0.0025,
      "step": 35760
    },
    {
      "epoch": 3.052308217424695,
      "grad_norm": 0.22578446567058563,
      "learning_rate": 3.473845891287652e-05,
      "loss": 0.0019,
      "step": 35770
    },
    {
      "epoch": 3.0531615325539723,
      "grad_norm": 0.06564775854349136,
      "learning_rate": 3.4734192337230144e-05,
      "loss": 0.0026,
      "step": 35780
    },
    {
      "epoch": 3.0540148476832494,
      "grad_norm": 0.43997350335121155,
      "learning_rate": 3.472992576158375e-05,
      "loss": 0.0023,
      "step": 35790
    },
    {
      "epoch": 3.0548681628125265,
      "grad_norm": 0.2467060685157776,
      "learning_rate": 3.472565918593737e-05,
      "loss": 0.0025,
      "step": 35800
    },
    {
      "epoch": 3.055721477941804,
      "grad_norm": 0.13811029493808746,
      "learning_rate": 3.472139261029098e-05,
      "loss": 0.0021,
      "step": 35810
    },
    {
      "epoch": 3.056574793071081,
      "grad_norm": 0.06576518714427948,
      "learning_rate": 3.47171260346446e-05,
      "loss": 0.0017,
      "step": 35820
    },
    {
      "epoch": 3.0574281082003583,
      "grad_norm": 0.05957408621907234,
      "learning_rate": 3.471285945899821e-05,
      "loss": 0.0017,
      "step": 35830
    },
    {
      "epoch": 3.058281423329636,
      "grad_norm": 0.26396098732948303,
      "learning_rate": 3.470859288335183e-05,
      "loss": 0.002,
      "step": 35840
    },
    {
      "epoch": 3.059134738458913,
      "grad_norm": 0.13257911801338196,
      "learning_rate": 3.470432630770544e-05,
      "loss": 0.0017,
      "step": 35850
    },
    {
      "epoch": 3.05998805358819,
      "grad_norm": 0.2246927171945572,
      "learning_rate": 3.470005973205905e-05,
      "loss": 0.0019,
      "step": 35860
    },
    {
      "epoch": 3.060841368717467,
      "grad_norm": 0.1878398060798645,
      "learning_rate": 3.4695793156412665e-05,
      "loss": 0.0022,
      "step": 35870
    },
    {
      "epoch": 3.0616946838467447,
      "grad_norm": 0.2678288221359253,
      "learning_rate": 3.469152658076627e-05,
      "loss": 0.0019,
      "step": 35880
    },
    {
      "epoch": 3.062547998976022,
      "grad_norm": 0.0310593880712986,
      "learning_rate": 3.4687260005119894e-05,
      "loss": 0.0019,
      "step": 35890
    },
    {
      "epoch": 3.063401314105299,
      "grad_norm": 0.30028867721557617,
      "learning_rate": 3.46829934294735e-05,
      "loss": 0.0022,
      "step": 35900
    },
    {
      "epoch": 3.0642546292345765,
      "grad_norm": 0.0690445601940155,
      "learning_rate": 3.467872685382712e-05,
      "loss": 0.0018,
      "step": 35910
    },
    {
      "epoch": 3.0651079443638536,
      "grad_norm": 0.256191223859787,
      "learning_rate": 3.467446027818073e-05,
      "loss": 0.0026,
      "step": 35920
    },
    {
      "epoch": 3.0659612594931307,
      "grad_norm": 0.11428839713335037,
      "learning_rate": 3.467019370253435e-05,
      "loss": 0.0022,
      "step": 35930
    },
    {
      "epoch": 3.0668145746224083,
      "grad_norm": 0.20412488281726837,
      "learning_rate": 3.466592712688796e-05,
      "loss": 0.0019,
      "step": 35940
    },
    {
      "epoch": 3.0676678897516854,
      "grad_norm": 0.12133872509002686,
      "learning_rate": 3.466166055124158e-05,
      "loss": 0.0021,
      "step": 35950
    },
    {
      "epoch": 3.0685212048809625,
      "grad_norm": 0.31960251927375793,
      "learning_rate": 3.4657393975595187e-05,
      "loss": 0.0019,
      "step": 35960
    },
    {
      "epoch": 3.0693745200102396,
      "grad_norm": 0.6157509088516235,
      "learning_rate": 3.46531273999488e-05,
      "loss": 0.002,
      "step": 35970
    },
    {
      "epoch": 3.070227835139517,
      "grad_norm": 0.2082301527261734,
      "learning_rate": 3.4648860824302415e-05,
      "loss": 0.0016,
      "step": 35980
    },
    {
      "epoch": 3.0710811502687942,
      "grad_norm": 0.03009205311536789,
      "learning_rate": 3.464459424865603e-05,
      "loss": 0.0019,
      "step": 35990
    },
    {
      "epoch": 3.0719344653980714,
      "grad_norm": 0.020875243470072746,
      "learning_rate": 3.4640327673009644e-05,
      "loss": 0.0023,
      "step": 36000
    },
    {
      "epoch": 3.072787780527349,
      "grad_norm": 0.24636107683181763,
      "learning_rate": 3.463606109736326e-05,
      "loss": 0.0019,
      "step": 36010
    },
    {
      "epoch": 3.073641095656626,
      "grad_norm": 0.28662770986557007,
      "learning_rate": 3.463179452171687e-05,
      "loss": 0.0022,
      "step": 36020
    },
    {
      "epoch": 3.074494410785903,
      "grad_norm": 0.4097265601158142,
      "learning_rate": 3.4627527946070486e-05,
      "loss": 0.0014,
      "step": 36030
    },
    {
      "epoch": 3.0753477259151807,
      "grad_norm": 0.3027690052986145,
      "learning_rate": 3.46232613704241e-05,
      "loss": 0.0021,
      "step": 36040
    },
    {
      "epoch": 3.076201041044458,
      "grad_norm": 0.1595153957605362,
      "learning_rate": 3.4618994794777715e-05,
      "loss": 0.0021,
      "step": 36050
    },
    {
      "epoch": 3.077054356173735,
      "grad_norm": 0.5004863142967224,
      "learning_rate": 3.461472821913133e-05,
      "loss": 0.0017,
      "step": 36060
    },
    {
      "epoch": 3.077907671303012,
      "grad_norm": 0.12445051968097687,
      "learning_rate": 3.461046164348494e-05,
      "loss": 0.0012,
      "step": 36070
    },
    {
      "epoch": 3.0787609864322896,
      "grad_norm": 0.05021470785140991,
      "learning_rate": 3.460619506783855e-05,
      "loss": 0.0024,
      "step": 36080
    },
    {
      "epoch": 3.0796143015615667,
      "grad_norm": 0.032266467809677124,
      "learning_rate": 3.460192849219217e-05,
      "loss": 0.0019,
      "step": 36090
    },
    {
      "epoch": 3.080467616690844,
      "grad_norm": 0.4235135614871979,
      "learning_rate": 3.459766191654578e-05,
      "loss": 0.0018,
      "step": 36100
    },
    {
      "epoch": 3.0813209318201213,
      "grad_norm": 0.23026522994041443,
      "learning_rate": 3.45933953408994e-05,
      "loss": 0.0015,
      "step": 36110
    },
    {
      "epoch": 3.0821742469493985,
      "grad_norm": 0.048501089215278625,
      "learning_rate": 3.458912876525301e-05,
      "loss": 0.0024,
      "step": 36120
    },
    {
      "epoch": 3.0830275620786756,
      "grad_norm": 0.17180760204792023,
      "learning_rate": 3.458486218960663e-05,
      "loss": 0.0017,
      "step": 36130
    },
    {
      "epoch": 3.083880877207953,
      "grad_norm": 0.06722446531057358,
      "learning_rate": 3.4580595613960236e-05,
      "loss": 0.0016,
      "step": 36140
    },
    {
      "epoch": 3.0847341923372302,
      "grad_norm": 0.17314760386943817,
      "learning_rate": 3.457632903831385e-05,
      "loss": 0.0021,
      "step": 36150
    },
    {
      "epoch": 3.0855875074665073,
      "grad_norm": 0.1453947275876999,
      "learning_rate": 3.4572062462667465e-05,
      "loss": 0.002,
      "step": 36160
    },
    {
      "epoch": 3.0864408225957845,
      "grad_norm": 0.28368324041366577,
      "learning_rate": 3.456779588702108e-05,
      "loss": 0.0019,
      "step": 36170
    },
    {
      "epoch": 3.087294137725062,
      "grad_norm": 0.14879654347896576,
      "learning_rate": 3.456352931137469e-05,
      "loss": 0.0027,
      "step": 36180
    },
    {
      "epoch": 3.088147452854339,
      "grad_norm": 0.4066506326198578,
      "learning_rate": 3.45592627357283e-05,
      "loss": 0.0017,
      "step": 36190
    },
    {
      "epoch": 3.0890007679836162,
      "grad_norm": 0.023755474016070366,
      "learning_rate": 3.455499616008192e-05,
      "loss": 0.0016,
      "step": 36200
    },
    {
      "epoch": 3.089854083112894,
      "grad_norm": 0.20550665259361267,
      "learning_rate": 3.455072958443553e-05,
      "loss": 0.0018,
      "step": 36210
    },
    {
      "epoch": 3.090707398242171,
      "grad_norm": 0.13153037428855896,
      "learning_rate": 3.454646300878915e-05,
      "loss": 0.002,
      "step": 36220
    },
    {
      "epoch": 3.091560713371448,
      "grad_norm": 0.14102093875408173,
      "learning_rate": 3.454219643314276e-05,
      "loss": 0.0022,
      "step": 36230
    },
    {
      "epoch": 3.092414028500725,
      "grad_norm": 0.13726821541786194,
      "learning_rate": 3.453792985749638e-05,
      "loss": 0.0017,
      "step": 36240
    },
    {
      "epoch": 3.0932673436300027,
      "grad_norm": 0.24869486689567566,
      "learning_rate": 3.4533663281849986e-05,
      "loss": 0.0014,
      "step": 36250
    },
    {
      "epoch": 3.0941206587592798,
      "grad_norm": 0.2444034069776535,
      "learning_rate": 3.452939670620361e-05,
      "loss": 0.0019,
      "step": 36260
    },
    {
      "epoch": 3.094973973888557,
      "grad_norm": 0.12491901218891144,
      "learning_rate": 3.4525130130557215e-05,
      "loss": 0.0026,
      "step": 36270
    },
    {
      "epoch": 3.0958272890178344,
      "grad_norm": 0.18895891308784485,
      "learning_rate": 3.452086355491083e-05,
      "loss": 0.0019,
      "step": 36280
    },
    {
      "epoch": 3.0966806041471115,
      "grad_norm": 0.35458266735076904,
      "learning_rate": 3.451659697926444e-05,
      "loss": 0.0017,
      "step": 36290
    },
    {
      "epoch": 3.0975339192763887,
      "grad_norm": 0.08621035516262054,
      "learning_rate": 3.451233040361806e-05,
      "loss": 0.0016,
      "step": 36300
    },
    {
      "epoch": 3.098387234405666,
      "grad_norm": 0.14870396256446838,
      "learning_rate": 3.450806382797167e-05,
      "loss": 0.0026,
      "step": 36310
    },
    {
      "epoch": 3.0992405495349433,
      "grad_norm": 0.0954539030790329,
      "learning_rate": 3.4503797252325286e-05,
      "loss": 0.0019,
      "step": 36320
    },
    {
      "epoch": 3.1000938646642204,
      "grad_norm": 0.29591768980026245,
      "learning_rate": 3.44995306766789e-05,
      "loss": 0.0018,
      "step": 36330
    },
    {
      "epoch": 3.1009471797934975,
      "grad_norm": 0.42583075165748596,
      "learning_rate": 3.4495264101032514e-05,
      "loss": 0.0021,
      "step": 36340
    },
    {
      "epoch": 3.101800494922775,
      "grad_norm": 0.16515478491783142,
      "learning_rate": 3.449099752538613e-05,
      "loss": 0.0019,
      "step": 36350
    },
    {
      "epoch": 3.102653810052052,
      "grad_norm": 0.499590665102005,
      "learning_rate": 3.448673094973974e-05,
      "loss": 0.0025,
      "step": 36360
    },
    {
      "epoch": 3.1035071251813293,
      "grad_norm": 0.33546459674835205,
      "learning_rate": 3.448246437409336e-05,
      "loss": 0.0027,
      "step": 36370
    },
    {
      "epoch": 3.104360440310607,
      "grad_norm": 0.23827049136161804,
      "learning_rate": 3.447819779844697e-05,
      "loss": 0.0021,
      "step": 36380
    },
    {
      "epoch": 3.105213755439884,
      "grad_norm": 0.3757111132144928,
      "learning_rate": 3.447393122280058e-05,
      "loss": 0.0024,
      "step": 36390
    },
    {
      "epoch": 3.106067070569161,
      "grad_norm": 0.47534817457199097,
      "learning_rate": 3.44696646471542e-05,
      "loss": 0.0018,
      "step": 36400
    },
    {
      "epoch": 3.1069203856984386,
      "grad_norm": 0.20538736879825592,
      "learning_rate": 3.446539807150781e-05,
      "loss": 0.0019,
      "step": 36410
    },
    {
      "epoch": 3.1077737008277158,
      "grad_norm": 0.07786563783884048,
      "learning_rate": 3.446113149586142e-05,
      "loss": 0.0014,
      "step": 36420
    },
    {
      "epoch": 3.108627015956993,
      "grad_norm": 0.03354097157716751,
      "learning_rate": 3.4456864920215036e-05,
      "loss": 0.0021,
      "step": 36430
    },
    {
      "epoch": 3.10948033108627,
      "grad_norm": 0.13053545355796814,
      "learning_rate": 3.445259834456865e-05,
      "loss": 0.002,
      "step": 36440
    },
    {
      "epoch": 3.1103336462155475,
      "grad_norm": 0.18831288814544678,
      "learning_rate": 3.4448331768922264e-05,
      "loss": 0.0023,
      "step": 36450
    },
    {
      "epoch": 3.1111869613448246,
      "grad_norm": 0.03482987359166145,
      "learning_rate": 3.444406519327588e-05,
      "loss": 0.0019,
      "step": 36460
    },
    {
      "epoch": 3.1120402764741018,
      "grad_norm": 0.13164642453193665,
      "learning_rate": 3.443979861762949e-05,
      "loss": 0.0024,
      "step": 36470
    },
    {
      "epoch": 3.1128935916033793,
      "grad_norm": 0.0364009290933609,
      "learning_rate": 3.443553204198311e-05,
      "loss": 0.0018,
      "step": 36480
    },
    {
      "epoch": 3.1137469067326564,
      "grad_norm": 0.06406058371067047,
      "learning_rate": 3.443126546633672e-05,
      "loss": 0.0015,
      "step": 36490
    },
    {
      "epoch": 3.1146002218619335,
      "grad_norm": 0.4889543056488037,
      "learning_rate": 3.442699889069033e-05,
      "loss": 0.0018,
      "step": 36500
    },
    {
      "epoch": 3.115453536991211,
      "grad_norm": 0.33692145347595215,
      "learning_rate": 3.442273231504395e-05,
      "loss": 0.0016,
      "step": 36510
    },
    {
      "epoch": 3.116306852120488,
      "grad_norm": 0.1333278864622116,
      "learning_rate": 3.441846573939756e-05,
      "loss": 0.0017,
      "step": 36520
    },
    {
      "epoch": 3.1171601672497653,
      "grad_norm": 0.17500464618206024,
      "learning_rate": 3.441419916375118e-05,
      "loss": 0.0021,
      "step": 36530
    },
    {
      "epoch": 3.1180134823790424,
      "grad_norm": 0.2799486815929413,
      "learning_rate": 3.4409932588104785e-05,
      "loss": 0.0022,
      "step": 36540
    },
    {
      "epoch": 3.11886679750832,
      "grad_norm": 0.14993825554847717,
      "learning_rate": 3.4405666012458406e-05,
      "loss": 0.0017,
      "step": 36550
    },
    {
      "epoch": 3.119720112637597,
      "grad_norm": 0.031416311860084534,
      "learning_rate": 3.4401399436812014e-05,
      "loss": 0.0019,
      "step": 36560
    },
    {
      "epoch": 3.120573427766874,
      "grad_norm": 0.14196951687335968,
      "learning_rate": 3.4397132861165635e-05,
      "loss": 0.0018,
      "step": 36570
    },
    {
      "epoch": 3.1214267428961517,
      "grad_norm": 0.052723463624715805,
      "learning_rate": 3.439286628551924e-05,
      "loss": 0.0019,
      "step": 36580
    },
    {
      "epoch": 3.122280058025429,
      "grad_norm": 0.3540083169937134,
      "learning_rate": 3.438859970987286e-05,
      "loss": 0.0019,
      "step": 36590
    },
    {
      "epoch": 3.123133373154706,
      "grad_norm": 0.27840372920036316,
      "learning_rate": 3.438433313422647e-05,
      "loss": 0.0016,
      "step": 36600
    },
    {
      "epoch": 3.123986688283983,
      "grad_norm": 0.1896989494562149,
      "learning_rate": 3.4380066558580085e-05,
      "loss": 0.0025,
      "step": 36610
    },
    {
      "epoch": 3.1248400034132606,
      "grad_norm": 0.19347885251045227,
      "learning_rate": 3.43757999829337e-05,
      "loss": 0.0024,
      "step": 36620
    },
    {
      "epoch": 3.1256933185425377,
      "grad_norm": 0.411011666059494,
      "learning_rate": 3.4371533407287314e-05,
      "loss": 0.0016,
      "step": 36630
    },
    {
      "epoch": 3.126546633671815,
      "grad_norm": 0.5012811422348022,
      "learning_rate": 3.436726683164093e-05,
      "loss": 0.0022,
      "step": 36640
    },
    {
      "epoch": 3.1273999488010924,
      "grad_norm": 0.5758321285247803,
      "learning_rate": 3.436300025599454e-05,
      "loss": 0.002,
      "step": 36650
    },
    {
      "epoch": 3.1282532639303695,
      "grad_norm": 0.18952083587646484,
      "learning_rate": 3.4358733680348156e-05,
      "loss": 0.0019,
      "step": 36660
    },
    {
      "epoch": 3.1291065790596466,
      "grad_norm": 0.08122606575489044,
      "learning_rate": 3.435446710470177e-05,
      "loss": 0.002,
      "step": 36670
    },
    {
      "epoch": 3.129959894188924,
      "grad_norm": 0.42606157064437866,
      "learning_rate": 3.4350200529055385e-05,
      "loss": 0.0016,
      "step": 36680
    },
    {
      "epoch": 3.1308132093182013,
      "grad_norm": 0.3762274980545044,
      "learning_rate": 3.434593395340899e-05,
      "loss": 0.0021,
      "step": 36690
    },
    {
      "epoch": 3.1316665244474784,
      "grad_norm": 0.17220397293567657,
      "learning_rate": 3.4341667377762607e-05,
      "loss": 0.0028,
      "step": 36700
    },
    {
      "epoch": 3.1325198395767555,
      "grad_norm": 0.5639564990997314,
      "learning_rate": 3.433740080211622e-05,
      "loss": 0.0018,
      "step": 36710
    },
    {
      "epoch": 3.133373154706033,
      "grad_norm": 0.13155004382133484,
      "learning_rate": 3.4333134226469835e-05,
      "loss": 0.0017,
      "step": 36720
    },
    {
      "epoch": 3.13422646983531,
      "grad_norm": 0.24393847584724426,
      "learning_rate": 3.432886765082345e-05,
      "loss": 0.0025,
      "step": 36730
    },
    {
      "epoch": 3.1350797849645873,
      "grad_norm": 0.07952701300382614,
      "learning_rate": 3.4324601075177064e-05,
      "loss": 0.0027,
      "step": 36740
    },
    {
      "epoch": 3.135933100093865,
      "grad_norm": 0.18651393055915833,
      "learning_rate": 3.432033449953068e-05,
      "loss": 0.0017,
      "step": 36750
    },
    {
      "epoch": 3.136786415223142,
      "grad_norm": 0.2776762843132019,
      "learning_rate": 3.431606792388429e-05,
      "loss": 0.0017,
      "step": 36760
    },
    {
      "epoch": 3.137639730352419,
      "grad_norm": 0.09902029484510422,
      "learning_rate": 3.4311801348237906e-05,
      "loss": 0.0021,
      "step": 36770
    },
    {
      "epoch": 3.138493045481696,
      "grad_norm": 0.21331387758255005,
      "learning_rate": 3.430753477259152e-05,
      "loss": 0.0019,
      "step": 36780
    },
    {
      "epoch": 3.1393463606109737,
      "grad_norm": 0.11638808250427246,
      "learning_rate": 3.4303268196945135e-05,
      "loss": 0.0022,
      "step": 36790
    },
    {
      "epoch": 3.140199675740251,
      "grad_norm": 0.18369892239570618,
      "learning_rate": 3.429900162129875e-05,
      "loss": 0.0018,
      "step": 36800
    },
    {
      "epoch": 3.141052990869528,
      "grad_norm": 0.18940109014511108,
      "learning_rate": 3.4294735045652356e-05,
      "loss": 0.0015,
      "step": 36810
    },
    {
      "epoch": 3.1419063059988055,
      "grad_norm": 0.2590603828430176,
      "learning_rate": 3.429046847000598e-05,
      "loss": 0.0023,
      "step": 36820
    },
    {
      "epoch": 3.1427596211280826,
      "grad_norm": 0.19643612205982208,
      "learning_rate": 3.4286201894359585e-05,
      "loss": 0.0018,
      "step": 36830
    },
    {
      "epoch": 3.1436129362573597,
      "grad_norm": 0.22203321754932404,
      "learning_rate": 3.4281935318713206e-05,
      "loss": 0.0018,
      "step": 36840
    },
    {
      "epoch": 3.1444662513866373,
      "grad_norm": 0.11297612637281418,
      "learning_rate": 3.4277668743066813e-05,
      "loss": 0.0019,
      "step": 36850
    },
    {
      "epoch": 3.1453195665159144,
      "grad_norm": 0.28259599208831787,
      "learning_rate": 3.4273402167420434e-05,
      "loss": 0.0026,
      "step": 36860
    },
    {
      "epoch": 3.1461728816451915,
      "grad_norm": 0.2670625150203705,
      "learning_rate": 3.426913559177404e-05,
      "loss": 0.0018,
      "step": 36870
    },
    {
      "epoch": 3.147026196774469,
      "grad_norm": 0.26035261154174805,
      "learning_rate": 3.426486901612766e-05,
      "loss": 0.002,
      "step": 36880
    },
    {
      "epoch": 3.147879511903746,
      "grad_norm": 0.024355215951800346,
      "learning_rate": 3.426060244048127e-05,
      "loss": 0.0016,
      "step": 36890
    },
    {
      "epoch": 3.1487328270330233,
      "grad_norm": 0.05721915140748024,
      "learning_rate": 3.4256335864834885e-05,
      "loss": 0.0015,
      "step": 36900
    },
    {
      "epoch": 3.1495861421623004,
      "grad_norm": 0.09512048959732056,
      "learning_rate": 3.42520692891885e-05,
      "loss": 0.002,
      "step": 36910
    },
    {
      "epoch": 3.150439457291578,
      "grad_norm": 0.24053271114826202,
      "learning_rate": 3.424780271354211e-05,
      "loss": 0.0024,
      "step": 36920
    },
    {
      "epoch": 3.151292772420855,
      "grad_norm": 0.03596047684550285,
      "learning_rate": 3.424353613789573e-05,
      "loss": 0.0021,
      "step": 36930
    },
    {
      "epoch": 3.152146087550132,
      "grad_norm": 0.1552598923444748,
      "learning_rate": 3.4239269562249335e-05,
      "loss": 0.0023,
      "step": 36940
    },
    {
      "epoch": 3.1529994026794097,
      "grad_norm": 0.16713963449001312,
      "learning_rate": 3.4235002986602956e-05,
      "loss": 0.0017,
      "step": 36950
    },
    {
      "epoch": 3.153852717808687,
      "grad_norm": 0.172491192817688,
      "learning_rate": 3.423073641095656e-05,
      "loss": 0.0015,
      "step": 36960
    },
    {
      "epoch": 3.154706032937964,
      "grad_norm": 0.16707026958465576,
      "learning_rate": 3.4226469835310184e-05,
      "loss": 0.0016,
      "step": 36970
    },
    {
      "epoch": 3.155559348067241,
      "grad_norm": 0.09612663090229034,
      "learning_rate": 3.422220325966379e-05,
      "loss": 0.0023,
      "step": 36980
    },
    {
      "epoch": 3.1564126631965186,
      "grad_norm": 0.13759344816207886,
      "learning_rate": 3.421793668401741e-05,
      "loss": 0.0017,
      "step": 36990
    },
    {
      "epoch": 3.1572659783257957,
      "grad_norm": 0.20171955227851868,
      "learning_rate": 3.421367010837102e-05,
      "loss": 0.0021,
      "step": 37000
    },
    {
      "epoch": 3.158119293455073,
      "grad_norm": 0.057727962732315063,
      "learning_rate": 3.4209403532724634e-05,
      "loss": 0.0024,
      "step": 37010
    },
    {
      "epoch": 3.1589726085843504,
      "grad_norm": 0.14212213456630707,
      "learning_rate": 3.420513695707825e-05,
      "loss": 0.002,
      "step": 37020
    },
    {
      "epoch": 3.1598259237136275,
      "grad_norm": 0.13080772757530212,
      "learning_rate": 3.420087038143186e-05,
      "loss": 0.0016,
      "step": 37030
    },
    {
      "epoch": 3.1606792388429046,
      "grad_norm": 0.10045505315065384,
      "learning_rate": 3.419660380578548e-05,
      "loss": 0.0017,
      "step": 37040
    },
    {
      "epoch": 3.161532553972182,
      "grad_norm": 0.22637078166007996,
      "learning_rate": 3.419233723013909e-05,
      "loss": 0.0015,
      "step": 37050
    },
    {
      "epoch": 3.1623858691014592,
      "grad_norm": 0.12201832979917526,
      "learning_rate": 3.4188070654492706e-05,
      "loss": 0.0019,
      "step": 37060
    },
    {
      "epoch": 3.1632391842307364,
      "grad_norm": 0.33323153853416443,
      "learning_rate": 3.418380407884632e-05,
      "loss": 0.0019,
      "step": 37070
    },
    {
      "epoch": 3.1640924993600135,
      "grad_norm": 0.06380338221788406,
      "learning_rate": 3.4179537503199934e-05,
      "loss": 0.0023,
      "step": 37080
    },
    {
      "epoch": 3.164945814489291,
      "grad_norm": 0.04423995688557625,
      "learning_rate": 3.417527092755355e-05,
      "loss": 0.0017,
      "step": 37090
    },
    {
      "epoch": 3.165799129618568,
      "grad_norm": 0.03360498696565628,
      "learning_rate": 3.417100435190716e-05,
      "loss": 0.0022,
      "step": 37100
    },
    {
      "epoch": 3.1666524447478452,
      "grad_norm": 0.3343667685985565,
      "learning_rate": 3.416673777626078e-05,
      "loss": 0.0019,
      "step": 37110
    },
    {
      "epoch": 3.167505759877123,
      "grad_norm": 0.08476240932941437,
      "learning_rate": 3.4162471200614384e-05,
      "loss": 0.0022,
      "step": 37120
    },
    {
      "epoch": 3.1683590750064,
      "grad_norm": 0.25924354791641235,
      "learning_rate": 3.4158204624968005e-05,
      "loss": 0.0019,
      "step": 37130
    },
    {
      "epoch": 3.169212390135677,
      "grad_norm": 0.3163357377052307,
      "learning_rate": 3.415393804932161e-05,
      "loss": 0.0019,
      "step": 37140
    },
    {
      "epoch": 3.170065705264954,
      "grad_norm": 0.13060976564884186,
      "learning_rate": 3.4149671473675234e-05,
      "loss": 0.0023,
      "step": 37150
    },
    {
      "epoch": 3.1709190203942317,
      "grad_norm": 0.09484667330980301,
      "learning_rate": 3.414540489802884e-05,
      "loss": 0.0025,
      "step": 37160
    },
    {
      "epoch": 3.171772335523509,
      "grad_norm": 0.26136699318885803,
      "learning_rate": 3.414113832238246e-05,
      "loss": 0.0018,
      "step": 37170
    },
    {
      "epoch": 3.172625650652786,
      "grad_norm": 0.2720279097557068,
      "learning_rate": 3.413687174673607e-05,
      "loss": 0.0021,
      "step": 37180
    },
    {
      "epoch": 3.1734789657820635,
      "grad_norm": 0.25480008125305176,
      "learning_rate": 3.413260517108969e-05,
      "loss": 0.0017,
      "step": 37190
    },
    {
      "epoch": 3.1743322809113406,
      "grad_norm": 0.15241596102714539,
      "learning_rate": 3.41283385954433e-05,
      "loss": 0.0021,
      "step": 37200
    },
    {
      "epoch": 3.1751855960406177,
      "grad_norm": 0.13013766705989838,
      "learning_rate": 3.412407201979691e-05,
      "loss": 0.0018,
      "step": 37210
    },
    {
      "epoch": 3.1760389111698952,
      "grad_norm": 0.4555175304412842,
      "learning_rate": 3.411980544415053e-05,
      "loss": 0.0022,
      "step": 37220
    },
    {
      "epoch": 3.1768922262991723,
      "grad_norm": 0.095555379986763,
      "learning_rate": 3.411553886850414e-05,
      "loss": 0.0021,
      "step": 37230
    },
    {
      "epoch": 3.1777455414284494,
      "grad_norm": 0.3571820855140686,
      "learning_rate": 3.4111272292857755e-05,
      "loss": 0.0022,
      "step": 37240
    },
    {
      "epoch": 3.178598856557727,
      "grad_norm": 0.3172909617424011,
      "learning_rate": 3.410700571721136e-05,
      "loss": 0.0015,
      "step": 37250
    },
    {
      "epoch": 3.179452171687004,
      "grad_norm": 0.31803736090660095,
      "learning_rate": 3.4102739141564984e-05,
      "loss": 0.0024,
      "step": 37260
    },
    {
      "epoch": 3.1803054868162812,
      "grad_norm": 0.2987866997718811,
      "learning_rate": 3.409847256591859e-05,
      "loss": 0.0016,
      "step": 37270
    },
    {
      "epoch": 3.1811588019455583,
      "grad_norm": 0.131504625082016,
      "learning_rate": 3.409420599027221e-05,
      "loss": 0.0021,
      "step": 37280
    },
    {
      "epoch": 3.182012117074836,
      "grad_norm": 0.3224165141582489,
      "learning_rate": 3.408993941462582e-05,
      "loss": 0.0013,
      "step": 37290
    },
    {
      "epoch": 3.182865432204113,
      "grad_norm": 0.1856655329465866,
      "learning_rate": 3.408567283897944e-05,
      "loss": 0.0026,
      "step": 37300
    },
    {
      "epoch": 3.18371874733339,
      "grad_norm": 0.07174290716648102,
      "learning_rate": 3.408140626333305e-05,
      "loss": 0.0022,
      "step": 37310
    },
    {
      "epoch": 3.1845720624626677,
      "grad_norm": 0.28777292370796204,
      "learning_rate": 3.407713968768666e-05,
      "loss": 0.0019,
      "step": 37320
    },
    {
      "epoch": 3.1854253775919448,
      "grad_norm": 0.2448950558900833,
      "learning_rate": 3.407287311204028e-05,
      "loss": 0.0023,
      "step": 37330
    },
    {
      "epoch": 3.186278692721222,
      "grad_norm": 0.10159488022327423,
      "learning_rate": 3.406860653639389e-05,
      "loss": 0.0022,
      "step": 37340
    },
    {
      "epoch": 3.187132007850499,
      "grad_norm": 0.33669137954711914,
      "learning_rate": 3.4064339960747505e-05,
      "loss": 0.0028,
      "step": 37350
    },
    {
      "epoch": 3.1879853229797765,
      "grad_norm": 0.1919352412223816,
      "learning_rate": 3.406007338510112e-05,
      "loss": 0.0022,
      "step": 37360
    },
    {
      "epoch": 3.1888386381090537,
      "grad_norm": 0.18888476490974426,
      "learning_rate": 3.4055806809454734e-05,
      "loss": 0.0018,
      "step": 37370
    },
    {
      "epoch": 3.1896919532383308,
      "grad_norm": 0.2890050411224365,
      "learning_rate": 3.405154023380835e-05,
      "loss": 0.0019,
      "step": 37380
    },
    {
      "epoch": 3.1905452683676083,
      "grad_norm": 0.11745639145374298,
      "learning_rate": 3.404727365816196e-05,
      "loss": 0.002,
      "step": 37390
    },
    {
      "epoch": 3.1913985834968854,
      "grad_norm": 0.127325639128685,
      "learning_rate": 3.4043007082515576e-05,
      "loss": 0.0018,
      "step": 37400
    },
    {
      "epoch": 3.1922518986261625,
      "grad_norm": 0.1337282955646515,
      "learning_rate": 3.403874050686919e-05,
      "loss": 0.002,
      "step": 37410
    },
    {
      "epoch": 3.19310521375544,
      "grad_norm": 0.20565283298492432,
      "learning_rate": 3.4034473931222805e-05,
      "loss": 0.0022,
      "step": 37420
    },
    {
      "epoch": 3.193958528884717,
      "grad_norm": 0.08104429394006729,
      "learning_rate": 3.403020735557641e-05,
      "loss": 0.0016,
      "step": 37430
    },
    {
      "epoch": 3.1948118440139943,
      "grad_norm": 0.3316754400730133,
      "learning_rate": 3.402594077993003e-05,
      "loss": 0.0016,
      "step": 37440
    },
    {
      "epoch": 3.1956651591432714,
      "grad_norm": 0.3538760244846344,
      "learning_rate": 3.402167420428364e-05,
      "loss": 0.0019,
      "step": 37450
    },
    {
      "epoch": 3.196518474272549,
      "grad_norm": 0.14783911406993866,
      "learning_rate": 3.401740762863726e-05,
      "loss": 0.0015,
      "step": 37460
    },
    {
      "epoch": 3.197371789401826,
      "grad_norm": 0.5640724897384644,
      "learning_rate": 3.401314105299087e-05,
      "loss": 0.002,
      "step": 37470
    },
    {
      "epoch": 3.198225104531103,
      "grad_norm": 0.13239401578903198,
      "learning_rate": 3.4008874477344483e-05,
      "loss": 0.0017,
      "step": 37480
    },
    {
      "epoch": 3.1990784196603808,
      "grad_norm": 0.2291715145111084,
      "learning_rate": 3.40046079016981e-05,
      "loss": 0.0027,
      "step": 37490
    },
    {
      "epoch": 3.199931734789658,
      "grad_norm": 0.2148222178220749,
      "learning_rate": 3.400034132605171e-05,
      "loss": 0.0015,
      "step": 37500
    },
    {
      "epoch": 3.200785049918935,
      "grad_norm": 0.1251021921634674,
      "learning_rate": 3.3996074750405326e-05,
      "loss": 0.0019,
      "step": 37510
    },
    {
      "epoch": 3.201638365048212,
      "grad_norm": 0.16517622768878937,
      "learning_rate": 3.399180817475894e-05,
      "loss": 0.0024,
      "step": 37520
    },
    {
      "epoch": 3.2024916801774896,
      "grad_norm": 0.11680146306753159,
      "learning_rate": 3.3987541599112555e-05,
      "loss": 0.0022,
      "step": 37530
    },
    {
      "epoch": 3.2033449953067668,
      "grad_norm": 0.2690247595310211,
      "learning_rate": 3.398327502346617e-05,
      "loss": 0.002,
      "step": 37540
    },
    {
      "epoch": 3.204198310436044,
      "grad_norm": 0.16734425723552704,
      "learning_rate": 3.397900844781978e-05,
      "loss": 0.002,
      "step": 37550
    },
    {
      "epoch": 3.2050516255653214,
      "grad_norm": 0.20367757976055145,
      "learning_rate": 3.397474187217339e-05,
      "loss": 0.0022,
      "step": 37560
    },
    {
      "epoch": 3.2059049406945985,
      "grad_norm": 0.22227297723293304,
      "learning_rate": 3.397047529652701e-05,
      "loss": 0.0018,
      "step": 37570
    },
    {
      "epoch": 3.2067582558238756,
      "grad_norm": 0.0647842288017273,
      "learning_rate": 3.396620872088062e-05,
      "loss": 0.0017,
      "step": 37580
    },
    {
      "epoch": 3.207611570953153,
      "grad_norm": 0.06498409807682037,
      "learning_rate": 3.396194214523424e-05,
      "loss": 0.0016,
      "step": 37590
    },
    {
      "epoch": 3.2084648860824303,
      "grad_norm": 0.30739128589630127,
      "learning_rate": 3.395767556958785e-05,
      "loss": 0.0022,
      "step": 37600
    },
    {
      "epoch": 3.2093182012117074,
      "grad_norm": 0.09430833160877228,
      "learning_rate": 3.395340899394147e-05,
      "loss": 0.0028,
      "step": 37610
    },
    {
      "epoch": 3.2101715163409845,
      "grad_norm": 0.39253857731819153,
      "learning_rate": 3.3949142418295076e-05,
      "loss": 0.0019,
      "step": 37620
    },
    {
      "epoch": 3.211024831470262,
      "grad_norm": 0.1529192179441452,
      "learning_rate": 3.394487584264869e-05,
      "loss": 0.0017,
      "step": 37630
    },
    {
      "epoch": 3.211878146599539,
      "grad_norm": 0.25885820388793945,
      "learning_rate": 3.3940609267002305e-05,
      "loss": 0.0017,
      "step": 37640
    },
    {
      "epoch": 3.2127314617288163,
      "grad_norm": 0.31780514121055603,
      "learning_rate": 3.393634269135592e-05,
      "loss": 0.0023,
      "step": 37650
    },
    {
      "epoch": 3.213584776858094,
      "grad_norm": 0.2844783663749695,
      "learning_rate": 3.393207611570953e-05,
      "loss": 0.002,
      "step": 37660
    },
    {
      "epoch": 3.214438091987371,
      "grad_norm": 0.16093799471855164,
      "learning_rate": 3.392780954006315e-05,
      "loss": 0.0015,
      "step": 37670
    },
    {
      "epoch": 3.215291407116648,
      "grad_norm": 0.03838397189974785,
      "learning_rate": 3.392354296441676e-05,
      "loss": 0.0022,
      "step": 37680
    },
    {
      "epoch": 3.2161447222459256,
      "grad_norm": 0.17210114002227783,
      "learning_rate": 3.3919276388770376e-05,
      "loss": 0.0021,
      "step": 37690
    },
    {
      "epoch": 3.2169980373752027,
      "grad_norm": 0.02485514059662819,
      "learning_rate": 3.391500981312399e-05,
      "loss": 0.0018,
      "step": 37700
    },
    {
      "epoch": 3.21785135250448,
      "grad_norm": 0.3946361839771271,
      "learning_rate": 3.3910743237477604e-05,
      "loss": 0.0021,
      "step": 37710
    },
    {
      "epoch": 3.218704667633757,
      "grad_norm": 0.10592660307884216,
      "learning_rate": 3.390647666183122e-05,
      "loss": 0.0014,
      "step": 37720
    },
    {
      "epoch": 3.2195579827630345,
      "grad_norm": 0.044648926705121994,
      "learning_rate": 3.390221008618483e-05,
      "loss": 0.0018,
      "step": 37730
    },
    {
      "epoch": 3.2204112978923116,
      "grad_norm": 0.20802344381809235,
      "learning_rate": 3.389794351053844e-05,
      "loss": 0.002,
      "step": 37740
    },
    {
      "epoch": 3.2212646130215887,
      "grad_norm": 0.05921448394656181,
      "learning_rate": 3.3893676934892054e-05,
      "loss": 0.0014,
      "step": 37750
    },
    {
      "epoch": 3.2221179281508663,
      "grad_norm": 0.5401377081871033,
      "learning_rate": 3.388941035924567e-05,
      "loss": 0.0013,
      "step": 37760
    },
    {
      "epoch": 3.2229712432801434,
      "grad_norm": 0.1887376308441162,
      "learning_rate": 3.388514378359928e-05,
      "loss": 0.0024,
      "step": 37770
    },
    {
      "epoch": 3.2238245584094205,
      "grad_norm": 0.1558716595172882,
      "learning_rate": 3.38808772079529e-05,
      "loss": 0.002,
      "step": 37780
    },
    {
      "epoch": 3.224677873538698,
      "grad_norm": 0.17243815958499908,
      "learning_rate": 3.387661063230651e-05,
      "loss": 0.0017,
      "step": 37790
    },
    {
      "epoch": 3.225531188667975,
      "grad_norm": 0.1337379813194275,
      "learning_rate": 3.3872344056660126e-05,
      "loss": 0.0013,
      "step": 37800
    },
    {
      "epoch": 3.2263845037972523,
      "grad_norm": 0.2802683413028717,
      "learning_rate": 3.386807748101374e-05,
      "loss": 0.0017,
      "step": 37810
    },
    {
      "epoch": 3.2272378189265294,
      "grad_norm": 0.14563068747520447,
      "learning_rate": 3.3863810905367354e-05,
      "loss": 0.0019,
      "step": 37820
    },
    {
      "epoch": 3.228091134055807,
      "grad_norm": 0.18027450144290924,
      "learning_rate": 3.385954432972097e-05,
      "loss": 0.002,
      "step": 37830
    },
    {
      "epoch": 3.228944449185084,
      "grad_norm": 0.03914696350693703,
      "learning_rate": 3.385527775407458e-05,
      "loss": 0.0016,
      "step": 37840
    },
    {
      "epoch": 3.229797764314361,
      "grad_norm": 0.36943596601486206,
      "learning_rate": 3.38510111784282e-05,
      "loss": 0.0016,
      "step": 37850
    },
    {
      "epoch": 3.2306510794436387,
      "grad_norm": 0.24428774416446686,
      "learning_rate": 3.384674460278181e-05,
      "loss": 0.0018,
      "step": 37860
    },
    {
      "epoch": 3.231504394572916,
      "grad_norm": 0.06799004971981049,
      "learning_rate": 3.384247802713542e-05,
      "loss": 0.0022,
      "step": 37870
    },
    {
      "epoch": 3.232357709702193,
      "grad_norm": 0.2620256543159485,
      "learning_rate": 3.383821145148904e-05,
      "loss": 0.0021,
      "step": 37880
    },
    {
      "epoch": 3.23321102483147,
      "grad_norm": 0.38730424642562866,
      "learning_rate": 3.383394487584265e-05,
      "loss": 0.0023,
      "step": 37890
    },
    {
      "epoch": 3.2340643399607476,
      "grad_norm": 0.20824308693408966,
      "learning_rate": 3.382967830019627e-05,
      "loss": 0.0024,
      "step": 37900
    },
    {
      "epoch": 3.2349176550900247,
      "grad_norm": 0.06735305488109589,
      "learning_rate": 3.3825411724549875e-05,
      "loss": 0.0021,
      "step": 37910
    },
    {
      "epoch": 3.235770970219302,
      "grad_norm": 0.1489008516073227,
      "learning_rate": 3.3821145148903497e-05,
      "loss": 0.0022,
      "step": 37920
    },
    {
      "epoch": 3.2366242853485794,
      "grad_norm": 0.13346809148788452,
      "learning_rate": 3.3816878573257104e-05,
      "loss": 0.0023,
      "step": 37930
    },
    {
      "epoch": 3.2374776004778565,
      "grad_norm": 0.069489985704422,
      "learning_rate": 3.381261199761072e-05,
      "loss": 0.0022,
      "step": 37940
    },
    {
      "epoch": 3.2383309156071336,
      "grad_norm": 0.20808063447475433,
      "learning_rate": 3.380834542196433e-05,
      "loss": 0.0021,
      "step": 37950
    },
    {
      "epoch": 3.239184230736411,
      "grad_norm": 0.189139261841774,
      "learning_rate": 3.380407884631795e-05,
      "loss": 0.0026,
      "step": 37960
    },
    {
      "epoch": 3.2400375458656883,
      "grad_norm": 0.18054184317588806,
      "learning_rate": 3.379981227067156e-05,
      "loss": 0.0017,
      "step": 37970
    },
    {
      "epoch": 3.2408908609949654,
      "grad_norm": 0.08142745494842529,
      "learning_rate": 3.3795545695025175e-05,
      "loss": 0.0022,
      "step": 37980
    },
    {
      "epoch": 3.2417441761242425,
      "grad_norm": 0.11813255399465561,
      "learning_rate": 3.379127911937879e-05,
      "loss": 0.002,
      "step": 37990
    },
    {
      "epoch": 3.24259749125352,
      "grad_norm": 0.035338759422302246,
      "learning_rate": 3.3787012543732404e-05,
      "loss": 0.0016,
      "step": 38000
    },
    {
      "epoch": 3.243450806382797,
      "grad_norm": 0.1829729974269867,
      "learning_rate": 3.378274596808602e-05,
      "loss": 0.0014,
      "step": 38010
    },
    {
      "epoch": 3.2443041215120743,
      "grad_norm": 0.03771944344043732,
      "learning_rate": 3.3778479392439625e-05,
      "loss": 0.0019,
      "step": 38020
    },
    {
      "epoch": 3.245157436641352,
      "grad_norm": 0.0725388154387474,
      "learning_rate": 3.3774212816793246e-05,
      "loss": 0.0015,
      "step": 38030
    },
    {
      "epoch": 3.246010751770629,
      "grad_norm": 0.1583007276058197,
      "learning_rate": 3.3769946241146854e-05,
      "loss": 0.0023,
      "step": 38040
    },
    {
      "epoch": 3.246864066899906,
      "grad_norm": 0.05797041952610016,
      "learning_rate": 3.376567966550047e-05,
      "loss": 0.0022,
      "step": 38050
    },
    {
      "epoch": 3.247717382029183,
      "grad_norm": 0.17852070927619934,
      "learning_rate": 3.376141308985408e-05,
      "loss": 0.0017,
      "step": 38060
    },
    {
      "epoch": 3.2485706971584607,
      "grad_norm": 0.1946428418159485,
      "learning_rate": 3.3757146514207697e-05,
      "loss": 0.002,
      "step": 38070
    },
    {
      "epoch": 3.249424012287738,
      "grad_norm": 0.0464339479804039,
      "learning_rate": 3.375287993856131e-05,
      "loss": 0.0029,
      "step": 38080
    },
    {
      "epoch": 3.250277327417015,
      "grad_norm": 0.11418662220239639,
      "learning_rate": 3.3748613362914925e-05,
      "loss": 0.0019,
      "step": 38090
    },
    {
      "epoch": 3.2511306425462925,
      "grad_norm": 0.04327617213129997,
      "learning_rate": 3.374434678726854e-05,
      "loss": 0.0022,
      "step": 38100
    },
    {
      "epoch": 3.2519839576755696,
      "grad_norm": 0.23401468992233276,
      "learning_rate": 3.3740080211622154e-05,
      "loss": 0.002,
      "step": 38110
    },
    {
      "epoch": 3.2528372728048467,
      "grad_norm": 0.41476526856422424,
      "learning_rate": 3.373581363597577e-05,
      "loss": 0.0016,
      "step": 38120
    },
    {
      "epoch": 3.2536905879341242,
      "grad_norm": 0.037207990884780884,
      "learning_rate": 3.373154706032938e-05,
      "loss": 0.0019,
      "step": 38130
    },
    {
      "epoch": 3.2545439030634014,
      "grad_norm": 0.059082500636577606,
      "learning_rate": 3.3727280484682996e-05,
      "loss": 0.002,
      "step": 38140
    },
    {
      "epoch": 3.2553972181926785,
      "grad_norm": 0.13964739441871643,
      "learning_rate": 3.372301390903661e-05,
      "loss": 0.0022,
      "step": 38150
    },
    {
      "epoch": 3.256250533321956,
      "grad_norm": 0.11275853216648102,
      "learning_rate": 3.3718747333390225e-05,
      "loss": 0.0019,
      "step": 38160
    },
    {
      "epoch": 3.257103848451233,
      "grad_norm": 0.036708757281303406,
      "learning_rate": 3.371448075774384e-05,
      "loss": 0.002,
      "step": 38170
    },
    {
      "epoch": 3.2579571635805102,
      "grad_norm": 0.49056822061538696,
      "learning_rate": 3.3710214182097446e-05,
      "loss": 0.0019,
      "step": 38180
    },
    {
      "epoch": 3.2588104787097874,
      "grad_norm": 0.03101455420255661,
      "learning_rate": 3.370594760645107e-05,
      "loss": 0.0019,
      "step": 38190
    },
    {
      "epoch": 3.259663793839065,
      "grad_norm": 0.19999612867832184,
      "learning_rate": 3.3701681030804675e-05,
      "loss": 0.0023,
      "step": 38200
    },
    {
      "epoch": 3.260517108968342,
      "grad_norm": 0.08202115446329117,
      "learning_rate": 3.3697414455158296e-05,
      "loss": 0.0024,
      "step": 38210
    },
    {
      "epoch": 3.261370424097619,
      "grad_norm": 0.06421537697315216,
      "learning_rate": 3.3693147879511903e-05,
      "loss": 0.0019,
      "step": 38220
    },
    {
      "epoch": 3.2622237392268967,
      "grad_norm": 0.37022489309310913,
      "learning_rate": 3.3688881303865524e-05,
      "loss": 0.0022,
      "step": 38230
    },
    {
      "epoch": 3.263077054356174,
      "grad_norm": 0.15105000138282776,
      "learning_rate": 3.368461472821913e-05,
      "loss": 0.0022,
      "step": 38240
    },
    {
      "epoch": 3.263930369485451,
      "grad_norm": 0.278820663690567,
      "learning_rate": 3.3680348152572746e-05,
      "loss": 0.0018,
      "step": 38250
    },
    {
      "epoch": 3.264783684614728,
      "grad_norm": 0.11443804204463959,
      "learning_rate": 3.367608157692636e-05,
      "loss": 0.0021,
      "step": 38260
    },
    {
      "epoch": 3.2656369997440056,
      "grad_norm": 0.1374816596508026,
      "learning_rate": 3.3671815001279975e-05,
      "loss": 0.0021,
      "step": 38270
    },
    {
      "epoch": 3.2664903148732827,
      "grad_norm": 0.32772892713546753,
      "learning_rate": 3.366754842563359e-05,
      "loss": 0.0019,
      "step": 38280
    },
    {
      "epoch": 3.26734363000256,
      "grad_norm": 0.15133221447467804,
      "learning_rate": 3.3663281849987196e-05,
      "loss": 0.0017,
      "step": 38290
    },
    {
      "epoch": 3.2681969451318373,
      "grad_norm": 0.15189801156520844,
      "learning_rate": 3.365901527434082e-05,
      "loss": 0.0021,
      "step": 38300
    },
    {
      "epoch": 3.2690502602611144,
      "grad_norm": 0.3417026698589325,
      "learning_rate": 3.3654748698694425e-05,
      "loss": 0.002,
      "step": 38310
    },
    {
      "epoch": 3.2699035753903916,
      "grad_norm": 0.023406509310007095,
      "learning_rate": 3.3650482123048046e-05,
      "loss": 0.0022,
      "step": 38320
    },
    {
      "epoch": 3.270756890519669,
      "grad_norm": 0.3171519339084625,
      "learning_rate": 3.364621554740165e-05,
      "loss": 0.0024,
      "step": 38330
    },
    {
      "epoch": 3.2716102056489462,
      "grad_norm": 0.08882026374340057,
      "learning_rate": 3.3641948971755274e-05,
      "loss": 0.0014,
      "step": 38340
    },
    {
      "epoch": 3.2724635207782233,
      "grad_norm": 0.20226964354515076,
      "learning_rate": 3.363768239610888e-05,
      "loss": 0.0017,
      "step": 38350
    },
    {
      "epoch": 3.273316835907501,
      "grad_norm": 0.3733358085155487,
      "learning_rate": 3.3633415820462496e-05,
      "loss": 0.0019,
      "step": 38360
    },
    {
      "epoch": 3.274170151036778,
      "grad_norm": 0.0790417417883873,
      "learning_rate": 3.362914924481611e-05,
      "loss": 0.002,
      "step": 38370
    },
    {
      "epoch": 3.275023466166055,
      "grad_norm": 0.1511814296245575,
      "learning_rate": 3.3624882669169724e-05,
      "loss": 0.0021,
      "step": 38380
    },
    {
      "epoch": 3.275876781295332,
      "grad_norm": 0.18375249207019806,
      "learning_rate": 3.362061609352334e-05,
      "loss": 0.0024,
      "step": 38390
    },
    {
      "epoch": 3.2767300964246098,
      "grad_norm": 0.34025970101356506,
      "learning_rate": 3.361634951787695e-05,
      "loss": 0.0019,
      "step": 38400
    },
    {
      "epoch": 3.277583411553887,
      "grad_norm": 0.17262797057628632,
      "learning_rate": 3.361208294223057e-05,
      "loss": 0.0022,
      "step": 38410
    },
    {
      "epoch": 3.278436726683164,
      "grad_norm": 0.410006582736969,
      "learning_rate": 3.360781636658418e-05,
      "loss": 0.0019,
      "step": 38420
    },
    {
      "epoch": 3.279290041812441,
      "grad_norm": 0.507061779499054,
      "learning_rate": 3.3603549790937796e-05,
      "loss": 0.0019,
      "step": 38430
    },
    {
      "epoch": 3.2801433569417187,
      "grad_norm": 0.5664337873458862,
      "learning_rate": 3.359928321529141e-05,
      "loss": 0.0019,
      "step": 38440
    },
    {
      "epoch": 3.2809966720709958,
      "grad_norm": 0.15194709599018097,
      "learning_rate": 3.3595016639645024e-05,
      "loss": 0.0021,
      "step": 38450
    },
    {
      "epoch": 3.281849987200273,
      "grad_norm": 0.3099706768989563,
      "learning_rate": 3.359075006399864e-05,
      "loss": 0.0018,
      "step": 38460
    },
    {
      "epoch": 3.2827033023295504,
      "grad_norm": 0.1094420850276947,
      "learning_rate": 3.358648348835225e-05,
      "loss": 0.0026,
      "step": 38470
    },
    {
      "epoch": 3.2835566174588275,
      "grad_norm": 0.41510888934135437,
      "learning_rate": 3.358221691270587e-05,
      "loss": 0.0023,
      "step": 38480
    },
    {
      "epoch": 3.2844099325881047,
      "grad_norm": 0.0989222526550293,
      "learning_rate": 3.3577950337059474e-05,
      "loss": 0.0023,
      "step": 38490
    },
    {
      "epoch": 3.285263247717382,
      "grad_norm": 0.24635043740272522,
      "learning_rate": 3.3573683761413095e-05,
      "loss": 0.0021,
      "step": 38500
    },
    {
      "epoch": 3.2861165628466593,
      "grad_norm": 0.46699246764183044,
      "learning_rate": 3.35694171857667e-05,
      "loss": 0.0021,
      "step": 38510
    },
    {
      "epoch": 3.2869698779759364,
      "grad_norm": 0.30355632305145264,
      "learning_rate": 3.3565150610120324e-05,
      "loss": 0.0019,
      "step": 38520
    },
    {
      "epoch": 3.287823193105214,
      "grad_norm": 0.07595475763082504,
      "learning_rate": 3.356088403447393e-05,
      "loss": 0.0022,
      "step": 38530
    },
    {
      "epoch": 3.288676508234491,
      "grad_norm": 0.1243119165301323,
      "learning_rate": 3.3556617458827546e-05,
      "loss": 0.0022,
      "step": 38540
    },
    {
      "epoch": 3.289529823363768,
      "grad_norm": 0.17268262803554535,
      "learning_rate": 3.355235088318116e-05,
      "loss": 0.0017,
      "step": 38550
    },
    {
      "epoch": 3.2903831384930453,
      "grad_norm": 0.3781295120716095,
      "learning_rate": 3.3548084307534774e-05,
      "loss": 0.0017,
      "step": 38560
    },
    {
      "epoch": 3.291236453622323,
      "grad_norm": 0.03214871138334274,
      "learning_rate": 3.354381773188839e-05,
      "loss": 0.0017,
      "step": 38570
    },
    {
      "epoch": 3.2920897687516,
      "grad_norm": 0.19311241805553436,
      "learning_rate": 3.3539551156242e-05,
      "loss": 0.0027,
      "step": 38580
    },
    {
      "epoch": 3.292943083880877,
      "grad_norm": 0.19008034467697144,
      "learning_rate": 3.353528458059562e-05,
      "loss": 0.0016,
      "step": 38590
    },
    {
      "epoch": 3.2937963990101546,
      "grad_norm": 0.048497945070266724,
      "learning_rate": 3.3531018004949224e-05,
      "loss": 0.0018,
      "step": 38600
    },
    {
      "epoch": 3.2946497141394318,
      "grad_norm": 0.15751975774765015,
      "learning_rate": 3.3526751429302845e-05,
      "loss": 0.0018,
      "step": 38610
    },
    {
      "epoch": 3.295503029268709,
      "grad_norm": 0.079786516726017,
      "learning_rate": 3.352248485365645e-05,
      "loss": 0.0021,
      "step": 38620
    },
    {
      "epoch": 3.296356344397986,
      "grad_norm": 0.2675248980522156,
      "learning_rate": 3.3518218278010074e-05,
      "loss": 0.0021,
      "step": 38630
    },
    {
      "epoch": 3.2972096595272635,
      "grad_norm": 0.14110571146011353,
      "learning_rate": 3.351395170236368e-05,
      "loss": 0.0022,
      "step": 38640
    },
    {
      "epoch": 3.2980629746565406,
      "grad_norm": 0.2842746078968048,
      "learning_rate": 3.35096851267173e-05,
      "loss": 0.0021,
      "step": 38650
    },
    {
      "epoch": 3.2989162897858177,
      "grad_norm": 0.03534556180238724,
      "learning_rate": 3.350541855107091e-05,
      "loss": 0.0023,
      "step": 38660
    },
    {
      "epoch": 3.2997696049150953,
      "grad_norm": 0.4202652871608734,
      "learning_rate": 3.350115197542453e-05,
      "loss": 0.0023,
      "step": 38670
    },
    {
      "epoch": 3.3006229200443724,
      "grad_norm": 0.4156973361968994,
      "learning_rate": 3.349688539977814e-05,
      "loss": 0.0019,
      "step": 38680
    },
    {
      "epoch": 3.3014762351736495,
      "grad_norm": 0.11211944371461868,
      "learning_rate": 3.349261882413175e-05,
      "loss": 0.0016,
      "step": 38690
    },
    {
      "epoch": 3.302329550302927,
      "grad_norm": 0.46155881881713867,
      "learning_rate": 3.348835224848537e-05,
      "loss": 0.0024,
      "step": 38700
    },
    {
      "epoch": 3.303182865432204,
      "grad_norm": 0.214127317070961,
      "learning_rate": 3.348408567283898e-05,
      "loss": 0.0017,
      "step": 38710
    },
    {
      "epoch": 3.3040361805614813,
      "grad_norm": 0.16582880914211273,
      "learning_rate": 3.3479819097192595e-05,
      "loss": 0.0022,
      "step": 38720
    },
    {
      "epoch": 3.3048894956907584,
      "grad_norm": 0.3166183531284332,
      "learning_rate": 3.347555252154621e-05,
      "loss": 0.0015,
      "step": 38730
    },
    {
      "epoch": 3.305742810820036,
      "grad_norm": 0.04436807706952095,
      "learning_rate": 3.3471285945899824e-05,
      "loss": 0.0021,
      "step": 38740
    },
    {
      "epoch": 3.306596125949313,
      "grad_norm": 0.04568901285529137,
      "learning_rate": 3.346701937025344e-05,
      "loss": 0.0022,
      "step": 38750
    },
    {
      "epoch": 3.30744944107859,
      "grad_norm": 0.166873037815094,
      "learning_rate": 3.346275279460705e-05,
      "loss": 0.0018,
      "step": 38760
    },
    {
      "epoch": 3.3083027562078677,
      "grad_norm": 0.41187334060668945,
      "learning_rate": 3.3458486218960666e-05,
      "loss": 0.0023,
      "step": 38770
    },
    {
      "epoch": 3.309156071337145,
      "grad_norm": 0.03635846823453903,
      "learning_rate": 3.345421964331428e-05,
      "loss": 0.0025,
      "step": 38780
    },
    {
      "epoch": 3.310009386466422,
      "grad_norm": 0.3199092447757721,
      "learning_rate": 3.3449953067667895e-05,
      "loss": 0.0018,
      "step": 38790
    },
    {
      "epoch": 3.310862701595699,
      "grad_norm": 0.16230255365371704,
      "learning_rate": 3.34456864920215e-05,
      "loss": 0.0022,
      "step": 38800
    },
    {
      "epoch": 3.3117160167249766,
      "grad_norm": 0.048007044941186905,
      "learning_rate": 3.3441419916375117e-05,
      "loss": 0.0021,
      "step": 38810
    },
    {
      "epoch": 3.3125693318542537,
      "grad_norm": 0.03232603520154953,
      "learning_rate": 3.343715334072873e-05,
      "loss": 0.002,
      "step": 38820
    },
    {
      "epoch": 3.313422646983531,
      "grad_norm": 0.16990530490875244,
      "learning_rate": 3.3432886765082345e-05,
      "loss": 0.0018,
      "step": 38830
    },
    {
      "epoch": 3.3142759621128084,
      "grad_norm": 0.060416627675294876,
      "learning_rate": 3.342862018943596e-05,
      "loss": 0.0019,
      "step": 38840
    },
    {
      "epoch": 3.3151292772420855,
      "grad_norm": 0.04202168807387352,
      "learning_rate": 3.3424353613789573e-05,
      "loss": 0.0021,
      "step": 38850
    },
    {
      "epoch": 3.3159825923713626,
      "grad_norm": 0.11390604823827744,
      "learning_rate": 3.342008703814319e-05,
      "loss": 0.0015,
      "step": 38860
    },
    {
      "epoch": 3.31683590750064,
      "grad_norm": 0.027807394042611122,
      "learning_rate": 3.34158204624968e-05,
      "loss": 0.0022,
      "step": 38870
    },
    {
      "epoch": 3.3176892226299173,
      "grad_norm": 0.11502650380134583,
      "learning_rate": 3.3411553886850416e-05,
      "loss": 0.0016,
      "step": 38880
    },
    {
      "epoch": 3.3185425377591944,
      "grad_norm": 0.14502890408039093,
      "learning_rate": 3.340728731120403e-05,
      "loss": 0.0019,
      "step": 38890
    },
    {
      "epoch": 3.319395852888472,
      "grad_norm": 0.0762421190738678,
      "learning_rate": 3.3403020735557645e-05,
      "loss": 0.0021,
      "step": 38900
    },
    {
      "epoch": 3.320249168017749,
      "grad_norm": 0.2700958549976349,
      "learning_rate": 3.339875415991125e-05,
      "loss": 0.0021,
      "step": 38910
    },
    {
      "epoch": 3.321102483147026,
      "grad_norm": 0.06444008648395538,
      "learning_rate": 3.339448758426487e-05,
      "loss": 0.0021,
      "step": 38920
    },
    {
      "epoch": 3.3219557982763033,
      "grad_norm": 0.10390998423099518,
      "learning_rate": 3.339022100861848e-05,
      "loss": 0.0018,
      "step": 38930
    },
    {
      "epoch": 3.322809113405581,
      "grad_norm": 0.17852695286273956,
      "learning_rate": 3.33859544329721e-05,
      "loss": 0.0019,
      "step": 38940
    },
    {
      "epoch": 3.323662428534858,
      "grad_norm": 0.49664533138275146,
      "learning_rate": 3.338168785732571e-05,
      "loss": 0.0021,
      "step": 38950
    },
    {
      "epoch": 3.324515743664135,
      "grad_norm": 0.13379162549972534,
      "learning_rate": 3.337742128167933e-05,
      "loss": 0.0022,
      "step": 38960
    },
    {
      "epoch": 3.325369058793412,
      "grad_norm": 0.15172472596168518,
      "learning_rate": 3.337315470603294e-05,
      "loss": 0.002,
      "step": 38970
    },
    {
      "epoch": 3.3262223739226897,
      "grad_norm": 0.13698524236679077,
      "learning_rate": 3.336888813038656e-05,
      "loss": 0.0019,
      "step": 38980
    },
    {
      "epoch": 3.327075689051967,
      "grad_norm": 0.26275259256362915,
      "learning_rate": 3.3364621554740166e-05,
      "loss": 0.002,
      "step": 38990
    },
    {
      "epoch": 3.327929004181244,
      "grad_norm": 0.12911106646060944,
      "learning_rate": 3.336035497909378e-05,
      "loss": 0.002,
      "step": 39000
    },
    {
      "epoch": 3.3287823193105215,
      "grad_norm": 0.06130508705973625,
      "learning_rate": 3.3356088403447395e-05,
      "loss": 0.0025,
      "step": 39010
    },
    {
      "epoch": 3.3296356344397986,
      "grad_norm": 0.20180641114711761,
      "learning_rate": 3.335182182780101e-05,
      "loss": 0.0018,
      "step": 39020
    },
    {
      "epoch": 3.3304889495690757,
      "grad_norm": 0.07766330242156982,
      "learning_rate": 3.334755525215462e-05,
      "loss": 0.0022,
      "step": 39030
    },
    {
      "epoch": 3.3313422646983533,
      "grad_norm": 0.2542537748813629,
      "learning_rate": 3.334328867650824e-05,
      "loss": 0.0029,
      "step": 39040
    },
    {
      "epoch": 3.3321955798276304,
      "grad_norm": 0.1359696090221405,
      "learning_rate": 3.333902210086185e-05,
      "loss": 0.0016,
      "step": 39050
    },
    {
      "epoch": 3.3330488949569075,
      "grad_norm": 0.14949552714824677,
      "learning_rate": 3.3334755525215466e-05,
      "loss": 0.0018,
      "step": 39060
    },
    {
      "epoch": 3.333902210086185,
      "grad_norm": 0.31800708174705505,
      "learning_rate": 3.333048894956908e-05,
      "loss": 0.0018,
      "step": 39070
    },
    {
      "epoch": 3.334755525215462,
      "grad_norm": 0.15066345036029816,
      "learning_rate": 3.332622237392269e-05,
      "loss": 0.0017,
      "step": 39080
    },
    {
      "epoch": 3.3356088403447393,
      "grad_norm": 0.08098925650119781,
      "learning_rate": 3.332195579827631e-05,
      "loss": 0.0016,
      "step": 39090
    },
    {
      "epoch": 3.3364621554740164,
      "grad_norm": 0.13073258101940155,
      "learning_rate": 3.3317689222629916e-05,
      "loss": 0.0018,
      "step": 39100
    },
    {
      "epoch": 3.337315470603294,
      "grad_norm": 0.4070585072040558,
      "learning_rate": 3.331342264698353e-05,
      "loss": 0.002,
      "step": 39110
    },
    {
      "epoch": 3.338168785732571,
      "grad_norm": 0.18742796778678894,
      "learning_rate": 3.3309156071337144e-05,
      "loss": 0.0019,
      "step": 39120
    },
    {
      "epoch": 3.339022100861848,
      "grad_norm": 0.22449322044849396,
      "learning_rate": 3.330488949569076e-05,
      "loss": 0.0023,
      "step": 39130
    },
    {
      "epoch": 3.3398754159911257,
      "grad_norm": 0.04512118175625801,
      "learning_rate": 3.330062292004437e-05,
      "loss": 0.0021,
      "step": 39140
    },
    {
      "epoch": 3.340728731120403,
      "grad_norm": 0.0440501868724823,
      "learning_rate": 3.329635634439799e-05,
      "loss": 0.002,
      "step": 39150
    },
    {
      "epoch": 3.34158204624968,
      "grad_norm": 0.24589328467845917,
      "learning_rate": 3.32920897687516e-05,
      "loss": 0.0016,
      "step": 39160
    },
    {
      "epoch": 3.342435361378957,
      "grad_norm": 0.2730087339878082,
      "learning_rate": 3.3287823193105216e-05,
      "loss": 0.0021,
      "step": 39170
    },
    {
      "epoch": 3.3432886765082346,
      "grad_norm": 0.08001743257045746,
      "learning_rate": 3.328355661745883e-05,
      "loss": 0.0018,
      "step": 39180
    },
    {
      "epoch": 3.3441419916375117,
      "grad_norm": 0.055009398609399796,
      "learning_rate": 3.3279290041812444e-05,
      "loss": 0.0019,
      "step": 39190
    },
    {
      "epoch": 3.344995306766789,
      "grad_norm": 0.2393205761909485,
      "learning_rate": 3.327502346616606e-05,
      "loss": 0.0019,
      "step": 39200
    },
    {
      "epoch": 3.3458486218960664,
      "grad_norm": 0.21438546478748322,
      "learning_rate": 3.327075689051967e-05,
      "loss": 0.0021,
      "step": 39210
    },
    {
      "epoch": 3.3467019370253435,
      "grad_norm": 0.5947116017341614,
      "learning_rate": 3.326649031487328e-05,
      "loss": 0.0022,
      "step": 39220
    },
    {
      "epoch": 3.3475552521546206,
      "grad_norm": 0.2054949253797531,
      "learning_rate": 3.32622237392269e-05,
      "loss": 0.0019,
      "step": 39230
    },
    {
      "epoch": 3.348408567283898,
      "grad_norm": 0.2847999632358551,
      "learning_rate": 3.325795716358051e-05,
      "loss": 0.0019,
      "step": 39240
    },
    {
      "epoch": 3.3492618824131752,
      "grad_norm": 0.04067658632993698,
      "learning_rate": 3.325369058793413e-05,
      "loss": 0.0015,
      "step": 39250
    },
    {
      "epoch": 3.3501151975424523,
      "grad_norm": 0.18709886074066162,
      "learning_rate": 3.324942401228774e-05,
      "loss": 0.0024,
      "step": 39260
    },
    {
      "epoch": 3.35096851267173,
      "grad_norm": 0.12338407337665558,
      "learning_rate": 3.324515743664136e-05,
      "loss": 0.0016,
      "step": 39270
    },
    {
      "epoch": 3.351821827801007,
      "grad_norm": 0.05623222887516022,
      "learning_rate": 3.3240890860994966e-05,
      "loss": 0.0018,
      "step": 39280
    },
    {
      "epoch": 3.352675142930284,
      "grad_norm": 0.09752191603183746,
      "learning_rate": 3.3236624285348587e-05,
      "loss": 0.0016,
      "step": 39290
    },
    {
      "epoch": 3.3535284580595612,
      "grad_norm": 0.32152578234672546,
      "learning_rate": 3.3232357709702194e-05,
      "loss": 0.0014,
      "step": 39300
    },
    {
      "epoch": 3.354381773188839,
      "grad_norm": 0.14903713762760162,
      "learning_rate": 3.322809113405581e-05,
      "loss": 0.0022,
      "step": 39310
    },
    {
      "epoch": 3.355235088318116,
      "grad_norm": 0.28938722610473633,
      "learning_rate": 3.322382455840942e-05,
      "loss": 0.0021,
      "step": 39320
    },
    {
      "epoch": 3.356088403447393,
      "grad_norm": 0.02788347564637661,
      "learning_rate": 3.321955798276303e-05,
      "loss": 0.0019,
      "step": 39330
    },
    {
      "epoch": 3.35694171857667,
      "grad_norm": 0.035545140504837036,
      "learning_rate": 3.321529140711665e-05,
      "loss": 0.0019,
      "step": 39340
    },
    {
      "epoch": 3.3577950337059477,
      "grad_norm": 0.19446398317813873,
      "learning_rate": 3.321102483147026e-05,
      "loss": 0.0021,
      "step": 39350
    },
    {
      "epoch": 3.358648348835225,
      "grad_norm": 0.44892260432243347,
      "learning_rate": 3.320675825582388e-05,
      "loss": 0.0021,
      "step": 39360
    },
    {
      "epoch": 3.359501663964502,
      "grad_norm": 0.5028064250946045,
      "learning_rate": 3.320249168017749e-05,
      "loss": 0.002,
      "step": 39370
    },
    {
      "epoch": 3.3603549790937794,
      "grad_norm": 0.1575772762298584,
      "learning_rate": 3.319822510453111e-05,
      "loss": 0.0016,
      "step": 39380
    },
    {
      "epoch": 3.3612082942230566,
      "grad_norm": 0.05781104043126106,
      "learning_rate": 3.3193958528884715e-05,
      "loss": 0.0023,
      "step": 39390
    },
    {
      "epoch": 3.3620616093523337,
      "grad_norm": 0.059158433228731155,
      "learning_rate": 3.3189691953238336e-05,
      "loss": 0.0023,
      "step": 39400
    },
    {
      "epoch": 3.3629149244816112,
      "grad_norm": 0.09475957602262497,
      "learning_rate": 3.3185425377591944e-05,
      "loss": 0.0023,
      "step": 39410
    },
    {
      "epoch": 3.3637682396108883,
      "grad_norm": 0.2905256748199463,
      "learning_rate": 3.318115880194556e-05,
      "loss": 0.0018,
      "step": 39420
    },
    {
      "epoch": 3.3646215547401654,
      "grad_norm": 0.24261072278022766,
      "learning_rate": 3.317689222629917e-05,
      "loss": 0.0013,
      "step": 39430
    },
    {
      "epoch": 3.365474869869443,
      "grad_norm": 0.12449938803911209,
      "learning_rate": 3.3172625650652787e-05,
      "loss": 0.0016,
      "step": 39440
    },
    {
      "epoch": 3.36632818499872,
      "grad_norm": 0.2929639220237732,
      "learning_rate": 3.31683590750064e-05,
      "loss": 0.0022,
      "step": 39450
    },
    {
      "epoch": 3.367181500127997,
      "grad_norm": 0.062291327863931656,
      "learning_rate": 3.3164092499360015e-05,
      "loss": 0.0019,
      "step": 39460
    },
    {
      "epoch": 3.3680348152572743,
      "grad_norm": 0.11298348009586334,
      "learning_rate": 3.315982592371363e-05,
      "loss": 0.0025,
      "step": 39470
    },
    {
      "epoch": 3.368888130386552,
      "grad_norm": 0.0341523177921772,
      "learning_rate": 3.3155559348067244e-05,
      "loss": 0.002,
      "step": 39480
    },
    {
      "epoch": 3.369741445515829,
      "grad_norm": 0.28297823667526245,
      "learning_rate": 3.315129277242086e-05,
      "loss": 0.0015,
      "step": 39490
    },
    {
      "epoch": 3.370594760645106,
      "grad_norm": 0.11536931246519089,
      "learning_rate": 3.314702619677447e-05,
      "loss": 0.0023,
      "step": 39500
    },
    {
      "epoch": 3.3714480757743837,
      "grad_norm": 0.20598894357681274,
      "learning_rate": 3.3142759621128086e-05,
      "loss": 0.0021,
      "step": 39510
    },
    {
      "epoch": 3.3723013909036608,
      "grad_norm": 0.07212471961975098,
      "learning_rate": 3.31384930454817e-05,
      "loss": 0.0015,
      "step": 39520
    },
    {
      "epoch": 3.373154706032938,
      "grad_norm": 0.3692867159843445,
      "learning_rate": 3.313422646983531e-05,
      "loss": 0.0023,
      "step": 39530
    },
    {
      "epoch": 3.374008021162215,
      "grad_norm": 0.08086811006069183,
      "learning_rate": 3.312995989418893e-05,
      "loss": 0.0015,
      "step": 39540
    },
    {
      "epoch": 3.3748613362914925,
      "grad_norm": 0.3166288435459137,
      "learning_rate": 3.3125693318542536e-05,
      "loss": 0.0016,
      "step": 39550
    },
    {
      "epoch": 3.3757146514207697,
      "grad_norm": 0.06720948964357376,
      "learning_rate": 3.312142674289616e-05,
      "loss": 0.0019,
      "step": 39560
    },
    {
      "epoch": 3.3765679665500468,
      "grad_norm": 0.5918095111846924,
      "learning_rate": 3.3117160167249765e-05,
      "loss": 0.0021,
      "step": 39570
    },
    {
      "epoch": 3.3774212816793243,
      "grad_norm": 0.13185806572437286,
      "learning_rate": 3.3112893591603386e-05,
      "loss": 0.0013,
      "step": 39580
    },
    {
      "epoch": 3.3782745968086014,
      "grad_norm": 0.18565772473812103,
      "learning_rate": 3.3108627015956993e-05,
      "loss": 0.0018,
      "step": 39590
    },
    {
      "epoch": 3.3791279119378785,
      "grad_norm": 0.33043181896209717,
      "learning_rate": 3.310436044031061e-05,
      "loss": 0.0022,
      "step": 39600
    },
    {
      "epoch": 3.379981227067156,
      "grad_norm": 0.04768134281039238,
      "learning_rate": 3.310009386466422e-05,
      "loss": 0.0017,
      "step": 39610
    },
    {
      "epoch": 3.380834542196433,
      "grad_norm": 0.2722449004650116,
      "learning_rate": 3.3095827289017836e-05,
      "loss": 0.0021,
      "step": 39620
    },
    {
      "epoch": 3.3816878573257103,
      "grad_norm": 0.1509784758090973,
      "learning_rate": 3.309156071337145e-05,
      "loss": 0.0019,
      "step": 39630
    },
    {
      "epoch": 3.382541172454988,
      "grad_norm": 0.2318907082080841,
      "learning_rate": 3.308729413772506e-05,
      "loss": 0.0018,
      "step": 39640
    },
    {
      "epoch": 3.383394487584265,
      "grad_norm": 0.09737411141395569,
      "learning_rate": 3.308302756207868e-05,
      "loss": 0.0021,
      "step": 39650
    },
    {
      "epoch": 3.384247802713542,
      "grad_norm": 0.24958807229995728,
      "learning_rate": 3.3078760986432286e-05,
      "loss": 0.0016,
      "step": 39660
    },
    {
      "epoch": 3.385101117842819,
      "grad_norm": 0.04772680252790451,
      "learning_rate": 3.307449441078591e-05,
      "loss": 0.0023,
      "step": 39670
    },
    {
      "epoch": 3.3859544329720968,
      "grad_norm": 0.23495438694953918,
      "learning_rate": 3.3070227835139515e-05,
      "loss": 0.0021,
      "step": 39680
    },
    {
      "epoch": 3.386807748101374,
      "grad_norm": 0.2629150450229645,
      "learning_rate": 3.3065961259493136e-05,
      "loss": 0.002,
      "step": 39690
    },
    {
      "epoch": 3.387661063230651,
      "grad_norm": 0.18476572632789612,
      "learning_rate": 3.306169468384674e-05,
      "loss": 0.002,
      "step": 39700
    },
    {
      "epoch": 3.388514378359928,
      "grad_norm": 0.17037129402160645,
      "learning_rate": 3.3057428108200364e-05,
      "loss": 0.002,
      "step": 39710
    },
    {
      "epoch": 3.3893676934892056,
      "grad_norm": 0.024839721620082855,
      "learning_rate": 3.305316153255397e-05,
      "loss": 0.0021,
      "step": 39720
    },
    {
      "epoch": 3.3902210086184827,
      "grad_norm": 0.15385282039642334,
      "learning_rate": 3.3048894956907586e-05,
      "loss": 0.0022,
      "step": 39730
    },
    {
      "epoch": 3.39107432374776,
      "grad_norm": 0.09247466921806335,
      "learning_rate": 3.30446283812612e-05,
      "loss": 0.002,
      "step": 39740
    },
    {
      "epoch": 3.3919276388770374,
      "grad_norm": 0.08301063627004623,
      "learning_rate": 3.3040361805614815e-05,
      "loss": 0.0017,
      "step": 39750
    },
    {
      "epoch": 3.3927809540063145,
      "grad_norm": 0.08404259383678436,
      "learning_rate": 3.303609522996843e-05,
      "loss": 0.0013,
      "step": 39760
    },
    {
      "epoch": 3.3936342691355916,
      "grad_norm": 0.1292974203824997,
      "learning_rate": 3.303182865432204e-05,
      "loss": 0.0019,
      "step": 39770
    },
    {
      "epoch": 3.394487584264869,
      "grad_norm": 0.0773262158036232,
      "learning_rate": 3.302756207867566e-05,
      "loss": 0.0016,
      "step": 39780
    },
    {
      "epoch": 3.3953408993941463,
      "grad_norm": 0.2955743968486786,
      "learning_rate": 3.302329550302927e-05,
      "loss": 0.003,
      "step": 39790
    },
    {
      "epoch": 3.3961942145234234,
      "grad_norm": 0.3295605480670929,
      "learning_rate": 3.3019028927382886e-05,
      "loss": 0.0023,
      "step": 39800
    },
    {
      "epoch": 3.397047529652701,
      "grad_norm": 0.05877058580517769,
      "learning_rate": 3.30147623517365e-05,
      "loss": 0.0022,
      "step": 39810
    },
    {
      "epoch": 3.397900844781978,
      "grad_norm": 0.17278176546096802,
      "learning_rate": 3.3010495776090114e-05,
      "loss": 0.0019,
      "step": 39820
    },
    {
      "epoch": 3.398754159911255,
      "grad_norm": 0.270455926656723,
      "learning_rate": 3.300622920044373e-05,
      "loss": 0.0017,
      "step": 39830
    },
    {
      "epoch": 3.3996074750405323,
      "grad_norm": 0.04557216167449951,
      "learning_rate": 3.3001962624797336e-05,
      "loss": 0.0017,
      "step": 39840
    },
    {
      "epoch": 3.40046079016981,
      "grad_norm": 0.13044029474258423,
      "learning_rate": 3.299769604915096e-05,
      "loss": 0.0018,
      "step": 39850
    },
    {
      "epoch": 3.401314105299087,
      "grad_norm": 0.3187931478023529,
      "learning_rate": 3.2993429473504564e-05,
      "loss": 0.0017,
      "step": 39860
    },
    {
      "epoch": 3.402167420428364,
      "grad_norm": 0.0285735335201025,
      "learning_rate": 3.298916289785818e-05,
      "loss": 0.0027,
      "step": 39870
    },
    {
      "epoch": 3.4030207355576416,
      "grad_norm": 0.06287171691656113,
      "learning_rate": 3.298489632221179e-05,
      "loss": 0.0023,
      "step": 39880
    },
    {
      "epoch": 3.4038740506869187,
      "grad_norm": 0.2618655860424042,
      "learning_rate": 3.298062974656541e-05,
      "loss": 0.0022,
      "step": 39890
    },
    {
      "epoch": 3.404727365816196,
      "grad_norm": 0.06346911191940308,
      "learning_rate": 3.297636317091902e-05,
      "loss": 0.0017,
      "step": 39900
    },
    {
      "epoch": 3.405580680945473,
      "grad_norm": 0.04032530635595322,
      "learning_rate": 3.2972096595272636e-05,
      "loss": 0.0015,
      "step": 39910
    },
    {
      "epoch": 3.4064339960747505,
      "grad_norm": 0.39121443033218384,
      "learning_rate": 3.296783001962625e-05,
      "loss": 0.0016,
      "step": 39920
    },
    {
      "epoch": 3.4072873112040276,
      "grad_norm": 0.3013949692249298,
      "learning_rate": 3.2963563443979864e-05,
      "loss": 0.0015,
      "step": 39930
    },
    {
      "epoch": 3.4081406263333047,
      "grad_norm": 0.30638387799263,
      "learning_rate": 3.295929686833348e-05,
      "loss": 0.002,
      "step": 39940
    },
    {
      "epoch": 3.4089939414625823,
      "grad_norm": 0.050522301346063614,
      "learning_rate": 3.2955030292687086e-05,
      "loss": 0.0023,
      "step": 39950
    },
    {
      "epoch": 3.4098472565918594,
      "grad_norm": 0.08243727684020996,
      "learning_rate": 3.295076371704071e-05,
      "loss": 0.0018,
      "step": 39960
    },
    {
      "epoch": 3.4107005717211365,
      "grad_norm": 0.23006656765937805,
      "learning_rate": 3.2946497141394314e-05,
      "loss": 0.0017,
      "step": 39970
    },
    {
      "epoch": 3.411553886850414,
      "grad_norm": 0.23555070161819458,
      "learning_rate": 3.2942230565747935e-05,
      "loss": 0.0014,
      "step": 39980
    },
    {
      "epoch": 3.412407201979691,
      "grad_norm": 0.24302729964256287,
      "learning_rate": 3.293796399010154e-05,
      "loss": 0.0023,
      "step": 39990
    },
    {
      "epoch": 3.4132605171089683,
      "grad_norm": 0.3974415957927704,
      "learning_rate": 3.2933697414455164e-05,
      "loss": 0.0021,
      "step": 40000
    },
    {
      "epoch": 3.414113832238246,
      "grad_norm": 0.07603219896554947,
      "learning_rate": 3.292943083880877e-05,
      "loss": 0.0016,
      "step": 40010
    },
    {
      "epoch": 3.414967147367523,
      "grad_norm": 0.09478287398815155,
      "learning_rate": 3.292516426316239e-05,
      "loss": 0.0022,
      "step": 40020
    },
    {
      "epoch": 3.4158204624968,
      "grad_norm": 0.3707897663116455,
      "learning_rate": 3.2920897687516e-05,
      "loss": 0.0021,
      "step": 40030
    },
    {
      "epoch": 3.416673777626077,
      "grad_norm": 0.10768290609121323,
      "learning_rate": 3.2916631111869614e-05,
      "loss": 0.0015,
      "step": 40040
    },
    {
      "epoch": 3.4175270927553547,
      "grad_norm": 0.4204251766204834,
      "learning_rate": 3.291236453622323e-05,
      "loss": 0.0025,
      "step": 40050
    },
    {
      "epoch": 3.418380407884632,
      "grad_norm": 0.19816410541534424,
      "learning_rate": 3.290809796057684e-05,
      "loss": 0.0021,
      "step": 40060
    },
    {
      "epoch": 3.419233723013909,
      "grad_norm": 0.39546164870262146,
      "learning_rate": 3.290383138493046e-05,
      "loss": 0.0015,
      "step": 40070
    },
    {
      "epoch": 3.420087038143186,
      "grad_norm": 0.20609642565250397,
      "learning_rate": 3.289956480928407e-05,
      "loss": 0.0023,
      "step": 40080
    },
    {
      "epoch": 3.4209403532724636,
      "grad_norm": 0.41461342573165894,
      "learning_rate": 3.2895298233637685e-05,
      "loss": 0.0023,
      "step": 40090
    },
    {
      "epoch": 3.4217936684017407,
      "grad_norm": 0.3921835422515869,
      "learning_rate": 3.28910316579913e-05,
      "loss": 0.0032,
      "step": 40100
    },
    {
      "epoch": 3.422646983531018,
      "grad_norm": 0.0467214435338974,
      "learning_rate": 3.2886765082344914e-05,
      "loss": 0.0022,
      "step": 40110
    },
    {
      "epoch": 3.4235002986602954,
      "grad_norm": 0.03802986815571785,
      "learning_rate": 3.288249850669853e-05,
      "loss": 0.0025,
      "step": 40120
    },
    {
      "epoch": 3.4243536137895725,
      "grad_norm": 0.09783876687288284,
      "learning_rate": 3.287823193105214e-05,
      "loss": 0.0023,
      "step": 40130
    },
    {
      "epoch": 3.4252069289188496,
      "grad_norm": 0.22675469517707825,
      "learning_rate": 3.287396535540575e-05,
      "loss": 0.002,
      "step": 40140
    },
    {
      "epoch": 3.426060244048127,
      "grad_norm": 0.14382071793079376,
      "learning_rate": 3.2869698779759364e-05,
      "loss": 0.0019,
      "step": 40150
    },
    {
      "epoch": 3.4269135591774043,
      "grad_norm": 0.21734581887722015,
      "learning_rate": 3.286543220411298e-05,
      "loss": 0.0025,
      "step": 40160
    },
    {
      "epoch": 3.4277668743066814,
      "grad_norm": 0.15100011229515076,
      "learning_rate": 3.286116562846659e-05,
      "loss": 0.0016,
      "step": 40170
    },
    {
      "epoch": 3.428620189435959,
      "grad_norm": 0.03214665502309799,
      "learning_rate": 3.2856899052820207e-05,
      "loss": 0.002,
      "step": 40180
    },
    {
      "epoch": 3.429473504565236,
      "grad_norm": 0.09421023726463318,
      "learning_rate": 3.285263247717382e-05,
      "loss": 0.0017,
      "step": 40190
    },
    {
      "epoch": 3.430326819694513,
      "grad_norm": 0.04056983068585396,
      "learning_rate": 3.2848365901527435e-05,
      "loss": 0.0016,
      "step": 40200
    },
    {
      "epoch": 3.4311801348237903,
      "grad_norm": 0.26045119762420654,
      "learning_rate": 3.284409932588105e-05,
      "loss": 0.0017,
      "step": 40210
    },
    {
      "epoch": 3.432033449953068,
      "grad_norm": 0.09498348832130432,
      "learning_rate": 3.2839832750234664e-05,
      "loss": 0.0023,
      "step": 40220
    },
    {
      "epoch": 3.432886765082345,
      "grad_norm": 0.1556268185377121,
      "learning_rate": 3.283556617458828e-05,
      "loss": 0.0019,
      "step": 40230
    },
    {
      "epoch": 3.433740080211622,
      "grad_norm": 0.22255447506904602,
      "learning_rate": 3.283129959894189e-05,
      "loss": 0.0014,
      "step": 40240
    },
    {
      "epoch": 3.4345933953408996,
      "grad_norm": 0.2484860122203827,
      "learning_rate": 3.2827033023295506e-05,
      "loss": 0.0015,
      "step": 40250
    },
    {
      "epoch": 3.4354467104701767,
      "grad_norm": 0.05421975255012512,
      "learning_rate": 3.2822766447649114e-05,
      "loss": 0.0023,
      "step": 40260
    },
    {
      "epoch": 3.436300025599454,
      "grad_norm": 0.047182079404592514,
      "learning_rate": 3.2818499872002735e-05,
      "loss": 0.0024,
      "step": 40270
    },
    {
      "epoch": 3.437153340728731,
      "grad_norm": 0.2199605107307434,
      "learning_rate": 3.281423329635634e-05,
      "loss": 0.0029,
      "step": 40280
    },
    {
      "epoch": 3.4380066558580085,
      "grad_norm": 0.03867661580443382,
      "learning_rate": 3.280996672070996e-05,
      "loss": 0.0021,
      "step": 40290
    },
    {
      "epoch": 3.4388599709872856,
      "grad_norm": 0.07611034065485,
      "learning_rate": 3.280570014506357e-05,
      "loss": 0.0023,
      "step": 40300
    },
    {
      "epoch": 3.4397132861165627,
      "grad_norm": 0.37216389179229736,
      "learning_rate": 3.280143356941719e-05,
      "loss": 0.002,
      "step": 40310
    },
    {
      "epoch": 3.4405666012458402,
      "grad_norm": 0.13537660241127014,
      "learning_rate": 3.27971669937708e-05,
      "loss": 0.0022,
      "step": 40320
    },
    {
      "epoch": 3.4414199163751173,
      "grad_norm": 0.37086576223373413,
      "learning_rate": 3.279290041812442e-05,
      "loss": 0.0021,
      "step": 40330
    },
    {
      "epoch": 3.4422732315043945,
      "grad_norm": 0.24931849539279938,
      "learning_rate": 3.278863384247803e-05,
      "loss": 0.002,
      "step": 40340
    },
    {
      "epoch": 3.443126546633672,
      "grad_norm": 0.03199409320950508,
      "learning_rate": 3.278436726683164e-05,
      "loss": 0.0016,
      "step": 40350
    },
    {
      "epoch": 3.443979861762949,
      "grad_norm": 0.0805387794971466,
      "learning_rate": 3.2780100691185256e-05,
      "loss": 0.0021,
      "step": 40360
    },
    {
      "epoch": 3.4448331768922262,
      "grad_norm": 0.12117544561624527,
      "learning_rate": 3.277583411553887e-05,
      "loss": 0.0024,
      "step": 40370
    },
    {
      "epoch": 3.445686492021504,
      "grad_norm": 0.14794185757637024,
      "learning_rate": 3.2771567539892485e-05,
      "loss": 0.0018,
      "step": 40380
    },
    {
      "epoch": 3.446539807150781,
      "grad_norm": 0.0627155676484108,
      "learning_rate": 3.27673009642461e-05,
      "loss": 0.002,
      "step": 40390
    },
    {
      "epoch": 3.447393122280058,
      "grad_norm": 0.23434852063655853,
      "learning_rate": 3.276303438859971e-05,
      "loss": 0.002,
      "step": 40400
    },
    {
      "epoch": 3.448246437409335,
      "grad_norm": 0.4686826467514038,
      "learning_rate": 3.275876781295332e-05,
      "loss": 0.0017,
      "step": 40410
    },
    {
      "epoch": 3.4490997525386127,
      "grad_norm": 0.1897580921649933,
      "learning_rate": 3.275450123730694e-05,
      "loss": 0.0018,
      "step": 40420
    },
    {
      "epoch": 3.44995306766789,
      "grad_norm": 0.1693774312734604,
      "learning_rate": 3.275023466166055e-05,
      "loss": 0.0016,
      "step": 40430
    },
    {
      "epoch": 3.450806382797167,
      "grad_norm": 0.2788154184818268,
      "learning_rate": 3.274596808601417e-05,
      "loss": 0.0019,
      "step": 40440
    },
    {
      "epoch": 3.451659697926444,
      "grad_norm": 0.27934569120407104,
      "learning_rate": 3.274170151036778e-05,
      "loss": 0.0023,
      "step": 40450
    },
    {
      "epoch": 3.4525130130557216,
      "grad_norm": 0.30360355973243713,
      "learning_rate": 3.273743493472139e-05,
      "loss": 0.0015,
      "step": 40460
    },
    {
      "epoch": 3.4533663281849987,
      "grad_norm": 0.21918313205242157,
      "learning_rate": 3.2733168359075006e-05,
      "loss": 0.0024,
      "step": 40470
    },
    {
      "epoch": 3.454219643314276,
      "grad_norm": 0.3489782512187958,
      "learning_rate": 3.272890178342862e-05,
      "loss": 0.0017,
      "step": 40480
    },
    {
      "epoch": 3.4550729584435533,
      "grad_norm": 0.2969507575035095,
      "learning_rate": 3.2724635207782234e-05,
      "loss": 0.0026,
      "step": 40490
    },
    {
      "epoch": 3.4559262735728304,
      "grad_norm": 0.32068634033203125,
      "learning_rate": 3.272036863213585e-05,
      "loss": 0.0026,
      "step": 40500
    },
    {
      "epoch": 3.4567795887021076,
      "grad_norm": 0.06388841569423676,
      "learning_rate": 3.271610205648946e-05,
      "loss": 0.0016,
      "step": 40510
    },
    {
      "epoch": 3.457632903831385,
      "grad_norm": 0.20609277486801147,
      "learning_rate": 3.271183548084308e-05,
      "loss": 0.0018,
      "step": 40520
    },
    {
      "epoch": 3.458486218960662,
      "grad_norm": 0.2897266447544098,
      "learning_rate": 3.270756890519669e-05,
      "loss": 0.0022,
      "step": 40530
    },
    {
      "epoch": 3.4593395340899393,
      "grad_norm": 0.11418469250202179,
      "learning_rate": 3.2703302329550306e-05,
      "loss": 0.0021,
      "step": 40540
    },
    {
      "epoch": 3.460192849219217,
      "grad_norm": 0.33137965202331543,
      "learning_rate": 3.269903575390392e-05,
      "loss": 0.0019,
      "step": 40550
    },
    {
      "epoch": 3.461046164348494,
      "grad_norm": 0.07856684178113937,
      "learning_rate": 3.2694769178257534e-05,
      "loss": 0.0016,
      "step": 40560
    },
    {
      "epoch": 3.461899479477771,
      "grad_norm": 0.025625906884670258,
      "learning_rate": 3.269050260261114e-05,
      "loss": 0.0023,
      "step": 40570
    },
    {
      "epoch": 3.462752794607048,
      "grad_norm": 0.3038283586502075,
      "learning_rate": 3.268623602696476e-05,
      "loss": 0.0017,
      "step": 40580
    },
    {
      "epoch": 3.4636061097363258,
      "grad_norm": 0.11376538872718811,
      "learning_rate": 3.268196945131837e-05,
      "loss": 0.0017,
      "step": 40590
    },
    {
      "epoch": 3.464459424865603,
      "grad_norm": 0.1893889456987381,
      "learning_rate": 3.267770287567199e-05,
      "loss": 0.0019,
      "step": 40600
    },
    {
      "epoch": 3.46531273999488,
      "grad_norm": 0.1680622547864914,
      "learning_rate": 3.26734363000256e-05,
      "loss": 0.0026,
      "step": 40610
    },
    {
      "epoch": 3.4661660551241575,
      "grad_norm": 0.2431516796350479,
      "learning_rate": 3.266916972437922e-05,
      "loss": 0.0023,
      "step": 40620
    },
    {
      "epoch": 3.4670193702534347,
      "grad_norm": 0.13761384785175323,
      "learning_rate": 3.266490314873283e-05,
      "loss": 0.0023,
      "step": 40630
    },
    {
      "epoch": 3.4678726853827118,
      "grad_norm": 0.18698875606060028,
      "learning_rate": 3.266063657308645e-05,
      "loss": 0.0021,
      "step": 40640
    },
    {
      "epoch": 3.468726000511989,
      "grad_norm": 0.1925075352191925,
      "learning_rate": 3.2656369997440056e-05,
      "loss": 0.0015,
      "step": 40650
    },
    {
      "epoch": 3.4695793156412664,
      "grad_norm": 0.09966030716896057,
      "learning_rate": 3.265210342179367e-05,
      "loss": 0.0021,
      "step": 40660
    },
    {
      "epoch": 3.4704326307705435,
      "grad_norm": 0.22300973534584045,
      "learning_rate": 3.2647836846147284e-05,
      "loss": 0.0018,
      "step": 40670
    },
    {
      "epoch": 3.4712859458998206,
      "grad_norm": 0.18891757726669312,
      "learning_rate": 3.26435702705009e-05,
      "loss": 0.0023,
      "step": 40680
    },
    {
      "epoch": 3.472139261029098,
      "grad_norm": 0.24432037770748138,
      "learning_rate": 3.263930369485451e-05,
      "loss": 0.0024,
      "step": 40690
    },
    {
      "epoch": 3.4729925761583753,
      "grad_norm": 0.21211156249046326,
      "learning_rate": 3.263503711920812e-05,
      "loss": 0.0021,
      "step": 40700
    },
    {
      "epoch": 3.4738458912876524,
      "grad_norm": 0.1311037540435791,
      "learning_rate": 3.263077054356174e-05,
      "loss": 0.0023,
      "step": 40710
    },
    {
      "epoch": 3.47469920641693,
      "grad_norm": 0.24220861494541168,
      "learning_rate": 3.262650396791535e-05,
      "loss": 0.002,
      "step": 40720
    },
    {
      "epoch": 3.475552521546207,
      "grad_norm": 0.15008947253227234,
      "learning_rate": 3.262223739226897e-05,
      "loss": 0.0023,
      "step": 40730
    },
    {
      "epoch": 3.476405836675484,
      "grad_norm": 0.08531123399734497,
      "learning_rate": 3.261797081662258e-05,
      "loss": 0.0024,
      "step": 40740
    },
    {
      "epoch": 3.4772591518047613,
      "grad_norm": 0.037970807403326035,
      "learning_rate": 3.26137042409762e-05,
      "loss": 0.0016,
      "step": 40750
    },
    {
      "epoch": 3.478112466934039,
      "grad_norm": 0.22794491052627563,
      "learning_rate": 3.2609437665329805e-05,
      "loss": 0.0029,
      "step": 40760
    },
    {
      "epoch": 3.478965782063316,
      "grad_norm": 0.3186253607273102,
      "learning_rate": 3.260517108968342e-05,
      "loss": 0.0021,
      "step": 40770
    },
    {
      "epoch": 3.479819097192593,
      "grad_norm": 0.20579776167869568,
      "learning_rate": 3.2600904514037034e-05,
      "loss": 0.0016,
      "step": 40780
    },
    {
      "epoch": 3.4806724123218706,
      "grad_norm": 0.2086394876241684,
      "learning_rate": 3.259663793839065e-05,
      "loss": 0.0019,
      "step": 40790
    },
    {
      "epoch": 3.4815257274511477,
      "grad_norm": 0.05068158358335495,
      "learning_rate": 3.259237136274426e-05,
      "loss": 0.0021,
      "step": 40800
    },
    {
      "epoch": 3.482379042580425,
      "grad_norm": 0.08079773932695389,
      "learning_rate": 3.258810478709788e-05,
      "loss": 0.0021,
      "step": 40810
    },
    {
      "epoch": 3.483232357709702,
      "grad_norm": 0.20671626925468445,
      "learning_rate": 3.258383821145149e-05,
      "loss": 0.0023,
      "step": 40820
    },
    {
      "epoch": 3.4840856728389795,
      "grad_norm": 0.4178614318370819,
      "learning_rate": 3.2579571635805105e-05,
      "loss": 0.0023,
      "step": 40830
    },
    {
      "epoch": 3.4849389879682566,
      "grad_norm": 0.28102239966392517,
      "learning_rate": 3.257530506015872e-05,
      "loss": 0.0021,
      "step": 40840
    },
    {
      "epoch": 3.4857923030975337,
      "grad_norm": 0.11879496276378632,
      "learning_rate": 3.2571038484512334e-05,
      "loss": 0.0017,
      "step": 40850
    },
    {
      "epoch": 3.4866456182268113,
      "grad_norm": 0.201382577419281,
      "learning_rate": 3.256677190886595e-05,
      "loss": 0.0029,
      "step": 40860
    },
    {
      "epoch": 3.4874989333560884,
      "grad_norm": 0.24799540638923645,
      "learning_rate": 3.256250533321956e-05,
      "loss": 0.0018,
      "step": 40870
    },
    {
      "epoch": 3.4883522484853655,
      "grad_norm": 0.2468830794095993,
      "learning_rate": 3.255823875757317e-05,
      "loss": 0.0022,
      "step": 40880
    },
    {
      "epoch": 3.489205563614643,
      "grad_norm": 0.20810358226299286,
      "learning_rate": 3.255397218192679e-05,
      "loss": 0.0019,
      "step": 40890
    },
    {
      "epoch": 3.49005887874392,
      "grad_norm": 0.24706493318080902,
      "learning_rate": 3.25497056062804e-05,
      "loss": 0.0016,
      "step": 40900
    },
    {
      "epoch": 3.4909121938731973,
      "grad_norm": 0.060819465667009354,
      "learning_rate": 3.254543903063402e-05,
      "loss": 0.0022,
      "step": 40910
    },
    {
      "epoch": 3.491765509002475,
      "grad_norm": 0.4301532506942749,
      "learning_rate": 3.2541172454987627e-05,
      "loss": 0.0015,
      "step": 40920
    },
    {
      "epoch": 3.492618824131752,
      "grad_norm": 0.1212279200553894,
      "learning_rate": 3.253690587934124e-05,
      "loss": 0.0027,
      "step": 40930
    },
    {
      "epoch": 3.493472139261029,
      "grad_norm": 0.2805574834346771,
      "learning_rate": 3.2532639303694855e-05,
      "loss": 0.0019,
      "step": 40940
    },
    {
      "epoch": 3.494325454390306,
      "grad_norm": 0.0797390267252922,
      "learning_rate": 3.252837272804847e-05,
      "loss": 0.0022,
      "step": 40950
    },
    {
      "epoch": 3.4951787695195837,
      "grad_norm": 0.045184176415205,
      "learning_rate": 3.2524106152402083e-05,
      "loss": 0.0021,
      "step": 40960
    },
    {
      "epoch": 3.496032084648861,
      "grad_norm": 0.0770624503493309,
      "learning_rate": 3.25198395767557e-05,
      "loss": 0.0027,
      "step": 40970
    },
    {
      "epoch": 3.496885399778138,
      "grad_norm": 0.1867101639509201,
      "learning_rate": 3.251557300110931e-05,
      "loss": 0.0019,
      "step": 40980
    },
    {
      "epoch": 3.4977387149074155,
      "grad_norm": 0.04670125991106033,
      "learning_rate": 3.2511306425462926e-05,
      "loss": 0.002,
      "step": 40990
    },
    {
      "epoch": 3.4985920300366926,
      "grad_norm": 0.2702611982822418,
      "learning_rate": 3.250703984981654e-05,
      "loss": 0.0022,
      "step": 41000
    },
    {
      "epoch": 3.4994453451659697,
      "grad_norm": 0.17353980243206024,
      "learning_rate": 3.250277327417015e-05,
      "loss": 0.0022,
      "step": 41010
    },
    {
      "epoch": 3.500298660295247,
      "grad_norm": 0.147600919008255,
      "learning_rate": 3.249850669852377e-05,
      "loss": 0.0023,
      "step": 41020
    },
    {
      "epoch": 3.5011519754245244,
      "grad_norm": 0.16910836100578308,
      "learning_rate": 3.2494240122877376e-05,
      "loss": 0.0019,
      "step": 41030
    },
    {
      "epoch": 3.5020052905538015,
      "grad_norm": 0.13274221122264862,
      "learning_rate": 3.2489973547231e-05,
      "loss": 0.0015,
      "step": 41040
    },
    {
      "epoch": 3.5028586056830786,
      "grad_norm": 0.5001286268234253,
      "learning_rate": 3.2485706971584605e-05,
      "loss": 0.0021,
      "step": 41050
    },
    {
      "epoch": 3.503711920812356,
      "grad_norm": 0.23096540570259094,
      "learning_rate": 3.2481440395938226e-05,
      "loss": 0.0018,
      "step": 41060
    },
    {
      "epoch": 3.5045652359416333,
      "grad_norm": 0.27809789776802063,
      "learning_rate": 3.247717382029183e-05,
      "loss": 0.0023,
      "step": 41070
    },
    {
      "epoch": 3.5054185510709104,
      "grad_norm": 0.20940443873405457,
      "learning_rate": 3.247290724464545e-05,
      "loss": 0.0022,
      "step": 41080
    },
    {
      "epoch": 3.506271866200188,
      "grad_norm": 0.12984758615493774,
      "learning_rate": 3.246864066899906e-05,
      "loss": 0.0016,
      "step": 41090
    },
    {
      "epoch": 3.507125181329465,
      "grad_norm": 0.43679529428482056,
      "learning_rate": 3.2464374093352676e-05,
      "loss": 0.0018,
      "step": 41100
    },
    {
      "epoch": 3.507978496458742,
      "grad_norm": 0.3888569474220276,
      "learning_rate": 3.246010751770629e-05,
      "loss": 0.0026,
      "step": 41110
    },
    {
      "epoch": 3.5088318115880197,
      "grad_norm": 0.035237353295087814,
      "learning_rate": 3.2455840942059905e-05,
      "loss": 0.0019,
      "step": 41120
    },
    {
      "epoch": 3.509685126717297,
      "grad_norm": 0.3729077875614166,
      "learning_rate": 3.245157436641352e-05,
      "loss": 0.0019,
      "step": 41130
    },
    {
      "epoch": 3.510538441846574,
      "grad_norm": 0.41070646047592163,
      "learning_rate": 3.244730779076713e-05,
      "loss": 0.0023,
      "step": 41140
    },
    {
      "epoch": 3.511391756975851,
      "grad_norm": 0.09980513900518417,
      "learning_rate": 3.244304121512075e-05,
      "loss": 0.0018,
      "step": 41150
    },
    {
      "epoch": 3.512245072105128,
      "grad_norm": 0.42815011739730835,
      "learning_rate": 3.243877463947436e-05,
      "loss": 0.0018,
      "step": 41160
    },
    {
      "epoch": 3.5130983872344057,
      "grad_norm": 0.024413511157035828,
      "learning_rate": 3.2434508063827976e-05,
      "loss": 0.002,
      "step": 41170
    },
    {
      "epoch": 3.513951702363683,
      "grad_norm": 0.18940280377864838,
      "learning_rate": 3.243024148818159e-05,
      "loss": 0.0026,
      "step": 41180
    },
    {
      "epoch": 3.51480501749296,
      "grad_norm": 0.26064619421958923,
      "learning_rate": 3.24259749125352e-05,
      "loss": 0.0027,
      "step": 41190
    },
    {
      "epoch": 3.5156583326222375,
      "grad_norm": 0.05555045232176781,
      "learning_rate": 3.242170833688881e-05,
      "loss": 0.0018,
      "step": 41200
    },
    {
      "epoch": 3.5165116477515146,
      "grad_norm": 0.16515018045902252,
      "learning_rate": 3.2417441761242426e-05,
      "loss": 0.0025,
      "step": 41210
    },
    {
      "epoch": 3.5173649628807917,
      "grad_norm": 0.31771373748779297,
      "learning_rate": 3.241317518559604e-05,
      "loss": 0.0016,
      "step": 41220
    },
    {
      "epoch": 3.5182182780100693,
      "grad_norm": 0.07423651218414307,
      "learning_rate": 3.2408908609949654e-05,
      "loss": 0.0015,
      "step": 41230
    },
    {
      "epoch": 3.5190715931393464,
      "grad_norm": 0.15151140093803406,
      "learning_rate": 3.240464203430327e-05,
      "loss": 0.0018,
      "step": 41240
    },
    {
      "epoch": 3.5199249082686235,
      "grad_norm": 0.3006070554256439,
      "learning_rate": 3.240037545865688e-05,
      "loss": 0.0015,
      "step": 41250
    },
    {
      "epoch": 3.520778223397901,
      "grad_norm": 0.2583339512348175,
      "learning_rate": 3.23961088830105e-05,
      "loss": 0.0024,
      "step": 41260
    },
    {
      "epoch": 3.521631538527178,
      "grad_norm": 0.07659546285867691,
      "learning_rate": 3.239184230736411e-05,
      "loss": 0.002,
      "step": 41270
    },
    {
      "epoch": 3.5224848536564553,
      "grad_norm": 0.07670947909355164,
      "learning_rate": 3.2387575731717726e-05,
      "loss": 0.0018,
      "step": 41280
    },
    {
      "epoch": 3.523338168785733,
      "grad_norm": 0.448081374168396,
      "learning_rate": 3.238330915607134e-05,
      "loss": 0.0016,
      "step": 41290
    },
    {
      "epoch": 3.52419148391501,
      "grad_norm": 0.08052214235067368,
      "learning_rate": 3.2379042580424954e-05,
      "loss": 0.002,
      "step": 41300
    },
    {
      "epoch": 3.525044799044287,
      "grad_norm": 0.23947906494140625,
      "learning_rate": 3.237477600477857e-05,
      "loss": 0.002,
      "step": 41310
    },
    {
      "epoch": 3.525898114173564,
      "grad_norm": 0.6149548292160034,
      "learning_rate": 3.2370509429132176e-05,
      "loss": 0.0024,
      "step": 41320
    },
    {
      "epoch": 3.5267514293028417,
      "grad_norm": 0.09752535820007324,
      "learning_rate": 3.23662428534858e-05,
      "loss": 0.0023,
      "step": 41330
    },
    {
      "epoch": 3.527604744432119,
      "grad_norm": 0.1318114548921585,
      "learning_rate": 3.2361976277839404e-05,
      "loss": 0.0022,
      "step": 41340
    },
    {
      "epoch": 3.528458059561396,
      "grad_norm": 0.16885827481746674,
      "learning_rate": 3.2357709702193025e-05,
      "loss": 0.0021,
      "step": 41350
    },
    {
      "epoch": 3.529311374690673,
      "grad_norm": 0.09319432079792023,
      "learning_rate": 3.235344312654663e-05,
      "loss": 0.0019,
      "step": 41360
    },
    {
      "epoch": 3.5301646898199506,
      "grad_norm": 0.33926156163215637,
      "learning_rate": 3.2349176550900254e-05,
      "loss": 0.0019,
      "step": 41370
    },
    {
      "epoch": 3.5310180049492277,
      "grad_norm": 0.11169777065515518,
      "learning_rate": 3.234490997525386e-05,
      "loss": 0.0015,
      "step": 41380
    },
    {
      "epoch": 3.531871320078505,
      "grad_norm": 0.3943290412425995,
      "learning_rate": 3.2340643399607476e-05,
      "loss": 0.0017,
      "step": 41390
    },
    {
      "epoch": 3.5327246352077823,
      "grad_norm": 0.3342527449131012,
      "learning_rate": 3.233637682396109e-05,
      "loss": 0.0022,
      "step": 41400
    },
    {
      "epoch": 3.5335779503370595,
      "grad_norm": 0.119809091091156,
      "learning_rate": 3.2332110248314704e-05,
      "loss": 0.0017,
      "step": 41410
    },
    {
      "epoch": 3.5344312654663366,
      "grad_norm": 0.23555001616477966,
      "learning_rate": 3.232784367266832e-05,
      "loss": 0.0018,
      "step": 41420
    },
    {
      "epoch": 3.535284580595614,
      "grad_norm": 0.08060802519321442,
      "learning_rate": 3.232357709702193e-05,
      "loss": 0.0017,
      "step": 41430
    },
    {
      "epoch": 3.5361378957248912,
      "grad_norm": 0.4853880703449249,
      "learning_rate": 3.231931052137555e-05,
      "loss": 0.0021,
      "step": 41440
    },
    {
      "epoch": 3.5369912108541683,
      "grad_norm": 0.08716119080781937,
      "learning_rate": 3.231504394572916e-05,
      "loss": 0.0024,
      "step": 41450
    },
    {
      "epoch": 3.537844525983446,
      "grad_norm": 0.1876770704984665,
      "learning_rate": 3.2310777370082775e-05,
      "loss": 0.0025,
      "step": 41460
    },
    {
      "epoch": 3.538697841112723,
      "grad_norm": 0.07941878587007523,
      "learning_rate": 3.230651079443638e-05,
      "loss": 0.0029,
      "step": 41470
    },
    {
      "epoch": 3.539551156242,
      "grad_norm": 0.11294257640838623,
      "learning_rate": 3.2302244218790004e-05,
      "loss": 0.0028,
      "step": 41480
    },
    {
      "epoch": 3.5404044713712777,
      "grad_norm": 0.04423045739531517,
      "learning_rate": 3.229797764314361e-05,
      "loss": 0.0021,
      "step": 41490
    },
    {
      "epoch": 3.541257786500555,
      "grad_norm": 0.22236336767673492,
      "learning_rate": 3.2293711067497225e-05,
      "loss": 0.0019,
      "step": 41500
    },
    {
      "epoch": 3.542111101629832,
      "grad_norm": 0.11560551077127457,
      "learning_rate": 3.228944449185084e-05,
      "loss": 0.0023,
      "step": 41510
    },
    {
      "epoch": 3.542964416759109,
      "grad_norm": 0.2113437056541443,
      "learning_rate": 3.2285177916204454e-05,
      "loss": 0.002,
      "step": 41520
    },
    {
      "epoch": 3.543817731888386,
      "grad_norm": 0.22550566494464874,
      "learning_rate": 3.228091134055807e-05,
      "loss": 0.0022,
      "step": 41530
    },
    {
      "epoch": 3.5446710470176637,
      "grad_norm": 0.4997541606426239,
      "learning_rate": 3.227664476491168e-05,
      "loss": 0.0023,
      "step": 41540
    },
    {
      "epoch": 3.5455243621469408,
      "grad_norm": 0.0316411517560482,
      "learning_rate": 3.2272378189265297e-05,
      "loss": 0.0027,
      "step": 41550
    },
    {
      "epoch": 3.546377677276218,
      "grad_norm": 0.029674267396330833,
      "learning_rate": 3.226811161361891e-05,
      "loss": 0.0021,
      "step": 41560
    },
    {
      "epoch": 3.5472309924054954,
      "grad_norm": 0.32053372263908386,
      "learning_rate": 3.2263845037972525e-05,
      "loss": 0.0022,
      "step": 41570
    },
    {
      "epoch": 3.5480843075347726,
      "grad_norm": 0.17867249250411987,
      "learning_rate": 3.225957846232614e-05,
      "loss": 0.0019,
      "step": 41580
    },
    {
      "epoch": 3.5489376226640497,
      "grad_norm": 0.16838082671165466,
      "learning_rate": 3.2255311886679754e-05,
      "loss": 0.0019,
      "step": 41590
    },
    {
      "epoch": 3.549790937793327,
      "grad_norm": 0.1404104381799698,
      "learning_rate": 3.225104531103337e-05,
      "loss": 0.0019,
      "step": 41600
    },
    {
      "epoch": 3.5506442529226043,
      "grad_norm": 0.11320196837186813,
      "learning_rate": 3.224677873538698e-05,
      "loss": 0.0022,
      "step": 41610
    },
    {
      "epoch": 3.5514975680518814,
      "grad_norm": 0.27520543336868286,
      "learning_rate": 3.2242512159740596e-05,
      "loss": 0.0016,
      "step": 41620
    },
    {
      "epoch": 3.552350883181159,
      "grad_norm": 0.11892373114824295,
      "learning_rate": 3.2238245584094204e-05,
      "loss": 0.0023,
      "step": 41630
    },
    {
      "epoch": 3.553204198310436,
      "grad_norm": 0.1382681280374527,
      "learning_rate": 3.2233979008447825e-05,
      "loss": 0.0019,
      "step": 41640
    },
    {
      "epoch": 3.554057513439713,
      "grad_norm": 0.15137632191181183,
      "learning_rate": 3.222971243280143e-05,
      "loss": 0.0019,
      "step": 41650
    },
    {
      "epoch": 3.5549108285689908,
      "grad_norm": 0.26211997866630554,
      "learning_rate": 3.222544585715505e-05,
      "loss": 0.0018,
      "step": 41660
    },
    {
      "epoch": 3.555764143698268,
      "grad_norm": 0.13550062477588654,
      "learning_rate": 3.222117928150866e-05,
      "loss": 0.0022,
      "step": 41670
    },
    {
      "epoch": 3.556617458827545,
      "grad_norm": 0.13870885968208313,
      "learning_rate": 3.221691270586228e-05,
      "loss": 0.0019,
      "step": 41680
    },
    {
      "epoch": 3.557470773956822,
      "grad_norm": 0.040636468678712845,
      "learning_rate": 3.221264613021589e-05,
      "loss": 0.0016,
      "step": 41690
    },
    {
      "epoch": 3.5583240890860997,
      "grad_norm": 0.22720909118652344,
      "learning_rate": 3.2208379554569503e-05,
      "loss": 0.0018,
      "step": 41700
    },
    {
      "epoch": 3.5591774042153768,
      "grad_norm": 0.11863889545202255,
      "learning_rate": 3.220411297892312e-05,
      "loss": 0.0021,
      "step": 41710
    },
    {
      "epoch": 3.560030719344654,
      "grad_norm": 0.27019959688186646,
      "learning_rate": 3.219984640327673e-05,
      "loss": 0.0017,
      "step": 41720
    },
    {
      "epoch": 3.560884034473931,
      "grad_norm": 0.04755684360861778,
      "learning_rate": 3.2195579827630346e-05,
      "loss": 0.0019,
      "step": 41730
    },
    {
      "epoch": 3.5617373496032085,
      "grad_norm": 0.09632641077041626,
      "learning_rate": 3.2191313251983954e-05,
      "loss": 0.0019,
      "step": 41740
    },
    {
      "epoch": 3.5625906647324856,
      "grad_norm": 0.17714551091194153,
      "learning_rate": 3.2187046676337575e-05,
      "loss": 0.0021,
      "step": 41750
    },
    {
      "epoch": 3.5634439798617628,
      "grad_norm": 0.26031631231307983,
      "learning_rate": 3.218278010069118e-05,
      "loss": 0.0022,
      "step": 41760
    },
    {
      "epoch": 3.5642972949910403,
      "grad_norm": 0.2792934477329254,
      "learning_rate": 3.21785135250448e-05,
      "loss": 0.0018,
      "step": 41770
    },
    {
      "epoch": 3.5651506101203174,
      "grad_norm": 0.14926651120185852,
      "learning_rate": 3.217424694939841e-05,
      "loss": 0.0022,
      "step": 41780
    },
    {
      "epoch": 3.5660039252495945,
      "grad_norm": 0.3115418553352356,
      "learning_rate": 3.216998037375203e-05,
      "loss": 0.0021,
      "step": 41790
    },
    {
      "epoch": 3.566857240378872,
      "grad_norm": 0.1668815165758133,
      "learning_rate": 3.216571379810564e-05,
      "loss": 0.002,
      "step": 41800
    },
    {
      "epoch": 3.567710555508149,
      "grad_norm": 0.09009085595607758,
      "learning_rate": 3.216144722245925e-05,
      "loss": 0.0018,
      "step": 41810
    },
    {
      "epoch": 3.5685638706374263,
      "grad_norm": 0.07793686538934708,
      "learning_rate": 3.215718064681287e-05,
      "loss": 0.002,
      "step": 41820
    },
    {
      "epoch": 3.569417185766704,
      "grad_norm": 0.16468656063079834,
      "learning_rate": 3.215291407116648e-05,
      "loss": 0.0027,
      "step": 41830
    },
    {
      "epoch": 3.570270500895981,
      "grad_norm": 0.2588146924972534,
      "learning_rate": 3.2148647495520096e-05,
      "loss": 0.0019,
      "step": 41840
    },
    {
      "epoch": 3.571123816025258,
      "grad_norm": 0.38613465428352356,
      "learning_rate": 3.214438091987371e-05,
      "loss": 0.002,
      "step": 41850
    },
    {
      "epoch": 3.5719771311545356,
      "grad_norm": 0.0929206907749176,
      "learning_rate": 3.2140114344227324e-05,
      "loss": 0.0022,
      "step": 41860
    },
    {
      "epoch": 3.5728304462838127,
      "grad_norm": 0.30410271883010864,
      "learning_rate": 3.213584776858094e-05,
      "loss": 0.002,
      "step": 41870
    },
    {
      "epoch": 3.57368376141309,
      "grad_norm": 0.28055521845817566,
      "learning_rate": 3.213158119293455e-05,
      "loss": 0.0017,
      "step": 41880
    },
    {
      "epoch": 3.574537076542367,
      "grad_norm": 0.16908739507198334,
      "learning_rate": 3.212731461728817e-05,
      "loss": 0.002,
      "step": 41890
    },
    {
      "epoch": 3.575390391671644,
      "grad_norm": 0.08252976089715958,
      "learning_rate": 3.212304804164178e-05,
      "loss": 0.0017,
      "step": 41900
    },
    {
      "epoch": 3.5762437068009216,
      "grad_norm": 0.1657980978488922,
      "learning_rate": 3.2118781465995396e-05,
      "loss": 0.0019,
      "step": 41910
    },
    {
      "epoch": 3.5770970219301987,
      "grad_norm": 0.04332400858402252,
      "learning_rate": 3.211451489034901e-05,
      "loss": 0.0022,
      "step": 41920
    },
    {
      "epoch": 3.577950337059476,
      "grad_norm": 0.36691170930862427,
      "learning_rate": 3.2110248314702624e-05,
      "loss": 0.0017,
      "step": 41930
    },
    {
      "epoch": 3.5788036521887534,
      "grad_norm": 0.24196231365203857,
      "learning_rate": 3.210598173905623e-05,
      "loss": 0.0022,
      "step": 41940
    },
    {
      "epoch": 3.5796569673180305,
      "grad_norm": 0.041357848793268204,
      "learning_rate": 3.210171516340985e-05,
      "loss": 0.0016,
      "step": 41950
    },
    {
      "epoch": 3.5805102824473076,
      "grad_norm": 0.24789348244667053,
      "learning_rate": 3.209744858776346e-05,
      "loss": 0.0016,
      "step": 41960
    },
    {
      "epoch": 3.581363597576585,
      "grad_norm": 0.1332567185163498,
      "learning_rate": 3.209318201211708e-05,
      "loss": 0.0015,
      "step": 41970
    },
    {
      "epoch": 3.5822169127058623,
      "grad_norm": 0.24681121110916138,
      "learning_rate": 3.208891543647069e-05,
      "loss": 0.002,
      "step": 41980
    },
    {
      "epoch": 3.5830702278351394,
      "grad_norm": 0.3731642961502075,
      "learning_rate": 3.20846488608243e-05,
      "loss": 0.0017,
      "step": 41990
    },
    {
      "epoch": 3.583923542964417,
      "grad_norm": 0.5245181322097778,
      "learning_rate": 3.208038228517792e-05,
      "loss": 0.0021,
      "step": 42000
    },
    {
      "epoch": 3.584776858093694,
      "grad_norm": 0.1696159839630127,
      "learning_rate": 3.207611570953153e-05,
      "loss": 0.0025,
      "step": 42010
    },
    {
      "epoch": 3.585630173222971,
      "grad_norm": 0.33281174302101135,
      "learning_rate": 3.2071849133885146e-05,
      "loss": 0.0029,
      "step": 42020
    },
    {
      "epoch": 3.5864834883522487,
      "grad_norm": 0.2074836641550064,
      "learning_rate": 3.206758255823876e-05,
      "loss": 0.0022,
      "step": 42030
    },
    {
      "epoch": 3.587336803481526,
      "grad_norm": 0.06528069078922272,
      "learning_rate": 3.2063315982592374e-05,
      "loss": 0.002,
      "step": 42040
    },
    {
      "epoch": 3.588190118610803,
      "grad_norm": 0.3939347565174103,
      "learning_rate": 3.205904940694598e-05,
      "loss": 0.0023,
      "step": 42050
    },
    {
      "epoch": 3.58904343374008,
      "grad_norm": 0.04088999703526497,
      "learning_rate": 3.20547828312996e-05,
      "loss": 0.0019,
      "step": 42060
    },
    {
      "epoch": 3.5898967488693576,
      "grad_norm": 0.025709906592965126,
      "learning_rate": 3.205051625565321e-05,
      "loss": 0.0015,
      "step": 42070
    },
    {
      "epoch": 3.5907500639986347,
      "grad_norm": 0.17053072154521942,
      "learning_rate": 3.204624968000683e-05,
      "loss": 0.0016,
      "step": 42080
    },
    {
      "epoch": 3.591603379127912,
      "grad_norm": 0.1354692131280899,
      "learning_rate": 3.204198310436044e-05,
      "loss": 0.0023,
      "step": 42090
    },
    {
      "epoch": 3.592456694257189,
      "grad_norm": 0.4500792324542999,
      "learning_rate": 3.203771652871406e-05,
      "loss": 0.0018,
      "step": 42100
    },
    {
      "epoch": 3.5933100093864665,
      "grad_norm": 0.19035795331001282,
      "learning_rate": 3.203344995306767e-05,
      "loss": 0.0022,
      "step": 42110
    },
    {
      "epoch": 3.5941633245157436,
      "grad_norm": 0.10832633078098297,
      "learning_rate": 3.202918337742129e-05,
      "loss": 0.0018,
      "step": 42120
    },
    {
      "epoch": 3.5950166396450207,
      "grad_norm": 0.31744229793548584,
      "learning_rate": 3.2024916801774895e-05,
      "loss": 0.0025,
      "step": 42130
    },
    {
      "epoch": 3.5958699547742983,
      "grad_norm": 0.03609585016965866,
      "learning_rate": 3.202065022612851e-05,
      "loss": 0.0021,
      "step": 42140
    },
    {
      "epoch": 3.5967232699035754,
      "grad_norm": 0.21104533970355988,
      "learning_rate": 3.2016383650482124e-05,
      "loss": 0.0021,
      "step": 42150
    },
    {
      "epoch": 3.5975765850328525,
      "grad_norm": 0.42343366146087646,
      "learning_rate": 3.201211707483574e-05,
      "loss": 0.0016,
      "step": 42160
    },
    {
      "epoch": 3.59842990016213,
      "grad_norm": 0.2812422811985016,
      "learning_rate": 3.200785049918935e-05,
      "loss": 0.0022,
      "step": 42170
    },
    {
      "epoch": 3.599283215291407,
      "grad_norm": 0.18560902774333954,
      "learning_rate": 3.200358392354297e-05,
      "loss": 0.0027,
      "step": 42180
    },
    {
      "epoch": 3.6001365304206843,
      "grad_norm": 0.18910712003707886,
      "learning_rate": 3.199931734789658e-05,
      "loss": 0.0017,
      "step": 42190
    },
    {
      "epoch": 3.600989845549962,
      "grad_norm": 0.24104905128479004,
      "learning_rate": 3.1995050772250195e-05,
      "loss": 0.0021,
      "step": 42200
    },
    {
      "epoch": 3.601843160679239,
      "grad_norm": 0.3539316654205322,
      "learning_rate": 3.199078419660381e-05,
      "loss": 0.0025,
      "step": 42210
    },
    {
      "epoch": 3.602696475808516,
      "grad_norm": 0.20716629922389984,
      "learning_rate": 3.1986517620957424e-05,
      "loss": 0.002,
      "step": 42220
    },
    {
      "epoch": 3.6035497909377936,
      "grad_norm": 0.07496262341737747,
      "learning_rate": 3.198225104531104e-05,
      "loss": 0.0016,
      "step": 42230
    },
    {
      "epoch": 3.6044031060670707,
      "grad_norm": 0.21290042996406555,
      "learning_rate": 3.197798446966465e-05,
      "loss": 0.0018,
      "step": 42240
    },
    {
      "epoch": 3.605256421196348,
      "grad_norm": 0.2247508317232132,
      "learning_rate": 3.197371789401826e-05,
      "loss": 0.0023,
      "step": 42250
    },
    {
      "epoch": 3.606109736325625,
      "grad_norm": 0.09771061688661575,
      "learning_rate": 3.1969451318371874e-05,
      "loss": 0.0017,
      "step": 42260
    },
    {
      "epoch": 3.606963051454902,
      "grad_norm": 0.3223760426044464,
      "learning_rate": 3.196518474272549e-05,
      "loss": 0.0019,
      "step": 42270
    },
    {
      "epoch": 3.6078163665841796,
      "grad_norm": 0.20229171216487885,
      "learning_rate": 3.19609181670791e-05,
      "loss": 0.002,
      "step": 42280
    },
    {
      "epoch": 3.6086696817134567,
      "grad_norm": 0.422873318195343,
      "learning_rate": 3.1956651591432717e-05,
      "loss": 0.0025,
      "step": 42290
    },
    {
      "epoch": 3.609522996842734,
      "grad_norm": 0.05363139882683754,
      "learning_rate": 3.195238501578633e-05,
      "loss": 0.0022,
      "step": 42300
    },
    {
      "epoch": 3.6103763119720114,
      "grad_norm": 0.05181271955370903,
      "learning_rate": 3.1948118440139945e-05,
      "loss": 0.0023,
      "step": 42310
    },
    {
      "epoch": 3.6112296271012885,
      "grad_norm": 0.5773435235023499,
      "learning_rate": 3.194385186449356e-05,
      "loss": 0.0016,
      "step": 42320
    },
    {
      "epoch": 3.6120829422305656,
      "grad_norm": 0.10372302681207657,
      "learning_rate": 3.1939585288847173e-05,
      "loss": 0.0019,
      "step": 42330
    },
    {
      "epoch": 3.612936257359843,
      "grad_norm": 0.053356803953647614,
      "learning_rate": 3.193531871320079e-05,
      "loss": 0.002,
      "step": 42340
    },
    {
      "epoch": 3.6137895724891202,
      "grad_norm": 0.1524335891008377,
      "learning_rate": 3.19310521375544e-05,
      "loss": 0.0017,
      "step": 42350
    },
    {
      "epoch": 3.6146428876183974,
      "grad_norm": 0.17103402316570282,
      "learning_rate": 3.192678556190801e-05,
      "loss": 0.0019,
      "step": 42360
    },
    {
      "epoch": 3.615496202747675,
      "grad_norm": 0.2990615963935852,
      "learning_rate": 3.192251898626163e-05,
      "loss": 0.0024,
      "step": 42370
    },
    {
      "epoch": 3.616349517876952,
      "grad_norm": 0.15187227725982666,
      "learning_rate": 3.191825241061524e-05,
      "loss": 0.0022,
      "step": 42380
    },
    {
      "epoch": 3.617202833006229,
      "grad_norm": 0.43236100673675537,
      "learning_rate": 3.191398583496886e-05,
      "loss": 0.0019,
      "step": 42390
    },
    {
      "epoch": 3.6180561481355067,
      "grad_norm": 0.054304275661706924,
      "learning_rate": 3.1909719259322466e-05,
      "loss": 0.0018,
      "step": 42400
    },
    {
      "epoch": 3.618909463264784,
      "grad_norm": 0.2812884449958801,
      "learning_rate": 3.190545268367609e-05,
      "loss": 0.0021,
      "step": 42410
    },
    {
      "epoch": 3.619762778394061,
      "grad_norm": 0.17621739208698273,
      "learning_rate": 3.1901186108029695e-05,
      "loss": 0.0027,
      "step": 42420
    },
    {
      "epoch": 3.620616093523338,
      "grad_norm": 0.030498458072543144,
      "learning_rate": 3.1896919532383316e-05,
      "loss": 0.0024,
      "step": 42430
    },
    {
      "epoch": 3.6214694086526156,
      "grad_norm": 0.1536155343055725,
      "learning_rate": 3.189265295673692e-05,
      "loss": 0.0019,
      "step": 42440
    },
    {
      "epoch": 3.6223227237818927,
      "grad_norm": 0.17154903709888458,
      "learning_rate": 3.188838638109054e-05,
      "loss": 0.0021,
      "step": 42450
    },
    {
      "epoch": 3.62317603891117,
      "grad_norm": 0.1341816484928131,
      "learning_rate": 3.188411980544415e-05,
      "loss": 0.0022,
      "step": 42460
    },
    {
      "epoch": 3.624029354040447,
      "grad_norm": 0.2031194120645523,
      "learning_rate": 3.1879853229797766e-05,
      "loss": 0.0019,
      "step": 42470
    },
    {
      "epoch": 3.6248826691697245,
      "grad_norm": 0.13018420338630676,
      "learning_rate": 3.187558665415138e-05,
      "loss": 0.0022,
      "step": 42480
    },
    {
      "epoch": 3.6257359842990016,
      "grad_norm": 0.46392133831977844,
      "learning_rate": 3.1871320078504995e-05,
      "loss": 0.0023,
      "step": 42490
    },
    {
      "epoch": 3.6265892994282787,
      "grad_norm": 0.07904832810163498,
      "learning_rate": 3.186705350285861e-05,
      "loss": 0.0024,
      "step": 42500
    },
    {
      "epoch": 3.6274426145575562,
      "grad_norm": 0.28243929147720337,
      "learning_rate": 3.186278692721222e-05,
      "loss": 0.0017,
      "step": 42510
    },
    {
      "epoch": 3.6282959296868333,
      "grad_norm": 0.10402727872133255,
      "learning_rate": 3.185852035156584e-05,
      "loss": 0.002,
      "step": 42520
    },
    {
      "epoch": 3.6291492448161105,
      "grad_norm": 0.39084017276763916,
      "learning_rate": 3.1854253775919445e-05,
      "loss": 0.0022,
      "step": 42530
    },
    {
      "epoch": 3.630002559945388,
      "grad_norm": 0.07029329985380173,
      "learning_rate": 3.1849987200273066e-05,
      "loss": 0.0018,
      "step": 42540
    },
    {
      "epoch": 3.630855875074665,
      "grad_norm": 0.1325683295726776,
      "learning_rate": 3.184572062462667e-05,
      "loss": 0.0027,
      "step": 42550
    },
    {
      "epoch": 3.6317091902039422,
      "grad_norm": 0.1758139431476593,
      "learning_rate": 3.184145404898029e-05,
      "loss": 0.0018,
      "step": 42560
    },
    {
      "epoch": 3.63256250533322,
      "grad_norm": 0.29869070649147034,
      "learning_rate": 3.18371874733339e-05,
      "loss": 0.0021,
      "step": 42570
    },
    {
      "epoch": 3.633415820462497,
      "grad_norm": 0.39525994658470154,
      "learning_rate": 3.1832920897687516e-05,
      "loss": 0.0024,
      "step": 42580
    },
    {
      "epoch": 3.634269135591774,
      "grad_norm": 0.15261641144752502,
      "learning_rate": 3.182865432204113e-05,
      "loss": 0.002,
      "step": 42590
    },
    {
      "epoch": 3.6351224507210516,
      "grad_norm": 0.2062729448080063,
      "learning_rate": 3.1824387746394744e-05,
      "loss": 0.0022,
      "step": 42600
    },
    {
      "epoch": 3.6359757658503287,
      "grad_norm": 0.22721637785434723,
      "learning_rate": 3.182012117074836e-05,
      "loss": 0.0026,
      "step": 42610
    },
    {
      "epoch": 3.6368290809796058,
      "grad_norm": 0.10030542314052582,
      "learning_rate": 3.181585459510197e-05,
      "loss": 0.0029,
      "step": 42620
    },
    {
      "epoch": 3.637682396108883,
      "grad_norm": 0.08295007795095444,
      "learning_rate": 3.181158801945559e-05,
      "loss": 0.0019,
      "step": 42630
    },
    {
      "epoch": 3.63853571123816,
      "grad_norm": 0.02607419528067112,
      "learning_rate": 3.18073214438092e-05,
      "loss": 0.0018,
      "step": 42640
    },
    {
      "epoch": 3.6393890263674376,
      "grad_norm": 0.4565095901489258,
      "learning_rate": 3.1803054868162816e-05,
      "loss": 0.0024,
      "step": 42650
    },
    {
      "epoch": 3.6402423414967147,
      "grad_norm": 0.33442121744155884,
      "learning_rate": 3.179878829251643e-05,
      "loss": 0.0021,
      "step": 42660
    },
    {
      "epoch": 3.6410956566259918,
      "grad_norm": 0.2446317821741104,
      "learning_rate": 3.179452171687004e-05,
      "loss": 0.0028,
      "step": 42670
    },
    {
      "epoch": 3.6419489717552693,
      "grad_norm": 0.03236772119998932,
      "learning_rate": 3.179025514122366e-05,
      "loss": 0.0026,
      "step": 42680
    },
    {
      "epoch": 3.6428022868845464,
      "grad_norm": 0.048028502613306046,
      "learning_rate": 3.1785988565577266e-05,
      "loss": 0.0019,
      "step": 42690
    },
    {
      "epoch": 3.6436556020138235,
      "grad_norm": 0.033466994762420654,
      "learning_rate": 3.178172198993089e-05,
      "loss": 0.0016,
      "step": 42700
    },
    {
      "epoch": 3.644508917143101,
      "grad_norm": 0.031250279396772385,
      "learning_rate": 3.1777455414284494e-05,
      "loss": 0.0022,
      "step": 42710
    },
    {
      "epoch": 3.645362232272378,
      "grad_norm": 0.15332511067390442,
      "learning_rate": 3.1773188838638115e-05,
      "loss": 0.0024,
      "step": 42720
    },
    {
      "epoch": 3.6462155474016553,
      "grad_norm": 0.2019636482000351,
      "learning_rate": 3.176892226299172e-05,
      "loss": 0.002,
      "step": 42730
    },
    {
      "epoch": 3.647068862530933,
      "grad_norm": 0.17008529603481293,
      "learning_rate": 3.1764655687345344e-05,
      "loss": 0.0022,
      "step": 42740
    },
    {
      "epoch": 3.64792217766021,
      "grad_norm": 0.09516475349664688,
      "learning_rate": 3.176038911169895e-05,
      "loss": 0.0018,
      "step": 42750
    },
    {
      "epoch": 3.648775492789487,
      "grad_norm": 0.09306944906711578,
      "learning_rate": 3.1756122536052566e-05,
      "loss": 0.0022,
      "step": 42760
    },
    {
      "epoch": 3.6496288079187647,
      "grad_norm": 0.1858479231595993,
      "learning_rate": 3.175185596040618e-05,
      "loss": 0.0018,
      "step": 42770
    },
    {
      "epoch": 3.6504821230480418,
      "grad_norm": 0.20384728908538818,
      "learning_rate": 3.1747589384759794e-05,
      "loss": 0.0017,
      "step": 42780
    },
    {
      "epoch": 3.651335438177319,
      "grad_norm": 0.2609539031982422,
      "learning_rate": 3.174332280911341e-05,
      "loss": 0.0018,
      "step": 42790
    },
    {
      "epoch": 3.652188753306596,
      "grad_norm": 0.5875823497772217,
      "learning_rate": 3.1739056233467016e-05,
      "loss": 0.0013,
      "step": 42800
    },
    {
      "epoch": 3.653042068435873,
      "grad_norm": 0.11064010113477707,
      "learning_rate": 3.173478965782064e-05,
      "loss": 0.0021,
      "step": 42810
    },
    {
      "epoch": 3.6538953835651506,
      "grad_norm": 0.2989746928215027,
      "learning_rate": 3.1730523082174244e-05,
      "loss": 0.0018,
      "step": 42820
    },
    {
      "epoch": 3.6547486986944278,
      "grad_norm": 0.1336696892976761,
      "learning_rate": 3.1726256506527865e-05,
      "loss": 0.0013,
      "step": 42830
    },
    {
      "epoch": 3.655602013823705,
      "grad_norm": 0.2609032094478607,
      "learning_rate": 3.172198993088147e-05,
      "loss": 0.0023,
      "step": 42840
    },
    {
      "epoch": 3.6564553289529824,
      "grad_norm": 0.28697875142097473,
      "learning_rate": 3.1717723355235094e-05,
      "loss": 0.0022,
      "step": 42850
    },
    {
      "epoch": 3.6573086440822595,
      "grad_norm": 0.055261045694351196,
      "learning_rate": 3.17134567795887e-05,
      "loss": 0.0019,
      "step": 42860
    },
    {
      "epoch": 3.6581619592115366,
      "grad_norm": 0.3903210461139679,
      "learning_rate": 3.1709190203942315e-05,
      "loss": 0.0017,
      "step": 42870
    },
    {
      "epoch": 3.659015274340814,
      "grad_norm": 0.023612776771187782,
      "learning_rate": 3.170492362829593e-05,
      "loss": 0.0025,
      "step": 42880
    },
    {
      "epoch": 3.6598685894700913,
      "grad_norm": 0.3715406060218811,
      "learning_rate": 3.1700657052649544e-05,
      "loss": 0.0024,
      "step": 42890
    },
    {
      "epoch": 3.6607219045993684,
      "grad_norm": 0.03249321132898331,
      "learning_rate": 3.169639047700316e-05,
      "loss": 0.0022,
      "step": 42900
    },
    {
      "epoch": 3.661575219728646,
      "grad_norm": 0.06410366296768188,
      "learning_rate": 3.169212390135677e-05,
      "loss": 0.0013,
      "step": 42910
    },
    {
      "epoch": 3.662428534857923,
      "grad_norm": 0.10875953733921051,
      "learning_rate": 3.1687857325710387e-05,
      "loss": 0.0016,
      "step": 42920
    },
    {
      "epoch": 3.6632818499872,
      "grad_norm": 0.2616041600704193,
      "learning_rate": 3.1683590750064e-05,
      "loss": 0.0018,
      "step": 42930
    },
    {
      "epoch": 3.6641351651164777,
      "grad_norm": 0.05948314443230629,
      "learning_rate": 3.1679324174417615e-05,
      "loss": 0.0015,
      "step": 42940
    },
    {
      "epoch": 3.664988480245755,
      "grad_norm": 0.3138602674007416,
      "learning_rate": 3.167505759877123e-05,
      "loss": 0.002,
      "step": 42950
    },
    {
      "epoch": 3.665841795375032,
      "grad_norm": 0.2756935954093933,
      "learning_rate": 3.1670791023124844e-05,
      "loss": 0.0019,
      "step": 42960
    },
    {
      "epoch": 3.6666951105043095,
      "grad_norm": 0.148626908659935,
      "learning_rate": 3.166652444747846e-05,
      "loss": 0.002,
      "step": 42970
    },
    {
      "epoch": 3.6675484256335866,
      "grad_norm": 0.28158414363861084,
      "learning_rate": 3.1662257871832065e-05,
      "loss": 0.0024,
      "step": 42980
    },
    {
      "epoch": 3.6684017407628637,
      "grad_norm": 0.18653662502765656,
      "learning_rate": 3.1657991296185686e-05,
      "loss": 0.002,
      "step": 42990
    },
    {
      "epoch": 3.669255055892141,
      "grad_norm": 0.258459210395813,
      "learning_rate": 3.1653724720539294e-05,
      "loss": 0.0016,
      "step": 43000
    },
    {
      "epoch": 3.670108371021418,
      "grad_norm": 0.44390538334846497,
      "learning_rate": 3.1649458144892915e-05,
      "loss": 0.0013,
      "step": 43010
    },
    {
      "epoch": 3.6709616861506955,
      "grad_norm": 0.27662572264671326,
      "learning_rate": 3.164519156924652e-05,
      "loss": 0.0017,
      "step": 43020
    },
    {
      "epoch": 3.6718150012799726,
      "grad_norm": 0.2694321274757385,
      "learning_rate": 3.164092499360014e-05,
      "loss": 0.0022,
      "step": 43030
    },
    {
      "epoch": 3.6726683164092497,
      "grad_norm": 0.2295578569173813,
      "learning_rate": 3.163665841795375e-05,
      "loss": 0.0015,
      "step": 43040
    },
    {
      "epoch": 3.6735216315385273,
      "grad_norm": 0.1554276943206787,
      "learning_rate": 3.1632391842307365e-05,
      "loss": 0.0022,
      "step": 43050
    },
    {
      "epoch": 3.6743749466678044,
      "grad_norm": 0.068418949842453,
      "learning_rate": 3.162812526666098e-05,
      "loss": 0.0024,
      "step": 43060
    },
    {
      "epoch": 3.6752282617970815,
      "grad_norm": 0.33821365237236023,
      "learning_rate": 3.1623858691014593e-05,
      "loss": 0.0017,
      "step": 43070
    },
    {
      "epoch": 3.676081576926359,
      "grad_norm": 0.116782046854496,
      "learning_rate": 3.161959211536821e-05,
      "loss": 0.002,
      "step": 43080
    },
    {
      "epoch": 3.676934892055636,
      "grad_norm": 0.06620150804519653,
      "learning_rate": 3.1615325539721815e-05,
      "loss": 0.0017,
      "step": 43090
    },
    {
      "epoch": 3.6777882071849133,
      "grad_norm": 0.14909376204013824,
      "learning_rate": 3.1611058964075436e-05,
      "loss": 0.0021,
      "step": 43100
    },
    {
      "epoch": 3.678641522314191,
      "grad_norm": 0.1450088769197464,
      "learning_rate": 3.1606792388429044e-05,
      "loss": 0.0016,
      "step": 43110
    },
    {
      "epoch": 3.679494837443468,
      "grad_norm": 0.059558331966400146,
      "learning_rate": 3.1602525812782665e-05,
      "loss": 0.002,
      "step": 43120
    },
    {
      "epoch": 3.680348152572745,
      "grad_norm": 0.30123332142829895,
      "learning_rate": 3.159825923713627e-05,
      "loss": 0.0022,
      "step": 43130
    },
    {
      "epoch": 3.6812014677020226,
      "grad_norm": 0.1569157838821411,
      "learning_rate": 3.159399266148989e-05,
      "loss": 0.0017,
      "step": 43140
    },
    {
      "epoch": 3.6820547828312997,
      "grad_norm": 0.4271976053714752,
      "learning_rate": 3.15897260858435e-05,
      "loss": 0.0021,
      "step": 43150
    },
    {
      "epoch": 3.682908097960577,
      "grad_norm": 0.21257725358009338,
      "learning_rate": 3.158545951019712e-05,
      "loss": 0.0019,
      "step": 43160
    },
    {
      "epoch": 3.683761413089854,
      "grad_norm": 0.13521602749824524,
      "learning_rate": 3.158119293455073e-05,
      "loss": 0.0019,
      "step": 43170
    },
    {
      "epoch": 3.684614728219131,
      "grad_norm": 0.24098917841911316,
      "learning_rate": 3.157692635890434e-05,
      "loss": 0.0022,
      "step": 43180
    },
    {
      "epoch": 3.6854680433484086,
      "grad_norm": 0.14775727689266205,
      "learning_rate": 3.157265978325796e-05,
      "loss": 0.0018,
      "step": 43190
    },
    {
      "epoch": 3.6863213584776857,
      "grad_norm": 0.31626376509666443,
      "learning_rate": 3.156839320761157e-05,
      "loss": 0.0017,
      "step": 43200
    },
    {
      "epoch": 3.687174673606963,
      "grad_norm": 0.3897811472415924,
      "learning_rate": 3.1564126631965186e-05,
      "loss": 0.0017,
      "step": 43210
    },
    {
      "epoch": 3.6880279887362404,
      "grad_norm": 0.07917364686727524,
      "learning_rate": 3.15598600563188e-05,
      "loss": 0.0018,
      "step": 43220
    },
    {
      "epoch": 3.6888813038655175,
      "grad_norm": 0.44049668312072754,
      "learning_rate": 3.1555593480672415e-05,
      "loss": 0.0016,
      "step": 43230
    },
    {
      "epoch": 3.6897346189947946,
      "grad_norm": 0.09563012421131134,
      "learning_rate": 3.155132690502603e-05,
      "loss": 0.0015,
      "step": 43240
    },
    {
      "epoch": 3.690587934124072,
      "grad_norm": 0.24020935595035553,
      "learning_rate": 3.154706032937964e-05,
      "loss": 0.0021,
      "step": 43250
    },
    {
      "epoch": 3.6914412492533493,
      "grad_norm": 0.28779032826423645,
      "learning_rate": 3.154279375373326e-05,
      "loss": 0.0022,
      "step": 43260
    },
    {
      "epoch": 3.6922945643826264,
      "grad_norm": 0.1511775553226471,
      "learning_rate": 3.153852717808687e-05,
      "loss": 0.0017,
      "step": 43270
    },
    {
      "epoch": 3.693147879511904,
      "grad_norm": 0.17476265132427216,
      "learning_rate": 3.1534260602440486e-05,
      "loss": 0.0019,
      "step": 43280
    },
    {
      "epoch": 3.694001194641181,
      "grad_norm": 0.2948105037212372,
      "learning_rate": 3.152999402679409e-05,
      "loss": 0.0023,
      "step": 43290
    },
    {
      "epoch": 3.694854509770458,
      "grad_norm": 0.0575331412255764,
      "learning_rate": 3.1525727451147714e-05,
      "loss": 0.0018,
      "step": 43300
    },
    {
      "epoch": 3.6957078248997357,
      "grad_norm": 0.025141645222902298,
      "learning_rate": 3.152146087550132e-05,
      "loss": 0.0018,
      "step": 43310
    },
    {
      "epoch": 3.696561140029013,
      "grad_norm": 0.2047637701034546,
      "learning_rate": 3.1517194299854936e-05,
      "loss": 0.0019,
      "step": 43320
    },
    {
      "epoch": 3.69741445515829,
      "grad_norm": 0.11367232352495193,
      "learning_rate": 3.151292772420855e-05,
      "loss": 0.0018,
      "step": 43330
    },
    {
      "epoch": 3.698267770287567,
      "grad_norm": 0.2241952121257782,
      "learning_rate": 3.1508661148562164e-05,
      "loss": 0.0017,
      "step": 43340
    },
    {
      "epoch": 3.6991210854168446,
      "grad_norm": 0.3196544051170349,
      "learning_rate": 3.150439457291578e-05,
      "loss": 0.002,
      "step": 43350
    },
    {
      "epoch": 3.6999744005461217,
      "grad_norm": 0.17092396318912506,
      "learning_rate": 3.150012799726939e-05,
      "loss": 0.0016,
      "step": 43360
    },
    {
      "epoch": 3.700827715675399,
      "grad_norm": 0.10210923850536346,
      "learning_rate": 3.149586142162301e-05,
      "loss": 0.0024,
      "step": 43370
    },
    {
      "epoch": 3.701681030804676,
      "grad_norm": 0.26586398482322693,
      "learning_rate": 3.149159484597662e-05,
      "loss": 0.0018,
      "step": 43380
    },
    {
      "epoch": 3.7025343459339535,
      "grad_norm": 0.2276875078678131,
      "learning_rate": 3.1487328270330236e-05,
      "loss": 0.0017,
      "step": 43390
    },
    {
      "epoch": 3.7033876610632306,
      "grad_norm": 0.09688368439674377,
      "learning_rate": 3.148306169468384e-05,
      "loss": 0.0023,
      "step": 43400
    },
    {
      "epoch": 3.7042409761925077,
      "grad_norm": 0.1137532889842987,
      "learning_rate": 3.1478795119037464e-05,
      "loss": 0.0019,
      "step": 43410
    },
    {
      "epoch": 3.7050942913217852,
      "grad_norm": 0.13808682560920715,
      "learning_rate": 3.147452854339107e-05,
      "loss": 0.0017,
      "step": 43420
    },
    {
      "epoch": 3.7059476064510624,
      "grad_norm": 0.07845577597618103,
      "learning_rate": 3.147026196774469e-05,
      "loss": 0.0023,
      "step": 43430
    },
    {
      "epoch": 3.7068009215803395,
      "grad_norm": 0.1333482265472412,
      "learning_rate": 3.14659953920983e-05,
      "loss": 0.0018,
      "step": 43440
    },
    {
      "epoch": 3.707654236709617,
      "grad_norm": 0.09628499299287796,
      "learning_rate": 3.146172881645192e-05,
      "loss": 0.0019,
      "step": 43450
    },
    {
      "epoch": 3.708507551838894,
      "grad_norm": 0.34421104192733765,
      "learning_rate": 3.145746224080553e-05,
      "loss": 0.0023,
      "step": 43460
    },
    {
      "epoch": 3.7093608669681712,
      "grad_norm": 0.15213683247566223,
      "learning_rate": 3.145319566515915e-05,
      "loss": 0.0018,
      "step": 43470
    },
    {
      "epoch": 3.710214182097449,
      "grad_norm": 0.033512942492961884,
      "learning_rate": 3.144892908951276e-05,
      "loss": 0.0021,
      "step": 43480
    },
    {
      "epoch": 3.711067497226726,
      "grad_norm": 0.192364901304245,
      "learning_rate": 3.144466251386637e-05,
      "loss": 0.0018,
      "step": 43490
    },
    {
      "epoch": 3.711920812356003,
      "grad_norm": 0.3558637201786041,
      "learning_rate": 3.1440395938219985e-05,
      "loss": 0.0017,
      "step": 43500
    },
    {
      "epoch": 3.7127741274852806,
      "grad_norm": 0.03838345408439636,
      "learning_rate": 3.14361293625736e-05,
      "loss": 0.0018,
      "step": 43510
    },
    {
      "epoch": 3.7136274426145577,
      "grad_norm": 0.11267949640750885,
      "learning_rate": 3.1431862786927214e-05,
      "loss": 0.0021,
      "step": 43520
    },
    {
      "epoch": 3.714480757743835,
      "grad_norm": 0.05204862356185913,
      "learning_rate": 3.142759621128083e-05,
      "loss": 0.002,
      "step": 43530
    },
    {
      "epoch": 3.715334072873112,
      "grad_norm": 0.03840724006295204,
      "learning_rate": 3.142332963563444e-05,
      "loss": 0.0019,
      "step": 43540
    },
    {
      "epoch": 3.716187388002389,
      "grad_norm": 0.18758775293827057,
      "learning_rate": 3.141906305998806e-05,
      "loss": 0.0022,
      "step": 43550
    },
    {
      "epoch": 3.7170407031316666,
      "grad_norm": 0.18589328229427338,
      "learning_rate": 3.141479648434167e-05,
      "loss": 0.0022,
      "step": 43560
    },
    {
      "epoch": 3.7178940182609437,
      "grad_norm": 0.14486853778362274,
      "learning_rate": 3.1410529908695285e-05,
      "loss": 0.0024,
      "step": 43570
    },
    {
      "epoch": 3.718747333390221,
      "grad_norm": 0.20912469923496246,
      "learning_rate": 3.14062633330489e-05,
      "loss": 0.0018,
      "step": 43580
    },
    {
      "epoch": 3.7196006485194983,
      "grad_norm": 0.11182384938001633,
      "learning_rate": 3.140199675740251e-05,
      "loss": 0.0018,
      "step": 43590
    },
    {
      "epoch": 3.7204539636487755,
      "grad_norm": 0.10232392698526382,
      "learning_rate": 3.139773018175612e-05,
      "loss": 0.0018,
      "step": 43600
    },
    {
      "epoch": 3.7213072787780526,
      "grad_norm": 0.2424170970916748,
      "learning_rate": 3.1393463606109735e-05,
      "loss": 0.0019,
      "step": 43610
    },
    {
      "epoch": 3.72216059390733,
      "grad_norm": 0.14812012016773224,
      "learning_rate": 3.138919703046335e-05,
      "loss": 0.0017,
      "step": 43620
    },
    {
      "epoch": 3.7230139090366072,
      "grad_norm": 0.13371820747852325,
      "learning_rate": 3.1384930454816964e-05,
      "loss": 0.0024,
      "step": 43630
    },
    {
      "epoch": 3.7238672241658843,
      "grad_norm": 0.24160872399806976,
      "learning_rate": 3.138066387917058e-05,
      "loss": 0.0022,
      "step": 43640
    },
    {
      "epoch": 3.724720539295162,
      "grad_norm": 0.055032264441251755,
      "learning_rate": 3.137639730352419e-05,
      "loss": 0.002,
      "step": 43650
    },
    {
      "epoch": 3.725573854424439,
      "grad_norm": 0.39962077140808105,
      "learning_rate": 3.1372130727877807e-05,
      "loss": 0.0022,
      "step": 43660
    },
    {
      "epoch": 3.726427169553716,
      "grad_norm": 0.18039584159851074,
      "learning_rate": 3.136786415223142e-05,
      "loss": 0.0022,
      "step": 43670
    },
    {
      "epoch": 3.7272804846829937,
      "grad_norm": 0.32201167941093445,
      "learning_rate": 3.1363597576585035e-05,
      "loss": 0.0021,
      "step": 43680
    },
    {
      "epoch": 3.7281337998122708,
      "grad_norm": 0.04002689570188522,
      "learning_rate": 3.135933100093865e-05,
      "loss": 0.0018,
      "step": 43690
    },
    {
      "epoch": 3.728987114941548,
      "grad_norm": 0.1705881506204605,
      "learning_rate": 3.1355064425292264e-05,
      "loss": 0.0022,
      "step": 43700
    },
    {
      "epoch": 3.729840430070825,
      "grad_norm": 0.1181512400507927,
      "learning_rate": 3.135079784964587e-05,
      "loss": 0.0019,
      "step": 43710
    },
    {
      "epoch": 3.7306937452001026,
      "grad_norm": 0.13054855167865753,
      "learning_rate": 3.134653127399949e-05,
      "loss": 0.0021,
      "step": 43720
    },
    {
      "epoch": 3.7315470603293797,
      "grad_norm": 0.12080215662717819,
      "learning_rate": 3.13422646983531e-05,
      "loss": 0.0018,
      "step": 43730
    },
    {
      "epoch": 3.7324003754586568,
      "grad_norm": 0.1675224006175995,
      "learning_rate": 3.133799812270672e-05,
      "loss": 0.0021,
      "step": 43740
    },
    {
      "epoch": 3.733253690587934,
      "grad_norm": 0.07692980021238327,
      "learning_rate": 3.133373154706033e-05,
      "loss": 0.0028,
      "step": 43750
    },
    {
      "epoch": 3.7341070057172114,
      "grad_norm": 0.2151774913072586,
      "learning_rate": 3.132946497141395e-05,
      "loss": 0.0021,
      "step": 43760
    },
    {
      "epoch": 3.7349603208464885,
      "grad_norm": 0.11970777064561844,
      "learning_rate": 3.1325198395767556e-05,
      "loss": 0.002,
      "step": 43770
    },
    {
      "epoch": 3.7358136359757657,
      "grad_norm": 0.3412052094936371,
      "learning_rate": 3.132093182012118e-05,
      "loss": 0.0019,
      "step": 43780
    },
    {
      "epoch": 3.736666951105043,
      "grad_norm": 0.29295337200164795,
      "learning_rate": 3.1316665244474785e-05,
      "loss": 0.0017,
      "step": 43790
    },
    {
      "epoch": 3.7375202662343203,
      "grad_norm": 0.17220965027809143,
      "learning_rate": 3.13123986688284e-05,
      "loss": 0.0022,
      "step": 43800
    },
    {
      "epoch": 3.7383735813635974,
      "grad_norm": 0.13033980131149292,
      "learning_rate": 3.1308132093182013e-05,
      "loss": 0.0024,
      "step": 43810
    },
    {
      "epoch": 3.739226896492875,
      "grad_norm": 0.2653716206550598,
      "learning_rate": 3.130386551753563e-05,
      "loss": 0.002,
      "step": 43820
    },
    {
      "epoch": 3.740080211622152,
      "grad_norm": 0.05930400267243385,
      "learning_rate": 3.129959894188924e-05,
      "loss": 0.0022,
      "step": 43830
    },
    {
      "epoch": 3.740933526751429,
      "grad_norm": 0.21619652211666107,
      "learning_rate": 3.1295332366242856e-05,
      "loss": 0.0019,
      "step": 43840
    },
    {
      "epoch": 3.7417868418807068,
      "grad_norm": 0.11560768634080887,
      "learning_rate": 3.129106579059647e-05,
      "loss": 0.0023,
      "step": 43850
    },
    {
      "epoch": 3.742640157009984,
      "grad_norm": 0.3553696274757385,
      "learning_rate": 3.128679921495008e-05,
      "loss": 0.0016,
      "step": 43860
    },
    {
      "epoch": 3.743493472139261,
      "grad_norm": 0.36551815271377563,
      "learning_rate": 3.12825326393037e-05,
      "loss": 0.0017,
      "step": 43870
    },
    {
      "epoch": 3.7443467872685385,
      "grad_norm": 0.22247768938541412,
      "learning_rate": 3.1278266063657306e-05,
      "loss": 0.0022,
      "step": 43880
    },
    {
      "epoch": 3.7452001023978156,
      "grad_norm": 0.13246116042137146,
      "learning_rate": 3.127399948801093e-05,
      "loss": 0.0018,
      "step": 43890
    },
    {
      "epoch": 3.7460534175270928,
      "grad_norm": 0.22344237565994263,
      "learning_rate": 3.1269732912364535e-05,
      "loss": 0.0023,
      "step": 43900
    },
    {
      "epoch": 3.74690673265637,
      "grad_norm": 0.1991599053144455,
      "learning_rate": 3.126546633671815e-05,
      "loss": 0.0022,
      "step": 43910
    },
    {
      "epoch": 3.747760047785647,
      "grad_norm": 0.5723771452903748,
      "learning_rate": 3.126119976107176e-05,
      "loss": 0.0021,
      "step": 43920
    },
    {
      "epoch": 3.7486133629149245,
      "grad_norm": 0.05006001517176628,
      "learning_rate": 3.125693318542538e-05,
      "loss": 0.0022,
      "step": 43930
    },
    {
      "epoch": 3.7494666780442016,
      "grad_norm": 0.048056360334157944,
      "learning_rate": 3.125266660977899e-05,
      "loss": 0.0016,
      "step": 43940
    },
    {
      "epoch": 3.7503199931734787,
      "grad_norm": 0.23605281114578247,
      "learning_rate": 3.1248400034132606e-05,
      "loss": 0.0019,
      "step": 43950
    },
    {
      "epoch": 3.7511733083027563,
      "grad_norm": 0.29778987169265747,
      "learning_rate": 3.124413345848622e-05,
      "loss": 0.002,
      "step": 43960
    },
    {
      "epoch": 3.7520266234320334,
      "grad_norm": 0.10601896047592163,
      "learning_rate": 3.1239866882839834e-05,
      "loss": 0.0019,
      "step": 43970
    },
    {
      "epoch": 3.7528799385613105,
      "grad_norm": 0.26611679792404175,
      "learning_rate": 3.123560030719345e-05,
      "loss": 0.0023,
      "step": 43980
    },
    {
      "epoch": 3.753733253690588,
      "grad_norm": 0.019182803109288216,
      "learning_rate": 3.123133373154706e-05,
      "loss": 0.0019,
      "step": 43990
    },
    {
      "epoch": 3.754586568819865,
      "grad_norm": 0.1513303816318512,
      "learning_rate": 3.122706715590068e-05,
      "loss": 0.0023,
      "step": 44000
    },
    {
      "epoch": 3.7554398839491423,
      "grad_norm": 0.06913745403289795,
      "learning_rate": 3.122280058025429e-05,
      "loss": 0.0021,
      "step": 44010
    },
    {
      "epoch": 3.75629319907842,
      "grad_norm": 0.14966337382793427,
      "learning_rate": 3.12185340046079e-05,
      "loss": 0.0017,
      "step": 44020
    },
    {
      "epoch": 3.757146514207697,
      "grad_norm": 0.04272136837244034,
      "learning_rate": 3.121426742896152e-05,
      "loss": 0.0017,
      "step": 44030
    },
    {
      "epoch": 3.757999829336974,
      "grad_norm": 0.25652337074279785,
      "learning_rate": 3.121000085331513e-05,
      "loss": 0.0017,
      "step": 44040
    },
    {
      "epoch": 3.7588531444662516,
      "grad_norm": 0.17372797429561615,
      "learning_rate": 3.120573427766875e-05,
      "loss": 0.0016,
      "step": 44050
    },
    {
      "epoch": 3.7597064595955287,
      "grad_norm": 0.14991284906864166,
      "learning_rate": 3.1201467702022356e-05,
      "loss": 0.0022,
      "step": 44060
    },
    {
      "epoch": 3.760559774724806,
      "grad_norm": 0.24063633382320404,
      "learning_rate": 3.119720112637598e-05,
      "loss": 0.002,
      "step": 44070
    },
    {
      "epoch": 3.761413089854083,
      "grad_norm": 0.1208750382065773,
      "learning_rate": 3.1192934550729584e-05,
      "loss": 0.002,
      "step": 44080
    },
    {
      "epoch": 3.7622664049833605,
      "grad_norm": 0.29727694392204285,
      "learning_rate": 3.1188667975083205e-05,
      "loss": 0.0021,
      "step": 44090
    },
    {
      "epoch": 3.7631197201126376,
      "grad_norm": 0.09551595151424408,
      "learning_rate": 3.118440139943681e-05,
      "loss": 0.002,
      "step": 44100
    },
    {
      "epoch": 3.7639730352419147,
      "grad_norm": 0.2224487066268921,
      "learning_rate": 3.118013482379043e-05,
      "loss": 0.0017,
      "step": 44110
    },
    {
      "epoch": 3.764826350371192,
      "grad_norm": 0.17652106285095215,
      "learning_rate": 3.117586824814404e-05,
      "loss": 0.0019,
      "step": 44120
    },
    {
      "epoch": 3.7656796655004694,
      "grad_norm": 0.25916534662246704,
      "learning_rate": 3.1171601672497656e-05,
      "loss": 0.0019,
      "step": 44130
    },
    {
      "epoch": 3.7665329806297465,
      "grad_norm": 0.25191807746887207,
      "learning_rate": 3.116733509685127e-05,
      "loss": 0.0021,
      "step": 44140
    },
    {
      "epoch": 3.7673862957590236,
      "grad_norm": 0.3185742497444153,
      "learning_rate": 3.116306852120488e-05,
      "loss": 0.0017,
      "step": 44150
    },
    {
      "epoch": 3.768239610888301,
      "grad_norm": 0.3905557692050934,
      "learning_rate": 3.11588019455585e-05,
      "loss": 0.0022,
      "step": 44160
    },
    {
      "epoch": 3.7690929260175783,
      "grad_norm": 0.017507845535874367,
      "learning_rate": 3.1154535369912106e-05,
      "loss": 0.0021,
      "step": 44170
    },
    {
      "epoch": 3.7699462411468554,
      "grad_norm": 0.24984952807426453,
      "learning_rate": 3.115026879426573e-05,
      "loss": 0.0022,
      "step": 44180
    },
    {
      "epoch": 3.770799556276133,
      "grad_norm": 0.04632486775517464,
      "learning_rate": 3.1146002218619334e-05,
      "loss": 0.0021,
      "step": 44190
    },
    {
      "epoch": 3.77165287140541,
      "grad_norm": 0.08918872475624084,
      "learning_rate": 3.1141735642972955e-05,
      "loss": 0.0019,
      "step": 44200
    },
    {
      "epoch": 3.772506186534687,
      "grad_norm": 0.04962911084294319,
      "learning_rate": 3.113746906732656e-05,
      "loss": 0.0018,
      "step": 44210
    },
    {
      "epoch": 3.7733595016639647,
      "grad_norm": 0.02109086886048317,
      "learning_rate": 3.113320249168018e-05,
      "loss": 0.0022,
      "step": 44220
    },
    {
      "epoch": 3.774212816793242,
      "grad_norm": 0.11173602193593979,
      "learning_rate": 3.112893591603379e-05,
      "loss": 0.0019,
      "step": 44230
    },
    {
      "epoch": 3.775066131922519,
      "grad_norm": 0.03659515455365181,
      "learning_rate": 3.1124669340387405e-05,
      "loss": 0.0022,
      "step": 44240
    },
    {
      "epoch": 3.7759194470517965,
      "grad_norm": 0.09801559895277023,
      "learning_rate": 3.112040276474102e-05,
      "loss": 0.0023,
      "step": 44250
    },
    {
      "epoch": 3.7767727621810736,
      "grad_norm": 0.08401518315076828,
      "learning_rate": 3.1116136189094634e-05,
      "loss": 0.0022,
      "step": 44260
    },
    {
      "epoch": 3.7776260773103507,
      "grad_norm": 0.19773782789707184,
      "learning_rate": 3.111186961344825e-05,
      "loss": 0.002,
      "step": 44270
    },
    {
      "epoch": 3.778479392439628,
      "grad_norm": 0.035284046083688736,
      "learning_rate": 3.110760303780186e-05,
      "loss": 0.0017,
      "step": 44280
    },
    {
      "epoch": 3.779332707568905,
      "grad_norm": 0.18287333846092224,
      "learning_rate": 3.110333646215548e-05,
      "loss": 0.0021,
      "step": 44290
    },
    {
      "epoch": 3.7801860226981825,
      "grad_norm": 0.04222341254353523,
      "learning_rate": 3.109906988650909e-05,
      "loss": 0.0022,
      "step": 44300
    },
    {
      "epoch": 3.7810393378274596,
      "grad_norm": 0.26252421736717224,
      "learning_rate": 3.1094803310862705e-05,
      "loss": 0.0019,
      "step": 44310
    },
    {
      "epoch": 3.7818926529567367,
      "grad_norm": 0.29468536376953125,
      "learning_rate": 3.109053673521632e-05,
      "loss": 0.0017,
      "step": 44320
    },
    {
      "epoch": 3.7827459680860143,
      "grad_norm": 0.19426237046718597,
      "learning_rate": 3.108627015956993e-05,
      "loss": 0.0019,
      "step": 44330
    },
    {
      "epoch": 3.7835992832152914,
      "grad_norm": 0.02762492373585701,
      "learning_rate": 3.108200358392355e-05,
      "loss": 0.0015,
      "step": 44340
    },
    {
      "epoch": 3.7844525983445685,
      "grad_norm": 0.25390878319740295,
      "learning_rate": 3.1077737008277155e-05,
      "loss": 0.0016,
      "step": 44350
    },
    {
      "epoch": 3.785305913473846,
      "grad_norm": 0.24427686631679535,
      "learning_rate": 3.1073470432630776e-05,
      "loss": 0.0019,
      "step": 44360
    },
    {
      "epoch": 3.786159228603123,
      "grad_norm": 0.103543721139431,
      "learning_rate": 3.1069203856984384e-05,
      "loss": 0.0019,
      "step": 44370
    },
    {
      "epoch": 3.7870125437324003,
      "grad_norm": 0.126902773976326,
      "learning_rate": 3.1064937281338e-05,
      "loss": 0.002,
      "step": 44380
    },
    {
      "epoch": 3.787865858861678,
      "grad_norm": 0.3350159823894501,
      "learning_rate": 3.106067070569161e-05,
      "loss": 0.0019,
      "step": 44390
    },
    {
      "epoch": 3.788719173990955,
      "grad_norm": 0.18366365134716034,
      "learning_rate": 3.1056404130045227e-05,
      "loss": 0.0018,
      "step": 44400
    },
    {
      "epoch": 3.789572489120232,
      "grad_norm": 0.16891245543956757,
      "learning_rate": 3.105213755439884e-05,
      "loss": 0.002,
      "step": 44410
    },
    {
      "epoch": 3.7904258042495096,
      "grad_norm": 0.08142423629760742,
      "learning_rate": 3.1047870978752455e-05,
      "loss": 0.0019,
      "step": 44420
    },
    {
      "epoch": 3.7912791193787867,
      "grad_norm": 0.20434942841529846,
      "learning_rate": 3.104360440310607e-05,
      "loss": 0.0023,
      "step": 44430
    },
    {
      "epoch": 3.792132434508064,
      "grad_norm": 0.1489829570055008,
      "learning_rate": 3.1039337827459683e-05,
      "loss": 0.0016,
      "step": 44440
    },
    {
      "epoch": 3.792985749637341,
      "grad_norm": 0.24671770632266998,
      "learning_rate": 3.10350712518133e-05,
      "loss": 0.0021,
      "step": 44450
    },
    {
      "epoch": 3.7938390647666185,
      "grad_norm": 0.26445257663726807,
      "learning_rate": 3.1030804676166905e-05,
      "loss": 0.0017,
      "step": 44460
    },
    {
      "epoch": 3.7946923798958956,
      "grad_norm": 0.06187467277050018,
      "learning_rate": 3.1026538100520526e-05,
      "loss": 0.0018,
      "step": 44470
    },
    {
      "epoch": 3.7955456950251727,
      "grad_norm": 0.2043473869562149,
      "learning_rate": 3.1022271524874134e-05,
      "loss": 0.0022,
      "step": 44480
    },
    {
      "epoch": 3.79639901015445,
      "grad_norm": 0.1886150985956192,
      "learning_rate": 3.1018004949227755e-05,
      "loss": 0.0021,
      "step": 44490
    },
    {
      "epoch": 3.7972523252837274,
      "grad_norm": 0.09342529624700546,
      "learning_rate": 3.101373837358136e-05,
      "loss": 0.0023,
      "step": 44500
    },
    {
      "epoch": 3.7981056404130045,
      "grad_norm": 0.16815359890460968,
      "learning_rate": 3.100947179793498e-05,
      "loss": 0.0018,
      "step": 44510
    },
    {
      "epoch": 3.7989589555422816,
      "grad_norm": 0.09387139230966568,
      "learning_rate": 3.100520522228859e-05,
      "loss": 0.0018,
      "step": 44520
    },
    {
      "epoch": 3.799812270671559,
      "grad_norm": 0.282949835062027,
      "learning_rate": 3.1000938646642205e-05,
      "loss": 0.0017,
      "step": 44530
    },
    {
      "epoch": 3.8006655858008362,
      "grad_norm": 0.11271239072084427,
      "learning_rate": 3.099667207099582e-05,
      "loss": 0.0019,
      "step": 44540
    },
    {
      "epoch": 3.8015189009301134,
      "grad_norm": 0.06282445788383484,
      "learning_rate": 3.099240549534943e-05,
      "loss": 0.0016,
      "step": 44550
    },
    {
      "epoch": 3.802372216059391,
      "grad_norm": 0.09395910799503326,
      "learning_rate": 3.098813891970305e-05,
      "loss": 0.0024,
      "step": 44560
    },
    {
      "epoch": 3.803225531188668,
      "grad_norm": 0.058016255497932434,
      "learning_rate": 3.098387234405666e-05,
      "loss": 0.0022,
      "step": 44570
    },
    {
      "epoch": 3.804078846317945,
      "grad_norm": 0.12992946803569794,
      "learning_rate": 3.0979605768410276e-05,
      "loss": 0.0013,
      "step": 44580
    },
    {
      "epoch": 3.8049321614472227,
      "grad_norm": 0.1882188320159912,
      "learning_rate": 3.097533919276389e-05,
      "loss": 0.0017,
      "step": 44590
    },
    {
      "epoch": 3.8057854765765,
      "grad_norm": 0.3890574872493744,
      "learning_rate": 3.0971072617117505e-05,
      "loss": 0.003,
      "step": 44600
    },
    {
      "epoch": 3.806638791705777,
      "grad_norm": 0.11314103752374649,
      "learning_rate": 3.096680604147112e-05,
      "loss": 0.0025,
      "step": 44610
    },
    {
      "epoch": 3.8074921068350545,
      "grad_norm": 0.37002092599868774,
      "learning_rate": 3.096253946582473e-05,
      "loss": 0.0025,
      "step": 44620
    },
    {
      "epoch": 3.8083454219643316,
      "grad_norm": 0.2315361201763153,
      "learning_rate": 3.095827289017835e-05,
      "loss": 0.0021,
      "step": 44630
    },
    {
      "epoch": 3.8091987370936087,
      "grad_norm": 0.4997030198574066,
      "learning_rate": 3.0954006314531955e-05,
      "loss": 0.0017,
      "step": 44640
    },
    {
      "epoch": 3.810052052222886,
      "grad_norm": 0.044197455048561096,
      "learning_rate": 3.094973973888557e-05,
      "loss": 0.0022,
      "step": 44650
    },
    {
      "epoch": 3.810905367352163,
      "grad_norm": 0.16851605474948883,
      "learning_rate": 3.094547316323918e-05,
      "loss": 0.0019,
      "step": 44660
    },
    {
      "epoch": 3.8117586824814405,
      "grad_norm": 0.147347554564476,
      "learning_rate": 3.09412065875928e-05,
      "loss": 0.0015,
      "step": 44670
    },
    {
      "epoch": 3.8126119976107176,
      "grad_norm": 0.07735875993967056,
      "learning_rate": 3.093694001194641e-05,
      "loss": 0.0018,
      "step": 44680
    },
    {
      "epoch": 3.8134653127399947,
      "grad_norm": 0.25581157207489014,
      "learning_rate": 3.0932673436300026e-05,
      "loss": 0.0017,
      "step": 44690
    },
    {
      "epoch": 3.8143186278692722,
      "grad_norm": 0.07456681877374649,
      "learning_rate": 3.092840686065364e-05,
      "loss": 0.0018,
      "step": 44700
    },
    {
      "epoch": 3.8151719429985493,
      "grad_norm": 0.03818929195404053,
      "learning_rate": 3.0924140285007254e-05,
      "loss": 0.0015,
      "step": 44710
    },
    {
      "epoch": 3.8160252581278264,
      "grad_norm": 0.20123440027236938,
      "learning_rate": 3.091987370936087e-05,
      "loss": 0.0019,
      "step": 44720
    },
    {
      "epoch": 3.816878573257104,
      "grad_norm": 0.08695603907108307,
      "learning_rate": 3.091560713371448e-05,
      "loss": 0.0018,
      "step": 44730
    },
    {
      "epoch": 3.817731888386381,
      "grad_norm": 0.1356276571750641,
      "learning_rate": 3.09113405580681e-05,
      "loss": 0.002,
      "step": 44740
    },
    {
      "epoch": 3.818585203515658,
      "grad_norm": 0.4375725984573364,
      "learning_rate": 3.090707398242171e-05,
      "loss": 0.0021,
      "step": 44750
    },
    {
      "epoch": 3.8194385186449358,
      "grad_norm": 0.14086861908435822,
      "learning_rate": 3.0902807406775326e-05,
      "loss": 0.0016,
      "step": 44760
    },
    {
      "epoch": 3.820291833774213,
      "grad_norm": 0.038777466863393784,
      "learning_rate": 3.089854083112893e-05,
      "loss": 0.0023,
      "step": 44770
    },
    {
      "epoch": 3.82114514890349,
      "grad_norm": 0.17394524812698364,
      "learning_rate": 3.0894274255482554e-05,
      "loss": 0.0022,
      "step": 44780
    },
    {
      "epoch": 3.8219984640327676,
      "grad_norm": 0.35272645950317383,
      "learning_rate": 3.089000767983616e-05,
      "loss": 0.0017,
      "step": 44790
    },
    {
      "epoch": 3.8228517791620447,
      "grad_norm": 0.07286998629570007,
      "learning_rate": 3.088574110418978e-05,
      "loss": 0.0015,
      "step": 44800
    },
    {
      "epoch": 3.8237050942913218,
      "grad_norm": 0.31352895498275757,
      "learning_rate": 3.088147452854339e-05,
      "loss": 0.0016,
      "step": 44810
    },
    {
      "epoch": 3.824558409420599,
      "grad_norm": 0.08179736137390137,
      "learning_rate": 3.087720795289701e-05,
      "loss": 0.0025,
      "step": 44820
    },
    {
      "epoch": 3.8254117245498764,
      "grad_norm": 0.03727366402745247,
      "learning_rate": 3.087294137725062e-05,
      "loss": 0.0023,
      "step": 44830
    },
    {
      "epoch": 3.8262650396791535,
      "grad_norm": 0.3940466344356537,
      "learning_rate": 3.086867480160423e-05,
      "loss": 0.0022,
      "step": 44840
    },
    {
      "epoch": 3.8271183548084307,
      "grad_norm": 0.27653780579566956,
      "learning_rate": 3.086440822595785e-05,
      "loss": 0.0019,
      "step": 44850
    },
    {
      "epoch": 3.8279716699377078,
      "grad_norm": 0.4053802788257599,
      "learning_rate": 3.086014165031146e-05,
      "loss": 0.0026,
      "step": 44860
    },
    {
      "epoch": 3.8288249850669853,
      "grad_norm": 0.15802805125713348,
      "learning_rate": 3.0855875074665076e-05,
      "loss": 0.0022,
      "step": 44870
    },
    {
      "epoch": 3.8296783001962624,
      "grad_norm": 0.043062008917331696,
      "learning_rate": 3.085160849901869e-05,
      "loss": 0.0021,
      "step": 44880
    },
    {
      "epoch": 3.8305316153255395,
      "grad_norm": 0.09691934287548065,
      "learning_rate": 3.0847341923372304e-05,
      "loss": 0.0018,
      "step": 44890
    },
    {
      "epoch": 3.831384930454817,
      "grad_norm": 0.1895497888326645,
      "learning_rate": 3.084307534772592e-05,
      "loss": 0.0019,
      "step": 44900
    },
    {
      "epoch": 3.832238245584094,
      "grad_norm": 0.036283429712057114,
      "learning_rate": 3.083880877207953e-05,
      "loss": 0.0016,
      "step": 44910
    },
    {
      "epoch": 3.8330915607133713,
      "grad_norm": 0.2370975911617279,
      "learning_rate": 3.083454219643314e-05,
      "loss": 0.0028,
      "step": 44920
    },
    {
      "epoch": 3.833944875842649,
      "grad_norm": 0.034070320427417755,
      "learning_rate": 3.083027562078676e-05,
      "loss": 0.0021,
      "step": 44930
    },
    {
      "epoch": 3.834798190971926,
      "grad_norm": 0.28584250807762146,
      "learning_rate": 3.082600904514037e-05,
      "loss": 0.0024,
      "step": 44940
    },
    {
      "epoch": 3.835651506101203,
      "grad_norm": 0.1774902492761612,
      "learning_rate": 3.082174246949398e-05,
      "loss": 0.0023,
      "step": 44950
    },
    {
      "epoch": 3.8365048212304806,
      "grad_norm": 0.26642587780952454,
      "learning_rate": 3.08174758938476e-05,
      "loss": 0.0022,
      "step": 44960
    },
    {
      "epoch": 3.8373581363597578,
      "grad_norm": 0.3559720814228058,
      "learning_rate": 3.081320931820121e-05,
      "loss": 0.0022,
      "step": 44970
    },
    {
      "epoch": 3.838211451489035,
      "grad_norm": 0.03803631290793419,
      "learning_rate": 3.0808942742554825e-05,
      "loss": 0.0022,
      "step": 44980
    },
    {
      "epoch": 3.8390647666183124,
      "grad_norm": 0.08942107856273651,
      "learning_rate": 3.080467616690844e-05,
      "loss": 0.0018,
      "step": 44990
    },
    {
      "epoch": 3.8399180817475895,
      "grad_norm": 0.13105565309524536,
      "learning_rate": 3.0800409591262054e-05,
      "loss": 0.0024,
      "step": 45000
    },
    {
      "epoch": 3.8407713968768666,
      "grad_norm": 0.2961120903491974,
      "learning_rate": 3.079614301561567e-05,
      "loss": 0.002,
      "step": 45010
    },
    {
      "epoch": 3.8416247120061437,
      "grad_norm": 0.41161635518074036,
      "learning_rate": 3.079187643996928e-05,
      "loss": 0.0019,
      "step": 45020
    },
    {
      "epoch": 3.842478027135421,
      "grad_norm": 0.3830535411834717,
      "learning_rate": 3.0787609864322897e-05,
      "loss": 0.0021,
      "step": 45030
    },
    {
      "epoch": 3.8433313422646984,
      "grad_norm": 0.06809450685977936,
      "learning_rate": 3.078334328867651e-05,
      "loss": 0.002,
      "step": 45040
    },
    {
      "epoch": 3.8441846573939755,
      "grad_norm": 0.3177933990955353,
      "learning_rate": 3.0779076713030125e-05,
      "loss": 0.0019,
      "step": 45050
    },
    {
      "epoch": 3.8450379725232526,
      "grad_norm": 0.4848736822605133,
      "learning_rate": 3.077481013738374e-05,
      "loss": 0.0022,
      "step": 45060
    },
    {
      "epoch": 3.84589128765253,
      "grad_norm": 0.13140937685966492,
      "learning_rate": 3.0770543561737354e-05,
      "loss": 0.002,
      "step": 45070
    },
    {
      "epoch": 3.8467446027818073,
      "grad_norm": 0.3099769949913025,
      "learning_rate": 3.076627698609096e-05,
      "loss": 0.0019,
      "step": 45080
    },
    {
      "epoch": 3.8475979179110844,
      "grad_norm": 0.4640413224697113,
      "learning_rate": 3.076201041044458e-05,
      "loss": 0.0017,
      "step": 45090
    },
    {
      "epoch": 3.848451233040362,
      "grad_norm": 0.4837323725223541,
      "learning_rate": 3.075774383479819e-05,
      "loss": 0.0019,
      "step": 45100
    },
    {
      "epoch": 3.849304548169639,
      "grad_norm": 0.13351090252399445,
      "learning_rate": 3.075347725915181e-05,
      "loss": 0.0021,
      "step": 45110
    },
    {
      "epoch": 3.850157863298916,
      "grad_norm": 0.37638789415359497,
      "learning_rate": 3.074921068350542e-05,
      "loss": 0.0023,
      "step": 45120
    },
    {
      "epoch": 3.8510111784281937,
      "grad_norm": 0.18471811711788177,
      "learning_rate": 3.074494410785904e-05,
      "loss": 0.0024,
      "step": 45130
    },
    {
      "epoch": 3.851864493557471,
      "grad_norm": 0.04481309652328491,
      "learning_rate": 3.0740677532212646e-05,
      "loss": 0.0016,
      "step": 45140
    },
    {
      "epoch": 3.852717808686748,
      "grad_norm": 0.2067081183195114,
      "learning_rate": 3.073641095656626e-05,
      "loss": 0.0023,
      "step": 45150
    },
    {
      "epoch": 3.8535711238160255,
      "grad_norm": 0.1465948075056076,
      "learning_rate": 3.0732144380919875e-05,
      "loss": 0.0018,
      "step": 45160
    },
    {
      "epoch": 3.8544244389453026,
      "grad_norm": 0.11365541815757751,
      "learning_rate": 3.072787780527349e-05,
      "loss": 0.0019,
      "step": 45170
    },
    {
      "epoch": 3.8552777540745797,
      "grad_norm": 0.029897956177592278,
      "learning_rate": 3.0723611229627103e-05,
      "loss": 0.0016,
      "step": 45180
    },
    {
      "epoch": 3.856131069203857,
      "grad_norm": 0.2043912261724472,
      "learning_rate": 3.071934465398071e-05,
      "loss": 0.0022,
      "step": 45190
    },
    {
      "epoch": 3.856984384333134,
      "grad_norm": 0.4474796652793884,
      "learning_rate": 3.071507807833433e-05,
      "loss": 0.0015,
      "step": 45200
    },
    {
      "epoch": 3.8578376994624115,
      "grad_norm": 0.2422247976064682,
      "learning_rate": 3.071081150268794e-05,
      "loss": 0.0021,
      "step": 45210
    },
    {
      "epoch": 3.8586910145916886,
      "grad_norm": 0.15434972941875458,
      "learning_rate": 3.070654492704156e-05,
      "loss": 0.002,
      "step": 45220
    },
    {
      "epoch": 3.8595443297209657,
      "grad_norm": 0.04319510608911514,
      "learning_rate": 3.070227835139517e-05,
      "loss": 0.0015,
      "step": 45230
    },
    {
      "epoch": 3.8603976448502433,
      "grad_norm": 0.2811051905155182,
      "learning_rate": 3.069801177574879e-05,
      "loss": 0.0018,
      "step": 45240
    },
    {
      "epoch": 3.8612509599795204,
      "grad_norm": 0.08150070160627365,
      "learning_rate": 3.0693745200102396e-05,
      "loss": 0.0019,
      "step": 45250
    },
    {
      "epoch": 3.8621042751087975,
      "grad_norm": 0.22504574060440063,
      "learning_rate": 3.068947862445602e-05,
      "loss": 0.0023,
      "step": 45260
    },
    {
      "epoch": 3.862957590238075,
      "grad_norm": 0.2780739665031433,
      "learning_rate": 3.0685212048809625e-05,
      "loss": 0.0012,
      "step": 45270
    },
    {
      "epoch": 3.863810905367352,
      "grad_norm": 0.06474027037620544,
      "learning_rate": 3.068094547316324e-05,
      "loss": 0.0016,
      "step": 45280
    },
    {
      "epoch": 3.8646642204966293,
      "grad_norm": 0.1991197168827057,
      "learning_rate": 3.067667889751685e-05,
      "loss": 0.0014,
      "step": 45290
    },
    {
      "epoch": 3.865517535625907,
      "grad_norm": 0.06683899462223053,
      "learning_rate": 3.067241232187047e-05,
      "loss": 0.0018,
      "step": 45300
    },
    {
      "epoch": 3.866370850755184,
      "grad_norm": 0.04921232908964157,
      "learning_rate": 3.066814574622408e-05,
      "loss": 0.0015,
      "step": 45310
    },
    {
      "epoch": 3.867224165884461,
      "grad_norm": 0.09494518488645554,
      "learning_rate": 3.0663879170577696e-05,
      "loss": 0.0023,
      "step": 45320
    },
    {
      "epoch": 3.8680774810137386,
      "grad_norm": 0.09370148181915283,
      "learning_rate": 3.065961259493131e-05,
      "loss": 0.0015,
      "step": 45330
    },
    {
      "epoch": 3.8689307961430157,
      "grad_norm": 0.2245330661535263,
      "learning_rate": 3.0655346019284924e-05,
      "loss": 0.0024,
      "step": 45340
    },
    {
      "epoch": 3.869784111272293,
      "grad_norm": 0.17166991531848907,
      "learning_rate": 3.065107944363854e-05,
      "loss": 0.0018,
      "step": 45350
    },
    {
      "epoch": 3.87063742640157,
      "grad_norm": 0.22579838335514069,
      "learning_rate": 3.064681286799215e-05,
      "loss": 0.0019,
      "step": 45360
    },
    {
      "epoch": 3.8714907415308475,
      "grad_norm": 0.24633678793907166,
      "learning_rate": 3.064254629234577e-05,
      "loss": 0.0019,
      "step": 45370
    },
    {
      "epoch": 3.8723440566601246,
      "grad_norm": 0.1573842316865921,
      "learning_rate": 3.063827971669938e-05,
      "loss": 0.002,
      "step": 45380
    },
    {
      "epoch": 3.8731973717894017,
      "grad_norm": 0.19132374227046967,
      "learning_rate": 3.063401314105299e-05,
      "loss": 0.0016,
      "step": 45390
    },
    {
      "epoch": 3.874050686918679,
      "grad_norm": 0.301154226064682,
      "learning_rate": 3.062974656540661e-05,
      "loss": 0.0018,
      "step": 45400
    },
    {
      "epoch": 3.8749040020479564,
      "grad_norm": 0.16229942440986633,
      "learning_rate": 3.062547998976022e-05,
      "loss": 0.0024,
      "step": 45410
    },
    {
      "epoch": 3.8757573171772335,
      "grad_norm": 0.5570325255393982,
      "learning_rate": 3.062121341411384e-05,
      "loss": 0.0018,
      "step": 45420
    },
    {
      "epoch": 3.8766106323065106,
      "grad_norm": 0.45085838437080383,
      "learning_rate": 3.0616946838467446e-05,
      "loss": 0.0022,
      "step": 45430
    },
    {
      "epoch": 3.877463947435788,
      "grad_norm": 0.14569051563739777,
      "learning_rate": 3.061268026282107e-05,
      "loss": 0.0017,
      "step": 45440
    },
    {
      "epoch": 3.8783172625650653,
      "grad_norm": 0.43192824721336365,
      "learning_rate": 3.0608413687174674e-05,
      "loss": 0.0021,
      "step": 45450
    },
    {
      "epoch": 3.8791705776943424,
      "grad_norm": 0.06517476588487625,
      "learning_rate": 3.060414711152829e-05,
      "loss": 0.0016,
      "step": 45460
    },
    {
      "epoch": 3.88002389282362,
      "grad_norm": 0.038396816700696945,
      "learning_rate": 3.05998805358819e-05,
      "loss": 0.0016,
      "step": 45470
    },
    {
      "epoch": 3.880877207952897,
      "grad_norm": 0.11525344848632812,
      "learning_rate": 3.059561396023552e-05,
      "loss": 0.0016,
      "step": 45480
    },
    {
      "epoch": 3.881730523082174,
      "grad_norm": 0.25534358620643616,
      "learning_rate": 3.059134738458913e-05,
      "loss": 0.0021,
      "step": 45490
    },
    {
      "epoch": 3.8825838382114517,
      "grad_norm": 0.319044828414917,
      "learning_rate": 3.058708080894274e-05,
      "loss": 0.002,
      "step": 45500
    },
    {
      "epoch": 3.883437153340729,
      "grad_norm": 0.41096407175064087,
      "learning_rate": 3.058281423329636e-05,
      "loss": 0.0022,
      "step": 45510
    },
    {
      "epoch": 3.884290468470006,
      "grad_norm": 0.22782137989997864,
      "learning_rate": 3.057854765764997e-05,
      "loss": 0.0022,
      "step": 45520
    },
    {
      "epoch": 3.8851437835992835,
      "grad_norm": 0.20586052536964417,
      "learning_rate": 3.057428108200359e-05,
      "loss": 0.0026,
      "step": 45530
    },
    {
      "epoch": 3.8859970987285606,
      "grad_norm": 0.07930254191160202,
      "learning_rate": 3.0570014506357196e-05,
      "loss": 0.0018,
      "step": 45540
    },
    {
      "epoch": 3.8868504138578377,
      "grad_norm": 0.2591092884540558,
      "learning_rate": 3.056574793071082e-05,
      "loss": 0.0015,
      "step": 45550
    },
    {
      "epoch": 3.887703728987115,
      "grad_norm": 0.22253069281578064,
      "learning_rate": 3.0561481355064424e-05,
      "loss": 0.0024,
      "step": 45560
    },
    {
      "epoch": 3.888557044116392,
      "grad_norm": 0.2781919240951538,
      "learning_rate": 3.0557214779418045e-05,
      "loss": 0.0023,
      "step": 45570
    },
    {
      "epoch": 3.8894103592456695,
      "grad_norm": 0.0818278044462204,
      "learning_rate": 3.055294820377165e-05,
      "loss": 0.002,
      "step": 45580
    },
    {
      "epoch": 3.8902636743749466,
      "grad_norm": 0.20069997012615204,
      "learning_rate": 3.054868162812527e-05,
      "loss": 0.003,
      "step": 45590
    },
    {
      "epoch": 3.8911169895042237,
      "grad_norm": 0.4310199022293091,
      "learning_rate": 3.054441505247888e-05,
      "loss": 0.0016,
      "step": 45600
    },
    {
      "epoch": 3.8919703046335012,
      "grad_norm": 0.07627002894878387,
      "learning_rate": 3.0540148476832495e-05,
      "loss": 0.0025,
      "step": 45610
    },
    {
      "epoch": 3.8928236197627784,
      "grad_norm": 0.1331631988286972,
      "learning_rate": 3.053588190118611e-05,
      "loss": 0.0021,
      "step": 45620
    },
    {
      "epoch": 3.8936769348920555,
      "grad_norm": 0.3199910819530487,
      "learning_rate": 3.0531615325539724e-05,
      "loss": 0.0023,
      "step": 45630
    },
    {
      "epoch": 3.894530250021333,
      "grad_norm": 0.17092996835708618,
      "learning_rate": 3.052734874989334e-05,
      "loss": 0.0024,
      "step": 45640
    },
    {
      "epoch": 3.89538356515061,
      "grad_norm": 0.22789418697357178,
      "learning_rate": 3.052308217424695e-05,
      "loss": 0.0022,
      "step": 45650
    },
    {
      "epoch": 3.8962368802798872,
      "grad_norm": 0.09572990238666534,
      "learning_rate": 3.051881559860057e-05,
      "loss": 0.0027,
      "step": 45660
    },
    {
      "epoch": 3.897090195409165,
      "grad_norm": 0.163833886384964,
      "learning_rate": 3.051454902295418e-05,
      "loss": 0.0023,
      "step": 45670
    },
    {
      "epoch": 3.897943510538442,
      "grad_norm": 0.0214339941740036,
      "learning_rate": 3.0510282447307792e-05,
      "loss": 0.0024,
      "step": 45680
    },
    {
      "epoch": 3.898796825667719,
      "grad_norm": 0.31835445761680603,
      "learning_rate": 3.050601587166141e-05,
      "loss": 0.0027,
      "step": 45690
    },
    {
      "epoch": 3.8996501407969966,
      "grad_norm": 0.11351441591978073,
      "learning_rate": 3.050174929601502e-05,
      "loss": 0.0023,
      "step": 45700
    },
    {
      "epoch": 3.9005034559262737,
      "grad_norm": 0.04493540897965431,
      "learning_rate": 3.049748272036863e-05,
      "loss": 0.0021,
      "step": 45710
    },
    {
      "epoch": 3.901356771055551,
      "grad_norm": 0.5434558391571045,
      "learning_rate": 3.049321614472225e-05,
      "loss": 0.0017,
      "step": 45720
    },
    {
      "epoch": 3.902210086184828,
      "grad_norm": 0.20522983372211456,
      "learning_rate": 3.048894956907586e-05,
      "loss": 0.0023,
      "step": 45730
    },
    {
      "epoch": 3.9030634013141055,
      "grad_norm": 0.14808931946754456,
      "learning_rate": 3.0484682993429474e-05,
      "loss": 0.002,
      "step": 45740
    },
    {
      "epoch": 3.9039167164433826,
      "grad_norm": 0.0761454626917839,
      "learning_rate": 3.0480416417783088e-05,
      "loss": 0.0026,
      "step": 45750
    },
    {
      "epoch": 3.9047700315726597,
      "grad_norm": 0.08140873908996582,
      "learning_rate": 3.0476149842136702e-05,
      "loss": 0.0021,
      "step": 45760
    },
    {
      "epoch": 3.905623346701937,
      "grad_norm": 0.1310652494430542,
      "learning_rate": 3.0471883266490313e-05,
      "loss": 0.0021,
      "step": 45770
    },
    {
      "epoch": 3.9064766618312143,
      "grad_norm": 0.29903551936149597,
      "learning_rate": 3.046761669084393e-05,
      "loss": 0.0021,
      "step": 45780
    },
    {
      "epoch": 3.9073299769604914,
      "grad_norm": 0.13334552943706512,
      "learning_rate": 3.046335011519754e-05,
      "loss": 0.0016,
      "step": 45790
    },
    {
      "epoch": 3.9081832920897686,
      "grad_norm": 0.08058199286460876,
      "learning_rate": 3.045908353955116e-05,
      "loss": 0.0019,
      "step": 45800
    },
    {
      "epoch": 3.909036607219046,
      "grad_norm": 0.3800632953643799,
      "learning_rate": 3.045481696390477e-05,
      "loss": 0.002,
      "step": 45810
    },
    {
      "epoch": 3.909889922348323,
      "grad_norm": 0.2239018976688385,
      "learning_rate": 3.0450550388258388e-05,
      "loss": 0.0021,
      "step": 45820
    },
    {
      "epoch": 3.9107432374776003,
      "grad_norm": 0.10784400254487991,
      "learning_rate": 3.0446283812612e-05,
      "loss": 0.0019,
      "step": 45830
    },
    {
      "epoch": 3.911596552606878,
      "grad_norm": 0.27625003457069397,
      "learning_rate": 3.0442017236965613e-05,
      "loss": 0.002,
      "step": 45840
    },
    {
      "epoch": 3.912449867736155,
      "grad_norm": 0.07350009679794312,
      "learning_rate": 3.0437750661319224e-05,
      "loss": 0.0021,
      "step": 45850
    },
    {
      "epoch": 3.913303182865432,
      "grad_norm": 0.20876359939575195,
      "learning_rate": 3.043348408567284e-05,
      "loss": 0.0019,
      "step": 45860
    },
    {
      "epoch": 3.9141564979947097,
      "grad_norm": 0.19419072568416595,
      "learning_rate": 3.0429217510026452e-05,
      "loss": 0.0024,
      "step": 45870
    },
    {
      "epoch": 3.9150098131239868,
      "grad_norm": 0.10888916999101639,
      "learning_rate": 3.042495093438007e-05,
      "loss": 0.0015,
      "step": 45880
    },
    {
      "epoch": 3.915863128253264,
      "grad_norm": 0.2820526361465454,
      "learning_rate": 3.042068435873368e-05,
      "loss": 0.0021,
      "step": 45890
    },
    {
      "epoch": 3.9167164433825414,
      "grad_norm": 0.186781644821167,
      "learning_rate": 3.0416417783087298e-05,
      "loss": 0.0019,
      "step": 45900
    },
    {
      "epoch": 3.9175697585118185,
      "grad_norm": 0.16739854216575623,
      "learning_rate": 3.041215120744091e-05,
      "loss": 0.0017,
      "step": 45910
    },
    {
      "epoch": 3.9184230736410957,
      "grad_norm": 0.07913976162672043,
      "learning_rate": 3.0407884631794527e-05,
      "loss": 0.0016,
      "step": 45920
    },
    {
      "epoch": 3.9192763887703728,
      "grad_norm": 0.21901845932006836,
      "learning_rate": 3.0403618056148138e-05,
      "loss": 0.0017,
      "step": 45930
    },
    {
      "epoch": 3.92012970389965,
      "grad_norm": 0.08664703369140625,
      "learning_rate": 3.0399351480501752e-05,
      "loss": 0.0017,
      "step": 45940
    },
    {
      "epoch": 3.9209830190289274,
      "grad_norm": 0.05431158468127251,
      "learning_rate": 3.0395084904855363e-05,
      "loss": 0.0019,
      "step": 45950
    },
    {
      "epoch": 3.9218363341582045,
      "grad_norm": 0.18925714492797852,
      "learning_rate": 3.039081832920898e-05,
      "loss": 0.0016,
      "step": 45960
    },
    {
      "epoch": 3.9226896492874817,
      "grad_norm": 0.24536192417144775,
      "learning_rate": 3.038655175356259e-05,
      "loss": 0.002,
      "step": 45970
    },
    {
      "epoch": 3.923542964416759,
      "grad_norm": 0.11337456852197647,
      "learning_rate": 3.0382285177916202e-05,
      "loss": 0.0018,
      "step": 45980
    },
    {
      "epoch": 3.9243962795460363,
      "grad_norm": 0.13452684879302979,
      "learning_rate": 3.037801860226982e-05,
      "loss": 0.002,
      "step": 45990
    },
    {
      "epoch": 3.9252495946753134,
      "grad_norm": 0.0434710830450058,
      "learning_rate": 3.037375202662343e-05,
      "loss": 0.0017,
      "step": 46000
    },
    {
      "epoch": 3.926102909804591,
      "grad_norm": 0.4143598675727844,
      "learning_rate": 3.0369485450977048e-05,
      "loss": 0.0022,
      "step": 46010
    },
    {
      "epoch": 3.926956224933868,
      "grad_norm": 0.09659772366285324,
      "learning_rate": 3.036521887533066e-05,
      "loss": 0.0019,
      "step": 46020
    },
    {
      "epoch": 3.927809540063145,
      "grad_norm": 0.14697790145874023,
      "learning_rate": 3.0360952299684277e-05,
      "loss": 0.0021,
      "step": 46030
    },
    {
      "epoch": 3.9286628551924228,
      "grad_norm": 0.1291215866804123,
      "learning_rate": 3.0356685724037887e-05,
      "loss": 0.0017,
      "step": 46040
    },
    {
      "epoch": 3.9295161703217,
      "grad_norm": 0.20365840196609497,
      "learning_rate": 3.0352419148391502e-05,
      "loss": 0.0021,
      "step": 46050
    },
    {
      "epoch": 3.930369485450977,
      "grad_norm": 0.024039683863520622,
      "learning_rate": 3.0348152572745116e-05,
      "loss": 0.0015,
      "step": 46060
    },
    {
      "epoch": 3.9312228005802545,
      "grad_norm": 0.01830390654504299,
      "learning_rate": 3.034388599709873e-05,
      "loss": 0.0018,
      "step": 46070
    },
    {
      "epoch": 3.9320761157095316,
      "grad_norm": 0.0314406082034111,
      "learning_rate": 3.033961942145234e-05,
      "loss": 0.0017,
      "step": 46080
    },
    {
      "epoch": 3.9329294308388087,
      "grad_norm": 0.3491840660572052,
      "learning_rate": 3.033535284580596e-05,
      "loss": 0.0015,
      "step": 46090
    },
    {
      "epoch": 3.933782745968086,
      "grad_norm": 0.09599022567272186,
      "learning_rate": 3.033108627015957e-05,
      "loss": 0.0017,
      "step": 46100
    },
    {
      "epoch": 3.9346360610973634,
      "grad_norm": 0.40364930033683777,
      "learning_rate": 3.0326819694513187e-05,
      "loss": 0.0023,
      "step": 46110
    },
    {
      "epoch": 3.9354893762266405,
      "grad_norm": 0.39421772956848145,
      "learning_rate": 3.0322553118866798e-05,
      "loss": 0.0023,
      "step": 46120
    },
    {
      "epoch": 3.9363426913559176,
      "grad_norm": 0.16572517156600952,
      "learning_rate": 3.0318286543220416e-05,
      "loss": 0.0023,
      "step": 46130
    },
    {
      "epoch": 3.9371960064851947,
      "grad_norm": 0.18464083969593048,
      "learning_rate": 3.0314019967574027e-05,
      "loss": 0.0021,
      "step": 46140
    },
    {
      "epoch": 3.9380493216144723,
      "grad_norm": 0.09310116618871689,
      "learning_rate": 3.030975339192764e-05,
      "loss": 0.0017,
      "step": 46150
    },
    {
      "epoch": 3.9389026367437494,
      "grad_norm": 0.14876753091812134,
      "learning_rate": 3.0305486816281255e-05,
      "loss": 0.0024,
      "step": 46160
    },
    {
      "epoch": 3.9397559518730265,
      "grad_norm": 0.24575498700141907,
      "learning_rate": 3.030122024063487e-05,
      "loss": 0.0024,
      "step": 46170
    },
    {
      "epoch": 3.940609267002304,
      "grad_norm": 0.09675240516662598,
      "learning_rate": 3.029695366498848e-05,
      "loss": 0.0018,
      "step": 46180
    },
    {
      "epoch": 3.941462582131581,
      "grad_norm": 0.09513616561889648,
      "learning_rate": 3.0292687089342098e-05,
      "loss": 0.0023,
      "step": 46190
    },
    {
      "epoch": 3.9423158972608583,
      "grad_norm": 0.03972893953323364,
      "learning_rate": 3.028842051369571e-05,
      "loss": 0.0022,
      "step": 46200
    },
    {
      "epoch": 3.943169212390136,
      "grad_norm": 0.07186960428953171,
      "learning_rate": 3.0284153938049326e-05,
      "loss": 0.0019,
      "step": 46210
    },
    {
      "epoch": 3.944022527519413,
      "grad_norm": 0.3140563368797302,
      "learning_rate": 3.0279887362402937e-05,
      "loss": 0.0018,
      "step": 46220
    },
    {
      "epoch": 3.94487584264869,
      "grad_norm": 0.5731837749481201,
      "learning_rate": 3.0275620786756555e-05,
      "loss": 0.0018,
      "step": 46230
    },
    {
      "epoch": 3.9457291577779676,
      "grad_norm": 0.026819774881005287,
      "learning_rate": 3.0271354211110166e-05,
      "loss": 0.0025,
      "step": 46240
    },
    {
      "epoch": 3.9465824729072447,
      "grad_norm": 0.20614075660705566,
      "learning_rate": 3.0267087635463776e-05,
      "loss": 0.0017,
      "step": 46250
    },
    {
      "epoch": 3.947435788036522,
      "grad_norm": 0.14985492825508118,
      "learning_rate": 3.026282105981739e-05,
      "loss": 0.0028,
      "step": 46260
    },
    {
      "epoch": 3.9482891031657994,
      "grad_norm": 0.24400709569454193,
      "learning_rate": 3.0258554484171005e-05,
      "loss": 0.0013,
      "step": 46270
    },
    {
      "epoch": 3.9491424182950765,
      "grad_norm": 0.3191641569137573,
      "learning_rate": 3.025428790852462e-05,
      "loss": 0.0021,
      "step": 46280
    },
    {
      "epoch": 3.9499957334243536,
      "grad_norm": 0.04250701889395714,
      "learning_rate": 3.025002133287823e-05,
      "loss": 0.0018,
      "step": 46290
    },
    {
      "epoch": 3.9508490485536307,
      "grad_norm": 0.22697512805461884,
      "learning_rate": 3.0245754757231848e-05,
      "loss": 0.0022,
      "step": 46300
    },
    {
      "epoch": 3.951702363682908,
      "grad_norm": 0.13210727274417877,
      "learning_rate": 3.024148818158546e-05,
      "loss": 0.0022,
      "step": 46310
    },
    {
      "epoch": 3.9525556788121854,
      "grad_norm": 0.42565348744392395,
      "learning_rate": 3.0237221605939076e-05,
      "loss": 0.0023,
      "step": 46320
    },
    {
      "epoch": 3.9534089939414625,
      "grad_norm": 0.0312295313924551,
      "learning_rate": 3.0232955030292687e-05,
      "loss": 0.0025,
      "step": 46330
    },
    {
      "epoch": 3.9542623090707396,
      "grad_norm": 0.13080573081970215,
      "learning_rate": 3.0228688454646305e-05,
      "loss": 0.0018,
      "step": 46340
    },
    {
      "epoch": 3.955115624200017,
      "grad_norm": 0.26112252473831177,
      "learning_rate": 3.0224421878999915e-05,
      "loss": 0.0019,
      "step": 46350
    },
    {
      "epoch": 3.9559689393292943,
      "grad_norm": 0.21083256602287292,
      "learning_rate": 3.022015530335353e-05,
      "loss": 0.0024,
      "step": 46360
    },
    {
      "epoch": 3.9568222544585714,
      "grad_norm": 0.16933675110340118,
      "learning_rate": 3.0215888727707144e-05,
      "loss": 0.0022,
      "step": 46370
    },
    {
      "epoch": 3.957675569587849,
      "grad_norm": 0.1003197580575943,
      "learning_rate": 3.0211622152060758e-05,
      "loss": 0.0021,
      "step": 46380
    },
    {
      "epoch": 3.958528884717126,
      "grad_norm": 0.41643011569976807,
      "learning_rate": 3.020735557641437e-05,
      "loss": 0.0018,
      "step": 46390
    },
    {
      "epoch": 3.959382199846403,
      "grad_norm": 0.2077777087688446,
      "learning_rate": 3.0203089000767987e-05,
      "loss": 0.0023,
      "step": 46400
    },
    {
      "epoch": 3.9602355149756807,
      "grad_norm": 0.355948269367218,
      "learning_rate": 3.0198822425121597e-05,
      "loss": 0.0018,
      "step": 46410
    },
    {
      "epoch": 3.961088830104958,
      "grad_norm": 0.20775054395198822,
      "learning_rate": 3.0194555849475215e-05,
      "loss": 0.0017,
      "step": 46420
    },
    {
      "epoch": 3.961942145234235,
      "grad_norm": 0.24871079623699188,
      "learning_rate": 3.0190289273828826e-05,
      "loss": 0.0019,
      "step": 46430
    },
    {
      "epoch": 3.9627954603635125,
      "grad_norm": 0.31467586755752563,
      "learning_rate": 3.0186022698182444e-05,
      "loss": 0.0021,
      "step": 46440
    },
    {
      "epoch": 3.9636487754927896,
      "grad_norm": 0.3430071175098419,
      "learning_rate": 3.0181756122536054e-05,
      "loss": 0.002,
      "step": 46450
    },
    {
      "epoch": 3.9645020906220667,
      "grad_norm": 0.13963881134986877,
      "learning_rate": 3.017748954688967e-05,
      "loss": 0.0015,
      "step": 46460
    },
    {
      "epoch": 3.965355405751344,
      "grad_norm": 0.29514867067337036,
      "learning_rate": 3.0173222971243283e-05,
      "loss": 0.0021,
      "step": 46470
    },
    {
      "epoch": 3.9662087208806214,
      "grad_norm": 0.38918083906173706,
      "learning_rate": 3.0168956395596897e-05,
      "loss": 0.0025,
      "step": 46480
    },
    {
      "epoch": 3.9670620360098985,
      "grad_norm": 0.245888814330101,
      "learning_rate": 3.0164689819950508e-05,
      "loss": 0.0016,
      "step": 46490
    },
    {
      "epoch": 3.9679153511391756,
      "grad_norm": 0.28044912219047546,
      "learning_rate": 3.0160423244304126e-05,
      "loss": 0.0018,
      "step": 46500
    },
    {
      "epoch": 3.9687686662684527,
      "grad_norm": 0.09352384507656097,
      "learning_rate": 3.0156156668657736e-05,
      "loss": 0.002,
      "step": 46510
    },
    {
      "epoch": 3.9696219813977303,
      "grad_norm": 0.13347366452217102,
      "learning_rate": 3.0151890093011347e-05,
      "loss": 0.0018,
      "step": 46520
    },
    {
      "epoch": 3.9704752965270074,
      "grad_norm": 0.2573758065700531,
      "learning_rate": 3.0147623517364965e-05,
      "loss": 0.0015,
      "step": 46530
    },
    {
      "epoch": 3.9713286116562845,
      "grad_norm": 0.09435359388589859,
      "learning_rate": 3.0143356941718576e-05,
      "loss": 0.0025,
      "step": 46540
    },
    {
      "epoch": 3.972181926785562,
      "grad_norm": 0.2561105191707611,
      "learning_rate": 3.0139090366072193e-05,
      "loss": 0.0018,
      "step": 46550
    },
    {
      "epoch": 3.973035241914839,
      "grad_norm": 0.16202795505523682,
      "learning_rate": 3.0134823790425804e-05,
      "loss": 0.0017,
      "step": 46560
    },
    {
      "epoch": 3.9738885570441163,
      "grad_norm": 0.11879149824380875,
      "learning_rate": 3.013055721477942e-05,
      "loss": 0.002,
      "step": 46570
    },
    {
      "epoch": 3.974741872173394,
      "grad_norm": 0.2509382367134094,
      "learning_rate": 3.0126290639133033e-05,
      "loss": 0.0019,
      "step": 46580
    },
    {
      "epoch": 3.975595187302671,
      "grad_norm": 0.4634701907634735,
      "learning_rate": 3.0122024063486647e-05,
      "loss": 0.0018,
      "step": 46590
    },
    {
      "epoch": 3.976448502431948,
      "grad_norm": 0.46203988790512085,
      "learning_rate": 3.0117757487840258e-05,
      "loss": 0.0014,
      "step": 46600
    },
    {
      "epoch": 3.9773018175612256,
      "grad_norm": 0.042060043662786484,
      "learning_rate": 3.0113490912193876e-05,
      "loss": 0.0017,
      "step": 46610
    },
    {
      "epoch": 3.9781551326905027,
      "grad_norm": 0.42288368940353394,
      "learning_rate": 3.0109224336547486e-05,
      "loss": 0.0022,
      "step": 46620
    },
    {
      "epoch": 3.97900844781978,
      "grad_norm": 0.4483549892902374,
      "learning_rate": 3.0104957760901104e-05,
      "loss": 0.0021,
      "step": 46630
    },
    {
      "epoch": 3.9798617629490574,
      "grad_norm": 0.18729455769062042,
      "learning_rate": 3.0100691185254715e-05,
      "loss": 0.002,
      "step": 46640
    },
    {
      "epoch": 3.9807150780783345,
      "grad_norm": 0.2903200685977936,
      "learning_rate": 3.0096424609608332e-05,
      "loss": 0.0016,
      "step": 46650
    },
    {
      "epoch": 3.9815683932076116,
      "grad_norm": 0.13109023869037628,
      "learning_rate": 3.0092158033961943e-05,
      "loss": 0.0015,
      "step": 46660
    },
    {
      "epoch": 3.9824217083368887,
      "grad_norm": 0.037330884486436844,
      "learning_rate": 3.0087891458315558e-05,
      "loss": 0.0018,
      "step": 46670
    },
    {
      "epoch": 3.983275023466166,
      "grad_norm": 0.2904987335205078,
      "learning_rate": 3.0083624882669172e-05,
      "loss": 0.0021,
      "step": 46680
    },
    {
      "epoch": 3.9841283385954434,
      "grad_norm": 0.3316921293735504,
      "learning_rate": 3.0079358307022786e-05,
      "loss": 0.0019,
      "step": 46690
    },
    {
      "epoch": 3.9849816537247205,
      "grad_norm": 0.34933197498321533,
      "learning_rate": 3.0075091731376397e-05,
      "loss": 0.0018,
      "step": 46700
    },
    {
      "epoch": 3.9858349688539976,
      "grad_norm": 0.21523113548755646,
      "learning_rate": 3.0070825155730015e-05,
      "loss": 0.0022,
      "step": 46710
    },
    {
      "epoch": 3.986688283983275,
      "grad_norm": 0.09647045284509659,
      "learning_rate": 3.0066558580083625e-05,
      "loss": 0.002,
      "step": 46720
    },
    {
      "epoch": 3.9875415991125522,
      "grad_norm": 0.22895747423171997,
      "learning_rate": 3.0062292004437243e-05,
      "loss": 0.002,
      "step": 46730
    },
    {
      "epoch": 3.9883949142418293,
      "grad_norm": 0.17378240823745728,
      "learning_rate": 3.0058025428790854e-05,
      "loss": 0.0021,
      "step": 46740
    },
    {
      "epoch": 3.989248229371107,
      "grad_norm": 0.3583413362503052,
      "learning_rate": 3.005375885314447e-05,
      "loss": 0.0024,
      "step": 46750
    },
    {
      "epoch": 3.990101544500384,
      "grad_norm": 0.09853953868150711,
      "learning_rate": 3.0049492277498082e-05,
      "loss": 0.002,
      "step": 46760
    },
    {
      "epoch": 3.990954859629661,
      "grad_norm": 0.04699190333485603,
      "learning_rate": 3.0045225701851693e-05,
      "loss": 0.0019,
      "step": 46770
    },
    {
      "epoch": 3.9918081747589387,
      "grad_norm": 0.4294341802597046,
      "learning_rate": 3.004095912620531e-05,
      "loss": 0.002,
      "step": 46780
    },
    {
      "epoch": 3.992661489888216,
      "grad_norm": 0.2804444432258606,
      "learning_rate": 3.003669255055892e-05,
      "loss": 0.0015,
      "step": 46790
    },
    {
      "epoch": 3.993514805017493,
      "grad_norm": 0.08268434554338455,
      "learning_rate": 3.0032425974912536e-05,
      "loss": 0.0021,
      "step": 46800
    },
    {
      "epoch": 3.9943681201467705,
      "grad_norm": 0.15224432945251465,
      "learning_rate": 3.0028159399266147e-05,
      "loss": 0.0022,
      "step": 46810
    },
    {
      "epoch": 3.9952214352760476,
      "grad_norm": 0.24587811529636383,
      "learning_rate": 3.0023892823619764e-05,
      "loss": 0.0026,
      "step": 46820
    },
    {
      "epoch": 3.9960747504053247,
      "grad_norm": 0.27905985713005066,
      "learning_rate": 3.0019626247973375e-05,
      "loss": 0.0019,
      "step": 46830
    },
    {
      "epoch": 3.996928065534602,
      "grad_norm": 0.13557317852973938,
      "learning_rate": 3.0015359672326993e-05,
      "loss": 0.0016,
      "step": 46840
    },
    {
      "epoch": 3.9977813806638793,
      "grad_norm": 0.11339346319437027,
      "learning_rate": 3.0011093096680604e-05,
      "loss": 0.0022,
      "step": 46850
    },
    {
      "epoch": 3.9986346957931564,
      "grad_norm": 0.14672386646270752,
      "learning_rate": 3.000682652103422e-05,
      "loss": 0.002,
      "step": 46860
    },
    {
      "epoch": 3.9994880109224336,
      "grad_norm": 0.2796792984008789,
      "learning_rate": 3.0002559945387832e-05,
      "loss": 0.0021,
      "step": 46870
    },
    {
      "epoch": 4.0,
      "eval_loss": 0.002039511688053608,
      "eval_runtime": 100.8989,
      "eval_samples_per_second": 1486.636,
      "eval_steps_per_second": 23.231,
      "step": 46876
    },
    {
      "epoch": 4.000341326051711,
      "grad_norm": 0.3225826621055603,
      "learning_rate": 2.9998293369741446e-05,
      "loss": 0.002,
      "step": 46880
    },
    {
      "epoch": 4.001194641180988,
      "grad_norm": 0.22357790172100067,
      "learning_rate": 2.999402679409506e-05,
      "loss": 0.002,
      "step": 46890
    },
    {
      "epoch": 4.002047956310266,
      "grad_norm": 0.13347648084163666,
      "learning_rate": 2.9989760218448675e-05,
      "loss": 0.0014,
      "step": 46900
    },
    {
      "epoch": 4.002901271439542,
      "grad_norm": 0.11706611514091492,
      "learning_rate": 2.9985493642802286e-05,
      "loss": 0.0016,
      "step": 46910
    },
    {
      "epoch": 4.00375458656882,
      "grad_norm": 0.37065058946609497,
      "learning_rate": 2.9981227067155903e-05,
      "loss": 0.0017,
      "step": 46920
    },
    {
      "epoch": 4.0046079016980975,
      "grad_norm": 0.049810752272605896,
      "learning_rate": 2.9976960491509514e-05,
      "loss": 0.002,
      "step": 46930
    },
    {
      "epoch": 4.005461216827374,
      "grad_norm": 0.061001308262348175,
      "learning_rate": 2.9972693915863132e-05,
      "loss": 0.0017,
      "step": 46940
    },
    {
      "epoch": 4.006314531956652,
      "grad_norm": 0.406019002199173,
      "learning_rate": 2.9968427340216743e-05,
      "loss": 0.0021,
      "step": 46950
    },
    {
      "epoch": 4.007167847085928,
      "grad_norm": 0.4818292260169983,
      "learning_rate": 2.996416076457036e-05,
      "loss": 0.002,
      "step": 46960
    },
    {
      "epoch": 4.008021162215206,
      "grad_norm": 0.21074934303760529,
      "learning_rate": 2.995989418892397e-05,
      "loss": 0.0012,
      "step": 46970
    },
    {
      "epoch": 4.0088744773444835,
      "grad_norm": 0.35377970337867737,
      "learning_rate": 2.9955627613277585e-05,
      "loss": 0.0024,
      "step": 46980
    },
    {
      "epoch": 4.00972779247376,
      "grad_norm": 0.2721223831176758,
      "learning_rate": 2.99513610376312e-05,
      "loss": 0.0018,
      "step": 46990
    },
    {
      "epoch": 4.010581107603038,
      "grad_norm": 0.2439517378807068,
      "learning_rate": 2.9947094461984814e-05,
      "loss": 0.0017,
      "step": 47000
    },
    {
      "epoch": 4.011434422732315,
      "grad_norm": 0.060820769518613815,
      "learning_rate": 2.9942827886338425e-05,
      "loss": 0.0022,
      "step": 47010
    },
    {
      "epoch": 4.012287737861592,
      "grad_norm": 0.2859135568141937,
      "learning_rate": 2.9938561310692042e-05,
      "loss": 0.0024,
      "step": 47020
    },
    {
      "epoch": 4.0131410529908695,
      "grad_norm": 0.04247000813484192,
      "learning_rate": 2.9934294735045653e-05,
      "loss": 0.0023,
      "step": 47030
    },
    {
      "epoch": 4.013994368120147,
      "grad_norm": 0.3608146905899048,
      "learning_rate": 2.9930028159399264e-05,
      "loss": 0.0015,
      "step": 47040
    },
    {
      "epoch": 4.014847683249424,
      "grad_norm": 0.24053102731704712,
      "learning_rate": 2.9925761583752882e-05,
      "loss": 0.0018,
      "step": 47050
    },
    {
      "epoch": 4.015700998378701,
      "grad_norm": 0.12468647211790085,
      "learning_rate": 2.9921495008106493e-05,
      "loss": 0.002,
      "step": 47060
    },
    {
      "epoch": 4.016554313507979,
      "grad_norm": 0.12697693705558777,
      "learning_rate": 2.991722843246011e-05,
      "loss": 0.0018,
      "step": 47070
    },
    {
      "epoch": 4.0174076286372555,
      "grad_norm": 0.3677853047847748,
      "learning_rate": 2.991296185681372e-05,
      "loss": 0.0021,
      "step": 47080
    },
    {
      "epoch": 4.018260943766533,
      "grad_norm": 0.35414832830429077,
      "learning_rate": 2.990869528116734e-05,
      "loss": 0.002,
      "step": 47090
    },
    {
      "epoch": 4.019114258895811,
      "grad_norm": 0.29252055287361145,
      "learning_rate": 2.990442870552095e-05,
      "loss": 0.0019,
      "step": 47100
    },
    {
      "epoch": 4.019967574025087,
      "grad_norm": 0.05043727159500122,
      "learning_rate": 2.9900162129874564e-05,
      "loss": 0.0024,
      "step": 47110
    },
    {
      "epoch": 4.020820889154365,
      "grad_norm": 0.23123760521411896,
      "learning_rate": 2.9895895554228175e-05,
      "loss": 0.0013,
      "step": 47120
    },
    {
      "epoch": 4.0216742042836415,
      "grad_norm": 0.3455864191055298,
      "learning_rate": 2.9891628978581792e-05,
      "loss": 0.0023,
      "step": 47130
    },
    {
      "epoch": 4.022527519412919,
      "grad_norm": 0.323915958404541,
      "learning_rate": 2.9887362402935403e-05,
      "loss": 0.0019,
      "step": 47140
    },
    {
      "epoch": 4.023380834542197,
      "grad_norm": 0.2658218443393707,
      "learning_rate": 2.988309582728902e-05,
      "loss": 0.0016,
      "step": 47150
    },
    {
      "epoch": 4.024234149671473,
      "grad_norm": 0.349621444940567,
      "learning_rate": 2.987882925164263e-05,
      "loss": 0.0022,
      "step": 47160
    },
    {
      "epoch": 4.025087464800751,
      "grad_norm": 0.1878061145544052,
      "learning_rate": 2.987456267599625e-05,
      "loss": 0.0022,
      "step": 47170
    },
    {
      "epoch": 4.025940779930028,
      "grad_norm": 0.09807322919368744,
      "learning_rate": 2.987029610034986e-05,
      "loss": 0.002,
      "step": 47180
    },
    {
      "epoch": 4.026794095059305,
      "grad_norm": 0.03444967791438103,
      "learning_rate": 2.9866029524703474e-05,
      "loss": 0.0021,
      "step": 47190
    },
    {
      "epoch": 4.027647410188583,
      "grad_norm": 0.13074041903018951,
      "learning_rate": 2.986176294905709e-05,
      "loss": 0.0017,
      "step": 47200
    },
    {
      "epoch": 4.02850072531786,
      "grad_norm": 0.09498992562294006,
      "learning_rate": 2.9857496373410703e-05,
      "loss": 0.0016,
      "step": 47210
    },
    {
      "epoch": 4.029354040447137,
      "grad_norm": 0.24138407409191132,
      "learning_rate": 2.9853229797764314e-05,
      "loss": 0.0022,
      "step": 47220
    },
    {
      "epoch": 4.030207355576414,
      "grad_norm": 0.22565913200378418,
      "learning_rate": 2.984896322211793e-05,
      "loss": 0.0019,
      "step": 47230
    },
    {
      "epoch": 4.031060670705692,
      "grad_norm": 0.11294077336788177,
      "learning_rate": 2.9844696646471542e-05,
      "loss": 0.0026,
      "step": 47240
    },
    {
      "epoch": 4.031913985834969,
      "grad_norm": 0.22705501317977905,
      "learning_rate": 2.984043007082516e-05,
      "loss": 0.0017,
      "step": 47250
    },
    {
      "epoch": 4.032767300964246,
      "grad_norm": 0.07986460626125336,
      "learning_rate": 2.983616349517877e-05,
      "loss": 0.0019,
      "step": 47260
    },
    {
      "epoch": 4.033620616093524,
      "grad_norm": 0.050921570509672165,
      "learning_rate": 2.9831896919532388e-05,
      "loss": 0.0017,
      "step": 47270
    },
    {
      "epoch": 4.0344739312228,
      "grad_norm": 0.08203839510679245,
      "learning_rate": 2.9827630343886e-05,
      "loss": 0.0017,
      "step": 47280
    },
    {
      "epoch": 4.035327246352078,
      "grad_norm": 0.18552763760089874,
      "learning_rate": 2.9823363768239613e-05,
      "loss": 0.0019,
      "step": 47290
    },
    {
      "epoch": 4.0361805614813555,
      "grad_norm": 0.2966850697994232,
      "learning_rate": 2.9819097192593228e-05,
      "loss": 0.0018,
      "step": 47300
    },
    {
      "epoch": 4.037033876610632,
      "grad_norm": 0.18191863596439362,
      "learning_rate": 2.981483061694684e-05,
      "loss": 0.0023,
      "step": 47310
    },
    {
      "epoch": 4.03788719173991,
      "grad_norm": 0.13115094602108002,
      "learning_rate": 2.9810564041300453e-05,
      "loss": 0.0021,
      "step": 47320
    },
    {
      "epoch": 4.038740506869186,
      "grad_norm": 0.4348902404308319,
      "learning_rate": 2.9806297465654064e-05,
      "loss": 0.0025,
      "step": 47330
    },
    {
      "epoch": 4.039593821998464,
      "grad_norm": 0.12971866130828857,
      "learning_rate": 2.980203089000768e-05,
      "loss": 0.0019,
      "step": 47340
    },
    {
      "epoch": 4.0404471371277415,
      "grad_norm": 0.11806300282478333,
      "learning_rate": 2.9797764314361292e-05,
      "loss": 0.0016,
      "step": 47350
    },
    {
      "epoch": 4.041300452257018,
      "grad_norm": 0.16499699652194977,
      "learning_rate": 2.979349773871491e-05,
      "loss": 0.0023,
      "step": 47360
    },
    {
      "epoch": 4.042153767386296,
      "grad_norm": 0.7574304938316345,
      "learning_rate": 2.978923116306852e-05,
      "loss": 0.0017,
      "step": 47370
    },
    {
      "epoch": 4.043007082515573,
      "grad_norm": 0.06452072411775589,
      "learning_rate": 2.9784964587422138e-05,
      "loss": 0.0017,
      "step": 47380
    },
    {
      "epoch": 4.04386039764485,
      "grad_norm": 0.0915408805012703,
      "learning_rate": 2.978069801177575e-05,
      "loss": 0.0017,
      "step": 47390
    },
    {
      "epoch": 4.0447137127741275,
      "grad_norm": 0.169509157538414,
      "learning_rate": 2.9776431436129367e-05,
      "loss": 0.002,
      "step": 47400
    },
    {
      "epoch": 4.045567027903405,
      "grad_norm": 0.06818179786205292,
      "learning_rate": 2.9772164860482978e-05,
      "loss": 0.0021,
      "step": 47410
    },
    {
      "epoch": 4.046420343032682,
      "grad_norm": 0.1162068247795105,
      "learning_rate": 2.9767898284836592e-05,
      "loss": 0.0016,
      "step": 47420
    },
    {
      "epoch": 4.047273658161959,
      "grad_norm": 0.17420095205307007,
      "learning_rate": 2.9763631709190203e-05,
      "loss": 0.0022,
      "step": 47430
    },
    {
      "epoch": 4.048126973291237,
      "grad_norm": 0.2630229592323303,
      "learning_rate": 2.975936513354382e-05,
      "loss": 0.0016,
      "step": 47440
    },
    {
      "epoch": 4.0489802884205135,
      "grad_norm": 0.3348645567893982,
      "learning_rate": 2.975509855789743e-05,
      "loss": 0.0021,
      "step": 47450
    },
    {
      "epoch": 4.049833603549791,
      "grad_norm": 0.03402126953005791,
      "learning_rate": 2.975083198225105e-05,
      "loss": 0.0016,
      "step": 47460
    },
    {
      "epoch": 4.050686918679069,
      "grad_norm": 0.2014978528022766,
      "learning_rate": 2.974656540660466e-05,
      "loss": 0.0022,
      "step": 47470
    },
    {
      "epoch": 4.051540233808345,
      "grad_norm": 0.11365604400634766,
      "learning_rate": 2.9742298830958277e-05,
      "loss": 0.0019,
      "step": 47480
    },
    {
      "epoch": 4.052393548937623,
      "grad_norm": 0.3681466281414032,
      "learning_rate": 2.9738032255311888e-05,
      "loss": 0.0018,
      "step": 47490
    },
    {
      "epoch": 4.0532468640668995,
      "grad_norm": 0.5018846392631531,
      "learning_rate": 2.9733765679665502e-05,
      "loss": 0.0018,
      "step": 47500
    },
    {
      "epoch": 4.054100179196177,
      "grad_norm": 0.12831564247608185,
      "learning_rate": 2.9729499104019117e-05,
      "loss": 0.002,
      "step": 47510
    },
    {
      "epoch": 4.054953494325455,
      "grad_norm": 0.2798458933830261,
      "learning_rate": 2.972523252837273e-05,
      "loss": 0.0021,
      "step": 47520
    },
    {
      "epoch": 4.055806809454731,
      "grad_norm": 0.298640638589859,
      "learning_rate": 2.972096595272634e-05,
      "loss": 0.0021,
      "step": 47530
    },
    {
      "epoch": 4.056660124584009,
      "grad_norm": 0.06995739787817001,
      "learning_rate": 2.971669937707996e-05,
      "loss": 0.002,
      "step": 47540
    },
    {
      "epoch": 4.057513439713286,
      "grad_norm": 0.11345293372869492,
      "learning_rate": 2.971243280143357e-05,
      "loss": 0.0019,
      "step": 47550
    },
    {
      "epoch": 4.058366754842563,
      "grad_norm": 0.033322080969810486,
      "learning_rate": 2.9708166225787188e-05,
      "loss": 0.0021,
      "step": 47560
    },
    {
      "epoch": 4.059220069971841,
      "grad_norm": 0.07852502167224884,
      "learning_rate": 2.97038996501408e-05,
      "loss": 0.0018,
      "step": 47570
    },
    {
      "epoch": 4.060073385101118,
      "grad_norm": 0.27813243865966797,
      "learning_rate": 2.969963307449441e-05,
      "loss": 0.0025,
      "step": 47580
    },
    {
      "epoch": 4.060926700230395,
      "grad_norm": 0.13848692178726196,
      "learning_rate": 2.9695366498848027e-05,
      "loss": 0.0022,
      "step": 47590
    },
    {
      "epoch": 4.061780015359672,
      "grad_norm": 0.18826645612716675,
      "learning_rate": 2.9691099923201638e-05,
      "loss": 0.002,
      "step": 47600
    },
    {
      "epoch": 4.06263333048895,
      "grad_norm": 0.5672967433929443,
      "learning_rate": 2.9686833347555256e-05,
      "loss": 0.0022,
      "step": 47610
    },
    {
      "epoch": 4.063486645618227,
      "grad_norm": 0.06222740188241005,
      "learning_rate": 2.9682566771908866e-05,
      "loss": 0.0017,
      "step": 47620
    },
    {
      "epoch": 4.064339960747504,
      "grad_norm": 0.05687662959098816,
      "learning_rate": 2.967830019626248e-05,
      "loss": 0.0019,
      "step": 47630
    },
    {
      "epoch": 4.065193275876782,
      "grad_norm": 0.20883245766162872,
      "learning_rate": 2.967403362061609e-05,
      "loss": 0.0017,
      "step": 47640
    },
    {
      "epoch": 4.066046591006058,
      "grad_norm": 0.35878315567970276,
      "learning_rate": 2.966976704496971e-05,
      "loss": 0.002,
      "step": 47650
    },
    {
      "epoch": 4.066899906135336,
      "grad_norm": 0.09904702752828598,
      "learning_rate": 2.966550046932332e-05,
      "loss": 0.0022,
      "step": 47660
    },
    {
      "epoch": 4.0677532212646135,
      "grad_norm": 0.3163253366947174,
      "learning_rate": 2.9661233893676938e-05,
      "loss": 0.0017,
      "step": 47670
    },
    {
      "epoch": 4.06860653639389,
      "grad_norm": 0.1323184072971344,
      "learning_rate": 2.965696731803055e-05,
      "loss": 0.002,
      "step": 47680
    },
    {
      "epoch": 4.069459851523168,
      "grad_norm": 0.5958701968193054,
      "learning_rate": 2.9652700742384166e-05,
      "loss": 0.0024,
      "step": 47690
    },
    {
      "epoch": 4.070313166652444,
      "grad_norm": 0.19121842086315155,
      "learning_rate": 2.9648434166737777e-05,
      "loss": 0.0021,
      "step": 47700
    },
    {
      "epoch": 4.071166481781722,
      "grad_norm": 0.06277163326740265,
      "learning_rate": 2.9644167591091395e-05,
      "loss": 0.0019,
      "step": 47710
    },
    {
      "epoch": 4.0720197969109995,
      "grad_norm": 0.2882668972015381,
      "learning_rate": 2.9639901015445005e-05,
      "loss": 0.0032,
      "step": 47720
    },
    {
      "epoch": 4.072873112040276,
      "grad_norm": 0.18488003313541412,
      "learning_rate": 2.963563443979862e-05,
      "loss": 0.0016,
      "step": 47730
    },
    {
      "epoch": 4.073726427169554,
      "grad_norm": 0.07508663833141327,
      "learning_rate": 2.963136786415223e-05,
      "loss": 0.002,
      "step": 47740
    },
    {
      "epoch": 4.074579742298831,
      "grad_norm": 0.2031722068786621,
      "learning_rate": 2.9627101288505848e-05,
      "loss": 0.0021,
      "step": 47750
    },
    {
      "epoch": 4.075433057428108,
      "grad_norm": 0.25904515385627747,
      "learning_rate": 2.962283471285946e-05,
      "loss": 0.0015,
      "step": 47760
    },
    {
      "epoch": 4.0762863725573855,
      "grad_norm": 0.33832699060440063,
      "learning_rate": 2.9618568137213077e-05,
      "loss": 0.002,
      "step": 47770
    },
    {
      "epoch": 4.077139687686663,
      "grad_norm": 0.11532182991504669,
      "learning_rate": 2.9614301561566687e-05,
      "loss": 0.0016,
      "step": 47780
    },
    {
      "epoch": 4.07799300281594,
      "grad_norm": 0.1154167428612709,
      "learning_rate": 2.9610034985920305e-05,
      "loss": 0.0014,
      "step": 47790
    },
    {
      "epoch": 4.078846317945217,
      "grad_norm": 0.08147767186164856,
      "learning_rate": 2.9605768410273916e-05,
      "loss": 0.002,
      "step": 47800
    },
    {
      "epoch": 4.079699633074495,
      "grad_norm": 0.05523115396499634,
      "learning_rate": 2.9601501834627534e-05,
      "loss": 0.0021,
      "step": 47810
    },
    {
      "epoch": 4.0805529482037715,
      "grad_norm": 0.17206934094429016,
      "learning_rate": 2.9597235258981144e-05,
      "loss": 0.0016,
      "step": 47820
    },
    {
      "epoch": 4.081406263333049,
      "grad_norm": 0.07695849239826202,
      "learning_rate": 2.959296868333476e-05,
      "loss": 0.002,
      "step": 47830
    },
    {
      "epoch": 4.082259578462327,
      "grad_norm": 0.24302639067173004,
      "learning_rate": 2.958870210768837e-05,
      "loss": 0.0023,
      "step": 47840
    },
    {
      "epoch": 4.083112893591603,
      "grad_norm": 0.2464865744113922,
      "learning_rate": 2.958443553204198e-05,
      "loss": 0.0018,
      "step": 47850
    },
    {
      "epoch": 4.083966208720881,
      "grad_norm": 0.03170742467045784,
      "learning_rate": 2.9580168956395598e-05,
      "loss": 0.0016,
      "step": 47860
    },
    {
      "epoch": 4.0848195238501575,
      "grad_norm": 0.35093459486961365,
      "learning_rate": 2.957590238074921e-05,
      "loss": 0.0019,
      "step": 47870
    },
    {
      "epoch": 4.085672838979435,
      "grad_norm": 0.3397102653980255,
      "learning_rate": 2.9571635805102827e-05,
      "loss": 0.0018,
      "step": 47880
    },
    {
      "epoch": 4.086526154108713,
      "grad_norm": 0.12375756353139877,
      "learning_rate": 2.9567369229456437e-05,
      "loss": 0.0022,
      "step": 47890
    },
    {
      "epoch": 4.087379469237989,
      "grad_norm": 0.5669605731964111,
      "learning_rate": 2.9563102653810055e-05,
      "loss": 0.0018,
      "step": 47900
    },
    {
      "epoch": 4.088232784367267,
      "grad_norm": 0.09739000350236893,
      "learning_rate": 2.9558836078163666e-05,
      "loss": 0.0014,
      "step": 47910
    },
    {
      "epoch": 4.089086099496544,
      "grad_norm": 0.3536650538444519,
      "learning_rate": 2.9554569502517283e-05,
      "loss": 0.0022,
      "step": 47920
    },
    {
      "epoch": 4.089939414625821,
      "grad_norm": 0.13990359008312225,
      "learning_rate": 2.9550302926870894e-05,
      "loss": 0.0019,
      "step": 47930
    },
    {
      "epoch": 4.0907927297550986,
      "grad_norm": 0.12753985822200775,
      "learning_rate": 2.954603635122451e-05,
      "loss": 0.002,
      "step": 47940
    },
    {
      "epoch": 4.091646044884376,
      "grad_norm": 0.39070597290992737,
      "learning_rate": 2.954176977557812e-05,
      "loss": 0.0024,
      "step": 47950
    },
    {
      "epoch": 4.092499360013653,
      "grad_norm": 0.16172565519809723,
      "learning_rate": 2.9537503199931737e-05,
      "loss": 0.002,
      "step": 47960
    },
    {
      "epoch": 4.09335267514293,
      "grad_norm": 0.16409149765968323,
      "learning_rate": 2.9533236624285348e-05,
      "loss": 0.0019,
      "step": 47970
    },
    {
      "epoch": 4.094205990272208,
      "grad_norm": 0.2779218554496765,
      "learning_rate": 2.9528970048638966e-05,
      "loss": 0.0019,
      "step": 47980
    },
    {
      "epoch": 4.0950593054014846,
      "grad_norm": 0.09696343541145325,
      "learning_rate": 2.9524703472992576e-05,
      "loss": 0.0017,
      "step": 47990
    },
    {
      "epoch": 4.095912620530762,
      "grad_norm": 0.33094993233680725,
      "learning_rate": 2.9520436897346194e-05,
      "loss": 0.0024,
      "step": 48000
    },
    {
      "epoch": 4.09676593566004,
      "grad_norm": 0.15086835622787476,
      "learning_rate": 2.9516170321699805e-05,
      "loss": 0.0018,
      "step": 48010
    },
    {
      "epoch": 4.097619250789316,
      "grad_norm": 0.09617843478918076,
      "learning_rate": 2.9511903746053422e-05,
      "loss": 0.0022,
      "step": 48020
    },
    {
      "epoch": 4.098472565918594,
      "grad_norm": 0.09817221015691757,
      "learning_rate": 2.9507637170407033e-05,
      "loss": 0.0018,
      "step": 48030
    },
    {
      "epoch": 4.0993258810478705,
      "grad_norm": 0.08027330040931702,
      "learning_rate": 2.9503370594760648e-05,
      "loss": 0.0014,
      "step": 48040
    },
    {
      "epoch": 4.100179196177148,
      "grad_norm": 0.02796335518360138,
      "learning_rate": 2.949910401911426e-05,
      "loss": 0.0018,
      "step": 48050
    },
    {
      "epoch": 4.101032511306426,
      "grad_norm": 0.18559066951274872,
      "learning_rate": 2.9494837443467876e-05,
      "loss": 0.002,
      "step": 48060
    },
    {
      "epoch": 4.101885826435702,
      "grad_norm": 0.13219693303108215,
      "learning_rate": 2.9490570867821487e-05,
      "loss": 0.0018,
      "step": 48070
    },
    {
      "epoch": 4.10273914156498,
      "grad_norm": 0.25750482082366943,
      "learning_rate": 2.9486304292175105e-05,
      "loss": 0.0028,
      "step": 48080
    },
    {
      "epoch": 4.103592456694257,
      "grad_norm": 0.1701963245868683,
      "learning_rate": 2.9482037716528715e-05,
      "loss": 0.0016,
      "step": 48090
    },
    {
      "epoch": 4.104445771823534,
      "grad_norm": 0.0888609066605568,
      "learning_rate": 2.9477771140882326e-05,
      "loss": 0.0016,
      "step": 48100
    },
    {
      "epoch": 4.105299086952812,
      "grad_norm": 0.057694755494594574,
      "learning_rate": 2.9473504565235944e-05,
      "loss": 0.0022,
      "step": 48110
    },
    {
      "epoch": 4.106152402082089,
      "grad_norm": 0.1894451081752777,
      "learning_rate": 2.9469237989589555e-05,
      "loss": 0.0018,
      "step": 48120
    },
    {
      "epoch": 4.107005717211366,
      "grad_norm": 0.058676715940237045,
      "learning_rate": 2.9464971413943172e-05,
      "loss": 0.0017,
      "step": 48130
    },
    {
      "epoch": 4.107859032340643,
      "grad_norm": 0.0596054382622242,
      "learning_rate": 2.9460704838296783e-05,
      "loss": 0.0019,
      "step": 48140
    },
    {
      "epoch": 4.108712347469921,
      "grad_norm": 0.30234113335609436,
      "learning_rate": 2.9456438262650397e-05,
      "loss": 0.0015,
      "step": 48150
    },
    {
      "epoch": 4.109565662599198,
      "grad_norm": 0.02873420901596546,
      "learning_rate": 2.945217168700401e-05,
      "loss": 0.0018,
      "step": 48160
    },
    {
      "epoch": 4.110418977728475,
      "grad_norm": 0.06523830443620682,
      "learning_rate": 2.9447905111357626e-05,
      "loss": 0.0014,
      "step": 48170
    },
    {
      "epoch": 4.111272292857753,
      "grad_norm": 0.3887329697608948,
      "learning_rate": 2.9443638535711237e-05,
      "loss": 0.0024,
      "step": 48180
    },
    {
      "epoch": 4.112125607987029,
      "grad_norm": 0.09477172791957855,
      "learning_rate": 2.9439371960064854e-05,
      "loss": 0.0022,
      "step": 48190
    },
    {
      "epoch": 4.112978923116307,
      "grad_norm": 0.34410855174064636,
      "learning_rate": 2.9435105384418465e-05,
      "loss": 0.0014,
      "step": 48200
    },
    {
      "epoch": 4.1138322382455845,
      "grad_norm": 0.1686977595090866,
      "learning_rate": 2.9430838808772083e-05,
      "loss": 0.0016,
      "step": 48210
    },
    {
      "epoch": 4.114685553374861,
      "grad_norm": 0.09904436022043228,
      "learning_rate": 2.9426572233125694e-05,
      "loss": 0.0017,
      "step": 48220
    },
    {
      "epoch": 4.115538868504139,
      "grad_norm": 0.11399644613265991,
      "learning_rate": 2.942230565747931e-05,
      "loss": 0.0021,
      "step": 48230
    },
    {
      "epoch": 4.116392183633415,
      "grad_norm": 0.18400077521800995,
      "learning_rate": 2.9418039081832922e-05,
      "loss": 0.0017,
      "step": 48240
    },
    {
      "epoch": 4.117245498762693,
      "grad_norm": 0.24694082140922546,
      "learning_rate": 2.9413772506186536e-05,
      "loss": 0.0022,
      "step": 48250
    },
    {
      "epoch": 4.1180988138919705,
      "grad_norm": 0.3755297362804413,
      "learning_rate": 2.9409505930540147e-05,
      "loss": 0.0022,
      "step": 48260
    },
    {
      "epoch": 4.118952129021247,
      "grad_norm": 0.16722612082958221,
      "learning_rate": 2.9405239354893765e-05,
      "loss": 0.0019,
      "step": 48270
    },
    {
      "epoch": 4.119805444150525,
      "grad_norm": 0.07936462014913559,
      "learning_rate": 2.9400972779247376e-05,
      "loss": 0.0018,
      "step": 48280
    },
    {
      "epoch": 4.120658759279802,
      "grad_norm": 0.15968061983585358,
      "learning_rate": 2.9396706203600993e-05,
      "loss": 0.002,
      "step": 48290
    },
    {
      "epoch": 4.121512074409079,
      "grad_norm": 0.11061161011457443,
      "learning_rate": 2.9392439627954604e-05,
      "loss": 0.0014,
      "step": 48300
    },
    {
      "epoch": 4.1223653895383565,
      "grad_norm": 0.11672813445329666,
      "learning_rate": 2.9388173052308222e-05,
      "loss": 0.002,
      "step": 48310
    },
    {
      "epoch": 4.123218704667634,
      "grad_norm": 0.2251788228750229,
      "learning_rate": 2.9383906476661833e-05,
      "loss": 0.0018,
      "step": 48320
    },
    {
      "epoch": 4.124072019796911,
      "grad_norm": 0.34584784507751465,
      "learning_rate": 2.937963990101545e-05,
      "loss": 0.0023,
      "step": 48330
    },
    {
      "epoch": 4.124925334926188,
      "grad_norm": 0.07539478689432144,
      "learning_rate": 2.937537332536906e-05,
      "loss": 0.0022,
      "step": 48340
    },
    {
      "epoch": 4.125778650055466,
      "grad_norm": 0.3230278491973877,
      "learning_rate": 2.9371106749722676e-05,
      "loss": 0.0016,
      "step": 48350
    },
    {
      "epoch": 4.1266319651847425,
      "grad_norm": 0.26787757873535156,
      "learning_rate": 2.9366840174076286e-05,
      "loss": 0.0021,
      "step": 48360
    },
    {
      "epoch": 4.12748528031402,
      "grad_norm": 0.16367055475711823,
      "learning_rate": 2.9362573598429897e-05,
      "loss": 0.0016,
      "step": 48370
    },
    {
      "epoch": 4.128338595443298,
      "grad_norm": 0.1663103848695755,
      "learning_rate": 2.9358307022783515e-05,
      "loss": 0.0017,
      "step": 48380
    },
    {
      "epoch": 4.129191910572574,
      "grad_norm": 0.46357613801956177,
      "learning_rate": 2.9354040447137126e-05,
      "loss": 0.0017,
      "step": 48390
    },
    {
      "epoch": 4.130045225701852,
      "grad_norm": 0.1532820463180542,
      "learning_rate": 2.9349773871490743e-05,
      "loss": 0.0021,
      "step": 48400
    },
    {
      "epoch": 4.1308985408311285,
      "grad_norm": 0.20592282712459564,
      "learning_rate": 2.9345507295844354e-05,
      "loss": 0.0012,
      "step": 48410
    },
    {
      "epoch": 4.131751855960406,
      "grad_norm": 0.14823362231254578,
      "learning_rate": 2.9341240720197972e-05,
      "loss": 0.0016,
      "step": 48420
    },
    {
      "epoch": 4.132605171089684,
      "grad_norm": 0.09552716463804245,
      "learning_rate": 2.9336974144551583e-05,
      "loss": 0.0017,
      "step": 48430
    },
    {
      "epoch": 4.13345848621896,
      "grad_norm": 0.5954551100730896,
      "learning_rate": 2.93327075689052e-05,
      "loss": 0.0023,
      "step": 48440
    },
    {
      "epoch": 4.134311801348238,
      "grad_norm": 0.05005403980612755,
      "learning_rate": 2.932844099325881e-05,
      "loss": 0.0022,
      "step": 48450
    },
    {
      "epoch": 4.135165116477515,
      "grad_norm": 0.18882176280021667,
      "learning_rate": 2.9324174417612425e-05,
      "loss": 0.0018,
      "step": 48460
    },
    {
      "epoch": 4.136018431606792,
      "grad_norm": 0.22109784185886383,
      "learning_rate": 2.9319907841966036e-05,
      "loss": 0.002,
      "step": 48470
    },
    {
      "epoch": 4.13687174673607,
      "grad_norm": 0.24186117947101593,
      "learning_rate": 2.9315641266319654e-05,
      "loss": 0.0019,
      "step": 48480
    },
    {
      "epoch": 4.137725061865347,
      "grad_norm": 0.21763569116592407,
      "learning_rate": 2.9311374690673265e-05,
      "loss": 0.0018,
      "step": 48490
    },
    {
      "epoch": 4.138578376994624,
      "grad_norm": 0.10010529309511185,
      "learning_rate": 2.9307108115026882e-05,
      "loss": 0.0024,
      "step": 48500
    },
    {
      "epoch": 4.139431692123901,
      "grad_norm": 0.19554086029529572,
      "learning_rate": 2.9302841539380493e-05,
      "loss": 0.0015,
      "step": 48510
    },
    {
      "epoch": 4.140285007253179,
      "grad_norm": 0.24086514115333557,
      "learning_rate": 2.929857496373411e-05,
      "loss": 0.0018,
      "step": 48520
    },
    {
      "epoch": 4.141138322382456,
      "grad_norm": 0.20637182891368866,
      "learning_rate": 2.929430838808772e-05,
      "loss": 0.0015,
      "step": 48530
    },
    {
      "epoch": 4.141991637511733,
      "grad_norm": 0.054043784737586975,
      "learning_rate": 2.929004181244134e-05,
      "loss": 0.0017,
      "step": 48540
    },
    {
      "epoch": 4.142844952641011,
      "grad_norm": 0.030074365437030792,
      "learning_rate": 2.928577523679495e-05,
      "loss": 0.0018,
      "step": 48550
    },
    {
      "epoch": 4.143698267770287,
      "grad_norm": 0.15144790709018707,
      "learning_rate": 2.9281508661148564e-05,
      "loss": 0.0024,
      "step": 48560
    },
    {
      "epoch": 4.144551582899565,
      "grad_norm": 0.3164879083633423,
      "learning_rate": 2.9277242085502175e-05,
      "loss": 0.0014,
      "step": 48570
    },
    {
      "epoch": 4.145404898028842,
      "grad_norm": 0.22118669748306274,
      "learning_rate": 2.9272975509855793e-05,
      "loss": 0.002,
      "step": 48580
    },
    {
      "epoch": 4.146258213158119,
      "grad_norm": 0.20745030045509338,
      "learning_rate": 2.9268708934209404e-05,
      "loss": 0.0022,
      "step": 48590
    },
    {
      "epoch": 4.147111528287397,
      "grad_norm": 0.16123633086681366,
      "learning_rate": 2.926444235856302e-05,
      "loss": 0.0019,
      "step": 48600
    },
    {
      "epoch": 4.147964843416673,
      "grad_norm": 0.17999757826328278,
      "learning_rate": 2.9260175782916632e-05,
      "loss": 0.002,
      "step": 48610
    },
    {
      "epoch": 4.148818158545951,
      "grad_norm": 0.2739180624485016,
      "learning_rate": 2.925590920727025e-05,
      "loss": 0.0022,
      "step": 48620
    },
    {
      "epoch": 4.1496714736752285,
      "grad_norm": 0.2192242443561554,
      "learning_rate": 2.925164263162386e-05,
      "loss": 0.0016,
      "step": 48630
    },
    {
      "epoch": 4.150524788804505,
      "grad_norm": 0.0958041101694107,
      "learning_rate": 2.924737605597747e-05,
      "loss": 0.0017,
      "step": 48640
    },
    {
      "epoch": 4.151378103933783,
      "grad_norm": 0.38791170716285706,
      "learning_rate": 2.924310948033109e-05,
      "loss": 0.0017,
      "step": 48650
    },
    {
      "epoch": 4.15223141906306,
      "grad_norm": 0.27811092138290405,
      "learning_rate": 2.92388429046847e-05,
      "loss": 0.0023,
      "step": 48660
    },
    {
      "epoch": 4.153084734192337,
      "grad_norm": 0.23065969347953796,
      "learning_rate": 2.9234576329038314e-05,
      "loss": 0.0021,
      "step": 48670
    },
    {
      "epoch": 4.1539380493216145,
      "grad_norm": 0.20851992070674896,
      "learning_rate": 2.9230309753391925e-05,
      "loss": 0.002,
      "step": 48680
    },
    {
      "epoch": 4.154791364450892,
      "grad_norm": 0.1275613009929657,
      "learning_rate": 2.9226043177745543e-05,
      "loss": 0.002,
      "step": 48690
    },
    {
      "epoch": 4.155644679580169,
      "grad_norm": 0.3188397288322449,
      "learning_rate": 2.9221776602099154e-05,
      "loss": 0.0023,
      "step": 48700
    },
    {
      "epoch": 4.156497994709446,
      "grad_norm": 0.1718602329492569,
      "learning_rate": 2.921751002645277e-05,
      "loss": 0.0016,
      "step": 48710
    },
    {
      "epoch": 4.157351309838724,
      "grad_norm": 0.027171971276402473,
      "learning_rate": 2.9213243450806382e-05,
      "loss": 0.0021,
      "step": 48720
    },
    {
      "epoch": 4.1582046249680005,
      "grad_norm": 0.17860619723796844,
      "learning_rate": 2.920897687516e-05,
      "loss": 0.0021,
      "step": 48730
    },
    {
      "epoch": 4.159057940097278,
      "grad_norm": 0.20482896268367767,
      "learning_rate": 2.920471029951361e-05,
      "loss": 0.0019,
      "step": 48740
    },
    {
      "epoch": 4.159911255226556,
      "grad_norm": 0.22446398437023163,
      "learning_rate": 2.9200443723867228e-05,
      "loss": 0.002,
      "step": 48750
    },
    {
      "epoch": 4.160764570355832,
      "grad_norm": 0.13969436287879944,
      "learning_rate": 2.919617714822084e-05,
      "loss": 0.0019,
      "step": 48760
    },
    {
      "epoch": 4.16161788548511,
      "grad_norm": 0.18771955370903015,
      "learning_rate": 2.9191910572574453e-05,
      "loss": 0.0022,
      "step": 48770
    },
    {
      "epoch": 4.1624712006143865,
      "grad_norm": 0.1490342915058136,
      "learning_rate": 2.9187643996928064e-05,
      "loss": 0.002,
      "step": 48780
    },
    {
      "epoch": 4.163324515743664,
      "grad_norm": 0.27408909797668457,
      "learning_rate": 2.9183377421281682e-05,
      "loss": 0.0015,
      "step": 48790
    },
    {
      "epoch": 4.164177830872942,
      "grad_norm": 0.19508086144924164,
      "learning_rate": 2.9179110845635293e-05,
      "loss": 0.0019,
      "step": 48800
    },
    {
      "epoch": 4.165031146002218,
      "grad_norm": 0.2093506157398224,
      "learning_rate": 2.917484426998891e-05,
      "loss": 0.0021,
      "step": 48810
    },
    {
      "epoch": 4.165884461131496,
      "grad_norm": 0.18698689341545105,
      "learning_rate": 2.917057769434252e-05,
      "loss": 0.0021,
      "step": 48820
    },
    {
      "epoch": 4.166737776260773,
      "grad_norm": 0.113315649330616,
      "learning_rate": 2.916631111869614e-05,
      "loss": 0.0022,
      "step": 48830
    },
    {
      "epoch": 4.16759109139005,
      "grad_norm": 0.049791157245635986,
      "learning_rate": 2.916204454304975e-05,
      "loss": 0.0017,
      "step": 48840
    },
    {
      "epoch": 4.168444406519328,
      "grad_norm": 0.4744170010089874,
      "learning_rate": 2.9157777967403367e-05,
      "loss": 0.0018,
      "step": 48850
    },
    {
      "epoch": 4.169297721648605,
      "grad_norm": 0.20818500220775604,
      "learning_rate": 2.9153511391756978e-05,
      "loss": 0.0018,
      "step": 48860
    },
    {
      "epoch": 4.170151036777882,
      "grad_norm": 0.3871345520019531,
      "learning_rate": 2.9149244816110592e-05,
      "loss": 0.0022,
      "step": 48870
    },
    {
      "epoch": 4.171004351907159,
      "grad_norm": 0.2380385547876358,
      "learning_rate": 2.9144978240464203e-05,
      "loss": 0.0018,
      "step": 48880
    },
    {
      "epoch": 4.171857667036437,
      "grad_norm": 0.1702631413936615,
      "learning_rate": 2.914071166481782e-05,
      "loss": 0.0019,
      "step": 48890
    },
    {
      "epoch": 4.172710982165714,
      "grad_norm": 0.10903993993997574,
      "learning_rate": 2.913644508917143e-05,
      "loss": 0.0016,
      "step": 48900
    },
    {
      "epoch": 4.173564297294991,
      "grad_norm": 0.24220433831214905,
      "learning_rate": 2.9132178513525043e-05,
      "loss": 0.0017,
      "step": 48910
    },
    {
      "epoch": 4.174417612424269,
      "grad_norm": 0.28517791628837585,
      "learning_rate": 2.912791193787866e-05,
      "loss": 0.0018,
      "step": 48920
    },
    {
      "epoch": 4.175270927553545,
      "grad_norm": 0.2029314637184143,
      "learning_rate": 2.912364536223227e-05,
      "loss": 0.0017,
      "step": 48930
    },
    {
      "epoch": 4.176124242682823,
      "grad_norm": 0.13156889379024506,
      "learning_rate": 2.911937878658589e-05,
      "loss": 0.002,
      "step": 48940
    },
    {
      "epoch": 4.1769775578121,
      "grad_norm": 0.1883842796087265,
      "learning_rate": 2.91151122109395e-05,
      "loss": 0.0018,
      "step": 48950
    },
    {
      "epoch": 4.177830872941377,
      "grad_norm": 0.13599224388599396,
      "learning_rate": 2.9110845635293117e-05,
      "loss": 0.0024,
      "step": 48960
    },
    {
      "epoch": 4.178684188070655,
      "grad_norm": 0.18740394711494446,
      "learning_rate": 2.9106579059646728e-05,
      "loss": 0.0018,
      "step": 48970
    },
    {
      "epoch": 4.179537503199931,
      "grad_norm": 0.029395509511232376,
      "learning_rate": 2.9102312484000342e-05,
      "loss": 0.0017,
      "step": 48980
    },
    {
      "epoch": 4.180390818329209,
      "grad_norm": 0.1667972058057785,
      "learning_rate": 2.9098045908353953e-05,
      "loss": 0.0024,
      "step": 48990
    },
    {
      "epoch": 4.1812441334584864,
      "grad_norm": 0.0576854906976223,
      "learning_rate": 2.909377933270757e-05,
      "loss": 0.0021,
      "step": 49000
    },
    {
      "epoch": 4.182097448587763,
      "grad_norm": 0.3918764591217041,
      "learning_rate": 2.908951275706118e-05,
      "loss": 0.0018,
      "step": 49010
    },
    {
      "epoch": 4.182950763717041,
      "grad_norm": 0.15415990352630615,
      "learning_rate": 2.90852461814148e-05,
      "loss": 0.0016,
      "step": 49020
    },
    {
      "epoch": 4.183804078846318,
      "grad_norm": 0.24554799497127533,
      "learning_rate": 2.908097960576841e-05,
      "loss": 0.0022,
      "step": 49030
    },
    {
      "epoch": 4.184657393975595,
      "grad_norm": 0.1893988996744156,
      "learning_rate": 2.9076713030122028e-05,
      "loss": 0.0021,
      "step": 49040
    },
    {
      "epoch": 4.185510709104872,
      "grad_norm": 0.17077137529850006,
      "learning_rate": 2.907244645447564e-05,
      "loss": 0.0024,
      "step": 49050
    },
    {
      "epoch": 4.18636402423415,
      "grad_norm": 0.18275699019432068,
      "learning_rate": 2.9068179878829256e-05,
      "loss": 0.0018,
      "step": 49060
    },
    {
      "epoch": 4.187217339363427,
      "grad_norm": 0.22309496998786926,
      "learning_rate": 2.9063913303182867e-05,
      "loss": 0.0018,
      "step": 49070
    },
    {
      "epoch": 4.188070654492704,
      "grad_norm": 0.13742774724960327,
      "learning_rate": 2.905964672753648e-05,
      "loss": 0.0013,
      "step": 49080
    },
    {
      "epoch": 4.188923969621982,
      "grad_norm": 0.3355376124382019,
      "learning_rate": 2.9055380151890092e-05,
      "loss": 0.0014,
      "step": 49090
    },
    {
      "epoch": 4.189777284751258,
      "grad_norm": 0.03326674550771713,
      "learning_rate": 2.905111357624371e-05,
      "loss": 0.0018,
      "step": 49100
    },
    {
      "epoch": 4.190630599880536,
      "grad_norm": 0.29546791315078735,
      "learning_rate": 2.904684700059732e-05,
      "loss": 0.0028,
      "step": 49110
    },
    {
      "epoch": 4.1914839150098135,
      "grad_norm": 0.08389695733785629,
      "learning_rate": 2.9042580424950938e-05,
      "loss": 0.0023,
      "step": 49120
    },
    {
      "epoch": 4.19233723013909,
      "grad_norm": 0.09728614240884781,
      "learning_rate": 2.903831384930455e-05,
      "loss": 0.002,
      "step": 49130
    },
    {
      "epoch": 4.193190545268368,
      "grad_norm": 0.4271143078804016,
      "learning_rate": 2.9034047273658167e-05,
      "loss": 0.0025,
      "step": 49140
    },
    {
      "epoch": 4.194043860397644,
      "grad_norm": 0.20777100324630737,
      "learning_rate": 2.9029780698011778e-05,
      "loss": 0.0017,
      "step": 49150
    },
    {
      "epoch": 4.194897175526922,
      "grad_norm": 0.11495131999254227,
      "learning_rate": 2.9025514122365395e-05,
      "loss": 0.002,
      "step": 49160
    },
    {
      "epoch": 4.1957504906561995,
      "grad_norm": 0.07646045833826065,
      "learning_rate": 2.9021247546719006e-05,
      "loss": 0.0024,
      "step": 49170
    },
    {
      "epoch": 4.196603805785476,
      "grad_norm": 0.28030794858932495,
      "learning_rate": 2.9016980971072617e-05,
      "loss": 0.0022,
      "step": 49180
    },
    {
      "epoch": 4.197457120914754,
      "grad_norm": 0.12032759934663773,
      "learning_rate": 2.901271439542623e-05,
      "loss": 0.0019,
      "step": 49190
    },
    {
      "epoch": 4.198310436044031,
      "grad_norm": 0.2538072168827057,
      "learning_rate": 2.9008447819779845e-05,
      "loss": 0.002,
      "step": 49200
    },
    {
      "epoch": 4.199163751173308,
      "grad_norm": 0.08051007986068726,
      "learning_rate": 2.900418124413346e-05,
      "loss": 0.0013,
      "step": 49210
    },
    {
      "epoch": 4.2000170663025855,
      "grad_norm": 0.27946776151657104,
      "learning_rate": 2.899991466848707e-05,
      "loss": 0.0015,
      "step": 49220
    },
    {
      "epoch": 4.200870381431863,
      "grad_norm": 0.18951791524887085,
      "learning_rate": 2.8995648092840688e-05,
      "loss": 0.0025,
      "step": 49230
    },
    {
      "epoch": 4.20172369656114,
      "grad_norm": 0.2854977548122406,
      "learning_rate": 2.89913815171943e-05,
      "loss": 0.0024,
      "step": 49240
    },
    {
      "epoch": 4.202577011690417,
      "grad_norm": 0.13287118077278137,
      "learning_rate": 2.8987114941547917e-05,
      "loss": 0.0021,
      "step": 49250
    },
    {
      "epoch": 4.203430326819695,
      "grad_norm": 0.057876940816640854,
      "learning_rate": 2.8982848365901527e-05,
      "loss": 0.0022,
      "step": 49260
    },
    {
      "epoch": 4.2042836419489715,
      "grad_norm": 0.22306473553180695,
      "learning_rate": 2.8978581790255145e-05,
      "loss": 0.0019,
      "step": 49270
    },
    {
      "epoch": 4.205136957078249,
      "grad_norm": 0.12090659141540527,
      "learning_rate": 2.8974315214608756e-05,
      "loss": 0.0023,
      "step": 49280
    },
    {
      "epoch": 4.205990272207527,
      "grad_norm": 0.14693273603916168,
      "learning_rate": 2.897004863896237e-05,
      "loss": 0.0017,
      "step": 49290
    },
    {
      "epoch": 4.206843587336803,
      "grad_norm": 0.027869103476405144,
      "learning_rate": 2.896578206331598e-05,
      "loss": 0.0022,
      "step": 49300
    },
    {
      "epoch": 4.207696902466081,
      "grad_norm": 0.04290357232093811,
      "learning_rate": 2.89615154876696e-05,
      "loss": 0.0019,
      "step": 49310
    },
    {
      "epoch": 4.2085502175953575,
      "grad_norm": 0.4688417613506317,
      "learning_rate": 2.895724891202321e-05,
      "loss": 0.0019,
      "step": 49320
    },
    {
      "epoch": 4.209403532724635,
      "grad_norm": 0.4084426462650299,
      "learning_rate": 2.8952982336376827e-05,
      "loss": 0.002,
      "step": 49330
    },
    {
      "epoch": 4.210256847853913,
      "grad_norm": 0.07021600008010864,
      "learning_rate": 2.8948715760730438e-05,
      "loss": 0.0025,
      "step": 49340
    },
    {
      "epoch": 4.211110162983189,
      "grad_norm": 0.20445072650909424,
      "learning_rate": 2.8944449185084056e-05,
      "loss": 0.0022,
      "step": 49350
    },
    {
      "epoch": 4.211963478112467,
      "grad_norm": 0.10239280015230179,
      "learning_rate": 2.8940182609437666e-05,
      "loss": 0.0019,
      "step": 49360
    },
    {
      "epoch": 4.212816793241744,
      "grad_norm": 0.3769282102584839,
      "learning_rate": 2.8935916033791284e-05,
      "loss": 0.0022,
      "step": 49370
    },
    {
      "epoch": 4.213670108371021,
      "grad_norm": 0.09314113855361938,
      "learning_rate": 2.8931649458144895e-05,
      "loss": 0.0024,
      "step": 49380
    },
    {
      "epoch": 4.214523423500299,
      "grad_norm": 0.33353060483932495,
      "learning_rate": 2.892738288249851e-05,
      "loss": 0.0022,
      "step": 49390
    },
    {
      "epoch": 4.215376738629576,
      "grad_norm": 0.1371859312057495,
      "learning_rate": 2.892311630685212e-05,
      "loss": 0.0017,
      "step": 49400
    },
    {
      "epoch": 4.216230053758853,
      "grad_norm": 0.10386761277914047,
      "learning_rate": 2.8918849731205738e-05,
      "loss": 0.0022,
      "step": 49410
    },
    {
      "epoch": 4.21708336888813,
      "grad_norm": 0.16809000074863434,
      "learning_rate": 2.891458315555935e-05,
      "loss": 0.002,
      "step": 49420
    },
    {
      "epoch": 4.217936684017408,
      "grad_norm": 0.14863905310630798,
      "learning_rate": 2.891031657991296e-05,
      "loss": 0.0019,
      "step": 49430
    },
    {
      "epoch": 4.218789999146685,
      "grad_norm": 0.18084363639354706,
      "learning_rate": 2.8906050004266577e-05,
      "loss": 0.0021,
      "step": 49440
    },
    {
      "epoch": 4.219643314275962,
      "grad_norm": 0.23651838302612305,
      "learning_rate": 2.8901783428620188e-05,
      "loss": 0.0025,
      "step": 49450
    },
    {
      "epoch": 4.22049662940524,
      "grad_norm": 0.20665326714515686,
      "learning_rate": 2.8897516852973805e-05,
      "loss": 0.0022,
      "step": 49460
    },
    {
      "epoch": 4.221349944534516,
      "grad_norm": 0.2698615789413452,
      "learning_rate": 2.8893250277327416e-05,
      "loss": 0.0021,
      "step": 49470
    },
    {
      "epoch": 4.222203259663794,
      "grad_norm": 0.21135009825229645,
      "learning_rate": 2.8888983701681034e-05,
      "loss": 0.0019,
      "step": 49480
    },
    {
      "epoch": 4.2230565747930715,
      "grad_norm": 0.4317103624343872,
      "learning_rate": 2.8884717126034645e-05,
      "loss": 0.0019,
      "step": 49490
    },
    {
      "epoch": 4.223909889922348,
      "grad_norm": 0.132196843624115,
      "learning_rate": 2.888045055038826e-05,
      "loss": 0.0022,
      "step": 49500
    },
    {
      "epoch": 4.224763205051626,
      "grad_norm": 0.4429483115673065,
      "learning_rate": 2.8876183974741873e-05,
      "loss": 0.0022,
      "step": 49510
    },
    {
      "epoch": 4.225616520180902,
      "grad_norm": 0.14960359036922455,
      "learning_rate": 2.8871917399095487e-05,
      "loss": 0.0019,
      "step": 49520
    },
    {
      "epoch": 4.22646983531018,
      "grad_norm": 0.04578547552227974,
      "learning_rate": 2.88676508234491e-05,
      "loss": 0.0021,
      "step": 49530
    },
    {
      "epoch": 4.2273231504394575,
      "grad_norm": 0.03521807864308357,
      "learning_rate": 2.8863384247802716e-05,
      "loss": 0.0022,
      "step": 49540
    },
    {
      "epoch": 4.228176465568734,
      "grad_norm": 0.2214803695678711,
      "learning_rate": 2.8859117672156327e-05,
      "loss": 0.002,
      "step": 49550
    },
    {
      "epoch": 4.229029780698012,
      "grad_norm": 0.13827992975711823,
      "learning_rate": 2.8854851096509944e-05,
      "loss": 0.0019,
      "step": 49560
    },
    {
      "epoch": 4.229883095827289,
      "grad_norm": 0.23066499829292297,
      "learning_rate": 2.8850584520863555e-05,
      "loss": 0.0018,
      "step": 49570
    },
    {
      "epoch": 4.230736410956566,
      "grad_norm": 0.18577620387077332,
      "learning_rate": 2.8846317945217173e-05,
      "loss": 0.0022,
      "step": 49580
    },
    {
      "epoch": 4.2315897260858435,
      "grad_norm": 0.46306705474853516,
      "learning_rate": 2.8842051369570784e-05,
      "loss": 0.0022,
      "step": 49590
    },
    {
      "epoch": 4.232443041215121,
      "grad_norm": 0.29560989141464233,
      "learning_rate": 2.8837784793924398e-05,
      "loss": 0.002,
      "step": 49600
    },
    {
      "epoch": 4.233296356344398,
      "grad_norm": 0.27605873346328735,
      "learning_rate": 2.8833518218278012e-05,
      "loss": 0.0021,
      "step": 49610
    },
    {
      "epoch": 4.234149671473675,
      "grad_norm": 0.030182670801877975,
      "learning_rate": 2.8829251642631627e-05,
      "loss": 0.0019,
      "step": 49620
    },
    {
      "epoch": 4.235002986602953,
      "grad_norm": 0.16198554635047913,
      "learning_rate": 2.8824985066985237e-05,
      "loss": 0.0022,
      "step": 49630
    },
    {
      "epoch": 4.2358563017322295,
      "grad_norm": 0.05274907499551773,
      "learning_rate": 2.8820718491338855e-05,
      "loss": 0.0015,
      "step": 49640
    },
    {
      "epoch": 4.236709616861507,
      "grad_norm": 0.2425028532743454,
      "learning_rate": 2.8816451915692466e-05,
      "loss": 0.0015,
      "step": 49650
    },
    {
      "epoch": 4.237562931990785,
      "grad_norm": 0.07715355604887009,
      "learning_rate": 2.8812185340046083e-05,
      "loss": 0.0017,
      "step": 49660
    },
    {
      "epoch": 4.238416247120061,
      "grad_norm": 0.3689284324645996,
      "learning_rate": 2.8807918764399694e-05,
      "loss": 0.0021,
      "step": 49670
    },
    {
      "epoch": 4.239269562249339,
      "grad_norm": 0.07814564555883408,
      "learning_rate": 2.8803652188753312e-05,
      "loss": 0.0027,
      "step": 49680
    },
    {
      "epoch": 4.2401228773786155,
      "grad_norm": 0.17342637479305267,
      "learning_rate": 2.8799385613106923e-05,
      "loss": 0.0019,
      "step": 49690
    },
    {
      "epoch": 4.240976192507893,
      "grad_norm": 0.2775891423225403,
      "learning_rate": 2.8795119037460534e-05,
      "loss": 0.0019,
      "step": 49700
    },
    {
      "epoch": 4.241829507637171,
      "grad_norm": 0.13349764049053192,
      "learning_rate": 2.8790852461814148e-05,
      "loss": 0.0021,
      "step": 49710
    },
    {
      "epoch": 4.242682822766447,
      "grad_norm": 0.2467607706785202,
      "learning_rate": 2.8786585886167762e-05,
      "loss": 0.0019,
      "step": 49720
    },
    {
      "epoch": 4.243536137895725,
      "grad_norm": 0.237991064786911,
      "learning_rate": 2.8782319310521376e-05,
      "loss": 0.0019,
      "step": 49730
    },
    {
      "epoch": 4.244389453025002,
      "grad_norm": 0.09867237508296967,
      "learning_rate": 2.8778052734874987e-05,
      "loss": 0.0021,
      "step": 49740
    },
    {
      "epoch": 4.245242768154279,
      "grad_norm": 0.07239818572998047,
      "learning_rate": 2.8773786159228605e-05,
      "loss": 0.0016,
      "step": 49750
    },
    {
      "epoch": 4.246096083283557,
      "grad_norm": 0.13373100757598877,
      "learning_rate": 2.8769519583582216e-05,
      "loss": 0.0019,
      "step": 49760
    },
    {
      "epoch": 4.246949398412834,
      "grad_norm": 0.2621370553970337,
      "learning_rate": 2.8765253007935833e-05,
      "loss": 0.0017,
      "step": 49770
    },
    {
      "epoch": 4.247802713542111,
      "grad_norm": 0.17730849981307983,
      "learning_rate": 2.8760986432289444e-05,
      "loss": 0.0021,
      "step": 49780
    },
    {
      "epoch": 4.248656028671388,
      "grad_norm": 0.1477973312139511,
      "learning_rate": 2.8756719856643062e-05,
      "loss": 0.0015,
      "step": 49790
    },
    {
      "epoch": 4.249509343800666,
      "grad_norm": 0.16207252442836761,
      "learning_rate": 2.8752453280996673e-05,
      "loss": 0.0018,
      "step": 49800
    },
    {
      "epoch": 4.250362658929943,
      "grad_norm": 0.13421572744846344,
      "learning_rate": 2.8748186705350287e-05,
      "loss": 0.0017,
      "step": 49810
    },
    {
      "epoch": 4.25121597405922,
      "grad_norm": 0.08620429039001465,
      "learning_rate": 2.87439201297039e-05,
      "loss": 0.0022,
      "step": 49820
    },
    {
      "epoch": 4.252069289188498,
      "grad_norm": 0.0594371035695076,
      "learning_rate": 2.8739653554057515e-05,
      "loss": 0.0018,
      "step": 49830
    },
    {
      "epoch": 4.252922604317774,
      "grad_norm": 0.3405703604221344,
      "learning_rate": 2.8735386978411126e-05,
      "loss": 0.002,
      "step": 49840
    },
    {
      "epoch": 4.253775919447052,
      "grad_norm": 0.3206750452518463,
      "learning_rate": 2.8731120402764744e-05,
      "loss": 0.0018,
      "step": 49850
    },
    {
      "epoch": 4.2546292345763295,
      "grad_norm": 0.18559464812278748,
      "learning_rate": 2.8726853827118355e-05,
      "loss": 0.0014,
      "step": 49860
    },
    {
      "epoch": 4.255482549705606,
      "grad_norm": 0.17078326642513275,
      "learning_rate": 2.8722587251471972e-05,
      "loss": 0.0019,
      "step": 49870
    },
    {
      "epoch": 4.256335864834884,
      "grad_norm": 0.37235137820243835,
      "learning_rate": 2.8718320675825583e-05,
      "loss": 0.0017,
      "step": 49880
    },
    {
      "epoch": 4.25718917996416,
      "grad_norm": 0.18633511662483215,
      "learning_rate": 2.87140541001792e-05,
      "loss": 0.002,
      "step": 49890
    },
    {
      "epoch": 4.258042495093438,
      "grad_norm": 0.5160889029502869,
      "learning_rate": 2.8709787524532812e-05,
      "loss": 0.0021,
      "step": 49900
    },
    {
      "epoch": 4.2588958102227155,
      "grad_norm": 0.37488284707069397,
      "learning_rate": 2.8705520948886426e-05,
      "loss": 0.0027,
      "step": 49910
    },
    {
      "epoch": 4.259749125351992,
      "grad_norm": 0.07778970897197723,
      "learning_rate": 2.870125437324004e-05,
      "loss": 0.0022,
      "step": 49920
    },
    {
      "epoch": 4.26060244048127,
      "grad_norm": 0.3414730727672577,
      "learning_rate": 2.8696987797593654e-05,
      "loss": 0.0025,
      "step": 49930
    },
    {
      "epoch": 4.261455755610547,
      "grad_norm": 0.27578631043434143,
      "learning_rate": 2.8692721221947265e-05,
      "loss": 0.0025,
      "step": 49940
    },
    {
      "epoch": 4.262309070739824,
      "grad_norm": 0.1868729144334793,
      "learning_rate": 2.8688454646300883e-05,
      "loss": 0.0024,
      "step": 49950
    },
    {
      "epoch": 4.2631623858691015,
      "grad_norm": 0.09930755943059921,
      "learning_rate": 2.8684188070654494e-05,
      "loss": 0.0018,
      "step": 49960
    },
    {
      "epoch": 4.264015700998379,
      "grad_norm": 0.09733571857213974,
      "learning_rate": 2.8679921495008105e-05,
      "loss": 0.0021,
      "step": 49970
    },
    {
      "epoch": 4.264869016127656,
      "grad_norm": 0.059484150260686874,
      "learning_rate": 2.8675654919361722e-05,
      "loss": 0.0013,
      "step": 49980
    },
    {
      "epoch": 4.265722331256933,
      "grad_norm": 0.27624833583831787,
      "learning_rate": 2.8671388343715333e-05,
      "loss": 0.0017,
      "step": 49990
    },
    {
      "epoch": 4.266575646386211,
      "grad_norm": 0.2343791276216507,
      "learning_rate": 2.866712176806895e-05,
      "loss": 0.0017,
      "step": 50000
    },
    {
      "epoch": 4.2674289615154875,
      "grad_norm": 0.24998554587364197,
      "learning_rate": 2.866285519242256e-05,
      "loss": 0.0016,
      "step": 50010
    },
    {
      "epoch": 4.268282276644765,
      "grad_norm": 0.048630356788635254,
      "learning_rate": 2.8658588616776176e-05,
      "loss": 0.0016,
      "step": 50020
    },
    {
      "epoch": 4.269135591774043,
      "grad_norm": 0.27732884883880615,
      "learning_rate": 2.865432204112979e-05,
      "loss": 0.0015,
      "step": 50030
    },
    {
      "epoch": 4.269988906903319,
      "grad_norm": 0.2467341125011444,
      "learning_rate": 2.8650055465483404e-05,
      "loss": 0.0017,
      "step": 50040
    },
    {
      "epoch": 4.270842222032597,
      "grad_norm": 0.3811131417751312,
      "learning_rate": 2.8645788889837015e-05,
      "loss": 0.0021,
      "step": 50050
    },
    {
      "epoch": 4.2716955371618734,
      "grad_norm": 0.06344606727361679,
      "learning_rate": 2.8641522314190633e-05,
      "loss": 0.0017,
      "step": 50060
    },
    {
      "epoch": 4.272548852291151,
      "grad_norm": 0.17075861990451813,
      "learning_rate": 2.8637255738544244e-05,
      "loss": 0.0019,
      "step": 50070
    },
    {
      "epoch": 4.2734021674204286,
      "grad_norm": 0.3112886846065521,
      "learning_rate": 2.863298916289786e-05,
      "loss": 0.0018,
      "step": 50080
    },
    {
      "epoch": 4.274255482549705,
      "grad_norm": 0.36092352867126465,
      "learning_rate": 2.8628722587251472e-05,
      "loss": 0.0016,
      "step": 50090
    },
    {
      "epoch": 4.275108797678983,
      "grad_norm": 0.22370989620685577,
      "learning_rate": 2.862445601160509e-05,
      "loss": 0.0014,
      "step": 50100
    },
    {
      "epoch": 4.27596211280826,
      "grad_norm": 0.1343407779932022,
      "learning_rate": 2.86201894359587e-05,
      "loss": 0.0022,
      "step": 50110
    },
    {
      "epoch": 4.276815427937537,
      "grad_norm": 0.15498630702495575,
      "learning_rate": 2.8615922860312315e-05,
      "loss": 0.0025,
      "step": 50120
    },
    {
      "epoch": 4.2776687430668145,
      "grad_norm": 0.20582464337348938,
      "learning_rate": 2.861165628466593e-05,
      "loss": 0.0019,
      "step": 50130
    },
    {
      "epoch": 4.278522058196092,
      "grad_norm": 0.24481871724128723,
      "learning_rate": 2.8607389709019543e-05,
      "loss": 0.0022,
      "step": 50140
    },
    {
      "epoch": 4.279375373325369,
      "grad_norm": 0.25197818875312805,
      "learning_rate": 2.8603123133373154e-05,
      "loss": 0.0026,
      "step": 50150
    },
    {
      "epoch": 4.280228688454646,
      "grad_norm": 0.1982833594083786,
      "learning_rate": 2.8598856557726772e-05,
      "loss": 0.0019,
      "step": 50160
    },
    {
      "epoch": 4.281082003583924,
      "grad_norm": 0.03338254615664482,
      "learning_rate": 2.8594589982080383e-05,
      "loss": 0.0019,
      "step": 50170
    },
    {
      "epoch": 4.2819353187132005,
      "grad_norm": 0.06409139931201935,
      "learning_rate": 2.8590323406434e-05,
      "loss": 0.0016,
      "step": 50180
    },
    {
      "epoch": 4.282788633842478,
      "grad_norm": 0.06600625813007355,
      "learning_rate": 2.858605683078761e-05,
      "loss": 0.0022,
      "step": 50190
    },
    {
      "epoch": 4.283641948971756,
      "grad_norm": 0.06197342276573181,
      "learning_rate": 2.858179025514123e-05,
      "loss": 0.0019,
      "step": 50200
    },
    {
      "epoch": 4.284495264101032,
      "grad_norm": 0.15276575088500977,
      "learning_rate": 2.857752367949484e-05,
      "loss": 0.002,
      "step": 50210
    },
    {
      "epoch": 4.28534857923031,
      "grad_norm": 0.1323801875114441,
      "learning_rate": 2.8573257103848454e-05,
      "loss": 0.0017,
      "step": 50220
    },
    {
      "epoch": 4.286201894359587,
      "grad_norm": 0.023298967629671097,
      "learning_rate": 2.8568990528202068e-05,
      "loss": 0.0016,
      "step": 50230
    },
    {
      "epoch": 4.287055209488864,
      "grad_norm": 0.29794684052467346,
      "learning_rate": 2.856472395255568e-05,
      "loss": 0.0019,
      "step": 50240
    },
    {
      "epoch": 4.287908524618142,
      "grad_norm": 0.13474901020526886,
      "learning_rate": 2.8560457376909293e-05,
      "loss": 0.0017,
      "step": 50250
    },
    {
      "epoch": 4.288761839747418,
      "grad_norm": 0.18316149711608887,
      "learning_rate": 2.8556190801262904e-05,
      "loss": 0.0018,
      "step": 50260
    },
    {
      "epoch": 4.289615154876696,
      "grad_norm": 0.026453038677573204,
      "learning_rate": 2.855192422561652e-05,
      "loss": 0.0021,
      "step": 50270
    },
    {
      "epoch": 4.290468470005973,
      "grad_norm": 0.38981613516807556,
      "learning_rate": 2.8547657649970133e-05,
      "loss": 0.0015,
      "step": 50280
    },
    {
      "epoch": 4.29132178513525,
      "grad_norm": 0.11809970438480377,
      "learning_rate": 2.854339107432375e-05,
      "loss": 0.0019,
      "step": 50290
    },
    {
      "epoch": 4.292175100264528,
      "grad_norm": 0.05775664746761322,
      "learning_rate": 2.853912449867736e-05,
      "loss": 0.0021,
      "step": 50300
    },
    {
      "epoch": 4.293028415393805,
      "grad_norm": 0.2161589413881302,
      "learning_rate": 2.853485792303098e-05,
      "loss": 0.0026,
      "step": 50310
    },
    {
      "epoch": 4.293881730523082,
      "grad_norm": 0.18090561032295227,
      "learning_rate": 2.853059134738459e-05,
      "loss": 0.002,
      "step": 50320
    },
    {
      "epoch": 4.294735045652359,
      "grad_norm": 0.33072900772094727,
      "learning_rate": 2.8526324771738204e-05,
      "loss": 0.0016,
      "step": 50330
    },
    {
      "epoch": 4.295588360781637,
      "grad_norm": 0.24909186363220215,
      "learning_rate": 2.8522058196091818e-05,
      "loss": 0.0021,
      "step": 50340
    },
    {
      "epoch": 4.296441675910914,
      "grad_norm": 0.1824573278427124,
      "learning_rate": 2.8517791620445432e-05,
      "loss": 0.0031,
      "step": 50350
    },
    {
      "epoch": 4.297294991040191,
      "grad_norm": 0.06455512344837189,
      "learning_rate": 2.8513525044799043e-05,
      "loss": 0.0019,
      "step": 50360
    },
    {
      "epoch": 4.298148306169469,
      "grad_norm": 0.27885499596595764,
      "learning_rate": 2.850925846915266e-05,
      "loss": 0.0019,
      "step": 50370
    },
    {
      "epoch": 4.299001621298745,
      "grad_norm": 0.17903436720371246,
      "learning_rate": 2.850499189350627e-05,
      "loss": 0.0018,
      "step": 50380
    },
    {
      "epoch": 4.299854936428023,
      "grad_norm": 0.10530059784650803,
      "learning_rate": 2.850072531785989e-05,
      "loss": 0.002,
      "step": 50390
    },
    {
      "epoch": 4.3007082515573005,
      "grad_norm": 0.034409407526254654,
      "learning_rate": 2.84964587422135e-05,
      "loss": 0.0015,
      "step": 50400
    },
    {
      "epoch": 4.301561566686577,
      "grad_norm": 0.09680069237947464,
      "learning_rate": 2.8492192166567118e-05,
      "loss": 0.0021,
      "step": 50410
    },
    {
      "epoch": 4.302414881815855,
      "grad_norm": 0.3312860429286957,
      "learning_rate": 2.848792559092073e-05,
      "loss": 0.0017,
      "step": 50420
    },
    {
      "epoch": 4.303268196945131,
      "grad_norm": 0.0593581385910511,
      "learning_rate": 2.8483659015274343e-05,
      "loss": 0.0019,
      "step": 50430
    },
    {
      "epoch": 4.304121512074409,
      "grad_norm": 0.058852821588516235,
      "learning_rate": 2.8479392439627957e-05,
      "loss": 0.0018,
      "step": 50440
    },
    {
      "epoch": 4.3049748272036865,
      "grad_norm": 0.14854052662849426,
      "learning_rate": 2.847512586398157e-05,
      "loss": 0.0016,
      "step": 50450
    },
    {
      "epoch": 4.305828142332963,
      "grad_norm": 0.2680513858795166,
      "learning_rate": 2.8470859288335182e-05,
      "loss": 0.0019,
      "step": 50460
    },
    {
      "epoch": 4.306681457462241,
      "grad_norm": 0.12839213013648987,
      "learning_rate": 2.84665927126888e-05,
      "loss": 0.0013,
      "step": 50470
    },
    {
      "epoch": 4.307534772591518,
      "grad_norm": 0.2782442569732666,
      "learning_rate": 2.846232613704241e-05,
      "loss": 0.0018,
      "step": 50480
    },
    {
      "epoch": 4.308388087720795,
      "grad_norm": 0.12362714856863022,
      "learning_rate": 2.8458059561396028e-05,
      "loss": 0.0019,
      "step": 50490
    },
    {
      "epoch": 4.3092414028500725,
      "grad_norm": 0.22248435020446777,
      "learning_rate": 2.845379298574964e-05,
      "loss": 0.0018,
      "step": 50500
    },
    {
      "epoch": 4.31009471797935,
      "grad_norm": 0.390813946723938,
      "learning_rate": 2.844952641010325e-05,
      "loss": 0.002,
      "step": 50510
    },
    {
      "epoch": 4.310948033108627,
      "grad_norm": 0.28424397110939026,
      "learning_rate": 2.8445259834456868e-05,
      "loss": 0.0019,
      "step": 50520
    },
    {
      "epoch": 4.311801348237904,
      "grad_norm": 0.3936232030391693,
      "learning_rate": 2.844099325881048e-05,
      "loss": 0.0023,
      "step": 50530
    },
    {
      "epoch": 4.312654663367182,
      "grad_norm": 0.0743284672498703,
      "learning_rate": 2.8436726683164096e-05,
      "loss": 0.0019,
      "step": 50540
    },
    {
      "epoch": 4.3135079784964585,
      "grad_norm": 0.24933122098445892,
      "learning_rate": 2.8432460107517707e-05,
      "loss": 0.0023,
      "step": 50550
    },
    {
      "epoch": 4.314361293625736,
      "grad_norm": 0.021440943703055382,
      "learning_rate": 2.842819353187132e-05,
      "loss": 0.0023,
      "step": 50560
    },
    {
      "epoch": 4.315214608755014,
      "grad_norm": 0.2079136073589325,
      "learning_rate": 2.8423926956224932e-05,
      "loss": 0.0016,
      "step": 50570
    },
    {
      "epoch": 4.31606792388429,
      "grad_norm": 0.0948018729686737,
      "learning_rate": 2.841966038057855e-05,
      "loss": 0.0017,
      "step": 50580
    },
    {
      "epoch": 4.316921239013568,
      "grad_norm": 0.16763870418071747,
      "learning_rate": 2.841539380493216e-05,
      "loss": 0.0016,
      "step": 50590
    },
    {
      "epoch": 4.317774554142845,
      "grad_norm": 0.33802875876426697,
      "learning_rate": 2.8411127229285778e-05,
      "loss": 0.0023,
      "step": 50600
    },
    {
      "epoch": 4.318627869272122,
      "grad_norm": 0.30554187297821045,
      "learning_rate": 2.840686065363939e-05,
      "loss": 0.0026,
      "step": 50610
    },
    {
      "epoch": 4.3194811844014,
      "grad_norm": 0.2381453663110733,
      "learning_rate": 2.8402594077993007e-05,
      "loss": 0.0015,
      "step": 50620
    },
    {
      "epoch": 4.320334499530676,
      "grad_norm": 0.13595320284366608,
      "learning_rate": 2.8398327502346617e-05,
      "loss": 0.0017,
      "step": 50630
    },
    {
      "epoch": 4.321187814659954,
      "grad_norm": 0.0842839926481247,
      "learning_rate": 2.839406092670023e-05,
      "loss": 0.0017,
      "step": 50640
    },
    {
      "epoch": 4.322041129789231,
      "grad_norm": 0.44364944100379944,
      "learning_rate": 2.8389794351053846e-05,
      "loss": 0.0016,
      "step": 50650
    },
    {
      "epoch": 4.322894444918508,
      "grad_norm": 0.4859848618507385,
      "learning_rate": 2.838552777540746e-05,
      "loss": 0.0017,
      "step": 50660
    },
    {
      "epoch": 4.323747760047786,
      "grad_norm": 0.3147509694099426,
      "learning_rate": 2.838126119976107e-05,
      "loss": 0.0016,
      "step": 50670
    },
    {
      "epoch": 4.324601075177063,
      "grad_norm": 0.3516952395439148,
      "learning_rate": 2.837699462411469e-05,
      "loss": 0.002,
      "step": 50680
    },
    {
      "epoch": 4.32545439030634,
      "grad_norm": 0.49311161041259766,
      "learning_rate": 2.83727280484683e-05,
      "loss": 0.0019,
      "step": 50690
    },
    {
      "epoch": 4.326307705435617,
      "grad_norm": 0.06349512934684753,
      "learning_rate": 2.8368461472821917e-05,
      "loss": 0.0018,
      "step": 50700
    },
    {
      "epoch": 4.327161020564895,
      "grad_norm": 0.3350234627723694,
      "learning_rate": 2.8364194897175528e-05,
      "loss": 0.0016,
      "step": 50710
    },
    {
      "epoch": 4.328014335694172,
      "grad_norm": 0.24271665513515472,
      "learning_rate": 2.8359928321529146e-05,
      "loss": 0.0023,
      "step": 50720
    },
    {
      "epoch": 4.328867650823449,
      "grad_norm": 0.38727715611457825,
      "learning_rate": 2.8355661745882756e-05,
      "loss": 0.0019,
      "step": 50730
    },
    {
      "epoch": 4.329720965952727,
      "grad_norm": 0.2119787633419037,
      "learning_rate": 2.835139517023637e-05,
      "loss": 0.0023,
      "step": 50740
    },
    {
      "epoch": 4.330574281082003,
      "grad_norm": 0.3156798183917999,
      "learning_rate": 2.8347128594589985e-05,
      "loss": 0.0018,
      "step": 50750
    },
    {
      "epoch": 4.331427596211281,
      "grad_norm": 0.31826457381248474,
      "learning_rate": 2.8342862018943596e-05,
      "loss": 0.0019,
      "step": 50760
    },
    {
      "epoch": 4.3322809113405585,
      "grad_norm": 0.309896320104599,
      "learning_rate": 2.833859544329721e-05,
      "loss": 0.0023,
      "step": 50770
    },
    {
      "epoch": 4.333134226469835,
      "grad_norm": 0.11715510487556458,
      "learning_rate": 2.833432886765082e-05,
      "loss": 0.0027,
      "step": 50780
    },
    {
      "epoch": 4.333987541599113,
      "grad_norm": 0.04378642141819,
      "learning_rate": 2.833006229200444e-05,
      "loss": 0.0022,
      "step": 50790
    },
    {
      "epoch": 4.334840856728389,
      "grad_norm": 0.2749062776565552,
      "learning_rate": 2.832579571635805e-05,
      "loss": 0.0021,
      "step": 50800
    },
    {
      "epoch": 4.335694171857667,
      "grad_norm": 0.11106985807418823,
      "learning_rate": 2.8321529140711667e-05,
      "loss": 0.0014,
      "step": 50810
    },
    {
      "epoch": 4.3365474869869445,
      "grad_norm": 0.13221992552280426,
      "learning_rate": 2.8317262565065278e-05,
      "loss": 0.0019,
      "step": 50820
    },
    {
      "epoch": 4.337400802116221,
      "grad_norm": 0.03386666253209114,
      "learning_rate": 2.8312995989418895e-05,
      "loss": 0.0019,
      "step": 50830
    },
    {
      "epoch": 4.338254117245499,
      "grad_norm": 0.2421751767396927,
      "learning_rate": 2.8308729413772506e-05,
      "loss": 0.0014,
      "step": 50840
    },
    {
      "epoch": 4.339107432374776,
      "grad_norm": 0.1496901661157608,
      "learning_rate": 2.8304462838126124e-05,
      "loss": 0.0017,
      "step": 50850
    },
    {
      "epoch": 4.339960747504053,
      "grad_norm": 0.3392343521118164,
      "learning_rate": 2.8300196262479735e-05,
      "loss": 0.0019,
      "step": 50860
    },
    {
      "epoch": 4.3408140626333305,
      "grad_norm": 0.1943173110485077,
      "learning_rate": 2.829592968683335e-05,
      "loss": 0.002,
      "step": 50870
    },
    {
      "epoch": 4.341667377762608,
      "grad_norm": 0.20612338185310364,
      "learning_rate": 2.829166311118696e-05,
      "loss": 0.0025,
      "step": 50880
    },
    {
      "epoch": 4.342520692891885,
      "grad_norm": 0.20261667668819427,
      "learning_rate": 2.8287396535540578e-05,
      "loss": 0.0022,
      "step": 50890
    },
    {
      "epoch": 4.343374008021162,
      "grad_norm": 0.13047456741333008,
      "learning_rate": 2.828312995989419e-05,
      "loss": 0.0021,
      "step": 50900
    },
    {
      "epoch": 4.34422732315044,
      "grad_norm": 0.24011602997779846,
      "learning_rate": 2.8278863384247806e-05,
      "loss": 0.002,
      "step": 50910
    },
    {
      "epoch": 4.3450806382797165,
      "grad_norm": 0.257587730884552,
      "learning_rate": 2.8274596808601417e-05,
      "loss": 0.0018,
      "step": 50920
    },
    {
      "epoch": 4.345933953408994,
      "grad_norm": 0.1325533092021942,
      "learning_rate": 2.8270330232955034e-05,
      "loss": 0.002,
      "step": 50930
    },
    {
      "epoch": 4.346787268538272,
      "grad_norm": 0.18903487920761108,
      "learning_rate": 2.8266063657308645e-05,
      "loss": 0.0016,
      "step": 50940
    },
    {
      "epoch": 4.347640583667548,
      "grad_norm": 0.3707205057144165,
      "learning_rate": 2.826179708166226e-05,
      "loss": 0.0016,
      "step": 50950
    },
    {
      "epoch": 4.348493898796826,
      "grad_norm": 0.33316075801849365,
      "learning_rate": 2.8257530506015874e-05,
      "loss": 0.0017,
      "step": 50960
    },
    {
      "epoch": 4.349347213926103,
      "grad_norm": 0.13842540979385376,
      "learning_rate": 2.8253263930369488e-05,
      "loss": 0.002,
      "step": 50970
    },
    {
      "epoch": 4.35020052905538,
      "grad_norm": 0.08036025613546371,
      "learning_rate": 2.82489973547231e-05,
      "loss": 0.0016,
      "step": 50980
    },
    {
      "epoch": 4.351053844184658,
      "grad_norm": 0.1754249781370163,
      "learning_rate": 2.8244730779076717e-05,
      "loss": 0.0023,
      "step": 50990
    },
    {
      "epoch": 4.351907159313934,
      "grad_norm": 0.28726762533187866,
      "learning_rate": 2.8240464203430327e-05,
      "loss": 0.0021,
      "step": 51000
    },
    {
      "epoch": 4.352760474443212,
      "grad_norm": 0.2140612155199051,
      "learning_rate": 2.8236197627783945e-05,
      "loss": 0.0022,
      "step": 51010
    },
    {
      "epoch": 4.353613789572489,
      "grad_norm": 0.22547876834869385,
      "learning_rate": 2.8231931052137556e-05,
      "loss": 0.002,
      "step": 51020
    },
    {
      "epoch": 4.354467104701766,
      "grad_norm": 0.022159717977046967,
      "learning_rate": 2.8227664476491167e-05,
      "loss": 0.0015,
      "step": 51030
    },
    {
      "epoch": 4.355320419831044,
      "grad_norm": 0.1956678181886673,
      "learning_rate": 2.8223397900844784e-05,
      "loss": 0.0022,
      "step": 51040
    },
    {
      "epoch": 4.356173734960321,
      "grad_norm": 0.14700692892074585,
      "learning_rate": 2.8219131325198395e-05,
      "loss": 0.0025,
      "step": 51050
    },
    {
      "epoch": 4.357027050089598,
      "grad_norm": 0.2079658955335617,
      "learning_rate": 2.8214864749552013e-05,
      "loss": 0.0021,
      "step": 51060
    },
    {
      "epoch": 4.357880365218875,
      "grad_norm": 0.13130556046962738,
      "learning_rate": 2.8210598173905624e-05,
      "loss": 0.0017,
      "step": 51070
    },
    {
      "epoch": 4.358733680348153,
      "grad_norm": 0.0669313445687294,
      "learning_rate": 2.8206331598259238e-05,
      "loss": 0.0019,
      "step": 51080
    },
    {
      "epoch": 4.35958699547743,
      "grad_norm": 0.050032295286655426,
      "learning_rate": 2.820206502261285e-05,
      "loss": 0.0019,
      "step": 51090
    },
    {
      "epoch": 4.360440310606707,
      "grad_norm": 0.03369075059890747,
      "learning_rate": 2.8197798446966466e-05,
      "loss": 0.002,
      "step": 51100
    },
    {
      "epoch": 4.361293625735985,
      "grad_norm": 0.03257467970252037,
      "learning_rate": 2.8193531871320077e-05,
      "loss": 0.0016,
      "step": 51110
    },
    {
      "epoch": 4.362146940865261,
      "grad_norm": 0.33377474546432495,
      "learning_rate": 2.8189265295673695e-05,
      "loss": 0.0017,
      "step": 51120
    },
    {
      "epoch": 4.363000255994539,
      "grad_norm": 0.14597223699092865,
      "learning_rate": 2.8184998720027306e-05,
      "loss": 0.0017,
      "step": 51130
    },
    {
      "epoch": 4.3638535711238156,
      "grad_norm": 0.21852460503578186,
      "learning_rate": 2.8180732144380923e-05,
      "loss": 0.002,
      "step": 51140
    },
    {
      "epoch": 4.364706886253093,
      "grad_norm": 0.20525509119033813,
      "learning_rate": 2.8176465568734534e-05,
      "loss": 0.002,
      "step": 51150
    },
    {
      "epoch": 4.365560201382371,
      "grad_norm": 0.02396724745631218,
      "learning_rate": 2.8172198993088152e-05,
      "loss": 0.0022,
      "step": 51160
    },
    {
      "epoch": 4.366413516511647,
      "grad_norm": 0.2798047363758087,
      "learning_rate": 2.8167932417441763e-05,
      "loss": 0.0019,
      "step": 51170
    },
    {
      "epoch": 4.367266831640925,
      "grad_norm": 0.2618456184864044,
      "learning_rate": 2.8163665841795377e-05,
      "loss": 0.0023,
      "step": 51180
    },
    {
      "epoch": 4.368120146770202,
      "grad_norm": 0.215956449508667,
      "learning_rate": 2.8159399266148988e-05,
      "loss": 0.0018,
      "step": 51190
    },
    {
      "epoch": 4.368973461899479,
      "grad_norm": 0.21281558275222778,
      "learning_rate": 2.8155132690502605e-05,
      "loss": 0.0015,
      "step": 51200
    },
    {
      "epoch": 4.369826777028757,
      "grad_norm": 0.24635693430900574,
      "learning_rate": 2.8150866114856216e-05,
      "loss": 0.002,
      "step": 51210
    },
    {
      "epoch": 4.370680092158034,
      "grad_norm": 0.13159583508968353,
      "learning_rate": 2.8146599539209834e-05,
      "loss": 0.0025,
      "step": 51220
    },
    {
      "epoch": 4.371533407287311,
      "grad_norm": 0.1659640371799469,
      "learning_rate": 2.8142332963563445e-05,
      "loss": 0.0019,
      "step": 51230
    },
    {
      "epoch": 4.372386722416588,
      "grad_norm": 0.1139601469039917,
      "learning_rate": 2.8138066387917062e-05,
      "loss": 0.0021,
      "step": 51240
    },
    {
      "epoch": 4.373240037545866,
      "grad_norm": 0.2577037811279297,
      "learning_rate": 2.8133799812270673e-05,
      "loss": 0.0019,
      "step": 51250
    },
    {
      "epoch": 4.374093352675143,
      "grad_norm": 0.09658784419298172,
      "learning_rate": 2.812953323662429e-05,
      "loss": 0.0019,
      "step": 51260
    },
    {
      "epoch": 4.37494666780442,
      "grad_norm": 0.18561039865016937,
      "learning_rate": 2.8125266660977902e-05,
      "loss": 0.0015,
      "step": 51270
    },
    {
      "epoch": 4.375799982933698,
      "grad_norm": 0.2784643769264221,
      "learning_rate": 2.8121000085331516e-05,
      "loss": 0.0022,
      "step": 51280
    },
    {
      "epoch": 4.376653298062974,
      "grad_norm": 0.06119810789823532,
      "learning_rate": 2.8116733509685127e-05,
      "loss": 0.0017,
      "step": 51290
    },
    {
      "epoch": 4.377506613192252,
      "grad_norm": 0.11905013024806976,
      "learning_rate": 2.8112466934038738e-05,
      "loss": 0.0025,
      "step": 51300
    },
    {
      "epoch": 4.3783599283215295,
      "grad_norm": 0.280259370803833,
      "learning_rate": 2.8108200358392355e-05,
      "loss": 0.0021,
      "step": 51310
    },
    {
      "epoch": 4.379213243450806,
      "grad_norm": 0.18223391473293304,
      "learning_rate": 2.8103933782745966e-05,
      "loss": 0.0022,
      "step": 51320
    },
    {
      "epoch": 4.380066558580084,
      "grad_norm": 0.16305167973041534,
      "learning_rate": 2.8099667207099584e-05,
      "loss": 0.0018,
      "step": 51330
    },
    {
      "epoch": 4.380919873709361,
      "grad_norm": 0.08222509920597076,
      "learning_rate": 2.8095400631453195e-05,
      "loss": 0.0019,
      "step": 51340
    },
    {
      "epoch": 4.381773188838638,
      "grad_norm": 0.3296959400177002,
      "learning_rate": 2.8091134055806812e-05,
      "loss": 0.0021,
      "step": 51350
    },
    {
      "epoch": 4.3826265039679155,
      "grad_norm": 0.06289166957139969,
      "learning_rate": 2.8086867480160423e-05,
      "loss": 0.0022,
      "step": 51360
    },
    {
      "epoch": 4.383479819097192,
      "grad_norm": 0.23002466559410095,
      "learning_rate": 2.808260090451404e-05,
      "loss": 0.0015,
      "step": 51370
    },
    {
      "epoch": 4.38433313422647,
      "grad_norm": 0.04291974753141403,
      "learning_rate": 2.807833432886765e-05,
      "loss": 0.0016,
      "step": 51380
    },
    {
      "epoch": 4.385186449355747,
      "grad_norm": 0.025777360424399376,
      "learning_rate": 2.8074067753221266e-05,
      "loss": 0.002,
      "step": 51390
    },
    {
      "epoch": 4.386039764485024,
      "grad_norm": 0.03508969396352768,
      "learning_rate": 2.8069801177574877e-05,
      "loss": 0.0017,
      "step": 51400
    },
    {
      "epoch": 4.3868930796143015,
      "grad_norm": 0.1294778436422348,
      "learning_rate": 2.8065534601928494e-05,
      "loss": 0.002,
      "step": 51410
    },
    {
      "epoch": 4.387746394743579,
      "grad_norm": 0.5113248825073242,
      "learning_rate": 2.8061268026282105e-05,
      "loss": 0.0024,
      "step": 51420
    },
    {
      "epoch": 4.388599709872856,
      "grad_norm": 0.2251918464899063,
      "learning_rate": 2.8057001450635723e-05,
      "loss": 0.0021,
      "step": 51430
    },
    {
      "epoch": 4.389453025002133,
      "grad_norm": 0.15424922108650208,
      "learning_rate": 2.8052734874989334e-05,
      "loss": 0.0021,
      "step": 51440
    },
    {
      "epoch": 4.390306340131411,
      "grad_norm": 0.17195238173007965,
      "learning_rate": 2.804846829934295e-05,
      "loss": 0.0021,
      "step": 51450
    },
    {
      "epoch": 4.3911596552606875,
      "grad_norm": 0.1520751565694809,
      "learning_rate": 2.8044201723696562e-05,
      "loss": 0.0016,
      "step": 51460
    },
    {
      "epoch": 4.392012970389965,
      "grad_norm": 0.1622297167778015,
      "learning_rate": 2.803993514805018e-05,
      "loss": 0.0019,
      "step": 51470
    },
    {
      "epoch": 4.392866285519243,
      "grad_norm": 0.03024660237133503,
      "learning_rate": 2.803566857240379e-05,
      "loss": 0.0018,
      "step": 51480
    },
    {
      "epoch": 4.393719600648519,
      "grad_norm": 0.033981695771217346,
      "learning_rate": 2.8031401996757405e-05,
      "loss": 0.0018,
      "step": 51490
    },
    {
      "epoch": 4.394572915777797,
      "grad_norm": 0.2927892208099365,
      "learning_rate": 2.8027135421111016e-05,
      "loss": 0.0019,
      "step": 51500
    },
    {
      "epoch": 4.3954262309070735,
      "grad_norm": 0.24880528450012207,
      "learning_rate": 2.8022868845464633e-05,
      "loss": 0.0018,
      "step": 51510
    },
    {
      "epoch": 4.396279546036351,
      "grad_norm": 0.3940369486808777,
      "learning_rate": 2.8018602269818244e-05,
      "loss": 0.0021,
      "step": 51520
    },
    {
      "epoch": 4.397132861165629,
      "grad_norm": 0.23867729306221008,
      "learning_rate": 2.8014335694171862e-05,
      "loss": 0.0017,
      "step": 51530
    },
    {
      "epoch": 4.397986176294905,
      "grad_norm": 0.13345055282115936,
      "learning_rate": 2.8010069118525473e-05,
      "loss": 0.0015,
      "step": 51540
    },
    {
      "epoch": 4.398839491424183,
      "grad_norm": 0.2556280791759491,
      "learning_rate": 2.800580254287909e-05,
      "loss": 0.0021,
      "step": 51550
    },
    {
      "epoch": 4.39969280655346,
      "grad_norm": 0.07228998839855194,
      "learning_rate": 2.80015359672327e-05,
      "loss": 0.0016,
      "step": 51560
    },
    {
      "epoch": 4.400546121682737,
      "grad_norm": 0.3440026342868805,
      "learning_rate": 2.7997269391586312e-05,
      "loss": 0.0019,
      "step": 51570
    },
    {
      "epoch": 4.401399436812015,
      "grad_norm": 0.1500556319952011,
      "learning_rate": 2.799300281593993e-05,
      "loss": 0.0022,
      "step": 51580
    },
    {
      "epoch": 4.402252751941292,
      "grad_norm": 0.170988067984581,
      "learning_rate": 2.798873624029354e-05,
      "loss": 0.0027,
      "step": 51590
    },
    {
      "epoch": 4.403106067070569,
      "grad_norm": 0.11216487735509872,
      "learning_rate": 2.7984469664647155e-05,
      "loss": 0.002,
      "step": 51600
    },
    {
      "epoch": 4.403959382199846,
      "grad_norm": 0.08317166566848755,
      "learning_rate": 2.7980203089000766e-05,
      "loss": 0.0012,
      "step": 51610
    },
    {
      "epoch": 4.404812697329124,
      "grad_norm": 0.036720991134643555,
      "learning_rate": 2.7975936513354383e-05,
      "loss": 0.0015,
      "step": 51620
    },
    {
      "epoch": 4.405666012458401,
      "grad_norm": 0.04213101044297218,
      "learning_rate": 2.7971669937707994e-05,
      "loss": 0.0017,
      "step": 51630
    },
    {
      "epoch": 4.406519327587678,
      "grad_norm": 0.11347398161888123,
      "learning_rate": 2.7967403362061612e-05,
      "loss": 0.0019,
      "step": 51640
    },
    {
      "epoch": 4.407372642716956,
      "grad_norm": 0.2179166078567505,
      "learning_rate": 2.7963136786415223e-05,
      "loss": 0.0015,
      "step": 51650
    },
    {
      "epoch": 4.408225957846232,
      "grad_norm": 0.06107138469815254,
      "learning_rate": 2.795887021076884e-05,
      "loss": 0.0017,
      "step": 51660
    },
    {
      "epoch": 4.40907927297551,
      "grad_norm": 0.5885257720947266,
      "learning_rate": 2.795460363512245e-05,
      "loss": 0.0017,
      "step": 51670
    },
    {
      "epoch": 4.4099325881047875,
      "grad_norm": 0.13621915876865387,
      "learning_rate": 2.795033705947607e-05,
      "loss": 0.0016,
      "step": 51680
    },
    {
      "epoch": 4.410785903234064,
      "grad_norm": 0.11750258505344391,
      "learning_rate": 2.794607048382968e-05,
      "loss": 0.0017,
      "step": 51690
    },
    {
      "epoch": 4.411639218363342,
      "grad_norm": 0.2029920518398285,
      "learning_rate": 2.7941803908183294e-05,
      "loss": 0.0024,
      "step": 51700
    },
    {
      "epoch": 4.412492533492619,
      "grad_norm": 0.3147371709346771,
      "learning_rate": 2.7937537332536905e-05,
      "loss": 0.0022,
      "step": 51710
    },
    {
      "epoch": 4.413345848621896,
      "grad_norm": 0.09959037601947784,
      "learning_rate": 2.7933270756890522e-05,
      "loss": 0.0022,
      "step": 51720
    },
    {
      "epoch": 4.4141991637511735,
      "grad_norm": 0.3463602066040039,
      "learning_rate": 2.7929004181244133e-05,
      "loss": 0.0019,
      "step": 51730
    },
    {
      "epoch": 4.41505247888045,
      "grad_norm": 0.0862010046839714,
      "learning_rate": 2.792473760559775e-05,
      "loss": 0.0025,
      "step": 51740
    },
    {
      "epoch": 4.415905794009728,
      "grad_norm": 0.07546167075634003,
      "learning_rate": 2.792047102995136e-05,
      "loss": 0.0016,
      "step": 51750
    },
    {
      "epoch": 4.416759109139005,
      "grad_norm": 0.09657732397317886,
      "learning_rate": 2.791620445430498e-05,
      "loss": 0.0018,
      "step": 51760
    },
    {
      "epoch": 4.417612424268282,
      "grad_norm": 0.12590035796165466,
      "learning_rate": 2.791193787865859e-05,
      "loss": 0.0021,
      "step": 51770
    },
    {
      "epoch": 4.4184657393975595,
      "grad_norm": 0.09543721377849579,
      "learning_rate": 2.7907671303012208e-05,
      "loss": 0.002,
      "step": 51780
    },
    {
      "epoch": 4.419319054526837,
      "grad_norm": 0.2769756615161896,
      "learning_rate": 2.790340472736582e-05,
      "loss": 0.0016,
      "step": 51790
    },
    {
      "epoch": 4.420172369656114,
      "grad_norm": 0.24887649714946747,
      "learning_rate": 2.7899138151719433e-05,
      "loss": 0.0021,
      "step": 51800
    },
    {
      "epoch": 4.421025684785391,
      "grad_norm": 0.4643211364746094,
      "learning_rate": 2.7894871576073044e-05,
      "loss": 0.002,
      "step": 51810
    },
    {
      "epoch": 4.421878999914669,
      "grad_norm": 0.38788479566574097,
      "learning_rate": 2.7890605000426654e-05,
      "loss": 0.0021,
      "step": 51820
    },
    {
      "epoch": 4.4227323150439455,
      "grad_norm": 0.0422210767865181,
      "learning_rate": 2.7886338424780272e-05,
      "loss": 0.0032,
      "step": 51830
    },
    {
      "epoch": 4.423585630173223,
      "grad_norm": 0.2785814702510834,
      "learning_rate": 2.7882071849133883e-05,
      "loss": 0.0018,
      "step": 51840
    },
    {
      "epoch": 4.424438945302501,
      "grad_norm": 0.2614986300468445,
      "learning_rate": 2.78778052734875e-05,
      "loss": 0.0019,
      "step": 51850
    },
    {
      "epoch": 4.425292260431777,
      "grad_norm": 0.2664247751235962,
      "learning_rate": 2.787353869784111e-05,
      "loss": 0.002,
      "step": 51860
    },
    {
      "epoch": 4.426145575561055,
      "grad_norm": 0.28979402780532837,
      "learning_rate": 2.786927212219473e-05,
      "loss": 0.0024,
      "step": 51870
    },
    {
      "epoch": 4.4269988906903315,
      "grad_norm": 0.48232078552246094,
      "learning_rate": 2.786500554654834e-05,
      "loss": 0.0025,
      "step": 51880
    },
    {
      "epoch": 4.427852205819609,
      "grad_norm": 0.4984481632709503,
      "learning_rate": 2.7860738970901958e-05,
      "loss": 0.0019,
      "step": 51890
    },
    {
      "epoch": 4.428705520948887,
      "grad_norm": 0.028940672054886818,
      "learning_rate": 2.785647239525557e-05,
      "loss": 0.0016,
      "step": 51900
    },
    {
      "epoch": 4.429558836078163,
      "grad_norm": 0.1323752999305725,
      "learning_rate": 2.7852205819609183e-05,
      "loss": 0.0019,
      "step": 51910
    },
    {
      "epoch": 4.430412151207441,
      "grad_norm": 0.04663969203829765,
      "learning_rate": 2.7847939243962794e-05,
      "loss": 0.002,
      "step": 51920
    },
    {
      "epoch": 4.431265466336718,
      "grad_norm": 0.26063302159309387,
      "learning_rate": 2.784367266831641e-05,
      "loss": 0.0021,
      "step": 51930
    },
    {
      "epoch": 4.432118781465995,
      "grad_norm": 0.18478941917419434,
      "learning_rate": 2.7839406092670022e-05,
      "loss": 0.0017,
      "step": 51940
    },
    {
      "epoch": 4.432972096595273,
      "grad_norm": 0.041748616844415665,
      "learning_rate": 2.783513951702364e-05,
      "loss": 0.0019,
      "step": 51950
    },
    {
      "epoch": 4.43382541172455,
      "grad_norm": 0.048753514885902405,
      "learning_rate": 2.783087294137725e-05,
      "loss": 0.0025,
      "step": 51960
    },
    {
      "epoch": 4.434678726853827,
      "grad_norm": 0.14879833161830902,
      "learning_rate": 2.7826606365730868e-05,
      "loss": 0.0016,
      "step": 51970
    },
    {
      "epoch": 4.435532041983104,
      "grad_norm": 0.20185646414756775,
      "learning_rate": 2.782233979008448e-05,
      "loss": 0.0016,
      "step": 51980
    },
    {
      "epoch": 4.436385357112382,
      "grad_norm": 0.18559874594211578,
      "learning_rate": 2.7818073214438097e-05,
      "loss": 0.0018,
      "step": 51990
    },
    {
      "epoch": 4.437238672241659,
      "grad_norm": 0.09553763270378113,
      "learning_rate": 2.7813806638791707e-05,
      "loss": 0.0016,
      "step": 52000
    },
    {
      "epoch": 4.438091987370936,
      "grad_norm": 0.36763298511505127,
      "learning_rate": 2.780954006314532e-05,
      "loss": 0.002,
      "step": 52010
    },
    {
      "epoch": 4.438945302500214,
      "grad_norm": 0.1646113246679306,
      "learning_rate": 2.7805273487498933e-05,
      "loss": 0.0022,
      "step": 52020
    },
    {
      "epoch": 4.43979861762949,
      "grad_norm": 0.1689516305923462,
      "learning_rate": 2.780100691185255e-05,
      "loss": 0.002,
      "step": 52030
    },
    {
      "epoch": 4.440651932758768,
      "grad_norm": 0.19654597342014313,
      "learning_rate": 2.779674033620616e-05,
      "loss": 0.0017,
      "step": 52040
    },
    {
      "epoch": 4.4415052478880455,
      "grad_norm": 0.19279037415981293,
      "learning_rate": 2.779247376055978e-05,
      "loss": 0.0016,
      "step": 52050
    },
    {
      "epoch": 4.442358563017322,
      "grad_norm": 0.08176121115684509,
      "learning_rate": 2.778820718491339e-05,
      "loss": 0.002,
      "step": 52060
    },
    {
      "epoch": 4.4432118781466,
      "grad_norm": 0.2579984664916992,
      "learning_rate": 2.7783940609267007e-05,
      "loss": 0.0018,
      "step": 52070
    },
    {
      "epoch": 4.444065193275877,
      "grad_norm": 0.03244108706712723,
      "learning_rate": 2.7779674033620618e-05,
      "loss": 0.0017,
      "step": 52080
    },
    {
      "epoch": 4.444918508405154,
      "grad_norm": 0.02852623350918293,
      "learning_rate": 2.777540745797423e-05,
      "loss": 0.0016,
      "step": 52090
    },
    {
      "epoch": 4.4457718235344315,
      "grad_norm": 0.16730421781539917,
      "learning_rate": 2.7771140882327846e-05,
      "loss": 0.0021,
      "step": 52100
    },
    {
      "epoch": 4.446625138663708,
      "grad_norm": 0.1687200963497162,
      "learning_rate": 2.7766874306681457e-05,
      "loss": 0.0015,
      "step": 52110
    },
    {
      "epoch": 4.447478453792986,
      "grad_norm": 0.22289885580539703,
      "learning_rate": 2.776260773103507e-05,
      "loss": 0.0016,
      "step": 52120
    },
    {
      "epoch": 4.448331768922263,
      "grad_norm": 0.13331250846385956,
      "learning_rate": 2.7758341155388682e-05,
      "loss": 0.0016,
      "step": 52130
    },
    {
      "epoch": 4.44918508405154,
      "grad_norm": 0.1607448011636734,
      "learning_rate": 2.77540745797423e-05,
      "loss": 0.0016,
      "step": 52140
    },
    {
      "epoch": 4.4500383991808174,
      "grad_norm": 0.34345942735671997,
      "learning_rate": 2.774980800409591e-05,
      "loss": 0.0019,
      "step": 52150
    },
    {
      "epoch": 4.450891714310095,
      "grad_norm": 0.04847603291273117,
      "learning_rate": 2.774554142844953e-05,
      "loss": 0.0021,
      "step": 52160
    },
    {
      "epoch": 4.451745029439372,
      "grad_norm": 0.14259929955005646,
      "learning_rate": 2.774127485280314e-05,
      "loss": 0.0019,
      "step": 52170
    },
    {
      "epoch": 4.452598344568649,
      "grad_norm": 0.03901771828532219,
      "learning_rate": 2.7737008277156757e-05,
      "loss": 0.002,
      "step": 52180
    },
    {
      "epoch": 4.453451659697927,
      "grad_norm": 0.20793546736240387,
      "learning_rate": 2.7732741701510368e-05,
      "loss": 0.0019,
      "step": 52190
    },
    {
      "epoch": 4.4543049748272034,
      "grad_norm": 0.07755276560783386,
      "learning_rate": 2.7728475125863985e-05,
      "loss": 0.0019,
      "step": 52200
    },
    {
      "epoch": 4.455158289956481,
      "grad_norm": 0.1683656871318817,
      "learning_rate": 2.7724208550217596e-05,
      "loss": 0.0018,
      "step": 52210
    },
    {
      "epoch": 4.4560116050857586,
      "grad_norm": 0.08393103629350662,
      "learning_rate": 2.771994197457121e-05,
      "loss": 0.0019,
      "step": 52220
    },
    {
      "epoch": 4.456864920215035,
      "grad_norm": 0.1881297081708908,
      "learning_rate": 2.771567539892482e-05,
      "loss": 0.0024,
      "step": 52230
    },
    {
      "epoch": 4.457718235344313,
      "grad_norm": 0.5004053711891174,
      "learning_rate": 2.771140882327844e-05,
      "loss": 0.0019,
      "step": 52240
    },
    {
      "epoch": 4.458571550473589,
      "grad_norm": 0.24207787215709686,
      "learning_rate": 2.770714224763205e-05,
      "loss": 0.0014,
      "step": 52250
    },
    {
      "epoch": 4.459424865602867,
      "grad_norm": 0.38888949155807495,
      "learning_rate": 2.7702875671985668e-05,
      "loss": 0.002,
      "step": 52260
    },
    {
      "epoch": 4.4602781807321445,
      "grad_norm": 0.3915341794490814,
      "learning_rate": 2.769860909633928e-05,
      "loss": 0.0023,
      "step": 52270
    },
    {
      "epoch": 4.461131495861421,
      "grad_norm": 0.18669134378433228,
      "learning_rate": 2.7694342520692896e-05,
      "loss": 0.0023,
      "step": 52280
    },
    {
      "epoch": 4.461984810990699,
      "grad_norm": 0.5558825731277466,
      "learning_rate": 2.7690075945046507e-05,
      "loss": 0.0017,
      "step": 52290
    },
    {
      "epoch": 4.462838126119976,
      "grad_norm": 0.18602074682712555,
      "learning_rate": 2.7685809369400125e-05,
      "loss": 0.0012,
      "step": 52300
    },
    {
      "epoch": 4.463691441249253,
      "grad_norm": 0.11546957492828369,
      "learning_rate": 2.7681542793753735e-05,
      "loss": 0.0022,
      "step": 52310
    },
    {
      "epoch": 4.4645447563785305,
      "grad_norm": 0.3545609414577484,
      "learning_rate": 2.767727621810735e-05,
      "loss": 0.002,
      "step": 52320
    },
    {
      "epoch": 4.465398071507808,
      "grad_norm": 0.16140830516815186,
      "learning_rate": 2.767300964246096e-05,
      "loss": 0.0014,
      "step": 52330
    },
    {
      "epoch": 4.466251386637085,
      "grad_norm": 0.2562629282474518,
      "learning_rate": 2.7668743066814578e-05,
      "loss": 0.0021,
      "step": 52340
    },
    {
      "epoch": 4.467104701766362,
      "grad_norm": 0.04273824393749237,
      "learning_rate": 2.766447649116819e-05,
      "loss": 0.0015,
      "step": 52350
    },
    {
      "epoch": 4.46795801689564,
      "grad_norm": 0.17289429903030396,
      "learning_rate": 2.76602099155218e-05,
      "loss": 0.002,
      "step": 52360
    },
    {
      "epoch": 4.4688113320249165,
      "grad_norm": 0.3816326856613159,
      "learning_rate": 2.7655943339875417e-05,
      "loss": 0.0017,
      "step": 52370
    },
    {
      "epoch": 4.469664647154194,
      "grad_norm": 0.05274202302098274,
      "learning_rate": 2.7651676764229028e-05,
      "loss": 0.0019,
      "step": 52380
    },
    {
      "epoch": 4.470517962283472,
      "grad_norm": 0.22378948330879211,
      "learning_rate": 2.7647410188582646e-05,
      "loss": 0.0021,
      "step": 52390
    },
    {
      "epoch": 4.471371277412748,
      "grad_norm": 0.040532149374485016,
      "learning_rate": 2.7643143612936257e-05,
      "loss": 0.002,
      "step": 52400
    },
    {
      "epoch": 4.472224592542026,
      "grad_norm": 0.2563496530056,
      "learning_rate": 2.7638877037289874e-05,
      "loss": 0.0018,
      "step": 52410
    },
    {
      "epoch": 4.473077907671303,
      "grad_norm": 0.27853769063949585,
      "learning_rate": 2.7634610461643485e-05,
      "loss": 0.0017,
      "step": 52420
    },
    {
      "epoch": 4.47393122280058,
      "grad_norm": 0.09017125517129898,
      "learning_rate": 2.76303438859971e-05,
      "loss": 0.0016,
      "step": 52430
    },
    {
      "epoch": 4.474784537929858,
      "grad_norm": 0.47848549485206604,
      "learning_rate": 2.762607731035071e-05,
      "loss": 0.0023,
      "step": 52440
    },
    {
      "epoch": 4.475637853059135,
      "grad_norm": 0.13457250595092773,
      "learning_rate": 2.7621810734704328e-05,
      "loss": 0.002,
      "step": 52450
    },
    {
      "epoch": 4.476491168188412,
      "grad_norm": 0.1936158388853073,
      "learning_rate": 2.761754415905794e-05,
      "loss": 0.002,
      "step": 52460
    },
    {
      "epoch": 4.477344483317689,
      "grad_norm": 0.10651349276304245,
      "learning_rate": 2.7613277583411556e-05,
      "loss": 0.002,
      "step": 52470
    },
    {
      "epoch": 4.478197798446966,
      "grad_norm": 0.27737098932266235,
      "learning_rate": 2.7609011007765167e-05,
      "loss": 0.0019,
      "step": 52480
    },
    {
      "epoch": 4.479051113576244,
      "grad_norm": 0.09813610464334488,
      "learning_rate": 2.7604744432118785e-05,
      "loss": 0.0018,
      "step": 52490
    },
    {
      "epoch": 4.479904428705521,
      "grad_norm": 0.2621135115623474,
      "learning_rate": 2.7600477856472396e-05,
      "loss": 0.002,
      "step": 52500
    },
    {
      "epoch": 4.480757743834798,
      "grad_norm": 0.35305073857307434,
      "learning_rate": 2.7596211280826013e-05,
      "loss": 0.0022,
      "step": 52510
    },
    {
      "epoch": 4.481611058964075,
      "grad_norm": 0.0936649814248085,
      "learning_rate": 2.7591944705179624e-05,
      "loss": 0.0017,
      "step": 52520
    },
    {
      "epoch": 4.482464374093353,
      "grad_norm": 0.15179391205310822,
      "learning_rate": 2.758767812953324e-05,
      "loss": 0.0018,
      "step": 52530
    },
    {
      "epoch": 4.48331768922263,
      "grad_norm": 0.16714099049568176,
      "learning_rate": 2.758341155388685e-05,
      "loss": 0.0017,
      "step": 52540
    },
    {
      "epoch": 4.484171004351907,
      "grad_norm": 0.09508951008319855,
      "learning_rate": 2.7579144978240467e-05,
      "loss": 0.0021,
      "step": 52550
    },
    {
      "epoch": 4.485024319481185,
      "grad_norm": 0.11455190181732178,
      "learning_rate": 2.7574878402594078e-05,
      "loss": 0.0017,
      "step": 52560
    },
    {
      "epoch": 4.485877634610461,
      "grad_norm": 0.10454878956079483,
      "learning_rate": 2.7570611826947695e-05,
      "loss": 0.0021,
      "step": 52570
    },
    {
      "epoch": 4.486730949739739,
      "grad_norm": 0.306297242641449,
      "learning_rate": 2.7566345251301306e-05,
      "loss": 0.0018,
      "step": 52580
    },
    {
      "epoch": 4.4875842648690165,
      "grad_norm": 0.4268486797809601,
      "learning_rate": 2.7562078675654924e-05,
      "loss": 0.0021,
      "step": 52590
    },
    {
      "epoch": 4.488437579998293,
      "grad_norm": 0.2209213525056839,
      "learning_rate": 2.7557812100008535e-05,
      "loss": 0.002,
      "step": 52600
    },
    {
      "epoch": 4.489290895127571,
      "grad_norm": 0.2644399404525757,
      "learning_rate": 2.7553545524362152e-05,
      "loss": 0.0018,
      "step": 52610
    },
    {
      "epoch": 4.490144210256847,
      "grad_norm": 0.10435865819454193,
      "learning_rate": 2.7549278948715763e-05,
      "loss": 0.0018,
      "step": 52620
    },
    {
      "epoch": 4.490997525386125,
      "grad_norm": 0.13479793071746826,
      "learning_rate": 2.7545012373069374e-05,
      "loss": 0.0019,
      "step": 52630
    },
    {
      "epoch": 4.4918508405154025,
      "grad_norm": 0.32736435532569885,
      "learning_rate": 2.754074579742299e-05,
      "loss": 0.0017,
      "step": 52640
    },
    {
      "epoch": 4.492704155644679,
      "grad_norm": 0.07888521999120712,
      "learning_rate": 2.7536479221776603e-05,
      "loss": 0.0018,
      "step": 52650
    },
    {
      "epoch": 4.493557470773957,
      "grad_norm": 0.1312655806541443,
      "learning_rate": 2.7532212646130217e-05,
      "loss": 0.0016,
      "step": 52660
    },
    {
      "epoch": 4.494410785903234,
      "grad_norm": 0.3282581567764282,
      "learning_rate": 2.7527946070483828e-05,
      "loss": 0.0019,
      "step": 52670
    },
    {
      "epoch": 4.495264101032511,
      "grad_norm": 0.29984042048454285,
      "learning_rate": 2.7523679494837445e-05,
      "loss": 0.0014,
      "step": 52680
    },
    {
      "epoch": 4.4961174161617885,
      "grad_norm": 0.40917351841926575,
      "learning_rate": 2.7519412919191056e-05,
      "loss": 0.0023,
      "step": 52690
    },
    {
      "epoch": 4.496970731291066,
      "grad_norm": 0.07740600407123566,
      "learning_rate": 2.7515146343544674e-05,
      "loss": 0.0023,
      "step": 52700
    },
    {
      "epoch": 4.497824046420343,
      "grad_norm": 0.11514908820390701,
      "learning_rate": 2.7510879767898285e-05,
      "loss": 0.0017,
      "step": 52710
    },
    {
      "epoch": 4.49867736154962,
      "grad_norm": 0.1494695246219635,
      "learning_rate": 2.7506613192251902e-05,
      "loss": 0.0015,
      "step": 52720
    },
    {
      "epoch": 4.499530676678898,
      "grad_norm": 0.10237382352352142,
      "learning_rate": 2.7502346616605513e-05,
      "loss": 0.0016,
      "step": 52730
    },
    {
      "epoch": 4.5003839918081745,
      "grad_norm": 0.044608816504478455,
      "learning_rate": 2.7498080040959127e-05,
      "loss": 0.0018,
      "step": 52740
    },
    {
      "epoch": 4.501237306937452,
      "grad_norm": 0.32069024443626404,
      "learning_rate": 2.749381346531274e-05,
      "loss": 0.0019,
      "step": 52750
    },
    {
      "epoch": 4.50209062206673,
      "grad_norm": 0.15119127929210663,
      "learning_rate": 2.7489546889666356e-05,
      "loss": 0.0025,
      "step": 52760
    },
    {
      "epoch": 4.502943937196006,
      "grad_norm": 0.38800594210624695,
      "learning_rate": 2.7485280314019967e-05,
      "loss": 0.0018,
      "step": 52770
    },
    {
      "epoch": 4.503797252325284,
      "grad_norm": 0.4648456275463104,
      "learning_rate": 2.7481013738373584e-05,
      "loss": 0.0021,
      "step": 52780
    },
    {
      "epoch": 4.504650567454561,
      "grad_norm": 0.035161323845386505,
      "learning_rate": 2.7476747162727195e-05,
      "loss": 0.0018,
      "step": 52790
    },
    {
      "epoch": 4.505503882583838,
      "grad_norm": 0.0639161467552185,
      "learning_rate": 2.7472480587080813e-05,
      "loss": 0.0014,
      "step": 52800
    },
    {
      "epoch": 4.506357197713116,
      "grad_norm": 0.2957533597946167,
      "learning_rate": 2.7468214011434424e-05,
      "loss": 0.0017,
      "step": 52810
    },
    {
      "epoch": 4.507210512842393,
      "grad_norm": 0.1665860265493393,
      "learning_rate": 2.746394743578804e-05,
      "loss": 0.0016,
      "step": 52820
    },
    {
      "epoch": 4.50806382797167,
      "grad_norm": 0.5549971461296082,
      "learning_rate": 2.7459680860141652e-05,
      "loss": 0.0016,
      "step": 52830
    },
    {
      "epoch": 4.508917143100947,
      "grad_norm": 0.16460859775543213,
      "learning_rate": 2.7455414284495266e-05,
      "loss": 0.002,
      "step": 52840
    },
    {
      "epoch": 4.509770458230224,
      "grad_norm": 0.15301227569580078,
      "learning_rate": 2.7451147708848877e-05,
      "loss": 0.0024,
      "step": 52850
    },
    {
      "epoch": 4.510623773359502,
      "grad_norm": 0.0538625493645668,
      "learning_rate": 2.7446881133202495e-05,
      "loss": 0.0017,
      "step": 52860
    },
    {
      "epoch": 4.511477088488779,
      "grad_norm": 0.06201358512043953,
      "learning_rate": 2.7442614557556106e-05,
      "loss": 0.0019,
      "step": 52870
    },
    {
      "epoch": 4.512330403618056,
      "grad_norm": 0.11256962269544601,
      "learning_rate": 2.7438347981909723e-05,
      "loss": 0.0014,
      "step": 52880
    },
    {
      "epoch": 4.513183718747333,
      "grad_norm": 0.3657532334327698,
      "learning_rate": 2.7434081406263334e-05,
      "loss": 0.0018,
      "step": 52890
    },
    {
      "epoch": 4.514037033876611,
      "grad_norm": 0.11024884134531021,
      "learning_rate": 2.7429814830616945e-05,
      "loss": 0.002,
      "step": 52900
    },
    {
      "epoch": 4.514890349005888,
      "grad_norm": 0.13311702013015747,
      "learning_rate": 2.7425548254970563e-05,
      "loss": 0.0015,
      "step": 52910
    },
    {
      "epoch": 4.515743664135165,
      "grad_norm": 0.23731327056884766,
      "learning_rate": 2.7421281679324174e-05,
      "loss": 0.0018,
      "step": 52920
    },
    {
      "epoch": 4.516596979264443,
      "grad_norm": 0.20578105747699738,
      "learning_rate": 2.741701510367779e-05,
      "loss": 0.0022,
      "step": 52930
    },
    {
      "epoch": 4.517450294393719,
      "grad_norm": 0.057228535413742065,
      "learning_rate": 2.7412748528031402e-05,
      "loss": 0.0017,
      "step": 52940
    },
    {
      "epoch": 4.518303609522997,
      "grad_norm": 0.062154728919267654,
      "learning_rate": 2.7408481952385016e-05,
      "loss": 0.0019,
      "step": 52950
    },
    {
      "epoch": 4.519156924652274,
      "grad_norm": 0.21167391538619995,
      "learning_rate": 2.740421537673863e-05,
      "loss": 0.0021,
      "step": 52960
    },
    {
      "epoch": 4.520010239781551,
      "grad_norm": 0.03440846875309944,
      "learning_rate": 2.7399948801092245e-05,
      "loss": 0.0019,
      "step": 52970
    },
    {
      "epoch": 4.520863554910829,
      "grad_norm": 0.04671819508075714,
      "learning_rate": 2.7395682225445856e-05,
      "loss": 0.002,
      "step": 52980
    },
    {
      "epoch": 4.521716870040105,
      "grad_norm": 0.13398270308971405,
      "learning_rate": 2.7391415649799473e-05,
      "loss": 0.0017,
      "step": 52990
    },
    {
      "epoch": 4.522570185169383,
      "grad_norm": 0.11811433732509613,
      "learning_rate": 2.7387149074153084e-05,
      "loss": 0.0017,
      "step": 53000
    },
    {
      "epoch": 4.5234235002986605,
      "grad_norm": 0.23680856823921204,
      "learning_rate": 2.7382882498506702e-05,
      "loss": 0.0022,
      "step": 53010
    },
    {
      "epoch": 4.524276815427937,
      "grad_norm": 0.28238236904144287,
      "learning_rate": 2.7378615922860313e-05,
      "loss": 0.0018,
      "step": 53020
    },
    {
      "epoch": 4.525130130557215,
      "grad_norm": 0.033280983567237854,
      "learning_rate": 2.737434934721393e-05,
      "loss": 0.0021,
      "step": 53030
    },
    {
      "epoch": 4.525983445686492,
      "grad_norm": 0.303372323513031,
      "learning_rate": 2.737008277156754e-05,
      "loss": 0.0016,
      "step": 53040
    },
    {
      "epoch": 4.526836760815769,
      "grad_norm": 0.24101237952709198,
      "learning_rate": 2.7365816195921155e-05,
      "loss": 0.0018,
      "step": 53050
    },
    {
      "epoch": 4.5276900759450465,
      "grad_norm": 0.28332361578941345,
      "learning_rate": 2.736154962027477e-05,
      "loss": 0.0017,
      "step": 53060
    },
    {
      "epoch": 4.528543391074324,
      "grad_norm": 0.2420172393321991,
      "learning_rate": 2.7357283044628384e-05,
      "loss": 0.0024,
      "step": 53070
    },
    {
      "epoch": 4.529396706203601,
      "grad_norm": 0.4382069408893585,
      "learning_rate": 2.7353016468981995e-05,
      "loss": 0.0018,
      "step": 53080
    },
    {
      "epoch": 4.530250021332878,
      "grad_norm": 0.02869609370827675,
      "learning_rate": 2.7348749893335612e-05,
      "loss": 0.0017,
      "step": 53090
    },
    {
      "epoch": 4.531103336462156,
      "grad_norm": 0.033506810665130615,
      "learning_rate": 2.7344483317689223e-05,
      "loss": 0.0017,
      "step": 53100
    },
    {
      "epoch": 4.5319566515914325,
      "grad_norm": 0.36591094732284546,
      "learning_rate": 2.734021674204284e-05,
      "loss": 0.0017,
      "step": 53110
    },
    {
      "epoch": 4.53280996672071,
      "grad_norm": 0.2227208912372589,
      "learning_rate": 2.733595016639645e-05,
      "loss": 0.0026,
      "step": 53120
    },
    {
      "epoch": 4.533663281849988,
      "grad_norm": 0.6083628535270691,
      "learning_rate": 2.733168359075007e-05,
      "loss": 0.0019,
      "step": 53130
    },
    {
      "epoch": 4.534516596979264,
      "grad_norm": 0.06773200631141663,
      "learning_rate": 2.732741701510368e-05,
      "loss": 0.0022,
      "step": 53140
    },
    {
      "epoch": 4.535369912108542,
      "grad_norm": 0.06044920161366463,
      "learning_rate": 2.732315043945729e-05,
      "loss": 0.0015,
      "step": 53150
    },
    {
      "epoch": 4.536223227237819,
      "grad_norm": 0.10577376186847687,
      "learning_rate": 2.7318883863810905e-05,
      "loss": 0.0027,
      "step": 53160
    },
    {
      "epoch": 4.537076542367096,
      "grad_norm": 0.04709711670875549,
      "learning_rate": 2.731461728816452e-05,
      "loss": 0.0016,
      "step": 53170
    },
    {
      "epoch": 4.537929857496374,
      "grad_norm": 0.5365968942642212,
      "learning_rate": 2.7310350712518134e-05,
      "loss": 0.002,
      "step": 53180
    },
    {
      "epoch": 4.538783172625651,
      "grad_norm": 0.030906138941645622,
      "learning_rate": 2.7306084136871745e-05,
      "loss": 0.002,
      "step": 53190
    },
    {
      "epoch": 4.539636487754928,
      "grad_norm": 0.19037534296512604,
      "learning_rate": 2.7301817561225362e-05,
      "loss": 0.0018,
      "step": 53200
    },
    {
      "epoch": 4.540489802884205,
      "grad_norm": 0.2032902091741562,
      "learning_rate": 2.7297550985578973e-05,
      "loss": 0.002,
      "step": 53210
    },
    {
      "epoch": 4.541343118013482,
      "grad_norm": 0.18601156771183014,
      "learning_rate": 2.729328440993259e-05,
      "loss": 0.0016,
      "step": 53220
    },
    {
      "epoch": 4.54219643314276,
      "grad_norm": 0.4442594647407532,
      "learning_rate": 2.72890178342862e-05,
      "loss": 0.0017,
      "step": 53230
    },
    {
      "epoch": 4.543049748272037,
      "grad_norm": 0.3135019540786743,
      "learning_rate": 2.728475125863982e-05,
      "loss": 0.0014,
      "step": 53240
    },
    {
      "epoch": 4.543903063401314,
      "grad_norm": 0.22119343280792236,
      "learning_rate": 2.728048468299343e-05,
      "loss": 0.0017,
      "step": 53250
    },
    {
      "epoch": 4.544756378530591,
      "grad_norm": 0.4352971911430359,
      "learning_rate": 2.7276218107347044e-05,
      "loss": 0.002,
      "step": 53260
    },
    {
      "epoch": 4.545609693659869,
      "grad_norm": 0.06523672491312027,
      "learning_rate": 2.727195153170066e-05,
      "loss": 0.0023,
      "step": 53270
    },
    {
      "epoch": 4.5464630087891456,
      "grad_norm": 0.1700923591852188,
      "learning_rate": 2.7267684956054273e-05,
      "loss": 0.0015,
      "step": 53280
    },
    {
      "epoch": 4.547316323918423,
      "grad_norm": 0.2803715765476227,
      "learning_rate": 2.7263418380407884e-05,
      "loss": 0.0026,
      "step": 53290
    },
    {
      "epoch": 4.548169639047701,
      "grad_norm": 0.15026162564754486,
      "learning_rate": 2.72591518047615e-05,
      "loss": 0.0019,
      "step": 53300
    },
    {
      "epoch": 4.549022954176977,
      "grad_norm": 0.33369243144989014,
      "learning_rate": 2.7254885229115112e-05,
      "loss": 0.002,
      "step": 53310
    },
    {
      "epoch": 4.549876269306255,
      "grad_norm": 0.14758680760860443,
      "learning_rate": 2.725061865346873e-05,
      "loss": 0.0019,
      "step": 53320
    },
    {
      "epoch": 4.5507295844355315,
      "grad_norm": 0.16534297168254852,
      "learning_rate": 2.724635207782234e-05,
      "loss": 0.0019,
      "step": 53330
    },
    {
      "epoch": 4.551582899564809,
      "grad_norm": 0.05839937925338745,
      "learning_rate": 2.7242085502175958e-05,
      "loss": 0.0022,
      "step": 53340
    },
    {
      "epoch": 4.552436214694087,
      "grad_norm": 0.3914787471294403,
      "learning_rate": 2.723781892652957e-05,
      "loss": 0.0019,
      "step": 53350
    },
    {
      "epoch": 4.553289529823363,
      "grad_norm": 0.04271543771028519,
      "learning_rate": 2.7233552350883183e-05,
      "loss": 0.0019,
      "step": 53360
    },
    {
      "epoch": 4.554142844952641,
      "grad_norm": 0.22918416559696198,
      "learning_rate": 2.7229285775236797e-05,
      "loss": 0.0018,
      "step": 53370
    },
    {
      "epoch": 4.554996160081918,
      "grad_norm": 0.31372392177581787,
      "learning_rate": 2.7225019199590412e-05,
      "loss": 0.0018,
      "step": 53380
    },
    {
      "epoch": 4.555849475211195,
      "grad_norm": 0.05063656345009804,
      "learning_rate": 2.7220752623944023e-05,
      "loss": 0.0023,
      "step": 53390
    },
    {
      "epoch": 4.556702790340473,
      "grad_norm": 0.135277658700943,
      "learning_rate": 2.721648604829764e-05,
      "loss": 0.0018,
      "step": 53400
    },
    {
      "epoch": 4.55755610546975,
      "grad_norm": 0.19199083745479584,
      "learning_rate": 2.721221947265125e-05,
      "loss": 0.0021,
      "step": 53410
    },
    {
      "epoch": 4.558409420599027,
      "grad_norm": 0.2771718204021454,
      "learning_rate": 2.7207952897004862e-05,
      "loss": 0.0014,
      "step": 53420
    },
    {
      "epoch": 4.559262735728304,
      "grad_norm": 0.043655164539813995,
      "learning_rate": 2.720368632135848e-05,
      "loss": 0.0018,
      "step": 53430
    },
    {
      "epoch": 4.560116050857582,
      "grad_norm": 0.593120276927948,
      "learning_rate": 2.719941974571209e-05,
      "loss": 0.0017,
      "step": 53440
    },
    {
      "epoch": 4.560969365986859,
      "grad_norm": 0.047050852328538895,
      "learning_rate": 2.7195153170065708e-05,
      "loss": 0.0021,
      "step": 53450
    },
    {
      "epoch": 4.561822681116136,
      "grad_norm": 0.15050986409187317,
      "learning_rate": 2.719088659441932e-05,
      "loss": 0.002,
      "step": 53460
    },
    {
      "epoch": 4.562675996245414,
      "grad_norm": 0.06665874272584915,
      "learning_rate": 2.7186620018772933e-05,
      "loss": 0.0019,
      "step": 53470
    },
    {
      "epoch": 4.56352931137469,
      "grad_norm": 0.14951573312282562,
      "learning_rate": 2.7182353443126547e-05,
      "loss": 0.0018,
      "step": 53480
    },
    {
      "epoch": 4.564382626503968,
      "grad_norm": 0.08506932109594345,
      "learning_rate": 2.717808686748016e-05,
      "loss": 0.002,
      "step": 53490
    },
    {
      "epoch": 4.5652359416332455,
      "grad_norm": 0.033502835780382156,
      "learning_rate": 2.7173820291833772e-05,
      "loss": 0.0018,
      "step": 53500
    },
    {
      "epoch": 4.566089256762522,
      "grad_norm": 0.18367300927639008,
      "learning_rate": 2.716955371618739e-05,
      "loss": 0.0023,
      "step": 53510
    },
    {
      "epoch": 4.5669425718918,
      "grad_norm": 0.42816802859306335,
      "learning_rate": 2.7165287140541e-05,
      "loss": 0.0022,
      "step": 53520
    },
    {
      "epoch": 4.567795887021077,
      "grad_norm": 0.03552525117993355,
      "learning_rate": 2.716102056489462e-05,
      "loss": 0.0021,
      "step": 53530
    },
    {
      "epoch": 4.568649202150354,
      "grad_norm": 0.3677574098110199,
      "learning_rate": 2.715675398924823e-05,
      "loss": 0.0017,
      "step": 53540
    },
    {
      "epoch": 4.5695025172796315,
      "grad_norm": 0.2464991807937622,
      "learning_rate": 2.7152487413601847e-05,
      "loss": 0.0021,
      "step": 53550
    },
    {
      "epoch": 4.570355832408909,
      "grad_norm": 0.1003403291106224,
      "learning_rate": 2.7148220837955458e-05,
      "loss": 0.0018,
      "step": 53560
    },
    {
      "epoch": 4.571209147538186,
      "grad_norm": 0.12052518874406815,
      "learning_rate": 2.7143954262309072e-05,
      "loss": 0.0018,
      "step": 53570
    },
    {
      "epoch": 4.572062462667463,
      "grad_norm": 0.3488575220108032,
      "learning_rate": 2.7139687686662686e-05,
      "loss": 0.0016,
      "step": 53580
    },
    {
      "epoch": 4.57291577779674,
      "grad_norm": 0.10436023771762848,
      "learning_rate": 2.71354211110163e-05,
      "loss": 0.0021,
      "step": 53590
    },
    {
      "epoch": 4.5737690929260175,
      "grad_norm": 0.18377096951007843,
      "learning_rate": 2.713115453536991e-05,
      "loss": 0.0015,
      "step": 53600
    },
    {
      "epoch": 4.574622408055295,
      "grad_norm": 0.03542939946055412,
      "learning_rate": 2.712688795972353e-05,
      "loss": 0.0019,
      "step": 53610
    },
    {
      "epoch": 4.575475723184572,
      "grad_norm": 0.09348681569099426,
      "learning_rate": 2.712262138407714e-05,
      "loss": 0.0019,
      "step": 53620
    },
    {
      "epoch": 4.576329038313849,
      "grad_norm": 0.08064129948616028,
      "learning_rate": 2.7118354808430758e-05,
      "loss": 0.0016,
      "step": 53630
    },
    {
      "epoch": 4.577182353443127,
      "grad_norm": 0.4681767523288727,
      "learning_rate": 2.711408823278437e-05,
      "loss": 0.0019,
      "step": 53640
    },
    {
      "epoch": 4.5780356685724035,
      "grad_norm": 0.15230964124202728,
      "learning_rate": 2.7109821657137986e-05,
      "loss": 0.0017,
      "step": 53650
    },
    {
      "epoch": 4.578888983701681,
      "grad_norm": 0.031140442937612534,
      "learning_rate": 2.7105555081491597e-05,
      "loss": 0.0019,
      "step": 53660
    },
    {
      "epoch": 4.579742298830959,
      "grad_norm": 0.11539196223020554,
      "learning_rate": 2.710128850584521e-05,
      "loss": 0.002,
      "step": 53670
    },
    {
      "epoch": 4.580595613960235,
      "grad_norm": 0.07524478435516357,
      "learning_rate": 2.7097021930198825e-05,
      "loss": 0.0018,
      "step": 53680
    },
    {
      "epoch": 4.581448929089513,
      "grad_norm": 0.03388139232993126,
      "learning_rate": 2.7092755354552436e-05,
      "loss": 0.0019,
      "step": 53690
    },
    {
      "epoch": 4.5823022442187895,
      "grad_norm": 0.430683434009552,
      "learning_rate": 2.708848877890605e-05,
      "loss": 0.0016,
      "step": 53700
    },
    {
      "epoch": 4.583155559348067,
      "grad_norm": 0.06418740004301071,
      "learning_rate": 2.708422220325966e-05,
      "loss": 0.0016,
      "step": 53710
    },
    {
      "epoch": 4.584008874477345,
      "grad_norm": 0.09679075330495834,
      "learning_rate": 2.707995562761328e-05,
      "loss": 0.0017,
      "step": 53720
    },
    {
      "epoch": 4.584862189606621,
      "grad_norm": 0.05736159533262253,
      "learning_rate": 2.707568905196689e-05,
      "loss": 0.0019,
      "step": 53730
    },
    {
      "epoch": 4.585715504735899,
      "grad_norm": 0.08134133368730545,
      "learning_rate": 2.7071422476320507e-05,
      "loss": 0.0017,
      "step": 53740
    },
    {
      "epoch": 4.586568819865176,
      "grad_norm": 0.32188352942466736,
      "learning_rate": 2.7067155900674118e-05,
      "loss": 0.0014,
      "step": 53750
    },
    {
      "epoch": 4.587422134994453,
      "grad_norm": 0.08515719324350357,
      "learning_rate": 2.7062889325027736e-05,
      "loss": 0.0022,
      "step": 53760
    },
    {
      "epoch": 4.588275450123731,
      "grad_norm": 0.047357041388750076,
      "learning_rate": 2.7058622749381347e-05,
      "loss": 0.002,
      "step": 53770
    },
    {
      "epoch": 4.589128765253008,
      "grad_norm": 0.13933703303337097,
      "learning_rate": 2.705435617373496e-05,
      "loss": 0.0018,
      "step": 53780
    },
    {
      "epoch": 4.589982080382285,
      "grad_norm": 0.14624476432800293,
      "learning_rate": 2.7050089598088575e-05,
      "loss": 0.002,
      "step": 53790
    },
    {
      "epoch": 4.590835395511562,
      "grad_norm": 0.05644051358103752,
      "learning_rate": 2.704582302244219e-05,
      "loss": 0.0018,
      "step": 53800
    },
    {
      "epoch": 4.59168871064084,
      "grad_norm": 0.12164623290300369,
      "learning_rate": 2.70415564467958e-05,
      "loss": 0.002,
      "step": 53810
    },
    {
      "epoch": 4.592542025770117,
      "grad_norm": 0.31465306878089905,
      "learning_rate": 2.7037289871149418e-05,
      "loss": 0.0023,
      "step": 53820
    },
    {
      "epoch": 4.593395340899394,
      "grad_norm": 0.28022199869155884,
      "learning_rate": 2.703302329550303e-05,
      "loss": 0.0019,
      "step": 53830
    },
    {
      "epoch": 4.594248656028672,
      "grad_norm": 0.3512585163116455,
      "learning_rate": 2.7028756719856646e-05,
      "loss": 0.002,
      "step": 53840
    },
    {
      "epoch": 4.595101971157948,
      "grad_norm": 0.31326961517333984,
      "learning_rate": 2.7024490144210257e-05,
      "loss": 0.0018,
      "step": 53850
    },
    {
      "epoch": 4.595955286287226,
      "grad_norm": 0.38073816895484924,
      "learning_rate": 2.7020223568563875e-05,
      "loss": 0.002,
      "step": 53860
    },
    {
      "epoch": 4.5968086014165035,
      "grad_norm": 0.03171147033572197,
      "learning_rate": 2.7015956992917486e-05,
      "loss": 0.0019,
      "step": 53870
    },
    {
      "epoch": 4.59766191654578,
      "grad_norm": 0.21871820092201233,
      "learning_rate": 2.70116904172711e-05,
      "loss": 0.0021,
      "step": 53880
    },
    {
      "epoch": 4.598515231675058,
      "grad_norm": 0.032159194350242615,
      "learning_rate": 2.7007423841624714e-05,
      "loss": 0.0019,
      "step": 53890
    },
    {
      "epoch": 4.599368546804335,
      "grad_norm": 0.05350618064403534,
      "learning_rate": 2.700315726597833e-05,
      "loss": 0.0022,
      "step": 53900
    },
    {
      "epoch": 4.600221861933612,
      "grad_norm": 0.11797697842121124,
      "learning_rate": 2.699889069033194e-05,
      "loss": 0.0016,
      "step": 53910
    },
    {
      "epoch": 4.6010751770628895,
      "grad_norm": 0.040641795843839645,
      "learning_rate": 2.6994624114685557e-05,
      "loss": 0.002,
      "step": 53920
    },
    {
      "epoch": 4.601928492192167,
      "grad_norm": 0.2928462326526642,
      "learning_rate": 2.6990357539039168e-05,
      "loss": 0.0024,
      "step": 53930
    },
    {
      "epoch": 4.602781807321444,
      "grad_norm": 0.0742027536034584,
      "learning_rate": 2.6986090963392785e-05,
      "loss": 0.0018,
      "step": 53940
    },
    {
      "epoch": 4.603635122450721,
      "grad_norm": 0.10307861864566803,
      "learning_rate": 2.6981824387746396e-05,
      "loss": 0.0021,
      "step": 53950
    },
    {
      "epoch": 4.604488437579998,
      "grad_norm": 0.1154514029622078,
      "learning_rate": 2.6977557812100007e-05,
      "loss": 0.0017,
      "step": 53960
    },
    {
      "epoch": 4.6053417527092755,
      "grad_norm": 0.18891267478466034,
      "learning_rate": 2.6973291236453625e-05,
      "loss": 0.0018,
      "step": 53970
    },
    {
      "epoch": 4.606195067838553,
      "grad_norm": 0.11386772245168686,
      "learning_rate": 2.6969024660807236e-05,
      "loss": 0.0018,
      "step": 53980
    },
    {
      "epoch": 4.60704838296783,
      "grad_norm": 0.15106749534606934,
      "learning_rate": 2.6964758085160853e-05,
      "loss": 0.0019,
      "step": 53990
    },
    {
      "epoch": 4.607901698097107,
      "grad_norm": 0.026991495862603188,
      "learning_rate": 2.6960491509514464e-05,
      "loss": 0.0017,
      "step": 54000
    },
    {
      "epoch": 4.608755013226385,
      "grad_norm": 0.06383037567138672,
      "learning_rate": 2.695622493386808e-05,
      "loss": 0.0017,
      "step": 54010
    },
    {
      "epoch": 4.6096083283556615,
      "grad_norm": 0.04397022724151611,
      "learning_rate": 2.695195835822169e-05,
      "loss": 0.0021,
      "step": 54020
    },
    {
      "epoch": 4.610461643484939,
      "grad_norm": 0.09780439734458923,
      "learning_rate": 2.6947691782575307e-05,
      "loss": 0.002,
      "step": 54030
    },
    {
      "epoch": 4.611314958614217,
      "grad_norm": 0.18904733657836914,
      "learning_rate": 2.6943425206928918e-05,
      "loss": 0.0019,
      "step": 54040
    },
    {
      "epoch": 4.612168273743493,
      "grad_norm": 0.2196754366159439,
      "learning_rate": 2.6939158631282535e-05,
      "loss": 0.0019,
      "step": 54050
    },
    {
      "epoch": 4.613021588872771,
      "grad_norm": 0.18746891617774963,
      "learning_rate": 2.6934892055636146e-05,
      "loss": 0.0017,
      "step": 54060
    },
    {
      "epoch": 4.6138749040020475,
      "grad_norm": 0.2521384060382843,
      "learning_rate": 2.6930625479989764e-05,
      "loss": 0.0022,
      "step": 54070
    },
    {
      "epoch": 4.614728219131325,
      "grad_norm": 0.11241934448480606,
      "learning_rate": 2.6926358904343375e-05,
      "loss": 0.0021,
      "step": 54080
    },
    {
      "epoch": 4.615581534260603,
      "grad_norm": 0.08352474123239517,
      "learning_rate": 2.692209232869699e-05,
      "loss": 0.0023,
      "step": 54090
    },
    {
      "epoch": 4.616434849389879,
      "grad_norm": 0.35342130064964294,
      "learning_rate": 2.6917825753050603e-05,
      "loss": 0.0018,
      "step": 54100
    },
    {
      "epoch": 4.617288164519157,
      "grad_norm": 0.06301677972078323,
      "learning_rate": 2.6913559177404217e-05,
      "loss": 0.0016,
      "step": 54110
    },
    {
      "epoch": 4.618141479648434,
      "grad_norm": 0.29951202869415283,
      "learning_rate": 2.6909292601757828e-05,
      "loss": 0.0022,
      "step": 54120
    },
    {
      "epoch": 4.618994794777711,
      "grad_norm": 0.37139472365379333,
      "learning_rate": 2.6905026026111446e-05,
      "loss": 0.0017,
      "step": 54130
    },
    {
      "epoch": 4.619848109906989,
      "grad_norm": 0.11111508309841156,
      "learning_rate": 2.6900759450465057e-05,
      "loss": 0.0016,
      "step": 54140
    },
    {
      "epoch": 4.620701425036266,
      "grad_norm": 0.031223582103848457,
      "learning_rate": 2.6896492874818674e-05,
      "loss": 0.0016,
      "step": 54150
    },
    {
      "epoch": 4.621554740165543,
      "grad_norm": 0.052431702613830566,
      "learning_rate": 2.6892226299172285e-05,
      "loss": 0.0023,
      "step": 54160
    },
    {
      "epoch": 4.62240805529482,
      "grad_norm": 0.23990367352962494,
      "learning_rate": 2.6887959723525903e-05,
      "loss": 0.0015,
      "step": 54170
    },
    {
      "epoch": 4.623261370424098,
      "grad_norm": 0.29532575607299805,
      "learning_rate": 2.6883693147879514e-05,
      "loss": 0.002,
      "step": 54180
    },
    {
      "epoch": 4.624114685553375,
      "grad_norm": 0.11696210503578186,
      "learning_rate": 2.6879426572233128e-05,
      "loss": 0.0015,
      "step": 54190
    },
    {
      "epoch": 4.624968000682652,
      "grad_norm": 0.3370225429534912,
      "learning_rate": 2.6875159996586742e-05,
      "loss": 0.0018,
      "step": 54200
    },
    {
      "epoch": 4.62582131581193,
      "grad_norm": 0.35758501291275024,
      "learning_rate": 2.6870893420940356e-05,
      "loss": 0.0015,
      "step": 54210
    },
    {
      "epoch": 4.626674630941206,
      "grad_norm": 0.14988981187343597,
      "learning_rate": 2.6866626845293967e-05,
      "loss": 0.0017,
      "step": 54220
    },
    {
      "epoch": 4.627527946070484,
      "grad_norm": 0.0995144322514534,
      "learning_rate": 2.6862360269647578e-05,
      "loss": 0.0018,
      "step": 54230
    },
    {
      "epoch": 4.6283812611997615,
      "grad_norm": 0.0982750803232193,
      "learning_rate": 2.6858093694001196e-05,
      "loss": 0.0022,
      "step": 54240
    },
    {
      "epoch": 4.629234576329038,
      "grad_norm": 0.04141771420836449,
      "learning_rate": 2.6853827118354807e-05,
      "loss": 0.0018,
      "step": 54250
    },
    {
      "epoch": 4.630087891458316,
      "grad_norm": 0.13186751306056976,
      "learning_rate": 2.6849560542708424e-05,
      "loss": 0.0022,
      "step": 54260
    },
    {
      "epoch": 4.630941206587593,
      "grad_norm": 0.04269510507583618,
      "learning_rate": 2.6845293967062035e-05,
      "loss": 0.002,
      "step": 54270
    },
    {
      "epoch": 4.63179452171687,
      "grad_norm": 0.3511856496334076,
      "learning_rate": 2.6841027391415653e-05,
      "loss": 0.0019,
      "step": 54280
    },
    {
      "epoch": 4.6326478368461474,
      "grad_norm": 0.12278706580400467,
      "learning_rate": 2.6836760815769264e-05,
      "loss": 0.0016,
      "step": 54290
    },
    {
      "epoch": 4.633501151975425,
      "grad_norm": 0.16699165105819702,
      "learning_rate": 2.683249424012288e-05,
      "loss": 0.0021,
      "step": 54300
    },
    {
      "epoch": 4.634354467104702,
      "grad_norm": 0.20420657098293304,
      "learning_rate": 2.6828227664476492e-05,
      "loss": 0.0018,
      "step": 54310
    },
    {
      "epoch": 4.635207782233979,
      "grad_norm": 0.18824604153633118,
      "learning_rate": 2.6823961088830106e-05,
      "loss": 0.0021,
      "step": 54320
    },
    {
      "epoch": 4.636061097363256,
      "grad_norm": 0.14935727417469025,
      "learning_rate": 2.6819694513183717e-05,
      "loss": 0.0019,
      "step": 54330
    },
    {
      "epoch": 4.636914412492533,
      "grad_norm": 0.04742901772260666,
      "learning_rate": 2.6815427937537335e-05,
      "loss": 0.0022,
      "step": 54340
    },
    {
      "epoch": 4.637767727621811,
      "grad_norm": 0.27741628885269165,
      "learning_rate": 2.6811161361890946e-05,
      "loss": 0.0017,
      "step": 54350
    },
    {
      "epoch": 4.638621042751088,
      "grad_norm": 0.2404101938009262,
      "learning_rate": 2.6806894786244563e-05,
      "loss": 0.0017,
      "step": 54360
    },
    {
      "epoch": 4.639474357880365,
      "grad_norm": 0.15729379653930664,
      "learning_rate": 2.6802628210598174e-05,
      "loss": 0.0021,
      "step": 54370
    },
    {
      "epoch": 4.640327673009643,
      "grad_norm": 0.2413341999053955,
      "learning_rate": 2.6798361634951792e-05,
      "loss": 0.0015,
      "step": 54380
    },
    {
      "epoch": 4.641180988138919,
      "grad_norm": 0.04460328444838524,
      "learning_rate": 2.6794095059305403e-05,
      "loss": 0.0019,
      "step": 54390
    },
    {
      "epoch": 4.642034303268197,
      "grad_norm": 0.03585250675678253,
      "learning_rate": 2.6789828483659017e-05,
      "loss": 0.0017,
      "step": 54400
    },
    {
      "epoch": 4.6428876183974745,
      "grad_norm": 0.4807686507701874,
      "learning_rate": 2.678556190801263e-05,
      "loss": 0.0021,
      "step": 54410
    },
    {
      "epoch": 4.643740933526751,
      "grad_norm": 0.04232874885201454,
      "learning_rate": 2.6781295332366245e-05,
      "loss": 0.0025,
      "step": 54420
    },
    {
      "epoch": 4.644594248656029,
      "grad_norm": 0.27081504464149475,
      "learning_rate": 2.6777028756719856e-05,
      "loss": 0.0016,
      "step": 54430
    },
    {
      "epoch": 4.645447563785305,
      "grad_norm": 0.29558315873146057,
      "learning_rate": 2.6772762181073474e-05,
      "loss": 0.0016,
      "step": 54440
    },
    {
      "epoch": 4.646300878914583,
      "grad_norm": 0.16689825057983398,
      "learning_rate": 2.6768495605427085e-05,
      "loss": 0.0014,
      "step": 54450
    },
    {
      "epoch": 4.6471541940438605,
      "grad_norm": 0.315593421459198,
      "learning_rate": 2.6764229029780702e-05,
      "loss": 0.0021,
      "step": 54460
    },
    {
      "epoch": 4.648007509173137,
      "grad_norm": 0.15958084166049957,
      "learning_rate": 2.6759962454134313e-05,
      "loss": 0.0018,
      "step": 54470
    },
    {
      "epoch": 4.648860824302415,
      "grad_norm": 0.13338898122310638,
      "learning_rate": 2.6755695878487924e-05,
      "loss": 0.0019,
      "step": 54480
    },
    {
      "epoch": 4.649714139431692,
      "grad_norm": 0.35050731897354126,
      "learning_rate": 2.675142930284154e-05,
      "loss": 0.0019,
      "step": 54490
    },
    {
      "epoch": 4.650567454560969,
      "grad_norm": 0.19201353192329407,
      "learning_rate": 2.6747162727195152e-05,
      "loss": 0.0017,
      "step": 54500
    },
    {
      "epoch": 4.6514207696902465,
      "grad_norm": 0.3732253909111023,
      "learning_rate": 2.674289615154877e-05,
      "loss": 0.0021,
      "step": 54510
    },
    {
      "epoch": 4.652274084819524,
      "grad_norm": 0.14397616684436798,
      "learning_rate": 2.673862957590238e-05,
      "loss": 0.0026,
      "step": 54520
    },
    {
      "epoch": 4.653127399948801,
      "grad_norm": 0.2960951626300812,
      "learning_rate": 2.6734363000255995e-05,
      "loss": 0.002,
      "step": 54530
    },
    {
      "epoch": 4.653980715078078,
      "grad_norm": 0.14818428456783295,
      "learning_rate": 2.6730096424609606e-05,
      "loss": 0.0018,
      "step": 54540
    },
    {
      "epoch": 4.654834030207356,
      "grad_norm": 0.5484971404075623,
      "learning_rate": 2.6725829848963224e-05,
      "loss": 0.0021,
      "step": 54550
    },
    {
      "epoch": 4.6556873453366325,
      "grad_norm": 0.33628004789352417,
      "learning_rate": 2.6721563273316835e-05,
      "loss": 0.0021,
      "step": 54560
    },
    {
      "epoch": 4.65654066046591,
      "grad_norm": 0.19119136035442352,
      "learning_rate": 2.6717296697670452e-05,
      "loss": 0.0019,
      "step": 54570
    },
    {
      "epoch": 4.657393975595188,
      "grad_norm": 0.2961421012878418,
      "learning_rate": 2.6713030122024063e-05,
      "loss": 0.0019,
      "step": 54580
    },
    {
      "epoch": 4.658247290724464,
      "grad_norm": 0.32181084156036377,
      "learning_rate": 2.670876354637768e-05,
      "loss": 0.0016,
      "step": 54590
    },
    {
      "epoch": 4.659100605853742,
      "grad_norm": 0.2242172807455063,
      "learning_rate": 2.670449697073129e-05,
      "loss": 0.0021,
      "step": 54600
    },
    {
      "epoch": 4.659953920983019,
      "grad_norm": 0.11583273857831955,
      "learning_rate": 2.670023039508491e-05,
      "loss": 0.0019,
      "step": 54610
    },
    {
      "epoch": 4.660807236112296,
      "grad_norm": 0.1156492754817009,
      "learning_rate": 2.669596381943852e-05,
      "loss": 0.0018,
      "step": 54620
    },
    {
      "epoch": 4.661660551241574,
      "grad_norm": 0.28115132451057434,
      "learning_rate": 2.6691697243792134e-05,
      "loss": 0.0021,
      "step": 54630
    },
    {
      "epoch": 4.662513866370851,
      "grad_norm": 0.03340392932295799,
      "learning_rate": 2.6687430668145745e-05,
      "loss": 0.0018,
      "step": 54640
    },
    {
      "epoch": 4.663367181500128,
      "grad_norm": 0.5116608142852783,
      "learning_rate": 2.6683164092499363e-05,
      "loss": 0.002,
      "step": 54650
    },
    {
      "epoch": 4.664220496629405,
      "grad_norm": 0.11214635521173477,
      "learning_rate": 2.6678897516852974e-05,
      "loss": 0.0017,
      "step": 54660
    },
    {
      "epoch": 4.665073811758683,
      "grad_norm": 0.21966862678527832,
      "learning_rate": 2.667463094120659e-05,
      "loss": 0.0022,
      "step": 54670
    },
    {
      "epoch": 4.66592712688796,
      "grad_norm": 0.2803293764591217,
      "learning_rate": 2.6670364365560202e-05,
      "loss": 0.0019,
      "step": 54680
    },
    {
      "epoch": 4.666780442017237,
      "grad_norm": 0.027118787169456482,
      "learning_rate": 2.666609778991382e-05,
      "loss": 0.002,
      "step": 54690
    },
    {
      "epoch": 4.667633757146514,
      "grad_norm": 0.08055323362350464,
      "learning_rate": 2.666183121426743e-05,
      "loss": 0.0015,
      "step": 54700
    },
    {
      "epoch": 4.668487072275791,
      "grad_norm": 0.4012223184108734,
      "learning_rate": 2.6657564638621048e-05,
      "loss": 0.0016,
      "step": 54710
    },
    {
      "epoch": 4.669340387405069,
      "grad_norm": 0.2815706729888916,
      "learning_rate": 2.665329806297466e-05,
      "loss": 0.0018,
      "step": 54720
    },
    {
      "epoch": 4.670193702534346,
      "grad_norm": 0.0256376713514328,
      "learning_rate": 2.6649031487328273e-05,
      "loss": 0.0018,
      "step": 54730
    },
    {
      "epoch": 4.671047017663623,
      "grad_norm": 0.06488779187202454,
      "learning_rate": 2.6644764911681884e-05,
      "loss": 0.0021,
      "step": 54740
    },
    {
      "epoch": 4.671900332792901,
      "grad_norm": 0.056485582143068314,
      "learning_rate": 2.6640498336035495e-05,
      "loss": 0.0013,
      "step": 54750
    },
    {
      "epoch": 4.672753647922177,
      "grad_norm": 0.33782392740249634,
      "learning_rate": 2.6636231760389113e-05,
      "loss": 0.0022,
      "step": 54760
    },
    {
      "epoch": 4.673606963051455,
      "grad_norm": 0.04964908957481384,
      "learning_rate": 2.6631965184742723e-05,
      "loss": 0.0013,
      "step": 54770
    },
    {
      "epoch": 4.6744602781807325,
      "grad_norm": 0.19433213770389557,
      "learning_rate": 2.662769860909634e-05,
      "loss": 0.0017,
      "step": 54780
    },
    {
      "epoch": 4.675313593310009,
      "grad_norm": 0.17008496820926666,
      "learning_rate": 2.6623432033449952e-05,
      "loss": 0.0018,
      "step": 54790
    },
    {
      "epoch": 4.676166908439287,
      "grad_norm": 0.35308218002319336,
      "learning_rate": 2.661916545780357e-05,
      "loss": 0.0016,
      "step": 54800
    },
    {
      "epoch": 4.677020223568563,
      "grad_norm": 0.23961862921714783,
      "learning_rate": 2.661489888215718e-05,
      "loss": 0.0018,
      "step": 54810
    },
    {
      "epoch": 4.677873538697841,
      "grad_norm": 0.15351331233978271,
      "learning_rate": 2.6610632306510798e-05,
      "loss": 0.0019,
      "step": 54820
    },
    {
      "epoch": 4.6787268538271185,
      "grad_norm": 0.09756237268447876,
      "learning_rate": 2.660636573086441e-05,
      "loss": 0.0022,
      "step": 54830
    },
    {
      "epoch": 4.679580168956395,
      "grad_norm": 0.23869521915912628,
      "learning_rate": 2.6602099155218023e-05,
      "loss": 0.002,
      "step": 54840
    },
    {
      "epoch": 4.680433484085673,
      "grad_norm": 0.06801854819059372,
      "learning_rate": 2.6597832579571634e-05,
      "loss": 0.0016,
      "step": 54850
    },
    {
      "epoch": 4.68128679921495,
      "grad_norm": 0.33571934700012207,
      "learning_rate": 2.659356600392525e-05,
      "loss": 0.0023,
      "step": 54860
    },
    {
      "epoch": 4.682140114344227,
      "grad_norm": 0.19844789803028107,
      "learning_rate": 2.6589299428278862e-05,
      "loss": 0.0016,
      "step": 54870
    },
    {
      "epoch": 4.6829934294735045,
      "grad_norm": 0.07745084911584854,
      "learning_rate": 2.658503285263248e-05,
      "loss": 0.0018,
      "step": 54880
    },
    {
      "epoch": 4.683846744602782,
      "grad_norm": 0.07764630019664764,
      "learning_rate": 2.658076627698609e-05,
      "loss": 0.002,
      "step": 54890
    },
    {
      "epoch": 4.684700059732059,
      "grad_norm": 0.07825670391321182,
      "learning_rate": 2.657649970133971e-05,
      "loss": 0.0019,
      "step": 54900
    },
    {
      "epoch": 4.685553374861336,
      "grad_norm": 0.5225803852081299,
      "learning_rate": 2.657223312569332e-05,
      "loss": 0.0019,
      "step": 54910
    },
    {
      "epoch": 4.686406689990614,
      "grad_norm": 0.14985370635986328,
      "learning_rate": 2.6567966550046937e-05,
      "loss": 0.0017,
      "step": 54920
    },
    {
      "epoch": 4.6872600051198905,
      "grad_norm": 0.07783547788858414,
      "learning_rate": 2.6563699974400548e-05,
      "loss": 0.0021,
      "step": 54930
    },
    {
      "epoch": 4.688113320249168,
      "grad_norm": 0.12546713650226593,
      "learning_rate": 2.6559433398754162e-05,
      "loss": 0.0018,
      "step": 54940
    },
    {
      "epoch": 4.688966635378446,
      "grad_norm": 0.15130038559436798,
      "learning_rate": 2.6555166823107773e-05,
      "loss": 0.002,
      "step": 54950
    },
    {
      "epoch": 4.689819950507722,
      "grad_norm": 0.15317678451538086,
      "learning_rate": 2.655090024746139e-05,
      "loss": 0.0016,
      "step": 54960
    },
    {
      "epoch": 4.690673265637,
      "grad_norm": 0.45937398076057434,
      "learning_rate": 2.6546633671815e-05,
      "loss": 0.0016,
      "step": 54970
    },
    {
      "epoch": 4.691526580766277,
      "grad_norm": 0.06275196373462677,
      "learning_rate": 2.654236709616862e-05,
      "loss": 0.0019,
      "step": 54980
    },
    {
      "epoch": 4.692379895895554,
      "grad_norm": 0.07412648946046829,
      "learning_rate": 2.653810052052223e-05,
      "loss": 0.0014,
      "step": 54990
    },
    {
      "epoch": 4.693233211024832,
      "grad_norm": 0.1823795586824417,
      "learning_rate": 2.6533833944875848e-05,
      "loss": 0.0017,
      "step": 55000
    },
    {
      "epoch": 4.694086526154109,
      "grad_norm": 0.29294759035110474,
      "learning_rate": 2.652956736922946e-05,
      "loss": 0.0017,
      "step": 55010
    },
    {
      "epoch": 4.694939841283386,
      "grad_norm": 0.1644378900527954,
      "learning_rate": 2.652530079358307e-05,
      "loss": 0.0017,
      "step": 55020
    },
    {
      "epoch": 4.695793156412663,
      "grad_norm": 0.29463571310043335,
      "learning_rate": 2.6521034217936687e-05,
      "loss": 0.0018,
      "step": 55030
    },
    {
      "epoch": 4.696646471541941,
      "grad_norm": 0.18536606431007385,
      "learning_rate": 2.6516767642290298e-05,
      "loss": 0.0016,
      "step": 55040
    },
    {
      "epoch": 4.697499786671218,
      "grad_norm": 0.18621504306793213,
      "learning_rate": 2.6512501066643912e-05,
      "loss": 0.0015,
      "step": 55050
    },
    {
      "epoch": 4.698353101800495,
      "grad_norm": 0.058226972818374634,
      "learning_rate": 2.6508234490997523e-05,
      "loss": 0.0018,
      "step": 55060
    },
    {
      "epoch": 4.699206416929772,
      "grad_norm": 0.38478103280067444,
      "learning_rate": 2.650396791535114e-05,
      "loss": 0.0023,
      "step": 55070
    },
    {
      "epoch": 4.700059732059049,
      "grad_norm": 0.38598203659057617,
      "learning_rate": 2.649970133970475e-05,
      "loss": 0.0018,
      "step": 55080
    },
    {
      "epoch": 4.700913047188327,
      "grad_norm": 0.24436238408088684,
      "learning_rate": 2.649543476405837e-05,
      "loss": 0.0016,
      "step": 55090
    },
    {
      "epoch": 4.701766362317604,
      "grad_norm": 0.2572336494922638,
      "learning_rate": 2.649116818841198e-05,
      "loss": 0.0019,
      "step": 55100
    },
    {
      "epoch": 4.702619677446881,
      "grad_norm": 0.20995622873306274,
      "learning_rate": 2.6486901612765597e-05,
      "loss": 0.0017,
      "step": 55110
    },
    {
      "epoch": 4.703472992576159,
      "grad_norm": 0.18207767605781555,
      "learning_rate": 2.648263503711921e-05,
      "loss": 0.0018,
      "step": 55120
    },
    {
      "epoch": 4.704326307705435,
      "grad_norm": 0.18407511711120605,
      "learning_rate": 2.6478368461472826e-05,
      "loss": 0.0022,
      "step": 55130
    },
    {
      "epoch": 4.705179622834713,
      "grad_norm": 0.5778548121452332,
      "learning_rate": 2.6474101885826437e-05,
      "loss": 0.0014,
      "step": 55140
    },
    {
      "epoch": 4.7060329379639905,
      "grad_norm": 0.6192561388015747,
      "learning_rate": 2.646983531018005e-05,
      "loss": 0.002,
      "step": 55150
    },
    {
      "epoch": 4.706886253093267,
      "grad_norm": 0.31528007984161377,
      "learning_rate": 2.6465568734533662e-05,
      "loss": 0.0016,
      "step": 55160
    },
    {
      "epoch": 4.707739568222545,
      "grad_norm": 0.06275167316198349,
      "learning_rate": 2.646130215888728e-05,
      "loss": 0.0019,
      "step": 55170
    },
    {
      "epoch": 4.708592883351821,
      "grad_norm": 0.29649895429611206,
      "learning_rate": 2.645703558324089e-05,
      "loss": 0.002,
      "step": 55180
    },
    {
      "epoch": 4.709446198481099,
      "grad_norm": 0.09740830212831497,
      "learning_rate": 2.6452769007594508e-05,
      "loss": 0.0017,
      "step": 55190
    },
    {
      "epoch": 4.7102995136103765,
      "grad_norm": 0.153199702501297,
      "learning_rate": 2.644850243194812e-05,
      "loss": 0.0015,
      "step": 55200
    },
    {
      "epoch": 4.711152828739653,
      "grad_norm": 0.2400810867547989,
      "learning_rate": 2.6444235856301736e-05,
      "loss": 0.002,
      "step": 55210
    },
    {
      "epoch": 4.712006143868931,
      "grad_norm": 0.38730868697166443,
      "learning_rate": 2.6439969280655347e-05,
      "loss": 0.0023,
      "step": 55220
    },
    {
      "epoch": 4.712859458998208,
      "grad_norm": 0.030089080333709717,
      "learning_rate": 2.6435702705008965e-05,
      "loss": 0.0023,
      "step": 55230
    },
    {
      "epoch": 4.713712774127485,
      "grad_norm": 0.18911951780319214,
      "learning_rate": 2.6431436129362576e-05,
      "loss": 0.0023,
      "step": 55240
    },
    {
      "epoch": 4.7145660892567625,
      "grad_norm": 0.25909700989723206,
      "learning_rate": 2.642716955371619e-05,
      "loss": 0.0019,
      "step": 55250
    },
    {
      "epoch": 4.71541940438604,
      "grad_norm": 0.06589118391275406,
      "learning_rate": 2.64229029780698e-05,
      "loss": 0.0015,
      "step": 55260
    },
    {
      "epoch": 4.716272719515317,
      "grad_norm": 0.02077741175889969,
      "learning_rate": 2.641863640242342e-05,
      "loss": 0.0018,
      "step": 55270
    },
    {
      "epoch": 4.717126034644594,
      "grad_norm": 0.12998715043067932,
      "learning_rate": 2.641436982677703e-05,
      "loss": 0.0017,
      "step": 55280
    },
    {
      "epoch": 4.717979349773872,
      "grad_norm": 0.2206570953130722,
      "learning_rate": 2.641010325113064e-05,
      "loss": 0.0015,
      "step": 55290
    },
    {
      "epoch": 4.7188326649031485,
      "grad_norm": 0.1128779724240303,
      "learning_rate": 2.6405836675484258e-05,
      "loss": 0.0019,
      "step": 55300
    },
    {
      "epoch": 4.719685980032426,
      "grad_norm": 0.05954313278198242,
      "learning_rate": 2.640157009983787e-05,
      "loss": 0.0019,
      "step": 55310
    },
    {
      "epoch": 4.720539295161704,
      "grad_norm": 0.1713966727256775,
      "learning_rate": 2.6397303524191486e-05,
      "loss": 0.0021,
      "step": 55320
    },
    {
      "epoch": 4.72139261029098,
      "grad_norm": 0.3128378987312317,
      "learning_rate": 2.6393036948545097e-05,
      "loss": 0.0014,
      "step": 55330
    },
    {
      "epoch": 4.722245925420258,
      "grad_norm": 0.14961501955986023,
      "learning_rate": 2.6388770372898715e-05,
      "loss": 0.0021,
      "step": 55340
    },
    {
      "epoch": 4.723099240549535,
      "grad_norm": 0.2056565284729004,
      "learning_rate": 2.6384503797252326e-05,
      "loss": 0.0021,
      "step": 55350
    },
    {
      "epoch": 4.723952555678812,
      "grad_norm": 0.18908235430717468,
      "learning_rate": 2.638023722160594e-05,
      "loss": 0.0018,
      "step": 55360
    },
    {
      "epoch": 4.72480587080809,
      "grad_norm": 0.08123099058866501,
      "learning_rate": 2.637597064595955e-05,
      "loss": 0.0015,
      "step": 55370
    },
    {
      "epoch": 4.725659185937367,
      "grad_norm": 0.028145376592874527,
      "learning_rate": 2.637170407031317e-05,
      "loss": 0.0019,
      "step": 55380
    },
    {
      "epoch": 4.726512501066644,
      "grad_norm": 0.18623091280460358,
      "learning_rate": 2.636743749466678e-05,
      "loss": 0.0015,
      "step": 55390
    },
    {
      "epoch": 4.727365816195921,
      "grad_norm": 0.29748982191085815,
      "learning_rate": 2.6363170919020397e-05,
      "loss": 0.0016,
      "step": 55400
    },
    {
      "epoch": 4.728219131325199,
      "grad_norm": 0.4015156030654907,
      "learning_rate": 2.6358904343374008e-05,
      "loss": 0.0015,
      "step": 55410
    },
    {
      "epoch": 4.7290724464544756,
      "grad_norm": 0.24892418086528778,
      "learning_rate": 2.6354637767727625e-05,
      "loss": 0.0021,
      "step": 55420
    },
    {
      "epoch": 4.729925761583753,
      "grad_norm": 0.16338114440441132,
      "learning_rate": 2.6350371192081236e-05,
      "loss": 0.0022,
      "step": 55430
    },
    {
      "epoch": 4.73077907671303,
      "grad_norm": 0.11476043611764908,
      "learning_rate": 2.6346104616434854e-05,
      "loss": 0.0021,
      "step": 55440
    },
    {
      "epoch": 4.731632391842307,
      "grad_norm": 0.31122758984565735,
      "learning_rate": 2.6341838040788465e-05,
      "loss": 0.0019,
      "step": 55450
    },
    {
      "epoch": 4.732485706971585,
      "grad_norm": 0.03978273645043373,
      "learning_rate": 2.633757146514208e-05,
      "loss": 0.0019,
      "step": 55460
    },
    {
      "epoch": 4.7333390221008615,
      "grad_norm": 0.1312861293554306,
      "learning_rate": 2.633330488949569e-05,
      "loss": 0.002,
      "step": 55470
    },
    {
      "epoch": 4.734192337230139,
      "grad_norm": 0.08367441594600677,
      "learning_rate": 2.6329038313849307e-05,
      "loss": 0.0018,
      "step": 55480
    },
    {
      "epoch": 4.735045652359417,
      "grad_norm": 0.22535361349582672,
      "learning_rate": 2.6324771738202918e-05,
      "loss": 0.0016,
      "step": 55490
    },
    {
      "epoch": 4.735898967488693,
      "grad_norm": 0.03302023559808731,
      "learning_rate": 2.6320505162556536e-05,
      "loss": 0.0023,
      "step": 55500
    },
    {
      "epoch": 4.736752282617971,
      "grad_norm": 0.035531166940927505,
      "learning_rate": 2.6316238586910147e-05,
      "loss": 0.0024,
      "step": 55510
    },
    {
      "epoch": 4.737605597747248,
      "grad_norm": 0.041275668889284134,
      "learning_rate": 2.6311972011263764e-05,
      "loss": 0.0018,
      "step": 55520
    },
    {
      "epoch": 4.738458912876525,
      "grad_norm": 0.23072248697280884,
      "learning_rate": 2.6307705435617375e-05,
      "loss": 0.0024,
      "step": 55530
    },
    {
      "epoch": 4.739312228005803,
      "grad_norm": 0.22288700938224792,
      "learning_rate": 2.6303438859970986e-05,
      "loss": 0.0018,
      "step": 55540
    },
    {
      "epoch": 4.740165543135079,
      "grad_norm": 0.42283394932746887,
      "learning_rate": 2.6299172284324604e-05,
      "loss": 0.0017,
      "step": 55550
    },
    {
      "epoch": 4.741018858264357,
      "grad_norm": 0.09949187934398651,
      "learning_rate": 2.6294905708678215e-05,
      "loss": 0.0019,
      "step": 55560
    },
    {
      "epoch": 4.741872173393634,
      "grad_norm": 0.39047542214393616,
      "learning_rate": 2.629063913303183e-05,
      "loss": 0.0019,
      "step": 55570
    },
    {
      "epoch": 4.742725488522911,
      "grad_norm": 0.325717955827713,
      "learning_rate": 2.628637255738544e-05,
      "loss": 0.0024,
      "step": 55580
    },
    {
      "epoch": 4.743578803652189,
      "grad_norm": 0.29900261759757996,
      "learning_rate": 2.6282105981739057e-05,
      "loss": 0.0019,
      "step": 55590
    },
    {
      "epoch": 4.744432118781466,
      "grad_norm": 0.13282416760921478,
      "learning_rate": 2.6277839406092668e-05,
      "loss": 0.0018,
      "step": 55600
    },
    {
      "epoch": 4.745285433910743,
      "grad_norm": 0.07550123333930969,
      "learning_rate": 2.6273572830446286e-05,
      "loss": 0.0018,
      "step": 55610
    },
    {
      "epoch": 4.74613874904002,
      "grad_norm": 0.24058787524700165,
      "learning_rate": 2.6269306254799897e-05,
      "loss": 0.0024,
      "step": 55620
    },
    {
      "epoch": 4.746992064169298,
      "grad_norm": 0.12530919909477234,
      "learning_rate": 2.6265039679153514e-05,
      "loss": 0.0022,
      "step": 55630
    },
    {
      "epoch": 4.747845379298575,
      "grad_norm": 0.04786859080195427,
      "learning_rate": 2.6260773103507125e-05,
      "loss": 0.0017,
      "step": 55640
    },
    {
      "epoch": 4.748698694427852,
      "grad_norm": 0.24077609181404114,
      "learning_rate": 2.6256506527860743e-05,
      "loss": 0.0026,
      "step": 55650
    },
    {
      "epoch": 4.74955200955713,
      "grad_norm": 0.2590109705924988,
      "learning_rate": 2.6252239952214354e-05,
      "loss": 0.0017,
      "step": 55660
    },
    {
      "epoch": 4.750405324686406,
      "grad_norm": 0.2087741196155548,
      "learning_rate": 2.6247973376567968e-05,
      "loss": 0.0023,
      "step": 55670
    },
    {
      "epoch": 4.751258639815684,
      "grad_norm": 0.17058250308036804,
      "learning_rate": 2.624370680092158e-05,
      "loss": 0.0022,
      "step": 55680
    },
    {
      "epoch": 4.7521119549449615,
      "grad_norm": 0.03408699855208397,
      "learning_rate": 2.6239440225275196e-05,
      "loss": 0.0018,
      "step": 55690
    },
    {
      "epoch": 4.752965270074238,
      "grad_norm": 0.1490979641675949,
      "learning_rate": 2.6235173649628807e-05,
      "loss": 0.0018,
      "step": 55700
    },
    {
      "epoch": 4.753818585203516,
      "grad_norm": 0.3007771968841553,
      "learning_rate": 2.6230907073982425e-05,
      "loss": 0.002,
      "step": 55710
    },
    {
      "epoch": 4.754671900332793,
      "grad_norm": 0.08815499395132065,
      "learning_rate": 2.6226640498336036e-05,
      "loss": 0.0024,
      "step": 55720
    },
    {
      "epoch": 4.75552521546207,
      "grad_norm": 0.15901124477386475,
      "learning_rate": 2.6222373922689653e-05,
      "loss": 0.002,
      "step": 55730
    },
    {
      "epoch": 4.7563785305913475,
      "grad_norm": 0.11536502838134766,
      "learning_rate": 2.6218107347043264e-05,
      "loss": 0.0018,
      "step": 55740
    },
    {
      "epoch": 4.757231845720625,
      "grad_norm": 0.12014048546552658,
      "learning_rate": 2.6213840771396882e-05,
      "loss": 0.0022,
      "step": 55750
    },
    {
      "epoch": 4.758085160849902,
      "grad_norm": 0.16777221858501434,
      "learning_rate": 2.6209574195750493e-05,
      "loss": 0.0025,
      "step": 55760
    },
    {
      "epoch": 4.758938475979179,
      "grad_norm": 0.14848852157592773,
      "learning_rate": 2.6205307620104107e-05,
      "loss": 0.0018,
      "step": 55770
    },
    {
      "epoch": 4.759791791108457,
      "grad_norm": 0.0588819645345211,
      "learning_rate": 2.6201041044457718e-05,
      "loss": 0.0017,
      "step": 55780
    },
    {
      "epoch": 4.7606451062377335,
      "grad_norm": 0.04542798176407814,
      "learning_rate": 2.6196774468811335e-05,
      "loss": 0.0018,
      "step": 55790
    },
    {
      "epoch": 4.761498421367011,
      "grad_norm": 0.02898126281797886,
      "learning_rate": 2.6192507893164946e-05,
      "loss": 0.0017,
      "step": 55800
    },
    {
      "epoch": 4.762351736496288,
      "grad_norm": 0.2579146921634674,
      "learning_rate": 2.6188241317518557e-05,
      "loss": 0.0022,
      "step": 55810
    },
    {
      "epoch": 4.763205051625565,
      "grad_norm": 0.12250504642724991,
      "learning_rate": 2.6183974741872175e-05,
      "loss": 0.0024,
      "step": 55820
    },
    {
      "epoch": 4.764058366754843,
      "grad_norm": 0.15264596045017242,
      "learning_rate": 2.6179708166225786e-05,
      "loss": 0.002,
      "step": 55830
    },
    {
      "epoch": 4.7649116818841195,
      "grad_norm": 0.2084479033946991,
      "learning_rate": 2.6175441590579403e-05,
      "loss": 0.0016,
      "step": 55840
    },
    {
      "epoch": 4.765764997013397,
      "grad_norm": 0.02774673141539097,
      "learning_rate": 2.6171175014933014e-05,
      "loss": 0.0018,
      "step": 55850
    },
    {
      "epoch": 4.766618312142675,
      "grad_norm": 0.029219159856438637,
      "learning_rate": 2.616690843928663e-05,
      "loss": 0.0025,
      "step": 55860
    },
    {
      "epoch": 4.767471627271951,
      "grad_norm": 0.21895168721675873,
      "learning_rate": 2.6162641863640243e-05,
      "loss": 0.0015,
      "step": 55870
    },
    {
      "epoch": 4.768324942401229,
      "grad_norm": 0.06357643753290176,
      "learning_rate": 2.6158375287993857e-05,
      "loss": 0.0017,
      "step": 55880
    },
    {
      "epoch": 4.769178257530506,
      "grad_norm": 0.241007998585701,
      "learning_rate": 2.6154108712347468e-05,
      "loss": 0.0013,
      "step": 55890
    },
    {
      "epoch": 4.770031572659783,
      "grad_norm": 0.0470120832324028,
      "learning_rate": 2.6149842136701085e-05,
      "loss": 0.0016,
      "step": 55900
    },
    {
      "epoch": 4.770884887789061,
      "grad_norm": 0.11458450555801392,
      "learning_rate": 2.6145575561054696e-05,
      "loss": 0.0021,
      "step": 55910
    },
    {
      "epoch": 4.771738202918337,
      "grad_norm": 0.15092280507087708,
      "learning_rate": 2.6141308985408314e-05,
      "loss": 0.002,
      "step": 55920
    },
    {
      "epoch": 4.772591518047615,
      "grad_norm": 0.17459838092327118,
      "learning_rate": 2.6137042409761925e-05,
      "loss": 0.0016,
      "step": 55930
    },
    {
      "epoch": 4.773444833176892,
      "grad_norm": 0.1518029421567917,
      "learning_rate": 2.6132775834115542e-05,
      "loss": 0.0017,
      "step": 55940
    },
    {
      "epoch": 4.774298148306169,
      "grad_norm": 0.23862910270690918,
      "learning_rate": 2.6128509258469153e-05,
      "loss": 0.0018,
      "step": 55950
    },
    {
      "epoch": 4.775151463435447,
      "grad_norm": 0.08776737004518509,
      "learning_rate": 2.612424268282277e-05,
      "loss": 0.0017,
      "step": 55960
    },
    {
      "epoch": 4.776004778564724,
      "grad_norm": 0.32932549715042114,
      "learning_rate": 2.611997610717638e-05,
      "loss": 0.0017,
      "step": 55970
    },
    {
      "epoch": 4.776858093694001,
      "grad_norm": 0.3529752194881439,
      "learning_rate": 2.6115709531529996e-05,
      "loss": 0.0016,
      "step": 55980
    },
    {
      "epoch": 4.777711408823278,
      "grad_norm": 0.21061809360980988,
      "learning_rate": 2.6111442955883607e-05,
      "loss": 0.0021,
      "step": 55990
    },
    {
      "epoch": 4.778564723952556,
      "grad_norm": 0.11316757649183273,
      "learning_rate": 2.6107176380237224e-05,
      "loss": 0.0019,
      "step": 56000
    },
    {
      "epoch": 4.779418039081833,
      "grad_norm": 0.04261934012174606,
      "learning_rate": 2.6102909804590835e-05,
      "loss": 0.0019,
      "step": 56010
    },
    {
      "epoch": 4.78027135421111,
      "grad_norm": 0.07711637020111084,
      "learning_rate": 2.6098643228944453e-05,
      "loss": 0.0016,
      "step": 56020
    },
    {
      "epoch": 4.781124669340388,
      "grad_norm": 0.11731114983558655,
      "learning_rate": 2.6094376653298064e-05,
      "loss": 0.0015,
      "step": 56030
    },
    {
      "epoch": 4.781977984469664,
      "grad_norm": 0.11041048914194107,
      "learning_rate": 2.609011007765168e-05,
      "loss": 0.0015,
      "step": 56040
    },
    {
      "epoch": 4.782831299598942,
      "grad_norm": 0.13091515004634857,
      "learning_rate": 2.6085843502005292e-05,
      "loss": 0.0014,
      "step": 56050
    },
    {
      "epoch": 4.7836846147282195,
      "grad_norm": 0.16591688990592957,
      "learning_rate": 2.608157692635891e-05,
      "loss": 0.0016,
      "step": 56060
    },
    {
      "epoch": 4.784537929857496,
      "grad_norm": 0.06155264377593994,
      "learning_rate": 2.607731035071252e-05,
      "loss": 0.0017,
      "step": 56070
    },
    {
      "epoch": 4.785391244986774,
      "grad_norm": 0.1491820365190506,
      "learning_rate": 2.607304377506613e-05,
      "loss": 0.0019,
      "step": 56080
    },
    {
      "epoch": 4.786244560116051,
      "grad_norm": 0.24104532599449158,
      "learning_rate": 2.6068777199419746e-05,
      "loss": 0.0018,
      "step": 56090
    },
    {
      "epoch": 4.787097875245328,
      "grad_norm": 0.21172669529914856,
      "learning_rate": 2.606451062377336e-05,
      "loss": 0.0018,
      "step": 56100
    },
    {
      "epoch": 4.7879511903746055,
      "grad_norm": 0.17442010343074799,
      "learning_rate": 2.6060244048126974e-05,
      "loss": 0.0016,
      "step": 56110
    },
    {
      "epoch": 4.788804505503883,
      "grad_norm": 0.1724366694688797,
      "learning_rate": 2.6055977472480585e-05,
      "loss": 0.0016,
      "step": 56120
    },
    {
      "epoch": 4.78965782063316,
      "grad_norm": 0.05770500376820564,
      "learning_rate": 2.6051710896834203e-05,
      "loss": 0.0017,
      "step": 56130
    },
    {
      "epoch": 4.790511135762437,
      "grad_norm": 0.4356830418109894,
      "learning_rate": 2.6047444321187813e-05,
      "loss": 0.002,
      "step": 56140
    },
    {
      "epoch": 4.791364450891714,
      "grad_norm": 0.1147589385509491,
      "learning_rate": 2.604317774554143e-05,
      "loss": 0.0016,
      "step": 56150
    },
    {
      "epoch": 4.7922177660209915,
      "grad_norm": 0.10001378506422043,
      "learning_rate": 2.6038911169895042e-05,
      "loss": 0.0022,
      "step": 56160
    },
    {
      "epoch": 4.793071081150269,
      "grad_norm": 0.2236548513174057,
      "learning_rate": 2.603464459424866e-05,
      "loss": 0.0017,
      "step": 56170
    },
    {
      "epoch": 4.793924396279546,
      "grad_norm": 0.17160087823867798,
      "learning_rate": 2.603037801860227e-05,
      "loss": 0.002,
      "step": 56180
    },
    {
      "epoch": 4.794777711408823,
      "grad_norm": 0.0696980357170105,
      "learning_rate": 2.6026111442955885e-05,
      "loss": 0.0016,
      "step": 56190
    },
    {
      "epoch": 4.795631026538101,
      "grad_norm": 0.259102463722229,
      "learning_rate": 2.60218448673095e-05,
      "loss": 0.0017,
      "step": 56200
    },
    {
      "epoch": 4.7964843416673775,
      "grad_norm": 0.05208282172679901,
      "learning_rate": 2.6017578291663113e-05,
      "loss": 0.0014,
      "step": 56210
    },
    {
      "epoch": 4.797337656796655,
      "grad_norm": 0.1544768214225769,
      "learning_rate": 2.6013311716016724e-05,
      "loss": 0.0019,
      "step": 56220
    },
    {
      "epoch": 4.798190971925933,
      "grad_norm": 0.044388122856616974,
      "learning_rate": 2.600904514037034e-05,
      "loss": 0.0014,
      "step": 56230
    },
    {
      "epoch": 4.799044287055209,
      "grad_norm": 0.03599020093679428,
      "learning_rate": 2.6004778564723952e-05,
      "loss": 0.0019,
      "step": 56240
    },
    {
      "epoch": 4.799897602184487,
      "grad_norm": 0.14919236302375793,
      "learning_rate": 2.600051198907757e-05,
      "loss": 0.0021,
      "step": 56250
    },
    {
      "epoch": 4.800750917313764,
      "grad_norm": 0.1299682855606079,
      "learning_rate": 2.599624541343118e-05,
      "loss": 0.0022,
      "step": 56260
    },
    {
      "epoch": 4.801604232443041,
      "grad_norm": 0.29275602102279663,
      "learning_rate": 2.59919788377848e-05,
      "loss": 0.0018,
      "step": 56270
    },
    {
      "epoch": 4.802457547572319,
      "grad_norm": 0.14476120471954346,
      "learning_rate": 2.598771226213841e-05,
      "loss": 0.0019,
      "step": 56280
    },
    {
      "epoch": 4.803310862701595,
      "grad_norm": 0.05177728831768036,
      "learning_rate": 2.5983445686492024e-05,
      "loss": 0.002,
      "step": 56290
    },
    {
      "epoch": 4.804164177830873,
      "grad_norm": 0.18673057854175568,
      "learning_rate": 2.5979179110845635e-05,
      "loss": 0.0023,
      "step": 56300
    },
    {
      "epoch": 4.80501749296015,
      "grad_norm": 0.3294205665588379,
      "learning_rate": 2.5974912535199252e-05,
      "loss": 0.0019,
      "step": 56310
    },
    {
      "epoch": 4.805870808089427,
      "grad_norm": 0.08247465640306473,
      "learning_rate": 2.5970645959552863e-05,
      "loss": 0.0018,
      "step": 56320
    },
    {
      "epoch": 4.806724123218705,
      "grad_norm": 0.09755786508321762,
      "learning_rate": 2.596637938390648e-05,
      "loss": 0.0015,
      "step": 56330
    },
    {
      "epoch": 4.807577438347982,
      "grad_norm": 0.3529652953147888,
      "learning_rate": 2.596211280826009e-05,
      "loss": 0.0016,
      "step": 56340
    },
    {
      "epoch": 4.808430753477259,
      "grad_norm": 0.11464933305978775,
      "learning_rate": 2.5957846232613702e-05,
      "loss": 0.002,
      "step": 56350
    },
    {
      "epoch": 4.809284068606536,
      "grad_norm": 0.35471251606941223,
      "learning_rate": 2.595357965696732e-05,
      "loss": 0.0016,
      "step": 56360
    },
    {
      "epoch": 4.810137383735814,
      "grad_norm": 0.15002381801605225,
      "learning_rate": 2.594931308132093e-05,
      "loss": 0.0022,
      "step": 56370
    },
    {
      "epoch": 4.810990698865091,
      "grad_norm": 0.09253022074699402,
      "learning_rate": 2.594504650567455e-05,
      "loss": 0.0019,
      "step": 56380
    },
    {
      "epoch": 4.811844013994368,
      "grad_norm": 0.05048837885260582,
      "learning_rate": 2.594077993002816e-05,
      "loss": 0.002,
      "step": 56390
    },
    {
      "epoch": 4.812697329123646,
      "grad_norm": 0.22466795146465302,
      "learning_rate": 2.5936513354381774e-05,
      "loss": 0.0021,
      "step": 56400
    },
    {
      "epoch": 4.813550644252922,
      "grad_norm": 0.1829950511455536,
      "learning_rate": 2.5932246778735388e-05,
      "loss": 0.0019,
      "step": 56410
    },
    {
      "epoch": 4.8144039593822,
      "grad_norm": 0.25580406188964844,
      "learning_rate": 2.5927980203089002e-05,
      "loss": 0.0021,
      "step": 56420
    },
    {
      "epoch": 4.8152572745114774,
      "grad_norm": 0.15004770457744598,
      "learning_rate": 2.5923713627442613e-05,
      "loss": 0.0017,
      "step": 56430
    },
    {
      "epoch": 4.816110589640754,
      "grad_norm": 0.07954072207212448,
      "learning_rate": 2.591944705179623e-05,
      "loss": 0.0015,
      "step": 56440
    },
    {
      "epoch": 4.816963904770032,
      "grad_norm": 0.22284206748008728,
      "learning_rate": 2.591518047614984e-05,
      "loss": 0.0017,
      "step": 56450
    },
    {
      "epoch": 4.817817219899309,
      "grad_norm": 0.06190396472811699,
      "learning_rate": 2.591091390050346e-05,
      "loss": 0.0018,
      "step": 56460
    },
    {
      "epoch": 4.818670535028586,
      "grad_norm": 0.17019297182559967,
      "learning_rate": 2.590664732485707e-05,
      "loss": 0.0018,
      "step": 56470
    },
    {
      "epoch": 4.819523850157863,
      "grad_norm": 0.2464500367641449,
      "learning_rate": 2.5902380749210687e-05,
      "loss": 0.0018,
      "step": 56480
    },
    {
      "epoch": 4.820377165287141,
      "grad_norm": 0.2584399878978729,
      "learning_rate": 2.58981141735643e-05,
      "loss": 0.0019,
      "step": 56490
    },
    {
      "epoch": 4.821230480416418,
      "grad_norm": 0.0370471253991127,
      "learning_rate": 2.5893847597917913e-05,
      "loss": 0.0021,
      "step": 56500
    },
    {
      "epoch": 4.822083795545695,
      "grad_norm": 0.24211998283863068,
      "learning_rate": 2.5889581022271527e-05,
      "loss": 0.0019,
      "step": 56510
    },
    {
      "epoch": 4.822937110674972,
      "grad_norm": 0.3691417872905731,
      "learning_rate": 2.588531444662514e-05,
      "loss": 0.0013,
      "step": 56520
    },
    {
      "epoch": 4.823790425804249,
      "grad_norm": 0.19300009310245514,
      "learning_rate": 2.5881047870978752e-05,
      "loss": 0.0019,
      "step": 56530
    },
    {
      "epoch": 4.824643740933527,
      "grad_norm": 0.03361476585268974,
      "learning_rate": 2.587678129533237e-05,
      "loss": 0.0018,
      "step": 56540
    },
    {
      "epoch": 4.825497056062804,
      "grad_norm": 0.10145843774080276,
      "learning_rate": 2.587251471968598e-05,
      "loss": 0.0016,
      "step": 56550
    },
    {
      "epoch": 4.826350371192081,
      "grad_norm": 0.1865524798631668,
      "learning_rate": 2.5868248144039598e-05,
      "loss": 0.002,
      "step": 56560
    },
    {
      "epoch": 4.827203686321359,
      "grad_norm": 0.05912827327847481,
      "learning_rate": 2.586398156839321e-05,
      "loss": 0.0021,
      "step": 56570
    },
    {
      "epoch": 4.828057001450635,
      "grad_norm": 0.13311104476451874,
      "learning_rate": 2.5859714992746827e-05,
      "loss": 0.0018,
      "step": 56580
    },
    {
      "epoch": 4.828910316579913,
      "grad_norm": 0.279058039188385,
      "learning_rate": 2.5855448417100437e-05,
      "loss": 0.0017,
      "step": 56590
    },
    {
      "epoch": 4.8297636317091905,
      "grad_norm": 0.07779707759618759,
      "learning_rate": 2.585118184145405e-05,
      "loss": 0.0024,
      "step": 56600
    },
    {
      "epoch": 4.830616946838467,
      "grad_norm": 0.36967939138412476,
      "learning_rate": 2.5846915265807662e-05,
      "loss": 0.0016,
      "step": 56610
    },
    {
      "epoch": 4.831470261967745,
      "grad_norm": 0.11623602360486984,
      "learning_rate": 2.5842648690161277e-05,
      "loss": 0.0014,
      "step": 56620
    },
    {
      "epoch": 4.832323577097022,
      "grad_norm": 0.16757246851921082,
      "learning_rate": 2.583838211451489e-05,
      "loss": 0.0017,
      "step": 56630
    },
    {
      "epoch": 4.833176892226299,
      "grad_norm": 0.11445706337690353,
      "learning_rate": 2.5834115538868502e-05,
      "loss": 0.0018,
      "step": 56640
    },
    {
      "epoch": 4.8340302073555765,
      "grad_norm": 0.21930155158042908,
      "learning_rate": 2.582984896322212e-05,
      "loss": 0.0019,
      "step": 56650
    },
    {
      "epoch": 4.834883522484853,
      "grad_norm": 0.06290524452924728,
      "learning_rate": 2.582558238757573e-05,
      "loss": 0.002,
      "step": 56660
    },
    {
      "epoch": 4.835736837614131,
      "grad_norm": 0.24993987381458282,
      "learning_rate": 2.5821315811929348e-05,
      "loss": 0.0017,
      "step": 56670
    },
    {
      "epoch": 4.836590152743408,
      "grad_norm": 0.024330221116542816,
      "learning_rate": 2.581704923628296e-05,
      "loss": 0.0016,
      "step": 56680
    },
    {
      "epoch": 4.837443467872685,
      "grad_norm": 0.299714058637619,
      "learning_rate": 2.5812782660636576e-05,
      "loss": 0.0019,
      "step": 56690
    },
    {
      "epoch": 4.8382967830019625,
      "grad_norm": 0.33450940251350403,
      "learning_rate": 2.5808516084990187e-05,
      "loss": 0.002,
      "step": 56700
    },
    {
      "epoch": 4.83915009813124,
      "grad_norm": 0.06401176750659943,
      "learning_rate": 2.58042495093438e-05,
      "loss": 0.0021,
      "step": 56710
    },
    {
      "epoch": 4.840003413260517,
      "grad_norm": 0.020651832222938538,
      "learning_rate": 2.5799982933697416e-05,
      "loss": 0.0015,
      "step": 56720
    },
    {
      "epoch": 4.840856728389794,
      "grad_norm": 0.13778594136238098,
      "learning_rate": 2.579571635805103e-05,
      "loss": 0.0019,
      "step": 56730
    },
    {
      "epoch": 4.841710043519072,
      "grad_norm": 0.09669851511716843,
      "learning_rate": 2.579144978240464e-05,
      "loss": 0.002,
      "step": 56740
    },
    {
      "epoch": 4.8425633586483485,
      "grad_norm": 0.39246001839637756,
      "learning_rate": 2.578718320675826e-05,
      "loss": 0.0019,
      "step": 56750
    },
    {
      "epoch": 4.843416673777626,
      "grad_norm": 0.18485352396965027,
      "learning_rate": 2.578291663111187e-05,
      "loss": 0.0022,
      "step": 56760
    },
    {
      "epoch": 4.844269988906904,
      "grad_norm": 0.38768482208251953,
      "learning_rate": 2.5778650055465487e-05,
      "loss": 0.0021,
      "step": 56770
    },
    {
      "epoch": 4.84512330403618,
      "grad_norm": 0.2419472187757492,
      "learning_rate": 2.5774383479819098e-05,
      "loss": 0.0018,
      "step": 56780
    },
    {
      "epoch": 4.845976619165458,
      "grad_norm": 0.3139473497867584,
      "learning_rate": 2.5770116904172715e-05,
      "loss": 0.0016,
      "step": 56790
    },
    {
      "epoch": 4.846829934294735,
      "grad_norm": 0.08193880319595337,
      "learning_rate": 2.5765850328526326e-05,
      "loss": 0.0015,
      "step": 56800
    },
    {
      "epoch": 4.847683249424012,
      "grad_norm": 0.32052451372146606,
      "learning_rate": 2.576158375287994e-05,
      "loss": 0.0022,
      "step": 56810
    },
    {
      "epoch": 4.84853656455329,
      "grad_norm": 0.050217460840940475,
      "learning_rate": 2.5757317177233555e-05,
      "loss": 0.002,
      "step": 56820
    },
    {
      "epoch": 4.849389879682567,
      "grad_norm": 0.4463668763637543,
      "learning_rate": 2.575305060158717e-05,
      "loss": 0.0021,
      "step": 56830
    },
    {
      "epoch": 4.850243194811844,
      "grad_norm": 0.22273604571819305,
      "learning_rate": 2.574878402594078e-05,
      "loss": 0.0017,
      "step": 56840
    },
    {
      "epoch": 4.851096509941121,
      "grad_norm": 0.09953831136226654,
      "learning_rate": 2.5744517450294397e-05,
      "loss": 0.0022,
      "step": 56850
    },
    {
      "epoch": 4.851949825070399,
      "grad_norm": 0.08222709596157074,
      "learning_rate": 2.574025087464801e-05,
      "loss": 0.0018,
      "step": 56860
    },
    {
      "epoch": 4.852803140199676,
      "grad_norm": 0.09736359864473343,
      "learning_rate": 2.573598429900162e-05,
      "loss": 0.0023,
      "step": 56870
    },
    {
      "epoch": 4.853656455328953,
      "grad_norm": 0.38355758786201477,
      "learning_rate": 2.5731717723355237e-05,
      "loss": 0.0016,
      "step": 56880
    },
    {
      "epoch": 4.85450977045823,
      "grad_norm": 0.09679538756608963,
      "learning_rate": 2.5727451147708848e-05,
      "loss": 0.0021,
      "step": 56890
    },
    {
      "epoch": 4.855363085587507,
      "grad_norm": 0.46037477254867554,
      "learning_rate": 2.5723184572062465e-05,
      "loss": 0.0022,
      "step": 56900
    },
    {
      "epoch": 4.856216400716785,
      "grad_norm": 0.44394755363464355,
      "learning_rate": 2.5718917996416076e-05,
      "loss": 0.0019,
      "step": 56910
    },
    {
      "epoch": 4.857069715846062,
      "grad_norm": 0.2646716833114624,
      "learning_rate": 2.571465142076969e-05,
      "loss": 0.0017,
      "step": 56920
    },
    {
      "epoch": 4.857923030975339,
      "grad_norm": 0.26612532138824463,
      "learning_rate": 2.5710384845123305e-05,
      "loss": 0.0019,
      "step": 56930
    },
    {
      "epoch": 4.858776346104617,
      "grad_norm": 0.09271162003278732,
      "learning_rate": 2.570611826947692e-05,
      "loss": 0.0018,
      "step": 56940
    },
    {
      "epoch": 4.859629661233893,
      "grad_norm": 0.20564958453178406,
      "learning_rate": 2.570185169383053e-05,
      "loss": 0.0018,
      "step": 56950
    },
    {
      "epoch": 4.860482976363171,
      "grad_norm": 0.18693386018276215,
      "learning_rate": 2.5697585118184147e-05,
      "loss": 0.0015,
      "step": 56960
    },
    {
      "epoch": 4.8613362914924485,
      "grad_norm": 0.026994403451681137,
      "learning_rate": 2.5693318542537758e-05,
      "loss": 0.0019,
      "step": 56970
    },
    {
      "epoch": 4.862189606621725,
      "grad_norm": 0.6348118782043457,
      "learning_rate": 2.5689051966891376e-05,
      "loss": 0.0019,
      "step": 56980
    },
    {
      "epoch": 4.863042921751003,
      "grad_norm": 0.06583301723003387,
      "learning_rate": 2.5684785391244987e-05,
      "loss": 0.0018,
      "step": 56990
    },
    {
      "epoch": 4.863896236880279,
      "grad_norm": 0.1698908507823944,
      "learning_rate": 2.5680518815598604e-05,
      "loss": 0.0025,
      "step": 57000
    },
    {
      "epoch": 4.864749552009557,
      "grad_norm": 0.24264182150363922,
      "learning_rate": 2.5676252239952215e-05,
      "loss": 0.0017,
      "step": 57010
    },
    {
      "epoch": 4.8656028671388345,
      "grad_norm": 0.5153364539146423,
      "learning_rate": 2.567198566430583e-05,
      "loss": 0.0024,
      "step": 57020
    },
    {
      "epoch": 4.866456182268111,
      "grad_norm": 0.31285619735717773,
      "learning_rate": 2.5667719088659444e-05,
      "loss": 0.0017,
      "step": 57030
    },
    {
      "epoch": 4.867309497397389,
      "grad_norm": 0.2938110828399658,
      "learning_rate": 2.5663452513013058e-05,
      "loss": 0.0021,
      "step": 57040
    },
    {
      "epoch": 4.868162812526666,
      "grad_norm": 0.07826606929302216,
      "learning_rate": 2.565918593736667e-05,
      "loss": 0.0016,
      "step": 57050
    },
    {
      "epoch": 4.869016127655943,
      "grad_norm": 0.07482699304819107,
      "learning_rate": 2.5654919361720286e-05,
      "loss": 0.0015,
      "step": 57060
    },
    {
      "epoch": 4.8698694427852205,
      "grad_norm": 0.1725044995546341,
      "learning_rate": 2.5650652786073897e-05,
      "loss": 0.0017,
      "step": 57070
    },
    {
      "epoch": 4.870722757914498,
      "grad_norm": 0.13441026210784912,
      "learning_rate": 2.5646386210427515e-05,
      "loss": 0.0019,
      "step": 57080
    },
    {
      "epoch": 4.871576073043775,
      "grad_norm": 0.1489858478307724,
      "learning_rate": 2.5642119634781126e-05,
      "loss": 0.0015,
      "step": 57090
    },
    {
      "epoch": 4.872429388173052,
      "grad_norm": 0.04125238209962845,
      "learning_rate": 2.5637853059134743e-05,
      "loss": 0.0027,
      "step": 57100
    },
    {
      "epoch": 4.87328270330233,
      "grad_norm": 0.07510875165462494,
      "learning_rate": 2.5633586483488354e-05,
      "loss": 0.0019,
      "step": 57110
    },
    {
      "epoch": 4.8741360184316065,
      "grad_norm": 0.03281298279762268,
      "learning_rate": 2.562931990784197e-05,
      "loss": 0.002,
      "step": 57120
    },
    {
      "epoch": 4.874989333560884,
      "grad_norm": 0.12438411265611649,
      "learning_rate": 2.5625053332195583e-05,
      "loss": 0.002,
      "step": 57130
    },
    {
      "epoch": 4.875842648690162,
      "grad_norm": 0.43390655517578125,
      "learning_rate": 2.5620786756549194e-05,
      "loss": 0.0016,
      "step": 57140
    },
    {
      "epoch": 4.876695963819438,
      "grad_norm": 0.35452258586883545,
      "learning_rate": 2.5616520180902808e-05,
      "loss": 0.0018,
      "step": 57150
    },
    {
      "epoch": 4.877549278948716,
      "grad_norm": 0.16926386952400208,
      "learning_rate": 2.561225360525642e-05,
      "loss": 0.0017,
      "step": 57160
    },
    {
      "epoch": 4.878402594077993,
      "grad_norm": 0.4231365919113159,
      "learning_rate": 2.5607987029610036e-05,
      "loss": 0.0021,
      "step": 57170
    },
    {
      "epoch": 4.87925590920727,
      "grad_norm": 0.19640743732452393,
      "learning_rate": 2.5603720453963647e-05,
      "loss": 0.0019,
      "step": 57180
    },
    {
      "epoch": 4.880109224336548,
      "grad_norm": 0.22173760831356049,
      "learning_rate": 2.5599453878317265e-05,
      "loss": 0.0015,
      "step": 57190
    },
    {
      "epoch": 4.880962539465825,
      "grad_norm": 0.15428543090820312,
      "learning_rate": 2.5595187302670876e-05,
      "loss": 0.0019,
      "step": 57200
    },
    {
      "epoch": 4.881815854595102,
      "grad_norm": 0.18338222801685333,
      "learning_rate": 2.5590920727024493e-05,
      "loss": 0.0019,
      "step": 57210
    },
    {
      "epoch": 4.882669169724379,
      "grad_norm": 0.13101668655872345,
      "learning_rate": 2.5586654151378104e-05,
      "loss": 0.0017,
      "step": 57220
    },
    {
      "epoch": 4.883522484853657,
      "grad_norm": 0.09554393589496613,
      "learning_rate": 2.5582387575731718e-05,
      "loss": 0.0022,
      "step": 57230
    },
    {
      "epoch": 4.884375799982934,
      "grad_norm": 0.11082503944635391,
      "learning_rate": 2.5578121000085333e-05,
      "loss": 0.0019,
      "step": 57240
    },
    {
      "epoch": 4.885229115112211,
      "grad_norm": 0.2806633412837982,
      "learning_rate": 2.5573854424438947e-05,
      "loss": 0.0017,
      "step": 57250
    },
    {
      "epoch": 4.886082430241488,
      "grad_norm": 0.22106310725212097,
      "learning_rate": 2.5569587848792558e-05,
      "loss": 0.0024,
      "step": 57260
    },
    {
      "epoch": 4.886935745370765,
      "grad_norm": 0.24924713373184204,
      "learning_rate": 2.5565321273146175e-05,
      "loss": 0.0023,
      "step": 57270
    },
    {
      "epoch": 4.887789060500043,
      "grad_norm": 0.11488662660121918,
      "learning_rate": 2.5561054697499786e-05,
      "loss": 0.0017,
      "step": 57280
    },
    {
      "epoch": 4.88864237562932,
      "grad_norm": 0.2767525613307953,
      "learning_rate": 2.5556788121853404e-05,
      "loss": 0.002,
      "step": 57290
    },
    {
      "epoch": 4.889495690758597,
      "grad_norm": 0.04608599469065666,
      "learning_rate": 2.5552521546207015e-05,
      "loss": 0.0018,
      "step": 57300
    },
    {
      "epoch": 4.890349005887875,
      "grad_norm": 0.1871234029531479,
      "learning_rate": 2.5548254970560632e-05,
      "loss": 0.0018,
      "step": 57310
    },
    {
      "epoch": 4.891202321017151,
      "grad_norm": 0.12081629037857056,
      "learning_rate": 2.5543988394914243e-05,
      "loss": 0.0019,
      "step": 57320
    },
    {
      "epoch": 4.892055636146429,
      "grad_norm": 0.5230910181999207,
      "learning_rate": 2.5539721819267857e-05,
      "loss": 0.0021,
      "step": 57330
    },
    {
      "epoch": 4.8929089512757065,
      "grad_norm": 0.13384000957012177,
      "learning_rate": 2.553545524362147e-05,
      "loss": 0.002,
      "step": 57340
    },
    {
      "epoch": 4.893762266404983,
      "grad_norm": 0.42673420906066895,
      "learning_rate": 2.5531188667975086e-05,
      "loss": 0.002,
      "step": 57350
    },
    {
      "epoch": 4.894615581534261,
      "grad_norm": 0.4161984622478485,
      "learning_rate": 2.5526922092328697e-05,
      "loss": 0.0017,
      "step": 57360
    },
    {
      "epoch": 4.895468896663537,
      "grad_norm": 0.22683821618556976,
      "learning_rate": 2.5522655516682314e-05,
      "loss": 0.0013,
      "step": 57370
    },
    {
      "epoch": 4.896322211792815,
      "grad_norm": 0.05311622470617294,
      "learning_rate": 2.5518388941035925e-05,
      "loss": 0.0018,
      "step": 57380
    },
    {
      "epoch": 4.8971755269220925,
      "grad_norm": 0.058624789118766785,
      "learning_rate": 2.5514122365389543e-05,
      "loss": 0.0018,
      "step": 57390
    },
    {
      "epoch": 4.898028842051369,
      "grad_norm": 0.09425760060548782,
      "learning_rate": 2.5509855789743154e-05,
      "loss": 0.0018,
      "step": 57400
    },
    {
      "epoch": 4.898882157180647,
      "grad_norm": 0.10226316004991531,
      "learning_rate": 2.5505589214096764e-05,
      "loss": 0.002,
      "step": 57410
    },
    {
      "epoch": 4.899735472309924,
      "grad_norm": 0.23894837498664856,
      "learning_rate": 2.5501322638450382e-05,
      "loss": 0.0017,
      "step": 57420
    },
    {
      "epoch": 4.900588787439201,
      "grad_norm": 0.03565818816423416,
      "learning_rate": 2.5497056062803993e-05,
      "loss": 0.0017,
      "step": 57430
    },
    {
      "epoch": 4.9014421025684785,
      "grad_norm": 0.16699819266796112,
      "learning_rate": 2.549278948715761e-05,
      "loss": 0.0023,
      "step": 57440
    },
    {
      "epoch": 4.902295417697756,
      "grad_norm": 0.0961553230881691,
      "learning_rate": 2.548852291151122e-05,
      "loss": 0.0015,
      "step": 57450
    },
    {
      "epoch": 4.903148732827033,
      "grad_norm": 0.09523919969797134,
      "learning_rate": 2.5484256335864836e-05,
      "loss": 0.0017,
      "step": 57460
    },
    {
      "epoch": 4.90400204795631,
      "grad_norm": 0.18540194630622864,
      "learning_rate": 2.5479989760218447e-05,
      "loss": 0.0017,
      "step": 57470
    },
    {
      "epoch": 4.904855363085588,
      "grad_norm": 0.15254336595535278,
      "learning_rate": 2.5475723184572064e-05,
      "loss": 0.0016,
      "step": 57480
    },
    {
      "epoch": 4.9057086782148644,
      "grad_norm": 0.13062547147274017,
      "learning_rate": 2.5471456608925675e-05,
      "loss": 0.0017,
      "step": 57490
    },
    {
      "epoch": 4.906561993344142,
      "grad_norm": 0.34952685236930847,
      "learning_rate": 2.5467190033279293e-05,
      "loss": 0.0017,
      "step": 57500
    },
    {
      "epoch": 4.90741530847342,
      "grad_norm": 0.36753925681114197,
      "learning_rate": 2.5462923457632903e-05,
      "loss": 0.0018,
      "step": 57510
    },
    {
      "epoch": 4.908268623602696,
      "grad_norm": 0.25772929191589355,
      "learning_rate": 2.545865688198652e-05,
      "loss": 0.002,
      "step": 57520
    },
    {
      "epoch": 4.909121938731974,
      "grad_norm": 0.30683135986328125,
      "learning_rate": 2.5454390306340132e-05,
      "loss": 0.0021,
      "step": 57530
    },
    {
      "epoch": 4.909975253861251,
      "grad_norm": 0.46800217032432556,
      "learning_rate": 2.5450123730693746e-05,
      "loss": 0.0021,
      "step": 57540
    },
    {
      "epoch": 4.910828568990528,
      "grad_norm": 0.09944358468055725,
      "learning_rate": 2.544585715504736e-05,
      "loss": 0.0016,
      "step": 57550
    },
    {
      "epoch": 4.9116818841198056,
      "grad_norm": 0.19359616935253143,
      "learning_rate": 2.5441590579400975e-05,
      "loss": 0.0019,
      "step": 57560
    },
    {
      "epoch": 4.912535199249083,
      "grad_norm": 0.19088992476463318,
      "learning_rate": 2.5437324003754586e-05,
      "loss": 0.0016,
      "step": 57570
    },
    {
      "epoch": 4.91338851437836,
      "grad_norm": 0.5488231182098389,
      "learning_rate": 2.5433057428108203e-05,
      "loss": 0.0015,
      "step": 57580
    },
    {
      "epoch": 4.914241829507637,
      "grad_norm": 0.2564987540245056,
      "learning_rate": 2.5428790852461814e-05,
      "loss": 0.0015,
      "step": 57590
    },
    {
      "epoch": 4.915095144636915,
      "grad_norm": 0.024949893355369568,
      "learning_rate": 2.542452427681543e-05,
      "loss": 0.0016,
      "step": 57600
    },
    {
      "epoch": 4.9159484597661915,
      "grad_norm": 0.04112069681286812,
      "learning_rate": 2.5420257701169043e-05,
      "loss": 0.0019,
      "step": 57610
    },
    {
      "epoch": 4.916801774895469,
      "grad_norm": 0.3720262050628662,
      "learning_rate": 2.541599112552266e-05,
      "loss": 0.0017,
      "step": 57620
    },
    {
      "epoch": 4.917655090024746,
      "grad_norm": 0.22266606986522675,
      "learning_rate": 2.541172454987627e-05,
      "loss": 0.0019,
      "step": 57630
    },
    {
      "epoch": 4.918508405154023,
      "grad_norm": 0.024400079622864723,
      "learning_rate": 2.5407457974229885e-05,
      "loss": 0.0016,
      "step": 57640
    },
    {
      "epoch": 4.919361720283301,
      "grad_norm": 0.09577839821577072,
      "learning_rate": 2.54031913985835e-05,
      "loss": 0.002,
      "step": 57650
    },
    {
      "epoch": 4.9202150354125775,
      "grad_norm": 0.18293260037899017,
      "learning_rate": 2.5398924822937114e-05,
      "loss": 0.0017,
      "step": 57660
    },
    {
      "epoch": 4.921068350541855,
      "grad_norm": 0.09861640632152557,
      "learning_rate": 2.5394658247290725e-05,
      "loss": 0.0022,
      "step": 57670
    },
    {
      "epoch": 4.921921665671133,
      "grad_norm": 0.04477876052260399,
      "learning_rate": 2.5390391671644335e-05,
      "loss": 0.0019,
      "step": 57680
    },
    {
      "epoch": 4.922774980800409,
      "grad_norm": 0.09507198631763458,
      "learning_rate": 2.5386125095997953e-05,
      "loss": 0.0019,
      "step": 57690
    },
    {
      "epoch": 4.923628295929687,
      "grad_norm": 0.34047919511795044,
      "learning_rate": 2.5381858520351564e-05,
      "loss": 0.0017,
      "step": 57700
    },
    {
      "epoch": 4.924481611058964,
      "grad_norm": 0.23909075558185577,
      "learning_rate": 2.537759194470518e-05,
      "loss": 0.0015,
      "step": 57710
    },
    {
      "epoch": 4.925334926188241,
      "grad_norm": 0.11144522577524185,
      "learning_rate": 2.5373325369058792e-05,
      "loss": 0.0021,
      "step": 57720
    },
    {
      "epoch": 4.926188241317519,
      "grad_norm": 0.31430330872535706,
      "learning_rate": 2.536905879341241e-05,
      "loss": 0.0022,
      "step": 57730
    },
    {
      "epoch": 4.927041556446795,
      "grad_norm": 0.2097683697938919,
      "learning_rate": 2.536479221776602e-05,
      "loss": 0.0018,
      "step": 57740
    },
    {
      "epoch": 4.927894871576073,
      "grad_norm": 0.12371010333299637,
      "learning_rate": 2.536052564211964e-05,
      "loss": 0.0019,
      "step": 57750
    },
    {
      "epoch": 4.92874818670535,
      "grad_norm": 0.07550622522830963,
      "learning_rate": 2.535625906647325e-05,
      "loss": 0.0019,
      "step": 57760
    },
    {
      "epoch": 4.929601501834627,
      "grad_norm": 0.22079071402549744,
      "learning_rate": 2.5351992490826864e-05,
      "loss": 0.0019,
      "step": 57770
    },
    {
      "epoch": 4.930454816963905,
      "grad_norm": 0.40266484022140503,
      "learning_rate": 2.5347725915180474e-05,
      "loss": 0.0016,
      "step": 57780
    },
    {
      "epoch": 4.931308132093182,
      "grad_norm": 0.1854495406150818,
      "learning_rate": 2.5343459339534092e-05,
      "loss": 0.0016,
      "step": 57790
    },
    {
      "epoch": 4.932161447222459,
      "grad_norm": 0.22113704681396484,
      "learning_rate": 2.5339192763887703e-05,
      "loss": 0.0021,
      "step": 57800
    },
    {
      "epoch": 4.933014762351736,
      "grad_norm": 0.20586217939853668,
      "learning_rate": 2.533492618824132e-05,
      "loss": 0.0015,
      "step": 57810
    },
    {
      "epoch": 4.933868077481014,
      "grad_norm": 0.3970651924610138,
      "learning_rate": 2.533065961259493e-05,
      "loss": 0.0019,
      "step": 57820
    },
    {
      "epoch": 4.934721392610291,
      "grad_norm": 0.3146058917045593,
      "learning_rate": 2.532639303694855e-05,
      "loss": 0.0017,
      "step": 57830
    },
    {
      "epoch": 4.935574707739568,
      "grad_norm": 0.053643640130758286,
      "learning_rate": 2.532212646130216e-05,
      "loss": 0.0016,
      "step": 57840
    },
    {
      "epoch": 4.936428022868846,
      "grad_norm": 0.12393001466989517,
      "learning_rate": 2.5317859885655778e-05,
      "loss": 0.0021,
      "step": 57850
    },
    {
      "epoch": 4.937281337998122,
      "grad_norm": 0.037725482136011124,
      "learning_rate": 2.531359331000939e-05,
      "loss": 0.0015,
      "step": 57860
    },
    {
      "epoch": 4.9381346531274,
      "grad_norm": 0.14588890969753265,
      "learning_rate": 2.5309326734363003e-05,
      "loss": 0.0018,
      "step": 57870
    },
    {
      "epoch": 4.9389879682566775,
      "grad_norm": 0.23811553418636322,
      "learning_rate": 2.5305060158716613e-05,
      "loss": 0.0014,
      "step": 57880
    },
    {
      "epoch": 4.939841283385954,
      "grad_norm": 0.1787717193365097,
      "learning_rate": 2.530079358307023e-05,
      "loss": 0.002,
      "step": 57890
    },
    {
      "epoch": 4.940694598515232,
      "grad_norm": 0.27561256289482117,
      "learning_rate": 2.5296527007423842e-05,
      "loss": 0.0015,
      "step": 57900
    },
    {
      "epoch": 4.941547913644509,
      "grad_norm": 0.1904071867465973,
      "learning_rate": 2.529226043177746e-05,
      "loss": 0.0024,
      "step": 57910
    },
    {
      "epoch": 4.942401228773786,
      "grad_norm": 0.0627518817782402,
      "learning_rate": 2.528799385613107e-05,
      "loss": 0.0022,
      "step": 57920
    },
    {
      "epoch": 4.9432545439030635,
      "grad_norm": 0.16389143466949463,
      "learning_rate": 2.5283727280484688e-05,
      "loss": 0.0019,
      "step": 57930
    },
    {
      "epoch": 4.944107859032341,
      "grad_norm": 0.3125859498977661,
      "learning_rate": 2.52794607048383e-05,
      "loss": 0.0019,
      "step": 57940
    },
    {
      "epoch": 4.944961174161618,
      "grad_norm": 0.18929257988929749,
      "learning_rate": 2.527519412919191e-05,
      "loss": 0.0021,
      "step": 57950
    },
    {
      "epoch": 4.945814489290895,
      "grad_norm": 0.06087745353579521,
      "learning_rate": 2.5270927553545527e-05,
      "loss": 0.0018,
      "step": 57960
    },
    {
      "epoch": 4.946667804420173,
      "grad_norm": 0.21762248873710632,
      "learning_rate": 2.5266660977899138e-05,
      "loss": 0.0014,
      "step": 57970
    },
    {
      "epoch": 4.9475211195494495,
      "grad_norm": 0.1836230456829071,
      "learning_rate": 2.5262394402252752e-05,
      "loss": 0.0013,
      "step": 57980
    },
    {
      "epoch": 4.948374434678727,
      "grad_norm": 0.10989721864461899,
      "learning_rate": 2.5258127826606363e-05,
      "loss": 0.0018,
      "step": 57990
    },
    {
      "epoch": 4.949227749808004,
      "grad_norm": 0.06039349362254143,
      "learning_rate": 2.525386125095998e-05,
      "loss": 0.002,
      "step": 58000
    },
    {
      "epoch": 4.950081064937281,
      "grad_norm": 0.19982220232486725,
      "learning_rate": 2.5249594675313592e-05,
      "loss": 0.0016,
      "step": 58010
    },
    {
      "epoch": 4.950934380066559,
      "grad_norm": 0.2602607309818268,
      "learning_rate": 2.524532809966721e-05,
      "loss": 0.0023,
      "step": 58020
    },
    {
      "epoch": 4.9517876951958355,
      "grad_norm": 0.329938679933548,
      "learning_rate": 2.524106152402082e-05,
      "loss": 0.0021,
      "step": 58030
    },
    {
      "epoch": 4.952641010325113,
      "grad_norm": 0.25949203968048096,
      "learning_rate": 2.5236794948374438e-05,
      "loss": 0.0019,
      "step": 58040
    },
    {
      "epoch": 4.953494325454391,
      "grad_norm": 0.14659692347049713,
      "learning_rate": 2.523252837272805e-05,
      "loss": 0.0016,
      "step": 58050
    },
    {
      "epoch": 4.954347640583667,
      "grad_norm": 0.1874699741601944,
      "learning_rate": 2.5228261797081666e-05,
      "loss": 0.0014,
      "step": 58060
    },
    {
      "epoch": 4.955200955712945,
      "grad_norm": 0.061009135097265244,
      "learning_rate": 2.5223995221435277e-05,
      "loss": 0.0017,
      "step": 58070
    },
    {
      "epoch": 4.956054270842222,
      "grad_norm": 0.20353932678699493,
      "learning_rate": 2.521972864578889e-05,
      "loss": 0.0018,
      "step": 58080
    },
    {
      "epoch": 4.956907585971499,
      "grad_norm": 0.17146266996860504,
      "learning_rate": 2.5215462070142502e-05,
      "loss": 0.0022,
      "step": 58090
    },
    {
      "epoch": 4.957760901100777,
      "grad_norm": 0.1479547917842865,
      "learning_rate": 2.521119549449612e-05,
      "loss": 0.0017,
      "step": 58100
    },
    {
      "epoch": 4.958614216230053,
      "grad_norm": 0.04212469235062599,
      "learning_rate": 2.520692891884973e-05,
      "loss": 0.0021,
      "step": 58110
    },
    {
      "epoch": 4.959467531359331,
      "grad_norm": 0.11736077070236206,
      "learning_rate": 2.520266234320335e-05,
      "loss": 0.0019,
      "step": 58120
    },
    {
      "epoch": 4.960320846488608,
      "grad_norm": 0.17756927013397217,
      "learning_rate": 2.519839576755696e-05,
      "loss": 0.0021,
      "step": 58130
    },
    {
      "epoch": 4.961174161617885,
      "grad_norm": 0.18655525147914886,
      "learning_rate": 2.5194129191910577e-05,
      "loss": 0.0021,
      "step": 58140
    },
    {
      "epoch": 4.962027476747163,
      "grad_norm": 0.20574431121349335,
      "learning_rate": 2.5189862616264188e-05,
      "loss": 0.0017,
      "step": 58150
    },
    {
      "epoch": 4.96288079187644,
      "grad_norm": 0.04536273330450058,
      "learning_rate": 2.5185596040617805e-05,
      "loss": 0.0025,
      "step": 58160
    },
    {
      "epoch": 4.963734107005717,
      "grad_norm": 0.27892401814460754,
      "learning_rate": 2.5181329464971416e-05,
      "loss": 0.0014,
      "step": 58170
    },
    {
      "epoch": 4.964587422134994,
      "grad_norm": 0.31494078040122986,
      "learning_rate": 2.517706288932503e-05,
      "loss": 0.0019,
      "step": 58180
    },
    {
      "epoch": 4.965440737264272,
      "grad_norm": 0.1532684713602066,
      "learning_rate": 2.517279631367864e-05,
      "loss": 0.0017,
      "step": 58190
    },
    {
      "epoch": 4.966294052393549,
      "grad_norm": 0.12791277468204498,
      "learning_rate": 2.5168529738032252e-05,
      "loss": 0.0018,
      "step": 58200
    },
    {
      "epoch": 4.967147367522826,
      "grad_norm": 0.1368633508682251,
      "learning_rate": 2.516426316238587e-05,
      "loss": 0.0023,
      "step": 58210
    },
    {
      "epoch": 4.968000682652104,
      "grad_norm": 0.25859418511390686,
      "learning_rate": 2.515999658673948e-05,
      "loss": 0.0018,
      "step": 58220
    },
    {
      "epoch": 4.96885399778138,
      "grad_norm": 0.11448399722576141,
      "learning_rate": 2.51557300110931e-05,
      "loss": 0.0017,
      "step": 58230
    },
    {
      "epoch": 4.969707312910658,
      "grad_norm": 0.16766373813152313,
      "learning_rate": 2.515146343544671e-05,
      "loss": 0.0019,
      "step": 58240
    },
    {
      "epoch": 4.9705606280399355,
      "grad_norm": 0.10295820236206055,
      "learning_rate": 2.5147196859800327e-05,
      "loss": 0.002,
      "step": 58250
    },
    {
      "epoch": 4.971413943169212,
      "grad_norm": 0.09836645424365997,
      "learning_rate": 2.5142930284153938e-05,
      "loss": 0.002,
      "step": 58260
    },
    {
      "epoch": 4.97226725829849,
      "grad_norm": 0.1499803066253662,
      "learning_rate": 2.5138663708507555e-05,
      "loss": 0.0013,
      "step": 58270
    },
    {
      "epoch": 4.973120573427767,
      "grad_norm": 0.24366284906864166,
      "learning_rate": 2.5134397132861166e-05,
      "loss": 0.002,
      "step": 58280
    },
    {
      "epoch": 4.973973888557044,
      "grad_norm": 0.14033319056034088,
      "learning_rate": 2.513013055721478e-05,
      "loss": 0.0016,
      "step": 58290
    },
    {
      "epoch": 4.9748272036863215,
      "grad_norm": 0.28439587354660034,
      "learning_rate": 2.512586398156839e-05,
      "loss": 0.0015,
      "step": 58300
    },
    {
      "epoch": 4.975680518815599,
      "grad_norm": 0.25904589891433716,
      "learning_rate": 2.512159740592201e-05,
      "loss": 0.0019,
      "step": 58310
    },
    {
      "epoch": 4.976533833944876,
      "grad_norm": 0.20433078706264496,
      "learning_rate": 2.511733083027562e-05,
      "loss": 0.0017,
      "step": 58320
    },
    {
      "epoch": 4.977387149074153,
      "grad_norm": 0.3323042392730713,
      "learning_rate": 2.5113064254629237e-05,
      "loss": 0.0025,
      "step": 58330
    },
    {
      "epoch": 4.978240464203431,
      "grad_norm": 0.13143390417099,
      "learning_rate": 2.5108797678982848e-05,
      "loss": 0.0018,
      "step": 58340
    },
    {
      "epoch": 4.9790937793327075,
      "grad_norm": 0.027208592742681503,
      "learning_rate": 2.5104531103336466e-05,
      "loss": 0.0021,
      "step": 58350
    },
    {
      "epoch": 4.979947094461985,
      "grad_norm": 0.22217890620231628,
      "learning_rate": 2.5100264527690077e-05,
      "loss": 0.0018,
      "step": 58360
    },
    {
      "epoch": 4.980800409591262,
      "grad_norm": 0.20131909847259521,
      "learning_rate": 2.5095997952043694e-05,
      "loss": 0.0017,
      "step": 58370
    },
    {
      "epoch": 4.981653724720539,
      "grad_norm": 0.03083578310906887,
      "learning_rate": 2.5091731376397305e-05,
      "loss": 0.0017,
      "step": 58380
    },
    {
      "epoch": 4.982507039849817,
      "grad_norm": 0.15337973833084106,
      "learning_rate": 2.508746480075092e-05,
      "loss": 0.0016,
      "step": 58390
    },
    {
      "epoch": 4.9833603549790935,
      "grad_norm": 0.03596148267388344,
      "learning_rate": 2.508319822510453e-05,
      "loss": 0.0019,
      "step": 58400
    },
    {
      "epoch": 4.984213670108371,
      "grad_norm": 0.14765705168247223,
      "learning_rate": 2.5078931649458148e-05,
      "loss": 0.0029,
      "step": 58410
    },
    {
      "epoch": 4.985066985237649,
      "grad_norm": 0.4387754797935486,
      "learning_rate": 2.507466507381176e-05,
      "loss": 0.0019,
      "step": 58420
    },
    {
      "epoch": 4.985920300366925,
      "grad_norm": 0.14700958132743835,
      "learning_rate": 2.5070398498165376e-05,
      "loss": 0.0025,
      "step": 58430
    },
    {
      "epoch": 4.986773615496203,
      "grad_norm": 0.0496450737118721,
      "learning_rate": 2.5066131922518987e-05,
      "loss": 0.0021,
      "step": 58440
    },
    {
      "epoch": 4.98762693062548,
      "grad_norm": 0.16937115788459778,
      "learning_rate": 2.5061865346872605e-05,
      "loss": 0.0018,
      "step": 58450
    },
    {
      "epoch": 4.988480245754757,
      "grad_norm": 0.24265322089195251,
      "learning_rate": 2.5057598771226216e-05,
      "loss": 0.0014,
      "step": 58460
    },
    {
      "epoch": 4.989333560884035,
      "grad_norm": 0.2919597923755646,
      "learning_rate": 2.5053332195579827e-05,
      "loss": 0.0017,
      "step": 58470
    },
    {
      "epoch": 4.990186876013311,
      "grad_norm": 0.16847698390483856,
      "learning_rate": 2.5049065619933444e-05,
      "loss": 0.002,
      "step": 58480
    },
    {
      "epoch": 4.991040191142589,
      "grad_norm": 0.10584811866283417,
      "learning_rate": 2.5044799044287055e-05,
      "loss": 0.0017,
      "step": 58490
    },
    {
      "epoch": 4.991893506271866,
      "grad_norm": 0.3843107223510742,
      "learning_rate": 2.504053246864067e-05,
      "loss": 0.0018,
      "step": 58500
    },
    {
      "epoch": 4.992746821401143,
      "grad_norm": 0.36996328830718994,
      "learning_rate": 2.503626589299428e-05,
      "loss": 0.0017,
      "step": 58510
    },
    {
      "epoch": 4.993600136530421,
      "grad_norm": 0.1682097315788269,
      "learning_rate": 2.5031999317347898e-05,
      "loss": 0.0019,
      "step": 58520
    },
    {
      "epoch": 4.994453451659698,
      "grad_norm": 0.11378540098667145,
      "learning_rate": 2.502773274170151e-05,
      "loss": 0.002,
      "step": 58530
    },
    {
      "epoch": 4.995306766788975,
      "grad_norm": 0.24159546196460724,
      "learning_rate": 2.5023466166055126e-05,
      "loss": 0.002,
      "step": 58540
    },
    {
      "epoch": 4.996160081918252,
      "grad_norm": 0.09592290967702866,
      "learning_rate": 2.5019199590408737e-05,
      "loss": 0.0022,
      "step": 58550
    },
    {
      "epoch": 4.99701339704753,
      "grad_norm": 0.5045368075370789,
      "learning_rate": 2.5014933014762355e-05,
      "loss": 0.0024,
      "step": 58560
    },
    {
      "epoch": 4.997866712176807,
      "grad_norm": 0.17232473194599152,
      "learning_rate": 2.5010666439115966e-05,
      "loss": 0.0017,
      "step": 58570
    },
    {
      "epoch": 4.998720027306084,
      "grad_norm": 0.07458513975143433,
      "learning_rate": 2.5006399863469583e-05,
      "loss": 0.0017,
      "step": 58580
    },
    {
      "epoch": 4.999573342435362,
      "grad_norm": 0.3282986879348755,
      "learning_rate": 2.5002133287823194e-05,
      "loss": 0.0019,
      "step": 58590
    },
    {
      "epoch": 5.0,
      "eval_loss": 0.0019171599997207522,
      "eval_runtime": 99.8359,
      "eval_samples_per_second": 1502.465,
      "eval_steps_per_second": 23.479,
      "step": 58595
    },
    {
      "epoch": 5.000426657564638,
      "grad_norm": 0.3689191937446594,
      "learning_rate": 2.499786671217681e-05,
      "loss": 0.002,
      "step": 58600
    },
    {
      "epoch": 5.001279972693916,
      "grad_norm": 0.4799303114414215,
      "learning_rate": 2.499360013653042e-05,
      "loss": 0.0022,
      "step": 58610
    },
    {
      "epoch": 5.002133287823193,
      "grad_norm": 0.22163288295269012,
      "learning_rate": 2.4989333560884033e-05,
      "loss": 0.002,
      "step": 58620
    },
    {
      "epoch": 5.00298660295247,
      "grad_norm": 0.21702170372009277,
      "learning_rate": 2.4985066985237648e-05,
      "loss": 0.0023,
      "step": 58630
    },
    {
      "epoch": 5.003839918081748,
      "grad_norm": 0.32039546966552734,
      "learning_rate": 2.4980800409591262e-05,
      "loss": 0.0018,
      "step": 58640
    },
    {
      "epoch": 5.004693233211025,
      "grad_norm": 0.22097912430763245,
      "learning_rate": 2.4976533833944876e-05,
      "loss": 0.0027,
      "step": 58650
    },
    {
      "epoch": 5.005546548340302,
      "grad_norm": 0.04018888249993324,
      "learning_rate": 2.497226725829849e-05,
      "loss": 0.0025,
      "step": 58660
    },
    {
      "epoch": 5.006399863469579,
      "grad_norm": 0.09526459872722626,
      "learning_rate": 2.4968000682652105e-05,
      "loss": 0.002,
      "step": 58670
    },
    {
      "epoch": 5.007253178598857,
      "grad_norm": 0.22647330164909363,
      "learning_rate": 2.496373410700572e-05,
      "loss": 0.0023,
      "step": 58680
    },
    {
      "epoch": 5.008106493728134,
      "grad_norm": 0.16772687435150146,
      "learning_rate": 2.4959467531359333e-05,
      "loss": 0.0019,
      "step": 58690
    },
    {
      "epoch": 5.008959808857411,
      "grad_norm": 0.028486812487244606,
      "learning_rate": 2.4955200955712947e-05,
      "loss": 0.0019,
      "step": 58700
    },
    {
      "epoch": 5.009813123986688,
      "grad_norm": 0.31494995951652527,
      "learning_rate": 2.4950934380066558e-05,
      "loss": 0.0016,
      "step": 58710
    },
    {
      "epoch": 5.010666439115965,
      "grad_norm": 0.3788433074951172,
      "learning_rate": 2.4946667804420172e-05,
      "loss": 0.0018,
      "step": 58720
    },
    {
      "epoch": 5.011519754245243,
      "grad_norm": 0.22145718336105347,
      "learning_rate": 2.4942401228773787e-05,
      "loss": 0.0021,
      "step": 58730
    },
    {
      "epoch": 5.01237306937452,
      "grad_norm": 0.2021535187959671,
      "learning_rate": 2.49381346531274e-05,
      "loss": 0.0014,
      "step": 58740
    },
    {
      "epoch": 5.013226384503797,
      "grad_norm": 0.22269804775714874,
      "learning_rate": 2.4933868077481015e-05,
      "loss": 0.0016,
      "step": 58750
    },
    {
      "epoch": 5.014079699633075,
      "grad_norm": 0.22270406782627106,
      "learning_rate": 2.492960150183463e-05,
      "loss": 0.0019,
      "step": 58760
    },
    {
      "epoch": 5.014933014762351,
      "grad_norm": 0.21818907558918,
      "learning_rate": 2.4925334926188244e-05,
      "loss": 0.0019,
      "step": 58770
    },
    {
      "epoch": 5.015786329891629,
      "grad_norm": 0.1858312338590622,
      "learning_rate": 2.4921068350541858e-05,
      "loss": 0.0018,
      "step": 58780
    },
    {
      "epoch": 5.0166396450209065,
      "grad_norm": 0.04920751973986626,
      "learning_rate": 2.4916801774895472e-05,
      "loss": 0.0016,
      "step": 58790
    },
    {
      "epoch": 5.017492960150183,
      "grad_norm": 0.2039150893688202,
      "learning_rate": 2.4912535199249083e-05,
      "loss": 0.0022,
      "step": 58800
    },
    {
      "epoch": 5.018346275279461,
      "grad_norm": 0.11253640055656433,
      "learning_rate": 2.4908268623602697e-05,
      "loss": 0.0016,
      "step": 58810
    },
    {
      "epoch": 5.019199590408738,
      "grad_norm": 0.16575127840042114,
      "learning_rate": 2.490400204795631e-05,
      "loss": 0.0017,
      "step": 58820
    },
    {
      "epoch": 5.020052905538015,
      "grad_norm": 0.12990297377109528,
      "learning_rate": 2.4899735472309926e-05,
      "loss": 0.002,
      "step": 58830
    },
    {
      "epoch": 5.0209062206672925,
      "grad_norm": 0.2906331717967987,
      "learning_rate": 2.489546889666354e-05,
      "loss": 0.0021,
      "step": 58840
    },
    {
      "epoch": 5.02175953579657,
      "grad_norm": 0.1636054515838623,
      "learning_rate": 2.4891202321017154e-05,
      "loss": 0.0019,
      "step": 58850
    },
    {
      "epoch": 5.022612850925847,
      "grad_norm": 0.21890167891979218,
      "learning_rate": 2.488693574537077e-05,
      "loss": 0.0016,
      "step": 58860
    },
    {
      "epoch": 5.023466166055124,
      "grad_norm": 0.12820205092430115,
      "learning_rate": 2.488266916972438e-05,
      "loss": 0.0015,
      "step": 58870
    },
    {
      "epoch": 5.024319481184401,
      "grad_norm": 0.16585871577262878,
      "learning_rate": 2.4878402594077994e-05,
      "loss": 0.0021,
      "step": 58880
    },
    {
      "epoch": 5.0251727963136785,
      "grad_norm": 0.09706518799066544,
      "learning_rate": 2.4874136018431608e-05,
      "loss": 0.0019,
      "step": 58890
    },
    {
      "epoch": 5.026026111442956,
      "grad_norm": 0.18838189542293549,
      "learning_rate": 2.4869869442785222e-05,
      "loss": 0.0022,
      "step": 58900
    },
    {
      "epoch": 5.026879426572233,
      "grad_norm": 0.18039487302303314,
      "learning_rate": 2.4865602867138836e-05,
      "loss": 0.0024,
      "step": 58910
    },
    {
      "epoch": 5.02773274170151,
      "grad_norm": 0.39971640706062317,
      "learning_rate": 2.4861336291492447e-05,
      "loss": 0.0021,
      "step": 58920
    },
    {
      "epoch": 5.028586056830788,
      "grad_norm": 0.1976727694272995,
      "learning_rate": 2.485706971584606e-05,
      "loss": 0.0022,
      "step": 58930
    },
    {
      "epoch": 5.0294393719600645,
      "grad_norm": 0.258903831243515,
      "learning_rate": 2.4852803140199676e-05,
      "loss": 0.0016,
      "step": 58940
    },
    {
      "epoch": 5.030292687089342,
      "grad_norm": 0.04865444824099541,
      "learning_rate": 2.484853656455329e-05,
      "loss": 0.0022,
      "step": 58950
    },
    {
      "epoch": 5.03114600221862,
      "grad_norm": 0.1732046902179718,
      "learning_rate": 2.4844269988906904e-05,
      "loss": 0.0021,
      "step": 58960
    },
    {
      "epoch": 5.031999317347896,
      "grad_norm": 0.22010116279125214,
      "learning_rate": 2.4840003413260518e-05,
      "loss": 0.0017,
      "step": 58970
    },
    {
      "epoch": 5.032852632477174,
      "grad_norm": 0.0318746455013752,
      "learning_rate": 2.4835736837614133e-05,
      "loss": 0.0018,
      "step": 58980
    },
    {
      "epoch": 5.033705947606451,
      "grad_norm": 0.4392234683036804,
      "learning_rate": 2.4831470261967747e-05,
      "loss": 0.0018,
      "step": 58990
    },
    {
      "epoch": 5.034559262735728,
      "grad_norm": 0.03135386481881142,
      "learning_rate": 2.482720368632136e-05,
      "loss": 0.0017,
      "step": 59000
    },
    {
      "epoch": 5.035412577865006,
      "grad_norm": 0.3318948745727539,
      "learning_rate": 2.4822937110674975e-05,
      "loss": 0.0019,
      "step": 59010
    },
    {
      "epoch": 5.036265892994283,
      "grad_norm": 0.14957433938980103,
      "learning_rate": 2.4818670535028586e-05,
      "loss": 0.0019,
      "step": 59020
    },
    {
      "epoch": 5.03711920812356,
      "grad_norm": 0.29180681705474854,
      "learning_rate": 2.48144039593822e-05,
      "loss": 0.002,
      "step": 59030
    },
    {
      "epoch": 5.037972523252837,
      "grad_norm": 0.3447631895542145,
      "learning_rate": 2.4810137383735815e-05,
      "loss": 0.0018,
      "step": 59040
    },
    {
      "epoch": 5.038825838382115,
      "grad_norm": 0.1390860676765442,
      "learning_rate": 2.480587080808943e-05,
      "loss": 0.0025,
      "step": 59050
    },
    {
      "epoch": 5.039679153511392,
      "grad_norm": 0.10900430381298065,
      "learning_rate": 2.4801604232443043e-05,
      "loss": 0.0021,
      "step": 59060
    },
    {
      "epoch": 5.040532468640669,
      "grad_norm": 0.3169358968734741,
      "learning_rate": 2.4797337656796657e-05,
      "loss": 0.0022,
      "step": 59070
    },
    {
      "epoch": 5.041385783769946,
      "grad_norm": 0.24453780055046082,
      "learning_rate": 2.479307108115027e-05,
      "loss": 0.0016,
      "step": 59080
    },
    {
      "epoch": 5.042239098899223,
      "grad_norm": 0.027556393295526505,
      "learning_rate": 2.4788804505503886e-05,
      "loss": 0.0014,
      "step": 59090
    },
    {
      "epoch": 5.043092414028501,
      "grad_norm": 0.19729329645633698,
      "learning_rate": 2.47845379298575e-05,
      "loss": 0.0014,
      "step": 59100
    },
    {
      "epoch": 5.043945729157778,
      "grad_norm": 0.07941614091396332,
      "learning_rate": 2.478027135421111e-05,
      "loss": 0.0014,
      "step": 59110
    },
    {
      "epoch": 5.044799044287055,
      "grad_norm": 0.08122800290584564,
      "learning_rate": 2.4776004778564725e-05,
      "loss": 0.0017,
      "step": 59120
    },
    {
      "epoch": 5.045652359416333,
      "grad_norm": 0.13089358806610107,
      "learning_rate": 2.4771738202918336e-05,
      "loss": 0.002,
      "step": 59130
    },
    {
      "epoch": 5.046505674545609,
      "grad_norm": 0.14761440455913544,
      "learning_rate": 2.476747162727195e-05,
      "loss": 0.0018,
      "step": 59140
    },
    {
      "epoch": 5.047358989674887,
      "grad_norm": 0.028834400698542595,
      "learning_rate": 2.4763205051625564e-05,
      "loss": 0.002,
      "step": 59150
    },
    {
      "epoch": 5.0482123048041645,
      "grad_norm": 0.09534066915512085,
      "learning_rate": 2.475893847597918e-05,
      "loss": 0.0025,
      "step": 59160
    },
    {
      "epoch": 5.049065619933441,
      "grad_norm": 0.22538964450359344,
      "learning_rate": 2.4754671900332793e-05,
      "loss": 0.0018,
      "step": 59170
    },
    {
      "epoch": 5.049918935062719,
      "grad_norm": 0.10277356952428818,
      "learning_rate": 2.4750405324686407e-05,
      "loss": 0.0016,
      "step": 59180
    },
    {
      "epoch": 5.050772250191996,
      "grad_norm": 0.14647391438484192,
      "learning_rate": 2.474613874904002e-05,
      "loss": 0.0017,
      "step": 59190
    },
    {
      "epoch": 5.051625565321273,
      "grad_norm": 0.04695136100053787,
      "learning_rate": 2.4741872173393636e-05,
      "loss": 0.0016,
      "step": 59200
    },
    {
      "epoch": 5.0524788804505505,
      "grad_norm": 0.28024399280548096,
      "learning_rate": 2.473760559774725e-05,
      "loss": 0.002,
      "step": 59210
    },
    {
      "epoch": 5.053332195579828,
      "grad_norm": 0.060446083545684814,
      "learning_rate": 2.4733339022100864e-05,
      "loss": 0.0023,
      "step": 59220
    },
    {
      "epoch": 5.054185510709105,
      "grad_norm": 0.07452721148729324,
      "learning_rate": 2.4729072446454475e-05,
      "loss": 0.0017,
      "step": 59230
    },
    {
      "epoch": 5.055038825838382,
      "grad_norm": 0.1812225580215454,
      "learning_rate": 2.472480587080809e-05,
      "loss": 0.0019,
      "step": 59240
    },
    {
      "epoch": 5.055892140967659,
      "grad_norm": 0.28092774748802185,
      "learning_rate": 2.4720539295161703e-05,
      "loss": 0.0019,
      "step": 59250
    },
    {
      "epoch": 5.0567454560969365,
      "grad_norm": 0.10836958885192871,
      "learning_rate": 2.4716272719515318e-05,
      "loss": 0.0014,
      "step": 59260
    },
    {
      "epoch": 5.057598771226214,
      "grad_norm": 0.22972360253334045,
      "learning_rate": 2.4712006143868932e-05,
      "loss": 0.0026,
      "step": 59270
    },
    {
      "epoch": 5.058452086355491,
      "grad_norm": 0.08343596011400223,
      "learning_rate": 2.4707739568222546e-05,
      "loss": 0.0019,
      "step": 59280
    },
    {
      "epoch": 5.059305401484768,
      "grad_norm": 0.1940392106771469,
      "learning_rate": 2.470347299257616e-05,
      "loss": 0.0022,
      "step": 59290
    },
    {
      "epoch": 5.060158716614046,
      "grad_norm": 0.05616996809840202,
      "learning_rate": 2.4699206416929775e-05,
      "loss": 0.0016,
      "step": 59300
    },
    {
      "epoch": 5.0610120317433225,
      "grad_norm": 0.2438742071390152,
      "learning_rate": 2.469493984128339e-05,
      "loss": 0.0019,
      "step": 59310
    },
    {
      "epoch": 5.0618653468726,
      "grad_norm": 0.035148970782756805,
      "learning_rate": 2.4690673265637003e-05,
      "loss": 0.0018,
      "step": 59320
    },
    {
      "epoch": 5.062718662001878,
      "grad_norm": 0.14888794720172882,
      "learning_rate": 2.4686406689990614e-05,
      "loss": 0.0018,
      "step": 59330
    },
    {
      "epoch": 5.063571977131154,
      "grad_norm": 0.18745553493499756,
      "learning_rate": 2.4682140114344228e-05,
      "loss": 0.0017,
      "step": 59340
    },
    {
      "epoch": 5.064425292260432,
      "grad_norm": 0.03682480379939079,
      "learning_rate": 2.4677873538697843e-05,
      "loss": 0.0018,
      "step": 59350
    },
    {
      "epoch": 5.065278607389709,
      "grad_norm": 0.5700821280479431,
      "learning_rate": 2.4673606963051457e-05,
      "loss": 0.0019,
      "step": 59360
    },
    {
      "epoch": 5.066131922518986,
      "grad_norm": 0.02915889024734497,
      "learning_rate": 2.466934038740507e-05,
      "loss": 0.0018,
      "step": 59370
    },
    {
      "epoch": 5.066985237648264,
      "grad_norm": 0.04570220410823822,
      "learning_rate": 2.4665073811758685e-05,
      "loss": 0.0015,
      "step": 59380
    },
    {
      "epoch": 5.067838552777541,
      "grad_norm": 0.23493258655071259,
      "learning_rate": 2.46608072361123e-05,
      "loss": 0.0015,
      "step": 59390
    },
    {
      "epoch": 5.068691867906818,
      "grad_norm": 0.25618770718574524,
      "learning_rate": 2.465654066046591e-05,
      "loss": 0.0017,
      "step": 59400
    },
    {
      "epoch": 5.069545183036095,
      "grad_norm": 0.16894683241844177,
      "learning_rate": 2.4652274084819525e-05,
      "loss": 0.0027,
      "step": 59410
    },
    {
      "epoch": 5.070398498165373,
      "grad_norm": 0.04685773700475693,
      "learning_rate": 2.464800750917314e-05,
      "loss": 0.0013,
      "step": 59420
    },
    {
      "epoch": 5.07125181329465,
      "grad_norm": 0.2193833291530609,
      "learning_rate": 2.4643740933526753e-05,
      "loss": 0.0017,
      "step": 59430
    },
    {
      "epoch": 5.072105128423927,
      "grad_norm": 0.11588215082883835,
      "learning_rate": 2.4639474357880364e-05,
      "loss": 0.0021,
      "step": 59440
    },
    {
      "epoch": 5.072958443553204,
      "grad_norm": 0.08951140940189362,
      "learning_rate": 2.4635207782233978e-05,
      "loss": 0.0018,
      "step": 59450
    },
    {
      "epoch": 5.073811758682481,
      "grad_norm": 0.3455539345741272,
      "learning_rate": 2.4630941206587592e-05,
      "loss": 0.002,
      "step": 59460
    },
    {
      "epoch": 5.074665073811759,
      "grad_norm": 0.028719071298837662,
      "learning_rate": 2.4626674630941207e-05,
      "loss": 0.0018,
      "step": 59470
    },
    {
      "epoch": 5.075518388941036,
      "grad_norm": 0.2737681567668915,
      "learning_rate": 2.462240805529482e-05,
      "loss": 0.0021,
      "step": 59480
    },
    {
      "epoch": 5.076371704070313,
      "grad_norm": 0.16457197070121765,
      "learning_rate": 2.4618141479648435e-05,
      "loss": 0.0029,
      "step": 59490
    },
    {
      "epoch": 5.077225019199591,
      "grad_norm": 0.23425224423408508,
      "learning_rate": 2.461387490400205e-05,
      "loss": 0.0023,
      "step": 59500
    },
    {
      "epoch": 5.078078334328867,
      "grad_norm": 0.3849457800388336,
      "learning_rate": 2.4609608328355664e-05,
      "loss": 0.0017,
      "step": 59510
    },
    {
      "epoch": 5.078931649458145,
      "grad_norm": 0.09474989771842957,
      "learning_rate": 2.4605341752709278e-05,
      "loss": 0.0018,
      "step": 59520
    },
    {
      "epoch": 5.0797849645874225,
      "grad_norm": 0.11629033833742142,
      "learning_rate": 2.4601075177062892e-05,
      "loss": 0.0014,
      "step": 59530
    },
    {
      "epoch": 5.080638279716699,
      "grad_norm": 0.3898460865020752,
      "learning_rate": 2.4596808601416503e-05,
      "loss": 0.0016,
      "step": 59540
    },
    {
      "epoch": 5.081491594845977,
      "grad_norm": 0.132878378033638,
      "learning_rate": 2.4592542025770117e-05,
      "loss": 0.0016,
      "step": 59550
    },
    {
      "epoch": 5.082344909975254,
      "grad_norm": 0.4431707262992859,
      "learning_rate": 2.458827545012373e-05,
      "loss": 0.0018,
      "step": 59560
    },
    {
      "epoch": 5.083198225104531,
      "grad_norm": 0.3465879261493683,
      "learning_rate": 2.4584008874477346e-05,
      "loss": 0.002,
      "step": 59570
    },
    {
      "epoch": 5.0840515402338085,
      "grad_norm": 0.38131779432296753,
      "learning_rate": 2.457974229883096e-05,
      "loss": 0.0018,
      "step": 59580
    },
    {
      "epoch": 5.084904855363086,
      "grad_norm": 0.11514031141996384,
      "learning_rate": 2.4575475723184574e-05,
      "loss": 0.0018,
      "step": 59590
    },
    {
      "epoch": 5.085758170492363,
      "grad_norm": 0.12772978842258453,
      "learning_rate": 2.457120914753819e-05,
      "loss": 0.0022,
      "step": 59600
    },
    {
      "epoch": 5.08661148562164,
      "grad_norm": 0.12657997012138367,
      "learning_rate": 2.4566942571891803e-05,
      "loss": 0.0016,
      "step": 59610
    },
    {
      "epoch": 5.087464800750917,
      "grad_norm": 0.20533044636249542,
      "learning_rate": 2.4562675996245417e-05,
      "loss": 0.0024,
      "step": 59620
    },
    {
      "epoch": 5.0883181158801944,
      "grad_norm": 0.2611493766307831,
      "learning_rate": 2.455840942059903e-05,
      "loss": 0.0019,
      "step": 59630
    },
    {
      "epoch": 5.089171431009472,
      "grad_norm": 0.09695304930210114,
      "learning_rate": 2.4554142844952642e-05,
      "loss": 0.0016,
      "step": 59640
    },
    {
      "epoch": 5.090024746138749,
      "grad_norm": 0.16838307678699493,
      "learning_rate": 2.4549876269306256e-05,
      "loss": 0.0018,
      "step": 59650
    },
    {
      "epoch": 5.090878061268026,
      "grad_norm": 0.11764517426490784,
      "learning_rate": 2.4545609693659867e-05,
      "loss": 0.0015,
      "step": 59660
    },
    {
      "epoch": 5.091731376397304,
      "grad_norm": 0.22162161767482758,
      "learning_rate": 2.454134311801348e-05,
      "loss": 0.0017,
      "step": 59670
    },
    {
      "epoch": 5.09258469152658,
      "grad_norm": 0.15244898200035095,
      "learning_rate": 2.4537076542367096e-05,
      "loss": 0.0018,
      "step": 59680
    },
    {
      "epoch": 5.093438006655858,
      "grad_norm": 0.07379074394702911,
      "learning_rate": 2.453280996672071e-05,
      "loss": 0.0015,
      "step": 59690
    },
    {
      "epoch": 5.0942913217851356,
      "grad_norm": 0.26445671916007996,
      "learning_rate": 2.4528543391074324e-05,
      "loss": 0.002,
      "step": 59700
    },
    {
      "epoch": 5.095144636914412,
      "grad_norm": 0.11690644919872284,
      "learning_rate": 2.4524276815427938e-05,
      "loss": 0.0021,
      "step": 59710
    },
    {
      "epoch": 5.09599795204369,
      "grad_norm": 0.19088561832904816,
      "learning_rate": 2.4520010239781552e-05,
      "loss": 0.002,
      "step": 59720
    },
    {
      "epoch": 5.096851267172967,
      "grad_norm": 0.3196905553340912,
      "learning_rate": 2.4515743664135167e-05,
      "loss": 0.002,
      "step": 59730
    },
    {
      "epoch": 5.097704582302244,
      "grad_norm": 0.1355854570865631,
      "learning_rate": 2.451147708848878e-05,
      "loss": 0.0018,
      "step": 59740
    },
    {
      "epoch": 5.0985578974315215,
      "grad_norm": 0.17047357559204102,
      "learning_rate": 2.4507210512842392e-05,
      "loss": 0.0022,
      "step": 59750
    },
    {
      "epoch": 5.099411212560799,
      "grad_norm": 0.18440891802310944,
      "learning_rate": 2.4502943937196006e-05,
      "loss": 0.0016,
      "step": 59760
    },
    {
      "epoch": 5.100264527690076,
      "grad_norm": 0.4954491853713989,
      "learning_rate": 2.449867736154962e-05,
      "loss": 0.0018,
      "step": 59770
    },
    {
      "epoch": 5.101117842819353,
      "grad_norm": 0.04421057552099228,
      "learning_rate": 2.4494410785903235e-05,
      "loss": 0.002,
      "step": 59780
    },
    {
      "epoch": 5.101971157948631,
      "grad_norm": 0.220515638589859,
      "learning_rate": 2.449014421025685e-05,
      "loss": 0.0025,
      "step": 59790
    },
    {
      "epoch": 5.1028244730779075,
      "grad_norm": 0.5048735737800598,
      "learning_rate": 2.4485877634610463e-05,
      "loss": 0.0021,
      "step": 59800
    },
    {
      "epoch": 5.103677788207185,
      "grad_norm": 0.5563430786132812,
      "learning_rate": 2.4481611058964077e-05,
      "loss": 0.0016,
      "step": 59810
    },
    {
      "epoch": 5.104531103336462,
      "grad_norm": 0.42490851879119873,
      "learning_rate": 2.447734448331769e-05,
      "loss": 0.0018,
      "step": 59820
    },
    {
      "epoch": 5.105384418465739,
      "grad_norm": 0.13244149088859558,
      "learning_rate": 2.4473077907671306e-05,
      "loss": 0.0013,
      "step": 59830
    },
    {
      "epoch": 5.106237733595017,
      "grad_norm": 0.2442864030599594,
      "learning_rate": 2.446881133202492e-05,
      "loss": 0.0014,
      "step": 59840
    },
    {
      "epoch": 5.1070910487242935,
      "grad_norm": 0.10992289334535599,
      "learning_rate": 2.446454475637853e-05,
      "loss": 0.0017,
      "step": 59850
    },
    {
      "epoch": 5.107944363853571,
      "grad_norm": 0.14848630130290985,
      "learning_rate": 2.4460278180732145e-05,
      "loss": 0.0017,
      "step": 59860
    },
    {
      "epoch": 5.108797678982849,
      "grad_norm": 0.14833690226078033,
      "learning_rate": 2.445601160508576e-05,
      "loss": 0.0015,
      "step": 59870
    },
    {
      "epoch": 5.109650994112125,
      "grad_norm": 0.048711273819208145,
      "learning_rate": 2.4451745029439374e-05,
      "loss": 0.0014,
      "step": 59880
    },
    {
      "epoch": 5.110504309241403,
      "grad_norm": 0.0947127565741539,
      "learning_rate": 2.4447478453792988e-05,
      "loss": 0.0018,
      "step": 59890
    },
    {
      "epoch": 5.11135762437068,
      "grad_norm": 0.16602274775505066,
      "learning_rate": 2.4443211878146602e-05,
      "loss": 0.002,
      "step": 59900
    },
    {
      "epoch": 5.112210939499957,
      "grad_norm": 0.14033080637454987,
      "learning_rate": 2.4438945302500216e-05,
      "loss": 0.0016,
      "step": 59910
    },
    {
      "epoch": 5.113064254629235,
      "grad_norm": 0.0806608721613884,
      "learning_rate": 2.443467872685383e-05,
      "loss": 0.0017,
      "step": 59920
    },
    {
      "epoch": 5.113917569758512,
      "grad_norm": 0.1235462948679924,
      "learning_rate": 2.443041215120744e-05,
      "loss": 0.0022,
      "step": 59930
    },
    {
      "epoch": 5.114770884887789,
      "grad_norm": 0.0975627526640892,
      "learning_rate": 2.4426145575561056e-05,
      "loss": 0.002,
      "step": 59940
    },
    {
      "epoch": 5.115624200017066,
      "grad_norm": 0.07772254198789597,
      "learning_rate": 2.442187899991467e-05,
      "loss": 0.0019,
      "step": 59950
    },
    {
      "epoch": 5.116477515146344,
      "grad_norm": 0.1712842881679535,
      "learning_rate": 2.4417612424268284e-05,
      "loss": 0.0016,
      "step": 59960
    },
    {
      "epoch": 5.117330830275621,
      "grad_norm": 0.32712113857269287,
      "learning_rate": 2.4413345848621895e-05,
      "loss": 0.0019,
      "step": 59970
    },
    {
      "epoch": 5.118184145404898,
      "grad_norm": 0.076299287378788,
      "learning_rate": 2.440907927297551e-05,
      "loss": 0.0019,
      "step": 59980
    },
    {
      "epoch": 5.119037460534175,
      "grad_norm": 0.22784222662448883,
      "learning_rate": 2.4404812697329123e-05,
      "loss": 0.0017,
      "step": 59990
    },
    {
      "epoch": 5.119890775663452,
      "grad_norm": 0.25763043761253357,
      "learning_rate": 2.4400546121682738e-05,
      "loss": 0.0018,
      "step": 60000
    },
    {
      "epoch": 5.12074409079273,
      "grad_norm": 0.03799784556031227,
      "learning_rate": 2.4396279546036352e-05,
      "loss": 0.0019,
      "step": 60010
    },
    {
      "epoch": 5.121597405922007,
      "grad_norm": 0.3167235553264618,
      "learning_rate": 2.4392012970389966e-05,
      "loss": 0.002,
      "step": 60020
    },
    {
      "epoch": 5.122450721051284,
      "grad_norm": 0.31397590041160583,
      "learning_rate": 2.438774639474358e-05,
      "loss": 0.0015,
      "step": 60030
    },
    {
      "epoch": 5.123304036180562,
      "grad_norm": 0.17184434831142426,
      "learning_rate": 2.4383479819097195e-05,
      "loss": 0.0015,
      "step": 60040
    },
    {
      "epoch": 5.124157351309838,
      "grad_norm": 0.4529179334640503,
      "learning_rate": 2.437921324345081e-05,
      "loss": 0.0022,
      "step": 60050
    },
    {
      "epoch": 5.125010666439116,
      "grad_norm": 0.2843535244464874,
      "learning_rate": 2.437494666780442e-05,
      "loss": 0.0016,
      "step": 60060
    },
    {
      "epoch": 5.1258639815683935,
      "grad_norm": 0.05719782039523125,
      "learning_rate": 2.4370680092158034e-05,
      "loss": 0.002,
      "step": 60070
    },
    {
      "epoch": 5.12671729669767,
      "grad_norm": 0.23768030107021332,
      "learning_rate": 2.4366413516511648e-05,
      "loss": 0.0012,
      "step": 60080
    },
    {
      "epoch": 5.127570611826948,
      "grad_norm": 0.28655388951301575,
      "learning_rate": 2.4362146940865262e-05,
      "loss": 0.0018,
      "step": 60090
    },
    {
      "epoch": 5.128423926956225,
      "grad_norm": 0.045188192278146744,
      "learning_rate": 2.4357880365218877e-05,
      "loss": 0.0014,
      "step": 60100
    },
    {
      "epoch": 5.129277242085502,
      "grad_norm": 0.03146575018763542,
      "learning_rate": 2.435361378957249e-05,
      "loss": 0.002,
      "step": 60110
    },
    {
      "epoch": 5.1301305572147795,
      "grad_norm": 0.240522563457489,
      "learning_rate": 2.4349347213926105e-05,
      "loss": 0.0021,
      "step": 60120
    },
    {
      "epoch": 5.130983872344057,
      "grad_norm": 0.10985409468412399,
      "learning_rate": 2.434508063827972e-05,
      "loss": 0.0018,
      "step": 60130
    },
    {
      "epoch": 5.131837187473334,
      "grad_norm": 0.1427818387746811,
      "learning_rate": 2.4340814062633334e-05,
      "loss": 0.0027,
      "step": 60140
    },
    {
      "epoch": 5.132690502602611,
      "grad_norm": 0.25876909494400024,
      "learning_rate": 2.4336547486986948e-05,
      "loss": 0.0018,
      "step": 60150
    },
    {
      "epoch": 5.133543817731889,
      "grad_norm": 0.1499948799610138,
      "learning_rate": 2.433228091134056e-05,
      "loss": 0.0017,
      "step": 60160
    },
    {
      "epoch": 5.1343971328611655,
      "grad_norm": 0.2527943253517151,
      "learning_rate": 2.4328014335694173e-05,
      "loss": 0.0019,
      "step": 60170
    },
    {
      "epoch": 5.135250447990443,
      "grad_norm": 0.1632114201784134,
      "learning_rate": 2.4323747760047787e-05,
      "loss": 0.0018,
      "step": 60180
    },
    {
      "epoch": 5.13610376311972,
      "grad_norm": 0.06276663392782211,
      "learning_rate": 2.4319481184401398e-05,
      "loss": 0.0017,
      "step": 60190
    },
    {
      "epoch": 5.136957078248997,
      "grad_norm": 0.11751425266265869,
      "learning_rate": 2.4315214608755012e-05,
      "loss": 0.0021,
      "step": 60200
    },
    {
      "epoch": 5.137810393378275,
      "grad_norm": 0.5851845741271973,
      "learning_rate": 2.4310948033108627e-05,
      "loss": 0.0021,
      "step": 60210
    },
    {
      "epoch": 5.1386637085075515,
      "grad_norm": 0.07796455919742584,
      "learning_rate": 2.430668145746224e-05,
      "loss": 0.0022,
      "step": 60220
    },
    {
      "epoch": 5.139517023636829,
      "grad_norm": 0.1289062798023224,
      "learning_rate": 2.4302414881815855e-05,
      "loss": 0.0016,
      "step": 60230
    },
    {
      "epoch": 5.140370338766107,
      "grad_norm": 0.04606976732611656,
      "learning_rate": 2.429814830616947e-05,
      "loss": 0.0016,
      "step": 60240
    },
    {
      "epoch": 5.141223653895383,
      "grad_norm": 0.38861116766929626,
      "learning_rate": 2.4293881730523084e-05,
      "loss": 0.0016,
      "step": 60250
    },
    {
      "epoch": 5.142076969024661,
      "grad_norm": 0.05920213460922241,
      "learning_rate": 2.4289615154876698e-05,
      "loss": 0.0015,
      "step": 60260
    },
    {
      "epoch": 5.142930284153938,
      "grad_norm": 0.0919792503118515,
      "learning_rate": 2.4285348579230312e-05,
      "loss": 0.0018,
      "step": 60270
    },
    {
      "epoch": 5.143783599283215,
      "grad_norm": 0.16658122837543488,
      "learning_rate": 2.4281082003583923e-05,
      "loss": 0.0012,
      "step": 60280
    },
    {
      "epoch": 5.144636914412493,
      "grad_norm": 0.0629987120628357,
      "learning_rate": 2.4276815427937537e-05,
      "loss": 0.0016,
      "step": 60290
    },
    {
      "epoch": 5.14549022954177,
      "grad_norm": 0.1528545767068863,
      "learning_rate": 2.427254885229115e-05,
      "loss": 0.0018,
      "step": 60300
    },
    {
      "epoch": 5.146343544671047,
      "grad_norm": 0.3499067425727844,
      "learning_rate": 2.4268282276644766e-05,
      "loss": 0.0022,
      "step": 60310
    },
    {
      "epoch": 5.147196859800324,
      "grad_norm": 0.2401655912399292,
      "learning_rate": 2.426401570099838e-05,
      "loss": 0.0017,
      "step": 60320
    },
    {
      "epoch": 5.148050174929602,
      "grad_norm": 0.23299728333950043,
      "learning_rate": 2.4259749125351994e-05,
      "loss": 0.0018,
      "step": 60330
    },
    {
      "epoch": 5.148903490058879,
      "grad_norm": 0.04166862741112709,
      "learning_rate": 2.425548254970561e-05,
      "loss": 0.0013,
      "step": 60340
    },
    {
      "epoch": 5.149756805188156,
      "grad_norm": 0.22097179293632507,
      "learning_rate": 2.4251215974059223e-05,
      "loss": 0.0016,
      "step": 60350
    },
    {
      "epoch": 5.150610120317433,
      "grad_norm": 0.23461072146892548,
      "learning_rate": 2.4246949398412837e-05,
      "loss": 0.002,
      "step": 60360
    },
    {
      "epoch": 5.15146343544671,
      "grad_norm": 0.05092775449156761,
      "learning_rate": 2.4242682822766448e-05,
      "loss": 0.0018,
      "step": 60370
    },
    {
      "epoch": 5.152316750575988,
      "grad_norm": 0.22390039265155792,
      "learning_rate": 2.4238416247120062e-05,
      "loss": 0.0017,
      "step": 60380
    },
    {
      "epoch": 5.153170065705265,
      "grad_norm": 0.20326513051986694,
      "learning_rate": 2.4234149671473676e-05,
      "loss": 0.0015,
      "step": 60390
    },
    {
      "epoch": 5.154023380834542,
      "grad_norm": 0.22128716111183167,
      "learning_rate": 2.422988309582729e-05,
      "loss": 0.0017,
      "step": 60400
    },
    {
      "epoch": 5.15487669596382,
      "grad_norm": 0.35054564476013184,
      "learning_rate": 2.4225616520180905e-05,
      "loss": 0.0017,
      "step": 60410
    },
    {
      "epoch": 5.155730011093096,
      "grad_norm": 0.2998945116996765,
      "learning_rate": 2.422134994453452e-05,
      "loss": 0.0019,
      "step": 60420
    },
    {
      "epoch": 5.156583326222374,
      "grad_norm": 0.13571517169475555,
      "learning_rate": 2.4217083368888133e-05,
      "loss": 0.002,
      "step": 60430
    },
    {
      "epoch": 5.1574366413516515,
      "grad_norm": 0.2419012486934662,
      "learning_rate": 2.4212816793241747e-05,
      "loss": 0.0021,
      "step": 60440
    },
    {
      "epoch": 5.158289956480928,
      "grad_norm": 0.22427694499492645,
      "learning_rate": 2.420855021759536e-05,
      "loss": 0.0021,
      "step": 60450
    },
    {
      "epoch": 5.159143271610206,
      "grad_norm": 0.039871782064437866,
      "learning_rate": 2.4204283641948972e-05,
      "loss": 0.0018,
      "step": 60460
    },
    {
      "epoch": 5.159996586739483,
      "grad_norm": 0.3146401345729828,
      "learning_rate": 2.4200017066302587e-05,
      "loss": 0.0021,
      "step": 60470
    },
    {
      "epoch": 5.16084990186876,
      "grad_norm": 0.33105188608169556,
      "learning_rate": 2.41957504906562e-05,
      "loss": 0.0016,
      "step": 60480
    },
    {
      "epoch": 5.1617032169980375,
      "grad_norm": 0.14497512578964233,
      "learning_rate": 2.4191483915009812e-05,
      "loss": 0.0019,
      "step": 60490
    },
    {
      "epoch": 5.162556532127315,
      "grad_norm": 0.1835789829492569,
      "learning_rate": 2.4187217339363426e-05,
      "loss": 0.0022,
      "step": 60500
    },
    {
      "epoch": 5.163409847256592,
      "grad_norm": 0.04161711409687996,
      "learning_rate": 2.418295076371704e-05,
      "loss": 0.0023,
      "step": 60510
    },
    {
      "epoch": 5.164263162385869,
      "grad_norm": 0.08144038915634155,
      "learning_rate": 2.4178684188070654e-05,
      "loss": 0.0022,
      "step": 60520
    },
    {
      "epoch": 5.165116477515147,
      "grad_norm": 0.09153161197900772,
      "learning_rate": 2.417441761242427e-05,
      "loss": 0.0017,
      "step": 60530
    },
    {
      "epoch": 5.1659697926444235,
      "grad_norm": 0.04892599582672119,
      "learning_rate": 2.4170151036777883e-05,
      "loss": 0.0018,
      "step": 60540
    },
    {
      "epoch": 5.166823107773701,
      "grad_norm": 0.18770422041416168,
      "learning_rate": 2.4165884461131497e-05,
      "loss": 0.0017,
      "step": 60550
    },
    {
      "epoch": 5.167676422902978,
      "grad_norm": 0.043755512684583664,
      "learning_rate": 2.416161788548511e-05,
      "loss": 0.0019,
      "step": 60560
    },
    {
      "epoch": 5.168529738032255,
      "grad_norm": 0.18096502125263214,
      "learning_rate": 2.4157351309838726e-05,
      "loss": 0.0017,
      "step": 60570
    },
    {
      "epoch": 5.169383053161533,
      "grad_norm": 0.07563648372888565,
      "learning_rate": 2.415308473419234e-05,
      "loss": 0.0019,
      "step": 60580
    },
    {
      "epoch": 5.1702363682908095,
      "grad_norm": 0.12807564437389374,
      "learning_rate": 2.414881815854595e-05,
      "loss": 0.0019,
      "step": 60590
    },
    {
      "epoch": 5.171089683420087,
      "grad_norm": 0.34097209572792053,
      "learning_rate": 2.4144551582899565e-05,
      "loss": 0.0017,
      "step": 60600
    },
    {
      "epoch": 5.171942998549365,
      "grad_norm": 0.5143366456031799,
      "learning_rate": 2.414028500725318e-05,
      "loss": 0.002,
      "step": 60610
    },
    {
      "epoch": 5.172796313678641,
      "grad_norm": 0.330492228269577,
      "learning_rate": 2.4136018431606794e-05,
      "loss": 0.002,
      "step": 60620
    },
    {
      "epoch": 5.173649628807919,
      "grad_norm": 0.1646767109632492,
      "learning_rate": 2.4131751855960408e-05,
      "loss": 0.002,
      "step": 60630
    },
    {
      "epoch": 5.174502943937196,
      "grad_norm": 0.040519632399082184,
      "learning_rate": 2.4127485280314022e-05,
      "loss": 0.0017,
      "step": 60640
    },
    {
      "epoch": 5.175356259066473,
      "grad_norm": 0.04715187847614288,
      "learning_rate": 2.4123218704667636e-05,
      "loss": 0.0017,
      "step": 60650
    },
    {
      "epoch": 5.176209574195751,
      "grad_norm": 0.10009608417749405,
      "learning_rate": 2.411895212902125e-05,
      "loss": 0.0025,
      "step": 60660
    },
    {
      "epoch": 5.177062889325028,
      "grad_norm": 0.07737428694963455,
      "learning_rate": 2.4114685553374865e-05,
      "loss": 0.0022,
      "step": 60670
    },
    {
      "epoch": 5.177916204454305,
      "grad_norm": 0.15799301862716675,
      "learning_rate": 2.4110418977728476e-05,
      "loss": 0.0018,
      "step": 60680
    },
    {
      "epoch": 5.178769519583582,
      "grad_norm": 0.10116173326969147,
      "learning_rate": 2.410615240208209e-05,
      "loss": 0.0019,
      "step": 60690
    },
    {
      "epoch": 5.179622834712859,
      "grad_norm": 0.15364132821559906,
      "learning_rate": 2.4101885826435704e-05,
      "loss": 0.0018,
      "step": 60700
    },
    {
      "epoch": 5.180476149842137,
      "grad_norm": 0.14708471298217773,
      "learning_rate": 2.4097619250789318e-05,
      "loss": 0.0016,
      "step": 60710
    },
    {
      "epoch": 5.181329464971414,
      "grad_norm": 0.12999506294727325,
      "learning_rate": 2.4093352675142933e-05,
      "loss": 0.0018,
      "step": 60720
    },
    {
      "epoch": 5.182182780100691,
      "grad_norm": 0.044699639081954956,
      "learning_rate": 2.4089086099496543e-05,
      "loss": 0.0015,
      "step": 60730
    },
    {
      "epoch": 5.183036095229968,
      "grad_norm": 0.0953294038772583,
      "learning_rate": 2.4084819523850158e-05,
      "loss": 0.0021,
      "step": 60740
    },
    {
      "epoch": 5.183889410359246,
      "grad_norm": 0.059768203645944595,
      "learning_rate": 2.4080552948203772e-05,
      "loss": 0.0018,
      "step": 60750
    },
    {
      "epoch": 5.1847427254885226,
      "grad_norm": 0.13326220214366913,
      "learning_rate": 2.4076286372557386e-05,
      "loss": 0.0019,
      "step": 60760
    },
    {
      "epoch": 5.1855960406178,
      "grad_norm": 0.20722916722297668,
      "learning_rate": 2.4072019796911e-05,
      "loss": 0.0019,
      "step": 60770
    },
    {
      "epoch": 5.186449355747078,
      "grad_norm": 0.20296263694763184,
      "learning_rate": 2.4067753221264615e-05,
      "loss": 0.0017,
      "step": 60780
    },
    {
      "epoch": 5.187302670876354,
      "grad_norm": 0.14975914359092712,
      "learning_rate": 2.406348664561823e-05,
      "loss": 0.0017,
      "step": 60790
    },
    {
      "epoch": 5.188155986005632,
      "grad_norm": 0.06511100381612778,
      "learning_rate": 2.405922006997184e-05,
      "loss": 0.0018,
      "step": 60800
    },
    {
      "epoch": 5.189009301134909,
      "grad_norm": 0.20436324179172516,
      "learning_rate": 2.4054953494325454e-05,
      "loss": 0.002,
      "step": 60810
    },
    {
      "epoch": 5.189862616264186,
      "grad_norm": 0.1298908144235611,
      "learning_rate": 2.4050686918679068e-05,
      "loss": 0.0017,
      "step": 60820
    },
    {
      "epoch": 5.190715931393464,
      "grad_norm": 0.15233363211154938,
      "learning_rate": 2.4046420343032682e-05,
      "loss": 0.0016,
      "step": 60830
    },
    {
      "epoch": 5.191569246522741,
      "grad_norm": 0.20262612402439117,
      "learning_rate": 2.4042153767386297e-05,
      "loss": 0.0018,
      "step": 60840
    },
    {
      "epoch": 5.192422561652018,
      "grad_norm": 0.13230472803115845,
      "learning_rate": 2.403788719173991e-05,
      "loss": 0.0014,
      "step": 60850
    },
    {
      "epoch": 5.193275876781295,
      "grad_norm": 0.06514818221330643,
      "learning_rate": 2.4033620616093525e-05,
      "loss": 0.0014,
      "step": 60860
    },
    {
      "epoch": 5.194129191910573,
      "grad_norm": 0.09313684701919556,
      "learning_rate": 2.402935404044714e-05,
      "loss": 0.0016,
      "step": 60870
    },
    {
      "epoch": 5.19498250703985,
      "grad_norm": 0.2022380232810974,
      "learning_rate": 2.4025087464800754e-05,
      "loss": 0.0018,
      "step": 60880
    },
    {
      "epoch": 5.195835822169127,
      "grad_norm": 0.0504748597741127,
      "learning_rate": 2.4020820889154368e-05,
      "loss": 0.0016,
      "step": 60890
    },
    {
      "epoch": 5.196689137298404,
      "grad_norm": 0.15048137307167053,
      "learning_rate": 2.401655431350798e-05,
      "loss": 0.0015,
      "step": 60900
    },
    {
      "epoch": 5.197542452427681,
      "grad_norm": 0.04385383799672127,
      "learning_rate": 2.4012287737861593e-05,
      "loss": 0.0021,
      "step": 60910
    },
    {
      "epoch": 5.198395767556959,
      "grad_norm": 0.29753822088241577,
      "learning_rate": 2.4008021162215207e-05,
      "loss": 0.0018,
      "step": 60920
    },
    {
      "epoch": 5.199249082686236,
      "grad_norm": 0.2762677073478699,
      "learning_rate": 2.400375458656882e-05,
      "loss": 0.0015,
      "step": 60930
    },
    {
      "epoch": 5.200102397815513,
      "grad_norm": 0.05370714142918587,
      "learning_rate": 2.3999488010922436e-05,
      "loss": 0.0019,
      "step": 60940
    },
    {
      "epoch": 5.200955712944791,
      "grad_norm": 0.4255155324935913,
      "learning_rate": 2.399522143527605e-05,
      "loss": 0.0014,
      "step": 60950
    },
    {
      "epoch": 5.201809028074067,
      "grad_norm": 0.05949309095740318,
      "learning_rate": 2.3990954859629664e-05,
      "loss": 0.0013,
      "step": 60960
    },
    {
      "epoch": 5.202662343203345,
      "grad_norm": 0.13459467887878418,
      "learning_rate": 2.398668828398328e-05,
      "loss": 0.0018,
      "step": 60970
    },
    {
      "epoch": 5.2035156583326225,
      "grad_norm": 0.04348204284906387,
      "learning_rate": 2.3982421708336893e-05,
      "loss": 0.0018,
      "step": 60980
    },
    {
      "epoch": 5.204368973461899,
      "grad_norm": 0.13075608015060425,
      "learning_rate": 2.3978155132690503e-05,
      "loss": 0.0017,
      "step": 60990
    },
    {
      "epoch": 5.205222288591177,
      "grad_norm": 0.11328177899122238,
      "learning_rate": 2.3973888557044118e-05,
      "loss": 0.0018,
      "step": 61000
    },
    {
      "epoch": 5.206075603720454,
      "grad_norm": 0.1331789344549179,
      "learning_rate": 2.396962198139773e-05,
      "loss": 0.0015,
      "step": 61010
    },
    {
      "epoch": 5.206928918849731,
      "grad_norm": 0.09385954588651657,
      "learning_rate": 2.3965355405751343e-05,
      "loss": 0.0016,
      "step": 61020
    },
    {
      "epoch": 5.2077822339790085,
      "grad_norm": 0.07740981131792068,
      "learning_rate": 2.3961088830104957e-05,
      "loss": 0.0017,
      "step": 61030
    },
    {
      "epoch": 5.208635549108286,
      "grad_norm": 0.11495184153318405,
      "learning_rate": 2.395682225445857e-05,
      "loss": 0.0024,
      "step": 61040
    },
    {
      "epoch": 5.209488864237563,
      "grad_norm": 0.18581277132034302,
      "learning_rate": 2.3952555678812186e-05,
      "loss": 0.0023,
      "step": 61050
    },
    {
      "epoch": 5.21034217936684,
      "grad_norm": 0.1331944316625595,
      "learning_rate": 2.39482891031658e-05,
      "loss": 0.0019,
      "step": 61060
    },
    {
      "epoch": 5.211195494496117,
      "grad_norm": 0.0620022714138031,
      "learning_rate": 2.3944022527519414e-05,
      "loss": 0.0017,
      "step": 61070
    },
    {
      "epoch": 5.2120488096253945,
      "grad_norm": 0.18607205152511597,
      "learning_rate": 2.3939755951873028e-05,
      "loss": 0.0014,
      "step": 61080
    },
    {
      "epoch": 5.212902124754672,
      "grad_norm": 0.18669310212135315,
      "learning_rate": 2.3935489376226643e-05,
      "loss": 0.002,
      "step": 61090
    },
    {
      "epoch": 5.213755439883949,
      "grad_norm": 0.07933060079813004,
      "learning_rate": 2.3931222800580257e-05,
      "loss": 0.0016,
      "step": 61100
    },
    {
      "epoch": 5.214608755013226,
      "grad_norm": 0.07739236205816269,
      "learning_rate": 2.3926956224933868e-05,
      "loss": 0.0019,
      "step": 61110
    },
    {
      "epoch": 5.215462070142504,
      "grad_norm": 0.1323910802602768,
      "learning_rate": 2.3922689649287482e-05,
      "loss": 0.0018,
      "step": 61120
    },
    {
      "epoch": 5.2163153852717805,
      "grad_norm": 0.5672023892402649,
      "learning_rate": 2.3918423073641096e-05,
      "loss": 0.0024,
      "step": 61130
    },
    {
      "epoch": 5.217168700401058,
      "grad_norm": 0.04476021230220795,
      "learning_rate": 2.391415649799471e-05,
      "loss": 0.0015,
      "step": 61140
    },
    {
      "epoch": 5.218022015530336,
      "grad_norm": 0.2581048011779785,
      "learning_rate": 2.3909889922348325e-05,
      "loss": 0.0016,
      "step": 61150
    },
    {
      "epoch": 5.218875330659612,
      "grad_norm": 0.3343525528907776,
      "learning_rate": 2.390562334670194e-05,
      "loss": 0.0016,
      "step": 61160
    },
    {
      "epoch": 5.21972864578889,
      "grad_norm": 0.12705746293067932,
      "learning_rate": 2.3901356771055553e-05,
      "loss": 0.0018,
      "step": 61170
    },
    {
      "epoch": 5.220581960918167,
      "grad_norm": 0.2722049355506897,
      "learning_rate": 2.3897090195409167e-05,
      "loss": 0.0017,
      "step": 61180
    },
    {
      "epoch": 5.221435276047444,
      "grad_norm": 0.03262517601251602,
      "learning_rate": 2.389282361976278e-05,
      "loss": 0.0019,
      "step": 61190
    },
    {
      "epoch": 5.222288591176722,
      "grad_norm": 0.21677397191524506,
      "learning_rate": 2.3888557044116396e-05,
      "loss": 0.0016,
      "step": 61200
    },
    {
      "epoch": 5.223141906305999,
      "grad_norm": 0.05494586005806923,
      "learning_rate": 2.3884290468470007e-05,
      "loss": 0.002,
      "step": 61210
    },
    {
      "epoch": 5.223995221435276,
      "grad_norm": 0.14808441698551178,
      "learning_rate": 2.388002389282362e-05,
      "loss": 0.0017,
      "step": 61220
    },
    {
      "epoch": 5.224848536564553,
      "grad_norm": 0.1518321931362152,
      "learning_rate": 2.3875757317177235e-05,
      "loss": 0.0015,
      "step": 61230
    },
    {
      "epoch": 5.225701851693831,
      "grad_norm": 0.4235408306121826,
      "learning_rate": 2.387149074153085e-05,
      "loss": 0.0021,
      "step": 61240
    },
    {
      "epoch": 5.226555166823108,
      "grad_norm": 0.1667054295539856,
      "learning_rate": 2.3867224165884464e-05,
      "loss": 0.0019,
      "step": 61250
    },
    {
      "epoch": 5.227408481952385,
      "grad_norm": 0.1101025938987732,
      "learning_rate": 2.3862957590238074e-05,
      "loss": 0.0023,
      "step": 61260
    },
    {
      "epoch": 5.228261797081662,
      "grad_norm": 0.4437933564186096,
      "learning_rate": 2.385869101459169e-05,
      "loss": 0.0015,
      "step": 61270
    },
    {
      "epoch": 5.229115112210939,
      "grad_norm": 0.22618351876735687,
      "learning_rate": 2.3854424438945303e-05,
      "loss": 0.0017,
      "step": 61280
    },
    {
      "epoch": 5.229968427340217,
      "grad_norm": 0.3063007891178131,
      "learning_rate": 2.3850157863298917e-05,
      "loss": 0.0014,
      "step": 61290
    },
    {
      "epoch": 5.230821742469494,
      "grad_norm": 0.06102661415934563,
      "learning_rate": 2.384589128765253e-05,
      "loss": 0.0017,
      "step": 61300
    },
    {
      "epoch": 5.231675057598771,
      "grad_norm": 0.36762940883636475,
      "learning_rate": 2.3841624712006146e-05,
      "loss": 0.0022,
      "step": 61310
    },
    {
      "epoch": 5.232528372728049,
      "grad_norm": 0.16600488126277924,
      "learning_rate": 2.3837358136359757e-05,
      "loss": 0.0017,
      "step": 61320
    },
    {
      "epoch": 5.233381687857325,
      "grad_norm": 0.1474265307188034,
      "learning_rate": 2.383309156071337e-05,
      "loss": 0.0018,
      "step": 61330
    },
    {
      "epoch": 5.234235002986603,
      "grad_norm": 0.23763729631900787,
      "learning_rate": 2.3828824985066985e-05,
      "loss": 0.0016,
      "step": 61340
    },
    {
      "epoch": 5.2350883181158805,
      "grad_norm": 0.03979789838194847,
      "learning_rate": 2.38245584094206e-05,
      "loss": 0.0014,
      "step": 61350
    },
    {
      "epoch": 5.235941633245157,
      "grad_norm": 0.0938771665096283,
      "learning_rate": 2.3820291833774213e-05,
      "loss": 0.0022,
      "step": 61360
    },
    {
      "epoch": 5.236794948374435,
      "grad_norm": 0.3874667286872864,
      "learning_rate": 2.3816025258127828e-05,
      "loss": 0.0019,
      "step": 61370
    },
    {
      "epoch": 5.237648263503712,
      "grad_norm": 0.255722314119339,
      "learning_rate": 2.3811758682481442e-05,
      "loss": 0.0019,
      "step": 61380
    },
    {
      "epoch": 5.238501578632989,
      "grad_norm": 0.25655344128608704,
      "learning_rate": 2.3807492106835056e-05,
      "loss": 0.0022,
      "step": 61390
    },
    {
      "epoch": 5.2393548937622665,
      "grad_norm": 0.2947552502155304,
      "learning_rate": 2.380322553118867e-05,
      "loss": 0.0023,
      "step": 61400
    },
    {
      "epoch": 5.240208208891544,
      "grad_norm": 0.22130092978477478,
      "learning_rate": 2.3798958955542285e-05,
      "loss": 0.0019,
      "step": 61410
    },
    {
      "epoch": 5.241061524020821,
      "grad_norm": 0.26071810722351074,
      "learning_rate": 2.3794692379895896e-05,
      "loss": 0.0017,
      "step": 61420
    },
    {
      "epoch": 5.241914839150098,
      "grad_norm": 0.31466448307037354,
      "learning_rate": 2.379042580424951e-05,
      "loss": 0.0023,
      "step": 61430
    },
    {
      "epoch": 5.242768154279375,
      "grad_norm": 0.18724337220191956,
      "learning_rate": 2.3786159228603124e-05,
      "loss": 0.002,
      "step": 61440
    },
    {
      "epoch": 5.2436214694086525,
      "grad_norm": 0.11716049164533615,
      "learning_rate": 2.3781892652956738e-05,
      "loss": 0.0024,
      "step": 61450
    },
    {
      "epoch": 5.24447478453793,
      "grad_norm": 0.020806951448321342,
      "learning_rate": 2.3777626077310352e-05,
      "loss": 0.0014,
      "step": 61460
    },
    {
      "epoch": 5.245328099667207,
      "grad_norm": 0.3160165250301361,
      "learning_rate": 2.3773359501663967e-05,
      "loss": 0.0021,
      "step": 61470
    },
    {
      "epoch": 5.246181414796484,
      "grad_norm": 0.09091256558895111,
      "learning_rate": 2.376909292601758e-05,
      "loss": 0.0015,
      "step": 61480
    },
    {
      "epoch": 5.247034729925762,
      "grad_norm": 0.047473594546318054,
      "learning_rate": 2.3764826350371195e-05,
      "loss": 0.0016,
      "step": 61490
    },
    {
      "epoch": 5.2478880450550385,
      "grad_norm": 0.11170479655265808,
      "learning_rate": 2.376055977472481e-05,
      "loss": 0.0018,
      "step": 61500
    },
    {
      "epoch": 5.248741360184316,
      "grad_norm": 0.5558542013168335,
      "learning_rate": 2.3756293199078424e-05,
      "loss": 0.002,
      "step": 61510
    },
    {
      "epoch": 5.249594675313594,
      "grad_norm": 0.06664115935564041,
      "learning_rate": 2.3752026623432035e-05,
      "loss": 0.0022,
      "step": 61520
    },
    {
      "epoch": 5.25044799044287,
      "grad_norm": 0.18105299770832062,
      "learning_rate": 2.374776004778565e-05,
      "loss": 0.0017,
      "step": 61530
    },
    {
      "epoch": 5.251301305572148,
      "grad_norm": 0.08562356233596802,
      "learning_rate": 2.374349347213926e-05,
      "loss": 0.0016,
      "step": 61540
    },
    {
      "epoch": 5.252154620701425,
      "grad_norm": 0.026586076244711876,
      "learning_rate": 2.3739226896492874e-05,
      "loss": 0.002,
      "step": 61550
    },
    {
      "epoch": 5.253007935830702,
      "grad_norm": 0.3408270478248596,
      "learning_rate": 2.3734960320846488e-05,
      "loss": 0.0016,
      "step": 61560
    },
    {
      "epoch": 5.25386125095998,
      "grad_norm": 0.11123845726251602,
      "learning_rate": 2.3730693745200102e-05,
      "loss": 0.0021,
      "step": 61570
    },
    {
      "epoch": 5.254714566089257,
      "grad_norm": 0.09403572976589203,
      "learning_rate": 2.3726427169553717e-05,
      "loss": 0.0014,
      "step": 61580
    },
    {
      "epoch": 5.255567881218534,
      "grad_norm": 0.06568419933319092,
      "learning_rate": 2.372216059390733e-05,
      "loss": 0.0021,
      "step": 61590
    },
    {
      "epoch": 5.256421196347811,
      "grad_norm": 0.2568961977958679,
      "learning_rate": 2.3717894018260945e-05,
      "loss": 0.0017,
      "step": 61600
    },
    {
      "epoch": 5.257274511477089,
      "grad_norm": 0.14891795814037323,
      "learning_rate": 2.371362744261456e-05,
      "loss": 0.0019,
      "step": 61610
    },
    {
      "epoch": 5.258127826606366,
      "grad_norm": 0.1444634348154068,
      "learning_rate": 2.3709360866968174e-05,
      "loss": 0.0018,
      "step": 61620
    },
    {
      "epoch": 5.258981141735643,
      "grad_norm": 0.3131977617740631,
      "learning_rate": 2.3705094291321784e-05,
      "loss": 0.0016,
      "step": 61630
    },
    {
      "epoch": 5.259834456864921,
      "grad_norm": 0.13898195326328278,
      "learning_rate": 2.37008277156754e-05,
      "loss": 0.0022,
      "step": 61640
    },
    {
      "epoch": 5.260687771994197,
      "grad_norm": 0.16938062012195587,
      "learning_rate": 2.3696561140029013e-05,
      "loss": 0.0019,
      "step": 61650
    },
    {
      "epoch": 5.261541087123475,
      "grad_norm": 0.05850442498922348,
      "learning_rate": 2.3692294564382627e-05,
      "loss": 0.0015,
      "step": 61660
    },
    {
      "epoch": 5.262394402252752,
      "grad_norm": 0.1729028970003128,
      "learning_rate": 2.368802798873624e-05,
      "loss": 0.0017,
      "step": 61670
    },
    {
      "epoch": 5.263247717382029,
      "grad_norm": 0.13194480538368225,
      "learning_rate": 2.3683761413089856e-05,
      "loss": 0.0016,
      "step": 61680
    },
    {
      "epoch": 5.264101032511307,
      "grad_norm": 0.08384929597377777,
      "learning_rate": 2.367949483744347e-05,
      "loss": 0.0017,
      "step": 61690
    },
    {
      "epoch": 5.264954347640583,
      "grad_norm": 0.1587531417608261,
      "learning_rate": 2.3675228261797084e-05,
      "loss": 0.0019,
      "step": 61700
    },
    {
      "epoch": 5.265807662769861,
      "grad_norm": 0.10406194627285004,
      "learning_rate": 2.36709616861507e-05,
      "loss": 0.0026,
      "step": 61710
    },
    {
      "epoch": 5.2666609778991385,
      "grad_norm": 0.31760770082473755,
      "learning_rate": 2.3666695110504313e-05,
      "loss": 0.0016,
      "step": 61720
    },
    {
      "epoch": 5.267514293028415,
      "grad_norm": 0.037610091269016266,
      "learning_rate": 2.3662428534857923e-05,
      "loss": 0.0017,
      "step": 61730
    },
    {
      "epoch": 5.268367608157693,
      "grad_norm": 0.09743098169565201,
      "learning_rate": 2.3658161959211538e-05,
      "loss": 0.0017,
      "step": 61740
    },
    {
      "epoch": 5.26922092328697,
      "grad_norm": 0.30469805002212524,
      "learning_rate": 2.3653895383565152e-05,
      "loss": 0.0018,
      "step": 61750
    },
    {
      "epoch": 5.270074238416247,
      "grad_norm": 0.16565117239952087,
      "learning_rate": 2.3649628807918766e-05,
      "loss": 0.0018,
      "step": 61760
    },
    {
      "epoch": 5.2709275535455244,
      "grad_norm": 0.3121020793914795,
      "learning_rate": 2.364536223227238e-05,
      "loss": 0.0021,
      "step": 61770
    },
    {
      "epoch": 5.271780868674802,
      "grad_norm": 0.05961015447974205,
      "learning_rate": 2.3641095656625995e-05,
      "loss": 0.0018,
      "step": 61780
    },
    {
      "epoch": 5.272634183804079,
      "grad_norm": 0.032819394022226334,
      "learning_rate": 2.3636829080979605e-05,
      "loss": 0.0018,
      "step": 61790
    },
    {
      "epoch": 5.273487498933356,
      "grad_norm": 0.13319744169712067,
      "learning_rate": 2.363256250533322e-05,
      "loss": 0.0019,
      "step": 61800
    },
    {
      "epoch": 5.274340814062633,
      "grad_norm": 0.1557200849056244,
      "learning_rate": 2.3628295929686834e-05,
      "loss": 0.0015,
      "step": 61810
    },
    {
      "epoch": 5.27519412919191,
      "grad_norm": 0.1762186884880066,
      "learning_rate": 2.3624029354040448e-05,
      "loss": 0.0017,
      "step": 61820
    },
    {
      "epoch": 5.276047444321188,
      "grad_norm": 0.2047722339630127,
      "learning_rate": 2.3619762778394062e-05,
      "loss": 0.0015,
      "step": 61830
    },
    {
      "epoch": 5.276900759450465,
      "grad_norm": 0.3874647617340088,
      "learning_rate": 2.3615496202747677e-05,
      "loss": 0.0022,
      "step": 61840
    },
    {
      "epoch": 5.277754074579742,
      "grad_norm": 0.11776386946439743,
      "learning_rate": 2.3611229627101288e-05,
      "loss": 0.0016,
      "step": 61850
    },
    {
      "epoch": 5.27860738970902,
      "grad_norm": 0.04983524978160858,
      "learning_rate": 2.3606963051454902e-05,
      "loss": 0.0017,
      "step": 61860
    },
    {
      "epoch": 5.279460704838296,
      "grad_norm": 0.031378086656332016,
      "learning_rate": 2.3602696475808516e-05,
      "loss": 0.0017,
      "step": 61870
    },
    {
      "epoch": 5.280314019967574,
      "grad_norm": 0.16566534340381622,
      "learning_rate": 2.359842990016213e-05,
      "loss": 0.0017,
      "step": 61880
    },
    {
      "epoch": 5.2811673350968515,
      "grad_norm": 0.11786023527383804,
      "learning_rate": 2.3594163324515745e-05,
      "loss": 0.0015,
      "step": 61890
    },
    {
      "epoch": 5.282020650226128,
      "grad_norm": 0.09795230627059937,
      "learning_rate": 2.358989674886936e-05,
      "loss": 0.0018,
      "step": 61900
    },
    {
      "epoch": 5.282873965355406,
      "grad_norm": 0.32416418194770813,
      "learning_rate": 2.3585630173222973e-05,
      "loss": 0.0017,
      "step": 61910
    },
    {
      "epoch": 5.283727280484683,
      "grad_norm": 0.030486000701785088,
      "learning_rate": 2.3581363597576587e-05,
      "loss": 0.0016,
      "step": 61920
    },
    {
      "epoch": 5.28458059561396,
      "grad_norm": 0.1331283152103424,
      "learning_rate": 2.35770970219302e-05,
      "loss": 0.0018,
      "step": 61930
    },
    {
      "epoch": 5.2854339107432375,
      "grad_norm": 0.1987190544605255,
      "learning_rate": 2.3572830446283812e-05,
      "loss": 0.0015,
      "step": 61940
    },
    {
      "epoch": 5.286287225872515,
      "grad_norm": 0.1828271448612213,
      "learning_rate": 2.3568563870637427e-05,
      "loss": 0.0017,
      "step": 61950
    },
    {
      "epoch": 5.287140541001792,
      "grad_norm": 0.049240246415138245,
      "learning_rate": 2.356429729499104e-05,
      "loss": 0.0015,
      "step": 61960
    },
    {
      "epoch": 5.287993856131069,
      "grad_norm": 0.20392142236232758,
      "learning_rate": 2.3560030719344655e-05,
      "loss": 0.0017,
      "step": 61970
    },
    {
      "epoch": 5.288847171260347,
      "grad_norm": 0.04445812106132507,
      "learning_rate": 2.355576414369827e-05,
      "loss": 0.0019,
      "step": 61980
    },
    {
      "epoch": 5.2897004863896235,
      "grad_norm": 0.17025162279605865,
      "learning_rate": 2.3551497568051884e-05,
      "loss": 0.0015,
      "step": 61990
    },
    {
      "epoch": 5.290553801518901,
      "grad_norm": 0.44368407130241394,
      "learning_rate": 2.3547230992405498e-05,
      "loss": 0.0018,
      "step": 62000
    },
    {
      "epoch": 5.291407116648179,
      "grad_norm": 0.1324269324541092,
      "learning_rate": 2.3542964416759112e-05,
      "loss": 0.002,
      "step": 62010
    },
    {
      "epoch": 5.292260431777455,
      "grad_norm": 0.16647885739803314,
      "learning_rate": 2.3538697841112726e-05,
      "loss": 0.0021,
      "step": 62020
    },
    {
      "epoch": 5.293113746906733,
      "grad_norm": 0.05906752869486809,
      "learning_rate": 2.353443126546634e-05,
      "loss": 0.0019,
      "step": 62030
    },
    {
      "epoch": 5.2939670620360095,
      "grad_norm": 0.07755044102668762,
      "learning_rate": 2.353016468981995e-05,
      "loss": 0.0018,
      "step": 62040
    },
    {
      "epoch": 5.294820377165287,
      "grad_norm": 0.14814692735671997,
      "learning_rate": 2.3525898114173566e-05,
      "loss": 0.0022,
      "step": 62050
    },
    {
      "epoch": 5.295673692294565,
      "grad_norm": 0.20732229948043823,
      "learning_rate": 2.3521631538527176e-05,
      "loss": 0.002,
      "step": 62060
    },
    {
      "epoch": 5.296527007423841,
      "grad_norm": 0.03028765134513378,
      "learning_rate": 2.351736496288079e-05,
      "loss": 0.0023,
      "step": 62070
    },
    {
      "epoch": 5.297380322553119,
      "grad_norm": 0.0745837539434433,
      "learning_rate": 2.3513098387234405e-05,
      "loss": 0.0014,
      "step": 62080
    },
    {
      "epoch": 5.298233637682396,
      "grad_norm": 0.04234008863568306,
      "learning_rate": 2.350883181158802e-05,
      "loss": 0.0017,
      "step": 62090
    },
    {
      "epoch": 5.299086952811673,
      "grad_norm": 0.33064064383506775,
      "learning_rate": 2.3504565235941633e-05,
      "loss": 0.0022,
      "step": 62100
    },
    {
      "epoch": 5.299940267940951,
      "grad_norm": 0.14899131655693054,
      "learning_rate": 2.3500298660295248e-05,
      "loss": 0.0018,
      "step": 62110
    },
    {
      "epoch": 5.300793583070228,
      "grad_norm": 0.13238367438316345,
      "learning_rate": 2.3496032084648862e-05,
      "loss": 0.0022,
      "step": 62120
    },
    {
      "epoch": 5.301646898199505,
      "grad_norm": 0.06064983457326889,
      "learning_rate": 2.3491765509002476e-05,
      "loss": 0.0018,
      "step": 62130
    },
    {
      "epoch": 5.302500213328782,
      "grad_norm": 0.18710795044898987,
      "learning_rate": 2.348749893335609e-05,
      "loss": 0.0016,
      "step": 62140
    },
    {
      "epoch": 5.30335352845806,
      "grad_norm": 0.1841643750667572,
      "learning_rate": 2.3483232357709705e-05,
      "loss": 0.0018,
      "step": 62150
    },
    {
      "epoch": 5.304206843587337,
      "grad_norm": 0.1844475269317627,
      "learning_rate": 2.3478965782063315e-05,
      "loss": 0.0016,
      "step": 62160
    },
    {
      "epoch": 5.305060158716614,
      "grad_norm": 0.09841632097959518,
      "learning_rate": 2.347469920641693e-05,
      "loss": 0.0019,
      "step": 62170
    },
    {
      "epoch": 5.305913473845891,
      "grad_norm": 0.16005420684814453,
      "learning_rate": 2.3470432630770544e-05,
      "loss": 0.0019,
      "step": 62180
    },
    {
      "epoch": 5.306766788975168,
      "grad_norm": 0.2792961001396179,
      "learning_rate": 2.3466166055124158e-05,
      "loss": 0.002,
      "step": 62190
    },
    {
      "epoch": 5.307620104104446,
      "grad_norm": 0.17435887455940247,
      "learning_rate": 2.3461899479477772e-05,
      "loss": 0.0016,
      "step": 62200
    },
    {
      "epoch": 5.308473419233723,
      "grad_norm": 0.14960038661956787,
      "learning_rate": 2.3457632903831387e-05,
      "loss": 0.0022,
      "step": 62210
    },
    {
      "epoch": 5.309326734363,
      "grad_norm": 0.24817869067192078,
      "learning_rate": 2.3453366328185e-05,
      "loss": 0.0018,
      "step": 62220
    },
    {
      "epoch": 5.310180049492278,
      "grad_norm": 0.15165311098098755,
      "learning_rate": 2.3449099752538615e-05,
      "loss": 0.0017,
      "step": 62230
    },
    {
      "epoch": 5.311033364621554,
      "grad_norm": 0.23835396766662598,
      "learning_rate": 2.344483317689223e-05,
      "loss": 0.0019,
      "step": 62240
    },
    {
      "epoch": 5.311886679750832,
      "grad_norm": 0.048416588455438614,
      "learning_rate": 2.344056660124584e-05,
      "loss": 0.0019,
      "step": 62250
    },
    {
      "epoch": 5.3127399948801095,
      "grad_norm": 0.3570590317249298,
      "learning_rate": 2.3436300025599454e-05,
      "loss": 0.0018,
      "step": 62260
    },
    {
      "epoch": 5.313593310009386,
      "grad_norm": 0.2066836804151535,
      "learning_rate": 2.343203344995307e-05,
      "loss": 0.0026,
      "step": 62270
    },
    {
      "epoch": 5.314446625138664,
      "grad_norm": 0.1811428666114807,
      "learning_rate": 2.3427766874306683e-05,
      "loss": 0.002,
      "step": 62280
    },
    {
      "epoch": 5.315299940267941,
      "grad_norm": 0.33249786496162415,
      "learning_rate": 2.3423500298660297e-05,
      "loss": 0.0015,
      "step": 62290
    },
    {
      "epoch": 5.316153255397218,
      "grad_norm": 0.31169599294662476,
      "learning_rate": 2.341923372301391e-05,
      "loss": 0.0016,
      "step": 62300
    },
    {
      "epoch": 5.3170065705264955,
      "grad_norm": 0.26473209261894226,
      "learning_rate": 2.3414967147367526e-05,
      "loss": 0.0017,
      "step": 62310
    },
    {
      "epoch": 5.317859885655773,
      "grad_norm": 0.27992546558380127,
      "learning_rate": 2.3410700571721137e-05,
      "loss": 0.0015,
      "step": 62320
    },
    {
      "epoch": 5.31871320078505,
      "grad_norm": 0.0254483874887228,
      "learning_rate": 2.340643399607475e-05,
      "loss": 0.0024,
      "step": 62330
    },
    {
      "epoch": 5.319566515914327,
      "grad_norm": 0.15344654023647308,
      "learning_rate": 2.3402167420428365e-05,
      "loss": 0.0023,
      "step": 62340
    },
    {
      "epoch": 5.320419831043605,
      "grad_norm": 0.2938742935657501,
      "learning_rate": 2.339790084478198e-05,
      "loss": 0.0016,
      "step": 62350
    },
    {
      "epoch": 5.3212731461728815,
      "grad_norm": 0.11469600349664688,
      "learning_rate": 2.3393634269135594e-05,
      "loss": 0.0016,
      "step": 62360
    },
    {
      "epoch": 5.322126461302159,
      "grad_norm": 0.1340838074684143,
      "learning_rate": 2.3389367693489204e-05,
      "loss": 0.0017,
      "step": 62370
    },
    {
      "epoch": 5.322979776431436,
      "grad_norm": 0.08418732136487961,
      "learning_rate": 2.338510111784282e-05,
      "loss": 0.0015,
      "step": 62380
    },
    {
      "epoch": 5.323833091560713,
      "grad_norm": 0.29512593150138855,
      "learning_rate": 2.3380834542196433e-05,
      "loss": 0.0018,
      "step": 62390
    },
    {
      "epoch": 5.324686406689991,
      "grad_norm": 0.539122998714447,
      "learning_rate": 2.3376567966550047e-05,
      "loss": 0.0018,
      "step": 62400
    },
    {
      "epoch": 5.3255397218192675,
      "grad_norm": 0.1936497539281845,
      "learning_rate": 2.337230139090366e-05,
      "loss": 0.0018,
      "step": 62410
    },
    {
      "epoch": 5.326393036948545,
      "grad_norm": 0.04589607194066048,
      "learning_rate": 2.3368034815257276e-05,
      "loss": 0.0018,
      "step": 62420
    },
    {
      "epoch": 5.327246352077823,
      "grad_norm": 0.042029693722724915,
      "learning_rate": 2.336376823961089e-05,
      "loss": 0.0016,
      "step": 62430
    },
    {
      "epoch": 5.328099667207099,
      "grad_norm": 0.20159415900707245,
      "learning_rate": 2.3359501663964504e-05,
      "loss": 0.0018,
      "step": 62440
    },
    {
      "epoch": 5.328952982336377,
      "grad_norm": 0.20370042324066162,
      "learning_rate": 2.3355235088318118e-05,
      "loss": 0.0013,
      "step": 62450
    },
    {
      "epoch": 5.329806297465654,
      "grad_norm": 0.2273307889699936,
      "learning_rate": 2.3350968512671733e-05,
      "loss": 0.0018,
      "step": 62460
    },
    {
      "epoch": 5.330659612594931,
      "grad_norm": 0.1666719913482666,
      "learning_rate": 2.3346701937025343e-05,
      "loss": 0.0017,
      "step": 62470
    },
    {
      "epoch": 5.331512927724209,
      "grad_norm": 0.04727218300104141,
      "learning_rate": 2.3342435361378958e-05,
      "loss": 0.0018,
      "step": 62480
    },
    {
      "epoch": 5.332366242853486,
      "grad_norm": 0.08496152609586716,
      "learning_rate": 2.3338168785732572e-05,
      "loss": 0.003,
      "step": 62490
    },
    {
      "epoch": 5.333219557982763,
      "grad_norm": 0.03399273380637169,
      "learning_rate": 2.3333902210086186e-05,
      "loss": 0.002,
      "step": 62500
    },
    {
      "epoch": 5.33407287311204,
      "grad_norm": 0.06319733709096909,
      "learning_rate": 2.33296356344398e-05,
      "loss": 0.0016,
      "step": 62510
    },
    {
      "epoch": 5.334926188241318,
      "grad_norm": 0.37758246064186096,
      "learning_rate": 2.3325369058793415e-05,
      "loss": 0.0019,
      "step": 62520
    },
    {
      "epoch": 5.335779503370595,
      "grad_norm": 0.38720449805259705,
      "learning_rate": 2.332110248314703e-05,
      "loss": 0.0015,
      "step": 62530
    },
    {
      "epoch": 5.336632818499872,
      "grad_norm": 0.31326574087142944,
      "learning_rate": 2.3316835907500643e-05,
      "loss": 0.0017,
      "step": 62540
    },
    {
      "epoch": 5.337486133629149,
      "grad_norm": 0.2572171986103058,
      "learning_rate": 2.3312569331854257e-05,
      "loss": 0.0018,
      "step": 62550
    },
    {
      "epoch": 5.338339448758426,
      "grad_norm": 0.11569368094205856,
      "learning_rate": 2.3308302756207868e-05,
      "loss": 0.0022,
      "step": 62560
    },
    {
      "epoch": 5.339192763887704,
      "grad_norm": 0.09836110472679138,
      "learning_rate": 2.3304036180561482e-05,
      "loss": 0.002,
      "step": 62570
    },
    {
      "epoch": 5.340046079016981,
      "grad_norm": 0.1837894171476364,
      "learning_rate": 2.3299769604915097e-05,
      "loss": 0.0017,
      "step": 62580
    },
    {
      "epoch": 5.340899394146258,
      "grad_norm": 0.10346215218305588,
      "learning_rate": 2.3295503029268708e-05,
      "loss": 0.002,
      "step": 62590
    },
    {
      "epoch": 5.341752709275536,
      "grad_norm": 0.29194048047065735,
      "learning_rate": 2.3291236453622322e-05,
      "loss": 0.0021,
      "step": 62600
    },
    {
      "epoch": 5.342606024404812,
      "grad_norm": 0.031811248511075974,
      "learning_rate": 2.3286969877975936e-05,
      "loss": 0.0026,
      "step": 62610
    },
    {
      "epoch": 5.34345933953409,
      "grad_norm": 0.28068581223487854,
      "learning_rate": 2.328270330232955e-05,
      "loss": 0.002,
      "step": 62620
    },
    {
      "epoch": 5.3443126546633675,
      "grad_norm": 0.42211583256721497,
      "learning_rate": 2.3278436726683164e-05,
      "loss": 0.0024,
      "step": 62630
    },
    {
      "epoch": 5.345165969792644,
      "grad_norm": 0.1843160092830658,
      "learning_rate": 2.327417015103678e-05,
      "loss": 0.0019,
      "step": 62640
    },
    {
      "epoch": 5.346019284921922,
      "grad_norm": 0.3841410279273987,
      "learning_rate": 2.3269903575390393e-05,
      "loss": 0.0016,
      "step": 62650
    },
    {
      "epoch": 5.346872600051199,
      "grad_norm": 0.06071486696600914,
      "learning_rate": 2.3265636999744007e-05,
      "loss": 0.0017,
      "step": 62660
    },
    {
      "epoch": 5.347725915180476,
      "grad_norm": 0.16607263684272766,
      "learning_rate": 2.326137042409762e-05,
      "loss": 0.0021,
      "step": 62670
    },
    {
      "epoch": 5.3485792303097535,
      "grad_norm": 0.1501467376947403,
      "learning_rate": 2.3257103848451232e-05,
      "loss": 0.0018,
      "step": 62680
    },
    {
      "epoch": 5.349432545439031,
      "grad_norm": 0.06011121720075607,
      "learning_rate": 2.3252837272804847e-05,
      "loss": 0.0018,
      "step": 62690
    },
    {
      "epoch": 5.350285860568308,
      "grad_norm": 0.047574520111083984,
      "learning_rate": 2.324857069715846e-05,
      "loss": 0.0018,
      "step": 62700
    },
    {
      "epoch": 5.351139175697585,
      "grad_norm": 0.17955078184604645,
      "learning_rate": 2.3244304121512075e-05,
      "loss": 0.0025,
      "step": 62710
    },
    {
      "epoch": 5.351992490826863,
      "grad_norm": 0.19071970880031586,
      "learning_rate": 2.324003754586569e-05,
      "loss": 0.002,
      "step": 62720
    },
    {
      "epoch": 5.3528458059561395,
      "grad_norm": 0.036868978291749954,
      "learning_rate": 2.3235770970219303e-05,
      "loss": 0.0018,
      "step": 62730
    },
    {
      "epoch": 5.353699121085417,
      "grad_norm": 0.34277352690696716,
      "learning_rate": 2.3231504394572918e-05,
      "loss": 0.0024,
      "step": 62740
    },
    {
      "epoch": 5.354552436214694,
      "grad_norm": 0.29414865374565125,
      "learning_rate": 2.3227237818926532e-05,
      "loss": 0.002,
      "step": 62750
    },
    {
      "epoch": 5.355405751343971,
      "grad_norm": 0.024507815018296242,
      "learning_rate": 2.3222971243280146e-05,
      "loss": 0.0019,
      "step": 62760
    },
    {
      "epoch": 5.356259066473249,
      "grad_norm": 0.050629980862140656,
      "learning_rate": 2.321870466763376e-05,
      "loss": 0.0022,
      "step": 62770
    },
    {
      "epoch": 5.3571123816025255,
      "grad_norm": 0.034150708466768265,
      "learning_rate": 2.321443809198737e-05,
      "loss": 0.0019,
      "step": 62780
    },
    {
      "epoch": 5.357965696731803,
      "grad_norm": 0.24145939946174622,
      "learning_rate": 2.3210171516340986e-05,
      "loss": 0.0019,
      "step": 62790
    },
    {
      "epoch": 5.358819011861081,
      "grad_norm": 0.3152563273906708,
      "learning_rate": 2.32059049406946e-05,
      "loss": 0.0019,
      "step": 62800
    },
    {
      "epoch": 5.359672326990357,
      "grad_norm": 0.20029065012931824,
      "learning_rate": 2.3201638365048214e-05,
      "loss": 0.0018,
      "step": 62810
    },
    {
      "epoch": 5.360525642119635,
      "grad_norm": 0.36587581038475037,
      "learning_rate": 2.3197371789401828e-05,
      "loss": 0.0018,
      "step": 62820
    },
    {
      "epoch": 5.361378957248912,
      "grad_norm": 0.2218484878540039,
      "learning_rate": 2.3193105213755443e-05,
      "loss": 0.0014,
      "step": 62830
    },
    {
      "epoch": 5.362232272378189,
      "grad_norm": 0.046142514795064926,
      "learning_rate": 2.3188838638109057e-05,
      "loss": 0.0021,
      "step": 62840
    },
    {
      "epoch": 5.363085587507467,
      "grad_norm": 0.07441394031047821,
      "learning_rate": 2.3184572062462668e-05,
      "loss": 0.0014,
      "step": 62850
    },
    {
      "epoch": 5.363938902636744,
      "grad_norm": 0.08623083680868149,
      "learning_rate": 2.3180305486816282e-05,
      "loss": 0.0016,
      "step": 62860
    },
    {
      "epoch": 5.364792217766021,
      "grad_norm": 0.22126413881778717,
      "learning_rate": 2.3176038911169896e-05,
      "loss": 0.0017,
      "step": 62870
    },
    {
      "epoch": 5.365645532895298,
      "grad_norm": 0.26442939043045044,
      "learning_rate": 2.317177233552351e-05,
      "loss": 0.0018,
      "step": 62880
    },
    {
      "epoch": 5.366498848024576,
      "grad_norm": 0.06719661504030228,
      "learning_rate": 2.316750575987712e-05,
      "loss": 0.0017,
      "step": 62890
    },
    {
      "epoch": 5.3673521631538526,
      "grad_norm": 0.351052850484848,
      "learning_rate": 2.3163239184230735e-05,
      "loss": 0.002,
      "step": 62900
    },
    {
      "epoch": 5.36820547828313,
      "grad_norm": 0.05125339701771736,
      "learning_rate": 2.315897260858435e-05,
      "loss": 0.0018,
      "step": 62910
    },
    {
      "epoch": 5.369058793412407,
      "grad_norm": 0.46198028326034546,
      "learning_rate": 2.3154706032937964e-05,
      "loss": 0.0021,
      "step": 62920
    },
    {
      "epoch": 5.369912108541684,
      "grad_norm": 0.06850864738225937,
      "learning_rate": 2.3150439457291578e-05,
      "loss": 0.0015,
      "step": 62930
    },
    {
      "epoch": 5.370765423670962,
      "grad_norm": 0.05846104398369789,
      "learning_rate": 2.3146172881645192e-05,
      "loss": 0.0019,
      "step": 62940
    },
    {
      "epoch": 5.3716187388002385,
      "grad_norm": 0.3423912227153778,
      "learning_rate": 2.3141906305998807e-05,
      "loss": 0.002,
      "step": 62950
    },
    {
      "epoch": 5.372472053929516,
      "grad_norm": 0.14564915001392365,
      "learning_rate": 2.313763973035242e-05,
      "loss": 0.0018,
      "step": 62960
    },
    {
      "epoch": 5.373325369058794,
      "grad_norm": 0.2018723487854004,
      "learning_rate": 2.3133373154706035e-05,
      "loss": 0.0015,
      "step": 62970
    },
    {
      "epoch": 5.37417868418807,
      "grad_norm": 0.3633367419242859,
      "learning_rate": 2.312910657905965e-05,
      "loss": 0.002,
      "step": 62980
    },
    {
      "epoch": 5.375031999317348,
      "grad_norm": 0.16790319979190826,
      "learning_rate": 2.312484000341326e-05,
      "loss": 0.0022,
      "step": 62990
    },
    {
      "epoch": 5.375885314446625,
      "grad_norm": 0.2666018009185791,
      "learning_rate": 2.3120573427766874e-05,
      "loss": 0.002,
      "step": 63000
    },
    {
      "epoch": 5.376738629575902,
      "grad_norm": 0.051739174872636795,
      "learning_rate": 2.311630685212049e-05,
      "loss": 0.0017,
      "step": 63010
    },
    {
      "epoch": 5.37759194470518,
      "grad_norm": 0.29467058181762695,
      "learning_rate": 2.3112040276474103e-05,
      "loss": 0.0021,
      "step": 63020
    },
    {
      "epoch": 5.378445259834457,
      "grad_norm": 0.1526987999677658,
      "learning_rate": 2.3107773700827717e-05,
      "loss": 0.002,
      "step": 63030
    },
    {
      "epoch": 5.379298574963734,
      "grad_norm": 0.024382242932915688,
      "learning_rate": 2.310350712518133e-05,
      "loss": 0.0018,
      "step": 63040
    },
    {
      "epoch": 5.380151890093011,
      "grad_norm": 0.23716312646865845,
      "learning_rate": 2.3099240549534946e-05,
      "loss": 0.0017,
      "step": 63050
    },
    {
      "epoch": 5.381005205222289,
      "grad_norm": 0.33396583795547485,
      "learning_rate": 2.309497397388856e-05,
      "loss": 0.0019,
      "step": 63060
    },
    {
      "epoch": 5.381858520351566,
      "grad_norm": 0.04419691488146782,
      "learning_rate": 2.3090707398242174e-05,
      "loss": 0.0019,
      "step": 63070
    },
    {
      "epoch": 5.382711835480843,
      "grad_norm": 0.13954603672027588,
      "learning_rate": 2.308644082259579e-05,
      "loss": 0.0018,
      "step": 63080
    },
    {
      "epoch": 5.383565150610121,
      "grad_norm": 0.042426299303770065,
      "learning_rate": 2.30821742469494e-05,
      "loss": 0.0016,
      "step": 63090
    },
    {
      "epoch": 5.384418465739397,
      "grad_norm": 0.19960945844650269,
      "learning_rate": 2.3077907671303013e-05,
      "loss": 0.002,
      "step": 63100
    },
    {
      "epoch": 5.385271780868675,
      "grad_norm": 0.18300358951091766,
      "learning_rate": 2.3073641095656628e-05,
      "loss": 0.0015,
      "step": 63110
    },
    {
      "epoch": 5.386125095997952,
      "grad_norm": 0.18474994599819183,
      "learning_rate": 2.306937452001024e-05,
      "loss": 0.002,
      "step": 63120
    },
    {
      "epoch": 5.386978411127229,
      "grad_norm": 0.0493864007294178,
      "learning_rate": 2.3065107944363853e-05,
      "loss": 0.0021,
      "step": 63130
    },
    {
      "epoch": 5.387831726256507,
      "grad_norm": 0.29159513115882874,
      "learning_rate": 2.3060841368717467e-05,
      "loss": 0.0022,
      "step": 63140
    },
    {
      "epoch": 5.388685041385783,
      "grad_norm": 0.029077500104904175,
      "learning_rate": 2.305657479307108e-05,
      "loss": 0.002,
      "step": 63150
    },
    {
      "epoch": 5.389538356515061,
      "grad_norm": 0.19776660203933716,
      "learning_rate": 2.3052308217424696e-05,
      "loss": 0.0015,
      "step": 63160
    },
    {
      "epoch": 5.3903916716443385,
      "grad_norm": 0.11456462740898132,
      "learning_rate": 2.304804164177831e-05,
      "loss": 0.0019,
      "step": 63170
    },
    {
      "epoch": 5.391244986773615,
      "grad_norm": 0.03444226458668709,
      "learning_rate": 2.3043775066131924e-05,
      "loss": 0.002,
      "step": 63180
    },
    {
      "epoch": 5.392098301902893,
      "grad_norm": 0.03540517017245293,
      "learning_rate": 2.3039508490485538e-05,
      "loss": 0.0016,
      "step": 63190
    },
    {
      "epoch": 5.39295161703217,
      "grad_norm": 0.23910100758075714,
      "learning_rate": 2.303524191483915e-05,
      "loss": 0.0015,
      "step": 63200
    },
    {
      "epoch": 5.393804932161447,
      "grad_norm": 0.034486643970012665,
      "learning_rate": 2.3030975339192763e-05,
      "loss": 0.0018,
      "step": 63210
    },
    {
      "epoch": 5.3946582472907245,
      "grad_norm": 0.03668176755309105,
      "learning_rate": 2.3026708763546378e-05,
      "loss": 0.0018,
      "step": 63220
    },
    {
      "epoch": 5.395511562420002,
      "grad_norm": 0.09332623332738876,
      "learning_rate": 2.3022442187899992e-05,
      "loss": 0.0019,
      "step": 63230
    },
    {
      "epoch": 5.396364877549279,
      "grad_norm": 0.12348511815071106,
      "learning_rate": 2.3018175612253606e-05,
      "loss": 0.0019,
      "step": 63240
    },
    {
      "epoch": 5.397218192678556,
      "grad_norm": 0.13029588758945465,
      "learning_rate": 2.301390903660722e-05,
      "loss": 0.0023,
      "step": 63250
    },
    {
      "epoch": 5.398071507807834,
      "grad_norm": 0.2525468170642853,
      "learning_rate": 2.3009642460960835e-05,
      "loss": 0.002,
      "step": 63260
    },
    {
      "epoch": 5.3989248229371105,
      "grad_norm": 0.2296273559331894,
      "learning_rate": 2.300537588531445e-05,
      "loss": 0.0023,
      "step": 63270
    },
    {
      "epoch": 5.399778138066388,
      "grad_norm": 0.211266428232193,
      "learning_rate": 2.3001109309668063e-05,
      "loss": 0.0019,
      "step": 63280
    },
    {
      "epoch": 5.400631453195665,
      "grad_norm": 0.2520473301410675,
      "learning_rate": 2.2996842734021677e-05,
      "loss": 0.0016,
      "step": 63290
    },
    {
      "epoch": 5.401484768324942,
      "grad_norm": 0.21999739110469818,
      "learning_rate": 2.2992576158375288e-05,
      "loss": 0.0015,
      "step": 63300
    },
    {
      "epoch": 5.40233808345422,
      "grad_norm": 0.1904156357049942,
      "learning_rate": 2.2988309582728902e-05,
      "loss": 0.0022,
      "step": 63310
    },
    {
      "epoch": 5.4031913985834965,
      "grad_norm": 0.166764497756958,
      "learning_rate": 2.2984043007082517e-05,
      "loss": 0.0022,
      "step": 63320
    },
    {
      "epoch": 5.404044713712774,
      "grad_norm": 0.3153528571128845,
      "learning_rate": 2.297977643143613e-05,
      "loss": 0.002,
      "step": 63330
    },
    {
      "epoch": 5.404898028842052,
      "grad_norm": 0.09943611174821854,
      "learning_rate": 2.2975509855789745e-05,
      "loss": 0.0018,
      "step": 63340
    },
    {
      "epoch": 5.405751343971328,
      "grad_norm": 0.0627821609377861,
      "learning_rate": 2.297124328014336e-05,
      "loss": 0.0019,
      "step": 63350
    },
    {
      "epoch": 5.406604659100606,
      "grad_norm": 0.08216949552297592,
      "learning_rate": 2.2966976704496974e-05,
      "loss": 0.0021,
      "step": 63360
    },
    {
      "epoch": 5.407457974229883,
      "grad_norm": 0.022609936073422432,
      "learning_rate": 2.2962710128850588e-05,
      "loss": 0.0016,
      "step": 63370
    },
    {
      "epoch": 5.40831128935916,
      "grad_norm": 0.20108111202716827,
      "learning_rate": 2.29584435532042e-05,
      "loss": 0.0017,
      "step": 63380
    },
    {
      "epoch": 5.409164604488438,
      "grad_norm": 0.3094198405742645,
      "learning_rate": 2.2954176977557813e-05,
      "loss": 0.0017,
      "step": 63390
    },
    {
      "epoch": 5.410017919617715,
      "grad_norm": 0.04550771787762642,
      "learning_rate": 2.2949910401911427e-05,
      "loss": 0.0022,
      "step": 63400
    },
    {
      "epoch": 5.410871234746992,
      "grad_norm": 0.07741167396306992,
      "learning_rate": 2.294564382626504e-05,
      "loss": 0.0017,
      "step": 63410
    },
    {
      "epoch": 5.411724549876269,
      "grad_norm": 0.13760115206241608,
      "learning_rate": 2.2941377250618652e-05,
      "loss": 0.0021,
      "step": 63420
    },
    {
      "epoch": 5.412577865005547,
      "grad_norm": 0.02528090961277485,
      "learning_rate": 2.2937110674972266e-05,
      "loss": 0.002,
      "step": 63430
    },
    {
      "epoch": 5.413431180134824,
      "grad_norm": 0.34632596373558044,
      "learning_rate": 2.293284409932588e-05,
      "loss": 0.0017,
      "step": 63440
    },
    {
      "epoch": 5.414284495264101,
      "grad_norm": 0.32699429988861084,
      "learning_rate": 2.2928577523679495e-05,
      "loss": 0.0018,
      "step": 63450
    },
    {
      "epoch": 5.415137810393379,
      "grad_norm": 0.048871397972106934,
      "learning_rate": 2.292431094803311e-05,
      "loss": 0.0017,
      "step": 63460
    },
    {
      "epoch": 5.415991125522655,
      "grad_norm": 0.13113366067409515,
      "learning_rate": 2.2920044372386723e-05,
      "loss": 0.0017,
      "step": 63470
    },
    {
      "epoch": 5.416844440651933,
      "grad_norm": 0.09358447790145874,
      "learning_rate": 2.2915777796740338e-05,
      "loss": 0.0023,
      "step": 63480
    },
    {
      "epoch": 5.41769775578121,
      "grad_norm": 0.11209122091531754,
      "learning_rate": 2.2911511221093952e-05,
      "loss": 0.0018,
      "step": 63490
    },
    {
      "epoch": 5.418551070910487,
      "grad_norm": 0.13488470017910004,
      "learning_rate": 2.2907244645447566e-05,
      "loss": 0.002,
      "step": 63500
    },
    {
      "epoch": 5.419404386039765,
      "grad_norm": 0.24494405090808868,
      "learning_rate": 2.2902978069801177e-05,
      "loss": 0.0018,
      "step": 63510
    },
    {
      "epoch": 5.420257701169041,
      "grad_norm": 0.0950087234377861,
      "learning_rate": 2.289871149415479e-05,
      "loss": 0.0014,
      "step": 63520
    },
    {
      "epoch": 5.421111016298319,
      "grad_norm": 0.13831941783428192,
      "learning_rate": 2.2894444918508405e-05,
      "loss": 0.0022,
      "step": 63530
    },
    {
      "epoch": 5.4219643314275965,
      "grad_norm": 0.035064104944467545,
      "learning_rate": 2.289017834286202e-05,
      "loss": 0.0018,
      "step": 63540
    },
    {
      "epoch": 5.422817646556873,
      "grad_norm": 0.14779351651668549,
      "learning_rate": 2.2885911767215634e-05,
      "loss": 0.0022,
      "step": 63550
    },
    {
      "epoch": 5.423670961686151,
      "grad_norm": 0.18104074895381927,
      "learning_rate": 2.2881645191569248e-05,
      "loss": 0.0017,
      "step": 63560
    },
    {
      "epoch": 5.424524276815428,
      "grad_norm": 0.13101600110530853,
      "learning_rate": 2.2877378615922862e-05,
      "loss": 0.0018,
      "step": 63570
    },
    {
      "epoch": 5.425377591944705,
      "grad_norm": 0.2919922173023224,
      "learning_rate": 2.2873112040276477e-05,
      "loss": 0.002,
      "step": 63580
    },
    {
      "epoch": 5.4262309070739825,
      "grad_norm": 0.1925165057182312,
      "learning_rate": 2.286884546463009e-05,
      "loss": 0.0022,
      "step": 63590
    },
    {
      "epoch": 5.42708422220326,
      "grad_norm": 0.21239878237247467,
      "learning_rate": 2.2864578888983705e-05,
      "loss": 0.0018,
      "step": 63600
    },
    {
      "epoch": 5.427937537332537,
      "grad_norm": 0.05109123885631561,
      "learning_rate": 2.2860312313337316e-05,
      "loss": 0.0027,
      "step": 63610
    },
    {
      "epoch": 5.428790852461814,
      "grad_norm": 0.11017464101314545,
      "learning_rate": 2.285604573769093e-05,
      "loss": 0.0018,
      "step": 63620
    },
    {
      "epoch": 5.429644167591091,
      "grad_norm": 0.13171963393688202,
      "learning_rate": 2.2851779162044545e-05,
      "loss": 0.0018,
      "step": 63630
    },
    {
      "epoch": 5.4304974827203685,
      "grad_norm": 0.21214453876018524,
      "learning_rate": 2.284751258639816e-05,
      "loss": 0.0018,
      "step": 63640
    },
    {
      "epoch": 5.431350797849646,
      "grad_norm": 0.33105579018592834,
      "learning_rate": 2.284324601075177e-05,
      "loss": 0.0024,
      "step": 63650
    },
    {
      "epoch": 5.432204112978923,
      "grad_norm": 0.1305253654718399,
      "learning_rate": 2.2838979435105384e-05,
      "loss": 0.0018,
      "step": 63660
    },
    {
      "epoch": 5.4330574281082,
      "grad_norm": 0.17543840408325195,
      "learning_rate": 2.2834712859458998e-05,
      "loss": 0.0016,
      "step": 63670
    },
    {
      "epoch": 5.433910743237478,
      "grad_norm": 0.11479485780000687,
      "learning_rate": 2.2830446283812612e-05,
      "loss": 0.0016,
      "step": 63680
    },
    {
      "epoch": 5.4347640583667545,
      "grad_norm": 0.11356604099273682,
      "learning_rate": 2.2826179708166227e-05,
      "loss": 0.0014,
      "step": 63690
    },
    {
      "epoch": 5.435617373496032,
      "grad_norm": 0.033092133700847626,
      "learning_rate": 2.282191313251984e-05,
      "loss": 0.0018,
      "step": 63700
    },
    {
      "epoch": 5.43647068862531,
      "grad_norm": 0.21853628754615784,
      "learning_rate": 2.2817646556873455e-05,
      "loss": 0.002,
      "step": 63710
    },
    {
      "epoch": 5.437324003754586,
      "grad_norm": 0.0757053941488266,
      "learning_rate": 2.281337998122707e-05,
      "loss": 0.0019,
      "step": 63720
    },
    {
      "epoch": 5.438177318883864,
      "grad_norm": 0.06724563241004944,
      "learning_rate": 2.280911340558068e-05,
      "loss": 0.002,
      "step": 63730
    },
    {
      "epoch": 5.439030634013141,
      "grad_norm": 0.22356601059436798,
      "learning_rate": 2.2804846829934294e-05,
      "loss": 0.0018,
      "step": 63740
    },
    {
      "epoch": 5.439883949142418,
      "grad_norm": 0.05616576224565506,
      "learning_rate": 2.280058025428791e-05,
      "loss": 0.0023,
      "step": 63750
    },
    {
      "epoch": 5.440737264271696,
      "grad_norm": 0.09567350894212723,
      "learning_rate": 2.2796313678641523e-05,
      "loss": 0.0019,
      "step": 63760
    },
    {
      "epoch": 5.441590579400973,
      "grad_norm": 0.030355818569660187,
      "learning_rate": 2.2792047102995137e-05,
      "loss": 0.0021,
      "step": 63770
    },
    {
      "epoch": 5.44244389453025,
      "grad_norm": 0.07512787729501724,
      "learning_rate": 2.278778052734875e-05,
      "loss": 0.0017,
      "step": 63780
    },
    {
      "epoch": 5.443297209659527,
      "grad_norm": 0.07448111474514008,
      "learning_rate": 2.2783513951702366e-05,
      "loss": 0.0015,
      "step": 63790
    },
    {
      "epoch": 5.444150524788805,
      "grad_norm": 0.07884464412927628,
      "learning_rate": 2.277924737605598e-05,
      "loss": 0.0019,
      "step": 63800
    },
    {
      "epoch": 5.445003839918082,
      "grad_norm": 0.309882253408432,
      "learning_rate": 2.2774980800409594e-05,
      "loss": 0.0015,
      "step": 63810
    },
    {
      "epoch": 5.445857155047359,
      "grad_norm": 0.09248290210962296,
      "learning_rate": 2.2770714224763205e-05,
      "loss": 0.002,
      "step": 63820
    },
    {
      "epoch": 5.446710470176637,
      "grad_norm": 0.05952455848455429,
      "learning_rate": 2.276644764911682e-05,
      "loss": 0.0017,
      "step": 63830
    },
    {
      "epoch": 5.447563785305913,
      "grad_norm": 0.1183389201760292,
      "learning_rate": 2.2762181073470433e-05,
      "loss": 0.0017,
      "step": 63840
    },
    {
      "epoch": 5.448417100435191,
      "grad_norm": 0.06077449396252632,
      "learning_rate": 2.2757914497824048e-05,
      "loss": 0.0021,
      "step": 63850
    },
    {
      "epoch": 5.449270415564468,
      "grad_norm": 0.2472127377986908,
      "learning_rate": 2.2753647922177662e-05,
      "loss": 0.0021,
      "step": 63860
    },
    {
      "epoch": 5.450123730693745,
      "grad_norm": 0.08143778145313263,
      "learning_rate": 2.2749381346531276e-05,
      "loss": 0.0017,
      "step": 63870
    },
    {
      "epoch": 5.450977045823023,
      "grad_norm": 0.38470664620399475,
      "learning_rate": 2.274511477088489e-05,
      "loss": 0.0013,
      "step": 63880
    },
    {
      "epoch": 5.451830360952299,
      "grad_norm": 0.0797341912984848,
      "learning_rate": 2.2740848195238505e-05,
      "loss": 0.0017,
      "step": 63890
    },
    {
      "epoch": 5.452683676081577,
      "grad_norm": 0.22058671712875366,
      "learning_rate": 2.273658161959212e-05,
      "loss": 0.0021,
      "step": 63900
    },
    {
      "epoch": 5.4535369912108544,
      "grad_norm": 0.09330973774194717,
      "learning_rate": 2.273231504394573e-05,
      "loss": 0.0024,
      "step": 63910
    },
    {
      "epoch": 5.454390306340131,
      "grad_norm": 0.1979297697544098,
      "learning_rate": 2.2728048468299344e-05,
      "loss": 0.0016,
      "step": 63920
    },
    {
      "epoch": 5.455243621469409,
      "grad_norm": 0.11110228300094604,
      "learning_rate": 2.2723781892652958e-05,
      "loss": 0.0018,
      "step": 63930
    },
    {
      "epoch": 5.456096936598686,
      "grad_norm": 0.0639645978808403,
      "learning_rate": 2.271951531700657e-05,
      "loss": 0.0016,
      "step": 63940
    },
    {
      "epoch": 5.456950251727963,
      "grad_norm": 0.043272990733385086,
      "learning_rate": 2.2715248741360183e-05,
      "loss": 0.0022,
      "step": 63950
    },
    {
      "epoch": 5.45780356685724,
      "grad_norm": 0.31537556648254395,
      "learning_rate": 2.2710982165713798e-05,
      "loss": 0.0021,
      "step": 63960
    },
    {
      "epoch": 5.458656881986518,
      "grad_norm": 0.16427958011627197,
      "learning_rate": 2.2706715590067412e-05,
      "loss": 0.0014,
      "step": 63970
    },
    {
      "epoch": 5.459510197115795,
      "grad_norm": 0.20446139574050903,
      "learning_rate": 2.2702449014421026e-05,
      "loss": 0.002,
      "step": 63980
    },
    {
      "epoch": 5.460363512245072,
      "grad_norm": 0.20602953433990479,
      "learning_rate": 2.269818243877464e-05,
      "loss": 0.0023,
      "step": 63990
    },
    {
      "epoch": 5.461216827374349,
      "grad_norm": 0.0832238718867302,
      "learning_rate": 2.2693915863128254e-05,
      "loss": 0.0023,
      "step": 64000
    },
    {
      "epoch": 5.462070142503626,
      "grad_norm": 0.12866729497909546,
      "learning_rate": 2.268964928748187e-05,
      "loss": 0.0021,
      "step": 64010
    },
    {
      "epoch": 5.462923457632904,
      "grad_norm": 0.238118976354599,
      "learning_rate": 2.2685382711835483e-05,
      "loss": 0.0016,
      "step": 64020
    },
    {
      "epoch": 5.463776772762181,
      "grad_norm": 0.042082685977220535,
      "learning_rate": 2.2681116136189097e-05,
      "loss": 0.002,
      "step": 64030
    },
    {
      "epoch": 5.464630087891458,
      "grad_norm": 0.27433109283447266,
      "learning_rate": 2.2676849560542708e-05,
      "loss": 0.0021,
      "step": 64040
    },
    {
      "epoch": 5.465483403020736,
      "grad_norm": 0.15659591555595398,
      "learning_rate": 2.2672582984896322e-05,
      "loss": 0.0019,
      "step": 64050
    },
    {
      "epoch": 5.466336718150012,
      "grad_norm": 0.06436529755592346,
      "learning_rate": 2.2668316409249937e-05,
      "loss": 0.0015,
      "step": 64060
    },
    {
      "epoch": 5.46719003327929,
      "grad_norm": 0.030128203332424164,
      "learning_rate": 2.266404983360355e-05,
      "loss": 0.0016,
      "step": 64070
    },
    {
      "epoch": 5.4680433484085675,
      "grad_norm": 0.1750304400920868,
      "learning_rate": 2.2659783257957165e-05,
      "loss": 0.0019,
      "step": 64080
    },
    {
      "epoch": 5.468896663537844,
      "grad_norm": 0.08127367496490479,
      "learning_rate": 2.265551668231078e-05,
      "loss": 0.0025,
      "step": 64090
    },
    {
      "epoch": 5.469749978667122,
      "grad_norm": 0.34681156277656555,
      "learning_rate": 2.2651250106664394e-05,
      "loss": 0.0018,
      "step": 64100
    },
    {
      "epoch": 5.470603293796399,
      "grad_norm": 0.08292890340089798,
      "learning_rate": 2.2646983531018008e-05,
      "loss": 0.0018,
      "step": 64110
    },
    {
      "epoch": 5.471456608925676,
      "grad_norm": 0.3543718755245209,
      "learning_rate": 2.2642716955371622e-05,
      "loss": 0.0019,
      "step": 64120
    },
    {
      "epoch": 5.4723099240549535,
      "grad_norm": 0.3169376850128174,
      "learning_rate": 2.2638450379725233e-05,
      "loss": 0.0018,
      "step": 64130
    },
    {
      "epoch": 5.473163239184231,
      "grad_norm": 0.22137966752052307,
      "learning_rate": 2.2634183804078847e-05,
      "loss": 0.0017,
      "step": 64140
    },
    {
      "epoch": 5.474016554313508,
      "grad_norm": 0.21755388379096985,
      "learning_rate": 2.262991722843246e-05,
      "loss": 0.0018,
      "step": 64150
    },
    {
      "epoch": 5.474869869442785,
      "grad_norm": 0.12886060774326324,
      "learning_rate": 2.2625650652786076e-05,
      "loss": 0.0016,
      "step": 64160
    },
    {
      "epoch": 5.475723184572063,
      "grad_norm": 0.1128888875246048,
      "learning_rate": 2.262138407713969e-05,
      "loss": 0.0024,
      "step": 64170
    },
    {
      "epoch": 5.4765764997013395,
      "grad_norm": 0.1650969386100769,
      "learning_rate": 2.26171175014933e-05,
      "loss": 0.0016,
      "step": 64180
    },
    {
      "epoch": 5.477429814830617,
      "grad_norm": 0.09582941979169846,
      "learning_rate": 2.2612850925846915e-05,
      "loss": 0.0018,
      "step": 64190
    },
    {
      "epoch": 5.478283129959895,
      "grad_norm": 0.26015353202819824,
      "learning_rate": 2.260858435020053e-05,
      "loss": 0.0016,
      "step": 64200
    },
    {
      "epoch": 5.479136445089171,
      "grad_norm": 0.19922147691249847,
      "learning_rate": 2.2604317774554143e-05,
      "loss": 0.0017,
      "step": 64210
    },
    {
      "epoch": 5.479989760218449,
      "grad_norm": 0.22456426918506622,
      "learning_rate": 2.2600051198907758e-05,
      "loss": 0.0019,
      "step": 64220
    },
    {
      "epoch": 5.4808430753477255,
      "grad_norm": 0.3822803795337677,
      "learning_rate": 2.2595784623261372e-05,
      "loss": 0.0016,
      "step": 64230
    },
    {
      "epoch": 5.481696390477003,
      "grad_norm": 0.09464820474386215,
      "learning_rate": 2.2591518047614986e-05,
      "loss": 0.0017,
      "step": 64240
    },
    {
      "epoch": 5.482549705606281,
      "grad_norm": 0.24552780389785767,
      "learning_rate": 2.2587251471968597e-05,
      "loss": 0.0016,
      "step": 64250
    },
    {
      "epoch": 5.483403020735557,
      "grad_norm": 0.3488709628582001,
      "learning_rate": 2.258298489632221e-05,
      "loss": 0.0021,
      "step": 64260
    },
    {
      "epoch": 5.484256335864835,
      "grad_norm": 0.2978088855743408,
      "learning_rate": 2.2578718320675825e-05,
      "loss": 0.0018,
      "step": 64270
    },
    {
      "epoch": 5.485109650994112,
      "grad_norm": 0.09557582437992096,
      "learning_rate": 2.257445174502944e-05,
      "loss": 0.0018,
      "step": 64280
    },
    {
      "epoch": 5.485962966123389,
      "grad_norm": 0.023611728101968765,
      "learning_rate": 2.2570185169383054e-05,
      "loss": 0.0021,
      "step": 64290
    },
    {
      "epoch": 5.486816281252667,
      "grad_norm": 0.3764910101890564,
      "learning_rate": 2.2565918593736668e-05,
      "loss": 0.0025,
      "step": 64300
    },
    {
      "epoch": 5.487669596381944,
      "grad_norm": 0.2232678085565567,
      "learning_rate": 2.2561652018090282e-05,
      "loss": 0.0021,
      "step": 64310
    },
    {
      "epoch": 5.488522911511221,
      "grad_norm": 0.028638603165745735,
      "learning_rate": 2.2557385442443897e-05,
      "loss": 0.0019,
      "step": 64320
    },
    {
      "epoch": 5.489376226640498,
      "grad_norm": 0.24207337200641632,
      "learning_rate": 2.255311886679751e-05,
      "loss": 0.0019,
      "step": 64330
    },
    {
      "epoch": 5.490229541769776,
      "grad_norm": 0.15968982875347137,
      "learning_rate": 2.2548852291151125e-05,
      "loss": 0.0021,
      "step": 64340
    },
    {
      "epoch": 5.491082856899053,
      "grad_norm": 0.12873810529708862,
      "learning_rate": 2.2544585715504736e-05,
      "loss": 0.0016,
      "step": 64350
    },
    {
      "epoch": 5.49193617202833,
      "grad_norm": 0.18755176663398743,
      "learning_rate": 2.254031913985835e-05,
      "loss": 0.0017,
      "step": 64360
    },
    {
      "epoch": 5.492789487157607,
      "grad_norm": 0.11201618611812592,
      "learning_rate": 2.2536052564211964e-05,
      "loss": 0.002,
      "step": 64370
    },
    {
      "epoch": 5.493642802286884,
      "grad_norm": 0.06242343783378601,
      "learning_rate": 2.253178598856558e-05,
      "loss": 0.0017,
      "step": 64380
    },
    {
      "epoch": 5.494496117416162,
      "grad_norm": 0.17285029590129852,
      "learning_rate": 2.2527519412919193e-05,
      "loss": 0.0016,
      "step": 64390
    },
    {
      "epoch": 5.495349432545439,
      "grad_norm": 0.3127082586288452,
      "learning_rate": 2.2523252837272807e-05,
      "loss": 0.0019,
      "step": 64400
    },
    {
      "epoch": 5.496202747674716,
      "grad_norm": 0.07674869894981384,
      "learning_rate": 2.251898626162642e-05,
      "loss": 0.0019,
      "step": 64410
    },
    {
      "epoch": 5.497056062803994,
      "grad_norm": 0.391754686832428,
      "learning_rate": 2.2514719685980036e-05,
      "loss": 0.0021,
      "step": 64420
    },
    {
      "epoch": 5.49790937793327,
      "grad_norm": 0.2479781210422516,
      "learning_rate": 2.251045311033365e-05,
      "loss": 0.0019,
      "step": 64430
    },
    {
      "epoch": 5.498762693062548,
      "grad_norm": 0.15317247807979584,
      "learning_rate": 2.250618653468726e-05,
      "loss": 0.0018,
      "step": 64440
    },
    {
      "epoch": 5.4996160081918255,
      "grad_norm": 0.16589082777500153,
      "learning_rate": 2.2501919959040875e-05,
      "loss": 0.0016,
      "step": 64450
    },
    {
      "epoch": 5.500469323321102,
      "grad_norm": 0.1867208182811737,
      "learning_rate": 2.2497653383394486e-05,
      "loss": 0.0022,
      "step": 64460
    },
    {
      "epoch": 5.50132263845038,
      "grad_norm": 0.08039430528879166,
      "learning_rate": 2.24933868077481e-05,
      "loss": 0.0022,
      "step": 64470
    },
    {
      "epoch": 5.502175953579657,
      "grad_norm": 0.0465325191617012,
      "learning_rate": 2.2489120232101714e-05,
      "loss": 0.0019,
      "step": 64480
    },
    {
      "epoch": 5.503029268708934,
      "grad_norm": 0.09540780633687973,
      "learning_rate": 2.248485365645533e-05,
      "loss": 0.0021,
      "step": 64490
    },
    {
      "epoch": 5.5038825838382115,
      "grad_norm": 0.2059057652950287,
      "learning_rate": 2.2480587080808943e-05,
      "loss": 0.0015,
      "step": 64500
    },
    {
      "epoch": 5.504735898967489,
      "grad_norm": 0.13794539868831635,
      "learning_rate": 2.2476320505162557e-05,
      "loss": 0.0018,
      "step": 64510
    },
    {
      "epoch": 5.505589214096766,
      "grad_norm": 0.04546737298369408,
      "learning_rate": 2.247205392951617e-05,
      "loss": 0.0021,
      "step": 64520
    },
    {
      "epoch": 5.506442529226043,
      "grad_norm": 0.04551038146018982,
      "learning_rate": 2.2467787353869786e-05,
      "loss": 0.0014,
      "step": 64530
    },
    {
      "epoch": 5.507295844355321,
      "grad_norm": 0.09214542806148529,
      "learning_rate": 2.24635207782234e-05,
      "loss": 0.0016,
      "step": 64540
    },
    {
      "epoch": 5.5081491594845975,
      "grad_norm": 0.13131798803806305,
      "learning_rate": 2.2459254202577014e-05,
      "loss": 0.0015,
      "step": 64550
    },
    {
      "epoch": 5.509002474613875,
      "grad_norm": 0.17091208696365356,
      "learning_rate": 2.2454987626930625e-05,
      "loss": 0.0016,
      "step": 64560
    },
    {
      "epoch": 5.509855789743153,
      "grad_norm": 0.07585377991199493,
      "learning_rate": 2.245072105128424e-05,
      "loss": 0.0017,
      "step": 64570
    },
    {
      "epoch": 5.510709104872429,
      "grad_norm": 0.15002985298633575,
      "learning_rate": 2.2446454475637853e-05,
      "loss": 0.0016,
      "step": 64580
    },
    {
      "epoch": 5.511562420001707,
      "grad_norm": 0.28443974256515503,
      "learning_rate": 2.2442187899991468e-05,
      "loss": 0.0015,
      "step": 64590
    },
    {
      "epoch": 5.5124157351309835,
      "grad_norm": 0.030563959851861,
      "learning_rate": 2.2437921324345082e-05,
      "loss": 0.0018,
      "step": 64600
    },
    {
      "epoch": 5.513269050260261,
      "grad_norm": 0.046417076140642166,
      "learning_rate": 2.2433654748698696e-05,
      "loss": 0.0019,
      "step": 64610
    },
    {
      "epoch": 5.514122365389539,
      "grad_norm": 0.1457250863313675,
      "learning_rate": 2.242938817305231e-05,
      "loss": 0.0017,
      "step": 64620
    },
    {
      "epoch": 5.514975680518815,
      "grad_norm": 0.15992611646652222,
      "learning_rate": 2.2425121597405925e-05,
      "loss": 0.0016,
      "step": 64630
    },
    {
      "epoch": 5.515828995648093,
      "grad_norm": 0.11400656402111053,
      "learning_rate": 2.242085502175954e-05,
      "loss": 0.0016,
      "step": 64640
    },
    {
      "epoch": 5.51668231077737,
      "grad_norm": 0.023383263498544693,
      "learning_rate": 2.2416588446113153e-05,
      "loss": 0.0021,
      "step": 64650
    },
    {
      "epoch": 5.517535625906647,
      "grad_norm": 0.24967798590660095,
      "learning_rate": 2.2412321870466764e-05,
      "loss": 0.0019,
      "step": 64660
    },
    {
      "epoch": 5.518388941035925,
      "grad_norm": 0.09257732331752777,
      "learning_rate": 2.2408055294820378e-05,
      "loss": 0.0021,
      "step": 64670
    },
    {
      "epoch": 5.519242256165202,
      "grad_norm": 0.420367956161499,
      "learning_rate": 2.2403788719173992e-05,
      "loss": 0.0022,
      "step": 64680
    },
    {
      "epoch": 5.520095571294479,
      "grad_norm": 0.16402195394039154,
      "learning_rate": 2.2399522143527607e-05,
      "loss": 0.002,
      "step": 64690
    },
    {
      "epoch": 5.520948886423756,
      "grad_norm": 0.08004869520664215,
      "learning_rate": 2.239525556788122e-05,
      "loss": 0.0018,
      "step": 64700
    },
    {
      "epoch": 5.521802201553034,
      "grad_norm": 0.10402748733758926,
      "learning_rate": 2.2390988992234832e-05,
      "loss": 0.0015,
      "step": 64710
    },
    {
      "epoch": 5.522655516682311,
      "grad_norm": 0.2960146367549896,
      "learning_rate": 2.2386722416588446e-05,
      "loss": 0.0018,
      "step": 64720
    },
    {
      "epoch": 5.523508831811588,
      "grad_norm": 0.21487146615982056,
      "learning_rate": 2.238245584094206e-05,
      "loss": 0.002,
      "step": 64730
    },
    {
      "epoch": 5.524362146940865,
      "grad_norm": 0.23122665286064148,
      "learning_rate": 2.2378189265295674e-05,
      "loss": 0.0017,
      "step": 64740
    },
    {
      "epoch": 5.525215462070142,
      "grad_norm": 0.026753265410661697,
      "learning_rate": 2.237392268964929e-05,
      "loss": 0.0019,
      "step": 64750
    },
    {
      "epoch": 5.52606877719942,
      "grad_norm": 0.12463882565498352,
      "learning_rate": 2.2369656114002903e-05,
      "loss": 0.0016,
      "step": 64760
    },
    {
      "epoch": 5.526922092328697,
      "grad_norm": 0.12040212750434875,
      "learning_rate": 2.2365389538356514e-05,
      "loss": 0.0018,
      "step": 64770
    },
    {
      "epoch": 5.527775407457974,
      "grad_norm": 0.1737343668937683,
      "learning_rate": 2.2361122962710128e-05,
      "loss": 0.0017,
      "step": 64780
    },
    {
      "epoch": 5.528628722587252,
      "grad_norm": 0.4026145339012146,
      "learning_rate": 2.2356856387063742e-05,
      "loss": 0.0017,
      "step": 64790
    },
    {
      "epoch": 5.529482037716528,
      "grad_norm": 0.294498085975647,
      "learning_rate": 2.2352589811417357e-05,
      "loss": 0.0017,
      "step": 64800
    },
    {
      "epoch": 5.530335352845806,
      "grad_norm": 0.18654169142246246,
      "learning_rate": 2.234832323577097e-05,
      "loss": 0.0022,
      "step": 64810
    },
    {
      "epoch": 5.5311886679750835,
      "grad_norm": 0.2469952404499054,
      "learning_rate": 2.2344056660124585e-05,
      "loss": 0.0018,
      "step": 64820
    },
    {
      "epoch": 5.53204198310436,
      "grad_norm": 0.02981892041862011,
      "learning_rate": 2.23397900844782e-05,
      "loss": 0.0015,
      "step": 64830
    },
    {
      "epoch": 5.532895298233638,
      "grad_norm": 0.039793334901332855,
      "learning_rate": 2.2335523508831813e-05,
      "loss": 0.0018,
      "step": 64840
    },
    {
      "epoch": 5.533748613362915,
      "grad_norm": 0.20979829132556915,
      "learning_rate": 2.2331256933185428e-05,
      "loss": 0.0019,
      "step": 64850
    },
    {
      "epoch": 5.534601928492192,
      "grad_norm": 0.11077901721000671,
      "learning_rate": 2.2326990357539042e-05,
      "loss": 0.0015,
      "step": 64860
    },
    {
      "epoch": 5.5354552436214695,
      "grad_norm": 0.13118095695972443,
      "learning_rate": 2.2322723781892653e-05,
      "loss": 0.0022,
      "step": 64870
    },
    {
      "epoch": 5.536308558750747,
      "grad_norm": 0.1129274070262909,
      "learning_rate": 2.2318457206246267e-05,
      "loss": 0.0019,
      "step": 64880
    },
    {
      "epoch": 5.537161873880024,
      "grad_norm": 0.16945171356201172,
      "learning_rate": 2.231419063059988e-05,
      "loss": 0.0021,
      "step": 64890
    },
    {
      "epoch": 5.538015189009301,
      "grad_norm": 0.09680861979722977,
      "learning_rate": 2.2309924054953496e-05,
      "loss": 0.0025,
      "step": 64900
    },
    {
      "epoch": 5.538868504138579,
      "grad_norm": 0.2552502453327179,
      "learning_rate": 2.230565747930711e-05,
      "loss": 0.002,
      "step": 64910
    },
    {
      "epoch": 5.5397218192678555,
      "grad_norm": 0.08206319063901901,
      "learning_rate": 2.2301390903660724e-05,
      "loss": 0.0016,
      "step": 64920
    },
    {
      "epoch": 5.540575134397133,
      "grad_norm": 0.07877129316329956,
      "learning_rate": 2.2297124328014338e-05,
      "loss": 0.0019,
      "step": 64930
    },
    {
      "epoch": 5.541428449526411,
      "grad_norm": 0.10980494320392609,
      "learning_rate": 2.2292857752367952e-05,
      "loss": 0.0014,
      "step": 64940
    },
    {
      "epoch": 5.542281764655687,
      "grad_norm": 0.19322849810123444,
      "learning_rate": 2.2288591176721567e-05,
      "loss": 0.0017,
      "step": 64950
    },
    {
      "epoch": 5.543135079784965,
      "grad_norm": 0.12718141078948975,
      "learning_rate": 2.228432460107518e-05,
      "loss": 0.0017,
      "step": 64960
    },
    {
      "epoch": 5.5439883949142414,
      "grad_norm": 0.12268736213445663,
      "learning_rate": 2.2280058025428792e-05,
      "loss": 0.0015,
      "step": 64970
    },
    {
      "epoch": 5.544841710043519,
      "grad_norm": 0.12296868860721588,
      "learning_rate": 2.2275791449782406e-05,
      "loss": 0.0017,
      "step": 64980
    },
    {
      "epoch": 5.5456950251727966,
      "grad_norm": 0.27542662620544434,
      "learning_rate": 2.2271524874136017e-05,
      "loss": 0.0016,
      "step": 64990
    },
    {
      "epoch": 5.546548340302073,
      "grad_norm": 0.05429086834192276,
      "learning_rate": 2.226725829848963e-05,
      "loss": 0.0023,
      "step": 65000
    },
    {
      "epoch": 5.547401655431351,
      "grad_norm": 0.13326385617256165,
      "learning_rate": 2.2262991722843245e-05,
      "loss": 0.0017,
      "step": 65010
    },
    {
      "epoch": 5.548254970560628,
      "grad_norm": 0.18418961763381958,
      "learning_rate": 2.225872514719686e-05,
      "loss": 0.0016,
      "step": 65020
    },
    {
      "epoch": 5.549108285689905,
      "grad_norm": 0.4229683578014374,
      "learning_rate": 2.2254458571550474e-05,
      "loss": 0.0016,
      "step": 65030
    },
    {
      "epoch": 5.5499616008191826,
      "grad_norm": 0.14776767790317535,
      "learning_rate": 2.2250191995904088e-05,
      "loss": 0.002,
      "step": 65040
    },
    {
      "epoch": 5.55081491594846,
      "grad_norm": 0.09477932751178741,
      "learning_rate": 2.2245925420257702e-05,
      "loss": 0.0021,
      "step": 65050
    },
    {
      "epoch": 5.551668231077737,
      "grad_norm": 0.11920527368783951,
      "learning_rate": 2.2241658844611317e-05,
      "loss": 0.0016,
      "step": 65060
    },
    {
      "epoch": 5.552521546207014,
      "grad_norm": 0.34544384479522705,
      "learning_rate": 2.223739226896493e-05,
      "loss": 0.002,
      "step": 65070
    },
    {
      "epoch": 5.553374861336292,
      "grad_norm": 0.1269717812538147,
      "learning_rate": 2.2233125693318542e-05,
      "loss": 0.0019,
      "step": 65080
    },
    {
      "epoch": 5.5542281764655685,
      "grad_norm": 0.3504631519317627,
      "learning_rate": 2.2228859117672156e-05,
      "loss": 0.0019,
      "step": 65090
    },
    {
      "epoch": 5.555081491594846,
      "grad_norm": 0.347149521112442,
      "learning_rate": 2.222459254202577e-05,
      "loss": 0.0018,
      "step": 65100
    },
    {
      "epoch": 5.555934806724123,
      "grad_norm": 0.03431549668312073,
      "learning_rate": 2.2220325966379384e-05,
      "loss": 0.0014,
      "step": 65110
    },
    {
      "epoch": 5.5567881218534,
      "grad_norm": 0.1014498919248581,
      "learning_rate": 2.2216059390733e-05,
      "loss": 0.0015,
      "step": 65120
    },
    {
      "epoch": 5.557641436982678,
      "grad_norm": 0.09456547349691391,
      "learning_rate": 2.2211792815086613e-05,
      "loss": 0.0013,
      "step": 65130
    },
    {
      "epoch": 5.5584947521119545,
      "grad_norm": 0.25888702273368835,
      "learning_rate": 2.2207526239440227e-05,
      "loss": 0.002,
      "step": 65140
    },
    {
      "epoch": 5.559348067241232,
      "grad_norm": 0.20343753695487976,
      "learning_rate": 2.220325966379384e-05,
      "loss": 0.0019,
      "step": 65150
    },
    {
      "epoch": 5.56020138237051,
      "grad_norm": 0.028479035943746567,
      "learning_rate": 2.2198993088147456e-05,
      "loss": 0.0019,
      "step": 65160
    },
    {
      "epoch": 5.561054697499786,
      "grad_norm": 0.12803460657596588,
      "learning_rate": 2.219472651250107e-05,
      "loss": 0.0013,
      "step": 65170
    },
    {
      "epoch": 5.561908012629064,
      "grad_norm": 0.18330411612987518,
      "learning_rate": 2.219045993685468e-05,
      "loss": 0.0019,
      "step": 65180
    },
    {
      "epoch": 5.562761327758341,
      "grad_norm": 0.26060307025909424,
      "learning_rate": 2.2186193361208295e-05,
      "loss": 0.0015,
      "step": 65190
    },
    {
      "epoch": 5.563614642887618,
      "grad_norm": 0.09325577318668365,
      "learning_rate": 2.218192678556191e-05,
      "loss": 0.0022,
      "step": 65200
    },
    {
      "epoch": 5.564467958016896,
      "grad_norm": 0.025176478549838066,
      "learning_rate": 2.2177660209915523e-05,
      "loss": 0.0016,
      "step": 65210
    },
    {
      "epoch": 5.565321273146173,
      "grad_norm": 0.02637953869998455,
      "learning_rate": 2.2173393634269138e-05,
      "loss": 0.0017,
      "step": 65220
    },
    {
      "epoch": 5.56617458827545,
      "grad_norm": 0.06627063453197479,
      "learning_rate": 2.2169127058622752e-05,
      "loss": 0.0015,
      "step": 65230
    },
    {
      "epoch": 5.567027903404727,
      "grad_norm": 0.046860408037900925,
      "learning_rate": 2.2164860482976363e-05,
      "loss": 0.0015,
      "step": 65240
    },
    {
      "epoch": 5.567881218534005,
      "grad_norm": 0.148341104388237,
      "learning_rate": 2.2160593907329977e-05,
      "loss": 0.0017,
      "step": 65250
    },
    {
      "epoch": 5.568734533663282,
      "grad_norm": 0.20429055392742157,
      "learning_rate": 2.215632733168359e-05,
      "loss": 0.0014,
      "step": 65260
    },
    {
      "epoch": 5.569587848792559,
      "grad_norm": 0.12980887293815613,
      "learning_rate": 2.2152060756037205e-05,
      "loss": 0.0014,
      "step": 65270
    },
    {
      "epoch": 5.570441163921837,
      "grad_norm": 0.24075567722320557,
      "learning_rate": 2.214779418039082e-05,
      "loss": 0.0024,
      "step": 65280
    },
    {
      "epoch": 5.571294479051113,
      "grad_norm": 0.1517975926399231,
      "learning_rate": 2.2143527604744434e-05,
      "loss": 0.0018,
      "step": 65290
    },
    {
      "epoch": 5.572147794180391,
      "grad_norm": 0.05353512614965439,
      "learning_rate": 2.2139261029098045e-05,
      "loss": 0.0012,
      "step": 65300
    },
    {
      "epoch": 5.5730011093096685,
      "grad_norm": 0.3829612731933594,
      "learning_rate": 2.213499445345166e-05,
      "loss": 0.0015,
      "step": 65310
    },
    {
      "epoch": 5.573854424438945,
      "grad_norm": 0.38696616888046265,
      "learning_rate": 2.2130727877805273e-05,
      "loss": 0.0016,
      "step": 65320
    },
    {
      "epoch": 5.574707739568223,
      "grad_norm": 0.0807270035147667,
      "learning_rate": 2.2126461302158888e-05,
      "loss": 0.0016,
      "step": 65330
    },
    {
      "epoch": 5.575561054697499,
      "grad_norm": 0.183975487947464,
      "learning_rate": 2.2122194726512502e-05,
      "loss": 0.0018,
      "step": 65340
    },
    {
      "epoch": 5.576414369826777,
      "grad_norm": 0.1147628054022789,
      "learning_rate": 2.2117928150866116e-05,
      "loss": 0.0019,
      "step": 65350
    },
    {
      "epoch": 5.5772676849560545,
      "grad_norm": 0.18501690030097961,
      "learning_rate": 2.211366157521973e-05,
      "loss": 0.0018,
      "step": 65360
    },
    {
      "epoch": 5.578121000085331,
      "grad_norm": 0.16703444719314575,
      "learning_rate": 2.2109394999573345e-05,
      "loss": 0.0017,
      "step": 65370
    },
    {
      "epoch": 5.578974315214609,
      "grad_norm": 0.036436550319194794,
      "learning_rate": 2.210512842392696e-05,
      "loss": 0.0017,
      "step": 65380
    },
    {
      "epoch": 5.579827630343886,
      "grad_norm": 0.2804649770259857,
      "learning_rate": 2.210086184828057e-05,
      "loss": 0.0022,
      "step": 65390
    },
    {
      "epoch": 5.580680945473163,
      "grad_norm": 0.0324958898127079,
      "learning_rate": 2.2096595272634184e-05,
      "loss": 0.0014,
      "step": 65400
    },
    {
      "epoch": 5.5815342606024405,
      "grad_norm": 0.2394380271434784,
      "learning_rate": 2.2092328696987798e-05,
      "loss": 0.0017,
      "step": 65410
    },
    {
      "epoch": 5.582387575731718,
      "grad_norm": 0.0568169504404068,
      "learning_rate": 2.2088062121341412e-05,
      "loss": 0.0019,
      "step": 65420
    },
    {
      "epoch": 5.583240890860995,
      "grad_norm": 0.10874275118112564,
      "learning_rate": 2.2083795545695027e-05,
      "loss": 0.002,
      "step": 65430
    },
    {
      "epoch": 5.584094205990272,
      "grad_norm": 0.08552351593971252,
      "learning_rate": 2.207952897004864e-05,
      "loss": 0.0016,
      "step": 65440
    },
    {
      "epoch": 5.584947521119549,
      "grad_norm": 0.2239430695772171,
      "learning_rate": 2.2075262394402255e-05,
      "loss": 0.0019,
      "step": 65450
    },
    {
      "epoch": 5.5858008362488265,
      "grad_norm": 0.049748245626688004,
      "learning_rate": 2.207099581875587e-05,
      "loss": 0.0017,
      "step": 65460
    },
    {
      "epoch": 5.586654151378104,
      "grad_norm": 0.18896907567977905,
      "learning_rate": 2.2066729243109484e-05,
      "loss": 0.002,
      "step": 65470
    },
    {
      "epoch": 5.587507466507381,
      "grad_norm": 0.2759873569011688,
      "learning_rate": 2.2062462667463098e-05,
      "loss": 0.0017,
      "step": 65480
    },
    {
      "epoch": 5.588360781636658,
      "grad_norm": 0.23511795699596405,
      "learning_rate": 2.205819609181671e-05,
      "loss": 0.0015,
      "step": 65490
    },
    {
      "epoch": 5.589214096765936,
      "grad_norm": 0.09498947858810425,
      "learning_rate": 2.2053929516170323e-05,
      "loss": 0.0013,
      "step": 65500
    },
    {
      "epoch": 5.5900674118952125,
      "grad_norm": 0.3475300967693329,
      "learning_rate": 2.2049662940523934e-05,
      "loss": 0.0018,
      "step": 65510
    },
    {
      "epoch": 5.59092072702449,
      "grad_norm": 0.022313706576824188,
      "learning_rate": 2.2045396364877548e-05,
      "loss": 0.0017,
      "step": 65520
    },
    {
      "epoch": 5.591774042153768,
      "grad_norm": 0.1856323629617691,
      "learning_rate": 2.2041129789231162e-05,
      "loss": 0.0022,
      "step": 65530
    },
    {
      "epoch": 5.592627357283044,
      "grad_norm": 0.14360560476779938,
      "learning_rate": 2.2036863213584776e-05,
      "loss": 0.0022,
      "step": 65540
    },
    {
      "epoch": 5.593480672412322,
      "grad_norm": 0.3079257607460022,
      "learning_rate": 2.203259663793839e-05,
      "loss": 0.0018,
      "step": 65550
    },
    {
      "epoch": 5.594333987541599,
      "grad_norm": 0.3576416075229645,
      "learning_rate": 2.2028330062292005e-05,
      "loss": 0.0017,
      "step": 65560
    },
    {
      "epoch": 5.595187302670876,
      "grad_norm": 0.17666000127792358,
      "learning_rate": 2.202406348664562e-05,
      "loss": 0.002,
      "step": 65570
    },
    {
      "epoch": 5.596040617800154,
      "grad_norm": 0.12949104607105255,
      "learning_rate": 2.2019796910999233e-05,
      "loss": 0.0017,
      "step": 65580
    },
    {
      "epoch": 5.596893932929431,
      "grad_norm": 0.13019883632659912,
      "learning_rate": 2.2015530335352848e-05,
      "loss": 0.0017,
      "step": 65590
    },
    {
      "epoch": 5.597747248058708,
      "grad_norm": 0.12070935219526291,
      "learning_rate": 2.2011263759706462e-05,
      "loss": 0.002,
      "step": 65600
    },
    {
      "epoch": 5.598600563187985,
      "grad_norm": 0.22229330241680145,
      "learning_rate": 2.2006997184060073e-05,
      "loss": 0.0021,
      "step": 65610
    },
    {
      "epoch": 5.599453878317263,
      "grad_norm": 0.17373165488243103,
      "learning_rate": 2.2002730608413687e-05,
      "loss": 0.0017,
      "step": 65620
    },
    {
      "epoch": 5.60030719344654,
      "grad_norm": 0.24463225901126862,
      "learning_rate": 2.19984640327673e-05,
      "loss": 0.0019,
      "step": 65630
    },
    {
      "epoch": 5.601160508575817,
      "grad_norm": 0.09700878709554672,
      "learning_rate": 2.1994197457120915e-05,
      "loss": 0.0021,
      "step": 65640
    },
    {
      "epoch": 5.602013823705095,
      "grad_norm": 0.23395346105098724,
      "learning_rate": 2.198993088147453e-05,
      "loss": 0.0022,
      "step": 65650
    },
    {
      "epoch": 5.602867138834371,
      "grad_norm": 0.09956733137369156,
      "learning_rate": 2.1985664305828144e-05,
      "loss": 0.0017,
      "step": 65660
    },
    {
      "epoch": 5.603720453963649,
      "grad_norm": 0.0957520455121994,
      "learning_rate": 2.1981397730181758e-05,
      "loss": 0.0017,
      "step": 65670
    },
    {
      "epoch": 5.6045737690929265,
      "grad_norm": 0.028829002752900124,
      "learning_rate": 2.1977131154535372e-05,
      "loss": 0.0022,
      "step": 65680
    },
    {
      "epoch": 5.605427084222203,
      "grad_norm": 0.2216925472021103,
      "learning_rate": 2.1972864578888987e-05,
      "loss": 0.0017,
      "step": 65690
    },
    {
      "epoch": 5.606280399351481,
      "grad_norm": 0.023728398606181145,
      "learning_rate": 2.1968598003242598e-05,
      "loss": 0.0019,
      "step": 65700
    },
    {
      "epoch": 5.607133714480757,
      "grad_norm": 0.22122591733932495,
      "learning_rate": 2.1964331427596212e-05,
      "loss": 0.0019,
      "step": 65710
    },
    {
      "epoch": 5.607987029610035,
      "grad_norm": 0.04047580808401108,
      "learning_rate": 2.1960064851949826e-05,
      "loss": 0.0017,
      "step": 65720
    },
    {
      "epoch": 5.6088403447393125,
      "grad_norm": 0.2566125690937042,
      "learning_rate": 2.195579827630344e-05,
      "loss": 0.0017,
      "step": 65730
    },
    {
      "epoch": 5.609693659868589,
      "grad_norm": 0.2422935515642166,
      "learning_rate": 2.1951531700657054e-05,
      "loss": 0.0017,
      "step": 65740
    },
    {
      "epoch": 5.610546974997867,
      "grad_norm": 0.0749511867761612,
      "learning_rate": 2.194726512501067e-05,
      "loss": 0.0018,
      "step": 65750
    },
    {
      "epoch": 5.611400290127144,
      "grad_norm": 0.3793221116065979,
      "learning_rate": 2.1942998549364283e-05,
      "loss": 0.002,
      "step": 65760
    },
    {
      "epoch": 5.612253605256421,
      "grad_norm": 0.030715394765138626,
      "learning_rate": 2.1938731973717894e-05,
      "loss": 0.0021,
      "step": 65770
    },
    {
      "epoch": 5.6131069203856985,
      "grad_norm": 0.2653637230396271,
      "learning_rate": 2.1934465398071508e-05,
      "loss": 0.0024,
      "step": 65780
    },
    {
      "epoch": 5.613960235514976,
      "grad_norm": 0.13446639478206635,
      "learning_rate": 2.1930198822425122e-05,
      "loss": 0.0019,
      "step": 65790
    },
    {
      "epoch": 5.614813550644253,
      "grad_norm": 0.31474387645721436,
      "learning_rate": 2.1925932246778737e-05,
      "loss": 0.0016,
      "step": 65800
    },
    {
      "epoch": 5.61566686577353,
      "grad_norm": 0.13401742279529572,
      "learning_rate": 2.192166567113235e-05,
      "loss": 0.002,
      "step": 65810
    },
    {
      "epoch": 5.616520180902807,
      "grad_norm": 0.3476988971233368,
      "learning_rate": 2.191739909548596e-05,
      "loss": 0.0026,
      "step": 65820
    },
    {
      "epoch": 5.6173734960320845,
      "grad_norm": 0.07894669473171234,
      "learning_rate": 2.1913132519839576e-05,
      "loss": 0.0018,
      "step": 65830
    },
    {
      "epoch": 5.618226811161362,
      "grad_norm": 0.11054135859012604,
      "learning_rate": 2.190886594419319e-05,
      "loss": 0.0016,
      "step": 65840
    },
    {
      "epoch": 5.619080126290639,
      "grad_norm": 0.39139896631240845,
      "learning_rate": 2.1904599368546804e-05,
      "loss": 0.0025,
      "step": 65850
    },
    {
      "epoch": 5.619933441419916,
      "grad_norm": 0.0586710199713707,
      "learning_rate": 2.190033279290042e-05,
      "loss": 0.0019,
      "step": 65860
    },
    {
      "epoch": 5.620786756549194,
      "grad_norm": 0.24912074208259583,
      "learning_rate": 2.1896066217254033e-05,
      "loss": 0.0022,
      "step": 65870
    },
    {
      "epoch": 5.6216400716784705,
      "grad_norm": 0.07429102808237076,
      "learning_rate": 2.1891799641607647e-05,
      "loss": 0.0015,
      "step": 65880
    },
    {
      "epoch": 5.622493386807748,
      "grad_norm": 0.1380683034658432,
      "learning_rate": 2.188753306596126e-05,
      "loss": 0.0021,
      "step": 65890
    },
    {
      "epoch": 5.623346701937026,
      "grad_norm": 0.2404000163078308,
      "learning_rate": 2.1883266490314876e-05,
      "loss": 0.0016,
      "step": 65900
    },
    {
      "epoch": 5.624200017066302,
      "grad_norm": 0.11334426701068878,
      "learning_rate": 2.187899991466849e-05,
      "loss": 0.0012,
      "step": 65910
    },
    {
      "epoch": 5.62505333219558,
      "grad_norm": 0.1494099348783493,
      "learning_rate": 2.18747333390221e-05,
      "loss": 0.0017,
      "step": 65920
    },
    {
      "epoch": 5.625906647324857,
      "grad_norm": 0.1378404200077057,
      "learning_rate": 2.1870466763375715e-05,
      "loss": 0.0022,
      "step": 65930
    },
    {
      "epoch": 5.626759962454134,
      "grad_norm": 0.03423573449254036,
      "learning_rate": 2.186620018772933e-05,
      "loss": 0.0016,
      "step": 65940
    },
    {
      "epoch": 5.627613277583412,
      "grad_norm": 0.29301944375038147,
      "learning_rate": 2.1861933612082943e-05,
      "loss": 0.0018,
      "step": 65950
    },
    {
      "epoch": 5.628466592712689,
      "grad_norm": 0.1800437569618225,
      "learning_rate": 2.1857667036436558e-05,
      "loss": 0.0017,
      "step": 65960
    },
    {
      "epoch": 5.629319907841966,
      "grad_norm": 0.4040558338165283,
      "learning_rate": 2.1853400460790172e-05,
      "loss": 0.002,
      "step": 65970
    },
    {
      "epoch": 5.630173222971243,
      "grad_norm": 0.3716621696949005,
      "learning_rate": 2.1849133885143786e-05,
      "loss": 0.0014,
      "step": 65980
    },
    {
      "epoch": 5.631026538100521,
      "grad_norm": 0.13622049987316132,
      "learning_rate": 2.18448673094974e-05,
      "loss": 0.0015,
      "step": 65990
    },
    {
      "epoch": 5.631879853229798,
      "grad_norm": 0.03657784312963486,
      "learning_rate": 2.1840600733851015e-05,
      "loss": 0.0016,
      "step": 66000
    },
    {
      "epoch": 5.632733168359075,
      "grad_norm": 0.040666788816452026,
      "learning_rate": 2.1836334158204625e-05,
      "loss": 0.0016,
      "step": 66010
    },
    {
      "epoch": 5.633586483488353,
      "grad_norm": 0.03502940759062767,
      "learning_rate": 2.183206758255824e-05,
      "loss": 0.0014,
      "step": 66020
    },
    {
      "epoch": 5.634439798617629,
      "grad_norm": 0.2232900857925415,
      "learning_rate": 2.1827801006911854e-05,
      "loss": 0.0014,
      "step": 66030
    },
    {
      "epoch": 5.635293113746907,
      "grad_norm": 0.13888734579086304,
      "learning_rate": 2.1823534431265465e-05,
      "loss": 0.0021,
      "step": 66040
    },
    {
      "epoch": 5.6361464288761844,
      "grad_norm": 0.09505146741867065,
      "learning_rate": 2.181926785561908e-05,
      "loss": 0.0014,
      "step": 66050
    },
    {
      "epoch": 5.636999744005461,
      "grad_norm": 0.25846579670906067,
      "learning_rate": 2.1815001279972693e-05,
      "loss": 0.0014,
      "step": 66060
    },
    {
      "epoch": 5.637853059134739,
      "grad_norm": 0.4637220799922943,
      "learning_rate": 2.1810734704326308e-05,
      "loss": 0.0016,
      "step": 66070
    },
    {
      "epoch": 5.638706374264015,
      "grad_norm": 0.08313708752393723,
      "learning_rate": 2.1806468128679922e-05,
      "loss": 0.0022,
      "step": 66080
    },
    {
      "epoch": 5.639559689393293,
      "grad_norm": 0.11513688415288925,
      "learning_rate": 2.1802201553033536e-05,
      "loss": 0.0018,
      "step": 66090
    },
    {
      "epoch": 5.64041300452257,
      "grad_norm": 0.09346989542245865,
      "learning_rate": 2.179793497738715e-05,
      "loss": 0.0016,
      "step": 66100
    },
    {
      "epoch": 5.641266319651847,
      "grad_norm": 0.049800217151641846,
      "learning_rate": 2.1793668401740764e-05,
      "loss": 0.0024,
      "step": 66110
    },
    {
      "epoch": 5.642119634781125,
      "grad_norm": 0.1996108740568161,
      "learning_rate": 2.178940182609438e-05,
      "loss": 0.0023,
      "step": 66120
    },
    {
      "epoch": 5.642972949910402,
      "grad_norm": 0.22521544992923737,
      "learning_rate": 2.178513525044799e-05,
      "loss": 0.0013,
      "step": 66130
    },
    {
      "epoch": 5.643826265039679,
      "grad_norm": 0.10033855587244034,
      "learning_rate": 2.1780868674801604e-05,
      "loss": 0.002,
      "step": 66140
    },
    {
      "epoch": 5.644679580168956,
      "grad_norm": 0.11682812869548798,
      "learning_rate": 2.1776602099155218e-05,
      "loss": 0.0016,
      "step": 66150
    },
    {
      "epoch": 5.645532895298234,
      "grad_norm": 0.2787238359451294,
      "learning_rate": 2.1772335523508832e-05,
      "loss": 0.0018,
      "step": 66160
    },
    {
      "epoch": 5.646386210427511,
      "grad_norm": 0.060736216604709625,
      "learning_rate": 2.1768068947862447e-05,
      "loss": 0.0016,
      "step": 66170
    },
    {
      "epoch": 5.647239525556788,
      "grad_norm": 0.11888672411441803,
      "learning_rate": 2.176380237221606e-05,
      "loss": 0.0018,
      "step": 66180
    },
    {
      "epoch": 5.648092840686065,
      "grad_norm": 0.09134633094072342,
      "learning_rate": 2.1759535796569675e-05,
      "loss": 0.002,
      "step": 66190
    },
    {
      "epoch": 5.648946155815342,
      "grad_norm": 0.25910675525665283,
      "learning_rate": 2.175526922092329e-05,
      "loss": 0.0021,
      "step": 66200
    },
    {
      "epoch": 5.64979947094462,
      "grad_norm": 0.2585417628288269,
      "learning_rate": 2.1751002645276903e-05,
      "loss": 0.0022,
      "step": 66210
    },
    {
      "epoch": 5.650652786073897,
      "grad_norm": 0.23280195891857147,
      "learning_rate": 2.1746736069630518e-05,
      "loss": 0.0024,
      "step": 66220
    },
    {
      "epoch": 5.651506101203174,
      "grad_norm": 0.11225422471761703,
      "learning_rate": 2.174246949398413e-05,
      "loss": 0.0019,
      "step": 66230
    },
    {
      "epoch": 5.652359416332452,
      "grad_norm": 0.09139904379844666,
      "learning_rate": 2.1738202918337743e-05,
      "loss": 0.002,
      "step": 66240
    },
    {
      "epoch": 5.653212731461728,
      "grad_norm": 0.33061525225639343,
      "learning_rate": 2.1733936342691357e-05,
      "loss": 0.0018,
      "step": 66250
    },
    {
      "epoch": 5.654066046591006,
      "grad_norm": 0.18153470754623413,
      "learning_rate": 2.172966976704497e-05,
      "loss": 0.0021,
      "step": 66260
    },
    {
      "epoch": 5.6549193617202835,
      "grad_norm": 0.3528805673122406,
      "learning_rate": 2.1725403191398586e-05,
      "loss": 0.0018,
      "step": 66270
    },
    {
      "epoch": 5.65577267684956,
      "grad_norm": 0.11340916901826859,
      "learning_rate": 2.17211366157522e-05,
      "loss": 0.0018,
      "step": 66280
    },
    {
      "epoch": 5.656625991978838,
      "grad_norm": 0.1500139981508255,
      "learning_rate": 2.1716870040105814e-05,
      "loss": 0.0017,
      "step": 66290
    },
    {
      "epoch": 5.657479307108115,
      "grad_norm": 0.18554674088954926,
      "learning_rate": 2.1712603464459428e-05,
      "loss": 0.0018,
      "step": 66300
    },
    {
      "epoch": 5.658332622237392,
      "grad_norm": 0.17037993669509888,
      "learning_rate": 2.170833688881304e-05,
      "loss": 0.0017,
      "step": 66310
    },
    {
      "epoch": 5.6591859373666695,
      "grad_norm": 0.06226927787065506,
      "learning_rate": 2.1704070313166653e-05,
      "loss": 0.0016,
      "step": 66320
    },
    {
      "epoch": 5.660039252495947,
      "grad_norm": 0.0944032073020935,
      "learning_rate": 2.1699803737520268e-05,
      "loss": 0.0016,
      "step": 66330
    },
    {
      "epoch": 5.660892567625224,
      "grad_norm": 0.10254959762096405,
      "learning_rate": 2.169553716187388e-05,
      "loss": 0.0017,
      "step": 66340
    },
    {
      "epoch": 5.661745882754501,
      "grad_norm": 0.040152259171009064,
      "learning_rate": 2.1691270586227493e-05,
      "loss": 0.0018,
      "step": 66350
    },
    {
      "epoch": 5.662599197883779,
      "grad_norm": 0.1644478738307953,
      "learning_rate": 2.1687004010581107e-05,
      "loss": 0.0017,
      "step": 66360
    },
    {
      "epoch": 5.6634525130130555,
      "grad_norm": 0.27708199620246887,
      "learning_rate": 2.168273743493472e-05,
      "loss": 0.0021,
      "step": 66370
    },
    {
      "epoch": 5.664305828142333,
      "grad_norm": 0.23939646780490875,
      "learning_rate": 2.1678470859288335e-05,
      "loss": 0.0016,
      "step": 66380
    },
    {
      "epoch": 5.665159143271611,
      "grad_norm": 0.02716686576604843,
      "learning_rate": 2.167420428364195e-05,
      "loss": 0.0017,
      "step": 66390
    },
    {
      "epoch": 5.666012458400887,
      "grad_norm": 0.3491743505001068,
      "learning_rate": 2.1669937707995564e-05,
      "loss": 0.0017,
      "step": 66400
    },
    {
      "epoch": 5.666865773530165,
      "grad_norm": 0.19317081570625305,
      "learning_rate": 2.1665671132349178e-05,
      "loss": 0.0017,
      "step": 66410
    },
    {
      "epoch": 5.667719088659442,
      "grad_norm": 0.23697127401828766,
      "learning_rate": 2.1661404556702792e-05,
      "loss": 0.0021,
      "step": 66420
    },
    {
      "epoch": 5.668572403788719,
      "grad_norm": 0.31307077407836914,
      "learning_rate": 2.1657137981056407e-05,
      "loss": 0.0016,
      "step": 66430
    },
    {
      "epoch": 5.669425718917997,
      "grad_norm": 0.14759264886379242,
      "learning_rate": 2.1652871405410017e-05,
      "loss": 0.0016,
      "step": 66440
    },
    {
      "epoch": 5.670279034047273,
      "grad_norm": 0.09614124894142151,
      "learning_rate": 2.1648604829763632e-05,
      "loss": 0.0019,
      "step": 66450
    },
    {
      "epoch": 5.671132349176551,
      "grad_norm": 0.2226807028055191,
      "learning_rate": 2.1644338254117246e-05,
      "loss": 0.0017,
      "step": 66460
    },
    {
      "epoch": 5.671985664305828,
      "grad_norm": 0.35711434483528137,
      "learning_rate": 2.164007167847086e-05,
      "loss": 0.0019,
      "step": 66470
    },
    {
      "epoch": 5.672838979435105,
      "grad_norm": 0.17008398473262787,
      "learning_rate": 2.1635805102824474e-05,
      "loss": 0.0016,
      "step": 66480
    },
    {
      "epoch": 5.673692294564383,
      "grad_norm": 0.25290176272392273,
      "learning_rate": 2.163153852717809e-05,
      "loss": 0.0021,
      "step": 66490
    },
    {
      "epoch": 5.67454560969366,
      "grad_norm": 0.4662173390388489,
      "learning_rate": 2.1627271951531703e-05,
      "loss": 0.0019,
      "step": 66500
    },
    {
      "epoch": 5.675398924822937,
      "grad_norm": 0.03968106955289841,
      "learning_rate": 2.1623005375885317e-05,
      "loss": 0.0023,
      "step": 66510
    },
    {
      "epoch": 5.676252239952214,
      "grad_norm": 0.19500388205051422,
      "learning_rate": 2.161873880023893e-05,
      "loss": 0.0019,
      "step": 66520
    },
    {
      "epoch": 5.677105555081492,
      "grad_norm": 0.03370601683855057,
      "learning_rate": 2.1614472224592546e-05,
      "loss": 0.0018,
      "step": 66530
    },
    {
      "epoch": 5.677958870210769,
      "grad_norm": 0.039436765015125275,
      "learning_rate": 2.1610205648946157e-05,
      "loss": 0.0019,
      "step": 66540
    },
    {
      "epoch": 5.678812185340046,
      "grad_norm": 0.04056064411997795,
      "learning_rate": 2.160593907329977e-05,
      "loss": 0.0018,
      "step": 66550
    },
    {
      "epoch": 5.679665500469323,
      "grad_norm": 0.22394047677516937,
      "learning_rate": 2.1601672497653385e-05,
      "loss": 0.0016,
      "step": 66560
    },
    {
      "epoch": 5.6805188155986,
      "grad_norm": 0.3337002694606781,
      "learning_rate": 2.1597405922006996e-05,
      "loss": 0.0017,
      "step": 66570
    },
    {
      "epoch": 5.681372130727878,
      "grad_norm": 0.14661653339862823,
      "learning_rate": 2.159313934636061e-05,
      "loss": 0.0018,
      "step": 66580
    },
    {
      "epoch": 5.682225445857155,
      "grad_norm": 0.11217400431632996,
      "learning_rate": 2.1588872770714224e-05,
      "loss": 0.002,
      "step": 66590
    },
    {
      "epoch": 5.683078760986432,
      "grad_norm": 0.10119674354791641,
      "learning_rate": 2.158460619506784e-05,
      "loss": 0.0021,
      "step": 66600
    },
    {
      "epoch": 5.68393207611571,
      "grad_norm": 0.18556810915470123,
      "learning_rate": 2.1580339619421453e-05,
      "loss": 0.0017,
      "step": 66610
    },
    {
      "epoch": 5.684785391244986,
      "grad_norm": 0.32822513580322266,
      "learning_rate": 2.1576073043775067e-05,
      "loss": 0.0017,
      "step": 66620
    },
    {
      "epoch": 5.685638706374264,
      "grad_norm": 0.09865415096282959,
      "learning_rate": 2.157180646812868e-05,
      "loss": 0.0018,
      "step": 66630
    },
    {
      "epoch": 5.6864920215035415,
      "grad_norm": 0.3449956774711609,
      "learning_rate": 2.1567539892482296e-05,
      "loss": 0.0021,
      "step": 66640
    },
    {
      "epoch": 5.687345336632818,
      "grad_norm": 0.1685095727443695,
      "learning_rate": 2.1563273316835906e-05,
      "loss": 0.0017,
      "step": 66650
    },
    {
      "epoch": 5.688198651762096,
      "grad_norm": 0.20020470023155212,
      "learning_rate": 2.155900674118952e-05,
      "loss": 0.0015,
      "step": 66660
    },
    {
      "epoch": 5.689051966891373,
      "grad_norm": 0.16418468952178955,
      "learning_rate": 2.1554740165543135e-05,
      "loss": 0.0019,
      "step": 66670
    },
    {
      "epoch": 5.68990528202065,
      "grad_norm": 0.04771507903933525,
      "learning_rate": 2.155047358989675e-05,
      "loss": 0.0013,
      "step": 66680
    },
    {
      "epoch": 5.6907585971499275,
      "grad_norm": 0.2797423005104065,
      "learning_rate": 2.1546207014250363e-05,
      "loss": 0.0022,
      "step": 66690
    },
    {
      "epoch": 5.691611912279205,
      "grad_norm": 0.05962308496236801,
      "learning_rate": 2.1541940438603978e-05,
      "loss": 0.0015,
      "step": 66700
    },
    {
      "epoch": 5.692465227408482,
      "grad_norm": 0.3113677203655243,
      "learning_rate": 2.1537673862957592e-05,
      "loss": 0.0017,
      "step": 66710
    },
    {
      "epoch": 5.693318542537759,
      "grad_norm": 0.0859646424651146,
      "learning_rate": 2.1533407287311206e-05,
      "loss": 0.0017,
      "step": 66720
    },
    {
      "epoch": 5.694171857667037,
      "grad_norm": 0.382693886756897,
      "learning_rate": 2.152914071166482e-05,
      "loss": 0.0015,
      "step": 66730
    },
    {
      "epoch": 5.6950251727963135,
      "grad_norm": 0.22099913656711578,
      "learning_rate": 2.1524874136018435e-05,
      "loss": 0.0016,
      "step": 66740
    },
    {
      "epoch": 5.695878487925591,
      "grad_norm": 0.12727400660514832,
      "learning_rate": 2.1520607560372045e-05,
      "loss": 0.0025,
      "step": 66750
    },
    {
      "epoch": 5.696731803054869,
      "grad_norm": 0.3002828061580658,
      "learning_rate": 2.151634098472566e-05,
      "loss": 0.0024,
      "step": 66760
    },
    {
      "epoch": 5.697585118184145,
      "grad_norm": 0.12058152258396149,
      "learning_rate": 2.1512074409079274e-05,
      "loss": 0.0021,
      "step": 66770
    },
    {
      "epoch": 5.698438433313423,
      "grad_norm": 0.16522550582885742,
      "learning_rate": 2.1507807833432888e-05,
      "loss": 0.0019,
      "step": 66780
    },
    {
      "epoch": 5.6992917484427,
      "grad_norm": 0.04152023419737816,
      "learning_rate": 2.1503541257786502e-05,
      "loss": 0.002,
      "step": 66790
    },
    {
      "epoch": 5.700145063571977,
      "grad_norm": 0.034884173423051834,
      "learning_rate": 2.1499274682140117e-05,
      "loss": 0.002,
      "step": 66800
    },
    {
      "epoch": 5.700998378701255,
      "grad_norm": 0.1528782844543457,
      "learning_rate": 2.149500810649373e-05,
      "loss": 0.0025,
      "step": 66810
    },
    {
      "epoch": 5.701851693830531,
      "grad_norm": 0.06240106374025345,
      "learning_rate": 2.1490741530847345e-05,
      "loss": 0.0018,
      "step": 66820
    },
    {
      "epoch": 5.702705008959809,
      "grad_norm": 0.26253554224967957,
      "learning_rate": 2.148647495520096e-05,
      "loss": 0.0019,
      "step": 66830
    },
    {
      "epoch": 5.703558324089086,
      "grad_norm": 0.40880176424980164,
      "learning_rate": 2.148220837955457e-05,
      "loss": 0.0019,
      "step": 66840
    },
    {
      "epoch": 5.704411639218363,
      "grad_norm": 0.49991467595100403,
      "learning_rate": 2.1477941803908184e-05,
      "loss": 0.0017,
      "step": 66850
    },
    {
      "epoch": 5.705264954347641,
      "grad_norm": 0.21811257302761078,
      "learning_rate": 2.14736752282618e-05,
      "loss": 0.0019,
      "step": 66860
    },
    {
      "epoch": 5.706118269476918,
      "grad_norm": 0.31439468264579773,
      "learning_rate": 2.146940865261541e-05,
      "loss": 0.0015,
      "step": 66870
    },
    {
      "epoch": 5.706971584606195,
      "grad_norm": 0.059486646205186844,
      "learning_rate": 2.1465142076969024e-05,
      "loss": 0.002,
      "step": 66880
    },
    {
      "epoch": 5.707824899735472,
      "grad_norm": 0.095722496509552,
      "learning_rate": 2.1460875501322638e-05,
      "loss": 0.0016,
      "step": 66890
    },
    {
      "epoch": 5.70867821486475,
      "grad_norm": 0.129464790225029,
      "learning_rate": 2.1456608925676252e-05,
      "loss": 0.0018,
      "step": 66900
    },
    {
      "epoch": 5.709531529994027,
      "grad_norm": 0.2796677350997925,
      "learning_rate": 2.1452342350029866e-05,
      "loss": 0.0021,
      "step": 66910
    },
    {
      "epoch": 5.710384845123304,
      "grad_norm": 0.028227083384990692,
      "learning_rate": 2.144807577438348e-05,
      "loss": 0.0015,
      "step": 66920
    },
    {
      "epoch": 5.711238160252581,
      "grad_norm": 0.3689366281032562,
      "learning_rate": 2.1443809198737095e-05,
      "loss": 0.002,
      "step": 66930
    },
    {
      "epoch": 5.712091475381858,
      "grad_norm": 0.27921390533447266,
      "learning_rate": 2.143954262309071e-05,
      "loss": 0.0017,
      "step": 66940
    },
    {
      "epoch": 5.712944790511136,
      "grad_norm": 0.11339433491230011,
      "learning_rate": 2.1435276047444323e-05,
      "loss": 0.0016,
      "step": 66950
    },
    {
      "epoch": 5.713798105640413,
      "grad_norm": 0.1760246306657791,
      "learning_rate": 2.1431009471797934e-05,
      "loss": 0.0016,
      "step": 66960
    },
    {
      "epoch": 5.71465142076969,
      "grad_norm": 0.06971923261880875,
      "learning_rate": 2.142674289615155e-05,
      "loss": 0.0017,
      "step": 66970
    },
    {
      "epoch": 5.715504735898968,
      "grad_norm": 0.10647660493850708,
      "learning_rate": 2.1422476320505163e-05,
      "loss": 0.0017,
      "step": 66980
    },
    {
      "epoch": 5.716358051028244,
      "grad_norm": 0.31634142994880676,
      "learning_rate": 2.1418209744858777e-05,
      "loss": 0.0018,
      "step": 66990
    },
    {
      "epoch": 5.717211366157522,
      "grad_norm": 0.25498077273368835,
      "learning_rate": 2.141394316921239e-05,
      "loss": 0.0016,
      "step": 67000
    },
    {
      "epoch": 5.7180646812867995,
      "grad_norm": 0.09275589883327484,
      "learning_rate": 2.1409676593566005e-05,
      "loss": 0.0019,
      "step": 67010
    },
    {
      "epoch": 5.718917996416076,
      "grad_norm": 0.14855870604515076,
      "learning_rate": 2.140541001791962e-05,
      "loss": 0.0015,
      "step": 67020
    },
    {
      "epoch": 5.719771311545354,
      "grad_norm": 0.19500839710235596,
      "learning_rate": 2.1401143442273234e-05,
      "loss": 0.002,
      "step": 67030
    },
    {
      "epoch": 5.720624626674631,
      "grad_norm": 0.04774501547217369,
      "learning_rate": 2.1396876866626848e-05,
      "loss": 0.0014,
      "step": 67040
    },
    {
      "epoch": 5.721477941803908,
      "grad_norm": 0.3626156151294708,
      "learning_rate": 2.1392610290980462e-05,
      "loss": 0.0013,
      "step": 67050
    },
    {
      "epoch": 5.7223312569331855,
      "grad_norm": 0.17191289365291595,
      "learning_rate": 2.1388343715334073e-05,
      "loss": 0.0017,
      "step": 67060
    },
    {
      "epoch": 5.723184572062463,
      "grad_norm": 0.09884212911128998,
      "learning_rate": 2.1384077139687688e-05,
      "loss": 0.0017,
      "step": 67070
    },
    {
      "epoch": 5.72403788719174,
      "grad_norm": 0.2793827950954437,
      "learning_rate": 2.1379810564041302e-05,
      "loss": 0.0018,
      "step": 67080
    },
    {
      "epoch": 5.724891202321017,
      "grad_norm": 0.14661750197410583,
      "learning_rate": 2.1375543988394916e-05,
      "loss": 0.0016,
      "step": 67090
    },
    {
      "epoch": 5.725744517450295,
      "grad_norm": 0.10972423106431961,
      "learning_rate": 2.1371277412748527e-05,
      "loss": 0.0018,
      "step": 67100
    },
    {
      "epoch": 5.7265978325795714,
      "grad_norm": 0.40092381834983826,
      "learning_rate": 2.136701083710214e-05,
      "loss": 0.002,
      "step": 67110
    },
    {
      "epoch": 5.727451147708849,
      "grad_norm": 0.048475250601768494,
      "learning_rate": 2.1362744261455755e-05,
      "loss": 0.0018,
      "step": 67120
    },
    {
      "epoch": 5.7283044628381266,
      "grad_norm": 0.09536874294281006,
      "learning_rate": 2.135847768580937e-05,
      "loss": 0.0015,
      "step": 67130
    },
    {
      "epoch": 5.729157777967403,
      "grad_norm": 0.03671100363135338,
      "learning_rate": 2.1354211110162984e-05,
      "loss": 0.002,
      "step": 67140
    },
    {
      "epoch": 5.730011093096681,
      "grad_norm": 0.029823124408721924,
      "learning_rate": 2.1349944534516598e-05,
      "loss": 0.0018,
      "step": 67150
    },
    {
      "epoch": 5.730864408225958,
      "grad_norm": 0.030164729803800583,
      "learning_rate": 2.1345677958870212e-05,
      "loss": 0.0018,
      "step": 67160
    },
    {
      "epoch": 5.731717723355235,
      "grad_norm": 0.049089886248111725,
      "learning_rate": 2.1341411383223827e-05,
      "loss": 0.0017,
      "step": 67170
    },
    {
      "epoch": 5.7325710384845125,
      "grad_norm": 0.20666608214378357,
      "learning_rate": 2.1337144807577437e-05,
      "loss": 0.0016,
      "step": 67180
    },
    {
      "epoch": 5.733424353613789,
      "grad_norm": 0.18530942499637604,
      "learning_rate": 2.133287823193105e-05,
      "loss": 0.0018,
      "step": 67190
    },
    {
      "epoch": 5.734277668743067,
      "grad_norm": 0.05985584482550621,
      "learning_rate": 2.1328611656284666e-05,
      "loss": 0.0018,
      "step": 67200
    },
    {
      "epoch": 5.735130983872344,
      "grad_norm": 0.058837756514549255,
      "learning_rate": 2.132434508063828e-05,
      "loss": 0.0016,
      "step": 67210
    },
    {
      "epoch": 5.735984299001621,
      "grad_norm": 0.22340480983257294,
      "learning_rate": 2.1320078504991894e-05,
      "loss": 0.0016,
      "step": 67220
    },
    {
      "epoch": 5.7368376141308985,
      "grad_norm": 0.34515050053596497,
      "learning_rate": 2.131581192934551e-05,
      "loss": 0.0024,
      "step": 67230
    },
    {
      "epoch": 5.737690929260176,
      "grad_norm": 0.15144823491573334,
      "learning_rate": 2.1311545353699123e-05,
      "loss": 0.0023,
      "step": 67240
    },
    {
      "epoch": 5.738544244389453,
      "grad_norm": 0.059467613697052,
      "learning_rate": 2.1307278778052737e-05,
      "loss": 0.0019,
      "step": 67250
    },
    {
      "epoch": 5.73939755951873,
      "grad_norm": 0.29352226853370667,
      "learning_rate": 2.130301220240635e-05,
      "loss": 0.002,
      "step": 67260
    },
    {
      "epoch": 5.740250874648008,
      "grad_norm": 0.3785659074783325,
      "learning_rate": 2.1298745626759962e-05,
      "loss": 0.0016,
      "step": 67270
    },
    {
      "epoch": 5.7411041897772845,
      "grad_norm": 0.09575065225362778,
      "learning_rate": 2.1294479051113576e-05,
      "loss": 0.0019,
      "step": 67280
    },
    {
      "epoch": 5.741957504906562,
      "grad_norm": 0.1379569172859192,
      "learning_rate": 2.129021247546719e-05,
      "loss": 0.0018,
      "step": 67290
    },
    {
      "epoch": 5.742810820035839,
      "grad_norm": 0.05270323529839516,
      "learning_rate": 2.1285945899820805e-05,
      "loss": 0.0024,
      "step": 67300
    },
    {
      "epoch": 5.743664135165116,
      "grad_norm": 0.15159408748149872,
      "learning_rate": 2.128167932417442e-05,
      "loss": 0.0021,
      "step": 67310
    },
    {
      "epoch": 5.744517450294394,
      "grad_norm": 0.27105557918548584,
      "learning_rate": 2.1277412748528033e-05,
      "loss": 0.0016,
      "step": 67320
    },
    {
      "epoch": 5.7453707654236705,
      "grad_norm": 0.0886266678571701,
      "learning_rate": 2.1273146172881648e-05,
      "loss": 0.0016,
      "step": 67330
    },
    {
      "epoch": 5.746224080552948,
      "grad_norm": 0.20355957746505737,
      "learning_rate": 2.1268879597235262e-05,
      "loss": 0.0024,
      "step": 67340
    },
    {
      "epoch": 5.747077395682226,
      "grad_norm": 0.4050660729408264,
      "learning_rate": 2.1264613021588876e-05,
      "loss": 0.0017,
      "step": 67350
    },
    {
      "epoch": 5.747930710811502,
      "grad_norm": 0.2230689525604248,
      "learning_rate": 2.126034644594249e-05,
      "loss": 0.0024,
      "step": 67360
    },
    {
      "epoch": 5.74878402594078,
      "grad_norm": 0.20360614359378815,
      "learning_rate": 2.12560798702961e-05,
      "loss": 0.002,
      "step": 67370
    },
    {
      "epoch": 5.749637341070057,
      "grad_norm": 0.16528968513011932,
      "learning_rate": 2.1251813294649715e-05,
      "loss": 0.0021,
      "step": 67380
    },
    {
      "epoch": 5.750490656199334,
      "grad_norm": 0.13062572479248047,
      "learning_rate": 2.1247546719003326e-05,
      "loss": 0.0012,
      "step": 67390
    },
    {
      "epoch": 5.751343971328612,
      "grad_norm": 0.07399369031190872,
      "learning_rate": 2.124328014335694e-05,
      "loss": 0.0023,
      "step": 67400
    },
    {
      "epoch": 5.752197286457889,
      "grad_norm": 0.23918263614177704,
      "learning_rate": 2.1239013567710555e-05,
      "loss": 0.0021,
      "step": 67410
    },
    {
      "epoch": 5.753050601587166,
      "grad_norm": 0.08396724611520767,
      "learning_rate": 2.123474699206417e-05,
      "loss": 0.002,
      "step": 67420
    },
    {
      "epoch": 5.753903916716443,
      "grad_norm": 0.11203583329916,
      "learning_rate": 2.1230480416417783e-05,
      "loss": 0.0016,
      "step": 67430
    },
    {
      "epoch": 5.754757231845721,
      "grad_norm": 0.10447517782449722,
      "learning_rate": 2.1226213840771398e-05,
      "loss": 0.0014,
      "step": 67440
    },
    {
      "epoch": 5.755610546974998,
      "grad_norm": 0.09368608146905899,
      "learning_rate": 2.1221947265125012e-05,
      "loss": 0.0021,
      "step": 67450
    },
    {
      "epoch": 5.756463862104275,
      "grad_norm": 0.18314561247825623,
      "learning_rate": 2.1217680689478626e-05,
      "loss": 0.0015,
      "step": 67460
    },
    {
      "epoch": 5.757317177233553,
      "grad_norm": 0.13393861055374146,
      "learning_rate": 2.121341411383224e-05,
      "loss": 0.0016,
      "step": 67470
    },
    {
      "epoch": 5.758170492362829,
      "grad_norm": 0.07871783524751663,
      "learning_rate": 2.1209147538185854e-05,
      "loss": 0.0017,
      "step": 67480
    },
    {
      "epoch": 5.759023807492107,
      "grad_norm": 0.09347223490476608,
      "learning_rate": 2.1204880962539465e-05,
      "loss": 0.0024,
      "step": 67490
    },
    {
      "epoch": 5.7598771226213845,
      "grad_norm": 0.27841606736183167,
      "learning_rate": 2.120061438689308e-05,
      "loss": 0.0017,
      "step": 67500
    },
    {
      "epoch": 5.760730437750661,
      "grad_norm": 0.3470858633518219,
      "learning_rate": 2.1196347811246694e-05,
      "loss": 0.0017,
      "step": 67510
    },
    {
      "epoch": 5.761583752879939,
      "grad_norm": 0.09438008815050125,
      "learning_rate": 2.1192081235600308e-05,
      "loss": 0.0018,
      "step": 67520
    },
    {
      "epoch": 5.762437068009216,
      "grad_norm": 0.25695186853408813,
      "learning_rate": 2.1187814659953922e-05,
      "loss": 0.002,
      "step": 67530
    },
    {
      "epoch": 5.763290383138493,
      "grad_norm": 0.13043296337127686,
      "learning_rate": 2.1183548084307537e-05,
      "loss": 0.0021,
      "step": 67540
    },
    {
      "epoch": 5.7641436982677705,
      "grad_norm": 0.04337294027209282,
      "learning_rate": 2.117928150866115e-05,
      "loss": 0.0022,
      "step": 67550
    },
    {
      "epoch": 5.764997013397047,
      "grad_norm": 0.11488230526447296,
      "learning_rate": 2.1175014933014765e-05,
      "loss": 0.0016,
      "step": 67560
    },
    {
      "epoch": 5.765850328526325,
      "grad_norm": 0.07865837961435318,
      "learning_rate": 2.117074835736838e-05,
      "loss": 0.0015,
      "step": 67570
    },
    {
      "epoch": 5.766703643655602,
      "grad_norm": 0.4276493787765503,
      "learning_rate": 2.116648178172199e-05,
      "loss": 0.0024,
      "step": 67580
    },
    {
      "epoch": 5.767556958784879,
      "grad_norm": 0.15102876722812653,
      "learning_rate": 2.1162215206075604e-05,
      "loss": 0.0016,
      "step": 67590
    },
    {
      "epoch": 5.7684102739141565,
      "grad_norm": 0.21963544189929962,
      "learning_rate": 2.115794863042922e-05,
      "loss": 0.002,
      "step": 67600
    },
    {
      "epoch": 5.769263589043434,
      "grad_norm": 0.26114246249198914,
      "learning_rate": 2.1153682054782833e-05,
      "loss": 0.0016,
      "step": 67610
    },
    {
      "epoch": 5.770116904172711,
      "grad_norm": 0.5008154511451721,
      "learning_rate": 2.1149415479136447e-05,
      "loss": 0.0015,
      "step": 67620
    },
    {
      "epoch": 5.770970219301988,
      "grad_norm": 0.14730383455753326,
      "learning_rate": 2.114514890349006e-05,
      "loss": 0.0018,
      "step": 67630
    },
    {
      "epoch": 5.771823534431266,
      "grad_norm": 0.1486147940158844,
      "learning_rate": 2.1140882327843672e-05,
      "loss": 0.0021,
      "step": 67640
    },
    {
      "epoch": 5.7726768495605425,
      "grad_norm": 0.2829369008541107,
      "learning_rate": 2.1136615752197286e-05,
      "loss": 0.0024,
      "step": 67650
    },
    {
      "epoch": 5.77353016468982,
      "grad_norm": 0.08021342009305954,
      "learning_rate": 2.11323491765509e-05,
      "loss": 0.0017,
      "step": 67660
    },
    {
      "epoch": 5.774383479819097,
      "grad_norm": 0.07527167350053787,
      "learning_rate": 2.1128082600904515e-05,
      "loss": 0.0016,
      "step": 67670
    },
    {
      "epoch": 5.775236794948374,
      "grad_norm": 0.11324439942836761,
      "learning_rate": 2.112381602525813e-05,
      "loss": 0.002,
      "step": 67680
    },
    {
      "epoch": 5.776090110077652,
      "grad_norm": 0.44324570894241333,
      "learning_rate": 2.1119549449611743e-05,
      "loss": 0.0016,
      "step": 67690
    },
    {
      "epoch": 5.7769434252069285,
      "grad_norm": 0.14860323071479797,
      "learning_rate": 2.1115282873965354e-05,
      "loss": 0.0017,
      "step": 67700
    },
    {
      "epoch": 5.777796740336206,
      "grad_norm": 0.17149561643600464,
      "learning_rate": 2.111101629831897e-05,
      "loss": 0.0024,
      "step": 67710
    },
    {
      "epoch": 5.778650055465484,
      "grad_norm": 0.2859060764312744,
      "learning_rate": 2.1106749722672583e-05,
      "loss": 0.0014,
      "step": 67720
    },
    {
      "epoch": 5.77950337059476,
      "grad_norm": 0.20125415921211243,
      "learning_rate": 2.1102483147026197e-05,
      "loss": 0.002,
      "step": 67730
    },
    {
      "epoch": 5.780356685724038,
      "grad_norm": 0.14795410633087158,
      "learning_rate": 2.109821657137981e-05,
      "loss": 0.0019,
      "step": 67740
    },
    {
      "epoch": 5.781210000853315,
      "grad_norm": 0.06625641137361526,
      "learning_rate": 2.1093949995733425e-05,
      "loss": 0.0019,
      "step": 67750
    },
    {
      "epoch": 5.782063315982592,
      "grad_norm": 0.10126148909330368,
      "learning_rate": 2.108968342008704e-05,
      "loss": 0.0017,
      "step": 67760
    },
    {
      "epoch": 5.78291663111187,
      "grad_norm": 0.030138127505779266,
      "learning_rate": 2.1085416844440654e-05,
      "loss": 0.0019,
      "step": 67770
    },
    {
      "epoch": 5.783769946241147,
      "grad_norm": 0.06146839261054993,
      "learning_rate": 2.1081150268794268e-05,
      "loss": 0.0017,
      "step": 67780
    },
    {
      "epoch": 5.784623261370424,
      "grad_norm": 0.31012994050979614,
      "learning_rate": 2.1076883693147882e-05,
      "loss": 0.002,
      "step": 67790
    },
    {
      "epoch": 5.785476576499701,
      "grad_norm": 0.383184552192688,
      "learning_rate": 2.1072617117501493e-05,
      "loss": 0.0019,
      "step": 67800
    },
    {
      "epoch": 5.786329891628979,
      "grad_norm": 0.14233747124671936,
      "learning_rate": 2.1068350541855108e-05,
      "loss": 0.0023,
      "step": 67810
    },
    {
      "epoch": 5.787183206758256,
      "grad_norm": 0.058726854622364044,
      "learning_rate": 2.1064083966208722e-05,
      "loss": 0.0017,
      "step": 67820
    },
    {
      "epoch": 5.788036521887533,
      "grad_norm": 0.27947962284088135,
      "learning_rate": 2.1059817390562336e-05,
      "loss": 0.0017,
      "step": 67830
    },
    {
      "epoch": 5.788889837016811,
      "grad_norm": 0.13121049106121063,
      "learning_rate": 2.105555081491595e-05,
      "loss": 0.0014,
      "step": 67840
    },
    {
      "epoch": 5.789743152146087,
      "grad_norm": 0.21797500550746918,
      "learning_rate": 2.1051284239269564e-05,
      "loss": 0.0019,
      "step": 67850
    },
    {
      "epoch": 5.790596467275365,
      "grad_norm": 0.05926921218633652,
      "learning_rate": 2.104701766362318e-05,
      "loss": 0.0018,
      "step": 67860
    },
    {
      "epoch": 5.7914497824046425,
      "grad_norm": 0.033383745700120926,
      "learning_rate": 2.1042751087976793e-05,
      "loss": 0.002,
      "step": 67870
    },
    {
      "epoch": 5.792303097533919,
      "grad_norm": 0.047144073992967606,
      "learning_rate": 2.1038484512330407e-05,
      "loss": 0.0017,
      "step": 67880
    },
    {
      "epoch": 5.793156412663197,
      "grad_norm": 0.2387545108795166,
      "learning_rate": 2.103421793668402e-05,
      "loss": 0.0016,
      "step": 67890
    },
    {
      "epoch": 5.794009727792474,
      "grad_norm": 0.239665225148201,
      "learning_rate": 2.1029951361037632e-05,
      "loss": 0.0021,
      "step": 67900
    },
    {
      "epoch": 5.794863042921751,
      "grad_norm": 0.11026836931705475,
      "learning_rate": 2.1025684785391243e-05,
      "loss": 0.0021,
      "step": 67910
    },
    {
      "epoch": 5.7957163580510285,
      "grad_norm": 0.05838768184185028,
      "learning_rate": 2.1021418209744857e-05,
      "loss": 0.0017,
      "step": 67920
    },
    {
      "epoch": 5.796569673180305,
      "grad_norm": 0.05711144581437111,
      "learning_rate": 2.101715163409847e-05,
      "loss": 0.0017,
      "step": 67930
    },
    {
      "epoch": 5.797422988309583,
      "grad_norm": 0.20179297029972076,
      "learning_rate": 2.1012885058452086e-05,
      "loss": 0.0015,
      "step": 67940
    },
    {
      "epoch": 5.79827630343886,
      "grad_norm": 0.1492345780134201,
      "learning_rate": 2.10086184828057e-05,
      "loss": 0.0019,
      "step": 67950
    },
    {
      "epoch": 5.799129618568137,
      "grad_norm": 0.3312532305717468,
      "learning_rate": 2.1004351907159314e-05,
      "loss": 0.002,
      "step": 67960
    },
    {
      "epoch": 5.7999829336974145,
      "grad_norm": 0.018282881006598473,
      "learning_rate": 2.100008533151293e-05,
      "loss": 0.0018,
      "step": 67970
    },
    {
      "epoch": 5.800836248826692,
      "grad_norm": 0.034964535385370255,
      "learning_rate": 2.0995818755866543e-05,
      "loss": 0.0018,
      "step": 67980
    },
    {
      "epoch": 5.801689563955969,
      "grad_norm": 0.08534058928489685,
      "learning_rate": 2.0991552180220157e-05,
      "loss": 0.0022,
      "step": 67990
    },
    {
      "epoch": 5.802542879085246,
      "grad_norm": 0.31380996108055115,
      "learning_rate": 2.098728560457377e-05,
      "loss": 0.0015,
      "step": 68000
    },
    {
      "epoch": 5.803396194214524,
      "grad_norm": 0.2396301031112671,
      "learning_rate": 2.0983019028927382e-05,
      "loss": 0.0018,
      "step": 68010
    },
    {
      "epoch": 5.8042495093438005,
      "grad_norm": 0.21720759570598602,
      "learning_rate": 2.0978752453280996e-05,
      "loss": 0.0017,
      "step": 68020
    },
    {
      "epoch": 5.805102824473078,
      "grad_norm": 0.3190896809101105,
      "learning_rate": 2.097448587763461e-05,
      "loss": 0.0021,
      "step": 68030
    },
    {
      "epoch": 5.805956139602355,
      "grad_norm": 0.2752769887447357,
      "learning_rate": 2.0970219301988225e-05,
      "loss": 0.0019,
      "step": 68040
    },
    {
      "epoch": 5.806809454731632,
      "grad_norm": 0.043742142617702484,
      "learning_rate": 2.096595272634184e-05,
      "loss": 0.0017,
      "step": 68050
    },
    {
      "epoch": 5.80766276986091,
      "grad_norm": 0.07584857940673828,
      "learning_rate": 2.0961686150695453e-05,
      "loss": 0.002,
      "step": 68060
    },
    {
      "epoch": 5.8085160849901865,
      "grad_norm": 0.0784173533320427,
      "learning_rate": 2.0957419575049068e-05,
      "loss": 0.0015,
      "step": 68070
    },
    {
      "epoch": 5.809369400119464,
      "grad_norm": 0.24352574348449707,
      "learning_rate": 2.0953152999402682e-05,
      "loss": 0.0018,
      "step": 68080
    },
    {
      "epoch": 5.810222715248742,
      "grad_norm": 0.0644659698009491,
      "learning_rate": 2.0948886423756296e-05,
      "loss": 0.0013,
      "step": 68090
    },
    {
      "epoch": 5.811076030378018,
      "grad_norm": 0.16297045350074768,
      "learning_rate": 2.094461984810991e-05,
      "loss": 0.0018,
      "step": 68100
    },
    {
      "epoch": 5.811929345507296,
      "grad_norm": 0.041357193142175674,
      "learning_rate": 2.094035327246352e-05,
      "loss": 0.0019,
      "step": 68110
    },
    {
      "epoch": 5.812782660636573,
      "grad_norm": 0.39137911796569824,
      "learning_rate": 2.0936086696817135e-05,
      "loss": 0.0017,
      "step": 68120
    },
    {
      "epoch": 5.81363597576585,
      "grad_norm": 0.10773205757141113,
      "learning_rate": 2.093182012117075e-05,
      "loss": 0.0014,
      "step": 68130
    },
    {
      "epoch": 5.814489290895128,
      "grad_norm": 0.2592369318008423,
      "learning_rate": 2.0927553545524364e-05,
      "loss": 0.0022,
      "step": 68140
    },
    {
      "epoch": 5.815342606024405,
      "grad_norm": 0.062317363917827606,
      "learning_rate": 2.0923286969877978e-05,
      "loss": 0.0014,
      "step": 68150
    },
    {
      "epoch": 5.816195921153682,
      "grad_norm": 0.2373075783252716,
      "learning_rate": 2.0919020394231592e-05,
      "loss": 0.0013,
      "step": 68160
    },
    {
      "epoch": 5.817049236282959,
      "grad_norm": 0.2991025149822235,
      "learning_rate": 2.0914753818585203e-05,
      "loss": 0.0016,
      "step": 68170
    },
    {
      "epoch": 5.817902551412237,
      "grad_norm": 0.23821265995502472,
      "learning_rate": 2.0910487242938817e-05,
      "loss": 0.0019,
      "step": 68180
    },
    {
      "epoch": 5.8187558665415136,
      "grad_norm": 0.2914624512195587,
      "learning_rate": 2.0906220667292432e-05,
      "loss": 0.0023,
      "step": 68190
    },
    {
      "epoch": 5.819609181670791,
      "grad_norm": 0.06066374480724335,
      "learning_rate": 2.0901954091646046e-05,
      "loss": 0.0022,
      "step": 68200
    },
    {
      "epoch": 5.820462496800069,
      "grad_norm": 0.19902266561985016,
      "learning_rate": 2.089768751599966e-05,
      "loss": 0.0018,
      "step": 68210
    },
    {
      "epoch": 5.821315811929345,
      "grad_norm": 0.1294027715921402,
      "learning_rate": 2.089342094035327e-05,
      "loss": 0.0016,
      "step": 68220
    },
    {
      "epoch": 5.822169127058623,
      "grad_norm": 0.03555489704012871,
      "learning_rate": 2.0889154364706885e-05,
      "loss": 0.0017,
      "step": 68230
    },
    {
      "epoch": 5.8230224421879,
      "grad_norm": 0.11057654023170471,
      "learning_rate": 2.08848877890605e-05,
      "loss": 0.0017,
      "step": 68240
    },
    {
      "epoch": 5.823875757317177,
      "grad_norm": 0.29490700364112854,
      "learning_rate": 2.0880621213414114e-05,
      "loss": 0.0018,
      "step": 68250
    },
    {
      "epoch": 5.824729072446455,
      "grad_norm": 0.2395646870136261,
      "learning_rate": 2.0876354637767728e-05,
      "loss": 0.0022,
      "step": 68260
    },
    {
      "epoch": 5.825582387575732,
      "grad_norm": 0.29317325353622437,
      "learning_rate": 2.0872088062121342e-05,
      "loss": 0.0018,
      "step": 68270
    },
    {
      "epoch": 5.826435702705009,
      "grad_norm": 0.14786756038665771,
      "learning_rate": 2.0867821486474957e-05,
      "loss": 0.0015,
      "step": 68280
    },
    {
      "epoch": 5.827289017834286,
      "grad_norm": 0.18896152079105377,
      "learning_rate": 2.086355491082857e-05,
      "loss": 0.0018,
      "step": 68290
    },
    {
      "epoch": 5.828142332963563,
      "grad_norm": 0.16546587646007538,
      "learning_rate": 2.0859288335182185e-05,
      "loss": 0.0019,
      "step": 68300
    },
    {
      "epoch": 5.828995648092841,
      "grad_norm": 0.23848599195480347,
      "learning_rate": 2.08550217595358e-05,
      "loss": 0.0018,
      "step": 68310
    },
    {
      "epoch": 5.829848963222118,
      "grad_norm": 0.038209639489650726,
      "learning_rate": 2.085075518388941e-05,
      "loss": 0.0015,
      "step": 68320
    },
    {
      "epoch": 5.830702278351395,
      "grad_norm": 0.13048380613327026,
      "learning_rate": 2.0846488608243024e-05,
      "loss": 0.0022,
      "step": 68330
    },
    {
      "epoch": 5.831555593480672,
      "grad_norm": 0.4927009642124176,
      "learning_rate": 2.084222203259664e-05,
      "loss": 0.0017,
      "step": 68340
    },
    {
      "epoch": 5.83240890860995,
      "grad_norm": 0.09982025623321533,
      "learning_rate": 2.0837955456950253e-05,
      "loss": 0.0025,
      "step": 68350
    },
    {
      "epoch": 5.833262223739227,
      "grad_norm": 0.05078324303030968,
      "learning_rate": 2.0833688881303867e-05,
      "loss": 0.0019,
      "step": 68360
    },
    {
      "epoch": 5.834115538868504,
      "grad_norm": 0.19990646839141846,
      "learning_rate": 2.082942230565748e-05,
      "loss": 0.0015,
      "step": 68370
    },
    {
      "epoch": 5.834968853997782,
      "grad_norm": 0.27410972118377686,
      "learning_rate": 2.0825155730011096e-05,
      "loss": 0.0018,
      "step": 68380
    },
    {
      "epoch": 5.835822169127058,
      "grad_norm": 0.36077991127967834,
      "learning_rate": 2.082088915436471e-05,
      "loss": 0.0026,
      "step": 68390
    },
    {
      "epoch": 5.836675484256336,
      "grad_norm": 0.3940370976924896,
      "learning_rate": 2.0816622578718324e-05,
      "loss": 0.0013,
      "step": 68400
    },
    {
      "epoch": 5.837528799385613,
      "grad_norm": 0.0498136468231678,
      "learning_rate": 2.0812356003071938e-05,
      "loss": 0.0016,
      "step": 68410
    },
    {
      "epoch": 5.83838211451489,
      "grad_norm": 0.07698517292737961,
      "learning_rate": 2.080808942742555e-05,
      "loss": 0.0016,
      "step": 68420
    },
    {
      "epoch": 5.839235429644168,
      "grad_norm": 0.08032145351171494,
      "learning_rate": 2.0803822851779163e-05,
      "loss": 0.0018,
      "step": 68430
    },
    {
      "epoch": 5.840088744773444,
      "grad_norm": 0.20867182314395905,
      "learning_rate": 2.0799556276132774e-05,
      "loss": 0.0013,
      "step": 68440
    },
    {
      "epoch": 5.840942059902722,
      "grad_norm": 0.13087831437587738,
      "learning_rate": 2.079528970048639e-05,
      "loss": 0.0019,
      "step": 68450
    },
    {
      "epoch": 5.8417953750319995,
      "grad_norm": 0.07651593536138535,
      "learning_rate": 2.0791023124840003e-05,
      "loss": 0.0017,
      "step": 68460
    },
    {
      "epoch": 5.842648690161276,
      "grad_norm": 0.03808856010437012,
      "learning_rate": 2.0786756549193617e-05,
      "loss": 0.0017,
      "step": 68470
    },
    {
      "epoch": 5.843502005290554,
      "grad_norm": 0.4101729393005371,
      "learning_rate": 2.078248997354723e-05,
      "loss": 0.0015,
      "step": 68480
    },
    {
      "epoch": 5.844355320419831,
      "grad_norm": 0.4919019341468811,
      "learning_rate": 2.0778223397900845e-05,
      "loss": 0.0018,
      "step": 68490
    },
    {
      "epoch": 5.845208635549108,
      "grad_norm": 0.09447238594293594,
      "learning_rate": 2.077395682225446e-05,
      "loss": 0.0024,
      "step": 68500
    },
    {
      "epoch": 5.8460619506783855,
      "grad_norm": 0.3350588083267212,
      "learning_rate": 2.0769690246608074e-05,
      "loss": 0.0024,
      "step": 68510
    },
    {
      "epoch": 5.846915265807663,
      "grad_norm": 0.23207928240299225,
      "learning_rate": 2.0765423670961688e-05,
      "loss": 0.0022,
      "step": 68520
    },
    {
      "epoch": 5.84776858093694,
      "grad_norm": 0.11322453618049622,
      "learning_rate": 2.07611570953153e-05,
      "loss": 0.0015,
      "step": 68530
    },
    {
      "epoch": 5.848621896066217,
      "grad_norm": 0.028489692136645317,
      "learning_rate": 2.0756890519668913e-05,
      "loss": 0.0016,
      "step": 68540
    },
    {
      "epoch": 5.849475211195495,
      "grad_norm": 0.24399684369564056,
      "learning_rate": 2.0752623944022527e-05,
      "loss": 0.0018,
      "step": 68550
    },
    {
      "epoch": 5.8503285263247715,
      "grad_norm": 0.08001171052455902,
      "learning_rate": 2.0748357368376142e-05,
      "loss": 0.0016,
      "step": 68560
    },
    {
      "epoch": 5.851181841454049,
      "grad_norm": 0.1662822663784027,
      "learning_rate": 2.0744090792729756e-05,
      "loss": 0.0018,
      "step": 68570
    },
    {
      "epoch": 5.852035156583327,
      "grad_norm": 0.2347361296415329,
      "learning_rate": 2.073982421708337e-05,
      "loss": 0.0019,
      "step": 68580
    },
    {
      "epoch": 5.852888471712603,
      "grad_norm": 0.23917245864868164,
      "learning_rate": 2.0735557641436984e-05,
      "loss": 0.0013,
      "step": 68590
    },
    {
      "epoch": 5.853741786841881,
      "grad_norm": 0.027440158650279045,
      "learning_rate": 2.07312910657906e-05,
      "loss": 0.0023,
      "step": 68600
    },
    {
      "epoch": 5.854595101971158,
      "grad_norm": 0.048954322934150696,
      "learning_rate": 2.0727024490144213e-05,
      "loss": 0.0015,
      "step": 68610
    },
    {
      "epoch": 5.855448417100435,
      "grad_norm": 0.1716236174106598,
      "learning_rate": 2.0722757914497827e-05,
      "loss": 0.0018,
      "step": 68620
    },
    {
      "epoch": 5.856301732229713,
      "grad_norm": 0.09045363962650299,
      "learning_rate": 2.0718491338851438e-05,
      "loss": 0.002,
      "step": 68630
    },
    {
      "epoch": 5.85715504735899,
      "grad_norm": 0.12522707879543304,
      "learning_rate": 2.0714224763205052e-05,
      "loss": 0.0013,
      "step": 68640
    },
    {
      "epoch": 5.858008362488267,
      "grad_norm": 0.2581530511379242,
      "learning_rate": 2.0709958187558666e-05,
      "loss": 0.0021,
      "step": 68650
    },
    {
      "epoch": 5.858861677617544,
      "grad_norm": 0.2020644247531891,
      "learning_rate": 2.070569161191228e-05,
      "loss": 0.0016,
      "step": 68660
    },
    {
      "epoch": 5.859714992746821,
      "grad_norm": 0.2973538041114807,
      "learning_rate": 2.0701425036265895e-05,
      "loss": 0.0023,
      "step": 68670
    },
    {
      "epoch": 5.860568307876099,
      "grad_norm": 0.13376766443252563,
      "learning_rate": 2.069715846061951e-05,
      "loss": 0.002,
      "step": 68680
    },
    {
      "epoch": 5.861421623005376,
      "grad_norm": 0.030222004279494286,
      "learning_rate": 2.0692891884973123e-05,
      "loss": 0.0023,
      "step": 68690
    },
    {
      "epoch": 5.862274938134653,
      "grad_norm": 0.18706463277339935,
      "learning_rate": 2.0688625309326734e-05,
      "loss": 0.0017,
      "step": 68700
    },
    {
      "epoch": 5.86312825326393,
      "grad_norm": 0.18635615706443787,
      "learning_rate": 2.068435873368035e-05,
      "loss": 0.0019,
      "step": 68710
    },
    {
      "epoch": 5.863981568393208,
      "grad_norm": 0.1664304882287979,
      "learning_rate": 2.0680092158033963e-05,
      "loss": 0.0016,
      "step": 68720
    },
    {
      "epoch": 5.864834883522485,
      "grad_norm": 0.2689744234085083,
      "learning_rate": 2.0675825582387577e-05,
      "loss": 0.0017,
      "step": 68730
    },
    {
      "epoch": 5.865688198651762,
      "grad_norm": 0.1889830380678177,
      "learning_rate": 2.067155900674119e-05,
      "loss": 0.0018,
      "step": 68740
    },
    {
      "epoch": 5.86654151378104,
      "grad_norm": 0.19169136881828308,
      "learning_rate": 2.0667292431094802e-05,
      "loss": 0.0017,
      "step": 68750
    },
    {
      "epoch": 5.867394828910316,
      "grad_norm": 0.31375566124916077,
      "learning_rate": 2.0663025855448416e-05,
      "loss": 0.0023,
      "step": 68760
    },
    {
      "epoch": 5.868248144039594,
      "grad_norm": 0.17691892385482788,
      "learning_rate": 2.065875927980203e-05,
      "loss": 0.0017,
      "step": 68770
    },
    {
      "epoch": 5.869101459168871,
      "grad_norm": 0.030826617032289505,
      "learning_rate": 2.0654492704155645e-05,
      "loss": 0.0018,
      "step": 68780
    },
    {
      "epoch": 5.869954774298148,
      "grad_norm": 0.13552050292491913,
      "learning_rate": 2.065022612850926e-05,
      "loss": 0.002,
      "step": 68790
    },
    {
      "epoch": 5.870808089427426,
      "grad_norm": 0.1459241360425949,
      "learning_rate": 2.0645959552862873e-05,
      "loss": 0.0027,
      "step": 68800
    },
    {
      "epoch": 5.871661404556702,
      "grad_norm": 0.12975457310676575,
      "learning_rate": 2.0641692977216488e-05,
      "loss": 0.0029,
      "step": 68810
    },
    {
      "epoch": 5.87251471968598,
      "grad_norm": 0.0783335492014885,
      "learning_rate": 2.0637426401570102e-05,
      "loss": 0.0016,
      "step": 68820
    },
    {
      "epoch": 5.8733680348152575,
      "grad_norm": 0.29882627725601196,
      "learning_rate": 2.0633159825923716e-05,
      "loss": 0.0016,
      "step": 68830
    },
    {
      "epoch": 5.874221349944534,
      "grad_norm": 0.04576708748936653,
      "learning_rate": 2.0628893250277327e-05,
      "loss": 0.0022,
      "step": 68840
    },
    {
      "epoch": 5.875074665073812,
      "grad_norm": 0.12087180465459824,
      "learning_rate": 2.062462667463094e-05,
      "loss": 0.0017,
      "step": 68850
    },
    {
      "epoch": 5.875927980203089,
      "grad_norm": 0.047689031809568405,
      "learning_rate": 2.0620360098984555e-05,
      "loss": 0.0019,
      "step": 68860
    },
    {
      "epoch": 5.876781295332366,
      "grad_norm": 0.09405655413866043,
      "learning_rate": 2.061609352333817e-05,
      "loss": 0.0018,
      "step": 68870
    },
    {
      "epoch": 5.8776346104616435,
      "grad_norm": 0.029571956023573875,
      "learning_rate": 2.0611826947691784e-05,
      "loss": 0.0022,
      "step": 68880
    },
    {
      "epoch": 5.878487925590921,
      "grad_norm": 0.08246558159589767,
      "learning_rate": 2.0607560372045398e-05,
      "loss": 0.0015,
      "step": 68890
    },
    {
      "epoch": 5.879341240720198,
      "grad_norm": 0.3587963283061981,
      "learning_rate": 2.0603293796399012e-05,
      "loss": 0.002,
      "step": 68900
    },
    {
      "epoch": 5.880194555849475,
      "grad_norm": 0.24079133570194244,
      "learning_rate": 2.0599027220752627e-05,
      "loss": 0.0013,
      "step": 68910
    },
    {
      "epoch": 5.881047870978753,
      "grad_norm": 0.0768425315618515,
      "learning_rate": 2.059476064510624e-05,
      "loss": 0.0018,
      "step": 68920
    },
    {
      "epoch": 5.8819011861080295,
      "grad_norm": 0.20437221229076385,
      "learning_rate": 2.0590494069459855e-05,
      "loss": 0.0018,
      "step": 68930
    },
    {
      "epoch": 5.882754501237307,
      "grad_norm": 0.1981639266014099,
      "learning_rate": 2.0586227493813466e-05,
      "loss": 0.0016,
      "step": 68940
    },
    {
      "epoch": 5.883607816366585,
      "grad_norm": 0.2796500325202942,
      "learning_rate": 2.058196091816708e-05,
      "loss": 0.002,
      "step": 68950
    },
    {
      "epoch": 5.884461131495861,
      "grad_norm": 0.1124347448348999,
      "learning_rate": 2.057769434252069e-05,
      "loss": 0.0014,
      "step": 68960
    },
    {
      "epoch": 5.885314446625139,
      "grad_norm": 0.05664916709065437,
      "learning_rate": 2.0573427766874305e-05,
      "loss": 0.0014,
      "step": 68970
    },
    {
      "epoch": 5.886167761754416,
      "grad_norm": 0.11508359760046005,
      "learning_rate": 2.056916119122792e-05,
      "loss": 0.002,
      "step": 68980
    },
    {
      "epoch": 5.887021076883693,
      "grad_norm": 0.31165847182273865,
      "learning_rate": 2.0564894615581534e-05,
      "loss": 0.0015,
      "step": 68990
    },
    {
      "epoch": 5.887874392012971,
      "grad_norm": 0.2958727478981018,
      "learning_rate": 2.0560628039935148e-05,
      "loss": 0.0021,
      "step": 69000
    },
    {
      "epoch": 5.888727707142247,
      "grad_norm": 0.04037585109472275,
      "learning_rate": 2.0556361464288762e-05,
      "loss": 0.0018,
      "step": 69010
    },
    {
      "epoch": 5.889581022271525,
      "grad_norm": 0.05090413987636566,
      "learning_rate": 2.0552094888642376e-05,
      "loss": 0.0019,
      "step": 69020
    },
    {
      "epoch": 5.890434337400802,
      "grad_norm": 0.022980010136961937,
      "learning_rate": 2.054782831299599e-05,
      "loss": 0.0018,
      "step": 69030
    },
    {
      "epoch": 5.891287652530079,
      "grad_norm": 0.2377629280090332,
      "learning_rate": 2.0543561737349605e-05,
      "loss": 0.0019,
      "step": 69040
    },
    {
      "epoch": 5.892140967659357,
      "grad_norm": 0.06024372950196266,
      "learning_rate": 2.053929516170322e-05,
      "loss": 0.0021,
      "step": 69050
    },
    {
      "epoch": 5.892994282788634,
      "grad_norm": 0.09428441524505615,
      "learning_rate": 2.053502858605683e-05,
      "loss": 0.0021,
      "step": 69060
    },
    {
      "epoch": 5.893847597917911,
      "grad_norm": 0.18837584555149078,
      "learning_rate": 2.0530762010410444e-05,
      "loss": 0.002,
      "step": 69070
    },
    {
      "epoch": 5.894700913047188,
      "grad_norm": 0.08456145226955414,
      "learning_rate": 2.052649543476406e-05,
      "loss": 0.002,
      "step": 69080
    },
    {
      "epoch": 5.895554228176466,
      "grad_norm": 0.11274221539497375,
      "learning_rate": 2.0522228859117673e-05,
      "loss": 0.0019,
      "step": 69090
    },
    {
      "epoch": 5.896407543305743,
      "grad_norm": 0.047173842787742615,
      "learning_rate": 2.0517962283471287e-05,
      "loss": 0.0016,
      "step": 69100
    },
    {
      "epoch": 5.89726085843502,
      "grad_norm": 0.05276030674576759,
      "learning_rate": 2.05136957078249e-05,
      "loss": 0.0022,
      "step": 69110
    },
    {
      "epoch": 5.898114173564298,
      "grad_norm": 0.16411422193050385,
      "learning_rate": 2.0509429132178515e-05,
      "loss": 0.0014,
      "step": 69120
    },
    {
      "epoch": 5.898967488693574,
      "grad_norm": 0.2433422952890396,
      "learning_rate": 2.050516255653213e-05,
      "loss": 0.002,
      "step": 69130
    },
    {
      "epoch": 5.899820803822852,
      "grad_norm": 0.1126079335808754,
      "learning_rate": 2.0500895980885744e-05,
      "loss": 0.0019,
      "step": 69140
    },
    {
      "epoch": 5.900674118952129,
      "grad_norm": 0.22405476868152618,
      "learning_rate": 2.0496629405239355e-05,
      "loss": 0.0022,
      "step": 69150
    },
    {
      "epoch": 5.901527434081406,
      "grad_norm": 0.09621427953243256,
      "learning_rate": 2.049236282959297e-05,
      "loss": 0.0015,
      "step": 69160
    },
    {
      "epoch": 5.902380749210684,
      "grad_norm": 0.11669884622097015,
      "learning_rate": 2.0488096253946583e-05,
      "loss": 0.0015,
      "step": 69170
    },
    {
      "epoch": 5.90323406433996,
      "grad_norm": 0.21755053102970123,
      "learning_rate": 2.0483829678300198e-05,
      "loss": 0.0014,
      "step": 69180
    },
    {
      "epoch": 5.904087379469238,
      "grad_norm": 0.21762710809707642,
      "learning_rate": 2.0479563102653812e-05,
      "loss": 0.0016,
      "step": 69190
    },
    {
      "epoch": 5.9049406945985154,
      "grad_norm": 0.3614053428173065,
      "learning_rate": 2.0475296527007426e-05,
      "loss": 0.0019,
      "step": 69200
    },
    {
      "epoch": 5.905794009727792,
      "grad_norm": 0.08026853948831558,
      "learning_rate": 2.047102995136104e-05,
      "loss": 0.002,
      "step": 69210
    },
    {
      "epoch": 5.90664732485707,
      "grad_norm": 0.17051783204078674,
      "learning_rate": 2.0466763375714654e-05,
      "loss": 0.0015,
      "step": 69220
    },
    {
      "epoch": 5.907500639986347,
      "grad_norm": 0.09493643045425415,
      "learning_rate": 2.0462496800068265e-05,
      "loss": 0.0018,
      "step": 69230
    },
    {
      "epoch": 5.908353955115624,
      "grad_norm": 0.2753716707229614,
      "learning_rate": 2.045823022442188e-05,
      "loss": 0.0019,
      "step": 69240
    },
    {
      "epoch": 5.9092072702449014,
      "grad_norm": 0.2918483316898346,
      "learning_rate": 2.0453963648775494e-05,
      "loss": 0.0017,
      "step": 69250
    },
    {
      "epoch": 5.910060585374179,
      "grad_norm": 0.274224191904068,
      "learning_rate": 2.0449697073129108e-05,
      "loss": 0.0018,
      "step": 69260
    },
    {
      "epoch": 5.910913900503456,
      "grad_norm": 0.1507258266210556,
      "learning_rate": 2.044543049748272e-05,
      "loss": 0.0014,
      "step": 69270
    },
    {
      "epoch": 5.911767215632733,
      "grad_norm": 0.22530913352966309,
      "learning_rate": 2.0441163921836333e-05,
      "loss": 0.0015,
      "step": 69280
    },
    {
      "epoch": 5.912620530762011,
      "grad_norm": 0.31797125935554504,
      "learning_rate": 2.0436897346189947e-05,
      "loss": 0.0016,
      "step": 69290
    },
    {
      "epoch": 5.913473845891287,
      "grad_norm": 0.03545834496617317,
      "learning_rate": 2.043263077054356e-05,
      "loss": 0.002,
      "step": 69300
    },
    {
      "epoch": 5.914327161020565,
      "grad_norm": 0.0822632759809494,
      "learning_rate": 2.0428364194897176e-05,
      "loss": 0.0017,
      "step": 69310
    },
    {
      "epoch": 5.9151804761498425,
      "grad_norm": 0.18495437502861023,
      "learning_rate": 2.042409761925079e-05,
      "loss": 0.0018,
      "step": 69320
    },
    {
      "epoch": 5.916033791279119,
      "grad_norm": 0.24705541133880615,
      "learning_rate": 2.0419831043604404e-05,
      "loss": 0.0017,
      "step": 69330
    },
    {
      "epoch": 5.916887106408397,
      "grad_norm": 0.3308572769165039,
      "learning_rate": 2.041556446795802e-05,
      "loss": 0.0018,
      "step": 69340
    },
    {
      "epoch": 5.917740421537674,
      "grad_norm": 0.09416385740041733,
      "learning_rate": 2.0411297892311633e-05,
      "loss": 0.0019,
      "step": 69350
    },
    {
      "epoch": 5.918593736666951,
      "grad_norm": 0.07625209540128708,
      "learning_rate": 2.0407031316665247e-05,
      "loss": 0.0017,
      "step": 69360
    },
    {
      "epoch": 5.9194470517962285,
      "grad_norm": 0.04254694655537605,
      "learning_rate": 2.0402764741018858e-05,
      "loss": 0.0014,
      "step": 69370
    },
    {
      "epoch": 5.920300366925505,
      "grad_norm": 0.22364874184131622,
      "learning_rate": 2.0398498165372472e-05,
      "loss": 0.0019,
      "step": 69380
    },
    {
      "epoch": 5.921153682054783,
      "grad_norm": 0.20002052187919617,
      "learning_rate": 2.0394231589726086e-05,
      "loss": 0.0017,
      "step": 69390
    },
    {
      "epoch": 5.92200699718406,
      "grad_norm": 0.27708739042282104,
      "learning_rate": 2.03899650140797e-05,
      "loss": 0.0022,
      "step": 69400
    },
    {
      "epoch": 5.922860312313337,
      "grad_norm": 0.11620991677045822,
      "learning_rate": 2.0385698438433315e-05,
      "loss": 0.0013,
      "step": 69410
    },
    {
      "epoch": 5.9237136274426145,
      "grad_norm": 0.12960201501846313,
      "learning_rate": 2.038143186278693e-05,
      "loss": 0.0021,
      "step": 69420
    },
    {
      "epoch": 5.924566942571892,
      "grad_norm": 0.1674102246761322,
      "learning_rate": 2.0377165287140543e-05,
      "loss": 0.0018,
      "step": 69430
    },
    {
      "epoch": 5.925420257701169,
      "grad_norm": 0.11001037806272507,
      "learning_rate": 2.0372898711494158e-05,
      "loss": 0.0019,
      "step": 69440
    },
    {
      "epoch": 5.926273572830446,
      "grad_norm": 0.06153501197695732,
      "learning_rate": 2.0368632135847772e-05,
      "loss": 0.0022,
      "step": 69450
    },
    {
      "epoch": 5.927126887959724,
      "grad_norm": 0.16280922293663025,
      "learning_rate": 2.0364365560201383e-05,
      "loss": 0.0021,
      "step": 69460
    },
    {
      "epoch": 5.9279802030890005,
      "grad_norm": 0.23801201581954956,
      "learning_rate": 2.0360098984554997e-05,
      "loss": 0.0018,
      "step": 69470
    },
    {
      "epoch": 5.928833518218278,
      "grad_norm": 0.11717092245817184,
      "learning_rate": 2.035583240890861e-05,
      "loss": 0.002,
      "step": 69480
    },
    {
      "epoch": 5.929686833347555,
      "grad_norm": 0.05223112553358078,
      "learning_rate": 2.0351565833262225e-05,
      "loss": 0.0018,
      "step": 69490
    },
    {
      "epoch": 5.930540148476832,
      "grad_norm": 0.3858650028705597,
      "learning_rate": 2.0347299257615836e-05,
      "loss": 0.0016,
      "step": 69500
    },
    {
      "epoch": 5.93139346360611,
      "grad_norm": 0.38163331151008606,
      "learning_rate": 2.034303268196945e-05,
      "loss": 0.0018,
      "step": 69510
    },
    {
      "epoch": 5.9322467787353865,
      "grad_norm": 0.11025914549827576,
      "learning_rate": 2.0338766106323065e-05,
      "loss": 0.0015,
      "step": 69520
    },
    {
      "epoch": 5.933100093864664,
      "grad_norm": 0.3430332541465759,
      "learning_rate": 2.033449953067668e-05,
      "loss": 0.0022,
      "step": 69530
    },
    {
      "epoch": 5.933953408993942,
      "grad_norm": 0.09841234982013702,
      "learning_rate": 2.0330232955030293e-05,
      "loss": 0.0025,
      "step": 69540
    },
    {
      "epoch": 5.934806724123218,
      "grad_norm": 0.2809486389160156,
      "learning_rate": 2.0325966379383908e-05,
      "loss": 0.0017,
      "step": 69550
    },
    {
      "epoch": 5.935660039252496,
      "grad_norm": 0.2944636940956116,
      "learning_rate": 2.0321699803737522e-05,
      "loss": 0.0018,
      "step": 69560
    },
    {
      "epoch": 5.936513354381773,
      "grad_norm": 0.20692680776119232,
      "learning_rate": 2.0317433228091136e-05,
      "loss": 0.002,
      "step": 69570
    },
    {
      "epoch": 5.93736666951105,
      "grad_norm": 0.11491597443819046,
      "learning_rate": 2.0313166652444747e-05,
      "loss": 0.0016,
      "step": 69580
    },
    {
      "epoch": 5.938219984640328,
      "grad_norm": 0.1315213441848755,
      "learning_rate": 2.030890007679836e-05,
      "loss": 0.0014,
      "step": 69590
    },
    {
      "epoch": 5.939073299769605,
      "grad_norm": 0.2096267193555832,
      "learning_rate": 2.0304633501151975e-05,
      "loss": 0.0014,
      "step": 69600
    },
    {
      "epoch": 5.939926614898882,
      "grad_norm": 0.04605657234787941,
      "learning_rate": 2.030036692550559e-05,
      "loss": 0.0019,
      "step": 69610
    },
    {
      "epoch": 5.940779930028159,
      "grad_norm": 0.16807468235492706,
      "learning_rate": 2.0296100349859204e-05,
      "loss": 0.0021,
      "step": 69620
    },
    {
      "epoch": 5.941633245157437,
      "grad_norm": 0.1266888678073883,
      "learning_rate": 2.0291833774212818e-05,
      "loss": 0.0014,
      "step": 69630
    },
    {
      "epoch": 5.942486560286714,
      "grad_norm": 0.0797853171825409,
      "learning_rate": 2.0287567198566432e-05,
      "loss": 0.0017,
      "step": 69640
    },
    {
      "epoch": 5.943339875415991,
      "grad_norm": 0.1841365247964859,
      "learning_rate": 2.0283300622920047e-05,
      "loss": 0.0015,
      "step": 69650
    },
    {
      "epoch": 5.944193190545269,
      "grad_norm": 0.14850527048110962,
      "learning_rate": 2.027903404727366e-05,
      "loss": 0.0019,
      "step": 69660
    },
    {
      "epoch": 5.945046505674545,
      "grad_norm": 0.07826148718595505,
      "learning_rate": 2.0274767471627275e-05,
      "loss": 0.0017,
      "step": 69670
    },
    {
      "epoch": 5.945899820803823,
      "grad_norm": 0.0629526823759079,
      "learning_rate": 2.0270500895980886e-05,
      "loss": 0.002,
      "step": 69680
    },
    {
      "epoch": 5.9467531359331005,
      "grad_norm": 0.4048381745815277,
      "learning_rate": 2.02662343203345e-05,
      "loss": 0.0017,
      "step": 69690
    },
    {
      "epoch": 5.947606451062377,
      "grad_norm": 0.17971624433994293,
      "learning_rate": 2.0261967744688114e-05,
      "loss": 0.0017,
      "step": 69700
    },
    {
      "epoch": 5.948459766191655,
      "grad_norm": 0.13085518777370453,
      "learning_rate": 2.025770116904173e-05,
      "loss": 0.0013,
      "step": 69710
    },
    {
      "epoch": 5.949313081320932,
      "grad_norm": 0.16856063902378082,
      "learning_rate": 2.0253434593395343e-05,
      "loss": 0.0015,
      "step": 69720
    },
    {
      "epoch": 5.950166396450209,
      "grad_norm": 0.20236220955848694,
      "learning_rate": 2.0249168017748957e-05,
      "loss": 0.0018,
      "step": 69730
    },
    {
      "epoch": 5.9510197115794865,
      "grad_norm": 0.13375523686408997,
      "learning_rate": 2.024490144210257e-05,
      "loss": 0.0021,
      "step": 69740
    },
    {
      "epoch": 5.951873026708763,
      "grad_norm": 0.29691773653030396,
      "learning_rate": 2.0240634866456186e-05,
      "loss": 0.0015,
      "step": 69750
    },
    {
      "epoch": 5.952726341838041,
      "grad_norm": 0.049729641526937485,
      "learning_rate": 2.0236368290809796e-05,
      "loss": 0.0014,
      "step": 69760
    },
    {
      "epoch": 5.953579656967318,
      "grad_norm": 0.11235884577035904,
      "learning_rate": 2.023210171516341e-05,
      "loss": 0.0024,
      "step": 69770
    },
    {
      "epoch": 5.954432972096595,
      "grad_norm": 0.18479952216148376,
      "learning_rate": 2.0227835139517025e-05,
      "loss": 0.0017,
      "step": 69780
    },
    {
      "epoch": 5.9552862872258725,
      "grad_norm": 0.16567875444889069,
      "learning_rate": 2.0223568563870636e-05,
      "loss": 0.002,
      "step": 69790
    },
    {
      "epoch": 5.95613960235515,
      "grad_norm": 0.5305679440498352,
      "learning_rate": 2.021930198822425e-05,
      "loss": 0.0018,
      "step": 69800
    },
    {
      "epoch": 5.956992917484427,
      "grad_norm": 0.32908111810684204,
      "learning_rate": 2.0215035412577864e-05,
      "loss": 0.0021,
      "step": 69810
    },
    {
      "epoch": 5.957846232613704,
      "grad_norm": 0.04329521581530571,
      "learning_rate": 2.021076883693148e-05,
      "loss": 0.0019,
      "step": 69820
    },
    {
      "epoch": 5.958699547742982,
      "grad_norm": 0.184864342212677,
      "learning_rate": 2.0206502261285093e-05,
      "loss": 0.0018,
      "step": 69830
    },
    {
      "epoch": 5.9595528628722585,
      "grad_norm": 0.22527630627155304,
      "learning_rate": 2.0202235685638707e-05,
      "loss": 0.0017,
      "step": 69840
    },
    {
      "epoch": 5.960406178001536,
      "grad_norm": 0.032295286655426025,
      "learning_rate": 2.019796910999232e-05,
      "loss": 0.0018,
      "step": 69850
    },
    {
      "epoch": 5.961259493130813,
      "grad_norm": 0.1866140216588974,
      "learning_rate": 2.0193702534345935e-05,
      "loss": 0.0015,
      "step": 69860
    },
    {
      "epoch": 5.96211280826009,
      "grad_norm": 0.3488863408565521,
      "learning_rate": 2.018943595869955e-05,
      "loss": 0.0021,
      "step": 69870
    },
    {
      "epoch": 5.962966123389368,
      "grad_norm": 0.03422834351658821,
      "learning_rate": 2.0185169383053164e-05,
      "loss": 0.0025,
      "step": 69880
    },
    {
      "epoch": 5.9638194385186445,
      "grad_norm": 0.03428817167878151,
      "learning_rate": 2.0180902807406775e-05,
      "loss": 0.002,
      "step": 69890
    },
    {
      "epoch": 5.964672753647922,
      "grad_norm": 0.2448430061340332,
      "learning_rate": 2.017663623176039e-05,
      "loss": 0.0021,
      "step": 69900
    },
    {
      "epoch": 5.9655260687772,
      "grad_norm": 0.10514643043279648,
      "learning_rate": 2.0172369656114003e-05,
      "loss": 0.0019,
      "step": 69910
    },
    {
      "epoch": 5.966379383906476,
      "grad_norm": 0.05521530285477638,
      "learning_rate": 2.0168103080467617e-05,
      "loss": 0.0019,
      "step": 69920
    },
    {
      "epoch": 5.967232699035754,
      "grad_norm": 0.042392343282699585,
      "learning_rate": 2.0163836504821232e-05,
      "loss": 0.002,
      "step": 69930
    },
    {
      "epoch": 5.968086014165031,
      "grad_norm": 0.4030337333679199,
      "learning_rate": 2.0159569929174846e-05,
      "loss": 0.0018,
      "step": 69940
    },
    {
      "epoch": 5.968939329294308,
      "grad_norm": 0.0323844738304615,
      "learning_rate": 2.015530335352846e-05,
      "loss": 0.002,
      "step": 69950
    },
    {
      "epoch": 5.969792644423586,
      "grad_norm": 0.11346082389354706,
      "learning_rate": 2.0151036777882074e-05,
      "loss": 0.0019,
      "step": 69960
    },
    {
      "epoch": 5.970645959552863,
      "grad_norm": 0.5464369654655457,
      "learning_rate": 2.014677020223569e-05,
      "loss": 0.0019,
      "step": 69970
    },
    {
      "epoch": 5.97149927468214,
      "grad_norm": 0.32175514101982117,
      "learning_rate": 2.0142503626589303e-05,
      "loss": 0.0022,
      "step": 69980
    },
    {
      "epoch": 5.972352589811417,
      "grad_norm": 0.14535893499851227,
      "learning_rate": 2.0138237050942914e-05,
      "loss": 0.002,
      "step": 69990
    },
    {
      "epoch": 5.973205904940695,
      "grad_norm": 0.08524034917354584,
      "learning_rate": 2.0133970475296528e-05,
      "loss": 0.0017,
      "step": 70000
    },
    {
      "epoch": 5.974059220069972,
      "grad_norm": 0.09426453709602356,
      "learning_rate": 2.0129703899650142e-05,
      "loss": 0.0015,
      "step": 70010
    },
    {
      "epoch": 5.974912535199249,
      "grad_norm": 0.0941433236002922,
      "learning_rate": 2.0125437324003757e-05,
      "loss": 0.0018,
      "step": 70020
    },
    {
      "epoch": 5.975765850328527,
      "grad_norm": 0.03613914176821709,
      "learning_rate": 2.0121170748357367e-05,
      "loss": 0.0018,
      "step": 70030
    },
    {
      "epoch": 5.976619165457803,
      "grad_norm": 0.1915721595287323,
      "learning_rate": 2.011690417271098e-05,
      "loss": 0.0016,
      "step": 70040
    },
    {
      "epoch": 5.977472480587081,
      "grad_norm": 0.15269197523593903,
      "learning_rate": 2.0112637597064596e-05,
      "loss": 0.0018,
      "step": 70050
    },
    {
      "epoch": 5.9783257957163585,
      "grad_norm": 0.15379251539707184,
      "learning_rate": 2.010837102141821e-05,
      "loss": 0.0017,
      "step": 70060
    },
    {
      "epoch": 5.979179110845635,
      "grad_norm": 0.3519626557826996,
      "learning_rate": 2.0104104445771824e-05,
      "loss": 0.0019,
      "step": 70070
    },
    {
      "epoch": 5.980032425974913,
      "grad_norm": 0.04549546539783478,
      "learning_rate": 2.009983787012544e-05,
      "loss": 0.0017,
      "step": 70080
    },
    {
      "epoch": 5.98088574110419,
      "grad_norm": 0.044821903109550476,
      "learning_rate": 2.0095571294479053e-05,
      "loss": 0.0019,
      "step": 70090
    },
    {
      "epoch": 5.981739056233467,
      "grad_norm": 0.11502997577190399,
      "learning_rate": 2.0091304718832664e-05,
      "loss": 0.0016,
      "step": 70100
    },
    {
      "epoch": 5.9825923713627445,
      "grad_norm": 0.13337093591690063,
      "learning_rate": 2.0087038143186278e-05,
      "loss": 0.0017,
      "step": 70110
    },
    {
      "epoch": 5.983445686492021,
      "grad_norm": 0.030865972861647606,
      "learning_rate": 2.0082771567539892e-05,
      "loss": 0.002,
      "step": 70120
    },
    {
      "epoch": 5.984299001621299,
      "grad_norm": 0.1650085598230362,
      "learning_rate": 2.0078504991893506e-05,
      "loss": 0.0016,
      "step": 70130
    },
    {
      "epoch": 5.985152316750576,
      "grad_norm": 0.1725795418024063,
      "learning_rate": 2.007423841624712e-05,
      "loss": 0.0019,
      "step": 70140
    },
    {
      "epoch": 5.986005631879853,
      "grad_norm": 0.16519129276275635,
      "learning_rate": 2.0069971840600735e-05,
      "loss": 0.0019,
      "step": 70150
    },
    {
      "epoch": 5.9868589470091305,
      "grad_norm": 0.28233808279037476,
      "learning_rate": 2.006570526495435e-05,
      "loss": 0.002,
      "step": 70160
    },
    {
      "epoch": 5.987712262138408,
      "grad_norm": 0.25246885418891907,
      "learning_rate": 2.0061438689307963e-05,
      "loss": 0.002,
      "step": 70170
    },
    {
      "epoch": 5.988565577267685,
      "grad_norm": 0.034054458141326904,
      "learning_rate": 2.0057172113661578e-05,
      "loss": 0.0024,
      "step": 70180
    },
    {
      "epoch": 5.989418892396962,
      "grad_norm": 0.04611629247665405,
      "learning_rate": 2.0052905538015192e-05,
      "loss": 0.0016,
      "step": 70190
    },
    {
      "epoch": 5.99027220752624,
      "grad_norm": 0.1295282542705536,
      "learning_rate": 2.0048638962368803e-05,
      "loss": 0.0015,
      "step": 70200
    },
    {
      "epoch": 5.9911255226555165,
      "grad_norm": 0.2595070004463196,
      "learning_rate": 2.0044372386722417e-05,
      "loss": 0.0015,
      "step": 70210
    },
    {
      "epoch": 5.991978837784794,
      "grad_norm": 0.1136678159236908,
      "learning_rate": 2.004010581107603e-05,
      "loss": 0.0016,
      "step": 70220
    },
    {
      "epoch": 5.992832152914071,
      "grad_norm": 0.22231225669384003,
      "learning_rate": 2.0035839235429645e-05,
      "loss": 0.0019,
      "step": 70230
    },
    {
      "epoch": 5.993685468043348,
      "grad_norm": 0.20293502509593964,
      "learning_rate": 2.003157265978326e-05,
      "loss": 0.0016,
      "step": 70240
    },
    {
      "epoch": 5.994538783172626,
      "grad_norm": 0.23750056326389313,
      "learning_rate": 2.0027306084136874e-05,
      "loss": 0.0018,
      "step": 70250
    },
    {
      "epoch": 5.9953920983019025,
      "grad_norm": 0.09245026856660843,
      "learning_rate": 2.0023039508490488e-05,
      "loss": 0.002,
      "step": 70260
    },
    {
      "epoch": 5.99624541343118,
      "grad_norm": 0.3312976658344269,
      "learning_rate": 2.0018772932844102e-05,
      "loss": 0.002,
      "step": 70270
    },
    {
      "epoch": 5.997098728560458,
      "grad_norm": 0.2028346210718155,
      "learning_rate": 2.0014506357197717e-05,
      "loss": 0.002,
      "step": 70280
    },
    {
      "epoch": 5.997952043689734,
      "grad_norm": 0.0674414113163948,
      "learning_rate": 2.0010239781551327e-05,
      "loss": 0.002,
      "step": 70290
    },
    {
      "epoch": 5.998805358819012,
      "grad_norm": 0.3299042582511902,
      "learning_rate": 2.0005973205904942e-05,
      "loss": 0.0023,
      "step": 70300
    },
    {
      "epoch": 5.999658673948289,
      "grad_norm": 0.23831357061862946,
      "learning_rate": 2.0001706630258556e-05,
      "loss": 0.0021,
      "step": 70310
    },
    {
      "epoch": 6.0,
      "eval_loss": 0.0018245121464133263,
      "eval_runtime": 100.8093,
      "eval_samples_per_second": 1487.958,
      "eval_steps_per_second": 23.252,
      "step": 70314
    },
    {
      "epoch": 6.000511989077566,
      "grad_norm": 0.032219793647527695,
      "learning_rate": 1.9997440054612167e-05,
      "loss": 0.0014,
      "step": 70320
    },
    {
      "epoch": 6.0013653042068436,
      "grad_norm": 0.28854188323020935,
      "learning_rate": 1.999317347896578e-05,
      "loss": 0.0025,
      "step": 70330
    },
    {
      "epoch": 6.002218619336121,
      "grad_norm": 0.13179390132427216,
      "learning_rate": 1.9988906903319395e-05,
      "loss": 0.0015,
      "step": 70340
    },
    {
      "epoch": 6.003071934465398,
      "grad_norm": 0.10278695076704025,
      "learning_rate": 1.998464032767301e-05,
      "loss": 0.002,
      "step": 70350
    },
    {
      "epoch": 6.003925249594675,
      "grad_norm": 0.12786605954170227,
      "learning_rate": 1.9980373752026624e-05,
      "loss": 0.002,
      "step": 70360
    },
    {
      "epoch": 6.004778564723953,
      "grad_norm": 0.16653800010681152,
      "learning_rate": 1.9976107176380238e-05,
      "loss": 0.0015,
      "step": 70370
    },
    {
      "epoch": 6.0056318798532295,
      "grad_norm": 0.09481091052293777,
      "learning_rate": 1.9971840600733852e-05,
      "loss": 0.0013,
      "step": 70380
    },
    {
      "epoch": 6.006485194982507,
      "grad_norm": 0.06686746329069138,
      "learning_rate": 1.9967574025087466e-05,
      "loss": 0.0014,
      "step": 70390
    },
    {
      "epoch": 6.007338510111785,
      "grad_norm": 0.05959409102797508,
      "learning_rate": 1.996330744944108e-05,
      "loss": 0.0023,
      "step": 70400
    },
    {
      "epoch": 6.008191825241061,
      "grad_norm": 0.2573625445365906,
      "learning_rate": 1.995904087379469e-05,
      "loss": 0.0018,
      "step": 70410
    },
    {
      "epoch": 6.009045140370339,
      "grad_norm": 0.33291471004486084,
      "learning_rate": 1.9954774298148306e-05,
      "loss": 0.0025,
      "step": 70420
    },
    {
      "epoch": 6.009898455499616,
      "grad_norm": 0.2403840869665146,
      "learning_rate": 1.995050772250192e-05,
      "loss": 0.0016,
      "step": 70430
    },
    {
      "epoch": 6.010751770628893,
      "grad_norm": 0.3809216618537903,
      "learning_rate": 1.9946241146855534e-05,
      "loss": 0.0017,
      "step": 70440
    },
    {
      "epoch": 6.011605085758171,
      "grad_norm": 0.20606841146945953,
      "learning_rate": 1.994197457120915e-05,
      "loss": 0.0019,
      "step": 70450
    },
    {
      "epoch": 6.012458400887447,
      "grad_norm": 0.03388280048966408,
      "learning_rate": 1.9937707995562763e-05,
      "loss": 0.0016,
      "step": 70460
    },
    {
      "epoch": 6.013311716016725,
      "grad_norm": 0.16356471180915833,
      "learning_rate": 1.9933441419916377e-05,
      "loss": 0.0022,
      "step": 70470
    },
    {
      "epoch": 6.014165031146002,
      "grad_norm": 0.32121405005455017,
      "learning_rate": 1.992917484426999e-05,
      "loss": 0.0019,
      "step": 70480
    },
    {
      "epoch": 6.015018346275279,
      "grad_norm": 0.2875860333442688,
      "learning_rate": 1.9924908268623606e-05,
      "loss": 0.002,
      "step": 70490
    },
    {
      "epoch": 6.015871661404557,
      "grad_norm": 0.19562359154224396,
      "learning_rate": 1.992064169297722e-05,
      "loss": 0.0017,
      "step": 70500
    },
    {
      "epoch": 6.016724976533834,
      "grad_norm": 0.135776549577713,
      "learning_rate": 1.991637511733083e-05,
      "loss": 0.0018,
      "step": 70510
    },
    {
      "epoch": 6.017578291663111,
      "grad_norm": 0.052714522927999496,
      "learning_rate": 1.9912108541684445e-05,
      "loss": 0.0019,
      "step": 70520
    },
    {
      "epoch": 6.018431606792388,
      "grad_norm": 0.11224736273288727,
      "learning_rate": 1.990784196603806e-05,
      "loss": 0.002,
      "step": 70530
    },
    {
      "epoch": 6.019284921921666,
      "grad_norm": 0.061753060668706894,
      "learning_rate": 1.9903575390391673e-05,
      "loss": 0.0018,
      "step": 70540
    },
    {
      "epoch": 6.020138237050943,
      "grad_norm": 0.03793356940150261,
      "learning_rate": 1.9899308814745288e-05,
      "loss": 0.0024,
      "step": 70550
    },
    {
      "epoch": 6.02099155218022,
      "grad_norm": 0.1114327684044838,
      "learning_rate": 1.98950422390989e-05,
      "loss": 0.0013,
      "step": 70560
    },
    {
      "epoch": 6.021844867309498,
      "grad_norm": 0.31647104024887085,
      "learning_rate": 1.9890775663452513e-05,
      "loss": 0.0018,
      "step": 70570
    },
    {
      "epoch": 6.022698182438774,
      "grad_norm": 0.04237639158964157,
      "learning_rate": 1.9886509087806127e-05,
      "loss": 0.0013,
      "step": 70580
    },
    {
      "epoch": 6.023551497568052,
      "grad_norm": 0.22290021181106567,
      "learning_rate": 1.988224251215974e-05,
      "loss": 0.0022,
      "step": 70590
    },
    {
      "epoch": 6.0244048126973295,
      "grad_norm": 0.29267385601997375,
      "learning_rate": 1.9877975936513355e-05,
      "loss": 0.0016,
      "step": 70600
    },
    {
      "epoch": 6.025258127826606,
      "grad_norm": 0.20857304334640503,
      "learning_rate": 1.987370936086697e-05,
      "loss": 0.002,
      "step": 70610
    },
    {
      "epoch": 6.026111442955884,
      "grad_norm": 0.07206804305315018,
      "learning_rate": 1.9869442785220584e-05,
      "loss": 0.0015,
      "step": 70620
    },
    {
      "epoch": 6.02696475808516,
      "grad_norm": 0.09451884031295776,
      "learning_rate": 1.9865176209574195e-05,
      "loss": 0.0015,
      "step": 70630
    },
    {
      "epoch": 6.027818073214438,
      "grad_norm": 0.32770055532455444,
      "learning_rate": 1.986090963392781e-05,
      "loss": 0.0018,
      "step": 70640
    },
    {
      "epoch": 6.0286713883437155,
      "grad_norm": 0.07936733961105347,
      "learning_rate": 1.9856643058281423e-05,
      "loss": 0.0019,
      "step": 70650
    },
    {
      "epoch": 6.029524703472992,
      "grad_norm": 0.07486789673566818,
      "learning_rate": 1.9852376482635037e-05,
      "loss": 0.0022,
      "step": 70660
    },
    {
      "epoch": 6.03037801860227,
      "grad_norm": 0.07364355772733688,
      "learning_rate": 1.984810990698865e-05,
      "loss": 0.0016,
      "step": 70670
    },
    {
      "epoch": 6.031231333731547,
      "grad_norm": 0.3319396674633026,
      "learning_rate": 1.9843843331342266e-05,
      "loss": 0.0016,
      "step": 70680
    },
    {
      "epoch": 6.032084648860824,
      "grad_norm": 0.22129099071025848,
      "learning_rate": 1.983957675569588e-05,
      "loss": 0.0017,
      "step": 70690
    },
    {
      "epoch": 6.0329379639901015,
      "grad_norm": 0.23357516527175903,
      "learning_rate": 1.9835310180049494e-05,
      "loss": 0.0017,
      "step": 70700
    },
    {
      "epoch": 6.033791279119379,
      "grad_norm": 0.18501834571361542,
      "learning_rate": 1.983104360440311e-05,
      "loss": 0.0017,
      "step": 70710
    },
    {
      "epoch": 6.034644594248656,
      "grad_norm": 0.05185019224882126,
      "learning_rate": 1.982677702875672e-05,
      "loss": 0.0018,
      "step": 70720
    },
    {
      "epoch": 6.035497909377933,
      "grad_norm": 0.19062025845050812,
      "learning_rate": 1.9822510453110334e-05,
      "loss": 0.0019,
      "step": 70730
    },
    {
      "epoch": 6.036351224507211,
      "grad_norm": 0.05851701274514198,
      "learning_rate": 1.9818243877463948e-05,
      "loss": 0.0018,
      "step": 70740
    },
    {
      "epoch": 6.0372045396364875,
      "grad_norm": 0.20426717400550842,
      "learning_rate": 1.9813977301817562e-05,
      "loss": 0.002,
      "step": 70750
    },
    {
      "epoch": 6.038057854765765,
      "grad_norm": 0.22025835514068604,
      "learning_rate": 1.9809710726171176e-05,
      "loss": 0.0018,
      "step": 70760
    },
    {
      "epoch": 6.038911169895043,
      "grad_norm": 0.20274165272712708,
      "learning_rate": 1.980544415052479e-05,
      "loss": 0.0015,
      "step": 70770
    },
    {
      "epoch": 6.039764485024319,
      "grad_norm": 0.10043234378099442,
      "learning_rate": 1.9801177574878405e-05,
      "loss": 0.002,
      "step": 70780
    },
    {
      "epoch": 6.040617800153597,
      "grad_norm": 0.3201698064804077,
      "learning_rate": 1.979691099923202e-05,
      "loss": 0.0017,
      "step": 70790
    },
    {
      "epoch": 6.041471115282874,
      "grad_norm": 0.026848768815398216,
      "learning_rate": 1.9792644423585633e-05,
      "loss": 0.0025,
      "step": 70800
    },
    {
      "epoch": 6.042324430412151,
      "grad_norm": 0.1303117275238037,
      "learning_rate": 1.9788377847939248e-05,
      "loss": 0.0018,
      "step": 70810
    },
    {
      "epoch": 6.043177745541429,
      "grad_norm": 0.20596520602703094,
      "learning_rate": 1.978411127229286e-05,
      "loss": 0.0024,
      "step": 70820
    },
    {
      "epoch": 6.044031060670705,
      "grad_norm": 0.20233702659606934,
      "learning_rate": 1.9779844696646473e-05,
      "loss": 0.0013,
      "step": 70830
    },
    {
      "epoch": 6.044884375799983,
      "grad_norm": 0.06051268428564072,
      "learning_rate": 1.9775578121000084e-05,
      "loss": 0.0016,
      "step": 70840
    },
    {
      "epoch": 6.04573769092926,
      "grad_norm": 0.3483608663082123,
      "learning_rate": 1.9771311545353698e-05,
      "loss": 0.0014,
      "step": 70850
    },
    {
      "epoch": 6.046591006058537,
      "grad_norm": 0.08003802597522736,
      "learning_rate": 1.9767044969707312e-05,
      "loss": 0.0018,
      "step": 70860
    },
    {
      "epoch": 6.047444321187815,
      "grad_norm": 0.23813442885875702,
      "learning_rate": 1.9762778394060926e-05,
      "loss": 0.0018,
      "step": 70870
    },
    {
      "epoch": 6.048297636317092,
      "grad_norm": 0.06226718798279762,
      "learning_rate": 1.975851181841454e-05,
      "loss": 0.0017,
      "step": 70880
    },
    {
      "epoch": 6.049150951446369,
      "grad_norm": 0.17612047493457794,
      "learning_rate": 1.9754245242768155e-05,
      "loss": 0.0014,
      "step": 70890
    },
    {
      "epoch": 6.050004266575646,
      "grad_norm": 0.2558996379375458,
      "learning_rate": 1.974997866712177e-05,
      "loss": 0.0016,
      "step": 70900
    },
    {
      "epoch": 6.050857581704924,
      "grad_norm": 0.2859800159931183,
      "learning_rate": 1.9745712091475383e-05,
      "loss": 0.0022,
      "step": 70910
    },
    {
      "epoch": 6.051710896834201,
      "grad_norm": 0.1387942135334015,
      "learning_rate": 1.9741445515828998e-05,
      "loss": 0.0017,
      "step": 70920
    },
    {
      "epoch": 6.052564211963478,
      "grad_norm": 0.2537132203578949,
      "learning_rate": 1.9737178940182612e-05,
      "loss": 0.002,
      "step": 70930
    },
    {
      "epoch": 6.053417527092756,
      "grad_norm": 0.06798350065946579,
      "learning_rate": 1.9732912364536223e-05,
      "loss": 0.0019,
      "step": 70940
    },
    {
      "epoch": 6.054270842222032,
      "grad_norm": 0.2222003936767578,
      "learning_rate": 1.9728645788889837e-05,
      "loss": 0.0021,
      "step": 70950
    },
    {
      "epoch": 6.05512415735131,
      "grad_norm": 0.07763978838920593,
      "learning_rate": 1.972437921324345e-05,
      "loss": 0.0018,
      "step": 70960
    },
    {
      "epoch": 6.0559774724805875,
      "grad_norm": 0.19185064733028412,
      "learning_rate": 1.9720112637597065e-05,
      "loss": 0.002,
      "step": 70970
    },
    {
      "epoch": 6.056830787609864,
      "grad_norm": 0.08007414638996124,
      "learning_rate": 1.971584606195068e-05,
      "loss": 0.0017,
      "step": 70980
    },
    {
      "epoch": 6.057684102739142,
      "grad_norm": 0.10987978428602219,
      "learning_rate": 1.9711579486304294e-05,
      "loss": 0.0019,
      "step": 70990
    },
    {
      "epoch": 6.058537417868418,
      "grad_norm": 0.4210817515850067,
      "learning_rate": 1.9707312910657908e-05,
      "loss": 0.0014,
      "step": 71000
    },
    {
      "epoch": 6.059390732997696,
      "grad_norm": 0.11940934509038925,
      "learning_rate": 1.9703046335011522e-05,
      "loss": 0.0021,
      "step": 71010
    },
    {
      "epoch": 6.0602440481269735,
      "grad_norm": 0.1536143720149994,
      "learning_rate": 1.9698779759365137e-05,
      "loss": 0.0017,
      "step": 71020
    },
    {
      "epoch": 6.06109736325625,
      "grad_norm": 0.14517217874526978,
      "learning_rate": 1.9694513183718747e-05,
      "loss": 0.0018,
      "step": 71030
    },
    {
      "epoch": 6.061950678385528,
      "grad_norm": 0.20337586104869843,
      "learning_rate": 1.969024660807236e-05,
      "loss": 0.0017,
      "step": 71040
    },
    {
      "epoch": 6.062803993514805,
      "grad_norm": 0.31134986877441406,
      "learning_rate": 1.9685980032425976e-05,
      "loss": 0.0016,
      "step": 71050
    },
    {
      "epoch": 6.063657308644082,
      "grad_norm": 0.3999042510986328,
      "learning_rate": 1.968171345677959e-05,
      "loss": 0.0022,
      "step": 71060
    },
    {
      "epoch": 6.0645106237733595,
      "grad_norm": 0.2751155495643616,
      "learning_rate": 1.9677446881133204e-05,
      "loss": 0.0019,
      "step": 71070
    },
    {
      "epoch": 6.065363938902637,
      "grad_norm": 0.22058267891407013,
      "learning_rate": 1.967318030548682e-05,
      "loss": 0.0017,
      "step": 71080
    },
    {
      "epoch": 6.066217254031914,
      "grad_norm": 0.09666483104228973,
      "learning_rate": 1.966891372984043e-05,
      "loss": 0.0017,
      "step": 71090
    },
    {
      "epoch": 6.067070569161191,
      "grad_norm": 0.30956777930259705,
      "learning_rate": 1.9664647154194044e-05,
      "loss": 0.0016,
      "step": 71100
    },
    {
      "epoch": 6.067923884290469,
      "grad_norm": 0.07592596113681793,
      "learning_rate": 1.9660380578547658e-05,
      "loss": 0.0019,
      "step": 71110
    },
    {
      "epoch": 6.0687771994197455,
      "grad_norm": 0.05437061935663223,
      "learning_rate": 1.9656114002901272e-05,
      "loss": 0.0017,
      "step": 71120
    },
    {
      "epoch": 6.069630514549023,
      "grad_norm": 0.13371382653713226,
      "learning_rate": 1.9651847427254886e-05,
      "loss": 0.002,
      "step": 71130
    },
    {
      "epoch": 6.070483829678301,
      "grad_norm": 0.03131381794810295,
      "learning_rate": 1.96475808516085e-05,
      "loss": 0.0019,
      "step": 71140
    },
    {
      "epoch": 6.071337144807577,
      "grad_norm": 0.2381836622953415,
      "learning_rate": 1.964331427596211e-05,
      "loss": 0.002,
      "step": 71150
    },
    {
      "epoch": 6.072190459936855,
      "grad_norm": 0.34699007868766785,
      "learning_rate": 1.9639047700315726e-05,
      "loss": 0.0021,
      "step": 71160
    },
    {
      "epoch": 6.073043775066132,
      "grad_norm": 0.06360034644603729,
      "learning_rate": 1.963478112466934e-05,
      "loss": 0.0015,
      "step": 71170
    },
    {
      "epoch": 6.073897090195409,
      "grad_norm": 0.19234591722488403,
      "learning_rate": 1.9630514549022954e-05,
      "loss": 0.0017,
      "step": 71180
    },
    {
      "epoch": 6.074750405324687,
      "grad_norm": 0.1687522679567337,
      "learning_rate": 1.962624797337657e-05,
      "loss": 0.0019,
      "step": 71190
    },
    {
      "epoch": 6.075603720453963,
      "grad_norm": 0.09198258817195892,
      "learning_rate": 1.9621981397730183e-05,
      "loss": 0.0017,
      "step": 71200
    },
    {
      "epoch": 6.076457035583241,
      "grad_norm": 0.23598095774650574,
      "learning_rate": 1.9617714822083797e-05,
      "loss": 0.0022,
      "step": 71210
    },
    {
      "epoch": 6.077310350712518,
      "grad_norm": 0.3618603050708771,
      "learning_rate": 1.961344824643741e-05,
      "loss": 0.0016,
      "step": 71220
    },
    {
      "epoch": 6.078163665841795,
      "grad_norm": 0.10967633128166199,
      "learning_rate": 1.9609181670791025e-05,
      "loss": 0.0021,
      "step": 71230
    },
    {
      "epoch": 6.079016980971073,
      "grad_norm": 0.14959780871868134,
      "learning_rate": 1.960491509514464e-05,
      "loss": 0.0017,
      "step": 71240
    },
    {
      "epoch": 6.07987029610035,
      "grad_norm": 0.06759392470121384,
      "learning_rate": 1.960064851949825e-05,
      "loss": 0.002,
      "step": 71250
    },
    {
      "epoch": 6.080723611229627,
      "grad_norm": 0.055941078811883926,
      "learning_rate": 1.9596381943851865e-05,
      "loss": 0.0022,
      "step": 71260
    },
    {
      "epoch": 6.081576926358904,
      "grad_norm": 0.27537935972213745,
      "learning_rate": 1.959211536820548e-05,
      "loss": 0.0025,
      "step": 71270
    },
    {
      "epoch": 6.082430241488182,
      "grad_norm": 0.09250245988368988,
      "learning_rate": 1.9587848792559093e-05,
      "loss": 0.0019,
      "step": 71280
    },
    {
      "epoch": 6.083283556617459,
      "grad_norm": 0.2330198436975479,
      "learning_rate": 1.9583582216912708e-05,
      "loss": 0.0018,
      "step": 71290
    },
    {
      "epoch": 6.084136871746736,
      "grad_norm": 0.3275921046733856,
      "learning_rate": 1.9579315641266322e-05,
      "loss": 0.0016,
      "step": 71300
    },
    {
      "epoch": 6.084990186876014,
      "grad_norm": 0.1492907851934433,
      "learning_rate": 1.9575049065619936e-05,
      "loss": 0.0017,
      "step": 71310
    },
    {
      "epoch": 6.08584350200529,
      "grad_norm": 0.06187006086111069,
      "learning_rate": 1.957078248997355e-05,
      "loss": 0.0021,
      "step": 71320
    },
    {
      "epoch": 6.086696817134568,
      "grad_norm": 0.020118193700909615,
      "learning_rate": 1.9566515914327164e-05,
      "loss": 0.0016,
      "step": 71330
    },
    {
      "epoch": 6.0875501322638454,
      "grad_norm": 0.2684139013290405,
      "learning_rate": 1.956224933868078e-05,
      "loss": 0.0019,
      "step": 71340
    },
    {
      "epoch": 6.088403447393122,
      "grad_norm": 0.34700635075569153,
      "learning_rate": 1.955798276303439e-05,
      "loss": 0.0017,
      "step": 71350
    },
    {
      "epoch": 6.0892567625224,
      "grad_norm": 0.031192397698760033,
      "learning_rate": 1.9553716187388e-05,
      "loss": 0.0019,
      "step": 71360
    },
    {
      "epoch": 6.090110077651676,
      "grad_norm": 0.14695097506046295,
      "learning_rate": 1.9549449611741615e-05,
      "loss": 0.0016,
      "step": 71370
    },
    {
      "epoch": 6.090963392780954,
      "grad_norm": 0.11925975233316422,
      "learning_rate": 1.954518303609523e-05,
      "loss": 0.0019,
      "step": 71380
    },
    {
      "epoch": 6.091816707910231,
      "grad_norm": 0.09329407662153244,
      "learning_rate": 1.9540916460448843e-05,
      "loss": 0.0021,
      "step": 71390
    },
    {
      "epoch": 6.092670023039508,
      "grad_norm": 0.11244958639144897,
      "learning_rate": 1.9536649884802457e-05,
      "loss": 0.0016,
      "step": 71400
    },
    {
      "epoch": 6.093523338168786,
      "grad_norm": 0.27382510900497437,
      "learning_rate": 1.953238330915607e-05,
      "loss": 0.0016,
      "step": 71410
    },
    {
      "epoch": 6.094376653298063,
      "grad_norm": 0.2544648349285126,
      "learning_rate": 1.9528116733509686e-05,
      "loss": 0.0016,
      "step": 71420
    },
    {
      "epoch": 6.09522996842734,
      "grad_norm": 0.4045493006706238,
      "learning_rate": 1.95238501578633e-05,
      "loss": 0.0015,
      "step": 71430
    },
    {
      "epoch": 6.096083283556617,
      "grad_norm": 0.2564370036125183,
      "learning_rate": 1.9519583582216914e-05,
      "loss": 0.0016,
      "step": 71440
    },
    {
      "epoch": 6.096936598685895,
      "grad_norm": 0.2557932436466217,
      "learning_rate": 1.951531700657053e-05,
      "loss": 0.002,
      "step": 71450
    },
    {
      "epoch": 6.097789913815172,
      "grad_norm": 0.3476715385913849,
      "learning_rate": 1.951105043092414e-05,
      "loss": 0.0017,
      "step": 71460
    },
    {
      "epoch": 6.098643228944449,
      "grad_norm": 0.037085261195898056,
      "learning_rate": 1.9506783855277754e-05,
      "loss": 0.0015,
      "step": 71470
    },
    {
      "epoch": 6.099496544073727,
      "grad_norm": 0.5084823966026306,
      "learning_rate": 1.9502517279631368e-05,
      "loss": 0.0019,
      "step": 71480
    },
    {
      "epoch": 6.100349859203003,
      "grad_norm": 0.13121022284030914,
      "learning_rate": 1.9498250703984982e-05,
      "loss": 0.0019,
      "step": 71490
    },
    {
      "epoch": 6.101203174332281,
      "grad_norm": 0.05091758072376251,
      "learning_rate": 1.9493984128338596e-05,
      "loss": 0.002,
      "step": 71500
    },
    {
      "epoch": 6.1020564894615585,
      "grad_norm": 0.05988713353872299,
      "learning_rate": 1.948971755269221e-05,
      "loss": 0.0022,
      "step": 71510
    },
    {
      "epoch": 6.102909804590835,
      "grad_norm": 0.4797039031982422,
      "learning_rate": 1.9485450977045825e-05,
      "loss": 0.0015,
      "step": 71520
    },
    {
      "epoch": 6.103763119720113,
      "grad_norm": 0.3091980516910553,
      "learning_rate": 1.948118440139944e-05,
      "loss": 0.0018,
      "step": 71530
    },
    {
      "epoch": 6.10461643484939,
      "grad_norm": 0.03238585963845253,
      "learning_rate": 1.9476917825753053e-05,
      "loss": 0.002,
      "step": 71540
    },
    {
      "epoch": 6.105469749978667,
      "grad_norm": 0.2752092778682709,
      "learning_rate": 1.9472651250106668e-05,
      "loss": 0.0016,
      "step": 71550
    },
    {
      "epoch": 6.1063230651079445,
      "grad_norm": 0.07468540966510773,
      "learning_rate": 1.946838467446028e-05,
      "loss": 0.0017,
      "step": 71560
    },
    {
      "epoch": 6.107176380237221,
      "grad_norm": 0.21689680218696594,
      "learning_rate": 1.9464118098813893e-05,
      "loss": 0.0022,
      "step": 71570
    },
    {
      "epoch": 6.108029695366499,
      "grad_norm": 0.09339341521263123,
      "learning_rate": 1.9459851523167507e-05,
      "loss": 0.002,
      "step": 71580
    },
    {
      "epoch": 6.108883010495776,
      "grad_norm": 0.17065320909023285,
      "learning_rate": 1.945558494752112e-05,
      "loss": 0.002,
      "step": 71590
    },
    {
      "epoch": 6.109736325625053,
      "grad_norm": 0.07546189427375793,
      "learning_rate": 1.9451318371874735e-05,
      "loss": 0.0021,
      "step": 71600
    },
    {
      "epoch": 6.1105896407543305,
      "grad_norm": 0.09732242673635483,
      "learning_rate": 1.944705179622835e-05,
      "loss": 0.0017,
      "step": 71610
    },
    {
      "epoch": 6.111442955883608,
      "grad_norm": 0.15025752782821655,
      "learning_rate": 1.944278522058196e-05,
      "loss": 0.0018,
      "step": 71620
    },
    {
      "epoch": 6.112296271012885,
      "grad_norm": 0.14054717123508453,
      "learning_rate": 1.9438518644935575e-05,
      "loss": 0.0017,
      "step": 71630
    },
    {
      "epoch": 6.113149586142162,
      "grad_norm": 0.36743107438087463,
      "learning_rate": 1.943425206928919e-05,
      "loss": 0.0022,
      "step": 71640
    },
    {
      "epoch": 6.11400290127144,
      "grad_norm": 0.058337584137916565,
      "learning_rate": 1.9429985493642803e-05,
      "loss": 0.0015,
      "step": 71650
    },
    {
      "epoch": 6.1148562164007165,
      "grad_norm": 0.2742755711078644,
      "learning_rate": 1.9425718917996417e-05,
      "loss": 0.0017,
      "step": 71660
    },
    {
      "epoch": 6.115709531529994,
      "grad_norm": 0.15350791811943054,
      "learning_rate": 1.942145234235003e-05,
      "loss": 0.0017,
      "step": 71670
    },
    {
      "epoch": 6.116562846659272,
      "grad_norm": 0.29358959197998047,
      "learning_rate": 1.9417185766703643e-05,
      "loss": 0.0022,
      "step": 71680
    },
    {
      "epoch": 6.117416161788548,
      "grad_norm": 0.1472545564174652,
      "learning_rate": 1.9412919191057257e-05,
      "loss": 0.0016,
      "step": 71690
    },
    {
      "epoch": 6.118269476917826,
      "grad_norm": 0.07830794900655746,
      "learning_rate": 1.940865261541087e-05,
      "loss": 0.0023,
      "step": 71700
    },
    {
      "epoch": 6.119122792047103,
      "grad_norm": 0.22004905343055725,
      "learning_rate": 1.9404386039764485e-05,
      "loss": 0.0018,
      "step": 71710
    },
    {
      "epoch": 6.11997610717638,
      "grad_norm": 0.25944453477859497,
      "learning_rate": 1.94001194641181e-05,
      "loss": 0.0015,
      "step": 71720
    },
    {
      "epoch": 6.120829422305658,
      "grad_norm": 0.04978122562170029,
      "learning_rate": 1.9395852888471714e-05,
      "loss": 0.0014,
      "step": 71730
    },
    {
      "epoch": 6.121682737434934,
      "grad_norm": 0.1741666942834854,
      "learning_rate": 1.9391586312825328e-05,
      "loss": 0.0014,
      "step": 71740
    },
    {
      "epoch": 6.122536052564212,
      "grad_norm": 0.03033924289047718,
      "learning_rate": 1.9387319737178942e-05,
      "loss": 0.0017,
      "step": 71750
    },
    {
      "epoch": 6.123389367693489,
      "grad_norm": 0.31209421157836914,
      "learning_rate": 1.9383053161532557e-05,
      "loss": 0.0016,
      "step": 71760
    },
    {
      "epoch": 6.124242682822766,
      "grad_norm": 0.13163186609745026,
      "learning_rate": 1.9378786585886167e-05,
      "loss": 0.0019,
      "step": 71770
    },
    {
      "epoch": 6.125095997952044,
      "grad_norm": 0.3296135365962982,
      "learning_rate": 1.937452001023978e-05,
      "loss": 0.0012,
      "step": 71780
    },
    {
      "epoch": 6.125949313081321,
      "grad_norm": 0.22833970189094543,
      "learning_rate": 1.9370253434593396e-05,
      "loss": 0.0016,
      "step": 71790
    },
    {
      "epoch": 6.126802628210598,
      "grad_norm": 0.14286848902702332,
      "learning_rate": 1.936598685894701e-05,
      "loss": 0.0016,
      "step": 71800
    },
    {
      "epoch": 6.127655943339875,
      "grad_norm": 0.06238250061869621,
      "learning_rate": 1.9361720283300624e-05,
      "loss": 0.0018,
      "step": 71810
    },
    {
      "epoch": 6.128509258469153,
      "grad_norm": 0.06069958209991455,
      "learning_rate": 1.935745370765424e-05,
      "loss": 0.0018,
      "step": 71820
    },
    {
      "epoch": 6.12936257359843,
      "grad_norm": 0.11006870120763779,
      "learning_rate": 1.9353187132007853e-05,
      "loss": 0.0016,
      "step": 71830
    },
    {
      "epoch": 6.130215888727707,
      "grad_norm": 0.2412678748369217,
      "learning_rate": 1.9348920556361467e-05,
      "loss": 0.0016,
      "step": 71840
    },
    {
      "epoch": 6.131069203856985,
      "grad_norm": 0.03102799504995346,
      "learning_rate": 1.934465398071508e-05,
      "loss": 0.0016,
      "step": 71850
    },
    {
      "epoch": 6.131922518986261,
      "grad_norm": 0.07726114988327026,
      "learning_rate": 1.9340387405068696e-05,
      "loss": 0.002,
      "step": 71860
    },
    {
      "epoch": 6.132775834115539,
      "grad_norm": 0.32654523849487305,
      "learning_rate": 1.9336120829422306e-05,
      "loss": 0.0016,
      "step": 71870
    },
    {
      "epoch": 6.1336291492448165,
      "grad_norm": 0.08207555115222931,
      "learning_rate": 1.933185425377592e-05,
      "loss": 0.0018,
      "step": 71880
    },
    {
      "epoch": 6.134482464374093,
      "grad_norm": 0.044820550829172134,
      "learning_rate": 1.932758767812953e-05,
      "loss": 0.0016,
      "step": 71890
    },
    {
      "epoch": 6.135335779503371,
      "grad_norm": 0.03212442621588707,
      "learning_rate": 1.9323321102483146e-05,
      "loss": 0.0017,
      "step": 71900
    },
    {
      "epoch": 6.136189094632648,
      "grad_norm": 0.10937488824129105,
      "learning_rate": 1.931905452683676e-05,
      "loss": 0.0021,
      "step": 71910
    },
    {
      "epoch": 6.137042409761925,
      "grad_norm": 0.24112308025360107,
      "learning_rate": 1.9314787951190374e-05,
      "loss": 0.0015,
      "step": 71920
    },
    {
      "epoch": 6.1378957248912025,
      "grad_norm": 0.1344323605298996,
      "learning_rate": 1.931052137554399e-05,
      "loss": 0.002,
      "step": 71930
    },
    {
      "epoch": 6.138749040020479,
      "grad_norm": 0.20353010296821594,
      "learning_rate": 1.9306254799897603e-05,
      "loss": 0.002,
      "step": 71940
    },
    {
      "epoch": 6.139602355149757,
      "grad_norm": 0.16787631809711456,
      "learning_rate": 1.9301988224251217e-05,
      "loss": 0.0019,
      "step": 71950
    },
    {
      "epoch": 6.140455670279034,
      "grad_norm": 0.1474088430404663,
      "learning_rate": 1.929772164860483e-05,
      "loss": 0.0019,
      "step": 71960
    },
    {
      "epoch": 6.141308985408311,
      "grad_norm": 0.23573051393032074,
      "learning_rate": 1.9293455072958445e-05,
      "loss": 0.0016,
      "step": 71970
    },
    {
      "epoch": 6.1421623005375885,
      "grad_norm": 0.4778607487678528,
      "learning_rate": 1.9289188497312056e-05,
      "loss": 0.0018,
      "step": 71980
    },
    {
      "epoch": 6.143015615666866,
      "grad_norm": 0.22265540063381195,
      "learning_rate": 1.928492192166567e-05,
      "loss": 0.0017,
      "step": 71990
    },
    {
      "epoch": 6.143868930796143,
      "grad_norm": 0.2562025785446167,
      "learning_rate": 1.9280655346019285e-05,
      "loss": 0.0016,
      "step": 72000
    },
    {
      "epoch": 6.14472224592542,
      "grad_norm": 0.22478187084197998,
      "learning_rate": 1.92763887703729e-05,
      "loss": 0.0015,
      "step": 72010
    },
    {
      "epoch": 6.145575561054698,
      "grad_norm": 0.14959701895713806,
      "learning_rate": 1.9272122194726513e-05,
      "loss": 0.0018,
      "step": 72020
    },
    {
      "epoch": 6.1464288761839745,
      "grad_norm": 0.454419881105423,
      "learning_rate": 1.9267855619080127e-05,
      "loss": 0.0015,
      "step": 72030
    },
    {
      "epoch": 6.147282191313252,
      "grad_norm": 0.09441893547773361,
      "learning_rate": 1.9263589043433742e-05,
      "loss": 0.0016,
      "step": 72040
    },
    {
      "epoch": 6.14813550644253,
      "grad_norm": 0.26965203881263733,
      "learning_rate": 1.9259322467787356e-05,
      "loss": 0.0014,
      "step": 72050
    },
    {
      "epoch": 6.148988821571806,
      "grad_norm": 0.1823066622018814,
      "learning_rate": 1.925505589214097e-05,
      "loss": 0.002,
      "step": 72060
    },
    {
      "epoch": 6.149842136701084,
      "grad_norm": 0.3321834206581116,
      "learning_rate": 1.9250789316494584e-05,
      "loss": 0.0016,
      "step": 72070
    },
    {
      "epoch": 6.150695451830361,
      "grad_norm": 0.23972871899604797,
      "learning_rate": 1.9246522740848195e-05,
      "loss": 0.0017,
      "step": 72080
    },
    {
      "epoch": 6.151548766959638,
      "grad_norm": 0.12487854063510895,
      "learning_rate": 1.924225616520181e-05,
      "loss": 0.0017,
      "step": 72090
    },
    {
      "epoch": 6.152402082088916,
      "grad_norm": 0.07552133500576019,
      "learning_rate": 1.9237989589555424e-05,
      "loss": 0.0018,
      "step": 72100
    },
    {
      "epoch": 6.153255397218192,
      "grad_norm": 0.27333006262779236,
      "learning_rate": 1.9233723013909038e-05,
      "loss": 0.002,
      "step": 72110
    },
    {
      "epoch": 6.15410871234747,
      "grad_norm": 0.22037191689014435,
      "learning_rate": 1.9229456438262652e-05,
      "loss": 0.0017,
      "step": 72120
    },
    {
      "epoch": 6.154962027476747,
      "grad_norm": 0.07499399036169052,
      "learning_rate": 1.9225189862616266e-05,
      "loss": 0.0017,
      "step": 72130
    },
    {
      "epoch": 6.155815342606024,
      "grad_norm": 0.11080403625965118,
      "learning_rate": 1.922092328696988e-05,
      "loss": 0.0014,
      "step": 72140
    },
    {
      "epoch": 6.156668657735302,
      "grad_norm": 0.04396054893732071,
      "learning_rate": 1.921665671132349e-05,
      "loss": 0.0022,
      "step": 72150
    },
    {
      "epoch": 6.157521972864579,
      "grad_norm": 0.26827120780944824,
      "learning_rate": 1.9212390135677106e-05,
      "loss": 0.0013,
      "step": 72160
    },
    {
      "epoch": 6.158375287993856,
      "grad_norm": 0.36701077222824097,
      "learning_rate": 1.920812356003072e-05,
      "loss": 0.0016,
      "step": 72170
    },
    {
      "epoch": 6.159228603123133,
      "grad_norm": 0.06589716672897339,
      "learning_rate": 1.9203856984384334e-05,
      "loss": 0.0019,
      "step": 72180
    },
    {
      "epoch": 6.160081918252411,
      "grad_norm": 0.36479926109313965,
      "learning_rate": 1.919959040873795e-05,
      "loss": 0.0017,
      "step": 72190
    },
    {
      "epoch": 6.160935233381688,
      "grad_norm": 0.15870478749275208,
      "learning_rate": 1.919532383309156e-05,
      "loss": 0.0021,
      "step": 72200
    },
    {
      "epoch": 6.161788548510965,
      "grad_norm": 0.06543391942977905,
      "learning_rate": 1.9191057257445174e-05,
      "loss": 0.0017,
      "step": 72210
    },
    {
      "epoch": 6.162641863640243,
      "grad_norm": 0.1302705556154251,
      "learning_rate": 1.9186790681798788e-05,
      "loss": 0.002,
      "step": 72220
    },
    {
      "epoch": 6.163495178769519,
      "grad_norm": 0.11292233318090439,
      "learning_rate": 1.9182524106152402e-05,
      "loss": 0.0022,
      "step": 72230
    },
    {
      "epoch": 6.164348493898797,
      "grad_norm": 0.3175090551376343,
      "learning_rate": 1.9178257530506016e-05,
      "loss": 0.0019,
      "step": 72240
    },
    {
      "epoch": 6.1652018090280745,
      "grad_norm": 0.0765690952539444,
      "learning_rate": 1.917399095485963e-05,
      "loss": 0.0014,
      "step": 72250
    },
    {
      "epoch": 6.166055124157351,
      "grad_norm": 0.23743319511413574,
      "learning_rate": 1.9169724379213245e-05,
      "loss": 0.0019,
      "step": 72260
    },
    {
      "epoch": 6.166908439286629,
      "grad_norm": 0.14709767699241638,
      "learning_rate": 1.916545780356686e-05,
      "loss": 0.0018,
      "step": 72270
    },
    {
      "epoch": 6.167761754415906,
      "grad_norm": 0.23818324506282806,
      "learning_rate": 1.9161191227920473e-05,
      "loss": 0.0016,
      "step": 72280
    },
    {
      "epoch": 6.168615069545183,
      "grad_norm": 0.31056809425354004,
      "learning_rate": 1.9156924652274084e-05,
      "loss": 0.0014,
      "step": 72290
    },
    {
      "epoch": 6.1694683846744605,
      "grad_norm": 0.05801910534501076,
      "learning_rate": 1.91526580766277e-05,
      "loss": 0.0017,
      "step": 72300
    },
    {
      "epoch": 6.170321699803737,
      "grad_norm": 0.07673247903585434,
      "learning_rate": 1.9148391500981313e-05,
      "loss": 0.0014,
      "step": 72310
    },
    {
      "epoch": 6.171175014933015,
      "grad_norm": 0.06228270381689072,
      "learning_rate": 1.9144124925334927e-05,
      "loss": 0.0016,
      "step": 72320
    },
    {
      "epoch": 6.172028330062292,
      "grad_norm": 0.09521997720003128,
      "learning_rate": 1.913985834968854e-05,
      "loss": 0.0015,
      "step": 72330
    },
    {
      "epoch": 6.172881645191569,
      "grad_norm": 0.03508531302213669,
      "learning_rate": 1.9135591774042155e-05,
      "loss": 0.0016,
      "step": 72340
    },
    {
      "epoch": 6.1737349603208465,
      "grad_norm": 0.260187566280365,
      "learning_rate": 1.913132519839577e-05,
      "loss": 0.0016,
      "step": 72350
    },
    {
      "epoch": 6.174588275450124,
      "grad_norm": 0.0566241480410099,
      "learning_rate": 1.9127058622749384e-05,
      "loss": 0.0017,
      "step": 72360
    },
    {
      "epoch": 6.175441590579401,
      "grad_norm": 0.03160935640335083,
      "learning_rate": 1.9122792047102998e-05,
      "loss": 0.0019,
      "step": 72370
    },
    {
      "epoch": 6.176294905708678,
      "grad_norm": 0.07804500311613083,
      "learning_rate": 1.9118525471456612e-05,
      "loss": 0.0021,
      "step": 72380
    },
    {
      "epoch": 6.177148220837956,
      "grad_norm": 0.18301080167293549,
      "learning_rate": 1.9114258895810223e-05,
      "loss": 0.0019,
      "step": 72390
    },
    {
      "epoch": 6.1780015359672324,
      "grad_norm": 0.23925675451755524,
      "learning_rate": 1.9109992320163837e-05,
      "loss": 0.0022,
      "step": 72400
    },
    {
      "epoch": 6.17885485109651,
      "grad_norm": 0.18639422953128815,
      "learning_rate": 1.910572574451745e-05,
      "loss": 0.0015,
      "step": 72410
    },
    {
      "epoch": 6.179708166225788,
      "grad_norm": 0.07794518768787384,
      "learning_rate": 1.9101459168871063e-05,
      "loss": 0.0019,
      "step": 72420
    },
    {
      "epoch": 6.180561481355064,
      "grad_norm": 0.34890881180763245,
      "learning_rate": 1.9097192593224677e-05,
      "loss": 0.0019,
      "step": 72430
    },
    {
      "epoch": 6.181414796484342,
      "grad_norm": 0.15885768830776215,
      "learning_rate": 1.909292601757829e-05,
      "loss": 0.0017,
      "step": 72440
    },
    {
      "epoch": 6.182268111613619,
      "grad_norm": 0.12933722138404846,
      "learning_rate": 1.9088659441931905e-05,
      "loss": 0.0019,
      "step": 72450
    },
    {
      "epoch": 6.183121426742896,
      "grad_norm": 0.4596165120601654,
      "learning_rate": 1.908439286628552e-05,
      "loss": 0.0016,
      "step": 72460
    },
    {
      "epoch": 6.1839747418721736,
      "grad_norm": 0.02535463683307171,
      "learning_rate": 1.9080126290639134e-05,
      "loss": 0.0019,
      "step": 72470
    },
    {
      "epoch": 6.18482805700145,
      "grad_norm": 0.11054079234600067,
      "learning_rate": 1.9075859714992748e-05,
      "loss": 0.002,
      "step": 72480
    },
    {
      "epoch": 6.185681372130728,
      "grad_norm": 0.11132302135229111,
      "learning_rate": 1.9071593139346362e-05,
      "loss": 0.0017,
      "step": 72490
    },
    {
      "epoch": 6.186534687260005,
      "grad_norm": 0.3108846843242645,
      "learning_rate": 1.9067326563699976e-05,
      "loss": 0.0021,
      "step": 72500
    },
    {
      "epoch": 6.187388002389282,
      "grad_norm": 0.22215640544891357,
      "learning_rate": 1.9063059988053587e-05,
      "loss": 0.0021,
      "step": 72510
    },
    {
      "epoch": 6.1882413175185595,
      "grad_norm": 0.22008532285690308,
      "learning_rate": 1.90587934124072e-05,
      "loss": 0.0019,
      "step": 72520
    },
    {
      "epoch": 6.189094632647837,
      "grad_norm": 0.029079658910632133,
      "learning_rate": 1.9054526836760816e-05,
      "loss": 0.0016,
      "step": 72530
    },
    {
      "epoch": 6.189947947777114,
      "grad_norm": 0.367448091506958,
      "learning_rate": 1.905026026111443e-05,
      "loss": 0.0019,
      "step": 72540
    },
    {
      "epoch": 6.190801262906391,
      "grad_norm": 0.05139225348830223,
      "learning_rate": 1.9045993685468044e-05,
      "loss": 0.002,
      "step": 72550
    },
    {
      "epoch": 6.191654578035669,
      "grad_norm": 0.1509321630001068,
      "learning_rate": 1.904172710982166e-05,
      "loss": 0.0017,
      "step": 72560
    },
    {
      "epoch": 6.1925078931649455,
      "grad_norm": 0.11461205035448074,
      "learning_rate": 1.9037460534175273e-05,
      "loss": 0.0017,
      "step": 72570
    },
    {
      "epoch": 6.193361208294223,
      "grad_norm": 0.2532569169998169,
      "learning_rate": 1.9033193958528887e-05,
      "loss": 0.0016,
      "step": 72580
    },
    {
      "epoch": 6.194214523423501,
      "grad_norm": 0.12518440186977386,
      "learning_rate": 1.90289273828825e-05,
      "loss": 0.0019,
      "step": 72590
    },
    {
      "epoch": 6.195067838552777,
      "grad_norm": 0.09288202971220016,
      "learning_rate": 1.9024660807236112e-05,
      "loss": 0.002,
      "step": 72600
    },
    {
      "epoch": 6.195921153682055,
      "grad_norm": 0.042093876749277115,
      "learning_rate": 1.9020394231589726e-05,
      "loss": 0.0016,
      "step": 72610
    },
    {
      "epoch": 6.196774468811332,
      "grad_norm": 0.37315478920936584,
      "learning_rate": 1.901612765594334e-05,
      "loss": 0.0015,
      "step": 72620
    },
    {
      "epoch": 6.197627783940609,
      "grad_norm": 0.0840824767947197,
      "learning_rate": 1.9011861080296955e-05,
      "loss": 0.0017,
      "step": 72630
    },
    {
      "epoch": 6.198481099069887,
      "grad_norm": 0.09576176106929779,
      "learning_rate": 1.900759450465057e-05,
      "loss": 0.002,
      "step": 72640
    },
    {
      "epoch": 6.199334414199164,
      "grad_norm": 0.3124825358390808,
      "learning_rate": 1.9003327929004183e-05,
      "loss": 0.0015,
      "step": 72650
    },
    {
      "epoch": 6.200187729328441,
      "grad_norm": 0.1797856241464615,
      "learning_rate": 1.8999061353357798e-05,
      "loss": 0.0019,
      "step": 72660
    },
    {
      "epoch": 6.201041044457718,
      "grad_norm": 0.12341152131557465,
      "learning_rate": 1.8994794777711412e-05,
      "loss": 0.0019,
      "step": 72670
    },
    {
      "epoch": 6.201894359586995,
      "grad_norm": 0.26031115651130676,
      "learning_rate": 1.8990528202065023e-05,
      "loss": 0.0016,
      "step": 72680
    },
    {
      "epoch": 6.202747674716273,
      "grad_norm": 0.27205193042755127,
      "learning_rate": 1.8986261626418637e-05,
      "loss": 0.0021,
      "step": 72690
    },
    {
      "epoch": 6.20360098984555,
      "grad_norm": 0.30020803213119507,
      "learning_rate": 1.898199505077225e-05,
      "loss": 0.0017,
      "step": 72700
    },
    {
      "epoch": 6.204454304974827,
      "grad_norm": 0.32212167978286743,
      "learning_rate": 1.8977728475125865e-05,
      "loss": 0.0016,
      "step": 72710
    },
    {
      "epoch": 6.205307620104104,
      "grad_norm": 0.044929955154657364,
      "learning_rate": 1.8973461899479476e-05,
      "loss": 0.0017,
      "step": 72720
    },
    {
      "epoch": 6.206160935233382,
      "grad_norm": 0.21854253113269806,
      "learning_rate": 1.896919532383309e-05,
      "loss": 0.0023,
      "step": 72730
    },
    {
      "epoch": 6.207014250362659,
      "grad_norm": 0.07240232080221176,
      "learning_rate": 1.8964928748186705e-05,
      "loss": 0.0014,
      "step": 72740
    },
    {
      "epoch": 6.207867565491936,
      "grad_norm": 0.388007789850235,
      "learning_rate": 1.896066217254032e-05,
      "loss": 0.0016,
      "step": 72750
    },
    {
      "epoch": 6.208720880621214,
      "grad_norm": 0.09815137088298798,
      "learning_rate": 1.8956395596893933e-05,
      "loss": 0.0016,
      "step": 72760
    },
    {
      "epoch": 6.20957419575049,
      "grad_norm": 0.4079361855983734,
      "learning_rate": 1.8952129021247547e-05,
      "loss": 0.002,
      "step": 72770
    },
    {
      "epoch": 6.210427510879768,
      "grad_norm": 0.27461910247802734,
      "learning_rate": 1.894786244560116e-05,
      "loss": 0.0015,
      "step": 72780
    },
    {
      "epoch": 6.2112808260090455,
      "grad_norm": 0.06648817658424377,
      "learning_rate": 1.8943595869954776e-05,
      "loss": 0.0022,
      "step": 72790
    },
    {
      "epoch": 6.212134141138322,
      "grad_norm": 0.20099641382694244,
      "learning_rate": 1.893932929430839e-05,
      "loss": 0.0018,
      "step": 72800
    },
    {
      "epoch": 6.2129874562676,
      "grad_norm": 0.07430943846702576,
      "learning_rate": 1.8935062718662004e-05,
      "loss": 0.0019,
      "step": 72810
    },
    {
      "epoch": 6.213840771396877,
      "grad_norm": 0.23687788844108582,
      "learning_rate": 1.8930796143015615e-05,
      "loss": 0.0021,
      "step": 72820
    },
    {
      "epoch": 6.214694086526154,
      "grad_norm": 0.07618409395217896,
      "learning_rate": 1.892652956736923e-05,
      "loss": 0.0015,
      "step": 72830
    },
    {
      "epoch": 6.2155474016554315,
      "grad_norm": 0.18429496884346008,
      "learning_rate": 1.8922262991722844e-05,
      "loss": 0.0021,
      "step": 72840
    },
    {
      "epoch": 6.216400716784708,
      "grad_norm": 0.1411375105381012,
      "learning_rate": 1.8917996416076458e-05,
      "loss": 0.0024,
      "step": 72850
    },
    {
      "epoch": 6.217254031913986,
      "grad_norm": 0.16156810522079468,
      "learning_rate": 1.8913729840430072e-05,
      "loss": 0.0019,
      "step": 72860
    },
    {
      "epoch": 6.218107347043263,
      "grad_norm": 0.17119868099689484,
      "learning_rate": 1.8909463264783686e-05,
      "loss": 0.0016,
      "step": 72870
    },
    {
      "epoch": 6.21896066217254,
      "grad_norm": 0.12575753033161163,
      "learning_rate": 1.89051966891373e-05,
      "loss": 0.0016,
      "step": 72880
    },
    {
      "epoch": 6.2198139773018175,
      "grad_norm": 0.16426251828670502,
      "learning_rate": 1.8900930113490915e-05,
      "loss": 0.0015,
      "step": 72890
    },
    {
      "epoch": 6.220667292431095,
      "grad_norm": 0.15751761198043823,
      "learning_rate": 1.889666353784453e-05,
      "loss": 0.0016,
      "step": 72900
    },
    {
      "epoch": 6.221520607560372,
      "grad_norm": 0.04575217142701149,
      "learning_rate": 1.8892396962198143e-05,
      "loss": 0.0015,
      "step": 72910
    },
    {
      "epoch": 6.222373922689649,
      "grad_norm": 0.1314551681280136,
      "learning_rate": 1.8888130386551754e-05,
      "loss": 0.0017,
      "step": 72920
    },
    {
      "epoch": 6.223227237818927,
      "grad_norm": 0.17168788611888885,
      "learning_rate": 1.888386381090537e-05,
      "loss": 0.0014,
      "step": 72930
    },
    {
      "epoch": 6.2240805529482035,
      "grad_norm": 0.3851647675037384,
      "learning_rate": 1.8879597235258983e-05,
      "loss": 0.0018,
      "step": 72940
    },
    {
      "epoch": 6.224933868077481,
      "grad_norm": 0.18560752272605896,
      "learning_rate": 1.8875330659612594e-05,
      "loss": 0.0015,
      "step": 72950
    },
    {
      "epoch": 6.225787183206759,
      "grad_norm": 0.027352605015039444,
      "learning_rate": 1.8871064083966208e-05,
      "loss": 0.0018,
      "step": 72960
    },
    {
      "epoch": 6.226640498336035,
      "grad_norm": 0.20211583375930786,
      "learning_rate": 1.8866797508319822e-05,
      "loss": 0.0017,
      "step": 72970
    },
    {
      "epoch": 6.227493813465313,
      "grad_norm": 0.03332137316465378,
      "learning_rate": 1.8862530932673436e-05,
      "loss": 0.0016,
      "step": 72980
    },
    {
      "epoch": 6.22834712859459,
      "grad_norm": 0.043252281844615936,
      "learning_rate": 1.885826435702705e-05,
      "loss": 0.0016,
      "step": 72990
    },
    {
      "epoch": 6.229200443723867,
      "grad_norm": 0.1619919091463089,
      "learning_rate": 1.8853997781380665e-05,
      "loss": 0.0015,
      "step": 73000
    },
    {
      "epoch": 6.230053758853145,
      "grad_norm": 0.10388145595788956,
      "learning_rate": 1.884973120573428e-05,
      "loss": 0.0014,
      "step": 73010
    },
    {
      "epoch": 6.230907073982422,
      "grad_norm": 0.2011677324771881,
      "learning_rate": 1.8845464630087893e-05,
      "loss": 0.0018,
      "step": 73020
    },
    {
      "epoch": 6.231760389111699,
      "grad_norm": 0.1190592423081398,
      "learning_rate": 1.8841198054441504e-05,
      "loss": 0.0016,
      "step": 73030
    },
    {
      "epoch": 6.232613704240976,
      "grad_norm": 0.02965434081852436,
      "learning_rate": 1.883693147879512e-05,
      "loss": 0.0017,
      "step": 73040
    },
    {
      "epoch": 6.233467019370253,
      "grad_norm": 0.32856714725494385,
      "learning_rate": 1.8832664903148733e-05,
      "loss": 0.0019,
      "step": 73050
    },
    {
      "epoch": 6.234320334499531,
      "grad_norm": 0.09102737158536911,
      "learning_rate": 1.8828398327502347e-05,
      "loss": 0.0022,
      "step": 73060
    },
    {
      "epoch": 6.235173649628808,
      "grad_norm": 0.06799919158220291,
      "learning_rate": 1.882413175185596e-05,
      "loss": 0.0015,
      "step": 73070
    },
    {
      "epoch": 6.236026964758085,
      "grad_norm": 0.11032206565141678,
      "learning_rate": 1.8819865176209575e-05,
      "loss": 0.0021,
      "step": 73080
    },
    {
      "epoch": 6.236880279887362,
      "grad_norm": 0.273294597864151,
      "learning_rate": 1.881559860056319e-05,
      "loss": 0.0018,
      "step": 73090
    },
    {
      "epoch": 6.23773359501664,
      "grad_norm": 0.1891467124223709,
      "learning_rate": 1.8811332024916804e-05,
      "loss": 0.0025,
      "step": 73100
    },
    {
      "epoch": 6.238586910145917,
      "grad_norm": 0.03647974878549576,
      "learning_rate": 1.8807065449270418e-05,
      "loss": 0.0022,
      "step": 73110
    },
    {
      "epoch": 6.239440225275194,
      "grad_norm": 0.20270715653896332,
      "learning_rate": 1.8802798873624032e-05,
      "loss": 0.0019,
      "step": 73120
    },
    {
      "epoch": 6.240293540404472,
      "grad_norm": 0.12922601401805878,
      "learning_rate": 1.8798532297977643e-05,
      "loss": 0.0021,
      "step": 73130
    },
    {
      "epoch": 6.241146855533748,
      "grad_norm": 0.16464854776859283,
      "learning_rate": 1.8794265722331257e-05,
      "loss": 0.0018,
      "step": 73140
    },
    {
      "epoch": 6.242000170663026,
      "grad_norm": 0.2722865045070648,
      "learning_rate": 1.878999914668487e-05,
      "loss": 0.0018,
      "step": 73150
    },
    {
      "epoch": 6.2428534857923035,
      "grad_norm": 0.2179766297340393,
      "learning_rate": 1.8785732571038486e-05,
      "loss": 0.0018,
      "step": 73160
    },
    {
      "epoch": 6.24370680092158,
      "grad_norm": 0.14224347472190857,
      "learning_rate": 1.87814659953921e-05,
      "loss": 0.0019,
      "step": 73170
    },
    {
      "epoch": 6.244560116050858,
      "grad_norm": 0.18166719377040863,
      "learning_rate": 1.8777199419745714e-05,
      "loss": 0.0015,
      "step": 73180
    },
    {
      "epoch": 6.245413431180134,
      "grad_norm": 0.14818017184734344,
      "learning_rate": 1.877293284409933e-05,
      "loss": 0.0016,
      "step": 73190
    },
    {
      "epoch": 6.246266746309412,
      "grad_norm": 0.08094707131385803,
      "learning_rate": 1.8768666268452943e-05,
      "loss": 0.0015,
      "step": 73200
    },
    {
      "epoch": 6.2471200614386895,
      "grad_norm": 0.22581151127815247,
      "learning_rate": 1.8764399692806557e-05,
      "loss": 0.0019,
      "step": 73210
    },
    {
      "epoch": 6.247973376567966,
      "grad_norm": 0.03205997496843338,
      "learning_rate": 1.8760133117160168e-05,
      "loss": 0.0018,
      "step": 73220
    },
    {
      "epoch": 6.248826691697244,
      "grad_norm": 0.40401723980903625,
      "learning_rate": 1.8755866541513782e-05,
      "loss": 0.0014,
      "step": 73230
    },
    {
      "epoch": 6.249680006826521,
      "grad_norm": 0.2350102663040161,
      "learning_rate": 1.8751599965867393e-05,
      "loss": 0.002,
      "step": 73240
    },
    {
      "epoch": 6.250533321955798,
      "grad_norm": 0.11981439590454102,
      "learning_rate": 1.8747333390221007e-05,
      "loss": 0.002,
      "step": 73250
    },
    {
      "epoch": 6.2513866370850755,
      "grad_norm": 0.13416504859924316,
      "learning_rate": 1.874306681457462e-05,
      "loss": 0.0019,
      "step": 73260
    },
    {
      "epoch": 6.252239952214353,
      "grad_norm": 0.12816107273101807,
      "learning_rate": 1.8738800238928236e-05,
      "loss": 0.0017,
      "step": 73270
    },
    {
      "epoch": 6.25309326734363,
      "grad_norm": 0.09381986409425735,
      "learning_rate": 1.873453366328185e-05,
      "loss": 0.0014,
      "step": 73280
    },
    {
      "epoch": 6.253946582472907,
      "grad_norm": 0.03782767429947853,
      "learning_rate": 1.8730267087635464e-05,
      "loss": 0.0018,
      "step": 73290
    },
    {
      "epoch": 6.254799897602185,
      "grad_norm": 0.14628350734710693,
      "learning_rate": 1.872600051198908e-05,
      "loss": 0.0017,
      "step": 73300
    },
    {
      "epoch": 6.2556532127314615,
      "grad_norm": 0.2081599086523056,
      "learning_rate": 1.8721733936342693e-05,
      "loss": 0.0015,
      "step": 73310
    },
    {
      "epoch": 6.256506527860739,
      "grad_norm": 0.06485222280025482,
      "learning_rate": 1.8717467360696307e-05,
      "loss": 0.0016,
      "step": 73320
    },
    {
      "epoch": 6.257359842990017,
      "grad_norm": 0.4727920889854431,
      "learning_rate": 1.871320078504992e-05,
      "loss": 0.0019,
      "step": 73330
    },
    {
      "epoch": 6.258213158119293,
      "grad_norm": 0.20627851784229279,
      "learning_rate": 1.8708934209403532e-05,
      "loss": 0.0018,
      "step": 73340
    },
    {
      "epoch": 6.259066473248571,
      "grad_norm": 0.11622710525989532,
      "learning_rate": 1.8704667633757146e-05,
      "loss": 0.0019,
      "step": 73350
    },
    {
      "epoch": 6.259919788377848,
      "grad_norm": 0.1364244967699051,
      "learning_rate": 1.870040105811076e-05,
      "loss": 0.0017,
      "step": 73360
    },
    {
      "epoch": 6.260773103507125,
      "grad_norm": 0.20338158309459686,
      "learning_rate": 1.8696134482464375e-05,
      "loss": 0.002,
      "step": 73370
    },
    {
      "epoch": 6.261626418636403,
      "grad_norm": 0.2707712650299072,
      "learning_rate": 1.869186790681799e-05,
      "loss": 0.0016,
      "step": 73380
    },
    {
      "epoch": 6.26247973376568,
      "grad_norm": 0.36625897884368896,
      "learning_rate": 1.8687601331171603e-05,
      "loss": 0.0019,
      "step": 73390
    },
    {
      "epoch": 6.263333048894957,
      "grad_norm": 0.14757730066776276,
      "learning_rate": 1.8683334755525217e-05,
      "loss": 0.0017,
      "step": 73400
    },
    {
      "epoch": 6.264186364024234,
      "grad_norm": 0.09257416427135468,
      "learning_rate": 1.8679068179878832e-05,
      "loss": 0.0022,
      "step": 73410
    },
    {
      "epoch": 6.265039679153511,
      "grad_norm": 0.05899691581726074,
      "learning_rate": 1.8674801604232446e-05,
      "loss": 0.0018,
      "step": 73420
    },
    {
      "epoch": 6.265892994282789,
      "grad_norm": 0.23658661544322968,
      "learning_rate": 1.867053502858606e-05,
      "loss": 0.0016,
      "step": 73430
    },
    {
      "epoch": 6.266746309412066,
      "grad_norm": 0.2210908979177475,
      "learning_rate": 1.866626845293967e-05,
      "loss": 0.0017,
      "step": 73440
    },
    {
      "epoch": 6.267599624541343,
      "grad_norm": 0.3625867962837219,
      "learning_rate": 1.8662001877293285e-05,
      "loss": 0.0022,
      "step": 73450
    },
    {
      "epoch": 6.26845293967062,
      "grad_norm": 0.3865062892436981,
      "learning_rate": 1.86577353016469e-05,
      "loss": 0.0021,
      "step": 73460
    },
    {
      "epoch": 6.269306254799898,
      "grad_norm": 0.11984807252883911,
      "learning_rate": 1.8653468726000514e-05,
      "loss": 0.0021,
      "step": 73470
    },
    {
      "epoch": 6.270159569929175,
      "grad_norm": 0.2797931432723999,
      "learning_rate": 1.8649202150354125e-05,
      "loss": 0.0016,
      "step": 73480
    },
    {
      "epoch": 6.271012885058452,
      "grad_norm": 0.2548805773258209,
      "learning_rate": 1.864493557470774e-05,
      "loss": 0.0018,
      "step": 73490
    },
    {
      "epoch": 6.27186620018773,
      "grad_norm": 0.14176805317401886,
      "learning_rate": 1.8640668999061353e-05,
      "loss": 0.0021,
      "step": 73500
    },
    {
      "epoch": 6.272719515317006,
      "grad_norm": 0.2394387274980545,
      "learning_rate": 1.8636402423414967e-05,
      "loss": 0.0015,
      "step": 73510
    },
    {
      "epoch": 6.273572830446284,
      "grad_norm": 0.23660661280155182,
      "learning_rate": 1.863213584776858e-05,
      "loss": 0.0016,
      "step": 73520
    },
    {
      "epoch": 6.274426145575561,
      "grad_norm": 0.06284051388502121,
      "learning_rate": 1.8627869272122196e-05,
      "loss": 0.002,
      "step": 73530
    },
    {
      "epoch": 6.275279460704838,
      "grad_norm": 0.07628049701452255,
      "learning_rate": 1.862360269647581e-05,
      "loss": 0.0019,
      "step": 73540
    },
    {
      "epoch": 6.276132775834116,
      "grad_norm": 0.3246416747570038,
      "learning_rate": 1.861933612082942e-05,
      "loss": 0.0017,
      "step": 73550
    },
    {
      "epoch": 6.276986090963392,
      "grad_norm": 0.2956465780735016,
      "learning_rate": 1.8615069545183035e-05,
      "loss": 0.0017,
      "step": 73560
    },
    {
      "epoch": 6.27783940609267,
      "grad_norm": 0.1464754194021225,
      "learning_rate": 1.861080296953665e-05,
      "loss": 0.0022,
      "step": 73570
    },
    {
      "epoch": 6.278692721221947,
      "grad_norm": 0.38338369131088257,
      "learning_rate": 1.8606536393890264e-05,
      "loss": 0.0019,
      "step": 73580
    },
    {
      "epoch": 6.279546036351224,
      "grad_norm": 0.06007770448923111,
      "learning_rate": 1.8602269818243878e-05,
      "loss": 0.0017,
      "step": 73590
    },
    {
      "epoch": 6.280399351480502,
      "grad_norm": 0.07620048522949219,
      "learning_rate": 1.8598003242597492e-05,
      "loss": 0.0018,
      "step": 73600
    },
    {
      "epoch": 6.281252666609779,
      "grad_norm": 0.31614309549331665,
      "learning_rate": 1.8593736666951106e-05,
      "loss": 0.0017,
      "step": 73610
    },
    {
      "epoch": 6.282105981739056,
      "grad_norm": 0.06769366562366486,
      "learning_rate": 1.858947009130472e-05,
      "loss": 0.0019,
      "step": 73620
    },
    {
      "epoch": 6.282959296868333,
      "grad_norm": 0.2096485048532486,
      "learning_rate": 1.8585203515658335e-05,
      "loss": 0.002,
      "step": 73630
    },
    {
      "epoch": 6.283812611997611,
      "grad_norm": 0.23951493203639984,
      "learning_rate": 1.858093694001195e-05,
      "loss": 0.0023,
      "step": 73640
    },
    {
      "epoch": 6.284665927126888,
      "grad_norm": 0.027244899421930313,
      "learning_rate": 1.857667036436556e-05,
      "loss": 0.0017,
      "step": 73650
    },
    {
      "epoch": 6.285519242256165,
      "grad_norm": 0.0799325555562973,
      "learning_rate": 1.8572403788719174e-05,
      "loss": 0.0021,
      "step": 73660
    },
    {
      "epoch": 6.286372557385443,
      "grad_norm": 0.25611352920532227,
      "learning_rate": 1.856813721307279e-05,
      "loss": 0.0016,
      "step": 73670
    },
    {
      "epoch": 6.287225872514719,
      "grad_norm": 0.200225830078125,
      "learning_rate": 1.8563870637426403e-05,
      "loss": 0.0018,
      "step": 73680
    },
    {
      "epoch": 6.288079187643997,
      "grad_norm": 0.17387115955352783,
      "learning_rate": 1.8559604061780017e-05,
      "loss": 0.0018,
      "step": 73690
    },
    {
      "epoch": 6.2889325027732745,
      "grad_norm": 0.5486230254173279,
      "learning_rate": 1.855533748613363e-05,
      "loss": 0.0015,
      "step": 73700
    },
    {
      "epoch": 6.289785817902551,
      "grad_norm": 0.2395816296339035,
      "learning_rate": 1.8551070910487245e-05,
      "loss": 0.002,
      "step": 73710
    },
    {
      "epoch": 6.290639133031829,
      "grad_norm": 0.2659471333026886,
      "learning_rate": 1.854680433484086e-05,
      "loss": 0.0021,
      "step": 73720
    },
    {
      "epoch": 6.291492448161106,
      "grad_norm": 0.5246955156326294,
      "learning_rate": 1.8542537759194474e-05,
      "loss": 0.0019,
      "step": 73730
    },
    {
      "epoch": 6.292345763290383,
      "grad_norm": 0.20384865999221802,
      "learning_rate": 1.8538271183548088e-05,
      "loss": 0.0021,
      "step": 73740
    },
    {
      "epoch": 6.2931990784196605,
      "grad_norm": 0.060624051839113235,
      "learning_rate": 1.85340046079017e-05,
      "loss": 0.0014,
      "step": 73750
    },
    {
      "epoch": 6.294052393548938,
      "grad_norm": 0.20526129007339478,
      "learning_rate": 1.8529738032255313e-05,
      "loss": 0.0017,
      "step": 73760
    },
    {
      "epoch": 6.294905708678215,
      "grad_norm": 0.14672762155532837,
      "learning_rate": 1.8525471456608924e-05,
      "loss": 0.0019,
      "step": 73770
    },
    {
      "epoch": 6.295759023807492,
      "grad_norm": 0.1868080347776413,
      "learning_rate": 1.852120488096254e-05,
      "loss": 0.0016,
      "step": 73780
    },
    {
      "epoch": 6.296612338936769,
      "grad_norm": 0.31178683042526245,
      "learning_rate": 1.8516938305316153e-05,
      "loss": 0.0017,
      "step": 73790
    },
    {
      "epoch": 6.2974656540660465,
      "grad_norm": 0.25758877396583557,
      "learning_rate": 1.8512671729669767e-05,
      "loss": 0.0022,
      "step": 73800
    },
    {
      "epoch": 6.298318969195324,
      "grad_norm": 0.20319555699825287,
      "learning_rate": 1.850840515402338e-05,
      "loss": 0.0017,
      "step": 73810
    },
    {
      "epoch": 6.299172284324601,
      "grad_norm": 0.12987059354782104,
      "learning_rate": 1.8504138578376995e-05,
      "loss": 0.0016,
      "step": 73820
    },
    {
      "epoch": 6.300025599453878,
      "grad_norm": 0.21955882012844086,
      "learning_rate": 1.849987200273061e-05,
      "loss": 0.0019,
      "step": 73830
    },
    {
      "epoch": 6.300878914583156,
      "grad_norm": 0.14516933262348175,
      "learning_rate": 1.8495605427084224e-05,
      "loss": 0.0015,
      "step": 73840
    },
    {
      "epoch": 6.3017322297124325,
      "grad_norm": 0.22683431208133698,
      "learning_rate": 1.8491338851437838e-05,
      "loss": 0.0017,
      "step": 73850
    },
    {
      "epoch": 6.30258554484171,
      "grad_norm": 0.2703109681606293,
      "learning_rate": 1.848707227579145e-05,
      "loss": 0.0017,
      "step": 73860
    },
    {
      "epoch": 6.303438859970988,
      "grad_norm": 0.035524625331163406,
      "learning_rate": 1.8482805700145063e-05,
      "loss": 0.0019,
      "step": 73870
    },
    {
      "epoch": 6.304292175100264,
      "grad_norm": 0.06014414131641388,
      "learning_rate": 1.8478539124498677e-05,
      "loss": 0.0016,
      "step": 73880
    },
    {
      "epoch": 6.305145490229542,
      "grad_norm": 0.14485317468643188,
      "learning_rate": 1.847427254885229e-05,
      "loss": 0.0025,
      "step": 73890
    },
    {
      "epoch": 6.305998805358819,
      "grad_norm": 0.1894935816526413,
      "learning_rate": 1.8470005973205906e-05,
      "loss": 0.0018,
      "step": 73900
    },
    {
      "epoch": 6.306852120488096,
      "grad_norm": 0.1860378235578537,
      "learning_rate": 1.846573939755952e-05,
      "loss": 0.0017,
      "step": 73910
    },
    {
      "epoch": 6.307705435617374,
      "grad_norm": 0.057416755706071854,
      "learning_rate": 1.8461472821913134e-05,
      "loss": 0.0015,
      "step": 73920
    },
    {
      "epoch": 6.30855875074665,
      "grad_norm": 0.1202770322561264,
      "learning_rate": 1.845720624626675e-05,
      "loss": 0.0018,
      "step": 73930
    },
    {
      "epoch": 6.309412065875928,
      "grad_norm": 0.22074845433235168,
      "learning_rate": 1.8452939670620363e-05,
      "loss": 0.0017,
      "step": 73940
    },
    {
      "epoch": 6.310265381005205,
      "grad_norm": 0.05982494354248047,
      "learning_rate": 1.8448673094973977e-05,
      "loss": 0.0018,
      "step": 73950
    },
    {
      "epoch": 6.311118696134482,
      "grad_norm": 0.0982266291975975,
      "learning_rate": 1.8444406519327588e-05,
      "loss": 0.002,
      "step": 73960
    },
    {
      "epoch": 6.31197201126376,
      "grad_norm": 0.05874805524945259,
      "learning_rate": 1.8440139943681202e-05,
      "loss": 0.0015,
      "step": 73970
    },
    {
      "epoch": 6.312825326393037,
      "grad_norm": 0.20362751185894012,
      "learning_rate": 1.8435873368034816e-05,
      "loss": 0.0016,
      "step": 73980
    },
    {
      "epoch": 6.313678641522314,
      "grad_norm": 0.07780418545007706,
      "learning_rate": 1.843160679238843e-05,
      "loss": 0.0019,
      "step": 73990
    },
    {
      "epoch": 6.314531956651591,
      "grad_norm": 0.1257052719593048,
      "learning_rate": 1.8427340216742045e-05,
      "loss": 0.0017,
      "step": 74000
    },
    {
      "epoch": 6.315385271780869,
      "grad_norm": 0.2917734980583191,
      "learning_rate": 1.8423073641095656e-05,
      "loss": 0.0015,
      "step": 74010
    },
    {
      "epoch": 6.316238586910146,
      "grad_norm": 0.09322167932987213,
      "learning_rate": 1.841880706544927e-05,
      "loss": 0.0017,
      "step": 74020
    },
    {
      "epoch": 6.317091902039423,
      "grad_norm": 0.18294842541217804,
      "learning_rate": 1.8414540489802884e-05,
      "loss": 0.0022,
      "step": 74030
    },
    {
      "epoch": 6.317945217168701,
      "grad_norm": 0.20129303634166718,
      "learning_rate": 1.84102739141565e-05,
      "loss": 0.0023,
      "step": 74040
    },
    {
      "epoch": 6.318798532297977,
      "grad_norm": 0.2392088621854782,
      "learning_rate": 1.8406007338510113e-05,
      "loss": 0.0019,
      "step": 74050
    },
    {
      "epoch": 6.319651847427255,
      "grad_norm": 0.03213000297546387,
      "learning_rate": 1.8401740762863727e-05,
      "loss": 0.0017,
      "step": 74060
    },
    {
      "epoch": 6.3205051625565325,
      "grad_norm": 0.1634121686220169,
      "learning_rate": 1.839747418721734e-05,
      "loss": 0.0022,
      "step": 74070
    },
    {
      "epoch": 6.321358477685809,
      "grad_norm": 0.041181981563568115,
      "learning_rate": 1.8393207611570952e-05,
      "loss": 0.0015,
      "step": 74080
    },
    {
      "epoch": 6.322211792815087,
      "grad_norm": 0.16536597907543182,
      "learning_rate": 1.8388941035924566e-05,
      "loss": 0.0015,
      "step": 74090
    },
    {
      "epoch": 6.323065107944364,
      "grad_norm": 0.09577932208776474,
      "learning_rate": 1.838467446027818e-05,
      "loss": 0.0018,
      "step": 74100
    },
    {
      "epoch": 6.323918423073641,
      "grad_norm": 0.13080047070980072,
      "learning_rate": 1.8380407884631795e-05,
      "loss": 0.0015,
      "step": 74110
    },
    {
      "epoch": 6.3247717382029185,
      "grad_norm": 0.09359259158372879,
      "learning_rate": 1.837614130898541e-05,
      "loss": 0.0014,
      "step": 74120
    },
    {
      "epoch": 6.325625053332196,
      "grad_norm": 0.40310361981391907,
      "learning_rate": 1.8371874733339023e-05,
      "loss": 0.0015,
      "step": 74130
    },
    {
      "epoch": 6.326478368461473,
      "grad_norm": 0.2497822493314743,
      "learning_rate": 1.8367608157692637e-05,
      "loss": 0.0018,
      "step": 74140
    },
    {
      "epoch": 6.32733168359075,
      "grad_norm": 0.07853160798549652,
      "learning_rate": 1.836334158204625e-05,
      "loss": 0.0018,
      "step": 74150
    },
    {
      "epoch": 6.328184998720027,
      "grad_norm": 0.07822050899267197,
      "learning_rate": 1.8359075006399866e-05,
      "loss": 0.0015,
      "step": 74160
    },
    {
      "epoch": 6.3290383138493045,
      "grad_norm": 0.04614005610346794,
      "learning_rate": 1.8354808430753477e-05,
      "loss": 0.002,
      "step": 74170
    },
    {
      "epoch": 6.329891628978582,
      "grad_norm": 0.16487866640090942,
      "learning_rate": 1.835054185510709e-05,
      "loss": 0.0015,
      "step": 74180
    },
    {
      "epoch": 6.330744944107859,
      "grad_norm": 0.28298869729042053,
      "learning_rate": 1.8346275279460705e-05,
      "loss": 0.002,
      "step": 74190
    },
    {
      "epoch": 6.331598259237136,
      "grad_norm": 0.0461106039583683,
      "learning_rate": 1.834200870381432e-05,
      "loss": 0.0019,
      "step": 74200
    },
    {
      "epoch": 6.332451574366414,
      "grad_norm": 0.11071816831827164,
      "learning_rate": 1.8337742128167934e-05,
      "loss": 0.0021,
      "step": 74210
    },
    {
      "epoch": 6.3333048894956905,
      "grad_norm": 0.18211480975151062,
      "learning_rate": 1.8333475552521548e-05,
      "loss": 0.0015,
      "step": 74220
    },
    {
      "epoch": 6.334158204624968,
      "grad_norm": 0.14921234548091888,
      "learning_rate": 1.8329208976875162e-05,
      "loss": 0.0021,
      "step": 74230
    },
    {
      "epoch": 6.335011519754246,
      "grad_norm": 0.06411787867546082,
      "learning_rate": 1.8324942401228776e-05,
      "loss": 0.0019,
      "step": 74240
    },
    {
      "epoch": 6.335864834883522,
      "grad_norm": 0.16436456143856049,
      "learning_rate": 1.832067582558239e-05,
      "loss": 0.0016,
      "step": 74250
    },
    {
      "epoch": 6.3367181500128,
      "grad_norm": 0.2398473173379898,
      "learning_rate": 1.8316409249936005e-05,
      "loss": 0.002,
      "step": 74260
    },
    {
      "epoch": 6.337571465142077,
      "grad_norm": 0.027909187600016594,
      "learning_rate": 1.8312142674289616e-05,
      "loss": 0.0017,
      "step": 74270
    },
    {
      "epoch": 6.338424780271354,
      "grad_norm": 0.09250403195619583,
      "learning_rate": 1.830787609864323e-05,
      "loss": 0.0023,
      "step": 74280
    },
    {
      "epoch": 6.339278095400632,
      "grad_norm": 0.16698093712329865,
      "learning_rate": 1.830360952299684e-05,
      "loss": 0.0014,
      "step": 74290
    },
    {
      "epoch": 6.340131410529908,
      "grad_norm": 0.07732296735048294,
      "learning_rate": 1.8299342947350455e-05,
      "loss": 0.0018,
      "step": 74300
    },
    {
      "epoch": 6.340984725659186,
      "grad_norm": 0.23002776503562927,
      "learning_rate": 1.829507637170407e-05,
      "loss": 0.0017,
      "step": 74310
    },
    {
      "epoch": 6.341838040788463,
      "grad_norm": 0.061950720846652985,
      "learning_rate": 1.8290809796057684e-05,
      "loss": 0.0015,
      "step": 74320
    },
    {
      "epoch": 6.34269135591774,
      "grad_norm": 0.23925615847110748,
      "learning_rate": 1.8286543220411298e-05,
      "loss": 0.0017,
      "step": 74330
    },
    {
      "epoch": 6.343544671047018,
      "grad_norm": 0.16923892498016357,
      "learning_rate": 1.8282276644764912e-05,
      "loss": 0.0019,
      "step": 74340
    },
    {
      "epoch": 6.344397986176295,
      "grad_norm": 0.2769606411457062,
      "learning_rate": 1.8278010069118526e-05,
      "loss": 0.0014,
      "step": 74350
    },
    {
      "epoch": 6.345251301305572,
      "grad_norm": 0.06428175419569016,
      "learning_rate": 1.827374349347214e-05,
      "loss": 0.0019,
      "step": 74360
    },
    {
      "epoch": 6.346104616434849,
      "grad_norm": 0.1518418788909912,
      "learning_rate": 1.8269476917825755e-05,
      "loss": 0.0015,
      "step": 74370
    },
    {
      "epoch": 6.346957931564127,
      "grad_norm": 0.035798680037260056,
      "learning_rate": 1.826521034217937e-05,
      "loss": 0.0019,
      "step": 74380
    },
    {
      "epoch": 6.347811246693404,
      "grad_norm": 0.058186810463666916,
      "learning_rate": 1.826094376653298e-05,
      "loss": 0.0017,
      "step": 74390
    },
    {
      "epoch": 6.348664561822681,
      "grad_norm": 0.22230565547943115,
      "learning_rate": 1.8256677190886594e-05,
      "loss": 0.0017,
      "step": 74400
    },
    {
      "epoch": 6.349517876951959,
      "grad_norm": 0.16503342986106873,
      "learning_rate": 1.825241061524021e-05,
      "loss": 0.002,
      "step": 74410
    },
    {
      "epoch": 6.350371192081235,
      "grad_norm": 0.06526786088943481,
      "learning_rate": 1.8248144039593823e-05,
      "loss": 0.0015,
      "step": 74420
    },
    {
      "epoch": 6.351224507210513,
      "grad_norm": 0.3139043152332306,
      "learning_rate": 1.8243877463947437e-05,
      "loss": 0.0019,
      "step": 74430
    },
    {
      "epoch": 6.3520778223397905,
      "grad_norm": 0.1294344812631607,
      "learning_rate": 1.823961088830105e-05,
      "loss": 0.0019,
      "step": 74440
    },
    {
      "epoch": 6.352931137469067,
      "grad_norm": 0.1692046821117401,
      "learning_rate": 1.8235344312654665e-05,
      "loss": 0.0018,
      "step": 74450
    },
    {
      "epoch": 6.353784452598345,
      "grad_norm": 0.0645052045583725,
      "learning_rate": 1.823107773700828e-05,
      "loss": 0.0018,
      "step": 74460
    },
    {
      "epoch": 6.354637767727622,
      "grad_norm": 0.4358782172203064,
      "learning_rate": 1.8226811161361894e-05,
      "loss": 0.0013,
      "step": 74470
    },
    {
      "epoch": 6.355491082856899,
      "grad_norm": 0.3127896785736084,
      "learning_rate": 1.8222544585715505e-05,
      "loss": 0.002,
      "step": 74480
    },
    {
      "epoch": 6.3563443979861765,
      "grad_norm": 0.1469535380601883,
      "learning_rate": 1.821827801006912e-05,
      "loss": 0.0016,
      "step": 74490
    },
    {
      "epoch": 6.357197713115454,
      "grad_norm": 0.11731797456741333,
      "learning_rate": 1.8214011434422733e-05,
      "loss": 0.0017,
      "step": 74500
    },
    {
      "epoch": 6.358051028244731,
      "grad_norm": 0.33242571353912354,
      "learning_rate": 1.8209744858776347e-05,
      "loss": 0.0017,
      "step": 74510
    },
    {
      "epoch": 6.358904343374008,
      "grad_norm": 0.13967883586883545,
      "learning_rate": 1.820547828312996e-05,
      "loss": 0.002,
      "step": 74520
    },
    {
      "epoch": 6.359757658503285,
      "grad_norm": 0.17244064807891846,
      "learning_rate": 1.8201211707483576e-05,
      "loss": 0.002,
      "step": 74530
    },
    {
      "epoch": 6.3606109736325624,
      "grad_norm": 0.03925885260105133,
      "learning_rate": 1.8196945131837187e-05,
      "loss": 0.0022,
      "step": 74540
    },
    {
      "epoch": 6.36146428876184,
      "grad_norm": 0.3553689122200012,
      "learning_rate": 1.81926785561908e-05,
      "loss": 0.0013,
      "step": 74550
    },
    {
      "epoch": 6.362317603891117,
      "grad_norm": 0.2162970006465912,
      "learning_rate": 1.8188411980544415e-05,
      "loss": 0.0022,
      "step": 74560
    },
    {
      "epoch": 6.363170919020394,
      "grad_norm": 0.184899240732193,
      "learning_rate": 1.818414540489803e-05,
      "loss": 0.0021,
      "step": 74570
    },
    {
      "epoch": 6.364024234149672,
      "grad_norm": 0.09436852484941483,
      "learning_rate": 1.8179878829251644e-05,
      "loss": 0.0018,
      "step": 74580
    },
    {
      "epoch": 6.364877549278948,
      "grad_norm": 0.25940218567848206,
      "learning_rate": 1.8175612253605258e-05,
      "loss": 0.0019,
      "step": 74590
    },
    {
      "epoch": 6.365730864408226,
      "grad_norm": 0.029978983104228973,
      "learning_rate": 1.817134567795887e-05,
      "loss": 0.0016,
      "step": 74600
    },
    {
      "epoch": 6.3665841795375036,
      "grad_norm": 0.11304468661546707,
      "learning_rate": 1.8167079102312483e-05,
      "loss": 0.0016,
      "step": 74610
    },
    {
      "epoch": 6.36743749466678,
      "grad_norm": 0.3445499837398529,
      "learning_rate": 1.8162812526666097e-05,
      "loss": 0.0017,
      "step": 74620
    },
    {
      "epoch": 6.368290809796058,
      "grad_norm": 0.09113884717226028,
      "learning_rate": 1.815854595101971e-05,
      "loss": 0.0015,
      "step": 74630
    },
    {
      "epoch": 6.369144124925335,
      "grad_norm": 0.20248891413211823,
      "learning_rate": 1.8154279375373326e-05,
      "loss": 0.002,
      "step": 74640
    },
    {
      "epoch": 6.369997440054612,
      "grad_norm": 0.148548886179924,
      "learning_rate": 1.815001279972694e-05,
      "loss": 0.002,
      "step": 74650
    },
    {
      "epoch": 6.3708507551838895,
      "grad_norm": 0.18124085664749146,
      "learning_rate": 1.8145746224080554e-05,
      "loss": 0.0015,
      "step": 74660
    },
    {
      "epoch": 6.371704070313166,
      "grad_norm": 0.2916782796382904,
      "learning_rate": 1.814147964843417e-05,
      "loss": 0.0016,
      "step": 74670
    },
    {
      "epoch": 6.372557385442444,
      "grad_norm": 0.019294165074825287,
      "learning_rate": 1.8137213072787783e-05,
      "loss": 0.0016,
      "step": 74680
    },
    {
      "epoch": 6.373410700571721,
      "grad_norm": 0.2979220747947693,
      "learning_rate": 1.8132946497141397e-05,
      "loss": 0.0019,
      "step": 74690
    },
    {
      "epoch": 6.374264015700998,
      "grad_norm": 0.42427828907966614,
      "learning_rate": 1.8128679921495008e-05,
      "loss": 0.0013,
      "step": 74700
    },
    {
      "epoch": 6.3751173308302755,
      "grad_norm": 0.20321489870548248,
      "learning_rate": 1.8124413345848622e-05,
      "loss": 0.002,
      "step": 74710
    },
    {
      "epoch": 6.375970645959553,
      "grad_norm": 0.057300493121147156,
      "learning_rate": 1.8120146770202236e-05,
      "loss": 0.0016,
      "step": 74720
    },
    {
      "epoch": 6.37682396108883,
      "grad_norm": 0.07879658788442612,
      "learning_rate": 1.811588019455585e-05,
      "loss": 0.0017,
      "step": 74730
    },
    {
      "epoch": 6.377677276218107,
      "grad_norm": 0.11445816606283188,
      "learning_rate": 1.8111613618909465e-05,
      "loss": 0.0022,
      "step": 74740
    },
    {
      "epoch": 6.378530591347385,
      "grad_norm": 0.06151862069964409,
      "learning_rate": 1.810734704326308e-05,
      "loss": 0.002,
      "step": 74750
    },
    {
      "epoch": 6.3793839064766615,
      "grad_norm": 0.26191475987434387,
      "learning_rate": 1.8103080467616693e-05,
      "loss": 0.0022,
      "step": 74760
    },
    {
      "epoch": 6.380237221605939,
      "grad_norm": 0.03491204231977463,
      "learning_rate": 1.8098813891970308e-05,
      "loss": 0.0025,
      "step": 74770
    },
    {
      "epoch": 6.381090536735217,
      "grad_norm": 0.19876767694950104,
      "learning_rate": 1.8094547316323922e-05,
      "loss": 0.0015,
      "step": 74780
    },
    {
      "epoch": 6.381943851864493,
      "grad_norm": 0.07990548014640808,
      "learning_rate": 1.8090280740677536e-05,
      "loss": 0.0018,
      "step": 74790
    },
    {
      "epoch": 6.382797166993771,
      "grad_norm": 0.20320704579353333,
      "learning_rate": 1.8086014165031147e-05,
      "loss": 0.002,
      "step": 74800
    },
    {
      "epoch": 6.383650482123048,
      "grad_norm": 0.060526758432388306,
      "learning_rate": 1.8081747589384758e-05,
      "loss": 0.0016,
      "step": 74810
    },
    {
      "epoch": 6.384503797252325,
      "grad_norm": 0.27113014459609985,
      "learning_rate": 1.8077481013738372e-05,
      "loss": 0.0017,
      "step": 74820
    },
    {
      "epoch": 6.385357112381603,
      "grad_norm": 0.10975439101457596,
      "learning_rate": 1.8073214438091986e-05,
      "loss": 0.002,
      "step": 74830
    },
    {
      "epoch": 6.38621042751088,
      "grad_norm": 0.2445090264081955,
      "learning_rate": 1.80689478624456e-05,
      "loss": 0.0018,
      "step": 74840
    },
    {
      "epoch": 6.387063742640157,
      "grad_norm": 0.07427996397018433,
      "learning_rate": 1.8064681286799215e-05,
      "loss": 0.0019,
      "step": 74850
    },
    {
      "epoch": 6.387917057769434,
      "grad_norm": 0.23739463090896606,
      "learning_rate": 1.806041471115283e-05,
      "loss": 0.0016,
      "step": 74860
    },
    {
      "epoch": 6.388770372898711,
      "grad_norm": 0.029199007898569107,
      "learning_rate": 1.8056148135506443e-05,
      "loss": 0.0016,
      "step": 74870
    },
    {
      "epoch": 6.389623688027989,
      "grad_norm": 0.10985998064279556,
      "learning_rate": 1.8051881559860057e-05,
      "loss": 0.0012,
      "step": 74880
    },
    {
      "epoch": 6.390477003157266,
      "grad_norm": 0.025326211005449295,
      "learning_rate": 1.804761498421367e-05,
      "loss": 0.002,
      "step": 74890
    },
    {
      "epoch": 6.391330318286543,
      "grad_norm": 0.3509790897369385,
      "learning_rate": 1.8043348408567286e-05,
      "loss": 0.0016,
      "step": 74900
    },
    {
      "epoch": 6.39218363341582,
      "grad_norm": 0.25414925813674927,
      "learning_rate": 1.8039081832920897e-05,
      "loss": 0.0017,
      "step": 74910
    },
    {
      "epoch": 6.393036948545098,
      "grad_norm": 0.18233531713485718,
      "learning_rate": 1.803481525727451e-05,
      "loss": 0.0019,
      "step": 74920
    },
    {
      "epoch": 6.393890263674375,
      "grad_norm": 0.2894619405269623,
      "learning_rate": 1.8030548681628125e-05,
      "loss": 0.0019,
      "step": 74930
    },
    {
      "epoch": 6.394743578803652,
      "grad_norm": 0.023443050682544708,
      "learning_rate": 1.802628210598174e-05,
      "loss": 0.0019,
      "step": 74940
    },
    {
      "epoch": 6.39559689393293,
      "grad_norm": 0.18270328640937805,
      "learning_rate": 1.8022015530335354e-05,
      "loss": 0.002,
      "step": 74950
    },
    {
      "epoch": 6.396450209062206,
      "grad_norm": 0.1874610334634781,
      "learning_rate": 1.8017748954688968e-05,
      "loss": 0.0019,
      "step": 74960
    },
    {
      "epoch": 6.397303524191484,
      "grad_norm": 0.1342126876115799,
      "learning_rate": 1.8013482379042582e-05,
      "loss": 0.0018,
      "step": 74970
    },
    {
      "epoch": 6.3981568393207615,
      "grad_norm": 0.09399136900901794,
      "learning_rate": 1.8009215803396196e-05,
      "loss": 0.0016,
      "step": 74980
    },
    {
      "epoch": 6.399010154450038,
      "grad_norm": 0.0807775929570198,
      "learning_rate": 1.800494922774981e-05,
      "loss": 0.0019,
      "step": 74990
    },
    {
      "epoch": 6.399863469579316,
      "grad_norm": 0.12697461247444153,
      "learning_rate": 1.8000682652103425e-05,
      "loss": 0.0018,
      "step": 75000
    },
    {
      "epoch": 6.400716784708593,
      "grad_norm": 0.1316061019897461,
      "learning_rate": 1.7996416076457036e-05,
      "loss": 0.0017,
      "step": 75010
    },
    {
      "epoch": 6.40157009983787,
      "grad_norm": 0.07771582156419754,
      "learning_rate": 1.799214950081065e-05,
      "loss": 0.0017,
      "step": 75020
    },
    {
      "epoch": 6.4024234149671475,
      "grad_norm": 0.37134289741516113,
      "learning_rate": 1.7987882925164264e-05,
      "loss": 0.0018,
      "step": 75030
    },
    {
      "epoch": 6.403276730096424,
      "grad_norm": 0.07637523859739304,
      "learning_rate": 1.798361634951788e-05,
      "loss": 0.0022,
      "step": 75040
    },
    {
      "epoch": 6.404130045225702,
      "grad_norm": 0.15975040197372437,
      "learning_rate": 1.7979349773871493e-05,
      "loss": 0.0022,
      "step": 75050
    },
    {
      "epoch": 6.404983360354979,
      "grad_norm": 0.42926278710365295,
      "learning_rate": 1.7975083198225107e-05,
      "loss": 0.0015,
      "step": 75060
    },
    {
      "epoch": 6.405836675484256,
      "grad_norm": 0.27255991101264954,
      "learning_rate": 1.797081662257872e-05,
      "loss": 0.002,
      "step": 75070
    },
    {
      "epoch": 6.4066899906135335,
      "grad_norm": 0.03393632546067238,
      "learning_rate": 1.7966550046932332e-05,
      "loss": 0.0017,
      "step": 75080
    },
    {
      "epoch": 6.407543305742811,
      "grad_norm": 0.11149609088897705,
      "learning_rate": 1.7962283471285946e-05,
      "loss": 0.0015,
      "step": 75090
    },
    {
      "epoch": 6.408396620872088,
      "grad_norm": 0.07935648411512375,
      "learning_rate": 1.795801689563956e-05,
      "loss": 0.0015,
      "step": 75100
    },
    {
      "epoch": 6.409249936001365,
      "grad_norm": 0.03209356963634491,
      "learning_rate": 1.7953750319993175e-05,
      "loss": 0.0017,
      "step": 75110
    },
    {
      "epoch": 6.410103251130643,
      "grad_norm": 0.04415685683488846,
      "learning_rate": 1.7949483744346786e-05,
      "loss": 0.0018,
      "step": 75120
    },
    {
      "epoch": 6.4109565662599195,
      "grad_norm": 0.23640015721321106,
      "learning_rate": 1.79452171687004e-05,
      "loss": 0.0018,
      "step": 75130
    },
    {
      "epoch": 6.411809881389197,
      "grad_norm": 0.29518529772758484,
      "learning_rate": 1.7940950593054014e-05,
      "loss": 0.0022,
      "step": 75140
    },
    {
      "epoch": 6.412663196518475,
      "grad_norm": 0.12879090011119843,
      "learning_rate": 1.793668401740763e-05,
      "loss": 0.0014,
      "step": 75150
    },
    {
      "epoch": 6.413516511647751,
      "grad_norm": 0.25402235984802246,
      "learning_rate": 1.7932417441761243e-05,
      "loss": 0.0017,
      "step": 75160
    },
    {
      "epoch": 6.414369826777029,
      "grad_norm": 0.18283304572105408,
      "learning_rate": 1.7928150866114857e-05,
      "loss": 0.002,
      "step": 75170
    },
    {
      "epoch": 6.415223141906306,
      "grad_norm": 0.10073377937078476,
      "learning_rate": 1.792388429046847e-05,
      "loss": 0.0017,
      "step": 75180
    },
    {
      "epoch": 6.416076457035583,
      "grad_norm": 0.4772704839706421,
      "learning_rate": 1.7919617714822085e-05,
      "loss": 0.0016,
      "step": 75190
    },
    {
      "epoch": 6.416929772164861,
      "grad_norm": 0.05989876016974449,
      "learning_rate": 1.79153511391757e-05,
      "loss": 0.002,
      "step": 75200
    },
    {
      "epoch": 6.417783087294138,
      "grad_norm": 0.20039159059524536,
      "learning_rate": 1.7911084563529314e-05,
      "loss": 0.0018,
      "step": 75210
    },
    {
      "epoch": 6.418636402423415,
      "grad_norm": 0.18366721272468567,
      "learning_rate": 1.7906817987882925e-05,
      "loss": 0.0016,
      "step": 75220
    },
    {
      "epoch": 6.419489717552692,
      "grad_norm": 0.07894971966743469,
      "learning_rate": 1.790255141223654e-05,
      "loss": 0.0016,
      "step": 75230
    },
    {
      "epoch": 6.420343032681969,
      "grad_norm": 0.2533988952636719,
      "learning_rate": 1.7898284836590153e-05,
      "loss": 0.0016,
      "step": 75240
    },
    {
      "epoch": 6.421196347811247,
      "grad_norm": 0.26087382435798645,
      "learning_rate": 1.7894018260943767e-05,
      "loss": 0.0016,
      "step": 75250
    },
    {
      "epoch": 6.422049662940524,
      "grad_norm": 0.13298149406909943,
      "learning_rate": 1.788975168529738e-05,
      "loss": 0.002,
      "step": 75260
    },
    {
      "epoch": 6.422902978069801,
      "grad_norm": 0.23646847903728485,
      "learning_rate": 1.7885485109650996e-05,
      "loss": 0.0015,
      "step": 75270
    },
    {
      "epoch": 6.423756293199078,
      "grad_norm": 0.25335562229156494,
      "learning_rate": 1.788121853400461e-05,
      "loss": 0.0017,
      "step": 75280
    },
    {
      "epoch": 6.424609608328356,
      "grad_norm": 0.10935383290052414,
      "learning_rate": 1.7876951958358224e-05,
      "loss": 0.0016,
      "step": 75290
    },
    {
      "epoch": 6.425462923457633,
      "grad_norm": 0.08478554338216782,
      "learning_rate": 1.787268538271184e-05,
      "loss": 0.0019,
      "step": 75300
    },
    {
      "epoch": 6.42631623858691,
      "grad_norm": 0.0428888238966465,
      "learning_rate": 1.7868418807065453e-05,
      "loss": 0.002,
      "step": 75310
    },
    {
      "epoch": 6.427169553716188,
      "grad_norm": 0.09219631552696228,
      "learning_rate": 1.7864152231419064e-05,
      "loss": 0.0019,
      "step": 75320
    },
    {
      "epoch": 6.428022868845464,
      "grad_norm": 0.084309883415699,
      "learning_rate": 1.7859885655772678e-05,
      "loss": 0.0017,
      "step": 75330
    },
    {
      "epoch": 6.428876183974742,
      "grad_norm": 0.1422661691904068,
      "learning_rate": 1.785561908012629e-05,
      "loss": 0.0018,
      "step": 75340
    },
    {
      "epoch": 6.4297294991040195,
      "grad_norm": 0.10154803842306137,
      "learning_rate": 1.7851352504479903e-05,
      "loss": 0.0026,
      "step": 75350
    },
    {
      "epoch": 6.430582814233296,
      "grad_norm": 0.07627497613430023,
      "learning_rate": 1.7847085928833517e-05,
      "loss": 0.0019,
      "step": 75360
    },
    {
      "epoch": 6.431436129362574,
      "grad_norm": 0.07294848561286926,
      "learning_rate": 1.784281935318713e-05,
      "loss": 0.0016,
      "step": 75370
    },
    {
      "epoch": 6.432289444491851,
      "grad_norm": 0.19860555231571198,
      "learning_rate": 1.7838552777540746e-05,
      "loss": 0.0015,
      "step": 75380
    },
    {
      "epoch": 6.433142759621128,
      "grad_norm": 0.09441973268985748,
      "learning_rate": 1.783428620189436e-05,
      "loss": 0.0018,
      "step": 75390
    },
    {
      "epoch": 6.4339960747504055,
      "grad_norm": 0.0754527598619461,
      "learning_rate": 1.7830019626247974e-05,
      "loss": 0.0016,
      "step": 75400
    },
    {
      "epoch": 6.434849389879682,
      "grad_norm": 0.03197323530912399,
      "learning_rate": 1.782575305060159e-05,
      "loss": 0.0014,
      "step": 75410
    },
    {
      "epoch": 6.43570270500896,
      "grad_norm": 0.033964335918426514,
      "learning_rate": 1.7821486474955203e-05,
      "loss": 0.0019,
      "step": 75420
    },
    {
      "epoch": 6.436556020138237,
      "grad_norm": 0.17106056213378906,
      "learning_rate": 1.7817219899308814e-05,
      "loss": 0.0019,
      "step": 75430
    },
    {
      "epoch": 6.437409335267514,
      "grad_norm": 0.36521580815315247,
      "learning_rate": 1.7812953323662428e-05,
      "loss": 0.0015,
      "step": 75440
    },
    {
      "epoch": 6.4382626503967915,
      "grad_norm": 0.16718964278697968,
      "learning_rate": 1.7808686748016042e-05,
      "loss": 0.0021,
      "step": 75450
    },
    {
      "epoch": 6.439115965526069,
      "grad_norm": 0.04717383533716202,
      "learning_rate": 1.7804420172369656e-05,
      "loss": 0.0017,
      "step": 75460
    },
    {
      "epoch": 6.439969280655346,
      "grad_norm": 0.09591226279735565,
      "learning_rate": 1.780015359672327e-05,
      "loss": 0.0017,
      "step": 75470
    },
    {
      "epoch": 6.440822595784623,
      "grad_norm": 0.028206272050738335,
      "learning_rate": 1.7795887021076885e-05,
      "loss": 0.0014,
      "step": 75480
    },
    {
      "epoch": 6.441675910913901,
      "grad_norm": 0.31256893277168274,
      "learning_rate": 1.77916204454305e-05,
      "loss": 0.0016,
      "step": 75490
    },
    {
      "epoch": 6.4425292260431775,
      "grad_norm": 0.11244170367717743,
      "learning_rate": 1.7787353869784113e-05,
      "loss": 0.0017,
      "step": 75500
    },
    {
      "epoch": 6.443382541172455,
      "grad_norm": 0.044787295162677765,
      "learning_rate": 1.7783087294137727e-05,
      "loss": 0.0022,
      "step": 75510
    },
    {
      "epoch": 6.444235856301733,
      "grad_norm": 0.08010845631361008,
      "learning_rate": 1.7778820718491342e-05,
      "loss": 0.002,
      "step": 75520
    },
    {
      "epoch": 6.445089171431009,
      "grad_norm": 0.38134440779685974,
      "learning_rate": 1.7774554142844953e-05,
      "loss": 0.0014,
      "step": 75530
    },
    {
      "epoch": 6.445942486560287,
      "grad_norm": 0.32542940974235535,
      "learning_rate": 1.7770287567198567e-05,
      "loss": 0.0015,
      "step": 75540
    },
    {
      "epoch": 6.446795801689564,
      "grad_norm": 0.07579221576452255,
      "learning_rate": 1.776602099155218e-05,
      "loss": 0.0021,
      "step": 75550
    },
    {
      "epoch": 6.447649116818841,
      "grad_norm": 0.059759777039289474,
      "learning_rate": 1.7761754415905795e-05,
      "loss": 0.0018,
      "step": 75560
    },
    {
      "epoch": 6.448502431948119,
      "grad_norm": 0.2567911744117737,
      "learning_rate": 1.775748784025941e-05,
      "loss": 0.0016,
      "step": 75570
    },
    {
      "epoch": 6.449355747077396,
      "grad_norm": 0.043789736926555634,
      "learning_rate": 1.7753221264613024e-05,
      "loss": 0.0015,
      "step": 75580
    },
    {
      "epoch": 6.450209062206673,
      "grad_norm": 0.022553779184818268,
      "learning_rate": 1.7748954688966638e-05,
      "loss": 0.0018,
      "step": 75590
    },
    {
      "epoch": 6.45106237733595,
      "grad_norm": 0.22512651979923248,
      "learning_rate": 1.7744688113320252e-05,
      "loss": 0.0017,
      "step": 75600
    },
    {
      "epoch": 6.451915692465227,
      "grad_norm": 0.19482970237731934,
      "learning_rate": 1.7740421537673863e-05,
      "loss": 0.0018,
      "step": 75610
    },
    {
      "epoch": 6.452769007594505,
      "grad_norm": 0.29525238275527954,
      "learning_rate": 1.7736154962027477e-05,
      "loss": 0.0017,
      "step": 75620
    },
    {
      "epoch": 6.453622322723782,
      "grad_norm": 0.18372642993927002,
      "learning_rate": 1.773188838638109e-05,
      "loss": 0.0019,
      "step": 75630
    },
    {
      "epoch": 6.454475637853059,
      "grad_norm": 0.03685804456472397,
      "learning_rate": 1.7727621810734706e-05,
      "loss": 0.0013,
      "step": 75640
    },
    {
      "epoch": 6.455328952982336,
      "grad_norm": 0.34824037551879883,
      "learning_rate": 1.7723355235088317e-05,
      "loss": 0.0016,
      "step": 75650
    },
    {
      "epoch": 6.456182268111614,
      "grad_norm": 0.05208244547247887,
      "learning_rate": 1.771908865944193e-05,
      "loss": 0.0014,
      "step": 75660
    },
    {
      "epoch": 6.4570355832408906,
      "grad_norm": 0.20698820054531097,
      "learning_rate": 1.7714822083795545e-05,
      "loss": 0.0021,
      "step": 75670
    },
    {
      "epoch": 6.457888898370168,
      "grad_norm": 0.2953319251537323,
      "learning_rate": 1.771055550814916e-05,
      "loss": 0.0015,
      "step": 75680
    },
    {
      "epoch": 6.458742213499446,
      "grad_norm": 0.043731819838285446,
      "learning_rate": 1.7706288932502774e-05,
      "loss": 0.0016,
      "step": 75690
    },
    {
      "epoch": 6.459595528628722,
      "grad_norm": 0.24180155992507935,
      "learning_rate": 1.7702022356856388e-05,
      "loss": 0.0013,
      "step": 75700
    },
    {
      "epoch": 6.460448843758,
      "grad_norm": 0.35054025053977966,
      "learning_rate": 1.7697755781210002e-05,
      "loss": 0.0016,
      "step": 75710
    },
    {
      "epoch": 6.461302158887277,
      "grad_norm": 0.30924731492996216,
      "learning_rate": 1.7693489205563616e-05,
      "loss": 0.0018,
      "step": 75720
    },
    {
      "epoch": 6.462155474016554,
      "grad_norm": 0.30870187282562256,
      "learning_rate": 1.768922262991723e-05,
      "loss": 0.0016,
      "step": 75730
    },
    {
      "epoch": 6.463008789145832,
      "grad_norm": 0.14830929040908813,
      "learning_rate": 1.768495605427084e-05,
      "loss": 0.0016,
      "step": 75740
    },
    {
      "epoch": 6.463862104275109,
      "grad_norm": 0.11357364803552628,
      "learning_rate": 1.7680689478624456e-05,
      "loss": 0.0023,
      "step": 75750
    },
    {
      "epoch": 6.464715419404386,
      "grad_norm": 0.29035890102386475,
      "learning_rate": 1.767642290297807e-05,
      "loss": 0.002,
      "step": 75760
    },
    {
      "epoch": 6.465568734533663,
      "grad_norm": 0.41775190830230713,
      "learning_rate": 1.7672156327331684e-05,
      "loss": 0.0021,
      "step": 75770
    },
    {
      "epoch": 6.46642204966294,
      "grad_norm": 0.33002984523773193,
      "learning_rate": 1.76678897516853e-05,
      "loss": 0.0016,
      "step": 75780
    },
    {
      "epoch": 6.467275364792218,
      "grad_norm": 0.14745506644248962,
      "learning_rate": 1.7663623176038913e-05,
      "loss": 0.0018,
      "step": 75790
    },
    {
      "epoch": 6.468128679921495,
      "grad_norm": 0.16442805528640747,
      "learning_rate": 1.7659356600392527e-05,
      "loss": 0.0014,
      "step": 75800
    },
    {
      "epoch": 6.468981995050772,
      "grad_norm": 0.16888561844825745,
      "learning_rate": 1.765509002474614e-05,
      "loss": 0.0018,
      "step": 75810
    },
    {
      "epoch": 6.469835310180049,
      "grad_norm": 0.042634692043066025,
      "learning_rate": 1.7650823449099755e-05,
      "loss": 0.0014,
      "step": 75820
    },
    {
      "epoch": 6.470688625309327,
      "grad_norm": 0.09619569778442383,
      "learning_rate": 1.764655687345337e-05,
      "loss": 0.0019,
      "step": 75830
    },
    {
      "epoch": 6.471541940438604,
      "grad_norm": 0.18183846771717072,
      "learning_rate": 1.764229029780698e-05,
      "loss": 0.0018,
      "step": 75840
    },
    {
      "epoch": 6.472395255567881,
      "grad_norm": 0.14892341196537018,
      "learning_rate": 1.7638023722160595e-05,
      "loss": 0.002,
      "step": 75850
    },
    {
      "epoch": 6.473248570697159,
      "grad_norm": 0.03321874886751175,
      "learning_rate": 1.763375714651421e-05,
      "loss": 0.0019,
      "step": 75860
    },
    {
      "epoch": 6.474101885826435,
      "grad_norm": 0.09375052154064178,
      "learning_rate": 1.762949057086782e-05,
      "loss": 0.0017,
      "step": 75870
    },
    {
      "epoch": 6.474955200955713,
      "grad_norm": 0.03672701120376587,
      "learning_rate": 1.7625223995221434e-05,
      "loss": 0.002,
      "step": 75880
    },
    {
      "epoch": 6.4758085160849905,
      "grad_norm": 0.33573922514915466,
      "learning_rate": 1.7620957419575048e-05,
      "loss": 0.0018,
      "step": 75890
    },
    {
      "epoch": 6.476661831214267,
      "grad_norm": 0.12814755737781525,
      "learning_rate": 1.7616690843928663e-05,
      "loss": 0.0017,
      "step": 75900
    },
    {
      "epoch": 6.477515146343545,
      "grad_norm": 0.31571829319000244,
      "learning_rate": 1.7612424268282277e-05,
      "loss": 0.0016,
      "step": 75910
    },
    {
      "epoch": 6.478368461472822,
      "grad_norm": 0.09497688710689545,
      "learning_rate": 1.760815769263589e-05,
      "loss": 0.0018,
      "step": 75920
    },
    {
      "epoch": 6.479221776602099,
      "grad_norm": 0.21959036588668823,
      "learning_rate": 1.7603891116989505e-05,
      "loss": 0.0016,
      "step": 75930
    },
    {
      "epoch": 6.4800750917313765,
      "grad_norm": 0.023306699469685555,
      "learning_rate": 1.759962454134312e-05,
      "loss": 0.0018,
      "step": 75940
    },
    {
      "epoch": 6.480928406860654,
      "grad_norm": 0.13547180593013763,
      "learning_rate": 1.7595357965696734e-05,
      "loss": 0.0019,
      "step": 75950
    },
    {
      "epoch": 6.481781721989931,
      "grad_norm": 0.11355271190404892,
      "learning_rate": 1.7591091390050345e-05,
      "loss": 0.0019,
      "step": 75960
    },
    {
      "epoch": 6.482635037119208,
      "grad_norm": 0.039474744349718094,
      "learning_rate": 1.758682481440396e-05,
      "loss": 0.002,
      "step": 75970
    },
    {
      "epoch": 6.483488352248485,
      "grad_norm": 0.09836280345916748,
      "learning_rate": 1.7582558238757573e-05,
      "loss": 0.0017,
      "step": 75980
    },
    {
      "epoch": 6.4843416673777625,
      "grad_norm": 0.21327807009220123,
      "learning_rate": 1.7578291663111187e-05,
      "loss": 0.0015,
      "step": 75990
    },
    {
      "epoch": 6.48519498250704,
      "grad_norm": 0.2750664949417114,
      "learning_rate": 1.75740250874648e-05,
      "loss": 0.0014,
      "step": 76000
    },
    {
      "epoch": 6.486048297636317,
      "grad_norm": 0.1278216689825058,
      "learning_rate": 1.7569758511818416e-05,
      "loss": 0.002,
      "step": 76010
    },
    {
      "epoch": 6.486901612765594,
      "grad_norm": 0.018397662788629532,
      "learning_rate": 1.756549193617203e-05,
      "loss": 0.0017,
      "step": 76020
    },
    {
      "epoch": 6.487754927894872,
      "grad_norm": 0.17132851481437683,
      "learning_rate": 1.7561225360525644e-05,
      "loss": 0.0015,
      "step": 76030
    },
    {
      "epoch": 6.4886082430241485,
      "grad_norm": 0.5261930823326111,
      "learning_rate": 1.755695878487926e-05,
      "loss": 0.0018,
      "step": 76040
    },
    {
      "epoch": 6.489461558153426,
      "grad_norm": 0.03328549861907959,
      "learning_rate": 1.755269220923287e-05,
      "loss": 0.0017,
      "step": 76050
    },
    {
      "epoch": 6.490314873282704,
      "grad_norm": 0.12899813055992126,
      "learning_rate": 1.7548425633586484e-05,
      "loss": 0.0016,
      "step": 76060
    },
    {
      "epoch": 6.49116818841198,
      "grad_norm": 0.3117285668849945,
      "learning_rate": 1.7544159057940098e-05,
      "loss": 0.0018,
      "step": 76070
    },
    {
      "epoch": 6.492021503541258,
      "grad_norm": 0.11479820311069489,
      "learning_rate": 1.7539892482293712e-05,
      "loss": 0.0016,
      "step": 76080
    },
    {
      "epoch": 6.492874818670535,
      "grad_norm": 0.0849737599492073,
      "learning_rate": 1.7535625906647326e-05,
      "loss": 0.0017,
      "step": 76090
    },
    {
      "epoch": 6.493728133799812,
      "grad_norm": 0.04486207664012909,
      "learning_rate": 1.753135933100094e-05,
      "loss": 0.0016,
      "step": 76100
    },
    {
      "epoch": 6.49458144892909,
      "grad_norm": 0.13205453753471375,
      "learning_rate": 1.7527092755354555e-05,
      "loss": 0.0021,
      "step": 76110
    },
    {
      "epoch": 6.495434764058366,
      "grad_norm": 0.14841435849666595,
      "learning_rate": 1.752282617970817e-05,
      "loss": 0.002,
      "step": 76120
    },
    {
      "epoch": 6.496288079187644,
      "grad_norm": 0.2005363255739212,
      "learning_rate": 1.7518559604061783e-05,
      "loss": 0.0017,
      "step": 76130
    },
    {
      "epoch": 6.497141394316921,
      "grad_norm": 0.18159955739974976,
      "learning_rate": 1.7514293028415394e-05,
      "loss": 0.0021,
      "step": 76140
    },
    {
      "epoch": 6.497994709446198,
      "grad_norm": 0.07894401997327805,
      "learning_rate": 1.751002645276901e-05,
      "loss": 0.0018,
      "step": 76150
    },
    {
      "epoch": 6.498848024575476,
      "grad_norm": 0.13088251650333405,
      "learning_rate": 1.7505759877122623e-05,
      "loss": 0.0021,
      "step": 76160
    },
    {
      "epoch": 6.499701339704753,
      "grad_norm": 0.04860449209809303,
      "learning_rate": 1.7501493301476233e-05,
      "loss": 0.0019,
      "step": 76170
    },
    {
      "epoch": 6.50055465483403,
      "grad_norm": 0.43243607878685,
      "learning_rate": 1.7497226725829848e-05,
      "loss": 0.0021,
      "step": 76180
    },
    {
      "epoch": 6.501407969963307,
      "grad_norm": 0.2049085646867752,
      "learning_rate": 1.7492960150183462e-05,
      "loss": 0.002,
      "step": 76190
    },
    {
      "epoch": 6.502261285092585,
      "grad_norm": 0.2025943100452423,
      "learning_rate": 1.7488693574537076e-05,
      "loss": 0.0018,
      "step": 76200
    },
    {
      "epoch": 6.503114600221862,
      "grad_norm": 0.061766475439071655,
      "learning_rate": 1.748442699889069e-05,
      "loss": 0.0017,
      "step": 76210
    },
    {
      "epoch": 6.503967915351139,
      "grad_norm": 0.2804569900035858,
      "learning_rate": 1.7480160423244305e-05,
      "loss": 0.0016,
      "step": 76220
    },
    {
      "epoch": 6.504821230480417,
      "grad_norm": 0.2880711853504181,
      "learning_rate": 1.747589384759792e-05,
      "loss": 0.002,
      "step": 76230
    },
    {
      "epoch": 6.505674545609693,
      "grad_norm": 0.23989872634410858,
      "learning_rate": 1.7471627271951533e-05,
      "loss": 0.0018,
      "step": 76240
    },
    {
      "epoch": 6.506527860738971,
      "grad_norm": 0.11178369075059891,
      "learning_rate": 1.7467360696305147e-05,
      "loss": 0.0017,
      "step": 76250
    },
    {
      "epoch": 6.5073811758682485,
      "grad_norm": 0.3078921437263489,
      "learning_rate": 1.746309412065876e-05,
      "loss": 0.0016,
      "step": 76260
    },
    {
      "epoch": 6.508234490997525,
      "grad_norm": 0.38948479294776917,
      "learning_rate": 1.7458827545012373e-05,
      "loss": 0.0018,
      "step": 76270
    },
    {
      "epoch": 6.509087806126803,
      "grad_norm": 0.18436437845230103,
      "learning_rate": 1.7454560969365987e-05,
      "loss": 0.0015,
      "step": 76280
    },
    {
      "epoch": 6.50994112125608,
      "grad_norm": 0.5845155715942383,
      "learning_rate": 1.74502943937196e-05,
      "loss": 0.0017,
      "step": 76290
    },
    {
      "epoch": 6.510794436385357,
      "grad_norm": 0.31157952547073364,
      "learning_rate": 1.7446027818073215e-05,
      "loss": 0.0017,
      "step": 76300
    },
    {
      "epoch": 6.5116477515146345,
      "grad_norm": 0.16902591288089752,
      "learning_rate": 1.744176124242683e-05,
      "loss": 0.0022,
      "step": 76310
    },
    {
      "epoch": 6.512501066643912,
      "grad_norm": 0.0733734741806984,
      "learning_rate": 1.7437494666780444e-05,
      "loss": 0.0017,
      "step": 76320
    },
    {
      "epoch": 6.513354381773189,
      "grad_norm": 0.23483823239803314,
      "learning_rate": 1.7433228091134058e-05,
      "loss": 0.0019,
      "step": 76330
    },
    {
      "epoch": 6.514207696902466,
      "grad_norm": 0.304231196641922,
      "learning_rate": 1.7428961515487672e-05,
      "loss": 0.0022,
      "step": 76340
    },
    {
      "epoch": 6.515061012031744,
      "grad_norm": 0.07908511161804199,
      "learning_rate": 1.7424694939841286e-05,
      "loss": 0.0021,
      "step": 76350
    },
    {
      "epoch": 6.5159143271610205,
      "grad_norm": 0.2916988730430603,
      "learning_rate": 1.74204283641949e-05,
      "loss": 0.0015,
      "step": 76360
    },
    {
      "epoch": 6.516767642290298,
      "grad_norm": 0.18317720293998718,
      "learning_rate": 1.741616178854851e-05,
      "loss": 0.002,
      "step": 76370
    },
    {
      "epoch": 6.517620957419575,
      "grad_norm": 0.3137502074241638,
      "learning_rate": 1.7411895212902126e-05,
      "loss": 0.0017,
      "step": 76380
    },
    {
      "epoch": 6.518474272548852,
      "grad_norm": 0.4594320058822632,
      "learning_rate": 1.740762863725574e-05,
      "loss": 0.0013,
      "step": 76390
    },
    {
      "epoch": 6.51932758767813,
      "grad_norm": 0.040324337780475616,
      "learning_rate": 1.740336206160935e-05,
      "loss": 0.0019,
      "step": 76400
    },
    {
      "epoch": 6.5201809028074065,
      "grad_norm": 0.2907021641731262,
      "learning_rate": 1.7399095485962965e-05,
      "loss": 0.0023,
      "step": 76410
    },
    {
      "epoch": 6.521034217936684,
      "grad_norm": 0.057658787816762924,
      "learning_rate": 1.739482891031658e-05,
      "loss": 0.0019,
      "step": 76420
    },
    {
      "epoch": 6.521887533065962,
      "grad_norm": 0.06055052950978279,
      "learning_rate": 1.7390562334670194e-05,
      "loss": 0.0015,
      "step": 76430
    },
    {
      "epoch": 6.522740848195238,
      "grad_norm": 0.07472490519285202,
      "learning_rate": 1.7386295759023808e-05,
      "loss": 0.0018,
      "step": 76440
    },
    {
      "epoch": 6.523594163324516,
      "grad_norm": 0.1517224907875061,
      "learning_rate": 1.7382029183377422e-05,
      "loss": 0.0015,
      "step": 76450
    },
    {
      "epoch": 6.524447478453793,
      "grad_norm": 0.06050926074385643,
      "learning_rate": 1.7377762607731036e-05,
      "loss": 0.0015,
      "step": 76460
    },
    {
      "epoch": 6.52530079358307,
      "grad_norm": 0.12999844551086426,
      "learning_rate": 1.737349603208465e-05,
      "loss": 0.002,
      "step": 76470
    },
    {
      "epoch": 6.526154108712348,
      "grad_norm": 0.054866284132003784,
      "learning_rate": 1.736922945643826e-05,
      "loss": 0.0017,
      "step": 76480
    },
    {
      "epoch": 6.527007423841624,
      "grad_norm": 0.0602232962846756,
      "learning_rate": 1.7364962880791876e-05,
      "loss": 0.0017,
      "step": 76490
    },
    {
      "epoch": 6.527860738970902,
      "grad_norm": 0.0755656510591507,
      "learning_rate": 1.736069630514549e-05,
      "loss": 0.0015,
      "step": 76500
    },
    {
      "epoch": 6.528714054100179,
      "grad_norm": 0.059586022049188614,
      "learning_rate": 1.7356429729499104e-05,
      "loss": 0.0017,
      "step": 76510
    },
    {
      "epoch": 6.529567369229456,
      "grad_norm": 0.03990614786744118,
      "learning_rate": 1.735216315385272e-05,
      "loss": 0.0021,
      "step": 76520
    },
    {
      "epoch": 6.530420684358734,
      "grad_norm": 0.29278719425201416,
      "learning_rate": 1.7347896578206333e-05,
      "loss": 0.0016,
      "step": 76530
    },
    {
      "epoch": 6.531273999488011,
      "grad_norm": 0.04624595120549202,
      "learning_rate": 1.7343630002559947e-05,
      "loss": 0.0015,
      "step": 76540
    },
    {
      "epoch": 6.532127314617288,
      "grad_norm": 0.06716728210449219,
      "learning_rate": 1.733936342691356e-05,
      "loss": 0.0016,
      "step": 76550
    },
    {
      "epoch": 6.532980629746565,
      "grad_norm": 0.29765450954437256,
      "learning_rate": 1.7335096851267175e-05,
      "loss": 0.0018,
      "step": 76560
    },
    {
      "epoch": 6.533833944875843,
      "grad_norm": 0.23702405393123627,
      "learning_rate": 1.733083027562079e-05,
      "loss": 0.0018,
      "step": 76570
    },
    {
      "epoch": 6.53468726000512,
      "grad_norm": 0.09306002408266068,
      "learning_rate": 1.73265636999744e-05,
      "loss": 0.0014,
      "step": 76580
    },
    {
      "epoch": 6.535540575134397,
      "grad_norm": 0.15442460775375366,
      "learning_rate": 1.7322297124328015e-05,
      "loss": 0.0016,
      "step": 76590
    },
    {
      "epoch": 6.536393890263675,
      "grad_norm": 0.028482995927333832,
      "learning_rate": 1.731803054868163e-05,
      "loss": 0.002,
      "step": 76600
    },
    {
      "epoch": 6.537247205392951,
      "grad_norm": 0.2393173724412918,
      "learning_rate": 1.7313763973035243e-05,
      "loss": 0.0015,
      "step": 76610
    },
    {
      "epoch": 6.538100520522229,
      "grad_norm": 0.25966596603393555,
      "learning_rate": 1.7309497397388857e-05,
      "loss": 0.0017,
      "step": 76620
    },
    {
      "epoch": 6.5389538356515065,
      "grad_norm": 0.052284590899944305,
      "learning_rate": 1.730523082174247e-05,
      "loss": 0.0018,
      "step": 76630
    },
    {
      "epoch": 6.539807150780783,
      "grad_norm": 0.3092013895511627,
      "learning_rate": 1.7300964246096086e-05,
      "loss": 0.0017,
      "step": 76640
    },
    {
      "epoch": 6.540660465910061,
      "grad_norm": 0.4376440942287445,
      "learning_rate": 1.72966976704497e-05,
      "loss": 0.0021,
      "step": 76650
    },
    {
      "epoch": 6.541513781039338,
      "grad_norm": 0.15324048697948456,
      "learning_rate": 1.7292431094803314e-05,
      "loss": 0.0015,
      "step": 76660
    },
    {
      "epoch": 6.542367096168615,
      "grad_norm": 0.1864439845085144,
      "learning_rate": 1.7288164519156925e-05,
      "loss": 0.002,
      "step": 76670
    },
    {
      "epoch": 6.5432204112978924,
      "grad_norm": 0.14863072335720062,
      "learning_rate": 1.728389794351054e-05,
      "loss": 0.0016,
      "step": 76680
    },
    {
      "epoch": 6.54407372642717,
      "grad_norm": 0.09649650007486343,
      "learning_rate": 1.727963136786415e-05,
      "loss": 0.0016,
      "step": 76690
    },
    {
      "epoch": 6.544927041556447,
      "grad_norm": 0.20314408838748932,
      "learning_rate": 1.7275364792217765e-05,
      "loss": 0.0018,
      "step": 76700
    },
    {
      "epoch": 6.545780356685724,
      "grad_norm": 0.057448890060186386,
      "learning_rate": 1.727109821657138e-05,
      "loss": 0.0019,
      "step": 76710
    },
    {
      "epoch": 6.546633671815002,
      "grad_norm": 0.21956400573253632,
      "learning_rate": 1.7266831640924993e-05,
      "loss": 0.0013,
      "step": 76720
    },
    {
      "epoch": 6.547486986944278,
      "grad_norm": 0.21852125227451324,
      "learning_rate": 1.7262565065278607e-05,
      "loss": 0.0019,
      "step": 76730
    },
    {
      "epoch": 6.548340302073556,
      "grad_norm": 0.265755832195282,
      "learning_rate": 1.725829848963222e-05,
      "loss": 0.0018,
      "step": 76740
    },
    {
      "epoch": 6.549193617202833,
      "grad_norm": 0.1327764391899109,
      "learning_rate": 1.7254031913985836e-05,
      "loss": 0.0019,
      "step": 76750
    },
    {
      "epoch": 6.55004693233211,
      "grad_norm": 0.03427407890558243,
      "learning_rate": 1.724976533833945e-05,
      "loss": 0.0015,
      "step": 76760
    },
    {
      "epoch": 6.550900247461388,
      "grad_norm": 0.16202658414840698,
      "learning_rate": 1.7245498762693064e-05,
      "loss": 0.0019,
      "step": 76770
    },
    {
      "epoch": 6.551753562590664,
      "grad_norm": 0.20093245804309845,
      "learning_rate": 1.724123218704668e-05,
      "loss": 0.0014,
      "step": 76780
    },
    {
      "epoch": 6.552606877719942,
      "grad_norm": 0.2078074961900711,
      "learning_rate": 1.723696561140029e-05,
      "loss": 0.0016,
      "step": 76790
    },
    {
      "epoch": 6.5534601928492195,
      "grad_norm": 0.1825665831565857,
      "learning_rate": 1.7232699035753904e-05,
      "loss": 0.0014,
      "step": 76800
    },
    {
      "epoch": 6.554313507978496,
      "grad_norm": 0.20645751059055328,
      "learning_rate": 1.7228432460107518e-05,
      "loss": 0.0017,
      "step": 76810
    },
    {
      "epoch": 6.555166823107774,
      "grad_norm": 0.22095200419425964,
      "learning_rate": 1.7224165884461132e-05,
      "loss": 0.0018,
      "step": 76820
    },
    {
      "epoch": 6.556020138237051,
      "grad_norm": 0.13017666339874268,
      "learning_rate": 1.7219899308814746e-05,
      "loss": 0.002,
      "step": 76830
    },
    {
      "epoch": 6.556873453366328,
      "grad_norm": 0.2516200542449951,
      "learning_rate": 1.721563273316836e-05,
      "loss": 0.0016,
      "step": 76840
    },
    {
      "epoch": 6.5577267684956055,
      "grad_norm": 0.18397055566310883,
      "learning_rate": 1.7211366157521975e-05,
      "loss": 0.0015,
      "step": 76850
    },
    {
      "epoch": 6.558580083624882,
      "grad_norm": 0.2577533721923828,
      "learning_rate": 1.720709958187559e-05,
      "loss": 0.0018,
      "step": 76860
    },
    {
      "epoch": 6.55943339875416,
      "grad_norm": 0.035504814237356186,
      "learning_rate": 1.7202833006229203e-05,
      "loss": 0.002,
      "step": 76870
    },
    {
      "epoch": 6.560286713883437,
      "grad_norm": 0.049498047679662704,
      "learning_rate": 1.7198566430582817e-05,
      "loss": 0.0016,
      "step": 76880
    },
    {
      "epoch": 6.561140029012714,
      "grad_norm": 0.12589718401432037,
      "learning_rate": 1.719429985493643e-05,
      "loss": 0.0016,
      "step": 76890
    },
    {
      "epoch": 6.5619933441419915,
      "grad_norm": 0.13313113152980804,
      "learning_rate": 1.7190033279290043e-05,
      "loss": 0.0021,
      "step": 76900
    },
    {
      "epoch": 6.562846659271269,
      "grad_norm": 0.05025916174054146,
      "learning_rate": 1.7185766703643657e-05,
      "loss": 0.0018,
      "step": 76910
    },
    {
      "epoch": 6.563699974400546,
      "grad_norm": 0.21419653296470642,
      "learning_rate": 1.718150012799727e-05,
      "loss": 0.0019,
      "step": 76920
    },
    {
      "epoch": 6.564553289529823,
      "grad_norm": 0.08464483171701431,
      "learning_rate": 1.7177233552350885e-05,
      "loss": 0.0016,
      "step": 76930
    },
    {
      "epoch": 6.565406604659101,
      "grad_norm": 0.2754032015800476,
      "learning_rate": 1.7172966976704496e-05,
      "loss": 0.0017,
      "step": 76940
    },
    {
      "epoch": 6.5662599197883775,
      "grad_norm": 0.27385830879211426,
      "learning_rate": 1.716870040105811e-05,
      "loss": 0.0017,
      "step": 76950
    },
    {
      "epoch": 6.567113234917655,
      "grad_norm": 0.6012551188468933,
      "learning_rate": 1.7164433825411725e-05,
      "loss": 0.0016,
      "step": 76960
    },
    {
      "epoch": 6.567966550046933,
      "grad_norm": 0.031065229326486588,
      "learning_rate": 1.716016724976534e-05,
      "loss": 0.002,
      "step": 76970
    },
    {
      "epoch": 6.568819865176209,
      "grad_norm": 0.179538756608963,
      "learning_rate": 1.7155900674118953e-05,
      "loss": 0.0017,
      "step": 76980
    },
    {
      "epoch": 6.569673180305487,
      "grad_norm": 0.23999716341495514,
      "learning_rate": 1.7151634098472567e-05,
      "loss": 0.0017,
      "step": 76990
    },
    {
      "epoch": 6.570526495434764,
      "grad_norm": 0.03468361869454384,
      "learning_rate": 1.7147367522826178e-05,
      "loss": 0.002,
      "step": 77000
    },
    {
      "epoch": 6.571379810564041,
      "grad_norm": 0.10099378228187561,
      "learning_rate": 1.7143100947179792e-05,
      "loss": 0.0018,
      "step": 77010
    },
    {
      "epoch": 6.572233125693319,
      "grad_norm": 0.24119415879249573,
      "learning_rate": 1.7138834371533407e-05,
      "loss": 0.0019,
      "step": 77020
    },
    {
      "epoch": 6.573086440822596,
      "grad_norm": 0.057078976184129715,
      "learning_rate": 1.713456779588702e-05,
      "loss": 0.0014,
      "step": 77030
    },
    {
      "epoch": 6.573939755951873,
      "grad_norm": 0.1973695009946823,
      "learning_rate": 1.7130301220240635e-05,
      "loss": 0.0014,
      "step": 77040
    },
    {
      "epoch": 6.57479307108115,
      "grad_norm": 0.1621374636888504,
      "learning_rate": 1.712603464459425e-05,
      "loss": 0.0017,
      "step": 77050
    },
    {
      "epoch": 6.575646386210428,
      "grad_norm": 0.19925765693187714,
      "learning_rate": 1.7121768068947864e-05,
      "loss": 0.0021,
      "step": 77060
    },
    {
      "epoch": 6.576499701339705,
      "grad_norm": 0.06041361764073372,
      "learning_rate": 1.7117501493301478e-05,
      "loss": 0.0018,
      "step": 77070
    },
    {
      "epoch": 6.577353016468982,
      "grad_norm": 0.21660231053829193,
      "learning_rate": 1.7113234917655092e-05,
      "loss": 0.002,
      "step": 77080
    },
    {
      "epoch": 6.578206331598259,
      "grad_norm": 0.04418593645095825,
      "learning_rate": 1.7108968342008706e-05,
      "loss": 0.0019,
      "step": 77090
    },
    {
      "epoch": 6.579059646727536,
      "grad_norm": 0.29860666394233704,
      "learning_rate": 1.7104701766362317e-05,
      "loss": 0.0026,
      "step": 77100
    },
    {
      "epoch": 6.579912961856814,
      "grad_norm": 0.0811753123998642,
      "learning_rate": 1.710043519071593e-05,
      "loss": 0.0016,
      "step": 77110
    },
    {
      "epoch": 6.580766276986091,
      "grad_norm": 0.05519001558423042,
      "learning_rate": 1.7096168615069546e-05,
      "loss": 0.0022,
      "step": 77120
    },
    {
      "epoch": 6.581619592115368,
      "grad_norm": 0.22693222761154175,
      "learning_rate": 1.709190203942316e-05,
      "loss": 0.0021,
      "step": 77130
    },
    {
      "epoch": 6.582472907244646,
      "grad_norm": 0.09713707119226456,
      "learning_rate": 1.7087635463776774e-05,
      "loss": 0.0015,
      "step": 77140
    },
    {
      "epoch": 6.583326222373922,
      "grad_norm": 0.04714849591255188,
      "learning_rate": 1.708336888813039e-05,
      "loss": 0.0018,
      "step": 77150
    },
    {
      "epoch": 6.5841795375032,
      "grad_norm": 0.26558783650398254,
      "learning_rate": 1.7079102312484003e-05,
      "loss": 0.0017,
      "step": 77160
    },
    {
      "epoch": 6.5850328526324775,
      "grad_norm": 0.09715954959392548,
      "learning_rate": 1.7074835736837617e-05,
      "loss": 0.0016,
      "step": 77170
    },
    {
      "epoch": 6.585886167761754,
      "grad_norm": 0.08109116554260254,
      "learning_rate": 1.707056916119123e-05,
      "loss": 0.0022,
      "step": 77180
    },
    {
      "epoch": 6.586739482891032,
      "grad_norm": 0.21683193743228912,
      "learning_rate": 1.7066302585544845e-05,
      "loss": 0.0016,
      "step": 77190
    },
    {
      "epoch": 6.587592798020309,
      "grad_norm": 0.151822030544281,
      "learning_rate": 1.7062036009898456e-05,
      "loss": 0.0018,
      "step": 77200
    },
    {
      "epoch": 6.588446113149586,
      "grad_norm": 0.0613095685839653,
      "learning_rate": 1.705776943425207e-05,
      "loss": 0.002,
      "step": 77210
    },
    {
      "epoch": 6.5892994282788635,
      "grad_norm": 0.035295624285936356,
      "learning_rate": 1.705350285860568e-05,
      "loss": 0.0021,
      "step": 77220
    },
    {
      "epoch": 6.59015274340814,
      "grad_norm": 0.11279725283384323,
      "learning_rate": 1.7049236282959296e-05,
      "loss": 0.0019,
      "step": 77230
    },
    {
      "epoch": 6.591006058537418,
      "grad_norm": 0.17122885584831238,
      "learning_rate": 1.704496970731291e-05,
      "loss": 0.0017,
      "step": 77240
    },
    {
      "epoch": 6.591859373666695,
      "grad_norm": 0.05615095794200897,
      "learning_rate": 1.7040703131666524e-05,
      "loss": 0.0014,
      "step": 77250
    },
    {
      "epoch": 6.592712688795972,
      "grad_norm": 0.11691213399171829,
      "learning_rate": 1.703643655602014e-05,
      "loss": 0.0021,
      "step": 77260
    },
    {
      "epoch": 6.5935660039252495,
      "grad_norm": 0.36438608169555664,
      "learning_rate": 1.7032169980373753e-05,
      "loss": 0.0019,
      "step": 77270
    },
    {
      "epoch": 6.594419319054527,
      "grad_norm": 0.045539166778326035,
      "learning_rate": 1.7027903404727367e-05,
      "loss": 0.0018,
      "step": 77280
    },
    {
      "epoch": 6.595272634183804,
      "grad_norm": 0.0633079931139946,
      "learning_rate": 1.702363682908098e-05,
      "loss": 0.0017,
      "step": 77290
    },
    {
      "epoch": 6.596125949313081,
      "grad_norm": 0.4868122637271881,
      "learning_rate": 1.7019370253434595e-05,
      "loss": 0.0028,
      "step": 77300
    },
    {
      "epoch": 6.596979264442359,
      "grad_norm": 0.049916137009859085,
      "learning_rate": 1.7015103677788206e-05,
      "loss": 0.0021,
      "step": 77310
    },
    {
      "epoch": 6.5978325795716355,
      "grad_norm": 0.09283284097909927,
      "learning_rate": 1.701083710214182e-05,
      "loss": 0.0016,
      "step": 77320
    },
    {
      "epoch": 6.598685894700913,
      "grad_norm": 0.08030648529529572,
      "learning_rate": 1.7006570526495435e-05,
      "loss": 0.0021,
      "step": 77330
    },
    {
      "epoch": 6.599539209830191,
      "grad_norm": 0.11091043800115585,
      "learning_rate": 1.700230395084905e-05,
      "loss": 0.0016,
      "step": 77340
    },
    {
      "epoch": 6.600392524959467,
      "grad_norm": 0.10843959450721741,
      "learning_rate": 1.6998037375202663e-05,
      "loss": 0.0019,
      "step": 77350
    },
    {
      "epoch": 6.601245840088745,
      "grad_norm": 0.047927625477313995,
      "learning_rate": 1.6993770799556277e-05,
      "loss": 0.0017,
      "step": 77360
    },
    {
      "epoch": 6.602099155218022,
      "grad_norm": 0.15252745151519775,
      "learning_rate": 1.698950422390989e-05,
      "loss": 0.0017,
      "step": 77370
    },
    {
      "epoch": 6.602952470347299,
      "grad_norm": 0.34895479679107666,
      "learning_rate": 1.6985237648263506e-05,
      "loss": 0.0016,
      "step": 77380
    },
    {
      "epoch": 6.603805785476577,
      "grad_norm": 0.349706768989563,
      "learning_rate": 1.698097107261712e-05,
      "loss": 0.0018,
      "step": 77390
    },
    {
      "epoch": 6.604659100605854,
      "grad_norm": 0.1653021275997162,
      "learning_rate": 1.6976704496970734e-05,
      "loss": 0.0015,
      "step": 77400
    },
    {
      "epoch": 6.605512415735131,
      "grad_norm": 0.04021947830915451,
      "learning_rate": 1.6972437921324345e-05,
      "loss": 0.0022,
      "step": 77410
    },
    {
      "epoch": 6.606365730864408,
      "grad_norm": 0.14933519065380096,
      "learning_rate": 1.696817134567796e-05,
      "loss": 0.0022,
      "step": 77420
    },
    {
      "epoch": 6.607219045993686,
      "grad_norm": 0.16802901029586792,
      "learning_rate": 1.6963904770031574e-05,
      "loss": 0.0019,
      "step": 77430
    },
    {
      "epoch": 6.608072361122963,
      "grad_norm": 0.3634454309940338,
      "learning_rate": 1.6959638194385188e-05,
      "loss": 0.002,
      "step": 77440
    },
    {
      "epoch": 6.60892567625224,
      "grad_norm": 0.14427971839904785,
      "learning_rate": 1.6955371618738802e-05,
      "loss": 0.002,
      "step": 77450
    },
    {
      "epoch": 6.609778991381517,
      "grad_norm": 0.31587696075439453,
      "learning_rate": 1.6951105043092416e-05,
      "loss": 0.0017,
      "step": 77460
    },
    {
      "epoch": 6.610632306510794,
      "grad_norm": 0.22386349737644196,
      "learning_rate": 1.6946838467446027e-05,
      "loss": 0.0014,
      "step": 77470
    },
    {
      "epoch": 6.611485621640072,
      "grad_norm": 0.20666995644569397,
      "learning_rate": 1.694257189179964e-05,
      "loss": 0.0018,
      "step": 77480
    },
    {
      "epoch": 6.612338936769349,
      "grad_norm": 0.31348398327827454,
      "learning_rate": 1.6938305316153256e-05,
      "loss": 0.0021,
      "step": 77490
    },
    {
      "epoch": 6.613192251898626,
      "grad_norm": 0.11151877045631409,
      "learning_rate": 1.693403874050687e-05,
      "loss": 0.0016,
      "step": 77500
    },
    {
      "epoch": 6.614045567027904,
      "grad_norm": 0.14796625077724457,
      "learning_rate": 1.6929772164860484e-05,
      "loss": 0.002,
      "step": 77510
    },
    {
      "epoch": 6.61489888215718,
      "grad_norm": 0.23851117491722107,
      "learning_rate": 1.69255055892141e-05,
      "loss": 0.0018,
      "step": 77520
    },
    {
      "epoch": 6.615752197286458,
      "grad_norm": 0.05971251055598259,
      "learning_rate": 1.692123901356771e-05,
      "loss": 0.0019,
      "step": 77530
    },
    {
      "epoch": 6.6166055124157355,
      "grad_norm": 0.11542961001396179,
      "learning_rate": 1.6916972437921324e-05,
      "loss": 0.0019,
      "step": 77540
    },
    {
      "epoch": 6.617458827545012,
      "grad_norm": 0.13520853221416473,
      "learning_rate": 1.6912705862274938e-05,
      "loss": 0.0023,
      "step": 77550
    },
    {
      "epoch": 6.61831214267429,
      "grad_norm": 0.1366148442029953,
      "learning_rate": 1.6908439286628552e-05,
      "loss": 0.002,
      "step": 77560
    },
    {
      "epoch": 6.619165457803567,
      "grad_norm": 0.21815097332000732,
      "learning_rate": 1.6904172710982166e-05,
      "loss": 0.0017,
      "step": 77570
    },
    {
      "epoch": 6.620018772932844,
      "grad_norm": 0.05997674539685249,
      "learning_rate": 1.689990613533578e-05,
      "loss": 0.0015,
      "step": 77580
    },
    {
      "epoch": 6.6208720880621215,
      "grad_norm": 0.03793918341398239,
      "learning_rate": 1.6895639559689395e-05,
      "loss": 0.0022,
      "step": 77590
    },
    {
      "epoch": 6.621725403191398,
      "grad_norm": 0.06722454726696014,
      "learning_rate": 1.689137298404301e-05,
      "loss": 0.0015,
      "step": 77600
    },
    {
      "epoch": 6.622578718320676,
      "grad_norm": 0.07374043017625809,
      "learning_rate": 1.6887106408396623e-05,
      "loss": 0.0016,
      "step": 77610
    },
    {
      "epoch": 6.623432033449953,
      "grad_norm": 0.18373848497867584,
      "learning_rate": 1.6882839832750234e-05,
      "loss": 0.0017,
      "step": 77620
    },
    {
      "epoch": 6.62428534857923,
      "grad_norm": 0.14926950633525848,
      "learning_rate": 1.6878573257103848e-05,
      "loss": 0.0013,
      "step": 77630
    },
    {
      "epoch": 6.6251386637085075,
      "grad_norm": 0.2725972533226013,
      "learning_rate": 1.6874306681457463e-05,
      "loss": 0.0016,
      "step": 77640
    },
    {
      "epoch": 6.625991978837785,
      "grad_norm": 0.23915702104568481,
      "learning_rate": 1.6870040105811077e-05,
      "loss": 0.0015,
      "step": 77650
    },
    {
      "epoch": 6.626845293967062,
      "grad_norm": 0.051209986209869385,
      "learning_rate": 1.686577353016469e-05,
      "loss": 0.0018,
      "step": 77660
    },
    {
      "epoch": 6.627698609096339,
      "grad_norm": 0.04167195037007332,
      "learning_rate": 1.6861506954518305e-05,
      "loss": 0.0013,
      "step": 77670
    },
    {
      "epoch": 6.628551924225617,
      "grad_norm": 0.16650114953517914,
      "learning_rate": 1.685724037887192e-05,
      "loss": 0.0017,
      "step": 77680
    },
    {
      "epoch": 6.6294052393548935,
      "grad_norm": 0.23757658898830414,
      "learning_rate": 1.6852973803225534e-05,
      "loss": 0.0017,
      "step": 77690
    },
    {
      "epoch": 6.630258554484171,
      "grad_norm": 0.23650330305099487,
      "learning_rate": 1.6848707227579148e-05,
      "loss": 0.002,
      "step": 77700
    },
    {
      "epoch": 6.631111869613449,
      "grad_norm": 0.3264559805393219,
      "learning_rate": 1.6844440651932762e-05,
      "loss": 0.0023,
      "step": 77710
    },
    {
      "epoch": 6.631965184742725,
      "grad_norm": 0.037288110703229904,
      "learning_rate": 1.6840174076286373e-05,
      "loss": 0.0019,
      "step": 77720
    },
    {
      "epoch": 6.632818499872003,
      "grad_norm": 0.23930469155311584,
      "learning_rate": 1.6835907500639987e-05,
      "loss": 0.0018,
      "step": 77730
    },
    {
      "epoch": 6.63367181500128,
      "grad_norm": 0.1439395546913147,
      "learning_rate": 1.6831640924993598e-05,
      "loss": 0.0016,
      "step": 77740
    },
    {
      "epoch": 6.634525130130557,
      "grad_norm": 0.11062850803136826,
      "learning_rate": 1.6827374349347212e-05,
      "loss": 0.0016,
      "step": 77750
    },
    {
      "epoch": 6.635378445259835,
      "grad_norm": 0.18032720685005188,
      "learning_rate": 1.6823107773700827e-05,
      "loss": 0.0018,
      "step": 77760
    },
    {
      "epoch": 6.636231760389112,
      "grad_norm": 0.03301827609539032,
      "learning_rate": 1.681884119805444e-05,
      "loss": 0.0018,
      "step": 77770
    },
    {
      "epoch": 6.637085075518389,
      "grad_norm": 0.03052675724029541,
      "learning_rate": 1.6814574622408055e-05,
      "loss": 0.0019,
      "step": 77780
    },
    {
      "epoch": 6.637938390647666,
      "grad_norm": 0.1728893369436264,
      "learning_rate": 1.681030804676167e-05,
      "loss": 0.0019,
      "step": 77790
    },
    {
      "epoch": 6.638791705776944,
      "grad_norm": 0.11767707765102386,
      "learning_rate": 1.6806041471115284e-05,
      "loss": 0.0018,
      "step": 77800
    },
    {
      "epoch": 6.6396450209062206,
      "grad_norm": 0.06155629828572273,
      "learning_rate": 1.6801774895468898e-05,
      "loss": 0.0018,
      "step": 77810
    },
    {
      "epoch": 6.640498336035498,
      "grad_norm": 0.06076240912079811,
      "learning_rate": 1.6797508319822512e-05,
      "loss": 0.0017,
      "step": 77820
    },
    {
      "epoch": 6.641351651164775,
      "grad_norm": 0.139219731092453,
      "learning_rate": 1.6793241744176126e-05,
      "loss": 0.0019,
      "step": 77830
    },
    {
      "epoch": 6.642204966294052,
      "grad_norm": 0.14802809059619904,
      "learning_rate": 1.6788975168529737e-05,
      "loss": 0.0017,
      "step": 77840
    },
    {
      "epoch": 6.64305828142333,
      "grad_norm": 0.09159217774868011,
      "learning_rate": 1.678470859288335e-05,
      "loss": 0.0014,
      "step": 77850
    },
    {
      "epoch": 6.6439115965526065,
      "grad_norm": 0.16243314743041992,
      "learning_rate": 1.6780442017236966e-05,
      "loss": 0.0019,
      "step": 77860
    },
    {
      "epoch": 6.644764911681884,
      "grad_norm": 0.03351911902427673,
      "learning_rate": 1.677617544159058e-05,
      "loss": 0.0014,
      "step": 77870
    },
    {
      "epoch": 6.645618226811162,
      "grad_norm": 0.12912344932556152,
      "learning_rate": 1.6771908865944194e-05,
      "loss": 0.002,
      "step": 77880
    },
    {
      "epoch": 6.646471541940438,
      "grad_norm": 0.05883592739701271,
      "learning_rate": 1.676764229029781e-05,
      "loss": 0.0021,
      "step": 77890
    },
    {
      "epoch": 6.647324857069716,
      "grad_norm": 0.33132001757621765,
      "learning_rate": 1.6763375714651423e-05,
      "loss": 0.0018,
      "step": 77900
    },
    {
      "epoch": 6.648178172198993,
      "grad_norm": 0.29035085439682007,
      "learning_rate": 1.6759109139005037e-05,
      "loss": 0.0019,
      "step": 77910
    },
    {
      "epoch": 6.64903148732827,
      "grad_norm": 0.16546109318733215,
      "learning_rate": 1.675484256335865e-05,
      "loss": 0.0021,
      "step": 77920
    },
    {
      "epoch": 6.649884802457548,
      "grad_norm": 0.20396021008491516,
      "learning_rate": 1.6750575987712265e-05,
      "loss": 0.0015,
      "step": 77930
    },
    {
      "epoch": 6.650738117586824,
      "grad_norm": 0.13257509469985962,
      "learning_rate": 1.6746309412065876e-05,
      "loss": 0.0015,
      "step": 77940
    },
    {
      "epoch": 6.651591432716102,
      "grad_norm": 0.11014219373464584,
      "learning_rate": 1.674204283641949e-05,
      "loss": 0.0018,
      "step": 77950
    },
    {
      "epoch": 6.652444747845379,
      "grad_norm": 0.21779583394527435,
      "learning_rate": 1.6737776260773105e-05,
      "loss": 0.0021,
      "step": 77960
    },
    {
      "epoch": 6.653298062974656,
      "grad_norm": 0.08689096570014954,
      "learning_rate": 1.673350968512672e-05,
      "loss": 0.0018,
      "step": 77970
    },
    {
      "epoch": 6.654151378103934,
      "grad_norm": 0.035370130091905594,
      "learning_rate": 1.6729243109480333e-05,
      "loss": 0.0018,
      "step": 77980
    },
    {
      "epoch": 6.655004693233211,
      "grad_norm": 0.32614511251449585,
      "learning_rate": 1.6724976533833947e-05,
      "loss": 0.0015,
      "step": 77990
    },
    {
      "epoch": 6.655858008362488,
      "grad_norm": 0.1849246472120285,
      "learning_rate": 1.6720709958187558e-05,
      "loss": 0.0023,
      "step": 78000
    },
    {
      "epoch": 6.656711323491765,
      "grad_norm": 0.2516995072364807,
      "learning_rate": 1.6716443382541173e-05,
      "loss": 0.002,
      "step": 78010
    },
    {
      "epoch": 6.657564638621043,
      "grad_norm": 0.09531597793102264,
      "learning_rate": 1.6712176806894787e-05,
      "loss": 0.0014,
      "step": 78020
    },
    {
      "epoch": 6.65841795375032,
      "grad_norm": 0.3301067650318146,
      "learning_rate": 1.67079102312484e-05,
      "loss": 0.0015,
      "step": 78030
    },
    {
      "epoch": 6.659271268879597,
      "grad_norm": 0.3626874089241028,
      "learning_rate": 1.6703643655602015e-05,
      "loss": 0.0017,
      "step": 78040
    },
    {
      "epoch": 6.660124584008875,
      "grad_norm": 0.18094174563884735,
      "learning_rate": 1.6699377079955626e-05,
      "loss": 0.0019,
      "step": 78050
    },
    {
      "epoch": 6.660977899138151,
      "grad_norm": 0.27501004934310913,
      "learning_rate": 1.669511050430924e-05,
      "loss": 0.0015,
      "step": 78060
    },
    {
      "epoch": 6.661831214267429,
      "grad_norm": 0.23852106928825378,
      "learning_rate": 1.6690843928662855e-05,
      "loss": 0.0021,
      "step": 78070
    },
    {
      "epoch": 6.6626845293967065,
      "grad_norm": 0.27245232462882996,
      "learning_rate": 1.668657735301647e-05,
      "loss": 0.0016,
      "step": 78080
    },
    {
      "epoch": 6.663537844525983,
      "grad_norm": 0.04188002273440361,
      "learning_rate": 1.6682310777370083e-05,
      "loss": 0.0019,
      "step": 78090
    },
    {
      "epoch": 6.664391159655261,
      "grad_norm": 0.09415678679943085,
      "learning_rate": 1.6678044201723697e-05,
      "loss": 0.0019,
      "step": 78100
    },
    {
      "epoch": 6.665244474784538,
      "grad_norm": 0.06266920268535614,
      "learning_rate": 1.667377762607731e-05,
      "loss": 0.0017,
      "step": 78110
    },
    {
      "epoch": 6.666097789913815,
      "grad_norm": 0.03385818377137184,
      "learning_rate": 1.6669511050430926e-05,
      "loss": 0.0022,
      "step": 78120
    },
    {
      "epoch": 6.6669511050430925,
      "grad_norm": 0.13147850334644318,
      "learning_rate": 1.666524447478454e-05,
      "loss": 0.0018,
      "step": 78130
    },
    {
      "epoch": 6.66780442017237,
      "grad_norm": 0.3105340600013733,
      "learning_rate": 1.6660977899138154e-05,
      "loss": 0.0021,
      "step": 78140
    },
    {
      "epoch": 6.668657735301647,
      "grad_norm": 0.0947706550359726,
      "learning_rate": 1.6656711323491765e-05,
      "loss": 0.0017,
      "step": 78150
    },
    {
      "epoch": 6.669511050430924,
      "grad_norm": 0.3270365595817566,
      "learning_rate": 1.665244474784538e-05,
      "loss": 0.0015,
      "step": 78160
    },
    {
      "epoch": 6.670364365560202,
      "grad_norm": 0.14552375674247742,
      "learning_rate": 1.6648178172198994e-05,
      "loss": 0.0012,
      "step": 78170
    },
    {
      "epoch": 6.6712176806894785,
      "grad_norm": 0.12407391518354416,
      "learning_rate": 1.6643911596552608e-05,
      "loss": 0.0017,
      "step": 78180
    },
    {
      "epoch": 6.672070995818756,
      "grad_norm": 0.04527604579925537,
      "learning_rate": 1.6639645020906222e-05,
      "loss": 0.0016,
      "step": 78190
    },
    {
      "epoch": 6.672924310948033,
      "grad_norm": 0.1706254482269287,
      "learning_rate": 1.6635378445259836e-05,
      "loss": 0.0016,
      "step": 78200
    },
    {
      "epoch": 6.67377762607731,
      "grad_norm": 0.13157129287719727,
      "learning_rate": 1.663111186961345e-05,
      "loss": 0.0018,
      "step": 78210
    },
    {
      "epoch": 6.674630941206588,
      "grad_norm": 0.09425916522741318,
      "learning_rate": 1.6626845293967065e-05,
      "loss": 0.002,
      "step": 78220
    },
    {
      "epoch": 6.6754842563358645,
      "grad_norm": 0.25211456418037415,
      "learning_rate": 1.662257871832068e-05,
      "loss": 0.0015,
      "step": 78230
    },
    {
      "epoch": 6.676337571465142,
      "grad_norm": 0.0264207161962986,
      "learning_rate": 1.6618312142674293e-05,
      "loss": 0.0018,
      "step": 78240
    },
    {
      "epoch": 6.67719088659442,
      "grad_norm": 0.16770076751708984,
      "learning_rate": 1.6614045567027904e-05,
      "loss": 0.0014,
      "step": 78250
    },
    {
      "epoch": 6.678044201723696,
      "grad_norm": 0.16841764748096466,
      "learning_rate": 1.6609778991381515e-05,
      "loss": 0.002,
      "step": 78260
    },
    {
      "epoch": 6.678897516852974,
      "grad_norm": 0.13402540981769562,
      "learning_rate": 1.660551241573513e-05,
      "loss": 0.0016,
      "step": 78270
    },
    {
      "epoch": 6.679750831982251,
      "grad_norm": 0.2546897828578949,
      "learning_rate": 1.6601245840088743e-05,
      "loss": 0.0019,
      "step": 78280
    },
    {
      "epoch": 6.680604147111528,
      "grad_norm": 0.15335127711296082,
      "learning_rate": 1.6596979264442358e-05,
      "loss": 0.0018,
      "step": 78290
    },
    {
      "epoch": 6.681457462240806,
      "grad_norm": 0.0474897064268589,
      "learning_rate": 1.6592712688795972e-05,
      "loss": 0.0022,
      "step": 78300
    },
    {
      "epoch": 6.682310777370082,
      "grad_norm": 0.16483815014362335,
      "learning_rate": 1.6588446113149586e-05,
      "loss": 0.0016,
      "step": 78310
    },
    {
      "epoch": 6.68316409249936,
      "grad_norm": 0.1590091735124588,
      "learning_rate": 1.65841795375032e-05,
      "loss": 0.0012,
      "step": 78320
    },
    {
      "epoch": 6.684017407628637,
      "grad_norm": 0.1660807877779007,
      "learning_rate": 1.6579912961856815e-05,
      "loss": 0.0016,
      "step": 78330
    },
    {
      "epoch": 6.684870722757914,
      "grad_norm": 0.24155695736408234,
      "learning_rate": 1.657564638621043e-05,
      "loss": 0.0019,
      "step": 78340
    },
    {
      "epoch": 6.685724037887192,
      "grad_norm": 0.2828081250190735,
      "learning_rate": 1.6571379810564043e-05,
      "loss": 0.0014,
      "step": 78350
    },
    {
      "epoch": 6.686577353016469,
      "grad_norm": 0.11978902667760849,
      "learning_rate": 1.6567113234917654e-05,
      "loss": 0.0025,
      "step": 78360
    },
    {
      "epoch": 6.687430668145746,
      "grad_norm": 0.22217969596385956,
      "learning_rate": 1.6562846659271268e-05,
      "loss": 0.0016,
      "step": 78370
    },
    {
      "epoch": 6.688283983275023,
      "grad_norm": 0.27378812432289124,
      "learning_rate": 1.6558580083624882e-05,
      "loss": 0.0019,
      "step": 78380
    },
    {
      "epoch": 6.689137298404301,
      "grad_norm": 0.028830189257860184,
      "learning_rate": 1.6554313507978497e-05,
      "loss": 0.0025,
      "step": 78390
    },
    {
      "epoch": 6.689990613533578,
      "grad_norm": 0.15086036920547485,
      "learning_rate": 1.655004693233211e-05,
      "loss": 0.0018,
      "step": 78400
    },
    {
      "epoch": 6.690843928662855,
      "grad_norm": 0.04789142310619354,
      "learning_rate": 1.6545780356685725e-05,
      "loss": 0.0017,
      "step": 78410
    },
    {
      "epoch": 6.691697243792133,
      "grad_norm": 0.06410054862499237,
      "learning_rate": 1.654151378103934e-05,
      "loss": 0.0018,
      "step": 78420
    },
    {
      "epoch": 6.692550558921409,
      "grad_norm": 0.20159558951854706,
      "learning_rate": 1.6537247205392954e-05,
      "loss": 0.0017,
      "step": 78430
    },
    {
      "epoch": 6.693403874050687,
      "grad_norm": 0.12030816823244095,
      "learning_rate": 1.6532980629746568e-05,
      "loss": 0.0017,
      "step": 78440
    },
    {
      "epoch": 6.6942571891799645,
      "grad_norm": 0.16931822896003723,
      "learning_rate": 1.6528714054100182e-05,
      "loss": 0.0015,
      "step": 78450
    },
    {
      "epoch": 6.695110504309241,
      "grad_norm": 0.15485480427742004,
      "learning_rate": 1.6524447478453793e-05,
      "loss": 0.0017,
      "step": 78460
    },
    {
      "epoch": 6.695963819438519,
      "grad_norm": 0.10943655669689178,
      "learning_rate": 1.6520180902807407e-05,
      "loss": 0.0014,
      "step": 78470
    },
    {
      "epoch": 6.696817134567796,
      "grad_norm": 0.0937834233045578,
      "learning_rate": 1.651591432716102e-05,
      "loss": 0.002,
      "step": 78480
    },
    {
      "epoch": 6.697670449697073,
      "grad_norm": 0.05750444903969765,
      "learning_rate": 1.6511647751514636e-05,
      "loss": 0.0022,
      "step": 78490
    },
    {
      "epoch": 6.6985237648263505,
      "grad_norm": 0.14248687028884888,
      "learning_rate": 1.650738117586825e-05,
      "loss": 0.0016,
      "step": 78500
    },
    {
      "epoch": 6.699377079955628,
      "grad_norm": 0.21089774370193481,
      "learning_rate": 1.6503114600221864e-05,
      "loss": 0.0014,
      "step": 78510
    },
    {
      "epoch": 6.700230395084905,
      "grad_norm": 0.2544465959072113,
      "learning_rate": 1.649884802457548e-05,
      "loss": 0.0022,
      "step": 78520
    },
    {
      "epoch": 6.701083710214182,
      "grad_norm": 0.11432944983243942,
      "learning_rate": 1.649458144892909e-05,
      "loss": 0.0014,
      "step": 78530
    },
    {
      "epoch": 6.70193702534346,
      "grad_norm": 0.183817058801651,
      "learning_rate": 1.6490314873282704e-05,
      "loss": 0.0019,
      "step": 78540
    },
    {
      "epoch": 6.7027903404727365,
      "grad_norm": 0.23785853385925293,
      "learning_rate": 1.6486048297636318e-05,
      "loss": 0.0013,
      "step": 78550
    },
    {
      "epoch": 6.703643655602014,
      "grad_norm": 0.2750226557254791,
      "learning_rate": 1.6481781721989932e-05,
      "loss": 0.0019,
      "step": 78560
    },
    {
      "epoch": 6.704496970731291,
      "grad_norm": 0.023484714329242706,
      "learning_rate": 1.6477515146343543e-05,
      "loss": 0.002,
      "step": 78570
    },
    {
      "epoch": 6.705350285860568,
      "grad_norm": 0.06873653084039688,
      "learning_rate": 1.6473248570697157e-05,
      "loss": 0.0014,
      "step": 78580
    },
    {
      "epoch": 6.706203600989846,
      "grad_norm": 0.13049371540546417,
      "learning_rate": 1.646898199505077e-05,
      "loss": 0.0013,
      "step": 78590
    },
    {
      "epoch": 6.7070569161191225,
      "grad_norm": 0.1154261901974678,
      "learning_rate": 1.6464715419404386e-05,
      "loss": 0.0015,
      "step": 78600
    },
    {
      "epoch": 6.7079102312484,
      "grad_norm": 0.027826081961393356,
      "learning_rate": 1.6460448843758e-05,
      "loss": 0.0018,
      "step": 78610
    },
    {
      "epoch": 6.708763546377678,
      "grad_norm": 0.07831818610429764,
      "learning_rate": 1.6456182268111614e-05,
      "loss": 0.0017,
      "step": 78620
    },
    {
      "epoch": 6.709616861506954,
      "grad_norm": 0.07534154504537582,
      "learning_rate": 1.645191569246523e-05,
      "loss": 0.0019,
      "step": 78630
    },
    {
      "epoch": 6.710470176636232,
      "grad_norm": 0.04137211665511131,
      "learning_rate": 1.6447649116818843e-05,
      "loss": 0.0019,
      "step": 78640
    },
    {
      "epoch": 6.711323491765509,
      "grad_norm": 0.15174239873886108,
      "learning_rate": 1.6443382541172457e-05,
      "loss": 0.0023,
      "step": 78650
    },
    {
      "epoch": 6.712176806894786,
      "grad_norm": 0.03001229651272297,
      "learning_rate": 1.643911596552607e-05,
      "loss": 0.0023,
      "step": 78660
    },
    {
      "epoch": 6.713030122024064,
      "grad_norm": 0.29424765706062317,
      "learning_rate": 1.6434849389879682e-05,
      "loss": 0.0021,
      "step": 78670
    },
    {
      "epoch": 6.71388343715334,
      "grad_norm": 0.36477309465408325,
      "learning_rate": 1.6430582814233296e-05,
      "loss": 0.0016,
      "step": 78680
    },
    {
      "epoch": 6.714736752282618,
      "grad_norm": 0.12582595646381378,
      "learning_rate": 1.642631623858691e-05,
      "loss": 0.0021,
      "step": 78690
    },
    {
      "epoch": 6.715590067411895,
      "grad_norm": 0.29218199849128723,
      "learning_rate": 1.6422049662940525e-05,
      "loss": 0.0016,
      "step": 78700
    },
    {
      "epoch": 6.716443382541172,
      "grad_norm": 0.07531989365816116,
      "learning_rate": 1.641778308729414e-05,
      "loss": 0.0017,
      "step": 78710
    },
    {
      "epoch": 6.71729669767045,
      "grad_norm": 0.10736149549484253,
      "learning_rate": 1.6413516511647753e-05,
      "loss": 0.0021,
      "step": 78720
    },
    {
      "epoch": 6.718150012799727,
      "grad_norm": 0.04771633818745613,
      "learning_rate": 1.6409249936001367e-05,
      "loss": 0.0013,
      "step": 78730
    },
    {
      "epoch": 6.719003327929004,
      "grad_norm": 0.3812761902809143,
      "learning_rate": 1.640498336035498e-05,
      "loss": 0.0019,
      "step": 78740
    },
    {
      "epoch": 6.719856643058281,
      "grad_norm": 0.09770046919584274,
      "learning_rate": 1.6400716784708596e-05,
      "loss": 0.0019,
      "step": 78750
    },
    {
      "epoch": 6.720709958187559,
      "grad_norm": 0.32665106654167175,
      "learning_rate": 1.639645020906221e-05,
      "loss": 0.0023,
      "step": 78760
    },
    {
      "epoch": 6.721563273316836,
      "grad_norm": 0.1064458042383194,
      "learning_rate": 1.639218363341582e-05,
      "loss": 0.002,
      "step": 78770
    },
    {
      "epoch": 6.722416588446113,
      "grad_norm": 0.11479035764932632,
      "learning_rate": 1.6387917057769435e-05,
      "loss": 0.0019,
      "step": 78780
    },
    {
      "epoch": 6.723269903575391,
      "grad_norm": 0.11190827190876007,
      "learning_rate": 1.638365048212305e-05,
      "loss": 0.0015,
      "step": 78790
    },
    {
      "epoch": 6.724123218704667,
      "grad_norm": 0.16856591403484344,
      "learning_rate": 1.637938390647666e-05,
      "loss": 0.0016,
      "step": 78800
    },
    {
      "epoch": 6.724976533833945,
      "grad_norm": 0.2760893404483795,
      "learning_rate": 1.6375117330830275e-05,
      "loss": 0.0019,
      "step": 78810
    },
    {
      "epoch": 6.7258298489632224,
      "grad_norm": 0.12673307955265045,
      "learning_rate": 1.637085075518389e-05,
      "loss": 0.0021,
      "step": 78820
    },
    {
      "epoch": 6.726683164092499,
      "grad_norm": 0.10889279097318649,
      "learning_rate": 1.6366584179537503e-05,
      "loss": 0.0014,
      "step": 78830
    },
    {
      "epoch": 6.727536479221777,
      "grad_norm": 0.18620365858078003,
      "learning_rate": 1.6362317603891117e-05,
      "loss": 0.0016,
      "step": 78840
    },
    {
      "epoch": 6.728389794351054,
      "grad_norm": 0.027960794046521187,
      "learning_rate": 1.635805102824473e-05,
      "loss": 0.0017,
      "step": 78850
    },
    {
      "epoch": 6.729243109480331,
      "grad_norm": 0.04266662523150444,
      "learning_rate": 1.6353784452598346e-05,
      "loss": 0.0018,
      "step": 78860
    },
    {
      "epoch": 6.730096424609608,
      "grad_norm": 0.16357986629009247,
      "learning_rate": 1.634951787695196e-05,
      "loss": 0.0015,
      "step": 78870
    },
    {
      "epoch": 6.730949739738886,
      "grad_norm": 0.20507581532001495,
      "learning_rate": 1.634525130130557e-05,
      "loss": 0.0018,
      "step": 78880
    },
    {
      "epoch": 6.731803054868163,
      "grad_norm": 0.0328558087348938,
      "learning_rate": 1.6340984725659185e-05,
      "loss": 0.0013,
      "step": 78890
    },
    {
      "epoch": 6.73265636999744,
      "grad_norm": 0.1037665605545044,
      "learning_rate": 1.63367181500128e-05,
      "loss": 0.0014,
      "step": 78900
    },
    {
      "epoch": 6.733509685126718,
      "grad_norm": 0.14220526814460754,
      "learning_rate": 1.6332451574366414e-05,
      "loss": 0.0024,
      "step": 78910
    },
    {
      "epoch": 6.734363000255994,
      "grad_norm": 0.06258091330528259,
      "learning_rate": 1.6328184998720028e-05,
      "loss": 0.0015,
      "step": 78920
    },
    {
      "epoch": 6.735216315385272,
      "grad_norm": 0.14665234088897705,
      "learning_rate": 1.6323918423073642e-05,
      "loss": 0.0016,
      "step": 78930
    },
    {
      "epoch": 6.736069630514549,
      "grad_norm": 0.06351880729198456,
      "learning_rate": 1.6319651847427256e-05,
      "loss": 0.0019,
      "step": 78940
    },
    {
      "epoch": 6.736922945643826,
      "grad_norm": 0.08267661184072495,
      "learning_rate": 1.631538527178087e-05,
      "loss": 0.0016,
      "step": 78950
    },
    {
      "epoch": 6.737776260773104,
      "grad_norm": 0.12586341798305511,
      "learning_rate": 1.6311118696134485e-05,
      "loss": 0.0019,
      "step": 78960
    },
    {
      "epoch": 6.73862957590238,
      "grad_norm": 0.2783975601196289,
      "learning_rate": 1.63068521204881e-05,
      "loss": 0.0018,
      "step": 78970
    },
    {
      "epoch": 6.739482891031658,
      "grad_norm": 0.11327242106199265,
      "learning_rate": 1.630258554484171e-05,
      "loss": 0.0017,
      "step": 78980
    },
    {
      "epoch": 6.7403362061609355,
      "grad_norm": 0.03693549335002899,
      "learning_rate": 1.6298318969195324e-05,
      "loss": 0.0016,
      "step": 78990
    },
    {
      "epoch": 6.741189521290212,
      "grad_norm": 0.1519404798746109,
      "learning_rate": 1.629405239354894e-05,
      "loss": 0.0015,
      "step": 79000
    },
    {
      "epoch": 6.74204283641949,
      "grad_norm": 0.05045368894934654,
      "learning_rate": 1.6289785817902553e-05,
      "loss": 0.0018,
      "step": 79010
    },
    {
      "epoch": 6.742896151548767,
      "grad_norm": 0.12063614279031754,
      "learning_rate": 1.6285519242256167e-05,
      "loss": 0.0021,
      "step": 79020
    },
    {
      "epoch": 6.743749466678044,
      "grad_norm": 0.049248822033405304,
      "learning_rate": 1.628125266660978e-05,
      "loss": 0.0016,
      "step": 79030
    },
    {
      "epoch": 6.7446027818073215,
      "grad_norm": 0.14939263463020325,
      "learning_rate": 1.6276986090963395e-05,
      "loss": 0.0016,
      "step": 79040
    },
    {
      "epoch": 6.745456096936598,
      "grad_norm": 0.05334516242146492,
      "learning_rate": 1.627271951531701e-05,
      "loss": 0.0019,
      "step": 79050
    },
    {
      "epoch": 6.746309412065876,
      "grad_norm": 0.22824540734291077,
      "learning_rate": 1.626845293967062e-05,
      "loss": 0.0015,
      "step": 79060
    },
    {
      "epoch": 6.747162727195153,
      "grad_norm": 0.15839625895023346,
      "learning_rate": 1.6264186364024235e-05,
      "loss": 0.0018,
      "step": 79070
    },
    {
      "epoch": 6.74801604232443,
      "grad_norm": 0.08068908751010895,
      "learning_rate": 1.625991978837785e-05,
      "loss": 0.0016,
      "step": 79080
    },
    {
      "epoch": 6.7488693574537075,
      "grad_norm": 0.07543963193893433,
      "learning_rate": 1.6255653212731463e-05,
      "loss": 0.0021,
      "step": 79090
    },
    {
      "epoch": 6.749722672582985,
      "grad_norm": 0.0533440038561821,
      "learning_rate": 1.6251386637085074e-05,
      "loss": 0.0019,
      "step": 79100
    },
    {
      "epoch": 6.750575987712262,
      "grad_norm": 0.1309380978345871,
      "learning_rate": 1.6247120061438688e-05,
      "loss": 0.0019,
      "step": 79110
    },
    {
      "epoch": 6.751429302841539,
      "grad_norm": 0.27924397587776184,
      "learning_rate": 1.6242853485792302e-05,
      "loss": 0.0018,
      "step": 79120
    },
    {
      "epoch": 6.752282617970817,
      "grad_norm": 0.09212891012430191,
      "learning_rate": 1.6238586910145917e-05,
      "loss": 0.0013,
      "step": 79130
    },
    {
      "epoch": 6.7531359331000935,
      "grad_norm": 0.11297571659088135,
      "learning_rate": 1.623432033449953e-05,
      "loss": 0.0021,
      "step": 79140
    },
    {
      "epoch": 6.753989248229371,
      "grad_norm": 0.29262351989746094,
      "learning_rate": 1.6230053758853145e-05,
      "loss": 0.0022,
      "step": 79150
    },
    {
      "epoch": 6.754842563358649,
      "grad_norm": 0.04275268316268921,
      "learning_rate": 1.622578718320676e-05,
      "loss": 0.0013,
      "step": 79160
    },
    {
      "epoch": 6.755695878487925,
      "grad_norm": 0.27516740560531616,
      "learning_rate": 1.6221520607560374e-05,
      "loss": 0.0015,
      "step": 79170
    },
    {
      "epoch": 6.756549193617203,
      "grad_norm": 0.2211608737707138,
      "learning_rate": 1.6217254031913988e-05,
      "loss": 0.0015,
      "step": 79180
    },
    {
      "epoch": 6.75740250874648,
      "grad_norm": 0.03513936325907707,
      "learning_rate": 1.62129874562676e-05,
      "loss": 0.0024,
      "step": 79190
    },
    {
      "epoch": 6.758255823875757,
      "grad_norm": 0.15306240320205688,
      "learning_rate": 1.6208720880621213e-05,
      "loss": 0.0015,
      "step": 79200
    },
    {
      "epoch": 6.759109139005035,
      "grad_norm": 0.3301010727882385,
      "learning_rate": 1.6204454304974827e-05,
      "loss": 0.0016,
      "step": 79210
    },
    {
      "epoch": 6.759962454134312,
      "grad_norm": 0.20172835886478424,
      "learning_rate": 1.620018772932844e-05,
      "loss": 0.002,
      "step": 79220
    },
    {
      "epoch": 6.760815769263589,
      "grad_norm": 0.400786429643631,
      "learning_rate": 1.6195921153682056e-05,
      "loss": 0.0017,
      "step": 79230
    },
    {
      "epoch": 6.761669084392866,
      "grad_norm": 0.21539056301116943,
      "learning_rate": 1.619165457803567e-05,
      "loss": 0.0018,
      "step": 79240
    },
    {
      "epoch": 6.762522399522144,
      "grad_norm": 0.1490316092967987,
      "learning_rate": 1.6187388002389284e-05,
      "loss": 0.0016,
      "step": 79250
    },
    {
      "epoch": 6.763375714651421,
      "grad_norm": 0.11599411070346832,
      "learning_rate": 1.61831214267429e-05,
      "loss": 0.0013,
      "step": 79260
    },
    {
      "epoch": 6.764229029780698,
      "grad_norm": 0.06178561970591545,
      "learning_rate": 1.6178854851096513e-05,
      "loss": 0.0018,
      "step": 79270
    },
    {
      "epoch": 6.765082344909976,
      "grad_norm": 0.3070581257343292,
      "learning_rate": 1.6174588275450127e-05,
      "loss": 0.0014,
      "step": 79280
    },
    {
      "epoch": 6.765935660039252,
      "grad_norm": 0.19802787899971008,
      "learning_rate": 1.6170321699803738e-05,
      "loss": 0.0014,
      "step": 79290
    },
    {
      "epoch": 6.76678897516853,
      "grad_norm": 0.2920606732368469,
      "learning_rate": 1.6166055124157352e-05,
      "loss": 0.002,
      "step": 79300
    },
    {
      "epoch": 6.767642290297807,
      "grad_norm": 0.21851247549057007,
      "learning_rate": 1.6161788548510966e-05,
      "loss": 0.0018,
      "step": 79310
    },
    {
      "epoch": 6.768495605427084,
      "grad_norm": 0.1749006062746048,
      "learning_rate": 1.615752197286458e-05,
      "loss": 0.0021,
      "step": 79320
    },
    {
      "epoch": 6.769348920556362,
      "grad_norm": 0.16431927680969238,
      "learning_rate": 1.615325539721819e-05,
      "loss": 0.0016,
      "step": 79330
    },
    {
      "epoch": 6.770202235685638,
      "grad_norm": 0.24226927757263184,
      "learning_rate": 1.6148988821571806e-05,
      "loss": 0.002,
      "step": 79340
    },
    {
      "epoch": 6.771055550814916,
      "grad_norm": 0.13393104076385498,
      "learning_rate": 1.614472224592542e-05,
      "loss": 0.0019,
      "step": 79350
    },
    {
      "epoch": 6.7719088659441935,
      "grad_norm": 0.16690440475940704,
      "learning_rate": 1.6140455670279034e-05,
      "loss": 0.0017,
      "step": 79360
    },
    {
      "epoch": 6.77276218107347,
      "grad_norm": 0.049647897481918335,
      "learning_rate": 1.6136189094632648e-05,
      "loss": 0.0016,
      "step": 79370
    },
    {
      "epoch": 6.773615496202748,
      "grad_norm": 0.2690141797065735,
      "learning_rate": 1.6131922518986263e-05,
      "loss": 0.0018,
      "step": 79380
    },
    {
      "epoch": 6.774468811332025,
      "grad_norm": 0.2585473358631134,
      "learning_rate": 1.6127655943339877e-05,
      "loss": 0.0016,
      "step": 79390
    },
    {
      "epoch": 6.775322126461302,
      "grad_norm": 0.18528708815574646,
      "learning_rate": 1.612338936769349e-05,
      "loss": 0.0019,
      "step": 79400
    },
    {
      "epoch": 6.7761754415905795,
      "grad_norm": 0.023220181465148926,
      "learning_rate": 1.6119122792047102e-05,
      "loss": 0.0015,
      "step": 79410
    },
    {
      "epoch": 6.777028756719856,
      "grad_norm": 0.0405878871679306,
      "learning_rate": 1.6114856216400716e-05,
      "loss": 0.0015,
      "step": 79420
    },
    {
      "epoch": 6.777882071849134,
      "grad_norm": 0.2915133535861969,
      "learning_rate": 1.611058964075433e-05,
      "loss": 0.0017,
      "step": 79430
    },
    {
      "epoch": 6.778735386978411,
      "grad_norm": 0.21917341649532318,
      "learning_rate": 1.6106323065107945e-05,
      "loss": 0.0019,
      "step": 79440
    },
    {
      "epoch": 6.779588702107688,
      "grad_norm": 0.05550937354564667,
      "learning_rate": 1.610205648946156e-05,
      "loss": 0.0018,
      "step": 79450
    },
    {
      "epoch": 6.7804420172369655,
      "grad_norm": 0.1465354710817337,
      "learning_rate": 1.6097789913815173e-05,
      "loss": 0.0018,
      "step": 79460
    },
    {
      "epoch": 6.781295332366243,
      "grad_norm": 0.0611155666410923,
      "learning_rate": 1.6093523338168787e-05,
      "loss": 0.0015,
      "step": 79470
    },
    {
      "epoch": 6.78214864749552,
      "grad_norm": 0.16262026131153107,
      "learning_rate": 1.60892567625224e-05,
      "loss": 0.0018,
      "step": 79480
    },
    {
      "epoch": 6.783001962624797,
      "grad_norm": 0.22076958417892456,
      "learning_rate": 1.6084990186876016e-05,
      "loss": 0.0017,
      "step": 79490
    },
    {
      "epoch": 6.783855277754075,
      "grad_norm": 0.20195192098617554,
      "learning_rate": 1.6080723611229627e-05,
      "loss": 0.0015,
      "step": 79500
    },
    {
      "epoch": 6.7847085928833515,
      "grad_norm": 0.31629568338394165,
      "learning_rate": 1.607645703558324e-05,
      "loss": 0.0021,
      "step": 79510
    },
    {
      "epoch": 6.785561908012629,
      "grad_norm": 0.10072021186351776,
      "learning_rate": 1.6072190459936855e-05,
      "loss": 0.0018,
      "step": 79520
    },
    {
      "epoch": 6.786415223141907,
      "grad_norm": 0.24610216915607452,
      "learning_rate": 1.606792388429047e-05,
      "loss": 0.0021,
      "step": 79530
    },
    {
      "epoch": 6.787268538271183,
      "grad_norm": 0.11422831565141678,
      "learning_rate": 1.6063657308644084e-05,
      "loss": 0.0017,
      "step": 79540
    },
    {
      "epoch": 6.788121853400461,
      "grad_norm": 0.18445837497711182,
      "learning_rate": 1.6059390732997698e-05,
      "loss": 0.0019,
      "step": 79550
    },
    {
      "epoch": 6.788975168529738,
      "grad_norm": 0.0782129243016243,
      "learning_rate": 1.6055124157351312e-05,
      "loss": 0.002,
      "step": 79560
    },
    {
      "epoch": 6.789828483659015,
      "grad_norm": 0.0630137249827385,
      "learning_rate": 1.6050857581704926e-05,
      "loss": 0.0019,
      "step": 79570
    },
    {
      "epoch": 6.790681798788293,
      "grad_norm": 0.29308491945266724,
      "learning_rate": 1.604659100605854e-05,
      "loss": 0.0012,
      "step": 79580
    },
    {
      "epoch": 6.79153511391757,
      "grad_norm": 0.049008797854185104,
      "learning_rate": 1.604232443041215e-05,
      "loss": 0.002,
      "step": 79590
    },
    {
      "epoch": 6.792388429046847,
      "grad_norm": 0.025767939165234566,
      "learning_rate": 1.6038057854765766e-05,
      "loss": 0.002,
      "step": 79600
    },
    {
      "epoch": 6.793241744176124,
      "grad_norm": 0.09611738473176956,
      "learning_rate": 1.603379127911938e-05,
      "loss": 0.0022,
      "step": 79610
    },
    {
      "epoch": 6.794095059305402,
      "grad_norm": 0.17634348571300507,
      "learning_rate": 1.602952470347299e-05,
      "loss": 0.0017,
      "step": 79620
    },
    {
      "epoch": 6.794948374434679,
      "grad_norm": 0.21455873548984528,
      "learning_rate": 1.6025258127826605e-05,
      "loss": 0.002,
      "step": 79630
    },
    {
      "epoch": 6.795801689563956,
      "grad_norm": 0.07756359875202179,
      "learning_rate": 1.602099155218022e-05,
      "loss": 0.0017,
      "step": 79640
    },
    {
      "epoch": 6.796655004693234,
      "grad_norm": 0.07854495942592621,
      "learning_rate": 1.6016724976533833e-05,
      "loss": 0.0014,
      "step": 79650
    },
    {
      "epoch": 6.79750831982251,
      "grad_norm": 0.07869523018598557,
      "learning_rate": 1.6012458400887448e-05,
      "loss": 0.0022,
      "step": 79660
    },
    {
      "epoch": 6.798361634951788,
      "grad_norm": 0.044741760939359665,
      "learning_rate": 1.6008191825241062e-05,
      "loss": 0.002,
      "step": 79670
    },
    {
      "epoch": 6.799214950081065,
      "grad_norm": 0.046602558344602585,
      "learning_rate": 1.6003925249594676e-05,
      "loss": 0.0016,
      "step": 79680
    },
    {
      "epoch": 6.800068265210342,
      "grad_norm": 0.18581506609916687,
      "learning_rate": 1.599965867394829e-05,
      "loss": 0.0018,
      "step": 79690
    },
    {
      "epoch": 6.80092158033962,
      "grad_norm": 0.2350752055644989,
      "learning_rate": 1.5995392098301905e-05,
      "loss": 0.0014,
      "step": 79700
    },
    {
      "epoch": 6.801774895468896,
      "grad_norm": 0.03427675738930702,
      "learning_rate": 1.599112552265552e-05,
      "loss": 0.002,
      "step": 79710
    },
    {
      "epoch": 6.802628210598174,
      "grad_norm": 0.04332716763019562,
      "learning_rate": 1.598685894700913e-05,
      "loss": 0.002,
      "step": 79720
    },
    {
      "epoch": 6.8034815257274515,
      "grad_norm": 0.030544258654117584,
      "learning_rate": 1.5982592371362744e-05,
      "loss": 0.0019,
      "step": 79730
    },
    {
      "epoch": 6.804334840856728,
      "grad_norm": 0.16422154009342194,
      "learning_rate": 1.5978325795716358e-05,
      "loss": 0.002,
      "step": 79740
    },
    {
      "epoch": 6.805188155986006,
      "grad_norm": 0.20119190216064453,
      "learning_rate": 1.5974059220069973e-05,
      "loss": 0.0019,
      "step": 79750
    },
    {
      "epoch": 6.806041471115283,
      "grad_norm": 0.05736471340060234,
      "learning_rate": 1.5969792644423587e-05,
      "loss": 0.0019,
      "step": 79760
    },
    {
      "epoch": 6.80689478624456,
      "grad_norm": 0.10749266296625137,
      "learning_rate": 1.59655260687772e-05,
      "loss": 0.0014,
      "step": 79770
    },
    {
      "epoch": 6.8077481013738375,
      "grad_norm": 0.1863011121749878,
      "learning_rate": 1.5961259493130815e-05,
      "loss": 0.0016,
      "step": 79780
    },
    {
      "epoch": 6.808601416503114,
      "grad_norm": 0.06356623768806458,
      "learning_rate": 1.595699291748443e-05,
      "loss": 0.0018,
      "step": 79790
    },
    {
      "epoch": 6.809454731632392,
      "grad_norm": 0.22621877491474152,
      "learning_rate": 1.5952726341838044e-05,
      "loss": 0.0016,
      "step": 79800
    },
    {
      "epoch": 6.810308046761669,
      "grad_norm": 0.32619521021842957,
      "learning_rate": 1.5948459766191658e-05,
      "loss": 0.0014,
      "step": 79810
    },
    {
      "epoch": 6.811161361890946,
      "grad_norm": 0.4547978937625885,
      "learning_rate": 1.594419319054527e-05,
      "loss": 0.0017,
      "step": 79820
    },
    {
      "epoch": 6.8120146770202235,
      "grad_norm": 0.03003839962184429,
      "learning_rate": 1.5939926614898883e-05,
      "loss": 0.0017,
      "step": 79830
    },
    {
      "epoch": 6.812867992149501,
      "grad_norm": 0.2401403784751892,
      "learning_rate": 1.5935660039252497e-05,
      "loss": 0.0016,
      "step": 79840
    },
    {
      "epoch": 6.813721307278778,
      "grad_norm": 0.1465585082769394,
      "learning_rate": 1.593139346360611e-05,
      "loss": 0.0021,
      "step": 79850
    },
    {
      "epoch": 6.814574622408055,
      "grad_norm": 0.058153171092271805,
      "learning_rate": 1.5927126887959722e-05,
      "loss": 0.0018,
      "step": 79860
    },
    {
      "epoch": 6.815427937537333,
      "grad_norm": 0.23372022807598114,
      "learning_rate": 1.5922860312313337e-05,
      "loss": 0.0019,
      "step": 79870
    },
    {
      "epoch": 6.8162812526666094,
      "grad_norm": 0.033344849944114685,
      "learning_rate": 1.591859373666695e-05,
      "loss": 0.0017,
      "step": 79880
    },
    {
      "epoch": 6.817134567795887,
      "grad_norm": 0.21754226088523865,
      "learning_rate": 1.5914327161020565e-05,
      "loss": 0.0016,
      "step": 79890
    },
    {
      "epoch": 6.8179878829251646,
      "grad_norm": 0.44191431999206543,
      "learning_rate": 1.591006058537418e-05,
      "loss": 0.0017,
      "step": 79900
    },
    {
      "epoch": 6.818841198054441,
      "grad_norm": 0.11190824955701828,
      "learning_rate": 1.5905794009727794e-05,
      "loss": 0.0017,
      "step": 79910
    },
    {
      "epoch": 6.819694513183719,
      "grad_norm": 0.04722239822149277,
      "learning_rate": 1.5901527434081408e-05,
      "loss": 0.0019,
      "step": 79920
    },
    {
      "epoch": 6.820547828312996,
      "grad_norm": 0.0786336287856102,
      "learning_rate": 1.589726085843502e-05,
      "loss": 0.0018,
      "step": 79930
    },
    {
      "epoch": 6.821401143442273,
      "grad_norm": 0.40263301134109497,
      "learning_rate": 1.5892994282788633e-05,
      "loss": 0.0019,
      "step": 79940
    },
    {
      "epoch": 6.8222544585715506,
      "grad_norm": 0.16530191898345947,
      "learning_rate": 1.5888727707142247e-05,
      "loss": 0.0016,
      "step": 79950
    },
    {
      "epoch": 6.823107773700828,
      "grad_norm": 0.04525163397192955,
      "learning_rate": 1.588446113149586e-05,
      "loss": 0.0017,
      "step": 79960
    },
    {
      "epoch": 6.823961088830105,
      "grad_norm": 0.18479007482528687,
      "learning_rate": 1.5880194555849476e-05,
      "loss": 0.0018,
      "step": 79970
    },
    {
      "epoch": 6.824814403959382,
      "grad_norm": 0.15521368384361267,
      "learning_rate": 1.587592798020309e-05,
      "loss": 0.0018,
      "step": 79980
    },
    {
      "epoch": 6.82566771908866,
      "grad_norm": 0.1654890477657318,
      "learning_rate": 1.5871661404556704e-05,
      "loss": 0.0016,
      "step": 79990
    },
    {
      "epoch": 6.8265210342179365,
      "grad_norm": 0.17944160103797913,
      "learning_rate": 1.586739482891032e-05,
      "loss": 0.0015,
      "step": 80000
    },
    {
      "epoch": 6.827374349347214,
      "grad_norm": 0.5076628923416138,
      "learning_rate": 1.5863128253263933e-05,
      "loss": 0.0019,
      "step": 80010
    },
    {
      "epoch": 6.828227664476492,
      "grad_norm": 0.1277979612350464,
      "learning_rate": 1.5858861677617547e-05,
      "loss": 0.0014,
      "step": 80020
    },
    {
      "epoch": 6.829080979605768,
      "grad_norm": 0.20270290970802307,
      "learning_rate": 1.5854595101971158e-05,
      "loss": 0.002,
      "step": 80030
    },
    {
      "epoch": 6.829934294735046,
      "grad_norm": 0.11089753359556198,
      "learning_rate": 1.5850328526324772e-05,
      "loss": 0.0015,
      "step": 80040
    },
    {
      "epoch": 6.8307876098643225,
      "grad_norm": 0.10471417754888535,
      "learning_rate": 1.5846061950678386e-05,
      "loss": 0.0017,
      "step": 80050
    },
    {
      "epoch": 6.8316409249936,
      "grad_norm": 0.30962035059928894,
      "learning_rate": 1.5841795375032e-05,
      "loss": 0.0019,
      "step": 80060
    },
    {
      "epoch": 6.832494240122878,
      "grad_norm": 0.13421882688999176,
      "learning_rate": 1.5837528799385615e-05,
      "loss": 0.0016,
      "step": 80070
    },
    {
      "epoch": 6.833347555252154,
      "grad_norm": 0.02875581942498684,
      "learning_rate": 1.583326222373923e-05,
      "loss": 0.0015,
      "step": 80080
    },
    {
      "epoch": 6.834200870381432,
      "grad_norm": 0.04329849034547806,
      "learning_rate": 1.5828995648092843e-05,
      "loss": 0.0019,
      "step": 80090
    },
    {
      "epoch": 6.835054185510709,
      "grad_norm": 0.2354358732700348,
      "learning_rate": 1.5824729072446457e-05,
      "loss": 0.0017,
      "step": 80100
    },
    {
      "epoch": 6.835907500639986,
      "grad_norm": 0.27412736415863037,
      "learning_rate": 1.582046249680007e-05,
      "loss": 0.0015,
      "step": 80110
    },
    {
      "epoch": 6.836760815769264,
      "grad_norm": 0.0421934649348259,
      "learning_rate": 1.5816195921153682e-05,
      "loss": 0.0023,
      "step": 80120
    },
    {
      "epoch": 6.837614130898541,
      "grad_norm": 0.03790711238980293,
      "learning_rate": 1.5811929345507297e-05,
      "loss": 0.0019,
      "step": 80130
    },
    {
      "epoch": 6.838467446027818,
      "grad_norm": 0.03672604635357857,
      "learning_rate": 1.5807662769860908e-05,
      "loss": 0.0017,
      "step": 80140
    },
    {
      "epoch": 6.839320761157095,
      "grad_norm": 0.07418268173933029,
      "learning_rate": 1.5803396194214522e-05,
      "loss": 0.0016,
      "step": 80150
    },
    {
      "epoch": 6.840174076286372,
      "grad_norm": 0.2919198274612427,
      "learning_rate": 1.5799129618568136e-05,
      "loss": 0.0019,
      "step": 80160
    },
    {
      "epoch": 6.84102739141565,
      "grad_norm": 0.020516037940979004,
      "learning_rate": 1.579486304292175e-05,
      "loss": 0.0016,
      "step": 80170
    },
    {
      "epoch": 6.841880706544927,
      "grad_norm": 0.11677061021327972,
      "learning_rate": 1.5790596467275365e-05,
      "loss": 0.0022,
      "step": 80180
    },
    {
      "epoch": 6.842734021674204,
      "grad_norm": 0.13856883347034454,
      "learning_rate": 1.578632989162898e-05,
      "loss": 0.0019,
      "step": 80190
    },
    {
      "epoch": 6.843587336803481,
      "grad_norm": 0.1373746395111084,
      "learning_rate": 1.5782063315982593e-05,
      "loss": 0.0019,
      "step": 80200
    },
    {
      "epoch": 6.844440651932759,
      "grad_norm": 0.16620370745658875,
      "learning_rate": 1.5777796740336207e-05,
      "loss": 0.0015,
      "step": 80210
    },
    {
      "epoch": 6.845293967062036,
      "grad_norm": 0.36191752552986145,
      "learning_rate": 1.577353016468982e-05,
      "loss": 0.0017,
      "step": 80220
    },
    {
      "epoch": 6.846147282191313,
      "grad_norm": 0.20758210122585297,
      "learning_rate": 1.5769263589043436e-05,
      "loss": 0.0018,
      "step": 80230
    },
    {
      "epoch": 6.847000597320591,
      "grad_norm": 0.06552180647850037,
      "learning_rate": 1.5764997013397047e-05,
      "loss": 0.0013,
      "step": 80240
    },
    {
      "epoch": 6.847853912449867,
      "grad_norm": 0.13771934807300568,
      "learning_rate": 1.576073043775066e-05,
      "loss": 0.0024,
      "step": 80250
    },
    {
      "epoch": 6.848707227579145,
      "grad_norm": 0.14468707144260406,
      "learning_rate": 1.5756463862104275e-05,
      "loss": 0.002,
      "step": 80260
    },
    {
      "epoch": 6.8495605427084225,
      "grad_norm": 0.058335382491350174,
      "learning_rate": 1.575219728645789e-05,
      "loss": 0.0016,
      "step": 80270
    },
    {
      "epoch": 6.850413857837699,
      "grad_norm": 0.21939291059970856,
      "learning_rate": 1.5747930710811504e-05,
      "loss": 0.0022,
      "step": 80280
    },
    {
      "epoch": 6.851267172966977,
      "grad_norm": 0.04479008913040161,
      "learning_rate": 1.5743664135165118e-05,
      "loss": 0.002,
      "step": 80290
    },
    {
      "epoch": 6.852120488096254,
      "grad_norm": 0.22357894480228424,
      "learning_rate": 1.5739397559518732e-05,
      "loss": 0.0017,
      "step": 80300
    },
    {
      "epoch": 6.852973803225531,
      "grad_norm": 0.039542242884635925,
      "learning_rate": 1.5735130983872346e-05,
      "loss": 0.0016,
      "step": 80310
    },
    {
      "epoch": 6.8538271183548085,
      "grad_norm": 0.17511530220508575,
      "learning_rate": 1.573086440822596e-05,
      "loss": 0.0019,
      "step": 80320
    },
    {
      "epoch": 6.854680433484086,
      "grad_norm": 0.18275539577007294,
      "learning_rate": 1.5726597832579575e-05,
      "loss": 0.0015,
      "step": 80330
    },
    {
      "epoch": 6.855533748613363,
      "grad_norm": 0.07489071786403656,
      "learning_rate": 1.5722331256933186e-05,
      "loss": 0.0015,
      "step": 80340
    },
    {
      "epoch": 6.85638706374264,
      "grad_norm": 0.3978239893913269,
      "learning_rate": 1.57180646812868e-05,
      "loss": 0.0013,
      "step": 80350
    },
    {
      "epoch": 6.857240378871918,
      "grad_norm": 0.044944338500499725,
      "learning_rate": 1.5713798105640414e-05,
      "loss": 0.0024,
      "step": 80360
    },
    {
      "epoch": 6.8580936940011945,
      "grad_norm": 0.1286531239748001,
      "learning_rate": 1.570953152999403e-05,
      "loss": 0.0019,
      "step": 80370
    },
    {
      "epoch": 6.858947009130472,
      "grad_norm": 0.04280894994735718,
      "learning_rate": 1.5705264954347643e-05,
      "loss": 0.0016,
      "step": 80380
    },
    {
      "epoch": 6.85980032425975,
      "grad_norm": 0.21734531223773956,
      "learning_rate": 1.5700998378701253e-05,
      "loss": 0.0017,
      "step": 80390
    },
    {
      "epoch": 6.860653639389026,
      "grad_norm": 0.132637619972229,
      "learning_rate": 1.5696731803054868e-05,
      "loss": 0.0016,
      "step": 80400
    },
    {
      "epoch": 6.861506954518304,
      "grad_norm": 0.12861153483390808,
      "learning_rate": 1.5692465227408482e-05,
      "loss": 0.0018,
      "step": 80410
    },
    {
      "epoch": 6.8623602696475805,
      "grad_norm": 0.07914094626903534,
      "learning_rate": 1.5688198651762096e-05,
      "loss": 0.0021,
      "step": 80420
    },
    {
      "epoch": 6.863213584776858,
      "grad_norm": 0.1291818767786026,
      "learning_rate": 1.568393207611571e-05,
      "loss": 0.0017,
      "step": 80430
    },
    {
      "epoch": 6.864066899906136,
      "grad_norm": 0.10605572909116745,
      "learning_rate": 1.5679665500469325e-05,
      "loss": 0.0017,
      "step": 80440
    },
    {
      "epoch": 6.864920215035412,
      "grad_norm": 0.27488499879837036,
      "learning_rate": 1.5675398924822935e-05,
      "loss": 0.0015,
      "step": 80450
    },
    {
      "epoch": 6.86577353016469,
      "grad_norm": 0.03830007091164589,
      "learning_rate": 1.567113234917655e-05,
      "loss": 0.0019,
      "step": 80460
    },
    {
      "epoch": 6.866626845293967,
      "grad_norm": 0.18335799872875214,
      "learning_rate": 1.5666865773530164e-05,
      "loss": 0.0017,
      "step": 80470
    },
    {
      "epoch": 6.867480160423244,
      "grad_norm": 0.14749479293823242,
      "learning_rate": 1.5662599197883778e-05,
      "loss": 0.0016,
      "step": 80480
    },
    {
      "epoch": 6.868333475552522,
      "grad_norm": 0.058768466114997864,
      "learning_rate": 1.5658332622237392e-05,
      "loss": 0.0017,
      "step": 80490
    },
    {
      "epoch": 6.869186790681799,
      "grad_norm": 0.09649454057216644,
      "learning_rate": 1.5654066046591007e-05,
      "loss": 0.0017,
      "step": 80500
    },
    {
      "epoch": 6.870040105811076,
      "grad_norm": 0.10863761603832245,
      "learning_rate": 1.564979947094462e-05,
      "loss": 0.0016,
      "step": 80510
    },
    {
      "epoch": 6.870893420940353,
      "grad_norm": 0.2382131665945053,
      "learning_rate": 1.5645532895298235e-05,
      "loss": 0.0018,
      "step": 80520
    },
    {
      "epoch": 6.87174673606963,
      "grad_norm": 0.11277801543474197,
      "learning_rate": 1.564126631965185e-05,
      "loss": 0.0019,
      "step": 80530
    },
    {
      "epoch": 6.872600051198908,
      "grad_norm": 0.1307980716228485,
      "learning_rate": 1.5636999744005464e-05,
      "loss": 0.0014,
      "step": 80540
    },
    {
      "epoch": 6.873453366328185,
      "grad_norm": 0.03061208687722683,
      "learning_rate": 1.5632733168359075e-05,
      "loss": 0.0017,
      "step": 80550
    },
    {
      "epoch": 6.874306681457462,
      "grad_norm": 0.1999734789133072,
      "learning_rate": 1.562846659271269e-05,
      "loss": 0.002,
      "step": 80560
    },
    {
      "epoch": 6.875159996586739,
      "grad_norm": 0.03443174809217453,
      "learning_rate": 1.5624200017066303e-05,
      "loss": 0.0018,
      "step": 80570
    },
    {
      "epoch": 6.876013311716017,
      "grad_norm": 0.0754493996500969,
      "learning_rate": 1.5619933441419917e-05,
      "loss": 0.0018,
      "step": 80580
    },
    {
      "epoch": 6.876866626845294,
      "grad_norm": 0.23524610698223114,
      "learning_rate": 1.561566686577353e-05,
      "loss": 0.0019,
      "step": 80590
    },
    {
      "epoch": 6.877719941974571,
      "grad_norm": 0.38241544365882874,
      "learning_rate": 1.5611400290127146e-05,
      "loss": 0.0016,
      "step": 80600
    },
    {
      "epoch": 6.878573257103849,
      "grad_norm": 0.09526851028203964,
      "learning_rate": 1.560713371448076e-05,
      "loss": 0.0014,
      "step": 80610
    },
    {
      "epoch": 6.879426572233125,
      "grad_norm": 0.10578690469264984,
      "learning_rate": 1.5602867138834374e-05,
      "loss": 0.0019,
      "step": 80620
    },
    {
      "epoch": 6.880279887362403,
      "grad_norm": 0.1807665228843689,
      "learning_rate": 1.559860056318799e-05,
      "loss": 0.0015,
      "step": 80630
    },
    {
      "epoch": 6.8811332024916805,
      "grad_norm": 0.2726243734359741,
      "learning_rate": 1.5594333987541603e-05,
      "loss": 0.0019,
      "step": 80640
    },
    {
      "epoch": 6.881986517620957,
      "grad_norm": 0.0993526354432106,
      "learning_rate": 1.5590067411895214e-05,
      "loss": 0.0022,
      "step": 80650
    },
    {
      "epoch": 6.882839832750235,
      "grad_norm": 0.1407712996006012,
      "learning_rate": 1.5585800836248828e-05,
      "loss": 0.0024,
      "step": 80660
    },
    {
      "epoch": 6.883693147879512,
      "grad_norm": 0.038653664290905,
      "learning_rate": 1.558153426060244e-05,
      "loss": 0.002,
      "step": 80670
    },
    {
      "epoch": 6.884546463008789,
      "grad_norm": 0.14379654824733734,
      "learning_rate": 1.5577267684956053e-05,
      "loss": 0.0021,
      "step": 80680
    },
    {
      "epoch": 6.8853997781380665,
      "grad_norm": 0.3391716182231903,
      "learning_rate": 1.5573001109309667e-05,
      "loss": 0.0017,
      "step": 80690
    },
    {
      "epoch": 6.886253093267344,
      "grad_norm": 0.043886009603738785,
      "learning_rate": 1.556873453366328e-05,
      "loss": 0.0018,
      "step": 80700
    },
    {
      "epoch": 6.887106408396621,
      "grad_norm": 0.04872642830014229,
      "learning_rate": 1.5564467958016896e-05,
      "loss": 0.0017,
      "step": 80710
    },
    {
      "epoch": 6.887959723525898,
      "grad_norm": 0.07702115923166275,
      "learning_rate": 1.556020138237051e-05,
      "loss": 0.0019,
      "step": 80720
    },
    {
      "epoch": 6.888813038655176,
      "grad_norm": 0.12882854044437408,
      "learning_rate": 1.5555934806724124e-05,
      "loss": 0.002,
      "step": 80730
    },
    {
      "epoch": 6.8896663537844525,
      "grad_norm": 0.02978070080280304,
      "learning_rate": 1.555166823107774e-05,
      "loss": 0.0023,
      "step": 80740
    },
    {
      "epoch": 6.89051966891373,
      "grad_norm": 0.11272208392620087,
      "learning_rate": 1.5547401655431353e-05,
      "loss": 0.0017,
      "step": 80750
    },
    {
      "epoch": 6.891372984043008,
      "grad_norm": 0.2762794494628906,
      "learning_rate": 1.5543135079784963e-05,
      "loss": 0.0019,
      "step": 80760
    },
    {
      "epoch": 6.892226299172284,
      "grad_norm": 0.27363350987434387,
      "learning_rate": 1.5538868504138578e-05,
      "loss": 0.0019,
      "step": 80770
    },
    {
      "epoch": 6.893079614301562,
      "grad_norm": 0.09729448705911636,
      "learning_rate": 1.5534601928492192e-05,
      "loss": 0.0013,
      "step": 80780
    },
    {
      "epoch": 6.8939329294308385,
      "grad_norm": 0.2202024906873703,
      "learning_rate": 1.5530335352845806e-05,
      "loss": 0.0023,
      "step": 80790
    },
    {
      "epoch": 6.894786244560116,
      "grad_norm": 0.05863374471664429,
      "learning_rate": 1.552606877719942e-05,
      "loss": 0.0019,
      "step": 80800
    },
    {
      "epoch": 6.895639559689394,
      "grad_norm": 0.019539829343557358,
      "learning_rate": 1.5521802201553035e-05,
      "loss": 0.002,
      "step": 80810
    },
    {
      "epoch": 6.89649287481867,
      "grad_norm": 0.08090793341398239,
      "learning_rate": 1.551753562590665e-05,
      "loss": 0.0019,
      "step": 80820
    },
    {
      "epoch": 6.897346189947948,
      "grad_norm": 0.21909494698047638,
      "learning_rate": 1.5513269050260263e-05,
      "loss": 0.0013,
      "step": 80830
    },
    {
      "epoch": 6.898199505077225,
      "grad_norm": 0.13687819242477417,
      "learning_rate": 1.5509002474613877e-05,
      "loss": 0.0019,
      "step": 80840
    },
    {
      "epoch": 6.899052820206502,
      "grad_norm": 0.1347108781337738,
      "learning_rate": 1.550473589896749e-05,
      "loss": 0.0018,
      "step": 80850
    },
    {
      "epoch": 6.89990613533578,
      "grad_norm": 0.5366805791854858,
      "learning_rate": 1.5500469323321102e-05,
      "loss": 0.0024,
      "step": 80860
    },
    {
      "epoch": 6.900759450465057,
      "grad_norm": 0.1486557424068451,
      "learning_rate": 1.5496202747674717e-05,
      "loss": 0.0017,
      "step": 80870
    },
    {
      "epoch": 6.901612765594334,
      "grad_norm": 0.21962125599384308,
      "learning_rate": 1.549193617202833e-05,
      "loss": 0.0019,
      "step": 80880
    },
    {
      "epoch": 6.902466080723611,
      "grad_norm": 0.14465975761413574,
      "learning_rate": 1.5487669596381945e-05,
      "loss": 0.0024,
      "step": 80890
    },
    {
      "epoch": 6.903319395852888,
      "grad_norm": 0.23426508903503418,
      "learning_rate": 1.548340302073556e-05,
      "loss": 0.0015,
      "step": 80900
    },
    {
      "epoch": 6.904172710982166,
      "grad_norm": 0.2558463215827942,
      "learning_rate": 1.5479136445089174e-05,
      "loss": 0.0018,
      "step": 80910
    },
    {
      "epoch": 6.905026026111443,
      "grad_norm": 0.09527556598186493,
      "learning_rate": 1.5474869869442784e-05,
      "loss": 0.0016,
      "step": 80920
    },
    {
      "epoch": 6.90587934124072,
      "grad_norm": 0.03774186596274376,
      "learning_rate": 1.54706032937964e-05,
      "loss": 0.0017,
      "step": 80930
    },
    {
      "epoch": 6.906732656369997,
      "grad_norm": 0.03375549241900444,
      "learning_rate": 1.5466336718150013e-05,
      "loss": 0.0017,
      "step": 80940
    },
    {
      "epoch": 6.907585971499275,
      "grad_norm": 0.25556981563568115,
      "learning_rate": 1.5462070142503627e-05,
      "loss": 0.0019,
      "step": 80950
    },
    {
      "epoch": 6.908439286628552,
      "grad_norm": 0.2057712823152542,
      "learning_rate": 1.545780356685724e-05,
      "loss": 0.0018,
      "step": 80960
    },
    {
      "epoch": 6.909292601757829,
      "grad_norm": 0.17395643889904022,
      "learning_rate": 1.5453536991210856e-05,
      "loss": 0.0019,
      "step": 80970
    },
    {
      "epoch": 6.910145916887107,
      "grad_norm": 0.11232781410217285,
      "learning_rate": 1.5449270415564467e-05,
      "loss": 0.0017,
      "step": 80980
    },
    {
      "epoch": 6.910999232016383,
      "grad_norm": 0.17399422824382782,
      "learning_rate": 1.544500383991808e-05,
      "loss": 0.0022,
      "step": 80990
    },
    {
      "epoch": 6.911852547145661,
      "grad_norm": 0.14820899069309235,
      "learning_rate": 1.5440737264271695e-05,
      "loss": 0.0017,
      "step": 81000
    },
    {
      "epoch": 6.912705862274938,
      "grad_norm": 0.290182501077652,
      "learning_rate": 1.543647068862531e-05,
      "loss": 0.0016,
      "step": 81010
    },
    {
      "epoch": 6.913559177404215,
      "grad_norm": 0.4552624225616455,
      "learning_rate": 1.5432204112978924e-05,
      "loss": 0.0017,
      "step": 81020
    },
    {
      "epoch": 6.914412492533493,
      "grad_norm": 0.046321239322423935,
      "learning_rate": 1.5427937537332538e-05,
      "loss": 0.0017,
      "step": 81030
    },
    {
      "epoch": 6.91526580766277,
      "grad_norm": 0.03789481893181801,
      "learning_rate": 1.5423670961686152e-05,
      "loss": 0.0018,
      "step": 81040
    },
    {
      "epoch": 6.916119122792047,
      "grad_norm": 0.2023880034685135,
      "learning_rate": 1.5419404386039766e-05,
      "loss": 0.0019,
      "step": 81050
    },
    {
      "epoch": 6.916972437921324,
      "grad_norm": 0.09512758255004883,
      "learning_rate": 1.541513781039338e-05,
      "loss": 0.0016,
      "step": 81060
    },
    {
      "epoch": 6.917825753050602,
      "grad_norm": 0.14524920284748077,
      "learning_rate": 1.541087123474699e-05,
      "loss": 0.0017,
      "step": 81070
    },
    {
      "epoch": 6.918679068179879,
      "grad_norm": 0.17632253468036652,
      "learning_rate": 1.5406604659100606e-05,
      "loss": 0.0013,
      "step": 81080
    },
    {
      "epoch": 6.919532383309156,
      "grad_norm": 0.20678161084651947,
      "learning_rate": 1.540233808345422e-05,
      "loss": 0.0022,
      "step": 81090
    },
    {
      "epoch": 6.920385698438434,
      "grad_norm": 0.20530705153942108,
      "learning_rate": 1.5398071507807834e-05,
      "loss": 0.0014,
      "step": 81100
    },
    {
      "epoch": 6.92123901356771,
      "grad_norm": 0.14485563337802887,
      "learning_rate": 1.5393804932161448e-05,
      "loss": 0.0021,
      "step": 81110
    },
    {
      "epoch": 6.922092328696988,
      "grad_norm": 0.13951903581619263,
      "learning_rate": 1.5389538356515063e-05,
      "loss": 0.0021,
      "step": 81120
    },
    {
      "epoch": 6.9229456438262655,
      "grad_norm": 0.2785477936267853,
      "learning_rate": 1.5385271780868677e-05,
      "loss": 0.0017,
      "step": 81130
    },
    {
      "epoch": 6.923798958955542,
      "grad_norm": 0.11785610020160675,
      "learning_rate": 1.538100520522229e-05,
      "loss": 0.0016,
      "step": 81140
    },
    {
      "epoch": 6.92465227408482,
      "grad_norm": 0.34805235266685486,
      "learning_rate": 1.5376738629575905e-05,
      "loss": 0.0018,
      "step": 81150
    },
    {
      "epoch": 6.925505589214096,
      "grad_norm": 0.08687491714954376,
      "learning_rate": 1.537247205392952e-05,
      "loss": 0.0021,
      "step": 81160
    },
    {
      "epoch": 6.926358904343374,
      "grad_norm": 0.22041188180446625,
      "learning_rate": 1.536820547828313e-05,
      "loss": 0.0016,
      "step": 81170
    },
    {
      "epoch": 6.9272122194726515,
      "grad_norm": 0.16684935986995697,
      "learning_rate": 1.5363938902636745e-05,
      "loss": 0.0017,
      "step": 81180
    },
    {
      "epoch": 6.928065534601928,
      "grad_norm": 0.14672337472438812,
      "learning_rate": 1.5359672326990355e-05,
      "loss": 0.0018,
      "step": 81190
    },
    {
      "epoch": 6.928918849731206,
      "grad_norm": 0.09445230662822723,
      "learning_rate": 1.535540575134397e-05,
      "loss": 0.0016,
      "step": 81200
    },
    {
      "epoch": 6.929772164860483,
      "grad_norm": 0.23582056164741516,
      "learning_rate": 1.5351139175697584e-05,
      "loss": 0.0017,
      "step": 81210
    },
    {
      "epoch": 6.93062547998976,
      "grad_norm": 0.12804336845874786,
      "learning_rate": 1.5346872600051198e-05,
      "loss": 0.0021,
      "step": 81220
    },
    {
      "epoch": 6.9314787951190375,
      "grad_norm": 0.048894401639699936,
      "learning_rate": 1.5342606024404812e-05,
      "loss": 0.0012,
      "step": 81230
    },
    {
      "epoch": 6.932332110248315,
      "grad_norm": 0.04627904295921326,
      "learning_rate": 1.5338339448758427e-05,
      "loss": 0.0017,
      "step": 81240
    },
    {
      "epoch": 6.933185425377592,
      "grad_norm": 0.14650017023086548,
      "learning_rate": 1.533407287311204e-05,
      "loss": 0.0018,
      "step": 81250
    },
    {
      "epoch": 6.934038740506869,
      "grad_norm": 0.16632041335105896,
      "learning_rate": 1.5329806297465655e-05,
      "loss": 0.0018,
      "step": 81260
    },
    {
      "epoch": 6.934892055636146,
      "grad_norm": 0.33639559149742126,
      "learning_rate": 1.532553972181927e-05,
      "loss": 0.0019,
      "step": 81270
    },
    {
      "epoch": 6.9357453707654235,
      "grad_norm": 0.1125546544790268,
      "learning_rate": 1.5321273146172884e-05,
      "loss": 0.0018,
      "step": 81280
    },
    {
      "epoch": 6.936598685894701,
      "grad_norm": 0.21445249021053314,
      "learning_rate": 1.5317006570526494e-05,
      "loss": 0.0017,
      "step": 81290
    },
    {
      "epoch": 6.937452001023978,
      "grad_norm": 0.28964683413505554,
      "learning_rate": 1.531273999488011e-05,
      "loss": 0.0016,
      "step": 81300
    },
    {
      "epoch": 6.938305316153255,
      "grad_norm": 0.2398247867822647,
      "learning_rate": 1.5308473419233723e-05,
      "loss": 0.0014,
      "step": 81310
    },
    {
      "epoch": 6.939158631282533,
      "grad_norm": 0.3115288019180298,
      "learning_rate": 1.5304206843587337e-05,
      "loss": 0.002,
      "step": 81320
    },
    {
      "epoch": 6.9400119464118095,
      "grad_norm": 0.043173547834157944,
      "learning_rate": 1.529994026794095e-05,
      "loss": 0.0016,
      "step": 81330
    },
    {
      "epoch": 6.940865261541087,
      "grad_norm": 0.2436007559299469,
      "learning_rate": 1.5295673692294566e-05,
      "loss": 0.0017,
      "step": 81340
    },
    {
      "epoch": 6.941718576670365,
      "grad_norm": 0.3291274309158325,
      "learning_rate": 1.529140711664818e-05,
      "loss": 0.0018,
      "step": 81350
    },
    {
      "epoch": 6.942571891799641,
      "grad_norm": 0.16719692945480347,
      "learning_rate": 1.5287140541001794e-05,
      "loss": 0.0016,
      "step": 81360
    },
    {
      "epoch": 6.943425206928919,
      "grad_norm": 0.06266902387142181,
      "learning_rate": 1.528287396535541e-05,
      "loss": 0.0018,
      "step": 81370
    },
    {
      "epoch": 6.944278522058196,
      "grad_norm": 0.14633193612098694,
      "learning_rate": 1.5278607389709023e-05,
      "loss": 0.0017,
      "step": 81380
    },
    {
      "epoch": 6.945131837187473,
      "grad_norm": 0.11053508520126343,
      "learning_rate": 1.5274340814062633e-05,
      "loss": 0.0018,
      "step": 81390
    },
    {
      "epoch": 6.945985152316751,
      "grad_norm": 0.1871553212404251,
      "learning_rate": 1.5270074238416248e-05,
      "loss": 0.002,
      "step": 81400
    },
    {
      "epoch": 6.946838467446028,
      "grad_norm": 0.3234173357486725,
      "learning_rate": 1.5265807662769862e-05,
      "loss": 0.0021,
      "step": 81410
    },
    {
      "epoch": 6.947691782575305,
      "grad_norm": 0.07098696380853653,
      "learning_rate": 1.5261541087123476e-05,
      "loss": 0.0017,
      "step": 81420
    },
    {
      "epoch": 6.948545097704582,
      "grad_norm": 0.06889224797487259,
      "learning_rate": 1.525727451147709e-05,
      "loss": 0.002,
      "step": 81430
    },
    {
      "epoch": 6.94939841283386,
      "grad_norm": 0.05001117289066315,
      "learning_rate": 1.5253007935830705e-05,
      "loss": 0.0019,
      "step": 81440
    },
    {
      "epoch": 6.950251727963137,
      "grad_norm": 0.04908694326877594,
      "learning_rate": 1.5248741360184316e-05,
      "loss": 0.0021,
      "step": 81450
    },
    {
      "epoch": 6.951105043092414,
      "grad_norm": 0.29813623428344727,
      "learning_rate": 1.524447478453793e-05,
      "loss": 0.0019,
      "step": 81460
    },
    {
      "epoch": 6.951958358221692,
      "grad_norm": 0.13823960721492767,
      "learning_rate": 1.5240208208891544e-05,
      "loss": 0.0014,
      "step": 81470
    },
    {
      "epoch": 6.952811673350968,
      "grad_norm": 0.06305365264415741,
      "learning_rate": 1.5235941633245157e-05,
      "loss": 0.0019,
      "step": 81480
    },
    {
      "epoch": 6.953664988480246,
      "grad_norm": 0.23983532190322876,
      "learning_rate": 1.523167505759877e-05,
      "loss": 0.0016,
      "step": 81490
    },
    {
      "epoch": 6.954518303609523,
      "grad_norm": 0.14592841267585754,
      "learning_rate": 1.5227408481952385e-05,
      "loss": 0.0015,
      "step": 81500
    },
    {
      "epoch": 6.9553716187388,
      "grad_norm": 0.04245540127158165,
      "learning_rate": 1.5223141906306e-05,
      "loss": 0.0016,
      "step": 81510
    },
    {
      "epoch": 6.956224933868078,
      "grad_norm": 0.11631527543067932,
      "learning_rate": 1.5218875330659612e-05,
      "loss": 0.0016,
      "step": 81520
    },
    {
      "epoch": 6.957078248997354,
      "grad_norm": 0.2368396520614624,
      "learning_rate": 1.5214608755013226e-05,
      "loss": 0.0015,
      "step": 81530
    },
    {
      "epoch": 6.957931564126632,
      "grad_norm": 0.032875027507543564,
      "learning_rate": 1.521034217936684e-05,
      "loss": 0.0018,
      "step": 81540
    },
    {
      "epoch": 6.9587848792559095,
      "grad_norm": 0.030278049409389496,
      "learning_rate": 1.5206075603720455e-05,
      "loss": 0.0017,
      "step": 81550
    },
    {
      "epoch": 6.959638194385186,
      "grad_norm": 0.1790986955165863,
      "learning_rate": 1.5201809028074069e-05,
      "loss": 0.0017,
      "step": 81560
    },
    {
      "epoch": 6.960491509514464,
      "grad_norm": 0.093022421002388,
      "learning_rate": 1.5197542452427681e-05,
      "loss": 0.0022,
      "step": 81570
    },
    {
      "epoch": 6.961344824643741,
      "grad_norm": 0.17060233652591705,
      "learning_rate": 1.5193275876781296e-05,
      "loss": 0.0016,
      "step": 81580
    },
    {
      "epoch": 6.962198139773018,
      "grad_norm": 0.03902677446603775,
      "learning_rate": 1.518900930113491e-05,
      "loss": 0.0016,
      "step": 81590
    },
    {
      "epoch": 6.9630514549022955,
      "grad_norm": 0.20244035124778748,
      "learning_rate": 1.5184742725488524e-05,
      "loss": 0.0015,
      "step": 81600
    },
    {
      "epoch": 6.963904770031573,
      "grad_norm": 0.11256744712591171,
      "learning_rate": 1.5180476149842138e-05,
      "loss": 0.0018,
      "step": 81610
    },
    {
      "epoch": 6.96475808516085,
      "grad_norm": 0.029404347762465477,
      "learning_rate": 1.5176209574195751e-05,
      "loss": 0.0015,
      "step": 81620
    },
    {
      "epoch": 6.965611400290127,
      "grad_norm": 0.16160349547863007,
      "learning_rate": 1.5171942998549365e-05,
      "loss": 0.002,
      "step": 81630
    },
    {
      "epoch": 6.966464715419404,
      "grad_norm": 0.5133152604103088,
      "learning_rate": 1.516767642290298e-05,
      "loss": 0.002,
      "step": 81640
    },
    {
      "epoch": 6.9673180305486815,
      "grad_norm": 0.1176350861787796,
      "learning_rate": 1.5163409847256594e-05,
      "loss": 0.0018,
      "step": 81650
    },
    {
      "epoch": 6.968171345677959,
      "grad_norm": 0.13159705698490143,
      "learning_rate": 1.5159143271610208e-05,
      "loss": 0.0016,
      "step": 81660
    },
    {
      "epoch": 6.969024660807236,
      "grad_norm": 0.5143606066703796,
      "learning_rate": 1.515487669596382e-05,
      "loss": 0.0015,
      "step": 81670
    },
    {
      "epoch": 6.969877975936513,
      "grad_norm": 0.09284297376871109,
      "learning_rate": 1.5150610120317435e-05,
      "loss": 0.0016,
      "step": 81680
    },
    {
      "epoch": 6.970731291065791,
      "grad_norm": 0.16905246675014496,
      "learning_rate": 1.5146343544671049e-05,
      "loss": 0.0019,
      "step": 81690
    },
    {
      "epoch": 6.9715846061950675,
      "grad_norm": 0.12850771844387054,
      "learning_rate": 1.5142076969024663e-05,
      "loss": 0.0016,
      "step": 81700
    },
    {
      "epoch": 6.972437921324345,
      "grad_norm": 0.21083249151706696,
      "learning_rate": 1.5137810393378277e-05,
      "loss": 0.0016,
      "step": 81710
    },
    {
      "epoch": 6.973291236453623,
      "grad_norm": 0.12815262377262115,
      "learning_rate": 1.5133543817731888e-05,
      "loss": 0.002,
      "step": 81720
    },
    {
      "epoch": 6.974144551582899,
      "grad_norm": 0.261283814907074,
      "learning_rate": 1.5129277242085502e-05,
      "loss": 0.002,
      "step": 81730
    },
    {
      "epoch": 6.974997866712177,
      "grad_norm": 0.2011636346578598,
      "learning_rate": 1.5125010666439115e-05,
      "loss": 0.0019,
      "step": 81740
    },
    {
      "epoch": 6.975851181841454,
      "grad_norm": 0.14460112154483795,
      "learning_rate": 1.512074409079273e-05,
      "loss": 0.0018,
      "step": 81750
    },
    {
      "epoch": 6.976704496970731,
      "grad_norm": 0.06133589148521423,
      "learning_rate": 1.5116477515146343e-05,
      "loss": 0.0013,
      "step": 81760
    },
    {
      "epoch": 6.977557812100009,
      "grad_norm": 0.5355666279792786,
      "learning_rate": 1.5112210939499958e-05,
      "loss": 0.0018,
      "step": 81770
    },
    {
      "epoch": 6.978411127229286,
      "grad_norm": 0.14942482113838196,
      "learning_rate": 1.5107944363853572e-05,
      "loss": 0.0016,
      "step": 81780
    },
    {
      "epoch": 6.979264442358563,
      "grad_norm": 0.026457887142896652,
      "learning_rate": 1.5103677788207184e-05,
      "loss": 0.0023,
      "step": 81790
    },
    {
      "epoch": 6.98011775748784,
      "grad_norm": 0.09777722507715225,
      "learning_rate": 1.5099411212560799e-05,
      "loss": 0.0019,
      "step": 81800
    },
    {
      "epoch": 6.980971072617118,
      "grad_norm": 0.027662916108965874,
      "learning_rate": 1.5095144636914413e-05,
      "loss": 0.0014,
      "step": 81810
    },
    {
      "epoch": 6.981824387746395,
      "grad_norm": 0.2565193474292755,
      "learning_rate": 1.5090878061268027e-05,
      "loss": 0.0017,
      "step": 81820
    },
    {
      "epoch": 6.982677702875672,
      "grad_norm": 0.3633561134338379,
      "learning_rate": 1.5086611485621641e-05,
      "loss": 0.0017,
      "step": 81830
    },
    {
      "epoch": 6.98353101800495,
      "grad_norm": 0.20514503121376038,
      "learning_rate": 1.5082344909975254e-05,
      "loss": 0.0018,
      "step": 81840
    },
    {
      "epoch": 6.984384333134226,
      "grad_norm": 0.14789196848869324,
      "learning_rate": 1.5078078334328868e-05,
      "loss": 0.0014,
      "step": 81850
    },
    {
      "epoch": 6.985237648263504,
      "grad_norm": 0.046356357634067535,
      "learning_rate": 1.5073811758682482e-05,
      "loss": 0.0021,
      "step": 81860
    },
    {
      "epoch": 6.986090963392781,
      "grad_norm": 0.3135996460914612,
      "learning_rate": 1.5069545183036097e-05,
      "loss": 0.0017,
      "step": 81870
    },
    {
      "epoch": 6.986944278522058,
      "grad_norm": 0.19900888204574585,
      "learning_rate": 1.506527860738971e-05,
      "loss": 0.0015,
      "step": 81880
    },
    {
      "epoch": 6.987797593651336,
      "grad_norm": 0.035854410380125046,
      "learning_rate": 1.5061012031743324e-05,
      "loss": 0.0014,
      "step": 81890
    },
    {
      "epoch": 6.988650908780612,
      "grad_norm": 0.12404147535562515,
      "learning_rate": 1.5056745456096938e-05,
      "loss": 0.0018,
      "step": 81900
    },
    {
      "epoch": 6.98950422390989,
      "grad_norm": 0.06492216885089874,
      "learning_rate": 1.5052478880450552e-05,
      "loss": 0.0021,
      "step": 81910
    },
    {
      "epoch": 6.9903575390391675,
      "grad_norm": 0.5956721901893616,
      "learning_rate": 1.5048212304804166e-05,
      "loss": 0.0019,
      "step": 81920
    },
    {
      "epoch": 6.991210854168444,
      "grad_norm": 0.027536975219845772,
      "learning_rate": 1.5043945729157779e-05,
      "loss": 0.0019,
      "step": 81930
    },
    {
      "epoch": 6.992064169297722,
      "grad_norm": 0.1639225333929062,
      "learning_rate": 1.5039679153511393e-05,
      "loss": 0.0017,
      "step": 81940
    },
    {
      "epoch": 6.992917484426999,
      "grad_norm": 0.049045901745557785,
      "learning_rate": 1.5035412577865007e-05,
      "loss": 0.0021,
      "step": 81950
    },
    {
      "epoch": 6.993770799556276,
      "grad_norm": 0.14416314661502838,
      "learning_rate": 1.5031146002218622e-05,
      "loss": 0.0017,
      "step": 81960
    },
    {
      "epoch": 6.9946241146855535,
      "grad_norm": 0.060401491820812225,
      "learning_rate": 1.5026879426572236e-05,
      "loss": 0.0017,
      "step": 81970
    },
    {
      "epoch": 6.995477429814831,
      "grad_norm": 0.09631116688251495,
      "learning_rate": 1.5022612850925847e-05,
      "loss": 0.0022,
      "step": 81980
    },
    {
      "epoch": 6.996330744944108,
      "grad_norm": 0.03973795846104622,
      "learning_rate": 1.501834627527946e-05,
      "loss": 0.0017,
      "step": 81990
    },
    {
      "epoch": 6.997184060073385,
      "grad_norm": 0.10996304452419281,
      "learning_rate": 1.5014079699633073e-05,
      "loss": 0.0025,
      "step": 82000
    },
    {
      "epoch": 6.998037375202662,
      "grad_norm": 0.08273861557245255,
      "learning_rate": 1.5009813123986688e-05,
      "loss": 0.0015,
      "step": 82010
    },
    {
      "epoch": 6.9988906903319394,
      "grad_norm": 0.17334647476673126,
      "learning_rate": 1.5005546548340302e-05,
      "loss": 0.0024,
      "step": 82020
    },
    {
      "epoch": 6.999744005461217,
      "grad_norm": 0.04793304204940796,
      "learning_rate": 1.5001279972693916e-05,
      "loss": 0.0015,
      "step": 82030
    },
    {
      "epoch": 7.0,
      "eval_loss": 0.0017822867957875133,
      "eval_runtime": 101.3725,
      "eval_samples_per_second": 1479.691,
      "eval_steps_per_second": 23.123,
      "step": 82033
    },
    {
      "epoch": 7.000597320590494,
      "grad_norm": 0.04649193957448006,
      "learning_rate": 1.499701339704753e-05,
      "loss": 0.002,
      "step": 82040
    },
    {
      "epoch": 7.001450635719771,
      "grad_norm": 0.24555325508117676,
      "learning_rate": 1.4992746821401143e-05,
      "loss": 0.0016,
      "step": 82050
    },
    {
      "epoch": 7.002303950849049,
      "grad_norm": 0.026532934978604317,
      "learning_rate": 1.4988480245754757e-05,
      "loss": 0.0016,
      "step": 82060
    },
    {
      "epoch": 7.003157265978325,
      "grad_norm": 0.21801543235778809,
      "learning_rate": 1.4984213670108371e-05,
      "loss": 0.0018,
      "step": 82070
    },
    {
      "epoch": 7.004010581107603,
      "grad_norm": 0.09409346431493759,
      "learning_rate": 1.4979947094461986e-05,
      "loss": 0.0017,
      "step": 82080
    },
    {
      "epoch": 7.0048638962368805,
      "grad_norm": 0.042280081659555435,
      "learning_rate": 1.49756805188156e-05,
      "loss": 0.0018,
      "step": 82090
    },
    {
      "epoch": 7.005717211366157,
      "grad_norm": 0.043570782989263535,
      "learning_rate": 1.4971413943169212e-05,
      "loss": 0.0019,
      "step": 82100
    },
    {
      "epoch": 7.006570526495435,
      "grad_norm": 0.046280406415462494,
      "learning_rate": 1.4967147367522827e-05,
      "loss": 0.0012,
      "step": 82110
    },
    {
      "epoch": 7.007423841624712,
      "grad_norm": 0.19987814128398895,
      "learning_rate": 1.4962880791876441e-05,
      "loss": 0.002,
      "step": 82120
    },
    {
      "epoch": 7.008277156753989,
      "grad_norm": 0.12786300480365753,
      "learning_rate": 1.4958614216230055e-05,
      "loss": 0.002,
      "step": 82130
    },
    {
      "epoch": 7.0091304718832665,
      "grad_norm": 0.09277760982513428,
      "learning_rate": 1.495434764058367e-05,
      "loss": 0.0015,
      "step": 82140
    },
    {
      "epoch": 7.009983787012544,
      "grad_norm": 0.08124537020921707,
      "learning_rate": 1.4950081064937282e-05,
      "loss": 0.0017,
      "step": 82150
    },
    {
      "epoch": 7.010837102141821,
      "grad_norm": 0.13170333206653595,
      "learning_rate": 1.4945814489290896e-05,
      "loss": 0.002,
      "step": 82160
    },
    {
      "epoch": 7.011690417271098,
      "grad_norm": 0.1362113356590271,
      "learning_rate": 1.494154791364451e-05,
      "loss": 0.0017,
      "step": 82170
    },
    {
      "epoch": 7.012543732400376,
      "grad_norm": 0.23260532319545746,
      "learning_rate": 1.4937281337998125e-05,
      "loss": 0.0015,
      "step": 82180
    },
    {
      "epoch": 7.0133970475296525,
      "grad_norm": 0.22384725511074066,
      "learning_rate": 1.4933014762351737e-05,
      "loss": 0.0024,
      "step": 82190
    },
    {
      "epoch": 7.01425036265893,
      "grad_norm": 0.11022499203681946,
      "learning_rate": 1.4928748186705351e-05,
      "loss": 0.0015,
      "step": 82200
    },
    {
      "epoch": 7.015103677788207,
      "grad_norm": 0.13147282600402832,
      "learning_rate": 1.4924481611058966e-05,
      "loss": 0.0014,
      "step": 82210
    },
    {
      "epoch": 7.015956992917484,
      "grad_norm": 0.2729456126689911,
      "learning_rate": 1.492021503541258e-05,
      "loss": 0.0016,
      "step": 82220
    },
    {
      "epoch": 7.016810308046762,
      "grad_norm": 0.234821155667305,
      "learning_rate": 1.4915948459766194e-05,
      "loss": 0.0015,
      "step": 82230
    },
    {
      "epoch": 7.0176636231760385,
      "grad_norm": 0.06775014102458954,
      "learning_rate": 1.4911681884119807e-05,
      "loss": 0.0016,
      "step": 82240
    },
    {
      "epoch": 7.018516938305316,
      "grad_norm": 0.2471170723438263,
      "learning_rate": 1.490741530847342e-05,
      "loss": 0.0019,
      "step": 82250
    },
    {
      "epoch": 7.019370253434594,
      "grad_norm": 0.23813971877098083,
      "learning_rate": 1.4903148732827032e-05,
      "loss": 0.0018,
      "step": 82260
    },
    {
      "epoch": 7.02022356856387,
      "grad_norm": 0.09077803045511246,
      "learning_rate": 1.4898882157180646e-05,
      "loss": 0.0018,
      "step": 82270
    },
    {
      "epoch": 7.021076883693148,
      "grad_norm": 0.03169115632772446,
      "learning_rate": 1.489461558153426e-05,
      "loss": 0.0018,
      "step": 82280
    },
    {
      "epoch": 7.021930198822425,
      "grad_norm": 0.18287162482738495,
      "learning_rate": 1.4890349005887875e-05,
      "loss": 0.0014,
      "step": 82290
    },
    {
      "epoch": 7.022783513951702,
      "grad_norm": 0.3994833528995514,
      "learning_rate": 1.4886082430241489e-05,
      "loss": 0.0019,
      "step": 82300
    },
    {
      "epoch": 7.02363682908098,
      "grad_norm": 0.11298320442438126,
      "learning_rate": 1.4881815854595101e-05,
      "loss": 0.0014,
      "step": 82310
    },
    {
      "epoch": 7.024490144210257,
      "grad_norm": 0.22158735990524292,
      "learning_rate": 1.4877549278948716e-05,
      "loss": 0.0017,
      "step": 82320
    },
    {
      "epoch": 7.025343459339534,
      "grad_norm": 0.2578921318054199,
      "learning_rate": 1.487328270330233e-05,
      "loss": 0.0018,
      "step": 82330
    },
    {
      "epoch": 7.026196774468811,
      "grad_norm": 0.21410347521305084,
      "learning_rate": 1.4869016127655944e-05,
      "loss": 0.0014,
      "step": 82340
    },
    {
      "epoch": 7.027050089598089,
      "grad_norm": 0.2914569675922394,
      "learning_rate": 1.4864749552009558e-05,
      "loss": 0.0016,
      "step": 82350
    },
    {
      "epoch": 7.027903404727366,
      "grad_norm": 0.27328380942344666,
      "learning_rate": 1.486048297636317e-05,
      "loss": 0.0019,
      "step": 82360
    },
    {
      "epoch": 7.028756719856643,
      "grad_norm": 0.028661930933594704,
      "learning_rate": 1.4856216400716785e-05,
      "loss": 0.0017,
      "step": 82370
    },
    {
      "epoch": 7.029610034985921,
      "grad_norm": 0.1661914438009262,
      "learning_rate": 1.48519498250704e-05,
      "loss": 0.0018,
      "step": 82380
    },
    {
      "epoch": 7.030463350115197,
      "grad_norm": 0.23695629835128784,
      "learning_rate": 1.4847683249424014e-05,
      "loss": 0.0016,
      "step": 82390
    },
    {
      "epoch": 7.031316665244475,
      "grad_norm": 0.1764330118894577,
      "learning_rate": 1.4843416673777628e-05,
      "loss": 0.0014,
      "step": 82400
    },
    {
      "epoch": 7.032169980373752,
      "grad_norm": 0.06599009782075882,
      "learning_rate": 1.483915009813124e-05,
      "loss": 0.0015,
      "step": 82410
    },
    {
      "epoch": 7.033023295503029,
      "grad_norm": 0.23883025348186493,
      "learning_rate": 1.4834883522484855e-05,
      "loss": 0.0016,
      "step": 82420
    },
    {
      "epoch": 7.033876610632307,
      "grad_norm": 0.11201350390911102,
      "learning_rate": 1.4830616946838469e-05,
      "loss": 0.0021,
      "step": 82430
    },
    {
      "epoch": 7.034729925761583,
      "grad_norm": 0.03433538228273392,
      "learning_rate": 1.4826350371192083e-05,
      "loss": 0.0017,
      "step": 82440
    },
    {
      "epoch": 7.035583240890861,
      "grad_norm": 0.40213853120803833,
      "learning_rate": 1.4822083795545697e-05,
      "loss": 0.0016,
      "step": 82450
    },
    {
      "epoch": 7.0364365560201385,
      "grad_norm": 0.2746300995349884,
      "learning_rate": 1.481781721989931e-05,
      "loss": 0.0018,
      "step": 82460
    },
    {
      "epoch": 7.037289871149415,
      "grad_norm": 0.1694672852754593,
      "learning_rate": 1.4813550644252924e-05,
      "loss": 0.0017,
      "step": 82470
    },
    {
      "epoch": 7.038143186278693,
      "grad_norm": 0.14810264110565186,
      "learning_rate": 1.4809284068606538e-05,
      "loss": 0.0016,
      "step": 82480
    },
    {
      "epoch": 7.03899650140797,
      "grad_norm": 0.294240266084671,
      "learning_rate": 1.4805017492960153e-05,
      "loss": 0.002,
      "step": 82490
    },
    {
      "epoch": 7.039849816537247,
      "grad_norm": 0.14192889630794525,
      "learning_rate": 1.4800750917313767e-05,
      "loss": 0.002,
      "step": 82500
    },
    {
      "epoch": 7.0407031316665245,
      "grad_norm": 0.05729823559522629,
      "learning_rate": 1.479648434166738e-05,
      "loss": 0.0016,
      "step": 82510
    },
    {
      "epoch": 7.041556446795802,
      "grad_norm": 0.23132406175136566,
      "learning_rate": 1.479221776602099e-05,
      "loss": 0.0022,
      "step": 82520
    },
    {
      "epoch": 7.042409761925079,
      "grad_norm": 0.2540113925933838,
      "learning_rate": 1.4787951190374604e-05,
      "loss": 0.0017,
      "step": 82530
    },
    {
      "epoch": 7.043263077054356,
      "grad_norm": 0.07815109938383102,
      "learning_rate": 1.4783684614728219e-05,
      "loss": 0.0017,
      "step": 82540
    },
    {
      "epoch": 7.044116392183634,
      "grad_norm": 0.09741605073213577,
      "learning_rate": 1.4779418039081833e-05,
      "loss": 0.0019,
      "step": 82550
    },
    {
      "epoch": 7.0449697073129105,
      "grad_norm": 0.12871888279914856,
      "learning_rate": 1.4775151463435447e-05,
      "loss": 0.0017,
      "step": 82560
    },
    {
      "epoch": 7.045823022442188,
      "grad_norm": 0.24021312594413757,
      "learning_rate": 1.477088488778906e-05,
      "loss": 0.0023,
      "step": 82570
    },
    {
      "epoch": 7.046676337571465,
      "grad_norm": 0.2618955671787262,
      "learning_rate": 1.4766618312142674e-05,
      "loss": 0.0023,
      "step": 82580
    },
    {
      "epoch": 7.047529652700742,
      "grad_norm": 0.3454802632331848,
      "learning_rate": 1.4762351736496288e-05,
      "loss": 0.0019,
      "step": 82590
    },
    {
      "epoch": 7.04838296783002,
      "grad_norm": 0.0567658506333828,
      "learning_rate": 1.4758085160849902e-05,
      "loss": 0.0018,
      "step": 82600
    },
    {
      "epoch": 7.0492362829592965,
      "grad_norm": 0.09235338866710663,
      "learning_rate": 1.4753818585203517e-05,
      "loss": 0.0017,
      "step": 82610
    },
    {
      "epoch": 7.050089598088574,
      "grad_norm": 0.06051894277334213,
      "learning_rate": 1.474955200955713e-05,
      "loss": 0.002,
      "step": 82620
    },
    {
      "epoch": 7.050942913217852,
      "grad_norm": 0.03294254094362259,
      "learning_rate": 1.4745285433910743e-05,
      "loss": 0.0018,
      "step": 82630
    },
    {
      "epoch": 7.051796228347128,
      "grad_norm": 0.3081854283809662,
      "learning_rate": 1.4741018858264358e-05,
      "loss": 0.0023,
      "step": 82640
    },
    {
      "epoch": 7.052649543476406,
      "grad_norm": 0.20007438957691193,
      "learning_rate": 1.4736752282617972e-05,
      "loss": 0.002,
      "step": 82650
    },
    {
      "epoch": 7.053502858605683,
      "grad_norm": 0.016540681943297386,
      "learning_rate": 1.4732485706971586e-05,
      "loss": 0.0017,
      "step": 82660
    },
    {
      "epoch": 7.05435617373496,
      "grad_norm": 0.18825387954711914,
      "learning_rate": 1.4728219131325199e-05,
      "loss": 0.0015,
      "step": 82670
    },
    {
      "epoch": 7.055209488864238,
      "grad_norm": 0.14630089700222015,
      "learning_rate": 1.4723952555678813e-05,
      "loss": 0.002,
      "step": 82680
    },
    {
      "epoch": 7.056062803993515,
      "grad_norm": 0.10663081705570221,
      "learning_rate": 1.4719685980032427e-05,
      "loss": 0.0019,
      "step": 82690
    },
    {
      "epoch": 7.056916119122792,
      "grad_norm": 0.2383635938167572,
      "learning_rate": 1.4715419404386041e-05,
      "loss": 0.0015,
      "step": 82700
    },
    {
      "epoch": 7.057769434252069,
      "grad_norm": 0.14773914217948914,
      "learning_rate": 1.4711152828739656e-05,
      "loss": 0.0019,
      "step": 82710
    },
    {
      "epoch": 7.058622749381347,
      "grad_norm": 0.21904811263084412,
      "learning_rate": 1.4706886253093268e-05,
      "loss": 0.002,
      "step": 82720
    },
    {
      "epoch": 7.059476064510624,
      "grad_norm": 0.07928059995174408,
      "learning_rate": 1.4702619677446882e-05,
      "loss": 0.0018,
      "step": 82730
    },
    {
      "epoch": 7.060329379639901,
      "grad_norm": 0.11605734378099442,
      "learning_rate": 1.4698353101800497e-05,
      "loss": 0.0017,
      "step": 82740
    },
    {
      "epoch": 7.061182694769178,
      "grad_norm": 0.1374271959066391,
      "learning_rate": 1.4694086526154111e-05,
      "loss": 0.0021,
      "step": 82750
    },
    {
      "epoch": 7.062036009898455,
      "grad_norm": 0.11618854850530624,
      "learning_rate": 1.4689819950507725e-05,
      "loss": 0.0018,
      "step": 82760
    },
    {
      "epoch": 7.062889325027733,
      "grad_norm": 0.07607489079236984,
      "learning_rate": 1.4685553374861338e-05,
      "loss": 0.0017,
      "step": 82770
    },
    {
      "epoch": 7.06374264015701,
      "grad_norm": 0.3436458706855774,
      "learning_rate": 1.4681286799214949e-05,
      "loss": 0.0018,
      "step": 82780
    },
    {
      "epoch": 7.064595955286287,
      "grad_norm": 0.1092098206281662,
      "learning_rate": 1.4677020223568563e-05,
      "loss": 0.0018,
      "step": 82790
    },
    {
      "epoch": 7.065449270415565,
      "grad_norm": 0.07859263569116592,
      "learning_rate": 1.4672753647922177e-05,
      "loss": 0.002,
      "step": 82800
    },
    {
      "epoch": 7.066302585544841,
      "grad_norm": 0.13457611203193665,
      "learning_rate": 1.4668487072275791e-05,
      "loss": 0.0021,
      "step": 82810
    },
    {
      "epoch": 7.067155900674119,
      "grad_norm": 0.2906523644924164,
      "learning_rate": 1.4664220496629406e-05,
      "loss": 0.0016,
      "step": 82820
    },
    {
      "epoch": 7.0680092158033965,
      "grad_norm": 0.224015474319458,
      "learning_rate": 1.4659953920983018e-05,
      "loss": 0.0017,
      "step": 82830
    },
    {
      "epoch": 7.068862530932673,
      "grad_norm": 0.09326304495334625,
      "learning_rate": 1.4655687345336632e-05,
      "loss": 0.0013,
      "step": 82840
    },
    {
      "epoch": 7.069715846061951,
      "grad_norm": 0.15584024786949158,
      "learning_rate": 1.4651420769690247e-05,
      "loss": 0.0019,
      "step": 82850
    },
    {
      "epoch": 7.070569161191228,
      "grad_norm": 0.031604595482349396,
      "learning_rate": 1.464715419404386e-05,
      "loss": 0.0016,
      "step": 82860
    },
    {
      "epoch": 7.071422476320505,
      "grad_norm": 0.034031420946121216,
      "learning_rate": 1.4642887618397475e-05,
      "loss": 0.0015,
      "step": 82870
    },
    {
      "epoch": 7.0722757914497825,
      "grad_norm": 0.16447536647319794,
      "learning_rate": 1.4638621042751088e-05,
      "loss": 0.002,
      "step": 82880
    },
    {
      "epoch": 7.07312910657906,
      "grad_norm": 0.1177230179309845,
      "learning_rate": 1.4634354467104702e-05,
      "loss": 0.0019,
      "step": 82890
    },
    {
      "epoch": 7.073982421708337,
      "grad_norm": 0.39391446113586426,
      "learning_rate": 1.4630087891458316e-05,
      "loss": 0.0016,
      "step": 82900
    },
    {
      "epoch": 7.074835736837614,
      "grad_norm": 0.2503730356693268,
      "learning_rate": 1.462582131581193e-05,
      "loss": 0.0018,
      "step": 82910
    },
    {
      "epoch": 7.075689051966892,
      "grad_norm": 0.07433082163333893,
      "learning_rate": 1.4621554740165545e-05,
      "loss": 0.0018,
      "step": 82920
    },
    {
      "epoch": 7.0765423670961685,
      "grad_norm": 0.3406105041503906,
      "learning_rate": 1.4617288164519157e-05,
      "loss": 0.0023,
      "step": 82930
    },
    {
      "epoch": 7.077395682225446,
      "grad_norm": 0.29205140471458435,
      "learning_rate": 1.4613021588872771e-05,
      "loss": 0.0018,
      "step": 82940
    },
    {
      "epoch": 7.078248997354723,
      "grad_norm": 0.15050168335437775,
      "learning_rate": 1.4608755013226386e-05,
      "loss": 0.0018,
      "step": 82950
    },
    {
      "epoch": 7.079102312484,
      "grad_norm": 0.21695376932621002,
      "learning_rate": 1.460448843758e-05,
      "loss": 0.0019,
      "step": 82960
    },
    {
      "epoch": 7.079955627613278,
      "grad_norm": 0.30895888805389404,
      "learning_rate": 1.4600221861933614e-05,
      "loss": 0.0018,
      "step": 82970
    },
    {
      "epoch": 7.0808089427425545,
      "grad_norm": 0.28796112537384033,
      "learning_rate": 1.4595955286287227e-05,
      "loss": 0.0012,
      "step": 82980
    },
    {
      "epoch": 7.081662257871832,
      "grad_norm": 0.04115433618426323,
      "learning_rate": 1.4591688710640841e-05,
      "loss": 0.0014,
      "step": 82990
    },
    {
      "epoch": 7.08251557300111,
      "grad_norm": 0.058408938348293304,
      "learning_rate": 1.4587422134994455e-05,
      "loss": 0.0019,
      "step": 83000
    },
    {
      "epoch": 7.083368888130386,
      "grad_norm": 0.3661918044090271,
      "learning_rate": 1.458315555934807e-05,
      "loss": 0.0017,
      "step": 83010
    },
    {
      "epoch": 7.084222203259664,
      "grad_norm": 0.02658374048769474,
      "learning_rate": 1.4578888983701684e-05,
      "loss": 0.0018,
      "step": 83020
    },
    {
      "epoch": 7.085075518388941,
      "grad_norm": 0.42155760526657104,
      "learning_rate": 1.4574622408055296e-05,
      "loss": 0.0018,
      "step": 83030
    },
    {
      "epoch": 7.085928833518218,
      "grad_norm": 0.04353386536240578,
      "learning_rate": 1.457035583240891e-05,
      "loss": 0.0016,
      "step": 83040
    },
    {
      "epoch": 7.086782148647496,
      "grad_norm": 0.11123110353946686,
      "learning_rate": 1.4566089256762521e-05,
      "loss": 0.0014,
      "step": 83050
    },
    {
      "epoch": 7.087635463776773,
      "grad_norm": 0.04564092680811882,
      "learning_rate": 1.4561822681116135e-05,
      "loss": 0.0017,
      "step": 83060
    },
    {
      "epoch": 7.08848877890605,
      "grad_norm": 0.07691642642021179,
      "learning_rate": 1.455755610546975e-05,
      "loss": 0.0014,
      "step": 83070
    },
    {
      "epoch": 7.089342094035327,
      "grad_norm": 0.06471674144268036,
      "learning_rate": 1.4553289529823364e-05,
      "loss": 0.0017,
      "step": 83080
    },
    {
      "epoch": 7.090195409164605,
      "grad_norm": 0.21962988376617432,
      "learning_rate": 1.4549022954176977e-05,
      "loss": 0.0017,
      "step": 83090
    },
    {
      "epoch": 7.0910487242938816,
      "grad_norm": 0.09474401921033859,
      "learning_rate": 1.454475637853059e-05,
      "loss": 0.0016,
      "step": 83100
    },
    {
      "epoch": 7.091902039423159,
      "grad_norm": 0.11285429447889328,
      "learning_rate": 1.4540489802884205e-05,
      "loss": 0.0014,
      "step": 83110
    },
    {
      "epoch": 7.092755354552436,
      "grad_norm": 0.1290384978055954,
      "learning_rate": 1.453622322723782e-05,
      "loss": 0.0014,
      "step": 83120
    },
    {
      "epoch": 7.093608669681713,
      "grad_norm": 0.12987416982650757,
      "learning_rate": 1.4531956651591433e-05,
      "loss": 0.0017,
      "step": 83130
    },
    {
      "epoch": 7.094461984810991,
      "grad_norm": 0.27599093317985535,
      "learning_rate": 1.4527690075945046e-05,
      "loss": 0.0015,
      "step": 83140
    },
    {
      "epoch": 7.0953152999402676,
      "grad_norm": 0.04404131695628166,
      "learning_rate": 1.452342350029866e-05,
      "loss": 0.0016,
      "step": 83150
    },
    {
      "epoch": 7.096168615069545,
      "grad_norm": 0.07680955529212952,
      "learning_rate": 1.4519156924652275e-05,
      "loss": 0.0018,
      "step": 83160
    },
    {
      "epoch": 7.097021930198823,
      "grad_norm": 0.2084362655878067,
      "learning_rate": 1.4514890349005889e-05,
      "loss": 0.0021,
      "step": 83170
    },
    {
      "epoch": 7.097875245328099,
      "grad_norm": 0.12984700500965118,
      "learning_rate": 1.4510623773359503e-05,
      "loss": 0.0022,
      "step": 83180
    },
    {
      "epoch": 7.098728560457377,
      "grad_norm": 0.19276101887226105,
      "learning_rate": 1.4506357197713116e-05,
      "loss": 0.0014,
      "step": 83190
    },
    {
      "epoch": 7.099581875586654,
      "grad_norm": 0.06232418864965439,
      "learning_rate": 1.450209062206673e-05,
      "loss": 0.0017,
      "step": 83200
    },
    {
      "epoch": 7.100435190715931,
      "grad_norm": 0.34510165452957153,
      "learning_rate": 1.4497824046420344e-05,
      "loss": 0.0018,
      "step": 83210
    },
    {
      "epoch": 7.101288505845209,
      "grad_norm": 0.03965476527810097,
      "learning_rate": 1.4493557470773958e-05,
      "loss": 0.0017,
      "step": 83220
    },
    {
      "epoch": 7.102141820974486,
      "grad_norm": 0.046016160398721695,
      "learning_rate": 1.4489290895127573e-05,
      "loss": 0.0016,
      "step": 83230
    },
    {
      "epoch": 7.102995136103763,
      "grad_norm": 0.058271072804927826,
      "learning_rate": 1.4485024319481185e-05,
      "loss": 0.0021,
      "step": 83240
    },
    {
      "epoch": 7.10384845123304,
      "grad_norm": 0.10772180557250977,
      "learning_rate": 1.44807577438348e-05,
      "loss": 0.002,
      "step": 83250
    },
    {
      "epoch": 7.104701766362318,
      "grad_norm": 0.048444390296936035,
      "learning_rate": 1.4476491168188414e-05,
      "loss": 0.0015,
      "step": 83260
    },
    {
      "epoch": 7.105555081491595,
      "grad_norm": 0.10893090069293976,
      "learning_rate": 1.4472224592542028e-05,
      "loss": 0.0014,
      "step": 83270
    },
    {
      "epoch": 7.106408396620872,
      "grad_norm": 0.02482181042432785,
      "learning_rate": 1.4467958016895642e-05,
      "loss": 0.0019,
      "step": 83280
    },
    {
      "epoch": 7.10726171175015,
      "grad_norm": 0.11544962227344513,
      "learning_rate": 1.4463691441249255e-05,
      "loss": 0.0016,
      "step": 83290
    },
    {
      "epoch": 7.108115026879426,
      "grad_norm": 0.05750836059451103,
      "learning_rate": 1.4459424865602869e-05,
      "loss": 0.0014,
      "step": 83300
    },
    {
      "epoch": 7.108968342008704,
      "grad_norm": 0.09115418046712875,
      "learning_rate": 1.445515828995648e-05,
      "loss": 0.002,
      "step": 83310
    },
    {
      "epoch": 7.109821657137981,
      "grad_norm": 0.0946808010339737,
      "learning_rate": 1.4450891714310094e-05,
      "loss": 0.0016,
      "step": 83320
    },
    {
      "epoch": 7.110674972267258,
      "grad_norm": 0.03389977663755417,
      "learning_rate": 1.4446625138663708e-05,
      "loss": 0.0015,
      "step": 83330
    },
    {
      "epoch": 7.111528287396536,
      "grad_norm": 0.044802483171224594,
      "learning_rate": 1.4442358563017322e-05,
      "loss": 0.0015,
      "step": 83340
    },
    {
      "epoch": 7.112381602525812,
      "grad_norm": 0.16003569960594177,
      "learning_rate": 1.4438091987370937e-05,
      "loss": 0.0017,
      "step": 83350
    },
    {
      "epoch": 7.11323491765509,
      "grad_norm": 0.2689383924007416,
      "learning_rate": 1.443382541172455e-05,
      "loss": 0.002,
      "step": 83360
    },
    {
      "epoch": 7.1140882327843675,
      "grad_norm": 0.238602414727211,
      "learning_rate": 1.4429558836078163e-05,
      "loss": 0.0016,
      "step": 83370
    },
    {
      "epoch": 7.114941547913644,
      "grad_norm": 0.07473589479923248,
      "learning_rate": 1.4425292260431778e-05,
      "loss": 0.0018,
      "step": 83380
    },
    {
      "epoch": 7.115794863042922,
      "grad_norm": 0.19970592856407166,
      "learning_rate": 1.4421025684785392e-05,
      "loss": 0.0016,
      "step": 83390
    },
    {
      "epoch": 7.116648178172199,
      "grad_norm": 0.2189318984746933,
      "learning_rate": 1.4416759109139006e-05,
      "loss": 0.002,
      "step": 83400
    },
    {
      "epoch": 7.117501493301476,
      "grad_norm": 0.02998795546591282,
      "learning_rate": 1.4412492533492619e-05,
      "loss": 0.0017,
      "step": 83410
    },
    {
      "epoch": 7.1183548084307535,
      "grad_norm": 0.15065911412239075,
      "learning_rate": 1.4408225957846233e-05,
      "loss": 0.0019,
      "step": 83420
    },
    {
      "epoch": 7.119208123560031,
      "grad_norm": 0.2035934180021286,
      "learning_rate": 1.4403959382199847e-05,
      "loss": 0.0019,
      "step": 83430
    },
    {
      "epoch": 7.120061438689308,
      "grad_norm": 0.11396282911300659,
      "learning_rate": 1.4399692806553461e-05,
      "loss": 0.0014,
      "step": 83440
    },
    {
      "epoch": 7.120914753818585,
      "grad_norm": 0.11740943044424057,
      "learning_rate": 1.4395426230907074e-05,
      "loss": 0.0024,
      "step": 83450
    },
    {
      "epoch": 7.121768068947863,
      "grad_norm": 0.25649917125701904,
      "learning_rate": 1.4391159655260688e-05,
      "loss": 0.0017,
      "step": 83460
    },
    {
      "epoch": 7.1226213840771395,
      "grad_norm": 0.1835111677646637,
      "learning_rate": 1.4386893079614302e-05,
      "loss": 0.0014,
      "step": 83470
    },
    {
      "epoch": 7.123474699206417,
      "grad_norm": 0.17824286222457886,
      "learning_rate": 1.4382626503967917e-05,
      "loss": 0.0019,
      "step": 83480
    },
    {
      "epoch": 7.124328014335694,
      "grad_norm": 0.148991659283638,
      "learning_rate": 1.4378359928321531e-05,
      "loss": 0.0018,
      "step": 83490
    },
    {
      "epoch": 7.125181329464971,
      "grad_norm": 0.1061394214630127,
      "learning_rate": 1.4374093352675143e-05,
      "loss": 0.0021,
      "step": 83500
    },
    {
      "epoch": 7.126034644594249,
      "grad_norm": 0.28052759170532227,
      "learning_rate": 1.4369826777028758e-05,
      "loss": 0.0015,
      "step": 83510
    },
    {
      "epoch": 7.1268879597235255,
      "grad_norm": 0.0231251809746027,
      "learning_rate": 1.4365560201382372e-05,
      "loss": 0.002,
      "step": 83520
    },
    {
      "epoch": 7.127741274852803,
      "grad_norm": 0.025002386420965195,
      "learning_rate": 1.4361293625735986e-05,
      "loss": 0.0015,
      "step": 83530
    },
    {
      "epoch": 7.128594589982081,
      "grad_norm": 0.1677459329366684,
      "learning_rate": 1.43570270500896e-05,
      "loss": 0.002,
      "step": 83540
    },
    {
      "epoch": 7.129447905111357,
      "grad_norm": 0.04100282862782478,
      "learning_rate": 1.4352760474443213e-05,
      "loss": 0.0022,
      "step": 83550
    },
    {
      "epoch": 7.130301220240635,
      "grad_norm": 0.0583021380007267,
      "learning_rate": 1.4348493898796827e-05,
      "loss": 0.0019,
      "step": 83560
    },
    {
      "epoch": 7.131154535369912,
      "grad_norm": 0.0730762705206871,
      "learning_rate": 1.4344227323150441e-05,
      "loss": 0.0016,
      "step": 83570
    },
    {
      "epoch": 7.132007850499189,
      "grad_norm": 0.03401358798146248,
      "learning_rate": 1.4339960747504052e-05,
      "loss": 0.0017,
      "step": 83580
    },
    {
      "epoch": 7.132861165628467,
      "grad_norm": 0.03433842211961746,
      "learning_rate": 1.4335694171857667e-05,
      "loss": 0.0021,
      "step": 83590
    },
    {
      "epoch": 7.133714480757744,
      "grad_norm": 0.018952978774905205,
      "learning_rate": 1.433142759621128e-05,
      "loss": 0.0015,
      "step": 83600
    },
    {
      "epoch": 7.134567795887021,
      "grad_norm": 0.06317824870347977,
      "learning_rate": 1.4327161020564895e-05,
      "loss": 0.0013,
      "step": 83610
    },
    {
      "epoch": 7.135421111016298,
      "grad_norm": 0.13246724009513855,
      "learning_rate": 1.4322894444918508e-05,
      "loss": 0.0017,
      "step": 83620
    },
    {
      "epoch": 7.136274426145576,
      "grad_norm": 0.257700651884079,
      "learning_rate": 1.4318627869272122e-05,
      "loss": 0.0018,
      "step": 83630
    },
    {
      "epoch": 7.137127741274853,
      "grad_norm": 0.031398676335811615,
      "learning_rate": 1.4314361293625736e-05,
      "loss": 0.0017,
      "step": 83640
    },
    {
      "epoch": 7.13798105640413,
      "grad_norm": 0.07765855640172958,
      "learning_rate": 1.431009471797935e-05,
      "loss": 0.0018,
      "step": 83650
    },
    {
      "epoch": 7.138834371533408,
      "grad_norm": 0.2510570287704468,
      "learning_rate": 1.4305828142332965e-05,
      "loss": 0.0019,
      "step": 83660
    },
    {
      "epoch": 7.139687686662684,
      "grad_norm": 0.2441394031047821,
      "learning_rate": 1.4301561566686577e-05,
      "loss": 0.0022,
      "step": 83670
    },
    {
      "epoch": 7.140541001791962,
      "grad_norm": 0.14403004944324493,
      "learning_rate": 1.4297294991040191e-05,
      "loss": 0.0016,
      "step": 83680
    },
    {
      "epoch": 7.141394316921239,
      "grad_norm": 0.16418229043483734,
      "learning_rate": 1.4293028415393806e-05,
      "loss": 0.002,
      "step": 83690
    },
    {
      "epoch": 7.142247632050516,
      "grad_norm": 0.08171792328357697,
      "learning_rate": 1.428876183974742e-05,
      "loss": 0.0016,
      "step": 83700
    },
    {
      "epoch": 7.143100947179794,
      "grad_norm": 0.09765412658452988,
      "learning_rate": 1.4284495264101034e-05,
      "loss": 0.0018,
      "step": 83710
    },
    {
      "epoch": 7.14395426230907,
      "grad_norm": 0.18267038464546204,
      "learning_rate": 1.4280228688454647e-05,
      "loss": 0.0018,
      "step": 83720
    },
    {
      "epoch": 7.144807577438348,
      "grad_norm": 0.027600135654211044,
      "learning_rate": 1.427596211280826e-05,
      "loss": 0.0018,
      "step": 83730
    },
    {
      "epoch": 7.1456608925676255,
      "grad_norm": 0.08690741658210754,
      "learning_rate": 1.4271695537161875e-05,
      "loss": 0.0018,
      "step": 83740
    },
    {
      "epoch": 7.146514207696902,
      "grad_norm": 0.11100444197654724,
      "learning_rate": 1.426742896151549e-05,
      "loss": 0.0018,
      "step": 83750
    },
    {
      "epoch": 7.14736752282618,
      "grad_norm": 0.035858821123838425,
      "learning_rate": 1.4263162385869102e-05,
      "loss": 0.002,
      "step": 83760
    },
    {
      "epoch": 7.148220837955457,
      "grad_norm": 0.14551672339439392,
      "learning_rate": 1.4258895810222716e-05,
      "loss": 0.0016,
      "step": 83770
    },
    {
      "epoch": 7.149074153084734,
      "grad_norm": 0.05784782022237778,
      "learning_rate": 1.425462923457633e-05,
      "loss": 0.002,
      "step": 83780
    },
    {
      "epoch": 7.1499274682140115,
      "grad_norm": 0.09412987530231476,
      "learning_rate": 1.4250362658929945e-05,
      "loss": 0.0014,
      "step": 83790
    },
    {
      "epoch": 7.150780783343289,
      "grad_norm": 0.1296958476305008,
      "learning_rate": 1.4246096083283559e-05,
      "loss": 0.0023,
      "step": 83800
    },
    {
      "epoch": 7.151634098472566,
      "grad_norm": 0.12876281142234802,
      "learning_rate": 1.4241829507637171e-05,
      "loss": 0.0014,
      "step": 83810
    },
    {
      "epoch": 7.152487413601843,
      "grad_norm": 0.04605391249060631,
      "learning_rate": 1.4237562931990786e-05,
      "loss": 0.0017,
      "step": 83820
    },
    {
      "epoch": 7.153340728731121,
      "grad_norm": 0.07587383687496185,
      "learning_rate": 1.42332963563444e-05,
      "loss": 0.0014,
      "step": 83830
    },
    {
      "epoch": 7.1541940438603975,
      "grad_norm": 0.166438028216362,
      "learning_rate": 1.4229029780698014e-05,
      "loss": 0.0013,
      "step": 83840
    },
    {
      "epoch": 7.155047358989675,
      "grad_norm": 0.10402608662843704,
      "learning_rate": 1.4224763205051625e-05,
      "loss": 0.0023,
      "step": 83850
    },
    {
      "epoch": 7.155900674118952,
      "grad_norm": 0.09740304201841354,
      "learning_rate": 1.422049662940524e-05,
      "loss": 0.0012,
      "step": 83860
    },
    {
      "epoch": 7.156753989248229,
      "grad_norm": 0.05961623787879944,
      "learning_rate": 1.4216230053758853e-05,
      "loss": 0.0019,
      "step": 83870
    },
    {
      "epoch": 7.157607304377507,
      "grad_norm": 0.09579804539680481,
      "learning_rate": 1.4211963478112466e-05,
      "loss": 0.0016,
      "step": 83880
    },
    {
      "epoch": 7.1584606195067835,
      "grad_norm": 0.04887509346008301,
      "learning_rate": 1.420769690246608e-05,
      "loss": 0.0015,
      "step": 83890
    },
    {
      "epoch": 7.159313934636061,
      "grad_norm": 0.28080102801322937,
      "learning_rate": 1.4203430326819694e-05,
      "loss": 0.0014,
      "step": 83900
    },
    {
      "epoch": 7.160167249765339,
      "grad_norm": 0.029221927747130394,
      "learning_rate": 1.4199163751173309e-05,
      "loss": 0.0016,
      "step": 83910
    },
    {
      "epoch": 7.161020564894615,
      "grad_norm": 0.1687992662191391,
      "learning_rate": 1.4194897175526923e-05,
      "loss": 0.0019,
      "step": 83920
    },
    {
      "epoch": 7.161873880023893,
      "grad_norm": 0.2519749104976654,
      "learning_rate": 1.4190630599880535e-05,
      "loss": 0.0018,
      "step": 83930
    },
    {
      "epoch": 7.16272719515317,
      "grad_norm": 0.06522607058286667,
      "learning_rate": 1.418636402423415e-05,
      "loss": 0.0017,
      "step": 83940
    },
    {
      "epoch": 7.163580510282447,
      "grad_norm": 0.20921748876571655,
      "learning_rate": 1.4182097448587764e-05,
      "loss": 0.0014,
      "step": 83950
    },
    {
      "epoch": 7.164433825411725,
      "grad_norm": 0.14417602121829987,
      "learning_rate": 1.4177830872941378e-05,
      "loss": 0.002,
      "step": 83960
    },
    {
      "epoch": 7.165287140541002,
      "grad_norm": 0.3259018063545227,
      "learning_rate": 1.4173564297294992e-05,
      "loss": 0.0016,
      "step": 83970
    },
    {
      "epoch": 7.166140455670279,
      "grad_norm": 0.09412191063165665,
      "learning_rate": 1.4169297721648605e-05,
      "loss": 0.0016,
      "step": 83980
    },
    {
      "epoch": 7.166993770799556,
      "grad_norm": 0.060384880751371384,
      "learning_rate": 1.416503114600222e-05,
      "loss": 0.0016,
      "step": 83990
    },
    {
      "epoch": 7.167847085928834,
      "grad_norm": 0.09077315032482147,
      "learning_rate": 1.4160764570355833e-05,
      "loss": 0.0016,
      "step": 84000
    },
    {
      "epoch": 7.168700401058111,
      "grad_norm": 0.2713821828365326,
      "learning_rate": 1.4156497994709448e-05,
      "loss": 0.0014,
      "step": 84010
    },
    {
      "epoch": 7.169553716187388,
      "grad_norm": 0.20976251363754272,
      "learning_rate": 1.4152231419063062e-05,
      "loss": 0.0022,
      "step": 84020
    },
    {
      "epoch": 7.170407031316666,
      "grad_norm": 0.10779566317796707,
      "learning_rate": 1.4147964843416675e-05,
      "loss": 0.0016,
      "step": 84030
    },
    {
      "epoch": 7.171260346445942,
      "grad_norm": 0.13004657626152039,
      "learning_rate": 1.4143698267770289e-05,
      "loss": 0.0019,
      "step": 84040
    },
    {
      "epoch": 7.17211366157522,
      "grad_norm": 0.16451409459114075,
      "learning_rate": 1.4139431692123903e-05,
      "loss": 0.0016,
      "step": 84050
    },
    {
      "epoch": 7.172966976704497,
      "grad_norm": 0.08683259040117264,
      "learning_rate": 1.4135165116477517e-05,
      "loss": 0.0013,
      "step": 84060
    },
    {
      "epoch": 7.173820291833774,
      "grad_norm": 0.27198919653892517,
      "learning_rate": 1.413089854083113e-05,
      "loss": 0.0015,
      "step": 84070
    },
    {
      "epoch": 7.174673606963052,
      "grad_norm": 0.30770546197891235,
      "learning_rate": 1.4126631965184744e-05,
      "loss": 0.0019,
      "step": 84080
    },
    {
      "epoch": 7.175526922092328,
      "grad_norm": 0.06448917835950851,
      "learning_rate": 1.4122365389538358e-05,
      "loss": 0.0016,
      "step": 84090
    },
    {
      "epoch": 7.176380237221606,
      "grad_norm": 0.03018854558467865,
      "learning_rate": 1.4118098813891973e-05,
      "loss": 0.0017,
      "step": 84100
    },
    {
      "epoch": 7.1772335523508834,
      "grad_norm": 0.19960235059261322,
      "learning_rate": 1.4113832238245583e-05,
      "loss": 0.0019,
      "step": 84110
    },
    {
      "epoch": 7.17808686748016,
      "grad_norm": 0.09180089086294174,
      "learning_rate": 1.4109565662599198e-05,
      "loss": 0.0016,
      "step": 84120
    },
    {
      "epoch": 7.178940182609438,
      "grad_norm": 0.11494293063879013,
      "learning_rate": 1.4105299086952812e-05,
      "loss": 0.0018,
      "step": 84130
    },
    {
      "epoch": 7.179793497738715,
      "grad_norm": 0.09166299551725388,
      "learning_rate": 1.4101032511306424e-05,
      "loss": 0.0022,
      "step": 84140
    },
    {
      "epoch": 7.180646812867992,
      "grad_norm": 0.044625043869018555,
      "learning_rate": 1.4096765935660039e-05,
      "loss": 0.0017,
      "step": 84150
    },
    {
      "epoch": 7.1815001279972694,
      "grad_norm": 0.07683154940605164,
      "learning_rate": 1.4092499360013653e-05,
      "loss": 0.002,
      "step": 84160
    },
    {
      "epoch": 7.182353443126547,
      "grad_norm": 0.1880638301372528,
      "learning_rate": 1.4088232784367267e-05,
      "loss": 0.0015,
      "step": 84170
    },
    {
      "epoch": 7.183206758255824,
      "grad_norm": 0.044722773134708405,
      "learning_rate": 1.4083966208720881e-05,
      "loss": 0.0015,
      "step": 84180
    },
    {
      "epoch": 7.184060073385101,
      "grad_norm": 0.12661957740783691,
      "learning_rate": 1.4079699633074494e-05,
      "loss": 0.0017,
      "step": 84190
    },
    {
      "epoch": 7.184913388514379,
      "grad_norm": 0.36741918325424194,
      "learning_rate": 1.4075433057428108e-05,
      "loss": 0.0017,
      "step": 84200
    },
    {
      "epoch": 7.185766703643655,
      "grad_norm": 0.2011798620223999,
      "learning_rate": 1.4071166481781722e-05,
      "loss": 0.0017,
      "step": 84210
    },
    {
      "epoch": 7.186620018772933,
      "grad_norm": 0.27876928448677063,
      "learning_rate": 1.4066899906135337e-05,
      "loss": 0.0015,
      "step": 84220
    },
    {
      "epoch": 7.18747333390221,
      "grad_norm": 0.1921471655368805,
      "learning_rate": 1.4062633330488951e-05,
      "loss": 0.0015,
      "step": 84230
    },
    {
      "epoch": 7.188326649031487,
      "grad_norm": 0.32910963892936707,
      "learning_rate": 1.4058366754842563e-05,
      "loss": 0.0019,
      "step": 84240
    },
    {
      "epoch": 7.189179964160765,
      "grad_norm": 0.2587929964065552,
      "learning_rate": 1.4054100179196178e-05,
      "loss": 0.0015,
      "step": 84250
    },
    {
      "epoch": 7.190033279290041,
      "grad_norm": 0.1990838497877121,
      "learning_rate": 1.4049833603549792e-05,
      "loss": 0.0015,
      "step": 84260
    },
    {
      "epoch": 7.190886594419319,
      "grad_norm": 0.2365162968635559,
      "learning_rate": 1.4045567027903406e-05,
      "loss": 0.0021,
      "step": 84270
    },
    {
      "epoch": 7.1917399095485965,
      "grad_norm": 0.1650504618883133,
      "learning_rate": 1.404130045225702e-05,
      "loss": 0.0015,
      "step": 84280
    },
    {
      "epoch": 7.192593224677873,
      "grad_norm": 0.293363481760025,
      "learning_rate": 1.4037033876610633e-05,
      "loss": 0.0018,
      "step": 84290
    },
    {
      "epoch": 7.193446539807151,
      "grad_norm": 0.23775306344032288,
      "learning_rate": 1.4032767300964247e-05,
      "loss": 0.0023,
      "step": 84300
    },
    {
      "epoch": 7.194299854936428,
      "grad_norm": 0.219609797000885,
      "learning_rate": 1.4028500725317861e-05,
      "loss": 0.0017,
      "step": 84310
    },
    {
      "epoch": 7.195153170065705,
      "grad_norm": 0.13079999387264252,
      "learning_rate": 1.4024234149671476e-05,
      "loss": 0.0021,
      "step": 84320
    },
    {
      "epoch": 7.1960064851949825,
      "grad_norm": 0.0637536570429802,
      "learning_rate": 1.401996757402509e-05,
      "loss": 0.0018,
      "step": 84330
    },
    {
      "epoch": 7.19685980032426,
      "grad_norm": 0.17928597331047058,
      "learning_rate": 1.4015700998378702e-05,
      "loss": 0.002,
      "step": 84340
    },
    {
      "epoch": 7.197713115453537,
      "grad_norm": 0.1137685477733612,
      "learning_rate": 1.4011434422732317e-05,
      "loss": 0.0015,
      "step": 84350
    },
    {
      "epoch": 7.198566430582814,
      "grad_norm": 0.2042091339826584,
      "learning_rate": 1.4007167847085931e-05,
      "loss": 0.0022,
      "step": 84360
    },
    {
      "epoch": 7.199419745712092,
      "grad_norm": 0.21881501376628876,
      "learning_rate": 1.4002901271439545e-05,
      "loss": 0.0016,
      "step": 84370
    },
    {
      "epoch": 7.2002730608413685,
      "grad_norm": 0.0483134388923645,
      "learning_rate": 1.3998634695793156e-05,
      "loss": 0.0015,
      "step": 84380
    },
    {
      "epoch": 7.201126375970646,
      "grad_norm": 0.41769516468048096,
      "learning_rate": 1.399436812014677e-05,
      "loss": 0.0019,
      "step": 84390
    },
    {
      "epoch": 7.201979691099924,
      "grad_norm": 0.1311699002981186,
      "learning_rate": 1.3990101544500383e-05,
      "loss": 0.0018,
      "step": 84400
    },
    {
      "epoch": 7.2028330062292,
      "grad_norm": 0.2180473804473877,
      "learning_rate": 1.3985834968853997e-05,
      "loss": 0.0015,
      "step": 84410
    },
    {
      "epoch": 7.203686321358478,
      "grad_norm": 0.2566951513290405,
      "learning_rate": 1.3981568393207611e-05,
      "loss": 0.0018,
      "step": 84420
    },
    {
      "epoch": 7.2045396364877545,
      "grad_norm": 0.0315193310379982,
      "learning_rate": 1.3977301817561226e-05,
      "loss": 0.0016,
      "step": 84430
    },
    {
      "epoch": 7.205392951617032,
      "grad_norm": 0.12587594985961914,
      "learning_rate": 1.397303524191484e-05,
      "loss": 0.0016,
      "step": 84440
    },
    {
      "epoch": 7.20624626674631,
      "grad_norm": 0.07435153424739838,
      "learning_rate": 1.3968768666268452e-05,
      "loss": 0.0015,
      "step": 84450
    },
    {
      "epoch": 7.207099581875586,
      "grad_norm": 0.11316022276878357,
      "learning_rate": 1.3964502090622067e-05,
      "loss": 0.0018,
      "step": 84460
    },
    {
      "epoch": 7.207952897004864,
      "grad_norm": 0.3802737891674042,
      "learning_rate": 1.396023551497568e-05,
      "loss": 0.0013,
      "step": 84470
    },
    {
      "epoch": 7.208806212134141,
      "grad_norm": 0.033975180238485336,
      "learning_rate": 1.3955968939329295e-05,
      "loss": 0.003,
      "step": 84480
    },
    {
      "epoch": 7.209659527263418,
      "grad_norm": 0.2753942906856537,
      "learning_rate": 1.395170236368291e-05,
      "loss": 0.002,
      "step": 84490
    },
    {
      "epoch": 7.210512842392696,
      "grad_norm": 0.20420528948307037,
      "learning_rate": 1.3947435788036522e-05,
      "loss": 0.0015,
      "step": 84500
    },
    {
      "epoch": 7.211366157521973,
      "grad_norm": 0.08599621057510376,
      "learning_rate": 1.3943169212390136e-05,
      "loss": 0.0022,
      "step": 84510
    },
    {
      "epoch": 7.21221947265125,
      "grad_norm": 0.13112938404083252,
      "learning_rate": 1.393890263674375e-05,
      "loss": 0.0018,
      "step": 84520
    },
    {
      "epoch": 7.213072787780527,
      "grad_norm": 0.41167062520980835,
      "learning_rate": 1.3934636061097365e-05,
      "loss": 0.0017,
      "step": 84530
    },
    {
      "epoch": 7.213926102909805,
      "grad_norm": 0.0363447330892086,
      "learning_rate": 1.3930369485450979e-05,
      "loss": 0.0017,
      "step": 84540
    },
    {
      "epoch": 7.214779418039082,
      "grad_norm": 0.23955997824668884,
      "learning_rate": 1.3926102909804591e-05,
      "loss": 0.0014,
      "step": 84550
    },
    {
      "epoch": 7.215632733168359,
      "grad_norm": 0.08491824567317963,
      "learning_rate": 1.3921836334158206e-05,
      "loss": 0.0016,
      "step": 84560
    },
    {
      "epoch": 7.216486048297637,
      "grad_norm": 0.04253332316875458,
      "learning_rate": 1.391756975851182e-05,
      "loss": 0.002,
      "step": 84570
    },
    {
      "epoch": 7.217339363426913,
      "grad_norm": 0.19946818053722382,
      "learning_rate": 1.3913303182865434e-05,
      "loss": 0.0019,
      "step": 84580
    },
    {
      "epoch": 7.218192678556191,
      "grad_norm": 0.043569933623075485,
      "learning_rate": 1.3909036607219048e-05,
      "loss": 0.0019,
      "step": 84590
    },
    {
      "epoch": 7.219045993685468,
      "grad_norm": 0.16602875292301178,
      "learning_rate": 1.390477003157266e-05,
      "loss": 0.0015,
      "step": 84600
    },
    {
      "epoch": 7.219899308814745,
      "grad_norm": 0.11053985357284546,
      "learning_rate": 1.3900503455926275e-05,
      "loss": 0.0019,
      "step": 84610
    },
    {
      "epoch": 7.220752623944023,
      "grad_norm": 0.11172544211149216,
      "learning_rate": 1.389623688027989e-05,
      "loss": 0.0017,
      "step": 84620
    },
    {
      "epoch": 7.221605939073299,
      "grad_norm": 0.1765860617160797,
      "learning_rate": 1.3891970304633504e-05,
      "loss": 0.002,
      "step": 84630
    },
    {
      "epoch": 7.222459254202577,
      "grad_norm": 0.15852081775665283,
      "learning_rate": 1.3887703728987114e-05,
      "loss": 0.0015,
      "step": 84640
    },
    {
      "epoch": 7.2233125693318545,
      "grad_norm": 0.29386138916015625,
      "learning_rate": 1.3883437153340729e-05,
      "loss": 0.0019,
      "step": 84650
    },
    {
      "epoch": 7.224165884461131,
      "grad_norm": 0.331909716129303,
      "learning_rate": 1.3879170577694341e-05,
      "loss": 0.0018,
      "step": 84660
    },
    {
      "epoch": 7.225019199590409,
      "grad_norm": 0.2584432363510132,
      "learning_rate": 1.3874904002047955e-05,
      "loss": 0.0023,
      "step": 84670
    },
    {
      "epoch": 7.225872514719686,
      "grad_norm": 0.38171446323394775,
      "learning_rate": 1.387063742640157e-05,
      "loss": 0.0018,
      "step": 84680
    },
    {
      "epoch": 7.226725829848963,
      "grad_norm": 0.13272425532341003,
      "learning_rate": 1.3866370850755184e-05,
      "loss": 0.002,
      "step": 84690
    },
    {
      "epoch": 7.2275791449782405,
      "grad_norm": 0.2179899513721466,
      "learning_rate": 1.3862104275108798e-05,
      "loss": 0.0017,
      "step": 84700
    },
    {
      "epoch": 7.228432460107518,
      "grad_norm": 0.07740180939435959,
      "learning_rate": 1.385783769946241e-05,
      "loss": 0.002,
      "step": 84710
    },
    {
      "epoch": 7.229285775236795,
      "grad_norm": 0.18596994876861572,
      "learning_rate": 1.3853571123816025e-05,
      "loss": 0.0018,
      "step": 84720
    },
    {
      "epoch": 7.230139090366072,
      "grad_norm": 0.29432207345962524,
      "learning_rate": 1.384930454816964e-05,
      "loss": 0.0018,
      "step": 84730
    },
    {
      "epoch": 7.23099240549535,
      "grad_norm": 0.028570355847477913,
      "learning_rate": 1.3845037972523253e-05,
      "loss": 0.0018,
      "step": 84740
    },
    {
      "epoch": 7.2318457206246265,
      "grad_norm": 0.02856816165149212,
      "learning_rate": 1.3840771396876868e-05,
      "loss": 0.0015,
      "step": 84750
    },
    {
      "epoch": 7.232699035753904,
      "grad_norm": 0.07559506595134735,
      "learning_rate": 1.383650482123048e-05,
      "loss": 0.0016,
      "step": 84760
    },
    {
      "epoch": 7.233552350883182,
      "grad_norm": 0.07890944927930832,
      "learning_rate": 1.3832238245584094e-05,
      "loss": 0.0013,
      "step": 84770
    },
    {
      "epoch": 7.234405666012458,
      "grad_norm": 0.18268442153930664,
      "learning_rate": 1.3827971669937709e-05,
      "loss": 0.0015,
      "step": 84780
    },
    {
      "epoch": 7.235258981141736,
      "grad_norm": 0.0442846454679966,
      "learning_rate": 1.3823705094291323e-05,
      "loss": 0.0017,
      "step": 84790
    },
    {
      "epoch": 7.2361122962710125,
      "grad_norm": 0.20257574319839478,
      "learning_rate": 1.3819438518644937e-05,
      "loss": 0.0014,
      "step": 84800
    },
    {
      "epoch": 7.23696561140029,
      "grad_norm": 0.2005065530538559,
      "learning_rate": 1.381517194299855e-05,
      "loss": 0.0017,
      "step": 84810
    },
    {
      "epoch": 7.237818926529568,
      "grad_norm": 0.2159976214170456,
      "learning_rate": 1.3810905367352164e-05,
      "loss": 0.0016,
      "step": 84820
    },
    {
      "epoch": 7.238672241658844,
      "grad_norm": 0.07928217947483063,
      "learning_rate": 1.3806638791705778e-05,
      "loss": 0.0015,
      "step": 84830
    },
    {
      "epoch": 7.239525556788122,
      "grad_norm": 0.06279976665973663,
      "learning_rate": 1.3802372216059392e-05,
      "loss": 0.0012,
      "step": 84840
    },
    {
      "epoch": 7.240378871917399,
      "grad_norm": 0.04407493397593498,
      "learning_rate": 1.3798105640413007e-05,
      "loss": 0.0017,
      "step": 84850
    },
    {
      "epoch": 7.241232187046676,
      "grad_norm": 0.24772313237190247,
      "learning_rate": 1.379383906476662e-05,
      "loss": 0.0015,
      "step": 84860
    },
    {
      "epoch": 7.242085502175954,
      "grad_norm": 0.235347718000412,
      "learning_rate": 1.3789572489120233e-05,
      "loss": 0.0014,
      "step": 84870
    },
    {
      "epoch": 7.242938817305231,
      "grad_norm": 0.05153723061084747,
      "learning_rate": 1.3785305913473848e-05,
      "loss": 0.0018,
      "step": 84880
    },
    {
      "epoch": 7.243792132434508,
      "grad_norm": 0.027429167181253433,
      "learning_rate": 1.3781039337827462e-05,
      "loss": 0.0016,
      "step": 84890
    },
    {
      "epoch": 7.244645447563785,
      "grad_norm": 0.13290080428123474,
      "learning_rate": 1.3776772762181076e-05,
      "loss": 0.0015,
      "step": 84900
    },
    {
      "epoch": 7.245498762693063,
      "grad_norm": 0.05769525468349457,
      "learning_rate": 1.3772506186534687e-05,
      "loss": 0.0015,
      "step": 84910
    },
    {
      "epoch": 7.24635207782234,
      "grad_norm": 0.20154359936714172,
      "learning_rate": 1.3768239610888301e-05,
      "loss": 0.0014,
      "step": 84920
    },
    {
      "epoch": 7.247205392951617,
      "grad_norm": 0.034156035631895065,
      "learning_rate": 1.3763973035241914e-05,
      "loss": 0.0012,
      "step": 84930
    },
    {
      "epoch": 7.248058708080895,
      "grad_norm": 0.06383885443210602,
      "learning_rate": 1.3759706459595528e-05,
      "loss": 0.0018,
      "step": 84940
    },
    {
      "epoch": 7.248912023210171,
      "grad_norm": 0.18914499878883362,
      "learning_rate": 1.3755439883949142e-05,
      "loss": 0.0019,
      "step": 84950
    },
    {
      "epoch": 7.249765338339449,
      "grad_norm": 0.13442321121692657,
      "learning_rate": 1.3751173308302757e-05,
      "loss": 0.0015,
      "step": 84960
    },
    {
      "epoch": 7.250618653468726,
      "grad_norm": 0.09954195469617844,
      "learning_rate": 1.374690673265637e-05,
      "loss": 0.002,
      "step": 84970
    },
    {
      "epoch": 7.251471968598003,
      "grad_norm": 0.05604887753725052,
      "learning_rate": 1.3742640157009983e-05,
      "loss": 0.0017,
      "step": 84980
    },
    {
      "epoch": 7.252325283727281,
      "grad_norm": 0.1987757533788681,
      "learning_rate": 1.3738373581363598e-05,
      "loss": 0.0016,
      "step": 84990
    },
    {
      "epoch": 7.253178598856557,
      "grad_norm": 0.07482031732797623,
      "learning_rate": 1.3734107005717212e-05,
      "loss": 0.0013,
      "step": 85000
    },
    {
      "epoch": 7.254031913985835,
      "grad_norm": 0.03450246527791023,
      "learning_rate": 1.3729840430070826e-05,
      "loss": 0.0021,
      "step": 85010
    },
    {
      "epoch": 7.2548852291151125,
      "grad_norm": 0.2028556913137436,
      "learning_rate": 1.3725573854424439e-05,
      "loss": 0.0018,
      "step": 85020
    },
    {
      "epoch": 7.255738544244389,
      "grad_norm": 0.09417799115180969,
      "learning_rate": 1.3721307278778053e-05,
      "loss": 0.0017,
      "step": 85030
    },
    {
      "epoch": 7.256591859373667,
      "grad_norm": 0.36157047748565674,
      "learning_rate": 1.3717040703131667e-05,
      "loss": 0.0016,
      "step": 85040
    },
    {
      "epoch": 7.257445174502944,
      "grad_norm": 0.04092501476407051,
      "learning_rate": 1.3712774127485281e-05,
      "loss": 0.0014,
      "step": 85050
    },
    {
      "epoch": 7.258298489632221,
      "grad_norm": 0.19949877262115479,
      "learning_rate": 1.3708507551838896e-05,
      "loss": 0.0015,
      "step": 85060
    },
    {
      "epoch": 7.2591518047614985,
      "grad_norm": 0.20252811908721924,
      "learning_rate": 1.3704240976192508e-05,
      "loss": 0.0015,
      "step": 85070
    },
    {
      "epoch": 7.260005119890776,
      "grad_norm": 0.03521270304918289,
      "learning_rate": 1.3699974400546122e-05,
      "loss": 0.0019,
      "step": 85080
    },
    {
      "epoch": 7.260858435020053,
      "grad_norm": 0.20777009427547455,
      "learning_rate": 1.3695707824899737e-05,
      "loss": 0.0015,
      "step": 85090
    },
    {
      "epoch": 7.26171175014933,
      "grad_norm": 0.0655994787812233,
      "learning_rate": 1.3691441249253351e-05,
      "loss": 0.0017,
      "step": 85100
    },
    {
      "epoch": 7.262565065278608,
      "grad_norm": 0.04799414798617363,
      "learning_rate": 1.3687174673606965e-05,
      "loss": 0.0016,
      "step": 85110
    },
    {
      "epoch": 7.2634183804078845,
      "grad_norm": 0.034964628517627716,
      "learning_rate": 1.3682908097960578e-05,
      "loss": 0.0017,
      "step": 85120
    },
    {
      "epoch": 7.264271695537162,
      "grad_norm": 0.272450715303421,
      "learning_rate": 1.3678641522314192e-05,
      "loss": 0.0017,
      "step": 85130
    },
    {
      "epoch": 7.26512501066644,
      "grad_norm": 0.22975239157676697,
      "learning_rate": 1.3674374946667806e-05,
      "loss": 0.002,
      "step": 85140
    },
    {
      "epoch": 7.265978325795716,
      "grad_norm": 0.09592542052268982,
      "learning_rate": 1.367010837102142e-05,
      "loss": 0.0016,
      "step": 85150
    },
    {
      "epoch": 7.266831640924994,
      "grad_norm": 0.3132244348526001,
      "learning_rate": 1.3665841795375035e-05,
      "loss": 0.0017,
      "step": 85160
    },
    {
      "epoch": 7.2676849560542705,
      "grad_norm": 0.1694633513689041,
      "learning_rate": 1.3661575219728645e-05,
      "loss": 0.0016,
      "step": 85170
    },
    {
      "epoch": 7.268538271183548,
      "grad_norm": 0.032243404537439346,
      "learning_rate": 1.365730864408226e-05,
      "loss": 0.0017,
      "step": 85180
    },
    {
      "epoch": 7.269391586312826,
      "grad_norm": 0.03163715824484825,
      "learning_rate": 1.3653042068435872e-05,
      "loss": 0.0013,
      "step": 85190
    },
    {
      "epoch": 7.270244901442102,
      "grad_norm": 0.031154580414295197,
      "learning_rate": 1.3648775492789486e-05,
      "loss": 0.0018,
      "step": 85200
    },
    {
      "epoch": 7.27109821657138,
      "grad_norm": 0.3271024227142334,
      "learning_rate": 1.36445089171431e-05,
      "loss": 0.0017,
      "step": 85210
    },
    {
      "epoch": 7.271951531700657,
      "grad_norm": 0.1676986664533615,
      "learning_rate": 1.3640242341496715e-05,
      "loss": 0.0023,
      "step": 85220
    },
    {
      "epoch": 7.272804846829934,
      "grad_norm": 0.07995276898145676,
      "learning_rate": 1.363597576585033e-05,
      "loss": 0.0016,
      "step": 85230
    },
    {
      "epoch": 7.2736581619592116,
      "grad_norm": 0.06510864198207855,
      "learning_rate": 1.3631709190203942e-05,
      "loss": 0.0019,
      "step": 85240
    },
    {
      "epoch": 7.274511477088489,
      "grad_norm": 0.04734779894351959,
      "learning_rate": 1.3627442614557556e-05,
      "loss": 0.0023,
      "step": 85250
    },
    {
      "epoch": 7.275364792217766,
      "grad_norm": 0.1168077141046524,
      "learning_rate": 1.362317603891117e-05,
      "loss": 0.0018,
      "step": 85260
    },
    {
      "epoch": 7.276218107347043,
      "grad_norm": 0.041851356625556946,
      "learning_rate": 1.3618909463264784e-05,
      "loss": 0.0021,
      "step": 85270
    },
    {
      "epoch": 7.277071422476321,
      "grad_norm": 0.16898047924041748,
      "learning_rate": 1.3614642887618399e-05,
      "loss": 0.0019,
      "step": 85280
    },
    {
      "epoch": 7.2779247376055975,
      "grad_norm": 0.0777813270688057,
      "learning_rate": 1.3610376311972011e-05,
      "loss": 0.002,
      "step": 85290
    },
    {
      "epoch": 7.278778052734875,
      "grad_norm": 0.05774980038404465,
      "learning_rate": 1.3606109736325626e-05,
      "loss": 0.0014,
      "step": 85300
    },
    {
      "epoch": 7.279631367864152,
      "grad_norm": 0.16429674625396729,
      "learning_rate": 1.360184316067924e-05,
      "loss": 0.0015,
      "step": 85310
    },
    {
      "epoch": 7.280484682993429,
      "grad_norm": 0.12855695188045502,
      "learning_rate": 1.3597576585032854e-05,
      "loss": 0.0015,
      "step": 85320
    },
    {
      "epoch": 7.281337998122707,
      "grad_norm": 0.18038403987884521,
      "learning_rate": 1.3593310009386467e-05,
      "loss": 0.0016,
      "step": 85330
    },
    {
      "epoch": 7.2821913132519835,
      "grad_norm": 0.16694800555706024,
      "learning_rate": 1.358904343374008e-05,
      "loss": 0.0014,
      "step": 85340
    },
    {
      "epoch": 7.283044628381261,
      "grad_norm": 0.12287846207618713,
      "learning_rate": 1.3584776858093695e-05,
      "loss": 0.0016,
      "step": 85350
    },
    {
      "epoch": 7.283897943510539,
      "grad_norm": 0.0253400020301342,
      "learning_rate": 1.358051028244731e-05,
      "loss": 0.0018,
      "step": 85360
    },
    {
      "epoch": 7.284751258639815,
      "grad_norm": 0.1277037262916565,
      "learning_rate": 1.3576243706800924e-05,
      "loss": 0.0017,
      "step": 85370
    },
    {
      "epoch": 7.285604573769093,
      "grad_norm": 0.10235218703746796,
      "learning_rate": 1.3571977131154536e-05,
      "loss": 0.0014,
      "step": 85380
    },
    {
      "epoch": 7.28645788889837,
      "grad_norm": 0.2709978222846985,
      "learning_rate": 1.356771055550815e-05,
      "loss": 0.0013,
      "step": 85390
    },
    {
      "epoch": 7.287311204027647,
      "grad_norm": 0.13951781392097473,
      "learning_rate": 1.3563443979861765e-05,
      "loss": 0.0017,
      "step": 85400
    },
    {
      "epoch": 7.288164519156925,
      "grad_norm": 0.11981484293937683,
      "learning_rate": 1.3559177404215379e-05,
      "loss": 0.0018,
      "step": 85410
    },
    {
      "epoch": 7.289017834286202,
      "grad_norm": 0.1351235955953598,
      "learning_rate": 1.3554910828568993e-05,
      "loss": 0.002,
      "step": 85420
    },
    {
      "epoch": 7.289871149415479,
      "grad_norm": 0.3622068464756012,
      "learning_rate": 1.3550644252922606e-05,
      "loss": 0.0017,
      "step": 85430
    },
    {
      "epoch": 7.290724464544756,
      "grad_norm": 0.34618714451789856,
      "learning_rate": 1.3546377677276218e-05,
      "loss": 0.0016,
      "step": 85440
    },
    {
      "epoch": 7.291577779674034,
      "grad_norm": 0.18846167623996735,
      "learning_rate": 1.354211110162983e-05,
      "loss": 0.0016,
      "step": 85450
    },
    {
      "epoch": 7.292431094803311,
      "grad_norm": 0.07636594772338867,
      "learning_rate": 1.3537844525983445e-05,
      "loss": 0.0012,
      "step": 85460
    },
    {
      "epoch": 7.293284409932588,
      "grad_norm": 0.2577996850013733,
      "learning_rate": 1.3533577950337059e-05,
      "loss": 0.002,
      "step": 85470
    },
    {
      "epoch": 7.294137725061866,
      "grad_norm": 0.18410629034042358,
      "learning_rate": 1.3529311374690673e-05,
      "loss": 0.0019,
      "step": 85480
    },
    {
      "epoch": 7.294991040191142,
      "grad_norm": 0.027167942374944687,
      "learning_rate": 1.3525044799044288e-05,
      "loss": 0.0018,
      "step": 85490
    },
    {
      "epoch": 7.29584435532042,
      "grad_norm": 0.18522226810455322,
      "learning_rate": 1.35207782233979e-05,
      "loss": 0.0015,
      "step": 85500
    },
    {
      "epoch": 7.2966976704496975,
      "grad_norm": 0.12840129435062408,
      "learning_rate": 1.3516511647751514e-05,
      "loss": 0.0023,
      "step": 85510
    },
    {
      "epoch": 7.297550985578974,
      "grad_norm": 0.02826634608209133,
      "learning_rate": 1.3512245072105129e-05,
      "loss": 0.0015,
      "step": 85520
    },
    {
      "epoch": 7.298404300708252,
      "grad_norm": 0.14972296357154846,
      "learning_rate": 1.3507978496458743e-05,
      "loss": 0.0024,
      "step": 85530
    },
    {
      "epoch": 7.299257615837528,
      "grad_norm": 0.2216135710477829,
      "learning_rate": 1.3503711920812357e-05,
      "loss": 0.0016,
      "step": 85540
    },
    {
      "epoch": 7.300110930966806,
      "grad_norm": 0.11571808904409409,
      "learning_rate": 1.349944534516597e-05,
      "loss": 0.0019,
      "step": 85550
    },
    {
      "epoch": 7.3009642460960835,
      "grad_norm": 0.02649170532822609,
      "learning_rate": 1.3495178769519584e-05,
      "loss": 0.0016,
      "step": 85560
    },
    {
      "epoch": 7.30181756122536,
      "grad_norm": 0.07529638707637787,
      "learning_rate": 1.3490912193873198e-05,
      "loss": 0.0021,
      "step": 85570
    },
    {
      "epoch": 7.302670876354638,
      "grad_norm": 0.10751901566982269,
      "learning_rate": 1.3486645618226812e-05,
      "loss": 0.0015,
      "step": 85580
    },
    {
      "epoch": 7.303524191483915,
      "grad_norm": 0.182467520236969,
      "learning_rate": 1.3482379042580427e-05,
      "loss": 0.0015,
      "step": 85590
    },
    {
      "epoch": 7.304377506613192,
      "grad_norm": 0.19818121194839478,
      "learning_rate": 1.347811246693404e-05,
      "loss": 0.0015,
      "step": 85600
    },
    {
      "epoch": 7.3052308217424695,
      "grad_norm": 0.06210560351610184,
      "learning_rate": 1.3473845891287653e-05,
      "loss": 0.0018,
      "step": 85610
    },
    {
      "epoch": 7.306084136871747,
      "grad_norm": 0.19062525033950806,
      "learning_rate": 1.3469579315641268e-05,
      "loss": 0.0017,
      "step": 85620
    },
    {
      "epoch": 7.306937452001024,
      "grad_norm": 0.043796319514513016,
      "learning_rate": 1.3465312739994882e-05,
      "loss": 0.0016,
      "step": 85630
    },
    {
      "epoch": 7.307790767130301,
      "grad_norm": 0.1272326111793518,
      "learning_rate": 1.3461046164348494e-05,
      "loss": 0.0019,
      "step": 85640
    },
    {
      "epoch": 7.308644082259579,
      "grad_norm": 0.1331404149532318,
      "learning_rate": 1.3456779588702109e-05,
      "loss": 0.0016,
      "step": 85650
    },
    {
      "epoch": 7.3094973973888555,
      "grad_norm": 0.0399666354060173,
      "learning_rate": 1.3452513013055723e-05,
      "loss": 0.002,
      "step": 85660
    },
    {
      "epoch": 7.310350712518133,
      "grad_norm": 0.039769209921360016,
      "learning_rate": 1.3448246437409337e-05,
      "loss": 0.0017,
      "step": 85670
    },
    {
      "epoch": 7.31120402764741,
      "grad_norm": 0.4044855833053589,
      "learning_rate": 1.3443979861762951e-05,
      "loss": 0.0014,
      "step": 85680
    },
    {
      "epoch": 7.312057342776687,
      "grad_norm": 0.11131135374307632,
      "learning_rate": 1.3439713286116564e-05,
      "loss": 0.0016,
      "step": 85690
    },
    {
      "epoch": 7.312910657905965,
      "grad_norm": 0.11059743911027908,
      "learning_rate": 1.3435446710470178e-05,
      "loss": 0.0016,
      "step": 85700
    },
    {
      "epoch": 7.3137639730352415,
      "grad_norm": 0.02831524796783924,
      "learning_rate": 1.3431180134823789e-05,
      "loss": 0.0019,
      "step": 85710
    },
    {
      "epoch": 7.314617288164519,
      "grad_norm": 0.08445454388856888,
      "learning_rate": 1.3426913559177403e-05,
      "loss": 0.0016,
      "step": 85720
    },
    {
      "epoch": 7.315470603293797,
      "grad_norm": 0.1460624635219574,
      "learning_rate": 1.3422646983531018e-05,
      "loss": 0.0015,
      "step": 85730
    },
    {
      "epoch": 7.316323918423073,
      "grad_norm": 0.023117708042263985,
      "learning_rate": 1.3418380407884632e-05,
      "loss": 0.0013,
      "step": 85740
    },
    {
      "epoch": 7.317177233552351,
      "grad_norm": 0.32558760046958923,
      "learning_rate": 1.3414113832238246e-05,
      "loss": 0.0017,
      "step": 85750
    },
    {
      "epoch": 7.318030548681628,
      "grad_norm": 0.4901427924633026,
      "learning_rate": 1.3409847256591859e-05,
      "loss": 0.0016,
      "step": 85760
    },
    {
      "epoch": 7.318883863810905,
      "grad_norm": 0.33598554134368896,
      "learning_rate": 1.3405580680945473e-05,
      "loss": 0.0016,
      "step": 85770
    },
    {
      "epoch": 7.319737178940183,
      "grad_norm": 0.06457380950450897,
      "learning_rate": 1.3401314105299087e-05,
      "loss": 0.0016,
      "step": 85780
    },
    {
      "epoch": 7.32059049406946,
      "grad_norm": 0.18642663955688477,
      "learning_rate": 1.3397047529652701e-05,
      "loss": 0.0016,
      "step": 85790
    },
    {
      "epoch": 7.321443809198737,
      "grad_norm": 0.21964259445667267,
      "learning_rate": 1.3392780954006316e-05,
      "loss": 0.0021,
      "step": 85800
    },
    {
      "epoch": 7.322297124328014,
      "grad_norm": 0.024516558274626732,
      "learning_rate": 1.3388514378359928e-05,
      "loss": 0.0017,
      "step": 85810
    },
    {
      "epoch": 7.323150439457292,
      "grad_norm": 0.2879028022289276,
      "learning_rate": 1.3384247802713542e-05,
      "loss": 0.0017,
      "step": 85820
    },
    {
      "epoch": 7.324003754586569,
      "grad_norm": 0.014596075750887394,
      "learning_rate": 1.3379981227067157e-05,
      "loss": 0.002,
      "step": 85830
    },
    {
      "epoch": 7.324857069715846,
      "grad_norm": 0.06100824475288391,
      "learning_rate": 1.337571465142077e-05,
      "loss": 0.0017,
      "step": 85840
    },
    {
      "epoch": 7.325710384845124,
      "grad_norm": 0.1492253541946411,
      "learning_rate": 1.3371448075774385e-05,
      "loss": 0.0021,
      "step": 85850
    },
    {
      "epoch": 7.3265636999744,
      "grad_norm": 0.3274199068546295,
      "learning_rate": 1.3367181500127998e-05,
      "loss": 0.0015,
      "step": 85860
    },
    {
      "epoch": 7.327417015103678,
      "grad_norm": 0.1675492376089096,
      "learning_rate": 1.3362914924481612e-05,
      "loss": 0.0014,
      "step": 85870
    },
    {
      "epoch": 7.3282703302329555,
      "grad_norm": 0.15106526017189026,
      "learning_rate": 1.3358648348835226e-05,
      "loss": 0.0021,
      "step": 85880
    },
    {
      "epoch": 7.329123645362232,
      "grad_norm": 0.2580772936344147,
      "learning_rate": 1.335438177318884e-05,
      "loss": 0.002,
      "step": 85890
    },
    {
      "epoch": 7.32997696049151,
      "grad_norm": 0.5259450674057007,
      "learning_rate": 1.3350115197542455e-05,
      "loss": 0.0017,
      "step": 85900
    },
    {
      "epoch": 7.330830275620786,
      "grad_norm": 0.04527176171541214,
      "learning_rate": 1.3345848621896067e-05,
      "loss": 0.0017,
      "step": 85910
    },
    {
      "epoch": 7.331683590750064,
      "grad_norm": 0.11397193372249603,
      "learning_rate": 1.3341582046249681e-05,
      "loss": 0.0017,
      "step": 85920
    },
    {
      "epoch": 7.3325369058793415,
      "grad_norm": 0.07686203718185425,
      "learning_rate": 1.3337315470603296e-05,
      "loss": 0.0017,
      "step": 85930
    },
    {
      "epoch": 7.333390221008618,
      "grad_norm": 0.20138858258724213,
      "learning_rate": 1.333304889495691e-05,
      "loss": 0.0014,
      "step": 85940
    },
    {
      "epoch": 7.334243536137896,
      "grad_norm": 0.272259384393692,
      "learning_rate": 1.3328782319310524e-05,
      "loss": 0.0013,
      "step": 85950
    },
    {
      "epoch": 7.335096851267173,
      "grad_norm": 0.05910848081111908,
      "learning_rate": 1.3324515743664137e-05,
      "loss": 0.0015,
      "step": 85960
    },
    {
      "epoch": 7.33595016639645,
      "grad_norm": 0.03416447341442108,
      "learning_rate": 1.3320249168017747e-05,
      "loss": 0.002,
      "step": 85970
    },
    {
      "epoch": 7.3368034815257275,
      "grad_norm": 0.3285137712955475,
      "learning_rate": 1.3315982592371362e-05,
      "loss": 0.0018,
      "step": 85980
    },
    {
      "epoch": 7.337656796655005,
      "grad_norm": 0.11553648114204407,
      "learning_rate": 1.3311716016724976e-05,
      "loss": 0.0015,
      "step": 85990
    },
    {
      "epoch": 7.338510111784282,
      "grad_norm": 0.11209728568792343,
      "learning_rate": 1.330744944107859e-05,
      "loss": 0.0018,
      "step": 86000
    },
    {
      "epoch": 7.339363426913559,
      "grad_norm": 0.05432332679629326,
      "learning_rate": 1.3303182865432204e-05,
      "loss": 0.0021,
      "step": 86010
    },
    {
      "epoch": 7.340216742042837,
      "grad_norm": 0.0926927775144577,
      "learning_rate": 1.3298916289785817e-05,
      "loss": 0.002,
      "step": 86020
    },
    {
      "epoch": 7.3410700571721135,
      "grad_norm": 0.14788684248924255,
      "learning_rate": 1.3294649714139431e-05,
      "loss": 0.0022,
      "step": 86030
    },
    {
      "epoch": 7.341923372301391,
      "grad_norm": 0.06202077865600586,
      "learning_rate": 1.3290383138493045e-05,
      "loss": 0.0019,
      "step": 86040
    },
    {
      "epoch": 7.342776687430668,
      "grad_norm": 0.22010363638401031,
      "learning_rate": 1.328611656284666e-05,
      "loss": 0.0015,
      "step": 86050
    },
    {
      "epoch": 7.343630002559945,
      "grad_norm": 0.09232030063867569,
      "learning_rate": 1.3281849987200274e-05,
      "loss": 0.0016,
      "step": 86060
    },
    {
      "epoch": 7.344483317689223,
      "grad_norm": 0.11267460882663727,
      "learning_rate": 1.3277583411553886e-05,
      "loss": 0.0018,
      "step": 86070
    },
    {
      "epoch": 7.3453366328184995,
      "grad_norm": 0.031126735731959343,
      "learning_rate": 1.32733168359075e-05,
      "loss": 0.0015,
      "step": 86080
    },
    {
      "epoch": 7.346189947947777,
      "grad_norm": 0.032457832247018814,
      "learning_rate": 1.3269050260261115e-05,
      "loss": 0.002,
      "step": 86090
    },
    {
      "epoch": 7.347043263077055,
      "grad_norm": 0.0832858756184578,
      "learning_rate": 1.326478368461473e-05,
      "loss": 0.0022,
      "step": 86100
    },
    {
      "epoch": 7.347896578206331,
      "grad_norm": 0.16750648617744446,
      "learning_rate": 1.3260517108968343e-05,
      "loss": 0.0018,
      "step": 86110
    },
    {
      "epoch": 7.348749893335609,
      "grad_norm": 0.3875417411327362,
      "learning_rate": 1.3256250533321956e-05,
      "loss": 0.0019,
      "step": 86120
    },
    {
      "epoch": 7.349603208464886,
      "grad_norm": 0.21938306093215942,
      "learning_rate": 1.325198395767557e-05,
      "loss": 0.0015,
      "step": 86130
    },
    {
      "epoch": 7.350456523594163,
      "grad_norm": 0.09743362665176392,
      "learning_rate": 1.3247717382029184e-05,
      "loss": 0.002,
      "step": 86140
    },
    {
      "epoch": 7.351309838723441,
      "grad_norm": 0.04037516936659813,
      "learning_rate": 1.3243450806382799e-05,
      "loss": 0.0021,
      "step": 86150
    },
    {
      "epoch": 7.352163153852718,
      "grad_norm": 0.037922151386737823,
      "learning_rate": 1.3239184230736413e-05,
      "loss": 0.0017,
      "step": 86160
    },
    {
      "epoch": 7.353016468981995,
      "grad_norm": 0.05512843281030655,
      "learning_rate": 1.3234917655090026e-05,
      "loss": 0.0019,
      "step": 86170
    },
    {
      "epoch": 7.353869784111272,
      "grad_norm": 0.09192686527967453,
      "learning_rate": 1.323065107944364e-05,
      "loss": 0.0015,
      "step": 86180
    },
    {
      "epoch": 7.35472309924055,
      "grad_norm": 0.1332179307937622,
      "learning_rate": 1.3226384503797254e-05,
      "loss": 0.0016,
      "step": 86190
    },
    {
      "epoch": 7.355576414369827,
      "grad_norm": 0.23896661400794983,
      "learning_rate": 1.3222117928150868e-05,
      "loss": 0.0018,
      "step": 86200
    },
    {
      "epoch": 7.356429729499104,
      "grad_norm": 0.056793276220560074,
      "learning_rate": 1.3217851352504482e-05,
      "loss": 0.0016,
      "step": 86210
    },
    {
      "epoch": 7.357283044628382,
      "grad_norm": 0.04627865180373192,
      "learning_rate": 1.3213584776858095e-05,
      "loss": 0.0016,
      "step": 86220
    },
    {
      "epoch": 7.358136359757658,
      "grad_norm": 0.056889649480581284,
      "learning_rate": 1.320931820121171e-05,
      "loss": 0.0017,
      "step": 86230
    },
    {
      "epoch": 7.358989674886936,
      "grad_norm": 0.05720445141196251,
      "learning_rate": 1.320505162556532e-05,
      "loss": 0.0016,
      "step": 86240
    },
    {
      "epoch": 7.3598429900162134,
      "grad_norm": 0.13209888339042664,
      "learning_rate": 1.3200785049918934e-05,
      "loss": 0.002,
      "step": 86250
    },
    {
      "epoch": 7.36069630514549,
      "grad_norm": 0.34479475021362305,
      "learning_rate": 1.3196518474272549e-05,
      "loss": 0.0014,
      "step": 86260
    },
    {
      "epoch": 7.361549620274768,
      "grad_norm": 0.23881083726882935,
      "learning_rate": 1.3192251898626163e-05,
      "loss": 0.0015,
      "step": 86270
    },
    {
      "epoch": 7.362402935404044,
      "grad_norm": 0.0331106036901474,
      "learning_rate": 1.3187985322979775e-05,
      "loss": 0.0017,
      "step": 86280
    },
    {
      "epoch": 7.363256250533322,
      "grad_norm": 0.04297812283039093,
      "learning_rate": 1.318371874733339e-05,
      "loss": 0.0022,
      "step": 86290
    },
    {
      "epoch": 7.364109565662599,
      "grad_norm": 0.06154026463627815,
      "learning_rate": 1.3179452171687004e-05,
      "loss": 0.0017,
      "step": 86300
    },
    {
      "epoch": 7.364962880791876,
      "grad_norm": 0.15094417333602905,
      "learning_rate": 1.3175185596040618e-05,
      "loss": 0.0019,
      "step": 86310
    },
    {
      "epoch": 7.365816195921154,
      "grad_norm": 0.2765693664550781,
      "learning_rate": 1.3170919020394232e-05,
      "loss": 0.0017,
      "step": 86320
    },
    {
      "epoch": 7.366669511050431,
      "grad_norm": 0.13471408188343048,
      "learning_rate": 1.3166652444747845e-05,
      "loss": 0.0017,
      "step": 86330
    },
    {
      "epoch": 7.367522826179708,
      "grad_norm": 0.19966724514961243,
      "learning_rate": 1.3162385869101459e-05,
      "loss": 0.0018,
      "step": 86340
    },
    {
      "epoch": 7.368376141308985,
      "grad_norm": 0.17771264910697937,
      "learning_rate": 1.3158119293455073e-05,
      "loss": 0.0014,
      "step": 86350
    },
    {
      "epoch": 7.369229456438263,
      "grad_norm": 0.14885912835597992,
      "learning_rate": 1.3153852717808688e-05,
      "loss": 0.0016,
      "step": 86360
    },
    {
      "epoch": 7.37008277156754,
      "grad_norm": 0.1820678561925888,
      "learning_rate": 1.3149586142162302e-05,
      "loss": 0.0019,
      "step": 86370
    },
    {
      "epoch": 7.370936086696817,
      "grad_norm": 0.22475434839725494,
      "learning_rate": 1.3145319566515914e-05,
      "loss": 0.0021,
      "step": 86380
    },
    {
      "epoch": 7.371789401826095,
      "grad_norm": 0.09836183488368988,
      "learning_rate": 1.3141052990869529e-05,
      "loss": 0.0017,
      "step": 86390
    },
    {
      "epoch": 7.372642716955371,
      "grad_norm": 0.16801899671554565,
      "learning_rate": 1.3136786415223143e-05,
      "loss": 0.0021,
      "step": 86400
    },
    {
      "epoch": 7.373496032084649,
      "grad_norm": 0.17970913648605347,
      "learning_rate": 1.3132519839576757e-05,
      "loss": 0.0017,
      "step": 86410
    },
    {
      "epoch": 7.374349347213926,
      "grad_norm": 0.30094054341316223,
      "learning_rate": 1.3128253263930371e-05,
      "loss": 0.0017,
      "step": 86420
    },
    {
      "epoch": 7.375202662343203,
      "grad_norm": 0.18904554843902588,
      "learning_rate": 1.3123986688283984e-05,
      "loss": 0.0018,
      "step": 86430
    },
    {
      "epoch": 7.376055977472481,
      "grad_norm": 0.1299775242805481,
      "learning_rate": 1.3119720112637598e-05,
      "loss": 0.0015,
      "step": 86440
    },
    {
      "epoch": 7.376909292601757,
      "grad_norm": 0.0920402854681015,
      "learning_rate": 1.3115453536991212e-05,
      "loss": 0.0015,
      "step": 86450
    },
    {
      "epoch": 7.377762607731035,
      "grad_norm": 0.16436490416526794,
      "learning_rate": 1.3111186961344827e-05,
      "loss": 0.0017,
      "step": 86460
    },
    {
      "epoch": 7.3786159228603125,
      "grad_norm": 0.23844784498214722,
      "learning_rate": 1.3106920385698441e-05,
      "loss": 0.0014,
      "step": 86470
    },
    {
      "epoch": 7.379469237989589,
      "grad_norm": 0.042978495359420776,
      "learning_rate": 1.3102653810052053e-05,
      "loss": 0.0016,
      "step": 86480
    },
    {
      "epoch": 7.380322553118867,
      "grad_norm": 0.03421620652079582,
      "learning_rate": 1.3098387234405668e-05,
      "loss": 0.002,
      "step": 86490
    },
    {
      "epoch": 7.381175868248144,
      "grad_norm": 0.07584366947412491,
      "learning_rate": 1.3094120658759279e-05,
      "loss": 0.002,
      "step": 86500
    },
    {
      "epoch": 7.382029183377421,
      "grad_norm": 0.13141953945159912,
      "learning_rate": 1.3089854083112893e-05,
      "loss": 0.0014,
      "step": 86510
    },
    {
      "epoch": 7.3828824985066985,
      "grad_norm": 0.1822555810213089,
      "learning_rate": 1.3085587507466507e-05,
      "loss": 0.0019,
      "step": 86520
    },
    {
      "epoch": 7.383735813635976,
      "grad_norm": 0.04424058273434639,
      "learning_rate": 1.3081320931820121e-05,
      "loss": 0.0017,
      "step": 86530
    },
    {
      "epoch": 7.384589128765253,
      "grad_norm": 0.20664963126182556,
      "learning_rate": 1.3077054356173734e-05,
      "loss": 0.0018,
      "step": 86540
    },
    {
      "epoch": 7.38544244389453,
      "grad_norm": 0.06369884312152863,
      "learning_rate": 1.3072787780527348e-05,
      "loss": 0.0023,
      "step": 86550
    },
    {
      "epoch": 7.386295759023808,
      "grad_norm": 0.1800588220357895,
      "learning_rate": 1.3068521204880962e-05,
      "loss": 0.002,
      "step": 86560
    },
    {
      "epoch": 7.3871490741530845,
      "grad_norm": 0.07854924350976944,
      "learning_rate": 1.3064254629234577e-05,
      "loss": 0.002,
      "step": 86570
    },
    {
      "epoch": 7.388002389282362,
      "grad_norm": 0.28992366790771484,
      "learning_rate": 1.305998805358819e-05,
      "loss": 0.0015,
      "step": 86580
    },
    {
      "epoch": 7.38885570441164,
      "grad_norm": 0.060829147696495056,
      "learning_rate": 1.3055721477941803e-05,
      "loss": 0.0018,
      "step": 86590
    },
    {
      "epoch": 7.389709019540916,
      "grad_norm": 0.23886844515800476,
      "learning_rate": 1.3051454902295418e-05,
      "loss": 0.0016,
      "step": 86600
    },
    {
      "epoch": 7.390562334670194,
      "grad_norm": 0.059027522802352905,
      "learning_rate": 1.3047188326649032e-05,
      "loss": 0.0017,
      "step": 86610
    },
    {
      "epoch": 7.391415649799471,
      "grad_norm": 0.20529018342494965,
      "learning_rate": 1.3042921751002646e-05,
      "loss": 0.0015,
      "step": 86620
    },
    {
      "epoch": 7.392268964928748,
      "grad_norm": 0.15512238442897797,
      "learning_rate": 1.303865517535626e-05,
      "loss": 0.0017,
      "step": 86630
    },
    {
      "epoch": 7.393122280058026,
      "grad_norm": 0.29933661222457886,
      "learning_rate": 1.3034388599709873e-05,
      "loss": 0.0017,
      "step": 86640
    },
    {
      "epoch": 7.393975595187302,
      "grad_norm": 0.0944414809346199,
      "learning_rate": 1.3030122024063487e-05,
      "loss": 0.0018,
      "step": 86650
    },
    {
      "epoch": 7.39482891031658,
      "grad_norm": 0.272436261177063,
      "learning_rate": 1.3025855448417101e-05,
      "loss": 0.0018,
      "step": 86660
    },
    {
      "epoch": 7.395682225445857,
      "grad_norm": 0.16883587837219238,
      "learning_rate": 1.3021588872770716e-05,
      "loss": 0.0021,
      "step": 86670
    },
    {
      "epoch": 7.396535540575134,
      "grad_norm": 0.18420714139938354,
      "learning_rate": 1.301732229712433e-05,
      "loss": 0.0018,
      "step": 86680
    },
    {
      "epoch": 7.397388855704412,
      "grad_norm": 0.09672685712575912,
      "learning_rate": 1.3013055721477942e-05,
      "loss": 0.0016,
      "step": 86690
    },
    {
      "epoch": 7.398242170833689,
      "grad_norm": 0.03045864962041378,
      "learning_rate": 1.3008789145831557e-05,
      "loss": 0.0018,
      "step": 86700
    },
    {
      "epoch": 7.399095485962966,
      "grad_norm": 0.18815045058727264,
      "learning_rate": 1.300452257018517e-05,
      "loss": 0.0017,
      "step": 86710
    },
    {
      "epoch": 7.399948801092243,
      "grad_norm": 0.13099972903728485,
      "learning_rate": 1.3000255994538785e-05,
      "loss": 0.0014,
      "step": 86720
    },
    {
      "epoch": 7.400802116221521,
      "grad_norm": 0.09204845875501633,
      "learning_rate": 1.29959894188924e-05,
      "loss": 0.002,
      "step": 86730
    },
    {
      "epoch": 7.401655431350798,
      "grad_norm": 0.23135429620742798,
      "learning_rate": 1.2991722843246012e-05,
      "loss": 0.0022,
      "step": 86740
    },
    {
      "epoch": 7.402508746480075,
      "grad_norm": 0.16877472400665283,
      "learning_rate": 1.2987456267599626e-05,
      "loss": 0.0019,
      "step": 86750
    },
    {
      "epoch": 7.403362061609353,
      "grad_norm": 0.0726439505815506,
      "learning_rate": 1.298318969195324e-05,
      "loss": 0.0015,
      "step": 86760
    },
    {
      "epoch": 7.404215376738629,
      "grad_norm": 0.04478049650788307,
      "learning_rate": 1.2978923116306851e-05,
      "loss": 0.0015,
      "step": 86770
    },
    {
      "epoch": 7.405068691867907,
      "grad_norm": 0.04841559752821922,
      "learning_rate": 1.2974656540660465e-05,
      "loss": 0.0014,
      "step": 86780
    },
    {
      "epoch": 7.405922006997184,
      "grad_norm": 0.027246061712503433,
      "learning_rate": 1.297038996501408e-05,
      "loss": 0.0017,
      "step": 86790
    },
    {
      "epoch": 7.406775322126461,
      "grad_norm": 0.12075667083263397,
      "learning_rate": 1.2966123389367694e-05,
      "loss": 0.0015,
      "step": 86800
    },
    {
      "epoch": 7.407628637255739,
      "grad_norm": 0.1275428682565689,
      "learning_rate": 1.2961856813721306e-05,
      "loss": 0.0023,
      "step": 86810
    },
    {
      "epoch": 7.408481952385015,
      "grad_norm": 0.16405507922172546,
      "learning_rate": 1.295759023807492e-05,
      "loss": 0.0013,
      "step": 86820
    },
    {
      "epoch": 7.409335267514293,
      "grad_norm": 0.15176191926002502,
      "learning_rate": 1.2953323662428535e-05,
      "loss": 0.0018,
      "step": 86830
    },
    {
      "epoch": 7.4101885826435705,
      "grad_norm": 0.16740944981575012,
      "learning_rate": 1.294905708678215e-05,
      "loss": 0.0019,
      "step": 86840
    },
    {
      "epoch": 7.411041897772847,
      "grad_norm": 0.26941898465156555,
      "learning_rate": 1.2944790511135763e-05,
      "loss": 0.0017,
      "step": 86850
    },
    {
      "epoch": 7.411895212902125,
      "grad_norm": 0.04851088300347328,
      "learning_rate": 1.2940523935489376e-05,
      "loss": 0.0014,
      "step": 86860
    },
    {
      "epoch": 7.412748528031402,
      "grad_norm": 0.11085974425077438,
      "learning_rate": 1.293625735984299e-05,
      "loss": 0.0018,
      "step": 86870
    },
    {
      "epoch": 7.413601843160679,
      "grad_norm": 0.11339890956878662,
      "learning_rate": 1.2931990784196604e-05,
      "loss": 0.0017,
      "step": 86880
    },
    {
      "epoch": 7.4144551582899565,
      "grad_norm": 0.043932266533374786,
      "learning_rate": 1.2927724208550219e-05,
      "loss": 0.0023,
      "step": 86890
    },
    {
      "epoch": 7.415308473419234,
      "grad_norm": 0.07896333187818527,
      "learning_rate": 1.2923457632903831e-05,
      "loss": 0.0015,
      "step": 86900
    },
    {
      "epoch": 7.416161788548511,
      "grad_norm": 0.08015792816877365,
      "learning_rate": 1.2919191057257445e-05,
      "loss": 0.0017,
      "step": 86910
    },
    {
      "epoch": 7.417015103677788,
      "grad_norm": 0.041096415370702744,
      "learning_rate": 1.291492448161106e-05,
      "loss": 0.0016,
      "step": 86920
    },
    {
      "epoch": 7.417868418807066,
      "grad_norm": 0.21872356534004211,
      "learning_rate": 1.2910657905964674e-05,
      "loss": 0.0017,
      "step": 86930
    },
    {
      "epoch": 7.4187217339363425,
      "grad_norm": 0.038746386766433716,
      "learning_rate": 1.2906391330318288e-05,
      "loss": 0.0019,
      "step": 86940
    },
    {
      "epoch": 7.41957504906562,
      "grad_norm": 0.18396243453025818,
      "learning_rate": 1.29021247546719e-05,
      "loss": 0.0016,
      "step": 86950
    },
    {
      "epoch": 7.420428364194898,
      "grad_norm": 0.09651915729045868,
      "learning_rate": 1.2897858179025515e-05,
      "loss": 0.0019,
      "step": 86960
    },
    {
      "epoch": 7.421281679324174,
      "grad_norm": 0.2501404583454132,
      "learning_rate": 1.289359160337913e-05,
      "loss": 0.0017,
      "step": 86970
    },
    {
      "epoch": 7.422134994453452,
      "grad_norm": 0.2934269905090332,
      "learning_rate": 1.2889325027732743e-05,
      "loss": 0.0017,
      "step": 86980
    },
    {
      "epoch": 7.422988309582729,
      "grad_norm": 0.2694135010242462,
      "learning_rate": 1.2885058452086358e-05,
      "loss": 0.002,
      "step": 86990
    },
    {
      "epoch": 7.423841624712006,
      "grad_norm": 0.08858808875083923,
      "learning_rate": 1.288079187643997e-05,
      "loss": 0.0016,
      "step": 87000
    },
    {
      "epoch": 7.424694939841284,
      "grad_norm": 0.14888444542884827,
      "learning_rate": 1.2876525300793584e-05,
      "loss": 0.0014,
      "step": 87010
    },
    {
      "epoch": 7.42554825497056,
      "grad_norm": 0.09401313960552216,
      "learning_rate": 1.2872258725147199e-05,
      "loss": 0.0018,
      "step": 87020
    },
    {
      "epoch": 7.426401570099838,
      "grad_norm": 0.22956761717796326,
      "learning_rate": 1.286799214950081e-05,
      "loss": 0.0015,
      "step": 87030
    },
    {
      "epoch": 7.427254885229115,
      "grad_norm": 0.2008877545595169,
      "learning_rate": 1.2863725573854424e-05,
      "loss": 0.0016,
      "step": 87040
    },
    {
      "epoch": 7.428108200358392,
      "grad_norm": 0.11008204519748688,
      "learning_rate": 1.2859458998208038e-05,
      "loss": 0.0017,
      "step": 87050
    },
    {
      "epoch": 7.42896151548767,
      "grad_norm": 0.07566650211811066,
      "learning_rate": 1.2855192422561652e-05,
      "loss": 0.0017,
      "step": 87060
    },
    {
      "epoch": 7.429814830616947,
      "grad_norm": 0.12076471745967865,
      "learning_rate": 1.2850925846915265e-05,
      "loss": 0.0016,
      "step": 87070
    },
    {
      "epoch": 7.430668145746224,
      "grad_norm": 0.10559581965208054,
      "learning_rate": 1.2846659271268879e-05,
      "loss": 0.0021,
      "step": 87080
    },
    {
      "epoch": 7.431521460875501,
      "grad_norm": 0.08226479589939117,
      "learning_rate": 1.2842392695622493e-05,
      "loss": 0.0018,
      "step": 87090
    },
    {
      "epoch": 7.432374776004779,
      "grad_norm": 0.2915855646133423,
      "learning_rate": 1.2838126119976108e-05,
      "loss": 0.002,
      "step": 87100
    },
    {
      "epoch": 7.433228091134056,
      "grad_norm": 0.049064815044403076,
      "learning_rate": 1.2833859544329722e-05,
      "loss": 0.0017,
      "step": 87110
    },
    {
      "epoch": 7.434081406263333,
      "grad_norm": 0.044256217777729034,
      "learning_rate": 1.2829592968683334e-05,
      "loss": 0.002,
      "step": 87120
    },
    {
      "epoch": 7.434934721392611,
      "grad_norm": 0.03446123003959656,
      "learning_rate": 1.2825326393036949e-05,
      "loss": 0.0019,
      "step": 87130
    },
    {
      "epoch": 7.435788036521887,
      "grad_norm": 0.16649286448955536,
      "learning_rate": 1.2821059817390563e-05,
      "loss": 0.002,
      "step": 87140
    },
    {
      "epoch": 7.436641351651165,
      "grad_norm": 0.07566063851118088,
      "learning_rate": 1.2816793241744177e-05,
      "loss": 0.0019,
      "step": 87150
    },
    {
      "epoch": 7.437494666780442,
      "grad_norm": 0.030046088621020317,
      "learning_rate": 1.2812526666097791e-05,
      "loss": 0.0015,
      "step": 87160
    },
    {
      "epoch": 7.438347981909719,
      "grad_norm": 0.286957710981369,
      "learning_rate": 1.2808260090451404e-05,
      "loss": 0.0017,
      "step": 87170
    },
    {
      "epoch": 7.439201297038997,
      "grad_norm": 0.3078501522541046,
      "learning_rate": 1.2803993514805018e-05,
      "loss": 0.0016,
      "step": 87180
    },
    {
      "epoch": 7.440054612168273,
      "grad_norm": 0.12638871371746063,
      "learning_rate": 1.2799726939158632e-05,
      "loss": 0.0017,
      "step": 87190
    },
    {
      "epoch": 7.440907927297551,
      "grad_norm": 0.1454491764307022,
      "learning_rate": 1.2795460363512247e-05,
      "loss": 0.0012,
      "step": 87200
    },
    {
      "epoch": 7.4417612424268285,
      "grad_norm": 0.040129512548446655,
      "learning_rate": 1.2791193787865859e-05,
      "loss": 0.0016,
      "step": 87210
    },
    {
      "epoch": 7.442614557556105,
      "grad_norm": 0.08695410937070847,
      "learning_rate": 1.2786927212219473e-05,
      "loss": 0.0014,
      "step": 87220
    },
    {
      "epoch": 7.443467872685383,
      "grad_norm": 0.04635903611779213,
      "learning_rate": 1.2782660636573088e-05,
      "loss": 0.0017,
      "step": 87230
    },
    {
      "epoch": 7.44432118781466,
      "grad_norm": 0.23754136264324188,
      "learning_rate": 1.2778394060926702e-05,
      "loss": 0.0017,
      "step": 87240
    },
    {
      "epoch": 7.445174502943937,
      "grad_norm": 0.29024821519851685,
      "learning_rate": 1.2774127485280316e-05,
      "loss": 0.0022,
      "step": 87250
    },
    {
      "epoch": 7.4460278180732145,
      "grad_norm": 0.1270950734615326,
      "learning_rate": 1.2769860909633929e-05,
      "loss": 0.002,
      "step": 87260
    },
    {
      "epoch": 7.446881133202492,
      "grad_norm": 0.056400101631879807,
      "learning_rate": 1.2765594333987543e-05,
      "loss": 0.0014,
      "step": 87270
    },
    {
      "epoch": 7.447734448331769,
      "grad_norm": 0.028187915682792664,
      "learning_rate": 1.2761327758341157e-05,
      "loss": 0.0014,
      "step": 87280
    },
    {
      "epoch": 7.448587763461046,
      "grad_norm": 0.11320153623819351,
      "learning_rate": 1.2757061182694771e-05,
      "loss": 0.0013,
      "step": 87290
    },
    {
      "epoch": 7.449441078590324,
      "grad_norm": 0.13383643329143524,
      "learning_rate": 1.2752794607048382e-05,
      "loss": 0.0017,
      "step": 87300
    },
    {
      "epoch": 7.4502943937196004,
      "grad_norm": 0.3473847806453705,
      "learning_rate": 1.2748528031401996e-05,
      "loss": 0.0021,
      "step": 87310
    },
    {
      "epoch": 7.451147708848878,
      "grad_norm": 0.17039979994297028,
      "learning_rate": 1.274426145575561e-05,
      "loss": 0.0016,
      "step": 87320
    },
    {
      "epoch": 7.452001023978156,
      "grad_norm": 0.045760150998830795,
      "learning_rate": 1.2739994880109223e-05,
      "loss": 0.0019,
      "step": 87330
    },
    {
      "epoch": 7.452854339107432,
      "grad_norm": 0.2570241093635559,
      "learning_rate": 1.2735728304462838e-05,
      "loss": 0.0019,
      "step": 87340
    },
    {
      "epoch": 7.45370765423671,
      "grad_norm": 0.3634165823459625,
      "learning_rate": 1.2731461728816452e-05,
      "loss": 0.0017,
      "step": 87350
    },
    {
      "epoch": 7.4545609693659864,
      "grad_norm": 0.2733541429042816,
      "learning_rate": 1.2727195153170066e-05,
      "loss": 0.0016,
      "step": 87360
    },
    {
      "epoch": 7.455414284495264,
      "grad_norm": 0.03324524313211441,
      "learning_rate": 1.272292857752368e-05,
      "loss": 0.0017,
      "step": 87370
    },
    {
      "epoch": 7.4562675996245416,
      "grad_norm": 0.02584831789135933,
      "learning_rate": 1.2718662001877293e-05,
      "loss": 0.0023,
      "step": 87380
    },
    {
      "epoch": 7.457120914753818,
      "grad_norm": 0.09543488174676895,
      "learning_rate": 1.2714395426230907e-05,
      "loss": 0.0018,
      "step": 87390
    },
    {
      "epoch": 7.457974229883096,
      "grad_norm": 0.291939914226532,
      "learning_rate": 1.2710128850584521e-05,
      "loss": 0.0016,
      "step": 87400
    },
    {
      "epoch": 7.458827545012373,
      "grad_norm": 0.04535670951008797,
      "learning_rate": 1.2705862274938135e-05,
      "loss": 0.0023,
      "step": 87410
    },
    {
      "epoch": 7.45968086014165,
      "grad_norm": 0.10949959605932236,
      "learning_rate": 1.270159569929175e-05,
      "loss": 0.0014,
      "step": 87420
    },
    {
      "epoch": 7.4605341752709275,
      "grad_norm": 0.37578994035720825,
      "learning_rate": 1.2697329123645362e-05,
      "loss": 0.0022,
      "step": 87430
    },
    {
      "epoch": 7.461387490400205,
      "grad_norm": 0.2533643841743469,
      "learning_rate": 1.2693062547998977e-05,
      "loss": 0.0014,
      "step": 87440
    },
    {
      "epoch": 7.462240805529482,
      "grad_norm": 0.1650434136390686,
      "learning_rate": 1.268879597235259e-05,
      "loss": 0.002,
      "step": 87450
    },
    {
      "epoch": 7.463094120658759,
      "grad_norm": 0.04653956741094589,
      "learning_rate": 1.2684529396706205e-05,
      "loss": 0.0015,
      "step": 87460
    },
    {
      "epoch": 7.463947435788037,
      "grad_norm": 0.07892559468746185,
      "learning_rate": 1.268026282105982e-05,
      "loss": 0.0017,
      "step": 87470
    },
    {
      "epoch": 7.4648007509173135,
      "grad_norm": 0.11362981796264648,
      "learning_rate": 1.2675996245413432e-05,
      "loss": 0.0015,
      "step": 87480
    },
    {
      "epoch": 7.465654066046591,
      "grad_norm": 0.0450892299413681,
      "learning_rate": 1.2671729669767046e-05,
      "loss": 0.0017,
      "step": 87490
    },
    {
      "epoch": 7.466507381175869,
      "grad_norm": 0.21837157011032104,
      "learning_rate": 1.266746309412066e-05,
      "loss": 0.0015,
      "step": 87500
    },
    {
      "epoch": 7.467360696305145,
      "grad_norm": 0.12693214416503906,
      "learning_rate": 1.2663196518474275e-05,
      "loss": 0.002,
      "step": 87510
    },
    {
      "epoch": 7.468214011434423,
      "grad_norm": 0.026908738538622856,
      "learning_rate": 1.2658929942827889e-05,
      "loss": 0.0013,
      "step": 87520
    },
    {
      "epoch": 7.4690673265636995,
      "grad_norm": 0.04229406267404556,
      "learning_rate": 1.2654663367181501e-05,
      "loss": 0.0014,
      "step": 87530
    },
    {
      "epoch": 7.469920641692977,
      "grad_norm": 0.1849866360425949,
      "learning_rate": 1.2650396791535116e-05,
      "loss": 0.0019,
      "step": 87540
    },
    {
      "epoch": 7.470773956822255,
      "grad_norm": 0.07646609097719193,
      "learning_rate": 1.264613021588873e-05,
      "loss": 0.0016,
      "step": 87550
    },
    {
      "epoch": 7.471627271951531,
      "grad_norm": 0.09418026357889175,
      "learning_rate": 1.2641863640242344e-05,
      "loss": 0.0012,
      "step": 87560
    },
    {
      "epoch": 7.472480587080809,
      "grad_norm": 0.0796380341053009,
      "learning_rate": 1.2637597064595955e-05,
      "loss": 0.0014,
      "step": 87570
    },
    {
      "epoch": 7.473333902210086,
      "grad_norm": 0.3045710027217865,
      "learning_rate": 1.2633330488949569e-05,
      "loss": 0.0017,
      "step": 87580
    },
    {
      "epoch": 7.474187217339363,
      "grad_norm": 0.051634449511766434,
      "learning_rate": 1.2629063913303182e-05,
      "loss": 0.0017,
      "step": 87590
    },
    {
      "epoch": 7.475040532468641,
      "grad_norm": 0.11639823019504547,
      "learning_rate": 1.2624797337656796e-05,
      "loss": 0.0019,
      "step": 87600
    },
    {
      "epoch": 7.475893847597918,
      "grad_norm": 0.050777778029441833,
      "learning_rate": 1.262053076201041e-05,
      "loss": 0.0015,
      "step": 87610
    },
    {
      "epoch": 7.476747162727195,
      "grad_norm": 0.07789786159992218,
      "learning_rate": 1.2616264186364024e-05,
      "loss": 0.002,
      "step": 87620
    },
    {
      "epoch": 7.477600477856472,
      "grad_norm": 0.09968573600053787,
      "learning_rate": 1.2611997610717639e-05,
      "loss": 0.0021,
      "step": 87630
    },
    {
      "epoch": 7.47845379298575,
      "grad_norm": 0.07599981874227524,
      "learning_rate": 1.2607731035071251e-05,
      "loss": 0.002,
      "step": 87640
    },
    {
      "epoch": 7.479307108115027,
      "grad_norm": 0.030268792062997818,
      "learning_rate": 1.2603464459424865e-05,
      "loss": 0.0016,
      "step": 87650
    },
    {
      "epoch": 7.480160423244304,
      "grad_norm": 0.22222810983657837,
      "learning_rate": 1.259919788377848e-05,
      "loss": 0.0016,
      "step": 87660
    },
    {
      "epoch": 7.481013738373582,
      "grad_norm": 0.04899372532963753,
      "learning_rate": 1.2594931308132094e-05,
      "loss": 0.0021,
      "step": 87670
    },
    {
      "epoch": 7.481867053502858,
      "grad_norm": 0.11064816266298294,
      "learning_rate": 1.2590664732485708e-05,
      "loss": 0.0026,
      "step": 87680
    },
    {
      "epoch": 7.482720368632136,
      "grad_norm": 0.09760799258947372,
      "learning_rate": 1.258639815683932e-05,
      "loss": 0.0019,
      "step": 87690
    },
    {
      "epoch": 7.4835736837614135,
      "grad_norm": 0.17212076485157013,
      "learning_rate": 1.2582131581192935e-05,
      "loss": 0.0017,
      "step": 87700
    },
    {
      "epoch": 7.48442699889069,
      "grad_norm": 0.038758620619773865,
      "learning_rate": 1.257786500554655e-05,
      "loss": 0.0016,
      "step": 87710
    },
    {
      "epoch": 7.485280314019968,
      "grad_norm": 0.3429461419582367,
      "learning_rate": 1.2573598429900163e-05,
      "loss": 0.0012,
      "step": 87720
    },
    {
      "epoch": 7.486133629149244,
      "grad_norm": 0.22504457831382751,
      "learning_rate": 1.2569331854253778e-05,
      "loss": 0.0019,
      "step": 87730
    },
    {
      "epoch": 7.486986944278522,
      "grad_norm": 0.209258034825325,
      "learning_rate": 1.256506527860739e-05,
      "loss": 0.0014,
      "step": 87740
    },
    {
      "epoch": 7.4878402594077995,
      "grad_norm": 0.02904621511697769,
      "learning_rate": 1.2560798702961004e-05,
      "loss": 0.0014,
      "step": 87750
    },
    {
      "epoch": 7.488693574537076,
      "grad_norm": 0.3422885239124298,
      "learning_rate": 1.2556532127314619e-05,
      "loss": 0.0013,
      "step": 87760
    },
    {
      "epoch": 7.489546889666354,
      "grad_norm": 0.04337901249527931,
      "learning_rate": 1.2552265551668233e-05,
      "loss": 0.0022,
      "step": 87770
    },
    {
      "epoch": 7.490400204795631,
      "grad_norm": 0.13604721426963806,
      "learning_rate": 1.2547998976021847e-05,
      "loss": 0.0017,
      "step": 87780
    },
    {
      "epoch": 7.491253519924908,
      "grad_norm": 0.14955732226371765,
      "learning_rate": 1.254373240037546e-05,
      "loss": 0.002,
      "step": 87790
    },
    {
      "epoch": 7.4921068350541855,
      "grad_norm": 0.0390881709754467,
      "learning_rate": 1.2539465824729074e-05,
      "loss": 0.0013,
      "step": 87800
    },
    {
      "epoch": 7.492960150183463,
      "grad_norm": 0.30666857957839966,
      "learning_rate": 1.2535199249082688e-05,
      "loss": 0.0015,
      "step": 87810
    },
    {
      "epoch": 7.49381346531274,
      "grad_norm": 0.08277589082717896,
      "learning_rate": 1.2530932673436302e-05,
      "loss": 0.0018,
      "step": 87820
    },
    {
      "epoch": 7.494666780442017,
      "grad_norm": 0.18427078425884247,
      "learning_rate": 1.2526666097789913e-05,
      "loss": 0.0019,
      "step": 87830
    },
    {
      "epoch": 7.495520095571295,
      "grad_norm": 0.1830398589372635,
      "learning_rate": 1.2522399522143528e-05,
      "loss": 0.0016,
      "step": 87840
    },
    {
      "epoch": 7.4963734107005715,
      "grad_norm": 0.23686258494853973,
      "learning_rate": 1.251813294649714e-05,
      "loss": 0.0014,
      "step": 87850
    },
    {
      "epoch": 7.497226725829849,
      "grad_norm": 0.19181500375270844,
      "learning_rate": 1.2513866370850754e-05,
      "loss": 0.0016,
      "step": 87860
    },
    {
      "epoch": 7.498080040959127,
      "grad_norm": 0.20302149653434753,
      "learning_rate": 1.2509599795204369e-05,
      "loss": 0.0017,
      "step": 87870
    },
    {
      "epoch": 7.498933356088403,
      "grad_norm": 0.202936053276062,
      "learning_rate": 1.2505333219557983e-05,
      "loss": 0.0017,
      "step": 87880
    },
    {
      "epoch": 7.499786671217681,
      "grad_norm": 0.15062503516674042,
      "learning_rate": 1.2501066643911597e-05,
      "loss": 0.0016,
      "step": 87890
    },
    {
      "epoch": 7.5006399863469575,
      "grad_norm": 0.14524105191230774,
      "learning_rate": 1.249680006826521e-05,
      "loss": 0.0024,
      "step": 87900
    },
    {
      "epoch": 7.501493301476235,
      "grad_norm": 0.051461927592754364,
      "learning_rate": 1.2492533492618824e-05,
      "loss": 0.0015,
      "step": 87910
    },
    {
      "epoch": 7.502346616605513,
      "grad_norm": 0.1463455706834793,
      "learning_rate": 1.2488266916972438e-05,
      "loss": 0.0015,
      "step": 87920
    },
    {
      "epoch": 7.503199931734789,
      "grad_norm": 0.19715143740177155,
      "learning_rate": 1.2484000341326052e-05,
      "loss": 0.0019,
      "step": 87930
    },
    {
      "epoch": 7.504053246864067,
      "grad_norm": 0.16537170112133026,
      "learning_rate": 1.2479733765679667e-05,
      "loss": 0.0012,
      "step": 87940
    },
    {
      "epoch": 7.504906561993344,
      "grad_norm": 0.22041307389736176,
      "learning_rate": 1.2475467190033279e-05,
      "loss": 0.0016,
      "step": 87950
    },
    {
      "epoch": 7.505759877122621,
      "grad_norm": 0.27851319313049316,
      "learning_rate": 1.2471200614386893e-05,
      "loss": 0.0015,
      "step": 87960
    },
    {
      "epoch": 7.506613192251899,
      "grad_norm": 0.1736372411251068,
      "learning_rate": 1.2466934038740508e-05,
      "loss": 0.0018,
      "step": 87970
    },
    {
      "epoch": 7.507466507381176,
      "grad_norm": 0.22155697643756866,
      "learning_rate": 1.2462667463094122e-05,
      "loss": 0.0018,
      "step": 87980
    },
    {
      "epoch": 7.508319822510453,
      "grad_norm": 0.0475250706076622,
      "learning_rate": 1.2458400887447736e-05,
      "loss": 0.0016,
      "step": 87990
    },
    {
      "epoch": 7.50917313763973,
      "grad_norm": 0.4927978217601776,
      "learning_rate": 1.2454134311801349e-05,
      "loss": 0.0022,
      "step": 88000
    },
    {
      "epoch": 7.510026452769008,
      "grad_norm": 0.1297958791255951,
      "learning_rate": 1.2449867736154963e-05,
      "loss": 0.0016,
      "step": 88010
    },
    {
      "epoch": 7.510879767898285,
      "grad_norm": 0.11181048303842545,
      "learning_rate": 1.2445601160508577e-05,
      "loss": 0.0018,
      "step": 88020
    },
    {
      "epoch": 7.511733083027562,
      "grad_norm": 0.329648494720459,
      "learning_rate": 1.244133458486219e-05,
      "loss": 0.0023,
      "step": 88030
    },
    {
      "epoch": 7.51258639815684,
      "grad_norm": 0.1933104395866394,
      "learning_rate": 1.2437068009215804e-05,
      "loss": 0.0015,
      "step": 88040
    },
    {
      "epoch": 7.513439713286116,
      "grad_norm": 0.05690784752368927,
      "learning_rate": 1.2432801433569418e-05,
      "loss": 0.0018,
      "step": 88050
    },
    {
      "epoch": 7.514293028415394,
      "grad_norm": 0.21233554184436798,
      "learning_rate": 1.242853485792303e-05,
      "loss": 0.0019,
      "step": 88060
    },
    {
      "epoch": 7.5151463435446715,
      "grad_norm": 0.26909083127975464,
      "learning_rate": 1.2424268282276645e-05,
      "loss": 0.0017,
      "step": 88070
    },
    {
      "epoch": 7.515999658673948,
      "grad_norm": 0.2813338339328766,
      "learning_rate": 1.2420001706630259e-05,
      "loss": 0.0019,
      "step": 88080
    },
    {
      "epoch": 7.516852973803226,
      "grad_norm": 0.0838065966963768,
      "learning_rate": 1.2415735130983873e-05,
      "loss": 0.0018,
      "step": 88090
    },
    {
      "epoch": 7.517706288932503,
      "grad_norm": 0.09291864186525345,
      "learning_rate": 1.2411468555337488e-05,
      "loss": 0.0021,
      "step": 88100
    },
    {
      "epoch": 7.51855960406178,
      "grad_norm": 0.0797700434923172,
      "learning_rate": 1.24072019796911e-05,
      "loss": 0.0017,
      "step": 88110
    },
    {
      "epoch": 7.5194129191910575,
      "grad_norm": 0.06380234658718109,
      "learning_rate": 1.2402935404044714e-05,
      "loss": 0.0013,
      "step": 88120
    },
    {
      "epoch": 7.520266234320334,
      "grad_norm": 0.04025587812066078,
      "learning_rate": 1.2398668828398329e-05,
      "loss": 0.0014,
      "step": 88130
    },
    {
      "epoch": 7.521119549449612,
      "grad_norm": 0.09671907126903534,
      "learning_rate": 1.2394402252751943e-05,
      "loss": 0.002,
      "step": 88140
    },
    {
      "epoch": 7.521972864578889,
      "grad_norm": 0.25553515553474426,
      "learning_rate": 1.2390135677105555e-05,
      "loss": 0.0014,
      "step": 88150
    },
    {
      "epoch": 7.522826179708166,
      "grad_norm": 0.0962955504655838,
      "learning_rate": 1.2385869101459168e-05,
      "loss": 0.0016,
      "step": 88160
    },
    {
      "epoch": 7.5236794948374435,
      "grad_norm": 0.27657702565193176,
      "learning_rate": 1.2381602525812782e-05,
      "loss": 0.0017,
      "step": 88170
    },
    {
      "epoch": 7.524532809966721,
      "grad_norm": 0.27241238951683044,
      "learning_rate": 1.2377335950166396e-05,
      "loss": 0.0022,
      "step": 88180
    },
    {
      "epoch": 7.525386125095998,
      "grad_norm": 0.04735155776143074,
      "learning_rate": 1.237306937452001e-05,
      "loss": 0.0017,
      "step": 88190
    },
    {
      "epoch": 7.526239440225275,
      "grad_norm": 0.1951104700565338,
      "learning_rate": 1.2368802798873625e-05,
      "loss": 0.0018,
      "step": 88200
    },
    {
      "epoch": 7.527092755354553,
      "grad_norm": 0.19489793479442596,
      "learning_rate": 1.2364536223227238e-05,
      "loss": 0.0015,
      "step": 88210
    },
    {
      "epoch": 7.5279460704838295,
      "grad_norm": 0.11363629996776581,
      "learning_rate": 1.2360269647580852e-05,
      "loss": 0.0018,
      "step": 88220
    },
    {
      "epoch": 7.528799385613107,
      "grad_norm": 0.19877946376800537,
      "learning_rate": 1.2356003071934466e-05,
      "loss": 0.0022,
      "step": 88230
    },
    {
      "epoch": 7.529652700742384,
      "grad_norm": 0.1610393524169922,
      "learning_rate": 1.235173649628808e-05,
      "loss": 0.0022,
      "step": 88240
    },
    {
      "epoch": 7.530506015871661,
      "grad_norm": 0.08164773136377335,
      "learning_rate": 1.2347469920641694e-05,
      "loss": 0.0019,
      "step": 88250
    },
    {
      "epoch": 7.531359331000939,
      "grad_norm": 0.16819380223751068,
      "learning_rate": 1.2343203344995307e-05,
      "loss": 0.0017,
      "step": 88260
    },
    {
      "epoch": 7.5322126461302155,
      "grad_norm": 0.11274566501379013,
      "learning_rate": 1.2338936769348921e-05,
      "loss": 0.0016,
      "step": 88270
    },
    {
      "epoch": 7.533065961259493,
      "grad_norm": 0.03426800295710564,
      "learning_rate": 1.2334670193702535e-05,
      "loss": 0.0015,
      "step": 88280
    },
    {
      "epoch": 7.533919276388771,
      "grad_norm": 0.06509541720151901,
      "learning_rate": 1.233040361805615e-05,
      "loss": 0.0015,
      "step": 88290
    },
    {
      "epoch": 7.534772591518047,
      "grad_norm": 0.07629165053367615,
      "learning_rate": 1.2326137042409762e-05,
      "loss": 0.0016,
      "step": 88300
    },
    {
      "epoch": 7.535625906647325,
      "grad_norm": 0.04393569007515907,
      "learning_rate": 1.2321870466763377e-05,
      "loss": 0.0015,
      "step": 88310
    },
    {
      "epoch": 7.536479221776602,
      "grad_norm": 0.053672052919864655,
      "learning_rate": 1.2317603891116989e-05,
      "loss": 0.0017,
      "step": 88320
    },
    {
      "epoch": 7.537332536905879,
      "grad_norm": 0.09448028355836868,
      "learning_rate": 1.2313337315470603e-05,
      "loss": 0.0014,
      "step": 88330
    },
    {
      "epoch": 7.538185852035157,
      "grad_norm": 0.18510302901268005,
      "learning_rate": 1.2309070739824218e-05,
      "loss": 0.0022,
      "step": 88340
    },
    {
      "epoch": 7.539039167164434,
      "grad_norm": 0.31149768829345703,
      "learning_rate": 1.2304804164177832e-05,
      "loss": 0.0019,
      "step": 88350
    },
    {
      "epoch": 7.539892482293711,
      "grad_norm": 0.19838285446166992,
      "learning_rate": 1.2300537588531446e-05,
      "loss": 0.0017,
      "step": 88360
    },
    {
      "epoch": 7.540745797422988,
      "grad_norm": 0.18211621046066284,
      "learning_rate": 1.2296271012885059e-05,
      "loss": 0.0022,
      "step": 88370
    },
    {
      "epoch": 7.541599112552266,
      "grad_norm": 0.03393436595797539,
      "learning_rate": 1.2292004437238673e-05,
      "loss": 0.0014,
      "step": 88380
    },
    {
      "epoch": 7.542452427681543,
      "grad_norm": 0.0186843853443861,
      "learning_rate": 1.2287737861592287e-05,
      "loss": 0.0016,
      "step": 88390
    },
    {
      "epoch": 7.54330574281082,
      "grad_norm": 0.10957466810941696,
      "learning_rate": 1.2283471285945901e-05,
      "loss": 0.0019,
      "step": 88400
    },
    {
      "epoch": 7.544159057940098,
      "grad_norm": 0.16617971658706665,
      "learning_rate": 1.2279204710299516e-05,
      "loss": 0.0014,
      "step": 88410
    },
    {
      "epoch": 7.545012373069374,
      "grad_norm": 0.05993061885237694,
      "learning_rate": 1.2274938134653128e-05,
      "loss": 0.0018,
      "step": 88420
    },
    {
      "epoch": 7.545865688198652,
      "grad_norm": 0.28891605138778687,
      "learning_rate": 1.227067155900674e-05,
      "loss": 0.0018,
      "step": 88430
    },
    {
      "epoch": 7.546719003327929,
      "grad_norm": 0.0624280609190464,
      "learning_rate": 1.2266404983360355e-05,
      "loss": 0.0016,
      "step": 88440
    },
    {
      "epoch": 7.547572318457206,
      "grad_norm": 0.2917321026325226,
      "learning_rate": 1.2262138407713969e-05,
      "loss": 0.002,
      "step": 88450
    },
    {
      "epoch": 7.548425633586484,
      "grad_norm": 0.1257336288690567,
      "learning_rate": 1.2257871832067583e-05,
      "loss": 0.0017,
      "step": 88460
    },
    {
      "epoch": 7.549278948715761,
      "grad_norm": 0.05726797878742218,
      "learning_rate": 1.2253605256421196e-05,
      "loss": 0.0017,
      "step": 88470
    },
    {
      "epoch": 7.550132263845038,
      "grad_norm": 0.2717749774456024,
      "learning_rate": 1.224933868077481e-05,
      "loss": 0.0015,
      "step": 88480
    },
    {
      "epoch": 7.550985578974315,
      "grad_norm": 0.030181463807821274,
      "learning_rate": 1.2245072105128424e-05,
      "loss": 0.0019,
      "step": 88490
    },
    {
      "epoch": 7.551838894103592,
      "grad_norm": 0.09668479859828949,
      "learning_rate": 1.2240805529482039e-05,
      "loss": 0.0019,
      "step": 88500
    },
    {
      "epoch": 7.55269220923287,
      "grad_norm": 0.07594435662031174,
      "learning_rate": 1.2236538953835653e-05,
      "loss": 0.0018,
      "step": 88510
    },
    {
      "epoch": 7.553545524362147,
      "grad_norm": 0.04329434037208557,
      "learning_rate": 1.2232272378189265e-05,
      "loss": 0.0023,
      "step": 88520
    },
    {
      "epoch": 7.554398839491424,
      "grad_norm": 0.2415744513273239,
      "learning_rate": 1.222800580254288e-05,
      "loss": 0.0019,
      "step": 88530
    },
    {
      "epoch": 7.555252154620701,
      "grad_norm": 0.06705363839864731,
      "learning_rate": 1.2223739226896494e-05,
      "loss": 0.0014,
      "step": 88540
    },
    {
      "epoch": 7.556105469749979,
      "grad_norm": 0.16374996304512024,
      "learning_rate": 1.2219472651250108e-05,
      "loss": 0.0018,
      "step": 88550
    },
    {
      "epoch": 7.556958784879256,
      "grad_norm": 0.21963244676589966,
      "learning_rate": 1.221520607560372e-05,
      "loss": 0.0017,
      "step": 88560
    },
    {
      "epoch": 7.557812100008533,
      "grad_norm": 0.14533549547195435,
      "learning_rate": 1.2210939499957335e-05,
      "loss": 0.0018,
      "step": 88570
    },
    {
      "epoch": 7.558665415137811,
      "grad_norm": 0.36675700545310974,
      "learning_rate": 1.2206672924310947e-05,
      "loss": 0.0014,
      "step": 88580
    },
    {
      "epoch": 7.559518730267087,
      "grad_norm": 0.11290955543518066,
      "learning_rate": 1.2202406348664562e-05,
      "loss": 0.0023,
      "step": 88590
    },
    {
      "epoch": 7.560372045396365,
      "grad_norm": 0.05141739919781685,
      "learning_rate": 1.2198139773018176e-05,
      "loss": 0.0015,
      "step": 88600
    },
    {
      "epoch": 7.561225360525642,
      "grad_norm": 0.09582503885030746,
      "learning_rate": 1.219387319737179e-05,
      "loss": 0.0017,
      "step": 88610
    },
    {
      "epoch": 7.562078675654919,
      "grad_norm": 0.0532790869474411,
      "learning_rate": 1.2189606621725404e-05,
      "loss": 0.0016,
      "step": 88620
    },
    {
      "epoch": 7.562931990784197,
      "grad_norm": 0.02523944340646267,
      "learning_rate": 1.2185340046079017e-05,
      "loss": 0.0018,
      "step": 88630
    },
    {
      "epoch": 7.563785305913473,
      "grad_norm": 0.31692376732826233,
      "learning_rate": 1.2181073470432631e-05,
      "loss": 0.0016,
      "step": 88640
    },
    {
      "epoch": 7.564638621042751,
      "grad_norm": 0.30824536085128784,
      "learning_rate": 1.2176806894786245e-05,
      "loss": 0.0017,
      "step": 88650
    },
    {
      "epoch": 7.5654919361720285,
      "grad_norm": 0.1094173863530159,
      "learning_rate": 1.217254031913986e-05,
      "loss": 0.0019,
      "step": 88660
    },
    {
      "epoch": 7.566345251301305,
      "grad_norm": 0.07559951394796371,
      "learning_rate": 1.2168273743493474e-05,
      "loss": 0.0017,
      "step": 88670
    },
    {
      "epoch": 7.567198566430583,
      "grad_norm": 0.22006820142269135,
      "learning_rate": 1.2164007167847086e-05,
      "loss": 0.0017,
      "step": 88680
    },
    {
      "epoch": 7.56805188155986,
      "grad_norm": 0.32613736391067505,
      "learning_rate": 1.2159740592200699e-05,
      "loss": 0.0018,
      "step": 88690
    },
    {
      "epoch": 7.568905196689137,
      "grad_norm": 0.06532704085111618,
      "learning_rate": 1.2155474016554313e-05,
      "loss": 0.0017,
      "step": 88700
    },
    {
      "epoch": 7.5697585118184145,
      "grad_norm": 0.36147212982177734,
      "learning_rate": 1.2151207440907928e-05,
      "loss": 0.0013,
      "step": 88710
    },
    {
      "epoch": 7.570611826947692,
      "grad_norm": 0.04386668652296066,
      "learning_rate": 1.2146940865261542e-05,
      "loss": 0.0021,
      "step": 88720
    },
    {
      "epoch": 7.571465142076969,
      "grad_norm": 0.1881452053785324,
      "learning_rate": 1.2142674289615156e-05,
      "loss": 0.0023,
      "step": 88730
    },
    {
      "epoch": 7.572318457206246,
      "grad_norm": 0.13714288175106049,
      "learning_rate": 1.2138407713968769e-05,
      "loss": 0.0015,
      "step": 88740
    },
    {
      "epoch": 7.573171772335524,
      "grad_norm": 0.10831385105848312,
      "learning_rate": 1.2134141138322383e-05,
      "loss": 0.0021,
      "step": 88750
    },
    {
      "epoch": 7.5740250874648005,
      "grad_norm": 0.3301742374897003,
      "learning_rate": 1.2129874562675997e-05,
      "loss": 0.0015,
      "step": 88760
    },
    {
      "epoch": 7.574878402594078,
      "grad_norm": 0.30952098965644836,
      "learning_rate": 1.2125607987029611e-05,
      "loss": 0.002,
      "step": 88770
    },
    {
      "epoch": 7.575731717723356,
      "grad_norm": 0.2349271923303604,
      "learning_rate": 1.2121341411383224e-05,
      "loss": 0.0018,
      "step": 88780
    },
    {
      "epoch": 7.576585032852632,
      "grad_norm": 0.11297260969877243,
      "learning_rate": 1.2117074835736838e-05,
      "loss": 0.0019,
      "step": 88790
    },
    {
      "epoch": 7.57743834798191,
      "grad_norm": 0.09319542348384857,
      "learning_rate": 1.2112808260090452e-05,
      "loss": 0.0019,
      "step": 88800
    },
    {
      "epoch": 7.578291663111187,
      "grad_norm": 0.14691683650016785,
      "learning_rate": 1.2108541684444067e-05,
      "loss": 0.0014,
      "step": 88810
    },
    {
      "epoch": 7.579144978240464,
      "grad_norm": 0.20292817056179047,
      "learning_rate": 1.210427510879768e-05,
      "loss": 0.0015,
      "step": 88820
    },
    {
      "epoch": 7.579998293369742,
      "grad_norm": 0.16764456033706665,
      "learning_rate": 1.2100008533151293e-05,
      "loss": 0.0022,
      "step": 88830
    },
    {
      "epoch": 7.580851608499019,
      "grad_norm": 0.34402182698249817,
      "learning_rate": 1.2095741957504906e-05,
      "loss": 0.0018,
      "step": 88840
    },
    {
      "epoch": 7.581704923628296,
      "grad_norm": 0.09610719233751297,
      "learning_rate": 1.209147538185852e-05,
      "loss": 0.0022,
      "step": 88850
    },
    {
      "epoch": 7.582558238757573,
      "grad_norm": 0.17304450273513794,
      "learning_rate": 1.2087208806212134e-05,
      "loss": 0.0015,
      "step": 88860
    },
    {
      "epoch": 7.58341155388685,
      "grad_norm": 0.22193403542041779,
      "learning_rate": 1.2082942230565749e-05,
      "loss": 0.002,
      "step": 88870
    },
    {
      "epoch": 7.584264869016128,
      "grad_norm": 0.15236248075962067,
      "learning_rate": 1.2078675654919363e-05,
      "loss": 0.0016,
      "step": 88880
    },
    {
      "epoch": 7.585118184145405,
      "grad_norm": 0.04329830780625343,
      "learning_rate": 1.2074409079272975e-05,
      "loss": 0.0018,
      "step": 88890
    },
    {
      "epoch": 7.585971499274682,
      "grad_norm": 0.2961944341659546,
      "learning_rate": 1.207014250362659e-05,
      "loss": 0.0022,
      "step": 88900
    },
    {
      "epoch": 7.586824814403959,
      "grad_norm": 0.07488410919904709,
      "learning_rate": 1.2065875927980204e-05,
      "loss": 0.0014,
      "step": 88910
    },
    {
      "epoch": 7.587678129533237,
      "grad_norm": 0.21772964298725128,
      "learning_rate": 1.2061609352333818e-05,
      "loss": 0.0018,
      "step": 88920
    },
    {
      "epoch": 7.588531444662514,
      "grad_norm": 0.06925731897354126,
      "learning_rate": 1.2057342776687432e-05,
      "loss": 0.0017,
      "step": 88930
    },
    {
      "epoch": 7.589384759791791,
      "grad_norm": 0.21700380742549896,
      "learning_rate": 1.2053076201041045e-05,
      "loss": 0.0017,
      "step": 88940
    },
    {
      "epoch": 7.590238074921069,
      "grad_norm": 0.36133241653442383,
      "learning_rate": 1.2048809625394659e-05,
      "loss": 0.0017,
      "step": 88950
    },
    {
      "epoch": 7.591091390050345,
      "grad_norm": 0.05871376767754555,
      "learning_rate": 1.2044543049748272e-05,
      "loss": 0.0018,
      "step": 88960
    },
    {
      "epoch": 7.591944705179623,
      "grad_norm": 0.11887874454259872,
      "learning_rate": 1.2040276474101886e-05,
      "loss": 0.0013,
      "step": 88970
    },
    {
      "epoch": 7.5927980203089,
      "grad_norm": 0.2465059757232666,
      "learning_rate": 1.20360098984555e-05,
      "loss": 0.0018,
      "step": 88980
    },
    {
      "epoch": 7.593651335438177,
      "grad_norm": 0.07425249367952347,
      "learning_rate": 1.2031743322809114e-05,
      "loss": 0.0017,
      "step": 88990
    },
    {
      "epoch": 7.594504650567455,
      "grad_norm": 0.09779028594493866,
      "learning_rate": 1.2027476747162727e-05,
      "loss": 0.0019,
      "step": 89000
    },
    {
      "epoch": 7.595357965696731,
      "grad_norm": 0.05935836583375931,
      "learning_rate": 1.2023210171516341e-05,
      "loss": 0.0016,
      "step": 89010
    },
    {
      "epoch": 7.596211280826009,
      "grad_norm": 0.06682693213224411,
      "learning_rate": 1.2018943595869955e-05,
      "loss": 0.0018,
      "step": 89020
    },
    {
      "epoch": 7.5970645959552865,
      "grad_norm": 0.11396344006061554,
      "learning_rate": 1.201467702022357e-05,
      "loss": 0.0016,
      "step": 89030
    },
    {
      "epoch": 7.597917911084563,
      "grad_norm": 0.23954571783542633,
      "learning_rate": 1.2010410444577184e-05,
      "loss": 0.0015,
      "step": 89040
    },
    {
      "epoch": 7.598771226213841,
      "grad_norm": 0.2704724073410034,
      "learning_rate": 1.2006143868930796e-05,
      "loss": 0.0023,
      "step": 89050
    },
    {
      "epoch": 7.599624541343118,
      "grad_norm": 0.0925402045249939,
      "learning_rate": 1.200187729328441e-05,
      "loss": 0.002,
      "step": 89060
    },
    {
      "epoch": 7.600477856472395,
      "grad_norm": 0.23852276802062988,
      "learning_rate": 1.1997610717638025e-05,
      "loss": 0.0015,
      "step": 89070
    },
    {
      "epoch": 7.6013311716016725,
      "grad_norm": 0.21883141994476318,
      "learning_rate": 1.199334414199164e-05,
      "loss": 0.0019,
      "step": 89080
    },
    {
      "epoch": 7.60218448673095,
      "grad_norm": 0.20080339908599854,
      "learning_rate": 1.1989077566345252e-05,
      "loss": 0.0017,
      "step": 89090
    },
    {
      "epoch": 7.603037801860227,
      "grad_norm": 0.20244795083999634,
      "learning_rate": 1.1984810990698864e-05,
      "loss": 0.0021,
      "step": 89100
    },
    {
      "epoch": 7.603891116989504,
      "grad_norm": 0.1634097695350647,
      "learning_rate": 1.1980544415052479e-05,
      "loss": 0.0014,
      "step": 89110
    },
    {
      "epoch": 7.604744432118782,
      "grad_norm": 0.033256903290748596,
      "learning_rate": 1.1976277839406093e-05,
      "loss": 0.0015,
      "step": 89120
    },
    {
      "epoch": 7.6055977472480585,
      "grad_norm": 0.07517153024673462,
      "learning_rate": 1.1972011263759707e-05,
      "loss": 0.0016,
      "step": 89130
    },
    {
      "epoch": 7.606451062377336,
      "grad_norm": 0.2175905853509903,
      "learning_rate": 1.1967744688113321e-05,
      "loss": 0.0015,
      "step": 89140
    },
    {
      "epoch": 7.607304377506614,
      "grad_norm": 0.16692402958869934,
      "learning_rate": 1.1963478112466934e-05,
      "loss": 0.0016,
      "step": 89150
    },
    {
      "epoch": 7.60815769263589,
      "grad_norm": 0.32829275727272034,
      "learning_rate": 1.1959211536820548e-05,
      "loss": 0.0015,
      "step": 89160
    },
    {
      "epoch": 7.609011007765168,
      "grad_norm": 0.0766676664352417,
      "learning_rate": 1.1954944961174162e-05,
      "loss": 0.0014,
      "step": 89170
    },
    {
      "epoch": 7.609864322894445,
      "grad_norm": 0.17435172200202942,
      "learning_rate": 1.1950678385527777e-05,
      "loss": 0.0012,
      "step": 89180
    },
    {
      "epoch": 7.610717638023722,
      "grad_norm": 0.1854795217514038,
      "learning_rate": 1.194641180988139e-05,
      "loss": 0.0014,
      "step": 89190
    },
    {
      "epoch": 7.611570953153,
      "grad_norm": 0.09199434518814087,
      "learning_rate": 1.1942145234235003e-05,
      "loss": 0.0016,
      "step": 89200
    },
    {
      "epoch": 7.612424268282277,
      "grad_norm": 0.029144221916794777,
      "learning_rate": 1.1937878658588618e-05,
      "loss": 0.0016,
      "step": 89210
    },
    {
      "epoch": 7.613277583411554,
      "grad_norm": 0.07546499371528625,
      "learning_rate": 1.1933612082942232e-05,
      "loss": 0.0016,
      "step": 89220
    },
    {
      "epoch": 7.614130898540831,
      "grad_norm": 0.23320914804935455,
      "learning_rate": 1.1929345507295844e-05,
      "loss": 0.0014,
      "step": 89230
    },
    {
      "epoch": 7.614984213670108,
      "grad_norm": 0.10928796976804733,
      "learning_rate": 1.1925078931649459e-05,
      "loss": 0.0017,
      "step": 89240
    },
    {
      "epoch": 7.615837528799386,
      "grad_norm": 0.02347714640200138,
      "learning_rate": 1.1920812356003073e-05,
      "loss": 0.0019,
      "step": 89250
    },
    {
      "epoch": 7.616690843928663,
      "grad_norm": 0.0960724800825119,
      "learning_rate": 1.1916545780356685e-05,
      "loss": 0.0023,
      "step": 89260
    },
    {
      "epoch": 7.61754415905794,
      "grad_norm": 0.09371066093444824,
      "learning_rate": 1.19122792047103e-05,
      "loss": 0.0016,
      "step": 89270
    },
    {
      "epoch": 7.618397474187217,
      "grad_norm": 0.17991073429584503,
      "learning_rate": 1.1908012629063914e-05,
      "loss": 0.0017,
      "step": 89280
    },
    {
      "epoch": 7.619250789316495,
      "grad_norm": 0.18461880087852478,
      "learning_rate": 1.1903746053417528e-05,
      "loss": 0.0016,
      "step": 89290
    },
    {
      "epoch": 7.620104104445772,
      "grad_norm": 0.07921838760375977,
      "learning_rate": 1.1899479477771142e-05,
      "loss": 0.0018,
      "step": 89300
    },
    {
      "epoch": 7.620957419575049,
      "grad_norm": 0.04208088666200638,
      "learning_rate": 1.1895212902124755e-05,
      "loss": 0.0016,
      "step": 89310
    },
    {
      "epoch": 7.621810734704327,
      "grad_norm": 0.07738468050956726,
      "learning_rate": 1.1890946326478369e-05,
      "loss": 0.0017,
      "step": 89320
    },
    {
      "epoch": 7.622664049833603,
      "grad_norm": 0.23747186362743378,
      "learning_rate": 1.1886679750831983e-05,
      "loss": 0.0018,
      "step": 89330
    },
    {
      "epoch": 7.623517364962881,
      "grad_norm": 0.21758799254894257,
      "learning_rate": 1.1882413175185598e-05,
      "loss": 0.0018,
      "step": 89340
    },
    {
      "epoch": 7.624370680092158,
      "grad_norm": 0.14673593640327454,
      "learning_rate": 1.1878146599539212e-05,
      "loss": 0.0024,
      "step": 89350
    },
    {
      "epoch": 7.625223995221435,
      "grad_norm": 0.2738650143146515,
      "learning_rate": 1.1873880023892824e-05,
      "loss": 0.0016,
      "step": 89360
    },
    {
      "epoch": 7.626077310350713,
      "grad_norm": 0.09490040689706802,
      "learning_rate": 1.1869613448246437e-05,
      "loss": 0.002,
      "step": 89370
    },
    {
      "epoch": 7.626930625479989,
      "grad_norm": 0.2023981809616089,
      "learning_rate": 1.1865346872600051e-05,
      "loss": 0.0021,
      "step": 89380
    },
    {
      "epoch": 7.627783940609267,
      "grad_norm": 0.16975507140159607,
      "learning_rate": 1.1861080296953665e-05,
      "loss": 0.0017,
      "step": 89390
    },
    {
      "epoch": 7.6286372557385445,
      "grad_norm": 0.18640074133872986,
      "learning_rate": 1.185681372130728e-05,
      "loss": 0.002,
      "step": 89400
    },
    {
      "epoch": 7.629490570867821,
      "grad_norm": 0.06714513152837753,
      "learning_rate": 1.1852547145660892e-05,
      "loss": 0.0014,
      "step": 89410
    },
    {
      "epoch": 7.630343885997099,
      "grad_norm": 0.13224709033966064,
      "learning_rate": 1.1848280570014506e-05,
      "loss": 0.0019,
      "step": 89420
    },
    {
      "epoch": 7.631197201126376,
      "grad_norm": 0.1275075376033783,
      "learning_rate": 1.184401399436812e-05,
      "loss": 0.0013,
      "step": 89430
    },
    {
      "epoch": 7.632050516255653,
      "grad_norm": 0.3438820540904999,
      "learning_rate": 1.1839747418721735e-05,
      "loss": 0.0016,
      "step": 89440
    },
    {
      "epoch": 7.6329038313849304,
      "grad_norm": 0.11461282521486282,
      "learning_rate": 1.183548084307535e-05,
      "loss": 0.0018,
      "step": 89450
    },
    {
      "epoch": 7.633757146514208,
      "grad_norm": 0.04442374408245087,
      "learning_rate": 1.1831214267428962e-05,
      "loss": 0.0017,
      "step": 89460
    },
    {
      "epoch": 7.634610461643485,
      "grad_norm": 0.11237701028585434,
      "learning_rate": 1.1826947691782576e-05,
      "loss": 0.0018,
      "step": 89470
    },
    {
      "epoch": 7.635463776772762,
      "grad_norm": 0.0383894108235836,
      "learning_rate": 1.182268111613619e-05,
      "loss": 0.0018,
      "step": 89480
    },
    {
      "epoch": 7.63631709190204,
      "grad_norm": 0.03993316739797592,
      "learning_rate": 1.1818414540489803e-05,
      "loss": 0.0019,
      "step": 89490
    },
    {
      "epoch": 7.637170407031316,
      "grad_norm": 0.36225825548171997,
      "learning_rate": 1.1814147964843417e-05,
      "loss": 0.002,
      "step": 89500
    },
    {
      "epoch": 7.638023722160594,
      "grad_norm": 0.2692447304725647,
      "learning_rate": 1.1809881389197031e-05,
      "loss": 0.0018,
      "step": 89510
    },
    {
      "epoch": 7.6388770372898716,
      "grad_norm": 0.032320160418748856,
      "learning_rate": 1.1805614813550644e-05,
      "loss": 0.0017,
      "step": 89520
    },
    {
      "epoch": 7.639730352419148,
      "grad_norm": 0.3354620039463043,
      "learning_rate": 1.1801348237904258e-05,
      "loss": 0.0018,
      "step": 89530
    },
    {
      "epoch": 7.640583667548426,
      "grad_norm": 0.16447801887989044,
      "learning_rate": 1.1797081662257872e-05,
      "loss": 0.0021,
      "step": 89540
    },
    {
      "epoch": 7.641436982677703,
      "grad_norm": 0.15490266680717468,
      "learning_rate": 1.1792815086611487e-05,
      "loss": 0.0017,
      "step": 89550
    },
    {
      "epoch": 7.64229029780698,
      "grad_norm": 0.28669819235801697,
      "learning_rate": 1.17885485109651e-05,
      "loss": 0.0016,
      "step": 89560
    },
    {
      "epoch": 7.6431436129362575,
      "grad_norm": 0.07783054560422897,
      "learning_rate": 1.1784281935318713e-05,
      "loss": 0.002,
      "step": 89570
    },
    {
      "epoch": 7.643996928065535,
      "grad_norm": 0.1099221482872963,
      "learning_rate": 1.1780015359672328e-05,
      "loss": 0.0018,
      "step": 89580
    },
    {
      "epoch": 7.644850243194812,
      "grad_norm": 0.2505810558795929,
      "learning_rate": 1.1775748784025942e-05,
      "loss": 0.002,
      "step": 89590
    },
    {
      "epoch": 7.645703558324089,
      "grad_norm": 0.12709012627601624,
      "learning_rate": 1.1771482208379556e-05,
      "loss": 0.0014,
      "step": 89600
    },
    {
      "epoch": 7.646556873453366,
      "grad_norm": 0.10856535285711288,
      "learning_rate": 1.176721563273317e-05,
      "loss": 0.002,
      "step": 89610
    },
    {
      "epoch": 7.6474101885826435,
      "grad_norm": 0.06387726962566376,
      "learning_rate": 1.1762949057086783e-05,
      "loss": 0.0016,
      "step": 89620
    },
    {
      "epoch": 7.648263503711921,
      "grad_norm": 0.11846579611301422,
      "learning_rate": 1.1758682481440395e-05,
      "loss": 0.0013,
      "step": 89630
    },
    {
      "epoch": 7.649116818841198,
      "grad_norm": 0.04734089970588684,
      "learning_rate": 1.175441590579401e-05,
      "loss": 0.0019,
      "step": 89640
    },
    {
      "epoch": 7.649970133970475,
      "grad_norm": 0.13268981873989105,
      "learning_rate": 1.1750149330147624e-05,
      "loss": 0.0015,
      "step": 89650
    },
    {
      "epoch": 7.650823449099753,
      "grad_norm": 0.18586240708827972,
      "learning_rate": 1.1745882754501238e-05,
      "loss": 0.0019,
      "step": 89660
    },
    {
      "epoch": 7.6516767642290295,
      "grad_norm": 0.29150092601776123,
      "learning_rate": 1.1741616178854852e-05,
      "loss": 0.0014,
      "step": 89670
    },
    {
      "epoch": 7.652530079358307,
      "grad_norm": 0.20055963099002838,
      "learning_rate": 1.1737349603208465e-05,
      "loss": 0.002,
      "step": 89680
    },
    {
      "epoch": 7.653383394487585,
      "grad_norm": 0.030885200947523117,
      "learning_rate": 1.1733083027562079e-05,
      "loss": 0.0016,
      "step": 89690
    },
    {
      "epoch": 7.654236709616861,
      "grad_norm": 0.0767248347401619,
      "learning_rate": 1.1728816451915693e-05,
      "loss": 0.0014,
      "step": 89700
    },
    {
      "epoch": 7.655090024746139,
      "grad_norm": 0.28093838691711426,
      "learning_rate": 1.1724549876269308e-05,
      "loss": 0.0012,
      "step": 89710
    },
    {
      "epoch": 7.6559433398754155,
      "grad_norm": 0.09269779175519943,
      "learning_rate": 1.172028330062292e-05,
      "loss": 0.0015,
      "step": 89720
    },
    {
      "epoch": 7.656796655004693,
      "grad_norm": 0.0917191132903099,
      "learning_rate": 1.1716016724976534e-05,
      "loss": 0.0018,
      "step": 89730
    },
    {
      "epoch": 7.657649970133971,
      "grad_norm": 0.044559068977832794,
      "learning_rate": 1.1711750149330149e-05,
      "loss": 0.0013,
      "step": 89740
    },
    {
      "epoch": 7.658503285263247,
      "grad_norm": 0.03871554508805275,
      "learning_rate": 1.1707483573683763e-05,
      "loss": 0.0019,
      "step": 89750
    },
    {
      "epoch": 7.659356600392525,
      "grad_norm": 0.1486094444990158,
      "learning_rate": 1.1703216998037375e-05,
      "loss": 0.0018,
      "step": 89760
    },
    {
      "epoch": 7.660209915521802,
      "grad_norm": 0.25965553522109985,
      "learning_rate": 1.169895042239099e-05,
      "loss": 0.0022,
      "step": 89770
    },
    {
      "epoch": 7.661063230651079,
      "grad_norm": 0.13603025674819946,
      "learning_rate": 1.1694683846744602e-05,
      "loss": 0.0018,
      "step": 89780
    },
    {
      "epoch": 7.661916545780357,
      "grad_norm": 0.11025674641132355,
      "learning_rate": 1.1690417271098216e-05,
      "loss": 0.0013,
      "step": 89790
    },
    {
      "epoch": 7.662769860909634,
      "grad_norm": 0.12955787777900696,
      "learning_rate": 1.168615069545183e-05,
      "loss": 0.0017,
      "step": 89800
    },
    {
      "epoch": 7.663623176038911,
      "grad_norm": 0.2750937342643738,
      "learning_rate": 1.1681884119805445e-05,
      "loss": 0.0016,
      "step": 89810
    },
    {
      "epoch": 7.664476491168188,
      "grad_norm": 0.27388128638267517,
      "learning_rate": 1.1677617544159059e-05,
      "loss": 0.0019,
      "step": 89820
    },
    {
      "epoch": 7.665329806297466,
      "grad_norm": 0.26666298508644104,
      "learning_rate": 1.1673350968512672e-05,
      "loss": 0.0017,
      "step": 89830
    },
    {
      "epoch": 7.666183121426743,
      "grad_norm": 0.08173638582229614,
      "learning_rate": 1.1669084392866286e-05,
      "loss": 0.0018,
      "step": 89840
    },
    {
      "epoch": 7.66703643655602,
      "grad_norm": 0.18348246812820435,
      "learning_rate": 1.16648178172199e-05,
      "loss": 0.0018,
      "step": 89850
    },
    {
      "epoch": 7.667889751685298,
      "grad_norm": 0.21974101662635803,
      "learning_rate": 1.1660551241573514e-05,
      "loss": 0.0016,
      "step": 89860
    },
    {
      "epoch": 7.668743066814574,
      "grad_norm": 0.1287539303302765,
      "learning_rate": 1.1656284665927129e-05,
      "loss": 0.0019,
      "step": 89870
    },
    {
      "epoch": 7.669596381943852,
      "grad_norm": 0.1656648814678192,
      "learning_rate": 1.1652018090280741e-05,
      "loss": 0.0015,
      "step": 89880
    },
    {
      "epoch": 7.6704496970731295,
      "grad_norm": 0.09435795247554779,
      "learning_rate": 1.1647751514634354e-05,
      "loss": 0.002,
      "step": 89890
    },
    {
      "epoch": 7.671303012202406,
      "grad_norm": 0.06490495055913925,
      "learning_rate": 1.1643484938987968e-05,
      "loss": 0.0019,
      "step": 89900
    },
    {
      "epoch": 7.672156327331684,
      "grad_norm": 0.2507476806640625,
      "learning_rate": 1.1639218363341582e-05,
      "loss": 0.0018,
      "step": 89910
    },
    {
      "epoch": 7.673009642460961,
      "grad_norm": 0.3469448685646057,
      "learning_rate": 1.1634951787695196e-05,
      "loss": 0.0015,
      "step": 89920
    },
    {
      "epoch": 7.673862957590238,
      "grad_norm": 0.29532042145729065,
      "learning_rate": 1.163068521204881e-05,
      "loss": 0.0014,
      "step": 89930
    },
    {
      "epoch": 7.6747162727195155,
      "grad_norm": 0.3097439110279083,
      "learning_rate": 1.1626418636402423e-05,
      "loss": 0.0017,
      "step": 89940
    },
    {
      "epoch": 7.675569587848792,
      "grad_norm": 0.11061778664588928,
      "learning_rate": 1.1622152060756038e-05,
      "loss": 0.0023,
      "step": 89950
    },
    {
      "epoch": 7.67642290297807,
      "grad_norm": 0.2900787591934204,
      "learning_rate": 1.1617885485109652e-05,
      "loss": 0.0018,
      "step": 89960
    },
    {
      "epoch": 7.677276218107347,
      "grad_norm": 0.03110950067639351,
      "learning_rate": 1.1613618909463266e-05,
      "loss": 0.0019,
      "step": 89970
    },
    {
      "epoch": 7.678129533236624,
      "grad_norm": 0.07640590518712997,
      "learning_rate": 1.160935233381688e-05,
      "loss": 0.0015,
      "step": 89980
    },
    {
      "epoch": 7.6789828483659015,
      "grad_norm": 0.16256432235240936,
      "learning_rate": 1.1605085758170493e-05,
      "loss": 0.0018,
      "step": 89990
    },
    {
      "epoch": 7.679836163495179,
      "grad_norm": 0.030030423775315285,
      "learning_rate": 1.1600819182524107e-05,
      "loss": 0.0017,
      "step": 90000
    },
    {
      "epoch": 7.680689478624456,
      "grad_norm": 0.07854697108268738,
      "learning_rate": 1.1596552606877721e-05,
      "loss": 0.0017,
      "step": 90010
    },
    {
      "epoch": 7.681542793753733,
      "grad_norm": 0.26562440395355225,
      "learning_rate": 1.1592286031231334e-05,
      "loss": 0.0017,
      "step": 90020
    },
    {
      "epoch": 7.682396108883011,
      "grad_norm": 0.1304125338792801,
      "learning_rate": 1.1588019455584948e-05,
      "loss": 0.0018,
      "step": 90030
    },
    {
      "epoch": 7.6832494240122875,
      "grad_norm": 0.14530692994594574,
      "learning_rate": 1.158375287993856e-05,
      "loss": 0.0021,
      "step": 90040
    },
    {
      "epoch": 7.684102739141565,
      "grad_norm": 0.20317146182060242,
      "learning_rate": 1.1579486304292175e-05,
      "loss": 0.0016,
      "step": 90050
    },
    {
      "epoch": 7.684956054270843,
      "grad_norm": 0.29195982217788696,
      "learning_rate": 1.1575219728645789e-05,
      "loss": 0.0015,
      "step": 90060
    },
    {
      "epoch": 7.685809369400119,
      "grad_norm": 0.12934905290603638,
      "learning_rate": 1.1570953152999403e-05,
      "loss": 0.0015,
      "step": 90070
    },
    {
      "epoch": 7.686662684529397,
      "grad_norm": 0.15155069530010223,
      "learning_rate": 1.1566686577353018e-05,
      "loss": 0.0016,
      "step": 90080
    },
    {
      "epoch": 7.6875159996586735,
      "grad_norm": 0.06253906339406967,
      "learning_rate": 1.156242000170663e-05,
      "loss": 0.0019,
      "step": 90090
    },
    {
      "epoch": 7.688369314787951,
      "grad_norm": 0.09363072365522385,
      "learning_rate": 1.1558153426060244e-05,
      "loss": 0.0024,
      "step": 90100
    },
    {
      "epoch": 7.689222629917229,
      "grad_norm": 0.054110944271087646,
      "learning_rate": 1.1553886850413859e-05,
      "loss": 0.0014,
      "step": 90110
    },
    {
      "epoch": 7.690075945046505,
      "grad_norm": 0.030660288408398628,
      "learning_rate": 1.1549620274767473e-05,
      "loss": 0.0017,
      "step": 90120
    },
    {
      "epoch": 7.690929260175783,
      "grad_norm": 0.26691192388534546,
      "learning_rate": 1.1545353699121087e-05,
      "loss": 0.0022,
      "step": 90130
    },
    {
      "epoch": 7.69178257530506,
      "grad_norm": 0.11418896168470383,
      "learning_rate": 1.15410871234747e-05,
      "loss": 0.0017,
      "step": 90140
    },
    {
      "epoch": 7.692635890434337,
      "grad_norm": 0.07565093040466309,
      "learning_rate": 1.1536820547828314e-05,
      "loss": 0.0018,
      "step": 90150
    },
    {
      "epoch": 7.693489205563615,
      "grad_norm": 0.06758807599544525,
      "learning_rate": 1.1532553972181926e-05,
      "loss": 0.0018,
      "step": 90160
    },
    {
      "epoch": 7.694342520692892,
      "grad_norm": 0.11707047373056412,
      "learning_rate": 1.152828739653554e-05,
      "loss": 0.0017,
      "step": 90170
    },
    {
      "epoch": 7.695195835822169,
      "grad_norm": 0.34158357977867126,
      "learning_rate": 1.1524020820889155e-05,
      "loss": 0.0018,
      "step": 90180
    },
    {
      "epoch": 7.696049150951446,
      "grad_norm": 0.32963037490844727,
      "learning_rate": 1.1519754245242769e-05,
      "loss": 0.0015,
      "step": 90190
    },
    {
      "epoch": 7.696902466080724,
      "grad_norm": 0.21993392705917358,
      "learning_rate": 1.1515487669596382e-05,
      "loss": 0.0018,
      "step": 90200
    },
    {
      "epoch": 7.697755781210001,
      "grad_norm": 0.03024853579699993,
      "learning_rate": 1.1511221093949996e-05,
      "loss": 0.0021,
      "step": 90210
    },
    {
      "epoch": 7.698609096339278,
      "grad_norm": 0.27592363953590393,
      "learning_rate": 1.150695451830361e-05,
      "loss": 0.0015,
      "step": 90220
    },
    {
      "epoch": 7.699462411468556,
      "grad_norm": 0.09389863908290863,
      "learning_rate": 1.1502687942657224e-05,
      "loss": 0.0016,
      "step": 90230
    },
    {
      "epoch": 7.700315726597832,
      "grad_norm": 0.11035402119159698,
      "learning_rate": 1.1498421367010839e-05,
      "loss": 0.0017,
      "step": 90240
    },
    {
      "epoch": 7.70116904172711,
      "grad_norm": 0.15724608302116394,
      "learning_rate": 1.1494154791364451e-05,
      "loss": 0.0019,
      "step": 90250
    },
    {
      "epoch": 7.7020223568563875,
      "grad_norm": 0.09585733711719513,
      "learning_rate": 1.1489888215718065e-05,
      "loss": 0.0021,
      "step": 90260
    },
    {
      "epoch": 7.702875671985664,
      "grad_norm": 0.23847696185112,
      "learning_rate": 1.148562164007168e-05,
      "loss": 0.0016,
      "step": 90270
    },
    {
      "epoch": 7.703728987114942,
      "grad_norm": 0.09543503820896149,
      "learning_rate": 1.1481355064425294e-05,
      "loss": 0.0015,
      "step": 90280
    },
    {
      "epoch": 7.704582302244219,
      "grad_norm": 0.2533778250217438,
      "learning_rate": 1.1477088488778906e-05,
      "loss": 0.0014,
      "step": 90290
    },
    {
      "epoch": 7.705435617373496,
      "grad_norm": 0.23766225576400757,
      "learning_rate": 1.147282191313252e-05,
      "loss": 0.0016,
      "step": 90300
    },
    {
      "epoch": 7.7062889325027735,
      "grad_norm": 0.3162797689437866,
      "learning_rate": 1.1468555337486133e-05,
      "loss": 0.0017,
      "step": 90310
    },
    {
      "epoch": 7.70714224763205,
      "grad_norm": 0.18339546024799347,
      "learning_rate": 1.1464288761839747e-05,
      "loss": 0.0015,
      "step": 90320
    },
    {
      "epoch": 7.707995562761328,
      "grad_norm": 0.044446010142564774,
      "learning_rate": 1.1460022186193362e-05,
      "loss": 0.002,
      "step": 90330
    },
    {
      "epoch": 7.708848877890605,
      "grad_norm": 0.12946158647537231,
      "learning_rate": 1.1455755610546976e-05,
      "loss": 0.0016,
      "step": 90340
    },
    {
      "epoch": 7.709702193019882,
      "grad_norm": 0.2752034366130829,
      "learning_rate": 1.1451489034900589e-05,
      "loss": 0.0016,
      "step": 90350
    },
    {
      "epoch": 7.7105555081491595,
      "grad_norm": 0.14644642174243927,
      "learning_rate": 1.1447222459254203e-05,
      "loss": 0.0019,
      "step": 90360
    },
    {
      "epoch": 7.711408823278437,
      "grad_norm": 0.42687445878982544,
      "learning_rate": 1.1442955883607817e-05,
      "loss": 0.0016,
      "step": 90370
    },
    {
      "epoch": 7.712262138407714,
      "grad_norm": 0.15065650641918182,
      "learning_rate": 1.1438689307961431e-05,
      "loss": 0.0017,
      "step": 90380
    },
    {
      "epoch": 7.713115453536991,
      "grad_norm": 0.21617674827575684,
      "learning_rate": 1.1434422732315045e-05,
      "loss": 0.0013,
      "step": 90390
    },
    {
      "epoch": 7.713968768666269,
      "grad_norm": 0.19508911669254303,
      "learning_rate": 1.1430156156668658e-05,
      "loss": 0.0018,
      "step": 90400
    },
    {
      "epoch": 7.7148220837955455,
      "grad_norm": 0.0650390088558197,
      "learning_rate": 1.1425889581022272e-05,
      "loss": 0.0015,
      "step": 90410
    },
    {
      "epoch": 7.715675398924823,
      "grad_norm": 0.060000065714120865,
      "learning_rate": 1.1421623005375885e-05,
      "loss": 0.0016,
      "step": 90420
    },
    {
      "epoch": 7.7165287140541,
      "grad_norm": 0.0935778021812439,
      "learning_rate": 1.1417356429729499e-05,
      "loss": 0.002,
      "step": 90430
    },
    {
      "epoch": 7.717382029183377,
      "grad_norm": 0.05759507417678833,
      "learning_rate": 1.1413089854083113e-05,
      "loss": 0.0017,
      "step": 90440
    },
    {
      "epoch": 7.718235344312655,
      "grad_norm": 0.14847451448440552,
      "learning_rate": 1.1408823278436728e-05,
      "loss": 0.0016,
      "step": 90450
    },
    {
      "epoch": 7.7190886594419315,
      "grad_norm": 0.07767394930124283,
      "learning_rate": 1.140455670279034e-05,
      "loss": 0.0018,
      "step": 90460
    },
    {
      "epoch": 7.719941974571209,
      "grad_norm": 0.11947911232709885,
      "learning_rate": 1.1400290127143954e-05,
      "loss": 0.0021,
      "step": 90470
    },
    {
      "epoch": 7.720795289700487,
      "grad_norm": 0.14758405089378357,
      "learning_rate": 1.1396023551497569e-05,
      "loss": 0.0019,
      "step": 90480
    },
    {
      "epoch": 7.721648604829763,
      "grad_norm": 0.11365707218647003,
      "learning_rate": 1.1391756975851183e-05,
      "loss": 0.0014,
      "step": 90490
    },
    {
      "epoch": 7.722501919959041,
      "grad_norm": 0.11177612096071243,
      "learning_rate": 1.1387490400204797e-05,
      "loss": 0.0018,
      "step": 90500
    },
    {
      "epoch": 7.723355235088318,
      "grad_norm": 0.21943818032741547,
      "learning_rate": 1.138322382455841e-05,
      "loss": 0.0015,
      "step": 90510
    },
    {
      "epoch": 7.724208550217595,
      "grad_norm": 0.2009107917547226,
      "learning_rate": 1.1378957248912024e-05,
      "loss": 0.0015,
      "step": 90520
    },
    {
      "epoch": 7.725061865346873,
      "grad_norm": 0.2109895944595337,
      "learning_rate": 1.1374690673265638e-05,
      "loss": 0.0015,
      "step": 90530
    },
    {
      "epoch": 7.72591518047615,
      "grad_norm": 0.15308865904808044,
      "learning_rate": 1.1370424097619252e-05,
      "loss": 0.002,
      "step": 90540
    },
    {
      "epoch": 7.726768495605427,
      "grad_norm": 0.036808114498853683,
      "learning_rate": 1.1366157521972865e-05,
      "loss": 0.002,
      "step": 90550
    },
    {
      "epoch": 7.727621810734704,
      "grad_norm": 0.25671857595443726,
      "learning_rate": 1.1361890946326479e-05,
      "loss": 0.0019,
      "step": 90560
    },
    {
      "epoch": 7.728475125863982,
      "grad_norm": 0.07536118477582932,
      "learning_rate": 1.1357624370680092e-05,
      "loss": 0.0017,
      "step": 90570
    },
    {
      "epoch": 7.7293284409932586,
      "grad_norm": 0.09464656561613083,
      "learning_rate": 1.1353357795033706e-05,
      "loss": 0.0019,
      "step": 90580
    },
    {
      "epoch": 7.730181756122536,
      "grad_norm": 0.14830879867076874,
      "learning_rate": 1.134909121938732e-05,
      "loss": 0.0015,
      "step": 90590
    },
    {
      "epoch": 7.731035071251814,
      "grad_norm": 0.1173533946275711,
      "learning_rate": 1.1344824643740934e-05,
      "loss": 0.0018,
      "step": 90600
    },
    {
      "epoch": 7.73188838638109,
      "grad_norm": 0.09414560347795486,
      "learning_rate": 1.1340558068094549e-05,
      "loss": 0.0017,
      "step": 90610
    },
    {
      "epoch": 7.732741701510368,
      "grad_norm": 0.13264156877994537,
      "learning_rate": 1.1336291492448161e-05,
      "loss": 0.0019,
      "step": 90620
    },
    {
      "epoch": 7.733595016639645,
      "grad_norm": 0.051731009036302567,
      "learning_rate": 1.1332024916801775e-05,
      "loss": 0.0018,
      "step": 90630
    },
    {
      "epoch": 7.734448331768922,
      "grad_norm": 0.1198117807507515,
      "learning_rate": 1.132775834115539e-05,
      "loss": 0.0021,
      "step": 90640
    },
    {
      "epoch": 7.7353016468982,
      "grad_norm": 0.09524612873792648,
      "learning_rate": 1.1323491765509004e-05,
      "loss": 0.0014,
      "step": 90650
    },
    {
      "epoch": 7.736154962027477,
      "grad_norm": 0.07753053307533264,
      "learning_rate": 1.1319225189862616e-05,
      "loss": 0.0018,
      "step": 90660
    },
    {
      "epoch": 7.737008277156754,
      "grad_norm": 0.15140576660633087,
      "learning_rate": 1.131495861421623e-05,
      "loss": 0.0021,
      "step": 90670
    },
    {
      "epoch": 7.737861592286031,
      "grad_norm": 0.03593653067946434,
      "learning_rate": 1.1310692038569845e-05,
      "loss": 0.0021,
      "step": 90680
    },
    {
      "epoch": 7.738714907415308,
      "grad_norm": 0.25456249713897705,
      "learning_rate": 1.1306425462923457e-05,
      "loss": 0.0016,
      "step": 90690
    },
    {
      "epoch": 7.739568222544586,
      "grad_norm": 0.20769593119621277,
      "learning_rate": 1.1302158887277072e-05,
      "loss": 0.0018,
      "step": 90700
    },
    {
      "epoch": 7.740421537673863,
      "grad_norm": 0.24437712132930756,
      "learning_rate": 1.1297892311630686e-05,
      "loss": 0.0014,
      "step": 90710
    },
    {
      "epoch": 7.74127485280314,
      "grad_norm": 0.19740332663059235,
      "learning_rate": 1.1293625735984298e-05,
      "loss": 0.0016,
      "step": 90720
    },
    {
      "epoch": 7.742128167932417,
      "grad_norm": 0.0361793152987957,
      "learning_rate": 1.1289359160337913e-05,
      "loss": 0.0017,
      "step": 90730
    },
    {
      "epoch": 7.742981483061695,
      "grad_norm": 0.28919416666030884,
      "learning_rate": 1.1285092584691527e-05,
      "loss": 0.002,
      "step": 90740
    },
    {
      "epoch": 7.743834798190972,
      "grad_norm": 0.25834763050079346,
      "learning_rate": 1.1280826009045141e-05,
      "loss": 0.0018,
      "step": 90750
    },
    {
      "epoch": 7.744688113320249,
      "grad_norm": 0.09785651415586472,
      "learning_rate": 1.1276559433398755e-05,
      "loss": 0.0013,
      "step": 90760
    },
    {
      "epoch": 7.745541428449527,
      "grad_norm": 0.18335923552513123,
      "learning_rate": 1.1272292857752368e-05,
      "loss": 0.0016,
      "step": 90770
    },
    {
      "epoch": 7.746394743578803,
      "grad_norm": 0.21795830130577087,
      "learning_rate": 1.1268026282105982e-05,
      "loss": 0.0017,
      "step": 90780
    },
    {
      "epoch": 7.747248058708081,
      "grad_norm": 0.14940248429775238,
      "learning_rate": 1.1263759706459596e-05,
      "loss": 0.0016,
      "step": 90790
    },
    {
      "epoch": 7.748101373837358,
      "grad_norm": 0.12945035099983215,
      "learning_rate": 1.125949313081321e-05,
      "loss": 0.0025,
      "step": 90800
    },
    {
      "epoch": 7.748954688966635,
      "grad_norm": 0.05345013737678528,
      "learning_rate": 1.1255226555166825e-05,
      "loss": 0.0021,
      "step": 90810
    },
    {
      "epoch": 7.749808004095913,
      "grad_norm": 0.11028826981782913,
      "learning_rate": 1.1250959979520438e-05,
      "loss": 0.0015,
      "step": 90820
    },
    {
      "epoch": 7.750661319225189,
      "grad_norm": 0.04236823692917824,
      "learning_rate": 1.124669340387405e-05,
      "loss": 0.0015,
      "step": 90830
    },
    {
      "epoch": 7.751514634354467,
      "grad_norm": 0.1790049523115158,
      "learning_rate": 1.1242426828227664e-05,
      "loss": 0.0017,
      "step": 90840
    },
    {
      "epoch": 7.7523679494837445,
      "grad_norm": 0.3277803361415863,
      "learning_rate": 1.1238160252581279e-05,
      "loss": 0.0016,
      "step": 90850
    },
    {
      "epoch": 7.753221264613021,
      "grad_norm": 0.08304405212402344,
      "learning_rate": 1.1233893676934893e-05,
      "loss": 0.0018,
      "step": 90860
    },
    {
      "epoch": 7.754074579742299,
      "grad_norm": 0.2395811825990677,
      "learning_rate": 1.1229627101288507e-05,
      "loss": 0.0016,
      "step": 90870
    },
    {
      "epoch": 7.754927894871576,
      "grad_norm": 0.2792217433452606,
      "learning_rate": 1.122536052564212e-05,
      "loss": 0.0017,
      "step": 90880
    },
    {
      "epoch": 7.755781210000853,
      "grad_norm": 0.20409992337226868,
      "learning_rate": 1.1221093949995734e-05,
      "loss": 0.0019,
      "step": 90890
    },
    {
      "epoch": 7.7566345251301305,
      "grad_norm": 0.14646771550178528,
      "learning_rate": 1.1216827374349348e-05,
      "loss": 0.0015,
      "step": 90900
    },
    {
      "epoch": 7.757487840259408,
      "grad_norm": 0.19895963370800018,
      "learning_rate": 1.1212560798702962e-05,
      "loss": 0.0014,
      "step": 90910
    },
    {
      "epoch": 7.758341155388685,
      "grad_norm": 0.026206817477941513,
      "learning_rate": 1.1208294223056577e-05,
      "loss": 0.0016,
      "step": 90920
    },
    {
      "epoch": 7.759194470517962,
      "grad_norm": 0.237052783370018,
      "learning_rate": 1.1204027647410189e-05,
      "loss": 0.0015,
      "step": 90930
    },
    {
      "epoch": 7.76004778564724,
      "grad_norm": 0.09189140051603317,
      "learning_rate": 1.1199761071763803e-05,
      "loss": 0.0019,
      "step": 90940
    },
    {
      "epoch": 7.7609011007765165,
      "grad_norm": 0.07574218511581421,
      "learning_rate": 1.1195494496117416e-05,
      "loss": 0.0016,
      "step": 90950
    },
    {
      "epoch": 7.761754415905794,
      "grad_norm": 0.28041619062423706,
      "learning_rate": 1.119122792047103e-05,
      "loss": 0.0018,
      "step": 90960
    },
    {
      "epoch": 7.762607731035072,
      "grad_norm": 0.10628898441791534,
      "learning_rate": 1.1186961344824644e-05,
      "loss": 0.0017,
      "step": 90970
    },
    {
      "epoch": 7.763461046164348,
      "grad_norm": 0.23679380118846893,
      "learning_rate": 1.1182694769178257e-05,
      "loss": 0.0024,
      "step": 90980
    },
    {
      "epoch": 7.764314361293626,
      "grad_norm": 0.10074538737535477,
      "learning_rate": 1.1178428193531871e-05,
      "loss": 0.0015,
      "step": 90990
    },
    {
      "epoch": 7.765167676422903,
      "grad_norm": 0.07959356158971786,
      "learning_rate": 1.1174161617885485e-05,
      "loss": 0.0016,
      "step": 91000
    },
    {
      "epoch": 7.76602099155218,
      "grad_norm": 0.2788715362548828,
      "learning_rate": 1.11698950422391e-05,
      "loss": 0.0016,
      "step": 91010
    },
    {
      "epoch": 7.766874306681458,
      "grad_norm": 0.16407525539398193,
      "learning_rate": 1.1165628466592714e-05,
      "loss": 0.0018,
      "step": 91020
    },
    {
      "epoch": 7.767727621810735,
      "grad_norm": 0.05819053202867508,
      "learning_rate": 1.1161361890946326e-05,
      "loss": 0.0018,
      "step": 91030
    },
    {
      "epoch": 7.768580936940012,
      "grad_norm": 0.17659850418567657,
      "learning_rate": 1.115709531529994e-05,
      "loss": 0.0019,
      "step": 91040
    },
    {
      "epoch": 7.769434252069289,
      "grad_norm": 0.16692541539669037,
      "learning_rate": 1.1152828739653555e-05,
      "loss": 0.0021,
      "step": 91050
    },
    {
      "epoch": 7.770287567198566,
      "grad_norm": 0.10833258926868439,
      "learning_rate": 1.1148562164007169e-05,
      "loss": 0.0016,
      "step": 91060
    },
    {
      "epoch": 7.771140882327844,
      "grad_norm": 0.054269496351480484,
      "learning_rate": 1.1144295588360783e-05,
      "loss": 0.0015,
      "step": 91070
    },
    {
      "epoch": 7.771994197457121,
      "grad_norm": 0.21796242892742157,
      "learning_rate": 1.1140029012714396e-05,
      "loss": 0.0021,
      "step": 91080
    },
    {
      "epoch": 7.772847512586398,
      "grad_norm": 0.36663052439689636,
      "learning_rate": 1.1135762437068008e-05,
      "loss": 0.0017,
      "step": 91090
    },
    {
      "epoch": 7.773700827715675,
      "grad_norm": 0.057779520750045776,
      "learning_rate": 1.1131495861421623e-05,
      "loss": 0.0014,
      "step": 91100
    },
    {
      "epoch": 7.774554142844953,
      "grad_norm": 0.19821886718273163,
      "learning_rate": 1.1127229285775237e-05,
      "loss": 0.0021,
      "step": 91110
    },
    {
      "epoch": 7.77540745797423,
      "grad_norm": 0.15053671598434448,
      "learning_rate": 1.1122962710128851e-05,
      "loss": 0.002,
      "step": 91120
    },
    {
      "epoch": 7.776260773103507,
      "grad_norm": 0.05245776101946831,
      "learning_rate": 1.1118696134482465e-05,
      "loss": 0.0014,
      "step": 91130
    },
    {
      "epoch": 7.777114088232785,
      "grad_norm": 0.06071697175502777,
      "learning_rate": 1.1114429558836078e-05,
      "loss": 0.0019,
      "step": 91140
    },
    {
      "epoch": 7.777967403362061,
      "grad_norm": 0.11335097253322601,
      "learning_rate": 1.1110162983189692e-05,
      "loss": 0.0017,
      "step": 91150
    },
    {
      "epoch": 7.778820718491339,
      "grad_norm": 0.19770139455795288,
      "learning_rate": 1.1105896407543306e-05,
      "loss": 0.0016,
      "step": 91160
    },
    {
      "epoch": 7.779674033620616,
      "grad_norm": 0.3066108226776123,
      "learning_rate": 1.110162983189692e-05,
      "loss": 0.002,
      "step": 91170
    },
    {
      "epoch": 7.780527348749893,
      "grad_norm": 0.0628170296549797,
      "learning_rate": 1.1097363256250535e-05,
      "loss": 0.002,
      "step": 91180
    },
    {
      "epoch": 7.781380663879171,
      "grad_norm": 0.23463737964630127,
      "learning_rate": 1.1093096680604147e-05,
      "loss": 0.0016,
      "step": 91190
    },
    {
      "epoch": 7.782233979008447,
      "grad_norm": 0.11990595608949661,
      "learning_rate": 1.1088830104957762e-05,
      "loss": 0.0016,
      "step": 91200
    },
    {
      "epoch": 7.783087294137725,
      "grad_norm": 0.2366855889558792,
      "learning_rate": 1.1084563529311376e-05,
      "loss": 0.0022,
      "step": 91210
    },
    {
      "epoch": 7.7839406092670025,
      "grad_norm": 0.21761837601661682,
      "learning_rate": 1.1080296953664989e-05,
      "loss": 0.0015,
      "step": 91220
    },
    {
      "epoch": 7.784793924396279,
      "grad_norm": 0.17237870395183563,
      "learning_rate": 1.1076030378018603e-05,
      "loss": 0.0014,
      "step": 91230
    },
    {
      "epoch": 7.785647239525557,
      "grad_norm": 0.2400411069393158,
      "learning_rate": 1.1071763802372217e-05,
      "loss": 0.0015,
      "step": 91240
    },
    {
      "epoch": 7.786500554654834,
      "grad_norm": 0.09554950892925262,
      "learning_rate": 1.106749722672583e-05,
      "loss": 0.0019,
      "step": 91250
    },
    {
      "epoch": 7.787353869784111,
      "grad_norm": 0.16610080003738403,
      "learning_rate": 1.1063230651079444e-05,
      "loss": 0.0018,
      "step": 91260
    },
    {
      "epoch": 7.7882071849133885,
      "grad_norm": 0.04227973148226738,
      "learning_rate": 1.1058964075433058e-05,
      "loss": 0.0013,
      "step": 91270
    },
    {
      "epoch": 7.789060500042666,
      "grad_norm": 0.2190069854259491,
      "learning_rate": 1.1054697499786672e-05,
      "loss": 0.0019,
      "step": 91280
    },
    {
      "epoch": 7.789913815171943,
      "grad_norm": 0.06254921853542328,
      "learning_rate": 1.1050430924140285e-05,
      "loss": 0.0017,
      "step": 91290
    },
    {
      "epoch": 7.79076713030122,
      "grad_norm": 0.06350762397050858,
      "learning_rate": 1.1046164348493899e-05,
      "loss": 0.0019,
      "step": 91300
    },
    {
      "epoch": 7.791620445430498,
      "grad_norm": 0.19499364495277405,
      "learning_rate": 1.1041897772847513e-05,
      "loss": 0.0019,
      "step": 91310
    },
    {
      "epoch": 7.7924737605597745,
      "grad_norm": 0.09834796190261841,
      "learning_rate": 1.1037631197201128e-05,
      "loss": 0.0014,
      "step": 91320
    },
    {
      "epoch": 7.793327075689052,
      "grad_norm": 0.06236080452799797,
      "learning_rate": 1.1033364621554742e-05,
      "loss": 0.0015,
      "step": 91330
    },
    {
      "epoch": 7.79418039081833,
      "grad_norm": 0.07485080510377884,
      "learning_rate": 1.1029098045908354e-05,
      "loss": 0.0022,
      "step": 91340
    },
    {
      "epoch": 7.795033705947606,
      "grad_norm": 0.09822850674390793,
      "learning_rate": 1.1024831470261967e-05,
      "loss": 0.0016,
      "step": 91350
    },
    {
      "epoch": 7.795887021076884,
      "grad_norm": 0.23771393299102783,
      "learning_rate": 1.1020564894615581e-05,
      "loss": 0.0016,
      "step": 91360
    },
    {
      "epoch": 7.796740336206161,
      "grad_norm": 0.050777826458215714,
      "learning_rate": 1.1016298318969195e-05,
      "loss": 0.0017,
      "step": 91370
    },
    {
      "epoch": 7.797593651335438,
      "grad_norm": 0.23584116995334625,
      "learning_rate": 1.101203174332281e-05,
      "loss": 0.0017,
      "step": 91380
    },
    {
      "epoch": 7.798446966464716,
      "grad_norm": 0.14710496366024017,
      "learning_rate": 1.1007765167676424e-05,
      "loss": 0.0015,
      "step": 91390
    },
    {
      "epoch": 7.799300281593993,
      "grad_norm": 0.03277267888188362,
      "learning_rate": 1.1003498592030036e-05,
      "loss": 0.0018,
      "step": 91400
    },
    {
      "epoch": 7.80015359672327,
      "grad_norm": 0.18048670887947083,
      "learning_rate": 1.099923201638365e-05,
      "loss": 0.0017,
      "step": 91410
    },
    {
      "epoch": 7.801006911852547,
      "grad_norm": 0.4348990321159363,
      "learning_rate": 1.0994965440737265e-05,
      "loss": 0.0019,
      "step": 91420
    },
    {
      "epoch": 7.801860226981824,
      "grad_norm": 0.064689040184021,
      "learning_rate": 1.0990698865090879e-05,
      "loss": 0.002,
      "step": 91430
    },
    {
      "epoch": 7.802713542111102,
      "grad_norm": 0.042734865099191666,
      "learning_rate": 1.0986432289444493e-05,
      "loss": 0.002,
      "step": 91440
    },
    {
      "epoch": 7.803566857240379,
      "grad_norm": 0.12880763411521912,
      "learning_rate": 1.0982165713798106e-05,
      "loss": 0.0018,
      "step": 91450
    },
    {
      "epoch": 7.804420172369656,
      "grad_norm": 0.16812370717525482,
      "learning_rate": 1.097789913815172e-05,
      "loss": 0.0018,
      "step": 91460
    },
    {
      "epoch": 7.805273487498933,
      "grad_norm": 0.17782744765281677,
      "learning_rate": 1.0973632562505334e-05,
      "loss": 0.0016,
      "step": 91470
    },
    {
      "epoch": 7.806126802628211,
      "grad_norm": 0.04291601851582527,
      "learning_rate": 1.0969365986858947e-05,
      "loss": 0.002,
      "step": 91480
    },
    {
      "epoch": 7.806980117757488,
      "grad_norm": 0.13033883273601532,
      "learning_rate": 1.0965099411212561e-05,
      "loss": 0.0016,
      "step": 91490
    },
    {
      "epoch": 7.807833432886765,
      "grad_norm": 0.03558071330189705,
      "learning_rate": 1.0960832835566175e-05,
      "loss": 0.0018,
      "step": 91500
    },
    {
      "epoch": 7.808686748016043,
      "grad_norm": 0.1834372580051422,
      "learning_rate": 1.0956566259919788e-05,
      "loss": 0.0017,
      "step": 91510
    },
    {
      "epoch": 7.809540063145319,
      "grad_norm": 0.07076947391033173,
      "learning_rate": 1.0952299684273402e-05,
      "loss": 0.0016,
      "step": 91520
    },
    {
      "epoch": 7.810393378274597,
      "grad_norm": 0.20318980515003204,
      "learning_rate": 1.0948033108627016e-05,
      "loss": 0.0017,
      "step": 91530
    },
    {
      "epoch": 7.811246693403874,
      "grad_norm": 0.029187744483351707,
      "learning_rate": 1.094376653298063e-05,
      "loss": 0.0015,
      "step": 91540
    },
    {
      "epoch": 7.812100008533151,
      "grad_norm": 0.20268064737319946,
      "learning_rate": 1.0939499957334245e-05,
      "loss": 0.0016,
      "step": 91550
    },
    {
      "epoch": 7.812953323662429,
      "grad_norm": 0.1627586930990219,
      "learning_rate": 1.0935233381687857e-05,
      "loss": 0.0016,
      "step": 91560
    },
    {
      "epoch": 7.813806638791705,
      "grad_norm": 0.1555551439523697,
      "learning_rate": 1.0930966806041472e-05,
      "loss": 0.0018,
      "step": 91570
    },
    {
      "epoch": 7.814659953920983,
      "grad_norm": 0.1477065533399582,
      "learning_rate": 1.0926700230395086e-05,
      "loss": 0.0016,
      "step": 91580
    },
    {
      "epoch": 7.8155132690502604,
      "grad_norm": 0.09536643326282501,
      "learning_rate": 1.09224336547487e-05,
      "loss": 0.0018,
      "step": 91590
    },
    {
      "epoch": 7.816366584179537,
      "grad_norm": 0.0771244540810585,
      "learning_rate": 1.0918167079102313e-05,
      "loss": 0.0015,
      "step": 91600
    },
    {
      "epoch": 7.817219899308815,
      "grad_norm": 0.13176152110099792,
      "learning_rate": 1.0913900503455927e-05,
      "loss": 0.0017,
      "step": 91610
    },
    {
      "epoch": 7.818073214438092,
      "grad_norm": 0.31951481103897095,
      "learning_rate": 1.090963392780954e-05,
      "loss": 0.0017,
      "step": 91620
    },
    {
      "epoch": 7.818926529567369,
      "grad_norm": 0.06561069190502167,
      "learning_rate": 1.0905367352163154e-05,
      "loss": 0.0013,
      "step": 91630
    },
    {
      "epoch": 7.819779844696646,
      "grad_norm": 0.11549384146928787,
      "learning_rate": 1.0901100776516768e-05,
      "loss": 0.002,
      "step": 91640
    },
    {
      "epoch": 7.820633159825924,
      "grad_norm": 0.14950595796108246,
      "learning_rate": 1.0896834200870382e-05,
      "loss": 0.002,
      "step": 91650
    },
    {
      "epoch": 7.821486474955201,
      "grad_norm": 0.027444172650575638,
      "learning_rate": 1.0892567625223995e-05,
      "loss": 0.002,
      "step": 91660
    },
    {
      "epoch": 7.822339790084478,
      "grad_norm": 0.03050057962536812,
      "learning_rate": 1.0888301049577609e-05,
      "loss": 0.0018,
      "step": 91670
    },
    {
      "epoch": 7.823193105213756,
      "grad_norm": 0.07573744654655457,
      "learning_rate": 1.0884034473931223e-05,
      "loss": 0.0018,
      "step": 91680
    },
    {
      "epoch": 7.824046420343032,
      "grad_norm": 0.056364670395851135,
      "learning_rate": 1.0879767898284838e-05,
      "loss": 0.0017,
      "step": 91690
    },
    {
      "epoch": 7.82489973547231,
      "grad_norm": 0.12997275590896606,
      "learning_rate": 1.0875501322638452e-05,
      "loss": 0.0017,
      "step": 91700
    },
    {
      "epoch": 7.8257530506015875,
      "grad_norm": 0.02852756157517433,
      "learning_rate": 1.0871234746992064e-05,
      "loss": 0.0014,
      "step": 91710
    },
    {
      "epoch": 7.826606365730864,
      "grad_norm": 0.04254739359021187,
      "learning_rate": 1.0866968171345679e-05,
      "loss": 0.0019,
      "step": 91720
    },
    {
      "epoch": 7.827459680860142,
      "grad_norm": 0.4364711344242096,
      "learning_rate": 1.0862701595699293e-05,
      "loss": 0.0017,
      "step": 91730
    },
    {
      "epoch": 7.828312995989419,
      "grad_norm": 0.2734583020210266,
      "learning_rate": 1.0858435020052907e-05,
      "loss": 0.0017,
      "step": 91740
    },
    {
      "epoch": 7.829166311118696,
      "grad_norm": 0.03879786655306816,
      "learning_rate": 1.085416844440652e-05,
      "loss": 0.0016,
      "step": 91750
    },
    {
      "epoch": 7.8300196262479735,
      "grad_norm": 0.16411639750003815,
      "learning_rate": 1.0849901868760134e-05,
      "loss": 0.0022,
      "step": 91760
    },
    {
      "epoch": 7.830872941377251,
      "grad_norm": 0.28561219573020935,
      "learning_rate": 1.0845635293113746e-05,
      "loss": 0.0018,
      "step": 91770
    },
    {
      "epoch": 7.831726256506528,
      "grad_norm": 0.13277778029441833,
      "learning_rate": 1.084136871746736e-05,
      "loss": 0.002,
      "step": 91780
    },
    {
      "epoch": 7.832579571635805,
      "grad_norm": 0.05002395063638687,
      "learning_rate": 1.0837102141820975e-05,
      "loss": 0.0014,
      "step": 91790
    },
    {
      "epoch": 7.833432886765082,
      "grad_norm": 0.2528582215309143,
      "learning_rate": 1.0832835566174589e-05,
      "loss": 0.0017,
      "step": 91800
    },
    {
      "epoch": 7.8342862018943595,
      "grad_norm": 0.24700087308883667,
      "learning_rate": 1.0828568990528203e-05,
      "loss": 0.0021,
      "step": 91810
    },
    {
      "epoch": 7.835139517023637,
      "grad_norm": 0.3631921410560608,
      "learning_rate": 1.0824302414881816e-05,
      "loss": 0.0017,
      "step": 91820
    },
    {
      "epoch": 7.835992832152914,
      "grad_norm": 0.04225742071866989,
      "learning_rate": 1.082003583923543e-05,
      "loss": 0.0016,
      "step": 91830
    },
    {
      "epoch": 7.836846147282191,
      "grad_norm": 0.12835770845413208,
      "learning_rate": 1.0815769263589044e-05,
      "loss": 0.0018,
      "step": 91840
    },
    {
      "epoch": 7.837699462411469,
      "grad_norm": 0.0793246254324913,
      "learning_rate": 1.0811502687942659e-05,
      "loss": 0.0016,
      "step": 91850
    },
    {
      "epoch": 7.8385527775407455,
      "grad_norm": 0.22034932672977448,
      "learning_rate": 1.0807236112296273e-05,
      "loss": 0.0018,
      "step": 91860
    },
    {
      "epoch": 7.839406092670023,
      "grad_norm": 0.0455794557929039,
      "learning_rate": 1.0802969536649885e-05,
      "loss": 0.0025,
      "step": 91870
    },
    {
      "epoch": 7.840259407799301,
      "grad_norm": 0.2346612960100174,
      "learning_rate": 1.0798702961003498e-05,
      "loss": 0.0017,
      "step": 91880
    },
    {
      "epoch": 7.841112722928577,
      "grad_norm": 0.16789278388023376,
      "learning_rate": 1.0794436385357112e-05,
      "loss": 0.002,
      "step": 91890
    },
    {
      "epoch": 7.841966038057855,
      "grad_norm": 0.05272302404046059,
      "learning_rate": 1.0790169809710726e-05,
      "loss": 0.0017,
      "step": 91900
    },
    {
      "epoch": 7.8428193531871315,
      "grad_norm": 0.2065698206424713,
      "learning_rate": 1.078590323406434e-05,
      "loss": 0.0016,
      "step": 91910
    },
    {
      "epoch": 7.843672668316409,
      "grad_norm": 0.24361780285835266,
      "learning_rate": 1.0781636658417953e-05,
      "loss": 0.0016,
      "step": 91920
    },
    {
      "epoch": 7.844525983445687,
      "grad_norm": 0.32598599791526794,
      "learning_rate": 1.0777370082771567e-05,
      "loss": 0.0013,
      "step": 91930
    },
    {
      "epoch": 7.845379298574963,
      "grad_norm": 0.16846641898155212,
      "learning_rate": 1.0773103507125182e-05,
      "loss": 0.0019,
      "step": 91940
    },
    {
      "epoch": 7.846232613704241,
      "grad_norm": 0.22545567154884338,
      "learning_rate": 1.0768836931478796e-05,
      "loss": 0.0018,
      "step": 91950
    },
    {
      "epoch": 7.847085928833518,
      "grad_norm": 0.04403245821595192,
      "learning_rate": 1.076457035583241e-05,
      "loss": 0.0017,
      "step": 91960
    },
    {
      "epoch": 7.847939243962795,
      "grad_norm": 0.4642443358898163,
      "learning_rate": 1.0760303780186023e-05,
      "loss": 0.0021,
      "step": 91970
    },
    {
      "epoch": 7.848792559092073,
      "grad_norm": 0.25248420238494873,
      "learning_rate": 1.0756037204539637e-05,
      "loss": 0.0014,
      "step": 91980
    },
    {
      "epoch": 7.84964587422135,
      "grad_norm": 0.3083028197288513,
      "learning_rate": 1.0751770628893251e-05,
      "loss": 0.0014,
      "step": 91990
    },
    {
      "epoch": 7.850499189350627,
      "grad_norm": 0.1884915679693222,
      "learning_rate": 1.0747504053246865e-05,
      "loss": 0.002,
      "step": 92000
    },
    {
      "epoch": 7.851352504479904,
      "grad_norm": 0.3987242579460144,
      "learning_rate": 1.074323747760048e-05,
      "loss": 0.0012,
      "step": 92010
    },
    {
      "epoch": 7.852205819609182,
      "grad_norm": 0.10979306697845459,
      "learning_rate": 1.0738970901954092e-05,
      "loss": 0.0017,
      "step": 92020
    },
    {
      "epoch": 7.853059134738459,
      "grad_norm": 0.29414552450180054,
      "learning_rate": 1.0734704326307705e-05,
      "loss": 0.0017,
      "step": 92030
    },
    {
      "epoch": 7.853912449867736,
      "grad_norm": 0.1586027294397354,
      "learning_rate": 1.0730437750661319e-05,
      "loss": 0.0018,
      "step": 92040
    },
    {
      "epoch": 7.854765764997014,
      "grad_norm": 0.15094836056232452,
      "learning_rate": 1.0726171175014933e-05,
      "loss": 0.0023,
      "step": 92050
    },
    {
      "epoch": 7.85561908012629,
      "grad_norm": 0.11185995489358902,
      "learning_rate": 1.0721904599368547e-05,
      "loss": 0.0018,
      "step": 92060
    },
    {
      "epoch": 7.856472395255568,
      "grad_norm": 0.14960254728794098,
      "learning_rate": 1.0717638023722162e-05,
      "loss": 0.0014,
      "step": 92070
    },
    {
      "epoch": 7.8573257103848455,
      "grad_norm": 0.43739452958106995,
      "learning_rate": 1.0713371448075774e-05,
      "loss": 0.0018,
      "step": 92080
    },
    {
      "epoch": 7.858179025514122,
      "grad_norm": 0.12232767790555954,
      "learning_rate": 1.0709104872429389e-05,
      "loss": 0.0015,
      "step": 92090
    },
    {
      "epoch": 7.8590323406434,
      "grad_norm": 0.04088011011481285,
      "learning_rate": 1.0704838296783003e-05,
      "loss": 0.0014,
      "step": 92100
    },
    {
      "epoch": 7.859885655772677,
      "grad_norm": 0.03143791854381561,
      "learning_rate": 1.0700571721136617e-05,
      "loss": 0.0019,
      "step": 92110
    },
    {
      "epoch": 7.860738970901954,
      "grad_norm": 0.07403091341257095,
      "learning_rate": 1.0696305145490231e-05,
      "loss": 0.0016,
      "step": 92120
    },
    {
      "epoch": 7.8615922860312315,
      "grad_norm": 0.12730275094509125,
      "learning_rate": 1.0692038569843844e-05,
      "loss": 0.0016,
      "step": 92130
    },
    {
      "epoch": 7.862445601160509,
      "grad_norm": 0.1844521164894104,
      "learning_rate": 1.0687771994197458e-05,
      "loss": 0.0023,
      "step": 92140
    },
    {
      "epoch": 7.863298916289786,
      "grad_norm": 0.14920295774936676,
      "learning_rate": 1.068350541855107e-05,
      "loss": 0.0017,
      "step": 92150
    },
    {
      "epoch": 7.864152231419063,
      "grad_norm": 0.13531096279621124,
      "learning_rate": 1.0679238842904685e-05,
      "loss": 0.0017,
      "step": 92160
    },
    {
      "epoch": 7.86500554654834,
      "grad_norm": 0.1671372354030609,
      "learning_rate": 1.0674972267258299e-05,
      "loss": 0.0014,
      "step": 92170
    },
    {
      "epoch": 7.8658588616776175,
      "grad_norm": 0.11089470982551575,
      "learning_rate": 1.0670705691611913e-05,
      "loss": 0.0018,
      "step": 92180
    },
    {
      "epoch": 7.866712176806895,
      "grad_norm": 0.09314722567796707,
      "learning_rate": 1.0666439115965526e-05,
      "loss": 0.0018,
      "step": 92190
    },
    {
      "epoch": 7.867565491936172,
      "grad_norm": 0.20423124730587006,
      "learning_rate": 1.066217254031914e-05,
      "loss": 0.0018,
      "step": 92200
    },
    {
      "epoch": 7.868418807065449,
      "grad_norm": 0.04230024665594101,
      "learning_rate": 1.0657905964672754e-05,
      "loss": 0.0014,
      "step": 92210
    },
    {
      "epoch": 7.869272122194727,
      "grad_norm": 0.046009551733732224,
      "learning_rate": 1.0653639389026369e-05,
      "loss": 0.0017,
      "step": 92220
    },
    {
      "epoch": 7.8701254373240035,
      "grad_norm": 0.10006129741668701,
      "learning_rate": 1.0649372813379981e-05,
      "loss": 0.0015,
      "step": 92230
    },
    {
      "epoch": 7.870978752453281,
      "grad_norm": 0.46300995349884033,
      "learning_rate": 1.0645106237733595e-05,
      "loss": 0.0012,
      "step": 92240
    },
    {
      "epoch": 7.871832067582559,
      "grad_norm": 0.041197389364242554,
      "learning_rate": 1.064083966208721e-05,
      "loss": 0.0017,
      "step": 92250
    },
    {
      "epoch": 7.872685382711835,
      "grad_norm": 0.1981656700372696,
      "learning_rate": 1.0636573086440824e-05,
      "loss": 0.0018,
      "step": 92260
    },
    {
      "epoch": 7.873538697841113,
      "grad_norm": 0.15590381622314453,
      "learning_rate": 1.0632306510794438e-05,
      "loss": 0.0018,
      "step": 92270
    },
    {
      "epoch": 7.8743920129703895,
      "grad_norm": 0.0762709230184555,
      "learning_rate": 1.062803993514805e-05,
      "loss": 0.0016,
      "step": 92280
    },
    {
      "epoch": 7.875245328099667,
      "grad_norm": 0.09689029306173325,
      "learning_rate": 1.0623773359501663e-05,
      "loss": 0.0016,
      "step": 92290
    },
    {
      "epoch": 7.876098643228945,
      "grad_norm": 0.1835300326347351,
      "learning_rate": 1.0619506783855277e-05,
      "loss": 0.0016,
      "step": 92300
    },
    {
      "epoch": 7.876951958358221,
      "grad_norm": 0.24150173366069794,
      "learning_rate": 1.0615240208208892e-05,
      "loss": 0.0013,
      "step": 92310
    },
    {
      "epoch": 7.877805273487499,
      "grad_norm": 0.19996820390224457,
      "learning_rate": 1.0610973632562506e-05,
      "loss": 0.0013,
      "step": 92320
    },
    {
      "epoch": 7.878658588616776,
      "grad_norm": 0.45678362250328064,
      "learning_rate": 1.060670705691612e-05,
      "loss": 0.0014,
      "step": 92330
    },
    {
      "epoch": 7.879511903746053,
      "grad_norm": 0.2887137532234192,
      "learning_rate": 1.0602440481269733e-05,
      "loss": 0.0019,
      "step": 92340
    },
    {
      "epoch": 7.880365218875331,
      "grad_norm": 0.14644969999790192,
      "learning_rate": 1.0598173905623347e-05,
      "loss": 0.0015,
      "step": 92350
    },
    {
      "epoch": 7.881218534004608,
      "grad_norm": 0.1774178147315979,
      "learning_rate": 1.0593907329976961e-05,
      "loss": 0.0018,
      "step": 92360
    },
    {
      "epoch": 7.882071849133885,
      "grad_norm": 0.2412155568599701,
      "learning_rate": 1.0589640754330575e-05,
      "loss": 0.0015,
      "step": 92370
    },
    {
      "epoch": 7.882925164263162,
      "grad_norm": 0.06310635805130005,
      "learning_rate": 1.058537417868419e-05,
      "loss": 0.0021,
      "step": 92380
    },
    {
      "epoch": 7.88377847939244,
      "grad_norm": 0.05978703126311302,
      "learning_rate": 1.0581107603037802e-05,
      "loss": 0.0016,
      "step": 92390
    },
    {
      "epoch": 7.884631794521717,
      "grad_norm": 0.18287864327430725,
      "learning_rate": 1.0576841027391416e-05,
      "loss": 0.0015,
      "step": 92400
    },
    {
      "epoch": 7.885485109650994,
      "grad_norm": 0.03189488500356674,
      "learning_rate": 1.057257445174503e-05,
      "loss": 0.0017,
      "step": 92410
    },
    {
      "epoch": 7.886338424780272,
      "grad_norm": 0.18148739635944366,
      "learning_rate": 1.0568307876098643e-05,
      "loss": 0.0015,
      "step": 92420
    },
    {
      "epoch": 7.887191739909548,
      "grad_norm": 0.09283152967691422,
      "learning_rate": 1.0564041300452257e-05,
      "loss": 0.0017,
      "step": 92430
    },
    {
      "epoch": 7.888045055038826,
      "grad_norm": 0.13013844192028046,
      "learning_rate": 1.0559774724805872e-05,
      "loss": 0.0017,
      "step": 92440
    },
    {
      "epoch": 7.8888983701681035,
      "grad_norm": 0.09200920909643173,
      "learning_rate": 1.0555508149159484e-05,
      "loss": 0.0019,
      "step": 92450
    },
    {
      "epoch": 7.88975168529738,
      "grad_norm": 0.12936656177043915,
      "learning_rate": 1.0551241573513098e-05,
      "loss": 0.0017,
      "step": 92460
    },
    {
      "epoch": 7.890605000426658,
      "grad_norm": 0.1833823323249817,
      "learning_rate": 1.0546974997866713e-05,
      "loss": 0.0015,
      "step": 92470
    },
    {
      "epoch": 7.891458315555935,
      "grad_norm": 0.23524674773216248,
      "learning_rate": 1.0542708422220327e-05,
      "loss": 0.0017,
      "step": 92480
    },
    {
      "epoch": 7.892311630685212,
      "grad_norm": 0.14528745412826538,
      "learning_rate": 1.0538441846573941e-05,
      "loss": 0.0018,
      "step": 92490
    },
    {
      "epoch": 7.8931649458144895,
      "grad_norm": 0.23782196640968323,
      "learning_rate": 1.0534175270927554e-05,
      "loss": 0.0017,
      "step": 92500
    },
    {
      "epoch": 7.894018260943767,
      "grad_norm": 0.2176436334848404,
      "learning_rate": 1.0529908695281168e-05,
      "loss": 0.0015,
      "step": 92510
    },
    {
      "epoch": 7.894871576073044,
      "grad_norm": 0.11130251735448837,
      "learning_rate": 1.0525642119634782e-05,
      "loss": 0.0017,
      "step": 92520
    },
    {
      "epoch": 7.895724891202321,
      "grad_norm": 0.05783114582300186,
      "learning_rate": 1.0521375543988396e-05,
      "loss": 0.0017,
      "step": 92530
    },
    {
      "epoch": 7.896578206331598,
      "grad_norm": 0.14355002343654633,
      "learning_rate": 1.051710896834201e-05,
      "loss": 0.002,
      "step": 92540
    },
    {
      "epoch": 7.8974315214608755,
      "grad_norm": 0.4358140826225281,
      "learning_rate": 1.0512842392695622e-05,
      "loss": 0.0017,
      "step": 92550
    },
    {
      "epoch": 7.898284836590153,
      "grad_norm": 0.18540287017822266,
      "learning_rate": 1.0508575817049236e-05,
      "loss": 0.0017,
      "step": 92560
    },
    {
      "epoch": 7.89913815171943,
      "grad_norm": 0.07615848630666733,
      "learning_rate": 1.050430924140285e-05,
      "loss": 0.0012,
      "step": 92570
    },
    {
      "epoch": 7.899991466848707,
      "grad_norm": 0.03701673820614815,
      "learning_rate": 1.0500042665756464e-05,
      "loss": 0.0016,
      "step": 92580
    },
    {
      "epoch": 7.900844781977985,
      "grad_norm": 0.10897822678089142,
      "learning_rate": 1.0495776090110079e-05,
      "loss": 0.0017,
      "step": 92590
    },
    {
      "epoch": 7.9016980971072615,
      "grad_norm": 0.2554861903190613,
      "learning_rate": 1.0491509514463691e-05,
      "loss": 0.0015,
      "step": 92600
    },
    {
      "epoch": 7.902551412236539,
      "grad_norm": 0.27148231863975525,
      "learning_rate": 1.0487242938817305e-05,
      "loss": 0.0012,
      "step": 92610
    },
    {
      "epoch": 7.903404727365817,
      "grad_norm": 0.18193762004375458,
      "learning_rate": 1.048297636317092e-05,
      "loss": 0.0017,
      "step": 92620
    },
    {
      "epoch": 7.904258042495093,
      "grad_norm": 0.25360897183418274,
      "learning_rate": 1.0478709787524534e-05,
      "loss": 0.0014,
      "step": 92630
    },
    {
      "epoch": 7.905111357624371,
      "grad_norm": 0.11242688447237015,
      "learning_rate": 1.0474443211878148e-05,
      "loss": 0.0018,
      "step": 92640
    },
    {
      "epoch": 7.9059646727536474,
      "grad_norm": 0.21781441569328308,
      "learning_rate": 1.047017663623176e-05,
      "loss": 0.0021,
      "step": 92650
    },
    {
      "epoch": 7.906817987882925,
      "grad_norm": 0.03117138147354126,
      "learning_rate": 1.0465910060585375e-05,
      "loss": 0.0021,
      "step": 92660
    },
    {
      "epoch": 7.907671303012203,
      "grad_norm": 0.14577002823352814,
      "learning_rate": 1.0461643484938989e-05,
      "loss": 0.0018,
      "step": 92670
    },
    {
      "epoch": 7.908524618141479,
      "grad_norm": 0.15027518570423126,
      "learning_rate": 1.0457376909292602e-05,
      "loss": 0.0016,
      "step": 92680
    },
    {
      "epoch": 7.909377933270757,
      "grad_norm": 0.16718193888664246,
      "learning_rate": 1.0453110333646216e-05,
      "loss": 0.0018,
      "step": 92690
    },
    {
      "epoch": 7.910231248400034,
      "grad_norm": 0.19356968998908997,
      "learning_rate": 1.044884375799983e-05,
      "loss": 0.0018,
      "step": 92700
    },
    {
      "epoch": 7.911084563529311,
      "grad_norm": 0.05988914892077446,
      "learning_rate": 1.0444577182353443e-05,
      "loss": 0.0018,
      "step": 92710
    },
    {
      "epoch": 7.9119378786585886,
      "grad_norm": 0.04190370440483093,
      "learning_rate": 1.0440310606707057e-05,
      "loss": 0.0017,
      "step": 92720
    },
    {
      "epoch": 7.912791193787866,
      "grad_norm": 0.13454604148864746,
      "learning_rate": 1.0436044031060671e-05,
      "loss": 0.0017,
      "step": 92730
    },
    {
      "epoch": 7.913644508917143,
      "grad_norm": 0.16732661426067352,
      "learning_rate": 1.0431777455414285e-05,
      "loss": 0.0018,
      "step": 92740
    },
    {
      "epoch": 7.91449782404642,
      "grad_norm": 0.39783963561058044,
      "learning_rate": 1.04275108797679e-05,
      "loss": 0.0014,
      "step": 92750
    },
    {
      "epoch": 7.915351139175698,
      "grad_norm": 0.15502412617206573,
      "learning_rate": 1.0423244304121512e-05,
      "loss": 0.0015,
      "step": 92760
    },
    {
      "epoch": 7.9162044543049745,
      "grad_norm": 0.18348334729671478,
      "learning_rate": 1.0418977728475126e-05,
      "loss": 0.0014,
      "step": 92770
    },
    {
      "epoch": 7.917057769434252,
      "grad_norm": 0.21227504312992096,
      "learning_rate": 1.041471115282874e-05,
      "loss": 0.0021,
      "step": 92780
    },
    {
      "epoch": 7.91791108456353,
      "grad_norm": 0.20115508139133453,
      "learning_rate": 1.0410444577182355e-05,
      "loss": 0.0023,
      "step": 92790
    },
    {
      "epoch": 7.918764399692806,
      "grad_norm": 0.2350376844406128,
      "learning_rate": 1.0406178001535969e-05,
      "loss": 0.0017,
      "step": 92800
    },
    {
      "epoch": 7.919617714822084,
      "grad_norm": 0.048841819167137146,
      "learning_rate": 1.0401911425889582e-05,
      "loss": 0.002,
      "step": 92810
    },
    {
      "epoch": 7.920471029951361,
      "grad_norm": 0.2172745168209076,
      "learning_rate": 1.0397644850243194e-05,
      "loss": 0.0016,
      "step": 92820
    },
    {
      "epoch": 7.921324345080638,
      "grad_norm": 0.08176983147859573,
      "learning_rate": 1.0393378274596808e-05,
      "loss": 0.002,
      "step": 92830
    },
    {
      "epoch": 7.922177660209916,
      "grad_norm": 0.2555466592311859,
      "learning_rate": 1.0389111698950423e-05,
      "loss": 0.0015,
      "step": 92840
    },
    {
      "epoch": 7.923030975339193,
      "grad_norm": 0.07793048024177551,
      "learning_rate": 1.0384845123304037e-05,
      "loss": 0.0016,
      "step": 92850
    },
    {
      "epoch": 7.92388429046847,
      "grad_norm": 0.09563466906547546,
      "learning_rate": 1.038057854765765e-05,
      "loss": 0.0015,
      "step": 92860
    },
    {
      "epoch": 7.924737605597747,
      "grad_norm": 0.024575699120759964,
      "learning_rate": 1.0376311972011264e-05,
      "loss": 0.0017,
      "step": 92870
    },
    {
      "epoch": 7.925590920727025,
      "grad_norm": 0.11118561774492264,
      "learning_rate": 1.0372045396364878e-05,
      "loss": 0.0015,
      "step": 92880
    },
    {
      "epoch": 7.926444235856302,
      "grad_norm": 0.03634665161371231,
      "learning_rate": 1.0367778820718492e-05,
      "loss": 0.0018,
      "step": 92890
    },
    {
      "epoch": 7.927297550985579,
      "grad_norm": 0.1635555475950241,
      "learning_rate": 1.0363512245072106e-05,
      "loss": 0.0022,
      "step": 92900
    },
    {
      "epoch": 7.928150866114856,
      "grad_norm": 0.1550927460193634,
      "learning_rate": 1.0359245669425719e-05,
      "loss": 0.0019,
      "step": 92910
    },
    {
      "epoch": 7.929004181244133,
      "grad_norm": 0.22597722709178925,
      "learning_rate": 1.0354979093779333e-05,
      "loss": 0.0016,
      "step": 92920
    },
    {
      "epoch": 7.929857496373411,
      "grad_norm": 0.029581882059574127,
      "learning_rate": 1.0350712518132947e-05,
      "loss": 0.0015,
      "step": 92930
    },
    {
      "epoch": 7.930710811502688,
      "grad_norm": 0.27125564217567444,
      "learning_rate": 1.0346445942486562e-05,
      "loss": 0.0019,
      "step": 92940
    },
    {
      "epoch": 7.931564126631965,
      "grad_norm": 0.14540262520313263,
      "learning_rate": 1.0342179366840174e-05,
      "loss": 0.0015,
      "step": 92950
    },
    {
      "epoch": 7.932417441761243,
      "grad_norm": 0.07574618607759476,
      "learning_rate": 1.0337912791193789e-05,
      "loss": 0.0015,
      "step": 92960
    },
    {
      "epoch": 7.933270756890519,
      "grad_norm": 0.030479123815894127,
      "learning_rate": 1.0333646215547401e-05,
      "loss": 0.0017,
      "step": 92970
    },
    {
      "epoch": 7.934124072019797,
      "grad_norm": 0.05833725258708,
      "learning_rate": 1.0329379639901015e-05,
      "loss": 0.0021,
      "step": 92980
    },
    {
      "epoch": 7.9349773871490745,
      "grad_norm": 0.11637196689844131,
      "learning_rate": 1.032511306425463e-05,
      "loss": 0.0017,
      "step": 92990
    },
    {
      "epoch": 7.935830702278351,
      "grad_norm": 0.12944261729717255,
      "learning_rate": 1.0320846488608244e-05,
      "loss": 0.0013,
      "step": 93000
    },
    {
      "epoch": 7.936684017407629,
      "grad_norm": 0.16270610690116882,
      "learning_rate": 1.0316579912961858e-05,
      "loss": 0.0015,
      "step": 93010
    },
    {
      "epoch": 7.937537332536905,
      "grad_norm": 0.2192116528749466,
      "learning_rate": 1.031231333731547e-05,
      "loss": 0.0016,
      "step": 93020
    },
    {
      "epoch": 7.938390647666183,
      "grad_norm": 0.16209633648395538,
      "learning_rate": 1.0308046761669085e-05,
      "loss": 0.0019,
      "step": 93030
    },
    {
      "epoch": 7.9392439627954605,
      "grad_norm": 0.1334799826145172,
      "learning_rate": 1.0303780186022699e-05,
      "loss": 0.0015,
      "step": 93040
    },
    {
      "epoch": 7.940097277924737,
      "grad_norm": 0.1333116590976715,
      "learning_rate": 1.0299513610376313e-05,
      "loss": 0.0017,
      "step": 93050
    },
    {
      "epoch": 7.940950593054015,
      "grad_norm": 0.23397473990917206,
      "learning_rate": 1.0295247034729928e-05,
      "loss": 0.0016,
      "step": 93060
    },
    {
      "epoch": 7.941803908183292,
      "grad_norm": 0.4068845510482788,
      "learning_rate": 1.029098045908354e-05,
      "loss": 0.0023,
      "step": 93070
    },
    {
      "epoch": 7.942657223312569,
      "grad_norm": 0.09663026034832001,
      "learning_rate": 1.0286713883437153e-05,
      "loss": 0.0017,
      "step": 93080
    },
    {
      "epoch": 7.9435105384418465,
      "grad_norm": 0.18418432772159576,
      "learning_rate": 1.0282447307790767e-05,
      "loss": 0.0027,
      "step": 93090
    },
    {
      "epoch": 7.944363853571124,
      "grad_norm": 0.05669195577502251,
      "learning_rate": 1.0278180732144381e-05,
      "loss": 0.002,
      "step": 93100
    },
    {
      "epoch": 7.945217168700401,
      "grad_norm": 0.11200378835201263,
      "learning_rate": 1.0273914156497995e-05,
      "loss": 0.0021,
      "step": 93110
    },
    {
      "epoch": 7.946070483829678,
      "grad_norm": 0.14446702599525452,
      "learning_rate": 1.026964758085161e-05,
      "loss": 0.002,
      "step": 93120
    },
    {
      "epoch": 7.946923798958956,
      "grad_norm": 0.12909217178821564,
      "learning_rate": 1.0265381005205222e-05,
      "loss": 0.0018,
      "step": 93130
    },
    {
      "epoch": 7.9477771140882325,
      "grad_norm": 0.2408394068479538,
      "learning_rate": 1.0261114429558836e-05,
      "loss": 0.0023,
      "step": 93140
    },
    {
      "epoch": 7.94863042921751,
      "grad_norm": 0.16870075464248657,
      "learning_rate": 1.025684785391245e-05,
      "loss": 0.0017,
      "step": 93150
    },
    {
      "epoch": 7.949483744346788,
      "grad_norm": 0.22928081452846527,
      "learning_rate": 1.0252581278266065e-05,
      "loss": 0.0016,
      "step": 93160
    },
    {
      "epoch": 7.950337059476064,
      "grad_norm": 0.10948746651411057,
      "learning_rate": 1.0248314702619677e-05,
      "loss": 0.0015,
      "step": 93170
    },
    {
      "epoch": 7.951190374605342,
      "grad_norm": 0.2379511445760727,
      "learning_rate": 1.0244048126973292e-05,
      "loss": 0.0019,
      "step": 93180
    },
    {
      "epoch": 7.952043689734619,
      "grad_norm": 0.09481168538331985,
      "learning_rate": 1.0239781551326906e-05,
      "loss": 0.0016,
      "step": 93190
    },
    {
      "epoch": 7.952897004863896,
      "grad_norm": 0.33076685667037964,
      "learning_rate": 1.023551497568052e-05,
      "loss": 0.0015,
      "step": 93200
    },
    {
      "epoch": 7.953750319993174,
      "grad_norm": 0.2088993787765503,
      "learning_rate": 1.0231248400034133e-05,
      "loss": 0.0014,
      "step": 93210
    },
    {
      "epoch": 7.954603635122451,
      "grad_norm": 0.06183912232518196,
      "learning_rate": 1.0226981824387747e-05,
      "loss": 0.0015,
      "step": 93220
    },
    {
      "epoch": 7.955456950251728,
      "grad_norm": 0.3999731242656708,
      "learning_rate": 1.022271524874136e-05,
      "loss": 0.0017,
      "step": 93230
    },
    {
      "epoch": 7.956310265381005,
      "grad_norm": 0.25417056679725647,
      "learning_rate": 1.0218448673094974e-05,
      "loss": 0.0016,
      "step": 93240
    },
    {
      "epoch": 7.957163580510283,
      "grad_norm": 0.11445841193199158,
      "learning_rate": 1.0214182097448588e-05,
      "loss": 0.0018,
      "step": 93250
    },
    {
      "epoch": 7.95801689563956,
      "grad_norm": 0.06538153439760208,
      "learning_rate": 1.0209915521802202e-05,
      "loss": 0.0015,
      "step": 93260
    },
    {
      "epoch": 7.958870210768837,
      "grad_norm": 0.07628173381090164,
      "learning_rate": 1.0205648946155816e-05,
      "loss": 0.0018,
      "step": 93270
    },
    {
      "epoch": 7.959723525898114,
      "grad_norm": 0.12070932239294052,
      "learning_rate": 1.0201382370509429e-05,
      "loss": 0.0016,
      "step": 93280
    },
    {
      "epoch": 7.960576841027391,
      "grad_norm": 0.18977974355220795,
      "learning_rate": 1.0197115794863043e-05,
      "loss": 0.002,
      "step": 93290
    },
    {
      "epoch": 7.961430156156669,
      "grad_norm": 0.045009247958660126,
      "learning_rate": 1.0192849219216657e-05,
      "loss": 0.0016,
      "step": 93300
    },
    {
      "epoch": 7.962283471285946,
      "grad_norm": 0.20012663304805756,
      "learning_rate": 1.0188582643570272e-05,
      "loss": 0.0021,
      "step": 93310
    },
    {
      "epoch": 7.963136786415223,
      "grad_norm": 0.043659500777721405,
      "learning_rate": 1.0184316067923886e-05,
      "loss": 0.0018,
      "step": 93320
    },
    {
      "epoch": 7.963990101544501,
      "grad_norm": 0.20384708046913147,
      "learning_rate": 1.0180049492277498e-05,
      "loss": 0.0021,
      "step": 93330
    },
    {
      "epoch": 7.964843416673777,
      "grad_norm": 0.08020304888486862,
      "learning_rate": 1.0175782916631113e-05,
      "loss": 0.0018,
      "step": 93340
    },
    {
      "epoch": 7.965696731803055,
      "grad_norm": 0.34184449911117554,
      "learning_rate": 1.0171516340984725e-05,
      "loss": 0.0013,
      "step": 93350
    },
    {
      "epoch": 7.9665500469323325,
      "grad_norm": 0.12865717709064484,
      "learning_rate": 1.016724976533834e-05,
      "loss": 0.0017,
      "step": 93360
    },
    {
      "epoch": 7.967403362061609,
      "grad_norm": 0.07684402167797089,
      "learning_rate": 1.0162983189691954e-05,
      "loss": 0.0017,
      "step": 93370
    },
    {
      "epoch": 7.968256677190887,
      "grad_norm": 0.2210916429758072,
      "learning_rate": 1.0158716614045568e-05,
      "loss": 0.0016,
      "step": 93380
    },
    {
      "epoch": 7.969109992320163,
      "grad_norm": 0.1643623560667038,
      "learning_rate": 1.015445003839918e-05,
      "loss": 0.0012,
      "step": 93390
    },
    {
      "epoch": 7.969963307449441,
      "grad_norm": 0.1662670373916626,
      "learning_rate": 1.0150183462752795e-05,
      "loss": 0.0016,
      "step": 93400
    },
    {
      "epoch": 7.9708166225787185,
      "grad_norm": 0.26240578293800354,
      "learning_rate": 1.0145916887106409e-05,
      "loss": 0.0018,
      "step": 93410
    },
    {
      "epoch": 7.971669937707995,
      "grad_norm": 0.15377368032932281,
      "learning_rate": 1.0141650311460023e-05,
      "loss": 0.0015,
      "step": 93420
    },
    {
      "epoch": 7.972523252837273,
      "grad_norm": 0.025578709319233894,
      "learning_rate": 1.0137383735813638e-05,
      "loss": 0.0023,
      "step": 93430
    },
    {
      "epoch": 7.97337656796655,
      "grad_norm": 0.07900568097829819,
      "learning_rate": 1.013311716016725e-05,
      "loss": 0.0016,
      "step": 93440
    },
    {
      "epoch": 7.974229883095827,
      "grad_norm": 0.09201336652040482,
      "learning_rate": 1.0128850584520864e-05,
      "loss": 0.0019,
      "step": 93450
    },
    {
      "epoch": 7.9750831982251045,
      "grad_norm": 0.24397750198841095,
      "learning_rate": 1.0124584008874479e-05,
      "loss": 0.0019,
      "step": 93460
    },
    {
      "epoch": 7.975936513354382,
      "grad_norm": 0.07387634366750717,
      "learning_rate": 1.0120317433228093e-05,
      "loss": 0.0016,
      "step": 93470
    },
    {
      "epoch": 7.976789828483659,
      "grad_norm": 0.034824781119823456,
      "learning_rate": 1.0116050857581705e-05,
      "loss": 0.0016,
      "step": 93480
    },
    {
      "epoch": 7.977643143612936,
      "grad_norm": 0.11790149658918381,
      "learning_rate": 1.0111784281935318e-05,
      "loss": 0.0015,
      "step": 93490
    },
    {
      "epoch": 7.978496458742214,
      "grad_norm": 0.13114012777805328,
      "learning_rate": 1.0107517706288932e-05,
      "loss": 0.0018,
      "step": 93500
    },
    {
      "epoch": 7.9793497738714905,
      "grad_norm": 0.09966497868299484,
      "learning_rate": 1.0103251130642546e-05,
      "loss": 0.0017,
      "step": 93510
    },
    {
      "epoch": 7.980203089000768,
      "grad_norm": 0.15144464373588562,
      "learning_rate": 1.009898455499616e-05,
      "loss": 0.0022,
      "step": 93520
    },
    {
      "epoch": 7.981056404130046,
      "grad_norm": 0.087616465985775,
      "learning_rate": 1.0094717979349775e-05,
      "loss": 0.0016,
      "step": 93530
    },
    {
      "epoch": 7.981909719259322,
      "grad_norm": 0.1913115531206131,
      "learning_rate": 1.0090451403703387e-05,
      "loss": 0.0022,
      "step": 93540
    },
    {
      "epoch": 7.9827630343886,
      "grad_norm": 0.13069500029087067,
      "learning_rate": 1.0086184828057002e-05,
      "loss": 0.0017,
      "step": 93550
    },
    {
      "epoch": 7.983616349517877,
      "grad_norm": 0.15047822892665863,
      "learning_rate": 1.0081918252410616e-05,
      "loss": 0.0014,
      "step": 93560
    },
    {
      "epoch": 7.984469664647154,
      "grad_norm": 0.14733636379241943,
      "learning_rate": 1.007765167676423e-05,
      "loss": 0.0016,
      "step": 93570
    },
    {
      "epoch": 7.985322979776432,
      "grad_norm": 0.02737138606607914,
      "learning_rate": 1.0073385101117844e-05,
      "loss": 0.0018,
      "step": 93580
    },
    {
      "epoch": 7.986176294905709,
      "grad_norm": 0.14570753276348114,
      "learning_rate": 1.0069118525471457e-05,
      "loss": 0.0018,
      "step": 93590
    },
    {
      "epoch": 7.987029610034986,
      "grad_norm": 0.04045720770955086,
      "learning_rate": 1.0064851949825071e-05,
      "loss": 0.0017,
      "step": 93600
    },
    {
      "epoch": 7.987882925164263,
      "grad_norm": 0.1443886160850525,
      "learning_rate": 1.0060585374178684e-05,
      "loss": 0.0014,
      "step": 93610
    },
    {
      "epoch": 7.988736240293541,
      "grad_norm": 0.06075474992394447,
      "learning_rate": 1.0056318798532298e-05,
      "loss": 0.0019,
      "step": 93620
    },
    {
      "epoch": 7.989589555422818,
      "grad_norm": 0.2035805583000183,
      "learning_rate": 1.0052052222885912e-05,
      "loss": 0.0016,
      "step": 93630
    },
    {
      "epoch": 7.990442870552095,
      "grad_norm": 0.49171751737594604,
      "learning_rate": 1.0047785647239526e-05,
      "loss": 0.0016,
      "step": 93640
    },
    {
      "epoch": 7.991296185681372,
      "grad_norm": 0.11151386052370071,
      "learning_rate": 1.0043519071593139e-05,
      "loss": 0.0018,
      "step": 93650
    },
    {
      "epoch": 7.992149500810649,
      "grad_norm": 0.07956311106681824,
      "learning_rate": 1.0039252495946753e-05,
      "loss": 0.002,
      "step": 93660
    },
    {
      "epoch": 7.993002815939927,
      "grad_norm": 0.12938693165779114,
      "learning_rate": 1.0034985920300367e-05,
      "loss": 0.0019,
      "step": 93670
    },
    {
      "epoch": 7.993856131069204,
      "grad_norm": 0.27587494254112244,
      "learning_rate": 1.0030719344653982e-05,
      "loss": 0.0017,
      "step": 93680
    },
    {
      "epoch": 7.994709446198481,
      "grad_norm": 0.06023424118757248,
      "learning_rate": 1.0026452769007596e-05,
      "loss": 0.0017,
      "step": 93690
    },
    {
      "epoch": 7.995562761327759,
      "grad_norm": 0.18518666923046112,
      "learning_rate": 1.0022186193361208e-05,
      "loss": 0.0015,
      "step": 93700
    },
    {
      "epoch": 7.996416076457035,
      "grad_norm": 0.031070929020643234,
      "learning_rate": 1.0017919617714823e-05,
      "loss": 0.0017,
      "step": 93710
    },
    {
      "epoch": 7.997269391586313,
      "grad_norm": 0.16195359826087952,
      "learning_rate": 1.0013653042068437e-05,
      "loss": 0.0014,
      "step": 93720
    },
    {
      "epoch": 7.9981227067155904,
      "grad_norm": 0.07487326115369797,
      "learning_rate": 1.0009386466422051e-05,
      "loss": 0.0014,
      "step": 93730
    },
    {
      "epoch": 7.998976021844867,
      "grad_norm": 0.4889175593852997,
      "learning_rate": 1.0005119890775664e-05,
      "loss": 0.0016,
      "step": 93740
    },
    {
      "epoch": 7.999829336974145,
      "grad_norm": 0.2896140515804291,
      "learning_rate": 1.0000853315129278e-05,
      "loss": 0.0016,
      "step": 93750
    },
    {
      "epoch": 8.0,
      "eval_loss": 0.0016770290676504374,
      "eval_runtime": 99.2115,
      "eval_samples_per_second": 1511.922,
      "eval_steps_per_second": 23.626,
      "step": 93752
    },
    {
      "epoch": 8.000682652103421,
      "grad_norm": 0.1213863343000412,
      "learning_rate": 9.99658673948289e-06,
      "loss": 0.0019,
      "step": 93760
    },
    {
      "epoch": 8.0015359672327,
      "grad_norm": 0.1531178057193756,
      "learning_rate": 9.992320163836505e-06,
      "loss": 0.0017,
      "step": 93770
    },
    {
      "epoch": 8.002389282361976,
      "grad_norm": 0.037459541112184525,
      "learning_rate": 9.988053588190119e-06,
      "loss": 0.0018,
      "step": 93780
    },
    {
      "epoch": 8.003242597491253,
      "grad_norm": 0.09789890050888062,
      "learning_rate": 9.983787012543733e-06,
      "loss": 0.0017,
      "step": 93790
    },
    {
      "epoch": 8.004095912620532,
      "grad_norm": 0.1468200534582138,
      "learning_rate": 9.979520436897346e-06,
      "loss": 0.0018,
      "step": 93800
    },
    {
      "epoch": 8.004949227749808,
      "grad_norm": 0.1309654265642166,
      "learning_rate": 9.97525386125096e-06,
      "loss": 0.0019,
      "step": 93810
    },
    {
      "epoch": 8.005802542879085,
      "grad_norm": 0.26912495493888855,
      "learning_rate": 9.970987285604574e-06,
      "loss": 0.0019,
      "step": 93820
    },
    {
      "epoch": 8.006655858008363,
      "grad_norm": 0.14607146382331848,
      "learning_rate": 9.966720709958189e-06,
      "loss": 0.0014,
      "step": 93830
    },
    {
      "epoch": 8.00750917313764,
      "grad_norm": 0.12521980702877045,
      "learning_rate": 9.962454134311803e-06,
      "loss": 0.0017,
      "step": 93840
    },
    {
      "epoch": 8.008362488266917,
      "grad_norm": 0.13198411464691162,
      "learning_rate": 9.958187558665415e-06,
      "loss": 0.0017,
      "step": 93850
    },
    {
      "epoch": 8.009215803396195,
      "grad_norm": 0.12742020189762115,
      "learning_rate": 9.95392098301903e-06,
      "loss": 0.0016,
      "step": 93860
    },
    {
      "epoch": 8.010069118525472,
      "grad_norm": 0.11681490391492844,
      "learning_rate": 9.949654407372644e-06,
      "loss": 0.0014,
      "step": 93870
    },
    {
      "epoch": 8.010922433654748,
      "grad_norm": 0.029610153287649155,
      "learning_rate": 9.945387831726256e-06,
      "loss": 0.0016,
      "step": 93880
    },
    {
      "epoch": 8.011775748784025,
      "grad_norm": 0.10008932650089264,
      "learning_rate": 9.94112125607987e-06,
      "loss": 0.0016,
      "step": 93890
    },
    {
      "epoch": 8.012629063913304,
      "grad_norm": 0.14752353727817535,
      "learning_rate": 9.936854680433485e-06,
      "loss": 0.0022,
      "step": 93900
    },
    {
      "epoch": 8.01348237904258,
      "grad_norm": 0.1638389378786087,
      "learning_rate": 9.932588104787097e-06,
      "loss": 0.0017,
      "step": 93910
    },
    {
      "epoch": 8.014335694171857,
      "grad_norm": 0.053610339760780334,
      "learning_rate": 9.928321529140712e-06,
      "loss": 0.002,
      "step": 93920
    },
    {
      "epoch": 8.015189009301135,
      "grad_norm": 0.035318128764629364,
      "learning_rate": 9.924054953494326e-06,
      "loss": 0.0015,
      "step": 93930
    },
    {
      "epoch": 8.016042324430412,
      "grad_norm": 0.33015361428260803,
      "learning_rate": 9.91978837784794e-06,
      "loss": 0.0018,
      "step": 93940
    },
    {
      "epoch": 8.016895639559689,
      "grad_norm": 0.15669065713882446,
      "learning_rate": 9.915521802201554e-06,
      "loss": 0.0019,
      "step": 93950
    },
    {
      "epoch": 8.017748954688967,
      "grad_norm": 0.16136717796325684,
      "learning_rate": 9.911255226555167e-06,
      "loss": 0.0018,
      "step": 93960
    },
    {
      "epoch": 8.018602269818244,
      "grad_norm": 0.20975834131240845,
      "learning_rate": 9.906988650908781e-06,
      "loss": 0.0018,
      "step": 93970
    },
    {
      "epoch": 8.01945558494752,
      "grad_norm": 0.09487792104482651,
      "learning_rate": 9.902722075262395e-06,
      "loss": 0.0017,
      "step": 93980
    },
    {
      "epoch": 8.020308900076799,
      "grad_norm": 0.07617033272981644,
      "learning_rate": 9.89845549961601e-06,
      "loss": 0.0017,
      "step": 93990
    },
    {
      "epoch": 8.021162215206076,
      "grad_norm": 0.1457778811454773,
      "learning_rate": 9.894188923969624e-06,
      "loss": 0.0015,
      "step": 94000
    },
    {
      "epoch": 8.022015530335352,
      "grad_norm": 0.13187851011753082,
      "learning_rate": 9.889922348323236e-06,
      "loss": 0.0016,
      "step": 94010
    },
    {
      "epoch": 8.02286884546463,
      "grad_norm": 0.03586035221815109,
      "learning_rate": 9.885655772676849e-06,
      "loss": 0.0015,
      "step": 94020
    },
    {
      "epoch": 8.023722160593907,
      "grad_norm": 0.27109965682029724,
      "learning_rate": 9.881389197030463e-06,
      "loss": 0.002,
      "step": 94030
    },
    {
      "epoch": 8.024575475723184,
      "grad_norm": 0.1294361650943756,
      "learning_rate": 9.877122621384077e-06,
      "loss": 0.0016,
      "step": 94040
    },
    {
      "epoch": 8.025428790852462,
      "grad_norm": 0.09569426625967026,
      "learning_rate": 9.872856045737692e-06,
      "loss": 0.0015,
      "step": 94050
    },
    {
      "epoch": 8.026282105981739,
      "grad_norm": 0.16395078599452972,
      "learning_rate": 9.868589470091306e-06,
      "loss": 0.002,
      "step": 94060
    },
    {
      "epoch": 8.027135421111016,
      "grad_norm": 0.07743705064058304,
      "learning_rate": 9.864322894444918e-06,
      "loss": 0.0021,
      "step": 94070
    },
    {
      "epoch": 8.027988736240294,
      "grad_norm": 0.10852836817502975,
      "learning_rate": 9.860056318798533e-06,
      "loss": 0.0018,
      "step": 94080
    },
    {
      "epoch": 8.02884205136957,
      "grad_norm": 0.09239228069782257,
      "learning_rate": 9.855789743152147e-06,
      "loss": 0.0014,
      "step": 94090
    },
    {
      "epoch": 8.029695366498848,
      "grad_norm": 0.0363793782889843,
      "learning_rate": 9.851523167505761e-06,
      "loss": 0.0017,
      "step": 94100
    },
    {
      "epoch": 8.030548681628126,
      "grad_norm": 0.063227079808712,
      "learning_rate": 9.847256591859374e-06,
      "loss": 0.0013,
      "step": 94110
    },
    {
      "epoch": 8.031401996757403,
      "grad_norm": 0.29088762402534485,
      "learning_rate": 9.842990016212988e-06,
      "loss": 0.0013,
      "step": 94120
    },
    {
      "epoch": 8.03225531188668,
      "grad_norm": 0.15863856673240662,
      "learning_rate": 9.838723440566602e-06,
      "loss": 0.0016,
      "step": 94130
    },
    {
      "epoch": 8.033108627015958,
      "grad_norm": 0.16349032521247864,
      "learning_rate": 9.834456864920215e-06,
      "loss": 0.0016,
      "step": 94140
    },
    {
      "epoch": 8.033961942145234,
      "grad_norm": 0.11457595229148865,
      "learning_rate": 9.830190289273829e-06,
      "loss": 0.0018,
      "step": 94150
    },
    {
      "epoch": 8.034815257274511,
      "grad_norm": 0.03127326816320419,
      "learning_rate": 9.825923713627443e-06,
      "loss": 0.0018,
      "step": 94160
    },
    {
      "epoch": 8.03566857240379,
      "grad_norm": 0.07503673434257507,
      "learning_rate": 9.821657137981056e-06,
      "loss": 0.0015,
      "step": 94170
    },
    {
      "epoch": 8.036521887533066,
      "grad_norm": 0.5196318626403809,
      "learning_rate": 9.81739056233467e-06,
      "loss": 0.0016,
      "step": 94180
    },
    {
      "epoch": 8.037375202662343,
      "grad_norm": 0.03955041989684105,
      "learning_rate": 9.813123986688284e-06,
      "loss": 0.0013,
      "step": 94190
    },
    {
      "epoch": 8.038228517791621,
      "grad_norm": 0.1763896495103836,
      "learning_rate": 9.808857411041898e-06,
      "loss": 0.0022,
      "step": 94200
    },
    {
      "epoch": 8.039081832920898,
      "grad_norm": 0.11384531855583191,
      "learning_rate": 9.804590835395513e-06,
      "loss": 0.0012,
      "step": 94210
    },
    {
      "epoch": 8.039935148050175,
      "grad_norm": 0.032437968999147415,
      "learning_rate": 9.800324259749125e-06,
      "loss": 0.0014,
      "step": 94220
    },
    {
      "epoch": 8.040788463179453,
      "grad_norm": 0.08097255975008011,
      "learning_rate": 9.79605768410274e-06,
      "loss": 0.0016,
      "step": 94230
    },
    {
      "epoch": 8.04164177830873,
      "grad_norm": 0.16375066339969635,
      "learning_rate": 9.791791108456354e-06,
      "loss": 0.0018,
      "step": 94240
    },
    {
      "epoch": 8.042495093438006,
      "grad_norm": 0.05355401709675789,
      "learning_rate": 9.787524532809968e-06,
      "loss": 0.0016,
      "step": 94250
    },
    {
      "epoch": 8.043348408567283,
      "grad_norm": 0.060092415660619736,
      "learning_rate": 9.783257957163582e-06,
      "loss": 0.0016,
      "step": 94260
    },
    {
      "epoch": 8.044201723696562,
      "grad_norm": 0.2513870596885681,
      "learning_rate": 9.778991381517195e-06,
      "loss": 0.0015,
      "step": 94270
    },
    {
      "epoch": 8.045055038825838,
      "grad_norm": 0.3429354429244995,
      "learning_rate": 9.774724805870807e-06,
      "loss": 0.0017,
      "step": 94280
    },
    {
      "epoch": 8.045908353955115,
      "grad_norm": 0.060393329709768295,
      "learning_rate": 9.770458230224422e-06,
      "loss": 0.0017,
      "step": 94290
    },
    {
      "epoch": 8.046761669084393,
      "grad_norm": 0.18316367268562317,
      "learning_rate": 9.766191654578036e-06,
      "loss": 0.0017,
      "step": 94300
    },
    {
      "epoch": 8.04761498421367,
      "grad_norm": 0.04042897745966911,
      "learning_rate": 9.76192507893165e-06,
      "loss": 0.0014,
      "step": 94310
    },
    {
      "epoch": 8.048468299342947,
      "grad_norm": 0.1023748442530632,
      "learning_rate": 9.757658503285264e-06,
      "loss": 0.0016,
      "step": 94320
    },
    {
      "epoch": 8.049321614472225,
      "grad_norm": 0.12486671656370163,
      "learning_rate": 9.753391927638877e-06,
      "loss": 0.0013,
      "step": 94330
    },
    {
      "epoch": 8.050174929601502,
      "grad_norm": 0.3284657597541809,
      "learning_rate": 9.749125351992491e-06,
      "loss": 0.002,
      "step": 94340
    },
    {
      "epoch": 8.051028244730778,
      "grad_norm": 0.11214582622051239,
      "learning_rate": 9.744858776346105e-06,
      "loss": 0.0017,
      "step": 94350
    },
    {
      "epoch": 8.051881559860057,
      "grad_norm": 0.18025407195091248,
      "learning_rate": 9.74059220069972e-06,
      "loss": 0.0021,
      "step": 94360
    },
    {
      "epoch": 8.052734874989333,
      "grad_norm": 0.03597607463598251,
      "learning_rate": 9.736325625053334e-06,
      "loss": 0.0013,
      "step": 94370
    },
    {
      "epoch": 8.05358819011861,
      "grad_norm": 0.2201603353023529,
      "learning_rate": 9.732059049406946e-06,
      "loss": 0.0016,
      "step": 94380
    },
    {
      "epoch": 8.054441505247889,
      "grad_norm": 0.13431885838508606,
      "learning_rate": 9.72779247376056e-06,
      "loss": 0.0018,
      "step": 94390
    },
    {
      "epoch": 8.055294820377165,
      "grad_norm": 0.32398542761802673,
      "learning_rate": 9.723525898114175e-06,
      "loss": 0.0016,
      "step": 94400
    },
    {
      "epoch": 8.056148135506442,
      "grad_norm": 0.14489486813545227,
      "learning_rate": 9.719259322467787e-06,
      "loss": 0.0017,
      "step": 94410
    },
    {
      "epoch": 8.05700145063572,
      "grad_norm": 0.15294739603996277,
      "learning_rate": 9.714992746821402e-06,
      "loss": 0.0014,
      "step": 94420
    },
    {
      "epoch": 8.057854765764997,
      "grad_norm": 0.18098540604114532,
      "learning_rate": 9.710726171175014e-06,
      "loss": 0.0017,
      "step": 94430
    },
    {
      "epoch": 8.058708080894274,
      "grad_norm": 0.15013417601585388,
      "learning_rate": 9.706459595528628e-06,
      "loss": 0.0017,
      "step": 94440
    },
    {
      "epoch": 8.059561396023552,
      "grad_norm": 0.03717691823840141,
      "learning_rate": 9.702193019882243e-06,
      "loss": 0.0014,
      "step": 94450
    },
    {
      "epoch": 8.060414711152829,
      "grad_norm": 0.2326824963092804,
      "learning_rate": 9.697926444235857e-06,
      "loss": 0.0014,
      "step": 94460
    },
    {
      "epoch": 8.061268026282105,
      "grad_norm": 0.1883164495229721,
      "learning_rate": 9.693659868589471e-06,
      "loss": 0.0017,
      "step": 94470
    },
    {
      "epoch": 8.062121341411384,
      "grad_norm": 0.2687656879425049,
      "learning_rate": 9.689393292943084e-06,
      "loss": 0.0018,
      "step": 94480
    },
    {
      "epoch": 8.06297465654066,
      "grad_norm": 0.23543265461921692,
      "learning_rate": 9.685126717296698e-06,
      "loss": 0.0017,
      "step": 94490
    },
    {
      "epoch": 8.063827971669937,
      "grad_norm": 0.12950031459331512,
      "learning_rate": 9.680860141650312e-06,
      "loss": 0.002,
      "step": 94500
    },
    {
      "epoch": 8.064681286799216,
      "grad_norm": 0.06261847913265228,
      "learning_rate": 9.676593566003926e-06,
      "loss": 0.0018,
      "step": 94510
    },
    {
      "epoch": 8.065534601928492,
      "grad_norm": 0.060895323753356934,
      "learning_rate": 9.67232699035754e-06,
      "loss": 0.002,
      "step": 94520
    },
    {
      "epoch": 8.066387917057769,
      "grad_norm": 0.3121788799762726,
      "learning_rate": 9.668060414711153e-06,
      "loss": 0.0016,
      "step": 94530
    },
    {
      "epoch": 8.067241232187047,
      "grad_norm": 0.1348477602005005,
      "learning_rate": 9.663793839064766e-06,
      "loss": 0.0018,
      "step": 94540
    },
    {
      "epoch": 8.068094547316324,
      "grad_norm": 0.059915829449892044,
      "learning_rate": 9.65952726341838e-06,
      "loss": 0.0016,
      "step": 94550
    },
    {
      "epoch": 8.0689478624456,
      "grad_norm": 0.07459503412246704,
      "learning_rate": 9.655260687771994e-06,
      "loss": 0.0013,
      "step": 94560
    },
    {
      "epoch": 8.06980117757488,
      "grad_norm": 0.19955536723136902,
      "learning_rate": 9.650994112125608e-06,
      "loss": 0.0015,
      "step": 94570
    },
    {
      "epoch": 8.070654492704156,
      "grad_norm": 0.16432379186153412,
      "learning_rate": 9.646727536479223e-06,
      "loss": 0.0015,
      "step": 94580
    },
    {
      "epoch": 8.071507807833433,
      "grad_norm": 0.0697246640920639,
      "learning_rate": 9.642460960832835e-06,
      "loss": 0.0015,
      "step": 94590
    },
    {
      "epoch": 8.072361122962711,
      "grad_norm": 0.06704342365264893,
      "learning_rate": 9.63819438518645e-06,
      "loss": 0.0017,
      "step": 94600
    },
    {
      "epoch": 8.073214438091988,
      "grad_norm": 0.28373852372169495,
      "learning_rate": 9.633927809540064e-06,
      "loss": 0.0014,
      "step": 94610
    },
    {
      "epoch": 8.074067753221264,
      "grad_norm": 0.20841699838638306,
      "learning_rate": 9.629661233893678e-06,
      "loss": 0.0021,
      "step": 94620
    },
    {
      "epoch": 8.074921068350541,
      "grad_norm": 0.12897774577140808,
      "learning_rate": 9.625394658247292e-06,
      "loss": 0.0016,
      "step": 94630
    },
    {
      "epoch": 8.07577438347982,
      "grad_norm": 0.1101381704211235,
      "learning_rate": 9.621128082600905e-06,
      "loss": 0.0018,
      "step": 94640
    },
    {
      "epoch": 8.076627698609096,
      "grad_norm": 0.13150140643119812,
      "learning_rate": 9.616861506954519e-06,
      "loss": 0.0016,
      "step": 94650
    },
    {
      "epoch": 8.077481013738373,
      "grad_norm": 0.13677090406417847,
      "learning_rate": 9.612594931308133e-06,
      "loss": 0.0015,
      "step": 94660
    },
    {
      "epoch": 8.078334328867651,
      "grad_norm": 0.34536734223365784,
      "learning_rate": 9.608328355661746e-06,
      "loss": 0.0017,
      "step": 94670
    },
    {
      "epoch": 8.079187643996928,
      "grad_norm": 0.11838933080434799,
      "learning_rate": 9.60406178001536e-06,
      "loss": 0.0016,
      "step": 94680
    },
    {
      "epoch": 8.080040959126205,
      "grad_norm": 0.048149559646844864,
      "learning_rate": 9.599795204368974e-06,
      "loss": 0.0013,
      "step": 94690
    },
    {
      "epoch": 8.080894274255483,
      "grad_norm": 0.28908592462539673,
      "learning_rate": 9.595528628722587e-06,
      "loss": 0.0019,
      "step": 94700
    },
    {
      "epoch": 8.08174758938476,
      "grad_norm": 0.2629217207431793,
      "learning_rate": 9.591262053076201e-06,
      "loss": 0.002,
      "step": 94710
    },
    {
      "epoch": 8.082600904514036,
      "grad_norm": 0.042514681816101074,
      "learning_rate": 9.586995477429815e-06,
      "loss": 0.0015,
      "step": 94720
    },
    {
      "epoch": 8.083454219643315,
      "grad_norm": 0.05218637362122536,
      "learning_rate": 9.58272890178343e-06,
      "loss": 0.0017,
      "step": 94730
    },
    {
      "epoch": 8.084307534772591,
      "grad_norm": 0.061858732253313065,
      "learning_rate": 9.578462326137042e-06,
      "loss": 0.0024,
      "step": 94740
    },
    {
      "epoch": 8.085160849901868,
      "grad_norm": 0.10722978413105011,
      "learning_rate": 9.574195750490656e-06,
      "loss": 0.002,
      "step": 94750
    },
    {
      "epoch": 8.086014165031147,
      "grad_norm": 0.09738273173570633,
      "learning_rate": 9.56992917484427e-06,
      "loss": 0.002,
      "step": 94760
    },
    {
      "epoch": 8.086867480160423,
      "grad_norm": 0.22074559330940247,
      "learning_rate": 9.565662599197885e-06,
      "loss": 0.0014,
      "step": 94770
    },
    {
      "epoch": 8.0877207952897,
      "grad_norm": 0.14378392696380615,
      "learning_rate": 9.561396023551499e-06,
      "loss": 0.0019,
      "step": 94780
    },
    {
      "epoch": 8.088574110418978,
      "grad_norm": 0.06118094176054001,
      "learning_rate": 9.557129447905112e-06,
      "loss": 0.0013,
      "step": 94790
    },
    {
      "epoch": 8.089427425548255,
      "grad_norm": 0.11184663325548172,
      "learning_rate": 9.552862872258726e-06,
      "loss": 0.0015,
      "step": 94800
    },
    {
      "epoch": 8.090280740677532,
      "grad_norm": 0.09651871025562286,
      "learning_rate": 9.548596296612338e-06,
      "loss": 0.0019,
      "step": 94810
    },
    {
      "epoch": 8.09113405580681,
      "grad_norm": 0.052387043833732605,
      "learning_rate": 9.544329720965953e-06,
      "loss": 0.0018,
      "step": 94820
    },
    {
      "epoch": 8.091987370936087,
      "grad_norm": 0.0967392846941948,
      "learning_rate": 9.540063145319567e-06,
      "loss": 0.0016,
      "step": 94830
    },
    {
      "epoch": 8.092840686065363,
      "grad_norm": 0.1441788226366043,
      "learning_rate": 9.535796569673181e-06,
      "loss": 0.0015,
      "step": 94840
    },
    {
      "epoch": 8.093694001194642,
      "grad_norm": 0.1897231638431549,
      "learning_rate": 9.531529994026794e-06,
      "loss": 0.0018,
      "step": 94850
    },
    {
      "epoch": 8.094547316323919,
      "grad_norm": 0.3432110548019409,
      "learning_rate": 9.527263418380408e-06,
      "loss": 0.0018,
      "step": 94860
    },
    {
      "epoch": 8.095400631453195,
      "grad_norm": 0.11299260705709457,
      "learning_rate": 9.522996842734022e-06,
      "loss": 0.0018,
      "step": 94870
    },
    {
      "epoch": 8.096253946582474,
      "grad_norm": 0.2190147042274475,
      "learning_rate": 9.518730267087636e-06,
      "loss": 0.0016,
      "step": 94880
    },
    {
      "epoch": 8.09710726171175,
      "grad_norm": 0.2356119453907013,
      "learning_rate": 9.51446369144125e-06,
      "loss": 0.002,
      "step": 94890
    },
    {
      "epoch": 8.097960576841027,
      "grad_norm": 0.12821783125400543,
      "learning_rate": 9.510197115794863e-06,
      "loss": 0.0019,
      "step": 94900
    },
    {
      "epoch": 8.098813891970305,
      "grad_norm": 0.3721458911895752,
      "learning_rate": 9.505930540148477e-06,
      "loss": 0.0022,
      "step": 94910
    },
    {
      "epoch": 8.099667207099582,
      "grad_norm": 0.21848873794078827,
      "learning_rate": 9.501663964502092e-06,
      "loss": 0.0018,
      "step": 94920
    },
    {
      "epoch": 8.100520522228859,
      "grad_norm": 0.03582353517413139,
      "learning_rate": 9.497397388855706e-06,
      "loss": 0.0018,
      "step": 94930
    },
    {
      "epoch": 8.101373837358137,
      "grad_norm": 0.24947161972522736,
      "learning_rate": 9.493130813209318e-06,
      "loss": 0.0015,
      "step": 94940
    },
    {
      "epoch": 8.102227152487414,
      "grad_norm": 0.15113353729248047,
      "learning_rate": 9.488864237562933e-06,
      "loss": 0.0016,
      "step": 94950
    },
    {
      "epoch": 8.10308046761669,
      "grad_norm": 0.09443573653697968,
      "learning_rate": 9.484597661916545e-06,
      "loss": 0.0016,
      "step": 94960
    },
    {
      "epoch": 8.103933782745967,
      "grad_norm": 0.0911765769124031,
      "learning_rate": 9.48033108627016e-06,
      "loss": 0.0016,
      "step": 94970
    },
    {
      "epoch": 8.104787097875246,
      "grad_norm": 0.06352699548006058,
      "learning_rate": 9.476064510623774e-06,
      "loss": 0.0016,
      "step": 94980
    },
    {
      "epoch": 8.105640413004522,
      "grad_norm": 0.07405562698841095,
      "learning_rate": 9.471797934977388e-06,
      "loss": 0.002,
      "step": 94990
    },
    {
      "epoch": 8.106493728133799,
      "grad_norm": 0.17502138018608093,
      "learning_rate": 9.467531359331002e-06,
      "loss": 0.0017,
      "step": 95000
    },
    {
      "epoch": 8.107347043263077,
      "grad_norm": 0.060139335691928864,
      "learning_rate": 9.463264783684615e-06,
      "loss": 0.0021,
      "step": 95010
    },
    {
      "epoch": 8.108200358392354,
      "grad_norm": 0.02906673774123192,
      "learning_rate": 9.458998208038229e-06,
      "loss": 0.0018,
      "step": 95020
    },
    {
      "epoch": 8.10905367352163,
      "grad_norm": 0.12789328396320343,
      "learning_rate": 9.454731632391843e-06,
      "loss": 0.0013,
      "step": 95030
    },
    {
      "epoch": 8.10990698865091,
      "grad_norm": 0.01925024390220642,
      "learning_rate": 9.450465056745457e-06,
      "loss": 0.002,
      "step": 95040
    },
    {
      "epoch": 8.110760303780186,
      "grad_norm": 0.06968505680561066,
      "learning_rate": 9.446198481099072e-06,
      "loss": 0.0017,
      "step": 95050
    },
    {
      "epoch": 8.111613618909463,
      "grad_norm": 0.03764687106013298,
      "learning_rate": 9.441931905452684e-06,
      "loss": 0.0015,
      "step": 95060
    },
    {
      "epoch": 8.112466934038741,
      "grad_norm": 0.09473419934511185,
      "learning_rate": 9.437665329806297e-06,
      "loss": 0.0018,
      "step": 95070
    },
    {
      "epoch": 8.113320249168018,
      "grad_norm": 0.18662308156490326,
      "learning_rate": 9.433398754159911e-06,
      "loss": 0.0016,
      "step": 95080
    },
    {
      "epoch": 8.114173564297294,
      "grad_norm": 0.1472972184419632,
      "learning_rate": 9.429132178513525e-06,
      "loss": 0.0014,
      "step": 95090
    },
    {
      "epoch": 8.115026879426573,
      "grad_norm": 0.3312382102012634,
      "learning_rate": 9.42486560286714e-06,
      "loss": 0.0015,
      "step": 95100
    },
    {
      "epoch": 8.11588019455585,
      "grad_norm": 0.1669674962759018,
      "learning_rate": 9.420599027220752e-06,
      "loss": 0.0019,
      "step": 95110
    },
    {
      "epoch": 8.116733509685126,
      "grad_norm": 0.17447857558727264,
      "learning_rate": 9.416332451574366e-06,
      "loss": 0.0022,
      "step": 95120
    },
    {
      "epoch": 8.117586824814405,
      "grad_norm": 0.1327919363975525,
      "learning_rate": 9.41206587592798e-06,
      "loss": 0.0016,
      "step": 95130
    },
    {
      "epoch": 8.118440139943681,
      "grad_norm": 0.19303354620933533,
      "learning_rate": 9.407799300281595e-06,
      "loss": 0.0018,
      "step": 95140
    },
    {
      "epoch": 8.119293455072958,
      "grad_norm": 0.18498274683952332,
      "learning_rate": 9.403532724635209e-06,
      "loss": 0.0016,
      "step": 95150
    },
    {
      "epoch": 8.120146770202236,
      "grad_norm": 0.10999860614538193,
      "learning_rate": 9.399266148988822e-06,
      "loss": 0.0014,
      "step": 95160
    },
    {
      "epoch": 8.121000085331513,
      "grad_norm": 0.05839232727885246,
      "learning_rate": 9.394999573342436e-06,
      "loss": 0.0018,
      "step": 95170
    },
    {
      "epoch": 8.12185340046079,
      "grad_norm": 0.19950318336486816,
      "learning_rate": 9.39073299769605e-06,
      "loss": 0.0016,
      "step": 95180
    },
    {
      "epoch": 8.122706715590068,
      "grad_norm": 0.1285560578107834,
      "learning_rate": 9.386466422049664e-06,
      "loss": 0.0013,
      "step": 95190
    },
    {
      "epoch": 8.123560030719345,
      "grad_norm": 0.03240169584751129,
      "learning_rate": 9.382199846403279e-06,
      "loss": 0.0015,
      "step": 95200
    },
    {
      "epoch": 8.124413345848621,
      "grad_norm": 0.14781780540943146,
      "learning_rate": 9.377933270756891e-06,
      "loss": 0.002,
      "step": 95210
    },
    {
      "epoch": 8.1252666609779,
      "grad_norm": 0.09451139718294144,
      "learning_rate": 9.373666695110504e-06,
      "loss": 0.0015,
      "step": 95220
    },
    {
      "epoch": 8.126119976107177,
      "grad_norm": 0.044016797095537186,
      "learning_rate": 9.369400119464118e-06,
      "loss": 0.0018,
      "step": 95230
    },
    {
      "epoch": 8.126973291236453,
      "grad_norm": 0.27415868639945984,
      "learning_rate": 9.365133543817732e-06,
      "loss": 0.0019,
      "step": 95240
    },
    {
      "epoch": 8.127826606365732,
      "grad_norm": 0.10874058306217194,
      "learning_rate": 9.360866968171346e-06,
      "loss": 0.0021,
      "step": 95250
    },
    {
      "epoch": 8.128679921495008,
      "grad_norm": 0.1297178566455841,
      "learning_rate": 9.35660039252496e-06,
      "loss": 0.0019,
      "step": 95260
    },
    {
      "epoch": 8.129533236624285,
      "grad_norm": 0.032171331346035004,
      "learning_rate": 9.352333816878573e-06,
      "loss": 0.0013,
      "step": 95270
    },
    {
      "epoch": 8.130386551753563,
      "grad_norm": 0.1327037662267685,
      "learning_rate": 9.348067241232187e-06,
      "loss": 0.002,
      "step": 95280
    },
    {
      "epoch": 8.13123986688284,
      "grad_norm": 0.23885369300842285,
      "learning_rate": 9.343800665585802e-06,
      "loss": 0.0017,
      "step": 95290
    },
    {
      "epoch": 8.132093182012117,
      "grad_norm": 0.11471517384052277,
      "learning_rate": 9.339534089939416e-06,
      "loss": 0.0015,
      "step": 95300
    },
    {
      "epoch": 8.132946497141395,
      "grad_norm": 0.059545211493968964,
      "learning_rate": 9.33526751429303e-06,
      "loss": 0.0015,
      "step": 95310
    },
    {
      "epoch": 8.133799812270672,
      "grad_norm": 0.15143659710884094,
      "learning_rate": 9.331000938646643e-06,
      "loss": 0.0015,
      "step": 95320
    },
    {
      "epoch": 8.134653127399949,
      "grad_norm": 0.21674509346485138,
      "learning_rate": 9.326734363000257e-06,
      "loss": 0.002,
      "step": 95330
    },
    {
      "epoch": 8.135506442529227,
      "grad_norm": 0.2560971677303314,
      "learning_rate": 9.32246778735387e-06,
      "loss": 0.0016,
      "step": 95340
    },
    {
      "epoch": 8.136359757658504,
      "grad_norm": 0.03592443838715553,
      "learning_rate": 9.318201211707484e-06,
      "loss": 0.0015,
      "step": 95350
    },
    {
      "epoch": 8.13721307278778,
      "grad_norm": 0.11318162828683853,
      "learning_rate": 9.313934636061098e-06,
      "loss": 0.0018,
      "step": 95360
    },
    {
      "epoch": 8.138066387917057,
      "grad_norm": 0.32731854915618896,
      "learning_rate": 9.30966806041471e-06,
      "loss": 0.0016,
      "step": 95370
    },
    {
      "epoch": 8.138919703046335,
      "grad_norm": 0.2723299264907837,
      "learning_rate": 9.305401484768325e-06,
      "loss": 0.0016,
      "step": 95380
    },
    {
      "epoch": 8.139773018175612,
      "grad_norm": 0.21899926662445068,
      "learning_rate": 9.301134909121939e-06,
      "loss": 0.0016,
      "step": 95390
    },
    {
      "epoch": 8.140626333304889,
      "grad_norm": 0.1833776831626892,
      "learning_rate": 9.296868333475553e-06,
      "loss": 0.0018,
      "step": 95400
    },
    {
      "epoch": 8.141479648434167,
      "grad_norm": 0.044473521411418915,
      "learning_rate": 9.292601757829167e-06,
      "loss": 0.0013,
      "step": 95410
    },
    {
      "epoch": 8.142332963563444,
      "grad_norm": 0.03125105798244476,
      "learning_rate": 9.28833518218278e-06,
      "loss": 0.0017,
      "step": 95420
    },
    {
      "epoch": 8.14318627869272,
      "grad_norm": 0.07849393039941788,
      "learning_rate": 9.284068606536394e-06,
      "loss": 0.002,
      "step": 95430
    },
    {
      "epoch": 8.144039593821999,
      "grad_norm": 0.1283368021249771,
      "learning_rate": 9.279802030890008e-06,
      "loss": 0.0015,
      "step": 95440
    },
    {
      "epoch": 8.144892908951276,
      "grad_norm": 0.13261005282402039,
      "learning_rate": 9.275535455243623e-06,
      "loss": 0.0017,
      "step": 95450
    },
    {
      "epoch": 8.145746224080552,
      "grad_norm": 0.14618366956710815,
      "learning_rate": 9.271268879597237e-06,
      "loss": 0.0015,
      "step": 95460
    },
    {
      "epoch": 8.14659953920983,
      "grad_norm": 0.06083499267697334,
      "learning_rate": 9.26700230395085e-06,
      "loss": 0.0016,
      "step": 95470
    },
    {
      "epoch": 8.147452854339107,
      "grad_norm": 0.15416082739830017,
      "learning_rate": 9.262735728304462e-06,
      "loss": 0.0017,
      "step": 95480
    },
    {
      "epoch": 8.148306169468384,
      "grad_norm": 0.3199252784252167,
      "learning_rate": 9.258469152658076e-06,
      "loss": 0.0017,
      "step": 95490
    },
    {
      "epoch": 8.149159484597662,
      "grad_norm": 0.1491072028875351,
      "learning_rate": 9.25420257701169e-06,
      "loss": 0.0015,
      "step": 95500
    },
    {
      "epoch": 8.15001279972694,
      "grad_norm": 0.07350962609052658,
      "learning_rate": 9.249936001365305e-06,
      "loss": 0.0015,
      "step": 95510
    },
    {
      "epoch": 8.150866114856216,
      "grad_norm": 0.2525089383125305,
      "learning_rate": 9.245669425718919e-06,
      "loss": 0.0014,
      "step": 95520
    },
    {
      "epoch": 8.151719429985494,
      "grad_norm": 0.02556939236819744,
      "learning_rate": 9.241402850072532e-06,
      "loss": 0.0016,
      "step": 95530
    },
    {
      "epoch": 8.152572745114771,
      "grad_norm": 0.07890768349170685,
      "learning_rate": 9.237136274426146e-06,
      "loss": 0.0014,
      "step": 95540
    },
    {
      "epoch": 8.153426060244048,
      "grad_norm": 0.09684962779283524,
      "learning_rate": 9.23286969877976e-06,
      "loss": 0.002,
      "step": 95550
    },
    {
      "epoch": 8.154279375373326,
      "grad_norm": 0.028936218470335007,
      "learning_rate": 9.228603123133374e-06,
      "loss": 0.0019,
      "step": 95560
    },
    {
      "epoch": 8.155132690502603,
      "grad_norm": 0.13268467783927917,
      "learning_rate": 9.224336547486989e-06,
      "loss": 0.0016,
      "step": 95570
    },
    {
      "epoch": 8.15598600563188,
      "grad_norm": 0.16131232678890228,
      "learning_rate": 9.220069971840601e-06,
      "loss": 0.0016,
      "step": 95580
    },
    {
      "epoch": 8.156839320761158,
      "grad_norm": 0.058342598378658295,
      "learning_rate": 9.215803396194215e-06,
      "loss": 0.0017,
      "step": 95590
    },
    {
      "epoch": 8.157692635890434,
      "grad_norm": 0.1271488517522812,
      "learning_rate": 9.211536820547828e-06,
      "loss": 0.0018,
      "step": 95600
    },
    {
      "epoch": 8.158545951019711,
      "grad_norm": 0.13153111934661865,
      "learning_rate": 9.207270244901442e-06,
      "loss": 0.0017,
      "step": 95610
    },
    {
      "epoch": 8.15939926614899,
      "grad_norm": 0.04664061591029167,
      "learning_rate": 9.203003669255056e-06,
      "loss": 0.0013,
      "step": 95620
    },
    {
      "epoch": 8.160252581278266,
      "grad_norm": 0.1647544801235199,
      "learning_rate": 9.19873709360867e-06,
      "loss": 0.0016,
      "step": 95630
    },
    {
      "epoch": 8.161105896407543,
      "grad_norm": 0.04470546916127205,
      "learning_rate": 9.194470517962283e-06,
      "loss": 0.0014,
      "step": 95640
    },
    {
      "epoch": 8.161959211536821,
      "grad_norm": 0.044658154249191284,
      "learning_rate": 9.190203942315897e-06,
      "loss": 0.0014,
      "step": 95650
    },
    {
      "epoch": 8.162812526666098,
      "grad_norm": 0.20674552023410797,
      "learning_rate": 9.185937366669512e-06,
      "loss": 0.0014,
      "step": 95660
    },
    {
      "epoch": 8.163665841795375,
      "grad_norm": 0.19966080784797668,
      "learning_rate": 9.181670791023126e-06,
      "loss": 0.0021,
      "step": 95670
    },
    {
      "epoch": 8.164519156924653,
      "grad_norm": 0.029957404360175133,
      "learning_rate": 9.177404215376738e-06,
      "loss": 0.0013,
      "step": 95680
    },
    {
      "epoch": 8.16537247205393,
      "grad_norm": 0.04248861223459244,
      "learning_rate": 9.173137639730353e-06,
      "loss": 0.0017,
      "step": 95690
    },
    {
      "epoch": 8.166225787183206,
      "grad_norm": 0.5278909206390381,
      "learning_rate": 9.168871064083967e-06,
      "loss": 0.0017,
      "step": 95700
    },
    {
      "epoch": 8.167079102312483,
      "grad_norm": 0.2944180965423584,
      "learning_rate": 9.164604488437581e-06,
      "loss": 0.0015,
      "step": 95710
    },
    {
      "epoch": 8.167932417441762,
      "grad_norm": 0.167822927236557,
      "learning_rate": 9.160337912791195e-06,
      "loss": 0.0016,
      "step": 95720
    },
    {
      "epoch": 8.168785732571038,
      "grad_norm": 0.30276140570640564,
      "learning_rate": 9.156071337144808e-06,
      "loss": 0.0016,
      "step": 95730
    },
    {
      "epoch": 8.169639047700315,
      "grad_norm": 0.12892916798591614,
      "learning_rate": 9.15180476149842e-06,
      "loss": 0.0021,
      "step": 95740
    },
    {
      "epoch": 8.170492362829593,
      "grad_norm": 0.1155996322631836,
      "learning_rate": 9.147538185852035e-06,
      "loss": 0.0015,
      "step": 95750
    },
    {
      "epoch": 8.17134567795887,
      "grad_norm": 0.2736969590187073,
      "learning_rate": 9.143271610205649e-06,
      "loss": 0.0016,
      "step": 95760
    },
    {
      "epoch": 8.172198993088147,
      "grad_norm": 0.09745623171329498,
      "learning_rate": 9.139005034559263e-06,
      "loss": 0.0015,
      "step": 95770
    },
    {
      "epoch": 8.173052308217425,
      "grad_norm": 0.14845286309719086,
      "learning_rate": 9.134738458912877e-06,
      "loss": 0.0021,
      "step": 95780
    },
    {
      "epoch": 8.173905623346702,
      "grad_norm": 0.23472903668880463,
      "learning_rate": 9.13047188326649e-06,
      "loss": 0.0021,
      "step": 95790
    },
    {
      "epoch": 8.174758938475978,
      "grad_norm": 0.14574328064918518,
      "learning_rate": 9.126205307620104e-06,
      "loss": 0.0016,
      "step": 95800
    },
    {
      "epoch": 8.175612253605257,
      "grad_norm": 0.0969318151473999,
      "learning_rate": 9.121938731973718e-06,
      "loss": 0.0015,
      "step": 95810
    },
    {
      "epoch": 8.176465568734534,
      "grad_norm": 0.22845454514026642,
      "learning_rate": 9.117672156327333e-06,
      "loss": 0.0021,
      "step": 95820
    },
    {
      "epoch": 8.17731888386381,
      "grad_norm": 0.20428188145160675,
      "learning_rate": 9.113405580680947e-06,
      "loss": 0.0023,
      "step": 95830
    },
    {
      "epoch": 8.178172198993089,
      "grad_norm": 0.21695619821548462,
      "learning_rate": 9.10913900503456e-06,
      "loss": 0.0013,
      "step": 95840
    },
    {
      "epoch": 8.179025514122365,
      "grad_norm": 0.1323803961277008,
      "learning_rate": 9.104872429388174e-06,
      "loss": 0.0016,
      "step": 95850
    },
    {
      "epoch": 8.179878829251642,
      "grad_norm": 0.11627345532178879,
      "learning_rate": 9.100605853741788e-06,
      "loss": 0.0014,
      "step": 95860
    },
    {
      "epoch": 8.18073214438092,
      "grad_norm": 0.04697704315185547,
      "learning_rate": 9.0963392780954e-06,
      "loss": 0.0019,
      "step": 95870
    },
    {
      "epoch": 8.181585459510197,
      "grad_norm": 0.29054102301597595,
      "learning_rate": 9.092072702449015e-06,
      "loss": 0.0018,
      "step": 95880
    },
    {
      "epoch": 8.182438774639474,
      "grad_norm": 0.10436294227838516,
      "learning_rate": 9.087806126802629e-06,
      "loss": 0.0019,
      "step": 95890
    },
    {
      "epoch": 8.183292089768752,
      "grad_norm": 0.09708455950021744,
      "learning_rate": 9.083539551156242e-06,
      "loss": 0.0015,
      "step": 95900
    },
    {
      "epoch": 8.184145404898029,
      "grad_norm": 0.1480376273393631,
      "learning_rate": 9.079272975509856e-06,
      "loss": 0.0014,
      "step": 95910
    },
    {
      "epoch": 8.184998720027306,
      "grad_norm": 0.11402228474617004,
      "learning_rate": 9.07500639986347e-06,
      "loss": 0.002,
      "step": 95920
    },
    {
      "epoch": 8.185852035156584,
      "grad_norm": 0.20010845363140106,
      "learning_rate": 9.070739824217084e-06,
      "loss": 0.0016,
      "step": 95930
    },
    {
      "epoch": 8.18670535028586,
      "grad_norm": 0.04495519772171974,
      "learning_rate": 9.066473248570698e-06,
      "loss": 0.0017,
      "step": 95940
    },
    {
      "epoch": 8.187558665415137,
      "grad_norm": 0.2014944851398468,
      "learning_rate": 9.062206672924311e-06,
      "loss": 0.0016,
      "step": 95950
    },
    {
      "epoch": 8.188411980544416,
      "grad_norm": 0.04770292714238167,
      "learning_rate": 9.057940097277925e-06,
      "loss": 0.0014,
      "step": 95960
    },
    {
      "epoch": 8.189265295673692,
      "grad_norm": 0.18511202931404114,
      "learning_rate": 9.05367352163154e-06,
      "loss": 0.0015,
      "step": 95970
    },
    {
      "epoch": 8.190118610802969,
      "grad_norm": 0.18112288415431976,
      "learning_rate": 9.049406945985154e-06,
      "loss": 0.0024,
      "step": 95980
    },
    {
      "epoch": 8.190971925932248,
      "grad_norm": 0.1234164610505104,
      "learning_rate": 9.045140370338768e-06,
      "loss": 0.0014,
      "step": 95990
    },
    {
      "epoch": 8.191825241061524,
      "grad_norm": 0.20408575236797333,
      "learning_rate": 9.040873794692379e-06,
      "loss": 0.0017,
      "step": 96000
    },
    {
      "epoch": 8.1926785561908,
      "grad_norm": 0.2539461553096771,
      "learning_rate": 9.036607219045993e-06,
      "loss": 0.0022,
      "step": 96010
    },
    {
      "epoch": 8.19353187132008,
      "grad_norm": 0.21862798929214478,
      "learning_rate": 9.032340643399607e-06,
      "loss": 0.0021,
      "step": 96020
    },
    {
      "epoch": 8.194385186449356,
      "grad_norm": 0.14403925836086273,
      "learning_rate": 9.028074067753222e-06,
      "loss": 0.0016,
      "step": 96030
    },
    {
      "epoch": 8.195238501578633,
      "grad_norm": 0.06161537766456604,
      "learning_rate": 9.023807492106836e-06,
      "loss": 0.002,
      "step": 96040
    },
    {
      "epoch": 8.196091816707911,
      "grad_norm": 0.16383075714111328,
      "learning_rate": 9.019540916460448e-06,
      "loss": 0.0014,
      "step": 96050
    },
    {
      "epoch": 8.196945131837188,
      "grad_norm": 0.03548107668757439,
      "learning_rate": 9.015274340814063e-06,
      "loss": 0.0015,
      "step": 96060
    },
    {
      "epoch": 8.197798446966464,
      "grad_norm": 0.11265238374471664,
      "learning_rate": 9.011007765167677e-06,
      "loss": 0.0019,
      "step": 96070
    },
    {
      "epoch": 8.198651762095741,
      "grad_norm": 0.3066318929195404,
      "learning_rate": 9.006741189521291e-06,
      "loss": 0.0015,
      "step": 96080
    },
    {
      "epoch": 8.19950507722502,
      "grad_norm": 0.04800112172961235,
      "learning_rate": 9.002474613874905e-06,
      "loss": 0.0016,
      "step": 96090
    },
    {
      "epoch": 8.200358392354296,
      "grad_norm": 0.14888058602809906,
      "learning_rate": 8.998208038228518e-06,
      "loss": 0.0019,
      "step": 96100
    },
    {
      "epoch": 8.201211707483573,
      "grad_norm": 0.30755293369293213,
      "learning_rate": 8.993941462582132e-06,
      "loss": 0.0013,
      "step": 96110
    },
    {
      "epoch": 8.202065022612851,
      "grad_norm": 0.27214574813842773,
      "learning_rate": 8.989674886935746e-06,
      "loss": 0.0013,
      "step": 96120
    },
    {
      "epoch": 8.202918337742128,
      "grad_norm": 0.11236849427223206,
      "learning_rate": 8.98540831128936e-06,
      "loss": 0.0015,
      "step": 96130
    },
    {
      "epoch": 8.203771652871405,
      "grad_norm": 0.06532887369394302,
      "learning_rate": 8.981141735642973e-06,
      "loss": 0.002,
      "step": 96140
    },
    {
      "epoch": 8.204624968000683,
      "grad_norm": 0.21275614202022552,
      "learning_rate": 8.976875159996587e-06,
      "loss": 0.0018,
      "step": 96150
    },
    {
      "epoch": 8.20547828312996,
      "grad_norm": 0.11376044154167175,
      "learning_rate": 8.9726085843502e-06,
      "loss": 0.0014,
      "step": 96160
    },
    {
      "epoch": 8.206331598259236,
      "grad_norm": 0.03310967981815338,
      "learning_rate": 8.968342008703814e-06,
      "loss": 0.0014,
      "step": 96170
    },
    {
      "epoch": 8.207184913388515,
      "grad_norm": 0.1465238630771637,
      "learning_rate": 8.964075433057428e-06,
      "loss": 0.0018,
      "step": 96180
    },
    {
      "epoch": 8.208038228517792,
      "grad_norm": 0.1617579311132431,
      "learning_rate": 8.959808857411043e-06,
      "loss": 0.0019,
      "step": 96190
    },
    {
      "epoch": 8.208891543647068,
      "grad_norm": 0.08008310943841934,
      "learning_rate": 8.955542281764657e-06,
      "loss": 0.002,
      "step": 96200
    },
    {
      "epoch": 8.209744858776347,
      "grad_norm": 0.039680931717157364,
      "learning_rate": 8.95127570611827e-06,
      "loss": 0.0014,
      "step": 96210
    },
    {
      "epoch": 8.210598173905623,
      "grad_norm": 0.1497005969285965,
      "learning_rate": 8.947009130471884e-06,
      "loss": 0.0017,
      "step": 96220
    },
    {
      "epoch": 8.2114514890349,
      "grad_norm": 0.15416212379932404,
      "learning_rate": 8.942742554825498e-06,
      "loss": 0.0017,
      "step": 96230
    },
    {
      "epoch": 8.212304804164178,
      "grad_norm": 0.325692355632782,
      "learning_rate": 8.938475979179112e-06,
      "loss": 0.0017,
      "step": 96240
    },
    {
      "epoch": 8.213158119293455,
      "grad_norm": 0.027146615087985992,
      "learning_rate": 8.934209403532726e-06,
      "loss": 0.0017,
      "step": 96250
    },
    {
      "epoch": 8.214011434422732,
      "grad_norm": 0.027265671640634537,
      "learning_rate": 8.929942827886339e-06,
      "loss": 0.0018,
      "step": 96260
    },
    {
      "epoch": 8.21486474955201,
      "grad_norm": 0.09363894164562225,
      "learning_rate": 8.925676252239951e-06,
      "loss": 0.0028,
      "step": 96270
    },
    {
      "epoch": 8.215718064681287,
      "grad_norm": 0.18072102963924408,
      "learning_rate": 8.921409676593566e-06,
      "loss": 0.0013,
      "step": 96280
    },
    {
      "epoch": 8.216571379810564,
      "grad_norm": 0.11196400225162506,
      "learning_rate": 8.91714310094718e-06,
      "loss": 0.0019,
      "step": 96290
    },
    {
      "epoch": 8.217424694939842,
      "grad_norm": 0.23661725223064423,
      "learning_rate": 8.912876525300794e-06,
      "loss": 0.002,
      "step": 96300
    },
    {
      "epoch": 8.218278010069119,
      "grad_norm": 0.4252244830131531,
      "learning_rate": 8.908609949654407e-06,
      "loss": 0.0015,
      "step": 96310
    },
    {
      "epoch": 8.219131325198395,
      "grad_norm": 0.18211007118225098,
      "learning_rate": 8.904343374008021e-06,
      "loss": 0.0017,
      "step": 96320
    },
    {
      "epoch": 8.219984640327674,
      "grad_norm": 0.22083993256092072,
      "learning_rate": 8.900076798361635e-06,
      "loss": 0.0013,
      "step": 96330
    },
    {
      "epoch": 8.22083795545695,
      "grad_norm": 0.12755197286605835,
      "learning_rate": 8.89581022271525e-06,
      "loss": 0.0021,
      "step": 96340
    },
    {
      "epoch": 8.221691270586227,
      "grad_norm": 0.34031081199645996,
      "learning_rate": 8.891543647068864e-06,
      "loss": 0.0017,
      "step": 96350
    },
    {
      "epoch": 8.222544585715506,
      "grad_norm": 0.05699412524700165,
      "learning_rate": 8.887277071422476e-06,
      "loss": 0.0015,
      "step": 96360
    },
    {
      "epoch": 8.223397900844782,
      "grad_norm": 0.3027588427066803,
      "learning_rate": 8.88301049577609e-06,
      "loss": 0.0021,
      "step": 96370
    },
    {
      "epoch": 8.224251215974059,
      "grad_norm": 0.11925683915615082,
      "learning_rate": 8.878743920129705e-06,
      "loss": 0.0014,
      "step": 96380
    },
    {
      "epoch": 8.225104531103337,
      "grad_norm": 0.1304941028356552,
      "learning_rate": 8.874477344483319e-06,
      "loss": 0.002,
      "step": 96390
    },
    {
      "epoch": 8.225957846232614,
      "grad_norm": 0.10904374718666077,
      "learning_rate": 8.870210768836932e-06,
      "loss": 0.002,
      "step": 96400
    },
    {
      "epoch": 8.22681116136189,
      "grad_norm": 0.07631850987672806,
      "learning_rate": 8.865944193190546e-06,
      "loss": 0.0014,
      "step": 96410
    },
    {
      "epoch": 8.227664476491169,
      "grad_norm": 0.09791915863752365,
      "learning_rate": 8.861677617544158e-06,
      "loss": 0.0015,
      "step": 96420
    },
    {
      "epoch": 8.228517791620446,
      "grad_norm": 0.030998101457953453,
      "learning_rate": 8.857411041897773e-06,
      "loss": 0.0017,
      "step": 96430
    },
    {
      "epoch": 8.229371106749722,
      "grad_norm": 0.18800580501556396,
      "learning_rate": 8.853144466251387e-06,
      "loss": 0.0014,
      "step": 96440
    },
    {
      "epoch": 8.230224421878999,
      "grad_norm": 0.09664568305015564,
      "learning_rate": 8.848877890605001e-06,
      "loss": 0.0024,
      "step": 96450
    },
    {
      "epoch": 8.231077737008277,
      "grad_norm": 0.18084973096847534,
      "learning_rate": 8.844611314958615e-06,
      "loss": 0.0016,
      "step": 96460
    },
    {
      "epoch": 8.231931052137554,
      "grad_norm": 0.25188249349594116,
      "learning_rate": 8.840344739312228e-06,
      "loss": 0.0016,
      "step": 96470
    },
    {
      "epoch": 8.23278436726683,
      "grad_norm": 0.1481790393590927,
      "learning_rate": 8.836078163665842e-06,
      "loss": 0.0016,
      "step": 96480
    },
    {
      "epoch": 8.23363768239611,
      "grad_norm": 0.0938086286187172,
      "learning_rate": 8.831811588019456e-06,
      "loss": 0.0019,
      "step": 96490
    },
    {
      "epoch": 8.234490997525386,
      "grad_norm": 0.15252196788787842,
      "learning_rate": 8.82754501237307e-06,
      "loss": 0.0017,
      "step": 96500
    },
    {
      "epoch": 8.235344312654663,
      "grad_norm": 0.17368489503860474,
      "learning_rate": 8.823278436726685e-06,
      "loss": 0.0018,
      "step": 96510
    },
    {
      "epoch": 8.236197627783941,
      "grad_norm": 0.11746099591255188,
      "learning_rate": 8.819011861080297e-06,
      "loss": 0.0017,
      "step": 96520
    },
    {
      "epoch": 8.237050942913218,
      "grad_norm": 0.0353267639875412,
      "learning_rate": 8.81474528543391e-06,
      "loss": 0.0019,
      "step": 96530
    },
    {
      "epoch": 8.237904258042494,
      "grad_norm": 0.05971565470099449,
      "learning_rate": 8.810478709787524e-06,
      "loss": 0.0017,
      "step": 96540
    },
    {
      "epoch": 8.238757573171773,
      "grad_norm": 0.16330283880233765,
      "learning_rate": 8.806212134141138e-06,
      "loss": 0.002,
      "step": 96550
    },
    {
      "epoch": 8.23961088830105,
      "grad_norm": 0.2528932988643646,
      "learning_rate": 8.801945558494753e-06,
      "loss": 0.0019,
      "step": 96560
    },
    {
      "epoch": 8.240464203430326,
      "grad_norm": 0.11243350803852081,
      "learning_rate": 8.797678982848367e-06,
      "loss": 0.0019,
      "step": 96570
    },
    {
      "epoch": 8.241317518559605,
      "grad_norm": 0.09658882766962051,
      "learning_rate": 8.79341240720198e-06,
      "loss": 0.0014,
      "step": 96580
    },
    {
      "epoch": 8.242170833688881,
      "grad_norm": 0.045744359493255615,
      "learning_rate": 8.789145831555594e-06,
      "loss": 0.0016,
      "step": 96590
    },
    {
      "epoch": 8.243024148818158,
      "grad_norm": 0.09710060060024261,
      "learning_rate": 8.784879255909208e-06,
      "loss": 0.0019,
      "step": 96600
    },
    {
      "epoch": 8.243877463947436,
      "grad_norm": 0.05943847447633743,
      "learning_rate": 8.780612680262822e-06,
      "loss": 0.0018,
      "step": 96610
    },
    {
      "epoch": 8.244730779076713,
      "grad_norm": 0.2526518702507019,
      "learning_rate": 8.776346104616435e-06,
      "loss": 0.0015,
      "step": 96620
    },
    {
      "epoch": 8.24558409420599,
      "grad_norm": 0.20660334825515747,
      "learning_rate": 8.772079528970049e-06,
      "loss": 0.0016,
      "step": 96630
    },
    {
      "epoch": 8.246437409335268,
      "grad_norm": 0.0781746432185173,
      "learning_rate": 8.767812953323663e-06,
      "loss": 0.0022,
      "step": 96640
    },
    {
      "epoch": 8.247290724464545,
      "grad_norm": 0.11701509356498718,
      "learning_rate": 8.763546377677277e-06,
      "loss": 0.0017,
      "step": 96650
    },
    {
      "epoch": 8.248144039593821,
      "grad_norm": 0.03195008262991905,
      "learning_rate": 8.759279802030892e-06,
      "loss": 0.0018,
      "step": 96660
    },
    {
      "epoch": 8.2489973547231,
      "grad_norm": 0.036526311188936234,
      "learning_rate": 8.755013226384504e-06,
      "loss": 0.0015,
      "step": 96670
    },
    {
      "epoch": 8.249850669852377,
      "grad_norm": 0.16258525848388672,
      "learning_rate": 8.750746650738117e-06,
      "loss": 0.0016,
      "step": 96680
    },
    {
      "epoch": 8.250703984981653,
      "grad_norm": 0.25409629940986633,
      "learning_rate": 8.746480075091731e-06,
      "loss": 0.002,
      "step": 96690
    },
    {
      "epoch": 8.251557300110932,
      "grad_norm": 0.06452838331460953,
      "learning_rate": 8.742213499445345e-06,
      "loss": 0.0021,
      "step": 96700
    },
    {
      "epoch": 8.252410615240208,
      "grad_norm": 0.21307486295700073,
      "learning_rate": 8.73794692379896e-06,
      "loss": 0.0016,
      "step": 96710
    },
    {
      "epoch": 8.253263930369485,
      "grad_norm": 0.09418952465057373,
      "learning_rate": 8.733680348152574e-06,
      "loss": 0.0019,
      "step": 96720
    },
    {
      "epoch": 8.254117245498763,
      "grad_norm": 0.09549827873706818,
      "learning_rate": 8.729413772506186e-06,
      "loss": 0.0015,
      "step": 96730
    },
    {
      "epoch": 8.25497056062804,
      "grad_norm": 0.10026756674051285,
      "learning_rate": 8.7251471968598e-06,
      "loss": 0.0018,
      "step": 96740
    },
    {
      "epoch": 8.255823875757317,
      "grad_norm": 0.26153573393821716,
      "learning_rate": 8.720880621213415e-06,
      "loss": 0.0018,
      "step": 96750
    },
    {
      "epoch": 8.256677190886595,
      "grad_norm": 0.09332721680402756,
      "learning_rate": 8.716614045567029e-06,
      "loss": 0.0017,
      "step": 96760
    },
    {
      "epoch": 8.257530506015872,
      "grad_norm": 0.21524569392204285,
      "learning_rate": 8.712347469920643e-06,
      "loss": 0.0017,
      "step": 96770
    },
    {
      "epoch": 8.258383821145149,
      "grad_norm": 0.25236383080482483,
      "learning_rate": 8.708080894274256e-06,
      "loss": 0.0014,
      "step": 96780
    },
    {
      "epoch": 8.259237136274425,
      "grad_norm": 0.11179804801940918,
      "learning_rate": 8.70381431862787e-06,
      "loss": 0.0017,
      "step": 96790
    },
    {
      "epoch": 8.260090451403704,
      "grad_norm": 0.26792651414871216,
      "learning_rate": 8.699547742981483e-06,
      "loss": 0.0016,
      "step": 96800
    },
    {
      "epoch": 8.26094376653298,
      "grad_norm": 0.2886270582675934,
      "learning_rate": 8.695281167335097e-06,
      "loss": 0.0017,
      "step": 96810
    },
    {
      "epoch": 8.261797081662257,
      "grad_norm": 0.20247915387153625,
      "learning_rate": 8.691014591688711e-06,
      "loss": 0.002,
      "step": 96820
    },
    {
      "epoch": 8.262650396791535,
      "grad_norm": 0.16196471452713013,
      "learning_rate": 8.686748016042325e-06,
      "loss": 0.0018,
      "step": 96830
    },
    {
      "epoch": 8.263503711920812,
      "grad_norm": 0.04666252061724663,
      "learning_rate": 8.682481440395938e-06,
      "loss": 0.0019,
      "step": 96840
    },
    {
      "epoch": 8.264357027050089,
      "grad_norm": 0.20058780908584595,
      "learning_rate": 8.678214864749552e-06,
      "loss": 0.0013,
      "step": 96850
    },
    {
      "epoch": 8.265210342179367,
      "grad_norm": 0.12906253337860107,
      "learning_rate": 8.673948289103166e-06,
      "loss": 0.0017,
      "step": 96860
    },
    {
      "epoch": 8.266063657308644,
      "grad_norm": 0.031323764473199844,
      "learning_rate": 8.66968171345678e-06,
      "loss": 0.0022,
      "step": 96870
    },
    {
      "epoch": 8.26691697243792,
      "grad_norm": 0.04844054952263832,
      "learning_rate": 8.665415137810395e-06,
      "loss": 0.0018,
      "step": 96880
    },
    {
      "epoch": 8.267770287567199,
      "grad_norm": 0.13261336088180542,
      "learning_rate": 8.661148562164007e-06,
      "loss": 0.0017,
      "step": 96890
    },
    {
      "epoch": 8.268623602696476,
      "grad_norm": 0.030666228383779526,
      "learning_rate": 8.656881986517622e-06,
      "loss": 0.0014,
      "step": 96900
    },
    {
      "epoch": 8.269476917825752,
      "grad_norm": 0.025201009586453438,
      "learning_rate": 8.652615410871236e-06,
      "loss": 0.0015,
      "step": 96910
    },
    {
      "epoch": 8.27033023295503,
      "grad_norm": 0.14647451043128967,
      "learning_rate": 8.64834883522485e-06,
      "loss": 0.0019,
      "step": 96920
    },
    {
      "epoch": 8.271183548084307,
      "grad_norm": 0.04982050880789757,
      "learning_rate": 8.644082259578463e-06,
      "loss": 0.0019,
      "step": 96930
    },
    {
      "epoch": 8.272036863213584,
      "grad_norm": 0.1805916130542755,
      "learning_rate": 8.639815683932075e-06,
      "loss": 0.0013,
      "step": 96940
    },
    {
      "epoch": 8.272890178342863,
      "grad_norm": 0.10846691578626633,
      "learning_rate": 8.63554910828569e-06,
      "loss": 0.0017,
      "step": 96950
    },
    {
      "epoch": 8.27374349347214,
      "grad_norm": 0.31643420457839966,
      "learning_rate": 8.631282532639304e-06,
      "loss": 0.0019,
      "step": 96960
    },
    {
      "epoch": 8.274596808601416,
      "grad_norm": 0.1821107566356659,
      "learning_rate": 8.627015956992918e-06,
      "loss": 0.0015,
      "step": 96970
    },
    {
      "epoch": 8.275450123730694,
      "grad_norm": 0.04261651635169983,
      "learning_rate": 8.622749381346532e-06,
      "loss": 0.0016,
      "step": 96980
    },
    {
      "epoch": 8.276303438859971,
      "grad_norm": 0.047379136085510254,
      "learning_rate": 8.618482805700145e-06,
      "loss": 0.0014,
      "step": 96990
    },
    {
      "epoch": 8.277156753989248,
      "grad_norm": 0.2598477005958557,
      "learning_rate": 8.614216230053759e-06,
      "loss": 0.0015,
      "step": 97000
    },
    {
      "epoch": 8.278010069118526,
      "grad_norm": 0.045052360743284225,
      "learning_rate": 8.609949654407373e-06,
      "loss": 0.0015,
      "step": 97010
    },
    {
      "epoch": 8.278863384247803,
      "grad_norm": 0.0558871366083622,
      "learning_rate": 8.605683078760987e-06,
      "loss": 0.0017,
      "step": 97020
    },
    {
      "epoch": 8.27971669937708,
      "grad_norm": 0.34791409969329834,
      "learning_rate": 8.601416503114602e-06,
      "loss": 0.0023,
      "step": 97030
    },
    {
      "epoch": 8.280570014506358,
      "grad_norm": 0.16214582324028015,
      "learning_rate": 8.597149927468214e-06,
      "loss": 0.0014,
      "step": 97040
    },
    {
      "epoch": 8.281423329635635,
      "grad_norm": 0.04238729923963547,
      "learning_rate": 8.592883351821828e-06,
      "loss": 0.0014,
      "step": 97050
    },
    {
      "epoch": 8.282276644764911,
      "grad_norm": 0.09191526472568512,
      "learning_rate": 8.588616776175443e-06,
      "loss": 0.0015,
      "step": 97060
    },
    {
      "epoch": 8.28312995989419,
      "grad_norm": 0.3288666903972626,
      "learning_rate": 8.584350200529055e-06,
      "loss": 0.0018,
      "step": 97070
    },
    {
      "epoch": 8.283983275023466,
      "grad_norm": 0.17889843881130219,
      "learning_rate": 8.58008362488267e-06,
      "loss": 0.0016,
      "step": 97080
    },
    {
      "epoch": 8.284836590152743,
      "grad_norm": 0.1712614744901657,
      "learning_rate": 8.575817049236284e-06,
      "loss": 0.0018,
      "step": 97090
    },
    {
      "epoch": 8.285689905282021,
      "grad_norm": 0.17694517970085144,
      "learning_rate": 8.571550473589896e-06,
      "loss": 0.0019,
      "step": 97100
    },
    {
      "epoch": 8.286543220411298,
      "grad_norm": 0.19421540200710297,
      "learning_rate": 8.56728389794351e-06,
      "loss": 0.0016,
      "step": 97110
    },
    {
      "epoch": 8.287396535540575,
      "grad_norm": 0.12010224163532257,
      "learning_rate": 8.563017322297125e-06,
      "loss": 0.0014,
      "step": 97120
    },
    {
      "epoch": 8.288249850669853,
      "grad_norm": 0.07640041410923004,
      "learning_rate": 8.558750746650739e-06,
      "loss": 0.0018,
      "step": 97130
    },
    {
      "epoch": 8.28910316579913,
      "grad_norm": 0.04364918917417526,
      "learning_rate": 8.554484171004353e-06,
      "loss": 0.0018,
      "step": 97140
    },
    {
      "epoch": 8.289956480928407,
      "grad_norm": 0.08022664487361908,
      "learning_rate": 8.550217595357966e-06,
      "loss": 0.0012,
      "step": 97150
    },
    {
      "epoch": 8.290809796057683,
      "grad_norm": 0.12898045778274536,
      "learning_rate": 8.54595101971158e-06,
      "loss": 0.0017,
      "step": 97160
    },
    {
      "epoch": 8.291663111186962,
      "grad_norm": 0.07798030972480774,
      "learning_rate": 8.541684444065194e-06,
      "loss": 0.0017,
      "step": 97170
    },
    {
      "epoch": 8.292516426316238,
      "grad_norm": 0.3112417757511139,
      "learning_rate": 8.537417868418808e-06,
      "loss": 0.0016,
      "step": 97180
    },
    {
      "epoch": 8.293369741445515,
      "grad_norm": 0.19944153726100922,
      "learning_rate": 8.533151292772423e-06,
      "loss": 0.0015,
      "step": 97190
    },
    {
      "epoch": 8.294223056574793,
      "grad_norm": 0.04012501984834671,
      "learning_rate": 8.528884717126035e-06,
      "loss": 0.0019,
      "step": 97200
    },
    {
      "epoch": 8.29507637170407,
      "grad_norm": 0.29512321949005127,
      "learning_rate": 8.524618141479648e-06,
      "loss": 0.0019,
      "step": 97210
    },
    {
      "epoch": 8.295929686833347,
      "grad_norm": 0.1806267499923706,
      "learning_rate": 8.520351565833262e-06,
      "loss": 0.0019,
      "step": 97220
    },
    {
      "epoch": 8.296783001962625,
      "grad_norm": 0.25673022866249084,
      "learning_rate": 8.516084990186876e-06,
      "loss": 0.0018,
      "step": 97230
    },
    {
      "epoch": 8.297636317091902,
      "grad_norm": 0.025917891412973404,
      "learning_rate": 8.51181841454049e-06,
      "loss": 0.0015,
      "step": 97240
    },
    {
      "epoch": 8.298489632221179,
      "grad_norm": 0.14652617275714874,
      "learning_rate": 8.507551838894103e-06,
      "loss": 0.0013,
      "step": 97250
    },
    {
      "epoch": 8.299342947350457,
      "grad_norm": 0.11419884115457535,
      "learning_rate": 8.503285263247717e-06,
      "loss": 0.0018,
      "step": 97260
    },
    {
      "epoch": 8.300196262479734,
      "grad_norm": 0.16476620733737946,
      "learning_rate": 8.499018687601332e-06,
      "loss": 0.0016,
      "step": 97270
    },
    {
      "epoch": 8.30104957760901,
      "grad_norm": 0.1514216810464859,
      "learning_rate": 8.494752111954946e-06,
      "loss": 0.0018,
      "step": 97280
    },
    {
      "epoch": 8.301902892738289,
      "grad_norm": 0.10788601636886597,
      "learning_rate": 8.49048553630856e-06,
      "loss": 0.0017,
      "step": 97290
    },
    {
      "epoch": 8.302756207867565,
      "grad_norm": 0.2545270025730133,
      "learning_rate": 8.486218960662173e-06,
      "loss": 0.0014,
      "step": 97300
    },
    {
      "epoch": 8.303609522996842,
      "grad_norm": 0.1323642134666443,
      "learning_rate": 8.481952385015787e-06,
      "loss": 0.0016,
      "step": 97310
    },
    {
      "epoch": 8.30446283812612,
      "grad_norm": 0.043440286070108414,
      "learning_rate": 8.477685809369401e-06,
      "loss": 0.0019,
      "step": 97320
    },
    {
      "epoch": 8.305316153255397,
      "grad_norm": 0.0697031170129776,
      "learning_rate": 8.473419233723014e-06,
      "loss": 0.0014,
      "step": 97330
    },
    {
      "epoch": 8.306169468384674,
      "grad_norm": 0.09940479695796967,
      "learning_rate": 8.469152658076628e-06,
      "loss": 0.0016,
      "step": 97340
    },
    {
      "epoch": 8.307022783513952,
      "grad_norm": 0.03112751618027687,
      "learning_rate": 8.464886082430242e-06,
      "loss": 0.0014,
      "step": 97350
    },
    {
      "epoch": 8.307876098643229,
      "grad_norm": 0.2704978287220001,
      "learning_rate": 8.460619506783855e-06,
      "loss": 0.0017,
      "step": 97360
    },
    {
      "epoch": 8.308729413772506,
      "grad_norm": 0.04532811790704727,
      "learning_rate": 8.456352931137469e-06,
      "loss": 0.0015,
      "step": 97370
    },
    {
      "epoch": 8.309582728901784,
      "grad_norm": 0.25766220688819885,
      "learning_rate": 8.452086355491083e-06,
      "loss": 0.0017,
      "step": 97380
    },
    {
      "epoch": 8.31043604403106,
      "grad_norm": 0.13192464411258698,
      "learning_rate": 8.447819779844697e-06,
      "loss": 0.0018,
      "step": 97390
    },
    {
      "epoch": 8.311289359160337,
      "grad_norm": 0.23518013954162598,
      "learning_rate": 8.443553204198312e-06,
      "loss": 0.0016,
      "step": 97400
    },
    {
      "epoch": 8.312142674289616,
      "grad_norm": 0.0989605113863945,
      "learning_rate": 8.439286628551924e-06,
      "loss": 0.0014,
      "step": 97410
    },
    {
      "epoch": 8.312995989418893,
      "grad_norm": 0.14161884784698486,
      "learning_rate": 8.435020052905538e-06,
      "loss": 0.0016,
      "step": 97420
    },
    {
      "epoch": 8.31384930454817,
      "grad_norm": 0.11197537183761597,
      "learning_rate": 8.430753477259153e-06,
      "loss": 0.0013,
      "step": 97430
    },
    {
      "epoch": 8.314702619677448,
      "grad_norm": 0.21167819201946259,
      "learning_rate": 8.426486901612767e-06,
      "loss": 0.0019,
      "step": 97440
    },
    {
      "epoch": 8.315555934806724,
      "grad_norm": 0.34218987822532654,
      "learning_rate": 8.422220325966381e-06,
      "loss": 0.0014,
      "step": 97450
    },
    {
      "epoch": 8.316409249936001,
      "grad_norm": 0.1846248060464859,
      "learning_rate": 8.417953750319994e-06,
      "loss": 0.0018,
      "step": 97460
    },
    {
      "epoch": 8.31726256506528,
      "grad_norm": 0.2899496257305145,
      "learning_rate": 8.413687174673606e-06,
      "loss": 0.0016,
      "step": 97470
    },
    {
      "epoch": 8.318115880194556,
      "grad_norm": 0.08447638154029846,
      "learning_rate": 8.40942059902722e-06,
      "loss": 0.0016,
      "step": 97480
    },
    {
      "epoch": 8.318969195323833,
      "grad_norm": 0.07645200937986374,
      "learning_rate": 8.405154023380835e-06,
      "loss": 0.0015,
      "step": 97490
    },
    {
      "epoch": 8.319822510453111,
      "grad_norm": 0.04265627637505531,
      "learning_rate": 8.400887447734449e-06,
      "loss": 0.0014,
      "step": 97500
    },
    {
      "epoch": 8.320675825582388,
      "grad_norm": 0.25948596000671387,
      "learning_rate": 8.396620872088063e-06,
      "loss": 0.0019,
      "step": 97510
    },
    {
      "epoch": 8.321529140711664,
      "grad_norm": 0.23338867723941803,
      "learning_rate": 8.392354296441676e-06,
      "loss": 0.0017,
      "step": 97520
    },
    {
      "epoch": 8.322382455840941,
      "grad_norm": 0.21050699055194855,
      "learning_rate": 8.38808772079529e-06,
      "loss": 0.0016,
      "step": 97530
    },
    {
      "epoch": 8.32323577097022,
      "grad_norm": 0.052935849875211716,
      "learning_rate": 8.383821145148904e-06,
      "loss": 0.0014,
      "step": 97540
    },
    {
      "epoch": 8.324089086099496,
      "grad_norm": 0.09252581000328064,
      "learning_rate": 8.379554569502518e-06,
      "loss": 0.0014,
      "step": 97550
    },
    {
      "epoch": 8.324942401228773,
      "grad_norm": 0.17102250456809998,
      "learning_rate": 8.375287993856133e-06,
      "loss": 0.0016,
      "step": 97560
    },
    {
      "epoch": 8.325795716358051,
      "grad_norm": 0.2551930248737335,
      "learning_rate": 8.371021418209745e-06,
      "loss": 0.0012,
      "step": 97570
    },
    {
      "epoch": 8.326649031487328,
      "grad_norm": 0.08000440895557404,
      "learning_rate": 8.36675484256336e-06,
      "loss": 0.0019,
      "step": 97580
    },
    {
      "epoch": 8.327502346616605,
      "grad_norm": 0.35939472913742065,
      "learning_rate": 8.362488266916974e-06,
      "loss": 0.0014,
      "step": 97590
    },
    {
      "epoch": 8.328355661745883,
      "grad_norm": 0.03812163323163986,
      "learning_rate": 8.358221691270586e-06,
      "loss": 0.0017,
      "step": 97600
    },
    {
      "epoch": 8.32920897687516,
      "grad_norm": 0.20621028542518616,
      "learning_rate": 8.3539551156242e-06,
      "loss": 0.0016,
      "step": 97610
    },
    {
      "epoch": 8.330062292004436,
      "grad_norm": 0.19535361230373383,
      "learning_rate": 8.349688539977813e-06,
      "loss": 0.0016,
      "step": 97620
    },
    {
      "epoch": 8.330915607133715,
      "grad_norm": 0.05734687298536301,
      "learning_rate": 8.345421964331427e-06,
      "loss": 0.0014,
      "step": 97630
    },
    {
      "epoch": 8.331768922262992,
      "grad_norm": 0.09811951965093613,
      "learning_rate": 8.341155388685042e-06,
      "loss": 0.0014,
      "step": 97640
    },
    {
      "epoch": 8.332622237392268,
      "grad_norm": 0.11080464720726013,
      "learning_rate": 8.336888813038656e-06,
      "loss": 0.0013,
      "step": 97650
    },
    {
      "epoch": 8.333475552521547,
      "grad_norm": 0.16674095392227173,
      "learning_rate": 8.33262223739227e-06,
      "loss": 0.0017,
      "step": 97660
    },
    {
      "epoch": 8.334328867650823,
      "grad_norm": 0.2808500826358795,
      "learning_rate": 8.328355661745883e-06,
      "loss": 0.0019,
      "step": 97670
    },
    {
      "epoch": 8.3351821827801,
      "grad_norm": 0.23655374348163605,
      "learning_rate": 8.324089086099497e-06,
      "loss": 0.0017,
      "step": 97680
    },
    {
      "epoch": 8.336035497909378,
      "grad_norm": 0.2691831588745117,
      "learning_rate": 8.319822510453111e-06,
      "loss": 0.0016,
      "step": 97690
    },
    {
      "epoch": 8.336888813038655,
      "grad_norm": 0.17905911803245544,
      "learning_rate": 8.315555934806725e-06,
      "loss": 0.0017,
      "step": 97700
    },
    {
      "epoch": 8.337742128167932,
      "grad_norm": 0.28468066453933716,
      "learning_rate": 8.31128935916034e-06,
      "loss": 0.0015,
      "step": 97710
    },
    {
      "epoch": 8.33859544329721,
      "grad_norm": 0.08183185756206512,
      "learning_rate": 8.307022783513952e-06,
      "loss": 0.0015,
      "step": 97720
    },
    {
      "epoch": 8.339448758426487,
      "grad_norm": 0.14204809069633484,
      "learning_rate": 8.302756207867565e-06,
      "loss": 0.0016,
      "step": 97730
    },
    {
      "epoch": 8.340302073555764,
      "grad_norm": 0.18873198330402374,
      "learning_rate": 8.298489632221179e-06,
      "loss": 0.002,
      "step": 97740
    },
    {
      "epoch": 8.341155388685042,
      "grad_norm": 0.075029157102108,
      "learning_rate": 8.294223056574793e-06,
      "loss": 0.0014,
      "step": 97750
    },
    {
      "epoch": 8.342008703814319,
      "grad_norm": 0.14463965594768524,
      "learning_rate": 8.289956480928407e-06,
      "loss": 0.0018,
      "step": 97760
    },
    {
      "epoch": 8.342862018943595,
      "grad_norm": 0.20515184104442596,
      "learning_rate": 8.285689905282022e-06,
      "loss": 0.0015,
      "step": 97770
    },
    {
      "epoch": 8.343715334072874,
      "grad_norm": 0.23618091642856598,
      "learning_rate": 8.281423329635634e-06,
      "loss": 0.0017,
      "step": 97780
    },
    {
      "epoch": 8.34456864920215,
      "grad_norm": 0.25084513425827026,
      "learning_rate": 8.277156753989248e-06,
      "loss": 0.0014,
      "step": 97790
    },
    {
      "epoch": 8.345421964331427,
      "grad_norm": 0.14806684851646423,
      "learning_rate": 8.272890178342863e-06,
      "loss": 0.0023,
      "step": 97800
    },
    {
      "epoch": 8.346275279460706,
      "grad_norm": 0.05851811170578003,
      "learning_rate": 8.268623602696477e-06,
      "loss": 0.0018,
      "step": 97810
    },
    {
      "epoch": 8.347128594589982,
      "grad_norm": 0.2878402769565582,
      "learning_rate": 8.264357027050091e-06,
      "loss": 0.0016,
      "step": 97820
    },
    {
      "epoch": 8.347981909719259,
      "grad_norm": 0.040126506239175797,
      "learning_rate": 8.260090451403704e-06,
      "loss": 0.0019,
      "step": 97830
    },
    {
      "epoch": 8.348835224848537,
      "grad_norm": 0.1366320699453354,
      "learning_rate": 8.255823875757318e-06,
      "loss": 0.0016,
      "step": 97840
    },
    {
      "epoch": 8.349688539977814,
      "grad_norm": 0.11880335956811905,
      "learning_rate": 8.251557300110932e-06,
      "loss": 0.0013,
      "step": 97850
    },
    {
      "epoch": 8.35054185510709,
      "grad_norm": 0.07942671328783035,
      "learning_rate": 8.247290724464545e-06,
      "loss": 0.0019,
      "step": 97860
    },
    {
      "epoch": 8.35139517023637,
      "grad_norm": 0.34655600786209106,
      "learning_rate": 8.243024148818159e-06,
      "loss": 0.0017,
      "step": 97870
    },
    {
      "epoch": 8.352248485365646,
      "grad_norm": 0.030622076243162155,
      "learning_rate": 8.238757573171771e-06,
      "loss": 0.0013,
      "step": 97880
    },
    {
      "epoch": 8.353101800494922,
      "grad_norm": 0.14519111812114716,
      "learning_rate": 8.234490997525386e-06,
      "loss": 0.0016,
      "step": 97890
    },
    {
      "epoch": 8.3539551156242,
      "grad_norm": 0.30989280343055725,
      "learning_rate": 8.230224421879e-06,
      "loss": 0.0016,
      "step": 97900
    },
    {
      "epoch": 8.354808430753478,
      "grad_norm": 0.0912465751171112,
      "learning_rate": 8.225957846232614e-06,
      "loss": 0.0018,
      "step": 97910
    },
    {
      "epoch": 8.355661745882754,
      "grad_norm": 0.34140822291374207,
      "learning_rate": 8.221691270586228e-06,
      "loss": 0.002,
      "step": 97920
    },
    {
      "epoch": 8.356515061012031,
      "grad_norm": 0.14912542700767517,
      "learning_rate": 8.217424694939841e-06,
      "loss": 0.0018,
      "step": 97930
    },
    {
      "epoch": 8.35736837614131,
      "grad_norm": 0.09156814217567444,
      "learning_rate": 8.213158119293455e-06,
      "loss": 0.0017,
      "step": 97940
    },
    {
      "epoch": 8.358221691270586,
      "grad_norm": 0.2702191472053528,
      "learning_rate": 8.20889154364707e-06,
      "loss": 0.0017,
      "step": 97950
    },
    {
      "epoch": 8.359075006399863,
      "grad_norm": 0.038936130702495575,
      "learning_rate": 8.204624968000684e-06,
      "loss": 0.0017,
      "step": 97960
    },
    {
      "epoch": 8.359928321529141,
      "grad_norm": 0.03044864907860756,
      "learning_rate": 8.200358392354298e-06,
      "loss": 0.0016,
      "step": 97970
    },
    {
      "epoch": 8.360781636658418,
      "grad_norm": 0.1991308182477951,
      "learning_rate": 8.19609181670791e-06,
      "loss": 0.0016,
      "step": 97980
    },
    {
      "epoch": 8.361634951787694,
      "grad_norm": 0.09309925884008408,
      "learning_rate": 8.191825241061525e-06,
      "loss": 0.0017,
      "step": 97990
    },
    {
      "epoch": 8.362488266916973,
      "grad_norm": 0.17248280346393585,
      "learning_rate": 8.187558665415137e-06,
      "loss": 0.0016,
      "step": 98000
    },
    {
      "epoch": 8.36334158204625,
      "grad_norm": 0.11888197809457779,
      "learning_rate": 8.183292089768751e-06,
      "loss": 0.0019,
      "step": 98010
    },
    {
      "epoch": 8.364194897175526,
      "grad_norm": 0.4884885549545288,
      "learning_rate": 8.179025514122366e-06,
      "loss": 0.0018,
      "step": 98020
    },
    {
      "epoch": 8.365048212304805,
      "grad_norm": 0.08865911513566971,
      "learning_rate": 8.17475893847598e-06,
      "loss": 0.0017,
      "step": 98030
    },
    {
      "epoch": 8.365901527434081,
      "grad_norm": 0.05010681599378586,
      "learning_rate": 8.170492362829593e-06,
      "loss": 0.0016,
      "step": 98040
    },
    {
      "epoch": 8.366754842563358,
      "grad_norm": 0.1461498737335205,
      "learning_rate": 8.166225787183207e-06,
      "loss": 0.0016,
      "step": 98050
    },
    {
      "epoch": 8.367608157692636,
      "grad_norm": 0.0950058177113533,
      "learning_rate": 8.161959211536821e-06,
      "loss": 0.0018,
      "step": 98060
    },
    {
      "epoch": 8.368461472821913,
      "grad_norm": 0.27453434467315674,
      "learning_rate": 8.157692635890435e-06,
      "loss": 0.0017,
      "step": 98070
    },
    {
      "epoch": 8.36931478795119,
      "grad_norm": 0.03194036707282066,
      "learning_rate": 8.15342606024405e-06,
      "loss": 0.0018,
      "step": 98080
    },
    {
      "epoch": 8.370168103080468,
      "grad_norm": 0.1895347535610199,
      "learning_rate": 8.149159484597662e-06,
      "loss": 0.0013,
      "step": 98090
    },
    {
      "epoch": 8.371021418209745,
      "grad_norm": 0.14605358242988586,
      "learning_rate": 8.144892908951276e-06,
      "loss": 0.0013,
      "step": 98100
    },
    {
      "epoch": 8.371874733339022,
      "grad_norm": 0.15000076591968536,
      "learning_rate": 8.14062633330489e-06,
      "loss": 0.0018,
      "step": 98110
    },
    {
      "epoch": 8.3727280484683,
      "grad_norm": 0.13138367235660553,
      "learning_rate": 8.136359757658505e-06,
      "loss": 0.0019,
      "step": 98120
    },
    {
      "epoch": 8.373581363597577,
      "grad_norm": 0.3250514268875122,
      "learning_rate": 8.132093182012117e-06,
      "loss": 0.0015,
      "step": 98130
    },
    {
      "epoch": 8.374434678726853,
      "grad_norm": 0.10906260460615158,
      "learning_rate": 8.127826606365732e-06,
      "loss": 0.0016,
      "step": 98140
    },
    {
      "epoch": 8.375287993856132,
      "grad_norm": 0.16371729969978333,
      "learning_rate": 8.123560030719344e-06,
      "loss": 0.0016,
      "step": 98150
    },
    {
      "epoch": 8.376141308985408,
      "grad_norm": 0.2370309680700302,
      "learning_rate": 8.119293455072958e-06,
      "loss": 0.0018,
      "step": 98160
    },
    {
      "epoch": 8.376994624114685,
      "grad_norm": 0.2739167809486389,
      "learning_rate": 8.115026879426573e-06,
      "loss": 0.0018,
      "step": 98170
    },
    {
      "epoch": 8.377847939243964,
      "grad_norm": 0.030053505674004555,
      "learning_rate": 8.110760303780187e-06,
      "loss": 0.0019,
      "step": 98180
    },
    {
      "epoch": 8.37870125437324,
      "grad_norm": 0.058535605669021606,
      "learning_rate": 8.1064937281338e-06,
      "loss": 0.0018,
      "step": 98190
    },
    {
      "epoch": 8.379554569502517,
      "grad_norm": 0.19946719706058502,
      "learning_rate": 8.102227152487414e-06,
      "loss": 0.0017,
      "step": 98200
    },
    {
      "epoch": 8.380407884631795,
      "grad_norm": 0.18004722893238068,
      "learning_rate": 8.097960576841028e-06,
      "loss": 0.0015,
      "step": 98210
    },
    {
      "epoch": 8.381261199761072,
      "grad_norm": 0.11471474915742874,
      "learning_rate": 8.093694001194642e-06,
      "loss": 0.0015,
      "step": 98220
    },
    {
      "epoch": 8.382114514890349,
      "grad_norm": 0.09927948564291,
      "learning_rate": 8.089427425548256e-06,
      "loss": 0.0021,
      "step": 98230
    },
    {
      "epoch": 8.382967830019627,
      "grad_norm": 0.45240283012390137,
      "learning_rate": 8.085160849901869e-06,
      "loss": 0.0019,
      "step": 98240
    },
    {
      "epoch": 8.383821145148904,
      "grad_norm": 0.17814947664737701,
      "learning_rate": 8.080894274255483e-06,
      "loss": 0.0017,
      "step": 98250
    },
    {
      "epoch": 8.38467446027818,
      "grad_norm": 0.09517913311719894,
      "learning_rate": 8.076627698609096e-06,
      "loss": 0.0015,
      "step": 98260
    },
    {
      "epoch": 8.385527775407457,
      "grad_norm": 0.12285002321004868,
      "learning_rate": 8.07236112296271e-06,
      "loss": 0.0015,
      "step": 98270
    },
    {
      "epoch": 8.386381090536736,
      "grad_norm": 0.32903796434402466,
      "learning_rate": 8.068094547316324e-06,
      "loss": 0.0013,
      "step": 98280
    },
    {
      "epoch": 8.387234405666012,
      "grad_norm": 0.18969452381134033,
      "learning_rate": 8.063827971669938e-06,
      "loss": 0.0015,
      "step": 98290
    },
    {
      "epoch": 8.388087720795289,
      "grad_norm": 0.20497797429561615,
      "learning_rate": 8.059561396023551e-06,
      "loss": 0.0021,
      "step": 98300
    },
    {
      "epoch": 8.388941035924567,
      "grad_norm": 0.09976226836442947,
      "learning_rate": 8.055294820377165e-06,
      "loss": 0.0018,
      "step": 98310
    },
    {
      "epoch": 8.389794351053844,
      "grad_norm": 0.2732558250427246,
      "learning_rate": 8.05102824473078e-06,
      "loss": 0.0013,
      "step": 98320
    },
    {
      "epoch": 8.39064766618312,
      "grad_norm": 0.1544194370508194,
      "learning_rate": 8.046761669084394e-06,
      "loss": 0.0019,
      "step": 98330
    },
    {
      "epoch": 8.391500981312399,
      "grad_norm": 0.2725858688354492,
      "learning_rate": 8.042495093438008e-06,
      "loss": 0.0014,
      "step": 98340
    },
    {
      "epoch": 8.392354296441676,
      "grad_norm": 0.16265471279621124,
      "learning_rate": 8.03822851779162e-06,
      "loss": 0.0018,
      "step": 98350
    },
    {
      "epoch": 8.393207611570952,
      "grad_norm": 0.13109904527664185,
      "learning_rate": 8.033961942145235e-06,
      "loss": 0.0014,
      "step": 98360
    },
    {
      "epoch": 8.39406092670023,
      "grad_norm": 0.22079218924045563,
      "learning_rate": 8.029695366498849e-06,
      "loss": 0.0014,
      "step": 98370
    },
    {
      "epoch": 8.394914241829508,
      "grad_norm": 0.046548400074243546,
      "learning_rate": 8.025428790852463e-06,
      "loss": 0.0015,
      "step": 98380
    },
    {
      "epoch": 8.395767556958784,
      "grad_norm": 0.1805797666311264,
      "learning_rate": 8.021162215206076e-06,
      "loss": 0.0014,
      "step": 98390
    },
    {
      "epoch": 8.396620872088063,
      "grad_norm": 0.18391923606395721,
      "learning_rate": 8.01689563955969e-06,
      "loss": 0.0017,
      "step": 98400
    },
    {
      "epoch": 8.39747418721734,
      "grad_norm": 0.06406019628047943,
      "learning_rate": 8.012629063913303e-06,
      "loss": 0.0017,
      "step": 98410
    },
    {
      "epoch": 8.398327502346616,
      "grad_norm": 0.16824054718017578,
      "learning_rate": 8.008362488266917e-06,
      "loss": 0.002,
      "step": 98420
    },
    {
      "epoch": 8.399180817475894,
      "grad_norm": 0.18230675160884857,
      "learning_rate": 8.004095912620531e-06,
      "loss": 0.0015,
      "step": 98430
    },
    {
      "epoch": 8.400034132605171,
      "grad_norm": 0.043098412454128265,
      "learning_rate": 7.999829336974145e-06,
      "loss": 0.0013,
      "step": 98440
    },
    {
      "epoch": 8.400887447734448,
      "grad_norm": 0.11154785007238388,
      "learning_rate": 7.99556276132776e-06,
      "loss": 0.0015,
      "step": 98450
    },
    {
      "epoch": 8.401740762863726,
      "grad_norm": 0.09438829869031906,
      "learning_rate": 7.991296185681372e-06,
      "loss": 0.0016,
      "step": 98460
    },
    {
      "epoch": 8.402594077993003,
      "grad_norm": 0.2180795818567276,
      "learning_rate": 7.987029610034986e-06,
      "loss": 0.0018,
      "step": 98470
    },
    {
      "epoch": 8.40344739312228,
      "grad_norm": 0.1130048930644989,
      "learning_rate": 7.9827630343886e-06,
      "loss": 0.0016,
      "step": 98480
    },
    {
      "epoch": 8.404300708251558,
      "grad_norm": 0.12634333968162537,
      "learning_rate": 7.978496458742215e-06,
      "loss": 0.0014,
      "step": 98490
    },
    {
      "epoch": 8.405154023380835,
      "grad_norm": 0.06392276287078857,
      "learning_rate": 7.974229883095829e-06,
      "loss": 0.0021,
      "step": 98500
    },
    {
      "epoch": 8.406007338510111,
      "grad_norm": 0.1648326963186264,
      "learning_rate": 7.969963307449442e-06,
      "loss": 0.0016,
      "step": 98510
    },
    {
      "epoch": 8.40686065363939,
      "grad_norm": 0.05829308554530144,
      "learning_rate": 7.965696731803056e-06,
      "loss": 0.0018,
      "step": 98520
    },
    {
      "epoch": 8.407713968768666,
      "grad_norm": 0.13198944926261902,
      "learning_rate": 7.961430156156668e-06,
      "loss": 0.0021,
      "step": 98530
    },
    {
      "epoch": 8.408567283897943,
      "grad_norm": 0.0579066127538681,
      "learning_rate": 7.957163580510283e-06,
      "loss": 0.0019,
      "step": 98540
    },
    {
      "epoch": 8.409420599027221,
      "grad_norm": 0.2716411352157593,
      "learning_rate": 7.952897004863897e-06,
      "loss": 0.0017,
      "step": 98550
    },
    {
      "epoch": 8.410273914156498,
      "grad_norm": 0.13272592425346375,
      "learning_rate": 7.94863042921751e-06,
      "loss": 0.0018,
      "step": 98560
    },
    {
      "epoch": 8.411127229285775,
      "grad_norm": 0.0800410807132721,
      "learning_rate": 7.944363853571124e-06,
      "loss": 0.0015,
      "step": 98570
    },
    {
      "epoch": 8.411980544415053,
      "grad_norm": 0.1802118569612503,
      "learning_rate": 7.940097277924738e-06,
      "loss": 0.0018,
      "step": 98580
    },
    {
      "epoch": 8.41283385954433,
      "grad_norm": 0.09270554035902023,
      "learning_rate": 7.935830702278352e-06,
      "loss": 0.002,
      "step": 98590
    },
    {
      "epoch": 8.413687174673607,
      "grad_norm": 0.1442500352859497,
      "learning_rate": 7.931564126631966e-06,
      "loss": 0.0022,
      "step": 98600
    },
    {
      "epoch": 8.414540489802885,
      "grad_norm": 0.09610925614833832,
      "learning_rate": 7.927297550985579e-06,
      "loss": 0.0014,
      "step": 98610
    },
    {
      "epoch": 8.415393804932162,
      "grad_norm": 0.23761186003684998,
      "learning_rate": 7.923030975339193e-06,
      "loss": 0.002,
      "step": 98620
    },
    {
      "epoch": 8.416247120061438,
      "grad_norm": 0.20303975045681,
      "learning_rate": 7.918764399692807e-06,
      "loss": 0.002,
      "step": 98630
    },
    {
      "epoch": 8.417100435190715,
      "grad_norm": 0.083268903195858,
      "learning_rate": 7.914497824046422e-06,
      "loss": 0.0013,
      "step": 98640
    },
    {
      "epoch": 8.417953750319993,
      "grad_norm": 0.27112695574760437,
      "learning_rate": 7.910231248400036e-06,
      "loss": 0.0021,
      "step": 98650
    },
    {
      "epoch": 8.41880706544927,
      "grad_norm": 0.06251996010541916,
      "learning_rate": 7.905964672753648e-06,
      "loss": 0.0016,
      "step": 98660
    },
    {
      "epoch": 8.419660380578547,
      "grad_norm": 0.18133385479450226,
      "learning_rate": 7.901698097107261e-06,
      "loss": 0.0014,
      "step": 98670
    },
    {
      "epoch": 8.420513695707825,
      "grad_norm": 0.11335603147745132,
      "learning_rate": 7.897431521460875e-06,
      "loss": 0.002,
      "step": 98680
    },
    {
      "epoch": 8.421367010837102,
      "grad_norm": 0.12016838788986206,
      "learning_rate": 7.89316494581449e-06,
      "loss": 0.0015,
      "step": 98690
    },
    {
      "epoch": 8.422220325966379,
      "grad_norm": 0.15329359471797943,
      "learning_rate": 7.888898370168104e-06,
      "loss": 0.0016,
      "step": 98700
    },
    {
      "epoch": 8.423073641095657,
      "grad_norm": 0.1119343712925911,
      "learning_rate": 7.884631794521718e-06,
      "loss": 0.002,
      "step": 98710
    },
    {
      "epoch": 8.423926956224934,
      "grad_norm": 0.14885948598384857,
      "learning_rate": 7.88036521887533e-06,
      "loss": 0.0017,
      "step": 98720
    },
    {
      "epoch": 8.42478027135421,
      "grad_norm": 0.21637330949306488,
      "learning_rate": 7.876098643228945e-06,
      "loss": 0.0018,
      "step": 98730
    },
    {
      "epoch": 8.425633586483489,
      "grad_norm": 0.03349529206752777,
      "learning_rate": 7.871832067582559e-06,
      "loss": 0.002,
      "step": 98740
    },
    {
      "epoch": 8.426486901612765,
      "grad_norm": 0.23904524743556976,
      "learning_rate": 7.867565491936173e-06,
      "loss": 0.0016,
      "step": 98750
    },
    {
      "epoch": 8.427340216742042,
      "grad_norm": 0.2530941069126129,
      "learning_rate": 7.863298916289787e-06,
      "loss": 0.0015,
      "step": 98760
    },
    {
      "epoch": 8.42819353187132,
      "grad_norm": 0.288837194442749,
      "learning_rate": 7.8590323406434e-06,
      "loss": 0.0018,
      "step": 98770
    },
    {
      "epoch": 8.429046847000597,
      "grad_norm": 0.07488565146923065,
      "learning_rate": 7.854765764997014e-06,
      "loss": 0.0016,
      "step": 98780
    },
    {
      "epoch": 8.429900162129874,
      "grad_norm": 0.0780167281627655,
      "learning_rate": 7.850499189350627e-06,
      "loss": 0.0018,
      "step": 98790
    },
    {
      "epoch": 8.430753477259152,
      "grad_norm": 0.11430669575929642,
      "learning_rate": 7.846232613704241e-06,
      "loss": 0.0016,
      "step": 98800
    },
    {
      "epoch": 8.431606792388429,
      "grad_norm": 0.09417307376861572,
      "learning_rate": 7.841966038057855e-06,
      "loss": 0.0017,
      "step": 98810
    },
    {
      "epoch": 8.432460107517706,
      "grad_norm": 0.25461721420288086,
      "learning_rate": 7.837699462411468e-06,
      "loss": 0.0017,
      "step": 98820
    },
    {
      "epoch": 8.433313422646984,
      "grad_norm": 0.14940929412841797,
      "learning_rate": 7.833432886765082e-06,
      "loss": 0.0019,
      "step": 98830
    },
    {
      "epoch": 8.43416673777626,
      "grad_norm": 0.25152263045310974,
      "learning_rate": 7.829166311118696e-06,
      "loss": 0.0015,
      "step": 98840
    },
    {
      "epoch": 8.435020052905537,
      "grad_norm": 0.08093170076608658,
      "learning_rate": 7.82489973547231e-06,
      "loss": 0.0021,
      "step": 98850
    },
    {
      "epoch": 8.435873368034816,
      "grad_norm": 0.041722800582647324,
      "learning_rate": 7.820633159825925e-06,
      "loss": 0.0018,
      "step": 98860
    },
    {
      "epoch": 8.436726683164093,
      "grad_norm": 0.03558455780148506,
      "learning_rate": 7.816366584179537e-06,
      "loss": 0.0016,
      "step": 98870
    },
    {
      "epoch": 8.43757999829337,
      "grad_norm": 0.09447529166936874,
      "learning_rate": 7.812100008533151e-06,
      "loss": 0.0015,
      "step": 98880
    },
    {
      "epoch": 8.438433313422648,
      "grad_norm": 0.12886455655097961,
      "learning_rate": 7.807833432886766e-06,
      "loss": 0.0018,
      "step": 98890
    },
    {
      "epoch": 8.439286628551924,
      "grad_norm": 0.07407361268997192,
      "learning_rate": 7.80356685724038e-06,
      "loss": 0.0016,
      "step": 98900
    },
    {
      "epoch": 8.440139943681201,
      "grad_norm": 0.02024991437792778,
      "learning_rate": 7.799300281593994e-06,
      "loss": 0.0023,
      "step": 98910
    },
    {
      "epoch": 8.44099325881048,
      "grad_norm": 0.06611423939466476,
      "learning_rate": 7.795033705947607e-06,
      "loss": 0.0017,
      "step": 98920
    },
    {
      "epoch": 8.441846573939756,
      "grad_norm": 0.03022756241261959,
      "learning_rate": 7.79076713030122e-06,
      "loss": 0.0015,
      "step": 98930
    },
    {
      "epoch": 8.442699889069033,
      "grad_norm": 0.04369572922587395,
      "learning_rate": 7.786500554654834e-06,
      "loss": 0.0017,
      "step": 98940
    },
    {
      "epoch": 8.443553204198311,
      "grad_norm": 0.12995104491710663,
      "learning_rate": 7.782233979008448e-06,
      "loss": 0.0017,
      "step": 98950
    },
    {
      "epoch": 8.444406519327588,
      "grad_norm": 0.12960989773273468,
      "learning_rate": 7.777967403362062e-06,
      "loss": 0.0015,
      "step": 98960
    },
    {
      "epoch": 8.445259834456865,
      "grad_norm": 0.24346940219402313,
      "learning_rate": 7.773700827715676e-06,
      "loss": 0.0015,
      "step": 98970
    },
    {
      "epoch": 8.446113149586143,
      "grad_norm": 0.09787210822105408,
      "learning_rate": 7.769434252069289e-06,
      "loss": 0.0017,
      "step": 98980
    },
    {
      "epoch": 8.44696646471542,
      "grad_norm": 0.2408769726753235,
      "learning_rate": 7.765167676422903e-06,
      "loss": 0.0015,
      "step": 98990
    },
    {
      "epoch": 8.447819779844696,
      "grad_norm": 0.11250016838312149,
      "learning_rate": 7.760901100776517e-06,
      "loss": 0.0015,
      "step": 99000
    },
    {
      "epoch": 8.448673094973973,
      "grad_norm": 0.0791756734251976,
      "learning_rate": 7.756634525130132e-06,
      "loss": 0.0016,
      "step": 99010
    },
    {
      "epoch": 8.449526410103251,
      "grad_norm": 0.13821235299110413,
      "learning_rate": 7.752367949483746e-06,
      "loss": 0.0016,
      "step": 99020
    },
    {
      "epoch": 8.450379725232528,
      "grad_norm": 0.03708040341734886,
      "learning_rate": 7.748101373837358e-06,
      "loss": 0.002,
      "step": 99030
    },
    {
      "epoch": 8.451233040361805,
      "grad_norm": 0.1444728821516037,
      "learning_rate": 7.743834798190973e-06,
      "loss": 0.0015,
      "step": 99040
    },
    {
      "epoch": 8.452086355491083,
      "grad_norm": 0.3790609538555145,
      "learning_rate": 7.739568222544587e-06,
      "loss": 0.0012,
      "step": 99050
    },
    {
      "epoch": 8.45293967062036,
      "grad_norm": 0.21724405884742737,
      "learning_rate": 7.7353016468982e-06,
      "loss": 0.0015,
      "step": 99060
    },
    {
      "epoch": 8.453792985749637,
      "grad_norm": 0.15112794935703278,
      "learning_rate": 7.731035071251814e-06,
      "loss": 0.0016,
      "step": 99070
    },
    {
      "epoch": 8.454646300878915,
      "grad_norm": 0.4392084777355194,
      "learning_rate": 7.726768495605428e-06,
      "loss": 0.002,
      "step": 99080
    },
    {
      "epoch": 8.455499616008192,
      "grad_norm": 0.031463343650102615,
      "learning_rate": 7.72250191995904e-06,
      "loss": 0.0016,
      "step": 99090
    },
    {
      "epoch": 8.456352931137468,
      "grad_norm": 0.14563551545143127,
      "learning_rate": 7.718235344312655e-06,
      "loss": 0.0018,
      "step": 99100
    },
    {
      "epoch": 8.457206246266747,
      "grad_norm": 0.1445988118648529,
      "learning_rate": 7.713968768666269e-06,
      "loss": 0.0014,
      "step": 99110
    },
    {
      "epoch": 8.458059561396023,
      "grad_norm": 0.255601704120636,
      "learning_rate": 7.709702193019883e-06,
      "loss": 0.0016,
      "step": 99120
    },
    {
      "epoch": 8.4589128765253,
      "grad_norm": 0.16340802609920502,
      "learning_rate": 7.705435617373496e-06,
      "loss": 0.0015,
      "step": 99130
    },
    {
      "epoch": 8.459766191654579,
      "grad_norm": 0.031142698600888252,
      "learning_rate": 7.70116904172711e-06,
      "loss": 0.0013,
      "step": 99140
    },
    {
      "epoch": 8.460619506783855,
      "grad_norm": 0.2525557577610016,
      "learning_rate": 7.696902466080724e-06,
      "loss": 0.002,
      "step": 99150
    },
    {
      "epoch": 8.461472821913132,
      "grad_norm": 0.05581510439515114,
      "learning_rate": 7.692635890434338e-06,
      "loss": 0.0015,
      "step": 99160
    },
    {
      "epoch": 8.46232613704241,
      "grad_norm": 0.2214716523885727,
      "learning_rate": 7.688369314787953e-06,
      "loss": 0.0016,
      "step": 99170
    },
    {
      "epoch": 8.463179452171687,
      "grad_norm": 0.12563958764076233,
      "learning_rate": 7.684102739141565e-06,
      "loss": 0.0017,
      "step": 99180
    },
    {
      "epoch": 8.464032767300964,
      "grad_norm": 0.04687342792749405,
      "learning_rate": 7.679836163495178e-06,
      "loss": 0.0016,
      "step": 99190
    },
    {
      "epoch": 8.464886082430242,
      "grad_norm": 0.1264181286096573,
      "learning_rate": 7.675569587848792e-06,
      "loss": 0.0014,
      "step": 99200
    },
    {
      "epoch": 8.465739397559519,
      "grad_norm": 0.04829532653093338,
      "learning_rate": 7.671303012202406e-06,
      "loss": 0.0021,
      "step": 99210
    },
    {
      "epoch": 8.466592712688795,
      "grad_norm": 0.167469322681427,
      "learning_rate": 7.66703643655602e-06,
      "loss": 0.0022,
      "step": 99220
    },
    {
      "epoch": 8.467446027818074,
      "grad_norm": 0.2167326807975769,
      "learning_rate": 7.662769860909635e-06,
      "loss": 0.0015,
      "step": 99230
    },
    {
      "epoch": 8.46829934294735,
      "grad_norm": 0.024650830775499344,
      "learning_rate": 7.658503285263247e-06,
      "loss": 0.0016,
      "step": 99240
    },
    {
      "epoch": 8.469152658076627,
      "grad_norm": 0.09546882659196854,
      "learning_rate": 7.654236709616861e-06,
      "loss": 0.0019,
      "step": 99250
    },
    {
      "epoch": 8.470005973205906,
      "grad_norm": 0.11055727303028107,
      "learning_rate": 7.649970133970476e-06,
      "loss": 0.0015,
      "step": 99260
    },
    {
      "epoch": 8.470859288335182,
      "grad_norm": 0.17725923657417297,
      "learning_rate": 7.64570355832409e-06,
      "loss": 0.0013,
      "step": 99270
    },
    {
      "epoch": 8.471712603464459,
      "grad_norm": 0.14133501052856445,
      "learning_rate": 7.641436982677704e-06,
      "loss": 0.0016,
      "step": 99280
    },
    {
      "epoch": 8.472565918593737,
      "grad_norm": 0.4136943519115448,
      "learning_rate": 7.637170407031317e-06,
      "loss": 0.0017,
      "step": 99290
    },
    {
      "epoch": 8.473419233723014,
      "grad_norm": 0.40331509709358215,
      "learning_rate": 7.632903831384931e-06,
      "loss": 0.0017,
      "step": 99300
    },
    {
      "epoch": 8.47427254885229,
      "grad_norm": 0.08029808104038239,
      "learning_rate": 7.628637255738545e-06,
      "loss": 0.0019,
      "step": 99310
    },
    {
      "epoch": 8.47512586398157,
      "grad_norm": 0.02857520617544651,
      "learning_rate": 7.624370680092158e-06,
      "loss": 0.0016,
      "step": 99320
    },
    {
      "epoch": 8.475979179110846,
      "grad_norm": 0.1294681876897812,
      "learning_rate": 7.620104104445772e-06,
      "loss": 0.0015,
      "step": 99330
    },
    {
      "epoch": 8.476832494240123,
      "grad_norm": 0.09586594998836517,
      "learning_rate": 7.615837528799385e-06,
      "loss": 0.002,
      "step": 99340
    },
    {
      "epoch": 8.477685809369401,
      "grad_norm": 0.16613727807998657,
      "learning_rate": 7.611570953153e-06,
      "loss": 0.0018,
      "step": 99350
    },
    {
      "epoch": 8.478539124498678,
      "grad_norm": 0.06480619311332703,
      "learning_rate": 7.607304377506613e-06,
      "loss": 0.0016,
      "step": 99360
    },
    {
      "epoch": 8.479392439627954,
      "grad_norm": 0.0998338907957077,
      "learning_rate": 7.603037801860227e-06,
      "loss": 0.0015,
      "step": 99370
    },
    {
      "epoch": 8.480245754757231,
      "grad_norm": 0.12972602248191833,
      "learning_rate": 7.598771226213841e-06,
      "loss": 0.0017,
      "step": 99380
    },
    {
      "epoch": 8.48109906988651,
      "grad_norm": 0.04178467392921448,
      "learning_rate": 7.594504650567455e-06,
      "loss": 0.0014,
      "step": 99390
    },
    {
      "epoch": 8.481952385015786,
      "grad_norm": 0.12838242948055267,
      "learning_rate": 7.590238074921069e-06,
      "loss": 0.0015,
      "step": 99400
    },
    {
      "epoch": 8.482805700145063,
      "grad_norm": 0.035528600215911865,
      "learning_rate": 7.5859714992746826e-06,
      "loss": 0.0016,
      "step": 99410
    },
    {
      "epoch": 8.483659015274341,
      "grad_norm": 0.022243646904826164,
      "learning_rate": 7.581704923628297e-06,
      "loss": 0.0019,
      "step": 99420
    },
    {
      "epoch": 8.484512330403618,
      "grad_norm": 0.38082635402679443,
      "learning_rate": 7.57743834798191e-06,
      "loss": 0.0016,
      "step": 99430
    },
    {
      "epoch": 8.485365645532895,
      "grad_norm": 0.08239371329545975,
      "learning_rate": 7.5731717723355244e-06,
      "loss": 0.0019,
      "step": 99440
    },
    {
      "epoch": 8.486218960662173,
      "grad_norm": 0.03753150999546051,
      "learning_rate": 7.568905196689139e-06,
      "loss": 0.0018,
      "step": 99450
    },
    {
      "epoch": 8.48707227579145,
      "grad_norm": 0.28841203451156616,
      "learning_rate": 7.564638621042751e-06,
      "loss": 0.0019,
      "step": 99460
    },
    {
      "epoch": 8.487925590920726,
      "grad_norm": 0.13249345123767853,
      "learning_rate": 7.560372045396365e-06,
      "loss": 0.0017,
      "step": 99470
    },
    {
      "epoch": 8.488778906050005,
      "grad_norm": 0.21884416043758392,
      "learning_rate": 7.556105469749979e-06,
      "loss": 0.0017,
      "step": 99480
    },
    {
      "epoch": 8.489632221179281,
      "grad_norm": 0.1630828082561493,
      "learning_rate": 7.551838894103592e-06,
      "loss": 0.002,
      "step": 99490
    },
    {
      "epoch": 8.490485536308558,
      "grad_norm": 0.1140352115035057,
      "learning_rate": 7.5475723184572065e-06,
      "loss": 0.0014,
      "step": 99500
    },
    {
      "epoch": 8.491338851437837,
      "grad_norm": 0.1852796971797943,
      "learning_rate": 7.543305742810821e-06,
      "loss": 0.0019,
      "step": 99510
    },
    {
      "epoch": 8.492192166567113,
      "grad_norm": 0.09286794066429138,
      "learning_rate": 7.539039167164434e-06,
      "loss": 0.002,
      "step": 99520
    },
    {
      "epoch": 8.49304548169639,
      "grad_norm": 0.1630563884973526,
      "learning_rate": 7.534772591518048e-06,
      "loss": 0.0013,
      "step": 99530
    },
    {
      "epoch": 8.493898796825668,
      "grad_norm": 0.2662328779697418,
      "learning_rate": 7.530506015871662e-06,
      "loss": 0.0016,
      "step": 99540
    },
    {
      "epoch": 8.494752111954945,
      "grad_norm": 0.04636313021183014,
      "learning_rate": 7.526239440225276e-06,
      "loss": 0.0018,
      "step": 99550
    },
    {
      "epoch": 8.495605427084222,
      "grad_norm": 0.13303925096988678,
      "learning_rate": 7.521972864578889e-06,
      "loss": 0.0026,
      "step": 99560
    },
    {
      "epoch": 8.4964587422135,
      "grad_norm": 0.16727235913276672,
      "learning_rate": 7.517706288932504e-06,
      "loss": 0.0023,
      "step": 99570
    },
    {
      "epoch": 8.497312057342777,
      "grad_norm": 0.1151607483625412,
      "learning_rate": 7.513439713286118e-06,
      "loss": 0.0015,
      "step": 99580
    },
    {
      "epoch": 8.498165372472053,
      "grad_norm": 0.02810945175588131,
      "learning_rate": 7.50917313763973e-06,
      "loss": 0.0013,
      "step": 99590
    },
    {
      "epoch": 8.499018687601332,
      "grad_norm": 0.21775420010089874,
      "learning_rate": 7.504906561993344e-06,
      "loss": 0.0014,
      "step": 99600
    },
    {
      "epoch": 8.499872002730609,
      "grad_norm": 0.03351174667477608,
      "learning_rate": 7.500639986346958e-06,
      "loss": 0.0015,
      "step": 99610
    },
    {
      "epoch": 8.500725317859885,
      "grad_norm": 0.043562572449445724,
      "learning_rate": 7.4963734107005714e-06,
      "loss": 0.0013,
      "step": 99620
    },
    {
      "epoch": 8.501578632989164,
      "grad_norm": 0.03129452094435692,
      "learning_rate": 7.492106835054186e-06,
      "loss": 0.0016,
      "step": 99630
    },
    {
      "epoch": 8.50243194811844,
      "grad_norm": 0.058985304087400436,
      "learning_rate": 7.4878402594078e-06,
      "loss": 0.0015,
      "step": 99640
    },
    {
      "epoch": 8.503285263247717,
      "grad_norm": 0.22055484354496002,
      "learning_rate": 7.483573683761413e-06,
      "loss": 0.0014,
      "step": 99650
    },
    {
      "epoch": 8.504138578376995,
      "grad_norm": 0.053701817989349365,
      "learning_rate": 7.4793071081150276e-06,
      "loss": 0.0012,
      "step": 99660
    },
    {
      "epoch": 8.504991893506272,
      "grad_norm": 0.0825740322470665,
      "learning_rate": 7.475040532468641e-06,
      "loss": 0.0016,
      "step": 99670
    },
    {
      "epoch": 8.505845208635549,
      "grad_norm": 0.2374388873577118,
      "learning_rate": 7.470773956822255e-06,
      "loss": 0.0018,
      "step": 99680
    },
    {
      "epoch": 8.506698523764827,
      "grad_norm": 0.3592221736907959,
      "learning_rate": 7.466507381175869e-06,
      "loss": 0.0014,
      "step": 99690
    },
    {
      "epoch": 8.507551838894104,
      "grad_norm": 0.12956467270851135,
      "learning_rate": 7.462240805529483e-06,
      "loss": 0.0016,
      "step": 99700
    },
    {
      "epoch": 8.50840515402338,
      "grad_norm": 0.04698564112186432,
      "learning_rate": 7.457974229883097e-06,
      "loss": 0.0017,
      "step": 99710
    },
    {
      "epoch": 8.509258469152659,
      "grad_norm": 0.29016435146331787,
      "learning_rate": 7.45370765423671e-06,
      "loss": 0.0022,
      "step": 99720
    },
    {
      "epoch": 8.510111784281936,
      "grad_norm": 0.2545355260372162,
      "learning_rate": 7.449441078590323e-06,
      "loss": 0.0017,
      "step": 99730
    },
    {
      "epoch": 8.510965099411212,
      "grad_norm": 0.021117430180311203,
      "learning_rate": 7.445174502943937e-06,
      "loss": 0.0016,
      "step": 99740
    },
    {
      "epoch": 8.511818414540489,
      "grad_norm": 0.2067601978778839,
      "learning_rate": 7.440907927297551e-06,
      "loss": 0.0017,
      "step": 99750
    },
    {
      "epoch": 8.512671729669767,
      "grad_norm": 0.11542542278766632,
      "learning_rate": 7.436641351651165e-06,
      "loss": 0.0017,
      "step": 99760
    },
    {
      "epoch": 8.513525044799044,
      "grad_norm": 0.051460929214954376,
      "learning_rate": 7.432374776004779e-06,
      "loss": 0.0017,
      "step": 99770
    },
    {
      "epoch": 8.51437835992832,
      "grad_norm": 0.20959003269672394,
      "learning_rate": 7.4281082003583925e-06,
      "loss": 0.0016,
      "step": 99780
    },
    {
      "epoch": 8.5152316750576,
      "grad_norm": 0.18076148629188538,
      "learning_rate": 7.423841624712007e-06,
      "loss": 0.0018,
      "step": 99790
    },
    {
      "epoch": 8.516084990186876,
      "grad_norm": 0.041224464774131775,
      "learning_rate": 7.41957504906562e-06,
      "loss": 0.0015,
      "step": 99800
    },
    {
      "epoch": 8.516938305316152,
      "grad_norm": 0.22267605364322662,
      "learning_rate": 7.415308473419234e-06,
      "loss": 0.0015,
      "step": 99810
    },
    {
      "epoch": 8.517791620445431,
      "grad_norm": 0.20236121118068695,
      "learning_rate": 7.411041897772849e-06,
      "loss": 0.0021,
      "step": 99820
    },
    {
      "epoch": 8.518644935574708,
      "grad_norm": 0.08829551935195923,
      "learning_rate": 7.406775322126462e-06,
      "loss": 0.0019,
      "step": 99830
    },
    {
      "epoch": 8.519498250703984,
      "grad_norm": 0.04845435172319412,
      "learning_rate": 7.402508746480076e-06,
      "loss": 0.0016,
      "step": 99840
    },
    {
      "epoch": 8.520351565833263,
      "grad_norm": 0.24911370873451233,
      "learning_rate": 7.39824217083369e-06,
      "loss": 0.0014,
      "step": 99850
    },
    {
      "epoch": 8.52120488096254,
      "grad_norm": 0.04153693467378616,
      "learning_rate": 7.393975595187302e-06,
      "loss": 0.0018,
      "step": 99860
    },
    {
      "epoch": 8.522058196091816,
      "grad_norm": 0.11183496564626694,
      "learning_rate": 7.3897090195409165e-06,
      "loss": 0.0016,
      "step": 99870
    },
    {
      "epoch": 8.522911511221094,
      "grad_norm": 0.07954683899879456,
      "learning_rate": 7.38544244389453e-06,
      "loss": 0.0016,
      "step": 99880
    },
    {
      "epoch": 8.523764826350371,
      "grad_norm": 0.05968241021037102,
      "learning_rate": 7.381175868248144e-06,
      "loss": 0.0016,
      "step": 99890
    },
    {
      "epoch": 8.524618141479648,
      "grad_norm": 0.1293712854385376,
      "learning_rate": 7.376909292601758e-06,
      "loss": 0.002,
      "step": 99900
    },
    {
      "epoch": 8.525471456608926,
      "grad_norm": 0.20608744025230408,
      "learning_rate": 7.372642716955372e-06,
      "loss": 0.0015,
      "step": 99910
    },
    {
      "epoch": 8.526324771738203,
      "grad_norm": 0.062420669943094254,
      "learning_rate": 7.368376141308986e-06,
      "loss": 0.0015,
      "step": 99920
    },
    {
      "epoch": 8.52717808686748,
      "grad_norm": 0.3045506179332733,
      "learning_rate": 7.364109565662599e-06,
      "loss": 0.0014,
      "step": 99930
    },
    {
      "epoch": 8.528031401996758,
      "grad_norm": 0.13060224056243896,
      "learning_rate": 7.359842990016214e-06,
      "loss": 0.0017,
      "step": 99940
    },
    {
      "epoch": 8.528884717126035,
      "grad_norm": 0.18192102015018463,
      "learning_rate": 7.355576414369828e-06,
      "loss": 0.0018,
      "step": 99950
    },
    {
      "epoch": 8.529738032255311,
      "grad_norm": 0.22776859998703003,
      "learning_rate": 7.351309838723441e-06,
      "loss": 0.0015,
      "step": 99960
    },
    {
      "epoch": 8.53059134738459,
      "grad_norm": 0.1989087164402008,
      "learning_rate": 7.3470432630770555e-06,
      "loss": 0.0017,
      "step": 99970
    },
    {
      "epoch": 8.531444662513866,
      "grad_norm": 0.14856234192848206,
      "learning_rate": 7.342776687430669e-06,
      "loss": 0.0017,
      "step": 99980
    },
    {
      "epoch": 8.532297977643143,
      "grad_norm": 0.34873533248901367,
      "learning_rate": 7.338510111784281e-06,
      "loss": 0.0019,
      "step": 99990
    },
    {
      "epoch": 8.533151292772422,
      "grad_norm": 0.2953300476074219,
      "learning_rate": 7.334243536137896e-06,
      "loss": 0.0016,
      "step": 100000
    },
    {
      "epoch": 8.534004607901698,
      "grad_norm": 0.02919461391866207,
      "learning_rate": 7.329976960491509e-06,
      "loss": 0.0019,
      "step": 100010
    },
    {
      "epoch": 8.534857923030975,
      "grad_norm": 0.09451642632484436,
      "learning_rate": 7.325710384845123e-06,
      "loss": 0.0015,
      "step": 100020
    },
    {
      "epoch": 8.535711238160253,
      "grad_norm": 0.34261590242385864,
      "learning_rate": 7.3214438091987375e-06,
      "loss": 0.002,
      "step": 100030
    },
    {
      "epoch": 8.53656455328953,
      "grad_norm": 0.05479207634925842,
      "learning_rate": 7.317177233552351e-06,
      "loss": 0.0019,
      "step": 100040
    },
    {
      "epoch": 8.537417868418807,
      "grad_norm": 0.11350398510694504,
      "learning_rate": 7.312910657905965e-06,
      "loss": 0.0015,
      "step": 100050
    },
    {
      "epoch": 8.538271183548085,
      "grad_norm": 0.05704386532306671,
      "learning_rate": 7.3086440822595786e-06,
      "loss": 0.0018,
      "step": 100060
    },
    {
      "epoch": 8.539124498677362,
      "grad_norm": 0.21940556168556213,
      "learning_rate": 7.304377506613193e-06,
      "loss": 0.0017,
      "step": 100070
    },
    {
      "epoch": 8.539977813806638,
      "grad_norm": 0.0321519710123539,
      "learning_rate": 7.300110930966807e-06,
      "loss": 0.0015,
      "step": 100080
    },
    {
      "epoch": 8.540831128935917,
      "grad_norm": 0.07409744709730148,
      "learning_rate": 7.2958443553204204e-06,
      "loss": 0.0015,
      "step": 100090
    },
    {
      "epoch": 8.541684444065194,
      "grad_norm": 0.04633115231990814,
      "learning_rate": 7.291577779674035e-06,
      "loss": 0.0015,
      "step": 100100
    },
    {
      "epoch": 8.54253775919447,
      "grad_norm": 0.1431121826171875,
      "learning_rate": 7.287311204027648e-06,
      "loss": 0.0015,
      "step": 100110
    },
    {
      "epoch": 8.543391074323747,
      "grad_norm": 0.12771862745285034,
      "learning_rate": 7.283044628381261e-06,
      "loss": 0.0021,
      "step": 100120
    },
    {
      "epoch": 8.544244389453025,
      "grad_norm": 0.03932851180434227,
      "learning_rate": 7.278778052734875e-06,
      "loss": 0.0016,
      "step": 100130
    },
    {
      "epoch": 8.545097704582302,
      "grad_norm": 0.2001236230134964,
      "learning_rate": 7.274511477088488e-06,
      "loss": 0.0018,
      "step": 100140
    },
    {
      "epoch": 8.545951019711579,
      "grad_norm": 0.3295876681804657,
      "learning_rate": 7.2702449014421025e-06,
      "loss": 0.002,
      "step": 100150
    },
    {
      "epoch": 8.546804334840857,
      "grad_norm": 0.06850039213895798,
      "learning_rate": 7.265978325795717e-06,
      "loss": 0.0017,
      "step": 100160
    },
    {
      "epoch": 8.547657649970134,
      "grad_norm": 0.1804836243391037,
      "learning_rate": 7.26171175014933e-06,
      "loss": 0.0014,
      "step": 100170
    },
    {
      "epoch": 8.54851096509941,
      "grad_norm": 0.21690316498279572,
      "learning_rate": 7.257445174502944e-06,
      "loss": 0.0016,
      "step": 100180
    },
    {
      "epoch": 8.549364280228689,
      "grad_norm": 0.2715604603290558,
      "learning_rate": 7.253178598856558e-06,
      "loss": 0.0015,
      "step": 100190
    },
    {
      "epoch": 8.550217595357966,
      "grad_norm": 0.07511182129383087,
      "learning_rate": 7.248912023210172e-06,
      "loss": 0.0015,
      "step": 100200
    },
    {
      "epoch": 8.551070910487242,
      "grad_norm": 0.21972525119781494,
      "learning_rate": 7.244645447563786e-06,
      "loss": 0.0021,
      "step": 100210
    },
    {
      "epoch": 8.55192422561652,
      "grad_norm": 0.13389603793621063,
      "learning_rate": 7.2403788719174e-06,
      "loss": 0.0017,
      "step": 100220
    },
    {
      "epoch": 8.552777540745797,
      "grad_norm": 0.062272582203149796,
      "learning_rate": 7.236112296271014e-06,
      "loss": 0.0014,
      "step": 100230
    },
    {
      "epoch": 8.553630855875074,
      "grad_norm": 0.28488290309906006,
      "learning_rate": 7.231845720624627e-06,
      "loss": 0.0015,
      "step": 100240
    },
    {
      "epoch": 8.554484171004352,
      "grad_norm": 0.30485638976097107,
      "learning_rate": 7.22757914497824e-06,
      "loss": 0.0018,
      "step": 100250
    },
    {
      "epoch": 8.555337486133629,
      "grad_norm": 0.27044588327407837,
      "learning_rate": 7.223312569331854e-06,
      "loss": 0.002,
      "step": 100260
    },
    {
      "epoch": 8.556190801262906,
      "grad_norm": 0.12498639523983002,
      "learning_rate": 7.219045993685468e-06,
      "loss": 0.0022,
      "step": 100270
    },
    {
      "epoch": 8.557044116392184,
      "grad_norm": 0.09431377798318863,
      "learning_rate": 7.214779418039082e-06,
      "loss": 0.002,
      "step": 100280
    },
    {
      "epoch": 8.55789743152146,
      "grad_norm": 0.04998263716697693,
      "learning_rate": 7.210512842392696e-06,
      "loss": 0.0013,
      "step": 100290
    },
    {
      "epoch": 8.558750746650738,
      "grad_norm": 0.07789402455091476,
      "learning_rate": 7.206246266746309e-06,
      "loss": 0.0022,
      "step": 100300
    },
    {
      "epoch": 8.559604061780016,
      "grad_norm": 0.1834617555141449,
      "learning_rate": 7.201979691099924e-06,
      "loss": 0.0017,
      "step": 100310
    },
    {
      "epoch": 8.560457376909293,
      "grad_norm": 0.19893883168697357,
      "learning_rate": 7.197713115453537e-06,
      "loss": 0.002,
      "step": 100320
    },
    {
      "epoch": 8.56131069203857,
      "grad_norm": 0.0876474604010582,
      "learning_rate": 7.193446539807151e-06,
      "loss": 0.0014,
      "step": 100330
    },
    {
      "epoch": 8.562164007167848,
      "grad_norm": 0.3951658606529236,
      "learning_rate": 7.1891799641607655e-06,
      "loss": 0.0016,
      "step": 100340
    },
    {
      "epoch": 8.563017322297124,
      "grad_norm": 0.02849862538278103,
      "learning_rate": 7.184913388514379e-06,
      "loss": 0.002,
      "step": 100350
    },
    {
      "epoch": 8.563870637426401,
      "grad_norm": 0.08353480696678162,
      "learning_rate": 7.180646812867993e-06,
      "loss": 0.0022,
      "step": 100360
    },
    {
      "epoch": 8.56472395255568,
      "grad_norm": 0.04001298546791077,
      "learning_rate": 7.1763802372216065e-06,
      "loss": 0.0013,
      "step": 100370
    },
    {
      "epoch": 8.565577267684956,
      "grad_norm": 0.14942888915538788,
      "learning_rate": 7.172113661575221e-06,
      "loss": 0.0019,
      "step": 100380
    },
    {
      "epoch": 8.566430582814233,
      "grad_norm": 0.1820286512374878,
      "learning_rate": 7.167847085928833e-06,
      "loss": 0.0016,
      "step": 100390
    },
    {
      "epoch": 8.567283897943511,
      "grad_norm": 0.1466427445411682,
      "learning_rate": 7.1635805102824475e-06,
      "loss": 0.0015,
      "step": 100400
    },
    {
      "epoch": 8.568137213072788,
      "grad_norm": 0.16624917089939117,
      "learning_rate": 7.159313934636061e-06,
      "loss": 0.002,
      "step": 100410
    },
    {
      "epoch": 8.568990528202065,
      "grad_norm": 0.4860396683216095,
      "learning_rate": 7.155047358989675e-06,
      "loss": 0.0014,
      "step": 100420
    },
    {
      "epoch": 8.569843843331343,
      "grad_norm": 0.13965575397014618,
      "learning_rate": 7.1507807833432885e-06,
      "loss": 0.002,
      "step": 100430
    },
    {
      "epoch": 8.57069715846062,
      "grad_norm": 0.05838322266936302,
      "learning_rate": 7.146514207696903e-06,
      "loss": 0.0017,
      "step": 100440
    },
    {
      "epoch": 8.571550473589896,
      "grad_norm": 0.16572926938533783,
      "learning_rate": 7.142247632050517e-06,
      "loss": 0.0017,
      "step": 100450
    },
    {
      "epoch": 8.572403788719175,
      "grad_norm": 0.20295898616313934,
      "learning_rate": 7.13798105640413e-06,
      "loss": 0.0013,
      "step": 100460
    },
    {
      "epoch": 8.573257103848452,
      "grad_norm": 0.13807623088359833,
      "learning_rate": 7.133714480757745e-06,
      "loss": 0.0017,
      "step": 100470
    },
    {
      "epoch": 8.574110418977728,
      "grad_norm": 0.03147927299141884,
      "learning_rate": 7.129447905111358e-06,
      "loss": 0.0018,
      "step": 100480
    },
    {
      "epoch": 8.574963734107005,
      "grad_norm": 0.09256679564714432,
      "learning_rate": 7.125181329464972e-06,
      "loss": 0.0015,
      "step": 100490
    },
    {
      "epoch": 8.575817049236283,
      "grad_norm": 0.1876891702413559,
      "learning_rate": 7.120914753818586e-06,
      "loss": 0.0018,
      "step": 100500
    },
    {
      "epoch": 8.57667036436556,
      "grad_norm": 0.12838442623615265,
      "learning_rate": 7.1166481781722e-06,
      "loss": 0.0017,
      "step": 100510
    },
    {
      "epoch": 8.577523679494837,
      "grad_norm": 0.1985645890235901,
      "learning_rate": 7.1123816025258125e-06,
      "loss": 0.0015,
      "step": 100520
    },
    {
      "epoch": 8.578376994624115,
      "grad_norm": 0.14639762043952942,
      "learning_rate": 7.108115026879427e-06,
      "loss": 0.0013,
      "step": 100530
    },
    {
      "epoch": 8.579230309753392,
      "grad_norm": 0.1595735251903534,
      "learning_rate": 7.10384845123304e-06,
      "loss": 0.0019,
      "step": 100540
    },
    {
      "epoch": 8.580083624882668,
      "grad_norm": 0.15512216091156006,
      "learning_rate": 7.099581875586654e-06,
      "loss": 0.0018,
      "step": 100550
    },
    {
      "epoch": 8.580936940011947,
      "grad_norm": 0.07639902830123901,
      "learning_rate": 7.095315299940268e-06,
      "loss": 0.0014,
      "step": 100560
    },
    {
      "epoch": 8.581790255141224,
      "grad_norm": 0.22887969017028809,
      "learning_rate": 7.091048724293882e-06,
      "loss": 0.0022,
      "step": 100570
    },
    {
      "epoch": 8.5826435702705,
      "grad_norm": 0.08014148473739624,
      "learning_rate": 7.086782148647496e-06,
      "loss": 0.0021,
      "step": 100580
    },
    {
      "epoch": 8.583496885399779,
      "grad_norm": 0.14780279994010925,
      "learning_rate": 7.08251557300111e-06,
      "loss": 0.0016,
      "step": 100590
    },
    {
      "epoch": 8.584350200529055,
      "grad_norm": 0.09509206563234329,
      "learning_rate": 7.078248997354724e-06,
      "loss": 0.0013,
      "step": 100600
    },
    {
      "epoch": 8.585203515658332,
      "grad_norm": 0.09618106484413147,
      "learning_rate": 7.073982421708337e-06,
      "loss": 0.0018,
      "step": 100610
    },
    {
      "epoch": 8.58605683078761,
      "grad_norm": 0.24061356484889984,
      "learning_rate": 7.0697158460619515e-06,
      "loss": 0.0015,
      "step": 100620
    },
    {
      "epoch": 8.586910145916887,
      "grad_norm": 0.20033375918865204,
      "learning_rate": 7.065449270415565e-06,
      "loss": 0.002,
      "step": 100630
    },
    {
      "epoch": 8.587763461046164,
      "grad_norm": 0.2892315089702606,
      "learning_rate": 7.061182694769179e-06,
      "loss": 0.0017,
      "step": 100640
    },
    {
      "epoch": 8.588616776175442,
      "grad_norm": 0.13307544589042664,
      "learning_rate": 7.056916119122792e-06,
      "loss": 0.0019,
      "step": 100650
    },
    {
      "epoch": 8.589470091304719,
      "grad_norm": 0.16582618653774261,
      "learning_rate": 7.052649543476406e-06,
      "loss": 0.0017,
      "step": 100660
    },
    {
      "epoch": 8.590323406433996,
      "grad_norm": 0.04781045764684677,
      "learning_rate": 7.048382967830019e-06,
      "loss": 0.0016,
      "step": 100670
    },
    {
      "epoch": 8.591176721563274,
      "grad_norm": 0.18261270225048065,
      "learning_rate": 7.0441163921836336e-06,
      "loss": 0.0016,
      "step": 100680
    },
    {
      "epoch": 8.59203003669255,
      "grad_norm": 0.12493567913770676,
      "learning_rate": 7.039849816537247e-06,
      "loss": 0.002,
      "step": 100690
    },
    {
      "epoch": 8.592883351821827,
      "grad_norm": 0.04055221378803253,
      "learning_rate": 7.035583240890861e-06,
      "loss": 0.0015,
      "step": 100700
    },
    {
      "epoch": 8.593736666951106,
      "grad_norm": 0.13447338342666626,
      "learning_rate": 7.0313166652444754e-06,
      "loss": 0.0017,
      "step": 100710
    },
    {
      "epoch": 8.594589982080382,
      "grad_norm": 0.07436555624008179,
      "learning_rate": 7.027050089598089e-06,
      "loss": 0.0012,
      "step": 100720
    },
    {
      "epoch": 8.595443297209659,
      "grad_norm": 0.3484216630458832,
      "learning_rate": 7.022783513951703e-06,
      "loss": 0.0019,
      "step": 100730
    },
    {
      "epoch": 8.596296612338937,
      "grad_norm": 0.11850015819072723,
      "learning_rate": 7.0185169383053165e-06,
      "loss": 0.0019,
      "step": 100740
    },
    {
      "epoch": 8.597149927468214,
      "grad_norm": 0.22071346640586853,
      "learning_rate": 7.014250362658931e-06,
      "loss": 0.0014,
      "step": 100750
    },
    {
      "epoch": 8.59800324259749,
      "grad_norm": 0.35935404896736145,
      "learning_rate": 7.009983787012545e-06,
      "loss": 0.0019,
      "step": 100760
    },
    {
      "epoch": 8.59885655772677,
      "grad_norm": 0.37917181849479675,
      "learning_rate": 7.005717211366158e-06,
      "loss": 0.002,
      "step": 100770
    },
    {
      "epoch": 8.599709872856046,
      "grad_norm": 0.09491764008998871,
      "learning_rate": 7.001450635719773e-06,
      "loss": 0.0016,
      "step": 100780
    },
    {
      "epoch": 8.600563187985323,
      "grad_norm": 0.2150997668504715,
      "learning_rate": 6.997184060073385e-06,
      "loss": 0.0017,
      "step": 100790
    },
    {
      "epoch": 8.601416503114601,
      "grad_norm": 0.12960506975650787,
      "learning_rate": 6.9929174844269985e-06,
      "loss": 0.0014,
      "step": 100800
    },
    {
      "epoch": 8.602269818243878,
      "grad_norm": 0.30038997530937195,
      "learning_rate": 6.988650908780613e-06,
      "loss": 0.0014,
      "step": 100810
    },
    {
      "epoch": 8.603123133373154,
      "grad_norm": 0.1722291260957718,
      "learning_rate": 6.984384333134226e-06,
      "loss": 0.0021,
      "step": 100820
    },
    {
      "epoch": 8.603976448502433,
      "grad_norm": 0.26021885871887207,
      "learning_rate": 6.98011775748784e-06,
      "loss": 0.0013,
      "step": 100830
    },
    {
      "epoch": 8.60482976363171,
      "grad_norm": 0.06600731611251831,
      "learning_rate": 6.975851181841455e-06,
      "loss": 0.0015,
      "step": 100840
    },
    {
      "epoch": 8.605683078760986,
      "grad_norm": 0.07830049097537994,
      "learning_rate": 6.971584606195068e-06,
      "loss": 0.0015,
      "step": 100850
    },
    {
      "epoch": 8.606536393890263,
      "grad_norm": 0.09755567461252213,
      "learning_rate": 6.967318030548682e-06,
      "loss": 0.0022,
      "step": 100860
    },
    {
      "epoch": 8.607389709019541,
      "grad_norm": 0.09804097563028336,
      "learning_rate": 6.963051454902296e-06,
      "loss": 0.0016,
      "step": 100870
    },
    {
      "epoch": 8.608243024148818,
      "grad_norm": 0.12938621640205383,
      "learning_rate": 6.95878487925591e-06,
      "loss": 0.0019,
      "step": 100880
    },
    {
      "epoch": 8.609096339278095,
      "grad_norm": 0.11217319220304489,
      "learning_rate": 6.954518303609524e-06,
      "loss": 0.0016,
      "step": 100890
    },
    {
      "epoch": 8.609949654407373,
      "grad_norm": 0.05158175155520439,
      "learning_rate": 6.9502517279631375e-06,
      "loss": 0.0016,
      "step": 100900
    },
    {
      "epoch": 8.61080296953665,
      "grad_norm": 0.23530976474285126,
      "learning_rate": 6.945985152316752e-06,
      "loss": 0.0015,
      "step": 100910
    },
    {
      "epoch": 8.611656284665926,
      "grad_norm": 0.18363156914710999,
      "learning_rate": 6.941718576670364e-06,
      "loss": 0.0014,
      "step": 100920
    },
    {
      "epoch": 8.612509599795205,
      "grad_norm": 0.20058880746364594,
      "learning_rate": 6.937452001023978e-06,
      "loss": 0.0023,
      "step": 100930
    },
    {
      "epoch": 8.613362914924481,
      "grad_norm": 0.0276601891964674,
      "learning_rate": 6.933185425377592e-06,
      "loss": 0.0016,
      "step": 100940
    },
    {
      "epoch": 8.614216230053758,
      "grad_norm": 0.19895672798156738,
      "learning_rate": 6.928918849731205e-06,
      "loss": 0.0015,
      "step": 100950
    },
    {
      "epoch": 8.615069545183037,
      "grad_norm": 0.07485390454530716,
      "learning_rate": 6.92465227408482e-06,
      "loss": 0.0021,
      "step": 100960
    },
    {
      "epoch": 8.615922860312313,
      "grad_norm": 0.1096181869506836,
      "learning_rate": 6.920385698438434e-06,
      "loss": 0.0019,
      "step": 100970
    },
    {
      "epoch": 8.61677617544159,
      "grad_norm": 0.09259922802448273,
      "learning_rate": 6.916119122792047e-06,
      "loss": 0.0016,
      "step": 100980
    },
    {
      "epoch": 8.617629490570868,
      "grad_norm": 0.07572578638792038,
      "learning_rate": 6.9118525471456615e-06,
      "loss": 0.0013,
      "step": 100990
    },
    {
      "epoch": 8.618482805700145,
      "grad_norm": 0.02876323089003563,
      "learning_rate": 6.907585971499275e-06,
      "loss": 0.0015,
      "step": 101000
    },
    {
      "epoch": 8.619336120829422,
      "grad_norm": 0.2350783795118332,
      "learning_rate": 6.903319395852889e-06,
      "loss": 0.0017,
      "step": 101010
    },
    {
      "epoch": 8.6201894359587,
      "grad_norm": 0.13981005549430847,
      "learning_rate": 6.899052820206503e-06,
      "loss": 0.0016,
      "step": 101020
    },
    {
      "epoch": 8.621042751087977,
      "grad_norm": 0.44426414370536804,
      "learning_rate": 6.894786244560117e-06,
      "loss": 0.0014,
      "step": 101030
    },
    {
      "epoch": 8.621896066217253,
      "grad_norm": 0.4864414930343628,
      "learning_rate": 6.890519668913731e-06,
      "loss": 0.0017,
      "step": 101040
    },
    {
      "epoch": 8.622749381346532,
      "grad_norm": 0.2868663966655731,
      "learning_rate": 6.8862530932673435e-06,
      "loss": 0.0017,
      "step": 101050
    },
    {
      "epoch": 8.623602696475809,
      "grad_norm": 0.21437008678913116,
      "learning_rate": 6.881986517620957e-06,
      "loss": 0.0018,
      "step": 101060
    },
    {
      "epoch": 8.624456011605085,
      "grad_norm": 0.026053717359900475,
      "learning_rate": 6.877719941974571e-06,
      "loss": 0.0017,
      "step": 101070
    },
    {
      "epoch": 8.625309326734364,
      "grad_norm": 0.13043761253356934,
      "learning_rate": 6.873453366328185e-06,
      "loss": 0.0017,
      "step": 101080
    },
    {
      "epoch": 8.62616264186364,
      "grad_norm": 0.16478298604488373,
      "learning_rate": 6.869186790681799e-06,
      "loss": 0.0015,
      "step": 101090
    },
    {
      "epoch": 8.627015956992917,
      "grad_norm": 0.06328298151493073,
      "learning_rate": 6.864920215035413e-06,
      "loss": 0.0014,
      "step": 101100
    },
    {
      "epoch": 8.627869272122195,
      "grad_norm": 0.11136339604854584,
      "learning_rate": 6.8606536393890264e-06,
      "loss": 0.002,
      "step": 101110
    },
    {
      "epoch": 8.628722587251472,
      "grad_norm": 0.1628122627735138,
      "learning_rate": 6.856387063742641e-06,
      "loss": 0.0013,
      "step": 101120
    },
    {
      "epoch": 8.629575902380749,
      "grad_norm": 0.027582654729485512,
      "learning_rate": 6.852120488096254e-06,
      "loss": 0.0013,
      "step": 101130
    },
    {
      "epoch": 8.630429217510027,
      "grad_norm": 0.16762666404247284,
      "learning_rate": 6.847853912449868e-06,
      "loss": 0.0019,
      "step": 101140
    },
    {
      "epoch": 8.631282532639304,
      "grad_norm": 0.10999668389558792,
      "learning_rate": 6.8435873368034826e-06,
      "loss": 0.0017,
      "step": 101150
    },
    {
      "epoch": 8.63213584776858,
      "grad_norm": 0.026077868416905403,
      "learning_rate": 6.839320761157096e-06,
      "loss": 0.0014,
      "step": 101160
    },
    {
      "epoch": 8.632989162897859,
      "grad_norm": 0.048922836780548096,
      "learning_rate": 6.83505418551071e-06,
      "loss": 0.0013,
      "step": 101170
    },
    {
      "epoch": 8.633842478027136,
      "grad_norm": 0.11291517317295074,
      "learning_rate": 6.830787609864323e-06,
      "loss": 0.0019,
      "step": 101180
    },
    {
      "epoch": 8.634695793156412,
      "grad_norm": 0.09246501326560974,
      "learning_rate": 6.826521034217936e-06,
      "loss": 0.0016,
      "step": 101190
    },
    {
      "epoch": 8.63554910828569,
      "grad_norm": 0.215691477060318,
      "learning_rate": 6.82225445857155e-06,
      "loss": 0.0024,
      "step": 101200
    },
    {
      "epoch": 8.636402423414967,
      "grad_norm": 0.08499487489461899,
      "learning_rate": 6.817987882925165e-06,
      "loss": 0.0016,
      "step": 101210
    },
    {
      "epoch": 8.637255738544244,
      "grad_norm": 0.3220287263393402,
      "learning_rate": 6.813721307278778e-06,
      "loss": 0.002,
      "step": 101220
    },
    {
      "epoch": 8.63810905367352,
      "grad_norm": 0.18375849723815918,
      "learning_rate": 6.809454731632392e-06,
      "loss": 0.0015,
      "step": 101230
    },
    {
      "epoch": 8.6389623688028,
      "grad_norm": 0.19764770567417145,
      "learning_rate": 6.805188155986006e-06,
      "loss": 0.0014,
      "step": 101240
    },
    {
      "epoch": 8.639815683932076,
      "grad_norm": 0.060242362320423126,
      "learning_rate": 6.80092158033962e-06,
      "loss": 0.0013,
      "step": 101250
    },
    {
      "epoch": 8.640668999061353,
      "grad_norm": 0.16514241695404053,
      "learning_rate": 6.796655004693233e-06,
      "loss": 0.0018,
      "step": 101260
    },
    {
      "epoch": 8.641522314190631,
      "grad_norm": 0.09255047887563705,
      "learning_rate": 6.7923884290468475e-06,
      "loss": 0.0015,
      "step": 101270
    },
    {
      "epoch": 8.642375629319908,
      "grad_norm": 0.12920698523521423,
      "learning_rate": 6.788121853400462e-06,
      "loss": 0.0016,
      "step": 101280
    },
    {
      "epoch": 8.643228944449184,
      "grad_norm": 0.07641718536615372,
      "learning_rate": 6.783855277754075e-06,
      "loss": 0.0017,
      "step": 101290
    },
    {
      "epoch": 8.644082259578463,
      "grad_norm": 0.09651129692792892,
      "learning_rate": 6.779588702107689e-06,
      "loss": 0.0015,
      "step": 101300
    },
    {
      "epoch": 8.64493557470774,
      "grad_norm": 0.04799735173583031,
      "learning_rate": 6.775322126461303e-06,
      "loss": 0.0016,
      "step": 101310
    },
    {
      "epoch": 8.645788889837016,
      "grad_norm": 0.4147142767906189,
      "learning_rate": 6.771055550814915e-06,
      "loss": 0.0016,
      "step": 101320
    },
    {
      "epoch": 8.646642204966295,
      "grad_norm": 0.3375244736671448,
      "learning_rate": 6.7667889751685296e-06,
      "loss": 0.0016,
      "step": 101330
    },
    {
      "epoch": 8.647495520095571,
      "grad_norm": 0.12756355106830597,
      "learning_rate": 6.762522399522144e-06,
      "loss": 0.0015,
      "step": 101340
    },
    {
      "epoch": 8.648348835224848,
      "grad_norm": 0.19948968291282654,
      "learning_rate": 6.758255823875757e-06,
      "loss": 0.0019,
      "step": 101350
    },
    {
      "epoch": 8.649202150354126,
      "grad_norm": 0.09421201795339584,
      "learning_rate": 6.7539892482293714e-06,
      "loss": 0.0016,
      "step": 101360
    },
    {
      "epoch": 8.650055465483403,
      "grad_norm": 0.09285707026720047,
      "learning_rate": 6.749722672582985e-06,
      "loss": 0.0017,
      "step": 101370
    },
    {
      "epoch": 8.65090878061268,
      "grad_norm": 0.07745938748121262,
      "learning_rate": 6.745456096936599e-06,
      "loss": 0.0015,
      "step": 101380
    },
    {
      "epoch": 8.651762095741958,
      "grad_norm": 0.07865577936172485,
      "learning_rate": 6.741189521290213e-06,
      "loss": 0.0019,
      "step": 101390
    },
    {
      "epoch": 8.652615410871235,
      "grad_norm": 0.09566834568977356,
      "learning_rate": 6.736922945643827e-06,
      "loss": 0.0016,
      "step": 101400
    },
    {
      "epoch": 8.653468726000511,
      "grad_norm": 0.03150394186377525,
      "learning_rate": 6.732656369997441e-06,
      "loss": 0.0014,
      "step": 101410
    },
    {
      "epoch": 8.65432204112979,
      "grad_norm": 0.109152652323246,
      "learning_rate": 6.728389794351054e-06,
      "loss": 0.0015,
      "step": 101420
    },
    {
      "epoch": 8.655175356259067,
      "grad_norm": 0.14858229458332062,
      "learning_rate": 6.724123218704669e-06,
      "loss": 0.0013,
      "step": 101430
    },
    {
      "epoch": 8.656028671388343,
      "grad_norm": 0.032089293003082275,
      "learning_rate": 6.719856643058282e-06,
      "loss": 0.0017,
      "step": 101440
    },
    {
      "epoch": 8.656881986517622,
      "grad_norm": 0.09605096280574799,
      "learning_rate": 6.7155900674118945e-06,
      "loss": 0.0015,
      "step": 101450
    },
    {
      "epoch": 8.657735301646898,
      "grad_norm": 0.25338324904441833,
      "learning_rate": 6.711323491765509e-06,
      "loss": 0.0016,
      "step": 101460
    },
    {
      "epoch": 8.658588616776175,
      "grad_norm": 0.18936537206172943,
      "learning_rate": 6.707056916119123e-06,
      "loss": 0.0014,
      "step": 101470
    },
    {
      "epoch": 8.659441931905453,
      "grad_norm": 0.1301489621400833,
      "learning_rate": 6.702790340472736e-06,
      "loss": 0.0016,
      "step": 101480
    },
    {
      "epoch": 8.66029524703473,
      "grad_norm": 0.1345863938331604,
      "learning_rate": 6.698523764826351e-06,
      "loss": 0.0019,
      "step": 101490
    },
    {
      "epoch": 8.661148562164007,
      "grad_norm": 0.19762872159481049,
      "learning_rate": 6.694257189179964e-06,
      "loss": 0.0012,
      "step": 101500
    },
    {
      "epoch": 8.662001877293285,
      "grad_norm": 0.18239827454090118,
      "learning_rate": 6.689990613533578e-06,
      "loss": 0.0015,
      "step": 101510
    },
    {
      "epoch": 8.662855192422562,
      "grad_norm": 0.20784667134284973,
      "learning_rate": 6.6857240378871925e-06,
      "loss": 0.0014,
      "step": 101520
    },
    {
      "epoch": 8.663708507551839,
      "grad_norm": 0.3443753123283386,
      "learning_rate": 6.681457462240806e-06,
      "loss": 0.0013,
      "step": 101530
    },
    {
      "epoch": 8.664561822681117,
      "grad_norm": 0.25471562147140503,
      "learning_rate": 6.67719088659442e-06,
      "loss": 0.0016,
      "step": 101540
    },
    {
      "epoch": 8.665415137810394,
      "grad_norm": 0.04692288860678673,
      "learning_rate": 6.6729243109480336e-06,
      "loss": 0.0018,
      "step": 101550
    },
    {
      "epoch": 8.66626845293967,
      "grad_norm": 0.11327539384365082,
      "learning_rate": 6.668657735301648e-06,
      "loss": 0.002,
      "step": 101560
    },
    {
      "epoch": 8.667121768068949,
      "grad_norm": 0.3991018831729889,
      "learning_rate": 6.664391159655262e-06,
      "loss": 0.0016,
      "step": 101570
    },
    {
      "epoch": 8.667975083198225,
      "grad_norm": 0.04570186510682106,
      "learning_rate": 6.660124584008874e-06,
      "loss": 0.0016,
      "step": 101580
    },
    {
      "epoch": 8.668828398327502,
      "grad_norm": 0.027246279641985893,
      "learning_rate": 6.655858008362488e-06,
      "loss": 0.0017,
      "step": 101590
    },
    {
      "epoch": 8.669681713456779,
      "grad_norm": 0.1990474909543991,
      "learning_rate": 6.651591432716102e-06,
      "loss": 0.0019,
      "step": 101600
    },
    {
      "epoch": 8.670535028586057,
      "grad_norm": 0.18059015274047852,
      "learning_rate": 6.647324857069716e-06,
      "loss": 0.0014,
      "step": 101610
    },
    {
      "epoch": 8.671388343715334,
      "grad_norm": 0.18160372972488403,
      "learning_rate": 6.64305828142333e-06,
      "loss": 0.0015,
      "step": 101620
    },
    {
      "epoch": 8.67224165884461,
      "grad_norm": 0.1642836034297943,
      "learning_rate": 6.638791705776943e-06,
      "loss": 0.0022,
      "step": 101630
    },
    {
      "epoch": 8.673094973973889,
      "grad_norm": 0.061269186437129974,
      "learning_rate": 6.6345251301305575e-06,
      "loss": 0.0015,
      "step": 101640
    },
    {
      "epoch": 8.673948289103166,
      "grad_norm": 0.032335538417100906,
      "learning_rate": 6.630258554484172e-06,
      "loss": 0.0014,
      "step": 101650
    },
    {
      "epoch": 8.674801604232442,
      "grad_norm": 0.09395665675401688,
      "learning_rate": 6.625991978837785e-06,
      "loss": 0.0018,
      "step": 101660
    },
    {
      "epoch": 8.67565491936172,
      "grad_norm": 0.12485858798027039,
      "learning_rate": 6.621725403191399e-06,
      "loss": 0.0016,
      "step": 101670
    },
    {
      "epoch": 8.676508234490997,
      "grad_norm": 0.05058387666940689,
      "learning_rate": 6.617458827545013e-06,
      "loss": 0.0015,
      "step": 101680
    },
    {
      "epoch": 8.677361549620274,
      "grad_norm": 0.16182665526866913,
      "learning_rate": 6.613192251898627e-06,
      "loss": 0.0016,
      "step": 101690
    },
    {
      "epoch": 8.678214864749553,
      "grad_norm": 0.06045692786574364,
      "learning_rate": 6.608925676252241e-06,
      "loss": 0.0018,
      "step": 101700
    },
    {
      "epoch": 8.67906817987883,
      "grad_norm": 0.1743428260087967,
      "learning_rate": 6.604659100605855e-06,
      "loss": 0.0015,
      "step": 101710
    },
    {
      "epoch": 8.679921495008106,
      "grad_norm": 0.21659992635250092,
      "learning_rate": 6.600392524959467e-06,
      "loss": 0.0014,
      "step": 101720
    },
    {
      "epoch": 8.680774810137384,
      "grad_norm": 0.056362830102443695,
      "learning_rate": 6.5961259493130814e-06,
      "loss": 0.0018,
      "step": 101730
    },
    {
      "epoch": 8.681628125266661,
      "grad_norm": 0.2684798836708069,
      "learning_rate": 6.591859373666695e-06,
      "loss": 0.0018,
      "step": 101740
    },
    {
      "epoch": 8.682481440395938,
      "grad_norm": 0.1486709862947464,
      "learning_rate": 6.587592798020309e-06,
      "loss": 0.0016,
      "step": 101750
    },
    {
      "epoch": 8.683334755525216,
      "grad_norm": 0.06044277921319008,
      "learning_rate": 6.5833262223739225e-06,
      "loss": 0.0013,
      "step": 101760
    },
    {
      "epoch": 8.684188070654493,
      "grad_norm": 0.23385798931121826,
      "learning_rate": 6.579059646727537e-06,
      "loss": 0.0014,
      "step": 101770
    },
    {
      "epoch": 8.68504138578377,
      "grad_norm": 0.04568105936050415,
      "learning_rate": 6.574793071081151e-06,
      "loss": 0.0013,
      "step": 101780
    },
    {
      "epoch": 8.685894700913048,
      "grad_norm": 0.16407953202724457,
      "learning_rate": 6.570526495434764e-06,
      "loss": 0.0018,
      "step": 101790
    },
    {
      "epoch": 8.686748016042324,
      "grad_norm": 0.1387445479631424,
      "learning_rate": 6.5662599197883786e-06,
      "loss": 0.0017,
      "step": 101800
    },
    {
      "epoch": 8.687601331171601,
      "grad_norm": 0.11466129124164581,
      "learning_rate": 6.561993344141992e-06,
      "loss": 0.0015,
      "step": 101810
    },
    {
      "epoch": 8.68845464630088,
      "grad_norm": 0.2099689543247223,
      "learning_rate": 6.557726768495606e-06,
      "loss": 0.002,
      "step": 101820
    },
    {
      "epoch": 8.689307961430156,
      "grad_norm": 0.0951361134648323,
      "learning_rate": 6.5534601928492204e-06,
      "loss": 0.0016,
      "step": 101830
    },
    {
      "epoch": 8.690161276559433,
      "grad_norm": 0.2404802143573761,
      "learning_rate": 6.549193617202834e-06,
      "loss": 0.0021,
      "step": 101840
    },
    {
      "epoch": 8.691014591688711,
      "grad_norm": 0.1813001036643982,
      "learning_rate": 6.544927041556446e-06,
      "loss": 0.0017,
      "step": 101850
    },
    {
      "epoch": 8.691867906817988,
      "grad_norm": 0.07400951534509659,
      "learning_rate": 6.540660465910061e-06,
      "loss": 0.0017,
      "step": 101860
    },
    {
      "epoch": 8.692721221947265,
      "grad_norm": 0.04233395680785179,
      "learning_rate": 6.536393890263674e-06,
      "loss": 0.0014,
      "step": 101870
    },
    {
      "epoch": 8.693574537076543,
      "grad_norm": 0.28340470790863037,
      "learning_rate": 6.532127314617288e-06,
      "loss": 0.0018,
      "step": 101880
    },
    {
      "epoch": 8.69442785220582,
      "grad_norm": 0.18025672435760498,
      "learning_rate": 6.527860738970902e-06,
      "loss": 0.0017,
      "step": 101890
    },
    {
      "epoch": 8.695281167335096,
      "grad_norm": 0.21318155527114868,
      "learning_rate": 6.523594163324516e-06,
      "loss": 0.0016,
      "step": 101900
    },
    {
      "epoch": 8.696134482464373,
      "grad_norm": 0.12876462936401367,
      "learning_rate": 6.51932758767813e-06,
      "loss": 0.0015,
      "step": 101910
    },
    {
      "epoch": 8.696987797593652,
      "grad_norm": 0.07439360022544861,
      "learning_rate": 6.5150610120317435e-06,
      "loss": 0.0018,
      "step": 101920
    },
    {
      "epoch": 8.697841112722928,
      "grad_norm": 0.047138214111328125,
      "learning_rate": 6.510794436385358e-06,
      "loss": 0.0015,
      "step": 101930
    },
    {
      "epoch": 8.698694427852207,
      "grad_norm": 0.060243479907512665,
      "learning_rate": 6.506527860738971e-06,
      "loss": 0.0015,
      "step": 101940
    },
    {
      "epoch": 8.699547742981483,
      "grad_norm": 0.15990744531154633,
      "learning_rate": 6.502261285092585e-06,
      "loss": 0.0017,
      "step": 101950
    },
    {
      "epoch": 8.70040105811076,
      "grad_norm": 0.0742795392870903,
      "learning_rate": 6.4979947094462e-06,
      "loss": 0.0017,
      "step": 101960
    },
    {
      "epoch": 8.701254373240037,
      "grad_norm": 0.057739850133657455,
      "learning_rate": 6.493728133799813e-06,
      "loss": 0.0018,
      "step": 101970
    },
    {
      "epoch": 8.702107688369315,
      "grad_norm": 0.2518792152404785,
      "learning_rate": 6.489461558153426e-06,
      "loss": 0.0013,
      "step": 101980
    },
    {
      "epoch": 8.702961003498592,
      "grad_norm": 0.02872861921787262,
      "learning_rate": 6.48519498250704e-06,
      "loss": 0.002,
      "step": 101990
    },
    {
      "epoch": 8.703814318627868,
      "grad_norm": 0.16560234129428864,
      "learning_rate": 6.480928406860653e-06,
      "loss": 0.0016,
      "step": 102000
    },
    {
      "epoch": 8.704667633757147,
      "grad_norm": 0.4487747251987457,
      "learning_rate": 6.4766618312142675e-06,
      "loss": 0.0017,
      "step": 102010
    },
    {
      "epoch": 8.705520948886424,
      "grad_norm": 0.10066524893045425,
      "learning_rate": 6.472395255567882e-06,
      "loss": 0.0017,
      "step": 102020
    },
    {
      "epoch": 8.7063742640157,
      "grad_norm": 0.30608704686164856,
      "learning_rate": 6.468128679921495e-06,
      "loss": 0.0018,
      "step": 102030
    },
    {
      "epoch": 8.707227579144979,
      "grad_norm": 0.15628547966480255,
      "learning_rate": 6.463862104275109e-06,
      "loss": 0.0018,
      "step": 102040
    },
    {
      "epoch": 8.708080894274255,
      "grad_norm": 0.16215001046657562,
      "learning_rate": 6.459595528628723e-06,
      "loss": 0.0014,
      "step": 102050
    },
    {
      "epoch": 8.708934209403532,
      "grad_norm": 0.20121163129806519,
      "learning_rate": 6.455328952982337e-06,
      "loss": 0.0018,
      "step": 102060
    },
    {
      "epoch": 8.70978752453281,
      "grad_norm": 0.16178585588932037,
      "learning_rate": 6.45106237733595e-06,
      "loss": 0.0016,
      "step": 102070
    },
    {
      "epoch": 8.710640839662087,
      "grad_norm": 0.05396190285682678,
      "learning_rate": 6.446795801689565e-06,
      "loss": 0.0019,
      "step": 102080
    },
    {
      "epoch": 8.711494154791364,
      "grad_norm": 0.11245284974575043,
      "learning_rate": 6.442529226043179e-06,
      "loss": 0.0016,
      "step": 102090
    },
    {
      "epoch": 8.712347469920642,
      "grad_norm": 0.21147160232067108,
      "learning_rate": 6.438262650396792e-06,
      "loss": 0.0014,
      "step": 102100
    },
    {
      "epoch": 8.713200785049919,
      "grad_norm": 0.061830487102270126,
      "learning_rate": 6.433996074750405e-06,
      "loss": 0.0014,
      "step": 102110
    },
    {
      "epoch": 8.714054100179196,
      "grad_norm": 0.14808610081672668,
      "learning_rate": 6.429729499104019e-06,
      "loss": 0.0015,
      "step": 102120
    },
    {
      "epoch": 8.714907415308474,
      "grad_norm": 0.2733193635940552,
      "learning_rate": 6.4254629234576324e-06,
      "loss": 0.0015,
      "step": 102130
    },
    {
      "epoch": 8.71576073043775,
      "grad_norm": 0.042635321617126465,
      "learning_rate": 6.421196347811247e-06,
      "loss": 0.0018,
      "step": 102140
    },
    {
      "epoch": 8.716614045567027,
      "grad_norm": 0.1123109683394432,
      "learning_rate": 6.416929772164861e-06,
      "loss": 0.0018,
      "step": 102150
    },
    {
      "epoch": 8.717467360696306,
      "grad_norm": 0.30635109543800354,
      "learning_rate": 6.412663196518474e-06,
      "loss": 0.0014,
      "step": 102160
    },
    {
      "epoch": 8.718320675825582,
      "grad_norm": 0.13517507910728455,
      "learning_rate": 6.4083966208720885e-06,
      "loss": 0.0013,
      "step": 102170
    },
    {
      "epoch": 8.71917399095486,
      "grad_norm": 0.16191479563713074,
      "learning_rate": 6.404130045225702e-06,
      "loss": 0.0014,
      "step": 102180
    },
    {
      "epoch": 8.720027306084138,
      "grad_norm": 0.1790492683649063,
      "learning_rate": 6.399863469579316e-06,
      "loss": 0.0016,
      "step": 102190
    },
    {
      "epoch": 8.720880621213414,
      "grad_norm": 0.021489890292286873,
      "learning_rate": 6.3955968939329296e-06,
      "loss": 0.0019,
      "step": 102200
    },
    {
      "epoch": 8.721733936342691,
      "grad_norm": 0.037053097039461136,
      "learning_rate": 6.391330318286544e-06,
      "loss": 0.0016,
      "step": 102210
    },
    {
      "epoch": 8.72258725147197,
      "grad_norm": 0.1688731610774994,
      "learning_rate": 6.387063742640158e-06,
      "loss": 0.0016,
      "step": 102220
    },
    {
      "epoch": 8.723440566601246,
      "grad_norm": 0.1298004686832428,
      "learning_rate": 6.3827971669937714e-06,
      "loss": 0.0017,
      "step": 102230
    },
    {
      "epoch": 8.724293881730523,
      "grad_norm": 0.033818040043115616,
      "learning_rate": 6.378530591347386e-06,
      "loss": 0.0015,
      "step": 102240
    },
    {
      "epoch": 8.725147196859801,
      "grad_norm": 0.048159416764974594,
      "learning_rate": 6.374264015700998e-06,
      "loss": 0.0015,
      "step": 102250
    },
    {
      "epoch": 8.726000511989078,
      "grad_norm": 0.11135251820087433,
      "learning_rate": 6.369997440054612e-06,
      "loss": 0.0015,
      "step": 102260
    },
    {
      "epoch": 8.726853827118354,
      "grad_norm": 0.305795282125473,
      "learning_rate": 6.365730864408226e-06,
      "loss": 0.0013,
      "step": 102270
    },
    {
      "epoch": 8.727707142247631,
      "grad_norm": 0.18134067952632904,
      "learning_rate": 6.36146428876184e-06,
      "loss": 0.002,
      "step": 102280
    },
    {
      "epoch": 8.72856045737691,
      "grad_norm": 0.23400412499904633,
      "learning_rate": 6.3571977131154535e-06,
      "loss": 0.0018,
      "step": 102290
    },
    {
      "epoch": 8.729413772506186,
      "grad_norm": 0.18058057129383087,
      "learning_rate": 6.352931137469068e-06,
      "loss": 0.0014,
      "step": 102300
    },
    {
      "epoch": 8.730267087635465,
      "grad_norm": 0.16296601295471191,
      "learning_rate": 6.348664561822681e-06,
      "loss": 0.0019,
      "step": 102310
    },
    {
      "epoch": 8.731120402764741,
      "grad_norm": 0.13696880638599396,
      "learning_rate": 6.344397986176295e-06,
      "loss": 0.0015,
      "step": 102320
    },
    {
      "epoch": 8.731973717894018,
      "grad_norm": 0.15429885685443878,
      "learning_rate": 6.34013141052991e-06,
      "loss": 0.0017,
      "step": 102330
    },
    {
      "epoch": 8.732827033023295,
      "grad_norm": 0.03860955312848091,
      "learning_rate": 6.335864834883523e-06,
      "loss": 0.0017,
      "step": 102340
    },
    {
      "epoch": 8.733680348152573,
      "grad_norm": 0.04932425543665886,
      "learning_rate": 6.331598259237137e-06,
      "loss": 0.0015,
      "step": 102350
    },
    {
      "epoch": 8.73453366328185,
      "grad_norm": 0.23593609035015106,
      "learning_rate": 6.327331683590751e-06,
      "loss": 0.0018,
      "step": 102360
    },
    {
      "epoch": 8.735386978411126,
      "grad_norm": 0.04215989634394646,
      "learning_rate": 6.323065107944365e-06,
      "loss": 0.0017,
      "step": 102370
    },
    {
      "epoch": 8.736240293540405,
      "grad_norm": 0.18353642523288727,
      "learning_rate": 6.3187985322979774e-06,
      "loss": 0.0018,
      "step": 102380
    },
    {
      "epoch": 8.737093608669682,
      "grad_norm": 0.10081802308559418,
      "learning_rate": 6.314531956651591e-06,
      "loss": 0.0014,
      "step": 102390
    },
    {
      "epoch": 8.737946923798958,
      "grad_norm": 0.2758493721485138,
      "learning_rate": 6.310265381005205e-06,
      "loss": 0.0021,
      "step": 102400
    },
    {
      "epoch": 8.738800238928237,
      "grad_norm": 0.17057378590106964,
      "learning_rate": 6.305998805358819e-06,
      "loss": 0.0017,
      "step": 102410
    },
    {
      "epoch": 8.739653554057513,
      "grad_norm": 0.13298705220222473,
      "learning_rate": 6.301732229712433e-06,
      "loss": 0.0016,
      "step": 102420
    },
    {
      "epoch": 8.74050686918679,
      "grad_norm": 0.07532831281423569,
      "learning_rate": 6.297465654066047e-06,
      "loss": 0.0014,
      "step": 102430
    },
    {
      "epoch": 8.741360184316068,
      "grad_norm": 0.023128848522901535,
      "learning_rate": 6.29319907841966e-06,
      "loss": 0.002,
      "step": 102440
    },
    {
      "epoch": 8.742213499445345,
      "grad_norm": 0.283268541097641,
      "learning_rate": 6.288932502773275e-06,
      "loss": 0.0018,
      "step": 102450
    },
    {
      "epoch": 8.743066814574622,
      "grad_norm": 0.20193098485469818,
      "learning_rate": 6.284665927126889e-06,
      "loss": 0.0016,
      "step": 102460
    },
    {
      "epoch": 8.7439201297039,
      "grad_norm": 0.22017207741737366,
      "learning_rate": 6.280399351480502e-06,
      "loss": 0.0016,
      "step": 102470
    },
    {
      "epoch": 8.744773444833177,
      "grad_norm": 0.2511269748210907,
      "learning_rate": 6.2761327758341165e-06,
      "loss": 0.0019,
      "step": 102480
    },
    {
      "epoch": 8.745626759962454,
      "grad_norm": 0.3431087136268616,
      "learning_rate": 6.27186620018773e-06,
      "loss": 0.0014,
      "step": 102490
    },
    {
      "epoch": 8.746480075091732,
      "grad_norm": 0.18269392848014832,
      "learning_rate": 6.267599624541344e-06,
      "loss": 0.0016,
      "step": 102500
    },
    {
      "epoch": 8.747333390221009,
      "grad_norm": 0.14806194603443146,
      "learning_rate": 6.263333048894957e-06,
      "loss": 0.0014,
      "step": 102510
    },
    {
      "epoch": 8.748186705350285,
      "grad_norm": 0.2542503774166107,
      "learning_rate": 6.25906647324857e-06,
      "loss": 0.0013,
      "step": 102520
    },
    {
      "epoch": 8.749040020479564,
      "grad_norm": 0.04799644649028778,
      "learning_rate": 6.254799897602184e-06,
      "loss": 0.0015,
      "step": 102530
    },
    {
      "epoch": 8.74989333560884,
      "grad_norm": 0.28653159737586975,
      "learning_rate": 6.2505333219557985e-06,
      "loss": 0.0015,
      "step": 102540
    },
    {
      "epoch": 8.750746650738117,
      "grad_norm": 0.10806959867477417,
      "learning_rate": 6.246266746309412e-06,
      "loss": 0.0017,
      "step": 102550
    },
    {
      "epoch": 8.751599965867396,
      "grad_norm": 0.2636392116546631,
      "learning_rate": 6.242000170663026e-06,
      "loss": 0.0018,
      "step": 102560
    },
    {
      "epoch": 8.752453280996672,
      "grad_norm": 0.25133684277534485,
      "learning_rate": 6.2377335950166395e-06,
      "loss": 0.0017,
      "step": 102570
    },
    {
      "epoch": 8.753306596125949,
      "grad_norm": 0.06065104529261589,
      "learning_rate": 6.233467019370254e-06,
      "loss": 0.0016,
      "step": 102580
    },
    {
      "epoch": 8.754159911255227,
      "grad_norm": 0.03211941197514534,
      "learning_rate": 6.229200443723868e-06,
      "loss": 0.0015,
      "step": 102590
    },
    {
      "epoch": 8.755013226384504,
      "grad_norm": 0.03851691633462906,
      "learning_rate": 6.2249338680774814e-06,
      "loss": 0.0016,
      "step": 102600
    },
    {
      "epoch": 8.75586654151378,
      "grad_norm": 0.2211330533027649,
      "learning_rate": 6.220667292431095e-06,
      "loss": 0.0014,
      "step": 102610
    },
    {
      "epoch": 8.756719856643059,
      "grad_norm": 0.173572838306427,
      "learning_rate": 6.216400716784709e-06,
      "loss": 0.0015,
      "step": 102620
    },
    {
      "epoch": 8.757573171772336,
      "grad_norm": 0.36096593737602234,
      "learning_rate": 6.2121341411383225e-06,
      "loss": 0.0018,
      "step": 102630
    },
    {
      "epoch": 8.758426486901612,
      "grad_norm": 0.19882437586784363,
      "learning_rate": 6.207867565491937e-06,
      "loss": 0.0014,
      "step": 102640
    },
    {
      "epoch": 8.759279802030889,
      "grad_norm": 0.13536350429058075,
      "learning_rate": 6.20360098984555e-06,
      "loss": 0.0016,
      "step": 102650
    },
    {
      "epoch": 8.760133117160168,
      "grad_norm": 0.03412749990820885,
      "learning_rate": 6.199334414199164e-06,
      "loss": 0.0017,
      "step": 102660
    },
    {
      "epoch": 8.760986432289444,
      "grad_norm": 0.1013212576508522,
      "learning_rate": 6.195067838552778e-06,
      "loss": 0.0017,
      "step": 102670
    },
    {
      "epoch": 8.761839747418723,
      "grad_norm": 0.19142143428325653,
      "learning_rate": 6.190801262906391e-06,
      "loss": 0.002,
      "step": 102680
    },
    {
      "epoch": 8.762693062548,
      "grad_norm": 0.23692888021469116,
      "learning_rate": 6.186534687260005e-06,
      "loss": 0.0014,
      "step": 102690
    },
    {
      "epoch": 8.763546377677276,
      "grad_norm": 0.021693294867873192,
      "learning_rate": 6.182268111613619e-06,
      "loss": 0.002,
      "step": 102700
    },
    {
      "epoch": 8.764399692806553,
      "grad_norm": 0.18154650926589966,
      "learning_rate": 6.178001535967233e-06,
      "loss": 0.0021,
      "step": 102710
    },
    {
      "epoch": 8.765253007935831,
      "grad_norm": 0.07649724185466766,
      "learning_rate": 6.173734960320847e-06,
      "loss": 0.0017,
      "step": 102720
    },
    {
      "epoch": 8.766106323065108,
      "grad_norm": 0.04207746312022209,
      "learning_rate": 6.169468384674461e-06,
      "loss": 0.0017,
      "step": 102730
    },
    {
      "epoch": 8.766959638194384,
      "grad_norm": 0.07636532932519913,
      "learning_rate": 6.165201809028075e-06,
      "loss": 0.0015,
      "step": 102740
    },
    {
      "epoch": 8.767812953323663,
      "grad_norm": 0.07746018469333649,
      "learning_rate": 6.160935233381688e-06,
      "loss": 0.0012,
      "step": 102750
    },
    {
      "epoch": 8.76866626845294,
      "grad_norm": 0.10949387401342392,
      "learning_rate": 6.156668657735302e-06,
      "loss": 0.0014,
      "step": 102760
    },
    {
      "epoch": 8.769519583582216,
      "grad_norm": 0.14762617647647858,
      "learning_rate": 6.152402082088916e-06,
      "loss": 0.0019,
      "step": 102770
    },
    {
      "epoch": 8.770372898711495,
      "grad_norm": 0.2674444913864136,
      "learning_rate": 6.148135506442529e-06,
      "loss": 0.0018,
      "step": 102780
    },
    {
      "epoch": 8.771226213840771,
      "grad_norm": 0.1472811996936798,
      "learning_rate": 6.1438689307961435e-06,
      "loss": 0.0019,
      "step": 102790
    },
    {
      "epoch": 8.772079528970048,
      "grad_norm": 0.09501480311155319,
      "learning_rate": 6.139602355149758e-06,
      "loss": 0.0016,
      "step": 102800
    },
    {
      "epoch": 8.772932844099326,
      "grad_norm": 0.11316198855638504,
      "learning_rate": 6.13533577950337e-06,
      "loss": 0.0014,
      "step": 102810
    },
    {
      "epoch": 8.773786159228603,
      "grad_norm": 0.23447205126285553,
      "learning_rate": 6.1310692038569846e-06,
      "loss": 0.0021,
      "step": 102820
    },
    {
      "epoch": 8.77463947435788,
      "grad_norm": 0.06387244164943695,
      "learning_rate": 6.126802628210598e-06,
      "loss": 0.0018,
      "step": 102830
    },
    {
      "epoch": 8.775492789487158,
      "grad_norm": 0.43555885553359985,
      "learning_rate": 6.122536052564212e-06,
      "loss": 0.0015,
      "step": 102840
    },
    {
      "epoch": 8.776346104616435,
      "grad_norm": 0.23116520047187805,
      "learning_rate": 6.1182694769178264e-06,
      "loss": 0.0016,
      "step": 102850
    },
    {
      "epoch": 8.777199419745711,
      "grad_norm": 0.19624173641204834,
      "learning_rate": 6.11400290127144e-06,
      "loss": 0.0012,
      "step": 102860
    },
    {
      "epoch": 8.77805273487499,
      "grad_norm": 0.06445836275815964,
      "learning_rate": 6.109736325625054e-06,
      "loss": 0.0014,
      "step": 102870
    },
    {
      "epoch": 8.778906050004267,
      "grad_norm": 0.32840079069137573,
      "learning_rate": 6.1054697499786675e-06,
      "loss": 0.0017,
      "step": 102880
    },
    {
      "epoch": 8.779759365133543,
      "grad_norm": 0.09565916657447815,
      "learning_rate": 6.101203174332281e-06,
      "loss": 0.0016,
      "step": 102890
    },
    {
      "epoch": 8.780612680262822,
      "grad_norm": 0.11264101415872574,
      "learning_rate": 6.096936598685895e-06,
      "loss": 0.0018,
      "step": 102900
    },
    {
      "epoch": 8.781465995392098,
      "grad_norm": 0.0833546593785286,
      "learning_rate": 6.0926700230395085e-06,
      "loss": 0.0014,
      "step": 102910
    },
    {
      "epoch": 8.782319310521375,
      "grad_norm": 0.23672911524772644,
      "learning_rate": 6.088403447393123e-06,
      "loss": 0.0013,
      "step": 102920
    },
    {
      "epoch": 8.783172625650653,
      "grad_norm": 0.09510529786348343,
      "learning_rate": 6.084136871746737e-06,
      "loss": 0.0016,
      "step": 102930
    },
    {
      "epoch": 8.78402594077993,
      "grad_norm": 0.1287304013967514,
      "learning_rate": 6.0798702961003495e-06,
      "loss": 0.0015,
      "step": 102940
    },
    {
      "epoch": 8.784879255909207,
      "grad_norm": 0.14831699430942535,
      "learning_rate": 6.075603720453964e-06,
      "loss": 0.0018,
      "step": 102950
    },
    {
      "epoch": 8.785732571038485,
      "grad_norm": 0.16034525632858276,
      "learning_rate": 6.071337144807578e-06,
      "loss": 0.002,
      "step": 102960
    },
    {
      "epoch": 8.786585886167762,
      "grad_norm": 0.16328135132789612,
      "learning_rate": 6.067070569161191e-06,
      "loss": 0.0015,
      "step": 102970
    },
    {
      "epoch": 8.787439201297039,
      "grad_norm": 0.06338045746088028,
      "learning_rate": 6.062803993514806e-06,
      "loss": 0.0014,
      "step": 102980
    },
    {
      "epoch": 8.788292516426317,
      "grad_norm": 0.034264400601387024,
      "learning_rate": 6.058537417868419e-06,
      "loss": 0.0017,
      "step": 102990
    },
    {
      "epoch": 8.789145831555594,
      "grad_norm": 0.19633372128009796,
      "learning_rate": 6.054270842222033e-06,
      "loss": 0.0015,
      "step": 103000
    },
    {
      "epoch": 8.78999914668487,
      "grad_norm": 0.07910215854644775,
      "learning_rate": 6.050004266575647e-06,
      "loss": 0.0019,
      "step": 103010
    },
    {
      "epoch": 8.790852461814147,
      "grad_norm": 0.0925050899386406,
      "learning_rate": 6.04573769092926e-06,
      "loss": 0.0015,
      "step": 103020
    },
    {
      "epoch": 8.791705776943425,
      "grad_norm": 0.21624937653541565,
      "learning_rate": 6.041471115282874e-06,
      "loss": 0.0012,
      "step": 103030
    },
    {
      "epoch": 8.792559092072702,
      "grad_norm": 0.24677836894989014,
      "learning_rate": 6.037204539636488e-06,
      "loss": 0.0017,
      "step": 103040
    },
    {
      "epoch": 8.79341240720198,
      "grad_norm": 0.16555924713611603,
      "learning_rate": 6.032937963990102e-06,
      "loss": 0.0017,
      "step": 103050
    },
    {
      "epoch": 8.794265722331257,
      "grad_norm": 0.14896772801876068,
      "learning_rate": 6.028671388343716e-06,
      "loss": 0.0015,
      "step": 103060
    },
    {
      "epoch": 8.795119037460534,
      "grad_norm": 0.03875570744276047,
      "learning_rate": 6.0244048126973296e-06,
      "loss": 0.0015,
      "step": 103070
    },
    {
      "epoch": 8.79597235258981,
      "grad_norm": 0.13903450965881348,
      "learning_rate": 6.020138237050943e-06,
      "loss": 0.0017,
      "step": 103080
    },
    {
      "epoch": 8.796825667719089,
      "grad_norm": 0.05509742349386215,
      "learning_rate": 6.015871661404557e-06,
      "loss": 0.0017,
      "step": 103090
    },
    {
      "epoch": 8.797678982848366,
      "grad_norm": 0.0842146947979927,
      "learning_rate": 6.011605085758171e-06,
      "loss": 0.0012,
      "step": 103100
    },
    {
      "epoch": 8.798532297977642,
      "grad_norm": 0.19931216537952423,
      "learning_rate": 6.007338510111785e-06,
      "loss": 0.0016,
      "step": 103110
    },
    {
      "epoch": 8.79938561310692,
      "grad_norm": 0.25107404589653015,
      "learning_rate": 6.003071934465398e-06,
      "loss": 0.0017,
      "step": 103120
    },
    {
      "epoch": 8.800238928236197,
      "grad_norm": 0.09486933052539825,
      "learning_rate": 5.9988053588190125e-06,
      "loss": 0.0017,
      "step": 103130
    },
    {
      "epoch": 8.801092243365474,
      "grad_norm": 0.10515164583921432,
      "learning_rate": 5.994538783172626e-06,
      "loss": 0.0017,
      "step": 103140
    },
    {
      "epoch": 8.801945558494753,
      "grad_norm": 0.09768437594175339,
      "learning_rate": 5.990272207526239e-06,
      "loss": 0.0019,
      "step": 103150
    },
    {
      "epoch": 8.80279887362403,
      "grad_norm": 0.24823851883411407,
      "learning_rate": 5.9860056318798535e-06,
      "loss": 0.0018,
      "step": 103160
    },
    {
      "epoch": 8.803652188753306,
      "grad_norm": 0.030714545398950577,
      "learning_rate": 5.981739056233467e-06,
      "loss": 0.0012,
      "step": 103170
    },
    {
      "epoch": 8.804505503882584,
      "grad_norm": 0.029031099751591682,
      "learning_rate": 5.977472480587081e-06,
      "loss": 0.0016,
      "step": 103180
    },
    {
      "epoch": 8.805358819011861,
      "grad_norm": 0.11525958776473999,
      "learning_rate": 5.973205904940695e-06,
      "loss": 0.0017,
      "step": 103190
    },
    {
      "epoch": 8.806212134141138,
      "grad_norm": 0.045424092561006546,
      "learning_rate": 5.968939329294309e-06,
      "loss": 0.0019,
      "step": 103200
    },
    {
      "epoch": 8.807065449270416,
      "grad_norm": 0.14840514957904816,
      "learning_rate": 5.964672753647922e-06,
      "loss": 0.0015,
      "step": 103210
    },
    {
      "epoch": 8.807918764399693,
      "grad_norm": 0.04934743046760559,
      "learning_rate": 5.960406178001536e-06,
      "loss": 0.0016,
      "step": 103220
    },
    {
      "epoch": 8.80877207952897,
      "grad_norm": 0.030574243515729904,
      "learning_rate": 5.95613960235515e-06,
      "loss": 0.0015,
      "step": 103230
    },
    {
      "epoch": 8.809625394658248,
      "grad_norm": 0.04035147652029991,
      "learning_rate": 5.951873026708764e-06,
      "loss": 0.0017,
      "step": 103240
    },
    {
      "epoch": 8.810478709787525,
      "grad_norm": 0.1704200655221939,
      "learning_rate": 5.9476064510623774e-06,
      "loss": 0.002,
      "step": 103250
    },
    {
      "epoch": 8.811332024916801,
      "grad_norm": 0.041157785803079605,
      "learning_rate": 5.943339875415992e-06,
      "loss": 0.0014,
      "step": 103260
    },
    {
      "epoch": 8.81218534004608,
      "grad_norm": 0.21563474833965302,
      "learning_rate": 5.939073299769606e-06,
      "loss": 0.0013,
      "step": 103270
    },
    {
      "epoch": 8.813038655175356,
      "grad_norm": 0.0451553650200367,
      "learning_rate": 5.9348067241232185e-06,
      "loss": 0.0015,
      "step": 103280
    },
    {
      "epoch": 8.813891970304633,
      "grad_norm": 0.14011919498443604,
      "learning_rate": 5.930540148476833e-06,
      "loss": 0.0017,
      "step": 103290
    },
    {
      "epoch": 8.814745285433911,
      "grad_norm": 0.04472363367676735,
      "learning_rate": 5.926273572830446e-06,
      "loss": 0.0017,
      "step": 103300
    },
    {
      "epoch": 8.815598600563188,
      "grad_norm": 0.058963675051927567,
      "learning_rate": 5.92200699718406e-06,
      "loss": 0.0022,
      "step": 103310
    },
    {
      "epoch": 8.816451915692465,
      "grad_norm": 0.06111988425254822,
      "learning_rate": 5.917740421537675e-06,
      "loss": 0.0016,
      "step": 103320
    },
    {
      "epoch": 8.817305230821743,
      "grad_norm": 0.30959099531173706,
      "learning_rate": 5.913473845891288e-06,
      "loss": 0.002,
      "step": 103330
    },
    {
      "epoch": 8.81815854595102,
      "grad_norm": 0.18706199526786804,
      "learning_rate": 5.909207270244901e-06,
      "loss": 0.0021,
      "step": 103340
    },
    {
      "epoch": 8.819011861080297,
      "grad_norm": 0.21946938335895538,
      "learning_rate": 5.904940694598516e-06,
      "loss": 0.0017,
      "step": 103350
    },
    {
      "epoch": 8.819865176209575,
      "grad_norm": 0.13670635223388672,
      "learning_rate": 5.900674118952129e-06,
      "loss": 0.0017,
      "step": 103360
    },
    {
      "epoch": 8.820718491338852,
      "grad_norm": 0.1296994537115097,
      "learning_rate": 5.896407543305743e-06,
      "loss": 0.0014,
      "step": 103370
    },
    {
      "epoch": 8.821571806468128,
      "grad_norm": 0.1818651556968689,
      "learning_rate": 5.892140967659357e-06,
      "loss": 0.0017,
      "step": 103380
    },
    {
      "epoch": 8.822425121597405,
      "grad_norm": 0.07837221026420593,
      "learning_rate": 5.887874392012971e-06,
      "loss": 0.0016,
      "step": 103390
    },
    {
      "epoch": 8.823278436726683,
      "grad_norm": 0.21726909279823303,
      "learning_rate": 5.883607816366585e-06,
      "loss": 0.0017,
      "step": 103400
    },
    {
      "epoch": 8.82413175185596,
      "grad_norm": 0.09397184103727341,
      "learning_rate": 5.879341240720198e-06,
      "loss": 0.0013,
      "step": 103410
    },
    {
      "epoch": 8.824985066985239,
      "grad_norm": 0.06639831513166428,
      "learning_rate": 5.875074665073812e-06,
      "loss": 0.0019,
      "step": 103420
    },
    {
      "epoch": 8.825838382114515,
      "grad_norm": 0.1809704601764679,
      "learning_rate": 5.870808089427426e-06,
      "loss": 0.002,
      "step": 103430
    },
    {
      "epoch": 8.826691697243792,
      "grad_norm": 0.030239958316087723,
      "learning_rate": 5.8665415137810395e-06,
      "loss": 0.0016,
      "step": 103440
    },
    {
      "epoch": 8.827545012373069,
      "grad_norm": 0.35942158102989197,
      "learning_rate": 5.862274938134654e-06,
      "loss": 0.0014,
      "step": 103450
    },
    {
      "epoch": 8.828398327502347,
      "grad_norm": 0.08596431463956833,
      "learning_rate": 5.858008362488267e-06,
      "loss": 0.0016,
      "step": 103460
    },
    {
      "epoch": 8.829251642631624,
      "grad_norm": 0.13651062548160553,
      "learning_rate": 5.8537417868418814e-06,
      "loss": 0.0018,
      "step": 103470
    },
    {
      "epoch": 8.8301049577609,
      "grad_norm": 0.34873729944229126,
      "learning_rate": 5.849475211195495e-06,
      "loss": 0.0017,
      "step": 103480
    },
    {
      "epoch": 8.830958272890179,
      "grad_norm": 0.2562270164489746,
      "learning_rate": 5.845208635549108e-06,
      "loss": 0.0017,
      "step": 103490
    },
    {
      "epoch": 8.831811588019455,
      "grad_norm": 0.12738460302352905,
      "learning_rate": 5.8409420599027225e-06,
      "loss": 0.0016,
      "step": 103500
    },
    {
      "epoch": 8.832664903148732,
      "grad_norm": 0.2722690999507904,
      "learning_rate": 5.836675484256336e-06,
      "loss": 0.0017,
      "step": 103510
    },
    {
      "epoch": 8.83351821827801,
      "grad_norm": 0.10303781181573868,
      "learning_rate": 5.83240890860995e-06,
      "loss": 0.0015,
      "step": 103520
    },
    {
      "epoch": 8.834371533407287,
      "grad_norm": 0.07326963543891907,
      "learning_rate": 5.828142332963564e-06,
      "loss": 0.0016,
      "step": 103530
    },
    {
      "epoch": 8.835224848536564,
      "grad_norm": 0.08042918890714645,
      "learning_rate": 5.823875757317177e-06,
      "loss": 0.002,
      "step": 103540
    },
    {
      "epoch": 8.836078163665842,
      "grad_norm": 0.12934301793575287,
      "learning_rate": 5.819609181670791e-06,
      "loss": 0.0016,
      "step": 103550
    },
    {
      "epoch": 8.836931478795119,
      "grad_norm": 0.3132498264312744,
      "learning_rate": 5.815342606024405e-06,
      "loss": 0.0018,
      "step": 103560
    },
    {
      "epoch": 8.837784793924396,
      "grad_norm": 0.2201901227235794,
      "learning_rate": 5.811076030378019e-06,
      "loss": 0.0019,
      "step": 103570
    },
    {
      "epoch": 8.838638109053674,
      "grad_norm": 0.14754316210746765,
      "learning_rate": 5.806809454731633e-06,
      "loss": 0.0014,
      "step": 103580
    },
    {
      "epoch": 8.83949142418295,
      "grad_norm": 0.07853788137435913,
      "learning_rate": 5.802542879085246e-06,
      "loss": 0.0021,
      "step": 103590
    },
    {
      "epoch": 8.840344739312227,
      "grad_norm": 0.09338221698999405,
      "learning_rate": 5.798276303438861e-06,
      "loss": 0.0015,
      "step": 103600
    },
    {
      "epoch": 8.841198054441506,
      "grad_norm": 0.16244882345199585,
      "learning_rate": 5.794009727792474e-06,
      "loss": 0.0017,
      "step": 103610
    },
    {
      "epoch": 8.842051369570783,
      "grad_norm": 0.07201152294874191,
      "learning_rate": 5.789743152146087e-06,
      "loss": 0.0013,
      "step": 103620
    },
    {
      "epoch": 8.84290468470006,
      "grad_norm": 0.39924049377441406,
      "learning_rate": 5.785476576499702e-06,
      "loss": 0.0019,
      "step": 103630
    },
    {
      "epoch": 8.843757999829338,
      "grad_norm": 0.07059724628925323,
      "learning_rate": 5.781210000853315e-06,
      "loss": 0.0015,
      "step": 103640
    },
    {
      "epoch": 8.844611314958614,
      "grad_norm": 0.03952056169509888,
      "learning_rate": 5.776943425206929e-06,
      "loss": 0.0019,
      "step": 103650
    },
    {
      "epoch": 8.845464630087891,
      "grad_norm": 0.1989825814962387,
      "learning_rate": 5.7726768495605435e-06,
      "loss": 0.002,
      "step": 103660
    },
    {
      "epoch": 8.84631794521717,
      "grad_norm": 0.09212275594472885,
      "learning_rate": 5.768410273914157e-06,
      "loss": 0.0016,
      "step": 103670
    },
    {
      "epoch": 8.847171260346446,
      "grad_norm": 0.21818137168884277,
      "learning_rate": 5.76414369826777e-06,
      "loss": 0.0017,
      "step": 103680
    },
    {
      "epoch": 8.848024575475723,
      "grad_norm": 0.03183365240693092,
      "learning_rate": 5.7598771226213846e-06,
      "loss": 0.0017,
      "step": 103690
    },
    {
      "epoch": 8.848877890605001,
      "grad_norm": 0.07792208343744278,
      "learning_rate": 5.755610546974998e-06,
      "loss": 0.0012,
      "step": 103700
    },
    {
      "epoch": 8.849731205734278,
      "grad_norm": 0.04133012518286705,
      "learning_rate": 5.751343971328612e-06,
      "loss": 0.0012,
      "step": 103710
    },
    {
      "epoch": 8.850584520863555,
      "grad_norm": 0.05734777823090553,
      "learning_rate": 5.747077395682226e-06,
      "loss": 0.0014,
      "step": 103720
    },
    {
      "epoch": 8.851437835992833,
      "grad_norm": 0.2190387099981308,
      "learning_rate": 5.74281082003584e-06,
      "loss": 0.0015,
      "step": 103730
    },
    {
      "epoch": 8.85229115112211,
      "grad_norm": 0.18586286902427673,
      "learning_rate": 5.738544244389453e-06,
      "loss": 0.0019,
      "step": 103740
    },
    {
      "epoch": 8.853144466251386,
      "grad_norm": 0.15144312381744385,
      "learning_rate": 5.734277668743067e-06,
      "loss": 0.0019,
      "step": 103750
    },
    {
      "epoch": 8.853997781380663,
      "grad_norm": 0.4140593409538269,
      "learning_rate": 5.730011093096681e-06,
      "loss": 0.0016,
      "step": 103760
    },
    {
      "epoch": 8.854851096509941,
      "grad_norm": 0.11401547491550446,
      "learning_rate": 5.725744517450294e-06,
      "loss": 0.0015,
      "step": 103770
    },
    {
      "epoch": 8.855704411639218,
      "grad_norm": 0.02982037328183651,
      "learning_rate": 5.7214779418039085e-06,
      "loss": 0.0018,
      "step": 103780
    },
    {
      "epoch": 8.856557726768497,
      "grad_norm": 0.035932961851358414,
      "learning_rate": 5.717211366157523e-06,
      "loss": 0.0018,
      "step": 103790
    },
    {
      "epoch": 8.857411041897773,
      "grad_norm": 0.07686106115579605,
      "learning_rate": 5.712944790511136e-06,
      "loss": 0.0016,
      "step": 103800
    },
    {
      "epoch": 8.85826435702705,
      "grad_norm": 0.36363181471824646,
      "learning_rate": 5.7086782148647495e-06,
      "loss": 0.0019,
      "step": 103810
    },
    {
      "epoch": 8.859117672156327,
      "grad_norm": 0.09227865934371948,
      "learning_rate": 5.704411639218364e-06,
      "loss": 0.0016,
      "step": 103820
    },
    {
      "epoch": 8.859970987285605,
      "grad_norm": 0.14389120042324066,
      "learning_rate": 5.700145063571977e-06,
      "loss": 0.0027,
      "step": 103830
    },
    {
      "epoch": 8.860824302414882,
      "grad_norm": 0.0920037254691124,
      "learning_rate": 5.695878487925591e-06,
      "loss": 0.0018,
      "step": 103840
    },
    {
      "epoch": 8.861677617544158,
      "grad_norm": 0.10710198432207108,
      "learning_rate": 5.691611912279205e-06,
      "loss": 0.0017,
      "step": 103850
    },
    {
      "epoch": 8.862530932673437,
      "grad_norm": 0.08430568873882294,
      "learning_rate": 5.687345336632819e-06,
      "loss": 0.0022,
      "step": 103860
    },
    {
      "epoch": 8.863384247802713,
      "grad_norm": 0.1287878155708313,
      "learning_rate": 5.6830787609864324e-06,
      "loss": 0.0014,
      "step": 103870
    },
    {
      "epoch": 8.86423756293199,
      "grad_norm": 0.3239338994026184,
      "learning_rate": 5.678812185340046e-06,
      "loss": 0.0015,
      "step": 103880
    },
    {
      "epoch": 8.865090878061268,
      "grad_norm": 0.14842453598976135,
      "learning_rate": 5.67454560969366e-06,
      "loss": 0.0017,
      "step": 103890
    },
    {
      "epoch": 8.865944193190545,
      "grad_norm": 0.17789296805858612,
      "learning_rate": 5.670279034047274e-06,
      "loss": 0.0017,
      "step": 103900
    },
    {
      "epoch": 8.866797508319822,
      "grad_norm": 0.2224033623933792,
      "learning_rate": 5.666012458400888e-06,
      "loss": 0.0021,
      "step": 103910
    },
    {
      "epoch": 8.8676508234491,
      "grad_norm": 0.14438340067863464,
      "learning_rate": 5.661745882754502e-06,
      "loss": 0.0018,
      "step": 103920
    },
    {
      "epoch": 8.868504138578377,
      "grad_norm": 0.027999190613627434,
      "learning_rate": 5.657479307108115e-06,
      "loss": 0.0015,
      "step": 103930
    },
    {
      "epoch": 8.869357453707654,
      "grad_norm": 0.2954113483428955,
      "learning_rate": 5.653212731461729e-06,
      "loss": 0.0015,
      "step": 103940
    },
    {
      "epoch": 8.870210768836932,
      "grad_norm": 0.12720195949077606,
      "learning_rate": 5.648946155815343e-06,
      "loss": 0.0017,
      "step": 103950
    },
    {
      "epoch": 8.871064083966209,
      "grad_norm": 0.2741904854774475,
      "learning_rate": 5.644679580168956e-06,
      "loss": 0.0012,
      "step": 103960
    },
    {
      "epoch": 8.871917399095485,
      "grad_norm": 0.029190290719270706,
      "learning_rate": 5.640413004522571e-06,
      "loss": 0.0014,
      "step": 103970
    },
    {
      "epoch": 8.872770714224764,
      "grad_norm": 0.04344473034143448,
      "learning_rate": 5.636146428876184e-06,
      "loss": 0.0016,
      "step": 103980
    },
    {
      "epoch": 8.87362402935404,
      "grad_norm": 0.16318438947200775,
      "learning_rate": 5.631879853229798e-06,
      "loss": 0.0015,
      "step": 103990
    },
    {
      "epoch": 8.874477344483317,
      "grad_norm": 0.224293053150177,
      "learning_rate": 5.6276132775834125e-06,
      "loss": 0.0019,
      "step": 104000
    },
    {
      "epoch": 8.875330659612596,
      "grad_norm": 0.19914492964744568,
      "learning_rate": 5.623346701937025e-06,
      "loss": 0.0014,
      "step": 104010
    },
    {
      "epoch": 8.876183974741872,
      "grad_norm": 0.08139467984437943,
      "learning_rate": 5.619080126290639e-06,
      "loss": 0.002,
      "step": 104020
    },
    {
      "epoch": 8.877037289871149,
      "grad_norm": 0.13191816210746765,
      "learning_rate": 5.6148135506442535e-06,
      "loss": 0.0016,
      "step": 104030
    },
    {
      "epoch": 8.877890605000427,
      "grad_norm": 0.1404668688774109,
      "learning_rate": 5.610546974997867e-06,
      "loss": 0.0018,
      "step": 104040
    },
    {
      "epoch": 8.878743920129704,
      "grad_norm": 0.0782540887594223,
      "learning_rate": 5.606280399351481e-06,
      "loss": 0.0015,
      "step": 104050
    },
    {
      "epoch": 8.87959723525898,
      "grad_norm": 0.2939146161079407,
      "learning_rate": 5.6020138237050945e-06,
      "loss": 0.0017,
      "step": 104060
    },
    {
      "epoch": 8.88045055038826,
      "grad_norm": 0.05971791222691536,
      "learning_rate": 5.597747248058708e-06,
      "loss": 0.0016,
      "step": 104070
    },
    {
      "epoch": 8.881303865517536,
      "grad_norm": 0.19902606308460236,
      "learning_rate": 5.593480672412322e-06,
      "loss": 0.0018,
      "step": 104080
    },
    {
      "epoch": 8.882157180646812,
      "grad_norm": 0.3061922788619995,
      "learning_rate": 5.5892140967659356e-06,
      "loss": 0.0016,
      "step": 104090
    },
    {
      "epoch": 8.883010495776091,
      "grad_norm": 0.13182660937309265,
      "learning_rate": 5.58494752111955e-06,
      "loss": 0.0016,
      "step": 104100
    },
    {
      "epoch": 8.883863810905368,
      "grad_norm": 0.09735573083162308,
      "learning_rate": 5.580680945473163e-06,
      "loss": 0.0015,
      "step": 104110
    },
    {
      "epoch": 8.884717126034644,
      "grad_norm": 0.21400956809520721,
      "learning_rate": 5.5764143698267774e-06,
      "loss": 0.0015,
      "step": 104120
    },
    {
      "epoch": 8.885570441163921,
      "grad_norm": 0.07958842813968658,
      "learning_rate": 5.572147794180392e-06,
      "loss": 0.0017,
      "step": 104130
    },
    {
      "epoch": 8.8864237562932,
      "grad_norm": 0.06584060192108154,
      "learning_rate": 5.567881218534004e-06,
      "loss": 0.0019,
      "step": 104140
    },
    {
      "epoch": 8.887277071422476,
      "grad_norm": 0.04409026354551315,
      "learning_rate": 5.5636146428876185e-06,
      "loss": 0.0016,
      "step": 104150
    },
    {
      "epoch": 8.888130386551754,
      "grad_norm": 0.057114582508802414,
      "learning_rate": 5.559348067241233e-06,
      "loss": 0.0013,
      "step": 104160
    },
    {
      "epoch": 8.888983701681031,
      "grad_norm": 0.035616178065538406,
      "learning_rate": 5.555081491594846e-06,
      "loss": 0.0019,
      "step": 104170
    },
    {
      "epoch": 8.889837016810308,
      "grad_norm": 0.3116367757320404,
      "learning_rate": 5.55081491594846e-06,
      "loss": 0.0015,
      "step": 104180
    },
    {
      "epoch": 8.890690331939584,
      "grad_norm": 0.12858045101165771,
      "learning_rate": 5.546548340302074e-06,
      "loss": 0.0019,
      "step": 104190
    },
    {
      "epoch": 8.891543647068863,
      "grad_norm": 0.11084413528442383,
      "learning_rate": 5.542281764655688e-06,
      "loss": 0.0018,
      "step": 104200
    },
    {
      "epoch": 8.89239696219814,
      "grad_norm": 0.08831775933504105,
      "learning_rate": 5.538015189009301e-06,
      "loss": 0.0014,
      "step": 104210
    },
    {
      "epoch": 8.893250277327416,
      "grad_norm": 0.2361402064561844,
      "learning_rate": 5.533748613362915e-06,
      "loss": 0.0015,
      "step": 104220
    },
    {
      "epoch": 8.894103592456695,
      "grad_norm": 0.09553685039281845,
      "learning_rate": 5.529482037716529e-06,
      "loss": 0.0018,
      "step": 104230
    },
    {
      "epoch": 8.894956907585971,
      "grad_norm": 0.12730777263641357,
      "learning_rate": 5.525215462070142e-06,
      "loss": 0.0015,
      "step": 104240
    },
    {
      "epoch": 8.895810222715248,
      "grad_norm": 0.07774191349744797,
      "learning_rate": 5.520948886423757e-06,
      "loss": 0.0017,
      "step": 104250
    },
    {
      "epoch": 8.896663537844526,
      "grad_norm": 0.11161322891712189,
      "learning_rate": 5.516682310777371e-06,
      "loss": 0.0013,
      "step": 104260
    },
    {
      "epoch": 8.897516852973803,
      "grad_norm": 0.2735719680786133,
      "learning_rate": 5.5124157351309834e-06,
      "loss": 0.002,
      "step": 104270
    },
    {
      "epoch": 8.89837016810308,
      "grad_norm": 0.05989944934844971,
      "learning_rate": 5.508149159484598e-06,
      "loss": 0.0018,
      "step": 104280
    },
    {
      "epoch": 8.899223483232358,
      "grad_norm": 0.4158988893032074,
      "learning_rate": 5.503882583838212e-06,
      "loss": 0.0018,
      "step": 104290
    },
    {
      "epoch": 8.900076798361635,
      "grad_norm": 0.12666843831539154,
      "learning_rate": 5.499616008191825e-06,
      "loss": 0.0017,
      "step": 104300
    },
    {
      "epoch": 8.900930113490912,
      "grad_norm": 0.1104620024561882,
      "learning_rate": 5.4953494325454395e-06,
      "loss": 0.0015,
      "step": 104310
    },
    {
      "epoch": 8.90178342862019,
      "grad_norm": 0.04538855329155922,
      "learning_rate": 5.491082856899053e-06,
      "loss": 0.0017,
      "step": 104320
    },
    {
      "epoch": 8.902636743749467,
      "grad_norm": 0.04956776276230812,
      "learning_rate": 5.486816281252667e-06,
      "loss": 0.0019,
      "step": 104330
    },
    {
      "epoch": 8.903490058878743,
      "grad_norm": 0.18170268833637238,
      "learning_rate": 5.482549705606281e-06,
      "loss": 0.0018,
      "step": 104340
    },
    {
      "epoch": 8.904343374008022,
      "grad_norm": 0.07954250276088715,
      "learning_rate": 5.478283129959894e-06,
      "loss": 0.0019,
      "step": 104350
    },
    {
      "epoch": 8.905196689137298,
      "grad_norm": 0.06592921167612076,
      "learning_rate": 5.474016554313508e-06,
      "loss": 0.0015,
      "step": 104360
    },
    {
      "epoch": 8.906050004266575,
      "grad_norm": 0.17647556960582733,
      "learning_rate": 5.4697499786671225e-06,
      "loss": 0.0016,
      "step": 104370
    },
    {
      "epoch": 8.906903319395854,
      "grad_norm": 0.02287004515528679,
      "learning_rate": 5.465483403020736e-06,
      "loss": 0.0015,
      "step": 104380
    },
    {
      "epoch": 8.90775663452513,
      "grad_norm": 0.24176327884197235,
      "learning_rate": 5.46121682737435e-06,
      "loss": 0.002,
      "step": 104390
    },
    {
      "epoch": 8.908609949654407,
      "grad_norm": 0.18270012736320496,
      "learning_rate": 5.4569502517279635e-06,
      "loss": 0.0016,
      "step": 104400
    },
    {
      "epoch": 8.909463264783685,
      "grad_norm": 0.2343757003545761,
      "learning_rate": 5.452683676081577e-06,
      "loss": 0.0018,
      "step": 104410
    },
    {
      "epoch": 8.910316579912962,
      "grad_norm": 0.09241966903209686,
      "learning_rate": 5.448417100435191e-06,
      "loss": 0.0018,
      "step": 104420
    },
    {
      "epoch": 8.911169895042239,
      "grad_norm": 0.09544744342565536,
      "learning_rate": 5.4441505247888045e-06,
      "loss": 0.0018,
      "step": 104430
    },
    {
      "epoch": 8.912023210171517,
      "grad_norm": 0.03219706192612648,
      "learning_rate": 5.439883949142419e-06,
      "loss": 0.0016,
      "step": 104440
    },
    {
      "epoch": 8.912876525300794,
      "grad_norm": 0.11003679037094116,
      "learning_rate": 5.435617373496032e-06,
      "loss": 0.002,
      "step": 104450
    },
    {
      "epoch": 8.91372984043007,
      "grad_norm": 0.1286858320236206,
      "learning_rate": 5.431350797849646e-06,
      "loss": 0.0019,
      "step": 104460
    },
    {
      "epoch": 8.914583155559349,
      "grad_norm": 0.03743981942534447,
      "learning_rate": 5.42708422220326e-06,
      "loss": 0.0019,
      "step": 104470
    },
    {
      "epoch": 8.915436470688626,
      "grad_norm": 0.05902516469359398,
      "learning_rate": 5.422817646556873e-06,
      "loss": 0.0013,
      "step": 104480
    },
    {
      "epoch": 8.916289785817902,
      "grad_norm": 0.066258504986763,
      "learning_rate": 5.418551070910487e-06,
      "loss": 0.0017,
      "step": 104490
    },
    {
      "epoch": 8.917143100947179,
      "grad_norm": 0.13235656917095184,
      "learning_rate": 5.414284495264102e-06,
      "loss": 0.0018,
      "step": 104500
    },
    {
      "epoch": 8.917996416076457,
      "grad_norm": 0.04287993162870407,
      "learning_rate": 5.410017919617715e-06,
      "loss": 0.0019,
      "step": 104510
    },
    {
      "epoch": 8.918849731205734,
      "grad_norm": 0.04174012318253517,
      "learning_rate": 5.405751343971329e-06,
      "loss": 0.0017,
      "step": 104520
    },
    {
      "epoch": 8.919703046335012,
      "grad_norm": 0.09029413759708405,
      "learning_rate": 5.401484768324943e-06,
      "loss": 0.0015,
      "step": 104530
    },
    {
      "epoch": 8.920556361464289,
      "grad_norm": 0.2197025865316391,
      "learning_rate": 5.397218192678556e-06,
      "loss": 0.0019,
      "step": 104540
    },
    {
      "epoch": 8.921409676593566,
      "grad_norm": 0.2514084279537201,
      "learning_rate": 5.39295161703217e-06,
      "loss": 0.0017,
      "step": 104550
    },
    {
      "epoch": 8.922262991722842,
      "grad_norm": 0.1288180947303772,
      "learning_rate": 5.388685041385784e-06,
      "loss": 0.0016,
      "step": 104560
    },
    {
      "epoch": 8.92311630685212,
      "grad_norm": 0.23616884648799896,
      "learning_rate": 5.384418465739398e-06,
      "loss": 0.0016,
      "step": 104570
    },
    {
      "epoch": 8.923969621981398,
      "grad_norm": 0.1581052988767624,
      "learning_rate": 5.380151890093011e-06,
      "loss": 0.0016,
      "step": 104580
    },
    {
      "epoch": 8.924822937110674,
      "grad_norm": 0.2148350477218628,
      "learning_rate": 5.375885314446626e-06,
      "loss": 0.0017,
      "step": 104590
    },
    {
      "epoch": 8.925676252239953,
      "grad_norm": 0.06329147517681122,
      "learning_rate": 5.37161873880024e-06,
      "loss": 0.0017,
      "step": 104600
    },
    {
      "epoch": 8.92652956736923,
      "grad_norm": 0.046174563467502594,
      "learning_rate": 5.367352163153852e-06,
      "loss": 0.0021,
      "step": 104610
    },
    {
      "epoch": 8.927382882498506,
      "grad_norm": 0.296220064163208,
      "learning_rate": 5.363085587507467e-06,
      "loss": 0.0019,
      "step": 104620
    },
    {
      "epoch": 8.928236197627784,
      "grad_norm": 0.13775306940078735,
      "learning_rate": 5.358819011861081e-06,
      "loss": 0.0017,
      "step": 104630
    },
    {
      "epoch": 8.929089512757061,
      "grad_norm": 0.11103560775518417,
      "learning_rate": 5.354552436214694e-06,
      "loss": 0.0014,
      "step": 104640
    },
    {
      "epoch": 8.929942827886338,
      "grad_norm": 0.29072052240371704,
      "learning_rate": 5.3502858605683085e-06,
      "loss": 0.0018,
      "step": 104650
    },
    {
      "epoch": 8.930796143015616,
      "grad_norm": 0.11034204065799713,
      "learning_rate": 5.346019284921922e-06,
      "loss": 0.0017,
      "step": 104660
    },
    {
      "epoch": 8.931649458144893,
      "grad_norm": 0.21658319234848022,
      "learning_rate": 5.341752709275535e-06,
      "loss": 0.0016,
      "step": 104670
    },
    {
      "epoch": 8.93250277327417,
      "grad_norm": 0.036935027688741684,
      "learning_rate": 5.3374861336291495e-06,
      "loss": 0.0015,
      "step": 104680
    },
    {
      "epoch": 8.933356088403448,
      "grad_norm": 0.07625837624073029,
      "learning_rate": 5.333219557982763e-06,
      "loss": 0.002,
      "step": 104690
    },
    {
      "epoch": 8.934209403532725,
      "grad_norm": 0.18360400199890137,
      "learning_rate": 5.328952982336377e-06,
      "loss": 0.0021,
      "step": 104700
    },
    {
      "epoch": 8.935062718662001,
      "grad_norm": 0.4329409599304199,
      "learning_rate": 5.3246864066899906e-06,
      "loss": 0.0013,
      "step": 104710
    },
    {
      "epoch": 8.93591603379128,
      "grad_norm": 0.21390773355960846,
      "learning_rate": 5.320419831043605e-06,
      "loss": 0.0017,
      "step": 104720
    },
    {
      "epoch": 8.936769348920556,
      "grad_norm": 0.11180496215820312,
      "learning_rate": 5.316153255397219e-06,
      "loss": 0.0019,
      "step": 104730
    },
    {
      "epoch": 8.937622664049833,
      "grad_norm": 0.10861457139253616,
      "learning_rate": 5.311886679750832e-06,
      "loss": 0.0019,
      "step": 104740
    },
    {
      "epoch": 8.938475979179112,
      "grad_norm": 0.03532511368393898,
      "learning_rate": 5.307620104104446e-06,
      "loss": 0.0013,
      "step": 104750
    },
    {
      "epoch": 8.939329294308388,
      "grad_norm": 0.17975199222564697,
      "learning_rate": 5.30335352845806e-06,
      "loss": 0.0015,
      "step": 104760
    },
    {
      "epoch": 8.940182609437665,
      "grad_norm": 0.05208103731274605,
      "learning_rate": 5.2990869528116735e-06,
      "loss": 0.0015,
      "step": 104770
    },
    {
      "epoch": 8.941035924566943,
      "grad_norm": 0.04638226330280304,
      "learning_rate": 5.294820377165288e-06,
      "loss": 0.0021,
      "step": 104780
    },
    {
      "epoch": 8.94188923969622,
      "grad_norm": 0.13219118118286133,
      "learning_rate": 5.290553801518901e-06,
      "loss": 0.0021,
      "step": 104790
    },
    {
      "epoch": 8.942742554825497,
      "grad_norm": 0.201288640499115,
      "learning_rate": 5.286287225872515e-06,
      "loss": 0.0017,
      "step": 104800
    },
    {
      "epoch": 8.943595869954775,
      "grad_norm": 0.03246038407087326,
      "learning_rate": 5.282020650226129e-06,
      "loss": 0.0013,
      "step": 104810
    },
    {
      "epoch": 8.944449185084052,
      "grad_norm": 0.11119987070560455,
      "learning_rate": 5.277754074579742e-06,
      "loss": 0.0017,
      "step": 104820
    },
    {
      "epoch": 8.945302500213328,
      "grad_norm": 0.1869121640920639,
      "learning_rate": 5.273487498933356e-06,
      "loss": 0.0016,
      "step": 104830
    },
    {
      "epoch": 8.946155815342607,
      "grad_norm": 0.2855958342552185,
      "learning_rate": 5.269220923286971e-06,
      "loss": 0.002,
      "step": 104840
    },
    {
      "epoch": 8.947009130471884,
      "grad_norm": 0.09639815241098404,
      "learning_rate": 5.264954347640584e-06,
      "loss": 0.0019,
      "step": 104850
    },
    {
      "epoch": 8.94786244560116,
      "grad_norm": 0.1028841957449913,
      "learning_rate": 5.260687771994198e-06,
      "loss": 0.0016,
      "step": 104860
    },
    {
      "epoch": 8.948715760730437,
      "grad_norm": 0.09674492478370667,
      "learning_rate": 5.256421196347811e-06,
      "loss": 0.0022,
      "step": 104870
    },
    {
      "epoch": 8.949569075859715,
      "grad_norm": 0.0620260015130043,
      "learning_rate": 5.252154620701425e-06,
      "loss": 0.0016,
      "step": 104880
    },
    {
      "epoch": 8.950422390988992,
      "grad_norm": 0.11370924860239029,
      "learning_rate": 5.247888045055039e-06,
      "loss": 0.002,
      "step": 104890
    },
    {
      "epoch": 8.95127570611827,
      "grad_norm": 0.06280042976140976,
      "learning_rate": 5.243621469408653e-06,
      "loss": 0.0019,
      "step": 104900
    },
    {
      "epoch": 8.952129021247547,
      "grad_norm": 0.08876307308673859,
      "learning_rate": 5.239354893762267e-06,
      "loss": 0.0014,
      "step": 104910
    },
    {
      "epoch": 8.952982336376824,
      "grad_norm": 0.12618158757686615,
      "learning_rate": 5.23508831811588e-06,
      "loss": 0.0014,
      "step": 104920
    },
    {
      "epoch": 8.9538356515061,
      "grad_norm": 0.13057070970535278,
      "learning_rate": 5.2308217424694945e-06,
      "loss": 0.0016,
      "step": 104930
    },
    {
      "epoch": 8.954688966635379,
      "grad_norm": 0.0939294844865799,
      "learning_rate": 5.226555166823108e-06,
      "loss": 0.0015,
      "step": 104940
    },
    {
      "epoch": 8.955542281764655,
      "grad_norm": 0.3101579248905182,
      "learning_rate": 5.222288591176721e-06,
      "loss": 0.0014,
      "step": 104950
    },
    {
      "epoch": 8.956395596893932,
      "grad_norm": 0.13546901941299438,
      "learning_rate": 5.2180220155303356e-06,
      "loss": 0.0016,
      "step": 104960
    },
    {
      "epoch": 8.95724891202321,
      "grad_norm": 0.05952129885554314,
      "learning_rate": 5.21375543988395e-06,
      "loss": 0.0016,
      "step": 104970
    },
    {
      "epoch": 8.958102227152487,
      "grad_norm": 0.11578234285116196,
      "learning_rate": 5.209488864237563e-06,
      "loss": 0.0018,
      "step": 104980
    },
    {
      "epoch": 8.958955542281764,
      "grad_norm": 0.06368261575698853,
      "learning_rate": 5.2052222885911774e-06,
      "loss": 0.0017,
      "step": 104990
    },
    {
      "epoch": 8.959808857411042,
      "grad_norm": 0.11303015798330307,
      "learning_rate": 5.200955712944791e-06,
      "loss": 0.002,
      "step": 105000
    },
    {
      "epoch": 8.960662172540319,
      "grad_norm": 0.03491700440645218,
      "learning_rate": 5.196689137298404e-06,
      "loss": 0.0018,
      "step": 105010
    },
    {
      "epoch": 8.961515487669596,
      "grad_norm": 0.25421565771102905,
      "learning_rate": 5.1924225616520185e-06,
      "loss": 0.0016,
      "step": 105020
    },
    {
      "epoch": 8.962368802798874,
      "grad_norm": 0.25273585319519043,
      "learning_rate": 5.188155986005632e-06,
      "loss": 0.0015,
      "step": 105030
    },
    {
      "epoch": 8.96322211792815,
      "grad_norm": 0.044824693351984024,
      "learning_rate": 5.183889410359246e-06,
      "loss": 0.0017,
      "step": 105040
    },
    {
      "epoch": 8.964075433057427,
      "grad_norm": 0.20169515907764435,
      "learning_rate": 5.1796228347128595e-06,
      "loss": 0.0019,
      "step": 105050
    },
    {
      "epoch": 8.964928748186706,
      "grad_norm": 0.3121787905693054,
      "learning_rate": 5.175356259066474e-06,
      "loss": 0.0016,
      "step": 105060
    },
    {
      "epoch": 8.965782063315983,
      "grad_norm": 0.06026119366288185,
      "learning_rate": 5.171089683420087e-06,
      "loss": 0.0015,
      "step": 105070
    },
    {
      "epoch": 8.96663537844526,
      "grad_norm": 0.2872951924800873,
      "learning_rate": 5.1668231077737005e-06,
      "loss": 0.0015,
      "step": 105080
    },
    {
      "epoch": 8.967488693574538,
      "grad_norm": 0.12801435589790344,
      "learning_rate": 5.162556532127315e-06,
      "loss": 0.0017,
      "step": 105090
    },
    {
      "epoch": 8.968342008703814,
      "grad_norm": 0.2934226095676422,
      "learning_rate": 5.158289956480929e-06,
      "loss": 0.0016,
      "step": 105100
    },
    {
      "epoch": 8.969195323833091,
      "grad_norm": 0.2514885663986206,
      "learning_rate": 5.154023380834542e-06,
      "loss": 0.0014,
      "step": 105110
    },
    {
      "epoch": 8.97004863896237,
      "grad_norm": 0.03996990621089935,
      "learning_rate": 5.149756805188157e-06,
      "loss": 0.0014,
      "step": 105120
    },
    {
      "epoch": 8.970901954091646,
      "grad_norm": 0.07909073680639267,
      "learning_rate": 5.14549022954177e-06,
      "loss": 0.0013,
      "step": 105130
    },
    {
      "epoch": 8.971755269220923,
      "grad_norm": 0.09370491653680801,
      "learning_rate": 5.1412236538953834e-06,
      "loss": 0.0017,
      "step": 105140
    },
    {
      "epoch": 8.972608584350201,
      "grad_norm": 0.0425751768052578,
      "learning_rate": 5.136957078248998e-06,
      "loss": 0.0016,
      "step": 105150
    },
    {
      "epoch": 8.973461899479478,
      "grad_norm": 0.11454100161790848,
      "learning_rate": 5.132690502602611e-06,
      "loss": 0.0015,
      "step": 105160
    },
    {
      "epoch": 8.974315214608755,
      "grad_norm": 0.03453677147626877,
      "learning_rate": 5.128423926956225e-06,
      "loss": 0.0013,
      "step": 105170
    },
    {
      "epoch": 8.975168529738033,
      "grad_norm": 0.13643205165863037,
      "learning_rate": 5.124157351309839e-06,
      "loss": 0.0017,
      "step": 105180
    },
    {
      "epoch": 8.97602184486731,
      "grad_norm": 0.1293424367904663,
      "learning_rate": 5.119890775663453e-06,
      "loss": 0.0015,
      "step": 105190
    },
    {
      "epoch": 8.976875159996586,
      "grad_norm": 0.29039523005485535,
      "learning_rate": 5.115624200017066e-06,
      "loss": 0.0018,
      "step": 105200
    },
    {
      "epoch": 8.977728475125865,
      "grad_norm": 0.21612536907196045,
      "learning_rate": 5.11135762437068e-06,
      "loss": 0.0015,
      "step": 105210
    },
    {
      "epoch": 8.978581790255141,
      "grad_norm": 0.09525325149297714,
      "learning_rate": 5.107091048724294e-06,
      "loss": 0.0017,
      "step": 105220
    },
    {
      "epoch": 8.979435105384418,
      "grad_norm": 0.18315719068050385,
      "learning_rate": 5.102824473077908e-06,
      "loss": 0.0016,
      "step": 105230
    },
    {
      "epoch": 8.980288420513695,
      "grad_norm": 0.13947299122810364,
      "learning_rate": 5.098557897431522e-06,
      "loss": 0.0018,
      "step": 105240
    },
    {
      "epoch": 8.981141735642973,
      "grad_norm": 0.07484914362430573,
      "learning_rate": 5.094291321785136e-06,
      "loss": 0.0016,
      "step": 105250
    },
    {
      "epoch": 8.98199505077225,
      "grad_norm": 0.27118900418281555,
      "learning_rate": 5.090024746138749e-06,
      "loss": 0.0016,
      "step": 105260
    },
    {
      "epoch": 8.982848365901528,
      "grad_norm": 0.2114039659500122,
      "learning_rate": 5.085758170492363e-06,
      "loss": 0.0014,
      "step": 105270
    },
    {
      "epoch": 8.983701681030805,
      "grad_norm": 0.1754232794046402,
      "learning_rate": 5.081491594845977e-06,
      "loss": 0.0015,
      "step": 105280
    },
    {
      "epoch": 8.984554996160082,
      "grad_norm": 0.14666418731212616,
      "learning_rate": 5.07722501919959e-06,
      "loss": 0.0019,
      "step": 105290
    },
    {
      "epoch": 8.985408311289358,
      "grad_norm": 0.19687551259994507,
      "learning_rate": 5.0729584435532045e-06,
      "loss": 0.0016,
      "step": 105300
    },
    {
      "epoch": 8.986261626418637,
      "grad_norm": 0.16555944085121155,
      "learning_rate": 5.068691867906819e-06,
      "loss": 0.0016,
      "step": 105310
    },
    {
      "epoch": 8.987114941547913,
      "grad_norm": 0.08346206694841385,
      "learning_rate": 5.064425292260432e-06,
      "loss": 0.0019,
      "step": 105320
    },
    {
      "epoch": 8.98796825667719,
      "grad_norm": 0.07567919790744781,
      "learning_rate": 5.060158716614046e-06,
      "loss": 0.0016,
      "step": 105330
    },
    {
      "epoch": 8.988821571806469,
      "grad_norm": 0.029416363686323166,
      "learning_rate": 5.055892140967659e-06,
      "loss": 0.0014,
      "step": 105340
    },
    {
      "epoch": 8.989674886935745,
      "grad_norm": 0.11082310229539871,
      "learning_rate": 5.051625565321273e-06,
      "loss": 0.0015,
      "step": 105350
    },
    {
      "epoch": 8.990528202065022,
      "grad_norm": 0.08021984249353409,
      "learning_rate": 5.047358989674887e-06,
      "loss": 0.0019,
      "step": 105360
    },
    {
      "epoch": 8.9913815171943,
      "grad_norm": 0.18477120995521545,
      "learning_rate": 5.043092414028501e-06,
      "loss": 0.0017,
      "step": 105370
    },
    {
      "epoch": 8.992234832323577,
      "grad_norm": 0.2529599964618683,
      "learning_rate": 5.038825838382115e-06,
      "loss": 0.0016,
      "step": 105380
    },
    {
      "epoch": 8.993088147452854,
      "grad_norm": 0.25690752267837524,
      "learning_rate": 5.0345592627357284e-06,
      "loss": 0.0017,
      "step": 105390
    },
    {
      "epoch": 8.993941462582132,
      "grad_norm": 0.11398384720087051,
      "learning_rate": 5.030292687089342e-06,
      "loss": 0.0013,
      "step": 105400
    },
    {
      "epoch": 8.994794777711409,
      "grad_norm": 0.20162945985794067,
      "learning_rate": 5.026026111442956e-06,
      "loss": 0.0015,
      "step": 105410
    },
    {
      "epoch": 8.995648092840685,
      "grad_norm": 0.08379410207271576,
      "learning_rate": 5.0217595357965695e-06,
      "loss": 0.0015,
      "step": 105420
    },
    {
      "epoch": 8.996501407969964,
      "grad_norm": 0.18261496722698212,
      "learning_rate": 5.017492960150184e-06,
      "loss": 0.0016,
      "step": 105430
    },
    {
      "epoch": 8.99735472309924,
      "grad_norm": 0.032935064285993576,
      "learning_rate": 5.013226384503798e-06,
      "loss": 0.0017,
      "step": 105440
    },
    {
      "epoch": 8.998208038228517,
      "grad_norm": 0.13538385927677155,
      "learning_rate": 5.008959808857411e-06,
      "loss": 0.0014,
      "step": 105450
    },
    {
      "epoch": 8.999061353357796,
      "grad_norm": 0.0489390529692173,
      "learning_rate": 5.004693233211026e-06,
      "loss": 0.0016,
      "step": 105460
    },
    {
      "epoch": 8.999914668487072,
      "grad_norm": 0.09040677547454834,
      "learning_rate": 5.000426657564639e-06,
      "loss": 0.0019,
      "step": 105470
    },
    {
      "epoch": 9.0,
      "eval_loss": 0.0016455453587695956,
      "eval_runtime": 99.9706,
      "eval_samples_per_second": 1500.441,
      "eval_steps_per_second": 23.447,
      "step": 105471
    },
    {
      "epoch": 9.000767983616349,
      "grad_norm": 0.14851370453834534,
      "learning_rate": 4.996160081918252e-06,
      "loss": 0.0015,
      "step": 105480
    },
    {
      "epoch": 9.001621298745627,
      "grad_norm": 0.09763351082801819,
      "learning_rate": 4.991893506271867e-06,
      "loss": 0.0014,
      "step": 105490
    },
    {
      "epoch": 9.002474613874904,
      "grad_norm": 0.05155812203884125,
      "learning_rate": 4.98762693062548e-06,
      "loss": 0.0014,
      "step": 105500
    },
    {
      "epoch": 9.00332792900418,
      "grad_norm": 0.23904816806316376,
      "learning_rate": 4.983360354979094e-06,
      "loss": 0.002,
      "step": 105510
    },
    {
      "epoch": 9.00418124413346,
      "grad_norm": 0.16483327746391296,
      "learning_rate": 4.979093779332708e-06,
      "loss": 0.0015,
      "step": 105520
    },
    {
      "epoch": 9.005034559262736,
      "grad_norm": 0.16533324122428894,
      "learning_rate": 4.974827203686322e-06,
      "loss": 0.0015,
      "step": 105530
    },
    {
      "epoch": 9.005887874392013,
      "grad_norm": 0.09620021283626556,
      "learning_rate": 4.970560628039935e-06,
      "loss": 0.002,
      "step": 105540
    },
    {
      "epoch": 9.006741189521291,
      "grad_norm": 0.226893350481987,
      "learning_rate": 4.966294052393549e-06,
      "loss": 0.0021,
      "step": 105550
    },
    {
      "epoch": 9.007594504650568,
      "grad_norm": 0.34968289732933044,
      "learning_rate": 4.962027476747163e-06,
      "loss": 0.0018,
      "step": 105560
    },
    {
      "epoch": 9.008447819779844,
      "grad_norm": 0.08023937791585922,
      "learning_rate": 4.957760901100777e-06,
      "loss": 0.0018,
      "step": 105570
    },
    {
      "epoch": 9.009301134909123,
      "grad_norm": 0.12882022559642792,
      "learning_rate": 4.9534943254543906e-06,
      "loss": 0.0017,
      "step": 105580
    },
    {
      "epoch": 9.0101544500384,
      "grad_norm": 0.2705933153629303,
      "learning_rate": 4.949227749808005e-06,
      "loss": 0.0021,
      "step": 105590
    },
    {
      "epoch": 9.011007765167676,
      "grad_norm": 0.20973671972751617,
      "learning_rate": 4.944961174161618e-06,
      "loss": 0.0019,
      "step": 105600
    },
    {
      "epoch": 9.011861080296955,
      "grad_norm": 0.1477992832660675,
      "learning_rate": 4.940694598515232e-06,
      "loss": 0.0016,
      "step": 105610
    },
    {
      "epoch": 9.012714395426231,
      "grad_norm": 0.27030646800994873,
      "learning_rate": 4.936428022868846e-06,
      "loss": 0.0017,
      "step": 105620
    },
    {
      "epoch": 9.013567710555508,
      "grad_norm": 0.2953464984893799,
      "learning_rate": 4.932161447222459e-06,
      "loss": 0.0021,
      "step": 105630
    },
    {
      "epoch": 9.014421025684785,
      "grad_norm": 0.39323627948760986,
      "learning_rate": 4.9278948715760735e-06,
      "loss": 0.0017,
      "step": 105640
    },
    {
      "epoch": 9.015274340814063,
      "grad_norm": 0.10090804845094681,
      "learning_rate": 4.923628295929687e-06,
      "loss": 0.0015,
      "step": 105650
    },
    {
      "epoch": 9.01612765594334,
      "grad_norm": 0.1466279923915863,
      "learning_rate": 4.919361720283301e-06,
      "loss": 0.0019,
      "step": 105660
    },
    {
      "epoch": 9.016980971072616,
      "grad_norm": 0.1460455358028412,
      "learning_rate": 4.9150951446369145e-06,
      "loss": 0.0016,
      "step": 105670
    },
    {
      "epoch": 9.017834286201895,
      "grad_norm": 0.04585527256131172,
      "learning_rate": 4.910828568990528e-06,
      "loss": 0.0016,
      "step": 105680
    },
    {
      "epoch": 9.018687601331171,
      "grad_norm": 0.04911273345351219,
      "learning_rate": 4.906561993344142e-06,
      "loss": 0.0017,
      "step": 105690
    },
    {
      "epoch": 9.019540916460448,
      "grad_norm": 0.16981814801692963,
      "learning_rate": 4.902295417697756e-06,
      "loss": 0.0015,
      "step": 105700
    },
    {
      "epoch": 9.020394231589727,
      "grad_norm": 0.09450596570968628,
      "learning_rate": 4.89802884205137e-06,
      "loss": 0.0015,
      "step": 105710
    },
    {
      "epoch": 9.021247546719003,
      "grad_norm": 0.05546024069190025,
      "learning_rate": 4.893762266404984e-06,
      "loss": 0.0016,
      "step": 105720
    },
    {
      "epoch": 9.02210086184828,
      "grad_norm": 0.07779452949762344,
      "learning_rate": 4.889495690758597e-06,
      "loss": 0.0015,
      "step": 105730
    },
    {
      "epoch": 9.022954176977558,
      "grad_norm": 0.2360561341047287,
      "learning_rate": 4.885229115112211e-06,
      "loss": 0.0016,
      "step": 105740
    },
    {
      "epoch": 9.023807492106835,
      "grad_norm": 0.059265345335006714,
      "learning_rate": 4.880962539465825e-06,
      "loss": 0.0015,
      "step": 105750
    },
    {
      "epoch": 9.024660807236112,
      "grad_norm": 0.15731114149093628,
      "learning_rate": 4.876695963819438e-06,
      "loss": 0.0014,
      "step": 105760
    },
    {
      "epoch": 9.02551412236539,
      "grad_norm": 0.07178464531898499,
      "learning_rate": 4.872429388173053e-06,
      "loss": 0.0016,
      "step": 105770
    },
    {
      "epoch": 9.026367437494667,
      "grad_norm": 0.1233547255396843,
      "learning_rate": 4.868162812526667e-06,
      "loss": 0.0017,
      "step": 105780
    },
    {
      "epoch": 9.027220752623943,
      "grad_norm": 0.12057362496852875,
      "learning_rate": 4.86389623688028e-06,
      "loss": 0.0014,
      "step": 105790
    },
    {
      "epoch": 9.028074067753222,
      "grad_norm": 0.11267784982919693,
      "learning_rate": 4.859629661233894e-06,
      "loss": 0.0017,
      "step": 105800
    },
    {
      "epoch": 9.028927382882499,
      "grad_norm": 0.17660917341709137,
      "learning_rate": 4.855363085587507e-06,
      "loss": 0.0019,
      "step": 105810
    },
    {
      "epoch": 9.029780698011775,
      "grad_norm": 0.049328919500112534,
      "learning_rate": 4.851096509941121e-06,
      "loss": 0.0014,
      "step": 105820
    },
    {
      "epoch": 9.030634013141054,
      "grad_norm": 0.21976198256015778,
      "learning_rate": 4.8468299342947356e-06,
      "loss": 0.0014,
      "step": 105830
    },
    {
      "epoch": 9.03148732827033,
      "grad_norm": 0.275199830532074,
      "learning_rate": 4.842563358648349e-06,
      "loss": 0.0012,
      "step": 105840
    },
    {
      "epoch": 9.032340643399607,
      "grad_norm": 0.11280623078346252,
      "learning_rate": 4.838296783001963e-06,
      "loss": 0.0014,
      "step": 105850
    },
    {
      "epoch": 9.033193958528885,
      "grad_norm": 0.13464662432670593,
      "learning_rate": 4.834030207355577e-06,
      "loss": 0.0017,
      "step": 105860
    },
    {
      "epoch": 9.034047273658162,
      "grad_norm": 0.026111846789717674,
      "learning_rate": 4.82976363170919e-06,
      "loss": 0.0014,
      "step": 105870
    },
    {
      "epoch": 9.034900588787439,
      "grad_norm": 0.12837490439414978,
      "learning_rate": 4.825497056062804e-06,
      "loss": 0.0015,
      "step": 105880
    },
    {
      "epoch": 9.035753903916717,
      "grad_norm": 0.04140588268637657,
      "learning_rate": 4.821230480416418e-06,
      "loss": 0.0018,
      "step": 105890
    },
    {
      "epoch": 9.036607219045994,
      "grad_norm": 0.39448636770248413,
      "learning_rate": 4.816963904770032e-06,
      "loss": 0.0014,
      "step": 105900
    },
    {
      "epoch": 9.03746053417527,
      "grad_norm": 0.14861930906772614,
      "learning_rate": 4.812697329123646e-06,
      "loss": 0.0018,
      "step": 105910
    },
    {
      "epoch": 9.038313849304549,
      "grad_norm": 0.24105295538902283,
      "learning_rate": 4.8084307534772595e-06,
      "loss": 0.002,
      "step": 105920
    },
    {
      "epoch": 9.039167164433826,
      "grad_norm": 0.16409066319465637,
      "learning_rate": 4.804164177830873e-06,
      "loss": 0.0017,
      "step": 105930
    },
    {
      "epoch": 9.040020479563102,
      "grad_norm": 0.21642419695854187,
      "learning_rate": 4.799897602184487e-06,
      "loss": 0.002,
      "step": 105940
    },
    {
      "epoch": 9.04087379469238,
      "grad_norm": 0.07661618292331696,
      "learning_rate": 4.7956310265381005e-06,
      "loss": 0.0015,
      "step": 105950
    },
    {
      "epoch": 9.041727109821657,
      "grad_norm": 0.06362685561180115,
      "learning_rate": 4.791364450891715e-06,
      "loss": 0.0017,
      "step": 105960
    },
    {
      "epoch": 9.042580424950934,
      "grad_norm": 0.06124518811702728,
      "learning_rate": 4.787097875245328e-06,
      "loss": 0.0014,
      "step": 105970
    },
    {
      "epoch": 9.043433740080213,
      "grad_norm": 0.21999135613441467,
      "learning_rate": 4.782831299598942e-06,
      "loss": 0.0016,
      "step": 105980
    },
    {
      "epoch": 9.04428705520949,
      "grad_norm": 0.12507781386375427,
      "learning_rate": 4.778564723952556e-06,
      "loss": 0.0015,
      "step": 105990
    },
    {
      "epoch": 9.045140370338766,
      "grad_norm": 0.13361458480358124,
      "learning_rate": 4.774298148306169e-06,
      "loss": 0.0015,
      "step": 106000
    },
    {
      "epoch": 9.045993685468043,
      "grad_norm": 0.0929403081536293,
      "learning_rate": 4.7700315726597834e-06,
      "loss": 0.0014,
      "step": 106010
    },
    {
      "epoch": 9.046847000597321,
      "grad_norm": 0.11820133030414581,
      "learning_rate": 4.765764997013397e-06,
      "loss": 0.0016,
      "step": 106020
    },
    {
      "epoch": 9.047700315726598,
      "grad_norm": 0.035482604056596756,
      "learning_rate": 4.761498421367011e-06,
      "loss": 0.0018,
      "step": 106030
    },
    {
      "epoch": 9.048553630855874,
      "grad_norm": 0.16910569369792938,
      "learning_rate": 4.757231845720625e-06,
      "loss": 0.0014,
      "step": 106040
    },
    {
      "epoch": 9.049406945985153,
      "grad_norm": 0.051201287657022476,
      "learning_rate": 4.752965270074239e-06,
      "loss": 0.0016,
      "step": 106050
    },
    {
      "epoch": 9.05026026111443,
      "grad_norm": 0.05774134770035744,
      "learning_rate": 4.748698694427853e-06,
      "loss": 0.0018,
      "step": 106060
    },
    {
      "epoch": 9.051113576243706,
      "grad_norm": 0.08027781546115875,
      "learning_rate": 4.744432118781466e-06,
      "loss": 0.0014,
      "step": 106070
    },
    {
      "epoch": 9.051966891372984,
      "grad_norm": 0.09344135224819183,
      "learning_rate": 4.74016554313508e-06,
      "loss": 0.0015,
      "step": 106080
    },
    {
      "epoch": 9.052820206502261,
      "grad_norm": 0.039961472153663635,
      "learning_rate": 4.735898967488694e-06,
      "loss": 0.002,
      "step": 106090
    },
    {
      "epoch": 9.053673521631538,
      "grad_norm": 0.16655217111110687,
      "learning_rate": 4.731632391842307e-06,
      "loss": 0.0014,
      "step": 106100
    },
    {
      "epoch": 9.054526836760816,
      "grad_norm": 0.07519042491912842,
      "learning_rate": 4.727365816195922e-06,
      "loss": 0.0015,
      "step": 106110
    },
    {
      "epoch": 9.055380151890093,
      "grad_norm": 0.0954253301024437,
      "learning_rate": 4.723099240549536e-06,
      "loss": 0.0014,
      "step": 106120
    },
    {
      "epoch": 9.05623346701937,
      "grad_norm": 0.1490045040845871,
      "learning_rate": 4.718832664903148e-06,
      "loss": 0.0012,
      "step": 106130
    },
    {
      "epoch": 9.057086782148648,
      "grad_norm": 0.05993670970201492,
      "learning_rate": 4.714566089256763e-06,
      "loss": 0.0015,
      "step": 106140
    },
    {
      "epoch": 9.057940097277925,
      "grad_norm": 0.11167346686124802,
      "learning_rate": 4.710299513610376e-06,
      "loss": 0.0015,
      "step": 106150
    },
    {
      "epoch": 9.058793412407201,
      "grad_norm": 0.07622305303812027,
      "learning_rate": 4.70603293796399e-06,
      "loss": 0.0016,
      "step": 106160
    },
    {
      "epoch": 9.05964672753648,
      "grad_norm": 0.035571273416280746,
      "learning_rate": 4.7017663623176045e-06,
      "loss": 0.0015,
      "step": 106170
    },
    {
      "epoch": 9.060500042665756,
      "grad_norm": 0.08500563353300095,
      "learning_rate": 4.697499786671218e-06,
      "loss": 0.0015,
      "step": 106180
    },
    {
      "epoch": 9.061353357795033,
      "grad_norm": 0.11687978357076645,
      "learning_rate": 4.693233211024832e-06,
      "loss": 0.0017,
      "step": 106190
    },
    {
      "epoch": 9.062206672924312,
      "grad_norm": 0.11113540828227997,
      "learning_rate": 4.6889666353784455e-06,
      "loss": 0.0015,
      "step": 106200
    },
    {
      "epoch": 9.063059988053588,
      "grad_norm": 0.19887308776378632,
      "learning_rate": 4.684700059732059e-06,
      "loss": 0.0017,
      "step": 106210
    },
    {
      "epoch": 9.063913303182865,
      "grad_norm": 0.09426887333393097,
      "learning_rate": 4.680433484085673e-06,
      "loss": 0.0012,
      "step": 106220
    },
    {
      "epoch": 9.064766618312143,
      "grad_norm": 0.10468653589487076,
      "learning_rate": 4.6761669084392866e-06,
      "loss": 0.0014,
      "step": 106230
    },
    {
      "epoch": 9.06561993344142,
      "grad_norm": 0.08719330281019211,
      "learning_rate": 4.671900332792901e-06,
      "loss": 0.0022,
      "step": 106240
    },
    {
      "epoch": 9.066473248570697,
      "grad_norm": 0.12958590686321259,
      "learning_rate": 4.667633757146515e-06,
      "loss": 0.0016,
      "step": 106250
    },
    {
      "epoch": 9.067326563699975,
      "grad_norm": 0.22060149908065796,
      "learning_rate": 4.6633671815001284e-06,
      "loss": 0.0016,
      "step": 106260
    },
    {
      "epoch": 9.068179878829252,
      "grad_norm": 0.3089904487133026,
      "learning_rate": 4.659100605853742e-06,
      "loss": 0.0014,
      "step": 106270
    },
    {
      "epoch": 9.069033193958528,
      "grad_norm": 0.05675597861409187,
      "learning_rate": 4.654834030207355e-06,
      "loss": 0.0017,
      "step": 106280
    },
    {
      "epoch": 9.069886509087807,
      "grad_norm": 0.05647734925150871,
      "learning_rate": 4.6505674545609695e-06,
      "loss": 0.0018,
      "step": 106290
    },
    {
      "epoch": 9.070739824217084,
      "grad_norm": 0.200851172208786,
      "learning_rate": 4.646300878914584e-06,
      "loss": 0.0013,
      "step": 106300
    },
    {
      "epoch": 9.07159313934636,
      "grad_norm": 0.156837597489357,
      "learning_rate": 4.642034303268197e-06,
      "loss": 0.002,
      "step": 106310
    },
    {
      "epoch": 9.072446454475639,
      "grad_norm": 0.12830626964569092,
      "learning_rate": 4.637767727621811e-06,
      "loss": 0.0019,
      "step": 106320
    },
    {
      "epoch": 9.073299769604915,
      "grad_norm": 0.1317761391401291,
      "learning_rate": 4.633501151975425e-06,
      "loss": 0.0014,
      "step": 106330
    },
    {
      "epoch": 9.074153084734192,
      "grad_norm": 0.23785047233104706,
      "learning_rate": 4.629234576329038e-06,
      "loss": 0.0014,
      "step": 106340
    },
    {
      "epoch": 9.075006399863469,
      "grad_norm": 0.1312246173620224,
      "learning_rate": 4.624968000682652e-06,
      "loss": 0.0016,
      "step": 106350
    },
    {
      "epoch": 9.075859714992747,
      "grad_norm": 0.05729670077562332,
      "learning_rate": 4.620701425036266e-06,
      "loss": 0.0019,
      "step": 106360
    },
    {
      "epoch": 9.076713030122024,
      "grad_norm": 0.056347280740737915,
      "learning_rate": 4.61643484938988e-06,
      "loss": 0.0017,
      "step": 106370
    },
    {
      "epoch": 9.0775663452513,
      "grad_norm": 0.257887065410614,
      "learning_rate": 4.612168273743494e-06,
      "loss": 0.0015,
      "step": 106380
    },
    {
      "epoch": 9.078419660380579,
      "grad_norm": 0.3138013184070587,
      "learning_rate": 4.607901698097108e-06,
      "loss": 0.0016,
      "step": 106390
    },
    {
      "epoch": 9.079272975509856,
      "grad_norm": 0.16410236060619354,
      "learning_rate": 4.603635122450721e-06,
      "loss": 0.002,
      "step": 106400
    },
    {
      "epoch": 9.080126290639132,
      "grad_norm": 0.06045740842819214,
      "learning_rate": 4.599368546804335e-06,
      "loss": 0.0012,
      "step": 106410
    },
    {
      "epoch": 9.08097960576841,
      "grad_norm": 0.34113532304763794,
      "learning_rate": 4.595101971157949e-06,
      "loss": 0.0019,
      "step": 106420
    },
    {
      "epoch": 9.081832920897687,
      "grad_norm": 0.1002345085144043,
      "learning_rate": 4.590835395511563e-06,
      "loss": 0.0017,
      "step": 106430
    },
    {
      "epoch": 9.082686236026964,
      "grad_norm": 0.24412943422794342,
      "learning_rate": 4.586568819865176e-06,
      "loss": 0.0018,
      "step": 106440
    },
    {
      "epoch": 9.083539551156242,
      "grad_norm": 0.2686636745929718,
      "learning_rate": 4.5823022442187906e-06,
      "loss": 0.0019,
      "step": 106450
    },
    {
      "epoch": 9.08439286628552,
      "grad_norm": 0.15468941628932953,
      "learning_rate": 4.578035668572404e-06,
      "loss": 0.002,
      "step": 106460
    },
    {
      "epoch": 9.085246181414796,
      "grad_norm": 0.04735826328396797,
      "learning_rate": 4.573769092926017e-06,
      "loss": 0.0017,
      "step": 106470
    },
    {
      "epoch": 9.086099496544074,
      "grad_norm": 0.342404842376709,
      "learning_rate": 4.569502517279632e-06,
      "loss": 0.0019,
      "step": 106480
    },
    {
      "epoch": 9.086952811673351,
      "grad_norm": 0.04310883209109306,
      "learning_rate": 4.565235941633245e-06,
      "loss": 0.0018,
      "step": 106490
    },
    {
      "epoch": 9.087806126802628,
      "grad_norm": 0.18714091181755066,
      "learning_rate": 4.560969365986859e-06,
      "loss": 0.0014,
      "step": 106500
    },
    {
      "epoch": 9.088659441931906,
      "grad_norm": 0.04413668438792229,
      "learning_rate": 4.5567027903404735e-06,
      "loss": 0.0013,
      "step": 106510
    },
    {
      "epoch": 9.089512757061183,
      "grad_norm": 0.20035035908222198,
      "learning_rate": 4.552436214694087e-06,
      "loss": 0.0015,
      "step": 106520
    },
    {
      "epoch": 9.09036607219046,
      "grad_norm": 0.22522246837615967,
      "learning_rate": 4.5481696390477e-06,
      "loss": 0.0014,
      "step": 106530
    },
    {
      "epoch": 9.091219387319738,
      "grad_norm": 0.11267019063234329,
      "learning_rate": 4.5439030634013145e-06,
      "loss": 0.0016,
      "step": 106540
    },
    {
      "epoch": 9.092072702449014,
      "grad_norm": 0.09755504131317139,
      "learning_rate": 4.539636487754928e-06,
      "loss": 0.002,
      "step": 106550
    },
    {
      "epoch": 9.092926017578291,
      "grad_norm": 0.14381061494350433,
      "learning_rate": 4.535369912108542e-06,
      "loss": 0.002,
      "step": 106560
    },
    {
      "epoch": 9.09377933270757,
      "grad_norm": 0.07647280395030975,
      "learning_rate": 4.5311033364621555e-06,
      "loss": 0.0017,
      "step": 106570
    },
    {
      "epoch": 9.094632647836846,
      "grad_norm": 0.19950540363788605,
      "learning_rate": 4.52683676081577e-06,
      "loss": 0.0023,
      "step": 106580
    },
    {
      "epoch": 9.095485962966123,
      "grad_norm": 0.047100432217121124,
      "learning_rate": 4.522570185169384e-06,
      "loss": 0.0014,
      "step": 106590
    },
    {
      "epoch": 9.096339278095401,
      "grad_norm": 0.23614265024662018,
      "learning_rate": 4.5183036095229965e-06,
      "loss": 0.0018,
      "step": 106600
    },
    {
      "epoch": 9.097192593224678,
      "grad_norm": 0.11185946315526962,
      "learning_rate": 4.514037033876611e-06,
      "loss": 0.0017,
      "step": 106610
    },
    {
      "epoch": 9.098045908353955,
      "grad_norm": 0.09679661691188812,
      "learning_rate": 4.509770458230224e-06,
      "loss": 0.0013,
      "step": 106620
    },
    {
      "epoch": 9.098899223483233,
      "grad_norm": 0.03076103702187538,
      "learning_rate": 4.505503882583838e-06,
      "loss": 0.0015,
      "step": 106630
    },
    {
      "epoch": 9.09975253861251,
      "grad_norm": 0.05220913141965866,
      "learning_rate": 4.501237306937453e-06,
      "loss": 0.0017,
      "step": 106640
    },
    {
      "epoch": 9.100605853741786,
      "grad_norm": 0.09699149429798126,
      "learning_rate": 4.496970731291066e-06,
      "loss": 0.0021,
      "step": 106650
    },
    {
      "epoch": 9.101459168871065,
      "grad_norm": 0.3226732313632965,
      "learning_rate": 4.49270415564468e-06,
      "loss": 0.0014,
      "step": 106660
    },
    {
      "epoch": 9.102312484000342,
      "grad_norm": 0.15025192499160767,
      "learning_rate": 4.488437579998294e-06,
      "loss": 0.0013,
      "step": 106670
    },
    {
      "epoch": 9.103165799129618,
      "grad_norm": 0.0337713398039341,
      "learning_rate": 4.484171004351907e-06,
      "loss": 0.0018,
      "step": 106680
    },
    {
      "epoch": 9.104019114258897,
      "grad_norm": 0.03106510639190674,
      "learning_rate": 4.479904428705521e-06,
      "loss": 0.0018,
      "step": 106690
    },
    {
      "epoch": 9.104872429388173,
      "grad_norm": 0.28752967715263367,
      "learning_rate": 4.475637853059135e-06,
      "loss": 0.002,
      "step": 106700
    },
    {
      "epoch": 9.10572574451745,
      "grad_norm": 0.17670311033725739,
      "learning_rate": 4.471371277412749e-06,
      "loss": 0.0017,
      "step": 106710
    },
    {
      "epoch": 9.106579059646727,
      "grad_norm": 0.11079980432987213,
      "learning_rate": 4.467104701766363e-06,
      "loss": 0.0019,
      "step": 106720
    },
    {
      "epoch": 9.107432374776005,
      "grad_norm": 0.17958544194698334,
      "learning_rate": 4.462838126119976e-06,
      "loss": 0.0017,
      "step": 106730
    },
    {
      "epoch": 9.108285689905282,
      "grad_norm": 0.13329607248306274,
      "learning_rate": 4.45857155047359e-06,
      "loss": 0.0014,
      "step": 106740
    },
    {
      "epoch": 9.109139005034558,
      "grad_norm": 0.3450110852718353,
      "learning_rate": 4.454304974827203e-06,
      "loss": 0.0013,
      "step": 106750
    },
    {
      "epoch": 9.109992320163837,
      "grad_norm": 0.22555267810821533,
      "learning_rate": 4.450038399180818e-06,
      "loss": 0.0017,
      "step": 106760
    },
    {
      "epoch": 9.110845635293114,
      "grad_norm": 0.03193829581141472,
      "learning_rate": 4.445771823534432e-06,
      "loss": 0.0014,
      "step": 106770
    },
    {
      "epoch": 9.11169895042239,
      "grad_norm": 0.16375231742858887,
      "learning_rate": 4.441505247888045e-06,
      "loss": 0.0019,
      "step": 106780
    },
    {
      "epoch": 9.112552265551669,
      "grad_norm": 0.03525581583380699,
      "learning_rate": 4.4372386722416595e-06,
      "loss": 0.0018,
      "step": 106790
    },
    {
      "epoch": 9.113405580680945,
      "grad_norm": 0.04838259518146515,
      "learning_rate": 4.432972096595273e-06,
      "loss": 0.0016,
      "step": 106800
    },
    {
      "epoch": 9.114258895810222,
      "grad_norm": 0.1471187323331833,
      "learning_rate": 4.428705520948886e-06,
      "loss": 0.002,
      "step": 106810
    },
    {
      "epoch": 9.1151122109395,
      "grad_norm": 0.037043433636426926,
      "learning_rate": 4.4244389453025005e-06,
      "loss": 0.0016,
      "step": 106820
    },
    {
      "epoch": 9.115965526068777,
      "grad_norm": 0.23573651909828186,
      "learning_rate": 4.420172369656114e-06,
      "loss": 0.0015,
      "step": 106830
    },
    {
      "epoch": 9.116818841198054,
      "grad_norm": 0.0960376039147377,
      "learning_rate": 4.415905794009728e-06,
      "loss": 0.0019,
      "step": 106840
    },
    {
      "epoch": 9.117672156327332,
      "grad_norm": 0.09875945746898651,
      "learning_rate": 4.411639218363342e-06,
      "loss": 0.0018,
      "step": 106850
    },
    {
      "epoch": 9.118525471456609,
      "grad_norm": 0.1453702449798584,
      "learning_rate": 4.407372642716955e-06,
      "loss": 0.0021,
      "step": 106860
    },
    {
      "epoch": 9.119378786585886,
      "grad_norm": 0.11808928847312927,
      "learning_rate": 4.403106067070569e-06,
      "loss": 0.0019,
      "step": 106870
    },
    {
      "epoch": 9.120232101715164,
      "grad_norm": 0.14934390783309937,
      "learning_rate": 4.3988394914241834e-06,
      "loss": 0.002,
      "step": 106880
    },
    {
      "epoch": 9.12108541684444,
      "grad_norm": 0.09327089786529541,
      "learning_rate": 4.394572915777797e-06,
      "loss": 0.0018,
      "step": 106890
    },
    {
      "epoch": 9.121938731973717,
      "grad_norm": 0.3340359330177307,
      "learning_rate": 4.390306340131411e-06,
      "loss": 0.0016,
      "step": 106900
    },
    {
      "epoch": 9.122792047102996,
      "grad_norm": 0.09631217271089554,
      "learning_rate": 4.3860397644850245e-06,
      "loss": 0.0017,
      "step": 106910
    },
    {
      "epoch": 9.123645362232272,
      "grad_norm": 0.062100086361169815,
      "learning_rate": 4.381773188838639e-06,
      "loss": 0.0017,
      "step": 106920
    },
    {
      "epoch": 9.124498677361549,
      "grad_norm": 0.18068864941596985,
      "learning_rate": 4.377506613192252e-06,
      "loss": 0.0015,
      "step": 106930
    },
    {
      "epoch": 9.125351992490828,
      "grad_norm": 0.2301318347454071,
      "learning_rate": 4.3732400375458655e-06,
      "loss": 0.0016,
      "step": 106940
    },
    {
      "epoch": 9.126205307620104,
      "grad_norm": 0.1990894228219986,
      "learning_rate": 4.36897346189948e-06,
      "loss": 0.002,
      "step": 106950
    },
    {
      "epoch": 9.12705862274938,
      "grad_norm": 0.11535653471946716,
      "learning_rate": 4.364706886253093e-06,
      "loss": 0.0016,
      "step": 106960
    },
    {
      "epoch": 9.12791193787866,
      "grad_norm": 0.5295040607452393,
      "learning_rate": 4.360440310606707e-06,
      "loss": 0.002,
      "step": 106970
    },
    {
      "epoch": 9.128765253007936,
      "grad_norm": 0.3628939092159271,
      "learning_rate": 4.356173734960322e-06,
      "loss": 0.0016,
      "step": 106980
    },
    {
      "epoch": 9.129618568137213,
      "grad_norm": 0.06229359284043312,
      "learning_rate": 4.351907159313935e-06,
      "loss": 0.0015,
      "step": 106990
    },
    {
      "epoch": 9.130471883266491,
      "grad_norm": 0.20032715797424316,
      "learning_rate": 4.347640583667548e-06,
      "loss": 0.0021,
      "step": 107000
    },
    {
      "epoch": 9.131325198395768,
      "grad_norm": 0.1424606591463089,
      "learning_rate": 4.343374008021163e-06,
      "loss": 0.0017,
      "step": 107010
    },
    {
      "epoch": 9.132178513525044,
      "grad_norm": 0.03260311856865883,
      "learning_rate": 4.339107432374776e-06,
      "loss": 0.0016,
      "step": 107020
    },
    {
      "epoch": 9.133031828654323,
      "grad_norm": 0.1495068520307541,
      "learning_rate": 4.33484085672839e-06,
      "loss": 0.0016,
      "step": 107030
    },
    {
      "epoch": 9.1338851437836,
      "grad_norm": 0.15158595144748688,
      "learning_rate": 4.330574281082004e-06,
      "loss": 0.0016,
      "step": 107040
    },
    {
      "epoch": 9.134738458912876,
      "grad_norm": 0.08822766691446304,
      "learning_rate": 4.326307705435618e-06,
      "loss": 0.0017,
      "step": 107050
    },
    {
      "epoch": 9.135591774042155,
      "grad_norm": 0.1506250500679016,
      "learning_rate": 4.322041129789231e-06,
      "loss": 0.0015,
      "step": 107060
    },
    {
      "epoch": 9.136445089171431,
      "grad_norm": 0.18186500668525696,
      "learning_rate": 4.317774554142845e-06,
      "loss": 0.0013,
      "step": 107070
    },
    {
      "epoch": 9.137298404300708,
      "grad_norm": 0.1980365514755249,
      "learning_rate": 4.313507978496459e-06,
      "loss": 0.0016,
      "step": 107080
    },
    {
      "epoch": 9.138151719429985,
      "grad_norm": 0.043442972004413605,
      "learning_rate": 4.309241402850072e-06,
      "loss": 0.0017,
      "step": 107090
    },
    {
      "epoch": 9.139005034559263,
      "grad_norm": 0.14545397460460663,
      "learning_rate": 4.3049748272036866e-06,
      "loss": 0.0014,
      "step": 107100
    },
    {
      "epoch": 9.13985834968854,
      "grad_norm": 0.09563466906547546,
      "learning_rate": 4.300708251557301e-06,
      "loss": 0.0015,
      "step": 107110
    },
    {
      "epoch": 9.140711664817816,
      "grad_norm": 0.11788605153560638,
      "learning_rate": 4.296441675910914e-06,
      "loss": 0.0014,
      "step": 107120
    },
    {
      "epoch": 9.141564979947095,
      "grad_norm": 0.16208110749721527,
      "learning_rate": 4.292175100264528e-06,
      "loss": 0.002,
      "step": 107130
    },
    {
      "epoch": 9.142418295076371,
      "grad_norm": 0.11982309073209763,
      "learning_rate": 4.287908524618142e-06,
      "loss": 0.0016,
      "step": 107140
    },
    {
      "epoch": 9.143271610205648,
      "grad_norm": 0.11491423845291138,
      "learning_rate": 4.283641948971755e-06,
      "loss": 0.0018,
      "step": 107150
    },
    {
      "epoch": 9.144124925334927,
      "grad_norm": 0.18367981910705566,
      "learning_rate": 4.2793753733253695e-06,
      "loss": 0.0014,
      "step": 107160
    },
    {
      "epoch": 9.144978240464203,
      "grad_norm": 0.21593375504016876,
      "learning_rate": 4.275108797678983e-06,
      "loss": 0.002,
      "step": 107170
    },
    {
      "epoch": 9.14583155559348,
      "grad_norm": 0.2376689314842224,
      "learning_rate": 4.270842222032597e-06,
      "loss": 0.0019,
      "step": 107180
    },
    {
      "epoch": 9.146684870722758,
      "grad_norm": 0.15454807877540588,
      "learning_rate": 4.266575646386211e-06,
      "loss": 0.0017,
      "step": 107190
    },
    {
      "epoch": 9.147538185852035,
      "grad_norm": 0.06338720768690109,
      "learning_rate": 4.262309070739824e-06,
      "loss": 0.0013,
      "step": 107200
    },
    {
      "epoch": 9.148391500981312,
      "grad_norm": 0.040840163826942444,
      "learning_rate": 4.258042495093438e-06,
      "loss": 0.0016,
      "step": 107210
    },
    {
      "epoch": 9.14924481611059,
      "grad_norm": 0.09531629830598831,
      "learning_rate": 4.2537759194470515e-06,
      "loss": 0.0018,
      "step": 107220
    },
    {
      "epoch": 9.150098131239867,
      "grad_norm": 0.14817042648792267,
      "learning_rate": 4.249509343800666e-06,
      "loss": 0.0013,
      "step": 107230
    },
    {
      "epoch": 9.150951446369143,
      "grad_norm": 0.16328762471675873,
      "learning_rate": 4.24524276815428e-06,
      "loss": 0.0017,
      "step": 107240
    },
    {
      "epoch": 9.151804761498422,
      "grad_norm": 0.15252164006233215,
      "learning_rate": 4.240976192507893e-06,
      "loss": 0.0017,
      "step": 107250
    },
    {
      "epoch": 9.152658076627699,
      "grad_norm": 0.05749567970633507,
      "learning_rate": 4.236709616861507e-06,
      "loss": 0.0016,
      "step": 107260
    },
    {
      "epoch": 9.153511391756975,
      "grad_norm": 0.11203116178512573,
      "learning_rate": 4.232443041215121e-06,
      "loss": 0.0018,
      "step": 107270
    },
    {
      "epoch": 9.154364706886254,
      "grad_norm": 0.32386070489883423,
      "learning_rate": 4.2281764655687344e-06,
      "loss": 0.0015,
      "step": 107280
    },
    {
      "epoch": 9.15521802201553,
      "grad_norm": 0.2877732515335083,
      "learning_rate": 4.223909889922349e-06,
      "loss": 0.0019,
      "step": 107290
    },
    {
      "epoch": 9.156071337144807,
      "grad_norm": 0.39585214853286743,
      "learning_rate": 4.219643314275962e-06,
      "loss": 0.0017,
      "step": 107300
    },
    {
      "epoch": 9.156924652274085,
      "grad_norm": 0.11225920170545578,
      "learning_rate": 4.215376738629576e-06,
      "loss": 0.0017,
      "step": 107310
    },
    {
      "epoch": 9.157777967403362,
      "grad_norm": 0.08012088388204575,
      "learning_rate": 4.2111101629831906e-06,
      "loss": 0.0016,
      "step": 107320
    },
    {
      "epoch": 9.158631282532639,
      "grad_norm": 0.09318998456001282,
      "learning_rate": 4.206843587336803e-06,
      "loss": 0.0018,
      "step": 107330
    },
    {
      "epoch": 9.159484597661917,
      "grad_norm": 0.11199157685041428,
      "learning_rate": 4.202577011690417e-06,
      "loss": 0.0019,
      "step": 107340
    },
    {
      "epoch": 9.160337912791194,
      "grad_norm": 0.14498862624168396,
      "learning_rate": 4.198310436044032e-06,
      "loss": 0.0016,
      "step": 107350
    },
    {
      "epoch": 9.16119122792047,
      "grad_norm": 0.3249555826187134,
      "learning_rate": 4.194043860397645e-06,
      "loss": 0.0018,
      "step": 107360
    },
    {
      "epoch": 9.162044543049749,
      "grad_norm": 0.17672233283519745,
      "learning_rate": 4.189777284751259e-06,
      "loss": 0.0016,
      "step": 107370
    },
    {
      "epoch": 9.162897858179026,
      "grad_norm": 0.18646936118602753,
      "learning_rate": 4.185510709104873e-06,
      "loss": 0.0016,
      "step": 107380
    },
    {
      "epoch": 9.163751173308302,
      "grad_norm": 0.1286468356847763,
      "learning_rate": 4.181244133458487e-06,
      "loss": 0.0022,
      "step": 107390
    },
    {
      "epoch": 9.16460448843758,
      "grad_norm": 0.13344508409500122,
      "learning_rate": 4.1769775578121e-06,
      "loss": 0.0017,
      "step": 107400
    },
    {
      "epoch": 9.165457803566857,
      "grad_norm": 0.1102326363325119,
      "learning_rate": 4.172710982165714e-06,
      "loss": 0.0018,
      "step": 107410
    },
    {
      "epoch": 9.166311118696134,
      "grad_norm": 0.09574412554502487,
      "learning_rate": 4.168444406519328e-06,
      "loss": 0.0015,
      "step": 107420
    },
    {
      "epoch": 9.167164433825413,
      "grad_norm": 0.4735557436943054,
      "learning_rate": 4.164177830872941e-06,
      "loss": 0.002,
      "step": 107430
    },
    {
      "epoch": 9.16801774895469,
      "grad_norm": 0.07660293579101562,
      "learning_rate": 4.1599112552265555e-06,
      "loss": 0.0015,
      "step": 107440
    },
    {
      "epoch": 9.168871064083966,
      "grad_norm": 0.11337631940841675,
      "learning_rate": 4.15564467958017e-06,
      "loss": 0.0015,
      "step": 107450
    },
    {
      "epoch": 9.169724379213243,
      "grad_norm": 0.03358890488743782,
      "learning_rate": 4.151378103933782e-06,
      "loss": 0.0014,
      "step": 107460
    },
    {
      "epoch": 9.170577694342521,
      "grad_norm": 0.11138100177049637,
      "learning_rate": 4.1471115282873965e-06,
      "loss": 0.0019,
      "step": 107470
    },
    {
      "epoch": 9.171431009471798,
      "grad_norm": 0.21440251171588898,
      "learning_rate": 4.142844952641011e-06,
      "loss": 0.0018,
      "step": 107480
    },
    {
      "epoch": 9.172284324601074,
      "grad_norm": 0.14682722091674805,
      "learning_rate": 4.138578376994624e-06,
      "loss": 0.0015,
      "step": 107490
    },
    {
      "epoch": 9.173137639730353,
      "grad_norm": 0.08494903147220612,
      "learning_rate": 4.134311801348238e-06,
      "loss": 0.0017,
      "step": 107500
    },
    {
      "epoch": 9.17399095485963,
      "grad_norm": 0.3648522198200226,
      "learning_rate": 4.130045225701852e-06,
      "loss": 0.0018,
      "step": 107510
    },
    {
      "epoch": 9.174844269988906,
      "grad_norm": 0.23346269130706787,
      "learning_rate": 4.125778650055466e-06,
      "loss": 0.0015,
      "step": 107520
    },
    {
      "epoch": 9.175697585118185,
      "grad_norm": 0.18232141435146332,
      "learning_rate": 4.1215120744090795e-06,
      "loss": 0.0017,
      "step": 107530
    },
    {
      "epoch": 9.176550900247461,
      "grad_norm": 0.05885303393006325,
      "learning_rate": 4.117245498762693e-06,
      "loss": 0.0013,
      "step": 107540
    },
    {
      "epoch": 9.177404215376738,
      "grad_norm": 0.23560397326946259,
      "learning_rate": 4.112978923116307e-06,
      "loss": 0.0015,
      "step": 107550
    },
    {
      "epoch": 9.178257530506016,
      "grad_norm": 0.09702068567276001,
      "learning_rate": 4.1087123474699205e-06,
      "loss": 0.0015,
      "step": 107560
    },
    {
      "epoch": 9.179110845635293,
      "grad_norm": 0.19961318373680115,
      "learning_rate": 4.104445771823535e-06,
      "loss": 0.0015,
      "step": 107570
    },
    {
      "epoch": 9.17996416076457,
      "grad_norm": 0.1842447817325592,
      "learning_rate": 4.100179196177149e-06,
      "loss": 0.0018,
      "step": 107580
    },
    {
      "epoch": 9.180817475893848,
      "grad_norm": 0.2369975447654724,
      "learning_rate": 4.095912620530762e-06,
      "loss": 0.0012,
      "step": 107590
    },
    {
      "epoch": 9.181670791023125,
      "grad_norm": 0.22290177643299103,
      "learning_rate": 4.091646044884376e-06,
      "loss": 0.0016,
      "step": 107600
    },
    {
      "epoch": 9.182524106152401,
      "grad_norm": 0.1722104251384735,
      "learning_rate": 4.08737946923799e-06,
      "loss": 0.0018,
      "step": 107610
    },
    {
      "epoch": 9.18337742128168,
      "grad_norm": 0.13108037412166595,
      "learning_rate": 4.083112893591603e-06,
      "loss": 0.0017,
      "step": 107620
    },
    {
      "epoch": 9.184230736410957,
      "grad_norm": 0.16469749808311462,
      "learning_rate": 4.078846317945218e-06,
      "loss": 0.0014,
      "step": 107630
    },
    {
      "epoch": 9.185084051540233,
      "grad_norm": 0.37671300768852234,
      "learning_rate": 4.074579742298831e-06,
      "loss": 0.0016,
      "step": 107640
    },
    {
      "epoch": 9.185937366669512,
      "grad_norm": 0.1656956821680069,
      "learning_rate": 4.070313166652445e-06,
      "loss": 0.0015,
      "step": 107650
    },
    {
      "epoch": 9.186790681798788,
      "grad_norm": 0.06632979214191437,
      "learning_rate": 4.066046591006059e-06,
      "loss": 0.0016,
      "step": 107660
    },
    {
      "epoch": 9.187643996928065,
      "grad_norm": 0.20272035896778107,
      "learning_rate": 4.061780015359672e-06,
      "loss": 0.0016,
      "step": 107670
    },
    {
      "epoch": 9.188497312057343,
      "grad_norm": 0.1758287400007248,
      "learning_rate": 4.057513439713286e-06,
      "loss": 0.0018,
      "step": 107680
    },
    {
      "epoch": 9.18935062718662,
      "grad_norm": 0.04877944663167,
      "learning_rate": 4.0532468640669e-06,
      "loss": 0.0011,
      "step": 107690
    },
    {
      "epoch": 9.190203942315897,
      "grad_norm": 0.1812725067138672,
      "learning_rate": 4.048980288420514e-06,
      "loss": 0.0017,
      "step": 107700
    },
    {
      "epoch": 9.191057257445175,
      "grad_norm": 0.12427322566509247,
      "learning_rate": 4.044713712774128e-06,
      "loss": 0.0017,
      "step": 107710
    },
    {
      "epoch": 9.191910572574452,
      "grad_norm": 0.11292800307273865,
      "learning_rate": 4.0404471371277416e-06,
      "loss": 0.0018,
      "step": 107720
    },
    {
      "epoch": 9.192763887703729,
      "grad_norm": 0.14356465637683868,
      "learning_rate": 4.036180561481355e-06,
      "loss": 0.0019,
      "step": 107730
    },
    {
      "epoch": 9.193617202833007,
      "grad_norm": 0.09358015656471252,
      "learning_rate": 4.031913985834969e-06,
      "loss": 0.0018,
      "step": 107740
    },
    {
      "epoch": 9.194470517962284,
      "grad_norm": 0.08854105323553085,
      "learning_rate": 4.027647410188583e-06,
      "loss": 0.0016,
      "step": 107750
    },
    {
      "epoch": 9.19532383309156,
      "grad_norm": 0.08106484264135361,
      "learning_rate": 4.023380834542197e-06,
      "loss": 0.0017,
      "step": 107760
    },
    {
      "epoch": 9.196177148220839,
      "grad_norm": 0.026364831253886223,
      "learning_rate": 4.01911425889581e-06,
      "loss": 0.0015,
      "step": 107770
    },
    {
      "epoch": 9.197030463350115,
      "grad_norm": 0.20146805047988892,
      "learning_rate": 4.0148476832494245e-06,
      "loss": 0.0019,
      "step": 107780
    },
    {
      "epoch": 9.197883778479392,
      "grad_norm": 0.2177804559469223,
      "learning_rate": 4.010581107603038e-06,
      "loss": 0.0019,
      "step": 107790
    },
    {
      "epoch": 9.19873709360867,
      "grad_norm": 0.031072750687599182,
      "learning_rate": 4.006314531956651e-06,
      "loss": 0.002,
      "step": 107800
    },
    {
      "epoch": 9.199590408737947,
      "grad_norm": 0.16343191266059875,
      "learning_rate": 4.0020479563102655e-06,
      "loss": 0.0015,
      "step": 107810
    },
    {
      "epoch": 9.200443723867224,
      "grad_norm": 0.05420643836259842,
      "learning_rate": 3.99778138066388e-06,
      "loss": 0.0015,
      "step": 107820
    },
    {
      "epoch": 9.2012970389965,
      "grad_norm": 0.19468954205513,
      "learning_rate": 3.993514805017493e-06,
      "loss": 0.0019,
      "step": 107830
    },
    {
      "epoch": 9.202150354125779,
      "grad_norm": 0.20185302197933197,
      "learning_rate": 3.989248229371107e-06,
      "loss": 0.0017,
      "step": 107840
    },
    {
      "epoch": 9.203003669255056,
      "grad_norm": 0.11143656075000763,
      "learning_rate": 3.984981653724721e-06,
      "loss": 0.0015,
      "step": 107850
    },
    {
      "epoch": 9.203856984384332,
      "grad_norm": 0.037634726613759995,
      "learning_rate": 3.980715078078334e-06,
      "loss": 0.0012,
      "step": 107860
    },
    {
      "epoch": 9.20471029951361,
      "grad_norm": 0.2554079294204712,
      "learning_rate": 3.976448502431948e-06,
      "loss": 0.0014,
      "step": 107870
    },
    {
      "epoch": 9.205563614642887,
      "grad_norm": 0.109434112906456,
      "learning_rate": 3.972181926785562e-06,
      "loss": 0.0015,
      "step": 107880
    },
    {
      "epoch": 9.206416929772164,
      "grad_norm": 0.11117813736200333,
      "learning_rate": 3.967915351139176e-06,
      "loss": 0.0017,
      "step": 107890
    },
    {
      "epoch": 9.207270244901443,
      "grad_norm": 0.34002795815467834,
      "learning_rate": 3.9636487754927894e-06,
      "loss": 0.0016,
      "step": 107900
    },
    {
      "epoch": 9.20812356003072,
      "grad_norm": 0.037187449634075165,
      "learning_rate": 3.959382199846404e-06,
      "loss": 0.0016,
      "step": 107910
    },
    {
      "epoch": 9.208976875159996,
      "grad_norm": 0.10395320504903793,
      "learning_rate": 3.955115624200018e-06,
      "loss": 0.0018,
      "step": 107920
    },
    {
      "epoch": 9.209830190289274,
      "grad_norm": 0.16310691833496094,
      "learning_rate": 3.9508490485536305e-06,
      "loss": 0.0017,
      "step": 107930
    },
    {
      "epoch": 9.210683505418551,
      "grad_norm": 0.03133945167064667,
      "learning_rate": 3.946582472907245e-06,
      "loss": 0.0016,
      "step": 107940
    },
    {
      "epoch": 9.211536820547828,
      "grad_norm": 0.36325007677078247,
      "learning_rate": 3.942315897260859e-06,
      "loss": 0.0015,
      "step": 107950
    },
    {
      "epoch": 9.212390135677106,
      "grad_norm": 0.1830892264842987,
      "learning_rate": 3.938049321614472e-06,
      "loss": 0.0014,
      "step": 107960
    },
    {
      "epoch": 9.213243450806383,
      "grad_norm": 0.09242068976163864,
      "learning_rate": 3.9337827459680866e-06,
      "loss": 0.0015,
      "step": 107970
    },
    {
      "epoch": 9.21409676593566,
      "grad_norm": 0.05891149118542671,
      "learning_rate": 3.9295161703217e-06,
      "loss": 0.0019,
      "step": 107980
    },
    {
      "epoch": 9.214950081064938,
      "grad_norm": 0.16240732371807098,
      "learning_rate": 3.925249594675313e-06,
      "loss": 0.0015,
      "step": 107990
    },
    {
      "epoch": 9.215803396194215,
      "grad_norm": 0.18443597853183746,
      "learning_rate": 3.920983019028928e-06,
      "loss": 0.0019,
      "step": 108000
    },
    {
      "epoch": 9.216656711323491,
      "grad_norm": 0.37681472301483154,
      "learning_rate": 3.916716443382541e-06,
      "loss": 0.0015,
      "step": 108010
    },
    {
      "epoch": 9.21751002645277,
      "grad_norm": 0.23784783482551575,
      "learning_rate": 3.912449867736155e-06,
      "loss": 0.0017,
      "step": 108020
    },
    {
      "epoch": 9.218363341582046,
      "grad_norm": 0.06932953000068665,
      "learning_rate": 3.908183292089769e-06,
      "loss": 0.0016,
      "step": 108030
    },
    {
      "epoch": 9.219216656711323,
      "grad_norm": 0.19057044386863708,
      "learning_rate": 3.903916716443383e-06,
      "loss": 0.0016,
      "step": 108040
    },
    {
      "epoch": 9.220069971840601,
      "grad_norm": 0.16544727981090546,
      "learning_rate": 3.899650140796997e-06,
      "loss": 0.0017,
      "step": 108050
    },
    {
      "epoch": 9.220923286969878,
      "grad_norm": 0.08025552332401276,
      "learning_rate": 3.89538356515061e-06,
      "loss": 0.0013,
      "step": 108060
    },
    {
      "epoch": 9.221776602099155,
      "grad_norm": 0.050419457256793976,
      "learning_rate": 3.891116989504224e-06,
      "loss": 0.0013,
      "step": 108070
    },
    {
      "epoch": 9.222629917228433,
      "grad_norm": 0.02889322116971016,
      "learning_rate": 3.886850413857838e-06,
      "loss": 0.0019,
      "step": 108080
    },
    {
      "epoch": 9.22348323235771,
      "grad_norm": 0.1640145480632782,
      "learning_rate": 3.8825838382114515e-06,
      "loss": 0.0016,
      "step": 108090
    },
    {
      "epoch": 9.224336547486987,
      "grad_norm": 0.18730664253234863,
      "learning_rate": 3.878317262565066e-06,
      "loss": 0.0017,
      "step": 108100
    },
    {
      "epoch": 9.225189862616265,
      "grad_norm": 0.13010992109775543,
      "learning_rate": 3.874050686918679e-06,
      "loss": 0.0016,
      "step": 108110
    },
    {
      "epoch": 9.226043177745542,
      "grad_norm": 0.03152180090546608,
      "learning_rate": 3.869784111272293e-06,
      "loss": 0.0023,
      "step": 108120
    },
    {
      "epoch": 9.226896492874818,
      "grad_norm": 0.06195298954844475,
      "learning_rate": 3.865517535625907e-06,
      "loss": 0.0019,
      "step": 108130
    },
    {
      "epoch": 9.227749808004097,
      "grad_norm": 0.06467138975858688,
      "learning_rate": 3.86125095997952e-06,
      "loss": 0.0015,
      "step": 108140
    },
    {
      "epoch": 9.228603123133373,
      "grad_norm": 0.2556619346141815,
      "learning_rate": 3.8569843843331344e-06,
      "loss": 0.0012,
      "step": 108150
    },
    {
      "epoch": 9.22945643826265,
      "grad_norm": 0.03986731916666031,
      "learning_rate": 3.852717808686748e-06,
      "loss": 0.0014,
      "step": 108160
    },
    {
      "epoch": 9.230309753391928,
      "grad_norm": 0.13085049390792847,
      "learning_rate": 3.848451233040362e-06,
      "loss": 0.0016,
      "step": 108170
    },
    {
      "epoch": 9.231163068521205,
      "grad_norm": 0.25442370772361755,
      "learning_rate": 3.844184657393976e-06,
      "loss": 0.0019,
      "step": 108180
    },
    {
      "epoch": 9.232016383650482,
      "grad_norm": 0.11094077676534653,
      "learning_rate": 3.839918081747589e-06,
      "loss": 0.0014,
      "step": 108190
    },
    {
      "epoch": 9.232869698779758,
      "grad_norm": 0.03508052974939346,
      "learning_rate": 3.835651506101203e-06,
      "loss": 0.0016,
      "step": 108200
    },
    {
      "epoch": 9.233723013909037,
      "grad_norm": 0.049944084137678146,
      "learning_rate": 3.831384930454817e-06,
      "loss": 0.0019,
      "step": 108210
    },
    {
      "epoch": 9.234576329038314,
      "grad_norm": 0.1472141295671463,
      "learning_rate": 3.827118354808431e-06,
      "loss": 0.0019,
      "step": 108220
    },
    {
      "epoch": 9.23542964416759,
      "grad_norm": 0.0534631572663784,
      "learning_rate": 3.822851779162045e-06,
      "loss": 0.0019,
      "step": 108230
    },
    {
      "epoch": 9.236282959296869,
      "grad_norm": 0.04516549035906792,
      "learning_rate": 3.818585203515658e-06,
      "loss": 0.002,
      "step": 108240
    },
    {
      "epoch": 9.237136274426145,
      "grad_norm": 0.25034642219543457,
      "learning_rate": 3.8143186278692726e-06,
      "loss": 0.0016,
      "step": 108250
    },
    {
      "epoch": 9.237989589555422,
      "grad_norm": 0.09982839971780777,
      "learning_rate": 3.810052052222886e-06,
      "loss": 0.0019,
      "step": 108260
    },
    {
      "epoch": 9.2388429046847,
      "grad_norm": 0.029072416946291924,
      "learning_rate": 3.8057854765765e-06,
      "loss": 0.0014,
      "step": 108270
    },
    {
      "epoch": 9.239696219813977,
      "grad_norm": 0.32591015100479126,
      "learning_rate": 3.8015189009301136e-06,
      "loss": 0.0019,
      "step": 108280
    },
    {
      "epoch": 9.240549534943254,
      "grad_norm": 0.11166742444038391,
      "learning_rate": 3.7972523252837275e-06,
      "loss": 0.0016,
      "step": 108290
    },
    {
      "epoch": 9.241402850072532,
      "grad_norm": 0.12994664907455444,
      "learning_rate": 3.7929857496373413e-06,
      "loss": 0.0015,
      "step": 108300
    },
    {
      "epoch": 9.242256165201809,
      "grad_norm": 0.09702743589878082,
      "learning_rate": 3.788719173990955e-06,
      "loss": 0.002,
      "step": 108310
    },
    {
      "epoch": 9.243109480331086,
      "grad_norm": 0.09153414517641068,
      "learning_rate": 3.7844525983445693e-06,
      "loss": 0.0013,
      "step": 108320
    },
    {
      "epoch": 9.243962795460364,
      "grad_norm": 0.15187159180641174,
      "learning_rate": 3.7801860226981823e-06,
      "loss": 0.0018,
      "step": 108330
    },
    {
      "epoch": 9.24481611058964,
      "grad_norm": 0.13343927264213562,
      "learning_rate": 3.775919447051796e-06,
      "loss": 0.0015,
      "step": 108340
    },
    {
      "epoch": 9.245669425718917,
      "grad_norm": 0.041902292519807816,
      "learning_rate": 3.7716528714054104e-06,
      "loss": 0.0016,
      "step": 108350
    },
    {
      "epoch": 9.246522740848196,
      "grad_norm": 0.07974807173013687,
      "learning_rate": 3.767386295759024e-06,
      "loss": 0.0014,
      "step": 108360
    },
    {
      "epoch": 9.247376055977472,
      "grad_norm": 0.029091844335198402,
      "learning_rate": 3.763119720112638e-06,
      "loss": 0.0015,
      "step": 108370
    },
    {
      "epoch": 9.24822937110675,
      "grad_norm": 0.1828085482120514,
      "learning_rate": 3.758853144466252e-06,
      "loss": 0.0013,
      "step": 108380
    },
    {
      "epoch": 9.249082686236028,
      "grad_norm": 0.12750764191150665,
      "learning_rate": 3.754586568819865e-06,
      "loss": 0.002,
      "step": 108390
    },
    {
      "epoch": 9.249936001365304,
      "grad_norm": 0.15694326162338257,
      "learning_rate": 3.750319993173479e-06,
      "loss": 0.0018,
      "step": 108400
    },
    {
      "epoch": 9.250789316494581,
      "grad_norm": 0.08702461421489716,
      "learning_rate": 3.746053417527093e-06,
      "loss": 0.0014,
      "step": 108410
    },
    {
      "epoch": 9.25164263162386,
      "grad_norm": 0.11052229255437851,
      "learning_rate": 3.7417868418807067e-06,
      "loss": 0.0018,
      "step": 108420
    },
    {
      "epoch": 9.252495946753136,
      "grad_norm": 0.18208427727222443,
      "learning_rate": 3.7375202662343205e-06,
      "loss": 0.0021,
      "step": 108430
    },
    {
      "epoch": 9.253349261882413,
      "grad_norm": 0.2565729320049286,
      "learning_rate": 3.7332536905879343e-06,
      "loss": 0.0018,
      "step": 108440
    },
    {
      "epoch": 9.254202577011691,
      "grad_norm": 0.16387875378131866,
      "learning_rate": 3.7289871149415485e-06,
      "loss": 0.0014,
      "step": 108450
    },
    {
      "epoch": 9.255055892140968,
      "grad_norm": 0.24811144173145294,
      "learning_rate": 3.7247205392951615e-06,
      "loss": 0.0016,
      "step": 108460
    },
    {
      "epoch": 9.255909207270244,
      "grad_norm": 0.14795051515102386,
      "learning_rate": 3.7204539636487753e-06,
      "loss": 0.0019,
      "step": 108470
    },
    {
      "epoch": 9.256762522399523,
      "grad_norm": 0.027459409087896347,
      "learning_rate": 3.7161873880023896e-06,
      "loss": 0.0013,
      "step": 108480
    },
    {
      "epoch": 9.2576158375288,
      "grad_norm": 0.06534797698259354,
      "learning_rate": 3.7119208123560034e-06,
      "loss": 0.0017,
      "step": 108490
    },
    {
      "epoch": 9.258469152658076,
      "grad_norm": 0.09614912420511246,
      "learning_rate": 3.707654236709617e-06,
      "loss": 0.0017,
      "step": 108500
    },
    {
      "epoch": 9.259322467787355,
      "grad_norm": 0.3054601550102234,
      "learning_rate": 3.703387661063231e-06,
      "loss": 0.0019,
      "step": 108510
    },
    {
      "epoch": 9.260175782916631,
      "grad_norm": 0.028498314321041107,
      "learning_rate": 3.699121085416845e-06,
      "loss": 0.0013,
      "step": 108520
    },
    {
      "epoch": 9.261029098045908,
      "grad_norm": 0.11613567918539047,
      "learning_rate": 3.6948545097704582e-06,
      "loss": 0.0018,
      "step": 108530
    },
    {
      "epoch": 9.261882413175186,
      "grad_norm": 0.07053400576114655,
      "learning_rate": 3.690587934124072e-06,
      "loss": 0.0014,
      "step": 108540
    },
    {
      "epoch": 9.262735728304463,
      "grad_norm": 0.1997208595275879,
      "learning_rate": 3.686321358477686e-06,
      "loss": 0.0014,
      "step": 108550
    },
    {
      "epoch": 9.26358904343374,
      "grad_norm": 0.04046227037906647,
      "learning_rate": 3.6820547828312997e-06,
      "loss": 0.0014,
      "step": 108560
    },
    {
      "epoch": 9.264442358563016,
      "grad_norm": 0.11288721859455109,
      "learning_rate": 3.677788207184914e-06,
      "loss": 0.0011,
      "step": 108570
    },
    {
      "epoch": 9.265295673692295,
      "grad_norm": 0.20284907519817352,
      "learning_rate": 3.6735216315385277e-06,
      "loss": 0.0016,
      "step": 108580
    },
    {
      "epoch": 9.266148988821572,
      "grad_norm": 0.049183107912540436,
      "learning_rate": 3.6692550558921407e-06,
      "loss": 0.0014,
      "step": 108590
    },
    {
      "epoch": 9.267002303950848,
      "grad_norm": 0.21592004597187042,
      "learning_rate": 3.6649884802457545e-06,
      "loss": 0.0016,
      "step": 108600
    },
    {
      "epoch": 9.267855619080127,
      "grad_norm": 0.06450509279966354,
      "learning_rate": 3.6607219045993688e-06,
      "loss": 0.0018,
      "step": 108610
    },
    {
      "epoch": 9.268708934209403,
      "grad_norm": 0.20105263590812683,
      "learning_rate": 3.6564553289529826e-06,
      "loss": 0.0021,
      "step": 108620
    },
    {
      "epoch": 9.26956224933868,
      "grad_norm": 0.15239840745925903,
      "learning_rate": 3.6521887533065964e-06,
      "loss": 0.0018,
      "step": 108630
    },
    {
      "epoch": 9.270415564467958,
      "grad_norm": 0.03583778068423271,
      "learning_rate": 3.6479221776602102e-06,
      "loss": 0.0018,
      "step": 108640
    },
    {
      "epoch": 9.271268879597235,
      "grad_norm": 0.08009153604507446,
      "learning_rate": 3.643655602013824e-06,
      "loss": 0.0023,
      "step": 108650
    },
    {
      "epoch": 9.272122194726512,
      "grad_norm": 0.0643465593457222,
      "learning_rate": 3.6393890263674374e-06,
      "loss": 0.0016,
      "step": 108660
    },
    {
      "epoch": 9.27297550985579,
      "grad_norm": 0.15062683820724487,
      "learning_rate": 3.6351224507210513e-06,
      "loss": 0.002,
      "step": 108670
    },
    {
      "epoch": 9.273828824985067,
      "grad_norm": 0.0550476610660553,
      "learning_rate": 3.630855875074665e-06,
      "loss": 0.0018,
      "step": 108680
    },
    {
      "epoch": 9.274682140114344,
      "grad_norm": 0.03377873823046684,
      "learning_rate": 3.626589299428279e-06,
      "loss": 0.0015,
      "step": 108690
    },
    {
      "epoch": 9.275535455243622,
      "grad_norm": 0.09706529974937439,
      "learning_rate": 3.622322723781893e-06,
      "loss": 0.0016,
      "step": 108700
    },
    {
      "epoch": 9.276388770372899,
      "grad_norm": 0.036799583584070206,
      "learning_rate": 3.618056148135507e-06,
      "loss": 0.0014,
      "step": 108710
    },
    {
      "epoch": 9.277242085502175,
      "grad_norm": 0.03223222866654396,
      "learning_rate": 3.61378957248912e-06,
      "loss": 0.0014,
      "step": 108720
    },
    {
      "epoch": 9.278095400631454,
      "grad_norm": 0.2698642611503601,
      "learning_rate": 3.609522996842734e-06,
      "loss": 0.0017,
      "step": 108730
    },
    {
      "epoch": 9.27894871576073,
      "grad_norm": 0.03364598751068115,
      "learning_rate": 3.605256421196348e-06,
      "loss": 0.0015,
      "step": 108740
    },
    {
      "epoch": 9.279802030890007,
      "grad_norm": 0.21590332686901093,
      "learning_rate": 3.600989845549962e-06,
      "loss": 0.0015,
      "step": 108750
    },
    {
      "epoch": 9.280655346019286,
      "grad_norm": 0.11258217692375183,
      "learning_rate": 3.5967232699035756e-06,
      "loss": 0.0016,
      "step": 108760
    },
    {
      "epoch": 9.281508661148562,
      "grad_norm": 0.0926503911614418,
      "learning_rate": 3.5924566942571894e-06,
      "loss": 0.0019,
      "step": 108770
    },
    {
      "epoch": 9.282361976277839,
      "grad_norm": 0.11022040992975235,
      "learning_rate": 3.5881901186108032e-06,
      "loss": 0.0016,
      "step": 108780
    },
    {
      "epoch": 9.283215291407117,
      "grad_norm": 0.0661780834197998,
      "learning_rate": 3.5839235429644166e-06,
      "loss": 0.0017,
      "step": 108790
    },
    {
      "epoch": 9.284068606536394,
      "grad_norm": 0.11499229073524475,
      "learning_rate": 3.5796569673180305e-06,
      "loss": 0.0016,
      "step": 108800
    },
    {
      "epoch": 9.28492192166567,
      "grad_norm": 0.14595220983028412,
      "learning_rate": 3.5753903916716443e-06,
      "loss": 0.0015,
      "step": 108810
    },
    {
      "epoch": 9.285775236794949,
      "grad_norm": 0.04065414145588875,
      "learning_rate": 3.5711238160252585e-06,
      "loss": 0.0018,
      "step": 108820
    },
    {
      "epoch": 9.286628551924226,
      "grad_norm": 0.09405911713838577,
      "learning_rate": 3.5668572403788723e-06,
      "loss": 0.0012,
      "step": 108830
    },
    {
      "epoch": 9.287481867053502,
      "grad_norm": 0.21843279898166656,
      "learning_rate": 3.562590664732486e-06,
      "loss": 0.0014,
      "step": 108840
    },
    {
      "epoch": 9.28833518218278,
      "grad_norm": 0.20022179186344147,
      "learning_rate": 3.5583240890861e-06,
      "loss": 0.0015,
      "step": 108850
    },
    {
      "epoch": 9.289188497312058,
      "grad_norm": 0.29275333881378174,
      "learning_rate": 3.5540575134397134e-06,
      "loss": 0.0017,
      "step": 108860
    },
    {
      "epoch": 9.290041812441334,
      "grad_norm": 0.2897784113883972,
      "learning_rate": 3.549790937793327e-06,
      "loss": 0.0013,
      "step": 108870
    },
    {
      "epoch": 9.290895127570613,
      "grad_norm": 0.1994781494140625,
      "learning_rate": 3.545524362146941e-06,
      "loss": 0.0014,
      "step": 108880
    },
    {
      "epoch": 9.29174844269989,
      "grad_norm": 0.21911047399044037,
      "learning_rate": 3.541257786500555e-06,
      "loss": 0.0017,
      "step": 108890
    },
    {
      "epoch": 9.292601757829166,
      "grad_norm": 0.07843728363513947,
      "learning_rate": 3.5369912108541686e-06,
      "loss": 0.0018,
      "step": 108900
    },
    {
      "epoch": 9.293455072958444,
      "grad_norm": 0.06305623054504395,
      "learning_rate": 3.5327246352077824e-06,
      "loss": 0.0013,
      "step": 108910
    },
    {
      "epoch": 9.294308388087721,
      "grad_norm": 0.06037980690598488,
      "learning_rate": 3.528458059561396e-06,
      "loss": 0.0015,
      "step": 108920
    },
    {
      "epoch": 9.295161703216998,
      "grad_norm": 0.07613126188516617,
      "learning_rate": 3.5241914839150097e-06,
      "loss": 0.0015,
      "step": 108930
    },
    {
      "epoch": 9.296015018346274,
      "grad_norm": 0.19660326838493347,
      "learning_rate": 3.5199249082686235e-06,
      "loss": 0.0015,
      "step": 108940
    },
    {
      "epoch": 9.296868333475553,
      "grad_norm": 0.06738150864839554,
      "learning_rate": 3.5156583326222377e-06,
      "loss": 0.0018,
      "step": 108950
    },
    {
      "epoch": 9.29772164860483,
      "grad_norm": 0.16136643290519714,
      "learning_rate": 3.5113917569758515e-06,
      "loss": 0.0017,
      "step": 108960
    },
    {
      "epoch": 9.298574963734106,
      "grad_norm": 0.04541933164000511,
      "learning_rate": 3.5071251813294654e-06,
      "loss": 0.0015,
      "step": 108970
    },
    {
      "epoch": 9.299428278863385,
      "grad_norm": 0.2624604105949402,
      "learning_rate": 3.502858605683079e-06,
      "loss": 0.0019,
      "step": 108980
    },
    {
      "epoch": 9.300281593992661,
      "grad_norm": 0.08621403574943542,
      "learning_rate": 3.4985920300366926e-06,
      "loss": 0.0015,
      "step": 108990
    },
    {
      "epoch": 9.301134909121938,
      "grad_norm": 0.23962992429733276,
      "learning_rate": 3.4943254543903064e-06,
      "loss": 0.0021,
      "step": 109000
    },
    {
      "epoch": 9.301988224251216,
      "grad_norm": 0.33440691232681274,
      "learning_rate": 3.49005887874392e-06,
      "loss": 0.0018,
      "step": 109010
    },
    {
      "epoch": 9.302841539380493,
      "grad_norm": 0.16549807786941528,
      "learning_rate": 3.485792303097534e-06,
      "loss": 0.0014,
      "step": 109020
    },
    {
      "epoch": 9.30369485450977,
      "grad_norm": 0.18568149209022522,
      "learning_rate": 3.481525727451148e-06,
      "loss": 0.0014,
      "step": 109030
    },
    {
      "epoch": 9.304548169639048,
      "grad_norm": 0.17079663276672363,
      "learning_rate": 3.477259151804762e-06,
      "loss": 0.0015,
      "step": 109040
    },
    {
      "epoch": 9.305401484768325,
      "grad_norm": 0.13070236146450043,
      "learning_rate": 3.472992576158376e-06,
      "loss": 0.0016,
      "step": 109050
    },
    {
      "epoch": 9.306254799897602,
      "grad_norm": 0.11389170587062836,
      "learning_rate": 3.468726000511989e-06,
      "loss": 0.002,
      "step": 109060
    },
    {
      "epoch": 9.30710811502688,
      "grad_norm": 0.14414839446544647,
      "learning_rate": 3.4644594248656027e-06,
      "loss": 0.0017,
      "step": 109070
    },
    {
      "epoch": 9.307961430156157,
      "grad_norm": 0.20039145648479462,
      "learning_rate": 3.460192849219217e-06,
      "loss": 0.0022,
      "step": 109080
    },
    {
      "epoch": 9.308814745285433,
      "grad_norm": 0.1301320344209671,
      "learning_rate": 3.4559262735728307e-06,
      "loss": 0.002,
      "step": 109090
    },
    {
      "epoch": 9.309668060414712,
      "grad_norm": 0.03326297178864479,
      "learning_rate": 3.4516596979264446e-06,
      "loss": 0.0015,
      "step": 109100
    },
    {
      "epoch": 9.310521375543988,
      "grad_norm": 0.037869084626436234,
      "learning_rate": 3.4473931222800584e-06,
      "loss": 0.0014,
      "step": 109110
    },
    {
      "epoch": 9.311374690673265,
      "grad_norm": 0.13203273713588715,
      "learning_rate": 3.4431265466336718e-06,
      "loss": 0.002,
      "step": 109120
    },
    {
      "epoch": 9.312228005802544,
      "grad_norm": 0.024511557072401047,
      "learning_rate": 3.4388599709872856e-06,
      "loss": 0.0014,
      "step": 109130
    },
    {
      "epoch": 9.31308132093182,
      "grad_norm": 0.28984925150871277,
      "learning_rate": 3.4345933953408994e-06,
      "loss": 0.0018,
      "step": 109140
    },
    {
      "epoch": 9.313934636061097,
      "grad_norm": 0.07141966372728348,
      "learning_rate": 3.4303268196945132e-06,
      "loss": 0.0018,
      "step": 109150
    },
    {
      "epoch": 9.314787951190375,
      "grad_norm": 0.1536528617143631,
      "learning_rate": 3.426060244048127e-06,
      "loss": 0.0015,
      "step": 109160
    },
    {
      "epoch": 9.315641266319652,
      "grad_norm": 0.233133003115654,
      "learning_rate": 3.4217936684017413e-06,
      "loss": 0.0016,
      "step": 109170
    },
    {
      "epoch": 9.316494581448929,
      "grad_norm": 0.15976683795452118,
      "learning_rate": 3.417527092755355e-06,
      "loss": 0.0016,
      "step": 109180
    },
    {
      "epoch": 9.317347896578207,
      "grad_norm": 0.061451759189367294,
      "learning_rate": 3.413260517108968e-06,
      "loss": 0.0017,
      "step": 109190
    },
    {
      "epoch": 9.318201211707484,
      "grad_norm": 0.031005535274744034,
      "learning_rate": 3.4089939414625823e-06,
      "loss": 0.0017,
      "step": 109200
    },
    {
      "epoch": 9.31905452683676,
      "grad_norm": 0.08504363894462585,
      "learning_rate": 3.404727365816196e-06,
      "loss": 0.0013,
      "step": 109210
    },
    {
      "epoch": 9.319907841966039,
      "grad_norm": 0.034915532916784286,
      "learning_rate": 3.40046079016981e-06,
      "loss": 0.0019,
      "step": 109220
    },
    {
      "epoch": 9.320761157095315,
      "grad_norm": 0.2830103635787964,
      "learning_rate": 3.3961942145234238e-06,
      "loss": 0.0015,
      "step": 109230
    },
    {
      "epoch": 9.321614472224592,
      "grad_norm": 0.09555166214704514,
      "learning_rate": 3.3919276388770376e-06,
      "loss": 0.0017,
      "step": 109240
    },
    {
      "epoch": 9.32246778735387,
      "grad_norm": 0.11733974516391754,
      "learning_rate": 3.3876610632306514e-06,
      "loss": 0.0018,
      "step": 109250
    },
    {
      "epoch": 9.323321102483147,
      "grad_norm": 0.20470286905765533,
      "learning_rate": 3.3833944875842648e-06,
      "loss": 0.0013,
      "step": 109260
    },
    {
      "epoch": 9.324174417612424,
      "grad_norm": 0.21988996863365173,
      "learning_rate": 3.3791279119378786e-06,
      "loss": 0.0015,
      "step": 109270
    },
    {
      "epoch": 9.325027732741702,
      "grad_norm": 0.09218594431877136,
      "learning_rate": 3.3748613362914924e-06,
      "loss": 0.0016,
      "step": 109280
    },
    {
      "epoch": 9.325881047870979,
      "grad_norm": 0.16358475387096405,
      "learning_rate": 3.3705947606451067e-06,
      "loss": 0.0021,
      "step": 109290
    },
    {
      "epoch": 9.326734363000256,
      "grad_norm": 0.14926117658615112,
      "learning_rate": 3.3663281849987205e-06,
      "loss": 0.0014,
      "step": 109300
    },
    {
      "epoch": 9.327587678129532,
      "grad_norm": 0.14112012088298798,
      "learning_rate": 3.3620616093523343e-06,
      "loss": 0.0016,
      "step": 109310
    },
    {
      "epoch": 9.32844099325881,
      "grad_norm": 0.08866951614618301,
      "learning_rate": 3.3577950337059473e-06,
      "loss": 0.0018,
      "step": 109320
    },
    {
      "epoch": 9.329294308388087,
      "grad_norm": 0.13009387254714966,
      "learning_rate": 3.3535284580595615e-06,
      "loss": 0.0014,
      "step": 109330
    },
    {
      "epoch": 9.330147623517364,
      "grad_norm": 0.22059032320976257,
      "learning_rate": 3.3492618824131753e-06,
      "loss": 0.0015,
      "step": 109340
    },
    {
      "epoch": 9.331000938646643,
      "grad_norm": 0.28555381298065186,
      "learning_rate": 3.344995306766789e-06,
      "loss": 0.0019,
      "step": 109350
    },
    {
      "epoch": 9.33185425377592,
      "grad_norm": 0.12927281856536865,
      "learning_rate": 3.340728731120403e-06,
      "loss": 0.0015,
      "step": 109360
    },
    {
      "epoch": 9.332707568905196,
      "grad_norm": 0.06488793343305588,
      "learning_rate": 3.3364621554740168e-06,
      "loss": 0.0016,
      "step": 109370
    },
    {
      "epoch": 9.333560884034474,
      "grad_norm": 0.11319974064826965,
      "learning_rate": 3.332195579827631e-06,
      "loss": 0.0016,
      "step": 109380
    },
    {
      "epoch": 9.334414199163751,
      "grad_norm": 0.06016739830374718,
      "learning_rate": 3.327929004181244e-06,
      "loss": 0.0015,
      "step": 109390
    },
    {
      "epoch": 9.335267514293028,
      "grad_norm": 0.1580858826637268,
      "learning_rate": 3.323662428534858e-06,
      "loss": 0.0017,
      "step": 109400
    },
    {
      "epoch": 9.336120829422306,
      "grad_norm": 0.03603849187493324,
      "learning_rate": 3.3193958528884716e-06,
      "loss": 0.0015,
      "step": 109410
    },
    {
      "epoch": 9.336974144551583,
      "grad_norm": 0.07946071773767471,
      "learning_rate": 3.315129277242086e-06,
      "loss": 0.0016,
      "step": 109420
    },
    {
      "epoch": 9.33782745968086,
      "grad_norm": 0.04407765716314316,
      "learning_rate": 3.3108627015956997e-06,
      "loss": 0.0015,
      "step": 109430
    },
    {
      "epoch": 9.338680774810138,
      "grad_norm": 0.07761139422655106,
      "learning_rate": 3.3065961259493135e-06,
      "loss": 0.0017,
      "step": 109440
    },
    {
      "epoch": 9.339534089939415,
      "grad_norm": 0.08898821473121643,
      "learning_rate": 3.3023295503029273e-06,
      "loss": 0.0015,
      "step": 109450
    },
    {
      "epoch": 9.340387405068691,
      "grad_norm": 0.09620001167058945,
      "learning_rate": 3.2980629746565407e-06,
      "loss": 0.0014,
      "step": 109460
    },
    {
      "epoch": 9.34124072019797,
      "grad_norm": 0.0788784995675087,
      "learning_rate": 3.2937963990101545e-06,
      "loss": 0.002,
      "step": 109470
    },
    {
      "epoch": 9.342094035327246,
      "grad_norm": 0.1609685719013214,
      "learning_rate": 3.2895298233637683e-06,
      "loss": 0.0016,
      "step": 109480
    },
    {
      "epoch": 9.342947350456523,
      "grad_norm": 0.11465772241353989,
      "learning_rate": 3.285263247717382e-06,
      "loss": 0.0015,
      "step": 109490
    },
    {
      "epoch": 9.343800665585801,
      "grad_norm": 0.1988774538040161,
      "learning_rate": 3.280996672070996e-06,
      "loss": 0.0014,
      "step": 109500
    },
    {
      "epoch": 9.344653980715078,
      "grad_norm": 0.1081041544675827,
      "learning_rate": 3.2767300964246102e-06,
      "loss": 0.0013,
      "step": 109510
    },
    {
      "epoch": 9.345507295844355,
      "grad_norm": 0.19919231534004211,
      "learning_rate": 3.272463520778223e-06,
      "loss": 0.0016,
      "step": 109520
    },
    {
      "epoch": 9.346360610973633,
      "grad_norm": 0.05082258582115173,
      "learning_rate": 3.268196945131837e-06,
      "loss": 0.0017,
      "step": 109530
    },
    {
      "epoch": 9.34721392610291,
      "grad_norm": 0.2219853401184082,
      "learning_rate": 3.263930369485451e-06,
      "loss": 0.0015,
      "step": 109540
    },
    {
      "epoch": 9.348067241232187,
      "grad_norm": 0.18306578695774078,
      "learning_rate": 3.259663793839065e-06,
      "loss": 0.0017,
      "step": 109550
    },
    {
      "epoch": 9.348920556361465,
      "grad_norm": 0.27085578441619873,
      "learning_rate": 3.255397218192679e-06,
      "loss": 0.0016,
      "step": 109560
    },
    {
      "epoch": 9.349773871490742,
      "grad_norm": 0.035331033170223236,
      "learning_rate": 3.2511306425462927e-06,
      "loss": 0.0018,
      "step": 109570
    },
    {
      "epoch": 9.350627186620018,
      "grad_norm": 0.3473328649997711,
      "learning_rate": 3.2468640668999065e-06,
      "loss": 0.0013,
      "step": 109580
    },
    {
      "epoch": 9.351480501749297,
      "grad_norm": 0.13935492932796478,
      "learning_rate": 3.24259749125352e-06,
      "loss": 0.0018,
      "step": 109590
    },
    {
      "epoch": 9.352333816878573,
      "grad_norm": 0.110933817923069,
      "learning_rate": 3.2383309156071337e-06,
      "loss": 0.0018,
      "step": 109600
    },
    {
      "epoch": 9.35318713200785,
      "grad_norm": 0.10264082252979279,
      "learning_rate": 3.2340643399607476e-06,
      "loss": 0.0013,
      "step": 109610
    },
    {
      "epoch": 9.354040447137129,
      "grad_norm": 0.35909315943717957,
      "learning_rate": 3.2297977643143614e-06,
      "loss": 0.002,
      "step": 109620
    },
    {
      "epoch": 9.354893762266405,
      "grad_norm": 0.3584858775138855,
      "learning_rate": 3.225531188667975e-06,
      "loss": 0.0017,
      "step": 109630
    },
    {
      "epoch": 9.355747077395682,
      "grad_norm": 0.12276297807693481,
      "learning_rate": 3.2212646130215894e-06,
      "loss": 0.0012,
      "step": 109640
    },
    {
      "epoch": 9.35660039252496,
      "grad_norm": 0.03488888218998909,
      "learning_rate": 3.2169980373752024e-06,
      "loss": 0.0021,
      "step": 109650
    },
    {
      "epoch": 9.357453707654237,
      "grad_norm": 0.08764790743589401,
      "learning_rate": 3.2127314617288162e-06,
      "loss": 0.0014,
      "step": 109660
    },
    {
      "epoch": 9.358307022783514,
      "grad_norm": 0.3441435396671295,
      "learning_rate": 3.2084648860824305e-06,
      "loss": 0.0014,
      "step": 109670
    },
    {
      "epoch": 9.35916033791279,
      "grad_norm": 0.11123883724212646,
      "learning_rate": 3.2041983104360443e-06,
      "loss": 0.0016,
      "step": 109680
    },
    {
      "epoch": 9.360013653042069,
      "grad_norm": 0.14751721918582916,
      "learning_rate": 3.199931734789658e-06,
      "loss": 0.002,
      "step": 109690
    },
    {
      "epoch": 9.360866968171345,
      "grad_norm": 0.2422381490468979,
      "learning_rate": 3.195665159143272e-06,
      "loss": 0.0013,
      "step": 109700
    },
    {
      "epoch": 9.361720283300622,
      "grad_norm": 0.0456165187060833,
      "learning_rate": 3.1913985834968857e-06,
      "loss": 0.0014,
      "step": 109710
    },
    {
      "epoch": 9.3625735984299,
      "grad_norm": 0.41426563262939453,
      "learning_rate": 3.187132007850499e-06,
      "loss": 0.0015,
      "step": 109720
    },
    {
      "epoch": 9.363426913559177,
      "grad_norm": 0.19219285249710083,
      "learning_rate": 3.182865432204113e-06,
      "loss": 0.0015,
      "step": 109730
    },
    {
      "epoch": 9.364280228688454,
      "grad_norm": 0.2690519094467163,
      "learning_rate": 3.1785988565577268e-06,
      "loss": 0.0013,
      "step": 109740
    },
    {
      "epoch": 9.365133543817732,
      "grad_norm": 0.19963735342025757,
      "learning_rate": 3.1743322809113406e-06,
      "loss": 0.0016,
      "step": 109750
    },
    {
      "epoch": 9.365986858947009,
      "grad_norm": 0.2944277822971344,
      "learning_rate": 3.170065705264955e-06,
      "loss": 0.0021,
      "step": 109760
    },
    {
      "epoch": 9.366840174076286,
      "grad_norm": 0.13680008053779602,
      "learning_rate": 3.1657991296185686e-06,
      "loss": 0.0019,
      "step": 109770
    },
    {
      "epoch": 9.367693489205564,
      "grad_norm": 0.06612652540206909,
      "learning_rate": 3.1615325539721824e-06,
      "loss": 0.0014,
      "step": 109780
    },
    {
      "epoch": 9.36854680433484,
      "grad_norm": 0.11660213023424149,
      "learning_rate": 3.1572659783257954e-06,
      "loss": 0.0018,
      "step": 109790
    },
    {
      "epoch": 9.369400119464117,
      "grad_norm": 0.05782793462276459,
      "learning_rate": 3.1529994026794097e-06,
      "loss": 0.002,
      "step": 109800
    },
    {
      "epoch": 9.370253434593396,
      "grad_norm": 0.03297168016433716,
      "learning_rate": 3.1487328270330235e-06,
      "loss": 0.0015,
      "step": 109810
    },
    {
      "epoch": 9.371106749722673,
      "grad_norm": 0.04984506592154503,
      "learning_rate": 3.1444662513866373e-06,
      "loss": 0.0018,
      "step": 109820
    },
    {
      "epoch": 9.37196006485195,
      "grad_norm": 0.08163932710886002,
      "learning_rate": 3.140199675740251e-06,
      "loss": 0.0017,
      "step": 109830
    },
    {
      "epoch": 9.372813379981228,
      "grad_norm": 0.2003515660762787,
      "learning_rate": 3.135933100093865e-06,
      "loss": 0.0017,
      "step": 109840
    },
    {
      "epoch": 9.373666695110504,
      "grad_norm": 0.11121794581413269,
      "learning_rate": 3.1316665244474783e-06,
      "loss": 0.0015,
      "step": 109850
    },
    {
      "epoch": 9.374520010239781,
      "grad_norm": 0.14781714975833893,
      "learning_rate": 3.127399948801092e-06,
      "loss": 0.0015,
      "step": 109860
    },
    {
      "epoch": 9.37537332536906,
      "grad_norm": 0.07431778311729431,
      "learning_rate": 3.123133373154706e-06,
      "loss": 0.0013,
      "step": 109870
    },
    {
      "epoch": 9.376226640498336,
      "grad_norm": 0.09617378562688828,
      "learning_rate": 3.1188667975083198e-06,
      "loss": 0.0013,
      "step": 109880
    },
    {
      "epoch": 9.377079955627613,
      "grad_norm": 0.1809784322977066,
      "learning_rate": 3.114600221861934e-06,
      "loss": 0.0016,
      "step": 109890
    },
    {
      "epoch": 9.377933270756891,
      "grad_norm": 0.03078022040426731,
      "learning_rate": 3.1103336462155474e-06,
      "loss": 0.0017,
      "step": 109900
    },
    {
      "epoch": 9.378786585886168,
      "grad_norm": 0.12100795656442642,
      "learning_rate": 3.1060670705691612e-06,
      "loss": 0.0012,
      "step": 109910
    },
    {
      "epoch": 9.379639901015445,
      "grad_norm": 0.17205090820789337,
      "learning_rate": 3.101800494922775e-06,
      "loss": 0.0017,
      "step": 109920
    },
    {
      "epoch": 9.380493216144723,
      "grad_norm": 0.08307775110006332,
      "learning_rate": 3.097533919276389e-06,
      "loss": 0.0016,
      "step": 109930
    },
    {
      "epoch": 9.381346531274,
      "grad_norm": 0.06033002957701683,
      "learning_rate": 3.0932673436300027e-06,
      "loss": 0.0018,
      "step": 109940
    },
    {
      "epoch": 9.382199846403276,
      "grad_norm": 0.04517316073179245,
      "learning_rate": 3.0890007679836165e-06,
      "loss": 0.0015,
      "step": 109950
    },
    {
      "epoch": 9.383053161532555,
      "grad_norm": 0.13867071270942688,
      "learning_rate": 3.0847341923372303e-06,
      "loss": 0.0022,
      "step": 109960
    },
    {
      "epoch": 9.383906476661831,
      "grad_norm": 0.04372198134660721,
      "learning_rate": 3.080467616690844e-06,
      "loss": 0.0014,
      "step": 109970
    },
    {
      "epoch": 9.384759791791108,
      "grad_norm": 0.19269384443759918,
      "learning_rate": 3.076201041044458e-06,
      "loss": 0.0017,
      "step": 109980
    },
    {
      "epoch": 9.385613106920387,
      "grad_norm": 0.2921864092350006,
      "learning_rate": 3.0719344653980718e-06,
      "loss": 0.0015,
      "step": 109990
    },
    {
      "epoch": 9.386466422049663,
      "grad_norm": 0.031395018100738525,
      "learning_rate": 3.067667889751685e-06,
      "loss": 0.0013,
      "step": 110000
    },
    {
      "epoch": 9.38731973717894,
      "grad_norm": 0.23183660209178925,
      "learning_rate": 3.063401314105299e-06,
      "loss": 0.0015,
      "step": 110010
    },
    {
      "epoch": 9.388173052308218,
      "grad_norm": 0.08036980032920837,
      "learning_rate": 3.0591347384589132e-06,
      "loss": 0.0018,
      "step": 110020
    },
    {
      "epoch": 9.389026367437495,
      "grad_norm": 0.14787358045578003,
      "learning_rate": 3.054868162812527e-06,
      "loss": 0.0015,
      "step": 110030
    },
    {
      "epoch": 9.389879682566772,
      "grad_norm": 0.04539969936013222,
      "learning_rate": 3.0506015871661404e-06,
      "loss": 0.0016,
      "step": 110040
    },
    {
      "epoch": 9.390732997696048,
      "grad_norm": 0.14607243239879608,
      "learning_rate": 3.0463350115197542e-06,
      "loss": 0.0018,
      "step": 110050
    },
    {
      "epoch": 9.391586312825327,
      "grad_norm": 0.18550658226013184,
      "learning_rate": 3.0420684358733685e-06,
      "loss": 0.002,
      "step": 110060
    },
    {
      "epoch": 9.392439627954603,
      "grad_norm": 0.19889456033706665,
      "learning_rate": 3.037801860226982e-06,
      "loss": 0.0014,
      "step": 110070
    },
    {
      "epoch": 9.39329294308388,
      "grad_norm": 0.055549632757902145,
      "learning_rate": 3.0335352845805957e-06,
      "loss": 0.0017,
      "step": 110080
    },
    {
      "epoch": 9.394146258213159,
      "grad_norm": 0.18024294078350067,
      "learning_rate": 3.0292687089342095e-06,
      "loss": 0.0017,
      "step": 110090
    },
    {
      "epoch": 9.394999573342435,
      "grad_norm": 0.2019929587841034,
      "learning_rate": 3.0250021332878233e-06,
      "loss": 0.0016,
      "step": 110100
    },
    {
      "epoch": 9.395852888471712,
      "grad_norm": 0.050218794494867325,
      "learning_rate": 3.020735557641437e-06,
      "loss": 0.002,
      "step": 110110
    },
    {
      "epoch": 9.39670620360099,
      "grad_norm": 0.16532552242279053,
      "learning_rate": 3.016468981995051e-06,
      "loss": 0.0015,
      "step": 110120
    },
    {
      "epoch": 9.397559518730267,
      "grad_norm": 0.15818998217582703,
      "learning_rate": 3.0122024063486648e-06,
      "loss": 0.0018,
      "step": 110130
    },
    {
      "epoch": 9.398412833859544,
      "grad_norm": 0.2208903431892395,
      "learning_rate": 3.0079358307022786e-06,
      "loss": 0.0016,
      "step": 110140
    },
    {
      "epoch": 9.399266148988822,
      "grad_norm": 0.035875048488378525,
      "learning_rate": 3.0036692550558924e-06,
      "loss": 0.0015,
      "step": 110150
    },
    {
      "epoch": 9.400119464118099,
      "grad_norm": 0.18982084095478058,
      "learning_rate": 2.9994026794095062e-06,
      "loss": 0.0015,
      "step": 110160
    },
    {
      "epoch": 9.400972779247375,
      "grad_norm": 0.16232064366340637,
      "learning_rate": 2.9951361037631196e-06,
      "loss": 0.0017,
      "step": 110170
    },
    {
      "epoch": 9.401826094376654,
      "grad_norm": 0.07700259238481522,
      "learning_rate": 2.9908695281167335e-06,
      "loss": 0.0017,
      "step": 110180
    },
    {
      "epoch": 9.40267940950593,
      "grad_norm": 0.2405812293291092,
      "learning_rate": 2.9866029524703477e-06,
      "loss": 0.0015,
      "step": 110190
    },
    {
      "epoch": 9.403532724635207,
      "grad_norm": 0.11281821876764297,
      "learning_rate": 2.982336376823961e-06,
      "loss": 0.0015,
      "step": 110200
    },
    {
      "epoch": 9.404386039764486,
      "grad_norm": 0.02857113443315029,
      "learning_rate": 2.978069801177575e-06,
      "loss": 0.0016,
      "step": 110210
    },
    {
      "epoch": 9.405239354893762,
      "grad_norm": 0.20752032101154327,
      "learning_rate": 2.9738032255311887e-06,
      "loss": 0.0012,
      "step": 110220
    },
    {
      "epoch": 9.406092670023039,
      "grad_norm": 0.09500075876712799,
      "learning_rate": 2.969536649884803e-06,
      "loss": 0.0016,
      "step": 110230
    },
    {
      "epoch": 9.406945985152317,
      "grad_norm": 0.05922519788146019,
      "learning_rate": 2.9652700742384164e-06,
      "loss": 0.0014,
      "step": 110240
    },
    {
      "epoch": 9.407799300281594,
      "grad_norm": 0.12939926981925964,
      "learning_rate": 2.96100349859203e-06,
      "loss": 0.0022,
      "step": 110250
    },
    {
      "epoch": 9.40865261541087,
      "grad_norm": 0.16237911581993103,
      "learning_rate": 2.956736922945644e-06,
      "loss": 0.0014,
      "step": 110260
    },
    {
      "epoch": 9.40950593054015,
      "grad_norm": 0.12906423211097717,
      "learning_rate": 2.952470347299258e-06,
      "loss": 0.0017,
      "step": 110270
    },
    {
      "epoch": 9.410359245669426,
      "grad_norm": 0.03457028791308403,
      "learning_rate": 2.9482037716528716e-06,
      "loss": 0.0013,
      "step": 110280
    },
    {
      "epoch": 9.411212560798702,
      "grad_norm": 0.14665253460407257,
      "learning_rate": 2.9439371960064854e-06,
      "loss": 0.0015,
      "step": 110290
    },
    {
      "epoch": 9.412065875927981,
      "grad_norm": 0.11698510497808456,
      "learning_rate": 2.939670620360099e-06,
      "loss": 0.0015,
      "step": 110300
    },
    {
      "epoch": 9.412919191057258,
      "grad_norm": 0.039837516844272614,
      "learning_rate": 2.935404044713713e-06,
      "loss": 0.0019,
      "step": 110310
    },
    {
      "epoch": 9.413772506186534,
      "grad_norm": 0.19656629860401154,
      "learning_rate": 2.931137469067327e-06,
      "loss": 0.0016,
      "step": 110320
    },
    {
      "epoch": 9.414625821315813,
      "grad_norm": 0.17989271879196167,
      "learning_rate": 2.9268708934209407e-06,
      "loss": 0.0023,
      "step": 110330
    },
    {
      "epoch": 9.41547913644509,
      "grad_norm": 0.251188725233078,
      "learning_rate": 2.922604317774554e-06,
      "loss": 0.0019,
      "step": 110340
    },
    {
      "epoch": 9.416332451574366,
      "grad_norm": 0.07893182337284088,
      "learning_rate": 2.918337742128168e-06,
      "loss": 0.0017,
      "step": 110350
    },
    {
      "epoch": 9.417185766703644,
      "grad_norm": 0.06347595155239105,
      "learning_rate": 2.914071166481782e-06,
      "loss": 0.0015,
      "step": 110360
    },
    {
      "epoch": 9.418039081832921,
      "grad_norm": 0.1467430591583252,
      "learning_rate": 2.9098045908353956e-06,
      "loss": 0.0016,
      "step": 110370
    },
    {
      "epoch": 9.418892396962198,
      "grad_norm": 0.14695709943771362,
      "learning_rate": 2.9055380151890094e-06,
      "loss": 0.0019,
      "step": 110380
    },
    {
      "epoch": 9.419745712091476,
      "grad_norm": 0.28792092204093933,
      "learning_rate": 2.901271439542623e-06,
      "loss": 0.0018,
      "step": 110390
    },
    {
      "epoch": 9.420599027220753,
      "grad_norm": 0.2251119315624237,
      "learning_rate": 2.897004863896237e-06,
      "loss": 0.0013,
      "step": 110400
    },
    {
      "epoch": 9.42145234235003,
      "grad_norm": 0.21308691799640656,
      "learning_rate": 2.892738288249851e-06,
      "loss": 0.0017,
      "step": 110410
    },
    {
      "epoch": 9.422305657479306,
      "grad_norm": 0.08692912757396698,
      "learning_rate": 2.8884717126034646e-06,
      "loss": 0.0017,
      "step": 110420
    },
    {
      "epoch": 9.423158972608585,
      "grad_norm": 0.1252591758966446,
      "learning_rate": 2.8842051369570785e-06,
      "loss": 0.0016,
      "step": 110430
    },
    {
      "epoch": 9.424012287737861,
      "grad_norm": 0.06508976966142654,
      "learning_rate": 2.8799385613106923e-06,
      "loss": 0.0017,
      "step": 110440
    },
    {
      "epoch": 9.424865602867138,
      "grad_norm": 0.09557411819696426,
      "learning_rate": 2.875671985664306e-06,
      "loss": 0.0018,
      "step": 110450
    },
    {
      "epoch": 9.425718917996416,
      "grad_norm": 0.24531283974647522,
      "learning_rate": 2.87140541001792e-06,
      "loss": 0.0014,
      "step": 110460
    },
    {
      "epoch": 9.426572233125693,
      "grad_norm": 0.03708124905824661,
      "learning_rate": 2.8671388343715333e-06,
      "loss": 0.0017,
      "step": 110470
    },
    {
      "epoch": 9.42742554825497,
      "grad_norm": 0.1607389897108078,
      "learning_rate": 2.862872258725147e-06,
      "loss": 0.0019,
      "step": 110480
    },
    {
      "epoch": 9.428278863384248,
      "grad_norm": 0.07692570984363556,
      "learning_rate": 2.8586056830787614e-06,
      "loss": 0.0016,
      "step": 110490
    },
    {
      "epoch": 9.429132178513525,
      "grad_norm": 0.05430411174893379,
      "learning_rate": 2.8543391074323748e-06,
      "loss": 0.0018,
      "step": 110500
    },
    {
      "epoch": 9.429985493642802,
      "grad_norm": 0.11312789469957352,
      "learning_rate": 2.8500725317859886e-06,
      "loss": 0.0016,
      "step": 110510
    },
    {
      "epoch": 9.43083880877208,
      "grad_norm": 0.027368294075131416,
      "learning_rate": 2.8458059561396024e-06,
      "loss": 0.0017,
      "step": 110520
    },
    {
      "epoch": 9.431692123901357,
      "grad_norm": 0.13292604684829712,
      "learning_rate": 2.8415393804932162e-06,
      "loss": 0.0014,
      "step": 110530
    },
    {
      "epoch": 9.432545439030633,
      "grad_norm": 0.254284530878067,
      "learning_rate": 2.83727280484683e-06,
      "loss": 0.0018,
      "step": 110540
    },
    {
      "epoch": 9.433398754159912,
      "grad_norm": 0.07589780539274216,
      "learning_rate": 2.833006229200444e-06,
      "loss": 0.0016,
      "step": 110550
    },
    {
      "epoch": 9.434252069289188,
      "grad_norm": 0.10956636071205139,
      "learning_rate": 2.8287396535540577e-06,
      "loss": 0.0016,
      "step": 110560
    },
    {
      "epoch": 9.435105384418465,
      "grad_norm": 0.2016756236553192,
      "learning_rate": 2.8244730779076715e-06,
      "loss": 0.0018,
      "step": 110570
    },
    {
      "epoch": 9.435958699547744,
      "grad_norm": 0.09414427727460861,
      "learning_rate": 2.8202065022612853e-06,
      "loss": 0.0019,
      "step": 110580
    },
    {
      "epoch": 9.43681201467702,
      "grad_norm": 0.3957766592502594,
      "learning_rate": 2.815939926614899e-06,
      "loss": 0.0018,
      "step": 110590
    },
    {
      "epoch": 9.437665329806297,
      "grad_norm": 0.07617110759019852,
      "learning_rate": 2.8116733509685125e-06,
      "loss": 0.0018,
      "step": 110600
    },
    {
      "epoch": 9.438518644935575,
      "grad_norm": 0.1837761402130127,
      "learning_rate": 2.8074067753221268e-06,
      "loss": 0.0017,
      "step": 110610
    },
    {
      "epoch": 9.439371960064852,
      "grad_norm": 0.1871613711118698,
      "learning_rate": 2.8031401996757406e-06,
      "loss": 0.0017,
      "step": 110620
    },
    {
      "epoch": 9.440225275194129,
      "grad_norm": 0.09461423009634018,
      "learning_rate": 2.798873624029354e-06,
      "loss": 0.002,
      "step": 110630
    },
    {
      "epoch": 9.441078590323407,
      "grad_norm": 0.08332998305559158,
      "learning_rate": 2.7946070483829678e-06,
      "loss": 0.0015,
      "step": 110640
    },
    {
      "epoch": 9.441931905452684,
      "grad_norm": 0.09634467214345932,
      "learning_rate": 2.7903404727365816e-06,
      "loss": 0.0016,
      "step": 110650
    },
    {
      "epoch": 9.44278522058196,
      "grad_norm": 0.05436480790376663,
      "learning_rate": 2.786073897090196e-06,
      "loss": 0.0015,
      "step": 110660
    },
    {
      "epoch": 9.443638535711239,
      "grad_norm": 0.09608764946460724,
      "learning_rate": 2.7818073214438092e-06,
      "loss": 0.0013,
      "step": 110670
    },
    {
      "epoch": 9.444491850840516,
      "grad_norm": 0.07151009887456894,
      "learning_rate": 2.777540745797423e-06,
      "loss": 0.0016,
      "step": 110680
    },
    {
      "epoch": 9.445345165969792,
      "grad_norm": 0.16108626127243042,
      "learning_rate": 2.773274170151037e-06,
      "loss": 0.0019,
      "step": 110690
    },
    {
      "epoch": 9.44619848109907,
      "grad_norm": 0.07497859001159668,
      "learning_rate": 2.7690075945046507e-06,
      "loss": 0.0016,
      "step": 110700
    },
    {
      "epoch": 9.447051796228347,
      "grad_norm": 0.2876329720020294,
      "learning_rate": 2.7647410188582645e-06,
      "loss": 0.0016,
      "step": 110710
    },
    {
      "epoch": 9.447905111357624,
      "grad_norm": 0.08388333022594452,
      "learning_rate": 2.7604744432118783e-06,
      "loss": 0.0018,
      "step": 110720
    },
    {
      "epoch": 9.448758426486902,
      "grad_norm": 0.05762510374188423,
      "learning_rate": 2.7562078675654917e-06,
      "loss": 0.0017,
      "step": 110730
    },
    {
      "epoch": 9.44961174161618,
      "grad_norm": 0.06305629760026932,
      "learning_rate": 2.751941291919106e-06,
      "loss": 0.0013,
      "step": 110740
    },
    {
      "epoch": 9.450465056745456,
      "grad_norm": 0.20323212444782257,
      "learning_rate": 2.7476747162727198e-06,
      "loss": 0.0013,
      "step": 110750
    },
    {
      "epoch": 9.451318371874734,
      "grad_norm": 0.09449777007102966,
      "learning_rate": 2.7434081406263336e-06,
      "loss": 0.0019,
      "step": 110760
    },
    {
      "epoch": 9.452171687004011,
      "grad_norm": 0.041836537420749664,
      "learning_rate": 2.739141564979947e-06,
      "loss": 0.0019,
      "step": 110770
    },
    {
      "epoch": 9.453025002133288,
      "grad_norm": 0.11258476972579956,
      "learning_rate": 2.7348749893335612e-06,
      "loss": 0.0016,
      "step": 110780
    },
    {
      "epoch": 9.453878317262564,
      "grad_norm": 0.07650481909513474,
      "learning_rate": 2.730608413687175e-06,
      "loss": 0.0015,
      "step": 110790
    },
    {
      "epoch": 9.454731632391843,
      "grad_norm": 0.12660415470600128,
      "learning_rate": 2.7263418380407884e-06,
      "loss": 0.0015,
      "step": 110800
    },
    {
      "epoch": 9.45558494752112,
      "grad_norm": 0.11033116281032562,
      "learning_rate": 2.7220752623944023e-06,
      "loss": 0.0015,
      "step": 110810
    },
    {
      "epoch": 9.456438262650396,
      "grad_norm": 0.044442858546972275,
      "learning_rate": 2.717808686748016e-06,
      "loss": 0.0012,
      "step": 110820
    },
    {
      "epoch": 9.457291577779674,
      "grad_norm": 0.07345262169837952,
      "learning_rate": 2.71354211110163e-06,
      "loss": 0.0018,
      "step": 110830
    },
    {
      "epoch": 9.458144892908951,
      "grad_norm": 0.30077701807022095,
      "learning_rate": 2.7092755354552437e-06,
      "loss": 0.0015,
      "step": 110840
    },
    {
      "epoch": 9.458998208038228,
      "grad_norm": 0.05894676595926285,
      "learning_rate": 2.7050089598088575e-06,
      "loss": 0.0018,
      "step": 110850
    },
    {
      "epoch": 9.459851523167506,
      "grad_norm": 0.08054904639720917,
      "learning_rate": 2.7007423841624713e-06,
      "loss": 0.0017,
      "step": 110860
    },
    {
      "epoch": 9.460704838296783,
      "grad_norm": 0.06208561360836029,
      "learning_rate": 2.696475808516085e-06,
      "loss": 0.0016,
      "step": 110870
    },
    {
      "epoch": 9.46155815342606,
      "grad_norm": 0.01927570439875126,
      "learning_rate": 2.692209232869699e-06,
      "loss": 0.0017,
      "step": 110880
    },
    {
      "epoch": 9.462411468555338,
      "grad_norm": 0.1474854052066803,
      "learning_rate": 2.687942657223313e-06,
      "loss": 0.002,
      "step": 110890
    },
    {
      "epoch": 9.463264783684615,
      "grad_norm": 0.25158819556236267,
      "learning_rate": 2.683676081576926e-06,
      "loss": 0.0019,
      "step": 110900
    },
    {
      "epoch": 9.464118098813891,
      "grad_norm": 0.1937207281589508,
      "learning_rate": 2.6794095059305404e-06,
      "loss": 0.0016,
      "step": 110910
    },
    {
      "epoch": 9.46497141394317,
      "grad_norm": 0.09747468680143356,
      "learning_rate": 2.6751429302841542e-06,
      "loss": 0.0017,
      "step": 110920
    },
    {
      "epoch": 9.465824729072446,
      "grad_norm": 0.13223744928836823,
      "learning_rate": 2.6708763546377676e-06,
      "loss": 0.0016,
      "step": 110930
    },
    {
      "epoch": 9.466678044201723,
      "grad_norm": 0.05197862535715103,
      "learning_rate": 2.6666097789913815e-06,
      "loss": 0.0014,
      "step": 110940
    },
    {
      "epoch": 9.467531359331002,
      "grad_norm": 0.049450989812612534,
      "learning_rate": 2.6623432033449953e-06,
      "loss": 0.0017,
      "step": 110950
    },
    {
      "epoch": 9.468384674460278,
      "grad_norm": 0.04604793339967728,
      "learning_rate": 2.6580766276986095e-06,
      "loss": 0.0016,
      "step": 110960
    },
    {
      "epoch": 9.469237989589555,
      "grad_norm": 0.06143900007009506,
      "learning_rate": 2.653810052052223e-06,
      "loss": 0.0015,
      "step": 110970
    },
    {
      "epoch": 9.470091304718833,
      "grad_norm": 0.24389947950839996,
      "learning_rate": 2.6495434764058367e-06,
      "loss": 0.0017,
      "step": 110980
    },
    {
      "epoch": 9.47094461984811,
      "grad_norm": 0.10974491387605667,
      "learning_rate": 2.6452769007594505e-06,
      "loss": 0.0019,
      "step": 110990
    },
    {
      "epoch": 9.471797934977387,
      "grad_norm": 0.07609901577234268,
      "learning_rate": 2.6410103251130644e-06,
      "loss": 0.0016,
      "step": 111000
    },
    {
      "epoch": 9.472651250106665,
      "grad_norm": 0.07199607789516449,
      "learning_rate": 2.636743749466678e-06,
      "loss": 0.0019,
      "step": 111010
    },
    {
      "epoch": 9.473504565235942,
      "grad_norm": 0.07369174808263779,
      "learning_rate": 2.632477173820292e-06,
      "loss": 0.0016,
      "step": 111020
    },
    {
      "epoch": 9.474357880365218,
      "grad_norm": 0.037752918899059296,
      "learning_rate": 2.6282105981739054e-06,
      "loss": 0.0014,
      "step": 111030
    },
    {
      "epoch": 9.475211195494497,
      "grad_norm": 0.166098952293396,
      "learning_rate": 2.6239440225275196e-06,
      "loss": 0.0013,
      "step": 111040
    },
    {
      "epoch": 9.476064510623774,
      "grad_norm": 0.12902627885341644,
      "learning_rate": 2.6196774468811335e-06,
      "loss": 0.0013,
      "step": 111050
    },
    {
      "epoch": 9.47691782575305,
      "grad_norm": 0.1811789721250534,
      "learning_rate": 2.6154108712347473e-06,
      "loss": 0.0014,
      "step": 111060
    },
    {
      "epoch": 9.477771140882329,
      "grad_norm": 0.17726770043373108,
      "learning_rate": 2.6111442955883607e-06,
      "loss": 0.0018,
      "step": 111070
    },
    {
      "epoch": 9.478624456011605,
      "grad_norm": 0.060059983283281326,
      "learning_rate": 2.606877719941975e-06,
      "loss": 0.0016,
      "step": 111080
    },
    {
      "epoch": 9.479477771140882,
      "grad_norm": 0.038469865918159485,
      "learning_rate": 2.6026111442955887e-06,
      "loss": 0.0018,
      "step": 111090
    },
    {
      "epoch": 9.48033108627016,
      "grad_norm": 0.17963670194149017,
      "learning_rate": 2.598344568649202e-06,
      "loss": 0.0016,
      "step": 111100
    },
    {
      "epoch": 9.481184401399437,
      "grad_norm": 0.09372273087501526,
      "learning_rate": 2.594077993002816e-06,
      "loss": 0.0016,
      "step": 111110
    },
    {
      "epoch": 9.482037716528714,
      "grad_norm": 0.14635272324085236,
      "learning_rate": 2.5898114173564297e-06,
      "loss": 0.0017,
      "step": 111120
    },
    {
      "epoch": 9.482891031657992,
      "grad_norm": 0.24791747331619263,
      "learning_rate": 2.5855448417100436e-06,
      "loss": 0.0017,
      "step": 111130
    },
    {
      "epoch": 9.483744346787269,
      "grad_norm": 0.0866517573595047,
      "learning_rate": 2.5812782660636574e-06,
      "loss": 0.0015,
      "step": 111140
    },
    {
      "epoch": 9.484597661916546,
      "grad_norm": 0.13209597766399384,
      "learning_rate": 2.577011690417271e-06,
      "loss": 0.0015,
      "step": 111150
    },
    {
      "epoch": 9.485450977045822,
      "grad_norm": 0.09576809406280518,
      "learning_rate": 2.572745114770885e-06,
      "loss": 0.0016,
      "step": 111160
    },
    {
      "epoch": 9.4863042921751,
      "grad_norm": 0.08203060925006866,
      "learning_rate": 2.568478539124499e-06,
      "loss": 0.0022,
      "step": 111170
    },
    {
      "epoch": 9.487157607304377,
      "grad_norm": 0.19670370221138,
      "learning_rate": 2.5642119634781127e-06,
      "loss": 0.0016,
      "step": 111180
    },
    {
      "epoch": 9.488010922433654,
      "grad_norm": 0.04125175625085831,
      "learning_rate": 2.5599453878317265e-06,
      "loss": 0.0017,
      "step": 111190
    },
    {
      "epoch": 9.488864237562932,
      "grad_norm": 0.16840724647045135,
      "learning_rate": 2.55567881218534e-06,
      "loss": 0.0017,
      "step": 111200
    },
    {
      "epoch": 9.489717552692209,
      "grad_norm": 0.08692361414432526,
      "learning_rate": 2.551412236538954e-06,
      "loss": 0.0017,
      "step": 111210
    },
    {
      "epoch": 9.490570867821486,
      "grad_norm": 0.23597775399684906,
      "learning_rate": 2.547145660892568e-06,
      "loss": 0.0017,
      "step": 111220
    },
    {
      "epoch": 9.491424182950764,
      "grad_norm": 0.19857478141784668,
      "learning_rate": 2.5428790852461813e-06,
      "loss": 0.0017,
      "step": 111230
    },
    {
      "epoch": 9.49227749808004,
      "grad_norm": 0.041827958077192307,
      "learning_rate": 2.538612509599795e-06,
      "loss": 0.0015,
      "step": 111240
    },
    {
      "epoch": 9.493130813209318,
      "grad_norm": 0.11348241567611694,
      "learning_rate": 2.5343459339534094e-06,
      "loss": 0.0021,
      "step": 111250
    },
    {
      "epoch": 9.493984128338596,
      "grad_norm": 0.048056669533252716,
      "learning_rate": 2.530079358307023e-06,
      "loss": 0.0019,
      "step": 111260
    },
    {
      "epoch": 9.494837443467873,
      "grad_norm": 0.046193961054086685,
      "learning_rate": 2.5258127826606366e-06,
      "loss": 0.0017,
      "step": 111270
    },
    {
      "epoch": 9.49569075859715,
      "grad_norm": 0.08235473930835724,
      "learning_rate": 2.5215462070142504e-06,
      "loss": 0.0013,
      "step": 111280
    },
    {
      "epoch": 9.496544073726428,
      "grad_norm": 0.19898101687431335,
      "learning_rate": 2.5172796313678642e-06,
      "loss": 0.002,
      "step": 111290
    },
    {
      "epoch": 9.497397388855704,
      "grad_norm": 0.324643611907959,
      "learning_rate": 2.513013055721478e-06,
      "loss": 0.0018,
      "step": 111300
    },
    {
      "epoch": 9.498250703984981,
      "grad_norm": 0.06579027324914932,
      "learning_rate": 2.508746480075092e-06,
      "loss": 0.0017,
      "step": 111310
    },
    {
      "epoch": 9.49910401911426,
      "grad_norm": 0.07474137097597122,
      "learning_rate": 2.5044799044287057e-06,
      "loss": 0.0018,
      "step": 111320
    },
    {
      "epoch": 9.499957334243536,
      "grad_norm": 0.23696523904800415,
      "learning_rate": 2.5002133287823195e-06,
      "loss": 0.0015,
      "step": 111330
    },
    {
      "epoch": 9.500810649372813,
      "grad_norm": 0.1080765351653099,
      "learning_rate": 2.4959467531359333e-06,
      "loss": 0.0016,
      "step": 111340
    },
    {
      "epoch": 9.501663964502091,
      "grad_norm": 0.13161231577396393,
      "learning_rate": 2.491680177489547e-06,
      "loss": 0.0015,
      "step": 111350
    },
    {
      "epoch": 9.502517279631368,
      "grad_norm": 0.03931807354092598,
      "learning_rate": 2.487413601843161e-06,
      "loss": 0.0019,
      "step": 111360
    },
    {
      "epoch": 9.503370594760645,
      "grad_norm": 0.04698782041668892,
      "learning_rate": 2.4831470261967743e-06,
      "loss": 0.0016,
      "step": 111370
    },
    {
      "epoch": 9.504223909889923,
      "grad_norm": 0.11382266134023666,
      "learning_rate": 2.4788804505503886e-06,
      "loss": 0.0014,
      "step": 111380
    },
    {
      "epoch": 9.5050772250192,
      "grad_norm": 0.2274867594242096,
      "learning_rate": 2.4746138749040024e-06,
      "loss": 0.0016,
      "step": 111390
    },
    {
      "epoch": 9.505930540148476,
      "grad_norm": 0.3102318346500397,
      "learning_rate": 2.470347299257616e-06,
      "loss": 0.0015,
      "step": 111400
    },
    {
      "epoch": 9.506783855277755,
      "grad_norm": 0.16170060634613037,
      "learning_rate": 2.4660807236112296e-06,
      "loss": 0.0016,
      "step": 111410
    },
    {
      "epoch": 9.507637170407031,
      "grad_norm": 0.06038518249988556,
      "learning_rate": 2.4618141479648434e-06,
      "loss": 0.0015,
      "step": 111420
    },
    {
      "epoch": 9.508490485536308,
      "grad_norm": 0.04459819570183754,
      "learning_rate": 2.4575475723184572e-06,
      "loss": 0.0017,
      "step": 111430
    },
    {
      "epoch": 9.509343800665587,
      "grad_norm": 0.09932668507099152,
      "learning_rate": 2.453280996672071e-06,
      "loss": 0.002,
      "step": 111440
    },
    {
      "epoch": 9.510197115794863,
      "grad_norm": 0.3077196180820465,
      "learning_rate": 2.449014421025685e-06,
      "loss": 0.0015,
      "step": 111450
    },
    {
      "epoch": 9.51105043092414,
      "grad_norm": 0.08528066426515579,
      "learning_rate": 2.4447478453792987e-06,
      "loss": 0.0016,
      "step": 111460
    },
    {
      "epoch": 9.511903746053417,
      "grad_norm": 0.09980573505163193,
      "learning_rate": 2.4404812697329125e-06,
      "loss": 0.0019,
      "step": 111470
    },
    {
      "epoch": 9.512757061182695,
      "grad_norm": 0.03653671219944954,
      "learning_rate": 2.4362146940865263e-06,
      "loss": 0.0021,
      "step": 111480
    },
    {
      "epoch": 9.513610376311972,
      "grad_norm": 0.13410109281539917,
      "learning_rate": 2.43194811844014e-06,
      "loss": 0.0015,
      "step": 111490
    },
    {
      "epoch": 9.51446369144125,
      "grad_norm": 0.11112341284751892,
      "learning_rate": 2.4276815427937535e-06,
      "loss": 0.0013,
      "step": 111500
    },
    {
      "epoch": 9.515317006570527,
      "grad_norm": 0.028850261121988297,
      "learning_rate": 2.4234149671473678e-06,
      "loss": 0.0012,
      "step": 111510
    },
    {
      "epoch": 9.516170321699803,
      "grad_norm": 0.16451101005077362,
      "learning_rate": 2.4191483915009816e-06,
      "loss": 0.0021,
      "step": 111520
    },
    {
      "epoch": 9.51702363682908,
      "grad_norm": 0.11135678738355637,
      "learning_rate": 2.414881815854595e-06,
      "loss": 0.0022,
      "step": 111530
    },
    {
      "epoch": 9.517876951958359,
      "grad_norm": 0.05921896919608116,
      "learning_rate": 2.410615240208209e-06,
      "loss": 0.0015,
      "step": 111540
    },
    {
      "epoch": 9.518730267087635,
      "grad_norm": 0.19923411309719086,
      "learning_rate": 2.406348664561823e-06,
      "loss": 0.0018,
      "step": 111550
    },
    {
      "epoch": 9.519583582216912,
      "grad_norm": 0.11000701785087585,
      "learning_rate": 2.4020820889154364e-06,
      "loss": 0.0015,
      "step": 111560
    },
    {
      "epoch": 9.52043689734619,
      "grad_norm": 0.18114949762821198,
      "learning_rate": 2.3978155132690503e-06,
      "loss": 0.0014,
      "step": 111570
    },
    {
      "epoch": 9.521290212475467,
      "grad_norm": 0.06262451410293579,
      "learning_rate": 2.393548937622664e-06,
      "loss": 0.0013,
      "step": 111580
    },
    {
      "epoch": 9.522143527604744,
      "grad_norm": 0.27294933795928955,
      "learning_rate": 2.389282361976278e-06,
      "loss": 0.0019,
      "step": 111590
    },
    {
      "epoch": 9.522996842734022,
      "grad_norm": 0.21846695244312286,
      "learning_rate": 2.3850157863298917e-06,
      "loss": 0.0017,
      "step": 111600
    },
    {
      "epoch": 9.523850157863299,
      "grad_norm": 0.07067395001649857,
      "learning_rate": 2.3807492106835055e-06,
      "loss": 0.0018,
      "step": 111610
    },
    {
      "epoch": 9.524703472992575,
      "grad_norm": 0.2873668074607849,
      "learning_rate": 2.3764826350371194e-06,
      "loss": 0.0017,
      "step": 111620
    },
    {
      "epoch": 9.525556788121854,
      "grad_norm": 0.20971474051475525,
      "learning_rate": 2.372216059390733e-06,
      "loss": 0.0015,
      "step": 111630
    },
    {
      "epoch": 9.52641010325113,
      "grad_norm": 0.14693710207939148,
      "learning_rate": 2.367949483744347e-06,
      "loss": 0.0018,
      "step": 111640
    },
    {
      "epoch": 9.527263418380407,
      "grad_norm": 0.05834442004561424,
      "learning_rate": 2.363682908097961e-06,
      "loss": 0.0014,
      "step": 111650
    },
    {
      "epoch": 9.528116733509686,
      "grad_norm": 0.08464989811182022,
      "learning_rate": 2.359416332451574e-06,
      "loss": 0.0015,
      "step": 111660
    },
    {
      "epoch": 9.528970048638962,
      "grad_norm": 0.07718973606824875,
      "learning_rate": 2.355149756805188e-06,
      "loss": 0.0019,
      "step": 111670
    },
    {
      "epoch": 9.529823363768239,
      "grad_norm": 0.11458280682563782,
      "learning_rate": 2.3508831811588023e-06,
      "loss": 0.0017,
      "step": 111680
    },
    {
      "epoch": 9.530676678897517,
      "grad_norm": 0.10845130681991577,
      "learning_rate": 2.346616605512416e-06,
      "loss": 0.0016,
      "step": 111690
    },
    {
      "epoch": 9.531529994026794,
      "grad_norm": 0.1518373042345047,
      "learning_rate": 2.3423500298660295e-06,
      "loss": 0.0017,
      "step": 111700
    },
    {
      "epoch": 9.53238330915607,
      "grad_norm": 0.2018105536699295,
      "learning_rate": 2.3380834542196433e-06,
      "loss": 0.0016,
      "step": 111710
    },
    {
      "epoch": 9.53323662428535,
      "grad_norm": 0.21811462938785553,
      "learning_rate": 2.3338168785732575e-06,
      "loss": 0.0014,
      "step": 111720
    },
    {
      "epoch": 9.534089939414626,
      "grad_norm": 0.08187094330787659,
      "learning_rate": 2.329550302926871e-06,
      "loss": 0.0014,
      "step": 111730
    },
    {
      "epoch": 9.534943254543903,
      "grad_norm": 0.07371538877487183,
      "learning_rate": 2.3252837272804847e-06,
      "loss": 0.0014,
      "step": 111740
    },
    {
      "epoch": 9.535796569673181,
      "grad_norm": 0.03406647592782974,
      "learning_rate": 2.3210171516340986e-06,
      "loss": 0.0014,
      "step": 111750
    },
    {
      "epoch": 9.536649884802458,
      "grad_norm": 0.2191884070634842,
      "learning_rate": 2.3167505759877124e-06,
      "loss": 0.0019,
      "step": 111760
    },
    {
      "epoch": 9.537503199931734,
      "grad_norm": 0.14641332626342773,
      "learning_rate": 2.312484000341326e-06,
      "loss": 0.0013,
      "step": 111770
    },
    {
      "epoch": 9.538356515061013,
      "grad_norm": 0.04931711032986641,
      "learning_rate": 2.30821742469494e-06,
      "loss": 0.0012,
      "step": 111780
    },
    {
      "epoch": 9.53920983019029,
      "grad_norm": 0.47568777203559875,
      "learning_rate": 2.303950849048554e-06,
      "loss": 0.0018,
      "step": 111790
    },
    {
      "epoch": 9.540063145319566,
      "grad_norm": 0.04772487282752991,
      "learning_rate": 2.2996842734021676e-06,
      "loss": 0.0016,
      "step": 111800
    },
    {
      "epoch": 9.540916460448845,
      "grad_norm": 0.08045069128274918,
      "learning_rate": 2.2954176977557815e-06,
      "loss": 0.0016,
      "step": 111810
    },
    {
      "epoch": 9.541769775578121,
      "grad_norm": 0.14718282222747803,
      "learning_rate": 2.2911511221093953e-06,
      "loss": 0.0011,
      "step": 111820
    },
    {
      "epoch": 9.542623090707398,
      "grad_norm": 0.06656678766012192,
      "learning_rate": 2.2868845464630087e-06,
      "loss": 0.0014,
      "step": 111830
    },
    {
      "epoch": 9.543476405836675,
      "grad_norm": 0.0925905779004097,
      "learning_rate": 2.2826179708166225e-06,
      "loss": 0.0015,
      "step": 111840
    },
    {
      "epoch": 9.544329720965953,
      "grad_norm": 0.2535293698310852,
      "learning_rate": 2.2783513951702367e-06,
      "loss": 0.0014,
      "step": 111850
    },
    {
      "epoch": 9.54518303609523,
      "grad_norm": 0.10123036056756973,
      "learning_rate": 2.27408481952385e-06,
      "loss": 0.0017,
      "step": 111860
    },
    {
      "epoch": 9.546036351224508,
      "grad_norm": 0.11517872661352158,
      "learning_rate": 2.269818243877464e-06,
      "loss": 0.0012,
      "step": 111870
    },
    {
      "epoch": 9.546889666353785,
      "grad_norm": 0.11078058928251266,
      "learning_rate": 2.2655516682310778e-06,
      "loss": 0.0014,
      "step": 111880
    },
    {
      "epoch": 9.547742981483061,
      "grad_norm": 0.27198636531829834,
      "learning_rate": 2.261285092584692e-06,
      "loss": 0.0017,
      "step": 111890
    },
    {
      "epoch": 9.548596296612338,
      "grad_norm": 0.1312551349401474,
      "learning_rate": 2.2570185169383054e-06,
      "loss": 0.002,
      "step": 111900
    },
    {
      "epoch": 9.549449611741617,
      "grad_norm": 0.0619015209376812,
      "learning_rate": 2.252751941291919e-06,
      "loss": 0.0016,
      "step": 111910
    },
    {
      "epoch": 9.550302926870893,
      "grad_norm": 0.16298487782478333,
      "learning_rate": 2.248485365645533e-06,
      "loss": 0.0013,
      "step": 111920
    },
    {
      "epoch": 9.55115624200017,
      "grad_norm": 0.03716729208827019,
      "learning_rate": 2.244218789999147e-06,
      "loss": 0.0014,
      "step": 111930
    },
    {
      "epoch": 9.552009557129448,
      "grad_norm": 0.18206733465194702,
      "learning_rate": 2.2399522143527607e-06,
      "loss": 0.0014,
      "step": 111940
    },
    {
      "epoch": 9.552862872258725,
      "grad_norm": 0.21895749866962433,
      "learning_rate": 2.2356856387063745e-06,
      "loss": 0.0012,
      "step": 111950
    },
    {
      "epoch": 9.553716187388002,
      "grad_norm": 0.09146437048912048,
      "learning_rate": 2.231419063059988e-06,
      "loss": 0.0014,
      "step": 111960
    },
    {
      "epoch": 9.55456950251728,
      "grad_norm": 0.2426404356956482,
      "learning_rate": 2.2271524874136017e-06,
      "loss": 0.0016,
      "step": 111970
    },
    {
      "epoch": 9.555422817646557,
      "grad_norm": 0.16591370105743408,
      "learning_rate": 2.222885911767216e-06,
      "loss": 0.0013,
      "step": 111980
    },
    {
      "epoch": 9.556276132775833,
      "grad_norm": 0.1508914977312088,
      "learning_rate": 2.2186193361208297e-06,
      "loss": 0.0012,
      "step": 111990
    },
    {
      "epoch": 9.557129447905112,
      "grad_norm": 0.23860955238342285,
      "learning_rate": 2.214352760474443e-06,
      "loss": 0.0018,
      "step": 112000
    },
    {
      "epoch": 9.557982763034389,
      "grad_norm": 0.0779566615819931,
      "learning_rate": 2.210086184828057e-06,
      "loss": 0.0014,
      "step": 112010
    },
    {
      "epoch": 9.558836078163665,
      "grad_norm": 0.15844444930553436,
      "learning_rate": 2.205819609181671e-06,
      "loss": 0.0014,
      "step": 112020
    },
    {
      "epoch": 9.559689393292944,
      "grad_norm": 0.11153833568096161,
      "learning_rate": 2.2015530335352846e-06,
      "loss": 0.002,
      "step": 112030
    },
    {
      "epoch": 9.56054270842222,
      "grad_norm": 0.0374021902680397,
      "learning_rate": 2.1972864578888984e-06,
      "loss": 0.0018,
      "step": 112040
    },
    {
      "epoch": 9.561396023551497,
      "grad_norm": 0.1153019443154335,
      "learning_rate": 2.1930198822425122e-06,
      "loss": 0.0018,
      "step": 112050
    },
    {
      "epoch": 9.562249338680775,
      "grad_norm": 0.13203662633895874,
      "learning_rate": 2.188753306596126e-06,
      "loss": 0.0019,
      "step": 112060
    },
    {
      "epoch": 9.563102653810052,
      "grad_norm": 0.057914186269044876,
      "learning_rate": 2.18448673094974e-06,
      "loss": 0.0017,
      "step": 112070
    },
    {
      "epoch": 9.563955968939329,
      "grad_norm": 0.03256930783390999,
      "learning_rate": 2.1802201553033537e-06,
      "loss": 0.0015,
      "step": 112080
    },
    {
      "epoch": 9.564809284068607,
      "grad_norm": 0.10974439233541489,
      "learning_rate": 2.1759535796569675e-06,
      "loss": 0.0018,
      "step": 112090
    },
    {
      "epoch": 9.565662599197884,
      "grad_norm": 0.38100579380989075,
      "learning_rate": 2.1716870040105813e-06,
      "loss": 0.0016,
      "step": 112100
    },
    {
      "epoch": 9.56651591432716,
      "grad_norm": 0.2533761262893677,
      "learning_rate": 2.167420428364195e-06,
      "loss": 0.0014,
      "step": 112110
    },
    {
      "epoch": 9.567369229456439,
      "grad_norm": 0.22053349018096924,
      "learning_rate": 2.163153852717809e-06,
      "loss": 0.0014,
      "step": 112120
    },
    {
      "epoch": 9.568222544585716,
      "grad_norm": 0.06287455558776855,
      "learning_rate": 2.1588872770714223e-06,
      "loss": 0.0014,
      "step": 112130
    },
    {
      "epoch": 9.569075859714992,
      "grad_norm": 0.1634422242641449,
      "learning_rate": 2.154620701425036e-06,
      "loss": 0.002,
      "step": 112140
    },
    {
      "epoch": 9.56992917484427,
      "grad_norm": 0.08087018877267838,
      "learning_rate": 2.1503541257786504e-06,
      "loss": 0.0015,
      "step": 112150
    },
    {
      "epoch": 9.570782489973547,
      "grad_norm": 0.037104833871126175,
      "learning_rate": 2.146087550132264e-06,
      "loss": 0.0011,
      "step": 112160
    },
    {
      "epoch": 9.571635805102824,
      "grad_norm": 0.029986824840307236,
      "learning_rate": 2.1418209744858776e-06,
      "loss": 0.0014,
      "step": 112170
    },
    {
      "epoch": 9.572489120232103,
      "grad_norm": 0.21902431547641754,
      "learning_rate": 2.1375543988394914e-06,
      "loss": 0.0012,
      "step": 112180
    },
    {
      "epoch": 9.57334243536138,
      "grad_norm": 0.07460048794746399,
      "learning_rate": 2.1332878231931057e-06,
      "loss": 0.002,
      "step": 112190
    },
    {
      "epoch": 9.574195750490656,
      "grad_norm": 0.1403294950723648,
      "learning_rate": 2.129021247546719e-06,
      "loss": 0.0019,
      "step": 112200
    },
    {
      "epoch": 9.575049065619933,
      "grad_norm": 0.23544082045555115,
      "learning_rate": 2.124754671900333e-06,
      "loss": 0.0014,
      "step": 112210
    },
    {
      "epoch": 9.575902380749211,
      "grad_norm": 0.0820949375629425,
      "learning_rate": 2.1204880962539467e-06,
      "loss": 0.0013,
      "step": 112220
    },
    {
      "epoch": 9.576755695878488,
      "grad_norm": 0.16402876377105713,
      "learning_rate": 2.1162215206075605e-06,
      "loss": 0.0017,
      "step": 112230
    },
    {
      "epoch": 9.577609011007766,
      "grad_norm": 0.25252461433410645,
      "learning_rate": 2.1119549449611743e-06,
      "loss": 0.0017,
      "step": 112240
    },
    {
      "epoch": 9.578462326137043,
      "grad_norm": 0.03456895425915718,
      "learning_rate": 2.107688369314788e-06,
      "loss": 0.0015,
      "step": 112250
    },
    {
      "epoch": 9.57931564126632,
      "grad_norm": 0.14981989562511444,
      "learning_rate": 2.1034217936684016e-06,
      "loss": 0.0018,
      "step": 112260
    },
    {
      "epoch": 9.580168956395596,
      "grad_norm": 0.05181416869163513,
      "learning_rate": 2.099155218022016e-06,
      "loss": 0.0014,
      "step": 112270
    },
    {
      "epoch": 9.581022271524875,
      "grad_norm": 0.18314816057682037,
      "learning_rate": 2.0948886423756296e-06,
      "loss": 0.0015,
      "step": 112280
    },
    {
      "epoch": 9.581875586654151,
      "grad_norm": 0.28665509819984436,
      "learning_rate": 2.0906220667292434e-06,
      "loss": 0.0019,
      "step": 112290
    },
    {
      "epoch": 9.582728901783428,
      "grad_norm": 0.08018594235181808,
      "learning_rate": 2.086355491082857e-06,
      "loss": 0.0018,
      "step": 112300
    },
    {
      "epoch": 9.583582216912706,
      "grad_norm": 0.06888200342655182,
      "learning_rate": 2.0820889154364706e-06,
      "loss": 0.0013,
      "step": 112310
    },
    {
      "epoch": 9.584435532041983,
      "grad_norm": 0.034858547151088715,
      "learning_rate": 2.077822339790085e-06,
      "loss": 0.0015,
      "step": 112320
    },
    {
      "epoch": 9.58528884717126,
      "grad_norm": 0.06462593376636505,
      "learning_rate": 2.0735557641436983e-06,
      "loss": 0.0015,
      "step": 112330
    },
    {
      "epoch": 9.586142162300538,
      "grad_norm": 0.08362846821546555,
      "learning_rate": 2.069289188497312e-06,
      "loss": 0.0014,
      "step": 112340
    },
    {
      "epoch": 9.586995477429815,
      "grad_norm": 0.146450012922287,
      "learning_rate": 2.065022612850926e-06,
      "loss": 0.0019,
      "step": 112350
    },
    {
      "epoch": 9.587848792559091,
      "grad_norm": 0.1676183044910431,
      "learning_rate": 2.0607560372045397e-06,
      "loss": 0.0011,
      "step": 112360
    },
    {
      "epoch": 9.58870210768837,
      "grad_norm": 0.16395126283168793,
      "learning_rate": 2.0564894615581535e-06,
      "loss": 0.0021,
      "step": 112370
    },
    {
      "epoch": 9.589555422817647,
      "grad_norm": 0.23662789165973663,
      "learning_rate": 2.0522228859117674e-06,
      "loss": 0.0015,
      "step": 112380
    },
    {
      "epoch": 9.590408737946923,
      "grad_norm": 0.18077167868614197,
      "learning_rate": 2.047956310265381e-06,
      "loss": 0.0016,
      "step": 112390
    },
    {
      "epoch": 9.591262053076202,
      "grad_norm": 0.07371632009744644,
      "learning_rate": 2.043689734618995e-06,
      "loss": 0.0014,
      "step": 112400
    },
    {
      "epoch": 9.592115368205478,
      "grad_norm": 0.03299348056316376,
      "learning_rate": 2.039423158972609e-06,
      "loss": 0.0018,
      "step": 112410
    },
    {
      "epoch": 9.592968683334755,
      "grad_norm": 0.3518320918083191,
      "learning_rate": 2.0351565833262226e-06,
      "loss": 0.0023,
      "step": 112420
    },
    {
      "epoch": 9.593821998464033,
      "grad_norm": 0.2612358629703522,
      "learning_rate": 2.030890007679836e-06,
      "loss": 0.0015,
      "step": 112430
    },
    {
      "epoch": 9.59467531359331,
      "grad_norm": 0.0402815043926239,
      "learning_rate": 2.02662343203345e-06,
      "loss": 0.0018,
      "step": 112440
    },
    {
      "epoch": 9.595528628722587,
      "grad_norm": 0.09537184983491898,
      "learning_rate": 2.022356856387064e-06,
      "loss": 0.0019,
      "step": 112450
    },
    {
      "epoch": 9.596381943851865,
      "grad_norm": 0.16371668875217438,
      "learning_rate": 2.0180902807406775e-06,
      "loss": 0.0019,
      "step": 112460
    },
    {
      "epoch": 9.597235258981142,
      "grad_norm": 0.035128381103277206,
      "learning_rate": 2.0138237050942913e-06,
      "loss": 0.0015,
      "step": 112470
    },
    {
      "epoch": 9.598088574110418,
      "grad_norm": 0.12772463262081146,
      "learning_rate": 2.009557129447905e-06,
      "loss": 0.0014,
      "step": 112480
    },
    {
      "epoch": 9.598941889239697,
      "grad_norm": 0.12789852917194366,
      "learning_rate": 2.005290553801519e-06,
      "loss": 0.0012,
      "step": 112490
    },
    {
      "epoch": 9.599795204368974,
      "grad_norm": 0.14677050709724426,
      "learning_rate": 2.0010239781551327e-06,
      "loss": 0.0014,
      "step": 112500
    },
    {
      "epoch": 9.60064851949825,
      "grad_norm": 0.0767177864909172,
      "learning_rate": 1.9967574025087466e-06,
      "loss": 0.0019,
      "step": 112510
    },
    {
      "epoch": 9.601501834627529,
      "grad_norm": 0.3969261646270752,
      "learning_rate": 1.9924908268623604e-06,
      "loss": 0.0017,
      "step": 112520
    },
    {
      "epoch": 9.602355149756805,
      "grad_norm": 0.21901419758796692,
      "learning_rate": 1.988224251215974e-06,
      "loss": 0.0014,
      "step": 112530
    },
    {
      "epoch": 9.603208464886082,
      "grad_norm": 0.1214231327176094,
      "learning_rate": 1.983957675569588e-06,
      "loss": 0.0014,
      "step": 112540
    },
    {
      "epoch": 9.60406178001536,
      "grad_norm": 0.11386546492576599,
      "learning_rate": 1.979691099923202e-06,
      "loss": 0.0018,
      "step": 112550
    },
    {
      "epoch": 9.604915095144637,
      "grad_norm": 0.19125574827194214,
      "learning_rate": 1.9754245242768152e-06,
      "loss": 0.0019,
      "step": 112560
    },
    {
      "epoch": 9.605768410273914,
      "grad_norm": 0.07691658288240433,
      "learning_rate": 1.9711579486304295e-06,
      "loss": 0.0015,
      "step": 112570
    },
    {
      "epoch": 9.60662172540319,
      "grad_norm": 0.061033256351947784,
      "learning_rate": 1.9668913729840433e-06,
      "loss": 0.0013,
      "step": 112580
    },
    {
      "epoch": 9.607475040532469,
      "grad_norm": 0.1659487634897232,
      "learning_rate": 1.9626247973376567e-06,
      "loss": 0.0015,
      "step": 112590
    },
    {
      "epoch": 9.608328355661746,
      "grad_norm": 0.07823870331048965,
      "learning_rate": 1.9583582216912705e-06,
      "loss": 0.0014,
      "step": 112600
    },
    {
      "epoch": 9.609181670791024,
      "grad_norm": 0.09282596409320831,
      "learning_rate": 1.9540916460448843e-06,
      "loss": 0.0015,
      "step": 112610
    },
    {
      "epoch": 9.6100349859203,
      "grad_norm": 0.07763751596212387,
      "learning_rate": 1.9498250703984986e-06,
      "loss": 0.0017,
      "step": 112620
    },
    {
      "epoch": 9.610888301049577,
      "grad_norm": 0.079714834690094,
      "learning_rate": 1.945558494752112e-06,
      "loss": 0.0016,
      "step": 112630
    },
    {
      "epoch": 9.611741616178854,
      "grad_norm": 0.08030037581920624,
      "learning_rate": 1.9412919191057258e-06,
      "loss": 0.0014,
      "step": 112640
    },
    {
      "epoch": 9.612594931308132,
      "grad_norm": 0.1494504064321518,
      "learning_rate": 1.9370253434593396e-06,
      "loss": 0.0014,
      "step": 112650
    },
    {
      "epoch": 9.61344824643741,
      "grad_norm": 0.08674123138189316,
      "learning_rate": 1.9327587678129534e-06,
      "loss": 0.0018,
      "step": 112660
    },
    {
      "epoch": 9.614301561566686,
      "grad_norm": 0.14400728046894073,
      "learning_rate": 1.9284921921665672e-06,
      "loss": 0.0016,
      "step": 112670
    },
    {
      "epoch": 9.615154876695964,
      "grad_norm": 0.1437925398349762,
      "learning_rate": 1.924225616520181e-06,
      "loss": 0.0014,
      "step": 112680
    },
    {
      "epoch": 9.616008191825241,
      "grad_norm": 0.12670256197452545,
      "learning_rate": 1.9199590408737944e-06,
      "loss": 0.0022,
      "step": 112690
    },
    {
      "epoch": 9.616861506954518,
      "grad_norm": 0.25574052333831787,
      "learning_rate": 1.9156924652274087e-06,
      "loss": 0.0016,
      "step": 112700
    },
    {
      "epoch": 9.617714822083796,
      "grad_norm": 0.11440858989953995,
      "learning_rate": 1.9114258895810225e-06,
      "loss": 0.0015,
      "step": 112710
    },
    {
      "epoch": 9.618568137213073,
      "grad_norm": 0.08518414199352264,
      "learning_rate": 1.9071593139346363e-06,
      "loss": 0.0017,
      "step": 112720
    },
    {
      "epoch": 9.61942145234235,
      "grad_norm": 0.34621402621269226,
      "learning_rate": 1.90289273828825e-06,
      "loss": 0.0016,
      "step": 112730
    },
    {
      "epoch": 9.620274767471628,
      "grad_norm": 0.07995753735303879,
      "learning_rate": 1.8986261626418637e-06,
      "loss": 0.0018,
      "step": 112740
    },
    {
      "epoch": 9.621128082600904,
      "grad_norm": 0.0635392814874649,
      "learning_rate": 1.8943595869954775e-06,
      "loss": 0.0015,
      "step": 112750
    },
    {
      "epoch": 9.621981397730181,
      "grad_norm": 0.09372323006391525,
      "learning_rate": 1.8900930113490912e-06,
      "loss": 0.0013,
      "step": 112760
    },
    {
      "epoch": 9.62283471285946,
      "grad_norm": 0.15739719569683075,
      "learning_rate": 1.8858264357027052e-06,
      "loss": 0.0014,
      "step": 112770
    },
    {
      "epoch": 9.623688027988736,
      "grad_norm": 0.30903324484825134,
      "learning_rate": 1.881559860056319e-06,
      "loss": 0.0018,
      "step": 112780
    },
    {
      "epoch": 9.624541343118013,
      "grad_norm": 0.07688836753368378,
      "learning_rate": 1.8772932844099326e-06,
      "loss": 0.0018,
      "step": 112790
    },
    {
      "epoch": 9.625394658247291,
      "grad_norm": 0.06790385395288467,
      "learning_rate": 1.8730267087635464e-06,
      "loss": 0.002,
      "step": 112800
    },
    {
      "epoch": 9.626247973376568,
      "grad_norm": 0.0814448818564415,
      "learning_rate": 1.8687601331171602e-06,
      "loss": 0.0016,
      "step": 112810
    },
    {
      "epoch": 9.627101288505845,
      "grad_norm": 0.12695588171482086,
      "learning_rate": 1.8644935574707743e-06,
      "loss": 0.0019,
      "step": 112820
    },
    {
      "epoch": 9.627954603635123,
      "grad_norm": 0.09741266071796417,
      "learning_rate": 1.8602269818243877e-06,
      "loss": 0.0016,
      "step": 112830
    },
    {
      "epoch": 9.6288079187644,
      "grad_norm": 0.08105505257844925,
      "learning_rate": 1.8559604061780017e-06,
      "loss": 0.0019,
      "step": 112840
    },
    {
      "epoch": 9.629661233893676,
      "grad_norm": 0.12291891872882843,
      "learning_rate": 1.8516938305316155e-06,
      "loss": 0.0013,
      "step": 112850
    },
    {
      "epoch": 9.630514549022955,
      "grad_norm": 0.05075569823384285,
      "learning_rate": 1.8474272548852291e-06,
      "loss": 0.0017,
      "step": 112860
    },
    {
      "epoch": 9.631367864152232,
      "grad_norm": 0.25643008947372437,
      "learning_rate": 1.843160679238843e-06,
      "loss": 0.0013,
      "step": 112870
    },
    {
      "epoch": 9.632221179281508,
      "grad_norm": 0.3801548480987549,
      "learning_rate": 1.838894103592457e-06,
      "loss": 0.0016,
      "step": 112880
    },
    {
      "epoch": 9.633074494410787,
      "grad_norm": 0.2181439846754074,
      "learning_rate": 1.8346275279460704e-06,
      "loss": 0.0017,
      "step": 112890
    },
    {
      "epoch": 9.633927809540063,
      "grad_norm": 0.30451449751853943,
      "learning_rate": 1.8303609522996844e-06,
      "loss": 0.0016,
      "step": 112900
    },
    {
      "epoch": 9.63478112466934,
      "grad_norm": 0.04426728934049606,
      "learning_rate": 1.8260943766532982e-06,
      "loss": 0.0011,
      "step": 112910
    },
    {
      "epoch": 9.635634439798618,
      "grad_norm": 0.21798944473266602,
      "learning_rate": 1.821827801006912e-06,
      "loss": 0.0019,
      "step": 112920
    },
    {
      "epoch": 9.636487754927895,
      "grad_norm": 0.09593759477138519,
      "learning_rate": 1.8175612253605256e-06,
      "loss": 0.0013,
      "step": 112930
    },
    {
      "epoch": 9.637341070057172,
      "grad_norm": 0.16490264236927032,
      "learning_rate": 1.8132946497141394e-06,
      "loss": 0.0016,
      "step": 112940
    },
    {
      "epoch": 9.638194385186448,
      "grad_norm": 0.2645737826824188,
      "learning_rate": 1.8090280740677535e-06,
      "loss": 0.0017,
      "step": 112950
    },
    {
      "epoch": 9.639047700315727,
      "grad_norm": 0.03746359422802925,
      "learning_rate": 1.804761498421367e-06,
      "loss": 0.0017,
      "step": 112960
    },
    {
      "epoch": 9.639901015445004,
      "grad_norm": 0.1121710017323494,
      "learning_rate": 1.800494922774981e-06,
      "loss": 0.0016,
      "step": 112970
    },
    {
      "epoch": 9.640754330574282,
      "grad_norm": 0.28965896368026733,
      "learning_rate": 1.7962283471285947e-06,
      "loss": 0.0015,
      "step": 112980
    },
    {
      "epoch": 9.641607645703559,
      "grad_norm": 0.23409652709960938,
      "learning_rate": 1.7919617714822083e-06,
      "loss": 0.0012,
      "step": 112990
    },
    {
      "epoch": 9.642460960832835,
      "grad_norm": 0.11349897086620331,
      "learning_rate": 1.7876951958358221e-06,
      "loss": 0.002,
      "step": 113000
    },
    {
      "epoch": 9.643314275962112,
      "grad_norm": 0.05131225287914276,
      "learning_rate": 1.7834286201894362e-06,
      "loss": 0.0015,
      "step": 113010
    },
    {
      "epoch": 9.64416759109139,
      "grad_norm": 0.23773619532585144,
      "learning_rate": 1.77916204454305e-06,
      "loss": 0.0018,
      "step": 113020
    },
    {
      "epoch": 9.645020906220667,
      "grad_norm": 0.14707231521606445,
      "learning_rate": 1.7748954688966636e-06,
      "loss": 0.0016,
      "step": 113030
    },
    {
      "epoch": 9.645874221349944,
      "grad_norm": 0.07257886230945587,
      "learning_rate": 1.7706288932502774e-06,
      "loss": 0.0017,
      "step": 113040
    },
    {
      "epoch": 9.646727536479222,
      "grad_norm": 0.21791063249111176,
      "learning_rate": 1.7663623176038912e-06,
      "loss": 0.0022,
      "step": 113050
    },
    {
      "epoch": 9.647580851608499,
      "grad_norm": 0.21903575956821442,
      "learning_rate": 1.7620957419575048e-06,
      "loss": 0.0015,
      "step": 113060
    },
    {
      "epoch": 9.648434166737776,
      "grad_norm": 0.1279233992099762,
      "learning_rate": 1.7578291663111189e-06,
      "loss": 0.0017,
      "step": 113070
    },
    {
      "epoch": 9.649287481867054,
      "grad_norm": 0.09501327574253082,
      "learning_rate": 1.7535625906647327e-06,
      "loss": 0.0017,
      "step": 113080
    },
    {
      "epoch": 9.65014079699633,
      "grad_norm": 0.039078522473573685,
      "learning_rate": 1.7492960150183463e-06,
      "loss": 0.0014,
      "step": 113090
    },
    {
      "epoch": 9.650994112125607,
      "grad_norm": 0.08811831474304199,
      "learning_rate": 1.74502943937196e-06,
      "loss": 0.0015,
      "step": 113100
    },
    {
      "epoch": 9.651847427254886,
      "grad_norm": 0.05548544228076935,
      "learning_rate": 1.740762863725574e-06,
      "loss": 0.0015,
      "step": 113110
    },
    {
      "epoch": 9.652700742384162,
      "grad_norm": 0.19886992871761322,
      "learning_rate": 1.736496288079188e-06,
      "loss": 0.0014,
      "step": 113120
    },
    {
      "epoch": 9.653554057513439,
      "grad_norm": 0.05483268201351166,
      "learning_rate": 1.7322297124328013e-06,
      "loss": 0.0015,
      "step": 113130
    },
    {
      "epoch": 9.654407372642718,
      "grad_norm": 0.1878848820924759,
      "learning_rate": 1.7279631367864154e-06,
      "loss": 0.0021,
      "step": 113140
    },
    {
      "epoch": 9.655260687771994,
      "grad_norm": 0.2724032998085022,
      "learning_rate": 1.7236965611400292e-06,
      "loss": 0.0018,
      "step": 113150
    },
    {
      "epoch": 9.65611400290127,
      "grad_norm": 0.04028209298849106,
      "learning_rate": 1.7194299854936428e-06,
      "loss": 0.0017,
      "step": 113160
    },
    {
      "epoch": 9.65696731803055,
      "grad_norm": 0.09264524281024933,
      "learning_rate": 1.7151634098472566e-06,
      "loss": 0.0014,
      "step": 113170
    },
    {
      "epoch": 9.657820633159826,
      "grad_norm": 0.036758337169885635,
      "learning_rate": 1.7108968342008706e-06,
      "loss": 0.0015,
      "step": 113180
    },
    {
      "epoch": 9.658673948289103,
      "grad_norm": 0.11191122233867645,
      "learning_rate": 1.706630258554484e-06,
      "loss": 0.0015,
      "step": 113190
    },
    {
      "epoch": 9.659527263418381,
      "grad_norm": 0.16474860906600952,
      "learning_rate": 1.702363682908098e-06,
      "loss": 0.0019,
      "step": 113200
    },
    {
      "epoch": 9.660380578547658,
      "grad_norm": 0.059129755944013596,
      "learning_rate": 1.6980971072617119e-06,
      "loss": 0.0016,
      "step": 113210
    },
    {
      "epoch": 9.661233893676934,
      "grad_norm": 0.11516077071428299,
      "learning_rate": 1.6938305316153257e-06,
      "loss": 0.0021,
      "step": 113220
    },
    {
      "epoch": 9.662087208806213,
      "grad_norm": 0.08004358410835266,
      "learning_rate": 1.6895639559689393e-06,
      "loss": 0.0013,
      "step": 113230
    },
    {
      "epoch": 9.66294052393549,
      "grad_norm": 0.183538019657135,
      "learning_rate": 1.6852973803225533e-06,
      "loss": 0.0015,
      "step": 113240
    },
    {
      "epoch": 9.663793839064766,
      "grad_norm": 0.09280797094106674,
      "learning_rate": 1.6810308046761671e-06,
      "loss": 0.0017,
      "step": 113250
    },
    {
      "epoch": 9.664647154194045,
      "grad_norm": 0.11791011691093445,
      "learning_rate": 1.6767642290297808e-06,
      "loss": 0.0016,
      "step": 113260
    },
    {
      "epoch": 9.665500469323321,
      "grad_norm": 0.04224339872598648,
      "learning_rate": 1.6724976533833946e-06,
      "loss": 0.0018,
      "step": 113270
    },
    {
      "epoch": 9.666353784452598,
      "grad_norm": 0.14600180089473724,
      "learning_rate": 1.6682310777370084e-06,
      "loss": 0.0013,
      "step": 113280
    },
    {
      "epoch": 9.667207099581876,
      "grad_norm": 0.09320083260536194,
      "learning_rate": 1.663964502090622e-06,
      "loss": 0.0014,
      "step": 113290
    },
    {
      "epoch": 9.668060414711153,
      "grad_norm": 0.09128711372613907,
      "learning_rate": 1.6596979264442358e-06,
      "loss": 0.0024,
      "step": 113300
    },
    {
      "epoch": 9.66891372984043,
      "grad_norm": 0.21921440958976746,
      "learning_rate": 1.6554313507978498e-06,
      "loss": 0.0015,
      "step": 113310
    },
    {
      "epoch": 9.669767044969706,
      "grad_norm": 0.16692772507667542,
      "learning_rate": 1.6511647751514637e-06,
      "loss": 0.0017,
      "step": 113320
    },
    {
      "epoch": 9.670620360098985,
      "grad_norm": 0.051869891583919525,
      "learning_rate": 1.6468981995050773e-06,
      "loss": 0.0013,
      "step": 113330
    },
    {
      "epoch": 9.671473675228262,
      "grad_norm": 0.09523006528615952,
      "learning_rate": 1.642631623858691e-06,
      "loss": 0.0015,
      "step": 113340
    },
    {
      "epoch": 9.67232699035754,
      "grad_norm": 0.033703919500112534,
      "learning_rate": 1.6383650482123051e-06,
      "loss": 0.0017,
      "step": 113350
    },
    {
      "epoch": 9.673180305486817,
      "grad_norm": 0.09412354230880737,
      "learning_rate": 1.6340984725659185e-06,
      "loss": 0.0017,
      "step": 113360
    },
    {
      "epoch": 9.674033620616093,
      "grad_norm": 0.1581811010837555,
      "learning_rate": 1.6298318969195325e-06,
      "loss": 0.0016,
      "step": 113370
    },
    {
      "epoch": 9.67488693574537,
      "grad_norm": 0.1272236555814743,
      "learning_rate": 1.6255653212731464e-06,
      "loss": 0.0016,
      "step": 113380
    },
    {
      "epoch": 9.675740250874648,
      "grad_norm": 0.18228831887245178,
      "learning_rate": 1.62129874562676e-06,
      "loss": 0.0017,
      "step": 113390
    },
    {
      "epoch": 9.676593566003925,
      "grad_norm": 0.11503162235021591,
      "learning_rate": 1.6170321699803738e-06,
      "loss": 0.0018,
      "step": 113400
    },
    {
      "epoch": 9.677446881133202,
      "grad_norm": 0.16795094311237335,
      "learning_rate": 1.6127655943339876e-06,
      "loss": 0.0016,
      "step": 113410
    },
    {
      "epoch": 9.67830019626248,
      "grad_norm": 0.41692423820495605,
      "learning_rate": 1.6084990186876012e-06,
      "loss": 0.0014,
      "step": 113420
    },
    {
      "epoch": 9.679153511391757,
      "grad_norm": 0.15697109699249268,
      "learning_rate": 1.6042324430412152e-06,
      "loss": 0.002,
      "step": 113430
    },
    {
      "epoch": 9.680006826521034,
      "grad_norm": 0.1469263881444931,
      "learning_rate": 1.599965867394829e-06,
      "loss": 0.0014,
      "step": 113440
    },
    {
      "epoch": 9.680860141650312,
      "grad_norm": 0.1366756707429886,
      "learning_rate": 1.5956992917484429e-06,
      "loss": 0.0017,
      "step": 113450
    },
    {
      "epoch": 9.681713456779589,
      "grad_norm": 0.23938004672527313,
      "learning_rate": 1.5914327161020565e-06,
      "loss": 0.0017,
      "step": 113460
    },
    {
      "epoch": 9.682566771908865,
      "grad_norm": 0.07995100319385529,
      "learning_rate": 1.5871661404556703e-06,
      "loss": 0.0015,
      "step": 113470
    },
    {
      "epoch": 9.683420087038144,
      "grad_norm": 0.05452079698443413,
      "learning_rate": 1.5828995648092843e-06,
      "loss": 0.0015,
      "step": 113480
    },
    {
      "epoch": 9.68427340216742,
      "grad_norm": 0.12445086240768433,
      "learning_rate": 1.5786329891628977e-06,
      "loss": 0.0016,
      "step": 113490
    },
    {
      "epoch": 9.685126717296697,
      "grad_norm": 0.14823272824287415,
      "learning_rate": 1.5743664135165117e-06,
      "loss": 0.0016,
      "step": 113500
    },
    {
      "epoch": 9.685980032425975,
      "grad_norm": 0.0977339893579483,
      "learning_rate": 1.5700998378701256e-06,
      "loss": 0.0013,
      "step": 113510
    },
    {
      "epoch": 9.686833347555252,
      "grad_norm": 0.18679171800613403,
      "learning_rate": 1.5658332622237392e-06,
      "loss": 0.0016,
      "step": 113520
    },
    {
      "epoch": 9.687686662684529,
      "grad_norm": 0.18083402514457703,
      "learning_rate": 1.561566686577353e-06,
      "loss": 0.0018,
      "step": 113530
    },
    {
      "epoch": 9.688539977813807,
      "grad_norm": 0.24547623097896576,
      "learning_rate": 1.557300110930967e-06,
      "loss": 0.0015,
      "step": 113540
    },
    {
      "epoch": 9.689393292943084,
      "grad_norm": 0.09239566326141357,
      "learning_rate": 1.5530335352845806e-06,
      "loss": 0.0014,
      "step": 113550
    },
    {
      "epoch": 9.69024660807236,
      "grad_norm": 0.4401398003101349,
      "learning_rate": 1.5487669596381944e-06,
      "loss": 0.0017,
      "step": 113560
    },
    {
      "epoch": 9.691099923201639,
      "grad_norm": 0.09849133342504501,
      "learning_rate": 1.5445003839918082e-06,
      "loss": 0.0013,
      "step": 113570
    },
    {
      "epoch": 9.691953238330916,
      "grad_norm": 0.16848434507846832,
      "learning_rate": 1.540233808345422e-06,
      "loss": 0.0024,
      "step": 113580
    },
    {
      "epoch": 9.692806553460192,
      "grad_norm": 0.060805369168519974,
      "learning_rate": 1.5359672326990359e-06,
      "loss": 0.0016,
      "step": 113590
    },
    {
      "epoch": 9.69365986858947,
      "grad_norm": 0.11863754689693451,
      "learning_rate": 1.5317006570526495e-06,
      "loss": 0.0022,
      "step": 113600
    },
    {
      "epoch": 9.694513183718747,
      "grad_norm": 0.09783874452114105,
      "learning_rate": 1.5274340814062635e-06,
      "loss": 0.0017,
      "step": 113610
    },
    {
      "epoch": 9.695366498848024,
      "grad_norm": 0.12067975848913193,
      "learning_rate": 1.5231675057598771e-06,
      "loss": 0.0016,
      "step": 113620
    },
    {
      "epoch": 9.696219813977303,
      "grad_norm": 0.18026317656040192,
      "learning_rate": 1.518900930113491e-06,
      "loss": 0.0015,
      "step": 113630
    },
    {
      "epoch": 9.69707312910658,
      "grad_norm": 0.23500880599021912,
      "learning_rate": 1.5146343544671048e-06,
      "loss": 0.0016,
      "step": 113640
    },
    {
      "epoch": 9.697926444235856,
      "grad_norm": 0.11378467082977295,
      "learning_rate": 1.5103677788207186e-06,
      "loss": 0.0017,
      "step": 113650
    },
    {
      "epoch": 9.698779759365134,
      "grad_norm": 0.2693587839603424,
      "learning_rate": 1.5061012031743324e-06,
      "loss": 0.0015,
      "step": 113660
    },
    {
      "epoch": 9.699633074494411,
      "grad_norm": 0.19699522852897644,
      "learning_rate": 1.5018346275279462e-06,
      "loss": 0.0014,
      "step": 113670
    },
    {
      "epoch": 9.700486389623688,
      "grad_norm": 0.18301881849765778,
      "learning_rate": 1.4975680518815598e-06,
      "loss": 0.0018,
      "step": 113680
    },
    {
      "epoch": 9.701339704752964,
      "grad_norm": 0.2731981873512268,
      "learning_rate": 1.4933014762351738e-06,
      "loss": 0.0018,
      "step": 113690
    },
    {
      "epoch": 9.702193019882243,
      "grad_norm": 0.27300405502319336,
      "learning_rate": 1.4890349005887875e-06,
      "loss": 0.0019,
      "step": 113700
    },
    {
      "epoch": 9.70304633501152,
      "grad_norm": 0.21801291406154633,
      "learning_rate": 1.4847683249424015e-06,
      "loss": 0.0014,
      "step": 113710
    },
    {
      "epoch": 9.703899650140798,
      "grad_norm": 0.08009827136993408,
      "learning_rate": 1.480501749296015e-06,
      "loss": 0.0011,
      "step": 113720
    },
    {
      "epoch": 9.704752965270075,
      "grad_norm": 0.1073228046298027,
      "learning_rate": 1.476235173649629e-06,
      "loss": 0.0013,
      "step": 113730
    },
    {
      "epoch": 9.705606280399351,
      "grad_norm": 0.1508914679288864,
      "learning_rate": 1.4719685980032427e-06,
      "loss": 0.0019,
      "step": 113740
    },
    {
      "epoch": 9.706459595528628,
      "grad_norm": 0.034806977957487106,
      "learning_rate": 1.4677020223568565e-06,
      "loss": 0.0015,
      "step": 113750
    },
    {
      "epoch": 9.707312910657906,
      "grad_norm": 0.0350249782204628,
      "learning_rate": 1.4634354467104704e-06,
      "loss": 0.0021,
      "step": 113760
    },
    {
      "epoch": 9.708166225787183,
      "grad_norm": 0.19830110669136047,
      "learning_rate": 1.459168871064084e-06,
      "loss": 0.0016,
      "step": 113770
    },
    {
      "epoch": 9.70901954091646,
      "grad_norm": 0.0616779625415802,
      "learning_rate": 1.4549022954176978e-06,
      "loss": 0.0016,
      "step": 113780
    },
    {
      "epoch": 9.709872856045738,
      "grad_norm": 0.1294415444135666,
      "learning_rate": 1.4506357197713116e-06,
      "loss": 0.0016,
      "step": 113790
    },
    {
      "epoch": 9.710726171175015,
      "grad_norm": 0.043038271367549896,
      "learning_rate": 1.4463691441249254e-06,
      "loss": 0.0015,
      "step": 113800
    },
    {
      "epoch": 9.711579486304291,
      "grad_norm": 0.2398136407136917,
      "learning_rate": 1.4421025684785392e-06,
      "loss": 0.0016,
      "step": 113810
    },
    {
      "epoch": 9.71243280143357,
      "grad_norm": 0.09605682641267776,
      "learning_rate": 1.437835992832153e-06,
      "loss": 0.0016,
      "step": 113820
    },
    {
      "epoch": 9.713286116562847,
      "grad_norm": 0.14333775639533997,
      "learning_rate": 1.4335694171857667e-06,
      "loss": 0.0017,
      "step": 113830
    },
    {
      "epoch": 9.714139431692123,
      "grad_norm": 0.11179999262094498,
      "learning_rate": 1.4293028415393807e-06,
      "loss": 0.0013,
      "step": 113840
    },
    {
      "epoch": 9.714992746821402,
      "grad_norm": 0.05002232640981674,
      "learning_rate": 1.4250362658929943e-06,
      "loss": 0.0016,
      "step": 113850
    },
    {
      "epoch": 9.715846061950678,
      "grad_norm": 0.397004097700119,
      "learning_rate": 1.4207696902466081e-06,
      "loss": 0.0016,
      "step": 113860
    },
    {
      "epoch": 9.716699377079955,
      "grad_norm": 0.04464687407016754,
      "learning_rate": 1.416503114600222e-06,
      "loss": 0.0016,
      "step": 113870
    },
    {
      "epoch": 9.717552692209233,
      "grad_norm": 0.07832010835409164,
      "learning_rate": 1.4122365389538357e-06,
      "loss": 0.0016,
      "step": 113880
    },
    {
      "epoch": 9.71840600733851,
      "grad_norm": 0.09890951216220856,
      "learning_rate": 1.4079699633074496e-06,
      "loss": 0.0014,
      "step": 113890
    },
    {
      "epoch": 9.719259322467787,
      "grad_norm": 0.21976743638515472,
      "learning_rate": 1.4037033876610634e-06,
      "loss": 0.0019,
      "step": 113900
    },
    {
      "epoch": 9.720112637597065,
      "grad_norm": 0.04443623870611191,
      "learning_rate": 1.399436812014677e-06,
      "loss": 0.0015,
      "step": 113910
    },
    {
      "epoch": 9.720965952726342,
      "grad_norm": 0.05115458741784096,
      "learning_rate": 1.3951702363682908e-06,
      "loss": 0.0013,
      "step": 113920
    },
    {
      "epoch": 9.721819267855619,
      "grad_norm": 0.1112876832485199,
      "learning_rate": 1.3909036607219046e-06,
      "loss": 0.0013,
      "step": 113930
    },
    {
      "epoch": 9.722672582984897,
      "grad_norm": 0.20310772955417633,
      "learning_rate": 1.3866370850755184e-06,
      "loss": 0.0021,
      "step": 113940
    },
    {
      "epoch": 9.723525898114174,
      "grad_norm": 0.15446875989437103,
      "learning_rate": 1.3823705094291323e-06,
      "loss": 0.0016,
      "step": 113950
    },
    {
      "epoch": 9.72437921324345,
      "grad_norm": 0.14389154314994812,
      "learning_rate": 1.3781039337827459e-06,
      "loss": 0.0013,
      "step": 113960
    },
    {
      "epoch": 9.725232528372729,
      "grad_norm": 0.06774789839982986,
      "learning_rate": 1.3738373581363599e-06,
      "loss": 0.0019,
      "step": 113970
    },
    {
      "epoch": 9.726085843502005,
      "grad_norm": 0.14714306592941284,
      "learning_rate": 1.3695707824899735e-06,
      "loss": 0.0014,
      "step": 113980
    },
    {
      "epoch": 9.726939158631282,
      "grad_norm": 0.03623644635081291,
      "learning_rate": 1.3653042068435875e-06,
      "loss": 0.0015,
      "step": 113990
    },
    {
      "epoch": 9.72779247376056,
      "grad_norm": 0.30724483728408813,
      "learning_rate": 1.3610376311972011e-06,
      "loss": 0.0013,
      "step": 114000
    },
    {
      "epoch": 9.728645788889837,
      "grad_norm": 0.19954729080200195,
      "learning_rate": 1.356771055550815e-06,
      "loss": 0.0016,
      "step": 114010
    },
    {
      "epoch": 9.729499104019114,
      "grad_norm": 0.13036394119262695,
      "learning_rate": 1.3525044799044288e-06,
      "loss": 0.0014,
      "step": 114020
    },
    {
      "epoch": 9.730352419148392,
      "grad_norm": 0.15086373686790466,
      "learning_rate": 1.3482379042580426e-06,
      "loss": 0.0016,
      "step": 114030
    },
    {
      "epoch": 9.731205734277669,
      "grad_norm": 0.3225526511669159,
      "learning_rate": 1.3439713286116564e-06,
      "loss": 0.0014,
      "step": 114040
    },
    {
      "epoch": 9.732059049406946,
      "grad_norm": 0.044439610093832016,
      "learning_rate": 1.3397047529652702e-06,
      "loss": 0.0015,
      "step": 114050
    },
    {
      "epoch": 9.732912364536222,
      "grad_norm": 0.15196281671524048,
      "learning_rate": 1.3354381773188838e-06,
      "loss": 0.0018,
      "step": 114060
    },
    {
      "epoch": 9.7337656796655,
      "grad_norm": 0.272030234336853,
      "learning_rate": 1.3311716016724976e-06,
      "loss": 0.0018,
      "step": 114070
    },
    {
      "epoch": 9.734618994794777,
      "grad_norm": 0.16282691061496735,
      "learning_rate": 1.3269050260261115e-06,
      "loss": 0.0015,
      "step": 114080
    },
    {
      "epoch": 9.735472309924056,
      "grad_norm": 0.05505872517824173,
      "learning_rate": 1.3226384503797253e-06,
      "loss": 0.0016,
      "step": 114090
    },
    {
      "epoch": 9.736325625053333,
      "grad_norm": 0.13061337172985077,
      "learning_rate": 1.318371874733339e-06,
      "loss": 0.0017,
      "step": 114100
    },
    {
      "epoch": 9.73717894018261,
      "grad_norm": 0.09364685416221619,
      "learning_rate": 1.3141052990869527e-06,
      "loss": 0.0014,
      "step": 114110
    },
    {
      "epoch": 9.738032255311886,
      "grad_norm": 0.21095484495162964,
      "learning_rate": 1.3098387234405667e-06,
      "loss": 0.0016,
      "step": 114120
    },
    {
      "epoch": 9.738885570441164,
      "grad_norm": 0.043585874140262604,
      "learning_rate": 1.3055721477941803e-06,
      "loss": 0.0016,
      "step": 114130
    },
    {
      "epoch": 9.739738885570441,
      "grad_norm": 0.18008747696876526,
      "learning_rate": 1.3013055721477944e-06,
      "loss": 0.0015,
      "step": 114140
    },
    {
      "epoch": 9.740592200699718,
      "grad_norm": 0.14488331973552704,
      "learning_rate": 1.297038996501408e-06,
      "loss": 0.0015,
      "step": 114150
    },
    {
      "epoch": 9.741445515828996,
      "grad_norm": 0.0554647259414196,
      "learning_rate": 1.2927724208550218e-06,
      "loss": 0.0017,
      "step": 114160
    },
    {
      "epoch": 9.742298830958273,
      "grad_norm": 0.32351651787757874,
      "learning_rate": 1.2885058452086356e-06,
      "loss": 0.0017,
      "step": 114170
    },
    {
      "epoch": 9.74315214608755,
      "grad_norm": 0.19061681628227234,
      "learning_rate": 1.2842392695622494e-06,
      "loss": 0.0018,
      "step": 114180
    },
    {
      "epoch": 9.744005461216828,
      "grad_norm": 0.14658884704113007,
      "learning_rate": 1.2799726939158632e-06,
      "loss": 0.0016,
      "step": 114190
    },
    {
      "epoch": 9.744858776346105,
      "grad_norm": 0.09898900985717773,
      "learning_rate": 1.275706118269477e-06,
      "loss": 0.0017,
      "step": 114200
    },
    {
      "epoch": 9.745712091475381,
      "grad_norm": 0.14588765799999237,
      "learning_rate": 1.2714395426230907e-06,
      "loss": 0.002,
      "step": 114210
    },
    {
      "epoch": 9.74656540660466,
      "grad_norm": 0.04962202161550522,
      "learning_rate": 1.2671729669767047e-06,
      "loss": 0.0015,
      "step": 114220
    },
    {
      "epoch": 9.747418721733936,
      "grad_norm": 0.034168798476457596,
      "learning_rate": 1.2629063913303183e-06,
      "loss": 0.0015,
      "step": 114230
    },
    {
      "epoch": 9.748272036863213,
      "grad_norm": 0.1471865028142929,
      "learning_rate": 1.2586398156839321e-06,
      "loss": 0.0016,
      "step": 114240
    },
    {
      "epoch": 9.749125351992491,
      "grad_norm": 0.1654110699892044,
      "learning_rate": 1.254373240037546e-06,
      "loss": 0.0014,
      "step": 114250
    },
    {
      "epoch": 9.749978667121768,
      "grad_norm": 0.08235525339841843,
      "learning_rate": 1.2501066643911597e-06,
      "loss": 0.0015,
      "step": 114260
    },
    {
      "epoch": 9.750831982251045,
      "grad_norm": 0.16683970391750336,
      "learning_rate": 1.2458400887447736e-06,
      "loss": 0.0016,
      "step": 114270
    },
    {
      "epoch": 9.751685297380323,
      "grad_norm": 0.0650627613067627,
      "learning_rate": 1.2415735130983872e-06,
      "loss": 0.0016,
      "step": 114280
    },
    {
      "epoch": 9.7525386125096,
      "grad_norm": 0.040168579667806625,
      "learning_rate": 1.2373069374520012e-06,
      "loss": 0.0016,
      "step": 114290
    },
    {
      "epoch": 9.753391927638877,
      "grad_norm": 0.1487579196691513,
      "learning_rate": 1.2330403618056148e-06,
      "loss": 0.0021,
      "step": 114300
    },
    {
      "epoch": 9.754245242768155,
      "grad_norm": 0.08568732440471649,
      "learning_rate": 1.2287737861592286e-06,
      "loss": 0.0018,
      "step": 114310
    },
    {
      "epoch": 9.755098557897432,
      "grad_norm": 0.4326951503753662,
      "learning_rate": 1.2245072105128424e-06,
      "loss": 0.0014,
      "step": 114320
    },
    {
      "epoch": 9.755951873026708,
      "grad_norm": 0.12808984518051147,
      "learning_rate": 1.2202406348664563e-06,
      "loss": 0.0017,
      "step": 114330
    },
    {
      "epoch": 9.756805188155987,
      "grad_norm": 0.08365495502948761,
      "learning_rate": 1.21597405922007e-06,
      "loss": 0.0015,
      "step": 114340
    },
    {
      "epoch": 9.757658503285263,
      "grad_norm": 0.2703187167644501,
      "learning_rate": 1.2117074835736839e-06,
      "loss": 0.0016,
      "step": 114350
    },
    {
      "epoch": 9.75851181841454,
      "grad_norm": 0.07875765860080719,
      "learning_rate": 1.2074409079272975e-06,
      "loss": 0.0017,
      "step": 114360
    },
    {
      "epoch": 9.759365133543819,
      "grad_norm": 0.11242947727441788,
      "learning_rate": 1.2031743322809115e-06,
      "loss": 0.0018,
      "step": 114370
    },
    {
      "epoch": 9.760218448673095,
      "grad_norm": 0.03557286784052849,
      "learning_rate": 1.1989077566345251e-06,
      "loss": 0.0014,
      "step": 114380
    },
    {
      "epoch": 9.761071763802372,
      "grad_norm": 0.1301191747188568,
      "learning_rate": 1.194641180988139e-06,
      "loss": 0.0019,
      "step": 114390
    },
    {
      "epoch": 9.76192507893165,
      "grad_norm": 0.2269940972328186,
      "learning_rate": 1.1903746053417528e-06,
      "loss": 0.0014,
      "step": 114400
    },
    {
      "epoch": 9.762778394060927,
      "grad_norm": 0.21879376471042633,
      "learning_rate": 1.1861080296953666e-06,
      "loss": 0.0016,
      "step": 114410
    },
    {
      "epoch": 9.763631709190204,
      "grad_norm": 0.0841447189450264,
      "learning_rate": 1.1818414540489804e-06,
      "loss": 0.0016,
      "step": 114420
    },
    {
      "epoch": 9.76448502431948,
      "grad_norm": 0.1789250671863556,
      "learning_rate": 1.177574878402594e-06,
      "loss": 0.002,
      "step": 114430
    },
    {
      "epoch": 9.765338339448759,
      "grad_norm": 0.12409599870443344,
      "learning_rate": 1.173308302756208e-06,
      "loss": 0.0018,
      "step": 114440
    },
    {
      "epoch": 9.766191654578035,
      "grad_norm": 0.11529090255498886,
      "learning_rate": 1.1690417271098216e-06,
      "loss": 0.0019,
      "step": 114450
    },
    {
      "epoch": 9.767044969707314,
      "grad_norm": 0.036546479910612106,
      "learning_rate": 1.1647751514634355e-06,
      "loss": 0.0017,
      "step": 114460
    },
    {
      "epoch": 9.76789828483659,
      "grad_norm": 0.24931564927101135,
      "learning_rate": 1.1605085758170493e-06,
      "loss": 0.0014,
      "step": 114470
    },
    {
      "epoch": 9.768751599965867,
      "grad_norm": 0.09512294828891754,
      "learning_rate": 1.156242000170663e-06,
      "loss": 0.0022,
      "step": 114480
    },
    {
      "epoch": 9.769604915095144,
      "grad_norm": 0.046704355627298355,
      "learning_rate": 1.151975424524277e-06,
      "loss": 0.0016,
      "step": 114490
    },
    {
      "epoch": 9.770458230224422,
      "grad_norm": 0.1151498481631279,
      "learning_rate": 1.1477088488778907e-06,
      "loss": 0.0013,
      "step": 114500
    },
    {
      "epoch": 9.771311545353699,
      "grad_norm": 0.051007065922021866,
      "learning_rate": 1.1434422732315043e-06,
      "loss": 0.0018,
      "step": 114510
    },
    {
      "epoch": 9.772164860482976,
      "grad_norm": 0.0758587196469307,
      "learning_rate": 1.1391756975851184e-06,
      "loss": 0.0018,
      "step": 114520
    },
    {
      "epoch": 9.773018175612254,
      "grad_norm": 0.18270312249660492,
      "learning_rate": 1.134909121938732e-06,
      "loss": 0.0014,
      "step": 114530
    },
    {
      "epoch": 9.77387149074153,
      "grad_norm": 0.13924866914749146,
      "learning_rate": 1.130642546292346e-06,
      "loss": 0.0019,
      "step": 114540
    },
    {
      "epoch": 9.774724805870807,
      "grad_norm": 0.16615642607212067,
      "learning_rate": 1.1263759706459596e-06,
      "loss": 0.0013,
      "step": 114550
    },
    {
      "epoch": 9.775578121000086,
      "grad_norm": 0.09530767053365707,
      "learning_rate": 1.1221093949995734e-06,
      "loss": 0.0015,
      "step": 114560
    },
    {
      "epoch": 9.776431436129362,
      "grad_norm": 0.23491469025611877,
      "learning_rate": 1.1178428193531872e-06,
      "loss": 0.0015,
      "step": 114570
    },
    {
      "epoch": 9.77728475125864,
      "grad_norm": 0.21472230553627014,
      "learning_rate": 1.1135762437068008e-06,
      "loss": 0.0015,
      "step": 114580
    },
    {
      "epoch": 9.778138066387918,
      "grad_norm": 0.03645694628357887,
      "learning_rate": 1.1093096680604149e-06,
      "loss": 0.0019,
      "step": 114590
    },
    {
      "epoch": 9.778991381517194,
      "grad_norm": 0.1486973613500595,
      "learning_rate": 1.1050430924140285e-06,
      "loss": 0.0015,
      "step": 114600
    },
    {
      "epoch": 9.779844696646471,
      "grad_norm": 0.04500063881278038,
      "learning_rate": 1.1007765167676423e-06,
      "loss": 0.0015,
      "step": 114610
    },
    {
      "epoch": 9.78069801177575,
      "grad_norm": 0.03464941307902336,
      "learning_rate": 1.0965099411212561e-06,
      "loss": 0.0013,
      "step": 114620
    },
    {
      "epoch": 9.781551326905026,
      "grad_norm": 0.10631919652223587,
      "learning_rate": 1.09224336547487e-06,
      "loss": 0.0019,
      "step": 114630
    },
    {
      "epoch": 9.782404642034303,
      "grad_norm": 0.13248811662197113,
      "learning_rate": 1.0879767898284838e-06,
      "loss": 0.0015,
      "step": 114640
    },
    {
      "epoch": 9.783257957163581,
      "grad_norm": 0.04328696429729462,
      "learning_rate": 1.0837102141820976e-06,
      "loss": 0.0015,
      "step": 114650
    },
    {
      "epoch": 9.784111272292858,
      "grad_norm": 0.16681309044361115,
      "learning_rate": 1.0794436385357112e-06,
      "loss": 0.0015,
      "step": 114660
    },
    {
      "epoch": 9.784964587422134,
      "grad_norm": 0.10002213716506958,
      "learning_rate": 1.0751770628893252e-06,
      "loss": 0.0017,
      "step": 114670
    },
    {
      "epoch": 9.785817902551413,
      "grad_norm": 0.3621748089790344,
      "learning_rate": 1.0709104872429388e-06,
      "loss": 0.0014,
      "step": 114680
    },
    {
      "epoch": 9.78667121768069,
      "grad_norm": 0.25394493341445923,
      "learning_rate": 1.0666439115965528e-06,
      "loss": 0.0019,
      "step": 114690
    },
    {
      "epoch": 9.787524532809966,
      "grad_norm": 0.3586985468864441,
      "learning_rate": 1.0623773359501664e-06,
      "loss": 0.0017,
      "step": 114700
    },
    {
      "epoch": 9.788377847939245,
      "grad_norm": 0.12081487476825714,
      "learning_rate": 1.0581107603037803e-06,
      "loss": 0.0015,
      "step": 114710
    },
    {
      "epoch": 9.789231163068521,
      "grad_norm": 0.1523757427930832,
      "learning_rate": 1.053844184657394e-06,
      "loss": 0.0016,
      "step": 114720
    },
    {
      "epoch": 9.790084478197798,
      "grad_norm": 0.09641174972057343,
      "learning_rate": 1.049577609011008e-06,
      "loss": 0.0014,
      "step": 114730
    },
    {
      "epoch": 9.790937793327076,
      "grad_norm": 0.039211150258779526,
      "learning_rate": 1.0453110333646217e-06,
      "loss": 0.0016,
      "step": 114740
    },
    {
      "epoch": 9.791791108456353,
      "grad_norm": 0.08202985674142838,
      "learning_rate": 1.0410444577182353e-06,
      "loss": 0.0017,
      "step": 114750
    },
    {
      "epoch": 9.79264442358563,
      "grad_norm": 0.08756281435489655,
      "learning_rate": 1.0367778820718491e-06,
      "loss": 0.0019,
      "step": 114760
    },
    {
      "epoch": 9.793497738714908,
      "grad_norm": 0.13056406378746033,
      "learning_rate": 1.032511306425463e-06,
      "loss": 0.0013,
      "step": 114770
    },
    {
      "epoch": 9.794351053844185,
      "grad_norm": 0.22160042822360992,
      "learning_rate": 1.0282447307790768e-06,
      "loss": 0.0013,
      "step": 114780
    },
    {
      "epoch": 9.795204368973462,
      "grad_norm": 0.23752446472644806,
      "learning_rate": 1.0239781551326906e-06,
      "loss": 0.0017,
      "step": 114790
    },
    {
      "epoch": 9.796057684102738,
      "grad_norm": 0.04745065048336983,
      "learning_rate": 1.0197115794863044e-06,
      "loss": 0.0013,
      "step": 114800
    },
    {
      "epoch": 9.796910999232017,
      "grad_norm": 0.11382930725812912,
      "learning_rate": 1.015445003839918e-06,
      "loss": 0.0016,
      "step": 114810
    },
    {
      "epoch": 9.797764314361293,
      "grad_norm": 0.27225401997566223,
      "learning_rate": 1.011178428193532e-06,
      "loss": 0.002,
      "step": 114820
    },
    {
      "epoch": 9.798617629490572,
      "grad_norm": 0.14838393032550812,
      "learning_rate": 1.0069118525471456e-06,
      "loss": 0.0016,
      "step": 114830
    },
    {
      "epoch": 9.799470944619848,
      "grad_norm": 0.09788323193788528,
      "learning_rate": 1.0026452769007595e-06,
      "loss": 0.002,
      "step": 114840
    },
    {
      "epoch": 9.800324259749125,
      "grad_norm": 0.026606427505612373,
      "learning_rate": 9.983787012543733e-07,
      "loss": 0.0015,
      "step": 114850
    },
    {
      "epoch": 9.801177574878402,
      "grad_norm": 0.11351250112056732,
      "learning_rate": 9.94112125607987e-07,
      "loss": 0.0016,
      "step": 114860
    },
    {
      "epoch": 9.80203089000768,
      "grad_norm": 0.040691666305065155,
      "learning_rate": 9.89845549961601e-07,
      "loss": 0.0012,
      "step": 114870
    },
    {
      "epoch": 9.802884205136957,
      "grad_norm": 0.16075265407562256,
      "learning_rate": 9.855789743152147e-07,
      "loss": 0.0016,
      "step": 114880
    },
    {
      "epoch": 9.803737520266234,
      "grad_norm": 0.06604094803333282,
      "learning_rate": 9.813123986688283e-07,
      "loss": 0.0016,
      "step": 114890
    },
    {
      "epoch": 9.804590835395512,
      "grad_norm": 0.09552748501300812,
      "learning_rate": 9.770458230224422e-07,
      "loss": 0.0012,
      "step": 114900
    },
    {
      "epoch": 9.805444150524789,
      "grad_norm": 0.20067600905895233,
      "learning_rate": 9.72779247376056e-07,
      "loss": 0.0017,
      "step": 114910
    },
    {
      "epoch": 9.806297465654065,
      "grad_norm": 0.11251595616340637,
      "learning_rate": 9.685126717296698e-07,
      "loss": 0.0016,
      "step": 114920
    },
    {
      "epoch": 9.807150780783344,
      "grad_norm": 0.20062106847763062,
      "learning_rate": 9.642460960832836e-07,
      "loss": 0.0013,
      "step": 114930
    },
    {
      "epoch": 9.80800409591262,
      "grad_norm": 0.11173734813928604,
      "learning_rate": 9.599795204368972e-07,
      "loss": 0.0013,
      "step": 114940
    },
    {
      "epoch": 9.808857411041897,
      "grad_norm": 0.029136082157492638,
      "learning_rate": 9.557129447905112e-07,
      "loss": 0.0016,
      "step": 114950
    },
    {
      "epoch": 9.809710726171176,
      "grad_norm": 0.07118985056877136,
      "learning_rate": 9.51446369144125e-07,
      "loss": 0.0017,
      "step": 114960
    },
    {
      "epoch": 9.810564041300452,
      "grad_norm": 0.07267461717128754,
      "learning_rate": 9.471797934977388e-07,
      "loss": 0.0016,
      "step": 114970
    },
    {
      "epoch": 9.811417356429729,
      "grad_norm": 0.03893519192934036,
      "learning_rate": 9.429132178513526e-07,
      "loss": 0.0015,
      "step": 114980
    },
    {
      "epoch": 9.812270671559007,
      "grad_norm": 0.20351004600524902,
      "learning_rate": 9.386466422049663e-07,
      "loss": 0.0019,
      "step": 114990
    },
    {
      "epoch": 9.813123986688284,
      "grad_norm": 0.28870290517807007,
      "learning_rate": 9.343800665585801e-07,
      "loss": 0.0019,
      "step": 115000
    },
    {
      "epoch": 9.81397730181756,
      "grad_norm": 0.06562278419733047,
      "learning_rate": 9.301134909121938e-07,
      "loss": 0.0016,
      "step": 115010
    },
    {
      "epoch": 9.81483061694684,
      "grad_norm": 0.11045905947685242,
      "learning_rate": 9.258469152658078e-07,
      "loss": 0.0014,
      "step": 115020
    },
    {
      "epoch": 9.815683932076116,
      "grad_norm": 0.13012760877609253,
      "learning_rate": 9.215803396194215e-07,
      "loss": 0.0015,
      "step": 115030
    },
    {
      "epoch": 9.816537247205392,
      "grad_norm": 0.2690465748310089,
      "learning_rate": 9.173137639730352e-07,
      "loss": 0.0019,
      "step": 115040
    },
    {
      "epoch": 9.817390562334671,
      "grad_norm": 0.2567231059074402,
      "learning_rate": 9.130471883266491e-07,
      "loss": 0.0013,
      "step": 115050
    },
    {
      "epoch": 9.818243877463948,
      "grad_norm": 0.08755933493375778,
      "learning_rate": 9.087806126802628e-07,
      "loss": 0.0018,
      "step": 115060
    },
    {
      "epoch": 9.819097192593224,
      "grad_norm": 0.03286014124751091,
      "learning_rate": 9.045140370338767e-07,
      "loss": 0.0018,
      "step": 115070
    },
    {
      "epoch": 9.819950507722503,
      "grad_norm": 0.2368738055229187,
      "learning_rate": 9.002474613874904e-07,
      "loss": 0.0016,
      "step": 115080
    },
    {
      "epoch": 9.82080382285178,
      "grad_norm": 0.10101762413978577,
      "learning_rate": 8.959808857411042e-07,
      "loss": 0.0016,
      "step": 115090
    },
    {
      "epoch": 9.821657137981056,
      "grad_norm": 0.12087875604629517,
      "learning_rate": 8.917143100947181e-07,
      "loss": 0.002,
      "step": 115100
    },
    {
      "epoch": 9.822510453110334,
      "grad_norm": 0.3468259274959564,
      "learning_rate": 8.874477344483318e-07,
      "loss": 0.002,
      "step": 115110
    },
    {
      "epoch": 9.823363768239611,
      "grad_norm": 0.32339000701904297,
      "learning_rate": 8.831811588019456e-07,
      "loss": 0.0017,
      "step": 115120
    },
    {
      "epoch": 9.824217083368888,
      "grad_norm": 0.13260382413864136,
      "learning_rate": 8.789145831555594e-07,
      "loss": 0.0017,
      "step": 115130
    },
    {
      "epoch": 9.825070398498166,
      "grad_norm": 0.14781983196735382,
      "learning_rate": 8.746480075091731e-07,
      "loss": 0.0011,
      "step": 115140
    },
    {
      "epoch": 9.825923713627443,
      "grad_norm": 0.3165484368801117,
      "learning_rate": 8.70381431862787e-07,
      "loss": 0.0015,
      "step": 115150
    },
    {
      "epoch": 9.82677702875672,
      "grad_norm": 0.12992876768112183,
      "learning_rate": 8.661148562164007e-07,
      "loss": 0.0015,
      "step": 115160
    },
    {
      "epoch": 9.827630343885996,
      "grad_norm": 0.10017047822475433,
      "learning_rate": 8.618482805700146e-07,
      "loss": 0.0015,
      "step": 115170
    },
    {
      "epoch": 9.828483659015275,
      "grad_norm": 0.044014591723680496,
      "learning_rate": 8.575817049236283e-07,
      "loss": 0.0019,
      "step": 115180
    },
    {
      "epoch": 9.829336974144551,
      "grad_norm": 0.2078651487827301,
      "learning_rate": 8.53315129277242e-07,
      "loss": 0.0017,
      "step": 115190
    },
    {
      "epoch": 9.83019028927383,
      "grad_norm": 0.04396113380789757,
      "learning_rate": 8.490485536308559e-07,
      "loss": 0.0017,
      "step": 115200
    },
    {
      "epoch": 9.831043604403106,
      "grad_norm": 0.30553755164146423,
      "learning_rate": 8.447819779844697e-07,
      "loss": 0.0014,
      "step": 115210
    },
    {
      "epoch": 9.831896919532383,
      "grad_norm": 0.032586611807346344,
      "learning_rate": 8.405154023380836e-07,
      "loss": 0.0019,
      "step": 115220
    },
    {
      "epoch": 9.83275023466166,
      "grad_norm": 0.05560588836669922,
      "learning_rate": 8.362488266916973e-07,
      "loss": 0.0018,
      "step": 115230
    },
    {
      "epoch": 9.833603549790938,
      "grad_norm": 0.2561191916465759,
      "learning_rate": 8.31982251045311e-07,
      "loss": 0.0015,
      "step": 115240
    },
    {
      "epoch": 9.834456864920215,
      "grad_norm": 0.09349194169044495,
      "learning_rate": 8.277156753989249e-07,
      "loss": 0.0012,
      "step": 115250
    },
    {
      "epoch": 9.835310180049492,
      "grad_norm": 0.12844403088092804,
      "learning_rate": 8.234490997525386e-07,
      "loss": 0.0017,
      "step": 115260
    },
    {
      "epoch": 9.83616349517877,
      "grad_norm": 0.07827945053577423,
      "learning_rate": 8.191825241061526e-07,
      "loss": 0.0014,
      "step": 115270
    },
    {
      "epoch": 9.837016810308047,
      "grad_norm": 0.11160210520029068,
      "learning_rate": 8.149159484597663e-07,
      "loss": 0.0014,
      "step": 115280
    },
    {
      "epoch": 9.837870125437323,
      "grad_norm": 0.2540399134159088,
      "learning_rate": 8.1064937281338e-07,
      "loss": 0.0013,
      "step": 115290
    },
    {
      "epoch": 9.838723440566602,
      "grad_norm": 0.16594472527503967,
      "learning_rate": 8.063827971669938e-07,
      "loss": 0.0017,
      "step": 115300
    },
    {
      "epoch": 9.839576755695878,
      "grad_norm": 0.06702162325382233,
      "learning_rate": 8.021162215206076e-07,
      "loss": 0.0017,
      "step": 115310
    },
    {
      "epoch": 9.840430070825155,
      "grad_norm": 0.25153082609176636,
      "learning_rate": 7.978496458742214e-07,
      "loss": 0.0016,
      "step": 115320
    },
    {
      "epoch": 9.841283385954434,
      "grad_norm": 0.10014542937278748,
      "learning_rate": 7.935830702278351e-07,
      "loss": 0.0015,
      "step": 115330
    },
    {
      "epoch": 9.84213670108371,
      "grad_norm": 0.16135059297084808,
      "learning_rate": 7.893164945814489e-07,
      "loss": 0.0018,
      "step": 115340
    },
    {
      "epoch": 9.842990016212987,
      "grad_norm": 0.24581961333751678,
      "learning_rate": 7.850499189350628e-07,
      "loss": 0.0016,
      "step": 115350
    },
    {
      "epoch": 9.843843331342265,
      "grad_norm": 0.1460953950881958,
      "learning_rate": 7.807833432886765e-07,
      "loss": 0.0015,
      "step": 115360
    },
    {
      "epoch": 9.844696646471542,
      "grad_norm": 0.14582282304763794,
      "learning_rate": 7.765167676422903e-07,
      "loss": 0.0015,
      "step": 115370
    },
    {
      "epoch": 9.845549961600819,
      "grad_norm": 0.21823464334011078,
      "learning_rate": 7.722501919959041e-07,
      "loss": 0.0014,
      "step": 115380
    },
    {
      "epoch": 9.846403276730097,
      "grad_norm": 0.16417191922664642,
      "learning_rate": 7.679836163495179e-07,
      "loss": 0.0017,
      "step": 115390
    },
    {
      "epoch": 9.847256591859374,
      "grad_norm": 0.23813089728355408,
      "learning_rate": 7.637170407031318e-07,
      "loss": 0.0019,
      "step": 115400
    },
    {
      "epoch": 9.84810990698865,
      "grad_norm": 0.20464207231998444,
      "learning_rate": 7.594504650567455e-07,
      "loss": 0.0018,
      "step": 115410
    },
    {
      "epoch": 9.848963222117929,
      "grad_norm": 0.04348359256982803,
      "learning_rate": 7.551838894103593e-07,
      "loss": 0.0016,
      "step": 115420
    },
    {
      "epoch": 9.849816537247206,
      "grad_norm": 0.05260995775461197,
      "learning_rate": 7.509173137639731e-07,
      "loss": 0.0014,
      "step": 115430
    },
    {
      "epoch": 9.850669852376482,
      "grad_norm": 0.05044310912489891,
      "learning_rate": 7.466507381175869e-07,
      "loss": 0.0013,
      "step": 115440
    },
    {
      "epoch": 9.85152316750576,
      "grad_norm": 0.07968741655349731,
      "learning_rate": 7.423841624712007e-07,
      "loss": 0.0015,
      "step": 115450
    },
    {
      "epoch": 9.852376482635037,
      "grad_norm": 0.09146663546562195,
      "learning_rate": 7.381175868248145e-07,
      "loss": 0.0014,
      "step": 115460
    },
    {
      "epoch": 9.853229797764314,
      "grad_norm": 0.1107369065284729,
      "learning_rate": 7.338510111784283e-07,
      "loss": 0.0015,
      "step": 115470
    },
    {
      "epoch": 9.854083112893592,
      "grad_norm": 0.10350559651851654,
      "learning_rate": 7.29584435532042e-07,
      "loss": 0.0015,
      "step": 115480
    },
    {
      "epoch": 9.854936428022869,
      "grad_norm": 0.14861734211444855,
      "learning_rate": 7.253178598856558e-07,
      "loss": 0.0012,
      "step": 115490
    },
    {
      "epoch": 9.855789743152146,
      "grad_norm": 0.2898087799549103,
      "learning_rate": 7.210512842392696e-07,
      "loss": 0.0018,
      "step": 115500
    },
    {
      "epoch": 9.856643058281424,
      "grad_norm": 0.16339226067066193,
      "learning_rate": 7.167847085928833e-07,
      "loss": 0.0022,
      "step": 115510
    },
    {
      "epoch": 9.8574963734107,
      "grad_norm": 0.132588192820549,
      "learning_rate": 7.125181329464971e-07,
      "loss": 0.0018,
      "step": 115520
    },
    {
      "epoch": 9.858349688539978,
      "grad_norm": 0.09019537270069122,
      "learning_rate": 7.08251557300111e-07,
      "loss": 0.0015,
      "step": 115530
    },
    {
      "epoch": 9.859203003669254,
      "grad_norm": 0.07514028251171112,
      "learning_rate": 7.039849816537248e-07,
      "loss": 0.0016,
      "step": 115540
    },
    {
      "epoch": 9.860056318798533,
      "grad_norm": 0.182954341173172,
      "learning_rate": 6.997184060073385e-07,
      "loss": 0.0014,
      "step": 115550
    },
    {
      "epoch": 9.86090963392781,
      "grad_norm": 0.2008792757987976,
      "learning_rate": 6.954518303609523e-07,
      "loss": 0.0017,
      "step": 115560
    },
    {
      "epoch": 9.861762949057088,
      "grad_norm": 0.05334225296974182,
      "learning_rate": 6.911852547145661e-07,
      "loss": 0.002,
      "step": 115570
    },
    {
      "epoch": 9.862616264186364,
      "grad_norm": 0.32509052753448486,
      "learning_rate": 6.869186790681799e-07,
      "loss": 0.0016,
      "step": 115580
    },
    {
      "epoch": 9.863469579315641,
      "grad_norm": 0.20120656490325928,
      "learning_rate": 6.826521034217938e-07,
      "loss": 0.0017,
      "step": 115590
    },
    {
      "epoch": 9.864322894444918,
      "grad_norm": 0.17093989253044128,
      "learning_rate": 6.783855277754075e-07,
      "loss": 0.0016,
      "step": 115600
    },
    {
      "epoch": 9.865176209574196,
      "grad_norm": 0.11926357448101044,
      "learning_rate": 6.741189521290213e-07,
      "loss": 0.0018,
      "step": 115610
    },
    {
      "epoch": 9.866029524703473,
      "grad_norm": 0.04367382079362869,
      "learning_rate": 6.698523764826351e-07,
      "loss": 0.0013,
      "step": 115620
    },
    {
      "epoch": 9.86688283983275,
      "grad_norm": 0.18008743226528168,
      "learning_rate": 6.655858008362488e-07,
      "loss": 0.0018,
      "step": 115630
    },
    {
      "epoch": 9.867736154962028,
      "grad_norm": 0.0444096103310585,
      "learning_rate": 6.613192251898626e-07,
      "loss": 0.0013,
      "step": 115640
    },
    {
      "epoch": 9.868589470091305,
      "grad_norm": 0.09830295294523239,
      "learning_rate": 6.570526495434763e-07,
      "loss": 0.0015,
      "step": 115650
    },
    {
      "epoch": 9.869442785220581,
      "grad_norm": 0.0680902749300003,
      "learning_rate": 6.527860738970902e-07,
      "loss": 0.0014,
      "step": 115660
    },
    {
      "epoch": 9.87029610034986,
      "grad_norm": 0.11174323409795761,
      "learning_rate": 6.48519498250704e-07,
      "loss": 0.0013,
      "step": 115670
    },
    {
      "epoch": 9.871149415479136,
      "grad_norm": 0.18369850516319275,
      "learning_rate": 6.442529226043178e-07,
      "loss": 0.0016,
      "step": 115680
    },
    {
      "epoch": 9.872002730608413,
      "grad_norm": 0.13461622595787048,
      "learning_rate": 6.399863469579316e-07,
      "loss": 0.0017,
      "step": 115690
    },
    {
      "epoch": 9.872856045737691,
      "grad_norm": 0.09307945519685745,
      "learning_rate": 6.357197713115453e-07,
      "loss": 0.0016,
      "step": 115700
    },
    {
      "epoch": 9.873709360866968,
      "grad_norm": 0.14504627883434296,
      "learning_rate": 6.314531956651591e-07,
      "loss": 0.0018,
      "step": 115710
    },
    {
      "epoch": 9.874562675996245,
      "grad_norm": 0.036450594663619995,
      "learning_rate": 6.27186620018773e-07,
      "loss": 0.0015,
      "step": 115720
    },
    {
      "epoch": 9.875415991125523,
      "grad_norm": 0.11275572329759598,
      "learning_rate": 6.229200443723868e-07,
      "loss": 0.0017,
      "step": 115730
    },
    {
      "epoch": 9.8762693062548,
      "grad_norm": 0.2639506757259369,
      "learning_rate": 6.186534687260006e-07,
      "loss": 0.0014,
      "step": 115740
    },
    {
      "epoch": 9.877122621384077,
      "grad_norm": 0.11117633432149887,
      "learning_rate": 6.143868930796143e-07,
      "loss": 0.0015,
      "step": 115750
    },
    {
      "epoch": 9.877975936513355,
      "grad_norm": 0.23309476673603058,
      "learning_rate": 6.101203174332281e-07,
      "loss": 0.0011,
      "step": 115760
    },
    {
      "epoch": 9.878829251642632,
      "grad_norm": 0.12683357298374176,
      "learning_rate": 6.058537417868419e-07,
      "loss": 0.0017,
      "step": 115770
    },
    {
      "epoch": 9.879682566771908,
      "grad_norm": 0.06229408085346222,
      "learning_rate": 6.015871661404558e-07,
      "loss": 0.0019,
      "step": 115780
    },
    {
      "epoch": 9.880535881901187,
      "grad_norm": 0.26739633083343506,
      "learning_rate": 5.973205904940695e-07,
      "loss": 0.0018,
      "step": 115790
    },
    {
      "epoch": 9.881389197030463,
      "grad_norm": 0.13178186118602753,
      "learning_rate": 5.930540148476833e-07,
      "loss": 0.0018,
      "step": 115800
    },
    {
      "epoch": 9.88224251215974,
      "grad_norm": 0.2281976193189621,
      "learning_rate": 5.88787439201297e-07,
      "loss": 0.0018,
      "step": 115810
    },
    {
      "epoch": 9.883095827289019,
      "grad_norm": 0.1502564251422882,
      "learning_rate": 5.845208635549108e-07,
      "loss": 0.0015,
      "step": 115820
    },
    {
      "epoch": 9.883949142418295,
      "grad_norm": 0.0609915554523468,
      "learning_rate": 5.802542879085246e-07,
      "loss": 0.0017,
      "step": 115830
    },
    {
      "epoch": 9.884802457547572,
      "grad_norm": 0.2343706339597702,
      "learning_rate": 5.759877122621385e-07,
      "loss": 0.0015,
      "step": 115840
    },
    {
      "epoch": 9.88565577267685,
      "grad_norm": 0.4898066222667694,
      "learning_rate": 5.717211366157522e-07,
      "loss": 0.0015,
      "step": 115850
    },
    {
      "epoch": 9.886509087806127,
      "grad_norm": 0.11216264963150024,
      "learning_rate": 5.67454560969366e-07,
      "loss": 0.0013,
      "step": 115860
    },
    {
      "epoch": 9.887362402935404,
      "grad_norm": 0.12846413254737854,
      "learning_rate": 5.631879853229798e-07,
      "loss": 0.0017,
      "step": 115870
    },
    {
      "epoch": 9.888215718064682,
      "grad_norm": 0.20050787925720215,
      "learning_rate": 5.589214096765936e-07,
      "loss": 0.0014,
      "step": 115880
    },
    {
      "epoch": 9.889069033193959,
      "grad_norm": 0.19100011885166168,
      "learning_rate": 5.546548340302074e-07,
      "loss": 0.0018,
      "step": 115890
    },
    {
      "epoch": 9.889922348323235,
      "grad_norm": 0.25182268023490906,
      "learning_rate": 5.503882583838211e-07,
      "loss": 0.0016,
      "step": 115900
    },
    {
      "epoch": 9.890775663452512,
      "grad_norm": 0.23507598042488098,
      "learning_rate": 5.46121682737435e-07,
      "loss": 0.0015,
      "step": 115910
    },
    {
      "epoch": 9.89162897858179,
      "grad_norm": 0.06680740416049957,
      "learning_rate": 5.418551070910488e-07,
      "loss": 0.0018,
      "step": 115920
    },
    {
      "epoch": 9.892482293711067,
      "grad_norm": 0.06042100116610527,
      "learning_rate": 5.375885314446626e-07,
      "loss": 0.0015,
      "step": 115930
    },
    {
      "epoch": 9.893335608840344,
      "grad_norm": 0.15822067856788635,
      "learning_rate": 5.333219557982764e-07,
      "loss": 0.0013,
      "step": 115940
    },
    {
      "epoch": 9.894188923969622,
      "grad_norm": 0.25654247403144836,
      "learning_rate": 5.290553801518901e-07,
      "loss": 0.0016,
      "step": 115950
    },
    {
      "epoch": 9.895042239098899,
      "grad_norm": 0.09632449597120285,
      "learning_rate": 5.24788804505504e-07,
      "loss": 0.0018,
      "step": 115960
    },
    {
      "epoch": 9.895895554228176,
      "grad_norm": 0.048244766891002655,
      "learning_rate": 5.205222288591177e-07,
      "loss": 0.0015,
      "step": 115970
    },
    {
      "epoch": 9.896748869357454,
      "grad_norm": 0.09970226138830185,
      "learning_rate": 5.162556532127315e-07,
      "loss": 0.0017,
      "step": 115980
    },
    {
      "epoch": 9.89760218448673,
      "grad_norm": 0.062345463782548904,
      "learning_rate": 5.119890775663453e-07,
      "loss": 0.0015,
      "step": 115990
    },
    {
      "epoch": 9.898455499616007,
      "grad_norm": 0.3138703405857086,
      "learning_rate": 5.07722501919959e-07,
      "loss": 0.0017,
      "step": 116000
    },
    {
      "epoch": 9.899308814745286,
      "grad_norm": 0.14680756628513336,
      "learning_rate": 5.034559262735728e-07,
      "loss": 0.0019,
      "step": 116010
    },
    {
      "epoch": 9.900162129874563,
      "grad_norm": 0.37819525599479675,
      "learning_rate": 4.991893506271866e-07,
      "loss": 0.0014,
      "step": 116020
    },
    {
      "epoch": 9.90101544500384,
      "grad_norm": 0.06569747626781464,
      "learning_rate": 4.949227749808005e-07,
      "loss": 0.0012,
      "step": 116030
    },
    {
      "epoch": 9.901868760133118,
      "grad_norm": 0.3103893995285034,
      "learning_rate": 4.906561993344142e-07,
      "loss": 0.0016,
      "step": 116040
    },
    {
      "epoch": 9.902722075262394,
      "grad_norm": 0.1262614130973816,
      "learning_rate": 4.86389623688028e-07,
      "loss": 0.0015,
      "step": 116050
    },
    {
      "epoch": 9.903575390391671,
      "grad_norm": 0.16687436401844025,
      "learning_rate": 4.821230480416418e-07,
      "loss": 0.0017,
      "step": 116060
    },
    {
      "epoch": 9.90442870552095,
      "grad_norm": 0.03250253200531006,
      "learning_rate": 4.778564723952556e-07,
      "loss": 0.0017,
      "step": 116070
    },
    {
      "epoch": 9.905282020650226,
      "grad_norm": 0.218829944729805,
      "learning_rate": 4.735898967488694e-07,
      "loss": 0.0015,
      "step": 116080
    },
    {
      "epoch": 9.906135335779503,
      "grad_norm": 0.0484049990773201,
      "learning_rate": 4.6932332110248315e-07,
      "loss": 0.0016,
      "step": 116090
    },
    {
      "epoch": 9.906988650908781,
      "grad_norm": 0.04107198119163513,
      "learning_rate": 4.650567454560969e-07,
      "loss": 0.0014,
      "step": 116100
    },
    {
      "epoch": 9.907841966038058,
      "grad_norm": 0.050601448863744736,
      "learning_rate": 4.6079016980971073e-07,
      "loss": 0.002,
      "step": 116110
    },
    {
      "epoch": 9.908695281167335,
      "grad_norm": 0.040070563554763794,
      "learning_rate": 4.5652359416332455e-07,
      "loss": 0.0015,
      "step": 116120
    },
    {
      "epoch": 9.909548596296613,
      "grad_norm": 0.14944370090961456,
      "learning_rate": 4.5225701851693837e-07,
      "loss": 0.0015,
      "step": 116130
    },
    {
      "epoch": 9.91040191142589,
      "grad_norm": 0.07963395863771439,
      "learning_rate": 4.479904428705521e-07,
      "loss": 0.0016,
      "step": 116140
    },
    {
      "epoch": 9.911255226555166,
      "grad_norm": 0.1497458666563034,
      "learning_rate": 4.437238672241659e-07,
      "loss": 0.0015,
      "step": 116150
    },
    {
      "epoch": 9.912108541684445,
      "grad_norm": 0.0780235156416893,
      "learning_rate": 4.394572915777797e-07,
      "loss": 0.0019,
      "step": 116160
    },
    {
      "epoch": 9.912961856813721,
      "grad_norm": 0.16447030007839203,
      "learning_rate": 4.351907159313935e-07,
      "loss": 0.0014,
      "step": 116170
    },
    {
      "epoch": 9.913815171942998,
      "grad_norm": 0.16543219983577728,
      "learning_rate": 4.309241402850073e-07,
      "loss": 0.0014,
      "step": 116180
    },
    {
      "epoch": 9.914668487072277,
      "grad_norm": 0.09273992478847504,
      "learning_rate": 4.26657564638621e-07,
      "loss": 0.0015,
      "step": 116190
    },
    {
      "epoch": 9.915521802201553,
      "grad_norm": 0.14817237854003906,
      "learning_rate": 4.223909889922348e-07,
      "loss": 0.0014,
      "step": 116200
    },
    {
      "epoch": 9.91637511733083,
      "grad_norm": 0.18315498530864716,
      "learning_rate": 4.1812441334584864e-07,
      "loss": 0.0018,
      "step": 116210
    },
    {
      "epoch": 9.917228432460108,
      "grad_norm": 0.040125902742147446,
      "learning_rate": 4.1385783769946246e-07,
      "loss": 0.0014,
      "step": 116220
    },
    {
      "epoch": 9.918081747589385,
      "grad_norm": 0.19767220318317413,
      "learning_rate": 4.095912620530763e-07,
      "loss": 0.002,
      "step": 116230
    },
    {
      "epoch": 9.918935062718662,
      "grad_norm": 0.09767792373895645,
      "learning_rate": 4.0532468640669e-07,
      "loss": 0.0013,
      "step": 116240
    },
    {
      "epoch": 9.91978837784794,
      "grad_norm": 0.03772404417395592,
      "learning_rate": 4.010581107603038e-07,
      "loss": 0.0019,
      "step": 116250
    },
    {
      "epoch": 9.920641692977217,
      "grad_norm": 0.03592970594763756,
      "learning_rate": 3.9679153511391757e-07,
      "loss": 0.0017,
      "step": 116260
    },
    {
      "epoch": 9.921495008106493,
      "grad_norm": 0.18013757467269897,
      "learning_rate": 3.925249594675314e-07,
      "loss": 0.0022,
      "step": 116270
    },
    {
      "epoch": 9.92234832323577,
      "grad_norm": 0.22029414772987366,
      "learning_rate": 3.8825838382114515e-07,
      "loss": 0.0015,
      "step": 116280
    },
    {
      "epoch": 9.923201638365049,
      "grad_norm": 0.06437686085700989,
      "learning_rate": 3.8399180817475897e-07,
      "loss": 0.0015,
      "step": 116290
    },
    {
      "epoch": 9.924054953494325,
      "grad_norm": 0.059955403208732605,
      "learning_rate": 3.7972523252837274e-07,
      "loss": 0.0014,
      "step": 116300
    },
    {
      "epoch": 9.924908268623602,
      "grad_norm": 0.18595048785209656,
      "learning_rate": 3.7545865688198655e-07,
      "loss": 0.0015,
      "step": 116310
    },
    {
      "epoch": 9.92576158375288,
      "grad_norm": 0.18115122616291046,
      "learning_rate": 3.7119208123560037e-07,
      "loss": 0.0011,
      "step": 116320
    },
    {
      "epoch": 9.926614898882157,
      "grad_norm": 0.14565351605415344,
      "learning_rate": 3.6692550558921413e-07,
      "loss": 0.0015,
      "step": 116330
    },
    {
      "epoch": 9.927468214011434,
      "grad_norm": 0.16867658495903015,
      "learning_rate": 3.626589299428279e-07,
      "loss": 0.0013,
      "step": 116340
    },
    {
      "epoch": 9.928321529140712,
      "grad_norm": 0.05679457262158394,
      "learning_rate": 3.5839235429644166e-07,
      "loss": 0.0016,
      "step": 116350
    },
    {
      "epoch": 9.929174844269989,
      "grad_norm": 0.13265997171401978,
      "learning_rate": 3.541257786500555e-07,
      "loss": 0.0016,
      "step": 116360
    },
    {
      "epoch": 9.930028159399265,
      "grad_norm": 0.0922752320766449,
      "learning_rate": 3.4985920300366925e-07,
      "loss": 0.0011,
      "step": 116370
    },
    {
      "epoch": 9.930881474528544,
      "grad_norm": 0.0627511739730835,
      "learning_rate": 3.4559262735728306e-07,
      "loss": 0.0014,
      "step": 116380
    },
    {
      "epoch": 9.93173478965782,
      "grad_norm": 0.11810337752103806,
      "learning_rate": 3.413260517108969e-07,
      "loss": 0.002,
      "step": 116390
    },
    {
      "epoch": 9.932588104787097,
      "grad_norm": 0.10099361836910248,
      "learning_rate": 3.3705947606451065e-07,
      "loss": 0.0016,
      "step": 116400
    },
    {
      "epoch": 9.933441419916376,
      "grad_norm": 0.16416990756988525,
      "learning_rate": 3.327929004181244e-07,
      "loss": 0.0015,
      "step": 116410
    },
    {
      "epoch": 9.934294735045652,
      "grad_norm": 0.1352185755968094,
      "learning_rate": 3.285263247717382e-07,
      "loss": 0.0013,
      "step": 116420
    },
    {
      "epoch": 9.935148050174929,
      "grad_norm": 0.16052208840847015,
      "learning_rate": 3.24259749125352e-07,
      "loss": 0.0015,
      "step": 116430
    },
    {
      "epoch": 9.936001365304207,
      "grad_norm": 0.050124745815992355,
      "learning_rate": 3.199931734789658e-07,
      "loss": 0.0013,
      "step": 116440
    },
    {
      "epoch": 9.936854680433484,
      "grad_norm": 0.04807530716061592,
      "learning_rate": 3.1572659783257957e-07,
      "loss": 0.0015,
      "step": 116450
    },
    {
      "epoch": 9.93770799556276,
      "grad_norm": 0.07790844887495041,
      "learning_rate": 3.114600221861934e-07,
      "loss": 0.0019,
      "step": 116460
    },
    {
      "epoch": 9.93856131069204,
      "grad_norm": 0.18298237025737762,
      "learning_rate": 3.0719344653980716e-07,
      "loss": 0.0015,
      "step": 116470
    },
    {
      "epoch": 9.939414625821316,
      "grad_norm": 0.1060245931148529,
      "learning_rate": 3.0292687089342097e-07,
      "loss": 0.0019,
      "step": 116480
    },
    {
      "epoch": 9.940267940950593,
      "grad_norm": 0.08210232853889465,
      "learning_rate": 2.9866029524703474e-07,
      "loss": 0.0019,
      "step": 116490
    },
    {
      "epoch": 9.941121256079871,
      "grad_norm": 0.1632625013589859,
      "learning_rate": 2.943937196006485e-07,
      "loss": 0.0015,
      "step": 116500
    }
  ],
  "logging_steps": 10,
  "max_steps": 117190,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 0.0,
  "train_batch_size": 64,
  "trial_name": null,
  "trial_params": null
}
