{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.9777777777777779,
  "eval_steps": 500,
  "global_step": 89000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.00022222222222222223,
      "grad_norm": 0.18136224150657654,
      "learning_rate": 4.9994444444444446e-05,
      "loss": 0.0019,
      "step": 10
    },
    {
      "epoch": 0.00044444444444444447,
      "grad_norm": 0.1257396787405014,
      "learning_rate": 4.998888888888889e-05,
      "loss": 0.0028,
      "step": 20
    },
    {
      "epoch": 0.0006666666666666666,
      "grad_norm": 0.11990851163864136,
      "learning_rate": 4.998333333333334e-05,
      "loss": 0.0028,
      "step": 30
    },
    {
      "epoch": 0.0008888888888888889,
      "grad_norm": 0.39090442657470703,
      "learning_rate": 4.997777777777778e-05,
      "loss": 0.0028,
      "step": 40
    },
    {
      "epoch": 0.0011111111111111111,
      "grad_norm": 0.5085268020629883,
      "learning_rate": 4.997222222222223e-05,
      "loss": 0.0033,
      "step": 50
    },
    {
      "epoch": 0.0013333333333333333,
      "grad_norm": 0.4217070937156677,
      "learning_rate": 4.996666666666667e-05,
      "loss": 0.0036,
      "step": 60
    },
    {
      "epoch": 0.0015555555555555555,
      "grad_norm": 0.4625404179096222,
      "learning_rate": 4.9961111111111114e-05,
      "loss": 0.0031,
      "step": 70
    },
    {
      "epoch": 0.0017777777777777779,
      "grad_norm": 0.33464884757995605,
      "learning_rate": 4.995555555555556e-05,
      "loss": 0.0035,
      "step": 80
    },
    {
      "epoch": 0.002,
      "grad_norm": 0.4768896996974945,
      "learning_rate": 4.995e-05,
      "loss": 0.0036,
      "step": 90
    },
    {
      "epoch": 0.0022222222222222222,
      "grad_norm": 0.4469669759273529,
      "learning_rate": 4.994444444444445e-05,
      "loss": 0.0026,
      "step": 100
    },
    {
      "epoch": 0.0024444444444444444,
      "grad_norm": 0.6041424870491028,
      "learning_rate": 4.993888888888889e-05,
      "loss": 0.0028,
      "step": 110
    },
    {
      "epoch": 0.0026666666666666666,
      "grad_norm": 0.32262519001960754,
      "learning_rate": 4.993333333333334e-05,
      "loss": 0.0022,
      "step": 120
    },
    {
      "epoch": 0.0028888888888888888,
      "grad_norm": 0.41101813316345215,
      "learning_rate": 4.992777777777778e-05,
      "loss": 0.0029,
      "step": 130
    },
    {
      "epoch": 0.003111111111111111,
      "grad_norm": 0.2880289554595947,
      "learning_rate": 4.9922222222222226e-05,
      "loss": 0.0025,
      "step": 140
    },
    {
      "epoch": 0.0033333333333333335,
      "grad_norm": 0.15437214076519012,
      "learning_rate": 4.991666666666667e-05,
      "loss": 0.0026,
      "step": 150
    },
    {
      "epoch": 0.0035555555555555557,
      "grad_norm": 0.2066020965576172,
      "learning_rate": 4.991111111111111e-05,
      "loss": 0.002,
      "step": 160
    },
    {
      "epoch": 0.003777777777777778,
      "grad_norm": 0.34024420380592346,
      "learning_rate": 4.9905555555555556e-05,
      "loss": 0.0032,
      "step": 170
    },
    {
      "epoch": 0.004,
      "grad_norm": 0.22391745448112488,
      "learning_rate": 4.99e-05,
      "loss": 0.0022,
      "step": 180
    },
    {
      "epoch": 0.004222222222222222,
      "grad_norm": 0.27738261222839355,
      "learning_rate": 4.989444444444445e-05,
      "loss": 0.0026,
      "step": 190
    },
    {
      "epoch": 0.0044444444444444444,
      "grad_norm": 0.4599222242832184,
      "learning_rate": 4.9888888888888894e-05,
      "loss": 0.002,
      "step": 200
    },
    {
      "epoch": 0.004666666666666667,
      "grad_norm": 0.12635396420955658,
      "learning_rate": 4.988333333333334e-05,
      "loss": 0.0032,
      "step": 210
    },
    {
      "epoch": 0.004888888888888889,
      "grad_norm": 0.5776050686836243,
      "learning_rate": 4.987777777777778e-05,
      "loss": 0.0023,
      "step": 220
    },
    {
      "epoch": 0.005111111111111111,
      "grad_norm": 0.4377775490283966,
      "learning_rate": 4.9872222222222225e-05,
      "loss": 0.0026,
      "step": 230
    },
    {
      "epoch": 0.005333333333333333,
      "grad_norm": 0.32659676671028137,
      "learning_rate": 4.986666666666667e-05,
      "loss": 0.0029,
      "step": 240
    },
    {
      "epoch": 0.005555555555555556,
      "grad_norm": 0.8068757057189941,
      "learning_rate": 4.986111111111111e-05,
      "loss": 0.0018,
      "step": 250
    },
    {
      "epoch": 0.0057777777777777775,
      "grad_norm": 0.5787664651870728,
      "learning_rate": 4.9855555555555555e-05,
      "loss": 0.0022,
      "step": 260
    },
    {
      "epoch": 0.006,
      "grad_norm": 0.2608084976673126,
      "learning_rate": 4.9850000000000006e-05,
      "loss": 0.0025,
      "step": 270
    },
    {
      "epoch": 0.006222222222222222,
      "grad_norm": 0.2981948256492615,
      "learning_rate": 4.984444444444445e-05,
      "loss": 0.0036,
      "step": 280
    },
    {
      "epoch": 0.0064444444444444445,
      "grad_norm": 0.14676804840564728,
      "learning_rate": 4.983888888888889e-05,
      "loss": 0.0022,
      "step": 290
    },
    {
      "epoch": 0.006666666666666667,
      "grad_norm": 0.7117627859115601,
      "learning_rate": 4.9833333333333336e-05,
      "loss": 0.0027,
      "step": 300
    },
    {
      "epoch": 0.006888888888888889,
      "grad_norm": 0.10416967421770096,
      "learning_rate": 4.982777777777778e-05,
      "loss": 0.003,
      "step": 310
    },
    {
      "epoch": 0.0071111111111111115,
      "grad_norm": 0.7170143127441406,
      "learning_rate": 4.982222222222222e-05,
      "loss": 0.0032,
      "step": 320
    },
    {
      "epoch": 0.007333333333333333,
      "grad_norm": 0.11452794820070267,
      "learning_rate": 4.981666666666667e-05,
      "loss": 0.0031,
      "step": 330
    },
    {
      "epoch": 0.007555555555555556,
      "grad_norm": 0.2218325138092041,
      "learning_rate": 4.981111111111112e-05,
      "loss": 0.0029,
      "step": 340
    },
    {
      "epoch": 0.0077777777777777776,
      "grad_norm": 0.32794156670570374,
      "learning_rate": 4.9805555555555554e-05,
      "loss": 0.003,
      "step": 350
    },
    {
      "epoch": 0.008,
      "grad_norm": 0.11209961026906967,
      "learning_rate": 4.9800000000000004e-05,
      "loss": 0.0027,
      "step": 360
    },
    {
      "epoch": 0.008222222222222223,
      "grad_norm": 0.1122223362326622,
      "learning_rate": 4.979444444444445e-05,
      "loss": 0.0019,
      "step": 370
    },
    {
      "epoch": 0.008444444444444444,
      "grad_norm": 0.525060772895813,
      "learning_rate": 4.978888888888889e-05,
      "loss": 0.002,
      "step": 380
    },
    {
      "epoch": 0.008666666666666666,
      "grad_norm": 0.19695675373077393,
      "learning_rate": 4.9783333333333335e-05,
      "loss": 0.0029,
      "step": 390
    },
    {
      "epoch": 0.008888888888888889,
      "grad_norm": 0.1587415188550949,
      "learning_rate": 4.977777777777778e-05,
      "loss": 0.0024,
      "step": 400
    },
    {
      "epoch": 0.009111111111111111,
      "grad_norm": 0.0997445210814476,
      "learning_rate": 4.977222222222223e-05,
      "loss": 0.0025,
      "step": 410
    },
    {
      "epoch": 0.009333333333333334,
      "grad_norm": 0.13144861161708832,
      "learning_rate": 4.9766666666666666e-05,
      "loss": 0.0022,
      "step": 420
    },
    {
      "epoch": 0.009555555555555555,
      "grad_norm": 0.6108284592628479,
      "learning_rate": 4.9761111111111116e-05,
      "loss": 0.0025,
      "step": 430
    },
    {
      "epoch": 0.009777777777777778,
      "grad_norm": 0.36314478516578674,
      "learning_rate": 4.975555555555555e-05,
      "loss": 0.0034,
      "step": 440
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.5660611987113953,
      "learning_rate": 4.975e-05,
      "loss": 0.0024,
      "step": 450
    },
    {
      "epoch": 0.010222222222222223,
      "grad_norm": 0.49844858050346375,
      "learning_rate": 4.974444444444445e-05,
      "loss": 0.0032,
      "step": 460
    },
    {
      "epoch": 0.010444444444444444,
      "grad_norm": 0.0981442779302597,
      "learning_rate": 4.973888888888889e-05,
      "loss": 0.0027,
      "step": 470
    },
    {
      "epoch": 0.010666666666666666,
      "grad_norm": 0.15335242450237274,
      "learning_rate": 4.973333333333334e-05,
      "loss": 0.0026,
      "step": 480
    },
    {
      "epoch": 0.010888888888888889,
      "grad_norm": 0.43068328499794006,
      "learning_rate": 4.972777777777778e-05,
      "loss": 0.0024,
      "step": 490
    },
    {
      "epoch": 0.011111111111111112,
      "grad_norm": 0.5414627194404602,
      "learning_rate": 4.972222222222223e-05,
      "loss": 0.0026,
      "step": 500
    },
    {
      "epoch": 0.011333333333333334,
      "grad_norm": 0.7222636938095093,
      "learning_rate": 4.9716666666666664e-05,
      "loss": 0.0026,
      "step": 510
    },
    {
      "epoch": 0.011555555555555555,
      "grad_norm": 0.24765388667583466,
      "learning_rate": 4.9711111111111115e-05,
      "loss": 0.0023,
      "step": 520
    },
    {
      "epoch": 0.011777777777777778,
      "grad_norm": 0.5191292762756348,
      "learning_rate": 4.970555555555556e-05,
      "loss": 0.0029,
      "step": 530
    },
    {
      "epoch": 0.012,
      "grad_norm": 0.7082278728485107,
      "learning_rate": 4.97e-05,
      "loss": 0.0031,
      "step": 540
    },
    {
      "epoch": 0.012222222222222223,
      "grad_norm": 0.08268345147371292,
      "learning_rate": 4.969444444444445e-05,
      "loss": 0.0028,
      "step": 550
    },
    {
      "epoch": 0.012444444444444444,
      "grad_norm": 0.23269890248775482,
      "learning_rate": 4.968888888888889e-05,
      "loss": 0.0024,
      "step": 560
    },
    {
      "epoch": 0.012666666666666666,
      "grad_norm": 0.18191692233085632,
      "learning_rate": 4.968333333333334e-05,
      "loss": 0.002,
      "step": 570
    },
    {
      "epoch": 0.012888888888888889,
      "grad_norm": 0.07610233128070831,
      "learning_rate": 4.9677777777777776e-05,
      "loss": 0.002,
      "step": 580
    },
    {
      "epoch": 0.013111111111111112,
      "grad_norm": 0.6650441884994507,
      "learning_rate": 4.9672222222222226e-05,
      "loss": 0.002,
      "step": 590
    },
    {
      "epoch": 0.013333333333333334,
      "grad_norm": 0.9648946523666382,
      "learning_rate": 4.966666666666667e-05,
      "loss": 0.0023,
      "step": 600
    },
    {
      "epoch": 0.013555555555555555,
      "grad_norm": 0.5458427667617798,
      "learning_rate": 4.9661111111111114e-05,
      "loss": 0.003,
      "step": 610
    },
    {
      "epoch": 0.013777777777777778,
      "grad_norm": 0.23798982799053192,
      "learning_rate": 4.965555555555556e-05,
      "loss": 0.0022,
      "step": 620
    },
    {
      "epoch": 0.014,
      "grad_norm": 0.1619175225496292,
      "learning_rate": 4.965e-05,
      "loss": 0.0025,
      "step": 630
    },
    {
      "epoch": 0.014222222222222223,
      "grad_norm": 0.5498142242431641,
      "learning_rate": 4.964444444444445e-05,
      "loss": 0.0026,
      "step": 640
    },
    {
      "epoch": 0.014444444444444444,
      "grad_norm": 0.09358549863100052,
      "learning_rate": 4.963888888888889e-05,
      "loss": 0.0029,
      "step": 650
    },
    {
      "epoch": 0.014666666666666666,
      "grad_norm": 0.744275689125061,
      "learning_rate": 4.963333333333334e-05,
      "loss": 0.0031,
      "step": 660
    },
    {
      "epoch": 0.014888888888888889,
      "grad_norm": 0.21629640460014343,
      "learning_rate": 4.962777777777778e-05,
      "loss": 0.0035,
      "step": 670
    },
    {
      "epoch": 0.015111111111111112,
      "grad_norm": 0.3868117034435272,
      "learning_rate": 4.9622222222222225e-05,
      "loss": 0.0022,
      "step": 680
    },
    {
      "epoch": 0.015333333333333332,
      "grad_norm": 0.4659760296344757,
      "learning_rate": 4.961666666666667e-05,
      "loss": 0.002,
      "step": 690
    },
    {
      "epoch": 0.015555555555555555,
      "grad_norm": 0.20871946215629578,
      "learning_rate": 4.961111111111111e-05,
      "loss": 0.0025,
      "step": 700
    },
    {
      "epoch": 0.01577777777777778,
      "grad_norm": 0.44075560569763184,
      "learning_rate": 4.960555555555556e-05,
      "loss": 0.003,
      "step": 710
    },
    {
      "epoch": 0.016,
      "grad_norm": 0.7770047783851624,
      "learning_rate": 4.96e-05,
      "loss": 0.0024,
      "step": 720
    },
    {
      "epoch": 0.01622222222222222,
      "grad_norm": 0.6632370948791504,
      "learning_rate": 4.959444444444445e-05,
      "loss": 0.0025,
      "step": 730
    },
    {
      "epoch": 0.016444444444444446,
      "grad_norm": 0.13410702347755432,
      "learning_rate": 4.958888888888889e-05,
      "loss": 0.0023,
      "step": 740
    },
    {
      "epoch": 0.016666666666666666,
      "grad_norm": 0.25440385937690735,
      "learning_rate": 4.958333333333334e-05,
      "loss": 0.0028,
      "step": 750
    },
    {
      "epoch": 0.016888888888888887,
      "grad_norm": 0.19565503299236298,
      "learning_rate": 4.957777777777778e-05,
      "loss": 0.0022,
      "step": 760
    },
    {
      "epoch": 0.01711111111111111,
      "grad_norm": 0.6437304615974426,
      "learning_rate": 4.9572222222222224e-05,
      "loss": 0.0024,
      "step": 770
    },
    {
      "epoch": 0.017333333333333333,
      "grad_norm": 0.3965647518634796,
      "learning_rate": 4.956666666666667e-05,
      "loss": 0.0039,
      "step": 780
    },
    {
      "epoch": 0.017555555555555557,
      "grad_norm": 0.27013975381851196,
      "learning_rate": 4.956111111111111e-05,
      "loss": 0.0034,
      "step": 790
    },
    {
      "epoch": 0.017777777777777778,
      "grad_norm": 0.3716948330402374,
      "learning_rate": 4.955555555555556e-05,
      "loss": 0.0039,
      "step": 800
    },
    {
      "epoch": 0.018,
      "grad_norm": 0.10660809278488159,
      "learning_rate": 4.9550000000000005e-05,
      "loss": 0.004,
      "step": 810
    },
    {
      "epoch": 0.018222222222222223,
      "grad_norm": 0.07346224784851074,
      "learning_rate": 4.954444444444445e-05,
      "loss": 0.0025,
      "step": 820
    },
    {
      "epoch": 0.018444444444444444,
      "grad_norm": 0.1375981718301773,
      "learning_rate": 4.953888888888889e-05,
      "loss": 0.0018,
      "step": 830
    },
    {
      "epoch": 0.018666666666666668,
      "grad_norm": 0.5254009962081909,
      "learning_rate": 4.9533333333333336e-05,
      "loss": 0.0037,
      "step": 840
    },
    {
      "epoch": 0.01888888888888889,
      "grad_norm": 0.0790649801492691,
      "learning_rate": 4.952777777777778e-05,
      "loss": 0.0032,
      "step": 850
    },
    {
      "epoch": 0.01911111111111111,
      "grad_norm": 0.142580047249794,
      "learning_rate": 4.952222222222222e-05,
      "loss": 0.0019,
      "step": 860
    },
    {
      "epoch": 0.019333333333333334,
      "grad_norm": 0.5284276008605957,
      "learning_rate": 4.9516666666666666e-05,
      "loss": 0.0028,
      "step": 870
    },
    {
      "epoch": 0.019555555555555555,
      "grad_norm": 0.25257408618927,
      "learning_rate": 4.951111111111112e-05,
      "loss": 0.0033,
      "step": 880
    },
    {
      "epoch": 0.019777777777777776,
      "grad_norm": 0.16419336199760437,
      "learning_rate": 4.950555555555556e-05,
      "loss": 0.002,
      "step": 890
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.31220921874046326,
      "learning_rate": 4.9500000000000004e-05,
      "loss": 0.0024,
      "step": 900
    },
    {
      "epoch": 0.02022222222222222,
      "grad_norm": 0.23285424709320068,
      "learning_rate": 4.949444444444445e-05,
      "loss": 0.0024,
      "step": 910
    },
    {
      "epoch": 0.020444444444444446,
      "grad_norm": 0.22007779777050018,
      "learning_rate": 4.948888888888889e-05,
      "loss": 0.0021,
      "step": 920
    },
    {
      "epoch": 0.020666666666666667,
      "grad_norm": 0.16383107006549835,
      "learning_rate": 4.9483333333333334e-05,
      "loss": 0.0023,
      "step": 930
    },
    {
      "epoch": 0.020888888888888887,
      "grad_norm": 0.07841568440198898,
      "learning_rate": 4.947777777777778e-05,
      "loss": 0.0035,
      "step": 940
    },
    {
      "epoch": 0.021111111111111112,
      "grad_norm": 0.3721179962158203,
      "learning_rate": 4.947222222222223e-05,
      "loss": 0.0028,
      "step": 950
    },
    {
      "epoch": 0.021333333333333333,
      "grad_norm": 0.1577865332365036,
      "learning_rate": 4.9466666666666665e-05,
      "loss": 0.0023,
      "step": 960
    },
    {
      "epoch": 0.021555555555555557,
      "grad_norm": 0.13446468114852905,
      "learning_rate": 4.9461111111111115e-05,
      "loss": 0.0042,
      "step": 970
    },
    {
      "epoch": 0.021777777777777778,
      "grad_norm": 0.6065349578857422,
      "learning_rate": 4.945555555555556e-05,
      "loss": 0.0024,
      "step": 980
    },
    {
      "epoch": 0.022,
      "grad_norm": 0.30389198660850525,
      "learning_rate": 4.945e-05,
      "loss": 0.0028,
      "step": 990
    },
    {
      "epoch": 0.022222222222222223,
      "grad_norm": 0.1489422619342804,
      "learning_rate": 4.9444444444444446e-05,
      "loss": 0.0028,
      "step": 1000
    },
    {
      "epoch": 0.022444444444444444,
      "grad_norm": 0.1668066829442978,
      "learning_rate": 4.943888888888889e-05,
      "loss": 0.002,
      "step": 1010
    },
    {
      "epoch": 0.02266666666666667,
      "grad_norm": 0.2992851138114929,
      "learning_rate": 4.943333333333334e-05,
      "loss": 0.0026,
      "step": 1020
    },
    {
      "epoch": 0.02288888888888889,
      "grad_norm": 0.13898052275180817,
      "learning_rate": 4.942777777777778e-05,
      "loss": 0.002,
      "step": 1030
    },
    {
      "epoch": 0.02311111111111111,
      "grad_norm": 0.2947733700275421,
      "learning_rate": 4.942222222222223e-05,
      "loss": 0.002,
      "step": 1040
    },
    {
      "epoch": 0.023333333333333334,
      "grad_norm": 0.1930217146873474,
      "learning_rate": 4.9416666666666664e-05,
      "loss": 0.0027,
      "step": 1050
    },
    {
      "epoch": 0.023555555555555555,
      "grad_norm": 0.08486530929803848,
      "learning_rate": 4.9411111111111114e-05,
      "loss": 0.0035,
      "step": 1060
    },
    {
      "epoch": 0.023777777777777776,
      "grad_norm": 0.294530987739563,
      "learning_rate": 4.940555555555556e-05,
      "loss": 0.0022,
      "step": 1070
    },
    {
      "epoch": 0.024,
      "grad_norm": 0.16038857400417328,
      "learning_rate": 4.94e-05,
      "loss": 0.003,
      "step": 1080
    },
    {
      "epoch": 0.02422222222222222,
      "grad_norm": 0.2274775356054306,
      "learning_rate": 4.939444444444445e-05,
      "loss": 0.0021,
      "step": 1090
    },
    {
      "epoch": 0.024444444444444446,
      "grad_norm": 0.29289165139198303,
      "learning_rate": 4.938888888888889e-05,
      "loss": 0.0025,
      "step": 1100
    },
    {
      "epoch": 0.024666666666666667,
      "grad_norm": 0.22219973802566528,
      "learning_rate": 4.938333333333334e-05,
      "loss": 0.0025,
      "step": 1110
    },
    {
      "epoch": 0.024888888888888887,
      "grad_norm": 0.15203586220741272,
      "learning_rate": 4.9377777777777776e-05,
      "loss": 0.0021,
      "step": 1120
    },
    {
      "epoch": 0.025111111111111112,
      "grad_norm": 0.10477111488580704,
      "learning_rate": 4.9372222222222226e-05,
      "loss": 0.0026,
      "step": 1130
    },
    {
      "epoch": 0.025333333333333333,
      "grad_norm": 0.10364114493131638,
      "learning_rate": 4.936666666666667e-05,
      "loss": 0.0027,
      "step": 1140
    },
    {
      "epoch": 0.025555555555555557,
      "grad_norm": 0.15854324400424957,
      "learning_rate": 4.936111111111111e-05,
      "loss": 0.0028,
      "step": 1150
    },
    {
      "epoch": 0.025777777777777778,
      "grad_norm": 0.11166857928037643,
      "learning_rate": 4.935555555555556e-05,
      "loss": 0.0026,
      "step": 1160
    },
    {
      "epoch": 0.026,
      "grad_norm": 0.451464980840683,
      "learning_rate": 4.935e-05,
      "loss": 0.0023,
      "step": 1170
    },
    {
      "epoch": 0.026222222222222223,
      "grad_norm": 0.1703833043575287,
      "learning_rate": 4.934444444444445e-05,
      "loss": 0.0024,
      "step": 1180
    },
    {
      "epoch": 0.026444444444444444,
      "grad_norm": 0.6020578145980835,
      "learning_rate": 4.933888888888889e-05,
      "loss": 0.0019,
      "step": 1190
    },
    {
      "epoch": 0.02666666666666667,
      "grad_norm": 0.0860452950000763,
      "learning_rate": 4.933333333333334e-05,
      "loss": 0.0028,
      "step": 1200
    },
    {
      "epoch": 0.02688888888888889,
      "grad_norm": 0.1173364669084549,
      "learning_rate": 4.932777777777778e-05,
      "loss": 0.0021,
      "step": 1210
    },
    {
      "epoch": 0.02711111111111111,
      "grad_norm": 0.2093277871608734,
      "learning_rate": 4.9322222222222225e-05,
      "loss": 0.0028,
      "step": 1220
    },
    {
      "epoch": 0.027333333333333334,
      "grad_norm": 0.21549421548843384,
      "learning_rate": 4.931666666666667e-05,
      "loss": 0.0024,
      "step": 1230
    },
    {
      "epoch": 0.027555555555555555,
      "grad_norm": 0.31172871589660645,
      "learning_rate": 4.931111111111111e-05,
      "loss": 0.0022,
      "step": 1240
    },
    {
      "epoch": 0.027777777777777776,
      "grad_norm": 0.5917750597000122,
      "learning_rate": 4.930555555555556e-05,
      "loss": 0.002,
      "step": 1250
    },
    {
      "epoch": 0.028,
      "grad_norm": 0.2790423333644867,
      "learning_rate": 4.93e-05,
      "loss": 0.0017,
      "step": 1260
    },
    {
      "epoch": 0.02822222222222222,
      "grad_norm": 0.6200277209281921,
      "learning_rate": 4.929444444444445e-05,
      "loss": 0.0024,
      "step": 1270
    },
    {
      "epoch": 0.028444444444444446,
      "grad_norm": 0.4869265854358673,
      "learning_rate": 4.928888888888889e-05,
      "loss": 0.0023,
      "step": 1280
    },
    {
      "epoch": 0.028666666666666667,
      "grad_norm": 0.3728191554546356,
      "learning_rate": 4.9283333333333336e-05,
      "loss": 0.0026,
      "step": 1290
    },
    {
      "epoch": 0.028888888888888888,
      "grad_norm": 0.29652512073516846,
      "learning_rate": 4.927777777777778e-05,
      "loss": 0.003,
      "step": 1300
    },
    {
      "epoch": 0.029111111111111112,
      "grad_norm": 0.3070666491985321,
      "learning_rate": 4.9272222222222223e-05,
      "loss": 0.0038,
      "step": 1310
    },
    {
      "epoch": 0.029333333333333333,
      "grad_norm": 0.4780174791812897,
      "learning_rate": 4.926666666666667e-05,
      "loss": 0.0024,
      "step": 1320
    },
    {
      "epoch": 0.029555555555555557,
      "grad_norm": 0.5219339728355408,
      "learning_rate": 4.926111111111111e-05,
      "loss": 0.0025,
      "step": 1330
    },
    {
      "epoch": 0.029777777777777778,
      "grad_norm": 0.19377703964710236,
      "learning_rate": 4.925555555555556e-05,
      "loss": 0.0028,
      "step": 1340
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.1924518644809723,
      "learning_rate": 4.9250000000000004e-05,
      "loss": 0.0033,
      "step": 1350
    },
    {
      "epoch": 0.030222222222222223,
      "grad_norm": 0.25878390669822693,
      "learning_rate": 4.924444444444445e-05,
      "loss": 0.0022,
      "step": 1360
    },
    {
      "epoch": 0.030444444444444444,
      "grad_norm": 0.3552412986755371,
      "learning_rate": 4.923888888888889e-05,
      "loss": 0.0026,
      "step": 1370
    },
    {
      "epoch": 0.030666666666666665,
      "grad_norm": 0.2143046259880066,
      "learning_rate": 4.9233333333333335e-05,
      "loss": 0.0032,
      "step": 1380
    },
    {
      "epoch": 0.03088888888888889,
      "grad_norm": 0.23252370953559875,
      "learning_rate": 4.922777777777778e-05,
      "loss": 0.0025,
      "step": 1390
    },
    {
      "epoch": 0.03111111111111111,
      "grad_norm": 0.12518000602722168,
      "learning_rate": 4.922222222222222e-05,
      "loss": 0.0026,
      "step": 1400
    },
    {
      "epoch": 0.03133333333333333,
      "grad_norm": 0.38373103737831116,
      "learning_rate": 4.9216666666666666e-05,
      "loss": 0.0025,
      "step": 1410
    },
    {
      "epoch": 0.03155555555555556,
      "grad_norm": 0.09537013620138168,
      "learning_rate": 4.9211111111111116e-05,
      "loss": 0.0037,
      "step": 1420
    },
    {
      "epoch": 0.03177777777777778,
      "grad_norm": 0.0892779529094696,
      "learning_rate": 4.920555555555556e-05,
      "loss": 0.003,
      "step": 1430
    },
    {
      "epoch": 0.032,
      "grad_norm": 0.20636393129825592,
      "learning_rate": 4.92e-05,
      "loss": 0.0042,
      "step": 1440
    },
    {
      "epoch": 0.03222222222222222,
      "grad_norm": 0.23411022126674652,
      "learning_rate": 4.919444444444445e-05,
      "loss": 0.0029,
      "step": 1450
    },
    {
      "epoch": 0.03244444444444444,
      "grad_norm": 0.1750851273536682,
      "learning_rate": 4.918888888888889e-05,
      "loss": 0.0025,
      "step": 1460
    },
    {
      "epoch": 0.03266666666666666,
      "grad_norm": 0.23074260354042053,
      "learning_rate": 4.9183333333333334e-05,
      "loss": 0.0026,
      "step": 1470
    },
    {
      "epoch": 0.03288888888888889,
      "grad_norm": 0.2777850031852722,
      "learning_rate": 4.917777777777778e-05,
      "loss": 0.0023,
      "step": 1480
    },
    {
      "epoch": 0.03311111111111111,
      "grad_norm": 0.4295497536659241,
      "learning_rate": 4.917222222222223e-05,
      "loss": 0.002,
      "step": 1490
    },
    {
      "epoch": 0.03333333333333333,
      "grad_norm": 0.20749026536941528,
      "learning_rate": 4.9166666666666665e-05,
      "loss": 0.0046,
      "step": 1500
    },
    {
      "epoch": 0.033555555555555554,
      "grad_norm": 0.397911936044693,
      "learning_rate": 4.9161111111111115e-05,
      "loss": 0.0026,
      "step": 1510
    },
    {
      "epoch": 0.033777777777777775,
      "grad_norm": 0.2624588906764984,
      "learning_rate": 4.915555555555556e-05,
      "loss": 0.0023,
      "step": 1520
    },
    {
      "epoch": 0.034,
      "grad_norm": 0.30708858370780945,
      "learning_rate": 4.915e-05,
      "loss": 0.002,
      "step": 1530
    },
    {
      "epoch": 0.03422222222222222,
      "grad_norm": 0.15910769999027252,
      "learning_rate": 4.9144444444444446e-05,
      "loss": 0.0018,
      "step": 1540
    },
    {
      "epoch": 0.034444444444444444,
      "grad_norm": 0.5939533710479736,
      "learning_rate": 4.913888888888889e-05,
      "loss": 0.0016,
      "step": 1550
    },
    {
      "epoch": 0.034666666666666665,
      "grad_norm": 0.662019670009613,
      "learning_rate": 4.913333333333334e-05,
      "loss": 0.0022,
      "step": 1560
    },
    {
      "epoch": 0.034888888888888886,
      "grad_norm": 0.12827898561954498,
      "learning_rate": 4.9127777777777776e-05,
      "loss": 0.0025,
      "step": 1570
    },
    {
      "epoch": 0.035111111111111114,
      "grad_norm": 1.1246353387832642,
      "learning_rate": 4.912222222222223e-05,
      "loss": 0.0024,
      "step": 1580
    },
    {
      "epoch": 0.035333333333333335,
      "grad_norm": 0.29279187321662903,
      "learning_rate": 4.9116666666666663e-05,
      "loss": 0.0034,
      "step": 1590
    },
    {
      "epoch": 0.035555555555555556,
      "grad_norm": 0.2554103136062622,
      "learning_rate": 4.9111111111111114e-05,
      "loss": 0.0019,
      "step": 1600
    },
    {
      "epoch": 0.035777777777777776,
      "grad_norm": 0.12698066234588623,
      "learning_rate": 4.910555555555556e-05,
      "loss": 0.003,
      "step": 1610
    },
    {
      "epoch": 0.036,
      "grad_norm": 0.47365331649780273,
      "learning_rate": 4.91e-05,
      "loss": 0.0022,
      "step": 1620
    },
    {
      "epoch": 0.036222222222222225,
      "grad_norm": 0.6128683686256409,
      "learning_rate": 4.909444444444445e-05,
      "loss": 0.0027,
      "step": 1630
    },
    {
      "epoch": 0.036444444444444446,
      "grad_norm": 0.23044432699680328,
      "learning_rate": 4.908888888888889e-05,
      "loss": 0.003,
      "step": 1640
    },
    {
      "epoch": 0.03666666666666667,
      "grad_norm": 0.3283839523792267,
      "learning_rate": 4.908333333333334e-05,
      "loss": 0.0024,
      "step": 1650
    },
    {
      "epoch": 0.03688888888888889,
      "grad_norm": 0.48383140563964844,
      "learning_rate": 4.9077777777777775e-05,
      "loss": 0.0024,
      "step": 1660
    },
    {
      "epoch": 0.03711111111111111,
      "grad_norm": 0.35002923011779785,
      "learning_rate": 4.9072222222222225e-05,
      "loss": 0.0029,
      "step": 1670
    },
    {
      "epoch": 0.037333333333333336,
      "grad_norm": 0.4710768759250641,
      "learning_rate": 4.906666666666667e-05,
      "loss": 0.0023,
      "step": 1680
    },
    {
      "epoch": 0.03755555555555556,
      "grad_norm": 0.3583163022994995,
      "learning_rate": 4.906111111111111e-05,
      "loss": 0.0019,
      "step": 1690
    },
    {
      "epoch": 0.03777777777777778,
      "grad_norm": 0.8728553056716919,
      "learning_rate": 4.905555555555556e-05,
      "loss": 0.0026,
      "step": 1700
    },
    {
      "epoch": 0.038,
      "grad_norm": 0.30611348152160645,
      "learning_rate": 4.905e-05,
      "loss": 0.0022,
      "step": 1710
    },
    {
      "epoch": 0.03822222222222222,
      "grad_norm": 0.2657378315925598,
      "learning_rate": 4.904444444444445e-05,
      "loss": 0.0033,
      "step": 1720
    },
    {
      "epoch": 0.03844444444444445,
      "grad_norm": 0.07540819048881531,
      "learning_rate": 4.903888888888889e-05,
      "loss": 0.0024,
      "step": 1730
    },
    {
      "epoch": 0.03866666666666667,
      "grad_norm": 0.36750274896621704,
      "learning_rate": 4.903333333333334e-05,
      "loss": 0.002,
      "step": 1740
    },
    {
      "epoch": 0.03888888888888889,
      "grad_norm": 0.28588175773620605,
      "learning_rate": 4.902777777777778e-05,
      "loss": 0.0025,
      "step": 1750
    },
    {
      "epoch": 0.03911111111111111,
      "grad_norm": 0.510310709476471,
      "learning_rate": 4.9022222222222224e-05,
      "loss": 0.0021,
      "step": 1760
    },
    {
      "epoch": 0.03933333333333333,
      "grad_norm": 0.09178324043750763,
      "learning_rate": 4.901666666666667e-05,
      "loss": 0.0024,
      "step": 1770
    },
    {
      "epoch": 0.03955555555555555,
      "grad_norm": 0.2258106917142868,
      "learning_rate": 4.901111111111111e-05,
      "loss": 0.0023,
      "step": 1780
    },
    {
      "epoch": 0.03977777777777778,
      "grad_norm": 0.5278077721595764,
      "learning_rate": 4.900555555555556e-05,
      "loss": 0.0029,
      "step": 1790
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.1396147757768631,
      "learning_rate": 4.9e-05,
      "loss": 0.0023,
      "step": 1800
    },
    {
      "epoch": 0.04022222222222222,
      "grad_norm": 0.25802332162857056,
      "learning_rate": 4.899444444444445e-05,
      "loss": 0.0026,
      "step": 1810
    },
    {
      "epoch": 0.04044444444444444,
      "grad_norm": 0.20102955400943756,
      "learning_rate": 4.898888888888889e-05,
      "loss": 0.003,
      "step": 1820
    },
    {
      "epoch": 0.04066666666666666,
      "grad_norm": 0.5657089352607727,
      "learning_rate": 4.8983333333333336e-05,
      "loss": 0.0022,
      "step": 1830
    },
    {
      "epoch": 0.04088888888888889,
      "grad_norm": 0.6954110264778137,
      "learning_rate": 4.897777777777778e-05,
      "loss": 0.0021,
      "step": 1840
    },
    {
      "epoch": 0.04111111111111111,
      "grad_norm": 0.36526915431022644,
      "learning_rate": 4.897222222222222e-05,
      "loss": 0.0028,
      "step": 1850
    },
    {
      "epoch": 0.04133333333333333,
      "grad_norm": 0.16089729964733124,
      "learning_rate": 4.8966666666666667e-05,
      "loss": 0.003,
      "step": 1860
    },
    {
      "epoch": 0.041555555555555554,
      "grad_norm": 0.10544057190418243,
      "learning_rate": 4.896111111111111e-05,
      "loss": 0.0022,
      "step": 1870
    },
    {
      "epoch": 0.041777777777777775,
      "grad_norm": 0.5724382996559143,
      "learning_rate": 4.895555555555556e-05,
      "loss": 0.002,
      "step": 1880
    },
    {
      "epoch": 0.042,
      "grad_norm": 0.37892207503318787,
      "learning_rate": 4.8950000000000004e-05,
      "loss": 0.002,
      "step": 1890
    },
    {
      "epoch": 0.042222222222222223,
      "grad_norm": 0.20810653269290924,
      "learning_rate": 4.894444444444445e-05,
      "loss": 0.0026,
      "step": 1900
    },
    {
      "epoch": 0.042444444444444444,
      "grad_norm": 0.40484002232551575,
      "learning_rate": 4.893888888888889e-05,
      "loss": 0.002,
      "step": 1910
    },
    {
      "epoch": 0.042666666666666665,
      "grad_norm": 0.18351687490940094,
      "learning_rate": 4.8933333333333335e-05,
      "loss": 0.0021,
      "step": 1920
    },
    {
      "epoch": 0.042888888888888886,
      "grad_norm": 0.308232843875885,
      "learning_rate": 4.892777777777778e-05,
      "loss": 0.0032,
      "step": 1930
    },
    {
      "epoch": 0.043111111111111114,
      "grad_norm": 0.4264993369579315,
      "learning_rate": 4.892222222222222e-05,
      "loss": 0.0025,
      "step": 1940
    },
    {
      "epoch": 0.043333333333333335,
      "grad_norm": 0.370993047952652,
      "learning_rate": 4.891666666666667e-05,
      "loss": 0.002,
      "step": 1950
    },
    {
      "epoch": 0.043555555555555556,
      "grad_norm": 0.2035728543996811,
      "learning_rate": 4.8911111111111116e-05,
      "loss": 0.002,
      "step": 1960
    },
    {
      "epoch": 0.04377777777777778,
      "grad_norm": 0.5475675463676453,
      "learning_rate": 4.890555555555556e-05,
      "loss": 0.0027,
      "step": 1970
    },
    {
      "epoch": 0.044,
      "grad_norm": 0.5180423259735107,
      "learning_rate": 4.89e-05,
      "loss": 0.002,
      "step": 1980
    },
    {
      "epoch": 0.044222222222222225,
      "grad_norm": 0.44806572794914246,
      "learning_rate": 4.8894444444444446e-05,
      "loss": 0.0021,
      "step": 1990
    },
    {
      "epoch": 0.044444444444444446,
      "grad_norm": 0.4453357458114624,
      "learning_rate": 4.888888888888889e-05,
      "loss": 0.0027,
      "step": 2000
    },
    {
      "epoch": 0.04466666666666667,
      "grad_norm": 0.23251153528690338,
      "learning_rate": 4.8883333333333333e-05,
      "loss": 0.0021,
      "step": 2010
    },
    {
      "epoch": 0.04488888888888889,
      "grad_norm": 0.2754266858100891,
      "learning_rate": 4.887777777777778e-05,
      "loss": 0.0021,
      "step": 2020
    },
    {
      "epoch": 0.04511111111111111,
      "grad_norm": 0.10001475363969803,
      "learning_rate": 4.887222222222223e-05,
      "loss": 0.0028,
      "step": 2030
    },
    {
      "epoch": 0.04533333333333334,
      "grad_norm": 0.45101550221443176,
      "learning_rate": 4.886666666666667e-05,
      "loss": 0.0026,
      "step": 2040
    },
    {
      "epoch": 0.04555555555555556,
      "grad_norm": 0.5487196445465088,
      "learning_rate": 4.8861111111111114e-05,
      "loss": 0.002,
      "step": 2050
    },
    {
      "epoch": 0.04577777777777778,
      "grad_norm": 0.25506043434143066,
      "learning_rate": 4.885555555555556e-05,
      "loss": 0.0031,
      "step": 2060
    },
    {
      "epoch": 0.046,
      "grad_norm": 0.19712430238723755,
      "learning_rate": 4.885e-05,
      "loss": 0.0028,
      "step": 2070
    },
    {
      "epoch": 0.04622222222222222,
      "grad_norm": 0.40182778239250183,
      "learning_rate": 4.8844444444444445e-05,
      "loss": 0.0025,
      "step": 2080
    },
    {
      "epoch": 0.04644444444444444,
      "grad_norm": 0.6671035885810852,
      "learning_rate": 4.883888888888889e-05,
      "loss": 0.0022,
      "step": 2090
    },
    {
      "epoch": 0.04666666666666667,
      "grad_norm": 0.1386437863111496,
      "learning_rate": 4.883333333333334e-05,
      "loss": 0.0028,
      "step": 2100
    },
    {
      "epoch": 0.04688888888888889,
      "grad_norm": 0.6519395709037781,
      "learning_rate": 4.8827777777777776e-05,
      "loss": 0.0025,
      "step": 2110
    },
    {
      "epoch": 0.04711111111111111,
      "grad_norm": 0.13412417471408844,
      "learning_rate": 4.8822222222222226e-05,
      "loss": 0.0022,
      "step": 2120
    },
    {
      "epoch": 0.04733333333333333,
      "grad_norm": 0.27781450748443604,
      "learning_rate": 4.881666666666667e-05,
      "loss": 0.0021,
      "step": 2130
    },
    {
      "epoch": 0.04755555555555555,
      "grad_norm": 0.07311749458312988,
      "learning_rate": 4.881111111111111e-05,
      "loss": 0.0022,
      "step": 2140
    },
    {
      "epoch": 0.04777777777777778,
      "grad_norm": 0.265307754278183,
      "learning_rate": 4.880555555555556e-05,
      "loss": 0.0024,
      "step": 2150
    },
    {
      "epoch": 0.048,
      "grad_norm": 0.10667604207992554,
      "learning_rate": 4.88e-05,
      "loss": 0.0019,
      "step": 2160
    },
    {
      "epoch": 0.04822222222222222,
      "grad_norm": 0.33462071418762207,
      "learning_rate": 4.879444444444445e-05,
      "loss": 0.0021,
      "step": 2170
    },
    {
      "epoch": 0.04844444444444444,
      "grad_norm": 0.7789852023124695,
      "learning_rate": 4.878888888888889e-05,
      "loss": 0.0026,
      "step": 2180
    },
    {
      "epoch": 0.048666666666666664,
      "grad_norm": 0.1981659233570099,
      "learning_rate": 4.878333333333334e-05,
      "loss": 0.0022,
      "step": 2190
    },
    {
      "epoch": 0.04888888888888889,
      "grad_norm": 0.6322519183158875,
      "learning_rate": 4.8777777777777775e-05,
      "loss": 0.0019,
      "step": 2200
    },
    {
      "epoch": 0.04911111111111111,
      "grad_norm": 0.2876902222633362,
      "learning_rate": 4.8772222222222225e-05,
      "loss": 0.0021,
      "step": 2210
    },
    {
      "epoch": 0.04933333333333333,
      "grad_norm": 0.42899206280708313,
      "learning_rate": 4.876666666666667e-05,
      "loss": 0.0019,
      "step": 2220
    },
    {
      "epoch": 0.049555555555555554,
      "grad_norm": 0.4991787075996399,
      "learning_rate": 4.876111111111111e-05,
      "loss": 0.0023,
      "step": 2230
    },
    {
      "epoch": 0.049777777777777775,
      "grad_norm": 0.2209697961807251,
      "learning_rate": 4.875555555555556e-05,
      "loss": 0.0022,
      "step": 2240
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.09507464617490768,
      "learning_rate": 4.875e-05,
      "loss": 0.0024,
      "step": 2250
    },
    {
      "epoch": 0.050222222222222224,
      "grad_norm": 0.09614235907793045,
      "learning_rate": 4.874444444444445e-05,
      "loss": 0.0027,
      "step": 2260
    },
    {
      "epoch": 0.050444444444444445,
      "grad_norm": 0.30721554160118103,
      "learning_rate": 4.8738888888888886e-05,
      "loss": 0.0029,
      "step": 2270
    },
    {
      "epoch": 0.050666666666666665,
      "grad_norm": 0.5685584545135498,
      "learning_rate": 4.8733333333333337e-05,
      "loss": 0.003,
      "step": 2280
    },
    {
      "epoch": 0.050888888888888886,
      "grad_norm": 0.1909579038619995,
      "learning_rate": 4.872777777777778e-05,
      "loss": 0.002,
      "step": 2290
    },
    {
      "epoch": 0.051111111111111114,
      "grad_norm": 0.4070048928260803,
      "learning_rate": 4.8722222222222224e-05,
      "loss": 0.0021,
      "step": 2300
    },
    {
      "epoch": 0.051333333333333335,
      "grad_norm": 0.2571655213832855,
      "learning_rate": 4.8716666666666674e-05,
      "loss": 0.0024,
      "step": 2310
    },
    {
      "epoch": 0.051555555555555556,
      "grad_norm": 0.32649749517440796,
      "learning_rate": 4.871111111111111e-05,
      "loss": 0.0017,
      "step": 2320
    },
    {
      "epoch": 0.05177777777777778,
      "grad_norm": 0.12676094472408295,
      "learning_rate": 4.870555555555556e-05,
      "loss": 0.0021,
      "step": 2330
    },
    {
      "epoch": 0.052,
      "grad_norm": 0.48652565479278564,
      "learning_rate": 4.87e-05,
      "loss": 0.0018,
      "step": 2340
    },
    {
      "epoch": 0.052222222222222225,
      "grad_norm": 0.8293614387512207,
      "learning_rate": 4.869444444444445e-05,
      "loss": 0.0026,
      "step": 2350
    },
    {
      "epoch": 0.052444444444444446,
      "grad_norm": 0.09335722774267197,
      "learning_rate": 4.868888888888889e-05,
      "loss": 0.0018,
      "step": 2360
    },
    {
      "epoch": 0.05266666666666667,
      "grad_norm": 0.6783593893051147,
      "learning_rate": 4.8683333333333335e-05,
      "loss": 0.0025,
      "step": 2370
    },
    {
      "epoch": 0.05288888888888889,
      "grad_norm": 0.2316983938217163,
      "learning_rate": 4.867777777777778e-05,
      "loss": 0.0024,
      "step": 2380
    },
    {
      "epoch": 0.05311111111111111,
      "grad_norm": 0.6489927768707275,
      "learning_rate": 4.867222222222222e-05,
      "loss": 0.002,
      "step": 2390
    },
    {
      "epoch": 0.05333333333333334,
      "grad_norm": 0.18456819653511047,
      "learning_rate": 4.866666666666667e-05,
      "loss": 0.0037,
      "step": 2400
    },
    {
      "epoch": 0.05355555555555556,
      "grad_norm": 0.3874620199203491,
      "learning_rate": 4.866111111111111e-05,
      "loss": 0.0023,
      "step": 2410
    },
    {
      "epoch": 0.05377777777777778,
      "grad_norm": 0.08815477788448334,
      "learning_rate": 4.865555555555556e-05,
      "loss": 0.0022,
      "step": 2420
    },
    {
      "epoch": 0.054,
      "grad_norm": 0.08928816765546799,
      "learning_rate": 4.8650000000000003e-05,
      "loss": 0.0024,
      "step": 2430
    },
    {
      "epoch": 0.05422222222222222,
      "grad_norm": 0.15888360142707825,
      "learning_rate": 4.864444444444445e-05,
      "loss": 0.0029,
      "step": 2440
    },
    {
      "epoch": 0.05444444444444444,
      "grad_norm": 0.4670133888721466,
      "learning_rate": 4.863888888888889e-05,
      "loss": 0.0021,
      "step": 2450
    },
    {
      "epoch": 0.05466666666666667,
      "grad_norm": 0.11157196760177612,
      "learning_rate": 4.8633333333333334e-05,
      "loss": 0.0021,
      "step": 2460
    },
    {
      "epoch": 0.05488888888888889,
      "grad_norm": 0.20061391592025757,
      "learning_rate": 4.862777777777778e-05,
      "loss": 0.0026,
      "step": 2470
    },
    {
      "epoch": 0.05511111111111111,
      "grad_norm": 0.9060165882110596,
      "learning_rate": 4.862222222222222e-05,
      "loss": 0.0026,
      "step": 2480
    },
    {
      "epoch": 0.05533333333333333,
      "grad_norm": 0.1746753454208374,
      "learning_rate": 4.861666666666667e-05,
      "loss": 0.0034,
      "step": 2490
    },
    {
      "epoch": 0.05555555555555555,
      "grad_norm": 0.8067827224731445,
      "learning_rate": 4.8611111111111115e-05,
      "loss": 0.003,
      "step": 2500
    },
    {
      "epoch": 0.05577777777777778,
      "grad_norm": 0.44341564178466797,
      "learning_rate": 4.860555555555556e-05,
      "loss": 0.0027,
      "step": 2510
    },
    {
      "epoch": 0.056,
      "grad_norm": 0.21443143486976624,
      "learning_rate": 4.86e-05,
      "loss": 0.0031,
      "step": 2520
    },
    {
      "epoch": 0.05622222222222222,
      "grad_norm": 0.19867828488349915,
      "learning_rate": 4.8594444444444446e-05,
      "loss": 0.0033,
      "step": 2530
    },
    {
      "epoch": 0.05644444444444444,
      "grad_norm": 0.3927657902240753,
      "learning_rate": 4.858888888888889e-05,
      "loss": 0.0025,
      "step": 2540
    },
    {
      "epoch": 0.056666666666666664,
      "grad_norm": 0.21444600820541382,
      "learning_rate": 4.858333333333333e-05,
      "loss": 0.0024,
      "step": 2550
    },
    {
      "epoch": 0.05688888888888889,
      "grad_norm": 0.49846842885017395,
      "learning_rate": 4.8577777777777776e-05,
      "loss": 0.0023,
      "step": 2560
    },
    {
      "epoch": 0.05711111111111111,
      "grad_norm": 0.16116438806056976,
      "learning_rate": 4.857222222222223e-05,
      "loss": 0.0025,
      "step": 2570
    },
    {
      "epoch": 0.05733333333333333,
      "grad_norm": 0.5744736790657043,
      "learning_rate": 4.856666666666667e-05,
      "loss": 0.0019,
      "step": 2580
    },
    {
      "epoch": 0.057555555555555554,
      "grad_norm": 0.23500892519950867,
      "learning_rate": 4.8561111111111114e-05,
      "loss": 0.0026,
      "step": 2590
    },
    {
      "epoch": 0.057777777777777775,
      "grad_norm": 0.2025858461856842,
      "learning_rate": 4.855555555555556e-05,
      "loss": 0.0024,
      "step": 2600
    },
    {
      "epoch": 0.058,
      "grad_norm": 0.5873250961303711,
      "learning_rate": 4.855e-05,
      "loss": 0.0031,
      "step": 2610
    },
    {
      "epoch": 0.058222222222222224,
      "grad_norm": 0.21893630921840668,
      "learning_rate": 4.8544444444444445e-05,
      "loss": 0.004,
      "step": 2620
    },
    {
      "epoch": 0.058444444444444445,
      "grad_norm": 0.12706400454044342,
      "learning_rate": 4.853888888888889e-05,
      "loss": 0.0022,
      "step": 2630
    },
    {
      "epoch": 0.058666666666666666,
      "grad_norm": 0.1083855926990509,
      "learning_rate": 4.853333333333334e-05,
      "loss": 0.0025,
      "step": 2640
    },
    {
      "epoch": 0.058888888888888886,
      "grad_norm": 0.08042916655540466,
      "learning_rate": 4.8527777777777775e-05,
      "loss": 0.003,
      "step": 2650
    },
    {
      "epoch": 0.059111111111111114,
      "grad_norm": 0.5113003849983215,
      "learning_rate": 4.8522222222222226e-05,
      "loss": 0.003,
      "step": 2660
    },
    {
      "epoch": 0.059333333333333335,
      "grad_norm": 0.10556299984455109,
      "learning_rate": 4.851666666666667e-05,
      "loss": 0.0032,
      "step": 2670
    },
    {
      "epoch": 0.059555555555555556,
      "grad_norm": 0.08553758263587952,
      "learning_rate": 4.851111111111111e-05,
      "loss": 0.0018,
      "step": 2680
    },
    {
      "epoch": 0.05977777777777778,
      "grad_norm": 0.23908311128616333,
      "learning_rate": 4.8505555555555556e-05,
      "loss": 0.0024,
      "step": 2690
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.2761317491531372,
      "learning_rate": 4.85e-05,
      "loss": 0.0037,
      "step": 2700
    },
    {
      "epoch": 0.060222222222222226,
      "grad_norm": 0.11688232421875,
      "learning_rate": 4.849444444444445e-05,
      "loss": 0.0026,
      "step": 2710
    },
    {
      "epoch": 0.060444444444444446,
      "grad_norm": 0.2364760935306549,
      "learning_rate": 4.848888888888889e-05,
      "loss": 0.0025,
      "step": 2720
    },
    {
      "epoch": 0.06066666666666667,
      "grad_norm": 0.292372465133667,
      "learning_rate": 4.848333333333334e-05,
      "loss": 0.0024,
      "step": 2730
    },
    {
      "epoch": 0.06088888888888889,
      "grad_norm": 0.15873035788536072,
      "learning_rate": 4.847777777777778e-05,
      "loss": 0.0035,
      "step": 2740
    },
    {
      "epoch": 0.06111111111111111,
      "grad_norm": 0.3392057716846466,
      "learning_rate": 4.8472222222222224e-05,
      "loss": 0.0019,
      "step": 2750
    },
    {
      "epoch": 0.06133333333333333,
      "grad_norm": 0.22572417557239532,
      "learning_rate": 4.8466666666666675e-05,
      "loss": 0.0024,
      "step": 2760
    },
    {
      "epoch": 0.06155555555555556,
      "grad_norm": 0.21147437393665314,
      "learning_rate": 4.846111111111111e-05,
      "loss": 0.0021,
      "step": 2770
    },
    {
      "epoch": 0.06177777777777778,
      "grad_norm": 0.2863698899745941,
      "learning_rate": 4.845555555555556e-05,
      "loss": 0.0027,
      "step": 2780
    },
    {
      "epoch": 0.062,
      "grad_norm": 0.28784504532814026,
      "learning_rate": 4.845e-05,
      "loss": 0.0023,
      "step": 2790
    },
    {
      "epoch": 0.06222222222222222,
      "grad_norm": 0.29738742113113403,
      "learning_rate": 4.844444444444445e-05,
      "loss": 0.0033,
      "step": 2800
    },
    {
      "epoch": 0.06244444444444444,
      "grad_norm": 0.3027525842189789,
      "learning_rate": 4.843888888888889e-05,
      "loss": 0.0034,
      "step": 2810
    },
    {
      "epoch": 0.06266666666666666,
      "grad_norm": 0.32155200839042664,
      "learning_rate": 4.8433333333333336e-05,
      "loss": 0.0021,
      "step": 2820
    },
    {
      "epoch": 0.06288888888888888,
      "grad_norm": 0.06759725511074066,
      "learning_rate": 4.842777777777778e-05,
      "loss": 0.0022,
      "step": 2830
    },
    {
      "epoch": 0.06311111111111112,
      "grad_norm": 0.4384385943412781,
      "learning_rate": 4.842222222222222e-05,
      "loss": 0.0025,
      "step": 2840
    },
    {
      "epoch": 0.06333333333333334,
      "grad_norm": 0.12176590412855148,
      "learning_rate": 4.8416666666666673e-05,
      "loss": 0.0023,
      "step": 2850
    },
    {
      "epoch": 0.06355555555555556,
      "grad_norm": 0.3115752041339874,
      "learning_rate": 4.841111111111111e-05,
      "loss": 0.0022,
      "step": 2860
    },
    {
      "epoch": 0.06377777777777778,
      "grad_norm": 0.42919546365737915,
      "learning_rate": 4.840555555555556e-05,
      "loss": 0.0024,
      "step": 2870
    },
    {
      "epoch": 0.064,
      "grad_norm": 0.08960189670324326,
      "learning_rate": 4.8400000000000004e-05,
      "loss": 0.0024,
      "step": 2880
    },
    {
      "epoch": 0.06422222222222222,
      "grad_norm": 0.249799907207489,
      "learning_rate": 4.839444444444445e-05,
      "loss": 0.0027,
      "step": 2890
    },
    {
      "epoch": 0.06444444444444444,
      "grad_norm": 0.38234373927116394,
      "learning_rate": 4.838888888888889e-05,
      "loss": 0.0026,
      "step": 2900
    },
    {
      "epoch": 0.06466666666666666,
      "grad_norm": 0.30922260880470276,
      "learning_rate": 4.8383333333333335e-05,
      "loss": 0.0026,
      "step": 2910
    },
    {
      "epoch": 0.06488888888888888,
      "grad_norm": 0.5116846561431885,
      "learning_rate": 4.837777777777778e-05,
      "loss": 0.0019,
      "step": 2920
    },
    {
      "epoch": 0.0651111111111111,
      "grad_norm": 0.10817784070968628,
      "learning_rate": 4.837222222222222e-05,
      "loss": 0.0019,
      "step": 2930
    },
    {
      "epoch": 0.06533333333333333,
      "grad_norm": 0.1366407871246338,
      "learning_rate": 4.836666666666667e-05,
      "loss": 0.0023,
      "step": 2940
    },
    {
      "epoch": 0.06555555555555556,
      "grad_norm": 0.6365175247192383,
      "learning_rate": 4.8361111111111116e-05,
      "loss": 0.0024,
      "step": 2950
    },
    {
      "epoch": 0.06577777777777778,
      "grad_norm": 0.5295706391334534,
      "learning_rate": 4.835555555555556e-05,
      "loss": 0.002,
      "step": 2960
    },
    {
      "epoch": 0.066,
      "grad_norm": 0.6378039121627808,
      "learning_rate": 4.835e-05,
      "loss": 0.0022,
      "step": 2970
    },
    {
      "epoch": 0.06622222222222222,
      "grad_norm": 0.06851588189601898,
      "learning_rate": 4.8344444444444447e-05,
      "loss": 0.002,
      "step": 2980
    },
    {
      "epoch": 0.06644444444444444,
      "grad_norm": 0.08001510798931122,
      "learning_rate": 4.833888888888889e-05,
      "loss": 0.0035,
      "step": 2990
    },
    {
      "epoch": 0.06666666666666667,
      "grad_norm": 0.33710622787475586,
      "learning_rate": 4.8333333333333334e-05,
      "loss": 0.002,
      "step": 3000
    },
    {
      "epoch": 0.06688888888888889,
      "grad_norm": 0.09814394265413284,
      "learning_rate": 4.832777777777778e-05,
      "loss": 0.0024,
      "step": 3010
    },
    {
      "epoch": 0.06711111111111111,
      "grad_norm": 0.2181451916694641,
      "learning_rate": 4.832222222222223e-05,
      "loss": 0.0025,
      "step": 3020
    },
    {
      "epoch": 0.06733333333333333,
      "grad_norm": 0.2788592576980591,
      "learning_rate": 4.831666666666667e-05,
      "loss": 0.0026,
      "step": 3030
    },
    {
      "epoch": 0.06755555555555555,
      "grad_norm": 0.25305435061454773,
      "learning_rate": 4.8311111111111115e-05,
      "loss": 0.0018,
      "step": 3040
    },
    {
      "epoch": 0.06777777777777778,
      "grad_norm": 0.1303301453590393,
      "learning_rate": 4.830555555555556e-05,
      "loss": 0.0027,
      "step": 3050
    },
    {
      "epoch": 0.068,
      "grad_norm": 0.6951040625572205,
      "learning_rate": 4.83e-05,
      "loss": 0.0019,
      "step": 3060
    },
    {
      "epoch": 0.06822222222222223,
      "grad_norm": 0.2338755577802658,
      "learning_rate": 4.8294444444444445e-05,
      "loss": 0.0026,
      "step": 3070
    },
    {
      "epoch": 0.06844444444444445,
      "grad_norm": 0.20668120682239532,
      "learning_rate": 4.828888888888889e-05,
      "loss": 0.0026,
      "step": 3080
    },
    {
      "epoch": 0.06866666666666667,
      "grad_norm": 0.23419712483882904,
      "learning_rate": 4.828333333333334e-05,
      "loss": 0.0031,
      "step": 3090
    },
    {
      "epoch": 0.06888888888888889,
      "grad_norm": 0.5031658411026001,
      "learning_rate": 4.8277777777777776e-05,
      "loss": 0.0036,
      "step": 3100
    },
    {
      "epoch": 0.06911111111111111,
      "grad_norm": 0.09435942023992538,
      "learning_rate": 4.8272222222222226e-05,
      "loss": 0.0029,
      "step": 3110
    },
    {
      "epoch": 0.06933333333333333,
      "grad_norm": 0.8811589479446411,
      "learning_rate": 4.826666666666667e-05,
      "loss": 0.0018,
      "step": 3120
    },
    {
      "epoch": 0.06955555555555555,
      "grad_norm": 0.4622746706008911,
      "learning_rate": 4.8261111111111113e-05,
      "loss": 0.0021,
      "step": 3130
    },
    {
      "epoch": 0.06977777777777777,
      "grad_norm": 0.4002342224121094,
      "learning_rate": 4.825555555555556e-05,
      "loss": 0.0027,
      "step": 3140
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.42543303966522217,
      "learning_rate": 4.825e-05,
      "loss": 0.0044,
      "step": 3150
    },
    {
      "epoch": 0.07022222222222223,
      "grad_norm": 0.31656286120414734,
      "learning_rate": 4.824444444444445e-05,
      "loss": 0.0022,
      "step": 3160
    },
    {
      "epoch": 0.07044444444444445,
      "grad_norm": 0.159981369972229,
      "learning_rate": 4.823888888888889e-05,
      "loss": 0.0028,
      "step": 3170
    },
    {
      "epoch": 0.07066666666666667,
      "grad_norm": 0.20882345736026764,
      "learning_rate": 4.823333333333334e-05,
      "loss": 0.0043,
      "step": 3180
    },
    {
      "epoch": 0.07088888888888889,
      "grad_norm": 0.23334211111068726,
      "learning_rate": 4.822777777777778e-05,
      "loss": 0.003,
      "step": 3190
    },
    {
      "epoch": 0.07111111111111111,
      "grad_norm": 0.4052722156047821,
      "learning_rate": 4.8222222222222225e-05,
      "loss": 0.0031,
      "step": 3200
    },
    {
      "epoch": 0.07133333333333333,
      "grad_norm": 0.6800134181976318,
      "learning_rate": 4.821666666666667e-05,
      "loss": 0.002,
      "step": 3210
    },
    {
      "epoch": 0.07155555555555555,
      "grad_norm": 0.5458373427391052,
      "learning_rate": 4.821111111111111e-05,
      "loss": 0.0023,
      "step": 3220
    },
    {
      "epoch": 0.07177777777777777,
      "grad_norm": 0.32230257987976074,
      "learning_rate": 4.820555555555556e-05,
      "loss": 0.002,
      "step": 3230
    },
    {
      "epoch": 0.072,
      "grad_norm": 0.6384418606758118,
      "learning_rate": 4.82e-05,
      "loss": 0.0025,
      "step": 3240
    },
    {
      "epoch": 0.07222222222222222,
      "grad_norm": 0.2624909281730652,
      "learning_rate": 4.819444444444445e-05,
      "loss": 0.003,
      "step": 3250
    },
    {
      "epoch": 0.07244444444444445,
      "grad_norm": 0.2569497525691986,
      "learning_rate": 4.8188888888888886e-05,
      "loss": 0.0019,
      "step": 3260
    },
    {
      "epoch": 0.07266666666666667,
      "grad_norm": 0.5199223756790161,
      "learning_rate": 4.818333333333334e-05,
      "loss": 0.0025,
      "step": 3270
    },
    {
      "epoch": 0.07288888888888889,
      "grad_norm": 0.15767967700958252,
      "learning_rate": 4.817777777777778e-05,
      "loss": 0.0027,
      "step": 3280
    },
    {
      "epoch": 0.07311111111111111,
      "grad_norm": 0.1340266466140747,
      "learning_rate": 4.8172222222222224e-05,
      "loss": 0.0029,
      "step": 3290
    },
    {
      "epoch": 0.07333333333333333,
      "grad_norm": 0.32428035140037537,
      "learning_rate": 4.8166666666666674e-05,
      "loss": 0.0027,
      "step": 3300
    },
    {
      "epoch": 0.07355555555555555,
      "grad_norm": 0.6082555651664734,
      "learning_rate": 4.816111111111111e-05,
      "loss": 0.0021,
      "step": 3310
    },
    {
      "epoch": 0.07377777777777778,
      "grad_norm": 0.35754576325416565,
      "learning_rate": 4.815555555555556e-05,
      "loss": 0.002,
      "step": 3320
    },
    {
      "epoch": 0.074,
      "grad_norm": 0.18766261637210846,
      "learning_rate": 4.815e-05,
      "loss": 0.0024,
      "step": 3330
    },
    {
      "epoch": 0.07422222222222222,
      "grad_norm": 0.2850710153579712,
      "learning_rate": 4.814444444444445e-05,
      "loss": 0.0025,
      "step": 3340
    },
    {
      "epoch": 0.07444444444444444,
      "grad_norm": 0.657513439655304,
      "learning_rate": 4.813888888888889e-05,
      "loss": 0.0025,
      "step": 3350
    },
    {
      "epoch": 0.07466666666666667,
      "grad_norm": 0.5076975226402283,
      "learning_rate": 4.8133333333333336e-05,
      "loss": 0.0021,
      "step": 3360
    },
    {
      "epoch": 0.0748888888888889,
      "grad_norm": 0.6184295415878296,
      "learning_rate": 4.8127777777777786e-05,
      "loss": 0.0027,
      "step": 3370
    },
    {
      "epoch": 0.07511111111111111,
      "grad_norm": 0.15415936708450317,
      "learning_rate": 4.812222222222222e-05,
      "loss": 0.0023,
      "step": 3380
    },
    {
      "epoch": 0.07533333333333334,
      "grad_norm": 0.2838314175605774,
      "learning_rate": 4.811666666666667e-05,
      "loss": 0.0028,
      "step": 3390
    },
    {
      "epoch": 0.07555555555555556,
      "grad_norm": 0.3814353346824646,
      "learning_rate": 4.811111111111111e-05,
      "loss": 0.0021,
      "step": 3400
    },
    {
      "epoch": 0.07577777777777778,
      "grad_norm": 0.3242916464805603,
      "learning_rate": 4.810555555555556e-05,
      "loss": 0.0045,
      "step": 3410
    },
    {
      "epoch": 0.076,
      "grad_norm": 0.176938995718956,
      "learning_rate": 4.8100000000000004e-05,
      "loss": 0.003,
      "step": 3420
    },
    {
      "epoch": 0.07622222222222222,
      "grad_norm": 0.10864792764186859,
      "learning_rate": 4.809444444444445e-05,
      "loss": 0.003,
      "step": 3430
    },
    {
      "epoch": 0.07644444444444444,
      "grad_norm": 0.21669051051139832,
      "learning_rate": 4.808888888888889e-05,
      "loss": 0.0019,
      "step": 3440
    },
    {
      "epoch": 0.07666666666666666,
      "grad_norm": 0.40716102719306946,
      "learning_rate": 4.8083333333333334e-05,
      "loss": 0.0031,
      "step": 3450
    },
    {
      "epoch": 0.0768888888888889,
      "grad_norm": 0.26766613125801086,
      "learning_rate": 4.8077777777777785e-05,
      "loss": 0.0026,
      "step": 3460
    },
    {
      "epoch": 0.07711111111111112,
      "grad_norm": 0.0881815254688263,
      "learning_rate": 4.807222222222222e-05,
      "loss": 0.0028,
      "step": 3470
    },
    {
      "epoch": 0.07733333333333334,
      "grad_norm": 0.3877483606338501,
      "learning_rate": 4.806666666666667e-05,
      "loss": 0.0019,
      "step": 3480
    },
    {
      "epoch": 0.07755555555555556,
      "grad_norm": 0.26899752020835876,
      "learning_rate": 4.8061111111111115e-05,
      "loss": 0.002,
      "step": 3490
    },
    {
      "epoch": 0.07777777777777778,
      "grad_norm": 0.26294025778770447,
      "learning_rate": 4.805555555555556e-05,
      "loss": 0.0021,
      "step": 3500
    },
    {
      "epoch": 0.078,
      "grad_norm": 0.36174145340919495,
      "learning_rate": 4.805e-05,
      "loss": 0.0041,
      "step": 3510
    },
    {
      "epoch": 0.07822222222222222,
      "grad_norm": 0.47623831033706665,
      "learning_rate": 4.8044444444444446e-05,
      "loss": 0.0029,
      "step": 3520
    },
    {
      "epoch": 0.07844444444444444,
      "grad_norm": 0.37139663100242615,
      "learning_rate": 4.803888888888889e-05,
      "loss": 0.0027,
      "step": 3530
    },
    {
      "epoch": 0.07866666666666666,
      "grad_norm": 0.5231442451477051,
      "learning_rate": 4.803333333333333e-05,
      "loss": 0.0028,
      "step": 3540
    },
    {
      "epoch": 0.07888888888888888,
      "grad_norm": 0.22803695499897003,
      "learning_rate": 4.8027777777777783e-05,
      "loss": 0.0028,
      "step": 3550
    },
    {
      "epoch": 0.0791111111111111,
      "grad_norm": 0.08848849684000015,
      "learning_rate": 4.802222222222223e-05,
      "loss": 0.0031,
      "step": 3560
    },
    {
      "epoch": 0.07933333333333334,
      "grad_norm": 0.14065806567668915,
      "learning_rate": 4.801666666666667e-05,
      "loss": 0.002,
      "step": 3570
    },
    {
      "epoch": 0.07955555555555556,
      "grad_norm": 0.2918705344200134,
      "learning_rate": 4.8011111111111114e-05,
      "loss": 0.0029,
      "step": 3580
    },
    {
      "epoch": 0.07977777777777778,
      "grad_norm": 0.15688394010066986,
      "learning_rate": 4.800555555555556e-05,
      "loss": 0.0029,
      "step": 3590
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.10236331820487976,
      "learning_rate": 4.8e-05,
      "loss": 0.0021,
      "step": 3600
    },
    {
      "epoch": 0.08022222222222222,
      "grad_norm": 0.11394805461168289,
      "learning_rate": 4.7994444444444445e-05,
      "loss": 0.0019,
      "step": 3610
    },
    {
      "epoch": 0.08044444444444444,
      "grad_norm": 0.6374033689498901,
      "learning_rate": 4.798888888888889e-05,
      "loss": 0.0029,
      "step": 3620
    },
    {
      "epoch": 0.08066666666666666,
      "grad_norm": 0.24692080914974213,
      "learning_rate": 4.798333333333334e-05,
      "loss": 0.0024,
      "step": 3630
    },
    {
      "epoch": 0.08088888888888889,
      "grad_norm": 0.11298120766878128,
      "learning_rate": 4.797777777777778e-05,
      "loss": 0.0027,
      "step": 3640
    },
    {
      "epoch": 0.0811111111111111,
      "grad_norm": 0.12251947075128555,
      "learning_rate": 4.7972222222222226e-05,
      "loss": 0.0027,
      "step": 3650
    },
    {
      "epoch": 0.08133333333333333,
      "grad_norm": 0.7221702933311462,
      "learning_rate": 4.796666666666667e-05,
      "loss": 0.0017,
      "step": 3660
    },
    {
      "epoch": 0.08155555555555556,
      "grad_norm": 0.4852449595928192,
      "learning_rate": 4.796111111111111e-05,
      "loss": 0.0026,
      "step": 3670
    },
    {
      "epoch": 0.08177777777777778,
      "grad_norm": 0.8688441514968872,
      "learning_rate": 4.7955555555555556e-05,
      "loss": 0.0019,
      "step": 3680
    },
    {
      "epoch": 0.082,
      "grad_norm": 0.5201417207717896,
      "learning_rate": 4.795e-05,
      "loss": 0.0022,
      "step": 3690
    },
    {
      "epoch": 0.08222222222222222,
      "grad_norm": 0.3259432315826416,
      "learning_rate": 4.794444444444445e-05,
      "loss": 0.0031,
      "step": 3700
    },
    {
      "epoch": 0.08244444444444445,
      "grad_norm": 0.1050436794757843,
      "learning_rate": 4.793888888888889e-05,
      "loss": 0.003,
      "step": 3710
    },
    {
      "epoch": 0.08266666666666667,
      "grad_norm": 0.17036758363246918,
      "learning_rate": 4.793333333333334e-05,
      "loss": 0.0052,
      "step": 3720
    },
    {
      "epoch": 0.08288888888888889,
      "grad_norm": 0.6591014862060547,
      "learning_rate": 4.792777777777778e-05,
      "loss": 0.0022,
      "step": 3730
    },
    {
      "epoch": 0.08311111111111111,
      "grad_norm": 0.366335928440094,
      "learning_rate": 4.7922222222222225e-05,
      "loss": 0.0028,
      "step": 3740
    },
    {
      "epoch": 0.08333333333333333,
      "grad_norm": 0.12046501785516739,
      "learning_rate": 4.791666666666667e-05,
      "loss": 0.0023,
      "step": 3750
    },
    {
      "epoch": 0.08355555555555555,
      "grad_norm": 0.396263986825943,
      "learning_rate": 4.791111111111111e-05,
      "loss": 0.0031,
      "step": 3760
    },
    {
      "epoch": 0.08377777777777778,
      "grad_norm": 0.16580171883106232,
      "learning_rate": 4.790555555555556e-05,
      "loss": 0.002,
      "step": 3770
    },
    {
      "epoch": 0.084,
      "grad_norm": 0.44159838557243347,
      "learning_rate": 4.79e-05,
      "loss": 0.0027,
      "step": 3780
    },
    {
      "epoch": 0.08422222222222223,
      "grad_norm": 0.39374056458473206,
      "learning_rate": 4.789444444444445e-05,
      "loss": 0.0029,
      "step": 3790
    },
    {
      "epoch": 0.08444444444444445,
      "grad_norm": 0.48423048853874207,
      "learning_rate": 4.7888888888888886e-05,
      "loss": 0.003,
      "step": 3800
    },
    {
      "epoch": 0.08466666666666667,
      "grad_norm": 0.40064486861228943,
      "learning_rate": 4.7883333333333336e-05,
      "loss": 0.0019,
      "step": 3810
    },
    {
      "epoch": 0.08488888888888889,
      "grad_norm": 0.15286526083946228,
      "learning_rate": 4.787777777777778e-05,
      "loss": 0.0033,
      "step": 3820
    },
    {
      "epoch": 0.08511111111111111,
      "grad_norm": 0.316430926322937,
      "learning_rate": 4.787222222222222e-05,
      "loss": 0.0024,
      "step": 3830
    },
    {
      "epoch": 0.08533333333333333,
      "grad_norm": 0.37712526321411133,
      "learning_rate": 4.7866666666666674e-05,
      "loss": 0.003,
      "step": 3840
    },
    {
      "epoch": 0.08555555555555555,
      "grad_norm": 0.2973676025867462,
      "learning_rate": 4.786111111111111e-05,
      "loss": 0.0028,
      "step": 3850
    },
    {
      "epoch": 0.08577777777777777,
      "grad_norm": 0.3367750644683838,
      "learning_rate": 4.785555555555556e-05,
      "loss": 0.0021,
      "step": 3860
    },
    {
      "epoch": 0.086,
      "grad_norm": 0.2106034755706787,
      "learning_rate": 4.785e-05,
      "loss": 0.002,
      "step": 3870
    },
    {
      "epoch": 0.08622222222222223,
      "grad_norm": 0.19576257467269897,
      "learning_rate": 4.784444444444445e-05,
      "loss": 0.0036,
      "step": 3880
    },
    {
      "epoch": 0.08644444444444445,
      "grad_norm": 0.22413839399814606,
      "learning_rate": 4.783888888888889e-05,
      "loss": 0.0027,
      "step": 3890
    },
    {
      "epoch": 0.08666666666666667,
      "grad_norm": 0.23833172023296356,
      "learning_rate": 4.7833333333333335e-05,
      "loss": 0.0018,
      "step": 3900
    },
    {
      "epoch": 0.08688888888888889,
      "grad_norm": 0.4601714313030243,
      "learning_rate": 4.7827777777777785e-05,
      "loss": 0.0027,
      "step": 3910
    },
    {
      "epoch": 0.08711111111111111,
      "grad_norm": 0.2549920082092285,
      "learning_rate": 4.782222222222222e-05,
      "loss": 0.0016,
      "step": 3920
    },
    {
      "epoch": 0.08733333333333333,
      "grad_norm": 0.7030780911445618,
      "learning_rate": 4.781666666666667e-05,
      "loss": 0.003,
      "step": 3930
    },
    {
      "epoch": 0.08755555555555555,
      "grad_norm": 0.2009430080652237,
      "learning_rate": 4.781111111111111e-05,
      "loss": 0.0043,
      "step": 3940
    },
    {
      "epoch": 0.08777777777777777,
      "grad_norm": 0.5873233675956726,
      "learning_rate": 4.780555555555556e-05,
      "loss": 0.0029,
      "step": 3950
    },
    {
      "epoch": 0.088,
      "grad_norm": 0.47305795550346375,
      "learning_rate": 4.78e-05,
      "loss": 0.0024,
      "step": 3960
    },
    {
      "epoch": 0.08822222222222222,
      "grad_norm": 0.15003244578838348,
      "learning_rate": 4.779444444444445e-05,
      "loss": 0.0022,
      "step": 3970
    },
    {
      "epoch": 0.08844444444444445,
      "grad_norm": 0.42037951946258545,
      "learning_rate": 4.778888888888889e-05,
      "loss": 0.0031,
      "step": 3980
    },
    {
      "epoch": 0.08866666666666667,
      "grad_norm": 0.33186283707618713,
      "learning_rate": 4.7783333333333334e-05,
      "loss": 0.0045,
      "step": 3990
    },
    {
      "epoch": 0.08888888888888889,
      "grad_norm": 0.08156353235244751,
      "learning_rate": 4.7777777777777784e-05,
      "loss": 0.0031,
      "step": 4000
    },
    {
      "epoch": 0.08911111111111111,
      "grad_norm": 0.4200913608074188,
      "learning_rate": 4.777222222222222e-05,
      "loss": 0.0023,
      "step": 4010
    },
    {
      "epoch": 0.08933333333333333,
      "grad_norm": 0.4735918939113617,
      "learning_rate": 4.776666666666667e-05,
      "loss": 0.0024,
      "step": 4020
    },
    {
      "epoch": 0.08955555555555555,
      "grad_norm": 0.5884014964103699,
      "learning_rate": 4.7761111111111115e-05,
      "loss": 0.0019,
      "step": 4030
    },
    {
      "epoch": 0.08977777777777778,
      "grad_norm": 0.16473358869552612,
      "learning_rate": 4.775555555555556e-05,
      "loss": 0.0034,
      "step": 4040
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.3493928909301758,
      "learning_rate": 4.775e-05,
      "loss": 0.0026,
      "step": 4050
    },
    {
      "epoch": 0.09022222222222222,
      "grad_norm": 0.39151936769485474,
      "learning_rate": 4.7744444444444445e-05,
      "loss": 0.0041,
      "step": 4060
    },
    {
      "epoch": 0.09044444444444444,
      "grad_norm": 0.4930236339569092,
      "learning_rate": 4.773888888888889e-05,
      "loss": 0.0028,
      "step": 4070
    },
    {
      "epoch": 0.09066666666666667,
      "grad_norm": 0.2520798444747925,
      "learning_rate": 4.773333333333333e-05,
      "loss": 0.0023,
      "step": 4080
    },
    {
      "epoch": 0.0908888888888889,
      "grad_norm": 0.25686362385749817,
      "learning_rate": 4.772777777777778e-05,
      "loss": 0.0021,
      "step": 4090
    },
    {
      "epoch": 0.09111111111111111,
      "grad_norm": 0.3630293607711792,
      "learning_rate": 4.7722222222222226e-05,
      "loss": 0.0023,
      "step": 4100
    },
    {
      "epoch": 0.09133333333333334,
      "grad_norm": 0.5672300457954407,
      "learning_rate": 4.771666666666667e-05,
      "loss": 0.0044,
      "step": 4110
    },
    {
      "epoch": 0.09155555555555556,
      "grad_norm": 0.5205963253974915,
      "learning_rate": 4.7711111111111114e-05,
      "loss": 0.0022,
      "step": 4120
    },
    {
      "epoch": 0.09177777777777778,
      "grad_norm": 0.17871075868606567,
      "learning_rate": 4.770555555555556e-05,
      "loss": 0.0027,
      "step": 4130
    },
    {
      "epoch": 0.092,
      "grad_norm": 0.35288068652153015,
      "learning_rate": 4.77e-05,
      "loss": 0.0023,
      "step": 4140
    },
    {
      "epoch": 0.09222222222222222,
      "grad_norm": 0.5944845080375671,
      "learning_rate": 4.7694444444444444e-05,
      "loss": 0.0026,
      "step": 4150
    },
    {
      "epoch": 0.09244444444444444,
      "grad_norm": 0.43101242184638977,
      "learning_rate": 4.768888888888889e-05,
      "loss": 0.0035,
      "step": 4160
    },
    {
      "epoch": 0.09266666666666666,
      "grad_norm": 0.31961047649383545,
      "learning_rate": 4.768333333333334e-05,
      "loss": 0.002,
      "step": 4170
    },
    {
      "epoch": 0.09288888888888888,
      "grad_norm": 0.4537692666053772,
      "learning_rate": 4.767777777777778e-05,
      "loss": 0.0029,
      "step": 4180
    },
    {
      "epoch": 0.09311111111111112,
      "grad_norm": 0.6915695071220398,
      "learning_rate": 4.7672222222222225e-05,
      "loss": 0.0021,
      "step": 4190
    },
    {
      "epoch": 0.09333333333333334,
      "grad_norm": 0.1491858959197998,
      "learning_rate": 4.766666666666667e-05,
      "loss": 0.0023,
      "step": 4200
    },
    {
      "epoch": 0.09355555555555556,
      "grad_norm": 0.36861035227775574,
      "learning_rate": 4.766111111111111e-05,
      "loss": 0.0022,
      "step": 4210
    },
    {
      "epoch": 0.09377777777777778,
      "grad_norm": 0.1405382603406906,
      "learning_rate": 4.7655555555555556e-05,
      "loss": 0.0024,
      "step": 4220
    },
    {
      "epoch": 0.094,
      "grad_norm": 0.17936815321445465,
      "learning_rate": 4.765e-05,
      "loss": 0.0022,
      "step": 4230
    },
    {
      "epoch": 0.09422222222222222,
      "grad_norm": 0.18313267827033997,
      "learning_rate": 4.764444444444445e-05,
      "loss": 0.0022,
      "step": 4240
    },
    {
      "epoch": 0.09444444444444444,
      "grad_norm": 0.7163147330284119,
      "learning_rate": 4.7638888888888887e-05,
      "loss": 0.0024,
      "step": 4250
    },
    {
      "epoch": 0.09466666666666666,
      "grad_norm": 0.1953587830066681,
      "learning_rate": 4.763333333333334e-05,
      "loss": 0.0028,
      "step": 4260
    },
    {
      "epoch": 0.09488888888888888,
      "grad_norm": 0.49443185329437256,
      "learning_rate": 4.762777777777778e-05,
      "loss": 0.0028,
      "step": 4270
    },
    {
      "epoch": 0.0951111111111111,
      "grad_norm": 0.1494574397802353,
      "learning_rate": 4.7622222222222224e-05,
      "loss": 0.0024,
      "step": 4280
    },
    {
      "epoch": 0.09533333333333334,
      "grad_norm": 0.163580060005188,
      "learning_rate": 4.761666666666667e-05,
      "loss": 0.003,
      "step": 4290
    },
    {
      "epoch": 0.09555555555555556,
      "grad_norm": 0.5352867245674133,
      "learning_rate": 4.761111111111111e-05,
      "loss": 0.0021,
      "step": 4300
    },
    {
      "epoch": 0.09577777777777778,
      "grad_norm": 0.2593863904476166,
      "learning_rate": 4.760555555555556e-05,
      "loss": 0.0027,
      "step": 4310
    },
    {
      "epoch": 0.096,
      "grad_norm": 0.5885840654373169,
      "learning_rate": 4.76e-05,
      "loss": 0.002,
      "step": 4320
    },
    {
      "epoch": 0.09622222222222222,
      "grad_norm": 0.1462649703025818,
      "learning_rate": 4.759444444444445e-05,
      "loss": 0.0021,
      "step": 4330
    },
    {
      "epoch": 0.09644444444444444,
      "grad_norm": 0.27830129861831665,
      "learning_rate": 4.7588888888888885e-05,
      "loss": 0.003,
      "step": 4340
    },
    {
      "epoch": 0.09666666666666666,
      "grad_norm": 0.14616148173809052,
      "learning_rate": 4.7583333333333336e-05,
      "loss": 0.002,
      "step": 4350
    },
    {
      "epoch": 0.09688888888888889,
      "grad_norm": 0.3431902229785919,
      "learning_rate": 4.757777777777778e-05,
      "loss": 0.003,
      "step": 4360
    },
    {
      "epoch": 0.0971111111111111,
      "grad_norm": 0.1966959834098816,
      "learning_rate": 4.757222222222222e-05,
      "loss": 0.0025,
      "step": 4370
    },
    {
      "epoch": 0.09733333333333333,
      "grad_norm": 0.5742807984352112,
      "learning_rate": 4.756666666666667e-05,
      "loss": 0.0029,
      "step": 4380
    },
    {
      "epoch": 0.09755555555555556,
      "grad_norm": 0.26493170857429504,
      "learning_rate": 4.756111111111111e-05,
      "loss": 0.0019,
      "step": 4390
    },
    {
      "epoch": 0.09777777777777778,
      "grad_norm": 0.6632086038589478,
      "learning_rate": 4.755555555555556e-05,
      "loss": 0.0019,
      "step": 4400
    },
    {
      "epoch": 0.098,
      "grad_norm": 0.12180208414793015,
      "learning_rate": 4.755e-05,
      "loss": 0.0033,
      "step": 4410
    },
    {
      "epoch": 0.09822222222222222,
      "grad_norm": 0.26830583810806274,
      "learning_rate": 4.754444444444445e-05,
      "loss": 0.0029,
      "step": 4420
    },
    {
      "epoch": 0.09844444444444445,
      "grad_norm": 0.11101680994033813,
      "learning_rate": 4.753888888888889e-05,
      "loss": 0.0022,
      "step": 4430
    },
    {
      "epoch": 0.09866666666666667,
      "grad_norm": 0.24322962760925293,
      "learning_rate": 4.7533333333333334e-05,
      "loss": 0.0028,
      "step": 4440
    },
    {
      "epoch": 0.09888888888888889,
      "grad_norm": 0.17778322100639343,
      "learning_rate": 4.7527777777777785e-05,
      "loss": 0.0017,
      "step": 4450
    },
    {
      "epoch": 0.09911111111111111,
      "grad_norm": 0.10079022496938705,
      "learning_rate": 4.752222222222222e-05,
      "loss": 0.0028,
      "step": 4460
    },
    {
      "epoch": 0.09933333333333333,
      "grad_norm": 0.6085756421089172,
      "learning_rate": 4.751666666666667e-05,
      "loss": 0.003,
      "step": 4470
    },
    {
      "epoch": 0.09955555555555555,
      "grad_norm": 0.1478700488805771,
      "learning_rate": 4.751111111111111e-05,
      "loss": 0.0029,
      "step": 4480
    },
    {
      "epoch": 0.09977777777777778,
      "grad_norm": 0.21882376074790955,
      "learning_rate": 4.750555555555556e-05,
      "loss": 0.0035,
      "step": 4490
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.23744302988052368,
      "learning_rate": 4.75e-05,
      "loss": 0.0033,
      "step": 4500
    },
    {
      "epoch": 0.10022222222222223,
      "grad_norm": 0.16148912906646729,
      "learning_rate": 4.7494444444444446e-05,
      "loss": 0.0021,
      "step": 4510
    },
    {
      "epoch": 0.10044444444444445,
      "grad_norm": 0.2038382887840271,
      "learning_rate": 4.7488888888888897e-05,
      "loss": 0.002,
      "step": 4520
    },
    {
      "epoch": 0.10066666666666667,
      "grad_norm": 0.293265700340271,
      "learning_rate": 4.748333333333333e-05,
      "loss": 0.0024,
      "step": 4530
    },
    {
      "epoch": 0.10088888888888889,
      "grad_norm": 0.2727988660335541,
      "learning_rate": 4.7477777777777784e-05,
      "loss": 0.0023,
      "step": 4540
    },
    {
      "epoch": 0.10111111111111111,
      "grad_norm": 0.28430822491645813,
      "learning_rate": 4.747222222222222e-05,
      "loss": 0.002,
      "step": 4550
    },
    {
      "epoch": 0.10133333333333333,
      "grad_norm": 0.4686819016933441,
      "learning_rate": 4.746666666666667e-05,
      "loss": 0.0023,
      "step": 4560
    },
    {
      "epoch": 0.10155555555555555,
      "grad_norm": 0.28691715002059937,
      "learning_rate": 4.7461111111111114e-05,
      "loss": 0.0024,
      "step": 4570
    },
    {
      "epoch": 0.10177777777777777,
      "grad_norm": 0.2538195848464966,
      "learning_rate": 4.745555555555556e-05,
      "loss": 0.0035,
      "step": 4580
    },
    {
      "epoch": 0.102,
      "grad_norm": 0.2049638032913208,
      "learning_rate": 4.745e-05,
      "loss": 0.0019,
      "step": 4590
    },
    {
      "epoch": 0.10222222222222223,
      "grad_norm": 0.3799535632133484,
      "learning_rate": 4.7444444444444445e-05,
      "loss": 0.0019,
      "step": 4600
    },
    {
      "epoch": 0.10244444444444445,
      "grad_norm": 0.25667962431907654,
      "learning_rate": 4.7438888888888895e-05,
      "loss": 0.0031,
      "step": 4610
    },
    {
      "epoch": 0.10266666666666667,
      "grad_norm": 0.26869699358940125,
      "learning_rate": 4.743333333333333e-05,
      "loss": 0.0027,
      "step": 4620
    },
    {
      "epoch": 0.10288888888888889,
      "grad_norm": 0.059329554438591,
      "learning_rate": 4.742777777777778e-05,
      "loss": 0.0023,
      "step": 4630
    },
    {
      "epoch": 0.10311111111111111,
      "grad_norm": 0.17207524180412292,
      "learning_rate": 4.7422222222222226e-05,
      "loss": 0.0022,
      "step": 4640
    },
    {
      "epoch": 0.10333333333333333,
      "grad_norm": 0.6340430974960327,
      "learning_rate": 4.741666666666667e-05,
      "loss": 0.003,
      "step": 4650
    },
    {
      "epoch": 0.10355555555555555,
      "grad_norm": 0.17171835899353027,
      "learning_rate": 4.741111111111111e-05,
      "loss": 0.0021,
      "step": 4660
    },
    {
      "epoch": 0.10377777777777777,
      "grad_norm": 0.9098469018936157,
      "learning_rate": 4.740555555555556e-05,
      "loss": 0.0041,
      "step": 4670
    },
    {
      "epoch": 0.104,
      "grad_norm": 0.21106834709644318,
      "learning_rate": 4.74e-05,
      "loss": 0.0025,
      "step": 4680
    },
    {
      "epoch": 0.10422222222222222,
      "grad_norm": 0.6052258014678955,
      "learning_rate": 4.7394444444444444e-05,
      "loss": 0.0019,
      "step": 4690
    },
    {
      "epoch": 0.10444444444444445,
      "grad_norm": 0.3783455193042755,
      "learning_rate": 4.7388888888888894e-05,
      "loss": 0.0026,
      "step": 4700
    },
    {
      "epoch": 0.10466666666666667,
      "grad_norm": 0.31603479385375977,
      "learning_rate": 4.738333333333334e-05,
      "loss": 0.0029,
      "step": 4710
    },
    {
      "epoch": 0.10488888888888889,
      "grad_norm": 0.1469343900680542,
      "learning_rate": 4.737777777777778e-05,
      "loss": 0.0021,
      "step": 4720
    },
    {
      "epoch": 0.10511111111111111,
      "grad_norm": 0.14168527722358704,
      "learning_rate": 4.7372222222222225e-05,
      "loss": 0.0019,
      "step": 4730
    },
    {
      "epoch": 0.10533333333333333,
      "grad_norm": 0.3280058801174164,
      "learning_rate": 4.736666666666667e-05,
      "loss": 0.0019,
      "step": 4740
    },
    {
      "epoch": 0.10555555555555556,
      "grad_norm": 0.18543711304664612,
      "learning_rate": 4.736111111111111e-05,
      "loss": 0.0034,
      "step": 4750
    },
    {
      "epoch": 0.10577777777777778,
      "grad_norm": 0.16830815374851227,
      "learning_rate": 4.7355555555555555e-05,
      "loss": 0.0027,
      "step": 4760
    },
    {
      "epoch": 0.106,
      "grad_norm": 0.27707329392433167,
      "learning_rate": 4.735e-05,
      "loss": 0.0027,
      "step": 4770
    },
    {
      "epoch": 0.10622222222222222,
      "grad_norm": 0.7657990455627441,
      "learning_rate": 4.734444444444445e-05,
      "loss": 0.002,
      "step": 4780
    },
    {
      "epoch": 0.10644444444444444,
      "grad_norm": 0.17888842523097992,
      "learning_rate": 4.733888888888889e-05,
      "loss": 0.002,
      "step": 4790
    },
    {
      "epoch": 0.10666666666666667,
      "grad_norm": 0.5248679518699646,
      "learning_rate": 4.7333333333333336e-05,
      "loss": 0.0023,
      "step": 4800
    },
    {
      "epoch": 0.1068888888888889,
      "grad_norm": 0.5267477631568909,
      "learning_rate": 4.732777777777778e-05,
      "loss": 0.0023,
      "step": 4810
    },
    {
      "epoch": 0.10711111111111112,
      "grad_norm": 0.10552003234624863,
      "learning_rate": 4.7322222222222224e-05,
      "loss": 0.0019,
      "step": 4820
    },
    {
      "epoch": 0.10733333333333334,
      "grad_norm": 0.26504722237586975,
      "learning_rate": 4.731666666666667e-05,
      "loss": 0.0017,
      "step": 4830
    },
    {
      "epoch": 0.10755555555555556,
      "grad_norm": 0.2883256673812866,
      "learning_rate": 4.731111111111111e-05,
      "loss": 0.0019,
      "step": 4840
    },
    {
      "epoch": 0.10777777777777778,
      "grad_norm": 0.14662900567054749,
      "learning_rate": 4.730555555555556e-05,
      "loss": 0.0023,
      "step": 4850
    },
    {
      "epoch": 0.108,
      "grad_norm": 0.3499821424484253,
      "learning_rate": 4.73e-05,
      "loss": 0.0031,
      "step": 4860
    },
    {
      "epoch": 0.10822222222222222,
      "grad_norm": 0.3225348889827728,
      "learning_rate": 4.729444444444445e-05,
      "loss": 0.0024,
      "step": 4870
    },
    {
      "epoch": 0.10844444444444444,
      "grad_norm": 0.17876116931438446,
      "learning_rate": 4.728888888888889e-05,
      "loss": 0.0019,
      "step": 4880
    },
    {
      "epoch": 0.10866666666666666,
      "grad_norm": 0.41175442934036255,
      "learning_rate": 4.7283333333333335e-05,
      "loss": 0.0022,
      "step": 4890
    },
    {
      "epoch": 0.10888888888888888,
      "grad_norm": 0.7313532829284668,
      "learning_rate": 4.727777777777778e-05,
      "loss": 0.0018,
      "step": 4900
    },
    {
      "epoch": 0.10911111111111112,
      "grad_norm": 0.6924906969070435,
      "learning_rate": 4.727222222222222e-05,
      "loss": 0.0037,
      "step": 4910
    },
    {
      "epoch": 0.10933333333333334,
      "grad_norm": 0.2758304178714752,
      "learning_rate": 4.726666666666667e-05,
      "loss": 0.0023,
      "step": 4920
    },
    {
      "epoch": 0.10955555555555556,
      "grad_norm": 0.2841912508010864,
      "learning_rate": 4.726111111111111e-05,
      "loss": 0.0027,
      "step": 4930
    },
    {
      "epoch": 0.10977777777777778,
      "grad_norm": 0.10414005815982819,
      "learning_rate": 4.725555555555556e-05,
      "loss": 0.0031,
      "step": 4940
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.10948897153139114,
      "learning_rate": 4.7249999999999997e-05,
      "loss": 0.0022,
      "step": 4950
    },
    {
      "epoch": 0.11022222222222222,
      "grad_norm": 0.11754206568002701,
      "learning_rate": 4.724444444444445e-05,
      "loss": 0.0021,
      "step": 4960
    },
    {
      "epoch": 0.11044444444444444,
      "grad_norm": 0.37484413385391235,
      "learning_rate": 4.723888888888889e-05,
      "loss": 0.0024,
      "step": 4970
    },
    {
      "epoch": 0.11066666666666666,
      "grad_norm": 0.40845826268196106,
      "learning_rate": 4.7233333333333334e-05,
      "loss": 0.0022,
      "step": 4980
    },
    {
      "epoch": 0.11088888888888888,
      "grad_norm": 0.36091646552085876,
      "learning_rate": 4.7227777777777784e-05,
      "loss": 0.0018,
      "step": 4990
    },
    {
      "epoch": 0.1111111111111111,
      "grad_norm": 0.7488969564437866,
      "learning_rate": 4.722222222222222e-05,
      "loss": 0.003,
      "step": 5000
    },
    {
      "epoch": 0.11133333333333334,
      "grad_norm": 0.3944908678531647,
      "learning_rate": 4.721666666666667e-05,
      "loss": 0.0023,
      "step": 5010
    },
    {
      "epoch": 0.11155555555555556,
      "grad_norm": 0.3122484087944031,
      "learning_rate": 4.721111111111111e-05,
      "loss": 0.0021,
      "step": 5020
    },
    {
      "epoch": 0.11177777777777778,
      "grad_norm": 0.2036600559949875,
      "learning_rate": 4.720555555555556e-05,
      "loss": 0.0028,
      "step": 5030
    },
    {
      "epoch": 0.112,
      "grad_norm": 0.48163676261901855,
      "learning_rate": 4.72e-05,
      "loss": 0.0025,
      "step": 5040
    },
    {
      "epoch": 0.11222222222222222,
      "grad_norm": 0.9635480642318726,
      "learning_rate": 4.7194444444444446e-05,
      "loss": 0.0021,
      "step": 5050
    },
    {
      "epoch": 0.11244444444444444,
      "grad_norm": 0.15614597499370575,
      "learning_rate": 4.7188888888888896e-05,
      "loss": 0.0035,
      "step": 5060
    },
    {
      "epoch": 0.11266666666666666,
      "grad_norm": 0.20557966828346252,
      "learning_rate": 4.718333333333333e-05,
      "loss": 0.0027,
      "step": 5070
    },
    {
      "epoch": 0.11288888888888889,
      "grad_norm": 0.5076311230659485,
      "learning_rate": 4.717777777777778e-05,
      "loss": 0.0031,
      "step": 5080
    },
    {
      "epoch": 0.1131111111111111,
      "grad_norm": 0.26753318309783936,
      "learning_rate": 4.717222222222222e-05,
      "loss": 0.0023,
      "step": 5090
    },
    {
      "epoch": 0.11333333333333333,
      "grad_norm": 0.3008311092853546,
      "learning_rate": 4.716666666666667e-05,
      "loss": 0.0022,
      "step": 5100
    },
    {
      "epoch": 0.11355555555555556,
      "grad_norm": 0.3909080922603607,
      "learning_rate": 4.7161111111111114e-05,
      "loss": 0.0029,
      "step": 5110
    },
    {
      "epoch": 0.11377777777777778,
      "grad_norm": 0.0957898423075676,
      "learning_rate": 4.715555555555556e-05,
      "loss": 0.0024,
      "step": 5120
    },
    {
      "epoch": 0.114,
      "grad_norm": 0.8840601444244385,
      "learning_rate": 4.715e-05,
      "loss": 0.0022,
      "step": 5130
    },
    {
      "epoch": 0.11422222222222222,
      "grad_norm": 0.30505454540252686,
      "learning_rate": 4.7144444444444444e-05,
      "loss": 0.0022,
      "step": 5140
    },
    {
      "epoch": 0.11444444444444445,
      "grad_norm": 0.22654609382152557,
      "learning_rate": 4.7138888888888895e-05,
      "loss": 0.0032,
      "step": 5150
    },
    {
      "epoch": 0.11466666666666667,
      "grad_norm": 0.39944806694984436,
      "learning_rate": 4.713333333333333e-05,
      "loss": 0.0021,
      "step": 5160
    },
    {
      "epoch": 0.11488888888888889,
      "grad_norm": 0.09436718374490738,
      "learning_rate": 4.712777777777778e-05,
      "loss": 0.0021,
      "step": 5170
    },
    {
      "epoch": 0.11511111111111111,
      "grad_norm": 0.16798974573612213,
      "learning_rate": 4.7122222222222225e-05,
      "loss": 0.0022,
      "step": 5180
    },
    {
      "epoch": 0.11533333333333333,
      "grad_norm": 0.49511146545410156,
      "learning_rate": 4.711666666666667e-05,
      "loss": 0.0035,
      "step": 5190
    },
    {
      "epoch": 0.11555555555555555,
      "grad_norm": 0.28094756603240967,
      "learning_rate": 4.711111111111111e-05,
      "loss": 0.0024,
      "step": 5200
    },
    {
      "epoch": 0.11577777777777777,
      "grad_norm": 0.5912323594093323,
      "learning_rate": 4.7105555555555556e-05,
      "loss": 0.0032,
      "step": 5210
    },
    {
      "epoch": 0.116,
      "grad_norm": 0.3529840111732483,
      "learning_rate": 4.71e-05,
      "loss": 0.0031,
      "step": 5220
    },
    {
      "epoch": 0.11622222222222223,
      "grad_norm": 0.4102780520915985,
      "learning_rate": 4.709444444444444e-05,
      "loss": 0.0025,
      "step": 5230
    },
    {
      "epoch": 0.11644444444444445,
      "grad_norm": 0.16133730113506317,
      "learning_rate": 4.7088888888888894e-05,
      "loss": 0.0019,
      "step": 5240
    },
    {
      "epoch": 0.11666666666666667,
      "grad_norm": 0.11951808631420135,
      "learning_rate": 4.708333333333334e-05,
      "loss": 0.0021,
      "step": 5250
    },
    {
      "epoch": 0.11688888888888889,
      "grad_norm": 0.11679204553365707,
      "learning_rate": 4.707777777777778e-05,
      "loss": 0.0028,
      "step": 5260
    },
    {
      "epoch": 0.11711111111111111,
      "grad_norm": 0.2415238916873932,
      "learning_rate": 4.7072222222222224e-05,
      "loss": 0.0036,
      "step": 5270
    },
    {
      "epoch": 0.11733333333333333,
      "grad_norm": 0.08868738263845444,
      "learning_rate": 4.706666666666667e-05,
      "loss": 0.0018,
      "step": 5280
    },
    {
      "epoch": 0.11755555555555555,
      "grad_norm": 0.15238545835018158,
      "learning_rate": 4.706111111111111e-05,
      "loss": 0.0021,
      "step": 5290
    },
    {
      "epoch": 0.11777777777777777,
      "grad_norm": 0.2533123195171356,
      "learning_rate": 4.7055555555555555e-05,
      "loss": 0.0025,
      "step": 5300
    },
    {
      "epoch": 0.118,
      "grad_norm": 0.2933482825756073,
      "learning_rate": 4.705e-05,
      "loss": 0.002,
      "step": 5310
    },
    {
      "epoch": 0.11822222222222223,
      "grad_norm": 0.09964815527200699,
      "learning_rate": 4.704444444444445e-05,
      "loss": 0.0026,
      "step": 5320
    },
    {
      "epoch": 0.11844444444444445,
      "grad_norm": 0.27226144075393677,
      "learning_rate": 4.703888888888889e-05,
      "loss": 0.0024,
      "step": 5330
    },
    {
      "epoch": 0.11866666666666667,
      "grad_norm": 0.311868280172348,
      "learning_rate": 4.7033333333333336e-05,
      "loss": 0.0027,
      "step": 5340
    },
    {
      "epoch": 0.11888888888888889,
      "grad_norm": 0.37533795833587646,
      "learning_rate": 4.702777777777778e-05,
      "loss": 0.0023,
      "step": 5350
    },
    {
      "epoch": 0.11911111111111111,
      "grad_norm": 0.7001430988311768,
      "learning_rate": 4.702222222222222e-05,
      "loss": 0.0028,
      "step": 5360
    },
    {
      "epoch": 0.11933333333333333,
      "grad_norm": 0.2344495803117752,
      "learning_rate": 4.701666666666667e-05,
      "loss": 0.004,
      "step": 5370
    },
    {
      "epoch": 0.11955555555555555,
      "grad_norm": 0.31778034567832947,
      "learning_rate": 4.701111111111111e-05,
      "loss": 0.0023,
      "step": 5380
    },
    {
      "epoch": 0.11977777777777777,
      "grad_norm": 0.4569031596183777,
      "learning_rate": 4.700555555555556e-05,
      "loss": 0.0021,
      "step": 5390
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.3405914306640625,
      "learning_rate": 4.7e-05,
      "loss": 0.0022,
      "step": 5400
    },
    {
      "epoch": 0.12022222222222222,
      "grad_norm": 0.3715011775493622,
      "learning_rate": 4.699444444444445e-05,
      "loss": 0.0023,
      "step": 5410
    },
    {
      "epoch": 0.12044444444444445,
      "grad_norm": 0.18776552379131317,
      "learning_rate": 4.698888888888889e-05,
      "loss": 0.003,
      "step": 5420
    },
    {
      "epoch": 0.12066666666666667,
      "grad_norm": 0.45656105875968933,
      "learning_rate": 4.6983333333333335e-05,
      "loss": 0.0018,
      "step": 5430
    },
    {
      "epoch": 0.12088888888888889,
      "grad_norm": 0.0779711902141571,
      "learning_rate": 4.6977777777777785e-05,
      "loss": 0.0024,
      "step": 5440
    },
    {
      "epoch": 0.12111111111111111,
      "grad_norm": 0.48605433106422424,
      "learning_rate": 4.697222222222222e-05,
      "loss": 0.0039,
      "step": 5450
    },
    {
      "epoch": 0.12133333333333333,
      "grad_norm": 0.12194381654262543,
      "learning_rate": 4.696666666666667e-05,
      "loss": 0.0022,
      "step": 5460
    },
    {
      "epoch": 0.12155555555555556,
      "grad_norm": 0.3378123342990875,
      "learning_rate": 4.696111111111111e-05,
      "loss": 0.0027,
      "step": 5470
    },
    {
      "epoch": 0.12177777777777778,
      "grad_norm": 0.6250636577606201,
      "learning_rate": 4.695555555555556e-05,
      "loss": 0.0025,
      "step": 5480
    },
    {
      "epoch": 0.122,
      "grad_norm": 0.17378956079483032,
      "learning_rate": 4.695e-05,
      "loss": 0.0034,
      "step": 5490
    },
    {
      "epoch": 0.12222222222222222,
      "grad_norm": 0.2870292663574219,
      "learning_rate": 4.6944444444444446e-05,
      "loss": 0.0031,
      "step": 5500
    },
    {
      "epoch": 0.12244444444444444,
      "grad_norm": 0.7101457715034485,
      "learning_rate": 4.69388888888889e-05,
      "loss": 0.0026,
      "step": 5510
    },
    {
      "epoch": 0.12266666666666666,
      "grad_norm": 0.43432334065437317,
      "learning_rate": 4.6933333333333333e-05,
      "loss": 0.0028,
      "step": 5520
    },
    {
      "epoch": 0.1228888888888889,
      "grad_norm": 0.7223741412162781,
      "learning_rate": 4.6927777777777784e-05,
      "loss": 0.0028,
      "step": 5530
    },
    {
      "epoch": 0.12311111111111112,
      "grad_norm": 0.6526695489883423,
      "learning_rate": 4.692222222222222e-05,
      "loss": 0.0024,
      "step": 5540
    },
    {
      "epoch": 0.12333333333333334,
      "grad_norm": 0.1293872594833374,
      "learning_rate": 4.691666666666667e-05,
      "loss": 0.0041,
      "step": 5550
    },
    {
      "epoch": 0.12355555555555556,
      "grad_norm": 0.09878276288509369,
      "learning_rate": 4.6911111111111114e-05,
      "loss": 0.0026,
      "step": 5560
    },
    {
      "epoch": 0.12377777777777778,
      "grad_norm": 0.2679086923599243,
      "learning_rate": 4.690555555555556e-05,
      "loss": 0.0025,
      "step": 5570
    },
    {
      "epoch": 0.124,
      "grad_norm": 0.15768691897392273,
      "learning_rate": 4.69e-05,
      "loss": 0.0026,
      "step": 5580
    },
    {
      "epoch": 0.12422222222222222,
      "grad_norm": 0.17004716396331787,
      "learning_rate": 4.6894444444444445e-05,
      "loss": 0.0033,
      "step": 5590
    },
    {
      "epoch": 0.12444444444444444,
      "grad_norm": 0.7874967455863953,
      "learning_rate": 4.6888888888888895e-05,
      "loss": 0.0025,
      "step": 5600
    },
    {
      "epoch": 0.12466666666666666,
      "grad_norm": 0.09782084077596664,
      "learning_rate": 4.688333333333333e-05,
      "loss": 0.0022,
      "step": 5610
    },
    {
      "epoch": 0.12488888888888888,
      "grad_norm": 0.1098422259092331,
      "learning_rate": 4.687777777777778e-05,
      "loss": 0.0034,
      "step": 5620
    },
    {
      "epoch": 0.12511111111111112,
      "grad_norm": 0.3923615515232086,
      "learning_rate": 4.6872222222222226e-05,
      "loss": 0.0027,
      "step": 5630
    },
    {
      "epoch": 0.12533333333333332,
      "grad_norm": 0.16374340653419495,
      "learning_rate": 4.686666666666667e-05,
      "loss": 0.0034,
      "step": 5640
    },
    {
      "epoch": 0.12555555555555556,
      "grad_norm": 0.09366831928491592,
      "learning_rate": 4.686111111111111e-05,
      "loss": 0.002,
      "step": 5650
    },
    {
      "epoch": 0.12577777777777777,
      "grad_norm": 0.2639159858226776,
      "learning_rate": 4.685555555555556e-05,
      "loss": 0.0025,
      "step": 5660
    },
    {
      "epoch": 0.126,
      "grad_norm": 0.5082367062568665,
      "learning_rate": 4.685000000000001e-05,
      "loss": 0.002,
      "step": 5670
    },
    {
      "epoch": 0.12622222222222224,
      "grad_norm": 0.22176550328731537,
      "learning_rate": 4.6844444444444444e-05,
      "loss": 0.0039,
      "step": 5680
    },
    {
      "epoch": 0.12644444444444444,
      "grad_norm": 0.1904754936695099,
      "learning_rate": 4.6838888888888894e-05,
      "loss": 0.0025,
      "step": 5690
    },
    {
      "epoch": 0.12666666666666668,
      "grad_norm": 0.12626153230667114,
      "learning_rate": 4.683333333333334e-05,
      "loss": 0.0029,
      "step": 5700
    },
    {
      "epoch": 0.12688888888888888,
      "grad_norm": 0.8115276098251343,
      "learning_rate": 4.682777777777778e-05,
      "loss": 0.0024,
      "step": 5710
    },
    {
      "epoch": 0.12711111111111112,
      "grad_norm": 0.22924493253231049,
      "learning_rate": 4.6822222222222225e-05,
      "loss": 0.0025,
      "step": 5720
    },
    {
      "epoch": 0.12733333333333333,
      "grad_norm": 0.08589740097522736,
      "learning_rate": 4.681666666666667e-05,
      "loss": 0.0033,
      "step": 5730
    },
    {
      "epoch": 0.12755555555555556,
      "grad_norm": 0.1394035667181015,
      "learning_rate": 4.681111111111111e-05,
      "loss": 0.0025,
      "step": 5740
    },
    {
      "epoch": 0.12777777777777777,
      "grad_norm": 0.37970757484436035,
      "learning_rate": 4.6805555555555556e-05,
      "loss": 0.0031,
      "step": 5750
    },
    {
      "epoch": 0.128,
      "grad_norm": 0.24766342341899872,
      "learning_rate": 4.6800000000000006e-05,
      "loss": 0.0023,
      "step": 5760
    },
    {
      "epoch": 0.1282222222222222,
      "grad_norm": 0.5176628232002258,
      "learning_rate": 4.679444444444445e-05,
      "loss": 0.0029,
      "step": 5770
    },
    {
      "epoch": 0.12844444444444444,
      "grad_norm": 0.2762990891933441,
      "learning_rate": 4.678888888888889e-05,
      "loss": 0.0025,
      "step": 5780
    },
    {
      "epoch": 0.12866666666666668,
      "grad_norm": 0.09381625056266785,
      "learning_rate": 4.6783333333333337e-05,
      "loss": 0.0043,
      "step": 5790
    },
    {
      "epoch": 0.1288888888888889,
      "grad_norm": 0.3890901505947113,
      "learning_rate": 4.677777777777778e-05,
      "loss": 0.0027,
      "step": 5800
    },
    {
      "epoch": 0.12911111111111112,
      "grad_norm": 0.5768534541130066,
      "learning_rate": 4.6772222222222224e-05,
      "loss": 0.003,
      "step": 5810
    },
    {
      "epoch": 0.12933333333333333,
      "grad_norm": 0.6634371280670166,
      "learning_rate": 4.676666666666667e-05,
      "loss": 0.0029,
      "step": 5820
    },
    {
      "epoch": 0.12955555555555556,
      "grad_norm": 0.5921535491943359,
      "learning_rate": 4.676111111111111e-05,
      "loss": 0.0029,
      "step": 5830
    },
    {
      "epoch": 0.12977777777777777,
      "grad_norm": 0.7571815252304077,
      "learning_rate": 4.675555555555556e-05,
      "loss": 0.0018,
      "step": 5840
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.07913647592067719,
      "learning_rate": 4.6750000000000005e-05,
      "loss": 0.002,
      "step": 5850
    },
    {
      "epoch": 0.1302222222222222,
      "grad_norm": 0.10573136061429977,
      "learning_rate": 4.674444444444445e-05,
      "loss": 0.0028,
      "step": 5860
    },
    {
      "epoch": 0.13044444444444445,
      "grad_norm": 0.6899195313453674,
      "learning_rate": 4.673888888888889e-05,
      "loss": 0.0026,
      "step": 5870
    },
    {
      "epoch": 0.13066666666666665,
      "grad_norm": 0.11438621580600739,
      "learning_rate": 4.6733333333333335e-05,
      "loss": 0.0025,
      "step": 5880
    },
    {
      "epoch": 0.1308888888888889,
      "grad_norm": 0.14869581162929535,
      "learning_rate": 4.672777777777778e-05,
      "loss": 0.0031,
      "step": 5890
    },
    {
      "epoch": 0.13111111111111112,
      "grad_norm": 0.1154685765504837,
      "learning_rate": 4.672222222222222e-05,
      "loss": 0.0022,
      "step": 5900
    },
    {
      "epoch": 0.13133333333333333,
      "grad_norm": 0.29069647192955017,
      "learning_rate": 4.671666666666667e-05,
      "loss": 0.0025,
      "step": 5910
    },
    {
      "epoch": 0.13155555555555556,
      "grad_norm": 0.23803558945655823,
      "learning_rate": 4.671111111111111e-05,
      "loss": 0.0025,
      "step": 5920
    },
    {
      "epoch": 0.13177777777777777,
      "grad_norm": 0.2961731255054474,
      "learning_rate": 4.670555555555556e-05,
      "loss": 0.0021,
      "step": 5930
    },
    {
      "epoch": 0.132,
      "grad_norm": 0.3960878551006317,
      "learning_rate": 4.6700000000000003e-05,
      "loss": 0.0019,
      "step": 5940
    },
    {
      "epoch": 0.1322222222222222,
      "grad_norm": 0.2538520097732544,
      "learning_rate": 4.669444444444445e-05,
      "loss": 0.0023,
      "step": 5950
    },
    {
      "epoch": 0.13244444444444445,
      "grad_norm": 0.1987076848745346,
      "learning_rate": 4.668888888888889e-05,
      "loss": 0.0019,
      "step": 5960
    },
    {
      "epoch": 0.13266666666666665,
      "grad_norm": 0.12510628998279572,
      "learning_rate": 4.6683333333333334e-05,
      "loss": 0.0023,
      "step": 5970
    },
    {
      "epoch": 0.1328888888888889,
      "grad_norm": 0.10554079711437225,
      "learning_rate": 4.6677777777777785e-05,
      "loss": 0.0019,
      "step": 5980
    },
    {
      "epoch": 0.13311111111111112,
      "grad_norm": 0.21533650159835815,
      "learning_rate": 4.667222222222222e-05,
      "loss": 0.0023,
      "step": 5990
    },
    {
      "epoch": 0.13333333333333333,
      "grad_norm": 0.19876089692115784,
      "learning_rate": 4.666666666666667e-05,
      "loss": 0.0028,
      "step": 6000
    },
    {
      "epoch": 0.13355555555555557,
      "grad_norm": 0.25948551297187805,
      "learning_rate": 4.666111111111111e-05,
      "loss": 0.0018,
      "step": 6010
    },
    {
      "epoch": 0.13377777777777777,
      "grad_norm": 0.1934577226638794,
      "learning_rate": 4.665555555555556e-05,
      "loss": 0.0023,
      "step": 6020
    },
    {
      "epoch": 0.134,
      "grad_norm": 0.0922926738858223,
      "learning_rate": 4.665e-05,
      "loss": 0.0029,
      "step": 6030
    },
    {
      "epoch": 0.13422222222222221,
      "grad_norm": 0.32861441373825073,
      "learning_rate": 4.6644444444444446e-05,
      "loss": 0.0024,
      "step": 6040
    },
    {
      "epoch": 0.13444444444444445,
      "grad_norm": 0.23537294566631317,
      "learning_rate": 4.6638888888888896e-05,
      "loss": 0.003,
      "step": 6050
    },
    {
      "epoch": 0.13466666666666666,
      "grad_norm": 0.12624289095401764,
      "learning_rate": 4.663333333333333e-05,
      "loss": 0.0024,
      "step": 6060
    },
    {
      "epoch": 0.1348888888888889,
      "grad_norm": 0.3213003873825073,
      "learning_rate": 4.662777777777778e-05,
      "loss": 0.003,
      "step": 6070
    },
    {
      "epoch": 0.1351111111111111,
      "grad_norm": 0.516680896282196,
      "learning_rate": 4.662222222222222e-05,
      "loss": 0.0021,
      "step": 6080
    },
    {
      "epoch": 0.13533333333333333,
      "grad_norm": 0.6166960000991821,
      "learning_rate": 4.661666666666667e-05,
      "loss": 0.0024,
      "step": 6090
    },
    {
      "epoch": 0.13555555555555557,
      "grad_norm": 0.40713807940483093,
      "learning_rate": 4.6611111111111114e-05,
      "loss": 0.0024,
      "step": 6100
    },
    {
      "epoch": 0.13577777777777778,
      "grad_norm": 0.7262693643569946,
      "learning_rate": 4.660555555555556e-05,
      "loss": 0.002,
      "step": 6110
    },
    {
      "epoch": 0.136,
      "grad_norm": 0.42702585458755493,
      "learning_rate": 4.660000000000001e-05,
      "loss": 0.002,
      "step": 6120
    },
    {
      "epoch": 0.13622222222222222,
      "grad_norm": 0.37812599539756775,
      "learning_rate": 4.6594444444444445e-05,
      "loss": 0.0023,
      "step": 6130
    },
    {
      "epoch": 0.13644444444444445,
      "grad_norm": 0.22241050004959106,
      "learning_rate": 4.6588888888888895e-05,
      "loss": 0.0017,
      "step": 6140
    },
    {
      "epoch": 0.13666666666666666,
      "grad_norm": 0.23110243678092957,
      "learning_rate": 4.658333333333333e-05,
      "loss": 0.0019,
      "step": 6150
    },
    {
      "epoch": 0.1368888888888889,
      "grad_norm": 0.19171090424060822,
      "learning_rate": 4.657777777777778e-05,
      "loss": 0.0023,
      "step": 6160
    },
    {
      "epoch": 0.1371111111111111,
      "grad_norm": 0.6709563136100769,
      "learning_rate": 4.6572222222222226e-05,
      "loss": 0.0029,
      "step": 6170
    },
    {
      "epoch": 0.13733333333333334,
      "grad_norm": 0.3578619062900543,
      "learning_rate": 4.656666666666667e-05,
      "loss": 0.0041,
      "step": 6180
    },
    {
      "epoch": 0.13755555555555554,
      "grad_norm": 0.11736971884965897,
      "learning_rate": 4.656111111111111e-05,
      "loss": 0.0022,
      "step": 6190
    },
    {
      "epoch": 0.13777777777777778,
      "grad_norm": 0.3192989230155945,
      "learning_rate": 4.6555555555555556e-05,
      "loss": 0.0027,
      "step": 6200
    },
    {
      "epoch": 0.138,
      "grad_norm": 0.13551534712314606,
      "learning_rate": 4.655000000000001e-05,
      "loss": 0.002,
      "step": 6210
    },
    {
      "epoch": 0.13822222222222222,
      "grad_norm": 0.08924899250268936,
      "learning_rate": 4.6544444444444443e-05,
      "loss": 0.0017,
      "step": 6220
    },
    {
      "epoch": 0.13844444444444445,
      "grad_norm": 0.3672833740711212,
      "learning_rate": 4.6538888888888894e-05,
      "loss": 0.0029,
      "step": 6230
    },
    {
      "epoch": 0.13866666666666666,
      "grad_norm": 0.2848806083202362,
      "learning_rate": 4.653333333333334e-05,
      "loss": 0.0026,
      "step": 6240
    },
    {
      "epoch": 0.1388888888888889,
      "grad_norm": 0.1901213377714157,
      "learning_rate": 4.652777777777778e-05,
      "loss": 0.0027,
      "step": 6250
    },
    {
      "epoch": 0.1391111111111111,
      "grad_norm": 0.29199016094207764,
      "learning_rate": 4.6522222222222224e-05,
      "loss": 0.0027,
      "step": 6260
    },
    {
      "epoch": 0.13933333333333334,
      "grad_norm": 0.2154516577720642,
      "learning_rate": 4.651666666666667e-05,
      "loss": 0.0032,
      "step": 6270
    },
    {
      "epoch": 0.13955555555555554,
      "grad_norm": 0.40719476342201233,
      "learning_rate": 4.651111111111111e-05,
      "loss": 0.0029,
      "step": 6280
    },
    {
      "epoch": 0.13977777777777778,
      "grad_norm": 0.26042768359184265,
      "learning_rate": 4.6505555555555555e-05,
      "loss": 0.002,
      "step": 6290
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.10983116179704666,
      "learning_rate": 4.6500000000000005e-05,
      "loss": 0.0029,
      "step": 6300
    },
    {
      "epoch": 0.14022222222222222,
      "grad_norm": 0.1289985477924347,
      "learning_rate": 4.649444444444445e-05,
      "loss": 0.0028,
      "step": 6310
    },
    {
      "epoch": 0.14044444444444446,
      "grad_norm": 0.42587709426879883,
      "learning_rate": 4.648888888888889e-05,
      "loss": 0.0026,
      "step": 6320
    },
    {
      "epoch": 0.14066666666666666,
      "grad_norm": 0.084693543612957,
      "learning_rate": 4.6483333333333336e-05,
      "loss": 0.0017,
      "step": 6330
    },
    {
      "epoch": 0.1408888888888889,
      "grad_norm": 0.8173889517784119,
      "learning_rate": 4.647777777777778e-05,
      "loss": 0.0023,
      "step": 6340
    },
    {
      "epoch": 0.1411111111111111,
      "grad_norm": 0.5415023565292358,
      "learning_rate": 4.647222222222222e-05,
      "loss": 0.0019,
      "step": 6350
    },
    {
      "epoch": 0.14133333333333334,
      "grad_norm": 0.1846771389245987,
      "learning_rate": 4.646666666666667e-05,
      "loss": 0.0018,
      "step": 6360
    },
    {
      "epoch": 0.14155555555555555,
      "grad_norm": 0.3973197937011719,
      "learning_rate": 4.646111111111111e-05,
      "loss": 0.0022,
      "step": 6370
    },
    {
      "epoch": 0.14177777777777778,
      "grad_norm": 0.3769369125366211,
      "learning_rate": 4.645555555555556e-05,
      "loss": 0.0023,
      "step": 6380
    },
    {
      "epoch": 0.142,
      "grad_norm": 0.6552179455757141,
      "learning_rate": 4.6450000000000004e-05,
      "loss": 0.0022,
      "step": 6390
    },
    {
      "epoch": 0.14222222222222222,
      "grad_norm": 0.1707301139831543,
      "learning_rate": 4.644444444444445e-05,
      "loss": 0.0028,
      "step": 6400
    },
    {
      "epoch": 0.14244444444444446,
      "grad_norm": 0.5753786563873291,
      "learning_rate": 4.643888888888889e-05,
      "loss": 0.0035,
      "step": 6410
    },
    {
      "epoch": 0.14266666666666666,
      "grad_norm": 0.5117953419685364,
      "learning_rate": 4.6433333333333335e-05,
      "loss": 0.0024,
      "step": 6420
    },
    {
      "epoch": 0.1428888888888889,
      "grad_norm": 0.38085779547691345,
      "learning_rate": 4.642777777777778e-05,
      "loss": 0.0025,
      "step": 6430
    },
    {
      "epoch": 0.1431111111111111,
      "grad_norm": 0.245209202170372,
      "learning_rate": 4.642222222222222e-05,
      "loss": 0.0023,
      "step": 6440
    },
    {
      "epoch": 0.14333333333333334,
      "grad_norm": 0.4945157766342163,
      "learning_rate": 4.641666666666667e-05,
      "loss": 0.0024,
      "step": 6450
    },
    {
      "epoch": 0.14355555555555555,
      "grad_norm": 0.10996203869581223,
      "learning_rate": 4.641111111111111e-05,
      "loss": 0.0024,
      "step": 6460
    },
    {
      "epoch": 0.14377777777777778,
      "grad_norm": 0.1286928653717041,
      "learning_rate": 4.640555555555556e-05,
      "loss": 0.0019,
      "step": 6470
    },
    {
      "epoch": 0.144,
      "grad_norm": 0.2503845691680908,
      "learning_rate": 4.64e-05,
      "loss": 0.0034,
      "step": 6480
    },
    {
      "epoch": 0.14422222222222222,
      "grad_norm": 0.08157335221767426,
      "learning_rate": 4.6394444444444447e-05,
      "loss": 0.0019,
      "step": 6490
    },
    {
      "epoch": 0.14444444444444443,
      "grad_norm": 0.31990957260131836,
      "learning_rate": 4.638888888888889e-05,
      "loss": 0.0025,
      "step": 6500
    },
    {
      "epoch": 0.14466666666666667,
      "grad_norm": 0.15626122057437897,
      "learning_rate": 4.6383333333333334e-05,
      "loss": 0.0019,
      "step": 6510
    },
    {
      "epoch": 0.1448888888888889,
      "grad_norm": 0.34955403208732605,
      "learning_rate": 4.6377777777777784e-05,
      "loss": 0.0024,
      "step": 6520
    },
    {
      "epoch": 0.1451111111111111,
      "grad_norm": 0.1889716237783432,
      "learning_rate": 4.637222222222222e-05,
      "loss": 0.0028,
      "step": 6530
    },
    {
      "epoch": 0.14533333333333334,
      "grad_norm": 0.2255772203207016,
      "learning_rate": 4.636666666666667e-05,
      "loss": 0.0022,
      "step": 6540
    },
    {
      "epoch": 0.14555555555555555,
      "grad_norm": 0.8707299828529358,
      "learning_rate": 4.636111111111111e-05,
      "loss": 0.0029,
      "step": 6550
    },
    {
      "epoch": 0.14577777777777778,
      "grad_norm": 0.215305358171463,
      "learning_rate": 4.635555555555556e-05,
      "loss": 0.0025,
      "step": 6560
    },
    {
      "epoch": 0.146,
      "grad_norm": 0.537045955657959,
      "learning_rate": 4.635e-05,
      "loss": 0.0021,
      "step": 6570
    },
    {
      "epoch": 0.14622222222222223,
      "grad_norm": 0.2866198718547821,
      "learning_rate": 4.6344444444444445e-05,
      "loss": 0.0023,
      "step": 6580
    },
    {
      "epoch": 0.14644444444444443,
      "grad_norm": 0.33958250284194946,
      "learning_rate": 4.6338888888888896e-05,
      "loss": 0.002,
      "step": 6590
    },
    {
      "epoch": 0.14666666666666667,
      "grad_norm": 0.2953362762928009,
      "learning_rate": 4.633333333333333e-05,
      "loss": 0.0022,
      "step": 6600
    },
    {
      "epoch": 0.1468888888888889,
      "grad_norm": 0.2329554706811905,
      "learning_rate": 4.632777777777778e-05,
      "loss": 0.0018,
      "step": 6610
    },
    {
      "epoch": 0.1471111111111111,
      "grad_norm": 0.13924762606620789,
      "learning_rate": 4.632222222222222e-05,
      "loss": 0.0033,
      "step": 6620
    },
    {
      "epoch": 0.14733333333333334,
      "grad_norm": 0.31534937024116516,
      "learning_rate": 4.631666666666667e-05,
      "loss": 0.0024,
      "step": 6630
    },
    {
      "epoch": 0.14755555555555555,
      "grad_norm": 0.39816799759864807,
      "learning_rate": 4.6311111111111113e-05,
      "loss": 0.0022,
      "step": 6640
    },
    {
      "epoch": 0.14777777777777779,
      "grad_norm": 0.17351989448070526,
      "learning_rate": 4.630555555555556e-05,
      "loss": 0.0017,
      "step": 6650
    },
    {
      "epoch": 0.148,
      "grad_norm": 0.3875214755535126,
      "learning_rate": 4.630000000000001e-05,
      "loss": 0.0019,
      "step": 6660
    },
    {
      "epoch": 0.14822222222222223,
      "grad_norm": 0.16101795434951782,
      "learning_rate": 4.6294444444444444e-05,
      "loss": 0.0027,
      "step": 6670
    },
    {
      "epoch": 0.14844444444444443,
      "grad_norm": 0.20241181552410126,
      "learning_rate": 4.6288888888888894e-05,
      "loss": 0.0026,
      "step": 6680
    },
    {
      "epoch": 0.14866666666666667,
      "grad_norm": 0.8173415660858154,
      "learning_rate": 4.628333333333333e-05,
      "loss": 0.0026,
      "step": 6690
    },
    {
      "epoch": 0.14888888888888888,
      "grad_norm": 0.5339122414588928,
      "learning_rate": 4.627777777777778e-05,
      "loss": 0.0032,
      "step": 6700
    },
    {
      "epoch": 0.1491111111111111,
      "grad_norm": 0.4109989106655121,
      "learning_rate": 4.6272222222222225e-05,
      "loss": 0.0022,
      "step": 6710
    },
    {
      "epoch": 0.14933333333333335,
      "grad_norm": 0.6189799904823303,
      "learning_rate": 4.626666666666667e-05,
      "loss": 0.0021,
      "step": 6720
    },
    {
      "epoch": 0.14955555555555555,
      "grad_norm": 0.1261695772409439,
      "learning_rate": 4.626111111111111e-05,
      "loss": 0.0021,
      "step": 6730
    },
    {
      "epoch": 0.1497777777777778,
      "grad_norm": 0.4782451093196869,
      "learning_rate": 4.6255555555555556e-05,
      "loss": 0.0024,
      "step": 6740
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.16279298067092896,
      "learning_rate": 4.6250000000000006e-05,
      "loss": 0.0037,
      "step": 6750
    },
    {
      "epoch": 0.15022222222222223,
      "grad_norm": 0.13688378036022186,
      "learning_rate": 4.624444444444444e-05,
      "loss": 0.0021,
      "step": 6760
    },
    {
      "epoch": 0.15044444444444444,
      "grad_norm": 0.40369129180908203,
      "learning_rate": 4.623888888888889e-05,
      "loss": 0.0024,
      "step": 6770
    },
    {
      "epoch": 0.15066666666666667,
      "grad_norm": 0.5311441421508789,
      "learning_rate": 4.623333333333334e-05,
      "loss": 0.0025,
      "step": 6780
    },
    {
      "epoch": 0.15088888888888888,
      "grad_norm": 0.17049643397331238,
      "learning_rate": 4.622777777777778e-05,
      "loss": 0.0022,
      "step": 6790
    },
    {
      "epoch": 0.1511111111111111,
      "grad_norm": 0.223154678940773,
      "learning_rate": 4.6222222222222224e-05,
      "loss": 0.0021,
      "step": 6800
    },
    {
      "epoch": 0.15133333333333332,
      "grad_norm": 0.08634022623300552,
      "learning_rate": 4.621666666666667e-05,
      "loss": 0.0023,
      "step": 6810
    },
    {
      "epoch": 0.15155555555555555,
      "grad_norm": 0.3915402293205261,
      "learning_rate": 4.621111111111111e-05,
      "loss": 0.002,
      "step": 6820
    },
    {
      "epoch": 0.1517777777777778,
      "grad_norm": 0.254169225692749,
      "learning_rate": 4.6205555555555555e-05,
      "loss": 0.003,
      "step": 6830
    },
    {
      "epoch": 0.152,
      "grad_norm": 0.2854224145412445,
      "learning_rate": 4.6200000000000005e-05,
      "loss": 0.0029,
      "step": 6840
    },
    {
      "epoch": 0.15222222222222223,
      "grad_norm": 0.2925223708152771,
      "learning_rate": 4.619444444444445e-05,
      "loss": 0.0021,
      "step": 6850
    },
    {
      "epoch": 0.15244444444444444,
      "grad_norm": 0.7347870469093323,
      "learning_rate": 4.618888888888889e-05,
      "loss": 0.0022,
      "step": 6860
    },
    {
      "epoch": 0.15266666666666667,
      "grad_norm": 0.2989449203014374,
      "learning_rate": 4.6183333333333336e-05,
      "loss": 0.0043,
      "step": 6870
    },
    {
      "epoch": 0.15288888888888888,
      "grad_norm": 0.6761919856071472,
      "learning_rate": 4.617777777777778e-05,
      "loss": 0.002,
      "step": 6880
    },
    {
      "epoch": 0.15311111111111111,
      "grad_norm": 0.2904265820980072,
      "learning_rate": 4.617222222222222e-05,
      "loss": 0.0027,
      "step": 6890
    },
    {
      "epoch": 0.15333333333333332,
      "grad_norm": 0.24656812846660614,
      "learning_rate": 4.6166666666666666e-05,
      "loss": 0.0027,
      "step": 6900
    },
    {
      "epoch": 0.15355555555555556,
      "grad_norm": 0.20146682858467102,
      "learning_rate": 4.6161111111111117e-05,
      "loss": 0.002,
      "step": 6910
    },
    {
      "epoch": 0.1537777777777778,
      "grad_norm": 0.23174656927585602,
      "learning_rate": 4.615555555555556e-05,
      "loss": 0.0033,
      "step": 6920
    },
    {
      "epoch": 0.154,
      "grad_norm": 0.09042485803365707,
      "learning_rate": 4.6150000000000004e-05,
      "loss": 0.0018,
      "step": 6930
    },
    {
      "epoch": 0.15422222222222223,
      "grad_norm": 0.194943368434906,
      "learning_rate": 4.614444444444445e-05,
      "loss": 0.0019,
      "step": 6940
    },
    {
      "epoch": 0.15444444444444444,
      "grad_norm": 0.21194544434547424,
      "learning_rate": 4.613888888888889e-05,
      "loss": 0.0025,
      "step": 6950
    },
    {
      "epoch": 0.15466666666666667,
      "grad_norm": 0.1394505351781845,
      "learning_rate": 4.6133333333333334e-05,
      "loss": 0.0022,
      "step": 6960
    },
    {
      "epoch": 0.15488888888888888,
      "grad_norm": 0.08023553341627121,
      "learning_rate": 4.612777777777778e-05,
      "loss": 0.0029,
      "step": 6970
    },
    {
      "epoch": 0.15511111111111112,
      "grad_norm": 0.24093571305274963,
      "learning_rate": 4.612222222222222e-05,
      "loss": 0.0027,
      "step": 6980
    },
    {
      "epoch": 0.15533333333333332,
      "grad_norm": 0.34455806016921997,
      "learning_rate": 4.611666666666667e-05,
      "loss": 0.0028,
      "step": 6990
    },
    {
      "epoch": 0.15555555555555556,
      "grad_norm": 0.78802490234375,
      "learning_rate": 4.6111111111111115e-05,
      "loss": 0.0023,
      "step": 7000
    },
    {
      "epoch": 0.15577777777777777,
      "grad_norm": 0.2152799814939499,
      "learning_rate": 4.610555555555556e-05,
      "loss": 0.0027,
      "step": 7010
    },
    {
      "epoch": 0.156,
      "grad_norm": 0.2837240397930145,
      "learning_rate": 4.61e-05,
      "loss": 0.0032,
      "step": 7020
    },
    {
      "epoch": 0.15622222222222223,
      "grad_norm": 0.12594681978225708,
      "learning_rate": 4.6094444444444446e-05,
      "loss": 0.0026,
      "step": 7030
    },
    {
      "epoch": 0.15644444444444444,
      "grad_norm": 0.15203647315502167,
      "learning_rate": 4.608888888888889e-05,
      "loss": 0.002,
      "step": 7040
    },
    {
      "epoch": 0.15666666666666668,
      "grad_norm": 0.5047513842582703,
      "learning_rate": 4.608333333333333e-05,
      "loss": 0.0019,
      "step": 7050
    },
    {
      "epoch": 0.15688888888888888,
      "grad_norm": 0.7201846241950989,
      "learning_rate": 4.6077777777777783e-05,
      "loss": 0.002,
      "step": 7060
    },
    {
      "epoch": 0.15711111111111112,
      "grad_norm": 0.21644052863121033,
      "learning_rate": 4.607222222222222e-05,
      "loss": 0.0019,
      "step": 7070
    },
    {
      "epoch": 0.15733333333333333,
      "grad_norm": 0.5853666663169861,
      "learning_rate": 4.606666666666667e-05,
      "loss": 0.0025,
      "step": 7080
    },
    {
      "epoch": 0.15755555555555556,
      "grad_norm": 0.3715531527996063,
      "learning_rate": 4.6061111111111114e-05,
      "loss": 0.003,
      "step": 7090
    },
    {
      "epoch": 0.15777777777777777,
      "grad_norm": 0.08001004159450531,
      "learning_rate": 4.605555555555556e-05,
      "loss": 0.0024,
      "step": 7100
    },
    {
      "epoch": 0.158,
      "grad_norm": 0.8277550339698792,
      "learning_rate": 4.605e-05,
      "loss": 0.0024,
      "step": 7110
    },
    {
      "epoch": 0.1582222222222222,
      "grad_norm": 0.09888133406639099,
      "learning_rate": 4.6044444444444445e-05,
      "loss": 0.0021,
      "step": 7120
    },
    {
      "epoch": 0.15844444444444444,
      "grad_norm": 0.5348217487335205,
      "learning_rate": 4.6038888888888895e-05,
      "loss": 0.0024,
      "step": 7130
    },
    {
      "epoch": 0.15866666666666668,
      "grad_norm": 0.5338298678398132,
      "learning_rate": 4.603333333333333e-05,
      "loss": 0.0023,
      "step": 7140
    },
    {
      "epoch": 0.15888888888888889,
      "grad_norm": 0.07780952006578445,
      "learning_rate": 4.602777777777778e-05,
      "loss": 0.002,
      "step": 7150
    },
    {
      "epoch": 0.15911111111111112,
      "grad_norm": 0.32588350772857666,
      "learning_rate": 4.602222222222222e-05,
      "loss": 0.0033,
      "step": 7160
    },
    {
      "epoch": 0.15933333333333333,
      "grad_norm": 0.5152071714401245,
      "learning_rate": 4.601666666666667e-05,
      "loss": 0.002,
      "step": 7170
    },
    {
      "epoch": 0.15955555555555556,
      "grad_norm": 0.288379430770874,
      "learning_rate": 4.601111111111111e-05,
      "loss": 0.0026,
      "step": 7180
    },
    {
      "epoch": 0.15977777777777777,
      "grad_norm": 0.5254493951797485,
      "learning_rate": 4.6005555555555556e-05,
      "loss": 0.0028,
      "step": 7190
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.47411319613456726,
      "learning_rate": 4.600000000000001e-05,
      "loss": 0.0019,
      "step": 7200
    },
    {
      "epoch": 0.1602222222222222,
      "grad_norm": 0.30079591274261475,
      "learning_rate": 4.5994444444444444e-05,
      "loss": 0.0019,
      "step": 7210
    },
    {
      "epoch": 0.16044444444444445,
      "grad_norm": 0.08977987617254257,
      "learning_rate": 4.5988888888888894e-05,
      "loss": 0.0027,
      "step": 7220
    },
    {
      "epoch": 0.16066666666666668,
      "grad_norm": 0.33831435441970825,
      "learning_rate": 4.598333333333333e-05,
      "loss": 0.0019,
      "step": 7230
    },
    {
      "epoch": 0.1608888888888889,
      "grad_norm": 0.21361446380615234,
      "learning_rate": 4.597777777777778e-05,
      "loss": 0.0032,
      "step": 7240
    },
    {
      "epoch": 0.16111111111111112,
      "grad_norm": 0.5265207290649414,
      "learning_rate": 4.5972222222222225e-05,
      "loss": 0.0025,
      "step": 7250
    },
    {
      "epoch": 0.16133333333333333,
      "grad_norm": 0.5149211883544922,
      "learning_rate": 4.596666666666667e-05,
      "loss": 0.0031,
      "step": 7260
    },
    {
      "epoch": 0.16155555555555556,
      "grad_norm": 0.3222373425960541,
      "learning_rate": 4.596111111111112e-05,
      "loss": 0.0028,
      "step": 7270
    },
    {
      "epoch": 0.16177777777777777,
      "grad_norm": 0.8346824049949646,
      "learning_rate": 4.5955555555555555e-05,
      "loss": 0.0034,
      "step": 7280
    },
    {
      "epoch": 0.162,
      "grad_norm": 0.09021694213151932,
      "learning_rate": 4.5950000000000006e-05,
      "loss": 0.0035,
      "step": 7290
    },
    {
      "epoch": 0.1622222222222222,
      "grad_norm": 0.546369731426239,
      "learning_rate": 4.594444444444444e-05,
      "loss": 0.0021,
      "step": 7300
    },
    {
      "epoch": 0.16244444444444445,
      "grad_norm": 0.13347329199314117,
      "learning_rate": 4.593888888888889e-05,
      "loss": 0.002,
      "step": 7310
    },
    {
      "epoch": 0.16266666666666665,
      "grad_norm": 0.1813848912715912,
      "learning_rate": 4.5933333333333336e-05,
      "loss": 0.002,
      "step": 7320
    },
    {
      "epoch": 0.1628888888888889,
      "grad_norm": 0.09687568247318268,
      "learning_rate": 4.592777777777778e-05,
      "loss": 0.0029,
      "step": 7330
    },
    {
      "epoch": 0.16311111111111112,
      "grad_norm": 0.2677570879459381,
      "learning_rate": 4.592222222222222e-05,
      "loss": 0.0025,
      "step": 7340
    },
    {
      "epoch": 0.16333333333333333,
      "grad_norm": 0.33598750829696655,
      "learning_rate": 4.591666666666667e-05,
      "loss": 0.0026,
      "step": 7350
    },
    {
      "epoch": 0.16355555555555557,
      "grad_norm": 0.2769095003604889,
      "learning_rate": 4.591111111111112e-05,
      "loss": 0.0024,
      "step": 7360
    },
    {
      "epoch": 0.16377777777777777,
      "grad_norm": 0.3278788924217224,
      "learning_rate": 4.5905555555555554e-05,
      "loss": 0.0029,
      "step": 7370
    },
    {
      "epoch": 0.164,
      "grad_norm": 0.17700284719467163,
      "learning_rate": 4.5900000000000004e-05,
      "loss": 0.0022,
      "step": 7380
    },
    {
      "epoch": 0.16422222222222221,
      "grad_norm": 0.1447528600692749,
      "learning_rate": 4.589444444444445e-05,
      "loss": 0.0022,
      "step": 7390
    },
    {
      "epoch": 0.16444444444444445,
      "grad_norm": 0.1779194176197052,
      "learning_rate": 4.588888888888889e-05,
      "loss": 0.0031,
      "step": 7400
    },
    {
      "epoch": 0.16466666666666666,
      "grad_norm": 0.6451154947280884,
      "learning_rate": 4.5883333333333335e-05,
      "loss": 0.0022,
      "step": 7410
    },
    {
      "epoch": 0.1648888888888889,
      "grad_norm": 0.18679706752300262,
      "learning_rate": 4.587777777777778e-05,
      "loss": 0.002,
      "step": 7420
    },
    {
      "epoch": 0.1651111111111111,
      "grad_norm": 0.37834835052490234,
      "learning_rate": 4.587222222222222e-05,
      "loss": 0.002,
      "step": 7430
    },
    {
      "epoch": 0.16533333333333333,
      "grad_norm": 0.2560677230358124,
      "learning_rate": 4.5866666666666666e-05,
      "loss": 0.002,
      "step": 7440
    },
    {
      "epoch": 0.16555555555555557,
      "grad_norm": 0.11535646766424179,
      "learning_rate": 4.5861111111111116e-05,
      "loss": 0.0021,
      "step": 7450
    },
    {
      "epoch": 0.16577777777777777,
      "grad_norm": 0.26324930787086487,
      "learning_rate": 4.585555555555556e-05,
      "loss": 0.0017,
      "step": 7460
    },
    {
      "epoch": 0.166,
      "grad_norm": 0.23629283905029297,
      "learning_rate": 4.585e-05,
      "loss": 0.0026,
      "step": 7470
    },
    {
      "epoch": 0.16622222222222222,
      "grad_norm": 0.11324132978916168,
      "learning_rate": 4.584444444444445e-05,
      "loss": 0.0024,
      "step": 7480
    },
    {
      "epoch": 0.16644444444444445,
      "grad_norm": 0.12050432711839676,
      "learning_rate": 4.583888888888889e-05,
      "loss": 0.0032,
      "step": 7490
    },
    {
      "epoch": 0.16666666666666666,
      "grad_norm": 0.1295040100812912,
      "learning_rate": 4.5833333333333334e-05,
      "loss": 0.0017,
      "step": 7500
    },
    {
      "epoch": 0.1668888888888889,
      "grad_norm": 0.28211885690689087,
      "learning_rate": 4.582777777777778e-05,
      "loss": 0.0018,
      "step": 7510
    },
    {
      "epoch": 0.1671111111111111,
      "grad_norm": 0.6643307209014893,
      "learning_rate": 4.582222222222222e-05,
      "loss": 0.0027,
      "step": 7520
    },
    {
      "epoch": 0.16733333333333333,
      "grad_norm": 0.10352413356304169,
      "learning_rate": 4.581666666666667e-05,
      "loss": 0.0029,
      "step": 7530
    },
    {
      "epoch": 0.16755555555555557,
      "grad_norm": 0.15501032769680023,
      "learning_rate": 4.5811111111111115e-05,
      "loss": 0.0027,
      "step": 7540
    },
    {
      "epoch": 0.16777777777777778,
      "grad_norm": 0.5332976579666138,
      "learning_rate": 4.580555555555556e-05,
      "loss": 0.0029,
      "step": 7550
    },
    {
      "epoch": 0.168,
      "grad_norm": 0.17555168271064758,
      "learning_rate": 4.58e-05,
      "loss": 0.0023,
      "step": 7560
    },
    {
      "epoch": 0.16822222222222222,
      "grad_norm": 0.36405274271965027,
      "learning_rate": 4.5794444444444446e-05,
      "loss": 0.0022,
      "step": 7570
    },
    {
      "epoch": 0.16844444444444445,
      "grad_norm": 0.3058820962905884,
      "learning_rate": 4.578888888888889e-05,
      "loss": 0.002,
      "step": 7580
    },
    {
      "epoch": 0.16866666666666666,
      "grad_norm": 0.3013482987880707,
      "learning_rate": 4.578333333333333e-05,
      "loss": 0.0027,
      "step": 7590
    },
    {
      "epoch": 0.1688888888888889,
      "grad_norm": 0.09433640539646149,
      "learning_rate": 4.577777777777778e-05,
      "loss": 0.0028,
      "step": 7600
    },
    {
      "epoch": 0.1691111111111111,
      "grad_norm": 0.5200780630111694,
      "learning_rate": 4.577222222222222e-05,
      "loss": 0.0021,
      "step": 7610
    },
    {
      "epoch": 0.16933333333333334,
      "grad_norm": 0.15467767417430878,
      "learning_rate": 4.576666666666667e-05,
      "loss": 0.0019,
      "step": 7620
    },
    {
      "epoch": 0.16955555555555554,
      "grad_norm": 0.513131856918335,
      "learning_rate": 4.5761111111111114e-05,
      "loss": 0.0021,
      "step": 7630
    },
    {
      "epoch": 0.16977777777777778,
      "grad_norm": 0.519201934337616,
      "learning_rate": 4.575555555555556e-05,
      "loss": 0.0023,
      "step": 7640
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.4600290060043335,
      "learning_rate": 4.575e-05,
      "loss": 0.0023,
      "step": 7650
    },
    {
      "epoch": 0.17022222222222222,
      "grad_norm": 0.35020914673805237,
      "learning_rate": 4.5744444444444444e-05,
      "loss": 0.002,
      "step": 7660
    },
    {
      "epoch": 0.17044444444444445,
      "grad_norm": 0.5017096996307373,
      "learning_rate": 4.5738888888888895e-05,
      "loss": 0.003,
      "step": 7670
    },
    {
      "epoch": 0.17066666666666666,
      "grad_norm": 0.3162284195423126,
      "learning_rate": 4.573333333333333e-05,
      "loss": 0.0028,
      "step": 7680
    },
    {
      "epoch": 0.1708888888888889,
      "grad_norm": 0.3854442238807678,
      "learning_rate": 4.572777777777778e-05,
      "loss": 0.0025,
      "step": 7690
    },
    {
      "epoch": 0.1711111111111111,
      "grad_norm": 0.09789397567510605,
      "learning_rate": 4.572222222222222e-05,
      "loss": 0.0027,
      "step": 7700
    },
    {
      "epoch": 0.17133333333333334,
      "grad_norm": 0.5780373215675354,
      "learning_rate": 4.571666666666667e-05,
      "loss": 0.0017,
      "step": 7710
    },
    {
      "epoch": 0.17155555555555554,
      "grad_norm": 0.439475953578949,
      "learning_rate": 4.571111111111111e-05,
      "loss": 0.0021,
      "step": 7720
    },
    {
      "epoch": 0.17177777777777778,
      "grad_norm": 0.17643487453460693,
      "learning_rate": 4.5705555555555556e-05,
      "loss": 0.0025,
      "step": 7730
    },
    {
      "epoch": 0.172,
      "grad_norm": 0.425977498292923,
      "learning_rate": 4.5700000000000006e-05,
      "loss": 0.0021,
      "step": 7740
    },
    {
      "epoch": 0.17222222222222222,
      "grad_norm": 0.979171633720398,
      "learning_rate": 4.569444444444444e-05,
      "loss": 0.0023,
      "step": 7750
    },
    {
      "epoch": 0.17244444444444446,
      "grad_norm": 0.24917440116405487,
      "learning_rate": 4.5688888888888893e-05,
      "loss": 0.0023,
      "step": 7760
    },
    {
      "epoch": 0.17266666666666666,
      "grad_norm": 0.39293304085731506,
      "learning_rate": 4.568333333333333e-05,
      "loss": 0.0022,
      "step": 7770
    },
    {
      "epoch": 0.1728888888888889,
      "grad_norm": 0.18771804869174957,
      "learning_rate": 4.567777777777778e-05,
      "loss": 0.0019,
      "step": 7780
    },
    {
      "epoch": 0.1731111111111111,
      "grad_norm": 0.10395628958940506,
      "learning_rate": 4.5672222222222224e-05,
      "loss": 0.0027,
      "step": 7790
    },
    {
      "epoch": 0.17333333333333334,
      "grad_norm": 0.38268131017684937,
      "learning_rate": 4.566666666666667e-05,
      "loss": 0.0024,
      "step": 7800
    },
    {
      "epoch": 0.17355555555555555,
      "grad_norm": 0.2294805347919464,
      "learning_rate": 4.566111111111112e-05,
      "loss": 0.0025,
      "step": 7810
    },
    {
      "epoch": 0.17377777777777778,
      "grad_norm": 0.7102019190788269,
      "learning_rate": 4.5655555555555555e-05,
      "loss": 0.0036,
      "step": 7820
    },
    {
      "epoch": 0.174,
      "grad_norm": 0.6438489556312561,
      "learning_rate": 4.5650000000000005e-05,
      "loss": 0.0022,
      "step": 7830
    },
    {
      "epoch": 0.17422222222222222,
      "grad_norm": 0.06623301655054092,
      "learning_rate": 4.564444444444444e-05,
      "loss": 0.0022,
      "step": 7840
    },
    {
      "epoch": 0.17444444444444446,
      "grad_norm": 0.22689375281333923,
      "learning_rate": 4.563888888888889e-05,
      "loss": 0.0031,
      "step": 7850
    },
    {
      "epoch": 0.17466666666666666,
      "grad_norm": 0.28565454483032227,
      "learning_rate": 4.5633333333333336e-05,
      "loss": 0.0027,
      "step": 7860
    },
    {
      "epoch": 0.1748888888888889,
      "grad_norm": 0.10335239768028259,
      "learning_rate": 4.562777777777778e-05,
      "loss": 0.0021,
      "step": 7870
    },
    {
      "epoch": 0.1751111111111111,
      "grad_norm": 0.27761590480804443,
      "learning_rate": 4.562222222222222e-05,
      "loss": 0.0019,
      "step": 7880
    },
    {
      "epoch": 0.17533333333333334,
      "grad_norm": 0.06283149868249893,
      "learning_rate": 4.5616666666666666e-05,
      "loss": 0.0027,
      "step": 7890
    },
    {
      "epoch": 0.17555555555555555,
      "grad_norm": 1.0105825662612915,
      "learning_rate": 4.561111111111112e-05,
      "loss": 0.0021,
      "step": 7900
    },
    {
      "epoch": 0.17577777777777778,
      "grad_norm": 0.29420801997184753,
      "learning_rate": 4.560555555555556e-05,
      "loss": 0.0023,
      "step": 7910
    },
    {
      "epoch": 0.176,
      "grad_norm": 0.5267698764801025,
      "learning_rate": 4.5600000000000004e-05,
      "loss": 0.0026,
      "step": 7920
    },
    {
      "epoch": 0.17622222222222222,
      "grad_norm": 0.22993171215057373,
      "learning_rate": 4.559444444444445e-05,
      "loss": 0.0021,
      "step": 7930
    },
    {
      "epoch": 0.17644444444444443,
      "grad_norm": 0.2191530466079712,
      "learning_rate": 4.558888888888889e-05,
      "loss": 0.0025,
      "step": 7940
    },
    {
      "epoch": 0.17666666666666667,
      "grad_norm": 0.36446458101272583,
      "learning_rate": 4.5583333333333335e-05,
      "loss": 0.0023,
      "step": 7950
    },
    {
      "epoch": 0.1768888888888889,
      "grad_norm": 0.1025657132267952,
      "learning_rate": 4.557777777777778e-05,
      "loss": 0.0021,
      "step": 7960
    },
    {
      "epoch": 0.1771111111111111,
      "grad_norm": 0.5702664256095886,
      "learning_rate": 4.557222222222222e-05,
      "loss": 0.0022,
      "step": 7970
    },
    {
      "epoch": 0.17733333333333334,
      "grad_norm": 0.5596723556518555,
      "learning_rate": 4.556666666666667e-05,
      "loss": 0.0033,
      "step": 7980
    },
    {
      "epoch": 0.17755555555555555,
      "grad_norm": 0.3577994406223297,
      "learning_rate": 4.5561111111111116e-05,
      "loss": 0.0025,
      "step": 7990
    },
    {
      "epoch": 0.17777777777777778,
      "grad_norm": 0.2225555181503296,
      "learning_rate": 4.555555555555556e-05,
      "loss": 0.0018,
      "step": 8000
    },
    {
      "epoch": 0.178,
      "grad_norm": 0.4051729142665863,
      "learning_rate": 4.555e-05,
      "loss": 0.0019,
      "step": 8010
    },
    {
      "epoch": 0.17822222222222223,
      "grad_norm": 0.18858259916305542,
      "learning_rate": 4.5544444444444446e-05,
      "loss": 0.0022,
      "step": 8020
    },
    {
      "epoch": 0.17844444444444443,
      "grad_norm": 0.2856435179710388,
      "learning_rate": 4.553888888888889e-05,
      "loss": 0.0023,
      "step": 8030
    },
    {
      "epoch": 0.17866666666666667,
      "grad_norm": 0.18852455914020538,
      "learning_rate": 4.553333333333333e-05,
      "loss": 0.0025,
      "step": 8040
    },
    {
      "epoch": 0.17888888888888888,
      "grad_norm": 0.11375447362661362,
      "learning_rate": 4.5527777777777784e-05,
      "loss": 0.0021,
      "step": 8050
    },
    {
      "epoch": 0.1791111111111111,
      "grad_norm": 0.07250942289829254,
      "learning_rate": 4.552222222222222e-05,
      "loss": 0.0022,
      "step": 8060
    },
    {
      "epoch": 0.17933333333333334,
      "grad_norm": 0.20974323153495789,
      "learning_rate": 4.551666666666667e-05,
      "loss": 0.0029,
      "step": 8070
    },
    {
      "epoch": 0.17955555555555555,
      "grad_norm": 0.13667799532413483,
      "learning_rate": 4.5511111111111114e-05,
      "loss": 0.0027,
      "step": 8080
    },
    {
      "epoch": 0.1797777777777778,
      "grad_norm": 0.33081182837486267,
      "learning_rate": 4.550555555555556e-05,
      "loss": 0.0026,
      "step": 8090
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.2857367694377899,
      "learning_rate": 4.55e-05,
      "loss": 0.0027,
      "step": 8100
    },
    {
      "epoch": 0.18022222222222223,
      "grad_norm": 0.20864345133304596,
      "learning_rate": 4.5494444444444445e-05,
      "loss": 0.0026,
      "step": 8110
    },
    {
      "epoch": 0.18044444444444444,
      "grad_norm": 0.2173609584569931,
      "learning_rate": 4.5488888888888895e-05,
      "loss": 0.0022,
      "step": 8120
    },
    {
      "epoch": 0.18066666666666667,
      "grad_norm": 0.3214811682701111,
      "learning_rate": 4.548333333333333e-05,
      "loss": 0.004,
      "step": 8130
    },
    {
      "epoch": 0.18088888888888888,
      "grad_norm": 0.7347515225410461,
      "learning_rate": 4.547777777777778e-05,
      "loss": 0.0018,
      "step": 8140
    },
    {
      "epoch": 0.1811111111111111,
      "grad_norm": 0.21161648631095886,
      "learning_rate": 4.5472222222222226e-05,
      "loss": 0.0026,
      "step": 8150
    },
    {
      "epoch": 0.18133333333333335,
      "grad_norm": 0.4553978145122528,
      "learning_rate": 4.546666666666667e-05,
      "loss": 0.002,
      "step": 8160
    },
    {
      "epoch": 0.18155555555555555,
      "grad_norm": 0.5796888470649719,
      "learning_rate": 4.546111111111111e-05,
      "loss": 0.0025,
      "step": 8170
    },
    {
      "epoch": 0.1817777777777778,
      "grad_norm": 0.10348668694496155,
      "learning_rate": 4.545555555555556e-05,
      "loss": 0.0021,
      "step": 8180
    },
    {
      "epoch": 0.182,
      "grad_norm": 0.044743165373802185,
      "learning_rate": 4.545000000000001e-05,
      "loss": 0.0023,
      "step": 8190
    },
    {
      "epoch": 0.18222222222222223,
      "grad_norm": 0.10344479233026505,
      "learning_rate": 4.5444444444444444e-05,
      "loss": 0.0025,
      "step": 8200
    },
    {
      "epoch": 0.18244444444444444,
      "grad_norm": 0.06563741713762283,
      "learning_rate": 4.5438888888888894e-05,
      "loss": 0.0025,
      "step": 8210
    },
    {
      "epoch": 0.18266666666666667,
      "grad_norm": 0.23238153755664825,
      "learning_rate": 4.543333333333333e-05,
      "loss": 0.0021,
      "step": 8220
    },
    {
      "epoch": 0.18288888888888888,
      "grad_norm": 0.20078080892562866,
      "learning_rate": 4.542777777777778e-05,
      "loss": 0.0022,
      "step": 8230
    },
    {
      "epoch": 0.1831111111111111,
      "grad_norm": 0.09929154068231583,
      "learning_rate": 4.5422222222222225e-05,
      "loss": 0.0023,
      "step": 8240
    },
    {
      "epoch": 0.18333333333333332,
      "grad_norm": 0.461078405380249,
      "learning_rate": 4.541666666666667e-05,
      "loss": 0.002,
      "step": 8250
    },
    {
      "epoch": 0.18355555555555556,
      "grad_norm": 0.11191276460886002,
      "learning_rate": 4.541111111111112e-05,
      "loss": 0.0022,
      "step": 8260
    },
    {
      "epoch": 0.1837777777777778,
      "grad_norm": 0.22916093468666077,
      "learning_rate": 4.5405555555555555e-05,
      "loss": 0.0023,
      "step": 8270
    },
    {
      "epoch": 0.184,
      "grad_norm": 0.11124330013990402,
      "learning_rate": 4.5400000000000006e-05,
      "loss": 0.0022,
      "step": 8280
    },
    {
      "epoch": 0.18422222222222223,
      "grad_norm": 0.13681262731552124,
      "learning_rate": 4.539444444444444e-05,
      "loss": 0.0023,
      "step": 8290
    },
    {
      "epoch": 0.18444444444444444,
      "grad_norm": 0.3408355712890625,
      "learning_rate": 4.538888888888889e-05,
      "loss": 0.0043,
      "step": 8300
    },
    {
      "epoch": 0.18466666666666667,
      "grad_norm": 0.11960823088884354,
      "learning_rate": 4.5383333333333336e-05,
      "loss": 0.0028,
      "step": 8310
    },
    {
      "epoch": 0.18488888888888888,
      "grad_norm": 0.1280045360326767,
      "learning_rate": 4.537777777777778e-05,
      "loss": 0.0021,
      "step": 8320
    },
    {
      "epoch": 0.18511111111111112,
      "grad_norm": 0.19700990617275238,
      "learning_rate": 4.537222222222223e-05,
      "loss": 0.002,
      "step": 8330
    },
    {
      "epoch": 0.18533333333333332,
      "grad_norm": 0.07950929552316666,
      "learning_rate": 4.536666666666667e-05,
      "loss": 0.0021,
      "step": 8340
    },
    {
      "epoch": 0.18555555555555556,
      "grad_norm": 0.15032804012298584,
      "learning_rate": 4.536111111111112e-05,
      "loss": 0.0024,
      "step": 8350
    },
    {
      "epoch": 0.18577777777777776,
      "grad_norm": 0.2548319697380066,
      "learning_rate": 4.5355555555555554e-05,
      "loss": 0.0024,
      "step": 8360
    },
    {
      "epoch": 0.186,
      "grad_norm": 0.3239092230796814,
      "learning_rate": 4.5350000000000005e-05,
      "loss": 0.0019,
      "step": 8370
    },
    {
      "epoch": 0.18622222222222223,
      "grad_norm": 0.24062864482402802,
      "learning_rate": 4.534444444444445e-05,
      "loss": 0.0028,
      "step": 8380
    },
    {
      "epoch": 0.18644444444444444,
      "grad_norm": 0.08740957081317902,
      "learning_rate": 4.533888888888889e-05,
      "loss": 0.0022,
      "step": 8390
    },
    {
      "epoch": 0.18666666666666668,
      "grad_norm": 0.4069017767906189,
      "learning_rate": 4.5333333333333335e-05,
      "loss": 0.0026,
      "step": 8400
    },
    {
      "epoch": 0.18688888888888888,
      "grad_norm": 0.3234952688217163,
      "learning_rate": 4.532777777777778e-05,
      "loss": 0.0027,
      "step": 8410
    },
    {
      "epoch": 0.18711111111111112,
      "grad_norm": 0.09232509136199951,
      "learning_rate": 4.532222222222223e-05,
      "loss": 0.0019,
      "step": 8420
    },
    {
      "epoch": 0.18733333333333332,
      "grad_norm": 0.44091588258743286,
      "learning_rate": 4.5316666666666666e-05,
      "loss": 0.0026,
      "step": 8430
    },
    {
      "epoch": 0.18755555555555556,
      "grad_norm": 0.33678001165390015,
      "learning_rate": 4.5311111111111116e-05,
      "loss": 0.004,
      "step": 8440
    },
    {
      "epoch": 0.18777777777777777,
      "grad_norm": 0.15476326644420624,
      "learning_rate": 4.530555555555556e-05,
      "loss": 0.0021,
      "step": 8450
    },
    {
      "epoch": 0.188,
      "grad_norm": 0.07737117260694504,
      "learning_rate": 4.53e-05,
      "loss": 0.0021,
      "step": 8460
    },
    {
      "epoch": 0.18822222222222224,
      "grad_norm": 0.2407485544681549,
      "learning_rate": 4.529444444444445e-05,
      "loss": 0.0028,
      "step": 8470
    },
    {
      "epoch": 0.18844444444444444,
      "grad_norm": 0.18760253489017487,
      "learning_rate": 4.528888888888889e-05,
      "loss": 0.0029,
      "step": 8480
    },
    {
      "epoch": 0.18866666666666668,
      "grad_norm": 0.0985187366604805,
      "learning_rate": 4.5283333333333334e-05,
      "loss": 0.0038,
      "step": 8490
    },
    {
      "epoch": 0.18888888888888888,
      "grad_norm": 0.49444299936294556,
      "learning_rate": 4.527777777777778e-05,
      "loss": 0.0024,
      "step": 8500
    },
    {
      "epoch": 0.18911111111111112,
      "grad_norm": 0.09011076390743256,
      "learning_rate": 4.527222222222223e-05,
      "loss": 0.0022,
      "step": 8510
    },
    {
      "epoch": 0.18933333333333333,
      "grad_norm": 0.23079492151737213,
      "learning_rate": 4.526666666666667e-05,
      "loss": 0.0025,
      "step": 8520
    },
    {
      "epoch": 0.18955555555555556,
      "grad_norm": 0.2324729561805725,
      "learning_rate": 4.5261111111111115e-05,
      "loss": 0.0022,
      "step": 8530
    },
    {
      "epoch": 0.18977777777777777,
      "grad_norm": 0.23698890209197998,
      "learning_rate": 4.525555555555556e-05,
      "loss": 0.002,
      "step": 8540
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.518109917640686,
      "learning_rate": 4.525e-05,
      "loss": 0.0022,
      "step": 8550
    },
    {
      "epoch": 0.1902222222222222,
      "grad_norm": 0.4147774875164032,
      "learning_rate": 4.5244444444444446e-05,
      "loss": 0.0031,
      "step": 8560
    },
    {
      "epoch": 0.19044444444444444,
      "grad_norm": 0.29271718859672546,
      "learning_rate": 4.523888888888889e-05,
      "loss": 0.0022,
      "step": 8570
    },
    {
      "epoch": 0.19066666666666668,
      "grad_norm": 0.06789151579141617,
      "learning_rate": 4.523333333333333e-05,
      "loss": 0.0028,
      "step": 8580
    },
    {
      "epoch": 0.19088888888888889,
      "grad_norm": 0.13752582669258118,
      "learning_rate": 4.522777777777778e-05,
      "loss": 0.0017,
      "step": 8590
    },
    {
      "epoch": 0.19111111111111112,
      "grad_norm": 0.3747495710849762,
      "learning_rate": 4.522222222222223e-05,
      "loss": 0.003,
      "step": 8600
    },
    {
      "epoch": 0.19133333333333333,
      "grad_norm": 0.23731674253940582,
      "learning_rate": 4.521666666666667e-05,
      "loss": 0.0028,
      "step": 8610
    },
    {
      "epoch": 0.19155555555555556,
      "grad_norm": 0.6096339225769043,
      "learning_rate": 4.5211111111111114e-05,
      "loss": 0.0022,
      "step": 8620
    },
    {
      "epoch": 0.19177777777777777,
      "grad_norm": 0.18456071615219116,
      "learning_rate": 4.520555555555556e-05,
      "loss": 0.0027,
      "step": 8630
    },
    {
      "epoch": 0.192,
      "grad_norm": 0.18587863445281982,
      "learning_rate": 4.52e-05,
      "loss": 0.0026,
      "step": 8640
    },
    {
      "epoch": 0.1922222222222222,
      "grad_norm": 0.18849311769008636,
      "learning_rate": 4.5194444444444444e-05,
      "loss": 0.0022,
      "step": 8650
    },
    {
      "epoch": 0.19244444444444445,
      "grad_norm": 0.26445624232292175,
      "learning_rate": 4.5188888888888895e-05,
      "loss": 0.0022,
      "step": 8660
    },
    {
      "epoch": 0.19266666666666668,
      "grad_norm": 0.4323269724845886,
      "learning_rate": 4.518333333333333e-05,
      "loss": 0.002,
      "step": 8670
    },
    {
      "epoch": 0.1928888888888889,
      "grad_norm": 0.08801605552434921,
      "learning_rate": 4.517777777777778e-05,
      "loss": 0.003,
      "step": 8680
    },
    {
      "epoch": 0.19311111111111112,
      "grad_norm": 0.5278593301773071,
      "learning_rate": 4.5172222222222225e-05,
      "loss": 0.0027,
      "step": 8690
    },
    {
      "epoch": 0.19333333333333333,
      "grad_norm": 0.19960138201713562,
      "learning_rate": 4.516666666666667e-05,
      "loss": 0.0028,
      "step": 8700
    },
    {
      "epoch": 0.19355555555555556,
      "grad_norm": 0.40606769919395447,
      "learning_rate": 4.516111111111111e-05,
      "loss": 0.0021,
      "step": 8710
    },
    {
      "epoch": 0.19377777777777777,
      "grad_norm": 0.07154685258865356,
      "learning_rate": 4.5155555555555556e-05,
      "loss": 0.0019,
      "step": 8720
    },
    {
      "epoch": 0.194,
      "grad_norm": 0.23129796981811523,
      "learning_rate": 4.5150000000000006e-05,
      "loss": 0.0024,
      "step": 8730
    },
    {
      "epoch": 0.1942222222222222,
      "grad_norm": 0.2319665253162384,
      "learning_rate": 4.514444444444444e-05,
      "loss": 0.0038,
      "step": 8740
    },
    {
      "epoch": 0.19444444444444445,
      "grad_norm": 0.13872036337852478,
      "learning_rate": 4.5138888888888894e-05,
      "loss": 0.0018,
      "step": 8750
    },
    {
      "epoch": 0.19466666666666665,
      "grad_norm": 1.1084257364273071,
      "learning_rate": 4.513333333333333e-05,
      "loss": 0.0022,
      "step": 8760
    },
    {
      "epoch": 0.1948888888888889,
      "grad_norm": 0.2579137086868286,
      "learning_rate": 4.512777777777778e-05,
      "loss": 0.0024,
      "step": 8770
    },
    {
      "epoch": 0.19511111111111112,
      "grad_norm": 0.18292367458343506,
      "learning_rate": 4.5122222222222224e-05,
      "loss": 0.0035,
      "step": 8780
    },
    {
      "epoch": 0.19533333333333333,
      "grad_norm": 0.22501878440380096,
      "learning_rate": 4.511666666666667e-05,
      "loss": 0.003,
      "step": 8790
    },
    {
      "epoch": 0.19555555555555557,
      "grad_norm": 0.18929658830165863,
      "learning_rate": 4.511111111111112e-05,
      "loss": 0.0026,
      "step": 8800
    },
    {
      "epoch": 0.19577777777777777,
      "grad_norm": 0.09051468968391418,
      "learning_rate": 4.5105555555555555e-05,
      "loss": 0.0022,
      "step": 8810
    },
    {
      "epoch": 0.196,
      "grad_norm": 0.25355222821235657,
      "learning_rate": 4.5100000000000005e-05,
      "loss": 0.0019,
      "step": 8820
    },
    {
      "epoch": 0.19622222222222221,
      "grad_norm": 0.11842254549264908,
      "learning_rate": 4.509444444444444e-05,
      "loss": 0.0025,
      "step": 8830
    },
    {
      "epoch": 0.19644444444444445,
      "grad_norm": 0.6116242408752441,
      "learning_rate": 4.508888888888889e-05,
      "loss": 0.0023,
      "step": 8840
    },
    {
      "epoch": 0.19666666666666666,
      "grad_norm": 0.1800856590270996,
      "learning_rate": 4.5083333333333336e-05,
      "loss": 0.0035,
      "step": 8850
    },
    {
      "epoch": 0.1968888888888889,
      "grad_norm": 0.32084470987319946,
      "learning_rate": 4.507777777777778e-05,
      "loss": 0.0023,
      "step": 8860
    },
    {
      "epoch": 0.1971111111111111,
      "grad_norm": 0.15896686911582947,
      "learning_rate": 4.507222222222223e-05,
      "loss": 0.0033,
      "step": 8870
    },
    {
      "epoch": 0.19733333333333333,
      "grad_norm": 0.7356580495834351,
      "learning_rate": 4.5066666666666667e-05,
      "loss": 0.0022,
      "step": 8880
    },
    {
      "epoch": 0.19755555555555557,
      "grad_norm": 0.3426799178123474,
      "learning_rate": 4.506111111111112e-05,
      "loss": 0.0025,
      "step": 8890
    },
    {
      "epoch": 0.19777777777777777,
      "grad_norm": 0.3970947861671448,
      "learning_rate": 4.5055555555555554e-05,
      "loss": 0.0024,
      "step": 8900
    },
    {
      "epoch": 0.198,
      "grad_norm": 0.23250722885131836,
      "learning_rate": 4.5050000000000004e-05,
      "loss": 0.0018,
      "step": 8910
    },
    {
      "epoch": 0.19822222222222222,
      "grad_norm": 0.4796593189239502,
      "learning_rate": 4.504444444444445e-05,
      "loss": 0.0024,
      "step": 8920
    },
    {
      "epoch": 0.19844444444444445,
      "grad_norm": 0.37076041102409363,
      "learning_rate": 4.503888888888889e-05,
      "loss": 0.0036,
      "step": 8930
    },
    {
      "epoch": 0.19866666666666666,
      "grad_norm": 0.2836012840270996,
      "learning_rate": 4.5033333333333335e-05,
      "loss": 0.0019,
      "step": 8940
    },
    {
      "epoch": 0.1988888888888889,
      "grad_norm": 0.3089466392993927,
      "learning_rate": 4.502777777777778e-05,
      "loss": 0.0022,
      "step": 8950
    },
    {
      "epoch": 0.1991111111111111,
      "grad_norm": 0.20073473453521729,
      "learning_rate": 4.502222222222223e-05,
      "loss": 0.002,
      "step": 8960
    },
    {
      "epoch": 0.19933333333333333,
      "grad_norm": 0.3527543842792511,
      "learning_rate": 4.5016666666666665e-05,
      "loss": 0.0019,
      "step": 8970
    },
    {
      "epoch": 0.19955555555555557,
      "grad_norm": 0.18119244277477264,
      "learning_rate": 4.5011111111111116e-05,
      "loss": 0.0023,
      "step": 8980
    },
    {
      "epoch": 0.19977777777777778,
      "grad_norm": 0.4327835142612457,
      "learning_rate": 4.500555555555556e-05,
      "loss": 0.0023,
      "step": 8990
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.3833872377872467,
      "learning_rate": 4.5e-05,
      "loss": 0.0023,
      "step": 9000
    },
    {
      "epoch": 0.20022222222222222,
      "grad_norm": 0.11367926001548767,
      "learning_rate": 4.4994444444444446e-05,
      "loss": 0.0023,
      "step": 9010
    },
    {
      "epoch": 0.20044444444444445,
      "grad_norm": 0.3635282516479492,
      "learning_rate": 4.498888888888889e-05,
      "loss": 0.0025,
      "step": 9020
    },
    {
      "epoch": 0.20066666666666666,
      "grad_norm": 0.5860576033592224,
      "learning_rate": 4.4983333333333334e-05,
      "loss": 0.0026,
      "step": 9030
    },
    {
      "epoch": 0.2008888888888889,
      "grad_norm": 0.4213685691356659,
      "learning_rate": 4.497777777777778e-05,
      "loss": 0.0022,
      "step": 9040
    },
    {
      "epoch": 0.2011111111111111,
      "grad_norm": 0.3685840368270874,
      "learning_rate": 4.497222222222223e-05,
      "loss": 0.0029,
      "step": 9050
    },
    {
      "epoch": 0.20133333333333334,
      "grad_norm": 0.39845606684684753,
      "learning_rate": 4.496666666666667e-05,
      "loss": 0.0029,
      "step": 9060
    },
    {
      "epoch": 0.20155555555555554,
      "grad_norm": 0.3205072581768036,
      "learning_rate": 4.4961111111111115e-05,
      "loss": 0.0027,
      "step": 9070
    },
    {
      "epoch": 0.20177777777777778,
      "grad_norm": 0.19367963075637817,
      "learning_rate": 4.495555555555556e-05,
      "loss": 0.0019,
      "step": 9080
    },
    {
      "epoch": 0.202,
      "grad_norm": 0.3970578908920288,
      "learning_rate": 4.495e-05,
      "loss": 0.0028,
      "step": 9090
    },
    {
      "epoch": 0.20222222222222222,
      "grad_norm": 0.41324490308761597,
      "learning_rate": 4.4944444444444445e-05,
      "loss": 0.002,
      "step": 9100
    },
    {
      "epoch": 0.20244444444444445,
      "grad_norm": 0.10380075126886368,
      "learning_rate": 4.493888888888889e-05,
      "loss": 0.0028,
      "step": 9110
    },
    {
      "epoch": 0.20266666666666666,
      "grad_norm": 0.5434147715568542,
      "learning_rate": 4.493333333333333e-05,
      "loss": 0.0019,
      "step": 9120
    },
    {
      "epoch": 0.2028888888888889,
      "grad_norm": 0.31774070858955383,
      "learning_rate": 4.492777777777778e-05,
      "loss": 0.0026,
      "step": 9130
    },
    {
      "epoch": 0.2031111111111111,
      "grad_norm": 0.4647757112979889,
      "learning_rate": 4.4922222222222226e-05,
      "loss": 0.0023,
      "step": 9140
    },
    {
      "epoch": 0.20333333333333334,
      "grad_norm": 0.15648408234119415,
      "learning_rate": 4.491666666666667e-05,
      "loss": 0.0024,
      "step": 9150
    },
    {
      "epoch": 0.20355555555555555,
      "grad_norm": 0.6324974894523621,
      "learning_rate": 4.491111111111111e-05,
      "loss": 0.0026,
      "step": 9160
    },
    {
      "epoch": 0.20377777777777778,
      "grad_norm": 0.5001170635223389,
      "learning_rate": 4.490555555555556e-05,
      "loss": 0.0024,
      "step": 9170
    },
    {
      "epoch": 0.204,
      "grad_norm": 0.6153891682624817,
      "learning_rate": 4.49e-05,
      "loss": 0.0022,
      "step": 9180
    },
    {
      "epoch": 0.20422222222222222,
      "grad_norm": 0.22066213190555573,
      "learning_rate": 4.4894444444444444e-05,
      "loss": 0.0024,
      "step": 9190
    },
    {
      "epoch": 0.20444444444444446,
      "grad_norm": 0.09473768621683121,
      "learning_rate": 4.4888888888888894e-05,
      "loss": 0.0031,
      "step": 9200
    },
    {
      "epoch": 0.20466666666666666,
      "grad_norm": 0.8369882106781006,
      "learning_rate": 4.488333333333333e-05,
      "loss": 0.0025,
      "step": 9210
    },
    {
      "epoch": 0.2048888888888889,
      "grad_norm": 0.08068714290857315,
      "learning_rate": 4.487777777777778e-05,
      "loss": 0.0024,
      "step": 9220
    },
    {
      "epoch": 0.2051111111111111,
      "grad_norm": 0.16976453363895416,
      "learning_rate": 4.4872222222222225e-05,
      "loss": 0.0021,
      "step": 9230
    },
    {
      "epoch": 0.20533333333333334,
      "grad_norm": 0.1149274930357933,
      "learning_rate": 4.486666666666667e-05,
      "loss": 0.0024,
      "step": 9240
    },
    {
      "epoch": 0.20555555555555555,
      "grad_norm": 0.10531359910964966,
      "learning_rate": 4.486111111111111e-05,
      "loss": 0.0024,
      "step": 9250
    },
    {
      "epoch": 0.20577777777777778,
      "grad_norm": 0.47476840019226074,
      "learning_rate": 4.4855555555555556e-05,
      "loss": 0.0021,
      "step": 9260
    },
    {
      "epoch": 0.206,
      "grad_norm": 0.2826838493347168,
      "learning_rate": 4.4850000000000006e-05,
      "loss": 0.0024,
      "step": 9270
    },
    {
      "epoch": 0.20622222222222222,
      "grad_norm": 0.18497444689273834,
      "learning_rate": 4.484444444444444e-05,
      "loss": 0.0022,
      "step": 9280
    },
    {
      "epoch": 0.20644444444444446,
      "grad_norm": 0.13178345561027527,
      "learning_rate": 4.483888888888889e-05,
      "loss": 0.0021,
      "step": 9290
    },
    {
      "epoch": 0.20666666666666667,
      "grad_norm": 0.4983195662498474,
      "learning_rate": 4.483333333333333e-05,
      "loss": 0.0024,
      "step": 9300
    },
    {
      "epoch": 0.2068888888888889,
      "grad_norm": 0.1771334707736969,
      "learning_rate": 4.482777777777778e-05,
      "loss": 0.0029,
      "step": 9310
    },
    {
      "epoch": 0.2071111111111111,
      "grad_norm": 0.08277776837348938,
      "learning_rate": 4.4822222222222224e-05,
      "loss": 0.0029,
      "step": 9320
    },
    {
      "epoch": 0.20733333333333334,
      "grad_norm": 0.7453472018241882,
      "learning_rate": 4.481666666666667e-05,
      "loss": 0.0029,
      "step": 9330
    },
    {
      "epoch": 0.20755555555555555,
      "grad_norm": 0.7466341853141785,
      "learning_rate": 4.481111111111112e-05,
      "loss": 0.0028,
      "step": 9340
    },
    {
      "epoch": 0.20777777777777778,
      "grad_norm": 0.1130112037062645,
      "learning_rate": 4.4805555555555554e-05,
      "loss": 0.0021,
      "step": 9350
    },
    {
      "epoch": 0.208,
      "grad_norm": 0.9980885982513428,
      "learning_rate": 4.4800000000000005e-05,
      "loss": 0.0025,
      "step": 9360
    },
    {
      "epoch": 0.20822222222222223,
      "grad_norm": 0.10312186181545258,
      "learning_rate": 4.479444444444444e-05,
      "loss": 0.0033,
      "step": 9370
    },
    {
      "epoch": 0.20844444444444443,
      "grad_norm": 0.3013392686843872,
      "learning_rate": 4.478888888888889e-05,
      "loss": 0.0029,
      "step": 9380
    },
    {
      "epoch": 0.20866666666666667,
      "grad_norm": 0.46773138642311096,
      "learning_rate": 4.4783333333333335e-05,
      "loss": 0.0033,
      "step": 9390
    },
    {
      "epoch": 0.2088888888888889,
      "grad_norm": 0.20779408514499664,
      "learning_rate": 4.477777777777778e-05,
      "loss": 0.002,
      "step": 9400
    },
    {
      "epoch": 0.2091111111111111,
      "grad_norm": 0.08763379603624344,
      "learning_rate": 4.477222222222223e-05,
      "loss": 0.0027,
      "step": 9410
    },
    {
      "epoch": 0.20933333333333334,
      "grad_norm": 0.09593907743692398,
      "learning_rate": 4.4766666666666666e-05,
      "loss": 0.003,
      "step": 9420
    },
    {
      "epoch": 0.20955555555555555,
      "grad_norm": 0.19997231662273407,
      "learning_rate": 4.4761111111111116e-05,
      "loss": 0.0028,
      "step": 9430
    },
    {
      "epoch": 0.20977777777777779,
      "grad_norm": 0.6586325168609619,
      "learning_rate": 4.475555555555555e-05,
      "loss": 0.0022,
      "step": 9440
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.21507558226585388,
      "learning_rate": 4.4750000000000004e-05,
      "loss": 0.0021,
      "step": 9450
    },
    {
      "epoch": 0.21022222222222223,
      "grad_norm": 0.3459387719631195,
      "learning_rate": 4.474444444444445e-05,
      "loss": 0.0029,
      "step": 9460
    },
    {
      "epoch": 0.21044444444444443,
      "grad_norm": 0.12647317349910736,
      "learning_rate": 4.473888888888889e-05,
      "loss": 0.0027,
      "step": 9470
    },
    {
      "epoch": 0.21066666666666667,
      "grad_norm": 0.2772887945175171,
      "learning_rate": 4.473333333333334e-05,
      "loss": 0.0022,
      "step": 9480
    },
    {
      "epoch": 0.21088888888888888,
      "grad_norm": 0.24307097494602203,
      "learning_rate": 4.472777777777778e-05,
      "loss": 0.0021,
      "step": 9490
    },
    {
      "epoch": 0.2111111111111111,
      "grad_norm": 0.43216225504875183,
      "learning_rate": 4.472222222222223e-05,
      "loss": 0.003,
      "step": 9500
    },
    {
      "epoch": 0.21133333333333335,
      "grad_norm": 0.3745139539241791,
      "learning_rate": 4.4716666666666665e-05,
      "loss": 0.0034,
      "step": 9510
    },
    {
      "epoch": 0.21155555555555555,
      "grad_norm": 0.36735013127326965,
      "learning_rate": 4.4711111111111115e-05,
      "loss": 0.0019,
      "step": 9520
    },
    {
      "epoch": 0.2117777777777778,
      "grad_norm": 0.28785380721092224,
      "learning_rate": 4.470555555555556e-05,
      "loss": 0.0031,
      "step": 9530
    },
    {
      "epoch": 0.212,
      "grad_norm": 0.12109118700027466,
      "learning_rate": 4.47e-05,
      "loss": 0.0018,
      "step": 9540
    },
    {
      "epoch": 0.21222222222222223,
      "grad_norm": 0.10889898240566254,
      "learning_rate": 4.4694444444444446e-05,
      "loss": 0.0021,
      "step": 9550
    },
    {
      "epoch": 0.21244444444444444,
      "grad_norm": 0.118297278881073,
      "learning_rate": 4.468888888888889e-05,
      "loss": 0.0039,
      "step": 9560
    },
    {
      "epoch": 0.21266666666666667,
      "grad_norm": 0.09159296751022339,
      "learning_rate": 4.468333333333334e-05,
      "loss": 0.0021,
      "step": 9570
    },
    {
      "epoch": 0.21288888888888888,
      "grad_norm": 0.09231496602296829,
      "learning_rate": 4.4677777777777777e-05,
      "loss": 0.0025,
      "step": 9580
    },
    {
      "epoch": 0.2131111111111111,
      "grad_norm": 0.4637409448623657,
      "learning_rate": 4.467222222222223e-05,
      "loss": 0.0025,
      "step": 9590
    },
    {
      "epoch": 0.21333333333333335,
      "grad_norm": 0.22884179651737213,
      "learning_rate": 4.466666666666667e-05,
      "loss": 0.0022,
      "step": 9600
    },
    {
      "epoch": 0.21355555555555555,
      "grad_norm": 0.07245699316263199,
      "learning_rate": 4.4661111111111114e-05,
      "loss": 0.0021,
      "step": 9610
    },
    {
      "epoch": 0.2137777777777778,
      "grad_norm": 0.18169517815113068,
      "learning_rate": 4.465555555555556e-05,
      "loss": 0.0024,
      "step": 9620
    },
    {
      "epoch": 0.214,
      "grad_norm": 0.0897071585059166,
      "learning_rate": 4.465e-05,
      "loss": 0.0026,
      "step": 9630
    },
    {
      "epoch": 0.21422222222222223,
      "grad_norm": 0.09970974922180176,
      "learning_rate": 4.4644444444444445e-05,
      "loss": 0.0021,
      "step": 9640
    },
    {
      "epoch": 0.21444444444444444,
      "grad_norm": 0.46587714552879333,
      "learning_rate": 4.463888888888889e-05,
      "loss": 0.0031,
      "step": 9650
    },
    {
      "epoch": 0.21466666666666667,
      "grad_norm": 0.4351731836795807,
      "learning_rate": 4.463333333333334e-05,
      "loss": 0.0032,
      "step": 9660
    },
    {
      "epoch": 0.21488888888888888,
      "grad_norm": 0.30238279700279236,
      "learning_rate": 4.462777777777778e-05,
      "loss": 0.0039,
      "step": 9670
    },
    {
      "epoch": 0.21511111111111111,
      "grad_norm": 0.1043529137969017,
      "learning_rate": 4.4622222222222226e-05,
      "loss": 0.0038,
      "step": 9680
    },
    {
      "epoch": 0.21533333333333332,
      "grad_norm": 0.1797737330198288,
      "learning_rate": 4.461666666666667e-05,
      "loss": 0.0021,
      "step": 9690
    },
    {
      "epoch": 0.21555555555555556,
      "grad_norm": 0.16848883032798767,
      "learning_rate": 4.461111111111111e-05,
      "loss": 0.0023,
      "step": 9700
    },
    {
      "epoch": 0.2157777777777778,
      "grad_norm": 0.6061630249023438,
      "learning_rate": 4.4605555555555556e-05,
      "loss": 0.002,
      "step": 9710
    },
    {
      "epoch": 0.216,
      "grad_norm": 0.6489899754524231,
      "learning_rate": 4.46e-05,
      "loss": 0.0022,
      "step": 9720
    },
    {
      "epoch": 0.21622222222222223,
      "grad_norm": 0.6933639049530029,
      "learning_rate": 4.4594444444444443e-05,
      "loss": 0.003,
      "step": 9730
    },
    {
      "epoch": 0.21644444444444444,
      "grad_norm": 0.17535991966724396,
      "learning_rate": 4.4588888888888894e-05,
      "loss": 0.0022,
      "step": 9740
    },
    {
      "epoch": 0.21666666666666667,
      "grad_norm": 0.44246038794517517,
      "learning_rate": 4.458333333333334e-05,
      "loss": 0.0022,
      "step": 9750
    },
    {
      "epoch": 0.21688888888888888,
      "grad_norm": 0.3955530524253845,
      "learning_rate": 4.457777777777778e-05,
      "loss": 0.0021,
      "step": 9760
    },
    {
      "epoch": 0.21711111111111112,
      "grad_norm": 0.18518702685832977,
      "learning_rate": 4.4572222222222224e-05,
      "loss": 0.002,
      "step": 9770
    },
    {
      "epoch": 0.21733333333333332,
      "grad_norm": 0.5012825727462769,
      "learning_rate": 4.456666666666667e-05,
      "loss": 0.0027,
      "step": 9780
    },
    {
      "epoch": 0.21755555555555556,
      "grad_norm": 0.2082461416721344,
      "learning_rate": 4.456111111111111e-05,
      "loss": 0.0022,
      "step": 9790
    },
    {
      "epoch": 0.21777777777777776,
      "grad_norm": 0.3099267780780792,
      "learning_rate": 4.4555555555555555e-05,
      "loss": 0.0024,
      "step": 9800
    },
    {
      "epoch": 0.218,
      "grad_norm": 0.2430058866739273,
      "learning_rate": 4.4550000000000005e-05,
      "loss": 0.0026,
      "step": 9810
    },
    {
      "epoch": 0.21822222222222223,
      "grad_norm": 0.2717766761779785,
      "learning_rate": 4.454444444444444e-05,
      "loss": 0.0024,
      "step": 9820
    },
    {
      "epoch": 0.21844444444444444,
      "grad_norm": 0.7615026831626892,
      "learning_rate": 4.453888888888889e-05,
      "loss": 0.002,
      "step": 9830
    },
    {
      "epoch": 0.21866666666666668,
      "grad_norm": 0.08616174012422562,
      "learning_rate": 4.4533333333333336e-05,
      "loss": 0.003,
      "step": 9840
    },
    {
      "epoch": 0.21888888888888888,
      "grad_norm": 0.24312862753868103,
      "learning_rate": 4.452777777777778e-05,
      "loss": 0.0035,
      "step": 9850
    },
    {
      "epoch": 0.21911111111111112,
      "grad_norm": 0.1577836126089096,
      "learning_rate": 4.452222222222222e-05,
      "loss": 0.0026,
      "step": 9860
    },
    {
      "epoch": 0.21933333333333332,
      "grad_norm": 0.14786340296268463,
      "learning_rate": 4.451666666666667e-05,
      "loss": 0.0022,
      "step": 9870
    },
    {
      "epoch": 0.21955555555555556,
      "grad_norm": 0.08228307217359543,
      "learning_rate": 4.451111111111112e-05,
      "loss": 0.0017,
      "step": 9880
    },
    {
      "epoch": 0.21977777777777777,
      "grad_norm": 0.424804151058197,
      "learning_rate": 4.4505555555555554e-05,
      "loss": 0.0026,
      "step": 9890
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.17645545303821564,
      "learning_rate": 4.4500000000000004e-05,
      "loss": 0.0027,
      "step": 9900
    },
    {
      "epoch": 0.22022222222222224,
      "grad_norm": 0.5579501390457153,
      "learning_rate": 4.449444444444444e-05,
      "loss": 0.002,
      "step": 9910
    },
    {
      "epoch": 0.22044444444444444,
      "grad_norm": 0.19912327826023102,
      "learning_rate": 4.448888888888889e-05,
      "loss": 0.0026,
      "step": 9920
    },
    {
      "epoch": 0.22066666666666668,
      "grad_norm": 0.32681459188461304,
      "learning_rate": 4.4483333333333335e-05,
      "loss": 0.002,
      "step": 9930
    },
    {
      "epoch": 0.22088888888888888,
      "grad_norm": 0.19294573366641998,
      "learning_rate": 4.447777777777778e-05,
      "loss": 0.0031,
      "step": 9940
    },
    {
      "epoch": 0.22111111111111112,
      "grad_norm": 0.19217173755168915,
      "learning_rate": 4.447222222222223e-05,
      "loss": 0.002,
      "step": 9950
    },
    {
      "epoch": 0.22133333333333333,
      "grad_norm": 0.14133432507514954,
      "learning_rate": 4.4466666666666666e-05,
      "loss": 0.0025,
      "step": 9960
    },
    {
      "epoch": 0.22155555555555556,
      "grad_norm": 0.7801581621170044,
      "learning_rate": 4.4461111111111116e-05,
      "loss": 0.0021,
      "step": 9970
    },
    {
      "epoch": 0.22177777777777777,
      "grad_norm": 0.14560435712337494,
      "learning_rate": 4.445555555555555e-05,
      "loss": 0.0024,
      "step": 9980
    },
    {
      "epoch": 0.222,
      "grad_norm": 0.7016459107398987,
      "learning_rate": 4.445e-05,
      "loss": 0.0022,
      "step": 9990
    },
    {
      "epoch": 0.2222222222222222,
      "grad_norm": 0.1358577013015747,
      "learning_rate": 4.4444444444444447e-05,
      "loss": 0.0022,
      "step": 10000
    },
    {
      "epoch": 0.22244444444444444,
      "grad_norm": 0.1874624490737915,
      "learning_rate": 4.443888888888889e-05,
      "loss": 0.0018,
      "step": 10010
    },
    {
      "epoch": 0.22266666666666668,
      "grad_norm": 0.22644701600074768,
      "learning_rate": 4.443333333333334e-05,
      "loss": 0.0021,
      "step": 10020
    },
    {
      "epoch": 0.2228888888888889,
      "grad_norm": 0.3984869718551636,
      "learning_rate": 4.442777777777778e-05,
      "loss": 0.0025,
      "step": 10030
    },
    {
      "epoch": 0.22311111111111112,
      "grad_norm": 0.3682888150215149,
      "learning_rate": 4.442222222222223e-05,
      "loss": 0.0023,
      "step": 10040
    },
    {
      "epoch": 0.22333333333333333,
      "grad_norm": 0.6181241273880005,
      "learning_rate": 4.4416666666666664e-05,
      "loss": 0.0022,
      "step": 10050
    },
    {
      "epoch": 0.22355555555555556,
      "grad_norm": 0.8591498732566833,
      "learning_rate": 4.4411111111111115e-05,
      "loss": 0.0023,
      "step": 10060
    },
    {
      "epoch": 0.22377777777777777,
      "grad_norm": 0.15405070781707764,
      "learning_rate": 4.440555555555556e-05,
      "loss": 0.0022,
      "step": 10070
    },
    {
      "epoch": 0.224,
      "grad_norm": 0.0679730772972107,
      "learning_rate": 4.44e-05,
      "loss": 0.0019,
      "step": 10080
    },
    {
      "epoch": 0.2242222222222222,
      "grad_norm": 0.3273687958717346,
      "learning_rate": 4.4394444444444445e-05,
      "loss": 0.0025,
      "step": 10090
    },
    {
      "epoch": 0.22444444444444445,
      "grad_norm": 0.3308854103088379,
      "learning_rate": 4.438888888888889e-05,
      "loss": 0.0022,
      "step": 10100
    },
    {
      "epoch": 0.22466666666666665,
      "grad_norm": 0.4582864046096802,
      "learning_rate": 4.438333333333334e-05,
      "loss": 0.002,
      "step": 10110
    },
    {
      "epoch": 0.2248888888888889,
      "grad_norm": 0.5636894106864929,
      "learning_rate": 4.4377777777777776e-05,
      "loss": 0.0034,
      "step": 10120
    },
    {
      "epoch": 0.22511111111111112,
      "grad_norm": 0.09616278856992722,
      "learning_rate": 4.4372222222222226e-05,
      "loss": 0.0023,
      "step": 10130
    },
    {
      "epoch": 0.22533333333333333,
      "grad_norm": 0.2725682258605957,
      "learning_rate": 4.436666666666667e-05,
      "loss": 0.0037,
      "step": 10140
    },
    {
      "epoch": 0.22555555555555556,
      "grad_norm": 0.11650343239307404,
      "learning_rate": 4.4361111111111113e-05,
      "loss": 0.0021,
      "step": 10150
    },
    {
      "epoch": 0.22577777777777777,
      "grad_norm": 0.8177209496498108,
      "learning_rate": 4.435555555555556e-05,
      "loss": 0.0023,
      "step": 10160
    },
    {
      "epoch": 0.226,
      "grad_norm": 0.34058621525764465,
      "learning_rate": 4.435e-05,
      "loss": 0.0025,
      "step": 10170
    },
    {
      "epoch": 0.2262222222222222,
      "grad_norm": 0.15620601177215576,
      "learning_rate": 4.4344444444444444e-05,
      "loss": 0.0026,
      "step": 10180
    },
    {
      "epoch": 0.22644444444444445,
      "grad_norm": 0.13459159433841705,
      "learning_rate": 4.433888888888889e-05,
      "loss": 0.0023,
      "step": 10190
    },
    {
      "epoch": 0.22666666666666666,
      "grad_norm": 0.08336322754621506,
      "learning_rate": 4.433333333333334e-05,
      "loss": 0.0019,
      "step": 10200
    },
    {
      "epoch": 0.2268888888888889,
      "grad_norm": 0.07173904031515121,
      "learning_rate": 4.432777777777778e-05,
      "loss": 0.0026,
      "step": 10210
    },
    {
      "epoch": 0.22711111111111112,
      "grad_norm": 0.49041280150413513,
      "learning_rate": 4.4322222222222225e-05,
      "loss": 0.0024,
      "step": 10220
    },
    {
      "epoch": 0.22733333333333333,
      "grad_norm": 0.15722939372062683,
      "learning_rate": 4.431666666666667e-05,
      "loss": 0.0019,
      "step": 10230
    },
    {
      "epoch": 0.22755555555555557,
      "grad_norm": 0.20408207178115845,
      "learning_rate": 4.431111111111111e-05,
      "loss": 0.0018,
      "step": 10240
    },
    {
      "epoch": 0.22777777777777777,
      "grad_norm": 0.39167821407318115,
      "learning_rate": 4.4305555555555556e-05,
      "loss": 0.0024,
      "step": 10250
    },
    {
      "epoch": 0.228,
      "grad_norm": 0.274942010641098,
      "learning_rate": 4.43e-05,
      "loss": 0.002,
      "step": 10260
    },
    {
      "epoch": 0.22822222222222222,
      "grad_norm": 0.31088986992836,
      "learning_rate": 4.429444444444444e-05,
      "loss": 0.0024,
      "step": 10270
    },
    {
      "epoch": 0.22844444444444445,
      "grad_norm": 0.7720872163772583,
      "learning_rate": 4.428888888888889e-05,
      "loss": 0.002,
      "step": 10280
    },
    {
      "epoch": 0.22866666666666666,
      "grad_norm": 0.613040566444397,
      "learning_rate": 4.428333333333334e-05,
      "loss": 0.0032,
      "step": 10290
    },
    {
      "epoch": 0.2288888888888889,
      "grad_norm": 0.147223562002182,
      "learning_rate": 4.427777777777778e-05,
      "loss": 0.002,
      "step": 10300
    },
    {
      "epoch": 0.2291111111111111,
      "grad_norm": 0.2557946741580963,
      "learning_rate": 4.4272222222222224e-05,
      "loss": 0.0025,
      "step": 10310
    },
    {
      "epoch": 0.22933333333333333,
      "grad_norm": 0.10395238548517227,
      "learning_rate": 4.426666666666667e-05,
      "loss": 0.0029,
      "step": 10320
    },
    {
      "epoch": 0.22955555555555557,
      "grad_norm": 0.38953089714050293,
      "learning_rate": 4.426111111111111e-05,
      "loss": 0.0022,
      "step": 10330
    },
    {
      "epoch": 0.22977777777777778,
      "grad_norm": 0.3838096857070923,
      "learning_rate": 4.4255555555555555e-05,
      "loss": 0.0029,
      "step": 10340
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.3467031419277191,
      "learning_rate": 4.4250000000000005e-05,
      "loss": 0.0022,
      "step": 10350
    },
    {
      "epoch": 0.23022222222222222,
      "grad_norm": 0.0704272910952568,
      "learning_rate": 4.424444444444444e-05,
      "loss": 0.0029,
      "step": 10360
    },
    {
      "epoch": 0.23044444444444445,
      "grad_norm": 0.34290051460266113,
      "learning_rate": 4.423888888888889e-05,
      "loss": 0.002,
      "step": 10370
    },
    {
      "epoch": 0.23066666666666666,
      "grad_norm": 0.11366521567106247,
      "learning_rate": 4.4233333333333336e-05,
      "loss": 0.002,
      "step": 10380
    },
    {
      "epoch": 0.2308888888888889,
      "grad_norm": 0.28106099367141724,
      "learning_rate": 4.422777777777778e-05,
      "loss": 0.0034,
      "step": 10390
    },
    {
      "epoch": 0.2311111111111111,
      "grad_norm": 0.6614365577697754,
      "learning_rate": 4.422222222222222e-05,
      "loss": 0.0023,
      "step": 10400
    },
    {
      "epoch": 0.23133333333333334,
      "grad_norm": 0.07588458061218262,
      "learning_rate": 4.4216666666666666e-05,
      "loss": 0.0034,
      "step": 10410
    },
    {
      "epoch": 0.23155555555555554,
      "grad_norm": 0.45749908685684204,
      "learning_rate": 4.4211111111111117e-05,
      "loss": 0.0023,
      "step": 10420
    },
    {
      "epoch": 0.23177777777777778,
      "grad_norm": 0.192323699593544,
      "learning_rate": 4.420555555555555e-05,
      "loss": 0.0027,
      "step": 10430
    },
    {
      "epoch": 0.232,
      "grad_norm": 0.09496759623289108,
      "learning_rate": 4.4200000000000004e-05,
      "loss": 0.0026,
      "step": 10440
    },
    {
      "epoch": 0.23222222222222222,
      "grad_norm": 0.14072300493717194,
      "learning_rate": 4.419444444444444e-05,
      "loss": 0.0028,
      "step": 10450
    },
    {
      "epoch": 0.23244444444444445,
      "grad_norm": 0.4255964457988739,
      "learning_rate": 4.418888888888889e-05,
      "loss": 0.0029,
      "step": 10460
    },
    {
      "epoch": 0.23266666666666666,
      "grad_norm": 0.09909185022115707,
      "learning_rate": 4.4183333333333334e-05,
      "loss": 0.0019,
      "step": 10470
    },
    {
      "epoch": 0.2328888888888889,
      "grad_norm": 0.16445358097553253,
      "learning_rate": 4.417777777777778e-05,
      "loss": 0.0021,
      "step": 10480
    },
    {
      "epoch": 0.2331111111111111,
      "grad_norm": 0.31521227955818176,
      "learning_rate": 4.417222222222223e-05,
      "loss": 0.0018,
      "step": 10490
    },
    {
      "epoch": 0.23333333333333334,
      "grad_norm": 0.44748127460479736,
      "learning_rate": 4.4166666666666665e-05,
      "loss": 0.0023,
      "step": 10500
    },
    {
      "epoch": 0.23355555555555554,
      "grad_norm": 0.3464817404747009,
      "learning_rate": 4.4161111111111115e-05,
      "loss": 0.0018,
      "step": 10510
    },
    {
      "epoch": 0.23377777777777778,
      "grad_norm": 0.27110978960990906,
      "learning_rate": 4.415555555555556e-05,
      "loss": 0.002,
      "step": 10520
    },
    {
      "epoch": 0.234,
      "grad_norm": 0.20814062654972076,
      "learning_rate": 4.415e-05,
      "loss": 0.0019,
      "step": 10530
    },
    {
      "epoch": 0.23422222222222222,
      "grad_norm": 0.07732021808624268,
      "learning_rate": 4.4144444444444446e-05,
      "loss": 0.0023,
      "step": 10540
    },
    {
      "epoch": 0.23444444444444446,
      "grad_norm": 0.3618537187576294,
      "learning_rate": 4.413888888888889e-05,
      "loss": 0.002,
      "step": 10550
    },
    {
      "epoch": 0.23466666666666666,
      "grad_norm": 0.1992321014404297,
      "learning_rate": 4.413333333333334e-05,
      "loss": 0.0029,
      "step": 10560
    },
    {
      "epoch": 0.2348888888888889,
      "grad_norm": 0.3204159438610077,
      "learning_rate": 4.412777777777778e-05,
      "loss": 0.0031,
      "step": 10570
    },
    {
      "epoch": 0.2351111111111111,
      "grad_norm": 0.2675580382347107,
      "learning_rate": 4.412222222222223e-05,
      "loss": 0.0024,
      "step": 10580
    },
    {
      "epoch": 0.23533333333333334,
      "grad_norm": 0.2637679874897003,
      "learning_rate": 4.411666666666667e-05,
      "loss": 0.0025,
      "step": 10590
    },
    {
      "epoch": 0.23555555555555555,
      "grad_norm": 0.13510273396968842,
      "learning_rate": 4.4111111111111114e-05,
      "loss": 0.0023,
      "step": 10600
    },
    {
      "epoch": 0.23577777777777778,
      "grad_norm": 0.19380387663841248,
      "learning_rate": 4.410555555555556e-05,
      "loss": 0.0022,
      "step": 10610
    },
    {
      "epoch": 0.236,
      "grad_norm": 0.24906954169273376,
      "learning_rate": 4.41e-05,
      "loss": 0.003,
      "step": 10620
    },
    {
      "epoch": 0.23622222222222222,
      "grad_norm": 0.1509614884853363,
      "learning_rate": 4.409444444444445e-05,
      "loss": 0.0028,
      "step": 10630
    },
    {
      "epoch": 0.23644444444444446,
      "grad_norm": 0.1716349869966507,
      "learning_rate": 4.408888888888889e-05,
      "loss": 0.0023,
      "step": 10640
    },
    {
      "epoch": 0.23666666666666666,
      "grad_norm": 0.10288066416978836,
      "learning_rate": 4.408333333333334e-05,
      "loss": 0.0027,
      "step": 10650
    },
    {
      "epoch": 0.2368888888888889,
      "grad_norm": 0.20990797877311707,
      "learning_rate": 4.407777777777778e-05,
      "loss": 0.0025,
      "step": 10660
    },
    {
      "epoch": 0.2371111111111111,
      "grad_norm": 0.42104101181030273,
      "learning_rate": 4.4072222222222226e-05,
      "loss": 0.003,
      "step": 10670
    },
    {
      "epoch": 0.23733333333333334,
      "grad_norm": 0.13807950913906097,
      "learning_rate": 4.406666666666667e-05,
      "loss": 0.0034,
      "step": 10680
    },
    {
      "epoch": 0.23755555555555555,
      "grad_norm": 0.4604295492172241,
      "learning_rate": 4.406111111111111e-05,
      "loss": 0.0042,
      "step": 10690
    },
    {
      "epoch": 0.23777777777777778,
      "grad_norm": 0.17167975008487701,
      "learning_rate": 4.4055555555555557e-05,
      "loss": 0.0026,
      "step": 10700
    },
    {
      "epoch": 0.238,
      "grad_norm": 0.11014122515916824,
      "learning_rate": 4.405e-05,
      "loss": 0.0028,
      "step": 10710
    },
    {
      "epoch": 0.23822222222222222,
      "grad_norm": 0.10486368834972382,
      "learning_rate": 4.404444444444445e-05,
      "loss": 0.0035,
      "step": 10720
    },
    {
      "epoch": 0.23844444444444443,
      "grad_norm": 0.08533252775669098,
      "learning_rate": 4.4038888888888894e-05,
      "loss": 0.0026,
      "step": 10730
    },
    {
      "epoch": 0.23866666666666667,
      "grad_norm": 0.1419665813446045,
      "learning_rate": 4.403333333333334e-05,
      "loss": 0.002,
      "step": 10740
    },
    {
      "epoch": 0.2388888888888889,
      "grad_norm": 0.3470931351184845,
      "learning_rate": 4.402777777777778e-05,
      "loss": 0.0022,
      "step": 10750
    },
    {
      "epoch": 0.2391111111111111,
      "grad_norm": 0.6409556269645691,
      "learning_rate": 4.4022222222222225e-05,
      "loss": 0.0022,
      "step": 10760
    },
    {
      "epoch": 0.23933333333333334,
      "grad_norm": 0.13471710681915283,
      "learning_rate": 4.401666666666667e-05,
      "loss": 0.0028,
      "step": 10770
    },
    {
      "epoch": 0.23955555555555555,
      "grad_norm": 0.1815672665834427,
      "learning_rate": 4.401111111111111e-05,
      "loss": 0.003,
      "step": 10780
    },
    {
      "epoch": 0.23977777777777778,
      "grad_norm": 0.1493932008743286,
      "learning_rate": 4.4005555555555555e-05,
      "loss": 0.0029,
      "step": 10790
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.15415897965431213,
      "learning_rate": 4.4000000000000006e-05,
      "loss": 0.0021,
      "step": 10800
    },
    {
      "epoch": 0.24022222222222223,
      "grad_norm": 0.459195613861084,
      "learning_rate": 4.399444444444445e-05,
      "loss": 0.0026,
      "step": 10810
    },
    {
      "epoch": 0.24044444444444443,
      "grad_norm": 0.15729176998138428,
      "learning_rate": 4.398888888888889e-05,
      "loss": 0.0021,
      "step": 10820
    },
    {
      "epoch": 0.24066666666666667,
      "grad_norm": 0.5220065712928772,
      "learning_rate": 4.3983333333333336e-05,
      "loss": 0.0021,
      "step": 10830
    },
    {
      "epoch": 0.2408888888888889,
      "grad_norm": 0.5391056537628174,
      "learning_rate": 4.397777777777778e-05,
      "loss": 0.0023,
      "step": 10840
    },
    {
      "epoch": 0.2411111111111111,
      "grad_norm": 0.2175266295671463,
      "learning_rate": 4.3972222222222223e-05,
      "loss": 0.0024,
      "step": 10850
    },
    {
      "epoch": 0.24133333333333334,
      "grad_norm": 0.3032051622867584,
      "learning_rate": 4.396666666666667e-05,
      "loss": 0.0022,
      "step": 10860
    },
    {
      "epoch": 0.24155555555555555,
      "grad_norm": 0.22730158269405365,
      "learning_rate": 4.396111111111112e-05,
      "loss": 0.0025,
      "step": 10870
    },
    {
      "epoch": 0.24177777777777779,
      "grad_norm": 0.29349803924560547,
      "learning_rate": 4.3955555555555554e-05,
      "loss": 0.0028,
      "step": 10880
    },
    {
      "epoch": 0.242,
      "grad_norm": 0.39311158657073975,
      "learning_rate": 4.3950000000000004e-05,
      "loss": 0.0023,
      "step": 10890
    },
    {
      "epoch": 0.24222222222222223,
      "grad_norm": 0.7280681729316711,
      "learning_rate": 4.394444444444445e-05,
      "loss": 0.003,
      "step": 10900
    },
    {
      "epoch": 0.24244444444444443,
      "grad_norm": 0.3731537461280823,
      "learning_rate": 4.393888888888889e-05,
      "loss": 0.002,
      "step": 10910
    },
    {
      "epoch": 0.24266666666666667,
      "grad_norm": 0.3928637206554413,
      "learning_rate": 4.3933333333333335e-05,
      "loss": 0.0029,
      "step": 10920
    },
    {
      "epoch": 0.24288888888888888,
      "grad_norm": 0.08277934789657593,
      "learning_rate": 4.392777777777778e-05,
      "loss": 0.002,
      "step": 10930
    },
    {
      "epoch": 0.2431111111111111,
      "grad_norm": 0.35958990454673767,
      "learning_rate": 4.392222222222223e-05,
      "loss": 0.0019,
      "step": 10940
    },
    {
      "epoch": 0.24333333333333335,
      "grad_norm": 0.5495185256004333,
      "learning_rate": 4.3916666666666666e-05,
      "loss": 0.0025,
      "step": 10950
    },
    {
      "epoch": 0.24355555555555555,
      "grad_norm": 0.3960854709148407,
      "learning_rate": 4.3911111111111116e-05,
      "loss": 0.0026,
      "step": 10960
    },
    {
      "epoch": 0.2437777777777778,
      "grad_norm": 0.25162702798843384,
      "learning_rate": 4.390555555555555e-05,
      "loss": 0.0026,
      "step": 10970
    },
    {
      "epoch": 0.244,
      "grad_norm": 0.604820966720581,
      "learning_rate": 4.39e-05,
      "loss": 0.0021,
      "step": 10980
    },
    {
      "epoch": 0.24422222222222223,
      "grad_norm": 0.0712382048368454,
      "learning_rate": 4.389444444444445e-05,
      "loss": 0.0019,
      "step": 10990
    },
    {
      "epoch": 0.24444444444444444,
      "grad_norm": 0.11342129856348038,
      "learning_rate": 4.388888888888889e-05,
      "loss": 0.0022,
      "step": 11000
    },
    {
      "epoch": 0.24466666666666667,
      "grad_norm": 0.4121454358100891,
      "learning_rate": 4.388333333333334e-05,
      "loss": 0.003,
      "step": 11010
    },
    {
      "epoch": 0.24488888888888888,
      "grad_norm": 0.47112250328063965,
      "learning_rate": 4.387777777777778e-05,
      "loss": 0.0024,
      "step": 11020
    },
    {
      "epoch": 0.2451111111111111,
      "grad_norm": 0.07542670518159866,
      "learning_rate": 4.387222222222223e-05,
      "loss": 0.0027,
      "step": 11030
    },
    {
      "epoch": 0.24533333333333332,
      "grad_norm": 0.48915895819664,
      "learning_rate": 4.3866666666666665e-05,
      "loss": 0.0018,
      "step": 11040
    },
    {
      "epoch": 0.24555555555555555,
      "grad_norm": 0.21365739405155182,
      "learning_rate": 4.3861111111111115e-05,
      "loss": 0.0023,
      "step": 11050
    },
    {
      "epoch": 0.2457777777777778,
      "grad_norm": 0.20674091577529907,
      "learning_rate": 4.385555555555556e-05,
      "loss": 0.0022,
      "step": 11060
    },
    {
      "epoch": 0.246,
      "grad_norm": 0.5117753744125366,
      "learning_rate": 4.385e-05,
      "loss": 0.0019,
      "step": 11070
    },
    {
      "epoch": 0.24622222222222223,
      "grad_norm": 0.10896140336990356,
      "learning_rate": 4.384444444444445e-05,
      "loss": 0.002,
      "step": 11080
    },
    {
      "epoch": 0.24644444444444444,
      "grad_norm": 0.15781551599502563,
      "learning_rate": 4.383888888888889e-05,
      "loss": 0.0027,
      "step": 11090
    },
    {
      "epoch": 0.24666666666666667,
      "grad_norm": 0.42649221420288086,
      "learning_rate": 4.383333333333334e-05,
      "loss": 0.0046,
      "step": 11100
    },
    {
      "epoch": 0.24688888888888888,
      "grad_norm": 0.17367589473724365,
      "learning_rate": 4.3827777777777776e-05,
      "loss": 0.0022,
      "step": 11110
    },
    {
      "epoch": 0.24711111111111111,
      "grad_norm": 0.3447993993759155,
      "learning_rate": 4.3822222222222227e-05,
      "loss": 0.0027,
      "step": 11120
    },
    {
      "epoch": 0.24733333333333332,
      "grad_norm": 0.2114972621202469,
      "learning_rate": 4.381666666666667e-05,
      "loss": 0.0032,
      "step": 11130
    },
    {
      "epoch": 0.24755555555555556,
      "grad_norm": 0.12768858671188354,
      "learning_rate": 4.3811111111111114e-05,
      "loss": 0.0021,
      "step": 11140
    },
    {
      "epoch": 0.2477777777777778,
      "grad_norm": 0.4892629086971283,
      "learning_rate": 4.380555555555556e-05,
      "loss": 0.0017,
      "step": 11150
    },
    {
      "epoch": 0.248,
      "grad_norm": 0.1295931339263916,
      "learning_rate": 4.38e-05,
      "loss": 0.0022,
      "step": 11160
    },
    {
      "epoch": 0.24822222222222223,
      "grad_norm": 0.6957725286483765,
      "learning_rate": 4.379444444444445e-05,
      "loss": 0.0028,
      "step": 11170
    },
    {
      "epoch": 0.24844444444444444,
      "grad_norm": 0.5891515612602234,
      "learning_rate": 4.378888888888889e-05,
      "loss": 0.0018,
      "step": 11180
    },
    {
      "epoch": 0.24866666666666667,
      "grad_norm": 0.2917264401912689,
      "learning_rate": 4.378333333333334e-05,
      "loss": 0.0025,
      "step": 11190
    },
    {
      "epoch": 0.24888888888888888,
      "grad_norm": 0.6743298768997192,
      "learning_rate": 4.377777777777778e-05,
      "loss": 0.0017,
      "step": 11200
    },
    {
      "epoch": 0.24911111111111112,
      "grad_norm": 0.15631143748760223,
      "learning_rate": 4.3772222222222225e-05,
      "loss": 0.0024,
      "step": 11210
    },
    {
      "epoch": 0.24933333333333332,
      "grad_norm": 0.14826363325119019,
      "learning_rate": 4.376666666666667e-05,
      "loss": 0.0019,
      "step": 11220
    },
    {
      "epoch": 0.24955555555555556,
      "grad_norm": 0.6674715876579285,
      "learning_rate": 4.376111111111111e-05,
      "loss": 0.002,
      "step": 11230
    },
    {
      "epoch": 0.24977777777777777,
      "grad_norm": 0.0655084103345871,
      "learning_rate": 4.3755555555555556e-05,
      "loss": 0.0035,
      "step": 11240
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.3529704511165619,
      "learning_rate": 4.375e-05,
      "loss": 0.0023,
      "step": 11250
    },
    {
      "epoch": 0.25022222222222223,
      "grad_norm": 0.5297444462776184,
      "learning_rate": 4.374444444444445e-05,
      "loss": 0.0021,
      "step": 11260
    },
    {
      "epoch": 0.25044444444444447,
      "grad_norm": 0.21577507257461548,
      "learning_rate": 4.3738888888888893e-05,
      "loss": 0.0025,
      "step": 11270
    },
    {
      "epoch": 0.25066666666666665,
      "grad_norm": 0.25962263345718384,
      "learning_rate": 4.373333333333334e-05,
      "loss": 0.0022,
      "step": 11280
    },
    {
      "epoch": 0.2508888888888889,
      "grad_norm": 0.6359318494796753,
      "learning_rate": 4.372777777777778e-05,
      "loss": 0.0029,
      "step": 11290
    },
    {
      "epoch": 0.2511111111111111,
      "grad_norm": 0.21689575910568237,
      "learning_rate": 4.3722222222222224e-05,
      "loss": 0.002,
      "step": 11300
    },
    {
      "epoch": 0.25133333333333335,
      "grad_norm": 0.3862301707267761,
      "learning_rate": 4.371666666666667e-05,
      "loss": 0.0021,
      "step": 11310
    },
    {
      "epoch": 0.25155555555555553,
      "grad_norm": 0.09214220941066742,
      "learning_rate": 4.371111111111111e-05,
      "loss": 0.0021,
      "step": 11320
    },
    {
      "epoch": 0.25177777777777777,
      "grad_norm": 0.3118068277835846,
      "learning_rate": 4.3705555555555555e-05,
      "loss": 0.0024,
      "step": 11330
    },
    {
      "epoch": 0.252,
      "grad_norm": 0.12817980349063873,
      "learning_rate": 4.3700000000000005e-05,
      "loss": 0.0021,
      "step": 11340
    },
    {
      "epoch": 0.25222222222222224,
      "grad_norm": 0.5622807741165161,
      "learning_rate": 4.369444444444445e-05,
      "loss": 0.0025,
      "step": 11350
    },
    {
      "epoch": 0.25244444444444447,
      "grad_norm": 0.2979681193828583,
      "learning_rate": 4.368888888888889e-05,
      "loss": 0.0019,
      "step": 11360
    },
    {
      "epoch": 0.25266666666666665,
      "grad_norm": 0.08366221189498901,
      "learning_rate": 4.3683333333333336e-05,
      "loss": 0.0024,
      "step": 11370
    },
    {
      "epoch": 0.2528888888888889,
      "grad_norm": 0.09608958661556244,
      "learning_rate": 4.367777777777778e-05,
      "loss": 0.0027,
      "step": 11380
    },
    {
      "epoch": 0.2531111111111111,
      "grad_norm": 0.4789440333843231,
      "learning_rate": 4.367222222222222e-05,
      "loss": 0.0023,
      "step": 11390
    },
    {
      "epoch": 0.25333333333333335,
      "grad_norm": 0.5536476969718933,
      "learning_rate": 4.3666666666666666e-05,
      "loss": 0.0025,
      "step": 11400
    },
    {
      "epoch": 0.25355555555555553,
      "grad_norm": 0.4356972277164459,
      "learning_rate": 4.366111111111112e-05,
      "loss": 0.0027,
      "step": 11410
    },
    {
      "epoch": 0.25377777777777777,
      "grad_norm": 0.19790257513523102,
      "learning_rate": 4.3655555555555554e-05,
      "loss": 0.003,
      "step": 11420
    },
    {
      "epoch": 0.254,
      "grad_norm": 0.8043885231018066,
      "learning_rate": 4.3650000000000004e-05,
      "loss": 0.0031,
      "step": 11430
    },
    {
      "epoch": 0.25422222222222224,
      "grad_norm": 0.46155139803886414,
      "learning_rate": 4.364444444444445e-05,
      "loss": 0.0023,
      "step": 11440
    },
    {
      "epoch": 0.2544444444444444,
      "grad_norm": 0.5619543790817261,
      "learning_rate": 4.363888888888889e-05,
      "loss": 0.0031,
      "step": 11450
    },
    {
      "epoch": 0.25466666666666665,
      "grad_norm": 0.45868584513664246,
      "learning_rate": 4.3633333333333335e-05,
      "loss": 0.003,
      "step": 11460
    },
    {
      "epoch": 0.2548888888888889,
      "grad_norm": 0.08221346139907837,
      "learning_rate": 4.362777777777778e-05,
      "loss": 0.0021,
      "step": 11470
    },
    {
      "epoch": 0.2551111111111111,
      "grad_norm": 0.3203446865081787,
      "learning_rate": 4.362222222222223e-05,
      "loss": 0.003,
      "step": 11480
    },
    {
      "epoch": 0.25533333333333336,
      "grad_norm": 0.3826610743999481,
      "learning_rate": 4.3616666666666665e-05,
      "loss": 0.002,
      "step": 11490
    },
    {
      "epoch": 0.25555555555555554,
      "grad_norm": 0.16000530123710632,
      "learning_rate": 4.3611111111111116e-05,
      "loss": 0.002,
      "step": 11500
    },
    {
      "epoch": 0.25577777777777777,
      "grad_norm": 0.10042263567447662,
      "learning_rate": 4.360555555555555e-05,
      "loss": 0.0028,
      "step": 11510
    },
    {
      "epoch": 0.256,
      "grad_norm": 0.581795334815979,
      "learning_rate": 4.36e-05,
      "loss": 0.0019,
      "step": 11520
    },
    {
      "epoch": 0.25622222222222224,
      "grad_norm": 0.3351135551929474,
      "learning_rate": 4.3594444444444446e-05,
      "loss": 0.0027,
      "step": 11530
    },
    {
      "epoch": 0.2564444444444444,
      "grad_norm": 0.08388208597898483,
      "learning_rate": 4.358888888888889e-05,
      "loss": 0.0025,
      "step": 11540
    },
    {
      "epoch": 0.25666666666666665,
      "grad_norm": 0.7795214653015137,
      "learning_rate": 4.358333333333334e-05,
      "loss": 0.0022,
      "step": 11550
    },
    {
      "epoch": 0.2568888888888889,
      "grad_norm": 0.279240220785141,
      "learning_rate": 4.357777777777778e-05,
      "loss": 0.0021,
      "step": 11560
    },
    {
      "epoch": 0.2571111111111111,
      "grad_norm": 0.24344155192375183,
      "learning_rate": 4.357222222222223e-05,
      "loss": 0.0038,
      "step": 11570
    },
    {
      "epoch": 0.25733333333333336,
      "grad_norm": 0.3396211564540863,
      "learning_rate": 4.3566666666666664e-05,
      "loss": 0.0024,
      "step": 11580
    },
    {
      "epoch": 0.25755555555555554,
      "grad_norm": 0.29132553935050964,
      "learning_rate": 4.3561111111111114e-05,
      "loss": 0.0027,
      "step": 11590
    },
    {
      "epoch": 0.2577777777777778,
      "grad_norm": 0.4530920088291168,
      "learning_rate": 4.355555555555556e-05,
      "loss": 0.002,
      "step": 11600
    },
    {
      "epoch": 0.258,
      "grad_norm": 0.4193338453769684,
      "learning_rate": 4.355e-05,
      "loss": 0.0026,
      "step": 11610
    },
    {
      "epoch": 0.25822222222222224,
      "grad_norm": 0.06624053418636322,
      "learning_rate": 4.354444444444445e-05,
      "loss": 0.0018,
      "step": 11620
    },
    {
      "epoch": 0.2584444444444444,
      "grad_norm": 0.7382391691207886,
      "learning_rate": 4.353888888888889e-05,
      "loss": 0.002,
      "step": 11630
    },
    {
      "epoch": 0.25866666666666666,
      "grad_norm": 0.4164266288280487,
      "learning_rate": 4.353333333333334e-05,
      "loss": 0.0023,
      "step": 11640
    },
    {
      "epoch": 0.2588888888888889,
      "grad_norm": 0.28106918931007385,
      "learning_rate": 4.3527777777777776e-05,
      "loss": 0.0027,
      "step": 11650
    },
    {
      "epoch": 0.2591111111111111,
      "grad_norm": 0.15411698818206787,
      "learning_rate": 4.3522222222222226e-05,
      "loss": 0.0028,
      "step": 11660
    },
    {
      "epoch": 0.25933333333333336,
      "grad_norm": 0.5702617168426514,
      "learning_rate": 4.351666666666667e-05,
      "loss": 0.0028,
      "step": 11670
    },
    {
      "epoch": 0.25955555555555554,
      "grad_norm": 0.18357408046722412,
      "learning_rate": 4.351111111111111e-05,
      "loss": 0.0025,
      "step": 11680
    },
    {
      "epoch": 0.2597777777777778,
      "grad_norm": 0.20123647153377533,
      "learning_rate": 4.350555555555556e-05,
      "loss": 0.0027,
      "step": 11690
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.5688657760620117,
      "learning_rate": 4.35e-05,
      "loss": 0.0025,
      "step": 11700
    },
    {
      "epoch": 0.26022222222222224,
      "grad_norm": 0.056029967963695526,
      "learning_rate": 4.349444444444445e-05,
      "loss": 0.0022,
      "step": 11710
    },
    {
      "epoch": 0.2604444444444444,
      "grad_norm": 0.21127499639987946,
      "learning_rate": 4.348888888888889e-05,
      "loss": 0.003,
      "step": 11720
    },
    {
      "epoch": 0.26066666666666666,
      "grad_norm": 0.32034730911254883,
      "learning_rate": 4.348333333333334e-05,
      "loss": 0.0021,
      "step": 11730
    },
    {
      "epoch": 0.2608888888888889,
      "grad_norm": 0.1974378377199173,
      "learning_rate": 4.347777777777778e-05,
      "loss": 0.0025,
      "step": 11740
    },
    {
      "epoch": 0.2611111111111111,
      "grad_norm": 0.21338708698749542,
      "learning_rate": 4.3472222222222225e-05,
      "loss": 0.0046,
      "step": 11750
    },
    {
      "epoch": 0.2613333333333333,
      "grad_norm": 0.3721129894256592,
      "learning_rate": 4.346666666666667e-05,
      "loss": 0.0027,
      "step": 11760
    },
    {
      "epoch": 0.26155555555555554,
      "grad_norm": 0.6995761394500732,
      "learning_rate": 4.346111111111111e-05,
      "loss": 0.0023,
      "step": 11770
    },
    {
      "epoch": 0.2617777777777778,
      "grad_norm": 0.08783645182847977,
      "learning_rate": 4.3455555555555555e-05,
      "loss": 0.0021,
      "step": 11780
    },
    {
      "epoch": 0.262,
      "grad_norm": 0.3637048602104187,
      "learning_rate": 4.345e-05,
      "loss": 0.0028,
      "step": 11790
    },
    {
      "epoch": 0.26222222222222225,
      "grad_norm": 0.37507086992263794,
      "learning_rate": 4.344444444444445e-05,
      "loss": 0.0026,
      "step": 11800
    },
    {
      "epoch": 0.2624444444444444,
      "grad_norm": 0.4732498824596405,
      "learning_rate": 4.343888888888889e-05,
      "loss": 0.0032,
      "step": 11810
    },
    {
      "epoch": 0.26266666666666666,
      "grad_norm": 0.30875101685523987,
      "learning_rate": 4.3433333333333336e-05,
      "loss": 0.0029,
      "step": 11820
    },
    {
      "epoch": 0.2628888888888889,
      "grad_norm": 0.48838093876838684,
      "learning_rate": 4.342777777777778e-05,
      "loss": 0.0028,
      "step": 11830
    },
    {
      "epoch": 0.26311111111111113,
      "grad_norm": 0.5447949767112732,
      "learning_rate": 4.3422222222222224e-05,
      "loss": 0.0029,
      "step": 11840
    },
    {
      "epoch": 0.2633333333333333,
      "grad_norm": 0.8714027404785156,
      "learning_rate": 4.341666666666667e-05,
      "loss": 0.0024,
      "step": 11850
    },
    {
      "epoch": 0.26355555555555554,
      "grad_norm": 0.38955217599868774,
      "learning_rate": 4.341111111111111e-05,
      "loss": 0.0031,
      "step": 11860
    },
    {
      "epoch": 0.2637777777777778,
      "grad_norm": 0.33911603689193726,
      "learning_rate": 4.3405555555555554e-05,
      "loss": 0.0022,
      "step": 11870
    },
    {
      "epoch": 0.264,
      "grad_norm": 0.3907072842121124,
      "learning_rate": 4.3400000000000005e-05,
      "loss": 0.0025,
      "step": 11880
    },
    {
      "epoch": 0.26422222222222225,
      "grad_norm": 0.2443249225616455,
      "learning_rate": 4.339444444444445e-05,
      "loss": 0.0024,
      "step": 11890
    },
    {
      "epoch": 0.2644444444444444,
      "grad_norm": 0.08892044425010681,
      "learning_rate": 4.338888888888889e-05,
      "loss": 0.0041,
      "step": 11900
    },
    {
      "epoch": 0.26466666666666666,
      "grad_norm": 0.10502507537603378,
      "learning_rate": 4.3383333333333335e-05,
      "loss": 0.004,
      "step": 11910
    },
    {
      "epoch": 0.2648888888888889,
      "grad_norm": 0.10055707395076752,
      "learning_rate": 4.337777777777778e-05,
      "loss": 0.0035,
      "step": 11920
    },
    {
      "epoch": 0.26511111111111113,
      "grad_norm": 0.2006373405456543,
      "learning_rate": 4.337222222222222e-05,
      "loss": 0.0019,
      "step": 11930
    },
    {
      "epoch": 0.2653333333333333,
      "grad_norm": 0.12915641069412231,
      "learning_rate": 4.3366666666666666e-05,
      "loss": 0.0022,
      "step": 11940
    },
    {
      "epoch": 0.26555555555555554,
      "grad_norm": 0.08035626262426376,
      "learning_rate": 4.3361111111111116e-05,
      "loss": 0.0029,
      "step": 11950
    },
    {
      "epoch": 0.2657777777777778,
      "grad_norm": 0.16471432149410248,
      "learning_rate": 4.335555555555556e-05,
      "loss": 0.0034,
      "step": 11960
    },
    {
      "epoch": 0.266,
      "grad_norm": 0.17115963995456696,
      "learning_rate": 4.335e-05,
      "loss": 0.0028,
      "step": 11970
    },
    {
      "epoch": 0.26622222222222225,
      "grad_norm": 0.3712836802005768,
      "learning_rate": 4.334444444444445e-05,
      "loss": 0.0021,
      "step": 11980
    },
    {
      "epoch": 0.26644444444444443,
      "grad_norm": 0.6738609671592712,
      "learning_rate": 4.333888888888889e-05,
      "loss": 0.0041,
      "step": 11990
    },
    {
      "epoch": 0.26666666666666666,
      "grad_norm": 0.08495014160871506,
      "learning_rate": 4.3333333333333334e-05,
      "loss": 0.0033,
      "step": 12000
    },
    {
      "epoch": 0.2668888888888889,
      "grad_norm": 0.08415146172046661,
      "learning_rate": 4.332777777777778e-05,
      "loss": 0.0037,
      "step": 12010
    },
    {
      "epoch": 0.26711111111111113,
      "grad_norm": 0.5124977827072144,
      "learning_rate": 4.332222222222223e-05,
      "loss": 0.0028,
      "step": 12020
    },
    {
      "epoch": 0.2673333333333333,
      "grad_norm": 0.39329078793525696,
      "learning_rate": 4.3316666666666665e-05,
      "loss": 0.0018,
      "step": 12030
    },
    {
      "epoch": 0.26755555555555555,
      "grad_norm": 0.11723306030035019,
      "learning_rate": 4.3311111111111115e-05,
      "loss": 0.0023,
      "step": 12040
    },
    {
      "epoch": 0.2677777777777778,
      "grad_norm": 0.19742955267429352,
      "learning_rate": 4.330555555555556e-05,
      "loss": 0.0024,
      "step": 12050
    },
    {
      "epoch": 0.268,
      "grad_norm": 0.3223482072353363,
      "learning_rate": 4.33e-05,
      "loss": 0.0025,
      "step": 12060
    },
    {
      "epoch": 0.2682222222222222,
      "grad_norm": 0.3675442039966583,
      "learning_rate": 4.3294444444444446e-05,
      "loss": 0.0026,
      "step": 12070
    },
    {
      "epoch": 0.26844444444444443,
      "grad_norm": 0.08714768290519714,
      "learning_rate": 4.328888888888889e-05,
      "loss": 0.0028,
      "step": 12080
    },
    {
      "epoch": 0.26866666666666666,
      "grad_norm": 0.6530784368515015,
      "learning_rate": 4.328333333333334e-05,
      "loss": 0.0025,
      "step": 12090
    },
    {
      "epoch": 0.2688888888888889,
      "grad_norm": 0.07054499536752701,
      "learning_rate": 4.3277777777777776e-05,
      "loss": 0.0031,
      "step": 12100
    },
    {
      "epoch": 0.26911111111111113,
      "grad_norm": 0.8847165703773499,
      "learning_rate": 4.327222222222223e-05,
      "loss": 0.0025,
      "step": 12110
    },
    {
      "epoch": 0.2693333333333333,
      "grad_norm": 0.39036524295806885,
      "learning_rate": 4.3266666666666664e-05,
      "loss": 0.0029,
      "step": 12120
    },
    {
      "epoch": 0.26955555555555555,
      "grad_norm": 0.8906151056289673,
      "learning_rate": 4.3261111111111114e-05,
      "loss": 0.0033,
      "step": 12130
    },
    {
      "epoch": 0.2697777777777778,
      "grad_norm": 0.3664460778236389,
      "learning_rate": 4.325555555555556e-05,
      "loss": 0.0028,
      "step": 12140
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.17694734036922455,
      "learning_rate": 4.325e-05,
      "loss": 0.0031,
      "step": 12150
    },
    {
      "epoch": 0.2702222222222222,
      "grad_norm": 0.13497687876224518,
      "learning_rate": 4.324444444444445e-05,
      "loss": 0.0019,
      "step": 12160
    },
    {
      "epoch": 0.27044444444444443,
      "grad_norm": 0.3744109272956848,
      "learning_rate": 4.323888888888889e-05,
      "loss": 0.0025,
      "step": 12170
    },
    {
      "epoch": 0.27066666666666667,
      "grad_norm": 0.17351146042346954,
      "learning_rate": 4.323333333333334e-05,
      "loss": 0.0019,
      "step": 12180
    },
    {
      "epoch": 0.2708888888888889,
      "grad_norm": 0.10416003316640854,
      "learning_rate": 4.3227777777777775e-05,
      "loss": 0.0028,
      "step": 12190
    },
    {
      "epoch": 0.27111111111111114,
      "grad_norm": 0.6450226306915283,
      "learning_rate": 4.3222222222222226e-05,
      "loss": 0.003,
      "step": 12200
    },
    {
      "epoch": 0.2713333333333333,
      "grad_norm": 0.4169904291629791,
      "learning_rate": 4.321666666666667e-05,
      "loss": 0.0028,
      "step": 12210
    },
    {
      "epoch": 0.27155555555555555,
      "grad_norm": 0.21629652380943298,
      "learning_rate": 4.321111111111111e-05,
      "loss": 0.002,
      "step": 12220
    },
    {
      "epoch": 0.2717777777777778,
      "grad_norm": 0.2964719235897064,
      "learning_rate": 4.320555555555556e-05,
      "loss": 0.002,
      "step": 12230
    },
    {
      "epoch": 0.272,
      "grad_norm": 0.4897197484970093,
      "learning_rate": 4.32e-05,
      "loss": 0.0025,
      "step": 12240
    },
    {
      "epoch": 0.2722222222222222,
      "grad_norm": 0.6328858733177185,
      "learning_rate": 4.319444444444445e-05,
      "loss": 0.003,
      "step": 12250
    },
    {
      "epoch": 0.27244444444444443,
      "grad_norm": 0.28379490971565247,
      "learning_rate": 4.318888888888889e-05,
      "loss": 0.0022,
      "step": 12260
    },
    {
      "epoch": 0.27266666666666667,
      "grad_norm": 0.10938356071710587,
      "learning_rate": 4.318333333333334e-05,
      "loss": 0.0019,
      "step": 12270
    },
    {
      "epoch": 0.2728888888888889,
      "grad_norm": 0.5943999290466309,
      "learning_rate": 4.317777777777778e-05,
      "loss": 0.0022,
      "step": 12280
    },
    {
      "epoch": 0.27311111111111114,
      "grad_norm": 0.34463271498680115,
      "learning_rate": 4.3172222222222224e-05,
      "loss": 0.0031,
      "step": 12290
    },
    {
      "epoch": 0.2733333333333333,
      "grad_norm": 0.091413214802742,
      "learning_rate": 4.316666666666667e-05,
      "loss": 0.0024,
      "step": 12300
    },
    {
      "epoch": 0.27355555555555555,
      "grad_norm": 0.09081655740737915,
      "learning_rate": 4.316111111111111e-05,
      "loss": 0.0026,
      "step": 12310
    },
    {
      "epoch": 0.2737777777777778,
      "grad_norm": 0.2268880009651184,
      "learning_rate": 4.315555555555556e-05,
      "loss": 0.0019,
      "step": 12320
    },
    {
      "epoch": 0.274,
      "grad_norm": 0.0891849473118782,
      "learning_rate": 4.315e-05,
      "loss": 0.0028,
      "step": 12330
    },
    {
      "epoch": 0.2742222222222222,
      "grad_norm": 0.33368203043937683,
      "learning_rate": 4.314444444444445e-05,
      "loss": 0.0019,
      "step": 12340
    },
    {
      "epoch": 0.27444444444444444,
      "grad_norm": 0.1280578076839447,
      "learning_rate": 4.313888888888889e-05,
      "loss": 0.0025,
      "step": 12350
    },
    {
      "epoch": 0.27466666666666667,
      "grad_norm": 0.1659795045852661,
      "learning_rate": 4.3133333333333336e-05,
      "loss": 0.0019,
      "step": 12360
    },
    {
      "epoch": 0.2748888888888889,
      "grad_norm": 0.41154685616493225,
      "learning_rate": 4.312777777777778e-05,
      "loss": 0.002,
      "step": 12370
    },
    {
      "epoch": 0.2751111111111111,
      "grad_norm": 0.2267686426639557,
      "learning_rate": 4.312222222222222e-05,
      "loss": 0.0033,
      "step": 12380
    },
    {
      "epoch": 0.2753333333333333,
      "grad_norm": 0.5904691815376282,
      "learning_rate": 4.311666666666667e-05,
      "loss": 0.0044,
      "step": 12390
    },
    {
      "epoch": 0.27555555555555555,
      "grad_norm": 0.4888423681259155,
      "learning_rate": 4.311111111111111e-05,
      "loss": 0.0025,
      "step": 12400
    },
    {
      "epoch": 0.2757777777777778,
      "grad_norm": 0.07970191538333893,
      "learning_rate": 4.310555555555556e-05,
      "loss": 0.0018,
      "step": 12410
    },
    {
      "epoch": 0.276,
      "grad_norm": 0.3791758418083191,
      "learning_rate": 4.3100000000000004e-05,
      "loss": 0.0022,
      "step": 12420
    },
    {
      "epoch": 0.2762222222222222,
      "grad_norm": 0.39453476667404175,
      "learning_rate": 4.309444444444445e-05,
      "loss": 0.0028,
      "step": 12430
    },
    {
      "epoch": 0.27644444444444444,
      "grad_norm": 0.6102295517921448,
      "learning_rate": 4.308888888888889e-05,
      "loss": 0.0021,
      "step": 12440
    },
    {
      "epoch": 0.27666666666666667,
      "grad_norm": 0.6196786761283875,
      "learning_rate": 4.3083333333333335e-05,
      "loss": 0.0034,
      "step": 12450
    },
    {
      "epoch": 0.2768888888888889,
      "grad_norm": 0.558108389377594,
      "learning_rate": 4.307777777777778e-05,
      "loss": 0.0024,
      "step": 12460
    },
    {
      "epoch": 0.2771111111111111,
      "grad_norm": 0.6617098450660706,
      "learning_rate": 4.307222222222222e-05,
      "loss": 0.0022,
      "step": 12470
    },
    {
      "epoch": 0.2773333333333333,
      "grad_norm": 0.25248944759368896,
      "learning_rate": 4.3066666666666665e-05,
      "loss": 0.0034,
      "step": 12480
    },
    {
      "epoch": 0.27755555555555556,
      "grad_norm": 0.38760727643966675,
      "learning_rate": 4.3061111111111116e-05,
      "loss": 0.0022,
      "step": 12490
    },
    {
      "epoch": 0.2777777777777778,
      "grad_norm": 0.35668450593948364,
      "learning_rate": 4.305555555555556e-05,
      "loss": 0.0019,
      "step": 12500
    },
    {
      "epoch": 0.278,
      "grad_norm": 0.10938026756048203,
      "learning_rate": 4.305e-05,
      "loss": 0.0021,
      "step": 12510
    },
    {
      "epoch": 0.2782222222222222,
      "grad_norm": 0.6027138233184814,
      "learning_rate": 4.3044444444444446e-05,
      "loss": 0.0026,
      "step": 12520
    },
    {
      "epoch": 0.27844444444444444,
      "grad_norm": 0.5048730969429016,
      "learning_rate": 4.303888888888889e-05,
      "loss": 0.0017,
      "step": 12530
    },
    {
      "epoch": 0.2786666666666667,
      "grad_norm": 0.7765785455703735,
      "learning_rate": 4.3033333333333334e-05,
      "loss": 0.0033,
      "step": 12540
    },
    {
      "epoch": 0.2788888888888889,
      "grad_norm": 0.18210358917713165,
      "learning_rate": 4.302777777777778e-05,
      "loss": 0.0028,
      "step": 12550
    },
    {
      "epoch": 0.2791111111111111,
      "grad_norm": 0.1400867998600006,
      "learning_rate": 4.302222222222223e-05,
      "loss": 0.002,
      "step": 12560
    },
    {
      "epoch": 0.2793333333333333,
      "grad_norm": 0.21465085446834564,
      "learning_rate": 4.3016666666666664e-05,
      "loss": 0.0025,
      "step": 12570
    },
    {
      "epoch": 0.27955555555555556,
      "grad_norm": 0.4586365818977356,
      "learning_rate": 4.3011111111111115e-05,
      "loss": 0.0023,
      "step": 12580
    },
    {
      "epoch": 0.2797777777777778,
      "grad_norm": 0.15643121302127838,
      "learning_rate": 4.300555555555556e-05,
      "loss": 0.002,
      "step": 12590
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.4337281882762909,
      "learning_rate": 4.3e-05,
      "loss": 0.0032,
      "step": 12600
    },
    {
      "epoch": 0.2802222222222222,
      "grad_norm": 0.2317940592765808,
      "learning_rate": 4.2994444444444445e-05,
      "loss": 0.003,
      "step": 12610
    },
    {
      "epoch": 0.28044444444444444,
      "grad_norm": 0.45463356375694275,
      "learning_rate": 4.298888888888889e-05,
      "loss": 0.0027,
      "step": 12620
    },
    {
      "epoch": 0.2806666666666667,
      "grad_norm": 0.35829973220825195,
      "learning_rate": 4.298333333333334e-05,
      "loss": 0.0022,
      "step": 12630
    },
    {
      "epoch": 0.2808888888888889,
      "grad_norm": 0.40430065989494324,
      "learning_rate": 4.2977777777777776e-05,
      "loss": 0.0033,
      "step": 12640
    },
    {
      "epoch": 0.2811111111111111,
      "grad_norm": 0.3496609032154083,
      "learning_rate": 4.2972222222222226e-05,
      "loss": 0.0026,
      "step": 12650
    },
    {
      "epoch": 0.2813333333333333,
      "grad_norm": 0.26603272557258606,
      "learning_rate": 4.296666666666666e-05,
      "loss": 0.0021,
      "step": 12660
    },
    {
      "epoch": 0.28155555555555556,
      "grad_norm": 0.1539144068956375,
      "learning_rate": 4.296111111111111e-05,
      "loss": 0.002,
      "step": 12670
    },
    {
      "epoch": 0.2817777777777778,
      "grad_norm": 0.5364012122154236,
      "learning_rate": 4.295555555555556e-05,
      "loss": 0.0033,
      "step": 12680
    },
    {
      "epoch": 0.282,
      "grad_norm": 0.418271005153656,
      "learning_rate": 4.295e-05,
      "loss": 0.0037,
      "step": 12690
    },
    {
      "epoch": 0.2822222222222222,
      "grad_norm": 0.470260351896286,
      "learning_rate": 4.294444444444445e-05,
      "loss": 0.0026,
      "step": 12700
    },
    {
      "epoch": 0.28244444444444444,
      "grad_norm": 0.13661251962184906,
      "learning_rate": 4.293888888888889e-05,
      "loss": 0.0028,
      "step": 12710
    },
    {
      "epoch": 0.2826666666666667,
      "grad_norm": 0.21610236167907715,
      "learning_rate": 4.293333333333334e-05,
      "loss": 0.0029,
      "step": 12720
    },
    {
      "epoch": 0.2828888888888889,
      "grad_norm": 0.14472696185112,
      "learning_rate": 4.2927777777777775e-05,
      "loss": 0.0026,
      "step": 12730
    },
    {
      "epoch": 0.2831111111111111,
      "grad_norm": 0.061876680701971054,
      "learning_rate": 4.2922222222222225e-05,
      "loss": 0.002,
      "step": 12740
    },
    {
      "epoch": 0.2833333333333333,
      "grad_norm": 0.5581403970718384,
      "learning_rate": 4.291666666666667e-05,
      "loss": 0.0045,
      "step": 12750
    },
    {
      "epoch": 0.28355555555555556,
      "grad_norm": 0.2553648352622986,
      "learning_rate": 4.291111111111111e-05,
      "loss": 0.0025,
      "step": 12760
    },
    {
      "epoch": 0.2837777777777778,
      "grad_norm": 0.5959973335266113,
      "learning_rate": 4.290555555555556e-05,
      "loss": 0.0026,
      "step": 12770
    },
    {
      "epoch": 0.284,
      "grad_norm": 0.0956815704703331,
      "learning_rate": 4.29e-05,
      "loss": 0.003,
      "step": 12780
    },
    {
      "epoch": 0.2842222222222222,
      "grad_norm": 0.3862484395503998,
      "learning_rate": 4.289444444444445e-05,
      "loss": 0.002,
      "step": 12790
    },
    {
      "epoch": 0.28444444444444444,
      "grad_norm": 0.21316051483154297,
      "learning_rate": 4.2888888888888886e-05,
      "loss": 0.0036,
      "step": 12800
    },
    {
      "epoch": 0.2846666666666667,
      "grad_norm": 0.37947502732276917,
      "learning_rate": 4.288333333333334e-05,
      "loss": 0.0028,
      "step": 12810
    },
    {
      "epoch": 0.2848888888888889,
      "grad_norm": 0.5052027106285095,
      "learning_rate": 4.287777777777778e-05,
      "loss": 0.0027,
      "step": 12820
    },
    {
      "epoch": 0.2851111111111111,
      "grad_norm": 0.21664094924926758,
      "learning_rate": 4.2872222222222224e-05,
      "loss": 0.0021,
      "step": 12830
    },
    {
      "epoch": 0.2853333333333333,
      "grad_norm": 0.245946004986763,
      "learning_rate": 4.286666666666667e-05,
      "loss": 0.0025,
      "step": 12840
    },
    {
      "epoch": 0.28555555555555556,
      "grad_norm": 0.29902905225753784,
      "learning_rate": 4.286111111111111e-05,
      "loss": 0.0024,
      "step": 12850
    },
    {
      "epoch": 0.2857777777777778,
      "grad_norm": 0.4418797194957733,
      "learning_rate": 4.285555555555556e-05,
      "loss": 0.0019,
      "step": 12860
    },
    {
      "epoch": 0.286,
      "grad_norm": 0.12679481506347656,
      "learning_rate": 4.285e-05,
      "loss": 0.0017,
      "step": 12870
    },
    {
      "epoch": 0.2862222222222222,
      "grad_norm": 0.08926699310541153,
      "learning_rate": 4.284444444444445e-05,
      "loss": 0.0023,
      "step": 12880
    },
    {
      "epoch": 0.28644444444444445,
      "grad_norm": 0.09540952742099762,
      "learning_rate": 4.283888888888889e-05,
      "loss": 0.0017,
      "step": 12890
    },
    {
      "epoch": 0.2866666666666667,
      "grad_norm": 0.3041512966156006,
      "learning_rate": 4.2833333333333335e-05,
      "loss": 0.0037,
      "step": 12900
    },
    {
      "epoch": 0.2868888888888889,
      "grad_norm": 0.8827250599861145,
      "learning_rate": 4.282777777777778e-05,
      "loss": 0.0031,
      "step": 12910
    },
    {
      "epoch": 0.2871111111111111,
      "grad_norm": 0.10418729484081268,
      "learning_rate": 4.282222222222222e-05,
      "loss": 0.0027,
      "step": 12920
    },
    {
      "epoch": 0.28733333333333333,
      "grad_norm": 0.2979722321033478,
      "learning_rate": 4.2816666666666666e-05,
      "loss": 0.0019,
      "step": 12930
    },
    {
      "epoch": 0.28755555555555556,
      "grad_norm": 0.140872523188591,
      "learning_rate": 4.281111111111111e-05,
      "loss": 0.0019,
      "step": 12940
    },
    {
      "epoch": 0.2877777777777778,
      "grad_norm": 0.14624068140983582,
      "learning_rate": 4.280555555555556e-05,
      "loss": 0.0028,
      "step": 12950
    },
    {
      "epoch": 0.288,
      "grad_norm": 0.5648062825202942,
      "learning_rate": 4.2800000000000004e-05,
      "loss": 0.003,
      "step": 12960
    },
    {
      "epoch": 0.2882222222222222,
      "grad_norm": 0.07599513977766037,
      "learning_rate": 4.279444444444445e-05,
      "loss": 0.0033,
      "step": 12970
    },
    {
      "epoch": 0.28844444444444445,
      "grad_norm": 0.43029648065567017,
      "learning_rate": 4.278888888888889e-05,
      "loss": 0.0021,
      "step": 12980
    },
    {
      "epoch": 0.2886666666666667,
      "grad_norm": 0.22733785212039948,
      "learning_rate": 4.2783333333333334e-05,
      "loss": 0.0025,
      "step": 12990
    },
    {
      "epoch": 0.28888888888888886,
      "grad_norm": 0.3884417712688446,
      "learning_rate": 4.277777777777778e-05,
      "loss": 0.0029,
      "step": 13000
    },
    {
      "epoch": 0.2891111111111111,
      "grad_norm": 0.5060570240020752,
      "learning_rate": 4.277222222222222e-05,
      "loss": 0.0033,
      "step": 13010
    },
    {
      "epoch": 0.28933333333333333,
      "grad_norm": 0.4693242609500885,
      "learning_rate": 4.2766666666666665e-05,
      "loss": 0.0018,
      "step": 13020
    },
    {
      "epoch": 0.28955555555555557,
      "grad_norm": 0.2263750284910202,
      "learning_rate": 4.2761111111111115e-05,
      "loss": 0.0021,
      "step": 13030
    },
    {
      "epoch": 0.2897777777777778,
      "grad_norm": 0.3358538746833801,
      "learning_rate": 4.275555555555556e-05,
      "loss": 0.0019,
      "step": 13040
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.09932166337966919,
      "learning_rate": 4.275e-05,
      "loss": 0.0021,
      "step": 13050
    },
    {
      "epoch": 0.2902222222222222,
      "grad_norm": 0.49345335364341736,
      "learning_rate": 4.2744444444444446e-05,
      "loss": 0.0022,
      "step": 13060
    },
    {
      "epoch": 0.29044444444444445,
      "grad_norm": 0.09663903713226318,
      "learning_rate": 4.273888888888889e-05,
      "loss": 0.002,
      "step": 13070
    },
    {
      "epoch": 0.2906666666666667,
      "grad_norm": 0.08349727094173431,
      "learning_rate": 4.273333333333333e-05,
      "loss": 0.0027,
      "step": 13080
    },
    {
      "epoch": 0.29088888888888886,
      "grad_norm": 0.07507488876581192,
      "learning_rate": 4.2727777777777777e-05,
      "loss": 0.0021,
      "step": 13090
    },
    {
      "epoch": 0.2911111111111111,
      "grad_norm": 0.3223012387752533,
      "learning_rate": 4.272222222222223e-05,
      "loss": 0.0025,
      "step": 13100
    },
    {
      "epoch": 0.29133333333333333,
      "grad_norm": 0.2692141532897949,
      "learning_rate": 4.2716666666666664e-05,
      "loss": 0.0022,
      "step": 13110
    },
    {
      "epoch": 0.29155555555555557,
      "grad_norm": 0.32090145349502563,
      "learning_rate": 4.2711111111111114e-05,
      "loss": 0.003,
      "step": 13120
    },
    {
      "epoch": 0.2917777777777778,
      "grad_norm": 0.47909003496170044,
      "learning_rate": 4.270555555555556e-05,
      "loss": 0.0018,
      "step": 13130
    },
    {
      "epoch": 0.292,
      "grad_norm": 0.2017015814781189,
      "learning_rate": 4.27e-05,
      "loss": 0.0025,
      "step": 13140
    },
    {
      "epoch": 0.2922222222222222,
      "grad_norm": 0.16144859790802002,
      "learning_rate": 4.2694444444444445e-05,
      "loss": 0.0027,
      "step": 13150
    },
    {
      "epoch": 0.29244444444444445,
      "grad_norm": 0.15786653757095337,
      "learning_rate": 4.268888888888889e-05,
      "loss": 0.0019,
      "step": 13160
    },
    {
      "epoch": 0.2926666666666667,
      "grad_norm": 0.6597810387611389,
      "learning_rate": 4.268333333333334e-05,
      "loss": 0.0023,
      "step": 13170
    },
    {
      "epoch": 0.29288888888888887,
      "grad_norm": 0.09679023921489716,
      "learning_rate": 4.2677777777777775e-05,
      "loss": 0.0023,
      "step": 13180
    },
    {
      "epoch": 0.2931111111111111,
      "grad_norm": 0.07523250579833984,
      "learning_rate": 4.2672222222222226e-05,
      "loss": 0.0021,
      "step": 13190
    },
    {
      "epoch": 0.29333333333333333,
      "grad_norm": 0.4167090058326721,
      "learning_rate": 4.266666666666667e-05,
      "loss": 0.0018,
      "step": 13200
    },
    {
      "epoch": 0.29355555555555557,
      "grad_norm": 0.194814071059227,
      "learning_rate": 4.266111111111111e-05,
      "loss": 0.0021,
      "step": 13210
    },
    {
      "epoch": 0.2937777777777778,
      "grad_norm": 0.42393627762794495,
      "learning_rate": 4.2655555555555556e-05,
      "loss": 0.0021,
      "step": 13220
    },
    {
      "epoch": 0.294,
      "grad_norm": 0.27715080976486206,
      "learning_rate": 4.265e-05,
      "loss": 0.002,
      "step": 13230
    },
    {
      "epoch": 0.2942222222222222,
      "grad_norm": 0.11273004859685898,
      "learning_rate": 4.264444444444445e-05,
      "loss": 0.0027,
      "step": 13240
    },
    {
      "epoch": 0.29444444444444445,
      "grad_norm": 0.4583492875099182,
      "learning_rate": 4.263888888888889e-05,
      "loss": 0.0023,
      "step": 13250
    },
    {
      "epoch": 0.2946666666666667,
      "grad_norm": 0.23922224342823029,
      "learning_rate": 4.263333333333334e-05,
      "loss": 0.002,
      "step": 13260
    },
    {
      "epoch": 0.29488888888888887,
      "grad_norm": 0.2281908243894577,
      "learning_rate": 4.262777777777778e-05,
      "loss": 0.0034,
      "step": 13270
    },
    {
      "epoch": 0.2951111111111111,
      "grad_norm": 0.25241249799728394,
      "learning_rate": 4.2622222222222224e-05,
      "loss": 0.0021,
      "step": 13280
    },
    {
      "epoch": 0.29533333333333334,
      "grad_norm": 0.39444273710250854,
      "learning_rate": 4.261666666666667e-05,
      "loss": 0.0026,
      "step": 13290
    },
    {
      "epoch": 0.29555555555555557,
      "grad_norm": 0.10152428597211838,
      "learning_rate": 4.261111111111111e-05,
      "loss": 0.0031,
      "step": 13300
    },
    {
      "epoch": 0.29577777777777775,
      "grad_norm": 0.355745792388916,
      "learning_rate": 4.260555555555556e-05,
      "loss": 0.0017,
      "step": 13310
    },
    {
      "epoch": 0.296,
      "grad_norm": 0.23812608420848846,
      "learning_rate": 4.26e-05,
      "loss": 0.0023,
      "step": 13320
    },
    {
      "epoch": 0.2962222222222222,
      "grad_norm": 0.3347514569759369,
      "learning_rate": 4.259444444444445e-05,
      "loss": 0.0033,
      "step": 13330
    },
    {
      "epoch": 0.29644444444444445,
      "grad_norm": 0.07654736936092377,
      "learning_rate": 4.258888888888889e-05,
      "loss": 0.0025,
      "step": 13340
    },
    {
      "epoch": 0.2966666666666667,
      "grad_norm": 0.3544570803642273,
      "learning_rate": 4.2583333333333336e-05,
      "loss": 0.0018,
      "step": 13350
    },
    {
      "epoch": 0.29688888888888887,
      "grad_norm": 0.13215090334415436,
      "learning_rate": 4.257777777777778e-05,
      "loss": 0.0021,
      "step": 13360
    },
    {
      "epoch": 0.2971111111111111,
      "grad_norm": 0.12771892547607422,
      "learning_rate": 4.257222222222222e-05,
      "loss": 0.0026,
      "step": 13370
    },
    {
      "epoch": 0.29733333333333334,
      "grad_norm": 0.09546231478452682,
      "learning_rate": 4.2566666666666674e-05,
      "loss": 0.0021,
      "step": 13380
    },
    {
      "epoch": 0.2975555555555556,
      "grad_norm": 0.4633464217185974,
      "learning_rate": 4.256111111111111e-05,
      "loss": 0.002,
      "step": 13390
    },
    {
      "epoch": 0.29777777777777775,
      "grad_norm": 0.151561439037323,
      "learning_rate": 4.255555555555556e-05,
      "loss": 0.0028,
      "step": 13400
    },
    {
      "epoch": 0.298,
      "grad_norm": 0.3251916766166687,
      "learning_rate": 4.2550000000000004e-05,
      "loss": 0.0022,
      "step": 13410
    },
    {
      "epoch": 0.2982222222222222,
      "grad_norm": 0.15086162090301514,
      "learning_rate": 4.254444444444445e-05,
      "loss": 0.0027,
      "step": 13420
    },
    {
      "epoch": 0.29844444444444446,
      "grad_norm": 0.35225313901901245,
      "learning_rate": 4.253888888888889e-05,
      "loss": 0.0022,
      "step": 13430
    },
    {
      "epoch": 0.2986666666666667,
      "grad_norm": 0.3081494867801666,
      "learning_rate": 4.2533333333333335e-05,
      "loss": 0.002,
      "step": 13440
    },
    {
      "epoch": 0.29888888888888887,
      "grad_norm": 0.3414478302001953,
      "learning_rate": 4.252777777777778e-05,
      "loss": 0.0023,
      "step": 13450
    },
    {
      "epoch": 0.2991111111111111,
      "grad_norm": 0.11503980308771133,
      "learning_rate": 4.252222222222222e-05,
      "loss": 0.002,
      "step": 13460
    },
    {
      "epoch": 0.29933333333333334,
      "grad_norm": 0.7231509685516357,
      "learning_rate": 4.251666666666667e-05,
      "loss": 0.0035,
      "step": 13470
    },
    {
      "epoch": 0.2995555555555556,
      "grad_norm": 0.3909507393836975,
      "learning_rate": 4.2511111111111116e-05,
      "loss": 0.0029,
      "step": 13480
    },
    {
      "epoch": 0.29977777777777775,
      "grad_norm": 0.31515800952911377,
      "learning_rate": 4.250555555555556e-05,
      "loss": 0.0017,
      "step": 13490
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.169448122382164,
      "learning_rate": 4.25e-05,
      "loss": 0.0027,
      "step": 13500
    },
    {
      "epoch": 0.3002222222222222,
      "grad_norm": 0.06493844091892242,
      "learning_rate": 4.2494444444444447e-05,
      "loss": 0.0027,
      "step": 13510
    },
    {
      "epoch": 0.30044444444444446,
      "grad_norm": 0.11412248015403748,
      "learning_rate": 4.248888888888889e-05,
      "loss": 0.0034,
      "step": 13520
    },
    {
      "epoch": 0.3006666666666667,
      "grad_norm": 0.09228352457284927,
      "learning_rate": 4.2483333333333334e-05,
      "loss": 0.0019,
      "step": 13530
    },
    {
      "epoch": 0.3008888888888889,
      "grad_norm": 0.2842331528663635,
      "learning_rate": 4.247777777777778e-05,
      "loss": 0.0042,
      "step": 13540
    },
    {
      "epoch": 0.3011111111111111,
      "grad_norm": 0.09938275814056396,
      "learning_rate": 4.247222222222223e-05,
      "loss": 0.0033,
      "step": 13550
    },
    {
      "epoch": 0.30133333333333334,
      "grad_norm": 0.24605779349803925,
      "learning_rate": 4.246666666666667e-05,
      "loss": 0.0041,
      "step": 13560
    },
    {
      "epoch": 0.3015555555555556,
      "grad_norm": 0.3249686062335968,
      "learning_rate": 4.2461111111111115e-05,
      "loss": 0.003,
      "step": 13570
    },
    {
      "epoch": 0.30177777777777776,
      "grad_norm": 0.5608416199684143,
      "learning_rate": 4.245555555555556e-05,
      "loss": 0.0022,
      "step": 13580
    },
    {
      "epoch": 0.302,
      "grad_norm": 0.06838575750589371,
      "learning_rate": 4.245e-05,
      "loss": 0.0032,
      "step": 13590
    },
    {
      "epoch": 0.3022222222222222,
      "grad_norm": 0.19024239480495453,
      "learning_rate": 4.2444444444444445e-05,
      "loss": 0.0023,
      "step": 13600
    },
    {
      "epoch": 0.30244444444444446,
      "grad_norm": 0.22522741556167603,
      "learning_rate": 4.243888888888889e-05,
      "loss": 0.0033,
      "step": 13610
    },
    {
      "epoch": 0.30266666666666664,
      "grad_norm": 0.2744351625442505,
      "learning_rate": 4.243333333333334e-05,
      "loss": 0.0024,
      "step": 13620
    },
    {
      "epoch": 0.3028888888888889,
      "grad_norm": 0.15707233548164368,
      "learning_rate": 4.2427777777777776e-05,
      "loss": 0.0029,
      "step": 13630
    },
    {
      "epoch": 0.3031111111111111,
      "grad_norm": 0.3038424253463745,
      "learning_rate": 4.2422222222222226e-05,
      "loss": 0.0023,
      "step": 13640
    },
    {
      "epoch": 0.30333333333333334,
      "grad_norm": 0.14211821556091309,
      "learning_rate": 4.241666666666667e-05,
      "loss": 0.002,
      "step": 13650
    },
    {
      "epoch": 0.3035555555555556,
      "grad_norm": 0.2707269489765167,
      "learning_rate": 4.2411111111111114e-05,
      "loss": 0.0026,
      "step": 13660
    },
    {
      "epoch": 0.30377777777777776,
      "grad_norm": 0.15566954016685486,
      "learning_rate": 4.240555555555556e-05,
      "loss": 0.0022,
      "step": 13670
    },
    {
      "epoch": 0.304,
      "grad_norm": 0.37538889050483704,
      "learning_rate": 4.24e-05,
      "loss": 0.0027,
      "step": 13680
    },
    {
      "epoch": 0.3042222222222222,
      "grad_norm": 0.12852846086025238,
      "learning_rate": 4.239444444444445e-05,
      "loss": 0.0034,
      "step": 13690
    },
    {
      "epoch": 0.30444444444444446,
      "grad_norm": 0.41700705885887146,
      "learning_rate": 4.238888888888889e-05,
      "loss": 0.0026,
      "step": 13700
    },
    {
      "epoch": 0.30466666666666664,
      "grad_norm": 0.39709487557411194,
      "learning_rate": 4.238333333333334e-05,
      "loss": 0.0021,
      "step": 13710
    },
    {
      "epoch": 0.3048888888888889,
      "grad_norm": 0.1416407823562622,
      "learning_rate": 4.2377777777777775e-05,
      "loss": 0.0023,
      "step": 13720
    },
    {
      "epoch": 0.3051111111111111,
      "grad_norm": 0.25401467084884644,
      "learning_rate": 4.2372222222222225e-05,
      "loss": 0.0021,
      "step": 13730
    },
    {
      "epoch": 0.30533333333333335,
      "grad_norm": 0.3020184338092804,
      "learning_rate": 4.236666666666667e-05,
      "loss": 0.003,
      "step": 13740
    },
    {
      "epoch": 0.3055555555555556,
      "grad_norm": 0.20963993668556213,
      "learning_rate": 4.236111111111111e-05,
      "loss": 0.0025,
      "step": 13750
    },
    {
      "epoch": 0.30577777777777776,
      "grad_norm": 0.23269018530845642,
      "learning_rate": 4.235555555555556e-05,
      "loss": 0.0028,
      "step": 13760
    },
    {
      "epoch": 0.306,
      "grad_norm": 0.2849157452583313,
      "learning_rate": 4.235e-05,
      "loss": 0.0028,
      "step": 13770
    },
    {
      "epoch": 0.30622222222222223,
      "grad_norm": 0.588435173034668,
      "learning_rate": 4.234444444444445e-05,
      "loss": 0.0022,
      "step": 13780
    },
    {
      "epoch": 0.30644444444444446,
      "grad_norm": 0.13599108159542084,
      "learning_rate": 4.2338888888888887e-05,
      "loss": 0.002,
      "step": 13790
    },
    {
      "epoch": 0.30666666666666664,
      "grad_norm": 0.18314118683338165,
      "learning_rate": 4.233333333333334e-05,
      "loss": 0.0021,
      "step": 13800
    },
    {
      "epoch": 0.3068888888888889,
      "grad_norm": 0.20671075582504272,
      "learning_rate": 4.232777777777778e-05,
      "loss": 0.0022,
      "step": 13810
    },
    {
      "epoch": 0.3071111111111111,
      "grad_norm": 0.4040444493293762,
      "learning_rate": 4.2322222222222224e-05,
      "loss": 0.0028,
      "step": 13820
    },
    {
      "epoch": 0.30733333333333335,
      "grad_norm": 0.7517138719558716,
      "learning_rate": 4.2316666666666674e-05,
      "loss": 0.0028,
      "step": 13830
    },
    {
      "epoch": 0.3075555555555556,
      "grad_norm": 0.5458652377128601,
      "learning_rate": 4.231111111111111e-05,
      "loss": 0.0019,
      "step": 13840
    },
    {
      "epoch": 0.30777777777777776,
      "grad_norm": 0.439397394657135,
      "learning_rate": 4.230555555555556e-05,
      "loss": 0.0023,
      "step": 13850
    },
    {
      "epoch": 0.308,
      "grad_norm": 0.3747949004173279,
      "learning_rate": 4.23e-05,
      "loss": 0.0018,
      "step": 13860
    },
    {
      "epoch": 0.30822222222222223,
      "grad_norm": 0.5371581315994263,
      "learning_rate": 4.229444444444445e-05,
      "loss": 0.0025,
      "step": 13870
    },
    {
      "epoch": 0.30844444444444447,
      "grad_norm": 0.588877260684967,
      "learning_rate": 4.228888888888889e-05,
      "loss": 0.003,
      "step": 13880
    },
    {
      "epoch": 0.30866666666666664,
      "grad_norm": 0.394630491733551,
      "learning_rate": 4.2283333333333336e-05,
      "loss": 0.0032,
      "step": 13890
    },
    {
      "epoch": 0.3088888888888889,
      "grad_norm": 0.5465302467346191,
      "learning_rate": 4.227777777777778e-05,
      "loss": 0.0036,
      "step": 13900
    },
    {
      "epoch": 0.3091111111111111,
      "grad_norm": 0.32198566198349,
      "learning_rate": 4.227222222222222e-05,
      "loss": 0.0026,
      "step": 13910
    },
    {
      "epoch": 0.30933333333333335,
      "grad_norm": 0.40063005685806274,
      "learning_rate": 4.226666666666667e-05,
      "loss": 0.0028,
      "step": 13920
    },
    {
      "epoch": 0.30955555555555553,
      "grad_norm": 0.29386815428733826,
      "learning_rate": 4.226111111111111e-05,
      "loss": 0.0029,
      "step": 13930
    },
    {
      "epoch": 0.30977777777777776,
      "grad_norm": 0.6944462656974792,
      "learning_rate": 4.225555555555556e-05,
      "loss": 0.0022,
      "step": 13940
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.501733660697937,
      "learning_rate": 4.2250000000000004e-05,
      "loss": 0.0033,
      "step": 13950
    },
    {
      "epoch": 0.31022222222222223,
      "grad_norm": 0.29393476247787476,
      "learning_rate": 4.224444444444445e-05,
      "loss": 0.0024,
      "step": 13960
    },
    {
      "epoch": 0.31044444444444447,
      "grad_norm": 0.37039318680763245,
      "learning_rate": 4.223888888888889e-05,
      "loss": 0.0019,
      "step": 13970
    },
    {
      "epoch": 0.31066666666666665,
      "grad_norm": 0.3170664310455322,
      "learning_rate": 4.2233333333333334e-05,
      "loss": 0.0022,
      "step": 13980
    },
    {
      "epoch": 0.3108888888888889,
      "grad_norm": 0.2698664963245392,
      "learning_rate": 4.222777777777778e-05,
      "loss": 0.0029,
      "step": 13990
    },
    {
      "epoch": 0.3111111111111111,
      "grad_norm": 0.16997678577899933,
      "learning_rate": 4.222222222222222e-05,
      "loss": 0.0026,
      "step": 14000
    },
    {
      "epoch": 0.31133333333333335,
      "grad_norm": 0.16930872201919556,
      "learning_rate": 4.221666666666667e-05,
      "loss": 0.0029,
      "step": 14010
    },
    {
      "epoch": 0.31155555555555553,
      "grad_norm": 0.13509239256381989,
      "learning_rate": 4.2211111111111115e-05,
      "loss": 0.0036,
      "step": 14020
    },
    {
      "epoch": 0.31177777777777776,
      "grad_norm": 0.5923622250556946,
      "learning_rate": 4.220555555555556e-05,
      "loss": 0.0019,
      "step": 14030
    },
    {
      "epoch": 0.312,
      "grad_norm": 0.22862710058689117,
      "learning_rate": 4.22e-05,
      "loss": 0.002,
      "step": 14040
    },
    {
      "epoch": 0.31222222222222223,
      "grad_norm": 0.443451851606369,
      "learning_rate": 4.2194444444444446e-05,
      "loss": 0.002,
      "step": 14050
    },
    {
      "epoch": 0.31244444444444447,
      "grad_norm": 0.20199035108089447,
      "learning_rate": 4.218888888888889e-05,
      "loss": 0.0026,
      "step": 14060
    },
    {
      "epoch": 0.31266666666666665,
      "grad_norm": 0.7891521453857422,
      "learning_rate": 4.218333333333333e-05,
      "loss": 0.0019,
      "step": 14070
    },
    {
      "epoch": 0.3128888888888889,
      "grad_norm": 0.25630244612693787,
      "learning_rate": 4.217777777777778e-05,
      "loss": 0.0028,
      "step": 14080
    },
    {
      "epoch": 0.3131111111111111,
      "grad_norm": 0.061402156949043274,
      "learning_rate": 4.217222222222223e-05,
      "loss": 0.003,
      "step": 14090
    },
    {
      "epoch": 0.31333333333333335,
      "grad_norm": 0.3838222622871399,
      "learning_rate": 4.216666666666667e-05,
      "loss": 0.002,
      "step": 14100
    },
    {
      "epoch": 0.31355555555555553,
      "grad_norm": 0.44450002908706665,
      "learning_rate": 4.2161111111111114e-05,
      "loss": 0.0021,
      "step": 14110
    },
    {
      "epoch": 0.31377777777777777,
      "grad_norm": 0.6152471899986267,
      "learning_rate": 4.215555555555556e-05,
      "loss": 0.0027,
      "step": 14120
    },
    {
      "epoch": 0.314,
      "grad_norm": 0.0643949881196022,
      "learning_rate": 4.215e-05,
      "loss": 0.002,
      "step": 14130
    },
    {
      "epoch": 0.31422222222222224,
      "grad_norm": 0.5258464217185974,
      "learning_rate": 4.2144444444444445e-05,
      "loss": 0.0024,
      "step": 14140
    },
    {
      "epoch": 0.31444444444444447,
      "grad_norm": 0.2586562931537628,
      "learning_rate": 4.213888888888889e-05,
      "loss": 0.0022,
      "step": 14150
    },
    {
      "epoch": 0.31466666666666665,
      "grad_norm": 0.17290513217449188,
      "learning_rate": 4.213333333333334e-05,
      "loss": 0.0019,
      "step": 14160
    },
    {
      "epoch": 0.3148888888888889,
      "grad_norm": 0.17061921954154968,
      "learning_rate": 4.2127777777777776e-05,
      "loss": 0.0022,
      "step": 14170
    },
    {
      "epoch": 0.3151111111111111,
      "grad_norm": 0.2020995169878006,
      "learning_rate": 4.2122222222222226e-05,
      "loss": 0.0034,
      "step": 14180
    },
    {
      "epoch": 0.31533333333333335,
      "grad_norm": 0.1466597467660904,
      "learning_rate": 4.211666666666667e-05,
      "loss": 0.0029,
      "step": 14190
    },
    {
      "epoch": 0.31555555555555553,
      "grad_norm": 0.18238510191440582,
      "learning_rate": 4.211111111111111e-05,
      "loss": 0.0025,
      "step": 14200
    },
    {
      "epoch": 0.31577777777777777,
      "grad_norm": 0.05894159525632858,
      "learning_rate": 4.2105555555555557e-05,
      "loss": 0.0025,
      "step": 14210
    },
    {
      "epoch": 0.316,
      "grad_norm": 0.17211255431175232,
      "learning_rate": 4.21e-05,
      "loss": 0.0035,
      "step": 14220
    },
    {
      "epoch": 0.31622222222222224,
      "grad_norm": 0.26523253321647644,
      "learning_rate": 4.209444444444445e-05,
      "loss": 0.0039,
      "step": 14230
    },
    {
      "epoch": 0.3164444444444444,
      "grad_norm": 0.3033546507358551,
      "learning_rate": 4.208888888888889e-05,
      "loss": 0.0036,
      "step": 14240
    },
    {
      "epoch": 0.31666666666666665,
      "grad_norm": 0.10123051702976227,
      "learning_rate": 4.208333333333334e-05,
      "loss": 0.0023,
      "step": 14250
    },
    {
      "epoch": 0.3168888888888889,
      "grad_norm": 0.24881543219089508,
      "learning_rate": 4.2077777777777774e-05,
      "loss": 0.003,
      "step": 14260
    },
    {
      "epoch": 0.3171111111111111,
      "grad_norm": 0.2785215377807617,
      "learning_rate": 4.2072222222222225e-05,
      "loss": 0.003,
      "step": 14270
    },
    {
      "epoch": 0.31733333333333336,
      "grad_norm": 0.14690281450748444,
      "learning_rate": 4.206666666666667e-05,
      "loss": 0.0022,
      "step": 14280
    },
    {
      "epoch": 0.31755555555555554,
      "grad_norm": 1.043285846710205,
      "learning_rate": 4.206111111111111e-05,
      "loss": 0.002,
      "step": 14290
    },
    {
      "epoch": 0.31777777777777777,
      "grad_norm": 0.3102797567844391,
      "learning_rate": 4.205555555555556e-05,
      "loss": 0.0025,
      "step": 14300
    },
    {
      "epoch": 0.318,
      "grad_norm": 0.12950144708156586,
      "learning_rate": 4.205e-05,
      "loss": 0.0033,
      "step": 14310
    },
    {
      "epoch": 0.31822222222222224,
      "grad_norm": 0.48177382349967957,
      "learning_rate": 4.204444444444445e-05,
      "loss": 0.0028,
      "step": 14320
    },
    {
      "epoch": 0.3184444444444444,
      "grad_norm": 0.1738959401845932,
      "learning_rate": 4.2038888888888886e-05,
      "loss": 0.0019,
      "step": 14330
    },
    {
      "epoch": 0.31866666666666665,
      "grad_norm": 0.22835999727249146,
      "learning_rate": 4.2033333333333336e-05,
      "loss": 0.0034,
      "step": 14340
    },
    {
      "epoch": 0.3188888888888889,
      "grad_norm": 0.47877103090286255,
      "learning_rate": 4.202777777777778e-05,
      "loss": 0.0034,
      "step": 14350
    },
    {
      "epoch": 0.3191111111111111,
      "grad_norm": 0.29464662075042725,
      "learning_rate": 4.2022222222222223e-05,
      "loss": 0.0037,
      "step": 14360
    },
    {
      "epoch": 0.31933333333333336,
      "grad_norm": 0.20916689932346344,
      "learning_rate": 4.2016666666666674e-05,
      "loss": 0.0024,
      "step": 14370
    },
    {
      "epoch": 0.31955555555555554,
      "grad_norm": 0.22612416744232178,
      "learning_rate": 4.201111111111111e-05,
      "loss": 0.0024,
      "step": 14380
    },
    {
      "epoch": 0.31977777777777777,
      "grad_norm": 0.12667126953601837,
      "learning_rate": 4.200555555555556e-05,
      "loss": 0.0032,
      "step": 14390
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.7567176222801208,
      "learning_rate": 4.2e-05,
      "loss": 0.0026,
      "step": 14400
    },
    {
      "epoch": 0.32022222222222224,
      "grad_norm": 0.08830712735652924,
      "learning_rate": 4.199444444444445e-05,
      "loss": 0.0022,
      "step": 14410
    },
    {
      "epoch": 0.3204444444444444,
      "grad_norm": 0.16670525074005127,
      "learning_rate": 4.198888888888889e-05,
      "loss": 0.0024,
      "step": 14420
    },
    {
      "epoch": 0.32066666666666666,
      "grad_norm": 0.7263057827949524,
      "learning_rate": 4.1983333333333335e-05,
      "loss": 0.0024,
      "step": 14430
    },
    {
      "epoch": 0.3208888888888889,
      "grad_norm": 0.5619568824768066,
      "learning_rate": 4.1977777777777785e-05,
      "loss": 0.0022,
      "step": 14440
    },
    {
      "epoch": 0.3211111111111111,
      "grad_norm": 0.29055655002593994,
      "learning_rate": 4.197222222222222e-05,
      "loss": 0.0025,
      "step": 14450
    },
    {
      "epoch": 0.32133333333333336,
      "grad_norm": 0.2003079056739807,
      "learning_rate": 4.196666666666667e-05,
      "loss": 0.0027,
      "step": 14460
    },
    {
      "epoch": 0.32155555555555554,
      "grad_norm": 0.32661664485931396,
      "learning_rate": 4.196111111111111e-05,
      "loss": 0.002,
      "step": 14470
    },
    {
      "epoch": 0.3217777777777778,
      "grad_norm": 0.5074272751808167,
      "learning_rate": 4.195555555555556e-05,
      "loss": 0.0027,
      "step": 14480
    },
    {
      "epoch": 0.322,
      "grad_norm": 0.0823875218629837,
      "learning_rate": 4.195e-05,
      "loss": 0.0017,
      "step": 14490
    },
    {
      "epoch": 0.32222222222222224,
      "grad_norm": 0.06475438177585602,
      "learning_rate": 4.194444444444445e-05,
      "loss": 0.0023,
      "step": 14500
    },
    {
      "epoch": 0.3224444444444444,
      "grad_norm": 0.11130794882774353,
      "learning_rate": 4.193888888888889e-05,
      "loss": 0.0019,
      "step": 14510
    },
    {
      "epoch": 0.32266666666666666,
      "grad_norm": 0.1696130484342575,
      "learning_rate": 4.1933333333333334e-05,
      "loss": 0.0023,
      "step": 14520
    },
    {
      "epoch": 0.3228888888888889,
      "grad_norm": 0.23384372889995575,
      "learning_rate": 4.1927777777777784e-05,
      "loss": 0.0023,
      "step": 14530
    },
    {
      "epoch": 0.3231111111111111,
      "grad_norm": 0.1738026738166809,
      "learning_rate": 4.192222222222222e-05,
      "loss": 0.0029,
      "step": 14540
    },
    {
      "epoch": 0.3233333333333333,
      "grad_norm": 0.542823076248169,
      "learning_rate": 4.191666666666667e-05,
      "loss": 0.0025,
      "step": 14550
    },
    {
      "epoch": 0.32355555555555554,
      "grad_norm": 0.2312406599521637,
      "learning_rate": 4.1911111111111115e-05,
      "loss": 0.0019,
      "step": 14560
    },
    {
      "epoch": 0.3237777777777778,
      "grad_norm": 0.2816787362098694,
      "learning_rate": 4.190555555555556e-05,
      "loss": 0.0025,
      "step": 14570
    },
    {
      "epoch": 0.324,
      "grad_norm": 0.2993108928203583,
      "learning_rate": 4.19e-05,
      "loss": 0.0039,
      "step": 14580
    },
    {
      "epoch": 0.32422222222222224,
      "grad_norm": 0.06331062316894531,
      "learning_rate": 4.1894444444444446e-05,
      "loss": 0.0021,
      "step": 14590
    },
    {
      "epoch": 0.3244444444444444,
      "grad_norm": 0.21722260117530823,
      "learning_rate": 4.188888888888889e-05,
      "loss": 0.0019,
      "step": 14600
    },
    {
      "epoch": 0.32466666666666666,
      "grad_norm": 0.11496071517467499,
      "learning_rate": 4.188333333333333e-05,
      "loss": 0.0038,
      "step": 14610
    },
    {
      "epoch": 0.3248888888888889,
      "grad_norm": 0.12397564947605133,
      "learning_rate": 4.187777777777778e-05,
      "loss": 0.0021,
      "step": 14620
    },
    {
      "epoch": 0.32511111111111113,
      "grad_norm": 0.7399137616157532,
      "learning_rate": 4.1872222222222227e-05,
      "loss": 0.0026,
      "step": 14630
    },
    {
      "epoch": 0.3253333333333333,
      "grad_norm": 0.21752022206783295,
      "learning_rate": 4.186666666666667e-05,
      "loss": 0.0021,
      "step": 14640
    },
    {
      "epoch": 0.32555555555555554,
      "grad_norm": 0.35159555077552795,
      "learning_rate": 4.1861111111111114e-05,
      "loss": 0.0033,
      "step": 14650
    },
    {
      "epoch": 0.3257777777777778,
      "grad_norm": 0.323589563369751,
      "learning_rate": 4.185555555555556e-05,
      "loss": 0.0026,
      "step": 14660
    },
    {
      "epoch": 0.326,
      "grad_norm": 0.08129251003265381,
      "learning_rate": 4.185e-05,
      "loss": 0.0033,
      "step": 14670
    },
    {
      "epoch": 0.32622222222222225,
      "grad_norm": 0.21019789576530457,
      "learning_rate": 4.1844444444444444e-05,
      "loss": 0.003,
      "step": 14680
    },
    {
      "epoch": 0.3264444444444444,
      "grad_norm": 0.376558393239975,
      "learning_rate": 4.183888888888889e-05,
      "loss": 0.0026,
      "step": 14690
    },
    {
      "epoch": 0.32666666666666666,
      "grad_norm": 0.255558043718338,
      "learning_rate": 4.183333333333334e-05,
      "loss": 0.0023,
      "step": 14700
    },
    {
      "epoch": 0.3268888888888889,
      "grad_norm": 0.1156233474612236,
      "learning_rate": 4.182777777777778e-05,
      "loss": 0.0028,
      "step": 14710
    },
    {
      "epoch": 0.32711111111111113,
      "grad_norm": 0.3356512188911438,
      "learning_rate": 4.1822222222222225e-05,
      "loss": 0.0021,
      "step": 14720
    },
    {
      "epoch": 0.3273333333333333,
      "grad_norm": 0.11861306428909302,
      "learning_rate": 4.181666666666667e-05,
      "loss": 0.0022,
      "step": 14730
    },
    {
      "epoch": 0.32755555555555554,
      "grad_norm": 0.1995549350976944,
      "learning_rate": 4.181111111111111e-05,
      "loss": 0.0018,
      "step": 14740
    },
    {
      "epoch": 0.3277777777777778,
      "grad_norm": 0.1386357843875885,
      "learning_rate": 4.1805555555555556e-05,
      "loss": 0.0018,
      "step": 14750
    },
    {
      "epoch": 0.328,
      "grad_norm": 0.3046705722808838,
      "learning_rate": 4.18e-05,
      "loss": 0.0026,
      "step": 14760
    },
    {
      "epoch": 0.32822222222222225,
      "grad_norm": 0.4319932460784912,
      "learning_rate": 4.179444444444445e-05,
      "loss": 0.0026,
      "step": 14770
    },
    {
      "epoch": 0.32844444444444443,
      "grad_norm": 0.11918555200099945,
      "learning_rate": 4.178888888888889e-05,
      "loss": 0.0026,
      "step": 14780
    },
    {
      "epoch": 0.32866666666666666,
      "grad_norm": 0.21139195561408997,
      "learning_rate": 4.178333333333334e-05,
      "loss": 0.0021,
      "step": 14790
    },
    {
      "epoch": 0.3288888888888889,
      "grad_norm": 0.538423478603363,
      "learning_rate": 4.177777777777778e-05,
      "loss": 0.0018,
      "step": 14800
    },
    {
      "epoch": 0.32911111111111113,
      "grad_norm": 0.4874683618545532,
      "learning_rate": 4.1772222222222224e-05,
      "loss": 0.0028,
      "step": 14810
    },
    {
      "epoch": 0.3293333333333333,
      "grad_norm": 0.8811502456665039,
      "learning_rate": 4.176666666666667e-05,
      "loss": 0.0029,
      "step": 14820
    },
    {
      "epoch": 0.32955555555555555,
      "grad_norm": 0.34555864334106445,
      "learning_rate": 4.176111111111111e-05,
      "loss": 0.0033,
      "step": 14830
    },
    {
      "epoch": 0.3297777777777778,
      "grad_norm": 0.5802227854728699,
      "learning_rate": 4.175555555555556e-05,
      "loss": 0.0023,
      "step": 14840
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.42495569586753845,
      "learning_rate": 4.175e-05,
      "loss": 0.0032,
      "step": 14850
    },
    {
      "epoch": 0.3302222222222222,
      "grad_norm": 0.251209020614624,
      "learning_rate": 4.174444444444445e-05,
      "loss": 0.0021,
      "step": 14860
    },
    {
      "epoch": 0.33044444444444443,
      "grad_norm": 0.17576397955417633,
      "learning_rate": 4.1738888888888885e-05,
      "loss": 0.0029,
      "step": 14870
    },
    {
      "epoch": 0.33066666666666666,
      "grad_norm": 0.49571338295936584,
      "learning_rate": 4.1733333333333336e-05,
      "loss": 0.0029,
      "step": 14880
    },
    {
      "epoch": 0.3308888888888889,
      "grad_norm": 0.3776607811450958,
      "learning_rate": 4.172777777777778e-05,
      "loss": 0.0031,
      "step": 14890
    },
    {
      "epoch": 0.33111111111111113,
      "grad_norm": 0.2547198534011841,
      "learning_rate": 4.172222222222222e-05,
      "loss": 0.0026,
      "step": 14900
    },
    {
      "epoch": 0.3313333333333333,
      "grad_norm": 0.3386807143688202,
      "learning_rate": 4.171666666666667e-05,
      "loss": 0.0021,
      "step": 14910
    },
    {
      "epoch": 0.33155555555555555,
      "grad_norm": 0.07428416609764099,
      "learning_rate": 4.171111111111111e-05,
      "loss": 0.0027,
      "step": 14920
    },
    {
      "epoch": 0.3317777777777778,
      "grad_norm": 0.07820186018943787,
      "learning_rate": 4.170555555555556e-05,
      "loss": 0.0018,
      "step": 14930
    },
    {
      "epoch": 0.332,
      "grad_norm": 0.07113020122051239,
      "learning_rate": 4.17e-05,
      "loss": 0.0018,
      "step": 14940
    },
    {
      "epoch": 0.3322222222222222,
      "grad_norm": 0.2993086874485016,
      "learning_rate": 4.169444444444445e-05,
      "loss": 0.003,
      "step": 14950
    },
    {
      "epoch": 0.33244444444444443,
      "grad_norm": 0.20045898854732513,
      "learning_rate": 4.168888888888889e-05,
      "loss": 0.0028,
      "step": 14960
    },
    {
      "epoch": 0.33266666666666667,
      "grad_norm": 0.33274737000465393,
      "learning_rate": 4.1683333333333335e-05,
      "loss": 0.003,
      "step": 14970
    },
    {
      "epoch": 0.3328888888888889,
      "grad_norm": 0.2615782618522644,
      "learning_rate": 4.1677777777777785e-05,
      "loss": 0.0027,
      "step": 14980
    },
    {
      "epoch": 0.33311111111111114,
      "grad_norm": 0.36058714985847473,
      "learning_rate": 4.167222222222222e-05,
      "loss": 0.0029,
      "step": 14990
    },
    {
      "epoch": 0.3333333333333333,
      "grad_norm": 0.07537557929754257,
      "learning_rate": 4.166666666666667e-05,
      "loss": 0.0021,
      "step": 15000
    },
    {
      "epoch": 0.33355555555555555,
      "grad_norm": 0.5555852651596069,
      "learning_rate": 4.166111111111111e-05,
      "loss": 0.0035,
      "step": 15010
    },
    {
      "epoch": 0.3337777777777778,
      "grad_norm": 0.08423399925231934,
      "learning_rate": 4.165555555555556e-05,
      "loss": 0.0021,
      "step": 15020
    },
    {
      "epoch": 0.334,
      "grad_norm": 0.22275707125663757,
      "learning_rate": 4.165e-05,
      "loss": 0.0021,
      "step": 15030
    },
    {
      "epoch": 0.3342222222222222,
      "grad_norm": 0.1787634938955307,
      "learning_rate": 4.1644444444444446e-05,
      "loss": 0.0027,
      "step": 15040
    },
    {
      "epoch": 0.33444444444444443,
      "grad_norm": 0.1220812126994133,
      "learning_rate": 4.163888888888889e-05,
      "loss": 0.0021,
      "step": 15050
    },
    {
      "epoch": 0.33466666666666667,
      "grad_norm": 0.5979129076004028,
      "learning_rate": 4.1633333333333333e-05,
      "loss": 0.002,
      "step": 15060
    },
    {
      "epoch": 0.3348888888888889,
      "grad_norm": 0.06544658541679382,
      "learning_rate": 4.1627777777777784e-05,
      "loss": 0.0024,
      "step": 15070
    },
    {
      "epoch": 0.33511111111111114,
      "grad_norm": 0.2896076440811157,
      "learning_rate": 4.162222222222222e-05,
      "loss": 0.0027,
      "step": 15080
    },
    {
      "epoch": 0.3353333333333333,
      "grad_norm": 0.21105867624282837,
      "learning_rate": 4.161666666666667e-05,
      "loss": 0.002,
      "step": 15090
    },
    {
      "epoch": 0.33555555555555555,
      "grad_norm": 0.448401540517807,
      "learning_rate": 4.1611111111111114e-05,
      "loss": 0.0021,
      "step": 15100
    },
    {
      "epoch": 0.3357777777777778,
      "grad_norm": 0.20186303555965424,
      "learning_rate": 4.160555555555556e-05,
      "loss": 0.0018,
      "step": 15110
    },
    {
      "epoch": 0.336,
      "grad_norm": 0.07156246155500412,
      "learning_rate": 4.16e-05,
      "loss": 0.0021,
      "step": 15120
    },
    {
      "epoch": 0.3362222222222222,
      "grad_norm": 0.39841601252555847,
      "learning_rate": 4.1594444444444445e-05,
      "loss": 0.002,
      "step": 15130
    },
    {
      "epoch": 0.33644444444444443,
      "grad_norm": 0.3511328101158142,
      "learning_rate": 4.158888888888889e-05,
      "loss": 0.0024,
      "step": 15140
    },
    {
      "epoch": 0.33666666666666667,
      "grad_norm": 0.20924992859363556,
      "learning_rate": 4.158333333333333e-05,
      "loss": 0.002,
      "step": 15150
    },
    {
      "epoch": 0.3368888888888889,
      "grad_norm": 0.06016199290752411,
      "learning_rate": 4.157777777777778e-05,
      "loss": 0.0023,
      "step": 15160
    },
    {
      "epoch": 0.3371111111111111,
      "grad_norm": 0.241324782371521,
      "learning_rate": 4.1572222222222226e-05,
      "loss": 0.0021,
      "step": 15170
    },
    {
      "epoch": 0.3373333333333333,
      "grad_norm": 0.2813851535320282,
      "learning_rate": 4.156666666666667e-05,
      "loss": 0.0024,
      "step": 15180
    },
    {
      "epoch": 0.33755555555555555,
      "grad_norm": 0.48280805349349976,
      "learning_rate": 4.156111111111111e-05,
      "loss": 0.0022,
      "step": 15190
    },
    {
      "epoch": 0.3377777777777778,
      "grad_norm": 0.2794865369796753,
      "learning_rate": 4.155555555555556e-05,
      "loss": 0.0035,
      "step": 15200
    },
    {
      "epoch": 0.338,
      "grad_norm": 0.3341990113258362,
      "learning_rate": 4.155e-05,
      "loss": 0.0023,
      "step": 15210
    },
    {
      "epoch": 0.3382222222222222,
      "grad_norm": 0.5092527270317078,
      "learning_rate": 4.1544444444444444e-05,
      "loss": 0.0031,
      "step": 15220
    },
    {
      "epoch": 0.33844444444444444,
      "grad_norm": 0.09093794226646423,
      "learning_rate": 4.153888888888889e-05,
      "loss": 0.0027,
      "step": 15230
    },
    {
      "epoch": 0.33866666666666667,
      "grad_norm": 0.16297271847724915,
      "learning_rate": 4.153333333333334e-05,
      "loss": 0.0019,
      "step": 15240
    },
    {
      "epoch": 0.3388888888888889,
      "grad_norm": 0.413178950548172,
      "learning_rate": 4.152777777777778e-05,
      "loss": 0.0024,
      "step": 15250
    },
    {
      "epoch": 0.3391111111111111,
      "grad_norm": 0.40919366478919983,
      "learning_rate": 4.1522222222222225e-05,
      "loss": 0.002,
      "step": 15260
    },
    {
      "epoch": 0.3393333333333333,
      "grad_norm": 0.47593674063682556,
      "learning_rate": 4.151666666666667e-05,
      "loss": 0.0021,
      "step": 15270
    },
    {
      "epoch": 0.33955555555555555,
      "grad_norm": 0.2636413872241974,
      "learning_rate": 4.151111111111111e-05,
      "loss": 0.0028,
      "step": 15280
    },
    {
      "epoch": 0.3397777777777778,
      "grad_norm": 0.08321960270404816,
      "learning_rate": 4.1505555555555556e-05,
      "loss": 0.0033,
      "step": 15290
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.6648018956184387,
      "learning_rate": 4.15e-05,
      "loss": 0.0022,
      "step": 15300
    },
    {
      "epoch": 0.3402222222222222,
      "grad_norm": 0.14376647770404816,
      "learning_rate": 4.149444444444445e-05,
      "loss": 0.0021,
      "step": 15310
    },
    {
      "epoch": 0.34044444444444444,
      "grad_norm": 0.09867788851261139,
      "learning_rate": 4.1488888888888886e-05,
      "loss": 0.0022,
      "step": 15320
    },
    {
      "epoch": 0.3406666666666667,
      "grad_norm": 0.11463107913732529,
      "learning_rate": 4.1483333333333337e-05,
      "loss": 0.0026,
      "step": 15330
    },
    {
      "epoch": 0.3408888888888889,
      "grad_norm": 0.1153484582901001,
      "learning_rate": 4.147777777777778e-05,
      "loss": 0.0026,
      "step": 15340
    },
    {
      "epoch": 0.3411111111111111,
      "grad_norm": 0.28296998143196106,
      "learning_rate": 4.1472222222222224e-05,
      "loss": 0.0026,
      "step": 15350
    },
    {
      "epoch": 0.3413333333333333,
      "grad_norm": 0.16976357996463776,
      "learning_rate": 4.146666666666667e-05,
      "loss": 0.0029,
      "step": 15360
    },
    {
      "epoch": 0.34155555555555556,
      "grad_norm": 0.32039761543273926,
      "learning_rate": 4.146111111111111e-05,
      "loss": 0.0032,
      "step": 15370
    },
    {
      "epoch": 0.3417777777777778,
      "grad_norm": 0.18024411797523499,
      "learning_rate": 4.145555555555556e-05,
      "loss": 0.0024,
      "step": 15380
    },
    {
      "epoch": 0.342,
      "grad_norm": 0.5121381282806396,
      "learning_rate": 4.145e-05,
      "loss": 0.0022,
      "step": 15390
    },
    {
      "epoch": 0.3422222222222222,
      "grad_norm": 0.3961377739906311,
      "learning_rate": 4.144444444444445e-05,
      "loss": 0.002,
      "step": 15400
    },
    {
      "epoch": 0.34244444444444444,
      "grad_norm": 0.5527412295341492,
      "learning_rate": 4.1438888888888885e-05,
      "loss": 0.0033,
      "step": 15410
    },
    {
      "epoch": 0.3426666666666667,
      "grad_norm": 0.06867650896310806,
      "learning_rate": 4.1433333333333335e-05,
      "loss": 0.0022,
      "step": 15420
    },
    {
      "epoch": 0.3428888888888889,
      "grad_norm": 0.29806673526763916,
      "learning_rate": 4.142777777777778e-05,
      "loss": 0.0019,
      "step": 15430
    },
    {
      "epoch": 0.3431111111111111,
      "grad_norm": 0.4019917845726013,
      "learning_rate": 4.142222222222222e-05,
      "loss": 0.0023,
      "step": 15440
    },
    {
      "epoch": 0.3433333333333333,
      "grad_norm": 0.2336573451757431,
      "learning_rate": 4.141666666666667e-05,
      "loss": 0.0029,
      "step": 15450
    },
    {
      "epoch": 0.34355555555555556,
      "grad_norm": 0.4250066876411438,
      "learning_rate": 4.141111111111111e-05,
      "loss": 0.0024,
      "step": 15460
    },
    {
      "epoch": 0.3437777777777778,
      "grad_norm": 0.2835173010826111,
      "learning_rate": 4.140555555555556e-05,
      "loss": 0.0018,
      "step": 15470
    },
    {
      "epoch": 0.344,
      "grad_norm": 0.10641136020421982,
      "learning_rate": 4.14e-05,
      "loss": 0.0027,
      "step": 15480
    },
    {
      "epoch": 0.3442222222222222,
      "grad_norm": 0.09712392836809158,
      "learning_rate": 4.139444444444445e-05,
      "loss": 0.0028,
      "step": 15490
    },
    {
      "epoch": 0.34444444444444444,
      "grad_norm": 0.39272263646125793,
      "learning_rate": 4.138888888888889e-05,
      "loss": 0.0038,
      "step": 15500
    },
    {
      "epoch": 0.3446666666666667,
      "grad_norm": 0.404170960187912,
      "learning_rate": 4.1383333333333334e-05,
      "loss": 0.0024,
      "step": 15510
    },
    {
      "epoch": 0.3448888888888889,
      "grad_norm": 0.2791658341884613,
      "learning_rate": 4.1377777777777784e-05,
      "loss": 0.0022,
      "step": 15520
    },
    {
      "epoch": 0.3451111111111111,
      "grad_norm": 0.1034979596734047,
      "learning_rate": 4.137222222222222e-05,
      "loss": 0.0018,
      "step": 15530
    },
    {
      "epoch": 0.3453333333333333,
      "grad_norm": 0.18572896718978882,
      "learning_rate": 4.136666666666667e-05,
      "loss": 0.0025,
      "step": 15540
    },
    {
      "epoch": 0.34555555555555556,
      "grad_norm": 0.09648272395133972,
      "learning_rate": 4.136111111111111e-05,
      "loss": 0.0024,
      "step": 15550
    },
    {
      "epoch": 0.3457777777777778,
      "grad_norm": 0.2968476116657257,
      "learning_rate": 4.135555555555556e-05,
      "loss": 0.0027,
      "step": 15560
    },
    {
      "epoch": 0.346,
      "grad_norm": 0.16686806082725525,
      "learning_rate": 4.135e-05,
      "loss": 0.0037,
      "step": 15570
    },
    {
      "epoch": 0.3462222222222222,
      "grad_norm": 0.3948427140712738,
      "learning_rate": 4.1344444444444446e-05,
      "loss": 0.0026,
      "step": 15580
    },
    {
      "epoch": 0.34644444444444444,
      "grad_norm": 0.4355746805667877,
      "learning_rate": 4.133888888888889e-05,
      "loss": 0.0021,
      "step": 15590
    },
    {
      "epoch": 0.3466666666666667,
      "grad_norm": 0.4340279996395111,
      "learning_rate": 4.133333333333333e-05,
      "loss": 0.0026,
      "step": 15600
    },
    {
      "epoch": 0.3468888888888889,
      "grad_norm": 0.3136645257472992,
      "learning_rate": 4.132777777777778e-05,
      "loss": 0.0022,
      "step": 15610
    },
    {
      "epoch": 0.3471111111111111,
      "grad_norm": 0.08029782027006149,
      "learning_rate": 4.132222222222222e-05,
      "loss": 0.0022,
      "step": 15620
    },
    {
      "epoch": 0.3473333333333333,
      "grad_norm": 0.1394881159067154,
      "learning_rate": 4.131666666666667e-05,
      "loss": 0.0025,
      "step": 15630
    },
    {
      "epoch": 0.34755555555555556,
      "grad_norm": 0.17588892579078674,
      "learning_rate": 4.1311111111111114e-05,
      "loss": 0.0023,
      "step": 15640
    },
    {
      "epoch": 0.3477777777777778,
      "grad_norm": 0.11368270218372345,
      "learning_rate": 4.130555555555556e-05,
      "loss": 0.0019,
      "step": 15650
    },
    {
      "epoch": 0.348,
      "grad_norm": 0.41915959119796753,
      "learning_rate": 4.13e-05,
      "loss": 0.0026,
      "step": 15660
    },
    {
      "epoch": 0.3482222222222222,
      "grad_norm": 0.1022658497095108,
      "learning_rate": 4.1294444444444445e-05,
      "loss": 0.0022,
      "step": 15670
    },
    {
      "epoch": 0.34844444444444445,
      "grad_norm": 0.7427648901939392,
      "learning_rate": 4.1288888888888895e-05,
      "loss": 0.0027,
      "step": 15680
    },
    {
      "epoch": 0.3486666666666667,
      "grad_norm": 0.2719700038433075,
      "learning_rate": 4.128333333333333e-05,
      "loss": 0.0033,
      "step": 15690
    },
    {
      "epoch": 0.3488888888888889,
      "grad_norm": 0.4910551607608795,
      "learning_rate": 4.127777777777778e-05,
      "loss": 0.0024,
      "step": 15700
    },
    {
      "epoch": 0.3491111111111111,
      "grad_norm": 0.14796182513237,
      "learning_rate": 4.1272222222222226e-05,
      "loss": 0.0021,
      "step": 15710
    },
    {
      "epoch": 0.34933333333333333,
      "grad_norm": 0.9105632901191711,
      "learning_rate": 4.126666666666667e-05,
      "loss": 0.0021,
      "step": 15720
    },
    {
      "epoch": 0.34955555555555556,
      "grad_norm": 0.5592777729034424,
      "learning_rate": 4.126111111111111e-05,
      "loss": 0.0017,
      "step": 15730
    },
    {
      "epoch": 0.3497777777777778,
      "grad_norm": 0.4343193471431732,
      "learning_rate": 4.1255555555555556e-05,
      "loss": 0.0022,
      "step": 15740
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.26422756910324097,
      "learning_rate": 4.125e-05,
      "loss": 0.0026,
      "step": 15750
    },
    {
      "epoch": 0.3502222222222222,
      "grad_norm": 0.10580012947320938,
      "learning_rate": 4.124444444444444e-05,
      "loss": 0.0025,
      "step": 15760
    },
    {
      "epoch": 0.35044444444444445,
      "grad_norm": 0.3606624901294708,
      "learning_rate": 4.1238888888888894e-05,
      "loss": 0.0025,
      "step": 15770
    },
    {
      "epoch": 0.3506666666666667,
      "grad_norm": 0.4813976287841797,
      "learning_rate": 4.123333333333334e-05,
      "loss": 0.0023,
      "step": 15780
    },
    {
      "epoch": 0.35088888888888886,
      "grad_norm": 0.12087858468294144,
      "learning_rate": 4.122777777777778e-05,
      "loss": 0.0024,
      "step": 15790
    },
    {
      "epoch": 0.3511111111111111,
      "grad_norm": 0.44688281416893005,
      "learning_rate": 4.1222222222222224e-05,
      "loss": 0.0024,
      "step": 15800
    },
    {
      "epoch": 0.35133333333333333,
      "grad_norm": 0.07901047170162201,
      "learning_rate": 4.121666666666667e-05,
      "loss": 0.0019,
      "step": 15810
    },
    {
      "epoch": 0.35155555555555557,
      "grad_norm": 0.09844426065683365,
      "learning_rate": 4.121111111111111e-05,
      "loss": 0.0017,
      "step": 15820
    },
    {
      "epoch": 0.3517777777777778,
      "grad_norm": 0.18470406532287598,
      "learning_rate": 4.1205555555555555e-05,
      "loss": 0.0022,
      "step": 15830
    },
    {
      "epoch": 0.352,
      "grad_norm": 0.345890611410141,
      "learning_rate": 4.12e-05,
      "loss": 0.0028,
      "step": 15840
    },
    {
      "epoch": 0.3522222222222222,
      "grad_norm": 0.13470321893692017,
      "learning_rate": 4.119444444444445e-05,
      "loss": 0.0027,
      "step": 15850
    },
    {
      "epoch": 0.35244444444444445,
      "grad_norm": 0.21138639748096466,
      "learning_rate": 4.118888888888889e-05,
      "loss": 0.0019,
      "step": 15860
    },
    {
      "epoch": 0.3526666666666667,
      "grad_norm": 0.19591540098190308,
      "learning_rate": 4.1183333333333336e-05,
      "loss": 0.0025,
      "step": 15870
    },
    {
      "epoch": 0.35288888888888886,
      "grad_norm": 0.16464069485664368,
      "learning_rate": 4.117777777777778e-05,
      "loss": 0.002,
      "step": 15880
    },
    {
      "epoch": 0.3531111111111111,
      "grad_norm": 0.6857066750526428,
      "learning_rate": 4.117222222222222e-05,
      "loss": 0.0038,
      "step": 15890
    },
    {
      "epoch": 0.35333333333333333,
      "grad_norm": 0.32207873463630676,
      "learning_rate": 4.116666666666667e-05,
      "loss": 0.0021,
      "step": 15900
    },
    {
      "epoch": 0.35355555555555557,
      "grad_norm": 0.2926118075847626,
      "learning_rate": 4.116111111111111e-05,
      "loss": 0.0025,
      "step": 15910
    },
    {
      "epoch": 0.3537777777777778,
      "grad_norm": 0.6436197757720947,
      "learning_rate": 4.115555555555556e-05,
      "loss": 0.0022,
      "step": 15920
    },
    {
      "epoch": 0.354,
      "grad_norm": 0.6329702138900757,
      "learning_rate": 4.115e-05,
      "loss": 0.0023,
      "step": 15930
    },
    {
      "epoch": 0.3542222222222222,
      "grad_norm": 0.25757768750190735,
      "learning_rate": 4.114444444444445e-05,
      "loss": 0.0024,
      "step": 15940
    },
    {
      "epoch": 0.35444444444444445,
      "grad_norm": 0.37393277883529663,
      "learning_rate": 4.113888888888889e-05,
      "loss": 0.0027,
      "step": 15950
    },
    {
      "epoch": 0.3546666666666667,
      "grad_norm": 0.2609628438949585,
      "learning_rate": 4.1133333333333335e-05,
      "loss": 0.0033,
      "step": 15960
    },
    {
      "epoch": 0.35488888888888886,
      "grad_norm": 0.19546781480312347,
      "learning_rate": 4.1127777777777785e-05,
      "loss": 0.0021,
      "step": 15970
    },
    {
      "epoch": 0.3551111111111111,
      "grad_norm": 0.23972681164741516,
      "learning_rate": 4.112222222222222e-05,
      "loss": 0.0021,
      "step": 15980
    },
    {
      "epoch": 0.35533333333333333,
      "grad_norm": 0.3199903666973114,
      "learning_rate": 4.111666666666667e-05,
      "loss": 0.0022,
      "step": 15990
    },
    {
      "epoch": 0.35555555555555557,
      "grad_norm": 0.09193800389766693,
      "learning_rate": 4.111111111111111e-05,
      "loss": 0.0027,
      "step": 16000
    },
    {
      "epoch": 0.3557777777777778,
      "grad_norm": 0.175706684589386,
      "learning_rate": 4.110555555555556e-05,
      "loss": 0.0021,
      "step": 16010
    },
    {
      "epoch": 0.356,
      "grad_norm": 0.14126907289028168,
      "learning_rate": 4.11e-05,
      "loss": 0.0023,
      "step": 16020
    },
    {
      "epoch": 0.3562222222222222,
      "grad_norm": 0.19761499762535095,
      "learning_rate": 4.1094444444444446e-05,
      "loss": 0.0021,
      "step": 16030
    },
    {
      "epoch": 0.35644444444444445,
      "grad_norm": 0.1929454356431961,
      "learning_rate": 4.10888888888889e-05,
      "loss": 0.003,
      "step": 16040
    },
    {
      "epoch": 0.3566666666666667,
      "grad_norm": 0.6347787976264954,
      "learning_rate": 4.1083333333333334e-05,
      "loss": 0.0033,
      "step": 16050
    },
    {
      "epoch": 0.35688888888888887,
      "grad_norm": 0.2660251259803772,
      "learning_rate": 4.1077777777777784e-05,
      "loss": 0.0025,
      "step": 16060
    },
    {
      "epoch": 0.3571111111111111,
      "grad_norm": 0.49262291193008423,
      "learning_rate": 4.107222222222222e-05,
      "loss": 0.0024,
      "step": 16070
    },
    {
      "epoch": 0.35733333333333334,
      "grad_norm": 0.40364590287208557,
      "learning_rate": 4.106666666666667e-05,
      "loss": 0.0017,
      "step": 16080
    },
    {
      "epoch": 0.35755555555555557,
      "grad_norm": 0.13859693706035614,
      "learning_rate": 4.1061111111111115e-05,
      "loss": 0.0022,
      "step": 16090
    },
    {
      "epoch": 0.35777777777777775,
      "grad_norm": 0.18377557396888733,
      "learning_rate": 4.105555555555556e-05,
      "loss": 0.0041,
      "step": 16100
    },
    {
      "epoch": 0.358,
      "grad_norm": 0.15171004831790924,
      "learning_rate": 4.105e-05,
      "loss": 0.0026,
      "step": 16110
    },
    {
      "epoch": 0.3582222222222222,
      "grad_norm": 0.29040390253067017,
      "learning_rate": 4.1044444444444445e-05,
      "loss": 0.0029,
      "step": 16120
    },
    {
      "epoch": 0.35844444444444445,
      "grad_norm": 0.11805688589811325,
      "learning_rate": 4.1038888888888896e-05,
      "loss": 0.0022,
      "step": 16130
    },
    {
      "epoch": 0.3586666666666667,
      "grad_norm": 0.29664358496665955,
      "learning_rate": 4.103333333333333e-05,
      "loss": 0.0034,
      "step": 16140
    },
    {
      "epoch": 0.35888888888888887,
      "grad_norm": 0.2600136995315552,
      "learning_rate": 4.102777777777778e-05,
      "loss": 0.0031,
      "step": 16150
    },
    {
      "epoch": 0.3591111111111111,
      "grad_norm": 0.14845815300941467,
      "learning_rate": 4.1022222222222226e-05,
      "loss": 0.0028,
      "step": 16160
    },
    {
      "epoch": 0.35933333333333334,
      "grad_norm": 0.06427151709794998,
      "learning_rate": 4.101666666666667e-05,
      "loss": 0.0018,
      "step": 16170
    },
    {
      "epoch": 0.3595555555555556,
      "grad_norm": 0.2053508311510086,
      "learning_rate": 4.101111111111111e-05,
      "loss": 0.0037,
      "step": 16180
    },
    {
      "epoch": 0.35977777777777775,
      "grad_norm": 0.1670190840959549,
      "learning_rate": 4.100555555555556e-05,
      "loss": 0.0023,
      "step": 16190
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.07938085496425629,
      "learning_rate": 4.1e-05,
      "loss": 0.002,
      "step": 16200
    },
    {
      "epoch": 0.3602222222222222,
      "grad_norm": 0.3151557743549347,
      "learning_rate": 4.0994444444444444e-05,
      "loss": 0.0042,
      "step": 16210
    },
    {
      "epoch": 0.36044444444444446,
      "grad_norm": 0.11568424105644226,
      "learning_rate": 4.0988888888888894e-05,
      "loss": 0.0025,
      "step": 16220
    },
    {
      "epoch": 0.3606666666666667,
      "grad_norm": 0.23637667298316956,
      "learning_rate": 4.098333333333334e-05,
      "loss": 0.0029,
      "step": 16230
    },
    {
      "epoch": 0.36088888888888887,
      "grad_norm": 0.10092970728874207,
      "learning_rate": 4.097777777777778e-05,
      "loss": 0.0036,
      "step": 16240
    },
    {
      "epoch": 0.3611111111111111,
      "grad_norm": 0.2579561471939087,
      "learning_rate": 4.0972222222222225e-05,
      "loss": 0.0022,
      "step": 16250
    },
    {
      "epoch": 0.36133333333333334,
      "grad_norm": 0.18521271646022797,
      "learning_rate": 4.096666666666667e-05,
      "loss": 0.0017,
      "step": 16260
    },
    {
      "epoch": 0.3615555555555556,
      "grad_norm": 0.1500261276960373,
      "learning_rate": 4.096111111111111e-05,
      "loss": 0.0019,
      "step": 16270
    },
    {
      "epoch": 0.36177777777777775,
      "grad_norm": 0.4092741012573242,
      "learning_rate": 4.0955555555555556e-05,
      "loss": 0.0029,
      "step": 16280
    },
    {
      "epoch": 0.362,
      "grad_norm": 0.26714077591896057,
      "learning_rate": 4.095e-05,
      "loss": 0.0029,
      "step": 16290
    },
    {
      "epoch": 0.3622222222222222,
      "grad_norm": 0.5597740411758423,
      "learning_rate": 4.094444444444445e-05,
      "loss": 0.0021,
      "step": 16300
    },
    {
      "epoch": 0.36244444444444446,
      "grad_norm": 0.2706264555454254,
      "learning_rate": 4.093888888888889e-05,
      "loss": 0.0027,
      "step": 16310
    },
    {
      "epoch": 0.3626666666666667,
      "grad_norm": 0.41924574971199036,
      "learning_rate": 4.093333333333334e-05,
      "loss": 0.0025,
      "step": 16320
    },
    {
      "epoch": 0.36288888888888887,
      "grad_norm": 0.4044753909111023,
      "learning_rate": 4.092777777777778e-05,
      "loss": 0.0026,
      "step": 16330
    },
    {
      "epoch": 0.3631111111111111,
      "grad_norm": 0.545486330986023,
      "learning_rate": 4.0922222222222224e-05,
      "loss": 0.0023,
      "step": 16340
    },
    {
      "epoch": 0.36333333333333334,
      "grad_norm": 0.601446270942688,
      "learning_rate": 4.091666666666667e-05,
      "loss": 0.0024,
      "step": 16350
    },
    {
      "epoch": 0.3635555555555556,
      "grad_norm": 0.3291124701499939,
      "learning_rate": 4.091111111111111e-05,
      "loss": 0.0027,
      "step": 16360
    },
    {
      "epoch": 0.36377777777777776,
      "grad_norm": 0.0907054916024208,
      "learning_rate": 4.090555555555556e-05,
      "loss": 0.0027,
      "step": 16370
    },
    {
      "epoch": 0.364,
      "grad_norm": 0.16873136162757874,
      "learning_rate": 4.09e-05,
      "loss": 0.0023,
      "step": 16380
    },
    {
      "epoch": 0.3642222222222222,
      "grad_norm": 0.26766711473464966,
      "learning_rate": 4.089444444444445e-05,
      "loss": 0.002,
      "step": 16390
    },
    {
      "epoch": 0.36444444444444446,
      "grad_norm": 0.3769319951534271,
      "learning_rate": 4.088888888888889e-05,
      "loss": 0.0019,
      "step": 16400
    },
    {
      "epoch": 0.36466666666666664,
      "grad_norm": 0.5548645853996277,
      "learning_rate": 4.0883333333333335e-05,
      "loss": 0.0034,
      "step": 16410
    },
    {
      "epoch": 0.3648888888888889,
      "grad_norm": 0.21649543941020966,
      "learning_rate": 4.087777777777778e-05,
      "loss": 0.0029,
      "step": 16420
    },
    {
      "epoch": 0.3651111111111111,
      "grad_norm": 0.11363431811332703,
      "learning_rate": 4.087222222222222e-05,
      "loss": 0.0023,
      "step": 16430
    },
    {
      "epoch": 0.36533333333333334,
      "grad_norm": 0.13338902592658997,
      "learning_rate": 4.086666666666667e-05,
      "loss": 0.0021,
      "step": 16440
    },
    {
      "epoch": 0.3655555555555556,
      "grad_norm": 0.14595085382461548,
      "learning_rate": 4.086111111111111e-05,
      "loss": 0.0032,
      "step": 16450
    },
    {
      "epoch": 0.36577777777777776,
      "grad_norm": 0.08677437156438828,
      "learning_rate": 4.085555555555556e-05,
      "loss": 0.0026,
      "step": 16460
    },
    {
      "epoch": 0.366,
      "grad_norm": 0.10688076913356781,
      "learning_rate": 4.085e-05,
      "loss": 0.002,
      "step": 16470
    },
    {
      "epoch": 0.3662222222222222,
      "grad_norm": 0.7800883054733276,
      "learning_rate": 4.084444444444445e-05,
      "loss": 0.0032,
      "step": 16480
    },
    {
      "epoch": 0.36644444444444446,
      "grad_norm": 0.10513340681791306,
      "learning_rate": 4.083888888888889e-05,
      "loss": 0.0023,
      "step": 16490
    },
    {
      "epoch": 0.36666666666666664,
      "grad_norm": 0.35709571838378906,
      "learning_rate": 4.0833333333333334e-05,
      "loss": 0.002,
      "step": 16500
    },
    {
      "epoch": 0.3668888888888889,
      "grad_norm": 0.18091042339801788,
      "learning_rate": 4.0827777777777785e-05,
      "loss": 0.0024,
      "step": 16510
    },
    {
      "epoch": 0.3671111111111111,
      "grad_norm": 0.20954503118991852,
      "learning_rate": 4.082222222222222e-05,
      "loss": 0.003,
      "step": 16520
    },
    {
      "epoch": 0.36733333333333335,
      "grad_norm": 0.432433158159256,
      "learning_rate": 4.081666666666667e-05,
      "loss": 0.0023,
      "step": 16530
    },
    {
      "epoch": 0.3675555555555556,
      "grad_norm": 0.1315275877714157,
      "learning_rate": 4.081111111111111e-05,
      "loss": 0.0021,
      "step": 16540
    },
    {
      "epoch": 0.36777777777777776,
      "grad_norm": 0.05164723843336105,
      "learning_rate": 4.080555555555556e-05,
      "loss": 0.0025,
      "step": 16550
    },
    {
      "epoch": 0.368,
      "grad_norm": 0.24036426842212677,
      "learning_rate": 4.08e-05,
      "loss": 0.003,
      "step": 16560
    },
    {
      "epoch": 0.36822222222222223,
      "grad_norm": 0.07150132209062576,
      "learning_rate": 4.0794444444444446e-05,
      "loss": 0.0017,
      "step": 16570
    },
    {
      "epoch": 0.36844444444444446,
      "grad_norm": 0.09343758970499039,
      "learning_rate": 4.0788888888888896e-05,
      "loss": 0.003,
      "step": 16580
    },
    {
      "epoch": 0.36866666666666664,
      "grad_norm": 0.4639306962490082,
      "learning_rate": 4.078333333333333e-05,
      "loss": 0.0027,
      "step": 16590
    },
    {
      "epoch": 0.3688888888888889,
      "grad_norm": 0.2688842713832855,
      "learning_rate": 4.0777777777777783e-05,
      "loss": 0.0022,
      "step": 16600
    },
    {
      "epoch": 0.3691111111111111,
      "grad_norm": 0.2694112956523895,
      "learning_rate": 4.077222222222222e-05,
      "loss": 0.0022,
      "step": 16610
    },
    {
      "epoch": 0.36933333333333335,
      "grad_norm": 0.1911635547876358,
      "learning_rate": 4.076666666666667e-05,
      "loss": 0.0028,
      "step": 16620
    },
    {
      "epoch": 0.3695555555555556,
      "grad_norm": 0.34393075108528137,
      "learning_rate": 4.0761111111111114e-05,
      "loss": 0.0019,
      "step": 16630
    },
    {
      "epoch": 0.36977777777777776,
      "grad_norm": 0.1501970738172531,
      "learning_rate": 4.075555555555556e-05,
      "loss": 0.0023,
      "step": 16640
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.5695267915725708,
      "learning_rate": 4.075e-05,
      "loss": 0.0023,
      "step": 16650
    },
    {
      "epoch": 0.37022222222222223,
      "grad_norm": 0.38420727849006653,
      "learning_rate": 4.0744444444444445e-05,
      "loss": 0.0021,
      "step": 16660
    },
    {
      "epoch": 0.37044444444444447,
      "grad_norm": 0.1571989506483078,
      "learning_rate": 4.0738888888888895e-05,
      "loss": 0.0021,
      "step": 16670
    },
    {
      "epoch": 0.37066666666666664,
      "grad_norm": 0.13003289699554443,
      "learning_rate": 4.073333333333333e-05,
      "loss": 0.0022,
      "step": 16680
    },
    {
      "epoch": 0.3708888888888889,
      "grad_norm": 0.07565318048000336,
      "learning_rate": 4.072777777777778e-05,
      "loss": 0.0024,
      "step": 16690
    },
    {
      "epoch": 0.3711111111111111,
      "grad_norm": 0.19115406274795532,
      "learning_rate": 4.0722222222222226e-05,
      "loss": 0.0031,
      "step": 16700
    },
    {
      "epoch": 0.37133333333333335,
      "grad_norm": 0.13466623425483704,
      "learning_rate": 4.071666666666667e-05,
      "loss": 0.0027,
      "step": 16710
    },
    {
      "epoch": 0.37155555555555553,
      "grad_norm": 0.2572283148765564,
      "learning_rate": 4.071111111111111e-05,
      "loss": 0.0033,
      "step": 16720
    },
    {
      "epoch": 0.37177777777777776,
      "grad_norm": 0.14553628861904144,
      "learning_rate": 4.0705555555555556e-05,
      "loss": 0.0027,
      "step": 16730
    },
    {
      "epoch": 0.372,
      "grad_norm": 0.15032179653644562,
      "learning_rate": 4.07e-05,
      "loss": 0.0021,
      "step": 16740
    },
    {
      "epoch": 0.37222222222222223,
      "grad_norm": 0.3648360073566437,
      "learning_rate": 4.0694444444444444e-05,
      "loss": 0.0028,
      "step": 16750
    },
    {
      "epoch": 0.37244444444444447,
      "grad_norm": 0.8468490839004517,
      "learning_rate": 4.0688888888888894e-05,
      "loss": 0.002,
      "step": 16760
    },
    {
      "epoch": 0.37266666666666665,
      "grad_norm": 0.5159291625022888,
      "learning_rate": 4.068333333333334e-05,
      "loss": 0.0025,
      "step": 16770
    },
    {
      "epoch": 0.3728888888888889,
      "grad_norm": 0.07139111310243607,
      "learning_rate": 4.067777777777778e-05,
      "loss": 0.0017,
      "step": 16780
    },
    {
      "epoch": 0.3731111111111111,
      "grad_norm": 0.3386034667491913,
      "learning_rate": 4.0672222222222225e-05,
      "loss": 0.0019,
      "step": 16790
    },
    {
      "epoch": 0.37333333333333335,
      "grad_norm": 0.3849795162677765,
      "learning_rate": 4.066666666666667e-05,
      "loss": 0.0023,
      "step": 16800
    },
    {
      "epoch": 0.37355555555555553,
      "grad_norm": 0.09773104637861252,
      "learning_rate": 4.066111111111111e-05,
      "loss": 0.0023,
      "step": 16810
    },
    {
      "epoch": 0.37377777777777776,
      "grad_norm": 0.08401574939489365,
      "learning_rate": 4.0655555555555555e-05,
      "loss": 0.0021,
      "step": 16820
    },
    {
      "epoch": 0.374,
      "grad_norm": 0.39053165912628174,
      "learning_rate": 4.065e-05,
      "loss": 0.003,
      "step": 16830
    },
    {
      "epoch": 0.37422222222222223,
      "grad_norm": 0.25802889466285706,
      "learning_rate": 4.064444444444445e-05,
      "loss": 0.002,
      "step": 16840
    },
    {
      "epoch": 0.37444444444444447,
      "grad_norm": 0.25365349650382996,
      "learning_rate": 4.063888888888889e-05,
      "loss": 0.0033,
      "step": 16850
    },
    {
      "epoch": 0.37466666666666665,
      "grad_norm": 0.1435767412185669,
      "learning_rate": 4.0633333333333336e-05,
      "loss": 0.0038,
      "step": 16860
    },
    {
      "epoch": 0.3748888888888889,
      "grad_norm": 0.15882281959056854,
      "learning_rate": 4.062777777777778e-05,
      "loss": 0.0019,
      "step": 16870
    },
    {
      "epoch": 0.3751111111111111,
      "grad_norm": 0.41644665598869324,
      "learning_rate": 4.062222222222222e-05,
      "loss": 0.0032,
      "step": 16880
    },
    {
      "epoch": 0.37533333333333335,
      "grad_norm": 0.10285744071006775,
      "learning_rate": 4.061666666666667e-05,
      "loss": 0.0031,
      "step": 16890
    },
    {
      "epoch": 0.37555555555555553,
      "grad_norm": 0.46375948190689087,
      "learning_rate": 4.061111111111111e-05,
      "loss": 0.0025,
      "step": 16900
    },
    {
      "epoch": 0.37577777777777777,
      "grad_norm": 0.31870925426483154,
      "learning_rate": 4.060555555555556e-05,
      "loss": 0.0024,
      "step": 16910
    },
    {
      "epoch": 0.376,
      "grad_norm": 0.1371704339981079,
      "learning_rate": 4.0600000000000004e-05,
      "loss": 0.0023,
      "step": 16920
    },
    {
      "epoch": 0.37622222222222224,
      "grad_norm": 0.2409355342388153,
      "learning_rate": 4.059444444444445e-05,
      "loss": 0.0024,
      "step": 16930
    },
    {
      "epoch": 0.37644444444444447,
      "grad_norm": 0.3195890486240387,
      "learning_rate": 4.058888888888889e-05,
      "loss": 0.002,
      "step": 16940
    },
    {
      "epoch": 0.37666666666666665,
      "grad_norm": 0.38467341661453247,
      "learning_rate": 4.0583333333333335e-05,
      "loss": 0.0023,
      "step": 16950
    },
    {
      "epoch": 0.3768888888888889,
      "grad_norm": 0.0678921565413475,
      "learning_rate": 4.057777777777778e-05,
      "loss": 0.0022,
      "step": 16960
    },
    {
      "epoch": 0.3771111111111111,
      "grad_norm": 0.1288118213415146,
      "learning_rate": 4.057222222222222e-05,
      "loss": 0.0025,
      "step": 16970
    },
    {
      "epoch": 0.37733333333333335,
      "grad_norm": 0.09096138924360275,
      "learning_rate": 4.056666666666667e-05,
      "loss": 0.0023,
      "step": 16980
    },
    {
      "epoch": 0.37755555555555553,
      "grad_norm": 0.10616788268089294,
      "learning_rate": 4.056111111111111e-05,
      "loss": 0.0022,
      "step": 16990
    },
    {
      "epoch": 0.37777777777777777,
      "grad_norm": 0.08945593982934952,
      "learning_rate": 4.055555555555556e-05,
      "loss": 0.0023,
      "step": 17000
    },
    {
      "epoch": 0.378,
      "grad_norm": 0.08438044041395187,
      "learning_rate": 4.055e-05,
      "loss": 0.0029,
      "step": 17010
    },
    {
      "epoch": 0.37822222222222224,
      "grad_norm": 0.17353183031082153,
      "learning_rate": 4.054444444444445e-05,
      "loss": 0.0024,
      "step": 17020
    },
    {
      "epoch": 0.37844444444444447,
      "grad_norm": 0.14012879133224487,
      "learning_rate": 4.053888888888889e-05,
      "loss": 0.0035,
      "step": 17030
    },
    {
      "epoch": 0.37866666666666665,
      "grad_norm": 0.4300646483898163,
      "learning_rate": 4.0533333333333334e-05,
      "loss": 0.0022,
      "step": 17040
    },
    {
      "epoch": 0.3788888888888889,
      "grad_norm": 0.28361180424690247,
      "learning_rate": 4.0527777777777784e-05,
      "loss": 0.0021,
      "step": 17050
    },
    {
      "epoch": 0.3791111111111111,
      "grad_norm": 0.10162591934204102,
      "learning_rate": 4.052222222222222e-05,
      "loss": 0.0035,
      "step": 17060
    },
    {
      "epoch": 0.37933333333333336,
      "grad_norm": 0.12807543575763702,
      "learning_rate": 4.051666666666667e-05,
      "loss": 0.0036,
      "step": 17070
    },
    {
      "epoch": 0.37955555555555553,
      "grad_norm": 0.7011188268661499,
      "learning_rate": 4.051111111111111e-05,
      "loss": 0.0028,
      "step": 17080
    },
    {
      "epoch": 0.37977777777777777,
      "grad_norm": 0.4786209166049957,
      "learning_rate": 4.050555555555556e-05,
      "loss": 0.0025,
      "step": 17090
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.10563317686319351,
      "learning_rate": 4.05e-05,
      "loss": 0.0021,
      "step": 17100
    },
    {
      "epoch": 0.38022222222222224,
      "grad_norm": 0.09494006633758545,
      "learning_rate": 4.0494444444444445e-05,
      "loss": 0.0017,
      "step": 17110
    },
    {
      "epoch": 0.3804444444444444,
      "grad_norm": 0.31385746598243713,
      "learning_rate": 4.0488888888888896e-05,
      "loss": 0.003,
      "step": 17120
    },
    {
      "epoch": 0.38066666666666665,
      "grad_norm": 0.16485056281089783,
      "learning_rate": 4.048333333333333e-05,
      "loss": 0.0023,
      "step": 17130
    },
    {
      "epoch": 0.3808888888888889,
      "grad_norm": 0.10853862017393112,
      "learning_rate": 4.047777777777778e-05,
      "loss": 0.004,
      "step": 17140
    },
    {
      "epoch": 0.3811111111111111,
      "grad_norm": 0.564527690410614,
      "learning_rate": 4.047222222222222e-05,
      "loss": 0.0029,
      "step": 17150
    },
    {
      "epoch": 0.38133333333333336,
      "grad_norm": 0.26015013456344604,
      "learning_rate": 4.046666666666667e-05,
      "loss": 0.0021,
      "step": 17160
    },
    {
      "epoch": 0.38155555555555554,
      "grad_norm": 0.8879269957542419,
      "learning_rate": 4.0461111111111114e-05,
      "loss": 0.0023,
      "step": 17170
    },
    {
      "epoch": 0.38177777777777777,
      "grad_norm": 0.19055868685245514,
      "learning_rate": 4.045555555555556e-05,
      "loss": 0.0024,
      "step": 17180
    },
    {
      "epoch": 0.382,
      "grad_norm": 0.6881898045539856,
      "learning_rate": 4.045000000000001e-05,
      "loss": 0.003,
      "step": 17190
    },
    {
      "epoch": 0.38222222222222224,
      "grad_norm": 0.6620717644691467,
      "learning_rate": 4.0444444444444444e-05,
      "loss": 0.0019,
      "step": 17200
    },
    {
      "epoch": 0.3824444444444444,
      "grad_norm": 0.17705859243869781,
      "learning_rate": 4.0438888888888895e-05,
      "loss": 0.0021,
      "step": 17210
    },
    {
      "epoch": 0.38266666666666665,
      "grad_norm": 0.2593458592891693,
      "learning_rate": 4.043333333333333e-05,
      "loss": 0.0018,
      "step": 17220
    },
    {
      "epoch": 0.3828888888888889,
      "grad_norm": 0.39610591530799866,
      "learning_rate": 4.042777777777778e-05,
      "loss": 0.0023,
      "step": 17230
    },
    {
      "epoch": 0.3831111111111111,
      "grad_norm": 0.41267096996307373,
      "learning_rate": 4.0422222222222225e-05,
      "loss": 0.0022,
      "step": 17240
    },
    {
      "epoch": 0.38333333333333336,
      "grad_norm": 0.5645290613174438,
      "learning_rate": 4.041666666666667e-05,
      "loss": 0.0028,
      "step": 17250
    },
    {
      "epoch": 0.38355555555555554,
      "grad_norm": 0.12309754639863968,
      "learning_rate": 4.041111111111111e-05,
      "loss": 0.0036,
      "step": 17260
    },
    {
      "epoch": 0.3837777777777778,
      "grad_norm": 0.21966341137886047,
      "learning_rate": 4.0405555555555556e-05,
      "loss": 0.0026,
      "step": 17270
    },
    {
      "epoch": 0.384,
      "grad_norm": 0.4078714847564697,
      "learning_rate": 4.0400000000000006e-05,
      "loss": 0.002,
      "step": 17280
    },
    {
      "epoch": 0.38422222222222224,
      "grad_norm": 0.11827868968248367,
      "learning_rate": 4.039444444444444e-05,
      "loss": 0.0029,
      "step": 17290
    },
    {
      "epoch": 0.3844444444444444,
      "grad_norm": 0.5135526657104492,
      "learning_rate": 4.038888888888889e-05,
      "loss": 0.0026,
      "step": 17300
    },
    {
      "epoch": 0.38466666666666666,
      "grad_norm": 0.1231570765376091,
      "learning_rate": 4.038333333333334e-05,
      "loss": 0.0029,
      "step": 17310
    },
    {
      "epoch": 0.3848888888888889,
      "grad_norm": 0.0676499605178833,
      "learning_rate": 4.037777777777778e-05,
      "loss": 0.0019,
      "step": 17320
    },
    {
      "epoch": 0.3851111111111111,
      "grad_norm": 0.14236651360988617,
      "learning_rate": 4.0372222222222224e-05,
      "loss": 0.0023,
      "step": 17330
    },
    {
      "epoch": 0.38533333333333336,
      "grad_norm": 0.12329493463039398,
      "learning_rate": 4.036666666666667e-05,
      "loss": 0.0043,
      "step": 17340
    },
    {
      "epoch": 0.38555555555555554,
      "grad_norm": 0.05589604750275612,
      "learning_rate": 4.036111111111111e-05,
      "loss": 0.0024,
      "step": 17350
    },
    {
      "epoch": 0.3857777777777778,
      "grad_norm": 0.20632421970367432,
      "learning_rate": 4.0355555555555555e-05,
      "loss": 0.0035,
      "step": 17360
    },
    {
      "epoch": 0.386,
      "grad_norm": 0.48760998249053955,
      "learning_rate": 4.0350000000000005e-05,
      "loss": 0.0021,
      "step": 17370
    },
    {
      "epoch": 0.38622222222222224,
      "grad_norm": 0.14673587679862976,
      "learning_rate": 4.034444444444445e-05,
      "loss": 0.0025,
      "step": 17380
    },
    {
      "epoch": 0.3864444444444444,
      "grad_norm": 0.08492891490459442,
      "learning_rate": 4.033888888888889e-05,
      "loss": 0.0023,
      "step": 17390
    },
    {
      "epoch": 0.38666666666666666,
      "grad_norm": 0.0881786197423935,
      "learning_rate": 4.0333333333333336e-05,
      "loss": 0.002,
      "step": 17400
    },
    {
      "epoch": 0.3868888888888889,
      "grad_norm": 0.14992965757846832,
      "learning_rate": 4.032777777777778e-05,
      "loss": 0.0021,
      "step": 17410
    },
    {
      "epoch": 0.38711111111111113,
      "grad_norm": 0.3629920184612274,
      "learning_rate": 4.032222222222222e-05,
      "loss": 0.0023,
      "step": 17420
    },
    {
      "epoch": 0.3873333333333333,
      "grad_norm": 0.505158007144928,
      "learning_rate": 4.0316666666666666e-05,
      "loss": 0.0022,
      "step": 17430
    },
    {
      "epoch": 0.38755555555555554,
      "grad_norm": 0.3581893742084503,
      "learning_rate": 4.031111111111111e-05,
      "loss": 0.0029,
      "step": 17440
    },
    {
      "epoch": 0.3877777777777778,
      "grad_norm": 0.40373626351356506,
      "learning_rate": 4.030555555555556e-05,
      "loss": 0.0021,
      "step": 17450
    },
    {
      "epoch": 0.388,
      "grad_norm": 0.22881628572940826,
      "learning_rate": 4.0300000000000004e-05,
      "loss": 0.003,
      "step": 17460
    },
    {
      "epoch": 0.38822222222222225,
      "grad_norm": 0.220613032579422,
      "learning_rate": 4.029444444444445e-05,
      "loss": 0.0027,
      "step": 17470
    },
    {
      "epoch": 0.3884444444444444,
      "grad_norm": 0.19313350319862366,
      "learning_rate": 4.028888888888889e-05,
      "loss": 0.0018,
      "step": 17480
    },
    {
      "epoch": 0.38866666666666666,
      "grad_norm": 0.4715878665447235,
      "learning_rate": 4.0283333333333334e-05,
      "loss": 0.0024,
      "step": 17490
    },
    {
      "epoch": 0.3888888888888889,
      "grad_norm": 0.35374903678894043,
      "learning_rate": 4.027777777777778e-05,
      "loss": 0.0022,
      "step": 17500
    },
    {
      "epoch": 0.38911111111111113,
      "grad_norm": 0.31697341799736023,
      "learning_rate": 4.027222222222222e-05,
      "loss": 0.0028,
      "step": 17510
    },
    {
      "epoch": 0.3893333333333333,
      "grad_norm": 0.18285873532295227,
      "learning_rate": 4.026666666666667e-05,
      "loss": 0.0021,
      "step": 17520
    },
    {
      "epoch": 0.38955555555555554,
      "grad_norm": 0.09896309673786163,
      "learning_rate": 4.026111111111111e-05,
      "loss": 0.003,
      "step": 17530
    },
    {
      "epoch": 0.3897777777777778,
      "grad_norm": 0.21551036834716797,
      "learning_rate": 4.025555555555556e-05,
      "loss": 0.0026,
      "step": 17540
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.07963307201862335,
      "learning_rate": 4.025e-05,
      "loss": 0.0036,
      "step": 17550
    },
    {
      "epoch": 0.39022222222222225,
      "grad_norm": 0.5276499390602112,
      "learning_rate": 4.0244444444444446e-05,
      "loss": 0.0031,
      "step": 17560
    },
    {
      "epoch": 0.3904444444444444,
      "grad_norm": 0.11119996756315231,
      "learning_rate": 4.023888888888889e-05,
      "loss": 0.0029,
      "step": 17570
    },
    {
      "epoch": 0.39066666666666666,
      "grad_norm": 0.13136988878250122,
      "learning_rate": 4.023333333333333e-05,
      "loss": 0.0029,
      "step": 17580
    },
    {
      "epoch": 0.3908888888888889,
      "grad_norm": 0.22912193834781647,
      "learning_rate": 4.0227777777777784e-05,
      "loss": 0.002,
      "step": 17590
    },
    {
      "epoch": 0.39111111111111113,
      "grad_norm": 0.10099853575229645,
      "learning_rate": 4.022222222222222e-05,
      "loss": 0.0019,
      "step": 17600
    },
    {
      "epoch": 0.3913333333333333,
      "grad_norm": 0.06903790682554245,
      "learning_rate": 4.021666666666667e-05,
      "loss": 0.002,
      "step": 17610
    },
    {
      "epoch": 0.39155555555555555,
      "grad_norm": 0.1300617903470993,
      "learning_rate": 4.021111111111111e-05,
      "loss": 0.0021,
      "step": 17620
    },
    {
      "epoch": 0.3917777777777778,
      "grad_norm": 0.7507734298706055,
      "learning_rate": 4.020555555555556e-05,
      "loss": 0.0019,
      "step": 17630
    },
    {
      "epoch": 0.392,
      "grad_norm": 0.19808590412139893,
      "learning_rate": 4.02e-05,
      "loss": 0.0022,
      "step": 17640
    },
    {
      "epoch": 0.39222222222222225,
      "grad_norm": 0.30695560574531555,
      "learning_rate": 4.0194444444444445e-05,
      "loss": 0.0017,
      "step": 17650
    },
    {
      "epoch": 0.39244444444444443,
      "grad_norm": 0.2702135443687439,
      "learning_rate": 4.0188888888888895e-05,
      "loss": 0.0023,
      "step": 17660
    },
    {
      "epoch": 0.39266666666666666,
      "grad_norm": 0.22194884717464447,
      "learning_rate": 4.018333333333333e-05,
      "loss": 0.0018,
      "step": 17670
    },
    {
      "epoch": 0.3928888888888889,
      "grad_norm": 0.49571073055267334,
      "learning_rate": 4.017777777777778e-05,
      "loss": 0.0028,
      "step": 17680
    },
    {
      "epoch": 0.39311111111111113,
      "grad_norm": 0.06863170862197876,
      "learning_rate": 4.017222222222222e-05,
      "loss": 0.0031,
      "step": 17690
    },
    {
      "epoch": 0.3933333333333333,
      "grad_norm": 0.4678868353366852,
      "learning_rate": 4.016666666666667e-05,
      "loss": 0.0021,
      "step": 17700
    },
    {
      "epoch": 0.39355555555555555,
      "grad_norm": 0.5121327638626099,
      "learning_rate": 4.016111111111111e-05,
      "loss": 0.0032,
      "step": 17710
    },
    {
      "epoch": 0.3937777777777778,
      "grad_norm": 0.11903692036867142,
      "learning_rate": 4.0155555555555557e-05,
      "loss": 0.0021,
      "step": 17720
    },
    {
      "epoch": 0.394,
      "grad_norm": 0.3888222277164459,
      "learning_rate": 4.015000000000001e-05,
      "loss": 0.0026,
      "step": 17730
    },
    {
      "epoch": 0.3942222222222222,
      "grad_norm": 0.16589298844337463,
      "learning_rate": 4.0144444444444444e-05,
      "loss": 0.0021,
      "step": 17740
    },
    {
      "epoch": 0.39444444444444443,
      "grad_norm": 0.09904079139232635,
      "learning_rate": 4.0138888888888894e-05,
      "loss": 0.002,
      "step": 17750
    },
    {
      "epoch": 0.39466666666666667,
      "grad_norm": 0.2193797379732132,
      "learning_rate": 4.013333333333333e-05,
      "loss": 0.0024,
      "step": 17760
    },
    {
      "epoch": 0.3948888888888889,
      "grad_norm": 0.25965413451194763,
      "learning_rate": 4.012777777777778e-05,
      "loss": 0.0022,
      "step": 17770
    },
    {
      "epoch": 0.39511111111111114,
      "grad_norm": 0.26890936493873596,
      "learning_rate": 4.0122222222222225e-05,
      "loss": 0.0024,
      "step": 17780
    },
    {
      "epoch": 0.3953333333333333,
      "grad_norm": 0.06407179683446884,
      "learning_rate": 4.011666666666667e-05,
      "loss": 0.0027,
      "step": 17790
    },
    {
      "epoch": 0.39555555555555555,
      "grad_norm": 0.06565788388252258,
      "learning_rate": 4.011111111111111e-05,
      "loss": 0.0026,
      "step": 17800
    },
    {
      "epoch": 0.3957777777777778,
      "grad_norm": 0.4039875268936157,
      "learning_rate": 4.0105555555555555e-05,
      "loss": 0.0024,
      "step": 17810
    },
    {
      "epoch": 0.396,
      "grad_norm": 0.2321322113275528,
      "learning_rate": 4.0100000000000006e-05,
      "loss": 0.0021,
      "step": 17820
    },
    {
      "epoch": 0.3962222222222222,
      "grad_norm": 0.5304480195045471,
      "learning_rate": 4.009444444444444e-05,
      "loss": 0.0028,
      "step": 17830
    },
    {
      "epoch": 0.39644444444444443,
      "grad_norm": 0.14189203083515167,
      "learning_rate": 4.008888888888889e-05,
      "loss": 0.0021,
      "step": 17840
    },
    {
      "epoch": 0.39666666666666667,
      "grad_norm": 0.08711566776037216,
      "learning_rate": 4.0083333333333336e-05,
      "loss": 0.0028,
      "step": 17850
    },
    {
      "epoch": 0.3968888888888889,
      "grad_norm": 0.16044816374778748,
      "learning_rate": 4.007777777777778e-05,
      "loss": 0.0035,
      "step": 17860
    },
    {
      "epoch": 0.39711111111111114,
      "grad_norm": 0.30009689927101135,
      "learning_rate": 4.0072222222222223e-05,
      "loss": 0.0025,
      "step": 17870
    },
    {
      "epoch": 0.3973333333333333,
      "grad_norm": 0.16967438161373138,
      "learning_rate": 4.006666666666667e-05,
      "loss": 0.0027,
      "step": 17880
    },
    {
      "epoch": 0.39755555555555555,
      "grad_norm": 0.309391587972641,
      "learning_rate": 4.006111111111111e-05,
      "loss": 0.003,
      "step": 17890
    },
    {
      "epoch": 0.3977777777777778,
      "grad_norm": 0.07488220185041428,
      "learning_rate": 4.0055555555555554e-05,
      "loss": 0.0021,
      "step": 17900
    },
    {
      "epoch": 0.398,
      "grad_norm": 0.4657379686832428,
      "learning_rate": 4.0050000000000004e-05,
      "loss": 0.002,
      "step": 17910
    },
    {
      "epoch": 0.3982222222222222,
      "grad_norm": 0.09601707756519318,
      "learning_rate": 4.004444444444445e-05,
      "loss": 0.0025,
      "step": 17920
    },
    {
      "epoch": 0.39844444444444443,
      "grad_norm": 0.14506010711193085,
      "learning_rate": 4.003888888888889e-05,
      "loss": 0.0025,
      "step": 17930
    },
    {
      "epoch": 0.39866666666666667,
      "grad_norm": 0.2823210656642914,
      "learning_rate": 4.0033333333333335e-05,
      "loss": 0.0023,
      "step": 17940
    },
    {
      "epoch": 0.3988888888888889,
      "grad_norm": 0.1203351616859436,
      "learning_rate": 4.002777777777778e-05,
      "loss": 0.002,
      "step": 17950
    },
    {
      "epoch": 0.39911111111111114,
      "grad_norm": 0.378732293844223,
      "learning_rate": 4.002222222222222e-05,
      "loss": 0.003,
      "step": 17960
    },
    {
      "epoch": 0.3993333333333333,
      "grad_norm": 0.30976933240890503,
      "learning_rate": 4.0016666666666666e-05,
      "loss": 0.003,
      "step": 17970
    },
    {
      "epoch": 0.39955555555555555,
      "grad_norm": 0.16466674208641052,
      "learning_rate": 4.001111111111111e-05,
      "loss": 0.0029,
      "step": 17980
    },
    {
      "epoch": 0.3997777777777778,
      "grad_norm": 0.12082327902317047,
      "learning_rate": 4.000555555555556e-05,
      "loss": 0.0022,
      "step": 17990
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.478895366191864,
      "learning_rate": 4e-05,
      "loss": 0.0022,
      "step": 18000
    },
    {
      "epoch": 0.4002222222222222,
      "grad_norm": 0.6352287530899048,
      "learning_rate": 3.999444444444445e-05,
      "loss": 0.002,
      "step": 18010
    },
    {
      "epoch": 0.40044444444444444,
      "grad_norm": 0.38291430473327637,
      "learning_rate": 3.998888888888889e-05,
      "loss": 0.0019,
      "step": 18020
    },
    {
      "epoch": 0.40066666666666667,
      "grad_norm": 0.09739252924919128,
      "learning_rate": 3.9983333333333334e-05,
      "loss": 0.0021,
      "step": 18030
    },
    {
      "epoch": 0.4008888888888889,
      "grad_norm": 0.1561943143606186,
      "learning_rate": 3.997777777777778e-05,
      "loss": 0.004,
      "step": 18040
    },
    {
      "epoch": 0.4011111111111111,
      "grad_norm": 0.309408038854599,
      "learning_rate": 3.997222222222222e-05,
      "loss": 0.0026,
      "step": 18050
    },
    {
      "epoch": 0.4013333333333333,
      "grad_norm": 0.07927841693162918,
      "learning_rate": 3.996666666666667e-05,
      "loss": 0.0023,
      "step": 18060
    },
    {
      "epoch": 0.40155555555555555,
      "grad_norm": 0.21891778707504272,
      "learning_rate": 3.996111111111111e-05,
      "loss": 0.0024,
      "step": 18070
    },
    {
      "epoch": 0.4017777777777778,
      "grad_norm": 0.7638088464736938,
      "learning_rate": 3.995555555555556e-05,
      "loss": 0.0023,
      "step": 18080
    },
    {
      "epoch": 0.402,
      "grad_norm": 0.15345101058483124,
      "learning_rate": 3.995e-05,
      "loss": 0.0022,
      "step": 18090
    },
    {
      "epoch": 0.4022222222222222,
      "grad_norm": 0.2811986207962036,
      "learning_rate": 3.9944444444444446e-05,
      "loss": 0.0019,
      "step": 18100
    },
    {
      "epoch": 0.40244444444444444,
      "grad_norm": 0.4678936302661896,
      "learning_rate": 3.993888888888889e-05,
      "loss": 0.0026,
      "step": 18110
    },
    {
      "epoch": 0.4026666666666667,
      "grad_norm": 0.2542388141155243,
      "learning_rate": 3.993333333333333e-05,
      "loss": 0.0041,
      "step": 18120
    },
    {
      "epoch": 0.4028888888888889,
      "grad_norm": 0.2257712483406067,
      "learning_rate": 3.992777777777778e-05,
      "loss": 0.0021,
      "step": 18130
    },
    {
      "epoch": 0.4031111111111111,
      "grad_norm": 0.13674286007881165,
      "learning_rate": 3.992222222222222e-05,
      "loss": 0.0027,
      "step": 18140
    },
    {
      "epoch": 0.4033333333333333,
      "grad_norm": 0.21418927609920502,
      "learning_rate": 3.991666666666667e-05,
      "loss": 0.0017,
      "step": 18150
    },
    {
      "epoch": 0.40355555555555556,
      "grad_norm": 0.6538528203964233,
      "learning_rate": 3.9911111111111114e-05,
      "loss": 0.003,
      "step": 18160
    },
    {
      "epoch": 0.4037777777777778,
      "grad_norm": 0.33699023723602295,
      "learning_rate": 3.990555555555556e-05,
      "loss": 0.0027,
      "step": 18170
    },
    {
      "epoch": 0.404,
      "grad_norm": 0.16709552705287933,
      "learning_rate": 3.99e-05,
      "loss": 0.0019,
      "step": 18180
    },
    {
      "epoch": 0.4042222222222222,
      "grad_norm": 0.28310516476631165,
      "learning_rate": 3.9894444444444444e-05,
      "loss": 0.0024,
      "step": 18190
    },
    {
      "epoch": 0.40444444444444444,
      "grad_norm": 0.10616111010313034,
      "learning_rate": 3.9888888888888895e-05,
      "loss": 0.0026,
      "step": 18200
    },
    {
      "epoch": 0.4046666666666667,
      "grad_norm": 0.055561408400535583,
      "learning_rate": 3.988333333333333e-05,
      "loss": 0.0019,
      "step": 18210
    },
    {
      "epoch": 0.4048888888888889,
      "grad_norm": 0.06472142040729523,
      "learning_rate": 3.987777777777778e-05,
      "loss": 0.0019,
      "step": 18220
    },
    {
      "epoch": 0.4051111111111111,
      "grad_norm": 0.15770576894283295,
      "learning_rate": 3.987222222222222e-05,
      "loss": 0.0024,
      "step": 18230
    },
    {
      "epoch": 0.4053333333333333,
      "grad_norm": 0.30955561995506287,
      "learning_rate": 3.986666666666667e-05,
      "loss": 0.0018,
      "step": 18240
    },
    {
      "epoch": 0.40555555555555556,
      "grad_norm": 0.0894857719540596,
      "learning_rate": 3.986111111111111e-05,
      "loss": 0.0026,
      "step": 18250
    },
    {
      "epoch": 0.4057777777777778,
      "grad_norm": 0.18972527980804443,
      "learning_rate": 3.9855555555555556e-05,
      "loss": 0.0026,
      "step": 18260
    },
    {
      "epoch": 0.406,
      "grad_norm": 0.3086355924606323,
      "learning_rate": 3.9850000000000006e-05,
      "loss": 0.003,
      "step": 18270
    },
    {
      "epoch": 0.4062222222222222,
      "grad_norm": 0.29175999760627747,
      "learning_rate": 3.984444444444444e-05,
      "loss": 0.0017,
      "step": 18280
    },
    {
      "epoch": 0.40644444444444444,
      "grad_norm": 0.5866427421569824,
      "learning_rate": 3.9838888888888894e-05,
      "loss": 0.0021,
      "step": 18290
    },
    {
      "epoch": 0.4066666666666667,
      "grad_norm": 0.07864005118608475,
      "learning_rate": 3.983333333333333e-05,
      "loss": 0.0024,
      "step": 18300
    },
    {
      "epoch": 0.4068888888888889,
      "grad_norm": 0.25912511348724365,
      "learning_rate": 3.982777777777778e-05,
      "loss": 0.0026,
      "step": 18310
    },
    {
      "epoch": 0.4071111111111111,
      "grad_norm": 0.5585376620292664,
      "learning_rate": 3.9822222222222224e-05,
      "loss": 0.0021,
      "step": 18320
    },
    {
      "epoch": 0.4073333333333333,
      "grad_norm": 0.18109039962291718,
      "learning_rate": 3.981666666666667e-05,
      "loss": 0.0018,
      "step": 18330
    },
    {
      "epoch": 0.40755555555555556,
      "grad_norm": 0.11969826370477676,
      "learning_rate": 3.981111111111112e-05,
      "loss": 0.0023,
      "step": 18340
    },
    {
      "epoch": 0.4077777777777778,
      "grad_norm": 0.3960236608982086,
      "learning_rate": 3.9805555555555555e-05,
      "loss": 0.0032,
      "step": 18350
    },
    {
      "epoch": 0.408,
      "grad_norm": 0.336159884929657,
      "learning_rate": 3.9800000000000005e-05,
      "loss": 0.0018,
      "step": 18360
    },
    {
      "epoch": 0.4082222222222222,
      "grad_norm": 0.2995055615901947,
      "learning_rate": 3.979444444444444e-05,
      "loss": 0.003,
      "step": 18370
    },
    {
      "epoch": 0.40844444444444444,
      "grad_norm": 0.275555282831192,
      "learning_rate": 3.978888888888889e-05,
      "loss": 0.0019,
      "step": 18380
    },
    {
      "epoch": 0.4086666666666667,
      "grad_norm": 0.7237882018089294,
      "learning_rate": 3.9783333333333336e-05,
      "loss": 0.0027,
      "step": 18390
    },
    {
      "epoch": 0.4088888888888889,
      "grad_norm": 0.15126153826713562,
      "learning_rate": 3.977777777777778e-05,
      "loss": 0.0019,
      "step": 18400
    },
    {
      "epoch": 0.4091111111111111,
      "grad_norm": 0.12173371016979218,
      "learning_rate": 3.977222222222222e-05,
      "loss": 0.0032,
      "step": 18410
    },
    {
      "epoch": 0.4093333333333333,
      "grad_norm": 0.11836248636245728,
      "learning_rate": 3.9766666666666667e-05,
      "loss": 0.0025,
      "step": 18420
    },
    {
      "epoch": 0.40955555555555556,
      "grad_norm": 0.3802339434623718,
      "learning_rate": 3.976111111111112e-05,
      "loss": 0.0022,
      "step": 18430
    },
    {
      "epoch": 0.4097777777777778,
      "grad_norm": 0.17936380207538605,
      "learning_rate": 3.9755555555555554e-05,
      "loss": 0.0021,
      "step": 18440
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.48324885964393616,
      "learning_rate": 3.9750000000000004e-05,
      "loss": 0.0016,
      "step": 18450
    },
    {
      "epoch": 0.4102222222222222,
      "grad_norm": 0.2991507947444916,
      "learning_rate": 3.974444444444445e-05,
      "loss": 0.0036,
      "step": 18460
    },
    {
      "epoch": 0.41044444444444445,
      "grad_norm": 0.07016030699014664,
      "learning_rate": 3.973888888888889e-05,
      "loss": 0.0022,
      "step": 18470
    },
    {
      "epoch": 0.4106666666666667,
      "grad_norm": 0.16621892154216766,
      "learning_rate": 3.9733333333333335e-05,
      "loss": 0.0023,
      "step": 18480
    },
    {
      "epoch": 0.4108888888888889,
      "grad_norm": 0.5646471977233887,
      "learning_rate": 3.972777777777778e-05,
      "loss": 0.0034,
      "step": 18490
    },
    {
      "epoch": 0.4111111111111111,
      "grad_norm": 0.45819076895713806,
      "learning_rate": 3.972222222222222e-05,
      "loss": 0.002,
      "step": 18500
    },
    {
      "epoch": 0.41133333333333333,
      "grad_norm": 0.5565257668495178,
      "learning_rate": 3.9716666666666665e-05,
      "loss": 0.0021,
      "step": 18510
    },
    {
      "epoch": 0.41155555555555556,
      "grad_norm": 0.1849043220281601,
      "learning_rate": 3.9711111111111116e-05,
      "loss": 0.0022,
      "step": 18520
    },
    {
      "epoch": 0.4117777777777778,
      "grad_norm": 0.1288040429353714,
      "learning_rate": 3.970555555555556e-05,
      "loss": 0.0023,
      "step": 18530
    },
    {
      "epoch": 0.412,
      "grad_norm": 0.1553652435541153,
      "learning_rate": 3.97e-05,
      "loss": 0.0021,
      "step": 18540
    },
    {
      "epoch": 0.4122222222222222,
      "grad_norm": 0.08041154593229294,
      "learning_rate": 3.9694444444444446e-05,
      "loss": 0.0044,
      "step": 18550
    },
    {
      "epoch": 0.41244444444444445,
      "grad_norm": 0.24243423342704773,
      "learning_rate": 3.968888888888889e-05,
      "loss": 0.0019,
      "step": 18560
    },
    {
      "epoch": 0.4126666666666667,
      "grad_norm": 0.1135668233036995,
      "learning_rate": 3.9683333333333333e-05,
      "loss": 0.0022,
      "step": 18570
    },
    {
      "epoch": 0.4128888888888889,
      "grad_norm": 0.06725477427244186,
      "learning_rate": 3.9677777777777784e-05,
      "loss": 0.0021,
      "step": 18580
    },
    {
      "epoch": 0.4131111111111111,
      "grad_norm": 0.10633005201816559,
      "learning_rate": 3.967222222222222e-05,
      "loss": 0.0023,
      "step": 18590
    },
    {
      "epoch": 0.41333333333333333,
      "grad_norm": 0.12410933524370193,
      "learning_rate": 3.966666666666667e-05,
      "loss": 0.0025,
      "step": 18600
    },
    {
      "epoch": 0.41355555555555557,
      "grad_norm": 0.05766672641038895,
      "learning_rate": 3.9661111111111114e-05,
      "loss": 0.0041,
      "step": 18610
    },
    {
      "epoch": 0.4137777777777778,
      "grad_norm": 0.3655925691127777,
      "learning_rate": 3.965555555555556e-05,
      "loss": 0.0027,
      "step": 18620
    },
    {
      "epoch": 0.414,
      "grad_norm": 0.3296140730381012,
      "learning_rate": 3.965e-05,
      "loss": 0.0024,
      "step": 18630
    },
    {
      "epoch": 0.4142222222222222,
      "grad_norm": 0.5026109218597412,
      "learning_rate": 3.9644444444444445e-05,
      "loss": 0.0024,
      "step": 18640
    },
    {
      "epoch": 0.41444444444444445,
      "grad_norm": 0.08640370517969131,
      "learning_rate": 3.9638888888888895e-05,
      "loss": 0.0021,
      "step": 18650
    },
    {
      "epoch": 0.4146666666666667,
      "grad_norm": 0.12250475585460663,
      "learning_rate": 3.963333333333333e-05,
      "loss": 0.0022,
      "step": 18660
    },
    {
      "epoch": 0.41488888888888886,
      "grad_norm": 0.3980516493320465,
      "learning_rate": 3.962777777777778e-05,
      "loss": 0.0019,
      "step": 18670
    },
    {
      "epoch": 0.4151111111111111,
      "grad_norm": 0.15043793618679047,
      "learning_rate": 3.962222222222222e-05,
      "loss": 0.0037,
      "step": 18680
    },
    {
      "epoch": 0.41533333333333333,
      "grad_norm": 0.3745482563972473,
      "learning_rate": 3.961666666666667e-05,
      "loss": 0.0026,
      "step": 18690
    },
    {
      "epoch": 0.41555555555555557,
      "grad_norm": 0.6227221488952637,
      "learning_rate": 3.961111111111111e-05,
      "loss": 0.0029,
      "step": 18700
    },
    {
      "epoch": 0.4157777777777778,
      "grad_norm": 0.11339451372623444,
      "learning_rate": 3.960555555555556e-05,
      "loss": 0.0025,
      "step": 18710
    },
    {
      "epoch": 0.416,
      "grad_norm": 0.14261877536773682,
      "learning_rate": 3.960000000000001e-05,
      "loss": 0.0024,
      "step": 18720
    },
    {
      "epoch": 0.4162222222222222,
      "grad_norm": 0.4062615931034088,
      "learning_rate": 3.9594444444444444e-05,
      "loss": 0.0027,
      "step": 18730
    },
    {
      "epoch": 0.41644444444444445,
      "grad_norm": 0.44865259528160095,
      "learning_rate": 3.9588888888888894e-05,
      "loss": 0.0022,
      "step": 18740
    },
    {
      "epoch": 0.4166666666666667,
      "grad_norm": 0.20047736167907715,
      "learning_rate": 3.958333333333333e-05,
      "loss": 0.0017,
      "step": 18750
    },
    {
      "epoch": 0.41688888888888886,
      "grad_norm": 0.523885190486908,
      "learning_rate": 3.957777777777778e-05,
      "loss": 0.0022,
      "step": 18760
    },
    {
      "epoch": 0.4171111111111111,
      "grad_norm": 0.06424596160650253,
      "learning_rate": 3.9572222222222225e-05,
      "loss": 0.0017,
      "step": 18770
    },
    {
      "epoch": 0.41733333333333333,
      "grad_norm": 0.24715159833431244,
      "learning_rate": 3.956666666666667e-05,
      "loss": 0.0021,
      "step": 18780
    },
    {
      "epoch": 0.41755555555555557,
      "grad_norm": 0.4264511466026306,
      "learning_rate": 3.956111111111112e-05,
      "loss": 0.0025,
      "step": 18790
    },
    {
      "epoch": 0.4177777777777778,
      "grad_norm": 0.35526371002197266,
      "learning_rate": 3.9555555555555556e-05,
      "loss": 0.0028,
      "step": 18800
    },
    {
      "epoch": 0.418,
      "grad_norm": 0.3778313100337982,
      "learning_rate": 3.9550000000000006e-05,
      "loss": 0.0031,
      "step": 18810
    },
    {
      "epoch": 0.4182222222222222,
      "grad_norm": 0.6234320402145386,
      "learning_rate": 3.954444444444444e-05,
      "loss": 0.0025,
      "step": 18820
    },
    {
      "epoch": 0.41844444444444445,
      "grad_norm": 0.29450634121894836,
      "learning_rate": 3.953888888888889e-05,
      "loss": 0.0024,
      "step": 18830
    },
    {
      "epoch": 0.4186666666666667,
      "grad_norm": 0.2123967856168747,
      "learning_rate": 3.9533333333333337e-05,
      "loss": 0.0027,
      "step": 18840
    },
    {
      "epoch": 0.41888888888888887,
      "grad_norm": 0.35220572352409363,
      "learning_rate": 3.952777777777778e-05,
      "loss": 0.0021,
      "step": 18850
    },
    {
      "epoch": 0.4191111111111111,
      "grad_norm": 0.0608762763440609,
      "learning_rate": 3.9522222222222224e-05,
      "loss": 0.0026,
      "step": 18860
    },
    {
      "epoch": 0.41933333333333334,
      "grad_norm": 0.4965721070766449,
      "learning_rate": 3.951666666666667e-05,
      "loss": 0.0021,
      "step": 18870
    },
    {
      "epoch": 0.41955555555555557,
      "grad_norm": 0.19979619979858398,
      "learning_rate": 3.951111111111112e-05,
      "loss": 0.0031,
      "step": 18880
    },
    {
      "epoch": 0.4197777777777778,
      "grad_norm": 0.19816024601459503,
      "learning_rate": 3.9505555555555554e-05,
      "loss": 0.0019,
      "step": 18890
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.20743410289287567,
      "learning_rate": 3.9500000000000005e-05,
      "loss": 0.0032,
      "step": 18900
    },
    {
      "epoch": 0.4202222222222222,
      "grad_norm": 0.25158247351646423,
      "learning_rate": 3.949444444444445e-05,
      "loss": 0.0021,
      "step": 18910
    },
    {
      "epoch": 0.42044444444444445,
      "grad_norm": 0.12602300941944122,
      "learning_rate": 3.948888888888889e-05,
      "loss": 0.0019,
      "step": 18920
    },
    {
      "epoch": 0.4206666666666667,
      "grad_norm": 0.5798454880714417,
      "learning_rate": 3.9483333333333335e-05,
      "loss": 0.0027,
      "step": 18930
    },
    {
      "epoch": 0.42088888888888887,
      "grad_norm": 0.34998512268066406,
      "learning_rate": 3.947777777777778e-05,
      "loss": 0.0038,
      "step": 18940
    },
    {
      "epoch": 0.4211111111111111,
      "grad_norm": 0.447271466255188,
      "learning_rate": 3.947222222222222e-05,
      "loss": 0.0031,
      "step": 18950
    },
    {
      "epoch": 0.42133333333333334,
      "grad_norm": 0.13149341940879822,
      "learning_rate": 3.9466666666666666e-05,
      "loss": 0.0023,
      "step": 18960
    },
    {
      "epoch": 0.42155555555555557,
      "grad_norm": 0.5655127763748169,
      "learning_rate": 3.9461111111111116e-05,
      "loss": 0.0029,
      "step": 18970
    },
    {
      "epoch": 0.42177777777777775,
      "grad_norm": 0.3047195076942444,
      "learning_rate": 3.945555555555556e-05,
      "loss": 0.0021,
      "step": 18980
    },
    {
      "epoch": 0.422,
      "grad_norm": 0.5117761492729187,
      "learning_rate": 3.9450000000000003e-05,
      "loss": 0.002,
      "step": 18990
    },
    {
      "epoch": 0.4222222222222222,
      "grad_norm": 0.15568013489246368,
      "learning_rate": 3.944444444444445e-05,
      "loss": 0.0021,
      "step": 19000
    },
    {
      "epoch": 0.42244444444444446,
      "grad_norm": 0.44532090425491333,
      "learning_rate": 3.943888888888889e-05,
      "loss": 0.0018,
      "step": 19010
    },
    {
      "epoch": 0.4226666666666667,
      "grad_norm": 0.5023950338363647,
      "learning_rate": 3.9433333333333334e-05,
      "loss": 0.002,
      "step": 19020
    },
    {
      "epoch": 0.42288888888888887,
      "grad_norm": 0.7029579877853394,
      "learning_rate": 3.942777777777778e-05,
      "loss": 0.003,
      "step": 19030
    },
    {
      "epoch": 0.4231111111111111,
      "grad_norm": 0.0919441282749176,
      "learning_rate": 3.942222222222222e-05,
      "loss": 0.0026,
      "step": 19040
    },
    {
      "epoch": 0.42333333333333334,
      "grad_norm": 0.4338313639163971,
      "learning_rate": 3.941666666666667e-05,
      "loss": 0.002,
      "step": 19050
    },
    {
      "epoch": 0.4235555555555556,
      "grad_norm": 0.12555725872516632,
      "learning_rate": 3.9411111111111115e-05,
      "loss": 0.0021,
      "step": 19060
    },
    {
      "epoch": 0.42377777777777775,
      "grad_norm": 0.3088790476322174,
      "learning_rate": 3.940555555555556e-05,
      "loss": 0.0026,
      "step": 19070
    },
    {
      "epoch": 0.424,
      "grad_norm": 0.15791475772857666,
      "learning_rate": 3.94e-05,
      "loss": 0.0017,
      "step": 19080
    },
    {
      "epoch": 0.4242222222222222,
      "grad_norm": 0.4360581338405609,
      "learning_rate": 3.9394444444444446e-05,
      "loss": 0.0019,
      "step": 19090
    },
    {
      "epoch": 0.42444444444444446,
      "grad_norm": 0.20571404695510864,
      "learning_rate": 3.938888888888889e-05,
      "loss": 0.0025,
      "step": 19100
    },
    {
      "epoch": 0.4246666666666667,
      "grad_norm": 0.10426449775695801,
      "learning_rate": 3.938333333333333e-05,
      "loss": 0.0026,
      "step": 19110
    },
    {
      "epoch": 0.42488888888888887,
      "grad_norm": 0.41035595536231995,
      "learning_rate": 3.937777777777778e-05,
      "loss": 0.0021,
      "step": 19120
    },
    {
      "epoch": 0.4251111111111111,
      "grad_norm": 0.10937593132257462,
      "learning_rate": 3.937222222222222e-05,
      "loss": 0.0026,
      "step": 19130
    },
    {
      "epoch": 0.42533333333333334,
      "grad_norm": 0.5438326001167297,
      "learning_rate": 3.936666666666667e-05,
      "loss": 0.0032,
      "step": 19140
    },
    {
      "epoch": 0.4255555555555556,
      "grad_norm": 0.0994490459561348,
      "learning_rate": 3.9361111111111114e-05,
      "loss": 0.0018,
      "step": 19150
    },
    {
      "epoch": 0.42577777777777776,
      "grad_norm": 0.12570062279701233,
      "learning_rate": 3.935555555555556e-05,
      "loss": 0.0022,
      "step": 19160
    },
    {
      "epoch": 0.426,
      "grad_norm": 0.30092012882232666,
      "learning_rate": 3.935e-05,
      "loss": 0.0023,
      "step": 19170
    },
    {
      "epoch": 0.4262222222222222,
      "grad_norm": 0.10429627448320389,
      "learning_rate": 3.9344444444444445e-05,
      "loss": 0.0021,
      "step": 19180
    },
    {
      "epoch": 0.42644444444444446,
      "grad_norm": 0.16930758953094482,
      "learning_rate": 3.9338888888888895e-05,
      "loss": 0.0022,
      "step": 19190
    },
    {
      "epoch": 0.4266666666666667,
      "grad_norm": 0.6642423272132874,
      "learning_rate": 3.933333333333333e-05,
      "loss": 0.0025,
      "step": 19200
    },
    {
      "epoch": 0.4268888888888889,
      "grad_norm": 0.3930743336677551,
      "learning_rate": 3.932777777777778e-05,
      "loss": 0.0023,
      "step": 19210
    },
    {
      "epoch": 0.4271111111111111,
      "grad_norm": 0.40773192048072815,
      "learning_rate": 3.932222222222222e-05,
      "loss": 0.0024,
      "step": 19220
    },
    {
      "epoch": 0.42733333333333334,
      "grad_norm": 0.3668869137763977,
      "learning_rate": 3.931666666666667e-05,
      "loss": 0.0024,
      "step": 19230
    },
    {
      "epoch": 0.4275555555555556,
      "grad_norm": 0.3638964295387268,
      "learning_rate": 3.931111111111111e-05,
      "loss": 0.0035,
      "step": 19240
    },
    {
      "epoch": 0.42777777777777776,
      "grad_norm": 0.07704447954893112,
      "learning_rate": 3.9305555555555556e-05,
      "loss": 0.002,
      "step": 19250
    },
    {
      "epoch": 0.428,
      "grad_norm": 0.11467186361551285,
      "learning_rate": 3.9300000000000007e-05,
      "loss": 0.0023,
      "step": 19260
    },
    {
      "epoch": 0.4282222222222222,
      "grad_norm": 0.25669047236442566,
      "learning_rate": 3.929444444444444e-05,
      "loss": 0.0024,
      "step": 19270
    },
    {
      "epoch": 0.42844444444444446,
      "grad_norm": 0.32864680886268616,
      "learning_rate": 3.9288888888888894e-05,
      "loss": 0.0022,
      "step": 19280
    },
    {
      "epoch": 0.42866666666666664,
      "grad_norm": 0.4030601382255554,
      "learning_rate": 3.928333333333333e-05,
      "loss": 0.0021,
      "step": 19290
    },
    {
      "epoch": 0.4288888888888889,
      "grad_norm": 0.1813412457704544,
      "learning_rate": 3.927777777777778e-05,
      "loss": 0.0027,
      "step": 19300
    },
    {
      "epoch": 0.4291111111111111,
      "grad_norm": 0.326251357793808,
      "learning_rate": 3.9272222222222224e-05,
      "loss": 0.0019,
      "step": 19310
    },
    {
      "epoch": 0.42933333333333334,
      "grad_norm": 0.07035200297832489,
      "learning_rate": 3.926666666666667e-05,
      "loss": 0.0034,
      "step": 19320
    },
    {
      "epoch": 0.4295555555555556,
      "grad_norm": 0.3984963893890381,
      "learning_rate": 3.926111111111112e-05,
      "loss": 0.0021,
      "step": 19330
    },
    {
      "epoch": 0.42977777777777776,
      "grad_norm": 0.28075629472732544,
      "learning_rate": 3.9255555555555555e-05,
      "loss": 0.0021,
      "step": 19340
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.2760254144668579,
      "learning_rate": 3.9250000000000005e-05,
      "loss": 0.0032,
      "step": 19350
    },
    {
      "epoch": 0.43022222222222223,
      "grad_norm": 0.10476405918598175,
      "learning_rate": 3.924444444444444e-05,
      "loss": 0.0025,
      "step": 19360
    },
    {
      "epoch": 0.43044444444444446,
      "grad_norm": 0.5272902250289917,
      "learning_rate": 3.923888888888889e-05,
      "loss": 0.002,
      "step": 19370
    },
    {
      "epoch": 0.43066666666666664,
      "grad_norm": 0.18188168108463287,
      "learning_rate": 3.9233333333333336e-05,
      "loss": 0.0023,
      "step": 19380
    },
    {
      "epoch": 0.4308888888888889,
      "grad_norm": 0.3615071773529053,
      "learning_rate": 3.922777777777778e-05,
      "loss": 0.0038,
      "step": 19390
    },
    {
      "epoch": 0.4311111111111111,
      "grad_norm": 0.17428453266620636,
      "learning_rate": 3.922222222222223e-05,
      "loss": 0.0026,
      "step": 19400
    },
    {
      "epoch": 0.43133333333333335,
      "grad_norm": 0.36034220457077026,
      "learning_rate": 3.921666666666667e-05,
      "loss": 0.0024,
      "step": 19410
    },
    {
      "epoch": 0.4315555555555556,
      "grad_norm": 0.1358690708875656,
      "learning_rate": 3.921111111111112e-05,
      "loss": 0.0024,
      "step": 19420
    },
    {
      "epoch": 0.43177777777777776,
      "grad_norm": 0.14626246690750122,
      "learning_rate": 3.9205555555555554e-05,
      "loss": 0.0028,
      "step": 19430
    },
    {
      "epoch": 0.432,
      "grad_norm": 0.15359719097614288,
      "learning_rate": 3.9200000000000004e-05,
      "loss": 0.0023,
      "step": 19440
    },
    {
      "epoch": 0.43222222222222223,
      "grad_norm": 0.15425661206245422,
      "learning_rate": 3.919444444444445e-05,
      "loss": 0.0023,
      "step": 19450
    },
    {
      "epoch": 0.43244444444444446,
      "grad_norm": 0.2174934446811676,
      "learning_rate": 3.918888888888889e-05,
      "loss": 0.0027,
      "step": 19460
    },
    {
      "epoch": 0.43266666666666664,
      "grad_norm": 0.49278876185417175,
      "learning_rate": 3.9183333333333335e-05,
      "loss": 0.003,
      "step": 19470
    },
    {
      "epoch": 0.4328888888888889,
      "grad_norm": 0.34435808658599854,
      "learning_rate": 3.917777777777778e-05,
      "loss": 0.0033,
      "step": 19480
    },
    {
      "epoch": 0.4331111111111111,
      "grad_norm": 0.5019506812095642,
      "learning_rate": 3.917222222222223e-05,
      "loss": 0.003,
      "step": 19490
    },
    {
      "epoch": 0.43333333333333335,
      "grad_norm": 0.12158378213644028,
      "learning_rate": 3.9166666666666665e-05,
      "loss": 0.0021,
      "step": 19500
    },
    {
      "epoch": 0.4335555555555556,
      "grad_norm": 0.12718012928962708,
      "learning_rate": 3.9161111111111116e-05,
      "loss": 0.002,
      "step": 19510
    },
    {
      "epoch": 0.43377777777777776,
      "grad_norm": 0.49427178502082825,
      "learning_rate": 3.915555555555556e-05,
      "loss": 0.0024,
      "step": 19520
    },
    {
      "epoch": 0.434,
      "grad_norm": 0.6650200486183167,
      "learning_rate": 3.915e-05,
      "loss": 0.0027,
      "step": 19530
    },
    {
      "epoch": 0.43422222222222223,
      "grad_norm": 0.17786329984664917,
      "learning_rate": 3.9144444444444446e-05,
      "loss": 0.0022,
      "step": 19540
    },
    {
      "epoch": 0.43444444444444447,
      "grad_norm": 0.37463074922561646,
      "learning_rate": 3.913888888888889e-05,
      "loss": 0.0017,
      "step": 19550
    },
    {
      "epoch": 0.43466666666666665,
      "grad_norm": 0.3385704457759857,
      "learning_rate": 3.9133333333333334e-05,
      "loss": 0.0023,
      "step": 19560
    },
    {
      "epoch": 0.4348888888888889,
      "grad_norm": 0.30499833822250366,
      "learning_rate": 3.912777777777778e-05,
      "loss": 0.0031,
      "step": 19570
    },
    {
      "epoch": 0.4351111111111111,
      "grad_norm": 0.5450598001480103,
      "learning_rate": 3.912222222222223e-05,
      "loss": 0.0032,
      "step": 19580
    },
    {
      "epoch": 0.43533333333333335,
      "grad_norm": 0.11780676245689392,
      "learning_rate": 3.911666666666667e-05,
      "loss": 0.002,
      "step": 19590
    },
    {
      "epoch": 0.43555555555555553,
      "grad_norm": 0.07680519670248032,
      "learning_rate": 3.9111111111111115e-05,
      "loss": 0.0024,
      "step": 19600
    },
    {
      "epoch": 0.43577777777777776,
      "grad_norm": 0.18441089987754822,
      "learning_rate": 3.910555555555556e-05,
      "loss": 0.0017,
      "step": 19610
    },
    {
      "epoch": 0.436,
      "grad_norm": 0.46974703669548035,
      "learning_rate": 3.91e-05,
      "loss": 0.0035,
      "step": 19620
    },
    {
      "epoch": 0.43622222222222223,
      "grad_norm": 0.1330195665359497,
      "learning_rate": 3.9094444444444445e-05,
      "loss": 0.0029,
      "step": 19630
    },
    {
      "epoch": 0.43644444444444447,
      "grad_norm": 0.6056460738182068,
      "learning_rate": 3.908888888888889e-05,
      "loss": 0.0023,
      "step": 19640
    },
    {
      "epoch": 0.43666666666666665,
      "grad_norm": 0.09996076673269272,
      "learning_rate": 3.908333333333333e-05,
      "loss": 0.0023,
      "step": 19650
    },
    {
      "epoch": 0.4368888888888889,
      "grad_norm": 0.177109956741333,
      "learning_rate": 3.907777777777778e-05,
      "loss": 0.0019,
      "step": 19660
    },
    {
      "epoch": 0.4371111111111111,
      "grad_norm": 0.5905782580375671,
      "learning_rate": 3.9072222222222226e-05,
      "loss": 0.0025,
      "step": 19670
    },
    {
      "epoch": 0.43733333333333335,
      "grad_norm": 0.7150183320045471,
      "learning_rate": 3.906666666666667e-05,
      "loss": 0.0025,
      "step": 19680
    },
    {
      "epoch": 0.43755555555555553,
      "grad_norm": 0.650686502456665,
      "learning_rate": 3.9061111111111113e-05,
      "loss": 0.002,
      "step": 19690
    },
    {
      "epoch": 0.43777777777777777,
      "grad_norm": 0.44559594988822937,
      "learning_rate": 3.905555555555556e-05,
      "loss": 0.0027,
      "step": 19700
    },
    {
      "epoch": 0.438,
      "grad_norm": 0.13546550273895264,
      "learning_rate": 3.905e-05,
      "loss": 0.0032,
      "step": 19710
    },
    {
      "epoch": 0.43822222222222224,
      "grad_norm": 0.08073011785745621,
      "learning_rate": 3.9044444444444444e-05,
      "loss": 0.0041,
      "step": 19720
    },
    {
      "epoch": 0.43844444444444447,
      "grad_norm": 0.07477620244026184,
      "learning_rate": 3.9038888888888894e-05,
      "loss": 0.0024,
      "step": 19730
    },
    {
      "epoch": 0.43866666666666665,
      "grad_norm": 0.12217526137828827,
      "learning_rate": 3.903333333333333e-05,
      "loss": 0.0018,
      "step": 19740
    },
    {
      "epoch": 0.4388888888888889,
      "grad_norm": 0.851128101348877,
      "learning_rate": 3.902777777777778e-05,
      "loss": 0.002,
      "step": 19750
    },
    {
      "epoch": 0.4391111111111111,
      "grad_norm": 0.20145393908023834,
      "learning_rate": 3.9022222222222225e-05,
      "loss": 0.0028,
      "step": 19760
    },
    {
      "epoch": 0.43933333333333335,
      "grad_norm": 0.25372210144996643,
      "learning_rate": 3.901666666666667e-05,
      "loss": 0.0036,
      "step": 19770
    },
    {
      "epoch": 0.43955555555555553,
      "grad_norm": 0.4544002115726471,
      "learning_rate": 3.901111111111111e-05,
      "loss": 0.0027,
      "step": 19780
    },
    {
      "epoch": 0.43977777777777777,
      "grad_norm": 0.32040324807167053,
      "learning_rate": 3.9005555555555556e-05,
      "loss": 0.002,
      "step": 19790
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.07133735716342926,
      "learning_rate": 3.9000000000000006e-05,
      "loss": 0.0022,
      "step": 19800
    },
    {
      "epoch": 0.44022222222222224,
      "grad_norm": 0.1621694713830948,
      "learning_rate": 3.899444444444444e-05,
      "loss": 0.0023,
      "step": 19810
    },
    {
      "epoch": 0.44044444444444447,
      "grad_norm": 0.4525434374809265,
      "learning_rate": 3.898888888888889e-05,
      "loss": 0.0017,
      "step": 19820
    },
    {
      "epoch": 0.44066666666666665,
      "grad_norm": 0.09216991066932678,
      "learning_rate": 3.898333333333333e-05,
      "loss": 0.0035,
      "step": 19830
    },
    {
      "epoch": 0.4408888888888889,
      "grad_norm": 0.3256835341453552,
      "learning_rate": 3.897777777777778e-05,
      "loss": 0.0017,
      "step": 19840
    },
    {
      "epoch": 0.4411111111111111,
      "grad_norm": 0.12769000232219696,
      "learning_rate": 3.8972222222222224e-05,
      "loss": 0.0032,
      "step": 19850
    },
    {
      "epoch": 0.44133333333333336,
      "grad_norm": 0.22256682813167572,
      "learning_rate": 3.896666666666667e-05,
      "loss": 0.0024,
      "step": 19860
    },
    {
      "epoch": 0.44155555555555553,
      "grad_norm": 0.384156197309494,
      "learning_rate": 3.896111111111112e-05,
      "loss": 0.0024,
      "step": 19870
    },
    {
      "epoch": 0.44177777777777777,
      "grad_norm": 0.11385197192430496,
      "learning_rate": 3.8955555555555555e-05,
      "loss": 0.0026,
      "step": 19880
    },
    {
      "epoch": 0.442,
      "grad_norm": 0.4268355369567871,
      "learning_rate": 3.8950000000000005e-05,
      "loss": 0.0034,
      "step": 19890
    },
    {
      "epoch": 0.44222222222222224,
      "grad_norm": 0.20690102875232697,
      "learning_rate": 3.894444444444444e-05,
      "loss": 0.0021,
      "step": 19900
    },
    {
      "epoch": 0.4424444444444444,
      "grad_norm": 0.32533860206604004,
      "learning_rate": 3.893888888888889e-05,
      "loss": 0.0025,
      "step": 19910
    },
    {
      "epoch": 0.44266666666666665,
      "grad_norm": 0.39766281843185425,
      "learning_rate": 3.8933333333333336e-05,
      "loss": 0.0023,
      "step": 19920
    },
    {
      "epoch": 0.4428888888888889,
      "grad_norm": 0.2583390772342682,
      "learning_rate": 3.892777777777778e-05,
      "loss": 0.0033,
      "step": 19930
    },
    {
      "epoch": 0.4431111111111111,
      "grad_norm": 0.7102461457252502,
      "learning_rate": 3.892222222222223e-05,
      "loss": 0.0032,
      "step": 19940
    },
    {
      "epoch": 0.44333333333333336,
      "grad_norm": 0.13899587094783783,
      "learning_rate": 3.8916666666666666e-05,
      "loss": 0.0022,
      "step": 19950
    },
    {
      "epoch": 0.44355555555555554,
      "grad_norm": 0.5166715979576111,
      "learning_rate": 3.8911111111111117e-05,
      "loss": 0.0026,
      "step": 19960
    },
    {
      "epoch": 0.44377777777777777,
      "grad_norm": 0.32750412821769714,
      "learning_rate": 3.890555555555555e-05,
      "loss": 0.0021,
      "step": 19970
    },
    {
      "epoch": 0.444,
      "grad_norm": 0.2405770868062973,
      "learning_rate": 3.8900000000000004e-05,
      "loss": 0.0034,
      "step": 19980
    },
    {
      "epoch": 0.44422222222222224,
      "grad_norm": 0.309739351272583,
      "learning_rate": 3.889444444444445e-05,
      "loss": 0.0019,
      "step": 19990
    },
    {
      "epoch": 0.4444444444444444,
      "grad_norm": 0.3697310984134674,
      "learning_rate": 3.888888888888889e-05,
      "loss": 0.0033,
      "step": 20000
    },
    {
      "epoch": 0.44466666666666665,
      "grad_norm": 0.5841736793518066,
      "learning_rate": 3.8883333333333334e-05,
      "loss": 0.0022,
      "step": 20010
    },
    {
      "epoch": 0.4448888888888889,
      "grad_norm": 0.27235519886016846,
      "learning_rate": 3.887777777777778e-05,
      "loss": 0.0019,
      "step": 20020
    },
    {
      "epoch": 0.4451111111111111,
      "grad_norm": 0.17868255078792572,
      "learning_rate": 3.887222222222223e-05,
      "loss": 0.0023,
      "step": 20030
    },
    {
      "epoch": 0.44533333333333336,
      "grad_norm": 0.48610466718673706,
      "learning_rate": 3.8866666666666665e-05,
      "loss": 0.0027,
      "step": 20040
    },
    {
      "epoch": 0.44555555555555554,
      "grad_norm": 0.11724215745925903,
      "learning_rate": 3.8861111111111115e-05,
      "loss": 0.0038,
      "step": 20050
    },
    {
      "epoch": 0.4457777777777778,
      "grad_norm": 0.16974304616451263,
      "learning_rate": 3.885555555555556e-05,
      "loss": 0.0027,
      "step": 20060
    },
    {
      "epoch": 0.446,
      "grad_norm": 0.2124561220407486,
      "learning_rate": 3.885e-05,
      "loss": 0.0025,
      "step": 20070
    },
    {
      "epoch": 0.44622222222222224,
      "grad_norm": 0.059921588748693466,
      "learning_rate": 3.8844444444444446e-05,
      "loss": 0.002,
      "step": 20080
    },
    {
      "epoch": 0.4464444444444444,
      "grad_norm": 0.2143768072128296,
      "learning_rate": 3.883888888888889e-05,
      "loss": 0.0022,
      "step": 20090
    },
    {
      "epoch": 0.44666666666666666,
      "grad_norm": 0.3536226153373718,
      "learning_rate": 3.883333333333333e-05,
      "loss": 0.0025,
      "step": 20100
    },
    {
      "epoch": 0.4468888888888889,
      "grad_norm": 0.34400373697280884,
      "learning_rate": 3.882777777777778e-05,
      "loss": 0.0021,
      "step": 20110
    },
    {
      "epoch": 0.4471111111111111,
      "grad_norm": 0.19368277490139008,
      "learning_rate": 3.882222222222223e-05,
      "loss": 0.0018,
      "step": 20120
    },
    {
      "epoch": 0.44733333333333336,
      "grad_norm": 0.3119572699069977,
      "learning_rate": 3.881666666666667e-05,
      "loss": 0.0024,
      "step": 20130
    },
    {
      "epoch": 0.44755555555555554,
      "grad_norm": 0.5278294086456299,
      "learning_rate": 3.8811111111111114e-05,
      "loss": 0.0021,
      "step": 20140
    },
    {
      "epoch": 0.4477777777777778,
      "grad_norm": 0.16503264009952545,
      "learning_rate": 3.880555555555556e-05,
      "loss": 0.0018,
      "step": 20150
    },
    {
      "epoch": 0.448,
      "grad_norm": 0.11002953350543976,
      "learning_rate": 3.88e-05,
      "loss": 0.0018,
      "step": 20160
    },
    {
      "epoch": 0.44822222222222224,
      "grad_norm": 0.17555534839630127,
      "learning_rate": 3.8794444444444445e-05,
      "loss": 0.0023,
      "step": 20170
    },
    {
      "epoch": 0.4484444444444444,
      "grad_norm": 0.270029217004776,
      "learning_rate": 3.878888888888889e-05,
      "loss": 0.0025,
      "step": 20180
    },
    {
      "epoch": 0.44866666666666666,
      "grad_norm": 0.45200517773628235,
      "learning_rate": 3.878333333333333e-05,
      "loss": 0.0019,
      "step": 20190
    },
    {
      "epoch": 0.4488888888888889,
      "grad_norm": 0.12210647761821747,
      "learning_rate": 3.877777777777778e-05,
      "loss": 0.002,
      "step": 20200
    },
    {
      "epoch": 0.4491111111111111,
      "grad_norm": 0.9095864295959473,
      "learning_rate": 3.8772222222222226e-05,
      "loss": 0.002,
      "step": 20210
    },
    {
      "epoch": 0.4493333333333333,
      "grad_norm": 0.2144751399755478,
      "learning_rate": 3.876666666666667e-05,
      "loss": 0.0027,
      "step": 20220
    },
    {
      "epoch": 0.44955555555555554,
      "grad_norm": 0.5719466209411621,
      "learning_rate": 3.876111111111111e-05,
      "loss": 0.0017,
      "step": 20230
    },
    {
      "epoch": 0.4497777777777778,
      "grad_norm": 0.09473232179880142,
      "learning_rate": 3.8755555555555556e-05,
      "loss": 0.0031,
      "step": 20240
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.24958597123622894,
      "learning_rate": 3.875e-05,
      "loss": 0.0017,
      "step": 20250
    },
    {
      "epoch": 0.45022222222222225,
      "grad_norm": 0.18018820881843567,
      "learning_rate": 3.8744444444444444e-05,
      "loss": 0.0022,
      "step": 20260
    },
    {
      "epoch": 0.4504444444444444,
      "grad_norm": 0.25086283683776855,
      "learning_rate": 3.8738888888888894e-05,
      "loss": 0.0024,
      "step": 20270
    },
    {
      "epoch": 0.45066666666666666,
      "grad_norm": 0.3087412416934967,
      "learning_rate": 3.873333333333333e-05,
      "loss": 0.0021,
      "step": 20280
    },
    {
      "epoch": 0.4508888888888889,
      "grad_norm": 0.7518524527549744,
      "learning_rate": 3.872777777777778e-05,
      "loss": 0.0023,
      "step": 20290
    },
    {
      "epoch": 0.45111111111111113,
      "grad_norm": 0.08650950342416763,
      "learning_rate": 3.8722222222222225e-05,
      "loss": 0.0027,
      "step": 20300
    },
    {
      "epoch": 0.4513333333333333,
      "grad_norm": 0.5645166635513306,
      "learning_rate": 3.871666666666667e-05,
      "loss": 0.0019,
      "step": 20310
    },
    {
      "epoch": 0.45155555555555554,
      "grad_norm": 0.07560912519693375,
      "learning_rate": 3.871111111111111e-05,
      "loss": 0.0022,
      "step": 20320
    },
    {
      "epoch": 0.4517777777777778,
      "grad_norm": 0.47503089904785156,
      "learning_rate": 3.8705555555555555e-05,
      "loss": 0.0021,
      "step": 20330
    },
    {
      "epoch": 0.452,
      "grad_norm": 0.18925254046916962,
      "learning_rate": 3.8700000000000006e-05,
      "loss": 0.0023,
      "step": 20340
    },
    {
      "epoch": 0.45222222222222225,
      "grad_norm": 0.05426369234919548,
      "learning_rate": 3.869444444444444e-05,
      "loss": 0.0019,
      "step": 20350
    },
    {
      "epoch": 0.4524444444444444,
      "grad_norm": 0.20593233406543732,
      "learning_rate": 3.868888888888889e-05,
      "loss": 0.0037,
      "step": 20360
    },
    {
      "epoch": 0.45266666666666666,
      "grad_norm": 0.26371482014656067,
      "learning_rate": 3.868333333333333e-05,
      "loss": 0.0022,
      "step": 20370
    },
    {
      "epoch": 0.4528888888888889,
      "grad_norm": 0.426095575094223,
      "learning_rate": 3.867777777777778e-05,
      "loss": 0.0023,
      "step": 20380
    },
    {
      "epoch": 0.45311111111111113,
      "grad_norm": 0.31611621379852295,
      "learning_rate": 3.867222222222222e-05,
      "loss": 0.0023,
      "step": 20390
    },
    {
      "epoch": 0.4533333333333333,
      "grad_norm": 0.36692503094673157,
      "learning_rate": 3.866666666666667e-05,
      "loss": 0.0032,
      "step": 20400
    },
    {
      "epoch": 0.45355555555555555,
      "grad_norm": 0.4149869680404663,
      "learning_rate": 3.866111111111112e-05,
      "loss": 0.0027,
      "step": 20410
    },
    {
      "epoch": 0.4537777777777778,
      "grad_norm": 0.6372742652893066,
      "learning_rate": 3.8655555555555554e-05,
      "loss": 0.0022,
      "step": 20420
    },
    {
      "epoch": 0.454,
      "grad_norm": 0.569939136505127,
      "learning_rate": 3.8650000000000004e-05,
      "loss": 0.0025,
      "step": 20430
    },
    {
      "epoch": 0.45422222222222225,
      "grad_norm": 0.09066867083311081,
      "learning_rate": 3.864444444444444e-05,
      "loss": 0.0021,
      "step": 20440
    },
    {
      "epoch": 0.45444444444444443,
      "grad_norm": 0.26582416892051697,
      "learning_rate": 3.863888888888889e-05,
      "loss": 0.0037,
      "step": 20450
    },
    {
      "epoch": 0.45466666666666666,
      "grad_norm": 0.22871938347816467,
      "learning_rate": 3.8633333333333335e-05,
      "loss": 0.0034,
      "step": 20460
    },
    {
      "epoch": 0.4548888888888889,
      "grad_norm": 0.40505483746528625,
      "learning_rate": 3.862777777777778e-05,
      "loss": 0.0019,
      "step": 20470
    },
    {
      "epoch": 0.45511111111111113,
      "grad_norm": 0.3993701636791229,
      "learning_rate": 3.862222222222223e-05,
      "loss": 0.0017,
      "step": 20480
    },
    {
      "epoch": 0.4553333333333333,
      "grad_norm": 0.12686598300933838,
      "learning_rate": 3.8616666666666666e-05,
      "loss": 0.0023,
      "step": 20490
    },
    {
      "epoch": 0.45555555555555555,
      "grad_norm": 0.15832243859767914,
      "learning_rate": 3.8611111111111116e-05,
      "loss": 0.0037,
      "step": 20500
    },
    {
      "epoch": 0.4557777777777778,
      "grad_norm": 0.5099989771842957,
      "learning_rate": 3.860555555555555e-05,
      "loss": 0.0024,
      "step": 20510
    },
    {
      "epoch": 0.456,
      "grad_norm": 0.4700279235839844,
      "learning_rate": 3.86e-05,
      "loss": 0.002,
      "step": 20520
    },
    {
      "epoch": 0.4562222222222222,
      "grad_norm": 0.11212513595819473,
      "learning_rate": 3.859444444444445e-05,
      "loss": 0.0021,
      "step": 20530
    },
    {
      "epoch": 0.45644444444444443,
      "grad_norm": 0.31075119972229004,
      "learning_rate": 3.858888888888889e-05,
      "loss": 0.0021,
      "step": 20540
    },
    {
      "epoch": 0.45666666666666667,
      "grad_norm": 0.0748160257935524,
      "learning_rate": 3.8583333333333334e-05,
      "loss": 0.0018,
      "step": 20550
    },
    {
      "epoch": 0.4568888888888889,
      "grad_norm": 0.08273076266050339,
      "learning_rate": 3.857777777777778e-05,
      "loss": 0.0028,
      "step": 20560
    },
    {
      "epoch": 0.45711111111111113,
      "grad_norm": 0.7650722861289978,
      "learning_rate": 3.857222222222223e-05,
      "loss": 0.0023,
      "step": 20570
    },
    {
      "epoch": 0.4573333333333333,
      "grad_norm": 0.22561942040920258,
      "learning_rate": 3.8566666666666664e-05,
      "loss": 0.0024,
      "step": 20580
    },
    {
      "epoch": 0.45755555555555555,
      "grad_norm": 0.1426636427640915,
      "learning_rate": 3.8561111111111115e-05,
      "loss": 0.0023,
      "step": 20590
    },
    {
      "epoch": 0.4577777777777778,
      "grad_norm": 0.3543342053890228,
      "learning_rate": 3.855555555555556e-05,
      "loss": 0.0024,
      "step": 20600
    },
    {
      "epoch": 0.458,
      "grad_norm": 0.6736214756965637,
      "learning_rate": 3.855e-05,
      "loss": 0.0021,
      "step": 20610
    },
    {
      "epoch": 0.4582222222222222,
      "grad_norm": 0.3061908781528473,
      "learning_rate": 3.8544444444444445e-05,
      "loss": 0.0029,
      "step": 20620
    },
    {
      "epoch": 0.45844444444444443,
      "grad_norm": 0.26436150074005127,
      "learning_rate": 3.853888888888889e-05,
      "loss": 0.003,
      "step": 20630
    },
    {
      "epoch": 0.45866666666666667,
      "grad_norm": 0.08766838163137436,
      "learning_rate": 3.853333333333334e-05,
      "loss": 0.0027,
      "step": 20640
    },
    {
      "epoch": 0.4588888888888889,
      "grad_norm": 0.1875714659690857,
      "learning_rate": 3.8527777777777776e-05,
      "loss": 0.0026,
      "step": 20650
    },
    {
      "epoch": 0.45911111111111114,
      "grad_norm": 0.5097553133964539,
      "learning_rate": 3.8522222222222226e-05,
      "loss": 0.0024,
      "step": 20660
    },
    {
      "epoch": 0.4593333333333333,
      "grad_norm": 0.377836674451828,
      "learning_rate": 3.851666666666667e-05,
      "loss": 0.003,
      "step": 20670
    },
    {
      "epoch": 0.45955555555555555,
      "grad_norm": 0.16618965566158295,
      "learning_rate": 3.8511111111111114e-05,
      "loss": 0.002,
      "step": 20680
    },
    {
      "epoch": 0.4597777777777778,
      "grad_norm": 0.36482468247413635,
      "learning_rate": 3.850555555555556e-05,
      "loss": 0.0021,
      "step": 20690
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.24537837505340576,
      "learning_rate": 3.85e-05,
      "loss": 0.0022,
      "step": 20700
    },
    {
      "epoch": 0.4602222222222222,
      "grad_norm": 0.22676801681518555,
      "learning_rate": 3.8494444444444444e-05,
      "loss": 0.0021,
      "step": 20710
    },
    {
      "epoch": 0.46044444444444443,
      "grad_norm": 0.49254995584487915,
      "learning_rate": 3.848888888888889e-05,
      "loss": 0.0018,
      "step": 20720
    },
    {
      "epoch": 0.46066666666666667,
      "grad_norm": 0.14441576600074768,
      "learning_rate": 3.848333333333334e-05,
      "loss": 0.0023,
      "step": 20730
    },
    {
      "epoch": 0.4608888888888889,
      "grad_norm": 0.6799965500831604,
      "learning_rate": 3.847777777777778e-05,
      "loss": 0.0019,
      "step": 20740
    },
    {
      "epoch": 0.46111111111111114,
      "grad_norm": 0.6516493558883667,
      "learning_rate": 3.8472222222222225e-05,
      "loss": 0.0022,
      "step": 20750
    },
    {
      "epoch": 0.4613333333333333,
      "grad_norm": 0.29153522849082947,
      "learning_rate": 3.846666666666667e-05,
      "loss": 0.0035,
      "step": 20760
    },
    {
      "epoch": 0.46155555555555555,
      "grad_norm": 0.23506267368793488,
      "learning_rate": 3.846111111111111e-05,
      "loss": 0.0024,
      "step": 20770
    },
    {
      "epoch": 0.4617777777777778,
      "grad_norm": 0.11053961515426636,
      "learning_rate": 3.8455555555555556e-05,
      "loss": 0.0025,
      "step": 20780
    },
    {
      "epoch": 0.462,
      "grad_norm": 0.17396581172943115,
      "learning_rate": 3.845e-05,
      "loss": 0.003,
      "step": 20790
    },
    {
      "epoch": 0.4622222222222222,
      "grad_norm": 0.11532790213823318,
      "learning_rate": 3.844444444444444e-05,
      "loss": 0.0031,
      "step": 20800
    },
    {
      "epoch": 0.46244444444444444,
      "grad_norm": 0.22772251069545746,
      "learning_rate": 3.843888888888889e-05,
      "loss": 0.0028,
      "step": 20810
    },
    {
      "epoch": 0.46266666666666667,
      "grad_norm": 0.07206889986991882,
      "learning_rate": 3.843333333333334e-05,
      "loss": 0.0024,
      "step": 20820
    },
    {
      "epoch": 0.4628888888888889,
      "grad_norm": 0.25044339895248413,
      "learning_rate": 3.842777777777778e-05,
      "loss": 0.0022,
      "step": 20830
    },
    {
      "epoch": 0.4631111111111111,
      "grad_norm": 0.18401722609996796,
      "learning_rate": 3.8422222222222224e-05,
      "loss": 0.0025,
      "step": 20840
    },
    {
      "epoch": 0.4633333333333333,
      "grad_norm": 0.20456135272979736,
      "learning_rate": 3.841666666666667e-05,
      "loss": 0.0019,
      "step": 20850
    },
    {
      "epoch": 0.46355555555555555,
      "grad_norm": 0.4993908107280731,
      "learning_rate": 3.841111111111111e-05,
      "loss": 0.0023,
      "step": 20860
    },
    {
      "epoch": 0.4637777777777778,
      "grad_norm": 0.07536130398511887,
      "learning_rate": 3.8405555555555555e-05,
      "loss": 0.0021,
      "step": 20870
    },
    {
      "epoch": 0.464,
      "grad_norm": 0.1275831013917923,
      "learning_rate": 3.8400000000000005e-05,
      "loss": 0.0022,
      "step": 20880
    },
    {
      "epoch": 0.4642222222222222,
      "grad_norm": 0.47603917121887207,
      "learning_rate": 3.839444444444444e-05,
      "loss": 0.0019,
      "step": 20890
    },
    {
      "epoch": 0.46444444444444444,
      "grad_norm": 0.3936800956726074,
      "learning_rate": 3.838888888888889e-05,
      "loss": 0.002,
      "step": 20900
    },
    {
      "epoch": 0.4646666666666667,
      "grad_norm": 0.11439736932516098,
      "learning_rate": 3.8383333333333336e-05,
      "loss": 0.0018,
      "step": 20910
    },
    {
      "epoch": 0.4648888888888889,
      "grad_norm": 0.3824378252029419,
      "learning_rate": 3.837777777777778e-05,
      "loss": 0.0032,
      "step": 20920
    },
    {
      "epoch": 0.4651111111111111,
      "grad_norm": 0.4778643250465393,
      "learning_rate": 3.837222222222222e-05,
      "loss": 0.002,
      "step": 20930
    },
    {
      "epoch": 0.4653333333333333,
      "grad_norm": 0.09152073413133621,
      "learning_rate": 3.8366666666666666e-05,
      "loss": 0.0035,
      "step": 20940
    },
    {
      "epoch": 0.46555555555555556,
      "grad_norm": 0.22644533216953278,
      "learning_rate": 3.836111111111112e-05,
      "loss": 0.0023,
      "step": 20950
    },
    {
      "epoch": 0.4657777777777778,
      "grad_norm": 0.4418129324913025,
      "learning_rate": 3.8355555555555553e-05,
      "loss": 0.0038,
      "step": 20960
    },
    {
      "epoch": 0.466,
      "grad_norm": 0.5336868762969971,
      "learning_rate": 3.8350000000000004e-05,
      "loss": 0.002,
      "step": 20970
    },
    {
      "epoch": 0.4662222222222222,
      "grad_norm": 0.23454459011554718,
      "learning_rate": 3.834444444444444e-05,
      "loss": 0.0024,
      "step": 20980
    },
    {
      "epoch": 0.46644444444444444,
      "grad_norm": 0.4079863131046295,
      "learning_rate": 3.833888888888889e-05,
      "loss": 0.0027,
      "step": 20990
    },
    {
      "epoch": 0.4666666666666667,
      "grad_norm": 0.08354274928569794,
      "learning_rate": 3.8333333333333334e-05,
      "loss": 0.0021,
      "step": 21000
    },
    {
      "epoch": 0.4668888888888889,
      "grad_norm": 0.10053955763578415,
      "learning_rate": 3.832777777777778e-05,
      "loss": 0.0017,
      "step": 21010
    },
    {
      "epoch": 0.4671111111111111,
      "grad_norm": 0.10851503163576126,
      "learning_rate": 3.832222222222223e-05,
      "loss": 0.0025,
      "step": 21020
    },
    {
      "epoch": 0.4673333333333333,
      "grad_norm": 0.2740812301635742,
      "learning_rate": 3.8316666666666665e-05,
      "loss": 0.0023,
      "step": 21030
    },
    {
      "epoch": 0.46755555555555556,
      "grad_norm": 0.27159029245376587,
      "learning_rate": 3.8311111111111115e-05,
      "loss": 0.0018,
      "step": 21040
    },
    {
      "epoch": 0.4677777777777778,
      "grad_norm": 0.47984978556632996,
      "learning_rate": 3.830555555555555e-05,
      "loss": 0.002,
      "step": 21050
    },
    {
      "epoch": 0.468,
      "grad_norm": 0.06980805099010468,
      "learning_rate": 3.83e-05,
      "loss": 0.0028,
      "step": 21060
    },
    {
      "epoch": 0.4682222222222222,
      "grad_norm": 0.27150285243988037,
      "learning_rate": 3.8294444444444446e-05,
      "loss": 0.0027,
      "step": 21070
    },
    {
      "epoch": 0.46844444444444444,
      "grad_norm": 0.23081906139850616,
      "learning_rate": 3.828888888888889e-05,
      "loss": 0.0028,
      "step": 21080
    },
    {
      "epoch": 0.4686666666666667,
      "grad_norm": 0.2761789858341217,
      "learning_rate": 3.828333333333334e-05,
      "loss": 0.0025,
      "step": 21090
    },
    {
      "epoch": 0.4688888888888889,
      "grad_norm": 0.2659653127193451,
      "learning_rate": 3.827777777777778e-05,
      "loss": 0.0021,
      "step": 21100
    },
    {
      "epoch": 0.4691111111111111,
      "grad_norm": 0.1397537887096405,
      "learning_rate": 3.827222222222223e-05,
      "loss": 0.0019,
      "step": 21110
    },
    {
      "epoch": 0.4693333333333333,
      "grad_norm": 0.142279714345932,
      "learning_rate": 3.8266666666666664e-05,
      "loss": 0.0028,
      "step": 21120
    },
    {
      "epoch": 0.46955555555555556,
      "grad_norm": 0.09298443794250488,
      "learning_rate": 3.8261111111111114e-05,
      "loss": 0.0026,
      "step": 21130
    },
    {
      "epoch": 0.4697777777777778,
      "grad_norm": 0.22980675101280212,
      "learning_rate": 3.825555555555556e-05,
      "loss": 0.0026,
      "step": 21140
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.547347903251648,
      "learning_rate": 3.825e-05,
      "loss": 0.0021,
      "step": 21150
    },
    {
      "epoch": 0.4702222222222222,
      "grad_norm": 0.12279976159334183,
      "learning_rate": 3.8244444444444445e-05,
      "loss": 0.0039,
      "step": 21160
    },
    {
      "epoch": 0.47044444444444444,
      "grad_norm": 0.18840058147907257,
      "learning_rate": 3.823888888888889e-05,
      "loss": 0.0021,
      "step": 21170
    },
    {
      "epoch": 0.4706666666666667,
      "grad_norm": 0.31096553802490234,
      "learning_rate": 3.823333333333334e-05,
      "loss": 0.0028,
      "step": 21180
    },
    {
      "epoch": 0.4708888888888889,
      "grad_norm": 0.15801487863063812,
      "learning_rate": 3.822777777777778e-05,
      "loss": 0.0019,
      "step": 21190
    },
    {
      "epoch": 0.4711111111111111,
      "grad_norm": 0.22812655568122864,
      "learning_rate": 3.8222222222222226e-05,
      "loss": 0.0024,
      "step": 21200
    },
    {
      "epoch": 0.4713333333333333,
      "grad_norm": 0.14973479509353638,
      "learning_rate": 3.821666666666667e-05,
      "loss": 0.0032,
      "step": 21210
    },
    {
      "epoch": 0.47155555555555556,
      "grad_norm": 0.3350876271724701,
      "learning_rate": 3.821111111111111e-05,
      "loss": 0.0019,
      "step": 21220
    },
    {
      "epoch": 0.4717777777777778,
      "grad_norm": 0.4537544250488281,
      "learning_rate": 3.820555555555556e-05,
      "loss": 0.0026,
      "step": 21230
    },
    {
      "epoch": 0.472,
      "grad_norm": 0.12060308456420898,
      "learning_rate": 3.82e-05,
      "loss": 0.003,
      "step": 21240
    },
    {
      "epoch": 0.4722222222222222,
      "grad_norm": 0.6518383622169495,
      "learning_rate": 3.8194444444444444e-05,
      "loss": 0.002,
      "step": 21250
    },
    {
      "epoch": 0.47244444444444444,
      "grad_norm": 0.42423027753829956,
      "learning_rate": 3.8188888888888894e-05,
      "loss": 0.0026,
      "step": 21260
    },
    {
      "epoch": 0.4726666666666667,
      "grad_norm": 0.21928450465202332,
      "learning_rate": 3.818333333333334e-05,
      "loss": 0.0033,
      "step": 21270
    },
    {
      "epoch": 0.4728888888888889,
      "grad_norm": 0.4475992023944855,
      "learning_rate": 3.817777777777778e-05,
      "loss": 0.002,
      "step": 21280
    },
    {
      "epoch": 0.4731111111111111,
      "grad_norm": 0.18059855699539185,
      "learning_rate": 3.8172222222222225e-05,
      "loss": 0.0025,
      "step": 21290
    },
    {
      "epoch": 0.47333333333333333,
      "grad_norm": 0.5498363375663757,
      "learning_rate": 3.816666666666667e-05,
      "loss": 0.002,
      "step": 21300
    },
    {
      "epoch": 0.47355555555555556,
      "grad_norm": 0.16095933318138123,
      "learning_rate": 3.816111111111111e-05,
      "loss": 0.0026,
      "step": 21310
    },
    {
      "epoch": 0.4737777777777778,
      "grad_norm": 0.32101181149482727,
      "learning_rate": 3.8155555555555555e-05,
      "loss": 0.003,
      "step": 21320
    },
    {
      "epoch": 0.474,
      "grad_norm": 0.21414728462696075,
      "learning_rate": 3.8150000000000006e-05,
      "loss": 0.002,
      "step": 21330
    },
    {
      "epoch": 0.4742222222222222,
      "grad_norm": 0.3265380859375,
      "learning_rate": 3.814444444444444e-05,
      "loss": 0.002,
      "step": 21340
    },
    {
      "epoch": 0.47444444444444445,
      "grad_norm": 0.1321946680545807,
      "learning_rate": 3.813888888888889e-05,
      "loss": 0.0022,
      "step": 21350
    },
    {
      "epoch": 0.4746666666666667,
      "grad_norm": 0.14531341195106506,
      "learning_rate": 3.8133333333333336e-05,
      "loss": 0.002,
      "step": 21360
    },
    {
      "epoch": 0.4748888888888889,
      "grad_norm": 0.30634036660194397,
      "learning_rate": 3.812777777777778e-05,
      "loss": 0.0023,
      "step": 21370
    },
    {
      "epoch": 0.4751111111111111,
      "grad_norm": 0.10471628606319427,
      "learning_rate": 3.8122222222222224e-05,
      "loss": 0.0024,
      "step": 21380
    },
    {
      "epoch": 0.47533333333333333,
      "grad_norm": 0.2909673750400543,
      "learning_rate": 3.811666666666667e-05,
      "loss": 0.0025,
      "step": 21390
    },
    {
      "epoch": 0.47555555555555556,
      "grad_norm": 0.4927535057067871,
      "learning_rate": 3.811111111111112e-05,
      "loss": 0.0028,
      "step": 21400
    },
    {
      "epoch": 0.4757777777777778,
      "grad_norm": 0.8153499364852905,
      "learning_rate": 3.8105555555555554e-05,
      "loss": 0.0035,
      "step": 21410
    },
    {
      "epoch": 0.476,
      "grad_norm": 0.47517457604408264,
      "learning_rate": 3.8100000000000005e-05,
      "loss": 0.0027,
      "step": 21420
    },
    {
      "epoch": 0.4762222222222222,
      "grad_norm": 0.14056462049484253,
      "learning_rate": 3.809444444444444e-05,
      "loss": 0.0019,
      "step": 21430
    },
    {
      "epoch": 0.47644444444444445,
      "grad_norm": 0.24530620872974396,
      "learning_rate": 3.808888888888889e-05,
      "loss": 0.0021,
      "step": 21440
    },
    {
      "epoch": 0.4766666666666667,
      "grad_norm": 0.10111924260854721,
      "learning_rate": 3.8083333333333335e-05,
      "loss": 0.0026,
      "step": 21450
    },
    {
      "epoch": 0.47688888888888886,
      "grad_norm": 0.42882025241851807,
      "learning_rate": 3.807777777777778e-05,
      "loss": 0.0023,
      "step": 21460
    },
    {
      "epoch": 0.4771111111111111,
      "grad_norm": 0.14761535823345184,
      "learning_rate": 3.807222222222223e-05,
      "loss": 0.0023,
      "step": 21470
    },
    {
      "epoch": 0.47733333333333333,
      "grad_norm": 0.15434451401233673,
      "learning_rate": 3.8066666666666666e-05,
      "loss": 0.0021,
      "step": 21480
    },
    {
      "epoch": 0.47755555555555557,
      "grad_norm": 0.43951067328453064,
      "learning_rate": 3.8061111111111116e-05,
      "loss": 0.0023,
      "step": 21490
    },
    {
      "epoch": 0.4777777777777778,
      "grad_norm": 0.2322339564561844,
      "learning_rate": 3.805555555555555e-05,
      "loss": 0.002,
      "step": 21500
    },
    {
      "epoch": 0.478,
      "grad_norm": 0.12877216935157776,
      "learning_rate": 3.805e-05,
      "loss": 0.0021,
      "step": 21510
    },
    {
      "epoch": 0.4782222222222222,
      "grad_norm": 0.08063358068466187,
      "learning_rate": 3.804444444444445e-05,
      "loss": 0.002,
      "step": 21520
    },
    {
      "epoch": 0.47844444444444445,
      "grad_norm": 0.07375489920377731,
      "learning_rate": 3.803888888888889e-05,
      "loss": 0.0019,
      "step": 21530
    },
    {
      "epoch": 0.4786666666666667,
      "grad_norm": 0.40266820788383484,
      "learning_rate": 3.803333333333334e-05,
      "loss": 0.0037,
      "step": 21540
    },
    {
      "epoch": 0.47888888888888886,
      "grad_norm": 0.35540029406547546,
      "learning_rate": 3.802777777777778e-05,
      "loss": 0.0024,
      "step": 21550
    },
    {
      "epoch": 0.4791111111111111,
      "grad_norm": 0.2232300043106079,
      "learning_rate": 3.802222222222223e-05,
      "loss": 0.0022,
      "step": 21560
    },
    {
      "epoch": 0.47933333333333333,
      "grad_norm": 0.21616272628307343,
      "learning_rate": 3.8016666666666665e-05,
      "loss": 0.0025,
      "step": 21570
    },
    {
      "epoch": 0.47955555555555557,
      "grad_norm": 0.5453145503997803,
      "learning_rate": 3.8011111111111115e-05,
      "loss": 0.0042,
      "step": 21580
    },
    {
      "epoch": 0.4797777777777778,
      "grad_norm": 0.32062405347824097,
      "learning_rate": 3.800555555555556e-05,
      "loss": 0.0022,
      "step": 21590
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.43238991498947144,
      "learning_rate": 3.8e-05,
      "loss": 0.0024,
      "step": 21600
    },
    {
      "epoch": 0.4802222222222222,
      "grad_norm": 0.06133602559566498,
      "learning_rate": 3.7994444444444446e-05,
      "loss": 0.0019,
      "step": 21610
    },
    {
      "epoch": 0.48044444444444445,
      "grad_norm": 0.37058210372924805,
      "learning_rate": 3.798888888888889e-05,
      "loss": 0.0024,
      "step": 21620
    },
    {
      "epoch": 0.4806666666666667,
      "grad_norm": 0.38106709718704224,
      "learning_rate": 3.798333333333334e-05,
      "loss": 0.0034,
      "step": 21630
    },
    {
      "epoch": 0.48088888888888887,
      "grad_norm": 0.16392725706100464,
      "learning_rate": 3.7977777777777776e-05,
      "loss": 0.0019,
      "step": 21640
    },
    {
      "epoch": 0.4811111111111111,
      "grad_norm": 0.639740526676178,
      "learning_rate": 3.797222222222223e-05,
      "loss": 0.0025,
      "step": 21650
    },
    {
      "epoch": 0.48133333333333334,
      "grad_norm": 0.11144198477268219,
      "learning_rate": 3.796666666666667e-05,
      "loss": 0.002,
      "step": 21660
    },
    {
      "epoch": 0.48155555555555557,
      "grad_norm": 0.2229492962360382,
      "learning_rate": 3.7961111111111114e-05,
      "loss": 0.0019,
      "step": 21670
    },
    {
      "epoch": 0.4817777777777778,
      "grad_norm": 0.2067658007144928,
      "learning_rate": 3.795555555555556e-05,
      "loss": 0.002,
      "step": 21680
    },
    {
      "epoch": 0.482,
      "grad_norm": 0.2829281985759735,
      "learning_rate": 3.795e-05,
      "loss": 0.0021,
      "step": 21690
    },
    {
      "epoch": 0.4822222222222222,
      "grad_norm": 0.23713579773902893,
      "learning_rate": 3.7944444444444444e-05,
      "loss": 0.002,
      "step": 21700
    },
    {
      "epoch": 0.48244444444444445,
      "grad_norm": 0.3688129484653473,
      "learning_rate": 3.793888888888889e-05,
      "loss": 0.002,
      "step": 21710
    },
    {
      "epoch": 0.4826666666666667,
      "grad_norm": 0.09648183733224869,
      "learning_rate": 3.793333333333334e-05,
      "loss": 0.0024,
      "step": 21720
    },
    {
      "epoch": 0.48288888888888887,
      "grad_norm": 0.27366188168525696,
      "learning_rate": 3.792777777777778e-05,
      "loss": 0.0022,
      "step": 21730
    },
    {
      "epoch": 0.4831111111111111,
      "grad_norm": 0.5909656882286072,
      "learning_rate": 3.7922222222222225e-05,
      "loss": 0.0024,
      "step": 21740
    },
    {
      "epoch": 0.48333333333333334,
      "grad_norm": 0.2555685341358185,
      "learning_rate": 3.791666666666667e-05,
      "loss": 0.0028,
      "step": 21750
    },
    {
      "epoch": 0.48355555555555557,
      "grad_norm": 0.5047475099563599,
      "learning_rate": 3.791111111111111e-05,
      "loss": 0.0029,
      "step": 21760
    },
    {
      "epoch": 0.48377777777777775,
      "grad_norm": 0.9874668121337891,
      "learning_rate": 3.7905555555555556e-05,
      "loss": 0.0027,
      "step": 21770
    },
    {
      "epoch": 0.484,
      "grad_norm": 0.19330890476703644,
      "learning_rate": 3.79e-05,
      "loss": 0.0028,
      "step": 21780
    },
    {
      "epoch": 0.4842222222222222,
      "grad_norm": 0.6537767648696899,
      "learning_rate": 3.789444444444444e-05,
      "loss": 0.002,
      "step": 21790
    },
    {
      "epoch": 0.48444444444444446,
      "grad_norm": 0.21578139066696167,
      "learning_rate": 3.7888888888888894e-05,
      "loss": 0.0021,
      "step": 21800
    },
    {
      "epoch": 0.4846666666666667,
      "grad_norm": 1.0046111345291138,
      "learning_rate": 3.788333333333334e-05,
      "loss": 0.0023,
      "step": 21810
    },
    {
      "epoch": 0.48488888888888887,
      "grad_norm": 0.4942554235458374,
      "learning_rate": 3.787777777777778e-05,
      "loss": 0.0018,
      "step": 21820
    },
    {
      "epoch": 0.4851111111111111,
      "grad_norm": 0.09554363787174225,
      "learning_rate": 3.7872222222222224e-05,
      "loss": 0.0027,
      "step": 21830
    },
    {
      "epoch": 0.48533333333333334,
      "grad_norm": 0.43488943576812744,
      "learning_rate": 3.786666666666667e-05,
      "loss": 0.0027,
      "step": 21840
    },
    {
      "epoch": 0.4855555555555556,
      "grad_norm": 0.2397010326385498,
      "learning_rate": 3.786111111111111e-05,
      "loss": 0.0027,
      "step": 21850
    },
    {
      "epoch": 0.48577777777777775,
      "grad_norm": 0.3827848732471466,
      "learning_rate": 3.7855555555555555e-05,
      "loss": 0.002,
      "step": 21860
    },
    {
      "epoch": 0.486,
      "grad_norm": 0.06068802252411842,
      "learning_rate": 3.7850000000000005e-05,
      "loss": 0.0028,
      "step": 21870
    },
    {
      "epoch": 0.4862222222222222,
      "grad_norm": 0.10575243085622787,
      "learning_rate": 3.784444444444445e-05,
      "loss": 0.0021,
      "step": 21880
    },
    {
      "epoch": 0.48644444444444446,
      "grad_norm": 0.6229380369186401,
      "learning_rate": 3.783888888888889e-05,
      "loss": 0.0018,
      "step": 21890
    },
    {
      "epoch": 0.4866666666666667,
      "grad_norm": 0.21803627908229828,
      "learning_rate": 3.7833333333333336e-05,
      "loss": 0.0036,
      "step": 21900
    },
    {
      "epoch": 0.48688888888888887,
      "grad_norm": 0.8263733983039856,
      "learning_rate": 3.782777777777778e-05,
      "loss": 0.0028,
      "step": 21910
    },
    {
      "epoch": 0.4871111111111111,
      "grad_norm": 0.08957322686910629,
      "learning_rate": 3.782222222222222e-05,
      "loss": 0.0029,
      "step": 21920
    },
    {
      "epoch": 0.48733333333333334,
      "grad_norm": 0.09881188720464706,
      "learning_rate": 3.7816666666666667e-05,
      "loss": 0.0018,
      "step": 21930
    },
    {
      "epoch": 0.4875555555555556,
      "grad_norm": 0.07473648339509964,
      "learning_rate": 3.781111111111112e-05,
      "loss": 0.0031,
      "step": 21940
    },
    {
      "epoch": 0.48777777777777775,
      "grad_norm": 0.1971457451581955,
      "learning_rate": 3.7805555555555554e-05,
      "loss": 0.0023,
      "step": 21950
    },
    {
      "epoch": 0.488,
      "grad_norm": 0.22442923486232758,
      "learning_rate": 3.7800000000000004e-05,
      "loss": 0.0017,
      "step": 21960
    },
    {
      "epoch": 0.4882222222222222,
      "grad_norm": 0.4404762089252472,
      "learning_rate": 3.779444444444445e-05,
      "loss": 0.0021,
      "step": 21970
    },
    {
      "epoch": 0.48844444444444446,
      "grad_norm": 0.621327817440033,
      "learning_rate": 3.778888888888889e-05,
      "loss": 0.0025,
      "step": 21980
    },
    {
      "epoch": 0.4886666666666667,
      "grad_norm": 0.16729220747947693,
      "learning_rate": 3.7783333333333335e-05,
      "loss": 0.0018,
      "step": 21990
    },
    {
      "epoch": 0.4888888888888889,
      "grad_norm": 0.31395483016967773,
      "learning_rate": 3.777777777777778e-05,
      "loss": 0.0032,
      "step": 22000
    },
    {
      "epoch": 0.4891111111111111,
      "grad_norm": 0.19863657653331757,
      "learning_rate": 3.777222222222223e-05,
      "loss": 0.002,
      "step": 22010
    },
    {
      "epoch": 0.48933333333333334,
      "grad_norm": 0.24882861971855164,
      "learning_rate": 3.7766666666666665e-05,
      "loss": 0.0021,
      "step": 22020
    },
    {
      "epoch": 0.4895555555555556,
      "grad_norm": 0.12043645232915878,
      "learning_rate": 3.7761111111111116e-05,
      "loss": 0.003,
      "step": 22030
    },
    {
      "epoch": 0.48977777777777776,
      "grad_norm": 0.579400897026062,
      "learning_rate": 3.775555555555555e-05,
      "loss": 0.0029,
      "step": 22040
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.07849109917879105,
      "learning_rate": 3.775e-05,
      "loss": 0.0022,
      "step": 22050
    },
    {
      "epoch": 0.4902222222222222,
      "grad_norm": 0.24803778529167175,
      "learning_rate": 3.7744444444444446e-05,
      "loss": 0.002,
      "step": 22060
    },
    {
      "epoch": 0.49044444444444446,
      "grad_norm": 0.07288703322410583,
      "learning_rate": 3.773888888888889e-05,
      "loss": 0.0026,
      "step": 22070
    },
    {
      "epoch": 0.49066666666666664,
      "grad_norm": 0.12225662171840668,
      "learning_rate": 3.773333333333334e-05,
      "loss": 0.0033,
      "step": 22080
    },
    {
      "epoch": 0.4908888888888889,
      "grad_norm": 0.25180622935295105,
      "learning_rate": 3.772777777777778e-05,
      "loss": 0.002,
      "step": 22090
    },
    {
      "epoch": 0.4911111111111111,
      "grad_norm": 0.1693645715713501,
      "learning_rate": 3.772222222222223e-05,
      "loss": 0.0025,
      "step": 22100
    },
    {
      "epoch": 0.49133333333333334,
      "grad_norm": 0.10272876173257828,
      "learning_rate": 3.7716666666666664e-05,
      "loss": 0.002,
      "step": 22110
    },
    {
      "epoch": 0.4915555555555556,
      "grad_norm": 0.27284061908721924,
      "learning_rate": 3.7711111111111114e-05,
      "loss": 0.0022,
      "step": 22120
    },
    {
      "epoch": 0.49177777777777776,
      "grad_norm": 0.31802648305892944,
      "learning_rate": 3.770555555555556e-05,
      "loss": 0.0019,
      "step": 22130
    },
    {
      "epoch": 0.492,
      "grad_norm": 0.1446959376335144,
      "learning_rate": 3.77e-05,
      "loss": 0.0017,
      "step": 22140
    },
    {
      "epoch": 0.4922222222222222,
      "grad_norm": 0.20176731050014496,
      "learning_rate": 3.769444444444445e-05,
      "loss": 0.0026,
      "step": 22150
    },
    {
      "epoch": 0.49244444444444446,
      "grad_norm": 0.590631902217865,
      "learning_rate": 3.768888888888889e-05,
      "loss": 0.0031,
      "step": 22160
    },
    {
      "epoch": 0.49266666666666664,
      "grad_norm": 0.11432919651269913,
      "learning_rate": 3.768333333333334e-05,
      "loss": 0.0033,
      "step": 22170
    },
    {
      "epoch": 0.4928888888888889,
      "grad_norm": 0.511592447757721,
      "learning_rate": 3.7677777777777776e-05,
      "loss": 0.0022,
      "step": 22180
    },
    {
      "epoch": 0.4931111111111111,
      "grad_norm": 0.33962735533714294,
      "learning_rate": 3.7672222222222226e-05,
      "loss": 0.0019,
      "step": 22190
    },
    {
      "epoch": 0.49333333333333335,
      "grad_norm": 0.057705044746398926,
      "learning_rate": 3.766666666666667e-05,
      "loss": 0.0022,
      "step": 22200
    },
    {
      "epoch": 0.4935555555555556,
      "grad_norm": 0.35149121284484863,
      "learning_rate": 3.766111111111111e-05,
      "loss": 0.0019,
      "step": 22210
    },
    {
      "epoch": 0.49377777777777776,
      "grad_norm": 0.36663568019866943,
      "learning_rate": 3.765555555555556e-05,
      "loss": 0.0031,
      "step": 22220
    },
    {
      "epoch": 0.494,
      "grad_norm": 0.4059288203716278,
      "learning_rate": 3.765e-05,
      "loss": 0.0021,
      "step": 22230
    },
    {
      "epoch": 0.49422222222222223,
      "grad_norm": 0.16550317406654358,
      "learning_rate": 3.764444444444445e-05,
      "loss": 0.0027,
      "step": 22240
    },
    {
      "epoch": 0.49444444444444446,
      "grad_norm": 0.11269056797027588,
      "learning_rate": 3.763888888888889e-05,
      "loss": 0.0039,
      "step": 22250
    },
    {
      "epoch": 0.49466666666666664,
      "grad_norm": 0.050430454313755035,
      "learning_rate": 3.763333333333334e-05,
      "loss": 0.002,
      "step": 22260
    },
    {
      "epoch": 0.4948888888888889,
      "grad_norm": 0.26836302876472473,
      "learning_rate": 3.762777777777778e-05,
      "loss": 0.0024,
      "step": 22270
    },
    {
      "epoch": 0.4951111111111111,
      "grad_norm": 0.3769676685333252,
      "learning_rate": 3.7622222222222225e-05,
      "loss": 0.0043,
      "step": 22280
    },
    {
      "epoch": 0.49533333333333335,
      "grad_norm": 0.3733789920806885,
      "learning_rate": 3.761666666666667e-05,
      "loss": 0.0028,
      "step": 22290
    },
    {
      "epoch": 0.4955555555555556,
      "grad_norm": 0.463750422000885,
      "learning_rate": 3.761111111111111e-05,
      "loss": 0.0022,
      "step": 22300
    },
    {
      "epoch": 0.49577777777777776,
      "grad_norm": 0.31248772144317627,
      "learning_rate": 3.7605555555555556e-05,
      "loss": 0.0022,
      "step": 22310
    },
    {
      "epoch": 0.496,
      "grad_norm": 0.11046871542930603,
      "learning_rate": 3.76e-05,
      "loss": 0.0022,
      "step": 22320
    },
    {
      "epoch": 0.49622222222222223,
      "grad_norm": 0.08843661844730377,
      "learning_rate": 3.759444444444445e-05,
      "loss": 0.0023,
      "step": 22330
    },
    {
      "epoch": 0.49644444444444447,
      "grad_norm": 0.4561045169830322,
      "learning_rate": 3.758888888888889e-05,
      "loss": 0.0023,
      "step": 22340
    },
    {
      "epoch": 0.49666666666666665,
      "grad_norm": 0.30120837688446045,
      "learning_rate": 3.7583333333333337e-05,
      "loss": 0.0026,
      "step": 22350
    },
    {
      "epoch": 0.4968888888888889,
      "grad_norm": 0.4884622395038605,
      "learning_rate": 3.757777777777778e-05,
      "loss": 0.0022,
      "step": 22360
    },
    {
      "epoch": 0.4971111111111111,
      "grad_norm": 0.3519832491874695,
      "learning_rate": 3.7572222222222224e-05,
      "loss": 0.0027,
      "step": 22370
    },
    {
      "epoch": 0.49733333333333335,
      "grad_norm": 0.5185797810554504,
      "learning_rate": 3.756666666666667e-05,
      "loss": 0.0023,
      "step": 22380
    },
    {
      "epoch": 0.49755555555555553,
      "grad_norm": 0.1019476056098938,
      "learning_rate": 3.756111111111111e-05,
      "loss": 0.0024,
      "step": 22390
    },
    {
      "epoch": 0.49777777777777776,
      "grad_norm": 0.34563183784484863,
      "learning_rate": 3.7555555555555554e-05,
      "loss": 0.0025,
      "step": 22400
    },
    {
      "epoch": 0.498,
      "grad_norm": 0.07576899230480194,
      "learning_rate": 3.7550000000000005e-05,
      "loss": 0.0018,
      "step": 22410
    },
    {
      "epoch": 0.49822222222222223,
      "grad_norm": 0.29076483845710754,
      "learning_rate": 3.754444444444445e-05,
      "loss": 0.0022,
      "step": 22420
    },
    {
      "epoch": 0.49844444444444447,
      "grad_norm": 0.19258436560630798,
      "learning_rate": 3.753888888888889e-05,
      "loss": 0.0023,
      "step": 22430
    },
    {
      "epoch": 0.49866666666666665,
      "grad_norm": 0.4233618676662445,
      "learning_rate": 3.7533333333333335e-05,
      "loss": 0.0027,
      "step": 22440
    },
    {
      "epoch": 0.4988888888888889,
      "grad_norm": 0.45887356996536255,
      "learning_rate": 3.752777777777778e-05,
      "loss": 0.0029,
      "step": 22450
    },
    {
      "epoch": 0.4991111111111111,
      "grad_norm": 0.37319478392601013,
      "learning_rate": 3.752222222222222e-05,
      "loss": 0.0019,
      "step": 22460
    },
    {
      "epoch": 0.49933333333333335,
      "grad_norm": 0.16010251641273499,
      "learning_rate": 3.7516666666666666e-05,
      "loss": 0.0018,
      "step": 22470
    },
    {
      "epoch": 0.49955555555555553,
      "grad_norm": 0.1265815943479538,
      "learning_rate": 3.7511111111111116e-05,
      "loss": 0.002,
      "step": 22480
    },
    {
      "epoch": 0.49977777777777777,
      "grad_norm": 0.7574863433837891,
      "learning_rate": 3.750555555555555e-05,
      "loss": 0.0025,
      "step": 22490
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.23514124751091003,
      "learning_rate": 3.7500000000000003e-05,
      "loss": 0.0019,
      "step": 22500
    },
    {
      "epoch": 0.5002222222222222,
      "grad_norm": 0.330278605222702,
      "learning_rate": 3.749444444444445e-05,
      "loss": 0.0031,
      "step": 22510
    },
    {
      "epoch": 0.5004444444444445,
      "grad_norm": 0.3319903314113617,
      "learning_rate": 3.748888888888889e-05,
      "loss": 0.0025,
      "step": 22520
    },
    {
      "epoch": 0.5006666666666667,
      "grad_norm": 0.24523967504501343,
      "learning_rate": 3.7483333333333334e-05,
      "loss": 0.0018,
      "step": 22530
    },
    {
      "epoch": 0.5008888888888889,
      "grad_norm": 0.08893881738185883,
      "learning_rate": 3.747777777777778e-05,
      "loss": 0.0034,
      "step": 22540
    },
    {
      "epoch": 0.5011111111111111,
      "grad_norm": 0.5122639536857605,
      "learning_rate": 3.747222222222223e-05,
      "loss": 0.0019,
      "step": 22550
    },
    {
      "epoch": 0.5013333333333333,
      "grad_norm": 0.13372525572776794,
      "learning_rate": 3.7466666666666665e-05,
      "loss": 0.0021,
      "step": 22560
    },
    {
      "epoch": 0.5015555555555555,
      "grad_norm": 0.11717130988836288,
      "learning_rate": 3.7461111111111115e-05,
      "loss": 0.0017,
      "step": 22570
    },
    {
      "epoch": 0.5017777777777778,
      "grad_norm": 0.2378375381231308,
      "learning_rate": 3.745555555555555e-05,
      "loss": 0.0021,
      "step": 22580
    },
    {
      "epoch": 0.502,
      "grad_norm": 0.11573846638202667,
      "learning_rate": 3.745e-05,
      "loss": 0.0023,
      "step": 22590
    },
    {
      "epoch": 0.5022222222222222,
      "grad_norm": 0.5294274091720581,
      "learning_rate": 3.7444444444444446e-05,
      "loss": 0.0021,
      "step": 22600
    },
    {
      "epoch": 0.5024444444444445,
      "grad_norm": 0.12274255603551865,
      "learning_rate": 3.743888888888889e-05,
      "loss": 0.0026,
      "step": 22610
    },
    {
      "epoch": 0.5026666666666667,
      "grad_norm": 0.3726734519004822,
      "learning_rate": 3.743333333333334e-05,
      "loss": 0.0021,
      "step": 22620
    },
    {
      "epoch": 0.5028888888888889,
      "grad_norm": 0.22012855112552643,
      "learning_rate": 3.7427777777777777e-05,
      "loss": 0.0025,
      "step": 22630
    },
    {
      "epoch": 0.5031111111111111,
      "grad_norm": 0.27635443210601807,
      "learning_rate": 3.742222222222223e-05,
      "loss": 0.0027,
      "step": 22640
    },
    {
      "epoch": 0.5033333333333333,
      "grad_norm": 0.26666563749313354,
      "learning_rate": 3.7416666666666664e-05,
      "loss": 0.0026,
      "step": 22650
    },
    {
      "epoch": 0.5035555555555555,
      "grad_norm": 0.34990760684013367,
      "learning_rate": 3.7411111111111114e-05,
      "loss": 0.0038,
      "step": 22660
    },
    {
      "epoch": 0.5037777777777778,
      "grad_norm": 0.27829116582870483,
      "learning_rate": 3.740555555555556e-05,
      "loss": 0.0024,
      "step": 22670
    },
    {
      "epoch": 0.504,
      "grad_norm": 0.1047709733247757,
      "learning_rate": 3.74e-05,
      "loss": 0.0019,
      "step": 22680
    },
    {
      "epoch": 0.5042222222222222,
      "grad_norm": 0.337704598903656,
      "learning_rate": 3.739444444444445e-05,
      "loss": 0.0024,
      "step": 22690
    },
    {
      "epoch": 0.5044444444444445,
      "grad_norm": 0.26499485969543457,
      "learning_rate": 3.738888888888889e-05,
      "loss": 0.0023,
      "step": 22700
    },
    {
      "epoch": 0.5046666666666667,
      "grad_norm": 0.2675286829471588,
      "learning_rate": 3.738333333333334e-05,
      "loss": 0.0027,
      "step": 22710
    },
    {
      "epoch": 0.5048888888888889,
      "grad_norm": 0.28899529576301575,
      "learning_rate": 3.7377777777777775e-05,
      "loss": 0.0028,
      "step": 22720
    },
    {
      "epoch": 0.5051111111111111,
      "grad_norm": 0.2560262382030487,
      "learning_rate": 3.7372222222222226e-05,
      "loss": 0.0022,
      "step": 22730
    },
    {
      "epoch": 0.5053333333333333,
      "grad_norm": 0.3450011909008026,
      "learning_rate": 3.736666666666667e-05,
      "loss": 0.003,
      "step": 22740
    },
    {
      "epoch": 0.5055555555555555,
      "grad_norm": 0.2603514790534973,
      "learning_rate": 3.736111111111111e-05,
      "loss": 0.0022,
      "step": 22750
    },
    {
      "epoch": 0.5057777777777778,
      "grad_norm": 0.24502407014369965,
      "learning_rate": 3.7355555555555556e-05,
      "loss": 0.0027,
      "step": 22760
    },
    {
      "epoch": 0.506,
      "grad_norm": 0.12375237792730331,
      "learning_rate": 3.735e-05,
      "loss": 0.0023,
      "step": 22770
    },
    {
      "epoch": 0.5062222222222222,
      "grad_norm": 0.33061665296554565,
      "learning_rate": 3.734444444444445e-05,
      "loss": 0.0024,
      "step": 22780
    },
    {
      "epoch": 0.5064444444444445,
      "grad_norm": 0.12337113916873932,
      "learning_rate": 3.733888888888889e-05,
      "loss": 0.0018,
      "step": 22790
    },
    {
      "epoch": 0.5066666666666667,
      "grad_norm": 0.5831109285354614,
      "learning_rate": 3.733333333333334e-05,
      "loss": 0.0024,
      "step": 22800
    },
    {
      "epoch": 0.5068888888888889,
      "grad_norm": 0.16476880013942719,
      "learning_rate": 3.732777777777778e-05,
      "loss": 0.0028,
      "step": 22810
    },
    {
      "epoch": 0.5071111111111111,
      "grad_norm": 0.40109723806381226,
      "learning_rate": 3.7322222222222224e-05,
      "loss": 0.0017,
      "step": 22820
    },
    {
      "epoch": 0.5073333333333333,
      "grad_norm": 0.10910893976688385,
      "learning_rate": 3.731666666666667e-05,
      "loss": 0.003,
      "step": 22830
    },
    {
      "epoch": 0.5075555555555555,
      "grad_norm": 0.4329807758331299,
      "learning_rate": 3.731111111111111e-05,
      "loss": 0.0031,
      "step": 22840
    },
    {
      "epoch": 0.5077777777777778,
      "grad_norm": 0.6049783825874329,
      "learning_rate": 3.7305555555555555e-05,
      "loss": 0.0022,
      "step": 22850
    },
    {
      "epoch": 0.508,
      "grad_norm": 0.18995027244091034,
      "learning_rate": 3.73e-05,
      "loss": 0.0025,
      "step": 22860
    },
    {
      "epoch": 0.5082222222222222,
      "grad_norm": 0.05452783405780792,
      "learning_rate": 3.729444444444445e-05,
      "loss": 0.003,
      "step": 22870
    },
    {
      "epoch": 0.5084444444444445,
      "grad_norm": 0.09138870239257812,
      "learning_rate": 3.728888888888889e-05,
      "loss": 0.0022,
      "step": 22880
    },
    {
      "epoch": 0.5086666666666667,
      "grad_norm": 0.1571083515882492,
      "learning_rate": 3.7283333333333336e-05,
      "loss": 0.0021,
      "step": 22890
    },
    {
      "epoch": 0.5088888888888888,
      "grad_norm": 0.35987889766693115,
      "learning_rate": 3.727777777777778e-05,
      "loss": 0.0031,
      "step": 22900
    },
    {
      "epoch": 0.5091111111111111,
      "grad_norm": 0.6500208377838135,
      "learning_rate": 3.727222222222222e-05,
      "loss": 0.0026,
      "step": 22910
    },
    {
      "epoch": 0.5093333333333333,
      "grad_norm": 0.7187303304672241,
      "learning_rate": 3.726666666666667e-05,
      "loss": 0.0026,
      "step": 22920
    },
    {
      "epoch": 0.5095555555555555,
      "grad_norm": 0.3999663293361664,
      "learning_rate": 3.726111111111111e-05,
      "loss": 0.0023,
      "step": 22930
    },
    {
      "epoch": 0.5097777777777778,
      "grad_norm": 0.6456895470619202,
      "learning_rate": 3.7255555555555554e-05,
      "loss": 0.0018,
      "step": 22940
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.20749057829380035,
      "learning_rate": 3.7250000000000004e-05,
      "loss": 0.0022,
      "step": 22950
    },
    {
      "epoch": 0.5102222222222222,
      "grad_norm": 0.25344452261924744,
      "learning_rate": 3.724444444444445e-05,
      "loss": 0.0019,
      "step": 22960
    },
    {
      "epoch": 0.5104444444444445,
      "grad_norm": 0.24699802696704865,
      "learning_rate": 3.723888888888889e-05,
      "loss": 0.0023,
      "step": 22970
    },
    {
      "epoch": 0.5106666666666667,
      "grad_norm": 0.6071383357048035,
      "learning_rate": 3.7233333333333335e-05,
      "loss": 0.0027,
      "step": 22980
    },
    {
      "epoch": 0.5108888888888888,
      "grad_norm": 0.45459797978401184,
      "learning_rate": 3.722777777777778e-05,
      "loss": 0.0026,
      "step": 22990
    },
    {
      "epoch": 0.5111111111111111,
      "grad_norm": 0.09980856627225876,
      "learning_rate": 3.722222222222222e-05,
      "loss": 0.0023,
      "step": 23000
    },
    {
      "epoch": 0.5113333333333333,
      "grad_norm": 0.08476950228214264,
      "learning_rate": 3.7216666666666666e-05,
      "loss": 0.0031,
      "step": 23010
    },
    {
      "epoch": 0.5115555555555555,
      "grad_norm": 0.333652138710022,
      "learning_rate": 3.7211111111111116e-05,
      "loss": 0.002,
      "step": 23020
    },
    {
      "epoch": 0.5117777777777778,
      "grad_norm": 0.41319653391838074,
      "learning_rate": 3.720555555555555e-05,
      "loss": 0.0023,
      "step": 23030
    },
    {
      "epoch": 0.512,
      "grad_norm": 0.23866358399391174,
      "learning_rate": 3.72e-05,
      "loss": 0.003,
      "step": 23040
    },
    {
      "epoch": 0.5122222222222222,
      "grad_norm": 0.5353508591651917,
      "learning_rate": 3.7194444444444447e-05,
      "loss": 0.0021,
      "step": 23050
    },
    {
      "epoch": 0.5124444444444445,
      "grad_norm": 0.15221521258354187,
      "learning_rate": 3.718888888888889e-05,
      "loss": 0.0018,
      "step": 23060
    },
    {
      "epoch": 0.5126666666666667,
      "grad_norm": 0.10450892150402069,
      "learning_rate": 3.7183333333333334e-05,
      "loss": 0.0022,
      "step": 23070
    },
    {
      "epoch": 0.5128888888888888,
      "grad_norm": 0.07688239216804504,
      "learning_rate": 3.717777777777778e-05,
      "loss": 0.0033,
      "step": 23080
    },
    {
      "epoch": 0.5131111111111111,
      "grad_norm": 0.6869023442268372,
      "learning_rate": 3.717222222222223e-05,
      "loss": 0.0021,
      "step": 23090
    },
    {
      "epoch": 0.5133333333333333,
      "grad_norm": 0.4261254072189331,
      "learning_rate": 3.7166666666666664e-05,
      "loss": 0.002,
      "step": 23100
    },
    {
      "epoch": 0.5135555555555555,
      "grad_norm": 0.20654501020908356,
      "learning_rate": 3.7161111111111115e-05,
      "loss": 0.0025,
      "step": 23110
    },
    {
      "epoch": 0.5137777777777778,
      "grad_norm": 0.10309720784425735,
      "learning_rate": 3.715555555555555e-05,
      "loss": 0.0034,
      "step": 23120
    },
    {
      "epoch": 0.514,
      "grad_norm": 0.24906587600708008,
      "learning_rate": 3.715e-05,
      "loss": 0.0021,
      "step": 23130
    },
    {
      "epoch": 0.5142222222222222,
      "grad_norm": 0.16073498129844666,
      "learning_rate": 3.7144444444444445e-05,
      "loss": 0.0019,
      "step": 23140
    },
    {
      "epoch": 0.5144444444444445,
      "grad_norm": 0.2771247327327728,
      "learning_rate": 3.713888888888889e-05,
      "loss": 0.0022,
      "step": 23150
    },
    {
      "epoch": 0.5146666666666667,
      "grad_norm": 0.06790103763341904,
      "learning_rate": 3.713333333333334e-05,
      "loss": 0.0017,
      "step": 23160
    },
    {
      "epoch": 0.5148888888888888,
      "grad_norm": 0.4486660063266754,
      "learning_rate": 3.7127777777777776e-05,
      "loss": 0.0028,
      "step": 23170
    },
    {
      "epoch": 0.5151111111111111,
      "grad_norm": 0.11313284933567047,
      "learning_rate": 3.7122222222222226e-05,
      "loss": 0.0018,
      "step": 23180
    },
    {
      "epoch": 0.5153333333333333,
      "grad_norm": 0.3831389546394348,
      "learning_rate": 3.711666666666666e-05,
      "loss": 0.0031,
      "step": 23190
    },
    {
      "epoch": 0.5155555555555555,
      "grad_norm": 0.1499546319246292,
      "learning_rate": 3.7111111111111113e-05,
      "loss": 0.002,
      "step": 23200
    },
    {
      "epoch": 0.5157777777777778,
      "grad_norm": 0.06860852986574173,
      "learning_rate": 3.710555555555556e-05,
      "loss": 0.002,
      "step": 23210
    },
    {
      "epoch": 0.516,
      "grad_norm": 0.28877022862434387,
      "learning_rate": 3.71e-05,
      "loss": 0.0025,
      "step": 23220
    },
    {
      "epoch": 0.5162222222222222,
      "grad_norm": 0.08925130218267441,
      "learning_rate": 3.709444444444445e-05,
      "loss": 0.0037,
      "step": 23230
    },
    {
      "epoch": 0.5164444444444445,
      "grad_norm": 0.2232276350259781,
      "learning_rate": 3.708888888888889e-05,
      "loss": 0.0022,
      "step": 23240
    },
    {
      "epoch": 0.5166666666666667,
      "grad_norm": 0.3236682415008545,
      "learning_rate": 3.708333333333334e-05,
      "loss": 0.0024,
      "step": 23250
    },
    {
      "epoch": 0.5168888888888888,
      "grad_norm": 0.3867899775505066,
      "learning_rate": 3.7077777777777775e-05,
      "loss": 0.0021,
      "step": 23260
    },
    {
      "epoch": 0.5171111111111111,
      "grad_norm": 0.09675928950309753,
      "learning_rate": 3.7072222222222225e-05,
      "loss": 0.0022,
      "step": 23270
    },
    {
      "epoch": 0.5173333333333333,
      "grad_norm": 0.4255082905292511,
      "learning_rate": 3.706666666666667e-05,
      "loss": 0.0031,
      "step": 23280
    },
    {
      "epoch": 0.5175555555555555,
      "grad_norm": 0.3289468288421631,
      "learning_rate": 3.706111111111111e-05,
      "loss": 0.0027,
      "step": 23290
    },
    {
      "epoch": 0.5177777777777778,
      "grad_norm": 0.09794378280639648,
      "learning_rate": 3.705555555555556e-05,
      "loss": 0.0026,
      "step": 23300
    },
    {
      "epoch": 0.518,
      "grad_norm": 0.07706134766340256,
      "learning_rate": 3.705e-05,
      "loss": 0.003,
      "step": 23310
    },
    {
      "epoch": 0.5182222222222223,
      "grad_norm": 0.075924351811409,
      "learning_rate": 3.704444444444445e-05,
      "loss": 0.0022,
      "step": 23320
    },
    {
      "epoch": 0.5184444444444445,
      "grad_norm": 0.20966239273548126,
      "learning_rate": 3.7038888888888886e-05,
      "loss": 0.002,
      "step": 23330
    },
    {
      "epoch": 0.5186666666666667,
      "grad_norm": 0.3561941683292389,
      "learning_rate": 3.703333333333334e-05,
      "loss": 0.002,
      "step": 23340
    },
    {
      "epoch": 0.5188888888888888,
      "grad_norm": 0.30538883805274963,
      "learning_rate": 3.702777777777778e-05,
      "loss": 0.0021,
      "step": 23350
    },
    {
      "epoch": 0.5191111111111111,
      "grad_norm": 0.20999982953071594,
      "learning_rate": 3.7022222222222224e-05,
      "loss": 0.0019,
      "step": 23360
    },
    {
      "epoch": 0.5193333333333333,
      "grad_norm": 0.09959987550973892,
      "learning_rate": 3.701666666666667e-05,
      "loss": 0.0034,
      "step": 23370
    },
    {
      "epoch": 0.5195555555555555,
      "grad_norm": 0.504553496837616,
      "learning_rate": 3.701111111111111e-05,
      "loss": 0.003,
      "step": 23380
    },
    {
      "epoch": 0.5197777777777778,
      "grad_norm": 0.4736504554748535,
      "learning_rate": 3.700555555555556e-05,
      "loss": 0.0019,
      "step": 23390
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.5766309499740601,
      "learning_rate": 3.7e-05,
      "loss": 0.0027,
      "step": 23400
    },
    {
      "epoch": 0.5202222222222223,
      "grad_norm": 0.11842183768749237,
      "learning_rate": 3.699444444444445e-05,
      "loss": 0.0019,
      "step": 23410
    },
    {
      "epoch": 0.5204444444444445,
      "grad_norm": 0.20387250185012817,
      "learning_rate": 3.698888888888889e-05,
      "loss": 0.0023,
      "step": 23420
    },
    {
      "epoch": 0.5206666666666667,
      "grad_norm": 0.09253077954053879,
      "learning_rate": 3.6983333333333336e-05,
      "loss": 0.0019,
      "step": 23430
    },
    {
      "epoch": 0.5208888888888888,
      "grad_norm": 0.5585277676582336,
      "learning_rate": 3.697777777777778e-05,
      "loss": 0.0027,
      "step": 23440
    },
    {
      "epoch": 0.5211111111111111,
      "grad_norm": 0.5851563811302185,
      "learning_rate": 3.697222222222222e-05,
      "loss": 0.002,
      "step": 23450
    },
    {
      "epoch": 0.5213333333333333,
      "grad_norm": 0.31933197379112244,
      "learning_rate": 3.6966666666666666e-05,
      "loss": 0.0037,
      "step": 23460
    },
    {
      "epoch": 0.5215555555555556,
      "grad_norm": 0.13929347693920135,
      "learning_rate": 3.696111111111111e-05,
      "loss": 0.0022,
      "step": 23470
    },
    {
      "epoch": 0.5217777777777778,
      "grad_norm": 0.28864529728889465,
      "learning_rate": 3.695555555555556e-05,
      "loss": 0.0024,
      "step": 23480
    },
    {
      "epoch": 0.522,
      "grad_norm": 0.5176506638526917,
      "learning_rate": 3.6950000000000004e-05,
      "loss": 0.0021,
      "step": 23490
    },
    {
      "epoch": 0.5222222222222223,
      "grad_norm": 0.4467771351337433,
      "learning_rate": 3.694444444444445e-05,
      "loss": 0.0025,
      "step": 23500
    },
    {
      "epoch": 0.5224444444444445,
      "grad_norm": 0.833186686038971,
      "learning_rate": 3.693888888888889e-05,
      "loss": 0.0022,
      "step": 23510
    },
    {
      "epoch": 0.5226666666666666,
      "grad_norm": 0.6359562277793884,
      "learning_rate": 3.6933333333333334e-05,
      "loss": 0.0026,
      "step": 23520
    },
    {
      "epoch": 0.5228888888888888,
      "grad_norm": 0.2402239888906479,
      "learning_rate": 3.692777777777778e-05,
      "loss": 0.0026,
      "step": 23530
    },
    {
      "epoch": 0.5231111111111111,
      "grad_norm": 0.22362253069877625,
      "learning_rate": 3.692222222222222e-05,
      "loss": 0.0018,
      "step": 23540
    },
    {
      "epoch": 0.5233333333333333,
      "grad_norm": 0.28978022933006287,
      "learning_rate": 3.6916666666666665e-05,
      "loss": 0.0021,
      "step": 23550
    },
    {
      "epoch": 0.5235555555555556,
      "grad_norm": 0.6430990695953369,
      "learning_rate": 3.6911111111111115e-05,
      "loss": 0.0023,
      "step": 23560
    },
    {
      "epoch": 0.5237777777777778,
      "grad_norm": 0.18203949928283691,
      "learning_rate": 3.690555555555556e-05,
      "loss": 0.0018,
      "step": 23570
    },
    {
      "epoch": 0.524,
      "grad_norm": 0.2219819575548172,
      "learning_rate": 3.69e-05,
      "loss": 0.0025,
      "step": 23580
    },
    {
      "epoch": 0.5242222222222223,
      "grad_norm": 0.3298673629760742,
      "learning_rate": 3.6894444444444446e-05,
      "loss": 0.0018,
      "step": 23590
    },
    {
      "epoch": 0.5244444444444445,
      "grad_norm": 0.3453739881515503,
      "learning_rate": 3.688888888888889e-05,
      "loss": 0.0028,
      "step": 23600
    },
    {
      "epoch": 0.5246666666666666,
      "grad_norm": 0.49744126200675964,
      "learning_rate": 3.688333333333333e-05,
      "loss": 0.0022,
      "step": 23610
    },
    {
      "epoch": 0.5248888888888888,
      "grad_norm": 0.32828542590141296,
      "learning_rate": 3.687777777777778e-05,
      "loss": 0.0024,
      "step": 23620
    },
    {
      "epoch": 0.5251111111111111,
      "grad_norm": 0.08420707285404205,
      "learning_rate": 3.687222222222223e-05,
      "loss": 0.0038,
      "step": 23630
    },
    {
      "epoch": 0.5253333333333333,
      "grad_norm": 0.2766728401184082,
      "learning_rate": 3.6866666666666664e-05,
      "loss": 0.002,
      "step": 23640
    },
    {
      "epoch": 0.5255555555555556,
      "grad_norm": 0.6741750240325928,
      "learning_rate": 3.6861111111111114e-05,
      "loss": 0.002,
      "step": 23650
    },
    {
      "epoch": 0.5257777777777778,
      "grad_norm": 0.4944975674152374,
      "learning_rate": 3.685555555555556e-05,
      "loss": 0.0031,
      "step": 23660
    },
    {
      "epoch": 0.526,
      "grad_norm": 0.9535590410232544,
      "learning_rate": 3.685e-05,
      "loss": 0.0024,
      "step": 23670
    },
    {
      "epoch": 0.5262222222222223,
      "grad_norm": 0.0742999017238617,
      "learning_rate": 3.6844444444444445e-05,
      "loss": 0.0018,
      "step": 23680
    },
    {
      "epoch": 0.5264444444444445,
      "grad_norm": 0.2761856019496918,
      "learning_rate": 3.683888888888889e-05,
      "loss": 0.0028,
      "step": 23690
    },
    {
      "epoch": 0.5266666666666666,
      "grad_norm": 0.31726697087287903,
      "learning_rate": 3.683333333333334e-05,
      "loss": 0.0025,
      "step": 23700
    },
    {
      "epoch": 0.5268888888888889,
      "grad_norm": 0.5287394523620605,
      "learning_rate": 3.6827777777777775e-05,
      "loss": 0.0039,
      "step": 23710
    },
    {
      "epoch": 0.5271111111111111,
      "grad_norm": 0.2662462890148163,
      "learning_rate": 3.6822222222222226e-05,
      "loss": 0.0017,
      "step": 23720
    },
    {
      "epoch": 0.5273333333333333,
      "grad_norm": 0.1874014437198639,
      "learning_rate": 3.681666666666667e-05,
      "loss": 0.0032,
      "step": 23730
    },
    {
      "epoch": 0.5275555555555556,
      "grad_norm": 0.12820297479629517,
      "learning_rate": 3.681111111111111e-05,
      "loss": 0.002,
      "step": 23740
    },
    {
      "epoch": 0.5277777777777778,
      "grad_norm": 0.2357170134782791,
      "learning_rate": 3.6805555555555556e-05,
      "loss": 0.0026,
      "step": 23750
    },
    {
      "epoch": 0.528,
      "grad_norm": 0.13727885484695435,
      "learning_rate": 3.68e-05,
      "loss": 0.0023,
      "step": 23760
    },
    {
      "epoch": 0.5282222222222223,
      "grad_norm": 0.3355371356010437,
      "learning_rate": 3.679444444444445e-05,
      "loss": 0.0026,
      "step": 23770
    },
    {
      "epoch": 0.5284444444444445,
      "grad_norm": 0.09907297790050507,
      "learning_rate": 3.678888888888889e-05,
      "loss": 0.0028,
      "step": 23780
    },
    {
      "epoch": 0.5286666666666666,
      "grad_norm": 0.2936679422855377,
      "learning_rate": 3.678333333333334e-05,
      "loss": 0.002,
      "step": 23790
    },
    {
      "epoch": 0.5288888888888889,
      "grad_norm": 0.2543881833553314,
      "learning_rate": 3.677777777777778e-05,
      "loss": 0.0024,
      "step": 23800
    },
    {
      "epoch": 0.5291111111111111,
      "grad_norm": 0.24496890604496002,
      "learning_rate": 3.6772222222222225e-05,
      "loss": 0.0022,
      "step": 23810
    },
    {
      "epoch": 0.5293333333333333,
      "grad_norm": 0.07980099320411682,
      "learning_rate": 3.676666666666667e-05,
      "loss": 0.0023,
      "step": 23820
    },
    {
      "epoch": 0.5295555555555556,
      "grad_norm": 0.2808895409107208,
      "learning_rate": 3.676111111111111e-05,
      "loss": 0.0023,
      "step": 23830
    },
    {
      "epoch": 0.5297777777777778,
      "grad_norm": 0.23895509541034698,
      "learning_rate": 3.675555555555556e-05,
      "loss": 0.0022,
      "step": 23840
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.10930653661489487,
      "learning_rate": 3.675e-05,
      "loss": 0.003,
      "step": 23850
    },
    {
      "epoch": 0.5302222222222223,
      "grad_norm": 0.20465758442878723,
      "learning_rate": 3.674444444444445e-05,
      "loss": 0.0034,
      "step": 23860
    },
    {
      "epoch": 0.5304444444444445,
      "grad_norm": 0.3262108266353607,
      "learning_rate": 3.673888888888889e-05,
      "loss": 0.0023,
      "step": 23870
    },
    {
      "epoch": 0.5306666666666666,
      "grad_norm": 0.09862513095140457,
      "learning_rate": 3.6733333333333336e-05,
      "loss": 0.0026,
      "step": 23880
    },
    {
      "epoch": 0.5308888888888889,
      "grad_norm": 0.2400154322385788,
      "learning_rate": 3.672777777777778e-05,
      "loss": 0.0022,
      "step": 23890
    },
    {
      "epoch": 0.5311111111111111,
      "grad_norm": 0.344951331615448,
      "learning_rate": 3.672222222222222e-05,
      "loss": 0.0023,
      "step": 23900
    },
    {
      "epoch": 0.5313333333333333,
      "grad_norm": 0.25015273690223694,
      "learning_rate": 3.671666666666667e-05,
      "loss": 0.0021,
      "step": 23910
    },
    {
      "epoch": 0.5315555555555556,
      "grad_norm": 0.13199369609355927,
      "learning_rate": 3.671111111111111e-05,
      "loss": 0.0023,
      "step": 23920
    },
    {
      "epoch": 0.5317777777777778,
      "grad_norm": 0.08537530899047852,
      "learning_rate": 3.670555555555556e-05,
      "loss": 0.002,
      "step": 23930
    },
    {
      "epoch": 0.532,
      "grad_norm": 0.43403467535972595,
      "learning_rate": 3.6700000000000004e-05,
      "loss": 0.0022,
      "step": 23940
    },
    {
      "epoch": 0.5322222222222223,
      "grad_norm": 0.3196602463722229,
      "learning_rate": 3.669444444444445e-05,
      "loss": 0.0021,
      "step": 23950
    },
    {
      "epoch": 0.5324444444444445,
      "grad_norm": 0.39968448877334595,
      "learning_rate": 3.668888888888889e-05,
      "loss": 0.0022,
      "step": 23960
    },
    {
      "epoch": 0.5326666666666666,
      "grad_norm": 0.159835547208786,
      "learning_rate": 3.6683333333333335e-05,
      "loss": 0.0023,
      "step": 23970
    },
    {
      "epoch": 0.5328888888888889,
      "grad_norm": 0.5849865674972534,
      "learning_rate": 3.667777777777778e-05,
      "loss": 0.002,
      "step": 23980
    },
    {
      "epoch": 0.5331111111111111,
      "grad_norm": 0.06949978321790695,
      "learning_rate": 3.667222222222222e-05,
      "loss": 0.0032,
      "step": 23990
    },
    {
      "epoch": 0.5333333333333333,
      "grad_norm": 0.11424300819635391,
      "learning_rate": 3.6666666666666666e-05,
      "loss": 0.0022,
      "step": 24000
    },
    {
      "epoch": 0.5335555555555556,
      "grad_norm": 0.2062027007341385,
      "learning_rate": 3.6661111111111116e-05,
      "loss": 0.0028,
      "step": 24010
    },
    {
      "epoch": 0.5337777777777778,
      "grad_norm": 0.281019926071167,
      "learning_rate": 3.665555555555556e-05,
      "loss": 0.0024,
      "step": 24020
    },
    {
      "epoch": 0.534,
      "grad_norm": 0.045908063650131226,
      "learning_rate": 3.665e-05,
      "loss": 0.0022,
      "step": 24030
    },
    {
      "epoch": 0.5342222222222223,
      "grad_norm": 0.18609866499900818,
      "learning_rate": 3.664444444444445e-05,
      "loss": 0.0025,
      "step": 24040
    },
    {
      "epoch": 0.5344444444444445,
      "grad_norm": 0.08698762208223343,
      "learning_rate": 3.663888888888889e-05,
      "loss": 0.0022,
      "step": 24050
    },
    {
      "epoch": 0.5346666666666666,
      "grad_norm": 0.1688319891691208,
      "learning_rate": 3.6633333333333334e-05,
      "loss": 0.0021,
      "step": 24060
    },
    {
      "epoch": 0.5348888888888889,
      "grad_norm": 0.3807124197483063,
      "learning_rate": 3.662777777777778e-05,
      "loss": 0.0026,
      "step": 24070
    },
    {
      "epoch": 0.5351111111111111,
      "grad_norm": 0.09264571964740753,
      "learning_rate": 3.662222222222223e-05,
      "loss": 0.0028,
      "step": 24080
    },
    {
      "epoch": 0.5353333333333333,
      "grad_norm": 0.0890955924987793,
      "learning_rate": 3.6616666666666664e-05,
      "loss": 0.002,
      "step": 24090
    },
    {
      "epoch": 0.5355555555555556,
      "grad_norm": 0.11306194961071014,
      "learning_rate": 3.6611111111111115e-05,
      "loss": 0.002,
      "step": 24100
    },
    {
      "epoch": 0.5357777777777778,
      "grad_norm": 0.2764134109020233,
      "learning_rate": 3.660555555555556e-05,
      "loss": 0.0025,
      "step": 24110
    },
    {
      "epoch": 0.536,
      "grad_norm": 0.32524678111076355,
      "learning_rate": 3.66e-05,
      "loss": 0.0019,
      "step": 24120
    },
    {
      "epoch": 0.5362222222222223,
      "grad_norm": 0.34715911746025085,
      "learning_rate": 3.6594444444444446e-05,
      "loss": 0.0019,
      "step": 24130
    },
    {
      "epoch": 0.5364444444444444,
      "grad_norm": 0.17376171052455902,
      "learning_rate": 3.658888888888889e-05,
      "loss": 0.0021,
      "step": 24140
    },
    {
      "epoch": 0.5366666666666666,
      "grad_norm": 0.2955971658229828,
      "learning_rate": 3.658333333333334e-05,
      "loss": 0.0019,
      "step": 24150
    },
    {
      "epoch": 0.5368888888888889,
      "grad_norm": 0.2609023451805115,
      "learning_rate": 3.6577777777777776e-05,
      "loss": 0.0019,
      "step": 24160
    },
    {
      "epoch": 0.5371111111111111,
      "grad_norm": 0.3254261314868927,
      "learning_rate": 3.6572222222222227e-05,
      "loss": 0.003,
      "step": 24170
    },
    {
      "epoch": 0.5373333333333333,
      "grad_norm": 0.4196457266807556,
      "learning_rate": 3.656666666666666e-05,
      "loss": 0.0021,
      "step": 24180
    },
    {
      "epoch": 0.5375555555555556,
      "grad_norm": 0.14859634637832642,
      "learning_rate": 3.6561111111111114e-05,
      "loss": 0.0026,
      "step": 24190
    },
    {
      "epoch": 0.5377777777777778,
      "grad_norm": 0.16202595829963684,
      "learning_rate": 3.655555555555556e-05,
      "loss": 0.0024,
      "step": 24200
    },
    {
      "epoch": 0.538,
      "grad_norm": 0.09714619815349579,
      "learning_rate": 3.655e-05,
      "loss": 0.0026,
      "step": 24210
    },
    {
      "epoch": 0.5382222222222223,
      "grad_norm": 0.6704584956169128,
      "learning_rate": 3.654444444444445e-05,
      "loss": 0.0028,
      "step": 24220
    },
    {
      "epoch": 0.5384444444444444,
      "grad_norm": 0.26539692282676697,
      "learning_rate": 3.653888888888889e-05,
      "loss": 0.002,
      "step": 24230
    },
    {
      "epoch": 0.5386666666666666,
      "grad_norm": 0.5310250520706177,
      "learning_rate": 3.653333333333334e-05,
      "loss": 0.0026,
      "step": 24240
    },
    {
      "epoch": 0.5388888888888889,
      "grad_norm": 0.32860374450683594,
      "learning_rate": 3.6527777777777775e-05,
      "loss": 0.0031,
      "step": 24250
    },
    {
      "epoch": 0.5391111111111111,
      "grad_norm": 0.5700228810310364,
      "learning_rate": 3.6522222222222225e-05,
      "loss": 0.0025,
      "step": 24260
    },
    {
      "epoch": 0.5393333333333333,
      "grad_norm": 0.26777851581573486,
      "learning_rate": 3.651666666666667e-05,
      "loss": 0.002,
      "step": 24270
    },
    {
      "epoch": 0.5395555555555556,
      "grad_norm": 0.26424598693847656,
      "learning_rate": 3.651111111111111e-05,
      "loss": 0.0022,
      "step": 24280
    },
    {
      "epoch": 0.5397777777777778,
      "grad_norm": 0.1783907115459442,
      "learning_rate": 3.650555555555556e-05,
      "loss": 0.002,
      "step": 24290
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.07589665800333023,
      "learning_rate": 3.65e-05,
      "loss": 0.0026,
      "step": 24300
    },
    {
      "epoch": 0.5402222222222223,
      "grad_norm": 0.08461537957191467,
      "learning_rate": 3.649444444444445e-05,
      "loss": 0.0028,
      "step": 24310
    },
    {
      "epoch": 0.5404444444444444,
      "grad_norm": 0.21688887476921082,
      "learning_rate": 3.648888888888889e-05,
      "loss": 0.0019,
      "step": 24320
    },
    {
      "epoch": 0.5406666666666666,
      "grad_norm": 0.3703020513057709,
      "learning_rate": 3.648333333333334e-05,
      "loss": 0.0022,
      "step": 24330
    },
    {
      "epoch": 0.5408888888888889,
      "grad_norm": 0.3613615036010742,
      "learning_rate": 3.647777777777778e-05,
      "loss": 0.0024,
      "step": 24340
    },
    {
      "epoch": 0.5411111111111111,
      "grad_norm": 0.23441697657108307,
      "learning_rate": 3.6472222222222224e-05,
      "loss": 0.0024,
      "step": 24350
    },
    {
      "epoch": 0.5413333333333333,
      "grad_norm": 0.5011165738105774,
      "learning_rate": 3.646666666666667e-05,
      "loss": 0.0022,
      "step": 24360
    },
    {
      "epoch": 0.5415555555555556,
      "grad_norm": 0.0522368922829628,
      "learning_rate": 3.646111111111111e-05,
      "loss": 0.0029,
      "step": 24370
    },
    {
      "epoch": 0.5417777777777778,
      "grad_norm": 0.31787794828414917,
      "learning_rate": 3.645555555555556e-05,
      "loss": 0.0024,
      "step": 24380
    },
    {
      "epoch": 0.542,
      "grad_norm": 0.09600400179624557,
      "learning_rate": 3.645e-05,
      "loss": 0.0033,
      "step": 24390
    },
    {
      "epoch": 0.5422222222222223,
      "grad_norm": 0.704491913318634,
      "learning_rate": 3.644444444444445e-05,
      "loss": 0.003,
      "step": 24400
    },
    {
      "epoch": 0.5424444444444444,
      "grad_norm": 0.4521637558937073,
      "learning_rate": 3.643888888888889e-05,
      "loss": 0.0023,
      "step": 24410
    },
    {
      "epoch": 0.5426666666666666,
      "grad_norm": 0.5224320888519287,
      "learning_rate": 3.6433333333333336e-05,
      "loss": 0.0024,
      "step": 24420
    },
    {
      "epoch": 0.5428888888888889,
      "grad_norm": 0.19728676974773407,
      "learning_rate": 3.642777777777778e-05,
      "loss": 0.002,
      "step": 24430
    },
    {
      "epoch": 0.5431111111111111,
      "grad_norm": 0.32752740383148193,
      "learning_rate": 3.642222222222222e-05,
      "loss": 0.0033,
      "step": 24440
    },
    {
      "epoch": 0.5433333333333333,
      "grad_norm": 0.25107526779174805,
      "learning_rate": 3.641666666666667e-05,
      "loss": 0.0026,
      "step": 24450
    },
    {
      "epoch": 0.5435555555555556,
      "grad_norm": 0.19301722943782806,
      "learning_rate": 3.641111111111111e-05,
      "loss": 0.0026,
      "step": 24460
    },
    {
      "epoch": 0.5437777777777778,
      "grad_norm": 0.27175456285476685,
      "learning_rate": 3.640555555555556e-05,
      "loss": 0.0021,
      "step": 24470
    },
    {
      "epoch": 0.544,
      "grad_norm": 0.5406876802444458,
      "learning_rate": 3.6400000000000004e-05,
      "loss": 0.003,
      "step": 24480
    },
    {
      "epoch": 0.5442222222222223,
      "grad_norm": 0.45153316855430603,
      "learning_rate": 3.639444444444445e-05,
      "loss": 0.0024,
      "step": 24490
    },
    {
      "epoch": 0.5444444444444444,
      "grad_norm": 0.20576761662960052,
      "learning_rate": 3.638888888888889e-05,
      "loss": 0.0021,
      "step": 24500
    },
    {
      "epoch": 0.5446666666666666,
      "grad_norm": 0.0754600316286087,
      "learning_rate": 3.6383333333333335e-05,
      "loss": 0.0031,
      "step": 24510
    },
    {
      "epoch": 0.5448888888888889,
      "grad_norm": 0.09078842401504517,
      "learning_rate": 3.637777777777778e-05,
      "loss": 0.0024,
      "step": 24520
    },
    {
      "epoch": 0.5451111111111111,
      "grad_norm": 0.16931059956550598,
      "learning_rate": 3.637222222222222e-05,
      "loss": 0.0025,
      "step": 24530
    },
    {
      "epoch": 0.5453333333333333,
      "grad_norm": 0.3160090148448944,
      "learning_rate": 3.636666666666667e-05,
      "loss": 0.0026,
      "step": 24540
    },
    {
      "epoch": 0.5455555555555556,
      "grad_norm": 0.6996190547943115,
      "learning_rate": 3.6361111111111116e-05,
      "loss": 0.002,
      "step": 24550
    },
    {
      "epoch": 0.5457777777777778,
      "grad_norm": 0.08923093974590302,
      "learning_rate": 3.635555555555556e-05,
      "loss": 0.0037,
      "step": 24560
    },
    {
      "epoch": 0.546,
      "grad_norm": 0.23182818293571472,
      "learning_rate": 3.635e-05,
      "loss": 0.0024,
      "step": 24570
    },
    {
      "epoch": 0.5462222222222223,
      "grad_norm": 0.4602343440055847,
      "learning_rate": 3.6344444444444446e-05,
      "loss": 0.0021,
      "step": 24580
    },
    {
      "epoch": 0.5464444444444444,
      "grad_norm": 0.2842375636100769,
      "learning_rate": 3.633888888888889e-05,
      "loss": 0.0025,
      "step": 24590
    },
    {
      "epoch": 0.5466666666666666,
      "grad_norm": 0.49838945269584656,
      "learning_rate": 3.633333333333333e-05,
      "loss": 0.002,
      "step": 24600
    },
    {
      "epoch": 0.5468888888888889,
      "grad_norm": 0.21221207082271576,
      "learning_rate": 3.632777777777778e-05,
      "loss": 0.0031,
      "step": 24610
    },
    {
      "epoch": 0.5471111111111111,
      "grad_norm": 0.39411604404449463,
      "learning_rate": 3.632222222222223e-05,
      "loss": 0.002,
      "step": 24620
    },
    {
      "epoch": 0.5473333333333333,
      "grad_norm": 0.22271309792995453,
      "learning_rate": 3.631666666666667e-05,
      "loss": 0.0019,
      "step": 24630
    },
    {
      "epoch": 0.5475555555555556,
      "grad_norm": 0.2975344955921173,
      "learning_rate": 3.6311111111111114e-05,
      "loss": 0.0027,
      "step": 24640
    },
    {
      "epoch": 0.5477777777777778,
      "grad_norm": 0.3679812550544739,
      "learning_rate": 3.630555555555556e-05,
      "loss": 0.0024,
      "step": 24650
    },
    {
      "epoch": 0.548,
      "grad_norm": 0.351648211479187,
      "learning_rate": 3.63e-05,
      "loss": 0.0022,
      "step": 24660
    },
    {
      "epoch": 0.5482222222222223,
      "grad_norm": 0.09671230614185333,
      "learning_rate": 3.6294444444444445e-05,
      "loss": 0.0018,
      "step": 24670
    },
    {
      "epoch": 0.5484444444444444,
      "grad_norm": 0.07702530175447464,
      "learning_rate": 3.628888888888889e-05,
      "loss": 0.0024,
      "step": 24680
    },
    {
      "epoch": 0.5486666666666666,
      "grad_norm": 0.6114253997802734,
      "learning_rate": 3.628333333333334e-05,
      "loss": 0.0018,
      "step": 24690
    },
    {
      "epoch": 0.5488888888888889,
      "grad_norm": 0.6021894812583923,
      "learning_rate": 3.6277777777777776e-05,
      "loss": 0.0024,
      "step": 24700
    },
    {
      "epoch": 0.5491111111111111,
      "grad_norm": 0.6427925229072571,
      "learning_rate": 3.6272222222222226e-05,
      "loss": 0.0024,
      "step": 24710
    },
    {
      "epoch": 0.5493333333333333,
      "grad_norm": 0.232418030500412,
      "learning_rate": 3.626666666666667e-05,
      "loss": 0.0028,
      "step": 24720
    },
    {
      "epoch": 0.5495555555555556,
      "grad_norm": 0.36994868516921997,
      "learning_rate": 3.626111111111111e-05,
      "loss": 0.0022,
      "step": 24730
    },
    {
      "epoch": 0.5497777777777778,
      "grad_norm": 0.5431197881698608,
      "learning_rate": 3.625555555555556e-05,
      "loss": 0.0025,
      "step": 24740
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.3573039472103119,
      "learning_rate": 3.625e-05,
      "loss": 0.0025,
      "step": 24750
    },
    {
      "epoch": 0.5502222222222222,
      "grad_norm": 0.19408005475997925,
      "learning_rate": 3.624444444444445e-05,
      "loss": 0.0024,
      "step": 24760
    },
    {
      "epoch": 0.5504444444444444,
      "grad_norm": 0.13834188878536224,
      "learning_rate": 3.623888888888889e-05,
      "loss": 0.0023,
      "step": 24770
    },
    {
      "epoch": 0.5506666666666666,
      "grad_norm": 0.17887164652347565,
      "learning_rate": 3.623333333333334e-05,
      "loss": 0.0027,
      "step": 24780
    },
    {
      "epoch": 0.5508888888888889,
      "grad_norm": 0.40734022855758667,
      "learning_rate": 3.6227777777777774e-05,
      "loss": 0.003,
      "step": 24790
    },
    {
      "epoch": 0.5511111111111111,
      "grad_norm": 0.5231853723526001,
      "learning_rate": 3.6222222222222225e-05,
      "loss": 0.0021,
      "step": 24800
    },
    {
      "epoch": 0.5513333333333333,
      "grad_norm": 0.6015381813049316,
      "learning_rate": 3.621666666666667e-05,
      "loss": 0.0025,
      "step": 24810
    },
    {
      "epoch": 0.5515555555555556,
      "grad_norm": 0.2331266701221466,
      "learning_rate": 3.621111111111111e-05,
      "loss": 0.0024,
      "step": 24820
    },
    {
      "epoch": 0.5517777777777778,
      "grad_norm": 0.423425555229187,
      "learning_rate": 3.620555555555556e-05,
      "loss": 0.0027,
      "step": 24830
    },
    {
      "epoch": 0.552,
      "grad_norm": 0.24722068011760712,
      "learning_rate": 3.62e-05,
      "loss": 0.0025,
      "step": 24840
    },
    {
      "epoch": 0.5522222222222222,
      "grad_norm": 0.08125898241996765,
      "learning_rate": 3.619444444444445e-05,
      "loss": 0.0026,
      "step": 24850
    },
    {
      "epoch": 0.5524444444444444,
      "grad_norm": 0.8891153335571289,
      "learning_rate": 3.6188888888888886e-05,
      "loss": 0.002,
      "step": 24860
    },
    {
      "epoch": 0.5526666666666666,
      "grad_norm": 0.7116054892539978,
      "learning_rate": 3.6183333333333336e-05,
      "loss": 0.0036,
      "step": 24870
    },
    {
      "epoch": 0.5528888888888889,
      "grad_norm": 0.2685142159461975,
      "learning_rate": 3.617777777777778e-05,
      "loss": 0.0029,
      "step": 24880
    },
    {
      "epoch": 0.5531111111111111,
      "grad_norm": 0.2841261923313141,
      "learning_rate": 3.6172222222222224e-05,
      "loss": 0.0024,
      "step": 24890
    },
    {
      "epoch": 0.5533333333333333,
      "grad_norm": 0.46758612990379333,
      "learning_rate": 3.6166666666666674e-05,
      "loss": 0.002,
      "step": 24900
    },
    {
      "epoch": 0.5535555555555556,
      "grad_norm": 0.1305599957704544,
      "learning_rate": 3.616111111111111e-05,
      "loss": 0.0021,
      "step": 24910
    },
    {
      "epoch": 0.5537777777777778,
      "grad_norm": 0.14398813247680664,
      "learning_rate": 3.615555555555556e-05,
      "loss": 0.0024,
      "step": 24920
    },
    {
      "epoch": 0.554,
      "grad_norm": 0.3245605230331421,
      "learning_rate": 3.615e-05,
      "loss": 0.0025,
      "step": 24930
    },
    {
      "epoch": 0.5542222222222222,
      "grad_norm": 0.13533708453178406,
      "learning_rate": 3.614444444444445e-05,
      "loss": 0.0021,
      "step": 24940
    },
    {
      "epoch": 0.5544444444444444,
      "grad_norm": 0.2501871585845947,
      "learning_rate": 3.613888888888889e-05,
      "loss": 0.0019,
      "step": 24950
    },
    {
      "epoch": 0.5546666666666666,
      "grad_norm": 0.1190684363245964,
      "learning_rate": 3.6133333333333335e-05,
      "loss": 0.0018,
      "step": 24960
    },
    {
      "epoch": 0.5548888888888889,
      "grad_norm": 0.3295668065547943,
      "learning_rate": 3.612777777777778e-05,
      "loss": 0.0024,
      "step": 24970
    },
    {
      "epoch": 0.5551111111111111,
      "grad_norm": 0.07798333466053009,
      "learning_rate": 3.612222222222222e-05,
      "loss": 0.002,
      "step": 24980
    },
    {
      "epoch": 0.5553333333333333,
      "grad_norm": 0.4804176688194275,
      "learning_rate": 3.611666666666667e-05,
      "loss": 0.0018,
      "step": 24990
    },
    {
      "epoch": 0.5555555555555556,
      "grad_norm": 0.2366115301847458,
      "learning_rate": 3.611111111111111e-05,
      "loss": 0.0019,
      "step": 25000
    },
    {
      "epoch": 0.5557777777777778,
      "grad_norm": 0.0582069493830204,
      "learning_rate": 3.610555555555556e-05,
      "loss": 0.0027,
      "step": 25010
    },
    {
      "epoch": 0.556,
      "grad_norm": 0.4683355987071991,
      "learning_rate": 3.61e-05,
      "loss": 0.0023,
      "step": 25020
    },
    {
      "epoch": 0.5562222222222222,
      "grad_norm": 0.2703627049922943,
      "learning_rate": 3.609444444444445e-05,
      "loss": 0.0023,
      "step": 25030
    },
    {
      "epoch": 0.5564444444444444,
      "grad_norm": 0.3931564390659332,
      "learning_rate": 3.608888888888889e-05,
      "loss": 0.0041,
      "step": 25040
    },
    {
      "epoch": 0.5566666666666666,
      "grad_norm": 0.45559900999069214,
      "learning_rate": 3.6083333333333334e-05,
      "loss": 0.0023,
      "step": 25050
    },
    {
      "epoch": 0.5568888888888889,
      "grad_norm": 0.09488794207572937,
      "learning_rate": 3.607777777777778e-05,
      "loss": 0.0028,
      "step": 25060
    },
    {
      "epoch": 0.5571111111111111,
      "grad_norm": 0.4444517493247986,
      "learning_rate": 3.607222222222222e-05,
      "loss": 0.0023,
      "step": 25070
    },
    {
      "epoch": 0.5573333333333333,
      "grad_norm": 0.4344528317451477,
      "learning_rate": 3.606666666666667e-05,
      "loss": 0.0022,
      "step": 25080
    },
    {
      "epoch": 0.5575555555555556,
      "grad_norm": 0.6780358552932739,
      "learning_rate": 3.6061111111111115e-05,
      "loss": 0.0022,
      "step": 25090
    },
    {
      "epoch": 0.5577777777777778,
      "grad_norm": 0.35426008701324463,
      "learning_rate": 3.605555555555556e-05,
      "loss": 0.0024,
      "step": 25100
    },
    {
      "epoch": 0.558,
      "grad_norm": 0.2985920310020447,
      "learning_rate": 3.605e-05,
      "loss": 0.002,
      "step": 25110
    },
    {
      "epoch": 0.5582222222222222,
      "grad_norm": 0.19577781856060028,
      "learning_rate": 3.6044444444444446e-05,
      "loss": 0.0024,
      "step": 25120
    },
    {
      "epoch": 0.5584444444444444,
      "grad_norm": 0.2890640199184418,
      "learning_rate": 3.603888888888889e-05,
      "loss": 0.0042,
      "step": 25130
    },
    {
      "epoch": 0.5586666666666666,
      "grad_norm": 0.3125651776790619,
      "learning_rate": 3.603333333333333e-05,
      "loss": 0.0018,
      "step": 25140
    },
    {
      "epoch": 0.5588888888888889,
      "grad_norm": 0.28875410556793213,
      "learning_rate": 3.6027777777777776e-05,
      "loss": 0.0023,
      "step": 25150
    },
    {
      "epoch": 0.5591111111111111,
      "grad_norm": 0.2319076508283615,
      "learning_rate": 3.602222222222223e-05,
      "loss": 0.002,
      "step": 25160
    },
    {
      "epoch": 0.5593333333333333,
      "grad_norm": 0.33629530668258667,
      "learning_rate": 3.601666666666667e-05,
      "loss": 0.0024,
      "step": 25170
    },
    {
      "epoch": 0.5595555555555556,
      "grad_norm": 0.6466503143310547,
      "learning_rate": 3.6011111111111114e-05,
      "loss": 0.0025,
      "step": 25180
    },
    {
      "epoch": 0.5597777777777778,
      "grad_norm": 0.5311434864997864,
      "learning_rate": 3.600555555555556e-05,
      "loss": 0.0017,
      "step": 25190
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.2326888144016266,
      "learning_rate": 3.6e-05,
      "loss": 0.0022,
      "step": 25200
    },
    {
      "epoch": 0.5602222222222222,
      "grad_norm": 0.42030176520347595,
      "learning_rate": 3.5994444444444444e-05,
      "loss": 0.0018,
      "step": 25210
    },
    {
      "epoch": 0.5604444444444444,
      "grad_norm": 0.24138757586479187,
      "learning_rate": 3.598888888888889e-05,
      "loss": 0.0026,
      "step": 25220
    },
    {
      "epoch": 0.5606666666666666,
      "grad_norm": 0.23846830427646637,
      "learning_rate": 3.598333333333334e-05,
      "loss": 0.0028,
      "step": 25230
    },
    {
      "epoch": 0.5608888888888889,
      "grad_norm": 0.3198033273220062,
      "learning_rate": 3.5977777777777775e-05,
      "loss": 0.0027,
      "step": 25240
    },
    {
      "epoch": 0.5611111111111111,
      "grad_norm": 0.5337551236152649,
      "learning_rate": 3.5972222222222225e-05,
      "loss": 0.0018,
      "step": 25250
    },
    {
      "epoch": 0.5613333333333334,
      "grad_norm": 0.4565019905567169,
      "learning_rate": 3.596666666666667e-05,
      "loss": 0.0024,
      "step": 25260
    },
    {
      "epoch": 0.5615555555555556,
      "grad_norm": 0.10540559887886047,
      "learning_rate": 3.596111111111111e-05,
      "loss": 0.0018,
      "step": 25270
    },
    {
      "epoch": 0.5617777777777778,
      "grad_norm": 0.5467562079429626,
      "learning_rate": 3.5955555555555556e-05,
      "loss": 0.0032,
      "step": 25280
    },
    {
      "epoch": 0.562,
      "grad_norm": 0.663129985332489,
      "learning_rate": 3.595e-05,
      "loss": 0.0022,
      "step": 25290
    },
    {
      "epoch": 0.5622222222222222,
      "grad_norm": 0.3052006959915161,
      "learning_rate": 3.594444444444445e-05,
      "loss": 0.0025,
      "step": 25300
    },
    {
      "epoch": 0.5624444444444444,
      "grad_norm": 0.49527445435523987,
      "learning_rate": 3.593888888888889e-05,
      "loss": 0.0023,
      "step": 25310
    },
    {
      "epoch": 0.5626666666666666,
      "grad_norm": 0.1059482991695404,
      "learning_rate": 3.593333333333334e-05,
      "loss": 0.0019,
      "step": 25320
    },
    {
      "epoch": 0.5628888888888889,
      "grad_norm": 0.4475671052932739,
      "learning_rate": 3.5927777777777774e-05,
      "loss": 0.0022,
      "step": 25330
    },
    {
      "epoch": 0.5631111111111111,
      "grad_norm": 0.2913174331188202,
      "learning_rate": 3.5922222222222224e-05,
      "loss": 0.0024,
      "step": 25340
    },
    {
      "epoch": 0.5633333333333334,
      "grad_norm": 0.2850126326084137,
      "learning_rate": 3.591666666666667e-05,
      "loss": 0.0018,
      "step": 25350
    },
    {
      "epoch": 0.5635555555555556,
      "grad_norm": 0.09120478481054306,
      "learning_rate": 3.591111111111111e-05,
      "loss": 0.0025,
      "step": 25360
    },
    {
      "epoch": 0.5637777777777778,
      "grad_norm": 0.3790292739868164,
      "learning_rate": 3.590555555555556e-05,
      "loss": 0.0041,
      "step": 25370
    },
    {
      "epoch": 0.564,
      "grad_norm": 0.3607722222805023,
      "learning_rate": 3.59e-05,
      "loss": 0.002,
      "step": 25380
    },
    {
      "epoch": 0.5642222222222222,
      "grad_norm": 0.13402582705020905,
      "learning_rate": 3.589444444444445e-05,
      "loss": 0.002,
      "step": 25390
    },
    {
      "epoch": 0.5644444444444444,
      "grad_norm": 0.07848752290010452,
      "learning_rate": 3.5888888888888886e-05,
      "loss": 0.0023,
      "step": 25400
    },
    {
      "epoch": 0.5646666666666667,
      "grad_norm": 0.18590334057807922,
      "learning_rate": 3.5883333333333336e-05,
      "loss": 0.0018,
      "step": 25410
    },
    {
      "epoch": 0.5648888888888889,
      "grad_norm": 0.07582981884479523,
      "learning_rate": 3.587777777777778e-05,
      "loss": 0.002,
      "step": 25420
    },
    {
      "epoch": 0.5651111111111111,
      "grad_norm": 0.2234725058078766,
      "learning_rate": 3.587222222222222e-05,
      "loss": 0.0022,
      "step": 25430
    },
    {
      "epoch": 0.5653333333333334,
      "grad_norm": 0.48578277230262756,
      "learning_rate": 3.586666666666667e-05,
      "loss": 0.0019,
      "step": 25440
    },
    {
      "epoch": 0.5655555555555556,
      "grad_norm": 0.28360408544540405,
      "learning_rate": 3.586111111111111e-05,
      "loss": 0.002,
      "step": 25450
    },
    {
      "epoch": 0.5657777777777778,
      "grad_norm": 0.0957932323217392,
      "learning_rate": 3.585555555555556e-05,
      "loss": 0.0033,
      "step": 25460
    },
    {
      "epoch": 0.566,
      "grad_norm": 0.33355191349983215,
      "learning_rate": 3.585e-05,
      "loss": 0.0019,
      "step": 25470
    },
    {
      "epoch": 0.5662222222222222,
      "grad_norm": 0.21500974893569946,
      "learning_rate": 3.584444444444445e-05,
      "loss": 0.0023,
      "step": 25480
    },
    {
      "epoch": 0.5664444444444444,
      "grad_norm": 0.12478212267160416,
      "learning_rate": 3.583888888888889e-05,
      "loss": 0.0028,
      "step": 25490
    },
    {
      "epoch": 0.5666666666666667,
      "grad_norm": 0.14688485860824585,
      "learning_rate": 3.5833333333333335e-05,
      "loss": 0.002,
      "step": 25500
    },
    {
      "epoch": 0.5668888888888889,
      "grad_norm": 0.07030633836984634,
      "learning_rate": 3.582777777777778e-05,
      "loss": 0.0021,
      "step": 25510
    },
    {
      "epoch": 0.5671111111111111,
      "grad_norm": 0.1307297646999359,
      "learning_rate": 3.582222222222222e-05,
      "loss": 0.0027,
      "step": 25520
    },
    {
      "epoch": 0.5673333333333334,
      "grad_norm": 0.07230790704488754,
      "learning_rate": 3.581666666666667e-05,
      "loss": 0.0028,
      "step": 25530
    },
    {
      "epoch": 0.5675555555555556,
      "grad_norm": 0.13322383165359497,
      "learning_rate": 3.581111111111111e-05,
      "loss": 0.0019,
      "step": 25540
    },
    {
      "epoch": 0.5677777777777778,
      "grad_norm": 0.07984738796949387,
      "learning_rate": 3.580555555555556e-05,
      "loss": 0.0019,
      "step": 25550
    },
    {
      "epoch": 0.568,
      "grad_norm": 0.7791730165481567,
      "learning_rate": 3.58e-05,
      "loss": 0.0025,
      "step": 25560
    },
    {
      "epoch": 0.5682222222222222,
      "grad_norm": 0.06664686650037766,
      "learning_rate": 3.5794444444444446e-05,
      "loss": 0.0023,
      "step": 25570
    },
    {
      "epoch": 0.5684444444444444,
      "grad_norm": 0.17979376018047333,
      "learning_rate": 3.578888888888889e-05,
      "loss": 0.002,
      "step": 25580
    },
    {
      "epoch": 0.5686666666666667,
      "grad_norm": 0.3102521002292633,
      "learning_rate": 3.5783333333333333e-05,
      "loss": 0.0027,
      "step": 25590
    },
    {
      "epoch": 0.5688888888888889,
      "grad_norm": 0.6225003600120544,
      "learning_rate": 3.577777777777778e-05,
      "loss": 0.0017,
      "step": 25600
    },
    {
      "epoch": 0.5691111111111111,
      "grad_norm": 0.11233891546726227,
      "learning_rate": 3.577222222222222e-05,
      "loss": 0.0025,
      "step": 25610
    },
    {
      "epoch": 0.5693333333333334,
      "grad_norm": 0.12731260061264038,
      "learning_rate": 3.576666666666667e-05,
      "loss": 0.0017,
      "step": 25620
    },
    {
      "epoch": 0.5695555555555556,
      "grad_norm": 0.2730950713157654,
      "learning_rate": 3.5761111111111114e-05,
      "loss": 0.0017,
      "step": 25630
    },
    {
      "epoch": 0.5697777777777778,
      "grad_norm": 0.4796798825263977,
      "learning_rate": 3.575555555555556e-05,
      "loss": 0.0026,
      "step": 25640
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.35494303703308105,
      "learning_rate": 3.575e-05,
      "loss": 0.0026,
      "step": 25650
    },
    {
      "epoch": 0.5702222222222222,
      "grad_norm": 0.18743076920509338,
      "learning_rate": 3.5744444444444445e-05,
      "loss": 0.0022,
      "step": 25660
    },
    {
      "epoch": 0.5704444444444444,
      "grad_norm": 0.6581491827964783,
      "learning_rate": 3.573888888888889e-05,
      "loss": 0.0024,
      "step": 25670
    },
    {
      "epoch": 0.5706666666666667,
      "grad_norm": 0.7104784846305847,
      "learning_rate": 3.573333333333333e-05,
      "loss": 0.0022,
      "step": 25680
    },
    {
      "epoch": 0.5708888888888889,
      "grad_norm": 0.20300529897212982,
      "learning_rate": 3.572777777777778e-05,
      "loss": 0.002,
      "step": 25690
    },
    {
      "epoch": 0.5711111111111111,
      "grad_norm": 0.06185517832636833,
      "learning_rate": 3.5722222222222226e-05,
      "loss": 0.0033,
      "step": 25700
    },
    {
      "epoch": 0.5713333333333334,
      "grad_norm": 0.19471940398216248,
      "learning_rate": 3.571666666666667e-05,
      "loss": 0.0017,
      "step": 25710
    },
    {
      "epoch": 0.5715555555555556,
      "grad_norm": 0.16287820041179657,
      "learning_rate": 3.571111111111111e-05,
      "loss": 0.0023,
      "step": 25720
    },
    {
      "epoch": 0.5717777777777778,
      "grad_norm": 0.14764566719532013,
      "learning_rate": 3.570555555555556e-05,
      "loss": 0.0018,
      "step": 25730
    },
    {
      "epoch": 0.572,
      "grad_norm": 0.24493388831615448,
      "learning_rate": 3.57e-05,
      "loss": 0.0034,
      "step": 25740
    },
    {
      "epoch": 0.5722222222222222,
      "grad_norm": 0.3329247534275055,
      "learning_rate": 3.5694444444444444e-05,
      "loss": 0.0018,
      "step": 25750
    },
    {
      "epoch": 0.5724444444444444,
      "grad_norm": 0.26723507046699524,
      "learning_rate": 3.568888888888889e-05,
      "loss": 0.0021,
      "step": 25760
    },
    {
      "epoch": 0.5726666666666667,
      "grad_norm": 0.10481920093297958,
      "learning_rate": 3.568333333333334e-05,
      "loss": 0.0024,
      "step": 25770
    },
    {
      "epoch": 0.5728888888888889,
      "grad_norm": 0.08149378001689911,
      "learning_rate": 3.567777777777778e-05,
      "loss": 0.0023,
      "step": 25780
    },
    {
      "epoch": 0.5731111111111111,
      "grad_norm": 0.2667219042778015,
      "learning_rate": 3.5672222222222225e-05,
      "loss": 0.0026,
      "step": 25790
    },
    {
      "epoch": 0.5733333333333334,
      "grad_norm": 0.48043474555015564,
      "learning_rate": 3.566666666666667e-05,
      "loss": 0.0023,
      "step": 25800
    },
    {
      "epoch": 0.5735555555555556,
      "grad_norm": 0.5440641641616821,
      "learning_rate": 3.566111111111111e-05,
      "loss": 0.0026,
      "step": 25810
    },
    {
      "epoch": 0.5737777777777778,
      "grad_norm": 0.09360873699188232,
      "learning_rate": 3.5655555555555556e-05,
      "loss": 0.0024,
      "step": 25820
    },
    {
      "epoch": 0.574,
      "grad_norm": 0.3285844624042511,
      "learning_rate": 3.565e-05,
      "loss": 0.0017,
      "step": 25830
    },
    {
      "epoch": 0.5742222222222222,
      "grad_norm": 0.6177963614463806,
      "learning_rate": 3.564444444444445e-05,
      "loss": 0.0024,
      "step": 25840
    },
    {
      "epoch": 0.5744444444444444,
      "grad_norm": 0.21270960569381714,
      "learning_rate": 3.5638888888888886e-05,
      "loss": 0.0021,
      "step": 25850
    },
    {
      "epoch": 0.5746666666666667,
      "grad_norm": 0.0989011824131012,
      "learning_rate": 3.563333333333334e-05,
      "loss": 0.0022,
      "step": 25860
    },
    {
      "epoch": 0.5748888888888889,
      "grad_norm": 0.16028505563735962,
      "learning_rate": 3.562777777777778e-05,
      "loss": 0.0021,
      "step": 25870
    },
    {
      "epoch": 0.5751111111111111,
      "grad_norm": 0.1953243762254715,
      "learning_rate": 3.5622222222222224e-05,
      "loss": 0.0045,
      "step": 25880
    },
    {
      "epoch": 0.5753333333333334,
      "grad_norm": 0.11617743223905563,
      "learning_rate": 3.561666666666667e-05,
      "loss": 0.0028,
      "step": 25890
    },
    {
      "epoch": 0.5755555555555556,
      "grad_norm": 0.8433560729026794,
      "learning_rate": 3.561111111111111e-05,
      "loss": 0.0025,
      "step": 25900
    },
    {
      "epoch": 0.5757777777777778,
      "grad_norm": 0.6813468337059021,
      "learning_rate": 3.560555555555556e-05,
      "loss": 0.0019,
      "step": 25910
    },
    {
      "epoch": 0.576,
      "grad_norm": 0.3449351191520691,
      "learning_rate": 3.56e-05,
      "loss": 0.0022,
      "step": 25920
    },
    {
      "epoch": 0.5762222222222222,
      "grad_norm": 0.12461883574724197,
      "learning_rate": 3.559444444444445e-05,
      "loss": 0.0026,
      "step": 25930
    },
    {
      "epoch": 0.5764444444444444,
      "grad_norm": 0.5266870260238647,
      "learning_rate": 3.5588888888888885e-05,
      "loss": 0.0018,
      "step": 25940
    },
    {
      "epoch": 0.5766666666666667,
      "grad_norm": 0.41465383768081665,
      "learning_rate": 3.5583333333333335e-05,
      "loss": 0.0022,
      "step": 25950
    },
    {
      "epoch": 0.5768888888888889,
      "grad_norm": 0.07669936865568161,
      "learning_rate": 3.557777777777778e-05,
      "loss": 0.0018,
      "step": 25960
    },
    {
      "epoch": 0.5771111111111111,
      "grad_norm": 0.24737800657749176,
      "learning_rate": 3.557222222222222e-05,
      "loss": 0.0026,
      "step": 25970
    },
    {
      "epoch": 0.5773333333333334,
      "grad_norm": 0.10351314395666122,
      "learning_rate": 3.556666666666667e-05,
      "loss": 0.002,
      "step": 25980
    },
    {
      "epoch": 0.5775555555555556,
      "grad_norm": 0.42038971185684204,
      "learning_rate": 3.556111111111111e-05,
      "loss": 0.0028,
      "step": 25990
    },
    {
      "epoch": 0.5777777777777777,
      "grad_norm": 0.28697869181632996,
      "learning_rate": 3.555555555555556e-05,
      "loss": 0.002,
      "step": 26000
    },
    {
      "epoch": 0.578,
      "grad_norm": 0.17701584100723267,
      "learning_rate": 3.555e-05,
      "loss": 0.0023,
      "step": 26010
    },
    {
      "epoch": 0.5782222222222222,
      "grad_norm": 0.5780913233757019,
      "learning_rate": 3.554444444444445e-05,
      "loss": 0.0025,
      "step": 26020
    },
    {
      "epoch": 0.5784444444444444,
      "grad_norm": 0.3024671673774719,
      "learning_rate": 3.553888888888889e-05,
      "loss": 0.0028,
      "step": 26030
    },
    {
      "epoch": 0.5786666666666667,
      "grad_norm": 0.2442774474620819,
      "learning_rate": 3.5533333333333334e-05,
      "loss": 0.0017,
      "step": 26040
    },
    {
      "epoch": 0.5788888888888889,
      "grad_norm": 0.07983773946762085,
      "learning_rate": 3.5527777777777785e-05,
      "loss": 0.0027,
      "step": 26050
    },
    {
      "epoch": 0.5791111111111111,
      "grad_norm": 0.16627027094364166,
      "learning_rate": 3.552222222222222e-05,
      "loss": 0.0035,
      "step": 26060
    },
    {
      "epoch": 0.5793333333333334,
      "grad_norm": 0.08551205694675446,
      "learning_rate": 3.551666666666667e-05,
      "loss": 0.0023,
      "step": 26070
    },
    {
      "epoch": 0.5795555555555556,
      "grad_norm": 0.20309555530548096,
      "learning_rate": 3.551111111111111e-05,
      "loss": 0.0021,
      "step": 26080
    },
    {
      "epoch": 0.5797777777777777,
      "grad_norm": 0.24544526636600494,
      "learning_rate": 3.550555555555556e-05,
      "loss": 0.0019,
      "step": 26090
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.10582765191793442,
      "learning_rate": 3.55e-05,
      "loss": 0.0029,
      "step": 26100
    },
    {
      "epoch": 0.5802222222222222,
      "grad_norm": 0.1805872619152069,
      "learning_rate": 3.5494444444444446e-05,
      "loss": 0.0022,
      "step": 26110
    },
    {
      "epoch": 0.5804444444444444,
      "grad_norm": 0.441586434841156,
      "learning_rate": 3.548888888888889e-05,
      "loss": 0.0021,
      "step": 26120
    },
    {
      "epoch": 0.5806666666666667,
      "grad_norm": 0.13348491489887238,
      "learning_rate": 3.548333333333333e-05,
      "loss": 0.0023,
      "step": 26130
    },
    {
      "epoch": 0.5808888888888889,
      "grad_norm": 0.35740435123443604,
      "learning_rate": 3.547777777777778e-05,
      "loss": 0.0022,
      "step": 26140
    },
    {
      "epoch": 0.5811111111111111,
      "grad_norm": 0.10607189685106277,
      "learning_rate": 3.547222222222222e-05,
      "loss": 0.0028,
      "step": 26150
    },
    {
      "epoch": 0.5813333333333334,
      "grad_norm": 0.5118887424468994,
      "learning_rate": 3.546666666666667e-05,
      "loss": 0.0024,
      "step": 26160
    },
    {
      "epoch": 0.5815555555555556,
      "grad_norm": 0.3405716121196747,
      "learning_rate": 3.5461111111111114e-05,
      "loss": 0.0027,
      "step": 26170
    },
    {
      "epoch": 0.5817777777777777,
      "grad_norm": 0.4507884383201599,
      "learning_rate": 3.545555555555556e-05,
      "loss": 0.0029,
      "step": 26180
    },
    {
      "epoch": 0.582,
      "grad_norm": 0.5482387542724609,
      "learning_rate": 3.545e-05,
      "loss": 0.0019,
      "step": 26190
    },
    {
      "epoch": 0.5822222222222222,
      "grad_norm": 0.16784414649009705,
      "learning_rate": 3.5444444444444445e-05,
      "loss": 0.0024,
      "step": 26200
    },
    {
      "epoch": 0.5824444444444444,
      "grad_norm": 0.2830642759799957,
      "learning_rate": 3.543888888888889e-05,
      "loss": 0.0037,
      "step": 26210
    },
    {
      "epoch": 0.5826666666666667,
      "grad_norm": 0.46536052227020264,
      "learning_rate": 3.543333333333333e-05,
      "loss": 0.0019,
      "step": 26220
    },
    {
      "epoch": 0.5828888888888889,
      "grad_norm": 0.08962663263082504,
      "learning_rate": 3.542777777777778e-05,
      "loss": 0.0025,
      "step": 26230
    },
    {
      "epoch": 0.5831111111111111,
      "grad_norm": 0.13894279301166534,
      "learning_rate": 3.5422222222222226e-05,
      "loss": 0.0018,
      "step": 26240
    },
    {
      "epoch": 0.5833333333333334,
      "grad_norm": 0.44122153520584106,
      "learning_rate": 3.541666666666667e-05,
      "loss": 0.0022,
      "step": 26250
    },
    {
      "epoch": 0.5835555555555556,
      "grad_norm": 0.08178110420703888,
      "learning_rate": 3.541111111111111e-05,
      "loss": 0.002,
      "step": 26260
    },
    {
      "epoch": 0.5837777777777777,
      "grad_norm": 0.33944520354270935,
      "learning_rate": 3.5405555555555556e-05,
      "loss": 0.0032,
      "step": 26270
    },
    {
      "epoch": 0.584,
      "grad_norm": 0.10205402225255966,
      "learning_rate": 3.54e-05,
      "loss": 0.002,
      "step": 26280
    },
    {
      "epoch": 0.5842222222222222,
      "grad_norm": 0.12676285207271576,
      "learning_rate": 3.5394444444444443e-05,
      "loss": 0.0038,
      "step": 26290
    },
    {
      "epoch": 0.5844444444444444,
      "grad_norm": 0.15884342789649963,
      "learning_rate": 3.538888888888889e-05,
      "loss": 0.0022,
      "step": 26300
    },
    {
      "epoch": 0.5846666666666667,
      "grad_norm": 0.1992374211549759,
      "learning_rate": 3.538333333333334e-05,
      "loss": 0.0021,
      "step": 26310
    },
    {
      "epoch": 0.5848888888888889,
      "grad_norm": 0.2178030163049698,
      "learning_rate": 3.537777777777778e-05,
      "loss": 0.0025,
      "step": 26320
    },
    {
      "epoch": 0.5851111111111111,
      "grad_norm": 0.23865662515163422,
      "learning_rate": 3.5372222222222224e-05,
      "loss": 0.0023,
      "step": 26330
    },
    {
      "epoch": 0.5853333333333334,
      "grad_norm": 0.26865822076797485,
      "learning_rate": 3.536666666666667e-05,
      "loss": 0.003,
      "step": 26340
    },
    {
      "epoch": 0.5855555555555556,
      "grad_norm": 0.28419029712677,
      "learning_rate": 3.536111111111111e-05,
      "loss": 0.0024,
      "step": 26350
    },
    {
      "epoch": 0.5857777777777777,
      "grad_norm": 0.5160540342330933,
      "learning_rate": 3.5355555555555555e-05,
      "loss": 0.0023,
      "step": 26360
    },
    {
      "epoch": 0.586,
      "grad_norm": 0.3547273278236389,
      "learning_rate": 3.535e-05,
      "loss": 0.0023,
      "step": 26370
    },
    {
      "epoch": 0.5862222222222222,
      "grad_norm": 0.5213907957077026,
      "learning_rate": 3.534444444444445e-05,
      "loss": 0.003,
      "step": 26380
    },
    {
      "epoch": 0.5864444444444444,
      "grad_norm": 0.5561813712120056,
      "learning_rate": 3.5338888888888886e-05,
      "loss": 0.0023,
      "step": 26390
    },
    {
      "epoch": 0.5866666666666667,
      "grad_norm": 0.43931835889816284,
      "learning_rate": 3.5333333333333336e-05,
      "loss": 0.0022,
      "step": 26400
    },
    {
      "epoch": 0.5868888888888889,
      "grad_norm": 0.1631687432527542,
      "learning_rate": 3.532777777777778e-05,
      "loss": 0.0033,
      "step": 26410
    },
    {
      "epoch": 0.5871111111111111,
      "grad_norm": 0.29462313652038574,
      "learning_rate": 3.532222222222222e-05,
      "loss": 0.0019,
      "step": 26420
    },
    {
      "epoch": 0.5873333333333334,
      "grad_norm": 0.1396830528974533,
      "learning_rate": 3.531666666666667e-05,
      "loss": 0.0027,
      "step": 26430
    },
    {
      "epoch": 0.5875555555555556,
      "grad_norm": 0.09797034412622452,
      "learning_rate": 3.531111111111111e-05,
      "loss": 0.0016,
      "step": 26440
    },
    {
      "epoch": 0.5877777777777777,
      "grad_norm": 0.6525615453720093,
      "learning_rate": 3.530555555555556e-05,
      "loss": 0.0016,
      "step": 26450
    },
    {
      "epoch": 0.588,
      "grad_norm": 0.6036663055419922,
      "learning_rate": 3.53e-05,
      "loss": 0.0027,
      "step": 26460
    },
    {
      "epoch": 0.5882222222222222,
      "grad_norm": 0.4716874063014984,
      "learning_rate": 3.529444444444445e-05,
      "loss": 0.0021,
      "step": 26470
    },
    {
      "epoch": 0.5884444444444444,
      "grad_norm": 0.3183613717556,
      "learning_rate": 3.528888888888889e-05,
      "loss": 0.0022,
      "step": 26480
    },
    {
      "epoch": 0.5886666666666667,
      "grad_norm": 0.46856802701950073,
      "learning_rate": 3.5283333333333335e-05,
      "loss": 0.0024,
      "step": 26490
    },
    {
      "epoch": 0.5888888888888889,
      "grad_norm": 0.2950478792190552,
      "learning_rate": 3.527777777777778e-05,
      "loss": 0.0029,
      "step": 26500
    },
    {
      "epoch": 0.5891111111111111,
      "grad_norm": 0.0784696564078331,
      "learning_rate": 3.527222222222222e-05,
      "loss": 0.0023,
      "step": 26510
    },
    {
      "epoch": 0.5893333333333334,
      "grad_norm": 0.6210506558418274,
      "learning_rate": 3.526666666666667e-05,
      "loss": 0.003,
      "step": 26520
    },
    {
      "epoch": 0.5895555555555556,
      "grad_norm": 0.4115569293498993,
      "learning_rate": 3.526111111111111e-05,
      "loss": 0.0021,
      "step": 26530
    },
    {
      "epoch": 0.5897777777777777,
      "grad_norm": 0.5239027142524719,
      "learning_rate": 3.525555555555556e-05,
      "loss": 0.0033,
      "step": 26540
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.295510470867157,
      "learning_rate": 3.525e-05,
      "loss": 0.0028,
      "step": 26550
    },
    {
      "epoch": 0.5902222222222222,
      "grad_norm": 0.3984779417514801,
      "learning_rate": 3.5244444444444447e-05,
      "loss": 0.0018,
      "step": 26560
    },
    {
      "epoch": 0.5904444444444444,
      "grad_norm": 0.4407110810279846,
      "learning_rate": 3.523888888888889e-05,
      "loss": 0.0019,
      "step": 26570
    },
    {
      "epoch": 0.5906666666666667,
      "grad_norm": 0.25090494751930237,
      "learning_rate": 3.5233333333333334e-05,
      "loss": 0.002,
      "step": 26580
    },
    {
      "epoch": 0.5908888888888889,
      "grad_norm": 0.15917432308197021,
      "learning_rate": 3.5227777777777784e-05,
      "loss": 0.002,
      "step": 26590
    },
    {
      "epoch": 0.5911111111111111,
      "grad_norm": 0.27375978231430054,
      "learning_rate": 3.522222222222222e-05,
      "loss": 0.0021,
      "step": 26600
    },
    {
      "epoch": 0.5913333333333334,
      "grad_norm": 0.21940340101718903,
      "learning_rate": 3.521666666666667e-05,
      "loss": 0.002,
      "step": 26610
    },
    {
      "epoch": 0.5915555555555555,
      "grad_norm": 0.2962382137775421,
      "learning_rate": 3.5211111111111115e-05,
      "loss": 0.0018,
      "step": 26620
    },
    {
      "epoch": 0.5917777777777777,
      "grad_norm": 0.10012230277061462,
      "learning_rate": 3.520555555555556e-05,
      "loss": 0.0024,
      "step": 26630
    },
    {
      "epoch": 0.592,
      "grad_norm": 0.2321735918521881,
      "learning_rate": 3.52e-05,
      "loss": 0.0028,
      "step": 26640
    },
    {
      "epoch": 0.5922222222222222,
      "grad_norm": 0.5499452352523804,
      "learning_rate": 3.5194444444444445e-05,
      "loss": 0.0023,
      "step": 26650
    },
    {
      "epoch": 0.5924444444444444,
      "grad_norm": 0.4046456515789032,
      "learning_rate": 3.518888888888889e-05,
      "loss": 0.0019,
      "step": 26660
    },
    {
      "epoch": 0.5926666666666667,
      "grad_norm": 0.17107751965522766,
      "learning_rate": 3.518333333333333e-05,
      "loss": 0.0029,
      "step": 26670
    },
    {
      "epoch": 0.5928888888888889,
      "grad_norm": 0.09110859036445618,
      "learning_rate": 3.517777777777778e-05,
      "loss": 0.0019,
      "step": 26680
    },
    {
      "epoch": 0.5931111111111111,
      "grad_norm": 0.10435685515403748,
      "learning_rate": 3.5172222222222226e-05,
      "loss": 0.0028,
      "step": 26690
    },
    {
      "epoch": 0.5933333333333334,
      "grad_norm": 0.20211227238178253,
      "learning_rate": 3.516666666666667e-05,
      "loss": 0.0022,
      "step": 26700
    },
    {
      "epoch": 0.5935555555555555,
      "grad_norm": 0.40098893642425537,
      "learning_rate": 3.5161111111111113e-05,
      "loss": 0.0023,
      "step": 26710
    },
    {
      "epoch": 0.5937777777777777,
      "grad_norm": 0.10856063663959503,
      "learning_rate": 3.515555555555556e-05,
      "loss": 0.0022,
      "step": 26720
    },
    {
      "epoch": 0.594,
      "grad_norm": 0.1432635337114334,
      "learning_rate": 3.515e-05,
      "loss": 0.0031,
      "step": 26730
    },
    {
      "epoch": 0.5942222222222222,
      "grad_norm": 0.12492533773183823,
      "learning_rate": 3.5144444444444444e-05,
      "loss": 0.0025,
      "step": 26740
    },
    {
      "epoch": 0.5944444444444444,
      "grad_norm": 0.3088541626930237,
      "learning_rate": 3.513888888888889e-05,
      "loss": 0.0021,
      "step": 26750
    },
    {
      "epoch": 0.5946666666666667,
      "grad_norm": 0.13484293222427368,
      "learning_rate": 3.513333333333334e-05,
      "loss": 0.0024,
      "step": 26760
    },
    {
      "epoch": 0.5948888888888889,
      "grad_norm": 0.2826065123081207,
      "learning_rate": 3.512777777777778e-05,
      "loss": 0.002,
      "step": 26770
    },
    {
      "epoch": 0.5951111111111111,
      "grad_norm": 0.16712215542793274,
      "learning_rate": 3.5122222222222225e-05,
      "loss": 0.002,
      "step": 26780
    },
    {
      "epoch": 0.5953333333333334,
      "grad_norm": 0.29873237013816833,
      "learning_rate": 3.511666666666667e-05,
      "loss": 0.0023,
      "step": 26790
    },
    {
      "epoch": 0.5955555555555555,
      "grad_norm": 0.3767612874507904,
      "learning_rate": 3.511111111111111e-05,
      "loss": 0.0022,
      "step": 26800
    },
    {
      "epoch": 0.5957777777777777,
      "grad_norm": 0.12106629461050034,
      "learning_rate": 3.5105555555555556e-05,
      "loss": 0.0021,
      "step": 26810
    },
    {
      "epoch": 0.596,
      "grad_norm": 0.1535799652338028,
      "learning_rate": 3.51e-05,
      "loss": 0.0018,
      "step": 26820
    },
    {
      "epoch": 0.5962222222222222,
      "grad_norm": 0.32388684153556824,
      "learning_rate": 3.509444444444445e-05,
      "loss": 0.002,
      "step": 26830
    },
    {
      "epoch": 0.5964444444444444,
      "grad_norm": 0.9076867699623108,
      "learning_rate": 3.5088888888888886e-05,
      "loss": 0.0018,
      "step": 26840
    },
    {
      "epoch": 0.5966666666666667,
      "grad_norm": 0.15771688520908356,
      "learning_rate": 3.508333333333334e-05,
      "loss": 0.0028,
      "step": 26850
    },
    {
      "epoch": 0.5968888888888889,
      "grad_norm": 0.47942784428596497,
      "learning_rate": 3.507777777777778e-05,
      "loss": 0.0022,
      "step": 26860
    },
    {
      "epoch": 0.5971111111111111,
      "grad_norm": 0.17254583537578583,
      "learning_rate": 3.5072222222222224e-05,
      "loss": 0.0032,
      "step": 26870
    },
    {
      "epoch": 0.5973333333333334,
      "grad_norm": 0.15481354296207428,
      "learning_rate": 3.506666666666667e-05,
      "loss": 0.0032,
      "step": 26880
    },
    {
      "epoch": 0.5975555555555555,
      "grad_norm": 0.6720656752586365,
      "learning_rate": 3.506111111111111e-05,
      "loss": 0.0023,
      "step": 26890
    },
    {
      "epoch": 0.5977777777777777,
      "grad_norm": 0.08823557943105698,
      "learning_rate": 3.505555555555556e-05,
      "loss": 0.0027,
      "step": 26900
    },
    {
      "epoch": 0.598,
      "grad_norm": 0.2718970775604248,
      "learning_rate": 3.505e-05,
      "loss": 0.002,
      "step": 26910
    },
    {
      "epoch": 0.5982222222222222,
      "grad_norm": 0.13225701451301575,
      "learning_rate": 3.504444444444445e-05,
      "loss": 0.0019,
      "step": 26920
    },
    {
      "epoch": 0.5984444444444444,
      "grad_norm": 0.07724165916442871,
      "learning_rate": 3.503888888888889e-05,
      "loss": 0.0022,
      "step": 26930
    },
    {
      "epoch": 0.5986666666666667,
      "grad_norm": 0.11279663443565369,
      "learning_rate": 3.5033333333333336e-05,
      "loss": 0.002,
      "step": 26940
    },
    {
      "epoch": 0.5988888888888889,
      "grad_norm": 0.4178889989852905,
      "learning_rate": 3.502777777777778e-05,
      "loss": 0.0034,
      "step": 26950
    },
    {
      "epoch": 0.5991111111111111,
      "grad_norm": 0.2643701136112213,
      "learning_rate": 3.502222222222222e-05,
      "loss": 0.0022,
      "step": 26960
    },
    {
      "epoch": 0.5993333333333334,
      "grad_norm": 0.11786778271198273,
      "learning_rate": 3.501666666666667e-05,
      "loss": 0.0028,
      "step": 26970
    },
    {
      "epoch": 0.5995555555555555,
      "grad_norm": 0.24897834658622742,
      "learning_rate": 3.501111111111111e-05,
      "loss": 0.0021,
      "step": 26980
    },
    {
      "epoch": 0.5997777777777777,
      "grad_norm": 0.10849827527999878,
      "learning_rate": 3.500555555555556e-05,
      "loss": 0.0021,
      "step": 26990
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.09921393543481827,
      "learning_rate": 3.5e-05,
      "loss": 0.0017,
      "step": 27000
    },
    {
      "epoch": 0.6002222222222222,
      "grad_norm": 0.43800920248031616,
      "learning_rate": 3.499444444444445e-05,
      "loss": 0.0022,
      "step": 27010
    },
    {
      "epoch": 0.6004444444444444,
      "grad_norm": 0.08456627279520035,
      "learning_rate": 3.498888888888889e-05,
      "loss": 0.0018,
      "step": 27020
    },
    {
      "epoch": 0.6006666666666667,
      "grad_norm": 0.17047053575515747,
      "learning_rate": 3.4983333333333334e-05,
      "loss": 0.0021,
      "step": 27030
    },
    {
      "epoch": 0.6008888888888889,
      "grad_norm": 0.45738857984542847,
      "learning_rate": 3.4977777777777785e-05,
      "loss": 0.0024,
      "step": 27040
    },
    {
      "epoch": 0.6011111111111112,
      "grad_norm": 0.5417641401290894,
      "learning_rate": 3.497222222222222e-05,
      "loss": 0.0025,
      "step": 27050
    },
    {
      "epoch": 0.6013333333333334,
      "grad_norm": 0.06616814434528351,
      "learning_rate": 3.496666666666667e-05,
      "loss": 0.0022,
      "step": 27060
    },
    {
      "epoch": 0.6015555555555555,
      "grad_norm": 0.21464788913726807,
      "learning_rate": 3.496111111111111e-05,
      "loss": 0.0018,
      "step": 27070
    },
    {
      "epoch": 0.6017777777777777,
      "grad_norm": 0.2946099638938904,
      "learning_rate": 3.495555555555556e-05,
      "loss": 0.0023,
      "step": 27080
    },
    {
      "epoch": 0.602,
      "grad_norm": 0.20846067368984222,
      "learning_rate": 3.495e-05,
      "loss": 0.002,
      "step": 27090
    },
    {
      "epoch": 0.6022222222222222,
      "grad_norm": 0.3397079408168793,
      "learning_rate": 3.4944444444444446e-05,
      "loss": 0.0021,
      "step": 27100
    },
    {
      "epoch": 0.6024444444444444,
      "grad_norm": 0.17726409435272217,
      "learning_rate": 3.4938888888888896e-05,
      "loss": 0.002,
      "step": 27110
    },
    {
      "epoch": 0.6026666666666667,
      "grad_norm": 0.2244662493467331,
      "learning_rate": 3.493333333333333e-05,
      "loss": 0.003,
      "step": 27120
    },
    {
      "epoch": 0.6028888888888889,
      "grad_norm": 0.6682181358337402,
      "learning_rate": 3.4927777777777783e-05,
      "loss": 0.0018,
      "step": 27130
    },
    {
      "epoch": 0.6031111111111112,
      "grad_norm": 0.18593454360961914,
      "learning_rate": 3.492222222222222e-05,
      "loss": 0.0025,
      "step": 27140
    },
    {
      "epoch": 0.6033333333333334,
      "grad_norm": 0.2088160514831543,
      "learning_rate": 3.491666666666667e-05,
      "loss": 0.0017,
      "step": 27150
    },
    {
      "epoch": 0.6035555555555555,
      "grad_norm": 0.5074771046638489,
      "learning_rate": 3.4911111111111114e-05,
      "loss": 0.0027,
      "step": 27160
    },
    {
      "epoch": 0.6037777777777777,
      "grad_norm": 0.3743572235107422,
      "learning_rate": 3.490555555555556e-05,
      "loss": 0.0017,
      "step": 27170
    },
    {
      "epoch": 0.604,
      "grad_norm": 0.4216311275959015,
      "learning_rate": 3.49e-05,
      "loss": 0.0035,
      "step": 27180
    },
    {
      "epoch": 0.6042222222222222,
      "grad_norm": 0.0885172039270401,
      "learning_rate": 3.4894444444444445e-05,
      "loss": 0.0022,
      "step": 27190
    },
    {
      "epoch": 0.6044444444444445,
      "grad_norm": 0.19123446941375732,
      "learning_rate": 3.4888888888888895e-05,
      "loss": 0.0026,
      "step": 27200
    },
    {
      "epoch": 0.6046666666666667,
      "grad_norm": 0.5088837742805481,
      "learning_rate": 3.488333333333333e-05,
      "loss": 0.0027,
      "step": 27210
    },
    {
      "epoch": 0.6048888888888889,
      "grad_norm": 0.4222007989883423,
      "learning_rate": 3.487777777777778e-05,
      "loss": 0.0021,
      "step": 27220
    },
    {
      "epoch": 0.6051111111111112,
      "grad_norm": 0.3367418944835663,
      "learning_rate": 3.4872222222222226e-05,
      "loss": 0.0024,
      "step": 27230
    },
    {
      "epoch": 0.6053333333333333,
      "grad_norm": 0.2008427232503891,
      "learning_rate": 3.486666666666667e-05,
      "loss": 0.0023,
      "step": 27240
    },
    {
      "epoch": 0.6055555555555555,
      "grad_norm": 0.07766792178153992,
      "learning_rate": 3.486111111111111e-05,
      "loss": 0.0022,
      "step": 27250
    },
    {
      "epoch": 0.6057777777777777,
      "grad_norm": 0.41971564292907715,
      "learning_rate": 3.4855555555555557e-05,
      "loss": 0.0026,
      "step": 27260
    },
    {
      "epoch": 0.606,
      "grad_norm": 0.5758955478668213,
      "learning_rate": 3.485e-05,
      "loss": 0.0024,
      "step": 27270
    },
    {
      "epoch": 0.6062222222222222,
      "grad_norm": 0.5675870180130005,
      "learning_rate": 3.4844444444444444e-05,
      "loss": 0.0023,
      "step": 27280
    },
    {
      "epoch": 0.6064444444444445,
      "grad_norm": 0.3614453971385956,
      "learning_rate": 3.4838888888888894e-05,
      "loss": 0.003,
      "step": 27290
    },
    {
      "epoch": 0.6066666666666667,
      "grad_norm": 0.4374772906303406,
      "learning_rate": 3.483333333333334e-05,
      "loss": 0.0023,
      "step": 27300
    },
    {
      "epoch": 0.6068888888888889,
      "grad_norm": 0.2188768982887268,
      "learning_rate": 3.482777777777778e-05,
      "loss": 0.0022,
      "step": 27310
    },
    {
      "epoch": 0.6071111111111112,
      "grad_norm": 0.3687629997730255,
      "learning_rate": 3.4822222222222225e-05,
      "loss": 0.0022,
      "step": 27320
    },
    {
      "epoch": 0.6073333333333333,
      "grad_norm": 0.2415711134672165,
      "learning_rate": 3.481666666666667e-05,
      "loss": 0.0032,
      "step": 27330
    },
    {
      "epoch": 0.6075555555555555,
      "grad_norm": 0.3106685280799866,
      "learning_rate": 3.481111111111111e-05,
      "loss": 0.0028,
      "step": 27340
    },
    {
      "epoch": 0.6077777777777778,
      "grad_norm": 0.08761268109083176,
      "learning_rate": 3.4805555555555555e-05,
      "loss": 0.003,
      "step": 27350
    },
    {
      "epoch": 0.608,
      "grad_norm": 0.389877587556839,
      "learning_rate": 3.48e-05,
      "loss": 0.0017,
      "step": 27360
    },
    {
      "epoch": 0.6082222222222222,
      "grad_norm": 0.32850566506385803,
      "learning_rate": 3.479444444444445e-05,
      "loss": 0.0043,
      "step": 27370
    },
    {
      "epoch": 0.6084444444444445,
      "grad_norm": 0.09424516558647156,
      "learning_rate": 3.478888888888889e-05,
      "loss": 0.0022,
      "step": 27380
    },
    {
      "epoch": 0.6086666666666667,
      "grad_norm": 0.15302331745624542,
      "learning_rate": 3.4783333333333336e-05,
      "loss": 0.0027,
      "step": 27390
    },
    {
      "epoch": 0.6088888888888889,
      "grad_norm": 0.772813081741333,
      "learning_rate": 3.477777777777778e-05,
      "loss": 0.0024,
      "step": 27400
    },
    {
      "epoch": 0.6091111111111112,
      "grad_norm": 0.06203502416610718,
      "learning_rate": 3.4772222222222223e-05,
      "loss": 0.0019,
      "step": 27410
    },
    {
      "epoch": 0.6093333333333333,
      "grad_norm": 0.16784292459487915,
      "learning_rate": 3.476666666666667e-05,
      "loss": 0.0019,
      "step": 27420
    },
    {
      "epoch": 0.6095555555555555,
      "grad_norm": 0.17304730415344238,
      "learning_rate": 3.476111111111111e-05,
      "loss": 0.0024,
      "step": 27430
    },
    {
      "epoch": 0.6097777777777778,
      "grad_norm": 0.1019565686583519,
      "learning_rate": 3.475555555555556e-05,
      "loss": 0.002,
      "step": 27440
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.21673741936683655,
      "learning_rate": 3.475e-05,
      "loss": 0.0025,
      "step": 27450
    },
    {
      "epoch": 0.6102222222222222,
      "grad_norm": 0.4747334420681,
      "learning_rate": 3.474444444444445e-05,
      "loss": 0.0021,
      "step": 27460
    },
    {
      "epoch": 0.6104444444444445,
      "grad_norm": 0.15987111628055573,
      "learning_rate": 3.473888888888889e-05,
      "loss": 0.002,
      "step": 27470
    },
    {
      "epoch": 0.6106666666666667,
      "grad_norm": 0.42693987488746643,
      "learning_rate": 3.4733333333333335e-05,
      "loss": 0.0022,
      "step": 27480
    },
    {
      "epoch": 0.6108888888888889,
      "grad_norm": 0.29962238669395447,
      "learning_rate": 3.472777777777778e-05,
      "loss": 0.002,
      "step": 27490
    },
    {
      "epoch": 0.6111111111111112,
      "grad_norm": 0.07874007523059845,
      "learning_rate": 3.472222222222222e-05,
      "loss": 0.0019,
      "step": 27500
    },
    {
      "epoch": 0.6113333333333333,
      "grad_norm": 0.19083982706069946,
      "learning_rate": 3.471666666666667e-05,
      "loss": 0.0023,
      "step": 27510
    },
    {
      "epoch": 0.6115555555555555,
      "grad_norm": 0.38875842094421387,
      "learning_rate": 3.471111111111111e-05,
      "loss": 0.0033,
      "step": 27520
    },
    {
      "epoch": 0.6117777777777778,
      "grad_norm": 0.21499088406562805,
      "learning_rate": 3.470555555555556e-05,
      "loss": 0.0019,
      "step": 27530
    },
    {
      "epoch": 0.612,
      "grad_norm": 0.2919909656047821,
      "learning_rate": 3.4699999999999996e-05,
      "loss": 0.002,
      "step": 27540
    },
    {
      "epoch": 0.6122222222222222,
      "grad_norm": 0.12078451365232468,
      "learning_rate": 3.469444444444445e-05,
      "loss": 0.0023,
      "step": 27550
    },
    {
      "epoch": 0.6124444444444445,
      "grad_norm": 0.20517772436141968,
      "learning_rate": 3.468888888888889e-05,
      "loss": 0.0018,
      "step": 27560
    },
    {
      "epoch": 0.6126666666666667,
      "grad_norm": 0.18608538806438446,
      "learning_rate": 3.4683333333333334e-05,
      "loss": 0.003,
      "step": 27570
    },
    {
      "epoch": 0.6128888888888889,
      "grad_norm": 0.15302380919456482,
      "learning_rate": 3.4677777777777784e-05,
      "loss": 0.0021,
      "step": 27580
    },
    {
      "epoch": 0.6131111111111112,
      "grad_norm": 0.09377845376729965,
      "learning_rate": 3.467222222222222e-05,
      "loss": 0.0022,
      "step": 27590
    },
    {
      "epoch": 0.6133333333333333,
      "grad_norm": 0.4536823332309723,
      "learning_rate": 3.466666666666667e-05,
      "loss": 0.0028,
      "step": 27600
    },
    {
      "epoch": 0.6135555555555555,
      "grad_norm": 0.1642480492591858,
      "learning_rate": 3.466111111111111e-05,
      "loss": 0.0019,
      "step": 27610
    },
    {
      "epoch": 0.6137777777777778,
      "grad_norm": 0.2709124684333801,
      "learning_rate": 3.465555555555556e-05,
      "loss": 0.0026,
      "step": 27620
    },
    {
      "epoch": 0.614,
      "grad_norm": 0.17163345217704773,
      "learning_rate": 3.465e-05,
      "loss": 0.0031,
      "step": 27630
    },
    {
      "epoch": 0.6142222222222222,
      "grad_norm": 0.1031246930360794,
      "learning_rate": 3.4644444444444446e-05,
      "loss": 0.0023,
      "step": 27640
    },
    {
      "epoch": 0.6144444444444445,
      "grad_norm": 0.17266996204853058,
      "learning_rate": 3.4638888888888896e-05,
      "loss": 0.0018,
      "step": 27650
    },
    {
      "epoch": 0.6146666666666667,
      "grad_norm": 0.320008248090744,
      "learning_rate": 3.463333333333333e-05,
      "loss": 0.0022,
      "step": 27660
    },
    {
      "epoch": 0.6148888888888889,
      "grad_norm": 0.16524828970432281,
      "learning_rate": 3.462777777777778e-05,
      "loss": 0.0028,
      "step": 27670
    },
    {
      "epoch": 0.6151111111111112,
      "grad_norm": 0.1591988056898117,
      "learning_rate": 3.462222222222222e-05,
      "loss": 0.0029,
      "step": 27680
    },
    {
      "epoch": 0.6153333333333333,
      "grad_norm": 0.3716620206832886,
      "learning_rate": 3.461666666666667e-05,
      "loss": 0.002,
      "step": 27690
    },
    {
      "epoch": 0.6155555555555555,
      "grad_norm": 0.6770825982093811,
      "learning_rate": 3.4611111111111114e-05,
      "loss": 0.0021,
      "step": 27700
    },
    {
      "epoch": 0.6157777777777778,
      "grad_norm": 0.4958629608154297,
      "learning_rate": 3.460555555555556e-05,
      "loss": 0.0021,
      "step": 27710
    },
    {
      "epoch": 0.616,
      "grad_norm": 0.34433889389038086,
      "learning_rate": 3.46e-05,
      "loss": 0.0019,
      "step": 27720
    },
    {
      "epoch": 0.6162222222222222,
      "grad_norm": 0.22424428164958954,
      "learning_rate": 3.4594444444444444e-05,
      "loss": 0.0026,
      "step": 27730
    },
    {
      "epoch": 0.6164444444444445,
      "grad_norm": 0.46442872285842896,
      "learning_rate": 3.4588888888888895e-05,
      "loss": 0.0037,
      "step": 27740
    },
    {
      "epoch": 0.6166666666666667,
      "grad_norm": 0.09409242123365402,
      "learning_rate": 3.458333333333333e-05,
      "loss": 0.0021,
      "step": 27750
    },
    {
      "epoch": 0.6168888888888889,
      "grad_norm": 0.30711519718170166,
      "learning_rate": 3.457777777777778e-05,
      "loss": 0.0019,
      "step": 27760
    },
    {
      "epoch": 0.6171111111111112,
      "grad_norm": 0.4499870538711548,
      "learning_rate": 3.4572222222222225e-05,
      "loss": 0.003,
      "step": 27770
    },
    {
      "epoch": 0.6173333333333333,
      "grad_norm": 0.46583813428878784,
      "learning_rate": 3.456666666666667e-05,
      "loss": 0.0022,
      "step": 27780
    },
    {
      "epoch": 0.6175555555555555,
      "grad_norm": 0.0364643894135952,
      "learning_rate": 3.456111111111111e-05,
      "loss": 0.0018,
      "step": 27790
    },
    {
      "epoch": 0.6177777777777778,
      "grad_norm": 0.08570998162031174,
      "learning_rate": 3.4555555555555556e-05,
      "loss": 0.0018,
      "step": 27800
    },
    {
      "epoch": 0.618,
      "grad_norm": 0.13011662662029266,
      "learning_rate": 3.455e-05,
      "loss": 0.0021,
      "step": 27810
    },
    {
      "epoch": 0.6182222222222222,
      "grad_norm": 0.135329008102417,
      "learning_rate": 3.454444444444444e-05,
      "loss": 0.0029,
      "step": 27820
    },
    {
      "epoch": 0.6184444444444445,
      "grad_norm": 0.23299509286880493,
      "learning_rate": 3.4538888888888893e-05,
      "loss": 0.0024,
      "step": 27830
    },
    {
      "epoch": 0.6186666666666667,
      "grad_norm": 0.3872945010662079,
      "learning_rate": 3.453333333333334e-05,
      "loss": 0.0026,
      "step": 27840
    },
    {
      "epoch": 0.6188888888888889,
      "grad_norm": 0.1939551681280136,
      "learning_rate": 3.452777777777778e-05,
      "loss": 0.0022,
      "step": 27850
    },
    {
      "epoch": 0.6191111111111111,
      "grad_norm": 0.21131610870361328,
      "learning_rate": 3.4522222222222224e-05,
      "loss": 0.0023,
      "step": 27860
    },
    {
      "epoch": 0.6193333333333333,
      "grad_norm": 0.8171724677085876,
      "learning_rate": 3.451666666666667e-05,
      "loss": 0.0031,
      "step": 27870
    },
    {
      "epoch": 0.6195555555555555,
      "grad_norm": 0.3223678469657898,
      "learning_rate": 3.451111111111111e-05,
      "loss": 0.0021,
      "step": 27880
    },
    {
      "epoch": 0.6197777777777778,
      "grad_norm": 0.389254629611969,
      "learning_rate": 3.4505555555555555e-05,
      "loss": 0.0022,
      "step": 27890
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.13759878277778625,
      "learning_rate": 3.45e-05,
      "loss": 0.0029,
      "step": 27900
    },
    {
      "epoch": 0.6202222222222222,
      "grad_norm": 0.21946415305137634,
      "learning_rate": 3.449444444444445e-05,
      "loss": 0.0036,
      "step": 27910
    },
    {
      "epoch": 0.6204444444444445,
      "grad_norm": 0.08809098601341248,
      "learning_rate": 3.448888888888889e-05,
      "loss": 0.0025,
      "step": 27920
    },
    {
      "epoch": 0.6206666666666667,
      "grad_norm": 0.3609403073787689,
      "learning_rate": 3.4483333333333336e-05,
      "loss": 0.0022,
      "step": 27930
    },
    {
      "epoch": 0.6208888888888889,
      "grad_norm": 0.15472054481506348,
      "learning_rate": 3.447777777777778e-05,
      "loss": 0.0021,
      "step": 27940
    },
    {
      "epoch": 0.6211111111111111,
      "grad_norm": 0.2257886826992035,
      "learning_rate": 3.447222222222222e-05,
      "loss": 0.0023,
      "step": 27950
    },
    {
      "epoch": 0.6213333333333333,
      "grad_norm": 0.1314014047384262,
      "learning_rate": 3.4466666666666666e-05,
      "loss": 0.003,
      "step": 27960
    },
    {
      "epoch": 0.6215555555555555,
      "grad_norm": 0.16366660594940186,
      "learning_rate": 3.446111111111111e-05,
      "loss": 0.0024,
      "step": 27970
    },
    {
      "epoch": 0.6217777777777778,
      "grad_norm": 0.1529305875301361,
      "learning_rate": 3.445555555555556e-05,
      "loss": 0.003,
      "step": 27980
    },
    {
      "epoch": 0.622,
      "grad_norm": 0.07467440515756607,
      "learning_rate": 3.445e-05,
      "loss": 0.0026,
      "step": 27990
    },
    {
      "epoch": 0.6222222222222222,
      "grad_norm": 0.40792545676231384,
      "learning_rate": 3.444444444444445e-05,
      "loss": 0.0027,
      "step": 28000
    },
    {
      "epoch": 0.6224444444444445,
      "grad_norm": 0.6897853016853333,
      "learning_rate": 3.443888888888889e-05,
      "loss": 0.002,
      "step": 28010
    },
    {
      "epoch": 0.6226666666666667,
      "grad_norm": 0.4184873402118683,
      "learning_rate": 3.4433333333333335e-05,
      "loss": 0.0021,
      "step": 28020
    },
    {
      "epoch": 0.6228888888888889,
      "grad_norm": 0.15957111120224,
      "learning_rate": 3.442777777777778e-05,
      "loss": 0.0027,
      "step": 28030
    },
    {
      "epoch": 0.6231111111111111,
      "grad_norm": 0.31774866580963135,
      "learning_rate": 3.442222222222222e-05,
      "loss": 0.0018,
      "step": 28040
    },
    {
      "epoch": 0.6233333333333333,
      "grad_norm": 0.5666636228561401,
      "learning_rate": 3.441666666666667e-05,
      "loss": 0.0019,
      "step": 28050
    },
    {
      "epoch": 0.6235555555555555,
      "grad_norm": 0.09904655814170837,
      "learning_rate": 3.441111111111111e-05,
      "loss": 0.0021,
      "step": 28060
    },
    {
      "epoch": 0.6237777777777778,
      "grad_norm": 0.36370569467544556,
      "learning_rate": 3.440555555555556e-05,
      "loss": 0.0018,
      "step": 28070
    },
    {
      "epoch": 0.624,
      "grad_norm": 0.6759033799171448,
      "learning_rate": 3.4399999999999996e-05,
      "loss": 0.0022,
      "step": 28080
    },
    {
      "epoch": 0.6242222222222222,
      "grad_norm": 0.2882315516471863,
      "learning_rate": 3.4394444444444446e-05,
      "loss": 0.0028,
      "step": 28090
    },
    {
      "epoch": 0.6244444444444445,
      "grad_norm": 0.1014263704419136,
      "learning_rate": 3.438888888888889e-05,
      "loss": 0.0022,
      "step": 28100
    },
    {
      "epoch": 0.6246666666666667,
      "grad_norm": 0.2641058564186096,
      "learning_rate": 3.438333333333333e-05,
      "loss": 0.0022,
      "step": 28110
    },
    {
      "epoch": 0.6248888888888889,
      "grad_norm": 0.3031455874443054,
      "learning_rate": 3.4377777777777784e-05,
      "loss": 0.0019,
      "step": 28120
    },
    {
      "epoch": 0.6251111111111111,
      "grad_norm": 0.6153059005737305,
      "learning_rate": 3.437222222222222e-05,
      "loss": 0.0021,
      "step": 28130
    },
    {
      "epoch": 0.6253333333333333,
      "grad_norm": 0.08833468705415726,
      "learning_rate": 3.436666666666667e-05,
      "loss": 0.0023,
      "step": 28140
    },
    {
      "epoch": 0.6255555555555555,
      "grad_norm": 0.16213490068912506,
      "learning_rate": 3.436111111111111e-05,
      "loss": 0.0026,
      "step": 28150
    },
    {
      "epoch": 0.6257777777777778,
      "grad_norm": 0.5569473505020142,
      "learning_rate": 3.435555555555556e-05,
      "loss": 0.002,
      "step": 28160
    },
    {
      "epoch": 0.626,
      "grad_norm": 0.5511751770973206,
      "learning_rate": 3.435e-05,
      "loss": 0.0022,
      "step": 28170
    },
    {
      "epoch": 0.6262222222222222,
      "grad_norm": 0.26898932456970215,
      "learning_rate": 3.4344444444444445e-05,
      "loss": 0.0027,
      "step": 28180
    },
    {
      "epoch": 0.6264444444444445,
      "grad_norm": 0.5547047853469849,
      "learning_rate": 3.4338888888888895e-05,
      "loss": 0.0025,
      "step": 28190
    },
    {
      "epoch": 0.6266666666666667,
      "grad_norm": 0.16968680918216705,
      "learning_rate": 3.433333333333333e-05,
      "loss": 0.0031,
      "step": 28200
    },
    {
      "epoch": 0.6268888888888889,
      "grad_norm": 0.13024447858333588,
      "learning_rate": 3.432777777777778e-05,
      "loss": 0.0035,
      "step": 28210
    },
    {
      "epoch": 0.6271111111111111,
      "grad_norm": 0.13652993738651276,
      "learning_rate": 3.432222222222222e-05,
      "loss": 0.002,
      "step": 28220
    },
    {
      "epoch": 0.6273333333333333,
      "grad_norm": 0.5442215204238892,
      "learning_rate": 3.431666666666667e-05,
      "loss": 0.0022,
      "step": 28230
    },
    {
      "epoch": 0.6275555555555555,
      "grad_norm": 0.05944433808326721,
      "learning_rate": 3.431111111111111e-05,
      "loss": 0.0023,
      "step": 28240
    },
    {
      "epoch": 0.6277777777777778,
      "grad_norm": 0.6486048698425293,
      "learning_rate": 3.430555555555556e-05,
      "loss": 0.0028,
      "step": 28250
    },
    {
      "epoch": 0.628,
      "grad_norm": 0.3294203579425812,
      "learning_rate": 3.430000000000001e-05,
      "loss": 0.0019,
      "step": 28260
    },
    {
      "epoch": 0.6282222222222222,
      "grad_norm": 0.15311191976070404,
      "learning_rate": 3.4294444444444444e-05,
      "loss": 0.0021,
      "step": 28270
    },
    {
      "epoch": 0.6284444444444445,
      "grad_norm": 0.6075184941291809,
      "learning_rate": 3.4288888888888894e-05,
      "loss": 0.0023,
      "step": 28280
    },
    {
      "epoch": 0.6286666666666667,
      "grad_norm": 0.3028842806816101,
      "learning_rate": 3.428333333333333e-05,
      "loss": 0.0028,
      "step": 28290
    },
    {
      "epoch": 0.6288888888888889,
      "grad_norm": 0.07845032215118408,
      "learning_rate": 3.427777777777778e-05,
      "loss": 0.0026,
      "step": 28300
    },
    {
      "epoch": 0.6291111111111111,
      "grad_norm": 0.4643513262271881,
      "learning_rate": 3.4272222222222225e-05,
      "loss": 0.0029,
      "step": 28310
    },
    {
      "epoch": 0.6293333333333333,
      "grad_norm": 0.6421661972999573,
      "learning_rate": 3.426666666666667e-05,
      "loss": 0.0021,
      "step": 28320
    },
    {
      "epoch": 0.6295555555555555,
      "grad_norm": 0.4469126760959625,
      "learning_rate": 3.426111111111111e-05,
      "loss": 0.0022,
      "step": 28330
    },
    {
      "epoch": 0.6297777777777778,
      "grad_norm": 0.10321515798568726,
      "learning_rate": 3.4255555555555555e-05,
      "loss": 0.0021,
      "step": 28340
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.2225293070077896,
      "learning_rate": 3.4250000000000006e-05,
      "loss": 0.0027,
      "step": 28350
    },
    {
      "epoch": 0.6302222222222222,
      "grad_norm": 0.09972848743200302,
      "learning_rate": 3.424444444444444e-05,
      "loss": 0.0028,
      "step": 28360
    },
    {
      "epoch": 0.6304444444444445,
      "grad_norm": 0.29018262028694153,
      "learning_rate": 3.423888888888889e-05,
      "loss": 0.0021,
      "step": 28370
    },
    {
      "epoch": 0.6306666666666667,
      "grad_norm": 0.1874905526638031,
      "learning_rate": 3.4233333333333336e-05,
      "loss": 0.0016,
      "step": 28380
    },
    {
      "epoch": 0.6308888888888889,
      "grad_norm": 0.37211233377456665,
      "learning_rate": 3.422777777777778e-05,
      "loss": 0.0022,
      "step": 28390
    },
    {
      "epoch": 0.6311111111111111,
      "grad_norm": 0.056376103311777115,
      "learning_rate": 3.4222222222222224e-05,
      "loss": 0.0023,
      "step": 28400
    },
    {
      "epoch": 0.6313333333333333,
      "grad_norm": 0.4378756582736969,
      "learning_rate": 3.421666666666667e-05,
      "loss": 0.002,
      "step": 28410
    },
    {
      "epoch": 0.6315555555555555,
      "grad_norm": 0.34473004937171936,
      "learning_rate": 3.421111111111111e-05,
      "loss": 0.0021,
      "step": 28420
    },
    {
      "epoch": 0.6317777777777778,
      "grad_norm": 0.703050971031189,
      "learning_rate": 3.4205555555555554e-05,
      "loss": 0.0022,
      "step": 28430
    },
    {
      "epoch": 0.632,
      "grad_norm": 0.09387332201004028,
      "learning_rate": 3.4200000000000005e-05,
      "loss": 0.0018,
      "step": 28440
    },
    {
      "epoch": 0.6322222222222222,
      "grad_norm": 0.1972781866788864,
      "learning_rate": 3.419444444444445e-05,
      "loss": 0.0022,
      "step": 28450
    },
    {
      "epoch": 0.6324444444444445,
      "grad_norm": 0.17838647961616516,
      "learning_rate": 3.418888888888889e-05,
      "loss": 0.002,
      "step": 28460
    },
    {
      "epoch": 0.6326666666666667,
      "grad_norm": 0.09340766072273254,
      "learning_rate": 3.4183333333333335e-05,
      "loss": 0.002,
      "step": 28470
    },
    {
      "epoch": 0.6328888888888888,
      "grad_norm": 0.4460710883140564,
      "learning_rate": 3.417777777777778e-05,
      "loss": 0.0022,
      "step": 28480
    },
    {
      "epoch": 0.6331111111111111,
      "grad_norm": 0.051866717636585236,
      "learning_rate": 3.417222222222222e-05,
      "loss": 0.0029,
      "step": 28490
    },
    {
      "epoch": 0.6333333333333333,
      "grad_norm": 0.23392459750175476,
      "learning_rate": 3.4166666666666666e-05,
      "loss": 0.0023,
      "step": 28500
    },
    {
      "epoch": 0.6335555555555555,
      "grad_norm": 0.0850013941526413,
      "learning_rate": 3.416111111111111e-05,
      "loss": 0.003,
      "step": 28510
    },
    {
      "epoch": 0.6337777777777778,
      "grad_norm": 0.14853926002979279,
      "learning_rate": 3.415555555555556e-05,
      "loss": 0.0022,
      "step": 28520
    },
    {
      "epoch": 0.634,
      "grad_norm": 0.05862058326601982,
      "learning_rate": 3.415e-05,
      "loss": 0.002,
      "step": 28530
    },
    {
      "epoch": 0.6342222222222222,
      "grad_norm": 0.5974919199943542,
      "learning_rate": 3.414444444444445e-05,
      "loss": 0.0026,
      "step": 28540
    },
    {
      "epoch": 0.6344444444444445,
      "grad_norm": 0.15188561379909515,
      "learning_rate": 3.413888888888889e-05,
      "loss": 0.0024,
      "step": 28550
    },
    {
      "epoch": 0.6346666666666667,
      "grad_norm": 0.18950755894184113,
      "learning_rate": 3.4133333333333334e-05,
      "loss": 0.0019,
      "step": 28560
    },
    {
      "epoch": 0.6348888888888888,
      "grad_norm": 0.32337528467178345,
      "learning_rate": 3.412777777777778e-05,
      "loss": 0.0029,
      "step": 28570
    },
    {
      "epoch": 0.6351111111111111,
      "grad_norm": 0.057880401611328125,
      "learning_rate": 3.412222222222222e-05,
      "loss": 0.0019,
      "step": 28580
    },
    {
      "epoch": 0.6353333333333333,
      "grad_norm": 0.19142331182956696,
      "learning_rate": 3.411666666666667e-05,
      "loss": 0.0021,
      "step": 28590
    },
    {
      "epoch": 0.6355555555555555,
      "grad_norm": 0.09181326627731323,
      "learning_rate": 3.411111111111111e-05,
      "loss": 0.0018,
      "step": 28600
    },
    {
      "epoch": 0.6357777777777778,
      "grad_norm": 0.1533580720424652,
      "learning_rate": 3.410555555555556e-05,
      "loss": 0.0018,
      "step": 28610
    },
    {
      "epoch": 0.636,
      "grad_norm": 0.32797130942344666,
      "learning_rate": 3.41e-05,
      "loss": 0.0023,
      "step": 28620
    },
    {
      "epoch": 0.6362222222222222,
      "grad_norm": 0.17967984080314636,
      "learning_rate": 3.4094444444444446e-05,
      "loss": 0.0021,
      "step": 28630
    },
    {
      "epoch": 0.6364444444444445,
      "grad_norm": 0.16920305788516998,
      "learning_rate": 3.408888888888889e-05,
      "loss": 0.0017,
      "step": 28640
    },
    {
      "epoch": 0.6366666666666667,
      "grad_norm": 0.20262256264686584,
      "learning_rate": 3.408333333333333e-05,
      "loss": 0.002,
      "step": 28650
    },
    {
      "epoch": 0.6368888888888888,
      "grad_norm": 0.14765408635139465,
      "learning_rate": 3.407777777777778e-05,
      "loss": 0.0018,
      "step": 28660
    },
    {
      "epoch": 0.6371111111111111,
      "grad_norm": 0.2763088643550873,
      "learning_rate": 3.407222222222222e-05,
      "loss": 0.0019,
      "step": 28670
    },
    {
      "epoch": 0.6373333333333333,
      "grad_norm": 0.2507980167865753,
      "learning_rate": 3.406666666666667e-05,
      "loss": 0.0018,
      "step": 28680
    },
    {
      "epoch": 0.6375555555555555,
      "grad_norm": 0.2830970287322998,
      "learning_rate": 3.406111111111111e-05,
      "loss": 0.0018,
      "step": 28690
    },
    {
      "epoch": 0.6377777777777778,
      "grad_norm": 0.1317235678434372,
      "learning_rate": 3.405555555555556e-05,
      "loss": 0.0024,
      "step": 28700
    },
    {
      "epoch": 0.638,
      "grad_norm": 0.2518744170665741,
      "learning_rate": 3.405e-05,
      "loss": 0.0028,
      "step": 28710
    },
    {
      "epoch": 0.6382222222222222,
      "grad_norm": 0.6279296278953552,
      "learning_rate": 3.4044444444444445e-05,
      "loss": 0.0028,
      "step": 28720
    },
    {
      "epoch": 0.6384444444444445,
      "grad_norm": 0.1969311684370041,
      "learning_rate": 3.4038888888888895e-05,
      "loss": 0.0021,
      "step": 28730
    },
    {
      "epoch": 0.6386666666666667,
      "grad_norm": 0.10450521111488342,
      "learning_rate": 3.403333333333333e-05,
      "loss": 0.0029,
      "step": 28740
    },
    {
      "epoch": 0.6388888888888888,
      "grad_norm": 0.061946768313646317,
      "learning_rate": 3.402777777777778e-05,
      "loss": 0.0028,
      "step": 28750
    },
    {
      "epoch": 0.6391111111111111,
      "grad_norm": 0.5071356892585754,
      "learning_rate": 3.402222222222222e-05,
      "loss": 0.0026,
      "step": 28760
    },
    {
      "epoch": 0.6393333333333333,
      "grad_norm": 0.19473066926002502,
      "learning_rate": 3.401666666666667e-05,
      "loss": 0.002,
      "step": 28770
    },
    {
      "epoch": 0.6395555555555555,
      "grad_norm": 0.3626687824726105,
      "learning_rate": 3.401111111111111e-05,
      "loss": 0.0032,
      "step": 28780
    },
    {
      "epoch": 0.6397777777777778,
      "grad_norm": 0.10531602799892426,
      "learning_rate": 3.4005555555555556e-05,
      "loss": 0.0021,
      "step": 28790
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.1530209183692932,
      "learning_rate": 3.4000000000000007e-05,
      "loss": 0.0029,
      "step": 28800
    },
    {
      "epoch": 0.6402222222222222,
      "grad_norm": 0.2896745502948761,
      "learning_rate": 3.399444444444444e-05,
      "loss": 0.0022,
      "step": 28810
    },
    {
      "epoch": 0.6404444444444445,
      "grad_norm": 0.3633266091346741,
      "learning_rate": 3.3988888888888894e-05,
      "loss": 0.0042,
      "step": 28820
    },
    {
      "epoch": 0.6406666666666667,
      "grad_norm": 0.8099431991577148,
      "learning_rate": 3.398333333333333e-05,
      "loss": 0.0022,
      "step": 28830
    },
    {
      "epoch": 0.6408888888888888,
      "grad_norm": 0.2082391232252121,
      "learning_rate": 3.397777777777778e-05,
      "loss": 0.0019,
      "step": 28840
    },
    {
      "epoch": 0.6411111111111111,
      "grad_norm": 0.07319585978984833,
      "learning_rate": 3.3972222222222224e-05,
      "loss": 0.002,
      "step": 28850
    },
    {
      "epoch": 0.6413333333333333,
      "grad_norm": 0.5006402134895325,
      "learning_rate": 3.396666666666667e-05,
      "loss": 0.0029,
      "step": 28860
    },
    {
      "epoch": 0.6415555555555555,
      "grad_norm": 0.5979799628257751,
      "learning_rate": 3.396111111111111e-05,
      "loss": 0.002,
      "step": 28870
    },
    {
      "epoch": 0.6417777777777778,
      "grad_norm": 0.34208545088768005,
      "learning_rate": 3.3955555555555555e-05,
      "loss": 0.0022,
      "step": 28880
    },
    {
      "epoch": 0.642,
      "grad_norm": 0.32211461663246155,
      "learning_rate": 3.3950000000000005e-05,
      "loss": 0.002,
      "step": 28890
    },
    {
      "epoch": 0.6422222222222222,
      "grad_norm": 0.07284309715032578,
      "learning_rate": 3.394444444444444e-05,
      "loss": 0.0035,
      "step": 28900
    },
    {
      "epoch": 0.6424444444444445,
      "grad_norm": 0.2744379937648773,
      "learning_rate": 3.393888888888889e-05,
      "loss": 0.0022,
      "step": 28910
    },
    {
      "epoch": 0.6426666666666667,
      "grad_norm": 0.08465652912855148,
      "learning_rate": 3.3933333333333336e-05,
      "loss": 0.0025,
      "step": 28920
    },
    {
      "epoch": 0.6428888888888888,
      "grad_norm": 0.45649200677871704,
      "learning_rate": 3.392777777777778e-05,
      "loss": 0.0019,
      "step": 28930
    },
    {
      "epoch": 0.6431111111111111,
      "grad_norm": 0.4019193649291992,
      "learning_rate": 3.392222222222222e-05,
      "loss": 0.0028,
      "step": 28940
    },
    {
      "epoch": 0.6433333333333333,
      "grad_norm": 0.18365085124969482,
      "learning_rate": 3.391666666666667e-05,
      "loss": 0.0032,
      "step": 28950
    },
    {
      "epoch": 0.6435555555555555,
      "grad_norm": 0.46101561188697815,
      "learning_rate": 3.391111111111111e-05,
      "loss": 0.0018,
      "step": 28960
    },
    {
      "epoch": 0.6437777777777778,
      "grad_norm": 0.3772488534450531,
      "learning_rate": 3.3905555555555554e-05,
      "loss": 0.0029,
      "step": 28970
    },
    {
      "epoch": 0.644,
      "grad_norm": 0.3215281069278717,
      "learning_rate": 3.3900000000000004e-05,
      "loss": 0.0018,
      "step": 28980
    },
    {
      "epoch": 0.6442222222222223,
      "grad_norm": 0.5973343849182129,
      "learning_rate": 3.389444444444445e-05,
      "loss": 0.002,
      "step": 28990
    },
    {
      "epoch": 0.6444444444444445,
      "grad_norm": 0.405922532081604,
      "learning_rate": 3.388888888888889e-05,
      "loss": 0.0022,
      "step": 29000
    },
    {
      "epoch": 0.6446666666666667,
      "grad_norm": 0.710139811038971,
      "learning_rate": 3.3883333333333335e-05,
      "loss": 0.0026,
      "step": 29010
    },
    {
      "epoch": 0.6448888888888888,
      "grad_norm": 0.3912481367588043,
      "learning_rate": 3.387777777777778e-05,
      "loss": 0.003,
      "step": 29020
    },
    {
      "epoch": 0.6451111111111111,
      "grad_norm": 0.16715452075004578,
      "learning_rate": 3.387222222222222e-05,
      "loss": 0.0033,
      "step": 29030
    },
    {
      "epoch": 0.6453333333333333,
      "grad_norm": 0.5907255411148071,
      "learning_rate": 3.3866666666666665e-05,
      "loss": 0.0023,
      "step": 29040
    },
    {
      "epoch": 0.6455555555555555,
      "grad_norm": 0.06795462220907211,
      "learning_rate": 3.386111111111111e-05,
      "loss": 0.0025,
      "step": 29050
    },
    {
      "epoch": 0.6457777777777778,
      "grad_norm": 0.35378536581993103,
      "learning_rate": 3.385555555555556e-05,
      "loss": 0.0022,
      "step": 29060
    },
    {
      "epoch": 0.646,
      "grad_norm": 0.2760840952396393,
      "learning_rate": 3.385e-05,
      "loss": 0.0023,
      "step": 29070
    },
    {
      "epoch": 0.6462222222222223,
      "grad_norm": 0.6183459758758545,
      "learning_rate": 3.3844444444444446e-05,
      "loss": 0.0032,
      "step": 29080
    },
    {
      "epoch": 0.6464444444444445,
      "grad_norm": 0.237649604678154,
      "learning_rate": 3.383888888888889e-05,
      "loss": 0.0024,
      "step": 29090
    },
    {
      "epoch": 0.6466666666666666,
      "grad_norm": 0.26772767305374146,
      "learning_rate": 3.3833333333333334e-05,
      "loss": 0.0025,
      "step": 29100
    },
    {
      "epoch": 0.6468888888888888,
      "grad_norm": 0.347750723361969,
      "learning_rate": 3.382777777777778e-05,
      "loss": 0.0021,
      "step": 29110
    },
    {
      "epoch": 0.6471111111111111,
      "grad_norm": 0.5574508309364319,
      "learning_rate": 3.382222222222222e-05,
      "loss": 0.0021,
      "step": 29120
    },
    {
      "epoch": 0.6473333333333333,
      "grad_norm": 0.10193543881177902,
      "learning_rate": 3.381666666666667e-05,
      "loss": 0.0021,
      "step": 29130
    },
    {
      "epoch": 0.6475555555555556,
      "grad_norm": 0.7346374988555908,
      "learning_rate": 3.381111111111111e-05,
      "loss": 0.0019,
      "step": 29140
    },
    {
      "epoch": 0.6477777777777778,
      "grad_norm": 0.31325051188468933,
      "learning_rate": 3.380555555555556e-05,
      "loss": 0.0019,
      "step": 29150
    },
    {
      "epoch": 0.648,
      "grad_norm": 0.4005768597126007,
      "learning_rate": 3.38e-05,
      "loss": 0.0025,
      "step": 29160
    },
    {
      "epoch": 0.6482222222222223,
      "grad_norm": 0.2993157207965851,
      "learning_rate": 3.3794444444444445e-05,
      "loss": 0.003,
      "step": 29170
    },
    {
      "epoch": 0.6484444444444445,
      "grad_norm": 0.35875192284584045,
      "learning_rate": 3.378888888888889e-05,
      "loss": 0.0025,
      "step": 29180
    },
    {
      "epoch": 0.6486666666666666,
      "grad_norm": 0.2490580976009369,
      "learning_rate": 3.378333333333333e-05,
      "loss": 0.0027,
      "step": 29190
    },
    {
      "epoch": 0.6488888888888888,
      "grad_norm": 0.05303681269288063,
      "learning_rate": 3.377777777777778e-05,
      "loss": 0.0027,
      "step": 29200
    },
    {
      "epoch": 0.6491111111111111,
      "grad_norm": 0.4107986092567444,
      "learning_rate": 3.377222222222222e-05,
      "loss": 0.0018,
      "step": 29210
    },
    {
      "epoch": 0.6493333333333333,
      "grad_norm": 0.5409123301506042,
      "learning_rate": 3.376666666666667e-05,
      "loss": 0.0021,
      "step": 29220
    },
    {
      "epoch": 0.6495555555555556,
      "grad_norm": 0.3725471794605255,
      "learning_rate": 3.376111111111111e-05,
      "loss": 0.0017,
      "step": 29230
    },
    {
      "epoch": 0.6497777777777778,
      "grad_norm": 0.39136213064193726,
      "learning_rate": 3.375555555555556e-05,
      "loss": 0.002,
      "step": 29240
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.6045136451721191,
      "learning_rate": 3.375000000000001e-05,
      "loss": 0.0022,
      "step": 29250
    },
    {
      "epoch": 0.6502222222222223,
      "grad_norm": 0.48232898116111755,
      "learning_rate": 3.3744444444444444e-05,
      "loss": 0.0021,
      "step": 29260
    },
    {
      "epoch": 0.6504444444444445,
      "grad_norm": 0.4055039584636688,
      "learning_rate": 3.3738888888888894e-05,
      "loss": 0.0018,
      "step": 29270
    },
    {
      "epoch": 0.6506666666666666,
      "grad_norm": 0.10931498557329178,
      "learning_rate": 3.373333333333333e-05,
      "loss": 0.0022,
      "step": 29280
    },
    {
      "epoch": 0.6508888888888889,
      "grad_norm": 0.6471652388572693,
      "learning_rate": 3.372777777777778e-05,
      "loss": 0.002,
      "step": 29290
    },
    {
      "epoch": 0.6511111111111111,
      "grad_norm": 0.23229722678661346,
      "learning_rate": 3.3722222222222225e-05,
      "loss": 0.0019,
      "step": 29300
    },
    {
      "epoch": 0.6513333333333333,
      "grad_norm": 0.15638573467731476,
      "learning_rate": 3.371666666666667e-05,
      "loss": 0.002,
      "step": 29310
    },
    {
      "epoch": 0.6515555555555556,
      "grad_norm": 0.18719466030597687,
      "learning_rate": 3.371111111111111e-05,
      "loss": 0.0033,
      "step": 29320
    },
    {
      "epoch": 0.6517777777777778,
      "grad_norm": 0.08436471223831177,
      "learning_rate": 3.3705555555555556e-05,
      "loss": 0.0033,
      "step": 29330
    },
    {
      "epoch": 0.652,
      "grad_norm": 0.9800666570663452,
      "learning_rate": 3.3700000000000006e-05,
      "loss": 0.0019,
      "step": 29340
    },
    {
      "epoch": 0.6522222222222223,
      "grad_norm": 0.3913510739803314,
      "learning_rate": 3.369444444444444e-05,
      "loss": 0.0026,
      "step": 29350
    },
    {
      "epoch": 0.6524444444444445,
      "grad_norm": 0.2184666246175766,
      "learning_rate": 3.368888888888889e-05,
      "loss": 0.0027,
      "step": 29360
    },
    {
      "epoch": 0.6526666666666666,
      "grad_norm": 0.16752848029136658,
      "learning_rate": 3.368333333333334e-05,
      "loss": 0.0031,
      "step": 29370
    },
    {
      "epoch": 0.6528888888888889,
      "grad_norm": 0.49100425839424133,
      "learning_rate": 3.367777777777778e-05,
      "loss": 0.0029,
      "step": 29380
    },
    {
      "epoch": 0.6531111111111111,
      "grad_norm": 0.07886577397584915,
      "learning_rate": 3.3672222222222224e-05,
      "loss": 0.0022,
      "step": 29390
    },
    {
      "epoch": 0.6533333333333333,
      "grad_norm": 0.0931883305311203,
      "learning_rate": 3.366666666666667e-05,
      "loss": 0.0021,
      "step": 29400
    },
    {
      "epoch": 0.6535555555555556,
      "grad_norm": 0.2973068654537201,
      "learning_rate": 3.366111111111112e-05,
      "loss": 0.0035,
      "step": 29410
    },
    {
      "epoch": 0.6537777777777778,
      "grad_norm": 0.23730024695396423,
      "learning_rate": 3.3655555555555554e-05,
      "loss": 0.0027,
      "step": 29420
    },
    {
      "epoch": 0.654,
      "grad_norm": 0.41532301902770996,
      "learning_rate": 3.3650000000000005e-05,
      "loss": 0.0024,
      "step": 29430
    },
    {
      "epoch": 0.6542222222222223,
      "grad_norm": 0.5161601901054382,
      "learning_rate": 3.364444444444445e-05,
      "loss": 0.0019,
      "step": 29440
    },
    {
      "epoch": 0.6544444444444445,
      "grad_norm": 0.3973235785961151,
      "learning_rate": 3.363888888888889e-05,
      "loss": 0.0023,
      "step": 29450
    },
    {
      "epoch": 0.6546666666666666,
      "grad_norm": 0.1124676913022995,
      "learning_rate": 3.3633333333333335e-05,
      "loss": 0.0016,
      "step": 29460
    },
    {
      "epoch": 0.6548888888888889,
      "grad_norm": 0.4649076759815216,
      "learning_rate": 3.362777777777778e-05,
      "loss": 0.0032,
      "step": 29470
    },
    {
      "epoch": 0.6551111111111111,
      "grad_norm": 0.11539968848228455,
      "learning_rate": 3.362222222222222e-05,
      "loss": 0.0021,
      "step": 29480
    },
    {
      "epoch": 0.6553333333333333,
      "grad_norm": 0.6216011643409729,
      "learning_rate": 3.3616666666666666e-05,
      "loss": 0.0027,
      "step": 29490
    },
    {
      "epoch": 0.6555555555555556,
      "grad_norm": 0.5259019732475281,
      "learning_rate": 3.3611111111111116e-05,
      "loss": 0.002,
      "step": 29500
    },
    {
      "epoch": 0.6557777777777778,
      "grad_norm": 0.495251327753067,
      "learning_rate": 3.360555555555556e-05,
      "loss": 0.0022,
      "step": 29510
    },
    {
      "epoch": 0.656,
      "grad_norm": 0.12594041228294373,
      "learning_rate": 3.3600000000000004e-05,
      "loss": 0.0021,
      "step": 29520
    },
    {
      "epoch": 0.6562222222222223,
      "grad_norm": 0.32672345638275146,
      "learning_rate": 3.359444444444445e-05,
      "loss": 0.0022,
      "step": 29530
    },
    {
      "epoch": 0.6564444444444445,
      "grad_norm": 0.12298881262540817,
      "learning_rate": 3.358888888888889e-05,
      "loss": 0.0018,
      "step": 29540
    },
    {
      "epoch": 0.6566666666666666,
      "grad_norm": 0.2933556139469147,
      "learning_rate": 3.3583333333333334e-05,
      "loss": 0.0028,
      "step": 29550
    },
    {
      "epoch": 0.6568888888888889,
      "grad_norm": 0.1911681443452835,
      "learning_rate": 3.357777777777778e-05,
      "loss": 0.0019,
      "step": 29560
    },
    {
      "epoch": 0.6571111111111111,
      "grad_norm": 0.19336220622062683,
      "learning_rate": 3.357222222222222e-05,
      "loss": 0.0022,
      "step": 29570
    },
    {
      "epoch": 0.6573333333333333,
      "grad_norm": 0.6655527353286743,
      "learning_rate": 3.356666666666667e-05,
      "loss": 0.003,
      "step": 29580
    },
    {
      "epoch": 0.6575555555555556,
      "grad_norm": 0.20167899131774902,
      "learning_rate": 3.3561111111111115e-05,
      "loss": 0.0021,
      "step": 29590
    },
    {
      "epoch": 0.6577777777777778,
      "grad_norm": 0.13554523885250092,
      "learning_rate": 3.355555555555556e-05,
      "loss": 0.0029,
      "step": 29600
    },
    {
      "epoch": 0.658,
      "grad_norm": 0.15070730447769165,
      "learning_rate": 3.355e-05,
      "loss": 0.0025,
      "step": 29610
    },
    {
      "epoch": 0.6582222222222223,
      "grad_norm": 0.26014387607574463,
      "learning_rate": 3.3544444444444446e-05,
      "loss": 0.0017,
      "step": 29620
    },
    {
      "epoch": 0.6584444444444445,
      "grad_norm": 0.29370197653770447,
      "learning_rate": 3.353888888888889e-05,
      "loss": 0.0022,
      "step": 29630
    },
    {
      "epoch": 0.6586666666666666,
      "grad_norm": 0.23871533572673798,
      "learning_rate": 3.353333333333333e-05,
      "loss": 0.0027,
      "step": 29640
    },
    {
      "epoch": 0.6588888888888889,
      "grad_norm": 0.1627839058637619,
      "learning_rate": 3.352777777777778e-05,
      "loss": 0.0021,
      "step": 29650
    },
    {
      "epoch": 0.6591111111111111,
      "grad_norm": 0.16954836249351501,
      "learning_rate": 3.352222222222222e-05,
      "loss": 0.0026,
      "step": 29660
    },
    {
      "epoch": 0.6593333333333333,
      "grad_norm": 0.15288759768009186,
      "learning_rate": 3.351666666666667e-05,
      "loss": 0.002,
      "step": 29670
    },
    {
      "epoch": 0.6595555555555556,
      "grad_norm": 0.14892837405204773,
      "learning_rate": 3.3511111111111114e-05,
      "loss": 0.0018,
      "step": 29680
    },
    {
      "epoch": 0.6597777777777778,
      "grad_norm": 0.13431008160114288,
      "learning_rate": 3.350555555555556e-05,
      "loss": 0.0021,
      "step": 29690
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.22253723442554474,
      "learning_rate": 3.35e-05,
      "loss": 0.0018,
      "step": 29700
    },
    {
      "epoch": 0.6602222222222223,
      "grad_norm": 0.16870605945587158,
      "learning_rate": 3.3494444444444445e-05,
      "loss": 0.0025,
      "step": 29710
    },
    {
      "epoch": 0.6604444444444444,
      "grad_norm": 0.1678875833749771,
      "learning_rate": 3.3488888888888895e-05,
      "loss": 0.0023,
      "step": 29720
    },
    {
      "epoch": 0.6606666666666666,
      "grad_norm": 0.19243085384368896,
      "learning_rate": 3.348333333333333e-05,
      "loss": 0.0019,
      "step": 29730
    },
    {
      "epoch": 0.6608888888888889,
      "grad_norm": 0.1919155865907669,
      "learning_rate": 3.347777777777778e-05,
      "loss": 0.0032,
      "step": 29740
    },
    {
      "epoch": 0.6611111111111111,
      "grad_norm": 0.1671532839536667,
      "learning_rate": 3.347222222222222e-05,
      "loss": 0.0022,
      "step": 29750
    },
    {
      "epoch": 0.6613333333333333,
      "grad_norm": 0.20445406436920166,
      "learning_rate": 3.346666666666667e-05,
      "loss": 0.0028,
      "step": 29760
    },
    {
      "epoch": 0.6615555555555556,
      "grad_norm": 0.40453699231147766,
      "learning_rate": 3.346111111111111e-05,
      "loss": 0.0028,
      "step": 29770
    },
    {
      "epoch": 0.6617777777777778,
      "grad_norm": 0.17395848035812378,
      "learning_rate": 3.3455555555555556e-05,
      "loss": 0.0025,
      "step": 29780
    },
    {
      "epoch": 0.662,
      "grad_norm": 0.3613085150718689,
      "learning_rate": 3.345000000000001e-05,
      "loss": 0.0022,
      "step": 29790
    },
    {
      "epoch": 0.6622222222222223,
      "grad_norm": 0.11209765076637268,
      "learning_rate": 3.3444444444444443e-05,
      "loss": 0.0021,
      "step": 29800
    },
    {
      "epoch": 0.6624444444444444,
      "grad_norm": 0.2381577342748642,
      "learning_rate": 3.3438888888888894e-05,
      "loss": 0.0021,
      "step": 29810
    },
    {
      "epoch": 0.6626666666666666,
      "grad_norm": 0.1156998872756958,
      "learning_rate": 3.343333333333333e-05,
      "loss": 0.0031,
      "step": 29820
    },
    {
      "epoch": 0.6628888888888889,
      "grad_norm": 0.45535552501678467,
      "learning_rate": 3.342777777777778e-05,
      "loss": 0.0025,
      "step": 29830
    },
    {
      "epoch": 0.6631111111111111,
      "grad_norm": 0.6763983368873596,
      "learning_rate": 3.3422222222222224e-05,
      "loss": 0.0023,
      "step": 29840
    },
    {
      "epoch": 0.6633333333333333,
      "grad_norm": 0.12215368449687958,
      "learning_rate": 3.341666666666667e-05,
      "loss": 0.0023,
      "step": 29850
    },
    {
      "epoch": 0.6635555555555556,
      "grad_norm": 0.11751700192689896,
      "learning_rate": 3.341111111111112e-05,
      "loss": 0.0025,
      "step": 29860
    },
    {
      "epoch": 0.6637777777777778,
      "grad_norm": 0.1196221336722374,
      "learning_rate": 3.3405555555555555e-05,
      "loss": 0.0028,
      "step": 29870
    },
    {
      "epoch": 0.664,
      "grad_norm": 0.2046804279088974,
      "learning_rate": 3.3400000000000005e-05,
      "loss": 0.0022,
      "step": 29880
    },
    {
      "epoch": 0.6642222222222223,
      "grad_norm": 0.08229582011699677,
      "learning_rate": 3.339444444444444e-05,
      "loss": 0.0018,
      "step": 29890
    },
    {
      "epoch": 0.6644444444444444,
      "grad_norm": 0.42133286595344543,
      "learning_rate": 3.338888888888889e-05,
      "loss": 0.0021,
      "step": 29900
    },
    {
      "epoch": 0.6646666666666666,
      "grad_norm": 0.08125568181276321,
      "learning_rate": 3.3383333333333336e-05,
      "loss": 0.0029,
      "step": 29910
    },
    {
      "epoch": 0.6648888888888889,
      "grad_norm": 0.20710480213165283,
      "learning_rate": 3.337777777777778e-05,
      "loss": 0.0021,
      "step": 29920
    },
    {
      "epoch": 0.6651111111111111,
      "grad_norm": 0.7511340379714966,
      "learning_rate": 3.337222222222222e-05,
      "loss": 0.0021,
      "step": 29930
    },
    {
      "epoch": 0.6653333333333333,
      "grad_norm": 0.6941742300987244,
      "learning_rate": 3.336666666666667e-05,
      "loss": 0.0032,
      "step": 29940
    },
    {
      "epoch": 0.6655555555555556,
      "grad_norm": 0.5602394938468933,
      "learning_rate": 3.336111111111112e-05,
      "loss": 0.002,
      "step": 29950
    },
    {
      "epoch": 0.6657777777777778,
      "grad_norm": 0.19470179080963135,
      "learning_rate": 3.3355555555555554e-05,
      "loss": 0.0026,
      "step": 29960
    },
    {
      "epoch": 0.666,
      "grad_norm": 0.5207781195640564,
      "learning_rate": 3.3350000000000004e-05,
      "loss": 0.0028,
      "step": 29970
    },
    {
      "epoch": 0.6662222222222223,
      "grad_norm": 0.23172155022621155,
      "learning_rate": 3.334444444444445e-05,
      "loss": 0.002,
      "step": 29980
    },
    {
      "epoch": 0.6664444444444444,
      "grad_norm": 0.22284194827079773,
      "learning_rate": 3.333888888888889e-05,
      "loss": 0.0025,
      "step": 29990
    },
    {
      "epoch": 0.6666666666666666,
      "grad_norm": 0.39704108238220215,
      "learning_rate": 3.3333333333333335e-05,
      "loss": 0.0017,
      "step": 30000
    },
    {
      "epoch": 0.6668888888888889,
      "grad_norm": 0.6222451329231262,
      "learning_rate": 3.332777777777778e-05,
      "loss": 0.0021,
      "step": 30010
    },
    {
      "epoch": 0.6671111111111111,
      "grad_norm": 0.26502105593681335,
      "learning_rate": 3.332222222222222e-05,
      "loss": 0.0029,
      "step": 30020
    },
    {
      "epoch": 0.6673333333333333,
      "grad_norm": 0.15586437284946442,
      "learning_rate": 3.3316666666666666e-05,
      "loss": 0.0023,
      "step": 30030
    },
    {
      "epoch": 0.6675555555555556,
      "grad_norm": 0.13866160809993744,
      "learning_rate": 3.3311111111111116e-05,
      "loss": 0.003,
      "step": 30040
    },
    {
      "epoch": 0.6677777777777778,
      "grad_norm": 0.41832929849624634,
      "learning_rate": 3.330555555555556e-05,
      "loss": 0.002,
      "step": 30050
    },
    {
      "epoch": 0.668,
      "grad_norm": 0.3017722964286804,
      "learning_rate": 3.33e-05,
      "loss": 0.0025,
      "step": 30060
    },
    {
      "epoch": 0.6682222222222223,
      "grad_norm": 0.0766974613070488,
      "learning_rate": 3.3294444444444447e-05,
      "loss": 0.0026,
      "step": 30070
    },
    {
      "epoch": 0.6684444444444444,
      "grad_norm": 0.5947498679161072,
      "learning_rate": 3.328888888888889e-05,
      "loss": 0.0022,
      "step": 30080
    },
    {
      "epoch": 0.6686666666666666,
      "grad_norm": 0.39587992429733276,
      "learning_rate": 3.3283333333333334e-05,
      "loss": 0.0023,
      "step": 30090
    },
    {
      "epoch": 0.6688888888888889,
      "grad_norm": 0.11949034780263901,
      "learning_rate": 3.327777777777778e-05,
      "loss": 0.002,
      "step": 30100
    },
    {
      "epoch": 0.6691111111111111,
      "grad_norm": 0.3141426742076874,
      "learning_rate": 3.327222222222222e-05,
      "loss": 0.0019,
      "step": 30110
    },
    {
      "epoch": 0.6693333333333333,
      "grad_norm": 0.28959861397743225,
      "learning_rate": 3.326666666666667e-05,
      "loss": 0.0026,
      "step": 30120
    },
    {
      "epoch": 0.6695555555555556,
      "grad_norm": 0.08945832401514053,
      "learning_rate": 3.3261111111111115e-05,
      "loss": 0.0026,
      "step": 30130
    },
    {
      "epoch": 0.6697777777777778,
      "grad_norm": 0.08529529720544815,
      "learning_rate": 3.325555555555556e-05,
      "loss": 0.0025,
      "step": 30140
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.25174573063850403,
      "learning_rate": 3.325e-05,
      "loss": 0.0023,
      "step": 30150
    },
    {
      "epoch": 0.6702222222222223,
      "grad_norm": 0.18806038796901703,
      "learning_rate": 3.3244444444444445e-05,
      "loss": 0.0023,
      "step": 30160
    },
    {
      "epoch": 0.6704444444444444,
      "grad_norm": 0.12984801828861237,
      "learning_rate": 3.323888888888889e-05,
      "loss": 0.0017,
      "step": 30170
    },
    {
      "epoch": 0.6706666666666666,
      "grad_norm": 0.5671334266662598,
      "learning_rate": 3.323333333333333e-05,
      "loss": 0.0033,
      "step": 30180
    },
    {
      "epoch": 0.6708888888888889,
      "grad_norm": 0.23458221554756165,
      "learning_rate": 3.322777777777778e-05,
      "loss": 0.002,
      "step": 30190
    },
    {
      "epoch": 0.6711111111111111,
      "grad_norm": 0.5583111643791199,
      "learning_rate": 3.322222222222222e-05,
      "loss": 0.0025,
      "step": 30200
    },
    {
      "epoch": 0.6713333333333333,
      "grad_norm": 0.37968605756759644,
      "learning_rate": 3.321666666666667e-05,
      "loss": 0.0022,
      "step": 30210
    },
    {
      "epoch": 0.6715555555555556,
      "grad_norm": 0.0774955227971077,
      "learning_rate": 3.3211111111111114e-05,
      "loss": 0.0018,
      "step": 30220
    },
    {
      "epoch": 0.6717777777777778,
      "grad_norm": 0.15064647793769836,
      "learning_rate": 3.320555555555556e-05,
      "loss": 0.0022,
      "step": 30230
    },
    {
      "epoch": 0.672,
      "grad_norm": 0.0643606185913086,
      "learning_rate": 3.32e-05,
      "loss": 0.0018,
      "step": 30240
    },
    {
      "epoch": 0.6722222222222223,
      "grad_norm": 0.14458197355270386,
      "learning_rate": 3.3194444444444444e-05,
      "loss": 0.003,
      "step": 30250
    },
    {
      "epoch": 0.6724444444444444,
      "grad_norm": 0.4409734010696411,
      "learning_rate": 3.3188888888888895e-05,
      "loss": 0.0026,
      "step": 30260
    },
    {
      "epoch": 0.6726666666666666,
      "grad_norm": 0.37695714831352234,
      "learning_rate": 3.318333333333333e-05,
      "loss": 0.0023,
      "step": 30270
    },
    {
      "epoch": 0.6728888888888889,
      "grad_norm": 0.14028723537921906,
      "learning_rate": 3.317777777777778e-05,
      "loss": 0.0034,
      "step": 30280
    },
    {
      "epoch": 0.6731111111111111,
      "grad_norm": 0.33459222316741943,
      "learning_rate": 3.317222222222222e-05,
      "loss": 0.0022,
      "step": 30290
    },
    {
      "epoch": 0.6733333333333333,
      "grad_norm": 0.08795013278722763,
      "learning_rate": 3.316666666666667e-05,
      "loss": 0.0021,
      "step": 30300
    },
    {
      "epoch": 0.6735555555555556,
      "grad_norm": 0.24822063744068146,
      "learning_rate": 3.316111111111111e-05,
      "loss": 0.0022,
      "step": 30310
    },
    {
      "epoch": 0.6737777777777778,
      "grad_norm": 0.4381081163883209,
      "learning_rate": 3.3155555555555556e-05,
      "loss": 0.0026,
      "step": 30320
    },
    {
      "epoch": 0.674,
      "grad_norm": 0.4737580120563507,
      "learning_rate": 3.3150000000000006e-05,
      "loss": 0.0019,
      "step": 30330
    },
    {
      "epoch": 0.6742222222222222,
      "grad_norm": 0.422268271446228,
      "learning_rate": 3.314444444444444e-05,
      "loss": 0.0021,
      "step": 30340
    },
    {
      "epoch": 0.6744444444444444,
      "grad_norm": 0.1863459348678589,
      "learning_rate": 3.313888888888889e-05,
      "loss": 0.0017,
      "step": 30350
    },
    {
      "epoch": 0.6746666666666666,
      "grad_norm": 0.06203167885541916,
      "learning_rate": 3.313333333333333e-05,
      "loss": 0.0019,
      "step": 30360
    },
    {
      "epoch": 0.6748888888888889,
      "grad_norm": 0.27165353298187256,
      "learning_rate": 3.312777777777778e-05,
      "loss": 0.0017,
      "step": 30370
    },
    {
      "epoch": 0.6751111111111111,
      "grad_norm": 0.11498407274484634,
      "learning_rate": 3.3122222222222224e-05,
      "loss": 0.0024,
      "step": 30380
    },
    {
      "epoch": 0.6753333333333333,
      "grad_norm": 0.4917233884334564,
      "learning_rate": 3.311666666666667e-05,
      "loss": 0.0029,
      "step": 30390
    },
    {
      "epoch": 0.6755555555555556,
      "grad_norm": 0.3353046476840973,
      "learning_rate": 3.311111111111112e-05,
      "loss": 0.0018,
      "step": 30400
    },
    {
      "epoch": 0.6757777777777778,
      "grad_norm": 0.6920825839042664,
      "learning_rate": 3.3105555555555555e-05,
      "loss": 0.0037,
      "step": 30410
    },
    {
      "epoch": 0.676,
      "grad_norm": 0.6489354968070984,
      "learning_rate": 3.3100000000000005e-05,
      "loss": 0.0031,
      "step": 30420
    },
    {
      "epoch": 0.6762222222222222,
      "grad_norm": 0.3637024760246277,
      "learning_rate": 3.309444444444444e-05,
      "loss": 0.0018,
      "step": 30430
    },
    {
      "epoch": 0.6764444444444444,
      "grad_norm": 0.07467104494571686,
      "learning_rate": 3.308888888888889e-05,
      "loss": 0.0026,
      "step": 30440
    },
    {
      "epoch": 0.6766666666666666,
      "grad_norm": 0.5259445905685425,
      "learning_rate": 3.3083333333333336e-05,
      "loss": 0.0023,
      "step": 30450
    },
    {
      "epoch": 0.6768888888888889,
      "grad_norm": 0.42317309975624084,
      "learning_rate": 3.307777777777778e-05,
      "loss": 0.0027,
      "step": 30460
    },
    {
      "epoch": 0.6771111111111111,
      "grad_norm": 0.1788441240787506,
      "learning_rate": 3.307222222222222e-05,
      "loss": 0.0031,
      "step": 30470
    },
    {
      "epoch": 0.6773333333333333,
      "grad_norm": 0.3493976593017578,
      "learning_rate": 3.3066666666666666e-05,
      "loss": 0.0022,
      "step": 30480
    },
    {
      "epoch": 0.6775555555555556,
      "grad_norm": 0.24478520452976227,
      "learning_rate": 3.306111111111112e-05,
      "loss": 0.0022,
      "step": 30490
    },
    {
      "epoch": 0.6777777777777778,
      "grad_norm": 0.12479496002197266,
      "learning_rate": 3.3055555555555553e-05,
      "loss": 0.0026,
      "step": 30500
    },
    {
      "epoch": 0.678,
      "grad_norm": 0.28195706009864807,
      "learning_rate": 3.3050000000000004e-05,
      "loss": 0.002,
      "step": 30510
    },
    {
      "epoch": 0.6782222222222222,
      "grad_norm": 0.32310932874679565,
      "learning_rate": 3.304444444444445e-05,
      "loss": 0.0029,
      "step": 30520
    },
    {
      "epoch": 0.6784444444444444,
      "grad_norm": 0.5751426815986633,
      "learning_rate": 3.303888888888889e-05,
      "loss": 0.0029,
      "step": 30530
    },
    {
      "epoch": 0.6786666666666666,
      "grad_norm": 0.40692347288131714,
      "learning_rate": 3.3033333333333334e-05,
      "loss": 0.0024,
      "step": 30540
    },
    {
      "epoch": 0.6788888888888889,
      "grad_norm": 0.2410709708929062,
      "learning_rate": 3.302777777777778e-05,
      "loss": 0.002,
      "step": 30550
    },
    {
      "epoch": 0.6791111111111111,
      "grad_norm": 0.4179041385650635,
      "learning_rate": 3.302222222222222e-05,
      "loss": 0.0022,
      "step": 30560
    },
    {
      "epoch": 0.6793333333333333,
      "grad_norm": 0.4089195430278778,
      "learning_rate": 3.3016666666666665e-05,
      "loss": 0.0018,
      "step": 30570
    },
    {
      "epoch": 0.6795555555555556,
      "grad_norm": 0.06453894823789597,
      "learning_rate": 3.3011111111111115e-05,
      "loss": 0.002,
      "step": 30580
    },
    {
      "epoch": 0.6797777777777778,
      "grad_norm": 0.6382026076316833,
      "learning_rate": 3.300555555555556e-05,
      "loss": 0.0024,
      "step": 30590
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.2854292094707489,
      "learning_rate": 3.3e-05,
      "loss": 0.0022,
      "step": 30600
    },
    {
      "epoch": 0.6802222222222222,
      "grad_norm": 0.16452279686927795,
      "learning_rate": 3.2994444444444446e-05,
      "loss": 0.0027,
      "step": 30610
    },
    {
      "epoch": 0.6804444444444444,
      "grad_norm": 0.07050289213657379,
      "learning_rate": 3.298888888888889e-05,
      "loss": 0.0016,
      "step": 30620
    },
    {
      "epoch": 0.6806666666666666,
      "grad_norm": 0.1354074627161026,
      "learning_rate": 3.298333333333333e-05,
      "loss": 0.0018,
      "step": 30630
    },
    {
      "epoch": 0.6808888888888889,
      "grad_norm": 0.5255046486854553,
      "learning_rate": 3.297777777777778e-05,
      "loss": 0.0029,
      "step": 30640
    },
    {
      "epoch": 0.6811111111111111,
      "grad_norm": 0.06452881544828415,
      "learning_rate": 3.297222222222223e-05,
      "loss": 0.0017,
      "step": 30650
    },
    {
      "epoch": 0.6813333333333333,
      "grad_norm": 0.1396186351776123,
      "learning_rate": 3.296666666666667e-05,
      "loss": 0.002,
      "step": 30660
    },
    {
      "epoch": 0.6815555555555556,
      "grad_norm": 0.22304721176624298,
      "learning_rate": 3.2961111111111114e-05,
      "loss": 0.0024,
      "step": 30670
    },
    {
      "epoch": 0.6817777777777778,
      "grad_norm": 0.2498042732477188,
      "learning_rate": 3.295555555555556e-05,
      "loss": 0.0019,
      "step": 30680
    },
    {
      "epoch": 0.682,
      "grad_norm": 0.15081357955932617,
      "learning_rate": 3.295e-05,
      "loss": 0.0017,
      "step": 30690
    },
    {
      "epoch": 0.6822222222222222,
      "grad_norm": 0.363108366727829,
      "learning_rate": 3.2944444444444445e-05,
      "loss": 0.0018,
      "step": 30700
    },
    {
      "epoch": 0.6824444444444444,
      "grad_norm": 0.09434967488050461,
      "learning_rate": 3.293888888888889e-05,
      "loss": 0.0028,
      "step": 30710
    },
    {
      "epoch": 0.6826666666666666,
      "grad_norm": 0.07325845211744308,
      "learning_rate": 3.293333333333333e-05,
      "loss": 0.0017,
      "step": 30720
    },
    {
      "epoch": 0.6828888888888889,
      "grad_norm": 0.22101537883281708,
      "learning_rate": 3.292777777777778e-05,
      "loss": 0.0025,
      "step": 30730
    },
    {
      "epoch": 0.6831111111111111,
      "grad_norm": 0.13363181054592133,
      "learning_rate": 3.2922222222222226e-05,
      "loss": 0.0021,
      "step": 30740
    },
    {
      "epoch": 0.6833333333333333,
      "grad_norm": 0.13638202846050262,
      "learning_rate": 3.291666666666667e-05,
      "loss": 0.0018,
      "step": 30750
    },
    {
      "epoch": 0.6835555555555556,
      "grad_norm": 0.1376497745513916,
      "learning_rate": 3.291111111111111e-05,
      "loss": 0.0036,
      "step": 30760
    },
    {
      "epoch": 0.6837777777777778,
      "grad_norm": 0.06846543401479721,
      "learning_rate": 3.2905555555555557e-05,
      "loss": 0.0022,
      "step": 30770
    },
    {
      "epoch": 0.684,
      "grad_norm": 0.3881246745586395,
      "learning_rate": 3.29e-05,
      "loss": 0.0018,
      "step": 30780
    },
    {
      "epoch": 0.6842222222222222,
      "grad_norm": 0.6452435851097107,
      "learning_rate": 3.2894444444444444e-05,
      "loss": 0.0025,
      "step": 30790
    },
    {
      "epoch": 0.6844444444444444,
      "grad_norm": 0.301682710647583,
      "learning_rate": 3.2888888888888894e-05,
      "loss": 0.0016,
      "step": 30800
    },
    {
      "epoch": 0.6846666666666666,
      "grad_norm": 0.3391385078430176,
      "learning_rate": 3.288333333333333e-05,
      "loss": 0.0024,
      "step": 30810
    },
    {
      "epoch": 0.6848888888888889,
      "grad_norm": 0.09348089247941971,
      "learning_rate": 3.287777777777778e-05,
      "loss": 0.0024,
      "step": 30820
    },
    {
      "epoch": 0.6851111111111111,
      "grad_norm": 0.2615887224674225,
      "learning_rate": 3.2872222222222225e-05,
      "loss": 0.0038,
      "step": 30830
    },
    {
      "epoch": 0.6853333333333333,
      "grad_norm": 0.1924157440662384,
      "learning_rate": 3.286666666666667e-05,
      "loss": 0.0021,
      "step": 30840
    },
    {
      "epoch": 0.6855555555555556,
      "grad_norm": 0.16984795033931732,
      "learning_rate": 3.286111111111111e-05,
      "loss": 0.0019,
      "step": 30850
    },
    {
      "epoch": 0.6857777777777778,
      "grad_norm": 0.36049801111221313,
      "learning_rate": 3.2855555555555555e-05,
      "loss": 0.0018,
      "step": 30860
    },
    {
      "epoch": 0.686,
      "grad_norm": 0.14204281568527222,
      "learning_rate": 3.2850000000000006e-05,
      "loss": 0.0027,
      "step": 30870
    },
    {
      "epoch": 0.6862222222222222,
      "grad_norm": 0.35991594195365906,
      "learning_rate": 3.284444444444444e-05,
      "loss": 0.0022,
      "step": 30880
    },
    {
      "epoch": 0.6864444444444444,
      "grad_norm": 0.3518913984298706,
      "learning_rate": 3.283888888888889e-05,
      "loss": 0.0019,
      "step": 30890
    },
    {
      "epoch": 0.6866666666666666,
      "grad_norm": 0.46820783615112305,
      "learning_rate": 3.283333333333333e-05,
      "loss": 0.0019,
      "step": 30900
    },
    {
      "epoch": 0.6868888888888889,
      "grad_norm": 0.07548463344573975,
      "learning_rate": 3.282777777777778e-05,
      "loss": 0.0021,
      "step": 30910
    },
    {
      "epoch": 0.6871111111111111,
      "grad_norm": 0.39742210507392883,
      "learning_rate": 3.2822222222222223e-05,
      "loss": 0.0021,
      "step": 30920
    },
    {
      "epoch": 0.6873333333333334,
      "grad_norm": 0.20766517519950867,
      "learning_rate": 3.281666666666667e-05,
      "loss": 0.0018,
      "step": 30930
    },
    {
      "epoch": 0.6875555555555556,
      "grad_norm": 0.3672502636909485,
      "learning_rate": 3.281111111111112e-05,
      "loss": 0.0022,
      "step": 30940
    },
    {
      "epoch": 0.6877777777777778,
      "grad_norm": 0.16550447046756744,
      "learning_rate": 3.2805555555555554e-05,
      "loss": 0.0021,
      "step": 30950
    },
    {
      "epoch": 0.688,
      "grad_norm": 0.11037787050008774,
      "learning_rate": 3.2800000000000004e-05,
      "loss": 0.003,
      "step": 30960
    },
    {
      "epoch": 0.6882222222222222,
      "grad_norm": 0.38912928104400635,
      "learning_rate": 3.279444444444444e-05,
      "loss": 0.002,
      "step": 30970
    },
    {
      "epoch": 0.6884444444444444,
      "grad_norm": 0.06359505653381348,
      "learning_rate": 3.278888888888889e-05,
      "loss": 0.0018,
      "step": 30980
    },
    {
      "epoch": 0.6886666666666666,
      "grad_norm": 0.13686780631542206,
      "learning_rate": 3.2783333333333335e-05,
      "loss": 0.002,
      "step": 30990
    },
    {
      "epoch": 0.6888888888888889,
      "grad_norm": 0.2887924909591675,
      "learning_rate": 3.277777777777778e-05,
      "loss": 0.0027,
      "step": 31000
    },
    {
      "epoch": 0.6891111111111111,
      "grad_norm": 0.14538738131523132,
      "learning_rate": 3.277222222222223e-05,
      "loss": 0.0024,
      "step": 31010
    },
    {
      "epoch": 0.6893333333333334,
      "grad_norm": 0.27689892053604126,
      "learning_rate": 3.2766666666666666e-05,
      "loss": 0.0025,
      "step": 31020
    },
    {
      "epoch": 0.6895555555555556,
      "grad_norm": 0.06457594782114029,
      "learning_rate": 3.2761111111111116e-05,
      "loss": 0.002,
      "step": 31030
    },
    {
      "epoch": 0.6897777777777778,
      "grad_norm": 0.1338157206773758,
      "learning_rate": 3.275555555555555e-05,
      "loss": 0.0033,
      "step": 31040
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.30961471796035767,
      "learning_rate": 3.275e-05,
      "loss": 0.002,
      "step": 31050
    },
    {
      "epoch": 0.6902222222222222,
      "grad_norm": 0.5895717144012451,
      "learning_rate": 3.274444444444445e-05,
      "loss": 0.0023,
      "step": 31060
    },
    {
      "epoch": 0.6904444444444444,
      "grad_norm": 0.6041656732559204,
      "learning_rate": 3.273888888888889e-05,
      "loss": 0.003,
      "step": 31070
    },
    {
      "epoch": 0.6906666666666667,
      "grad_norm": 0.24184487760066986,
      "learning_rate": 3.2733333333333334e-05,
      "loss": 0.0034,
      "step": 31080
    },
    {
      "epoch": 0.6908888888888889,
      "grad_norm": 0.19033050537109375,
      "learning_rate": 3.272777777777778e-05,
      "loss": 0.0029,
      "step": 31090
    },
    {
      "epoch": 0.6911111111111111,
      "grad_norm": 0.14847896993160248,
      "learning_rate": 3.272222222222223e-05,
      "loss": 0.0022,
      "step": 31100
    },
    {
      "epoch": 0.6913333333333334,
      "grad_norm": 0.14857032895088196,
      "learning_rate": 3.2716666666666665e-05,
      "loss": 0.002,
      "step": 31110
    },
    {
      "epoch": 0.6915555555555556,
      "grad_norm": 0.5194435715675354,
      "learning_rate": 3.2711111111111115e-05,
      "loss": 0.0021,
      "step": 31120
    },
    {
      "epoch": 0.6917777777777778,
      "grad_norm": 0.2134588211774826,
      "learning_rate": 3.270555555555556e-05,
      "loss": 0.003,
      "step": 31130
    },
    {
      "epoch": 0.692,
      "grad_norm": 0.4613480269908905,
      "learning_rate": 3.27e-05,
      "loss": 0.0021,
      "step": 31140
    },
    {
      "epoch": 0.6922222222222222,
      "grad_norm": 0.08097783476114273,
      "learning_rate": 3.2694444444444446e-05,
      "loss": 0.004,
      "step": 31150
    },
    {
      "epoch": 0.6924444444444444,
      "grad_norm": 0.2680448591709137,
      "learning_rate": 3.268888888888889e-05,
      "loss": 0.0024,
      "step": 31160
    },
    {
      "epoch": 0.6926666666666667,
      "grad_norm": 0.1761917620897293,
      "learning_rate": 3.268333333333333e-05,
      "loss": 0.0022,
      "step": 31170
    },
    {
      "epoch": 0.6928888888888889,
      "grad_norm": 0.56484454870224,
      "learning_rate": 3.2677777777777776e-05,
      "loss": 0.003,
      "step": 31180
    },
    {
      "epoch": 0.6931111111111111,
      "grad_norm": 0.1537657231092453,
      "learning_rate": 3.2672222222222227e-05,
      "loss": 0.0017,
      "step": 31190
    },
    {
      "epoch": 0.6933333333333334,
      "grad_norm": 0.12691766023635864,
      "learning_rate": 3.266666666666667e-05,
      "loss": 0.0032,
      "step": 31200
    },
    {
      "epoch": 0.6935555555555556,
      "grad_norm": 0.4371521770954132,
      "learning_rate": 3.2661111111111114e-05,
      "loss": 0.0023,
      "step": 31210
    },
    {
      "epoch": 0.6937777777777778,
      "grad_norm": 0.10422585904598236,
      "learning_rate": 3.265555555555556e-05,
      "loss": 0.0023,
      "step": 31220
    },
    {
      "epoch": 0.694,
      "grad_norm": 0.1509651392698288,
      "learning_rate": 3.265e-05,
      "loss": 0.0031,
      "step": 31230
    },
    {
      "epoch": 0.6942222222222222,
      "grad_norm": 0.2248533070087433,
      "learning_rate": 3.2644444444444444e-05,
      "loss": 0.0026,
      "step": 31240
    },
    {
      "epoch": 0.6944444444444444,
      "grad_norm": 0.19843260943889618,
      "learning_rate": 3.263888888888889e-05,
      "loss": 0.002,
      "step": 31250
    },
    {
      "epoch": 0.6946666666666667,
      "grad_norm": 0.1321679651737213,
      "learning_rate": 3.263333333333333e-05,
      "loss": 0.0028,
      "step": 31260
    },
    {
      "epoch": 0.6948888888888889,
      "grad_norm": 0.08723252266645432,
      "learning_rate": 3.262777777777778e-05,
      "loss": 0.0032,
      "step": 31270
    },
    {
      "epoch": 0.6951111111111111,
      "grad_norm": 0.14896994829177856,
      "learning_rate": 3.2622222222222225e-05,
      "loss": 0.0019,
      "step": 31280
    },
    {
      "epoch": 0.6953333333333334,
      "grad_norm": 0.5369846224784851,
      "learning_rate": 3.261666666666667e-05,
      "loss": 0.0017,
      "step": 31290
    },
    {
      "epoch": 0.6955555555555556,
      "grad_norm": 0.35956525802612305,
      "learning_rate": 3.261111111111111e-05,
      "loss": 0.002,
      "step": 31300
    },
    {
      "epoch": 0.6957777777777778,
      "grad_norm": 0.3111523389816284,
      "learning_rate": 3.2605555555555556e-05,
      "loss": 0.0024,
      "step": 31310
    },
    {
      "epoch": 0.696,
      "grad_norm": 0.2744235098361969,
      "learning_rate": 3.26e-05,
      "loss": 0.0023,
      "step": 31320
    },
    {
      "epoch": 0.6962222222222222,
      "grad_norm": 0.049530964344739914,
      "learning_rate": 3.259444444444444e-05,
      "loss": 0.0026,
      "step": 31330
    },
    {
      "epoch": 0.6964444444444444,
      "grad_norm": 0.6191121339797974,
      "learning_rate": 3.2588888888888893e-05,
      "loss": 0.0027,
      "step": 31340
    },
    {
      "epoch": 0.6966666666666667,
      "grad_norm": 0.1419094055891037,
      "learning_rate": 3.258333333333333e-05,
      "loss": 0.002,
      "step": 31350
    },
    {
      "epoch": 0.6968888888888889,
      "grad_norm": 0.401224285364151,
      "learning_rate": 3.257777777777778e-05,
      "loss": 0.002,
      "step": 31360
    },
    {
      "epoch": 0.6971111111111111,
      "grad_norm": 0.41680747270584106,
      "learning_rate": 3.2572222222222224e-05,
      "loss": 0.003,
      "step": 31370
    },
    {
      "epoch": 0.6973333333333334,
      "grad_norm": 0.06378133594989777,
      "learning_rate": 3.256666666666667e-05,
      "loss": 0.0028,
      "step": 31380
    },
    {
      "epoch": 0.6975555555555556,
      "grad_norm": 0.20211666822433472,
      "learning_rate": 3.256111111111111e-05,
      "loss": 0.0025,
      "step": 31390
    },
    {
      "epoch": 0.6977777777777778,
      "grad_norm": 0.8586276173591614,
      "learning_rate": 3.2555555555555555e-05,
      "loss": 0.0025,
      "step": 31400
    },
    {
      "epoch": 0.698,
      "grad_norm": 0.33467182517051697,
      "learning_rate": 3.2550000000000005e-05,
      "loss": 0.0028,
      "step": 31410
    },
    {
      "epoch": 0.6982222222222222,
      "grad_norm": 0.5051848292350769,
      "learning_rate": 3.254444444444444e-05,
      "loss": 0.0021,
      "step": 31420
    },
    {
      "epoch": 0.6984444444444444,
      "grad_norm": 0.3984743058681488,
      "learning_rate": 3.253888888888889e-05,
      "loss": 0.0022,
      "step": 31430
    },
    {
      "epoch": 0.6986666666666667,
      "grad_norm": 0.19250670075416565,
      "learning_rate": 3.253333333333333e-05,
      "loss": 0.0017,
      "step": 31440
    },
    {
      "epoch": 0.6988888888888889,
      "grad_norm": 0.07885624468326569,
      "learning_rate": 3.252777777777778e-05,
      "loss": 0.0021,
      "step": 31450
    },
    {
      "epoch": 0.6991111111111111,
      "grad_norm": 0.23873566091060638,
      "learning_rate": 3.252222222222222e-05,
      "loss": 0.003,
      "step": 31460
    },
    {
      "epoch": 0.6993333333333334,
      "grad_norm": 0.3410182595252991,
      "learning_rate": 3.2516666666666666e-05,
      "loss": 0.0023,
      "step": 31470
    },
    {
      "epoch": 0.6995555555555556,
      "grad_norm": 0.2937295436859131,
      "learning_rate": 3.251111111111112e-05,
      "loss": 0.0024,
      "step": 31480
    },
    {
      "epoch": 0.6997777777777778,
      "grad_norm": 0.16479134559631348,
      "learning_rate": 3.2505555555555554e-05,
      "loss": 0.0021,
      "step": 31490
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.5051916241645813,
      "learning_rate": 3.2500000000000004e-05,
      "loss": 0.0031,
      "step": 31500
    },
    {
      "epoch": 0.7002222222222222,
      "grad_norm": 0.36411017179489136,
      "learning_rate": 3.249444444444444e-05,
      "loss": 0.003,
      "step": 31510
    },
    {
      "epoch": 0.7004444444444444,
      "grad_norm": 0.10481016337871552,
      "learning_rate": 3.248888888888889e-05,
      "loss": 0.0019,
      "step": 31520
    },
    {
      "epoch": 0.7006666666666667,
      "grad_norm": 0.3188537061214447,
      "learning_rate": 3.2483333333333335e-05,
      "loss": 0.0026,
      "step": 31530
    },
    {
      "epoch": 0.7008888888888889,
      "grad_norm": 0.26554498076438904,
      "learning_rate": 3.247777777777778e-05,
      "loss": 0.0027,
      "step": 31540
    },
    {
      "epoch": 0.7011111111111111,
      "grad_norm": 0.25651586055755615,
      "learning_rate": 3.247222222222223e-05,
      "loss": 0.0035,
      "step": 31550
    },
    {
      "epoch": 0.7013333333333334,
      "grad_norm": 0.3640146851539612,
      "learning_rate": 3.2466666666666665e-05,
      "loss": 0.0023,
      "step": 31560
    },
    {
      "epoch": 0.7015555555555556,
      "grad_norm": 0.15522418916225433,
      "learning_rate": 3.2461111111111116e-05,
      "loss": 0.0032,
      "step": 31570
    },
    {
      "epoch": 0.7017777777777777,
      "grad_norm": 0.1477048695087433,
      "learning_rate": 3.245555555555555e-05,
      "loss": 0.0029,
      "step": 31580
    },
    {
      "epoch": 0.702,
      "grad_norm": 0.1765626221895218,
      "learning_rate": 3.245e-05,
      "loss": 0.0032,
      "step": 31590
    },
    {
      "epoch": 0.7022222222222222,
      "grad_norm": 0.5214569568634033,
      "learning_rate": 3.2444444444444446e-05,
      "loss": 0.002,
      "step": 31600
    },
    {
      "epoch": 0.7024444444444444,
      "grad_norm": 0.288255900144577,
      "learning_rate": 3.243888888888889e-05,
      "loss": 0.0028,
      "step": 31610
    },
    {
      "epoch": 0.7026666666666667,
      "grad_norm": 0.45180177688598633,
      "learning_rate": 3.243333333333333e-05,
      "loss": 0.0028,
      "step": 31620
    },
    {
      "epoch": 0.7028888888888889,
      "grad_norm": 0.11741619557142258,
      "learning_rate": 3.242777777777778e-05,
      "loss": 0.0023,
      "step": 31630
    },
    {
      "epoch": 0.7031111111111111,
      "grad_norm": 0.18068785965442657,
      "learning_rate": 3.242222222222223e-05,
      "loss": 0.0026,
      "step": 31640
    },
    {
      "epoch": 0.7033333333333334,
      "grad_norm": 0.2574184834957123,
      "learning_rate": 3.2416666666666664e-05,
      "loss": 0.0023,
      "step": 31650
    },
    {
      "epoch": 0.7035555555555556,
      "grad_norm": 0.26508668065071106,
      "learning_rate": 3.2411111111111114e-05,
      "loss": 0.0024,
      "step": 31660
    },
    {
      "epoch": 0.7037777777777777,
      "grad_norm": 0.07952500134706497,
      "learning_rate": 3.240555555555556e-05,
      "loss": 0.0019,
      "step": 31670
    },
    {
      "epoch": 0.704,
      "grad_norm": 0.28789910674095154,
      "learning_rate": 3.24e-05,
      "loss": 0.0026,
      "step": 31680
    },
    {
      "epoch": 0.7042222222222222,
      "grad_norm": 0.38054296374320984,
      "learning_rate": 3.2394444444444445e-05,
      "loss": 0.003,
      "step": 31690
    },
    {
      "epoch": 0.7044444444444444,
      "grad_norm": 0.48314550518989563,
      "learning_rate": 3.238888888888889e-05,
      "loss": 0.0019,
      "step": 31700
    },
    {
      "epoch": 0.7046666666666667,
      "grad_norm": 0.140370711684227,
      "learning_rate": 3.238333333333333e-05,
      "loss": 0.0023,
      "step": 31710
    },
    {
      "epoch": 0.7048888888888889,
      "grad_norm": 0.4975658059120178,
      "learning_rate": 3.2377777777777776e-05,
      "loss": 0.0025,
      "step": 31720
    },
    {
      "epoch": 0.7051111111111111,
      "grad_norm": 0.2524724304676056,
      "learning_rate": 3.2372222222222226e-05,
      "loss": 0.002,
      "step": 31730
    },
    {
      "epoch": 0.7053333333333334,
      "grad_norm": 0.3593885600566864,
      "learning_rate": 3.236666666666667e-05,
      "loss": 0.002,
      "step": 31740
    },
    {
      "epoch": 0.7055555555555556,
      "grad_norm": 0.6658147573471069,
      "learning_rate": 3.236111111111111e-05,
      "loss": 0.0023,
      "step": 31750
    },
    {
      "epoch": 0.7057777777777777,
      "grad_norm": 0.2296762615442276,
      "learning_rate": 3.235555555555556e-05,
      "loss": 0.0021,
      "step": 31760
    },
    {
      "epoch": 0.706,
      "grad_norm": 0.3997693657875061,
      "learning_rate": 3.235e-05,
      "loss": 0.0021,
      "step": 31770
    },
    {
      "epoch": 0.7062222222222222,
      "grad_norm": 0.5807432532310486,
      "learning_rate": 3.2344444444444444e-05,
      "loss": 0.0029,
      "step": 31780
    },
    {
      "epoch": 0.7064444444444444,
      "grad_norm": 0.6310513615608215,
      "learning_rate": 3.2338888888888894e-05,
      "loss": 0.0027,
      "step": 31790
    },
    {
      "epoch": 0.7066666666666667,
      "grad_norm": 0.2654212713241577,
      "learning_rate": 3.233333333333333e-05,
      "loss": 0.0021,
      "step": 31800
    },
    {
      "epoch": 0.7068888888888889,
      "grad_norm": 0.45456114411354065,
      "learning_rate": 3.232777777777778e-05,
      "loss": 0.0018,
      "step": 31810
    },
    {
      "epoch": 0.7071111111111111,
      "grad_norm": 0.04757622256875038,
      "learning_rate": 3.2322222222222225e-05,
      "loss": 0.002,
      "step": 31820
    },
    {
      "epoch": 0.7073333333333334,
      "grad_norm": 0.5513744950294495,
      "learning_rate": 3.231666666666667e-05,
      "loss": 0.0023,
      "step": 31830
    },
    {
      "epoch": 0.7075555555555556,
      "grad_norm": 0.11220593750476837,
      "learning_rate": 3.231111111111111e-05,
      "loss": 0.0025,
      "step": 31840
    },
    {
      "epoch": 0.7077777777777777,
      "grad_norm": 0.09462778270244598,
      "learning_rate": 3.2305555555555556e-05,
      "loss": 0.0027,
      "step": 31850
    },
    {
      "epoch": 0.708,
      "grad_norm": 0.4943263828754425,
      "learning_rate": 3.2300000000000006e-05,
      "loss": 0.004,
      "step": 31860
    },
    {
      "epoch": 0.7082222222222222,
      "grad_norm": 0.3826352059841156,
      "learning_rate": 3.229444444444444e-05,
      "loss": 0.0024,
      "step": 31870
    },
    {
      "epoch": 0.7084444444444444,
      "grad_norm": 0.2744365334510803,
      "learning_rate": 3.228888888888889e-05,
      "loss": 0.0021,
      "step": 31880
    },
    {
      "epoch": 0.7086666666666667,
      "grad_norm": 0.3264480233192444,
      "learning_rate": 3.2283333333333337e-05,
      "loss": 0.0026,
      "step": 31890
    },
    {
      "epoch": 0.7088888888888889,
      "grad_norm": 0.1707129031419754,
      "learning_rate": 3.227777777777778e-05,
      "loss": 0.0025,
      "step": 31900
    },
    {
      "epoch": 0.7091111111111111,
      "grad_norm": 0.36242830753326416,
      "learning_rate": 3.2272222222222224e-05,
      "loss": 0.0019,
      "step": 31910
    },
    {
      "epoch": 0.7093333333333334,
      "grad_norm": 0.5225049257278442,
      "learning_rate": 3.226666666666667e-05,
      "loss": 0.0019,
      "step": 31920
    },
    {
      "epoch": 0.7095555555555556,
      "grad_norm": 0.06718733161687851,
      "learning_rate": 3.226111111111112e-05,
      "loss": 0.0017,
      "step": 31930
    },
    {
      "epoch": 0.7097777777777777,
      "grad_norm": 0.6860524415969849,
      "learning_rate": 3.2255555555555554e-05,
      "loss": 0.0023,
      "step": 31940
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.13162629306316376,
      "learning_rate": 3.2250000000000005e-05,
      "loss": 0.0019,
      "step": 31950
    },
    {
      "epoch": 0.7102222222222222,
      "grad_norm": 0.18947704136371613,
      "learning_rate": 3.224444444444444e-05,
      "loss": 0.0019,
      "step": 31960
    },
    {
      "epoch": 0.7104444444444444,
      "grad_norm": 0.3175862729549408,
      "learning_rate": 3.223888888888889e-05,
      "loss": 0.0022,
      "step": 31970
    },
    {
      "epoch": 0.7106666666666667,
      "grad_norm": 0.1129971593618393,
      "learning_rate": 3.2233333333333335e-05,
      "loss": 0.0022,
      "step": 31980
    },
    {
      "epoch": 0.7108888888888889,
      "grad_norm": 0.16327299177646637,
      "learning_rate": 3.222777777777778e-05,
      "loss": 0.0025,
      "step": 31990
    },
    {
      "epoch": 0.7111111111111111,
      "grad_norm": 0.30641964077949524,
      "learning_rate": 3.222222222222223e-05,
      "loss": 0.0018,
      "step": 32000
    },
    {
      "epoch": 0.7113333333333334,
      "grad_norm": 0.18166634440422058,
      "learning_rate": 3.2216666666666666e-05,
      "loss": 0.0019,
      "step": 32010
    },
    {
      "epoch": 0.7115555555555556,
      "grad_norm": 0.42105892300605774,
      "learning_rate": 3.2211111111111116e-05,
      "loss": 0.0029,
      "step": 32020
    },
    {
      "epoch": 0.7117777777777777,
      "grad_norm": 0.3667703866958618,
      "learning_rate": 3.220555555555555e-05,
      "loss": 0.0019,
      "step": 32030
    },
    {
      "epoch": 0.712,
      "grad_norm": 0.4363263249397278,
      "learning_rate": 3.2200000000000003e-05,
      "loss": 0.0022,
      "step": 32040
    },
    {
      "epoch": 0.7122222222222222,
      "grad_norm": 0.10566803067922592,
      "learning_rate": 3.219444444444445e-05,
      "loss": 0.002,
      "step": 32050
    },
    {
      "epoch": 0.7124444444444444,
      "grad_norm": 0.24844926595687866,
      "learning_rate": 3.218888888888889e-05,
      "loss": 0.0024,
      "step": 32060
    },
    {
      "epoch": 0.7126666666666667,
      "grad_norm": 0.4218388795852661,
      "learning_rate": 3.218333333333334e-05,
      "loss": 0.0037,
      "step": 32070
    },
    {
      "epoch": 0.7128888888888889,
      "grad_norm": 0.4395652711391449,
      "learning_rate": 3.217777777777778e-05,
      "loss": 0.0017,
      "step": 32080
    },
    {
      "epoch": 0.7131111111111111,
      "grad_norm": 0.4167989194393158,
      "learning_rate": 3.217222222222223e-05,
      "loss": 0.0021,
      "step": 32090
    },
    {
      "epoch": 0.7133333333333334,
      "grad_norm": 0.05889265611767769,
      "learning_rate": 3.2166666666666665e-05,
      "loss": 0.0021,
      "step": 32100
    },
    {
      "epoch": 0.7135555555555556,
      "grad_norm": 0.3597124218940735,
      "learning_rate": 3.2161111111111115e-05,
      "loss": 0.0038,
      "step": 32110
    },
    {
      "epoch": 0.7137777777777777,
      "grad_norm": 0.2949863374233246,
      "learning_rate": 3.215555555555556e-05,
      "loss": 0.0021,
      "step": 32120
    },
    {
      "epoch": 0.714,
      "grad_norm": 0.07595793902873993,
      "learning_rate": 3.215e-05,
      "loss": 0.0027,
      "step": 32130
    },
    {
      "epoch": 0.7142222222222222,
      "grad_norm": 0.49838316440582275,
      "learning_rate": 3.2144444444444446e-05,
      "loss": 0.0022,
      "step": 32140
    },
    {
      "epoch": 0.7144444444444444,
      "grad_norm": 0.39236050844192505,
      "learning_rate": 3.213888888888889e-05,
      "loss": 0.002,
      "step": 32150
    },
    {
      "epoch": 0.7146666666666667,
      "grad_norm": 0.32556942105293274,
      "learning_rate": 3.213333333333334e-05,
      "loss": 0.0019,
      "step": 32160
    },
    {
      "epoch": 0.7148888888888889,
      "grad_norm": 0.27185049653053284,
      "learning_rate": 3.2127777777777776e-05,
      "loss": 0.0021,
      "step": 32170
    },
    {
      "epoch": 0.7151111111111111,
      "grad_norm": 0.12891440093517303,
      "learning_rate": 3.212222222222223e-05,
      "loss": 0.0022,
      "step": 32180
    },
    {
      "epoch": 0.7153333333333334,
      "grad_norm": 0.08030795305967331,
      "learning_rate": 3.211666666666667e-05,
      "loss": 0.0018,
      "step": 32190
    },
    {
      "epoch": 0.7155555555555555,
      "grad_norm": 0.06916561722755432,
      "learning_rate": 3.2111111111111114e-05,
      "loss": 0.0017,
      "step": 32200
    },
    {
      "epoch": 0.7157777777777777,
      "grad_norm": 0.255297988653183,
      "learning_rate": 3.210555555555556e-05,
      "loss": 0.0015,
      "step": 32210
    },
    {
      "epoch": 0.716,
      "grad_norm": 0.5011364221572876,
      "learning_rate": 3.21e-05,
      "loss": 0.0023,
      "step": 32220
    },
    {
      "epoch": 0.7162222222222222,
      "grad_norm": 0.0587732158601284,
      "learning_rate": 3.2094444444444445e-05,
      "loss": 0.0033,
      "step": 32230
    },
    {
      "epoch": 0.7164444444444444,
      "grad_norm": 0.5390698909759521,
      "learning_rate": 3.208888888888889e-05,
      "loss": 0.0022,
      "step": 32240
    },
    {
      "epoch": 0.7166666666666667,
      "grad_norm": 0.4532381594181061,
      "learning_rate": 3.208333333333334e-05,
      "loss": 0.0021,
      "step": 32250
    },
    {
      "epoch": 0.7168888888888889,
      "grad_norm": 0.18118086457252502,
      "learning_rate": 3.207777777777778e-05,
      "loss": 0.0026,
      "step": 32260
    },
    {
      "epoch": 0.7171111111111111,
      "grad_norm": 0.5021523237228394,
      "learning_rate": 3.2072222222222226e-05,
      "loss": 0.0017,
      "step": 32270
    },
    {
      "epoch": 0.7173333333333334,
      "grad_norm": 0.7189956903457642,
      "learning_rate": 3.206666666666667e-05,
      "loss": 0.002,
      "step": 32280
    },
    {
      "epoch": 0.7175555555555555,
      "grad_norm": 0.24468928575515747,
      "learning_rate": 3.206111111111111e-05,
      "loss": 0.0026,
      "step": 32290
    },
    {
      "epoch": 0.7177777777777777,
      "grad_norm": 0.08383534848690033,
      "learning_rate": 3.2055555555555556e-05,
      "loss": 0.0027,
      "step": 32300
    },
    {
      "epoch": 0.718,
      "grad_norm": 0.12432925403118134,
      "learning_rate": 3.205e-05,
      "loss": 0.0026,
      "step": 32310
    },
    {
      "epoch": 0.7182222222222222,
      "grad_norm": 0.29774409532546997,
      "learning_rate": 3.204444444444444e-05,
      "loss": 0.0022,
      "step": 32320
    },
    {
      "epoch": 0.7184444444444444,
      "grad_norm": 0.15193864703178406,
      "learning_rate": 3.2038888888888894e-05,
      "loss": 0.0019,
      "step": 32330
    },
    {
      "epoch": 0.7186666666666667,
      "grad_norm": 0.524174153804779,
      "learning_rate": 3.203333333333334e-05,
      "loss": 0.0018,
      "step": 32340
    },
    {
      "epoch": 0.7188888888888889,
      "grad_norm": 0.17480674386024475,
      "learning_rate": 3.202777777777778e-05,
      "loss": 0.0022,
      "step": 32350
    },
    {
      "epoch": 0.7191111111111111,
      "grad_norm": 0.13610675930976868,
      "learning_rate": 3.2022222222222224e-05,
      "loss": 0.0031,
      "step": 32360
    },
    {
      "epoch": 0.7193333333333334,
      "grad_norm": 0.3317217230796814,
      "learning_rate": 3.201666666666667e-05,
      "loss": 0.002,
      "step": 32370
    },
    {
      "epoch": 0.7195555555555555,
      "grad_norm": 0.11683731526136398,
      "learning_rate": 3.201111111111111e-05,
      "loss": 0.002,
      "step": 32380
    },
    {
      "epoch": 0.7197777777777777,
      "grad_norm": 0.32305580377578735,
      "learning_rate": 3.2005555555555555e-05,
      "loss": 0.0023,
      "step": 32390
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.5175667405128479,
      "learning_rate": 3.2000000000000005e-05,
      "loss": 0.0029,
      "step": 32400
    },
    {
      "epoch": 0.7202222222222222,
      "grad_norm": 0.057953543961048126,
      "learning_rate": 3.199444444444444e-05,
      "loss": 0.0023,
      "step": 32410
    },
    {
      "epoch": 0.7204444444444444,
      "grad_norm": 0.291889488697052,
      "learning_rate": 3.198888888888889e-05,
      "loss": 0.0022,
      "step": 32420
    },
    {
      "epoch": 0.7206666666666667,
      "grad_norm": 0.2603268027305603,
      "learning_rate": 3.1983333333333336e-05,
      "loss": 0.002,
      "step": 32430
    },
    {
      "epoch": 0.7208888888888889,
      "grad_norm": 0.9271935224533081,
      "learning_rate": 3.197777777777778e-05,
      "loss": 0.0017,
      "step": 32440
    },
    {
      "epoch": 0.7211111111111111,
      "grad_norm": 0.3737092912197113,
      "learning_rate": 3.197222222222222e-05,
      "loss": 0.0017,
      "step": 32450
    },
    {
      "epoch": 0.7213333333333334,
      "grad_norm": 0.0991927981376648,
      "learning_rate": 3.196666666666667e-05,
      "loss": 0.0018,
      "step": 32460
    },
    {
      "epoch": 0.7215555555555555,
      "grad_norm": 0.19693294167518616,
      "learning_rate": 3.196111111111112e-05,
      "loss": 0.0025,
      "step": 32470
    },
    {
      "epoch": 0.7217777777777777,
      "grad_norm": 0.29177984595298767,
      "learning_rate": 3.1955555555555554e-05,
      "loss": 0.0021,
      "step": 32480
    },
    {
      "epoch": 0.722,
      "grad_norm": 0.09109319001436234,
      "learning_rate": 3.1950000000000004e-05,
      "loss": 0.0032,
      "step": 32490
    },
    {
      "epoch": 0.7222222222222222,
      "grad_norm": 0.06064119189977646,
      "learning_rate": 3.194444444444444e-05,
      "loss": 0.0029,
      "step": 32500
    },
    {
      "epoch": 0.7224444444444444,
      "grad_norm": 0.15398962795734406,
      "learning_rate": 3.193888888888889e-05,
      "loss": 0.0025,
      "step": 32510
    },
    {
      "epoch": 0.7226666666666667,
      "grad_norm": 0.1905711591243744,
      "learning_rate": 3.1933333333333335e-05,
      "loss": 0.0033,
      "step": 32520
    },
    {
      "epoch": 0.7228888888888889,
      "grad_norm": 0.5433496832847595,
      "learning_rate": 3.192777777777778e-05,
      "loss": 0.0022,
      "step": 32530
    },
    {
      "epoch": 0.7231111111111111,
      "grad_norm": 0.10410630702972412,
      "learning_rate": 3.192222222222223e-05,
      "loss": 0.0019,
      "step": 32540
    },
    {
      "epoch": 0.7233333333333334,
      "grad_norm": 0.4039677679538727,
      "learning_rate": 3.1916666666666665e-05,
      "loss": 0.0016,
      "step": 32550
    },
    {
      "epoch": 0.7235555555555555,
      "grad_norm": 0.07588671892881393,
      "learning_rate": 3.1911111111111116e-05,
      "loss": 0.0028,
      "step": 32560
    },
    {
      "epoch": 0.7237777777777777,
      "grad_norm": 0.2888246774673462,
      "learning_rate": 3.190555555555555e-05,
      "loss": 0.0022,
      "step": 32570
    },
    {
      "epoch": 0.724,
      "grad_norm": 0.2592949867248535,
      "learning_rate": 3.19e-05,
      "loss": 0.0023,
      "step": 32580
    },
    {
      "epoch": 0.7242222222222222,
      "grad_norm": 0.1292382925748825,
      "learning_rate": 3.1894444444444446e-05,
      "loss": 0.0019,
      "step": 32590
    },
    {
      "epoch": 0.7244444444444444,
      "grad_norm": 0.08090975880622864,
      "learning_rate": 3.188888888888889e-05,
      "loss": 0.003,
      "step": 32600
    },
    {
      "epoch": 0.7246666666666667,
      "grad_norm": 0.42506515979766846,
      "learning_rate": 3.188333333333334e-05,
      "loss": 0.0017,
      "step": 32610
    },
    {
      "epoch": 0.7248888888888889,
      "grad_norm": 0.6350328326225281,
      "learning_rate": 3.187777777777778e-05,
      "loss": 0.002,
      "step": 32620
    },
    {
      "epoch": 0.7251111111111112,
      "grad_norm": 0.48834478855133057,
      "learning_rate": 3.187222222222223e-05,
      "loss": 0.0019,
      "step": 32630
    },
    {
      "epoch": 0.7253333333333334,
      "grad_norm": 0.12306217104196548,
      "learning_rate": 3.1866666666666664e-05,
      "loss": 0.0022,
      "step": 32640
    },
    {
      "epoch": 0.7255555555555555,
      "grad_norm": 0.6199405193328857,
      "learning_rate": 3.1861111111111115e-05,
      "loss": 0.0023,
      "step": 32650
    },
    {
      "epoch": 0.7257777777777777,
      "grad_norm": 0.07064533978700638,
      "learning_rate": 3.185555555555556e-05,
      "loss": 0.0023,
      "step": 32660
    },
    {
      "epoch": 0.726,
      "grad_norm": 0.22222833335399628,
      "learning_rate": 3.185e-05,
      "loss": 0.0019,
      "step": 32670
    },
    {
      "epoch": 0.7262222222222222,
      "grad_norm": 0.4669576585292816,
      "learning_rate": 3.1844444444444445e-05,
      "loss": 0.0023,
      "step": 32680
    },
    {
      "epoch": 0.7264444444444444,
      "grad_norm": 0.2696005403995514,
      "learning_rate": 3.183888888888889e-05,
      "loss": 0.0025,
      "step": 32690
    },
    {
      "epoch": 0.7266666666666667,
      "grad_norm": 0.1158660501241684,
      "learning_rate": 3.183333333333334e-05,
      "loss": 0.0022,
      "step": 32700
    },
    {
      "epoch": 0.7268888888888889,
      "grad_norm": 0.24648898839950562,
      "learning_rate": 3.1827777777777776e-05,
      "loss": 0.0024,
      "step": 32710
    },
    {
      "epoch": 0.7271111111111112,
      "grad_norm": 0.08037199825048447,
      "learning_rate": 3.1822222222222226e-05,
      "loss": 0.0019,
      "step": 32720
    },
    {
      "epoch": 0.7273333333333334,
      "grad_norm": 1.0299328565597534,
      "learning_rate": 3.181666666666667e-05,
      "loss": 0.0033,
      "step": 32730
    },
    {
      "epoch": 0.7275555555555555,
      "grad_norm": 0.12876048684120178,
      "learning_rate": 3.181111111111111e-05,
      "loss": 0.0025,
      "step": 32740
    },
    {
      "epoch": 0.7277777777777777,
      "grad_norm": 0.2209760546684265,
      "learning_rate": 3.180555555555556e-05,
      "loss": 0.0026,
      "step": 32750
    },
    {
      "epoch": 0.728,
      "grad_norm": 0.6920538544654846,
      "learning_rate": 3.18e-05,
      "loss": 0.003,
      "step": 32760
    },
    {
      "epoch": 0.7282222222222222,
      "grad_norm": 0.2019146978855133,
      "learning_rate": 3.1794444444444444e-05,
      "loss": 0.0024,
      "step": 32770
    },
    {
      "epoch": 0.7284444444444444,
      "grad_norm": 0.4089711606502533,
      "learning_rate": 3.178888888888889e-05,
      "loss": 0.0022,
      "step": 32780
    },
    {
      "epoch": 0.7286666666666667,
      "grad_norm": 0.2070842981338501,
      "learning_rate": 3.178333333333334e-05,
      "loss": 0.0028,
      "step": 32790
    },
    {
      "epoch": 0.7288888888888889,
      "grad_norm": 0.23044151067733765,
      "learning_rate": 3.177777777777778e-05,
      "loss": 0.0024,
      "step": 32800
    },
    {
      "epoch": 0.7291111111111112,
      "grad_norm": 0.17323508858680725,
      "learning_rate": 3.1772222222222225e-05,
      "loss": 0.0025,
      "step": 32810
    },
    {
      "epoch": 0.7293333333333333,
      "grad_norm": 0.34520408511161804,
      "learning_rate": 3.176666666666667e-05,
      "loss": 0.0021,
      "step": 32820
    },
    {
      "epoch": 0.7295555555555555,
      "grad_norm": 0.8722782135009766,
      "learning_rate": 3.176111111111111e-05,
      "loss": 0.0025,
      "step": 32830
    },
    {
      "epoch": 0.7297777777777777,
      "grad_norm": 0.059541210532188416,
      "learning_rate": 3.1755555555555556e-05,
      "loss": 0.0018,
      "step": 32840
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.37376800179481506,
      "learning_rate": 3.175e-05,
      "loss": 0.0032,
      "step": 32850
    },
    {
      "epoch": 0.7302222222222222,
      "grad_norm": 0.10621486604213715,
      "learning_rate": 3.174444444444444e-05,
      "loss": 0.0025,
      "step": 32860
    },
    {
      "epoch": 0.7304444444444445,
      "grad_norm": 0.5476396679878235,
      "learning_rate": 3.173888888888889e-05,
      "loss": 0.0027,
      "step": 32870
    },
    {
      "epoch": 0.7306666666666667,
      "grad_norm": 0.6109206080436707,
      "learning_rate": 3.173333333333334e-05,
      "loss": 0.003,
      "step": 32880
    },
    {
      "epoch": 0.7308888888888889,
      "grad_norm": 0.07640504837036133,
      "learning_rate": 3.172777777777778e-05,
      "loss": 0.0028,
      "step": 32890
    },
    {
      "epoch": 0.7311111111111112,
      "grad_norm": 0.5681039094924927,
      "learning_rate": 3.1722222222222224e-05,
      "loss": 0.0025,
      "step": 32900
    },
    {
      "epoch": 0.7313333333333333,
      "grad_norm": 0.15466652810573578,
      "learning_rate": 3.171666666666667e-05,
      "loss": 0.0033,
      "step": 32910
    },
    {
      "epoch": 0.7315555555555555,
      "grad_norm": 0.057051487267017365,
      "learning_rate": 3.171111111111111e-05,
      "loss": 0.002,
      "step": 32920
    },
    {
      "epoch": 0.7317777777777777,
      "grad_norm": 0.14998385310173035,
      "learning_rate": 3.1705555555555554e-05,
      "loss": 0.0017,
      "step": 32930
    },
    {
      "epoch": 0.732,
      "grad_norm": 0.19914180040359497,
      "learning_rate": 3.1700000000000005e-05,
      "loss": 0.0029,
      "step": 32940
    },
    {
      "epoch": 0.7322222222222222,
      "grad_norm": 0.4483006000518799,
      "learning_rate": 3.169444444444444e-05,
      "loss": 0.0023,
      "step": 32950
    },
    {
      "epoch": 0.7324444444444445,
      "grad_norm": 0.2636825442314148,
      "learning_rate": 3.168888888888889e-05,
      "loss": 0.0028,
      "step": 32960
    },
    {
      "epoch": 0.7326666666666667,
      "grad_norm": 0.42329221963882446,
      "learning_rate": 3.1683333333333335e-05,
      "loss": 0.0021,
      "step": 32970
    },
    {
      "epoch": 0.7328888888888889,
      "grad_norm": 0.3872021734714508,
      "learning_rate": 3.167777777777778e-05,
      "loss": 0.0043,
      "step": 32980
    },
    {
      "epoch": 0.7331111111111112,
      "grad_norm": 0.3012581467628479,
      "learning_rate": 3.167222222222222e-05,
      "loss": 0.0024,
      "step": 32990
    },
    {
      "epoch": 0.7333333333333333,
      "grad_norm": 0.2418927103281021,
      "learning_rate": 3.1666666666666666e-05,
      "loss": 0.0019,
      "step": 33000
    },
    {
      "epoch": 0.7335555555555555,
      "grad_norm": 0.35419631004333496,
      "learning_rate": 3.1661111111111116e-05,
      "loss": 0.0019,
      "step": 33010
    },
    {
      "epoch": 0.7337777777777778,
      "grad_norm": 0.16281482577323914,
      "learning_rate": 3.165555555555555e-05,
      "loss": 0.0025,
      "step": 33020
    },
    {
      "epoch": 0.734,
      "grad_norm": 0.3259757459163666,
      "learning_rate": 3.1650000000000004e-05,
      "loss": 0.0019,
      "step": 33030
    },
    {
      "epoch": 0.7342222222222222,
      "grad_norm": 0.48319560289382935,
      "learning_rate": 3.164444444444444e-05,
      "loss": 0.0029,
      "step": 33040
    },
    {
      "epoch": 0.7344444444444445,
      "grad_norm": 0.21735407412052155,
      "learning_rate": 3.163888888888889e-05,
      "loss": 0.0019,
      "step": 33050
    },
    {
      "epoch": 0.7346666666666667,
      "grad_norm": 0.43398258090019226,
      "learning_rate": 3.1633333333333334e-05,
      "loss": 0.0023,
      "step": 33060
    },
    {
      "epoch": 0.7348888888888889,
      "grad_norm": 0.39087700843811035,
      "learning_rate": 3.162777777777778e-05,
      "loss": 0.0028,
      "step": 33070
    },
    {
      "epoch": 0.7351111111111112,
      "grad_norm": 0.2846531569957733,
      "learning_rate": 3.162222222222223e-05,
      "loss": 0.0027,
      "step": 33080
    },
    {
      "epoch": 0.7353333333333333,
      "grad_norm": 0.13067302107810974,
      "learning_rate": 3.1616666666666665e-05,
      "loss": 0.0026,
      "step": 33090
    },
    {
      "epoch": 0.7355555555555555,
      "grad_norm": 0.349764883518219,
      "learning_rate": 3.1611111111111115e-05,
      "loss": 0.002,
      "step": 33100
    },
    {
      "epoch": 0.7357777777777778,
      "grad_norm": 0.19647900760173798,
      "learning_rate": 3.160555555555555e-05,
      "loss": 0.0023,
      "step": 33110
    },
    {
      "epoch": 0.736,
      "grad_norm": 0.3094973862171173,
      "learning_rate": 3.16e-05,
      "loss": 0.0035,
      "step": 33120
    },
    {
      "epoch": 0.7362222222222222,
      "grad_norm": 0.19249695539474487,
      "learning_rate": 3.1594444444444446e-05,
      "loss": 0.002,
      "step": 33130
    },
    {
      "epoch": 0.7364444444444445,
      "grad_norm": 0.3122663199901581,
      "learning_rate": 3.158888888888889e-05,
      "loss": 0.0026,
      "step": 33140
    },
    {
      "epoch": 0.7366666666666667,
      "grad_norm": 0.22217562794685364,
      "learning_rate": 3.158333333333334e-05,
      "loss": 0.0027,
      "step": 33150
    },
    {
      "epoch": 0.7368888888888889,
      "grad_norm": 0.07867822051048279,
      "learning_rate": 3.1577777777777777e-05,
      "loss": 0.0021,
      "step": 33160
    },
    {
      "epoch": 0.7371111111111112,
      "grad_norm": 0.18458139896392822,
      "learning_rate": 3.157222222222223e-05,
      "loss": 0.0025,
      "step": 33170
    },
    {
      "epoch": 0.7373333333333333,
      "grad_norm": 0.15694183111190796,
      "learning_rate": 3.1566666666666664e-05,
      "loss": 0.0022,
      "step": 33180
    },
    {
      "epoch": 0.7375555555555555,
      "grad_norm": 0.632194995880127,
      "learning_rate": 3.1561111111111114e-05,
      "loss": 0.0025,
      "step": 33190
    },
    {
      "epoch": 0.7377777777777778,
      "grad_norm": 0.35263657569885254,
      "learning_rate": 3.155555555555556e-05,
      "loss": 0.0028,
      "step": 33200
    },
    {
      "epoch": 0.738,
      "grad_norm": 0.09851616621017456,
      "learning_rate": 3.155e-05,
      "loss": 0.0022,
      "step": 33210
    },
    {
      "epoch": 0.7382222222222222,
      "grad_norm": 0.0999051183462143,
      "learning_rate": 3.154444444444445e-05,
      "loss": 0.0017,
      "step": 33220
    },
    {
      "epoch": 0.7384444444444445,
      "grad_norm": 0.17939364910125732,
      "learning_rate": 3.153888888888889e-05,
      "loss": 0.002,
      "step": 33230
    },
    {
      "epoch": 0.7386666666666667,
      "grad_norm": 0.391118586063385,
      "learning_rate": 3.153333333333334e-05,
      "loss": 0.0027,
      "step": 33240
    },
    {
      "epoch": 0.7388888888888889,
      "grad_norm": 0.1248212531208992,
      "learning_rate": 3.1527777777777775e-05,
      "loss": 0.002,
      "step": 33250
    },
    {
      "epoch": 0.7391111111111112,
      "grad_norm": 0.5097466707229614,
      "learning_rate": 3.1522222222222226e-05,
      "loss": 0.0018,
      "step": 33260
    },
    {
      "epoch": 0.7393333333333333,
      "grad_norm": 0.33558881282806396,
      "learning_rate": 3.151666666666667e-05,
      "loss": 0.0022,
      "step": 33270
    },
    {
      "epoch": 0.7395555555555555,
      "grad_norm": 0.7001179456710815,
      "learning_rate": 3.151111111111111e-05,
      "loss": 0.0021,
      "step": 33280
    },
    {
      "epoch": 0.7397777777777778,
      "grad_norm": 0.11926456540822983,
      "learning_rate": 3.1505555555555556e-05,
      "loss": 0.0018,
      "step": 33290
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.1375412791967392,
      "learning_rate": 3.15e-05,
      "loss": 0.0026,
      "step": 33300
    },
    {
      "epoch": 0.7402222222222222,
      "grad_norm": 0.4862009286880493,
      "learning_rate": 3.149444444444445e-05,
      "loss": 0.0022,
      "step": 33310
    },
    {
      "epoch": 0.7404444444444445,
      "grad_norm": 0.2698548138141632,
      "learning_rate": 3.148888888888889e-05,
      "loss": 0.0028,
      "step": 33320
    },
    {
      "epoch": 0.7406666666666667,
      "grad_norm": 0.3685646951198578,
      "learning_rate": 3.148333333333334e-05,
      "loss": 0.0021,
      "step": 33330
    },
    {
      "epoch": 0.7408888888888889,
      "grad_norm": 0.15816590189933777,
      "learning_rate": 3.147777777777778e-05,
      "loss": 0.0019,
      "step": 33340
    },
    {
      "epoch": 0.7411111111111112,
      "grad_norm": 0.1195499449968338,
      "learning_rate": 3.1472222222222225e-05,
      "loss": 0.0018,
      "step": 33350
    },
    {
      "epoch": 0.7413333333333333,
      "grad_norm": 0.16250672936439514,
      "learning_rate": 3.146666666666667e-05,
      "loss": 0.0023,
      "step": 33360
    },
    {
      "epoch": 0.7415555555555555,
      "grad_norm": 0.1224290058016777,
      "learning_rate": 3.146111111111111e-05,
      "loss": 0.0023,
      "step": 33370
    },
    {
      "epoch": 0.7417777777777778,
      "grad_norm": 0.08401065319776535,
      "learning_rate": 3.1455555555555555e-05,
      "loss": 0.0021,
      "step": 33380
    },
    {
      "epoch": 0.742,
      "grad_norm": 0.10441668331623077,
      "learning_rate": 3.145e-05,
      "loss": 0.0024,
      "step": 33390
    },
    {
      "epoch": 0.7422222222222222,
      "grad_norm": 0.3891909122467041,
      "learning_rate": 3.144444444444445e-05,
      "loss": 0.0032,
      "step": 33400
    },
    {
      "epoch": 0.7424444444444445,
      "grad_norm": 0.19040504097938538,
      "learning_rate": 3.143888888888889e-05,
      "loss": 0.0024,
      "step": 33410
    },
    {
      "epoch": 0.7426666666666667,
      "grad_norm": 0.40108364820480347,
      "learning_rate": 3.1433333333333336e-05,
      "loss": 0.0024,
      "step": 33420
    },
    {
      "epoch": 0.7428888888888889,
      "grad_norm": 0.18679599463939667,
      "learning_rate": 3.142777777777778e-05,
      "loss": 0.0023,
      "step": 33430
    },
    {
      "epoch": 0.7431111111111111,
      "grad_norm": 0.6654512882232666,
      "learning_rate": 3.142222222222222e-05,
      "loss": 0.0026,
      "step": 33440
    },
    {
      "epoch": 0.7433333333333333,
      "grad_norm": 0.20519627630710602,
      "learning_rate": 3.141666666666667e-05,
      "loss": 0.0018,
      "step": 33450
    },
    {
      "epoch": 0.7435555555555555,
      "grad_norm": 0.1939816176891327,
      "learning_rate": 3.141111111111111e-05,
      "loss": 0.0033,
      "step": 33460
    },
    {
      "epoch": 0.7437777777777778,
      "grad_norm": 0.0664636567234993,
      "learning_rate": 3.1405555555555554e-05,
      "loss": 0.0036,
      "step": 33470
    },
    {
      "epoch": 0.744,
      "grad_norm": 0.49404972791671753,
      "learning_rate": 3.1400000000000004e-05,
      "loss": 0.0022,
      "step": 33480
    },
    {
      "epoch": 0.7442222222222222,
      "grad_norm": 0.3635734021663666,
      "learning_rate": 3.139444444444445e-05,
      "loss": 0.0033,
      "step": 33490
    },
    {
      "epoch": 0.7444444444444445,
      "grad_norm": 0.855633556842804,
      "learning_rate": 3.138888888888889e-05,
      "loss": 0.0022,
      "step": 33500
    },
    {
      "epoch": 0.7446666666666667,
      "grad_norm": 0.17564944922924042,
      "learning_rate": 3.1383333333333335e-05,
      "loss": 0.0022,
      "step": 33510
    },
    {
      "epoch": 0.7448888888888889,
      "grad_norm": 0.2125733345746994,
      "learning_rate": 3.137777777777778e-05,
      "loss": 0.0025,
      "step": 33520
    },
    {
      "epoch": 0.7451111111111111,
      "grad_norm": 0.536895215511322,
      "learning_rate": 3.137222222222222e-05,
      "loss": 0.0031,
      "step": 33530
    },
    {
      "epoch": 0.7453333333333333,
      "grad_norm": 0.26796334981918335,
      "learning_rate": 3.1366666666666666e-05,
      "loss": 0.0025,
      "step": 33540
    },
    {
      "epoch": 0.7455555555555555,
      "grad_norm": 0.23034067451953888,
      "learning_rate": 3.1361111111111116e-05,
      "loss": 0.0027,
      "step": 33550
    },
    {
      "epoch": 0.7457777777777778,
      "grad_norm": 0.43902918696403503,
      "learning_rate": 3.135555555555555e-05,
      "loss": 0.0031,
      "step": 33560
    },
    {
      "epoch": 0.746,
      "grad_norm": 0.1189834251999855,
      "learning_rate": 3.135e-05,
      "loss": 0.0019,
      "step": 33570
    },
    {
      "epoch": 0.7462222222222222,
      "grad_norm": 0.12639443576335907,
      "learning_rate": 3.134444444444445e-05,
      "loss": 0.0021,
      "step": 33580
    },
    {
      "epoch": 0.7464444444444445,
      "grad_norm": 0.36124998331069946,
      "learning_rate": 3.133888888888889e-05,
      "loss": 0.0022,
      "step": 33590
    },
    {
      "epoch": 0.7466666666666667,
      "grad_norm": 0.4957803785800934,
      "learning_rate": 3.1333333333333334e-05,
      "loss": 0.0021,
      "step": 33600
    },
    {
      "epoch": 0.7468888888888889,
      "grad_norm": 0.07917073369026184,
      "learning_rate": 3.132777777777778e-05,
      "loss": 0.0021,
      "step": 33610
    },
    {
      "epoch": 0.7471111111111111,
      "grad_norm": 0.4999418258666992,
      "learning_rate": 3.132222222222223e-05,
      "loss": 0.0026,
      "step": 33620
    },
    {
      "epoch": 0.7473333333333333,
      "grad_norm": 0.46450275182724,
      "learning_rate": 3.1316666666666664e-05,
      "loss": 0.0019,
      "step": 33630
    },
    {
      "epoch": 0.7475555555555555,
      "grad_norm": 0.2023441344499588,
      "learning_rate": 3.1311111111111115e-05,
      "loss": 0.0022,
      "step": 33640
    },
    {
      "epoch": 0.7477777777777778,
      "grad_norm": 0.6002823114395142,
      "learning_rate": 3.130555555555555e-05,
      "loss": 0.0021,
      "step": 33650
    },
    {
      "epoch": 0.748,
      "grad_norm": 0.19396738708019257,
      "learning_rate": 3.13e-05,
      "loss": 0.002,
      "step": 33660
    },
    {
      "epoch": 0.7482222222222222,
      "grad_norm": 0.28459078073501587,
      "learning_rate": 3.1294444444444445e-05,
      "loss": 0.0026,
      "step": 33670
    },
    {
      "epoch": 0.7484444444444445,
      "grad_norm": 0.41548770666122437,
      "learning_rate": 3.128888888888889e-05,
      "loss": 0.0022,
      "step": 33680
    },
    {
      "epoch": 0.7486666666666667,
      "grad_norm": 0.22851960361003876,
      "learning_rate": 3.128333333333334e-05,
      "loss": 0.0019,
      "step": 33690
    },
    {
      "epoch": 0.7488888888888889,
      "grad_norm": 0.8755497336387634,
      "learning_rate": 3.1277777777777776e-05,
      "loss": 0.0029,
      "step": 33700
    },
    {
      "epoch": 0.7491111111111111,
      "grad_norm": 0.3793640732765198,
      "learning_rate": 3.1272222222222226e-05,
      "loss": 0.0021,
      "step": 33710
    },
    {
      "epoch": 0.7493333333333333,
      "grad_norm": 0.073719821870327,
      "learning_rate": 3.126666666666666e-05,
      "loss": 0.0032,
      "step": 33720
    },
    {
      "epoch": 0.7495555555555555,
      "grad_norm": 0.3179789185523987,
      "learning_rate": 3.1261111111111114e-05,
      "loss": 0.0019,
      "step": 33730
    },
    {
      "epoch": 0.7497777777777778,
      "grad_norm": 0.17985029518604279,
      "learning_rate": 3.125555555555556e-05,
      "loss": 0.0025,
      "step": 33740
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.08387503027915955,
      "learning_rate": 3.125e-05,
      "loss": 0.0023,
      "step": 33750
    },
    {
      "epoch": 0.7502222222222222,
      "grad_norm": 0.7623613476753235,
      "learning_rate": 3.124444444444445e-05,
      "loss": 0.0019,
      "step": 33760
    },
    {
      "epoch": 0.7504444444444445,
      "grad_norm": 0.85611492395401,
      "learning_rate": 3.123888888888889e-05,
      "loss": 0.0038,
      "step": 33770
    },
    {
      "epoch": 0.7506666666666667,
      "grad_norm": 0.07530311495065689,
      "learning_rate": 3.123333333333334e-05,
      "loss": 0.0018,
      "step": 33780
    },
    {
      "epoch": 0.7508888888888889,
      "grad_norm": 0.11686157435178757,
      "learning_rate": 3.1227777777777775e-05,
      "loss": 0.0021,
      "step": 33790
    },
    {
      "epoch": 0.7511111111111111,
      "grad_norm": 0.2110794335603714,
      "learning_rate": 3.1222222222222225e-05,
      "loss": 0.0019,
      "step": 33800
    },
    {
      "epoch": 0.7513333333333333,
      "grad_norm": 0.13003236055374146,
      "learning_rate": 3.121666666666667e-05,
      "loss": 0.0025,
      "step": 33810
    },
    {
      "epoch": 0.7515555555555555,
      "grad_norm": 0.2428765743970871,
      "learning_rate": 3.121111111111111e-05,
      "loss": 0.0021,
      "step": 33820
    },
    {
      "epoch": 0.7517777777777778,
      "grad_norm": 0.5172675848007202,
      "learning_rate": 3.1205555555555556e-05,
      "loss": 0.0022,
      "step": 33830
    },
    {
      "epoch": 0.752,
      "grad_norm": 0.20421522855758667,
      "learning_rate": 3.12e-05,
      "loss": 0.0021,
      "step": 33840
    },
    {
      "epoch": 0.7522222222222222,
      "grad_norm": 0.4135793149471283,
      "learning_rate": 3.119444444444445e-05,
      "loss": 0.002,
      "step": 33850
    },
    {
      "epoch": 0.7524444444444445,
      "grad_norm": 0.46722427010536194,
      "learning_rate": 3.1188888888888887e-05,
      "loss": 0.0019,
      "step": 33860
    },
    {
      "epoch": 0.7526666666666667,
      "grad_norm": 0.1062973216176033,
      "learning_rate": 3.118333333333334e-05,
      "loss": 0.002,
      "step": 33870
    },
    {
      "epoch": 0.7528888888888889,
      "grad_norm": 0.07829706370830536,
      "learning_rate": 3.117777777777778e-05,
      "loss": 0.0022,
      "step": 33880
    },
    {
      "epoch": 0.7531111111111111,
      "grad_norm": 0.07392990589141846,
      "learning_rate": 3.1172222222222224e-05,
      "loss": 0.0025,
      "step": 33890
    },
    {
      "epoch": 0.7533333333333333,
      "grad_norm": 0.1597796380519867,
      "learning_rate": 3.116666666666667e-05,
      "loss": 0.0022,
      "step": 33900
    },
    {
      "epoch": 0.7535555555555555,
      "grad_norm": 0.12865331768989563,
      "learning_rate": 3.116111111111111e-05,
      "loss": 0.0022,
      "step": 33910
    },
    {
      "epoch": 0.7537777777777778,
      "grad_norm": 0.6022264361381531,
      "learning_rate": 3.1155555555555555e-05,
      "loss": 0.0024,
      "step": 33920
    },
    {
      "epoch": 0.754,
      "grad_norm": 0.3905452489852905,
      "learning_rate": 3.115e-05,
      "loss": 0.0019,
      "step": 33930
    },
    {
      "epoch": 0.7542222222222222,
      "grad_norm": 0.15843679010868073,
      "learning_rate": 3.114444444444445e-05,
      "loss": 0.0031,
      "step": 33940
    },
    {
      "epoch": 0.7544444444444445,
      "grad_norm": 0.10725158452987671,
      "learning_rate": 3.113888888888889e-05,
      "loss": 0.0023,
      "step": 33950
    },
    {
      "epoch": 0.7546666666666667,
      "grad_norm": 0.09166279435157776,
      "learning_rate": 3.1133333333333336e-05,
      "loss": 0.0025,
      "step": 33960
    },
    {
      "epoch": 0.7548888888888889,
      "grad_norm": 0.46188172698020935,
      "learning_rate": 3.112777777777778e-05,
      "loss": 0.0017,
      "step": 33970
    },
    {
      "epoch": 0.7551111111111111,
      "grad_norm": 0.2928915023803711,
      "learning_rate": 3.112222222222222e-05,
      "loss": 0.0019,
      "step": 33980
    },
    {
      "epoch": 0.7553333333333333,
      "grad_norm": 0.1955653429031372,
      "learning_rate": 3.1116666666666666e-05,
      "loss": 0.003,
      "step": 33990
    },
    {
      "epoch": 0.7555555555555555,
      "grad_norm": 0.23872902989387512,
      "learning_rate": 3.111111111111111e-05,
      "loss": 0.0016,
      "step": 34000
    },
    {
      "epoch": 0.7557777777777778,
      "grad_norm": 0.13270258903503418,
      "learning_rate": 3.1105555555555553e-05,
      "loss": 0.0019,
      "step": 34010
    },
    {
      "epoch": 0.756,
      "grad_norm": 0.38439205288887024,
      "learning_rate": 3.1100000000000004e-05,
      "loss": 0.0024,
      "step": 34020
    },
    {
      "epoch": 0.7562222222222222,
      "grad_norm": 0.21707221865653992,
      "learning_rate": 3.109444444444445e-05,
      "loss": 0.002,
      "step": 34030
    },
    {
      "epoch": 0.7564444444444445,
      "grad_norm": 0.08366597443819046,
      "learning_rate": 3.108888888888889e-05,
      "loss": 0.0028,
      "step": 34040
    },
    {
      "epoch": 0.7566666666666667,
      "grad_norm": 0.457823246717453,
      "learning_rate": 3.1083333333333334e-05,
      "loss": 0.0026,
      "step": 34050
    },
    {
      "epoch": 0.7568888888888889,
      "grad_norm": 0.08401764929294586,
      "learning_rate": 3.107777777777778e-05,
      "loss": 0.002,
      "step": 34060
    },
    {
      "epoch": 0.7571111111111111,
      "grad_norm": 0.22470177710056305,
      "learning_rate": 3.107222222222222e-05,
      "loss": 0.0022,
      "step": 34070
    },
    {
      "epoch": 0.7573333333333333,
      "grad_norm": 0.08518290519714355,
      "learning_rate": 3.1066666666666665e-05,
      "loss": 0.0023,
      "step": 34080
    },
    {
      "epoch": 0.7575555555555555,
      "grad_norm": 0.5374561548233032,
      "learning_rate": 3.1061111111111115e-05,
      "loss": 0.0018,
      "step": 34090
    },
    {
      "epoch": 0.7577777777777778,
      "grad_norm": 0.45790764689445496,
      "learning_rate": 3.105555555555555e-05,
      "loss": 0.0023,
      "step": 34100
    },
    {
      "epoch": 0.758,
      "grad_norm": 0.2333839386701584,
      "learning_rate": 3.105e-05,
      "loss": 0.002,
      "step": 34110
    },
    {
      "epoch": 0.7582222222222222,
      "grad_norm": 0.4329957067966461,
      "learning_rate": 3.1044444444444446e-05,
      "loss": 0.0023,
      "step": 34120
    },
    {
      "epoch": 0.7584444444444445,
      "grad_norm": 0.2026987075805664,
      "learning_rate": 3.103888888888889e-05,
      "loss": 0.0021,
      "step": 34130
    },
    {
      "epoch": 0.7586666666666667,
      "grad_norm": 0.24093221127986908,
      "learning_rate": 3.103333333333333e-05,
      "loss": 0.002,
      "step": 34140
    },
    {
      "epoch": 0.7588888888888888,
      "grad_norm": 0.13603074848651886,
      "learning_rate": 3.102777777777778e-05,
      "loss": 0.0019,
      "step": 34150
    },
    {
      "epoch": 0.7591111111111111,
      "grad_norm": 0.2612747848033905,
      "learning_rate": 3.102222222222223e-05,
      "loss": 0.0028,
      "step": 34160
    },
    {
      "epoch": 0.7593333333333333,
      "grad_norm": 0.34824058413505554,
      "learning_rate": 3.1016666666666664e-05,
      "loss": 0.002,
      "step": 34170
    },
    {
      "epoch": 0.7595555555555555,
      "grad_norm": 0.2697995603084564,
      "learning_rate": 3.1011111111111114e-05,
      "loss": 0.002,
      "step": 34180
    },
    {
      "epoch": 0.7597777777777778,
      "grad_norm": 0.37289130687713623,
      "learning_rate": 3.100555555555555e-05,
      "loss": 0.0019,
      "step": 34190
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.12622487545013428,
      "learning_rate": 3.1e-05,
      "loss": 0.0016,
      "step": 34200
    },
    {
      "epoch": 0.7602222222222222,
      "grad_norm": 0.5480309128761292,
      "learning_rate": 3.0994444444444445e-05,
      "loss": 0.0021,
      "step": 34210
    },
    {
      "epoch": 0.7604444444444445,
      "grad_norm": 0.24000458419322968,
      "learning_rate": 3.098888888888889e-05,
      "loss": 0.0023,
      "step": 34220
    },
    {
      "epoch": 0.7606666666666667,
      "grad_norm": 0.11472690850496292,
      "learning_rate": 3.098333333333334e-05,
      "loss": 0.0021,
      "step": 34230
    },
    {
      "epoch": 0.7608888888888888,
      "grad_norm": 0.2830040752887726,
      "learning_rate": 3.0977777777777776e-05,
      "loss": 0.0023,
      "step": 34240
    },
    {
      "epoch": 0.7611111111111111,
      "grad_norm": 0.4097723066806793,
      "learning_rate": 3.0972222222222226e-05,
      "loss": 0.0031,
      "step": 34250
    },
    {
      "epoch": 0.7613333333333333,
      "grad_norm": 0.3450022339820862,
      "learning_rate": 3.096666666666666e-05,
      "loss": 0.0038,
      "step": 34260
    },
    {
      "epoch": 0.7615555555555555,
      "grad_norm": 0.38248613476753235,
      "learning_rate": 3.096111111111111e-05,
      "loss": 0.0022,
      "step": 34270
    },
    {
      "epoch": 0.7617777777777778,
      "grad_norm": 0.41504567861557007,
      "learning_rate": 3.0955555555555557e-05,
      "loss": 0.0019,
      "step": 34280
    },
    {
      "epoch": 0.762,
      "grad_norm": 0.27409628033638,
      "learning_rate": 3.095e-05,
      "loss": 0.0019,
      "step": 34290
    },
    {
      "epoch": 0.7622222222222222,
      "grad_norm": 0.3333591818809509,
      "learning_rate": 3.094444444444445e-05,
      "loss": 0.0023,
      "step": 34300
    },
    {
      "epoch": 0.7624444444444445,
      "grad_norm": 0.33610886335372925,
      "learning_rate": 3.093888888888889e-05,
      "loss": 0.002,
      "step": 34310
    },
    {
      "epoch": 0.7626666666666667,
      "grad_norm": 0.14338403940200806,
      "learning_rate": 3.093333333333334e-05,
      "loss": 0.0019,
      "step": 34320
    },
    {
      "epoch": 0.7628888888888888,
      "grad_norm": 0.17676325142383575,
      "learning_rate": 3.0927777777777774e-05,
      "loss": 0.0026,
      "step": 34330
    },
    {
      "epoch": 0.7631111111111111,
      "grad_norm": 0.5436623692512512,
      "learning_rate": 3.0922222222222225e-05,
      "loss": 0.0019,
      "step": 34340
    },
    {
      "epoch": 0.7633333333333333,
      "grad_norm": 0.38587215542793274,
      "learning_rate": 3.091666666666667e-05,
      "loss": 0.0021,
      "step": 34350
    },
    {
      "epoch": 0.7635555555555555,
      "grad_norm": 0.37384673953056335,
      "learning_rate": 3.091111111111111e-05,
      "loss": 0.0018,
      "step": 34360
    },
    {
      "epoch": 0.7637777777777778,
      "grad_norm": 0.36657947301864624,
      "learning_rate": 3.0905555555555555e-05,
      "loss": 0.0023,
      "step": 34370
    },
    {
      "epoch": 0.764,
      "grad_norm": 0.6217219829559326,
      "learning_rate": 3.09e-05,
      "loss": 0.002,
      "step": 34380
    },
    {
      "epoch": 0.7642222222222222,
      "grad_norm": 0.1043529063463211,
      "learning_rate": 3.089444444444445e-05,
      "loss": 0.0026,
      "step": 34390
    },
    {
      "epoch": 0.7644444444444445,
      "grad_norm": 0.25525447726249695,
      "learning_rate": 3.088888888888889e-05,
      "loss": 0.002,
      "step": 34400
    },
    {
      "epoch": 0.7646666666666667,
      "grad_norm": 0.32529211044311523,
      "learning_rate": 3.0883333333333336e-05,
      "loss": 0.0026,
      "step": 34410
    },
    {
      "epoch": 0.7648888888888888,
      "grad_norm": 0.15090657770633698,
      "learning_rate": 3.087777777777778e-05,
      "loss": 0.0019,
      "step": 34420
    },
    {
      "epoch": 0.7651111111111111,
      "grad_norm": 0.4579845070838928,
      "learning_rate": 3.0872222222222223e-05,
      "loss": 0.0028,
      "step": 34430
    },
    {
      "epoch": 0.7653333333333333,
      "grad_norm": 0.1254495531320572,
      "learning_rate": 3.086666666666667e-05,
      "loss": 0.0019,
      "step": 34440
    },
    {
      "epoch": 0.7655555555555555,
      "grad_norm": 0.29762938618659973,
      "learning_rate": 3.086111111111111e-05,
      "loss": 0.0029,
      "step": 34450
    },
    {
      "epoch": 0.7657777777777778,
      "grad_norm": 0.14897479116916656,
      "learning_rate": 3.085555555555556e-05,
      "loss": 0.0018,
      "step": 34460
    },
    {
      "epoch": 0.766,
      "grad_norm": 0.4206985533237457,
      "learning_rate": 3.0850000000000004e-05,
      "loss": 0.0027,
      "step": 34470
    },
    {
      "epoch": 0.7662222222222222,
      "grad_norm": 0.32404908537864685,
      "learning_rate": 3.084444444444445e-05,
      "loss": 0.0028,
      "step": 34480
    },
    {
      "epoch": 0.7664444444444445,
      "grad_norm": 0.20635181665420532,
      "learning_rate": 3.083888888888889e-05,
      "loss": 0.0026,
      "step": 34490
    },
    {
      "epoch": 0.7666666666666667,
      "grad_norm": 0.6638965606689453,
      "learning_rate": 3.0833333333333335e-05,
      "loss": 0.0022,
      "step": 34500
    },
    {
      "epoch": 0.7668888888888888,
      "grad_norm": 0.7903128862380981,
      "learning_rate": 3.082777777777778e-05,
      "loss": 0.0037,
      "step": 34510
    },
    {
      "epoch": 0.7671111111111111,
      "grad_norm": 0.793924868106842,
      "learning_rate": 3.082222222222222e-05,
      "loss": 0.0024,
      "step": 34520
    },
    {
      "epoch": 0.7673333333333333,
      "grad_norm": 0.13531368970870972,
      "learning_rate": 3.0816666666666666e-05,
      "loss": 0.0025,
      "step": 34530
    },
    {
      "epoch": 0.7675555555555555,
      "grad_norm": 0.46950945258140564,
      "learning_rate": 3.0811111111111116e-05,
      "loss": 0.0021,
      "step": 34540
    },
    {
      "epoch": 0.7677777777777778,
      "grad_norm": 0.6220360994338989,
      "learning_rate": 3.080555555555556e-05,
      "loss": 0.0027,
      "step": 34550
    },
    {
      "epoch": 0.768,
      "grad_norm": 0.34829044342041016,
      "learning_rate": 3.08e-05,
      "loss": 0.0019,
      "step": 34560
    },
    {
      "epoch": 0.7682222222222223,
      "grad_norm": 0.16146551072597504,
      "learning_rate": 3.079444444444445e-05,
      "loss": 0.0026,
      "step": 34570
    },
    {
      "epoch": 0.7684444444444445,
      "grad_norm": 0.26645541191101074,
      "learning_rate": 3.078888888888889e-05,
      "loss": 0.0023,
      "step": 34580
    },
    {
      "epoch": 0.7686666666666667,
      "grad_norm": 0.3897271454334259,
      "learning_rate": 3.0783333333333334e-05,
      "loss": 0.0019,
      "step": 34590
    },
    {
      "epoch": 0.7688888888888888,
      "grad_norm": 0.11686938256025314,
      "learning_rate": 3.077777777777778e-05,
      "loss": 0.0027,
      "step": 34600
    },
    {
      "epoch": 0.7691111111111111,
      "grad_norm": 0.07618827372789383,
      "learning_rate": 3.077222222222223e-05,
      "loss": 0.0021,
      "step": 34610
    },
    {
      "epoch": 0.7693333333333333,
      "grad_norm": 0.5980158448219299,
      "learning_rate": 3.0766666666666665e-05,
      "loss": 0.0023,
      "step": 34620
    },
    {
      "epoch": 0.7695555555555555,
      "grad_norm": 0.2984372675418854,
      "learning_rate": 3.0761111111111115e-05,
      "loss": 0.0021,
      "step": 34630
    },
    {
      "epoch": 0.7697777777777778,
      "grad_norm": 0.06873819231987,
      "learning_rate": 3.075555555555556e-05,
      "loss": 0.0026,
      "step": 34640
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.31607651710510254,
      "learning_rate": 3.075e-05,
      "loss": 0.0026,
      "step": 34650
    },
    {
      "epoch": 0.7702222222222223,
      "grad_norm": 0.22516100108623505,
      "learning_rate": 3.0744444444444446e-05,
      "loss": 0.002,
      "step": 34660
    },
    {
      "epoch": 0.7704444444444445,
      "grad_norm": 0.4799349904060364,
      "learning_rate": 3.073888888888889e-05,
      "loss": 0.002,
      "step": 34670
    },
    {
      "epoch": 0.7706666666666667,
      "grad_norm": 0.15410324931144714,
      "learning_rate": 3.073333333333334e-05,
      "loss": 0.0021,
      "step": 34680
    },
    {
      "epoch": 0.7708888888888888,
      "grad_norm": 0.6136061549186707,
      "learning_rate": 3.0727777777777776e-05,
      "loss": 0.0022,
      "step": 34690
    },
    {
      "epoch": 0.7711111111111111,
      "grad_norm": 0.4878080487251282,
      "learning_rate": 3.0722222222222227e-05,
      "loss": 0.0024,
      "step": 34700
    },
    {
      "epoch": 0.7713333333333333,
      "grad_norm": 0.20789188146591187,
      "learning_rate": 3.0716666666666663e-05,
      "loss": 0.0021,
      "step": 34710
    },
    {
      "epoch": 0.7715555555555556,
      "grad_norm": 0.09506530314683914,
      "learning_rate": 3.0711111111111114e-05,
      "loss": 0.0018,
      "step": 34720
    },
    {
      "epoch": 0.7717777777777778,
      "grad_norm": 0.28072670102119446,
      "learning_rate": 3.070555555555556e-05,
      "loss": 0.0024,
      "step": 34730
    },
    {
      "epoch": 0.772,
      "grad_norm": 0.3518729507923126,
      "learning_rate": 3.07e-05,
      "loss": 0.0019,
      "step": 34740
    },
    {
      "epoch": 0.7722222222222223,
      "grad_norm": 0.29106584191322327,
      "learning_rate": 3.069444444444445e-05,
      "loss": 0.0031,
      "step": 34750
    },
    {
      "epoch": 0.7724444444444445,
      "grad_norm": 0.2724841833114624,
      "learning_rate": 3.068888888888889e-05,
      "loss": 0.0029,
      "step": 34760
    },
    {
      "epoch": 0.7726666666666666,
      "grad_norm": 0.2678697109222412,
      "learning_rate": 3.068333333333334e-05,
      "loss": 0.0021,
      "step": 34770
    },
    {
      "epoch": 0.7728888888888888,
      "grad_norm": 0.07775992155075073,
      "learning_rate": 3.0677777777777775e-05,
      "loss": 0.0026,
      "step": 34780
    },
    {
      "epoch": 0.7731111111111111,
      "grad_norm": 0.23573952913284302,
      "learning_rate": 3.0672222222222225e-05,
      "loss": 0.0025,
      "step": 34790
    },
    {
      "epoch": 0.7733333333333333,
      "grad_norm": 0.30074360966682434,
      "learning_rate": 3.066666666666667e-05,
      "loss": 0.0019,
      "step": 34800
    },
    {
      "epoch": 0.7735555555555556,
      "grad_norm": 0.052589528262615204,
      "learning_rate": 3.066111111111111e-05,
      "loss": 0.0032,
      "step": 34810
    },
    {
      "epoch": 0.7737777777777778,
      "grad_norm": 0.06258867681026459,
      "learning_rate": 3.065555555555556e-05,
      "loss": 0.0021,
      "step": 34820
    },
    {
      "epoch": 0.774,
      "grad_norm": 0.16621935367584229,
      "learning_rate": 3.065e-05,
      "loss": 0.0017,
      "step": 34830
    },
    {
      "epoch": 0.7742222222222223,
      "grad_norm": 0.0859382376074791,
      "learning_rate": 3.064444444444445e-05,
      "loss": 0.0023,
      "step": 34840
    },
    {
      "epoch": 0.7744444444444445,
      "grad_norm": 0.3498002886772156,
      "learning_rate": 3.063888888888889e-05,
      "loss": 0.002,
      "step": 34850
    },
    {
      "epoch": 0.7746666666666666,
      "grad_norm": 0.27012401819229126,
      "learning_rate": 3.063333333333334e-05,
      "loss": 0.0022,
      "step": 34860
    },
    {
      "epoch": 0.7748888888888888,
      "grad_norm": 0.10563784837722778,
      "learning_rate": 3.062777777777778e-05,
      "loss": 0.0027,
      "step": 34870
    },
    {
      "epoch": 0.7751111111111111,
      "grad_norm": 0.09254229813814163,
      "learning_rate": 3.0622222222222224e-05,
      "loss": 0.0022,
      "step": 34880
    },
    {
      "epoch": 0.7753333333333333,
      "grad_norm": 0.23001538217067719,
      "learning_rate": 3.061666666666667e-05,
      "loss": 0.0015,
      "step": 34890
    },
    {
      "epoch": 0.7755555555555556,
      "grad_norm": 0.2542048394680023,
      "learning_rate": 3.061111111111111e-05,
      "loss": 0.0022,
      "step": 34900
    },
    {
      "epoch": 0.7757777777777778,
      "grad_norm": 0.1766486018896103,
      "learning_rate": 3.060555555555556e-05,
      "loss": 0.0019,
      "step": 34910
    },
    {
      "epoch": 0.776,
      "grad_norm": 0.14318764209747314,
      "learning_rate": 3.06e-05,
      "loss": 0.0021,
      "step": 34920
    },
    {
      "epoch": 0.7762222222222223,
      "grad_norm": 0.08449044823646545,
      "learning_rate": 3.059444444444445e-05,
      "loss": 0.002,
      "step": 34930
    },
    {
      "epoch": 0.7764444444444445,
      "grad_norm": 0.3056349456310272,
      "learning_rate": 3.058888888888889e-05,
      "loss": 0.0023,
      "step": 34940
    },
    {
      "epoch": 0.7766666666666666,
      "grad_norm": 0.11435818672180176,
      "learning_rate": 3.0583333333333336e-05,
      "loss": 0.0037,
      "step": 34950
    },
    {
      "epoch": 0.7768888888888889,
      "grad_norm": 0.3649890422821045,
      "learning_rate": 3.057777777777778e-05,
      "loss": 0.0025,
      "step": 34960
    },
    {
      "epoch": 0.7771111111111111,
      "grad_norm": 0.4574781358242035,
      "learning_rate": 3.057222222222222e-05,
      "loss": 0.0024,
      "step": 34970
    },
    {
      "epoch": 0.7773333333333333,
      "grad_norm": 0.1498892903327942,
      "learning_rate": 3.0566666666666667e-05,
      "loss": 0.0027,
      "step": 34980
    },
    {
      "epoch": 0.7775555555555556,
      "grad_norm": 0.25024017691612244,
      "learning_rate": 3.056111111111111e-05,
      "loss": 0.0023,
      "step": 34990
    },
    {
      "epoch": 0.7777777777777778,
      "grad_norm": 0.2084314376115799,
      "learning_rate": 3.055555555555556e-05,
      "loss": 0.0026,
      "step": 35000
    },
    {
      "epoch": 0.778,
      "grad_norm": 0.18155092000961304,
      "learning_rate": 3.0550000000000004e-05,
      "loss": 0.0028,
      "step": 35010
    },
    {
      "epoch": 0.7782222222222223,
      "grad_norm": 0.44633838534355164,
      "learning_rate": 3.054444444444445e-05,
      "loss": 0.0019,
      "step": 35020
    },
    {
      "epoch": 0.7784444444444445,
      "grad_norm": 0.1836858093738556,
      "learning_rate": 3.053888888888889e-05,
      "loss": 0.0021,
      "step": 35030
    },
    {
      "epoch": 0.7786666666666666,
      "grad_norm": 0.5905869603157043,
      "learning_rate": 3.0533333333333335e-05,
      "loss": 0.0024,
      "step": 35040
    },
    {
      "epoch": 0.7788888888888889,
      "grad_norm": 0.10309714823961258,
      "learning_rate": 3.052777777777778e-05,
      "loss": 0.0027,
      "step": 35050
    },
    {
      "epoch": 0.7791111111111111,
      "grad_norm": 0.3367970287799835,
      "learning_rate": 3.052222222222222e-05,
      "loss": 0.0023,
      "step": 35060
    },
    {
      "epoch": 0.7793333333333333,
      "grad_norm": 0.6213488578796387,
      "learning_rate": 3.0516666666666665e-05,
      "loss": 0.0026,
      "step": 35070
    },
    {
      "epoch": 0.7795555555555556,
      "grad_norm": 0.09073935449123383,
      "learning_rate": 3.0511111111111112e-05,
      "loss": 0.0025,
      "step": 35080
    },
    {
      "epoch": 0.7797777777777778,
      "grad_norm": 0.1599307656288147,
      "learning_rate": 3.050555555555556e-05,
      "loss": 0.0036,
      "step": 35090
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.18288783729076385,
      "learning_rate": 3.05e-05,
      "loss": 0.0017,
      "step": 35100
    },
    {
      "epoch": 0.7802222222222223,
      "grad_norm": 0.3238145112991333,
      "learning_rate": 3.0494444444444446e-05,
      "loss": 0.0019,
      "step": 35110
    },
    {
      "epoch": 0.7804444444444445,
      "grad_norm": 0.1407029628753662,
      "learning_rate": 3.048888888888889e-05,
      "loss": 0.003,
      "step": 35120
    },
    {
      "epoch": 0.7806666666666666,
      "grad_norm": 0.19307102262973785,
      "learning_rate": 3.0483333333333337e-05,
      "loss": 0.0017,
      "step": 35130
    },
    {
      "epoch": 0.7808888888888889,
      "grad_norm": 0.13296332955360413,
      "learning_rate": 3.0477777777777777e-05,
      "loss": 0.0027,
      "step": 35140
    },
    {
      "epoch": 0.7811111111111111,
      "grad_norm": 0.31618162989616394,
      "learning_rate": 3.0472222222222224e-05,
      "loss": 0.0023,
      "step": 35150
    },
    {
      "epoch": 0.7813333333333333,
      "grad_norm": 0.09954648464918137,
      "learning_rate": 3.0466666666666664e-05,
      "loss": 0.0024,
      "step": 35160
    },
    {
      "epoch": 0.7815555555555556,
      "grad_norm": 0.08613119274377823,
      "learning_rate": 3.046111111111111e-05,
      "loss": 0.0026,
      "step": 35170
    },
    {
      "epoch": 0.7817777777777778,
      "grad_norm": 0.7652351260185242,
      "learning_rate": 3.0455555555555558e-05,
      "loss": 0.0022,
      "step": 35180
    },
    {
      "epoch": 0.782,
      "grad_norm": 0.15061067044734955,
      "learning_rate": 3.045e-05,
      "loss": 0.0017,
      "step": 35190
    },
    {
      "epoch": 0.7822222222222223,
      "grad_norm": 0.5010599493980408,
      "learning_rate": 3.044444444444445e-05,
      "loss": 0.0027,
      "step": 35200
    },
    {
      "epoch": 0.7824444444444445,
      "grad_norm": 0.2815741300582886,
      "learning_rate": 3.043888888888889e-05,
      "loss": 0.0023,
      "step": 35210
    },
    {
      "epoch": 0.7826666666666666,
      "grad_norm": 0.42191147804260254,
      "learning_rate": 3.0433333333333336e-05,
      "loss": 0.0038,
      "step": 35220
    },
    {
      "epoch": 0.7828888888888889,
      "grad_norm": 0.05455126240849495,
      "learning_rate": 3.0427777777777776e-05,
      "loss": 0.002,
      "step": 35230
    },
    {
      "epoch": 0.7831111111111111,
      "grad_norm": 0.1297026425600052,
      "learning_rate": 3.0422222222222223e-05,
      "loss": 0.0025,
      "step": 35240
    },
    {
      "epoch": 0.7833333333333333,
      "grad_norm": 0.6248058080673218,
      "learning_rate": 3.0416666666666666e-05,
      "loss": 0.0018,
      "step": 35250
    },
    {
      "epoch": 0.7835555555555556,
      "grad_norm": 0.2672524154186249,
      "learning_rate": 3.0411111111111113e-05,
      "loss": 0.0031,
      "step": 35260
    },
    {
      "epoch": 0.7837777777777778,
      "grad_norm": 0.2323761284351349,
      "learning_rate": 3.040555555555556e-05,
      "loss": 0.003,
      "step": 35270
    },
    {
      "epoch": 0.784,
      "grad_norm": 0.4154786467552185,
      "learning_rate": 3.04e-05,
      "loss": 0.0023,
      "step": 35280
    },
    {
      "epoch": 0.7842222222222223,
      "grad_norm": 0.20815005898475647,
      "learning_rate": 3.0394444444444447e-05,
      "loss": 0.0021,
      "step": 35290
    },
    {
      "epoch": 0.7844444444444445,
      "grad_norm": 0.10947025567293167,
      "learning_rate": 3.0388888888888887e-05,
      "loss": 0.0019,
      "step": 35300
    },
    {
      "epoch": 0.7846666666666666,
      "grad_norm": 0.39645034074783325,
      "learning_rate": 3.0383333333333334e-05,
      "loss": 0.0029,
      "step": 35310
    },
    {
      "epoch": 0.7848888888888889,
      "grad_norm": 0.6017937064170837,
      "learning_rate": 3.0377777777777778e-05,
      "loss": 0.0021,
      "step": 35320
    },
    {
      "epoch": 0.7851111111111111,
      "grad_norm": 0.32666510343551636,
      "learning_rate": 3.0372222222222225e-05,
      "loss": 0.0018,
      "step": 35330
    },
    {
      "epoch": 0.7853333333333333,
      "grad_norm": 0.38867485523223877,
      "learning_rate": 3.0366666666666665e-05,
      "loss": 0.0022,
      "step": 35340
    },
    {
      "epoch": 0.7855555555555556,
      "grad_norm": 0.49118006229400635,
      "learning_rate": 3.0361111111111112e-05,
      "loss": 0.0022,
      "step": 35350
    },
    {
      "epoch": 0.7857777777777778,
      "grad_norm": 0.19715720415115356,
      "learning_rate": 3.035555555555556e-05,
      "loss": 0.002,
      "step": 35360
    },
    {
      "epoch": 0.786,
      "grad_norm": 0.3273094892501831,
      "learning_rate": 3.035e-05,
      "loss": 0.0019,
      "step": 35370
    },
    {
      "epoch": 0.7862222222222223,
      "grad_norm": 0.2763400375843048,
      "learning_rate": 3.0344444444444446e-05,
      "loss": 0.002,
      "step": 35380
    },
    {
      "epoch": 0.7864444444444444,
      "grad_norm": 0.09896440804004669,
      "learning_rate": 3.033888888888889e-05,
      "loss": 0.0023,
      "step": 35390
    },
    {
      "epoch": 0.7866666666666666,
      "grad_norm": 0.07318156212568283,
      "learning_rate": 3.0333333333333337e-05,
      "loss": 0.0026,
      "step": 35400
    },
    {
      "epoch": 0.7868888888888889,
      "grad_norm": 0.14382074773311615,
      "learning_rate": 3.0327777777777777e-05,
      "loss": 0.0024,
      "step": 35410
    },
    {
      "epoch": 0.7871111111111111,
      "grad_norm": 0.4212665259838104,
      "learning_rate": 3.0322222222222224e-05,
      "loss": 0.0025,
      "step": 35420
    },
    {
      "epoch": 0.7873333333333333,
      "grad_norm": 0.20950545370578766,
      "learning_rate": 3.0316666666666664e-05,
      "loss": 0.0021,
      "step": 35430
    },
    {
      "epoch": 0.7875555555555556,
      "grad_norm": 0.2524945139884949,
      "learning_rate": 3.031111111111111e-05,
      "loss": 0.0033,
      "step": 35440
    },
    {
      "epoch": 0.7877777777777778,
      "grad_norm": 0.07185477763414383,
      "learning_rate": 3.0305555555555558e-05,
      "loss": 0.0021,
      "step": 35450
    },
    {
      "epoch": 0.788,
      "grad_norm": 0.5362460613250732,
      "learning_rate": 3.03e-05,
      "loss": 0.0026,
      "step": 35460
    },
    {
      "epoch": 0.7882222222222223,
      "grad_norm": 0.3134037256240845,
      "learning_rate": 3.0294444444444448e-05,
      "loss": 0.002,
      "step": 35470
    },
    {
      "epoch": 0.7884444444444444,
      "grad_norm": 0.4281156361103058,
      "learning_rate": 3.028888888888889e-05,
      "loss": 0.0027,
      "step": 35480
    },
    {
      "epoch": 0.7886666666666666,
      "grad_norm": 0.4144333302974701,
      "learning_rate": 3.0283333333333335e-05,
      "loss": 0.0023,
      "step": 35490
    },
    {
      "epoch": 0.7888888888888889,
      "grad_norm": 0.0794001892209053,
      "learning_rate": 3.0277777777777776e-05,
      "loss": 0.0017,
      "step": 35500
    },
    {
      "epoch": 0.7891111111111111,
      "grad_norm": 0.31276702880859375,
      "learning_rate": 3.0272222222222222e-05,
      "loss": 0.0018,
      "step": 35510
    },
    {
      "epoch": 0.7893333333333333,
      "grad_norm": 0.067759670317173,
      "learning_rate": 3.0266666666666666e-05,
      "loss": 0.0021,
      "step": 35520
    },
    {
      "epoch": 0.7895555555555556,
      "grad_norm": 0.2965187132358551,
      "learning_rate": 3.0261111111111113e-05,
      "loss": 0.0026,
      "step": 35530
    },
    {
      "epoch": 0.7897777777777778,
      "grad_norm": 0.10860148817300797,
      "learning_rate": 3.025555555555556e-05,
      "loss": 0.0025,
      "step": 35540
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.2781578004360199,
      "learning_rate": 3.025e-05,
      "loss": 0.0019,
      "step": 35550
    },
    {
      "epoch": 0.7902222222222223,
      "grad_norm": 0.4025581479072571,
      "learning_rate": 3.0244444444444447e-05,
      "loss": 0.0018,
      "step": 35560
    },
    {
      "epoch": 0.7904444444444444,
      "grad_norm": 0.21984079480171204,
      "learning_rate": 3.0238888888888887e-05,
      "loss": 0.0027,
      "step": 35570
    },
    {
      "epoch": 0.7906666666666666,
      "grad_norm": 0.17049255967140198,
      "learning_rate": 3.0233333333333334e-05,
      "loss": 0.0023,
      "step": 35580
    },
    {
      "epoch": 0.7908888888888889,
      "grad_norm": 0.31367531418800354,
      "learning_rate": 3.0227777777777778e-05,
      "loss": 0.0024,
      "step": 35590
    },
    {
      "epoch": 0.7911111111111111,
      "grad_norm": 0.38028547167778015,
      "learning_rate": 3.0222222222222225e-05,
      "loss": 0.0021,
      "step": 35600
    },
    {
      "epoch": 0.7913333333333333,
      "grad_norm": 0.08391613513231277,
      "learning_rate": 3.0216666666666665e-05,
      "loss": 0.0024,
      "step": 35610
    },
    {
      "epoch": 0.7915555555555556,
      "grad_norm": 0.1093999594449997,
      "learning_rate": 3.0211111111111112e-05,
      "loss": 0.0021,
      "step": 35620
    },
    {
      "epoch": 0.7917777777777778,
      "grad_norm": 0.16228769719600677,
      "learning_rate": 3.020555555555556e-05,
      "loss": 0.0024,
      "step": 35630
    },
    {
      "epoch": 0.792,
      "grad_norm": 0.1549418866634369,
      "learning_rate": 3.02e-05,
      "loss": 0.0019,
      "step": 35640
    },
    {
      "epoch": 0.7922222222222223,
      "grad_norm": 0.0923733189702034,
      "learning_rate": 3.0194444444444446e-05,
      "loss": 0.0018,
      "step": 35650
    },
    {
      "epoch": 0.7924444444444444,
      "grad_norm": 0.17715248465538025,
      "learning_rate": 3.018888888888889e-05,
      "loss": 0.002,
      "step": 35660
    },
    {
      "epoch": 0.7926666666666666,
      "grad_norm": 0.15630033612251282,
      "learning_rate": 3.0183333333333336e-05,
      "loss": 0.0019,
      "step": 35670
    },
    {
      "epoch": 0.7928888888888889,
      "grad_norm": 0.14940738677978516,
      "learning_rate": 3.0177777777777776e-05,
      "loss": 0.0029,
      "step": 35680
    },
    {
      "epoch": 0.7931111111111111,
      "grad_norm": 0.17343522608280182,
      "learning_rate": 3.0172222222222223e-05,
      "loss": 0.002,
      "step": 35690
    },
    {
      "epoch": 0.7933333333333333,
      "grad_norm": 0.21858200430870056,
      "learning_rate": 3.016666666666667e-05,
      "loss": 0.0022,
      "step": 35700
    },
    {
      "epoch": 0.7935555555555556,
      "grad_norm": 0.23404647409915924,
      "learning_rate": 3.016111111111111e-05,
      "loss": 0.0034,
      "step": 35710
    },
    {
      "epoch": 0.7937777777777778,
      "grad_norm": 0.2935597896575928,
      "learning_rate": 3.0155555555555557e-05,
      "loss": 0.0018,
      "step": 35720
    },
    {
      "epoch": 0.794,
      "grad_norm": 0.4687335193157196,
      "learning_rate": 3.015e-05,
      "loss": 0.002,
      "step": 35730
    },
    {
      "epoch": 0.7942222222222223,
      "grad_norm": 0.15028654038906097,
      "learning_rate": 3.0144444444444448e-05,
      "loss": 0.002,
      "step": 35740
    },
    {
      "epoch": 0.7944444444444444,
      "grad_norm": 0.05828221142292023,
      "learning_rate": 3.0138888888888888e-05,
      "loss": 0.0027,
      "step": 35750
    },
    {
      "epoch": 0.7946666666666666,
      "grad_norm": 0.16156737506389618,
      "learning_rate": 3.0133333333333335e-05,
      "loss": 0.0023,
      "step": 35760
    },
    {
      "epoch": 0.7948888888888889,
      "grad_norm": 0.29166918992996216,
      "learning_rate": 3.012777777777778e-05,
      "loss": 0.0026,
      "step": 35770
    },
    {
      "epoch": 0.7951111111111111,
      "grad_norm": 0.15079672634601593,
      "learning_rate": 3.0122222222222226e-05,
      "loss": 0.0027,
      "step": 35780
    },
    {
      "epoch": 0.7953333333333333,
      "grad_norm": 0.18361195921897888,
      "learning_rate": 3.011666666666667e-05,
      "loss": 0.0018,
      "step": 35790
    },
    {
      "epoch": 0.7955555555555556,
      "grad_norm": 0.061370570212602615,
      "learning_rate": 3.0111111111111113e-05,
      "loss": 0.0031,
      "step": 35800
    },
    {
      "epoch": 0.7957777777777778,
      "grad_norm": 0.10033971071243286,
      "learning_rate": 3.010555555555556e-05,
      "loss": 0.0018,
      "step": 35810
    },
    {
      "epoch": 0.796,
      "grad_norm": 0.2294633686542511,
      "learning_rate": 3.01e-05,
      "loss": 0.002,
      "step": 35820
    },
    {
      "epoch": 0.7962222222222223,
      "grad_norm": 0.0940779522061348,
      "learning_rate": 3.0094444444444447e-05,
      "loss": 0.0018,
      "step": 35830
    },
    {
      "epoch": 0.7964444444444444,
      "grad_norm": 0.3318639397621155,
      "learning_rate": 3.008888888888889e-05,
      "loss": 0.0029,
      "step": 35840
    },
    {
      "epoch": 0.7966666666666666,
      "grad_norm": 0.23756596446037292,
      "learning_rate": 3.0083333333333337e-05,
      "loss": 0.0024,
      "step": 35850
    },
    {
      "epoch": 0.7968888888888889,
      "grad_norm": 0.16820813715457916,
      "learning_rate": 3.0077777777777777e-05,
      "loss": 0.0027,
      "step": 35860
    },
    {
      "epoch": 0.7971111111111111,
      "grad_norm": 0.4341326951980591,
      "learning_rate": 3.0072222222222224e-05,
      "loss": 0.003,
      "step": 35870
    },
    {
      "epoch": 0.7973333333333333,
      "grad_norm": 0.06074857339262962,
      "learning_rate": 3.006666666666667e-05,
      "loss": 0.0019,
      "step": 35880
    },
    {
      "epoch": 0.7975555555555556,
      "grad_norm": 0.35036036372184753,
      "learning_rate": 3.006111111111111e-05,
      "loss": 0.0028,
      "step": 35890
    },
    {
      "epoch": 0.7977777777777778,
      "grad_norm": 0.09959518909454346,
      "learning_rate": 3.005555555555556e-05,
      "loss": 0.0031,
      "step": 35900
    },
    {
      "epoch": 0.798,
      "grad_norm": 0.10498080402612686,
      "learning_rate": 3.0050000000000002e-05,
      "loss": 0.0028,
      "step": 35910
    },
    {
      "epoch": 0.7982222222222223,
      "grad_norm": 0.12127930670976639,
      "learning_rate": 3.004444444444445e-05,
      "loss": 0.0022,
      "step": 35920
    },
    {
      "epoch": 0.7984444444444444,
      "grad_norm": 0.2015269696712494,
      "learning_rate": 3.003888888888889e-05,
      "loss": 0.0026,
      "step": 35930
    },
    {
      "epoch": 0.7986666666666666,
      "grad_norm": 0.46523621678352356,
      "learning_rate": 3.0033333333333336e-05,
      "loss": 0.0039,
      "step": 35940
    },
    {
      "epoch": 0.7988888888888889,
      "grad_norm": 0.20936161279678345,
      "learning_rate": 3.0027777777777776e-05,
      "loss": 0.0022,
      "step": 35950
    },
    {
      "epoch": 0.7991111111111111,
      "grad_norm": 0.3797179162502289,
      "learning_rate": 3.0022222222222223e-05,
      "loss": 0.0026,
      "step": 35960
    },
    {
      "epoch": 0.7993333333333333,
      "grad_norm": 0.17858083546161652,
      "learning_rate": 3.001666666666667e-05,
      "loss": 0.002,
      "step": 35970
    },
    {
      "epoch": 0.7995555555555556,
      "grad_norm": 0.18052968382835388,
      "learning_rate": 3.0011111111111114e-05,
      "loss": 0.0019,
      "step": 35980
    },
    {
      "epoch": 0.7997777777777778,
      "grad_norm": 0.2432015836238861,
      "learning_rate": 3.000555555555556e-05,
      "loss": 0.0025,
      "step": 35990
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.0821508914232254,
      "learning_rate": 3e-05,
      "loss": 0.0028,
      "step": 36000
    },
    {
      "epoch": 0.8002222222222222,
      "grad_norm": 0.07888780534267426,
      "learning_rate": 2.9994444444444448e-05,
      "loss": 0.0022,
      "step": 36010
    },
    {
      "epoch": 0.8004444444444444,
      "grad_norm": 0.13238602876663208,
      "learning_rate": 2.9988888888888888e-05,
      "loss": 0.0019,
      "step": 36020
    },
    {
      "epoch": 0.8006666666666666,
      "grad_norm": 0.08385069668292999,
      "learning_rate": 2.9983333333333335e-05,
      "loss": 0.0023,
      "step": 36030
    },
    {
      "epoch": 0.8008888888888889,
      "grad_norm": 0.43268460035324097,
      "learning_rate": 2.997777777777778e-05,
      "loss": 0.0018,
      "step": 36040
    },
    {
      "epoch": 0.8011111111111111,
      "grad_norm": 0.09262342005968094,
      "learning_rate": 2.9972222222222225e-05,
      "loss": 0.002,
      "step": 36050
    },
    {
      "epoch": 0.8013333333333333,
      "grad_norm": 0.1830315887928009,
      "learning_rate": 2.9966666666666672e-05,
      "loss": 0.0023,
      "step": 36060
    },
    {
      "epoch": 0.8015555555555556,
      "grad_norm": 0.39518022537231445,
      "learning_rate": 2.9961111111111112e-05,
      "loss": 0.002,
      "step": 36070
    },
    {
      "epoch": 0.8017777777777778,
      "grad_norm": 0.2487061321735382,
      "learning_rate": 2.995555555555556e-05,
      "loss": 0.0019,
      "step": 36080
    },
    {
      "epoch": 0.802,
      "grad_norm": 0.25696972012519836,
      "learning_rate": 2.995e-05,
      "loss": 0.0019,
      "step": 36090
    },
    {
      "epoch": 0.8022222222222222,
      "grad_norm": 0.31052398681640625,
      "learning_rate": 2.9944444444444446e-05,
      "loss": 0.0026,
      "step": 36100
    },
    {
      "epoch": 0.8024444444444444,
      "grad_norm": 0.44836321473121643,
      "learning_rate": 2.993888888888889e-05,
      "loss": 0.0023,
      "step": 36110
    },
    {
      "epoch": 0.8026666666666666,
      "grad_norm": 0.20416967570781708,
      "learning_rate": 2.9933333333333337e-05,
      "loss": 0.0023,
      "step": 36120
    },
    {
      "epoch": 0.8028888888888889,
      "grad_norm": 0.15391288697719574,
      "learning_rate": 2.9927777777777777e-05,
      "loss": 0.0021,
      "step": 36130
    },
    {
      "epoch": 0.8031111111111111,
      "grad_norm": 0.32095012068748474,
      "learning_rate": 2.9922222222222224e-05,
      "loss": 0.003,
      "step": 36140
    },
    {
      "epoch": 0.8033333333333333,
      "grad_norm": 0.18057651817798615,
      "learning_rate": 2.991666666666667e-05,
      "loss": 0.0019,
      "step": 36150
    },
    {
      "epoch": 0.8035555555555556,
      "grad_norm": 0.3948954939842224,
      "learning_rate": 2.991111111111111e-05,
      "loss": 0.0027,
      "step": 36160
    },
    {
      "epoch": 0.8037777777777778,
      "grad_norm": 0.3798057734966278,
      "learning_rate": 2.9905555555555558e-05,
      "loss": 0.0021,
      "step": 36170
    },
    {
      "epoch": 0.804,
      "grad_norm": 0.7307071685791016,
      "learning_rate": 2.9900000000000002e-05,
      "loss": 0.002,
      "step": 36180
    },
    {
      "epoch": 0.8042222222222222,
      "grad_norm": 0.49702179431915283,
      "learning_rate": 2.989444444444445e-05,
      "loss": 0.002,
      "step": 36190
    },
    {
      "epoch": 0.8044444444444444,
      "grad_norm": 0.31514668464660645,
      "learning_rate": 2.988888888888889e-05,
      "loss": 0.002,
      "step": 36200
    },
    {
      "epoch": 0.8046666666666666,
      "grad_norm": 0.301431804895401,
      "learning_rate": 2.9883333333333336e-05,
      "loss": 0.0031,
      "step": 36210
    },
    {
      "epoch": 0.8048888888888889,
      "grad_norm": 0.1842985898256302,
      "learning_rate": 2.9877777777777776e-05,
      "loss": 0.0017,
      "step": 36220
    },
    {
      "epoch": 0.8051111111111111,
      "grad_norm": 0.4473089873790741,
      "learning_rate": 2.9872222222222223e-05,
      "loss": 0.0018,
      "step": 36230
    },
    {
      "epoch": 0.8053333333333333,
      "grad_norm": 0.0961829349398613,
      "learning_rate": 2.986666666666667e-05,
      "loss": 0.0022,
      "step": 36240
    },
    {
      "epoch": 0.8055555555555556,
      "grad_norm": 0.13217304646968842,
      "learning_rate": 2.9861111111111113e-05,
      "loss": 0.0034,
      "step": 36250
    },
    {
      "epoch": 0.8057777777777778,
      "grad_norm": 0.1157500147819519,
      "learning_rate": 2.985555555555556e-05,
      "loss": 0.0025,
      "step": 36260
    },
    {
      "epoch": 0.806,
      "grad_norm": 0.08032616227865219,
      "learning_rate": 2.985e-05,
      "loss": 0.0029,
      "step": 36270
    },
    {
      "epoch": 0.8062222222222222,
      "grad_norm": 0.497234046459198,
      "learning_rate": 2.9844444444444447e-05,
      "loss": 0.0024,
      "step": 36280
    },
    {
      "epoch": 0.8064444444444444,
      "grad_norm": 0.5396566987037659,
      "learning_rate": 2.9838888888888888e-05,
      "loss": 0.0018,
      "step": 36290
    },
    {
      "epoch": 0.8066666666666666,
      "grad_norm": 0.27960091829299927,
      "learning_rate": 2.9833333333333335e-05,
      "loss": 0.004,
      "step": 36300
    },
    {
      "epoch": 0.8068888888888889,
      "grad_norm": 0.24385806918144226,
      "learning_rate": 2.9827777777777778e-05,
      "loss": 0.0019,
      "step": 36310
    },
    {
      "epoch": 0.8071111111111111,
      "grad_norm": 0.09164990484714508,
      "learning_rate": 2.9822222222222225e-05,
      "loss": 0.0019,
      "step": 36320
    },
    {
      "epoch": 0.8073333333333333,
      "grad_norm": 0.6952590346336365,
      "learning_rate": 2.9816666666666672e-05,
      "loss": 0.0034,
      "step": 36330
    },
    {
      "epoch": 0.8075555555555556,
      "grad_norm": 0.21251513063907623,
      "learning_rate": 2.9811111111111112e-05,
      "loss": 0.002,
      "step": 36340
    },
    {
      "epoch": 0.8077777777777778,
      "grad_norm": 0.3369898796081543,
      "learning_rate": 2.980555555555556e-05,
      "loss": 0.0016,
      "step": 36350
    },
    {
      "epoch": 0.808,
      "grad_norm": 0.21441836655139923,
      "learning_rate": 2.98e-05,
      "loss": 0.0026,
      "step": 36360
    },
    {
      "epoch": 0.8082222222222222,
      "grad_norm": 0.09787895530462265,
      "learning_rate": 2.9794444444444446e-05,
      "loss": 0.0028,
      "step": 36370
    },
    {
      "epoch": 0.8084444444444444,
      "grad_norm": 0.08131107687950134,
      "learning_rate": 2.978888888888889e-05,
      "loss": 0.002,
      "step": 36380
    },
    {
      "epoch": 0.8086666666666666,
      "grad_norm": 0.3458559513092041,
      "learning_rate": 2.9783333333333337e-05,
      "loss": 0.0029,
      "step": 36390
    },
    {
      "epoch": 0.8088888888888889,
      "grad_norm": 0.5516549348831177,
      "learning_rate": 2.9777777777777777e-05,
      "loss": 0.0023,
      "step": 36400
    },
    {
      "epoch": 0.8091111111111111,
      "grad_norm": 0.48001599311828613,
      "learning_rate": 2.9772222222222224e-05,
      "loss": 0.0018,
      "step": 36410
    },
    {
      "epoch": 0.8093333333333333,
      "grad_norm": 0.21962705254554749,
      "learning_rate": 2.976666666666667e-05,
      "loss": 0.0019,
      "step": 36420
    },
    {
      "epoch": 0.8095555555555556,
      "grad_norm": 0.3311052620410919,
      "learning_rate": 2.976111111111111e-05,
      "loss": 0.0041,
      "step": 36430
    },
    {
      "epoch": 0.8097777777777778,
      "grad_norm": 0.2621997892856598,
      "learning_rate": 2.9755555555555558e-05,
      "loss": 0.0023,
      "step": 36440
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.11517465114593506,
      "learning_rate": 2.975e-05,
      "loss": 0.0029,
      "step": 36450
    },
    {
      "epoch": 0.8102222222222222,
      "grad_norm": 0.26056167483329773,
      "learning_rate": 2.974444444444445e-05,
      "loss": 0.0019,
      "step": 36460
    },
    {
      "epoch": 0.8104444444444444,
      "grad_norm": 0.5258575677871704,
      "learning_rate": 2.973888888888889e-05,
      "loss": 0.0021,
      "step": 36470
    },
    {
      "epoch": 0.8106666666666666,
      "grad_norm": 0.13166089355945587,
      "learning_rate": 2.9733333333333336e-05,
      "loss": 0.0024,
      "step": 36480
    },
    {
      "epoch": 0.8108888888888889,
      "grad_norm": 0.3008231222629547,
      "learning_rate": 2.9727777777777776e-05,
      "loss": 0.0029,
      "step": 36490
    },
    {
      "epoch": 0.8111111111111111,
      "grad_norm": 0.1195363700389862,
      "learning_rate": 2.9722222222222223e-05,
      "loss": 0.0024,
      "step": 36500
    },
    {
      "epoch": 0.8113333333333334,
      "grad_norm": 0.24261000752449036,
      "learning_rate": 2.971666666666667e-05,
      "loss": 0.0022,
      "step": 36510
    },
    {
      "epoch": 0.8115555555555556,
      "grad_norm": 0.2973831593990326,
      "learning_rate": 2.9711111111111113e-05,
      "loss": 0.0034,
      "step": 36520
    },
    {
      "epoch": 0.8117777777777778,
      "grad_norm": 0.16873586177825928,
      "learning_rate": 2.970555555555556e-05,
      "loss": 0.0026,
      "step": 36530
    },
    {
      "epoch": 0.812,
      "grad_norm": 0.3405784070491791,
      "learning_rate": 2.97e-05,
      "loss": 0.002,
      "step": 36540
    },
    {
      "epoch": 0.8122222222222222,
      "grad_norm": 0.2424057126045227,
      "learning_rate": 2.9694444444444447e-05,
      "loss": 0.0028,
      "step": 36550
    },
    {
      "epoch": 0.8124444444444444,
      "grad_norm": 0.3433505892753601,
      "learning_rate": 2.9688888888888887e-05,
      "loss": 0.0035,
      "step": 36560
    },
    {
      "epoch": 0.8126666666666666,
      "grad_norm": 0.33098793029785156,
      "learning_rate": 2.9683333333333334e-05,
      "loss": 0.0023,
      "step": 36570
    },
    {
      "epoch": 0.8128888888888889,
      "grad_norm": 0.21795639395713806,
      "learning_rate": 2.9677777777777778e-05,
      "loss": 0.0029,
      "step": 36580
    },
    {
      "epoch": 0.8131111111111111,
      "grad_norm": 0.35266926884651184,
      "learning_rate": 2.9672222222222225e-05,
      "loss": 0.0021,
      "step": 36590
    },
    {
      "epoch": 0.8133333333333334,
      "grad_norm": 0.16684606671333313,
      "learning_rate": 2.9666666666666672e-05,
      "loss": 0.0024,
      "step": 36600
    },
    {
      "epoch": 0.8135555555555556,
      "grad_norm": 0.2771730422973633,
      "learning_rate": 2.9661111111111112e-05,
      "loss": 0.0021,
      "step": 36610
    },
    {
      "epoch": 0.8137777777777778,
      "grad_norm": 0.10995165258646011,
      "learning_rate": 2.965555555555556e-05,
      "loss": 0.003,
      "step": 36620
    },
    {
      "epoch": 0.814,
      "grad_norm": 0.0912749245762825,
      "learning_rate": 2.965e-05,
      "loss": 0.002,
      "step": 36630
    },
    {
      "epoch": 0.8142222222222222,
      "grad_norm": 0.06391055136919022,
      "learning_rate": 2.9644444444444446e-05,
      "loss": 0.0016,
      "step": 36640
    },
    {
      "epoch": 0.8144444444444444,
      "grad_norm": 0.4829151928424835,
      "learning_rate": 2.963888888888889e-05,
      "loss": 0.002,
      "step": 36650
    },
    {
      "epoch": 0.8146666666666667,
      "grad_norm": 0.16508057713508606,
      "learning_rate": 2.9633333333333336e-05,
      "loss": 0.0019,
      "step": 36660
    },
    {
      "epoch": 0.8148888888888889,
      "grad_norm": 0.1286037415266037,
      "learning_rate": 2.9627777777777777e-05,
      "loss": 0.0017,
      "step": 36670
    },
    {
      "epoch": 0.8151111111111111,
      "grad_norm": 0.31948062777519226,
      "learning_rate": 2.9622222222222224e-05,
      "loss": 0.0019,
      "step": 36680
    },
    {
      "epoch": 0.8153333333333334,
      "grad_norm": 0.07138705253601074,
      "learning_rate": 2.961666666666667e-05,
      "loss": 0.0017,
      "step": 36690
    },
    {
      "epoch": 0.8155555555555556,
      "grad_norm": 0.516278862953186,
      "learning_rate": 2.961111111111111e-05,
      "loss": 0.0018,
      "step": 36700
    },
    {
      "epoch": 0.8157777777777778,
      "grad_norm": 0.312743604183197,
      "learning_rate": 2.9605555555555558e-05,
      "loss": 0.0032,
      "step": 36710
    },
    {
      "epoch": 0.816,
      "grad_norm": 0.4203760027885437,
      "learning_rate": 2.96e-05,
      "loss": 0.0026,
      "step": 36720
    },
    {
      "epoch": 0.8162222222222222,
      "grad_norm": 0.21126456558704376,
      "learning_rate": 2.9594444444444448e-05,
      "loss": 0.002,
      "step": 36730
    },
    {
      "epoch": 0.8164444444444444,
      "grad_norm": 0.30725839734077454,
      "learning_rate": 2.958888888888889e-05,
      "loss": 0.0026,
      "step": 36740
    },
    {
      "epoch": 0.8166666666666667,
      "grad_norm": 0.17821244895458221,
      "learning_rate": 2.9583333333333335e-05,
      "loss": 0.0022,
      "step": 36750
    },
    {
      "epoch": 0.8168888888888889,
      "grad_norm": 0.3482282757759094,
      "learning_rate": 2.9577777777777775e-05,
      "loss": 0.0019,
      "step": 36760
    },
    {
      "epoch": 0.8171111111111111,
      "grad_norm": 0.49201130867004395,
      "learning_rate": 2.9572222222222222e-05,
      "loss": 0.0017,
      "step": 36770
    },
    {
      "epoch": 0.8173333333333334,
      "grad_norm": 0.6739973425865173,
      "learning_rate": 2.956666666666667e-05,
      "loss": 0.0022,
      "step": 36780
    },
    {
      "epoch": 0.8175555555555556,
      "grad_norm": 0.11172974109649658,
      "learning_rate": 2.9561111111111113e-05,
      "loss": 0.0018,
      "step": 36790
    },
    {
      "epoch": 0.8177777777777778,
      "grad_norm": 0.11380689591169357,
      "learning_rate": 2.955555555555556e-05,
      "loss": 0.0029,
      "step": 36800
    },
    {
      "epoch": 0.818,
      "grad_norm": 0.19661729037761688,
      "learning_rate": 2.955e-05,
      "loss": 0.0022,
      "step": 36810
    },
    {
      "epoch": 0.8182222222222222,
      "grad_norm": 0.062285780906677246,
      "learning_rate": 2.9544444444444447e-05,
      "loss": 0.0022,
      "step": 36820
    },
    {
      "epoch": 0.8184444444444444,
      "grad_norm": 0.0715487077832222,
      "learning_rate": 2.9538888888888887e-05,
      "loss": 0.0018,
      "step": 36830
    },
    {
      "epoch": 0.8186666666666667,
      "grad_norm": 0.2033574879169464,
      "learning_rate": 2.9533333333333334e-05,
      "loss": 0.0019,
      "step": 36840
    },
    {
      "epoch": 0.8188888888888889,
      "grad_norm": 0.07997363060712814,
      "learning_rate": 2.9527777777777778e-05,
      "loss": 0.0019,
      "step": 36850
    },
    {
      "epoch": 0.8191111111111111,
      "grad_norm": 0.08794636279344559,
      "learning_rate": 2.9522222222222225e-05,
      "loss": 0.0022,
      "step": 36860
    },
    {
      "epoch": 0.8193333333333334,
      "grad_norm": 0.5602749586105347,
      "learning_rate": 2.951666666666667e-05,
      "loss": 0.0032,
      "step": 36870
    },
    {
      "epoch": 0.8195555555555556,
      "grad_norm": 0.07996000349521637,
      "learning_rate": 2.951111111111111e-05,
      "loss": 0.0019,
      "step": 36880
    },
    {
      "epoch": 0.8197777777777778,
      "grad_norm": 0.27232274413108826,
      "learning_rate": 2.950555555555556e-05,
      "loss": 0.0033,
      "step": 36890
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.23671959340572357,
      "learning_rate": 2.95e-05,
      "loss": 0.003,
      "step": 36900
    },
    {
      "epoch": 0.8202222222222222,
      "grad_norm": 0.6615260243415833,
      "learning_rate": 2.9494444444444446e-05,
      "loss": 0.002,
      "step": 36910
    },
    {
      "epoch": 0.8204444444444444,
      "grad_norm": 0.08396334946155548,
      "learning_rate": 2.948888888888889e-05,
      "loss": 0.0026,
      "step": 36920
    },
    {
      "epoch": 0.8206666666666667,
      "grad_norm": 0.2132255882024765,
      "learning_rate": 2.9483333333333336e-05,
      "loss": 0.0022,
      "step": 36930
    },
    {
      "epoch": 0.8208888888888889,
      "grad_norm": 0.06397323310375214,
      "learning_rate": 2.9477777777777783e-05,
      "loss": 0.0024,
      "step": 36940
    },
    {
      "epoch": 0.8211111111111111,
      "grad_norm": 0.12674367427825928,
      "learning_rate": 2.9472222222222223e-05,
      "loss": 0.0033,
      "step": 36950
    },
    {
      "epoch": 0.8213333333333334,
      "grad_norm": 0.2734038233757019,
      "learning_rate": 2.946666666666667e-05,
      "loss": 0.0018,
      "step": 36960
    },
    {
      "epoch": 0.8215555555555556,
      "grad_norm": 0.33162471652030945,
      "learning_rate": 2.946111111111111e-05,
      "loss": 0.002,
      "step": 36970
    },
    {
      "epoch": 0.8217777777777778,
      "grad_norm": 0.22742225229740143,
      "learning_rate": 2.9455555555555557e-05,
      "loss": 0.0021,
      "step": 36980
    },
    {
      "epoch": 0.822,
      "grad_norm": 0.06682022660970688,
      "learning_rate": 2.945e-05,
      "loss": 0.0017,
      "step": 36990
    },
    {
      "epoch": 0.8222222222222222,
      "grad_norm": 0.3034207224845886,
      "learning_rate": 2.9444444444444448e-05,
      "loss": 0.0021,
      "step": 37000
    },
    {
      "epoch": 0.8224444444444444,
      "grad_norm": 0.362465500831604,
      "learning_rate": 2.9438888888888888e-05,
      "loss": 0.0027,
      "step": 37010
    },
    {
      "epoch": 0.8226666666666667,
      "grad_norm": 0.08516234159469604,
      "learning_rate": 2.9433333333333335e-05,
      "loss": 0.002,
      "step": 37020
    },
    {
      "epoch": 0.8228888888888889,
      "grad_norm": 0.12933795154094696,
      "learning_rate": 2.9427777777777782e-05,
      "loss": 0.0029,
      "step": 37030
    },
    {
      "epoch": 0.8231111111111111,
      "grad_norm": 0.21121686697006226,
      "learning_rate": 2.9422222222222222e-05,
      "loss": 0.002,
      "step": 37040
    },
    {
      "epoch": 0.8233333333333334,
      "grad_norm": 0.30048611760139465,
      "learning_rate": 2.941666666666667e-05,
      "loss": 0.002,
      "step": 37050
    },
    {
      "epoch": 0.8235555555555556,
      "grad_norm": 0.5121955871582031,
      "learning_rate": 2.9411111111111113e-05,
      "loss": 0.0026,
      "step": 37060
    },
    {
      "epoch": 0.8237777777777778,
      "grad_norm": 0.09309331327676773,
      "learning_rate": 2.940555555555556e-05,
      "loss": 0.0024,
      "step": 37070
    },
    {
      "epoch": 0.824,
      "grad_norm": 0.06280816346406937,
      "learning_rate": 2.94e-05,
      "loss": 0.0021,
      "step": 37080
    },
    {
      "epoch": 0.8242222222222222,
      "grad_norm": 0.1920424997806549,
      "learning_rate": 2.9394444444444447e-05,
      "loss": 0.0022,
      "step": 37090
    },
    {
      "epoch": 0.8244444444444444,
      "grad_norm": 0.3484363555908203,
      "learning_rate": 2.9388888888888887e-05,
      "loss": 0.0019,
      "step": 37100
    },
    {
      "epoch": 0.8246666666666667,
      "grad_norm": 0.20656263828277588,
      "learning_rate": 2.9383333333333334e-05,
      "loss": 0.002,
      "step": 37110
    },
    {
      "epoch": 0.8248888888888889,
      "grad_norm": 0.28561481833457947,
      "learning_rate": 2.937777777777778e-05,
      "loss": 0.0018,
      "step": 37120
    },
    {
      "epoch": 0.8251111111111111,
      "grad_norm": 0.1881096065044403,
      "learning_rate": 2.9372222222222224e-05,
      "loss": 0.0023,
      "step": 37130
    },
    {
      "epoch": 0.8253333333333334,
      "grad_norm": 0.6468279957771301,
      "learning_rate": 2.936666666666667e-05,
      "loss": 0.0037,
      "step": 37140
    },
    {
      "epoch": 0.8255555555555556,
      "grad_norm": 0.6628478169441223,
      "learning_rate": 2.936111111111111e-05,
      "loss": 0.0022,
      "step": 37150
    },
    {
      "epoch": 0.8257777777777778,
      "grad_norm": 0.11470985412597656,
      "learning_rate": 2.935555555555556e-05,
      "loss": 0.0019,
      "step": 37160
    },
    {
      "epoch": 0.826,
      "grad_norm": 0.20864342153072357,
      "learning_rate": 2.935e-05,
      "loss": 0.0024,
      "step": 37170
    },
    {
      "epoch": 0.8262222222222222,
      "grad_norm": 0.25764700770378113,
      "learning_rate": 2.9344444444444445e-05,
      "loss": 0.0022,
      "step": 37180
    },
    {
      "epoch": 0.8264444444444444,
      "grad_norm": 0.0811995416879654,
      "learning_rate": 2.933888888888889e-05,
      "loss": 0.0017,
      "step": 37190
    },
    {
      "epoch": 0.8266666666666667,
      "grad_norm": 0.26169028878211975,
      "learning_rate": 2.9333333333333336e-05,
      "loss": 0.0019,
      "step": 37200
    },
    {
      "epoch": 0.8268888888888889,
      "grad_norm": 0.4598085880279541,
      "learning_rate": 2.9327777777777783e-05,
      "loss": 0.0021,
      "step": 37210
    },
    {
      "epoch": 0.8271111111111111,
      "grad_norm": 0.4713784456253052,
      "learning_rate": 2.9322222222222223e-05,
      "loss": 0.003,
      "step": 37220
    },
    {
      "epoch": 0.8273333333333334,
      "grad_norm": 0.2500641942024231,
      "learning_rate": 2.931666666666667e-05,
      "loss": 0.0028,
      "step": 37230
    },
    {
      "epoch": 0.8275555555555556,
      "grad_norm": 0.16567891836166382,
      "learning_rate": 2.931111111111111e-05,
      "loss": 0.002,
      "step": 37240
    },
    {
      "epoch": 0.8277777777777777,
      "grad_norm": 0.07455413788557053,
      "learning_rate": 2.9305555555555557e-05,
      "loss": 0.0018,
      "step": 37250
    },
    {
      "epoch": 0.828,
      "grad_norm": 0.357930064201355,
      "learning_rate": 2.93e-05,
      "loss": 0.002,
      "step": 37260
    },
    {
      "epoch": 0.8282222222222222,
      "grad_norm": 0.1899099498987198,
      "learning_rate": 2.9294444444444448e-05,
      "loss": 0.002,
      "step": 37270
    },
    {
      "epoch": 0.8284444444444444,
      "grad_norm": 0.2712976932525635,
      "learning_rate": 2.9288888888888888e-05,
      "loss": 0.0031,
      "step": 37280
    },
    {
      "epoch": 0.8286666666666667,
      "grad_norm": 0.20855046808719635,
      "learning_rate": 2.9283333333333335e-05,
      "loss": 0.002,
      "step": 37290
    },
    {
      "epoch": 0.8288888888888889,
      "grad_norm": 0.2572181224822998,
      "learning_rate": 2.927777777777778e-05,
      "loss": 0.0019,
      "step": 37300
    },
    {
      "epoch": 0.8291111111111111,
      "grad_norm": 0.29351985454559326,
      "learning_rate": 2.9272222222222222e-05,
      "loss": 0.0019,
      "step": 37310
    },
    {
      "epoch": 0.8293333333333334,
      "grad_norm": 0.23227255046367645,
      "learning_rate": 2.926666666666667e-05,
      "loss": 0.0028,
      "step": 37320
    },
    {
      "epoch": 0.8295555555555556,
      "grad_norm": 0.24719491600990295,
      "learning_rate": 2.9261111111111112e-05,
      "loss": 0.0024,
      "step": 37330
    },
    {
      "epoch": 0.8297777777777777,
      "grad_norm": 0.14991655945777893,
      "learning_rate": 2.925555555555556e-05,
      "loss": 0.0019,
      "step": 37340
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.22911661863327026,
      "learning_rate": 2.925e-05,
      "loss": 0.0016,
      "step": 37350
    },
    {
      "epoch": 0.8302222222222222,
      "grad_norm": 0.2438429743051529,
      "learning_rate": 2.9244444444444446e-05,
      "loss": 0.0026,
      "step": 37360
    },
    {
      "epoch": 0.8304444444444444,
      "grad_norm": 0.7310044169425964,
      "learning_rate": 2.9238888888888887e-05,
      "loss": 0.0019,
      "step": 37370
    },
    {
      "epoch": 0.8306666666666667,
      "grad_norm": 0.30016791820526123,
      "learning_rate": 2.9233333333333334e-05,
      "loss": 0.0024,
      "step": 37380
    },
    {
      "epoch": 0.8308888888888889,
      "grad_norm": 0.3394302725791931,
      "learning_rate": 2.922777777777778e-05,
      "loss": 0.0024,
      "step": 37390
    },
    {
      "epoch": 0.8311111111111111,
      "grad_norm": 0.2808341979980469,
      "learning_rate": 2.9222222222222224e-05,
      "loss": 0.0022,
      "step": 37400
    },
    {
      "epoch": 0.8313333333333334,
      "grad_norm": 0.36414283514022827,
      "learning_rate": 2.921666666666667e-05,
      "loss": 0.0021,
      "step": 37410
    },
    {
      "epoch": 0.8315555555555556,
      "grad_norm": 0.1650683432817459,
      "learning_rate": 2.921111111111111e-05,
      "loss": 0.0018,
      "step": 37420
    },
    {
      "epoch": 0.8317777777777777,
      "grad_norm": 0.13442911207675934,
      "learning_rate": 2.9205555555555558e-05,
      "loss": 0.0019,
      "step": 37430
    },
    {
      "epoch": 0.832,
      "grad_norm": 0.05043862760066986,
      "learning_rate": 2.9199999999999998e-05,
      "loss": 0.0018,
      "step": 37440
    },
    {
      "epoch": 0.8322222222222222,
      "grad_norm": 0.08349630236625671,
      "learning_rate": 2.9194444444444445e-05,
      "loss": 0.0021,
      "step": 37450
    },
    {
      "epoch": 0.8324444444444444,
      "grad_norm": 0.5378886461257935,
      "learning_rate": 2.918888888888889e-05,
      "loss": 0.0039,
      "step": 37460
    },
    {
      "epoch": 0.8326666666666667,
      "grad_norm": 0.2219199538230896,
      "learning_rate": 2.9183333333333336e-05,
      "loss": 0.0022,
      "step": 37470
    },
    {
      "epoch": 0.8328888888888889,
      "grad_norm": 0.5537720918655396,
      "learning_rate": 2.9177777777777783e-05,
      "loss": 0.002,
      "step": 37480
    },
    {
      "epoch": 0.8331111111111111,
      "grad_norm": 0.8232463002204895,
      "learning_rate": 2.9172222222222223e-05,
      "loss": 0.0035,
      "step": 37490
    },
    {
      "epoch": 0.8333333333333334,
      "grad_norm": 0.1079760417342186,
      "learning_rate": 2.916666666666667e-05,
      "loss": 0.0028,
      "step": 37500
    },
    {
      "epoch": 0.8335555555555556,
      "grad_norm": 0.11692790687084198,
      "learning_rate": 2.916111111111111e-05,
      "loss": 0.0024,
      "step": 37510
    },
    {
      "epoch": 0.8337777777777777,
      "grad_norm": 0.37409618496894836,
      "learning_rate": 2.9155555555555557e-05,
      "loss": 0.002,
      "step": 37520
    },
    {
      "epoch": 0.834,
      "grad_norm": 0.38883936405181885,
      "learning_rate": 2.915e-05,
      "loss": 0.0019,
      "step": 37530
    },
    {
      "epoch": 0.8342222222222222,
      "grad_norm": 0.12495878338813782,
      "learning_rate": 2.9144444444444447e-05,
      "loss": 0.0024,
      "step": 37540
    },
    {
      "epoch": 0.8344444444444444,
      "grad_norm": 0.593989372253418,
      "learning_rate": 2.9138888888888888e-05,
      "loss": 0.0037,
      "step": 37550
    },
    {
      "epoch": 0.8346666666666667,
      "grad_norm": 0.3235468864440918,
      "learning_rate": 2.9133333333333334e-05,
      "loss": 0.0026,
      "step": 37560
    },
    {
      "epoch": 0.8348888888888889,
      "grad_norm": 0.5521326065063477,
      "learning_rate": 2.912777777777778e-05,
      "loss": 0.0028,
      "step": 37570
    },
    {
      "epoch": 0.8351111111111111,
      "grad_norm": 0.14990778267383575,
      "learning_rate": 2.912222222222222e-05,
      "loss": 0.0025,
      "step": 37580
    },
    {
      "epoch": 0.8353333333333334,
      "grad_norm": 0.5357467532157898,
      "learning_rate": 2.911666666666667e-05,
      "loss": 0.0021,
      "step": 37590
    },
    {
      "epoch": 0.8355555555555556,
      "grad_norm": 0.28329455852508545,
      "learning_rate": 2.9111111111111112e-05,
      "loss": 0.0027,
      "step": 37600
    },
    {
      "epoch": 0.8357777777777777,
      "grad_norm": 0.2683059871196747,
      "learning_rate": 2.910555555555556e-05,
      "loss": 0.0021,
      "step": 37610
    },
    {
      "epoch": 0.836,
      "grad_norm": 0.6009790897369385,
      "learning_rate": 2.91e-05,
      "loss": 0.0032,
      "step": 37620
    },
    {
      "epoch": 0.8362222222222222,
      "grad_norm": 0.39313092827796936,
      "learning_rate": 2.9094444444444446e-05,
      "loss": 0.0022,
      "step": 37630
    },
    {
      "epoch": 0.8364444444444444,
      "grad_norm": 0.11974829435348511,
      "learning_rate": 2.9088888888888886e-05,
      "loss": 0.0027,
      "step": 37640
    },
    {
      "epoch": 0.8366666666666667,
      "grad_norm": 0.25787225365638733,
      "learning_rate": 2.9083333333333333e-05,
      "loss": 0.002,
      "step": 37650
    },
    {
      "epoch": 0.8368888888888889,
      "grad_norm": 0.1545475572347641,
      "learning_rate": 2.907777777777778e-05,
      "loss": 0.0022,
      "step": 37660
    },
    {
      "epoch": 0.8371111111111111,
      "grad_norm": 0.19351452589035034,
      "learning_rate": 2.9072222222222224e-05,
      "loss": 0.002,
      "step": 37670
    },
    {
      "epoch": 0.8373333333333334,
      "grad_norm": 0.5870078802108765,
      "learning_rate": 2.906666666666667e-05,
      "loss": 0.002,
      "step": 37680
    },
    {
      "epoch": 0.8375555555555556,
      "grad_norm": 0.6657525300979614,
      "learning_rate": 2.906111111111111e-05,
      "loss": 0.0022,
      "step": 37690
    },
    {
      "epoch": 0.8377777777777777,
      "grad_norm": 0.15103012323379517,
      "learning_rate": 2.9055555555555558e-05,
      "loss": 0.0019,
      "step": 37700
    },
    {
      "epoch": 0.838,
      "grad_norm": 0.1330842226743698,
      "learning_rate": 2.9049999999999998e-05,
      "loss": 0.0019,
      "step": 37710
    },
    {
      "epoch": 0.8382222222222222,
      "grad_norm": 0.31941038370132446,
      "learning_rate": 2.9044444444444445e-05,
      "loss": 0.0022,
      "step": 37720
    },
    {
      "epoch": 0.8384444444444444,
      "grad_norm": 0.260600209236145,
      "learning_rate": 2.903888888888889e-05,
      "loss": 0.0023,
      "step": 37730
    },
    {
      "epoch": 0.8386666666666667,
      "grad_norm": 0.1250855028629303,
      "learning_rate": 2.9033333333333335e-05,
      "loss": 0.0018,
      "step": 37740
    },
    {
      "epoch": 0.8388888888888889,
      "grad_norm": 0.07470579445362091,
      "learning_rate": 2.9027777777777782e-05,
      "loss": 0.0032,
      "step": 37750
    },
    {
      "epoch": 0.8391111111111111,
      "grad_norm": 0.251176655292511,
      "learning_rate": 2.9022222222222223e-05,
      "loss": 0.0028,
      "step": 37760
    },
    {
      "epoch": 0.8393333333333334,
      "grad_norm": 0.17698417603969574,
      "learning_rate": 2.901666666666667e-05,
      "loss": 0.0019,
      "step": 37770
    },
    {
      "epoch": 0.8395555555555556,
      "grad_norm": 0.7705617547035217,
      "learning_rate": 2.901111111111111e-05,
      "loss": 0.0022,
      "step": 37780
    },
    {
      "epoch": 0.8397777777777777,
      "grad_norm": 0.07561193406581879,
      "learning_rate": 2.9005555555555557e-05,
      "loss": 0.0023,
      "step": 37790
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.14863844215869904,
      "learning_rate": 2.9e-05,
      "loss": 0.0022,
      "step": 37800
    },
    {
      "epoch": 0.8402222222222222,
      "grad_norm": 0.2044847458600998,
      "learning_rate": 2.8994444444444447e-05,
      "loss": 0.002,
      "step": 37810
    },
    {
      "epoch": 0.8404444444444444,
      "grad_norm": 0.15650077164173126,
      "learning_rate": 2.8988888888888887e-05,
      "loss": 0.0024,
      "step": 37820
    },
    {
      "epoch": 0.8406666666666667,
      "grad_norm": 0.2520747780799866,
      "learning_rate": 2.8983333333333334e-05,
      "loss": 0.0026,
      "step": 37830
    },
    {
      "epoch": 0.8408888888888889,
      "grad_norm": 0.23035761713981628,
      "learning_rate": 2.897777777777778e-05,
      "loss": 0.0023,
      "step": 37840
    },
    {
      "epoch": 0.8411111111111111,
      "grad_norm": 0.10615070164203644,
      "learning_rate": 2.897222222222222e-05,
      "loss": 0.0026,
      "step": 37850
    },
    {
      "epoch": 0.8413333333333334,
      "grad_norm": 0.44354620575904846,
      "learning_rate": 2.8966666666666668e-05,
      "loss": 0.0019,
      "step": 37860
    },
    {
      "epoch": 0.8415555555555555,
      "grad_norm": 0.0768812745809555,
      "learning_rate": 2.8961111111111112e-05,
      "loss": 0.0018,
      "step": 37870
    },
    {
      "epoch": 0.8417777777777777,
      "grad_norm": 0.5146933794021606,
      "learning_rate": 2.895555555555556e-05,
      "loss": 0.0026,
      "step": 37880
    },
    {
      "epoch": 0.842,
      "grad_norm": 0.07348979264497757,
      "learning_rate": 2.895e-05,
      "loss": 0.0021,
      "step": 37890
    },
    {
      "epoch": 0.8422222222222222,
      "grad_norm": 0.2107749581336975,
      "learning_rate": 2.8944444444444446e-05,
      "loss": 0.0031,
      "step": 37900
    },
    {
      "epoch": 0.8424444444444444,
      "grad_norm": 0.2401254028081894,
      "learning_rate": 2.8938888888888886e-05,
      "loss": 0.0018,
      "step": 37910
    },
    {
      "epoch": 0.8426666666666667,
      "grad_norm": 0.5465995073318481,
      "learning_rate": 2.8933333333333333e-05,
      "loss": 0.003,
      "step": 37920
    },
    {
      "epoch": 0.8428888888888889,
      "grad_norm": 0.08868925273418427,
      "learning_rate": 2.892777777777778e-05,
      "loss": 0.0023,
      "step": 37930
    },
    {
      "epoch": 0.8431111111111111,
      "grad_norm": 0.10321629047393799,
      "learning_rate": 2.8922222222222224e-05,
      "loss": 0.0031,
      "step": 37940
    },
    {
      "epoch": 0.8433333333333334,
      "grad_norm": 0.8396634459495544,
      "learning_rate": 2.891666666666667e-05,
      "loss": 0.0018,
      "step": 37950
    },
    {
      "epoch": 0.8435555555555555,
      "grad_norm": 0.3095107972621918,
      "learning_rate": 2.891111111111111e-05,
      "loss": 0.0018,
      "step": 37960
    },
    {
      "epoch": 0.8437777777777777,
      "grad_norm": 0.271469384431839,
      "learning_rate": 2.8905555555555558e-05,
      "loss": 0.0021,
      "step": 37970
    },
    {
      "epoch": 0.844,
      "grad_norm": 0.2623697817325592,
      "learning_rate": 2.8899999999999998e-05,
      "loss": 0.0028,
      "step": 37980
    },
    {
      "epoch": 0.8442222222222222,
      "grad_norm": 0.19076569378376007,
      "learning_rate": 2.8894444444444445e-05,
      "loss": 0.0022,
      "step": 37990
    },
    {
      "epoch": 0.8444444444444444,
      "grad_norm": 0.19088701903820038,
      "learning_rate": 2.8888888888888888e-05,
      "loss": 0.0023,
      "step": 38000
    },
    {
      "epoch": 0.8446666666666667,
      "grad_norm": 0.4505593478679657,
      "learning_rate": 2.8883333333333335e-05,
      "loss": 0.0023,
      "step": 38010
    },
    {
      "epoch": 0.8448888888888889,
      "grad_norm": 0.38024571537971497,
      "learning_rate": 2.8877777777777782e-05,
      "loss": 0.0025,
      "step": 38020
    },
    {
      "epoch": 0.8451111111111111,
      "grad_norm": 0.07684531807899475,
      "learning_rate": 2.8872222222222222e-05,
      "loss": 0.002,
      "step": 38030
    },
    {
      "epoch": 0.8453333333333334,
      "grad_norm": 0.26803258061408997,
      "learning_rate": 2.886666666666667e-05,
      "loss": 0.0021,
      "step": 38040
    },
    {
      "epoch": 0.8455555555555555,
      "grad_norm": 0.1657164841890335,
      "learning_rate": 2.886111111111111e-05,
      "loss": 0.0029,
      "step": 38050
    },
    {
      "epoch": 0.8457777777777777,
      "grad_norm": 0.4764401614665985,
      "learning_rate": 2.8855555555555556e-05,
      "loss": 0.0027,
      "step": 38060
    },
    {
      "epoch": 0.846,
      "grad_norm": 0.10254699736833572,
      "learning_rate": 2.885e-05,
      "loss": 0.0023,
      "step": 38070
    },
    {
      "epoch": 0.8462222222222222,
      "grad_norm": 0.08656145632266998,
      "learning_rate": 2.8844444444444447e-05,
      "loss": 0.0036,
      "step": 38080
    },
    {
      "epoch": 0.8464444444444444,
      "grad_norm": 0.3221908509731293,
      "learning_rate": 2.8838888888888887e-05,
      "loss": 0.0029,
      "step": 38090
    },
    {
      "epoch": 0.8466666666666667,
      "grad_norm": 0.2307237982749939,
      "learning_rate": 2.8833333333333334e-05,
      "loss": 0.0023,
      "step": 38100
    },
    {
      "epoch": 0.8468888888888889,
      "grad_norm": 0.14549213647842407,
      "learning_rate": 2.882777777777778e-05,
      "loss": 0.0023,
      "step": 38110
    },
    {
      "epoch": 0.8471111111111111,
      "grad_norm": 0.18108437955379486,
      "learning_rate": 2.882222222222222e-05,
      "loss": 0.0021,
      "step": 38120
    },
    {
      "epoch": 0.8473333333333334,
      "grad_norm": 0.20556601881980896,
      "learning_rate": 2.8816666666666668e-05,
      "loss": 0.0025,
      "step": 38130
    },
    {
      "epoch": 0.8475555555555555,
      "grad_norm": 0.3373899757862091,
      "learning_rate": 2.881111111111111e-05,
      "loss": 0.0021,
      "step": 38140
    },
    {
      "epoch": 0.8477777777777777,
      "grad_norm": 0.1394495666027069,
      "learning_rate": 2.880555555555556e-05,
      "loss": 0.0022,
      "step": 38150
    },
    {
      "epoch": 0.848,
      "grad_norm": 0.2014031559228897,
      "learning_rate": 2.88e-05,
      "loss": 0.0022,
      "step": 38160
    },
    {
      "epoch": 0.8482222222222222,
      "grad_norm": 0.32899919152259827,
      "learning_rate": 2.8794444444444446e-05,
      "loss": 0.0022,
      "step": 38170
    },
    {
      "epoch": 0.8484444444444444,
      "grad_norm": 0.27269247174263,
      "learning_rate": 2.8788888888888893e-05,
      "loss": 0.0021,
      "step": 38180
    },
    {
      "epoch": 0.8486666666666667,
      "grad_norm": 0.08026678115129471,
      "learning_rate": 2.8783333333333333e-05,
      "loss": 0.0019,
      "step": 38190
    },
    {
      "epoch": 0.8488888888888889,
      "grad_norm": 0.09847963601350784,
      "learning_rate": 2.877777777777778e-05,
      "loss": 0.0018,
      "step": 38200
    },
    {
      "epoch": 0.8491111111111111,
      "grad_norm": 0.7446115016937256,
      "learning_rate": 2.8772222222222223e-05,
      "loss": 0.0026,
      "step": 38210
    },
    {
      "epoch": 0.8493333333333334,
      "grad_norm": 0.18015269935131073,
      "learning_rate": 2.876666666666667e-05,
      "loss": 0.0017,
      "step": 38220
    },
    {
      "epoch": 0.8495555555555555,
      "grad_norm": 0.3449932932853699,
      "learning_rate": 2.876111111111111e-05,
      "loss": 0.0021,
      "step": 38230
    },
    {
      "epoch": 0.8497777777777777,
      "grad_norm": 0.40749475359916687,
      "learning_rate": 2.8755555555555557e-05,
      "loss": 0.0019,
      "step": 38240
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.15032172203063965,
      "learning_rate": 2.8749999999999997e-05,
      "loss": 0.0019,
      "step": 38250
    },
    {
      "epoch": 0.8502222222222222,
      "grad_norm": 0.07964808493852615,
      "learning_rate": 2.8744444444444444e-05,
      "loss": 0.0017,
      "step": 38260
    },
    {
      "epoch": 0.8504444444444444,
      "grad_norm": 0.16923817992210388,
      "learning_rate": 2.873888888888889e-05,
      "loss": 0.0024,
      "step": 38270
    },
    {
      "epoch": 0.8506666666666667,
      "grad_norm": 0.24275507032871246,
      "learning_rate": 2.8733333333333335e-05,
      "loss": 0.0026,
      "step": 38280
    },
    {
      "epoch": 0.8508888888888889,
      "grad_norm": 0.37415915727615356,
      "learning_rate": 2.8727777777777782e-05,
      "loss": 0.002,
      "step": 38290
    },
    {
      "epoch": 0.8511111111111112,
      "grad_norm": 0.1531464010477066,
      "learning_rate": 2.8722222222222222e-05,
      "loss": 0.0021,
      "step": 38300
    },
    {
      "epoch": 0.8513333333333334,
      "grad_norm": 0.11548081040382385,
      "learning_rate": 2.871666666666667e-05,
      "loss": 0.0027,
      "step": 38310
    },
    {
      "epoch": 0.8515555555555555,
      "grad_norm": 0.3574371039867401,
      "learning_rate": 2.8711111111111113e-05,
      "loss": 0.0027,
      "step": 38320
    },
    {
      "epoch": 0.8517777777777777,
      "grad_norm": 0.08815590292215347,
      "learning_rate": 2.8705555555555556e-05,
      "loss": 0.0019,
      "step": 38330
    },
    {
      "epoch": 0.852,
      "grad_norm": 0.6102887988090515,
      "learning_rate": 2.87e-05,
      "loss": 0.002,
      "step": 38340
    },
    {
      "epoch": 0.8522222222222222,
      "grad_norm": 0.2883216440677643,
      "learning_rate": 2.8694444444444447e-05,
      "loss": 0.0038,
      "step": 38350
    },
    {
      "epoch": 0.8524444444444444,
      "grad_norm": 0.16313618421554565,
      "learning_rate": 2.8688888888888894e-05,
      "loss": 0.002,
      "step": 38360
    },
    {
      "epoch": 0.8526666666666667,
      "grad_norm": 0.13455937802791595,
      "learning_rate": 2.8683333333333334e-05,
      "loss": 0.002,
      "step": 38370
    },
    {
      "epoch": 0.8528888888888889,
      "grad_norm": 0.7787915468215942,
      "learning_rate": 2.867777777777778e-05,
      "loss": 0.0025,
      "step": 38380
    },
    {
      "epoch": 0.8531111111111112,
      "grad_norm": 0.6716918349266052,
      "learning_rate": 2.8672222222222224e-05,
      "loss": 0.0016,
      "step": 38390
    },
    {
      "epoch": 0.8533333333333334,
      "grad_norm": 0.3286314606666565,
      "learning_rate": 2.8666666666666668e-05,
      "loss": 0.0023,
      "step": 38400
    },
    {
      "epoch": 0.8535555555555555,
      "grad_norm": 0.17668108642101288,
      "learning_rate": 2.866111111111111e-05,
      "loss": 0.002,
      "step": 38410
    },
    {
      "epoch": 0.8537777777777777,
      "grad_norm": 0.387219101190567,
      "learning_rate": 2.8655555555555558e-05,
      "loss": 0.0016,
      "step": 38420
    },
    {
      "epoch": 0.854,
      "grad_norm": 0.07351215183734894,
      "learning_rate": 2.865e-05,
      "loss": 0.0022,
      "step": 38430
    },
    {
      "epoch": 0.8542222222222222,
      "grad_norm": 0.44881752133369446,
      "learning_rate": 2.8644444444444445e-05,
      "loss": 0.0023,
      "step": 38440
    },
    {
      "epoch": 0.8544444444444445,
      "grad_norm": 0.20030559599399567,
      "learning_rate": 2.8638888888888892e-05,
      "loss": 0.0025,
      "step": 38450
    },
    {
      "epoch": 0.8546666666666667,
      "grad_norm": 0.20843695104122162,
      "learning_rate": 2.8633333333333336e-05,
      "loss": 0.0026,
      "step": 38460
    },
    {
      "epoch": 0.8548888888888889,
      "grad_norm": 0.1871456503868103,
      "learning_rate": 2.8627777777777783e-05,
      "loss": 0.0018,
      "step": 38470
    },
    {
      "epoch": 0.8551111111111112,
      "grad_norm": 0.2477046251296997,
      "learning_rate": 2.8622222222222223e-05,
      "loss": 0.0022,
      "step": 38480
    },
    {
      "epoch": 0.8553333333333333,
      "grad_norm": 0.21332794427871704,
      "learning_rate": 2.861666666666667e-05,
      "loss": 0.0021,
      "step": 38490
    },
    {
      "epoch": 0.8555555555555555,
      "grad_norm": 0.6380148530006409,
      "learning_rate": 2.861111111111111e-05,
      "loss": 0.0017,
      "step": 38500
    },
    {
      "epoch": 0.8557777777777777,
      "grad_norm": 0.3333776891231537,
      "learning_rate": 2.8605555555555557e-05,
      "loss": 0.0024,
      "step": 38510
    },
    {
      "epoch": 0.856,
      "grad_norm": 0.5922794342041016,
      "learning_rate": 2.86e-05,
      "loss": 0.0028,
      "step": 38520
    },
    {
      "epoch": 0.8562222222222222,
      "grad_norm": 0.5036888718605042,
      "learning_rate": 2.8594444444444448e-05,
      "loss": 0.0038,
      "step": 38530
    },
    {
      "epoch": 0.8564444444444445,
      "grad_norm": 0.3716806173324585,
      "learning_rate": 2.8588888888888895e-05,
      "loss": 0.0023,
      "step": 38540
    },
    {
      "epoch": 0.8566666666666667,
      "grad_norm": 0.43945905566215515,
      "learning_rate": 2.8583333333333335e-05,
      "loss": 0.0023,
      "step": 38550
    },
    {
      "epoch": 0.8568888888888889,
      "grad_norm": 0.6638593077659607,
      "learning_rate": 2.857777777777778e-05,
      "loss": 0.0025,
      "step": 38560
    },
    {
      "epoch": 0.8571111111111112,
      "grad_norm": 0.045375656336545944,
      "learning_rate": 2.8572222222222222e-05,
      "loss": 0.0033,
      "step": 38570
    },
    {
      "epoch": 0.8573333333333333,
      "grad_norm": 0.37793460488319397,
      "learning_rate": 2.856666666666667e-05,
      "loss": 0.0021,
      "step": 38580
    },
    {
      "epoch": 0.8575555555555555,
      "grad_norm": 0.506169855594635,
      "learning_rate": 2.8561111111111112e-05,
      "loss": 0.0022,
      "step": 38590
    },
    {
      "epoch": 0.8577777777777778,
      "grad_norm": 0.25494855642318726,
      "learning_rate": 2.855555555555556e-05,
      "loss": 0.0024,
      "step": 38600
    },
    {
      "epoch": 0.858,
      "grad_norm": 0.35142797231674194,
      "learning_rate": 2.855e-05,
      "loss": 0.002,
      "step": 38610
    },
    {
      "epoch": 0.8582222222222222,
      "grad_norm": 0.32994985580444336,
      "learning_rate": 2.8544444444444446e-05,
      "loss": 0.0018,
      "step": 38620
    },
    {
      "epoch": 0.8584444444444445,
      "grad_norm": 0.31288397312164307,
      "learning_rate": 2.8538888888888893e-05,
      "loss": 0.0029,
      "step": 38630
    },
    {
      "epoch": 0.8586666666666667,
      "grad_norm": 0.6631353497505188,
      "learning_rate": 2.8533333333333333e-05,
      "loss": 0.0028,
      "step": 38640
    },
    {
      "epoch": 0.8588888888888889,
      "grad_norm": 0.1438935101032257,
      "learning_rate": 2.852777777777778e-05,
      "loss": 0.0026,
      "step": 38650
    },
    {
      "epoch": 0.8591111111111112,
      "grad_norm": 0.10633912682533264,
      "learning_rate": 2.8522222222222224e-05,
      "loss": 0.0034,
      "step": 38660
    },
    {
      "epoch": 0.8593333333333333,
      "grad_norm": 0.3622843623161316,
      "learning_rate": 2.851666666666667e-05,
      "loss": 0.002,
      "step": 38670
    },
    {
      "epoch": 0.8595555555555555,
      "grad_norm": 0.2069661170244217,
      "learning_rate": 2.851111111111111e-05,
      "loss": 0.0026,
      "step": 38680
    },
    {
      "epoch": 0.8597777777777778,
      "grad_norm": 0.222217857837677,
      "learning_rate": 2.8505555555555558e-05,
      "loss": 0.0028,
      "step": 38690
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.4712882339954376,
      "learning_rate": 2.8499999999999998e-05,
      "loss": 0.0019,
      "step": 38700
    },
    {
      "epoch": 0.8602222222222222,
      "grad_norm": 0.3350418210029602,
      "learning_rate": 2.8494444444444445e-05,
      "loss": 0.002,
      "step": 38710
    },
    {
      "epoch": 0.8604444444444445,
      "grad_norm": 0.5237940549850464,
      "learning_rate": 2.8488888888888892e-05,
      "loss": 0.002,
      "step": 38720
    },
    {
      "epoch": 0.8606666666666667,
      "grad_norm": 0.7053958177566528,
      "learning_rate": 2.8483333333333336e-05,
      "loss": 0.0029,
      "step": 38730
    },
    {
      "epoch": 0.8608888888888889,
      "grad_norm": 0.21350564062595367,
      "learning_rate": 2.8477777777777783e-05,
      "loss": 0.003,
      "step": 38740
    },
    {
      "epoch": 0.8611111111111112,
      "grad_norm": 0.07555585354566574,
      "learning_rate": 2.8472222222222223e-05,
      "loss": 0.0022,
      "step": 38750
    },
    {
      "epoch": 0.8613333333333333,
      "grad_norm": 0.06621255725622177,
      "learning_rate": 2.846666666666667e-05,
      "loss": 0.002,
      "step": 38760
    },
    {
      "epoch": 0.8615555555555555,
      "grad_norm": 0.08838613331317902,
      "learning_rate": 2.846111111111111e-05,
      "loss": 0.0032,
      "step": 38770
    },
    {
      "epoch": 0.8617777777777778,
      "grad_norm": 0.1561860740184784,
      "learning_rate": 2.8455555555555557e-05,
      "loss": 0.0022,
      "step": 38780
    },
    {
      "epoch": 0.862,
      "grad_norm": 0.1066519096493721,
      "learning_rate": 2.845e-05,
      "loss": 0.0019,
      "step": 38790
    },
    {
      "epoch": 0.8622222222222222,
      "grad_norm": 0.13948386907577515,
      "learning_rate": 2.8444444444444447e-05,
      "loss": 0.0028,
      "step": 38800
    },
    {
      "epoch": 0.8624444444444445,
      "grad_norm": 0.083976149559021,
      "learning_rate": 2.8438888888888894e-05,
      "loss": 0.0029,
      "step": 38810
    },
    {
      "epoch": 0.8626666666666667,
      "grad_norm": 0.102393239736557,
      "learning_rate": 2.8433333333333334e-05,
      "loss": 0.0026,
      "step": 38820
    },
    {
      "epoch": 0.8628888888888889,
      "grad_norm": 0.1813143640756607,
      "learning_rate": 2.842777777777778e-05,
      "loss": 0.0019,
      "step": 38830
    },
    {
      "epoch": 0.8631111111111112,
      "grad_norm": 0.2718183100223541,
      "learning_rate": 2.842222222222222e-05,
      "loss": 0.0034,
      "step": 38840
    },
    {
      "epoch": 0.8633333333333333,
      "grad_norm": 0.49972009658813477,
      "learning_rate": 2.841666666666667e-05,
      "loss": 0.0032,
      "step": 38850
    },
    {
      "epoch": 0.8635555555555555,
      "grad_norm": 0.1374860554933548,
      "learning_rate": 2.8411111111111112e-05,
      "loss": 0.0024,
      "step": 38860
    },
    {
      "epoch": 0.8637777777777778,
      "grad_norm": 0.20958451926708221,
      "learning_rate": 2.840555555555556e-05,
      "loss": 0.0021,
      "step": 38870
    },
    {
      "epoch": 0.864,
      "grad_norm": 0.07302119582891464,
      "learning_rate": 2.84e-05,
      "loss": 0.004,
      "step": 38880
    },
    {
      "epoch": 0.8642222222222222,
      "grad_norm": 0.5159280896186829,
      "learning_rate": 2.8394444444444446e-05,
      "loss": 0.0028,
      "step": 38890
    },
    {
      "epoch": 0.8644444444444445,
      "grad_norm": 0.1628541797399521,
      "learning_rate": 2.8388888888888893e-05,
      "loss": 0.002,
      "step": 38900
    },
    {
      "epoch": 0.8646666666666667,
      "grad_norm": 0.08342082798480988,
      "learning_rate": 2.8383333333333333e-05,
      "loss": 0.0024,
      "step": 38910
    },
    {
      "epoch": 0.8648888888888889,
      "grad_norm": 0.0763888955116272,
      "learning_rate": 2.837777777777778e-05,
      "loss": 0.0023,
      "step": 38920
    },
    {
      "epoch": 0.8651111111111112,
      "grad_norm": 0.22206754982471466,
      "learning_rate": 2.8372222222222224e-05,
      "loss": 0.0021,
      "step": 38930
    },
    {
      "epoch": 0.8653333333333333,
      "grad_norm": 0.12141479551792145,
      "learning_rate": 2.836666666666667e-05,
      "loss": 0.0019,
      "step": 38940
    },
    {
      "epoch": 0.8655555555555555,
      "grad_norm": 0.6295638680458069,
      "learning_rate": 2.836111111111111e-05,
      "loss": 0.002,
      "step": 38950
    },
    {
      "epoch": 0.8657777777777778,
      "grad_norm": 0.16679075360298157,
      "learning_rate": 2.8355555555555558e-05,
      "loss": 0.0022,
      "step": 38960
    },
    {
      "epoch": 0.866,
      "grad_norm": 0.22890321910381317,
      "learning_rate": 2.8349999999999998e-05,
      "loss": 0.003,
      "step": 38970
    },
    {
      "epoch": 0.8662222222222222,
      "grad_norm": 0.49969208240509033,
      "learning_rate": 2.8344444444444445e-05,
      "loss": 0.0023,
      "step": 38980
    },
    {
      "epoch": 0.8664444444444445,
      "grad_norm": 0.19200900197029114,
      "learning_rate": 2.8338888888888892e-05,
      "loss": 0.0019,
      "step": 38990
    },
    {
      "epoch": 0.8666666666666667,
      "grad_norm": 0.43102091550827026,
      "learning_rate": 2.8333333333333335e-05,
      "loss": 0.0018,
      "step": 39000
    },
    {
      "epoch": 0.8668888888888889,
      "grad_norm": 0.18641582131385803,
      "learning_rate": 2.8327777777777782e-05,
      "loss": 0.004,
      "step": 39010
    },
    {
      "epoch": 0.8671111111111112,
      "grad_norm": 0.2366536408662796,
      "learning_rate": 2.8322222222222222e-05,
      "loss": 0.003,
      "step": 39020
    },
    {
      "epoch": 0.8673333333333333,
      "grad_norm": 0.6444446444511414,
      "learning_rate": 2.831666666666667e-05,
      "loss": 0.0019,
      "step": 39030
    },
    {
      "epoch": 0.8675555555555555,
      "grad_norm": 0.23651669919490814,
      "learning_rate": 2.831111111111111e-05,
      "loss": 0.0024,
      "step": 39040
    },
    {
      "epoch": 0.8677777777777778,
      "grad_norm": 0.22066286206245422,
      "learning_rate": 2.8305555555555557e-05,
      "loss": 0.0024,
      "step": 39050
    },
    {
      "epoch": 0.868,
      "grad_norm": 0.14507634937763214,
      "learning_rate": 2.83e-05,
      "loss": 0.0023,
      "step": 39060
    },
    {
      "epoch": 0.8682222222222222,
      "grad_norm": 0.26661133766174316,
      "learning_rate": 2.8294444444444447e-05,
      "loss": 0.0019,
      "step": 39070
    },
    {
      "epoch": 0.8684444444444445,
      "grad_norm": 0.18243490159511566,
      "learning_rate": 2.8288888888888894e-05,
      "loss": 0.0022,
      "step": 39080
    },
    {
      "epoch": 0.8686666666666667,
      "grad_norm": 0.3860965371131897,
      "learning_rate": 2.8283333333333334e-05,
      "loss": 0.0021,
      "step": 39090
    },
    {
      "epoch": 0.8688888888888889,
      "grad_norm": 0.14080460369586945,
      "learning_rate": 2.827777777777778e-05,
      "loss": 0.0018,
      "step": 39100
    },
    {
      "epoch": 0.8691111111111111,
      "grad_norm": 0.37691736221313477,
      "learning_rate": 2.827222222222222e-05,
      "loss": 0.0028,
      "step": 39110
    },
    {
      "epoch": 0.8693333333333333,
      "grad_norm": 0.1445026844739914,
      "learning_rate": 2.8266666666666668e-05,
      "loss": 0.0022,
      "step": 39120
    },
    {
      "epoch": 0.8695555555555555,
      "grad_norm": 0.31865179538726807,
      "learning_rate": 2.8261111111111112e-05,
      "loss": 0.002,
      "step": 39130
    },
    {
      "epoch": 0.8697777777777778,
      "grad_norm": 0.5268528461456299,
      "learning_rate": 2.825555555555556e-05,
      "loss": 0.002,
      "step": 39140
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.05596590414643288,
      "learning_rate": 2.825e-05,
      "loss": 0.0025,
      "step": 39150
    },
    {
      "epoch": 0.8702222222222222,
      "grad_norm": 0.11992257833480835,
      "learning_rate": 2.8244444444444446e-05,
      "loss": 0.0026,
      "step": 39160
    },
    {
      "epoch": 0.8704444444444445,
      "grad_norm": 0.2583272457122803,
      "learning_rate": 2.8238888888888893e-05,
      "loss": 0.0025,
      "step": 39170
    },
    {
      "epoch": 0.8706666666666667,
      "grad_norm": 0.1971852034330368,
      "learning_rate": 2.8233333333333333e-05,
      "loss": 0.0038,
      "step": 39180
    },
    {
      "epoch": 0.8708888888888889,
      "grad_norm": 0.225821852684021,
      "learning_rate": 2.822777777777778e-05,
      "loss": 0.0016,
      "step": 39190
    },
    {
      "epoch": 0.8711111111111111,
      "grad_norm": 0.10252118855714798,
      "learning_rate": 2.8222222222222223e-05,
      "loss": 0.002,
      "step": 39200
    },
    {
      "epoch": 0.8713333333333333,
      "grad_norm": 0.050075702369213104,
      "learning_rate": 2.821666666666667e-05,
      "loss": 0.0028,
      "step": 39210
    },
    {
      "epoch": 0.8715555555555555,
      "grad_norm": 0.22103151679039001,
      "learning_rate": 2.821111111111111e-05,
      "loss": 0.0029,
      "step": 39220
    },
    {
      "epoch": 0.8717777777777778,
      "grad_norm": 0.28634557127952576,
      "learning_rate": 2.8205555555555557e-05,
      "loss": 0.0022,
      "step": 39230
    },
    {
      "epoch": 0.872,
      "grad_norm": 0.2655220329761505,
      "learning_rate": 2.8199999999999998e-05,
      "loss": 0.0018,
      "step": 39240
    },
    {
      "epoch": 0.8722222222222222,
      "grad_norm": 0.06409082561731339,
      "learning_rate": 2.8194444444444445e-05,
      "loss": 0.0018,
      "step": 39250
    },
    {
      "epoch": 0.8724444444444445,
      "grad_norm": 0.12391381710767746,
      "learning_rate": 2.818888888888889e-05,
      "loss": 0.002,
      "step": 39260
    },
    {
      "epoch": 0.8726666666666667,
      "grad_norm": 0.10970522463321686,
      "learning_rate": 2.8183333333333335e-05,
      "loss": 0.002,
      "step": 39270
    },
    {
      "epoch": 0.8728888888888889,
      "grad_norm": 0.1392739862203598,
      "learning_rate": 2.8177777777777782e-05,
      "loss": 0.0019,
      "step": 39280
    },
    {
      "epoch": 0.8731111111111111,
      "grad_norm": 0.09074443578720093,
      "learning_rate": 2.8172222222222222e-05,
      "loss": 0.0017,
      "step": 39290
    },
    {
      "epoch": 0.8733333333333333,
      "grad_norm": 0.11698726564645767,
      "learning_rate": 2.816666666666667e-05,
      "loss": 0.0018,
      "step": 39300
    },
    {
      "epoch": 0.8735555555555555,
      "grad_norm": 0.10948701947927475,
      "learning_rate": 2.816111111111111e-05,
      "loss": 0.0028,
      "step": 39310
    },
    {
      "epoch": 0.8737777777777778,
      "grad_norm": 0.31681981682777405,
      "learning_rate": 2.8155555555555556e-05,
      "loss": 0.0026,
      "step": 39320
    },
    {
      "epoch": 0.874,
      "grad_norm": 0.27966025471687317,
      "learning_rate": 2.815e-05,
      "loss": 0.0026,
      "step": 39330
    },
    {
      "epoch": 0.8742222222222222,
      "grad_norm": 0.11489596962928772,
      "learning_rate": 2.8144444444444447e-05,
      "loss": 0.0019,
      "step": 39340
    },
    {
      "epoch": 0.8744444444444445,
      "grad_norm": 0.6388531923294067,
      "learning_rate": 2.8138888888888894e-05,
      "loss": 0.0025,
      "step": 39350
    },
    {
      "epoch": 0.8746666666666667,
      "grad_norm": 0.14135248959064484,
      "learning_rate": 2.8133333333333334e-05,
      "loss": 0.0019,
      "step": 39360
    },
    {
      "epoch": 0.8748888888888889,
      "grad_norm": 0.13744108378887177,
      "learning_rate": 2.812777777777778e-05,
      "loss": 0.0025,
      "step": 39370
    },
    {
      "epoch": 0.8751111111111111,
      "grad_norm": 0.330645352602005,
      "learning_rate": 2.812222222222222e-05,
      "loss": 0.0025,
      "step": 39380
    },
    {
      "epoch": 0.8753333333333333,
      "grad_norm": 0.4384756088256836,
      "learning_rate": 2.8116666666666668e-05,
      "loss": 0.0032,
      "step": 39390
    },
    {
      "epoch": 0.8755555555555555,
      "grad_norm": 0.1918243169784546,
      "learning_rate": 2.811111111111111e-05,
      "loss": 0.0027,
      "step": 39400
    },
    {
      "epoch": 0.8757777777777778,
      "grad_norm": 0.3193315267562866,
      "learning_rate": 2.810555555555556e-05,
      "loss": 0.0021,
      "step": 39410
    },
    {
      "epoch": 0.876,
      "grad_norm": 0.3020080327987671,
      "learning_rate": 2.8100000000000005e-05,
      "loss": 0.0023,
      "step": 39420
    },
    {
      "epoch": 0.8762222222222222,
      "grad_norm": 0.1299048215150833,
      "learning_rate": 2.8094444444444446e-05,
      "loss": 0.0019,
      "step": 39430
    },
    {
      "epoch": 0.8764444444444445,
      "grad_norm": 0.4794280529022217,
      "learning_rate": 2.8088888888888893e-05,
      "loss": 0.0027,
      "step": 39440
    },
    {
      "epoch": 0.8766666666666667,
      "grad_norm": 0.28119856119155884,
      "learning_rate": 2.8083333333333333e-05,
      "loss": 0.0018,
      "step": 39450
    },
    {
      "epoch": 0.8768888888888889,
      "grad_norm": 0.2814382016658783,
      "learning_rate": 2.807777777777778e-05,
      "loss": 0.0038,
      "step": 39460
    },
    {
      "epoch": 0.8771111111111111,
      "grad_norm": 0.11143115162849426,
      "learning_rate": 2.8072222222222223e-05,
      "loss": 0.0018,
      "step": 39470
    },
    {
      "epoch": 0.8773333333333333,
      "grad_norm": 0.3145846426486969,
      "learning_rate": 2.806666666666667e-05,
      "loss": 0.0019,
      "step": 39480
    },
    {
      "epoch": 0.8775555555555555,
      "grad_norm": 0.23305772244930267,
      "learning_rate": 2.806111111111111e-05,
      "loss": 0.0025,
      "step": 39490
    },
    {
      "epoch": 0.8777777777777778,
      "grad_norm": 0.06639988720417023,
      "learning_rate": 2.8055555555555557e-05,
      "loss": 0.0023,
      "step": 39500
    },
    {
      "epoch": 0.878,
      "grad_norm": 0.13586385548114777,
      "learning_rate": 2.8050000000000004e-05,
      "loss": 0.0017,
      "step": 39510
    },
    {
      "epoch": 0.8782222222222222,
      "grad_norm": 0.11500223726034164,
      "learning_rate": 2.8044444444444444e-05,
      "loss": 0.002,
      "step": 39520
    },
    {
      "epoch": 0.8784444444444445,
      "grad_norm": 0.15393806993961334,
      "learning_rate": 2.803888888888889e-05,
      "loss": 0.0025,
      "step": 39530
    },
    {
      "epoch": 0.8786666666666667,
      "grad_norm": 0.26062723994255066,
      "learning_rate": 2.8033333333333335e-05,
      "loss": 0.0036,
      "step": 39540
    },
    {
      "epoch": 0.8788888888888889,
      "grad_norm": 0.24834102392196655,
      "learning_rate": 2.8027777777777782e-05,
      "loss": 0.0034,
      "step": 39550
    },
    {
      "epoch": 0.8791111111111111,
      "grad_norm": 0.20402243733406067,
      "learning_rate": 2.8022222222222222e-05,
      "loss": 0.0018,
      "step": 39560
    },
    {
      "epoch": 0.8793333333333333,
      "grad_norm": 0.3473843038082123,
      "learning_rate": 2.801666666666667e-05,
      "loss": 0.0021,
      "step": 39570
    },
    {
      "epoch": 0.8795555555555555,
      "grad_norm": 0.08553902804851532,
      "learning_rate": 2.801111111111111e-05,
      "loss": 0.0021,
      "step": 39580
    },
    {
      "epoch": 0.8797777777777778,
      "grad_norm": 0.32248952984809875,
      "learning_rate": 2.8005555555555556e-05,
      "loss": 0.0018,
      "step": 39590
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.454091340303421,
      "learning_rate": 2.8000000000000003e-05,
      "loss": 0.0029,
      "step": 39600
    },
    {
      "epoch": 0.8802222222222222,
      "grad_norm": 0.43742263317108154,
      "learning_rate": 2.7994444444444447e-05,
      "loss": 0.0028,
      "step": 39610
    },
    {
      "epoch": 0.8804444444444445,
      "grad_norm": 0.1505732387304306,
      "learning_rate": 2.7988888888888893e-05,
      "loss": 0.0018,
      "step": 39620
    },
    {
      "epoch": 0.8806666666666667,
      "grad_norm": 0.16935738921165466,
      "learning_rate": 2.7983333333333334e-05,
      "loss": 0.0027,
      "step": 39630
    },
    {
      "epoch": 0.8808888888888889,
      "grad_norm": 0.21008481085300446,
      "learning_rate": 2.797777777777778e-05,
      "loss": 0.0029,
      "step": 39640
    },
    {
      "epoch": 0.8811111111111111,
      "grad_norm": 0.10267489403486252,
      "learning_rate": 2.797222222222222e-05,
      "loss": 0.0028,
      "step": 39650
    },
    {
      "epoch": 0.8813333333333333,
      "grad_norm": 0.2701954245567322,
      "learning_rate": 2.7966666666666668e-05,
      "loss": 0.0031,
      "step": 39660
    },
    {
      "epoch": 0.8815555555555555,
      "grad_norm": 0.23451247811317444,
      "learning_rate": 2.796111111111111e-05,
      "loss": 0.0022,
      "step": 39670
    },
    {
      "epoch": 0.8817777777777778,
      "grad_norm": 0.2528580129146576,
      "learning_rate": 2.7955555555555558e-05,
      "loss": 0.002,
      "step": 39680
    },
    {
      "epoch": 0.882,
      "grad_norm": 0.07681797444820404,
      "learning_rate": 2.7950000000000005e-05,
      "loss": 0.0019,
      "step": 39690
    },
    {
      "epoch": 0.8822222222222222,
      "grad_norm": 0.11311608552932739,
      "learning_rate": 2.7944444444444445e-05,
      "loss": 0.0018,
      "step": 39700
    },
    {
      "epoch": 0.8824444444444445,
      "grad_norm": 0.11933527886867523,
      "learning_rate": 2.7938888888888892e-05,
      "loss": 0.0024,
      "step": 39710
    },
    {
      "epoch": 0.8826666666666667,
      "grad_norm": 0.3323171138763428,
      "learning_rate": 2.7933333333333332e-05,
      "loss": 0.0018,
      "step": 39720
    },
    {
      "epoch": 0.8828888888888888,
      "grad_norm": 0.44621992111206055,
      "learning_rate": 2.792777777777778e-05,
      "loss": 0.0036,
      "step": 39730
    },
    {
      "epoch": 0.8831111111111111,
      "grad_norm": 0.6089993715286255,
      "learning_rate": 2.7922222222222223e-05,
      "loss": 0.0027,
      "step": 39740
    },
    {
      "epoch": 0.8833333333333333,
      "grad_norm": 0.14686113595962524,
      "learning_rate": 2.791666666666667e-05,
      "loss": 0.0017,
      "step": 39750
    },
    {
      "epoch": 0.8835555555555555,
      "grad_norm": 0.11203102022409439,
      "learning_rate": 2.791111111111111e-05,
      "loss": 0.0017,
      "step": 39760
    },
    {
      "epoch": 0.8837777777777778,
      "grad_norm": 0.5595943331718445,
      "learning_rate": 2.7905555555555557e-05,
      "loss": 0.0016,
      "step": 39770
    },
    {
      "epoch": 0.884,
      "grad_norm": 0.3462832272052765,
      "learning_rate": 2.7900000000000004e-05,
      "loss": 0.0027,
      "step": 39780
    },
    {
      "epoch": 0.8842222222222222,
      "grad_norm": 0.600171685218811,
      "learning_rate": 2.7894444444444444e-05,
      "loss": 0.0023,
      "step": 39790
    },
    {
      "epoch": 0.8844444444444445,
      "grad_norm": 0.09508876502513885,
      "learning_rate": 2.788888888888889e-05,
      "loss": 0.0024,
      "step": 39800
    },
    {
      "epoch": 0.8846666666666667,
      "grad_norm": 0.06450286507606506,
      "learning_rate": 2.7883333333333335e-05,
      "loss": 0.0029,
      "step": 39810
    },
    {
      "epoch": 0.8848888888888888,
      "grad_norm": 0.15887577831745148,
      "learning_rate": 2.787777777777778e-05,
      "loss": 0.0027,
      "step": 39820
    },
    {
      "epoch": 0.8851111111111111,
      "grad_norm": 0.29618048667907715,
      "learning_rate": 2.7872222222222222e-05,
      "loss": 0.0021,
      "step": 39830
    },
    {
      "epoch": 0.8853333333333333,
      "grad_norm": 0.1873447299003601,
      "learning_rate": 2.786666666666667e-05,
      "loss": 0.002,
      "step": 39840
    },
    {
      "epoch": 0.8855555555555555,
      "grad_norm": 0.16162438690662384,
      "learning_rate": 2.786111111111111e-05,
      "loss": 0.0024,
      "step": 39850
    },
    {
      "epoch": 0.8857777777777778,
      "grad_norm": 0.44304779171943665,
      "learning_rate": 2.7855555555555556e-05,
      "loss": 0.0023,
      "step": 39860
    },
    {
      "epoch": 0.886,
      "grad_norm": 0.15397794544696808,
      "learning_rate": 2.7850000000000003e-05,
      "loss": 0.0018,
      "step": 39870
    },
    {
      "epoch": 0.8862222222222222,
      "grad_norm": 0.32124990224838257,
      "learning_rate": 2.7844444444444446e-05,
      "loss": 0.002,
      "step": 39880
    },
    {
      "epoch": 0.8864444444444445,
      "grad_norm": 0.5355710983276367,
      "learning_rate": 2.7838888888888893e-05,
      "loss": 0.0022,
      "step": 39890
    },
    {
      "epoch": 0.8866666666666667,
      "grad_norm": 0.3633826673030853,
      "learning_rate": 2.7833333333333333e-05,
      "loss": 0.0031,
      "step": 39900
    },
    {
      "epoch": 0.8868888888888888,
      "grad_norm": 0.5452044010162354,
      "learning_rate": 2.782777777777778e-05,
      "loss": 0.0031,
      "step": 39910
    },
    {
      "epoch": 0.8871111111111111,
      "grad_norm": 0.35635173320770264,
      "learning_rate": 2.782222222222222e-05,
      "loss": 0.0037,
      "step": 39920
    },
    {
      "epoch": 0.8873333333333333,
      "grad_norm": 0.3264469504356384,
      "learning_rate": 2.7816666666666667e-05,
      "loss": 0.0027,
      "step": 39930
    },
    {
      "epoch": 0.8875555555555555,
      "grad_norm": 0.44642364978790283,
      "learning_rate": 2.781111111111111e-05,
      "loss": 0.0016,
      "step": 39940
    },
    {
      "epoch": 0.8877777777777778,
      "grad_norm": 0.2900143265724182,
      "learning_rate": 2.7805555555555558e-05,
      "loss": 0.0033,
      "step": 39950
    },
    {
      "epoch": 0.888,
      "grad_norm": 0.4565678536891937,
      "learning_rate": 2.7800000000000005e-05,
      "loss": 0.0021,
      "step": 39960
    },
    {
      "epoch": 0.8882222222222222,
      "grad_norm": 0.12793637812137604,
      "learning_rate": 2.7794444444444445e-05,
      "loss": 0.0017,
      "step": 39970
    },
    {
      "epoch": 0.8884444444444445,
      "grad_norm": 0.09688898175954819,
      "learning_rate": 2.7788888888888892e-05,
      "loss": 0.0022,
      "step": 39980
    },
    {
      "epoch": 0.8886666666666667,
      "grad_norm": 0.0651264414191246,
      "learning_rate": 2.7783333333333332e-05,
      "loss": 0.0017,
      "step": 39990
    },
    {
      "epoch": 0.8888888888888888,
      "grad_norm": 0.0900745764374733,
      "learning_rate": 2.777777777777778e-05,
      "loss": 0.0019,
      "step": 40000
    },
    {
      "epoch": 0.8891111111111111,
      "grad_norm": 0.22982031106948853,
      "learning_rate": 2.7772222222222223e-05,
      "loss": 0.0018,
      "step": 40010
    },
    {
      "epoch": 0.8893333333333333,
      "grad_norm": 0.2252867966890335,
      "learning_rate": 2.776666666666667e-05,
      "loss": 0.0025,
      "step": 40020
    },
    {
      "epoch": 0.8895555555555555,
      "grad_norm": 0.12537796795368195,
      "learning_rate": 2.776111111111111e-05,
      "loss": 0.0019,
      "step": 40030
    },
    {
      "epoch": 0.8897777777777778,
      "grad_norm": 0.29251617193222046,
      "learning_rate": 2.7755555555555557e-05,
      "loss": 0.0027,
      "step": 40040
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.1602174937725067,
      "learning_rate": 2.7750000000000004e-05,
      "loss": 0.0022,
      "step": 40050
    },
    {
      "epoch": 0.8902222222222222,
      "grad_norm": 0.5769889950752258,
      "learning_rate": 2.7744444444444444e-05,
      "loss": 0.002,
      "step": 40060
    },
    {
      "epoch": 0.8904444444444445,
      "grad_norm": 0.3996824622154236,
      "learning_rate": 2.773888888888889e-05,
      "loss": 0.0019,
      "step": 40070
    },
    {
      "epoch": 0.8906666666666667,
      "grad_norm": 0.09550309181213379,
      "learning_rate": 2.7733333333333334e-05,
      "loss": 0.0022,
      "step": 40080
    },
    {
      "epoch": 0.8908888888888888,
      "grad_norm": 0.3946281671524048,
      "learning_rate": 2.772777777777778e-05,
      "loss": 0.0031,
      "step": 40090
    },
    {
      "epoch": 0.8911111111111111,
      "grad_norm": 0.46576806902885437,
      "learning_rate": 2.772222222222222e-05,
      "loss": 0.0029,
      "step": 40100
    },
    {
      "epoch": 0.8913333333333333,
      "grad_norm": 0.1260482668876648,
      "learning_rate": 2.771666666666667e-05,
      "loss": 0.0017,
      "step": 40110
    },
    {
      "epoch": 0.8915555555555555,
      "grad_norm": 0.18613477051258087,
      "learning_rate": 2.771111111111111e-05,
      "loss": 0.0023,
      "step": 40120
    },
    {
      "epoch": 0.8917777777777778,
      "grad_norm": 0.09129928052425385,
      "learning_rate": 2.7705555555555556e-05,
      "loss": 0.002,
      "step": 40130
    },
    {
      "epoch": 0.892,
      "grad_norm": 0.4176056683063507,
      "learning_rate": 2.7700000000000002e-05,
      "loss": 0.0029,
      "step": 40140
    },
    {
      "epoch": 0.8922222222222222,
      "grad_norm": 0.526638925075531,
      "learning_rate": 2.7694444444444446e-05,
      "loss": 0.0025,
      "step": 40150
    },
    {
      "epoch": 0.8924444444444445,
      "grad_norm": 0.1899019479751587,
      "learning_rate": 2.7688888888888893e-05,
      "loss": 0.0019,
      "step": 40160
    },
    {
      "epoch": 0.8926666666666667,
      "grad_norm": 0.49967506527900696,
      "learning_rate": 2.7683333333333333e-05,
      "loss": 0.0023,
      "step": 40170
    },
    {
      "epoch": 0.8928888888888888,
      "grad_norm": 0.40121909976005554,
      "learning_rate": 2.767777777777778e-05,
      "loss": 0.0028,
      "step": 40180
    },
    {
      "epoch": 0.8931111111111111,
      "grad_norm": 0.08825841546058655,
      "learning_rate": 2.767222222222222e-05,
      "loss": 0.0019,
      "step": 40190
    },
    {
      "epoch": 0.8933333333333333,
      "grad_norm": 0.144924134016037,
      "learning_rate": 2.7666666666666667e-05,
      "loss": 0.004,
      "step": 40200
    },
    {
      "epoch": 0.8935555555555555,
      "grad_norm": 0.35993579030036926,
      "learning_rate": 2.766111111111111e-05,
      "loss": 0.0018,
      "step": 40210
    },
    {
      "epoch": 0.8937777777777778,
      "grad_norm": 0.1458035260438919,
      "learning_rate": 2.7655555555555558e-05,
      "loss": 0.0025,
      "step": 40220
    },
    {
      "epoch": 0.894,
      "grad_norm": 0.09014933556318283,
      "learning_rate": 2.7650000000000005e-05,
      "loss": 0.0031,
      "step": 40230
    },
    {
      "epoch": 0.8942222222222223,
      "grad_norm": 0.7957612872123718,
      "learning_rate": 2.7644444444444445e-05,
      "loss": 0.0018,
      "step": 40240
    },
    {
      "epoch": 0.8944444444444445,
      "grad_norm": 0.21637903153896332,
      "learning_rate": 2.7638888888888892e-05,
      "loss": 0.0029,
      "step": 40250
    },
    {
      "epoch": 0.8946666666666667,
      "grad_norm": 0.1065385490655899,
      "learning_rate": 2.7633333333333332e-05,
      "loss": 0.0019,
      "step": 40260
    },
    {
      "epoch": 0.8948888888888888,
      "grad_norm": 0.6336796283721924,
      "learning_rate": 2.762777777777778e-05,
      "loss": 0.0032,
      "step": 40270
    },
    {
      "epoch": 0.8951111111111111,
      "grad_norm": 0.43611881136894226,
      "learning_rate": 2.7622222222222222e-05,
      "loss": 0.0018,
      "step": 40280
    },
    {
      "epoch": 0.8953333333333333,
      "grad_norm": 0.2361908257007599,
      "learning_rate": 2.761666666666667e-05,
      "loss": 0.0024,
      "step": 40290
    },
    {
      "epoch": 0.8955555555555555,
      "grad_norm": 0.25100594758987427,
      "learning_rate": 2.761111111111111e-05,
      "loss": 0.0027,
      "step": 40300
    },
    {
      "epoch": 0.8957777777777778,
      "grad_norm": 0.13619530200958252,
      "learning_rate": 2.7605555555555556e-05,
      "loss": 0.003,
      "step": 40310
    },
    {
      "epoch": 0.896,
      "grad_norm": 0.16504374146461487,
      "learning_rate": 2.7600000000000003e-05,
      "loss": 0.0024,
      "step": 40320
    },
    {
      "epoch": 0.8962222222222223,
      "grad_norm": 0.4094785153865814,
      "learning_rate": 2.7594444444444444e-05,
      "loss": 0.002,
      "step": 40330
    },
    {
      "epoch": 0.8964444444444445,
      "grad_norm": 0.4244750142097473,
      "learning_rate": 2.758888888888889e-05,
      "loss": 0.002,
      "step": 40340
    },
    {
      "epoch": 0.8966666666666666,
      "grad_norm": 0.08020927011966705,
      "learning_rate": 2.7583333333333334e-05,
      "loss": 0.002,
      "step": 40350
    },
    {
      "epoch": 0.8968888888888888,
      "grad_norm": 0.10981415212154388,
      "learning_rate": 2.757777777777778e-05,
      "loss": 0.0023,
      "step": 40360
    },
    {
      "epoch": 0.8971111111111111,
      "grad_norm": 0.16615258157253265,
      "learning_rate": 2.757222222222222e-05,
      "loss": 0.0031,
      "step": 40370
    },
    {
      "epoch": 0.8973333333333333,
      "grad_norm": 0.10346405953168869,
      "learning_rate": 2.7566666666666668e-05,
      "loss": 0.0037,
      "step": 40380
    },
    {
      "epoch": 0.8975555555555556,
      "grad_norm": 0.19134294986724854,
      "learning_rate": 2.7561111111111108e-05,
      "loss": 0.0026,
      "step": 40390
    },
    {
      "epoch": 0.8977777777777778,
      "grad_norm": 0.2753361463546753,
      "learning_rate": 2.7555555555555555e-05,
      "loss": 0.0021,
      "step": 40400
    },
    {
      "epoch": 0.898,
      "grad_norm": 0.12238675355911255,
      "learning_rate": 2.7550000000000002e-05,
      "loss": 0.0027,
      "step": 40410
    },
    {
      "epoch": 0.8982222222222223,
      "grad_norm": 0.12634842097759247,
      "learning_rate": 2.7544444444444446e-05,
      "loss": 0.0024,
      "step": 40420
    },
    {
      "epoch": 0.8984444444444445,
      "grad_norm": 0.3226458430290222,
      "learning_rate": 2.7538888888888893e-05,
      "loss": 0.002,
      "step": 40430
    },
    {
      "epoch": 0.8986666666666666,
      "grad_norm": 0.07289652526378632,
      "learning_rate": 2.7533333333333333e-05,
      "loss": 0.0024,
      "step": 40440
    },
    {
      "epoch": 0.8988888888888888,
      "grad_norm": 0.09666489064693451,
      "learning_rate": 2.752777777777778e-05,
      "loss": 0.0025,
      "step": 40450
    },
    {
      "epoch": 0.8991111111111111,
      "grad_norm": 0.6372077465057373,
      "learning_rate": 2.752222222222222e-05,
      "loss": 0.002,
      "step": 40460
    },
    {
      "epoch": 0.8993333333333333,
      "grad_norm": 0.3756312131881714,
      "learning_rate": 2.7516666666666667e-05,
      "loss": 0.0032,
      "step": 40470
    },
    {
      "epoch": 0.8995555555555556,
      "grad_norm": 0.2948680818080902,
      "learning_rate": 2.751111111111111e-05,
      "loss": 0.0019,
      "step": 40480
    },
    {
      "epoch": 0.8997777777777778,
      "grad_norm": 0.05934971943497658,
      "learning_rate": 2.7505555555555557e-05,
      "loss": 0.0026,
      "step": 40490
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.14662809669971466,
      "learning_rate": 2.7500000000000004e-05,
      "loss": 0.002,
      "step": 40500
    },
    {
      "epoch": 0.9002222222222223,
      "grad_norm": 0.17013178765773773,
      "learning_rate": 2.7494444444444445e-05,
      "loss": 0.0019,
      "step": 40510
    },
    {
      "epoch": 0.9004444444444445,
      "grad_norm": 0.3352247178554535,
      "learning_rate": 2.748888888888889e-05,
      "loss": 0.0022,
      "step": 40520
    },
    {
      "epoch": 0.9006666666666666,
      "grad_norm": 0.23446916043758392,
      "learning_rate": 2.748333333333333e-05,
      "loss": 0.0017,
      "step": 40530
    },
    {
      "epoch": 0.9008888888888889,
      "grad_norm": 0.4791796803474426,
      "learning_rate": 2.747777777777778e-05,
      "loss": 0.0024,
      "step": 40540
    },
    {
      "epoch": 0.9011111111111111,
      "grad_norm": 0.3403736650943756,
      "learning_rate": 2.7472222222222222e-05,
      "loss": 0.0025,
      "step": 40550
    },
    {
      "epoch": 0.9013333333333333,
      "grad_norm": 0.7114672660827637,
      "learning_rate": 2.746666666666667e-05,
      "loss": 0.0028,
      "step": 40560
    },
    {
      "epoch": 0.9015555555555556,
      "grad_norm": 0.4745289385318756,
      "learning_rate": 2.746111111111111e-05,
      "loss": 0.0024,
      "step": 40570
    },
    {
      "epoch": 0.9017777777777778,
      "grad_norm": 0.06699798256158829,
      "learning_rate": 2.7455555555555556e-05,
      "loss": 0.0021,
      "step": 40580
    },
    {
      "epoch": 0.902,
      "grad_norm": 0.12392197549343109,
      "learning_rate": 2.7450000000000003e-05,
      "loss": 0.002,
      "step": 40590
    },
    {
      "epoch": 0.9022222222222223,
      "grad_norm": 0.39613670110702515,
      "learning_rate": 2.7444444444444443e-05,
      "loss": 0.0027,
      "step": 40600
    },
    {
      "epoch": 0.9024444444444445,
      "grad_norm": 0.2038503736257553,
      "learning_rate": 2.743888888888889e-05,
      "loss": 0.003,
      "step": 40610
    },
    {
      "epoch": 0.9026666666666666,
      "grad_norm": 0.06321319192647934,
      "learning_rate": 2.7433333333333334e-05,
      "loss": 0.002,
      "step": 40620
    },
    {
      "epoch": 0.9028888888888889,
      "grad_norm": 0.5564383268356323,
      "learning_rate": 2.742777777777778e-05,
      "loss": 0.0027,
      "step": 40630
    },
    {
      "epoch": 0.9031111111111111,
      "grad_norm": 0.39748555421829224,
      "learning_rate": 2.742222222222222e-05,
      "loss": 0.0022,
      "step": 40640
    },
    {
      "epoch": 0.9033333333333333,
      "grad_norm": 0.23437754809856415,
      "learning_rate": 2.7416666666666668e-05,
      "loss": 0.0022,
      "step": 40650
    },
    {
      "epoch": 0.9035555555555556,
      "grad_norm": 0.20213709771633148,
      "learning_rate": 2.7411111111111115e-05,
      "loss": 0.0021,
      "step": 40660
    },
    {
      "epoch": 0.9037777777777778,
      "grad_norm": 0.13064369559288025,
      "learning_rate": 2.7405555555555555e-05,
      "loss": 0.0015,
      "step": 40670
    },
    {
      "epoch": 0.904,
      "grad_norm": 0.10129989683628082,
      "learning_rate": 2.7400000000000002e-05,
      "loss": 0.0028,
      "step": 40680
    },
    {
      "epoch": 0.9042222222222223,
      "grad_norm": 0.38980790972709656,
      "learning_rate": 2.7394444444444445e-05,
      "loss": 0.0022,
      "step": 40690
    },
    {
      "epoch": 0.9044444444444445,
      "grad_norm": 0.39148470759391785,
      "learning_rate": 2.7388888888888892e-05,
      "loss": 0.002,
      "step": 40700
    },
    {
      "epoch": 0.9046666666666666,
      "grad_norm": 0.3567243814468384,
      "learning_rate": 2.7383333333333333e-05,
      "loss": 0.0025,
      "step": 40710
    },
    {
      "epoch": 0.9048888888888889,
      "grad_norm": 0.3808120787143707,
      "learning_rate": 2.737777777777778e-05,
      "loss": 0.0021,
      "step": 40720
    },
    {
      "epoch": 0.9051111111111111,
      "grad_norm": 0.4634144604206085,
      "learning_rate": 2.737222222222222e-05,
      "loss": 0.0018,
      "step": 40730
    },
    {
      "epoch": 0.9053333333333333,
      "grad_norm": 0.29142946004867554,
      "learning_rate": 2.7366666666666667e-05,
      "loss": 0.0019,
      "step": 40740
    },
    {
      "epoch": 0.9055555555555556,
      "grad_norm": 0.07462090998888016,
      "learning_rate": 2.7361111111111114e-05,
      "loss": 0.0018,
      "step": 40750
    },
    {
      "epoch": 0.9057777777777778,
      "grad_norm": 0.1914503425359726,
      "learning_rate": 2.7355555555555557e-05,
      "loss": 0.002,
      "step": 40760
    },
    {
      "epoch": 0.906,
      "grad_norm": 0.14445185661315918,
      "learning_rate": 2.7350000000000004e-05,
      "loss": 0.003,
      "step": 40770
    },
    {
      "epoch": 0.9062222222222223,
      "grad_norm": 0.2859088182449341,
      "learning_rate": 2.7344444444444444e-05,
      "loss": 0.002,
      "step": 40780
    },
    {
      "epoch": 0.9064444444444445,
      "grad_norm": 0.2775421142578125,
      "learning_rate": 2.733888888888889e-05,
      "loss": 0.002,
      "step": 40790
    },
    {
      "epoch": 0.9066666666666666,
      "grad_norm": 0.23825959861278534,
      "learning_rate": 2.733333333333333e-05,
      "loss": 0.0022,
      "step": 40800
    },
    {
      "epoch": 0.9068888888888889,
      "grad_norm": 0.2869267463684082,
      "learning_rate": 2.732777777777778e-05,
      "loss": 0.0025,
      "step": 40810
    },
    {
      "epoch": 0.9071111111111111,
      "grad_norm": 0.15353842079639435,
      "learning_rate": 2.7322222222222222e-05,
      "loss": 0.0024,
      "step": 40820
    },
    {
      "epoch": 0.9073333333333333,
      "grad_norm": 0.516632080078125,
      "learning_rate": 2.731666666666667e-05,
      "loss": 0.003,
      "step": 40830
    },
    {
      "epoch": 0.9075555555555556,
      "grad_norm": 0.06589458882808685,
      "learning_rate": 2.7311111111111116e-05,
      "loss": 0.0021,
      "step": 40840
    },
    {
      "epoch": 0.9077777777777778,
      "grad_norm": 0.12536580860614777,
      "learning_rate": 2.7305555555555556e-05,
      "loss": 0.003,
      "step": 40850
    },
    {
      "epoch": 0.908,
      "grad_norm": 0.06579085439443588,
      "learning_rate": 2.7300000000000003e-05,
      "loss": 0.0019,
      "step": 40860
    },
    {
      "epoch": 0.9082222222222223,
      "grad_norm": 0.43397167325019836,
      "learning_rate": 2.7294444444444443e-05,
      "loss": 0.0024,
      "step": 40870
    },
    {
      "epoch": 0.9084444444444445,
      "grad_norm": 0.08862390369176865,
      "learning_rate": 2.728888888888889e-05,
      "loss": 0.0017,
      "step": 40880
    },
    {
      "epoch": 0.9086666666666666,
      "grad_norm": 0.18628227710723877,
      "learning_rate": 2.7283333333333334e-05,
      "loss": 0.0027,
      "step": 40890
    },
    {
      "epoch": 0.9088888888888889,
      "grad_norm": 0.23233488202095032,
      "learning_rate": 2.727777777777778e-05,
      "loss": 0.002,
      "step": 40900
    },
    {
      "epoch": 0.9091111111111111,
      "grad_norm": 0.17606660723686218,
      "learning_rate": 2.727222222222222e-05,
      "loss": 0.0018,
      "step": 40910
    },
    {
      "epoch": 0.9093333333333333,
      "grad_norm": 0.4878632128238678,
      "learning_rate": 2.7266666666666668e-05,
      "loss": 0.0026,
      "step": 40920
    },
    {
      "epoch": 0.9095555555555556,
      "grad_norm": 0.31052446365356445,
      "learning_rate": 2.7261111111111115e-05,
      "loss": 0.0022,
      "step": 40930
    },
    {
      "epoch": 0.9097777777777778,
      "grad_norm": 0.25827255845069885,
      "learning_rate": 2.7255555555555555e-05,
      "loss": 0.0027,
      "step": 40940
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.11827687174081802,
      "learning_rate": 2.725e-05,
      "loss": 0.0019,
      "step": 40950
    },
    {
      "epoch": 0.9102222222222223,
      "grad_norm": 0.19904106855392456,
      "learning_rate": 2.7244444444444445e-05,
      "loss": 0.0019,
      "step": 40960
    },
    {
      "epoch": 0.9104444444444444,
      "grad_norm": 0.16556669771671295,
      "learning_rate": 2.7238888888888892e-05,
      "loss": 0.0019,
      "step": 40970
    },
    {
      "epoch": 0.9106666666666666,
      "grad_norm": 0.2849085032939911,
      "learning_rate": 2.7233333333333332e-05,
      "loss": 0.0021,
      "step": 40980
    },
    {
      "epoch": 0.9108888888888889,
      "grad_norm": 0.06517032533884048,
      "learning_rate": 2.722777777777778e-05,
      "loss": 0.0028,
      "step": 40990
    },
    {
      "epoch": 0.9111111111111111,
      "grad_norm": 0.4006802439689636,
      "learning_rate": 2.7222222222222223e-05,
      "loss": 0.0022,
      "step": 41000
    },
    {
      "epoch": 0.9113333333333333,
      "grad_norm": 0.4985586404800415,
      "learning_rate": 2.7216666666666666e-05,
      "loss": 0.0026,
      "step": 41010
    },
    {
      "epoch": 0.9115555555555556,
      "grad_norm": 0.09839306026697159,
      "learning_rate": 2.7211111111111113e-05,
      "loss": 0.0018,
      "step": 41020
    },
    {
      "epoch": 0.9117777777777778,
      "grad_norm": 0.17466579377651215,
      "learning_rate": 2.7205555555555557e-05,
      "loss": 0.0024,
      "step": 41030
    },
    {
      "epoch": 0.912,
      "grad_norm": 0.06324544548988342,
      "learning_rate": 2.7200000000000004e-05,
      "loss": 0.0023,
      "step": 41040
    },
    {
      "epoch": 0.9122222222222223,
      "grad_norm": 0.20811456441879272,
      "learning_rate": 2.7194444444444444e-05,
      "loss": 0.002,
      "step": 41050
    },
    {
      "epoch": 0.9124444444444444,
      "grad_norm": 0.37939006090164185,
      "learning_rate": 2.718888888888889e-05,
      "loss": 0.0018,
      "step": 41060
    },
    {
      "epoch": 0.9126666666666666,
      "grad_norm": 0.13296076655387878,
      "learning_rate": 2.7183333333333335e-05,
      "loss": 0.002,
      "step": 41070
    },
    {
      "epoch": 0.9128888888888889,
      "grad_norm": 0.35138294100761414,
      "learning_rate": 2.717777777777778e-05,
      "loss": 0.0019,
      "step": 41080
    },
    {
      "epoch": 0.9131111111111111,
      "grad_norm": 0.0924498662352562,
      "learning_rate": 2.717222222222222e-05,
      "loss": 0.0018,
      "step": 41090
    },
    {
      "epoch": 0.9133333333333333,
      "grad_norm": 0.46852806210517883,
      "learning_rate": 2.716666666666667e-05,
      "loss": 0.0036,
      "step": 41100
    },
    {
      "epoch": 0.9135555555555556,
      "grad_norm": 0.06491436064243317,
      "learning_rate": 2.7161111111111116e-05,
      "loss": 0.0024,
      "step": 41110
    },
    {
      "epoch": 0.9137777777777778,
      "grad_norm": 0.14638233184814453,
      "learning_rate": 2.7155555555555556e-05,
      "loss": 0.0024,
      "step": 41120
    },
    {
      "epoch": 0.914,
      "grad_norm": 0.3968518376350403,
      "learning_rate": 2.7150000000000003e-05,
      "loss": 0.0024,
      "step": 41130
    },
    {
      "epoch": 0.9142222222222223,
      "grad_norm": 0.418510377407074,
      "learning_rate": 2.7144444444444446e-05,
      "loss": 0.0017,
      "step": 41140
    },
    {
      "epoch": 0.9144444444444444,
      "grad_norm": 0.2942003905773163,
      "learning_rate": 2.7138888888888893e-05,
      "loss": 0.0024,
      "step": 41150
    },
    {
      "epoch": 0.9146666666666666,
      "grad_norm": 0.20787936449050903,
      "learning_rate": 2.7133333333333333e-05,
      "loss": 0.0019,
      "step": 41160
    },
    {
      "epoch": 0.9148888888888889,
      "grad_norm": 0.22319559752941132,
      "learning_rate": 2.712777777777778e-05,
      "loss": 0.003,
      "step": 41170
    },
    {
      "epoch": 0.9151111111111111,
      "grad_norm": 0.22360575199127197,
      "learning_rate": 2.712222222222222e-05,
      "loss": 0.0038,
      "step": 41180
    },
    {
      "epoch": 0.9153333333333333,
      "grad_norm": 0.07980934530496597,
      "learning_rate": 2.7116666666666667e-05,
      "loss": 0.0018,
      "step": 41190
    },
    {
      "epoch": 0.9155555555555556,
      "grad_norm": 0.1551840454339981,
      "learning_rate": 2.7111111111111114e-05,
      "loss": 0.003,
      "step": 41200
    },
    {
      "epoch": 0.9157777777777778,
      "grad_norm": 0.2252371609210968,
      "learning_rate": 2.7105555555555558e-05,
      "loss": 0.0021,
      "step": 41210
    },
    {
      "epoch": 0.916,
      "grad_norm": 0.15604464709758759,
      "learning_rate": 2.7100000000000005e-05,
      "loss": 0.0027,
      "step": 41220
    },
    {
      "epoch": 0.9162222222222223,
      "grad_norm": 0.1366477906703949,
      "learning_rate": 2.7094444444444445e-05,
      "loss": 0.0027,
      "step": 41230
    },
    {
      "epoch": 0.9164444444444444,
      "grad_norm": 0.10316150635480881,
      "learning_rate": 2.7088888888888892e-05,
      "loss": 0.0023,
      "step": 41240
    },
    {
      "epoch": 0.9166666666666666,
      "grad_norm": 0.08653663843870163,
      "learning_rate": 2.7083333333333332e-05,
      "loss": 0.0018,
      "step": 41250
    },
    {
      "epoch": 0.9168888888888889,
      "grad_norm": 0.2941187620162964,
      "learning_rate": 2.707777777777778e-05,
      "loss": 0.0024,
      "step": 41260
    },
    {
      "epoch": 0.9171111111111111,
      "grad_norm": 0.36595579981803894,
      "learning_rate": 2.7072222222222223e-05,
      "loss": 0.002,
      "step": 41270
    },
    {
      "epoch": 0.9173333333333333,
      "grad_norm": 0.18297497928142548,
      "learning_rate": 2.706666666666667e-05,
      "loss": 0.0018,
      "step": 41280
    },
    {
      "epoch": 0.9175555555555556,
      "grad_norm": 0.6727362871170044,
      "learning_rate": 2.7061111111111116e-05,
      "loss": 0.0026,
      "step": 41290
    },
    {
      "epoch": 0.9177777777777778,
      "grad_norm": 0.13681001961231232,
      "learning_rate": 2.7055555555555557e-05,
      "loss": 0.0018,
      "step": 41300
    },
    {
      "epoch": 0.918,
      "grad_norm": 0.5851772427558899,
      "learning_rate": 2.7050000000000004e-05,
      "loss": 0.0027,
      "step": 41310
    },
    {
      "epoch": 0.9182222222222223,
      "grad_norm": 0.44795069098472595,
      "learning_rate": 2.7044444444444444e-05,
      "loss": 0.0027,
      "step": 41320
    },
    {
      "epoch": 0.9184444444444444,
      "grad_norm": 0.4660274386405945,
      "learning_rate": 2.703888888888889e-05,
      "loss": 0.002,
      "step": 41330
    },
    {
      "epoch": 0.9186666666666666,
      "grad_norm": 0.24591456353664398,
      "learning_rate": 2.7033333333333334e-05,
      "loss": 0.0021,
      "step": 41340
    },
    {
      "epoch": 0.9188888888888889,
      "grad_norm": 0.1894061416387558,
      "learning_rate": 2.702777777777778e-05,
      "loss": 0.0022,
      "step": 41350
    },
    {
      "epoch": 0.9191111111111111,
      "grad_norm": 0.2139281928539276,
      "learning_rate": 2.702222222222222e-05,
      "loss": 0.0023,
      "step": 41360
    },
    {
      "epoch": 0.9193333333333333,
      "grad_norm": 0.45231375098228455,
      "learning_rate": 2.701666666666667e-05,
      "loss": 0.0018,
      "step": 41370
    },
    {
      "epoch": 0.9195555555555556,
      "grad_norm": 0.08420376479625702,
      "learning_rate": 2.7011111111111115e-05,
      "loss": 0.002,
      "step": 41380
    },
    {
      "epoch": 0.9197777777777778,
      "grad_norm": 0.35022953152656555,
      "learning_rate": 2.7005555555555555e-05,
      "loss": 0.002,
      "step": 41390
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.09581059217453003,
      "learning_rate": 2.7000000000000002e-05,
      "loss": 0.0018,
      "step": 41400
    },
    {
      "epoch": 0.9202222222222223,
      "grad_norm": 0.38664519786834717,
      "learning_rate": 2.6994444444444446e-05,
      "loss": 0.0025,
      "step": 41410
    },
    {
      "epoch": 0.9204444444444444,
      "grad_norm": 0.17435652017593384,
      "learning_rate": 2.6988888888888893e-05,
      "loss": 0.0018,
      "step": 41420
    },
    {
      "epoch": 0.9206666666666666,
      "grad_norm": 0.20064985752105713,
      "learning_rate": 2.6983333333333333e-05,
      "loss": 0.0028,
      "step": 41430
    },
    {
      "epoch": 0.9208888888888889,
      "grad_norm": 0.09218695014715195,
      "learning_rate": 2.697777777777778e-05,
      "loss": 0.002,
      "step": 41440
    },
    {
      "epoch": 0.9211111111111111,
      "grad_norm": 0.0829763188958168,
      "learning_rate": 2.697222222222222e-05,
      "loss": 0.0024,
      "step": 41450
    },
    {
      "epoch": 0.9213333333333333,
      "grad_norm": 0.24203552305698395,
      "learning_rate": 2.6966666666666667e-05,
      "loss": 0.0018,
      "step": 41460
    },
    {
      "epoch": 0.9215555555555556,
      "grad_norm": 0.15716172754764557,
      "learning_rate": 2.6961111111111114e-05,
      "loss": 0.0027,
      "step": 41470
    },
    {
      "epoch": 0.9217777777777778,
      "grad_norm": 0.1488039344549179,
      "learning_rate": 2.6955555555555558e-05,
      "loss": 0.0019,
      "step": 41480
    },
    {
      "epoch": 0.922,
      "grad_norm": 0.2719711661338806,
      "learning_rate": 2.6950000000000005e-05,
      "loss": 0.0025,
      "step": 41490
    },
    {
      "epoch": 0.9222222222222223,
      "grad_norm": 0.08939728140830994,
      "learning_rate": 2.6944444444444445e-05,
      "loss": 0.002,
      "step": 41500
    },
    {
      "epoch": 0.9224444444444444,
      "grad_norm": 0.2710237205028534,
      "learning_rate": 2.693888888888889e-05,
      "loss": 0.0027,
      "step": 41510
    },
    {
      "epoch": 0.9226666666666666,
      "grad_norm": 0.40672028064727783,
      "learning_rate": 2.6933333333333332e-05,
      "loss": 0.0029,
      "step": 41520
    },
    {
      "epoch": 0.9228888888888889,
      "grad_norm": 0.31727278232574463,
      "learning_rate": 2.692777777777778e-05,
      "loss": 0.0021,
      "step": 41530
    },
    {
      "epoch": 0.9231111111111111,
      "grad_norm": 0.29060861468315125,
      "learning_rate": 2.6922222222222222e-05,
      "loss": 0.002,
      "step": 41540
    },
    {
      "epoch": 0.9233333333333333,
      "grad_norm": 0.22847039997577667,
      "learning_rate": 2.691666666666667e-05,
      "loss": 0.0021,
      "step": 41550
    },
    {
      "epoch": 0.9235555555555556,
      "grad_norm": 0.46965527534484863,
      "learning_rate": 2.6911111111111116e-05,
      "loss": 0.002,
      "step": 41560
    },
    {
      "epoch": 0.9237777777777778,
      "grad_norm": 0.33345136046409607,
      "learning_rate": 2.6905555555555556e-05,
      "loss": 0.0017,
      "step": 41570
    },
    {
      "epoch": 0.924,
      "grad_norm": 0.08644931763410568,
      "learning_rate": 2.6900000000000003e-05,
      "loss": 0.0021,
      "step": 41580
    },
    {
      "epoch": 0.9242222222222222,
      "grad_norm": 0.22773447632789612,
      "learning_rate": 2.6894444444444444e-05,
      "loss": 0.002,
      "step": 41590
    },
    {
      "epoch": 0.9244444444444444,
      "grad_norm": 0.13058583438396454,
      "learning_rate": 2.688888888888889e-05,
      "loss": 0.0023,
      "step": 41600
    },
    {
      "epoch": 0.9246666666666666,
      "grad_norm": 0.1507372260093689,
      "learning_rate": 2.6883333333333334e-05,
      "loss": 0.0035,
      "step": 41610
    },
    {
      "epoch": 0.9248888888888889,
      "grad_norm": 0.5155996084213257,
      "learning_rate": 2.687777777777778e-05,
      "loss": 0.0019,
      "step": 41620
    },
    {
      "epoch": 0.9251111111111111,
      "grad_norm": 0.45075860619544983,
      "learning_rate": 2.687222222222222e-05,
      "loss": 0.002,
      "step": 41630
    },
    {
      "epoch": 0.9253333333333333,
      "grad_norm": 0.23330876231193542,
      "learning_rate": 2.6866666666666668e-05,
      "loss": 0.0016,
      "step": 41640
    },
    {
      "epoch": 0.9255555555555556,
      "grad_norm": 0.15376567840576172,
      "learning_rate": 2.6861111111111115e-05,
      "loss": 0.0018,
      "step": 41650
    },
    {
      "epoch": 0.9257777777777778,
      "grad_norm": 0.2141648679971695,
      "learning_rate": 2.6855555555555555e-05,
      "loss": 0.0026,
      "step": 41660
    },
    {
      "epoch": 0.926,
      "grad_norm": 0.2396956831216812,
      "learning_rate": 2.6850000000000002e-05,
      "loss": 0.0018,
      "step": 41670
    },
    {
      "epoch": 0.9262222222222222,
      "grad_norm": 0.15047018229961395,
      "learning_rate": 2.6844444444444446e-05,
      "loss": 0.0025,
      "step": 41680
    },
    {
      "epoch": 0.9264444444444444,
      "grad_norm": 0.40293240547180176,
      "learning_rate": 2.6838888888888893e-05,
      "loss": 0.002,
      "step": 41690
    },
    {
      "epoch": 0.9266666666666666,
      "grad_norm": 0.24449127912521362,
      "learning_rate": 2.6833333333333333e-05,
      "loss": 0.0024,
      "step": 41700
    },
    {
      "epoch": 0.9268888888888889,
      "grad_norm": 0.16674935817718506,
      "learning_rate": 2.682777777777778e-05,
      "loss": 0.002,
      "step": 41710
    },
    {
      "epoch": 0.9271111111111111,
      "grad_norm": 0.20555353164672852,
      "learning_rate": 2.682222222222222e-05,
      "loss": 0.0023,
      "step": 41720
    },
    {
      "epoch": 0.9273333333333333,
      "grad_norm": 0.14209218323230743,
      "learning_rate": 2.6816666666666667e-05,
      "loss": 0.0028,
      "step": 41730
    },
    {
      "epoch": 0.9275555555555556,
      "grad_norm": 0.07221110165119171,
      "learning_rate": 2.6811111111111114e-05,
      "loss": 0.0019,
      "step": 41740
    },
    {
      "epoch": 0.9277777777777778,
      "grad_norm": 0.2832804322242737,
      "learning_rate": 2.6805555555555557e-05,
      "loss": 0.002,
      "step": 41750
    },
    {
      "epoch": 0.928,
      "grad_norm": 0.0913647785782814,
      "learning_rate": 2.6800000000000004e-05,
      "loss": 0.0025,
      "step": 41760
    },
    {
      "epoch": 0.9282222222222222,
      "grad_norm": 0.2738926112651825,
      "learning_rate": 2.6794444444444444e-05,
      "loss": 0.002,
      "step": 41770
    },
    {
      "epoch": 0.9284444444444444,
      "grad_norm": 0.08302197605371475,
      "learning_rate": 2.678888888888889e-05,
      "loss": 0.0019,
      "step": 41780
    },
    {
      "epoch": 0.9286666666666666,
      "grad_norm": 0.1081073060631752,
      "learning_rate": 2.678333333333333e-05,
      "loss": 0.002,
      "step": 41790
    },
    {
      "epoch": 0.9288888888888889,
      "grad_norm": 0.2930518686771393,
      "learning_rate": 2.677777777777778e-05,
      "loss": 0.003,
      "step": 41800
    },
    {
      "epoch": 0.9291111111111111,
      "grad_norm": 0.06617800891399384,
      "learning_rate": 2.6772222222222222e-05,
      "loss": 0.0023,
      "step": 41810
    },
    {
      "epoch": 0.9293333333333333,
      "grad_norm": 0.09162357449531555,
      "learning_rate": 2.676666666666667e-05,
      "loss": 0.0029,
      "step": 41820
    },
    {
      "epoch": 0.9295555555555556,
      "grad_norm": 0.17972706258296967,
      "learning_rate": 2.6761111111111116e-05,
      "loss": 0.002,
      "step": 41830
    },
    {
      "epoch": 0.9297777777777778,
      "grad_norm": 0.23849892616271973,
      "learning_rate": 2.6755555555555556e-05,
      "loss": 0.0021,
      "step": 41840
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.11017905175685883,
      "learning_rate": 2.6750000000000003e-05,
      "loss": 0.0029,
      "step": 41850
    },
    {
      "epoch": 0.9302222222222222,
      "grad_norm": 0.45131155848503113,
      "learning_rate": 2.6744444444444443e-05,
      "loss": 0.0025,
      "step": 41860
    },
    {
      "epoch": 0.9304444444444444,
      "grad_norm": 0.43738746643066406,
      "learning_rate": 2.673888888888889e-05,
      "loss": 0.002,
      "step": 41870
    },
    {
      "epoch": 0.9306666666666666,
      "grad_norm": 0.26240476965904236,
      "learning_rate": 2.6733333333333334e-05,
      "loss": 0.0025,
      "step": 41880
    },
    {
      "epoch": 0.9308888888888889,
      "grad_norm": 0.12301192432641983,
      "learning_rate": 2.672777777777778e-05,
      "loss": 0.0018,
      "step": 41890
    },
    {
      "epoch": 0.9311111111111111,
      "grad_norm": 0.2482360601425171,
      "learning_rate": 2.6722222222222228e-05,
      "loss": 0.0023,
      "step": 41900
    },
    {
      "epoch": 0.9313333333333333,
      "grad_norm": 0.21647900342941284,
      "learning_rate": 2.6716666666666668e-05,
      "loss": 0.002,
      "step": 41910
    },
    {
      "epoch": 0.9315555555555556,
      "grad_norm": 0.08980653434991837,
      "learning_rate": 2.6711111111111115e-05,
      "loss": 0.0019,
      "step": 41920
    },
    {
      "epoch": 0.9317777777777778,
      "grad_norm": 0.1111280620098114,
      "learning_rate": 2.6705555555555555e-05,
      "loss": 0.0017,
      "step": 41930
    },
    {
      "epoch": 0.932,
      "grad_norm": 0.4647359251976013,
      "learning_rate": 2.6700000000000002e-05,
      "loss": 0.0019,
      "step": 41940
    },
    {
      "epoch": 0.9322222222222222,
      "grad_norm": 0.135106161236763,
      "learning_rate": 2.6694444444444445e-05,
      "loss": 0.0017,
      "step": 41950
    },
    {
      "epoch": 0.9324444444444444,
      "grad_norm": 0.2728239595890045,
      "learning_rate": 2.6688888888888892e-05,
      "loss": 0.0017,
      "step": 41960
    },
    {
      "epoch": 0.9326666666666666,
      "grad_norm": 0.12200553715229034,
      "learning_rate": 2.6683333333333333e-05,
      "loss": 0.002,
      "step": 41970
    },
    {
      "epoch": 0.9328888888888889,
      "grad_norm": 0.2283182293176651,
      "learning_rate": 2.667777777777778e-05,
      "loss": 0.0019,
      "step": 41980
    },
    {
      "epoch": 0.9331111111111111,
      "grad_norm": 0.24976174533367157,
      "learning_rate": 2.6672222222222226e-05,
      "loss": 0.0024,
      "step": 41990
    },
    {
      "epoch": 0.9333333333333333,
      "grad_norm": 0.4329413175582886,
      "learning_rate": 2.6666666666666667e-05,
      "loss": 0.0027,
      "step": 42000
    },
    {
      "epoch": 0.9335555555555556,
      "grad_norm": 0.19202111661434174,
      "learning_rate": 2.6661111111111114e-05,
      "loss": 0.0022,
      "step": 42010
    },
    {
      "epoch": 0.9337777777777778,
      "grad_norm": 0.27888408303260803,
      "learning_rate": 2.6655555555555557e-05,
      "loss": 0.0021,
      "step": 42020
    },
    {
      "epoch": 0.934,
      "grad_norm": 0.23984986543655396,
      "learning_rate": 2.6650000000000004e-05,
      "loss": 0.002,
      "step": 42030
    },
    {
      "epoch": 0.9342222222222222,
      "grad_norm": 0.27489298582077026,
      "learning_rate": 2.6644444444444444e-05,
      "loss": 0.0017,
      "step": 42040
    },
    {
      "epoch": 0.9344444444444444,
      "grad_norm": 0.5911338925361633,
      "learning_rate": 2.663888888888889e-05,
      "loss": 0.0021,
      "step": 42050
    },
    {
      "epoch": 0.9346666666666666,
      "grad_norm": 0.2283724993467331,
      "learning_rate": 2.663333333333333e-05,
      "loss": 0.0022,
      "step": 42060
    },
    {
      "epoch": 0.9348888888888889,
      "grad_norm": 0.16164931654930115,
      "learning_rate": 2.6627777777777778e-05,
      "loss": 0.0019,
      "step": 42070
    },
    {
      "epoch": 0.9351111111111111,
      "grad_norm": 0.23084600269794464,
      "learning_rate": 2.6622222222222225e-05,
      "loss": 0.002,
      "step": 42080
    },
    {
      "epoch": 0.9353333333333333,
      "grad_norm": 0.15097913146018982,
      "learning_rate": 2.661666666666667e-05,
      "loss": 0.0016,
      "step": 42090
    },
    {
      "epoch": 0.9355555555555556,
      "grad_norm": 0.07683775573968887,
      "learning_rate": 2.6611111111111116e-05,
      "loss": 0.002,
      "step": 42100
    },
    {
      "epoch": 0.9357777777777778,
      "grad_norm": 0.35597214102745056,
      "learning_rate": 2.6605555555555556e-05,
      "loss": 0.0019,
      "step": 42110
    },
    {
      "epoch": 0.936,
      "grad_norm": 0.27027639746665955,
      "learning_rate": 2.6600000000000003e-05,
      "loss": 0.003,
      "step": 42120
    },
    {
      "epoch": 0.9362222222222222,
      "grad_norm": 0.2902526259422302,
      "learning_rate": 2.6594444444444443e-05,
      "loss": 0.0017,
      "step": 42130
    },
    {
      "epoch": 0.9364444444444444,
      "grad_norm": 0.2866058647632599,
      "learning_rate": 2.658888888888889e-05,
      "loss": 0.0021,
      "step": 42140
    },
    {
      "epoch": 0.9366666666666666,
      "grad_norm": 0.22913002967834473,
      "learning_rate": 2.6583333333333333e-05,
      "loss": 0.002,
      "step": 42150
    },
    {
      "epoch": 0.9368888888888889,
      "grad_norm": 0.33674925565719604,
      "learning_rate": 2.657777777777778e-05,
      "loss": 0.0019,
      "step": 42160
    },
    {
      "epoch": 0.9371111111111111,
      "grad_norm": 0.30231350660324097,
      "learning_rate": 2.6572222222222227e-05,
      "loss": 0.0025,
      "step": 42170
    },
    {
      "epoch": 0.9373333333333334,
      "grad_norm": 0.43024444580078125,
      "learning_rate": 2.6566666666666668e-05,
      "loss": 0.0021,
      "step": 42180
    },
    {
      "epoch": 0.9375555555555556,
      "grad_norm": 0.16534729301929474,
      "learning_rate": 2.6561111111111114e-05,
      "loss": 0.0019,
      "step": 42190
    },
    {
      "epoch": 0.9377777777777778,
      "grad_norm": 0.1981632262468338,
      "learning_rate": 2.6555555555555555e-05,
      "loss": 0.0021,
      "step": 42200
    },
    {
      "epoch": 0.938,
      "grad_norm": 0.06376636028289795,
      "learning_rate": 2.655e-05,
      "loss": 0.0023,
      "step": 42210
    },
    {
      "epoch": 0.9382222222222222,
      "grad_norm": 0.0666673555970192,
      "learning_rate": 2.6544444444444445e-05,
      "loss": 0.0019,
      "step": 42220
    },
    {
      "epoch": 0.9384444444444444,
      "grad_norm": 0.04675773158669472,
      "learning_rate": 2.6538888888888892e-05,
      "loss": 0.0027,
      "step": 42230
    },
    {
      "epoch": 0.9386666666666666,
      "grad_norm": 0.2576594650745392,
      "learning_rate": 2.6533333333333332e-05,
      "loss": 0.0021,
      "step": 42240
    },
    {
      "epoch": 0.9388888888888889,
      "grad_norm": 0.07773558050394058,
      "learning_rate": 2.652777777777778e-05,
      "loss": 0.0019,
      "step": 42250
    },
    {
      "epoch": 0.9391111111111111,
      "grad_norm": 0.6973097324371338,
      "learning_rate": 2.6522222222222226e-05,
      "loss": 0.0032,
      "step": 42260
    },
    {
      "epoch": 0.9393333333333334,
      "grad_norm": 0.2994087338447571,
      "learning_rate": 2.6516666666666666e-05,
      "loss": 0.0027,
      "step": 42270
    },
    {
      "epoch": 0.9395555555555556,
      "grad_norm": 0.11528228223323822,
      "learning_rate": 2.6511111111111113e-05,
      "loss": 0.0021,
      "step": 42280
    },
    {
      "epoch": 0.9397777777777778,
      "grad_norm": 0.24348567426204681,
      "learning_rate": 2.6505555555555557e-05,
      "loss": 0.0019,
      "step": 42290
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.5475265979766846,
      "learning_rate": 2.6500000000000004e-05,
      "loss": 0.0018,
      "step": 42300
    },
    {
      "epoch": 0.9402222222222222,
      "grad_norm": 0.23569761216640472,
      "learning_rate": 2.6494444444444444e-05,
      "loss": 0.0019,
      "step": 42310
    },
    {
      "epoch": 0.9404444444444444,
      "grad_norm": 0.5637575387954712,
      "learning_rate": 2.648888888888889e-05,
      "loss": 0.0025,
      "step": 42320
    },
    {
      "epoch": 0.9406666666666667,
      "grad_norm": 0.32960885763168335,
      "learning_rate": 2.648333333333333e-05,
      "loss": 0.0019,
      "step": 42330
    },
    {
      "epoch": 0.9408888888888889,
      "grad_norm": 0.49210503697395325,
      "learning_rate": 2.6477777777777778e-05,
      "loss": 0.0024,
      "step": 42340
    },
    {
      "epoch": 0.9411111111111111,
      "grad_norm": 0.09331594407558441,
      "learning_rate": 2.6472222222222225e-05,
      "loss": 0.0032,
      "step": 42350
    },
    {
      "epoch": 0.9413333333333334,
      "grad_norm": 0.5557737350463867,
      "learning_rate": 2.646666666666667e-05,
      "loss": 0.003,
      "step": 42360
    },
    {
      "epoch": 0.9415555555555556,
      "grad_norm": 0.37632453441619873,
      "learning_rate": 2.6461111111111115e-05,
      "loss": 0.0023,
      "step": 42370
    },
    {
      "epoch": 0.9417777777777778,
      "grad_norm": 0.5472423434257507,
      "learning_rate": 2.6455555555555556e-05,
      "loss": 0.0025,
      "step": 42380
    },
    {
      "epoch": 0.942,
      "grad_norm": 0.5706678628921509,
      "learning_rate": 2.6450000000000003e-05,
      "loss": 0.0025,
      "step": 42390
    },
    {
      "epoch": 0.9422222222222222,
      "grad_norm": 0.26689597964286804,
      "learning_rate": 2.6444444444444443e-05,
      "loss": 0.0018,
      "step": 42400
    },
    {
      "epoch": 0.9424444444444444,
      "grad_norm": 0.08911208808422089,
      "learning_rate": 2.643888888888889e-05,
      "loss": 0.0024,
      "step": 42410
    },
    {
      "epoch": 0.9426666666666667,
      "grad_norm": 0.21296367049217224,
      "learning_rate": 2.6433333333333333e-05,
      "loss": 0.002,
      "step": 42420
    },
    {
      "epoch": 0.9428888888888889,
      "grad_norm": 0.07450012117624283,
      "learning_rate": 2.642777777777778e-05,
      "loss": 0.0016,
      "step": 42430
    },
    {
      "epoch": 0.9431111111111111,
      "grad_norm": 0.11322052776813507,
      "learning_rate": 2.6422222222222227e-05,
      "loss": 0.0019,
      "step": 42440
    },
    {
      "epoch": 0.9433333333333334,
      "grad_norm": 0.07016301900148392,
      "learning_rate": 2.6416666666666667e-05,
      "loss": 0.0026,
      "step": 42450
    },
    {
      "epoch": 0.9435555555555556,
      "grad_norm": 0.22463813424110413,
      "learning_rate": 2.6411111111111114e-05,
      "loss": 0.0026,
      "step": 42460
    },
    {
      "epoch": 0.9437777777777778,
      "grad_norm": 0.3650140166282654,
      "learning_rate": 2.6405555555555554e-05,
      "loss": 0.0016,
      "step": 42470
    },
    {
      "epoch": 0.944,
      "grad_norm": 0.5296210646629333,
      "learning_rate": 2.64e-05,
      "loss": 0.0017,
      "step": 42480
    },
    {
      "epoch": 0.9442222222222222,
      "grad_norm": 0.22802099585533142,
      "learning_rate": 2.6394444444444445e-05,
      "loss": 0.0019,
      "step": 42490
    },
    {
      "epoch": 0.9444444444444444,
      "grad_norm": 0.6210546493530273,
      "learning_rate": 2.6388888888888892e-05,
      "loss": 0.0019,
      "step": 42500
    },
    {
      "epoch": 0.9446666666666667,
      "grad_norm": 0.2660004794597626,
      "learning_rate": 2.6383333333333332e-05,
      "loss": 0.002,
      "step": 42510
    },
    {
      "epoch": 0.9448888888888889,
      "grad_norm": 0.29594454169273376,
      "learning_rate": 2.637777777777778e-05,
      "loss": 0.0025,
      "step": 42520
    },
    {
      "epoch": 0.9451111111111111,
      "grad_norm": 0.3592945337295532,
      "learning_rate": 2.6372222222222226e-05,
      "loss": 0.0023,
      "step": 42530
    },
    {
      "epoch": 0.9453333333333334,
      "grad_norm": 0.3240092396736145,
      "learning_rate": 2.6366666666666666e-05,
      "loss": 0.002,
      "step": 42540
    },
    {
      "epoch": 0.9455555555555556,
      "grad_norm": 0.42218950390815735,
      "learning_rate": 2.6361111111111113e-05,
      "loss": 0.0021,
      "step": 42550
    },
    {
      "epoch": 0.9457777777777778,
      "grad_norm": 0.48124203085899353,
      "learning_rate": 2.6355555555555557e-05,
      "loss": 0.0021,
      "step": 42560
    },
    {
      "epoch": 0.946,
      "grad_norm": 0.484300434589386,
      "learning_rate": 2.6350000000000004e-05,
      "loss": 0.0022,
      "step": 42570
    },
    {
      "epoch": 0.9462222222222222,
      "grad_norm": 0.1134321317076683,
      "learning_rate": 2.6344444444444444e-05,
      "loss": 0.0021,
      "step": 42580
    },
    {
      "epoch": 0.9464444444444444,
      "grad_norm": 0.16507737338542938,
      "learning_rate": 2.633888888888889e-05,
      "loss": 0.002,
      "step": 42590
    },
    {
      "epoch": 0.9466666666666667,
      "grad_norm": 0.293192058801651,
      "learning_rate": 2.633333333333333e-05,
      "loss": 0.0025,
      "step": 42600
    },
    {
      "epoch": 0.9468888888888889,
      "grad_norm": 0.5872282981872559,
      "learning_rate": 2.6327777777777778e-05,
      "loss": 0.002,
      "step": 42610
    },
    {
      "epoch": 0.9471111111111111,
      "grad_norm": 0.25010931491851807,
      "learning_rate": 2.6322222222222225e-05,
      "loss": 0.0019,
      "step": 42620
    },
    {
      "epoch": 0.9473333333333334,
      "grad_norm": 0.33548328280448914,
      "learning_rate": 2.6316666666666668e-05,
      "loss": 0.0022,
      "step": 42630
    },
    {
      "epoch": 0.9475555555555556,
      "grad_norm": 0.4107257127761841,
      "learning_rate": 2.6311111111111115e-05,
      "loss": 0.0021,
      "step": 42640
    },
    {
      "epoch": 0.9477777777777778,
      "grad_norm": 0.16738735139369965,
      "learning_rate": 2.6305555555555555e-05,
      "loss": 0.0026,
      "step": 42650
    },
    {
      "epoch": 0.948,
      "grad_norm": 0.1043296754360199,
      "learning_rate": 2.6300000000000002e-05,
      "loss": 0.002,
      "step": 42660
    },
    {
      "epoch": 0.9482222222222222,
      "grad_norm": 0.7981318235397339,
      "learning_rate": 2.6294444444444442e-05,
      "loss": 0.002,
      "step": 42670
    },
    {
      "epoch": 0.9484444444444444,
      "grad_norm": 0.2485818713903427,
      "learning_rate": 2.628888888888889e-05,
      "loss": 0.0021,
      "step": 42680
    },
    {
      "epoch": 0.9486666666666667,
      "grad_norm": 0.217817023396492,
      "learning_rate": 2.6283333333333333e-05,
      "loss": 0.0019,
      "step": 42690
    },
    {
      "epoch": 0.9488888888888889,
      "grad_norm": 0.237601175904274,
      "learning_rate": 2.627777777777778e-05,
      "loss": 0.0044,
      "step": 42700
    },
    {
      "epoch": 0.9491111111111111,
      "grad_norm": 0.39435678720474243,
      "learning_rate": 2.6272222222222227e-05,
      "loss": 0.002,
      "step": 42710
    },
    {
      "epoch": 0.9493333333333334,
      "grad_norm": 0.1211383119225502,
      "learning_rate": 2.6266666666666667e-05,
      "loss": 0.0018,
      "step": 42720
    },
    {
      "epoch": 0.9495555555555556,
      "grad_norm": 0.200825035572052,
      "learning_rate": 2.6261111111111114e-05,
      "loss": 0.0023,
      "step": 42730
    },
    {
      "epoch": 0.9497777777777778,
      "grad_norm": 0.4046129286289215,
      "learning_rate": 2.6255555555555554e-05,
      "loss": 0.0027,
      "step": 42740
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.3036954700946808,
      "learning_rate": 2.625e-05,
      "loss": 0.0019,
      "step": 42750
    },
    {
      "epoch": 0.9502222222222222,
      "grad_norm": 0.496789813041687,
      "learning_rate": 2.6244444444444445e-05,
      "loss": 0.0021,
      "step": 42760
    },
    {
      "epoch": 0.9504444444444444,
      "grad_norm": 0.26948124170303345,
      "learning_rate": 2.623888888888889e-05,
      "loss": 0.0044,
      "step": 42770
    },
    {
      "epoch": 0.9506666666666667,
      "grad_norm": 0.3196523189544678,
      "learning_rate": 2.6233333333333332e-05,
      "loss": 0.002,
      "step": 42780
    },
    {
      "epoch": 0.9508888888888889,
      "grad_norm": 0.12953612208366394,
      "learning_rate": 2.622777777777778e-05,
      "loss": 0.003,
      "step": 42790
    },
    {
      "epoch": 0.9511111111111111,
      "grad_norm": 0.3931526243686676,
      "learning_rate": 2.6222222222222226e-05,
      "loss": 0.0025,
      "step": 42800
    },
    {
      "epoch": 0.9513333333333334,
      "grad_norm": 0.5053495764732361,
      "learning_rate": 2.6216666666666666e-05,
      "loss": 0.0019,
      "step": 42810
    },
    {
      "epoch": 0.9515555555555556,
      "grad_norm": 0.15770845115184784,
      "learning_rate": 2.6211111111111113e-05,
      "loss": 0.0022,
      "step": 42820
    },
    {
      "epoch": 0.9517777777777777,
      "grad_norm": 0.15490293502807617,
      "learning_rate": 2.6205555555555556e-05,
      "loss": 0.0019,
      "step": 42830
    },
    {
      "epoch": 0.952,
      "grad_norm": 0.14649811387062073,
      "learning_rate": 2.6200000000000003e-05,
      "loss": 0.002,
      "step": 42840
    },
    {
      "epoch": 0.9522222222222222,
      "grad_norm": 0.14174555242061615,
      "learning_rate": 2.6194444444444443e-05,
      "loss": 0.0023,
      "step": 42850
    },
    {
      "epoch": 0.9524444444444444,
      "grad_norm": 0.10824500024318695,
      "learning_rate": 2.618888888888889e-05,
      "loss": 0.0022,
      "step": 42860
    },
    {
      "epoch": 0.9526666666666667,
      "grad_norm": 0.519877016544342,
      "learning_rate": 2.618333333333333e-05,
      "loss": 0.002,
      "step": 42870
    },
    {
      "epoch": 0.9528888888888889,
      "grad_norm": 0.3259149491786957,
      "learning_rate": 2.6177777777777777e-05,
      "loss": 0.0033,
      "step": 42880
    },
    {
      "epoch": 0.9531111111111111,
      "grad_norm": 0.11045295745134354,
      "learning_rate": 2.6172222222222224e-05,
      "loss": 0.0018,
      "step": 42890
    },
    {
      "epoch": 0.9533333333333334,
      "grad_norm": 0.9033506512641907,
      "learning_rate": 2.6166666666666668e-05,
      "loss": 0.0023,
      "step": 42900
    },
    {
      "epoch": 0.9535555555555556,
      "grad_norm": 0.2916821241378784,
      "learning_rate": 2.6161111111111115e-05,
      "loss": 0.0025,
      "step": 42910
    },
    {
      "epoch": 0.9537777777777777,
      "grad_norm": 0.3953840136528015,
      "learning_rate": 2.6155555555555555e-05,
      "loss": 0.0017,
      "step": 42920
    },
    {
      "epoch": 0.954,
      "grad_norm": 0.14307038486003876,
      "learning_rate": 2.6150000000000002e-05,
      "loss": 0.0021,
      "step": 42930
    },
    {
      "epoch": 0.9542222222222222,
      "grad_norm": 0.4022902548313141,
      "learning_rate": 2.6144444444444442e-05,
      "loss": 0.0021,
      "step": 42940
    },
    {
      "epoch": 0.9544444444444444,
      "grad_norm": 0.10462431609630585,
      "learning_rate": 2.613888888888889e-05,
      "loss": 0.0029,
      "step": 42950
    },
    {
      "epoch": 0.9546666666666667,
      "grad_norm": 0.11303013563156128,
      "learning_rate": 2.6133333333333333e-05,
      "loss": 0.0022,
      "step": 42960
    },
    {
      "epoch": 0.9548888888888889,
      "grad_norm": 0.13476210832595825,
      "learning_rate": 2.612777777777778e-05,
      "loss": 0.0016,
      "step": 42970
    },
    {
      "epoch": 0.9551111111111111,
      "grad_norm": 0.12677954137325287,
      "learning_rate": 2.6122222222222227e-05,
      "loss": 0.0022,
      "step": 42980
    },
    {
      "epoch": 0.9553333333333334,
      "grad_norm": 0.21680347621440887,
      "learning_rate": 2.6116666666666667e-05,
      "loss": 0.0023,
      "step": 42990
    },
    {
      "epoch": 0.9555555555555556,
      "grad_norm": 0.060820627957582474,
      "learning_rate": 2.6111111111111114e-05,
      "loss": 0.0019,
      "step": 43000
    },
    {
      "epoch": 0.9557777777777777,
      "grad_norm": 0.7104219794273376,
      "learning_rate": 2.6105555555555554e-05,
      "loss": 0.0022,
      "step": 43010
    },
    {
      "epoch": 0.956,
      "grad_norm": 0.1128988042473793,
      "learning_rate": 2.61e-05,
      "loss": 0.0025,
      "step": 43020
    },
    {
      "epoch": 0.9562222222222222,
      "grad_norm": 0.23632824420928955,
      "learning_rate": 2.6094444444444444e-05,
      "loss": 0.0018,
      "step": 43030
    },
    {
      "epoch": 0.9564444444444444,
      "grad_norm": 0.5070614218711853,
      "learning_rate": 2.608888888888889e-05,
      "loss": 0.0018,
      "step": 43040
    },
    {
      "epoch": 0.9566666666666667,
      "grad_norm": 0.2090759128332138,
      "learning_rate": 2.608333333333333e-05,
      "loss": 0.0021,
      "step": 43050
    },
    {
      "epoch": 0.9568888888888889,
      "grad_norm": 0.6603326797485352,
      "learning_rate": 2.607777777777778e-05,
      "loss": 0.0024,
      "step": 43060
    },
    {
      "epoch": 0.9571111111111111,
      "grad_norm": 0.1183861494064331,
      "learning_rate": 2.6072222222222225e-05,
      "loss": 0.0021,
      "step": 43070
    },
    {
      "epoch": 0.9573333333333334,
      "grad_norm": 0.3751576542854309,
      "learning_rate": 2.6066666666666666e-05,
      "loss": 0.0026,
      "step": 43080
    },
    {
      "epoch": 0.9575555555555556,
      "grad_norm": 0.31405794620513916,
      "learning_rate": 2.6061111111111113e-05,
      "loss": 0.0021,
      "step": 43090
    },
    {
      "epoch": 0.9577777777777777,
      "grad_norm": 0.08408945798873901,
      "learning_rate": 2.6055555555555556e-05,
      "loss": 0.0031,
      "step": 43100
    },
    {
      "epoch": 0.958,
      "grad_norm": 0.22827878594398499,
      "learning_rate": 2.6050000000000003e-05,
      "loss": 0.0019,
      "step": 43110
    },
    {
      "epoch": 0.9582222222222222,
      "grad_norm": 0.32299742102622986,
      "learning_rate": 2.6044444444444443e-05,
      "loss": 0.0032,
      "step": 43120
    },
    {
      "epoch": 0.9584444444444444,
      "grad_norm": 0.3967679440975189,
      "learning_rate": 2.603888888888889e-05,
      "loss": 0.0019,
      "step": 43130
    },
    {
      "epoch": 0.9586666666666667,
      "grad_norm": 0.28849372267723083,
      "learning_rate": 2.6033333333333337e-05,
      "loss": 0.0021,
      "step": 43140
    },
    {
      "epoch": 0.9588888888888889,
      "grad_norm": 0.5367441177368164,
      "learning_rate": 2.6027777777777777e-05,
      "loss": 0.0021,
      "step": 43150
    },
    {
      "epoch": 0.9591111111111111,
      "grad_norm": 0.34381288290023804,
      "learning_rate": 2.6022222222222224e-05,
      "loss": 0.0023,
      "step": 43160
    },
    {
      "epoch": 0.9593333333333334,
      "grad_norm": 0.41982439160346985,
      "learning_rate": 2.6016666666666668e-05,
      "loss": 0.0024,
      "step": 43170
    },
    {
      "epoch": 0.9595555555555556,
      "grad_norm": 0.8333602547645569,
      "learning_rate": 2.6011111111111115e-05,
      "loss": 0.0018,
      "step": 43180
    },
    {
      "epoch": 0.9597777777777777,
      "grad_norm": 0.22376970946788788,
      "learning_rate": 2.6005555555555555e-05,
      "loss": 0.0021,
      "step": 43190
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.0695306658744812,
      "learning_rate": 2.6000000000000002e-05,
      "loss": 0.0022,
      "step": 43200
    },
    {
      "epoch": 0.9602222222222222,
      "grad_norm": 0.12738457322120667,
      "learning_rate": 2.5994444444444442e-05,
      "loss": 0.0018,
      "step": 43210
    },
    {
      "epoch": 0.9604444444444444,
      "grad_norm": 0.33737242221832275,
      "learning_rate": 2.598888888888889e-05,
      "loss": 0.0021,
      "step": 43220
    },
    {
      "epoch": 0.9606666666666667,
      "grad_norm": 0.6884828209877014,
      "learning_rate": 2.5983333333333336e-05,
      "loss": 0.0028,
      "step": 43230
    },
    {
      "epoch": 0.9608888888888889,
      "grad_norm": 0.22961819171905518,
      "learning_rate": 2.597777777777778e-05,
      "loss": 0.0025,
      "step": 43240
    },
    {
      "epoch": 0.9611111111111111,
      "grad_norm": 0.18473346531391144,
      "learning_rate": 2.5972222222222226e-05,
      "loss": 0.003,
      "step": 43250
    },
    {
      "epoch": 0.9613333333333334,
      "grad_norm": 0.21180693805217743,
      "learning_rate": 2.5966666666666667e-05,
      "loss": 0.0019,
      "step": 43260
    },
    {
      "epoch": 0.9615555555555556,
      "grad_norm": 0.09411635249853134,
      "learning_rate": 2.5961111111111113e-05,
      "loss": 0.0019,
      "step": 43270
    },
    {
      "epoch": 0.9617777777777777,
      "grad_norm": 0.7570671439170837,
      "learning_rate": 2.5955555555555554e-05,
      "loss": 0.0026,
      "step": 43280
    },
    {
      "epoch": 0.962,
      "grad_norm": 0.10901069641113281,
      "learning_rate": 2.595e-05,
      "loss": 0.0025,
      "step": 43290
    },
    {
      "epoch": 0.9622222222222222,
      "grad_norm": 0.3960877060890198,
      "learning_rate": 2.5944444444444444e-05,
      "loss": 0.0022,
      "step": 43300
    },
    {
      "epoch": 0.9624444444444444,
      "grad_norm": 0.2477473020553589,
      "learning_rate": 2.593888888888889e-05,
      "loss": 0.0023,
      "step": 43310
    },
    {
      "epoch": 0.9626666666666667,
      "grad_norm": 0.17694233357906342,
      "learning_rate": 2.5933333333333338e-05,
      "loss": 0.0022,
      "step": 43320
    },
    {
      "epoch": 0.9628888888888889,
      "grad_norm": 0.22280044853687286,
      "learning_rate": 2.5927777777777778e-05,
      "loss": 0.0021,
      "step": 43330
    },
    {
      "epoch": 0.9631111111111111,
      "grad_norm": 0.11263029277324677,
      "learning_rate": 2.5922222222222225e-05,
      "loss": 0.0017,
      "step": 43340
    },
    {
      "epoch": 0.9633333333333334,
      "grad_norm": 0.19290593266487122,
      "learning_rate": 2.5916666666666665e-05,
      "loss": 0.0029,
      "step": 43350
    },
    {
      "epoch": 0.9635555555555556,
      "grad_norm": 0.12460041046142578,
      "learning_rate": 2.5911111111111112e-05,
      "loss": 0.0035,
      "step": 43360
    },
    {
      "epoch": 0.9637777777777777,
      "grad_norm": 0.30133605003356934,
      "learning_rate": 2.5905555555555556e-05,
      "loss": 0.0028,
      "step": 43370
    },
    {
      "epoch": 0.964,
      "grad_norm": 0.6555137038230896,
      "learning_rate": 2.5900000000000003e-05,
      "loss": 0.0018,
      "step": 43380
    },
    {
      "epoch": 0.9642222222222222,
      "grad_norm": 0.40856119990348816,
      "learning_rate": 2.5894444444444443e-05,
      "loss": 0.0022,
      "step": 43390
    },
    {
      "epoch": 0.9644444444444444,
      "grad_norm": 0.5455223321914673,
      "learning_rate": 2.588888888888889e-05,
      "loss": 0.0032,
      "step": 43400
    },
    {
      "epoch": 0.9646666666666667,
      "grad_norm": 0.32740455865859985,
      "learning_rate": 2.5883333333333337e-05,
      "loss": 0.002,
      "step": 43410
    },
    {
      "epoch": 0.9648888888888889,
      "grad_norm": 0.5882527232170105,
      "learning_rate": 2.5877777777777777e-05,
      "loss": 0.002,
      "step": 43420
    },
    {
      "epoch": 0.9651111111111111,
      "grad_norm": 0.06653730571269989,
      "learning_rate": 2.5872222222222224e-05,
      "loss": 0.0019,
      "step": 43430
    },
    {
      "epoch": 0.9653333333333334,
      "grad_norm": 0.09870756417512894,
      "learning_rate": 2.5866666666666667e-05,
      "loss": 0.0017,
      "step": 43440
    },
    {
      "epoch": 0.9655555555555555,
      "grad_norm": 0.3054181933403015,
      "learning_rate": 2.5861111111111114e-05,
      "loss": 0.002,
      "step": 43450
    },
    {
      "epoch": 0.9657777777777777,
      "grad_norm": 0.5585576295852661,
      "learning_rate": 2.5855555555555555e-05,
      "loss": 0.0023,
      "step": 43460
    },
    {
      "epoch": 0.966,
      "grad_norm": 0.11676681786775589,
      "learning_rate": 2.585e-05,
      "loss": 0.0021,
      "step": 43470
    },
    {
      "epoch": 0.9662222222222222,
      "grad_norm": 0.28465598821640015,
      "learning_rate": 2.5844444444444442e-05,
      "loss": 0.0021,
      "step": 43480
    },
    {
      "epoch": 0.9664444444444444,
      "grad_norm": 0.31657740473747253,
      "learning_rate": 2.583888888888889e-05,
      "loss": 0.0019,
      "step": 43490
    },
    {
      "epoch": 0.9666666666666667,
      "grad_norm": 0.4010377824306488,
      "learning_rate": 2.5833333333333336e-05,
      "loss": 0.0019,
      "step": 43500
    },
    {
      "epoch": 0.9668888888888889,
      "grad_norm": 0.5494635701179504,
      "learning_rate": 2.582777777777778e-05,
      "loss": 0.0022,
      "step": 43510
    },
    {
      "epoch": 0.9671111111111111,
      "grad_norm": 0.3078081011772156,
      "learning_rate": 2.5822222222222226e-05,
      "loss": 0.0028,
      "step": 43520
    },
    {
      "epoch": 0.9673333333333334,
      "grad_norm": 0.17392654716968536,
      "learning_rate": 2.5816666666666666e-05,
      "loss": 0.003,
      "step": 43530
    },
    {
      "epoch": 0.9675555555555555,
      "grad_norm": 0.10809175670146942,
      "learning_rate": 2.5811111111111113e-05,
      "loss": 0.0027,
      "step": 43540
    },
    {
      "epoch": 0.9677777777777777,
      "grad_norm": 0.5313287973403931,
      "learning_rate": 2.5805555555555553e-05,
      "loss": 0.0019,
      "step": 43550
    },
    {
      "epoch": 0.968,
      "grad_norm": 0.6662430763244629,
      "learning_rate": 2.58e-05,
      "loss": 0.0024,
      "step": 43560
    },
    {
      "epoch": 0.9682222222222222,
      "grad_norm": 0.3300684690475464,
      "learning_rate": 2.5794444444444444e-05,
      "loss": 0.0025,
      "step": 43570
    },
    {
      "epoch": 0.9684444444444444,
      "grad_norm": 0.3904769718647003,
      "learning_rate": 2.578888888888889e-05,
      "loss": 0.0018,
      "step": 43580
    },
    {
      "epoch": 0.9686666666666667,
      "grad_norm": 0.1253225952386856,
      "learning_rate": 2.5783333333333338e-05,
      "loss": 0.0022,
      "step": 43590
    },
    {
      "epoch": 0.9688888888888889,
      "grad_norm": 0.429008424282074,
      "learning_rate": 2.5777777777777778e-05,
      "loss": 0.0021,
      "step": 43600
    },
    {
      "epoch": 0.9691111111111111,
      "grad_norm": 0.4502071142196655,
      "learning_rate": 2.5772222222222225e-05,
      "loss": 0.0026,
      "step": 43610
    },
    {
      "epoch": 0.9693333333333334,
      "grad_norm": 0.06847785413265228,
      "learning_rate": 2.5766666666666665e-05,
      "loss": 0.0027,
      "step": 43620
    },
    {
      "epoch": 0.9695555555555555,
      "grad_norm": 0.1083841621875763,
      "learning_rate": 2.5761111111111112e-05,
      "loss": 0.0021,
      "step": 43630
    },
    {
      "epoch": 0.9697777777777777,
      "grad_norm": 0.2171810418367386,
      "learning_rate": 2.5755555555555556e-05,
      "loss": 0.0018,
      "step": 43640
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.176217183470726,
      "learning_rate": 2.5750000000000002e-05,
      "loss": 0.0018,
      "step": 43650
    },
    {
      "epoch": 0.9702222222222222,
      "grad_norm": 0.2365388125181198,
      "learning_rate": 2.5744444444444443e-05,
      "loss": 0.0023,
      "step": 43660
    },
    {
      "epoch": 0.9704444444444444,
      "grad_norm": 0.1306958794593811,
      "learning_rate": 2.573888888888889e-05,
      "loss": 0.0025,
      "step": 43670
    },
    {
      "epoch": 0.9706666666666667,
      "grad_norm": 0.07001232355833054,
      "learning_rate": 2.5733333333333337e-05,
      "loss": 0.0024,
      "step": 43680
    },
    {
      "epoch": 0.9708888888888889,
      "grad_norm": 0.2883647382259369,
      "learning_rate": 2.572777777777778e-05,
      "loss": 0.003,
      "step": 43690
    },
    {
      "epoch": 0.9711111111111111,
      "grad_norm": 0.4811401069164276,
      "learning_rate": 2.5722222222222224e-05,
      "loss": 0.0027,
      "step": 43700
    },
    {
      "epoch": 0.9713333333333334,
      "grad_norm": 0.07059286534786224,
      "learning_rate": 2.5716666666666667e-05,
      "loss": 0.0024,
      "step": 43710
    },
    {
      "epoch": 0.9715555555555555,
      "grad_norm": 0.3541065454483032,
      "learning_rate": 2.5711111111111114e-05,
      "loss": 0.0034,
      "step": 43720
    },
    {
      "epoch": 0.9717777777777777,
      "grad_norm": 0.13267308473587036,
      "learning_rate": 2.5705555555555554e-05,
      "loss": 0.0026,
      "step": 43730
    },
    {
      "epoch": 0.972,
      "grad_norm": 0.411073237657547,
      "learning_rate": 2.57e-05,
      "loss": 0.0022,
      "step": 43740
    },
    {
      "epoch": 0.9722222222222222,
      "grad_norm": 0.18854328989982605,
      "learning_rate": 2.5694444444444445e-05,
      "loss": 0.0033,
      "step": 43750
    },
    {
      "epoch": 0.9724444444444444,
      "grad_norm": 0.3351380527019501,
      "learning_rate": 2.5688888888888892e-05,
      "loss": 0.0031,
      "step": 43760
    },
    {
      "epoch": 0.9726666666666667,
      "grad_norm": 0.2380668669939041,
      "learning_rate": 2.5683333333333335e-05,
      "loss": 0.002,
      "step": 43770
    },
    {
      "epoch": 0.9728888888888889,
      "grad_norm": 0.0713573694229126,
      "learning_rate": 2.567777777777778e-05,
      "loss": 0.0018,
      "step": 43780
    },
    {
      "epoch": 0.9731111111111111,
      "grad_norm": 0.17266608774662018,
      "learning_rate": 2.5672222222222226e-05,
      "loss": 0.0032,
      "step": 43790
    },
    {
      "epoch": 0.9733333333333334,
      "grad_norm": 0.055988725274801254,
      "learning_rate": 2.5666666666666666e-05,
      "loss": 0.0016,
      "step": 43800
    },
    {
      "epoch": 0.9735555555555555,
      "grad_norm": 0.14509831368923187,
      "learning_rate": 2.5661111111111113e-05,
      "loss": 0.0031,
      "step": 43810
    },
    {
      "epoch": 0.9737777777777777,
      "grad_norm": 0.3279915750026703,
      "learning_rate": 2.5655555555555557e-05,
      "loss": 0.0021,
      "step": 43820
    },
    {
      "epoch": 0.974,
      "grad_norm": 0.30721622705459595,
      "learning_rate": 2.5650000000000003e-05,
      "loss": 0.0023,
      "step": 43830
    },
    {
      "epoch": 0.9742222222222222,
      "grad_norm": 0.07649007439613342,
      "learning_rate": 2.5644444444444444e-05,
      "loss": 0.0019,
      "step": 43840
    },
    {
      "epoch": 0.9744444444444444,
      "grad_norm": 0.36100900173187256,
      "learning_rate": 2.563888888888889e-05,
      "loss": 0.0021,
      "step": 43850
    },
    {
      "epoch": 0.9746666666666667,
      "grad_norm": 0.1527874618768692,
      "learning_rate": 2.5633333333333338e-05,
      "loss": 0.0023,
      "step": 43860
    },
    {
      "epoch": 0.9748888888888889,
      "grad_norm": 0.10053854435682297,
      "learning_rate": 2.5627777777777778e-05,
      "loss": 0.0028,
      "step": 43870
    },
    {
      "epoch": 0.9751111111111112,
      "grad_norm": 0.23892655968666077,
      "learning_rate": 2.5622222222222225e-05,
      "loss": 0.0017,
      "step": 43880
    },
    {
      "epoch": 0.9753333333333334,
      "grad_norm": 0.103695809841156,
      "learning_rate": 2.5616666666666668e-05,
      "loss": 0.0026,
      "step": 43890
    },
    {
      "epoch": 0.9755555555555555,
      "grad_norm": 0.5139601230621338,
      "learning_rate": 2.5611111111111115e-05,
      "loss": 0.0026,
      "step": 43900
    },
    {
      "epoch": 0.9757777777777777,
      "grad_norm": 0.512733519077301,
      "learning_rate": 2.5605555555555555e-05,
      "loss": 0.002,
      "step": 43910
    },
    {
      "epoch": 0.976,
      "grad_norm": 0.17313802242279053,
      "learning_rate": 2.5600000000000002e-05,
      "loss": 0.002,
      "step": 43920
    },
    {
      "epoch": 0.9762222222222222,
      "grad_norm": 0.27618125081062317,
      "learning_rate": 2.5594444444444442e-05,
      "loss": 0.0032,
      "step": 43930
    },
    {
      "epoch": 0.9764444444444444,
      "grad_norm": 0.2634340226650238,
      "learning_rate": 2.558888888888889e-05,
      "loss": 0.002,
      "step": 43940
    },
    {
      "epoch": 0.9766666666666667,
      "grad_norm": 0.31597888469696045,
      "learning_rate": 2.5583333333333336e-05,
      "loss": 0.0021,
      "step": 43950
    },
    {
      "epoch": 0.9768888888888889,
      "grad_norm": 0.22041510045528412,
      "learning_rate": 2.557777777777778e-05,
      "loss": 0.0025,
      "step": 43960
    },
    {
      "epoch": 0.9771111111111112,
      "grad_norm": 0.05550903081893921,
      "learning_rate": 2.5572222222222227e-05,
      "loss": 0.0019,
      "step": 43970
    },
    {
      "epoch": 0.9773333333333334,
      "grad_norm": 0.5540592074394226,
      "learning_rate": 2.5566666666666667e-05,
      "loss": 0.0028,
      "step": 43980
    },
    {
      "epoch": 0.9775555555555555,
      "grad_norm": 0.22172346711158752,
      "learning_rate": 2.5561111111111114e-05,
      "loss": 0.0021,
      "step": 43990
    },
    {
      "epoch": 0.9777777777777777,
      "grad_norm": 0.2503708004951477,
      "learning_rate": 2.5555555555555554e-05,
      "loss": 0.0029,
      "step": 44000
    },
    {
      "epoch": 0.978,
      "grad_norm": 0.2856001555919647,
      "learning_rate": 2.555e-05,
      "loss": 0.0032,
      "step": 44010
    },
    {
      "epoch": 0.9782222222222222,
      "grad_norm": 0.21717606484889984,
      "learning_rate": 2.5544444444444445e-05,
      "loss": 0.0028,
      "step": 44020
    },
    {
      "epoch": 0.9784444444444444,
      "grad_norm": 0.22675831615924835,
      "learning_rate": 2.553888888888889e-05,
      "loss": 0.0021,
      "step": 44030
    },
    {
      "epoch": 0.9786666666666667,
      "grad_norm": 0.27463191747665405,
      "learning_rate": 2.553333333333334e-05,
      "loss": 0.002,
      "step": 44040
    },
    {
      "epoch": 0.9788888888888889,
      "grad_norm": 0.18470928072929382,
      "learning_rate": 2.552777777777778e-05,
      "loss": 0.0027,
      "step": 44050
    },
    {
      "epoch": 0.9791111111111112,
      "grad_norm": 0.08831465244293213,
      "learning_rate": 2.5522222222222226e-05,
      "loss": 0.0022,
      "step": 44060
    },
    {
      "epoch": 0.9793333333333333,
      "grad_norm": 0.3126228153705597,
      "learning_rate": 2.5516666666666666e-05,
      "loss": 0.0021,
      "step": 44070
    },
    {
      "epoch": 0.9795555555555555,
      "grad_norm": 0.11249201744794846,
      "learning_rate": 2.5511111111111113e-05,
      "loss": 0.0023,
      "step": 44080
    },
    {
      "epoch": 0.9797777777777777,
      "grad_norm": 0.7161502838134766,
      "learning_rate": 2.5505555555555556e-05,
      "loss": 0.002,
      "step": 44090
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.13181927800178528,
      "learning_rate": 2.5500000000000003e-05,
      "loss": 0.0023,
      "step": 44100
    },
    {
      "epoch": 0.9802222222222222,
      "grad_norm": 0.10531861335039139,
      "learning_rate": 2.5494444444444443e-05,
      "loss": 0.0018,
      "step": 44110
    },
    {
      "epoch": 0.9804444444444445,
      "grad_norm": 0.05545143783092499,
      "learning_rate": 2.548888888888889e-05,
      "loss": 0.002,
      "step": 44120
    },
    {
      "epoch": 0.9806666666666667,
      "grad_norm": 0.31465455889701843,
      "learning_rate": 2.5483333333333337e-05,
      "loss": 0.003,
      "step": 44130
    },
    {
      "epoch": 0.9808888888888889,
      "grad_norm": 0.16079649329185486,
      "learning_rate": 2.5477777777777777e-05,
      "loss": 0.0024,
      "step": 44140
    },
    {
      "epoch": 0.9811111111111112,
      "grad_norm": 0.10789364576339722,
      "learning_rate": 2.5472222222222224e-05,
      "loss": 0.0021,
      "step": 44150
    },
    {
      "epoch": 0.9813333333333333,
      "grad_norm": 0.466805100440979,
      "learning_rate": 2.5466666666666668e-05,
      "loss": 0.002,
      "step": 44160
    },
    {
      "epoch": 0.9815555555555555,
      "grad_norm": 0.13516457378864288,
      "learning_rate": 2.5461111111111115e-05,
      "loss": 0.0025,
      "step": 44170
    },
    {
      "epoch": 0.9817777777777777,
      "grad_norm": 0.10492318123579025,
      "learning_rate": 2.5455555555555555e-05,
      "loss": 0.0021,
      "step": 44180
    },
    {
      "epoch": 0.982,
      "grad_norm": 0.4354404807090759,
      "learning_rate": 2.5450000000000002e-05,
      "loss": 0.0029,
      "step": 44190
    },
    {
      "epoch": 0.9822222222222222,
      "grad_norm": 0.11916571855545044,
      "learning_rate": 2.5444444444444442e-05,
      "loss": 0.0018,
      "step": 44200
    },
    {
      "epoch": 0.9824444444444445,
      "grad_norm": 0.4043787717819214,
      "learning_rate": 2.543888888888889e-05,
      "loss": 0.0022,
      "step": 44210
    },
    {
      "epoch": 0.9826666666666667,
      "grad_norm": 0.1513243466615677,
      "learning_rate": 2.5433333333333336e-05,
      "loss": 0.0019,
      "step": 44220
    },
    {
      "epoch": 0.9828888888888889,
      "grad_norm": 0.5529747605323792,
      "learning_rate": 2.542777777777778e-05,
      "loss": 0.0023,
      "step": 44230
    },
    {
      "epoch": 0.9831111111111112,
      "grad_norm": 0.2803173065185547,
      "learning_rate": 2.5422222222222227e-05,
      "loss": 0.0018,
      "step": 44240
    },
    {
      "epoch": 0.9833333333333333,
      "grad_norm": 0.06974054872989655,
      "learning_rate": 2.5416666666666667e-05,
      "loss": 0.0023,
      "step": 44250
    },
    {
      "epoch": 0.9835555555555555,
      "grad_norm": 0.30817174911499023,
      "learning_rate": 2.5411111111111114e-05,
      "loss": 0.003,
      "step": 44260
    },
    {
      "epoch": 0.9837777777777778,
      "grad_norm": 0.16200338304042816,
      "learning_rate": 2.5405555555555554e-05,
      "loss": 0.0019,
      "step": 44270
    },
    {
      "epoch": 0.984,
      "grad_norm": 0.5390952229499817,
      "learning_rate": 2.54e-05,
      "loss": 0.0019,
      "step": 44280
    },
    {
      "epoch": 0.9842222222222222,
      "grad_norm": 0.6289590001106262,
      "learning_rate": 2.5394444444444444e-05,
      "loss": 0.002,
      "step": 44290
    },
    {
      "epoch": 0.9844444444444445,
      "grad_norm": 0.08857683837413788,
      "learning_rate": 2.538888888888889e-05,
      "loss": 0.0025,
      "step": 44300
    },
    {
      "epoch": 0.9846666666666667,
      "grad_norm": 0.7855722904205322,
      "learning_rate": 2.5383333333333338e-05,
      "loss": 0.0018,
      "step": 44310
    },
    {
      "epoch": 0.9848888888888889,
      "grad_norm": 0.5580607652664185,
      "learning_rate": 2.537777777777778e-05,
      "loss": 0.0025,
      "step": 44320
    },
    {
      "epoch": 0.9851111111111112,
      "grad_norm": 0.06084911525249481,
      "learning_rate": 2.5372222222222225e-05,
      "loss": 0.0025,
      "step": 44330
    },
    {
      "epoch": 0.9853333333333333,
      "grad_norm": 0.1839779168367386,
      "learning_rate": 2.5366666666666665e-05,
      "loss": 0.0028,
      "step": 44340
    },
    {
      "epoch": 0.9855555555555555,
      "grad_norm": 0.07230239361524582,
      "learning_rate": 2.5361111111111112e-05,
      "loss": 0.0019,
      "step": 44350
    },
    {
      "epoch": 0.9857777777777778,
      "grad_norm": 0.2403450906276703,
      "learning_rate": 2.5355555555555556e-05,
      "loss": 0.0031,
      "step": 44360
    },
    {
      "epoch": 0.986,
      "grad_norm": 0.13169698417186737,
      "learning_rate": 2.5350000000000003e-05,
      "loss": 0.0032,
      "step": 44370
    },
    {
      "epoch": 0.9862222222222222,
      "grad_norm": 0.27440503239631653,
      "learning_rate": 2.534444444444445e-05,
      "loss": 0.0023,
      "step": 44380
    },
    {
      "epoch": 0.9864444444444445,
      "grad_norm": 0.2237149327993393,
      "learning_rate": 2.533888888888889e-05,
      "loss": 0.0032,
      "step": 44390
    },
    {
      "epoch": 0.9866666666666667,
      "grad_norm": 0.065537229180336,
      "learning_rate": 2.5333333333333337e-05,
      "loss": 0.0027,
      "step": 44400
    },
    {
      "epoch": 0.9868888888888889,
      "grad_norm": 0.13262391090393066,
      "learning_rate": 2.5327777777777777e-05,
      "loss": 0.0029,
      "step": 44410
    },
    {
      "epoch": 0.9871111111111112,
      "grad_norm": 0.2837238609790802,
      "learning_rate": 2.5322222222222224e-05,
      "loss": 0.0035,
      "step": 44420
    },
    {
      "epoch": 0.9873333333333333,
      "grad_norm": 0.38182467222213745,
      "learning_rate": 2.5316666666666668e-05,
      "loss": 0.0017,
      "step": 44430
    },
    {
      "epoch": 0.9875555555555555,
      "grad_norm": 0.19797760248184204,
      "learning_rate": 2.5311111111111115e-05,
      "loss": 0.0022,
      "step": 44440
    },
    {
      "epoch": 0.9877777777777778,
      "grad_norm": 0.30573713779449463,
      "learning_rate": 2.5305555555555555e-05,
      "loss": 0.0029,
      "step": 44450
    },
    {
      "epoch": 0.988,
      "grad_norm": 0.4123101532459259,
      "learning_rate": 2.5300000000000002e-05,
      "loss": 0.003,
      "step": 44460
    },
    {
      "epoch": 0.9882222222222222,
      "grad_norm": 0.07403713464736938,
      "learning_rate": 2.529444444444445e-05,
      "loss": 0.0026,
      "step": 44470
    },
    {
      "epoch": 0.9884444444444445,
      "grad_norm": 0.5920395851135254,
      "learning_rate": 2.528888888888889e-05,
      "loss": 0.0025,
      "step": 44480
    },
    {
      "epoch": 0.9886666666666667,
      "grad_norm": 0.07724715024232864,
      "learning_rate": 2.5283333333333336e-05,
      "loss": 0.0018,
      "step": 44490
    },
    {
      "epoch": 0.9888888888888889,
      "grad_norm": 0.14701193571090698,
      "learning_rate": 2.527777777777778e-05,
      "loss": 0.0025,
      "step": 44500
    },
    {
      "epoch": 0.9891111111111112,
      "grad_norm": 0.07823364436626434,
      "learning_rate": 2.5272222222222226e-05,
      "loss": 0.002,
      "step": 44510
    },
    {
      "epoch": 0.9893333333333333,
      "grad_norm": 0.13480502367019653,
      "learning_rate": 2.5266666666666666e-05,
      "loss": 0.0026,
      "step": 44520
    },
    {
      "epoch": 0.9895555555555555,
      "grad_norm": 0.29455462098121643,
      "learning_rate": 2.5261111111111113e-05,
      "loss": 0.0027,
      "step": 44530
    },
    {
      "epoch": 0.9897777777777778,
      "grad_norm": 0.2554246485233307,
      "learning_rate": 2.5255555555555554e-05,
      "loss": 0.0019,
      "step": 44540
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.0986633226275444,
      "learning_rate": 2.525e-05,
      "loss": 0.0021,
      "step": 44550
    },
    {
      "epoch": 0.9902222222222222,
      "grad_norm": 0.5408576726913452,
      "learning_rate": 2.5244444444444447e-05,
      "loss": 0.0021,
      "step": 44560
    },
    {
      "epoch": 0.9904444444444445,
      "grad_norm": 0.28341132402420044,
      "learning_rate": 2.523888888888889e-05,
      "loss": 0.0027,
      "step": 44570
    },
    {
      "epoch": 0.9906666666666667,
      "grad_norm": 0.4557189643383026,
      "learning_rate": 2.5233333333333338e-05,
      "loss": 0.0023,
      "step": 44580
    },
    {
      "epoch": 0.9908888888888889,
      "grad_norm": 0.2614111006259918,
      "learning_rate": 2.5227777777777778e-05,
      "loss": 0.002,
      "step": 44590
    },
    {
      "epoch": 0.9911111111111112,
      "grad_norm": 0.5802608132362366,
      "learning_rate": 2.5222222222222225e-05,
      "loss": 0.0022,
      "step": 44600
    },
    {
      "epoch": 0.9913333333333333,
      "grad_norm": 0.3806121051311493,
      "learning_rate": 2.5216666666666665e-05,
      "loss": 0.0024,
      "step": 44610
    },
    {
      "epoch": 0.9915555555555555,
      "grad_norm": 0.2835339307785034,
      "learning_rate": 2.5211111111111112e-05,
      "loss": 0.0019,
      "step": 44620
    },
    {
      "epoch": 0.9917777777777778,
      "grad_norm": 0.13861314952373505,
      "learning_rate": 2.5205555555555556e-05,
      "loss": 0.0019,
      "step": 44630
    },
    {
      "epoch": 0.992,
      "grad_norm": 0.33582603931427,
      "learning_rate": 2.5200000000000003e-05,
      "loss": 0.0032,
      "step": 44640
    },
    {
      "epoch": 0.9922222222222222,
      "grad_norm": 0.14356233179569244,
      "learning_rate": 2.519444444444445e-05,
      "loss": 0.0021,
      "step": 44650
    },
    {
      "epoch": 0.9924444444444445,
      "grad_norm": 0.46505844593048096,
      "learning_rate": 2.518888888888889e-05,
      "loss": 0.0026,
      "step": 44660
    },
    {
      "epoch": 0.9926666666666667,
      "grad_norm": 0.36273232102394104,
      "learning_rate": 2.5183333333333337e-05,
      "loss": 0.0025,
      "step": 44670
    },
    {
      "epoch": 0.9928888888888889,
      "grad_norm": 0.3022545576095581,
      "learning_rate": 2.5177777777777777e-05,
      "loss": 0.0024,
      "step": 44680
    },
    {
      "epoch": 0.9931111111111111,
      "grad_norm": 0.14890386164188385,
      "learning_rate": 2.5172222222222224e-05,
      "loss": 0.0017,
      "step": 44690
    },
    {
      "epoch": 0.9933333333333333,
      "grad_norm": 0.6985365748405457,
      "learning_rate": 2.5166666666666667e-05,
      "loss": 0.0021,
      "step": 44700
    },
    {
      "epoch": 0.9935555555555555,
      "grad_norm": 0.5969297289848328,
      "learning_rate": 2.5161111111111114e-05,
      "loss": 0.0026,
      "step": 44710
    },
    {
      "epoch": 0.9937777777777778,
      "grad_norm": 0.09724702686071396,
      "learning_rate": 2.5155555555555555e-05,
      "loss": 0.0026,
      "step": 44720
    },
    {
      "epoch": 0.994,
      "grad_norm": 0.45761242508888245,
      "learning_rate": 2.515e-05,
      "loss": 0.0021,
      "step": 44730
    },
    {
      "epoch": 0.9942222222222222,
      "grad_norm": 0.580750048160553,
      "learning_rate": 2.514444444444445e-05,
      "loss": 0.0018,
      "step": 44740
    },
    {
      "epoch": 0.9944444444444445,
      "grad_norm": 0.4397006928920746,
      "learning_rate": 2.513888888888889e-05,
      "loss": 0.0032,
      "step": 44750
    },
    {
      "epoch": 0.9946666666666667,
      "grad_norm": 0.10121982544660568,
      "learning_rate": 2.5133333333333336e-05,
      "loss": 0.0025,
      "step": 44760
    },
    {
      "epoch": 0.9948888888888889,
      "grad_norm": 0.15250812470912933,
      "learning_rate": 2.512777777777778e-05,
      "loss": 0.0023,
      "step": 44770
    },
    {
      "epoch": 0.9951111111111111,
      "grad_norm": 0.44169482588768005,
      "learning_rate": 2.5122222222222226e-05,
      "loss": 0.0025,
      "step": 44780
    },
    {
      "epoch": 0.9953333333333333,
      "grad_norm": 0.14996863901615143,
      "learning_rate": 2.5116666666666666e-05,
      "loss": 0.0022,
      "step": 44790
    },
    {
      "epoch": 0.9955555555555555,
      "grad_norm": 0.8809218406677246,
      "learning_rate": 2.5111111111111113e-05,
      "loss": 0.0022,
      "step": 44800
    },
    {
      "epoch": 0.9957777777777778,
      "grad_norm": 0.16110704839229584,
      "learning_rate": 2.5105555555555553e-05,
      "loss": 0.0017,
      "step": 44810
    },
    {
      "epoch": 0.996,
      "grad_norm": 0.2006174921989441,
      "learning_rate": 2.51e-05,
      "loss": 0.0021,
      "step": 44820
    },
    {
      "epoch": 0.9962222222222222,
      "grad_norm": 0.4073326587677002,
      "learning_rate": 2.5094444444444447e-05,
      "loss": 0.0023,
      "step": 44830
    },
    {
      "epoch": 0.9964444444444445,
      "grad_norm": 0.1010047122836113,
      "learning_rate": 2.508888888888889e-05,
      "loss": 0.0025,
      "step": 44840
    },
    {
      "epoch": 0.9966666666666667,
      "grad_norm": 0.055543940514326096,
      "learning_rate": 2.5083333333333338e-05,
      "loss": 0.0023,
      "step": 44850
    },
    {
      "epoch": 0.9968888888888889,
      "grad_norm": 0.11372820287942886,
      "learning_rate": 2.5077777777777778e-05,
      "loss": 0.0017,
      "step": 44860
    },
    {
      "epoch": 0.9971111111111111,
      "grad_norm": 0.08965067565441132,
      "learning_rate": 2.5072222222222225e-05,
      "loss": 0.0033,
      "step": 44870
    },
    {
      "epoch": 0.9973333333333333,
      "grad_norm": 0.21424010396003723,
      "learning_rate": 2.5066666666666665e-05,
      "loss": 0.0027,
      "step": 44880
    },
    {
      "epoch": 0.9975555555555555,
      "grad_norm": 0.3907814621925354,
      "learning_rate": 2.5061111111111112e-05,
      "loss": 0.0024,
      "step": 44890
    },
    {
      "epoch": 0.9977777777777778,
      "grad_norm": 0.3015292286872864,
      "learning_rate": 2.5055555555555555e-05,
      "loss": 0.0018,
      "step": 44900
    },
    {
      "epoch": 0.998,
      "grad_norm": 0.09225790202617645,
      "learning_rate": 2.5050000000000002e-05,
      "loss": 0.0021,
      "step": 44910
    },
    {
      "epoch": 0.9982222222222222,
      "grad_norm": 0.39194256067276,
      "learning_rate": 2.504444444444445e-05,
      "loss": 0.0022,
      "step": 44920
    },
    {
      "epoch": 0.9984444444444445,
      "grad_norm": 0.14521591365337372,
      "learning_rate": 2.503888888888889e-05,
      "loss": 0.0018,
      "step": 44930
    },
    {
      "epoch": 0.9986666666666667,
      "grad_norm": 0.38454651832580566,
      "learning_rate": 2.5033333333333336e-05,
      "loss": 0.0028,
      "step": 44940
    },
    {
      "epoch": 0.9988888888888889,
      "grad_norm": 0.184287428855896,
      "learning_rate": 2.5027777777777777e-05,
      "loss": 0.0022,
      "step": 44950
    },
    {
      "epoch": 0.9991111111111111,
      "grad_norm": 0.1381235122680664,
      "learning_rate": 2.5022222222222224e-05,
      "loss": 0.0025,
      "step": 44960
    },
    {
      "epoch": 0.9993333333333333,
      "grad_norm": 0.5121480822563171,
      "learning_rate": 2.5016666666666667e-05,
      "loss": 0.0033,
      "step": 44970
    },
    {
      "epoch": 0.9995555555555555,
      "grad_norm": 0.1964137852191925,
      "learning_rate": 2.5011111111111114e-05,
      "loss": 0.0017,
      "step": 44980
    },
    {
      "epoch": 0.9997777777777778,
      "grad_norm": 0.0789545550942421,
      "learning_rate": 2.5005555555555554e-05,
      "loss": 0.0043,
      "step": 44990
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.4413757920265198,
      "learning_rate": 2.5e-05,
      "loss": 0.0026,
      "step": 45000
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.0022984810639172792,
      "eval_runtime": 133.5815,
      "eval_samples_per_second": 1497.213,
      "eval_steps_per_second": 37.43,
      "step": 45000
    },
    {
      "epoch": 1.0002222222222221,
      "grad_norm": 0.5176054835319519,
      "learning_rate": 2.4994444444444445e-05,
      "loss": 0.0018,
      "step": 45010
    },
    {
      "epoch": 1.0004444444444445,
      "grad_norm": 0.2407313734292984,
      "learning_rate": 2.498888888888889e-05,
      "loss": 0.0021,
      "step": 45020
    },
    {
      "epoch": 1.0006666666666666,
      "grad_norm": 0.3739192485809326,
      "learning_rate": 2.4983333333333335e-05,
      "loss": 0.0024,
      "step": 45030
    },
    {
      "epoch": 1.000888888888889,
      "grad_norm": 0.33104604482650757,
      "learning_rate": 2.497777777777778e-05,
      "loss": 0.0027,
      "step": 45040
    },
    {
      "epoch": 1.001111111111111,
      "grad_norm": 0.2979651987552643,
      "learning_rate": 2.4972222222222226e-05,
      "loss": 0.0019,
      "step": 45050
    },
    {
      "epoch": 1.0013333333333334,
      "grad_norm": 0.09270210564136505,
      "learning_rate": 2.496666666666667e-05,
      "loss": 0.0025,
      "step": 45060
    },
    {
      "epoch": 1.0015555555555555,
      "grad_norm": 0.07503707706928253,
      "learning_rate": 2.4961111111111113e-05,
      "loss": 0.0028,
      "step": 45070
    },
    {
      "epoch": 1.0017777777777779,
      "grad_norm": 0.09047728031873703,
      "learning_rate": 2.4955555555555556e-05,
      "loss": 0.0025,
      "step": 45080
    },
    {
      "epoch": 1.002,
      "grad_norm": 0.30401402711868286,
      "learning_rate": 2.495e-05,
      "loss": 0.0018,
      "step": 45090
    },
    {
      "epoch": 1.0022222222222221,
      "grad_norm": 0.6746562123298645,
      "learning_rate": 2.4944444444444447e-05,
      "loss": 0.0021,
      "step": 45100
    },
    {
      "epoch": 1.0024444444444445,
      "grad_norm": 0.4451807141304016,
      "learning_rate": 2.493888888888889e-05,
      "loss": 0.0037,
      "step": 45110
    },
    {
      "epoch": 1.0026666666666666,
      "grad_norm": 0.2363061159849167,
      "learning_rate": 2.4933333333333334e-05,
      "loss": 0.003,
      "step": 45120
    },
    {
      "epoch": 1.002888888888889,
      "grad_norm": 0.4277859926223755,
      "learning_rate": 2.4927777777777778e-05,
      "loss": 0.0021,
      "step": 45130
    },
    {
      "epoch": 1.003111111111111,
      "grad_norm": 0.30103665590286255,
      "learning_rate": 2.4922222222222225e-05,
      "loss": 0.002,
      "step": 45140
    },
    {
      "epoch": 1.0033333333333334,
      "grad_norm": 0.046833138912916183,
      "learning_rate": 2.4916666666666668e-05,
      "loss": 0.0021,
      "step": 45150
    },
    {
      "epoch": 1.0035555555555555,
      "grad_norm": 0.42163360118865967,
      "learning_rate": 2.491111111111111e-05,
      "loss": 0.0041,
      "step": 45160
    },
    {
      "epoch": 1.0037777777777779,
      "grad_norm": 0.4066593050956726,
      "learning_rate": 2.490555555555556e-05,
      "loss": 0.0019,
      "step": 45170
    },
    {
      "epoch": 1.004,
      "grad_norm": 0.548825740814209,
      "learning_rate": 2.4900000000000002e-05,
      "loss": 0.0021,
      "step": 45180
    },
    {
      "epoch": 1.0042222222222221,
      "grad_norm": 0.13884282112121582,
      "learning_rate": 2.4894444444444446e-05,
      "loss": 0.0022,
      "step": 45190
    },
    {
      "epoch": 1.0044444444444445,
      "grad_norm": 0.07870043814182281,
      "learning_rate": 2.488888888888889e-05,
      "loss": 0.002,
      "step": 45200
    },
    {
      "epoch": 1.0046666666666666,
      "grad_norm": 0.07341883331537247,
      "learning_rate": 2.4883333333333333e-05,
      "loss": 0.0018,
      "step": 45210
    },
    {
      "epoch": 1.004888888888889,
      "grad_norm": 0.46121636033058167,
      "learning_rate": 2.4877777777777776e-05,
      "loss": 0.003,
      "step": 45220
    },
    {
      "epoch": 1.005111111111111,
      "grad_norm": 0.3648626208305359,
      "learning_rate": 2.4872222222222223e-05,
      "loss": 0.002,
      "step": 45230
    },
    {
      "epoch": 1.0053333333333334,
      "grad_norm": 0.8056733012199402,
      "learning_rate": 2.486666666666667e-05,
      "loss": 0.0025,
      "step": 45240
    },
    {
      "epoch": 1.0055555555555555,
      "grad_norm": 0.29943040013313293,
      "learning_rate": 2.4861111111111114e-05,
      "loss": 0.0021,
      "step": 45250
    },
    {
      "epoch": 1.0057777777777779,
      "grad_norm": 0.4242159426212311,
      "learning_rate": 2.4855555555555557e-05,
      "loss": 0.0024,
      "step": 45260
    },
    {
      "epoch": 1.006,
      "grad_norm": 0.06230949983000755,
      "learning_rate": 2.485e-05,
      "loss": 0.0024,
      "step": 45270
    },
    {
      "epoch": 1.0062222222222221,
      "grad_norm": 0.23189404606819153,
      "learning_rate": 2.4844444444444444e-05,
      "loss": 0.0021,
      "step": 45280
    },
    {
      "epoch": 1.0064444444444445,
      "grad_norm": 0.11221536993980408,
      "learning_rate": 2.4838888888888888e-05,
      "loss": 0.0034,
      "step": 45290
    },
    {
      "epoch": 1.0066666666666666,
      "grad_norm": 0.4512443542480469,
      "learning_rate": 2.4833333333333335e-05,
      "loss": 0.0027,
      "step": 45300
    },
    {
      "epoch": 1.006888888888889,
      "grad_norm": 0.07698936015367508,
      "learning_rate": 2.482777777777778e-05,
      "loss": 0.0019,
      "step": 45310
    },
    {
      "epoch": 1.007111111111111,
      "grad_norm": 0.10328011959791183,
      "learning_rate": 2.4822222222222225e-05,
      "loss": 0.002,
      "step": 45320
    },
    {
      "epoch": 1.0073333333333334,
      "grad_norm": 0.2174336463212967,
      "learning_rate": 2.481666666666667e-05,
      "loss": 0.003,
      "step": 45330
    },
    {
      "epoch": 1.0075555555555555,
      "grad_norm": 0.1735800951719284,
      "learning_rate": 2.4811111111111113e-05,
      "loss": 0.0018,
      "step": 45340
    },
    {
      "epoch": 1.0077777777777779,
      "grad_norm": 0.22993914783000946,
      "learning_rate": 2.4805555555555556e-05,
      "loss": 0.0019,
      "step": 45350
    },
    {
      "epoch": 1.008,
      "grad_norm": 0.4114433825016022,
      "learning_rate": 2.48e-05,
      "loss": 0.0021,
      "step": 45360
    },
    {
      "epoch": 1.0082222222222221,
      "grad_norm": 0.2723665237426758,
      "learning_rate": 2.4794444444444447e-05,
      "loss": 0.0023,
      "step": 45370
    },
    {
      "epoch": 1.0084444444444445,
      "grad_norm": 0.25974857807159424,
      "learning_rate": 2.478888888888889e-05,
      "loss": 0.0024,
      "step": 45380
    },
    {
      "epoch": 1.0086666666666666,
      "grad_norm": 0.4221127927303314,
      "learning_rate": 2.4783333333333334e-05,
      "loss": 0.0029,
      "step": 45390
    },
    {
      "epoch": 1.008888888888889,
      "grad_norm": 0.27353036403656006,
      "learning_rate": 2.477777777777778e-05,
      "loss": 0.0017,
      "step": 45400
    },
    {
      "epoch": 1.009111111111111,
      "grad_norm": 0.07825837284326553,
      "learning_rate": 2.4772222222222224e-05,
      "loss": 0.0018,
      "step": 45410
    },
    {
      "epoch": 1.0093333333333334,
      "grad_norm": 0.16268862783908844,
      "learning_rate": 2.4766666666666668e-05,
      "loss": 0.0035,
      "step": 45420
    },
    {
      "epoch": 1.0095555555555555,
      "grad_norm": 0.2364901453256607,
      "learning_rate": 2.476111111111111e-05,
      "loss": 0.0024,
      "step": 45430
    },
    {
      "epoch": 1.0097777777777779,
      "grad_norm": 0.33930787444114685,
      "learning_rate": 2.475555555555556e-05,
      "loss": 0.0017,
      "step": 45440
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.6094174981117249,
      "learning_rate": 2.4750000000000002e-05,
      "loss": 0.0018,
      "step": 45450
    },
    {
      "epoch": 1.0102222222222221,
      "grad_norm": 0.10880541056394577,
      "learning_rate": 2.4744444444444445e-05,
      "loss": 0.003,
      "step": 45460
    },
    {
      "epoch": 1.0104444444444445,
      "grad_norm": 0.19189415872097015,
      "learning_rate": 2.473888888888889e-05,
      "loss": 0.0034,
      "step": 45470
    },
    {
      "epoch": 1.0106666666666666,
      "grad_norm": 0.26058298349380493,
      "learning_rate": 2.4733333333333333e-05,
      "loss": 0.0024,
      "step": 45480
    },
    {
      "epoch": 1.010888888888889,
      "grad_norm": 0.1744745969772339,
      "learning_rate": 2.472777777777778e-05,
      "loss": 0.0021,
      "step": 45490
    },
    {
      "epoch": 1.011111111111111,
      "grad_norm": 0.6026159524917603,
      "learning_rate": 2.4722222222222223e-05,
      "loss": 0.0023,
      "step": 45500
    },
    {
      "epoch": 1.0113333333333334,
      "grad_norm": 0.08843144029378891,
      "learning_rate": 2.471666666666667e-05,
      "loss": 0.0018,
      "step": 45510
    },
    {
      "epoch": 1.0115555555555555,
      "grad_norm": 0.2410079687833786,
      "learning_rate": 2.4711111111111114e-05,
      "loss": 0.0017,
      "step": 45520
    },
    {
      "epoch": 1.0117777777777779,
      "grad_norm": 0.14274291694164276,
      "learning_rate": 2.4705555555555557e-05,
      "loss": 0.0019,
      "step": 45530
    },
    {
      "epoch": 1.012,
      "grad_norm": 0.15536387264728546,
      "learning_rate": 2.47e-05,
      "loss": 0.0019,
      "step": 45540
    },
    {
      "epoch": 1.0122222222222221,
      "grad_norm": 0.18177074193954468,
      "learning_rate": 2.4694444444444444e-05,
      "loss": 0.0021,
      "step": 45550
    },
    {
      "epoch": 1.0124444444444445,
      "grad_norm": 0.20711734890937805,
      "learning_rate": 2.4688888888888888e-05,
      "loss": 0.0022,
      "step": 45560
    },
    {
      "epoch": 1.0126666666666666,
      "grad_norm": 0.10162904858589172,
      "learning_rate": 2.4683333333333335e-05,
      "loss": 0.0025,
      "step": 45570
    },
    {
      "epoch": 1.012888888888889,
      "grad_norm": 0.20164023339748383,
      "learning_rate": 2.467777777777778e-05,
      "loss": 0.0023,
      "step": 45580
    },
    {
      "epoch": 1.013111111111111,
      "grad_norm": 0.26993700861930847,
      "learning_rate": 2.4672222222222225e-05,
      "loss": 0.0024,
      "step": 45590
    },
    {
      "epoch": 1.0133333333333334,
      "grad_norm": 0.7246323227882385,
      "learning_rate": 2.466666666666667e-05,
      "loss": 0.0029,
      "step": 45600
    },
    {
      "epoch": 1.0135555555555555,
      "grad_norm": 0.08831422030925751,
      "learning_rate": 2.4661111111111112e-05,
      "loss": 0.0036,
      "step": 45610
    },
    {
      "epoch": 1.0137777777777779,
      "grad_norm": 0.22833622992038727,
      "learning_rate": 2.4655555555555556e-05,
      "loss": 0.002,
      "step": 45620
    },
    {
      "epoch": 1.014,
      "grad_norm": 0.501474916934967,
      "learning_rate": 2.465e-05,
      "loss": 0.0035,
      "step": 45630
    },
    {
      "epoch": 1.0142222222222221,
      "grad_norm": 0.4018220901489258,
      "learning_rate": 2.4644444444444446e-05,
      "loss": 0.0031,
      "step": 45640
    },
    {
      "epoch": 1.0144444444444445,
      "grad_norm": 0.20222392678260803,
      "learning_rate": 2.463888888888889e-05,
      "loss": 0.0026,
      "step": 45650
    },
    {
      "epoch": 1.0146666666666666,
      "grad_norm": 0.2911561131477356,
      "learning_rate": 2.4633333333333334e-05,
      "loss": 0.0019,
      "step": 45660
    },
    {
      "epoch": 1.014888888888889,
      "grad_norm": 0.14261728525161743,
      "learning_rate": 2.462777777777778e-05,
      "loss": 0.002,
      "step": 45670
    },
    {
      "epoch": 1.015111111111111,
      "grad_norm": 0.18245358765125275,
      "learning_rate": 2.4622222222222224e-05,
      "loss": 0.002,
      "step": 45680
    },
    {
      "epoch": 1.0153333333333334,
      "grad_norm": 0.2141578495502472,
      "learning_rate": 2.4616666666666668e-05,
      "loss": 0.0022,
      "step": 45690
    },
    {
      "epoch": 1.0155555555555555,
      "grad_norm": 0.13890071213245392,
      "learning_rate": 2.461111111111111e-05,
      "loss": 0.0022,
      "step": 45700
    },
    {
      "epoch": 1.0157777777777777,
      "grad_norm": 0.22416262328624725,
      "learning_rate": 2.4605555555555558e-05,
      "loss": 0.0026,
      "step": 45710
    },
    {
      "epoch": 1.016,
      "grad_norm": 0.18707993626594543,
      "learning_rate": 2.46e-05,
      "loss": 0.0024,
      "step": 45720
    },
    {
      "epoch": 1.0162222222222221,
      "grad_norm": 0.30540111660957336,
      "learning_rate": 2.4594444444444445e-05,
      "loss": 0.0022,
      "step": 45730
    },
    {
      "epoch": 1.0164444444444445,
      "grad_norm": 0.4747166931629181,
      "learning_rate": 2.458888888888889e-05,
      "loss": 0.0025,
      "step": 45740
    },
    {
      "epoch": 1.0166666666666666,
      "grad_norm": 0.21450239419937134,
      "learning_rate": 2.4583333333333332e-05,
      "loss": 0.0018,
      "step": 45750
    },
    {
      "epoch": 1.016888888888889,
      "grad_norm": 0.3632642924785614,
      "learning_rate": 2.457777777777778e-05,
      "loss": 0.0035,
      "step": 45760
    },
    {
      "epoch": 1.017111111111111,
      "grad_norm": 0.4187201261520386,
      "learning_rate": 2.4572222222222223e-05,
      "loss": 0.0026,
      "step": 45770
    },
    {
      "epoch": 1.0173333333333334,
      "grad_norm": 0.5629763007164001,
      "learning_rate": 2.456666666666667e-05,
      "loss": 0.0019,
      "step": 45780
    },
    {
      "epoch": 1.0175555555555555,
      "grad_norm": 0.14088281989097595,
      "learning_rate": 2.4561111111111113e-05,
      "loss": 0.0022,
      "step": 45790
    },
    {
      "epoch": 1.0177777777777777,
      "grad_norm": 0.14368823170661926,
      "learning_rate": 2.4555555555555557e-05,
      "loss": 0.0029,
      "step": 45800
    },
    {
      "epoch": 1.018,
      "grad_norm": 0.09835714101791382,
      "learning_rate": 2.455e-05,
      "loss": 0.0021,
      "step": 45810
    },
    {
      "epoch": 1.0182222222222221,
      "grad_norm": 0.16234175860881805,
      "learning_rate": 2.4544444444444444e-05,
      "loss": 0.0027,
      "step": 45820
    },
    {
      "epoch": 1.0184444444444445,
      "grad_norm": 0.07821860164403915,
      "learning_rate": 2.4538888888888888e-05,
      "loss": 0.0034,
      "step": 45830
    },
    {
      "epoch": 1.0186666666666666,
      "grad_norm": 0.07355852425098419,
      "learning_rate": 2.4533333333333334e-05,
      "loss": 0.0019,
      "step": 45840
    },
    {
      "epoch": 1.018888888888889,
      "grad_norm": 0.45870670676231384,
      "learning_rate": 2.452777777777778e-05,
      "loss": 0.0023,
      "step": 45850
    },
    {
      "epoch": 1.019111111111111,
      "grad_norm": 0.12058176845312119,
      "learning_rate": 2.4522222222222225e-05,
      "loss": 0.0025,
      "step": 45860
    },
    {
      "epoch": 1.0193333333333334,
      "grad_norm": 0.3320566713809967,
      "learning_rate": 2.451666666666667e-05,
      "loss": 0.0027,
      "step": 45870
    },
    {
      "epoch": 1.0195555555555555,
      "grad_norm": 0.08661606907844543,
      "learning_rate": 2.4511111111111112e-05,
      "loss": 0.002,
      "step": 45880
    },
    {
      "epoch": 1.0197777777777777,
      "grad_norm": 0.25056055188179016,
      "learning_rate": 2.4505555555555556e-05,
      "loss": 0.0028,
      "step": 45890
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.11942040920257568,
      "learning_rate": 2.45e-05,
      "loss": 0.0024,
      "step": 45900
    },
    {
      "epoch": 1.0202222222222221,
      "grad_norm": 0.07251273840665817,
      "learning_rate": 2.4494444444444446e-05,
      "loss": 0.0025,
      "step": 45910
    },
    {
      "epoch": 1.0204444444444445,
      "grad_norm": 0.23914921283721924,
      "learning_rate": 2.448888888888889e-05,
      "loss": 0.0019,
      "step": 45920
    },
    {
      "epoch": 1.0206666666666666,
      "grad_norm": 0.4352818429470062,
      "learning_rate": 2.4483333333333333e-05,
      "loss": 0.0026,
      "step": 45930
    },
    {
      "epoch": 1.020888888888889,
      "grad_norm": 0.26247438788414,
      "learning_rate": 2.447777777777778e-05,
      "loss": 0.0019,
      "step": 45940
    },
    {
      "epoch": 1.021111111111111,
      "grad_norm": 0.22840279340744019,
      "learning_rate": 2.4472222222222224e-05,
      "loss": 0.002,
      "step": 45950
    },
    {
      "epoch": 1.0213333333333334,
      "grad_norm": 0.10977856069803238,
      "learning_rate": 2.4466666666666667e-05,
      "loss": 0.0026,
      "step": 45960
    },
    {
      "epoch": 1.0215555555555556,
      "grad_norm": 0.1497730165719986,
      "learning_rate": 2.446111111111111e-05,
      "loss": 0.0019,
      "step": 45970
    },
    {
      "epoch": 1.0217777777777777,
      "grad_norm": 0.0651741698384285,
      "learning_rate": 2.4455555555555558e-05,
      "loss": 0.0033,
      "step": 45980
    },
    {
      "epoch": 1.022,
      "grad_norm": 0.2226680964231491,
      "learning_rate": 2.445e-05,
      "loss": 0.0018,
      "step": 45990
    },
    {
      "epoch": 1.0222222222222221,
      "grad_norm": 0.1356498897075653,
      "learning_rate": 2.4444444444444445e-05,
      "loss": 0.0022,
      "step": 46000
    },
    {
      "epoch": 1.0224444444444445,
      "grad_norm": 0.2892250418663025,
      "learning_rate": 2.443888888888889e-05,
      "loss": 0.0022,
      "step": 46010
    },
    {
      "epoch": 1.0226666666666666,
      "grad_norm": 0.1890636682510376,
      "learning_rate": 2.4433333333333335e-05,
      "loss": 0.0029,
      "step": 46020
    },
    {
      "epoch": 1.022888888888889,
      "grad_norm": 0.46040865778923035,
      "learning_rate": 2.442777777777778e-05,
      "loss": 0.0022,
      "step": 46030
    },
    {
      "epoch": 1.023111111111111,
      "grad_norm": 0.5089225172996521,
      "learning_rate": 2.4422222222222223e-05,
      "loss": 0.0019,
      "step": 46040
    },
    {
      "epoch": 1.0233333333333334,
      "grad_norm": 0.2908087372779846,
      "learning_rate": 2.441666666666667e-05,
      "loss": 0.0018,
      "step": 46050
    },
    {
      "epoch": 1.0235555555555556,
      "grad_norm": 0.3928709924221039,
      "learning_rate": 2.4411111111111113e-05,
      "loss": 0.0023,
      "step": 46060
    },
    {
      "epoch": 1.0237777777777777,
      "grad_norm": 0.2923109829425812,
      "learning_rate": 2.4405555555555557e-05,
      "loss": 0.0019,
      "step": 46070
    },
    {
      "epoch": 1.024,
      "grad_norm": 0.06211281195282936,
      "learning_rate": 2.44e-05,
      "loss": 0.0026,
      "step": 46080
    },
    {
      "epoch": 1.0242222222222221,
      "grad_norm": 0.08934742957353592,
      "learning_rate": 2.4394444444444444e-05,
      "loss": 0.0037,
      "step": 46090
    },
    {
      "epoch": 1.0244444444444445,
      "grad_norm": 0.20781981945037842,
      "learning_rate": 2.4388888888888887e-05,
      "loss": 0.0028,
      "step": 46100
    },
    {
      "epoch": 1.0246666666666666,
      "grad_norm": 0.34151691198349,
      "learning_rate": 2.4383333333333334e-05,
      "loss": 0.002,
      "step": 46110
    },
    {
      "epoch": 1.024888888888889,
      "grad_norm": 0.12651033699512482,
      "learning_rate": 2.437777777777778e-05,
      "loss": 0.0024,
      "step": 46120
    },
    {
      "epoch": 1.025111111111111,
      "grad_norm": 0.10353144258260727,
      "learning_rate": 2.4372222222222225e-05,
      "loss": 0.0018,
      "step": 46130
    },
    {
      "epoch": 1.0253333333333334,
      "grad_norm": 0.19358019530773163,
      "learning_rate": 2.4366666666666668e-05,
      "loss": 0.0025,
      "step": 46140
    },
    {
      "epoch": 1.0255555555555556,
      "grad_norm": 0.40858373045921326,
      "learning_rate": 2.4361111111111112e-05,
      "loss": 0.0027,
      "step": 46150
    },
    {
      "epoch": 1.0257777777777777,
      "grad_norm": 0.5750057697296143,
      "learning_rate": 2.4355555555555555e-05,
      "loss": 0.0024,
      "step": 46160
    },
    {
      "epoch": 1.026,
      "grad_norm": 0.17801533639431,
      "learning_rate": 2.435e-05,
      "loss": 0.002,
      "step": 46170
    },
    {
      "epoch": 1.0262222222222221,
      "grad_norm": 0.6377955079078674,
      "learning_rate": 2.4344444444444446e-05,
      "loss": 0.0025,
      "step": 46180
    },
    {
      "epoch": 1.0264444444444445,
      "grad_norm": 0.0762801319360733,
      "learning_rate": 2.433888888888889e-05,
      "loss": 0.0027,
      "step": 46190
    },
    {
      "epoch": 1.0266666666666666,
      "grad_norm": 0.4288889765739441,
      "learning_rate": 2.4333333333333336e-05,
      "loss": 0.0022,
      "step": 46200
    },
    {
      "epoch": 1.026888888888889,
      "grad_norm": 0.15226979553699493,
      "learning_rate": 2.432777777777778e-05,
      "loss": 0.002,
      "step": 46210
    },
    {
      "epoch": 1.027111111111111,
      "grad_norm": 0.11793316900730133,
      "learning_rate": 2.4322222222222224e-05,
      "loss": 0.0024,
      "step": 46220
    },
    {
      "epoch": 1.0273333333333334,
      "grad_norm": 0.32591190934181213,
      "learning_rate": 2.4316666666666667e-05,
      "loss": 0.0031,
      "step": 46230
    },
    {
      "epoch": 1.0275555555555556,
      "grad_norm": 0.116535484790802,
      "learning_rate": 2.431111111111111e-05,
      "loss": 0.0017,
      "step": 46240
    },
    {
      "epoch": 1.0277777777777777,
      "grad_norm": 0.1290186196565628,
      "learning_rate": 2.4305555555555558e-05,
      "loss": 0.0021,
      "step": 46250
    },
    {
      "epoch": 1.028,
      "grad_norm": 0.5186728835105896,
      "learning_rate": 2.43e-05,
      "loss": 0.0016,
      "step": 46260
    },
    {
      "epoch": 1.0282222222222221,
      "grad_norm": 0.2811976969242096,
      "learning_rate": 2.4294444444444445e-05,
      "loss": 0.0017,
      "step": 46270
    },
    {
      "epoch": 1.0284444444444445,
      "grad_norm": 0.12518495321273804,
      "learning_rate": 2.4288888888888888e-05,
      "loss": 0.0029,
      "step": 46280
    },
    {
      "epoch": 1.0286666666666666,
      "grad_norm": 0.4191451072692871,
      "learning_rate": 2.4283333333333335e-05,
      "loss": 0.003,
      "step": 46290
    },
    {
      "epoch": 1.028888888888889,
      "grad_norm": 0.2432042509317398,
      "learning_rate": 2.427777777777778e-05,
      "loss": 0.002,
      "step": 46300
    },
    {
      "epoch": 1.029111111111111,
      "grad_norm": 0.10734815150499344,
      "learning_rate": 2.4272222222222222e-05,
      "loss": 0.0031,
      "step": 46310
    },
    {
      "epoch": 1.0293333333333334,
      "grad_norm": 0.3152194917201996,
      "learning_rate": 2.426666666666667e-05,
      "loss": 0.0026,
      "step": 46320
    },
    {
      "epoch": 1.0295555555555556,
      "grad_norm": 0.1257408857345581,
      "learning_rate": 2.4261111111111113e-05,
      "loss": 0.0018,
      "step": 46330
    },
    {
      "epoch": 1.0297777777777777,
      "grad_norm": 0.1860101819038391,
      "learning_rate": 2.4255555555555556e-05,
      "loss": 0.0017,
      "step": 46340
    },
    {
      "epoch": 1.03,
      "grad_norm": 0.3294878602027893,
      "learning_rate": 2.425e-05,
      "loss": 0.0018,
      "step": 46350
    },
    {
      "epoch": 1.0302222222222222,
      "grad_norm": 0.13877592980861664,
      "learning_rate": 2.4244444444444443e-05,
      "loss": 0.0018,
      "step": 46360
    },
    {
      "epoch": 1.0304444444444445,
      "grad_norm": 0.22724401950836182,
      "learning_rate": 2.423888888888889e-05,
      "loss": 0.0027,
      "step": 46370
    },
    {
      "epoch": 1.0306666666666666,
      "grad_norm": 0.14142325520515442,
      "learning_rate": 2.4233333333333337e-05,
      "loss": 0.0026,
      "step": 46380
    },
    {
      "epoch": 1.030888888888889,
      "grad_norm": 0.22102971374988556,
      "learning_rate": 2.422777777777778e-05,
      "loss": 0.002,
      "step": 46390
    },
    {
      "epoch": 1.031111111111111,
      "grad_norm": 0.11033828556537628,
      "learning_rate": 2.4222222222222224e-05,
      "loss": 0.0024,
      "step": 46400
    },
    {
      "epoch": 1.0313333333333334,
      "grad_norm": 0.08026795089244843,
      "learning_rate": 2.4216666666666668e-05,
      "loss": 0.0017,
      "step": 46410
    },
    {
      "epoch": 1.0315555555555556,
      "grad_norm": 0.2617436647415161,
      "learning_rate": 2.421111111111111e-05,
      "loss": 0.0028,
      "step": 46420
    },
    {
      "epoch": 1.0317777777777777,
      "grad_norm": 0.33081841468811035,
      "learning_rate": 2.4205555555555555e-05,
      "loss": 0.0027,
      "step": 46430
    },
    {
      "epoch": 1.032,
      "grad_norm": 0.18159304559230804,
      "learning_rate": 2.4200000000000002e-05,
      "loss": 0.0018,
      "step": 46440
    },
    {
      "epoch": 1.0322222222222222,
      "grad_norm": 0.1278008073568344,
      "learning_rate": 2.4194444444444446e-05,
      "loss": 0.0021,
      "step": 46450
    },
    {
      "epoch": 1.0324444444444445,
      "grad_norm": 0.4222824275493622,
      "learning_rate": 2.418888888888889e-05,
      "loss": 0.0024,
      "step": 46460
    },
    {
      "epoch": 1.0326666666666666,
      "grad_norm": 0.3502603769302368,
      "learning_rate": 2.4183333333333336e-05,
      "loss": 0.0018,
      "step": 46470
    },
    {
      "epoch": 1.032888888888889,
      "grad_norm": 0.08403437584638596,
      "learning_rate": 2.417777777777778e-05,
      "loss": 0.0023,
      "step": 46480
    },
    {
      "epoch": 1.033111111111111,
      "grad_norm": 0.3650707006454468,
      "learning_rate": 2.4172222222222223e-05,
      "loss": 0.0019,
      "step": 46490
    },
    {
      "epoch": 1.0333333333333334,
      "grad_norm": 0.6552190184593201,
      "learning_rate": 2.4166666666666667e-05,
      "loss": 0.0032,
      "step": 46500
    },
    {
      "epoch": 1.0335555555555556,
      "grad_norm": 0.22862471640110016,
      "learning_rate": 2.4161111111111114e-05,
      "loss": 0.0018,
      "step": 46510
    },
    {
      "epoch": 1.0337777777777777,
      "grad_norm": 0.18539801239967346,
      "learning_rate": 2.4155555555555557e-05,
      "loss": 0.002,
      "step": 46520
    },
    {
      "epoch": 1.034,
      "grad_norm": 0.2090347856283188,
      "learning_rate": 2.415e-05,
      "loss": 0.0024,
      "step": 46530
    },
    {
      "epoch": 1.0342222222222222,
      "grad_norm": 0.1351282000541687,
      "learning_rate": 2.4144444444444444e-05,
      "loss": 0.0024,
      "step": 46540
    },
    {
      "epoch": 1.0344444444444445,
      "grad_norm": 0.564387321472168,
      "learning_rate": 2.4138888888888888e-05,
      "loss": 0.0021,
      "step": 46550
    },
    {
      "epoch": 1.0346666666666666,
      "grad_norm": 0.10693182796239853,
      "learning_rate": 2.4133333333333335e-05,
      "loss": 0.0019,
      "step": 46560
    },
    {
      "epoch": 1.034888888888889,
      "grad_norm": 0.27903783321380615,
      "learning_rate": 2.412777777777778e-05,
      "loss": 0.0034,
      "step": 46570
    },
    {
      "epoch": 1.035111111111111,
      "grad_norm": 0.1274280995130539,
      "learning_rate": 2.4122222222222225e-05,
      "loss": 0.0026,
      "step": 46580
    },
    {
      "epoch": 1.0353333333333334,
      "grad_norm": 0.09299901127815247,
      "learning_rate": 2.411666666666667e-05,
      "loss": 0.0019,
      "step": 46590
    },
    {
      "epoch": 1.0355555555555556,
      "grad_norm": 0.2618110179901123,
      "learning_rate": 2.4111111111111113e-05,
      "loss": 0.003,
      "step": 46600
    },
    {
      "epoch": 1.0357777777777777,
      "grad_norm": 0.5759573578834534,
      "learning_rate": 2.4105555555555556e-05,
      "loss": 0.0018,
      "step": 46610
    },
    {
      "epoch": 1.036,
      "grad_norm": 0.19380758702754974,
      "learning_rate": 2.41e-05,
      "loss": 0.002,
      "step": 46620
    },
    {
      "epoch": 1.0362222222222222,
      "grad_norm": 0.11821065843105316,
      "learning_rate": 2.4094444444444443e-05,
      "loss": 0.0021,
      "step": 46630
    },
    {
      "epoch": 1.0364444444444445,
      "grad_norm": 0.21959815919399261,
      "learning_rate": 2.408888888888889e-05,
      "loss": 0.0031,
      "step": 46640
    },
    {
      "epoch": 1.0366666666666666,
      "grad_norm": 0.3292107880115509,
      "learning_rate": 2.4083333333333337e-05,
      "loss": 0.0024,
      "step": 46650
    },
    {
      "epoch": 1.036888888888889,
      "grad_norm": 0.2704227566719055,
      "learning_rate": 2.407777777777778e-05,
      "loss": 0.0021,
      "step": 46660
    },
    {
      "epoch": 1.037111111111111,
      "grad_norm": 0.35690274834632874,
      "learning_rate": 2.4072222222222224e-05,
      "loss": 0.0024,
      "step": 46670
    },
    {
      "epoch": 1.0373333333333334,
      "grad_norm": 0.2984517216682434,
      "learning_rate": 2.4066666666666668e-05,
      "loss": 0.0019,
      "step": 46680
    },
    {
      "epoch": 1.0375555555555556,
      "grad_norm": 0.4063844680786133,
      "learning_rate": 2.406111111111111e-05,
      "loss": 0.0019,
      "step": 46690
    },
    {
      "epoch": 1.0377777777777777,
      "grad_norm": 0.22966784238815308,
      "learning_rate": 2.4055555555555555e-05,
      "loss": 0.0022,
      "step": 46700
    },
    {
      "epoch": 1.038,
      "grad_norm": 0.5723633766174316,
      "learning_rate": 2.4050000000000002e-05,
      "loss": 0.0025,
      "step": 46710
    },
    {
      "epoch": 1.0382222222222222,
      "grad_norm": 0.057756733149290085,
      "learning_rate": 2.4044444444444445e-05,
      "loss": 0.0022,
      "step": 46720
    },
    {
      "epoch": 1.0384444444444445,
      "grad_norm": 0.38657787442207336,
      "learning_rate": 2.4038888888888892e-05,
      "loss": 0.0026,
      "step": 46730
    },
    {
      "epoch": 1.0386666666666666,
      "grad_norm": 0.5293309092521667,
      "learning_rate": 2.4033333333333336e-05,
      "loss": 0.0018,
      "step": 46740
    },
    {
      "epoch": 1.038888888888889,
      "grad_norm": 0.5097622871398926,
      "learning_rate": 2.402777777777778e-05,
      "loss": 0.0018,
      "step": 46750
    },
    {
      "epoch": 1.039111111111111,
      "grad_norm": 0.1094411164522171,
      "learning_rate": 2.4022222222222223e-05,
      "loss": 0.0026,
      "step": 46760
    },
    {
      "epoch": 1.0393333333333334,
      "grad_norm": 0.39718928933143616,
      "learning_rate": 2.4016666666666667e-05,
      "loss": 0.0017,
      "step": 46770
    },
    {
      "epoch": 1.0395555555555556,
      "grad_norm": 0.24127209186553955,
      "learning_rate": 2.4011111111111113e-05,
      "loss": 0.0017,
      "step": 46780
    },
    {
      "epoch": 1.0397777777777777,
      "grad_norm": 0.5884813070297241,
      "learning_rate": 2.4005555555555557e-05,
      "loss": 0.0027,
      "step": 46790
    },
    {
      "epoch": 1.04,
      "grad_norm": 0.14163430035114288,
      "learning_rate": 2.4e-05,
      "loss": 0.0019,
      "step": 46800
    },
    {
      "epoch": 1.0402222222222222,
      "grad_norm": 0.43096041679382324,
      "learning_rate": 2.3994444444444444e-05,
      "loss": 0.0019,
      "step": 46810
    },
    {
      "epoch": 1.0404444444444445,
      "grad_norm": 0.13947798311710358,
      "learning_rate": 2.398888888888889e-05,
      "loss": 0.0025,
      "step": 46820
    },
    {
      "epoch": 1.0406666666666666,
      "grad_norm": 0.20274454355239868,
      "learning_rate": 2.3983333333333335e-05,
      "loss": 0.0028,
      "step": 46830
    },
    {
      "epoch": 1.040888888888889,
      "grad_norm": 0.10895609110593796,
      "learning_rate": 2.3977777777777778e-05,
      "loss": 0.0017,
      "step": 46840
    },
    {
      "epoch": 1.041111111111111,
      "grad_norm": 0.38682031631469727,
      "learning_rate": 2.3972222222222225e-05,
      "loss": 0.0017,
      "step": 46850
    },
    {
      "epoch": 1.0413333333333332,
      "grad_norm": 0.5428717732429504,
      "learning_rate": 2.396666666666667e-05,
      "loss": 0.0017,
      "step": 46860
    },
    {
      "epoch": 1.0415555555555556,
      "grad_norm": 0.500592827796936,
      "learning_rate": 2.3961111111111112e-05,
      "loss": 0.0018,
      "step": 46870
    },
    {
      "epoch": 1.0417777777777777,
      "grad_norm": 0.6647689342498779,
      "learning_rate": 2.3955555555555556e-05,
      "loss": 0.002,
      "step": 46880
    },
    {
      "epoch": 1.042,
      "grad_norm": 0.5743712782859802,
      "learning_rate": 2.395e-05,
      "loss": 0.0026,
      "step": 46890
    },
    {
      "epoch": 1.0422222222222222,
      "grad_norm": 0.10797931253910065,
      "learning_rate": 2.3944444444444443e-05,
      "loss": 0.0019,
      "step": 46900
    },
    {
      "epoch": 1.0424444444444445,
      "grad_norm": 0.1031440943479538,
      "learning_rate": 2.393888888888889e-05,
      "loss": 0.0019,
      "step": 46910
    },
    {
      "epoch": 1.0426666666666666,
      "grad_norm": 0.16250109672546387,
      "learning_rate": 2.3933333333333337e-05,
      "loss": 0.0031,
      "step": 46920
    },
    {
      "epoch": 1.042888888888889,
      "grad_norm": 0.2151678204536438,
      "learning_rate": 2.392777777777778e-05,
      "loss": 0.0017,
      "step": 46930
    },
    {
      "epoch": 1.043111111111111,
      "grad_norm": 0.09953168034553528,
      "learning_rate": 2.3922222222222224e-05,
      "loss": 0.0019,
      "step": 46940
    },
    {
      "epoch": 1.0433333333333334,
      "grad_norm": 0.3251674175262451,
      "learning_rate": 2.3916666666666668e-05,
      "loss": 0.0017,
      "step": 46950
    },
    {
      "epoch": 1.0435555555555556,
      "grad_norm": 0.2748689353466034,
      "learning_rate": 2.391111111111111e-05,
      "loss": 0.0027,
      "step": 46960
    },
    {
      "epoch": 1.0437777777777777,
      "grad_norm": 0.328346848487854,
      "learning_rate": 2.3905555555555555e-05,
      "loss": 0.0021,
      "step": 46970
    },
    {
      "epoch": 1.044,
      "grad_norm": 0.30240151286125183,
      "learning_rate": 2.39e-05,
      "loss": 0.0025,
      "step": 46980
    },
    {
      "epoch": 1.0442222222222222,
      "grad_norm": 0.2065623551607132,
      "learning_rate": 2.3894444444444445e-05,
      "loss": 0.0017,
      "step": 46990
    },
    {
      "epoch": 1.0444444444444445,
      "grad_norm": 0.44047075510025024,
      "learning_rate": 2.3888888888888892e-05,
      "loss": 0.0021,
      "step": 47000
    },
    {
      "epoch": 1.0446666666666666,
      "grad_norm": 0.1478414237499237,
      "learning_rate": 2.3883333333333336e-05,
      "loss": 0.0027,
      "step": 47010
    },
    {
      "epoch": 1.044888888888889,
      "grad_norm": 0.07941897213459015,
      "learning_rate": 2.387777777777778e-05,
      "loss": 0.0023,
      "step": 47020
    },
    {
      "epoch": 1.045111111111111,
      "grad_norm": 0.1880428045988083,
      "learning_rate": 2.3872222222222223e-05,
      "loss": 0.0026,
      "step": 47030
    },
    {
      "epoch": 1.0453333333333332,
      "grad_norm": 0.40838149189949036,
      "learning_rate": 2.3866666666666666e-05,
      "loss": 0.0023,
      "step": 47040
    },
    {
      "epoch": 1.0455555555555556,
      "grad_norm": 0.060079749673604965,
      "learning_rate": 2.3861111111111113e-05,
      "loss": 0.0018,
      "step": 47050
    },
    {
      "epoch": 1.0457777777777777,
      "grad_norm": 0.44175398349761963,
      "learning_rate": 2.3855555555555557e-05,
      "loss": 0.002,
      "step": 47060
    },
    {
      "epoch": 1.046,
      "grad_norm": 0.2718523442745209,
      "learning_rate": 2.385e-05,
      "loss": 0.0027,
      "step": 47070
    },
    {
      "epoch": 1.0462222222222222,
      "grad_norm": 0.13058345019817352,
      "learning_rate": 2.3844444444444444e-05,
      "loss": 0.0021,
      "step": 47080
    },
    {
      "epoch": 1.0464444444444445,
      "grad_norm": 0.17329734563827515,
      "learning_rate": 2.383888888888889e-05,
      "loss": 0.0025,
      "step": 47090
    },
    {
      "epoch": 1.0466666666666666,
      "grad_norm": 0.17009854316711426,
      "learning_rate": 2.3833333333333334e-05,
      "loss": 0.0025,
      "step": 47100
    },
    {
      "epoch": 1.046888888888889,
      "grad_norm": 0.05417605862021446,
      "learning_rate": 2.3827777777777778e-05,
      "loss": 0.0021,
      "step": 47110
    },
    {
      "epoch": 1.047111111111111,
      "grad_norm": 0.07252895832061768,
      "learning_rate": 2.3822222222222225e-05,
      "loss": 0.0021,
      "step": 47120
    },
    {
      "epoch": 1.0473333333333332,
      "grad_norm": 0.1789182424545288,
      "learning_rate": 2.381666666666667e-05,
      "loss": 0.002,
      "step": 47130
    },
    {
      "epoch": 1.0475555555555556,
      "grad_norm": 0.4226798713207245,
      "learning_rate": 2.3811111111111112e-05,
      "loss": 0.0019,
      "step": 47140
    },
    {
      "epoch": 1.0477777777777777,
      "grad_norm": 0.32255223393440247,
      "learning_rate": 2.3805555555555556e-05,
      "loss": 0.0021,
      "step": 47150
    },
    {
      "epoch": 1.048,
      "grad_norm": 0.14913541078567505,
      "learning_rate": 2.38e-05,
      "loss": 0.002,
      "step": 47160
    },
    {
      "epoch": 1.0482222222222222,
      "grad_norm": 0.30455753207206726,
      "learning_rate": 2.3794444444444443e-05,
      "loss": 0.0026,
      "step": 47170
    },
    {
      "epoch": 1.0484444444444445,
      "grad_norm": 0.055980827659368515,
      "learning_rate": 2.378888888888889e-05,
      "loss": 0.0019,
      "step": 47180
    },
    {
      "epoch": 1.0486666666666666,
      "grad_norm": 0.17281267046928406,
      "learning_rate": 2.3783333333333337e-05,
      "loss": 0.0019,
      "step": 47190
    },
    {
      "epoch": 1.048888888888889,
      "grad_norm": 0.3976926803588867,
      "learning_rate": 2.377777777777778e-05,
      "loss": 0.0027,
      "step": 47200
    },
    {
      "epoch": 1.049111111111111,
      "grad_norm": 0.1961170732975006,
      "learning_rate": 2.3772222222222224e-05,
      "loss": 0.0022,
      "step": 47210
    },
    {
      "epoch": 1.0493333333333332,
      "grad_norm": 0.18650542199611664,
      "learning_rate": 2.3766666666666667e-05,
      "loss": 0.0041,
      "step": 47220
    },
    {
      "epoch": 1.0495555555555556,
      "grad_norm": 0.44339534640312195,
      "learning_rate": 2.376111111111111e-05,
      "loss": 0.002,
      "step": 47230
    },
    {
      "epoch": 1.0497777777777777,
      "grad_norm": 0.0877622440457344,
      "learning_rate": 2.3755555555555554e-05,
      "loss": 0.0033,
      "step": 47240
    },
    {
      "epoch": 1.05,
      "grad_norm": 0.13508376479148865,
      "learning_rate": 2.375e-05,
      "loss": 0.0022,
      "step": 47250
    },
    {
      "epoch": 1.0502222222222222,
      "grad_norm": 0.2021263986825943,
      "learning_rate": 2.3744444444444448e-05,
      "loss": 0.0017,
      "step": 47260
    },
    {
      "epoch": 1.0504444444444445,
      "grad_norm": 0.5694851279258728,
      "learning_rate": 2.3738888888888892e-05,
      "loss": 0.0031,
      "step": 47270
    },
    {
      "epoch": 1.0506666666666666,
      "grad_norm": 0.3397967517375946,
      "learning_rate": 2.3733333333333335e-05,
      "loss": 0.0019,
      "step": 47280
    },
    {
      "epoch": 1.050888888888889,
      "grad_norm": 0.33330175280570984,
      "learning_rate": 2.372777777777778e-05,
      "loss": 0.0016,
      "step": 47290
    },
    {
      "epoch": 1.051111111111111,
      "grad_norm": 0.5333696603775024,
      "learning_rate": 2.3722222222222222e-05,
      "loss": 0.0021,
      "step": 47300
    },
    {
      "epoch": 1.0513333333333332,
      "grad_norm": 0.4809037446975708,
      "learning_rate": 2.3716666666666666e-05,
      "loss": 0.0022,
      "step": 47310
    },
    {
      "epoch": 1.0515555555555556,
      "grad_norm": 0.4317978322505951,
      "learning_rate": 2.3711111111111113e-05,
      "loss": 0.0019,
      "step": 47320
    },
    {
      "epoch": 1.0517777777777777,
      "grad_norm": 0.23973849415779114,
      "learning_rate": 2.3705555555555557e-05,
      "loss": 0.0018,
      "step": 47330
    },
    {
      "epoch": 1.052,
      "grad_norm": 0.09872611612081528,
      "learning_rate": 2.37e-05,
      "loss": 0.0025,
      "step": 47340
    },
    {
      "epoch": 1.0522222222222222,
      "grad_norm": 0.12971386313438416,
      "learning_rate": 2.3694444444444447e-05,
      "loss": 0.0017,
      "step": 47350
    },
    {
      "epoch": 1.0524444444444445,
      "grad_norm": 0.2363748997449875,
      "learning_rate": 2.368888888888889e-05,
      "loss": 0.0019,
      "step": 47360
    },
    {
      "epoch": 1.0526666666666666,
      "grad_norm": 0.25371110439300537,
      "learning_rate": 2.3683333333333334e-05,
      "loss": 0.0021,
      "step": 47370
    },
    {
      "epoch": 1.052888888888889,
      "grad_norm": 0.11575570702552795,
      "learning_rate": 2.3677777777777778e-05,
      "loss": 0.0022,
      "step": 47380
    },
    {
      "epoch": 1.053111111111111,
      "grad_norm": 0.35747790336608887,
      "learning_rate": 2.3672222222222225e-05,
      "loss": 0.0025,
      "step": 47390
    },
    {
      "epoch": 1.0533333333333332,
      "grad_norm": 0.22782640159130096,
      "learning_rate": 2.3666666666666668e-05,
      "loss": 0.0017,
      "step": 47400
    },
    {
      "epoch": 1.0535555555555556,
      "grad_norm": 0.24953840672969818,
      "learning_rate": 2.3661111111111112e-05,
      "loss": 0.0019,
      "step": 47410
    },
    {
      "epoch": 1.0537777777777777,
      "grad_norm": 0.16744738817214966,
      "learning_rate": 2.3655555555555555e-05,
      "loss": 0.0023,
      "step": 47420
    },
    {
      "epoch": 1.054,
      "grad_norm": 0.17259861528873444,
      "learning_rate": 2.365e-05,
      "loss": 0.0027,
      "step": 47430
    },
    {
      "epoch": 1.0542222222222222,
      "grad_norm": 0.5880388617515564,
      "learning_rate": 2.3644444444444446e-05,
      "loss": 0.0022,
      "step": 47440
    },
    {
      "epoch": 1.0544444444444445,
      "grad_norm": 0.5188854336738586,
      "learning_rate": 2.363888888888889e-05,
      "loss": 0.002,
      "step": 47450
    },
    {
      "epoch": 1.0546666666666666,
      "grad_norm": 0.5173363089561462,
      "learning_rate": 2.3633333333333336e-05,
      "loss": 0.002,
      "step": 47460
    },
    {
      "epoch": 1.054888888888889,
      "grad_norm": 0.11431152373552322,
      "learning_rate": 2.362777777777778e-05,
      "loss": 0.0028,
      "step": 47470
    },
    {
      "epoch": 1.055111111111111,
      "grad_norm": 0.23484204709529877,
      "learning_rate": 2.3622222222222223e-05,
      "loss": 0.0018,
      "step": 47480
    },
    {
      "epoch": 1.0553333333333332,
      "grad_norm": 0.2367938905954361,
      "learning_rate": 2.3616666666666667e-05,
      "loss": 0.0023,
      "step": 47490
    },
    {
      "epoch": 1.0555555555555556,
      "grad_norm": 0.28407904505729675,
      "learning_rate": 2.361111111111111e-05,
      "loss": 0.0032,
      "step": 47500
    },
    {
      "epoch": 1.0557777777777777,
      "grad_norm": 0.1600772738456726,
      "learning_rate": 2.3605555555555554e-05,
      "loss": 0.0035,
      "step": 47510
    },
    {
      "epoch": 1.056,
      "grad_norm": 0.13552160561084747,
      "learning_rate": 2.36e-05,
      "loss": 0.002,
      "step": 47520
    },
    {
      "epoch": 1.0562222222222222,
      "grad_norm": 0.5035257935523987,
      "learning_rate": 2.3594444444444448e-05,
      "loss": 0.0031,
      "step": 47530
    },
    {
      "epoch": 1.0564444444444445,
      "grad_norm": 0.4028163552284241,
      "learning_rate": 2.358888888888889e-05,
      "loss": 0.0019,
      "step": 47540
    },
    {
      "epoch": 1.0566666666666666,
      "grad_norm": 0.18531303107738495,
      "learning_rate": 2.3583333333333335e-05,
      "loss": 0.0022,
      "step": 47550
    },
    {
      "epoch": 1.056888888888889,
      "grad_norm": 0.37284788489341736,
      "learning_rate": 2.357777777777778e-05,
      "loss": 0.0027,
      "step": 47560
    },
    {
      "epoch": 1.0571111111111111,
      "grad_norm": 0.04795316606760025,
      "learning_rate": 2.3572222222222222e-05,
      "loss": 0.0018,
      "step": 47570
    },
    {
      "epoch": 1.0573333333333332,
      "grad_norm": 0.14348770678043365,
      "learning_rate": 2.3566666666666666e-05,
      "loss": 0.0027,
      "step": 47580
    },
    {
      "epoch": 1.0575555555555556,
      "grad_norm": 0.1103036031126976,
      "learning_rate": 2.3561111111111113e-05,
      "loss": 0.0021,
      "step": 47590
    },
    {
      "epoch": 1.0577777777777777,
      "grad_norm": 0.30600979924201965,
      "learning_rate": 2.3555555555555556e-05,
      "loss": 0.0019,
      "step": 47600
    },
    {
      "epoch": 1.058,
      "grad_norm": 0.18876077234745026,
      "learning_rate": 2.355e-05,
      "loss": 0.003,
      "step": 47610
    },
    {
      "epoch": 1.0582222222222222,
      "grad_norm": 0.29142212867736816,
      "learning_rate": 2.3544444444444447e-05,
      "loss": 0.0024,
      "step": 47620
    },
    {
      "epoch": 1.0584444444444445,
      "grad_norm": 0.05995597690343857,
      "learning_rate": 2.353888888888889e-05,
      "loss": 0.0019,
      "step": 47630
    },
    {
      "epoch": 1.0586666666666666,
      "grad_norm": 0.13368380069732666,
      "learning_rate": 2.3533333333333334e-05,
      "loss": 0.0024,
      "step": 47640
    },
    {
      "epoch": 1.058888888888889,
      "grad_norm": 0.17236782610416412,
      "learning_rate": 2.3527777777777777e-05,
      "loss": 0.0022,
      "step": 47650
    },
    {
      "epoch": 1.0591111111111111,
      "grad_norm": 0.20310570299625397,
      "learning_rate": 2.3522222222222224e-05,
      "loss": 0.0024,
      "step": 47660
    },
    {
      "epoch": 1.0593333333333332,
      "grad_norm": 0.16258744895458221,
      "learning_rate": 2.3516666666666668e-05,
      "loss": 0.0026,
      "step": 47670
    },
    {
      "epoch": 1.0595555555555556,
      "grad_norm": 0.176596000790596,
      "learning_rate": 2.351111111111111e-05,
      "loss": 0.002,
      "step": 47680
    },
    {
      "epoch": 1.0597777777777777,
      "grad_norm": 0.6108916997909546,
      "learning_rate": 2.3505555555555555e-05,
      "loss": 0.0021,
      "step": 47690
    },
    {
      "epoch": 1.06,
      "grad_norm": 0.13556240499019623,
      "learning_rate": 2.35e-05,
      "loss": 0.0022,
      "step": 47700
    },
    {
      "epoch": 1.0602222222222222,
      "grad_norm": 0.08804559707641602,
      "learning_rate": 2.3494444444444446e-05,
      "loss": 0.002,
      "step": 47710
    },
    {
      "epoch": 1.0604444444444445,
      "grad_norm": 0.1173555850982666,
      "learning_rate": 2.3488888888888893e-05,
      "loss": 0.0021,
      "step": 47720
    },
    {
      "epoch": 1.0606666666666666,
      "grad_norm": 0.5345273017883301,
      "learning_rate": 2.3483333333333336e-05,
      "loss": 0.0029,
      "step": 47730
    },
    {
      "epoch": 1.060888888888889,
      "grad_norm": 0.4873897433280945,
      "learning_rate": 2.347777777777778e-05,
      "loss": 0.0036,
      "step": 47740
    },
    {
      "epoch": 1.0611111111111111,
      "grad_norm": 0.16292068362236023,
      "learning_rate": 2.3472222222222223e-05,
      "loss": 0.0019,
      "step": 47750
    },
    {
      "epoch": 1.0613333333333332,
      "grad_norm": 0.41369226574897766,
      "learning_rate": 2.3466666666666667e-05,
      "loss": 0.0026,
      "step": 47760
    },
    {
      "epoch": 1.0615555555555556,
      "grad_norm": 0.16307389736175537,
      "learning_rate": 2.346111111111111e-05,
      "loss": 0.002,
      "step": 47770
    },
    {
      "epoch": 1.0617777777777777,
      "grad_norm": 0.1714361608028412,
      "learning_rate": 2.3455555555555557e-05,
      "loss": 0.0019,
      "step": 47780
    },
    {
      "epoch": 1.062,
      "grad_norm": 0.40890106558799744,
      "learning_rate": 2.345e-05,
      "loss": 0.0021,
      "step": 47790
    },
    {
      "epoch": 1.0622222222222222,
      "grad_norm": 0.6160464286804199,
      "learning_rate": 2.3444444444444448e-05,
      "loss": 0.0022,
      "step": 47800
    },
    {
      "epoch": 1.0624444444444445,
      "grad_norm": 0.714262843132019,
      "learning_rate": 2.343888888888889e-05,
      "loss": 0.0022,
      "step": 47810
    },
    {
      "epoch": 1.0626666666666666,
      "grad_norm": 0.07381488382816315,
      "learning_rate": 2.3433333333333335e-05,
      "loss": 0.0021,
      "step": 47820
    },
    {
      "epoch": 1.0628888888888888,
      "grad_norm": 0.1522904485464096,
      "learning_rate": 2.342777777777778e-05,
      "loss": 0.0019,
      "step": 47830
    },
    {
      "epoch": 1.0631111111111111,
      "grad_norm": 0.11315922439098358,
      "learning_rate": 2.3422222222222222e-05,
      "loss": 0.002,
      "step": 47840
    },
    {
      "epoch": 1.0633333333333332,
      "grad_norm": 0.5434458255767822,
      "learning_rate": 2.341666666666667e-05,
      "loss": 0.0017,
      "step": 47850
    },
    {
      "epoch": 1.0635555555555556,
      "grad_norm": 0.38793569803237915,
      "learning_rate": 2.3411111111111112e-05,
      "loss": 0.002,
      "step": 47860
    },
    {
      "epoch": 1.0637777777777777,
      "grad_norm": 0.3908540606498718,
      "learning_rate": 2.3405555555555556e-05,
      "loss": 0.002,
      "step": 47870
    },
    {
      "epoch": 1.064,
      "grad_norm": 0.4047633707523346,
      "learning_rate": 2.3400000000000003e-05,
      "loss": 0.002,
      "step": 47880
    },
    {
      "epoch": 1.0642222222222222,
      "grad_norm": 0.11650103330612183,
      "learning_rate": 2.3394444444444447e-05,
      "loss": 0.0024,
      "step": 47890
    },
    {
      "epoch": 1.0644444444444445,
      "grad_norm": 0.3643101453781128,
      "learning_rate": 2.338888888888889e-05,
      "loss": 0.0025,
      "step": 47900
    },
    {
      "epoch": 1.0646666666666667,
      "grad_norm": 0.525719404220581,
      "learning_rate": 2.3383333333333334e-05,
      "loss": 0.0024,
      "step": 47910
    },
    {
      "epoch": 1.064888888888889,
      "grad_norm": 0.621497392654419,
      "learning_rate": 2.337777777777778e-05,
      "loss": 0.0028,
      "step": 47920
    },
    {
      "epoch": 1.0651111111111111,
      "grad_norm": 0.33013227581977844,
      "learning_rate": 2.3372222222222224e-05,
      "loss": 0.0033,
      "step": 47930
    },
    {
      "epoch": 1.0653333333333332,
      "grad_norm": 0.45188847184181213,
      "learning_rate": 2.3366666666666668e-05,
      "loss": 0.0026,
      "step": 47940
    },
    {
      "epoch": 1.0655555555555556,
      "grad_norm": 0.22245338559150696,
      "learning_rate": 2.336111111111111e-05,
      "loss": 0.0023,
      "step": 47950
    },
    {
      "epoch": 1.0657777777777777,
      "grad_norm": 0.24262796342372894,
      "learning_rate": 2.3355555555555555e-05,
      "loss": 0.0037,
      "step": 47960
    },
    {
      "epoch": 1.066,
      "grad_norm": 0.08201579004526138,
      "learning_rate": 2.3350000000000002e-05,
      "loss": 0.0024,
      "step": 47970
    },
    {
      "epoch": 1.0662222222222222,
      "grad_norm": 0.08441736549139023,
      "learning_rate": 2.3344444444444445e-05,
      "loss": 0.0028,
      "step": 47980
    },
    {
      "epoch": 1.0664444444444445,
      "grad_norm": 0.20381149649620056,
      "learning_rate": 2.3338888888888892e-05,
      "loss": 0.0027,
      "step": 47990
    },
    {
      "epoch": 1.0666666666666667,
      "grad_norm": 0.10477171093225479,
      "learning_rate": 2.3333333333333336e-05,
      "loss": 0.0028,
      "step": 48000
    },
    {
      "epoch": 1.0668888888888888,
      "grad_norm": 0.40276023745536804,
      "learning_rate": 2.332777777777778e-05,
      "loss": 0.0022,
      "step": 48010
    },
    {
      "epoch": 1.0671111111111111,
      "grad_norm": 0.20424622297286987,
      "learning_rate": 2.3322222222222223e-05,
      "loss": 0.0021,
      "step": 48020
    },
    {
      "epoch": 1.0673333333333332,
      "grad_norm": 0.3879980146884918,
      "learning_rate": 2.3316666666666666e-05,
      "loss": 0.0025,
      "step": 48030
    },
    {
      "epoch": 1.0675555555555556,
      "grad_norm": 0.2756730914115906,
      "learning_rate": 2.331111111111111e-05,
      "loss": 0.0026,
      "step": 48040
    },
    {
      "epoch": 1.0677777777777777,
      "grad_norm": 0.0703936442732811,
      "learning_rate": 2.3305555555555557e-05,
      "loss": 0.002,
      "step": 48050
    },
    {
      "epoch": 1.068,
      "grad_norm": 0.3445979356765747,
      "learning_rate": 2.3300000000000004e-05,
      "loss": 0.0019,
      "step": 48060
    },
    {
      "epoch": 1.0682222222222222,
      "grad_norm": 0.4072536826133728,
      "learning_rate": 2.3294444444444447e-05,
      "loss": 0.0025,
      "step": 48070
    },
    {
      "epoch": 1.0684444444444445,
      "grad_norm": 0.25183048844337463,
      "learning_rate": 2.328888888888889e-05,
      "loss": 0.0028,
      "step": 48080
    },
    {
      "epoch": 1.0686666666666667,
      "grad_norm": 0.14713908731937408,
      "learning_rate": 2.3283333333333335e-05,
      "loss": 0.0022,
      "step": 48090
    },
    {
      "epoch": 1.068888888888889,
      "grad_norm": 0.212336003780365,
      "learning_rate": 2.3277777777777778e-05,
      "loss": 0.0019,
      "step": 48100
    },
    {
      "epoch": 1.0691111111111111,
      "grad_norm": 0.19527526199817657,
      "learning_rate": 2.3272222222222222e-05,
      "loss": 0.0018,
      "step": 48110
    },
    {
      "epoch": 1.0693333333333332,
      "grad_norm": 0.26836150884628296,
      "learning_rate": 2.326666666666667e-05,
      "loss": 0.0023,
      "step": 48120
    },
    {
      "epoch": 1.0695555555555556,
      "grad_norm": 0.19469650089740753,
      "learning_rate": 2.3261111111111112e-05,
      "loss": 0.0023,
      "step": 48130
    },
    {
      "epoch": 1.0697777777777777,
      "grad_norm": 0.21885189414024353,
      "learning_rate": 2.3255555555555556e-05,
      "loss": 0.0028,
      "step": 48140
    },
    {
      "epoch": 1.07,
      "grad_norm": 0.31314706802368164,
      "learning_rate": 2.3250000000000003e-05,
      "loss": 0.0028,
      "step": 48150
    },
    {
      "epoch": 1.0702222222222222,
      "grad_norm": 0.07347681373357773,
      "learning_rate": 2.3244444444444446e-05,
      "loss": 0.0017,
      "step": 48160
    },
    {
      "epoch": 1.0704444444444445,
      "grad_norm": 0.2852802276611328,
      "learning_rate": 2.323888888888889e-05,
      "loss": 0.0027,
      "step": 48170
    },
    {
      "epoch": 1.0706666666666667,
      "grad_norm": 0.17933130264282227,
      "learning_rate": 2.3233333333333333e-05,
      "loss": 0.0037,
      "step": 48180
    },
    {
      "epoch": 1.0708888888888888,
      "grad_norm": 0.09731299430131912,
      "learning_rate": 2.322777777777778e-05,
      "loss": 0.0022,
      "step": 48190
    },
    {
      "epoch": 1.0711111111111111,
      "grad_norm": 0.3159869611263275,
      "learning_rate": 2.3222222222222224e-05,
      "loss": 0.002,
      "step": 48200
    },
    {
      "epoch": 1.0713333333333332,
      "grad_norm": 0.7391040325164795,
      "learning_rate": 2.3216666666666667e-05,
      "loss": 0.0021,
      "step": 48210
    },
    {
      "epoch": 1.0715555555555556,
      "grad_norm": 0.22870111465454102,
      "learning_rate": 2.321111111111111e-05,
      "loss": 0.0027,
      "step": 48220
    },
    {
      "epoch": 1.0717777777777777,
      "grad_norm": 0.43230703473091125,
      "learning_rate": 2.3205555555555555e-05,
      "loss": 0.002,
      "step": 48230
    },
    {
      "epoch": 1.072,
      "grad_norm": 0.20779328048229218,
      "learning_rate": 2.32e-05,
      "loss": 0.0024,
      "step": 48240
    },
    {
      "epoch": 1.0722222222222222,
      "grad_norm": 0.48902609944343567,
      "learning_rate": 2.3194444444444445e-05,
      "loss": 0.0021,
      "step": 48250
    },
    {
      "epoch": 1.0724444444444445,
      "grad_norm": 0.4151966869831085,
      "learning_rate": 2.3188888888888892e-05,
      "loss": 0.0021,
      "step": 48260
    },
    {
      "epoch": 1.0726666666666667,
      "grad_norm": 0.166411355137825,
      "learning_rate": 2.3183333333333336e-05,
      "loss": 0.0027,
      "step": 48270
    },
    {
      "epoch": 1.072888888888889,
      "grad_norm": 0.3774523437023163,
      "learning_rate": 2.317777777777778e-05,
      "loss": 0.0019,
      "step": 48280
    },
    {
      "epoch": 1.0731111111111111,
      "grad_norm": 0.4703212380409241,
      "learning_rate": 2.3172222222222223e-05,
      "loss": 0.0033,
      "step": 48290
    },
    {
      "epoch": 1.0733333333333333,
      "grad_norm": 0.1296171396970749,
      "learning_rate": 2.3166666666666666e-05,
      "loss": 0.0034,
      "step": 48300
    },
    {
      "epoch": 1.0735555555555556,
      "grad_norm": 0.21835871040821075,
      "learning_rate": 2.316111111111111e-05,
      "loss": 0.003,
      "step": 48310
    },
    {
      "epoch": 1.0737777777777777,
      "grad_norm": 0.2204824984073639,
      "learning_rate": 2.3155555555555557e-05,
      "loss": 0.0018,
      "step": 48320
    },
    {
      "epoch": 1.074,
      "grad_norm": 0.19794708490371704,
      "learning_rate": 2.3150000000000004e-05,
      "loss": 0.002,
      "step": 48330
    },
    {
      "epoch": 1.0742222222222222,
      "grad_norm": 0.6437619924545288,
      "learning_rate": 2.3144444444444447e-05,
      "loss": 0.0025,
      "step": 48340
    },
    {
      "epoch": 1.0744444444444445,
      "grad_norm": 0.24202604591846466,
      "learning_rate": 2.313888888888889e-05,
      "loss": 0.0027,
      "step": 48350
    },
    {
      "epoch": 1.0746666666666667,
      "grad_norm": 0.35859164595603943,
      "learning_rate": 2.3133333333333334e-05,
      "loss": 0.0024,
      "step": 48360
    },
    {
      "epoch": 1.0748888888888888,
      "grad_norm": 0.12009750306606293,
      "learning_rate": 2.3127777777777778e-05,
      "loss": 0.0023,
      "step": 48370
    },
    {
      "epoch": 1.0751111111111111,
      "grad_norm": 0.22156597673892975,
      "learning_rate": 2.312222222222222e-05,
      "loss": 0.0029,
      "step": 48380
    },
    {
      "epoch": 1.0753333333333333,
      "grad_norm": 0.25943389534950256,
      "learning_rate": 2.311666666666667e-05,
      "loss": 0.0022,
      "step": 48390
    },
    {
      "epoch": 1.0755555555555556,
      "grad_norm": 0.08081802725791931,
      "learning_rate": 2.3111111111111112e-05,
      "loss": 0.0022,
      "step": 48400
    },
    {
      "epoch": 1.0757777777777777,
      "grad_norm": 0.09672124683856964,
      "learning_rate": 2.3105555555555556e-05,
      "loss": 0.002,
      "step": 48410
    },
    {
      "epoch": 1.076,
      "grad_norm": 0.10536690801382065,
      "learning_rate": 2.3100000000000002e-05,
      "loss": 0.0028,
      "step": 48420
    },
    {
      "epoch": 1.0762222222222222,
      "grad_norm": 0.11909763514995575,
      "learning_rate": 2.3094444444444446e-05,
      "loss": 0.0035,
      "step": 48430
    },
    {
      "epoch": 1.0764444444444445,
      "grad_norm": 0.23329707980155945,
      "learning_rate": 2.308888888888889e-05,
      "loss": 0.0023,
      "step": 48440
    },
    {
      "epoch": 1.0766666666666667,
      "grad_norm": 0.2514002323150635,
      "learning_rate": 2.3083333333333333e-05,
      "loss": 0.0022,
      "step": 48450
    },
    {
      "epoch": 1.076888888888889,
      "grad_norm": 0.14739403128623962,
      "learning_rate": 2.307777777777778e-05,
      "loss": 0.0033,
      "step": 48460
    },
    {
      "epoch": 1.0771111111111111,
      "grad_norm": 0.2606823742389679,
      "learning_rate": 2.3072222222222224e-05,
      "loss": 0.002,
      "step": 48470
    },
    {
      "epoch": 1.0773333333333333,
      "grad_norm": 0.08465500921010971,
      "learning_rate": 2.3066666666666667e-05,
      "loss": 0.002,
      "step": 48480
    },
    {
      "epoch": 1.0775555555555556,
      "grad_norm": 0.3148978352546692,
      "learning_rate": 2.306111111111111e-05,
      "loss": 0.0028,
      "step": 48490
    },
    {
      "epoch": 1.0777777777777777,
      "grad_norm": 0.3860975503921509,
      "learning_rate": 2.3055555555555558e-05,
      "loss": 0.0018,
      "step": 48500
    },
    {
      "epoch": 1.078,
      "grad_norm": 0.3455502390861511,
      "learning_rate": 2.305e-05,
      "loss": 0.0019,
      "step": 48510
    },
    {
      "epoch": 1.0782222222222222,
      "grad_norm": 0.41148459911346436,
      "learning_rate": 2.3044444444444445e-05,
      "loss": 0.0021,
      "step": 48520
    },
    {
      "epoch": 1.0784444444444445,
      "grad_norm": 0.10990168899297714,
      "learning_rate": 2.3038888888888892e-05,
      "loss": 0.0018,
      "step": 48530
    },
    {
      "epoch": 1.0786666666666667,
      "grad_norm": 0.16956889629364014,
      "learning_rate": 2.3033333333333335e-05,
      "loss": 0.0018,
      "step": 48540
    },
    {
      "epoch": 1.0788888888888888,
      "grad_norm": 0.4261503517627716,
      "learning_rate": 2.302777777777778e-05,
      "loss": 0.0022,
      "step": 48550
    },
    {
      "epoch": 1.0791111111111111,
      "grad_norm": 0.1908625215291977,
      "learning_rate": 2.3022222222222222e-05,
      "loss": 0.0026,
      "step": 48560
    },
    {
      "epoch": 1.0793333333333333,
      "grad_norm": 0.22568538784980774,
      "learning_rate": 2.3016666666666666e-05,
      "loss": 0.0027,
      "step": 48570
    },
    {
      "epoch": 1.0795555555555556,
      "grad_norm": 0.47946757078170776,
      "learning_rate": 2.301111111111111e-05,
      "loss": 0.0021,
      "step": 48580
    },
    {
      "epoch": 1.0797777777777777,
      "grad_norm": 0.07589194923639297,
      "learning_rate": 2.3005555555555556e-05,
      "loss": 0.0021,
      "step": 48590
    },
    {
      "epoch": 1.08,
      "grad_norm": 0.34651342034339905,
      "learning_rate": 2.3000000000000003e-05,
      "loss": 0.0019,
      "step": 48600
    },
    {
      "epoch": 1.0802222222222222,
      "grad_norm": 0.645179033279419,
      "learning_rate": 2.2994444444444447e-05,
      "loss": 0.0021,
      "step": 48610
    },
    {
      "epoch": 1.0804444444444445,
      "grad_norm": 0.3025859594345093,
      "learning_rate": 2.298888888888889e-05,
      "loss": 0.0031,
      "step": 48620
    },
    {
      "epoch": 1.0806666666666667,
      "grad_norm": 0.13692998886108398,
      "learning_rate": 2.2983333333333334e-05,
      "loss": 0.0017,
      "step": 48630
    },
    {
      "epoch": 1.0808888888888888,
      "grad_norm": 0.41273143887519836,
      "learning_rate": 2.2977777777777778e-05,
      "loss": 0.0019,
      "step": 48640
    },
    {
      "epoch": 1.0811111111111111,
      "grad_norm": 0.16847620904445648,
      "learning_rate": 2.297222222222222e-05,
      "loss": 0.0026,
      "step": 48650
    },
    {
      "epoch": 1.0813333333333333,
      "grad_norm": 0.20444026589393616,
      "learning_rate": 2.2966666666666668e-05,
      "loss": 0.0037,
      "step": 48660
    },
    {
      "epoch": 1.0815555555555556,
      "grad_norm": 0.30950599908828735,
      "learning_rate": 2.296111111111111e-05,
      "loss": 0.0026,
      "step": 48670
    },
    {
      "epoch": 1.0817777777777777,
      "grad_norm": 0.08769304305315018,
      "learning_rate": 2.295555555555556e-05,
      "loss": 0.0018,
      "step": 48680
    },
    {
      "epoch": 1.082,
      "grad_norm": 0.1990968883037567,
      "learning_rate": 2.2950000000000002e-05,
      "loss": 0.0019,
      "step": 48690
    },
    {
      "epoch": 1.0822222222222222,
      "grad_norm": 0.11284352093935013,
      "learning_rate": 2.2944444444444446e-05,
      "loss": 0.0026,
      "step": 48700
    },
    {
      "epoch": 1.0824444444444445,
      "grad_norm": 0.16460222005844116,
      "learning_rate": 2.293888888888889e-05,
      "loss": 0.0028,
      "step": 48710
    },
    {
      "epoch": 1.0826666666666667,
      "grad_norm": 0.10802630335092545,
      "learning_rate": 2.2933333333333333e-05,
      "loss": 0.0026,
      "step": 48720
    },
    {
      "epoch": 1.0828888888888888,
      "grad_norm": 0.44718068838119507,
      "learning_rate": 2.292777777777778e-05,
      "loss": 0.0023,
      "step": 48730
    },
    {
      "epoch": 1.0831111111111111,
      "grad_norm": 0.5024260878562927,
      "learning_rate": 2.2922222222222223e-05,
      "loss": 0.0028,
      "step": 48740
    },
    {
      "epoch": 1.0833333333333333,
      "grad_norm": 0.37050455808639526,
      "learning_rate": 2.2916666666666667e-05,
      "loss": 0.0018,
      "step": 48750
    },
    {
      "epoch": 1.0835555555555556,
      "grad_norm": 0.14645573496818542,
      "learning_rate": 2.291111111111111e-05,
      "loss": 0.0023,
      "step": 48760
    },
    {
      "epoch": 1.0837777777777777,
      "grad_norm": 0.4011296033859253,
      "learning_rate": 2.2905555555555557e-05,
      "loss": 0.0017,
      "step": 48770
    },
    {
      "epoch": 1.084,
      "grad_norm": 0.4218108355998993,
      "learning_rate": 2.29e-05,
      "loss": 0.0018,
      "step": 48780
    },
    {
      "epoch": 1.0842222222222222,
      "grad_norm": 0.060415398329496384,
      "learning_rate": 2.2894444444444445e-05,
      "loss": 0.0017,
      "step": 48790
    },
    {
      "epoch": 1.0844444444444445,
      "grad_norm": 0.11194916814565659,
      "learning_rate": 2.288888888888889e-05,
      "loss": 0.002,
      "step": 48800
    },
    {
      "epoch": 1.0846666666666667,
      "grad_norm": 0.07548714429140091,
      "learning_rate": 2.2883333333333335e-05,
      "loss": 0.0018,
      "step": 48810
    },
    {
      "epoch": 1.0848888888888888,
      "grad_norm": 0.16297589242458344,
      "learning_rate": 2.287777777777778e-05,
      "loss": 0.0028,
      "step": 48820
    },
    {
      "epoch": 1.0851111111111111,
      "grad_norm": 0.4373989701271057,
      "learning_rate": 2.2872222222222222e-05,
      "loss": 0.0018,
      "step": 48830
    },
    {
      "epoch": 1.0853333333333333,
      "grad_norm": 0.13345392048358917,
      "learning_rate": 2.2866666666666666e-05,
      "loss": 0.0032,
      "step": 48840
    },
    {
      "epoch": 1.0855555555555556,
      "grad_norm": 0.35069018602371216,
      "learning_rate": 2.286111111111111e-05,
      "loss": 0.0019,
      "step": 48850
    },
    {
      "epoch": 1.0857777777777777,
      "grad_norm": 0.37325459718704224,
      "learning_rate": 2.2855555555555556e-05,
      "loss": 0.0022,
      "step": 48860
    },
    {
      "epoch": 1.086,
      "grad_norm": 0.3499535024166107,
      "learning_rate": 2.2850000000000003e-05,
      "loss": 0.0025,
      "step": 48870
    },
    {
      "epoch": 1.0862222222222222,
      "grad_norm": 0.21382343769073486,
      "learning_rate": 2.2844444444444447e-05,
      "loss": 0.0026,
      "step": 48880
    },
    {
      "epoch": 1.0864444444444445,
      "grad_norm": 0.09407630562782288,
      "learning_rate": 2.283888888888889e-05,
      "loss": 0.0026,
      "step": 48890
    },
    {
      "epoch": 1.0866666666666667,
      "grad_norm": 0.27275633811950684,
      "learning_rate": 2.2833333333333334e-05,
      "loss": 0.002,
      "step": 48900
    },
    {
      "epoch": 1.0868888888888888,
      "grad_norm": 0.4836210310459137,
      "learning_rate": 2.2827777777777777e-05,
      "loss": 0.0017,
      "step": 48910
    },
    {
      "epoch": 1.0871111111111111,
      "grad_norm": 0.10797462612390518,
      "learning_rate": 2.282222222222222e-05,
      "loss": 0.0027,
      "step": 48920
    },
    {
      "epoch": 1.0873333333333333,
      "grad_norm": 0.3872992694377899,
      "learning_rate": 2.2816666666666668e-05,
      "loss": 0.0037,
      "step": 48930
    },
    {
      "epoch": 1.0875555555555556,
      "grad_norm": 0.2126714140176773,
      "learning_rate": 2.281111111111111e-05,
      "loss": 0.0018,
      "step": 48940
    },
    {
      "epoch": 1.0877777777777777,
      "grad_norm": 0.04040681943297386,
      "learning_rate": 2.280555555555556e-05,
      "loss": 0.0023,
      "step": 48950
    },
    {
      "epoch": 1.088,
      "grad_norm": 0.2174815833568573,
      "learning_rate": 2.2800000000000002e-05,
      "loss": 0.002,
      "step": 48960
    },
    {
      "epoch": 1.0882222222222222,
      "grad_norm": 0.20571859180927277,
      "learning_rate": 2.2794444444444445e-05,
      "loss": 0.0018,
      "step": 48970
    },
    {
      "epoch": 1.0884444444444445,
      "grad_norm": 0.42266586422920227,
      "learning_rate": 2.278888888888889e-05,
      "loss": 0.0017,
      "step": 48980
    },
    {
      "epoch": 1.0886666666666667,
      "grad_norm": 0.46842119097709656,
      "learning_rate": 2.2783333333333336e-05,
      "loss": 0.0017,
      "step": 48990
    },
    {
      "epoch": 1.0888888888888888,
      "grad_norm": 0.1597752422094345,
      "learning_rate": 2.277777777777778e-05,
      "loss": 0.0021,
      "step": 49000
    },
    {
      "epoch": 1.0891111111111111,
      "grad_norm": 0.20514285564422607,
      "learning_rate": 2.2772222222222223e-05,
      "loss": 0.0026,
      "step": 49010
    },
    {
      "epoch": 1.0893333333333333,
      "grad_norm": 0.06855177879333496,
      "learning_rate": 2.2766666666666667e-05,
      "loss": 0.0019,
      "step": 49020
    },
    {
      "epoch": 1.0895555555555556,
      "grad_norm": 0.18807446956634521,
      "learning_rate": 2.276111111111111e-05,
      "loss": 0.0018,
      "step": 49030
    },
    {
      "epoch": 1.0897777777777777,
      "grad_norm": 0.6600061058998108,
      "learning_rate": 2.2755555555555557e-05,
      "loss": 0.0022,
      "step": 49040
    },
    {
      "epoch": 1.09,
      "grad_norm": 0.08968944847583771,
      "learning_rate": 2.275e-05,
      "loss": 0.0021,
      "step": 49050
    },
    {
      "epoch": 1.0902222222222222,
      "grad_norm": 0.33665230870246887,
      "learning_rate": 2.2744444444444448e-05,
      "loss": 0.0025,
      "step": 49060
    },
    {
      "epoch": 1.0904444444444445,
      "grad_norm": 0.5310399532318115,
      "learning_rate": 2.273888888888889e-05,
      "loss": 0.0039,
      "step": 49070
    },
    {
      "epoch": 1.0906666666666667,
      "grad_norm": 0.09104632586240768,
      "learning_rate": 2.2733333333333335e-05,
      "loss": 0.0034,
      "step": 49080
    },
    {
      "epoch": 1.0908888888888888,
      "grad_norm": 0.4872036278247833,
      "learning_rate": 2.272777777777778e-05,
      "loss": 0.0022,
      "step": 49090
    },
    {
      "epoch": 1.0911111111111111,
      "grad_norm": 0.051658935844898224,
      "learning_rate": 2.2722222222222222e-05,
      "loss": 0.0021,
      "step": 49100
    },
    {
      "epoch": 1.0913333333333333,
      "grad_norm": 0.22374212741851807,
      "learning_rate": 2.2716666666666665e-05,
      "loss": 0.0026,
      "step": 49110
    },
    {
      "epoch": 1.0915555555555556,
      "grad_norm": 0.08998385816812515,
      "learning_rate": 2.2711111111111112e-05,
      "loss": 0.002,
      "step": 49120
    },
    {
      "epoch": 1.0917777777777777,
      "grad_norm": 0.3866844177246094,
      "learning_rate": 2.270555555555556e-05,
      "loss": 0.0029,
      "step": 49130
    },
    {
      "epoch": 1.092,
      "grad_norm": 0.5561846494674683,
      "learning_rate": 2.2700000000000003e-05,
      "loss": 0.0017,
      "step": 49140
    },
    {
      "epoch": 1.0922222222222222,
      "grad_norm": 0.6200763583183289,
      "learning_rate": 2.2694444444444446e-05,
      "loss": 0.0026,
      "step": 49150
    },
    {
      "epoch": 1.0924444444444443,
      "grad_norm": 0.25380775332450867,
      "learning_rate": 2.268888888888889e-05,
      "loss": 0.0027,
      "step": 49160
    },
    {
      "epoch": 1.0926666666666667,
      "grad_norm": 0.3174709975719452,
      "learning_rate": 2.2683333333333334e-05,
      "loss": 0.0023,
      "step": 49170
    },
    {
      "epoch": 1.0928888888888888,
      "grad_norm": 0.16588394343852997,
      "learning_rate": 2.2677777777777777e-05,
      "loss": 0.0029,
      "step": 49180
    },
    {
      "epoch": 1.0931111111111111,
      "grad_norm": 0.07430011034011841,
      "learning_rate": 2.2672222222222224e-05,
      "loss": 0.0022,
      "step": 49190
    },
    {
      "epoch": 1.0933333333333333,
      "grad_norm": 0.531988799571991,
      "learning_rate": 2.2666666666666668e-05,
      "loss": 0.0017,
      "step": 49200
    },
    {
      "epoch": 1.0935555555555556,
      "grad_norm": 0.19730611145496368,
      "learning_rate": 2.2661111111111115e-05,
      "loss": 0.0021,
      "step": 49210
    },
    {
      "epoch": 1.0937777777777777,
      "grad_norm": 0.5302790403366089,
      "learning_rate": 2.2655555555555558e-05,
      "loss": 0.0019,
      "step": 49220
    },
    {
      "epoch": 1.094,
      "grad_norm": 0.3296034634113312,
      "learning_rate": 2.265e-05,
      "loss": 0.0018,
      "step": 49230
    },
    {
      "epoch": 1.0942222222222222,
      "grad_norm": 0.38598987460136414,
      "learning_rate": 2.2644444444444445e-05,
      "loss": 0.0027,
      "step": 49240
    },
    {
      "epoch": 1.0944444444444446,
      "grad_norm": 0.2328796535730362,
      "learning_rate": 2.263888888888889e-05,
      "loss": 0.0023,
      "step": 49250
    },
    {
      "epoch": 1.0946666666666667,
      "grad_norm": 0.31389501690864563,
      "learning_rate": 2.2633333333333336e-05,
      "loss": 0.0024,
      "step": 49260
    },
    {
      "epoch": 1.0948888888888888,
      "grad_norm": 0.17982302606105804,
      "learning_rate": 2.262777777777778e-05,
      "loss": 0.0016,
      "step": 49270
    },
    {
      "epoch": 1.0951111111111111,
      "grad_norm": 0.3022799789905548,
      "learning_rate": 2.2622222222222223e-05,
      "loss": 0.0017,
      "step": 49280
    },
    {
      "epoch": 1.0953333333333333,
      "grad_norm": 0.2658354341983795,
      "learning_rate": 2.2616666666666666e-05,
      "loss": 0.0029,
      "step": 49290
    },
    {
      "epoch": 1.0955555555555556,
      "grad_norm": 0.5263518691062927,
      "learning_rate": 2.2611111111111113e-05,
      "loss": 0.0023,
      "step": 49300
    },
    {
      "epoch": 1.0957777777777777,
      "grad_norm": 0.11218284070491791,
      "learning_rate": 2.2605555555555557e-05,
      "loss": 0.0027,
      "step": 49310
    },
    {
      "epoch": 1.096,
      "grad_norm": 0.06455924361944199,
      "learning_rate": 2.26e-05,
      "loss": 0.0025,
      "step": 49320
    },
    {
      "epoch": 1.0962222222222222,
      "grad_norm": 0.08586249500513077,
      "learning_rate": 2.2594444444444447e-05,
      "loss": 0.0017,
      "step": 49330
    },
    {
      "epoch": 1.0964444444444443,
      "grad_norm": 0.20603986084461212,
      "learning_rate": 2.258888888888889e-05,
      "loss": 0.0019,
      "step": 49340
    },
    {
      "epoch": 1.0966666666666667,
      "grad_norm": 0.46167296171188354,
      "learning_rate": 2.2583333333333335e-05,
      "loss": 0.0019,
      "step": 49350
    },
    {
      "epoch": 1.0968888888888888,
      "grad_norm": 0.3931187391281128,
      "learning_rate": 2.2577777777777778e-05,
      "loss": 0.0018,
      "step": 49360
    },
    {
      "epoch": 1.0971111111111111,
      "grad_norm": 0.12681709229946136,
      "learning_rate": 2.257222222222222e-05,
      "loss": 0.0021,
      "step": 49370
    },
    {
      "epoch": 1.0973333333333333,
      "grad_norm": 0.09355200082063675,
      "learning_rate": 2.2566666666666665e-05,
      "loss": 0.0025,
      "step": 49380
    },
    {
      "epoch": 1.0975555555555556,
      "grad_norm": 0.23942840099334717,
      "learning_rate": 2.2561111111111112e-05,
      "loss": 0.002,
      "step": 49390
    },
    {
      "epoch": 1.0977777777777777,
      "grad_norm": 0.2449624091386795,
      "learning_rate": 2.255555555555556e-05,
      "loss": 0.0018,
      "step": 49400
    },
    {
      "epoch": 1.098,
      "grad_norm": 0.05467282235622406,
      "learning_rate": 2.2550000000000003e-05,
      "loss": 0.0022,
      "step": 49410
    },
    {
      "epoch": 1.0982222222222222,
      "grad_norm": 0.04840513691306114,
      "learning_rate": 2.2544444444444446e-05,
      "loss": 0.0022,
      "step": 49420
    },
    {
      "epoch": 1.0984444444444446,
      "grad_norm": 0.18543383479118347,
      "learning_rate": 2.253888888888889e-05,
      "loss": 0.0035,
      "step": 49430
    },
    {
      "epoch": 1.0986666666666667,
      "grad_norm": 0.35628584027290344,
      "learning_rate": 2.2533333333333333e-05,
      "loss": 0.0019,
      "step": 49440
    },
    {
      "epoch": 1.0988888888888888,
      "grad_norm": 0.463365763425827,
      "learning_rate": 2.2527777777777777e-05,
      "loss": 0.0025,
      "step": 49450
    },
    {
      "epoch": 1.0991111111111111,
      "grad_norm": 0.12202716618776321,
      "learning_rate": 2.2522222222222224e-05,
      "loss": 0.0019,
      "step": 49460
    },
    {
      "epoch": 1.0993333333333333,
      "grad_norm": 0.16188278794288635,
      "learning_rate": 2.2516666666666667e-05,
      "loss": 0.0018,
      "step": 49470
    },
    {
      "epoch": 1.0995555555555556,
      "grad_norm": 0.34702548384666443,
      "learning_rate": 2.2511111111111114e-05,
      "loss": 0.0021,
      "step": 49480
    },
    {
      "epoch": 1.0997777777777777,
      "grad_norm": 0.13547377288341522,
      "learning_rate": 2.2505555555555558e-05,
      "loss": 0.0022,
      "step": 49490
    },
    {
      "epoch": 1.1,
      "grad_norm": 0.22242991626262665,
      "learning_rate": 2.25e-05,
      "loss": 0.0017,
      "step": 49500
    },
    {
      "epoch": 1.1002222222222222,
      "grad_norm": 0.4030602276325226,
      "learning_rate": 2.2494444444444445e-05,
      "loss": 0.0018,
      "step": 49510
    },
    {
      "epoch": 1.1004444444444443,
      "grad_norm": 0.26195022463798523,
      "learning_rate": 2.248888888888889e-05,
      "loss": 0.002,
      "step": 49520
    },
    {
      "epoch": 1.1006666666666667,
      "grad_norm": 0.3422282040119171,
      "learning_rate": 2.2483333333333335e-05,
      "loss": 0.0019,
      "step": 49530
    },
    {
      "epoch": 1.1008888888888888,
      "grad_norm": 0.3058457374572754,
      "learning_rate": 2.247777777777778e-05,
      "loss": 0.0021,
      "step": 49540
    },
    {
      "epoch": 1.1011111111111112,
      "grad_norm": 0.27163153886795044,
      "learning_rate": 2.2472222222222223e-05,
      "loss": 0.0041,
      "step": 49550
    },
    {
      "epoch": 1.1013333333333333,
      "grad_norm": 0.07742585241794586,
      "learning_rate": 2.2466666666666666e-05,
      "loss": 0.0019,
      "step": 49560
    },
    {
      "epoch": 1.1015555555555556,
      "grad_norm": 0.19440358877182007,
      "learning_rate": 2.2461111111111113e-05,
      "loss": 0.0027,
      "step": 49570
    },
    {
      "epoch": 1.1017777777777777,
      "grad_norm": 0.44491881132125854,
      "learning_rate": 2.2455555555555557e-05,
      "loss": 0.0022,
      "step": 49580
    },
    {
      "epoch": 1.102,
      "grad_norm": 0.6358106732368469,
      "learning_rate": 2.245e-05,
      "loss": 0.0021,
      "step": 49590
    },
    {
      "epoch": 1.1022222222222222,
      "grad_norm": 0.23323287069797516,
      "learning_rate": 2.2444444444444447e-05,
      "loss": 0.0029,
      "step": 49600
    },
    {
      "epoch": 1.1024444444444446,
      "grad_norm": 0.23254399001598358,
      "learning_rate": 2.243888888888889e-05,
      "loss": 0.0023,
      "step": 49610
    },
    {
      "epoch": 1.1026666666666667,
      "grad_norm": 0.7426252961158752,
      "learning_rate": 2.2433333333333334e-05,
      "loss": 0.0032,
      "step": 49620
    },
    {
      "epoch": 1.1028888888888888,
      "grad_norm": 0.4310471713542938,
      "learning_rate": 2.2427777777777778e-05,
      "loss": 0.0022,
      "step": 49630
    },
    {
      "epoch": 1.1031111111111112,
      "grad_norm": 0.5266132354736328,
      "learning_rate": 2.242222222222222e-05,
      "loss": 0.0017,
      "step": 49640
    },
    {
      "epoch": 1.1033333333333333,
      "grad_norm": 0.9167659282684326,
      "learning_rate": 2.2416666666666665e-05,
      "loss": 0.0022,
      "step": 49650
    },
    {
      "epoch": 1.1035555555555556,
      "grad_norm": 0.29035234451293945,
      "learning_rate": 2.2411111111111112e-05,
      "loss": 0.0021,
      "step": 49660
    },
    {
      "epoch": 1.1037777777777777,
      "grad_norm": 0.46064916253089905,
      "learning_rate": 2.240555555555556e-05,
      "loss": 0.0018,
      "step": 49670
    },
    {
      "epoch": 1.104,
      "grad_norm": 0.2165127992630005,
      "learning_rate": 2.2400000000000002e-05,
      "loss": 0.003,
      "step": 49680
    },
    {
      "epoch": 1.1042222222222222,
      "grad_norm": 0.28499796986579895,
      "learning_rate": 2.2394444444444446e-05,
      "loss": 0.002,
      "step": 49690
    },
    {
      "epoch": 1.1044444444444443,
      "grad_norm": 0.4861760139465332,
      "learning_rate": 2.238888888888889e-05,
      "loss": 0.0026,
      "step": 49700
    },
    {
      "epoch": 1.1046666666666667,
      "grad_norm": 0.14741241931915283,
      "learning_rate": 2.2383333333333333e-05,
      "loss": 0.0024,
      "step": 49710
    },
    {
      "epoch": 1.1048888888888888,
      "grad_norm": 0.2189893275499344,
      "learning_rate": 2.2377777777777777e-05,
      "loss": 0.0021,
      "step": 49720
    },
    {
      "epoch": 1.1051111111111112,
      "grad_norm": 0.5906627774238586,
      "learning_rate": 2.2372222222222224e-05,
      "loss": 0.002,
      "step": 49730
    },
    {
      "epoch": 1.1053333333333333,
      "grad_norm": 0.6870743036270142,
      "learning_rate": 2.236666666666667e-05,
      "loss": 0.0019,
      "step": 49740
    },
    {
      "epoch": 1.1055555555555556,
      "grad_norm": 0.49985742568969727,
      "learning_rate": 2.2361111111111114e-05,
      "loss": 0.002,
      "step": 49750
    },
    {
      "epoch": 1.1057777777777777,
      "grad_norm": 0.6105996370315552,
      "learning_rate": 2.2355555555555558e-05,
      "loss": 0.0018,
      "step": 49760
    },
    {
      "epoch": 1.106,
      "grad_norm": 0.14515163004398346,
      "learning_rate": 2.235e-05,
      "loss": 0.0022,
      "step": 49770
    },
    {
      "epoch": 1.1062222222222222,
      "grad_norm": 0.2266359180212021,
      "learning_rate": 2.2344444444444445e-05,
      "loss": 0.0019,
      "step": 49780
    },
    {
      "epoch": 1.1064444444444443,
      "grad_norm": 0.3598940968513489,
      "learning_rate": 2.2338888888888888e-05,
      "loss": 0.0018,
      "step": 49790
    },
    {
      "epoch": 1.1066666666666667,
      "grad_norm": 0.44961991906166077,
      "learning_rate": 2.2333333333333335e-05,
      "loss": 0.0025,
      "step": 49800
    },
    {
      "epoch": 1.1068888888888888,
      "grad_norm": 0.27218911051750183,
      "learning_rate": 2.232777777777778e-05,
      "loss": 0.0024,
      "step": 49810
    },
    {
      "epoch": 1.1071111111111112,
      "grad_norm": 0.07948365807533264,
      "learning_rate": 2.2322222222222222e-05,
      "loss": 0.0017,
      "step": 49820
    },
    {
      "epoch": 1.1073333333333333,
      "grad_norm": 0.2791522145271301,
      "learning_rate": 2.231666666666667e-05,
      "loss": 0.002,
      "step": 49830
    },
    {
      "epoch": 1.1075555555555556,
      "grad_norm": 0.08170223981142044,
      "learning_rate": 2.2311111111111113e-05,
      "loss": 0.0019,
      "step": 49840
    },
    {
      "epoch": 1.1077777777777778,
      "grad_norm": 0.055343251675367355,
      "learning_rate": 2.2305555555555556e-05,
      "loss": 0.0017,
      "step": 49850
    },
    {
      "epoch": 1.108,
      "grad_norm": 0.10454399138689041,
      "learning_rate": 2.23e-05,
      "loss": 0.003,
      "step": 49860
    },
    {
      "epoch": 1.1082222222222222,
      "grad_norm": 0.45634812116622925,
      "learning_rate": 2.2294444444444447e-05,
      "loss": 0.0021,
      "step": 49870
    },
    {
      "epoch": 1.1084444444444443,
      "grad_norm": 0.2700049877166748,
      "learning_rate": 2.228888888888889e-05,
      "loss": 0.0023,
      "step": 49880
    },
    {
      "epoch": 1.1086666666666667,
      "grad_norm": 0.12524522840976715,
      "learning_rate": 2.2283333333333334e-05,
      "loss": 0.0028,
      "step": 49890
    },
    {
      "epoch": 1.1088888888888888,
      "grad_norm": 0.42551565170288086,
      "learning_rate": 2.2277777777777778e-05,
      "loss": 0.0022,
      "step": 49900
    },
    {
      "epoch": 1.1091111111111112,
      "grad_norm": 0.07234853506088257,
      "learning_rate": 2.227222222222222e-05,
      "loss": 0.0024,
      "step": 49910
    },
    {
      "epoch": 1.1093333333333333,
      "grad_norm": 0.08485617488622665,
      "learning_rate": 2.2266666666666668e-05,
      "loss": 0.0019,
      "step": 49920
    },
    {
      "epoch": 1.1095555555555556,
      "grad_norm": 0.06883300095796585,
      "learning_rate": 2.226111111111111e-05,
      "loss": 0.0027,
      "step": 49930
    },
    {
      "epoch": 1.1097777777777778,
      "grad_norm": 0.06643730401992798,
      "learning_rate": 2.225555555555556e-05,
      "loss": 0.0019,
      "step": 49940
    },
    {
      "epoch": 1.11,
      "grad_norm": 0.12914444506168365,
      "learning_rate": 2.2250000000000002e-05,
      "loss": 0.0019,
      "step": 49950
    },
    {
      "epoch": 1.1102222222222222,
      "grad_norm": 0.06145414710044861,
      "learning_rate": 2.2244444444444446e-05,
      "loss": 0.002,
      "step": 49960
    },
    {
      "epoch": 1.1104444444444443,
      "grad_norm": 0.06095180660486221,
      "learning_rate": 2.223888888888889e-05,
      "loss": 0.0032,
      "step": 49970
    },
    {
      "epoch": 1.1106666666666667,
      "grad_norm": 0.10219570249319077,
      "learning_rate": 2.2233333333333333e-05,
      "loss": 0.0025,
      "step": 49980
    },
    {
      "epoch": 1.1108888888888888,
      "grad_norm": 0.1352761834859848,
      "learning_rate": 2.2227777777777776e-05,
      "loss": 0.0021,
      "step": 49990
    },
    {
      "epoch": 1.1111111111111112,
      "grad_norm": 0.19105516374111176,
      "learning_rate": 2.2222222222222223e-05,
      "loss": 0.002,
      "step": 50000
    },
    {
      "epoch": 1.1113333333333333,
      "grad_norm": 0.0528223030269146,
      "learning_rate": 2.221666666666667e-05,
      "loss": 0.0018,
      "step": 50010
    },
    {
      "epoch": 1.1115555555555556,
      "grad_norm": 0.5300835967063904,
      "learning_rate": 2.2211111111111114e-05,
      "loss": 0.003,
      "step": 50020
    },
    {
      "epoch": 1.1117777777777778,
      "grad_norm": 0.11712411046028137,
      "learning_rate": 2.2205555555555557e-05,
      "loss": 0.0028,
      "step": 50030
    },
    {
      "epoch": 1.112,
      "grad_norm": 0.07865827530622482,
      "learning_rate": 2.22e-05,
      "loss": 0.0021,
      "step": 50040
    },
    {
      "epoch": 1.1122222222222222,
      "grad_norm": 0.4579835832118988,
      "learning_rate": 2.2194444444444444e-05,
      "loss": 0.0018,
      "step": 50050
    },
    {
      "epoch": 1.1124444444444443,
      "grad_norm": 0.14640498161315918,
      "learning_rate": 2.2188888888888888e-05,
      "loss": 0.003,
      "step": 50060
    },
    {
      "epoch": 1.1126666666666667,
      "grad_norm": 0.1975741982460022,
      "learning_rate": 2.2183333333333335e-05,
      "loss": 0.0026,
      "step": 50070
    },
    {
      "epoch": 1.1128888888888888,
      "grad_norm": 0.1731388419866562,
      "learning_rate": 2.217777777777778e-05,
      "loss": 0.0023,
      "step": 50080
    },
    {
      "epoch": 1.1131111111111112,
      "grad_norm": 0.11784485727548599,
      "learning_rate": 2.2172222222222222e-05,
      "loss": 0.0022,
      "step": 50090
    },
    {
      "epoch": 1.1133333333333333,
      "grad_norm": 0.4871600866317749,
      "learning_rate": 2.216666666666667e-05,
      "loss": 0.002,
      "step": 50100
    },
    {
      "epoch": 1.1135555555555556,
      "grad_norm": 0.4162982404232025,
      "learning_rate": 2.2161111111111113e-05,
      "loss": 0.002,
      "step": 50110
    },
    {
      "epoch": 1.1137777777777778,
      "grad_norm": 0.12371610105037689,
      "learning_rate": 2.2155555555555556e-05,
      "loss": 0.0023,
      "step": 50120
    },
    {
      "epoch": 1.114,
      "grad_norm": 0.37218543887138367,
      "learning_rate": 2.215e-05,
      "loss": 0.0024,
      "step": 50130
    },
    {
      "epoch": 1.1142222222222222,
      "grad_norm": 0.09843480587005615,
      "learning_rate": 2.2144444444444447e-05,
      "loss": 0.0024,
      "step": 50140
    },
    {
      "epoch": 1.1144444444444443,
      "grad_norm": 0.10533729195594788,
      "learning_rate": 2.213888888888889e-05,
      "loss": 0.0018,
      "step": 50150
    },
    {
      "epoch": 1.1146666666666667,
      "grad_norm": 0.06094018369913101,
      "learning_rate": 2.2133333333333334e-05,
      "loss": 0.0024,
      "step": 50160
    },
    {
      "epoch": 1.1148888888888888,
      "grad_norm": 0.5826209783554077,
      "learning_rate": 2.2127777777777777e-05,
      "loss": 0.0018,
      "step": 50170
    },
    {
      "epoch": 1.1151111111111112,
      "grad_norm": 0.6083256006240845,
      "learning_rate": 2.212222222222222e-05,
      "loss": 0.002,
      "step": 50180
    },
    {
      "epoch": 1.1153333333333333,
      "grad_norm": 0.20040929317474365,
      "learning_rate": 2.2116666666666668e-05,
      "loss": 0.0029,
      "step": 50190
    },
    {
      "epoch": 1.1155555555555556,
      "grad_norm": 0.17756327986717224,
      "learning_rate": 2.211111111111111e-05,
      "loss": 0.0023,
      "step": 50200
    },
    {
      "epoch": 1.1157777777777778,
      "grad_norm": 0.21841536462306976,
      "learning_rate": 2.2105555555555558e-05,
      "loss": 0.0029,
      "step": 50210
    },
    {
      "epoch": 1.116,
      "grad_norm": 0.13404490053653717,
      "learning_rate": 2.2100000000000002e-05,
      "loss": 0.0018,
      "step": 50220
    },
    {
      "epoch": 1.1162222222222222,
      "grad_norm": 0.23832201957702637,
      "learning_rate": 2.2094444444444445e-05,
      "loss": 0.002,
      "step": 50230
    },
    {
      "epoch": 1.1164444444444444,
      "grad_norm": 0.4429771602153778,
      "learning_rate": 2.208888888888889e-05,
      "loss": 0.0033,
      "step": 50240
    },
    {
      "epoch": 1.1166666666666667,
      "grad_norm": 0.6076470613479614,
      "learning_rate": 2.2083333333333333e-05,
      "loss": 0.0028,
      "step": 50250
    },
    {
      "epoch": 1.1168888888888888,
      "grad_norm": 0.5087706446647644,
      "learning_rate": 2.207777777777778e-05,
      "loss": 0.0021,
      "step": 50260
    },
    {
      "epoch": 1.1171111111111112,
      "grad_norm": 0.6362220644950867,
      "learning_rate": 2.2072222222222223e-05,
      "loss": 0.0032,
      "step": 50270
    },
    {
      "epoch": 1.1173333333333333,
      "grad_norm": 0.2672235369682312,
      "learning_rate": 2.206666666666667e-05,
      "loss": 0.0022,
      "step": 50280
    },
    {
      "epoch": 1.1175555555555556,
      "grad_norm": 0.15715904533863068,
      "learning_rate": 2.2061111111111114e-05,
      "loss": 0.0038,
      "step": 50290
    },
    {
      "epoch": 1.1177777777777778,
      "grad_norm": 0.14361721277236938,
      "learning_rate": 2.2055555555555557e-05,
      "loss": 0.002,
      "step": 50300
    },
    {
      "epoch": 1.1179999999999999,
      "grad_norm": 0.16220438480377197,
      "learning_rate": 2.205e-05,
      "loss": 0.0018,
      "step": 50310
    },
    {
      "epoch": 1.1182222222222222,
      "grad_norm": 0.3341321349143982,
      "learning_rate": 2.2044444444444444e-05,
      "loss": 0.0022,
      "step": 50320
    },
    {
      "epoch": 1.1184444444444444,
      "grad_norm": 0.38636747002601624,
      "learning_rate": 2.203888888888889e-05,
      "loss": 0.0027,
      "step": 50330
    },
    {
      "epoch": 1.1186666666666667,
      "grad_norm": 0.05386945605278015,
      "learning_rate": 2.2033333333333335e-05,
      "loss": 0.0031,
      "step": 50340
    },
    {
      "epoch": 1.1188888888888888,
      "grad_norm": 0.4934667646884918,
      "learning_rate": 2.2027777777777778e-05,
      "loss": 0.0019,
      "step": 50350
    },
    {
      "epoch": 1.1191111111111112,
      "grad_norm": 0.5594040155410767,
      "learning_rate": 2.2022222222222225e-05,
      "loss": 0.0019,
      "step": 50360
    },
    {
      "epoch": 1.1193333333333333,
      "grad_norm": 0.5955455303192139,
      "learning_rate": 2.201666666666667e-05,
      "loss": 0.0019,
      "step": 50370
    },
    {
      "epoch": 1.1195555555555556,
      "grad_norm": 0.4856923222541809,
      "learning_rate": 2.2011111111111112e-05,
      "loss": 0.0024,
      "step": 50380
    },
    {
      "epoch": 1.1197777777777778,
      "grad_norm": 0.21702173352241516,
      "learning_rate": 2.2005555555555556e-05,
      "loss": 0.0024,
      "step": 50390
    },
    {
      "epoch": 1.12,
      "grad_norm": 0.10188984125852585,
      "learning_rate": 2.2000000000000003e-05,
      "loss": 0.0033,
      "step": 50400
    },
    {
      "epoch": 1.1202222222222222,
      "grad_norm": 0.4697573482990265,
      "learning_rate": 2.1994444444444446e-05,
      "loss": 0.002,
      "step": 50410
    },
    {
      "epoch": 1.1204444444444444,
      "grad_norm": 0.3578633666038513,
      "learning_rate": 2.198888888888889e-05,
      "loss": 0.0019,
      "step": 50420
    },
    {
      "epoch": 1.1206666666666667,
      "grad_norm": 0.3138151466846466,
      "learning_rate": 2.1983333333333333e-05,
      "loss": 0.0036,
      "step": 50430
    },
    {
      "epoch": 1.1208888888888888,
      "grad_norm": 0.1039273589849472,
      "learning_rate": 2.1977777777777777e-05,
      "loss": 0.0026,
      "step": 50440
    },
    {
      "epoch": 1.1211111111111112,
      "grad_norm": 0.2356383353471756,
      "learning_rate": 2.1972222222222224e-05,
      "loss": 0.0018,
      "step": 50450
    },
    {
      "epoch": 1.1213333333333333,
      "grad_norm": 0.14182636141777039,
      "learning_rate": 2.1966666666666668e-05,
      "loss": 0.0018,
      "step": 50460
    },
    {
      "epoch": 1.1215555555555556,
      "grad_norm": 0.14774388074874878,
      "learning_rate": 2.1961111111111114e-05,
      "loss": 0.0024,
      "step": 50470
    },
    {
      "epoch": 1.1217777777777778,
      "grad_norm": 0.22054728865623474,
      "learning_rate": 2.1955555555555558e-05,
      "loss": 0.0026,
      "step": 50480
    },
    {
      "epoch": 1.1219999999999999,
      "grad_norm": 0.0939590111374855,
      "learning_rate": 2.195e-05,
      "loss": 0.0029,
      "step": 50490
    },
    {
      "epoch": 1.1222222222222222,
      "grad_norm": 0.06283149123191833,
      "learning_rate": 2.1944444444444445e-05,
      "loss": 0.0027,
      "step": 50500
    },
    {
      "epoch": 1.1224444444444444,
      "grad_norm": 0.0939718708395958,
      "learning_rate": 2.193888888888889e-05,
      "loss": 0.0018,
      "step": 50510
    },
    {
      "epoch": 1.1226666666666667,
      "grad_norm": 0.21990980207920074,
      "learning_rate": 2.1933333333333332e-05,
      "loss": 0.0017,
      "step": 50520
    },
    {
      "epoch": 1.1228888888888888,
      "grad_norm": 0.05298447981476784,
      "learning_rate": 2.192777777777778e-05,
      "loss": 0.0026,
      "step": 50530
    },
    {
      "epoch": 1.1231111111111112,
      "grad_norm": 0.18312174081802368,
      "learning_rate": 2.1922222222222226e-05,
      "loss": 0.0024,
      "step": 50540
    },
    {
      "epoch": 1.1233333333333333,
      "grad_norm": 0.6349513530731201,
      "learning_rate": 2.191666666666667e-05,
      "loss": 0.0018,
      "step": 50550
    },
    {
      "epoch": 1.1235555555555556,
      "grad_norm": 0.2554915249347687,
      "learning_rate": 2.1911111111111113e-05,
      "loss": 0.0024,
      "step": 50560
    },
    {
      "epoch": 1.1237777777777778,
      "grad_norm": 0.47319212555885315,
      "learning_rate": 2.1905555555555557e-05,
      "loss": 0.0025,
      "step": 50570
    },
    {
      "epoch": 1.124,
      "grad_norm": 0.20929652452468872,
      "learning_rate": 2.19e-05,
      "loss": 0.0019,
      "step": 50580
    },
    {
      "epoch": 1.1242222222222222,
      "grad_norm": 0.11386311054229736,
      "learning_rate": 2.1894444444444444e-05,
      "loss": 0.0019,
      "step": 50590
    },
    {
      "epoch": 1.1244444444444444,
      "grad_norm": 0.20428399741649628,
      "learning_rate": 2.188888888888889e-05,
      "loss": 0.0021,
      "step": 50600
    },
    {
      "epoch": 1.1246666666666667,
      "grad_norm": 0.24028243124485016,
      "learning_rate": 2.1883333333333334e-05,
      "loss": 0.0021,
      "step": 50610
    },
    {
      "epoch": 1.1248888888888888,
      "grad_norm": 0.2702142596244812,
      "learning_rate": 2.1877777777777778e-05,
      "loss": 0.0025,
      "step": 50620
    },
    {
      "epoch": 1.1251111111111112,
      "grad_norm": 0.13416101038455963,
      "learning_rate": 2.1872222222222225e-05,
      "loss": 0.0031,
      "step": 50630
    },
    {
      "epoch": 1.1253333333333333,
      "grad_norm": 0.2535625994205475,
      "learning_rate": 2.186666666666667e-05,
      "loss": 0.0021,
      "step": 50640
    },
    {
      "epoch": 1.1255555555555556,
      "grad_norm": 0.323954701423645,
      "learning_rate": 2.1861111111111112e-05,
      "loss": 0.0023,
      "step": 50650
    },
    {
      "epoch": 1.1257777777777778,
      "grad_norm": 0.2624344229698181,
      "learning_rate": 2.1855555555555556e-05,
      "loss": 0.0018,
      "step": 50660
    },
    {
      "epoch": 1.126,
      "grad_norm": 0.1432800590991974,
      "learning_rate": 2.1850000000000003e-05,
      "loss": 0.0019,
      "step": 50670
    },
    {
      "epoch": 1.1262222222222222,
      "grad_norm": 0.05018327757716179,
      "learning_rate": 2.1844444444444446e-05,
      "loss": 0.002,
      "step": 50680
    },
    {
      "epoch": 1.1264444444444444,
      "grad_norm": 0.32856762409210205,
      "learning_rate": 2.183888888888889e-05,
      "loss": 0.0026,
      "step": 50690
    },
    {
      "epoch": 1.1266666666666667,
      "grad_norm": 0.1254936307668686,
      "learning_rate": 2.1833333333333333e-05,
      "loss": 0.0031,
      "step": 50700
    },
    {
      "epoch": 1.1268888888888888,
      "grad_norm": 0.33932608366012573,
      "learning_rate": 2.1827777777777777e-05,
      "loss": 0.0029,
      "step": 50710
    },
    {
      "epoch": 1.1271111111111112,
      "grad_norm": 0.09547404944896698,
      "learning_rate": 2.1822222222222224e-05,
      "loss": 0.0018,
      "step": 50720
    },
    {
      "epoch": 1.1273333333333333,
      "grad_norm": 0.09303401410579681,
      "learning_rate": 2.1816666666666667e-05,
      "loss": 0.0021,
      "step": 50730
    },
    {
      "epoch": 1.1275555555555556,
      "grad_norm": 0.21954819560050964,
      "learning_rate": 2.1811111111111114e-05,
      "loss": 0.002,
      "step": 50740
    },
    {
      "epoch": 1.1277777777777778,
      "grad_norm": 0.24512341618537903,
      "learning_rate": 2.1805555555555558e-05,
      "loss": 0.0023,
      "step": 50750
    },
    {
      "epoch": 1.1280000000000001,
      "grad_norm": 0.2181796431541443,
      "learning_rate": 2.18e-05,
      "loss": 0.0028,
      "step": 50760
    },
    {
      "epoch": 1.1282222222222222,
      "grad_norm": 0.17995871603488922,
      "learning_rate": 2.1794444444444445e-05,
      "loss": 0.0031,
      "step": 50770
    },
    {
      "epoch": 1.1284444444444444,
      "grad_norm": 0.34525632858276367,
      "learning_rate": 2.178888888888889e-05,
      "loss": 0.0024,
      "step": 50780
    },
    {
      "epoch": 1.1286666666666667,
      "grad_norm": 0.2466069757938385,
      "learning_rate": 2.1783333333333332e-05,
      "loss": 0.0019,
      "step": 50790
    },
    {
      "epoch": 1.1288888888888888,
      "grad_norm": 0.29098260402679443,
      "learning_rate": 2.177777777777778e-05,
      "loss": 0.0017,
      "step": 50800
    },
    {
      "epoch": 1.1291111111111112,
      "grad_norm": 0.10258626192808151,
      "learning_rate": 2.1772222222222226e-05,
      "loss": 0.0024,
      "step": 50810
    },
    {
      "epoch": 1.1293333333333333,
      "grad_norm": 0.5420529246330261,
      "learning_rate": 2.176666666666667e-05,
      "loss": 0.0019,
      "step": 50820
    },
    {
      "epoch": 1.1295555555555556,
      "grad_norm": 0.3027617633342743,
      "learning_rate": 2.1761111111111113e-05,
      "loss": 0.0017,
      "step": 50830
    },
    {
      "epoch": 1.1297777777777778,
      "grad_norm": 0.11463603377342224,
      "learning_rate": 2.1755555555555557e-05,
      "loss": 0.0029,
      "step": 50840
    },
    {
      "epoch": 1.13,
      "grad_norm": 0.44922953844070435,
      "learning_rate": 2.175e-05,
      "loss": 0.0019,
      "step": 50850
    },
    {
      "epoch": 1.1302222222222222,
      "grad_norm": 0.3863404393196106,
      "learning_rate": 2.1744444444444444e-05,
      "loss": 0.002,
      "step": 50860
    },
    {
      "epoch": 1.1304444444444444,
      "grad_norm": 0.18855150043964386,
      "learning_rate": 2.173888888888889e-05,
      "loss": 0.0019,
      "step": 50870
    },
    {
      "epoch": 1.1306666666666667,
      "grad_norm": 0.09612017124891281,
      "learning_rate": 2.1733333333333334e-05,
      "loss": 0.0024,
      "step": 50880
    },
    {
      "epoch": 1.1308888888888888,
      "grad_norm": 0.44443562626838684,
      "learning_rate": 2.1727777777777778e-05,
      "loss": 0.0033,
      "step": 50890
    },
    {
      "epoch": 1.1311111111111112,
      "grad_norm": 0.5303711891174316,
      "learning_rate": 2.1722222222222225e-05,
      "loss": 0.0026,
      "step": 50900
    },
    {
      "epoch": 1.1313333333333333,
      "grad_norm": 0.11865747720003128,
      "learning_rate": 2.1716666666666668e-05,
      "loss": 0.0028,
      "step": 50910
    },
    {
      "epoch": 1.1315555555555556,
      "grad_norm": 0.09575799107551575,
      "learning_rate": 2.1711111111111112e-05,
      "loss": 0.002,
      "step": 50920
    },
    {
      "epoch": 1.1317777777777778,
      "grad_norm": 0.05528293922543526,
      "learning_rate": 2.1705555555555555e-05,
      "loss": 0.0019,
      "step": 50930
    },
    {
      "epoch": 1.1320000000000001,
      "grad_norm": 0.23173944652080536,
      "learning_rate": 2.1700000000000002e-05,
      "loss": 0.0022,
      "step": 50940
    },
    {
      "epoch": 1.1322222222222222,
      "grad_norm": 0.4755706489086151,
      "learning_rate": 2.1694444444444446e-05,
      "loss": 0.0021,
      "step": 50950
    },
    {
      "epoch": 1.1324444444444444,
      "grad_norm": 0.09297371655702591,
      "learning_rate": 2.168888888888889e-05,
      "loss": 0.0024,
      "step": 50960
    },
    {
      "epoch": 1.1326666666666667,
      "grad_norm": 0.0920945480465889,
      "learning_rate": 2.1683333333333333e-05,
      "loss": 0.003,
      "step": 50970
    },
    {
      "epoch": 1.1328888888888888,
      "grad_norm": 0.20511023700237274,
      "learning_rate": 2.167777777777778e-05,
      "loss": 0.0021,
      "step": 50980
    },
    {
      "epoch": 1.1331111111111112,
      "grad_norm": 0.404733806848526,
      "learning_rate": 2.1672222222222223e-05,
      "loss": 0.002,
      "step": 50990
    },
    {
      "epoch": 1.1333333333333333,
      "grad_norm": 0.29779285192489624,
      "learning_rate": 2.1666666666666667e-05,
      "loss": 0.0019,
      "step": 51000
    },
    {
      "epoch": 1.1335555555555556,
      "grad_norm": 0.12566225230693817,
      "learning_rate": 2.1661111111111114e-05,
      "loss": 0.003,
      "step": 51010
    },
    {
      "epoch": 1.1337777777777778,
      "grad_norm": 0.06126799434423447,
      "learning_rate": 2.1655555555555558e-05,
      "loss": 0.0022,
      "step": 51020
    },
    {
      "epoch": 1.134,
      "grad_norm": 0.09279461205005646,
      "learning_rate": 2.165e-05,
      "loss": 0.0026,
      "step": 51030
    },
    {
      "epoch": 1.1342222222222222,
      "grad_norm": 0.3020661771297455,
      "learning_rate": 2.1644444444444445e-05,
      "loss": 0.002,
      "step": 51040
    },
    {
      "epoch": 1.1344444444444444,
      "grad_norm": 0.12821903824806213,
      "learning_rate": 2.1638888888888888e-05,
      "loss": 0.0017,
      "step": 51050
    },
    {
      "epoch": 1.1346666666666667,
      "grad_norm": 0.4467408061027527,
      "learning_rate": 2.1633333333333332e-05,
      "loss": 0.0023,
      "step": 51060
    },
    {
      "epoch": 1.1348888888888888,
      "grad_norm": 0.7227435111999512,
      "learning_rate": 2.162777777777778e-05,
      "loss": 0.0019,
      "step": 51070
    },
    {
      "epoch": 1.1351111111111112,
      "grad_norm": 0.29435834288597107,
      "learning_rate": 2.1622222222222226e-05,
      "loss": 0.0033,
      "step": 51080
    },
    {
      "epoch": 1.1353333333333333,
      "grad_norm": 0.3896346092224121,
      "learning_rate": 2.161666666666667e-05,
      "loss": 0.0024,
      "step": 51090
    },
    {
      "epoch": 1.1355555555555557,
      "grad_norm": 0.1024676188826561,
      "learning_rate": 2.1611111111111113e-05,
      "loss": 0.0024,
      "step": 51100
    },
    {
      "epoch": 1.1357777777777778,
      "grad_norm": 0.07754561305046082,
      "learning_rate": 2.1605555555555556e-05,
      "loss": 0.0029,
      "step": 51110
    },
    {
      "epoch": 1.1360000000000001,
      "grad_norm": 0.3717937767505646,
      "learning_rate": 2.16e-05,
      "loss": 0.0039,
      "step": 51120
    },
    {
      "epoch": 1.1362222222222222,
      "grad_norm": 0.547071635723114,
      "learning_rate": 2.1594444444444443e-05,
      "loss": 0.0031,
      "step": 51130
    },
    {
      "epoch": 1.1364444444444444,
      "grad_norm": 0.10334727168083191,
      "learning_rate": 2.158888888888889e-05,
      "loss": 0.0028,
      "step": 51140
    },
    {
      "epoch": 1.1366666666666667,
      "grad_norm": 0.539075493812561,
      "learning_rate": 2.1583333333333334e-05,
      "loss": 0.002,
      "step": 51150
    },
    {
      "epoch": 1.1368888888888888,
      "grad_norm": 0.12613829970359802,
      "learning_rate": 2.157777777777778e-05,
      "loss": 0.0021,
      "step": 51160
    },
    {
      "epoch": 1.1371111111111112,
      "grad_norm": 0.6316206455230713,
      "learning_rate": 2.1572222222222224e-05,
      "loss": 0.002,
      "step": 51170
    },
    {
      "epoch": 1.1373333333333333,
      "grad_norm": 0.4804949462413788,
      "learning_rate": 2.1566666666666668e-05,
      "loss": 0.0018,
      "step": 51180
    },
    {
      "epoch": 1.1375555555555557,
      "grad_norm": 0.09772190451622009,
      "learning_rate": 2.156111111111111e-05,
      "loss": 0.0023,
      "step": 51190
    },
    {
      "epoch": 1.1377777777777778,
      "grad_norm": 0.5573500990867615,
      "learning_rate": 2.1555555555555555e-05,
      "loss": 0.002,
      "step": 51200
    },
    {
      "epoch": 1.138,
      "grad_norm": 0.18227316439151764,
      "learning_rate": 2.1550000000000002e-05,
      "loss": 0.0022,
      "step": 51210
    },
    {
      "epoch": 1.1382222222222222,
      "grad_norm": 0.5522267818450928,
      "learning_rate": 2.1544444444444446e-05,
      "loss": 0.0029,
      "step": 51220
    },
    {
      "epoch": 1.1384444444444444,
      "grad_norm": 0.0648198202252388,
      "learning_rate": 2.153888888888889e-05,
      "loss": 0.0032,
      "step": 51230
    },
    {
      "epoch": 1.1386666666666667,
      "grad_norm": 0.4843840003013611,
      "learning_rate": 2.1533333333333333e-05,
      "loss": 0.002,
      "step": 51240
    },
    {
      "epoch": 1.1388888888888888,
      "grad_norm": 0.3127065598964691,
      "learning_rate": 2.152777777777778e-05,
      "loss": 0.0026,
      "step": 51250
    },
    {
      "epoch": 1.1391111111111112,
      "grad_norm": 0.21718940138816833,
      "learning_rate": 2.1522222222222223e-05,
      "loss": 0.0027,
      "step": 51260
    },
    {
      "epoch": 1.1393333333333333,
      "grad_norm": 0.323569655418396,
      "learning_rate": 2.1516666666666667e-05,
      "loss": 0.0017,
      "step": 51270
    },
    {
      "epoch": 1.1395555555555554,
      "grad_norm": 0.06695841252803802,
      "learning_rate": 2.1511111111111114e-05,
      "loss": 0.0024,
      "step": 51280
    },
    {
      "epoch": 1.1397777777777778,
      "grad_norm": 0.1091524139046669,
      "learning_rate": 2.1505555555555557e-05,
      "loss": 0.0021,
      "step": 51290
    },
    {
      "epoch": 1.1400000000000001,
      "grad_norm": 0.4959665536880493,
      "learning_rate": 2.15e-05,
      "loss": 0.0021,
      "step": 51300
    },
    {
      "epoch": 1.1402222222222222,
      "grad_norm": 0.33976033329963684,
      "learning_rate": 2.1494444444444444e-05,
      "loss": 0.0021,
      "step": 51310
    },
    {
      "epoch": 1.1404444444444444,
      "grad_norm": 0.3254336416721344,
      "learning_rate": 2.1488888888888888e-05,
      "loss": 0.0021,
      "step": 51320
    },
    {
      "epoch": 1.1406666666666667,
      "grad_norm": 0.10539185255765915,
      "learning_rate": 2.148333333333333e-05,
      "loss": 0.0023,
      "step": 51330
    },
    {
      "epoch": 1.1408888888888888,
      "grad_norm": 0.36835575103759766,
      "learning_rate": 2.147777777777778e-05,
      "loss": 0.0024,
      "step": 51340
    },
    {
      "epoch": 1.1411111111111112,
      "grad_norm": 0.165157750248909,
      "learning_rate": 2.1472222222222225e-05,
      "loss": 0.0032,
      "step": 51350
    },
    {
      "epoch": 1.1413333333333333,
      "grad_norm": 0.38281309604644775,
      "learning_rate": 2.146666666666667e-05,
      "loss": 0.002,
      "step": 51360
    },
    {
      "epoch": 1.1415555555555557,
      "grad_norm": 0.06579451262950897,
      "learning_rate": 2.1461111111111112e-05,
      "loss": 0.0034,
      "step": 51370
    },
    {
      "epoch": 1.1417777777777778,
      "grad_norm": 0.2456492930650711,
      "learning_rate": 2.1455555555555556e-05,
      "loss": 0.002,
      "step": 51380
    },
    {
      "epoch": 1.142,
      "grad_norm": 0.44785428047180176,
      "learning_rate": 2.145e-05,
      "loss": 0.003,
      "step": 51390
    },
    {
      "epoch": 1.1422222222222222,
      "grad_norm": 0.35377177596092224,
      "learning_rate": 2.1444444444444443e-05,
      "loss": 0.0019,
      "step": 51400
    },
    {
      "epoch": 1.1424444444444444,
      "grad_norm": 0.25780680775642395,
      "learning_rate": 2.143888888888889e-05,
      "loss": 0.0022,
      "step": 51410
    },
    {
      "epoch": 1.1426666666666667,
      "grad_norm": 0.429764062166214,
      "learning_rate": 2.1433333333333334e-05,
      "loss": 0.002,
      "step": 51420
    },
    {
      "epoch": 1.1428888888888888,
      "grad_norm": 0.2899225652217865,
      "learning_rate": 2.142777777777778e-05,
      "loss": 0.0026,
      "step": 51430
    },
    {
      "epoch": 1.1431111111111112,
      "grad_norm": 0.3149779140949249,
      "learning_rate": 2.1422222222222224e-05,
      "loss": 0.002,
      "step": 51440
    },
    {
      "epoch": 1.1433333333333333,
      "grad_norm": 0.38871610164642334,
      "learning_rate": 2.1416666666666668e-05,
      "loss": 0.0021,
      "step": 51450
    },
    {
      "epoch": 1.1435555555555554,
      "grad_norm": 0.17912639677524567,
      "learning_rate": 2.141111111111111e-05,
      "loss": 0.002,
      "step": 51460
    },
    {
      "epoch": 1.1437777777777778,
      "grad_norm": 0.2524077296257019,
      "learning_rate": 2.1405555555555555e-05,
      "loss": 0.002,
      "step": 51470
    },
    {
      "epoch": 1.144,
      "grad_norm": 0.1432161182165146,
      "learning_rate": 2.1400000000000002e-05,
      "loss": 0.0024,
      "step": 51480
    },
    {
      "epoch": 1.1442222222222223,
      "grad_norm": 0.06373676657676697,
      "learning_rate": 2.1394444444444445e-05,
      "loss": 0.0018,
      "step": 51490
    },
    {
      "epoch": 1.1444444444444444,
      "grad_norm": 0.24186168611049652,
      "learning_rate": 2.138888888888889e-05,
      "loss": 0.0025,
      "step": 51500
    },
    {
      "epoch": 1.1446666666666667,
      "grad_norm": 0.5447813272476196,
      "learning_rate": 2.1383333333333332e-05,
      "loss": 0.0021,
      "step": 51510
    },
    {
      "epoch": 1.1448888888888888,
      "grad_norm": 0.10823585093021393,
      "learning_rate": 2.137777777777778e-05,
      "loss": 0.0032,
      "step": 51520
    },
    {
      "epoch": 1.1451111111111112,
      "grad_norm": 0.1610163301229477,
      "learning_rate": 2.1372222222222223e-05,
      "loss": 0.003,
      "step": 51530
    },
    {
      "epoch": 1.1453333333333333,
      "grad_norm": 0.08769521117210388,
      "learning_rate": 2.1366666666666667e-05,
      "loss": 0.0022,
      "step": 51540
    },
    {
      "epoch": 1.1455555555555557,
      "grad_norm": 0.6188486218452454,
      "learning_rate": 2.1361111111111113e-05,
      "loss": 0.0021,
      "step": 51550
    },
    {
      "epoch": 1.1457777777777778,
      "grad_norm": 0.2022385150194168,
      "learning_rate": 2.1355555555555557e-05,
      "loss": 0.0024,
      "step": 51560
    },
    {
      "epoch": 1.146,
      "grad_norm": 0.2399953305721283,
      "learning_rate": 2.135e-05,
      "loss": 0.0019,
      "step": 51570
    },
    {
      "epoch": 1.1462222222222223,
      "grad_norm": 0.1530432552099228,
      "learning_rate": 2.1344444444444444e-05,
      "loss": 0.002,
      "step": 51580
    },
    {
      "epoch": 1.1464444444444444,
      "grad_norm": 0.0653996467590332,
      "learning_rate": 2.1338888888888888e-05,
      "loss": 0.0019,
      "step": 51590
    },
    {
      "epoch": 1.1466666666666667,
      "grad_norm": 0.16248151659965515,
      "learning_rate": 2.1333333333333335e-05,
      "loss": 0.0017,
      "step": 51600
    },
    {
      "epoch": 1.1468888888888888,
      "grad_norm": 0.32155656814575195,
      "learning_rate": 2.1327777777777778e-05,
      "loss": 0.0025,
      "step": 51610
    },
    {
      "epoch": 1.1471111111111112,
      "grad_norm": 0.20242148637771606,
      "learning_rate": 2.1322222222222225e-05,
      "loss": 0.0016,
      "step": 51620
    },
    {
      "epoch": 1.1473333333333333,
      "grad_norm": 0.15397483110427856,
      "learning_rate": 2.131666666666667e-05,
      "loss": 0.0019,
      "step": 51630
    },
    {
      "epoch": 1.1475555555555554,
      "grad_norm": 0.0975908562541008,
      "learning_rate": 2.1311111111111112e-05,
      "loss": 0.0029,
      "step": 51640
    },
    {
      "epoch": 1.1477777777777778,
      "grad_norm": 0.31916218996047974,
      "learning_rate": 2.1305555555555556e-05,
      "loss": 0.0017,
      "step": 51650
    },
    {
      "epoch": 1.148,
      "grad_norm": 0.371924489736557,
      "learning_rate": 2.13e-05,
      "loss": 0.0032,
      "step": 51660
    },
    {
      "epoch": 1.1482222222222223,
      "grad_norm": 0.3743358254432678,
      "learning_rate": 2.1294444444444446e-05,
      "loss": 0.0018,
      "step": 51670
    },
    {
      "epoch": 1.1484444444444444,
      "grad_norm": 0.26731076836586,
      "learning_rate": 2.128888888888889e-05,
      "loss": 0.002,
      "step": 51680
    },
    {
      "epoch": 1.1486666666666667,
      "grad_norm": 0.12249990552663803,
      "learning_rate": 2.1283333333333337e-05,
      "loss": 0.0027,
      "step": 51690
    },
    {
      "epoch": 1.1488888888888888,
      "grad_norm": 0.17112421989440918,
      "learning_rate": 2.127777777777778e-05,
      "loss": 0.0021,
      "step": 51700
    },
    {
      "epoch": 1.1491111111111112,
      "grad_norm": 0.17419704794883728,
      "learning_rate": 2.1272222222222224e-05,
      "loss": 0.0022,
      "step": 51710
    },
    {
      "epoch": 1.1493333333333333,
      "grad_norm": 0.1374390870332718,
      "learning_rate": 2.1266666666666667e-05,
      "loss": 0.002,
      "step": 51720
    },
    {
      "epoch": 1.1495555555555557,
      "grad_norm": 0.4161626398563385,
      "learning_rate": 2.126111111111111e-05,
      "loss": 0.0031,
      "step": 51730
    },
    {
      "epoch": 1.1497777777777778,
      "grad_norm": 0.1703791469335556,
      "learning_rate": 2.1255555555555558e-05,
      "loss": 0.0022,
      "step": 51740
    },
    {
      "epoch": 1.15,
      "grad_norm": 0.20702868700027466,
      "learning_rate": 2.125e-05,
      "loss": 0.002,
      "step": 51750
    },
    {
      "epoch": 1.1502222222222223,
      "grad_norm": 0.27612048387527466,
      "learning_rate": 2.1244444444444445e-05,
      "loss": 0.0019,
      "step": 51760
    },
    {
      "epoch": 1.1504444444444444,
      "grad_norm": 0.3676159679889679,
      "learning_rate": 2.123888888888889e-05,
      "loss": 0.0022,
      "step": 51770
    },
    {
      "epoch": 1.1506666666666667,
      "grad_norm": 0.14923009276390076,
      "learning_rate": 2.1233333333333336e-05,
      "loss": 0.0024,
      "step": 51780
    },
    {
      "epoch": 1.1508888888888889,
      "grad_norm": 0.24454669654369354,
      "learning_rate": 2.122777777777778e-05,
      "loss": 0.0018,
      "step": 51790
    },
    {
      "epoch": 1.1511111111111112,
      "grad_norm": 0.4389552175998688,
      "learning_rate": 2.1222222222222223e-05,
      "loss": 0.0019,
      "step": 51800
    },
    {
      "epoch": 1.1513333333333333,
      "grad_norm": 0.09218896180391312,
      "learning_rate": 2.121666666666667e-05,
      "loss": 0.0031,
      "step": 51810
    },
    {
      "epoch": 1.1515555555555554,
      "grad_norm": 0.07845675200223923,
      "learning_rate": 2.1211111111111113e-05,
      "loss": 0.0029,
      "step": 51820
    },
    {
      "epoch": 1.1517777777777778,
      "grad_norm": 0.13608597218990326,
      "learning_rate": 2.1205555555555557e-05,
      "loss": 0.0027,
      "step": 51830
    },
    {
      "epoch": 1.152,
      "grad_norm": 0.22989074885845184,
      "learning_rate": 2.12e-05,
      "loss": 0.0025,
      "step": 51840
    },
    {
      "epoch": 1.1522222222222223,
      "grad_norm": 0.4285110533237457,
      "learning_rate": 2.1194444444444444e-05,
      "loss": 0.0023,
      "step": 51850
    },
    {
      "epoch": 1.1524444444444444,
      "grad_norm": 0.16353438794612885,
      "learning_rate": 2.1188888888888887e-05,
      "loss": 0.0027,
      "step": 51860
    },
    {
      "epoch": 1.1526666666666667,
      "grad_norm": 0.5769596695899963,
      "learning_rate": 2.1183333333333334e-05,
      "loss": 0.0022,
      "step": 51870
    },
    {
      "epoch": 1.1528888888888889,
      "grad_norm": 0.31378981471061707,
      "learning_rate": 2.117777777777778e-05,
      "loss": 0.0015,
      "step": 51880
    },
    {
      "epoch": 1.1531111111111112,
      "grad_norm": 0.06744684278964996,
      "learning_rate": 2.1172222222222225e-05,
      "loss": 0.0026,
      "step": 51890
    },
    {
      "epoch": 1.1533333333333333,
      "grad_norm": 0.24765561521053314,
      "learning_rate": 2.116666666666667e-05,
      "loss": 0.0025,
      "step": 51900
    },
    {
      "epoch": 1.1535555555555557,
      "grad_norm": 0.5569843053817749,
      "learning_rate": 2.1161111111111112e-05,
      "loss": 0.002,
      "step": 51910
    },
    {
      "epoch": 1.1537777777777778,
      "grad_norm": 0.3348141312599182,
      "learning_rate": 2.1155555555555556e-05,
      "loss": 0.0019,
      "step": 51920
    },
    {
      "epoch": 1.154,
      "grad_norm": 0.11207743734121323,
      "learning_rate": 2.115e-05,
      "loss": 0.002,
      "step": 51930
    },
    {
      "epoch": 1.1542222222222223,
      "grad_norm": 0.4299063980579376,
      "learning_rate": 2.1144444444444446e-05,
      "loss": 0.0025,
      "step": 51940
    },
    {
      "epoch": 1.1544444444444444,
      "grad_norm": 0.2618795931339264,
      "learning_rate": 2.113888888888889e-05,
      "loss": 0.0025,
      "step": 51950
    },
    {
      "epoch": 1.1546666666666667,
      "grad_norm": 0.5106733441352844,
      "learning_rate": 2.1133333333333337e-05,
      "loss": 0.0025,
      "step": 51960
    },
    {
      "epoch": 1.1548888888888889,
      "grad_norm": 0.4231312870979309,
      "learning_rate": 2.112777777777778e-05,
      "loss": 0.0018,
      "step": 51970
    },
    {
      "epoch": 1.1551111111111112,
      "grad_norm": 0.3416862487792969,
      "learning_rate": 2.1122222222222224e-05,
      "loss": 0.0028,
      "step": 51980
    },
    {
      "epoch": 1.1553333333333333,
      "grad_norm": 0.11134883016347885,
      "learning_rate": 2.1116666666666667e-05,
      "loss": 0.0021,
      "step": 51990
    },
    {
      "epoch": 1.1555555555555554,
      "grad_norm": 0.41782236099243164,
      "learning_rate": 2.111111111111111e-05,
      "loss": 0.0018,
      "step": 52000
    },
    {
      "epoch": 1.1557777777777778,
      "grad_norm": 0.4456856846809387,
      "learning_rate": 2.1105555555555558e-05,
      "loss": 0.0024,
      "step": 52010
    },
    {
      "epoch": 1.156,
      "grad_norm": 0.3087708353996277,
      "learning_rate": 2.11e-05,
      "loss": 0.0017,
      "step": 52020
    },
    {
      "epoch": 1.1562222222222223,
      "grad_norm": 0.3600914180278778,
      "learning_rate": 2.1094444444444445e-05,
      "loss": 0.0024,
      "step": 52030
    },
    {
      "epoch": 1.1564444444444444,
      "grad_norm": 0.37844985723495483,
      "learning_rate": 2.108888888888889e-05,
      "loss": 0.0016,
      "step": 52040
    },
    {
      "epoch": 1.1566666666666667,
      "grad_norm": 0.10939501971006393,
      "learning_rate": 2.1083333333333335e-05,
      "loss": 0.0018,
      "step": 52050
    },
    {
      "epoch": 1.1568888888888889,
      "grad_norm": 0.19493429362773895,
      "learning_rate": 2.107777777777778e-05,
      "loss": 0.0016,
      "step": 52060
    },
    {
      "epoch": 1.1571111111111112,
      "grad_norm": 0.4669581353664398,
      "learning_rate": 2.1072222222222222e-05,
      "loss": 0.002,
      "step": 52070
    },
    {
      "epoch": 1.1573333333333333,
      "grad_norm": 0.24815300107002258,
      "learning_rate": 2.106666666666667e-05,
      "loss": 0.0019,
      "step": 52080
    },
    {
      "epoch": 1.1575555555555557,
      "grad_norm": 0.34314876794815063,
      "learning_rate": 2.1061111111111113e-05,
      "loss": 0.0035,
      "step": 52090
    },
    {
      "epoch": 1.1577777777777778,
      "grad_norm": 0.11473187059164047,
      "learning_rate": 2.1055555555555556e-05,
      "loss": 0.003,
      "step": 52100
    },
    {
      "epoch": 1.158,
      "grad_norm": 0.06332339346408844,
      "learning_rate": 2.105e-05,
      "loss": 0.0019,
      "step": 52110
    },
    {
      "epoch": 1.1582222222222223,
      "grad_norm": 0.10272962599992752,
      "learning_rate": 2.1044444444444444e-05,
      "loss": 0.0018,
      "step": 52120
    },
    {
      "epoch": 1.1584444444444444,
      "grad_norm": 0.17639169096946716,
      "learning_rate": 2.1038888888888887e-05,
      "loss": 0.0023,
      "step": 52130
    },
    {
      "epoch": 1.1586666666666667,
      "grad_norm": 0.10640128701925278,
      "learning_rate": 2.1033333333333334e-05,
      "loss": 0.0019,
      "step": 52140
    },
    {
      "epoch": 1.1588888888888889,
      "grad_norm": 0.0666438639163971,
      "learning_rate": 2.102777777777778e-05,
      "loss": 0.0018,
      "step": 52150
    },
    {
      "epoch": 1.1591111111111112,
      "grad_norm": 0.2194034606218338,
      "learning_rate": 2.1022222222222225e-05,
      "loss": 0.0021,
      "step": 52160
    },
    {
      "epoch": 1.1593333333333333,
      "grad_norm": 0.08727246522903442,
      "learning_rate": 2.1016666666666668e-05,
      "loss": 0.0022,
      "step": 52170
    },
    {
      "epoch": 1.1595555555555555,
      "grad_norm": 0.2859007716178894,
      "learning_rate": 2.1011111111111112e-05,
      "loss": 0.0021,
      "step": 52180
    },
    {
      "epoch": 1.1597777777777778,
      "grad_norm": 0.18712979555130005,
      "learning_rate": 2.1005555555555555e-05,
      "loss": 0.0023,
      "step": 52190
    },
    {
      "epoch": 1.16,
      "grad_norm": 0.07294122874736786,
      "learning_rate": 2.1e-05,
      "loss": 0.0022,
      "step": 52200
    },
    {
      "epoch": 1.1602222222222223,
      "grad_norm": 0.14761194586753845,
      "learning_rate": 2.0994444444444446e-05,
      "loss": 0.0025,
      "step": 52210
    },
    {
      "epoch": 1.1604444444444444,
      "grad_norm": 0.43030601739883423,
      "learning_rate": 2.0988888888888893e-05,
      "loss": 0.002,
      "step": 52220
    },
    {
      "epoch": 1.1606666666666667,
      "grad_norm": 0.1405085027217865,
      "learning_rate": 2.0983333333333336e-05,
      "loss": 0.0018,
      "step": 52230
    },
    {
      "epoch": 1.1608888888888889,
      "grad_norm": 0.10492388159036636,
      "learning_rate": 2.097777777777778e-05,
      "loss": 0.0027,
      "step": 52240
    },
    {
      "epoch": 1.1611111111111112,
      "grad_norm": 0.3499473035335541,
      "learning_rate": 2.0972222222222223e-05,
      "loss": 0.0017,
      "step": 52250
    },
    {
      "epoch": 1.1613333333333333,
      "grad_norm": 0.09331439435482025,
      "learning_rate": 2.0966666666666667e-05,
      "loss": 0.0021,
      "step": 52260
    },
    {
      "epoch": 1.1615555555555557,
      "grad_norm": 0.09865998476743698,
      "learning_rate": 2.096111111111111e-05,
      "loss": 0.0019,
      "step": 52270
    },
    {
      "epoch": 1.1617777777777778,
      "grad_norm": 0.31456807255744934,
      "learning_rate": 2.0955555555555557e-05,
      "loss": 0.0023,
      "step": 52280
    },
    {
      "epoch": 1.162,
      "grad_norm": 0.5524133443832397,
      "learning_rate": 2.095e-05,
      "loss": 0.002,
      "step": 52290
    },
    {
      "epoch": 1.1622222222222223,
      "grad_norm": 0.5280352234840393,
      "learning_rate": 2.0944444444444445e-05,
      "loss": 0.0016,
      "step": 52300
    },
    {
      "epoch": 1.1624444444444444,
      "grad_norm": 0.29763558506965637,
      "learning_rate": 2.093888888888889e-05,
      "loss": 0.002,
      "step": 52310
    },
    {
      "epoch": 1.1626666666666667,
      "grad_norm": 0.07742918282747269,
      "learning_rate": 2.0933333333333335e-05,
      "loss": 0.0016,
      "step": 52320
    },
    {
      "epoch": 1.1628888888888889,
      "grad_norm": 0.6363571882247925,
      "learning_rate": 2.092777777777778e-05,
      "loss": 0.0026,
      "step": 52330
    },
    {
      "epoch": 1.1631111111111112,
      "grad_norm": 0.49797412753105164,
      "learning_rate": 2.0922222222222222e-05,
      "loss": 0.0018,
      "step": 52340
    },
    {
      "epoch": 1.1633333333333333,
      "grad_norm": 0.3138190507888794,
      "learning_rate": 2.091666666666667e-05,
      "loss": 0.0028,
      "step": 52350
    },
    {
      "epoch": 1.1635555555555555,
      "grad_norm": 0.6094903349876404,
      "learning_rate": 2.0911111111111113e-05,
      "loss": 0.0022,
      "step": 52360
    },
    {
      "epoch": 1.1637777777777778,
      "grad_norm": 0.4474157691001892,
      "learning_rate": 2.0905555555555556e-05,
      "loss": 0.0022,
      "step": 52370
    },
    {
      "epoch": 1.164,
      "grad_norm": 0.551154613494873,
      "learning_rate": 2.09e-05,
      "loss": 0.0019,
      "step": 52380
    },
    {
      "epoch": 1.1642222222222223,
      "grad_norm": 0.10224215686321259,
      "learning_rate": 2.0894444444444443e-05,
      "loss": 0.0027,
      "step": 52390
    },
    {
      "epoch": 1.1644444444444444,
      "grad_norm": 0.28351160883903503,
      "learning_rate": 2.088888888888889e-05,
      "loss": 0.0028,
      "step": 52400
    },
    {
      "epoch": 1.1646666666666667,
      "grad_norm": 0.40230298042297363,
      "learning_rate": 2.0883333333333334e-05,
      "loss": 0.0031,
      "step": 52410
    },
    {
      "epoch": 1.1648888888888889,
      "grad_norm": 0.3839239180088043,
      "learning_rate": 2.087777777777778e-05,
      "loss": 0.0026,
      "step": 52420
    },
    {
      "epoch": 1.165111111111111,
      "grad_norm": 0.15620821714401245,
      "learning_rate": 2.0872222222222224e-05,
      "loss": 0.0019,
      "step": 52430
    },
    {
      "epoch": 1.1653333333333333,
      "grad_norm": 0.0883888304233551,
      "learning_rate": 2.0866666666666668e-05,
      "loss": 0.0016,
      "step": 52440
    },
    {
      "epoch": 1.1655555555555557,
      "grad_norm": 0.2575445771217346,
      "learning_rate": 2.086111111111111e-05,
      "loss": 0.0018,
      "step": 52450
    },
    {
      "epoch": 1.1657777777777778,
      "grad_norm": 0.4736053943634033,
      "learning_rate": 2.0855555555555555e-05,
      "loss": 0.0017,
      "step": 52460
    },
    {
      "epoch": 1.166,
      "grad_norm": 0.06964901089668274,
      "learning_rate": 2.085e-05,
      "loss": 0.002,
      "step": 52470
    },
    {
      "epoch": 1.1662222222222223,
      "grad_norm": 0.42785704135894775,
      "learning_rate": 2.0844444444444446e-05,
      "loss": 0.003,
      "step": 52480
    },
    {
      "epoch": 1.1664444444444444,
      "grad_norm": 0.19330386817455292,
      "learning_rate": 2.0838888888888892e-05,
      "loss": 0.0021,
      "step": 52490
    },
    {
      "epoch": 1.1666666666666667,
      "grad_norm": 0.1605127453804016,
      "learning_rate": 2.0833333333333336e-05,
      "loss": 0.0019,
      "step": 52500
    },
    {
      "epoch": 1.1668888888888889,
      "grad_norm": 0.07440442591905594,
      "learning_rate": 2.082777777777778e-05,
      "loss": 0.0029,
      "step": 52510
    },
    {
      "epoch": 1.1671111111111112,
      "grad_norm": 0.06522833555936813,
      "learning_rate": 2.0822222222222223e-05,
      "loss": 0.0019,
      "step": 52520
    },
    {
      "epoch": 1.1673333333333333,
      "grad_norm": 0.22716264426708221,
      "learning_rate": 2.0816666666666667e-05,
      "loss": 0.0023,
      "step": 52530
    },
    {
      "epoch": 1.1675555555555555,
      "grad_norm": 0.4679494798183441,
      "learning_rate": 2.081111111111111e-05,
      "loss": 0.0023,
      "step": 52540
    },
    {
      "epoch": 1.1677777777777778,
      "grad_norm": 0.06467945873737335,
      "learning_rate": 2.0805555555555557e-05,
      "loss": 0.0033,
      "step": 52550
    },
    {
      "epoch": 1.168,
      "grad_norm": 0.203250452876091,
      "learning_rate": 2.08e-05,
      "loss": 0.0018,
      "step": 52560
    },
    {
      "epoch": 1.1682222222222223,
      "grad_norm": 0.14315256476402283,
      "learning_rate": 2.0794444444444444e-05,
      "loss": 0.0023,
      "step": 52570
    },
    {
      "epoch": 1.1684444444444444,
      "grad_norm": 0.26259079575538635,
      "learning_rate": 2.078888888888889e-05,
      "loss": 0.0029,
      "step": 52580
    },
    {
      "epoch": 1.1686666666666667,
      "grad_norm": 0.08712983876466751,
      "learning_rate": 2.0783333333333335e-05,
      "loss": 0.0021,
      "step": 52590
    },
    {
      "epoch": 1.1688888888888889,
      "grad_norm": 0.06720598042011261,
      "learning_rate": 2.077777777777778e-05,
      "loss": 0.0018,
      "step": 52600
    },
    {
      "epoch": 1.169111111111111,
      "grad_norm": 0.24591313302516937,
      "learning_rate": 2.0772222222222222e-05,
      "loss": 0.0028,
      "step": 52610
    },
    {
      "epoch": 1.1693333333333333,
      "grad_norm": 0.45207029581069946,
      "learning_rate": 2.076666666666667e-05,
      "loss": 0.0022,
      "step": 52620
    },
    {
      "epoch": 1.1695555555555555,
      "grad_norm": 0.05217441916465759,
      "learning_rate": 2.0761111111111112e-05,
      "loss": 0.0036,
      "step": 52630
    },
    {
      "epoch": 1.1697777777777778,
      "grad_norm": 0.3287484645843506,
      "learning_rate": 2.0755555555555556e-05,
      "loss": 0.002,
      "step": 52640
    },
    {
      "epoch": 1.17,
      "grad_norm": 0.23084913194179535,
      "learning_rate": 2.075e-05,
      "loss": 0.0024,
      "step": 52650
    },
    {
      "epoch": 1.1702222222222223,
      "grad_norm": 0.07284530252218246,
      "learning_rate": 2.0744444444444443e-05,
      "loss": 0.0019,
      "step": 52660
    },
    {
      "epoch": 1.1704444444444444,
      "grad_norm": 0.44525083899497986,
      "learning_rate": 2.073888888888889e-05,
      "loss": 0.002,
      "step": 52670
    },
    {
      "epoch": 1.1706666666666667,
      "grad_norm": 0.4128521978855133,
      "learning_rate": 2.0733333333333334e-05,
      "loss": 0.0021,
      "step": 52680
    },
    {
      "epoch": 1.1708888888888889,
      "grad_norm": 0.2878675162792206,
      "learning_rate": 2.072777777777778e-05,
      "loss": 0.0018,
      "step": 52690
    },
    {
      "epoch": 1.1711111111111112,
      "grad_norm": 0.5550253987312317,
      "learning_rate": 2.0722222222222224e-05,
      "loss": 0.0027,
      "step": 52700
    },
    {
      "epoch": 1.1713333333333333,
      "grad_norm": 0.5030210614204407,
      "learning_rate": 2.0716666666666668e-05,
      "loss": 0.0021,
      "step": 52710
    },
    {
      "epoch": 1.1715555555555555,
      "grad_norm": 0.17706415057182312,
      "learning_rate": 2.071111111111111e-05,
      "loss": 0.0024,
      "step": 52720
    },
    {
      "epoch": 1.1717777777777778,
      "grad_norm": 0.13080795109272003,
      "learning_rate": 2.0705555555555555e-05,
      "loss": 0.002,
      "step": 52730
    },
    {
      "epoch": 1.172,
      "grad_norm": 0.234640434384346,
      "learning_rate": 2.07e-05,
      "loss": 0.0018,
      "step": 52740
    },
    {
      "epoch": 1.1722222222222223,
      "grad_norm": 0.2978998124599457,
      "learning_rate": 2.0694444444444445e-05,
      "loss": 0.0024,
      "step": 52750
    },
    {
      "epoch": 1.1724444444444444,
      "grad_norm": 0.24986860156059265,
      "learning_rate": 2.0688888888888892e-05,
      "loss": 0.0017,
      "step": 52760
    },
    {
      "epoch": 1.1726666666666667,
      "grad_norm": 0.16620036959648132,
      "learning_rate": 2.0683333333333336e-05,
      "loss": 0.0021,
      "step": 52770
    },
    {
      "epoch": 1.1728888888888889,
      "grad_norm": 0.4998413324356079,
      "learning_rate": 2.067777777777778e-05,
      "loss": 0.0023,
      "step": 52780
    },
    {
      "epoch": 1.173111111111111,
      "grad_norm": 0.08389173448085785,
      "learning_rate": 2.0672222222222223e-05,
      "loss": 0.0016,
      "step": 52790
    },
    {
      "epoch": 1.1733333333333333,
      "grad_norm": 0.16444958746433258,
      "learning_rate": 2.0666666666666666e-05,
      "loss": 0.0028,
      "step": 52800
    },
    {
      "epoch": 1.1735555555555555,
      "grad_norm": 0.11984702199697495,
      "learning_rate": 2.066111111111111e-05,
      "loss": 0.0022,
      "step": 52810
    },
    {
      "epoch": 1.1737777777777778,
      "grad_norm": 0.06112224608659744,
      "learning_rate": 2.0655555555555557e-05,
      "loss": 0.0024,
      "step": 52820
    },
    {
      "epoch": 1.174,
      "grad_norm": 0.48918455839157104,
      "learning_rate": 2.065e-05,
      "loss": 0.0024,
      "step": 52830
    },
    {
      "epoch": 1.1742222222222223,
      "grad_norm": 0.12021825462579727,
      "learning_rate": 2.0644444444444447e-05,
      "loss": 0.0021,
      "step": 52840
    },
    {
      "epoch": 1.1744444444444444,
      "grad_norm": 0.09190912544727325,
      "learning_rate": 2.063888888888889e-05,
      "loss": 0.0035,
      "step": 52850
    },
    {
      "epoch": 1.1746666666666667,
      "grad_norm": 0.4075722098350525,
      "learning_rate": 2.0633333333333335e-05,
      "loss": 0.0029,
      "step": 52860
    },
    {
      "epoch": 1.1748888888888889,
      "grad_norm": 0.2997337281703949,
      "learning_rate": 2.0627777777777778e-05,
      "loss": 0.0021,
      "step": 52870
    },
    {
      "epoch": 1.1751111111111112,
      "grad_norm": 0.06697434186935425,
      "learning_rate": 2.062222222222222e-05,
      "loss": 0.0027,
      "step": 52880
    },
    {
      "epoch": 1.1753333333333333,
      "grad_norm": 0.19831852614879608,
      "learning_rate": 2.061666666666667e-05,
      "loss": 0.0023,
      "step": 52890
    },
    {
      "epoch": 1.1755555555555555,
      "grad_norm": 0.05560464784502983,
      "learning_rate": 2.0611111111111112e-05,
      "loss": 0.0018,
      "step": 52900
    },
    {
      "epoch": 1.1757777777777778,
      "grad_norm": 0.1932554543018341,
      "learning_rate": 2.0605555555555556e-05,
      "loss": 0.0026,
      "step": 52910
    },
    {
      "epoch": 1.176,
      "grad_norm": 0.1496979147195816,
      "learning_rate": 2.06e-05,
      "loss": 0.002,
      "step": 52920
    },
    {
      "epoch": 1.1762222222222223,
      "grad_norm": 0.16059079766273499,
      "learning_rate": 2.0594444444444446e-05,
      "loss": 0.0019,
      "step": 52930
    },
    {
      "epoch": 1.1764444444444444,
      "grad_norm": 0.4451283812522888,
      "learning_rate": 2.058888888888889e-05,
      "loss": 0.002,
      "step": 52940
    },
    {
      "epoch": 1.1766666666666667,
      "grad_norm": 0.44020843505859375,
      "learning_rate": 2.0583333333333333e-05,
      "loss": 0.0017,
      "step": 52950
    },
    {
      "epoch": 1.1768888888888889,
      "grad_norm": 0.7153042554855347,
      "learning_rate": 2.057777777777778e-05,
      "loss": 0.0022,
      "step": 52960
    },
    {
      "epoch": 1.177111111111111,
      "grad_norm": 0.0753960907459259,
      "learning_rate": 2.0572222222222224e-05,
      "loss": 0.0025,
      "step": 52970
    },
    {
      "epoch": 1.1773333333333333,
      "grad_norm": 0.26436281204223633,
      "learning_rate": 2.0566666666666667e-05,
      "loss": 0.0018,
      "step": 52980
    },
    {
      "epoch": 1.1775555555555555,
      "grad_norm": 0.31995150446891785,
      "learning_rate": 2.056111111111111e-05,
      "loss": 0.002,
      "step": 52990
    },
    {
      "epoch": 1.1777777777777778,
      "grad_norm": 0.3856333792209625,
      "learning_rate": 2.0555555555555555e-05,
      "loss": 0.0019,
      "step": 53000
    },
    {
      "epoch": 1.178,
      "grad_norm": 0.2895266115665436,
      "learning_rate": 2.055e-05,
      "loss": 0.002,
      "step": 53010
    },
    {
      "epoch": 1.1782222222222223,
      "grad_norm": 0.1350991576910019,
      "learning_rate": 2.054444444444445e-05,
      "loss": 0.0024,
      "step": 53020
    },
    {
      "epoch": 1.1784444444444444,
      "grad_norm": 0.09340626001358032,
      "learning_rate": 2.0538888888888892e-05,
      "loss": 0.0018,
      "step": 53030
    },
    {
      "epoch": 1.1786666666666668,
      "grad_norm": 0.33861055970191956,
      "learning_rate": 2.0533333333333336e-05,
      "loss": 0.0026,
      "step": 53040
    },
    {
      "epoch": 1.1788888888888889,
      "grad_norm": 0.38921618461608887,
      "learning_rate": 2.052777777777778e-05,
      "loss": 0.0018,
      "step": 53050
    },
    {
      "epoch": 1.1791111111111112,
      "grad_norm": 0.08973351120948792,
      "learning_rate": 2.0522222222222223e-05,
      "loss": 0.0018,
      "step": 53060
    },
    {
      "epoch": 1.1793333333333333,
      "grad_norm": 0.1261662393808365,
      "learning_rate": 2.0516666666666666e-05,
      "loss": 0.0021,
      "step": 53070
    },
    {
      "epoch": 1.1795555555555555,
      "grad_norm": 0.17333193123340607,
      "learning_rate": 2.0511111111111113e-05,
      "loss": 0.0016,
      "step": 53080
    },
    {
      "epoch": 1.1797777777777778,
      "grad_norm": 0.5003436207771301,
      "learning_rate": 2.0505555555555557e-05,
      "loss": 0.0022,
      "step": 53090
    },
    {
      "epoch": 1.18,
      "grad_norm": 0.3825377821922302,
      "learning_rate": 2.05e-05,
      "loss": 0.0028,
      "step": 53100
    },
    {
      "epoch": 1.1802222222222223,
      "grad_norm": 0.6561313271522522,
      "learning_rate": 2.0494444444444447e-05,
      "loss": 0.0019,
      "step": 53110
    },
    {
      "epoch": 1.1804444444444444,
      "grad_norm": 0.40503183007240295,
      "learning_rate": 2.048888888888889e-05,
      "loss": 0.0025,
      "step": 53120
    },
    {
      "epoch": 1.1806666666666668,
      "grad_norm": 0.4424421489238739,
      "learning_rate": 2.0483333333333334e-05,
      "loss": 0.0022,
      "step": 53130
    },
    {
      "epoch": 1.1808888888888889,
      "grad_norm": 0.35736721754074097,
      "learning_rate": 2.0477777777777778e-05,
      "loss": 0.002,
      "step": 53140
    },
    {
      "epoch": 1.181111111111111,
      "grad_norm": 0.3348739445209503,
      "learning_rate": 2.0472222222222225e-05,
      "loss": 0.0023,
      "step": 53150
    },
    {
      "epoch": 1.1813333333333333,
      "grad_norm": 0.08973301202058792,
      "learning_rate": 2.046666666666667e-05,
      "loss": 0.0023,
      "step": 53160
    },
    {
      "epoch": 1.1815555555555555,
      "grad_norm": 0.6074267625808716,
      "learning_rate": 2.0461111111111112e-05,
      "loss": 0.0029,
      "step": 53170
    },
    {
      "epoch": 1.1817777777777778,
      "grad_norm": 0.42084774374961853,
      "learning_rate": 2.0455555555555555e-05,
      "loss": 0.0024,
      "step": 53180
    },
    {
      "epoch": 1.182,
      "grad_norm": 0.1917395144701004,
      "learning_rate": 2.045e-05,
      "loss": 0.0018,
      "step": 53190
    },
    {
      "epoch": 1.1822222222222223,
      "grad_norm": 0.35223522782325745,
      "learning_rate": 2.0444444444444446e-05,
      "loss": 0.0021,
      "step": 53200
    },
    {
      "epoch": 1.1824444444444444,
      "grad_norm": 0.2857525050640106,
      "learning_rate": 2.043888888888889e-05,
      "loss": 0.0031,
      "step": 53210
    },
    {
      "epoch": 1.1826666666666668,
      "grad_norm": 0.08117447048425674,
      "learning_rate": 2.0433333333333336e-05,
      "loss": 0.0024,
      "step": 53220
    },
    {
      "epoch": 1.1828888888888889,
      "grad_norm": 0.26557186245918274,
      "learning_rate": 2.042777777777778e-05,
      "loss": 0.0024,
      "step": 53230
    },
    {
      "epoch": 1.1831111111111112,
      "grad_norm": 0.13542874157428741,
      "learning_rate": 2.0422222222222224e-05,
      "loss": 0.002,
      "step": 53240
    },
    {
      "epoch": 1.1833333333333333,
      "grad_norm": 0.14096219837665558,
      "learning_rate": 2.0416666666666667e-05,
      "loss": 0.0026,
      "step": 53250
    },
    {
      "epoch": 1.1835555555555555,
      "grad_norm": 0.4057333767414093,
      "learning_rate": 2.041111111111111e-05,
      "loss": 0.0022,
      "step": 53260
    },
    {
      "epoch": 1.1837777777777778,
      "grad_norm": 0.9840968251228333,
      "learning_rate": 2.0405555555555554e-05,
      "loss": 0.0022,
      "step": 53270
    },
    {
      "epoch": 1.184,
      "grad_norm": 0.2754559814929962,
      "learning_rate": 2.04e-05,
      "loss": 0.0018,
      "step": 53280
    },
    {
      "epoch": 1.1842222222222223,
      "grad_norm": 0.34002602100372314,
      "learning_rate": 2.0394444444444448e-05,
      "loss": 0.0018,
      "step": 53290
    },
    {
      "epoch": 1.1844444444444444,
      "grad_norm": 0.09234896302223206,
      "learning_rate": 2.0388888888888892e-05,
      "loss": 0.0023,
      "step": 53300
    },
    {
      "epoch": 1.1846666666666668,
      "grad_norm": 0.4830774664878845,
      "learning_rate": 2.0383333333333335e-05,
      "loss": 0.0022,
      "step": 53310
    },
    {
      "epoch": 1.1848888888888889,
      "grad_norm": 0.4094366431236267,
      "learning_rate": 2.037777777777778e-05,
      "loss": 0.0024,
      "step": 53320
    },
    {
      "epoch": 1.185111111111111,
      "grad_norm": 0.6247701048851013,
      "learning_rate": 2.0372222222222222e-05,
      "loss": 0.0022,
      "step": 53330
    },
    {
      "epoch": 1.1853333333333333,
      "grad_norm": 0.16661909222602844,
      "learning_rate": 2.0366666666666666e-05,
      "loss": 0.0024,
      "step": 53340
    },
    {
      "epoch": 1.1855555555555555,
      "grad_norm": 0.055105745792388916,
      "learning_rate": 2.0361111111111113e-05,
      "loss": 0.0018,
      "step": 53350
    },
    {
      "epoch": 1.1857777777777778,
      "grad_norm": 0.3858008086681366,
      "learning_rate": 2.0355555555555556e-05,
      "loss": 0.0018,
      "step": 53360
    },
    {
      "epoch": 1.186,
      "grad_norm": 0.45537814497947693,
      "learning_rate": 2.035e-05,
      "loss": 0.002,
      "step": 53370
    },
    {
      "epoch": 1.1862222222222223,
      "grad_norm": 0.0607215017080307,
      "learning_rate": 2.0344444444444447e-05,
      "loss": 0.0026,
      "step": 53380
    },
    {
      "epoch": 1.1864444444444444,
      "grad_norm": 0.3785097002983093,
      "learning_rate": 2.033888888888889e-05,
      "loss": 0.0018,
      "step": 53390
    },
    {
      "epoch": 1.1866666666666668,
      "grad_norm": 0.218821719288826,
      "learning_rate": 2.0333333333333334e-05,
      "loss": 0.0022,
      "step": 53400
    },
    {
      "epoch": 1.1868888888888889,
      "grad_norm": 0.3171725571155548,
      "learning_rate": 2.0327777777777778e-05,
      "loss": 0.0022,
      "step": 53410
    },
    {
      "epoch": 1.1871111111111112,
      "grad_norm": 0.12942379713058472,
      "learning_rate": 2.0322222222222225e-05,
      "loss": 0.0017,
      "step": 53420
    },
    {
      "epoch": 1.1873333333333334,
      "grad_norm": 0.08871371299028397,
      "learning_rate": 2.0316666666666668e-05,
      "loss": 0.0019,
      "step": 53430
    },
    {
      "epoch": 1.1875555555555555,
      "grad_norm": 0.21041987836360931,
      "learning_rate": 2.031111111111111e-05,
      "loss": 0.0018,
      "step": 53440
    },
    {
      "epoch": 1.1877777777777778,
      "grad_norm": 0.07406879216432571,
      "learning_rate": 2.0305555555555555e-05,
      "loss": 0.0021,
      "step": 53450
    },
    {
      "epoch": 1.188,
      "grad_norm": 0.3094339370727539,
      "learning_rate": 2.0300000000000002e-05,
      "loss": 0.0018,
      "step": 53460
    },
    {
      "epoch": 1.1882222222222223,
      "grad_norm": 0.13231754302978516,
      "learning_rate": 2.0294444444444446e-05,
      "loss": 0.0017,
      "step": 53470
    },
    {
      "epoch": 1.1884444444444444,
      "grad_norm": 0.2905714809894562,
      "learning_rate": 2.028888888888889e-05,
      "loss": 0.0019,
      "step": 53480
    },
    {
      "epoch": 1.1886666666666668,
      "grad_norm": 0.14983372390270233,
      "learning_rate": 2.0283333333333336e-05,
      "loss": 0.0018,
      "step": 53490
    },
    {
      "epoch": 1.1888888888888889,
      "grad_norm": 0.20908844470977783,
      "learning_rate": 2.027777777777778e-05,
      "loss": 0.0037,
      "step": 53500
    },
    {
      "epoch": 1.189111111111111,
      "grad_norm": 0.19593080878257751,
      "learning_rate": 2.0272222222222223e-05,
      "loss": 0.0028,
      "step": 53510
    },
    {
      "epoch": 1.1893333333333334,
      "grad_norm": 0.058884263038635254,
      "learning_rate": 2.0266666666666667e-05,
      "loss": 0.0027,
      "step": 53520
    },
    {
      "epoch": 1.1895555555555555,
      "grad_norm": 0.5528138875961304,
      "learning_rate": 2.026111111111111e-05,
      "loss": 0.0022,
      "step": 53530
    },
    {
      "epoch": 1.1897777777777778,
      "grad_norm": 0.05785728245973587,
      "learning_rate": 2.0255555555555554e-05,
      "loss": 0.0018,
      "step": 53540
    },
    {
      "epoch": 1.19,
      "grad_norm": 0.13129480183124542,
      "learning_rate": 2.025e-05,
      "loss": 0.0018,
      "step": 53550
    },
    {
      "epoch": 1.1902222222222223,
      "grad_norm": 0.4847794771194458,
      "learning_rate": 2.0244444444444448e-05,
      "loss": 0.0029,
      "step": 53560
    },
    {
      "epoch": 1.1904444444444444,
      "grad_norm": 0.06630115956068039,
      "learning_rate": 2.023888888888889e-05,
      "loss": 0.0018,
      "step": 53570
    },
    {
      "epoch": 1.1906666666666668,
      "grad_norm": 0.6086823344230652,
      "learning_rate": 2.0233333333333335e-05,
      "loss": 0.0028,
      "step": 53580
    },
    {
      "epoch": 1.1908888888888889,
      "grad_norm": 0.4569833278656006,
      "learning_rate": 2.022777777777778e-05,
      "loss": 0.0018,
      "step": 53590
    },
    {
      "epoch": 1.1911111111111112,
      "grad_norm": 0.47928303480148315,
      "learning_rate": 2.0222222222222222e-05,
      "loss": 0.0022,
      "step": 53600
    },
    {
      "epoch": 1.1913333333333334,
      "grad_norm": 0.16078127920627594,
      "learning_rate": 2.0216666666666666e-05,
      "loss": 0.0017,
      "step": 53610
    },
    {
      "epoch": 1.1915555555555555,
      "grad_norm": 0.33216339349746704,
      "learning_rate": 2.0211111111111113e-05,
      "loss": 0.0022,
      "step": 53620
    },
    {
      "epoch": 1.1917777777777778,
      "grad_norm": 0.2906437814235687,
      "learning_rate": 2.0205555555555556e-05,
      "loss": 0.0021,
      "step": 53630
    },
    {
      "epoch": 1.192,
      "grad_norm": 0.2792626619338989,
      "learning_rate": 2.0200000000000003e-05,
      "loss": 0.0023,
      "step": 53640
    },
    {
      "epoch": 1.1922222222222223,
      "grad_norm": 0.3335549831390381,
      "learning_rate": 2.0194444444444447e-05,
      "loss": 0.0021,
      "step": 53650
    },
    {
      "epoch": 1.1924444444444444,
      "grad_norm": 0.06478167325258255,
      "learning_rate": 2.018888888888889e-05,
      "loss": 0.002,
      "step": 53660
    },
    {
      "epoch": 1.1926666666666668,
      "grad_norm": 0.1091977059841156,
      "learning_rate": 2.0183333333333334e-05,
      "loss": 0.0017,
      "step": 53670
    },
    {
      "epoch": 1.1928888888888889,
      "grad_norm": 0.21442285180091858,
      "learning_rate": 2.0177777777777777e-05,
      "loss": 0.0024,
      "step": 53680
    },
    {
      "epoch": 1.193111111111111,
      "grad_norm": 0.36228156089782715,
      "learning_rate": 2.0172222222222224e-05,
      "loss": 0.0019,
      "step": 53690
    },
    {
      "epoch": 1.1933333333333334,
      "grad_norm": 0.10643714666366577,
      "learning_rate": 2.0166666666666668e-05,
      "loss": 0.0025,
      "step": 53700
    },
    {
      "epoch": 1.1935555555555555,
      "grad_norm": 0.44152823090553284,
      "learning_rate": 2.016111111111111e-05,
      "loss": 0.0024,
      "step": 53710
    },
    {
      "epoch": 1.1937777777777778,
      "grad_norm": 0.19449037313461304,
      "learning_rate": 2.0155555555555555e-05,
      "loss": 0.0021,
      "step": 53720
    },
    {
      "epoch": 1.194,
      "grad_norm": 0.08233731985092163,
      "learning_rate": 2.0150000000000002e-05,
      "loss": 0.0025,
      "step": 53730
    },
    {
      "epoch": 1.1942222222222223,
      "grad_norm": 0.11346004903316498,
      "learning_rate": 2.0144444444444445e-05,
      "loss": 0.0017,
      "step": 53740
    },
    {
      "epoch": 1.1944444444444444,
      "grad_norm": 0.13853563368320465,
      "learning_rate": 2.013888888888889e-05,
      "loss": 0.0023,
      "step": 53750
    },
    {
      "epoch": 1.1946666666666665,
      "grad_norm": 0.0750231072306633,
      "learning_rate": 2.0133333333333336e-05,
      "loss": 0.0017,
      "step": 53760
    },
    {
      "epoch": 1.194888888888889,
      "grad_norm": 0.5989235043525696,
      "learning_rate": 2.012777777777778e-05,
      "loss": 0.0019,
      "step": 53770
    },
    {
      "epoch": 1.1951111111111112,
      "grad_norm": 0.09998970478773117,
      "learning_rate": 2.0122222222222223e-05,
      "loss": 0.0023,
      "step": 53780
    },
    {
      "epoch": 1.1953333333333334,
      "grad_norm": 0.7118657827377319,
      "learning_rate": 2.0116666666666667e-05,
      "loss": 0.0024,
      "step": 53790
    },
    {
      "epoch": 1.1955555555555555,
      "grad_norm": 0.09089919924736023,
      "learning_rate": 2.011111111111111e-05,
      "loss": 0.0023,
      "step": 53800
    },
    {
      "epoch": 1.1957777777777778,
      "grad_norm": 0.26520854234695435,
      "learning_rate": 2.0105555555555554e-05,
      "loss": 0.002,
      "step": 53810
    },
    {
      "epoch": 1.196,
      "grad_norm": 0.42100241780281067,
      "learning_rate": 2.01e-05,
      "loss": 0.0019,
      "step": 53820
    },
    {
      "epoch": 1.1962222222222223,
      "grad_norm": 0.22365504503250122,
      "learning_rate": 2.0094444444444448e-05,
      "loss": 0.0021,
      "step": 53830
    },
    {
      "epoch": 1.1964444444444444,
      "grad_norm": 0.22516682744026184,
      "learning_rate": 2.008888888888889e-05,
      "loss": 0.0022,
      "step": 53840
    },
    {
      "epoch": 1.1966666666666668,
      "grad_norm": 0.24766215682029724,
      "learning_rate": 2.0083333333333335e-05,
      "loss": 0.0025,
      "step": 53850
    },
    {
      "epoch": 1.196888888888889,
      "grad_norm": 0.060876622796058655,
      "learning_rate": 2.0077777777777778e-05,
      "loss": 0.0028,
      "step": 53860
    },
    {
      "epoch": 1.197111111111111,
      "grad_norm": 0.1620742827653885,
      "learning_rate": 2.0072222222222222e-05,
      "loss": 0.0018,
      "step": 53870
    },
    {
      "epoch": 1.1973333333333334,
      "grad_norm": 0.17841307818889618,
      "learning_rate": 2.0066666666666665e-05,
      "loss": 0.0019,
      "step": 53880
    },
    {
      "epoch": 1.1975555555555555,
      "grad_norm": 0.08531410247087479,
      "learning_rate": 2.0061111111111112e-05,
      "loss": 0.0021,
      "step": 53890
    },
    {
      "epoch": 1.1977777777777778,
      "grad_norm": 0.06685725599527359,
      "learning_rate": 2.0055555555555556e-05,
      "loss": 0.0022,
      "step": 53900
    },
    {
      "epoch": 1.198,
      "grad_norm": 0.24590688943862915,
      "learning_rate": 2.0050000000000003e-05,
      "loss": 0.002,
      "step": 53910
    },
    {
      "epoch": 1.1982222222222223,
      "grad_norm": 0.552282989025116,
      "learning_rate": 2.0044444444444446e-05,
      "loss": 0.0021,
      "step": 53920
    },
    {
      "epoch": 1.1984444444444444,
      "grad_norm": 0.05294761434197426,
      "learning_rate": 2.003888888888889e-05,
      "loss": 0.0022,
      "step": 53930
    },
    {
      "epoch": 1.1986666666666665,
      "grad_norm": 0.6991057395935059,
      "learning_rate": 2.0033333333333334e-05,
      "loss": 0.0019,
      "step": 53940
    },
    {
      "epoch": 1.198888888888889,
      "grad_norm": 0.1265001893043518,
      "learning_rate": 2.0027777777777777e-05,
      "loss": 0.0026,
      "step": 53950
    },
    {
      "epoch": 1.199111111111111,
      "grad_norm": 0.12142003327608109,
      "learning_rate": 2.0022222222222224e-05,
      "loss": 0.0018,
      "step": 53960
    },
    {
      "epoch": 1.1993333333333334,
      "grad_norm": 0.13362744450569153,
      "learning_rate": 2.0016666666666668e-05,
      "loss": 0.0019,
      "step": 53970
    },
    {
      "epoch": 1.1995555555555555,
      "grad_norm": 0.15859389305114746,
      "learning_rate": 2.001111111111111e-05,
      "loss": 0.002,
      "step": 53980
    },
    {
      "epoch": 1.1997777777777778,
      "grad_norm": 0.08760067075490952,
      "learning_rate": 2.0005555555555555e-05,
      "loss": 0.0021,
      "step": 53990
    },
    {
      "epoch": 1.2,
      "grad_norm": 0.3462500274181366,
      "learning_rate": 2e-05,
      "loss": 0.0024,
      "step": 54000
    },
    {
      "epoch": 1.2002222222222223,
      "grad_norm": 0.19526346027851105,
      "learning_rate": 1.9994444444444445e-05,
      "loss": 0.0028,
      "step": 54010
    },
    {
      "epoch": 1.2004444444444444,
      "grad_norm": 0.1859632134437561,
      "learning_rate": 1.998888888888889e-05,
      "loss": 0.002,
      "step": 54020
    },
    {
      "epoch": 1.2006666666666668,
      "grad_norm": 0.42376115918159485,
      "learning_rate": 1.9983333333333336e-05,
      "loss": 0.0029,
      "step": 54030
    },
    {
      "epoch": 1.200888888888889,
      "grad_norm": 0.4884008765220642,
      "learning_rate": 1.997777777777778e-05,
      "loss": 0.0031,
      "step": 54040
    },
    {
      "epoch": 1.201111111111111,
      "grad_norm": 0.26778528094291687,
      "learning_rate": 1.9972222222222223e-05,
      "loss": 0.0022,
      "step": 54050
    },
    {
      "epoch": 1.2013333333333334,
      "grad_norm": 0.23357509076595306,
      "learning_rate": 1.9966666666666666e-05,
      "loss": 0.0018,
      "step": 54060
    },
    {
      "epoch": 1.2015555555555555,
      "grad_norm": 0.4275451898574829,
      "learning_rate": 1.996111111111111e-05,
      "loss": 0.0019,
      "step": 54070
    },
    {
      "epoch": 1.2017777777777778,
      "grad_norm": 0.263921320438385,
      "learning_rate": 1.9955555555555557e-05,
      "loss": 0.0025,
      "step": 54080
    },
    {
      "epoch": 1.202,
      "grad_norm": 0.10713482648134232,
      "learning_rate": 1.995e-05,
      "loss": 0.0029,
      "step": 54090
    },
    {
      "epoch": 1.2022222222222223,
      "grad_norm": 0.34767258167266846,
      "learning_rate": 1.9944444444444447e-05,
      "loss": 0.0017,
      "step": 54100
    },
    {
      "epoch": 1.2024444444444444,
      "grad_norm": 0.07730432599782944,
      "learning_rate": 1.993888888888889e-05,
      "loss": 0.0026,
      "step": 54110
    },
    {
      "epoch": 1.2026666666666666,
      "grad_norm": 0.18538405001163483,
      "learning_rate": 1.9933333333333334e-05,
      "loss": 0.0018,
      "step": 54120
    },
    {
      "epoch": 1.202888888888889,
      "grad_norm": 0.2283366322517395,
      "learning_rate": 1.9927777777777778e-05,
      "loss": 0.0021,
      "step": 54130
    },
    {
      "epoch": 1.203111111111111,
      "grad_norm": 0.08386828750371933,
      "learning_rate": 1.992222222222222e-05,
      "loss": 0.002,
      "step": 54140
    },
    {
      "epoch": 1.2033333333333334,
      "grad_norm": 0.14583295583724976,
      "learning_rate": 1.9916666666666665e-05,
      "loss": 0.0022,
      "step": 54150
    },
    {
      "epoch": 1.2035555555555555,
      "grad_norm": 0.2320602536201477,
      "learning_rate": 1.9911111111111112e-05,
      "loss": 0.002,
      "step": 54160
    },
    {
      "epoch": 1.2037777777777778,
      "grad_norm": 0.12733568251132965,
      "learning_rate": 1.990555555555556e-05,
      "loss": 0.0019,
      "step": 54170
    },
    {
      "epoch": 1.204,
      "grad_norm": 0.3856654763221741,
      "learning_rate": 1.9900000000000003e-05,
      "loss": 0.0019,
      "step": 54180
    },
    {
      "epoch": 1.2042222222222223,
      "grad_norm": 0.2570910155773163,
      "learning_rate": 1.9894444444444446e-05,
      "loss": 0.0022,
      "step": 54190
    },
    {
      "epoch": 1.2044444444444444,
      "grad_norm": 0.06713152676820755,
      "learning_rate": 1.988888888888889e-05,
      "loss": 0.002,
      "step": 54200
    },
    {
      "epoch": 1.2046666666666668,
      "grad_norm": 0.0791558176279068,
      "learning_rate": 1.9883333333333333e-05,
      "loss": 0.0026,
      "step": 54210
    },
    {
      "epoch": 1.204888888888889,
      "grad_norm": 0.490447074174881,
      "learning_rate": 1.9877777777777777e-05,
      "loss": 0.0017,
      "step": 54220
    },
    {
      "epoch": 1.205111111111111,
      "grad_norm": 0.11002767086029053,
      "learning_rate": 1.9872222222222224e-05,
      "loss": 0.0023,
      "step": 54230
    },
    {
      "epoch": 1.2053333333333334,
      "grad_norm": 0.20718957483768463,
      "learning_rate": 1.9866666666666667e-05,
      "loss": 0.0019,
      "step": 54240
    },
    {
      "epoch": 1.2055555555555555,
      "grad_norm": 0.07985170185565948,
      "learning_rate": 1.986111111111111e-05,
      "loss": 0.0039,
      "step": 54250
    },
    {
      "epoch": 1.2057777777777778,
      "grad_norm": 0.20352143049240112,
      "learning_rate": 1.9855555555555558e-05,
      "loss": 0.0017,
      "step": 54260
    },
    {
      "epoch": 1.206,
      "grad_norm": 0.2784166932106018,
      "learning_rate": 1.985e-05,
      "loss": 0.0025,
      "step": 54270
    },
    {
      "epoch": 1.2062222222222223,
      "grad_norm": 0.17764483392238617,
      "learning_rate": 1.9844444444444445e-05,
      "loss": 0.0022,
      "step": 54280
    },
    {
      "epoch": 1.2064444444444444,
      "grad_norm": 0.37491923570632935,
      "learning_rate": 1.9838888888888892e-05,
      "loss": 0.0021,
      "step": 54290
    },
    {
      "epoch": 1.2066666666666666,
      "grad_norm": 0.8806704878807068,
      "learning_rate": 1.9833333333333335e-05,
      "loss": 0.003,
      "step": 54300
    },
    {
      "epoch": 1.206888888888889,
      "grad_norm": 0.29379570484161377,
      "learning_rate": 1.982777777777778e-05,
      "loss": 0.0017,
      "step": 54310
    },
    {
      "epoch": 1.207111111111111,
      "grad_norm": 0.06449507176876068,
      "learning_rate": 1.9822222222222223e-05,
      "loss": 0.0021,
      "step": 54320
    },
    {
      "epoch": 1.2073333333333334,
      "grad_norm": 0.29733237624168396,
      "learning_rate": 1.9816666666666666e-05,
      "loss": 0.0026,
      "step": 54330
    },
    {
      "epoch": 1.2075555555555555,
      "grad_norm": 0.1253085434436798,
      "learning_rate": 1.981111111111111e-05,
      "loss": 0.0018,
      "step": 54340
    },
    {
      "epoch": 1.2077777777777778,
      "grad_norm": 0.24326986074447632,
      "learning_rate": 1.9805555555555557e-05,
      "loss": 0.002,
      "step": 54350
    },
    {
      "epoch": 1.208,
      "grad_norm": 0.07260580360889435,
      "learning_rate": 1.9800000000000004e-05,
      "loss": 0.002,
      "step": 54360
    },
    {
      "epoch": 1.2082222222222223,
      "grad_norm": 0.3475055992603302,
      "learning_rate": 1.9794444444444447e-05,
      "loss": 0.0022,
      "step": 54370
    },
    {
      "epoch": 1.2084444444444444,
      "grad_norm": 0.10263266414403915,
      "learning_rate": 1.978888888888889e-05,
      "loss": 0.0019,
      "step": 54380
    },
    {
      "epoch": 1.2086666666666668,
      "grad_norm": 0.40943530201911926,
      "learning_rate": 1.9783333333333334e-05,
      "loss": 0.0022,
      "step": 54390
    },
    {
      "epoch": 1.208888888888889,
      "grad_norm": 0.12248046696186066,
      "learning_rate": 1.9777777777777778e-05,
      "loss": 0.002,
      "step": 54400
    },
    {
      "epoch": 1.209111111111111,
      "grad_norm": 0.35748305916786194,
      "learning_rate": 1.977222222222222e-05,
      "loss": 0.0025,
      "step": 54410
    },
    {
      "epoch": 1.2093333333333334,
      "grad_norm": 0.22537478804588318,
      "learning_rate": 1.9766666666666668e-05,
      "loss": 0.0024,
      "step": 54420
    },
    {
      "epoch": 1.2095555555555555,
      "grad_norm": 0.2505725920200348,
      "learning_rate": 1.9761111111111112e-05,
      "loss": 0.0018,
      "step": 54430
    },
    {
      "epoch": 1.2097777777777778,
      "grad_norm": 0.11134117841720581,
      "learning_rate": 1.975555555555556e-05,
      "loss": 0.0026,
      "step": 54440
    },
    {
      "epoch": 1.21,
      "grad_norm": 0.36015915870666504,
      "learning_rate": 1.9750000000000002e-05,
      "loss": 0.0023,
      "step": 54450
    },
    {
      "epoch": 1.2102222222222223,
      "grad_norm": 0.2997085750102997,
      "learning_rate": 1.9744444444444446e-05,
      "loss": 0.0026,
      "step": 54460
    },
    {
      "epoch": 1.2104444444444444,
      "grad_norm": 0.08831557631492615,
      "learning_rate": 1.973888888888889e-05,
      "loss": 0.0029,
      "step": 54470
    },
    {
      "epoch": 1.2106666666666666,
      "grad_norm": 0.38811713457107544,
      "learning_rate": 1.9733333333333333e-05,
      "loss": 0.002,
      "step": 54480
    },
    {
      "epoch": 1.210888888888889,
      "grad_norm": 0.2217690646648407,
      "learning_rate": 1.972777777777778e-05,
      "loss": 0.002,
      "step": 54490
    },
    {
      "epoch": 1.211111111111111,
      "grad_norm": 0.45842018723487854,
      "learning_rate": 1.9722222222222224e-05,
      "loss": 0.0031,
      "step": 54500
    },
    {
      "epoch": 1.2113333333333334,
      "grad_norm": 0.43003979325294495,
      "learning_rate": 1.9716666666666667e-05,
      "loss": 0.0019,
      "step": 54510
    },
    {
      "epoch": 1.2115555555555555,
      "grad_norm": 0.5273091197013855,
      "learning_rate": 1.971111111111111e-05,
      "loss": 0.0026,
      "step": 54520
    },
    {
      "epoch": 1.2117777777777778,
      "grad_norm": 0.22385455667972565,
      "learning_rate": 1.9705555555555558e-05,
      "loss": 0.0027,
      "step": 54530
    },
    {
      "epoch": 1.212,
      "grad_norm": 0.16548395156860352,
      "learning_rate": 1.97e-05,
      "loss": 0.0028,
      "step": 54540
    },
    {
      "epoch": 1.2122222222222223,
      "grad_norm": 0.10686399787664413,
      "learning_rate": 1.9694444444444445e-05,
      "loss": 0.0033,
      "step": 54550
    },
    {
      "epoch": 1.2124444444444444,
      "grad_norm": 0.332795113325119,
      "learning_rate": 1.968888888888889e-05,
      "loss": 0.0019,
      "step": 54560
    },
    {
      "epoch": 1.2126666666666668,
      "grad_norm": 0.40294432640075684,
      "learning_rate": 1.9683333333333335e-05,
      "loss": 0.0028,
      "step": 54570
    },
    {
      "epoch": 1.212888888888889,
      "grad_norm": 0.07216738164424896,
      "learning_rate": 1.967777777777778e-05,
      "loss": 0.0019,
      "step": 54580
    },
    {
      "epoch": 1.213111111111111,
      "grad_norm": 0.1267695426940918,
      "learning_rate": 1.9672222222222222e-05,
      "loss": 0.0019,
      "step": 54590
    },
    {
      "epoch": 1.2133333333333334,
      "grad_norm": 0.2315027266740799,
      "learning_rate": 1.9666666666666666e-05,
      "loss": 0.0017,
      "step": 54600
    },
    {
      "epoch": 1.2135555555555555,
      "grad_norm": 0.17583097517490387,
      "learning_rate": 1.966111111111111e-05,
      "loss": 0.0024,
      "step": 54610
    },
    {
      "epoch": 1.2137777777777778,
      "grad_norm": 0.12866201996803284,
      "learning_rate": 1.9655555555555556e-05,
      "loss": 0.0027,
      "step": 54620
    },
    {
      "epoch": 1.214,
      "grad_norm": 0.29287776350975037,
      "learning_rate": 1.9650000000000003e-05,
      "loss": 0.0021,
      "step": 54630
    },
    {
      "epoch": 1.2142222222222223,
      "grad_norm": 0.21511517465114594,
      "learning_rate": 1.9644444444444447e-05,
      "loss": 0.0018,
      "step": 54640
    },
    {
      "epoch": 1.2144444444444444,
      "grad_norm": 0.6566393971443176,
      "learning_rate": 1.963888888888889e-05,
      "loss": 0.0022,
      "step": 54650
    },
    {
      "epoch": 1.2146666666666666,
      "grad_norm": 0.1990039199590683,
      "learning_rate": 1.9633333333333334e-05,
      "loss": 0.0017,
      "step": 54660
    },
    {
      "epoch": 1.214888888888889,
      "grad_norm": 0.2589273154735565,
      "learning_rate": 1.9627777777777778e-05,
      "loss": 0.002,
      "step": 54670
    },
    {
      "epoch": 1.215111111111111,
      "grad_norm": 0.550347089767456,
      "learning_rate": 1.962222222222222e-05,
      "loss": 0.0021,
      "step": 54680
    },
    {
      "epoch": 1.2153333333333334,
      "grad_norm": 0.13370130956172943,
      "learning_rate": 1.9616666666666668e-05,
      "loss": 0.0018,
      "step": 54690
    },
    {
      "epoch": 1.2155555555555555,
      "grad_norm": 0.19713027775287628,
      "learning_rate": 1.9611111111111115e-05,
      "loss": 0.0019,
      "step": 54700
    },
    {
      "epoch": 1.2157777777777778,
      "grad_norm": 0.15124325454235077,
      "learning_rate": 1.960555555555556e-05,
      "loss": 0.002,
      "step": 54710
    },
    {
      "epoch": 1.216,
      "grad_norm": 0.08221527934074402,
      "learning_rate": 1.9600000000000002e-05,
      "loss": 0.0022,
      "step": 54720
    },
    {
      "epoch": 1.2162222222222223,
      "grad_norm": 0.22264888882637024,
      "learning_rate": 1.9594444444444446e-05,
      "loss": 0.002,
      "step": 54730
    },
    {
      "epoch": 1.2164444444444444,
      "grad_norm": 0.11444409936666489,
      "learning_rate": 1.958888888888889e-05,
      "loss": 0.0032,
      "step": 54740
    },
    {
      "epoch": 1.2166666666666668,
      "grad_norm": 0.3149089217185974,
      "learning_rate": 1.9583333333333333e-05,
      "loss": 0.0019,
      "step": 54750
    },
    {
      "epoch": 1.216888888888889,
      "grad_norm": 0.062110573053359985,
      "learning_rate": 1.957777777777778e-05,
      "loss": 0.0023,
      "step": 54760
    },
    {
      "epoch": 1.217111111111111,
      "grad_norm": 0.36765560507774353,
      "learning_rate": 1.9572222222222223e-05,
      "loss": 0.0018,
      "step": 54770
    },
    {
      "epoch": 1.2173333333333334,
      "grad_norm": 0.37143710255622864,
      "learning_rate": 1.9566666666666667e-05,
      "loss": 0.0019,
      "step": 54780
    },
    {
      "epoch": 1.2175555555555555,
      "grad_norm": 0.06066405028104782,
      "learning_rate": 1.9561111111111114e-05,
      "loss": 0.0019,
      "step": 54790
    },
    {
      "epoch": 1.2177777777777778,
      "grad_norm": 0.10769776254892349,
      "learning_rate": 1.9555555555555557e-05,
      "loss": 0.0028,
      "step": 54800
    },
    {
      "epoch": 1.218,
      "grad_norm": 0.5925965905189514,
      "learning_rate": 1.955e-05,
      "loss": 0.0021,
      "step": 54810
    },
    {
      "epoch": 1.2182222222222223,
      "grad_norm": 0.08972297608852386,
      "learning_rate": 1.9544444444444444e-05,
      "loss": 0.0023,
      "step": 54820
    },
    {
      "epoch": 1.2184444444444444,
      "grad_norm": 0.12766580283641815,
      "learning_rate": 1.953888888888889e-05,
      "loss": 0.0023,
      "step": 54830
    },
    {
      "epoch": 1.2186666666666666,
      "grad_norm": 0.42986226081848145,
      "learning_rate": 1.9533333333333335e-05,
      "loss": 0.0023,
      "step": 54840
    },
    {
      "epoch": 1.218888888888889,
      "grad_norm": 0.3772661089897156,
      "learning_rate": 1.952777777777778e-05,
      "loss": 0.0028,
      "step": 54850
    },
    {
      "epoch": 1.219111111111111,
      "grad_norm": 0.07383418828248978,
      "learning_rate": 1.9522222222222222e-05,
      "loss": 0.0024,
      "step": 54860
    },
    {
      "epoch": 1.2193333333333334,
      "grad_norm": 0.05553388595581055,
      "learning_rate": 1.9516666666666666e-05,
      "loss": 0.002,
      "step": 54870
    },
    {
      "epoch": 1.2195555555555555,
      "grad_norm": 0.5428265929222107,
      "learning_rate": 1.9511111111111113e-05,
      "loss": 0.0019,
      "step": 54880
    },
    {
      "epoch": 1.2197777777777778,
      "grad_norm": 0.10240841656923294,
      "learning_rate": 1.9505555555555556e-05,
      "loss": 0.0031,
      "step": 54890
    },
    {
      "epoch": 1.22,
      "grad_norm": 0.4970518946647644,
      "learning_rate": 1.9500000000000003e-05,
      "loss": 0.0029,
      "step": 54900
    },
    {
      "epoch": 1.2202222222222223,
      "grad_norm": 0.4576590359210968,
      "learning_rate": 1.9494444444444447e-05,
      "loss": 0.002,
      "step": 54910
    },
    {
      "epoch": 1.2204444444444444,
      "grad_norm": 0.5474873781204224,
      "learning_rate": 1.948888888888889e-05,
      "loss": 0.0025,
      "step": 54920
    },
    {
      "epoch": 1.2206666666666668,
      "grad_norm": 0.20890478789806366,
      "learning_rate": 1.9483333333333334e-05,
      "loss": 0.0021,
      "step": 54930
    },
    {
      "epoch": 1.220888888888889,
      "grad_norm": 0.33144161105155945,
      "learning_rate": 1.9477777777777777e-05,
      "loss": 0.0028,
      "step": 54940
    },
    {
      "epoch": 1.221111111111111,
      "grad_norm": 0.1902984231710434,
      "learning_rate": 1.947222222222222e-05,
      "loss": 0.0028,
      "step": 54950
    },
    {
      "epoch": 1.2213333333333334,
      "grad_norm": 0.475829154253006,
      "learning_rate": 1.9466666666666668e-05,
      "loss": 0.0019,
      "step": 54960
    },
    {
      "epoch": 1.2215555555555555,
      "grad_norm": 0.34288185834884644,
      "learning_rate": 1.9461111111111115e-05,
      "loss": 0.0021,
      "step": 54970
    },
    {
      "epoch": 1.2217777777777779,
      "grad_norm": 0.2688901722431183,
      "learning_rate": 1.9455555555555558e-05,
      "loss": 0.0021,
      "step": 54980
    },
    {
      "epoch": 1.222,
      "grad_norm": 0.22532765567302704,
      "learning_rate": 1.9450000000000002e-05,
      "loss": 0.0017,
      "step": 54990
    },
    {
      "epoch": 1.2222222222222223,
      "grad_norm": 0.11592281609773636,
      "learning_rate": 1.9444444444444445e-05,
      "loss": 0.0026,
      "step": 55000
    },
    {
      "epoch": 1.2224444444444444,
      "grad_norm": 0.1835615634918213,
      "learning_rate": 1.943888888888889e-05,
      "loss": 0.0019,
      "step": 55010
    },
    {
      "epoch": 1.2226666666666666,
      "grad_norm": 0.17098359763622284,
      "learning_rate": 1.9433333333333332e-05,
      "loss": 0.0022,
      "step": 55020
    },
    {
      "epoch": 1.222888888888889,
      "grad_norm": 0.17974096536636353,
      "learning_rate": 1.942777777777778e-05,
      "loss": 0.0022,
      "step": 55030
    },
    {
      "epoch": 1.223111111111111,
      "grad_norm": 0.06349783390760422,
      "learning_rate": 1.9422222222222223e-05,
      "loss": 0.0017,
      "step": 55040
    },
    {
      "epoch": 1.2233333333333334,
      "grad_norm": 0.18630950152873993,
      "learning_rate": 1.9416666666666667e-05,
      "loss": 0.0026,
      "step": 55050
    },
    {
      "epoch": 1.2235555555555555,
      "grad_norm": 0.3412338197231293,
      "learning_rate": 1.9411111111111113e-05,
      "loss": 0.0023,
      "step": 55060
    },
    {
      "epoch": 1.2237777777777779,
      "grad_norm": 0.20311127603054047,
      "learning_rate": 1.9405555555555557e-05,
      "loss": 0.003,
      "step": 55070
    },
    {
      "epoch": 1.224,
      "grad_norm": 0.3991328179836273,
      "learning_rate": 1.94e-05,
      "loss": 0.0018,
      "step": 55080
    },
    {
      "epoch": 1.224222222222222,
      "grad_norm": 0.24578401446342468,
      "learning_rate": 1.9394444444444444e-05,
      "loss": 0.0023,
      "step": 55090
    },
    {
      "epoch": 1.2244444444444444,
      "grad_norm": 0.502334475517273,
      "learning_rate": 1.938888888888889e-05,
      "loss": 0.0025,
      "step": 55100
    },
    {
      "epoch": 1.2246666666666666,
      "grad_norm": 0.34603267908096313,
      "learning_rate": 1.9383333333333335e-05,
      "loss": 0.002,
      "step": 55110
    },
    {
      "epoch": 1.224888888888889,
      "grad_norm": 0.25896570086479187,
      "learning_rate": 1.9377777777777778e-05,
      "loss": 0.0025,
      "step": 55120
    },
    {
      "epoch": 1.225111111111111,
      "grad_norm": 0.37106388807296753,
      "learning_rate": 1.9372222222222222e-05,
      "loss": 0.0019,
      "step": 55130
    },
    {
      "epoch": 1.2253333333333334,
      "grad_norm": 0.06462202966213226,
      "learning_rate": 1.9366666666666665e-05,
      "loss": 0.0018,
      "step": 55140
    },
    {
      "epoch": 1.2255555555555555,
      "grad_norm": 0.45294076204299927,
      "learning_rate": 1.9361111111111112e-05,
      "loss": 0.0029,
      "step": 55150
    },
    {
      "epoch": 1.2257777777777779,
      "grad_norm": 0.13604958355426788,
      "learning_rate": 1.9355555555555556e-05,
      "loss": 0.0019,
      "step": 55160
    },
    {
      "epoch": 1.226,
      "grad_norm": 0.161662757396698,
      "learning_rate": 1.9350000000000003e-05,
      "loss": 0.0022,
      "step": 55170
    },
    {
      "epoch": 1.2262222222222223,
      "grad_norm": 0.25898945331573486,
      "learning_rate": 1.9344444444444446e-05,
      "loss": 0.002,
      "step": 55180
    },
    {
      "epoch": 1.2264444444444444,
      "grad_norm": 0.12361360341310501,
      "learning_rate": 1.933888888888889e-05,
      "loss": 0.0019,
      "step": 55190
    },
    {
      "epoch": 1.2266666666666666,
      "grad_norm": 0.13283494114875793,
      "learning_rate": 1.9333333333333333e-05,
      "loss": 0.002,
      "step": 55200
    },
    {
      "epoch": 1.226888888888889,
      "grad_norm": 0.48682793974876404,
      "learning_rate": 1.9327777777777777e-05,
      "loss": 0.0024,
      "step": 55210
    },
    {
      "epoch": 1.227111111111111,
      "grad_norm": 0.10809291899204254,
      "learning_rate": 1.932222222222222e-05,
      "loss": 0.0025,
      "step": 55220
    },
    {
      "epoch": 1.2273333333333334,
      "grad_norm": 0.17093142867088318,
      "learning_rate": 1.9316666666666668e-05,
      "loss": 0.002,
      "step": 55230
    },
    {
      "epoch": 1.2275555555555555,
      "grad_norm": 0.1064772978425026,
      "learning_rate": 1.9311111111111114e-05,
      "loss": 0.0028,
      "step": 55240
    },
    {
      "epoch": 1.2277777777777779,
      "grad_norm": 0.0956370085477829,
      "learning_rate": 1.9305555555555558e-05,
      "loss": 0.0028,
      "step": 55250
    },
    {
      "epoch": 1.228,
      "grad_norm": 0.32581162452697754,
      "learning_rate": 1.93e-05,
      "loss": 0.0017,
      "step": 55260
    },
    {
      "epoch": 1.228222222222222,
      "grad_norm": 0.5126030445098877,
      "learning_rate": 1.9294444444444445e-05,
      "loss": 0.003,
      "step": 55270
    },
    {
      "epoch": 1.2284444444444444,
      "grad_norm": 0.16373035311698914,
      "learning_rate": 1.928888888888889e-05,
      "loss": 0.0032,
      "step": 55280
    },
    {
      "epoch": 1.2286666666666666,
      "grad_norm": 0.16164422035217285,
      "learning_rate": 1.9283333333333332e-05,
      "loss": 0.0015,
      "step": 55290
    },
    {
      "epoch": 1.228888888888889,
      "grad_norm": 0.18073566257953644,
      "learning_rate": 1.927777777777778e-05,
      "loss": 0.0021,
      "step": 55300
    },
    {
      "epoch": 1.229111111111111,
      "grad_norm": 0.16301339864730835,
      "learning_rate": 1.9272222222222223e-05,
      "loss": 0.0031,
      "step": 55310
    },
    {
      "epoch": 1.2293333333333334,
      "grad_norm": 0.2261999547481537,
      "learning_rate": 1.926666666666667e-05,
      "loss": 0.0021,
      "step": 55320
    },
    {
      "epoch": 1.2295555555555555,
      "grad_norm": 0.12130161374807358,
      "learning_rate": 1.9261111111111113e-05,
      "loss": 0.002,
      "step": 55330
    },
    {
      "epoch": 1.2297777777777779,
      "grad_norm": 0.5001174211502075,
      "learning_rate": 1.9255555555555557e-05,
      "loss": 0.0028,
      "step": 55340
    },
    {
      "epoch": 1.23,
      "grad_norm": 0.25219252705574036,
      "learning_rate": 1.925e-05,
      "loss": 0.0029,
      "step": 55350
    },
    {
      "epoch": 1.2302222222222223,
      "grad_norm": 0.27784132957458496,
      "learning_rate": 1.9244444444444444e-05,
      "loss": 0.0021,
      "step": 55360
    },
    {
      "epoch": 1.2304444444444445,
      "grad_norm": 0.4019014239311218,
      "learning_rate": 1.923888888888889e-05,
      "loss": 0.0027,
      "step": 55370
    },
    {
      "epoch": 1.2306666666666666,
      "grad_norm": 0.4947742223739624,
      "learning_rate": 1.9233333333333334e-05,
      "loss": 0.0016,
      "step": 55380
    },
    {
      "epoch": 1.230888888888889,
      "grad_norm": 0.23927932977676392,
      "learning_rate": 1.9227777777777778e-05,
      "loss": 0.0033,
      "step": 55390
    },
    {
      "epoch": 1.231111111111111,
      "grad_norm": 0.4801897406578064,
      "learning_rate": 1.922222222222222e-05,
      "loss": 0.002,
      "step": 55400
    },
    {
      "epoch": 1.2313333333333334,
      "grad_norm": 0.3949865698814392,
      "learning_rate": 1.921666666666667e-05,
      "loss": 0.0023,
      "step": 55410
    },
    {
      "epoch": 1.2315555555555555,
      "grad_norm": 0.26317858695983887,
      "learning_rate": 1.9211111111111112e-05,
      "loss": 0.0027,
      "step": 55420
    },
    {
      "epoch": 1.2317777777777779,
      "grad_norm": 0.2894390821456909,
      "learning_rate": 1.9205555555555556e-05,
      "loss": 0.0018,
      "step": 55430
    },
    {
      "epoch": 1.232,
      "grad_norm": 0.08617215603590012,
      "learning_rate": 1.9200000000000003e-05,
      "loss": 0.0029,
      "step": 55440
    },
    {
      "epoch": 1.232222222222222,
      "grad_norm": 0.194435253739357,
      "learning_rate": 1.9194444444444446e-05,
      "loss": 0.0017,
      "step": 55450
    },
    {
      "epoch": 1.2324444444444445,
      "grad_norm": 0.18670205771923065,
      "learning_rate": 1.918888888888889e-05,
      "loss": 0.0017,
      "step": 55460
    },
    {
      "epoch": 1.2326666666666666,
      "grad_norm": 0.32829365134239197,
      "learning_rate": 1.9183333333333333e-05,
      "loss": 0.0021,
      "step": 55470
    },
    {
      "epoch": 1.232888888888889,
      "grad_norm": 0.13897065818309784,
      "learning_rate": 1.9177777777777777e-05,
      "loss": 0.0023,
      "step": 55480
    },
    {
      "epoch": 1.233111111111111,
      "grad_norm": 0.10633322596549988,
      "learning_rate": 1.917222222222222e-05,
      "loss": 0.0018,
      "step": 55490
    },
    {
      "epoch": 1.2333333333333334,
      "grad_norm": 0.3746166527271271,
      "learning_rate": 1.9166666666666667e-05,
      "loss": 0.0025,
      "step": 55500
    },
    {
      "epoch": 1.2335555555555555,
      "grad_norm": 0.26987752318382263,
      "learning_rate": 1.9161111111111114e-05,
      "loss": 0.0021,
      "step": 55510
    },
    {
      "epoch": 1.2337777777777779,
      "grad_norm": 0.3994625508785248,
      "learning_rate": 1.9155555555555558e-05,
      "loss": 0.002,
      "step": 55520
    },
    {
      "epoch": 1.234,
      "grad_norm": 0.29410678148269653,
      "learning_rate": 1.915e-05,
      "loss": 0.003,
      "step": 55530
    },
    {
      "epoch": 1.2342222222222223,
      "grad_norm": 0.12292634695768356,
      "learning_rate": 1.9144444444444445e-05,
      "loss": 0.0022,
      "step": 55540
    },
    {
      "epoch": 1.2344444444444445,
      "grad_norm": 0.06369107961654663,
      "learning_rate": 1.913888888888889e-05,
      "loss": 0.0027,
      "step": 55550
    },
    {
      "epoch": 1.2346666666666666,
      "grad_norm": 0.34815433621406555,
      "learning_rate": 1.9133333333333332e-05,
      "loss": 0.002,
      "step": 55560
    },
    {
      "epoch": 1.234888888888889,
      "grad_norm": 0.37976542115211487,
      "learning_rate": 1.912777777777778e-05,
      "loss": 0.0016,
      "step": 55570
    },
    {
      "epoch": 1.235111111111111,
      "grad_norm": 0.3484876751899719,
      "learning_rate": 1.9122222222222222e-05,
      "loss": 0.0034,
      "step": 55580
    },
    {
      "epoch": 1.2353333333333334,
      "grad_norm": 0.23982948064804077,
      "learning_rate": 1.911666666666667e-05,
      "loss": 0.002,
      "step": 55590
    },
    {
      "epoch": 1.2355555555555555,
      "grad_norm": 0.07403021305799484,
      "learning_rate": 1.9111111111111113e-05,
      "loss": 0.0027,
      "step": 55600
    },
    {
      "epoch": 1.2357777777777779,
      "grad_norm": 0.19369088113307953,
      "learning_rate": 1.9105555555555557e-05,
      "loss": 0.0018,
      "step": 55610
    },
    {
      "epoch": 1.236,
      "grad_norm": 0.12501557171344757,
      "learning_rate": 1.91e-05,
      "loss": 0.002,
      "step": 55620
    },
    {
      "epoch": 1.2362222222222221,
      "grad_norm": 0.18214459717273712,
      "learning_rate": 1.9094444444444447e-05,
      "loss": 0.0018,
      "step": 55630
    },
    {
      "epoch": 1.2364444444444445,
      "grad_norm": 0.13657014071941376,
      "learning_rate": 1.908888888888889e-05,
      "loss": 0.0025,
      "step": 55640
    },
    {
      "epoch": 1.2366666666666666,
      "grad_norm": 0.31388726830482483,
      "learning_rate": 1.9083333333333334e-05,
      "loss": 0.0019,
      "step": 55650
    },
    {
      "epoch": 1.236888888888889,
      "grad_norm": 0.18917670845985413,
      "learning_rate": 1.9077777777777778e-05,
      "loss": 0.0019,
      "step": 55660
    },
    {
      "epoch": 1.237111111111111,
      "grad_norm": 0.15623962879180908,
      "learning_rate": 1.907222222222222e-05,
      "loss": 0.0033,
      "step": 55670
    },
    {
      "epoch": 1.2373333333333334,
      "grad_norm": 0.08534891158342361,
      "learning_rate": 1.9066666666666668e-05,
      "loss": 0.0019,
      "step": 55680
    },
    {
      "epoch": 1.2375555555555555,
      "grad_norm": 0.07639247179031372,
      "learning_rate": 1.9061111111111112e-05,
      "loss": 0.0018,
      "step": 55690
    },
    {
      "epoch": 1.2377777777777779,
      "grad_norm": 0.37020015716552734,
      "learning_rate": 1.905555555555556e-05,
      "loss": 0.0022,
      "step": 55700
    },
    {
      "epoch": 1.238,
      "grad_norm": 0.1386348158121109,
      "learning_rate": 1.9050000000000002e-05,
      "loss": 0.0017,
      "step": 55710
    },
    {
      "epoch": 1.2382222222222223,
      "grad_norm": 0.10367639362812042,
      "learning_rate": 1.9044444444444446e-05,
      "loss": 0.0023,
      "step": 55720
    },
    {
      "epoch": 1.2384444444444445,
      "grad_norm": 0.197182297706604,
      "learning_rate": 1.903888888888889e-05,
      "loss": 0.002,
      "step": 55730
    },
    {
      "epoch": 1.2386666666666666,
      "grad_norm": 0.04425698518753052,
      "learning_rate": 1.9033333333333333e-05,
      "loss": 0.0019,
      "step": 55740
    },
    {
      "epoch": 1.238888888888889,
      "grad_norm": 0.21854627132415771,
      "learning_rate": 1.9027777777777776e-05,
      "loss": 0.0018,
      "step": 55750
    },
    {
      "epoch": 1.239111111111111,
      "grad_norm": 0.599590003490448,
      "learning_rate": 1.9022222222222223e-05,
      "loss": 0.0018,
      "step": 55760
    },
    {
      "epoch": 1.2393333333333334,
      "grad_norm": 0.07571181654930115,
      "learning_rate": 1.901666666666667e-05,
      "loss": 0.0023,
      "step": 55770
    },
    {
      "epoch": 1.2395555555555555,
      "grad_norm": 0.22267155349254608,
      "learning_rate": 1.9011111111111114e-05,
      "loss": 0.0017,
      "step": 55780
    },
    {
      "epoch": 1.2397777777777779,
      "grad_norm": 0.23151442408561707,
      "learning_rate": 1.9005555555555557e-05,
      "loss": 0.0022,
      "step": 55790
    },
    {
      "epoch": 1.24,
      "grad_norm": 0.22079260647296906,
      "learning_rate": 1.9e-05,
      "loss": 0.0028,
      "step": 55800
    },
    {
      "epoch": 1.2402222222222221,
      "grad_norm": 0.21193592250347137,
      "learning_rate": 1.8994444444444445e-05,
      "loss": 0.0019,
      "step": 55810
    },
    {
      "epoch": 1.2404444444444445,
      "grad_norm": 0.12263431400060654,
      "learning_rate": 1.8988888888888888e-05,
      "loss": 0.0021,
      "step": 55820
    },
    {
      "epoch": 1.2406666666666666,
      "grad_norm": 0.2543281018733978,
      "learning_rate": 1.8983333333333335e-05,
      "loss": 0.0021,
      "step": 55830
    },
    {
      "epoch": 1.240888888888889,
      "grad_norm": 0.07351519912481308,
      "learning_rate": 1.897777777777778e-05,
      "loss": 0.0019,
      "step": 55840
    },
    {
      "epoch": 1.241111111111111,
      "grad_norm": 0.4460326135158539,
      "learning_rate": 1.8972222222222222e-05,
      "loss": 0.0041,
      "step": 55850
    },
    {
      "epoch": 1.2413333333333334,
      "grad_norm": 0.13897323608398438,
      "learning_rate": 1.896666666666667e-05,
      "loss": 0.0023,
      "step": 55860
    },
    {
      "epoch": 1.2415555555555555,
      "grad_norm": 0.08887536078691483,
      "learning_rate": 1.8961111111111113e-05,
      "loss": 0.002,
      "step": 55870
    },
    {
      "epoch": 1.2417777777777779,
      "grad_norm": 0.07792583107948303,
      "learning_rate": 1.8955555555555556e-05,
      "loss": 0.0028,
      "step": 55880
    },
    {
      "epoch": 1.242,
      "grad_norm": 0.22025670111179352,
      "learning_rate": 1.895e-05,
      "loss": 0.0025,
      "step": 55890
    },
    {
      "epoch": 1.2422222222222223,
      "grad_norm": 0.7506755590438843,
      "learning_rate": 1.8944444444444447e-05,
      "loss": 0.0023,
      "step": 55900
    },
    {
      "epoch": 1.2424444444444445,
      "grad_norm": 0.09097445011138916,
      "learning_rate": 1.893888888888889e-05,
      "loss": 0.0021,
      "step": 55910
    },
    {
      "epoch": 1.2426666666666666,
      "grad_norm": 0.1657140702009201,
      "learning_rate": 1.8933333333333334e-05,
      "loss": 0.002,
      "step": 55920
    },
    {
      "epoch": 1.242888888888889,
      "grad_norm": 0.18197780847549438,
      "learning_rate": 1.8927777777777777e-05,
      "loss": 0.0022,
      "step": 55930
    },
    {
      "epoch": 1.243111111111111,
      "grad_norm": 0.11414934694766998,
      "learning_rate": 1.8922222222222224e-05,
      "loss": 0.0021,
      "step": 55940
    },
    {
      "epoch": 1.2433333333333334,
      "grad_norm": 0.5508929491043091,
      "learning_rate": 1.8916666666666668e-05,
      "loss": 0.002,
      "step": 55950
    },
    {
      "epoch": 1.2435555555555555,
      "grad_norm": 0.10078687220811844,
      "learning_rate": 1.891111111111111e-05,
      "loss": 0.0034,
      "step": 55960
    },
    {
      "epoch": 1.2437777777777779,
      "grad_norm": 0.4125504195690155,
      "learning_rate": 1.890555555555556e-05,
      "loss": 0.0018,
      "step": 55970
    },
    {
      "epoch": 1.244,
      "grad_norm": 0.2136203646659851,
      "learning_rate": 1.8900000000000002e-05,
      "loss": 0.0017,
      "step": 55980
    },
    {
      "epoch": 1.2442222222222221,
      "grad_norm": 0.20074564218521118,
      "learning_rate": 1.8894444444444446e-05,
      "loss": 0.0025,
      "step": 55990
    },
    {
      "epoch": 1.2444444444444445,
      "grad_norm": 0.17566218972206116,
      "learning_rate": 1.888888888888889e-05,
      "loss": 0.0024,
      "step": 56000
    },
    {
      "epoch": 1.2446666666666666,
      "grad_norm": 0.38824936747550964,
      "learning_rate": 1.8883333333333333e-05,
      "loss": 0.0023,
      "step": 56010
    },
    {
      "epoch": 1.244888888888889,
      "grad_norm": 0.1307031363248825,
      "learning_rate": 1.8877777777777776e-05,
      "loss": 0.0028,
      "step": 56020
    },
    {
      "epoch": 1.245111111111111,
      "grad_norm": 0.23652713000774384,
      "learning_rate": 1.8872222222222223e-05,
      "loss": 0.0019,
      "step": 56030
    },
    {
      "epoch": 1.2453333333333334,
      "grad_norm": 0.6128230094909668,
      "learning_rate": 1.886666666666667e-05,
      "loss": 0.0022,
      "step": 56040
    },
    {
      "epoch": 1.2455555555555555,
      "grad_norm": 0.08493521809577942,
      "learning_rate": 1.8861111111111114e-05,
      "loss": 0.0019,
      "step": 56050
    },
    {
      "epoch": 1.2457777777777779,
      "grad_norm": 0.4113497734069824,
      "learning_rate": 1.8855555555555557e-05,
      "loss": 0.0018,
      "step": 56060
    },
    {
      "epoch": 1.246,
      "grad_norm": 0.15901827812194824,
      "learning_rate": 1.885e-05,
      "loss": 0.0024,
      "step": 56070
    },
    {
      "epoch": 1.2462222222222223,
      "grad_norm": 0.3179757595062256,
      "learning_rate": 1.8844444444444444e-05,
      "loss": 0.002,
      "step": 56080
    },
    {
      "epoch": 1.2464444444444445,
      "grad_norm": 0.5711562037467957,
      "learning_rate": 1.8838888888888888e-05,
      "loss": 0.0017,
      "step": 56090
    },
    {
      "epoch": 1.2466666666666666,
      "grad_norm": 0.1549120843410492,
      "learning_rate": 1.8833333333333335e-05,
      "loss": 0.0022,
      "step": 56100
    },
    {
      "epoch": 1.246888888888889,
      "grad_norm": 0.5316888093948364,
      "learning_rate": 1.882777777777778e-05,
      "loss": 0.0028,
      "step": 56110
    },
    {
      "epoch": 1.247111111111111,
      "grad_norm": 0.1824083775281906,
      "learning_rate": 1.8822222222222225e-05,
      "loss": 0.0028,
      "step": 56120
    },
    {
      "epoch": 1.2473333333333334,
      "grad_norm": 0.42803269624710083,
      "learning_rate": 1.881666666666667e-05,
      "loss": 0.0027,
      "step": 56130
    },
    {
      "epoch": 1.2475555555555555,
      "grad_norm": 0.2938813269138336,
      "learning_rate": 1.8811111111111112e-05,
      "loss": 0.0022,
      "step": 56140
    },
    {
      "epoch": 1.2477777777777779,
      "grad_norm": 0.42553916573524475,
      "learning_rate": 1.8805555555555556e-05,
      "loss": 0.0017,
      "step": 56150
    },
    {
      "epoch": 1.248,
      "grad_norm": 0.2310122549533844,
      "learning_rate": 1.88e-05,
      "loss": 0.002,
      "step": 56160
    },
    {
      "epoch": 1.2482222222222221,
      "grad_norm": 0.5558630228042603,
      "learning_rate": 1.8794444444444447e-05,
      "loss": 0.0021,
      "step": 56170
    },
    {
      "epoch": 1.2484444444444445,
      "grad_norm": 0.20572760701179504,
      "learning_rate": 1.878888888888889e-05,
      "loss": 0.0022,
      "step": 56180
    },
    {
      "epoch": 1.2486666666666666,
      "grad_norm": 0.21537800133228302,
      "learning_rate": 1.8783333333333334e-05,
      "loss": 0.0017,
      "step": 56190
    },
    {
      "epoch": 1.248888888888889,
      "grad_norm": 0.21029332280158997,
      "learning_rate": 1.8777777777777777e-05,
      "loss": 0.0022,
      "step": 56200
    },
    {
      "epoch": 1.249111111111111,
      "grad_norm": 0.16980689764022827,
      "learning_rate": 1.8772222222222224e-05,
      "loss": 0.0034,
      "step": 56210
    },
    {
      "epoch": 1.2493333333333334,
      "grad_norm": 0.5047878623008728,
      "learning_rate": 1.8766666666666668e-05,
      "loss": 0.0019,
      "step": 56220
    },
    {
      "epoch": 1.2495555555555555,
      "grad_norm": 0.6985981464385986,
      "learning_rate": 1.876111111111111e-05,
      "loss": 0.0017,
      "step": 56230
    },
    {
      "epoch": 1.2497777777777777,
      "grad_norm": 0.2611517608165741,
      "learning_rate": 1.8755555555555558e-05,
      "loss": 0.002,
      "step": 56240
    },
    {
      "epoch": 1.25,
      "grad_norm": 0.06924421340227127,
      "learning_rate": 1.8750000000000002e-05,
      "loss": 0.0022,
      "step": 56250
    },
    {
      "epoch": 1.2502222222222223,
      "grad_norm": 0.0994349792599678,
      "learning_rate": 1.8744444444444445e-05,
      "loss": 0.0022,
      "step": 56260
    },
    {
      "epoch": 1.2504444444444445,
      "grad_norm": 0.11198613792657852,
      "learning_rate": 1.873888888888889e-05,
      "loss": 0.0022,
      "step": 56270
    },
    {
      "epoch": 1.2506666666666666,
      "grad_norm": 0.2946530878543854,
      "learning_rate": 1.8733333333333332e-05,
      "loss": 0.002,
      "step": 56280
    },
    {
      "epoch": 1.250888888888889,
      "grad_norm": 0.19022437930107117,
      "learning_rate": 1.8727777777777776e-05,
      "loss": 0.0018,
      "step": 56290
    },
    {
      "epoch": 1.251111111111111,
      "grad_norm": 0.10061337053775787,
      "learning_rate": 1.8722222222222223e-05,
      "loss": 0.0017,
      "step": 56300
    },
    {
      "epoch": 1.2513333333333334,
      "grad_norm": 0.06973496824502945,
      "learning_rate": 1.871666666666667e-05,
      "loss": 0.002,
      "step": 56310
    },
    {
      "epoch": 1.2515555555555555,
      "grad_norm": 0.31192147731781006,
      "learning_rate": 1.8711111111111113e-05,
      "loss": 0.003,
      "step": 56320
    },
    {
      "epoch": 1.2517777777777779,
      "grad_norm": 0.2627255320549011,
      "learning_rate": 1.8705555555555557e-05,
      "loss": 0.0026,
      "step": 56330
    },
    {
      "epoch": 1.252,
      "grad_norm": 0.3769233822822571,
      "learning_rate": 1.87e-05,
      "loss": 0.0019,
      "step": 56340
    },
    {
      "epoch": 1.2522222222222221,
      "grad_norm": 0.2683781683444977,
      "learning_rate": 1.8694444444444444e-05,
      "loss": 0.0027,
      "step": 56350
    },
    {
      "epoch": 1.2524444444444445,
      "grad_norm": 0.40804070234298706,
      "learning_rate": 1.8688888888888888e-05,
      "loss": 0.0019,
      "step": 56360
    },
    {
      "epoch": 1.2526666666666666,
      "grad_norm": 0.08340074121952057,
      "learning_rate": 1.8683333333333335e-05,
      "loss": 0.0019,
      "step": 56370
    },
    {
      "epoch": 1.252888888888889,
      "grad_norm": 0.1691320538520813,
      "learning_rate": 1.8677777777777778e-05,
      "loss": 0.0016,
      "step": 56380
    },
    {
      "epoch": 1.253111111111111,
      "grad_norm": 0.14442864060401917,
      "learning_rate": 1.8672222222222225e-05,
      "loss": 0.0021,
      "step": 56390
    },
    {
      "epoch": 1.2533333333333334,
      "grad_norm": 0.22897255420684814,
      "learning_rate": 1.866666666666667e-05,
      "loss": 0.0024,
      "step": 56400
    },
    {
      "epoch": 1.2535555555555555,
      "grad_norm": 0.2057478278875351,
      "learning_rate": 1.8661111111111112e-05,
      "loss": 0.0025,
      "step": 56410
    },
    {
      "epoch": 1.2537777777777777,
      "grad_norm": 0.10220170021057129,
      "learning_rate": 1.8655555555555556e-05,
      "loss": 0.0021,
      "step": 56420
    },
    {
      "epoch": 1.254,
      "grad_norm": 0.3782908320426941,
      "learning_rate": 1.865e-05,
      "loss": 0.0022,
      "step": 56430
    },
    {
      "epoch": 1.2542222222222223,
      "grad_norm": 0.2164689302444458,
      "learning_rate": 1.8644444444444446e-05,
      "loss": 0.0021,
      "step": 56440
    },
    {
      "epoch": 1.2544444444444445,
      "grad_norm": 0.2722897231578827,
      "learning_rate": 1.863888888888889e-05,
      "loss": 0.0019,
      "step": 56450
    },
    {
      "epoch": 1.2546666666666666,
      "grad_norm": 0.1691046953201294,
      "learning_rate": 1.8633333333333333e-05,
      "loss": 0.0017,
      "step": 56460
    },
    {
      "epoch": 1.254888888888889,
      "grad_norm": 0.45772668719291687,
      "learning_rate": 1.8627777777777777e-05,
      "loss": 0.002,
      "step": 56470
    },
    {
      "epoch": 1.255111111111111,
      "grad_norm": 0.20675145089626312,
      "learning_rate": 1.8622222222222224e-05,
      "loss": 0.002,
      "step": 56480
    },
    {
      "epoch": 1.2553333333333334,
      "grad_norm": 0.1348867267370224,
      "learning_rate": 1.8616666666666667e-05,
      "loss": 0.0021,
      "step": 56490
    },
    {
      "epoch": 1.2555555555555555,
      "grad_norm": 0.41838985681533813,
      "learning_rate": 1.861111111111111e-05,
      "loss": 0.0023,
      "step": 56500
    },
    {
      "epoch": 1.2557777777777779,
      "grad_norm": 0.08256152272224426,
      "learning_rate": 1.8605555555555558e-05,
      "loss": 0.0016,
      "step": 56510
    },
    {
      "epoch": 1.256,
      "grad_norm": 0.5536353588104248,
      "learning_rate": 1.86e-05,
      "loss": 0.0022,
      "step": 56520
    },
    {
      "epoch": 1.2562222222222221,
      "grad_norm": 0.06856405735015869,
      "learning_rate": 1.8594444444444445e-05,
      "loss": 0.0019,
      "step": 56530
    },
    {
      "epoch": 1.2564444444444445,
      "grad_norm": 0.3447470963001251,
      "learning_rate": 1.858888888888889e-05,
      "loss": 0.002,
      "step": 56540
    },
    {
      "epoch": 1.2566666666666666,
      "grad_norm": 0.36288708448410034,
      "learning_rate": 1.8583333333333332e-05,
      "loss": 0.0019,
      "step": 56550
    },
    {
      "epoch": 1.256888888888889,
      "grad_norm": 0.1317354440689087,
      "learning_rate": 1.8577777777777776e-05,
      "loss": 0.0026,
      "step": 56560
    },
    {
      "epoch": 1.257111111111111,
      "grad_norm": 0.2480028122663498,
      "learning_rate": 1.8572222222222223e-05,
      "loss": 0.0022,
      "step": 56570
    },
    {
      "epoch": 1.2573333333333334,
      "grad_norm": 0.07619544118642807,
      "learning_rate": 1.856666666666667e-05,
      "loss": 0.0028,
      "step": 56580
    },
    {
      "epoch": 1.2575555555555555,
      "grad_norm": 0.2459469586610794,
      "learning_rate": 1.8561111111111113e-05,
      "loss": 0.0019,
      "step": 56590
    },
    {
      "epoch": 1.2577777777777777,
      "grad_norm": 0.11935246735811234,
      "learning_rate": 1.8555555555555557e-05,
      "loss": 0.0019,
      "step": 56600
    },
    {
      "epoch": 1.258,
      "grad_norm": 0.1466091126203537,
      "learning_rate": 1.855e-05,
      "loss": 0.0023,
      "step": 56610
    },
    {
      "epoch": 1.2582222222222224,
      "grad_norm": 0.18211941421031952,
      "learning_rate": 1.8544444444444444e-05,
      "loss": 0.0018,
      "step": 56620
    },
    {
      "epoch": 1.2584444444444445,
      "grad_norm": 0.20735937356948853,
      "learning_rate": 1.8538888888888887e-05,
      "loss": 0.0021,
      "step": 56630
    },
    {
      "epoch": 1.2586666666666666,
      "grad_norm": 0.06962347775697708,
      "learning_rate": 1.8533333333333334e-05,
      "loss": 0.0019,
      "step": 56640
    },
    {
      "epoch": 1.258888888888889,
      "grad_norm": 0.40933558344841003,
      "learning_rate": 1.852777777777778e-05,
      "loss": 0.0026,
      "step": 56650
    },
    {
      "epoch": 1.259111111111111,
      "grad_norm": 0.27226200699806213,
      "learning_rate": 1.8522222222222225e-05,
      "loss": 0.0024,
      "step": 56660
    },
    {
      "epoch": 1.2593333333333334,
      "grad_norm": 0.10552224516868591,
      "learning_rate": 1.851666666666667e-05,
      "loss": 0.0034,
      "step": 56670
    },
    {
      "epoch": 1.2595555555555555,
      "grad_norm": 0.09877248108386993,
      "learning_rate": 1.8511111111111112e-05,
      "loss": 0.002,
      "step": 56680
    },
    {
      "epoch": 1.2597777777777779,
      "grad_norm": 0.08223331719636917,
      "learning_rate": 1.8505555555555556e-05,
      "loss": 0.0017,
      "step": 56690
    },
    {
      "epoch": 1.26,
      "grad_norm": 0.5326204895973206,
      "learning_rate": 1.85e-05,
      "loss": 0.0017,
      "step": 56700
    },
    {
      "epoch": 1.2602222222222221,
      "grad_norm": 0.37344595789909363,
      "learning_rate": 1.8494444444444446e-05,
      "loss": 0.003,
      "step": 56710
    },
    {
      "epoch": 1.2604444444444445,
      "grad_norm": 0.07028700411319733,
      "learning_rate": 1.848888888888889e-05,
      "loss": 0.0019,
      "step": 56720
    },
    {
      "epoch": 1.2606666666666666,
      "grad_norm": 0.2608092427253723,
      "learning_rate": 1.8483333333333333e-05,
      "loss": 0.0019,
      "step": 56730
    },
    {
      "epoch": 1.260888888888889,
      "grad_norm": 0.3674374222755432,
      "learning_rate": 1.847777777777778e-05,
      "loss": 0.0023,
      "step": 56740
    },
    {
      "epoch": 1.261111111111111,
      "grad_norm": 0.20908206701278687,
      "learning_rate": 1.8472222222222224e-05,
      "loss": 0.0032,
      "step": 56750
    },
    {
      "epoch": 1.2613333333333334,
      "grad_norm": 0.3612563908100128,
      "learning_rate": 1.8466666666666667e-05,
      "loss": 0.0025,
      "step": 56760
    },
    {
      "epoch": 1.2615555555555555,
      "grad_norm": 0.10071668028831482,
      "learning_rate": 1.846111111111111e-05,
      "loss": 0.0027,
      "step": 56770
    },
    {
      "epoch": 1.2617777777777777,
      "grad_norm": 0.36021846532821655,
      "learning_rate": 1.8455555555555558e-05,
      "loss": 0.0016,
      "step": 56780
    },
    {
      "epoch": 1.262,
      "grad_norm": 0.10142721980810165,
      "learning_rate": 1.845e-05,
      "loss": 0.0021,
      "step": 56790
    },
    {
      "epoch": 1.2622222222222224,
      "grad_norm": 0.07999515533447266,
      "learning_rate": 1.8444444444444445e-05,
      "loss": 0.0018,
      "step": 56800
    },
    {
      "epoch": 1.2624444444444445,
      "grad_norm": 0.23136703670024872,
      "learning_rate": 1.843888888888889e-05,
      "loss": 0.0018,
      "step": 56810
    },
    {
      "epoch": 1.2626666666666666,
      "grad_norm": 0.7795445919036865,
      "learning_rate": 1.8433333333333332e-05,
      "loss": 0.002,
      "step": 56820
    },
    {
      "epoch": 1.262888888888889,
      "grad_norm": 0.40822839736938477,
      "learning_rate": 1.842777777777778e-05,
      "loss": 0.0025,
      "step": 56830
    },
    {
      "epoch": 1.263111111111111,
      "grad_norm": 0.6381939649581909,
      "learning_rate": 1.8422222222222222e-05,
      "loss": 0.0019,
      "step": 56840
    },
    {
      "epoch": 1.2633333333333332,
      "grad_norm": 0.17219515144824982,
      "learning_rate": 1.841666666666667e-05,
      "loss": 0.0023,
      "step": 56850
    },
    {
      "epoch": 1.2635555555555555,
      "grad_norm": 0.1445440798997879,
      "learning_rate": 1.8411111111111113e-05,
      "loss": 0.003,
      "step": 56860
    },
    {
      "epoch": 1.2637777777777779,
      "grad_norm": 0.1346375197172165,
      "learning_rate": 1.8405555555555556e-05,
      "loss": 0.0019,
      "step": 56870
    },
    {
      "epoch": 1.264,
      "grad_norm": 0.3354450464248657,
      "learning_rate": 1.84e-05,
      "loss": 0.002,
      "step": 56880
    },
    {
      "epoch": 1.2642222222222221,
      "grad_norm": 0.0877610296010971,
      "learning_rate": 1.8394444444444444e-05,
      "loss": 0.002,
      "step": 56890
    },
    {
      "epoch": 1.2644444444444445,
      "grad_norm": 0.07712045311927795,
      "learning_rate": 1.838888888888889e-05,
      "loss": 0.0022,
      "step": 56900
    },
    {
      "epoch": 1.2646666666666666,
      "grad_norm": 0.4271964132785797,
      "learning_rate": 1.8383333333333334e-05,
      "loss": 0.0018,
      "step": 56910
    },
    {
      "epoch": 1.264888888888889,
      "grad_norm": 0.16597463190555573,
      "learning_rate": 1.837777777777778e-05,
      "loss": 0.002,
      "step": 56920
    },
    {
      "epoch": 1.265111111111111,
      "grad_norm": 0.10405007749795914,
      "learning_rate": 1.8372222222222225e-05,
      "loss": 0.0021,
      "step": 56930
    },
    {
      "epoch": 1.2653333333333334,
      "grad_norm": 0.3181854784488678,
      "learning_rate": 1.8366666666666668e-05,
      "loss": 0.0023,
      "step": 56940
    },
    {
      "epoch": 1.2655555555555555,
      "grad_norm": 0.19976650178432465,
      "learning_rate": 1.836111111111111e-05,
      "loss": 0.0025,
      "step": 56950
    },
    {
      "epoch": 1.2657777777777777,
      "grad_norm": 0.46490201354026794,
      "learning_rate": 1.8355555555555555e-05,
      "loss": 0.002,
      "step": 56960
    },
    {
      "epoch": 1.266,
      "grad_norm": 0.07634469121694565,
      "learning_rate": 1.8350000000000002e-05,
      "loss": 0.0025,
      "step": 56970
    },
    {
      "epoch": 1.2662222222222224,
      "grad_norm": 0.14151887595653534,
      "learning_rate": 1.8344444444444446e-05,
      "loss": 0.0017,
      "step": 56980
    },
    {
      "epoch": 1.2664444444444445,
      "grad_norm": 0.08143330365419388,
      "learning_rate": 1.833888888888889e-05,
      "loss": 0.0024,
      "step": 56990
    },
    {
      "epoch": 1.2666666666666666,
      "grad_norm": 0.3264680504798889,
      "learning_rate": 1.8333333333333333e-05,
      "loss": 0.0025,
      "step": 57000
    },
    {
      "epoch": 1.266888888888889,
      "grad_norm": 0.40368378162384033,
      "learning_rate": 1.832777777777778e-05,
      "loss": 0.0019,
      "step": 57010
    },
    {
      "epoch": 1.267111111111111,
      "grad_norm": 0.38086140155792236,
      "learning_rate": 1.8322222222222223e-05,
      "loss": 0.0025,
      "step": 57020
    },
    {
      "epoch": 1.2673333333333332,
      "grad_norm": 0.10517053306102753,
      "learning_rate": 1.8316666666666667e-05,
      "loss": 0.0025,
      "step": 57030
    },
    {
      "epoch": 1.2675555555555555,
      "grad_norm": 0.6420117616653442,
      "learning_rate": 1.8311111111111114e-05,
      "loss": 0.0019,
      "step": 57040
    },
    {
      "epoch": 1.267777777777778,
      "grad_norm": 0.3493562936782837,
      "learning_rate": 1.8305555555555557e-05,
      "loss": 0.0024,
      "step": 57050
    },
    {
      "epoch": 1.268,
      "grad_norm": 0.257251501083374,
      "learning_rate": 1.83e-05,
      "loss": 0.0019,
      "step": 57060
    },
    {
      "epoch": 1.2682222222222221,
      "grad_norm": 0.09119009971618652,
      "learning_rate": 1.8294444444444445e-05,
      "loss": 0.0019,
      "step": 57070
    },
    {
      "epoch": 1.2684444444444445,
      "grad_norm": 0.21032166481018066,
      "learning_rate": 1.8288888888888888e-05,
      "loss": 0.0023,
      "step": 57080
    },
    {
      "epoch": 1.2686666666666666,
      "grad_norm": 0.43251341581344604,
      "learning_rate": 1.828333333333333e-05,
      "loss": 0.0019,
      "step": 57090
    },
    {
      "epoch": 1.268888888888889,
      "grad_norm": 0.07270586490631104,
      "learning_rate": 1.827777777777778e-05,
      "loss": 0.0017,
      "step": 57100
    },
    {
      "epoch": 1.269111111111111,
      "grad_norm": 0.259474515914917,
      "learning_rate": 1.8272222222222226e-05,
      "loss": 0.002,
      "step": 57110
    },
    {
      "epoch": 1.2693333333333334,
      "grad_norm": 0.16088426113128662,
      "learning_rate": 1.826666666666667e-05,
      "loss": 0.0026,
      "step": 57120
    },
    {
      "epoch": 1.2695555555555555,
      "grad_norm": 0.17300137877464294,
      "learning_rate": 1.8261111111111113e-05,
      "loss": 0.0024,
      "step": 57130
    },
    {
      "epoch": 1.2697777777777777,
      "grad_norm": 0.3125624358654022,
      "learning_rate": 1.8255555555555556e-05,
      "loss": 0.0028,
      "step": 57140
    },
    {
      "epoch": 1.27,
      "grad_norm": 0.1353738009929657,
      "learning_rate": 1.825e-05,
      "loss": 0.0025,
      "step": 57150
    },
    {
      "epoch": 1.2702222222222221,
      "grad_norm": 0.25593245029449463,
      "learning_rate": 1.8244444444444443e-05,
      "loss": 0.002,
      "step": 57160
    },
    {
      "epoch": 1.2704444444444445,
      "grad_norm": 0.1040782630443573,
      "learning_rate": 1.823888888888889e-05,
      "loss": 0.0017,
      "step": 57170
    },
    {
      "epoch": 1.2706666666666666,
      "grad_norm": 0.08654129505157471,
      "learning_rate": 1.8233333333333334e-05,
      "loss": 0.0018,
      "step": 57180
    },
    {
      "epoch": 1.270888888888889,
      "grad_norm": 0.08988654613494873,
      "learning_rate": 1.822777777777778e-05,
      "loss": 0.0018,
      "step": 57190
    },
    {
      "epoch": 1.271111111111111,
      "grad_norm": 0.3397526741027832,
      "learning_rate": 1.8222222222222224e-05,
      "loss": 0.0019,
      "step": 57200
    },
    {
      "epoch": 1.2713333333333332,
      "grad_norm": 0.09052854031324387,
      "learning_rate": 1.8216666666666668e-05,
      "loss": 0.0028,
      "step": 57210
    },
    {
      "epoch": 1.2715555555555556,
      "grad_norm": 0.4338945746421814,
      "learning_rate": 1.821111111111111e-05,
      "loss": 0.0017,
      "step": 57220
    },
    {
      "epoch": 1.271777777777778,
      "grad_norm": 0.48860493302345276,
      "learning_rate": 1.8205555555555555e-05,
      "loss": 0.0025,
      "step": 57230
    },
    {
      "epoch": 1.272,
      "grad_norm": 0.8224771022796631,
      "learning_rate": 1.8200000000000002e-05,
      "loss": 0.0025,
      "step": 57240
    },
    {
      "epoch": 1.2722222222222221,
      "grad_norm": 0.3590320646762848,
      "learning_rate": 1.8194444444444445e-05,
      "loss": 0.0016,
      "step": 57250
    },
    {
      "epoch": 1.2724444444444445,
      "grad_norm": 0.29863104224205017,
      "learning_rate": 1.818888888888889e-05,
      "loss": 0.0019,
      "step": 57260
    },
    {
      "epoch": 1.2726666666666666,
      "grad_norm": 0.07695261389017105,
      "learning_rate": 1.8183333333333336e-05,
      "loss": 0.002,
      "step": 57270
    },
    {
      "epoch": 1.272888888888889,
      "grad_norm": 0.3994438946247101,
      "learning_rate": 1.817777777777778e-05,
      "loss": 0.0027,
      "step": 57280
    },
    {
      "epoch": 1.273111111111111,
      "grad_norm": 0.26017168164253235,
      "learning_rate": 1.8172222222222223e-05,
      "loss": 0.0027,
      "step": 57290
    },
    {
      "epoch": 1.2733333333333334,
      "grad_norm": 0.14465993642807007,
      "learning_rate": 1.8166666666666667e-05,
      "loss": 0.0017,
      "step": 57300
    },
    {
      "epoch": 1.2735555555555556,
      "grad_norm": 0.21732130646705627,
      "learning_rate": 1.8161111111111114e-05,
      "loss": 0.0017,
      "step": 57310
    },
    {
      "epoch": 1.2737777777777777,
      "grad_norm": 0.46924492716789246,
      "learning_rate": 1.8155555555555557e-05,
      "loss": 0.0019,
      "step": 57320
    },
    {
      "epoch": 1.274,
      "grad_norm": 0.5948363542556763,
      "learning_rate": 1.815e-05,
      "loss": 0.0022,
      "step": 57330
    },
    {
      "epoch": 1.2742222222222221,
      "grad_norm": 0.16773436963558197,
      "learning_rate": 1.8144444444444444e-05,
      "loss": 0.0018,
      "step": 57340
    },
    {
      "epoch": 1.2744444444444445,
      "grad_norm": 0.4015887975692749,
      "learning_rate": 1.8138888888888888e-05,
      "loss": 0.0035,
      "step": 57350
    },
    {
      "epoch": 1.2746666666666666,
      "grad_norm": 0.34744641184806824,
      "learning_rate": 1.8133333333333335e-05,
      "loss": 0.0019,
      "step": 57360
    },
    {
      "epoch": 1.274888888888889,
      "grad_norm": 0.16689899563789368,
      "learning_rate": 1.812777777777778e-05,
      "loss": 0.0024,
      "step": 57370
    },
    {
      "epoch": 1.275111111111111,
      "grad_norm": 0.10562288016080856,
      "learning_rate": 1.8122222222222225e-05,
      "loss": 0.0026,
      "step": 57380
    },
    {
      "epoch": 1.2753333333333332,
      "grad_norm": 0.29632052779197693,
      "learning_rate": 1.811666666666667e-05,
      "loss": 0.002,
      "step": 57390
    },
    {
      "epoch": 1.2755555555555556,
      "grad_norm": 0.24278485774993896,
      "learning_rate": 1.8111111111111112e-05,
      "loss": 0.002,
      "step": 57400
    },
    {
      "epoch": 1.275777777777778,
      "grad_norm": 0.05937551334500313,
      "learning_rate": 1.8105555555555556e-05,
      "loss": 0.0018,
      "step": 57410
    },
    {
      "epoch": 1.276,
      "grad_norm": 0.39383676648139954,
      "learning_rate": 1.81e-05,
      "loss": 0.0018,
      "step": 57420
    },
    {
      "epoch": 1.2762222222222221,
      "grad_norm": 0.19014793634414673,
      "learning_rate": 1.8094444444444443e-05,
      "loss": 0.0026,
      "step": 57430
    },
    {
      "epoch": 1.2764444444444445,
      "grad_norm": 0.13025279343128204,
      "learning_rate": 1.808888888888889e-05,
      "loss": 0.0018,
      "step": 57440
    },
    {
      "epoch": 1.2766666666666666,
      "grad_norm": 0.3924761414527893,
      "learning_rate": 1.8083333333333337e-05,
      "loss": 0.0022,
      "step": 57450
    },
    {
      "epoch": 1.276888888888889,
      "grad_norm": 0.11352010071277618,
      "learning_rate": 1.807777777777778e-05,
      "loss": 0.0019,
      "step": 57460
    },
    {
      "epoch": 1.277111111111111,
      "grad_norm": 0.5171027779579163,
      "learning_rate": 1.8072222222222224e-05,
      "loss": 0.0032,
      "step": 57470
    },
    {
      "epoch": 1.2773333333333334,
      "grad_norm": 0.16273272037506104,
      "learning_rate": 1.8066666666666668e-05,
      "loss": 0.0019,
      "step": 57480
    },
    {
      "epoch": 1.2775555555555556,
      "grad_norm": 0.2948352098464966,
      "learning_rate": 1.806111111111111e-05,
      "loss": 0.002,
      "step": 57490
    },
    {
      "epoch": 1.2777777777777777,
      "grad_norm": 0.1340782195329666,
      "learning_rate": 1.8055555555555555e-05,
      "loss": 0.0024,
      "step": 57500
    },
    {
      "epoch": 1.278,
      "grad_norm": 0.15088887512683868,
      "learning_rate": 1.805e-05,
      "loss": 0.0028,
      "step": 57510
    },
    {
      "epoch": 1.2782222222222221,
      "grad_norm": 0.2082221359014511,
      "learning_rate": 1.8044444444444445e-05,
      "loss": 0.003,
      "step": 57520
    },
    {
      "epoch": 1.2784444444444445,
      "grad_norm": 0.12552568316459656,
      "learning_rate": 1.803888888888889e-05,
      "loss": 0.0019,
      "step": 57530
    },
    {
      "epoch": 1.2786666666666666,
      "grad_norm": 0.2182607352733612,
      "learning_rate": 1.8033333333333336e-05,
      "loss": 0.0027,
      "step": 57540
    },
    {
      "epoch": 1.278888888888889,
      "grad_norm": 0.29075518250465393,
      "learning_rate": 1.802777777777778e-05,
      "loss": 0.0024,
      "step": 57550
    },
    {
      "epoch": 1.279111111111111,
      "grad_norm": 0.6245161294937134,
      "learning_rate": 1.8022222222222223e-05,
      "loss": 0.0021,
      "step": 57560
    },
    {
      "epoch": 1.2793333333333332,
      "grad_norm": 0.0533369705080986,
      "learning_rate": 1.8016666666666666e-05,
      "loss": 0.0017,
      "step": 57570
    },
    {
      "epoch": 1.2795555555555556,
      "grad_norm": 0.18049080669879913,
      "learning_rate": 1.8011111111111113e-05,
      "loss": 0.0019,
      "step": 57580
    },
    {
      "epoch": 1.279777777777778,
      "grad_norm": 0.18292202055454254,
      "learning_rate": 1.8005555555555557e-05,
      "loss": 0.002,
      "step": 57590
    },
    {
      "epoch": 1.28,
      "grad_norm": 0.08540504425764084,
      "learning_rate": 1.8e-05,
      "loss": 0.0019,
      "step": 57600
    },
    {
      "epoch": 1.2802222222222222,
      "grad_norm": 0.2718121111392975,
      "learning_rate": 1.7994444444444444e-05,
      "loss": 0.0018,
      "step": 57610
    },
    {
      "epoch": 1.2804444444444445,
      "grad_norm": 0.13551919162273407,
      "learning_rate": 1.7988888888888888e-05,
      "loss": 0.0016,
      "step": 57620
    },
    {
      "epoch": 1.2806666666666666,
      "grad_norm": 0.28911319375038147,
      "learning_rate": 1.7983333333333335e-05,
      "loss": 0.0027,
      "step": 57630
    },
    {
      "epoch": 1.280888888888889,
      "grad_norm": 0.12649904191493988,
      "learning_rate": 1.7977777777777778e-05,
      "loss": 0.0017,
      "step": 57640
    },
    {
      "epoch": 1.281111111111111,
      "grad_norm": 0.104060597717762,
      "learning_rate": 1.7972222222222225e-05,
      "loss": 0.0021,
      "step": 57650
    },
    {
      "epoch": 1.2813333333333334,
      "grad_norm": 0.09754998981952667,
      "learning_rate": 1.796666666666667e-05,
      "loss": 0.0028,
      "step": 57660
    },
    {
      "epoch": 1.2815555555555556,
      "grad_norm": 0.12371844798326492,
      "learning_rate": 1.7961111111111112e-05,
      "loss": 0.0025,
      "step": 57670
    },
    {
      "epoch": 1.2817777777777777,
      "grad_norm": 0.6841171383857727,
      "learning_rate": 1.7955555555555556e-05,
      "loss": 0.0018,
      "step": 57680
    },
    {
      "epoch": 1.282,
      "grad_norm": 0.5010125637054443,
      "learning_rate": 1.795e-05,
      "loss": 0.0028,
      "step": 57690
    },
    {
      "epoch": 1.2822222222222222,
      "grad_norm": 0.16539250314235687,
      "learning_rate": 1.7944444444444443e-05,
      "loss": 0.0026,
      "step": 57700
    },
    {
      "epoch": 1.2824444444444445,
      "grad_norm": 0.07823796570301056,
      "learning_rate": 1.793888888888889e-05,
      "loss": 0.0021,
      "step": 57710
    },
    {
      "epoch": 1.2826666666666666,
      "grad_norm": 0.0929727554321289,
      "learning_rate": 1.7933333333333337e-05,
      "loss": 0.0019,
      "step": 57720
    },
    {
      "epoch": 1.282888888888889,
      "grad_norm": 0.08708743751049042,
      "learning_rate": 1.792777777777778e-05,
      "loss": 0.0021,
      "step": 57730
    },
    {
      "epoch": 1.283111111111111,
      "grad_norm": 0.21532943844795227,
      "learning_rate": 1.7922222222222224e-05,
      "loss": 0.0024,
      "step": 57740
    },
    {
      "epoch": 1.2833333333333332,
      "grad_norm": 0.09834475815296173,
      "learning_rate": 1.7916666666666667e-05,
      "loss": 0.0023,
      "step": 57750
    },
    {
      "epoch": 1.2835555555555556,
      "grad_norm": 0.1499139666557312,
      "learning_rate": 1.791111111111111e-05,
      "loss": 0.0028,
      "step": 57760
    },
    {
      "epoch": 1.283777777777778,
      "grad_norm": 0.4714111387729645,
      "learning_rate": 1.7905555555555554e-05,
      "loss": 0.002,
      "step": 57770
    },
    {
      "epoch": 1.284,
      "grad_norm": 0.08113450556993484,
      "learning_rate": 1.79e-05,
      "loss": 0.002,
      "step": 57780
    },
    {
      "epoch": 1.2842222222222222,
      "grad_norm": 0.27042704820632935,
      "learning_rate": 1.7894444444444445e-05,
      "loss": 0.003,
      "step": 57790
    },
    {
      "epoch": 1.2844444444444445,
      "grad_norm": 0.4112328588962555,
      "learning_rate": 1.788888888888889e-05,
      "loss": 0.0027,
      "step": 57800
    },
    {
      "epoch": 1.2846666666666666,
      "grad_norm": 0.1913215070962906,
      "learning_rate": 1.7883333333333335e-05,
      "loss": 0.0017,
      "step": 57810
    },
    {
      "epoch": 1.284888888888889,
      "grad_norm": 0.233698308467865,
      "learning_rate": 1.787777777777778e-05,
      "loss": 0.0021,
      "step": 57820
    },
    {
      "epoch": 1.285111111111111,
      "grad_norm": 0.10662826150655746,
      "learning_rate": 1.7872222222222223e-05,
      "loss": 0.0019,
      "step": 57830
    },
    {
      "epoch": 1.2853333333333334,
      "grad_norm": 0.49286922812461853,
      "learning_rate": 1.7866666666666666e-05,
      "loss": 0.0018,
      "step": 57840
    },
    {
      "epoch": 1.2855555555555556,
      "grad_norm": 0.11980384588241577,
      "learning_rate": 1.7861111111111113e-05,
      "loss": 0.0026,
      "step": 57850
    },
    {
      "epoch": 1.2857777777777777,
      "grad_norm": 0.05808109790086746,
      "learning_rate": 1.7855555555555557e-05,
      "loss": 0.0017,
      "step": 57860
    },
    {
      "epoch": 1.286,
      "grad_norm": 0.052563317120075226,
      "learning_rate": 1.785e-05,
      "loss": 0.0021,
      "step": 57870
    },
    {
      "epoch": 1.2862222222222222,
      "grad_norm": 0.08332960307598114,
      "learning_rate": 1.7844444444444444e-05,
      "loss": 0.0021,
      "step": 57880
    },
    {
      "epoch": 1.2864444444444445,
      "grad_norm": 0.144156813621521,
      "learning_rate": 1.783888888888889e-05,
      "loss": 0.0019,
      "step": 57890
    },
    {
      "epoch": 1.2866666666666666,
      "grad_norm": 0.21446698904037476,
      "learning_rate": 1.7833333333333334e-05,
      "loss": 0.0024,
      "step": 57900
    },
    {
      "epoch": 1.286888888888889,
      "grad_norm": 0.32528194785118103,
      "learning_rate": 1.7827777777777778e-05,
      "loss": 0.0021,
      "step": 57910
    },
    {
      "epoch": 1.287111111111111,
      "grad_norm": 0.19629724323749542,
      "learning_rate": 1.7822222222222225e-05,
      "loss": 0.0022,
      "step": 57920
    },
    {
      "epoch": 1.2873333333333332,
      "grad_norm": 0.2167631983757019,
      "learning_rate": 1.781666666666667e-05,
      "loss": 0.0025,
      "step": 57930
    },
    {
      "epoch": 1.2875555555555556,
      "grad_norm": 0.38057181239128113,
      "learning_rate": 1.7811111111111112e-05,
      "loss": 0.0021,
      "step": 57940
    },
    {
      "epoch": 1.287777777777778,
      "grad_norm": 0.20644262433052063,
      "learning_rate": 1.7805555555555555e-05,
      "loss": 0.0022,
      "step": 57950
    },
    {
      "epoch": 1.288,
      "grad_norm": 0.6242169737815857,
      "learning_rate": 1.78e-05,
      "loss": 0.002,
      "step": 57960
    },
    {
      "epoch": 1.2882222222222222,
      "grad_norm": 0.2695550322532654,
      "learning_rate": 1.7794444444444443e-05,
      "loss": 0.0017,
      "step": 57970
    },
    {
      "epoch": 1.2884444444444445,
      "grad_norm": 0.09600339084863663,
      "learning_rate": 1.778888888888889e-05,
      "loss": 0.0018,
      "step": 57980
    },
    {
      "epoch": 1.2886666666666666,
      "grad_norm": 0.3273994028568268,
      "learning_rate": 1.7783333333333336e-05,
      "loss": 0.0018,
      "step": 57990
    },
    {
      "epoch": 1.2888888888888888,
      "grad_norm": 0.3123064339160919,
      "learning_rate": 1.777777777777778e-05,
      "loss": 0.0025,
      "step": 58000
    },
    {
      "epoch": 1.289111111111111,
      "grad_norm": 0.20506781339645386,
      "learning_rate": 1.7772222222222224e-05,
      "loss": 0.0024,
      "step": 58010
    },
    {
      "epoch": 1.2893333333333334,
      "grad_norm": 0.08891323953866959,
      "learning_rate": 1.7766666666666667e-05,
      "loss": 0.0019,
      "step": 58020
    },
    {
      "epoch": 1.2895555555555556,
      "grad_norm": 0.07736438512802124,
      "learning_rate": 1.776111111111111e-05,
      "loss": 0.0022,
      "step": 58030
    },
    {
      "epoch": 1.2897777777777777,
      "grad_norm": 0.25096991658210754,
      "learning_rate": 1.7755555555555554e-05,
      "loss": 0.0027,
      "step": 58040
    },
    {
      "epoch": 1.29,
      "grad_norm": 0.2577221393585205,
      "learning_rate": 1.775e-05,
      "loss": 0.0022,
      "step": 58050
    },
    {
      "epoch": 1.2902222222222222,
      "grad_norm": 0.4557671844959259,
      "learning_rate": 1.7744444444444445e-05,
      "loss": 0.0016,
      "step": 58060
    },
    {
      "epoch": 1.2904444444444445,
      "grad_norm": 0.18371546268463135,
      "learning_rate": 1.773888888888889e-05,
      "loss": 0.0018,
      "step": 58070
    },
    {
      "epoch": 1.2906666666666666,
      "grad_norm": 0.4419213831424713,
      "learning_rate": 1.7733333333333335e-05,
      "loss": 0.0026,
      "step": 58080
    },
    {
      "epoch": 1.290888888888889,
      "grad_norm": 0.4085996448993683,
      "learning_rate": 1.772777777777778e-05,
      "loss": 0.0031,
      "step": 58090
    },
    {
      "epoch": 1.291111111111111,
      "grad_norm": 0.463652640581131,
      "learning_rate": 1.7722222222222222e-05,
      "loss": 0.0024,
      "step": 58100
    },
    {
      "epoch": 1.2913333333333332,
      "grad_norm": 0.3566284775733948,
      "learning_rate": 1.7716666666666666e-05,
      "loss": 0.0033,
      "step": 58110
    },
    {
      "epoch": 1.2915555555555556,
      "grad_norm": 0.21527144312858582,
      "learning_rate": 1.7711111111111113e-05,
      "loss": 0.0018,
      "step": 58120
    },
    {
      "epoch": 1.291777777777778,
      "grad_norm": 0.06883896142244339,
      "learning_rate": 1.7705555555555556e-05,
      "loss": 0.0021,
      "step": 58130
    },
    {
      "epoch": 1.292,
      "grad_norm": 0.4786645174026489,
      "learning_rate": 1.77e-05,
      "loss": 0.0027,
      "step": 58140
    },
    {
      "epoch": 1.2922222222222222,
      "grad_norm": 0.25232359766960144,
      "learning_rate": 1.7694444444444443e-05,
      "loss": 0.0023,
      "step": 58150
    },
    {
      "epoch": 1.2924444444444445,
      "grad_norm": 0.22472165524959564,
      "learning_rate": 1.768888888888889e-05,
      "loss": 0.002,
      "step": 58160
    },
    {
      "epoch": 1.2926666666666666,
      "grad_norm": 0.5215998888015747,
      "learning_rate": 1.7683333333333334e-05,
      "loss": 0.0026,
      "step": 58170
    },
    {
      "epoch": 1.2928888888888888,
      "grad_norm": 0.16495868563652039,
      "learning_rate": 1.7677777777777778e-05,
      "loss": 0.0019,
      "step": 58180
    },
    {
      "epoch": 1.293111111111111,
      "grad_norm": 0.2025422602891922,
      "learning_rate": 1.7672222222222224e-05,
      "loss": 0.0025,
      "step": 58190
    },
    {
      "epoch": 1.2933333333333334,
      "grad_norm": 0.07067649066448212,
      "learning_rate": 1.7666666666666668e-05,
      "loss": 0.0017,
      "step": 58200
    },
    {
      "epoch": 1.2935555555555556,
      "grad_norm": 0.23385097086429596,
      "learning_rate": 1.766111111111111e-05,
      "loss": 0.0021,
      "step": 58210
    },
    {
      "epoch": 1.2937777777777777,
      "grad_norm": 0.135829895734787,
      "learning_rate": 1.7655555555555555e-05,
      "loss": 0.0019,
      "step": 58220
    },
    {
      "epoch": 1.294,
      "grad_norm": 0.11826322227716446,
      "learning_rate": 1.765e-05,
      "loss": 0.0022,
      "step": 58230
    },
    {
      "epoch": 1.2942222222222222,
      "grad_norm": 0.08241604268550873,
      "learning_rate": 1.7644444444444446e-05,
      "loss": 0.0022,
      "step": 58240
    },
    {
      "epoch": 1.2944444444444445,
      "grad_norm": 0.057974923402071,
      "learning_rate": 1.763888888888889e-05,
      "loss": 0.0017,
      "step": 58250
    },
    {
      "epoch": 1.2946666666666666,
      "grad_norm": 0.07371518015861511,
      "learning_rate": 1.7633333333333336e-05,
      "loss": 0.0019,
      "step": 58260
    },
    {
      "epoch": 1.294888888888889,
      "grad_norm": 0.1878906488418579,
      "learning_rate": 1.762777777777778e-05,
      "loss": 0.0018,
      "step": 58270
    },
    {
      "epoch": 1.295111111111111,
      "grad_norm": 0.3955266773700714,
      "learning_rate": 1.7622222222222223e-05,
      "loss": 0.0035,
      "step": 58280
    },
    {
      "epoch": 1.2953333333333332,
      "grad_norm": 0.15252071619033813,
      "learning_rate": 1.7616666666666667e-05,
      "loss": 0.0015,
      "step": 58290
    },
    {
      "epoch": 1.2955555555555556,
      "grad_norm": 0.4344383180141449,
      "learning_rate": 1.761111111111111e-05,
      "loss": 0.0018,
      "step": 58300
    },
    {
      "epoch": 1.2957777777777777,
      "grad_norm": 0.11398034542798996,
      "learning_rate": 1.7605555555555557e-05,
      "loss": 0.0018,
      "step": 58310
    },
    {
      "epoch": 1.296,
      "grad_norm": 0.5694616436958313,
      "learning_rate": 1.76e-05,
      "loss": 0.002,
      "step": 58320
    },
    {
      "epoch": 1.2962222222222222,
      "grad_norm": 0.534048318862915,
      "learning_rate": 1.7594444444444444e-05,
      "loss": 0.0022,
      "step": 58330
    },
    {
      "epoch": 1.2964444444444445,
      "grad_norm": 0.2719338536262512,
      "learning_rate": 1.758888888888889e-05,
      "loss": 0.0017,
      "step": 58340
    },
    {
      "epoch": 1.2966666666666666,
      "grad_norm": 0.5048340559005737,
      "learning_rate": 1.7583333333333335e-05,
      "loss": 0.0021,
      "step": 58350
    },
    {
      "epoch": 1.2968888888888888,
      "grad_norm": 0.1284150630235672,
      "learning_rate": 1.757777777777778e-05,
      "loss": 0.0023,
      "step": 58360
    },
    {
      "epoch": 1.297111111111111,
      "grad_norm": 0.18809616565704346,
      "learning_rate": 1.7572222222222222e-05,
      "loss": 0.003,
      "step": 58370
    },
    {
      "epoch": 1.2973333333333334,
      "grad_norm": 0.09015332162380219,
      "learning_rate": 1.756666666666667e-05,
      "loss": 0.003,
      "step": 58380
    },
    {
      "epoch": 1.2975555555555556,
      "grad_norm": 0.2367897629737854,
      "learning_rate": 1.7561111111111113e-05,
      "loss": 0.0019,
      "step": 58390
    },
    {
      "epoch": 1.2977777777777777,
      "grad_norm": 0.7632423639297485,
      "learning_rate": 1.7555555555555556e-05,
      "loss": 0.002,
      "step": 58400
    },
    {
      "epoch": 1.298,
      "grad_norm": 0.317706435918808,
      "learning_rate": 1.755e-05,
      "loss": 0.0027,
      "step": 58410
    },
    {
      "epoch": 1.2982222222222222,
      "grad_norm": 0.3283211290836334,
      "learning_rate": 1.7544444444444443e-05,
      "loss": 0.003,
      "step": 58420
    },
    {
      "epoch": 1.2984444444444445,
      "grad_norm": 0.47261708974838257,
      "learning_rate": 1.753888888888889e-05,
      "loss": 0.0017,
      "step": 58430
    },
    {
      "epoch": 1.2986666666666666,
      "grad_norm": 0.3894270956516266,
      "learning_rate": 1.7533333333333334e-05,
      "loss": 0.0018,
      "step": 58440
    },
    {
      "epoch": 1.298888888888889,
      "grad_norm": 0.17860062420368195,
      "learning_rate": 1.752777777777778e-05,
      "loss": 0.0021,
      "step": 58450
    },
    {
      "epoch": 1.299111111111111,
      "grad_norm": 0.1821349561214447,
      "learning_rate": 1.7522222222222224e-05,
      "loss": 0.0023,
      "step": 58460
    },
    {
      "epoch": 1.2993333333333332,
      "grad_norm": 0.5834993720054626,
      "learning_rate": 1.7516666666666668e-05,
      "loss": 0.0031,
      "step": 58470
    },
    {
      "epoch": 1.2995555555555556,
      "grad_norm": 0.2619023621082306,
      "learning_rate": 1.751111111111111e-05,
      "loss": 0.002,
      "step": 58480
    },
    {
      "epoch": 1.2997777777777777,
      "grad_norm": 0.4027767479419708,
      "learning_rate": 1.7505555555555555e-05,
      "loss": 0.0032,
      "step": 58490
    },
    {
      "epoch": 1.3,
      "grad_norm": 0.2405971735715866,
      "learning_rate": 1.75e-05,
      "loss": 0.0026,
      "step": 58500
    },
    {
      "epoch": 1.3002222222222222,
      "grad_norm": 0.06217644736170769,
      "learning_rate": 1.7494444444444445e-05,
      "loss": 0.0023,
      "step": 58510
    },
    {
      "epoch": 1.3004444444444445,
      "grad_norm": 0.32366567850112915,
      "learning_rate": 1.7488888888888892e-05,
      "loss": 0.0018,
      "step": 58520
    },
    {
      "epoch": 1.3006666666666666,
      "grad_norm": 0.2756870687007904,
      "learning_rate": 1.7483333333333336e-05,
      "loss": 0.0018,
      "step": 58530
    },
    {
      "epoch": 1.3008888888888888,
      "grad_norm": 0.14159606397151947,
      "learning_rate": 1.747777777777778e-05,
      "loss": 0.0021,
      "step": 58540
    },
    {
      "epoch": 1.301111111111111,
      "grad_norm": 0.0705200582742691,
      "learning_rate": 1.7472222222222223e-05,
      "loss": 0.0021,
      "step": 58550
    },
    {
      "epoch": 1.3013333333333335,
      "grad_norm": 0.4143828749656677,
      "learning_rate": 1.7466666666666667e-05,
      "loss": 0.002,
      "step": 58560
    },
    {
      "epoch": 1.3015555555555556,
      "grad_norm": 0.4425537884235382,
      "learning_rate": 1.746111111111111e-05,
      "loss": 0.002,
      "step": 58570
    },
    {
      "epoch": 1.3017777777777777,
      "grad_norm": 0.18008123338222504,
      "learning_rate": 1.7455555555555557e-05,
      "loss": 0.002,
      "step": 58580
    },
    {
      "epoch": 1.302,
      "grad_norm": 0.2712251543998718,
      "learning_rate": 1.745e-05,
      "loss": 0.0024,
      "step": 58590
    },
    {
      "epoch": 1.3022222222222222,
      "grad_norm": 0.11184542626142502,
      "learning_rate": 1.7444444444444448e-05,
      "loss": 0.0018,
      "step": 58600
    },
    {
      "epoch": 1.3024444444444445,
      "grad_norm": 0.3898090720176697,
      "learning_rate": 1.743888888888889e-05,
      "loss": 0.0034,
      "step": 58610
    },
    {
      "epoch": 1.3026666666666666,
      "grad_norm": 0.13520272076129913,
      "learning_rate": 1.7433333333333335e-05,
      "loss": 0.0022,
      "step": 58620
    },
    {
      "epoch": 1.302888888888889,
      "grad_norm": 0.2085157185792923,
      "learning_rate": 1.7427777777777778e-05,
      "loss": 0.0021,
      "step": 58630
    },
    {
      "epoch": 1.303111111111111,
      "grad_norm": 0.08877436816692352,
      "learning_rate": 1.7422222222222222e-05,
      "loss": 0.002,
      "step": 58640
    },
    {
      "epoch": 1.3033333333333332,
      "grad_norm": 0.07914028316736221,
      "learning_rate": 1.741666666666667e-05,
      "loss": 0.0028,
      "step": 58650
    },
    {
      "epoch": 1.3035555555555556,
      "grad_norm": 0.431102454662323,
      "learning_rate": 1.7411111111111112e-05,
      "loss": 0.0028,
      "step": 58660
    },
    {
      "epoch": 1.3037777777777777,
      "grad_norm": 0.11008801311254501,
      "learning_rate": 1.7405555555555556e-05,
      "loss": 0.0041,
      "step": 58670
    },
    {
      "epoch": 1.304,
      "grad_norm": 0.18395382165908813,
      "learning_rate": 1.74e-05,
      "loss": 0.0023,
      "step": 58680
    },
    {
      "epoch": 1.3042222222222222,
      "grad_norm": 0.5285058617591858,
      "learning_rate": 1.7394444444444446e-05,
      "loss": 0.0033,
      "step": 58690
    },
    {
      "epoch": 1.3044444444444445,
      "grad_norm": 0.08599664270877838,
      "learning_rate": 1.738888888888889e-05,
      "loss": 0.002,
      "step": 58700
    },
    {
      "epoch": 1.3046666666666666,
      "grad_norm": 0.11265698075294495,
      "learning_rate": 1.7383333333333333e-05,
      "loss": 0.0021,
      "step": 58710
    },
    {
      "epoch": 1.3048888888888888,
      "grad_norm": 0.37369924783706665,
      "learning_rate": 1.737777777777778e-05,
      "loss": 0.002,
      "step": 58720
    },
    {
      "epoch": 1.305111111111111,
      "grad_norm": 0.3803538382053375,
      "learning_rate": 1.7372222222222224e-05,
      "loss": 0.0021,
      "step": 58730
    },
    {
      "epoch": 1.3053333333333335,
      "grad_norm": 0.3562443256378174,
      "learning_rate": 1.7366666666666668e-05,
      "loss": 0.0019,
      "step": 58740
    },
    {
      "epoch": 1.3055555555555556,
      "grad_norm": 0.11418996006250381,
      "learning_rate": 1.736111111111111e-05,
      "loss": 0.002,
      "step": 58750
    },
    {
      "epoch": 1.3057777777777777,
      "grad_norm": 0.4081510305404663,
      "learning_rate": 1.7355555555555555e-05,
      "loss": 0.0023,
      "step": 58760
    },
    {
      "epoch": 1.306,
      "grad_norm": 0.16614045202732086,
      "learning_rate": 1.7349999999999998e-05,
      "loss": 0.0017,
      "step": 58770
    },
    {
      "epoch": 1.3062222222222222,
      "grad_norm": 0.3852403461933136,
      "learning_rate": 1.7344444444444445e-05,
      "loss": 0.0022,
      "step": 58780
    },
    {
      "epoch": 1.3064444444444445,
      "grad_norm": 0.42874518036842346,
      "learning_rate": 1.7338888888888892e-05,
      "loss": 0.0023,
      "step": 58790
    },
    {
      "epoch": 1.3066666666666666,
      "grad_norm": 0.307836651802063,
      "learning_rate": 1.7333333333333336e-05,
      "loss": 0.0023,
      "step": 58800
    },
    {
      "epoch": 1.306888888888889,
      "grad_norm": 0.2371288686990738,
      "learning_rate": 1.732777777777778e-05,
      "loss": 0.0025,
      "step": 58810
    },
    {
      "epoch": 1.3071111111111111,
      "grad_norm": 0.07919017225503922,
      "learning_rate": 1.7322222222222223e-05,
      "loss": 0.0027,
      "step": 58820
    },
    {
      "epoch": 1.3073333333333332,
      "grad_norm": 0.07402224093675613,
      "learning_rate": 1.7316666666666666e-05,
      "loss": 0.0017,
      "step": 58830
    },
    {
      "epoch": 1.3075555555555556,
      "grad_norm": 0.0474984310567379,
      "learning_rate": 1.731111111111111e-05,
      "loss": 0.0019,
      "step": 58840
    },
    {
      "epoch": 1.3077777777777777,
      "grad_norm": 0.7409967184066772,
      "learning_rate": 1.7305555555555557e-05,
      "loss": 0.0018,
      "step": 58850
    },
    {
      "epoch": 1.308,
      "grad_norm": 0.7937697172164917,
      "learning_rate": 1.73e-05,
      "loss": 0.0022,
      "step": 58860
    },
    {
      "epoch": 1.3082222222222222,
      "grad_norm": 0.05851178243756294,
      "learning_rate": 1.7294444444444447e-05,
      "loss": 0.0025,
      "step": 58870
    },
    {
      "epoch": 1.3084444444444445,
      "grad_norm": 0.42386066913604736,
      "learning_rate": 1.728888888888889e-05,
      "loss": 0.0025,
      "step": 58880
    },
    {
      "epoch": 1.3086666666666666,
      "grad_norm": 0.5014658570289612,
      "learning_rate": 1.7283333333333334e-05,
      "loss": 0.0021,
      "step": 58890
    },
    {
      "epoch": 1.3088888888888888,
      "grad_norm": 0.44328737258911133,
      "learning_rate": 1.7277777777777778e-05,
      "loss": 0.0023,
      "step": 58900
    },
    {
      "epoch": 1.3091111111111111,
      "grad_norm": 0.3244803845882416,
      "learning_rate": 1.727222222222222e-05,
      "loss": 0.0019,
      "step": 58910
    },
    {
      "epoch": 1.3093333333333335,
      "grad_norm": 0.4290260374546051,
      "learning_rate": 1.726666666666667e-05,
      "loss": 0.002,
      "step": 58920
    },
    {
      "epoch": 1.3095555555555556,
      "grad_norm": 0.17844946682453156,
      "learning_rate": 1.7261111111111112e-05,
      "loss": 0.002,
      "step": 58930
    },
    {
      "epoch": 1.3097777777777777,
      "grad_norm": 0.13949023187160492,
      "learning_rate": 1.7255555555555556e-05,
      "loss": 0.0024,
      "step": 58940
    },
    {
      "epoch": 1.31,
      "grad_norm": 0.3308383822441101,
      "learning_rate": 1.725e-05,
      "loss": 0.0026,
      "step": 58950
    },
    {
      "epoch": 1.3102222222222222,
      "grad_norm": 0.2808155119419098,
      "learning_rate": 1.7244444444444446e-05,
      "loss": 0.0017,
      "step": 58960
    },
    {
      "epoch": 1.3104444444444445,
      "grad_norm": 0.071206234395504,
      "learning_rate": 1.723888888888889e-05,
      "loss": 0.0018,
      "step": 58970
    },
    {
      "epoch": 1.3106666666666666,
      "grad_norm": 0.23069196939468384,
      "learning_rate": 1.7233333333333333e-05,
      "loss": 0.0018,
      "step": 58980
    },
    {
      "epoch": 1.310888888888889,
      "grad_norm": 0.26830801367759705,
      "learning_rate": 1.722777777777778e-05,
      "loss": 0.0019,
      "step": 58990
    },
    {
      "epoch": 1.3111111111111111,
      "grad_norm": 0.38627341389656067,
      "learning_rate": 1.7222222222222224e-05,
      "loss": 0.002,
      "step": 59000
    },
    {
      "epoch": 1.3113333333333332,
      "grad_norm": 0.5377968549728394,
      "learning_rate": 1.7216666666666667e-05,
      "loss": 0.0027,
      "step": 59010
    },
    {
      "epoch": 1.3115555555555556,
      "grad_norm": 0.12876588106155396,
      "learning_rate": 1.721111111111111e-05,
      "loss": 0.0021,
      "step": 59020
    },
    {
      "epoch": 1.3117777777777777,
      "grad_norm": 0.14111453294754028,
      "learning_rate": 1.7205555555555554e-05,
      "loss": 0.0019,
      "step": 59030
    },
    {
      "epoch": 1.312,
      "grad_norm": 0.06041278690099716,
      "learning_rate": 1.7199999999999998e-05,
      "loss": 0.002,
      "step": 59040
    },
    {
      "epoch": 1.3122222222222222,
      "grad_norm": 0.14174027740955353,
      "learning_rate": 1.7194444444444445e-05,
      "loss": 0.0019,
      "step": 59050
    },
    {
      "epoch": 1.3124444444444445,
      "grad_norm": 0.6062844395637512,
      "learning_rate": 1.7188888888888892e-05,
      "loss": 0.0026,
      "step": 59060
    },
    {
      "epoch": 1.3126666666666666,
      "grad_norm": 0.17723432183265686,
      "learning_rate": 1.7183333333333335e-05,
      "loss": 0.0022,
      "step": 59070
    },
    {
      "epoch": 1.3128888888888888,
      "grad_norm": 0.10615984350442886,
      "learning_rate": 1.717777777777778e-05,
      "loss": 0.0025,
      "step": 59080
    },
    {
      "epoch": 1.3131111111111111,
      "grad_norm": 0.09291922301054001,
      "learning_rate": 1.7172222222222223e-05,
      "loss": 0.0027,
      "step": 59090
    },
    {
      "epoch": 1.3133333333333335,
      "grad_norm": 0.08192535489797592,
      "learning_rate": 1.7166666666666666e-05,
      "loss": 0.0025,
      "step": 59100
    },
    {
      "epoch": 1.3135555555555556,
      "grad_norm": 0.20931121706962585,
      "learning_rate": 1.716111111111111e-05,
      "loss": 0.002,
      "step": 59110
    },
    {
      "epoch": 1.3137777777777777,
      "grad_norm": 0.31290286779403687,
      "learning_rate": 1.7155555555555557e-05,
      "loss": 0.0023,
      "step": 59120
    },
    {
      "epoch": 1.314,
      "grad_norm": 0.18970847129821777,
      "learning_rate": 1.7150000000000004e-05,
      "loss": 0.0024,
      "step": 59130
    },
    {
      "epoch": 1.3142222222222222,
      "grad_norm": 0.2167336493730545,
      "learning_rate": 1.7144444444444447e-05,
      "loss": 0.0017,
      "step": 59140
    },
    {
      "epoch": 1.3144444444444445,
      "grad_norm": 0.30554378032684326,
      "learning_rate": 1.713888888888889e-05,
      "loss": 0.0021,
      "step": 59150
    },
    {
      "epoch": 1.3146666666666667,
      "grad_norm": 0.13454049825668335,
      "learning_rate": 1.7133333333333334e-05,
      "loss": 0.0028,
      "step": 59160
    },
    {
      "epoch": 1.314888888888889,
      "grad_norm": 0.2581162452697754,
      "learning_rate": 1.7127777777777778e-05,
      "loss": 0.0021,
      "step": 59170
    },
    {
      "epoch": 1.3151111111111111,
      "grad_norm": 0.396106094121933,
      "learning_rate": 1.712222222222222e-05,
      "loss": 0.003,
      "step": 59180
    },
    {
      "epoch": 1.3153333333333332,
      "grad_norm": 0.4253111481666565,
      "learning_rate": 1.7116666666666668e-05,
      "loss": 0.0018,
      "step": 59190
    },
    {
      "epoch": 1.3155555555555556,
      "grad_norm": 0.24663330614566803,
      "learning_rate": 1.7111111111111112e-05,
      "loss": 0.002,
      "step": 59200
    },
    {
      "epoch": 1.3157777777777777,
      "grad_norm": 0.06841456145048141,
      "learning_rate": 1.7105555555555555e-05,
      "loss": 0.002,
      "step": 59210
    },
    {
      "epoch": 1.316,
      "grad_norm": 0.7626933455467224,
      "learning_rate": 1.7100000000000002e-05,
      "loss": 0.0029,
      "step": 59220
    },
    {
      "epoch": 1.3162222222222222,
      "grad_norm": 0.057969458401203156,
      "learning_rate": 1.7094444444444446e-05,
      "loss": 0.0019,
      "step": 59230
    },
    {
      "epoch": 1.3164444444444445,
      "grad_norm": 0.07486079633235931,
      "learning_rate": 1.708888888888889e-05,
      "loss": 0.0026,
      "step": 59240
    },
    {
      "epoch": 1.3166666666666667,
      "grad_norm": 0.323621541261673,
      "learning_rate": 1.7083333333333333e-05,
      "loss": 0.0017,
      "step": 59250
    },
    {
      "epoch": 1.3168888888888888,
      "grad_norm": 0.07001512497663498,
      "learning_rate": 1.707777777777778e-05,
      "loss": 0.0026,
      "step": 59260
    },
    {
      "epoch": 1.3171111111111111,
      "grad_norm": 0.5763023495674133,
      "learning_rate": 1.7072222222222223e-05,
      "loss": 0.0026,
      "step": 59270
    },
    {
      "epoch": 1.3173333333333335,
      "grad_norm": 0.15758803486824036,
      "learning_rate": 1.7066666666666667e-05,
      "loss": 0.0018,
      "step": 59280
    },
    {
      "epoch": 1.3175555555555556,
      "grad_norm": 0.3175162076950073,
      "learning_rate": 1.706111111111111e-05,
      "loss": 0.0021,
      "step": 59290
    },
    {
      "epoch": 1.3177777777777777,
      "grad_norm": 0.1424422413110733,
      "learning_rate": 1.7055555555555554e-05,
      "loss": 0.0028,
      "step": 59300
    },
    {
      "epoch": 1.318,
      "grad_norm": 0.166535422205925,
      "learning_rate": 1.705e-05,
      "loss": 0.0018,
      "step": 59310
    },
    {
      "epoch": 1.3182222222222222,
      "grad_norm": 0.07226208597421646,
      "learning_rate": 1.7044444444444445e-05,
      "loss": 0.0018,
      "step": 59320
    },
    {
      "epoch": 1.3184444444444443,
      "grad_norm": 0.14483220875263214,
      "learning_rate": 1.703888888888889e-05,
      "loss": 0.0021,
      "step": 59330
    },
    {
      "epoch": 1.3186666666666667,
      "grad_norm": 0.2487943321466446,
      "learning_rate": 1.7033333333333335e-05,
      "loss": 0.0017,
      "step": 59340
    },
    {
      "epoch": 1.318888888888889,
      "grad_norm": 0.06115591153502464,
      "learning_rate": 1.702777777777778e-05,
      "loss": 0.0025,
      "step": 59350
    },
    {
      "epoch": 1.3191111111111111,
      "grad_norm": 0.2360626459121704,
      "learning_rate": 1.7022222222222222e-05,
      "loss": 0.0024,
      "step": 59360
    },
    {
      "epoch": 1.3193333333333332,
      "grad_norm": 0.11645964533090591,
      "learning_rate": 1.7016666666666666e-05,
      "loss": 0.0019,
      "step": 59370
    },
    {
      "epoch": 1.3195555555555556,
      "grad_norm": 0.10348837077617645,
      "learning_rate": 1.701111111111111e-05,
      "loss": 0.002,
      "step": 59380
    },
    {
      "epoch": 1.3197777777777777,
      "grad_norm": 0.320209264755249,
      "learning_rate": 1.7005555555555556e-05,
      "loss": 0.0019,
      "step": 59390
    },
    {
      "epoch": 1.32,
      "grad_norm": 0.08604727685451508,
      "learning_rate": 1.7000000000000003e-05,
      "loss": 0.003,
      "step": 59400
    },
    {
      "epoch": 1.3202222222222222,
      "grad_norm": 0.29182496666908264,
      "learning_rate": 1.6994444444444447e-05,
      "loss": 0.0019,
      "step": 59410
    },
    {
      "epoch": 1.3204444444444445,
      "grad_norm": 0.22933094203472137,
      "learning_rate": 1.698888888888889e-05,
      "loss": 0.0019,
      "step": 59420
    },
    {
      "epoch": 1.3206666666666667,
      "grad_norm": 0.07390788197517395,
      "learning_rate": 1.6983333333333334e-05,
      "loss": 0.0028,
      "step": 59430
    },
    {
      "epoch": 1.3208888888888888,
      "grad_norm": 0.5045219659805298,
      "learning_rate": 1.6977777777777777e-05,
      "loss": 0.0036,
      "step": 59440
    },
    {
      "epoch": 1.3211111111111111,
      "grad_norm": 0.49800994992256165,
      "learning_rate": 1.697222222222222e-05,
      "loss": 0.0016,
      "step": 59450
    },
    {
      "epoch": 1.3213333333333335,
      "grad_norm": 0.30853426456451416,
      "learning_rate": 1.6966666666666668e-05,
      "loss": 0.0018,
      "step": 59460
    },
    {
      "epoch": 1.3215555555555556,
      "grad_norm": 0.14684243500232697,
      "learning_rate": 1.696111111111111e-05,
      "loss": 0.0024,
      "step": 59470
    },
    {
      "epoch": 1.3217777777777777,
      "grad_norm": 0.16072432696819305,
      "learning_rate": 1.6955555555555555e-05,
      "loss": 0.0018,
      "step": 59480
    },
    {
      "epoch": 1.322,
      "grad_norm": 0.06521763652563095,
      "learning_rate": 1.6950000000000002e-05,
      "loss": 0.0017,
      "step": 59490
    },
    {
      "epoch": 1.3222222222222222,
      "grad_norm": 0.23761844635009766,
      "learning_rate": 1.6944444444444446e-05,
      "loss": 0.0018,
      "step": 59500
    },
    {
      "epoch": 1.3224444444444443,
      "grad_norm": 0.20243576169013977,
      "learning_rate": 1.693888888888889e-05,
      "loss": 0.0017,
      "step": 59510
    },
    {
      "epoch": 1.3226666666666667,
      "grad_norm": 0.23232823610305786,
      "learning_rate": 1.6933333333333333e-05,
      "loss": 0.0022,
      "step": 59520
    },
    {
      "epoch": 1.322888888888889,
      "grad_norm": 0.21788838505744934,
      "learning_rate": 1.692777777777778e-05,
      "loss": 0.0031,
      "step": 59530
    },
    {
      "epoch": 1.3231111111111111,
      "grad_norm": 0.4689885079860687,
      "learning_rate": 1.6922222222222223e-05,
      "loss": 0.0027,
      "step": 59540
    },
    {
      "epoch": 1.3233333333333333,
      "grad_norm": 0.1433676928281784,
      "learning_rate": 1.6916666666666667e-05,
      "loss": 0.0025,
      "step": 59550
    },
    {
      "epoch": 1.3235555555555556,
      "grad_norm": 0.34785783290863037,
      "learning_rate": 1.691111111111111e-05,
      "loss": 0.0025,
      "step": 59560
    },
    {
      "epoch": 1.3237777777777777,
      "grad_norm": 0.4205476641654968,
      "learning_rate": 1.6905555555555554e-05,
      "loss": 0.0017,
      "step": 59570
    },
    {
      "epoch": 1.324,
      "grad_norm": 0.24563726782798767,
      "learning_rate": 1.69e-05,
      "loss": 0.0025,
      "step": 59580
    },
    {
      "epoch": 1.3242222222222222,
      "grad_norm": 0.1272423267364502,
      "learning_rate": 1.6894444444444444e-05,
      "loss": 0.0021,
      "step": 59590
    },
    {
      "epoch": 1.3244444444444445,
      "grad_norm": 0.09309446811676025,
      "learning_rate": 1.688888888888889e-05,
      "loss": 0.0024,
      "step": 59600
    },
    {
      "epoch": 1.3246666666666667,
      "grad_norm": 0.10792454332113266,
      "learning_rate": 1.6883333333333335e-05,
      "loss": 0.0018,
      "step": 59610
    },
    {
      "epoch": 1.3248888888888888,
      "grad_norm": 0.22530972957611084,
      "learning_rate": 1.687777777777778e-05,
      "loss": 0.0028,
      "step": 59620
    },
    {
      "epoch": 1.3251111111111111,
      "grad_norm": 0.37574702501296997,
      "learning_rate": 1.6872222222222222e-05,
      "loss": 0.002,
      "step": 59630
    },
    {
      "epoch": 1.3253333333333333,
      "grad_norm": 0.0918579027056694,
      "learning_rate": 1.6866666666666666e-05,
      "loss": 0.0027,
      "step": 59640
    },
    {
      "epoch": 1.3255555555555556,
      "grad_norm": 0.45379638671875,
      "learning_rate": 1.6861111111111112e-05,
      "loss": 0.0026,
      "step": 59650
    },
    {
      "epoch": 1.3257777777777777,
      "grad_norm": 0.10896290838718414,
      "learning_rate": 1.6855555555555556e-05,
      "loss": 0.0025,
      "step": 59660
    },
    {
      "epoch": 1.326,
      "grad_norm": 0.4727438986301422,
      "learning_rate": 1.6850000000000003e-05,
      "loss": 0.0018,
      "step": 59670
    },
    {
      "epoch": 1.3262222222222222,
      "grad_norm": 0.30176597833633423,
      "learning_rate": 1.6844444444444447e-05,
      "loss": 0.0024,
      "step": 59680
    },
    {
      "epoch": 1.3264444444444443,
      "grad_norm": 0.41419389843940735,
      "learning_rate": 1.683888888888889e-05,
      "loss": 0.0036,
      "step": 59690
    },
    {
      "epoch": 1.3266666666666667,
      "grad_norm": 0.06685405224561691,
      "learning_rate": 1.6833333333333334e-05,
      "loss": 0.0018,
      "step": 59700
    },
    {
      "epoch": 1.326888888888889,
      "grad_norm": 0.47053077816963196,
      "learning_rate": 1.6827777777777777e-05,
      "loss": 0.0022,
      "step": 59710
    },
    {
      "epoch": 1.3271111111111111,
      "grad_norm": 0.45033010840415955,
      "learning_rate": 1.6822222222222224e-05,
      "loss": 0.0026,
      "step": 59720
    },
    {
      "epoch": 1.3273333333333333,
      "grad_norm": 0.1285039484500885,
      "learning_rate": 1.6816666666666668e-05,
      "loss": 0.0017,
      "step": 59730
    },
    {
      "epoch": 1.3275555555555556,
      "grad_norm": 0.18117012083530426,
      "learning_rate": 1.681111111111111e-05,
      "loss": 0.0018,
      "step": 59740
    },
    {
      "epoch": 1.3277777777777777,
      "grad_norm": 0.21533548831939697,
      "learning_rate": 1.6805555555555558e-05,
      "loss": 0.0023,
      "step": 59750
    },
    {
      "epoch": 1.328,
      "grad_norm": 0.17593979835510254,
      "learning_rate": 1.6800000000000002e-05,
      "loss": 0.002,
      "step": 59760
    },
    {
      "epoch": 1.3282222222222222,
      "grad_norm": 0.08582010120153427,
      "learning_rate": 1.6794444444444445e-05,
      "loss": 0.0019,
      "step": 59770
    },
    {
      "epoch": 1.3284444444444445,
      "grad_norm": 0.543538510799408,
      "learning_rate": 1.678888888888889e-05,
      "loss": 0.0026,
      "step": 59780
    },
    {
      "epoch": 1.3286666666666667,
      "grad_norm": 0.16602136194705963,
      "learning_rate": 1.6783333333333336e-05,
      "loss": 0.0021,
      "step": 59790
    },
    {
      "epoch": 1.3288888888888888,
      "grad_norm": 0.23362226784229279,
      "learning_rate": 1.677777777777778e-05,
      "loss": 0.0017,
      "step": 59800
    },
    {
      "epoch": 1.3291111111111111,
      "grad_norm": 0.07574334740638733,
      "learning_rate": 1.6772222222222223e-05,
      "loss": 0.0023,
      "step": 59810
    },
    {
      "epoch": 1.3293333333333333,
      "grad_norm": 0.2661946415901184,
      "learning_rate": 1.6766666666666667e-05,
      "loss": 0.0027,
      "step": 59820
    },
    {
      "epoch": 1.3295555555555556,
      "grad_norm": 0.11299034208059311,
      "learning_rate": 1.676111111111111e-05,
      "loss": 0.0018,
      "step": 59830
    },
    {
      "epoch": 1.3297777777777777,
      "grad_norm": 0.39981192350387573,
      "learning_rate": 1.6755555555555557e-05,
      "loss": 0.0026,
      "step": 59840
    },
    {
      "epoch": 1.33,
      "grad_norm": 0.19111929833889008,
      "learning_rate": 1.675e-05,
      "loss": 0.0034,
      "step": 59850
    },
    {
      "epoch": 1.3302222222222222,
      "grad_norm": 0.2841053605079651,
      "learning_rate": 1.6744444444444448e-05,
      "loss": 0.0024,
      "step": 59860
    },
    {
      "epoch": 1.3304444444444443,
      "grad_norm": 0.10769864916801453,
      "learning_rate": 1.673888888888889e-05,
      "loss": 0.0022,
      "step": 59870
    },
    {
      "epoch": 1.3306666666666667,
      "grad_norm": 0.06330575048923492,
      "learning_rate": 1.6733333333333335e-05,
      "loss": 0.0021,
      "step": 59880
    },
    {
      "epoch": 1.330888888888889,
      "grad_norm": 0.23252035677433014,
      "learning_rate": 1.6727777777777778e-05,
      "loss": 0.0018,
      "step": 59890
    },
    {
      "epoch": 1.3311111111111111,
      "grad_norm": 0.19119857251644135,
      "learning_rate": 1.6722222222222222e-05,
      "loss": 0.0022,
      "step": 59900
    },
    {
      "epoch": 1.3313333333333333,
      "grad_norm": 0.2101464420557022,
      "learning_rate": 1.6716666666666665e-05,
      "loss": 0.0019,
      "step": 59910
    },
    {
      "epoch": 1.3315555555555556,
      "grad_norm": 0.18362842500209808,
      "learning_rate": 1.6711111111111112e-05,
      "loss": 0.0018,
      "step": 59920
    },
    {
      "epoch": 1.3317777777777777,
      "grad_norm": 0.09424377977848053,
      "learning_rate": 1.670555555555556e-05,
      "loss": 0.0018,
      "step": 59930
    },
    {
      "epoch": 1.332,
      "grad_norm": 0.65240478515625,
      "learning_rate": 1.6700000000000003e-05,
      "loss": 0.0019,
      "step": 59940
    },
    {
      "epoch": 1.3322222222222222,
      "grad_norm": 0.06298764050006866,
      "learning_rate": 1.6694444444444446e-05,
      "loss": 0.0023,
      "step": 59950
    },
    {
      "epoch": 1.3324444444444445,
      "grad_norm": 0.06583577394485474,
      "learning_rate": 1.668888888888889e-05,
      "loss": 0.0021,
      "step": 59960
    },
    {
      "epoch": 1.3326666666666667,
      "grad_norm": 0.3621690571308136,
      "learning_rate": 1.6683333333333333e-05,
      "loss": 0.0017,
      "step": 59970
    },
    {
      "epoch": 1.3328888888888888,
      "grad_norm": 0.19927182793617249,
      "learning_rate": 1.6677777777777777e-05,
      "loss": 0.0018,
      "step": 59980
    },
    {
      "epoch": 1.3331111111111111,
      "grad_norm": 0.18993757665157318,
      "learning_rate": 1.6672222222222224e-05,
      "loss": 0.0017,
      "step": 59990
    },
    {
      "epoch": 1.3333333333333333,
      "grad_norm": 0.20366939902305603,
      "learning_rate": 1.6666666666666667e-05,
      "loss": 0.0021,
      "step": 60000
    },
    {
      "epoch": 1.3335555555555556,
      "grad_norm": 0.34425634145736694,
      "learning_rate": 1.666111111111111e-05,
      "loss": 0.0018,
      "step": 60010
    },
    {
      "epoch": 1.3337777777777777,
      "grad_norm": 0.14448240399360657,
      "learning_rate": 1.6655555555555558e-05,
      "loss": 0.0023,
      "step": 60020
    },
    {
      "epoch": 1.334,
      "grad_norm": 0.07670730352401733,
      "learning_rate": 1.665e-05,
      "loss": 0.002,
      "step": 60030
    },
    {
      "epoch": 1.3342222222222222,
      "grad_norm": 0.4281066954135895,
      "learning_rate": 1.6644444444444445e-05,
      "loss": 0.0025,
      "step": 60040
    },
    {
      "epoch": 1.3344444444444443,
      "grad_norm": 0.21140256524085999,
      "learning_rate": 1.663888888888889e-05,
      "loss": 0.002,
      "step": 60050
    },
    {
      "epoch": 1.3346666666666667,
      "grad_norm": 0.33874595165252686,
      "learning_rate": 1.6633333333333336e-05,
      "loss": 0.0027,
      "step": 60060
    },
    {
      "epoch": 1.334888888888889,
      "grad_norm": 0.28814050555229187,
      "learning_rate": 1.662777777777778e-05,
      "loss": 0.0021,
      "step": 60070
    },
    {
      "epoch": 1.3351111111111111,
      "grad_norm": 0.17581026256084442,
      "learning_rate": 1.6622222222222223e-05,
      "loss": 0.0025,
      "step": 60080
    },
    {
      "epoch": 1.3353333333333333,
      "grad_norm": 0.3111274242401123,
      "learning_rate": 1.6616666666666666e-05,
      "loss": 0.0025,
      "step": 60090
    },
    {
      "epoch": 1.3355555555555556,
      "grad_norm": 0.16451995074748993,
      "learning_rate": 1.661111111111111e-05,
      "loss": 0.0021,
      "step": 60100
    },
    {
      "epoch": 1.3357777777777777,
      "grad_norm": 0.2163430005311966,
      "learning_rate": 1.6605555555555557e-05,
      "loss": 0.0019,
      "step": 60110
    },
    {
      "epoch": 1.336,
      "grad_norm": 0.12407317012548447,
      "learning_rate": 1.66e-05,
      "loss": 0.0022,
      "step": 60120
    },
    {
      "epoch": 1.3362222222222222,
      "grad_norm": 0.19248734414577484,
      "learning_rate": 1.6594444444444447e-05,
      "loss": 0.0021,
      "step": 60130
    },
    {
      "epoch": 1.3364444444444445,
      "grad_norm": 0.2049517035484314,
      "learning_rate": 1.658888888888889e-05,
      "loss": 0.0021,
      "step": 60140
    },
    {
      "epoch": 1.3366666666666667,
      "grad_norm": 0.07603380084037781,
      "learning_rate": 1.6583333333333334e-05,
      "loss": 0.0018,
      "step": 60150
    },
    {
      "epoch": 1.3368888888888888,
      "grad_norm": 0.4129589796066284,
      "learning_rate": 1.6577777777777778e-05,
      "loss": 0.0022,
      "step": 60160
    },
    {
      "epoch": 1.3371111111111111,
      "grad_norm": 0.34402984380722046,
      "learning_rate": 1.657222222222222e-05,
      "loss": 0.0017,
      "step": 60170
    },
    {
      "epoch": 1.3373333333333333,
      "grad_norm": 0.3757260739803314,
      "learning_rate": 1.6566666666666665e-05,
      "loss": 0.0019,
      "step": 60180
    },
    {
      "epoch": 1.3375555555555556,
      "grad_norm": 0.12172166258096695,
      "learning_rate": 1.6561111111111112e-05,
      "loss": 0.0018,
      "step": 60190
    },
    {
      "epoch": 1.3377777777777777,
      "grad_norm": 0.09155912697315216,
      "learning_rate": 1.655555555555556e-05,
      "loss": 0.002,
      "step": 60200
    },
    {
      "epoch": 1.338,
      "grad_norm": 0.11896796524524689,
      "learning_rate": 1.6550000000000002e-05,
      "loss": 0.0019,
      "step": 60210
    },
    {
      "epoch": 1.3382222222222222,
      "grad_norm": 0.06321892142295837,
      "learning_rate": 1.6544444444444446e-05,
      "loss": 0.0016,
      "step": 60220
    },
    {
      "epoch": 1.3384444444444443,
      "grad_norm": 0.32289084792137146,
      "learning_rate": 1.653888888888889e-05,
      "loss": 0.0033,
      "step": 60230
    },
    {
      "epoch": 1.3386666666666667,
      "grad_norm": 0.5019437670707703,
      "learning_rate": 1.6533333333333333e-05,
      "loss": 0.0016,
      "step": 60240
    },
    {
      "epoch": 1.338888888888889,
      "grad_norm": 0.2316640168428421,
      "learning_rate": 1.6527777777777777e-05,
      "loss": 0.0023,
      "step": 60250
    },
    {
      "epoch": 1.3391111111111111,
      "grad_norm": 0.45640918612480164,
      "learning_rate": 1.6522222222222224e-05,
      "loss": 0.0017,
      "step": 60260
    },
    {
      "epoch": 1.3393333333333333,
      "grad_norm": 0.1090058907866478,
      "learning_rate": 1.6516666666666667e-05,
      "loss": 0.0019,
      "step": 60270
    },
    {
      "epoch": 1.3395555555555556,
      "grad_norm": 0.4140792787075043,
      "learning_rate": 1.651111111111111e-05,
      "loss": 0.0026,
      "step": 60280
    },
    {
      "epoch": 1.3397777777777777,
      "grad_norm": 0.11369752138853073,
      "learning_rate": 1.6505555555555558e-05,
      "loss": 0.0022,
      "step": 60290
    },
    {
      "epoch": 1.34,
      "grad_norm": 0.08183147013187408,
      "learning_rate": 1.65e-05,
      "loss": 0.0023,
      "step": 60300
    },
    {
      "epoch": 1.3402222222222222,
      "grad_norm": 0.07288281619548798,
      "learning_rate": 1.6494444444444445e-05,
      "loss": 0.0018,
      "step": 60310
    },
    {
      "epoch": 1.3404444444444445,
      "grad_norm": 0.058906469494104385,
      "learning_rate": 1.648888888888889e-05,
      "loss": 0.0019,
      "step": 60320
    },
    {
      "epoch": 1.3406666666666667,
      "grad_norm": 0.4979405701160431,
      "learning_rate": 1.6483333333333335e-05,
      "loss": 0.0027,
      "step": 60330
    },
    {
      "epoch": 1.3408888888888888,
      "grad_norm": 0.1890881359577179,
      "learning_rate": 1.647777777777778e-05,
      "loss": 0.0031,
      "step": 60340
    },
    {
      "epoch": 1.3411111111111111,
      "grad_norm": 0.08624228090047836,
      "learning_rate": 1.6472222222222222e-05,
      "loss": 0.0017,
      "step": 60350
    },
    {
      "epoch": 1.3413333333333333,
      "grad_norm": 0.11842319369316101,
      "learning_rate": 1.6466666666666666e-05,
      "loss": 0.0023,
      "step": 60360
    },
    {
      "epoch": 1.3415555555555556,
      "grad_norm": 0.17668859660625458,
      "learning_rate": 1.6461111111111113e-05,
      "loss": 0.0028,
      "step": 60370
    },
    {
      "epoch": 1.3417777777777777,
      "grad_norm": 0.1980019360780716,
      "learning_rate": 1.6455555555555556e-05,
      "loss": 0.0021,
      "step": 60380
    },
    {
      "epoch": 1.342,
      "grad_norm": 0.26154157519340515,
      "learning_rate": 1.645e-05,
      "loss": 0.0018,
      "step": 60390
    },
    {
      "epoch": 1.3422222222222222,
      "grad_norm": 0.07864447683095932,
      "learning_rate": 1.6444444444444447e-05,
      "loss": 0.0028,
      "step": 60400
    },
    {
      "epoch": 1.3424444444444443,
      "grad_norm": 0.23491010069847107,
      "learning_rate": 1.643888888888889e-05,
      "loss": 0.0022,
      "step": 60410
    },
    {
      "epoch": 1.3426666666666667,
      "grad_norm": 0.1868220567703247,
      "learning_rate": 1.6433333333333334e-05,
      "loss": 0.0019,
      "step": 60420
    },
    {
      "epoch": 1.342888888888889,
      "grad_norm": 0.1978372037410736,
      "learning_rate": 1.6427777777777778e-05,
      "loss": 0.0021,
      "step": 60430
    },
    {
      "epoch": 1.3431111111111111,
      "grad_norm": 0.22871260344982147,
      "learning_rate": 1.642222222222222e-05,
      "loss": 0.002,
      "step": 60440
    },
    {
      "epoch": 1.3433333333333333,
      "grad_norm": 0.29814037680625916,
      "learning_rate": 1.6416666666666665e-05,
      "loss": 0.0023,
      "step": 60450
    },
    {
      "epoch": 1.3435555555555556,
      "grad_norm": 0.2604193091392517,
      "learning_rate": 1.6411111111111112e-05,
      "loss": 0.0021,
      "step": 60460
    },
    {
      "epoch": 1.3437777777777777,
      "grad_norm": 0.16622306406497955,
      "learning_rate": 1.640555555555556e-05,
      "loss": 0.003,
      "step": 60470
    },
    {
      "epoch": 1.3439999999999999,
      "grad_norm": 0.18650037050247192,
      "learning_rate": 1.6400000000000002e-05,
      "loss": 0.0026,
      "step": 60480
    },
    {
      "epoch": 1.3442222222222222,
      "grad_norm": 0.32917484641075134,
      "learning_rate": 1.6394444444444446e-05,
      "loss": 0.0031,
      "step": 60490
    },
    {
      "epoch": 1.3444444444444446,
      "grad_norm": 0.433447003364563,
      "learning_rate": 1.638888888888889e-05,
      "loss": 0.0029,
      "step": 60500
    },
    {
      "epoch": 1.3446666666666667,
      "grad_norm": 0.13246265053749084,
      "learning_rate": 1.6383333333333333e-05,
      "loss": 0.0021,
      "step": 60510
    },
    {
      "epoch": 1.3448888888888888,
      "grad_norm": 0.4680633246898651,
      "learning_rate": 1.6377777777777776e-05,
      "loss": 0.0018,
      "step": 60520
    },
    {
      "epoch": 1.3451111111111111,
      "grad_norm": 0.07403788715600967,
      "learning_rate": 1.6372222222222223e-05,
      "loss": 0.0019,
      "step": 60530
    },
    {
      "epoch": 1.3453333333333333,
      "grad_norm": 0.06991714984178543,
      "learning_rate": 1.6366666666666667e-05,
      "loss": 0.0017,
      "step": 60540
    },
    {
      "epoch": 1.3455555555555556,
      "grad_norm": 0.05118154361844063,
      "learning_rate": 1.6361111111111114e-05,
      "loss": 0.0023,
      "step": 60550
    },
    {
      "epoch": 1.3457777777777777,
      "grad_norm": 0.17421972751617432,
      "learning_rate": 1.6355555555555557e-05,
      "loss": 0.0018,
      "step": 60560
    },
    {
      "epoch": 1.346,
      "grad_norm": 0.09125880897045135,
      "learning_rate": 1.635e-05,
      "loss": 0.0026,
      "step": 60570
    },
    {
      "epoch": 1.3462222222222222,
      "grad_norm": 0.3008961081504822,
      "learning_rate": 1.6344444444444445e-05,
      "loss": 0.0019,
      "step": 60580
    },
    {
      "epoch": 1.3464444444444443,
      "grad_norm": 0.24306270480155945,
      "learning_rate": 1.6338888888888888e-05,
      "loss": 0.0021,
      "step": 60590
    },
    {
      "epoch": 1.3466666666666667,
      "grad_norm": 0.1903686672449112,
      "learning_rate": 1.6333333333333335e-05,
      "loss": 0.0021,
      "step": 60600
    },
    {
      "epoch": 1.346888888888889,
      "grad_norm": 0.2535041868686676,
      "learning_rate": 1.632777777777778e-05,
      "loss": 0.0033,
      "step": 60610
    },
    {
      "epoch": 1.3471111111111111,
      "grad_norm": 0.29839661717414856,
      "learning_rate": 1.6322222222222222e-05,
      "loss": 0.0021,
      "step": 60620
    },
    {
      "epoch": 1.3473333333333333,
      "grad_norm": 0.5453654527664185,
      "learning_rate": 1.6316666666666666e-05,
      "loss": 0.0019,
      "step": 60630
    },
    {
      "epoch": 1.3475555555555556,
      "grad_norm": 0.3989108204841614,
      "learning_rate": 1.6311111111111113e-05,
      "loss": 0.0023,
      "step": 60640
    },
    {
      "epoch": 1.3477777777777777,
      "grad_norm": 0.13782167434692383,
      "learning_rate": 1.6305555555555556e-05,
      "loss": 0.0028,
      "step": 60650
    },
    {
      "epoch": 1.3479999999999999,
      "grad_norm": 0.07615582644939423,
      "learning_rate": 1.63e-05,
      "loss": 0.0024,
      "step": 60660
    },
    {
      "epoch": 1.3482222222222222,
      "grad_norm": 0.28874391317367554,
      "learning_rate": 1.6294444444444447e-05,
      "loss": 0.0031,
      "step": 60670
    },
    {
      "epoch": 1.3484444444444446,
      "grad_norm": 0.16734273731708527,
      "learning_rate": 1.628888888888889e-05,
      "loss": 0.0019,
      "step": 60680
    },
    {
      "epoch": 1.3486666666666667,
      "grad_norm": 0.07335452735424042,
      "learning_rate": 1.6283333333333334e-05,
      "loss": 0.0017,
      "step": 60690
    },
    {
      "epoch": 1.3488888888888888,
      "grad_norm": 0.09314762055873871,
      "learning_rate": 1.6277777777777777e-05,
      "loss": 0.0029,
      "step": 60700
    },
    {
      "epoch": 1.3491111111111111,
      "grad_norm": 0.13960964977741241,
      "learning_rate": 1.627222222222222e-05,
      "loss": 0.0018,
      "step": 60710
    },
    {
      "epoch": 1.3493333333333333,
      "grad_norm": 0.4700116813182831,
      "learning_rate": 1.6266666666666665e-05,
      "loss": 0.0019,
      "step": 60720
    },
    {
      "epoch": 1.3495555555555556,
      "grad_norm": 0.47428256273269653,
      "learning_rate": 1.626111111111111e-05,
      "loss": 0.0018,
      "step": 60730
    },
    {
      "epoch": 1.3497777777777777,
      "grad_norm": 0.08908267319202423,
      "learning_rate": 1.625555555555556e-05,
      "loss": 0.0019,
      "step": 60740
    },
    {
      "epoch": 1.35,
      "grad_norm": 0.3979147970676422,
      "learning_rate": 1.6250000000000002e-05,
      "loss": 0.0021,
      "step": 60750
    },
    {
      "epoch": 1.3502222222222222,
      "grad_norm": 0.4160560965538025,
      "learning_rate": 1.6244444444444446e-05,
      "loss": 0.0022,
      "step": 60760
    },
    {
      "epoch": 1.3504444444444443,
      "grad_norm": 0.21028518676757812,
      "learning_rate": 1.623888888888889e-05,
      "loss": 0.0021,
      "step": 60770
    },
    {
      "epoch": 1.3506666666666667,
      "grad_norm": 0.30346062779426575,
      "learning_rate": 1.6233333333333333e-05,
      "loss": 0.0029,
      "step": 60780
    },
    {
      "epoch": 1.3508888888888888,
      "grad_norm": 0.07625589519739151,
      "learning_rate": 1.6227777777777776e-05,
      "loss": 0.0028,
      "step": 60790
    },
    {
      "epoch": 1.3511111111111112,
      "grad_norm": 0.0687187910079956,
      "learning_rate": 1.6222222222222223e-05,
      "loss": 0.0034,
      "step": 60800
    },
    {
      "epoch": 1.3513333333333333,
      "grad_norm": 0.10599306970834732,
      "learning_rate": 1.6216666666666667e-05,
      "loss": 0.0031,
      "step": 60810
    },
    {
      "epoch": 1.3515555555555556,
      "grad_norm": 0.4675312042236328,
      "learning_rate": 1.6211111111111114e-05,
      "loss": 0.0017,
      "step": 60820
    },
    {
      "epoch": 1.3517777777777777,
      "grad_norm": 0.2599065899848938,
      "learning_rate": 1.6205555555555557e-05,
      "loss": 0.0017,
      "step": 60830
    },
    {
      "epoch": 1.3519999999999999,
      "grad_norm": 0.7081320285797119,
      "learning_rate": 1.62e-05,
      "loss": 0.002,
      "step": 60840
    },
    {
      "epoch": 1.3522222222222222,
      "grad_norm": 0.3558463752269745,
      "learning_rate": 1.6194444444444444e-05,
      "loss": 0.0019,
      "step": 60850
    },
    {
      "epoch": 1.3524444444444446,
      "grad_norm": 0.31144726276397705,
      "learning_rate": 1.6188888888888888e-05,
      "loss": 0.0025,
      "step": 60860
    },
    {
      "epoch": 1.3526666666666667,
      "grad_norm": 0.14889821410179138,
      "learning_rate": 1.6183333333333335e-05,
      "loss": 0.0018,
      "step": 60870
    },
    {
      "epoch": 1.3528888888888888,
      "grad_norm": 0.4368189871311188,
      "learning_rate": 1.617777777777778e-05,
      "loss": 0.0019,
      "step": 60880
    },
    {
      "epoch": 1.3531111111111112,
      "grad_norm": 0.5685813426971436,
      "learning_rate": 1.6172222222222222e-05,
      "loss": 0.002,
      "step": 60890
    },
    {
      "epoch": 1.3533333333333333,
      "grad_norm": 0.08446736633777618,
      "learning_rate": 1.6166666666666665e-05,
      "loss": 0.0026,
      "step": 60900
    },
    {
      "epoch": 1.3535555555555556,
      "grad_norm": 0.6172003746032715,
      "learning_rate": 1.6161111111111112e-05,
      "loss": 0.002,
      "step": 60910
    },
    {
      "epoch": 1.3537777777777777,
      "grad_norm": 0.37864965200424194,
      "learning_rate": 1.6155555555555556e-05,
      "loss": 0.0019,
      "step": 60920
    },
    {
      "epoch": 1.354,
      "grad_norm": 0.23409397900104523,
      "learning_rate": 1.6150000000000003e-05,
      "loss": 0.0028,
      "step": 60930
    },
    {
      "epoch": 1.3542222222222222,
      "grad_norm": 0.1634180247783661,
      "learning_rate": 1.6144444444444446e-05,
      "loss": 0.0019,
      "step": 60940
    },
    {
      "epoch": 1.3544444444444443,
      "grad_norm": 0.28063303232192993,
      "learning_rate": 1.613888888888889e-05,
      "loss": 0.0021,
      "step": 60950
    },
    {
      "epoch": 1.3546666666666667,
      "grad_norm": 0.23647728562355042,
      "learning_rate": 1.6133333333333334e-05,
      "loss": 0.0025,
      "step": 60960
    },
    {
      "epoch": 1.3548888888888888,
      "grad_norm": 0.07807391881942749,
      "learning_rate": 1.6127777777777777e-05,
      "loss": 0.0028,
      "step": 60970
    },
    {
      "epoch": 1.3551111111111112,
      "grad_norm": 0.41570404171943665,
      "learning_rate": 1.612222222222222e-05,
      "loss": 0.0025,
      "step": 60980
    },
    {
      "epoch": 1.3553333333333333,
      "grad_norm": 0.4699612855911255,
      "learning_rate": 1.6116666666666668e-05,
      "loss": 0.0022,
      "step": 60990
    },
    {
      "epoch": 1.3555555555555556,
      "grad_norm": 0.13555730879306793,
      "learning_rate": 1.6111111111111115e-05,
      "loss": 0.0021,
      "step": 61000
    },
    {
      "epoch": 1.3557777777777777,
      "grad_norm": 0.28480687737464905,
      "learning_rate": 1.6105555555555558e-05,
      "loss": 0.0024,
      "step": 61010
    },
    {
      "epoch": 1.3559999999999999,
      "grad_norm": 0.2224797010421753,
      "learning_rate": 1.6100000000000002e-05,
      "loss": 0.0023,
      "step": 61020
    },
    {
      "epoch": 1.3562222222222222,
      "grad_norm": 0.2944740355014801,
      "learning_rate": 1.6094444444444445e-05,
      "loss": 0.002,
      "step": 61030
    },
    {
      "epoch": 1.3564444444444446,
      "grad_norm": 0.2277943342924118,
      "learning_rate": 1.608888888888889e-05,
      "loss": 0.0024,
      "step": 61040
    },
    {
      "epoch": 1.3566666666666667,
      "grad_norm": 0.2724633514881134,
      "learning_rate": 1.6083333333333332e-05,
      "loss": 0.0022,
      "step": 61050
    },
    {
      "epoch": 1.3568888888888888,
      "grad_norm": 0.11371129751205444,
      "learning_rate": 1.607777777777778e-05,
      "loss": 0.0023,
      "step": 61060
    },
    {
      "epoch": 1.3571111111111112,
      "grad_norm": 0.07962916791439056,
      "learning_rate": 1.6072222222222223e-05,
      "loss": 0.0022,
      "step": 61070
    },
    {
      "epoch": 1.3573333333333333,
      "grad_norm": 0.42501968145370483,
      "learning_rate": 1.606666666666667e-05,
      "loss": 0.0022,
      "step": 61080
    },
    {
      "epoch": 1.3575555555555556,
      "grad_norm": 0.3624246120452881,
      "learning_rate": 1.6061111111111113e-05,
      "loss": 0.002,
      "step": 61090
    },
    {
      "epoch": 1.3577777777777778,
      "grad_norm": 0.5657093524932861,
      "learning_rate": 1.6055555555555557e-05,
      "loss": 0.0021,
      "step": 61100
    },
    {
      "epoch": 1.358,
      "grad_norm": 0.28665003180503845,
      "learning_rate": 1.605e-05,
      "loss": 0.0029,
      "step": 61110
    },
    {
      "epoch": 1.3582222222222222,
      "grad_norm": 0.46003666520118713,
      "learning_rate": 1.6044444444444444e-05,
      "loss": 0.0024,
      "step": 61120
    },
    {
      "epoch": 1.3584444444444443,
      "grad_norm": 0.08262918144464493,
      "learning_rate": 1.603888888888889e-05,
      "loss": 0.0026,
      "step": 61130
    },
    {
      "epoch": 1.3586666666666667,
      "grad_norm": 0.3691706657409668,
      "learning_rate": 1.6033333333333335e-05,
      "loss": 0.0022,
      "step": 61140
    },
    {
      "epoch": 1.3588888888888888,
      "grad_norm": 0.14847098290920258,
      "learning_rate": 1.6027777777777778e-05,
      "loss": 0.0022,
      "step": 61150
    },
    {
      "epoch": 1.3591111111111112,
      "grad_norm": 0.3373182713985443,
      "learning_rate": 1.602222222222222e-05,
      "loss": 0.0024,
      "step": 61160
    },
    {
      "epoch": 1.3593333333333333,
      "grad_norm": 0.13529853522777557,
      "learning_rate": 1.601666666666667e-05,
      "loss": 0.0018,
      "step": 61170
    },
    {
      "epoch": 1.3595555555555556,
      "grad_norm": 0.4256828725337982,
      "learning_rate": 1.6011111111111112e-05,
      "loss": 0.0028,
      "step": 61180
    },
    {
      "epoch": 1.3597777777777778,
      "grad_norm": 0.11291993409395218,
      "learning_rate": 1.6005555555555556e-05,
      "loss": 0.0027,
      "step": 61190
    },
    {
      "epoch": 1.3599999999999999,
      "grad_norm": 0.2607519030570984,
      "learning_rate": 1.6000000000000003e-05,
      "loss": 0.0026,
      "step": 61200
    },
    {
      "epoch": 1.3602222222222222,
      "grad_norm": 0.10390766710042953,
      "learning_rate": 1.5994444444444446e-05,
      "loss": 0.0019,
      "step": 61210
    },
    {
      "epoch": 1.3604444444444446,
      "grad_norm": 0.23332689702510834,
      "learning_rate": 1.598888888888889e-05,
      "loss": 0.002,
      "step": 61220
    },
    {
      "epoch": 1.3606666666666667,
      "grad_norm": 0.3343786299228668,
      "learning_rate": 1.5983333333333333e-05,
      "loss": 0.0017,
      "step": 61230
    },
    {
      "epoch": 1.3608888888888888,
      "grad_norm": 0.1421329826116562,
      "learning_rate": 1.5977777777777777e-05,
      "loss": 0.0019,
      "step": 61240
    },
    {
      "epoch": 1.3611111111111112,
      "grad_norm": 0.0559283085167408,
      "learning_rate": 1.597222222222222e-05,
      "loss": 0.0017,
      "step": 61250
    },
    {
      "epoch": 1.3613333333333333,
      "grad_norm": 0.25649890303611755,
      "learning_rate": 1.5966666666666667e-05,
      "loss": 0.0021,
      "step": 61260
    },
    {
      "epoch": 1.3615555555555556,
      "grad_norm": 0.06893955171108246,
      "learning_rate": 1.5961111111111114e-05,
      "loss": 0.0029,
      "step": 61270
    },
    {
      "epoch": 1.3617777777777778,
      "grad_norm": 0.23917879164218903,
      "learning_rate": 1.5955555555555558e-05,
      "loss": 0.0031,
      "step": 61280
    },
    {
      "epoch": 1.362,
      "grad_norm": 0.27016398310661316,
      "learning_rate": 1.595e-05,
      "loss": 0.0017,
      "step": 61290
    },
    {
      "epoch": 1.3622222222222222,
      "grad_norm": 0.2891647517681122,
      "learning_rate": 1.5944444444444445e-05,
      "loss": 0.0026,
      "step": 61300
    },
    {
      "epoch": 1.3624444444444443,
      "grad_norm": 0.10810547322034836,
      "learning_rate": 1.593888888888889e-05,
      "loss": 0.002,
      "step": 61310
    },
    {
      "epoch": 1.3626666666666667,
      "grad_norm": 0.14295150339603424,
      "learning_rate": 1.5933333333333332e-05,
      "loss": 0.0019,
      "step": 61320
    },
    {
      "epoch": 1.3628888888888888,
      "grad_norm": 0.07322564721107483,
      "learning_rate": 1.592777777777778e-05,
      "loss": 0.0024,
      "step": 61330
    },
    {
      "epoch": 1.3631111111111112,
      "grad_norm": 0.18347662687301636,
      "learning_rate": 1.5922222222222223e-05,
      "loss": 0.0016,
      "step": 61340
    },
    {
      "epoch": 1.3633333333333333,
      "grad_norm": 0.3875036835670471,
      "learning_rate": 1.591666666666667e-05,
      "loss": 0.0029,
      "step": 61350
    },
    {
      "epoch": 1.3635555555555556,
      "grad_norm": 0.36210259795188904,
      "learning_rate": 1.5911111111111113e-05,
      "loss": 0.0017,
      "step": 61360
    },
    {
      "epoch": 1.3637777777777778,
      "grad_norm": 0.1979951709508896,
      "learning_rate": 1.5905555555555557e-05,
      "loss": 0.0026,
      "step": 61370
    },
    {
      "epoch": 1.3639999999999999,
      "grad_norm": 0.23103822767734528,
      "learning_rate": 1.59e-05,
      "loss": 0.0017,
      "step": 61380
    },
    {
      "epoch": 1.3642222222222222,
      "grad_norm": 0.15996013581752777,
      "learning_rate": 1.5894444444444444e-05,
      "loss": 0.0023,
      "step": 61390
    },
    {
      "epoch": 1.3644444444444446,
      "grad_norm": 0.1450795978307724,
      "learning_rate": 1.588888888888889e-05,
      "loss": 0.0022,
      "step": 61400
    },
    {
      "epoch": 1.3646666666666667,
      "grad_norm": 0.25635483860969543,
      "learning_rate": 1.5883333333333334e-05,
      "loss": 0.0026,
      "step": 61410
    },
    {
      "epoch": 1.3648888888888888,
      "grad_norm": 0.34268447756767273,
      "learning_rate": 1.5877777777777778e-05,
      "loss": 0.0023,
      "step": 61420
    },
    {
      "epoch": 1.3651111111111112,
      "grad_norm": 0.050773221999406815,
      "learning_rate": 1.587222222222222e-05,
      "loss": 0.002,
      "step": 61430
    },
    {
      "epoch": 1.3653333333333333,
      "grad_norm": 0.08569011837244034,
      "learning_rate": 1.586666666666667e-05,
      "loss": 0.0017,
      "step": 61440
    },
    {
      "epoch": 1.3655555555555556,
      "grad_norm": 0.5101435780525208,
      "learning_rate": 1.5861111111111112e-05,
      "loss": 0.002,
      "step": 61450
    },
    {
      "epoch": 1.3657777777777778,
      "grad_norm": 0.40075185894966125,
      "learning_rate": 1.5855555555555555e-05,
      "loss": 0.0028,
      "step": 61460
    },
    {
      "epoch": 1.366,
      "grad_norm": 0.2972104251384735,
      "learning_rate": 1.5850000000000002e-05,
      "loss": 0.0019,
      "step": 61470
    },
    {
      "epoch": 1.3662222222222222,
      "grad_norm": 0.15640303492546082,
      "learning_rate": 1.5844444444444446e-05,
      "loss": 0.002,
      "step": 61480
    },
    {
      "epoch": 1.3664444444444444,
      "grad_norm": 0.10654623806476593,
      "learning_rate": 1.583888888888889e-05,
      "loss": 0.0026,
      "step": 61490
    },
    {
      "epoch": 1.3666666666666667,
      "grad_norm": 0.2745678424835205,
      "learning_rate": 1.5833333333333333e-05,
      "loss": 0.0019,
      "step": 61500
    },
    {
      "epoch": 1.3668888888888888,
      "grad_norm": 0.12743736803531647,
      "learning_rate": 1.5827777777777777e-05,
      "loss": 0.0018,
      "step": 61510
    },
    {
      "epoch": 1.3671111111111112,
      "grad_norm": 0.37444013357162476,
      "learning_rate": 1.582222222222222e-05,
      "loss": 0.002,
      "step": 61520
    },
    {
      "epoch": 1.3673333333333333,
      "grad_norm": 0.2625868022441864,
      "learning_rate": 1.5816666666666667e-05,
      "loss": 0.0023,
      "step": 61530
    },
    {
      "epoch": 1.3675555555555556,
      "grad_norm": 0.18253333866596222,
      "learning_rate": 1.5811111111111114e-05,
      "loss": 0.0022,
      "step": 61540
    },
    {
      "epoch": 1.3677777777777778,
      "grad_norm": 0.5954551696777344,
      "learning_rate": 1.5805555555555558e-05,
      "loss": 0.0025,
      "step": 61550
    },
    {
      "epoch": 1.3679999999999999,
      "grad_norm": 0.057641610503196716,
      "learning_rate": 1.58e-05,
      "loss": 0.0021,
      "step": 61560
    },
    {
      "epoch": 1.3682222222222222,
      "grad_norm": 0.1073758602142334,
      "learning_rate": 1.5794444444444445e-05,
      "loss": 0.002,
      "step": 61570
    },
    {
      "epoch": 1.3684444444444446,
      "grad_norm": 0.18253038823604584,
      "learning_rate": 1.5788888888888888e-05,
      "loss": 0.0021,
      "step": 61580
    },
    {
      "epoch": 1.3686666666666667,
      "grad_norm": 0.20377951860427856,
      "learning_rate": 1.5783333333333332e-05,
      "loss": 0.0023,
      "step": 61590
    },
    {
      "epoch": 1.3688888888888888,
      "grad_norm": 0.27567726373672485,
      "learning_rate": 1.577777777777778e-05,
      "loss": 0.0032,
      "step": 61600
    },
    {
      "epoch": 1.3691111111111112,
      "grad_norm": 0.30556851625442505,
      "learning_rate": 1.5772222222222226e-05,
      "loss": 0.0026,
      "step": 61610
    },
    {
      "epoch": 1.3693333333333333,
      "grad_norm": 0.20370179414749146,
      "learning_rate": 1.576666666666667e-05,
      "loss": 0.0017,
      "step": 61620
    },
    {
      "epoch": 1.3695555555555556,
      "grad_norm": 0.3344152271747589,
      "learning_rate": 1.5761111111111113e-05,
      "loss": 0.0017,
      "step": 61630
    },
    {
      "epoch": 1.3697777777777778,
      "grad_norm": 0.4270245134830475,
      "learning_rate": 1.5755555555555556e-05,
      "loss": 0.0022,
      "step": 61640
    },
    {
      "epoch": 1.37,
      "grad_norm": 0.606783926486969,
      "learning_rate": 1.575e-05,
      "loss": 0.0018,
      "step": 61650
    },
    {
      "epoch": 1.3702222222222222,
      "grad_norm": 0.16729210317134857,
      "learning_rate": 1.5744444444444444e-05,
      "loss": 0.0024,
      "step": 61660
    },
    {
      "epoch": 1.3704444444444444,
      "grad_norm": 0.7180203199386597,
      "learning_rate": 1.573888888888889e-05,
      "loss": 0.0018,
      "step": 61670
    },
    {
      "epoch": 1.3706666666666667,
      "grad_norm": 0.6796864867210388,
      "learning_rate": 1.5733333333333334e-05,
      "loss": 0.0021,
      "step": 61680
    },
    {
      "epoch": 1.3708888888888888,
      "grad_norm": 0.2908379137516022,
      "learning_rate": 1.5727777777777778e-05,
      "loss": 0.0021,
      "step": 61690
    },
    {
      "epoch": 1.3711111111111112,
      "grad_norm": 0.26592010259628296,
      "learning_rate": 1.5722222222222225e-05,
      "loss": 0.0019,
      "step": 61700
    },
    {
      "epoch": 1.3713333333333333,
      "grad_norm": 0.4939969480037689,
      "learning_rate": 1.5716666666666668e-05,
      "loss": 0.0018,
      "step": 61710
    },
    {
      "epoch": 1.3715555555555556,
      "grad_norm": 0.12220273166894913,
      "learning_rate": 1.571111111111111e-05,
      "loss": 0.0027,
      "step": 61720
    },
    {
      "epoch": 1.3717777777777778,
      "grad_norm": 0.09880281984806061,
      "learning_rate": 1.5705555555555555e-05,
      "loss": 0.0022,
      "step": 61730
    },
    {
      "epoch": 1.3719999999999999,
      "grad_norm": 0.10383692383766174,
      "learning_rate": 1.5700000000000002e-05,
      "loss": 0.0021,
      "step": 61740
    },
    {
      "epoch": 1.3722222222222222,
      "grad_norm": 0.2360558807849884,
      "learning_rate": 1.5694444444444446e-05,
      "loss": 0.0028,
      "step": 61750
    },
    {
      "epoch": 1.3724444444444446,
      "grad_norm": 0.6530852317810059,
      "learning_rate": 1.568888888888889e-05,
      "loss": 0.002,
      "step": 61760
    },
    {
      "epoch": 1.3726666666666667,
      "grad_norm": 0.4531539976596832,
      "learning_rate": 1.5683333333333333e-05,
      "loss": 0.0019,
      "step": 61770
    },
    {
      "epoch": 1.3728888888888888,
      "grad_norm": 0.24575893580913544,
      "learning_rate": 1.5677777777777776e-05,
      "loss": 0.0028,
      "step": 61780
    },
    {
      "epoch": 1.3731111111111112,
      "grad_norm": 0.4761204719543457,
      "learning_rate": 1.5672222222222223e-05,
      "loss": 0.0016,
      "step": 61790
    },
    {
      "epoch": 1.3733333333333333,
      "grad_norm": 0.3330193758010864,
      "learning_rate": 1.5666666666666667e-05,
      "loss": 0.0019,
      "step": 61800
    },
    {
      "epoch": 1.3735555555555554,
      "grad_norm": 0.15327954292297363,
      "learning_rate": 1.5661111111111114e-05,
      "loss": 0.0019,
      "step": 61810
    },
    {
      "epoch": 1.3737777777777778,
      "grad_norm": 0.08583875745534897,
      "learning_rate": 1.5655555555555557e-05,
      "loss": 0.0019,
      "step": 61820
    },
    {
      "epoch": 1.374,
      "grad_norm": 0.14684347808361053,
      "learning_rate": 1.565e-05,
      "loss": 0.0019,
      "step": 61830
    },
    {
      "epoch": 1.3742222222222222,
      "grad_norm": 0.18123340606689453,
      "learning_rate": 1.5644444444444444e-05,
      "loss": 0.0033,
      "step": 61840
    },
    {
      "epoch": 1.3744444444444444,
      "grad_norm": 0.22329474985599518,
      "learning_rate": 1.5638888888888888e-05,
      "loss": 0.0026,
      "step": 61850
    },
    {
      "epoch": 1.3746666666666667,
      "grad_norm": 0.21958602964878082,
      "learning_rate": 1.563333333333333e-05,
      "loss": 0.0027,
      "step": 61860
    },
    {
      "epoch": 1.3748888888888888,
      "grad_norm": 0.2177751362323761,
      "learning_rate": 1.562777777777778e-05,
      "loss": 0.0023,
      "step": 61870
    },
    {
      "epoch": 1.3751111111111112,
      "grad_norm": 0.26190420985221863,
      "learning_rate": 1.5622222222222225e-05,
      "loss": 0.0027,
      "step": 61880
    },
    {
      "epoch": 1.3753333333333333,
      "grad_norm": 0.24316094815731049,
      "learning_rate": 1.561666666666667e-05,
      "loss": 0.0019,
      "step": 61890
    },
    {
      "epoch": 1.3755555555555556,
      "grad_norm": 0.38174182176589966,
      "learning_rate": 1.5611111111111113e-05,
      "loss": 0.0018,
      "step": 61900
    },
    {
      "epoch": 1.3757777777777778,
      "grad_norm": 0.3304263949394226,
      "learning_rate": 1.5605555555555556e-05,
      "loss": 0.0018,
      "step": 61910
    },
    {
      "epoch": 1.376,
      "grad_norm": 0.27177658677101135,
      "learning_rate": 1.56e-05,
      "loss": 0.002,
      "step": 61920
    },
    {
      "epoch": 1.3762222222222222,
      "grad_norm": 0.5104578733444214,
      "learning_rate": 1.5594444444444443e-05,
      "loss": 0.0022,
      "step": 61930
    },
    {
      "epoch": 1.3764444444444446,
      "grad_norm": 0.4026799201965332,
      "learning_rate": 1.558888888888889e-05,
      "loss": 0.0026,
      "step": 61940
    },
    {
      "epoch": 1.3766666666666667,
      "grad_norm": 0.095718614757061,
      "learning_rate": 1.5583333333333334e-05,
      "loss": 0.0018,
      "step": 61950
    },
    {
      "epoch": 1.3768888888888888,
      "grad_norm": 0.37061959505081177,
      "learning_rate": 1.5577777777777777e-05,
      "loss": 0.0028,
      "step": 61960
    },
    {
      "epoch": 1.3771111111111112,
      "grad_norm": 0.10545340925455093,
      "learning_rate": 1.5572222222222224e-05,
      "loss": 0.0017,
      "step": 61970
    },
    {
      "epoch": 1.3773333333333333,
      "grad_norm": 0.489247590303421,
      "learning_rate": 1.5566666666666668e-05,
      "loss": 0.0017,
      "step": 61980
    },
    {
      "epoch": 1.3775555555555554,
      "grad_norm": 0.37854695320129395,
      "learning_rate": 1.556111111111111e-05,
      "loss": 0.0027,
      "step": 61990
    },
    {
      "epoch": 1.3777777777777778,
      "grad_norm": 0.13157497346401215,
      "learning_rate": 1.5555555555555555e-05,
      "loss": 0.0019,
      "step": 62000
    },
    {
      "epoch": 1.3780000000000001,
      "grad_norm": 0.1769338697195053,
      "learning_rate": 1.5550000000000002e-05,
      "loss": 0.0028,
      "step": 62010
    },
    {
      "epoch": 1.3782222222222222,
      "grad_norm": 0.22575446963310242,
      "learning_rate": 1.5544444444444445e-05,
      "loss": 0.0025,
      "step": 62020
    },
    {
      "epoch": 1.3784444444444444,
      "grad_norm": 0.3514796793460846,
      "learning_rate": 1.553888888888889e-05,
      "loss": 0.0025,
      "step": 62030
    },
    {
      "epoch": 1.3786666666666667,
      "grad_norm": 0.4049419164657593,
      "learning_rate": 1.5533333333333333e-05,
      "loss": 0.0017,
      "step": 62040
    },
    {
      "epoch": 1.3788888888888888,
      "grad_norm": 0.641362190246582,
      "learning_rate": 1.5527777777777776e-05,
      "loss": 0.0018,
      "step": 62050
    },
    {
      "epoch": 1.3791111111111112,
      "grad_norm": 0.1055677980184555,
      "learning_rate": 1.5522222222222223e-05,
      "loss": 0.0027,
      "step": 62060
    },
    {
      "epoch": 1.3793333333333333,
      "grad_norm": 0.0734843984246254,
      "learning_rate": 1.5516666666666667e-05,
      "loss": 0.002,
      "step": 62070
    },
    {
      "epoch": 1.3795555555555556,
      "grad_norm": 0.6429903507232666,
      "learning_rate": 1.5511111111111114e-05,
      "loss": 0.0018,
      "step": 62080
    },
    {
      "epoch": 1.3797777777777778,
      "grad_norm": 0.25872525572776794,
      "learning_rate": 1.5505555555555557e-05,
      "loss": 0.0016,
      "step": 62090
    },
    {
      "epoch": 1.38,
      "grad_norm": 0.20196747779846191,
      "learning_rate": 1.55e-05,
      "loss": 0.0022,
      "step": 62100
    },
    {
      "epoch": 1.3802222222222222,
      "grad_norm": 0.1758309006690979,
      "learning_rate": 1.5494444444444444e-05,
      "loss": 0.002,
      "step": 62110
    },
    {
      "epoch": 1.3804444444444444,
      "grad_norm": 0.07270896434783936,
      "learning_rate": 1.5488888888888888e-05,
      "loss": 0.0019,
      "step": 62120
    },
    {
      "epoch": 1.3806666666666667,
      "grad_norm": 0.28286027908325195,
      "learning_rate": 1.548333333333333e-05,
      "loss": 0.0018,
      "step": 62130
    },
    {
      "epoch": 1.3808888888888888,
      "grad_norm": 0.049551285803318024,
      "learning_rate": 1.5477777777777778e-05,
      "loss": 0.0016,
      "step": 62140
    },
    {
      "epoch": 1.3811111111111112,
      "grad_norm": 0.07090459018945694,
      "learning_rate": 1.5472222222222225e-05,
      "loss": 0.0029,
      "step": 62150
    },
    {
      "epoch": 1.3813333333333333,
      "grad_norm": 0.7136471271514893,
      "learning_rate": 1.546666666666667e-05,
      "loss": 0.0026,
      "step": 62160
    },
    {
      "epoch": 1.3815555555555554,
      "grad_norm": 0.07740497589111328,
      "learning_rate": 1.5461111111111112e-05,
      "loss": 0.0024,
      "step": 62170
    },
    {
      "epoch": 1.3817777777777778,
      "grad_norm": 0.40403348207473755,
      "learning_rate": 1.5455555555555556e-05,
      "loss": 0.0041,
      "step": 62180
    },
    {
      "epoch": 1.3820000000000001,
      "grad_norm": 0.3027139902114868,
      "learning_rate": 1.545e-05,
      "loss": 0.0021,
      "step": 62190
    },
    {
      "epoch": 1.3822222222222222,
      "grad_norm": 0.07490822672843933,
      "learning_rate": 1.5444444444444446e-05,
      "loss": 0.0021,
      "step": 62200
    },
    {
      "epoch": 1.3824444444444444,
      "grad_norm": 0.16471152007579803,
      "learning_rate": 1.543888888888889e-05,
      "loss": 0.0017,
      "step": 62210
    },
    {
      "epoch": 1.3826666666666667,
      "grad_norm": 0.14510619640350342,
      "learning_rate": 1.5433333333333334e-05,
      "loss": 0.0018,
      "step": 62220
    },
    {
      "epoch": 1.3828888888888888,
      "grad_norm": 0.1362570971250534,
      "learning_rate": 1.542777777777778e-05,
      "loss": 0.0017,
      "step": 62230
    },
    {
      "epoch": 1.3831111111111112,
      "grad_norm": 0.1609867662191391,
      "learning_rate": 1.5422222222222224e-05,
      "loss": 0.0021,
      "step": 62240
    },
    {
      "epoch": 1.3833333333333333,
      "grad_norm": 0.27409887313842773,
      "learning_rate": 1.5416666666666668e-05,
      "loss": 0.0019,
      "step": 62250
    },
    {
      "epoch": 1.3835555555555556,
      "grad_norm": 0.07569573819637299,
      "learning_rate": 1.541111111111111e-05,
      "loss": 0.0017,
      "step": 62260
    },
    {
      "epoch": 1.3837777777777778,
      "grad_norm": 0.49253320693969727,
      "learning_rate": 1.5405555555555558e-05,
      "loss": 0.0023,
      "step": 62270
    },
    {
      "epoch": 1.384,
      "grad_norm": 0.14010249078273773,
      "learning_rate": 1.54e-05,
      "loss": 0.0017,
      "step": 62280
    },
    {
      "epoch": 1.3842222222222222,
      "grad_norm": 0.12548653781414032,
      "learning_rate": 1.5394444444444445e-05,
      "loss": 0.0021,
      "step": 62290
    },
    {
      "epoch": 1.3844444444444444,
      "grad_norm": 0.2692069709300995,
      "learning_rate": 1.538888888888889e-05,
      "loss": 0.0024,
      "step": 62300
    },
    {
      "epoch": 1.3846666666666667,
      "grad_norm": 0.21817214787006378,
      "learning_rate": 1.5383333333333332e-05,
      "loss": 0.0045,
      "step": 62310
    },
    {
      "epoch": 1.3848888888888888,
      "grad_norm": 0.16945046186447144,
      "learning_rate": 1.537777777777778e-05,
      "loss": 0.0021,
      "step": 62320
    },
    {
      "epoch": 1.3851111111111112,
      "grad_norm": 0.1974017322063446,
      "learning_rate": 1.5372222222222223e-05,
      "loss": 0.0028,
      "step": 62330
    },
    {
      "epoch": 1.3853333333333333,
      "grad_norm": 0.1609657257795334,
      "learning_rate": 1.536666666666667e-05,
      "loss": 0.0026,
      "step": 62340
    },
    {
      "epoch": 1.3855555555555554,
      "grad_norm": 0.2518078684806824,
      "learning_rate": 1.5361111111111113e-05,
      "loss": 0.0018,
      "step": 62350
    },
    {
      "epoch": 1.3857777777777778,
      "grad_norm": 0.5386611223220825,
      "learning_rate": 1.5355555555555557e-05,
      "loss": 0.0019,
      "step": 62360
    },
    {
      "epoch": 1.3860000000000001,
      "grad_norm": 0.5243775248527527,
      "learning_rate": 1.535e-05,
      "loss": 0.0019,
      "step": 62370
    },
    {
      "epoch": 1.3862222222222222,
      "grad_norm": 0.2731948494911194,
      "learning_rate": 1.5344444444444444e-05,
      "loss": 0.0021,
      "step": 62380
    },
    {
      "epoch": 1.3864444444444444,
      "grad_norm": 0.2780166268348694,
      "learning_rate": 1.5338888888888888e-05,
      "loss": 0.002,
      "step": 62390
    },
    {
      "epoch": 1.3866666666666667,
      "grad_norm": 0.11380951851606369,
      "learning_rate": 1.5333333333333334e-05,
      "loss": 0.0018,
      "step": 62400
    },
    {
      "epoch": 1.3868888888888888,
      "grad_norm": 0.5966266393661499,
      "learning_rate": 1.532777777777778e-05,
      "loss": 0.0017,
      "step": 62410
    },
    {
      "epoch": 1.3871111111111112,
      "grad_norm": 0.27486056089401245,
      "learning_rate": 1.5322222222222225e-05,
      "loss": 0.0017,
      "step": 62420
    },
    {
      "epoch": 1.3873333333333333,
      "grad_norm": 0.7457044124603271,
      "learning_rate": 1.531666666666667e-05,
      "loss": 0.0024,
      "step": 62430
    },
    {
      "epoch": 1.3875555555555557,
      "grad_norm": 0.0906873568892479,
      "learning_rate": 1.5311111111111112e-05,
      "loss": 0.0023,
      "step": 62440
    },
    {
      "epoch": 1.3877777777777778,
      "grad_norm": 0.1358300894498825,
      "learning_rate": 1.5305555555555556e-05,
      "loss": 0.0027,
      "step": 62450
    },
    {
      "epoch": 1.388,
      "grad_norm": 0.08502154797315598,
      "learning_rate": 1.53e-05,
      "loss": 0.002,
      "step": 62460
    },
    {
      "epoch": 1.3882222222222222,
      "grad_norm": 0.5117044448852539,
      "learning_rate": 1.5294444444444446e-05,
      "loss": 0.0022,
      "step": 62470
    },
    {
      "epoch": 1.3884444444444444,
      "grad_norm": 0.568871796131134,
      "learning_rate": 1.528888888888889e-05,
      "loss": 0.0023,
      "step": 62480
    },
    {
      "epoch": 1.3886666666666667,
      "grad_norm": 0.14497719705104828,
      "learning_rate": 1.5283333333333333e-05,
      "loss": 0.0019,
      "step": 62490
    },
    {
      "epoch": 1.3888888888888888,
      "grad_norm": 0.1774960309267044,
      "learning_rate": 1.527777777777778e-05,
      "loss": 0.0034,
      "step": 62500
    },
    {
      "epoch": 1.3891111111111112,
      "grad_norm": 0.204550638794899,
      "learning_rate": 1.5272222222222224e-05,
      "loss": 0.0019,
      "step": 62510
    },
    {
      "epoch": 1.3893333333333333,
      "grad_norm": 0.21979613602161407,
      "learning_rate": 1.5266666666666667e-05,
      "loss": 0.0025,
      "step": 62520
    },
    {
      "epoch": 1.3895555555555554,
      "grad_norm": 0.0637379139661789,
      "learning_rate": 1.526111111111111e-05,
      "loss": 0.0017,
      "step": 62530
    },
    {
      "epoch": 1.3897777777777778,
      "grad_norm": 0.12720631062984467,
      "learning_rate": 1.5255555555555556e-05,
      "loss": 0.0036,
      "step": 62540
    },
    {
      "epoch": 1.3900000000000001,
      "grad_norm": 0.1536596566438675,
      "learning_rate": 1.525e-05,
      "loss": 0.0018,
      "step": 62550
    },
    {
      "epoch": 1.3902222222222222,
      "grad_norm": 0.33336013555526733,
      "learning_rate": 1.5244444444444445e-05,
      "loss": 0.002,
      "step": 62560
    },
    {
      "epoch": 1.3904444444444444,
      "grad_norm": 0.09412170946598053,
      "learning_rate": 1.5238888888888888e-05,
      "loss": 0.0024,
      "step": 62570
    },
    {
      "epoch": 1.3906666666666667,
      "grad_norm": 0.07604118436574936,
      "learning_rate": 1.5233333333333332e-05,
      "loss": 0.0019,
      "step": 62580
    },
    {
      "epoch": 1.3908888888888888,
      "grad_norm": 0.19873374700546265,
      "learning_rate": 1.5227777777777779e-05,
      "loss": 0.0028,
      "step": 62590
    },
    {
      "epoch": 1.3911111111111112,
      "grad_norm": 0.12134862691164017,
      "learning_rate": 1.5222222222222224e-05,
      "loss": 0.0019,
      "step": 62600
    },
    {
      "epoch": 1.3913333333333333,
      "grad_norm": 0.07343485951423645,
      "learning_rate": 1.5216666666666668e-05,
      "loss": 0.0017,
      "step": 62610
    },
    {
      "epoch": 1.3915555555555557,
      "grad_norm": 0.11343014240264893,
      "learning_rate": 1.5211111111111111e-05,
      "loss": 0.0028,
      "step": 62620
    },
    {
      "epoch": 1.3917777777777778,
      "grad_norm": 0.2817269265651703,
      "learning_rate": 1.5205555555555557e-05,
      "loss": 0.0026,
      "step": 62630
    },
    {
      "epoch": 1.392,
      "grad_norm": 0.43988391757011414,
      "learning_rate": 1.52e-05,
      "loss": 0.002,
      "step": 62640
    },
    {
      "epoch": 1.3922222222222222,
      "grad_norm": 0.06427008658647537,
      "learning_rate": 1.5194444444444444e-05,
      "loss": 0.0028,
      "step": 62650
    },
    {
      "epoch": 1.3924444444444444,
      "grad_norm": 0.22755402326583862,
      "learning_rate": 1.5188888888888889e-05,
      "loss": 0.0031,
      "step": 62660
    },
    {
      "epoch": 1.3926666666666667,
      "grad_norm": 0.2900552749633789,
      "learning_rate": 1.5183333333333333e-05,
      "loss": 0.0021,
      "step": 62670
    },
    {
      "epoch": 1.3928888888888888,
      "grad_norm": 0.2690552771091461,
      "learning_rate": 1.517777777777778e-05,
      "loss": 0.0019,
      "step": 62680
    },
    {
      "epoch": 1.3931111111111112,
      "grad_norm": 0.11403722316026688,
      "learning_rate": 1.5172222222222223e-05,
      "loss": 0.003,
      "step": 62690
    },
    {
      "epoch": 1.3933333333333333,
      "grad_norm": 0.15792928636074066,
      "learning_rate": 1.5166666666666668e-05,
      "loss": 0.0034,
      "step": 62700
    },
    {
      "epoch": 1.3935555555555554,
      "grad_norm": 0.47191107273101807,
      "learning_rate": 1.5161111111111112e-05,
      "loss": 0.0025,
      "step": 62710
    },
    {
      "epoch": 1.3937777777777778,
      "grad_norm": 0.22667405009269714,
      "learning_rate": 1.5155555555555555e-05,
      "loss": 0.002,
      "step": 62720
    },
    {
      "epoch": 1.3940000000000001,
      "grad_norm": 0.15250641107559204,
      "learning_rate": 1.515e-05,
      "loss": 0.0017,
      "step": 62730
    },
    {
      "epoch": 1.3942222222222223,
      "grad_norm": 0.20483753085136414,
      "learning_rate": 1.5144444444444444e-05,
      "loss": 0.0022,
      "step": 62740
    },
    {
      "epoch": 1.3944444444444444,
      "grad_norm": 0.12680014967918396,
      "learning_rate": 1.5138888888888888e-05,
      "loss": 0.0019,
      "step": 62750
    },
    {
      "epoch": 1.3946666666666667,
      "grad_norm": 0.4986070990562439,
      "learning_rate": 1.5133333333333333e-05,
      "loss": 0.0021,
      "step": 62760
    },
    {
      "epoch": 1.3948888888888888,
      "grad_norm": 0.07332292944192886,
      "learning_rate": 1.512777777777778e-05,
      "loss": 0.0018,
      "step": 62770
    },
    {
      "epoch": 1.3951111111111112,
      "grad_norm": 0.6090342998504639,
      "learning_rate": 1.5122222222222224e-05,
      "loss": 0.002,
      "step": 62780
    },
    {
      "epoch": 1.3953333333333333,
      "grad_norm": 0.31313270330429077,
      "learning_rate": 1.5116666666666667e-05,
      "loss": 0.0018,
      "step": 62790
    },
    {
      "epoch": 1.3955555555555557,
      "grad_norm": 0.1003139317035675,
      "learning_rate": 1.5111111111111112e-05,
      "loss": 0.0022,
      "step": 62800
    },
    {
      "epoch": 1.3957777777777778,
      "grad_norm": 0.10667234659194946,
      "learning_rate": 1.5105555555555556e-05,
      "loss": 0.0022,
      "step": 62810
    },
    {
      "epoch": 1.396,
      "grad_norm": 0.2363622784614563,
      "learning_rate": 1.51e-05,
      "loss": 0.0019,
      "step": 62820
    },
    {
      "epoch": 1.3962222222222223,
      "grad_norm": 0.29805299639701843,
      "learning_rate": 1.5094444444444445e-05,
      "loss": 0.0021,
      "step": 62830
    },
    {
      "epoch": 1.3964444444444444,
      "grad_norm": 0.40843355655670166,
      "learning_rate": 1.5088888888888888e-05,
      "loss": 0.0029,
      "step": 62840
    },
    {
      "epoch": 1.3966666666666667,
      "grad_norm": 0.2860574722290039,
      "learning_rate": 1.5083333333333335e-05,
      "loss": 0.0026,
      "step": 62850
    },
    {
      "epoch": 1.3968888888888888,
      "grad_norm": 0.058213409036397934,
      "learning_rate": 1.5077777777777779e-05,
      "loss": 0.0034,
      "step": 62860
    },
    {
      "epoch": 1.3971111111111112,
      "grad_norm": 0.33085447549819946,
      "learning_rate": 1.5072222222222224e-05,
      "loss": 0.0022,
      "step": 62870
    },
    {
      "epoch": 1.3973333333333333,
      "grad_norm": 0.2061285525560379,
      "learning_rate": 1.5066666666666668e-05,
      "loss": 0.0023,
      "step": 62880
    },
    {
      "epoch": 1.3975555555555554,
      "grad_norm": 0.23241132497787476,
      "learning_rate": 1.5061111111111113e-05,
      "loss": 0.0019,
      "step": 62890
    },
    {
      "epoch": 1.3977777777777778,
      "grad_norm": 0.5132449269294739,
      "learning_rate": 1.5055555555555556e-05,
      "loss": 0.0019,
      "step": 62900
    },
    {
      "epoch": 1.3980000000000001,
      "grad_norm": 0.5517197847366333,
      "learning_rate": 1.505e-05,
      "loss": 0.0022,
      "step": 62910
    },
    {
      "epoch": 1.3982222222222223,
      "grad_norm": 0.07229498028755188,
      "learning_rate": 1.5044444444444445e-05,
      "loss": 0.0017,
      "step": 62920
    },
    {
      "epoch": 1.3984444444444444,
      "grad_norm": 0.10365406423807144,
      "learning_rate": 1.5038888888888889e-05,
      "loss": 0.0028,
      "step": 62930
    },
    {
      "epoch": 1.3986666666666667,
      "grad_norm": 0.05710139125585556,
      "learning_rate": 1.5033333333333336e-05,
      "loss": 0.0021,
      "step": 62940
    },
    {
      "epoch": 1.3988888888888888,
      "grad_norm": 0.0747850313782692,
      "learning_rate": 1.502777777777778e-05,
      "loss": 0.0019,
      "step": 62950
    },
    {
      "epoch": 1.3991111111111112,
      "grad_norm": 0.1666848063468933,
      "learning_rate": 1.5022222222222224e-05,
      "loss": 0.0018,
      "step": 62960
    },
    {
      "epoch": 1.3993333333333333,
      "grad_norm": 0.5699393153190613,
      "learning_rate": 1.5016666666666668e-05,
      "loss": 0.002,
      "step": 62970
    },
    {
      "epoch": 1.3995555555555557,
      "grad_norm": 0.35993674397468567,
      "learning_rate": 1.5011111111111112e-05,
      "loss": 0.0017,
      "step": 62980
    },
    {
      "epoch": 1.3997777777777778,
      "grad_norm": 0.1526881754398346,
      "learning_rate": 1.5005555555555557e-05,
      "loss": 0.0033,
      "step": 62990
    },
    {
      "epoch": 1.4,
      "grad_norm": 0.13593575358390808,
      "learning_rate": 1.5e-05,
      "loss": 0.0019,
      "step": 63000
    },
    {
      "epoch": 1.4002222222222223,
      "grad_norm": 0.08600512892007828,
      "learning_rate": 1.4994444444444444e-05,
      "loss": 0.0024,
      "step": 63010
    },
    {
      "epoch": 1.4004444444444444,
      "grad_norm": 0.15970878303050995,
      "learning_rate": 1.498888888888889e-05,
      "loss": 0.002,
      "step": 63020
    },
    {
      "epoch": 1.4006666666666667,
      "grad_norm": 0.16385087370872498,
      "learning_rate": 1.4983333333333336e-05,
      "loss": 0.0021,
      "step": 63030
    },
    {
      "epoch": 1.4008888888888889,
      "grad_norm": 0.14427988231182098,
      "learning_rate": 1.497777777777778e-05,
      "loss": 0.0019,
      "step": 63040
    },
    {
      "epoch": 1.4011111111111112,
      "grad_norm": 0.2306026816368103,
      "learning_rate": 1.4972222222222223e-05,
      "loss": 0.0017,
      "step": 63050
    },
    {
      "epoch": 1.4013333333333333,
      "grad_norm": 0.1524282842874527,
      "learning_rate": 1.4966666666666668e-05,
      "loss": 0.003,
      "step": 63060
    },
    {
      "epoch": 1.4015555555555554,
      "grad_norm": 0.17766951024532318,
      "learning_rate": 1.4961111111111112e-05,
      "loss": 0.0026,
      "step": 63070
    },
    {
      "epoch": 1.4017777777777778,
      "grad_norm": 0.554408848285675,
      "learning_rate": 1.4955555555555556e-05,
      "loss": 0.0017,
      "step": 63080
    },
    {
      "epoch": 1.4020000000000001,
      "grad_norm": 0.3081922233104706,
      "learning_rate": 1.4950000000000001e-05,
      "loss": 0.0025,
      "step": 63090
    },
    {
      "epoch": 1.4022222222222223,
      "grad_norm": 0.23636697232723236,
      "learning_rate": 1.4944444444444444e-05,
      "loss": 0.0019,
      "step": 63100
    },
    {
      "epoch": 1.4024444444444444,
      "grad_norm": 0.2096806764602661,
      "learning_rate": 1.4938888888888888e-05,
      "loss": 0.0021,
      "step": 63110
    },
    {
      "epoch": 1.4026666666666667,
      "grad_norm": 0.18200424313545227,
      "learning_rate": 1.4933333333333335e-05,
      "loss": 0.002,
      "step": 63120
    },
    {
      "epoch": 1.4028888888888889,
      "grad_norm": 0.2119569331407547,
      "learning_rate": 1.492777777777778e-05,
      "loss": 0.0019,
      "step": 63130
    },
    {
      "epoch": 1.403111111111111,
      "grad_norm": 0.12590673565864563,
      "learning_rate": 1.4922222222222224e-05,
      "loss": 0.0021,
      "step": 63140
    },
    {
      "epoch": 1.4033333333333333,
      "grad_norm": 0.4324336051940918,
      "learning_rate": 1.4916666666666667e-05,
      "loss": 0.002,
      "step": 63150
    },
    {
      "epoch": 1.4035555555555557,
      "grad_norm": 0.25097689032554626,
      "learning_rate": 1.4911111111111113e-05,
      "loss": 0.0017,
      "step": 63160
    },
    {
      "epoch": 1.4037777777777778,
      "grad_norm": 0.054756250232458115,
      "learning_rate": 1.4905555555555556e-05,
      "loss": 0.0027,
      "step": 63170
    },
    {
      "epoch": 1.404,
      "grad_norm": 0.06473512202501297,
      "learning_rate": 1.49e-05,
      "loss": 0.0018,
      "step": 63180
    },
    {
      "epoch": 1.4042222222222223,
      "grad_norm": 0.07504209876060486,
      "learning_rate": 1.4894444444444445e-05,
      "loss": 0.0025,
      "step": 63190
    },
    {
      "epoch": 1.4044444444444444,
      "grad_norm": 0.07043548673391342,
      "learning_rate": 1.4888888888888888e-05,
      "loss": 0.0021,
      "step": 63200
    },
    {
      "epoch": 1.4046666666666667,
      "grad_norm": 0.1721358448266983,
      "learning_rate": 1.4883333333333335e-05,
      "loss": 0.0019,
      "step": 63210
    },
    {
      "epoch": 1.4048888888888889,
      "grad_norm": 0.17714719474315643,
      "learning_rate": 1.4877777777777779e-05,
      "loss": 0.0017,
      "step": 63220
    },
    {
      "epoch": 1.4051111111111112,
      "grad_norm": 0.1748877763748169,
      "learning_rate": 1.4872222222222224e-05,
      "loss": 0.0019,
      "step": 63230
    },
    {
      "epoch": 1.4053333333333333,
      "grad_norm": 0.36831361055374146,
      "learning_rate": 1.4866666666666668e-05,
      "loss": 0.0023,
      "step": 63240
    },
    {
      "epoch": 1.4055555555555554,
      "grad_norm": 0.21917399764060974,
      "learning_rate": 1.4861111111111111e-05,
      "loss": 0.0019,
      "step": 63250
    },
    {
      "epoch": 1.4057777777777778,
      "grad_norm": 0.16831333935260773,
      "learning_rate": 1.4855555555555557e-05,
      "loss": 0.0027,
      "step": 63260
    },
    {
      "epoch": 1.4060000000000001,
      "grad_norm": 0.253757506608963,
      "learning_rate": 1.485e-05,
      "loss": 0.0019,
      "step": 63270
    },
    {
      "epoch": 1.4062222222222223,
      "grad_norm": 0.15114134550094604,
      "learning_rate": 1.4844444444444444e-05,
      "loss": 0.0028,
      "step": 63280
    },
    {
      "epoch": 1.4064444444444444,
      "grad_norm": 0.3847837746143341,
      "learning_rate": 1.4838888888888889e-05,
      "loss": 0.002,
      "step": 63290
    },
    {
      "epoch": 1.4066666666666667,
      "grad_norm": 0.12584850192070007,
      "learning_rate": 1.4833333333333336e-05,
      "loss": 0.0021,
      "step": 63300
    },
    {
      "epoch": 1.4068888888888889,
      "grad_norm": 0.0462237223982811,
      "learning_rate": 1.482777777777778e-05,
      "loss": 0.0017,
      "step": 63310
    },
    {
      "epoch": 1.407111111111111,
      "grad_norm": 0.22670462727546692,
      "learning_rate": 1.4822222222222223e-05,
      "loss": 0.0021,
      "step": 63320
    },
    {
      "epoch": 1.4073333333333333,
      "grad_norm": 0.31604960560798645,
      "learning_rate": 1.4816666666666668e-05,
      "loss": 0.0031,
      "step": 63330
    },
    {
      "epoch": 1.4075555555555557,
      "grad_norm": 0.33855393528938293,
      "learning_rate": 1.4811111111111112e-05,
      "loss": 0.0017,
      "step": 63340
    },
    {
      "epoch": 1.4077777777777778,
      "grad_norm": 0.2636207640171051,
      "learning_rate": 1.4805555555555555e-05,
      "loss": 0.002,
      "step": 63350
    },
    {
      "epoch": 1.408,
      "grad_norm": 0.18515554070472717,
      "learning_rate": 1.48e-05,
      "loss": 0.0019,
      "step": 63360
    },
    {
      "epoch": 1.4082222222222223,
      "grad_norm": 0.22898505628108978,
      "learning_rate": 1.4794444444444444e-05,
      "loss": 0.0028,
      "step": 63370
    },
    {
      "epoch": 1.4084444444444444,
      "grad_norm": 0.2878563106060028,
      "learning_rate": 1.4788888888888888e-05,
      "loss": 0.0019,
      "step": 63380
    },
    {
      "epoch": 1.4086666666666667,
      "grad_norm": 0.10568132251501083,
      "learning_rate": 1.4783333333333335e-05,
      "loss": 0.0019,
      "step": 63390
    },
    {
      "epoch": 1.4088888888888889,
      "grad_norm": 0.3237442076206207,
      "learning_rate": 1.477777777777778e-05,
      "loss": 0.0021,
      "step": 63400
    },
    {
      "epoch": 1.4091111111111112,
      "grad_norm": 0.07137800753116608,
      "learning_rate": 1.4772222222222223e-05,
      "loss": 0.002,
      "step": 63410
    },
    {
      "epoch": 1.4093333333333333,
      "grad_norm": 0.3263418972492218,
      "learning_rate": 1.4766666666666667e-05,
      "loss": 0.0025,
      "step": 63420
    },
    {
      "epoch": 1.4095555555555555,
      "grad_norm": 0.1916256546974182,
      "learning_rate": 1.4761111111111112e-05,
      "loss": 0.0027,
      "step": 63430
    },
    {
      "epoch": 1.4097777777777778,
      "grad_norm": 0.11390527337789536,
      "learning_rate": 1.4755555555555556e-05,
      "loss": 0.0023,
      "step": 63440
    },
    {
      "epoch": 1.41,
      "grad_norm": 0.30712759494781494,
      "learning_rate": 1.475e-05,
      "loss": 0.0019,
      "step": 63450
    },
    {
      "epoch": 1.4102222222222223,
      "grad_norm": 0.23523543775081635,
      "learning_rate": 1.4744444444444445e-05,
      "loss": 0.002,
      "step": 63460
    },
    {
      "epoch": 1.4104444444444444,
      "grad_norm": 0.08231572061777115,
      "learning_rate": 1.4738888888888892e-05,
      "loss": 0.0025,
      "step": 63470
    },
    {
      "epoch": 1.4106666666666667,
      "grad_norm": 0.3163858950138092,
      "learning_rate": 1.4733333333333335e-05,
      "loss": 0.0016,
      "step": 63480
    },
    {
      "epoch": 1.4108888888888889,
      "grad_norm": 0.16015823185443878,
      "learning_rate": 1.4727777777777779e-05,
      "loss": 0.0021,
      "step": 63490
    },
    {
      "epoch": 1.411111111111111,
      "grad_norm": 0.2069273740053177,
      "learning_rate": 1.4722222222222224e-05,
      "loss": 0.0037,
      "step": 63500
    },
    {
      "epoch": 1.4113333333333333,
      "grad_norm": 0.25155648589134216,
      "learning_rate": 1.4716666666666668e-05,
      "loss": 0.0016,
      "step": 63510
    },
    {
      "epoch": 1.4115555555555557,
      "grad_norm": 0.12375238537788391,
      "learning_rate": 1.4711111111111111e-05,
      "loss": 0.0026,
      "step": 63520
    },
    {
      "epoch": 1.4117777777777778,
      "grad_norm": 0.26073983311653137,
      "learning_rate": 1.4705555555555556e-05,
      "loss": 0.002,
      "step": 63530
    },
    {
      "epoch": 1.412,
      "grad_norm": 0.1317577213048935,
      "learning_rate": 1.47e-05,
      "loss": 0.0018,
      "step": 63540
    },
    {
      "epoch": 1.4122222222222223,
      "grad_norm": 0.1387830674648285,
      "learning_rate": 1.4694444444444443e-05,
      "loss": 0.003,
      "step": 63550
    },
    {
      "epoch": 1.4124444444444444,
      "grad_norm": 0.12353716045618057,
      "learning_rate": 1.468888888888889e-05,
      "loss": 0.0028,
      "step": 63560
    },
    {
      "epoch": 1.4126666666666667,
      "grad_norm": 0.7310550808906555,
      "learning_rate": 1.4683333333333336e-05,
      "loss": 0.0018,
      "step": 63570
    },
    {
      "epoch": 1.4128888888888889,
      "grad_norm": 0.31188175082206726,
      "learning_rate": 1.467777777777778e-05,
      "loss": 0.0018,
      "step": 63580
    },
    {
      "epoch": 1.4131111111111112,
      "grad_norm": 0.13022953271865845,
      "learning_rate": 1.4672222222222223e-05,
      "loss": 0.0025,
      "step": 63590
    },
    {
      "epoch": 1.4133333333333333,
      "grad_norm": 0.4541892409324646,
      "learning_rate": 1.4666666666666668e-05,
      "loss": 0.0022,
      "step": 63600
    },
    {
      "epoch": 1.4135555555555555,
      "grad_norm": 0.28232669830322266,
      "learning_rate": 1.4661111111111112e-05,
      "loss": 0.003,
      "step": 63610
    },
    {
      "epoch": 1.4137777777777778,
      "grad_norm": 0.35365864634513855,
      "learning_rate": 1.4655555555555555e-05,
      "loss": 0.0021,
      "step": 63620
    },
    {
      "epoch": 1.414,
      "grad_norm": 0.11288955807685852,
      "learning_rate": 1.465e-05,
      "loss": 0.002,
      "step": 63630
    },
    {
      "epoch": 1.4142222222222223,
      "grad_norm": 0.16032326221466064,
      "learning_rate": 1.4644444444444444e-05,
      "loss": 0.0022,
      "step": 63640
    },
    {
      "epoch": 1.4144444444444444,
      "grad_norm": 0.2039375901222229,
      "learning_rate": 1.463888888888889e-05,
      "loss": 0.0018,
      "step": 63650
    },
    {
      "epoch": 1.4146666666666667,
      "grad_norm": 0.38261643052101135,
      "learning_rate": 1.4633333333333334e-05,
      "loss": 0.0031,
      "step": 63660
    },
    {
      "epoch": 1.4148888888888889,
      "grad_norm": 0.538506805896759,
      "learning_rate": 1.462777777777778e-05,
      "loss": 0.0017,
      "step": 63670
    },
    {
      "epoch": 1.415111111111111,
      "grad_norm": 0.2048504501581192,
      "learning_rate": 1.4622222222222223e-05,
      "loss": 0.003,
      "step": 63680
    },
    {
      "epoch": 1.4153333333333333,
      "grad_norm": 0.29026204347610474,
      "learning_rate": 1.4616666666666667e-05,
      "loss": 0.0018,
      "step": 63690
    },
    {
      "epoch": 1.4155555555555557,
      "grad_norm": 0.1615132838487625,
      "learning_rate": 1.4611111111111112e-05,
      "loss": 0.003,
      "step": 63700
    },
    {
      "epoch": 1.4157777777777778,
      "grad_norm": 0.22942441701889038,
      "learning_rate": 1.4605555555555556e-05,
      "loss": 0.0027,
      "step": 63710
    },
    {
      "epoch": 1.416,
      "grad_norm": 0.18378162384033203,
      "learning_rate": 1.4599999999999999e-05,
      "loss": 0.0016,
      "step": 63720
    },
    {
      "epoch": 1.4162222222222223,
      "grad_norm": 0.16649006307125092,
      "learning_rate": 1.4594444444444444e-05,
      "loss": 0.0027,
      "step": 63730
    },
    {
      "epoch": 1.4164444444444444,
      "grad_norm": 0.526302695274353,
      "learning_rate": 1.4588888888888891e-05,
      "loss": 0.0027,
      "step": 63740
    },
    {
      "epoch": 1.4166666666666667,
      "grad_norm": 0.2500671148300171,
      "learning_rate": 1.4583333333333335e-05,
      "loss": 0.0019,
      "step": 63750
    },
    {
      "epoch": 1.4168888888888889,
      "grad_norm": 0.18723668158054352,
      "learning_rate": 1.4577777777777778e-05,
      "loss": 0.0017,
      "step": 63760
    },
    {
      "epoch": 1.4171111111111112,
      "grad_norm": 0.5199235677719116,
      "learning_rate": 1.4572222222222224e-05,
      "loss": 0.0024,
      "step": 63770
    },
    {
      "epoch": 1.4173333333333333,
      "grad_norm": 0.2675745189189911,
      "learning_rate": 1.4566666666666667e-05,
      "loss": 0.0029,
      "step": 63780
    },
    {
      "epoch": 1.4175555555555555,
      "grad_norm": 0.245878666639328,
      "learning_rate": 1.456111111111111e-05,
      "loss": 0.0028,
      "step": 63790
    },
    {
      "epoch": 1.4177777777777778,
      "grad_norm": 0.09130208939313889,
      "learning_rate": 1.4555555555555556e-05,
      "loss": 0.0021,
      "step": 63800
    },
    {
      "epoch": 1.418,
      "grad_norm": 0.2125401496887207,
      "learning_rate": 1.455e-05,
      "loss": 0.0026,
      "step": 63810
    },
    {
      "epoch": 1.4182222222222223,
      "grad_norm": 0.06656448543071747,
      "learning_rate": 1.4544444444444443e-05,
      "loss": 0.0027,
      "step": 63820
    },
    {
      "epoch": 1.4184444444444444,
      "grad_norm": 0.29831692576408386,
      "learning_rate": 1.453888888888889e-05,
      "loss": 0.0019,
      "step": 63830
    },
    {
      "epoch": 1.4186666666666667,
      "grad_norm": 0.06828844547271729,
      "learning_rate": 1.4533333333333335e-05,
      "loss": 0.0019,
      "step": 63840
    },
    {
      "epoch": 1.4188888888888889,
      "grad_norm": 0.12373314797878265,
      "learning_rate": 1.4527777777777779e-05,
      "loss": 0.002,
      "step": 63850
    },
    {
      "epoch": 1.419111111111111,
      "grad_norm": 0.5151364803314209,
      "learning_rate": 1.4522222222222222e-05,
      "loss": 0.0027,
      "step": 63860
    },
    {
      "epoch": 1.4193333333333333,
      "grad_norm": 0.08301462978124619,
      "learning_rate": 1.4516666666666668e-05,
      "loss": 0.0018,
      "step": 63870
    },
    {
      "epoch": 1.4195555555555557,
      "grad_norm": 0.20512545108795166,
      "learning_rate": 1.4511111111111111e-05,
      "loss": 0.0029,
      "step": 63880
    },
    {
      "epoch": 1.4197777777777778,
      "grad_norm": 0.4740155339241028,
      "learning_rate": 1.4505555555555555e-05,
      "loss": 0.0025,
      "step": 63890
    },
    {
      "epoch": 1.42,
      "grad_norm": 0.18824999034404755,
      "learning_rate": 1.45e-05,
      "loss": 0.0028,
      "step": 63900
    },
    {
      "epoch": 1.4202222222222223,
      "grad_norm": 0.17749562859535217,
      "learning_rate": 1.4494444444444444e-05,
      "loss": 0.0025,
      "step": 63910
    },
    {
      "epoch": 1.4204444444444444,
      "grad_norm": 0.3147161900997162,
      "learning_rate": 1.448888888888889e-05,
      "loss": 0.0019,
      "step": 63920
    },
    {
      "epoch": 1.4206666666666667,
      "grad_norm": 0.13501140475273132,
      "learning_rate": 1.4483333333333334e-05,
      "loss": 0.0017,
      "step": 63930
    },
    {
      "epoch": 1.4208888888888889,
      "grad_norm": 0.49104395508766174,
      "learning_rate": 1.447777777777778e-05,
      "loss": 0.0031,
      "step": 63940
    },
    {
      "epoch": 1.4211111111111112,
      "grad_norm": 0.49001675844192505,
      "learning_rate": 1.4472222222222223e-05,
      "loss": 0.0025,
      "step": 63950
    },
    {
      "epoch": 1.4213333333333333,
      "grad_norm": 0.3498510718345642,
      "learning_rate": 1.4466666666666667e-05,
      "loss": 0.002,
      "step": 63960
    },
    {
      "epoch": 1.4215555555555555,
      "grad_norm": 0.18120935559272766,
      "learning_rate": 1.4461111111111112e-05,
      "loss": 0.0035,
      "step": 63970
    },
    {
      "epoch": 1.4217777777777778,
      "grad_norm": 0.6091212034225464,
      "learning_rate": 1.4455555555555555e-05,
      "loss": 0.0022,
      "step": 63980
    },
    {
      "epoch": 1.422,
      "grad_norm": 0.5078317523002625,
      "learning_rate": 1.4449999999999999e-05,
      "loss": 0.0018,
      "step": 63990
    },
    {
      "epoch": 1.4222222222222223,
      "grad_norm": 0.3835833668708801,
      "learning_rate": 1.4444444444444444e-05,
      "loss": 0.0018,
      "step": 64000
    },
    {
      "epoch": 1.4224444444444444,
      "grad_norm": 0.3077842891216278,
      "learning_rate": 1.4438888888888891e-05,
      "loss": 0.0019,
      "step": 64010
    },
    {
      "epoch": 1.4226666666666667,
      "grad_norm": 0.3525744378566742,
      "learning_rate": 1.4433333333333335e-05,
      "loss": 0.0018,
      "step": 64020
    },
    {
      "epoch": 1.4228888888888889,
      "grad_norm": 0.21176400780677795,
      "learning_rate": 1.4427777777777778e-05,
      "loss": 0.0018,
      "step": 64030
    },
    {
      "epoch": 1.423111111111111,
      "grad_norm": 0.30945590138435364,
      "learning_rate": 1.4422222222222223e-05,
      "loss": 0.002,
      "step": 64040
    },
    {
      "epoch": 1.4233333333333333,
      "grad_norm": 0.19398127496242523,
      "learning_rate": 1.4416666666666667e-05,
      "loss": 0.0021,
      "step": 64050
    },
    {
      "epoch": 1.4235555555555557,
      "grad_norm": 0.2854396104812622,
      "learning_rate": 1.441111111111111e-05,
      "loss": 0.0021,
      "step": 64060
    },
    {
      "epoch": 1.4237777777777778,
      "grad_norm": 0.3829975724220276,
      "learning_rate": 1.4405555555555556e-05,
      "loss": 0.0019,
      "step": 64070
    },
    {
      "epoch": 1.424,
      "grad_norm": 0.18567760288715363,
      "learning_rate": 1.44e-05,
      "loss": 0.0021,
      "step": 64080
    },
    {
      "epoch": 1.4242222222222223,
      "grad_norm": 0.5766708254814148,
      "learning_rate": 1.4394444444444446e-05,
      "loss": 0.002,
      "step": 64090
    },
    {
      "epoch": 1.4244444444444444,
      "grad_norm": 0.3009471297264099,
      "learning_rate": 1.438888888888889e-05,
      "loss": 0.0019,
      "step": 64100
    },
    {
      "epoch": 1.4246666666666667,
      "grad_norm": 0.2854726016521454,
      "learning_rate": 1.4383333333333335e-05,
      "loss": 0.0033,
      "step": 64110
    },
    {
      "epoch": 1.4248888888888889,
      "grad_norm": 0.07887759059667587,
      "learning_rate": 1.4377777777777779e-05,
      "loss": 0.002,
      "step": 64120
    },
    {
      "epoch": 1.4251111111111112,
      "grad_norm": 0.11101015657186508,
      "learning_rate": 1.4372222222222222e-05,
      "loss": 0.002,
      "step": 64130
    },
    {
      "epoch": 1.4253333333333333,
      "grad_norm": 0.5330176949501038,
      "learning_rate": 1.4366666666666667e-05,
      "loss": 0.0022,
      "step": 64140
    },
    {
      "epoch": 1.4255555555555555,
      "grad_norm": 0.31240811944007874,
      "learning_rate": 1.4361111111111111e-05,
      "loss": 0.0018,
      "step": 64150
    },
    {
      "epoch": 1.4257777777777778,
      "grad_norm": 0.06236334145069122,
      "learning_rate": 1.4355555555555556e-05,
      "loss": 0.002,
      "step": 64160
    },
    {
      "epoch": 1.426,
      "grad_norm": 0.44901013374328613,
      "learning_rate": 1.435e-05,
      "loss": 0.0036,
      "step": 64170
    },
    {
      "epoch": 1.4262222222222223,
      "grad_norm": 0.5004202127456665,
      "learning_rate": 1.4344444444444447e-05,
      "loss": 0.0026,
      "step": 64180
    },
    {
      "epoch": 1.4264444444444444,
      "grad_norm": 0.23338180780410767,
      "learning_rate": 1.433888888888889e-05,
      "loss": 0.0027,
      "step": 64190
    },
    {
      "epoch": 1.4266666666666667,
      "grad_norm": 0.3761533796787262,
      "learning_rate": 1.4333333333333334e-05,
      "loss": 0.0027,
      "step": 64200
    },
    {
      "epoch": 1.4268888888888889,
      "grad_norm": 0.13640689849853516,
      "learning_rate": 1.4327777777777779e-05,
      "loss": 0.0021,
      "step": 64210
    },
    {
      "epoch": 1.427111111111111,
      "grad_norm": 0.35144978761672974,
      "learning_rate": 1.4322222222222223e-05,
      "loss": 0.0019,
      "step": 64220
    },
    {
      "epoch": 1.4273333333333333,
      "grad_norm": 0.5098093748092651,
      "learning_rate": 1.4316666666666668e-05,
      "loss": 0.0021,
      "step": 64230
    },
    {
      "epoch": 1.4275555555555557,
      "grad_norm": 0.24664847552776337,
      "learning_rate": 1.4311111111111111e-05,
      "loss": 0.002,
      "step": 64240
    },
    {
      "epoch": 1.4277777777777778,
      "grad_norm": 0.19415129721164703,
      "learning_rate": 1.4305555555555555e-05,
      "loss": 0.0019,
      "step": 64250
    },
    {
      "epoch": 1.428,
      "grad_norm": 0.2591094672679901,
      "learning_rate": 1.43e-05,
      "loss": 0.0031,
      "step": 64260
    },
    {
      "epoch": 1.4282222222222223,
      "grad_norm": 0.10026226192712784,
      "learning_rate": 1.4294444444444447e-05,
      "loss": 0.0021,
      "step": 64270
    },
    {
      "epoch": 1.4284444444444444,
      "grad_norm": 0.07331511378288269,
      "learning_rate": 1.428888888888889e-05,
      "loss": 0.0027,
      "step": 64280
    },
    {
      "epoch": 1.4286666666666665,
      "grad_norm": 0.15337681770324707,
      "learning_rate": 1.4283333333333334e-05,
      "loss": 0.0018,
      "step": 64290
    },
    {
      "epoch": 1.4288888888888889,
      "grad_norm": 0.3824012577533722,
      "learning_rate": 1.427777777777778e-05,
      "loss": 0.0019,
      "step": 64300
    },
    {
      "epoch": 1.4291111111111112,
      "grad_norm": 0.394710898399353,
      "learning_rate": 1.4272222222222223e-05,
      "loss": 0.0017,
      "step": 64310
    },
    {
      "epoch": 1.4293333333333333,
      "grad_norm": 0.5663988590240479,
      "learning_rate": 1.4266666666666667e-05,
      "loss": 0.0019,
      "step": 64320
    },
    {
      "epoch": 1.4295555555555555,
      "grad_norm": 0.1625937819480896,
      "learning_rate": 1.4261111111111112e-05,
      "loss": 0.0019,
      "step": 64330
    },
    {
      "epoch": 1.4297777777777778,
      "grad_norm": 0.4546359181404114,
      "learning_rate": 1.4255555555555556e-05,
      "loss": 0.0028,
      "step": 64340
    },
    {
      "epoch": 1.43,
      "grad_norm": 0.2105308175086975,
      "learning_rate": 1.4249999999999999e-05,
      "loss": 0.002,
      "step": 64350
    },
    {
      "epoch": 1.4302222222222223,
      "grad_norm": 0.10679896920919418,
      "learning_rate": 1.4244444444444446e-05,
      "loss": 0.0023,
      "step": 64360
    },
    {
      "epoch": 1.4304444444444444,
      "grad_norm": 0.1272294968366623,
      "learning_rate": 1.4238888888888891e-05,
      "loss": 0.0016,
      "step": 64370
    },
    {
      "epoch": 1.4306666666666668,
      "grad_norm": 0.0946352630853653,
      "learning_rate": 1.4233333333333335e-05,
      "loss": 0.0017,
      "step": 64380
    },
    {
      "epoch": 1.4308888888888889,
      "grad_norm": 0.40214598178863525,
      "learning_rate": 1.4227777777777778e-05,
      "loss": 0.0018,
      "step": 64390
    },
    {
      "epoch": 1.431111111111111,
      "grad_norm": 0.41827237606048584,
      "learning_rate": 1.4222222222222224e-05,
      "loss": 0.0023,
      "step": 64400
    },
    {
      "epoch": 1.4313333333333333,
      "grad_norm": 0.3163357973098755,
      "learning_rate": 1.4216666666666667e-05,
      "loss": 0.0022,
      "step": 64410
    },
    {
      "epoch": 1.4315555555555557,
      "grad_norm": 0.16748258471488953,
      "learning_rate": 1.421111111111111e-05,
      "loss": 0.0033,
      "step": 64420
    },
    {
      "epoch": 1.4317777777777778,
      "grad_norm": 0.6574654579162598,
      "learning_rate": 1.4205555555555556e-05,
      "loss": 0.0021,
      "step": 64430
    },
    {
      "epoch": 1.432,
      "grad_norm": 0.3467537462711334,
      "learning_rate": 1.42e-05,
      "loss": 0.0016,
      "step": 64440
    },
    {
      "epoch": 1.4322222222222223,
      "grad_norm": 0.19766008853912354,
      "learning_rate": 1.4194444444444447e-05,
      "loss": 0.0018,
      "step": 64450
    },
    {
      "epoch": 1.4324444444444444,
      "grad_norm": 0.07818777859210968,
      "learning_rate": 1.418888888888889e-05,
      "loss": 0.0016,
      "step": 64460
    },
    {
      "epoch": 1.4326666666666665,
      "grad_norm": 0.2655726671218872,
      "learning_rate": 1.4183333333333335e-05,
      "loss": 0.0017,
      "step": 64470
    },
    {
      "epoch": 1.4328888888888889,
      "grad_norm": 0.19300585985183716,
      "learning_rate": 1.4177777777777779e-05,
      "loss": 0.0024,
      "step": 64480
    },
    {
      "epoch": 1.4331111111111112,
      "grad_norm": 0.7046743035316467,
      "learning_rate": 1.4172222222222222e-05,
      "loss": 0.002,
      "step": 64490
    },
    {
      "epoch": 1.4333333333333333,
      "grad_norm": 0.13400408625602722,
      "learning_rate": 1.4166666666666668e-05,
      "loss": 0.0022,
      "step": 64500
    },
    {
      "epoch": 1.4335555555555555,
      "grad_norm": 0.29503050446510315,
      "learning_rate": 1.4161111111111111e-05,
      "loss": 0.002,
      "step": 64510
    },
    {
      "epoch": 1.4337777777777778,
      "grad_norm": 0.0697430968284607,
      "learning_rate": 1.4155555555555555e-05,
      "loss": 0.0023,
      "step": 64520
    },
    {
      "epoch": 1.434,
      "grad_norm": 0.28858882188796997,
      "learning_rate": 1.415e-05,
      "loss": 0.0021,
      "step": 64530
    },
    {
      "epoch": 1.4342222222222223,
      "grad_norm": 0.07580079883337021,
      "learning_rate": 1.4144444444444447e-05,
      "loss": 0.0025,
      "step": 64540
    },
    {
      "epoch": 1.4344444444444444,
      "grad_norm": 0.23336513340473175,
      "learning_rate": 1.413888888888889e-05,
      "loss": 0.0021,
      "step": 64550
    },
    {
      "epoch": 1.4346666666666668,
      "grad_norm": 0.24464941024780273,
      "learning_rate": 1.4133333333333334e-05,
      "loss": 0.0019,
      "step": 64560
    },
    {
      "epoch": 1.4348888888888889,
      "grad_norm": 0.11767578125,
      "learning_rate": 1.412777777777778e-05,
      "loss": 0.0026,
      "step": 64570
    },
    {
      "epoch": 1.435111111111111,
      "grad_norm": 0.23929622769355774,
      "learning_rate": 1.4122222222222223e-05,
      "loss": 0.0024,
      "step": 64580
    },
    {
      "epoch": 1.4353333333333333,
      "grad_norm": 0.28542202711105347,
      "learning_rate": 1.4116666666666666e-05,
      "loss": 0.0022,
      "step": 64590
    },
    {
      "epoch": 1.4355555555555555,
      "grad_norm": 0.5716192722320557,
      "learning_rate": 1.4111111111111112e-05,
      "loss": 0.0018,
      "step": 64600
    },
    {
      "epoch": 1.4357777777777778,
      "grad_norm": 0.21432025730609894,
      "learning_rate": 1.4105555555555555e-05,
      "loss": 0.0026,
      "step": 64610
    },
    {
      "epoch": 1.436,
      "grad_norm": 0.1772967129945755,
      "learning_rate": 1.4099999999999999e-05,
      "loss": 0.0023,
      "step": 64620
    },
    {
      "epoch": 1.4362222222222223,
      "grad_norm": 0.13886041939258575,
      "learning_rate": 1.4094444444444446e-05,
      "loss": 0.002,
      "step": 64630
    },
    {
      "epoch": 1.4364444444444444,
      "grad_norm": 0.11197619140148163,
      "learning_rate": 1.4088888888888891e-05,
      "loss": 0.0017,
      "step": 64640
    },
    {
      "epoch": 1.4366666666666665,
      "grad_norm": 0.39950695633888245,
      "learning_rate": 1.4083333333333335e-05,
      "loss": 0.0017,
      "step": 64650
    },
    {
      "epoch": 1.4368888888888889,
      "grad_norm": 0.0914633572101593,
      "learning_rate": 1.4077777777777778e-05,
      "loss": 0.0025,
      "step": 64660
    },
    {
      "epoch": 1.4371111111111112,
      "grad_norm": 0.3371344804763794,
      "learning_rate": 1.4072222222222223e-05,
      "loss": 0.0025,
      "step": 64670
    },
    {
      "epoch": 1.4373333333333334,
      "grad_norm": 0.30093348026275635,
      "learning_rate": 1.4066666666666667e-05,
      "loss": 0.002,
      "step": 64680
    },
    {
      "epoch": 1.4375555555555555,
      "grad_norm": 0.4103267192840576,
      "learning_rate": 1.406111111111111e-05,
      "loss": 0.0017,
      "step": 64690
    },
    {
      "epoch": 1.4377777777777778,
      "grad_norm": 0.3802248239517212,
      "learning_rate": 1.4055555555555556e-05,
      "loss": 0.0023,
      "step": 64700
    },
    {
      "epoch": 1.438,
      "grad_norm": 0.24592414498329163,
      "learning_rate": 1.4050000000000003e-05,
      "loss": 0.0017,
      "step": 64710
    },
    {
      "epoch": 1.4382222222222223,
      "grad_norm": 0.19117331504821777,
      "learning_rate": 1.4044444444444446e-05,
      "loss": 0.0025,
      "step": 64720
    },
    {
      "epoch": 1.4384444444444444,
      "grad_norm": 0.12039001286029816,
      "learning_rate": 1.403888888888889e-05,
      "loss": 0.002,
      "step": 64730
    },
    {
      "epoch": 1.4386666666666668,
      "grad_norm": 0.2791270613670349,
      "learning_rate": 1.4033333333333335e-05,
      "loss": 0.0028,
      "step": 64740
    },
    {
      "epoch": 1.4388888888888889,
      "grad_norm": 0.07192007452249527,
      "learning_rate": 1.4027777777777779e-05,
      "loss": 0.0034,
      "step": 64750
    },
    {
      "epoch": 1.439111111111111,
      "grad_norm": 0.11664899438619614,
      "learning_rate": 1.4022222222222222e-05,
      "loss": 0.0019,
      "step": 64760
    },
    {
      "epoch": 1.4393333333333334,
      "grad_norm": 0.20065240561962128,
      "learning_rate": 1.4016666666666667e-05,
      "loss": 0.0022,
      "step": 64770
    },
    {
      "epoch": 1.4395555555555555,
      "grad_norm": 0.06637512147426605,
      "learning_rate": 1.4011111111111111e-05,
      "loss": 0.0018,
      "step": 64780
    },
    {
      "epoch": 1.4397777777777778,
      "grad_norm": 0.068520687520504,
      "learning_rate": 1.4005555555555555e-05,
      "loss": 0.0017,
      "step": 64790
    },
    {
      "epoch": 1.44,
      "grad_norm": 0.07936953008174896,
      "learning_rate": 1.4000000000000001e-05,
      "loss": 0.0028,
      "step": 64800
    },
    {
      "epoch": 1.4402222222222223,
      "grad_norm": 0.2635219991207123,
      "learning_rate": 1.3994444444444447e-05,
      "loss": 0.0018,
      "step": 64810
    },
    {
      "epoch": 1.4404444444444444,
      "grad_norm": 0.17965707182884216,
      "learning_rate": 1.398888888888889e-05,
      "loss": 0.0028,
      "step": 64820
    },
    {
      "epoch": 1.4406666666666665,
      "grad_norm": 0.11924195289611816,
      "learning_rate": 1.3983333333333334e-05,
      "loss": 0.0025,
      "step": 64830
    },
    {
      "epoch": 1.4408888888888889,
      "grad_norm": 0.1381455361843109,
      "learning_rate": 1.3977777777777779e-05,
      "loss": 0.0018,
      "step": 64840
    },
    {
      "epoch": 1.4411111111111112,
      "grad_norm": 0.10012245923280716,
      "learning_rate": 1.3972222222222223e-05,
      "loss": 0.0021,
      "step": 64850
    },
    {
      "epoch": 1.4413333333333334,
      "grad_norm": 0.24240922927856445,
      "learning_rate": 1.3966666666666666e-05,
      "loss": 0.002,
      "step": 64860
    },
    {
      "epoch": 1.4415555555555555,
      "grad_norm": 0.06977387517690659,
      "learning_rate": 1.3961111111111111e-05,
      "loss": 0.0028,
      "step": 64870
    },
    {
      "epoch": 1.4417777777777778,
      "grad_norm": 0.11503861844539642,
      "learning_rate": 1.3955555555555555e-05,
      "loss": 0.0029,
      "step": 64880
    },
    {
      "epoch": 1.442,
      "grad_norm": 0.3702765703201294,
      "learning_rate": 1.3950000000000002e-05,
      "loss": 0.0018,
      "step": 64890
    },
    {
      "epoch": 1.4422222222222223,
      "grad_norm": 0.07012159377336502,
      "learning_rate": 1.3944444444444446e-05,
      "loss": 0.0019,
      "step": 64900
    },
    {
      "epoch": 1.4424444444444444,
      "grad_norm": 0.6308464407920837,
      "learning_rate": 1.393888888888889e-05,
      "loss": 0.0026,
      "step": 64910
    },
    {
      "epoch": 1.4426666666666668,
      "grad_norm": 0.2604418098926544,
      "learning_rate": 1.3933333333333334e-05,
      "loss": 0.0028,
      "step": 64920
    },
    {
      "epoch": 1.4428888888888889,
      "grad_norm": 0.3030109703540802,
      "learning_rate": 1.3927777777777778e-05,
      "loss": 0.002,
      "step": 64930
    },
    {
      "epoch": 1.443111111111111,
      "grad_norm": 0.5240787863731384,
      "learning_rate": 1.3922222222222223e-05,
      "loss": 0.0018,
      "step": 64940
    },
    {
      "epoch": 1.4433333333333334,
      "grad_norm": 0.06771252304315567,
      "learning_rate": 1.3916666666666667e-05,
      "loss": 0.0024,
      "step": 64950
    },
    {
      "epoch": 1.4435555555555555,
      "grad_norm": 0.25918105244636536,
      "learning_rate": 1.391111111111111e-05,
      "loss": 0.0019,
      "step": 64960
    },
    {
      "epoch": 1.4437777777777778,
      "grad_norm": 0.44136592745780945,
      "learning_rate": 1.3905555555555555e-05,
      "loss": 0.0019,
      "step": 64970
    },
    {
      "epoch": 1.444,
      "grad_norm": 0.09848932921886444,
      "learning_rate": 1.3900000000000002e-05,
      "loss": 0.0018,
      "step": 64980
    },
    {
      "epoch": 1.4442222222222223,
      "grad_norm": 0.5534730553627014,
      "learning_rate": 1.3894444444444446e-05,
      "loss": 0.0019,
      "step": 64990
    },
    {
      "epoch": 1.4444444444444444,
      "grad_norm": 0.30492639541625977,
      "learning_rate": 1.388888888888889e-05,
      "loss": 0.002,
      "step": 65000
    },
    {
      "epoch": 1.4446666666666665,
      "grad_norm": 0.4979631006717682,
      "learning_rate": 1.3883333333333335e-05,
      "loss": 0.002,
      "step": 65010
    },
    {
      "epoch": 1.444888888888889,
      "grad_norm": 0.5546164512634277,
      "learning_rate": 1.3877777777777778e-05,
      "loss": 0.0018,
      "step": 65020
    },
    {
      "epoch": 1.4451111111111112,
      "grad_norm": 0.08969558030366898,
      "learning_rate": 1.3872222222222222e-05,
      "loss": 0.0029,
      "step": 65030
    },
    {
      "epoch": 1.4453333333333334,
      "grad_norm": 0.3197837769985199,
      "learning_rate": 1.3866666666666667e-05,
      "loss": 0.0024,
      "step": 65040
    },
    {
      "epoch": 1.4455555555555555,
      "grad_norm": 0.46863889694213867,
      "learning_rate": 1.386111111111111e-05,
      "loss": 0.0018,
      "step": 65050
    },
    {
      "epoch": 1.4457777777777778,
      "grad_norm": 0.2218201607465744,
      "learning_rate": 1.3855555555555554e-05,
      "loss": 0.0017,
      "step": 65060
    },
    {
      "epoch": 1.446,
      "grad_norm": 0.2168666422367096,
      "learning_rate": 1.3850000000000001e-05,
      "loss": 0.0019,
      "step": 65070
    },
    {
      "epoch": 1.4462222222222223,
      "grad_norm": 0.2521636486053467,
      "learning_rate": 1.3844444444444446e-05,
      "loss": 0.0024,
      "step": 65080
    },
    {
      "epoch": 1.4464444444444444,
      "grad_norm": 0.13324004411697388,
      "learning_rate": 1.383888888888889e-05,
      "loss": 0.0026,
      "step": 65090
    },
    {
      "epoch": 1.4466666666666668,
      "grad_norm": 0.13005025684833527,
      "learning_rate": 1.3833333333333334e-05,
      "loss": 0.0028,
      "step": 65100
    },
    {
      "epoch": 1.446888888888889,
      "grad_norm": 0.34700456261634827,
      "learning_rate": 1.3827777777777779e-05,
      "loss": 0.0031,
      "step": 65110
    },
    {
      "epoch": 1.447111111111111,
      "grad_norm": 0.16268883645534515,
      "learning_rate": 1.3822222222222222e-05,
      "loss": 0.002,
      "step": 65120
    },
    {
      "epoch": 1.4473333333333334,
      "grad_norm": 0.12234095484018326,
      "learning_rate": 1.3816666666666666e-05,
      "loss": 0.0018,
      "step": 65130
    },
    {
      "epoch": 1.4475555555555555,
      "grad_norm": 0.510593593120575,
      "learning_rate": 1.3811111111111111e-05,
      "loss": 0.0026,
      "step": 65140
    },
    {
      "epoch": 1.4477777777777778,
      "grad_norm": 0.3669532537460327,
      "learning_rate": 1.3805555555555555e-05,
      "loss": 0.0027,
      "step": 65150
    },
    {
      "epoch": 1.448,
      "grad_norm": 0.5949073433876038,
      "learning_rate": 1.3800000000000002e-05,
      "loss": 0.002,
      "step": 65160
    },
    {
      "epoch": 1.4482222222222223,
      "grad_norm": 0.5381985902786255,
      "learning_rate": 1.3794444444444445e-05,
      "loss": 0.0027,
      "step": 65170
    },
    {
      "epoch": 1.4484444444444444,
      "grad_norm": 0.45885902643203735,
      "learning_rate": 1.378888888888889e-05,
      "loss": 0.002,
      "step": 65180
    },
    {
      "epoch": 1.4486666666666665,
      "grad_norm": 0.08762449771165848,
      "learning_rate": 1.3783333333333334e-05,
      "loss": 0.0019,
      "step": 65190
    },
    {
      "epoch": 1.448888888888889,
      "grad_norm": 0.17340442538261414,
      "learning_rate": 1.3777777777777778e-05,
      "loss": 0.0024,
      "step": 65200
    },
    {
      "epoch": 1.4491111111111112,
      "grad_norm": 0.6258456707000732,
      "learning_rate": 1.3772222222222223e-05,
      "loss": 0.0027,
      "step": 65210
    },
    {
      "epoch": 1.4493333333333334,
      "grad_norm": 0.09025087207555771,
      "learning_rate": 1.3766666666666666e-05,
      "loss": 0.0023,
      "step": 65220
    },
    {
      "epoch": 1.4495555555555555,
      "grad_norm": 0.0383325070142746,
      "learning_rate": 1.376111111111111e-05,
      "loss": 0.0024,
      "step": 65230
    },
    {
      "epoch": 1.4497777777777778,
      "grad_norm": 0.2726101279258728,
      "learning_rate": 1.3755555555555555e-05,
      "loss": 0.0019,
      "step": 65240
    },
    {
      "epoch": 1.45,
      "grad_norm": 0.1567511260509491,
      "learning_rate": 1.3750000000000002e-05,
      "loss": 0.0016,
      "step": 65250
    },
    {
      "epoch": 1.4502222222222223,
      "grad_norm": 0.34499526023864746,
      "learning_rate": 1.3744444444444446e-05,
      "loss": 0.0018,
      "step": 65260
    },
    {
      "epoch": 1.4504444444444444,
      "grad_norm": 0.3177183270454407,
      "learning_rate": 1.373888888888889e-05,
      "loss": 0.002,
      "step": 65270
    },
    {
      "epoch": 1.4506666666666668,
      "grad_norm": 0.07443481683731079,
      "learning_rate": 1.3733333333333335e-05,
      "loss": 0.002,
      "step": 65280
    },
    {
      "epoch": 1.450888888888889,
      "grad_norm": 0.22001774609088898,
      "learning_rate": 1.3727777777777778e-05,
      "loss": 0.0019,
      "step": 65290
    },
    {
      "epoch": 1.451111111111111,
      "grad_norm": 0.2707142233848572,
      "learning_rate": 1.3722222222222222e-05,
      "loss": 0.0019,
      "step": 65300
    },
    {
      "epoch": 1.4513333333333334,
      "grad_norm": 0.08229051530361176,
      "learning_rate": 1.3716666666666667e-05,
      "loss": 0.0019,
      "step": 65310
    },
    {
      "epoch": 1.4515555555555555,
      "grad_norm": 0.06678929924964905,
      "learning_rate": 1.371111111111111e-05,
      "loss": 0.0027,
      "step": 65320
    },
    {
      "epoch": 1.4517777777777778,
      "grad_norm": 0.06056695058941841,
      "learning_rate": 1.3705555555555557e-05,
      "loss": 0.0017,
      "step": 65330
    },
    {
      "epoch": 1.452,
      "grad_norm": 0.2439771145582199,
      "learning_rate": 1.3700000000000001e-05,
      "loss": 0.0019,
      "step": 65340
    },
    {
      "epoch": 1.4522222222222223,
      "grad_norm": 0.32382211089134216,
      "learning_rate": 1.3694444444444446e-05,
      "loss": 0.0028,
      "step": 65350
    },
    {
      "epoch": 1.4524444444444444,
      "grad_norm": 0.17603348195552826,
      "learning_rate": 1.368888888888889e-05,
      "loss": 0.0019,
      "step": 65360
    },
    {
      "epoch": 1.4526666666666666,
      "grad_norm": 0.24646194279193878,
      "learning_rate": 1.3683333333333333e-05,
      "loss": 0.0028,
      "step": 65370
    },
    {
      "epoch": 1.452888888888889,
      "grad_norm": 0.08693703263998032,
      "learning_rate": 1.3677777777777779e-05,
      "loss": 0.0026,
      "step": 65380
    },
    {
      "epoch": 1.4531111111111112,
      "grad_norm": 0.09959879517555237,
      "learning_rate": 1.3672222222222222e-05,
      "loss": 0.0029,
      "step": 65390
    },
    {
      "epoch": 1.4533333333333334,
      "grad_norm": 0.34250348806381226,
      "learning_rate": 1.3666666666666666e-05,
      "loss": 0.0026,
      "step": 65400
    },
    {
      "epoch": 1.4535555555555555,
      "grad_norm": 0.06218595802783966,
      "learning_rate": 1.3661111111111111e-05,
      "loss": 0.0018,
      "step": 65410
    },
    {
      "epoch": 1.4537777777777778,
      "grad_norm": 0.12301163375377655,
      "learning_rate": 1.3655555555555558e-05,
      "loss": 0.0017,
      "step": 65420
    },
    {
      "epoch": 1.454,
      "grad_norm": 0.22662955522537231,
      "learning_rate": 1.3650000000000001e-05,
      "loss": 0.0017,
      "step": 65430
    },
    {
      "epoch": 1.4542222222222223,
      "grad_norm": 0.24804136157035828,
      "learning_rate": 1.3644444444444445e-05,
      "loss": 0.0025,
      "step": 65440
    },
    {
      "epoch": 1.4544444444444444,
      "grad_norm": 0.20346076786518097,
      "learning_rate": 1.363888888888889e-05,
      "loss": 0.0018,
      "step": 65450
    },
    {
      "epoch": 1.4546666666666668,
      "grad_norm": 0.4770186245441437,
      "learning_rate": 1.3633333333333334e-05,
      "loss": 0.0026,
      "step": 65460
    },
    {
      "epoch": 1.454888888888889,
      "grad_norm": 0.42479372024536133,
      "learning_rate": 1.3627777777777777e-05,
      "loss": 0.0016,
      "step": 65470
    },
    {
      "epoch": 1.455111111111111,
      "grad_norm": 0.07762914896011353,
      "learning_rate": 1.3622222222222223e-05,
      "loss": 0.0018,
      "step": 65480
    },
    {
      "epoch": 1.4553333333333334,
      "grad_norm": 0.31686291098594666,
      "learning_rate": 1.3616666666666666e-05,
      "loss": 0.0018,
      "step": 65490
    },
    {
      "epoch": 1.4555555555555555,
      "grad_norm": 0.6841970086097717,
      "learning_rate": 1.3611111111111111e-05,
      "loss": 0.002,
      "step": 65500
    },
    {
      "epoch": 1.4557777777777778,
      "grad_norm": 0.1292405128479004,
      "learning_rate": 1.3605555555555557e-05,
      "loss": 0.0021,
      "step": 65510
    },
    {
      "epoch": 1.456,
      "grad_norm": 0.2678772211074829,
      "learning_rate": 1.3600000000000002e-05,
      "loss": 0.0032,
      "step": 65520
    },
    {
      "epoch": 1.4562222222222223,
      "grad_norm": 0.41322702169418335,
      "learning_rate": 1.3594444444444445e-05,
      "loss": 0.0019,
      "step": 65530
    },
    {
      "epoch": 1.4564444444444444,
      "grad_norm": 0.41261589527130127,
      "learning_rate": 1.358888888888889e-05,
      "loss": 0.0022,
      "step": 65540
    },
    {
      "epoch": 1.4566666666666666,
      "grad_norm": 0.7091668844223022,
      "learning_rate": 1.3583333333333334e-05,
      "loss": 0.0022,
      "step": 65550
    },
    {
      "epoch": 1.456888888888889,
      "grad_norm": 0.13994541764259338,
      "learning_rate": 1.3577777777777778e-05,
      "loss": 0.0027,
      "step": 65560
    },
    {
      "epoch": 1.4571111111111112,
      "grad_norm": 0.2228560745716095,
      "learning_rate": 1.3572222222222223e-05,
      "loss": 0.0019,
      "step": 65570
    },
    {
      "epoch": 1.4573333333333334,
      "grad_norm": 0.3053199052810669,
      "learning_rate": 1.3566666666666667e-05,
      "loss": 0.0025,
      "step": 65580
    },
    {
      "epoch": 1.4575555555555555,
      "grad_norm": 0.05289642885327339,
      "learning_rate": 1.356111111111111e-05,
      "loss": 0.0019,
      "step": 65590
    },
    {
      "epoch": 1.4577777777777778,
      "grad_norm": 0.13797348737716675,
      "learning_rate": 1.3555555555555557e-05,
      "loss": 0.0026,
      "step": 65600
    },
    {
      "epoch": 1.458,
      "grad_norm": 0.1804967224597931,
      "learning_rate": 1.3550000000000002e-05,
      "loss": 0.002,
      "step": 65610
    },
    {
      "epoch": 1.458222222222222,
      "grad_norm": 0.0950503796339035,
      "learning_rate": 1.3544444444444446e-05,
      "loss": 0.0037,
      "step": 65620
    },
    {
      "epoch": 1.4584444444444444,
      "grad_norm": 0.12842418253421783,
      "learning_rate": 1.353888888888889e-05,
      "loss": 0.0024,
      "step": 65630
    },
    {
      "epoch": 1.4586666666666668,
      "grad_norm": 0.3135373890399933,
      "learning_rate": 1.3533333333333335e-05,
      "loss": 0.0027,
      "step": 65640
    },
    {
      "epoch": 1.458888888888889,
      "grad_norm": 0.4400773048400879,
      "learning_rate": 1.3527777777777778e-05,
      "loss": 0.0029,
      "step": 65650
    },
    {
      "epoch": 1.459111111111111,
      "grad_norm": 0.43446049094200134,
      "learning_rate": 1.3522222222222222e-05,
      "loss": 0.0018,
      "step": 65660
    },
    {
      "epoch": 1.4593333333333334,
      "grad_norm": 0.14108942449092865,
      "learning_rate": 1.3516666666666667e-05,
      "loss": 0.0028,
      "step": 65670
    },
    {
      "epoch": 1.4595555555555555,
      "grad_norm": 0.3177853226661682,
      "learning_rate": 1.351111111111111e-05,
      "loss": 0.002,
      "step": 65680
    },
    {
      "epoch": 1.4597777777777778,
      "grad_norm": 0.36912044882774353,
      "learning_rate": 1.3505555555555558e-05,
      "loss": 0.0033,
      "step": 65690
    },
    {
      "epoch": 1.46,
      "grad_norm": 0.12455550581216812,
      "learning_rate": 1.3500000000000001e-05,
      "loss": 0.0031,
      "step": 65700
    },
    {
      "epoch": 1.4602222222222223,
      "grad_norm": 0.21797725558280945,
      "learning_rate": 1.3494444444444446e-05,
      "loss": 0.0019,
      "step": 65710
    },
    {
      "epoch": 1.4604444444444444,
      "grad_norm": 0.11137706786394119,
      "learning_rate": 1.348888888888889e-05,
      "loss": 0.002,
      "step": 65720
    },
    {
      "epoch": 1.4606666666666666,
      "grad_norm": 0.20344477891921997,
      "learning_rate": 1.3483333333333334e-05,
      "loss": 0.0017,
      "step": 65730
    },
    {
      "epoch": 1.460888888888889,
      "grad_norm": 0.7795342206954956,
      "learning_rate": 1.3477777777777779e-05,
      "loss": 0.0042,
      "step": 65740
    },
    {
      "epoch": 1.4611111111111112,
      "grad_norm": 0.08516460657119751,
      "learning_rate": 1.3472222222222222e-05,
      "loss": 0.0018,
      "step": 65750
    },
    {
      "epoch": 1.4613333333333334,
      "grad_norm": 0.1665879338979721,
      "learning_rate": 1.3466666666666666e-05,
      "loss": 0.0017,
      "step": 65760
    },
    {
      "epoch": 1.4615555555555555,
      "grad_norm": 0.21649739146232605,
      "learning_rate": 1.3461111111111111e-05,
      "loss": 0.0022,
      "step": 65770
    },
    {
      "epoch": 1.4617777777777778,
      "grad_norm": 0.13795335590839386,
      "learning_rate": 1.3455555555555558e-05,
      "loss": 0.0025,
      "step": 65780
    },
    {
      "epoch": 1.462,
      "grad_norm": 0.17631898820400238,
      "learning_rate": 1.3450000000000002e-05,
      "loss": 0.0019,
      "step": 65790
    },
    {
      "epoch": 1.462222222222222,
      "grad_norm": 0.14640136063098907,
      "learning_rate": 1.3444444444444445e-05,
      "loss": 0.0026,
      "step": 65800
    },
    {
      "epoch": 1.4624444444444444,
      "grad_norm": 0.3317635655403137,
      "learning_rate": 1.343888888888889e-05,
      "loss": 0.0021,
      "step": 65810
    },
    {
      "epoch": 1.4626666666666668,
      "grad_norm": 0.10824516415596008,
      "learning_rate": 1.3433333333333334e-05,
      "loss": 0.0017,
      "step": 65820
    },
    {
      "epoch": 1.462888888888889,
      "grad_norm": 0.10154459625482559,
      "learning_rate": 1.3427777777777778e-05,
      "loss": 0.0017,
      "step": 65830
    },
    {
      "epoch": 1.463111111111111,
      "grad_norm": 0.08058515191078186,
      "learning_rate": 1.3422222222222223e-05,
      "loss": 0.002,
      "step": 65840
    },
    {
      "epoch": 1.4633333333333334,
      "grad_norm": 0.06623583287000656,
      "learning_rate": 1.3416666666666666e-05,
      "loss": 0.0023,
      "step": 65850
    },
    {
      "epoch": 1.4635555555555555,
      "grad_norm": 0.06137745827436447,
      "learning_rate": 1.341111111111111e-05,
      "loss": 0.0016,
      "step": 65860
    },
    {
      "epoch": 1.4637777777777778,
      "grad_norm": 0.23328472673892975,
      "learning_rate": 1.3405555555555557e-05,
      "loss": 0.0028,
      "step": 65870
    },
    {
      "epoch": 1.464,
      "grad_norm": 0.23950394988059998,
      "learning_rate": 1.3400000000000002e-05,
      "loss": 0.0017,
      "step": 65880
    },
    {
      "epoch": 1.4642222222222223,
      "grad_norm": 0.42609161138534546,
      "learning_rate": 1.3394444444444446e-05,
      "loss": 0.0026,
      "step": 65890
    },
    {
      "epoch": 1.4644444444444444,
      "grad_norm": 0.19151610136032104,
      "learning_rate": 1.338888888888889e-05,
      "loss": 0.002,
      "step": 65900
    },
    {
      "epoch": 1.4646666666666666,
      "grad_norm": 0.21125395596027374,
      "learning_rate": 1.3383333333333335e-05,
      "loss": 0.0019,
      "step": 65910
    },
    {
      "epoch": 1.464888888888889,
      "grad_norm": 0.27752751111984253,
      "learning_rate": 1.3377777777777778e-05,
      "loss": 0.0019,
      "step": 65920
    },
    {
      "epoch": 1.465111111111111,
      "grad_norm": 0.07797357439994812,
      "learning_rate": 1.3372222222222222e-05,
      "loss": 0.002,
      "step": 65930
    },
    {
      "epoch": 1.4653333333333334,
      "grad_norm": 0.4814739525318146,
      "learning_rate": 1.3366666666666667e-05,
      "loss": 0.002,
      "step": 65940
    },
    {
      "epoch": 1.4655555555555555,
      "grad_norm": 0.31337082386016846,
      "learning_rate": 1.3361111111111114e-05,
      "loss": 0.002,
      "step": 65950
    },
    {
      "epoch": 1.4657777777777778,
      "grad_norm": 0.10474555194377899,
      "learning_rate": 1.3355555555555557e-05,
      "loss": 0.0021,
      "step": 65960
    },
    {
      "epoch": 1.466,
      "grad_norm": 0.11023546010255814,
      "learning_rate": 1.3350000000000001e-05,
      "loss": 0.0022,
      "step": 65970
    },
    {
      "epoch": 1.466222222222222,
      "grad_norm": 0.43172016739845276,
      "learning_rate": 1.3344444444444446e-05,
      "loss": 0.0025,
      "step": 65980
    },
    {
      "epoch": 1.4664444444444444,
      "grad_norm": 0.3175993859767914,
      "learning_rate": 1.333888888888889e-05,
      "loss": 0.0018,
      "step": 65990
    },
    {
      "epoch": 1.4666666666666668,
      "grad_norm": 0.10213661938905716,
      "learning_rate": 1.3333333333333333e-05,
      "loss": 0.0022,
      "step": 66000
    },
    {
      "epoch": 1.466888888888889,
      "grad_norm": 0.09628236293792725,
      "learning_rate": 1.3327777777777779e-05,
      "loss": 0.0028,
      "step": 66010
    },
    {
      "epoch": 1.467111111111111,
      "grad_norm": 0.45811793208122253,
      "learning_rate": 1.3322222222222222e-05,
      "loss": 0.0018,
      "step": 66020
    },
    {
      "epoch": 1.4673333333333334,
      "grad_norm": 0.23228876292705536,
      "learning_rate": 1.3316666666666666e-05,
      "loss": 0.0033,
      "step": 66030
    },
    {
      "epoch": 1.4675555555555555,
      "grad_norm": 0.09076514840126038,
      "learning_rate": 1.3311111111111113e-05,
      "loss": 0.002,
      "step": 66040
    },
    {
      "epoch": 1.4677777777777778,
      "grad_norm": 0.25097155570983887,
      "learning_rate": 1.3305555555555558e-05,
      "loss": 0.0026,
      "step": 66050
    },
    {
      "epoch": 1.468,
      "grad_norm": 0.4331420361995697,
      "learning_rate": 1.3300000000000001e-05,
      "loss": 0.0026,
      "step": 66060
    },
    {
      "epoch": 1.4682222222222223,
      "grad_norm": 0.19263407588005066,
      "learning_rate": 1.3294444444444445e-05,
      "loss": 0.0019,
      "step": 66070
    },
    {
      "epoch": 1.4684444444444444,
      "grad_norm": 0.1565927267074585,
      "learning_rate": 1.328888888888889e-05,
      "loss": 0.0026,
      "step": 66080
    },
    {
      "epoch": 1.4686666666666666,
      "grad_norm": 0.17161749303340912,
      "learning_rate": 1.3283333333333334e-05,
      "loss": 0.0022,
      "step": 66090
    },
    {
      "epoch": 1.468888888888889,
      "grad_norm": 0.09508059918880463,
      "learning_rate": 1.3277777777777777e-05,
      "loss": 0.002,
      "step": 66100
    },
    {
      "epoch": 1.469111111111111,
      "grad_norm": 0.48053088784217834,
      "learning_rate": 1.3272222222222223e-05,
      "loss": 0.0022,
      "step": 66110
    },
    {
      "epoch": 1.4693333333333334,
      "grad_norm": 0.32988807559013367,
      "learning_rate": 1.3266666666666666e-05,
      "loss": 0.0019,
      "step": 66120
    },
    {
      "epoch": 1.4695555555555555,
      "grad_norm": 0.2717020809650421,
      "learning_rate": 1.3261111111111113e-05,
      "loss": 0.0029,
      "step": 66130
    },
    {
      "epoch": 1.4697777777777778,
      "grad_norm": 0.3919093608856201,
      "learning_rate": 1.3255555555555557e-05,
      "loss": 0.0024,
      "step": 66140
    },
    {
      "epoch": 1.47,
      "grad_norm": 0.20313993096351624,
      "learning_rate": 1.3250000000000002e-05,
      "loss": 0.0022,
      "step": 66150
    },
    {
      "epoch": 1.470222222222222,
      "grad_norm": 0.4561507999897003,
      "learning_rate": 1.3244444444444445e-05,
      "loss": 0.0024,
      "step": 66160
    },
    {
      "epoch": 1.4704444444444444,
      "grad_norm": 0.1007007285952568,
      "learning_rate": 1.3238888888888889e-05,
      "loss": 0.0018,
      "step": 66170
    },
    {
      "epoch": 1.4706666666666668,
      "grad_norm": 0.09716907143592834,
      "learning_rate": 1.3233333333333334e-05,
      "loss": 0.0022,
      "step": 66180
    },
    {
      "epoch": 1.470888888888889,
      "grad_norm": 0.08996006101369858,
      "learning_rate": 1.3227777777777778e-05,
      "loss": 0.0018,
      "step": 66190
    },
    {
      "epoch": 1.471111111111111,
      "grad_norm": 0.13410736620426178,
      "learning_rate": 1.3222222222222221e-05,
      "loss": 0.002,
      "step": 66200
    },
    {
      "epoch": 1.4713333333333334,
      "grad_norm": 0.12755709886550903,
      "learning_rate": 1.3216666666666667e-05,
      "loss": 0.0018,
      "step": 66210
    },
    {
      "epoch": 1.4715555555555555,
      "grad_norm": 0.17361213266849518,
      "learning_rate": 1.3211111111111114e-05,
      "loss": 0.0018,
      "step": 66220
    },
    {
      "epoch": 1.4717777777777779,
      "grad_norm": 0.2746817469596863,
      "learning_rate": 1.3205555555555557e-05,
      "loss": 0.0017,
      "step": 66230
    },
    {
      "epoch": 1.472,
      "grad_norm": 0.29800671339035034,
      "learning_rate": 1.32e-05,
      "loss": 0.0023,
      "step": 66240
    },
    {
      "epoch": 1.4722222222222223,
      "grad_norm": 0.07214941829442978,
      "learning_rate": 1.3194444444444446e-05,
      "loss": 0.0019,
      "step": 66250
    },
    {
      "epoch": 1.4724444444444444,
      "grad_norm": 0.12301076948642731,
      "learning_rate": 1.318888888888889e-05,
      "loss": 0.0019,
      "step": 66260
    },
    {
      "epoch": 1.4726666666666666,
      "grad_norm": 0.3858281075954437,
      "learning_rate": 1.3183333333333333e-05,
      "loss": 0.0021,
      "step": 66270
    },
    {
      "epoch": 1.472888888888889,
      "grad_norm": 0.2599479556083679,
      "learning_rate": 1.3177777777777778e-05,
      "loss": 0.0035,
      "step": 66280
    },
    {
      "epoch": 1.473111111111111,
      "grad_norm": 0.057295676320791245,
      "learning_rate": 1.3172222222222222e-05,
      "loss": 0.0028,
      "step": 66290
    },
    {
      "epoch": 1.4733333333333334,
      "grad_norm": 0.14879682660102844,
      "learning_rate": 1.3166666666666665e-05,
      "loss": 0.0022,
      "step": 66300
    },
    {
      "epoch": 1.4735555555555555,
      "grad_norm": 0.5149450302124023,
      "learning_rate": 1.3161111111111112e-05,
      "loss": 0.0019,
      "step": 66310
    },
    {
      "epoch": 1.4737777777777779,
      "grad_norm": 0.16861547529697418,
      "learning_rate": 1.3155555555555558e-05,
      "loss": 0.0028,
      "step": 66320
    },
    {
      "epoch": 1.474,
      "grad_norm": 0.06788884103298187,
      "learning_rate": 1.3150000000000001e-05,
      "loss": 0.0025,
      "step": 66330
    },
    {
      "epoch": 1.474222222222222,
      "grad_norm": 0.5010367035865784,
      "learning_rate": 1.3144444444444445e-05,
      "loss": 0.0021,
      "step": 66340
    },
    {
      "epoch": 1.4744444444444444,
      "grad_norm": 0.3022434413433075,
      "learning_rate": 1.313888888888889e-05,
      "loss": 0.0018,
      "step": 66350
    },
    {
      "epoch": 1.4746666666666668,
      "grad_norm": 0.25629672408103943,
      "learning_rate": 1.3133333333333334e-05,
      "loss": 0.0018,
      "step": 66360
    },
    {
      "epoch": 1.474888888888889,
      "grad_norm": 0.11356756836175919,
      "learning_rate": 1.3127777777777777e-05,
      "loss": 0.0027,
      "step": 66370
    },
    {
      "epoch": 1.475111111111111,
      "grad_norm": 0.2582526206970215,
      "learning_rate": 1.3122222222222222e-05,
      "loss": 0.0025,
      "step": 66380
    },
    {
      "epoch": 1.4753333333333334,
      "grad_norm": 0.1397508680820465,
      "learning_rate": 1.3116666666666666e-05,
      "loss": 0.0019,
      "step": 66390
    },
    {
      "epoch": 1.4755555555555555,
      "grad_norm": 0.5121122598648071,
      "learning_rate": 1.3111111111111113e-05,
      "loss": 0.0019,
      "step": 66400
    },
    {
      "epoch": 1.4757777777777779,
      "grad_norm": 0.5918399095535278,
      "learning_rate": 1.3105555555555556e-05,
      "loss": 0.0019,
      "step": 66410
    },
    {
      "epoch": 1.476,
      "grad_norm": 0.11377620697021484,
      "learning_rate": 1.3100000000000002e-05,
      "loss": 0.0028,
      "step": 66420
    },
    {
      "epoch": 1.4762222222222223,
      "grad_norm": 0.47323495149612427,
      "learning_rate": 1.3094444444444445e-05,
      "loss": 0.0025,
      "step": 66430
    },
    {
      "epoch": 1.4764444444444444,
      "grad_norm": 0.12940633296966553,
      "learning_rate": 1.3088888888888889e-05,
      "loss": 0.0017,
      "step": 66440
    },
    {
      "epoch": 1.4766666666666666,
      "grad_norm": 0.10237665474414825,
      "learning_rate": 1.3083333333333334e-05,
      "loss": 0.0018,
      "step": 66450
    },
    {
      "epoch": 1.476888888888889,
      "grad_norm": 0.44113558530807495,
      "learning_rate": 1.3077777777777778e-05,
      "loss": 0.0022,
      "step": 66460
    },
    {
      "epoch": 1.477111111111111,
      "grad_norm": 0.5645033121109009,
      "learning_rate": 1.3072222222222221e-05,
      "loss": 0.0019,
      "step": 66470
    },
    {
      "epoch": 1.4773333333333334,
      "grad_norm": 0.0941234603524208,
      "learning_rate": 1.3066666666666666e-05,
      "loss": 0.0019,
      "step": 66480
    },
    {
      "epoch": 1.4775555555555555,
      "grad_norm": 0.09840014576911926,
      "learning_rate": 1.3061111111111113e-05,
      "loss": 0.002,
      "step": 66490
    },
    {
      "epoch": 1.4777777777777779,
      "grad_norm": 0.2628478407859802,
      "learning_rate": 1.3055555555555557e-05,
      "loss": 0.002,
      "step": 66500
    },
    {
      "epoch": 1.478,
      "grad_norm": 0.14898739755153656,
      "learning_rate": 1.305e-05,
      "loss": 0.0019,
      "step": 66510
    },
    {
      "epoch": 1.478222222222222,
      "grad_norm": 0.2184215635061264,
      "learning_rate": 1.3044444444444446e-05,
      "loss": 0.0025,
      "step": 66520
    },
    {
      "epoch": 1.4784444444444444,
      "grad_norm": 0.16751082241535187,
      "learning_rate": 1.303888888888889e-05,
      "loss": 0.0019,
      "step": 66530
    },
    {
      "epoch": 1.4786666666666668,
      "grad_norm": 0.17929495871067047,
      "learning_rate": 1.3033333333333333e-05,
      "loss": 0.0021,
      "step": 66540
    },
    {
      "epoch": 1.478888888888889,
      "grad_norm": 0.10909133404493332,
      "learning_rate": 1.3027777777777778e-05,
      "loss": 0.0018,
      "step": 66550
    },
    {
      "epoch": 1.479111111111111,
      "grad_norm": 0.09575751423835754,
      "learning_rate": 1.3022222222222222e-05,
      "loss": 0.0018,
      "step": 66560
    },
    {
      "epoch": 1.4793333333333334,
      "grad_norm": 0.6789097189903259,
      "learning_rate": 1.3016666666666669e-05,
      "loss": 0.002,
      "step": 66570
    },
    {
      "epoch": 1.4795555555555555,
      "grad_norm": 0.10444320738315582,
      "learning_rate": 1.3011111111111112e-05,
      "loss": 0.002,
      "step": 66580
    },
    {
      "epoch": 1.4797777777777779,
      "grad_norm": 0.30382323265075684,
      "learning_rate": 1.3005555555555557e-05,
      "loss": 0.0018,
      "step": 66590
    },
    {
      "epoch": 1.48,
      "grad_norm": 0.06396620720624924,
      "learning_rate": 1.3000000000000001e-05,
      "loss": 0.002,
      "step": 66600
    },
    {
      "epoch": 1.4802222222222223,
      "grad_norm": 0.17164041101932526,
      "learning_rate": 1.2994444444444444e-05,
      "loss": 0.0019,
      "step": 66610
    },
    {
      "epoch": 1.4804444444444445,
      "grad_norm": 0.08343283832073212,
      "learning_rate": 1.298888888888889e-05,
      "loss": 0.0018,
      "step": 66620
    },
    {
      "epoch": 1.4806666666666666,
      "grad_norm": 0.06708085536956787,
      "learning_rate": 1.2983333333333333e-05,
      "loss": 0.0016,
      "step": 66630
    },
    {
      "epoch": 1.480888888888889,
      "grad_norm": 0.3000999391078949,
      "learning_rate": 1.2977777777777777e-05,
      "loss": 0.0025,
      "step": 66640
    },
    {
      "epoch": 1.481111111111111,
      "grad_norm": 0.2993523180484772,
      "learning_rate": 1.2972222222222222e-05,
      "loss": 0.0017,
      "step": 66650
    },
    {
      "epoch": 1.4813333333333334,
      "grad_norm": 0.09190282225608826,
      "learning_rate": 1.2966666666666669e-05,
      "loss": 0.0021,
      "step": 66660
    },
    {
      "epoch": 1.4815555555555555,
      "grad_norm": 0.3678952753543854,
      "learning_rate": 1.2961111111111113e-05,
      "loss": 0.0018,
      "step": 66670
    },
    {
      "epoch": 1.4817777777777779,
      "grad_norm": 0.2349306046962738,
      "learning_rate": 1.2955555555555556e-05,
      "loss": 0.0024,
      "step": 66680
    },
    {
      "epoch": 1.482,
      "grad_norm": 0.21003304421901703,
      "learning_rate": 1.2950000000000001e-05,
      "loss": 0.0027,
      "step": 66690
    },
    {
      "epoch": 1.482222222222222,
      "grad_norm": 0.09333127737045288,
      "learning_rate": 1.2944444444444445e-05,
      "loss": 0.0018,
      "step": 66700
    },
    {
      "epoch": 1.4824444444444445,
      "grad_norm": 0.4831267297267914,
      "learning_rate": 1.2938888888888888e-05,
      "loss": 0.0021,
      "step": 66710
    },
    {
      "epoch": 1.4826666666666668,
      "grad_norm": 0.4066964387893677,
      "learning_rate": 1.2933333333333334e-05,
      "loss": 0.0016,
      "step": 66720
    },
    {
      "epoch": 1.482888888888889,
      "grad_norm": 0.23991455137729645,
      "learning_rate": 1.2927777777777777e-05,
      "loss": 0.002,
      "step": 66730
    },
    {
      "epoch": 1.483111111111111,
      "grad_norm": 0.19501285254955292,
      "learning_rate": 1.2922222222222221e-05,
      "loss": 0.0025,
      "step": 66740
    },
    {
      "epoch": 1.4833333333333334,
      "grad_norm": 0.5017731189727783,
      "learning_rate": 1.2916666666666668e-05,
      "loss": 0.0021,
      "step": 66750
    },
    {
      "epoch": 1.4835555555555555,
      "grad_norm": 0.206691712141037,
      "learning_rate": 1.2911111111111113e-05,
      "loss": 0.0018,
      "step": 66760
    },
    {
      "epoch": 1.4837777777777776,
      "grad_norm": 0.0763002336025238,
      "learning_rate": 1.2905555555555557e-05,
      "loss": 0.002,
      "step": 66770
    },
    {
      "epoch": 1.484,
      "grad_norm": 0.27157217264175415,
      "learning_rate": 1.29e-05,
      "loss": 0.0018,
      "step": 66780
    },
    {
      "epoch": 1.4842222222222223,
      "grad_norm": 0.42947229743003845,
      "learning_rate": 1.2894444444444445e-05,
      "loss": 0.0026,
      "step": 66790
    },
    {
      "epoch": 1.4844444444444445,
      "grad_norm": 0.14249421656131744,
      "learning_rate": 1.2888888888888889e-05,
      "loss": 0.002,
      "step": 66800
    },
    {
      "epoch": 1.4846666666666666,
      "grad_norm": 0.26127713918685913,
      "learning_rate": 1.2883333333333333e-05,
      "loss": 0.0026,
      "step": 66810
    },
    {
      "epoch": 1.484888888888889,
      "grad_norm": 0.7610450983047485,
      "learning_rate": 1.2877777777777778e-05,
      "loss": 0.0021,
      "step": 66820
    },
    {
      "epoch": 1.485111111111111,
      "grad_norm": 0.5829152464866638,
      "learning_rate": 1.2872222222222221e-05,
      "loss": 0.0019,
      "step": 66830
    },
    {
      "epoch": 1.4853333333333334,
      "grad_norm": 0.09632892161607742,
      "learning_rate": 1.2866666666666668e-05,
      "loss": 0.0018,
      "step": 66840
    },
    {
      "epoch": 1.4855555555555555,
      "grad_norm": 0.11357279866933823,
      "learning_rate": 1.2861111111111112e-05,
      "loss": 0.0028,
      "step": 66850
    },
    {
      "epoch": 1.4857777777777779,
      "grad_norm": 0.11038943380117416,
      "learning_rate": 1.2855555555555557e-05,
      "loss": 0.0022,
      "step": 66860
    },
    {
      "epoch": 1.486,
      "grad_norm": 0.15530820190906525,
      "learning_rate": 1.285e-05,
      "loss": 0.0017,
      "step": 66870
    },
    {
      "epoch": 1.4862222222222221,
      "grad_norm": 0.21686086058616638,
      "learning_rate": 1.2844444444444446e-05,
      "loss": 0.0017,
      "step": 66880
    },
    {
      "epoch": 1.4864444444444445,
      "grad_norm": 0.12036676704883575,
      "learning_rate": 1.283888888888889e-05,
      "loss": 0.0028,
      "step": 66890
    },
    {
      "epoch": 1.4866666666666668,
      "grad_norm": 0.0705811157822609,
      "learning_rate": 1.2833333333333333e-05,
      "loss": 0.002,
      "step": 66900
    },
    {
      "epoch": 1.486888888888889,
      "grad_norm": 0.1158679649233818,
      "learning_rate": 1.2827777777777778e-05,
      "loss": 0.0021,
      "step": 66910
    },
    {
      "epoch": 1.487111111111111,
      "grad_norm": 0.36929741501808167,
      "learning_rate": 1.2822222222222222e-05,
      "loss": 0.0024,
      "step": 66920
    },
    {
      "epoch": 1.4873333333333334,
      "grad_norm": 0.16318301856517792,
      "learning_rate": 1.2816666666666669e-05,
      "loss": 0.0029,
      "step": 66930
    },
    {
      "epoch": 1.4875555555555555,
      "grad_norm": 0.1651102900505066,
      "learning_rate": 1.2811111111111112e-05,
      "loss": 0.0021,
      "step": 66940
    },
    {
      "epoch": 1.4877777777777776,
      "grad_norm": 0.09025852382183075,
      "learning_rate": 1.2805555555555558e-05,
      "loss": 0.0023,
      "step": 66950
    },
    {
      "epoch": 1.488,
      "grad_norm": 0.30176496505737305,
      "learning_rate": 1.2800000000000001e-05,
      "loss": 0.002,
      "step": 66960
    },
    {
      "epoch": 1.4882222222222223,
      "grad_norm": 0.04787138104438782,
      "learning_rate": 1.2794444444444445e-05,
      "loss": 0.0017,
      "step": 66970
    },
    {
      "epoch": 1.4884444444444445,
      "grad_norm": 0.06408653408288956,
      "learning_rate": 1.278888888888889e-05,
      "loss": 0.0017,
      "step": 66980
    },
    {
      "epoch": 1.4886666666666666,
      "grad_norm": 0.347557008266449,
      "learning_rate": 1.2783333333333333e-05,
      "loss": 0.0017,
      "step": 66990
    },
    {
      "epoch": 1.488888888888889,
      "grad_norm": 0.14242853224277496,
      "learning_rate": 1.2777777777777777e-05,
      "loss": 0.0026,
      "step": 67000
    },
    {
      "epoch": 1.489111111111111,
      "grad_norm": 0.15954037010669708,
      "learning_rate": 1.2772222222222222e-05,
      "loss": 0.0021,
      "step": 67010
    },
    {
      "epoch": 1.4893333333333334,
      "grad_norm": 0.26085421442985535,
      "learning_rate": 1.276666666666667e-05,
      "loss": 0.0022,
      "step": 67020
    },
    {
      "epoch": 1.4895555555555555,
      "grad_norm": 0.1590602993965149,
      "learning_rate": 1.2761111111111113e-05,
      "loss": 0.0022,
      "step": 67030
    },
    {
      "epoch": 1.4897777777777779,
      "grad_norm": 0.18842536211013794,
      "learning_rate": 1.2755555555555556e-05,
      "loss": 0.0031,
      "step": 67040
    },
    {
      "epoch": 1.49,
      "grad_norm": 0.20780394971370697,
      "learning_rate": 1.2750000000000002e-05,
      "loss": 0.0021,
      "step": 67050
    },
    {
      "epoch": 1.4902222222222221,
      "grad_norm": 0.10804728418588638,
      "learning_rate": 1.2744444444444445e-05,
      "loss": 0.0019,
      "step": 67060
    },
    {
      "epoch": 1.4904444444444445,
      "grad_norm": 0.2807595431804657,
      "learning_rate": 1.2738888888888889e-05,
      "loss": 0.0024,
      "step": 67070
    },
    {
      "epoch": 1.4906666666666666,
      "grad_norm": 0.06730922311544418,
      "learning_rate": 1.2733333333333334e-05,
      "loss": 0.0026,
      "step": 67080
    },
    {
      "epoch": 1.490888888888889,
      "grad_norm": 0.40915966033935547,
      "learning_rate": 1.2727777777777778e-05,
      "loss": 0.0024,
      "step": 67090
    },
    {
      "epoch": 1.491111111111111,
      "grad_norm": 0.3326125144958496,
      "learning_rate": 1.2722222222222221e-05,
      "loss": 0.0021,
      "step": 67100
    },
    {
      "epoch": 1.4913333333333334,
      "grad_norm": 0.07755123823881149,
      "learning_rate": 1.2716666666666668e-05,
      "loss": 0.0017,
      "step": 67110
    },
    {
      "epoch": 1.4915555555555555,
      "grad_norm": 0.06637609004974365,
      "learning_rate": 1.2711111111111113e-05,
      "loss": 0.0022,
      "step": 67120
    },
    {
      "epoch": 1.4917777777777776,
      "grad_norm": 0.209395170211792,
      "learning_rate": 1.2705555555555557e-05,
      "loss": 0.0018,
      "step": 67130
    },
    {
      "epoch": 1.492,
      "grad_norm": 0.4566650688648224,
      "learning_rate": 1.27e-05,
      "loss": 0.0023,
      "step": 67140
    },
    {
      "epoch": 1.4922222222222223,
      "grad_norm": 0.07106735557317734,
      "learning_rate": 1.2694444444444446e-05,
      "loss": 0.0025,
      "step": 67150
    },
    {
      "epoch": 1.4924444444444445,
      "grad_norm": 0.10855985432863235,
      "learning_rate": 1.268888888888889e-05,
      "loss": 0.0023,
      "step": 67160
    },
    {
      "epoch": 1.4926666666666666,
      "grad_norm": 0.12382659316062927,
      "learning_rate": 1.2683333333333333e-05,
      "loss": 0.0021,
      "step": 67170
    },
    {
      "epoch": 1.492888888888889,
      "grad_norm": 0.13532744348049164,
      "learning_rate": 1.2677777777777778e-05,
      "loss": 0.0027,
      "step": 67180
    },
    {
      "epoch": 1.493111111111111,
      "grad_norm": 0.4959091544151306,
      "learning_rate": 1.2672222222222225e-05,
      "loss": 0.0022,
      "step": 67190
    },
    {
      "epoch": 1.4933333333333334,
      "grad_norm": 0.2849932014942169,
      "learning_rate": 1.2666666666666668e-05,
      "loss": 0.0019,
      "step": 67200
    },
    {
      "epoch": 1.4935555555555555,
      "grad_norm": 0.23462840914726257,
      "learning_rate": 1.2661111111111112e-05,
      "loss": 0.0026,
      "step": 67210
    },
    {
      "epoch": 1.4937777777777779,
      "grad_norm": 0.07200204581022263,
      "learning_rate": 1.2655555555555557e-05,
      "loss": 0.0027,
      "step": 67220
    },
    {
      "epoch": 1.494,
      "grad_norm": 0.13676957786083221,
      "learning_rate": 1.2650000000000001e-05,
      "loss": 0.0025,
      "step": 67230
    },
    {
      "epoch": 1.4942222222222221,
      "grad_norm": 0.5549263954162598,
      "learning_rate": 1.2644444444444444e-05,
      "loss": 0.002,
      "step": 67240
    },
    {
      "epoch": 1.4944444444444445,
      "grad_norm": 0.14701572060585022,
      "learning_rate": 1.263888888888889e-05,
      "loss": 0.0017,
      "step": 67250
    },
    {
      "epoch": 1.4946666666666666,
      "grad_norm": 0.20671863853931427,
      "learning_rate": 1.2633333333333333e-05,
      "loss": 0.0025,
      "step": 67260
    },
    {
      "epoch": 1.494888888888889,
      "grad_norm": 0.21839725971221924,
      "learning_rate": 1.2627777777777777e-05,
      "loss": 0.0026,
      "step": 67270
    },
    {
      "epoch": 1.495111111111111,
      "grad_norm": 0.43866705894470215,
      "learning_rate": 1.2622222222222224e-05,
      "loss": 0.004,
      "step": 67280
    },
    {
      "epoch": 1.4953333333333334,
      "grad_norm": 0.28472259640693665,
      "learning_rate": 1.2616666666666669e-05,
      "loss": 0.0019,
      "step": 67290
    },
    {
      "epoch": 1.4955555555555555,
      "grad_norm": 0.28511011600494385,
      "learning_rate": 1.2611111111111113e-05,
      "loss": 0.0018,
      "step": 67300
    },
    {
      "epoch": 1.4957777777777777,
      "grad_norm": 0.19433054327964783,
      "learning_rate": 1.2605555555555556e-05,
      "loss": 0.0026,
      "step": 67310
    },
    {
      "epoch": 1.496,
      "grad_norm": 0.26089584827423096,
      "learning_rate": 1.2600000000000001e-05,
      "loss": 0.0017,
      "step": 67320
    },
    {
      "epoch": 1.4962222222222223,
      "grad_norm": 0.04646048694849014,
      "learning_rate": 1.2594444444444445e-05,
      "loss": 0.0017,
      "step": 67330
    },
    {
      "epoch": 1.4964444444444445,
      "grad_norm": 0.12423591315746307,
      "learning_rate": 1.2588888888888888e-05,
      "loss": 0.0025,
      "step": 67340
    },
    {
      "epoch": 1.4966666666666666,
      "grad_norm": 0.46885401010513306,
      "learning_rate": 1.2583333333333334e-05,
      "loss": 0.0018,
      "step": 67350
    },
    {
      "epoch": 1.496888888888889,
      "grad_norm": 0.20906893908977509,
      "learning_rate": 1.2577777777777777e-05,
      "loss": 0.0019,
      "step": 67360
    },
    {
      "epoch": 1.497111111111111,
      "grad_norm": 0.5401282906532288,
      "learning_rate": 1.2572222222222224e-05,
      "loss": 0.0029,
      "step": 67370
    },
    {
      "epoch": 1.4973333333333334,
      "grad_norm": 0.1492537409067154,
      "learning_rate": 1.2566666666666668e-05,
      "loss": 0.0024,
      "step": 67380
    },
    {
      "epoch": 1.4975555555555555,
      "grad_norm": 0.05480441078543663,
      "learning_rate": 1.2561111111111113e-05,
      "loss": 0.002,
      "step": 67390
    },
    {
      "epoch": 1.4977777777777779,
      "grad_norm": 0.2413414865732193,
      "learning_rate": 1.2555555555555557e-05,
      "loss": 0.0021,
      "step": 67400
    },
    {
      "epoch": 1.498,
      "grad_norm": 0.11478458344936371,
      "learning_rate": 1.255e-05,
      "loss": 0.0027,
      "step": 67410
    },
    {
      "epoch": 1.4982222222222221,
      "grad_norm": 0.15658079087734222,
      "learning_rate": 1.2544444444444445e-05,
      "loss": 0.0019,
      "step": 67420
    },
    {
      "epoch": 1.4984444444444445,
      "grad_norm": 0.2983134388923645,
      "learning_rate": 1.2538888888888889e-05,
      "loss": 0.0019,
      "step": 67430
    },
    {
      "epoch": 1.4986666666666666,
      "grad_norm": 0.4968332052230835,
      "learning_rate": 1.2533333333333332e-05,
      "loss": 0.0017,
      "step": 67440
    },
    {
      "epoch": 1.498888888888889,
      "grad_norm": 0.28758686780929565,
      "learning_rate": 1.2527777777777778e-05,
      "loss": 0.0019,
      "step": 67450
    },
    {
      "epoch": 1.499111111111111,
      "grad_norm": 0.12560726702213287,
      "learning_rate": 1.2522222222222225e-05,
      "loss": 0.0021,
      "step": 67460
    },
    {
      "epoch": 1.4993333333333334,
      "grad_norm": 0.07995559275150299,
      "learning_rate": 1.2516666666666668e-05,
      "loss": 0.002,
      "step": 67470
    },
    {
      "epoch": 1.4995555555555555,
      "grad_norm": 0.10518086701631546,
      "learning_rate": 1.2511111111111112e-05,
      "loss": 0.0017,
      "step": 67480
    },
    {
      "epoch": 1.4997777777777777,
      "grad_norm": 0.15772351622581482,
      "learning_rate": 1.2505555555555557e-05,
      "loss": 0.002,
      "step": 67490
    },
    {
      "epoch": 1.5,
      "grad_norm": 0.20443224906921387,
      "learning_rate": 1.25e-05,
      "loss": 0.0016,
      "step": 67500
    },
    {
      "epoch": 1.5002222222222223,
      "grad_norm": 0.19885145127773285,
      "learning_rate": 1.2494444444444444e-05,
      "loss": 0.0022,
      "step": 67510
    },
    {
      "epoch": 1.5004444444444445,
      "grad_norm": 0.0972808301448822,
      "learning_rate": 1.248888888888889e-05,
      "loss": 0.0025,
      "step": 67520
    },
    {
      "epoch": 1.5006666666666666,
      "grad_norm": 0.13623978197574615,
      "learning_rate": 1.2483333333333335e-05,
      "loss": 0.0024,
      "step": 67530
    },
    {
      "epoch": 1.500888888888889,
      "grad_norm": 0.6761875748634338,
      "learning_rate": 1.2477777777777778e-05,
      "loss": 0.0016,
      "step": 67540
    },
    {
      "epoch": 1.501111111111111,
      "grad_norm": 0.06391197443008423,
      "learning_rate": 1.2472222222222223e-05,
      "loss": 0.0022,
      "step": 67550
    },
    {
      "epoch": 1.5013333333333332,
      "grad_norm": 0.1883150041103363,
      "learning_rate": 1.2466666666666667e-05,
      "loss": 0.0037,
      "step": 67560
    },
    {
      "epoch": 1.5015555555555555,
      "grad_norm": 0.10581641644239426,
      "learning_rate": 1.2461111111111112e-05,
      "loss": 0.0023,
      "step": 67570
    },
    {
      "epoch": 1.5017777777777779,
      "grad_norm": 0.36276084184646606,
      "learning_rate": 1.2455555555555556e-05,
      "loss": 0.0025,
      "step": 67580
    },
    {
      "epoch": 1.502,
      "grad_norm": 0.22985239326953888,
      "learning_rate": 1.2450000000000001e-05,
      "loss": 0.0018,
      "step": 67590
    },
    {
      "epoch": 1.5022222222222221,
      "grad_norm": 0.3850593566894531,
      "learning_rate": 1.2444444444444445e-05,
      "loss": 0.0021,
      "step": 67600
    },
    {
      "epoch": 1.5024444444444445,
      "grad_norm": 0.16896571218967438,
      "learning_rate": 1.2438888888888888e-05,
      "loss": 0.0019,
      "step": 67610
    },
    {
      "epoch": 1.5026666666666668,
      "grad_norm": 0.2830207347869873,
      "learning_rate": 1.2433333333333335e-05,
      "loss": 0.0024,
      "step": 67620
    },
    {
      "epoch": 1.502888888888889,
      "grad_norm": 0.16620507836341858,
      "learning_rate": 1.2427777777777779e-05,
      "loss": 0.0025,
      "step": 67630
    },
    {
      "epoch": 1.503111111111111,
      "grad_norm": 0.27300864458084106,
      "learning_rate": 1.2422222222222222e-05,
      "loss": 0.0029,
      "step": 67640
    },
    {
      "epoch": 1.5033333333333334,
      "grad_norm": 0.4919763207435608,
      "learning_rate": 1.2416666666666667e-05,
      "loss": 0.0028,
      "step": 67650
    },
    {
      "epoch": 1.5035555555555555,
      "grad_norm": 0.10615500062704086,
      "learning_rate": 1.2411111111111113e-05,
      "loss": 0.0019,
      "step": 67660
    },
    {
      "epoch": 1.5037777777777777,
      "grad_norm": 0.6533693075180054,
      "learning_rate": 1.2405555555555556e-05,
      "loss": 0.0017,
      "step": 67670
    },
    {
      "epoch": 1.504,
      "grad_norm": 0.13622413575649261,
      "learning_rate": 1.24e-05,
      "loss": 0.0027,
      "step": 67680
    },
    {
      "epoch": 1.5042222222222223,
      "grad_norm": 0.1581055074930191,
      "learning_rate": 1.2394444444444445e-05,
      "loss": 0.0023,
      "step": 67690
    },
    {
      "epoch": 1.5044444444444445,
      "grad_norm": 0.07480256259441376,
      "learning_rate": 1.238888888888889e-05,
      "loss": 0.0017,
      "step": 67700
    },
    {
      "epoch": 1.5046666666666666,
      "grad_norm": 0.12389656901359558,
      "learning_rate": 1.2383333333333334e-05,
      "loss": 0.0021,
      "step": 67710
    },
    {
      "epoch": 1.504888888888889,
      "grad_norm": 0.4081820845603943,
      "learning_rate": 1.237777777777778e-05,
      "loss": 0.0028,
      "step": 67720
    },
    {
      "epoch": 1.505111111111111,
      "grad_norm": 0.3727286756038666,
      "learning_rate": 1.2372222222222223e-05,
      "loss": 0.0017,
      "step": 67730
    },
    {
      "epoch": 1.5053333333333332,
      "grad_norm": 0.2108469307422638,
      "learning_rate": 1.2366666666666666e-05,
      "loss": 0.0037,
      "step": 67740
    },
    {
      "epoch": 1.5055555555555555,
      "grad_norm": 0.761540949344635,
      "learning_rate": 1.2361111111111112e-05,
      "loss": 0.0022,
      "step": 67750
    },
    {
      "epoch": 1.5057777777777779,
      "grad_norm": 0.47086676955223083,
      "learning_rate": 1.2355555555555557e-05,
      "loss": 0.0027,
      "step": 67760
    },
    {
      "epoch": 1.506,
      "grad_norm": 0.2171744704246521,
      "learning_rate": 1.235e-05,
      "loss": 0.0022,
      "step": 67770
    },
    {
      "epoch": 1.5062222222222221,
      "grad_norm": 0.15161088109016418,
      "learning_rate": 1.2344444444444444e-05,
      "loss": 0.0021,
      "step": 67780
    },
    {
      "epoch": 1.5064444444444445,
      "grad_norm": 0.3161296844482422,
      "learning_rate": 1.233888888888889e-05,
      "loss": 0.0022,
      "step": 67790
    },
    {
      "epoch": 1.5066666666666668,
      "grad_norm": 0.30235037207603455,
      "learning_rate": 1.2333333333333334e-05,
      "loss": 0.0026,
      "step": 67800
    },
    {
      "epoch": 1.506888888888889,
      "grad_norm": 0.4007601737976074,
      "learning_rate": 1.2327777777777778e-05,
      "loss": 0.0023,
      "step": 67810
    },
    {
      "epoch": 1.507111111111111,
      "grad_norm": 0.1915876269340515,
      "learning_rate": 1.2322222222222223e-05,
      "loss": 0.0025,
      "step": 67820
    },
    {
      "epoch": 1.5073333333333334,
      "grad_norm": 0.12472496926784515,
      "learning_rate": 1.2316666666666667e-05,
      "loss": 0.0021,
      "step": 67830
    },
    {
      "epoch": 1.5075555555555555,
      "grad_norm": 0.07879617065191269,
      "learning_rate": 1.2311111111111112e-05,
      "loss": 0.0017,
      "step": 67840
    },
    {
      "epoch": 1.5077777777777777,
      "grad_norm": 0.10721095651388168,
      "learning_rate": 1.2305555555555556e-05,
      "loss": 0.0018,
      "step": 67850
    },
    {
      "epoch": 1.508,
      "grad_norm": 0.11733847856521606,
      "learning_rate": 1.23e-05,
      "loss": 0.0017,
      "step": 67860
    },
    {
      "epoch": 1.5082222222222224,
      "grad_norm": 0.2623504400253296,
      "learning_rate": 1.2294444444444444e-05,
      "loss": 0.0023,
      "step": 67870
    },
    {
      "epoch": 1.5084444444444445,
      "grad_norm": 0.07001128792762756,
      "learning_rate": 1.228888888888889e-05,
      "loss": 0.0018,
      "step": 67880
    },
    {
      "epoch": 1.5086666666666666,
      "grad_norm": 0.5471950769424438,
      "learning_rate": 1.2283333333333335e-05,
      "loss": 0.0019,
      "step": 67890
    },
    {
      "epoch": 1.508888888888889,
      "grad_norm": 0.14227238297462463,
      "learning_rate": 1.2277777777777778e-05,
      "loss": 0.0018,
      "step": 67900
    },
    {
      "epoch": 1.509111111111111,
      "grad_norm": 0.2242399901151657,
      "learning_rate": 1.2272222222222222e-05,
      "loss": 0.0026,
      "step": 67910
    },
    {
      "epoch": 1.5093333333333332,
      "grad_norm": 0.3649774491786957,
      "learning_rate": 1.2266666666666667e-05,
      "loss": 0.0021,
      "step": 67920
    },
    {
      "epoch": 1.5095555555555555,
      "grad_norm": 0.23170222342014313,
      "learning_rate": 1.2261111111111112e-05,
      "loss": 0.0022,
      "step": 67930
    },
    {
      "epoch": 1.5097777777777779,
      "grad_norm": 0.2488754391670227,
      "learning_rate": 1.2255555555555556e-05,
      "loss": 0.0019,
      "step": 67940
    },
    {
      "epoch": 1.51,
      "grad_norm": 0.18757402896881104,
      "learning_rate": 1.225e-05,
      "loss": 0.0039,
      "step": 67950
    },
    {
      "epoch": 1.5102222222222221,
      "grad_norm": 0.48241421580314636,
      "learning_rate": 1.2244444444444445e-05,
      "loss": 0.002,
      "step": 67960
    },
    {
      "epoch": 1.5104444444444445,
      "grad_norm": 0.0907057449221611,
      "learning_rate": 1.223888888888889e-05,
      "loss": 0.0033,
      "step": 67970
    },
    {
      "epoch": 1.5106666666666668,
      "grad_norm": 0.08168914914131165,
      "learning_rate": 1.2233333333333334e-05,
      "loss": 0.0028,
      "step": 67980
    },
    {
      "epoch": 1.5108888888888887,
      "grad_norm": 0.49928176403045654,
      "learning_rate": 1.2227777777777779e-05,
      "loss": 0.0017,
      "step": 67990
    },
    {
      "epoch": 1.511111111111111,
      "grad_norm": 0.4731821119785309,
      "learning_rate": 1.2222222222222222e-05,
      "loss": 0.0016,
      "step": 68000
    },
    {
      "epoch": 1.5113333333333334,
      "grad_norm": 0.3918954133987427,
      "learning_rate": 1.2216666666666668e-05,
      "loss": 0.0017,
      "step": 68010
    },
    {
      "epoch": 1.5115555555555555,
      "grad_norm": 0.3311757445335388,
      "learning_rate": 1.2211111111111111e-05,
      "loss": 0.0021,
      "step": 68020
    },
    {
      "epoch": 1.5117777777777777,
      "grad_norm": 0.13426415622234344,
      "learning_rate": 1.2205555555555557e-05,
      "loss": 0.0017,
      "step": 68030
    },
    {
      "epoch": 1.512,
      "grad_norm": 0.564547061920166,
      "learning_rate": 1.22e-05,
      "loss": 0.0021,
      "step": 68040
    },
    {
      "epoch": 1.5122222222222224,
      "grad_norm": 0.22460833191871643,
      "learning_rate": 1.2194444444444444e-05,
      "loss": 0.0019,
      "step": 68050
    },
    {
      "epoch": 1.5124444444444445,
      "grad_norm": 0.13541807234287262,
      "learning_rate": 1.218888888888889e-05,
      "loss": 0.0023,
      "step": 68060
    },
    {
      "epoch": 1.5126666666666666,
      "grad_norm": 0.06958815455436707,
      "learning_rate": 1.2183333333333334e-05,
      "loss": 0.002,
      "step": 68070
    },
    {
      "epoch": 1.512888888888889,
      "grad_norm": 0.39212843775749207,
      "learning_rate": 1.2177777777777778e-05,
      "loss": 0.0019,
      "step": 68080
    },
    {
      "epoch": 1.513111111111111,
      "grad_norm": 0.35033804178237915,
      "learning_rate": 1.2172222222222223e-05,
      "loss": 0.002,
      "step": 68090
    },
    {
      "epoch": 1.5133333333333332,
      "grad_norm": 0.22559626400470734,
      "learning_rate": 1.2166666666666668e-05,
      "loss": 0.0018,
      "step": 68100
    },
    {
      "epoch": 1.5135555555555555,
      "grad_norm": 0.15064787864685059,
      "learning_rate": 1.2161111111111112e-05,
      "loss": 0.0019,
      "step": 68110
    },
    {
      "epoch": 1.5137777777777779,
      "grad_norm": 0.44848304986953735,
      "learning_rate": 1.2155555555555555e-05,
      "loss": 0.0025,
      "step": 68120
    },
    {
      "epoch": 1.514,
      "grad_norm": 0.15513597428798676,
      "learning_rate": 1.215e-05,
      "loss": 0.0022,
      "step": 68130
    },
    {
      "epoch": 1.5142222222222221,
      "grad_norm": 0.34121087193489075,
      "learning_rate": 1.2144444444444444e-05,
      "loss": 0.002,
      "step": 68140
    },
    {
      "epoch": 1.5144444444444445,
      "grad_norm": 0.08298560231924057,
      "learning_rate": 1.213888888888889e-05,
      "loss": 0.0028,
      "step": 68150
    },
    {
      "epoch": 1.5146666666666668,
      "grad_norm": 0.35491830110549927,
      "learning_rate": 1.2133333333333335e-05,
      "loss": 0.0025,
      "step": 68160
    },
    {
      "epoch": 1.5148888888888887,
      "grad_norm": 0.24564920365810394,
      "learning_rate": 1.2127777777777778e-05,
      "loss": 0.0017,
      "step": 68170
    },
    {
      "epoch": 1.515111111111111,
      "grad_norm": 0.06759800016880035,
      "learning_rate": 1.2122222222222222e-05,
      "loss": 0.0018,
      "step": 68180
    },
    {
      "epoch": 1.5153333333333334,
      "grad_norm": 0.22079651057720184,
      "learning_rate": 1.2116666666666669e-05,
      "loss": 0.0023,
      "step": 68190
    },
    {
      "epoch": 1.5155555555555555,
      "grad_norm": 0.4692467749118805,
      "learning_rate": 1.2111111111111112e-05,
      "loss": 0.0018,
      "step": 68200
    },
    {
      "epoch": 1.5157777777777777,
      "grad_norm": 0.24215978384017944,
      "learning_rate": 1.2105555555555556e-05,
      "loss": 0.0018,
      "step": 68210
    },
    {
      "epoch": 1.516,
      "grad_norm": 0.46268561482429504,
      "learning_rate": 1.2100000000000001e-05,
      "loss": 0.0022,
      "step": 68220
    },
    {
      "epoch": 1.5162222222222224,
      "grad_norm": 0.450587660074234,
      "learning_rate": 1.2094444444444445e-05,
      "loss": 0.0017,
      "step": 68230
    },
    {
      "epoch": 1.5164444444444445,
      "grad_norm": 0.3003231883049011,
      "learning_rate": 1.208888888888889e-05,
      "loss": 0.0033,
      "step": 68240
    },
    {
      "epoch": 1.5166666666666666,
      "grad_norm": 0.13340768218040466,
      "learning_rate": 1.2083333333333333e-05,
      "loss": 0.0019,
      "step": 68250
    },
    {
      "epoch": 1.516888888888889,
      "grad_norm": 0.07017598301172256,
      "learning_rate": 1.2077777777777779e-05,
      "loss": 0.0019,
      "step": 68260
    },
    {
      "epoch": 1.517111111111111,
      "grad_norm": 0.47208157181739807,
      "learning_rate": 1.2072222222222222e-05,
      "loss": 0.0019,
      "step": 68270
    },
    {
      "epoch": 1.5173333333333332,
      "grad_norm": 0.06999372690916061,
      "learning_rate": 1.2066666666666667e-05,
      "loss": 0.0016,
      "step": 68280
    },
    {
      "epoch": 1.5175555555555555,
      "grad_norm": 0.18802738189697266,
      "learning_rate": 1.2061111111111113e-05,
      "loss": 0.0017,
      "step": 68290
    },
    {
      "epoch": 1.517777777777778,
      "grad_norm": 0.07642379403114319,
      "learning_rate": 1.2055555555555556e-05,
      "loss": 0.0019,
      "step": 68300
    },
    {
      "epoch": 1.518,
      "grad_norm": 0.08684278279542923,
      "learning_rate": 1.205e-05,
      "loss": 0.0024,
      "step": 68310
    },
    {
      "epoch": 1.5182222222222221,
      "grad_norm": 0.144283264875412,
      "learning_rate": 1.2044444444444445e-05,
      "loss": 0.0016,
      "step": 68320
    },
    {
      "epoch": 1.5184444444444445,
      "grad_norm": 0.37172210216522217,
      "learning_rate": 1.203888888888889e-05,
      "loss": 0.002,
      "step": 68330
    },
    {
      "epoch": 1.5186666666666668,
      "grad_norm": 0.34145820140838623,
      "learning_rate": 1.2033333333333334e-05,
      "loss": 0.0018,
      "step": 68340
    },
    {
      "epoch": 1.5188888888888887,
      "grad_norm": 0.6676668524742126,
      "learning_rate": 1.2027777777777777e-05,
      "loss": 0.0019,
      "step": 68350
    },
    {
      "epoch": 1.519111111111111,
      "grad_norm": 0.5494816899299622,
      "learning_rate": 1.2022222222222223e-05,
      "loss": 0.0019,
      "step": 68360
    },
    {
      "epoch": 1.5193333333333334,
      "grad_norm": 0.07750281691551208,
      "learning_rate": 1.2016666666666668e-05,
      "loss": 0.0022,
      "step": 68370
    },
    {
      "epoch": 1.5195555555555555,
      "grad_norm": 0.27865806221961975,
      "learning_rate": 1.2011111111111111e-05,
      "loss": 0.0016,
      "step": 68380
    },
    {
      "epoch": 1.5197777777777777,
      "grad_norm": 0.05991946533322334,
      "learning_rate": 1.2005555555555557e-05,
      "loss": 0.0026,
      "step": 68390
    },
    {
      "epoch": 1.52,
      "grad_norm": 0.403006911277771,
      "learning_rate": 1.2e-05,
      "loss": 0.0018,
      "step": 68400
    },
    {
      "epoch": 1.5202222222222224,
      "grad_norm": 0.2796662151813507,
      "learning_rate": 1.1994444444444446e-05,
      "loss": 0.0019,
      "step": 68410
    },
    {
      "epoch": 1.5204444444444445,
      "grad_norm": 0.18884745240211487,
      "learning_rate": 1.1988888888888889e-05,
      "loss": 0.0016,
      "step": 68420
    },
    {
      "epoch": 1.5206666666666666,
      "grad_norm": 0.09859376400709152,
      "learning_rate": 1.1983333333333334e-05,
      "loss": 0.0019,
      "step": 68430
    },
    {
      "epoch": 1.520888888888889,
      "grad_norm": 0.1691758781671524,
      "learning_rate": 1.1977777777777778e-05,
      "loss": 0.0018,
      "step": 68440
    },
    {
      "epoch": 1.521111111111111,
      "grad_norm": 0.20481416583061218,
      "learning_rate": 1.1972222222222221e-05,
      "loss": 0.0019,
      "step": 68450
    },
    {
      "epoch": 1.5213333333333332,
      "grad_norm": 0.3163608908653259,
      "learning_rate": 1.1966666666666668e-05,
      "loss": 0.0024,
      "step": 68460
    },
    {
      "epoch": 1.5215555555555556,
      "grad_norm": 0.1769404262304306,
      "learning_rate": 1.1961111111111112e-05,
      "loss": 0.0015,
      "step": 68470
    },
    {
      "epoch": 1.521777777777778,
      "grad_norm": 0.2793700695037842,
      "learning_rate": 1.1955555555555556e-05,
      "loss": 0.0017,
      "step": 68480
    },
    {
      "epoch": 1.522,
      "grad_norm": 0.20920692384243011,
      "learning_rate": 1.195e-05,
      "loss": 0.0022,
      "step": 68490
    },
    {
      "epoch": 1.5222222222222221,
      "grad_norm": 0.21878129243850708,
      "learning_rate": 1.1944444444444446e-05,
      "loss": 0.0029,
      "step": 68500
    },
    {
      "epoch": 1.5224444444444445,
      "grad_norm": 0.07528647035360336,
      "learning_rate": 1.193888888888889e-05,
      "loss": 0.0019,
      "step": 68510
    },
    {
      "epoch": 1.5226666666666666,
      "grad_norm": 0.42718198895454407,
      "learning_rate": 1.1933333333333333e-05,
      "loss": 0.0025,
      "step": 68520
    },
    {
      "epoch": 1.5228888888888887,
      "grad_norm": 0.6401267647743225,
      "learning_rate": 1.1927777777777778e-05,
      "loss": 0.0019,
      "step": 68530
    },
    {
      "epoch": 1.523111111111111,
      "grad_norm": 0.49771732091903687,
      "learning_rate": 1.1922222222222222e-05,
      "loss": 0.002,
      "step": 68540
    },
    {
      "epoch": 1.5233333333333334,
      "grad_norm": 0.368134081363678,
      "learning_rate": 1.1916666666666667e-05,
      "loss": 0.002,
      "step": 68550
    },
    {
      "epoch": 1.5235555555555556,
      "grad_norm": 0.07168009132146835,
      "learning_rate": 1.1911111111111112e-05,
      "loss": 0.003,
      "step": 68560
    },
    {
      "epoch": 1.5237777777777777,
      "grad_norm": 0.09514745324850082,
      "learning_rate": 1.1905555555555556e-05,
      "loss": 0.0024,
      "step": 68570
    },
    {
      "epoch": 1.524,
      "grad_norm": 0.1441737562417984,
      "learning_rate": 1.19e-05,
      "loss": 0.002,
      "step": 68580
    },
    {
      "epoch": 1.5242222222222224,
      "grad_norm": 0.24175715446472168,
      "learning_rate": 1.1894444444444445e-05,
      "loss": 0.0023,
      "step": 68590
    },
    {
      "epoch": 1.5244444444444445,
      "grad_norm": 0.08840801566839218,
      "learning_rate": 1.188888888888889e-05,
      "loss": 0.0022,
      "step": 68600
    },
    {
      "epoch": 1.5246666666666666,
      "grad_norm": 0.06881673634052277,
      "learning_rate": 1.1883333333333334e-05,
      "loss": 0.0018,
      "step": 68610
    },
    {
      "epoch": 1.524888888888889,
      "grad_norm": 0.4394531548023224,
      "learning_rate": 1.1877777777777777e-05,
      "loss": 0.0018,
      "step": 68620
    },
    {
      "epoch": 1.525111111111111,
      "grad_norm": 0.15071670711040497,
      "learning_rate": 1.1872222222222224e-05,
      "loss": 0.0018,
      "step": 68630
    },
    {
      "epoch": 1.5253333333333332,
      "grad_norm": 0.1643131822347641,
      "learning_rate": 1.1866666666666668e-05,
      "loss": 0.0019,
      "step": 68640
    },
    {
      "epoch": 1.5255555555555556,
      "grad_norm": 0.2058085948228836,
      "learning_rate": 1.1861111111111111e-05,
      "loss": 0.0022,
      "step": 68650
    },
    {
      "epoch": 1.525777777777778,
      "grad_norm": 0.24607786536216736,
      "learning_rate": 1.1855555555555556e-05,
      "loss": 0.0028,
      "step": 68660
    },
    {
      "epoch": 1.526,
      "grad_norm": 0.12519586086273193,
      "learning_rate": 1.185e-05,
      "loss": 0.0017,
      "step": 68670
    },
    {
      "epoch": 1.5262222222222221,
      "grad_norm": 0.24980312585830688,
      "learning_rate": 1.1844444444444445e-05,
      "loss": 0.0026,
      "step": 68680
    },
    {
      "epoch": 1.5264444444444445,
      "grad_norm": 0.13681498169898987,
      "learning_rate": 1.1838888888888889e-05,
      "loss": 0.0018,
      "step": 68690
    },
    {
      "epoch": 1.5266666666666666,
      "grad_norm": 0.535731852054596,
      "learning_rate": 1.1833333333333334e-05,
      "loss": 0.0024,
      "step": 68700
    },
    {
      "epoch": 1.5268888888888887,
      "grad_norm": 0.4700430929660797,
      "learning_rate": 1.1827777777777778e-05,
      "loss": 0.0036,
      "step": 68710
    },
    {
      "epoch": 1.527111111111111,
      "grad_norm": 0.04287802800536156,
      "learning_rate": 1.1822222222222223e-05,
      "loss": 0.0017,
      "step": 68720
    },
    {
      "epoch": 1.5273333333333334,
      "grad_norm": 0.2881823182106018,
      "learning_rate": 1.1816666666666668e-05,
      "loss": 0.0022,
      "step": 68730
    },
    {
      "epoch": 1.5275555555555556,
      "grad_norm": 0.2463540881872177,
      "learning_rate": 1.1811111111111112e-05,
      "loss": 0.0021,
      "step": 68740
    },
    {
      "epoch": 1.5277777777777777,
      "grad_norm": 0.457694947719574,
      "learning_rate": 1.1805555555555555e-05,
      "loss": 0.0019,
      "step": 68750
    },
    {
      "epoch": 1.528,
      "grad_norm": 0.3042784631252289,
      "learning_rate": 1.18e-05,
      "loss": 0.0017,
      "step": 68760
    },
    {
      "epoch": 1.5282222222222224,
      "grad_norm": 0.2033255249261856,
      "learning_rate": 1.1794444444444446e-05,
      "loss": 0.0023,
      "step": 68770
    },
    {
      "epoch": 1.5284444444444445,
      "grad_norm": 0.1292862445116043,
      "learning_rate": 1.178888888888889e-05,
      "loss": 0.0027,
      "step": 68780
    },
    {
      "epoch": 1.5286666666666666,
      "grad_norm": 0.07913338392972946,
      "learning_rate": 1.1783333333333333e-05,
      "loss": 0.0027,
      "step": 68790
    },
    {
      "epoch": 1.528888888888889,
      "grad_norm": 0.4306260049343109,
      "learning_rate": 1.1777777777777778e-05,
      "loss": 0.0019,
      "step": 68800
    },
    {
      "epoch": 1.529111111111111,
      "grad_norm": 0.32966506481170654,
      "learning_rate": 1.1772222222222223e-05,
      "loss": 0.0019,
      "step": 68810
    },
    {
      "epoch": 1.5293333333333332,
      "grad_norm": 0.14145274460315704,
      "learning_rate": 1.1766666666666667e-05,
      "loss": 0.0022,
      "step": 68820
    },
    {
      "epoch": 1.5295555555555556,
      "grad_norm": 0.3057129383087158,
      "learning_rate": 1.1761111111111112e-05,
      "loss": 0.0017,
      "step": 68830
    },
    {
      "epoch": 1.529777777777778,
      "grad_norm": 0.21750298142433167,
      "learning_rate": 1.1755555555555556e-05,
      "loss": 0.0025,
      "step": 68840
    },
    {
      "epoch": 1.53,
      "grad_norm": 0.07293576002120972,
      "learning_rate": 1.175e-05,
      "loss": 0.0017,
      "step": 68850
    },
    {
      "epoch": 1.5302222222222222,
      "grad_norm": 0.1827227771282196,
      "learning_rate": 1.1744444444444446e-05,
      "loss": 0.0027,
      "step": 68860
    },
    {
      "epoch": 1.5304444444444445,
      "grad_norm": 0.1650545299053192,
      "learning_rate": 1.173888888888889e-05,
      "loss": 0.0018,
      "step": 68870
    },
    {
      "epoch": 1.5306666666666666,
      "grad_norm": 0.07656241953372955,
      "learning_rate": 1.1733333333333333e-05,
      "loss": 0.0017,
      "step": 68880
    },
    {
      "epoch": 1.5308888888888887,
      "grad_norm": 0.24410392343997955,
      "learning_rate": 1.1727777777777779e-05,
      "loss": 0.0018,
      "step": 68890
    },
    {
      "epoch": 1.531111111111111,
      "grad_norm": 0.38801831007003784,
      "learning_rate": 1.1722222222222224e-05,
      "loss": 0.0027,
      "step": 68900
    },
    {
      "epoch": 1.5313333333333334,
      "grad_norm": 0.33047226071357727,
      "learning_rate": 1.1716666666666667e-05,
      "loss": 0.0021,
      "step": 68910
    },
    {
      "epoch": 1.5315555555555556,
      "grad_norm": 0.11404962092638016,
      "learning_rate": 1.1711111111111111e-05,
      "loss": 0.0021,
      "step": 68920
    },
    {
      "epoch": 1.5317777777777777,
      "grad_norm": 0.08153045177459717,
      "learning_rate": 1.1705555555555556e-05,
      "loss": 0.002,
      "step": 68930
    },
    {
      "epoch": 1.532,
      "grad_norm": 0.15607677400112152,
      "learning_rate": 1.1700000000000001e-05,
      "loss": 0.0021,
      "step": 68940
    },
    {
      "epoch": 1.5322222222222224,
      "grad_norm": 0.14293473958969116,
      "learning_rate": 1.1694444444444445e-05,
      "loss": 0.0019,
      "step": 68950
    },
    {
      "epoch": 1.5324444444444445,
      "grad_norm": 0.281719446182251,
      "learning_rate": 1.168888888888889e-05,
      "loss": 0.0025,
      "step": 68960
    },
    {
      "epoch": 1.5326666666666666,
      "grad_norm": 0.341545432806015,
      "learning_rate": 1.1683333333333334e-05,
      "loss": 0.002,
      "step": 68970
    },
    {
      "epoch": 1.532888888888889,
      "grad_norm": 0.2769761383533478,
      "learning_rate": 1.1677777777777777e-05,
      "loss": 0.0023,
      "step": 68980
    },
    {
      "epoch": 1.533111111111111,
      "grad_norm": 0.23182447254657745,
      "learning_rate": 1.1672222222222223e-05,
      "loss": 0.0018,
      "step": 68990
    },
    {
      "epoch": 1.5333333333333332,
      "grad_norm": 0.1727450042963028,
      "learning_rate": 1.1666666666666668e-05,
      "loss": 0.0017,
      "step": 69000
    },
    {
      "epoch": 1.5335555555555556,
      "grad_norm": 0.12374468147754669,
      "learning_rate": 1.1661111111111111e-05,
      "loss": 0.0018,
      "step": 69010
    },
    {
      "epoch": 1.533777777777778,
      "grad_norm": 0.46755266189575195,
      "learning_rate": 1.1655555555555555e-05,
      "loss": 0.0022,
      "step": 69020
    },
    {
      "epoch": 1.534,
      "grad_norm": 0.6215280890464783,
      "learning_rate": 1.1650000000000002e-05,
      "loss": 0.0018,
      "step": 69030
    },
    {
      "epoch": 1.5342222222222222,
      "grad_norm": 0.2916615903377533,
      "learning_rate": 1.1644444444444446e-05,
      "loss": 0.0017,
      "step": 69040
    },
    {
      "epoch": 1.5344444444444445,
      "grad_norm": 0.3013530373573303,
      "learning_rate": 1.1638888888888889e-05,
      "loss": 0.0028,
      "step": 69050
    },
    {
      "epoch": 1.5346666666666666,
      "grad_norm": 0.10660212486982346,
      "learning_rate": 1.1633333333333334e-05,
      "loss": 0.0029,
      "step": 69060
    },
    {
      "epoch": 1.5348888888888887,
      "grad_norm": 0.12765589356422424,
      "learning_rate": 1.1627777777777778e-05,
      "loss": 0.0016,
      "step": 69070
    },
    {
      "epoch": 1.535111111111111,
      "grad_norm": 0.22837267816066742,
      "learning_rate": 1.1622222222222223e-05,
      "loss": 0.0023,
      "step": 69080
    },
    {
      "epoch": 1.5353333333333334,
      "grad_norm": 0.45099082589149475,
      "learning_rate": 1.1616666666666667e-05,
      "loss": 0.0026,
      "step": 69090
    },
    {
      "epoch": 1.5355555555555556,
      "grad_norm": 0.10234362632036209,
      "learning_rate": 1.1611111111111112e-05,
      "loss": 0.0026,
      "step": 69100
    },
    {
      "epoch": 1.5357777777777777,
      "grad_norm": 0.16816163063049316,
      "learning_rate": 1.1605555555555555e-05,
      "loss": 0.0026,
      "step": 69110
    },
    {
      "epoch": 1.536,
      "grad_norm": 0.23624971508979797,
      "learning_rate": 1.16e-05,
      "loss": 0.0029,
      "step": 69120
    },
    {
      "epoch": 1.5362222222222224,
      "grad_norm": 0.09360315650701523,
      "learning_rate": 1.1594444444444446e-05,
      "loss": 0.0017,
      "step": 69130
    },
    {
      "epoch": 1.5364444444444443,
      "grad_norm": 0.10318342596292496,
      "learning_rate": 1.158888888888889e-05,
      "loss": 0.0018,
      "step": 69140
    },
    {
      "epoch": 1.5366666666666666,
      "grad_norm": 0.17099906504154205,
      "learning_rate": 1.1583333333333333e-05,
      "loss": 0.0022,
      "step": 69150
    },
    {
      "epoch": 1.536888888888889,
      "grad_norm": 0.06768271327018738,
      "learning_rate": 1.1577777777777778e-05,
      "loss": 0.002,
      "step": 69160
    },
    {
      "epoch": 1.537111111111111,
      "grad_norm": 0.1495966762304306,
      "learning_rate": 1.1572222222222224e-05,
      "loss": 0.0018,
      "step": 69170
    },
    {
      "epoch": 1.5373333333333332,
      "grad_norm": 0.3988904356956482,
      "learning_rate": 1.1566666666666667e-05,
      "loss": 0.0025,
      "step": 69180
    },
    {
      "epoch": 1.5375555555555556,
      "grad_norm": 0.3876115083694458,
      "learning_rate": 1.156111111111111e-05,
      "loss": 0.0017,
      "step": 69190
    },
    {
      "epoch": 1.537777777777778,
      "grad_norm": 0.12598741054534912,
      "learning_rate": 1.1555555555555556e-05,
      "loss": 0.0018,
      "step": 69200
    },
    {
      "epoch": 1.538,
      "grad_norm": 0.24555589258670807,
      "learning_rate": 1.1550000000000001e-05,
      "loss": 0.0036,
      "step": 69210
    },
    {
      "epoch": 1.5382222222222222,
      "grad_norm": 0.3702501654624939,
      "learning_rate": 1.1544444444444445e-05,
      "loss": 0.0023,
      "step": 69220
    },
    {
      "epoch": 1.5384444444444445,
      "grad_norm": 0.20798423886299133,
      "learning_rate": 1.153888888888889e-05,
      "loss": 0.0027,
      "step": 69230
    },
    {
      "epoch": 1.5386666666666666,
      "grad_norm": 0.3780424892902374,
      "learning_rate": 1.1533333333333334e-05,
      "loss": 0.0018,
      "step": 69240
    },
    {
      "epoch": 1.5388888888888888,
      "grad_norm": 0.155075803399086,
      "learning_rate": 1.1527777777777779e-05,
      "loss": 0.002,
      "step": 69250
    },
    {
      "epoch": 1.539111111111111,
      "grad_norm": 0.9358659386634827,
      "learning_rate": 1.1522222222222222e-05,
      "loss": 0.0021,
      "step": 69260
    },
    {
      "epoch": 1.5393333333333334,
      "grad_norm": 0.0775262638926506,
      "learning_rate": 1.1516666666666668e-05,
      "loss": 0.0025,
      "step": 69270
    },
    {
      "epoch": 1.5395555555555556,
      "grad_norm": 0.19221055507659912,
      "learning_rate": 1.1511111111111111e-05,
      "loss": 0.0027,
      "step": 69280
    },
    {
      "epoch": 1.5397777777777777,
      "grad_norm": 0.4936845898628235,
      "learning_rate": 1.1505555555555555e-05,
      "loss": 0.0026,
      "step": 69290
    },
    {
      "epoch": 1.54,
      "grad_norm": 0.08701006323099136,
      "learning_rate": 1.1500000000000002e-05,
      "loss": 0.0028,
      "step": 69300
    },
    {
      "epoch": 1.5402222222222224,
      "grad_norm": 0.07828322798013687,
      "learning_rate": 1.1494444444444445e-05,
      "loss": 0.0025,
      "step": 69310
    },
    {
      "epoch": 1.5404444444444443,
      "grad_norm": 0.17653189599514008,
      "learning_rate": 1.1488888888888889e-05,
      "loss": 0.0024,
      "step": 69320
    },
    {
      "epoch": 1.5406666666666666,
      "grad_norm": 0.2330385446548462,
      "learning_rate": 1.1483333333333334e-05,
      "loss": 0.0018,
      "step": 69330
    },
    {
      "epoch": 1.540888888888889,
      "grad_norm": 0.1278318464756012,
      "learning_rate": 1.147777777777778e-05,
      "loss": 0.0019,
      "step": 69340
    },
    {
      "epoch": 1.541111111111111,
      "grad_norm": 0.07616914808750153,
      "learning_rate": 1.1472222222222223e-05,
      "loss": 0.0019,
      "step": 69350
    },
    {
      "epoch": 1.5413333333333332,
      "grad_norm": 0.2009781152009964,
      "learning_rate": 1.1466666666666666e-05,
      "loss": 0.0017,
      "step": 69360
    },
    {
      "epoch": 1.5415555555555556,
      "grad_norm": 0.34200504422187805,
      "learning_rate": 1.1461111111111112e-05,
      "loss": 0.0024,
      "step": 69370
    },
    {
      "epoch": 1.541777777777778,
      "grad_norm": 0.2301107794046402,
      "learning_rate": 1.1455555555555555e-05,
      "loss": 0.0018,
      "step": 69380
    },
    {
      "epoch": 1.542,
      "grad_norm": 0.14837004244327545,
      "learning_rate": 1.145e-05,
      "loss": 0.0019,
      "step": 69390
    },
    {
      "epoch": 1.5422222222222222,
      "grad_norm": 0.352230966091156,
      "learning_rate": 1.1444444444444446e-05,
      "loss": 0.0023,
      "step": 69400
    },
    {
      "epoch": 1.5424444444444445,
      "grad_norm": 0.15496812760829926,
      "learning_rate": 1.143888888888889e-05,
      "loss": 0.002,
      "step": 69410
    },
    {
      "epoch": 1.5426666666666666,
      "grad_norm": 0.45305755734443665,
      "learning_rate": 1.1433333333333333e-05,
      "loss": 0.0024,
      "step": 69420
    },
    {
      "epoch": 1.5428888888888888,
      "grad_norm": 0.3202114999294281,
      "learning_rate": 1.1427777777777778e-05,
      "loss": 0.0019,
      "step": 69430
    },
    {
      "epoch": 1.543111111111111,
      "grad_norm": 0.07569301128387451,
      "learning_rate": 1.1422222222222223e-05,
      "loss": 0.0023,
      "step": 69440
    },
    {
      "epoch": 1.5433333333333334,
      "grad_norm": 0.45432859659194946,
      "learning_rate": 1.1416666666666667e-05,
      "loss": 0.0018,
      "step": 69450
    },
    {
      "epoch": 1.5435555555555556,
      "grad_norm": 0.3627175986766815,
      "learning_rate": 1.141111111111111e-05,
      "loss": 0.0034,
      "step": 69460
    },
    {
      "epoch": 1.5437777777777777,
      "grad_norm": 0.18014204502105713,
      "learning_rate": 1.1405555555555556e-05,
      "loss": 0.0023,
      "step": 69470
    },
    {
      "epoch": 1.544,
      "grad_norm": 0.2791805863380432,
      "learning_rate": 1.1400000000000001e-05,
      "loss": 0.0028,
      "step": 69480
    },
    {
      "epoch": 1.5442222222222224,
      "grad_norm": 0.12031718343496323,
      "learning_rate": 1.1394444444444445e-05,
      "loss": 0.0031,
      "step": 69490
    },
    {
      "epoch": 1.5444444444444443,
      "grad_norm": 0.357871949672699,
      "learning_rate": 1.138888888888889e-05,
      "loss": 0.0017,
      "step": 69500
    },
    {
      "epoch": 1.5446666666666666,
      "grad_norm": 0.20778442919254303,
      "learning_rate": 1.1383333333333333e-05,
      "loss": 0.0022,
      "step": 69510
    },
    {
      "epoch": 1.544888888888889,
      "grad_norm": 0.2653700113296509,
      "learning_rate": 1.1377777777777779e-05,
      "loss": 0.0018,
      "step": 69520
    },
    {
      "epoch": 1.545111111111111,
      "grad_norm": 0.44293317198753357,
      "learning_rate": 1.1372222222222224e-05,
      "loss": 0.0018,
      "step": 69530
    },
    {
      "epoch": 1.5453333333333332,
      "grad_norm": 0.18592171370983124,
      "learning_rate": 1.1366666666666667e-05,
      "loss": 0.0023,
      "step": 69540
    },
    {
      "epoch": 1.5455555555555556,
      "grad_norm": 0.29159003496170044,
      "learning_rate": 1.1361111111111111e-05,
      "loss": 0.0019,
      "step": 69550
    },
    {
      "epoch": 1.545777777777778,
      "grad_norm": 0.29290276765823364,
      "learning_rate": 1.1355555555555556e-05,
      "loss": 0.0017,
      "step": 69560
    },
    {
      "epoch": 1.546,
      "grad_norm": 0.2082609087228775,
      "learning_rate": 1.1350000000000001e-05,
      "loss": 0.0016,
      "step": 69570
    },
    {
      "epoch": 1.5462222222222222,
      "grad_norm": 0.077191561460495,
      "learning_rate": 1.1344444444444445e-05,
      "loss": 0.002,
      "step": 69580
    },
    {
      "epoch": 1.5464444444444445,
      "grad_norm": 0.11270733922719955,
      "learning_rate": 1.1338888888888889e-05,
      "loss": 0.0018,
      "step": 69590
    },
    {
      "epoch": 1.5466666666666666,
      "grad_norm": 0.07955504953861237,
      "learning_rate": 1.1333333333333334e-05,
      "loss": 0.0021,
      "step": 69600
    },
    {
      "epoch": 1.5468888888888888,
      "grad_norm": 0.14527928829193115,
      "learning_rate": 1.1327777777777779e-05,
      "loss": 0.0024,
      "step": 69610
    },
    {
      "epoch": 1.547111111111111,
      "grad_norm": 0.42992955446243286,
      "learning_rate": 1.1322222222222223e-05,
      "loss": 0.002,
      "step": 69620
    },
    {
      "epoch": 1.5473333333333334,
      "grad_norm": 0.306508868932724,
      "learning_rate": 1.1316666666666668e-05,
      "loss": 0.0034,
      "step": 69630
    },
    {
      "epoch": 1.5475555555555556,
      "grad_norm": 0.6357447504997253,
      "learning_rate": 1.1311111111111111e-05,
      "loss": 0.0023,
      "step": 69640
    },
    {
      "epoch": 1.5477777777777777,
      "grad_norm": 0.13591007888317108,
      "learning_rate": 1.1305555555555557e-05,
      "loss": 0.0025,
      "step": 69650
    },
    {
      "epoch": 1.548,
      "grad_norm": 0.16386164724826813,
      "learning_rate": 1.13e-05,
      "loss": 0.0027,
      "step": 69660
    },
    {
      "epoch": 1.5482222222222224,
      "grad_norm": 0.5544676184654236,
      "learning_rate": 1.1294444444444445e-05,
      "loss": 0.0023,
      "step": 69670
    },
    {
      "epoch": 1.5484444444444443,
      "grad_norm": 0.08225139230489731,
      "learning_rate": 1.1288888888888889e-05,
      "loss": 0.002,
      "step": 69680
    },
    {
      "epoch": 1.5486666666666666,
      "grad_norm": 0.2367265373468399,
      "learning_rate": 1.1283333333333333e-05,
      "loss": 0.0024,
      "step": 69690
    },
    {
      "epoch": 1.548888888888889,
      "grad_norm": 0.5460788011550903,
      "learning_rate": 1.127777777777778e-05,
      "loss": 0.0026,
      "step": 69700
    },
    {
      "epoch": 1.549111111111111,
      "grad_norm": 0.2532104551792145,
      "learning_rate": 1.1272222222222223e-05,
      "loss": 0.0028,
      "step": 69710
    },
    {
      "epoch": 1.5493333333333332,
      "grad_norm": 0.4444601237773895,
      "learning_rate": 1.1266666666666667e-05,
      "loss": 0.002,
      "step": 69720
    },
    {
      "epoch": 1.5495555555555556,
      "grad_norm": 0.5823292136192322,
      "learning_rate": 1.1261111111111112e-05,
      "loss": 0.0035,
      "step": 69730
    },
    {
      "epoch": 1.549777777777778,
      "grad_norm": 0.41627684235572815,
      "learning_rate": 1.1255555555555557e-05,
      "loss": 0.0022,
      "step": 69740
    },
    {
      "epoch": 1.55,
      "grad_norm": 0.24384759366512299,
      "learning_rate": 1.125e-05,
      "loss": 0.0027,
      "step": 69750
    },
    {
      "epoch": 1.5502222222222222,
      "grad_norm": 0.6608381867408752,
      "learning_rate": 1.1244444444444444e-05,
      "loss": 0.0027,
      "step": 69760
    },
    {
      "epoch": 1.5504444444444445,
      "grad_norm": 0.07065069675445557,
      "learning_rate": 1.123888888888889e-05,
      "loss": 0.002,
      "step": 69770
    },
    {
      "epoch": 1.5506666666666666,
      "grad_norm": 0.21256332099437714,
      "learning_rate": 1.1233333333333333e-05,
      "loss": 0.0027,
      "step": 69780
    },
    {
      "epoch": 1.5508888888888888,
      "grad_norm": 0.23345504701137543,
      "learning_rate": 1.1227777777777778e-05,
      "loss": 0.003,
      "step": 69790
    },
    {
      "epoch": 1.551111111111111,
      "grad_norm": 0.32922157645225525,
      "learning_rate": 1.1222222222222224e-05,
      "loss": 0.0017,
      "step": 69800
    },
    {
      "epoch": 1.5513333333333335,
      "grad_norm": 0.247517928481102,
      "learning_rate": 1.1216666666666667e-05,
      "loss": 0.0021,
      "step": 69810
    },
    {
      "epoch": 1.5515555555555556,
      "grad_norm": 0.4953915774822235,
      "learning_rate": 1.121111111111111e-05,
      "loss": 0.0019,
      "step": 69820
    },
    {
      "epoch": 1.5517777777777777,
      "grad_norm": 0.4649352729320526,
      "learning_rate": 1.1205555555555556e-05,
      "loss": 0.0016,
      "step": 69830
    },
    {
      "epoch": 1.552,
      "grad_norm": 0.24500370025634766,
      "learning_rate": 1.1200000000000001e-05,
      "loss": 0.003,
      "step": 69840
    },
    {
      "epoch": 1.5522222222222222,
      "grad_norm": 0.3704703748226166,
      "learning_rate": 1.1194444444444445e-05,
      "loss": 0.0019,
      "step": 69850
    },
    {
      "epoch": 1.5524444444444443,
      "grad_norm": 0.07427787035703659,
      "learning_rate": 1.1188888888888888e-05,
      "loss": 0.0021,
      "step": 69860
    },
    {
      "epoch": 1.5526666666666666,
      "grad_norm": 0.19737029075622559,
      "learning_rate": 1.1183333333333335e-05,
      "loss": 0.0019,
      "step": 69870
    },
    {
      "epoch": 1.552888888888889,
      "grad_norm": 0.3915218412876129,
      "learning_rate": 1.1177777777777779e-05,
      "loss": 0.0026,
      "step": 69880
    },
    {
      "epoch": 1.553111111111111,
      "grad_norm": 0.2147294282913208,
      "learning_rate": 1.1172222222222222e-05,
      "loss": 0.002,
      "step": 69890
    },
    {
      "epoch": 1.5533333333333332,
      "grad_norm": 0.3001452088356018,
      "learning_rate": 1.1166666666666668e-05,
      "loss": 0.002,
      "step": 69900
    },
    {
      "epoch": 1.5535555555555556,
      "grad_norm": 0.2032005339860916,
      "learning_rate": 1.1161111111111111e-05,
      "loss": 0.0021,
      "step": 69910
    },
    {
      "epoch": 1.553777777777778,
      "grad_norm": 0.13451267778873444,
      "learning_rate": 1.1155555555555556e-05,
      "loss": 0.002,
      "step": 69920
    },
    {
      "epoch": 1.554,
      "grad_norm": 0.08596843481063843,
      "learning_rate": 1.115e-05,
      "loss": 0.0041,
      "step": 69930
    },
    {
      "epoch": 1.5542222222222222,
      "grad_norm": 0.06316698342561722,
      "learning_rate": 1.1144444444444445e-05,
      "loss": 0.0022,
      "step": 69940
    },
    {
      "epoch": 1.5544444444444445,
      "grad_norm": 0.25578251481056213,
      "learning_rate": 1.1138888888888889e-05,
      "loss": 0.0027,
      "step": 69950
    },
    {
      "epoch": 1.5546666666666666,
      "grad_norm": 0.1932913213968277,
      "learning_rate": 1.1133333333333334e-05,
      "loss": 0.0027,
      "step": 69960
    },
    {
      "epoch": 1.5548888888888888,
      "grad_norm": 0.058710042387247086,
      "learning_rate": 1.112777777777778e-05,
      "loss": 0.0027,
      "step": 69970
    },
    {
      "epoch": 1.555111111111111,
      "grad_norm": 0.2332143485546112,
      "learning_rate": 1.1122222222222223e-05,
      "loss": 0.0025,
      "step": 69980
    },
    {
      "epoch": 1.5553333333333335,
      "grad_norm": 0.16463391482830048,
      "learning_rate": 1.1116666666666666e-05,
      "loss": 0.0028,
      "step": 69990
    },
    {
      "epoch": 1.5555555555555556,
      "grad_norm": 0.29327237606048584,
      "learning_rate": 1.1111111111111112e-05,
      "loss": 0.0023,
      "step": 70000
    },
    {
      "epoch": 1.5557777777777777,
      "grad_norm": 0.27458456158638,
      "learning_rate": 1.1105555555555557e-05,
      "loss": 0.0021,
      "step": 70010
    },
    {
      "epoch": 1.556,
      "grad_norm": 0.05201343446969986,
      "learning_rate": 1.11e-05,
      "loss": 0.0018,
      "step": 70020
    },
    {
      "epoch": 1.5562222222222222,
      "grad_norm": 0.17092636227607727,
      "learning_rate": 1.1094444444444444e-05,
      "loss": 0.0029,
      "step": 70030
    },
    {
      "epoch": 1.5564444444444443,
      "grad_norm": 0.11078909784555435,
      "learning_rate": 1.108888888888889e-05,
      "loss": 0.0031,
      "step": 70040
    },
    {
      "epoch": 1.5566666666666666,
      "grad_norm": 0.38358360528945923,
      "learning_rate": 1.1083333333333335e-05,
      "loss": 0.0018,
      "step": 70050
    },
    {
      "epoch": 1.556888888888889,
      "grad_norm": 0.16790799796581268,
      "learning_rate": 1.1077777777777778e-05,
      "loss": 0.0018,
      "step": 70060
    },
    {
      "epoch": 1.5571111111111111,
      "grad_norm": 0.15447856485843658,
      "learning_rate": 1.1072222222222223e-05,
      "loss": 0.0019,
      "step": 70070
    },
    {
      "epoch": 1.5573333333333332,
      "grad_norm": 0.25611045956611633,
      "learning_rate": 1.1066666666666667e-05,
      "loss": 0.0019,
      "step": 70080
    },
    {
      "epoch": 1.5575555555555556,
      "grad_norm": 0.23219193518161774,
      "learning_rate": 1.106111111111111e-05,
      "loss": 0.0018,
      "step": 70090
    },
    {
      "epoch": 1.557777777777778,
      "grad_norm": 0.08767546713352203,
      "learning_rate": 1.1055555555555556e-05,
      "loss": 0.0019,
      "step": 70100
    },
    {
      "epoch": 1.558,
      "grad_norm": 0.2741464674472809,
      "learning_rate": 1.1050000000000001e-05,
      "loss": 0.0017,
      "step": 70110
    },
    {
      "epoch": 1.5582222222222222,
      "grad_norm": 0.28616219758987427,
      "learning_rate": 1.1044444444444444e-05,
      "loss": 0.0019,
      "step": 70120
    },
    {
      "epoch": 1.5584444444444445,
      "grad_norm": 0.3453766107559204,
      "learning_rate": 1.103888888888889e-05,
      "loss": 0.0017,
      "step": 70130
    },
    {
      "epoch": 1.5586666666666666,
      "grad_norm": 0.05880746617913246,
      "learning_rate": 1.1033333333333335e-05,
      "loss": 0.0027,
      "step": 70140
    },
    {
      "epoch": 1.5588888888888888,
      "grad_norm": 0.09687913209199905,
      "learning_rate": 1.1027777777777779e-05,
      "loss": 0.0025,
      "step": 70150
    },
    {
      "epoch": 1.5591111111111111,
      "grad_norm": 0.4391968846321106,
      "learning_rate": 1.1022222222222222e-05,
      "loss": 0.0022,
      "step": 70160
    },
    {
      "epoch": 1.5593333333333335,
      "grad_norm": 0.30298691987991333,
      "learning_rate": 1.1016666666666667e-05,
      "loss": 0.0018,
      "step": 70170
    },
    {
      "epoch": 1.5595555555555556,
      "grad_norm": 0.3992421627044678,
      "learning_rate": 1.1011111111111113e-05,
      "loss": 0.002,
      "step": 70180
    },
    {
      "epoch": 1.5597777777777777,
      "grad_norm": 0.0975058525800705,
      "learning_rate": 1.1005555555555556e-05,
      "loss": 0.0023,
      "step": 70190
    },
    {
      "epoch": 1.56,
      "grad_norm": 0.16658657789230347,
      "learning_rate": 1.1000000000000001e-05,
      "loss": 0.0021,
      "step": 70200
    },
    {
      "epoch": 1.5602222222222222,
      "grad_norm": 0.35720500349998474,
      "learning_rate": 1.0994444444444445e-05,
      "loss": 0.002,
      "step": 70210
    },
    {
      "epoch": 1.5604444444444443,
      "grad_norm": 0.2648565471172333,
      "learning_rate": 1.0988888888888889e-05,
      "loss": 0.0017,
      "step": 70220
    },
    {
      "epoch": 1.5606666666666666,
      "grad_norm": 0.07048896700143814,
      "learning_rate": 1.0983333333333334e-05,
      "loss": 0.0018,
      "step": 70230
    },
    {
      "epoch": 1.560888888888889,
      "grad_norm": 0.08097627013921738,
      "learning_rate": 1.0977777777777779e-05,
      "loss": 0.002,
      "step": 70240
    },
    {
      "epoch": 1.5611111111111111,
      "grad_norm": 0.5504911541938782,
      "learning_rate": 1.0972222222222223e-05,
      "loss": 0.0019,
      "step": 70250
    },
    {
      "epoch": 1.5613333333333332,
      "grad_norm": 0.16215607523918152,
      "learning_rate": 1.0966666666666666e-05,
      "loss": 0.0023,
      "step": 70260
    },
    {
      "epoch": 1.5615555555555556,
      "grad_norm": 0.5784617066383362,
      "learning_rate": 1.0961111111111113e-05,
      "loss": 0.0018,
      "step": 70270
    },
    {
      "epoch": 1.561777777777778,
      "grad_norm": 0.2738032639026642,
      "learning_rate": 1.0955555555555557e-05,
      "loss": 0.0017,
      "step": 70280
    },
    {
      "epoch": 1.562,
      "grad_norm": 0.2442186027765274,
      "learning_rate": 1.095e-05,
      "loss": 0.0018,
      "step": 70290
    },
    {
      "epoch": 1.5622222222222222,
      "grad_norm": 0.47104600071907043,
      "learning_rate": 1.0944444444444445e-05,
      "loss": 0.0032,
      "step": 70300
    },
    {
      "epoch": 1.5624444444444445,
      "grad_norm": 0.07074066996574402,
      "learning_rate": 1.0938888888888889e-05,
      "loss": 0.002,
      "step": 70310
    },
    {
      "epoch": 1.5626666666666666,
      "grad_norm": 0.203822523355484,
      "learning_rate": 1.0933333333333334e-05,
      "loss": 0.0027,
      "step": 70320
    },
    {
      "epoch": 1.5628888888888888,
      "grad_norm": 0.4228949546813965,
      "learning_rate": 1.0927777777777778e-05,
      "loss": 0.0016,
      "step": 70330
    },
    {
      "epoch": 1.5631111111111111,
      "grad_norm": 0.3815050423145294,
      "learning_rate": 1.0922222222222223e-05,
      "loss": 0.0023,
      "step": 70340
    },
    {
      "epoch": 1.5633333333333335,
      "grad_norm": 0.08662910014390945,
      "learning_rate": 1.0916666666666667e-05,
      "loss": 0.002,
      "step": 70350
    },
    {
      "epoch": 1.5635555555555556,
      "grad_norm": 0.1859988421201706,
      "learning_rate": 1.0911111111111112e-05,
      "loss": 0.0025,
      "step": 70360
    },
    {
      "epoch": 1.5637777777777777,
      "grad_norm": 0.10327941924333572,
      "learning_rate": 1.0905555555555557e-05,
      "loss": 0.0016,
      "step": 70370
    },
    {
      "epoch": 1.564,
      "grad_norm": 0.4163077175617218,
      "learning_rate": 1.09e-05,
      "loss": 0.0021,
      "step": 70380
    },
    {
      "epoch": 1.5642222222222222,
      "grad_norm": 0.3114248216152191,
      "learning_rate": 1.0894444444444444e-05,
      "loss": 0.0025,
      "step": 70390
    },
    {
      "epoch": 1.5644444444444443,
      "grad_norm": 0.18739363551139832,
      "learning_rate": 1.088888888888889e-05,
      "loss": 0.0019,
      "step": 70400
    },
    {
      "epoch": 1.5646666666666667,
      "grad_norm": 0.5626564621925354,
      "learning_rate": 1.0883333333333335e-05,
      "loss": 0.0018,
      "step": 70410
    },
    {
      "epoch": 1.564888888888889,
      "grad_norm": 0.5641643404960632,
      "learning_rate": 1.0877777777777778e-05,
      "loss": 0.0023,
      "step": 70420
    },
    {
      "epoch": 1.5651111111111111,
      "grad_norm": 0.1978956162929535,
      "learning_rate": 1.0872222222222222e-05,
      "loss": 0.0021,
      "step": 70430
    },
    {
      "epoch": 1.5653333333333332,
      "grad_norm": 0.39790570735931396,
      "learning_rate": 1.0866666666666667e-05,
      "loss": 0.0026,
      "step": 70440
    },
    {
      "epoch": 1.5655555555555556,
      "grad_norm": 0.34291502833366394,
      "learning_rate": 1.0861111111111112e-05,
      "loss": 0.0024,
      "step": 70450
    },
    {
      "epoch": 1.565777777777778,
      "grad_norm": 0.20702075958251953,
      "learning_rate": 1.0855555555555556e-05,
      "loss": 0.0021,
      "step": 70460
    },
    {
      "epoch": 1.5659999999999998,
      "grad_norm": 0.3624277710914612,
      "learning_rate": 1.0850000000000001e-05,
      "loss": 0.0021,
      "step": 70470
    },
    {
      "epoch": 1.5662222222222222,
      "grad_norm": 0.15373431146144867,
      "learning_rate": 1.0844444444444445e-05,
      "loss": 0.002,
      "step": 70480
    },
    {
      "epoch": 1.5664444444444445,
      "grad_norm": 0.19808338582515717,
      "learning_rate": 1.083888888888889e-05,
      "loss": 0.0021,
      "step": 70490
    },
    {
      "epoch": 1.5666666666666667,
      "grad_norm": 0.23000195622444153,
      "learning_rate": 1.0833333333333334e-05,
      "loss": 0.0024,
      "step": 70500
    },
    {
      "epoch": 1.5668888888888888,
      "grad_norm": 0.11843735724687576,
      "learning_rate": 1.0827777777777779e-05,
      "loss": 0.0025,
      "step": 70510
    },
    {
      "epoch": 1.5671111111111111,
      "grad_norm": 0.35556861758232117,
      "learning_rate": 1.0822222222222222e-05,
      "loss": 0.0018,
      "step": 70520
    },
    {
      "epoch": 1.5673333333333335,
      "grad_norm": 0.41184690594673157,
      "learning_rate": 1.0816666666666666e-05,
      "loss": 0.0019,
      "step": 70530
    },
    {
      "epoch": 1.5675555555555556,
      "grad_norm": 0.2037024348974228,
      "learning_rate": 1.0811111111111113e-05,
      "loss": 0.002,
      "step": 70540
    },
    {
      "epoch": 1.5677777777777777,
      "grad_norm": 0.18518367409706116,
      "learning_rate": 1.0805555555555556e-05,
      "loss": 0.0023,
      "step": 70550
    },
    {
      "epoch": 1.568,
      "grad_norm": 0.3573508560657501,
      "learning_rate": 1.08e-05,
      "loss": 0.0026,
      "step": 70560
    },
    {
      "epoch": 1.5682222222222222,
      "grad_norm": 0.11704716086387634,
      "learning_rate": 1.0794444444444445e-05,
      "loss": 0.0018,
      "step": 70570
    },
    {
      "epoch": 1.5684444444444443,
      "grad_norm": 0.08339525014162064,
      "learning_rate": 1.078888888888889e-05,
      "loss": 0.0021,
      "step": 70580
    },
    {
      "epoch": 1.5686666666666667,
      "grad_norm": 0.07938072085380554,
      "learning_rate": 1.0783333333333334e-05,
      "loss": 0.0019,
      "step": 70590
    },
    {
      "epoch": 1.568888888888889,
      "grad_norm": 0.2994384765625,
      "learning_rate": 1.0777777777777778e-05,
      "loss": 0.0033,
      "step": 70600
    },
    {
      "epoch": 1.5691111111111111,
      "grad_norm": 0.579371988773346,
      "learning_rate": 1.0772222222222223e-05,
      "loss": 0.0024,
      "step": 70610
    },
    {
      "epoch": 1.5693333333333332,
      "grad_norm": 0.31087806820869446,
      "learning_rate": 1.0766666666666666e-05,
      "loss": 0.0037,
      "step": 70620
    },
    {
      "epoch": 1.5695555555555556,
      "grad_norm": 0.26314976811408997,
      "learning_rate": 1.0761111111111112e-05,
      "loss": 0.0026,
      "step": 70630
    },
    {
      "epoch": 1.569777777777778,
      "grad_norm": 0.285740464925766,
      "learning_rate": 1.0755555555555557e-05,
      "loss": 0.002,
      "step": 70640
    },
    {
      "epoch": 1.5699999999999998,
      "grad_norm": 0.3312597870826721,
      "learning_rate": 1.075e-05,
      "loss": 0.0022,
      "step": 70650
    },
    {
      "epoch": 1.5702222222222222,
      "grad_norm": 0.15575401484966278,
      "learning_rate": 1.0744444444444444e-05,
      "loss": 0.0026,
      "step": 70660
    },
    {
      "epoch": 1.5704444444444445,
      "grad_norm": 0.24477703869342804,
      "learning_rate": 1.073888888888889e-05,
      "loss": 0.0017,
      "step": 70670
    },
    {
      "epoch": 1.5706666666666667,
      "grad_norm": 0.41484519839286804,
      "learning_rate": 1.0733333333333334e-05,
      "loss": 0.0021,
      "step": 70680
    },
    {
      "epoch": 1.5708888888888888,
      "grad_norm": 0.24409911036491394,
      "learning_rate": 1.0727777777777778e-05,
      "loss": 0.0024,
      "step": 70690
    },
    {
      "epoch": 1.5711111111111111,
      "grad_norm": 0.12137418985366821,
      "learning_rate": 1.0722222222222222e-05,
      "loss": 0.0025,
      "step": 70700
    },
    {
      "epoch": 1.5713333333333335,
      "grad_norm": 0.41315144300460815,
      "learning_rate": 1.0716666666666667e-05,
      "loss": 0.0023,
      "step": 70710
    },
    {
      "epoch": 1.5715555555555556,
      "grad_norm": 0.1369285136461258,
      "learning_rate": 1.0711111111111112e-05,
      "loss": 0.0017,
      "step": 70720
    },
    {
      "epoch": 1.5717777777777777,
      "grad_norm": 0.13548491895198822,
      "learning_rate": 1.0705555555555556e-05,
      "loss": 0.002,
      "step": 70730
    },
    {
      "epoch": 1.572,
      "grad_norm": 0.4503313899040222,
      "learning_rate": 1.0700000000000001e-05,
      "loss": 0.0027,
      "step": 70740
    },
    {
      "epoch": 1.5722222222222222,
      "grad_norm": 0.06868062168359756,
      "learning_rate": 1.0694444444444444e-05,
      "loss": 0.0016,
      "step": 70750
    },
    {
      "epoch": 1.5724444444444443,
      "grad_norm": 0.05160713940858841,
      "learning_rate": 1.068888888888889e-05,
      "loss": 0.0018,
      "step": 70760
    },
    {
      "epoch": 1.5726666666666667,
      "grad_norm": 0.40040236711502075,
      "learning_rate": 1.0683333333333333e-05,
      "loss": 0.0016,
      "step": 70770
    },
    {
      "epoch": 1.572888888888889,
      "grad_norm": 0.5001131296157837,
      "learning_rate": 1.0677777777777779e-05,
      "loss": 0.0016,
      "step": 70780
    },
    {
      "epoch": 1.5731111111111111,
      "grad_norm": 0.2642090320587158,
      "learning_rate": 1.0672222222222222e-05,
      "loss": 0.0019,
      "step": 70790
    },
    {
      "epoch": 1.5733333333333333,
      "grad_norm": 0.24848134815692902,
      "learning_rate": 1.0666666666666667e-05,
      "loss": 0.0023,
      "step": 70800
    },
    {
      "epoch": 1.5735555555555556,
      "grad_norm": 0.5015530586242676,
      "learning_rate": 1.0661111111111113e-05,
      "loss": 0.0018,
      "step": 70810
    },
    {
      "epoch": 1.573777777777778,
      "grad_norm": 0.28617358207702637,
      "learning_rate": 1.0655555555555556e-05,
      "loss": 0.002,
      "step": 70820
    },
    {
      "epoch": 1.5739999999999998,
      "grad_norm": 0.09127200394868851,
      "learning_rate": 1.065e-05,
      "loss": 0.0018,
      "step": 70830
    },
    {
      "epoch": 1.5742222222222222,
      "grad_norm": 0.09424306452274323,
      "learning_rate": 1.0644444444444445e-05,
      "loss": 0.0019,
      "step": 70840
    },
    {
      "epoch": 1.5744444444444445,
      "grad_norm": 0.3016897439956665,
      "learning_rate": 1.063888888888889e-05,
      "loss": 0.0016,
      "step": 70850
    },
    {
      "epoch": 1.5746666666666667,
      "grad_norm": 0.28527116775512695,
      "learning_rate": 1.0633333333333334e-05,
      "loss": 0.0024,
      "step": 70860
    },
    {
      "epoch": 1.5748888888888888,
      "grad_norm": 0.49789807200431824,
      "learning_rate": 1.0627777777777779e-05,
      "loss": 0.002,
      "step": 70870
    },
    {
      "epoch": 1.5751111111111111,
      "grad_norm": 0.2691621780395508,
      "learning_rate": 1.0622222222222223e-05,
      "loss": 0.0023,
      "step": 70880
    },
    {
      "epoch": 1.5753333333333335,
      "grad_norm": 0.32952818274497986,
      "learning_rate": 1.0616666666666668e-05,
      "loss": 0.002,
      "step": 70890
    },
    {
      "epoch": 1.5755555555555556,
      "grad_norm": 0.37733370065689087,
      "learning_rate": 1.0611111111111111e-05,
      "loss": 0.0022,
      "step": 70900
    },
    {
      "epoch": 1.5757777777777777,
      "grad_norm": 0.7112533450126648,
      "learning_rate": 1.0605555555555557e-05,
      "loss": 0.0025,
      "step": 70910
    },
    {
      "epoch": 1.576,
      "grad_norm": 0.06184396147727966,
      "learning_rate": 1.06e-05,
      "loss": 0.0029,
      "step": 70920
    },
    {
      "epoch": 1.5762222222222222,
      "grad_norm": 0.47836145758628845,
      "learning_rate": 1.0594444444444444e-05,
      "loss": 0.002,
      "step": 70930
    },
    {
      "epoch": 1.5764444444444443,
      "grad_norm": 0.1056211069226265,
      "learning_rate": 1.058888888888889e-05,
      "loss": 0.0018,
      "step": 70940
    },
    {
      "epoch": 1.5766666666666667,
      "grad_norm": 0.16241100430488586,
      "learning_rate": 1.0583333333333334e-05,
      "loss": 0.0024,
      "step": 70950
    },
    {
      "epoch": 1.576888888888889,
      "grad_norm": 0.08110542595386505,
      "learning_rate": 1.0577777777777778e-05,
      "loss": 0.0018,
      "step": 70960
    },
    {
      "epoch": 1.5771111111111111,
      "grad_norm": 0.28463244438171387,
      "learning_rate": 1.0572222222222223e-05,
      "loss": 0.0019,
      "step": 70970
    },
    {
      "epoch": 1.5773333333333333,
      "grad_norm": 0.40325990319252014,
      "learning_rate": 1.0566666666666668e-05,
      "loss": 0.0027,
      "step": 70980
    },
    {
      "epoch": 1.5775555555555556,
      "grad_norm": 0.37057071924209595,
      "learning_rate": 1.0561111111111112e-05,
      "loss": 0.0018,
      "step": 70990
    },
    {
      "epoch": 1.5777777777777777,
      "grad_norm": 0.23354242742061615,
      "learning_rate": 1.0555555555555555e-05,
      "loss": 0.0023,
      "step": 71000
    },
    {
      "epoch": 1.5779999999999998,
      "grad_norm": 0.259680837392807,
      "learning_rate": 1.055e-05,
      "loss": 0.0021,
      "step": 71010
    },
    {
      "epoch": 1.5782222222222222,
      "grad_norm": 0.27774739265441895,
      "learning_rate": 1.0544444444444444e-05,
      "loss": 0.0018,
      "step": 71020
    },
    {
      "epoch": 1.5784444444444445,
      "grad_norm": 0.17648561298847198,
      "learning_rate": 1.053888888888889e-05,
      "loss": 0.0025,
      "step": 71030
    },
    {
      "epoch": 1.5786666666666667,
      "grad_norm": 0.11817020922899246,
      "learning_rate": 1.0533333333333335e-05,
      "loss": 0.0019,
      "step": 71040
    },
    {
      "epoch": 1.5788888888888888,
      "grad_norm": 0.4557003974914551,
      "learning_rate": 1.0527777777777778e-05,
      "loss": 0.0018,
      "step": 71050
    },
    {
      "epoch": 1.5791111111111111,
      "grad_norm": 0.12400466203689575,
      "learning_rate": 1.0522222222222222e-05,
      "loss": 0.0021,
      "step": 71060
    },
    {
      "epoch": 1.5793333333333335,
      "grad_norm": 0.42975643277168274,
      "learning_rate": 1.0516666666666667e-05,
      "loss": 0.0016,
      "step": 71070
    },
    {
      "epoch": 1.5795555555555556,
      "grad_norm": 0.08868243545293808,
      "learning_rate": 1.0511111111111112e-05,
      "loss": 0.003,
      "step": 71080
    },
    {
      "epoch": 1.5797777777777777,
      "grad_norm": 0.1809167116880417,
      "learning_rate": 1.0505555555555556e-05,
      "loss": 0.0017,
      "step": 71090
    },
    {
      "epoch": 1.58,
      "grad_norm": 0.20196375250816345,
      "learning_rate": 1.05e-05,
      "loss": 0.0018,
      "step": 71100
    },
    {
      "epoch": 1.5802222222222222,
      "grad_norm": 0.21575890481472015,
      "learning_rate": 1.0494444444444446e-05,
      "loss": 0.0025,
      "step": 71110
    },
    {
      "epoch": 1.5804444444444443,
      "grad_norm": 0.08335697650909424,
      "learning_rate": 1.048888888888889e-05,
      "loss": 0.0017,
      "step": 71120
    },
    {
      "epoch": 1.5806666666666667,
      "grad_norm": 0.21444249153137207,
      "learning_rate": 1.0483333333333333e-05,
      "loss": 0.0022,
      "step": 71130
    },
    {
      "epoch": 1.580888888888889,
      "grad_norm": 0.06655922532081604,
      "learning_rate": 1.0477777777777779e-05,
      "loss": 0.0025,
      "step": 71140
    },
    {
      "epoch": 1.5811111111111111,
      "grad_norm": 0.08546949177980423,
      "learning_rate": 1.0472222222222222e-05,
      "loss": 0.0019,
      "step": 71150
    },
    {
      "epoch": 1.5813333333333333,
      "grad_norm": 0.5356103181838989,
      "learning_rate": 1.0466666666666668e-05,
      "loss": 0.0018,
      "step": 71160
    },
    {
      "epoch": 1.5815555555555556,
      "grad_norm": 0.32719749212265015,
      "learning_rate": 1.0461111111111111e-05,
      "loss": 0.0023,
      "step": 71170
    },
    {
      "epoch": 1.5817777777777777,
      "grad_norm": 0.09140340238809586,
      "learning_rate": 1.0455555555555556e-05,
      "loss": 0.0016,
      "step": 71180
    },
    {
      "epoch": 1.5819999999999999,
      "grad_norm": 0.3328641653060913,
      "learning_rate": 1.045e-05,
      "loss": 0.0017,
      "step": 71190
    },
    {
      "epoch": 1.5822222222222222,
      "grad_norm": 0.0656217634677887,
      "learning_rate": 1.0444444444444445e-05,
      "loss": 0.0023,
      "step": 71200
    },
    {
      "epoch": 1.5824444444444445,
      "grad_norm": 0.4659837782382965,
      "learning_rate": 1.043888888888889e-05,
      "loss": 0.0021,
      "step": 71210
    },
    {
      "epoch": 1.5826666666666667,
      "grad_norm": 0.632449209690094,
      "learning_rate": 1.0433333333333334e-05,
      "loss": 0.0023,
      "step": 71220
    },
    {
      "epoch": 1.5828888888888888,
      "grad_norm": 0.21050004661083221,
      "learning_rate": 1.0427777777777778e-05,
      "loss": 0.0018,
      "step": 71230
    },
    {
      "epoch": 1.5831111111111111,
      "grad_norm": 0.08449099212884903,
      "learning_rate": 1.0422222222222223e-05,
      "loss": 0.0027,
      "step": 71240
    },
    {
      "epoch": 1.5833333333333335,
      "grad_norm": 0.27828216552734375,
      "learning_rate": 1.0416666666666668e-05,
      "loss": 0.0037,
      "step": 71250
    },
    {
      "epoch": 1.5835555555555556,
      "grad_norm": 0.08140558749437332,
      "learning_rate": 1.0411111111111112e-05,
      "loss": 0.0017,
      "step": 71260
    },
    {
      "epoch": 1.5837777777777777,
      "grad_norm": 0.23148378729820251,
      "learning_rate": 1.0405555555555555e-05,
      "loss": 0.0022,
      "step": 71270
    },
    {
      "epoch": 1.584,
      "grad_norm": 0.08401628583669662,
      "learning_rate": 1.04e-05,
      "loss": 0.003,
      "step": 71280
    },
    {
      "epoch": 1.5842222222222222,
      "grad_norm": 0.1382838487625122,
      "learning_rate": 1.0394444444444446e-05,
      "loss": 0.0022,
      "step": 71290
    },
    {
      "epoch": 1.5844444444444443,
      "grad_norm": 0.30794668197631836,
      "learning_rate": 1.038888888888889e-05,
      "loss": 0.0023,
      "step": 71300
    },
    {
      "epoch": 1.5846666666666667,
      "grad_norm": 0.08420106023550034,
      "learning_rate": 1.0383333333333334e-05,
      "loss": 0.0018,
      "step": 71310
    },
    {
      "epoch": 1.584888888888889,
      "grad_norm": 0.22888554632663727,
      "learning_rate": 1.0377777777777778e-05,
      "loss": 0.0019,
      "step": 71320
    },
    {
      "epoch": 1.5851111111111111,
      "grad_norm": 0.8100765347480774,
      "learning_rate": 1.0372222222222222e-05,
      "loss": 0.0028,
      "step": 71330
    },
    {
      "epoch": 1.5853333333333333,
      "grad_norm": 0.126278355717659,
      "learning_rate": 1.0366666666666667e-05,
      "loss": 0.0028,
      "step": 71340
    },
    {
      "epoch": 1.5855555555555556,
      "grad_norm": 0.08341663330793381,
      "learning_rate": 1.0361111111111112e-05,
      "loss": 0.0018,
      "step": 71350
    },
    {
      "epoch": 1.5857777777777777,
      "grad_norm": 0.10008608549833298,
      "learning_rate": 1.0355555555555556e-05,
      "loss": 0.002,
      "step": 71360
    },
    {
      "epoch": 1.5859999999999999,
      "grad_norm": 0.0832832083106041,
      "learning_rate": 1.035e-05,
      "loss": 0.002,
      "step": 71370
    },
    {
      "epoch": 1.5862222222222222,
      "grad_norm": 0.21481600403785706,
      "learning_rate": 1.0344444444444446e-05,
      "loss": 0.003,
      "step": 71380
    },
    {
      "epoch": 1.5864444444444445,
      "grad_norm": 0.2755418121814728,
      "learning_rate": 1.033888888888889e-05,
      "loss": 0.0022,
      "step": 71390
    },
    {
      "epoch": 1.5866666666666667,
      "grad_norm": 0.10870768874883652,
      "learning_rate": 1.0333333333333333e-05,
      "loss": 0.002,
      "step": 71400
    },
    {
      "epoch": 1.5868888888888888,
      "grad_norm": 0.07669024914503098,
      "learning_rate": 1.0327777777777778e-05,
      "loss": 0.002,
      "step": 71410
    },
    {
      "epoch": 1.5871111111111111,
      "grad_norm": 0.35852622985839844,
      "learning_rate": 1.0322222222222224e-05,
      "loss": 0.0041,
      "step": 71420
    },
    {
      "epoch": 1.5873333333333335,
      "grad_norm": 0.2225513905286789,
      "learning_rate": 1.0316666666666667e-05,
      "loss": 0.0017,
      "step": 71430
    },
    {
      "epoch": 1.5875555555555556,
      "grad_norm": 0.19165197014808655,
      "learning_rate": 1.031111111111111e-05,
      "loss": 0.0019,
      "step": 71440
    },
    {
      "epoch": 1.5877777777777777,
      "grad_norm": 0.2442011684179306,
      "learning_rate": 1.0305555555555556e-05,
      "loss": 0.0018,
      "step": 71450
    },
    {
      "epoch": 1.588,
      "grad_norm": 0.3051624596118927,
      "learning_rate": 1.03e-05,
      "loss": 0.0017,
      "step": 71460
    },
    {
      "epoch": 1.5882222222222222,
      "grad_norm": 0.48102912306785583,
      "learning_rate": 1.0294444444444445e-05,
      "loss": 0.0037,
      "step": 71470
    },
    {
      "epoch": 1.5884444444444443,
      "grad_norm": 0.2881913185119629,
      "learning_rate": 1.028888888888889e-05,
      "loss": 0.0031,
      "step": 71480
    },
    {
      "epoch": 1.5886666666666667,
      "grad_norm": 0.25840938091278076,
      "learning_rate": 1.0283333333333334e-05,
      "loss": 0.002,
      "step": 71490
    },
    {
      "epoch": 1.588888888888889,
      "grad_norm": 0.2724844813346863,
      "learning_rate": 1.0277777777777777e-05,
      "loss": 0.0018,
      "step": 71500
    },
    {
      "epoch": 1.5891111111111111,
      "grad_norm": 0.33671683073043823,
      "learning_rate": 1.0272222222222224e-05,
      "loss": 0.0019,
      "step": 71510
    },
    {
      "epoch": 1.5893333333333333,
      "grad_norm": 0.16770969331264496,
      "learning_rate": 1.0266666666666668e-05,
      "loss": 0.002,
      "step": 71520
    },
    {
      "epoch": 1.5895555555555556,
      "grad_norm": 0.0768914669752121,
      "learning_rate": 1.0261111111111111e-05,
      "loss": 0.0019,
      "step": 71530
    },
    {
      "epoch": 1.5897777777777777,
      "grad_norm": 0.293438196182251,
      "learning_rate": 1.0255555555555557e-05,
      "loss": 0.0022,
      "step": 71540
    },
    {
      "epoch": 1.5899999999999999,
      "grad_norm": 0.2348201870918274,
      "learning_rate": 1.025e-05,
      "loss": 0.0019,
      "step": 71550
    },
    {
      "epoch": 1.5902222222222222,
      "grad_norm": 0.15816490352153778,
      "learning_rate": 1.0244444444444445e-05,
      "loss": 0.0025,
      "step": 71560
    },
    {
      "epoch": 1.5904444444444445,
      "grad_norm": 0.7219449877738953,
      "learning_rate": 1.0238888888888889e-05,
      "loss": 0.0032,
      "step": 71570
    },
    {
      "epoch": 1.5906666666666667,
      "grad_norm": 0.28913065791130066,
      "learning_rate": 1.0233333333333334e-05,
      "loss": 0.0019,
      "step": 71580
    },
    {
      "epoch": 1.5908888888888888,
      "grad_norm": 0.29805198311805725,
      "learning_rate": 1.0227777777777778e-05,
      "loss": 0.0017,
      "step": 71590
    },
    {
      "epoch": 1.5911111111111111,
      "grad_norm": 0.1170736774802208,
      "learning_rate": 1.0222222222222223e-05,
      "loss": 0.0019,
      "step": 71600
    },
    {
      "epoch": 1.5913333333333335,
      "grad_norm": 0.44830894470214844,
      "learning_rate": 1.0216666666666668e-05,
      "loss": 0.0019,
      "step": 71610
    },
    {
      "epoch": 1.5915555555555554,
      "grad_norm": 0.4813988208770752,
      "learning_rate": 1.0211111111111112e-05,
      "loss": 0.002,
      "step": 71620
    },
    {
      "epoch": 1.5917777777777777,
      "grad_norm": 0.2213660031557083,
      "learning_rate": 1.0205555555555555e-05,
      "loss": 0.0023,
      "step": 71630
    },
    {
      "epoch": 1.592,
      "grad_norm": 0.12207265943288803,
      "learning_rate": 1.02e-05,
      "loss": 0.0019,
      "step": 71640
    },
    {
      "epoch": 1.5922222222222222,
      "grad_norm": 0.18467557430267334,
      "learning_rate": 1.0194444444444446e-05,
      "loss": 0.002,
      "step": 71650
    },
    {
      "epoch": 1.5924444444444443,
      "grad_norm": 0.29634392261505127,
      "learning_rate": 1.018888888888889e-05,
      "loss": 0.0021,
      "step": 71660
    },
    {
      "epoch": 1.5926666666666667,
      "grad_norm": 0.08843641728162766,
      "learning_rate": 1.0183333333333333e-05,
      "loss": 0.0023,
      "step": 71670
    },
    {
      "epoch": 1.592888888888889,
      "grad_norm": 0.21403053402900696,
      "learning_rate": 1.0177777777777778e-05,
      "loss": 0.0021,
      "step": 71680
    },
    {
      "epoch": 1.5931111111111111,
      "grad_norm": 0.17975324392318726,
      "learning_rate": 1.0172222222222223e-05,
      "loss": 0.0021,
      "step": 71690
    },
    {
      "epoch": 1.5933333333333333,
      "grad_norm": 0.26437193155288696,
      "learning_rate": 1.0166666666666667e-05,
      "loss": 0.002,
      "step": 71700
    },
    {
      "epoch": 1.5935555555555556,
      "grad_norm": 0.27523887157440186,
      "learning_rate": 1.0161111111111112e-05,
      "loss": 0.0021,
      "step": 71710
    },
    {
      "epoch": 1.5937777777777777,
      "grad_norm": 0.09444943815469742,
      "learning_rate": 1.0155555555555556e-05,
      "loss": 0.0019,
      "step": 71720
    },
    {
      "epoch": 1.5939999999999999,
      "grad_norm": 0.1498006284236908,
      "learning_rate": 1.0150000000000001e-05,
      "loss": 0.0017,
      "step": 71730
    },
    {
      "epoch": 1.5942222222222222,
      "grad_norm": 0.2293856143951416,
      "learning_rate": 1.0144444444444445e-05,
      "loss": 0.002,
      "step": 71740
    },
    {
      "epoch": 1.5944444444444446,
      "grad_norm": 0.06812052428722382,
      "learning_rate": 1.013888888888889e-05,
      "loss": 0.0017,
      "step": 71750
    },
    {
      "epoch": 1.5946666666666667,
      "grad_norm": 0.11545276641845703,
      "learning_rate": 1.0133333333333333e-05,
      "loss": 0.0018,
      "step": 71760
    },
    {
      "epoch": 1.5948888888888888,
      "grad_norm": 0.1086953803896904,
      "learning_rate": 1.0127777777777777e-05,
      "loss": 0.0018,
      "step": 71770
    },
    {
      "epoch": 1.5951111111111111,
      "grad_norm": 0.10986582189798355,
      "learning_rate": 1.0122222222222224e-05,
      "loss": 0.0027,
      "step": 71780
    },
    {
      "epoch": 1.5953333333333335,
      "grad_norm": 0.08547500520944595,
      "learning_rate": 1.0116666666666667e-05,
      "loss": 0.0019,
      "step": 71790
    },
    {
      "epoch": 1.5955555555555554,
      "grad_norm": 0.2609076499938965,
      "learning_rate": 1.0111111111111111e-05,
      "loss": 0.002,
      "step": 71800
    },
    {
      "epoch": 1.5957777777777777,
      "grad_norm": 0.4262581765651703,
      "learning_rate": 1.0105555555555556e-05,
      "loss": 0.0019,
      "step": 71810
    },
    {
      "epoch": 1.596,
      "grad_norm": 0.6048540472984314,
      "learning_rate": 1.0100000000000002e-05,
      "loss": 0.0019,
      "step": 71820
    },
    {
      "epoch": 1.5962222222222222,
      "grad_norm": 0.6924598217010498,
      "learning_rate": 1.0094444444444445e-05,
      "loss": 0.0027,
      "step": 71830
    },
    {
      "epoch": 1.5964444444444443,
      "grad_norm": 0.6092066764831543,
      "learning_rate": 1.0088888888888889e-05,
      "loss": 0.0018,
      "step": 71840
    },
    {
      "epoch": 1.5966666666666667,
      "grad_norm": 0.18839499354362488,
      "learning_rate": 1.0083333333333334e-05,
      "loss": 0.0023,
      "step": 71850
    },
    {
      "epoch": 1.596888888888889,
      "grad_norm": 0.272079199552536,
      "learning_rate": 1.0077777777777777e-05,
      "loss": 0.0017,
      "step": 71860
    },
    {
      "epoch": 1.5971111111111111,
      "grad_norm": 0.30100545287132263,
      "learning_rate": 1.0072222222222223e-05,
      "loss": 0.0021,
      "step": 71870
    },
    {
      "epoch": 1.5973333333333333,
      "grad_norm": 0.2614150047302246,
      "learning_rate": 1.0066666666666668e-05,
      "loss": 0.0022,
      "step": 71880
    },
    {
      "epoch": 1.5975555555555556,
      "grad_norm": 0.12727300822734833,
      "learning_rate": 1.0061111111111112e-05,
      "loss": 0.0027,
      "step": 71890
    },
    {
      "epoch": 1.5977777777777777,
      "grad_norm": 0.21863341331481934,
      "learning_rate": 1.0055555555555555e-05,
      "loss": 0.0031,
      "step": 71900
    },
    {
      "epoch": 1.5979999999999999,
      "grad_norm": 0.1535118967294693,
      "learning_rate": 1.005e-05,
      "loss": 0.0022,
      "step": 71910
    },
    {
      "epoch": 1.5982222222222222,
      "grad_norm": 0.14841583371162415,
      "learning_rate": 1.0044444444444446e-05,
      "loss": 0.0026,
      "step": 71920
    },
    {
      "epoch": 1.5984444444444446,
      "grad_norm": 0.3757838308811188,
      "learning_rate": 1.0038888888888889e-05,
      "loss": 0.0021,
      "step": 71930
    },
    {
      "epoch": 1.5986666666666667,
      "grad_norm": 0.08444776386022568,
      "learning_rate": 1.0033333333333333e-05,
      "loss": 0.0017,
      "step": 71940
    },
    {
      "epoch": 1.5988888888888888,
      "grad_norm": 0.15314291417598724,
      "learning_rate": 1.0027777777777778e-05,
      "loss": 0.0019,
      "step": 71950
    },
    {
      "epoch": 1.5991111111111111,
      "grad_norm": 0.346914678812027,
      "learning_rate": 1.0022222222222223e-05,
      "loss": 0.0017,
      "step": 71960
    },
    {
      "epoch": 1.5993333333333335,
      "grad_norm": 0.1659175604581833,
      "learning_rate": 1.0016666666666667e-05,
      "loss": 0.002,
      "step": 71970
    },
    {
      "epoch": 1.5995555555555554,
      "grad_norm": 0.2355593889951706,
      "learning_rate": 1.0011111111111112e-05,
      "loss": 0.0034,
      "step": 71980
    },
    {
      "epoch": 1.5997777777777777,
      "grad_norm": 0.11809919774532318,
      "learning_rate": 1.0005555555555556e-05,
      "loss": 0.0018,
      "step": 71990
    },
    {
      "epoch": 1.6,
      "grad_norm": 0.08708765357732773,
      "learning_rate": 1e-05,
      "loss": 0.0019,
      "step": 72000
    },
    {
      "epoch": 1.6002222222222222,
      "grad_norm": 0.08849998563528061,
      "learning_rate": 9.994444444444444e-06,
      "loss": 0.0019,
      "step": 72010
    },
    {
      "epoch": 1.6004444444444443,
      "grad_norm": 0.19723820686340332,
      "learning_rate": 9.98888888888889e-06,
      "loss": 0.004,
      "step": 72020
    },
    {
      "epoch": 1.6006666666666667,
      "grad_norm": 0.3406114876270294,
      "learning_rate": 9.983333333333333e-06,
      "loss": 0.002,
      "step": 72030
    },
    {
      "epoch": 1.600888888888889,
      "grad_norm": 0.3266061842441559,
      "learning_rate": 9.977777777777778e-06,
      "loss": 0.0025,
      "step": 72040
    },
    {
      "epoch": 1.6011111111111112,
      "grad_norm": 0.2852804958820343,
      "learning_rate": 9.972222222222224e-06,
      "loss": 0.0028,
      "step": 72050
    },
    {
      "epoch": 1.6013333333333333,
      "grad_norm": 0.18309403955936432,
      "learning_rate": 9.966666666666667e-06,
      "loss": 0.0018,
      "step": 72060
    },
    {
      "epoch": 1.6015555555555556,
      "grad_norm": 0.39470624923706055,
      "learning_rate": 9.96111111111111e-06,
      "loss": 0.0019,
      "step": 72070
    },
    {
      "epoch": 1.6017777777777777,
      "grad_norm": 0.331702321767807,
      "learning_rate": 9.955555555555556e-06,
      "loss": 0.0019,
      "step": 72080
    },
    {
      "epoch": 1.6019999999999999,
      "grad_norm": 0.1769321858882904,
      "learning_rate": 9.950000000000001e-06,
      "loss": 0.0017,
      "step": 72090
    },
    {
      "epoch": 1.6022222222222222,
      "grad_norm": 0.4057423174381256,
      "learning_rate": 9.944444444444445e-06,
      "loss": 0.0016,
      "step": 72100
    },
    {
      "epoch": 1.6024444444444446,
      "grad_norm": 0.10381191223859787,
      "learning_rate": 9.938888888888888e-06,
      "loss": 0.0038,
      "step": 72110
    },
    {
      "epoch": 1.6026666666666667,
      "grad_norm": 0.08396362513303757,
      "learning_rate": 9.933333333333334e-06,
      "loss": 0.0022,
      "step": 72120
    },
    {
      "epoch": 1.6028888888888888,
      "grad_norm": 0.2916644811630249,
      "learning_rate": 9.927777777777779e-06,
      "loss": 0.0023,
      "step": 72130
    },
    {
      "epoch": 1.6031111111111112,
      "grad_norm": 0.15624664723873138,
      "learning_rate": 9.922222222222222e-06,
      "loss": 0.0023,
      "step": 72140
    },
    {
      "epoch": 1.6033333333333335,
      "grad_norm": 0.1465160846710205,
      "learning_rate": 9.916666666666668e-06,
      "loss": 0.0024,
      "step": 72150
    },
    {
      "epoch": 1.6035555555555554,
      "grad_norm": 0.41024982929229736,
      "learning_rate": 9.911111111111111e-06,
      "loss": 0.0017,
      "step": 72160
    },
    {
      "epoch": 1.6037777777777777,
      "grad_norm": 0.5975680351257324,
      "learning_rate": 9.905555555555555e-06,
      "loss": 0.0016,
      "step": 72170
    },
    {
      "epoch": 1.604,
      "grad_norm": 0.11904613673686981,
      "learning_rate": 9.900000000000002e-06,
      "loss": 0.0034,
      "step": 72180
    },
    {
      "epoch": 1.6042222222222222,
      "grad_norm": 0.35597607493400574,
      "learning_rate": 9.894444444444445e-06,
      "loss": 0.0027,
      "step": 72190
    },
    {
      "epoch": 1.6044444444444443,
      "grad_norm": 0.25651782751083374,
      "learning_rate": 9.888888888888889e-06,
      "loss": 0.0022,
      "step": 72200
    },
    {
      "epoch": 1.6046666666666667,
      "grad_norm": 0.12269498407840729,
      "learning_rate": 9.883333333333334e-06,
      "loss": 0.0021,
      "step": 72210
    },
    {
      "epoch": 1.604888888888889,
      "grad_norm": 0.09358895570039749,
      "learning_rate": 9.87777777777778e-06,
      "loss": 0.0026,
      "step": 72220
    },
    {
      "epoch": 1.6051111111111112,
      "grad_norm": 0.06779786199331284,
      "learning_rate": 9.872222222222223e-06,
      "loss": 0.0025,
      "step": 72230
    },
    {
      "epoch": 1.6053333333333333,
      "grad_norm": 0.21910351514816284,
      "learning_rate": 9.866666666666667e-06,
      "loss": 0.0021,
      "step": 72240
    },
    {
      "epoch": 1.6055555555555556,
      "grad_norm": 0.27148374915122986,
      "learning_rate": 9.861111111111112e-06,
      "loss": 0.0022,
      "step": 72250
    },
    {
      "epoch": 1.6057777777777777,
      "grad_norm": 0.1784173995256424,
      "learning_rate": 9.855555555555555e-06,
      "loss": 0.0021,
      "step": 72260
    },
    {
      "epoch": 1.6059999999999999,
      "grad_norm": 0.5409436225891113,
      "learning_rate": 9.85e-06,
      "loss": 0.0027,
      "step": 72270
    },
    {
      "epoch": 1.6062222222222222,
      "grad_norm": 0.2315572202205658,
      "learning_rate": 9.844444444444446e-06,
      "loss": 0.0017,
      "step": 72280
    },
    {
      "epoch": 1.6064444444444446,
      "grad_norm": 0.20735566318035126,
      "learning_rate": 9.83888888888889e-06,
      "loss": 0.0033,
      "step": 72290
    },
    {
      "epoch": 1.6066666666666667,
      "grad_norm": 0.06950973719358444,
      "learning_rate": 9.833333333333333e-06,
      "loss": 0.0029,
      "step": 72300
    },
    {
      "epoch": 1.6068888888888888,
      "grad_norm": 0.3023596405982971,
      "learning_rate": 9.827777777777778e-06,
      "loss": 0.003,
      "step": 72310
    },
    {
      "epoch": 1.6071111111111112,
      "grad_norm": 0.14928334951400757,
      "learning_rate": 9.822222222222223e-06,
      "loss": 0.0022,
      "step": 72320
    },
    {
      "epoch": 1.6073333333333333,
      "grad_norm": 0.10077300667762756,
      "learning_rate": 9.816666666666667e-06,
      "loss": 0.0019,
      "step": 72330
    },
    {
      "epoch": 1.6075555555555554,
      "grad_norm": 0.2580517530441284,
      "learning_rate": 9.81111111111111e-06,
      "loss": 0.002,
      "step": 72340
    },
    {
      "epoch": 1.6077777777777778,
      "grad_norm": 0.3727063238620758,
      "learning_rate": 9.805555555555557e-06,
      "loss": 0.0017,
      "step": 72350
    },
    {
      "epoch": 1.608,
      "grad_norm": 0.39462965726852417,
      "learning_rate": 9.800000000000001e-06,
      "loss": 0.0018,
      "step": 72360
    },
    {
      "epoch": 1.6082222222222222,
      "grad_norm": 0.08008207380771637,
      "learning_rate": 9.794444444444445e-06,
      "loss": 0.0021,
      "step": 72370
    },
    {
      "epoch": 1.6084444444444443,
      "grad_norm": 0.5108731985092163,
      "learning_rate": 9.78888888888889e-06,
      "loss": 0.0018,
      "step": 72380
    },
    {
      "epoch": 1.6086666666666667,
      "grad_norm": 0.32335004210472107,
      "learning_rate": 9.783333333333333e-06,
      "loss": 0.0019,
      "step": 72390
    },
    {
      "epoch": 1.608888888888889,
      "grad_norm": 0.41312336921691895,
      "learning_rate": 9.777777777777779e-06,
      "loss": 0.0024,
      "step": 72400
    },
    {
      "epoch": 1.6091111111111112,
      "grad_norm": 0.1188320517539978,
      "learning_rate": 9.772222222222222e-06,
      "loss": 0.0018,
      "step": 72410
    },
    {
      "epoch": 1.6093333333333333,
      "grad_norm": 0.16416597366333008,
      "learning_rate": 9.766666666666667e-06,
      "loss": 0.0021,
      "step": 72420
    },
    {
      "epoch": 1.6095555555555556,
      "grad_norm": 0.054430119693279266,
      "learning_rate": 9.761111111111111e-06,
      "loss": 0.0015,
      "step": 72430
    },
    {
      "epoch": 1.6097777777777778,
      "grad_norm": 0.7373676896095276,
      "learning_rate": 9.755555555555556e-06,
      "loss": 0.0025,
      "step": 72440
    },
    {
      "epoch": 1.6099999999999999,
      "grad_norm": 0.204862579703331,
      "learning_rate": 9.750000000000002e-06,
      "loss": 0.0018,
      "step": 72450
    },
    {
      "epoch": 1.6102222222222222,
      "grad_norm": 0.3422764837741852,
      "learning_rate": 9.744444444444445e-06,
      "loss": 0.0026,
      "step": 72460
    },
    {
      "epoch": 1.6104444444444446,
      "grad_norm": 0.05828610435128212,
      "learning_rate": 9.738888888888889e-06,
      "loss": 0.0021,
      "step": 72470
    },
    {
      "epoch": 1.6106666666666667,
      "grad_norm": 0.3156987130641937,
      "learning_rate": 9.733333333333334e-06,
      "loss": 0.0034,
      "step": 72480
    },
    {
      "epoch": 1.6108888888888888,
      "grad_norm": 0.2752898037433624,
      "learning_rate": 9.727777777777779e-06,
      "loss": 0.0025,
      "step": 72490
    },
    {
      "epoch": 1.6111111111111112,
      "grad_norm": 0.06675883382558823,
      "learning_rate": 9.722222222222223e-06,
      "loss": 0.0018,
      "step": 72500
    },
    {
      "epoch": 1.6113333333333333,
      "grad_norm": 0.46900835633277893,
      "learning_rate": 9.716666666666666e-06,
      "loss": 0.0035,
      "step": 72510
    },
    {
      "epoch": 1.6115555555555554,
      "grad_norm": 0.35787686705589294,
      "learning_rate": 9.711111111111111e-06,
      "loss": 0.0019,
      "step": 72520
    },
    {
      "epoch": 1.6117777777777778,
      "grad_norm": 0.13854900002479553,
      "learning_rate": 9.705555555555557e-06,
      "loss": 0.0027,
      "step": 72530
    },
    {
      "epoch": 1.612,
      "grad_norm": 0.256196528673172,
      "learning_rate": 9.7e-06,
      "loss": 0.0026,
      "step": 72540
    },
    {
      "epoch": 1.6122222222222222,
      "grad_norm": 0.6016148328781128,
      "learning_rate": 9.694444444444446e-06,
      "loss": 0.0039,
      "step": 72550
    },
    {
      "epoch": 1.6124444444444443,
      "grad_norm": 0.35836055874824524,
      "learning_rate": 9.688888888888889e-06,
      "loss": 0.0023,
      "step": 72560
    },
    {
      "epoch": 1.6126666666666667,
      "grad_norm": 0.10611803829669952,
      "learning_rate": 9.683333333333333e-06,
      "loss": 0.0023,
      "step": 72570
    },
    {
      "epoch": 1.612888888888889,
      "grad_norm": 0.05194086953997612,
      "learning_rate": 9.677777777777778e-06,
      "loss": 0.0017,
      "step": 72580
    },
    {
      "epoch": 1.6131111111111112,
      "grad_norm": 0.46854546666145325,
      "learning_rate": 9.672222222222223e-06,
      "loss": 0.0019,
      "step": 72590
    },
    {
      "epoch": 1.6133333333333333,
      "grad_norm": 0.07067106664180756,
      "learning_rate": 9.666666666666667e-06,
      "loss": 0.0017,
      "step": 72600
    },
    {
      "epoch": 1.6135555555555556,
      "grad_norm": 0.34123435616493225,
      "learning_rate": 9.66111111111111e-06,
      "loss": 0.0017,
      "step": 72610
    },
    {
      "epoch": 1.6137777777777778,
      "grad_norm": 0.07007686793804169,
      "learning_rate": 9.655555555555557e-06,
      "loss": 0.0016,
      "step": 72620
    },
    {
      "epoch": 1.6139999999999999,
      "grad_norm": 0.23187896609306335,
      "learning_rate": 9.65e-06,
      "loss": 0.0021,
      "step": 72630
    },
    {
      "epoch": 1.6142222222222222,
      "grad_norm": 0.5983492732048035,
      "learning_rate": 9.644444444444444e-06,
      "loss": 0.0021,
      "step": 72640
    },
    {
      "epoch": 1.6144444444444446,
      "grad_norm": 0.09002936631441116,
      "learning_rate": 9.63888888888889e-06,
      "loss": 0.0017,
      "step": 72650
    },
    {
      "epoch": 1.6146666666666667,
      "grad_norm": 0.175932377576828,
      "learning_rate": 9.633333333333335e-06,
      "loss": 0.0035,
      "step": 72660
    },
    {
      "epoch": 1.6148888888888888,
      "grad_norm": 0.1141229048371315,
      "learning_rate": 9.627777777777778e-06,
      "loss": 0.0023,
      "step": 72670
    },
    {
      "epoch": 1.6151111111111112,
      "grad_norm": 0.05473070591688156,
      "learning_rate": 9.622222222222222e-06,
      "loss": 0.0019,
      "step": 72680
    },
    {
      "epoch": 1.6153333333333333,
      "grad_norm": 0.12152017652988434,
      "learning_rate": 9.616666666666667e-06,
      "loss": 0.0019,
      "step": 72690
    },
    {
      "epoch": 1.6155555555555554,
      "grad_norm": 0.15694978833198547,
      "learning_rate": 9.61111111111111e-06,
      "loss": 0.0023,
      "step": 72700
    },
    {
      "epoch": 1.6157777777777778,
      "grad_norm": 0.05578548461198807,
      "learning_rate": 9.605555555555556e-06,
      "loss": 0.0017,
      "step": 72710
    },
    {
      "epoch": 1.616,
      "grad_norm": 0.34383174777030945,
      "learning_rate": 9.600000000000001e-06,
      "loss": 0.0032,
      "step": 72720
    },
    {
      "epoch": 1.6162222222222222,
      "grad_norm": 0.14368708431720734,
      "learning_rate": 9.594444444444445e-06,
      "loss": 0.0017,
      "step": 72730
    },
    {
      "epoch": 1.6164444444444444,
      "grad_norm": 0.40278857946395874,
      "learning_rate": 9.588888888888888e-06,
      "loss": 0.0019,
      "step": 72740
    },
    {
      "epoch": 1.6166666666666667,
      "grad_norm": 0.2761096954345703,
      "learning_rate": 9.583333333333334e-06,
      "loss": 0.0025,
      "step": 72750
    },
    {
      "epoch": 1.616888888888889,
      "grad_norm": 0.26179298758506775,
      "learning_rate": 9.577777777777779e-06,
      "loss": 0.0036,
      "step": 72760
    },
    {
      "epoch": 1.6171111111111112,
      "grad_norm": 0.3159862458705902,
      "learning_rate": 9.572222222222222e-06,
      "loss": 0.0018,
      "step": 72770
    },
    {
      "epoch": 1.6173333333333333,
      "grad_norm": 0.2452082633972168,
      "learning_rate": 9.566666666666666e-06,
      "loss": 0.0021,
      "step": 72780
    },
    {
      "epoch": 1.6175555555555556,
      "grad_norm": 0.16513316333293915,
      "learning_rate": 9.561111111111111e-06,
      "loss": 0.0019,
      "step": 72790
    },
    {
      "epoch": 1.6177777777777778,
      "grad_norm": 0.7372456192970276,
      "learning_rate": 9.555555555555556e-06,
      "loss": 0.0019,
      "step": 72800
    },
    {
      "epoch": 1.6179999999999999,
      "grad_norm": 0.11133924126625061,
      "learning_rate": 9.55e-06,
      "loss": 0.0016,
      "step": 72810
    },
    {
      "epoch": 1.6182222222222222,
      "grad_norm": 0.08039679378271103,
      "learning_rate": 9.544444444444445e-06,
      "loss": 0.0027,
      "step": 72820
    },
    {
      "epoch": 1.6184444444444446,
      "grad_norm": 0.16321730613708496,
      "learning_rate": 9.538888888888889e-06,
      "loss": 0.0019,
      "step": 72830
    },
    {
      "epoch": 1.6186666666666667,
      "grad_norm": 0.6484048962593079,
      "learning_rate": 9.533333333333334e-06,
      "loss": 0.0026,
      "step": 72840
    },
    {
      "epoch": 1.6188888888888888,
      "grad_norm": 0.23251424729824066,
      "learning_rate": 9.52777777777778e-06,
      "loss": 0.0018,
      "step": 72850
    },
    {
      "epoch": 1.6191111111111112,
      "grad_norm": 0.45170918107032776,
      "learning_rate": 9.522222222222223e-06,
      "loss": 0.0027,
      "step": 72860
    },
    {
      "epoch": 1.6193333333333333,
      "grad_norm": 0.2634192109107971,
      "learning_rate": 9.516666666666666e-06,
      "loss": 0.0031,
      "step": 72870
    },
    {
      "epoch": 1.6195555555555554,
      "grad_norm": 0.26457276940345764,
      "learning_rate": 9.511111111111112e-06,
      "loss": 0.002,
      "step": 72880
    },
    {
      "epoch": 1.6197777777777778,
      "grad_norm": 0.08383138477802277,
      "learning_rate": 9.505555555555557e-06,
      "loss": 0.0024,
      "step": 72890
    },
    {
      "epoch": 1.62,
      "grad_norm": 0.08640846610069275,
      "learning_rate": 9.5e-06,
      "loss": 0.0018,
      "step": 72900
    },
    {
      "epoch": 1.6202222222222222,
      "grad_norm": 0.595479428768158,
      "learning_rate": 9.494444444444444e-06,
      "loss": 0.0033,
      "step": 72910
    },
    {
      "epoch": 1.6204444444444444,
      "grad_norm": 0.1310703456401825,
      "learning_rate": 9.48888888888889e-06,
      "loss": 0.0018,
      "step": 72920
    },
    {
      "epoch": 1.6206666666666667,
      "grad_norm": 0.29179415106773376,
      "learning_rate": 9.483333333333335e-06,
      "loss": 0.0028,
      "step": 72930
    },
    {
      "epoch": 1.620888888888889,
      "grad_norm": 0.09735368937253952,
      "learning_rate": 9.477777777777778e-06,
      "loss": 0.0022,
      "step": 72940
    },
    {
      "epoch": 1.621111111111111,
      "grad_norm": 0.5402142405509949,
      "learning_rate": 9.472222222222223e-06,
      "loss": 0.002,
      "step": 72950
    },
    {
      "epoch": 1.6213333333333333,
      "grad_norm": 0.16673225164413452,
      "learning_rate": 9.466666666666667e-06,
      "loss": 0.0021,
      "step": 72960
    },
    {
      "epoch": 1.6215555555555556,
      "grad_norm": 0.11581051349639893,
      "learning_rate": 9.461111111111112e-06,
      "loss": 0.002,
      "step": 72970
    },
    {
      "epoch": 1.6217777777777778,
      "grad_norm": 0.2434748113155365,
      "learning_rate": 9.455555555555556e-06,
      "loss": 0.0022,
      "step": 72980
    },
    {
      "epoch": 1.6219999999999999,
      "grad_norm": 0.09996602684259415,
      "learning_rate": 9.450000000000001e-06,
      "loss": 0.0018,
      "step": 72990
    },
    {
      "epoch": 1.6222222222222222,
      "grad_norm": 0.06644374877214432,
      "learning_rate": 9.444444444444445e-06,
      "loss": 0.0021,
      "step": 73000
    },
    {
      "epoch": 1.6224444444444446,
      "grad_norm": 0.1686168611049652,
      "learning_rate": 9.438888888888888e-06,
      "loss": 0.0017,
      "step": 73010
    },
    {
      "epoch": 1.6226666666666667,
      "grad_norm": 0.1427076756954193,
      "learning_rate": 9.433333333333335e-06,
      "loss": 0.0019,
      "step": 73020
    },
    {
      "epoch": 1.6228888888888888,
      "grad_norm": 0.24169139564037323,
      "learning_rate": 9.427777777777779e-06,
      "loss": 0.0017,
      "step": 73030
    },
    {
      "epoch": 1.6231111111111112,
      "grad_norm": 0.4106881320476532,
      "learning_rate": 9.422222222222222e-06,
      "loss": 0.0016,
      "step": 73040
    },
    {
      "epoch": 1.6233333333333333,
      "grad_norm": 0.2303769737482071,
      "learning_rate": 9.416666666666667e-06,
      "loss": 0.0018,
      "step": 73050
    },
    {
      "epoch": 1.6235555555555554,
      "grad_norm": 0.14058884978294373,
      "learning_rate": 9.411111111111113e-06,
      "loss": 0.0022,
      "step": 73060
    },
    {
      "epoch": 1.6237777777777778,
      "grad_norm": 0.8045247197151184,
      "learning_rate": 9.405555555555556e-06,
      "loss": 0.002,
      "step": 73070
    },
    {
      "epoch": 1.624,
      "grad_norm": 0.14881497621536255,
      "learning_rate": 9.4e-06,
      "loss": 0.002,
      "step": 73080
    },
    {
      "epoch": 1.6242222222222222,
      "grad_norm": 0.47133293747901917,
      "learning_rate": 9.394444444444445e-06,
      "loss": 0.0028,
      "step": 73090
    },
    {
      "epoch": 1.6244444444444444,
      "grad_norm": 0.31421366333961487,
      "learning_rate": 9.388888888888889e-06,
      "loss": 0.002,
      "step": 73100
    },
    {
      "epoch": 1.6246666666666667,
      "grad_norm": 0.29212796688079834,
      "learning_rate": 9.383333333333334e-06,
      "loss": 0.0017,
      "step": 73110
    },
    {
      "epoch": 1.624888888888889,
      "grad_norm": 0.11204222589731216,
      "learning_rate": 9.377777777777779e-06,
      "loss": 0.002,
      "step": 73120
    },
    {
      "epoch": 1.625111111111111,
      "grad_norm": 0.30685174465179443,
      "learning_rate": 9.372222222222223e-06,
      "loss": 0.0028,
      "step": 73130
    },
    {
      "epoch": 1.6253333333333333,
      "grad_norm": 0.21813440322875977,
      "learning_rate": 9.366666666666666e-06,
      "loss": 0.002,
      "step": 73140
    },
    {
      "epoch": 1.6255555555555556,
      "grad_norm": 0.42747926712036133,
      "learning_rate": 9.361111111111111e-06,
      "loss": 0.003,
      "step": 73150
    },
    {
      "epoch": 1.6257777777777778,
      "grad_norm": 0.32533541321754456,
      "learning_rate": 9.355555555555557e-06,
      "loss": 0.002,
      "step": 73160
    },
    {
      "epoch": 1.626,
      "grad_norm": 0.11551539599895477,
      "learning_rate": 9.35e-06,
      "loss": 0.002,
      "step": 73170
    },
    {
      "epoch": 1.6262222222222222,
      "grad_norm": 0.44928520917892456,
      "learning_rate": 9.344444444444444e-06,
      "loss": 0.0017,
      "step": 73180
    },
    {
      "epoch": 1.6264444444444446,
      "grad_norm": 0.13210207223892212,
      "learning_rate": 9.338888888888889e-06,
      "loss": 0.0018,
      "step": 73190
    },
    {
      "epoch": 1.6266666666666667,
      "grad_norm": 0.19595842063426971,
      "learning_rate": 9.333333333333334e-06,
      "loss": 0.0021,
      "step": 73200
    },
    {
      "epoch": 1.6268888888888888,
      "grad_norm": 0.09076827764511108,
      "learning_rate": 9.327777777777778e-06,
      "loss": 0.0018,
      "step": 73210
    },
    {
      "epoch": 1.6271111111111112,
      "grad_norm": 0.13235655426979065,
      "learning_rate": 9.322222222222223e-06,
      "loss": 0.0016,
      "step": 73220
    },
    {
      "epoch": 1.6273333333333333,
      "grad_norm": 0.2728103697299957,
      "learning_rate": 9.316666666666667e-06,
      "loss": 0.0024,
      "step": 73230
    },
    {
      "epoch": 1.6275555555555554,
      "grad_norm": 0.27597862482070923,
      "learning_rate": 9.311111111111112e-06,
      "loss": 0.0018,
      "step": 73240
    },
    {
      "epoch": 1.6277777777777778,
      "grad_norm": 0.4701779782772064,
      "learning_rate": 9.305555555555555e-06,
      "loss": 0.0028,
      "step": 73250
    },
    {
      "epoch": 1.6280000000000001,
      "grad_norm": 0.31957167387008667,
      "learning_rate": 9.3e-06,
      "loss": 0.0018,
      "step": 73260
    },
    {
      "epoch": 1.6282222222222222,
      "grad_norm": 0.29183995723724365,
      "learning_rate": 9.294444444444444e-06,
      "loss": 0.0028,
      "step": 73270
    },
    {
      "epoch": 1.6284444444444444,
      "grad_norm": 0.5288302898406982,
      "learning_rate": 9.288888888888888e-06,
      "loss": 0.0018,
      "step": 73280
    },
    {
      "epoch": 1.6286666666666667,
      "grad_norm": 0.14117251336574554,
      "learning_rate": 9.283333333333335e-06,
      "loss": 0.0024,
      "step": 73290
    },
    {
      "epoch": 1.628888888888889,
      "grad_norm": 0.16170388460159302,
      "learning_rate": 9.277777777777778e-06,
      "loss": 0.003,
      "step": 73300
    },
    {
      "epoch": 1.629111111111111,
      "grad_norm": 0.15225256979465485,
      "learning_rate": 9.272222222222222e-06,
      "loss": 0.002,
      "step": 73310
    },
    {
      "epoch": 1.6293333333333333,
      "grad_norm": 0.34896209836006165,
      "learning_rate": 9.266666666666667e-06,
      "loss": 0.0017,
      "step": 73320
    },
    {
      "epoch": 1.6295555555555556,
      "grad_norm": 0.3468952775001526,
      "learning_rate": 9.261111111111112e-06,
      "loss": 0.0017,
      "step": 73330
    },
    {
      "epoch": 1.6297777777777778,
      "grad_norm": 0.2674570381641388,
      "learning_rate": 9.255555555555556e-06,
      "loss": 0.0017,
      "step": 73340
    },
    {
      "epoch": 1.63,
      "grad_norm": 0.4817970395088196,
      "learning_rate": 9.25e-06,
      "loss": 0.0028,
      "step": 73350
    },
    {
      "epoch": 1.6302222222222222,
      "grad_norm": 0.24725203216075897,
      "learning_rate": 9.244444444444445e-06,
      "loss": 0.0028,
      "step": 73360
    },
    {
      "epoch": 1.6304444444444446,
      "grad_norm": 0.39969995617866516,
      "learning_rate": 9.23888888888889e-06,
      "loss": 0.0017,
      "step": 73370
    },
    {
      "epoch": 1.6306666666666667,
      "grad_norm": 0.12976180016994476,
      "learning_rate": 9.233333333333334e-06,
      "loss": 0.0025,
      "step": 73380
    },
    {
      "epoch": 1.6308888888888888,
      "grad_norm": 0.28003549575805664,
      "learning_rate": 9.227777777777779e-06,
      "loss": 0.002,
      "step": 73390
    },
    {
      "epoch": 1.6311111111111112,
      "grad_norm": 0.11806266009807587,
      "learning_rate": 9.222222222222222e-06,
      "loss": 0.0026,
      "step": 73400
    },
    {
      "epoch": 1.6313333333333333,
      "grad_norm": 0.5939635038375854,
      "learning_rate": 9.216666666666666e-06,
      "loss": 0.0028,
      "step": 73410
    },
    {
      "epoch": 1.6315555555555554,
      "grad_norm": 0.08519668877124786,
      "learning_rate": 9.211111111111111e-06,
      "loss": 0.002,
      "step": 73420
    },
    {
      "epoch": 1.6317777777777778,
      "grad_norm": 0.2291133552789688,
      "learning_rate": 9.205555555555556e-06,
      "loss": 0.0017,
      "step": 73430
    },
    {
      "epoch": 1.6320000000000001,
      "grad_norm": 0.3410649001598358,
      "learning_rate": 9.2e-06,
      "loss": 0.0025,
      "step": 73440
    },
    {
      "epoch": 1.6322222222222222,
      "grad_norm": 0.48721280694007874,
      "learning_rate": 9.194444444444445e-06,
      "loss": 0.0021,
      "step": 73450
    },
    {
      "epoch": 1.6324444444444444,
      "grad_norm": 0.17169269919395447,
      "learning_rate": 9.18888888888889e-06,
      "loss": 0.0017,
      "step": 73460
    },
    {
      "epoch": 1.6326666666666667,
      "grad_norm": 0.16345486044883728,
      "learning_rate": 9.183333333333334e-06,
      "loss": 0.002,
      "step": 73470
    },
    {
      "epoch": 1.6328888888888888,
      "grad_norm": 0.05825691297650337,
      "learning_rate": 9.177777777777778e-06,
      "loss": 0.002,
      "step": 73480
    },
    {
      "epoch": 1.633111111111111,
      "grad_norm": 0.18986430764198303,
      "learning_rate": 9.172222222222223e-06,
      "loss": 0.0018,
      "step": 73490
    },
    {
      "epoch": 1.6333333333333333,
      "grad_norm": 0.484791100025177,
      "learning_rate": 9.166666666666666e-06,
      "loss": 0.0018,
      "step": 73500
    },
    {
      "epoch": 1.6335555555555556,
      "grad_norm": 0.35895922780036926,
      "learning_rate": 9.161111111111112e-06,
      "loss": 0.0021,
      "step": 73510
    },
    {
      "epoch": 1.6337777777777778,
      "grad_norm": 0.46855881810188293,
      "learning_rate": 9.155555555555557e-06,
      "loss": 0.0018,
      "step": 73520
    },
    {
      "epoch": 1.634,
      "grad_norm": 0.15513592958450317,
      "learning_rate": 9.15e-06,
      "loss": 0.0018,
      "step": 73530
    },
    {
      "epoch": 1.6342222222222222,
      "grad_norm": 0.0845509022474289,
      "learning_rate": 9.144444444444444e-06,
      "loss": 0.0019,
      "step": 73540
    },
    {
      "epoch": 1.6344444444444446,
      "grad_norm": 0.3963371813297272,
      "learning_rate": 9.13888888888889e-06,
      "loss": 0.0027,
      "step": 73550
    },
    {
      "epoch": 1.6346666666666667,
      "grad_norm": 0.19718609750270844,
      "learning_rate": 9.133333333333335e-06,
      "loss": 0.002,
      "step": 73560
    },
    {
      "epoch": 1.6348888888888888,
      "grad_norm": 0.16572262346744537,
      "learning_rate": 9.127777777777778e-06,
      "loss": 0.0023,
      "step": 73570
    },
    {
      "epoch": 1.6351111111111112,
      "grad_norm": 0.2065672129392624,
      "learning_rate": 9.122222222222222e-06,
      "loss": 0.0022,
      "step": 73580
    },
    {
      "epoch": 1.6353333333333333,
      "grad_norm": 0.27109581232070923,
      "learning_rate": 9.116666666666667e-06,
      "loss": 0.0018,
      "step": 73590
    },
    {
      "epoch": 1.6355555555555554,
      "grad_norm": 0.2609165906906128,
      "learning_rate": 9.111111111111112e-06,
      "loss": 0.0016,
      "step": 73600
    },
    {
      "epoch": 1.6357777777777778,
      "grad_norm": 0.12608739733695984,
      "learning_rate": 9.105555555555556e-06,
      "loss": 0.0032,
      "step": 73610
    },
    {
      "epoch": 1.6360000000000001,
      "grad_norm": 0.620599627494812,
      "learning_rate": 9.100000000000001e-06,
      "loss": 0.0019,
      "step": 73620
    },
    {
      "epoch": 1.6362222222222222,
      "grad_norm": 0.4835856854915619,
      "learning_rate": 9.094444444444445e-06,
      "loss": 0.0024,
      "step": 73630
    },
    {
      "epoch": 1.6364444444444444,
      "grad_norm": 0.3094720244407654,
      "learning_rate": 9.08888888888889e-06,
      "loss": 0.002,
      "step": 73640
    },
    {
      "epoch": 1.6366666666666667,
      "grad_norm": 0.5906320810317993,
      "learning_rate": 9.083333333333333e-06,
      "loss": 0.0017,
      "step": 73650
    },
    {
      "epoch": 1.6368888888888888,
      "grad_norm": 0.14450901746749878,
      "learning_rate": 9.077777777777779e-06,
      "loss": 0.0018,
      "step": 73660
    },
    {
      "epoch": 1.637111111111111,
      "grad_norm": 0.49606624245643616,
      "learning_rate": 9.072222222222222e-06,
      "loss": 0.0017,
      "step": 73670
    },
    {
      "epoch": 1.6373333333333333,
      "grad_norm": 0.3806343972682953,
      "learning_rate": 9.066666666666667e-06,
      "loss": 0.0017,
      "step": 73680
    },
    {
      "epoch": 1.6375555555555557,
      "grad_norm": 0.3564554452896118,
      "learning_rate": 9.061111111111113e-06,
      "loss": 0.0021,
      "step": 73690
    },
    {
      "epoch": 1.6377777777777778,
      "grad_norm": 0.31977733969688416,
      "learning_rate": 9.055555555555556e-06,
      "loss": 0.0021,
      "step": 73700
    },
    {
      "epoch": 1.638,
      "grad_norm": 0.07785294950008392,
      "learning_rate": 9.05e-06,
      "loss": 0.0018,
      "step": 73710
    },
    {
      "epoch": 1.6382222222222222,
      "grad_norm": 0.17455148696899414,
      "learning_rate": 9.044444444444445e-06,
      "loss": 0.0018,
      "step": 73720
    },
    {
      "epoch": 1.6384444444444446,
      "grad_norm": 0.08546138554811478,
      "learning_rate": 9.03888888888889e-06,
      "loss": 0.003,
      "step": 73730
    },
    {
      "epoch": 1.6386666666666667,
      "grad_norm": 0.10219687968492508,
      "learning_rate": 9.033333333333334e-06,
      "loss": 0.0018,
      "step": 73740
    },
    {
      "epoch": 1.6388888888888888,
      "grad_norm": 0.298503577709198,
      "learning_rate": 9.027777777777777e-06,
      "loss": 0.0022,
      "step": 73750
    },
    {
      "epoch": 1.6391111111111112,
      "grad_norm": 0.09231070429086685,
      "learning_rate": 9.022222222222223e-06,
      "loss": 0.0026,
      "step": 73760
    },
    {
      "epoch": 1.6393333333333333,
      "grad_norm": 0.1873822659254074,
      "learning_rate": 9.016666666666668e-06,
      "loss": 0.0019,
      "step": 73770
    },
    {
      "epoch": 1.6395555555555554,
      "grad_norm": 0.09100329875946045,
      "learning_rate": 9.011111111111111e-06,
      "loss": 0.0017,
      "step": 73780
    },
    {
      "epoch": 1.6397777777777778,
      "grad_norm": 0.0628892183303833,
      "learning_rate": 9.005555555555557e-06,
      "loss": 0.002,
      "step": 73790
    },
    {
      "epoch": 1.6400000000000001,
      "grad_norm": 0.3627198338508606,
      "learning_rate": 9e-06,
      "loss": 0.0026,
      "step": 73800
    },
    {
      "epoch": 1.6402222222222222,
      "grad_norm": 0.27613726258277893,
      "learning_rate": 8.994444444444444e-06,
      "loss": 0.0026,
      "step": 73810
    },
    {
      "epoch": 1.6404444444444444,
      "grad_norm": 0.5732234716415405,
      "learning_rate": 8.988888888888889e-06,
      "loss": 0.0019,
      "step": 73820
    },
    {
      "epoch": 1.6406666666666667,
      "grad_norm": 0.2171289622783661,
      "learning_rate": 8.983333333333334e-06,
      "loss": 0.0018,
      "step": 73830
    },
    {
      "epoch": 1.6408888888888888,
      "grad_norm": 0.30069929361343384,
      "learning_rate": 8.977777777777778e-06,
      "loss": 0.0033,
      "step": 73840
    },
    {
      "epoch": 1.641111111111111,
      "grad_norm": 0.13970451056957245,
      "learning_rate": 8.972222222222221e-06,
      "loss": 0.0023,
      "step": 73850
    },
    {
      "epoch": 1.6413333333333333,
      "grad_norm": 0.24101395905017853,
      "learning_rate": 8.966666666666668e-06,
      "loss": 0.0031,
      "step": 73860
    },
    {
      "epoch": 1.6415555555555557,
      "grad_norm": 0.155702143907547,
      "learning_rate": 8.961111111111112e-06,
      "loss": 0.0027,
      "step": 73870
    },
    {
      "epoch": 1.6417777777777778,
      "grad_norm": 0.5105956196784973,
      "learning_rate": 8.955555555555555e-06,
      "loss": 0.0018,
      "step": 73880
    },
    {
      "epoch": 1.642,
      "grad_norm": 0.11620211601257324,
      "learning_rate": 8.95e-06,
      "loss": 0.0018,
      "step": 73890
    },
    {
      "epoch": 1.6422222222222222,
      "grad_norm": 0.5223754644393921,
      "learning_rate": 8.944444444444444e-06,
      "loss": 0.0019,
      "step": 73900
    },
    {
      "epoch": 1.6424444444444446,
      "grad_norm": 0.19883541762828827,
      "learning_rate": 8.93888888888889e-06,
      "loss": 0.0016,
      "step": 73910
    },
    {
      "epoch": 1.6426666666666667,
      "grad_norm": 0.203386127948761,
      "learning_rate": 8.933333333333333e-06,
      "loss": 0.0027,
      "step": 73920
    },
    {
      "epoch": 1.6428888888888888,
      "grad_norm": 0.17163564264774323,
      "learning_rate": 8.927777777777778e-06,
      "loss": 0.0025,
      "step": 73930
    },
    {
      "epoch": 1.6431111111111112,
      "grad_norm": 0.1705554872751236,
      "learning_rate": 8.922222222222222e-06,
      "loss": 0.0019,
      "step": 73940
    },
    {
      "epoch": 1.6433333333333333,
      "grad_norm": 0.15800634026527405,
      "learning_rate": 8.916666666666667e-06,
      "loss": 0.0034,
      "step": 73950
    },
    {
      "epoch": 1.6435555555555554,
      "grad_norm": 0.16763214766979218,
      "learning_rate": 8.911111111111112e-06,
      "loss": 0.002,
      "step": 73960
    },
    {
      "epoch": 1.6437777777777778,
      "grad_norm": 0.5361900329589844,
      "learning_rate": 8.905555555555556e-06,
      "loss": 0.0018,
      "step": 73970
    },
    {
      "epoch": 1.6440000000000001,
      "grad_norm": 0.12876063585281372,
      "learning_rate": 8.9e-06,
      "loss": 0.0017,
      "step": 73980
    },
    {
      "epoch": 1.6442222222222223,
      "grad_norm": 0.3580548167228699,
      "learning_rate": 8.894444444444445e-06,
      "loss": 0.0032,
      "step": 73990
    },
    {
      "epoch": 1.6444444444444444,
      "grad_norm": 0.11680173128843307,
      "learning_rate": 8.88888888888889e-06,
      "loss": 0.0017,
      "step": 74000
    },
    {
      "epoch": 1.6446666666666667,
      "grad_norm": 0.3086717426776886,
      "learning_rate": 8.883333333333334e-06,
      "loss": 0.0026,
      "step": 74010
    },
    {
      "epoch": 1.6448888888888888,
      "grad_norm": 0.09788110852241516,
      "learning_rate": 8.877777777777777e-06,
      "loss": 0.0028,
      "step": 74020
    },
    {
      "epoch": 1.645111111111111,
      "grad_norm": 0.08701065182685852,
      "learning_rate": 8.872222222222222e-06,
      "loss": 0.0021,
      "step": 74030
    },
    {
      "epoch": 1.6453333333333333,
      "grad_norm": 0.3061676621437073,
      "learning_rate": 8.866666666666668e-06,
      "loss": 0.0019,
      "step": 74040
    },
    {
      "epoch": 1.6455555555555557,
      "grad_norm": 0.27445319294929504,
      "learning_rate": 8.861111111111111e-06,
      "loss": 0.0017,
      "step": 74050
    },
    {
      "epoch": 1.6457777777777778,
      "grad_norm": 0.1685718446969986,
      "learning_rate": 8.855555555555556e-06,
      "loss": 0.0029,
      "step": 74060
    },
    {
      "epoch": 1.646,
      "grad_norm": 0.09854765981435776,
      "learning_rate": 8.85e-06,
      "loss": 0.0017,
      "step": 74070
    },
    {
      "epoch": 1.6462222222222223,
      "grad_norm": 0.33307045698165894,
      "learning_rate": 8.844444444444445e-06,
      "loss": 0.0026,
      "step": 74080
    },
    {
      "epoch": 1.6464444444444446,
      "grad_norm": 0.3121965527534485,
      "learning_rate": 8.838888888888889e-06,
      "loss": 0.0022,
      "step": 74090
    },
    {
      "epoch": 1.6466666666666665,
      "grad_norm": 0.23317579925060272,
      "learning_rate": 8.833333333333334e-06,
      "loss": 0.0023,
      "step": 74100
    },
    {
      "epoch": 1.6468888888888888,
      "grad_norm": 0.13755877315998077,
      "learning_rate": 8.827777777777778e-06,
      "loss": 0.0016,
      "step": 74110
    },
    {
      "epoch": 1.6471111111111112,
      "grad_norm": 0.10634999722242355,
      "learning_rate": 8.822222222222223e-06,
      "loss": 0.0025,
      "step": 74120
    },
    {
      "epoch": 1.6473333333333333,
      "grad_norm": 0.3163487911224365,
      "learning_rate": 8.816666666666668e-06,
      "loss": 0.002,
      "step": 74130
    },
    {
      "epoch": 1.6475555555555554,
      "grad_norm": 0.2856130301952362,
      "learning_rate": 8.811111111111112e-06,
      "loss": 0.0018,
      "step": 74140
    },
    {
      "epoch": 1.6477777777777778,
      "grad_norm": 0.4829034209251404,
      "learning_rate": 8.805555555555555e-06,
      "loss": 0.0017,
      "step": 74150
    },
    {
      "epoch": 1.6480000000000001,
      "grad_norm": 0.5815664529800415,
      "learning_rate": 8.8e-06,
      "loss": 0.0028,
      "step": 74160
    },
    {
      "epoch": 1.6482222222222223,
      "grad_norm": 0.2523443400859833,
      "learning_rate": 8.794444444444446e-06,
      "loss": 0.0025,
      "step": 74170
    },
    {
      "epoch": 1.6484444444444444,
      "grad_norm": 0.06854861229658127,
      "learning_rate": 8.78888888888889e-06,
      "loss": 0.002,
      "step": 74180
    },
    {
      "epoch": 1.6486666666666667,
      "grad_norm": 0.1623985320329666,
      "learning_rate": 8.783333333333335e-06,
      "loss": 0.0022,
      "step": 74190
    },
    {
      "epoch": 1.6488888888888888,
      "grad_norm": 0.0581696555018425,
      "learning_rate": 8.777777777777778e-06,
      "loss": 0.0017,
      "step": 74200
    },
    {
      "epoch": 1.649111111111111,
      "grad_norm": 0.21721453964710236,
      "learning_rate": 8.772222222222222e-06,
      "loss": 0.0018,
      "step": 74210
    },
    {
      "epoch": 1.6493333333333333,
      "grad_norm": 0.33966389298439026,
      "learning_rate": 8.766666666666667e-06,
      "loss": 0.0018,
      "step": 74220
    },
    {
      "epoch": 1.6495555555555557,
      "grad_norm": 0.12957750260829926,
      "learning_rate": 8.761111111111112e-06,
      "loss": 0.0017,
      "step": 74230
    },
    {
      "epoch": 1.6497777777777778,
      "grad_norm": 0.25129908323287964,
      "learning_rate": 8.755555555555556e-06,
      "loss": 0.0019,
      "step": 74240
    },
    {
      "epoch": 1.65,
      "grad_norm": 0.30731716752052307,
      "learning_rate": 8.75e-06,
      "loss": 0.0018,
      "step": 74250
    },
    {
      "epoch": 1.6502222222222223,
      "grad_norm": 0.07001599669456482,
      "learning_rate": 8.744444444444446e-06,
      "loss": 0.0018,
      "step": 74260
    },
    {
      "epoch": 1.6504444444444446,
      "grad_norm": 0.08761655539274216,
      "learning_rate": 8.73888888888889e-06,
      "loss": 0.0019,
      "step": 74270
    },
    {
      "epoch": 1.6506666666666665,
      "grad_norm": 0.19924266636371613,
      "learning_rate": 8.733333333333333e-06,
      "loss": 0.0027,
      "step": 74280
    },
    {
      "epoch": 1.6508888888888889,
      "grad_norm": 0.4361991584300995,
      "learning_rate": 8.727777777777779e-06,
      "loss": 0.0021,
      "step": 74290
    },
    {
      "epoch": 1.6511111111111112,
      "grad_norm": 0.3714975118637085,
      "learning_rate": 8.722222222222224e-06,
      "loss": 0.0023,
      "step": 74300
    },
    {
      "epoch": 1.6513333333333333,
      "grad_norm": 0.2239939570426941,
      "learning_rate": 8.716666666666667e-06,
      "loss": 0.0023,
      "step": 74310
    },
    {
      "epoch": 1.6515555555555554,
      "grad_norm": 0.41993576288223267,
      "learning_rate": 8.711111111111111e-06,
      "loss": 0.0026,
      "step": 74320
    },
    {
      "epoch": 1.6517777777777778,
      "grad_norm": 0.1908338963985443,
      "learning_rate": 8.705555555555556e-06,
      "loss": 0.0018,
      "step": 74330
    },
    {
      "epoch": 1.6520000000000001,
      "grad_norm": 0.07909192144870758,
      "learning_rate": 8.7e-06,
      "loss": 0.002,
      "step": 74340
    },
    {
      "epoch": 1.6522222222222223,
      "grad_norm": 0.16467592120170593,
      "learning_rate": 8.694444444444445e-06,
      "loss": 0.002,
      "step": 74350
    },
    {
      "epoch": 1.6524444444444444,
      "grad_norm": 0.35041579604148865,
      "learning_rate": 8.68888888888889e-06,
      "loss": 0.0019,
      "step": 74360
    },
    {
      "epoch": 1.6526666666666667,
      "grad_norm": 0.2055608332157135,
      "learning_rate": 8.683333333333334e-06,
      "loss": 0.003,
      "step": 74370
    },
    {
      "epoch": 1.6528888888888889,
      "grad_norm": 0.18742424249649048,
      "learning_rate": 8.677777777777777e-06,
      "loss": 0.0017,
      "step": 74380
    },
    {
      "epoch": 1.653111111111111,
      "grad_norm": 0.3506087064743042,
      "learning_rate": 8.672222222222223e-06,
      "loss": 0.0018,
      "step": 74390
    },
    {
      "epoch": 1.6533333333333333,
      "grad_norm": 0.19112879037857056,
      "learning_rate": 8.666666666666668e-06,
      "loss": 0.0018,
      "step": 74400
    },
    {
      "epoch": 1.6535555555555557,
      "grad_norm": 0.3051844835281372,
      "learning_rate": 8.661111111111111e-06,
      "loss": 0.0019,
      "step": 74410
    },
    {
      "epoch": 1.6537777777777778,
      "grad_norm": 0.12981681525707245,
      "learning_rate": 8.655555555555555e-06,
      "loss": 0.0017,
      "step": 74420
    },
    {
      "epoch": 1.654,
      "grad_norm": 0.1475643813610077,
      "learning_rate": 8.65e-06,
      "loss": 0.0024,
      "step": 74430
    },
    {
      "epoch": 1.6542222222222223,
      "grad_norm": 0.4976120889186859,
      "learning_rate": 8.644444444444445e-06,
      "loss": 0.0018,
      "step": 74440
    },
    {
      "epoch": 1.6544444444444446,
      "grad_norm": 0.134292334318161,
      "learning_rate": 8.638888888888889e-06,
      "loss": 0.0028,
      "step": 74450
    },
    {
      "epoch": 1.6546666666666665,
      "grad_norm": 0.2278936803340912,
      "learning_rate": 8.633333333333334e-06,
      "loss": 0.0017,
      "step": 74460
    },
    {
      "epoch": 1.6548888888888889,
      "grad_norm": 0.2140650451183319,
      "learning_rate": 8.627777777777778e-06,
      "loss": 0.002,
      "step": 74470
    },
    {
      "epoch": 1.6551111111111112,
      "grad_norm": 0.4127560555934906,
      "learning_rate": 8.622222222222223e-06,
      "loss": 0.0025,
      "step": 74480
    },
    {
      "epoch": 1.6553333333333333,
      "grad_norm": 0.11830524355173111,
      "learning_rate": 8.616666666666667e-06,
      "loss": 0.0022,
      "step": 74490
    },
    {
      "epoch": 1.6555555555555554,
      "grad_norm": 0.5009253025054932,
      "learning_rate": 8.611111111111112e-06,
      "loss": 0.0022,
      "step": 74500
    },
    {
      "epoch": 1.6557777777777778,
      "grad_norm": 0.05499539524316788,
      "learning_rate": 8.605555555555555e-06,
      "loss": 0.0028,
      "step": 74510
    },
    {
      "epoch": 1.6560000000000001,
      "grad_norm": 0.2621462941169739,
      "learning_rate": 8.599999999999999e-06,
      "loss": 0.0017,
      "step": 74520
    },
    {
      "epoch": 1.6562222222222223,
      "grad_norm": 0.425464928150177,
      "learning_rate": 8.594444444444446e-06,
      "loss": 0.002,
      "step": 74530
    },
    {
      "epoch": 1.6564444444444444,
      "grad_norm": 0.07320259511470795,
      "learning_rate": 8.58888888888889e-06,
      "loss": 0.0018,
      "step": 74540
    },
    {
      "epoch": 1.6566666666666667,
      "grad_norm": 0.4536187946796417,
      "learning_rate": 8.583333333333333e-06,
      "loss": 0.0018,
      "step": 74550
    },
    {
      "epoch": 1.6568888888888889,
      "grad_norm": 0.15539440512657166,
      "learning_rate": 8.577777777777778e-06,
      "loss": 0.0018,
      "step": 74560
    },
    {
      "epoch": 1.657111111111111,
      "grad_norm": 0.06362048536539078,
      "learning_rate": 8.572222222222224e-06,
      "loss": 0.0018,
      "step": 74570
    },
    {
      "epoch": 1.6573333333333333,
      "grad_norm": 0.19561269879341125,
      "learning_rate": 8.566666666666667e-06,
      "loss": 0.002,
      "step": 74580
    },
    {
      "epoch": 1.6575555555555557,
      "grad_norm": 0.05394147336483002,
      "learning_rate": 8.56111111111111e-06,
      "loss": 0.0021,
      "step": 74590
    },
    {
      "epoch": 1.6577777777777778,
      "grad_norm": 0.18434298038482666,
      "learning_rate": 8.555555555555556e-06,
      "loss": 0.0026,
      "step": 74600
    },
    {
      "epoch": 1.658,
      "grad_norm": 0.25520315766334534,
      "learning_rate": 8.550000000000001e-06,
      "loss": 0.0023,
      "step": 74610
    },
    {
      "epoch": 1.6582222222222223,
      "grad_norm": 0.07667847722768784,
      "learning_rate": 8.544444444444445e-06,
      "loss": 0.0026,
      "step": 74620
    },
    {
      "epoch": 1.6584444444444446,
      "grad_norm": 0.24780206382274628,
      "learning_rate": 8.53888888888889e-06,
      "loss": 0.002,
      "step": 74630
    },
    {
      "epoch": 1.6586666666666665,
      "grad_norm": 0.33029359579086304,
      "learning_rate": 8.533333333333334e-06,
      "loss": 0.0023,
      "step": 74640
    },
    {
      "epoch": 1.6588888888888889,
      "grad_norm": 0.2557756304740906,
      "learning_rate": 8.527777777777777e-06,
      "loss": 0.0022,
      "step": 74650
    },
    {
      "epoch": 1.6591111111111112,
      "grad_norm": 0.26376473903656006,
      "learning_rate": 8.522222222222222e-06,
      "loss": 0.0018,
      "step": 74660
    },
    {
      "epoch": 1.6593333333333333,
      "grad_norm": 0.33361220359802246,
      "learning_rate": 8.516666666666668e-06,
      "loss": 0.0018,
      "step": 74670
    },
    {
      "epoch": 1.6595555555555555,
      "grad_norm": 0.5511989593505859,
      "learning_rate": 8.511111111111111e-06,
      "loss": 0.0018,
      "step": 74680
    },
    {
      "epoch": 1.6597777777777778,
      "grad_norm": 0.0748865082859993,
      "learning_rate": 8.505555555555555e-06,
      "loss": 0.002,
      "step": 74690
    },
    {
      "epoch": 1.6600000000000001,
      "grad_norm": 0.284358412027359,
      "learning_rate": 8.500000000000002e-06,
      "loss": 0.0023,
      "step": 74700
    },
    {
      "epoch": 1.6602222222222223,
      "grad_norm": 0.06337857246398926,
      "learning_rate": 8.494444444444445e-06,
      "loss": 0.0016,
      "step": 74710
    },
    {
      "epoch": 1.6604444444444444,
      "grad_norm": 0.2744748890399933,
      "learning_rate": 8.488888888888889e-06,
      "loss": 0.0019,
      "step": 74720
    },
    {
      "epoch": 1.6606666666666667,
      "grad_norm": 0.2050771564245224,
      "learning_rate": 8.483333333333334e-06,
      "loss": 0.002,
      "step": 74730
    },
    {
      "epoch": 1.6608888888888889,
      "grad_norm": 0.31897443532943726,
      "learning_rate": 8.477777777777778e-06,
      "loss": 0.0024,
      "step": 74740
    },
    {
      "epoch": 1.661111111111111,
      "grad_norm": 0.11752920597791672,
      "learning_rate": 8.472222222222223e-06,
      "loss": 0.0028,
      "step": 74750
    },
    {
      "epoch": 1.6613333333333333,
      "grad_norm": 0.21628005802631378,
      "learning_rate": 8.466666666666666e-06,
      "loss": 0.0024,
      "step": 74760
    },
    {
      "epoch": 1.6615555555555557,
      "grad_norm": 0.36162227392196655,
      "learning_rate": 8.461111111111112e-06,
      "loss": 0.0019,
      "step": 74770
    },
    {
      "epoch": 1.6617777777777778,
      "grad_norm": 0.41308534145355225,
      "learning_rate": 8.455555555555555e-06,
      "loss": 0.0021,
      "step": 74780
    },
    {
      "epoch": 1.662,
      "grad_norm": 0.14689496159553528,
      "learning_rate": 8.45e-06,
      "loss": 0.0022,
      "step": 74790
    },
    {
      "epoch": 1.6622222222222223,
      "grad_norm": 0.18390321731567383,
      "learning_rate": 8.444444444444446e-06,
      "loss": 0.0018,
      "step": 74800
    },
    {
      "epoch": 1.6624444444444444,
      "grad_norm": 0.1352749615907669,
      "learning_rate": 8.43888888888889e-06,
      "loss": 0.0021,
      "step": 74810
    },
    {
      "epoch": 1.6626666666666665,
      "grad_norm": 0.14731773734092712,
      "learning_rate": 8.433333333333333e-06,
      "loss": 0.0018,
      "step": 74820
    },
    {
      "epoch": 1.6628888888888889,
      "grad_norm": 0.41631656885147095,
      "learning_rate": 8.427777777777778e-06,
      "loss": 0.0018,
      "step": 74830
    },
    {
      "epoch": 1.6631111111111112,
      "grad_norm": 0.0692313015460968,
      "learning_rate": 8.422222222222223e-06,
      "loss": 0.0023,
      "step": 74840
    },
    {
      "epoch": 1.6633333333333333,
      "grad_norm": 0.24406033754348755,
      "learning_rate": 8.416666666666667e-06,
      "loss": 0.0023,
      "step": 74850
    },
    {
      "epoch": 1.6635555555555555,
      "grad_norm": 0.5121720433235168,
      "learning_rate": 8.411111111111112e-06,
      "loss": 0.0022,
      "step": 74860
    },
    {
      "epoch": 1.6637777777777778,
      "grad_norm": 0.24908776581287384,
      "learning_rate": 8.405555555555556e-06,
      "loss": 0.0017,
      "step": 74870
    },
    {
      "epoch": 1.6640000000000001,
      "grad_norm": 0.2719244062900543,
      "learning_rate": 8.400000000000001e-06,
      "loss": 0.0026,
      "step": 74880
    },
    {
      "epoch": 1.6642222222222223,
      "grad_norm": 0.08350411057472229,
      "learning_rate": 8.394444444444444e-06,
      "loss": 0.002,
      "step": 74890
    },
    {
      "epoch": 1.6644444444444444,
      "grad_norm": 0.2943347096443176,
      "learning_rate": 8.38888888888889e-06,
      "loss": 0.002,
      "step": 74900
    },
    {
      "epoch": 1.6646666666666667,
      "grad_norm": 0.49585244059562683,
      "learning_rate": 8.383333333333333e-06,
      "loss": 0.0019,
      "step": 74910
    },
    {
      "epoch": 1.6648888888888889,
      "grad_norm": 0.14536070823669434,
      "learning_rate": 8.377777777777779e-06,
      "loss": 0.0019,
      "step": 74920
    },
    {
      "epoch": 1.665111111111111,
      "grad_norm": 0.41775718331336975,
      "learning_rate": 8.372222222222224e-06,
      "loss": 0.0024,
      "step": 74930
    },
    {
      "epoch": 1.6653333333333333,
      "grad_norm": 0.15316732227802277,
      "learning_rate": 8.366666666666667e-06,
      "loss": 0.0021,
      "step": 74940
    },
    {
      "epoch": 1.6655555555555557,
      "grad_norm": 0.07692286372184753,
      "learning_rate": 8.361111111111111e-06,
      "loss": 0.0018,
      "step": 74950
    },
    {
      "epoch": 1.6657777777777778,
      "grad_norm": 0.4937889575958252,
      "learning_rate": 8.355555555555556e-06,
      "loss": 0.0023,
      "step": 74960
    },
    {
      "epoch": 1.666,
      "grad_norm": 0.11705051362514496,
      "learning_rate": 8.350000000000001e-06,
      "loss": 0.0019,
      "step": 74970
    },
    {
      "epoch": 1.6662222222222223,
      "grad_norm": 0.28963759541511536,
      "learning_rate": 8.344444444444445e-06,
      "loss": 0.0018,
      "step": 74980
    },
    {
      "epoch": 1.6664444444444444,
      "grad_norm": 0.4348370134830475,
      "learning_rate": 8.338888888888888e-06,
      "loss": 0.002,
      "step": 74990
    },
    {
      "epoch": 1.6666666666666665,
      "grad_norm": 0.14140936732292175,
      "learning_rate": 8.333333333333334e-06,
      "loss": 0.0016,
      "step": 75000
    },
    {
      "epoch": 1.6668888888888889,
      "grad_norm": 0.19701795279979706,
      "learning_rate": 8.327777777777779e-06,
      "loss": 0.0017,
      "step": 75010
    },
    {
      "epoch": 1.6671111111111112,
      "grad_norm": 0.29866135120391846,
      "learning_rate": 8.322222222222223e-06,
      "loss": 0.0019,
      "step": 75020
    },
    {
      "epoch": 1.6673333333333333,
      "grad_norm": 0.11276078969240189,
      "learning_rate": 8.316666666666668e-06,
      "loss": 0.0016,
      "step": 75030
    },
    {
      "epoch": 1.6675555555555555,
      "grad_norm": 0.3751635253429413,
      "learning_rate": 8.311111111111111e-06,
      "loss": 0.0018,
      "step": 75040
    },
    {
      "epoch": 1.6677777777777778,
      "grad_norm": 0.08270324021577835,
      "learning_rate": 8.305555555555555e-06,
      "loss": 0.0019,
      "step": 75050
    },
    {
      "epoch": 1.6680000000000001,
      "grad_norm": 0.24046945571899414,
      "learning_rate": 8.3e-06,
      "loss": 0.0019,
      "step": 75060
    },
    {
      "epoch": 1.6682222222222223,
      "grad_norm": 0.5092304944992065,
      "learning_rate": 8.294444444444445e-06,
      "loss": 0.0019,
      "step": 75070
    },
    {
      "epoch": 1.6684444444444444,
      "grad_norm": 0.14866621792316437,
      "learning_rate": 8.288888888888889e-06,
      "loss": 0.0021,
      "step": 75080
    },
    {
      "epoch": 1.6686666666666667,
      "grad_norm": 0.23805606365203857,
      "learning_rate": 8.283333333333333e-06,
      "loss": 0.0026,
      "step": 75090
    },
    {
      "epoch": 1.6688888888888889,
      "grad_norm": 0.2342308610677719,
      "learning_rate": 8.27777777777778e-06,
      "loss": 0.0017,
      "step": 75100
    },
    {
      "epoch": 1.669111111111111,
      "grad_norm": 0.38592109084129333,
      "learning_rate": 8.272222222222223e-06,
      "loss": 0.0024,
      "step": 75110
    },
    {
      "epoch": 1.6693333333333333,
      "grad_norm": 0.0787038803100586,
      "learning_rate": 8.266666666666667e-06,
      "loss": 0.0018,
      "step": 75120
    },
    {
      "epoch": 1.6695555555555557,
      "grad_norm": 0.23420609533786774,
      "learning_rate": 8.261111111111112e-06,
      "loss": 0.0029,
      "step": 75130
    },
    {
      "epoch": 1.6697777777777778,
      "grad_norm": 0.2740357220172882,
      "learning_rate": 8.255555555555555e-06,
      "loss": 0.0018,
      "step": 75140
    },
    {
      "epoch": 1.67,
      "grad_norm": 0.05538400635123253,
      "learning_rate": 8.25e-06,
      "loss": 0.0033,
      "step": 75150
    },
    {
      "epoch": 1.6702222222222223,
      "grad_norm": 0.09902453422546387,
      "learning_rate": 8.244444444444444e-06,
      "loss": 0.0023,
      "step": 75160
    },
    {
      "epoch": 1.6704444444444444,
      "grad_norm": 0.3077661991119385,
      "learning_rate": 8.23888888888889e-06,
      "loss": 0.002,
      "step": 75170
    },
    {
      "epoch": 1.6706666666666665,
      "grad_norm": 0.40071532130241394,
      "learning_rate": 8.233333333333333e-06,
      "loss": 0.0017,
      "step": 75180
    },
    {
      "epoch": 1.6708888888888889,
      "grad_norm": 0.19910642504692078,
      "learning_rate": 8.227777777777778e-06,
      "loss": 0.0027,
      "step": 75190
    },
    {
      "epoch": 1.6711111111111112,
      "grad_norm": 0.07852863520383835,
      "learning_rate": 8.222222222222223e-06,
      "loss": 0.0019,
      "step": 75200
    },
    {
      "epoch": 1.6713333333333333,
      "grad_norm": 0.06722712516784668,
      "learning_rate": 8.216666666666667e-06,
      "loss": 0.0027,
      "step": 75210
    },
    {
      "epoch": 1.6715555555555555,
      "grad_norm": 0.2827913463115692,
      "learning_rate": 8.21111111111111e-06,
      "loss": 0.0019,
      "step": 75220
    },
    {
      "epoch": 1.6717777777777778,
      "grad_norm": 0.15981872379779816,
      "learning_rate": 8.205555555555556e-06,
      "loss": 0.0018,
      "step": 75230
    },
    {
      "epoch": 1.6720000000000002,
      "grad_norm": 0.21265973150730133,
      "learning_rate": 8.200000000000001e-06,
      "loss": 0.0018,
      "step": 75240
    },
    {
      "epoch": 1.6722222222222223,
      "grad_norm": 0.2182268500328064,
      "learning_rate": 8.194444444444445e-06,
      "loss": 0.0017,
      "step": 75250
    },
    {
      "epoch": 1.6724444444444444,
      "grad_norm": 0.6072208285331726,
      "learning_rate": 8.188888888888888e-06,
      "loss": 0.0028,
      "step": 75260
    },
    {
      "epoch": 1.6726666666666667,
      "grad_norm": 0.18966171145439148,
      "learning_rate": 8.183333333333333e-06,
      "loss": 0.0019,
      "step": 75270
    },
    {
      "epoch": 1.6728888888888889,
      "grad_norm": 0.45715177059173584,
      "learning_rate": 8.177777777777779e-06,
      "loss": 0.0017,
      "step": 75280
    },
    {
      "epoch": 1.673111111111111,
      "grad_norm": 0.1822638362646103,
      "learning_rate": 8.172222222222222e-06,
      "loss": 0.0026,
      "step": 75290
    },
    {
      "epoch": 1.6733333333333333,
      "grad_norm": 0.3147943317890167,
      "learning_rate": 8.166666666666668e-06,
      "loss": 0.0023,
      "step": 75300
    },
    {
      "epoch": 1.6735555555555557,
      "grad_norm": 0.08069130033254623,
      "learning_rate": 8.161111111111111e-06,
      "loss": 0.0021,
      "step": 75310
    },
    {
      "epoch": 1.6737777777777778,
      "grad_norm": 0.174078568816185,
      "learning_rate": 8.155555555555556e-06,
      "loss": 0.0019,
      "step": 75320
    },
    {
      "epoch": 1.674,
      "grad_norm": 0.3272787928581238,
      "learning_rate": 8.15e-06,
      "loss": 0.0019,
      "step": 75330
    },
    {
      "epoch": 1.6742222222222223,
      "grad_norm": 0.1924867033958435,
      "learning_rate": 8.144444444444445e-06,
      "loss": 0.0018,
      "step": 75340
    },
    {
      "epoch": 1.6744444444444444,
      "grad_norm": 0.05974586680531502,
      "learning_rate": 8.138888888888889e-06,
      "loss": 0.0021,
      "step": 75350
    },
    {
      "epoch": 1.6746666666666665,
      "grad_norm": 0.08945221453905106,
      "learning_rate": 8.133333333333332e-06,
      "loss": 0.0026,
      "step": 75360
    },
    {
      "epoch": 1.6748888888888889,
      "grad_norm": 0.21838398277759552,
      "learning_rate": 8.12777777777778e-06,
      "loss": 0.0034,
      "step": 75370
    },
    {
      "epoch": 1.6751111111111112,
      "grad_norm": 0.14546701312065125,
      "learning_rate": 8.122222222222223e-06,
      "loss": 0.0018,
      "step": 75380
    },
    {
      "epoch": 1.6753333333333333,
      "grad_norm": 0.47693055868148804,
      "learning_rate": 8.116666666666666e-06,
      "loss": 0.0018,
      "step": 75390
    },
    {
      "epoch": 1.6755555555555555,
      "grad_norm": 0.20273633301258087,
      "learning_rate": 8.111111111111112e-06,
      "loss": 0.0019,
      "step": 75400
    },
    {
      "epoch": 1.6757777777777778,
      "grad_norm": 0.24648915231227875,
      "learning_rate": 8.105555555555557e-06,
      "loss": 0.0021,
      "step": 75410
    },
    {
      "epoch": 1.6760000000000002,
      "grad_norm": 0.3240622282028198,
      "learning_rate": 8.1e-06,
      "loss": 0.0024,
      "step": 75420
    },
    {
      "epoch": 1.676222222222222,
      "grad_norm": 0.5849533677101135,
      "learning_rate": 8.094444444444444e-06,
      "loss": 0.0019,
      "step": 75430
    },
    {
      "epoch": 1.6764444444444444,
      "grad_norm": 0.12055390328168869,
      "learning_rate": 8.08888888888889e-06,
      "loss": 0.0018,
      "step": 75440
    },
    {
      "epoch": 1.6766666666666667,
      "grad_norm": 0.15846163034439087,
      "learning_rate": 8.083333333333333e-06,
      "loss": 0.0021,
      "step": 75450
    },
    {
      "epoch": 1.6768888888888889,
      "grad_norm": 0.12297948449850082,
      "learning_rate": 8.077777777777778e-06,
      "loss": 0.0023,
      "step": 75460
    },
    {
      "epoch": 1.677111111111111,
      "grad_norm": 0.1354689747095108,
      "learning_rate": 8.072222222222223e-06,
      "loss": 0.0027,
      "step": 75470
    },
    {
      "epoch": 1.6773333333333333,
      "grad_norm": 0.45690470933914185,
      "learning_rate": 8.066666666666667e-06,
      "loss": 0.0018,
      "step": 75480
    },
    {
      "epoch": 1.6775555555555557,
      "grad_norm": 0.08436128497123718,
      "learning_rate": 8.06111111111111e-06,
      "loss": 0.0024,
      "step": 75490
    },
    {
      "epoch": 1.6777777777777778,
      "grad_norm": 0.28113314509391785,
      "learning_rate": 8.055555555555557e-06,
      "loss": 0.0017,
      "step": 75500
    },
    {
      "epoch": 1.678,
      "grad_norm": 0.08515878766775131,
      "learning_rate": 8.050000000000001e-06,
      "loss": 0.0018,
      "step": 75510
    },
    {
      "epoch": 1.6782222222222223,
      "grad_norm": 0.2922886610031128,
      "learning_rate": 8.044444444444444e-06,
      "loss": 0.0029,
      "step": 75520
    },
    {
      "epoch": 1.6784444444444444,
      "grad_norm": 0.42591434717178345,
      "learning_rate": 8.03888888888889e-06,
      "loss": 0.0031,
      "step": 75530
    },
    {
      "epoch": 1.6786666666666665,
      "grad_norm": 0.06970197707414627,
      "learning_rate": 8.033333333333335e-06,
      "loss": 0.002,
      "step": 75540
    },
    {
      "epoch": 1.6788888888888889,
      "grad_norm": 0.46954983472824097,
      "learning_rate": 8.027777777777778e-06,
      "loss": 0.002,
      "step": 75550
    },
    {
      "epoch": 1.6791111111111112,
      "grad_norm": 0.32824602723121643,
      "learning_rate": 8.022222222222222e-06,
      "loss": 0.0022,
      "step": 75560
    },
    {
      "epoch": 1.6793333333333333,
      "grad_norm": 0.45613354444503784,
      "learning_rate": 8.016666666666667e-06,
      "loss": 0.0017,
      "step": 75570
    },
    {
      "epoch": 1.6795555555555555,
      "grad_norm": 0.09891731292009354,
      "learning_rate": 8.01111111111111e-06,
      "loss": 0.0019,
      "step": 75580
    },
    {
      "epoch": 1.6797777777777778,
      "grad_norm": 0.13273370265960693,
      "learning_rate": 8.005555555555556e-06,
      "loss": 0.0017,
      "step": 75590
    },
    {
      "epoch": 1.6800000000000002,
      "grad_norm": 0.22978328168392181,
      "learning_rate": 8.000000000000001e-06,
      "loss": 0.0018,
      "step": 75600
    },
    {
      "epoch": 1.680222222222222,
      "grad_norm": 0.33654162287712097,
      "learning_rate": 7.994444444444445e-06,
      "loss": 0.0025,
      "step": 75610
    },
    {
      "epoch": 1.6804444444444444,
      "grad_norm": 0.3132113218307495,
      "learning_rate": 7.988888888888888e-06,
      "loss": 0.0032,
      "step": 75620
    },
    {
      "epoch": 1.6806666666666668,
      "grad_norm": 0.35725724697113037,
      "learning_rate": 7.983333333333334e-06,
      "loss": 0.0028,
      "step": 75630
    },
    {
      "epoch": 1.6808888888888889,
      "grad_norm": 0.3880838453769684,
      "learning_rate": 7.977777777777779e-06,
      "loss": 0.0031,
      "step": 75640
    },
    {
      "epoch": 1.681111111111111,
      "grad_norm": 0.07767185568809509,
      "learning_rate": 7.972222222222223e-06,
      "loss": 0.0036,
      "step": 75650
    },
    {
      "epoch": 1.6813333333333333,
      "grad_norm": 0.48576226830482483,
      "learning_rate": 7.966666666666666e-06,
      "loss": 0.002,
      "step": 75660
    },
    {
      "epoch": 1.6815555555555557,
      "grad_norm": 0.5116288065910339,
      "learning_rate": 7.961111111111111e-06,
      "loss": 0.0019,
      "step": 75670
    },
    {
      "epoch": 1.6817777777777778,
      "grad_norm": 0.13013339042663574,
      "learning_rate": 7.955555555555557e-06,
      "loss": 0.002,
      "step": 75680
    },
    {
      "epoch": 1.682,
      "grad_norm": 0.37203481793403625,
      "learning_rate": 7.95e-06,
      "loss": 0.0016,
      "step": 75690
    },
    {
      "epoch": 1.6822222222222223,
      "grad_norm": 0.1999080330133438,
      "learning_rate": 7.944444444444445e-06,
      "loss": 0.002,
      "step": 75700
    },
    {
      "epoch": 1.6824444444444444,
      "grad_norm": 0.18445098400115967,
      "learning_rate": 7.938888888888889e-06,
      "loss": 0.0019,
      "step": 75710
    },
    {
      "epoch": 1.6826666666666665,
      "grad_norm": 0.07367510348558426,
      "learning_rate": 7.933333333333334e-06,
      "loss": 0.0019,
      "step": 75720
    },
    {
      "epoch": 1.6828888888888889,
      "grad_norm": 0.08656805008649826,
      "learning_rate": 7.927777777777778e-06,
      "loss": 0.0017,
      "step": 75730
    },
    {
      "epoch": 1.6831111111111112,
      "grad_norm": 0.09031934291124344,
      "learning_rate": 7.922222222222223e-06,
      "loss": 0.0016,
      "step": 75740
    },
    {
      "epoch": 1.6833333333333333,
      "grad_norm": 0.16258162260055542,
      "learning_rate": 7.916666666666667e-06,
      "loss": 0.0025,
      "step": 75750
    },
    {
      "epoch": 1.6835555555555555,
      "grad_norm": 0.2599506080150604,
      "learning_rate": 7.91111111111111e-06,
      "loss": 0.0017,
      "step": 75760
    },
    {
      "epoch": 1.6837777777777778,
      "grad_norm": 0.08670258522033691,
      "learning_rate": 7.905555555555557e-06,
      "loss": 0.0017,
      "step": 75770
    },
    {
      "epoch": 1.6840000000000002,
      "grad_norm": 0.17473247647285461,
      "learning_rate": 7.9e-06,
      "loss": 0.0017,
      "step": 75780
    },
    {
      "epoch": 1.684222222222222,
      "grad_norm": 0.5619097352027893,
      "learning_rate": 7.894444444444444e-06,
      "loss": 0.0031,
      "step": 75790
    },
    {
      "epoch": 1.6844444444444444,
      "grad_norm": 0.22285766899585724,
      "learning_rate": 7.88888888888889e-06,
      "loss": 0.0018,
      "step": 75800
    },
    {
      "epoch": 1.6846666666666668,
      "grad_norm": 0.3831239640712738,
      "learning_rate": 7.883333333333335e-06,
      "loss": 0.0024,
      "step": 75810
    },
    {
      "epoch": 1.6848888888888889,
      "grad_norm": 0.36643949151039124,
      "learning_rate": 7.877777777777778e-06,
      "loss": 0.0018,
      "step": 75820
    },
    {
      "epoch": 1.685111111111111,
      "grad_norm": 0.175878643989563,
      "learning_rate": 7.872222222222222e-06,
      "loss": 0.0023,
      "step": 75830
    },
    {
      "epoch": 1.6853333333333333,
      "grad_norm": 0.33432406187057495,
      "learning_rate": 7.866666666666667e-06,
      "loss": 0.0015,
      "step": 75840
    },
    {
      "epoch": 1.6855555555555557,
      "grad_norm": 0.17794373631477356,
      "learning_rate": 7.861111111111112e-06,
      "loss": 0.0022,
      "step": 75850
    },
    {
      "epoch": 1.6857777777777778,
      "grad_norm": 0.4413892924785614,
      "learning_rate": 7.855555555555556e-06,
      "loss": 0.0036,
      "step": 75860
    },
    {
      "epoch": 1.686,
      "grad_norm": 0.16662906110286713,
      "learning_rate": 7.850000000000001e-06,
      "loss": 0.002,
      "step": 75870
    },
    {
      "epoch": 1.6862222222222223,
      "grad_norm": 0.145674929022789,
      "learning_rate": 7.844444444444445e-06,
      "loss": 0.0032,
      "step": 75880
    },
    {
      "epoch": 1.6864444444444444,
      "grad_norm": 0.14502978324890137,
      "learning_rate": 7.838888888888888e-06,
      "loss": 0.0027,
      "step": 75890
    },
    {
      "epoch": 1.6866666666666665,
      "grad_norm": 0.2498445212841034,
      "learning_rate": 7.833333333333333e-06,
      "loss": 0.0022,
      "step": 75900
    },
    {
      "epoch": 1.6868888888888889,
      "grad_norm": 0.0812634602189064,
      "learning_rate": 7.827777777777779e-06,
      "loss": 0.0018,
      "step": 75910
    },
    {
      "epoch": 1.6871111111111112,
      "grad_norm": 0.2391146719455719,
      "learning_rate": 7.822222222222222e-06,
      "loss": 0.0017,
      "step": 75920
    },
    {
      "epoch": 1.6873333333333334,
      "grad_norm": 0.20114265382289886,
      "learning_rate": 7.816666666666666e-06,
      "loss": 0.002,
      "step": 75930
    },
    {
      "epoch": 1.6875555555555555,
      "grad_norm": 0.4883171617984772,
      "learning_rate": 7.811111111111113e-06,
      "loss": 0.0021,
      "step": 75940
    },
    {
      "epoch": 1.6877777777777778,
      "grad_norm": 0.272222101688385,
      "learning_rate": 7.805555555555556e-06,
      "loss": 0.0022,
      "step": 75950
    },
    {
      "epoch": 1.688,
      "grad_norm": 0.09579397737979889,
      "learning_rate": 7.8e-06,
      "loss": 0.0019,
      "step": 75960
    },
    {
      "epoch": 1.688222222222222,
      "grad_norm": 0.3809792995452881,
      "learning_rate": 7.794444444444445e-06,
      "loss": 0.0018,
      "step": 75970
    },
    {
      "epoch": 1.6884444444444444,
      "grad_norm": 0.20059022307395935,
      "learning_rate": 7.788888888888889e-06,
      "loss": 0.0022,
      "step": 75980
    },
    {
      "epoch": 1.6886666666666668,
      "grad_norm": 0.1822868138551712,
      "learning_rate": 7.783333333333334e-06,
      "loss": 0.0018,
      "step": 75990
    },
    {
      "epoch": 1.6888888888888889,
      "grad_norm": 0.067844457924366,
      "learning_rate": 7.777777777777777e-06,
      "loss": 0.0017,
      "step": 76000
    },
    {
      "epoch": 1.689111111111111,
      "grad_norm": 0.2434103637933731,
      "learning_rate": 7.772222222222223e-06,
      "loss": 0.0025,
      "step": 76010
    },
    {
      "epoch": 1.6893333333333334,
      "grad_norm": 0.09322458505630493,
      "learning_rate": 7.766666666666666e-06,
      "loss": 0.0027,
      "step": 76020
    },
    {
      "epoch": 1.6895555555555557,
      "grad_norm": 0.29958540201187134,
      "learning_rate": 7.761111111111112e-06,
      "loss": 0.0026,
      "step": 76030
    },
    {
      "epoch": 1.6897777777777778,
      "grad_norm": 0.27537405490875244,
      "learning_rate": 7.755555555555557e-06,
      "loss": 0.0024,
      "step": 76040
    },
    {
      "epoch": 1.69,
      "grad_norm": 0.16401058435440063,
      "learning_rate": 7.75e-06,
      "loss": 0.0026,
      "step": 76050
    },
    {
      "epoch": 1.6902222222222223,
      "grad_norm": 0.4232643246650696,
      "learning_rate": 7.744444444444444e-06,
      "loss": 0.0018,
      "step": 76060
    },
    {
      "epoch": 1.6904444444444444,
      "grad_norm": 0.36065104603767395,
      "learning_rate": 7.738888888888889e-06,
      "loss": 0.0025,
      "step": 76070
    },
    {
      "epoch": 1.6906666666666665,
      "grad_norm": 0.3080633580684662,
      "learning_rate": 7.733333333333334e-06,
      "loss": 0.0019,
      "step": 76080
    },
    {
      "epoch": 1.6908888888888889,
      "grad_norm": 0.1990271955728531,
      "learning_rate": 7.727777777777778e-06,
      "loss": 0.0018,
      "step": 76090
    },
    {
      "epoch": 1.6911111111111112,
      "grad_norm": 0.11397542804479599,
      "learning_rate": 7.722222222222223e-06,
      "loss": 0.0019,
      "step": 76100
    },
    {
      "epoch": 1.6913333333333334,
      "grad_norm": 0.11976152658462524,
      "learning_rate": 7.716666666666667e-06,
      "loss": 0.0016,
      "step": 76110
    },
    {
      "epoch": 1.6915555555555555,
      "grad_norm": 0.44053971767425537,
      "learning_rate": 7.711111111111112e-06,
      "loss": 0.0021,
      "step": 76120
    },
    {
      "epoch": 1.6917777777777778,
      "grad_norm": 0.13909761607646942,
      "learning_rate": 7.705555555555556e-06,
      "loss": 0.0029,
      "step": 76130
    },
    {
      "epoch": 1.692,
      "grad_norm": 0.10798311233520508,
      "learning_rate": 7.7e-06,
      "loss": 0.0028,
      "step": 76140
    },
    {
      "epoch": 1.692222222222222,
      "grad_norm": 0.2569435238838196,
      "learning_rate": 7.694444444444444e-06,
      "loss": 0.0017,
      "step": 76150
    },
    {
      "epoch": 1.6924444444444444,
      "grad_norm": 0.1432647407054901,
      "learning_rate": 7.68888888888889e-06,
      "loss": 0.0017,
      "step": 76160
    },
    {
      "epoch": 1.6926666666666668,
      "grad_norm": 0.20695894956588745,
      "learning_rate": 7.683333333333335e-06,
      "loss": 0.0016,
      "step": 76170
    },
    {
      "epoch": 1.6928888888888889,
      "grad_norm": 0.08955081552267075,
      "learning_rate": 7.677777777777778e-06,
      "loss": 0.0018,
      "step": 76180
    },
    {
      "epoch": 1.693111111111111,
      "grad_norm": 0.06540932506322861,
      "learning_rate": 7.672222222222222e-06,
      "loss": 0.002,
      "step": 76190
    },
    {
      "epoch": 1.6933333333333334,
      "grad_norm": 0.1450626403093338,
      "learning_rate": 7.666666666666667e-06,
      "loss": 0.0018,
      "step": 76200
    },
    {
      "epoch": 1.6935555555555557,
      "grad_norm": 0.6214094161987305,
      "learning_rate": 7.661111111111112e-06,
      "loss": 0.0017,
      "step": 76210
    },
    {
      "epoch": 1.6937777777777778,
      "grad_norm": 0.15632733702659607,
      "learning_rate": 7.655555555555556e-06,
      "loss": 0.0023,
      "step": 76220
    },
    {
      "epoch": 1.694,
      "grad_norm": 0.16424301266670227,
      "learning_rate": 7.65e-06,
      "loss": 0.0021,
      "step": 76230
    },
    {
      "epoch": 1.6942222222222223,
      "grad_norm": 0.28653421998023987,
      "learning_rate": 7.644444444444445e-06,
      "loss": 0.0021,
      "step": 76240
    },
    {
      "epoch": 1.6944444444444444,
      "grad_norm": 0.23747846484184265,
      "learning_rate": 7.63888888888889e-06,
      "loss": 0.0016,
      "step": 76250
    },
    {
      "epoch": 1.6946666666666665,
      "grad_norm": 0.16354088485240936,
      "learning_rate": 7.633333333333334e-06,
      "loss": 0.0018,
      "step": 76260
    },
    {
      "epoch": 1.694888888888889,
      "grad_norm": 0.20712673664093018,
      "learning_rate": 7.627777777777778e-06,
      "loss": 0.0019,
      "step": 76270
    },
    {
      "epoch": 1.6951111111111112,
      "grad_norm": 0.23040755093097687,
      "learning_rate": 7.6222222222222225e-06,
      "loss": 0.0018,
      "step": 76280
    },
    {
      "epoch": 1.6953333333333334,
      "grad_norm": 0.10761519521474838,
      "learning_rate": 7.616666666666666e-06,
      "loss": 0.0023,
      "step": 76290
    },
    {
      "epoch": 1.6955555555555555,
      "grad_norm": 0.19170396029949188,
      "learning_rate": 7.611111111111112e-06,
      "loss": 0.0028,
      "step": 76300
    },
    {
      "epoch": 1.6957777777777778,
      "grad_norm": 0.12947013974189758,
      "learning_rate": 7.605555555555556e-06,
      "loss": 0.0018,
      "step": 76310
    },
    {
      "epoch": 1.696,
      "grad_norm": 0.11937489360570908,
      "learning_rate": 7.6e-06,
      "loss": 0.0027,
      "step": 76320
    },
    {
      "epoch": 1.696222222222222,
      "grad_norm": 0.26399725675582886,
      "learning_rate": 7.5944444444444445e-06,
      "loss": 0.0019,
      "step": 76330
    },
    {
      "epoch": 1.6964444444444444,
      "grad_norm": 0.4812338948249817,
      "learning_rate": 7.58888888888889e-06,
      "loss": 0.0017,
      "step": 76340
    },
    {
      "epoch": 1.6966666666666668,
      "grad_norm": 0.1268732249736786,
      "learning_rate": 7.583333333333334e-06,
      "loss": 0.0043,
      "step": 76350
    },
    {
      "epoch": 1.696888888888889,
      "grad_norm": 0.20369544625282288,
      "learning_rate": 7.577777777777778e-06,
      "loss": 0.002,
      "step": 76360
    },
    {
      "epoch": 1.697111111111111,
      "grad_norm": 0.1634809374809265,
      "learning_rate": 7.572222222222222e-06,
      "loss": 0.0017,
      "step": 76370
    },
    {
      "epoch": 1.6973333333333334,
      "grad_norm": 0.07319870591163635,
      "learning_rate": 7.5666666666666665e-06,
      "loss": 0.0016,
      "step": 76380
    },
    {
      "epoch": 1.6975555555555557,
      "grad_norm": 0.25295501947402954,
      "learning_rate": 7.561111111111112e-06,
      "loss": 0.0026,
      "step": 76390
    },
    {
      "epoch": 1.6977777777777778,
      "grad_norm": 0.1471763551235199,
      "learning_rate": 7.555555555555556e-06,
      "loss": 0.0021,
      "step": 76400
    },
    {
      "epoch": 1.698,
      "grad_norm": 0.18219268321990967,
      "learning_rate": 7.55e-06,
      "loss": 0.0017,
      "step": 76410
    },
    {
      "epoch": 1.6982222222222223,
      "grad_norm": 0.2335364669561386,
      "learning_rate": 7.544444444444444e-06,
      "loss": 0.0019,
      "step": 76420
    },
    {
      "epoch": 1.6984444444444444,
      "grad_norm": 0.07804460823535919,
      "learning_rate": 7.538888888888889e-06,
      "loss": 0.0019,
      "step": 76430
    },
    {
      "epoch": 1.6986666666666665,
      "grad_norm": 0.20779414474964142,
      "learning_rate": 7.533333333333334e-06,
      "loss": 0.0021,
      "step": 76440
    },
    {
      "epoch": 1.698888888888889,
      "grad_norm": 0.1444326937198639,
      "learning_rate": 7.527777777777778e-06,
      "loss": 0.0014,
      "step": 76450
    },
    {
      "epoch": 1.6991111111111112,
      "grad_norm": 0.07191424071788788,
      "learning_rate": 7.5222222222222226e-06,
      "loss": 0.0016,
      "step": 76460
    },
    {
      "epoch": 1.6993333333333334,
      "grad_norm": 0.08357197046279907,
      "learning_rate": 7.516666666666668e-06,
      "loss": 0.0028,
      "step": 76470
    },
    {
      "epoch": 1.6995555555555555,
      "grad_norm": 0.33893463015556335,
      "learning_rate": 7.511111111111112e-06,
      "loss": 0.0018,
      "step": 76480
    },
    {
      "epoch": 1.6997777777777778,
      "grad_norm": 0.3759894073009491,
      "learning_rate": 7.505555555555556e-06,
      "loss": 0.0019,
      "step": 76490
    },
    {
      "epoch": 1.7,
      "grad_norm": 0.15043753385543823,
      "learning_rate": 7.5e-06,
      "loss": 0.0018,
      "step": 76500
    },
    {
      "epoch": 1.700222222222222,
      "grad_norm": 0.5495935678482056,
      "learning_rate": 7.494444444444445e-06,
      "loss": 0.0018,
      "step": 76510
    },
    {
      "epoch": 1.7004444444444444,
      "grad_norm": 0.06400349736213684,
      "learning_rate": 7.48888888888889e-06,
      "loss": 0.0018,
      "step": 76520
    },
    {
      "epoch": 1.7006666666666668,
      "grad_norm": 0.3673853278160095,
      "learning_rate": 7.483333333333334e-06,
      "loss": 0.0035,
      "step": 76530
    },
    {
      "epoch": 1.700888888888889,
      "grad_norm": 0.11088456958532333,
      "learning_rate": 7.477777777777778e-06,
      "loss": 0.0016,
      "step": 76540
    },
    {
      "epoch": 1.701111111111111,
      "grad_norm": 0.33010971546173096,
      "learning_rate": 7.472222222222222e-06,
      "loss": 0.0021,
      "step": 76550
    },
    {
      "epoch": 1.7013333333333334,
      "grad_norm": 0.34251585602760315,
      "learning_rate": 7.4666666666666675e-06,
      "loss": 0.0019,
      "step": 76560
    },
    {
      "epoch": 1.7015555555555557,
      "grad_norm": 0.40034574270248413,
      "learning_rate": 7.461111111111112e-06,
      "loss": 0.002,
      "step": 76570
    },
    {
      "epoch": 1.7017777777777776,
      "grad_norm": 0.09791838377714157,
      "learning_rate": 7.455555555555556e-06,
      "loss": 0.0036,
      "step": 76580
    },
    {
      "epoch": 1.702,
      "grad_norm": 0.24659182131290436,
      "learning_rate": 7.45e-06,
      "loss": 0.0021,
      "step": 76590
    },
    {
      "epoch": 1.7022222222222223,
      "grad_norm": 0.07004853338003159,
      "learning_rate": 7.444444444444444e-06,
      "loss": 0.0019,
      "step": 76600
    },
    {
      "epoch": 1.7024444444444444,
      "grad_norm": 0.372599720954895,
      "learning_rate": 7.4388888888888895e-06,
      "loss": 0.0019,
      "step": 76610
    },
    {
      "epoch": 1.7026666666666666,
      "grad_norm": 0.42619165778160095,
      "learning_rate": 7.433333333333334e-06,
      "loss": 0.002,
      "step": 76620
    },
    {
      "epoch": 1.702888888888889,
      "grad_norm": 0.2236459106206894,
      "learning_rate": 7.427777777777778e-06,
      "loss": 0.0017,
      "step": 76630
    },
    {
      "epoch": 1.7031111111111112,
      "grad_norm": 0.07804156839847565,
      "learning_rate": 7.422222222222222e-06,
      "loss": 0.0016,
      "step": 76640
    },
    {
      "epoch": 1.7033333333333334,
      "grad_norm": 0.13346481323242188,
      "learning_rate": 7.416666666666668e-06,
      "loss": 0.0025,
      "step": 76650
    },
    {
      "epoch": 1.7035555555555555,
      "grad_norm": 0.21463264524936676,
      "learning_rate": 7.4111111111111115e-06,
      "loss": 0.0019,
      "step": 76660
    },
    {
      "epoch": 1.7037777777777778,
      "grad_norm": 0.3050198554992676,
      "learning_rate": 7.405555555555556e-06,
      "loss": 0.0027,
      "step": 76670
    },
    {
      "epoch": 1.704,
      "grad_norm": 0.2795112729072571,
      "learning_rate": 7.4e-06,
      "loss": 0.0029,
      "step": 76680
    },
    {
      "epoch": 1.704222222222222,
      "grad_norm": 0.32713067531585693,
      "learning_rate": 7.394444444444444e-06,
      "loss": 0.002,
      "step": 76690
    },
    {
      "epoch": 1.7044444444444444,
      "grad_norm": 0.26584306359291077,
      "learning_rate": 7.38888888888889e-06,
      "loss": 0.0019,
      "step": 76700
    },
    {
      "epoch": 1.7046666666666668,
      "grad_norm": 0.19101755321025848,
      "learning_rate": 7.3833333333333335e-06,
      "loss": 0.0016,
      "step": 76710
    },
    {
      "epoch": 1.704888888888889,
      "grad_norm": 0.12186569720506668,
      "learning_rate": 7.377777777777778e-06,
      "loss": 0.0017,
      "step": 76720
    },
    {
      "epoch": 1.705111111111111,
      "grad_norm": 0.11214254051446915,
      "learning_rate": 7.372222222222222e-06,
      "loss": 0.002,
      "step": 76730
    },
    {
      "epoch": 1.7053333333333334,
      "grad_norm": 0.254965603351593,
      "learning_rate": 7.3666666666666676e-06,
      "loss": 0.0018,
      "step": 76740
    },
    {
      "epoch": 1.7055555555555557,
      "grad_norm": 0.29917094111442566,
      "learning_rate": 7.361111111111112e-06,
      "loss": 0.002,
      "step": 76750
    },
    {
      "epoch": 1.7057777777777776,
      "grad_norm": 0.1963905692100525,
      "learning_rate": 7.3555555555555555e-06,
      "loss": 0.0018,
      "step": 76760
    },
    {
      "epoch": 1.706,
      "grad_norm": 0.21947291493415833,
      "learning_rate": 7.35e-06,
      "loss": 0.0019,
      "step": 76770
    },
    {
      "epoch": 1.7062222222222223,
      "grad_norm": 0.06185015290975571,
      "learning_rate": 7.344444444444445e-06,
      "loss": 0.0019,
      "step": 76780
    },
    {
      "epoch": 1.7064444444444444,
      "grad_norm": 0.4645173251628876,
      "learning_rate": 7.33888888888889e-06,
      "loss": 0.002,
      "step": 76790
    },
    {
      "epoch": 1.7066666666666666,
      "grad_norm": 0.3035918176174164,
      "learning_rate": 7.333333333333334e-06,
      "loss": 0.0024,
      "step": 76800
    },
    {
      "epoch": 1.706888888888889,
      "grad_norm": 0.2684991955757141,
      "learning_rate": 7.3277777777777775e-06,
      "loss": 0.0019,
      "step": 76810
    },
    {
      "epoch": 1.7071111111111112,
      "grad_norm": 0.06411543488502502,
      "learning_rate": 7.322222222222222e-06,
      "loss": 0.0018,
      "step": 76820
    },
    {
      "epoch": 1.7073333333333334,
      "grad_norm": 0.3135492503643036,
      "learning_rate": 7.316666666666667e-06,
      "loss": 0.0019,
      "step": 76830
    },
    {
      "epoch": 1.7075555555555555,
      "grad_norm": 0.35610195994377136,
      "learning_rate": 7.311111111111112e-06,
      "loss": 0.0027,
      "step": 76840
    },
    {
      "epoch": 1.7077777777777778,
      "grad_norm": 0.15149502456188202,
      "learning_rate": 7.305555555555556e-06,
      "loss": 0.0021,
      "step": 76850
    },
    {
      "epoch": 1.708,
      "grad_norm": 0.20373283326625824,
      "learning_rate": 7.2999999999999996e-06,
      "loss": 0.0028,
      "step": 76860
    },
    {
      "epoch": 1.708222222222222,
      "grad_norm": 0.34632420539855957,
      "learning_rate": 7.294444444444446e-06,
      "loss": 0.0019,
      "step": 76870
    },
    {
      "epoch": 1.7084444444444444,
      "grad_norm": 0.0681435763835907,
      "learning_rate": 7.288888888888889e-06,
      "loss": 0.0026,
      "step": 76880
    },
    {
      "epoch": 1.7086666666666668,
      "grad_norm": 0.24904468655586243,
      "learning_rate": 7.283333333333334e-06,
      "loss": 0.0016,
      "step": 76890
    },
    {
      "epoch": 1.708888888888889,
      "grad_norm": 0.3162619173526764,
      "learning_rate": 7.277777777777778e-06,
      "loss": 0.0019,
      "step": 76900
    },
    {
      "epoch": 1.709111111111111,
      "grad_norm": 0.3419048488140106,
      "learning_rate": 7.272222222222222e-06,
      "loss": 0.0017,
      "step": 76910
    },
    {
      "epoch": 1.7093333333333334,
      "grad_norm": 0.3965277373790741,
      "learning_rate": 7.266666666666668e-06,
      "loss": 0.0024,
      "step": 76920
    },
    {
      "epoch": 1.7095555555555557,
      "grad_norm": 0.2870030999183655,
      "learning_rate": 7.261111111111111e-06,
      "loss": 0.0027,
      "step": 76930
    },
    {
      "epoch": 1.7097777777777776,
      "grad_norm": 0.1480017602443695,
      "learning_rate": 7.255555555555556e-06,
      "loss": 0.0018,
      "step": 76940
    },
    {
      "epoch": 1.71,
      "grad_norm": 0.17719437181949615,
      "learning_rate": 7.25e-06,
      "loss": 0.0021,
      "step": 76950
    },
    {
      "epoch": 1.7102222222222223,
      "grad_norm": 0.46889257431030273,
      "learning_rate": 7.244444444444445e-06,
      "loss": 0.0023,
      "step": 76960
    },
    {
      "epoch": 1.7104444444444444,
      "grad_norm": 0.18817701935768127,
      "learning_rate": 7.23888888888889e-06,
      "loss": 0.0034,
      "step": 76970
    },
    {
      "epoch": 1.7106666666666666,
      "grad_norm": 0.4187590479850769,
      "learning_rate": 7.233333333333333e-06,
      "loss": 0.0019,
      "step": 76980
    },
    {
      "epoch": 1.710888888888889,
      "grad_norm": 0.2277306318283081,
      "learning_rate": 7.227777777777778e-06,
      "loss": 0.0018,
      "step": 76990
    },
    {
      "epoch": 1.7111111111111112,
      "grad_norm": 0.18129661679267883,
      "learning_rate": 7.222222222222222e-06,
      "loss": 0.0017,
      "step": 77000
    },
    {
      "epoch": 1.7113333333333334,
      "grad_norm": 0.1535225361585617,
      "learning_rate": 7.216666666666667e-06,
      "loss": 0.0018,
      "step": 77010
    },
    {
      "epoch": 1.7115555555555555,
      "grad_norm": 0.20490720868110657,
      "learning_rate": 7.211111111111112e-06,
      "loss": 0.0034,
      "step": 77020
    },
    {
      "epoch": 1.7117777777777778,
      "grad_norm": 0.08904001861810684,
      "learning_rate": 7.205555555555555e-06,
      "loss": 0.0027,
      "step": 77030
    },
    {
      "epoch": 1.712,
      "grad_norm": 0.15805469453334808,
      "learning_rate": 7.2e-06,
      "loss": 0.0023,
      "step": 77040
    },
    {
      "epoch": 1.712222222222222,
      "grad_norm": 0.22338254749774933,
      "learning_rate": 7.194444444444445e-06,
      "loss": 0.0019,
      "step": 77050
    },
    {
      "epoch": 1.7124444444444444,
      "grad_norm": 0.13777513802051544,
      "learning_rate": 7.188888888888889e-06,
      "loss": 0.0017,
      "step": 77060
    },
    {
      "epoch": 1.7126666666666668,
      "grad_norm": 0.4382246732711792,
      "learning_rate": 7.183333333333334e-06,
      "loss": 0.0019,
      "step": 77070
    },
    {
      "epoch": 1.712888888888889,
      "grad_norm": 0.11898090690374374,
      "learning_rate": 7.177777777777778e-06,
      "loss": 0.0019,
      "step": 77080
    },
    {
      "epoch": 1.713111111111111,
      "grad_norm": 0.05735369399189949,
      "learning_rate": 7.172222222222223e-06,
      "loss": 0.0033,
      "step": 77090
    },
    {
      "epoch": 1.7133333333333334,
      "grad_norm": 0.301399290561676,
      "learning_rate": 7.166666666666667e-06,
      "loss": 0.0024,
      "step": 77100
    },
    {
      "epoch": 1.7135555555555557,
      "grad_norm": 0.27619490027427673,
      "learning_rate": 7.161111111111111e-06,
      "loss": 0.0019,
      "step": 77110
    },
    {
      "epoch": 1.7137777777777776,
      "grad_norm": 0.2577338218688965,
      "learning_rate": 7.155555555555556e-06,
      "loss": 0.0024,
      "step": 77120
    },
    {
      "epoch": 1.714,
      "grad_norm": 0.07534842193126678,
      "learning_rate": 7.15e-06,
      "loss": 0.0016,
      "step": 77130
    },
    {
      "epoch": 1.7142222222222223,
      "grad_norm": 0.38087359070777893,
      "learning_rate": 7.144444444444445e-06,
      "loss": 0.0023,
      "step": 77140
    },
    {
      "epoch": 1.7144444444444444,
      "grad_norm": 0.5070342421531677,
      "learning_rate": 7.13888888888889e-06,
      "loss": 0.0018,
      "step": 77150
    },
    {
      "epoch": 1.7146666666666666,
      "grad_norm": 0.3995984196662903,
      "learning_rate": 7.133333333333333e-06,
      "loss": 0.0028,
      "step": 77160
    },
    {
      "epoch": 1.714888888888889,
      "grad_norm": 0.44092828035354614,
      "learning_rate": 7.127777777777778e-06,
      "loss": 0.0018,
      "step": 77170
    },
    {
      "epoch": 1.7151111111111113,
      "grad_norm": 0.08250408619642258,
      "learning_rate": 7.122222222222223e-06,
      "loss": 0.0022,
      "step": 77180
    },
    {
      "epoch": 1.7153333333333334,
      "grad_norm": 0.246527761220932,
      "learning_rate": 7.116666666666667e-06,
      "loss": 0.0018,
      "step": 77190
    },
    {
      "epoch": 1.7155555555555555,
      "grad_norm": 0.2519785165786743,
      "learning_rate": 7.111111111111112e-06,
      "loss": 0.0017,
      "step": 77200
    },
    {
      "epoch": 1.7157777777777778,
      "grad_norm": 0.179389089345932,
      "learning_rate": 7.105555555555555e-06,
      "loss": 0.0018,
      "step": 77210
    },
    {
      "epoch": 1.716,
      "grad_norm": 0.226532444357872,
      "learning_rate": 7.1e-06,
      "loss": 0.0024,
      "step": 77220
    },
    {
      "epoch": 1.716222222222222,
      "grad_norm": 0.16097669303417206,
      "learning_rate": 7.094444444444445e-06,
      "loss": 0.0026,
      "step": 77230
    },
    {
      "epoch": 1.7164444444444444,
      "grad_norm": 0.45157164335250854,
      "learning_rate": 7.0888888888888894e-06,
      "loss": 0.002,
      "step": 77240
    },
    {
      "epoch": 1.7166666666666668,
      "grad_norm": 0.13353151082992554,
      "learning_rate": 7.083333333333334e-06,
      "loss": 0.0025,
      "step": 77250
    },
    {
      "epoch": 1.716888888888889,
      "grad_norm": 0.08276891708374023,
      "learning_rate": 7.077777777777777e-06,
      "loss": 0.003,
      "step": 77260
    },
    {
      "epoch": 1.717111111111111,
      "grad_norm": 0.19085367023944855,
      "learning_rate": 7.0722222222222235e-06,
      "loss": 0.0019,
      "step": 77270
    },
    {
      "epoch": 1.7173333333333334,
      "grad_norm": 0.1117606908082962,
      "learning_rate": 7.066666666666667e-06,
      "loss": 0.0019,
      "step": 77280
    },
    {
      "epoch": 1.7175555555555555,
      "grad_norm": 0.20489627122879028,
      "learning_rate": 7.0611111111111115e-06,
      "loss": 0.0017,
      "step": 77290
    },
    {
      "epoch": 1.7177777777777776,
      "grad_norm": 0.0770261362195015,
      "learning_rate": 7.055555555555556e-06,
      "loss": 0.0019,
      "step": 77300
    },
    {
      "epoch": 1.718,
      "grad_norm": 0.24597781896591187,
      "learning_rate": 7.049999999999999e-06,
      "loss": 0.0025,
      "step": 77310
    },
    {
      "epoch": 1.7182222222222223,
      "grad_norm": 0.27456632256507874,
      "learning_rate": 7.0444444444444455e-06,
      "loss": 0.002,
      "step": 77320
    },
    {
      "epoch": 1.7184444444444444,
      "grad_norm": 0.2231157273054123,
      "learning_rate": 7.038888888888889e-06,
      "loss": 0.0018,
      "step": 77330
    },
    {
      "epoch": 1.7186666666666666,
      "grad_norm": 0.29790881276130676,
      "learning_rate": 7.0333333333333335e-06,
      "loss": 0.002,
      "step": 77340
    },
    {
      "epoch": 1.718888888888889,
      "grad_norm": 0.6460497379302979,
      "learning_rate": 7.027777777777778e-06,
      "loss": 0.0017,
      "step": 77350
    },
    {
      "epoch": 1.7191111111111113,
      "grad_norm": 0.46057358384132385,
      "learning_rate": 7.022222222222223e-06,
      "loss": 0.0017,
      "step": 77360
    },
    {
      "epoch": 1.7193333333333334,
      "grad_norm": 0.5466060042381287,
      "learning_rate": 7.0166666666666675e-06,
      "loss": 0.0016,
      "step": 77370
    },
    {
      "epoch": 1.7195555555555555,
      "grad_norm": 0.08386806398630142,
      "learning_rate": 7.011111111111111e-06,
      "loss": 0.002,
      "step": 77380
    },
    {
      "epoch": 1.7197777777777778,
      "grad_norm": 0.09316812455654144,
      "learning_rate": 7.0055555555555555e-06,
      "loss": 0.0018,
      "step": 77390
    },
    {
      "epoch": 1.72,
      "grad_norm": 0.35196825861930847,
      "learning_rate": 7.000000000000001e-06,
      "loss": 0.0022,
      "step": 77400
    },
    {
      "epoch": 1.720222222222222,
      "grad_norm": 0.19488801062107086,
      "learning_rate": 6.994444444444445e-06,
      "loss": 0.0019,
      "step": 77410
    },
    {
      "epoch": 1.7204444444444444,
      "grad_norm": 0.18471156060695648,
      "learning_rate": 6.9888888888888895e-06,
      "loss": 0.0018,
      "step": 77420
    },
    {
      "epoch": 1.7206666666666668,
      "grad_norm": 0.10445678234100342,
      "learning_rate": 6.983333333333333e-06,
      "loss": 0.0022,
      "step": 77430
    },
    {
      "epoch": 1.720888888888889,
      "grad_norm": 0.15179014205932617,
      "learning_rate": 6.9777777777777775e-06,
      "loss": 0.0028,
      "step": 77440
    },
    {
      "epoch": 1.721111111111111,
      "grad_norm": 0.32859647274017334,
      "learning_rate": 6.972222222222223e-06,
      "loss": 0.0024,
      "step": 77450
    },
    {
      "epoch": 1.7213333333333334,
      "grad_norm": 0.31187430024147034,
      "learning_rate": 6.966666666666667e-06,
      "loss": 0.0025,
      "step": 77460
    },
    {
      "epoch": 1.7215555555555555,
      "grad_norm": 0.5120747685432434,
      "learning_rate": 6.9611111111111116e-06,
      "loss": 0.0018,
      "step": 77470
    },
    {
      "epoch": 1.7217777777777776,
      "grad_norm": 0.28461384773254395,
      "learning_rate": 6.955555555555555e-06,
      "loss": 0.0017,
      "step": 77480
    },
    {
      "epoch": 1.722,
      "grad_norm": 0.11428458243608475,
      "learning_rate": 6.950000000000001e-06,
      "loss": 0.0019,
      "step": 77490
    },
    {
      "epoch": 1.7222222222222223,
      "grad_norm": 0.07061698287725449,
      "learning_rate": 6.944444444444445e-06,
      "loss": 0.0016,
      "step": 77500
    },
    {
      "epoch": 1.7224444444444444,
      "grad_norm": 0.39727136492729187,
      "learning_rate": 6.938888888888889e-06,
      "loss": 0.002,
      "step": 77510
    },
    {
      "epoch": 1.7226666666666666,
      "grad_norm": 0.13541586697101593,
      "learning_rate": 6.933333333333334e-06,
      "loss": 0.0021,
      "step": 77520
    },
    {
      "epoch": 1.722888888888889,
      "grad_norm": 0.23035846650600433,
      "learning_rate": 6.927777777777777e-06,
      "loss": 0.0019,
      "step": 77530
    },
    {
      "epoch": 1.7231111111111113,
      "grad_norm": 0.13316267728805542,
      "learning_rate": 6.922222222222223e-06,
      "loss": 0.0018,
      "step": 77540
    },
    {
      "epoch": 1.7233333333333334,
      "grad_norm": 0.22595541179180145,
      "learning_rate": 6.916666666666667e-06,
      "loss": 0.0025,
      "step": 77550
    },
    {
      "epoch": 1.7235555555555555,
      "grad_norm": 0.15606194734573364,
      "learning_rate": 6.911111111111111e-06,
      "loss": 0.0026,
      "step": 77560
    },
    {
      "epoch": 1.7237777777777779,
      "grad_norm": 0.0895301103591919,
      "learning_rate": 6.905555555555556e-06,
      "loss": 0.0016,
      "step": 77570
    },
    {
      "epoch": 1.724,
      "grad_norm": 0.05485456809401512,
      "learning_rate": 6.900000000000001e-06,
      "loss": 0.0019,
      "step": 77580
    },
    {
      "epoch": 1.724222222222222,
      "grad_norm": 0.6390829086303711,
      "learning_rate": 6.894444444444445e-06,
      "loss": 0.0021,
      "step": 77590
    },
    {
      "epoch": 1.7244444444444444,
      "grad_norm": 0.1426306813955307,
      "learning_rate": 6.888888888888889e-06,
      "loss": 0.0018,
      "step": 77600
    },
    {
      "epoch": 1.7246666666666668,
      "grad_norm": 0.17629031836986542,
      "learning_rate": 6.883333333333333e-06,
      "loss": 0.0017,
      "step": 77610
    },
    {
      "epoch": 1.724888888888889,
      "grad_norm": 0.35854941606521606,
      "learning_rate": 6.877777777777778e-06,
      "loss": 0.0026,
      "step": 77620
    },
    {
      "epoch": 1.725111111111111,
      "grad_norm": 0.29143470525741577,
      "learning_rate": 6.872222222222223e-06,
      "loss": 0.0018,
      "step": 77630
    },
    {
      "epoch": 1.7253333333333334,
      "grad_norm": 0.2853621244430542,
      "learning_rate": 6.866666666666667e-06,
      "loss": 0.0026,
      "step": 77640
    },
    {
      "epoch": 1.7255555555555555,
      "grad_norm": 0.645844578742981,
      "learning_rate": 6.861111111111111e-06,
      "loss": 0.0018,
      "step": 77650
    },
    {
      "epoch": 1.7257777777777776,
      "grad_norm": 0.5374395847320557,
      "learning_rate": 6.855555555555555e-06,
      "loss": 0.002,
      "step": 77660
    },
    {
      "epoch": 1.726,
      "grad_norm": 0.3267990052700043,
      "learning_rate": 6.8500000000000005e-06,
      "loss": 0.0019,
      "step": 77670
    },
    {
      "epoch": 1.7262222222222223,
      "grad_norm": 0.1311267763376236,
      "learning_rate": 6.844444444444445e-06,
      "loss": 0.0021,
      "step": 77680
    },
    {
      "epoch": 1.7264444444444444,
      "grad_norm": 0.1550133377313614,
      "learning_rate": 6.838888888888889e-06,
      "loss": 0.0028,
      "step": 77690
    },
    {
      "epoch": 1.7266666666666666,
      "grad_norm": 0.20312048494815826,
      "learning_rate": 6.833333333333333e-06,
      "loss": 0.0016,
      "step": 77700
    },
    {
      "epoch": 1.726888888888889,
      "grad_norm": 0.17421340942382812,
      "learning_rate": 6.827777777777779e-06,
      "loss": 0.002,
      "step": 77710
    },
    {
      "epoch": 1.7271111111111113,
      "grad_norm": 0.3176545202732086,
      "learning_rate": 6.8222222222222225e-06,
      "loss": 0.0021,
      "step": 77720
    },
    {
      "epoch": 1.7273333333333334,
      "grad_norm": 0.24766433238983154,
      "learning_rate": 6.816666666666667e-06,
      "loss": 0.0027,
      "step": 77730
    },
    {
      "epoch": 1.7275555555555555,
      "grad_norm": 0.27954429388046265,
      "learning_rate": 6.811111111111111e-06,
      "loss": 0.0018,
      "step": 77740
    },
    {
      "epoch": 1.7277777777777779,
      "grad_norm": 0.08435225486755371,
      "learning_rate": 6.805555555555556e-06,
      "loss": 0.002,
      "step": 77750
    },
    {
      "epoch": 1.728,
      "grad_norm": 0.12043756991624832,
      "learning_rate": 6.800000000000001e-06,
      "loss": 0.0028,
      "step": 77760
    },
    {
      "epoch": 1.728222222222222,
      "grad_norm": 0.19679348170757294,
      "learning_rate": 6.794444444444445e-06,
      "loss": 0.0022,
      "step": 77770
    },
    {
      "epoch": 1.7284444444444444,
      "grad_norm": 0.19074119627475739,
      "learning_rate": 6.788888888888889e-06,
      "loss": 0.0027,
      "step": 77780
    },
    {
      "epoch": 1.7286666666666668,
      "grad_norm": 0.13660351932048798,
      "learning_rate": 6.783333333333333e-06,
      "loss": 0.0023,
      "step": 77790
    },
    {
      "epoch": 1.728888888888889,
      "grad_norm": 0.3984752893447876,
      "learning_rate": 6.777777777777779e-06,
      "loss": 0.0018,
      "step": 77800
    },
    {
      "epoch": 1.729111111111111,
      "grad_norm": 0.20328548550605774,
      "learning_rate": 6.772222222222223e-06,
      "loss": 0.002,
      "step": 77810
    },
    {
      "epoch": 1.7293333333333334,
      "grad_norm": 0.36735042929649353,
      "learning_rate": 6.766666666666667e-06,
      "loss": 0.0026,
      "step": 77820
    },
    {
      "epoch": 1.7295555555555555,
      "grad_norm": 0.5077112317085266,
      "learning_rate": 6.761111111111111e-06,
      "loss": 0.0019,
      "step": 77830
    },
    {
      "epoch": 1.7297777777777776,
      "grad_norm": 0.09597061574459076,
      "learning_rate": 6.755555555555555e-06,
      "loss": 0.0022,
      "step": 77840
    },
    {
      "epoch": 1.73,
      "grad_norm": 0.06388716399669647,
      "learning_rate": 6.750000000000001e-06,
      "loss": 0.0018,
      "step": 77850
    },
    {
      "epoch": 1.7302222222222223,
      "grad_norm": 0.23275713622570038,
      "learning_rate": 6.744444444444445e-06,
      "loss": 0.0025,
      "step": 77860
    },
    {
      "epoch": 1.7304444444444445,
      "grad_norm": 0.4275788366794586,
      "learning_rate": 6.738888888888889e-06,
      "loss": 0.0021,
      "step": 77870
    },
    {
      "epoch": 1.7306666666666666,
      "grad_norm": 0.12584224343299866,
      "learning_rate": 6.733333333333333e-06,
      "loss": 0.0024,
      "step": 77880
    },
    {
      "epoch": 1.730888888888889,
      "grad_norm": 0.32987844944000244,
      "learning_rate": 6.727777777777779e-06,
      "loss": 0.0018,
      "step": 77890
    },
    {
      "epoch": 1.7311111111111113,
      "grad_norm": 0.27149415016174316,
      "learning_rate": 6.722222222222223e-06,
      "loss": 0.0024,
      "step": 77900
    },
    {
      "epoch": 1.7313333333333332,
      "grad_norm": 0.12969861924648285,
      "learning_rate": 6.716666666666667e-06,
      "loss": 0.0019,
      "step": 77910
    },
    {
      "epoch": 1.7315555555555555,
      "grad_norm": 0.10287287086248398,
      "learning_rate": 6.711111111111111e-06,
      "loss": 0.0017,
      "step": 77920
    },
    {
      "epoch": 1.7317777777777779,
      "grad_norm": 0.27165278792381287,
      "learning_rate": 6.705555555555555e-06,
      "loss": 0.0018,
      "step": 77930
    },
    {
      "epoch": 1.732,
      "grad_norm": 0.5055801272392273,
      "learning_rate": 6.700000000000001e-06,
      "loss": 0.0026,
      "step": 77940
    },
    {
      "epoch": 1.732222222222222,
      "grad_norm": 0.3782055377960205,
      "learning_rate": 6.694444444444445e-06,
      "loss": 0.0025,
      "step": 77950
    },
    {
      "epoch": 1.7324444444444445,
      "grad_norm": 0.1538848578929901,
      "learning_rate": 6.688888888888889e-06,
      "loss": 0.0018,
      "step": 77960
    },
    {
      "epoch": 1.7326666666666668,
      "grad_norm": 0.3967629671096802,
      "learning_rate": 6.6833333333333334e-06,
      "loss": 0.0018,
      "step": 77970
    },
    {
      "epoch": 1.732888888888889,
      "grad_norm": 0.5896111130714417,
      "learning_rate": 6.677777777777779e-06,
      "loss": 0.0019,
      "step": 77980
    },
    {
      "epoch": 1.733111111111111,
      "grad_norm": 0.17733465135097504,
      "learning_rate": 6.672222222222223e-06,
      "loss": 0.0017,
      "step": 77990
    },
    {
      "epoch": 1.7333333333333334,
      "grad_norm": 0.3697528541088104,
      "learning_rate": 6.666666666666667e-06,
      "loss": 0.0027,
      "step": 78000
    },
    {
      "epoch": 1.7335555555555555,
      "grad_norm": 0.29963454604148865,
      "learning_rate": 6.661111111111111e-06,
      "loss": 0.002,
      "step": 78010
    },
    {
      "epoch": 1.7337777777777776,
      "grad_norm": 0.1605389267206192,
      "learning_rate": 6.655555555555556e-06,
      "loss": 0.0017,
      "step": 78020
    },
    {
      "epoch": 1.734,
      "grad_norm": 0.12917520105838776,
      "learning_rate": 6.650000000000001e-06,
      "loss": 0.0026,
      "step": 78030
    },
    {
      "epoch": 1.7342222222222223,
      "grad_norm": 0.34322667121887207,
      "learning_rate": 6.644444444444445e-06,
      "loss": 0.0019,
      "step": 78040
    },
    {
      "epoch": 1.7344444444444445,
      "grad_norm": 0.20143236219882965,
      "learning_rate": 6.638888888888889e-06,
      "loss": 0.0023,
      "step": 78050
    },
    {
      "epoch": 1.7346666666666666,
      "grad_norm": 0.35538360476493835,
      "learning_rate": 6.633333333333333e-06,
      "loss": 0.002,
      "step": 78060
    },
    {
      "epoch": 1.734888888888889,
      "grad_norm": 0.14618322253227234,
      "learning_rate": 6.627777777777778e-06,
      "loss": 0.0021,
      "step": 78070
    },
    {
      "epoch": 1.7351111111111113,
      "grad_norm": 0.21344879269599915,
      "learning_rate": 6.622222222222223e-06,
      "loss": 0.0034,
      "step": 78080
    },
    {
      "epoch": 1.7353333333333332,
      "grad_norm": 0.21463541686534882,
      "learning_rate": 6.616666666666667e-06,
      "loss": 0.0017,
      "step": 78090
    },
    {
      "epoch": 1.7355555555555555,
      "grad_norm": 0.39734530448913574,
      "learning_rate": 6.611111111111111e-06,
      "loss": 0.0019,
      "step": 78100
    },
    {
      "epoch": 1.7357777777777779,
      "grad_norm": 0.3513394296169281,
      "learning_rate": 6.605555555555557e-06,
      "loss": 0.0025,
      "step": 78110
    },
    {
      "epoch": 1.736,
      "grad_norm": 0.25618159770965576,
      "learning_rate": 6.6e-06,
      "loss": 0.0019,
      "step": 78120
    },
    {
      "epoch": 1.7362222222222221,
      "grad_norm": 0.06426029652357101,
      "learning_rate": 6.594444444444445e-06,
      "loss": 0.0017,
      "step": 78130
    },
    {
      "epoch": 1.7364444444444445,
      "grad_norm": 0.08148770779371262,
      "learning_rate": 6.588888888888889e-06,
      "loss": 0.0022,
      "step": 78140
    },
    {
      "epoch": 1.7366666666666668,
      "grad_norm": 0.34566235542297363,
      "learning_rate": 6.583333333333333e-06,
      "loss": 0.002,
      "step": 78150
    },
    {
      "epoch": 1.736888888888889,
      "grad_norm": 0.21838854253292084,
      "learning_rate": 6.577777777777779e-06,
      "loss": 0.0017,
      "step": 78160
    },
    {
      "epoch": 1.737111111111111,
      "grad_norm": 0.6138148307800293,
      "learning_rate": 6.572222222222222e-06,
      "loss": 0.0022,
      "step": 78170
    },
    {
      "epoch": 1.7373333333333334,
      "grad_norm": 0.29194143414497375,
      "learning_rate": 6.566666666666667e-06,
      "loss": 0.0025,
      "step": 78180
    },
    {
      "epoch": 1.7375555555555555,
      "grad_norm": 0.41179996728897095,
      "learning_rate": 6.561111111111111e-06,
      "loss": 0.0019,
      "step": 78190
    },
    {
      "epoch": 1.7377777777777776,
      "grad_norm": 0.20573976635932922,
      "learning_rate": 6.555555555555556e-06,
      "loss": 0.002,
      "step": 78200
    },
    {
      "epoch": 1.738,
      "grad_norm": 0.0773412212729454,
      "learning_rate": 6.550000000000001e-06,
      "loss": 0.0017,
      "step": 78210
    },
    {
      "epoch": 1.7382222222222223,
      "grad_norm": 0.36154258251190186,
      "learning_rate": 6.544444444444444e-06,
      "loss": 0.002,
      "step": 78220
    },
    {
      "epoch": 1.7384444444444445,
      "grad_norm": 0.19465003907680511,
      "learning_rate": 6.538888888888889e-06,
      "loss": 0.0019,
      "step": 78230
    },
    {
      "epoch": 1.7386666666666666,
      "grad_norm": 0.17864933609962463,
      "learning_rate": 6.533333333333333e-06,
      "loss": 0.0038,
      "step": 78240
    },
    {
      "epoch": 1.738888888888889,
      "grad_norm": 0.5803521871566772,
      "learning_rate": 6.5277777777777784e-06,
      "loss": 0.0025,
      "step": 78250
    },
    {
      "epoch": 1.7391111111111113,
      "grad_norm": 0.07638729363679886,
      "learning_rate": 6.522222222222223e-06,
      "loss": 0.0026,
      "step": 78260
    },
    {
      "epoch": 1.7393333333333332,
      "grad_norm": 0.138250470161438,
      "learning_rate": 6.516666666666666e-06,
      "loss": 0.0019,
      "step": 78270
    },
    {
      "epoch": 1.7395555555555555,
      "grad_norm": 0.3670966923236847,
      "learning_rate": 6.511111111111111e-06,
      "loss": 0.003,
      "step": 78280
    },
    {
      "epoch": 1.7397777777777779,
      "grad_norm": 0.07268994301557541,
      "learning_rate": 6.505555555555556e-06,
      "loss": 0.0034,
      "step": 78290
    },
    {
      "epoch": 1.74,
      "grad_norm": 0.10796376317739487,
      "learning_rate": 6.5000000000000004e-06,
      "loss": 0.0022,
      "step": 78300
    },
    {
      "epoch": 1.7402222222222221,
      "grad_norm": 0.22008681297302246,
      "learning_rate": 6.494444444444445e-06,
      "loss": 0.0018,
      "step": 78310
    },
    {
      "epoch": 1.7404444444444445,
      "grad_norm": 0.371425062417984,
      "learning_rate": 6.488888888888888e-06,
      "loss": 0.0015,
      "step": 78320
    },
    {
      "epoch": 1.7406666666666668,
      "grad_norm": 0.21519114077091217,
      "learning_rate": 6.4833333333333345e-06,
      "loss": 0.0024,
      "step": 78330
    },
    {
      "epoch": 1.740888888888889,
      "grad_norm": 0.13491660356521606,
      "learning_rate": 6.477777777777778e-06,
      "loss": 0.0021,
      "step": 78340
    },
    {
      "epoch": 1.741111111111111,
      "grad_norm": 0.3394630253314972,
      "learning_rate": 6.4722222222222225e-06,
      "loss": 0.002,
      "step": 78350
    },
    {
      "epoch": 1.7413333333333334,
      "grad_norm": 0.31101810932159424,
      "learning_rate": 6.466666666666667e-06,
      "loss": 0.0026,
      "step": 78360
    },
    {
      "epoch": 1.7415555555555555,
      "grad_norm": 0.0933729037642479,
      "learning_rate": 6.4611111111111104e-06,
      "loss": 0.0024,
      "step": 78370
    },
    {
      "epoch": 1.7417777777777776,
      "grad_norm": 0.10549499094486237,
      "learning_rate": 6.4555555555555565e-06,
      "loss": 0.0028,
      "step": 78380
    },
    {
      "epoch": 1.742,
      "grad_norm": 0.07745260000228882,
      "learning_rate": 6.45e-06,
      "loss": 0.0024,
      "step": 78390
    },
    {
      "epoch": 1.7422222222222223,
      "grad_norm": 0.18460571765899658,
      "learning_rate": 6.4444444444444445e-06,
      "loss": 0.0021,
      "step": 78400
    },
    {
      "epoch": 1.7424444444444445,
      "grad_norm": 0.1642848402261734,
      "learning_rate": 6.438888888888889e-06,
      "loss": 0.0021,
      "step": 78410
    },
    {
      "epoch": 1.7426666666666666,
      "grad_norm": 0.10594827681779861,
      "learning_rate": 6.433333333333334e-06,
      "loss": 0.0019,
      "step": 78420
    },
    {
      "epoch": 1.742888888888889,
      "grad_norm": 0.2752440571784973,
      "learning_rate": 6.4277777777777785e-06,
      "loss": 0.0018,
      "step": 78430
    },
    {
      "epoch": 1.743111111111111,
      "grad_norm": 0.061710529029369354,
      "learning_rate": 6.422222222222223e-06,
      "loss": 0.0018,
      "step": 78440
    },
    {
      "epoch": 1.7433333333333332,
      "grad_norm": 0.5645928382873535,
      "learning_rate": 6.4166666666666665e-06,
      "loss": 0.0025,
      "step": 78450
    },
    {
      "epoch": 1.7435555555555555,
      "grad_norm": 0.08619362115859985,
      "learning_rate": 6.411111111111111e-06,
      "loss": 0.0019,
      "step": 78460
    },
    {
      "epoch": 1.7437777777777779,
      "grad_norm": 0.16320466995239258,
      "learning_rate": 6.405555555555556e-06,
      "loss": 0.0018,
      "step": 78470
    },
    {
      "epoch": 1.744,
      "grad_norm": 0.2317725569009781,
      "learning_rate": 6.4000000000000006e-06,
      "loss": 0.0019,
      "step": 78480
    },
    {
      "epoch": 1.7442222222222221,
      "grad_norm": 0.0862407460808754,
      "learning_rate": 6.394444444444445e-06,
      "loss": 0.0019,
      "step": 78490
    },
    {
      "epoch": 1.7444444444444445,
      "grad_norm": 0.0752461776137352,
      "learning_rate": 6.3888888888888885e-06,
      "loss": 0.0025,
      "step": 78500
    },
    {
      "epoch": 1.7446666666666668,
      "grad_norm": 0.1107247918844223,
      "learning_rate": 6.383333333333335e-06,
      "loss": 0.0017,
      "step": 78510
    },
    {
      "epoch": 1.744888888888889,
      "grad_norm": 0.09143763035535812,
      "learning_rate": 6.377777777777778e-06,
      "loss": 0.0019,
      "step": 78520
    },
    {
      "epoch": 1.745111111111111,
      "grad_norm": 0.5053751468658447,
      "learning_rate": 6.3722222222222226e-06,
      "loss": 0.002,
      "step": 78530
    },
    {
      "epoch": 1.7453333333333334,
      "grad_norm": 0.0699155181646347,
      "learning_rate": 6.366666666666667e-06,
      "loss": 0.0029,
      "step": 78540
    },
    {
      "epoch": 1.7455555555555555,
      "grad_norm": 0.12692277133464813,
      "learning_rate": 6.3611111111111105e-06,
      "loss": 0.003,
      "step": 78550
    },
    {
      "epoch": 1.7457777777777777,
      "grad_norm": 0.07693874835968018,
      "learning_rate": 6.355555555555557e-06,
      "loss": 0.0016,
      "step": 78560
    },
    {
      "epoch": 1.746,
      "grad_norm": 0.12705694139003754,
      "learning_rate": 6.35e-06,
      "loss": 0.0018,
      "step": 78570
    },
    {
      "epoch": 1.7462222222222223,
      "grad_norm": 0.1291714310646057,
      "learning_rate": 6.344444444444445e-06,
      "loss": 0.0021,
      "step": 78580
    },
    {
      "epoch": 1.7464444444444445,
      "grad_norm": 0.2244628667831421,
      "learning_rate": 6.338888888888889e-06,
      "loss": 0.002,
      "step": 78590
    },
    {
      "epoch": 1.7466666666666666,
      "grad_norm": 0.6234465837478638,
      "learning_rate": 6.333333333333334e-06,
      "loss": 0.0018,
      "step": 78600
    },
    {
      "epoch": 1.746888888888889,
      "grad_norm": 0.11750151962041855,
      "learning_rate": 6.327777777777779e-06,
      "loss": 0.0019,
      "step": 78610
    },
    {
      "epoch": 1.747111111111111,
      "grad_norm": 0.08030042797327042,
      "learning_rate": 6.322222222222222e-06,
      "loss": 0.0024,
      "step": 78620
    },
    {
      "epoch": 1.7473333333333332,
      "grad_norm": 0.0747164636850357,
      "learning_rate": 6.316666666666667e-06,
      "loss": 0.0016,
      "step": 78630
    },
    {
      "epoch": 1.7475555555555555,
      "grad_norm": 0.30776700377464294,
      "learning_rate": 6.311111111111112e-06,
      "loss": 0.002,
      "step": 78640
    },
    {
      "epoch": 1.7477777777777779,
      "grad_norm": 0.10378798097372055,
      "learning_rate": 6.305555555555556e-06,
      "loss": 0.0016,
      "step": 78650
    },
    {
      "epoch": 1.748,
      "grad_norm": 0.08693523705005646,
      "learning_rate": 6.300000000000001e-06,
      "loss": 0.0017,
      "step": 78660
    },
    {
      "epoch": 1.7482222222222221,
      "grad_norm": 0.214948371052742,
      "learning_rate": 6.294444444444444e-06,
      "loss": 0.0019,
      "step": 78670
    },
    {
      "epoch": 1.7484444444444445,
      "grad_norm": 0.088463194668293,
      "learning_rate": 6.288888888888889e-06,
      "loss": 0.0016,
      "step": 78680
    },
    {
      "epoch": 1.7486666666666668,
      "grad_norm": 0.5614972710609436,
      "learning_rate": 6.283333333333334e-06,
      "loss": 0.0017,
      "step": 78690
    },
    {
      "epoch": 1.748888888888889,
      "grad_norm": 0.4375694990158081,
      "learning_rate": 6.277777777777778e-06,
      "loss": 0.002,
      "step": 78700
    },
    {
      "epoch": 1.749111111111111,
      "grad_norm": 0.3198772668838501,
      "learning_rate": 6.272222222222223e-06,
      "loss": 0.0018,
      "step": 78710
    },
    {
      "epoch": 1.7493333333333334,
      "grad_norm": 0.11025784909725189,
      "learning_rate": 6.266666666666666e-06,
      "loss": 0.0026,
      "step": 78720
    },
    {
      "epoch": 1.7495555555555555,
      "grad_norm": 0.07668758928775787,
      "learning_rate": 6.261111111111112e-06,
      "loss": 0.0017,
      "step": 78730
    },
    {
      "epoch": 1.7497777777777777,
      "grad_norm": 0.11465175449848175,
      "learning_rate": 6.255555555555556e-06,
      "loss": 0.0025,
      "step": 78740
    },
    {
      "epoch": 1.75,
      "grad_norm": 0.20085465908050537,
      "learning_rate": 6.25e-06,
      "loss": 0.0021,
      "step": 78750
    },
    {
      "epoch": 1.7502222222222223,
      "grad_norm": 0.2775641977787018,
      "learning_rate": 6.244444444444445e-06,
      "loss": 0.0017,
      "step": 78760
    },
    {
      "epoch": 1.7504444444444445,
      "grad_norm": 0.055308133363723755,
      "learning_rate": 6.238888888888889e-06,
      "loss": 0.0019,
      "step": 78770
    },
    {
      "epoch": 1.7506666666666666,
      "grad_norm": 0.07026023417711258,
      "learning_rate": 6.2333333333333335e-06,
      "loss": 0.0021,
      "step": 78780
    },
    {
      "epoch": 1.750888888888889,
      "grad_norm": 0.1704474240541458,
      "learning_rate": 6.227777777777778e-06,
      "loss": 0.0025,
      "step": 78790
    },
    {
      "epoch": 1.751111111111111,
      "grad_norm": 0.22610361874103546,
      "learning_rate": 6.222222222222222e-06,
      "loss": 0.0019,
      "step": 78800
    },
    {
      "epoch": 1.7513333333333332,
      "grad_norm": 0.47636622190475464,
      "learning_rate": 6.2166666666666676e-06,
      "loss": 0.002,
      "step": 78810
    },
    {
      "epoch": 1.7515555555555555,
      "grad_norm": 0.29692307114601135,
      "learning_rate": 6.211111111111111e-06,
      "loss": 0.0017,
      "step": 78820
    },
    {
      "epoch": 1.7517777777777779,
      "grad_norm": 0.3862208127975464,
      "learning_rate": 6.205555555555556e-06,
      "loss": 0.002,
      "step": 78830
    },
    {
      "epoch": 1.752,
      "grad_norm": 0.13713307678699493,
      "learning_rate": 6.2e-06,
      "loss": 0.0034,
      "step": 78840
    },
    {
      "epoch": 1.7522222222222221,
      "grad_norm": 0.3722285032272339,
      "learning_rate": 6.194444444444445e-06,
      "loss": 0.002,
      "step": 78850
    },
    {
      "epoch": 1.7524444444444445,
      "grad_norm": 0.21780036389827728,
      "learning_rate": 6.18888888888889e-06,
      "loss": 0.002,
      "step": 78860
    },
    {
      "epoch": 1.7526666666666668,
      "grad_norm": 0.1444847285747528,
      "learning_rate": 6.183333333333333e-06,
      "loss": 0.0017,
      "step": 78870
    },
    {
      "epoch": 1.752888888888889,
      "grad_norm": 0.07041485607624054,
      "learning_rate": 6.177777777777778e-06,
      "loss": 0.0025,
      "step": 78880
    },
    {
      "epoch": 1.753111111111111,
      "grad_norm": 0.5362544655799866,
      "learning_rate": 6.172222222222222e-06,
      "loss": 0.0018,
      "step": 78890
    },
    {
      "epoch": 1.7533333333333334,
      "grad_norm": 0.151518315076828,
      "learning_rate": 6.166666666666667e-06,
      "loss": 0.0019,
      "step": 78900
    },
    {
      "epoch": 1.7535555555555555,
      "grad_norm": 0.31379199028015137,
      "learning_rate": 6.161111111111112e-06,
      "loss": 0.0025,
      "step": 78910
    },
    {
      "epoch": 1.7537777777777777,
      "grad_norm": 0.313914030790329,
      "learning_rate": 6.155555555555556e-06,
      "loss": 0.0017,
      "step": 78920
    },
    {
      "epoch": 1.754,
      "grad_norm": 0.3590972125530243,
      "learning_rate": 6.15e-06,
      "loss": 0.0021,
      "step": 78930
    },
    {
      "epoch": 1.7542222222222223,
      "grad_norm": 0.44071224331855774,
      "learning_rate": 6.144444444444445e-06,
      "loss": 0.0036,
      "step": 78940
    },
    {
      "epoch": 1.7544444444444445,
      "grad_norm": 0.1221076250076294,
      "learning_rate": 6.138888888888889e-06,
      "loss": 0.0019,
      "step": 78950
    },
    {
      "epoch": 1.7546666666666666,
      "grad_norm": 0.33242639899253845,
      "learning_rate": 6.133333333333334e-06,
      "loss": 0.0017,
      "step": 78960
    },
    {
      "epoch": 1.754888888888889,
      "grad_norm": 0.14913971722126007,
      "learning_rate": 6.127777777777778e-06,
      "loss": 0.0017,
      "step": 78970
    },
    {
      "epoch": 1.755111111111111,
      "grad_norm": 0.11985760182142258,
      "learning_rate": 6.1222222222222224e-06,
      "loss": 0.0017,
      "step": 78980
    },
    {
      "epoch": 1.7553333333333332,
      "grad_norm": 0.27014124393463135,
      "learning_rate": 6.116666666666667e-06,
      "loss": 0.0029,
      "step": 78990
    },
    {
      "epoch": 1.7555555555555555,
      "grad_norm": 0.26008105278015137,
      "learning_rate": 6.111111111111111e-06,
      "loss": 0.0017,
      "step": 79000
    },
    {
      "epoch": 1.7557777777777779,
      "grad_norm": 0.06632445007562637,
      "learning_rate": 6.105555555555556e-06,
      "loss": 0.0022,
      "step": 79010
    },
    {
      "epoch": 1.756,
      "grad_norm": 0.12103907018899918,
      "learning_rate": 6.1e-06,
      "loss": 0.002,
      "step": 79020
    },
    {
      "epoch": 1.7562222222222221,
      "grad_norm": 0.2617985010147095,
      "learning_rate": 6.094444444444445e-06,
      "loss": 0.0018,
      "step": 79030
    },
    {
      "epoch": 1.7564444444444445,
      "grad_norm": 0.45764607191085815,
      "learning_rate": 6.088888888888889e-06,
      "loss": 0.002,
      "step": 79040
    },
    {
      "epoch": 1.7566666666666668,
      "grad_norm": 0.0820285826921463,
      "learning_rate": 6.083333333333334e-06,
      "loss": 0.0025,
      "step": 79050
    },
    {
      "epoch": 1.756888888888889,
      "grad_norm": 0.39448171854019165,
      "learning_rate": 6.077777777777778e-06,
      "loss": 0.0026,
      "step": 79060
    },
    {
      "epoch": 1.757111111111111,
      "grad_norm": 0.21585768461227417,
      "learning_rate": 6.072222222222222e-06,
      "loss": 0.0031,
      "step": 79070
    },
    {
      "epoch": 1.7573333333333334,
      "grad_norm": 0.32967662811279297,
      "learning_rate": 6.066666666666667e-06,
      "loss": 0.0019,
      "step": 79080
    },
    {
      "epoch": 1.7575555555555555,
      "grad_norm": 0.33839744329452515,
      "learning_rate": 6.061111111111111e-06,
      "loss": 0.0029,
      "step": 79090
    },
    {
      "epoch": 1.7577777777777777,
      "grad_norm": 0.23420684039592743,
      "learning_rate": 6.055555555555556e-06,
      "loss": 0.0017,
      "step": 79100
    },
    {
      "epoch": 1.758,
      "grad_norm": 0.34102627635002136,
      "learning_rate": 6.0500000000000005e-06,
      "loss": 0.0026,
      "step": 79110
    },
    {
      "epoch": 1.7582222222222224,
      "grad_norm": 0.24974246323108673,
      "learning_rate": 6.044444444444445e-06,
      "loss": 0.0025,
      "step": 79120
    },
    {
      "epoch": 1.7584444444444445,
      "grad_norm": 0.36452922224998474,
      "learning_rate": 6.038888888888889e-06,
      "loss": 0.0027,
      "step": 79130
    },
    {
      "epoch": 1.7586666666666666,
      "grad_norm": 0.10451404750347137,
      "learning_rate": 6.033333333333334e-06,
      "loss": 0.0023,
      "step": 79140
    },
    {
      "epoch": 1.758888888888889,
      "grad_norm": 0.11257121711969376,
      "learning_rate": 6.027777777777778e-06,
      "loss": 0.0019,
      "step": 79150
    },
    {
      "epoch": 1.759111111111111,
      "grad_norm": 0.2420741319656372,
      "learning_rate": 6.0222222222222225e-06,
      "loss": 0.0021,
      "step": 79160
    },
    {
      "epoch": 1.7593333333333332,
      "grad_norm": 0.17293772101402283,
      "learning_rate": 6.016666666666667e-06,
      "loss": 0.0021,
      "step": 79170
    },
    {
      "epoch": 1.7595555555555555,
      "grad_norm": 0.18766863644123077,
      "learning_rate": 6.011111111111111e-06,
      "loss": 0.0021,
      "step": 79180
    },
    {
      "epoch": 1.7597777777777779,
      "grad_norm": 0.5188747048377991,
      "learning_rate": 6.005555555555556e-06,
      "loss": 0.0026,
      "step": 79190
    },
    {
      "epoch": 1.76,
      "grad_norm": 0.42615917325019836,
      "learning_rate": 6e-06,
      "loss": 0.002,
      "step": 79200
    },
    {
      "epoch": 1.7602222222222221,
      "grad_norm": 0.3295283615589142,
      "learning_rate": 5.9944444444444446e-06,
      "loss": 0.0018,
      "step": 79210
    },
    {
      "epoch": 1.7604444444444445,
      "grad_norm": 0.22233766317367554,
      "learning_rate": 5.988888888888889e-06,
      "loss": 0.0025,
      "step": 79220
    },
    {
      "epoch": 1.7606666666666668,
      "grad_norm": 0.08400377631187439,
      "learning_rate": 5.983333333333334e-06,
      "loss": 0.0026,
      "step": 79230
    },
    {
      "epoch": 1.7608888888888887,
      "grad_norm": 0.07222965359687805,
      "learning_rate": 5.977777777777778e-06,
      "loss": 0.0017,
      "step": 79240
    },
    {
      "epoch": 1.761111111111111,
      "grad_norm": 0.25801265239715576,
      "learning_rate": 5.972222222222223e-06,
      "loss": 0.0018,
      "step": 79250
    },
    {
      "epoch": 1.7613333333333334,
      "grad_norm": 0.2467377781867981,
      "learning_rate": 5.9666666666666666e-06,
      "loss": 0.0018,
      "step": 79260
    },
    {
      "epoch": 1.7615555555555555,
      "grad_norm": 0.059301964938640594,
      "learning_rate": 5.961111111111111e-06,
      "loss": 0.0018,
      "step": 79270
    },
    {
      "epoch": 1.7617777777777777,
      "grad_norm": 0.07638233155012131,
      "learning_rate": 5.955555555555556e-06,
      "loss": 0.0026,
      "step": 79280
    },
    {
      "epoch": 1.762,
      "grad_norm": 0.0839085578918457,
      "learning_rate": 5.95e-06,
      "loss": 0.0017,
      "step": 79290
    },
    {
      "epoch": 1.7622222222222224,
      "grad_norm": 0.11079101264476776,
      "learning_rate": 5.944444444444445e-06,
      "loss": 0.0021,
      "step": 79300
    },
    {
      "epoch": 1.7624444444444445,
      "grad_norm": 0.3721885681152344,
      "learning_rate": 5.938888888888889e-06,
      "loss": 0.0019,
      "step": 79310
    },
    {
      "epoch": 1.7626666666666666,
      "grad_norm": 0.08862148970365524,
      "learning_rate": 5.933333333333334e-06,
      "loss": 0.0016,
      "step": 79320
    },
    {
      "epoch": 1.762888888888889,
      "grad_norm": 0.061183780431747437,
      "learning_rate": 5.927777777777778e-06,
      "loss": 0.0019,
      "step": 79330
    },
    {
      "epoch": 1.763111111111111,
      "grad_norm": 0.09495560079813004,
      "learning_rate": 5.922222222222223e-06,
      "loss": 0.0019,
      "step": 79340
    },
    {
      "epoch": 1.7633333333333332,
      "grad_norm": 0.11067097634077072,
      "learning_rate": 5.916666666666667e-06,
      "loss": 0.0027,
      "step": 79350
    },
    {
      "epoch": 1.7635555555555555,
      "grad_norm": 0.15766899287700653,
      "learning_rate": 5.9111111111111115e-06,
      "loss": 0.0017,
      "step": 79360
    },
    {
      "epoch": 1.7637777777777779,
      "grad_norm": 0.28458836674690247,
      "learning_rate": 5.905555555555556e-06,
      "loss": 0.0022,
      "step": 79370
    },
    {
      "epoch": 1.764,
      "grad_norm": 0.691437840461731,
      "learning_rate": 5.9e-06,
      "loss": 0.0017,
      "step": 79380
    },
    {
      "epoch": 1.7642222222222221,
      "grad_norm": 0.13664160668849945,
      "learning_rate": 5.894444444444445e-06,
      "loss": 0.0019,
      "step": 79390
    },
    {
      "epoch": 1.7644444444444445,
      "grad_norm": 0.0713573694229126,
      "learning_rate": 5.888888888888889e-06,
      "loss": 0.0023,
      "step": 79400
    },
    {
      "epoch": 1.7646666666666668,
      "grad_norm": 0.23925580084323883,
      "learning_rate": 5.8833333333333335e-06,
      "loss": 0.0016,
      "step": 79410
    },
    {
      "epoch": 1.7648888888888887,
      "grad_norm": 0.18705542385578156,
      "learning_rate": 5.877777777777778e-06,
      "loss": 0.0017,
      "step": 79420
    },
    {
      "epoch": 1.765111111111111,
      "grad_norm": 0.15588746964931488,
      "learning_rate": 5.872222222222223e-06,
      "loss": 0.0019,
      "step": 79430
    },
    {
      "epoch": 1.7653333333333334,
      "grad_norm": 0.07992754131555557,
      "learning_rate": 5.866666666666667e-06,
      "loss": 0.0025,
      "step": 79440
    },
    {
      "epoch": 1.7655555555555555,
      "grad_norm": 0.23508423566818237,
      "learning_rate": 5.861111111111112e-06,
      "loss": 0.0024,
      "step": 79450
    },
    {
      "epoch": 1.7657777777777777,
      "grad_norm": 0.08511576056480408,
      "learning_rate": 5.8555555555555555e-06,
      "loss": 0.0023,
      "step": 79460
    },
    {
      "epoch": 1.766,
      "grad_norm": 0.14198674261569977,
      "learning_rate": 5.850000000000001e-06,
      "loss": 0.0018,
      "step": 79470
    },
    {
      "epoch": 1.7662222222222224,
      "grad_norm": 0.32012104988098145,
      "learning_rate": 5.844444444444445e-06,
      "loss": 0.0018,
      "step": 79480
    },
    {
      "epoch": 1.7664444444444445,
      "grad_norm": 0.2738381326198578,
      "learning_rate": 5.838888888888889e-06,
      "loss": 0.0015,
      "step": 79490
    },
    {
      "epoch": 1.7666666666666666,
      "grad_norm": 0.38495510816574097,
      "learning_rate": 5.833333333333334e-06,
      "loss": 0.0019,
      "step": 79500
    },
    {
      "epoch": 1.766888888888889,
      "grad_norm": 0.5402854681015015,
      "learning_rate": 5.8277777777777775e-06,
      "loss": 0.003,
      "step": 79510
    },
    {
      "epoch": 1.767111111111111,
      "grad_norm": 0.08953604847192764,
      "learning_rate": 5.822222222222223e-06,
      "loss": 0.0026,
      "step": 79520
    },
    {
      "epoch": 1.7673333333333332,
      "grad_norm": 0.3175787627696991,
      "learning_rate": 5.816666666666667e-06,
      "loss": 0.0024,
      "step": 79530
    },
    {
      "epoch": 1.7675555555555555,
      "grad_norm": 0.4238754212856293,
      "learning_rate": 5.8111111111111116e-06,
      "loss": 0.0018,
      "step": 79540
    },
    {
      "epoch": 1.767777777777778,
      "grad_norm": 0.39972853660583496,
      "learning_rate": 5.805555555555556e-06,
      "loss": 0.0022,
      "step": 79550
    },
    {
      "epoch": 1.768,
      "grad_norm": 0.14998476207256317,
      "learning_rate": 5.8e-06,
      "loss": 0.0018,
      "step": 79560
    },
    {
      "epoch": 1.7682222222222221,
      "grad_norm": 0.11510353535413742,
      "learning_rate": 5.794444444444445e-06,
      "loss": 0.0017,
      "step": 79570
    },
    {
      "epoch": 1.7684444444444445,
      "grad_norm": 0.09674622118473053,
      "learning_rate": 5.788888888888889e-06,
      "loss": 0.0029,
      "step": 79580
    },
    {
      "epoch": 1.7686666666666668,
      "grad_norm": 0.07368390262126923,
      "learning_rate": 5.783333333333334e-06,
      "loss": 0.0019,
      "step": 79590
    },
    {
      "epoch": 1.7688888888888887,
      "grad_norm": 0.27752426266670227,
      "learning_rate": 5.777777777777778e-06,
      "loss": 0.0018,
      "step": 79600
    },
    {
      "epoch": 1.769111111111111,
      "grad_norm": 0.05764997750520706,
      "learning_rate": 5.772222222222222e-06,
      "loss": 0.0026,
      "step": 79610
    },
    {
      "epoch": 1.7693333333333334,
      "grad_norm": 0.4258568584918976,
      "learning_rate": 5.766666666666667e-06,
      "loss": 0.0028,
      "step": 79620
    },
    {
      "epoch": 1.7695555555555555,
      "grad_norm": 0.11537614464759827,
      "learning_rate": 5.761111111111111e-06,
      "loss": 0.0018,
      "step": 79630
    },
    {
      "epoch": 1.7697777777777777,
      "grad_norm": 0.09691721946001053,
      "learning_rate": 5.755555555555556e-06,
      "loss": 0.0018,
      "step": 79640
    },
    {
      "epoch": 1.77,
      "grad_norm": 0.11803193390369415,
      "learning_rate": 5.750000000000001e-06,
      "loss": 0.002,
      "step": 79650
    },
    {
      "epoch": 1.7702222222222224,
      "grad_norm": 0.12945254147052765,
      "learning_rate": 5.744444444444444e-06,
      "loss": 0.0017,
      "step": 79660
    },
    {
      "epoch": 1.7704444444444445,
      "grad_norm": 0.13291707634925842,
      "learning_rate": 5.73888888888889e-06,
      "loss": 0.0019,
      "step": 79670
    },
    {
      "epoch": 1.7706666666666666,
      "grad_norm": 0.20367462933063507,
      "learning_rate": 5.733333333333333e-06,
      "loss": 0.0019,
      "step": 79680
    },
    {
      "epoch": 1.770888888888889,
      "grad_norm": 0.3239418864250183,
      "learning_rate": 5.727777777777778e-06,
      "loss": 0.0025,
      "step": 79690
    },
    {
      "epoch": 1.771111111111111,
      "grad_norm": 0.24977532029151917,
      "learning_rate": 5.722222222222223e-06,
      "loss": 0.0019,
      "step": 79700
    },
    {
      "epoch": 1.7713333333333332,
      "grad_norm": 0.49487462639808655,
      "learning_rate": 5.7166666666666664e-06,
      "loss": 0.0024,
      "step": 79710
    },
    {
      "epoch": 1.7715555555555556,
      "grad_norm": 0.53416508436203,
      "learning_rate": 5.711111111111112e-06,
      "loss": 0.0019,
      "step": 79720
    },
    {
      "epoch": 1.771777777777778,
      "grad_norm": 0.12155088037252426,
      "learning_rate": 5.705555555555555e-06,
      "loss": 0.0022,
      "step": 79730
    },
    {
      "epoch": 1.772,
      "grad_norm": 0.13146382570266724,
      "learning_rate": 5.7000000000000005e-06,
      "loss": 0.0021,
      "step": 79740
    },
    {
      "epoch": 1.7722222222222221,
      "grad_norm": 0.48241761326789856,
      "learning_rate": 5.694444444444445e-06,
      "loss": 0.003,
      "step": 79750
    },
    {
      "epoch": 1.7724444444444445,
      "grad_norm": 0.06803659349679947,
      "learning_rate": 5.688888888888889e-06,
      "loss": 0.0024,
      "step": 79760
    },
    {
      "epoch": 1.7726666666666666,
      "grad_norm": 0.6485198736190796,
      "learning_rate": 5.683333333333334e-06,
      "loss": 0.0025,
      "step": 79770
    },
    {
      "epoch": 1.7728888888888887,
      "grad_norm": 0.41001763939857483,
      "learning_rate": 5.677777777777778e-06,
      "loss": 0.0018,
      "step": 79780
    },
    {
      "epoch": 1.773111111111111,
      "grad_norm": 0.38586896657943726,
      "learning_rate": 5.6722222222222225e-06,
      "loss": 0.0022,
      "step": 79790
    },
    {
      "epoch": 1.7733333333333334,
      "grad_norm": 0.42852580547332764,
      "learning_rate": 5.666666666666667e-06,
      "loss": 0.0026,
      "step": 79800
    },
    {
      "epoch": 1.7735555555555556,
      "grad_norm": 0.10773084312677383,
      "learning_rate": 5.661111111111111e-06,
      "loss": 0.0016,
      "step": 79810
    },
    {
      "epoch": 1.7737777777777777,
      "grad_norm": 0.23284967243671417,
      "learning_rate": 5.655555555555556e-06,
      "loss": 0.0018,
      "step": 79820
    },
    {
      "epoch": 1.774,
      "grad_norm": 0.07026906311511993,
      "learning_rate": 5.65e-06,
      "loss": 0.0023,
      "step": 79830
    },
    {
      "epoch": 1.7742222222222224,
      "grad_norm": 0.26091140508651733,
      "learning_rate": 5.6444444444444445e-06,
      "loss": 0.0023,
      "step": 79840
    },
    {
      "epoch": 1.7744444444444445,
      "grad_norm": 0.08741123974323273,
      "learning_rate": 5.63888888888889e-06,
      "loss": 0.0019,
      "step": 79850
    },
    {
      "epoch": 1.7746666666666666,
      "grad_norm": 0.21301639080047607,
      "learning_rate": 5.633333333333333e-06,
      "loss": 0.003,
      "step": 79860
    },
    {
      "epoch": 1.774888888888889,
      "grad_norm": 0.5467205047607422,
      "learning_rate": 5.6277777777777786e-06,
      "loss": 0.0017,
      "step": 79870
    },
    {
      "epoch": 1.775111111111111,
      "grad_norm": 0.27611541748046875,
      "learning_rate": 5.622222222222222e-06,
      "loss": 0.0021,
      "step": 79880
    },
    {
      "epoch": 1.7753333333333332,
      "grad_norm": 0.27344468235969543,
      "learning_rate": 5.6166666666666665e-06,
      "loss": 0.0018,
      "step": 79890
    },
    {
      "epoch": 1.7755555555555556,
      "grad_norm": 0.2907393276691437,
      "learning_rate": 5.611111111111112e-06,
      "loss": 0.0018,
      "step": 79900
    },
    {
      "epoch": 1.775777777777778,
      "grad_norm": 0.11050476133823395,
      "learning_rate": 5.605555555555555e-06,
      "loss": 0.0023,
      "step": 79910
    },
    {
      "epoch": 1.776,
      "grad_norm": 0.18035757541656494,
      "learning_rate": 5.600000000000001e-06,
      "loss": 0.0019,
      "step": 79920
    },
    {
      "epoch": 1.7762222222222221,
      "grad_norm": 0.5348548889160156,
      "learning_rate": 5.594444444444444e-06,
      "loss": 0.002,
      "step": 79930
    },
    {
      "epoch": 1.7764444444444445,
      "grad_norm": 0.259075790643692,
      "learning_rate": 5.588888888888889e-06,
      "loss": 0.002,
      "step": 79940
    },
    {
      "epoch": 1.7766666666666666,
      "grad_norm": 0.07152596861124039,
      "learning_rate": 5.583333333333334e-06,
      "loss": 0.0018,
      "step": 79950
    },
    {
      "epoch": 1.7768888888888887,
      "grad_norm": 0.26844486594200134,
      "learning_rate": 5.577777777777778e-06,
      "loss": 0.0019,
      "step": 79960
    },
    {
      "epoch": 1.777111111111111,
      "grad_norm": 0.11935807764530182,
      "learning_rate": 5.572222222222223e-06,
      "loss": 0.0024,
      "step": 79970
    },
    {
      "epoch": 1.7773333333333334,
      "grad_norm": 0.10691855847835541,
      "learning_rate": 5.566666666666667e-06,
      "loss": 0.0025,
      "step": 79980
    },
    {
      "epoch": 1.7775555555555556,
      "grad_norm": 0.27060362696647644,
      "learning_rate": 5.561111111111111e-06,
      "loss": 0.0018,
      "step": 79990
    },
    {
      "epoch": 1.7777777777777777,
      "grad_norm": 0.07910885661840439,
      "learning_rate": 5.555555555555556e-06,
      "loss": 0.0017,
      "step": 80000
    },
    {
      "epoch": 1.778,
      "grad_norm": 0.06974904984235764,
      "learning_rate": 5.55e-06,
      "loss": 0.0019,
      "step": 80010
    },
    {
      "epoch": 1.7782222222222224,
      "grad_norm": 0.35368552803993225,
      "learning_rate": 5.544444444444445e-06,
      "loss": 0.0026,
      "step": 80020
    },
    {
      "epoch": 1.7784444444444445,
      "grad_norm": 0.21680933237075806,
      "learning_rate": 5.538888888888889e-06,
      "loss": 0.0016,
      "step": 80030
    },
    {
      "epoch": 1.7786666666666666,
      "grad_norm": 0.04973762854933739,
      "learning_rate": 5.5333333333333334e-06,
      "loss": 0.0022,
      "step": 80040
    },
    {
      "epoch": 1.778888888888889,
      "grad_norm": 0.08535666018724442,
      "learning_rate": 5.527777777777778e-06,
      "loss": 0.0018,
      "step": 80050
    },
    {
      "epoch": 1.779111111111111,
      "grad_norm": 0.32508206367492676,
      "learning_rate": 5.522222222222222e-06,
      "loss": 0.0018,
      "step": 80060
    },
    {
      "epoch": 1.7793333333333332,
      "grad_norm": 0.11609124392271042,
      "learning_rate": 5.5166666666666675e-06,
      "loss": 0.0027,
      "step": 80070
    },
    {
      "epoch": 1.7795555555555556,
      "grad_norm": 0.3563290238380432,
      "learning_rate": 5.511111111111111e-06,
      "loss": 0.0017,
      "step": 80080
    },
    {
      "epoch": 1.779777777777778,
      "grad_norm": 0.17668211460113525,
      "learning_rate": 5.505555555555556e-06,
      "loss": 0.0018,
      "step": 80090
    },
    {
      "epoch": 1.78,
      "grad_norm": 0.2617279291152954,
      "learning_rate": 5.500000000000001e-06,
      "loss": 0.0026,
      "step": 80100
    },
    {
      "epoch": 1.7802222222222222,
      "grad_norm": 0.7601261138916016,
      "learning_rate": 5.494444444444444e-06,
      "loss": 0.0019,
      "step": 80110
    },
    {
      "epoch": 1.7804444444444445,
      "grad_norm": 0.27076515555381775,
      "learning_rate": 5.4888888888888895e-06,
      "loss": 0.0025,
      "step": 80120
    },
    {
      "epoch": 1.7806666666666666,
      "grad_norm": 0.3751241862773895,
      "learning_rate": 5.483333333333333e-06,
      "loss": 0.0019,
      "step": 80130
    },
    {
      "epoch": 1.7808888888888887,
      "grad_norm": 0.3145608603954315,
      "learning_rate": 5.477777777777778e-06,
      "loss": 0.0021,
      "step": 80140
    },
    {
      "epoch": 1.781111111111111,
      "grad_norm": 0.12623172998428345,
      "learning_rate": 5.472222222222223e-06,
      "loss": 0.0016,
      "step": 80150
    },
    {
      "epoch": 1.7813333333333334,
      "grad_norm": 0.11900974810123444,
      "learning_rate": 5.466666666666667e-06,
      "loss": 0.002,
      "step": 80160
    },
    {
      "epoch": 1.7815555555555556,
      "grad_norm": 0.08203459531068802,
      "learning_rate": 5.4611111111111115e-06,
      "loss": 0.0017,
      "step": 80170
    },
    {
      "epoch": 1.7817777777777777,
      "grad_norm": 0.18973539769649506,
      "learning_rate": 5.455555555555556e-06,
      "loss": 0.0017,
      "step": 80180
    },
    {
      "epoch": 1.782,
      "grad_norm": 0.18962983787059784,
      "learning_rate": 5.45e-06,
      "loss": 0.0019,
      "step": 80190
    },
    {
      "epoch": 1.7822222222222224,
      "grad_norm": 0.3266659080982208,
      "learning_rate": 5.444444444444445e-06,
      "loss": 0.0026,
      "step": 80200
    },
    {
      "epoch": 1.7824444444444445,
      "grad_norm": 0.18734832108020782,
      "learning_rate": 5.438888888888889e-06,
      "loss": 0.0017,
      "step": 80210
    },
    {
      "epoch": 1.7826666666666666,
      "grad_norm": 0.1507989764213562,
      "learning_rate": 5.4333333333333335e-06,
      "loss": 0.0019,
      "step": 80220
    },
    {
      "epoch": 1.782888888888889,
      "grad_norm": 0.23939689993858337,
      "learning_rate": 5.427777777777778e-06,
      "loss": 0.0021,
      "step": 80230
    },
    {
      "epoch": 1.783111111111111,
      "grad_norm": 0.12708508968353271,
      "learning_rate": 5.422222222222222e-06,
      "loss": 0.0026,
      "step": 80240
    },
    {
      "epoch": 1.7833333333333332,
      "grad_norm": 0.2450432926416397,
      "learning_rate": 5.416666666666667e-06,
      "loss": 0.0018,
      "step": 80250
    },
    {
      "epoch": 1.7835555555555556,
      "grad_norm": 0.080443374812603,
      "learning_rate": 5.411111111111111e-06,
      "loss": 0.0019,
      "step": 80260
    },
    {
      "epoch": 1.783777777777778,
      "grad_norm": 0.5550836324691772,
      "learning_rate": 5.405555555555556e-06,
      "loss": 0.0017,
      "step": 80270
    },
    {
      "epoch": 1.784,
      "grad_norm": 0.20818418264389038,
      "learning_rate": 5.4e-06,
      "loss": 0.0017,
      "step": 80280
    },
    {
      "epoch": 1.7842222222222222,
      "grad_norm": 0.2985079288482666,
      "learning_rate": 5.394444444444445e-06,
      "loss": 0.0026,
      "step": 80290
    },
    {
      "epoch": 1.7844444444444445,
      "grad_norm": 0.11552856117486954,
      "learning_rate": 5.388888888888889e-06,
      "loss": 0.0018,
      "step": 80300
    },
    {
      "epoch": 1.7846666666666666,
      "grad_norm": 0.3679759204387665,
      "learning_rate": 5.383333333333333e-06,
      "loss": 0.0031,
      "step": 80310
    },
    {
      "epoch": 1.7848888888888887,
      "grad_norm": 0.314403235912323,
      "learning_rate": 5.3777777777777784e-06,
      "loss": 0.0018,
      "step": 80320
    },
    {
      "epoch": 1.785111111111111,
      "grad_norm": 0.4759479761123657,
      "learning_rate": 5.372222222222222e-06,
      "loss": 0.0019,
      "step": 80330
    },
    {
      "epoch": 1.7853333333333334,
      "grad_norm": 0.1228996217250824,
      "learning_rate": 5.366666666666667e-06,
      "loss": 0.0019,
      "step": 80340
    },
    {
      "epoch": 1.7855555555555556,
      "grad_norm": 0.1682204306125641,
      "learning_rate": 5.361111111111111e-06,
      "loss": 0.0018,
      "step": 80350
    },
    {
      "epoch": 1.7857777777777777,
      "grad_norm": 0.23892006278038025,
      "learning_rate": 5.355555555555556e-06,
      "loss": 0.0018,
      "step": 80360
    },
    {
      "epoch": 1.786,
      "grad_norm": 0.3079899251461029,
      "learning_rate": 5.3500000000000004e-06,
      "loss": 0.002,
      "step": 80370
    },
    {
      "epoch": 1.7862222222222224,
      "grad_norm": 0.3562513589859009,
      "learning_rate": 5.344444444444445e-06,
      "loss": 0.0024,
      "step": 80380
    },
    {
      "epoch": 1.7864444444444443,
      "grad_norm": 0.21837735176086426,
      "learning_rate": 5.338888888888889e-06,
      "loss": 0.0021,
      "step": 80390
    },
    {
      "epoch": 1.7866666666666666,
      "grad_norm": 0.15121620893478394,
      "learning_rate": 5.333333333333334e-06,
      "loss": 0.0025,
      "step": 80400
    },
    {
      "epoch": 1.786888888888889,
      "grad_norm": 0.0941624790430069,
      "learning_rate": 5.327777777777778e-06,
      "loss": 0.0019,
      "step": 80410
    },
    {
      "epoch": 1.787111111111111,
      "grad_norm": 0.3413407504558563,
      "learning_rate": 5.3222222222222225e-06,
      "loss": 0.0017,
      "step": 80420
    },
    {
      "epoch": 1.7873333333333332,
      "grad_norm": 0.11680688709020615,
      "learning_rate": 5.316666666666667e-06,
      "loss": 0.0027,
      "step": 80430
    },
    {
      "epoch": 1.7875555555555556,
      "grad_norm": 0.06604564189910889,
      "learning_rate": 5.311111111111111e-06,
      "loss": 0.0015,
      "step": 80440
    },
    {
      "epoch": 1.787777777777778,
      "grad_norm": 0.10316397249698639,
      "learning_rate": 5.305555555555556e-06,
      "loss": 0.0026,
      "step": 80450
    },
    {
      "epoch": 1.788,
      "grad_norm": 0.09917950630187988,
      "learning_rate": 5.3e-06,
      "loss": 0.0025,
      "step": 80460
    },
    {
      "epoch": 1.7882222222222222,
      "grad_norm": 0.12816216051578522,
      "learning_rate": 5.294444444444445e-06,
      "loss": 0.0019,
      "step": 80470
    },
    {
      "epoch": 1.7884444444444445,
      "grad_norm": 0.0839187279343605,
      "learning_rate": 5.288888888888889e-06,
      "loss": 0.0021,
      "step": 80480
    },
    {
      "epoch": 1.7886666666666666,
      "grad_norm": 0.43932703137397766,
      "learning_rate": 5.283333333333334e-06,
      "loss": 0.0018,
      "step": 80490
    },
    {
      "epoch": 1.7888888888888888,
      "grad_norm": 0.33773088455200195,
      "learning_rate": 5.277777777777778e-06,
      "loss": 0.0024,
      "step": 80500
    },
    {
      "epoch": 1.789111111111111,
      "grad_norm": 0.16386666893959045,
      "learning_rate": 5.272222222222222e-06,
      "loss": 0.0019,
      "step": 80510
    },
    {
      "epoch": 1.7893333333333334,
      "grad_norm": 0.1257837563753128,
      "learning_rate": 5.266666666666667e-06,
      "loss": 0.0027,
      "step": 80520
    },
    {
      "epoch": 1.7895555555555556,
      "grad_norm": 0.1947118043899536,
      "learning_rate": 5.261111111111111e-06,
      "loss": 0.0016,
      "step": 80530
    },
    {
      "epoch": 1.7897777777777777,
      "grad_norm": 0.24157142639160156,
      "learning_rate": 5.255555555555556e-06,
      "loss": 0.0019,
      "step": 80540
    },
    {
      "epoch": 1.79,
      "grad_norm": 0.1137661561369896,
      "learning_rate": 5.25e-06,
      "loss": 0.0017,
      "step": 80550
    },
    {
      "epoch": 1.7902222222222224,
      "grad_norm": 0.4128759801387787,
      "learning_rate": 5.244444444444445e-06,
      "loss": 0.0016,
      "step": 80560
    },
    {
      "epoch": 1.7904444444444443,
      "grad_norm": 0.778203010559082,
      "learning_rate": 5.238888888888889e-06,
      "loss": 0.0027,
      "step": 80570
    },
    {
      "epoch": 1.7906666666666666,
      "grad_norm": 0.21576589345932007,
      "learning_rate": 5.233333333333334e-06,
      "loss": 0.002,
      "step": 80580
    },
    {
      "epoch": 1.790888888888889,
      "grad_norm": 0.5427871346473694,
      "learning_rate": 5.227777777777778e-06,
      "loss": 0.0019,
      "step": 80590
    },
    {
      "epoch": 1.791111111111111,
      "grad_norm": 0.23628218472003937,
      "learning_rate": 5.2222222222222226e-06,
      "loss": 0.002,
      "step": 80600
    },
    {
      "epoch": 1.7913333333333332,
      "grad_norm": 0.15523816645145416,
      "learning_rate": 5.216666666666667e-06,
      "loss": 0.002,
      "step": 80610
    },
    {
      "epoch": 1.7915555555555556,
      "grad_norm": 0.20326466858386993,
      "learning_rate": 5.211111111111111e-06,
      "loss": 0.0027,
      "step": 80620
    },
    {
      "epoch": 1.791777777777778,
      "grad_norm": 0.09803201258182526,
      "learning_rate": 5.205555555555556e-06,
      "loss": 0.0019,
      "step": 80630
    },
    {
      "epoch": 1.792,
      "grad_norm": 0.3504396378993988,
      "learning_rate": 5.2e-06,
      "loss": 0.0019,
      "step": 80640
    },
    {
      "epoch": 1.7922222222222222,
      "grad_norm": 0.10752572864294052,
      "learning_rate": 5.194444444444445e-06,
      "loss": 0.0017,
      "step": 80650
    },
    {
      "epoch": 1.7924444444444445,
      "grad_norm": 0.0611693374812603,
      "learning_rate": 5.188888888888889e-06,
      "loss": 0.0019,
      "step": 80660
    },
    {
      "epoch": 1.7926666666666666,
      "grad_norm": 0.27688735723495483,
      "learning_rate": 5.183333333333333e-06,
      "loss": 0.002,
      "step": 80670
    },
    {
      "epoch": 1.7928888888888888,
      "grad_norm": 0.43035534024238586,
      "learning_rate": 5.177777777777778e-06,
      "loss": 0.0017,
      "step": 80680
    },
    {
      "epoch": 1.793111111111111,
      "grad_norm": 0.07619675248861313,
      "learning_rate": 5.172222222222223e-06,
      "loss": 0.0022,
      "step": 80690
    },
    {
      "epoch": 1.7933333333333334,
      "grad_norm": 0.09265202283859253,
      "learning_rate": 5.166666666666667e-06,
      "loss": 0.0025,
      "step": 80700
    },
    {
      "epoch": 1.7935555555555556,
      "grad_norm": 0.06493108719587326,
      "learning_rate": 5.161111111111112e-06,
      "loss": 0.0018,
      "step": 80710
    },
    {
      "epoch": 1.7937777777777777,
      "grad_norm": 0.10071510821580887,
      "learning_rate": 5.155555555555555e-06,
      "loss": 0.0023,
      "step": 80720
    },
    {
      "epoch": 1.794,
      "grad_norm": 0.265164852142334,
      "learning_rate": 5.15e-06,
      "loss": 0.0025,
      "step": 80730
    },
    {
      "epoch": 1.7942222222222224,
      "grad_norm": 0.22488565742969513,
      "learning_rate": 5.144444444444445e-06,
      "loss": 0.0018,
      "step": 80740
    },
    {
      "epoch": 1.7944444444444443,
      "grad_norm": 0.13990333676338196,
      "learning_rate": 5.138888888888889e-06,
      "loss": 0.0017,
      "step": 80750
    },
    {
      "epoch": 1.7946666666666666,
      "grad_norm": 0.13509508967399597,
      "learning_rate": 5.133333333333334e-06,
      "loss": 0.0018,
      "step": 80760
    },
    {
      "epoch": 1.794888888888889,
      "grad_norm": 0.619290292263031,
      "learning_rate": 5.127777777777778e-06,
      "loss": 0.0022,
      "step": 80770
    },
    {
      "epoch": 1.795111111111111,
      "grad_norm": 0.25150227546691895,
      "learning_rate": 5.122222222222223e-06,
      "loss": 0.0023,
      "step": 80780
    },
    {
      "epoch": 1.7953333333333332,
      "grad_norm": 0.3687126040458679,
      "learning_rate": 5.116666666666667e-06,
      "loss": 0.002,
      "step": 80790
    },
    {
      "epoch": 1.7955555555555556,
      "grad_norm": 0.15674236416816711,
      "learning_rate": 5.1111111111111115e-06,
      "loss": 0.0017,
      "step": 80800
    },
    {
      "epoch": 1.795777777777778,
      "grad_norm": 0.2366582304239273,
      "learning_rate": 5.105555555555556e-06,
      "loss": 0.0017,
      "step": 80810
    },
    {
      "epoch": 1.796,
      "grad_norm": 0.059513967484235764,
      "learning_rate": 5.1e-06,
      "loss": 0.0016,
      "step": 80820
    },
    {
      "epoch": 1.7962222222222222,
      "grad_norm": 0.33014628291130066,
      "learning_rate": 5.094444444444445e-06,
      "loss": 0.0018,
      "step": 80830
    },
    {
      "epoch": 1.7964444444444445,
      "grad_norm": 0.4496214687824249,
      "learning_rate": 5.088888888888889e-06,
      "loss": 0.0022,
      "step": 80840
    },
    {
      "epoch": 1.7966666666666666,
      "grad_norm": 0.2634485065937042,
      "learning_rate": 5.0833333333333335e-06,
      "loss": 0.0019,
      "step": 80850
    },
    {
      "epoch": 1.7968888888888888,
      "grad_norm": 0.27538344264030457,
      "learning_rate": 5.077777777777778e-06,
      "loss": 0.0018,
      "step": 80860
    },
    {
      "epoch": 1.797111111111111,
      "grad_norm": 0.295282244682312,
      "learning_rate": 5.072222222222222e-06,
      "loss": 0.0021,
      "step": 80870
    },
    {
      "epoch": 1.7973333333333334,
      "grad_norm": 0.10174809396266937,
      "learning_rate": 5.066666666666667e-06,
      "loss": 0.0021,
      "step": 80880
    },
    {
      "epoch": 1.7975555555555556,
      "grad_norm": 0.24894915521144867,
      "learning_rate": 5.061111111111112e-06,
      "loss": 0.0017,
      "step": 80890
    },
    {
      "epoch": 1.7977777777777777,
      "grad_norm": 0.059986215084791183,
      "learning_rate": 5.0555555555555555e-06,
      "loss": 0.0027,
      "step": 80900
    },
    {
      "epoch": 1.798,
      "grad_norm": 0.16695475578308105,
      "learning_rate": 5.050000000000001e-06,
      "loss": 0.0017,
      "step": 80910
    },
    {
      "epoch": 1.7982222222222224,
      "grad_norm": 0.1789570301771164,
      "learning_rate": 5.044444444444444e-06,
      "loss": 0.0021,
      "step": 80920
    },
    {
      "epoch": 1.7984444444444443,
      "grad_norm": 0.24023482203483582,
      "learning_rate": 5.038888888888889e-06,
      "loss": 0.0028,
      "step": 80930
    },
    {
      "epoch": 1.7986666666666666,
      "grad_norm": 0.2531825006008148,
      "learning_rate": 5.033333333333334e-06,
      "loss": 0.0017,
      "step": 80940
    },
    {
      "epoch": 1.798888888888889,
      "grad_norm": 0.264909952878952,
      "learning_rate": 5.0277777777777775e-06,
      "loss": 0.0022,
      "step": 80950
    },
    {
      "epoch": 1.799111111111111,
      "grad_norm": 0.3288886845111847,
      "learning_rate": 5.022222222222223e-06,
      "loss": 0.0022,
      "step": 80960
    },
    {
      "epoch": 1.7993333333333332,
      "grad_norm": 0.33644378185272217,
      "learning_rate": 5.016666666666666e-06,
      "loss": 0.0016,
      "step": 80970
    },
    {
      "epoch": 1.7995555555555556,
      "grad_norm": 0.21452875435352325,
      "learning_rate": 5.011111111111112e-06,
      "loss": 0.0017,
      "step": 80980
    },
    {
      "epoch": 1.799777777777778,
      "grad_norm": 0.0915256142616272,
      "learning_rate": 5.005555555555556e-06,
      "loss": 0.0018,
      "step": 80990
    },
    {
      "epoch": 1.8,
      "grad_norm": 0.13991431891918182,
      "learning_rate": 5e-06,
      "loss": 0.0023,
      "step": 81000
    },
    {
      "epoch": 1.8002222222222222,
      "grad_norm": 0.3078632056713104,
      "learning_rate": 4.994444444444445e-06,
      "loss": 0.0017,
      "step": 81010
    },
    {
      "epoch": 1.8004444444444445,
      "grad_norm": 0.6657452583312988,
      "learning_rate": 4.988888888888889e-06,
      "loss": 0.002,
      "step": 81020
    },
    {
      "epoch": 1.8006666666666666,
      "grad_norm": 0.09125260263681412,
      "learning_rate": 4.983333333333334e-06,
      "loss": 0.002,
      "step": 81030
    },
    {
      "epoch": 1.8008888888888888,
      "grad_norm": 0.1248006820678711,
      "learning_rate": 4.977777777777778e-06,
      "loss": 0.0016,
      "step": 81040
    },
    {
      "epoch": 1.801111111111111,
      "grad_norm": 0.09989457577466965,
      "learning_rate": 4.9722222222222224e-06,
      "loss": 0.0021,
      "step": 81050
    },
    {
      "epoch": 1.8013333333333335,
      "grad_norm": 0.32207679748535156,
      "learning_rate": 4.966666666666667e-06,
      "loss": 0.0024,
      "step": 81060
    },
    {
      "epoch": 1.8015555555555556,
      "grad_norm": 0.6180999875068665,
      "learning_rate": 4.961111111111111e-06,
      "loss": 0.003,
      "step": 81070
    },
    {
      "epoch": 1.8017777777777777,
      "grad_norm": 0.14330953359603882,
      "learning_rate": 4.955555555555556e-06,
      "loss": 0.0017,
      "step": 81080
    },
    {
      "epoch": 1.802,
      "grad_norm": 0.3286123275756836,
      "learning_rate": 4.950000000000001e-06,
      "loss": 0.0018,
      "step": 81090
    },
    {
      "epoch": 1.8022222222222222,
      "grad_norm": 0.11556119471788406,
      "learning_rate": 4.9444444444444444e-06,
      "loss": 0.0018,
      "step": 81100
    },
    {
      "epoch": 1.8024444444444443,
      "grad_norm": 0.16163736581802368,
      "learning_rate": 4.93888888888889e-06,
      "loss": 0.0029,
      "step": 81110
    },
    {
      "epoch": 1.8026666666666666,
      "grad_norm": 0.0808122381567955,
      "learning_rate": 4.933333333333333e-06,
      "loss": 0.0017,
      "step": 81120
    },
    {
      "epoch": 1.802888888888889,
      "grad_norm": 0.16279764473438263,
      "learning_rate": 4.927777777777778e-06,
      "loss": 0.0026,
      "step": 81130
    },
    {
      "epoch": 1.803111111111111,
      "grad_norm": 0.07850637286901474,
      "learning_rate": 4.922222222222223e-06,
      "loss": 0.0026,
      "step": 81140
    },
    {
      "epoch": 1.8033333333333332,
      "grad_norm": 0.08092344552278519,
      "learning_rate": 4.9166666666666665e-06,
      "loss": 0.0018,
      "step": 81150
    },
    {
      "epoch": 1.8035555555555556,
      "grad_norm": 0.574786901473999,
      "learning_rate": 4.911111111111112e-06,
      "loss": 0.0019,
      "step": 81160
    },
    {
      "epoch": 1.803777777777778,
      "grad_norm": 0.2951849102973938,
      "learning_rate": 4.905555555555555e-06,
      "loss": 0.0023,
      "step": 81170
    },
    {
      "epoch": 1.804,
      "grad_norm": 0.3158614933490753,
      "learning_rate": 4.9000000000000005e-06,
      "loss": 0.0019,
      "step": 81180
    },
    {
      "epoch": 1.8042222222222222,
      "grad_norm": 0.13260874152183533,
      "learning_rate": 4.894444444444445e-06,
      "loss": 0.0017,
      "step": 81190
    },
    {
      "epoch": 1.8044444444444445,
      "grad_norm": 0.06866048276424408,
      "learning_rate": 4.888888888888889e-06,
      "loss": 0.0022,
      "step": 81200
    },
    {
      "epoch": 1.8046666666666666,
      "grad_norm": 0.11143141984939575,
      "learning_rate": 4.883333333333334e-06,
      "loss": 0.0018,
      "step": 81210
    },
    {
      "epoch": 1.8048888888888888,
      "grad_norm": 0.28262513875961304,
      "learning_rate": 4.877777777777778e-06,
      "loss": 0.0024,
      "step": 81220
    },
    {
      "epoch": 1.805111111111111,
      "grad_norm": 0.6042439937591553,
      "learning_rate": 4.8722222222222225e-06,
      "loss": 0.0029,
      "step": 81230
    },
    {
      "epoch": 1.8053333333333335,
      "grad_norm": 0.5517237186431885,
      "learning_rate": 4.866666666666667e-06,
      "loss": 0.0018,
      "step": 81240
    },
    {
      "epoch": 1.8055555555555556,
      "grad_norm": 0.25170010328292847,
      "learning_rate": 4.861111111111111e-06,
      "loss": 0.0017,
      "step": 81250
    },
    {
      "epoch": 1.8057777777777777,
      "grad_norm": 0.17438873648643494,
      "learning_rate": 4.855555555555556e-06,
      "loss": 0.0019,
      "step": 81260
    },
    {
      "epoch": 1.806,
      "grad_norm": 0.1809139847755432,
      "learning_rate": 4.85e-06,
      "loss": 0.0016,
      "step": 81270
    },
    {
      "epoch": 1.8062222222222222,
      "grad_norm": 0.5387402772903442,
      "learning_rate": 4.8444444444444446e-06,
      "loss": 0.0026,
      "step": 81280
    },
    {
      "epoch": 1.8064444444444443,
      "grad_norm": 0.43851861357688904,
      "learning_rate": 4.838888888888889e-06,
      "loss": 0.0019,
      "step": 81290
    },
    {
      "epoch": 1.8066666666666666,
      "grad_norm": 0.29406076669692993,
      "learning_rate": 4.833333333333333e-06,
      "loss": 0.002,
      "step": 81300
    },
    {
      "epoch": 1.806888888888889,
      "grad_norm": 0.1771908402442932,
      "learning_rate": 4.827777777777779e-06,
      "loss": 0.0018,
      "step": 81310
    },
    {
      "epoch": 1.8071111111111111,
      "grad_norm": 0.400982528924942,
      "learning_rate": 4.822222222222222e-06,
      "loss": 0.0032,
      "step": 81320
    },
    {
      "epoch": 1.8073333333333332,
      "grad_norm": 0.2756900191307068,
      "learning_rate": 4.816666666666667e-06,
      "loss": 0.0021,
      "step": 81330
    },
    {
      "epoch": 1.8075555555555556,
      "grad_norm": 0.07878530025482178,
      "learning_rate": 4.811111111111111e-06,
      "loss": 0.0019,
      "step": 81340
    },
    {
      "epoch": 1.807777777777778,
      "grad_norm": 0.3953500986099243,
      "learning_rate": 4.805555555555555e-06,
      "loss": 0.0018,
      "step": 81350
    },
    {
      "epoch": 1.808,
      "grad_norm": 0.17684145271778107,
      "learning_rate": 4.800000000000001e-06,
      "loss": 0.0031,
      "step": 81360
    },
    {
      "epoch": 1.8082222222222222,
      "grad_norm": 0.19836239516735077,
      "learning_rate": 4.794444444444444e-06,
      "loss": 0.0019,
      "step": 81370
    },
    {
      "epoch": 1.8084444444444445,
      "grad_norm": 0.12222166359424591,
      "learning_rate": 4.7888888888888894e-06,
      "loss": 0.0022,
      "step": 81380
    },
    {
      "epoch": 1.8086666666666666,
      "grad_norm": 0.07519469410181046,
      "learning_rate": 4.783333333333333e-06,
      "loss": 0.0037,
      "step": 81390
    },
    {
      "epoch": 1.8088888888888888,
      "grad_norm": 0.22777274250984192,
      "learning_rate": 4.777777777777778e-06,
      "loss": 0.0016,
      "step": 81400
    },
    {
      "epoch": 1.8091111111111111,
      "grad_norm": 0.1769029051065445,
      "learning_rate": 4.772222222222223e-06,
      "loss": 0.0016,
      "step": 81410
    },
    {
      "epoch": 1.8093333333333335,
      "grad_norm": 0.43727099895477295,
      "learning_rate": 4.766666666666667e-06,
      "loss": 0.0021,
      "step": 81420
    },
    {
      "epoch": 1.8095555555555556,
      "grad_norm": 0.22759757936000824,
      "learning_rate": 4.7611111111111115e-06,
      "loss": 0.002,
      "step": 81430
    },
    {
      "epoch": 1.8097777777777777,
      "grad_norm": 0.38476431369781494,
      "learning_rate": 4.755555555555556e-06,
      "loss": 0.0021,
      "step": 81440
    },
    {
      "epoch": 1.81,
      "grad_norm": 0.5791194438934326,
      "learning_rate": 4.75e-06,
      "loss": 0.0021,
      "step": 81450
    },
    {
      "epoch": 1.8102222222222222,
      "grad_norm": 0.06211612746119499,
      "learning_rate": 4.744444444444445e-06,
      "loss": 0.0018,
      "step": 81460
    },
    {
      "epoch": 1.8104444444444443,
      "grad_norm": 0.3611491322517395,
      "learning_rate": 4.738888888888889e-06,
      "loss": 0.0016,
      "step": 81470
    },
    {
      "epoch": 1.8106666666666666,
      "grad_norm": 0.3133668601512909,
      "learning_rate": 4.7333333333333335e-06,
      "loss": 0.0017,
      "step": 81480
    },
    {
      "epoch": 1.810888888888889,
      "grad_norm": 0.11681981384754181,
      "learning_rate": 4.727777777777778e-06,
      "loss": 0.0022,
      "step": 81490
    },
    {
      "epoch": 1.8111111111111111,
      "grad_norm": 0.14161014556884766,
      "learning_rate": 4.722222222222222e-06,
      "loss": 0.0023,
      "step": 81500
    },
    {
      "epoch": 1.8113333333333332,
      "grad_norm": 0.08503767102956772,
      "learning_rate": 4.7166666666666675e-06,
      "loss": 0.0019,
      "step": 81510
    },
    {
      "epoch": 1.8115555555555556,
      "grad_norm": 0.10747997462749481,
      "learning_rate": 4.711111111111111e-06,
      "loss": 0.0016,
      "step": 81520
    },
    {
      "epoch": 1.811777777777778,
      "grad_norm": 0.24589018523693085,
      "learning_rate": 4.705555555555556e-06,
      "loss": 0.0028,
      "step": 81530
    },
    {
      "epoch": 1.812,
      "grad_norm": 0.19065484404563904,
      "learning_rate": 4.7e-06,
      "loss": 0.0015,
      "step": 81540
    },
    {
      "epoch": 1.8122222222222222,
      "grad_norm": 0.521821141242981,
      "learning_rate": 4.694444444444444e-06,
      "loss": 0.002,
      "step": 81550
    },
    {
      "epoch": 1.8124444444444445,
      "grad_norm": 0.31632813811302185,
      "learning_rate": 4.6888888888888895e-06,
      "loss": 0.0016,
      "step": 81560
    },
    {
      "epoch": 1.8126666666666666,
      "grad_norm": 0.06730925291776657,
      "learning_rate": 4.683333333333333e-06,
      "loss": 0.0028,
      "step": 81570
    },
    {
      "epoch": 1.8128888888888888,
      "grad_norm": 0.11066752672195435,
      "learning_rate": 4.677777777777778e-06,
      "loss": 0.0016,
      "step": 81580
    },
    {
      "epoch": 1.8131111111111111,
      "grad_norm": 0.09894917160272598,
      "learning_rate": 4.672222222222222e-06,
      "loss": 0.0023,
      "step": 81590
    },
    {
      "epoch": 1.8133333333333335,
      "grad_norm": 0.10786553472280502,
      "learning_rate": 4.666666666666667e-06,
      "loss": 0.002,
      "step": 81600
    },
    {
      "epoch": 1.8135555555555556,
      "grad_norm": 0.36853811144828796,
      "learning_rate": 4.6611111111111116e-06,
      "loss": 0.0021,
      "step": 81610
    },
    {
      "epoch": 1.8137777777777777,
      "grad_norm": 0.36847585439682007,
      "learning_rate": 4.655555555555556e-06,
      "loss": 0.0018,
      "step": 81620
    },
    {
      "epoch": 1.814,
      "grad_norm": 0.33352920413017273,
      "learning_rate": 4.65e-06,
      "loss": 0.0024,
      "step": 81630
    },
    {
      "epoch": 1.8142222222222222,
      "grad_norm": 0.10976751893758774,
      "learning_rate": 4.644444444444444e-06,
      "loss": 0.0016,
      "step": 81640
    },
    {
      "epoch": 1.8144444444444443,
      "grad_norm": 0.28612402081489563,
      "learning_rate": 4.638888888888889e-06,
      "loss": 0.0022,
      "step": 81650
    },
    {
      "epoch": 1.8146666666666667,
      "grad_norm": 0.09108670055866241,
      "learning_rate": 4.633333333333334e-06,
      "loss": 0.0019,
      "step": 81660
    },
    {
      "epoch": 1.814888888888889,
      "grad_norm": 0.6059545278549194,
      "learning_rate": 4.627777777777778e-06,
      "loss": 0.0031,
      "step": 81670
    },
    {
      "epoch": 1.8151111111111111,
      "grad_norm": 0.18615350127220154,
      "learning_rate": 4.622222222222222e-06,
      "loss": 0.002,
      "step": 81680
    },
    {
      "epoch": 1.8153333333333332,
      "grad_norm": 0.07590563595294952,
      "learning_rate": 4.616666666666667e-06,
      "loss": 0.0027,
      "step": 81690
    },
    {
      "epoch": 1.8155555555555556,
      "grad_norm": 0.2239801436662674,
      "learning_rate": 4.611111111111111e-06,
      "loss": 0.0025,
      "step": 81700
    },
    {
      "epoch": 1.815777777777778,
      "grad_norm": 0.5339511036872864,
      "learning_rate": 4.605555555555556e-06,
      "loss": 0.0025,
      "step": 81710
    },
    {
      "epoch": 1.8159999999999998,
      "grad_norm": 0.2620982825756073,
      "learning_rate": 4.6e-06,
      "loss": 0.0017,
      "step": 81720
    },
    {
      "epoch": 1.8162222222222222,
      "grad_norm": 0.08337530493736267,
      "learning_rate": 4.594444444444445e-06,
      "loss": 0.0025,
      "step": 81730
    },
    {
      "epoch": 1.8164444444444445,
      "grad_norm": 0.16337531805038452,
      "learning_rate": 4.588888888888889e-06,
      "loss": 0.0025,
      "step": 81740
    },
    {
      "epoch": 1.8166666666666667,
      "grad_norm": 0.13617058098316193,
      "learning_rate": 4.583333333333333e-06,
      "loss": 0.0022,
      "step": 81750
    },
    {
      "epoch": 1.8168888888888888,
      "grad_norm": 0.07412315905094147,
      "learning_rate": 4.5777777777777785e-06,
      "loss": 0.0019,
      "step": 81760
    },
    {
      "epoch": 1.8171111111111111,
      "grad_norm": 0.0599372535943985,
      "learning_rate": 4.572222222222222e-06,
      "loss": 0.0019,
      "step": 81770
    },
    {
      "epoch": 1.8173333333333335,
      "grad_norm": 0.1263469010591507,
      "learning_rate": 4.566666666666667e-06,
      "loss": 0.0022,
      "step": 81780
    },
    {
      "epoch": 1.8175555555555556,
      "grad_norm": 0.211101695895195,
      "learning_rate": 4.561111111111111e-06,
      "loss": 0.0019,
      "step": 81790
    },
    {
      "epoch": 1.8177777777777777,
      "grad_norm": 0.16871146857738495,
      "learning_rate": 4.555555555555556e-06,
      "loss": 0.0028,
      "step": 81800
    },
    {
      "epoch": 1.818,
      "grad_norm": 0.4494210183620453,
      "learning_rate": 4.5500000000000005e-06,
      "loss": 0.0021,
      "step": 81810
    },
    {
      "epoch": 1.8182222222222222,
      "grad_norm": 0.27996188402175903,
      "learning_rate": 4.544444444444445e-06,
      "loss": 0.0022,
      "step": 81820
    },
    {
      "epoch": 1.8184444444444443,
      "grad_norm": 0.08883194625377655,
      "learning_rate": 4.538888888888889e-06,
      "loss": 0.0018,
      "step": 81830
    },
    {
      "epoch": 1.8186666666666667,
      "grad_norm": 0.468029648065567,
      "learning_rate": 4.533333333333334e-06,
      "loss": 0.0026,
      "step": 81840
    },
    {
      "epoch": 1.818888888888889,
      "grad_norm": 0.14103439450263977,
      "learning_rate": 4.527777777777778e-06,
      "loss": 0.0019,
      "step": 81850
    },
    {
      "epoch": 1.8191111111111111,
      "grad_norm": 0.5228209495544434,
      "learning_rate": 4.5222222222222225e-06,
      "loss": 0.0017,
      "step": 81860
    },
    {
      "epoch": 1.8193333333333332,
      "grad_norm": 0.13609115779399872,
      "learning_rate": 4.516666666666667e-06,
      "loss": 0.0021,
      "step": 81870
    },
    {
      "epoch": 1.8195555555555556,
      "grad_norm": 0.2578139305114746,
      "learning_rate": 4.511111111111111e-06,
      "loss": 0.0016,
      "step": 81880
    },
    {
      "epoch": 1.819777777777778,
      "grad_norm": 0.21940723061561584,
      "learning_rate": 4.505555555555556e-06,
      "loss": 0.0028,
      "step": 81890
    },
    {
      "epoch": 1.8199999999999998,
      "grad_norm": 0.11519530415534973,
      "learning_rate": 4.5e-06,
      "loss": 0.0022,
      "step": 81900
    },
    {
      "epoch": 1.8202222222222222,
      "grad_norm": 0.16620363295078278,
      "learning_rate": 4.4944444444444445e-06,
      "loss": 0.002,
      "step": 81910
    },
    {
      "epoch": 1.8204444444444445,
      "grad_norm": 0.2717055678367615,
      "learning_rate": 4.488888888888889e-06,
      "loss": 0.0028,
      "step": 81920
    },
    {
      "epoch": 1.8206666666666667,
      "grad_norm": 0.11601364612579346,
      "learning_rate": 4.483333333333334e-06,
      "loss": 0.0018,
      "step": 81930
    },
    {
      "epoch": 1.8208888888888888,
      "grad_norm": 0.15229164063930511,
      "learning_rate": 4.477777777777778e-06,
      "loss": 0.0018,
      "step": 81940
    },
    {
      "epoch": 1.8211111111111111,
      "grad_norm": 0.27390965819358826,
      "learning_rate": 4.472222222222222e-06,
      "loss": 0.002,
      "step": 81950
    },
    {
      "epoch": 1.8213333333333335,
      "grad_norm": 0.25957775115966797,
      "learning_rate": 4.4666666666666665e-06,
      "loss": 0.0035,
      "step": 81960
    },
    {
      "epoch": 1.8215555555555556,
      "grad_norm": 0.09163164347410202,
      "learning_rate": 4.461111111111111e-06,
      "loss": 0.0017,
      "step": 81970
    },
    {
      "epoch": 1.8217777777777777,
      "grad_norm": 0.20141808688640594,
      "learning_rate": 4.455555555555556e-06,
      "loss": 0.0025,
      "step": 81980
    },
    {
      "epoch": 1.822,
      "grad_norm": 0.08259780704975128,
      "learning_rate": 4.45e-06,
      "loss": 0.0022,
      "step": 81990
    },
    {
      "epoch": 1.8222222222222222,
      "grad_norm": 0.22987161576747894,
      "learning_rate": 4.444444444444445e-06,
      "loss": 0.0019,
      "step": 82000
    },
    {
      "epoch": 1.8224444444444443,
      "grad_norm": 0.11678636074066162,
      "learning_rate": 4.4388888888888886e-06,
      "loss": 0.0026,
      "step": 82010
    },
    {
      "epoch": 1.8226666666666667,
      "grad_norm": 0.06986617296934128,
      "learning_rate": 4.433333333333334e-06,
      "loss": 0.0022,
      "step": 82020
    },
    {
      "epoch": 1.822888888888889,
      "grad_norm": 0.12410388886928558,
      "learning_rate": 4.427777777777778e-06,
      "loss": 0.0024,
      "step": 82030
    },
    {
      "epoch": 1.8231111111111111,
      "grad_norm": 0.27326881885528564,
      "learning_rate": 4.422222222222223e-06,
      "loss": 0.0018,
      "step": 82040
    },
    {
      "epoch": 1.8233333333333333,
      "grad_norm": 0.41019517183303833,
      "learning_rate": 4.416666666666667e-06,
      "loss": 0.0018,
      "step": 82050
    },
    {
      "epoch": 1.8235555555555556,
      "grad_norm": 0.20707716047763824,
      "learning_rate": 4.411111111111111e-06,
      "loss": 0.002,
      "step": 82060
    },
    {
      "epoch": 1.823777777777778,
      "grad_norm": 0.23218290507793427,
      "learning_rate": 4.405555555555556e-06,
      "loss": 0.0026,
      "step": 82070
    },
    {
      "epoch": 1.8239999999999998,
      "grad_norm": 0.123662568628788,
      "learning_rate": 4.4e-06,
      "loss": 0.0019,
      "step": 82080
    },
    {
      "epoch": 1.8242222222222222,
      "grad_norm": 0.24791643023490906,
      "learning_rate": 4.394444444444445e-06,
      "loss": 0.0018,
      "step": 82090
    },
    {
      "epoch": 1.8244444444444445,
      "grad_norm": 0.07896586507558823,
      "learning_rate": 4.388888888888889e-06,
      "loss": 0.0015,
      "step": 82100
    },
    {
      "epoch": 1.8246666666666667,
      "grad_norm": 0.07114472985267639,
      "learning_rate": 4.3833333333333334e-06,
      "loss": 0.0015,
      "step": 82110
    },
    {
      "epoch": 1.8248888888888888,
      "grad_norm": 0.2565140724182129,
      "learning_rate": 4.377777777777778e-06,
      "loss": 0.0017,
      "step": 82120
    },
    {
      "epoch": 1.8251111111111111,
      "grad_norm": 0.34589335322380066,
      "learning_rate": 4.372222222222223e-06,
      "loss": 0.0019,
      "step": 82130
    },
    {
      "epoch": 1.8253333333333335,
      "grad_norm": 0.2598286271095276,
      "learning_rate": 4.366666666666667e-06,
      "loss": 0.0023,
      "step": 82140
    },
    {
      "epoch": 1.8255555555555556,
      "grad_norm": 0.22739166021347046,
      "learning_rate": 4.361111111111112e-06,
      "loss": 0.0015,
      "step": 82150
    },
    {
      "epoch": 1.8257777777777777,
      "grad_norm": 0.08840024471282959,
      "learning_rate": 4.3555555555555555e-06,
      "loss": 0.0018,
      "step": 82160
    },
    {
      "epoch": 1.826,
      "grad_norm": 0.08250505477190018,
      "learning_rate": 4.35e-06,
      "loss": 0.0019,
      "step": 82170
    },
    {
      "epoch": 1.8262222222222222,
      "grad_norm": 0.12231098860502243,
      "learning_rate": 4.344444444444445e-06,
      "loss": 0.0026,
      "step": 82180
    },
    {
      "epoch": 1.8264444444444443,
      "grad_norm": 0.2226840704679489,
      "learning_rate": 4.338888888888889e-06,
      "loss": 0.0019,
      "step": 82190
    },
    {
      "epoch": 1.8266666666666667,
      "grad_norm": 0.2704629898071289,
      "learning_rate": 4.333333333333334e-06,
      "loss": 0.0018,
      "step": 82200
    },
    {
      "epoch": 1.826888888888889,
      "grad_norm": 0.20908348262310028,
      "learning_rate": 4.3277777777777775e-06,
      "loss": 0.002,
      "step": 82210
    },
    {
      "epoch": 1.8271111111111111,
      "grad_norm": 0.17802365124225616,
      "learning_rate": 4.322222222222223e-06,
      "loss": 0.0018,
      "step": 82220
    },
    {
      "epoch": 1.8273333333333333,
      "grad_norm": 0.14165008068084717,
      "learning_rate": 4.316666666666667e-06,
      "loss": 0.0027,
      "step": 82230
    },
    {
      "epoch": 1.8275555555555556,
      "grad_norm": 0.3619232177734375,
      "learning_rate": 4.3111111111111115e-06,
      "loss": 0.0021,
      "step": 82240
    },
    {
      "epoch": 1.8277777777777777,
      "grad_norm": 0.3982294797897339,
      "learning_rate": 4.305555555555556e-06,
      "loss": 0.0025,
      "step": 82250
    },
    {
      "epoch": 1.8279999999999998,
      "grad_norm": 0.17840221524238586,
      "learning_rate": 4.2999999999999995e-06,
      "loss": 0.0023,
      "step": 82260
    },
    {
      "epoch": 1.8282222222222222,
      "grad_norm": 0.5972312688827515,
      "learning_rate": 4.294444444444445e-06,
      "loss": 0.0024,
      "step": 82270
    },
    {
      "epoch": 1.8284444444444445,
      "grad_norm": 0.13588204979896545,
      "learning_rate": 4.288888888888889e-06,
      "loss": 0.0028,
      "step": 82280
    },
    {
      "epoch": 1.8286666666666667,
      "grad_norm": 0.17671693861484528,
      "learning_rate": 4.2833333333333335e-06,
      "loss": 0.0018,
      "step": 82290
    },
    {
      "epoch": 1.8288888888888888,
      "grad_norm": 0.4766591191291809,
      "learning_rate": 4.277777777777778e-06,
      "loss": 0.0015,
      "step": 82300
    },
    {
      "epoch": 1.8291111111111111,
      "grad_norm": 0.10524354875087738,
      "learning_rate": 4.272222222222222e-06,
      "loss": 0.0016,
      "step": 82310
    },
    {
      "epoch": 1.8293333333333335,
      "grad_norm": 0.05649036169052124,
      "learning_rate": 4.266666666666667e-06,
      "loss": 0.0017,
      "step": 82320
    },
    {
      "epoch": 1.8295555555555556,
      "grad_norm": 0.20058785378932953,
      "learning_rate": 4.261111111111111e-06,
      "loss": 0.0029,
      "step": 82330
    },
    {
      "epoch": 1.8297777777777777,
      "grad_norm": 0.15148936212062836,
      "learning_rate": 4.2555555555555556e-06,
      "loss": 0.002,
      "step": 82340
    },
    {
      "epoch": 1.83,
      "grad_norm": 0.2354203164577484,
      "learning_rate": 4.250000000000001e-06,
      "loss": 0.0034,
      "step": 82350
    },
    {
      "epoch": 1.8302222222222222,
      "grad_norm": 0.3878512978553772,
      "learning_rate": 4.244444444444444e-06,
      "loss": 0.0018,
      "step": 82360
    },
    {
      "epoch": 1.8304444444444443,
      "grad_norm": 0.7087003588676453,
      "learning_rate": 4.238888888888889e-06,
      "loss": 0.0033,
      "step": 82370
    },
    {
      "epoch": 1.8306666666666667,
      "grad_norm": 0.10201834887266159,
      "learning_rate": 4.233333333333333e-06,
      "loss": 0.0019,
      "step": 82380
    },
    {
      "epoch": 1.830888888888889,
      "grad_norm": 0.35573652386665344,
      "learning_rate": 4.227777777777778e-06,
      "loss": 0.0025,
      "step": 82390
    },
    {
      "epoch": 1.8311111111111111,
      "grad_norm": 0.49757617712020874,
      "learning_rate": 4.222222222222223e-06,
      "loss": 0.0017,
      "step": 82400
    },
    {
      "epoch": 1.8313333333333333,
      "grad_norm": 0.12423046678304672,
      "learning_rate": 4.216666666666666e-06,
      "loss": 0.0018,
      "step": 82410
    },
    {
      "epoch": 1.8315555555555556,
      "grad_norm": 0.537908136844635,
      "learning_rate": 4.211111111111112e-06,
      "loss": 0.0016,
      "step": 82420
    },
    {
      "epoch": 1.8317777777777777,
      "grad_norm": 0.5647748708724976,
      "learning_rate": 4.205555555555556e-06,
      "loss": 0.0018,
      "step": 82430
    },
    {
      "epoch": 1.8319999999999999,
      "grad_norm": 0.22629201412200928,
      "learning_rate": 4.2000000000000004e-06,
      "loss": 0.0018,
      "step": 82440
    },
    {
      "epoch": 1.8322222222222222,
      "grad_norm": 0.1758800595998764,
      "learning_rate": 4.194444444444445e-06,
      "loss": 0.0021,
      "step": 82450
    },
    {
      "epoch": 1.8324444444444445,
      "grad_norm": 0.4054698348045349,
      "learning_rate": 4.188888888888889e-06,
      "loss": 0.0027,
      "step": 82460
    },
    {
      "epoch": 1.8326666666666667,
      "grad_norm": 0.10283589363098145,
      "learning_rate": 4.183333333333334e-06,
      "loss": 0.0016,
      "step": 82470
    },
    {
      "epoch": 1.8328888888888888,
      "grad_norm": 0.30967482924461365,
      "learning_rate": 4.177777777777778e-06,
      "loss": 0.0033,
      "step": 82480
    },
    {
      "epoch": 1.8331111111111111,
      "grad_norm": 0.38792884349823,
      "learning_rate": 4.1722222222222225e-06,
      "loss": 0.0026,
      "step": 82490
    },
    {
      "epoch": 1.8333333333333335,
      "grad_norm": 0.34139037132263184,
      "learning_rate": 4.166666666666667e-06,
      "loss": 0.0018,
      "step": 82500
    },
    {
      "epoch": 1.8335555555555556,
      "grad_norm": 0.20325399935245514,
      "learning_rate": 4.161111111111111e-06,
      "loss": 0.0016,
      "step": 82510
    },
    {
      "epoch": 1.8337777777777777,
      "grad_norm": 0.10597292333841324,
      "learning_rate": 4.155555555555556e-06,
      "loss": 0.002,
      "step": 82520
    },
    {
      "epoch": 1.834,
      "grad_norm": 0.24329659342765808,
      "learning_rate": 4.15e-06,
      "loss": 0.0018,
      "step": 82530
    },
    {
      "epoch": 1.8342222222222222,
      "grad_norm": 0.24581913650035858,
      "learning_rate": 4.1444444444444445e-06,
      "loss": 0.0017,
      "step": 82540
    },
    {
      "epoch": 1.8344444444444443,
      "grad_norm": 0.22265397012233734,
      "learning_rate": 4.13888888888889e-06,
      "loss": 0.0017,
      "step": 82550
    },
    {
      "epoch": 1.8346666666666667,
      "grad_norm": 0.09113751351833344,
      "learning_rate": 4.133333333333333e-06,
      "loss": 0.0023,
      "step": 82560
    },
    {
      "epoch": 1.834888888888889,
      "grad_norm": 0.15185554325580597,
      "learning_rate": 4.127777777777778e-06,
      "loss": 0.0018,
      "step": 82570
    },
    {
      "epoch": 1.8351111111111111,
      "grad_norm": 0.16595664620399475,
      "learning_rate": 4.122222222222222e-06,
      "loss": 0.0018,
      "step": 82580
    },
    {
      "epoch": 1.8353333333333333,
      "grad_norm": 0.5961131453514099,
      "learning_rate": 4.1166666666666665e-06,
      "loss": 0.0016,
      "step": 82590
    },
    {
      "epoch": 1.8355555555555556,
      "grad_norm": 0.2641620337963104,
      "learning_rate": 4.111111111111112e-06,
      "loss": 0.0025,
      "step": 82600
    },
    {
      "epoch": 1.8357777777777777,
      "grad_norm": 0.41041287779808044,
      "learning_rate": 4.105555555555555e-06,
      "loss": 0.0024,
      "step": 82610
    },
    {
      "epoch": 1.8359999999999999,
      "grad_norm": 0.061262600123882294,
      "learning_rate": 4.1000000000000006e-06,
      "loss": 0.002,
      "step": 82620
    },
    {
      "epoch": 1.8362222222222222,
      "grad_norm": 0.5371155738830566,
      "learning_rate": 4.094444444444444e-06,
      "loss": 0.0017,
      "step": 82630
    },
    {
      "epoch": 1.8364444444444445,
      "grad_norm": 0.2655893564224243,
      "learning_rate": 4.088888888888889e-06,
      "loss": 0.0018,
      "step": 82640
    },
    {
      "epoch": 1.8366666666666667,
      "grad_norm": 0.23845817148685455,
      "learning_rate": 4.083333333333334e-06,
      "loss": 0.0016,
      "step": 82650
    },
    {
      "epoch": 1.8368888888888888,
      "grad_norm": 0.12225577980279922,
      "learning_rate": 4.077777777777778e-06,
      "loss": 0.0019,
      "step": 82660
    },
    {
      "epoch": 1.8371111111111111,
      "grad_norm": 0.22241316735744476,
      "learning_rate": 4.0722222222222226e-06,
      "loss": 0.0018,
      "step": 82670
    },
    {
      "epoch": 1.8373333333333335,
      "grad_norm": 0.20676842331886292,
      "learning_rate": 4.066666666666666e-06,
      "loss": 0.0019,
      "step": 82680
    },
    {
      "epoch": 1.8375555555555556,
      "grad_norm": 0.13432665169239044,
      "learning_rate": 4.061111111111111e-06,
      "loss": 0.0019,
      "step": 82690
    },
    {
      "epoch": 1.8377777777777777,
      "grad_norm": 0.31466230750083923,
      "learning_rate": 4.055555555555556e-06,
      "loss": 0.0019,
      "step": 82700
    },
    {
      "epoch": 1.838,
      "grad_norm": 0.3953983187675476,
      "learning_rate": 4.05e-06,
      "loss": 0.0025,
      "step": 82710
    },
    {
      "epoch": 1.8382222222222222,
      "grad_norm": 0.12013287097215652,
      "learning_rate": 4.044444444444445e-06,
      "loss": 0.0018,
      "step": 82720
    },
    {
      "epoch": 1.8384444444444443,
      "grad_norm": 0.05969937518239021,
      "learning_rate": 4.038888888888889e-06,
      "loss": 0.0021,
      "step": 82730
    },
    {
      "epoch": 1.8386666666666667,
      "grad_norm": 0.31402331590652466,
      "learning_rate": 4.033333333333333e-06,
      "loss": 0.0027,
      "step": 82740
    },
    {
      "epoch": 1.838888888888889,
      "grad_norm": 0.11000080406665802,
      "learning_rate": 4.027777777777779e-06,
      "loss": 0.0015,
      "step": 82750
    },
    {
      "epoch": 1.8391111111111111,
      "grad_norm": 0.16021379828453064,
      "learning_rate": 4.022222222222222e-06,
      "loss": 0.0018,
      "step": 82760
    },
    {
      "epoch": 1.8393333333333333,
      "grad_norm": 0.09634382277727127,
      "learning_rate": 4.0166666666666675e-06,
      "loss": 0.0017,
      "step": 82770
    },
    {
      "epoch": 1.8395555555555556,
      "grad_norm": 0.23446543514728546,
      "learning_rate": 4.011111111111111e-06,
      "loss": 0.0018,
      "step": 82780
    },
    {
      "epoch": 1.8397777777777777,
      "grad_norm": 0.2173791080713272,
      "learning_rate": 4.005555555555555e-06,
      "loss": 0.0024,
      "step": 82790
    },
    {
      "epoch": 1.8399999999999999,
      "grad_norm": 0.19994844496250153,
      "learning_rate": 4.000000000000001e-06,
      "loss": 0.0017,
      "step": 82800
    },
    {
      "epoch": 1.8402222222222222,
      "grad_norm": 0.3013986051082611,
      "learning_rate": 3.994444444444444e-06,
      "loss": 0.0029,
      "step": 82810
    },
    {
      "epoch": 1.8404444444444445,
      "grad_norm": 0.7448872327804565,
      "learning_rate": 3.9888888888888895e-06,
      "loss": 0.002,
      "step": 82820
    },
    {
      "epoch": 1.8406666666666667,
      "grad_norm": 0.092471644282341,
      "learning_rate": 3.983333333333333e-06,
      "loss": 0.0018,
      "step": 82830
    },
    {
      "epoch": 1.8408888888888888,
      "grad_norm": 0.6188473105430603,
      "learning_rate": 3.977777777777778e-06,
      "loss": 0.0022,
      "step": 82840
    },
    {
      "epoch": 1.8411111111111111,
      "grad_norm": 0.461397647857666,
      "learning_rate": 3.972222222222223e-06,
      "loss": 0.0025,
      "step": 82850
    },
    {
      "epoch": 1.8413333333333335,
      "grad_norm": 0.2067854106426239,
      "learning_rate": 3.966666666666667e-06,
      "loss": 0.0025,
      "step": 82860
    },
    {
      "epoch": 1.8415555555555554,
      "grad_norm": 0.37193360924720764,
      "learning_rate": 3.9611111111111115e-06,
      "loss": 0.002,
      "step": 82870
    },
    {
      "epoch": 1.8417777777777777,
      "grad_norm": 0.6449404358863831,
      "learning_rate": 3.955555555555555e-06,
      "loss": 0.0019,
      "step": 82880
    },
    {
      "epoch": 1.842,
      "grad_norm": 0.16127952933311462,
      "learning_rate": 3.95e-06,
      "loss": 0.0018,
      "step": 82890
    },
    {
      "epoch": 1.8422222222222222,
      "grad_norm": 0.12035553902387619,
      "learning_rate": 3.944444444444445e-06,
      "loss": 0.0017,
      "step": 82900
    },
    {
      "epoch": 1.8424444444444443,
      "grad_norm": 0.49546244740486145,
      "learning_rate": 3.938888888888889e-06,
      "loss": 0.0016,
      "step": 82910
    },
    {
      "epoch": 1.8426666666666667,
      "grad_norm": 0.24124452471733093,
      "learning_rate": 3.9333333333333335e-06,
      "loss": 0.0017,
      "step": 82920
    },
    {
      "epoch": 1.842888888888889,
      "grad_norm": 0.1381537765264511,
      "learning_rate": 3.927777777777778e-06,
      "loss": 0.0016,
      "step": 82930
    },
    {
      "epoch": 1.8431111111111111,
      "grad_norm": 0.2174733728170395,
      "learning_rate": 3.922222222222222e-06,
      "loss": 0.0023,
      "step": 82940
    },
    {
      "epoch": 1.8433333333333333,
      "grad_norm": 0.2056088000535965,
      "learning_rate": 3.916666666666667e-06,
      "loss": 0.0026,
      "step": 82950
    },
    {
      "epoch": 1.8435555555555556,
      "grad_norm": 0.09326383471488953,
      "learning_rate": 3.911111111111111e-06,
      "loss": 0.0019,
      "step": 82960
    },
    {
      "epoch": 1.8437777777777777,
      "grad_norm": 0.3283286392688751,
      "learning_rate": 3.905555555555556e-06,
      "loss": 0.0016,
      "step": 82970
    },
    {
      "epoch": 1.8439999999999999,
      "grad_norm": 0.07694690674543381,
      "learning_rate": 3.9e-06,
      "loss": 0.0018,
      "step": 82980
    },
    {
      "epoch": 1.8442222222222222,
      "grad_norm": 0.332258939743042,
      "learning_rate": 3.894444444444444e-06,
      "loss": 0.0025,
      "step": 82990
    },
    {
      "epoch": 1.8444444444444446,
      "grad_norm": 0.3521285057067871,
      "learning_rate": 3.888888888888889e-06,
      "loss": 0.002,
      "step": 83000
    },
    {
      "epoch": 1.8446666666666667,
      "grad_norm": 0.14302441477775574,
      "learning_rate": 3.883333333333333e-06,
      "loss": 0.0027,
      "step": 83010
    },
    {
      "epoch": 1.8448888888888888,
      "grad_norm": 0.5870251059532166,
      "learning_rate": 3.877777777777778e-06,
      "loss": 0.0018,
      "step": 83020
    },
    {
      "epoch": 1.8451111111111111,
      "grad_norm": 0.21741674840450287,
      "learning_rate": 3.872222222222222e-06,
      "loss": 0.0026,
      "step": 83030
    },
    {
      "epoch": 1.8453333333333335,
      "grad_norm": 0.11473725736141205,
      "learning_rate": 3.866666666666667e-06,
      "loss": 0.0017,
      "step": 83040
    },
    {
      "epoch": 1.8455555555555554,
      "grad_norm": 0.24787680804729462,
      "learning_rate": 3.861111111111112e-06,
      "loss": 0.0025,
      "step": 83050
    },
    {
      "epoch": 1.8457777777777777,
      "grad_norm": 0.08108533918857574,
      "learning_rate": 3.855555555555556e-06,
      "loss": 0.002,
      "step": 83060
    },
    {
      "epoch": 1.846,
      "grad_norm": 0.20924824476242065,
      "learning_rate": 3.85e-06,
      "loss": 0.0017,
      "step": 83070
    },
    {
      "epoch": 1.8462222222222222,
      "grad_norm": 0.5516300201416016,
      "learning_rate": 3.844444444444445e-06,
      "loss": 0.0021,
      "step": 83080
    },
    {
      "epoch": 1.8464444444444443,
      "grad_norm": 0.450367271900177,
      "learning_rate": 3.838888888888889e-06,
      "loss": 0.0019,
      "step": 83090
    },
    {
      "epoch": 1.8466666666666667,
      "grad_norm": 0.0912773534655571,
      "learning_rate": 3.833333333333334e-06,
      "loss": 0.0021,
      "step": 83100
    },
    {
      "epoch": 1.846888888888889,
      "grad_norm": 0.06061064079403877,
      "learning_rate": 3.827777777777778e-06,
      "loss": 0.0021,
      "step": 83110
    },
    {
      "epoch": 1.8471111111111111,
      "grad_norm": 0.4449814558029175,
      "learning_rate": 3.8222222222222224e-06,
      "loss": 0.002,
      "step": 83120
    },
    {
      "epoch": 1.8473333333333333,
      "grad_norm": 0.14600789546966553,
      "learning_rate": 3.816666666666667e-06,
      "loss": 0.0021,
      "step": 83130
    },
    {
      "epoch": 1.8475555555555556,
      "grad_norm": 0.16941875219345093,
      "learning_rate": 3.8111111111111112e-06,
      "loss": 0.0019,
      "step": 83140
    },
    {
      "epoch": 1.8477777777777777,
      "grad_norm": 0.17033804953098297,
      "learning_rate": 3.805555555555556e-06,
      "loss": 0.0024,
      "step": 83150
    },
    {
      "epoch": 1.8479999999999999,
      "grad_norm": 0.11873584240674973,
      "learning_rate": 3.8e-06,
      "loss": 0.0025,
      "step": 83160
    },
    {
      "epoch": 1.8482222222222222,
      "grad_norm": 0.23702853918075562,
      "learning_rate": 3.794444444444445e-06,
      "loss": 0.0028,
      "step": 83170
    },
    {
      "epoch": 1.8484444444444446,
      "grad_norm": 0.0512162446975708,
      "learning_rate": 3.788888888888889e-06,
      "loss": 0.0023,
      "step": 83180
    },
    {
      "epoch": 1.8486666666666667,
      "grad_norm": 0.5760629773139954,
      "learning_rate": 3.7833333333333333e-06,
      "loss": 0.0019,
      "step": 83190
    },
    {
      "epoch": 1.8488888888888888,
      "grad_norm": 0.3827386796474457,
      "learning_rate": 3.777777777777778e-06,
      "loss": 0.0026,
      "step": 83200
    },
    {
      "epoch": 1.8491111111111111,
      "grad_norm": 0.34088197350502014,
      "learning_rate": 3.772222222222222e-06,
      "loss": 0.0033,
      "step": 83210
    },
    {
      "epoch": 1.8493333333333335,
      "grad_norm": 0.21586871147155762,
      "learning_rate": 3.766666666666667e-06,
      "loss": 0.0034,
      "step": 83220
    },
    {
      "epoch": 1.8495555555555554,
      "grad_norm": 0.11141029000282288,
      "learning_rate": 3.7611111111111113e-06,
      "loss": 0.0018,
      "step": 83230
    },
    {
      "epoch": 1.8497777777777777,
      "grad_norm": 0.46919646859169006,
      "learning_rate": 3.755555555555556e-06,
      "loss": 0.0017,
      "step": 83240
    },
    {
      "epoch": 1.85,
      "grad_norm": 0.16691799461841583,
      "learning_rate": 3.75e-06,
      "loss": 0.0022,
      "step": 83250
    },
    {
      "epoch": 1.8502222222222222,
      "grad_norm": 0.2779100239276886,
      "learning_rate": 3.744444444444445e-06,
      "loss": 0.0019,
      "step": 83260
    },
    {
      "epoch": 1.8504444444444443,
      "grad_norm": 0.4288700819015503,
      "learning_rate": 3.738888888888889e-06,
      "loss": 0.002,
      "step": 83270
    },
    {
      "epoch": 1.8506666666666667,
      "grad_norm": 0.16709910333156586,
      "learning_rate": 3.7333333333333337e-06,
      "loss": 0.0018,
      "step": 83280
    },
    {
      "epoch": 1.850888888888889,
      "grad_norm": 0.17904575169086456,
      "learning_rate": 3.727777777777778e-06,
      "loss": 0.0034,
      "step": 83290
    },
    {
      "epoch": 1.8511111111111112,
      "grad_norm": 0.13173095881938934,
      "learning_rate": 3.722222222222222e-06,
      "loss": 0.0021,
      "step": 83300
    },
    {
      "epoch": 1.8513333333333333,
      "grad_norm": 0.4274962544441223,
      "learning_rate": 3.716666666666667e-06,
      "loss": 0.0017,
      "step": 83310
    },
    {
      "epoch": 1.8515555555555556,
      "grad_norm": 0.16352097690105438,
      "learning_rate": 3.711111111111111e-06,
      "loss": 0.0017,
      "step": 83320
    },
    {
      "epoch": 1.8517777777777777,
      "grad_norm": 0.21789802610874176,
      "learning_rate": 3.7055555555555557e-06,
      "loss": 0.0023,
      "step": 83330
    },
    {
      "epoch": 1.8519999999999999,
      "grad_norm": 0.2280767858028412,
      "learning_rate": 3.7e-06,
      "loss": 0.0022,
      "step": 83340
    },
    {
      "epoch": 1.8522222222222222,
      "grad_norm": 0.424439936876297,
      "learning_rate": 3.694444444444445e-06,
      "loss": 0.0027,
      "step": 83350
    },
    {
      "epoch": 1.8524444444444446,
      "grad_norm": 0.12535589933395386,
      "learning_rate": 3.688888888888889e-06,
      "loss": 0.0017,
      "step": 83360
    },
    {
      "epoch": 1.8526666666666667,
      "grad_norm": 0.5084260106086731,
      "learning_rate": 3.6833333333333338e-06,
      "loss": 0.0021,
      "step": 83370
    },
    {
      "epoch": 1.8528888888888888,
      "grad_norm": 0.08039991557598114,
      "learning_rate": 3.6777777777777778e-06,
      "loss": 0.0018,
      "step": 83380
    },
    {
      "epoch": 1.8531111111111112,
      "grad_norm": 0.3678940534591675,
      "learning_rate": 3.6722222222222226e-06,
      "loss": 0.002,
      "step": 83390
    },
    {
      "epoch": 1.8533333333333335,
      "grad_norm": 0.2626974284648895,
      "learning_rate": 3.666666666666667e-06,
      "loss": 0.0017,
      "step": 83400
    },
    {
      "epoch": 1.8535555555555554,
      "grad_norm": 0.09943263232707977,
      "learning_rate": 3.661111111111111e-06,
      "loss": 0.0032,
      "step": 83410
    },
    {
      "epoch": 1.8537777777777777,
      "grad_norm": 0.36734145879745483,
      "learning_rate": 3.655555555555556e-06,
      "loss": 0.0018,
      "step": 83420
    },
    {
      "epoch": 1.854,
      "grad_norm": 0.236819788813591,
      "learning_rate": 3.6499999999999998e-06,
      "loss": 0.0018,
      "step": 83430
    },
    {
      "epoch": 1.8542222222222222,
      "grad_norm": 0.4271087646484375,
      "learning_rate": 3.6444444444444446e-06,
      "loss": 0.0019,
      "step": 83440
    },
    {
      "epoch": 1.8544444444444443,
      "grad_norm": 0.09864451736211777,
      "learning_rate": 3.638888888888889e-06,
      "loss": 0.003,
      "step": 83450
    },
    {
      "epoch": 1.8546666666666667,
      "grad_norm": 0.25067171454429626,
      "learning_rate": 3.633333333333334e-06,
      "loss": 0.0018,
      "step": 83460
    },
    {
      "epoch": 1.854888888888889,
      "grad_norm": 0.10731729120016098,
      "learning_rate": 3.627777777777778e-06,
      "loss": 0.0017,
      "step": 83470
    },
    {
      "epoch": 1.8551111111111112,
      "grad_norm": 0.485280305147171,
      "learning_rate": 3.6222222222222226e-06,
      "loss": 0.0019,
      "step": 83480
    },
    {
      "epoch": 1.8553333333333333,
      "grad_norm": 0.19297809898853302,
      "learning_rate": 3.6166666666666666e-06,
      "loss": 0.0024,
      "step": 83490
    },
    {
      "epoch": 1.8555555555555556,
      "grad_norm": 0.39294493198394775,
      "learning_rate": 3.611111111111111e-06,
      "loss": 0.0019,
      "step": 83500
    },
    {
      "epoch": 1.8557777777777777,
      "grad_norm": 0.0769147202372551,
      "learning_rate": 3.605555555555556e-06,
      "loss": 0.0016,
      "step": 83510
    },
    {
      "epoch": 1.8559999999999999,
      "grad_norm": 0.38507890701293945,
      "learning_rate": 3.6e-06,
      "loss": 0.0017,
      "step": 83520
    },
    {
      "epoch": 1.8562222222222222,
      "grad_norm": 0.5204114317893982,
      "learning_rate": 3.5944444444444447e-06,
      "loss": 0.0022,
      "step": 83530
    },
    {
      "epoch": 1.8564444444444446,
      "grad_norm": 0.07721102237701416,
      "learning_rate": 3.588888888888889e-06,
      "loss": 0.0034,
      "step": 83540
    },
    {
      "epoch": 1.8566666666666667,
      "grad_norm": 0.5338982343673706,
      "learning_rate": 3.5833333333333335e-06,
      "loss": 0.0017,
      "step": 83550
    },
    {
      "epoch": 1.8568888888888888,
      "grad_norm": 0.1891375631093979,
      "learning_rate": 3.577777777777778e-06,
      "loss": 0.0026,
      "step": 83560
    },
    {
      "epoch": 1.8571111111111112,
      "grad_norm": 0.08838766068220139,
      "learning_rate": 3.5722222222222227e-06,
      "loss": 0.0018,
      "step": 83570
    },
    {
      "epoch": 1.8573333333333333,
      "grad_norm": 0.18040864169597626,
      "learning_rate": 3.5666666666666667e-06,
      "loss": 0.0019,
      "step": 83580
    },
    {
      "epoch": 1.8575555555555554,
      "grad_norm": 0.26052460074424744,
      "learning_rate": 3.5611111111111115e-06,
      "loss": 0.0017,
      "step": 83590
    },
    {
      "epoch": 1.8577777777777778,
      "grad_norm": 0.3690366744995117,
      "learning_rate": 3.555555555555556e-06,
      "loss": 0.0016,
      "step": 83600
    },
    {
      "epoch": 1.858,
      "grad_norm": 0.5529982447624207,
      "learning_rate": 3.55e-06,
      "loss": 0.0026,
      "step": 83610
    },
    {
      "epoch": 1.8582222222222222,
      "grad_norm": 0.11883720755577087,
      "learning_rate": 3.5444444444444447e-06,
      "loss": 0.0018,
      "step": 83620
    },
    {
      "epoch": 1.8584444444444443,
      "grad_norm": 0.10485178977251053,
      "learning_rate": 3.5388888888888887e-06,
      "loss": 0.0025,
      "step": 83630
    },
    {
      "epoch": 1.8586666666666667,
      "grad_norm": 0.24456843733787537,
      "learning_rate": 3.5333333333333335e-06,
      "loss": 0.0027,
      "step": 83640
    },
    {
      "epoch": 1.858888888888889,
      "grad_norm": 0.7441070675849915,
      "learning_rate": 3.527777777777778e-06,
      "loss": 0.0019,
      "step": 83650
    },
    {
      "epoch": 1.8591111111111112,
      "grad_norm": 0.09986420720815659,
      "learning_rate": 3.5222222222222228e-06,
      "loss": 0.0025,
      "step": 83660
    },
    {
      "epoch": 1.8593333333333333,
      "grad_norm": 0.28862038254737854,
      "learning_rate": 3.5166666666666667e-06,
      "loss": 0.0026,
      "step": 83670
    },
    {
      "epoch": 1.8595555555555556,
      "grad_norm": 0.43896037340164185,
      "learning_rate": 3.5111111111111116e-06,
      "loss": 0.0025,
      "step": 83680
    },
    {
      "epoch": 1.8597777777777778,
      "grad_norm": 0.20536959171295166,
      "learning_rate": 3.5055555555555555e-06,
      "loss": 0.0024,
      "step": 83690
    },
    {
      "epoch": 1.8599999999999999,
      "grad_norm": 0.10812145471572876,
      "learning_rate": 3.5000000000000004e-06,
      "loss": 0.0018,
      "step": 83700
    },
    {
      "epoch": 1.8602222222222222,
      "grad_norm": 0.11956407874822617,
      "learning_rate": 3.4944444444444448e-06,
      "loss": 0.0025,
      "step": 83710
    },
    {
      "epoch": 1.8604444444444446,
      "grad_norm": 0.1086399108171463,
      "learning_rate": 3.4888888888888888e-06,
      "loss": 0.0017,
      "step": 83720
    },
    {
      "epoch": 1.8606666666666667,
      "grad_norm": 0.2183028608560562,
      "learning_rate": 3.4833333333333336e-06,
      "loss": 0.0016,
      "step": 83730
    },
    {
      "epoch": 1.8608888888888888,
      "grad_norm": 0.3332769274711609,
      "learning_rate": 3.4777777777777776e-06,
      "loss": 0.0021,
      "step": 83740
    },
    {
      "epoch": 1.8611111111111112,
      "grad_norm": 0.2448032945394516,
      "learning_rate": 3.4722222222222224e-06,
      "loss": 0.002,
      "step": 83750
    },
    {
      "epoch": 1.8613333333333333,
      "grad_norm": 0.2383706122636795,
      "learning_rate": 3.466666666666667e-06,
      "loss": 0.0022,
      "step": 83760
    },
    {
      "epoch": 1.8615555555555554,
      "grad_norm": 0.06550344079732895,
      "learning_rate": 3.4611111111111116e-06,
      "loss": 0.0035,
      "step": 83770
    },
    {
      "epoch": 1.8617777777777778,
      "grad_norm": 0.27583056688308716,
      "learning_rate": 3.4555555555555556e-06,
      "loss": 0.0019,
      "step": 83780
    },
    {
      "epoch": 1.862,
      "grad_norm": 0.1947675198316574,
      "learning_rate": 3.4500000000000004e-06,
      "loss": 0.0021,
      "step": 83790
    },
    {
      "epoch": 1.8622222222222222,
      "grad_norm": 0.10399050265550613,
      "learning_rate": 3.4444444444444444e-06,
      "loss": 0.0018,
      "step": 83800
    },
    {
      "epoch": 1.8624444444444443,
      "grad_norm": 0.16244933009147644,
      "learning_rate": 3.438888888888889e-06,
      "loss": 0.002,
      "step": 83810
    },
    {
      "epoch": 1.8626666666666667,
      "grad_norm": 0.24915528297424316,
      "learning_rate": 3.4333333333333336e-06,
      "loss": 0.0017,
      "step": 83820
    },
    {
      "epoch": 1.862888888888889,
      "grad_norm": 0.1068994551897049,
      "learning_rate": 3.4277777777777776e-06,
      "loss": 0.0023,
      "step": 83830
    },
    {
      "epoch": 1.8631111111111112,
      "grad_norm": 0.19508418440818787,
      "learning_rate": 3.4222222222222224e-06,
      "loss": 0.0017,
      "step": 83840
    },
    {
      "epoch": 1.8633333333333333,
      "grad_norm": 0.17665867507457733,
      "learning_rate": 3.4166666666666664e-06,
      "loss": 0.0033,
      "step": 83850
    },
    {
      "epoch": 1.8635555555555556,
      "grad_norm": 0.481831818819046,
      "learning_rate": 3.4111111111111113e-06,
      "loss": 0.002,
      "step": 83860
    },
    {
      "epoch": 1.8637777777777778,
      "grad_norm": 0.26416972279548645,
      "learning_rate": 3.4055555555555557e-06,
      "loss": 0.0024,
      "step": 83870
    },
    {
      "epoch": 1.8639999999999999,
      "grad_norm": 0.4404996335506439,
      "learning_rate": 3.4000000000000005e-06,
      "loss": 0.0027,
      "step": 83880
    },
    {
      "epoch": 1.8642222222222222,
      "grad_norm": 0.12110940366983414,
      "learning_rate": 3.3944444444444445e-06,
      "loss": 0.0026,
      "step": 83890
    },
    {
      "epoch": 1.8644444444444446,
      "grad_norm": 0.13604988157749176,
      "learning_rate": 3.3888888888888893e-06,
      "loss": 0.0018,
      "step": 83900
    },
    {
      "epoch": 1.8646666666666667,
      "grad_norm": 0.08598300814628601,
      "learning_rate": 3.3833333333333337e-06,
      "loss": 0.0016,
      "step": 83910
    },
    {
      "epoch": 1.8648888888888888,
      "grad_norm": 0.5361654758453369,
      "learning_rate": 3.3777777777777777e-06,
      "loss": 0.0021,
      "step": 83920
    },
    {
      "epoch": 1.8651111111111112,
      "grad_norm": 0.24768409132957458,
      "learning_rate": 3.3722222222222225e-06,
      "loss": 0.002,
      "step": 83930
    },
    {
      "epoch": 1.8653333333333333,
      "grad_norm": 0.1652158945798874,
      "learning_rate": 3.3666666666666665e-06,
      "loss": 0.0029,
      "step": 83940
    },
    {
      "epoch": 1.8655555555555554,
      "grad_norm": 0.36877012252807617,
      "learning_rate": 3.3611111111111113e-06,
      "loss": 0.0018,
      "step": 83950
    },
    {
      "epoch": 1.8657777777777778,
      "grad_norm": 0.26997944712638855,
      "learning_rate": 3.3555555555555557e-06,
      "loss": 0.0018,
      "step": 83960
    },
    {
      "epoch": 1.866,
      "grad_norm": 0.12329837679862976,
      "learning_rate": 3.3500000000000005e-06,
      "loss": 0.002,
      "step": 83970
    },
    {
      "epoch": 1.8662222222222222,
      "grad_norm": 0.2587895393371582,
      "learning_rate": 3.3444444444444445e-06,
      "loss": 0.0019,
      "step": 83980
    },
    {
      "epoch": 1.8664444444444444,
      "grad_norm": 0.30642974376678467,
      "learning_rate": 3.3388888888888893e-06,
      "loss": 0.0016,
      "step": 83990
    },
    {
      "epoch": 1.8666666666666667,
      "grad_norm": 0.1004071980714798,
      "learning_rate": 3.3333333333333333e-06,
      "loss": 0.002,
      "step": 84000
    },
    {
      "epoch": 1.866888888888889,
      "grad_norm": 0.45415201783180237,
      "learning_rate": 3.327777777777778e-06,
      "loss": 0.0029,
      "step": 84010
    },
    {
      "epoch": 1.8671111111111112,
      "grad_norm": 0.39760610461235046,
      "learning_rate": 3.3222222222222226e-06,
      "loss": 0.0027,
      "step": 84020
    },
    {
      "epoch": 1.8673333333333333,
      "grad_norm": 0.048770178109407425,
      "learning_rate": 3.3166666666666665e-06,
      "loss": 0.0019,
      "step": 84030
    },
    {
      "epoch": 1.8675555555555556,
      "grad_norm": 0.07138741761445999,
      "learning_rate": 3.3111111111111114e-06,
      "loss": 0.0017,
      "step": 84040
    },
    {
      "epoch": 1.8677777777777778,
      "grad_norm": 0.16397935152053833,
      "learning_rate": 3.3055555555555553e-06,
      "loss": 0.0021,
      "step": 84050
    },
    {
      "epoch": 1.8679999999999999,
      "grad_norm": 0.19989275932312012,
      "learning_rate": 3.3e-06,
      "loss": 0.0028,
      "step": 84060
    },
    {
      "epoch": 1.8682222222222222,
      "grad_norm": 0.1627175509929657,
      "learning_rate": 3.2944444444444446e-06,
      "loss": 0.0026,
      "step": 84070
    },
    {
      "epoch": 1.8684444444444446,
      "grad_norm": 0.36511626839637756,
      "learning_rate": 3.2888888888888894e-06,
      "loss": 0.0016,
      "step": 84080
    },
    {
      "epoch": 1.8686666666666667,
      "grad_norm": 0.3714708983898163,
      "learning_rate": 3.2833333333333334e-06,
      "loss": 0.0038,
      "step": 84090
    },
    {
      "epoch": 1.8688888888888888,
      "grad_norm": 0.08438637107610703,
      "learning_rate": 3.277777777777778e-06,
      "loss": 0.0021,
      "step": 84100
    },
    {
      "epoch": 1.8691111111111112,
      "grad_norm": 0.11604084074497223,
      "learning_rate": 3.272222222222222e-06,
      "loss": 0.0019,
      "step": 84110
    },
    {
      "epoch": 1.8693333333333333,
      "grad_norm": 0.5641048550605774,
      "learning_rate": 3.2666666666666666e-06,
      "loss": 0.0022,
      "step": 84120
    },
    {
      "epoch": 1.8695555555555554,
      "grad_norm": 0.39827755093574524,
      "learning_rate": 3.2611111111111114e-06,
      "loss": 0.0019,
      "step": 84130
    },
    {
      "epoch": 1.8697777777777778,
      "grad_norm": 0.30319756269454956,
      "learning_rate": 3.2555555555555554e-06,
      "loss": 0.0027,
      "step": 84140
    },
    {
      "epoch": 1.87,
      "grad_norm": 0.0917072594165802,
      "learning_rate": 3.2500000000000002e-06,
      "loss": 0.0022,
      "step": 84150
    },
    {
      "epoch": 1.8702222222222222,
      "grad_norm": 0.06233477592468262,
      "learning_rate": 3.244444444444444e-06,
      "loss": 0.0015,
      "step": 84160
    },
    {
      "epoch": 1.8704444444444444,
      "grad_norm": 0.2187027633190155,
      "learning_rate": 3.238888888888889e-06,
      "loss": 0.0021,
      "step": 84170
    },
    {
      "epoch": 1.8706666666666667,
      "grad_norm": 0.5209842920303345,
      "learning_rate": 3.2333333333333334e-06,
      "loss": 0.0018,
      "step": 84180
    },
    {
      "epoch": 1.870888888888889,
      "grad_norm": 0.2580464780330658,
      "learning_rate": 3.2277777777777783e-06,
      "loss": 0.0017,
      "step": 84190
    },
    {
      "epoch": 1.871111111111111,
      "grad_norm": 0.11967077106237411,
      "learning_rate": 3.2222222222222222e-06,
      "loss": 0.0021,
      "step": 84200
    },
    {
      "epoch": 1.8713333333333333,
      "grad_norm": 0.06090690940618515,
      "learning_rate": 3.216666666666667e-06,
      "loss": 0.0019,
      "step": 84210
    },
    {
      "epoch": 1.8715555555555556,
      "grad_norm": 0.08481711894273758,
      "learning_rate": 3.2111111111111115e-06,
      "loss": 0.0018,
      "step": 84220
    },
    {
      "epoch": 1.8717777777777778,
      "grad_norm": 0.3586946427822113,
      "learning_rate": 3.2055555555555555e-06,
      "loss": 0.0027,
      "step": 84230
    },
    {
      "epoch": 1.8719999999999999,
      "grad_norm": 0.45253682136535645,
      "learning_rate": 3.2000000000000003e-06,
      "loss": 0.0019,
      "step": 84240
    },
    {
      "epoch": 1.8722222222222222,
      "grad_norm": 0.20788811147212982,
      "learning_rate": 3.1944444444444443e-06,
      "loss": 0.0034,
      "step": 84250
    },
    {
      "epoch": 1.8724444444444446,
      "grad_norm": 0.33314499258995056,
      "learning_rate": 3.188888888888889e-06,
      "loss": 0.0022,
      "step": 84260
    },
    {
      "epoch": 1.8726666666666667,
      "grad_norm": 0.4222449064254761,
      "learning_rate": 3.1833333333333335e-06,
      "loss": 0.0019,
      "step": 84270
    },
    {
      "epoch": 1.8728888888888888,
      "grad_norm": 0.33561477065086365,
      "learning_rate": 3.1777777777777783e-06,
      "loss": 0.0017,
      "step": 84280
    },
    {
      "epoch": 1.8731111111111112,
      "grad_norm": 0.4406384229660034,
      "learning_rate": 3.1722222222222223e-06,
      "loss": 0.0016,
      "step": 84290
    },
    {
      "epoch": 1.8733333333333333,
      "grad_norm": 0.5376229286193848,
      "learning_rate": 3.166666666666667e-06,
      "loss": 0.0018,
      "step": 84300
    },
    {
      "epoch": 1.8735555555555554,
      "grad_norm": 0.24719619750976562,
      "learning_rate": 3.161111111111111e-06,
      "loss": 0.0018,
      "step": 84310
    },
    {
      "epoch": 1.8737777777777778,
      "grad_norm": 0.20319817960262299,
      "learning_rate": 3.155555555555556e-06,
      "loss": 0.0017,
      "step": 84320
    },
    {
      "epoch": 1.874,
      "grad_norm": 0.16143237054347992,
      "learning_rate": 3.1500000000000003e-06,
      "loss": 0.002,
      "step": 84330
    },
    {
      "epoch": 1.8742222222222222,
      "grad_norm": 0.3865293264389038,
      "learning_rate": 3.1444444444444443e-06,
      "loss": 0.0029,
      "step": 84340
    },
    {
      "epoch": 1.8744444444444444,
      "grad_norm": 0.47952380776405334,
      "learning_rate": 3.138888888888889e-06,
      "loss": 0.003,
      "step": 84350
    },
    {
      "epoch": 1.8746666666666667,
      "grad_norm": 0.18683545291423798,
      "learning_rate": 3.133333333333333e-06,
      "loss": 0.0027,
      "step": 84360
    },
    {
      "epoch": 1.874888888888889,
      "grad_norm": 0.1543990671634674,
      "learning_rate": 3.127777777777778e-06,
      "loss": 0.0024,
      "step": 84370
    },
    {
      "epoch": 1.875111111111111,
      "grad_norm": 0.18100379407405853,
      "learning_rate": 3.1222222222222224e-06,
      "loss": 0.0018,
      "step": 84380
    },
    {
      "epoch": 1.8753333333333333,
      "grad_norm": 0.3109774589538574,
      "learning_rate": 3.1166666666666668e-06,
      "loss": 0.0016,
      "step": 84390
    },
    {
      "epoch": 1.8755555555555556,
      "grad_norm": 0.13281692564487457,
      "learning_rate": 3.111111111111111e-06,
      "loss": 0.0026,
      "step": 84400
    },
    {
      "epoch": 1.8757777777777778,
      "grad_norm": 0.1061684712767601,
      "learning_rate": 3.1055555555555556e-06,
      "loss": 0.0019,
      "step": 84410
    },
    {
      "epoch": 1.876,
      "grad_norm": 0.09161976724863052,
      "learning_rate": 3.1e-06,
      "loss": 0.0024,
      "step": 84420
    },
    {
      "epoch": 1.8762222222222222,
      "grad_norm": 0.22689497470855713,
      "learning_rate": 3.094444444444445e-06,
      "loss": 0.0025,
      "step": 84430
    },
    {
      "epoch": 1.8764444444444446,
      "grad_norm": 0.3940412998199463,
      "learning_rate": 3.088888888888889e-06,
      "loss": 0.0019,
      "step": 84440
    },
    {
      "epoch": 1.8766666666666667,
      "grad_norm": 0.3123511075973511,
      "learning_rate": 3.0833333333333336e-06,
      "loss": 0.0018,
      "step": 84450
    },
    {
      "epoch": 1.8768888888888888,
      "grad_norm": 0.09361816942691803,
      "learning_rate": 3.077777777777778e-06,
      "loss": 0.0035,
      "step": 84460
    },
    {
      "epoch": 1.8771111111111112,
      "grad_norm": 0.3106265366077423,
      "learning_rate": 3.0722222222222224e-06,
      "loss": 0.0015,
      "step": 84470
    },
    {
      "epoch": 1.8773333333333333,
      "grad_norm": 0.10009999573230743,
      "learning_rate": 3.066666666666667e-06,
      "loss": 0.0021,
      "step": 84480
    },
    {
      "epoch": 1.8775555555555554,
      "grad_norm": 0.3838699460029602,
      "learning_rate": 3.0611111111111112e-06,
      "loss": 0.0021,
      "step": 84490
    },
    {
      "epoch": 1.8777777777777778,
      "grad_norm": 0.3567304313182831,
      "learning_rate": 3.0555555555555556e-06,
      "loss": 0.0023,
      "step": 84500
    },
    {
      "epoch": 1.8780000000000001,
      "grad_norm": 0.17457129061222076,
      "learning_rate": 3.05e-06,
      "loss": 0.0024,
      "step": 84510
    },
    {
      "epoch": 1.8782222222222222,
      "grad_norm": 0.16364838182926178,
      "learning_rate": 3.0444444444444444e-06,
      "loss": 0.0024,
      "step": 84520
    },
    {
      "epoch": 1.8784444444444444,
      "grad_norm": 0.3828265964984894,
      "learning_rate": 3.038888888888889e-06,
      "loss": 0.0025,
      "step": 84530
    },
    {
      "epoch": 1.8786666666666667,
      "grad_norm": 0.2102271020412445,
      "learning_rate": 3.0333333333333337e-06,
      "loss": 0.0025,
      "step": 84540
    },
    {
      "epoch": 1.878888888888889,
      "grad_norm": 0.4676882326602936,
      "learning_rate": 3.027777777777778e-06,
      "loss": 0.002,
      "step": 84550
    },
    {
      "epoch": 1.879111111111111,
      "grad_norm": 0.16377617418766022,
      "learning_rate": 3.0222222222222225e-06,
      "loss": 0.0024,
      "step": 84560
    },
    {
      "epoch": 1.8793333333333333,
      "grad_norm": 0.16819103062152863,
      "learning_rate": 3.016666666666667e-06,
      "loss": 0.0026,
      "step": 84570
    },
    {
      "epoch": 1.8795555555555556,
      "grad_norm": 0.37693142890930176,
      "learning_rate": 3.0111111111111113e-06,
      "loss": 0.0021,
      "step": 84580
    },
    {
      "epoch": 1.8797777777777778,
      "grad_norm": 0.05097251757979393,
      "learning_rate": 3.0055555555555557e-06,
      "loss": 0.0018,
      "step": 84590
    },
    {
      "epoch": 1.88,
      "grad_norm": 0.27651798725128174,
      "learning_rate": 3e-06,
      "loss": 0.0025,
      "step": 84600
    },
    {
      "epoch": 1.8802222222222222,
      "grad_norm": 0.12934789061546326,
      "learning_rate": 2.9944444444444445e-06,
      "loss": 0.0021,
      "step": 84610
    },
    {
      "epoch": 1.8804444444444446,
      "grad_norm": 0.19519084692001343,
      "learning_rate": 2.988888888888889e-06,
      "loss": 0.0017,
      "step": 84620
    },
    {
      "epoch": 1.8806666666666667,
      "grad_norm": 0.20922715961933136,
      "learning_rate": 2.9833333333333333e-06,
      "loss": 0.002,
      "step": 84630
    },
    {
      "epoch": 1.8808888888888888,
      "grad_norm": 0.05382523313164711,
      "learning_rate": 2.977777777777778e-06,
      "loss": 0.002,
      "step": 84640
    },
    {
      "epoch": 1.8811111111111112,
      "grad_norm": 0.3904475271701813,
      "learning_rate": 2.9722222222222225e-06,
      "loss": 0.0026,
      "step": 84650
    },
    {
      "epoch": 1.8813333333333333,
      "grad_norm": 0.12281453609466553,
      "learning_rate": 2.966666666666667e-06,
      "loss": 0.0017,
      "step": 84660
    },
    {
      "epoch": 1.8815555555555554,
      "grad_norm": 0.23147965967655182,
      "learning_rate": 2.9611111111111113e-06,
      "loss": 0.0026,
      "step": 84670
    },
    {
      "epoch": 1.8817777777777778,
      "grad_norm": 0.46371346712112427,
      "learning_rate": 2.9555555555555557e-06,
      "loss": 0.0019,
      "step": 84680
    },
    {
      "epoch": 1.8820000000000001,
      "grad_norm": 0.0785008892416954,
      "learning_rate": 2.95e-06,
      "loss": 0.002,
      "step": 84690
    },
    {
      "epoch": 1.8822222222222222,
      "grad_norm": 0.42796024680137634,
      "learning_rate": 2.9444444444444445e-06,
      "loss": 0.0029,
      "step": 84700
    },
    {
      "epoch": 1.8824444444444444,
      "grad_norm": 0.1051204651594162,
      "learning_rate": 2.938888888888889e-06,
      "loss": 0.0024,
      "step": 84710
    },
    {
      "epoch": 1.8826666666666667,
      "grad_norm": 0.37001776695251465,
      "learning_rate": 2.9333333333333333e-06,
      "loss": 0.0031,
      "step": 84720
    },
    {
      "epoch": 1.8828888888888888,
      "grad_norm": 0.30100882053375244,
      "learning_rate": 2.9277777777777777e-06,
      "loss": 0.0018,
      "step": 84730
    },
    {
      "epoch": 1.883111111111111,
      "grad_norm": 0.575886607170105,
      "learning_rate": 2.9222222222222226e-06,
      "loss": 0.0021,
      "step": 84740
    },
    {
      "epoch": 1.8833333333333333,
      "grad_norm": 0.16554519534111023,
      "learning_rate": 2.916666666666667e-06,
      "loss": 0.0019,
      "step": 84750
    },
    {
      "epoch": 1.8835555555555556,
      "grad_norm": 0.12757495045661926,
      "learning_rate": 2.9111111111111114e-06,
      "loss": 0.0025,
      "step": 84760
    },
    {
      "epoch": 1.8837777777777778,
      "grad_norm": 0.35590890049934387,
      "learning_rate": 2.9055555555555558e-06,
      "loss": 0.0022,
      "step": 84770
    },
    {
      "epoch": 1.884,
      "grad_norm": 0.2868221700191498,
      "learning_rate": 2.9e-06,
      "loss": 0.0016,
      "step": 84780
    },
    {
      "epoch": 1.8842222222222222,
      "grad_norm": 0.19424858689308167,
      "learning_rate": 2.8944444444444446e-06,
      "loss": 0.0028,
      "step": 84790
    },
    {
      "epoch": 1.8844444444444446,
      "grad_norm": 0.13983535766601562,
      "learning_rate": 2.888888888888889e-06,
      "loss": 0.002,
      "step": 84800
    },
    {
      "epoch": 1.8846666666666667,
      "grad_norm": 0.19648919999599457,
      "learning_rate": 2.8833333333333334e-06,
      "loss": 0.0018,
      "step": 84810
    },
    {
      "epoch": 1.8848888888888888,
      "grad_norm": 0.16110379993915558,
      "learning_rate": 2.877777777777778e-06,
      "loss": 0.0022,
      "step": 84820
    },
    {
      "epoch": 1.8851111111111112,
      "grad_norm": 0.16687257587909698,
      "learning_rate": 2.872222222222222e-06,
      "loss": 0.0018,
      "step": 84830
    },
    {
      "epoch": 1.8853333333333333,
      "grad_norm": 0.0756993293762207,
      "learning_rate": 2.8666666666666666e-06,
      "loss": 0.0018,
      "step": 84840
    },
    {
      "epoch": 1.8855555555555554,
      "grad_norm": 0.6453551650047302,
      "learning_rate": 2.8611111111111114e-06,
      "loss": 0.0022,
      "step": 84850
    },
    {
      "epoch": 1.8857777777777778,
      "grad_norm": 0.11856495589017868,
      "learning_rate": 2.855555555555556e-06,
      "loss": 0.0026,
      "step": 84860
    },
    {
      "epoch": 1.8860000000000001,
      "grad_norm": 0.39682626724243164,
      "learning_rate": 2.8500000000000002e-06,
      "loss": 0.0018,
      "step": 84870
    },
    {
      "epoch": 1.8862222222222222,
      "grad_norm": 0.11077010631561279,
      "learning_rate": 2.8444444444444446e-06,
      "loss": 0.0018,
      "step": 84880
    },
    {
      "epoch": 1.8864444444444444,
      "grad_norm": 0.10862764716148376,
      "learning_rate": 2.838888888888889e-06,
      "loss": 0.0019,
      "step": 84890
    },
    {
      "epoch": 1.8866666666666667,
      "grad_norm": 0.0847507044672966,
      "learning_rate": 2.8333333333333335e-06,
      "loss": 0.0019,
      "step": 84900
    },
    {
      "epoch": 1.8868888888888888,
      "grad_norm": 0.16231629252433777,
      "learning_rate": 2.827777777777778e-06,
      "loss": 0.0019,
      "step": 84910
    },
    {
      "epoch": 1.887111111111111,
      "grad_norm": 0.09761568903923035,
      "learning_rate": 2.8222222222222223e-06,
      "loss": 0.0018,
      "step": 84920
    },
    {
      "epoch": 1.8873333333333333,
      "grad_norm": 0.09458015114068985,
      "learning_rate": 2.8166666666666667e-06,
      "loss": 0.0019,
      "step": 84930
    },
    {
      "epoch": 1.8875555555555557,
      "grad_norm": 0.11646513640880585,
      "learning_rate": 2.811111111111111e-06,
      "loss": 0.0028,
      "step": 84940
    },
    {
      "epoch": 1.8877777777777778,
      "grad_norm": 0.10443945229053497,
      "learning_rate": 2.805555555555556e-06,
      "loss": 0.0018,
      "step": 84950
    },
    {
      "epoch": 1.888,
      "grad_norm": 0.10590824484825134,
      "learning_rate": 2.8000000000000003e-06,
      "loss": 0.0015,
      "step": 84960
    },
    {
      "epoch": 1.8882222222222222,
      "grad_norm": 0.1816481053829193,
      "learning_rate": 2.7944444444444447e-06,
      "loss": 0.0019,
      "step": 84970
    },
    {
      "epoch": 1.8884444444444446,
      "grad_norm": 0.19277523458003998,
      "learning_rate": 2.788888888888889e-06,
      "loss": 0.0019,
      "step": 84980
    },
    {
      "epoch": 1.8886666666666667,
      "grad_norm": 0.1520514339208603,
      "learning_rate": 2.7833333333333335e-06,
      "loss": 0.0024,
      "step": 84990
    },
    {
      "epoch": 1.8888888888888888,
      "grad_norm": 0.48315247893333435,
      "learning_rate": 2.777777777777778e-06,
      "loss": 0.0018,
      "step": 85000
    },
    {
      "epoch": 1.8891111111111112,
      "grad_norm": 0.20798948407173157,
      "learning_rate": 2.7722222222222223e-06,
      "loss": 0.0026,
      "step": 85010
    },
    {
      "epoch": 1.8893333333333333,
      "grad_norm": 0.1946464329957962,
      "learning_rate": 2.7666666666666667e-06,
      "loss": 0.0025,
      "step": 85020
    },
    {
      "epoch": 1.8895555555555554,
      "grad_norm": 0.2665395438671112,
      "learning_rate": 2.761111111111111e-06,
      "loss": 0.0021,
      "step": 85030
    },
    {
      "epoch": 1.8897777777777778,
      "grad_norm": 0.06469573080539703,
      "learning_rate": 2.7555555555555555e-06,
      "loss": 0.003,
      "step": 85040
    },
    {
      "epoch": 1.8900000000000001,
      "grad_norm": 0.14742633700370789,
      "learning_rate": 2.7500000000000004e-06,
      "loss": 0.002,
      "step": 85050
    },
    {
      "epoch": 1.8902222222222222,
      "grad_norm": 0.24431125819683075,
      "learning_rate": 2.7444444444444448e-06,
      "loss": 0.002,
      "step": 85060
    },
    {
      "epoch": 1.8904444444444444,
      "grad_norm": 0.09100891649723053,
      "learning_rate": 2.738888888888889e-06,
      "loss": 0.0026,
      "step": 85070
    },
    {
      "epoch": 1.8906666666666667,
      "grad_norm": 0.18738916516304016,
      "learning_rate": 2.7333333333333336e-06,
      "loss": 0.0027,
      "step": 85080
    },
    {
      "epoch": 1.8908888888888888,
      "grad_norm": 0.2058275043964386,
      "learning_rate": 2.727777777777778e-06,
      "loss": 0.0023,
      "step": 85090
    },
    {
      "epoch": 1.891111111111111,
      "grad_norm": 0.32368558645248413,
      "learning_rate": 2.7222222222222224e-06,
      "loss": 0.002,
      "step": 85100
    },
    {
      "epoch": 1.8913333333333333,
      "grad_norm": 0.301188200712204,
      "learning_rate": 2.7166666666666668e-06,
      "loss": 0.0019,
      "step": 85110
    },
    {
      "epoch": 1.8915555555555557,
      "grad_norm": 0.1254539042711258,
      "learning_rate": 2.711111111111111e-06,
      "loss": 0.0016,
      "step": 85120
    },
    {
      "epoch": 1.8917777777777778,
      "grad_norm": 0.3706022799015045,
      "learning_rate": 2.7055555555555556e-06,
      "loss": 0.0018,
      "step": 85130
    },
    {
      "epoch": 1.892,
      "grad_norm": 0.21979176998138428,
      "learning_rate": 2.7e-06,
      "loss": 0.0034,
      "step": 85140
    },
    {
      "epoch": 1.8922222222222222,
      "grad_norm": 0.23246726393699646,
      "learning_rate": 2.6944444444444444e-06,
      "loss": 0.0022,
      "step": 85150
    },
    {
      "epoch": 1.8924444444444446,
      "grad_norm": 0.08198156207799911,
      "learning_rate": 2.6888888888888892e-06,
      "loss": 0.0016,
      "step": 85160
    },
    {
      "epoch": 1.8926666666666667,
      "grad_norm": 0.3990314304828644,
      "learning_rate": 2.6833333333333336e-06,
      "loss": 0.0017,
      "step": 85170
    },
    {
      "epoch": 1.8928888888888888,
      "grad_norm": 0.28797149658203125,
      "learning_rate": 2.677777777777778e-06,
      "loss": 0.002,
      "step": 85180
    },
    {
      "epoch": 1.8931111111111112,
      "grad_norm": 0.3570112884044647,
      "learning_rate": 2.6722222222222224e-06,
      "loss": 0.002,
      "step": 85190
    },
    {
      "epoch": 1.8933333333333333,
      "grad_norm": 0.32870015501976013,
      "learning_rate": 2.666666666666667e-06,
      "loss": 0.0016,
      "step": 85200
    },
    {
      "epoch": 1.8935555555555554,
      "grad_norm": 0.15516698360443115,
      "learning_rate": 2.6611111111111112e-06,
      "loss": 0.0019,
      "step": 85210
    },
    {
      "epoch": 1.8937777777777778,
      "grad_norm": 0.4571673572063446,
      "learning_rate": 2.6555555555555556e-06,
      "loss": 0.0018,
      "step": 85220
    },
    {
      "epoch": 1.8940000000000001,
      "grad_norm": 0.2400917112827301,
      "learning_rate": 2.65e-06,
      "loss": 0.0017,
      "step": 85230
    },
    {
      "epoch": 1.8942222222222223,
      "grad_norm": 0.5206611752510071,
      "learning_rate": 2.6444444444444444e-06,
      "loss": 0.0024,
      "step": 85240
    },
    {
      "epoch": 1.8944444444444444,
      "grad_norm": 0.0949205830693245,
      "learning_rate": 2.638888888888889e-06,
      "loss": 0.0016,
      "step": 85250
    },
    {
      "epoch": 1.8946666666666667,
      "grad_norm": 0.15843746066093445,
      "learning_rate": 2.6333333333333337e-06,
      "loss": 0.0017,
      "step": 85260
    },
    {
      "epoch": 1.8948888888888888,
      "grad_norm": 0.0936039462685585,
      "learning_rate": 2.627777777777778e-06,
      "loss": 0.003,
      "step": 85270
    },
    {
      "epoch": 1.895111111111111,
      "grad_norm": 0.18834316730499268,
      "learning_rate": 2.6222222222222225e-06,
      "loss": 0.0019,
      "step": 85280
    },
    {
      "epoch": 1.8953333333333333,
      "grad_norm": 0.24756945669651031,
      "learning_rate": 2.616666666666667e-06,
      "loss": 0.0019,
      "step": 85290
    },
    {
      "epoch": 1.8955555555555557,
      "grad_norm": 0.26420262455940247,
      "learning_rate": 2.6111111111111113e-06,
      "loss": 0.002,
      "step": 85300
    },
    {
      "epoch": 1.8957777777777778,
      "grad_norm": 0.3472118377685547,
      "learning_rate": 2.6055555555555557e-06,
      "loss": 0.002,
      "step": 85310
    },
    {
      "epoch": 1.896,
      "grad_norm": 0.07796148955821991,
      "learning_rate": 2.6e-06,
      "loss": 0.0018,
      "step": 85320
    },
    {
      "epoch": 1.8962222222222223,
      "grad_norm": 0.1378200799226761,
      "learning_rate": 2.5944444444444445e-06,
      "loss": 0.0019,
      "step": 85330
    },
    {
      "epoch": 1.8964444444444446,
      "grad_norm": 0.29516902565956116,
      "learning_rate": 2.588888888888889e-06,
      "loss": 0.0016,
      "step": 85340
    },
    {
      "epoch": 1.8966666666666665,
      "grad_norm": 0.08928808569908142,
      "learning_rate": 2.5833333333333333e-06,
      "loss": 0.0017,
      "step": 85350
    },
    {
      "epoch": 1.8968888888888888,
      "grad_norm": 0.07779230177402496,
      "learning_rate": 2.5777777777777777e-06,
      "loss": 0.0017,
      "step": 85360
    },
    {
      "epoch": 1.8971111111111112,
      "grad_norm": 0.1909678429365158,
      "learning_rate": 2.5722222222222225e-06,
      "loss": 0.0018,
      "step": 85370
    },
    {
      "epoch": 1.8973333333333333,
      "grad_norm": 0.10672414302825928,
      "learning_rate": 2.566666666666667e-06,
      "loss": 0.0022,
      "step": 85380
    },
    {
      "epoch": 1.8975555555555554,
      "grad_norm": 0.3495160639286041,
      "learning_rate": 2.5611111111111113e-06,
      "loss": 0.0032,
      "step": 85390
    },
    {
      "epoch": 1.8977777777777778,
      "grad_norm": 0.12015384435653687,
      "learning_rate": 2.5555555555555557e-06,
      "loss": 0.0018,
      "step": 85400
    },
    {
      "epoch": 1.8980000000000001,
      "grad_norm": 0.6219395399093628,
      "learning_rate": 2.55e-06,
      "loss": 0.0018,
      "step": 85410
    },
    {
      "epoch": 1.8982222222222223,
      "grad_norm": 0.23553508520126343,
      "learning_rate": 2.5444444444444446e-06,
      "loss": 0.0025,
      "step": 85420
    },
    {
      "epoch": 1.8984444444444444,
      "grad_norm": 0.09896624088287354,
      "learning_rate": 2.538888888888889e-06,
      "loss": 0.0016,
      "step": 85430
    },
    {
      "epoch": 1.8986666666666667,
      "grad_norm": 0.43747952580451965,
      "learning_rate": 2.5333333333333334e-06,
      "loss": 0.0026,
      "step": 85440
    },
    {
      "epoch": 1.8988888888888888,
      "grad_norm": 0.40934187173843384,
      "learning_rate": 2.5277777777777778e-06,
      "loss": 0.0025,
      "step": 85450
    },
    {
      "epoch": 1.899111111111111,
      "grad_norm": 0.05786648765206337,
      "learning_rate": 2.522222222222222e-06,
      "loss": 0.0026,
      "step": 85460
    },
    {
      "epoch": 1.8993333333333333,
      "grad_norm": 0.05680335685610771,
      "learning_rate": 2.516666666666667e-06,
      "loss": 0.0017,
      "step": 85470
    },
    {
      "epoch": 1.8995555555555557,
      "grad_norm": 0.39865899085998535,
      "learning_rate": 2.5111111111111114e-06,
      "loss": 0.0019,
      "step": 85480
    },
    {
      "epoch": 1.8997777777777778,
      "grad_norm": 0.13646332919597626,
      "learning_rate": 2.505555555555556e-06,
      "loss": 0.0017,
      "step": 85490
    },
    {
      "epoch": 1.9,
      "grad_norm": 0.10549865663051605,
      "learning_rate": 2.5e-06,
      "loss": 0.0032,
      "step": 85500
    },
    {
      "epoch": 1.9002222222222223,
      "grad_norm": 0.37279221415519714,
      "learning_rate": 2.4944444444444446e-06,
      "loss": 0.0017,
      "step": 85510
    },
    {
      "epoch": 1.9004444444444446,
      "grad_norm": 0.2066810578107834,
      "learning_rate": 2.488888888888889e-06,
      "loss": 0.0025,
      "step": 85520
    },
    {
      "epoch": 1.9006666666666665,
      "grad_norm": 0.31679874658584595,
      "learning_rate": 2.4833333333333334e-06,
      "loss": 0.0026,
      "step": 85530
    },
    {
      "epoch": 1.9008888888888889,
      "grad_norm": 0.1373225599527359,
      "learning_rate": 2.477777777777778e-06,
      "loss": 0.0018,
      "step": 85540
    },
    {
      "epoch": 1.9011111111111112,
      "grad_norm": 0.3044295907020569,
      "learning_rate": 2.4722222222222222e-06,
      "loss": 0.0019,
      "step": 85550
    },
    {
      "epoch": 1.9013333333333333,
      "grad_norm": 0.26760777831077576,
      "learning_rate": 2.4666666666666666e-06,
      "loss": 0.0019,
      "step": 85560
    },
    {
      "epoch": 1.9015555555555554,
      "grad_norm": 0.41473326086997986,
      "learning_rate": 2.4611111111111115e-06,
      "loss": 0.0018,
      "step": 85570
    },
    {
      "epoch": 1.9017777777777778,
      "grad_norm": 0.15216238796710968,
      "learning_rate": 2.455555555555556e-06,
      "loss": 0.0033,
      "step": 85580
    },
    {
      "epoch": 1.9020000000000001,
      "grad_norm": 0.13451159000396729,
      "learning_rate": 2.4500000000000003e-06,
      "loss": 0.0026,
      "step": 85590
    },
    {
      "epoch": 1.9022222222222223,
      "grad_norm": 0.07877830415964127,
      "learning_rate": 2.4444444444444447e-06,
      "loss": 0.0023,
      "step": 85600
    },
    {
      "epoch": 1.9024444444444444,
      "grad_norm": 0.21105772256851196,
      "learning_rate": 2.438888888888889e-06,
      "loss": 0.0022,
      "step": 85610
    },
    {
      "epoch": 1.9026666666666667,
      "grad_norm": 0.20470848679542542,
      "learning_rate": 2.4333333333333335e-06,
      "loss": 0.0018,
      "step": 85620
    },
    {
      "epoch": 1.9028888888888889,
      "grad_norm": 0.38454943895339966,
      "learning_rate": 2.427777777777778e-06,
      "loss": 0.0017,
      "step": 85630
    },
    {
      "epoch": 1.903111111111111,
      "grad_norm": 0.1656852513551712,
      "learning_rate": 2.4222222222222223e-06,
      "loss": 0.0018,
      "step": 85640
    },
    {
      "epoch": 1.9033333333333333,
      "grad_norm": 0.06448183953762054,
      "learning_rate": 2.4166666666666667e-06,
      "loss": 0.0019,
      "step": 85650
    },
    {
      "epoch": 1.9035555555555557,
      "grad_norm": 0.2559623420238495,
      "learning_rate": 2.411111111111111e-06,
      "loss": 0.0017,
      "step": 85660
    },
    {
      "epoch": 1.9037777777777778,
      "grad_norm": 0.11614477634429932,
      "learning_rate": 2.4055555555555555e-06,
      "loss": 0.0018,
      "step": 85670
    },
    {
      "epoch": 1.904,
      "grad_norm": 0.33035406470298767,
      "learning_rate": 2.4000000000000003e-06,
      "loss": 0.0018,
      "step": 85680
    },
    {
      "epoch": 1.9042222222222223,
      "grad_norm": 0.20261213183403015,
      "learning_rate": 2.3944444444444447e-06,
      "loss": 0.0023,
      "step": 85690
    },
    {
      "epoch": 1.9044444444444446,
      "grad_norm": 0.5237102508544922,
      "learning_rate": 2.388888888888889e-06,
      "loss": 0.0023,
      "step": 85700
    },
    {
      "epoch": 1.9046666666666665,
      "grad_norm": 0.1257466971874237,
      "learning_rate": 2.3833333333333335e-06,
      "loss": 0.0016,
      "step": 85710
    },
    {
      "epoch": 1.9048888888888889,
      "grad_norm": 0.06616760790348053,
      "learning_rate": 2.377777777777778e-06,
      "loss": 0.0028,
      "step": 85720
    },
    {
      "epoch": 1.9051111111111112,
      "grad_norm": 0.5205033421516418,
      "learning_rate": 2.3722222222222223e-06,
      "loss": 0.0018,
      "step": 85730
    },
    {
      "epoch": 1.9053333333333333,
      "grad_norm": 0.11207469552755356,
      "learning_rate": 2.3666666666666667e-06,
      "loss": 0.0027,
      "step": 85740
    },
    {
      "epoch": 1.9055555555555554,
      "grad_norm": 0.32286643981933594,
      "learning_rate": 2.361111111111111e-06,
      "loss": 0.0017,
      "step": 85750
    },
    {
      "epoch": 1.9057777777777778,
      "grad_norm": 0.16810722649097443,
      "learning_rate": 2.3555555555555555e-06,
      "loss": 0.002,
      "step": 85760
    },
    {
      "epoch": 1.9060000000000001,
      "grad_norm": 0.25527751445770264,
      "learning_rate": 2.35e-06,
      "loss": 0.0019,
      "step": 85770
    },
    {
      "epoch": 1.9062222222222223,
      "grad_norm": 0.42492470145225525,
      "learning_rate": 2.3444444444444448e-06,
      "loss": 0.0021,
      "step": 85780
    },
    {
      "epoch": 1.9064444444444444,
      "grad_norm": 0.2248179018497467,
      "learning_rate": 2.338888888888889e-06,
      "loss": 0.0018,
      "step": 85790
    },
    {
      "epoch": 1.9066666666666667,
      "grad_norm": 0.3215036690235138,
      "learning_rate": 2.3333333333333336e-06,
      "loss": 0.0017,
      "step": 85800
    },
    {
      "epoch": 1.9068888888888889,
      "grad_norm": 0.45759549736976624,
      "learning_rate": 2.327777777777778e-06,
      "loss": 0.0033,
      "step": 85810
    },
    {
      "epoch": 1.907111111111111,
      "grad_norm": 0.19069594144821167,
      "learning_rate": 2.322222222222222e-06,
      "loss": 0.0017,
      "step": 85820
    },
    {
      "epoch": 1.9073333333333333,
      "grad_norm": 0.39361071586608887,
      "learning_rate": 2.316666666666667e-06,
      "loss": 0.0019,
      "step": 85830
    },
    {
      "epoch": 1.9075555555555557,
      "grad_norm": 0.35829198360443115,
      "learning_rate": 2.311111111111111e-06,
      "loss": 0.0031,
      "step": 85840
    },
    {
      "epoch": 1.9077777777777778,
      "grad_norm": 0.08396229147911072,
      "learning_rate": 2.3055555555555556e-06,
      "loss": 0.0018,
      "step": 85850
    },
    {
      "epoch": 1.908,
      "grad_norm": 0.08082065731287003,
      "learning_rate": 2.3e-06,
      "loss": 0.0021,
      "step": 85860
    },
    {
      "epoch": 1.9082222222222223,
      "grad_norm": 0.12540872395038605,
      "learning_rate": 2.2944444444444444e-06,
      "loss": 0.0033,
      "step": 85870
    },
    {
      "epoch": 1.9084444444444446,
      "grad_norm": 0.3708328306674957,
      "learning_rate": 2.2888888888888892e-06,
      "loss": 0.0021,
      "step": 85880
    },
    {
      "epoch": 1.9086666666666665,
      "grad_norm": 0.11262793093919754,
      "learning_rate": 2.2833333333333336e-06,
      "loss": 0.0027,
      "step": 85890
    },
    {
      "epoch": 1.9088888888888889,
      "grad_norm": 0.07340479642152786,
      "learning_rate": 2.277777777777778e-06,
      "loss": 0.0026,
      "step": 85900
    },
    {
      "epoch": 1.9091111111111112,
      "grad_norm": 0.09487545490264893,
      "learning_rate": 2.2722222222222224e-06,
      "loss": 0.0034,
      "step": 85910
    },
    {
      "epoch": 1.9093333333333333,
      "grad_norm": 0.47039514780044556,
      "learning_rate": 2.266666666666667e-06,
      "loss": 0.0019,
      "step": 85920
    },
    {
      "epoch": 1.9095555555555555,
      "grad_norm": 0.0892917588353157,
      "learning_rate": 2.2611111111111112e-06,
      "loss": 0.0024,
      "step": 85930
    },
    {
      "epoch": 1.9097777777777778,
      "grad_norm": 0.22064480185508728,
      "learning_rate": 2.2555555555555557e-06,
      "loss": 0.0031,
      "step": 85940
    },
    {
      "epoch": 1.9100000000000001,
      "grad_norm": 0.7305915355682373,
      "learning_rate": 2.25e-06,
      "loss": 0.0018,
      "step": 85950
    },
    {
      "epoch": 1.9102222222222223,
      "grad_norm": 0.39615386724472046,
      "learning_rate": 2.2444444444444445e-06,
      "loss": 0.002,
      "step": 85960
    },
    {
      "epoch": 1.9104444444444444,
      "grad_norm": 0.0861867219209671,
      "learning_rate": 2.238888888888889e-06,
      "loss": 0.0018,
      "step": 85970
    },
    {
      "epoch": 1.9106666666666667,
      "grad_norm": 0.325809121131897,
      "learning_rate": 2.2333333333333333e-06,
      "loss": 0.0018,
      "step": 85980
    },
    {
      "epoch": 1.9108888888888889,
      "grad_norm": 0.17255248129367828,
      "learning_rate": 2.227777777777778e-06,
      "loss": 0.0023,
      "step": 85990
    },
    {
      "epoch": 1.911111111111111,
      "grad_norm": 0.2047913819551468,
      "learning_rate": 2.2222222222222225e-06,
      "loss": 0.0017,
      "step": 86000
    },
    {
      "epoch": 1.9113333333333333,
      "grad_norm": 0.383163183927536,
      "learning_rate": 2.216666666666667e-06,
      "loss": 0.0021,
      "step": 86010
    },
    {
      "epoch": 1.9115555555555557,
      "grad_norm": 0.45653781294822693,
      "learning_rate": 2.2111111111111113e-06,
      "loss": 0.0026,
      "step": 86020
    },
    {
      "epoch": 1.9117777777777778,
      "grad_norm": 0.11145446449518204,
      "learning_rate": 2.2055555555555557e-06,
      "loss": 0.0026,
      "step": 86030
    },
    {
      "epoch": 1.912,
      "grad_norm": 0.07510745525360107,
      "learning_rate": 2.2e-06,
      "loss": 0.0025,
      "step": 86040
    },
    {
      "epoch": 1.9122222222222223,
      "grad_norm": 0.07752469182014465,
      "learning_rate": 2.1944444444444445e-06,
      "loss": 0.0029,
      "step": 86050
    },
    {
      "epoch": 1.9124444444444444,
      "grad_norm": 0.12842781841754913,
      "learning_rate": 2.188888888888889e-06,
      "loss": 0.0019,
      "step": 86060
    },
    {
      "epoch": 1.9126666666666665,
      "grad_norm": 0.10611426085233688,
      "learning_rate": 2.1833333333333333e-06,
      "loss": 0.0021,
      "step": 86070
    },
    {
      "epoch": 1.9128888888888889,
      "grad_norm": 0.258751779794693,
      "learning_rate": 2.1777777777777777e-06,
      "loss": 0.0018,
      "step": 86080
    },
    {
      "epoch": 1.9131111111111112,
      "grad_norm": 0.4270991384983063,
      "learning_rate": 2.1722222222222226e-06,
      "loss": 0.0016,
      "step": 86090
    },
    {
      "epoch": 1.9133333333333333,
      "grad_norm": 0.06956755369901657,
      "learning_rate": 2.166666666666667e-06,
      "loss": 0.0031,
      "step": 86100
    },
    {
      "epoch": 1.9135555555555555,
      "grad_norm": 0.19140639901161194,
      "learning_rate": 2.1611111111111114e-06,
      "loss": 0.0034,
      "step": 86110
    },
    {
      "epoch": 1.9137777777777778,
      "grad_norm": 0.2195845991373062,
      "learning_rate": 2.1555555555555558e-06,
      "loss": 0.0018,
      "step": 86120
    },
    {
      "epoch": 1.9140000000000001,
      "grad_norm": 0.2310144454240799,
      "learning_rate": 2.1499999999999997e-06,
      "loss": 0.0017,
      "step": 86130
    },
    {
      "epoch": 1.9142222222222223,
      "grad_norm": 0.27674561738967896,
      "learning_rate": 2.1444444444444446e-06,
      "loss": 0.0021,
      "step": 86140
    },
    {
      "epoch": 1.9144444444444444,
      "grad_norm": 0.47623181343078613,
      "learning_rate": 2.138888888888889e-06,
      "loss": 0.0017,
      "step": 86150
    },
    {
      "epoch": 1.9146666666666667,
      "grad_norm": 0.24732442200183868,
      "learning_rate": 2.1333333333333334e-06,
      "loss": 0.0024,
      "step": 86160
    },
    {
      "epoch": 1.9148888888888889,
      "grad_norm": 0.08566869795322418,
      "learning_rate": 2.1277777777777778e-06,
      "loss": 0.0025,
      "step": 86170
    },
    {
      "epoch": 1.915111111111111,
      "grad_norm": 0.34272870421409607,
      "learning_rate": 2.122222222222222e-06,
      "loss": 0.0021,
      "step": 86180
    },
    {
      "epoch": 1.9153333333333333,
      "grad_norm": 0.6047815680503845,
      "learning_rate": 2.1166666666666666e-06,
      "loss": 0.0018,
      "step": 86190
    },
    {
      "epoch": 1.9155555555555557,
      "grad_norm": 0.3411351442337036,
      "learning_rate": 2.1111111111111114e-06,
      "loss": 0.0029,
      "step": 86200
    },
    {
      "epoch": 1.9157777777777778,
      "grad_norm": 0.10102185606956482,
      "learning_rate": 2.105555555555556e-06,
      "loss": 0.0022,
      "step": 86210
    },
    {
      "epoch": 1.916,
      "grad_norm": 0.19429358839988708,
      "learning_rate": 2.1000000000000002e-06,
      "loss": 0.0021,
      "step": 86220
    },
    {
      "epoch": 1.9162222222222223,
      "grad_norm": 0.21682152152061462,
      "learning_rate": 2.0944444444444446e-06,
      "loss": 0.0018,
      "step": 86230
    },
    {
      "epoch": 1.9164444444444444,
      "grad_norm": 0.12671726942062378,
      "learning_rate": 2.088888888888889e-06,
      "loss": 0.0021,
      "step": 86240
    },
    {
      "epoch": 1.9166666666666665,
      "grad_norm": 0.07847858965396881,
      "learning_rate": 2.0833333333333334e-06,
      "loss": 0.0034,
      "step": 86250
    },
    {
      "epoch": 1.9168888888888889,
      "grad_norm": 0.36740872263908386,
      "learning_rate": 2.077777777777778e-06,
      "loss": 0.0016,
      "step": 86260
    },
    {
      "epoch": 1.9171111111111112,
      "grad_norm": 0.11134526133537292,
      "learning_rate": 2.0722222222222222e-06,
      "loss": 0.0017,
      "step": 86270
    },
    {
      "epoch": 1.9173333333333333,
      "grad_norm": 0.06626474857330322,
      "learning_rate": 2.0666666666666666e-06,
      "loss": 0.0034,
      "step": 86280
    },
    {
      "epoch": 1.9175555555555555,
      "grad_norm": 0.24214251339435577,
      "learning_rate": 2.061111111111111e-06,
      "loss": 0.0018,
      "step": 86290
    },
    {
      "epoch": 1.9177777777777778,
      "grad_norm": 0.36170271039009094,
      "learning_rate": 2.055555555555556e-06,
      "loss": 0.0018,
      "step": 86300
    },
    {
      "epoch": 1.9180000000000001,
      "grad_norm": 0.45056965947151184,
      "learning_rate": 2.0500000000000003e-06,
      "loss": 0.0019,
      "step": 86310
    },
    {
      "epoch": 1.9182222222222223,
      "grad_norm": 0.17217949032783508,
      "learning_rate": 2.0444444444444447e-06,
      "loss": 0.0027,
      "step": 86320
    },
    {
      "epoch": 1.9184444444444444,
      "grad_norm": 0.3033716678619385,
      "learning_rate": 2.038888888888889e-06,
      "loss": 0.0023,
      "step": 86330
    },
    {
      "epoch": 1.9186666666666667,
      "grad_norm": 0.6629330515861511,
      "learning_rate": 2.033333333333333e-06,
      "loss": 0.0018,
      "step": 86340
    },
    {
      "epoch": 1.9188888888888889,
      "grad_norm": 0.4694986641407013,
      "learning_rate": 2.027777777777778e-06,
      "loss": 0.0019,
      "step": 86350
    },
    {
      "epoch": 1.919111111111111,
      "grad_norm": 0.3663272261619568,
      "learning_rate": 2.0222222222222223e-06,
      "loss": 0.0027,
      "step": 86360
    },
    {
      "epoch": 1.9193333333333333,
      "grad_norm": 0.4408629238605499,
      "learning_rate": 2.0166666666666667e-06,
      "loss": 0.0016,
      "step": 86370
    },
    {
      "epoch": 1.9195555555555557,
      "grad_norm": 0.16769371926784515,
      "learning_rate": 2.011111111111111e-06,
      "loss": 0.0017,
      "step": 86380
    },
    {
      "epoch": 1.9197777777777778,
      "grad_norm": 0.1535031646490097,
      "learning_rate": 2.0055555555555555e-06,
      "loss": 0.0017,
      "step": 86390
    },
    {
      "epoch": 1.92,
      "grad_norm": 0.07383561134338379,
      "learning_rate": 2.0000000000000003e-06,
      "loss": 0.0019,
      "step": 86400
    },
    {
      "epoch": 1.9202222222222223,
      "grad_norm": 0.20947112143039703,
      "learning_rate": 1.9944444444444447e-06,
      "loss": 0.0019,
      "step": 86410
    },
    {
      "epoch": 1.9204444444444444,
      "grad_norm": 0.13943172991275787,
      "learning_rate": 1.988888888888889e-06,
      "loss": 0.0021,
      "step": 86420
    },
    {
      "epoch": 1.9206666666666665,
      "grad_norm": 0.18710190057754517,
      "learning_rate": 1.9833333333333335e-06,
      "loss": 0.0021,
      "step": 86430
    },
    {
      "epoch": 1.9208888888888889,
      "grad_norm": 0.319364994764328,
      "learning_rate": 1.9777777777777775e-06,
      "loss": 0.0017,
      "step": 86440
    },
    {
      "epoch": 1.9211111111111112,
      "grad_norm": 0.09331269562244415,
      "learning_rate": 1.9722222222222224e-06,
      "loss": 0.0025,
      "step": 86450
    },
    {
      "epoch": 1.9213333333333333,
      "grad_norm": 0.3694522976875305,
      "learning_rate": 1.9666666666666668e-06,
      "loss": 0.0019,
      "step": 86460
    },
    {
      "epoch": 1.9215555555555555,
      "grad_norm": 0.16343192756175995,
      "learning_rate": 1.961111111111111e-06,
      "loss": 0.0018,
      "step": 86470
    },
    {
      "epoch": 1.9217777777777778,
      "grad_norm": 0.28082719445228577,
      "learning_rate": 1.9555555555555556e-06,
      "loss": 0.0024,
      "step": 86480
    },
    {
      "epoch": 1.9220000000000002,
      "grad_norm": 0.1192089170217514,
      "learning_rate": 1.95e-06,
      "loss": 0.0024,
      "step": 86490
    },
    {
      "epoch": 1.9222222222222223,
      "grad_norm": 0.07446792721748352,
      "learning_rate": 1.9444444444444444e-06,
      "loss": 0.0019,
      "step": 86500
    },
    {
      "epoch": 1.9224444444444444,
      "grad_norm": 0.13409261405467987,
      "learning_rate": 1.938888888888889e-06,
      "loss": 0.0021,
      "step": 86510
    },
    {
      "epoch": 1.9226666666666667,
      "grad_norm": 0.14773356914520264,
      "learning_rate": 1.9333333333333336e-06,
      "loss": 0.0017,
      "step": 86520
    },
    {
      "epoch": 1.9228888888888889,
      "grad_norm": 0.07596474140882492,
      "learning_rate": 1.927777777777778e-06,
      "loss": 0.0018,
      "step": 86530
    },
    {
      "epoch": 1.923111111111111,
      "grad_norm": 0.28591322898864746,
      "learning_rate": 1.9222222222222224e-06,
      "loss": 0.0017,
      "step": 86540
    },
    {
      "epoch": 1.9233333333333333,
      "grad_norm": 0.18055520951747894,
      "learning_rate": 1.916666666666667e-06,
      "loss": 0.0018,
      "step": 86550
    },
    {
      "epoch": 1.9235555555555557,
      "grad_norm": 0.09242966026067734,
      "learning_rate": 1.9111111111111112e-06,
      "loss": 0.0033,
      "step": 86560
    },
    {
      "epoch": 1.9237777777777778,
      "grad_norm": 0.18588456511497498,
      "learning_rate": 1.9055555555555556e-06,
      "loss": 0.0017,
      "step": 86570
    },
    {
      "epoch": 1.924,
      "grad_norm": 0.28420278429985046,
      "learning_rate": 1.9e-06,
      "loss": 0.0025,
      "step": 86580
    },
    {
      "epoch": 1.9242222222222223,
      "grad_norm": 0.10600415617227554,
      "learning_rate": 1.8944444444444444e-06,
      "loss": 0.0025,
      "step": 86590
    },
    {
      "epoch": 1.9244444444444444,
      "grad_norm": 0.1693250834941864,
      "learning_rate": 1.888888888888889e-06,
      "loss": 0.0016,
      "step": 86600
    },
    {
      "epoch": 1.9246666666666665,
      "grad_norm": 0.08421970158815384,
      "learning_rate": 1.8833333333333334e-06,
      "loss": 0.0016,
      "step": 86610
    },
    {
      "epoch": 1.9248888888888889,
      "grad_norm": 0.23008441925048828,
      "learning_rate": 1.877777777777778e-06,
      "loss": 0.0019,
      "step": 86620
    },
    {
      "epoch": 1.9251111111111112,
      "grad_norm": 0.2208978533744812,
      "learning_rate": 1.8722222222222225e-06,
      "loss": 0.0019,
      "step": 86630
    },
    {
      "epoch": 1.9253333333333333,
      "grad_norm": 0.09107670933008194,
      "learning_rate": 1.8666666666666669e-06,
      "loss": 0.0019,
      "step": 86640
    },
    {
      "epoch": 1.9255555555555555,
      "grad_norm": 0.10914555191993713,
      "learning_rate": 1.861111111111111e-06,
      "loss": 0.0036,
      "step": 86650
    },
    {
      "epoch": 1.9257777777777778,
      "grad_norm": 0.33556535840034485,
      "learning_rate": 1.8555555555555555e-06,
      "loss": 0.002,
      "step": 86660
    },
    {
      "epoch": 1.9260000000000002,
      "grad_norm": 0.07502005249261856,
      "learning_rate": 1.85e-06,
      "loss": 0.0018,
      "step": 86670
    },
    {
      "epoch": 1.926222222222222,
      "grad_norm": 0.30230453610420227,
      "learning_rate": 1.8444444444444445e-06,
      "loss": 0.0017,
      "step": 86680
    },
    {
      "epoch": 1.9264444444444444,
      "grad_norm": 0.15108990669250488,
      "learning_rate": 1.8388888888888889e-06,
      "loss": 0.0018,
      "step": 86690
    },
    {
      "epoch": 1.9266666666666667,
      "grad_norm": 0.49505236744880676,
      "learning_rate": 1.8333333333333335e-06,
      "loss": 0.0018,
      "step": 86700
    },
    {
      "epoch": 1.9268888888888889,
      "grad_norm": 0.6194310188293457,
      "learning_rate": 1.827777777777778e-06,
      "loss": 0.0021,
      "step": 86710
    },
    {
      "epoch": 1.927111111111111,
      "grad_norm": 0.25890684127807617,
      "learning_rate": 1.8222222222222223e-06,
      "loss": 0.0017,
      "step": 86720
    },
    {
      "epoch": 1.9273333333333333,
      "grad_norm": 0.2406426966190338,
      "learning_rate": 1.816666666666667e-06,
      "loss": 0.0019,
      "step": 86730
    },
    {
      "epoch": 1.9275555555555557,
      "grad_norm": 0.39976438879966736,
      "learning_rate": 1.8111111111111113e-06,
      "loss": 0.0018,
      "step": 86740
    },
    {
      "epoch": 1.9277777777777778,
      "grad_norm": 0.45180901885032654,
      "learning_rate": 1.8055555555555555e-06,
      "loss": 0.0018,
      "step": 86750
    },
    {
      "epoch": 1.928,
      "grad_norm": 0.285129576921463,
      "learning_rate": 1.8e-06,
      "loss": 0.002,
      "step": 86760
    },
    {
      "epoch": 1.9282222222222223,
      "grad_norm": 0.11892714351415634,
      "learning_rate": 1.7944444444444445e-06,
      "loss": 0.0018,
      "step": 86770
    },
    {
      "epoch": 1.9284444444444444,
      "grad_norm": 0.2966171205043793,
      "learning_rate": 1.788888888888889e-06,
      "loss": 0.0018,
      "step": 86780
    },
    {
      "epoch": 1.9286666666666665,
      "grad_norm": 0.3154482841491699,
      "learning_rate": 1.7833333333333333e-06,
      "loss": 0.0017,
      "step": 86790
    },
    {
      "epoch": 1.9288888888888889,
      "grad_norm": 0.25220048427581787,
      "learning_rate": 1.777777777777778e-06,
      "loss": 0.0018,
      "step": 86800
    },
    {
      "epoch": 1.9291111111111112,
      "grad_norm": 0.38099294900894165,
      "learning_rate": 1.7722222222222224e-06,
      "loss": 0.0017,
      "step": 86810
    },
    {
      "epoch": 1.9293333333333333,
      "grad_norm": 0.2198566496372223,
      "learning_rate": 1.7666666666666668e-06,
      "loss": 0.0025,
      "step": 86820
    },
    {
      "epoch": 1.9295555555555555,
      "grad_norm": 0.10914799571037292,
      "learning_rate": 1.7611111111111114e-06,
      "loss": 0.0028,
      "step": 86830
    },
    {
      "epoch": 1.9297777777777778,
      "grad_norm": 0.07879512757062912,
      "learning_rate": 1.7555555555555558e-06,
      "loss": 0.0018,
      "step": 86840
    },
    {
      "epoch": 1.9300000000000002,
      "grad_norm": 0.34113383293151855,
      "learning_rate": 1.7500000000000002e-06,
      "loss": 0.0022,
      "step": 86850
    },
    {
      "epoch": 1.930222222222222,
      "grad_norm": 0.08229665458202362,
      "learning_rate": 1.7444444444444444e-06,
      "loss": 0.0019,
      "step": 86860
    },
    {
      "epoch": 1.9304444444444444,
      "grad_norm": 0.20706391334533691,
      "learning_rate": 1.7388888888888888e-06,
      "loss": 0.0018,
      "step": 86870
    },
    {
      "epoch": 1.9306666666666668,
      "grad_norm": 0.18094120919704437,
      "learning_rate": 1.7333333333333334e-06,
      "loss": 0.003,
      "step": 86880
    },
    {
      "epoch": 1.9308888888888889,
      "grad_norm": 0.24563387036323547,
      "learning_rate": 1.7277777777777778e-06,
      "loss": 0.0019,
      "step": 86890
    },
    {
      "epoch": 1.931111111111111,
      "grad_norm": 0.14205078780651093,
      "learning_rate": 1.7222222222222222e-06,
      "loss": 0.0024,
      "step": 86900
    },
    {
      "epoch": 1.9313333333333333,
      "grad_norm": 0.3692902624607086,
      "learning_rate": 1.7166666666666668e-06,
      "loss": 0.0025,
      "step": 86910
    },
    {
      "epoch": 1.9315555555555557,
      "grad_norm": 0.2975904941558838,
      "learning_rate": 1.7111111111111112e-06,
      "loss": 0.0026,
      "step": 86920
    },
    {
      "epoch": 1.9317777777777778,
      "grad_norm": 0.07687509059906006,
      "learning_rate": 1.7055555555555556e-06,
      "loss": 0.002,
      "step": 86930
    },
    {
      "epoch": 1.932,
      "grad_norm": 0.14688538014888763,
      "learning_rate": 1.7000000000000002e-06,
      "loss": 0.0018,
      "step": 86940
    },
    {
      "epoch": 1.9322222222222223,
      "grad_norm": 0.19826188683509827,
      "learning_rate": 1.6944444444444446e-06,
      "loss": 0.0017,
      "step": 86950
    },
    {
      "epoch": 1.9324444444444444,
      "grad_norm": 0.09767315536737442,
      "learning_rate": 1.6888888888888888e-06,
      "loss": 0.002,
      "step": 86960
    },
    {
      "epoch": 1.9326666666666665,
      "grad_norm": 0.1972580850124359,
      "learning_rate": 1.6833333333333332e-06,
      "loss": 0.0019,
      "step": 86970
    },
    {
      "epoch": 1.9328888888888889,
      "grad_norm": 0.3264518976211548,
      "learning_rate": 1.6777777777777779e-06,
      "loss": 0.002,
      "step": 86980
    },
    {
      "epoch": 1.9331111111111112,
      "grad_norm": 0.2665093243122101,
      "learning_rate": 1.6722222222222223e-06,
      "loss": 0.0018,
      "step": 86990
    },
    {
      "epoch": 1.9333333333333333,
      "grad_norm": 0.2577989399433136,
      "learning_rate": 1.6666666666666667e-06,
      "loss": 0.0026,
      "step": 87000
    },
    {
      "epoch": 1.9335555555555555,
      "grad_norm": 0.09167665243148804,
      "learning_rate": 1.6611111111111113e-06,
      "loss": 0.0034,
      "step": 87010
    },
    {
      "epoch": 1.9337777777777778,
      "grad_norm": 0.13277123868465424,
      "learning_rate": 1.6555555555555557e-06,
      "loss": 0.003,
      "step": 87020
    },
    {
      "epoch": 1.9340000000000002,
      "grad_norm": 0.39904946088790894,
      "learning_rate": 1.65e-06,
      "loss": 0.0029,
      "step": 87030
    },
    {
      "epoch": 1.934222222222222,
      "grad_norm": 0.2601345479488373,
      "learning_rate": 1.6444444444444447e-06,
      "loss": 0.0016,
      "step": 87040
    },
    {
      "epoch": 1.9344444444444444,
      "grad_norm": 0.22323982417583466,
      "learning_rate": 1.638888888888889e-06,
      "loss": 0.0019,
      "step": 87050
    },
    {
      "epoch": 1.9346666666666668,
      "grad_norm": 0.23154304921627045,
      "learning_rate": 1.6333333333333333e-06,
      "loss": 0.0016,
      "step": 87060
    },
    {
      "epoch": 1.9348888888888889,
      "grad_norm": 0.2259400188922882,
      "learning_rate": 1.6277777777777777e-06,
      "loss": 0.0018,
      "step": 87070
    },
    {
      "epoch": 1.935111111111111,
      "grad_norm": 0.30519387125968933,
      "learning_rate": 1.622222222222222e-06,
      "loss": 0.0022,
      "step": 87080
    },
    {
      "epoch": 1.9353333333333333,
      "grad_norm": 0.278194397687912,
      "learning_rate": 1.6166666666666667e-06,
      "loss": 0.0017,
      "step": 87090
    },
    {
      "epoch": 1.9355555555555557,
      "grad_norm": 0.2460378110408783,
      "learning_rate": 1.6111111111111111e-06,
      "loss": 0.0024,
      "step": 87100
    },
    {
      "epoch": 1.9357777777777778,
      "grad_norm": 0.23157097399234772,
      "learning_rate": 1.6055555555555557e-06,
      "loss": 0.0019,
      "step": 87110
    },
    {
      "epoch": 1.936,
      "grad_norm": 0.19534966349601746,
      "learning_rate": 1.6000000000000001e-06,
      "loss": 0.0018,
      "step": 87120
    },
    {
      "epoch": 1.9362222222222223,
      "grad_norm": 0.2070690393447876,
      "learning_rate": 1.5944444444444445e-06,
      "loss": 0.0027,
      "step": 87130
    },
    {
      "epoch": 1.9364444444444444,
      "grad_norm": 0.37172552943229675,
      "learning_rate": 1.5888888888888892e-06,
      "loss": 0.0018,
      "step": 87140
    },
    {
      "epoch": 1.9366666666666665,
      "grad_norm": 0.09133356064558029,
      "learning_rate": 1.5833333333333336e-06,
      "loss": 0.0017,
      "step": 87150
    },
    {
      "epoch": 1.9368888888888889,
      "grad_norm": 0.18582160770893097,
      "learning_rate": 1.577777777777778e-06,
      "loss": 0.0017,
      "step": 87160
    },
    {
      "epoch": 1.9371111111111112,
      "grad_norm": 0.08955105394124985,
      "learning_rate": 1.5722222222222222e-06,
      "loss": 0.0027,
      "step": 87170
    },
    {
      "epoch": 1.9373333333333334,
      "grad_norm": 0.34598833322525024,
      "learning_rate": 1.5666666666666666e-06,
      "loss": 0.0027,
      "step": 87180
    },
    {
      "epoch": 1.9375555555555555,
      "grad_norm": 0.14783251285552979,
      "learning_rate": 1.5611111111111112e-06,
      "loss": 0.0017,
      "step": 87190
    },
    {
      "epoch": 1.9377777777777778,
      "grad_norm": 0.18924885988235474,
      "learning_rate": 1.5555555555555556e-06,
      "loss": 0.0015,
      "step": 87200
    },
    {
      "epoch": 1.938,
      "grad_norm": 0.10365590453147888,
      "learning_rate": 1.55e-06,
      "loss": 0.0026,
      "step": 87210
    },
    {
      "epoch": 1.938222222222222,
      "grad_norm": 0.17710770666599274,
      "learning_rate": 1.5444444444444446e-06,
      "loss": 0.0024,
      "step": 87220
    },
    {
      "epoch": 1.9384444444444444,
      "grad_norm": 0.13773366808891296,
      "learning_rate": 1.538888888888889e-06,
      "loss": 0.002,
      "step": 87230
    },
    {
      "epoch": 1.9386666666666668,
      "grad_norm": 0.15148207545280457,
      "learning_rate": 1.5333333333333334e-06,
      "loss": 0.0025,
      "step": 87240
    },
    {
      "epoch": 1.9388888888888889,
      "grad_norm": 0.5895885825157166,
      "learning_rate": 1.5277777777777778e-06,
      "loss": 0.0017,
      "step": 87250
    },
    {
      "epoch": 1.939111111111111,
      "grad_norm": 0.5951807498931885,
      "learning_rate": 1.5222222222222222e-06,
      "loss": 0.0017,
      "step": 87260
    },
    {
      "epoch": 1.9393333333333334,
      "grad_norm": 0.4513607919216156,
      "learning_rate": 1.5166666666666668e-06,
      "loss": 0.0019,
      "step": 87270
    },
    {
      "epoch": 1.9395555555555557,
      "grad_norm": 0.11704115569591522,
      "learning_rate": 1.5111111111111112e-06,
      "loss": 0.0039,
      "step": 87280
    },
    {
      "epoch": 1.9397777777777778,
      "grad_norm": 0.24547286331653595,
      "learning_rate": 1.5055555555555556e-06,
      "loss": 0.0019,
      "step": 87290
    },
    {
      "epoch": 1.94,
      "grad_norm": 0.3289671540260315,
      "learning_rate": 1.5e-06,
      "loss": 0.002,
      "step": 87300
    },
    {
      "epoch": 1.9402222222222223,
      "grad_norm": 0.08638036996126175,
      "learning_rate": 1.4944444444444444e-06,
      "loss": 0.0018,
      "step": 87310
    },
    {
      "epoch": 1.9404444444444444,
      "grad_norm": 0.11644122749567032,
      "learning_rate": 1.488888888888889e-06,
      "loss": 0.0016,
      "step": 87320
    },
    {
      "epoch": 1.9406666666666665,
      "grad_norm": 0.3324028551578522,
      "learning_rate": 1.4833333333333335e-06,
      "loss": 0.0023,
      "step": 87330
    },
    {
      "epoch": 1.9408888888888889,
      "grad_norm": 0.12027119845151901,
      "learning_rate": 1.4777777777777779e-06,
      "loss": 0.0019,
      "step": 87340
    },
    {
      "epoch": 1.9411111111111112,
      "grad_norm": 0.2725573182106018,
      "learning_rate": 1.4722222222222223e-06,
      "loss": 0.0018,
      "step": 87350
    },
    {
      "epoch": 1.9413333333333334,
      "grad_norm": 0.23045691847801208,
      "learning_rate": 1.4666666666666667e-06,
      "loss": 0.0018,
      "step": 87360
    },
    {
      "epoch": 1.9415555555555555,
      "grad_norm": 0.21797066926956177,
      "learning_rate": 1.4611111111111113e-06,
      "loss": 0.0017,
      "step": 87370
    },
    {
      "epoch": 1.9417777777777778,
      "grad_norm": 0.3264060616493225,
      "learning_rate": 1.4555555555555557e-06,
      "loss": 0.0018,
      "step": 87380
    },
    {
      "epoch": 1.942,
      "grad_norm": 0.30113327503204346,
      "learning_rate": 1.45e-06,
      "loss": 0.0022,
      "step": 87390
    },
    {
      "epoch": 1.942222222222222,
      "grad_norm": 0.09777116030454636,
      "learning_rate": 1.4444444444444445e-06,
      "loss": 0.0019,
      "step": 87400
    },
    {
      "epoch": 1.9424444444444444,
      "grad_norm": 0.6177881956100464,
      "learning_rate": 1.438888888888889e-06,
      "loss": 0.0021,
      "step": 87410
    },
    {
      "epoch": 1.9426666666666668,
      "grad_norm": 0.32790741324424744,
      "learning_rate": 1.4333333333333333e-06,
      "loss": 0.0019,
      "step": 87420
    },
    {
      "epoch": 1.9428888888888889,
      "grad_norm": 0.29626062512397766,
      "learning_rate": 1.427777777777778e-06,
      "loss": 0.0016,
      "step": 87430
    },
    {
      "epoch": 1.943111111111111,
      "grad_norm": 0.17353561520576477,
      "learning_rate": 1.4222222222222223e-06,
      "loss": 0.0028,
      "step": 87440
    },
    {
      "epoch": 1.9433333333333334,
      "grad_norm": 0.16221700608730316,
      "learning_rate": 1.4166666666666667e-06,
      "loss": 0.0022,
      "step": 87450
    },
    {
      "epoch": 1.9435555555555557,
      "grad_norm": 0.0810185968875885,
      "learning_rate": 1.4111111111111111e-06,
      "loss": 0.0026,
      "step": 87460
    },
    {
      "epoch": 1.9437777777777778,
      "grad_norm": 0.24717170000076294,
      "learning_rate": 1.4055555555555555e-06,
      "loss": 0.0018,
      "step": 87470
    },
    {
      "epoch": 1.944,
      "grad_norm": 0.3296644985675812,
      "learning_rate": 1.4000000000000001e-06,
      "loss": 0.002,
      "step": 87480
    },
    {
      "epoch": 1.9442222222222223,
      "grad_norm": 0.08085855841636658,
      "learning_rate": 1.3944444444444446e-06,
      "loss": 0.0023,
      "step": 87490
    },
    {
      "epoch": 1.9444444444444444,
      "grad_norm": 0.20583710074424744,
      "learning_rate": 1.388888888888889e-06,
      "loss": 0.0023,
      "step": 87500
    },
    {
      "epoch": 1.9446666666666665,
      "grad_norm": 0.11980298906564713,
      "learning_rate": 1.3833333333333334e-06,
      "loss": 0.0019,
      "step": 87510
    },
    {
      "epoch": 1.944888888888889,
      "grad_norm": 0.12836772203445435,
      "learning_rate": 1.3777777777777778e-06,
      "loss": 0.0019,
      "step": 87520
    },
    {
      "epoch": 1.9451111111111112,
      "grad_norm": 0.3172553777694702,
      "learning_rate": 1.3722222222222224e-06,
      "loss": 0.002,
      "step": 87530
    },
    {
      "epoch": 1.9453333333333334,
      "grad_norm": 0.10154622793197632,
      "learning_rate": 1.3666666666666668e-06,
      "loss": 0.0019,
      "step": 87540
    },
    {
      "epoch": 1.9455555555555555,
      "grad_norm": 0.1102803498506546,
      "learning_rate": 1.3611111111111112e-06,
      "loss": 0.0029,
      "step": 87550
    },
    {
      "epoch": 1.9457777777777778,
      "grad_norm": 0.2972280979156494,
      "learning_rate": 1.3555555555555556e-06,
      "loss": 0.0029,
      "step": 87560
    },
    {
      "epoch": 1.946,
      "grad_norm": 0.17196278274059296,
      "learning_rate": 1.35e-06,
      "loss": 0.0019,
      "step": 87570
    },
    {
      "epoch": 1.946222222222222,
      "grad_norm": 0.11787252873182297,
      "learning_rate": 1.3444444444444446e-06,
      "loss": 0.0026,
      "step": 87580
    },
    {
      "epoch": 1.9464444444444444,
      "grad_norm": 0.14055480062961578,
      "learning_rate": 1.338888888888889e-06,
      "loss": 0.0027,
      "step": 87590
    },
    {
      "epoch": 1.9466666666666668,
      "grad_norm": 0.09765303879976273,
      "learning_rate": 1.3333333333333334e-06,
      "loss": 0.0019,
      "step": 87600
    },
    {
      "epoch": 1.946888888888889,
      "grad_norm": 0.14479228854179382,
      "learning_rate": 1.3277777777777778e-06,
      "loss": 0.0017,
      "step": 87610
    },
    {
      "epoch": 1.947111111111111,
      "grad_norm": 0.17442579567432404,
      "learning_rate": 1.3222222222222222e-06,
      "loss": 0.0026,
      "step": 87620
    },
    {
      "epoch": 1.9473333333333334,
      "grad_norm": 0.13067252933979034,
      "learning_rate": 1.3166666666666668e-06,
      "loss": 0.0017,
      "step": 87630
    },
    {
      "epoch": 1.9475555555555557,
      "grad_norm": 0.4063463509082794,
      "learning_rate": 1.3111111111111112e-06,
      "loss": 0.0027,
      "step": 87640
    },
    {
      "epoch": 1.9477777777777778,
      "grad_norm": 0.17438171803951263,
      "learning_rate": 1.3055555555555556e-06,
      "loss": 0.0029,
      "step": 87650
    },
    {
      "epoch": 1.948,
      "grad_norm": 0.2637202739715576,
      "learning_rate": 1.3e-06,
      "loss": 0.0019,
      "step": 87660
    },
    {
      "epoch": 1.9482222222222223,
      "grad_norm": 0.47893568873405457,
      "learning_rate": 1.2944444444444445e-06,
      "loss": 0.0017,
      "step": 87670
    },
    {
      "epoch": 1.9484444444444444,
      "grad_norm": 0.11754181981086731,
      "learning_rate": 1.2888888888888889e-06,
      "loss": 0.0031,
      "step": 87680
    },
    {
      "epoch": 1.9486666666666665,
      "grad_norm": 0.10836955159902573,
      "learning_rate": 1.2833333333333335e-06,
      "loss": 0.0023,
      "step": 87690
    },
    {
      "epoch": 1.948888888888889,
      "grad_norm": 0.400028258562088,
      "learning_rate": 1.2777777777777779e-06,
      "loss": 0.0019,
      "step": 87700
    },
    {
      "epoch": 1.9491111111111112,
      "grad_norm": 0.08011239767074585,
      "learning_rate": 1.2722222222222223e-06,
      "loss": 0.0017,
      "step": 87710
    },
    {
      "epoch": 1.9493333333333334,
      "grad_norm": 0.10207321494817734,
      "learning_rate": 1.2666666666666667e-06,
      "loss": 0.0017,
      "step": 87720
    },
    {
      "epoch": 1.9495555555555555,
      "grad_norm": 0.1921263188123703,
      "learning_rate": 1.261111111111111e-06,
      "loss": 0.0018,
      "step": 87730
    },
    {
      "epoch": 1.9497777777777778,
      "grad_norm": 0.4213390052318573,
      "learning_rate": 1.2555555555555557e-06,
      "loss": 0.0021,
      "step": 87740
    },
    {
      "epoch": 1.95,
      "grad_norm": 0.6347759962081909,
      "learning_rate": 1.25e-06,
      "loss": 0.0021,
      "step": 87750
    },
    {
      "epoch": 1.950222222222222,
      "grad_norm": 0.19275079667568207,
      "learning_rate": 1.2444444444444445e-06,
      "loss": 0.0016,
      "step": 87760
    },
    {
      "epoch": 1.9504444444444444,
      "grad_norm": 0.1776137799024582,
      "learning_rate": 1.238888888888889e-06,
      "loss": 0.0024,
      "step": 87770
    },
    {
      "epoch": 1.9506666666666668,
      "grad_norm": 0.15119877457618713,
      "learning_rate": 1.2333333333333333e-06,
      "loss": 0.002,
      "step": 87780
    },
    {
      "epoch": 1.950888888888889,
      "grad_norm": 0.14328236877918243,
      "learning_rate": 1.227777777777778e-06,
      "loss": 0.0019,
      "step": 87790
    },
    {
      "epoch": 1.951111111111111,
      "grad_norm": 0.27951565384864807,
      "learning_rate": 1.2222222222222223e-06,
      "loss": 0.0027,
      "step": 87800
    },
    {
      "epoch": 1.9513333333333334,
      "grad_norm": 0.1515323519706726,
      "learning_rate": 1.2166666666666667e-06,
      "loss": 0.0018,
      "step": 87810
    },
    {
      "epoch": 1.9515555555555557,
      "grad_norm": 0.18108396232128143,
      "learning_rate": 1.2111111111111111e-06,
      "loss": 0.0019,
      "step": 87820
    },
    {
      "epoch": 1.9517777777777776,
      "grad_norm": 0.22977687418460846,
      "learning_rate": 1.2055555555555555e-06,
      "loss": 0.0018,
      "step": 87830
    },
    {
      "epoch": 1.952,
      "grad_norm": 0.3632160425186157,
      "learning_rate": 1.2000000000000002e-06,
      "loss": 0.0019,
      "step": 87840
    },
    {
      "epoch": 1.9522222222222223,
      "grad_norm": 0.2662688195705414,
      "learning_rate": 1.1944444444444446e-06,
      "loss": 0.0016,
      "step": 87850
    },
    {
      "epoch": 1.9524444444444444,
      "grad_norm": 0.24395045638084412,
      "learning_rate": 1.188888888888889e-06,
      "loss": 0.0024,
      "step": 87860
    },
    {
      "epoch": 1.9526666666666666,
      "grad_norm": 0.09679831564426422,
      "learning_rate": 1.1833333333333334e-06,
      "loss": 0.0023,
      "step": 87870
    },
    {
      "epoch": 1.952888888888889,
      "grad_norm": 0.08851680904626846,
      "learning_rate": 1.1777777777777778e-06,
      "loss": 0.0017,
      "step": 87880
    },
    {
      "epoch": 1.9531111111111112,
      "grad_norm": 0.05774549022316933,
      "learning_rate": 1.1722222222222224e-06,
      "loss": 0.0028,
      "step": 87890
    },
    {
      "epoch": 1.9533333333333334,
      "grad_norm": 0.10539630055427551,
      "learning_rate": 1.1666666666666668e-06,
      "loss": 0.0033,
      "step": 87900
    },
    {
      "epoch": 1.9535555555555555,
      "grad_norm": 0.20299746096134186,
      "learning_rate": 1.161111111111111e-06,
      "loss": 0.0017,
      "step": 87910
    },
    {
      "epoch": 1.9537777777777778,
      "grad_norm": 0.3271696865558624,
      "learning_rate": 1.1555555555555556e-06,
      "loss": 0.0025,
      "step": 87920
    },
    {
      "epoch": 1.954,
      "grad_norm": 0.10377330332994461,
      "learning_rate": 1.15e-06,
      "loss": 0.0018,
      "step": 87930
    },
    {
      "epoch": 1.954222222222222,
      "grad_norm": 0.2662251889705658,
      "learning_rate": 1.1444444444444446e-06,
      "loss": 0.0032,
      "step": 87940
    },
    {
      "epoch": 1.9544444444444444,
      "grad_norm": 0.15138936042785645,
      "learning_rate": 1.138888888888889e-06,
      "loss": 0.002,
      "step": 87950
    },
    {
      "epoch": 1.9546666666666668,
      "grad_norm": 0.13205188512802124,
      "learning_rate": 1.1333333333333334e-06,
      "loss": 0.0019,
      "step": 87960
    },
    {
      "epoch": 1.954888888888889,
      "grad_norm": 0.2663627564907074,
      "learning_rate": 1.1277777777777778e-06,
      "loss": 0.0021,
      "step": 87970
    },
    {
      "epoch": 1.955111111111111,
      "grad_norm": 0.22483235597610474,
      "learning_rate": 1.1222222222222222e-06,
      "loss": 0.0024,
      "step": 87980
    },
    {
      "epoch": 1.9553333333333334,
      "grad_norm": 0.14484111964702606,
      "learning_rate": 1.1166666666666666e-06,
      "loss": 0.0023,
      "step": 87990
    },
    {
      "epoch": 1.9555555555555557,
      "grad_norm": 0.28352412581443787,
      "learning_rate": 1.1111111111111112e-06,
      "loss": 0.0025,
      "step": 88000
    },
    {
      "epoch": 1.9557777777777776,
      "grad_norm": 0.20966866612434387,
      "learning_rate": 1.1055555555555557e-06,
      "loss": 0.0017,
      "step": 88010
    },
    {
      "epoch": 1.956,
      "grad_norm": 0.3412025272846222,
      "learning_rate": 1.1e-06,
      "loss": 0.0022,
      "step": 88020
    },
    {
      "epoch": 1.9562222222222223,
      "grad_norm": 0.2758244574069977,
      "learning_rate": 1.0944444444444445e-06,
      "loss": 0.002,
      "step": 88030
    },
    {
      "epoch": 1.9564444444444444,
      "grad_norm": 0.1100199744105339,
      "learning_rate": 1.0888888888888889e-06,
      "loss": 0.0017,
      "step": 88040
    },
    {
      "epoch": 1.9566666666666666,
      "grad_norm": 0.6174695491790771,
      "learning_rate": 1.0833333333333335e-06,
      "loss": 0.0018,
      "step": 88050
    },
    {
      "epoch": 1.956888888888889,
      "grad_norm": 0.13176308572292328,
      "learning_rate": 1.0777777777777779e-06,
      "loss": 0.0028,
      "step": 88060
    },
    {
      "epoch": 1.9571111111111112,
      "grad_norm": 0.4416835904121399,
      "learning_rate": 1.0722222222222223e-06,
      "loss": 0.0021,
      "step": 88070
    },
    {
      "epoch": 1.9573333333333334,
      "grad_norm": 0.07541361451148987,
      "learning_rate": 1.0666666666666667e-06,
      "loss": 0.0018,
      "step": 88080
    },
    {
      "epoch": 1.9575555555555555,
      "grad_norm": 0.16870851814746857,
      "learning_rate": 1.061111111111111e-06,
      "loss": 0.0019,
      "step": 88090
    },
    {
      "epoch": 1.9577777777777778,
      "grad_norm": 0.17050309479236603,
      "learning_rate": 1.0555555555555557e-06,
      "loss": 0.0022,
      "step": 88100
    },
    {
      "epoch": 1.958,
      "grad_norm": 0.15309865772724152,
      "learning_rate": 1.0500000000000001e-06,
      "loss": 0.0031,
      "step": 88110
    },
    {
      "epoch": 1.958222222222222,
      "grad_norm": 0.08458082377910614,
      "learning_rate": 1.0444444444444445e-06,
      "loss": 0.0025,
      "step": 88120
    },
    {
      "epoch": 1.9584444444444444,
      "grad_norm": 0.292843759059906,
      "learning_rate": 1.038888888888889e-06,
      "loss": 0.0025,
      "step": 88130
    },
    {
      "epoch": 1.9586666666666668,
      "grad_norm": 0.3304778039455414,
      "learning_rate": 1.0333333333333333e-06,
      "loss": 0.003,
      "step": 88140
    },
    {
      "epoch": 1.958888888888889,
      "grad_norm": 0.42650195956230164,
      "learning_rate": 1.027777777777778e-06,
      "loss": 0.0027,
      "step": 88150
    },
    {
      "epoch": 1.959111111111111,
      "grad_norm": 0.09091086685657501,
      "learning_rate": 1.0222222222222223e-06,
      "loss": 0.0028,
      "step": 88160
    },
    {
      "epoch": 1.9593333333333334,
      "grad_norm": 0.5660480856895447,
      "learning_rate": 1.0166666666666665e-06,
      "loss": 0.0018,
      "step": 88170
    },
    {
      "epoch": 1.9595555555555557,
      "grad_norm": 0.24452251195907593,
      "learning_rate": 1.0111111111111111e-06,
      "loss": 0.0019,
      "step": 88180
    },
    {
      "epoch": 1.9597777777777776,
      "grad_norm": 0.3102577328681946,
      "learning_rate": 1.0055555555555556e-06,
      "loss": 0.0017,
      "step": 88190
    },
    {
      "epoch": 1.96,
      "grad_norm": 0.49003851413726807,
      "learning_rate": 1.0000000000000002e-06,
      "loss": 0.0019,
      "step": 88200
    },
    {
      "epoch": 1.9602222222222223,
      "grad_norm": 0.09375746548175812,
      "learning_rate": 9.944444444444446e-07,
      "loss": 0.0024,
      "step": 88210
    },
    {
      "epoch": 1.9604444444444444,
      "grad_norm": 0.3160874545574188,
      "learning_rate": 9.888888888888888e-07,
      "loss": 0.0019,
      "step": 88220
    },
    {
      "epoch": 1.9606666666666666,
      "grad_norm": 0.0857376828789711,
      "learning_rate": 9.833333333333334e-07,
      "loss": 0.0018,
      "step": 88230
    },
    {
      "epoch": 1.960888888888889,
      "grad_norm": 0.11678032577037811,
      "learning_rate": 9.777777777777778e-07,
      "loss": 0.0018,
      "step": 88240
    },
    {
      "epoch": 1.9611111111111112,
      "grad_norm": 0.630561113357544,
      "learning_rate": 9.722222222222222e-07,
      "loss": 0.0028,
      "step": 88250
    },
    {
      "epoch": 1.9613333333333334,
      "grad_norm": 0.16752444207668304,
      "learning_rate": 9.666666666666668e-07,
      "loss": 0.0016,
      "step": 88260
    },
    {
      "epoch": 1.9615555555555555,
      "grad_norm": 0.10338105261325836,
      "learning_rate": 9.611111111111112e-07,
      "loss": 0.0017,
      "step": 88270
    },
    {
      "epoch": 1.9617777777777778,
      "grad_norm": 0.24032358825206757,
      "learning_rate": 9.555555555555556e-07,
      "loss": 0.0019,
      "step": 88280
    },
    {
      "epoch": 1.962,
      "grad_norm": 0.07521072030067444,
      "learning_rate": 9.5e-07,
      "loss": 0.0016,
      "step": 88290
    },
    {
      "epoch": 1.962222222222222,
      "grad_norm": 0.5894924998283386,
      "learning_rate": 9.444444444444445e-07,
      "loss": 0.0024,
      "step": 88300
    },
    {
      "epoch": 1.9624444444444444,
      "grad_norm": 0.21333324909210205,
      "learning_rate": 9.38888888888889e-07,
      "loss": 0.0024,
      "step": 88310
    },
    {
      "epoch": 1.9626666666666668,
      "grad_norm": 0.09180828183889389,
      "learning_rate": 9.333333333333334e-07,
      "loss": 0.0018,
      "step": 88320
    },
    {
      "epoch": 1.962888888888889,
      "grad_norm": 0.23884031176567078,
      "learning_rate": 9.277777777777777e-07,
      "loss": 0.0032,
      "step": 88330
    },
    {
      "epoch": 1.963111111111111,
      "grad_norm": 0.33821722865104675,
      "learning_rate": 9.222222222222222e-07,
      "loss": 0.0022,
      "step": 88340
    },
    {
      "epoch": 1.9633333333333334,
      "grad_norm": 0.12724663317203522,
      "learning_rate": 9.166666666666667e-07,
      "loss": 0.0021,
      "step": 88350
    },
    {
      "epoch": 1.9635555555555557,
      "grad_norm": 0.11801836639642715,
      "learning_rate": 9.111111111111112e-07,
      "loss": 0.002,
      "step": 88360
    },
    {
      "epoch": 1.9637777777777776,
      "grad_norm": 0.1206427663564682,
      "learning_rate": 9.055555555555557e-07,
      "loss": 0.0027,
      "step": 88370
    },
    {
      "epoch": 1.964,
      "grad_norm": 0.4794980585575104,
      "learning_rate": 9e-07,
      "loss": 0.0018,
      "step": 88380
    },
    {
      "epoch": 1.9642222222222223,
      "grad_norm": 0.18106374144554138,
      "learning_rate": 8.944444444444445e-07,
      "loss": 0.0018,
      "step": 88390
    },
    {
      "epoch": 1.9644444444444444,
      "grad_norm": 0.4954226613044739,
      "learning_rate": 8.88888888888889e-07,
      "loss": 0.0031,
      "step": 88400
    },
    {
      "epoch": 1.9646666666666666,
      "grad_norm": 0.11560633778572083,
      "learning_rate": 8.833333333333334e-07,
      "loss": 0.0034,
      "step": 88410
    },
    {
      "epoch": 1.964888888888889,
      "grad_norm": 0.3437519073486328,
      "learning_rate": 8.777777777777779e-07,
      "loss": 0.0017,
      "step": 88420
    },
    {
      "epoch": 1.9651111111111113,
      "grad_norm": 0.17586567997932434,
      "learning_rate": 8.722222222222222e-07,
      "loss": 0.0018,
      "step": 88430
    },
    {
      "epoch": 1.9653333333333334,
      "grad_norm": 0.35928165912628174,
      "learning_rate": 8.666666666666667e-07,
      "loss": 0.0016,
      "step": 88440
    },
    {
      "epoch": 1.9655555555555555,
      "grad_norm": 0.6216354370117188,
      "learning_rate": 8.611111111111111e-07,
      "loss": 0.0021,
      "step": 88450
    },
    {
      "epoch": 1.9657777777777778,
      "grad_norm": 0.2580222487449646,
      "learning_rate": 8.555555555555556e-07,
      "loss": 0.0018,
      "step": 88460
    },
    {
      "epoch": 1.966,
      "grad_norm": 0.11177045106887817,
      "learning_rate": 8.500000000000001e-07,
      "loss": 0.0027,
      "step": 88470
    },
    {
      "epoch": 1.966222222222222,
      "grad_norm": 0.12695033848285675,
      "learning_rate": 8.444444444444444e-07,
      "loss": 0.002,
      "step": 88480
    },
    {
      "epoch": 1.9664444444444444,
      "grad_norm": 0.2242588996887207,
      "learning_rate": 8.388888888888889e-07,
      "loss": 0.0019,
      "step": 88490
    },
    {
      "epoch": 1.9666666666666668,
      "grad_norm": 0.0915471762418747,
      "learning_rate": 8.333333333333333e-07,
      "loss": 0.0019,
      "step": 88500
    },
    {
      "epoch": 1.966888888888889,
      "grad_norm": 0.39795318245887756,
      "learning_rate": 8.277777777777778e-07,
      "loss": 0.0015,
      "step": 88510
    },
    {
      "epoch": 1.967111111111111,
      "grad_norm": 0.3536124527454376,
      "learning_rate": 8.222222222222223e-07,
      "loss": 0.0018,
      "step": 88520
    },
    {
      "epoch": 1.9673333333333334,
      "grad_norm": 0.08768641948699951,
      "learning_rate": 8.166666666666666e-07,
      "loss": 0.0017,
      "step": 88530
    },
    {
      "epoch": 1.9675555555555555,
      "grad_norm": 0.16869594156742096,
      "learning_rate": 8.11111111111111e-07,
      "loss": 0.0024,
      "step": 88540
    },
    {
      "epoch": 1.9677777777777776,
      "grad_norm": 0.14548762142658234,
      "learning_rate": 8.055555555555556e-07,
      "loss": 0.0019,
      "step": 88550
    },
    {
      "epoch": 1.968,
      "grad_norm": 0.2616020441055298,
      "learning_rate": 8.000000000000001e-07,
      "loss": 0.0026,
      "step": 88560
    },
    {
      "epoch": 1.9682222222222223,
      "grad_norm": 0.6039602756500244,
      "learning_rate": 7.944444444444446e-07,
      "loss": 0.0018,
      "step": 88570
    },
    {
      "epoch": 1.9684444444444444,
      "grad_norm": 0.3124561309814453,
      "learning_rate": 7.88888888888889e-07,
      "loss": 0.0019,
      "step": 88580
    },
    {
      "epoch": 1.9686666666666666,
      "grad_norm": 0.1455216258764267,
      "learning_rate": 7.833333333333333e-07,
      "loss": 0.0016,
      "step": 88590
    },
    {
      "epoch": 1.968888888888889,
      "grad_norm": 0.3506281077861786,
      "learning_rate": 7.777777777777778e-07,
      "loss": 0.0035,
      "step": 88600
    },
    {
      "epoch": 1.9691111111111113,
      "grad_norm": 0.11588558554649353,
      "learning_rate": 7.722222222222223e-07,
      "loss": 0.0018,
      "step": 88610
    },
    {
      "epoch": 1.9693333333333334,
      "grad_norm": 0.27721360325813293,
      "learning_rate": 7.666666666666667e-07,
      "loss": 0.0029,
      "step": 88620
    },
    {
      "epoch": 1.9695555555555555,
      "grad_norm": 0.153561532497406,
      "learning_rate": 7.611111111111111e-07,
      "loss": 0.0028,
      "step": 88630
    },
    {
      "epoch": 1.9697777777777778,
      "grad_norm": 0.11346882581710815,
      "learning_rate": 7.555555555555556e-07,
      "loss": 0.0017,
      "step": 88640
    },
    {
      "epoch": 1.97,
      "grad_norm": 0.5719148516654968,
      "learning_rate": 7.5e-07,
      "loss": 0.0024,
      "step": 88650
    },
    {
      "epoch": 1.970222222222222,
      "grad_norm": 0.2799305021762848,
      "learning_rate": 7.444444444444445e-07,
      "loss": 0.0021,
      "step": 88660
    },
    {
      "epoch": 1.9704444444444444,
      "grad_norm": 0.1566285490989685,
      "learning_rate": 7.388888888888889e-07,
      "loss": 0.0029,
      "step": 88670
    },
    {
      "epoch": 1.9706666666666668,
      "grad_norm": 0.1614389717578888,
      "learning_rate": 7.333333333333333e-07,
      "loss": 0.0015,
      "step": 88680
    },
    {
      "epoch": 1.970888888888889,
      "grad_norm": 0.17507228255271912,
      "learning_rate": 7.277777777777778e-07,
      "loss": 0.0018,
      "step": 88690
    },
    {
      "epoch": 1.971111111111111,
      "grad_norm": 0.35073328018188477,
      "learning_rate": 7.222222222222222e-07,
      "loss": 0.0018,
      "step": 88700
    },
    {
      "epoch": 1.9713333333333334,
      "grad_norm": 0.3966979682445526,
      "learning_rate": 7.166666666666667e-07,
      "loss": 0.0018,
      "step": 88710
    },
    {
      "epoch": 1.9715555555555555,
      "grad_norm": 0.15672209858894348,
      "learning_rate": 7.111111111111112e-07,
      "loss": 0.0021,
      "step": 88720
    },
    {
      "epoch": 1.9717777777777776,
      "grad_norm": 0.5422604084014893,
      "learning_rate": 7.055555555555556e-07,
      "loss": 0.0024,
      "step": 88730
    },
    {
      "epoch": 1.972,
      "grad_norm": 0.2773032784461975,
      "learning_rate": 7.000000000000001e-07,
      "loss": 0.0016,
      "step": 88740
    },
    {
      "epoch": 1.9722222222222223,
      "grad_norm": 0.18722091615200043,
      "learning_rate": 6.944444444444445e-07,
      "loss": 0.0023,
      "step": 88750
    },
    {
      "epoch": 1.9724444444444444,
      "grad_norm": 0.095424123108387,
      "learning_rate": 6.888888888888889e-07,
      "loss": 0.0018,
      "step": 88760
    },
    {
      "epoch": 1.9726666666666666,
      "grad_norm": 0.16017885506153107,
      "learning_rate": 6.833333333333334e-07,
      "loss": 0.0019,
      "step": 88770
    },
    {
      "epoch": 1.972888888888889,
      "grad_norm": 0.46278584003448486,
      "learning_rate": 6.777777777777778e-07,
      "loss": 0.0017,
      "step": 88780
    },
    {
      "epoch": 1.9731111111111113,
      "grad_norm": 0.11984656006097794,
      "learning_rate": 6.722222222222223e-07,
      "loss": 0.0026,
      "step": 88790
    },
    {
      "epoch": 1.9733333333333334,
      "grad_norm": 0.24100050330162048,
      "learning_rate": 6.666666666666667e-07,
      "loss": 0.0019,
      "step": 88800
    },
    {
      "epoch": 1.9735555555555555,
      "grad_norm": 0.12247913330793381,
      "learning_rate": 6.611111111111111e-07,
      "loss": 0.0017,
      "step": 88810
    },
    {
      "epoch": 1.9737777777777779,
      "grad_norm": 0.18262211978435516,
      "learning_rate": 6.555555555555556e-07,
      "loss": 0.0015,
      "step": 88820
    },
    {
      "epoch": 1.974,
      "grad_norm": 0.3549332618713379,
      "learning_rate": 6.5e-07,
      "loss": 0.0025,
      "step": 88830
    },
    {
      "epoch": 1.974222222222222,
      "grad_norm": 0.13287700712680817,
      "learning_rate": 6.444444444444444e-07,
      "loss": 0.0028,
      "step": 88840
    },
    {
      "epoch": 1.9744444444444444,
      "grad_norm": 0.2820574641227722,
      "learning_rate": 6.388888888888889e-07,
      "loss": 0.0018,
      "step": 88850
    },
    {
      "epoch": 1.9746666666666668,
      "grad_norm": 0.5163200497627258,
      "learning_rate": 6.333333333333333e-07,
      "loss": 0.0021,
      "step": 88860
    },
    {
      "epoch": 1.974888888888889,
      "grad_norm": 0.06679218262434006,
      "learning_rate": 6.277777777777778e-07,
      "loss": 0.0016,
      "step": 88870
    },
    {
      "epoch": 1.975111111111111,
      "grad_norm": 0.3704274594783783,
      "learning_rate": 6.222222222222223e-07,
      "loss": 0.0026,
      "step": 88880
    },
    {
      "epoch": 1.9753333333333334,
      "grad_norm": 0.10469403117895126,
      "learning_rate": 6.166666666666667e-07,
      "loss": 0.0027,
      "step": 88890
    },
    {
      "epoch": 1.9755555555555555,
      "grad_norm": 0.14002253115177155,
      "learning_rate": 6.111111111111112e-07,
      "loss": 0.0022,
      "step": 88900
    },
    {
      "epoch": 1.9757777777777776,
      "grad_norm": 0.22820916771888733,
      "learning_rate": 6.055555555555556e-07,
      "loss": 0.0016,
      "step": 88910
    },
    {
      "epoch": 1.976,
      "grad_norm": 0.33846187591552734,
      "learning_rate": 6.000000000000001e-07,
      "loss": 0.0018,
      "step": 88920
    },
    {
      "epoch": 1.9762222222222223,
      "grad_norm": 0.09567456692457199,
      "learning_rate": 5.944444444444445e-07,
      "loss": 0.0017,
      "step": 88930
    },
    {
      "epoch": 1.9764444444444444,
      "grad_norm": 0.08396785706281662,
      "learning_rate": 5.888888888888889e-07,
      "loss": 0.002,
      "step": 88940
    },
    {
      "epoch": 1.9766666666666666,
      "grad_norm": 0.2551710903644562,
      "learning_rate": 5.833333333333334e-07,
      "loss": 0.002,
      "step": 88950
    },
    {
      "epoch": 1.976888888888889,
      "grad_norm": 0.2315758764743805,
      "learning_rate": 5.777777777777778e-07,
      "loss": 0.0016,
      "step": 88960
    },
    {
      "epoch": 1.9771111111111113,
      "grad_norm": 0.1391066163778305,
      "learning_rate": 5.722222222222223e-07,
      "loss": 0.002,
      "step": 88970
    },
    {
      "epoch": 1.9773333333333334,
      "grad_norm": 0.24825312197208405,
      "learning_rate": 5.666666666666667e-07,
      "loss": 0.0032,
      "step": 88980
    },
    {
      "epoch": 1.9775555555555555,
      "grad_norm": 0.15707559883594513,
      "learning_rate": 5.611111111111111e-07,
      "loss": 0.0018,
      "step": 88990
    },
    {
      "epoch": 1.9777777777777779,
      "grad_norm": 0.223246768116951,
      "learning_rate": 5.555555555555556e-07,
      "loss": 0.0018,
      "step": 89000
    }
  ],
  "logging_steps": 10,
  "max_steps": 90000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 0.0,
  "train_batch_size": 40,
  "trial_name": null,
  "trial_params": null
}
