{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.0,
  "eval_steps": 500,
  "global_step": 18000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0011111111111111111,
      "grad_norm": 3.0700552463531494,
      "learning_rate": 4.997222222222223e-05,
      "loss": 0.0031,
      "step": 10
    },
    {
      "epoch": 0.0022222222222222222,
      "grad_norm": 1.4950768947601318,
      "learning_rate": 4.994444444444445e-05,
      "loss": 0.0048,
      "step": 20
    },
    {
      "epoch": 0.0033333333333333335,
      "grad_norm": 0.6149237751960754,
      "learning_rate": 4.991666666666667e-05,
      "loss": 0.0044,
      "step": 30
    },
    {
      "epoch": 0.0044444444444444444,
      "grad_norm": 1.9777902364730835,
      "learning_rate": 4.9888888888888894e-05,
      "loss": 0.0037,
      "step": 40
    },
    {
      "epoch": 0.005555555555555556,
      "grad_norm": 2.86961030960083,
      "learning_rate": 4.986111111111111e-05,
      "loss": 0.0037,
      "step": 50
    },
    {
      "epoch": 0.006666666666666667,
      "grad_norm": 2.6157729625701904,
      "learning_rate": 4.9833333333333336e-05,
      "loss": 0.0049,
      "step": 60
    },
    {
      "epoch": 0.0077777777777777776,
      "grad_norm": 0.6991698741912842,
      "learning_rate": 4.9805555555555554e-05,
      "loss": 0.0033,
      "step": 70
    },
    {
      "epoch": 0.008888888888888889,
      "grad_norm": 0.5612363815307617,
      "learning_rate": 4.977777777777778e-05,
      "loss": 0.0024,
      "step": 80
    },
    {
      "epoch": 0.01,
      "grad_norm": 2.2055225372314453,
      "learning_rate": 4.975e-05,
      "loss": 0.0031,
      "step": 90
    },
    {
      "epoch": 0.011111111111111112,
      "grad_norm": 0.9313123226165771,
      "learning_rate": 4.972222222222223e-05,
      "loss": 0.0047,
      "step": 100
    },
    {
      "epoch": 0.012222222222222223,
      "grad_norm": 1.1315138339996338,
      "learning_rate": 4.969444444444445e-05,
      "loss": 0.0029,
      "step": 110
    },
    {
      "epoch": 0.013333333333333334,
      "grad_norm": 2.151494026184082,
      "learning_rate": 4.966666666666667e-05,
      "loss": 0.0029,
      "step": 120
    },
    {
      "epoch": 0.014444444444444444,
      "grad_norm": 1.2256516218185425,
      "learning_rate": 4.963888888888889e-05,
      "loss": 0.0049,
      "step": 130
    },
    {
      "epoch": 0.015555555555555555,
      "grad_norm": 0.5669606328010559,
      "learning_rate": 4.961111111111111e-05,
      "loss": 0.0033,
      "step": 140
    },
    {
      "epoch": 0.016666666666666666,
      "grad_norm": 2.253342390060425,
      "learning_rate": 4.958333333333334e-05,
      "loss": 0.0047,
      "step": 150
    },
    {
      "epoch": 0.017777777777777778,
      "grad_norm": 1.119771957397461,
      "learning_rate": 4.955555555555556e-05,
      "loss": 0.0041,
      "step": 160
    },
    {
      "epoch": 0.01888888888888889,
      "grad_norm": 1.064324140548706,
      "learning_rate": 4.952777777777778e-05,
      "loss": 0.003,
      "step": 170
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.691924810409546,
      "learning_rate": 4.9500000000000004e-05,
      "loss": 0.0034,
      "step": 180
    },
    {
      "epoch": 0.021111111111111112,
      "grad_norm": 1.8994908332824707,
      "learning_rate": 4.947222222222223e-05,
      "loss": 0.0052,
      "step": 190
    },
    {
      "epoch": 0.022222222222222223,
      "grad_norm": 1.5721306800842285,
      "learning_rate": 4.9444444444444446e-05,
      "loss": 0.0049,
      "step": 200
    },
    {
      "epoch": 0.023333333333333334,
      "grad_norm": 1.049666166305542,
      "learning_rate": 4.9416666666666664e-05,
      "loss": 0.0055,
      "step": 210
    },
    {
      "epoch": 0.024444444444444446,
      "grad_norm": 2.175769090652466,
      "learning_rate": 4.938888888888889e-05,
      "loss": 0.0045,
      "step": 220
    },
    {
      "epoch": 0.025555555555555557,
      "grad_norm": 1.4645075798034668,
      "learning_rate": 4.936111111111111e-05,
      "loss": 0.0053,
      "step": 230
    },
    {
      "epoch": 0.02666666666666667,
      "grad_norm": 1.4607665538787842,
      "learning_rate": 4.933333333333334e-05,
      "loss": 0.004,
      "step": 240
    },
    {
      "epoch": 0.027777777777777776,
      "grad_norm": 0.7962955832481384,
      "learning_rate": 4.930555555555556e-05,
      "loss": 0.0034,
      "step": 250
    },
    {
      "epoch": 0.028888888888888888,
      "grad_norm": 2.469658136367798,
      "learning_rate": 4.927777777777778e-05,
      "loss": 0.0042,
      "step": 260
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.4173068106174469,
      "learning_rate": 4.9250000000000004e-05,
      "loss": 0.0049,
      "step": 270
    },
    {
      "epoch": 0.03111111111111111,
      "grad_norm": 1.817014217376709,
      "learning_rate": 4.922222222222222e-05,
      "loss": 0.0042,
      "step": 280
    },
    {
      "epoch": 0.03222222222222222,
      "grad_norm": 0.8021082878112793,
      "learning_rate": 4.919444444444445e-05,
      "loss": 0.0038,
      "step": 290
    },
    {
      "epoch": 0.03333333333333333,
      "grad_norm": 0.6661232709884644,
      "learning_rate": 4.9166666666666665e-05,
      "loss": 0.0037,
      "step": 300
    },
    {
      "epoch": 0.034444444444444444,
      "grad_norm": 0.6888176202774048,
      "learning_rate": 4.913888888888889e-05,
      "loss": 0.0034,
      "step": 310
    },
    {
      "epoch": 0.035555555555555556,
      "grad_norm": 0.7875222563743591,
      "learning_rate": 4.9111111111111114e-05,
      "loss": 0.0029,
      "step": 320
    },
    {
      "epoch": 0.03666666666666667,
      "grad_norm": 0.5275673866271973,
      "learning_rate": 4.908333333333334e-05,
      "loss": 0.0037,
      "step": 330
    },
    {
      "epoch": 0.03777777777777778,
      "grad_norm": 1.351914644241333,
      "learning_rate": 4.905555555555556e-05,
      "loss": 0.003,
      "step": 340
    },
    {
      "epoch": 0.03888888888888889,
      "grad_norm": 0.7656432390213013,
      "learning_rate": 4.902777777777778e-05,
      "loss": 0.003,
      "step": 350
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.9067072868347168,
      "learning_rate": 4.9e-05,
      "loss": 0.0024,
      "step": 360
    },
    {
      "epoch": 0.04111111111111111,
      "grad_norm": 0.3023003935813904,
      "learning_rate": 4.897222222222222e-05,
      "loss": 0.0033,
      "step": 370
    },
    {
      "epoch": 0.042222222222222223,
      "grad_norm": 0.930850088596344,
      "learning_rate": 4.894444444444445e-05,
      "loss": 0.0026,
      "step": 380
    },
    {
      "epoch": 0.043333333333333335,
      "grad_norm": 0.7957099080085754,
      "learning_rate": 4.891666666666667e-05,
      "loss": 0.004,
      "step": 390
    },
    {
      "epoch": 0.044444444444444446,
      "grad_norm": 1.0858913660049438,
      "learning_rate": 4.888888888888889e-05,
      "loss": 0.0043,
      "step": 400
    },
    {
      "epoch": 0.04555555555555556,
      "grad_norm": 0.9018084406852722,
      "learning_rate": 4.8861111111111114e-05,
      "loss": 0.0036,
      "step": 410
    },
    {
      "epoch": 0.04666666666666667,
      "grad_norm": 1.0305911302566528,
      "learning_rate": 4.883333333333334e-05,
      "loss": 0.0034,
      "step": 420
    },
    {
      "epoch": 0.04777777777777778,
      "grad_norm": 2.0283524990081787,
      "learning_rate": 4.880555555555556e-05,
      "loss": 0.0043,
      "step": 430
    },
    {
      "epoch": 0.04888888888888889,
      "grad_norm": 1.3835389614105225,
      "learning_rate": 4.8777777777777775e-05,
      "loss": 0.0035,
      "step": 440
    },
    {
      "epoch": 0.05,
      "grad_norm": 1.7340506315231323,
      "learning_rate": 4.875e-05,
      "loss": 0.004,
      "step": 450
    },
    {
      "epoch": 0.051111111111111114,
      "grad_norm": 0.9673075675964355,
      "learning_rate": 4.8722222222222224e-05,
      "loss": 0.0046,
      "step": 460
    },
    {
      "epoch": 0.052222222222222225,
      "grad_norm": 0.6574969291687012,
      "learning_rate": 4.869444444444445e-05,
      "loss": 0.0045,
      "step": 470
    },
    {
      "epoch": 0.05333333333333334,
      "grad_norm": 0.4878309965133667,
      "learning_rate": 4.866666666666667e-05,
      "loss": 0.003,
      "step": 480
    },
    {
      "epoch": 0.05444444444444444,
      "grad_norm": 0.979112982749939,
      "learning_rate": 4.863888888888889e-05,
      "loss": 0.0026,
      "step": 490
    },
    {
      "epoch": 0.05555555555555555,
      "grad_norm": 0.9007571339607239,
      "learning_rate": 4.8611111111111115e-05,
      "loss": 0.0035,
      "step": 500
    },
    {
      "epoch": 0.056666666666666664,
      "grad_norm": 0.81739741563797,
      "learning_rate": 4.858333333333333e-05,
      "loss": 0.0032,
      "step": 510
    },
    {
      "epoch": 0.057777777777777775,
      "grad_norm": 0.7631022930145264,
      "learning_rate": 4.855555555555556e-05,
      "loss": 0.0045,
      "step": 520
    },
    {
      "epoch": 0.058888888888888886,
      "grad_norm": 0.8741490840911865,
      "learning_rate": 4.8527777777777775e-05,
      "loss": 0.0034,
      "step": 530
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.5837172269821167,
      "learning_rate": 4.85e-05,
      "loss": 0.0032,
      "step": 540
    },
    {
      "epoch": 0.06111111111111111,
      "grad_norm": 1.5316882133483887,
      "learning_rate": 4.8472222222222224e-05,
      "loss": 0.0054,
      "step": 550
    },
    {
      "epoch": 0.06222222222222222,
      "grad_norm": 0.3500928282737732,
      "learning_rate": 4.844444444444445e-05,
      "loss": 0.0049,
      "step": 560
    },
    {
      "epoch": 0.06333333333333334,
      "grad_norm": 1.0581963062286377,
      "learning_rate": 4.8416666666666673e-05,
      "loss": 0.0032,
      "step": 570
    },
    {
      "epoch": 0.06444444444444444,
      "grad_norm": 0.6696316599845886,
      "learning_rate": 4.838888888888889e-05,
      "loss": 0.0037,
      "step": 580
    },
    {
      "epoch": 0.06555555555555556,
      "grad_norm": 1.3749278783798218,
      "learning_rate": 4.8361111111111116e-05,
      "loss": 0.0031,
      "step": 590
    },
    {
      "epoch": 0.06666666666666667,
      "grad_norm": 1.267825961112976,
      "learning_rate": 4.8333333333333334e-05,
      "loss": 0.004,
      "step": 600
    },
    {
      "epoch": 0.06777777777777778,
      "grad_norm": 0.6850067377090454,
      "learning_rate": 4.830555555555556e-05,
      "loss": 0.0018,
      "step": 610
    },
    {
      "epoch": 0.06888888888888889,
      "grad_norm": 0.6633182764053345,
      "learning_rate": 4.8277777777777776e-05,
      "loss": 0.0032,
      "step": 620
    },
    {
      "epoch": 0.07,
      "grad_norm": 1.46794593334198,
      "learning_rate": 4.825e-05,
      "loss": 0.0039,
      "step": 630
    },
    {
      "epoch": 0.07111111111111111,
      "grad_norm": 1.122620701789856,
      "learning_rate": 4.8222222222222225e-05,
      "loss": 0.0035,
      "step": 640
    },
    {
      "epoch": 0.07222222222222222,
      "grad_norm": 2.1307408809661865,
      "learning_rate": 4.819444444444445e-05,
      "loss": 0.0034,
      "step": 650
    },
    {
      "epoch": 0.07333333333333333,
      "grad_norm": 0.8171386122703552,
      "learning_rate": 4.8166666666666674e-05,
      "loss": 0.0028,
      "step": 660
    },
    {
      "epoch": 0.07444444444444444,
      "grad_norm": 0.48503074049949646,
      "learning_rate": 4.813888888888889e-05,
      "loss": 0.0032,
      "step": 670
    },
    {
      "epoch": 0.07555555555555556,
      "grad_norm": 0.694233238697052,
      "learning_rate": 4.811111111111111e-05,
      "loss": 0.0028,
      "step": 680
    },
    {
      "epoch": 0.07666666666666666,
      "grad_norm": 1.286031723022461,
      "learning_rate": 4.8083333333333334e-05,
      "loss": 0.0033,
      "step": 690
    },
    {
      "epoch": 0.07777777777777778,
      "grad_norm": 0.8149377703666687,
      "learning_rate": 4.805555555555556e-05,
      "loss": 0.0037,
      "step": 700
    },
    {
      "epoch": 0.07888888888888888,
      "grad_norm": 0.6451476812362671,
      "learning_rate": 4.8027777777777783e-05,
      "loss": 0.0023,
      "step": 710
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.8615784645080566,
      "learning_rate": 4.8e-05,
      "loss": 0.0017,
      "step": 720
    },
    {
      "epoch": 0.0811111111111111,
      "grad_norm": 1.042348861694336,
      "learning_rate": 4.7972222222222226e-05,
      "loss": 0.0045,
      "step": 730
    },
    {
      "epoch": 0.08222222222222222,
      "grad_norm": 0.2562902569770813,
      "learning_rate": 4.794444444444445e-05,
      "loss": 0.0043,
      "step": 740
    },
    {
      "epoch": 0.08333333333333333,
      "grad_norm": 0.9455849528312683,
      "learning_rate": 4.791666666666667e-05,
      "loss": 0.0037,
      "step": 750
    },
    {
      "epoch": 0.08444444444444445,
      "grad_norm": 1.1204078197479248,
      "learning_rate": 4.7888888888888886e-05,
      "loss": 0.0034,
      "step": 760
    },
    {
      "epoch": 0.08555555555555555,
      "grad_norm": 1.874455451965332,
      "learning_rate": 4.786111111111111e-05,
      "loss": 0.004,
      "step": 770
    },
    {
      "epoch": 0.08666666666666667,
      "grad_norm": 1.3827780485153198,
      "learning_rate": 4.7833333333333335e-05,
      "loss": 0.0029,
      "step": 780
    },
    {
      "epoch": 0.08777777777777777,
      "grad_norm": 0.8709132075309753,
      "learning_rate": 4.780555555555556e-05,
      "loss": 0.003,
      "step": 790
    },
    {
      "epoch": 0.08888888888888889,
      "grad_norm": 0.5244458317756653,
      "learning_rate": 4.7777777777777784e-05,
      "loss": 0.0034,
      "step": 800
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.6387361884117126,
      "learning_rate": 4.775e-05,
      "loss": 0.0031,
      "step": 810
    },
    {
      "epoch": 0.09111111111111111,
      "grad_norm": 0.7504494786262512,
      "learning_rate": 4.7722222222222226e-05,
      "loss": 0.0018,
      "step": 820
    },
    {
      "epoch": 0.09222222222222222,
      "grad_norm": 0.7013571262359619,
      "learning_rate": 4.7694444444444444e-05,
      "loss": 0.0055,
      "step": 830
    },
    {
      "epoch": 0.09333333333333334,
      "grad_norm": 0.9483696818351746,
      "learning_rate": 4.766666666666667e-05,
      "loss": 0.0039,
      "step": 840
    },
    {
      "epoch": 0.09444444444444444,
      "grad_norm": 1.3614336252212524,
      "learning_rate": 4.7638888888888887e-05,
      "loss": 0.0046,
      "step": 850
    },
    {
      "epoch": 0.09555555555555556,
      "grad_norm": 1.0414880514144897,
      "learning_rate": 4.761111111111111e-05,
      "loss": 0.003,
      "step": 860
    },
    {
      "epoch": 0.09666666666666666,
      "grad_norm": 1.846846580505371,
      "learning_rate": 4.7583333333333336e-05,
      "loss": 0.0035,
      "step": 870
    },
    {
      "epoch": 0.09777777777777778,
      "grad_norm": 0.42575573921203613,
      "learning_rate": 4.755555555555556e-05,
      "loss": 0.0022,
      "step": 880
    },
    {
      "epoch": 0.09888888888888889,
      "grad_norm": 0.6969318985939026,
      "learning_rate": 4.7527777777777785e-05,
      "loss": 0.0024,
      "step": 890
    },
    {
      "epoch": 0.1,
      "grad_norm": 1.0314949750900269,
      "learning_rate": 4.75e-05,
      "loss": 0.0037,
      "step": 900
    },
    {
      "epoch": 0.10111111111111111,
      "grad_norm": 0.9253856539726257,
      "learning_rate": 4.747222222222222e-05,
      "loss": 0.0034,
      "step": 910
    },
    {
      "epoch": 0.10222222222222223,
      "grad_norm": 0.9945423603057861,
      "learning_rate": 4.7444444444444445e-05,
      "loss": 0.003,
      "step": 920
    },
    {
      "epoch": 0.10333333333333333,
      "grad_norm": 0.7612621188163757,
      "learning_rate": 4.741666666666667e-05,
      "loss": 0.0037,
      "step": 930
    },
    {
      "epoch": 0.10444444444444445,
      "grad_norm": 1.4581732749938965,
      "learning_rate": 4.7388888888888894e-05,
      "loss": 0.0042,
      "step": 940
    },
    {
      "epoch": 0.10555555555555556,
      "grad_norm": 0.5062525868415833,
      "learning_rate": 4.736111111111111e-05,
      "loss": 0.0024,
      "step": 950
    },
    {
      "epoch": 0.10666666666666667,
      "grad_norm": 0.36601653695106506,
      "learning_rate": 4.7333333333333336e-05,
      "loss": 0.0028,
      "step": 960
    },
    {
      "epoch": 0.10777777777777778,
      "grad_norm": 0.7098039984703064,
      "learning_rate": 4.730555555555556e-05,
      "loss": 0.004,
      "step": 970
    },
    {
      "epoch": 0.10888888888888888,
      "grad_norm": 0.26600387692451477,
      "learning_rate": 4.727777777777778e-05,
      "loss": 0.0025,
      "step": 980
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.7320523262023926,
      "learning_rate": 4.7249999999999997e-05,
      "loss": 0.004,
      "step": 990
    },
    {
      "epoch": 0.1111111111111111,
      "grad_norm": 1.066270351409912,
      "learning_rate": 4.722222222222222e-05,
      "loss": 0.0031,
      "step": 1000
    },
    {
      "epoch": 0.11222222222222222,
      "grad_norm": 0.38025397062301636,
      "learning_rate": 4.7194444444444446e-05,
      "loss": 0.0026,
      "step": 1010
    },
    {
      "epoch": 0.11333333333333333,
      "grad_norm": 0.816499650478363,
      "learning_rate": 4.716666666666667e-05,
      "loss": 0.0028,
      "step": 1020
    },
    {
      "epoch": 0.11444444444444445,
      "grad_norm": 0.20604200661182404,
      "learning_rate": 4.7138888888888895e-05,
      "loss": 0.004,
      "step": 1030
    },
    {
      "epoch": 0.11555555555555555,
      "grad_norm": 0.8925098180770874,
      "learning_rate": 4.711111111111111e-05,
      "loss": 0.0027,
      "step": 1040
    },
    {
      "epoch": 0.11666666666666667,
      "grad_norm": 0.45309287309646606,
      "learning_rate": 4.708333333333334e-05,
      "loss": 0.0023,
      "step": 1050
    },
    {
      "epoch": 0.11777777777777777,
      "grad_norm": 1.3829138278961182,
      "learning_rate": 4.7055555555555555e-05,
      "loss": 0.0025,
      "step": 1060
    },
    {
      "epoch": 0.11888888888888889,
      "grad_norm": 1.5104049444198608,
      "learning_rate": 4.702777777777778e-05,
      "loss": 0.0025,
      "step": 1070
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.4257427453994751,
      "learning_rate": 4.7e-05,
      "loss": 0.0029,
      "step": 1080
    },
    {
      "epoch": 0.12111111111111111,
      "grad_norm": 0.8716062307357788,
      "learning_rate": 4.697222222222222e-05,
      "loss": 0.0031,
      "step": 1090
    },
    {
      "epoch": 0.12222222222222222,
      "grad_norm": 1.648526668548584,
      "learning_rate": 4.6944444444444446e-05,
      "loss": 0.0029,
      "step": 1100
    },
    {
      "epoch": 0.12333333333333334,
      "grad_norm": 1.0199590921401978,
      "learning_rate": 4.691666666666667e-05,
      "loss": 0.0026,
      "step": 1110
    },
    {
      "epoch": 0.12444444444444444,
      "grad_norm": 0.42237699031829834,
      "learning_rate": 4.6888888888888895e-05,
      "loss": 0.0022,
      "step": 1120
    },
    {
      "epoch": 0.12555555555555556,
      "grad_norm": 0.31845560669898987,
      "learning_rate": 4.686111111111111e-05,
      "loss": 0.0028,
      "step": 1130
    },
    {
      "epoch": 0.12666666666666668,
      "grad_norm": 0.2887641191482544,
      "learning_rate": 4.683333333333334e-05,
      "loss": 0.002,
      "step": 1140
    },
    {
      "epoch": 0.12777777777777777,
      "grad_norm": 1.024325966835022,
      "learning_rate": 4.6805555555555556e-05,
      "loss": 0.0032,
      "step": 1150
    },
    {
      "epoch": 0.1288888888888889,
      "grad_norm": 0.4691718518733978,
      "learning_rate": 4.677777777777778e-05,
      "loss": 0.0024,
      "step": 1160
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.6394081115722656,
      "learning_rate": 4.6750000000000005e-05,
      "loss": 0.0027,
      "step": 1170
    },
    {
      "epoch": 0.13111111111111112,
      "grad_norm": 0.8869588375091553,
      "learning_rate": 4.672222222222222e-05,
      "loss": 0.0031,
      "step": 1180
    },
    {
      "epoch": 0.1322222222222222,
      "grad_norm": 0.6498413681983948,
      "learning_rate": 4.669444444444445e-05,
      "loss": 0.0033,
      "step": 1190
    },
    {
      "epoch": 0.13333333333333333,
      "grad_norm": 1.0259641408920288,
      "learning_rate": 4.666666666666667e-05,
      "loss": 0.004,
      "step": 1200
    },
    {
      "epoch": 0.13444444444444445,
      "grad_norm": 1.4882128238677979,
      "learning_rate": 4.6638888888888896e-05,
      "loss": 0.0034,
      "step": 1210
    },
    {
      "epoch": 0.13555555555555557,
      "grad_norm": 0.6128101944923401,
      "learning_rate": 4.6611111111111114e-05,
      "loss": 0.0025,
      "step": 1220
    },
    {
      "epoch": 0.13666666666666666,
      "grad_norm": 0.28968876600265503,
      "learning_rate": 4.658333333333333e-05,
      "loss": 0.0029,
      "step": 1230
    },
    {
      "epoch": 0.13777777777777778,
      "grad_norm": 0.5076297521591187,
      "learning_rate": 4.6555555555555556e-05,
      "loss": 0.003,
      "step": 1240
    },
    {
      "epoch": 0.1388888888888889,
      "grad_norm": 1.663919448852539,
      "learning_rate": 4.652777777777778e-05,
      "loss": 0.0021,
      "step": 1250
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.9890554547309875,
      "learning_rate": 4.6500000000000005e-05,
      "loss": 0.0027,
      "step": 1260
    },
    {
      "epoch": 0.1411111111111111,
      "grad_norm": 1.5251784324645996,
      "learning_rate": 4.647222222222222e-05,
      "loss": 0.0028,
      "step": 1270
    },
    {
      "epoch": 0.14222222222222222,
      "grad_norm": 0.3376781642436981,
      "learning_rate": 4.644444444444445e-05,
      "loss": 0.0023,
      "step": 1280
    },
    {
      "epoch": 0.14333333333333334,
      "grad_norm": 0.5174353122711182,
      "learning_rate": 4.641666666666667e-05,
      "loss": 0.0029,
      "step": 1290
    },
    {
      "epoch": 0.14444444444444443,
      "grad_norm": 1.0380938053131104,
      "learning_rate": 4.638888888888889e-05,
      "loss": 0.0022,
      "step": 1300
    },
    {
      "epoch": 0.14555555555555555,
      "grad_norm": 0.8020428419113159,
      "learning_rate": 4.636111111111111e-05,
      "loss": 0.0032,
      "step": 1310
    },
    {
      "epoch": 0.14666666666666667,
      "grad_norm": 0.4411776065826416,
      "learning_rate": 4.633333333333333e-05,
      "loss": 0.002,
      "step": 1320
    },
    {
      "epoch": 0.14777777777777779,
      "grad_norm": 1.8781349658966064,
      "learning_rate": 4.630555555555556e-05,
      "loss": 0.003,
      "step": 1330
    },
    {
      "epoch": 0.14888888888888888,
      "grad_norm": 0.6574270725250244,
      "learning_rate": 4.627777777777778e-05,
      "loss": 0.0029,
      "step": 1340
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.5001106858253479,
      "learning_rate": 4.6250000000000006e-05,
      "loss": 0.003,
      "step": 1350
    },
    {
      "epoch": 0.1511111111111111,
      "grad_norm": 1.4849168062210083,
      "learning_rate": 4.6222222222222224e-05,
      "loss": 0.0036,
      "step": 1360
    },
    {
      "epoch": 0.15222222222222223,
      "grad_norm": 1.6743921041488647,
      "learning_rate": 4.619444444444445e-05,
      "loss": 0.0036,
      "step": 1370
    },
    {
      "epoch": 0.15333333333333332,
      "grad_norm": 1.1644445657730103,
      "learning_rate": 4.6166666666666666e-05,
      "loss": 0.0031,
      "step": 1380
    },
    {
      "epoch": 0.15444444444444444,
      "grad_norm": 1.0787019729614258,
      "learning_rate": 4.613888888888889e-05,
      "loss": 0.0026,
      "step": 1390
    },
    {
      "epoch": 0.15555555555555556,
      "grad_norm": 0.5067228078842163,
      "learning_rate": 4.6111111111111115e-05,
      "loss": 0.0031,
      "step": 1400
    },
    {
      "epoch": 0.15666666666666668,
      "grad_norm": 0.4803752303123474,
      "learning_rate": 4.608333333333333e-05,
      "loss": 0.0042,
      "step": 1410
    },
    {
      "epoch": 0.15777777777777777,
      "grad_norm": 0.9772912263870239,
      "learning_rate": 4.605555555555556e-05,
      "loss": 0.0029,
      "step": 1420
    },
    {
      "epoch": 0.15888888888888889,
      "grad_norm": 0.5366730093955994,
      "learning_rate": 4.602777777777778e-05,
      "loss": 0.0043,
      "step": 1430
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.27100422978401184,
      "learning_rate": 4.600000000000001e-05,
      "loss": 0.0038,
      "step": 1440
    },
    {
      "epoch": 0.16111111111111112,
      "grad_norm": 0.25126150250434875,
      "learning_rate": 4.5972222222222225e-05,
      "loss": 0.0032,
      "step": 1450
    },
    {
      "epoch": 0.1622222222222222,
      "grad_norm": 0.35457852482795715,
      "learning_rate": 4.594444444444444e-05,
      "loss": 0.0028,
      "step": 1460
    },
    {
      "epoch": 0.16333333333333333,
      "grad_norm": 0.5380374193191528,
      "learning_rate": 4.591666666666667e-05,
      "loss": 0.0024,
      "step": 1470
    },
    {
      "epoch": 0.16444444444444445,
      "grad_norm": 0.4944601058959961,
      "learning_rate": 4.588888888888889e-05,
      "loss": 0.0038,
      "step": 1480
    },
    {
      "epoch": 0.16555555555555557,
      "grad_norm": 0.4716973304748535,
      "learning_rate": 4.5861111111111116e-05,
      "loss": 0.0034,
      "step": 1490
    },
    {
      "epoch": 0.16666666666666666,
      "grad_norm": 1.0679532289505005,
      "learning_rate": 4.5833333333333334e-05,
      "loss": 0.0029,
      "step": 1500
    },
    {
      "epoch": 0.16777777777777778,
      "grad_norm": 0.622649610042572,
      "learning_rate": 4.580555555555556e-05,
      "loss": 0.0018,
      "step": 1510
    },
    {
      "epoch": 0.1688888888888889,
      "grad_norm": 0.7751505374908447,
      "learning_rate": 4.577777777777778e-05,
      "loss": 0.003,
      "step": 1520
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.5599237680435181,
      "learning_rate": 4.575e-05,
      "loss": 0.0037,
      "step": 1530
    },
    {
      "epoch": 0.1711111111111111,
      "grad_norm": 1.7689597606658936,
      "learning_rate": 4.572222222222222e-05,
      "loss": 0.0032,
      "step": 1540
    },
    {
      "epoch": 0.17222222222222222,
      "grad_norm": 1.6381213665008545,
      "learning_rate": 4.569444444444444e-05,
      "loss": 0.0039,
      "step": 1550
    },
    {
      "epoch": 0.17333333333333334,
      "grad_norm": 0.5985482335090637,
      "learning_rate": 4.566666666666667e-05,
      "loss": 0.0029,
      "step": 1560
    },
    {
      "epoch": 0.17444444444444446,
      "grad_norm": 0.8021303415298462,
      "learning_rate": 4.563888888888889e-05,
      "loss": 0.0016,
      "step": 1570
    },
    {
      "epoch": 0.17555555555555555,
      "grad_norm": 1.3724555969238281,
      "learning_rate": 4.561111111111112e-05,
      "loss": 0.0031,
      "step": 1580
    },
    {
      "epoch": 0.17666666666666667,
      "grad_norm": 0.6609362363815308,
      "learning_rate": 4.5583333333333335e-05,
      "loss": 0.0021,
      "step": 1590
    },
    {
      "epoch": 0.17777777777777778,
      "grad_norm": 0.44087404012680054,
      "learning_rate": 4.555555555555556e-05,
      "loss": 0.0027,
      "step": 1600
    },
    {
      "epoch": 0.17888888888888888,
      "grad_norm": 0.22040177881717682,
      "learning_rate": 4.5527777777777784e-05,
      "loss": 0.0012,
      "step": 1610
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.3210013508796692,
      "learning_rate": 4.55e-05,
      "loss": 0.0049,
      "step": 1620
    },
    {
      "epoch": 0.1811111111111111,
      "grad_norm": 0.836098313331604,
      "learning_rate": 4.5472222222222226e-05,
      "loss": 0.0029,
      "step": 1630
    },
    {
      "epoch": 0.18222222222222223,
      "grad_norm": 1.0060579776763916,
      "learning_rate": 4.5444444444444444e-05,
      "loss": 0.0023,
      "step": 1640
    },
    {
      "epoch": 0.18333333333333332,
      "grad_norm": 1.704818606376648,
      "learning_rate": 4.541666666666667e-05,
      "loss": 0.0027,
      "step": 1650
    },
    {
      "epoch": 0.18444444444444444,
      "grad_norm": 0.20699933171272278,
      "learning_rate": 4.538888888888889e-05,
      "loss": 0.0041,
      "step": 1660
    },
    {
      "epoch": 0.18555555555555556,
      "grad_norm": 1.2690283060073853,
      "learning_rate": 4.536111111111112e-05,
      "loss": 0.0028,
      "step": 1670
    },
    {
      "epoch": 0.18666666666666668,
      "grad_norm": 1.7788488864898682,
      "learning_rate": 4.5333333333333335e-05,
      "loss": 0.0027,
      "step": 1680
    },
    {
      "epoch": 0.18777777777777777,
      "grad_norm": 0.6210315823554993,
      "learning_rate": 4.530555555555556e-05,
      "loss": 0.0035,
      "step": 1690
    },
    {
      "epoch": 0.18888888888888888,
      "grad_norm": 0.9730743765830994,
      "learning_rate": 4.527777777777778e-05,
      "loss": 0.0033,
      "step": 1700
    },
    {
      "epoch": 0.19,
      "grad_norm": 1.2532382011413574,
      "learning_rate": 4.525e-05,
      "loss": 0.0025,
      "step": 1710
    },
    {
      "epoch": 0.19111111111111112,
      "grad_norm": 0.23767679929733276,
      "learning_rate": 4.522222222222223e-05,
      "loss": 0.0035,
      "step": 1720
    },
    {
      "epoch": 0.1922222222222222,
      "grad_norm": 0.3403467535972595,
      "learning_rate": 4.5194444444444444e-05,
      "loss": 0.003,
      "step": 1730
    },
    {
      "epoch": 0.19333333333333333,
      "grad_norm": 1.859349250793457,
      "learning_rate": 4.516666666666667e-05,
      "loss": 0.0037,
      "step": 1740
    },
    {
      "epoch": 0.19444444444444445,
      "grad_norm": 0.9530767798423767,
      "learning_rate": 4.5138888888888894e-05,
      "loss": 0.0035,
      "step": 1750
    },
    {
      "epoch": 0.19555555555555557,
      "grad_norm": 1.2371941804885864,
      "learning_rate": 4.511111111111112e-05,
      "loss": 0.0055,
      "step": 1760
    },
    {
      "epoch": 0.19666666666666666,
      "grad_norm": 1.4395229816436768,
      "learning_rate": 4.5083333333333336e-05,
      "loss": 0.0033,
      "step": 1770
    },
    {
      "epoch": 0.19777777777777777,
      "grad_norm": 0.6814742684364319,
      "learning_rate": 4.5055555555555554e-05,
      "loss": 0.0045,
      "step": 1780
    },
    {
      "epoch": 0.1988888888888889,
      "grad_norm": 1.6312822103500366,
      "learning_rate": 4.502777777777778e-05,
      "loss": 0.0043,
      "step": 1790
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.7591491937637329,
      "learning_rate": 4.5e-05,
      "loss": 0.0024,
      "step": 1800
    },
    {
      "epoch": 0.2011111111111111,
      "grad_norm": 0.8300706744194031,
      "learning_rate": 4.497222222222223e-05,
      "loss": 0.0023,
      "step": 1810
    },
    {
      "epoch": 0.20222222222222222,
      "grad_norm": 0.2716841697692871,
      "learning_rate": 4.4944444444444445e-05,
      "loss": 0.002,
      "step": 1820
    },
    {
      "epoch": 0.20333333333333334,
      "grad_norm": 2.0597951412200928,
      "learning_rate": 4.491666666666667e-05,
      "loss": 0.0025,
      "step": 1830
    },
    {
      "epoch": 0.20444444444444446,
      "grad_norm": 0.487608402967453,
      "learning_rate": 4.4888888888888894e-05,
      "loss": 0.0019,
      "step": 1840
    },
    {
      "epoch": 0.20555555555555555,
      "grad_norm": 1.1484745740890503,
      "learning_rate": 4.486111111111111e-05,
      "loss": 0.0029,
      "step": 1850
    },
    {
      "epoch": 0.20666666666666667,
      "grad_norm": 0.9166586995124817,
      "learning_rate": 4.483333333333333e-05,
      "loss": 0.0036,
      "step": 1860
    },
    {
      "epoch": 0.20777777777777778,
      "grad_norm": 0.289020299911499,
      "learning_rate": 4.4805555555555554e-05,
      "loss": 0.0025,
      "step": 1870
    },
    {
      "epoch": 0.2088888888888889,
      "grad_norm": 0.8196869492530823,
      "learning_rate": 4.477777777777778e-05,
      "loss": 0.0031,
      "step": 1880
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.6912788152694702,
      "learning_rate": 4.4750000000000004e-05,
      "loss": 0.0034,
      "step": 1890
    },
    {
      "epoch": 0.2111111111111111,
      "grad_norm": 0.338276207447052,
      "learning_rate": 4.472222222222223e-05,
      "loss": 0.0021,
      "step": 1900
    },
    {
      "epoch": 0.21222222222222223,
      "grad_norm": 0.8765454292297363,
      "learning_rate": 4.4694444444444446e-05,
      "loss": 0.0032,
      "step": 1910
    },
    {
      "epoch": 0.21333333333333335,
      "grad_norm": 1.666841745376587,
      "learning_rate": 4.466666666666667e-05,
      "loss": 0.0047,
      "step": 1920
    },
    {
      "epoch": 0.21444444444444444,
      "grad_norm": 0.7913281917572021,
      "learning_rate": 4.463888888888889e-05,
      "loss": 0.0034,
      "step": 1930
    },
    {
      "epoch": 0.21555555555555556,
      "grad_norm": 1.4937262535095215,
      "learning_rate": 4.461111111111111e-05,
      "loss": 0.0038,
      "step": 1940
    },
    {
      "epoch": 0.21666666666666667,
      "grad_norm": 1.8378158807754517,
      "learning_rate": 4.458333333333334e-05,
      "loss": 0.004,
      "step": 1950
    },
    {
      "epoch": 0.21777777777777776,
      "grad_norm": 0.7926437854766846,
      "learning_rate": 4.4555555555555555e-05,
      "loss": 0.0023,
      "step": 1960
    },
    {
      "epoch": 0.21888888888888888,
      "grad_norm": 1.823100209236145,
      "learning_rate": 4.452777777777778e-05,
      "loss": 0.0027,
      "step": 1970
    },
    {
      "epoch": 0.22,
      "grad_norm": 1.9020873308181763,
      "learning_rate": 4.4500000000000004e-05,
      "loss": 0.0031,
      "step": 1980
    },
    {
      "epoch": 0.22111111111111112,
      "grad_norm": 0.6097890734672546,
      "learning_rate": 4.447222222222223e-05,
      "loss": 0.0024,
      "step": 1990
    },
    {
      "epoch": 0.2222222222222222,
      "grad_norm": 0.6424171328544617,
      "learning_rate": 4.4444444444444447e-05,
      "loss": 0.0033,
      "step": 2000
    },
    {
      "epoch": 0.22333333333333333,
      "grad_norm": 0.6614252328872681,
      "learning_rate": 4.4416666666666664e-05,
      "loss": 0.0028,
      "step": 2010
    },
    {
      "epoch": 0.22444444444444445,
      "grad_norm": 1.6081769466400146,
      "learning_rate": 4.438888888888889e-05,
      "loss": 0.0034,
      "step": 2020
    },
    {
      "epoch": 0.22555555555555556,
      "grad_norm": 1.9824424982070923,
      "learning_rate": 4.4361111111111113e-05,
      "loss": 0.0031,
      "step": 2030
    },
    {
      "epoch": 0.22666666666666666,
      "grad_norm": 0.402626633644104,
      "learning_rate": 4.433333333333334e-05,
      "loss": 0.003,
      "step": 2040
    },
    {
      "epoch": 0.22777777777777777,
      "grad_norm": 0.24620580673217773,
      "learning_rate": 4.4305555555555556e-05,
      "loss": 0.0018,
      "step": 2050
    },
    {
      "epoch": 0.2288888888888889,
      "grad_norm": 0.5120841264724731,
      "learning_rate": 4.427777777777778e-05,
      "loss": 0.0023,
      "step": 2060
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.3065105080604553,
      "learning_rate": 4.4250000000000005e-05,
      "loss": 0.0029,
      "step": 2070
    },
    {
      "epoch": 0.2311111111111111,
      "grad_norm": 1.0012047290802002,
      "learning_rate": 4.422222222222222e-05,
      "loss": 0.0039,
      "step": 2080
    },
    {
      "epoch": 0.23222222222222222,
      "grad_norm": 2.190959930419922,
      "learning_rate": 4.419444444444444e-05,
      "loss": 0.003,
      "step": 2090
    },
    {
      "epoch": 0.23333333333333334,
      "grad_norm": 0.4849998950958252,
      "learning_rate": 4.4166666666666665e-05,
      "loss": 0.0043,
      "step": 2100
    },
    {
      "epoch": 0.23444444444444446,
      "grad_norm": 1.0034958124160767,
      "learning_rate": 4.413888888888889e-05,
      "loss": 0.003,
      "step": 2110
    },
    {
      "epoch": 0.23555555555555555,
      "grad_norm": 1.2255363464355469,
      "learning_rate": 4.4111111111111114e-05,
      "loss": 0.0027,
      "step": 2120
    },
    {
      "epoch": 0.23666666666666666,
      "grad_norm": 0.7775565385818481,
      "learning_rate": 4.408333333333334e-05,
      "loss": 0.0036,
      "step": 2130
    },
    {
      "epoch": 0.23777777777777778,
      "grad_norm": 0.6496701836585999,
      "learning_rate": 4.4055555555555557e-05,
      "loss": 0.0017,
      "step": 2140
    },
    {
      "epoch": 0.2388888888888889,
      "grad_norm": 0.6191654205322266,
      "learning_rate": 4.402777777777778e-05,
      "loss": 0.0033,
      "step": 2150
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.4452304244041443,
      "learning_rate": 4.4000000000000006e-05,
      "loss": 0.0035,
      "step": 2160
    },
    {
      "epoch": 0.2411111111111111,
      "grad_norm": 0.23689112067222595,
      "learning_rate": 4.3972222222222223e-05,
      "loss": 0.0017,
      "step": 2170
    },
    {
      "epoch": 0.24222222222222223,
      "grad_norm": 0.24676251411437988,
      "learning_rate": 4.394444444444445e-05,
      "loss": 0.002,
      "step": 2180
    },
    {
      "epoch": 0.24333333333333335,
      "grad_norm": 1.3038575649261475,
      "learning_rate": 4.3916666666666666e-05,
      "loss": 0.0031,
      "step": 2190
    },
    {
      "epoch": 0.24444444444444444,
      "grad_norm": 0.9197463989257812,
      "learning_rate": 4.388888888888889e-05,
      "loss": 0.0041,
      "step": 2200
    },
    {
      "epoch": 0.24555555555555555,
      "grad_norm": 0.31884050369262695,
      "learning_rate": 4.3861111111111115e-05,
      "loss": 0.0041,
      "step": 2210
    },
    {
      "epoch": 0.24666666666666667,
      "grad_norm": 0.22249652445316315,
      "learning_rate": 4.383333333333334e-05,
      "loss": 0.0041,
      "step": 2220
    },
    {
      "epoch": 0.2477777777777778,
      "grad_norm": 1.3258905410766602,
      "learning_rate": 4.380555555555556e-05,
      "loss": 0.0049,
      "step": 2230
    },
    {
      "epoch": 0.24888888888888888,
      "grad_norm": 0.7949188351631165,
      "learning_rate": 4.377777777777778e-05,
      "loss": 0.0032,
      "step": 2240
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.6179333925247192,
      "learning_rate": 4.375e-05,
      "loss": 0.0025,
      "step": 2250
    },
    {
      "epoch": 0.2511111111111111,
      "grad_norm": 0.8182664513587952,
      "learning_rate": 4.3722222222222224e-05,
      "loss": 0.0042,
      "step": 2260
    },
    {
      "epoch": 0.25222222222222224,
      "grad_norm": 1.7226924896240234,
      "learning_rate": 4.369444444444445e-05,
      "loss": 0.0032,
      "step": 2270
    },
    {
      "epoch": 0.25333333333333335,
      "grad_norm": 0.7557732462882996,
      "learning_rate": 4.3666666666666666e-05,
      "loss": 0.0026,
      "step": 2280
    },
    {
      "epoch": 0.2544444444444444,
      "grad_norm": 0.8885076642036438,
      "learning_rate": 4.363888888888889e-05,
      "loss": 0.0047,
      "step": 2290
    },
    {
      "epoch": 0.25555555555555554,
      "grad_norm": 0.729784369468689,
      "learning_rate": 4.3611111111111116e-05,
      "loss": 0.004,
      "step": 2300
    },
    {
      "epoch": 0.25666666666666665,
      "grad_norm": 0.7717751264572144,
      "learning_rate": 4.358333333333334e-05,
      "loss": 0.005,
      "step": 2310
    },
    {
      "epoch": 0.2577777777777778,
      "grad_norm": 1.3924404382705688,
      "learning_rate": 4.355555555555556e-05,
      "loss": 0.0028,
      "step": 2320
    },
    {
      "epoch": 0.2588888888888889,
      "grad_norm": 1.7863975763320923,
      "learning_rate": 4.3527777777777776e-05,
      "loss": 0.0044,
      "step": 2330
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.49696972966194153,
      "learning_rate": 4.35e-05,
      "loss": 0.0024,
      "step": 2340
    },
    {
      "epoch": 0.2611111111111111,
      "grad_norm": 0.380403608083725,
      "learning_rate": 4.3472222222222225e-05,
      "loss": 0.003,
      "step": 2350
    },
    {
      "epoch": 0.26222222222222225,
      "grad_norm": 1.2035452127456665,
      "learning_rate": 4.344444444444445e-05,
      "loss": 0.0032,
      "step": 2360
    },
    {
      "epoch": 0.2633333333333333,
      "grad_norm": 0.9272711277008057,
      "learning_rate": 4.341666666666667e-05,
      "loss": 0.003,
      "step": 2370
    },
    {
      "epoch": 0.2644444444444444,
      "grad_norm": 1.1932761669158936,
      "learning_rate": 4.338888888888889e-05,
      "loss": 0.0044,
      "step": 2380
    },
    {
      "epoch": 0.26555555555555554,
      "grad_norm": 0.9592673182487488,
      "learning_rate": 4.3361111111111116e-05,
      "loss": 0.0038,
      "step": 2390
    },
    {
      "epoch": 0.26666666666666666,
      "grad_norm": 1.0702184438705444,
      "learning_rate": 4.3333333333333334e-05,
      "loss": 0.0019,
      "step": 2400
    },
    {
      "epoch": 0.2677777777777778,
      "grad_norm": 0.7164571285247803,
      "learning_rate": 4.330555555555556e-05,
      "loss": 0.003,
      "step": 2410
    },
    {
      "epoch": 0.2688888888888889,
      "grad_norm": 1.5783580541610718,
      "learning_rate": 4.3277777777777776e-05,
      "loss": 0.0026,
      "step": 2420
    },
    {
      "epoch": 0.27,
      "grad_norm": 1.4887899160385132,
      "learning_rate": 4.325e-05,
      "loss": 0.0029,
      "step": 2430
    },
    {
      "epoch": 0.27111111111111114,
      "grad_norm": 2.233668327331543,
      "learning_rate": 4.3222222222222226e-05,
      "loss": 0.0021,
      "step": 2440
    },
    {
      "epoch": 0.2722222222222222,
      "grad_norm": 0.9266456365585327,
      "learning_rate": 4.319444444444445e-05,
      "loss": 0.0024,
      "step": 2450
    },
    {
      "epoch": 0.2733333333333333,
      "grad_norm": 0.6984192728996277,
      "learning_rate": 4.316666666666667e-05,
      "loss": 0.0033,
      "step": 2460
    },
    {
      "epoch": 0.27444444444444444,
      "grad_norm": 1.0088837146759033,
      "learning_rate": 4.313888888888889e-05,
      "loss": 0.0044,
      "step": 2470
    },
    {
      "epoch": 0.27555555555555555,
      "grad_norm": 2.015071392059326,
      "learning_rate": 4.311111111111111e-05,
      "loss": 0.004,
      "step": 2480
    },
    {
      "epoch": 0.27666666666666667,
      "grad_norm": 0.6231352686882019,
      "learning_rate": 4.3083333333333335e-05,
      "loss": 0.003,
      "step": 2490
    },
    {
      "epoch": 0.2777777777777778,
      "grad_norm": 1.3409008979797363,
      "learning_rate": 4.305555555555556e-05,
      "loss": 0.0022,
      "step": 2500
    },
    {
      "epoch": 0.2788888888888889,
      "grad_norm": 0.7710054516792297,
      "learning_rate": 4.302777777777778e-05,
      "loss": 0.003,
      "step": 2510
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.9457400441169739,
      "learning_rate": 4.3e-05,
      "loss": 0.0023,
      "step": 2520
    },
    {
      "epoch": 0.2811111111111111,
      "grad_norm": 0.4102317988872528,
      "learning_rate": 4.2972222222222226e-05,
      "loss": 0.0029,
      "step": 2530
    },
    {
      "epoch": 0.2822222222222222,
      "grad_norm": 0.2644469738006592,
      "learning_rate": 4.294444444444445e-05,
      "loss": 0.0029,
      "step": 2540
    },
    {
      "epoch": 0.2833333333333333,
      "grad_norm": 1.9885526895523071,
      "learning_rate": 4.291666666666667e-05,
      "loss": 0.003,
      "step": 2550
    },
    {
      "epoch": 0.28444444444444444,
      "grad_norm": 0.43215224146842957,
      "learning_rate": 4.2888888888888886e-05,
      "loss": 0.0038,
      "step": 2560
    },
    {
      "epoch": 0.28555555555555556,
      "grad_norm": 0.36223307251930237,
      "learning_rate": 4.286111111111111e-05,
      "loss": 0.0028,
      "step": 2570
    },
    {
      "epoch": 0.2866666666666667,
      "grad_norm": 0.5215763449668884,
      "learning_rate": 4.2833333333333335e-05,
      "loss": 0.0041,
      "step": 2580
    },
    {
      "epoch": 0.2877777777777778,
      "grad_norm": 0.2760792374610901,
      "learning_rate": 4.280555555555556e-05,
      "loss": 0.0028,
      "step": 2590
    },
    {
      "epoch": 0.28888888888888886,
      "grad_norm": 0.6205505728721619,
      "learning_rate": 4.277777777777778e-05,
      "loss": 0.0013,
      "step": 2600
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.6987556219100952,
      "learning_rate": 4.275e-05,
      "loss": 0.003,
      "step": 2610
    },
    {
      "epoch": 0.2911111111111111,
      "grad_norm": 1.0275969505310059,
      "learning_rate": 4.272222222222223e-05,
      "loss": 0.0026,
      "step": 2620
    },
    {
      "epoch": 0.2922222222222222,
      "grad_norm": 0.29734334349632263,
      "learning_rate": 4.2694444444444445e-05,
      "loss": 0.0023,
      "step": 2630
    },
    {
      "epoch": 0.29333333333333333,
      "grad_norm": 0.841003954410553,
      "learning_rate": 4.266666666666667e-05,
      "loss": 0.0026,
      "step": 2640
    },
    {
      "epoch": 0.29444444444444445,
      "grad_norm": 0.9071629047393799,
      "learning_rate": 4.263888888888889e-05,
      "loss": 0.0024,
      "step": 2650
    },
    {
      "epoch": 0.29555555555555557,
      "grad_norm": 0.9255874752998352,
      "learning_rate": 4.261111111111111e-05,
      "loss": 0.0021,
      "step": 2660
    },
    {
      "epoch": 0.2966666666666667,
      "grad_norm": 0.6175210475921631,
      "learning_rate": 4.2583333333333336e-05,
      "loss": 0.0037,
      "step": 2670
    },
    {
      "epoch": 0.29777777777777775,
      "grad_norm": 0.6470442414283752,
      "learning_rate": 4.255555555555556e-05,
      "loss": 0.0024,
      "step": 2680
    },
    {
      "epoch": 0.29888888888888887,
      "grad_norm": 1.0387325286865234,
      "learning_rate": 4.252777777777778e-05,
      "loss": 0.002,
      "step": 2690
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.4479096233844757,
      "learning_rate": 4.25e-05,
      "loss": 0.0025,
      "step": 2700
    },
    {
      "epoch": 0.3011111111111111,
      "grad_norm": 0.6225482225418091,
      "learning_rate": 4.247222222222223e-05,
      "loss": 0.0019,
      "step": 2710
    },
    {
      "epoch": 0.3022222222222222,
      "grad_norm": 0.38489505648612976,
      "learning_rate": 4.2444444444444445e-05,
      "loss": 0.0033,
      "step": 2720
    },
    {
      "epoch": 0.30333333333333334,
      "grad_norm": 0.4938759207725525,
      "learning_rate": 4.241666666666667e-05,
      "loss": 0.0032,
      "step": 2730
    },
    {
      "epoch": 0.30444444444444446,
      "grad_norm": 0.5592071413993835,
      "learning_rate": 4.238888888888889e-05,
      "loss": 0.0055,
      "step": 2740
    },
    {
      "epoch": 0.3055555555555556,
      "grad_norm": 0.7391082644462585,
      "learning_rate": 4.236111111111111e-05,
      "loss": 0.0021,
      "step": 2750
    },
    {
      "epoch": 0.30666666666666664,
      "grad_norm": 0.964409351348877,
      "learning_rate": 4.233333333333334e-05,
      "loss": 0.0022,
      "step": 2760
    },
    {
      "epoch": 0.30777777777777776,
      "grad_norm": 0.4809102416038513,
      "learning_rate": 4.230555555555556e-05,
      "loss": 0.003,
      "step": 2770
    },
    {
      "epoch": 0.3088888888888889,
      "grad_norm": 0.3452770411968231,
      "learning_rate": 4.227777777777778e-05,
      "loss": 0.0036,
      "step": 2780
    },
    {
      "epoch": 0.31,
      "grad_norm": 1.1908527612686157,
      "learning_rate": 4.2250000000000004e-05,
      "loss": 0.0029,
      "step": 2790
    },
    {
      "epoch": 0.3111111111111111,
      "grad_norm": 0.5286042094230652,
      "learning_rate": 4.222222222222222e-05,
      "loss": 0.0028,
      "step": 2800
    },
    {
      "epoch": 0.31222222222222223,
      "grad_norm": 0.8948708176612854,
      "learning_rate": 4.2194444444444446e-05,
      "loss": 0.0025,
      "step": 2810
    },
    {
      "epoch": 0.31333333333333335,
      "grad_norm": 0.8834894299507141,
      "learning_rate": 4.216666666666667e-05,
      "loss": 0.0027,
      "step": 2820
    },
    {
      "epoch": 0.31444444444444447,
      "grad_norm": 0.4649202823638916,
      "learning_rate": 4.213888888888889e-05,
      "loss": 0.0033,
      "step": 2830
    },
    {
      "epoch": 0.31555555555555553,
      "grad_norm": 0.6467373371124268,
      "learning_rate": 4.211111111111111e-05,
      "loss": 0.0025,
      "step": 2840
    },
    {
      "epoch": 0.31666666666666665,
      "grad_norm": 0.9342171549797058,
      "learning_rate": 4.208333333333334e-05,
      "loss": 0.0021,
      "step": 2850
    },
    {
      "epoch": 0.31777777777777777,
      "grad_norm": 1.2954952716827393,
      "learning_rate": 4.205555555555556e-05,
      "loss": 0.0026,
      "step": 2860
    },
    {
      "epoch": 0.3188888888888889,
      "grad_norm": 1.3181911706924438,
      "learning_rate": 4.202777777777778e-05,
      "loss": 0.0026,
      "step": 2870
    },
    {
      "epoch": 0.32,
      "grad_norm": 1.301188588142395,
      "learning_rate": 4.2e-05,
      "loss": 0.0025,
      "step": 2880
    },
    {
      "epoch": 0.3211111111111111,
      "grad_norm": 1.5072556734085083,
      "learning_rate": 4.197222222222222e-05,
      "loss": 0.0031,
      "step": 2890
    },
    {
      "epoch": 0.32222222222222224,
      "grad_norm": 0.5145612359046936,
      "learning_rate": 4.194444444444445e-05,
      "loss": 0.0024,
      "step": 2900
    },
    {
      "epoch": 0.3233333333333333,
      "grad_norm": 0.8214753270149231,
      "learning_rate": 4.191666666666667e-05,
      "loss": 0.0033,
      "step": 2910
    },
    {
      "epoch": 0.3244444444444444,
      "grad_norm": 0.42867064476013184,
      "learning_rate": 4.188888888888889e-05,
      "loss": 0.0044,
      "step": 2920
    },
    {
      "epoch": 0.32555555555555554,
      "grad_norm": 0.4364844262599945,
      "learning_rate": 4.1861111111111114e-05,
      "loss": 0.0025,
      "step": 2930
    },
    {
      "epoch": 0.32666666666666666,
      "grad_norm": 0.5343170762062073,
      "learning_rate": 4.183333333333334e-05,
      "loss": 0.0023,
      "step": 2940
    },
    {
      "epoch": 0.3277777777777778,
      "grad_norm": 0.8534681797027588,
      "learning_rate": 4.1805555555555556e-05,
      "loss": 0.0033,
      "step": 2950
    },
    {
      "epoch": 0.3288888888888889,
      "grad_norm": 1.1223812103271484,
      "learning_rate": 4.177777777777778e-05,
      "loss": 0.0037,
      "step": 2960
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.3912811577320099,
      "learning_rate": 4.175e-05,
      "loss": 0.0027,
      "step": 2970
    },
    {
      "epoch": 0.33111111111111113,
      "grad_norm": 1.3171850442886353,
      "learning_rate": 4.172222222222222e-05,
      "loss": 0.004,
      "step": 2980
    },
    {
      "epoch": 0.3322222222222222,
      "grad_norm": 0.43189260363578796,
      "learning_rate": 4.169444444444445e-05,
      "loss": 0.0031,
      "step": 2990
    },
    {
      "epoch": 0.3333333333333333,
      "grad_norm": 1.2583318948745728,
      "learning_rate": 4.166666666666667e-05,
      "loss": 0.0031,
      "step": 3000
    },
    {
      "epoch": 0.33444444444444443,
      "grad_norm": 0.4736776351928711,
      "learning_rate": 4.163888888888889e-05,
      "loss": 0.0035,
      "step": 3010
    },
    {
      "epoch": 0.33555555555555555,
      "grad_norm": 0.3222203850746155,
      "learning_rate": 4.1611111111111114e-05,
      "loss": 0.0024,
      "step": 3020
    },
    {
      "epoch": 0.33666666666666667,
      "grad_norm": 0.7243872880935669,
      "learning_rate": 4.158333333333333e-05,
      "loss": 0.0033,
      "step": 3030
    },
    {
      "epoch": 0.3377777777777778,
      "grad_norm": 0.7015203833580017,
      "learning_rate": 4.155555555555556e-05,
      "loss": 0.0028,
      "step": 3040
    },
    {
      "epoch": 0.3388888888888889,
      "grad_norm": 0.3568875193595886,
      "learning_rate": 4.152777777777778e-05,
      "loss": 0.0033,
      "step": 3050
    },
    {
      "epoch": 0.34,
      "grad_norm": 1.0435445308685303,
      "learning_rate": 4.15e-05,
      "loss": 0.0049,
      "step": 3060
    },
    {
      "epoch": 0.3411111111111111,
      "grad_norm": 1.2440859079360962,
      "learning_rate": 4.1472222222222224e-05,
      "loss": 0.0034,
      "step": 3070
    },
    {
      "epoch": 0.3422222222222222,
      "grad_norm": 0.35998988151550293,
      "learning_rate": 4.144444444444445e-05,
      "loss": 0.0034,
      "step": 3080
    },
    {
      "epoch": 0.3433333333333333,
      "grad_norm": 0.4131912589073181,
      "learning_rate": 4.141666666666667e-05,
      "loss": 0.0032,
      "step": 3090
    },
    {
      "epoch": 0.34444444444444444,
      "grad_norm": 0.6788975596427917,
      "learning_rate": 4.138888888888889e-05,
      "loss": 0.0026,
      "step": 3100
    },
    {
      "epoch": 0.34555555555555556,
      "grad_norm": 0.9359388947486877,
      "learning_rate": 4.136111111111111e-05,
      "loss": 0.0019,
      "step": 3110
    },
    {
      "epoch": 0.3466666666666667,
      "grad_norm": 0.37836456298828125,
      "learning_rate": 4.133333333333333e-05,
      "loss": 0.0033,
      "step": 3120
    },
    {
      "epoch": 0.3477777777777778,
      "grad_norm": 0.6012294292449951,
      "learning_rate": 4.130555555555556e-05,
      "loss": 0.0035,
      "step": 3130
    },
    {
      "epoch": 0.3488888888888889,
      "grad_norm": 0.682543158531189,
      "learning_rate": 4.127777777777778e-05,
      "loss": 0.0029,
      "step": 3140
    },
    {
      "epoch": 0.35,
      "grad_norm": 1.2086673974990845,
      "learning_rate": 4.125e-05,
      "loss": 0.0028,
      "step": 3150
    },
    {
      "epoch": 0.3511111111111111,
      "grad_norm": 0.9373343586921692,
      "learning_rate": 4.1222222222222224e-05,
      "loss": 0.0038,
      "step": 3160
    },
    {
      "epoch": 0.3522222222222222,
      "grad_norm": 0.8215547204017639,
      "learning_rate": 4.119444444444445e-05,
      "loss": 0.0036,
      "step": 3170
    },
    {
      "epoch": 0.35333333333333333,
      "grad_norm": 0.7755266427993774,
      "learning_rate": 4.116666666666667e-05,
      "loss": 0.0054,
      "step": 3180
    },
    {
      "epoch": 0.35444444444444445,
      "grad_norm": 1.5825809240341187,
      "learning_rate": 4.113888888888889e-05,
      "loss": 0.0021,
      "step": 3190
    },
    {
      "epoch": 0.35555555555555557,
      "grad_norm": 0.8621925115585327,
      "learning_rate": 4.111111111111111e-05,
      "loss": 0.0038,
      "step": 3200
    },
    {
      "epoch": 0.3566666666666667,
      "grad_norm": 0.7156771421432495,
      "learning_rate": 4.1083333333333334e-05,
      "loss": 0.0036,
      "step": 3210
    },
    {
      "epoch": 0.35777777777777775,
      "grad_norm": 0.4882987141609192,
      "learning_rate": 4.105555555555556e-05,
      "loss": 0.0029,
      "step": 3220
    },
    {
      "epoch": 0.35888888888888887,
      "grad_norm": 0.34258243441581726,
      "learning_rate": 4.102777777777778e-05,
      "loss": 0.0035,
      "step": 3230
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.7781195044517517,
      "learning_rate": 4.1e-05,
      "loss": 0.0024,
      "step": 3240
    },
    {
      "epoch": 0.3611111111111111,
      "grad_norm": 2.2470855712890625,
      "learning_rate": 4.0972222222222225e-05,
      "loss": 0.0047,
      "step": 3250
    },
    {
      "epoch": 0.3622222222222222,
      "grad_norm": 0.5828129649162292,
      "learning_rate": 4.094444444444445e-05,
      "loss": 0.0024,
      "step": 3260
    },
    {
      "epoch": 0.36333333333333334,
      "grad_norm": 0.8406656384468079,
      "learning_rate": 4.091666666666667e-05,
      "loss": 0.0031,
      "step": 3270
    },
    {
      "epoch": 0.36444444444444446,
      "grad_norm": 0.8501036763191223,
      "learning_rate": 4.088888888888889e-05,
      "loss": 0.0028,
      "step": 3280
    },
    {
      "epoch": 0.3655555555555556,
      "grad_norm": 0.8627871870994568,
      "learning_rate": 4.086111111111111e-05,
      "loss": 0.0037,
      "step": 3290
    },
    {
      "epoch": 0.36666666666666664,
      "grad_norm": 1.0523487329483032,
      "learning_rate": 4.0833333333333334e-05,
      "loss": 0.0025,
      "step": 3300
    },
    {
      "epoch": 0.36777777777777776,
      "grad_norm": 1.0745174884796143,
      "learning_rate": 4.080555555555556e-05,
      "loss": 0.0029,
      "step": 3310
    },
    {
      "epoch": 0.3688888888888889,
      "grad_norm": 1.1270332336425781,
      "learning_rate": 4.0777777777777783e-05,
      "loss": 0.0022,
      "step": 3320
    },
    {
      "epoch": 0.37,
      "grad_norm": 1.0334306955337524,
      "learning_rate": 4.075e-05,
      "loss": 0.0028,
      "step": 3330
    },
    {
      "epoch": 0.3711111111111111,
      "grad_norm": 0.9131604433059692,
      "learning_rate": 4.0722222222222226e-05,
      "loss": 0.0024,
      "step": 3340
    },
    {
      "epoch": 0.37222222222222223,
      "grad_norm": 0.45440372824668884,
      "learning_rate": 4.0694444444444444e-05,
      "loss": 0.0039,
      "step": 3350
    },
    {
      "epoch": 0.37333333333333335,
      "grad_norm": 1.6489875316619873,
      "learning_rate": 4.066666666666667e-05,
      "loss": 0.0025,
      "step": 3360
    },
    {
      "epoch": 0.37444444444444447,
      "grad_norm": 0.6576839685440063,
      "learning_rate": 4.063888888888889e-05,
      "loss": 0.0017,
      "step": 3370
    },
    {
      "epoch": 0.37555555555555553,
      "grad_norm": 0.2820996046066284,
      "learning_rate": 4.061111111111111e-05,
      "loss": 0.0026,
      "step": 3380
    },
    {
      "epoch": 0.37666666666666665,
      "grad_norm": 1.2745232582092285,
      "learning_rate": 4.0583333333333335e-05,
      "loss": 0.0027,
      "step": 3390
    },
    {
      "epoch": 0.37777777777777777,
      "grad_norm": 1.4632282257080078,
      "learning_rate": 4.055555555555556e-05,
      "loss": 0.002,
      "step": 3400
    },
    {
      "epoch": 0.3788888888888889,
      "grad_norm": 1.383358120918274,
      "learning_rate": 4.0527777777777784e-05,
      "loss": 0.0028,
      "step": 3410
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.5754746198654175,
      "learning_rate": 4.05e-05,
      "loss": 0.0038,
      "step": 3420
    },
    {
      "epoch": 0.3811111111111111,
      "grad_norm": 0.6732253432273865,
      "learning_rate": 4.047222222222222e-05,
      "loss": 0.0027,
      "step": 3430
    },
    {
      "epoch": 0.38222222222222224,
      "grad_norm": 0.47870099544525146,
      "learning_rate": 4.0444444444444444e-05,
      "loss": 0.0025,
      "step": 3440
    },
    {
      "epoch": 0.38333333333333336,
      "grad_norm": 0.6812795996665955,
      "learning_rate": 4.041666666666667e-05,
      "loss": 0.0017,
      "step": 3450
    },
    {
      "epoch": 0.3844444444444444,
      "grad_norm": 0.6160933971405029,
      "learning_rate": 4.038888888888889e-05,
      "loss": 0.0057,
      "step": 3460
    },
    {
      "epoch": 0.38555555555555554,
      "grad_norm": 0.2586503028869629,
      "learning_rate": 4.036111111111111e-05,
      "loss": 0.0027,
      "step": 3470
    },
    {
      "epoch": 0.38666666666666666,
      "grad_norm": 0.21916690468788147,
      "learning_rate": 4.0333333333333336e-05,
      "loss": 0.0021,
      "step": 3480
    },
    {
      "epoch": 0.3877777777777778,
      "grad_norm": 0.332112580537796,
      "learning_rate": 4.030555555555556e-05,
      "loss": 0.0041,
      "step": 3490
    },
    {
      "epoch": 0.3888888888888889,
      "grad_norm": 1.0147250890731812,
      "learning_rate": 4.027777777777778e-05,
      "loss": 0.0013,
      "step": 3500
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.7282718420028687,
      "learning_rate": 4.025e-05,
      "loss": 0.0026,
      "step": 3510
    },
    {
      "epoch": 0.39111111111111113,
      "grad_norm": 1.1497721672058105,
      "learning_rate": 4.022222222222222e-05,
      "loss": 0.0022,
      "step": 3520
    },
    {
      "epoch": 0.39222222222222225,
      "grad_norm": 0.5510079860687256,
      "learning_rate": 4.0194444444444445e-05,
      "loss": 0.0028,
      "step": 3530
    },
    {
      "epoch": 0.3933333333333333,
      "grad_norm": 1.2739661931991577,
      "learning_rate": 4.016666666666667e-05,
      "loss": 0.0032,
      "step": 3540
    },
    {
      "epoch": 0.39444444444444443,
      "grad_norm": 0.6730904579162598,
      "learning_rate": 4.0138888888888894e-05,
      "loss": 0.003,
      "step": 3550
    },
    {
      "epoch": 0.39555555555555555,
      "grad_norm": 0.2532411515712738,
      "learning_rate": 4.011111111111111e-05,
      "loss": 0.002,
      "step": 3560
    },
    {
      "epoch": 0.39666666666666667,
      "grad_norm": 0.29374948143959045,
      "learning_rate": 4.0083333333333336e-05,
      "loss": 0.0021,
      "step": 3570
    },
    {
      "epoch": 0.3977777777777778,
      "grad_norm": 1.0296905040740967,
      "learning_rate": 4.0055555555555554e-05,
      "loss": 0.0032,
      "step": 3580
    },
    {
      "epoch": 0.3988888888888889,
      "grad_norm": 0.6605075001716614,
      "learning_rate": 4.002777777777778e-05,
      "loss": 0.0017,
      "step": 3590
    },
    {
      "epoch": 0.4,
      "grad_norm": 1.2156758308410645,
      "learning_rate": 4e-05,
      "loss": 0.0024,
      "step": 3600
    },
    {
      "epoch": 0.4011111111111111,
      "grad_norm": 0.4873082637786865,
      "learning_rate": 3.997222222222222e-05,
      "loss": 0.0022,
      "step": 3610
    },
    {
      "epoch": 0.4022222222222222,
      "grad_norm": 1.2842445373535156,
      "learning_rate": 3.9944444444444446e-05,
      "loss": 0.0035,
      "step": 3620
    },
    {
      "epoch": 0.4033333333333333,
      "grad_norm": 0.2783203423023224,
      "learning_rate": 3.991666666666667e-05,
      "loss": 0.0019,
      "step": 3630
    },
    {
      "epoch": 0.40444444444444444,
      "grad_norm": 0.6753761768341064,
      "learning_rate": 3.9888888888888895e-05,
      "loss": 0.0035,
      "step": 3640
    },
    {
      "epoch": 0.40555555555555556,
      "grad_norm": 0.412943571805954,
      "learning_rate": 3.986111111111111e-05,
      "loss": 0.0031,
      "step": 3650
    },
    {
      "epoch": 0.4066666666666667,
      "grad_norm": 0.6810782551765442,
      "learning_rate": 3.983333333333333e-05,
      "loss": 0.0023,
      "step": 3660
    },
    {
      "epoch": 0.4077777777777778,
      "grad_norm": 1.2741096019744873,
      "learning_rate": 3.9805555555555555e-05,
      "loss": 0.0029,
      "step": 3670
    },
    {
      "epoch": 0.4088888888888889,
      "grad_norm": 0.9710729122161865,
      "learning_rate": 3.977777777777778e-05,
      "loss": 0.0025,
      "step": 3680
    },
    {
      "epoch": 0.41,
      "grad_norm": 1.197137475013733,
      "learning_rate": 3.9750000000000004e-05,
      "loss": 0.0028,
      "step": 3690
    },
    {
      "epoch": 0.4111111111111111,
      "grad_norm": 1.1269385814666748,
      "learning_rate": 3.972222222222222e-05,
      "loss": 0.0025,
      "step": 3700
    },
    {
      "epoch": 0.4122222222222222,
      "grad_norm": 0.7792144417762756,
      "learning_rate": 3.9694444444444446e-05,
      "loss": 0.0019,
      "step": 3710
    },
    {
      "epoch": 0.41333333333333333,
      "grad_norm": 0.3710724115371704,
      "learning_rate": 3.966666666666667e-05,
      "loss": 0.0041,
      "step": 3720
    },
    {
      "epoch": 0.41444444444444445,
      "grad_norm": 0.3050025701522827,
      "learning_rate": 3.9638888888888895e-05,
      "loss": 0.0017,
      "step": 3730
    },
    {
      "epoch": 0.41555555555555557,
      "grad_norm": 0.9656577706336975,
      "learning_rate": 3.961111111111111e-05,
      "loss": 0.0041,
      "step": 3740
    },
    {
      "epoch": 0.4166666666666667,
      "grad_norm": 0.47116026282310486,
      "learning_rate": 3.958333333333333e-05,
      "loss": 0.0013,
      "step": 3750
    },
    {
      "epoch": 0.4177777777777778,
      "grad_norm": 0.39445939660072327,
      "learning_rate": 3.9555555555555556e-05,
      "loss": 0.0023,
      "step": 3760
    },
    {
      "epoch": 0.41888888888888887,
      "grad_norm": 0.5686680674552917,
      "learning_rate": 3.952777777777778e-05,
      "loss": 0.0017,
      "step": 3770
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.8759547472000122,
      "learning_rate": 3.9500000000000005e-05,
      "loss": 0.0025,
      "step": 3780
    },
    {
      "epoch": 0.4211111111111111,
      "grad_norm": 1.9731277227401733,
      "learning_rate": 3.947222222222222e-05,
      "loss": 0.0038,
      "step": 3790
    },
    {
      "epoch": 0.4222222222222222,
      "grad_norm": 0.5132455825805664,
      "learning_rate": 3.944444444444445e-05,
      "loss": 0.003,
      "step": 3800
    },
    {
      "epoch": 0.42333333333333334,
      "grad_norm": 0.7649633288383484,
      "learning_rate": 3.941666666666667e-05,
      "loss": 0.0034,
      "step": 3810
    },
    {
      "epoch": 0.42444444444444446,
      "grad_norm": 1.4835139513015747,
      "learning_rate": 3.938888888888889e-05,
      "loss": 0.0031,
      "step": 3820
    },
    {
      "epoch": 0.4255555555555556,
      "grad_norm": 0.43158531188964844,
      "learning_rate": 3.9361111111111114e-05,
      "loss": 0.0028,
      "step": 3830
    },
    {
      "epoch": 0.4266666666666667,
      "grad_norm": 0.3611918091773987,
      "learning_rate": 3.933333333333333e-05,
      "loss": 0.0024,
      "step": 3840
    },
    {
      "epoch": 0.42777777777777776,
      "grad_norm": 0.9966666102409363,
      "learning_rate": 3.9305555555555556e-05,
      "loss": 0.003,
      "step": 3850
    },
    {
      "epoch": 0.4288888888888889,
      "grad_norm": 0.9198718667030334,
      "learning_rate": 3.927777777777778e-05,
      "loss": 0.0031,
      "step": 3860
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.6949105858802795,
      "learning_rate": 3.9250000000000005e-05,
      "loss": 0.0013,
      "step": 3870
    },
    {
      "epoch": 0.4311111111111111,
      "grad_norm": 0.7443214654922485,
      "learning_rate": 3.922222222222223e-05,
      "loss": 0.0046,
      "step": 3880
    },
    {
      "epoch": 0.43222222222222223,
      "grad_norm": 0.4588110148906708,
      "learning_rate": 3.919444444444445e-05,
      "loss": 0.0017,
      "step": 3890
    },
    {
      "epoch": 0.43333333333333335,
      "grad_norm": 0.3499806523323059,
      "learning_rate": 3.9166666666666665e-05,
      "loss": 0.0016,
      "step": 3900
    },
    {
      "epoch": 0.43444444444444447,
      "grad_norm": 0.9138139486312866,
      "learning_rate": 3.913888888888889e-05,
      "loss": 0.0013,
      "step": 3910
    },
    {
      "epoch": 0.43555555555555553,
      "grad_norm": 0.3360236883163452,
      "learning_rate": 3.9111111111111115e-05,
      "loss": 0.0025,
      "step": 3920
    },
    {
      "epoch": 0.43666666666666665,
      "grad_norm": 0.4426015019416809,
      "learning_rate": 3.908333333333333e-05,
      "loss": 0.0023,
      "step": 3930
    },
    {
      "epoch": 0.43777777777777777,
      "grad_norm": 1.6428937911987305,
      "learning_rate": 3.905555555555556e-05,
      "loss": 0.0031,
      "step": 3940
    },
    {
      "epoch": 0.4388888888888889,
      "grad_norm": 1.154129147529602,
      "learning_rate": 3.902777777777778e-05,
      "loss": 0.0018,
      "step": 3950
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.1119245290756226,
      "learning_rate": 3.9000000000000006e-05,
      "loss": 0.0034,
      "step": 3960
    },
    {
      "epoch": 0.4411111111111111,
      "grad_norm": 1.2258347272872925,
      "learning_rate": 3.8972222222222224e-05,
      "loss": 0.0024,
      "step": 3970
    },
    {
      "epoch": 0.44222222222222224,
      "grad_norm": 0.6314541697502136,
      "learning_rate": 3.894444444444444e-05,
      "loss": 0.0031,
      "step": 3980
    },
    {
      "epoch": 0.44333333333333336,
      "grad_norm": 1.0901271104812622,
      "learning_rate": 3.8916666666666666e-05,
      "loss": 0.0028,
      "step": 3990
    },
    {
      "epoch": 0.4444444444444444,
      "grad_norm": 0.9571859240531921,
      "learning_rate": 3.888888888888889e-05,
      "loss": 0.0022,
      "step": 4000
    },
    {
      "epoch": 0.44555555555555554,
      "grad_norm": 0.27720844745635986,
      "learning_rate": 3.8861111111111115e-05,
      "loss": 0.0041,
      "step": 4010
    },
    {
      "epoch": 0.44666666666666666,
      "grad_norm": 0.5727286338806152,
      "learning_rate": 3.883333333333333e-05,
      "loss": 0.0028,
      "step": 4020
    },
    {
      "epoch": 0.4477777777777778,
      "grad_norm": 0.6311402320861816,
      "learning_rate": 3.880555555555556e-05,
      "loss": 0.0045,
      "step": 4030
    },
    {
      "epoch": 0.4488888888888889,
      "grad_norm": 0.6802089810371399,
      "learning_rate": 3.877777777777778e-05,
      "loss": 0.0035,
      "step": 4040
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.9248159527778625,
      "learning_rate": 3.875e-05,
      "loss": 0.0036,
      "step": 4050
    },
    {
      "epoch": 0.45111111111111113,
      "grad_norm": 0.19680406153202057,
      "learning_rate": 3.8722222222222225e-05,
      "loss": 0.0024,
      "step": 4060
    },
    {
      "epoch": 0.45222222222222225,
      "grad_norm": 0.9578199982643127,
      "learning_rate": 3.869444444444444e-05,
      "loss": 0.0026,
      "step": 4070
    },
    {
      "epoch": 0.4533333333333333,
      "grad_norm": 1.548802137374878,
      "learning_rate": 3.866666666666667e-05,
      "loss": 0.0024,
      "step": 4080
    },
    {
      "epoch": 0.45444444444444443,
      "grad_norm": 1.2355377674102783,
      "learning_rate": 3.863888888888889e-05,
      "loss": 0.0019,
      "step": 4090
    },
    {
      "epoch": 0.45555555555555555,
      "grad_norm": 0.7908111810684204,
      "learning_rate": 3.8611111111111116e-05,
      "loss": 0.0027,
      "step": 4100
    },
    {
      "epoch": 0.45666666666666667,
      "grad_norm": 0.8429959416389465,
      "learning_rate": 3.8583333333333334e-05,
      "loss": 0.0021,
      "step": 4110
    },
    {
      "epoch": 0.4577777777777778,
      "grad_norm": 0.1418604552745819,
      "learning_rate": 3.855555555555556e-05,
      "loss": 0.0028,
      "step": 4120
    },
    {
      "epoch": 0.4588888888888889,
      "grad_norm": 0.6989763379096985,
      "learning_rate": 3.8527777777777776e-05,
      "loss": 0.0017,
      "step": 4130
    },
    {
      "epoch": 0.46,
      "grad_norm": 1.6951366662979126,
      "learning_rate": 3.85e-05,
      "loss": 0.0019,
      "step": 4140
    },
    {
      "epoch": 0.46111111111111114,
      "grad_norm": 1.0254820585250854,
      "learning_rate": 3.8472222222222225e-05,
      "loss": 0.0034,
      "step": 4150
    },
    {
      "epoch": 0.4622222222222222,
      "grad_norm": 0.31540173292160034,
      "learning_rate": 3.844444444444444e-05,
      "loss": 0.0028,
      "step": 4160
    },
    {
      "epoch": 0.4633333333333333,
      "grad_norm": 1.55231773853302,
      "learning_rate": 3.841666666666667e-05,
      "loss": 0.0027,
      "step": 4170
    },
    {
      "epoch": 0.46444444444444444,
      "grad_norm": 1.286189079284668,
      "learning_rate": 3.838888888888889e-05,
      "loss": 0.0019,
      "step": 4180
    },
    {
      "epoch": 0.46555555555555556,
      "grad_norm": 0.25547608733177185,
      "learning_rate": 3.836111111111112e-05,
      "loss": 0.0018,
      "step": 4190
    },
    {
      "epoch": 0.4666666666666667,
      "grad_norm": 0.7814409732818604,
      "learning_rate": 3.8333333333333334e-05,
      "loss": 0.0017,
      "step": 4200
    },
    {
      "epoch": 0.4677777777777778,
      "grad_norm": 1.3265653848648071,
      "learning_rate": 3.830555555555555e-05,
      "loss": 0.0029,
      "step": 4210
    },
    {
      "epoch": 0.4688888888888889,
      "grad_norm": 1.6037068367004395,
      "learning_rate": 3.827777777777778e-05,
      "loss": 0.0026,
      "step": 4220
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.092024803161621,
      "learning_rate": 3.825e-05,
      "loss": 0.0023,
      "step": 4230
    },
    {
      "epoch": 0.4711111111111111,
      "grad_norm": 0.35457566380500793,
      "learning_rate": 3.8222222222222226e-05,
      "loss": 0.0027,
      "step": 4240
    },
    {
      "epoch": 0.4722222222222222,
      "grad_norm": 0.44749927520751953,
      "learning_rate": 3.8194444444444444e-05,
      "loss": 0.0024,
      "step": 4250
    },
    {
      "epoch": 0.47333333333333333,
      "grad_norm": 0.42450568079948425,
      "learning_rate": 3.816666666666667e-05,
      "loss": 0.0012,
      "step": 4260
    },
    {
      "epoch": 0.47444444444444445,
      "grad_norm": 0.7645098567008972,
      "learning_rate": 3.813888888888889e-05,
      "loss": 0.0024,
      "step": 4270
    },
    {
      "epoch": 0.47555555555555556,
      "grad_norm": 0.5022972226142883,
      "learning_rate": 3.811111111111112e-05,
      "loss": 0.0036,
      "step": 4280
    },
    {
      "epoch": 0.4766666666666667,
      "grad_norm": 0.6166990995407104,
      "learning_rate": 3.8083333333333335e-05,
      "loss": 0.0021,
      "step": 4290
    },
    {
      "epoch": 0.4777777777777778,
      "grad_norm": 0.6720030903816223,
      "learning_rate": 3.805555555555555e-05,
      "loss": 0.0028,
      "step": 4300
    },
    {
      "epoch": 0.47888888888888886,
      "grad_norm": 0.5015101432800293,
      "learning_rate": 3.802777777777778e-05,
      "loss": 0.0042,
      "step": 4310
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.6093082427978516,
      "learning_rate": 3.8e-05,
      "loss": 0.0027,
      "step": 4320
    },
    {
      "epoch": 0.4811111111111111,
      "grad_norm": 0.5321515202522278,
      "learning_rate": 3.797222222222223e-05,
      "loss": 0.0027,
      "step": 4330
    },
    {
      "epoch": 0.4822222222222222,
      "grad_norm": 1.2651231288909912,
      "learning_rate": 3.7944444444444444e-05,
      "loss": 0.0026,
      "step": 4340
    },
    {
      "epoch": 0.48333333333333334,
      "grad_norm": 0.764187216758728,
      "learning_rate": 3.791666666666667e-05,
      "loss": 0.0022,
      "step": 4350
    },
    {
      "epoch": 0.48444444444444446,
      "grad_norm": 0.8124554753303528,
      "learning_rate": 3.7888888888888894e-05,
      "loss": 0.0033,
      "step": 4360
    },
    {
      "epoch": 0.4855555555555556,
      "grad_norm": 1.030702829360962,
      "learning_rate": 3.786111111111111e-05,
      "loss": 0.0026,
      "step": 4370
    },
    {
      "epoch": 0.4866666666666667,
      "grad_norm": 0.11635808646678925,
      "learning_rate": 3.7833333333333336e-05,
      "loss": 0.0026,
      "step": 4380
    },
    {
      "epoch": 0.48777777777777775,
      "grad_norm": 0.9499735832214355,
      "learning_rate": 3.7805555555555554e-05,
      "loss": 0.0019,
      "step": 4390
    },
    {
      "epoch": 0.4888888888888889,
      "grad_norm": 0.7744536995887756,
      "learning_rate": 3.777777777777778e-05,
      "loss": 0.0029,
      "step": 4400
    },
    {
      "epoch": 0.49,
      "grad_norm": 1.0056517124176025,
      "learning_rate": 3.775e-05,
      "loss": 0.0036,
      "step": 4410
    },
    {
      "epoch": 0.4911111111111111,
      "grad_norm": 1.116045355796814,
      "learning_rate": 3.772222222222223e-05,
      "loss": 0.004,
      "step": 4420
    },
    {
      "epoch": 0.4922222222222222,
      "grad_norm": 0.30181998014450073,
      "learning_rate": 3.769444444444445e-05,
      "loss": 0.0031,
      "step": 4430
    },
    {
      "epoch": 0.49333333333333335,
      "grad_norm": 1.4166394472122192,
      "learning_rate": 3.766666666666667e-05,
      "loss": 0.0038,
      "step": 4440
    },
    {
      "epoch": 0.49444444444444446,
      "grad_norm": 1.6352380514144897,
      "learning_rate": 3.763888888888889e-05,
      "loss": 0.0034,
      "step": 4450
    },
    {
      "epoch": 0.4955555555555556,
      "grad_norm": 0.31250613927841187,
      "learning_rate": 3.761111111111111e-05,
      "loss": 0.003,
      "step": 4460
    },
    {
      "epoch": 0.49666666666666665,
      "grad_norm": 0.43887361884117126,
      "learning_rate": 3.7583333333333337e-05,
      "loss": 0.0038,
      "step": 4470
    },
    {
      "epoch": 0.49777777777777776,
      "grad_norm": 2.1528241634368896,
      "learning_rate": 3.7555555555555554e-05,
      "loss": 0.0033,
      "step": 4480
    },
    {
      "epoch": 0.4988888888888889,
      "grad_norm": 0.38587453961372375,
      "learning_rate": 3.752777777777778e-05,
      "loss": 0.0041,
      "step": 4490
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.6027277112007141,
      "learning_rate": 3.7500000000000003e-05,
      "loss": 0.0029,
      "step": 4500
    },
    {
      "epoch": 0.5011111111111111,
      "grad_norm": 0.7516794204711914,
      "learning_rate": 3.747222222222223e-05,
      "loss": 0.0016,
      "step": 4510
    },
    {
      "epoch": 0.5022222222222222,
      "grad_norm": 0.6645077466964722,
      "learning_rate": 3.7444444444444446e-05,
      "loss": 0.0037,
      "step": 4520
    },
    {
      "epoch": 0.5033333333333333,
      "grad_norm": 0.9240484833717346,
      "learning_rate": 3.7416666666666664e-05,
      "loss": 0.0033,
      "step": 4530
    },
    {
      "epoch": 0.5044444444444445,
      "grad_norm": 1.4149539470672607,
      "learning_rate": 3.738888888888889e-05,
      "loss": 0.004,
      "step": 4540
    },
    {
      "epoch": 0.5055555555555555,
      "grad_norm": 0.5609406232833862,
      "learning_rate": 3.736111111111111e-05,
      "loss": 0.0022,
      "step": 4550
    },
    {
      "epoch": 0.5066666666666667,
      "grad_norm": 0.37669649720191956,
      "learning_rate": 3.733333333333334e-05,
      "loss": 0.0021,
      "step": 4560
    },
    {
      "epoch": 0.5077777777777778,
      "grad_norm": 0.3835429847240448,
      "learning_rate": 3.7305555555555555e-05,
      "loss": 0.003,
      "step": 4570
    },
    {
      "epoch": 0.5088888888888888,
      "grad_norm": 1.0681025981903076,
      "learning_rate": 3.727777777777778e-05,
      "loss": 0.0025,
      "step": 4580
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.5304321646690369,
      "learning_rate": 3.7250000000000004e-05,
      "loss": 0.0022,
      "step": 4590
    },
    {
      "epoch": 0.5111111111111111,
      "grad_norm": 0.7417749166488647,
      "learning_rate": 3.722222222222222e-05,
      "loss": 0.0027,
      "step": 4600
    },
    {
      "epoch": 0.5122222222222222,
      "grad_norm": 0.42273032665252686,
      "learning_rate": 3.7194444444444447e-05,
      "loss": 0.0031,
      "step": 4610
    },
    {
      "epoch": 0.5133333333333333,
      "grad_norm": 0.9240736961364746,
      "learning_rate": 3.7166666666666664e-05,
      "loss": 0.0029,
      "step": 4620
    },
    {
      "epoch": 0.5144444444444445,
      "grad_norm": 0.7228775024414062,
      "learning_rate": 3.713888888888889e-05,
      "loss": 0.0029,
      "step": 4630
    },
    {
      "epoch": 0.5155555555555555,
      "grad_norm": 0.5774876475334167,
      "learning_rate": 3.7111111111111113e-05,
      "loss": 0.0019,
      "step": 4640
    },
    {
      "epoch": 0.5166666666666667,
      "grad_norm": 0.6028045415878296,
      "learning_rate": 3.708333333333334e-05,
      "loss": 0.0037,
      "step": 4650
    },
    {
      "epoch": 0.5177777777777778,
      "grad_norm": 1.1798055171966553,
      "learning_rate": 3.705555555555556e-05,
      "loss": 0.0027,
      "step": 4660
    },
    {
      "epoch": 0.5188888888888888,
      "grad_norm": 1.0169864892959595,
      "learning_rate": 3.702777777777778e-05,
      "loss": 0.0035,
      "step": 4670
    },
    {
      "epoch": 0.52,
      "grad_norm": 1.4169725179672241,
      "learning_rate": 3.7e-05,
      "loss": 0.0027,
      "step": 4680
    },
    {
      "epoch": 0.5211111111111111,
      "grad_norm": 0.3576868772506714,
      "learning_rate": 3.697222222222222e-05,
      "loss": 0.0027,
      "step": 4690
    },
    {
      "epoch": 0.5222222222222223,
      "grad_norm": 0.38609641790390015,
      "learning_rate": 3.694444444444445e-05,
      "loss": 0.0043,
      "step": 4700
    },
    {
      "epoch": 0.5233333333333333,
      "grad_norm": 1.1137611865997314,
      "learning_rate": 3.6916666666666665e-05,
      "loss": 0.0028,
      "step": 4710
    },
    {
      "epoch": 0.5244444444444445,
      "grad_norm": 0.22101368010044098,
      "learning_rate": 3.688888888888889e-05,
      "loss": 0.0027,
      "step": 4720
    },
    {
      "epoch": 0.5255555555555556,
      "grad_norm": 1.2877793312072754,
      "learning_rate": 3.6861111111111114e-05,
      "loss": 0.0026,
      "step": 4730
    },
    {
      "epoch": 0.5266666666666666,
      "grad_norm": 0.7309991121292114,
      "learning_rate": 3.683333333333334e-05,
      "loss": 0.0038,
      "step": 4740
    },
    {
      "epoch": 0.5277777777777778,
      "grad_norm": 1.621936321258545,
      "learning_rate": 3.6805555555555556e-05,
      "loss": 0.0019,
      "step": 4750
    },
    {
      "epoch": 0.5288888888888889,
      "grad_norm": 1.2808594703674316,
      "learning_rate": 3.677777777777778e-05,
      "loss": 0.0024,
      "step": 4760
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.5587729811668396,
      "learning_rate": 3.675e-05,
      "loss": 0.0033,
      "step": 4770
    },
    {
      "epoch": 0.5311111111111111,
      "grad_norm": 1.7652658224105835,
      "learning_rate": 3.672222222222222e-05,
      "loss": 0.0034,
      "step": 4780
    },
    {
      "epoch": 0.5322222222222223,
      "grad_norm": 0.6126907467842102,
      "learning_rate": 3.669444444444445e-05,
      "loss": 0.004,
      "step": 4790
    },
    {
      "epoch": 0.5333333333333333,
      "grad_norm": 0.634208619594574,
      "learning_rate": 3.6666666666666666e-05,
      "loss": 0.0039,
      "step": 4800
    },
    {
      "epoch": 0.5344444444444445,
      "grad_norm": 0.9661039113998413,
      "learning_rate": 3.663888888888889e-05,
      "loss": 0.0031,
      "step": 4810
    },
    {
      "epoch": 0.5355555555555556,
      "grad_norm": 0.2411777824163437,
      "learning_rate": 3.6611111111111115e-05,
      "loss": 0.0054,
      "step": 4820
    },
    {
      "epoch": 0.5366666666666666,
      "grad_norm": 0.15452061593532562,
      "learning_rate": 3.658333333333334e-05,
      "loss": 0.0022,
      "step": 4830
    },
    {
      "epoch": 0.5377777777777778,
      "grad_norm": 0.37315642833709717,
      "learning_rate": 3.655555555555556e-05,
      "loss": 0.0051,
      "step": 4840
    },
    {
      "epoch": 0.5388888888888889,
      "grad_norm": 0.9661254286766052,
      "learning_rate": 3.6527777777777775e-05,
      "loss": 0.0022,
      "step": 4850
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.8898246884346008,
      "learning_rate": 3.65e-05,
      "loss": 0.0022,
      "step": 4860
    },
    {
      "epoch": 0.5411111111111111,
      "grad_norm": 0.8022931814193726,
      "learning_rate": 3.6472222222222224e-05,
      "loss": 0.0041,
      "step": 4870
    },
    {
      "epoch": 0.5422222222222223,
      "grad_norm": 0.9342001080513,
      "learning_rate": 3.644444444444445e-05,
      "loss": 0.0036,
      "step": 4880
    },
    {
      "epoch": 0.5433333333333333,
      "grad_norm": 0.46307170391082764,
      "learning_rate": 3.641666666666667e-05,
      "loss": 0.003,
      "step": 4890
    },
    {
      "epoch": 0.5444444444444444,
      "grad_norm": 0.3043079376220703,
      "learning_rate": 3.638888888888889e-05,
      "loss": 0.0022,
      "step": 4900
    },
    {
      "epoch": 0.5455555555555556,
      "grad_norm": 1.081870436668396,
      "learning_rate": 3.6361111111111116e-05,
      "loss": 0.002,
      "step": 4910
    },
    {
      "epoch": 0.5466666666666666,
      "grad_norm": 1.183359146118164,
      "learning_rate": 3.633333333333333e-05,
      "loss": 0.0037,
      "step": 4920
    },
    {
      "epoch": 0.5477777777777778,
      "grad_norm": 0.46094441413879395,
      "learning_rate": 3.630555555555556e-05,
      "loss": 0.0022,
      "step": 4930
    },
    {
      "epoch": 0.5488888888888889,
      "grad_norm": 0.6452173590660095,
      "learning_rate": 3.6277777777777776e-05,
      "loss": 0.0019,
      "step": 4940
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.1735759675502777,
      "learning_rate": 3.625e-05,
      "loss": 0.0027,
      "step": 4950
    },
    {
      "epoch": 0.5511111111111111,
      "grad_norm": 0.9253333210945129,
      "learning_rate": 3.6222222222222225e-05,
      "loss": 0.0021,
      "step": 4960
    },
    {
      "epoch": 0.5522222222222222,
      "grad_norm": 0.299134224653244,
      "learning_rate": 3.619444444444445e-05,
      "loss": 0.0025,
      "step": 4970
    },
    {
      "epoch": 0.5533333333333333,
      "grad_norm": 0.9013280272483826,
      "learning_rate": 3.6166666666666674e-05,
      "loss": 0.0023,
      "step": 4980
    },
    {
      "epoch": 0.5544444444444444,
      "grad_norm": 1.2274823188781738,
      "learning_rate": 3.613888888888889e-05,
      "loss": 0.0034,
      "step": 4990
    },
    {
      "epoch": 0.5555555555555556,
      "grad_norm": 1.1977627277374268,
      "learning_rate": 3.611111111111111e-05,
      "loss": 0.0036,
      "step": 5000
    },
    {
      "epoch": 0.5566666666666666,
      "grad_norm": 1.2648555040359497,
      "learning_rate": 3.6083333333333334e-05,
      "loss": 0.0024,
      "step": 5010
    },
    {
      "epoch": 0.5577777777777778,
      "grad_norm": 0.13040204346179962,
      "learning_rate": 3.605555555555556e-05,
      "loss": 0.0023,
      "step": 5020
    },
    {
      "epoch": 0.5588888888888889,
      "grad_norm": 0.31431713700294495,
      "learning_rate": 3.6027777777777776e-05,
      "loss": 0.0025,
      "step": 5030
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.5023629665374756,
      "learning_rate": 3.6e-05,
      "loss": 0.0025,
      "step": 5040
    },
    {
      "epoch": 0.5611111111111111,
      "grad_norm": 0.6514123678207397,
      "learning_rate": 3.5972222222222225e-05,
      "loss": 0.0029,
      "step": 5050
    },
    {
      "epoch": 0.5622222222222222,
      "grad_norm": 0.17328011989593506,
      "learning_rate": 3.594444444444445e-05,
      "loss": 0.0027,
      "step": 5060
    },
    {
      "epoch": 0.5633333333333334,
      "grad_norm": 0.8424209356307983,
      "learning_rate": 3.591666666666667e-05,
      "loss": 0.0041,
      "step": 5070
    },
    {
      "epoch": 0.5644444444444444,
      "grad_norm": 1.3428212404251099,
      "learning_rate": 3.5888888888888886e-05,
      "loss": 0.0026,
      "step": 5080
    },
    {
      "epoch": 0.5655555555555556,
      "grad_norm": 0.5338220000267029,
      "learning_rate": 3.586111111111111e-05,
      "loss": 0.0026,
      "step": 5090
    },
    {
      "epoch": 0.5666666666666667,
      "grad_norm": 1.1200278997421265,
      "learning_rate": 3.5833333333333335e-05,
      "loss": 0.0036,
      "step": 5100
    },
    {
      "epoch": 0.5677777777777778,
      "grad_norm": 0.9456819295883179,
      "learning_rate": 3.580555555555556e-05,
      "loss": 0.0038,
      "step": 5110
    },
    {
      "epoch": 0.5688888888888889,
      "grad_norm": 0.6822942495346069,
      "learning_rate": 3.577777777777778e-05,
      "loss": 0.0022,
      "step": 5120
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.5017435550689697,
      "learning_rate": 3.575e-05,
      "loss": 0.0018,
      "step": 5130
    },
    {
      "epoch": 0.5711111111111111,
      "grad_norm": 0.9919865727424622,
      "learning_rate": 3.5722222222222226e-05,
      "loss": 0.003,
      "step": 5140
    },
    {
      "epoch": 0.5722222222222222,
      "grad_norm": 0.4701949954032898,
      "learning_rate": 3.5694444444444444e-05,
      "loss": 0.0018,
      "step": 5150
    },
    {
      "epoch": 0.5733333333333334,
      "grad_norm": 0.29972395300865173,
      "learning_rate": 3.566666666666667e-05,
      "loss": 0.0041,
      "step": 5160
    },
    {
      "epoch": 0.5744444444444444,
      "grad_norm": 0.8100090622901917,
      "learning_rate": 3.5638888888888886e-05,
      "loss": 0.0021,
      "step": 5170
    },
    {
      "epoch": 0.5755555555555556,
      "grad_norm": 0.607279360294342,
      "learning_rate": 3.561111111111111e-05,
      "loss": 0.0015,
      "step": 5180
    },
    {
      "epoch": 0.5766666666666667,
      "grad_norm": 1.3426662683486938,
      "learning_rate": 3.5583333333333335e-05,
      "loss": 0.0023,
      "step": 5190
    },
    {
      "epoch": 0.5777777777777777,
      "grad_norm": 0.7400482892990112,
      "learning_rate": 3.555555555555556e-05,
      "loss": 0.0042,
      "step": 5200
    },
    {
      "epoch": 0.5788888888888889,
      "grad_norm": 0.5832657814025879,
      "learning_rate": 3.5527777777777785e-05,
      "loss": 0.0035,
      "step": 5210
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.766108512878418,
      "learning_rate": 3.55e-05,
      "loss": 0.0027,
      "step": 5220
    },
    {
      "epoch": 0.5811111111111111,
      "grad_norm": 0.3744034767150879,
      "learning_rate": 3.547222222222222e-05,
      "loss": 0.0023,
      "step": 5230
    },
    {
      "epoch": 0.5822222222222222,
      "grad_norm": 0.4925144910812378,
      "learning_rate": 3.5444444444444445e-05,
      "loss": 0.0035,
      "step": 5240
    },
    {
      "epoch": 0.5833333333333334,
      "grad_norm": 1.424570083618164,
      "learning_rate": 3.541666666666667e-05,
      "loss": 0.0029,
      "step": 5250
    },
    {
      "epoch": 0.5844444444444444,
      "grad_norm": 0.215641051530838,
      "learning_rate": 3.538888888888889e-05,
      "loss": 0.0021,
      "step": 5260
    },
    {
      "epoch": 0.5855555555555556,
      "grad_norm": 0.9622876644134521,
      "learning_rate": 3.536111111111111e-05,
      "loss": 0.0032,
      "step": 5270
    },
    {
      "epoch": 0.5866666666666667,
      "grad_norm": 0.8422481417655945,
      "learning_rate": 3.5333333333333336e-05,
      "loss": 0.0026,
      "step": 5280
    },
    {
      "epoch": 0.5877777777777777,
      "grad_norm": 0.5846402645111084,
      "learning_rate": 3.530555555555556e-05,
      "loss": 0.0021,
      "step": 5290
    },
    {
      "epoch": 0.5888888888888889,
      "grad_norm": 0.6178728342056274,
      "learning_rate": 3.527777777777778e-05,
      "loss": 0.0034,
      "step": 5300
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.718804121017456,
      "learning_rate": 3.525e-05,
      "loss": 0.0023,
      "step": 5310
    },
    {
      "epoch": 0.5911111111111111,
      "grad_norm": 1.0127239227294922,
      "learning_rate": 3.522222222222222e-05,
      "loss": 0.0028,
      "step": 5320
    },
    {
      "epoch": 0.5922222222222222,
      "grad_norm": 0.7480525970458984,
      "learning_rate": 3.5194444444444445e-05,
      "loss": 0.0022,
      "step": 5330
    },
    {
      "epoch": 0.5933333333333334,
      "grad_norm": 1.502846598625183,
      "learning_rate": 3.516666666666667e-05,
      "loss": 0.0026,
      "step": 5340
    },
    {
      "epoch": 0.5944444444444444,
      "grad_norm": 1.2379862070083618,
      "learning_rate": 3.513888888888889e-05,
      "loss": 0.0025,
      "step": 5350
    },
    {
      "epoch": 0.5955555555555555,
      "grad_norm": 1.929871678352356,
      "learning_rate": 3.511111111111111e-05,
      "loss": 0.0021,
      "step": 5360
    },
    {
      "epoch": 0.5966666666666667,
      "grad_norm": 1.10017728805542,
      "learning_rate": 3.508333333333334e-05,
      "loss": 0.0022,
      "step": 5370
    },
    {
      "epoch": 0.5977777777777777,
      "grad_norm": 0.90458744764328,
      "learning_rate": 3.505555555555556e-05,
      "loss": 0.0024,
      "step": 5380
    },
    {
      "epoch": 0.5988888888888889,
      "grad_norm": 0.5753609538078308,
      "learning_rate": 3.502777777777778e-05,
      "loss": 0.0022,
      "step": 5390
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.1816788613796234,
      "learning_rate": 3.5e-05,
      "loss": 0.0026,
      "step": 5400
    },
    {
      "epoch": 0.6011111111111112,
      "grad_norm": 0.32362037897109985,
      "learning_rate": 3.497222222222222e-05,
      "loss": 0.003,
      "step": 5410
    },
    {
      "epoch": 0.6022222222222222,
      "grad_norm": 0.47926175594329834,
      "learning_rate": 3.4944444444444446e-05,
      "loss": 0.0019,
      "step": 5420
    },
    {
      "epoch": 0.6033333333333334,
      "grad_norm": 0.4172903299331665,
      "learning_rate": 3.491666666666667e-05,
      "loss": 0.0024,
      "step": 5430
    },
    {
      "epoch": 0.6044444444444445,
      "grad_norm": 0.39082857966423035,
      "learning_rate": 3.4888888888888895e-05,
      "loss": 0.0032,
      "step": 5440
    },
    {
      "epoch": 0.6055555555555555,
      "grad_norm": 1.4645529985427856,
      "learning_rate": 3.486111111111111e-05,
      "loss": 0.0018,
      "step": 5450
    },
    {
      "epoch": 0.6066666666666667,
      "grad_norm": 0.3016658127307892,
      "learning_rate": 3.483333333333334e-05,
      "loss": 0.0028,
      "step": 5460
    },
    {
      "epoch": 0.6077777777777778,
      "grad_norm": 1.4187735319137573,
      "learning_rate": 3.4805555555555555e-05,
      "loss": 0.003,
      "step": 5470
    },
    {
      "epoch": 0.6088888888888889,
      "grad_norm": 0.7621396780014038,
      "learning_rate": 3.477777777777778e-05,
      "loss": 0.0033,
      "step": 5480
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.6979958415031433,
      "learning_rate": 3.475e-05,
      "loss": 0.003,
      "step": 5490
    },
    {
      "epoch": 0.6111111111111112,
      "grad_norm": 1.5147813558578491,
      "learning_rate": 3.472222222222222e-05,
      "loss": 0.0028,
      "step": 5500
    },
    {
      "epoch": 0.6122222222222222,
      "grad_norm": 1.5166751146316528,
      "learning_rate": 3.469444444444445e-05,
      "loss": 0.0031,
      "step": 5510
    },
    {
      "epoch": 0.6133333333333333,
      "grad_norm": 1.9932667016983032,
      "learning_rate": 3.466666666666667e-05,
      "loss": 0.0025,
      "step": 5520
    },
    {
      "epoch": 0.6144444444444445,
      "grad_norm": 1.3389192819595337,
      "learning_rate": 3.4638888888888896e-05,
      "loss": 0.0039,
      "step": 5530
    },
    {
      "epoch": 0.6155555555555555,
      "grad_norm": 0.6738877892494202,
      "learning_rate": 3.4611111111111114e-05,
      "loss": 0.0032,
      "step": 5540
    },
    {
      "epoch": 0.6166666666666667,
      "grad_norm": 0.22060462832450867,
      "learning_rate": 3.458333333333333e-05,
      "loss": 0.003,
      "step": 5550
    },
    {
      "epoch": 0.6177777777777778,
      "grad_norm": 0.855093240737915,
      "learning_rate": 3.4555555555555556e-05,
      "loss": 0.0028,
      "step": 5560
    },
    {
      "epoch": 0.6188888888888889,
      "grad_norm": 0.7092060446739197,
      "learning_rate": 3.452777777777778e-05,
      "loss": 0.0034,
      "step": 5570
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.2941351532936096,
      "learning_rate": 3.45e-05,
      "loss": 0.003,
      "step": 5580
    },
    {
      "epoch": 0.6211111111111111,
      "grad_norm": 0.5839240550994873,
      "learning_rate": 3.447222222222222e-05,
      "loss": 0.0027,
      "step": 5590
    },
    {
      "epoch": 0.6222222222222222,
      "grad_norm": 0.4154515266418457,
      "learning_rate": 3.444444444444445e-05,
      "loss": 0.0024,
      "step": 5600
    },
    {
      "epoch": 0.6233333333333333,
      "grad_norm": 0.8025537729263306,
      "learning_rate": 3.441666666666667e-05,
      "loss": 0.0033,
      "step": 5610
    },
    {
      "epoch": 0.6244444444444445,
      "grad_norm": 1.3009670972824097,
      "learning_rate": 3.438888888888889e-05,
      "loss": 0.0023,
      "step": 5620
    },
    {
      "epoch": 0.6255555555555555,
      "grad_norm": 0.4022991359233856,
      "learning_rate": 3.436111111111111e-05,
      "loss": 0.0021,
      "step": 5630
    },
    {
      "epoch": 0.6266666666666667,
      "grad_norm": 0.6141431331634521,
      "learning_rate": 3.433333333333333e-05,
      "loss": 0.002,
      "step": 5640
    },
    {
      "epoch": 0.6277777777777778,
      "grad_norm": 0.6123852133750916,
      "learning_rate": 3.430555555555556e-05,
      "loss": 0.0025,
      "step": 5650
    },
    {
      "epoch": 0.6288888888888889,
      "grad_norm": 0.5505852699279785,
      "learning_rate": 3.427777777777778e-05,
      "loss": 0.0028,
      "step": 5660
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.4161178767681122,
      "learning_rate": 3.4250000000000006e-05,
      "loss": 0.0021,
      "step": 5670
    },
    {
      "epoch": 0.6311111111111111,
      "grad_norm": 0.6931526064872742,
      "learning_rate": 3.4222222222222224e-05,
      "loss": 0.0041,
      "step": 5680
    },
    {
      "epoch": 0.6322222222222222,
      "grad_norm": 0.8123947978019714,
      "learning_rate": 3.419444444444445e-05,
      "loss": 0.0031,
      "step": 5690
    },
    {
      "epoch": 0.6333333333333333,
      "grad_norm": 0.25643280148506165,
      "learning_rate": 3.4166666666666666e-05,
      "loss": 0.0022,
      "step": 5700
    },
    {
      "epoch": 0.6344444444444445,
      "grad_norm": 0.31783533096313477,
      "learning_rate": 3.413888888888889e-05,
      "loss": 0.0025,
      "step": 5710
    },
    {
      "epoch": 0.6355555555555555,
      "grad_norm": 0.7011194825172424,
      "learning_rate": 3.411111111111111e-05,
      "loss": 0.0034,
      "step": 5720
    },
    {
      "epoch": 0.6366666666666667,
      "grad_norm": 1.0295661687850952,
      "learning_rate": 3.408333333333333e-05,
      "loss": 0.0027,
      "step": 5730
    },
    {
      "epoch": 0.6377777777777778,
      "grad_norm": 0.5211998820304871,
      "learning_rate": 3.405555555555556e-05,
      "loss": 0.0017,
      "step": 5740
    },
    {
      "epoch": 0.6388888888888888,
      "grad_norm": 0.35167309641838074,
      "learning_rate": 3.402777777777778e-05,
      "loss": 0.0026,
      "step": 5750
    },
    {
      "epoch": 0.64,
      "grad_norm": 1.2483400106430054,
      "learning_rate": 3.4000000000000007e-05,
      "loss": 0.0032,
      "step": 5760
    },
    {
      "epoch": 0.6411111111111111,
      "grad_norm": 0.42256060242652893,
      "learning_rate": 3.3972222222222224e-05,
      "loss": 0.002,
      "step": 5770
    },
    {
      "epoch": 0.6422222222222222,
      "grad_norm": 1.028615117073059,
      "learning_rate": 3.394444444444444e-05,
      "loss": 0.0018,
      "step": 5780
    },
    {
      "epoch": 0.6433333333333333,
      "grad_norm": 0.3101773262023926,
      "learning_rate": 3.391666666666667e-05,
      "loss": 0.0032,
      "step": 5790
    },
    {
      "epoch": 0.6444444444444445,
      "grad_norm": 0.9038141369819641,
      "learning_rate": 3.388888888888889e-05,
      "loss": 0.0027,
      "step": 5800
    },
    {
      "epoch": 0.6455555555555555,
      "grad_norm": 0.941906213760376,
      "learning_rate": 3.386111111111111e-05,
      "loss": 0.0029,
      "step": 5810
    },
    {
      "epoch": 0.6466666666666666,
      "grad_norm": 1.2382965087890625,
      "learning_rate": 3.3833333333333334e-05,
      "loss": 0.0026,
      "step": 5820
    },
    {
      "epoch": 0.6477777777777778,
      "grad_norm": 1.4430854320526123,
      "learning_rate": 3.380555555555556e-05,
      "loss": 0.0025,
      "step": 5830
    },
    {
      "epoch": 0.6488888888888888,
      "grad_norm": 0.6374237537384033,
      "learning_rate": 3.377777777777778e-05,
      "loss": 0.0038,
      "step": 5840
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.42792412638664246,
      "learning_rate": 3.375000000000001e-05,
      "loss": 0.0042,
      "step": 5850
    },
    {
      "epoch": 0.6511111111111111,
      "grad_norm": 0.4708753526210785,
      "learning_rate": 3.3722222222222225e-05,
      "loss": 0.0048,
      "step": 5860
    },
    {
      "epoch": 0.6522222222222223,
      "grad_norm": 0.6762149930000305,
      "learning_rate": 3.369444444444444e-05,
      "loss": 0.0018,
      "step": 5870
    },
    {
      "epoch": 0.6533333333333333,
      "grad_norm": 0.8953261971473694,
      "learning_rate": 3.366666666666667e-05,
      "loss": 0.0055,
      "step": 5880
    },
    {
      "epoch": 0.6544444444444445,
      "grad_norm": 0.6332931518554688,
      "learning_rate": 3.363888888888889e-05,
      "loss": 0.0023,
      "step": 5890
    },
    {
      "epoch": 0.6555555555555556,
      "grad_norm": 0.4806354343891144,
      "learning_rate": 3.3611111111111116e-05,
      "loss": 0.0031,
      "step": 5900
    },
    {
      "epoch": 0.6566666666666666,
      "grad_norm": 0.27058273553848267,
      "learning_rate": 3.3583333333333334e-05,
      "loss": 0.0035,
      "step": 5910
    },
    {
      "epoch": 0.6577777777777778,
      "grad_norm": 0.7910370826721191,
      "learning_rate": 3.355555555555556e-05,
      "loss": 0.0031,
      "step": 5920
    },
    {
      "epoch": 0.6588888888888889,
      "grad_norm": 0.25512680411338806,
      "learning_rate": 3.352777777777778e-05,
      "loss": 0.0022,
      "step": 5930
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.7258310317993164,
      "learning_rate": 3.35e-05,
      "loss": 0.0023,
      "step": 5940
    },
    {
      "epoch": 0.6611111111111111,
      "grad_norm": 0.40552061796188354,
      "learning_rate": 3.347222222222222e-05,
      "loss": 0.0025,
      "step": 5950
    },
    {
      "epoch": 0.6622222222222223,
      "grad_norm": 0.9491146802902222,
      "learning_rate": 3.3444444444444443e-05,
      "loss": 0.0028,
      "step": 5960
    },
    {
      "epoch": 0.6633333333333333,
      "grad_norm": 1.1039330959320068,
      "learning_rate": 3.341666666666667e-05,
      "loss": 0.0025,
      "step": 5970
    },
    {
      "epoch": 0.6644444444444444,
      "grad_norm": 0.41067466139793396,
      "learning_rate": 3.338888888888889e-05,
      "loss": 0.0017,
      "step": 5980
    },
    {
      "epoch": 0.6655555555555556,
      "grad_norm": 0.5119562745094299,
      "learning_rate": 3.336111111111112e-05,
      "loss": 0.0026,
      "step": 5990
    },
    {
      "epoch": 0.6666666666666666,
      "grad_norm": 0.9097198843955994,
      "learning_rate": 3.3333333333333335e-05,
      "loss": 0.002,
      "step": 6000
    },
    {
      "epoch": 0.6677777777777778,
      "grad_norm": 1.2558315992355347,
      "learning_rate": 3.330555555555556e-05,
      "loss": 0.0018,
      "step": 6010
    },
    {
      "epoch": 0.6688888888888889,
      "grad_norm": 0.6080952882766724,
      "learning_rate": 3.327777777777778e-05,
      "loss": 0.0026,
      "step": 6020
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.2926306426525116,
      "learning_rate": 3.325e-05,
      "loss": 0.0034,
      "step": 6030
    },
    {
      "epoch": 0.6711111111111111,
      "grad_norm": 1.636061668395996,
      "learning_rate": 3.322222222222222e-05,
      "loss": 0.0032,
      "step": 6040
    },
    {
      "epoch": 0.6722222222222223,
      "grad_norm": 1.5679106712341309,
      "learning_rate": 3.3194444444444444e-05,
      "loss": 0.0023,
      "step": 6050
    },
    {
      "epoch": 0.6733333333333333,
      "grad_norm": 1.0356781482696533,
      "learning_rate": 3.316666666666667e-05,
      "loss": 0.004,
      "step": 6060
    },
    {
      "epoch": 0.6744444444444444,
      "grad_norm": 0.5913482308387756,
      "learning_rate": 3.313888888888889e-05,
      "loss": 0.0021,
      "step": 6070
    },
    {
      "epoch": 0.6755555555555556,
      "grad_norm": 0.47998103499412537,
      "learning_rate": 3.311111111111112e-05,
      "loss": 0.0023,
      "step": 6080
    },
    {
      "epoch": 0.6766666666666666,
      "grad_norm": 0.37565937638282776,
      "learning_rate": 3.3083333333333336e-05,
      "loss": 0.0033,
      "step": 6090
    },
    {
      "epoch": 0.6777777777777778,
      "grad_norm": 0.34228426218032837,
      "learning_rate": 3.3055555555555553e-05,
      "loss": 0.0026,
      "step": 6100
    },
    {
      "epoch": 0.6788888888888889,
      "grad_norm": 0.41800323128700256,
      "learning_rate": 3.302777777777778e-05,
      "loss": 0.0029,
      "step": 6110
    },
    {
      "epoch": 0.68,
      "grad_norm": 1.5382215976715088,
      "learning_rate": 3.3e-05,
      "loss": 0.005,
      "step": 6120
    },
    {
      "epoch": 0.6811111111111111,
      "grad_norm": 1.7089407444000244,
      "learning_rate": 3.297222222222223e-05,
      "loss": 0.0035,
      "step": 6130
    },
    {
      "epoch": 0.6822222222222222,
      "grad_norm": 0.9085544943809509,
      "learning_rate": 3.2944444444444445e-05,
      "loss": 0.0033,
      "step": 6140
    },
    {
      "epoch": 0.6833333333333333,
      "grad_norm": 0.4977976083755493,
      "learning_rate": 3.291666666666667e-05,
      "loss": 0.0027,
      "step": 6150
    },
    {
      "epoch": 0.6844444444444444,
      "grad_norm": 1.529821753501892,
      "learning_rate": 3.2888888888888894e-05,
      "loss": 0.004,
      "step": 6160
    },
    {
      "epoch": 0.6855555555555556,
      "grad_norm": 0.18517203629016876,
      "learning_rate": 3.286111111111111e-05,
      "loss": 0.0017,
      "step": 6170
    },
    {
      "epoch": 0.6866666666666666,
      "grad_norm": 1.9498151540756226,
      "learning_rate": 3.283333333333333e-05,
      "loss": 0.0022,
      "step": 6180
    },
    {
      "epoch": 0.6877777777777778,
      "grad_norm": 0.30028432607650757,
      "learning_rate": 3.2805555555555554e-05,
      "loss": 0.0028,
      "step": 6190
    },
    {
      "epoch": 0.6888888888888889,
      "grad_norm": 0.2860972285270691,
      "learning_rate": 3.277777777777778e-05,
      "loss": 0.004,
      "step": 6200
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.6609627604484558,
      "learning_rate": 3.275e-05,
      "loss": 0.0031,
      "step": 6210
    },
    {
      "epoch": 0.6911111111111111,
      "grad_norm": 1.3367466926574707,
      "learning_rate": 3.272222222222223e-05,
      "loss": 0.0045,
      "step": 6220
    },
    {
      "epoch": 0.6922222222222222,
      "grad_norm": 0.41764286160469055,
      "learning_rate": 3.2694444444444446e-05,
      "loss": 0.0021,
      "step": 6230
    },
    {
      "epoch": 0.6933333333333334,
      "grad_norm": 0.9412057995796204,
      "learning_rate": 3.266666666666667e-05,
      "loss": 0.003,
      "step": 6240
    },
    {
      "epoch": 0.6944444444444444,
      "grad_norm": 0.517922580242157,
      "learning_rate": 3.263888888888889e-05,
      "loss": 0.0017,
      "step": 6250
    },
    {
      "epoch": 0.6955555555555556,
      "grad_norm": 0.6275427341461182,
      "learning_rate": 3.261111111111111e-05,
      "loss": 0.0029,
      "step": 6260
    },
    {
      "epoch": 0.6966666666666667,
      "grad_norm": 0.9920108914375305,
      "learning_rate": 3.258333333333333e-05,
      "loss": 0.0035,
      "step": 6270
    },
    {
      "epoch": 0.6977777777777778,
      "grad_norm": 1.298078179359436,
      "learning_rate": 3.2555555555555555e-05,
      "loss": 0.0016,
      "step": 6280
    },
    {
      "epoch": 0.6988888888888889,
      "grad_norm": 0.4929306209087372,
      "learning_rate": 3.252777777777778e-05,
      "loss": 0.0027,
      "step": 6290
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.9369645714759827,
      "learning_rate": 3.2500000000000004e-05,
      "loss": 0.0024,
      "step": 6300
    },
    {
      "epoch": 0.7011111111111111,
      "grad_norm": 0.6954972743988037,
      "learning_rate": 3.247222222222223e-05,
      "loss": 0.0032,
      "step": 6310
    },
    {
      "epoch": 0.7022222222222222,
      "grad_norm": 0.6966001987457275,
      "learning_rate": 3.2444444444444446e-05,
      "loss": 0.0041,
      "step": 6320
    },
    {
      "epoch": 0.7033333333333334,
      "grad_norm": 0.498249888420105,
      "learning_rate": 3.2416666666666664e-05,
      "loss": 0.0032,
      "step": 6330
    },
    {
      "epoch": 0.7044444444444444,
      "grad_norm": 1.098534107208252,
      "learning_rate": 3.238888888888889e-05,
      "loss": 0.0023,
      "step": 6340
    },
    {
      "epoch": 0.7055555555555556,
      "grad_norm": 0.5404091477394104,
      "learning_rate": 3.236111111111111e-05,
      "loss": 0.0034,
      "step": 6350
    },
    {
      "epoch": 0.7066666666666667,
      "grad_norm": 1.21099853515625,
      "learning_rate": 3.233333333333333e-05,
      "loss": 0.0031,
      "step": 6360
    },
    {
      "epoch": 0.7077777777777777,
      "grad_norm": 0.6143848299980164,
      "learning_rate": 3.2305555555555556e-05,
      "loss": 0.0042,
      "step": 6370
    },
    {
      "epoch": 0.7088888888888889,
      "grad_norm": 0.42012181878089905,
      "learning_rate": 3.227777777777778e-05,
      "loss": 0.0022,
      "step": 6380
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.8885357975959778,
      "learning_rate": 3.2250000000000005e-05,
      "loss": 0.0029,
      "step": 6390
    },
    {
      "epoch": 0.7111111111111111,
      "grad_norm": 0.3839171826839447,
      "learning_rate": 3.222222222222223e-05,
      "loss": 0.0026,
      "step": 6400
    },
    {
      "epoch": 0.7122222222222222,
      "grad_norm": 0.4652775526046753,
      "learning_rate": 3.219444444444445e-05,
      "loss": 0.002,
      "step": 6410
    },
    {
      "epoch": 0.7133333333333334,
      "grad_norm": 0.2972100079059601,
      "learning_rate": 3.2166666666666665e-05,
      "loss": 0.0024,
      "step": 6420
    },
    {
      "epoch": 0.7144444444444444,
      "grad_norm": 0.6986169219017029,
      "learning_rate": 3.213888888888889e-05,
      "loss": 0.0026,
      "step": 6430
    },
    {
      "epoch": 0.7155555555555555,
      "grad_norm": 0.2645339071750641,
      "learning_rate": 3.2111111111111114e-05,
      "loss": 0.0028,
      "step": 6440
    },
    {
      "epoch": 0.7166666666666667,
      "grad_norm": 0.7816920876502991,
      "learning_rate": 3.208333333333334e-05,
      "loss": 0.0023,
      "step": 6450
    },
    {
      "epoch": 0.7177777777777777,
      "grad_norm": 0.958167552947998,
      "learning_rate": 3.2055555555555556e-05,
      "loss": 0.0028,
      "step": 6460
    },
    {
      "epoch": 0.7188888888888889,
      "grad_norm": 0.8802586197853088,
      "learning_rate": 3.202777777777778e-05,
      "loss": 0.0039,
      "step": 6470
    },
    {
      "epoch": 0.72,
      "grad_norm": 1.4242953062057495,
      "learning_rate": 3.2000000000000005e-05,
      "loss": 0.003,
      "step": 6480
    },
    {
      "epoch": 0.7211111111111111,
      "grad_norm": 0.3666199743747711,
      "learning_rate": 3.197222222222222e-05,
      "loss": 0.0039,
      "step": 6490
    },
    {
      "epoch": 0.7222222222222222,
      "grad_norm": 0.4863370656967163,
      "learning_rate": 3.194444444444444e-05,
      "loss": 0.0023,
      "step": 6500
    },
    {
      "epoch": 0.7233333333333334,
      "grad_norm": 0.24151407182216644,
      "learning_rate": 3.1916666666666665e-05,
      "loss": 0.003,
      "step": 6510
    },
    {
      "epoch": 0.7244444444444444,
      "grad_norm": 0.6427504420280457,
      "learning_rate": 3.188888888888889e-05,
      "loss": 0.0023,
      "step": 6520
    },
    {
      "epoch": 0.7255555555555555,
      "grad_norm": 0.29688066244125366,
      "learning_rate": 3.1861111111111115e-05,
      "loss": 0.0015,
      "step": 6530
    },
    {
      "epoch": 0.7266666666666667,
      "grad_norm": 0.48381122946739197,
      "learning_rate": 3.183333333333334e-05,
      "loss": 0.0031,
      "step": 6540
    },
    {
      "epoch": 0.7277777777777777,
      "grad_norm": 1.7358503341674805,
      "learning_rate": 3.180555555555556e-05,
      "loss": 0.003,
      "step": 6550
    },
    {
      "epoch": 0.7288888888888889,
      "grad_norm": 0.6038172841072083,
      "learning_rate": 3.177777777777778e-05,
      "loss": 0.0025,
      "step": 6560
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.8457213640213013,
      "learning_rate": 3.175e-05,
      "loss": 0.0032,
      "step": 6570
    },
    {
      "epoch": 0.7311111111111112,
      "grad_norm": 0.9429774880409241,
      "learning_rate": 3.1722222222222224e-05,
      "loss": 0.0052,
      "step": 6580
    },
    {
      "epoch": 0.7322222222222222,
      "grad_norm": 1.3026460409164429,
      "learning_rate": 3.169444444444444e-05,
      "loss": 0.0024,
      "step": 6590
    },
    {
      "epoch": 0.7333333333333333,
      "grad_norm": 0.4957084357738495,
      "learning_rate": 3.1666666666666666e-05,
      "loss": 0.0034,
      "step": 6600
    },
    {
      "epoch": 0.7344444444444445,
      "grad_norm": 0.9687581062316895,
      "learning_rate": 3.163888888888889e-05,
      "loss": 0.0023,
      "step": 6610
    },
    {
      "epoch": 0.7355555555555555,
      "grad_norm": 0.6548499464988708,
      "learning_rate": 3.1611111111111115e-05,
      "loss": 0.002,
      "step": 6620
    },
    {
      "epoch": 0.7366666666666667,
      "grad_norm": 0.19403021037578583,
      "learning_rate": 3.158333333333334e-05,
      "loss": 0.0029,
      "step": 6630
    },
    {
      "epoch": 0.7377777777777778,
      "grad_norm": 0.21122877299785614,
      "learning_rate": 3.155555555555556e-05,
      "loss": 0.0029,
      "step": 6640
    },
    {
      "epoch": 0.7388888888888889,
      "grad_norm": 0.5525373816490173,
      "learning_rate": 3.1527777777777775e-05,
      "loss": 0.0017,
      "step": 6650
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.41765204071998596,
      "learning_rate": 3.15e-05,
      "loss": 0.0018,
      "step": 6660
    },
    {
      "epoch": 0.7411111111111112,
      "grad_norm": 0.4002000391483307,
      "learning_rate": 3.1472222222222225e-05,
      "loss": 0.0028,
      "step": 6670
    },
    {
      "epoch": 0.7422222222222222,
      "grad_norm": 0.5140433311462402,
      "learning_rate": 3.144444444444445e-05,
      "loss": 0.0019,
      "step": 6680
    },
    {
      "epoch": 0.7433333333333333,
      "grad_norm": 0.8266180753707886,
      "learning_rate": 3.141666666666667e-05,
      "loss": 0.0028,
      "step": 6690
    },
    {
      "epoch": 0.7444444444444445,
      "grad_norm": 0.8429659605026245,
      "learning_rate": 3.138888888888889e-05,
      "loss": 0.0037,
      "step": 6700
    },
    {
      "epoch": 0.7455555555555555,
      "grad_norm": 1.1842585802078247,
      "learning_rate": 3.1361111111111116e-05,
      "loss": 0.0028,
      "step": 6710
    },
    {
      "epoch": 0.7466666666666667,
      "grad_norm": 0.26024484634399414,
      "learning_rate": 3.1333333333333334e-05,
      "loss": 0.0022,
      "step": 6720
    },
    {
      "epoch": 0.7477777777777778,
      "grad_norm": 0.6241930723190308,
      "learning_rate": 3.130555555555555e-05,
      "loss": 0.0019,
      "step": 6730
    },
    {
      "epoch": 0.7488888888888889,
      "grad_norm": 1.3688377141952515,
      "learning_rate": 3.1277777777777776e-05,
      "loss": 0.0021,
      "step": 6740
    },
    {
      "epoch": 0.75,
      "grad_norm": 1.0485949516296387,
      "learning_rate": 3.125e-05,
      "loss": 0.0042,
      "step": 6750
    },
    {
      "epoch": 0.7511111111111111,
      "grad_norm": 0.8626778721809387,
      "learning_rate": 3.1222222222222225e-05,
      "loss": 0.0014,
      "step": 6760
    },
    {
      "epoch": 0.7522222222222222,
      "grad_norm": 0.20603534579277039,
      "learning_rate": 3.119444444444445e-05,
      "loss": 0.0028,
      "step": 6770
    },
    {
      "epoch": 0.7533333333333333,
      "grad_norm": 0.5758033990859985,
      "learning_rate": 3.116666666666667e-05,
      "loss": 0.0018,
      "step": 6780
    },
    {
      "epoch": 0.7544444444444445,
      "grad_norm": 0.6243874430656433,
      "learning_rate": 3.113888888888889e-05,
      "loss": 0.0015,
      "step": 6790
    },
    {
      "epoch": 0.7555555555555555,
      "grad_norm": 0.5992411375045776,
      "learning_rate": 3.111111111111111e-05,
      "loss": 0.0017,
      "step": 6800
    },
    {
      "epoch": 0.7566666666666667,
      "grad_norm": 1.0410964488983154,
      "learning_rate": 3.1083333333333334e-05,
      "loss": 0.0017,
      "step": 6810
    },
    {
      "epoch": 0.7577777777777778,
      "grad_norm": 0.2713397443294525,
      "learning_rate": 3.105555555555555e-05,
      "loss": 0.0032,
      "step": 6820
    },
    {
      "epoch": 0.7588888888888888,
      "grad_norm": 1.3567237854003906,
      "learning_rate": 3.102777777777778e-05,
      "loss": 0.0025,
      "step": 6830
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.6288111805915833,
      "learning_rate": 3.1e-05,
      "loss": 0.0043,
      "step": 6840
    },
    {
      "epoch": 0.7611111111111111,
      "grad_norm": 0.5812094211578369,
      "learning_rate": 3.0972222222222226e-05,
      "loss": 0.0025,
      "step": 6850
    },
    {
      "epoch": 0.7622222222222222,
      "grad_norm": 0.9515522718429565,
      "learning_rate": 3.094444444444445e-05,
      "loss": 0.0027,
      "step": 6860
    },
    {
      "epoch": 0.7633333333333333,
      "grad_norm": 0.8826587796211243,
      "learning_rate": 3.091666666666667e-05,
      "loss": 0.0039,
      "step": 6870
    },
    {
      "epoch": 0.7644444444444445,
      "grad_norm": 0.7274607419967651,
      "learning_rate": 3.088888888888889e-05,
      "loss": 0.0026,
      "step": 6880
    },
    {
      "epoch": 0.7655555555555555,
      "grad_norm": 0.4764636754989624,
      "learning_rate": 3.086111111111111e-05,
      "loss": 0.0039,
      "step": 6890
    },
    {
      "epoch": 0.7666666666666667,
      "grad_norm": 1.1354849338531494,
      "learning_rate": 3.0833333333333335e-05,
      "loss": 0.0034,
      "step": 6900
    },
    {
      "epoch": 0.7677777777777778,
      "grad_norm": 0.37826070189476013,
      "learning_rate": 3.080555555555556e-05,
      "loss": 0.0048,
      "step": 6910
    },
    {
      "epoch": 0.7688888888888888,
      "grad_norm": 1.1921560764312744,
      "learning_rate": 3.077777777777778e-05,
      "loss": 0.004,
      "step": 6920
    },
    {
      "epoch": 0.77,
      "grad_norm": 1.9364904165267944,
      "learning_rate": 3.075e-05,
      "loss": 0.0023,
      "step": 6930
    },
    {
      "epoch": 0.7711111111111111,
      "grad_norm": 1.4291131496429443,
      "learning_rate": 3.0722222222222227e-05,
      "loss": 0.003,
      "step": 6940
    },
    {
      "epoch": 0.7722222222222223,
      "grad_norm": 0.5772622227668762,
      "learning_rate": 3.069444444444445e-05,
      "loss": 0.0034,
      "step": 6950
    },
    {
      "epoch": 0.7733333333333333,
      "grad_norm": 0.6625645160675049,
      "learning_rate": 3.066666666666667e-05,
      "loss": 0.0035,
      "step": 6960
    },
    {
      "epoch": 0.7744444444444445,
      "grad_norm": 0.4118405878543854,
      "learning_rate": 3.063888888888889e-05,
      "loss": 0.0032,
      "step": 6970
    },
    {
      "epoch": 0.7755555555555556,
      "grad_norm": 0.6358884572982788,
      "learning_rate": 3.061111111111111e-05,
      "loss": 0.0028,
      "step": 6980
    },
    {
      "epoch": 0.7766666666666666,
      "grad_norm": 0.5518575310707092,
      "learning_rate": 3.0583333333333336e-05,
      "loss": 0.002,
      "step": 6990
    },
    {
      "epoch": 0.7777777777777778,
      "grad_norm": 1.402800440788269,
      "learning_rate": 3.055555555555556e-05,
      "loss": 0.0032,
      "step": 7000
    },
    {
      "epoch": 0.7788888888888889,
      "grad_norm": 1.3412036895751953,
      "learning_rate": 3.052777777777778e-05,
      "loss": 0.0032,
      "step": 7010
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.29058122634887695,
      "learning_rate": 3.05e-05,
      "loss": 0.0027,
      "step": 7020
    },
    {
      "epoch": 0.7811111111111111,
      "grad_norm": 0.2598102390766144,
      "learning_rate": 3.0472222222222224e-05,
      "loss": 0.003,
      "step": 7030
    },
    {
      "epoch": 0.7822222222222223,
      "grad_norm": 0.39726996421813965,
      "learning_rate": 3.044444444444445e-05,
      "loss": 0.0035,
      "step": 7040
    },
    {
      "epoch": 0.7833333333333333,
      "grad_norm": 0.20314238965511322,
      "learning_rate": 3.0416666666666666e-05,
      "loss": 0.0013,
      "step": 7050
    },
    {
      "epoch": 0.7844444444444445,
      "grad_norm": 0.4596671164035797,
      "learning_rate": 3.0388888888888887e-05,
      "loss": 0.0026,
      "step": 7060
    },
    {
      "epoch": 0.7855555555555556,
      "grad_norm": 0.3430171608924866,
      "learning_rate": 3.0361111111111112e-05,
      "loss": 0.0022,
      "step": 7070
    },
    {
      "epoch": 0.7866666666666666,
      "grad_norm": 0.6668195724487305,
      "learning_rate": 3.0333333333333337e-05,
      "loss": 0.0029,
      "step": 7080
    },
    {
      "epoch": 0.7877777777777778,
      "grad_norm": 0.37395066022872925,
      "learning_rate": 3.0305555555555558e-05,
      "loss": 0.0023,
      "step": 7090
    },
    {
      "epoch": 0.7888888888888889,
      "grad_norm": 0.9528930187225342,
      "learning_rate": 3.0277777777777776e-05,
      "loss": 0.0024,
      "step": 7100
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.42374110221862793,
      "learning_rate": 3.025e-05,
      "loss": 0.0034,
      "step": 7110
    },
    {
      "epoch": 0.7911111111111111,
      "grad_norm": 0.4833676517009735,
      "learning_rate": 3.0222222222222225e-05,
      "loss": 0.002,
      "step": 7120
    },
    {
      "epoch": 0.7922222222222223,
      "grad_norm": 0.6880311965942383,
      "learning_rate": 3.0194444444444446e-05,
      "loss": 0.002,
      "step": 7130
    },
    {
      "epoch": 0.7933333333333333,
      "grad_norm": 0.4712998569011688,
      "learning_rate": 3.016666666666667e-05,
      "loss": 0.0036,
      "step": 7140
    },
    {
      "epoch": 0.7944444444444444,
      "grad_norm": 1.0068081617355347,
      "learning_rate": 3.0138888888888888e-05,
      "loss": 0.0026,
      "step": 7150
    },
    {
      "epoch": 0.7955555555555556,
      "grad_norm": 0.5749937891960144,
      "learning_rate": 3.0111111111111113e-05,
      "loss": 0.0035,
      "step": 7160
    },
    {
      "epoch": 0.7966666666666666,
      "grad_norm": 1.1608000993728638,
      "learning_rate": 3.0083333333333337e-05,
      "loss": 0.0022,
      "step": 7170
    },
    {
      "epoch": 0.7977777777777778,
      "grad_norm": 0.5477316379547119,
      "learning_rate": 3.005555555555556e-05,
      "loss": 0.0024,
      "step": 7180
    },
    {
      "epoch": 0.7988888888888889,
      "grad_norm": 1.030403971672058,
      "learning_rate": 3.0027777777777776e-05,
      "loss": 0.0038,
      "step": 7190
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.6848457455635071,
      "learning_rate": 3e-05,
      "loss": 0.0023,
      "step": 7200
    },
    {
      "epoch": 0.8011111111111111,
      "grad_norm": 0.7215147018432617,
      "learning_rate": 2.9972222222222225e-05,
      "loss": 0.0025,
      "step": 7210
    },
    {
      "epoch": 0.8022222222222222,
      "grad_norm": 0.3922169804573059,
      "learning_rate": 2.9944444444444446e-05,
      "loss": 0.0015,
      "step": 7220
    },
    {
      "epoch": 0.8033333333333333,
      "grad_norm": 0.1832464188337326,
      "learning_rate": 2.991666666666667e-05,
      "loss": 0.0034,
      "step": 7230
    },
    {
      "epoch": 0.8044444444444444,
      "grad_norm": 0.39770105481147766,
      "learning_rate": 2.988888888888889e-05,
      "loss": 0.0019,
      "step": 7240
    },
    {
      "epoch": 0.8055555555555556,
      "grad_norm": 0.4623812139034271,
      "learning_rate": 2.9861111111111113e-05,
      "loss": 0.0017,
      "step": 7250
    },
    {
      "epoch": 0.8066666666666666,
      "grad_norm": 0.4239290952682495,
      "learning_rate": 2.9833333333333335e-05,
      "loss": 0.0025,
      "step": 7260
    },
    {
      "epoch": 0.8077777777777778,
      "grad_norm": 0.7161137461662292,
      "learning_rate": 2.980555555555556e-05,
      "loss": 0.0036,
      "step": 7270
    },
    {
      "epoch": 0.8088888888888889,
      "grad_norm": 0.782029926776886,
      "learning_rate": 2.9777777777777777e-05,
      "loss": 0.0027,
      "step": 7280
    },
    {
      "epoch": 0.81,
      "grad_norm": 1.083720088005066,
      "learning_rate": 2.975e-05,
      "loss": 0.0025,
      "step": 7290
    },
    {
      "epoch": 0.8111111111111111,
      "grad_norm": 1.6663942337036133,
      "learning_rate": 2.9722222222222223e-05,
      "loss": 0.0033,
      "step": 7300
    },
    {
      "epoch": 0.8122222222222222,
      "grad_norm": 0.761389970779419,
      "learning_rate": 2.9694444444444447e-05,
      "loss": 0.002,
      "step": 7310
    },
    {
      "epoch": 0.8133333333333334,
      "grad_norm": 0.29980844259262085,
      "learning_rate": 2.9666666666666672e-05,
      "loss": 0.0036,
      "step": 7320
    },
    {
      "epoch": 0.8144444444444444,
      "grad_norm": 0.5917448997497559,
      "learning_rate": 2.963888888888889e-05,
      "loss": 0.0018,
      "step": 7330
    },
    {
      "epoch": 0.8155555555555556,
      "grad_norm": 0.521523654460907,
      "learning_rate": 2.961111111111111e-05,
      "loss": 0.0035,
      "step": 7340
    },
    {
      "epoch": 0.8166666666666667,
      "grad_norm": 0.31607434153556824,
      "learning_rate": 2.9583333333333335e-05,
      "loss": 0.0021,
      "step": 7350
    },
    {
      "epoch": 0.8177777777777778,
      "grad_norm": 0.5138639807701111,
      "learning_rate": 2.955555555555556e-05,
      "loss": 0.0037,
      "step": 7360
    },
    {
      "epoch": 0.8188888888888889,
      "grad_norm": 0.27453485131263733,
      "learning_rate": 2.9527777777777778e-05,
      "loss": 0.0021,
      "step": 7370
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.5282496809959412,
      "learning_rate": 2.95e-05,
      "loss": 0.0026,
      "step": 7380
    },
    {
      "epoch": 0.8211111111111111,
      "grad_norm": 2.188840389251709,
      "learning_rate": 2.9472222222222223e-05,
      "loss": 0.0028,
      "step": 7390
    },
    {
      "epoch": 0.8222222222222222,
      "grad_norm": 1.1036453247070312,
      "learning_rate": 2.9444444444444448e-05,
      "loss": 0.0019,
      "step": 7400
    },
    {
      "epoch": 0.8233333333333334,
      "grad_norm": 1.1501822471618652,
      "learning_rate": 2.941666666666667e-05,
      "loss": 0.0025,
      "step": 7410
    },
    {
      "epoch": 0.8244444444444444,
      "grad_norm": 0.6736859083175659,
      "learning_rate": 2.9388888888888887e-05,
      "loss": 0.0023,
      "step": 7420
    },
    {
      "epoch": 0.8255555555555556,
      "grad_norm": 0.574995219707489,
      "learning_rate": 2.936111111111111e-05,
      "loss": 0.0025,
      "step": 7430
    },
    {
      "epoch": 0.8266666666666667,
      "grad_norm": 1.849271297454834,
      "learning_rate": 2.9333333333333336e-05,
      "loss": 0.0026,
      "step": 7440
    },
    {
      "epoch": 0.8277777777777777,
      "grad_norm": 0.9358388781547546,
      "learning_rate": 2.9305555555555557e-05,
      "loss": 0.0026,
      "step": 7450
    },
    {
      "epoch": 0.8288888888888889,
      "grad_norm": 0.5562517642974854,
      "learning_rate": 2.927777777777778e-05,
      "loss": 0.0021,
      "step": 7460
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.5903311371803284,
      "learning_rate": 2.925e-05,
      "loss": 0.003,
      "step": 7470
    },
    {
      "epoch": 0.8311111111111111,
      "grad_norm": 0.3341221213340759,
      "learning_rate": 2.9222222222222224e-05,
      "loss": 0.0044,
      "step": 7480
    },
    {
      "epoch": 0.8322222222222222,
      "grad_norm": 1.276218056678772,
      "learning_rate": 2.9194444444444445e-05,
      "loss": 0.0021,
      "step": 7490
    },
    {
      "epoch": 0.8333333333333334,
      "grad_norm": 0.3357451558113098,
      "learning_rate": 2.916666666666667e-05,
      "loss": 0.0023,
      "step": 7500
    },
    {
      "epoch": 0.8344444444444444,
      "grad_norm": 0.2394236922264099,
      "learning_rate": 2.9138888888888888e-05,
      "loss": 0.0023,
      "step": 7510
    },
    {
      "epoch": 0.8355555555555556,
      "grad_norm": 0.44574031233787537,
      "learning_rate": 2.9111111111111112e-05,
      "loss": 0.0024,
      "step": 7520
    },
    {
      "epoch": 0.8366666666666667,
      "grad_norm": 0.2035495489835739,
      "learning_rate": 2.9083333333333333e-05,
      "loss": 0.0017,
      "step": 7530
    },
    {
      "epoch": 0.8377777777777777,
      "grad_norm": 0.36177292466163635,
      "learning_rate": 2.9055555555555558e-05,
      "loss": 0.0035,
      "step": 7540
    },
    {
      "epoch": 0.8388888888888889,
      "grad_norm": 1.5804628133773804,
      "learning_rate": 2.9027777777777782e-05,
      "loss": 0.0046,
      "step": 7550
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.7166199684143066,
      "learning_rate": 2.9e-05,
      "loss": 0.0024,
      "step": 7560
    },
    {
      "epoch": 0.8411111111111111,
      "grad_norm": 1.096932053565979,
      "learning_rate": 2.897222222222222e-05,
      "loss": 0.0017,
      "step": 7570
    },
    {
      "epoch": 0.8422222222222222,
      "grad_norm": 0.6864030361175537,
      "learning_rate": 2.8944444444444446e-05,
      "loss": 0.0033,
      "step": 7580
    },
    {
      "epoch": 0.8433333333333334,
      "grad_norm": 0.34539124369621277,
      "learning_rate": 2.891666666666667e-05,
      "loss": 0.0027,
      "step": 7590
    },
    {
      "epoch": 0.8444444444444444,
      "grad_norm": 0.46774154901504517,
      "learning_rate": 2.8888888888888888e-05,
      "loss": 0.002,
      "step": 7600
    },
    {
      "epoch": 0.8455555555555555,
      "grad_norm": 0.6777253150939941,
      "learning_rate": 2.886111111111111e-05,
      "loss": 0.0025,
      "step": 7610
    },
    {
      "epoch": 0.8466666666666667,
      "grad_norm": 0.7033416032791138,
      "learning_rate": 2.8833333333333334e-05,
      "loss": 0.0022,
      "step": 7620
    },
    {
      "epoch": 0.8477777777777777,
      "grad_norm": 0.14118370413780212,
      "learning_rate": 2.880555555555556e-05,
      "loss": 0.002,
      "step": 7630
    },
    {
      "epoch": 0.8488888888888889,
      "grad_norm": 0.4449675679206848,
      "learning_rate": 2.877777777777778e-05,
      "loss": 0.0031,
      "step": 7640
    },
    {
      "epoch": 0.85,
      "grad_norm": 1.1865276098251343,
      "learning_rate": 2.8749999999999997e-05,
      "loss": 0.0026,
      "step": 7650
    },
    {
      "epoch": 0.8511111111111112,
      "grad_norm": 1.2977718114852905,
      "learning_rate": 2.8722222222222222e-05,
      "loss": 0.002,
      "step": 7660
    },
    {
      "epoch": 0.8522222222222222,
      "grad_norm": 0.9155640602111816,
      "learning_rate": 2.8694444444444447e-05,
      "loss": 0.0019,
      "step": 7670
    },
    {
      "epoch": 0.8533333333333334,
      "grad_norm": 0.4809284210205078,
      "learning_rate": 2.8666666666666668e-05,
      "loss": 0.0031,
      "step": 7680
    },
    {
      "epoch": 0.8544444444444445,
      "grad_norm": 0.9522565603256226,
      "learning_rate": 2.8638888888888892e-05,
      "loss": 0.0027,
      "step": 7690
    },
    {
      "epoch": 0.8555555555555555,
      "grad_norm": 0.7747524976730347,
      "learning_rate": 2.861111111111111e-05,
      "loss": 0.0025,
      "step": 7700
    },
    {
      "epoch": 0.8566666666666667,
      "grad_norm": 0.6311603784561157,
      "learning_rate": 2.8583333333333335e-05,
      "loss": 0.0036,
      "step": 7710
    },
    {
      "epoch": 0.8577777777777778,
      "grad_norm": 1.0275630950927734,
      "learning_rate": 2.855555555555556e-05,
      "loss": 0.0038,
      "step": 7720
    },
    {
      "epoch": 0.8588888888888889,
      "grad_norm": 1.0668988227844238,
      "learning_rate": 2.852777777777778e-05,
      "loss": 0.0032,
      "step": 7730
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.5444148182868958,
      "learning_rate": 2.8499999999999998e-05,
      "loss": 0.0042,
      "step": 7740
    },
    {
      "epoch": 0.8611111111111112,
      "grad_norm": 0.41354864835739136,
      "learning_rate": 2.8472222222222223e-05,
      "loss": 0.0021,
      "step": 7750
    },
    {
      "epoch": 0.8622222222222222,
      "grad_norm": 0.4738128185272217,
      "learning_rate": 2.8444444444444447e-05,
      "loss": 0.0028,
      "step": 7760
    },
    {
      "epoch": 0.8633333333333333,
      "grad_norm": 0.41209447383880615,
      "learning_rate": 2.841666666666667e-05,
      "loss": 0.0029,
      "step": 7770
    },
    {
      "epoch": 0.8644444444444445,
      "grad_norm": 0.6147467494010925,
      "learning_rate": 2.8388888888888893e-05,
      "loss": 0.0032,
      "step": 7780
    },
    {
      "epoch": 0.8655555555555555,
      "grad_norm": 0.9135393500328064,
      "learning_rate": 2.836111111111111e-05,
      "loss": 0.0025,
      "step": 7790
    },
    {
      "epoch": 0.8666666666666667,
      "grad_norm": 0.918085515499115,
      "learning_rate": 2.8333333333333335e-05,
      "loss": 0.0031,
      "step": 7800
    },
    {
      "epoch": 0.8677777777777778,
      "grad_norm": 1.2993630170822144,
      "learning_rate": 2.8305555555555557e-05,
      "loss": 0.0016,
      "step": 7810
    },
    {
      "epoch": 0.8688888888888889,
      "grad_norm": 0.32946375012397766,
      "learning_rate": 2.827777777777778e-05,
      "loss": 0.0051,
      "step": 7820
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.2834133505821228,
      "learning_rate": 2.825e-05,
      "loss": 0.003,
      "step": 7830
    },
    {
      "epoch": 0.8711111111111111,
      "grad_norm": 0.33652031421661377,
      "learning_rate": 2.8222222222222223e-05,
      "loss": 0.002,
      "step": 7840
    },
    {
      "epoch": 0.8722222222222222,
      "grad_norm": 0.9484490156173706,
      "learning_rate": 2.8194444444444445e-05,
      "loss": 0.0044,
      "step": 7850
    },
    {
      "epoch": 0.8733333333333333,
      "grad_norm": 0.42883360385894775,
      "learning_rate": 2.816666666666667e-05,
      "loss": 0.0023,
      "step": 7860
    },
    {
      "epoch": 0.8744444444444445,
      "grad_norm": 0.7706499099731445,
      "learning_rate": 2.8138888888888894e-05,
      "loss": 0.004,
      "step": 7870
    },
    {
      "epoch": 0.8755555555555555,
      "grad_norm": 0.8144621253013611,
      "learning_rate": 2.811111111111111e-05,
      "loss": 0.0017,
      "step": 7880
    },
    {
      "epoch": 0.8766666666666667,
      "grad_norm": 0.22674043476581573,
      "learning_rate": 2.8083333333333333e-05,
      "loss": 0.0033,
      "step": 7890
    },
    {
      "epoch": 0.8777777777777778,
      "grad_norm": 1.807982325553894,
      "learning_rate": 2.8055555555555557e-05,
      "loss": 0.002,
      "step": 7900
    },
    {
      "epoch": 0.8788888888888889,
      "grad_norm": 0.4803933799266815,
      "learning_rate": 2.8027777777777782e-05,
      "loss": 0.0027,
      "step": 7910
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.978137731552124,
      "learning_rate": 2.8000000000000003e-05,
      "loss": 0.0028,
      "step": 7920
    },
    {
      "epoch": 0.8811111111111111,
      "grad_norm": 0.7045735716819763,
      "learning_rate": 2.797222222222222e-05,
      "loss": 0.0026,
      "step": 7930
    },
    {
      "epoch": 0.8822222222222222,
      "grad_norm": 0.35491254925727844,
      "learning_rate": 2.7944444444444445e-05,
      "loss": 0.0026,
      "step": 7940
    },
    {
      "epoch": 0.8833333333333333,
      "grad_norm": 0.3699679970741272,
      "learning_rate": 2.791666666666667e-05,
      "loss": 0.0026,
      "step": 7950
    },
    {
      "epoch": 0.8844444444444445,
      "grad_norm": 0.8997035622596741,
      "learning_rate": 2.788888888888889e-05,
      "loss": 0.0016,
      "step": 7960
    },
    {
      "epoch": 0.8855555555555555,
      "grad_norm": 0.524021327495575,
      "learning_rate": 2.786111111111111e-05,
      "loss": 0.0034,
      "step": 7970
    },
    {
      "epoch": 0.8866666666666667,
      "grad_norm": 1.7155297994613647,
      "learning_rate": 2.7833333333333333e-05,
      "loss": 0.0037,
      "step": 7980
    },
    {
      "epoch": 0.8877777777777778,
      "grad_norm": 0.8683817982673645,
      "learning_rate": 2.7805555555555558e-05,
      "loss": 0.0031,
      "step": 7990
    },
    {
      "epoch": 0.8888888888888888,
      "grad_norm": 0.520753026008606,
      "learning_rate": 2.777777777777778e-05,
      "loss": 0.003,
      "step": 8000
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.582534909248352,
      "learning_rate": 2.7750000000000004e-05,
      "loss": 0.002,
      "step": 8010
    },
    {
      "epoch": 0.8911111111111111,
      "grad_norm": 1.109519362449646,
      "learning_rate": 2.772222222222222e-05,
      "loss": 0.0023,
      "step": 8020
    },
    {
      "epoch": 0.8922222222222222,
      "grad_norm": 0.3865494728088379,
      "learning_rate": 2.7694444444444446e-05,
      "loss": 0.003,
      "step": 8030
    },
    {
      "epoch": 0.8933333333333333,
      "grad_norm": 0.295432448387146,
      "learning_rate": 2.7666666666666667e-05,
      "loss": 0.0033,
      "step": 8040
    },
    {
      "epoch": 0.8944444444444445,
      "grad_norm": 0.927492618560791,
      "learning_rate": 2.7638888888888892e-05,
      "loss": 0.003,
      "step": 8050
    },
    {
      "epoch": 0.8955555555555555,
      "grad_norm": 1.889712929725647,
      "learning_rate": 2.761111111111111e-05,
      "loss": 0.0041,
      "step": 8060
    },
    {
      "epoch": 0.8966666666666666,
      "grad_norm": 0.8142092227935791,
      "learning_rate": 2.7583333333333334e-05,
      "loss": 0.002,
      "step": 8070
    },
    {
      "epoch": 0.8977777777777778,
      "grad_norm": 0.7095982432365417,
      "learning_rate": 2.7555555555555555e-05,
      "loss": 0.0046,
      "step": 8080
    },
    {
      "epoch": 0.8988888888888888,
      "grad_norm": 0.5954828858375549,
      "learning_rate": 2.752777777777778e-05,
      "loss": 0.0024,
      "step": 8090
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.5029622316360474,
      "learning_rate": 2.7500000000000004e-05,
      "loss": 0.0024,
      "step": 8100
    },
    {
      "epoch": 0.9011111111111111,
      "grad_norm": 0.9345322847366333,
      "learning_rate": 2.7472222222222222e-05,
      "loss": 0.0015,
      "step": 8110
    },
    {
      "epoch": 0.9022222222222223,
      "grad_norm": 0.4993644058704376,
      "learning_rate": 2.7444444444444443e-05,
      "loss": 0.0026,
      "step": 8120
    },
    {
      "epoch": 0.9033333333333333,
      "grad_norm": 1.0469365119934082,
      "learning_rate": 2.7416666666666668e-05,
      "loss": 0.0017,
      "step": 8130
    },
    {
      "epoch": 0.9044444444444445,
      "grad_norm": 0.5994834899902344,
      "learning_rate": 2.7388888888888892e-05,
      "loss": 0.0016,
      "step": 8140
    },
    {
      "epoch": 0.9055555555555556,
      "grad_norm": 0.14685273170471191,
      "learning_rate": 2.7361111111111114e-05,
      "loss": 0.0022,
      "step": 8150
    },
    {
      "epoch": 0.9066666666666666,
      "grad_norm": 0.6017106771469116,
      "learning_rate": 2.733333333333333e-05,
      "loss": 0.0024,
      "step": 8160
    },
    {
      "epoch": 0.9077777777777778,
      "grad_norm": 0.49400535225868225,
      "learning_rate": 2.7305555555555556e-05,
      "loss": 0.004,
      "step": 8170
    },
    {
      "epoch": 0.9088888888888889,
      "grad_norm": 1.0222437381744385,
      "learning_rate": 2.727777777777778e-05,
      "loss": 0.0029,
      "step": 8180
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.9953376650810242,
      "learning_rate": 2.725e-05,
      "loss": 0.0029,
      "step": 8190
    },
    {
      "epoch": 0.9111111111111111,
      "grad_norm": 1.490415096282959,
      "learning_rate": 2.7222222222222223e-05,
      "loss": 0.0025,
      "step": 8200
    },
    {
      "epoch": 0.9122222222222223,
      "grad_norm": 0.32749488949775696,
      "learning_rate": 2.7194444444444444e-05,
      "loss": 0.003,
      "step": 8210
    },
    {
      "epoch": 0.9133333333333333,
      "grad_norm": 0.919975221157074,
      "learning_rate": 2.716666666666667e-05,
      "loss": 0.0027,
      "step": 8220
    },
    {
      "epoch": 0.9144444444444444,
      "grad_norm": 0.7231315970420837,
      "learning_rate": 2.7138888888888893e-05,
      "loss": 0.0018,
      "step": 8230
    },
    {
      "epoch": 0.9155555555555556,
      "grad_norm": 0.5061383843421936,
      "learning_rate": 2.7111111111111114e-05,
      "loss": 0.0029,
      "step": 8240
    },
    {
      "epoch": 0.9166666666666666,
      "grad_norm": 1.570374846458435,
      "learning_rate": 2.7083333333333332e-05,
      "loss": 0.0037,
      "step": 8250
    },
    {
      "epoch": 0.9177777777777778,
      "grad_norm": 0.7926295399665833,
      "learning_rate": 2.7055555555555557e-05,
      "loss": 0.003,
      "step": 8260
    },
    {
      "epoch": 0.9188888888888889,
      "grad_norm": 0.21417191624641418,
      "learning_rate": 2.702777777777778e-05,
      "loss": 0.0036,
      "step": 8270
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.37056905031204224,
      "learning_rate": 2.7000000000000002e-05,
      "loss": 0.0032,
      "step": 8280
    },
    {
      "epoch": 0.9211111111111111,
      "grad_norm": 0.5052613019943237,
      "learning_rate": 2.697222222222222e-05,
      "loss": 0.0033,
      "step": 8290
    },
    {
      "epoch": 0.9222222222222223,
      "grad_norm": 0.9818968772888184,
      "learning_rate": 2.6944444444444445e-05,
      "loss": 0.0017,
      "step": 8300
    },
    {
      "epoch": 0.9233333333333333,
      "grad_norm": 0.34621232748031616,
      "learning_rate": 2.691666666666667e-05,
      "loss": 0.0033,
      "step": 8310
    },
    {
      "epoch": 0.9244444444444444,
      "grad_norm": 0.2217799872159958,
      "learning_rate": 2.688888888888889e-05,
      "loss": 0.0016,
      "step": 8320
    },
    {
      "epoch": 0.9255555555555556,
      "grad_norm": 0.9134103059768677,
      "learning_rate": 2.6861111111111115e-05,
      "loss": 0.0035,
      "step": 8330
    },
    {
      "epoch": 0.9266666666666666,
      "grad_norm": 1.0446566343307495,
      "learning_rate": 2.6833333333333333e-05,
      "loss": 0.0027,
      "step": 8340
    },
    {
      "epoch": 0.9277777777777778,
      "grad_norm": 0.3893686532974243,
      "learning_rate": 2.6805555555555557e-05,
      "loss": 0.0019,
      "step": 8350
    },
    {
      "epoch": 0.9288888888888889,
      "grad_norm": 0.6357945799827576,
      "learning_rate": 2.677777777777778e-05,
      "loss": 0.0046,
      "step": 8360
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.1827273964881897,
      "learning_rate": 2.6750000000000003e-05,
      "loss": 0.0023,
      "step": 8370
    },
    {
      "epoch": 0.9311111111111111,
      "grad_norm": 0.6334822177886963,
      "learning_rate": 2.6722222222222228e-05,
      "loss": 0.0037,
      "step": 8380
    },
    {
      "epoch": 0.9322222222222222,
      "grad_norm": 0.4426812529563904,
      "learning_rate": 2.6694444444444445e-05,
      "loss": 0.0021,
      "step": 8390
    },
    {
      "epoch": 0.9333333333333333,
      "grad_norm": 0.6338089108467102,
      "learning_rate": 2.6666666666666667e-05,
      "loss": 0.0027,
      "step": 8400
    },
    {
      "epoch": 0.9344444444444444,
      "grad_norm": 0.43883922696113586,
      "learning_rate": 2.663888888888889e-05,
      "loss": 0.0015,
      "step": 8410
    },
    {
      "epoch": 0.9355555555555556,
      "grad_norm": 0.49025192856788635,
      "learning_rate": 2.6611111111111116e-05,
      "loss": 0.0028,
      "step": 8420
    },
    {
      "epoch": 0.9366666666666666,
      "grad_norm": 0.29782578349113464,
      "learning_rate": 2.6583333333333333e-05,
      "loss": 0.0032,
      "step": 8430
    },
    {
      "epoch": 0.9377777777777778,
      "grad_norm": 0.3119035065174103,
      "learning_rate": 2.6555555555555555e-05,
      "loss": 0.0025,
      "step": 8440
    },
    {
      "epoch": 0.9388888888888889,
      "grad_norm": 0.41353297233581543,
      "learning_rate": 2.652777777777778e-05,
      "loss": 0.0019,
      "step": 8450
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.34153446555137634,
      "learning_rate": 2.6500000000000004e-05,
      "loss": 0.002,
      "step": 8460
    },
    {
      "epoch": 0.9411111111111111,
      "grad_norm": 0.29125547409057617,
      "learning_rate": 2.6472222222222225e-05,
      "loss": 0.0024,
      "step": 8470
    },
    {
      "epoch": 0.9422222222222222,
      "grad_norm": 0.20076610147953033,
      "learning_rate": 2.6444444444444443e-05,
      "loss": 0.0041,
      "step": 8480
    },
    {
      "epoch": 0.9433333333333334,
      "grad_norm": 0.39438194036483765,
      "learning_rate": 2.6416666666666667e-05,
      "loss": 0.002,
      "step": 8490
    },
    {
      "epoch": 0.9444444444444444,
      "grad_norm": 0.5858469605445862,
      "learning_rate": 2.6388888888888892e-05,
      "loss": 0.0033,
      "step": 8500
    },
    {
      "epoch": 0.9455555555555556,
      "grad_norm": 0.39891403913497925,
      "learning_rate": 2.6361111111111113e-05,
      "loss": 0.0031,
      "step": 8510
    },
    {
      "epoch": 0.9466666666666667,
      "grad_norm": 0.43900448083877563,
      "learning_rate": 2.633333333333333e-05,
      "loss": 0.0032,
      "step": 8520
    },
    {
      "epoch": 0.9477777777777778,
      "grad_norm": 0.3402964472770691,
      "learning_rate": 2.6305555555555555e-05,
      "loss": 0.0018,
      "step": 8530
    },
    {
      "epoch": 0.9488888888888889,
      "grad_norm": 1.5125728845596313,
      "learning_rate": 2.627777777777778e-05,
      "loss": 0.0041,
      "step": 8540
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.6007381677627563,
      "learning_rate": 2.625e-05,
      "loss": 0.0026,
      "step": 8550
    },
    {
      "epoch": 0.9511111111111111,
      "grad_norm": 0.5349636673927307,
      "learning_rate": 2.6222222222222226e-05,
      "loss": 0.0013,
      "step": 8560
    },
    {
      "epoch": 0.9522222222222222,
      "grad_norm": 0.8142592310905457,
      "learning_rate": 2.6194444444444443e-05,
      "loss": 0.0041,
      "step": 8570
    },
    {
      "epoch": 0.9533333333333334,
      "grad_norm": 0.6942611336708069,
      "learning_rate": 2.6166666666666668e-05,
      "loss": 0.0018,
      "step": 8580
    },
    {
      "epoch": 0.9544444444444444,
      "grad_norm": 0.4798634648323059,
      "learning_rate": 2.613888888888889e-05,
      "loss": 0.0026,
      "step": 8590
    },
    {
      "epoch": 0.9555555555555556,
      "grad_norm": 0.1364576816558838,
      "learning_rate": 2.6111111111111114e-05,
      "loss": 0.0042,
      "step": 8600
    },
    {
      "epoch": 0.9566666666666667,
      "grad_norm": 0.9739030599594116,
      "learning_rate": 2.608333333333333e-05,
      "loss": 0.0035,
      "step": 8610
    },
    {
      "epoch": 0.9577777777777777,
      "grad_norm": 0.5425032377243042,
      "learning_rate": 2.6055555555555556e-05,
      "loss": 0.0023,
      "step": 8620
    },
    {
      "epoch": 0.9588888888888889,
      "grad_norm": 0.33681946992874146,
      "learning_rate": 2.6027777777777777e-05,
      "loss": 0.0038,
      "step": 8630
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.4202065169811249,
      "learning_rate": 2.6000000000000002e-05,
      "loss": 0.0025,
      "step": 8640
    },
    {
      "epoch": 0.9611111111111111,
      "grad_norm": 0.22853799164295197,
      "learning_rate": 2.5972222222222226e-05,
      "loss": 0.0022,
      "step": 8650
    },
    {
      "epoch": 0.9622222222222222,
      "grad_norm": 0.7109531164169312,
      "learning_rate": 2.5944444444444444e-05,
      "loss": 0.003,
      "step": 8660
    },
    {
      "epoch": 0.9633333333333334,
      "grad_norm": 0.3069259524345398,
      "learning_rate": 2.5916666666666665e-05,
      "loss": 0.0022,
      "step": 8670
    },
    {
      "epoch": 0.9644444444444444,
      "grad_norm": 0.743016242980957,
      "learning_rate": 2.588888888888889e-05,
      "loss": 0.0039,
      "step": 8680
    },
    {
      "epoch": 0.9655555555555555,
      "grad_norm": 0.7609074711799622,
      "learning_rate": 2.5861111111111114e-05,
      "loss": 0.0027,
      "step": 8690
    },
    {
      "epoch": 0.9666666666666667,
      "grad_norm": 0.6789766550064087,
      "learning_rate": 2.5833333333333336e-05,
      "loss": 0.002,
      "step": 8700
    },
    {
      "epoch": 0.9677777777777777,
      "grad_norm": 0.7809475660324097,
      "learning_rate": 2.5805555555555553e-05,
      "loss": 0.0036,
      "step": 8710
    },
    {
      "epoch": 0.9688888888888889,
      "grad_norm": 0.5542806386947632,
      "learning_rate": 2.5777777777777778e-05,
      "loss": 0.0023,
      "step": 8720
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.4628327190876007,
      "learning_rate": 2.5750000000000002e-05,
      "loss": 0.0015,
      "step": 8730
    },
    {
      "epoch": 0.9711111111111111,
      "grad_norm": 1.081859827041626,
      "learning_rate": 2.5722222222222224e-05,
      "loss": 0.0019,
      "step": 8740
    },
    {
      "epoch": 0.9722222222222222,
      "grad_norm": 0.4133208990097046,
      "learning_rate": 2.5694444444444445e-05,
      "loss": 0.0024,
      "step": 8750
    },
    {
      "epoch": 0.9733333333333334,
      "grad_norm": 0.4224258363246918,
      "learning_rate": 2.5666666666666666e-05,
      "loss": 0.002,
      "step": 8760
    },
    {
      "epoch": 0.9744444444444444,
      "grad_norm": 0.7377756834030151,
      "learning_rate": 2.563888888888889e-05,
      "loss": 0.0041,
      "step": 8770
    },
    {
      "epoch": 0.9755555555555555,
      "grad_norm": 0.9499526619911194,
      "learning_rate": 2.5611111111111115e-05,
      "loss": 0.003,
      "step": 8780
    },
    {
      "epoch": 0.9766666666666667,
      "grad_norm": 0.658311128616333,
      "learning_rate": 2.5583333333333336e-05,
      "loss": 0.0035,
      "step": 8790
    },
    {
      "epoch": 0.9777777777777777,
      "grad_norm": 1.2164109945297241,
      "learning_rate": 2.5555555555555554e-05,
      "loss": 0.0022,
      "step": 8800
    },
    {
      "epoch": 0.9788888888888889,
      "grad_norm": 0.877289354801178,
      "learning_rate": 2.552777777777778e-05,
      "loss": 0.0024,
      "step": 8810
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.6537654995918274,
      "learning_rate": 2.5500000000000003e-05,
      "loss": 0.0025,
      "step": 8820
    },
    {
      "epoch": 0.9811111111111112,
      "grad_norm": 0.35503461956977844,
      "learning_rate": 2.5472222222222224e-05,
      "loss": 0.0018,
      "step": 8830
    },
    {
      "epoch": 0.9822222222222222,
      "grad_norm": 0.36828503012657166,
      "learning_rate": 2.5444444444444442e-05,
      "loss": 0.0018,
      "step": 8840
    },
    {
      "epoch": 0.9833333333333333,
      "grad_norm": 0.39574047923088074,
      "learning_rate": 2.5416666666666667e-05,
      "loss": 0.004,
      "step": 8850
    },
    {
      "epoch": 0.9844444444444445,
      "grad_norm": 0.5337520241737366,
      "learning_rate": 2.538888888888889e-05,
      "loss": 0.0038,
      "step": 8860
    },
    {
      "epoch": 0.9855555555555555,
      "grad_norm": 0.8086676001548767,
      "learning_rate": 2.5361111111111112e-05,
      "loss": 0.0024,
      "step": 8870
    },
    {
      "epoch": 0.9866666666666667,
      "grad_norm": 0.7771495580673218,
      "learning_rate": 2.5333333333333337e-05,
      "loss": 0.0014,
      "step": 8880
    },
    {
      "epoch": 0.9877777777777778,
      "grad_norm": 0.607947587966919,
      "learning_rate": 2.5305555555555555e-05,
      "loss": 0.0041,
      "step": 8890
    },
    {
      "epoch": 0.9888888888888889,
      "grad_norm": 0.2738959491252899,
      "learning_rate": 2.527777777777778e-05,
      "loss": 0.0036,
      "step": 8900
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.4211924374103546,
      "learning_rate": 2.525e-05,
      "loss": 0.0026,
      "step": 8910
    },
    {
      "epoch": 0.9911111111111112,
      "grad_norm": 0.37486371397972107,
      "learning_rate": 2.5222222222222225e-05,
      "loss": 0.0027,
      "step": 8920
    },
    {
      "epoch": 0.9922222222222222,
      "grad_norm": 0.16590437293052673,
      "learning_rate": 2.519444444444445e-05,
      "loss": 0.0037,
      "step": 8930
    },
    {
      "epoch": 0.9933333333333333,
      "grad_norm": 0.40324777364730835,
      "learning_rate": 2.5166666666666667e-05,
      "loss": 0.0044,
      "step": 8940
    },
    {
      "epoch": 0.9944444444444445,
      "grad_norm": 0.40164604783058167,
      "learning_rate": 2.513888888888889e-05,
      "loss": 0.0026,
      "step": 8950
    },
    {
      "epoch": 0.9955555555555555,
      "grad_norm": 1.386362075805664,
      "learning_rate": 2.5111111111111113e-05,
      "loss": 0.0036,
      "step": 8960
    },
    {
      "epoch": 0.9966666666666667,
      "grad_norm": 1.2994028329849243,
      "learning_rate": 2.5083333333333338e-05,
      "loss": 0.0029,
      "step": 8970
    },
    {
      "epoch": 0.9977777777777778,
      "grad_norm": 1.2428680658340454,
      "learning_rate": 2.5055555555555555e-05,
      "loss": 0.0027,
      "step": 8980
    },
    {
      "epoch": 0.9988888888888889,
      "grad_norm": 1.0017980337142944,
      "learning_rate": 2.5027777777777777e-05,
      "loss": 0.0035,
      "step": 8990
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.6536831855773926,
      "learning_rate": 2.5e-05,
      "loss": 0.0028,
      "step": 9000
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.002635263605043292,
      "eval_runtime": 28.1597,
      "eval_samples_per_second": 1420.472,
      "eval_steps_per_second": 35.512,
      "step": 9000
    },
    {
      "epoch": 1.001111111111111,
      "grad_norm": 0.4455735385417938,
      "learning_rate": 2.4972222222222226e-05,
      "loss": 0.0035,
      "step": 9010
    },
    {
      "epoch": 1.0022222222222221,
      "grad_norm": 0.8822943568229675,
      "learning_rate": 2.4944444444444447e-05,
      "loss": 0.0038,
      "step": 9020
    },
    {
      "epoch": 1.0033333333333334,
      "grad_norm": 0.3419266939163208,
      "learning_rate": 2.4916666666666668e-05,
      "loss": 0.003,
      "step": 9030
    },
    {
      "epoch": 1.0044444444444445,
      "grad_norm": 0.8655841946601868,
      "learning_rate": 2.488888888888889e-05,
      "loss": 0.0037,
      "step": 9040
    },
    {
      "epoch": 1.0055555555555555,
      "grad_norm": 0.1911911815404892,
      "learning_rate": 2.4861111111111114e-05,
      "loss": 0.0026,
      "step": 9050
    },
    {
      "epoch": 1.0066666666666666,
      "grad_norm": 0.4130578637123108,
      "learning_rate": 2.4833333333333335e-05,
      "loss": 0.0019,
      "step": 9060
    },
    {
      "epoch": 1.0077777777777779,
      "grad_norm": 0.3658210337162018,
      "learning_rate": 2.4805555555555556e-05,
      "loss": 0.0011,
      "step": 9070
    },
    {
      "epoch": 1.008888888888889,
      "grad_norm": 0.4469245970249176,
      "learning_rate": 2.477777777777778e-05,
      "loss": 0.0022,
      "step": 9080
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.313184916973114,
      "learning_rate": 2.4750000000000002e-05,
      "loss": 0.0027,
      "step": 9090
    },
    {
      "epoch": 1.011111111111111,
      "grad_norm": 0.554568350315094,
      "learning_rate": 2.4722222222222223e-05,
      "loss": 0.0027,
      "step": 9100
    },
    {
      "epoch": 1.0122222222222221,
      "grad_norm": 1.2326656579971313,
      "learning_rate": 2.4694444444444444e-05,
      "loss": 0.003,
      "step": 9110
    },
    {
      "epoch": 1.0133333333333334,
      "grad_norm": 0.42810770869255066,
      "learning_rate": 2.466666666666667e-05,
      "loss": 0.0028,
      "step": 9120
    },
    {
      "epoch": 1.0144444444444445,
      "grad_norm": 1.1950483322143555,
      "learning_rate": 2.463888888888889e-05,
      "loss": 0.0009,
      "step": 9130
    },
    {
      "epoch": 1.0155555555555555,
      "grad_norm": 1.154214859008789,
      "learning_rate": 2.461111111111111e-05,
      "loss": 0.0021,
      "step": 9140
    },
    {
      "epoch": 1.0166666666666666,
      "grad_norm": 0.5954508185386658,
      "learning_rate": 2.4583333333333332e-05,
      "loss": 0.0034,
      "step": 9150
    },
    {
      "epoch": 1.0177777777777777,
      "grad_norm": 1.0540831089019775,
      "learning_rate": 2.4555555555555557e-05,
      "loss": 0.0037,
      "step": 9160
    },
    {
      "epoch": 1.018888888888889,
      "grad_norm": 0.3767932653427124,
      "learning_rate": 2.452777777777778e-05,
      "loss": 0.0029,
      "step": 9170
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.42848464846611023,
      "learning_rate": 2.45e-05,
      "loss": 0.0021,
      "step": 9180
    },
    {
      "epoch": 1.021111111111111,
      "grad_norm": 0.4848744869232178,
      "learning_rate": 2.4472222222222224e-05,
      "loss": 0.0031,
      "step": 9190
    },
    {
      "epoch": 1.0222222222222221,
      "grad_norm": 0.36630767583847046,
      "learning_rate": 2.4444444444444445e-05,
      "loss": 0.0044,
      "step": 9200
    },
    {
      "epoch": 1.0233333333333334,
      "grad_norm": 0.7989292740821838,
      "learning_rate": 2.441666666666667e-05,
      "loss": 0.0029,
      "step": 9210
    },
    {
      "epoch": 1.0244444444444445,
      "grad_norm": 0.9206880331039429,
      "learning_rate": 2.4388888888888887e-05,
      "loss": 0.0027,
      "step": 9220
    },
    {
      "epoch": 1.0255555555555556,
      "grad_norm": 0.5505924820899963,
      "learning_rate": 2.4361111111111112e-05,
      "loss": 0.0017,
      "step": 9230
    },
    {
      "epoch": 1.0266666666666666,
      "grad_norm": 0.9758782982826233,
      "learning_rate": 2.4333333333333336e-05,
      "loss": 0.0029,
      "step": 9240
    },
    {
      "epoch": 1.0277777777777777,
      "grad_norm": 0.3320182263851166,
      "learning_rate": 2.4305555555555558e-05,
      "loss": 0.0024,
      "step": 9250
    },
    {
      "epoch": 1.028888888888889,
      "grad_norm": 0.8314686417579651,
      "learning_rate": 2.427777777777778e-05,
      "loss": 0.0027,
      "step": 9260
    },
    {
      "epoch": 1.03,
      "grad_norm": 0.2715774178504944,
      "learning_rate": 2.425e-05,
      "loss": 0.003,
      "step": 9270
    },
    {
      "epoch": 1.031111111111111,
      "grad_norm": 0.8034668564796448,
      "learning_rate": 2.4222222222222224e-05,
      "loss": 0.0021,
      "step": 9280
    },
    {
      "epoch": 1.0322222222222222,
      "grad_norm": 0.48299968242645264,
      "learning_rate": 2.4194444444444446e-05,
      "loss": 0.0025,
      "step": 9290
    },
    {
      "epoch": 1.0333333333333334,
      "grad_norm": 0.7405492067337036,
      "learning_rate": 2.4166666666666667e-05,
      "loss": 0.0039,
      "step": 9300
    },
    {
      "epoch": 1.0344444444444445,
      "grad_norm": 0.7819569706916809,
      "learning_rate": 2.4138888888888888e-05,
      "loss": 0.0023,
      "step": 9310
    },
    {
      "epoch": 1.0355555555555556,
      "grad_norm": 0.7953463196754456,
      "learning_rate": 2.4111111111111113e-05,
      "loss": 0.0028,
      "step": 9320
    },
    {
      "epoch": 1.0366666666666666,
      "grad_norm": 1.273681640625,
      "learning_rate": 2.4083333333333337e-05,
      "loss": 0.0016,
      "step": 9330
    },
    {
      "epoch": 1.0377777777777777,
      "grad_norm": 0.3580164313316345,
      "learning_rate": 2.4055555555555555e-05,
      "loss": 0.003,
      "step": 9340
    },
    {
      "epoch": 1.038888888888889,
      "grad_norm": 0.23814699053764343,
      "learning_rate": 2.402777777777778e-05,
      "loss": 0.0024,
      "step": 9350
    },
    {
      "epoch": 1.04,
      "grad_norm": 0.8029000759124756,
      "learning_rate": 2.4e-05,
      "loss": 0.0031,
      "step": 9360
    },
    {
      "epoch": 1.041111111111111,
      "grad_norm": 0.33785513043403625,
      "learning_rate": 2.3972222222222225e-05,
      "loss": 0.0023,
      "step": 9370
    },
    {
      "epoch": 1.0422222222222222,
      "grad_norm": 0.5598128437995911,
      "learning_rate": 2.3944444444444443e-05,
      "loss": 0.0029,
      "step": 9380
    },
    {
      "epoch": 1.0433333333333334,
      "grad_norm": 1.0147918462753296,
      "learning_rate": 2.3916666666666668e-05,
      "loss": 0.0019,
      "step": 9390
    },
    {
      "epoch": 1.0444444444444445,
      "grad_norm": 0.68538498878479,
      "learning_rate": 2.3888888888888892e-05,
      "loss": 0.0035,
      "step": 9400
    },
    {
      "epoch": 1.0455555555555556,
      "grad_norm": 0.31008321046829224,
      "learning_rate": 2.3861111111111113e-05,
      "loss": 0.0024,
      "step": 9410
    },
    {
      "epoch": 1.0466666666666666,
      "grad_norm": 0.5293928980827332,
      "learning_rate": 2.3833333333333334e-05,
      "loss": 0.0016,
      "step": 9420
    },
    {
      "epoch": 1.0477777777777777,
      "grad_norm": 0.22732101380825043,
      "learning_rate": 2.3805555555555556e-05,
      "loss": 0.0022,
      "step": 9430
    },
    {
      "epoch": 1.048888888888889,
      "grad_norm": 0.9028283357620239,
      "learning_rate": 2.377777777777778e-05,
      "loss": 0.0031,
      "step": 9440
    },
    {
      "epoch": 1.05,
      "grad_norm": 0.7968275547027588,
      "learning_rate": 2.375e-05,
      "loss": 0.002,
      "step": 9450
    },
    {
      "epoch": 1.051111111111111,
      "grad_norm": 0.6262202858924866,
      "learning_rate": 2.3722222222222222e-05,
      "loss": 0.0018,
      "step": 9460
    },
    {
      "epoch": 1.0522222222222222,
      "grad_norm": 0.8907027244567871,
      "learning_rate": 2.3694444444444447e-05,
      "loss": 0.0026,
      "step": 9470
    },
    {
      "epoch": 1.0533333333333332,
      "grad_norm": 0.7563890814781189,
      "learning_rate": 2.3666666666666668e-05,
      "loss": 0.0032,
      "step": 9480
    },
    {
      "epoch": 1.0544444444444445,
      "grad_norm": 1.1385022401809692,
      "learning_rate": 2.363888888888889e-05,
      "loss": 0.0022,
      "step": 9490
    },
    {
      "epoch": 1.0555555555555556,
      "grad_norm": 0.18433427810668945,
      "learning_rate": 2.361111111111111e-05,
      "loss": 0.0031,
      "step": 9500
    },
    {
      "epoch": 1.0566666666666666,
      "grad_norm": 0.6370303630828857,
      "learning_rate": 2.3583333333333335e-05,
      "loss": 0.003,
      "step": 9510
    },
    {
      "epoch": 1.0577777777777777,
      "grad_norm": 0.3241952955722809,
      "learning_rate": 2.3555555555555556e-05,
      "loss": 0.002,
      "step": 9520
    },
    {
      "epoch": 1.058888888888889,
      "grad_norm": 0.2838745713233948,
      "learning_rate": 2.3527777777777777e-05,
      "loss": 0.004,
      "step": 9530
    },
    {
      "epoch": 1.06,
      "grad_norm": 0.921293318271637,
      "learning_rate": 2.35e-05,
      "loss": 0.0015,
      "step": 9540
    },
    {
      "epoch": 1.0611111111111111,
      "grad_norm": 0.7209481596946716,
      "learning_rate": 2.3472222222222223e-05,
      "loss": 0.0039,
      "step": 9550
    },
    {
      "epoch": 1.0622222222222222,
      "grad_norm": 0.7214418649673462,
      "learning_rate": 2.3444444444444448e-05,
      "loss": 0.0019,
      "step": 9560
    },
    {
      "epoch": 1.0633333333333332,
      "grad_norm": 1.1716235876083374,
      "learning_rate": 2.341666666666667e-05,
      "loss": 0.0027,
      "step": 9570
    },
    {
      "epoch": 1.0644444444444445,
      "grad_norm": 1.3773576021194458,
      "learning_rate": 2.338888888888889e-05,
      "loss": 0.0035,
      "step": 9580
    },
    {
      "epoch": 1.0655555555555556,
      "grad_norm": 0.20300434529781342,
      "learning_rate": 2.336111111111111e-05,
      "loss": 0.0022,
      "step": 9590
    },
    {
      "epoch": 1.0666666666666667,
      "grad_norm": 1.0836902856826782,
      "learning_rate": 2.3333333333333336e-05,
      "loss": 0.0035,
      "step": 9600
    },
    {
      "epoch": 1.0677777777777777,
      "grad_norm": 0.2595375180244446,
      "learning_rate": 2.3305555555555557e-05,
      "loss": 0.0024,
      "step": 9610
    },
    {
      "epoch": 1.068888888888889,
      "grad_norm": 0.276195228099823,
      "learning_rate": 2.3277777777777778e-05,
      "loss": 0.0013,
      "step": 9620
    },
    {
      "epoch": 1.07,
      "grad_norm": 0.39432016015052795,
      "learning_rate": 2.3250000000000003e-05,
      "loss": 0.0016,
      "step": 9630
    },
    {
      "epoch": 1.0711111111111111,
      "grad_norm": 0.5202818512916565,
      "learning_rate": 2.3222222222222224e-05,
      "loss": 0.0037,
      "step": 9640
    },
    {
      "epoch": 1.0722222222222222,
      "grad_norm": 0.7532241344451904,
      "learning_rate": 2.3194444444444445e-05,
      "loss": 0.0032,
      "step": 9650
    },
    {
      "epoch": 1.0733333333333333,
      "grad_norm": 0.33681783080101013,
      "learning_rate": 2.3166666666666666e-05,
      "loss": 0.0031,
      "step": 9660
    },
    {
      "epoch": 1.0744444444444445,
      "grad_norm": 0.7083671689033508,
      "learning_rate": 2.313888888888889e-05,
      "loss": 0.0035,
      "step": 9670
    },
    {
      "epoch": 1.0755555555555556,
      "grad_norm": 0.5682876110076904,
      "learning_rate": 2.3111111111111112e-05,
      "loss": 0.0026,
      "step": 9680
    },
    {
      "epoch": 1.0766666666666667,
      "grad_norm": 0.7339712977409363,
      "learning_rate": 2.3083333333333333e-05,
      "loss": 0.0019,
      "step": 9690
    },
    {
      "epoch": 1.0777777777777777,
      "grad_norm": 0.14872391521930695,
      "learning_rate": 2.3055555555555558e-05,
      "loss": 0.0025,
      "step": 9700
    },
    {
      "epoch": 1.0788888888888888,
      "grad_norm": 0.9650283455848694,
      "learning_rate": 2.302777777777778e-05,
      "loss": 0.0033,
      "step": 9710
    },
    {
      "epoch": 1.08,
      "grad_norm": 0.357363224029541,
      "learning_rate": 2.3000000000000003e-05,
      "loss": 0.0028,
      "step": 9720
    },
    {
      "epoch": 1.0811111111111111,
      "grad_norm": 0.7692821621894836,
      "learning_rate": 2.297222222222222e-05,
      "loss": 0.0038,
      "step": 9730
    },
    {
      "epoch": 1.0822222222222222,
      "grad_norm": 0.4196628928184509,
      "learning_rate": 2.2944444444444446e-05,
      "loss": 0.0015,
      "step": 9740
    },
    {
      "epoch": 1.0833333333333333,
      "grad_norm": 0.6116062998771667,
      "learning_rate": 2.2916666666666667e-05,
      "loss": 0.0021,
      "step": 9750
    },
    {
      "epoch": 1.0844444444444445,
      "grad_norm": 0.4402202367782593,
      "learning_rate": 2.288888888888889e-05,
      "loss": 0.0014,
      "step": 9760
    },
    {
      "epoch": 1.0855555555555556,
      "grad_norm": 0.5016900897026062,
      "learning_rate": 2.286111111111111e-05,
      "loss": 0.0035,
      "step": 9770
    },
    {
      "epoch": 1.0866666666666667,
      "grad_norm": 0.38515764474868774,
      "learning_rate": 2.2833333333333334e-05,
      "loss": 0.0019,
      "step": 9780
    },
    {
      "epoch": 1.0877777777777777,
      "grad_norm": 0.7745875120162964,
      "learning_rate": 2.280555555555556e-05,
      "loss": 0.0034,
      "step": 9790
    },
    {
      "epoch": 1.0888888888888888,
      "grad_norm": 0.830592930316925,
      "learning_rate": 2.277777777777778e-05,
      "loss": 0.0031,
      "step": 9800
    },
    {
      "epoch": 1.09,
      "grad_norm": 0.6327815651893616,
      "learning_rate": 2.275e-05,
      "loss": 0.0033,
      "step": 9810
    },
    {
      "epoch": 1.0911111111111111,
      "grad_norm": 0.2961393892765045,
      "learning_rate": 2.2722222222222222e-05,
      "loss": 0.0027,
      "step": 9820
    },
    {
      "epoch": 1.0922222222222222,
      "grad_norm": 0.2996240258216858,
      "learning_rate": 2.2694444444444446e-05,
      "loss": 0.0041,
      "step": 9830
    },
    {
      "epoch": 1.0933333333333333,
      "grad_norm": 0.5580875873565674,
      "learning_rate": 2.2666666666666668e-05,
      "loss": 0.0016,
      "step": 9840
    },
    {
      "epoch": 1.0944444444444446,
      "grad_norm": 0.709304928779602,
      "learning_rate": 2.263888888888889e-05,
      "loss": 0.0024,
      "step": 9850
    },
    {
      "epoch": 1.0955555555555556,
      "grad_norm": 0.7856571674346924,
      "learning_rate": 2.2611111111111113e-05,
      "loss": 0.0026,
      "step": 9860
    },
    {
      "epoch": 1.0966666666666667,
      "grad_norm": 0.9128175377845764,
      "learning_rate": 2.2583333333333335e-05,
      "loss": 0.0042,
      "step": 9870
    },
    {
      "epoch": 1.0977777777777777,
      "grad_norm": 0.7155571579933167,
      "learning_rate": 2.255555555555556e-05,
      "loss": 0.0016,
      "step": 9880
    },
    {
      "epoch": 1.0988888888888888,
      "grad_norm": 0.47728726267814636,
      "learning_rate": 2.2527777777777777e-05,
      "loss": 0.0018,
      "step": 9890
    },
    {
      "epoch": 1.1,
      "grad_norm": 0.7061384320259094,
      "learning_rate": 2.25e-05,
      "loss": 0.0025,
      "step": 9900
    },
    {
      "epoch": 1.1011111111111112,
      "grad_norm": 0.35407304763793945,
      "learning_rate": 2.2472222222222223e-05,
      "loss": 0.0024,
      "step": 9910
    },
    {
      "epoch": 1.1022222222222222,
      "grad_norm": 0.23750682175159454,
      "learning_rate": 2.2444444444444447e-05,
      "loss": 0.0033,
      "step": 9920
    },
    {
      "epoch": 1.1033333333333333,
      "grad_norm": 0.7730443477630615,
      "learning_rate": 2.2416666666666665e-05,
      "loss": 0.0017,
      "step": 9930
    },
    {
      "epoch": 1.1044444444444443,
      "grad_norm": 0.24292264878749847,
      "learning_rate": 2.238888888888889e-05,
      "loss": 0.0042,
      "step": 9940
    },
    {
      "epoch": 1.1055555555555556,
      "grad_norm": 0.4343518316745758,
      "learning_rate": 2.2361111111111114e-05,
      "loss": 0.0013,
      "step": 9950
    },
    {
      "epoch": 1.1066666666666667,
      "grad_norm": 1.1876564025878906,
      "learning_rate": 2.2333333333333335e-05,
      "loss": 0.0024,
      "step": 9960
    },
    {
      "epoch": 1.1077777777777778,
      "grad_norm": 0.46366024017333984,
      "learning_rate": 2.2305555555555556e-05,
      "loss": 0.0024,
      "step": 9970
    },
    {
      "epoch": 1.1088888888888888,
      "grad_norm": 0.4853222072124481,
      "learning_rate": 2.2277777777777778e-05,
      "loss": 0.0022,
      "step": 9980
    },
    {
      "epoch": 1.11,
      "grad_norm": 0.7464315891265869,
      "learning_rate": 2.2250000000000002e-05,
      "loss": 0.0018,
      "step": 9990
    },
    {
      "epoch": 1.1111111111111112,
      "grad_norm": 0.30646848678588867,
      "learning_rate": 2.2222222222222223e-05,
      "loss": 0.0038,
      "step": 10000
    },
    {
      "epoch": 1.1122222222222222,
      "grad_norm": 1.3400518894195557,
      "learning_rate": 2.2194444444444444e-05,
      "loss": 0.0022,
      "step": 10010
    },
    {
      "epoch": 1.1133333333333333,
      "grad_norm": 0.45115962624549866,
      "learning_rate": 2.216666666666667e-05,
      "loss": 0.0018,
      "step": 10020
    },
    {
      "epoch": 1.1144444444444443,
      "grad_norm": 0.7858312726020813,
      "learning_rate": 2.213888888888889e-05,
      "loss": 0.0025,
      "step": 10030
    },
    {
      "epoch": 1.1155555555555556,
      "grad_norm": 0.23274514079093933,
      "learning_rate": 2.211111111111111e-05,
      "loss": 0.0022,
      "step": 10040
    },
    {
      "epoch": 1.1166666666666667,
      "grad_norm": 0.26424047350883484,
      "learning_rate": 2.2083333333333333e-05,
      "loss": 0.0024,
      "step": 10050
    },
    {
      "epoch": 1.1177777777777778,
      "grad_norm": 0.5694652795791626,
      "learning_rate": 2.2055555555555557e-05,
      "loss": 0.0032,
      "step": 10060
    },
    {
      "epoch": 1.1188888888888888,
      "grad_norm": 0.62043696641922,
      "learning_rate": 2.2027777777777778e-05,
      "loss": 0.0024,
      "step": 10070
    },
    {
      "epoch": 1.12,
      "grad_norm": 0.43619316816329956,
      "learning_rate": 2.2000000000000003e-05,
      "loss": 0.0036,
      "step": 10080
    },
    {
      "epoch": 1.1211111111111112,
      "grad_norm": 1.0009822845458984,
      "learning_rate": 2.1972222222222224e-05,
      "loss": 0.002,
      "step": 10090
    },
    {
      "epoch": 1.1222222222222222,
      "grad_norm": 0.40197649598121643,
      "learning_rate": 2.1944444444444445e-05,
      "loss": 0.0023,
      "step": 10100
    },
    {
      "epoch": 1.1233333333333333,
      "grad_norm": 0.4452570080757141,
      "learning_rate": 2.191666666666667e-05,
      "loss": 0.0035,
      "step": 10110
    },
    {
      "epoch": 1.1244444444444444,
      "grad_norm": 0.761959433555603,
      "learning_rate": 2.188888888888889e-05,
      "loss": 0.0028,
      "step": 10120
    },
    {
      "epoch": 1.1255555555555556,
      "grad_norm": 0.7950915098190308,
      "learning_rate": 2.1861111111111112e-05,
      "loss": 0.004,
      "step": 10130
    },
    {
      "epoch": 1.1266666666666667,
      "grad_norm": 0.418117493391037,
      "learning_rate": 2.1833333333333333e-05,
      "loss": 0.0019,
      "step": 10140
    },
    {
      "epoch": 1.1277777777777778,
      "grad_norm": 0.6143043637275696,
      "learning_rate": 2.1805555555555558e-05,
      "loss": 0.0019,
      "step": 10150
    },
    {
      "epoch": 1.1288888888888888,
      "grad_norm": 1.1657086610794067,
      "learning_rate": 2.177777777777778e-05,
      "loss": 0.0038,
      "step": 10160
    },
    {
      "epoch": 1.13,
      "grad_norm": 0.704139232635498,
      "learning_rate": 2.175e-05,
      "loss": 0.0035,
      "step": 10170
    },
    {
      "epoch": 1.1311111111111112,
      "grad_norm": 0.8808297514915466,
      "learning_rate": 2.1722222222222225e-05,
      "loss": 0.0029,
      "step": 10180
    },
    {
      "epoch": 1.1322222222222222,
      "grad_norm": 1.4660332202911377,
      "learning_rate": 2.1694444444444446e-05,
      "loss": 0.0027,
      "step": 10190
    },
    {
      "epoch": 1.1333333333333333,
      "grad_norm": 1.102691888809204,
      "learning_rate": 2.1666666666666667e-05,
      "loss": 0.0024,
      "step": 10200
    },
    {
      "epoch": 1.1344444444444444,
      "grad_norm": 1.0869861841201782,
      "learning_rate": 2.1638888888888888e-05,
      "loss": 0.0024,
      "step": 10210
    },
    {
      "epoch": 1.1355555555555557,
      "grad_norm": 0.4475213289260864,
      "learning_rate": 2.1611111111111113e-05,
      "loss": 0.0027,
      "step": 10220
    },
    {
      "epoch": 1.1366666666666667,
      "grad_norm": 0.5883828997612,
      "learning_rate": 2.1583333333333334e-05,
      "loss": 0.0013,
      "step": 10230
    },
    {
      "epoch": 1.1377777777777778,
      "grad_norm": 0.4670313596725464,
      "learning_rate": 2.1555555555555555e-05,
      "loss": 0.0026,
      "step": 10240
    },
    {
      "epoch": 1.1388888888888888,
      "grad_norm": 0.9693495631217957,
      "learning_rate": 2.152777777777778e-05,
      "loss": 0.003,
      "step": 10250
    },
    {
      "epoch": 1.1400000000000001,
      "grad_norm": 0.39584314823150635,
      "learning_rate": 2.15e-05,
      "loss": 0.0015,
      "step": 10260
    },
    {
      "epoch": 1.1411111111111112,
      "grad_norm": 0.498897910118103,
      "learning_rate": 2.1472222222222225e-05,
      "loss": 0.002,
      "step": 10270
    },
    {
      "epoch": 1.1422222222222222,
      "grad_norm": 0.5057734251022339,
      "learning_rate": 2.1444444444444443e-05,
      "loss": 0.0038,
      "step": 10280
    },
    {
      "epoch": 1.1433333333333333,
      "grad_norm": 0.8803353905677795,
      "learning_rate": 2.1416666666666668e-05,
      "loss": 0.0034,
      "step": 10290
    },
    {
      "epoch": 1.1444444444444444,
      "grad_norm": 0.8200146555900574,
      "learning_rate": 2.138888888888889e-05,
      "loss": 0.0027,
      "step": 10300
    },
    {
      "epoch": 1.1455555555555557,
      "grad_norm": 0.3529326617717743,
      "learning_rate": 2.1361111111111113e-05,
      "loss": 0.0029,
      "step": 10310
    },
    {
      "epoch": 1.1466666666666667,
      "grad_norm": 0.833646833896637,
      "learning_rate": 2.1333333333333335e-05,
      "loss": 0.0022,
      "step": 10320
    },
    {
      "epoch": 1.1477777777777778,
      "grad_norm": 0.5936205387115479,
      "learning_rate": 2.1305555555555556e-05,
      "loss": 0.002,
      "step": 10330
    },
    {
      "epoch": 1.1488888888888888,
      "grad_norm": 0.8441964387893677,
      "learning_rate": 2.127777777777778e-05,
      "loss": 0.0028,
      "step": 10340
    },
    {
      "epoch": 1.15,
      "grad_norm": 0.41009777784347534,
      "learning_rate": 2.125e-05,
      "loss": 0.0022,
      "step": 10350
    },
    {
      "epoch": 1.1511111111111112,
      "grad_norm": 0.22574016451835632,
      "learning_rate": 2.1222222222222223e-05,
      "loss": 0.0021,
      "step": 10360
    },
    {
      "epoch": 1.1522222222222223,
      "grad_norm": 0.8767898678779602,
      "learning_rate": 2.1194444444444444e-05,
      "loss": 0.003,
      "step": 10370
    },
    {
      "epoch": 1.1533333333333333,
      "grad_norm": 0.9522053599357605,
      "learning_rate": 2.116666666666667e-05,
      "loss": 0.003,
      "step": 10380
    },
    {
      "epoch": 1.1544444444444444,
      "grad_norm": 0.7187240719795227,
      "learning_rate": 2.113888888888889e-05,
      "loss": 0.0033,
      "step": 10390
    },
    {
      "epoch": 1.1555555555555554,
      "grad_norm": 0.6210516691207886,
      "learning_rate": 2.111111111111111e-05,
      "loss": 0.0032,
      "step": 10400
    },
    {
      "epoch": 1.1566666666666667,
      "grad_norm": 0.4149720072746277,
      "learning_rate": 2.1083333333333335e-05,
      "loss": 0.0027,
      "step": 10410
    },
    {
      "epoch": 1.1577777777777778,
      "grad_norm": 0.5616205334663391,
      "learning_rate": 2.1055555555555556e-05,
      "loss": 0.0017,
      "step": 10420
    },
    {
      "epoch": 1.1588888888888889,
      "grad_norm": 0.6277226805686951,
      "learning_rate": 2.102777777777778e-05,
      "loss": 0.0042,
      "step": 10430
    },
    {
      "epoch": 1.16,
      "grad_norm": 0.706567645072937,
      "learning_rate": 2.1e-05,
      "loss": 0.0031,
      "step": 10440
    },
    {
      "epoch": 1.1611111111111112,
      "grad_norm": 0.8998408317565918,
      "learning_rate": 2.0972222222222223e-05,
      "loss": 0.002,
      "step": 10450
    },
    {
      "epoch": 1.1622222222222223,
      "grad_norm": 0.9164380431175232,
      "learning_rate": 2.0944444444444445e-05,
      "loss": 0.0032,
      "step": 10460
    },
    {
      "epoch": 1.1633333333333333,
      "grad_norm": 0.8756355047225952,
      "learning_rate": 2.091666666666667e-05,
      "loss": 0.0031,
      "step": 10470
    },
    {
      "epoch": 1.1644444444444444,
      "grad_norm": 0.2424594759941101,
      "learning_rate": 2.088888888888889e-05,
      "loss": 0.0021,
      "step": 10480
    },
    {
      "epoch": 1.1655555555555557,
      "grad_norm": 0.7252755761146545,
      "learning_rate": 2.086111111111111e-05,
      "loss": 0.0024,
      "step": 10490
    },
    {
      "epoch": 1.1666666666666667,
      "grad_norm": 0.311874657869339,
      "learning_rate": 2.0833333333333336e-05,
      "loss": 0.0031,
      "step": 10500
    },
    {
      "epoch": 1.1677777777777778,
      "grad_norm": 1.3326672315597534,
      "learning_rate": 2.0805555555555557e-05,
      "loss": 0.0036,
      "step": 10510
    },
    {
      "epoch": 1.1688888888888889,
      "grad_norm": 0.9362274408340454,
      "learning_rate": 2.077777777777778e-05,
      "loss": 0.0028,
      "step": 10520
    },
    {
      "epoch": 1.17,
      "grad_norm": 0.8505627512931824,
      "learning_rate": 2.075e-05,
      "loss": 0.005,
      "step": 10530
    },
    {
      "epoch": 1.1711111111111112,
      "grad_norm": 0.2848008871078491,
      "learning_rate": 2.0722222222222224e-05,
      "loss": 0.0018,
      "step": 10540
    },
    {
      "epoch": 1.1722222222222223,
      "grad_norm": 0.8182588815689087,
      "learning_rate": 2.0694444444444445e-05,
      "loss": 0.0012,
      "step": 10550
    },
    {
      "epoch": 1.1733333333333333,
      "grad_norm": 0.7536355257034302,
      "learning_rate": 2.0666666666666666e-05,
      "loss": 0.0029,
      "step": 10560
    },
    {
      "epoch": 1.1744444444444444,
      "grad_norm": 0.4482644498348236,
      "learning_rate": 2.063888888888889e-05,
      "loss": 0.002,
      "step": 10570
    },
    {
      "epoch": 1.1755555555555555,
      "grad_norm": 1.087165117263794,
      "learning_rate": 2.0611111111111112e-05,
      "loss": 0.0028,
      "step": 10580
    },
    {
      "epoch": 1.1766666666666667,
      "grad_norm": 0.5151293277740479,
      "learning_rate": 2.0583333333333333e-05,
      "loss": 0.0031,
      "step": 10590
    },
    {
      "epoch": 1.1777777777777778,
      "grad_norm": 0.3911157250404358,
      "learning_rate": 2.0555555555555555e-05,
      "loss": 0.0031,
      "step": 10600
    },
    {
      "epoch": 1.1788888888888889,
      "grad_norm": 0.38842514157295227,
      "learning_rate": 2.052777777777778e-05,
      "loss": 0.0035,
      "step": 10610
    },
    {
      "epoch": 1.18,
      "grad_norm": 0.6915459036827087,
      "learning_rate": 2.05e-05,
      "loss": 0.002,
      "step": 10620
    },
    {
      "epoch": 1.181111111111111,
      "grad_norm": 0.4558451473712921,
      "learning_rate": 2.0472222222222225e-05,
      "loss": 0.0026,
      "step": 10630
    },
    {
      "epoch": 1.1822222222222223,
      "grad_norm": 0.5452444553375244,
      "learning_rate": 2.0444444444444446e-05,
      "loss": 0.0041,
      "step": 10640
    },
    {
      "epoch": 1.1833333333333333,
      "grad_norm": 0.5939311981201172,
      "learning_rate": 2.0416666666666667e-05,
      "loss": 0.0028,
      "step": 10650
    },
    {
      "epoch": 1.1844444444444444,
      "grad_norm": 0.292031466960907,
      "learning_rate": 2.0388888888888892e-05,
      "loss": 0.0021,
      "step": 10660
    },
    {
      "epoch": 1.1855555555555555,
      "grad_norm": 0.5547700524330139,
      "learning_rate": 2.0361111111111113e-05,
      "loss": 0.0036,
      "step": 10670
    },
    {
      "epoch": 1.1866666666666668,
      "grad_norm": 0.36688393354415894,
      "learning_rate": 2.0333333333333334e-05,
      "loss": 0.0031,
      "step": 10680
    },
    {
      "epoch": 1.1877777777777778,
      "grad_norm": 0.8035362958908081,
      "learning_rate": 2.0305555555555555e-05,
      "loss": 0.0038,
      "step": 10690
    },
    {
      "epoch": 1.1888888888888889,
      "grad_norm": 0.4062511920928955,
      "learning_rate": 2.027777777777778e-05,
      "loss": 0.0031,
      "step": 10700
    },
    {
      "epoch": 1.19,
      "grad_norm": 0.7726858854293823,
      "learning_rate": 2.025e-05,
      "loss": 0.0026,
      "step": 10710
    },
    {
      "epoch": 1.1911111111111112,
      "grad_norm": 0.327841192483902,
      "learning_rate": 2.0222222222222222e-05,
      "loss": 0.0029,
      "step": 10720
    },
    {
      "epoch": 1.1922222222222223,
      "grad_norm": 0.7277897000312805,
      "learning_rate": 2.0194444444444447e-05,
      "loss": 0.0029,
      "step": 10730
    },
    {
      "epoch": 1.1933333333333334,
      "grad_norm": 0.3044048249721527,
      "learning_rate": 2.0166666666666668e-05,
      "loss": 0.0024,
      "step": 10740
    },
    {
      "epoch": 1.1944444444444444,
      "grad_norm": 0.36207523941993713,
      "learning_rate": 2.013888888888889e-05,
      "loss": 0.0033,
      "step": 10750
    },
    {
      "epoch": 1.1955555555555555,
      "grad_norm": 0.37165379524230957,
      "learning_rate": 2.011111111111111e-05,
      "loss": 0.0034,
      "step": 10760
    },
    {
      "epoch": 1.1966666666666668,
      "grad_norm": 0.5193033218383789,
      "learning_rate": 2.0083333333333335e-05,
      "loss": 0.0033,
      "step": 10770
    },
    {
      "epoch": 1.1977777777777778,
      "grad_norm": 0.31635817885398865,
      "learning_rate": 2.0055555555555556e-05,
      "loss": 0.0026,
      "step": 10780
    },
    {
      "epoch": 1.198888888888889,
      "grad_norm": 0.330518513917923,
      "learning_rate": 2.0027777777777777e-05,
      "loss": 0.0016,
      "step": 10790
    },
    {
      "epoch": 1.2,
      "grad_norm": 1.1356745958328247,
      "learning_rate": 2e-05,
      "loss": 0.0038,
      "step": 10800
    },
    {
      "epoch": 1.201111111111111,
      "grad_norm": 1.6324248313903809,
      "learning_rate": 1.9972222222222223e-05,
      "loss": 0.003,
      "step": 10810
    },
    {
      "epoch": 1.2022222222222223,
      "grad_norm": 0.5441088080406189,
      "learning_rate": 1.9944444444444447e-05,
      "loss": 0.001,
      "step": 10820
    },
    {
      "epoch": 1.2033333333333334,
      "grad_norm": 0.3748619556427002,
      "learning_rate": 1.9916666666666665e-05,
      "loss": 0.002,
      "step": 10830
    },
    {
      "epoch": 1.2044444444444444,
      "grad_norm": 0.2895600497722626,
      "learning_rate": 1.988888888888889e-05,
      "loss": 0.0036,
      "step": 10840
    },
    {
      "epoch": 1.2055555555555555,
      "grad_norm": 0.8068753480911255,
      "learning_rate": 1.986111111111111e-05,
      "loss": 0.0026,
      "step": 10850
    },
    {
      "epoch": 1.2066666666666666,
      "grad_norm": 0.7812053561210632,
      "learning_rate": 1.9833333333333335e-05,
      "loss": 0.0029,
      "step": 10860
    },
    {
      "epoch": 1.2077777777777778,
      "grad_norm": 1.302944540977478,
      "learning_rate": 1.9805555555555557e-05,
      "loss": 0.003,
      "step": 10870
    },
    {
      "epoch": 1.208888888888889,
      "grad_norm": 0.37449508905410767,
      "learning_rate": 1.9777777777777778e-05,
      "loss": 0.0021,
      "step": 10880
    },
    {
      "epoch": 1.21,
      "grad_norm": 0.8795546293258667,
      "learning_rate": 1.9750000000000002e-05,
      "loss": 0.0036,
      "step": 10890
    },
    {
      "epoch": 1.211111111111111,
      "grad_norm": 0.5150206685066223,
      "learning_rate": 1.9722222222222224e-05,
      "loss": 0.0029,
      "step": 10900
    },
    {
      "epoch": 1.2122222222222223,
      "grad_norm": 1.1856502294540405,
      "learning_rate": 1.9694444444444445e-05,
      "loss": 0.0027,
      "step": 10910
    },
    {
      "epoch": 1.2133333333333334,
      "grad_norm": 0.7808341383934021,
      "learning_rate": 1.9666666666666666e-05,
      "loss": 0.0015,
      "step": 10920
    },
    {
      "epoch": 1.2144444444444444,
      "grad_norm": 0.4775255024433136,
      "learning_rate": 1.963888888888889e-05,
      "loss": 0.0028,
      "step": 10930
    },
    {
      "epoch": 1.2155555555555555,
      "grad_norm": 0.6419719457626343,
      "learning_rate": 1.9611111111111115e-05,
      "loss": 0.0037,
      "step": 10940
    },
    {
      "epoch": 1.2166666666666668,
      "grad_norm": 0.3831096887588501,
      "learning_rate": 1.9583333333333333e-05,
      "loss": 0.0036,
      "step": 10950
    },
    {
      "epoch": 1.2177777777777778,
      "grad_norm": 0.4794059991836548,
      "learning_rate": 1.9555555555555557e-05,
      "loss": 0.0037,
      "step": 10960
    },
    {
      "epoch": 1.218888888888889,
      "grad_norm": 0.2348119616508484,
      "learning_rate": 1.952777777777778e-05,
      "loss": 0.0022,
      "step": 10970
    },
    {
      "epoch": 1.22,
      "grad_norm": 0.8181978464126587,
      "learning_rate": 1.9500000000000003e-05,
      "loss": 0.0031,
      "step": 10980
    },
    {
      "epoch": 1.221111111111111,
      "grad_norm": 0.27704915404319763,
      "learning_rate": 1.947222222222222e-05,
      "loss": 0.0023,
      "step": 10990
    },
    {
      "epoch": 1.2222222222222223,
      "grad_norm": 0.445321649312973,
      "learning_rate": 1.9444444444444445e-05,
      "loss": 0.0029,
      "step": 11000
    },
    {
      "epoch": 1.2233333333333334,
      "grad_norm": 0.626655101776123,
      "learning_rate": 1.9416666666666667e-05,
      "loss": 0.003,
      "step": 11010
    },
    {
      "epoch": 1.2244444444444444,
      "grad_norm": 0.18683673441410065,
      "learning_rate": 1.938888888888889e-05,
      "loss": 0.0019,
      "step": 11020
    },
    {
      "epoch": 1.2255555555555555,
      "grad_norm": 0.4644821584224701,
      "learning_rate": 1.9361111111111112e-05,
      "loss": 0.0028,
      "step": 11030
    },
    {
      "epoch": 1.2266666666666666,
      "grad_norm": 0.4204351007938385,
      "learning_rate": 1.9333333333333333e-05,
      "loss": 0.0037,
      "step": 11040
    },
    {
      "epoch": 1.2277777777777779,
      "grad_norm": 0.4254094958305359,
      "learning_rate": 1.9305555555555558e-05,
      "loss": 0.0021,
      "step": 11050
    },
    {
      "epoch": 1.228888888888889,
      "grad_norm": 0.6266613006591797,
      "learning_rate": 1.927777777777778e-05,
      "loss": 0.0032,
      "step": 11060
    },
    {
      "epoch": 1.23,
      "grad_norm": 0.23775546252727509,
      "learning_rate": 1.925e-05,
      "loss": 0.0025,
      "step": 11070
    },
    {
      "epoch": 1.231111111111111,
      "grad_norm": 0.24821363389492035,
      "learning_rate": 1.922222222222222e-05,
      "loss": 0.0027,
      "step": 11080
    },
    {
      "epoch": 1.232222222222222,
      "grad_norm": 0.6077772378921509,
      "learning_rate": 1.9194444444444446e-05,
      "loss": 0.0015,
      "step": 11090
    },
    {
      "epoch": 1.2333333333333334,
      "grad_norm": 1.054286003112793,
      "learning_rate": 1.9166666666666667e-05,
      "loss": 0.0028,
      "step": 11100
    },
    {
      "epoch": 1.2344444444444445,
      "grad_norm": 0.3059265911579132,
      "learning_rate": 1.913888888888889e-05,
      "loss": 0.0028,
      "step": 11110
    },
    {
      "epoch": 1.2355555555555555,
      "grad_norm": 0.9466648101806641,
      "learning_rate": 1.9111111111111113e-05,
      "loss": 0.0027,
      "step": 11120
    },
    {
      "epoch": 1.2366666666666666,
      "grad_norm": 1.2823553085327148,
      "learning_rate": 1.9083333333333334e-05,
      "loss": 0.0032,
      "step": 11130
    },
    {
      "epoch": 1.2377777777777779,
      "grad_norm": 0.7303196787834167,
      "learning_rate": 1.905555555555556e-05,
      "loss": 0.0049,
      "step": 11140
    },
    {
      "epoch": 1.238888888888889,
      "grad_norm": 0.5392626523971558,
      "learning_rate": 1.9027777777777776e-05,
      "loss": 0.0038,
      "step": 11150
    },
    {
      "epoch": 1.24,
      "grad_norm": 0.8464284539222717,
      "learning_rate": 1.9e-05,
      "loss": 0.0014,
      "step": 11160
    },
    {
      "epoch": 1.241111111111111,
      "grad_norm": 0.9638274312019348,
      "learning_rate": 1.8972222222222222e-05,
      "loss": 0.0036,
      "step": 11170
    },
    {
      "epoch": 1.2422222222222223,
      "grad_norm": 0.2539365291595459,
      "learning_rate": 1.8944444444444447e-05,
      "loss": 0.003,
      "step": 11180
    },
    {
      "epoch": 1.2433333333333334,
      "grad_norm": 0.41728681325912476,
      "learning_rate": 1.8916666666666668e-05,
      "loss": 0.0021,
      "step": 11190
    },
    {
      "epoch": 1.2444444444444445,
      "grad_norm": 0.7701579928398132,
      "learning_rate": 1.888888888888889e-05,
      "loss": 0.0055,
      "step": 11200
    },
    {
      "epoch": 1.2455555555555555,
      "grad_norm": 0.5287615060806274,
      "learning_rate": 1.8861111111111114e-05,
      "loss": 0.0024,
      "step": 11210
    },
    {
      "epoch": 1.2466666666666666,
      "grad_norm": 0.2326192557811737,
      "learning_rate": 1.8833333333333335e-05,
      "loss": 0.0018,
      "step": 11220
    },
    {
      "epoch": 1.2477777777777779,
      "grad_norm": 0.5884983539581299,
      "learning_rate": 1.8805555555555556e-05,
      "loss": 0.0025,
      "step": 11230
    },
    {
      "epoch": 1.248888888888889,
      "grad_norm": 1.6279833316802979,
      "learning_rate": 1.8777777777777777e-05,
      "loss": 0.0032,
      "step": 11240
    },
    {
      "epoch": 1.25,
      "grad_norm": 0.7154802680015564,
      "learning_rate": 1.8750000000000002e-05,
      "loss": 0.0026,
      "step": 11250
    },
    {
      "epoch": 1.251111111111111,
      "grad_norm": 0.24342294037342072,
      "learning_rate": 1.8722222222222223e-05,
      "loss": 0.0025,
      "step": 11260
    },
    {
      "epoch": 1.2522222222222221,
      "grad_norm": 0.9939667582511902,
      "learning_rate": 1.8694444444444444e-05,
      "loss": 0.002,
      "step": 11270
    },
    {
      "epoch": 1.2533333333333334,
      "grad_norm": 0.39793291687965393,
      "learning_rate": 1.866666666666667e-05,
      "loss": 0.0028,
      "step": 11280
    },
    {
      "epoch": 1.2544444444444445,
      "grad_norm": 0.19878870248794556,
      "learning_rate": 1.863888888888889e-05,
      "loss": 0.0032,
      "step": 11290
    },
    {
      "epoch": 1.2555555555555555,
      "grad_norm": 0.19772958755493164,
      "learning_rate": 1.861111111111111e-05,
      "loss": 0.001,
      "step": 11300
    },
    {
      "epoch": 1.2566666666666666,
      "grad_norm": 0.4488407075405121,
      "learning_rate": 1.8583333333333332e-05,
      "loss": 0.0015,
      "step": 11310
    },
    {
      "epoch": 1.2577777777777777,
      "grad_norm": 0.5261385440826416,
      "learning_rate": 1.8555555555555557e-05,
      "loss": 0.0019,
      "step": 11320
    },
    {
      "epoch": 1.258888888888889,
      "grad_norm": 0.2476014792919159,
      "learning_rate": 1.852777777777778e-05,
      "loss": 0.002,
      "step": 11330
    },
    {
      "epoch": 1.26,
      "grad_norm": 0.705610454082489,
      "learning_rate": 1.85e-05,
      "loss": 0.0022,
      "step": 11340
    },
    {
      "epoch": 1.261111111111111,
      "grad_norm": 0.6594572067260742,
      "learning_rate": 1.8472222222222224e-05,
      "loss": 0.0035,
      "step": 11350
    },
    {
      "epoch": 1.2622222222222224,
      "grad_norm": 0.49533718824386597,
      "learning_rate": 1.8444444444444445e-05,
      "loss": 0.0021,
      "step": 11360
    },
    {
      "epoch": 1.2633333333333332,
      "grad_norm": 1.0998308658599854,
      "learning_rate": 1.841666666666667e-05,
      "loss": 0.0036,
      "step": 11370
    },
    {
      "epoch": 1.2644444444444445,
      "grad_norm": 0.6095529794692993,
      "learning_rate": 1.838888888888889e-05,
      "loss": 0.003,
      "step": 11380
    },
    {
      "epoch": 1.2655555555555555,
      "grad_norm": 0.3686603903770447,
      "learning_rate": 1.836111111111111e-05,
      "loss": 0.0021,
      "step": 11390
    },
    {
      "epoch": 1.2666666666666666,
      "grad_norm": 0.61808842420578,
      "learning_rate": 1.8333333333333333e-05,
      "loss": 0.0017,
      "step": 11400
    },
    {
      "epoch": 1.267777777777778,
      "grad_norm": 0.3038006126880646,
      "learning_rate": 1.8305555555555557e-05,
      "loss": 0.0034,
      "step": 11410
    },
    {
      "epoch": 1.268888888888889,
      "grad_norm": 0.569980800151825,
      "learning_rate": 1.827777777777778e-05,
      "loss": 0.0025,
      "step": 11420
    },
    {
      "epoch": 1.27,
      "grad_norm": 0.8388835191726685,
      "learning_rate": 1.825e-05,
      "loss": 0.0019,
      "step": 11430
    },
    {
      "epoch": 1.271111111111111,
      "grad_norm": 0.7312702536582947,
      "learning_rate": 1.8222222222222224e-05,
      "loss": 0.0025,
      "step": 11440
    },
    {
      "epoch": 1.2722222222222221,
      "grad_norm": 0.22310379147529602,
      "learning_rate": 1.8194444444444445e-05,
      "loss": 0.0027,
      "step": 11450
    },
    {
      "epoch": 1.2733333333333334,
      "grad_norm": 0.31509560346603394,
      "learning_rate": 1.8166666666666667e-05,
      "loss": 0.0024,
      "step": 11460
    },
    {
      "epoch": 1.2744444444444445,
      "grad_norm": 0.31748440861701965,
      "learning_rate": 1.8138888888888888e-05,
      "loss": 0.0018,
      "step": 11470
    },
    {
      "epoch": 1.2755555555555556,
      "grad_norm": 0.4770238697528839,
      "learning_rate": 1.8111111111111112e-05,
      "loss": 0.0022,
      "step": 11480
    },
    {
      "epoch": 1.2766666666666666,
      "grad_norm": 0.6731203198432922,
      "learning_rate": 1.8083333333333337e-05,
      "loss": 0.0025,
      "step": 11490
    },
    {
      "epoch": 1.2777777777777777,
      "grad_norm": 0.1939428299665451,
      "learning_rate": 1.8055555555555555e-05,
      "loss": 0.003,
      "step": 11500
    },
    {
      "epoch": 1.278888888888889,
      "grad_norm": 0.2714584469795227,
      "learning_rate": 1.802777777777778e-05,
      "loss": 0.0032,
      "step": 11510
    },
    {
      "epoch": 1.28,
      "grad_norm": 0.7537263035774231,
      "learning_rate": 1.8e-05,
      "loss": 0.0026,
      "step": 11520
    },
    {
      "epoch": 1.281111111111111,
      "grad_norm": 0.24738292396068573,
      "learning_rate": 1.7972222222222225e-05,
      "loss": 0.0025,
      "step": 11530
    },
    {
      "epoch": 1.2822222222222222,
      "grad_norm": 0.25020185112953186,
      "learning_rate": 1.7944444444444443e-05,
      "loss": 0.0034,
      "step": 11540
    },
    {
      "epoch": 1.2833333333333332,
      "grad_norm": 0.3511268198490143,
      "learning_rate": 1.7916666666666667e-05,
      "loss": 0.0012,
      "step": 11550
    },
    {
      "epoch": 1.2844444444444445,
      "grad_norm": 0.40792223811149597,
      "learning_rate": 1.788888888888889e-05,
      "loss": 0.0027,
      "step": 11560
    },
    {
      "epoch": 1.2855555555555556,
      "grad_norm": 0.3446478247642517,
      "learning_rate": 1.7861111111111113e-05,
      "loss": 0.0027,
      "step": 11570
    },
    {
      "epoch": 1.2866666666666666,
      "grad_norm": 0.3527722954750061,
      "learning_rate": 1.7833333333333334e-05,
      "loss": 0.0024,
      "step": 11580
    },
    {
      "epoch": 1.287777777777778,
      "grad_norm": 0.19384188950061798,
      "learning_rate": 1.7805555555555555e-05,
      "loss": 0.0024,
      "step": 11590
    },
    {
      "epoch": 1.2888888888888888,
      "grad_norm": 0.4256443679332733,
      "learning_rate": 1.777777777777778e-05,
      "loss": 0.002,
      "step": 11600
    },
    {
      "epoch": 1.29,
      "grad_norm": 0.9027326703071594,
      "learning_rate": 1.775e-05,
      "loss": 0.002,
      "step": 11610
    },
    {
      "epoch": 1.291111111111111,
      "grad_norm": 0.5230433940887451,
      "learning_rate": 1.7722222222222222e-05,
      "loss": 0.0021,
      "step": 11620
    },
    {
      "epoch": 1.2922222222222222,
      "grad_norm": 0.5566489696502686,
      "learning_rate": 1.7694444444444443e-05,
      "loss": 0.0024,
      "step": 11630
    },
    {
      "epoch": 1.2933333333333334,
      "grad_norm": 0.430963933467865,
      "learning_rate": 1.7666666666666668e-05,
      "loss": 0.002,
      "step": 11640
    },
    {
      "epoch": 1.2944444444444445,
      "grad_norm": 0.3225845396518707,
      "learning_rate": 1.763888888888889e-05,
      "loss": 0.0028,
      "step": 11650
    },
    {
      "epoch": 1.2955555555555556,
      "grad_norm": 0.754951000213623,
      "learning_rate": 1.761111111111111e-05,
      "loss": 0.0015,
      "step": 11660
    },
    {
      "epoch": 1.2966666666666666,
      "grad_norm": 0.5388416051864624,
      "learning_rate": 1.7583333333333335e-05,
      "loss": 0.0016,
      "step": 11670
    },
    {
      "epoch": 1.2977777777777777,
      "grad_norm": 0.39477401971817017,
      "learning_rate": 1.7555555555555556e-05,
      "loss": 0.0042,
      "step": 11680
    },
    {
      "epoch": 1.298888888888889,
      "grad_norm": 0.5637203454971313,
      "learning_rate": 1.752777777777778e-05,
      "loss": 0.0044,
      "step": 11690
    },
    {
      "epoch": 1.3,
      "grad_norm": 0.7055072784423828,
      "learning_rate": 1.75e-05,
      "loss": 0.0014,
      "step": 11700
    },
    {
      "epoch": 1.301111111111111,
      "grad_norm": 0.6236470341682434,
      "learning_rate": 1.7472222222222223e-05,
      "loss": 0.0017,
      "step": 11710
    },
    {
      "epoch": 1.3022222222222222,
      "grad_norm": 0.2642246186733246,
      "learning_rate": 1.7444444444444448e-05,
      "loss": 0.0022,
      "step": 11720
    },
    {
      "epoch": 1.3033333333333332,
      "grad_norm": 0.3640715181827545,
      "learning_rate": 1.741666666666667e-05,
      "loss": 0.0028,
      "step": 11730
    },
    {
      "epoch": 1.3044444444444445,
      "grad_norm": 0.42096784710884094,
      "learning_rate": 1.738888888888889e-05,
      "loss": 0.0022,
      "step": 11740
    },
    {
      "epoch": 1.3055555555555556,
      "grad_norm": 0.46688127517700195,
      "learning_rate": 1.736111111111111e-05,
      "loss": 0.0014,
      "step": 11750
    },
    {
      "epoch": 1.3066666666666666,
      "grad_norm": 0.1916024535894394,
      "learning_rate": 1.7333333333333336e-05,
      "loss": 0.0024,
      "step": 11760
    },
    {
      "epoch": 1.3077777777777777,
      "grad_norm": 0.7721542119979858,
      "learning_rate": 1.7305555555555557e-05,
      "loss": 0.0035,
      "step": 11770
    },
    {
      "epoch": 1.3088888888888888,
      "grad_norm": 0.6710201501846313,
      "learning_rate": 1.7277777777777778e-05,
      "loss": 0.0023,
      "step": 11780
    },
    {
      "epoch": 1.31,
      "grad_norm": 0.20469142496585846,
      "learning_rate": 1.725e-05,
      "loss": 0.0036,
      "step": 11790
    },
    {
      "epoch": 1.3111111111111111,
      "grad_norm": 0.378195583820343,
      "learning_rate": 1.7222222222222224e-05,
      "loss": 0.0018,
      "step": 11800
    },
    {
      "epoch": 1.3122222222222222,
      "grad_norm": 0.4985814690589905,
      "learning_rate": 1.7194444444444445e-05,
      "loss": 0.0028,
      "step": 11810
    },
    {
      "epoch": 1.3133333333333335,
      "grad_norm": 0.207185760140419,
      "learning_rate": 1.7166666666666666e-05,
      "loss": 0.0023,
      "step": 11820
    },
    {
      "epoch": 1.3144444444444445,
      "grad_norm": 0.46542632579803467,
      "learning_rate": 1.713888888888889e-05,
      "loss": 0.0016,
      "step": 11830
    },
    {
      "epoch": 1.3155555555555556,
      "grad_norm": 0.16052712500095367,
      "learning_rate": 1.7111111111111112e-05,
      "loss": 0.0024,
      "step": 11840
    },
    {
      "epoch": 1.3166666666666667,
      "grad_norm": 0.5561782121658325,
      "learning_rate": 1.7083333333333333e-05,
      "loss": 0.0024,
      "step": 11850
    },
    {
      "epoch": 1.3177777777777777,
      "grad_norm": 0.3877613842487335,
      "learning_rate": 1.7055555555555554e-05,
      "loss": 0.0029,
      "step": 11860
    },
    {
      "epoch": 1.318888888888889,
      "grad_norm": 0.21534636616706848,
      "learning_rate": 1.702777777777778e-05,
      "loss": 0.0025,
      "step": 11870
    },
    {
      "epoch": 1.32,
      "grad_norm": 0.6306895613670349,
      "learning_rate": 1.7000000000000003e-05,
      "loss": 0.002,
      "step": 11880
    },
    {
      "epoch": 1.3211111111111111,
      "grad_norm": 0.32753756642341614,
      "learning_rate": 1.697222222222222e-05,
      "loss": 0.0015,
      "step": 11890
    },
    {
      "epoch": 1.3222222222222222,
      "grad_norm": 0.5362967848777771,
      "learning_rate": 1.6944444444444446e-05,
      "loss": 0.0023,
      "step": 11900
    },
    {
      "epoch": 1.3233333333333333,
      "grad_norm": 0.4355649948120117,
      "learning_rate": 1.6916666666666667e-05,
      "loss": 0.0043,
      "step": 11910
    },
    {
      "epoch": 1.3244444444444445,
      "grad_norm": 1.1763473749160767,
      "learning_rate": 1.688888888888889e-05,
      "loss": 0.0013,
      "step": 11920
    },
    {
      "epoch": 1.3255555555555556,
      "grad_norm": 0.8059101104736328,
      "learning_rate": 1.6861111111111112e-05,
      "loss": 0.003,
      "step": 11930
    },
    {
      "epoch": 1.3266666666666667,
      "grad_norm": 0.5312238931655884,
      "learning_rate": 1.6833333333333334e-05,
      "loss": 0.0013,
      "step": 11940
    },
    {
      "epoch": 1.3277777777777777,
      "grad_norm": 0.22788161039352417,
      "learning_rate": 1.6805555555555558e-05,
      "loss": 0.002,
      "step": 11950
    },
    {
      "epoch": 1.3288888888888888,
      "grad_norm": 1.072317361831665,
      "learning_rate": 1.677777777777778e-05,
      "loss": 0.004,
      "step": 11960
    },
    {
      "epoch": 1.33,
      "grad_norm": 0.6869581937789917,
      "learning_rate": 1.675e-05,
      "loss": 0.0038,
      "step": 11970
    },
    {
      "epoch": 1.3311111111111111,
      "grad_norm": 0.7242679595947266,
      "learning_rate": 1.6722222222222222e-05,
      "loss": 0.0019,
      "step": 11980
    },
    {
      "epoch": 1.3322222222222222,
      "grad_norm": 0.5317043662071228,
      "learning_rate": 1.6694444444444446e-05,
      "loss": 0.0028,
      "step": 11990
    },
    {
      "epoch": 1.3333333333333333,
      "grad_norm": 0.47232484817504883,
      "learning_rate": 1.6666666666666667e-05,
      "loss": 0.0018,
      "step": 12000
    },
    {
      "epoch": 1.3344444444444443,
      "grad_norm": 0.43647125363349915,
      "learning_rate": 1.663888888888889e-05,
      "loss": 0.0025,
      "step": 12010
    },
    {
      "epoch": 1.3355555555555556,
      "grad_norm": 0.5529834628105164,
      "learning_rate": 1.661111111111111e-05,
      "loss": 0.0025,
      "step": 12020
    },
    {
      "epoch": 1.3366666666666667,
      "grad_norm": 1.5780065059661865,
      "learning_rate": 1.6583333333333334e-05,
      "loss": 0.0028,
      "step": 12030
    },
    {
      "epoch": 1.3377777777777777,
      "grad_norm": 0.3060537278652191,
      "learning_rate": 1.655555555555556e-05,
      "loss": 0.0018,
      "step": 12040
    },
    {
      "epoch": 1.338888888888889,
      "grad_norm": 0.990548312664032,
      "learning_rate": 1.6527777777777777e-05,
      "loss": 0.0025,
      "step": 12050
    },
    {
      "epoch": 1.34,
      "grad_norm": 0.3671996295452118,
      "learning_rate": 1.65e-05,
      "loss": 0.0021,
      "step": 12060
    },
    {
      "epoch": 1.3411111111111111,
      "grad_norm": 1.0474058389663696,
      "learning_rate": 1.6472222222222222e-05,
      "loss": 0.0028,
      "step": 12070
    },
    {
      "epoch": 1.3422222222222222,
      "grad_norm": 1.1397112607955933,
      "learning_rate": 1.6444444444444447e-05,
      "loss": 0.0035,
      "step": 12080
    },
    {
      "epoch": 1.3433333333333333,
      "grad_norm": 1.1069672107696533,
      "learning_rate": 1.6416666666666665e-05,
      "loss": 0.0026,
      "step": 12090
    },
    {
      "epoch": 1.3444444444444446,
      "grad_norm": 0.2506476640701294,
      "learning_rate": 1.638888888888889e-05,
      "loss": 0.0019,
      "step": 12100
    },
    {
      "epoch": 1.3455555555555556,
      "grad_norm": 0.847606897354126,
      "learning_rate": 1.6361111111111114e-05,
      "loss": 0.0027,
      "step": 12110
    },
    {
      "epoch": 1.3466666666666667,
      "grad_norm": 0.8890894055366516,
      "learning_rate": 1.6333333333333335e-05,
      "loss": 0.0033,
      "step": 12120
    },
    {
      "epoch": 1.3477777777777777,
      "grad_norm": 0.6648288369178772,
      "learning_rate": 1.6305555555555556e-05,
      "loss": 0.0026,
      "step": 12130
    },
    {
      "epoch": 1.3488888888888888,
      "grad_norm": 0.7886565923690796,
      "learning_rate": 1.6277777777777777e-05,
      "loss": 0.0021,
      "step": 12140
    },
    {
      "epoch": 1.35,
      "grad_norm": 0.8094552755355835,
      "learning_rate": 1.6250000000000002e-05,
      "loss": 0.0031,
      "step": 12150
    },
    {
      "epoch": 1.3511111111111112,
      "grad_norm": 1.0529234409332275,
      "learning_rate": 1.6222222222222223e-05,
      "loss": 0.0022,
      "step": 12160
    },
    {
      "epoch": 1.3522222222222222,
      "grad_norm": 0.5321967005729675,
      "learning_rate": 1.6194444444444444e-05,
      "loss": 0.0013,
      "step": 12170
    },
    {
      "epoch": 1.3533333333333333,
      "grad_norm": 0.5663415789604187,
      "learning_rate": 1.6166666666666665e-05,
      "loss": 0.002,
      "step": 12180
    },
    {
      "epoch": 1.3544444444444443,
      "grad_norm": 0.2982804477214813,
      "learning_rate": 1.613888888888889e-05,
      "loss": 0.0038,
      "step": 12190
    },
    {
      "epoch": 1.3555555555555556,
      "grad_norm": 0.2667999565601349,
      "learning_rate": 1.6111111111111115e-05,
      "loss": 0.0029,
      "step": 12200
    },
    {
      "epoch": 1.3566666666666667,
      "grad_norm": 0.6941690444946289,
      "learning_rate": 1.6083333333333332e-05,
      "loss": 0.0032,
      "step": 12210
    },
    {
      "epoch": 1.3577777777777778,
      "grad_norm": 0.7645883560180664,
      "learning_rate": 1.6055555555555557e-05,
      "loss": 0.0025,
      "step": 12220
    },
    {
      "epoch": 1.3588888888888888,
      "grad_norm": 0.351306289434433,
      "learning_rate": 1.6027777777777778e-05,
      "loss": 0.0015,
      "step": 12230
    },
    {
      "epoch": 1.3599999999999999,
      "grad_norm": 1.6049771308898926,
      "learning_rate": 1.6000000000000003e-05,
      "loss": 0.0018,
      "step": 12240
    },
    {
      "epoch": 1.3611111111111112,
      "grad_norm": 0.8389881253242493,
      "learning_rate": 1.597222222222222e-05,
      "loss": 0.0036,
      "step": 12250
    },
    {
      "epoch": 1.3622222222222222,
      "grad_norm": 0.9724191427230835,
      "learning_rate": 1.5944444444444445e-05,
      "loss": 0.0021,
      "step": 12260
    },
    {
      "epoch": 1.3633333333333333,
      "grad_norm": 0.9865201711654663,
      "learning_rate": 1.591666666666667e-05,
      "loss": 0.002,
      "step": 12270
    },
    {
      "epoch": 1.3644444444444446,
      "grad_norm": 0.8140263557434082,
      "learning_rate": 1.588888888888889e-05,
      "loss": 0.0035,
      "step": 12280
    },
    {
      "epoch": 1.3655555555555556,
      "grad_norm": 0.6813890933990479,
      "learning_rate": 1.5861111111111112e-05,
      "loss": 0.0035,
      "step": 12290
    },
    {
      "epoch": 1.3666666666666667,
      "grad_norm": 0.4583192467689514,
      "learning_rate": 1.5833333333333333e-05,
      "loss": 0.0025,
      "step": 12300
    },
    {
      "epoch": 1.3677777777777778,
      "grad_norm": 0.4524408280849457,
      "learning_rate": 1.5805555555555558e-05,
      "loss": 0.0021,
      "step": 12310
    },
    {
      "epoch": 1.3688888888888888,
      "grad_norm": 0.4452904462814331,
      "learning_rate": 1.577777777777778e-05,
      "loss": 0.0016,
      "step": 12320
    },
    {
      "epoch": 1.37,
      "grad_norm": 0.8167307376861572,
      "learning_rate": 1.575e-05,
      "loss": 0.0031,
      "step": 12330
    },
    {
      "epoch": 1.3711111111111112,
      "grad_norm": 1.1827704906463623,
      "learning_rate": 1.5722222222222225e-05,
      "loss": 0.0024,
      "step": 12340
    },
    {
      "epoch": 1.3722222222222222,
      "grad_norm": 0.7820682525634766,
      "learning_rate": 1.5694444444444446e-05,
      "loss": 0.0021,
      "step": 12350
    },
    {
      "epoch": 1.3733333333333333,
      "grad_norm": 0.28826797008514404,
      "learning_rate": 1.5666666666666667e-05,
      "loss": 0.0017,
      "step": 12360
    },
    {
      "epoch": 1.3744444444444444,
      "grad_norm": 0.2962726652622223,
      "learning_rate": 1.5638888888888888e-05,
      "loss": 0.0019,
      "step": 12370
    },
    {
      "epoch": 1.3755555555555556,
      "grad_norm": 0.2954988181591034,
      "learning_rate": 1.5611111111111113e-05,
      "loss": 0.0022,
      "step": 12380
    },
    {
      "epoch": 1.3766666666666667,
      "grad_norm": 0.38237330317497253,
      "learning_rate": 1.5583333333333334e-05,
      "loss": 0.0015,
      "step": 12390
    },
    {
      "epoch": 1.3777777777777778,
      "grad_norm": 0.4281514286994934,
      "learning_rate": 1.5555555555555555e-05,
      "loss": 0.0032,
      "step": 12400
    },
    {
      "epoch": 1.3788888888888888,
      "grad_norm": 0.1530788242816925,
      "learning_rate": 1.5527777777777776e-05,
      "loss": 0.0018,
      "step": 12410
    },
    {
      "epoch": 1.38,
      "grad_norm": 0.5244238972663879,
      "learning_rate": 1.55e-05,
      "loss": 0.0022,
      "step": 12420
    },
    {
      "epoch": 1.3811111111111112,
      "grad_norm": 0.7320107221603394,
      "learning_rate": 1.5472222222222225e-05,
      "loss": 0.0016,
      "step": 12430
    },
    {
      "epoch": 1.3822222222222222,
      "grad_norm": 0.2162894904613495,
      "learning_rate": 1.5444444444444446e-05,
      "loss": 0.0019,
      "step": 12440
    },
    {
      "epoch": 1.3833333333333333,
      "grad_norm": 1.370438575744629,
      "learning_rate": 1.5416666666666668e-05,
      "loss": 0.0024,
      "step": 12450
    },
    {
      "epoch": 1.3844444444444444,
      "grad_norm": 0.8295824527740479,
      "learning_rate": 1.538888888888889e-05,
      "loss": 0.0019,
      "step": 12460
    },
    {
      "epoch": 1.3855555555555554,
      "grad_norm": 0.8242315053939819,
      "learning_rate": 1.5361111111111113e-05,
      "loss": 0.0041,
      "step": 12470
    },
    {
      "epoch": 1.3866666666666667,
      "grad_norm": 0.5140878558158875,
      "learning_rate": 1.5333333333333334e-05,
      "loss": 0.003,
      "step": 12480
    },
    {
      "epoch": 1.3877777777777778,
      "grad_norm": 0.12298627942800522,
      "learning_rate": 1.5305555555555556e-05,
      "loss": 0.0019,
      "step": 12490
    },
    {
      "epoch": 1.3888888888888888,
      "grad_norm": 0.20783084630966187,
      "learning_rate": 1.527777777777778e-05,
      "loss": 0.0036,
      "step": 12500
    },
    {
      "epoch": 1.3900000000000001,
      "grad_norm": 0.416715145111084,
      "learning_rate": 1.525e-05,
      "loss": 0.0015,
      "step": 12510
    },
    {
      "epoch": 1.3911111111111112,
      "grad_norm": 0.5418457388877869,
      "learning_rate": 1.5222222222222224e-05,
      "loss": 0.0031,
      "step": 12520
    },
    {
      "epoch": 1.3922222222222222,
      "grad_norm": 0.13558681309223175,
      "learning_rate": 1.5194444444444444e-05,
      "loss": 0.0017,
      "step": 12530
    },
    {
      "epoch": 1.3933333333333333,
      "grad_norm": 0.3747935891151428,
      "learning_rate": 1.5166666666666668e-05,
      "loss": 0.0029,
      "step": 12540
    },
    {
      "epoch": 1.3944444444444444,
      "grad_norm": 0.7137526273727417,
      "learning_rate": 1.5138888888888888e-05,
      "loss": 0.0032,
      "step": 12550
    },
    {
      "epoch": 1.3955555555555557,
      "grad_norm": 0.732291042804718,
      "learning_rate": 1.5111111111111112e-05,
      "loss": 0.004,
      "step": 12560
    },
    {
      "epoch": 1.3966666666666667,
      "grad_norm": 0.9544353485107422,
      "learning_rate": 1.5083333333333335e-05,
      "loss": 0.0039,
      "step": 12570
    },
    {
      "epoch": 1.3977777777777778,
      "grad_norm": 0.6188119649887085,
      "learning_rate": 1.5055555555555556e-05,
      "loss": 0.0021,
      "step": 12580
    },
    {
      "epoch": 1.3988888888888888,
      "grad_norm": 0.373555988073349,
      "learning_rate": 1.502777777777778e-05,
      "loss": 0.0022,
      "step": 12590
    },
    {
      "epoch": 1.4,
      "grad_norm": 0.3224382996559143,
      "learning_rate": 1.5e-05,
      "loss": 0.0018,
      "step": 12600
    },
    {
      "epoch": 1.4011111111111112,
      "grad_norm": 0.5661002993583679,
      "learning_rate": 1.4972222222222223e-05,
      "loss": 0.0026,
      "step": 12610
    },
    {
      "epoch": 1.4022222222222223,
      "grad_norm": 0.4613901674747467,
      "learning_rate": 1.4944444444444444e-05,
      "loss": 0.0026,
      "step": 12620
    },
    {
      "epoch": 1.4033333333333333,
      "grad_norm": 0.7009825110435486,
      "learning_rate": 1.4916666666666667e-05,
      "loss": 0.0026,
      "step": 12630
    },
    {
      "epoch": 1.4044444444444444,
      "grad_norm": 0.3678240478038788,
      "learning_rate": 1.4888888888888888e-05,
      "loss": 0.0016,
      "step": 12640
    },
    {
      "epoch": 1.4055555555555554,
      "grad_norm": 0.4958145022392273,
      "learning_rate": 1.4861111111111111e-05,
      "loss": 0.002,
      "step": 12650
    },
    {
      "epoch": 1.4066666666666667,
      "grad_norm": 0.7501254677772522,
      "learning_rate": 1.4833333333333336e-05,
      "loss": 0.003,
      "step": 12660
    },
    {
      "epoch": 1.4077777777777778,
      "grad_norm": 0.6606482863426208,
      "learning_rate": 1.4805555555555555e-05,
      "loss": 0.0018,
      "step": 12670
    },
    {
      "epoch": 1.4088888888888889,
      "grad_norm": 0.2762661576271057,
      "learning_rate": 1.477777777777778e-05,
      "loss": 0.0021,
      "step": 12680
    },
    {
      "epoch": 1.41,
      "grad_norm": 0.8120168447494507,
      "learning_rate": 1.475e-05,
      "loss": 0.0012,
      "step": 12690
    },
    {
      "epoch": 1.411111111111111,
      "grad_norm": 0.7570980787277222,
      "learning_rate": 1.4722222222222224e-05,
      "loss": 0.0039,
      "step": 12700
    },
    {
      "epoch": 1.4122222222222223,
      "grad_norm": 0.7473071813583374,
      "learning_rate": 1.4694444444444443e-05,
      "loss": 0.0048,
      "step": 12710
    },
    {
      "epoch": 1.4133333333333333,
      "grad_norm": 0.6670584082603455,
      "learning_rate": 1.4666666666666668e-05,
      "loss": 0.0018,
      "step": 12720
    },
    {
      "epoch": 1.4144444444444444,
      "grad_norm": 0.7085650563240051,
      "learning_rate": 1.463888888888889e-05,
      "loss": 0.0018,
      "step": 12730
    },
    {
      "epoch": 1.4155555555555557,
      "grad_norm": 1.1289827823638916,
      "learning_rate": 1.4611111111111112e-05,
      "loss": 0.0042,
      "step": 12740
    },
    {
      "epoch": 1.4166666666666667,
      "grad_norm": 0.8669185042381287,
      "learning_rate": 1.4583333333333335e-05,
      "loss": 0.0036,
      "step": 12750
    },
    {
      "epoch": 1.4177777777777778,
      "grad_norm": 0.27019429206848145,
      "learning_rate": 1.4555555555555556e-05,
      "loss": 0.0031,
      "step": 12760
    },
    {
      "epoch": 1.4188888888888889,
      "grad_norm": 0.7393198013305664,
      "learning_rate": 1.4527777777777779e-05,
      "loss": 0.002,
      "step": 12770
    },
    {
      "epoch": 1.42,
      "grad_norm": 0.2875610291957855,
      "learning_rate": 1.45e-05,
      "loss": 0.0035,
      "step": 12780
    },
    {
      "epoch": 1.4211111111111112,
      "grad_norm": 0.6587491631507874,
      "learning_rate": 1.4472222222222223e-05,
      "loss": 0.0025,
      "step": 12790
    },
    {
      "epoch": 1.4222222222222223,
      "grad_norm": 0.5471358895301819,
      "learning_rate": 1.4444444444444444e-05,
      "loss": 0.002,
      "step": 12800
    },
    {
      "epoch": 1.4233333333333333,
      "grad_norm": 0.3943958580493927,
      "learning_rate": 1.4416666666666667e-05,
      "loss": 0.0037,
      "step": 12810
    },
    {
      "epoch": 1.4244444444444444,
      "grad_norm": 0.7960891127586365,
      "learning_rate": 1.438888888888889e-05,
      "loss": 0.0014,
      "step": 12820
    },
    {
      "epoch": 1.4255555555555555,
      "grad_norm": 1.185179591178894,
      "learning_rate": 1.4361111111111111e-05,
      "loss": 0.0036,
      "step": 12830
    },
    {
      "epoch": 1.4266666666666667,
      "grad_norm": 0.27002307772636414,
      "learning_rate": 1.4333333333333334e-05,
      "loss": 0.0026,
      "step": 12840
    },
    {
      "epoch": 1.4277777777777778,
      "grad_norm": 0.35277655720710754,
      "learning_rate": 1.4305555555555555e-05,
      "loss": 0.002,
      "step": 12850
    },
    {
      "epoch": 1.4288888888888889,
      "grad_norm": 0.1892600953578949,
      "learning_rate": 1.427777777777778e-05,
      "loss": 0.0011,
      "step": 12860
    },
    {
      "epoch": 1.43,
      "grad_norm": 0.6872816681861877,
      "learning_rate": 1.4249999999999999e-05,
      "loss": 0.0027,
      "step": 12870
    },
    {
      "epoch": 1.431111111111111,
      "grad_norm": 0.6218903660774231,
      "learning_rate": 1.4222222222222224e-05,
      "loss": 0.0037,
      "step": 12880
    },
    {
      "epoch": 1.4322222222222223,
      "grad_norm": 0.831752598285675,
      "learning_rate": 1.4194444444444447e-05,
      "loss": 0.0016,
      "step": 12890
    },
    {
      "epoch": 1.4333333333333333,
      "grad_norm": 0.3733728528022766,
      "learning_rate": 1.4166666666666668e-05,
      "loss": 0.0013,
      "step": 12900
    },
    {
      "epoch": 1.4344444444444444,
      "grad_norm": 0.6941701769828796,
      "learning_rate": 1.413888888888889e-05,
      "loss": 0.0023,
      "step": 12910
    },
    {
      "epoch": 1.4355555555555555,
      "grad_norm": 1.10219407081604,
      "learning_rate": 1.4111111111111112e-05,
      "loss": 0.0013,
      "step": 12920
    },
    {
      "epoch": 1.4366666666666665,
      "grad_norm": 0.20099228620529175,
      "learning_rate": 1.4083333333333335e-05,
      "loss": 0.0023,
      "step": 12930
    },
    {
      "epoch": 1.4377777777777778,
      "grad_norm": 0.264085054397583,
      "learning_rate": 1.4055555555555556e-05,
      "loss": 0.0038,
      "step": 12940
    },
    {
      "epoch": 1.4388888888888889,
      "grad_norm": 0.24243520200252533,
      "learning_rate": 1.4027777777777779e-05,
      "loss": 0.0018,
      "step": 12950
    },
    {
      "epoch": 1.44,
      "grad_norm": 0.39859408140182495,
      "learning_rate": 1.4000000000000001e-05,
      "loss": 0.0033,
      "step": 12960
    },
    {
      "epoch": 1.4411111111111112,
      "grad_norm": 0.25066015124320984,
      "learning_rate": 1.3972222222222223e-05,
      "loss": 0.0018,
      "step": 12970
    },
    {
      "epoch": 1.4422222222222223,
      "grad_norm": 0.41441306471824646,
      "learning_rate": 1.3944444444444446e-05,
      "loss": 0.0028,
      "step": 12980
    },
    {
      "epoch": 1.4433333333333334,
      "grad_norm": 0.5175843834877014,
      "learning_rate": 1.3916666666666667e-05,
      "loss": 0.0026,
      "step": 12990
    },
    {
      "epoch": 1.4444444444444444,
      "grad_norm": 0.2487485706806183,
      "learning_rate": 1.388888888888889e-05,
      "loss": 0.0025,
      "step": 13000
    },
    {
      "epoch": 1.4455555555555555,
      "grad_norm": 0.27604642510414124,
      "learning_rate": 1.386111111111111e-05,
      "loss": 0.0032,
      "step": 13010
    },
    {
      "epoch": 1.4466666666666668,
      "grad_norm": 0.23701630532741547,
      "learning_rate": 1.3833333333333334e-05,
      "loss": 0.0028,
      "step": 13020
    },
    {
      "epoch": 1.4477777777777778,
      "grad_norm": 0.16365455090999603,
      "learning_rate": 1.3805555555555555e-05,
      "loss": 0.0033,
      "step": 13030
    },
    {
      "epoch": 1.448888888888889,
      "grad_norm": 0.3780040144920349,
      "learning_rate": 1.3777777777777778e-05,
      "loss": 0.0022,
      "step": 13040
    },
    {
      "epoch": 1.45,
      "grad_norm": 0.5712012648582458,
      "learning_rate": 1.3750000000000002e-05,
      "loss": 0.0017,
      "step": 13050
    },
    {
      "epoch": 1.451111111111111,
      "grad_norm": 0.8768951892852783,
      "learning_rate": 1.3722222222222222e-05,
      "loss": 0.0027,
      "step": 13060
    },
    {
      "epoch": 1.4522222222222223,
      "grad_norm": 0.5827508568763733,
      "learning_rate": 1.3694444444444446e-05,
      "loss": 0.0009,
      "step": 13070
    },
    {
      "epoch": 1.4533333333333334,
      "grad_norm": 0.9370390772819519,
      "learning_rate": 1.3666666666666666e-05,
      "loss": 0.0024,
      "step": 13080
    },
    {
      "epoch": 1.4544444444444444,
      "grad_norm": 0.3059768080711365,
      "learning_rate": 1.363888888888889e-05,
      "loss": 0.0021,
      "step": 13090
    },
    {
      "epoch": 1.4555555555555555,
      "grad_norm": 0.38577669858932495,
      "learning_rate": 1.3611111111111111e-05,
      "loss": 0.0022,
      "step": 13100
    },
    {
      "epoch": 1.4566666666666666,
      "grad_norm": 1.1154991388320923,
      "learning_rate": 1.3583333333333334e-05,
      "loss": 0.0014,
      "step": 13110
    },
    {
      "epoch": 1.4577777777777778,
      "grad_norm": 0.8336677551269531,
      "learning_rate": 1.3555555555555557e-05,
      "loss": 0.0028,
      "step": 13120
    },
    {
      "epoch": 1.458888888888889,
      "grad_norm": 0.27985015511512756,
      "learning_rate": 1.3527777777777778e-05,
      "loss": 0.0028,
      "step": 13130
    },
    {
      "epoch": 1.46,
      "grad_norm": 0.707004964351654,
      "learning_rate": 1.3500000000000001e-05,
      "loss": 0.0023,
      "step": 13140
    },
    {
      "epoch": 1.4611111111111112,
      "grad_norm": 0.19971582293510437,
      "learning_rate": 1.3472222222222222e-05,
      "loss": 0.0031,
      "step": 13150
    },
    {
      "epoch": 1.462222222222222,
      "grad_norm": 0.32480019330978394,
      "learning_rate": 1.3444444444444445e-05,
      "loss": 0.0027,
      "step": 13160
    },
    {
      "epoch": 1.4633333333333334,
      "grad_norm": 0.3320437967777252,
      "learning_rate": 1.3416666666666666e-05,
      "loss": 0.0014,
      "step": 13170
    },
    {
      "epoch": 1.4644444444444444,
      "grad_norm": 0.6320151090621948,
      "learning_rate": 1.338888888888889e-05,
      "loss": 0.0024,
      "step": 13180
    },
    {
      "epoch": 1.4655555555555555,
      "grad_norm": 0.5770665407180786,
      "learning_rate": 1.3361111111111114e-05,
      "loss": 0.003,
      "step": 13190
    },
    {
      "epoch": 1.4666666666666668,
      "grad_norm": 0.3337085545063019,
      "learning_rate": 1.3333333333333333e-05,
      "loss": 0.0027,
      "step": 13200
    },
    {
      "epoch": 1.4677777777777778,
      "grad_norm": 0.4753411114215851,
      "learning_rate": 1.3305555555555558e-05,
      "loss": 0.0024,
      "step": 13210
    },
    {
      "epoch": 1.468888888888889,
      "grad_norm": 0.2727672755718231,
      "learning_rate": 1.3277777777777777e-05,
      "loss": 0.0015,
      "step": 13220
    },
    {
      "epoch": 1.47,
      "grad_norm": 0.23516462743282318,
      "learning_rate": 1.3250000000000002e-05,
      "loss": 0.0025,
      "step": 13230
    },
    {
      "epoch": 1.471111111111111,
      "grad_norm": 0.4830184578895569,
      "learning_rate": 1.3222222222222221e-05,
      "loss": 0.0033,
      "step": 13240
    },
    {
      "epoch": 1.4722222222222223,
      "grad_norm": 0.4973728656768799,
      "learning_rate": 1.3194444444444446e-05,
      "loss": 0.0021,
      "step": 13250
    },
    {
      "epoch": 1.4733333333333334,
      "grad_norm": 1.0373740196228027,
      "learning_rate": 1.3166666666666665e-05,
      "loss": 0.0022,
      "step": 13260
    },
    {
      "epoch": 1.4744444444444444,
      "grad_norm": 0.8011364936828613,
      "learning_rate": 1.313888888888889e-05,
      "loss": 0.0015,
      "step": 13270
    },
    {
      "epoch": 1.4755555555555555,
      "grad_norm": 0.31611818075180054,
      "learning_rate": 1.3111111111111113e-05,
      "loss": 0.0027,
      "step": 13280
    },
    {
      "epoch": 1.4766666666666666,
      "grad_norm": 0.6653721332550049,
      "learning_rate": 1.3083333333333334e-05,
      "loss": 0.0031,
      "step": 13290
    },
    {
      "epoch": 1.4777777777777779,
      "grad_norm": 0.7484797239303589,
      "learning_rate": 1.3055555555555557e-05,
      "loss": 0.0021,
      "step": 13300
    },
    {
      "epoch": 1.478888888888889,
      "grad_norm": 0.8602089881896973,
      "learning_rate": 1.3027777777777778e-05,
      "loss": 0.0024,
      "step": 13310
    },
    {
      "epoch": 1.48,
      "grad_norm": 0.2785494923591614,
      "learning_rate": 1.3000000000000001e-05,
      "loss": 0.0032,
      "step": 13320
    },
    {
      "epoch": 1.481111111111111,
      "grad_norm": 0.5279113054275513,
      "learning_rate": 1.2972222222222222e-05,
      "loss": 0.0033,
      "step": 13330
    },
    {
      "epoch": 1.482222222222222,
      "grad_norm": 0.39679843187332153,
      "learning_rate": 1.2944444444444445e-05,
      "loss": 0.0015,
      "step": 13340
    },
    {
      "epoch": 1.4833333333333334,
      "grad_norm": 0.6175228357315063,
      "learning_rate": 1.2916666666666668e-05,
      "loss": 0.0017,
      "step": 13350
    },
    {
      "epoch": 1.4844444444444445,
      "grad_norm": 0.8910881876945496,
      "learning_rate": 1.2888888888888889e-05,
      "loss": 0.0026,
      "step": 13360
    },
    {
      "epoch": 1.4855555555555555,
      "grad_norm": 0.6019268035888672,
      "learning_rate": 1.2861111111111112e-05,
      "loss": 0.0048,
      "step": 13370
    },
    {
      "epoch": 1.4866666666666668,
      "grad_norm": 0.2803790271282196,
      "learning_rate": 1.2833333333333333e-05,
      "loss": 0.0011,
      "step": 13380
    },
    {
      "epoch": 1.4877777777777776,
      "grad_norm": 0.15051037073135376,
      "learning_rate": 1.2805555555555558e-05,
      "loss": 0.0029,
      "step": 13390
    },
    {
      "epoch": 1.488888888888889,
      "grad_norm": 0.7862672209739685,
      "learning_rate": 1.2777777777777777e-05,
      "loss": 0.0021,
      "step": 13400
    },
    {
      "epoch": 1.49,
      "grad_norm": 0.16104871034622192,
      "learning_rate": 1.2750000000000002e-05,
      "loss": 0.0018,
      "step": 13410
    },
    {
      "epoch": 1.491111111111111,
      "grad_norm": 0.7051717638969421,
      "learning_rate": 1.2722222222222221e-05,
      "loss": 0.0031,
      "step": 13420
    },
    {
      "epoch": 1.4922222222222223,
      "grad_norm": 0.33643436431884766,
      "learning_rate": 1.2694444444444446e-05,
      "loss": 0.0022,
      "step": 13430
    },
    {
      "epoch": 1.4933333333333334,
      "grad_norm": 0.1915215104818344,
      "learning_rate": 1.2666666666666668e-05,
      "loss": 0.0022,
      "step": 13440
    },
    {
      "epoch": 1.4944444444444445,
      "grad_norm": 0.4142362177371979,
      "learning_rate": 1.263888888888889e-05,
      "loss": 0.0036,
      "step": 13450
    },
    {
      "epoch": 1.4955555555555555,
      "grad_norm": 0.3658655285835266,
      "learning_rate": 1.2611111111111113e-05,
      "loss": 0.0021,
      "step": 13460
    },
    {
      "epoch": 1.4966666666666666,
      "grad_norm": 0.3886353671550751,
      "learning_rate": 1.2583333333333334e-05,
      "loss": 0.0027,
      "step": 13470
    },
    {
      "epoch": 1.4977777777777779,
      "grad_norm": 0.7271935939788818,
      "learning_rate": 1.2555555555555557e-05,
      "loss": 0.0024,
      "step": 13480
    },
    {
      "epoch": 1.498888888888889,
      "grad_norm": 0.5733277201652527,
      "learning_rate": 1.2527777777777778e-05,
      "loss": 0.004,
      "step": 13490
    },
    {
      "epoch": 1.5,
      "grad_norm": 0.641768753528595,
      "learning_rate": 1.25e-05,
      "loss": 0.0021,
      "step": 13500
    },
    {
      "epoch": 1.501111111111111,
      "grad_norm": 0.34165820479393005,
      "learning_rate": 1.2472222222222223e-05,
      "loss": 0.0023,
      "step": 13510
    },
    {
      "epoch": 1.5022222222222221,
      "grad_norm": 0.2690971791744232,
      "learning_rate": 1.2444444444444445e-05,
      "loss": 0.003,
      "step": 13520
    },
    {
      "epoch": 1.5033333333333334,
      "grad_norm": 0.19311732053756714,
      "learning_rate": 1.2416666666666667e-05,
      "loss": 0.0023,
      "step": 13530
    },
    {
      "epoch": 1.5044444444444445,
      "grad_norm": 1.3251490592956543,
      "learning_rate": 1.238888888888889e-05,
      "loss": 0.0032,
      "step": 13540
    },
    {
      "epoch": 1.5055555555555555,
      "grad_norm": 0.5730856657028198,
      "learning_rate": 1.2361111111111112e-05,
      "loss": 0.0021,
      "step": 13550
    },
    {
      "epoch": 1.5066666666666668,
      "grad_norm": 0.31873366236686707,
      "learning_rate": 1.2333333333333334e-05,
      "loss": 0.0035,
      "step": 13560
    },
    {
      "epoch": 1.5077777777777777,
      "grad_norm": 0.9549129009246826,
      "learning_rate": 1.2305555555555556e-05,
      "loss": 0.0024,
      "step": 13570
    },
    {
      "epoch": 1.508888888888889,
      "grad_norm": 0.6905159950256348,
      "learning_rate": 1.2277777777777778e-05,
      "loss": 0.0042,
      "step": 13580
    },
    {
      "epoch": 1.51,
      "grad_norm": 0.7473359107971191,
      "learning_rate": 1.225e-05,
      "loss": 0.0019,
      "step": 13590
    },
    {
      "epoch": 1.511111111111111,
      "grad_norm": 0.6938674449920654,
      "learning_rate": 1.2222222222222222e-05,
      "loss": 0.002,
      "step": 13600
    },
    {
      "epoch": 1.5122222222222224,
      "grad_norm": 0.5407857298851013,
      "learning_rate": 1.2194444444444444e-05,
      "loss": 0.0026,
      "step": 13610
    },
    {
      "epoch": 1.5133333333333332,
      "grad_norm": 0.2735908627510071,
      "learning_rate": 1.2166666666666668e-05,
      "loss": 0.0023,
      "step": 13620
    },
    {
      "epoch": 1.5144444444444445,
      "grad_norm": 1.1728326082229614,
      "learning_rate": 1.213888888888889e-05,
      "loss": 0.0027,
      "step": 13630
    },
    {
      "epoch": 1.5155555555555555,
      "grad_norm": 1.0962756872177124,
      "learning_rate": 1.2111111111111112e-05,
      "loss": 0.0026,
      "step": 13640
    },
    {
      "epoch": 1.5166666666666666,
      "grad_norm": 0.5724783539772034,
      "learning_rate": 1.2083333333333333e-05,
      "loss": 0.0048,
      "step": 13650
    },
    {
      "epoch": 1.517777777777778,
      "grad_norm": 0.5471845269203186,
      "learning_rate": 1.2055555555555556e-05,
      "loss": 0.0026,
      "step": 13660
    },
    {
      "epoch": 1.5188888888888887,
      "grad_norm": 0.5044011473655701,
      "learning_rate": 1.2027777777777777e-05,
      "loss": 0.0019,
      "step": 13670
    },
    {
      "epoch": 1.52,
      "grad_norm": 0.373283714056015,
      "learning_rate": 1.2e-05,
      "loss": 0.0021,
      "step": 13680
    },
    {
      "epoch": 1.521111111111111,
      "grad_norm": 0.5783753991127014,
      "learning_rate": 1.1972222222222221e-05,
      "loss": 0.0039,
      "step": 13690
    },
    {
      "epoch": 1.5222222222222221,
      "grad_norm": 0.49209001660346985,
      "learning_rate": 1.1944444444444446e-05,
      "loss": 0.0015,
      "step": 13700
    },
    {
      "epoch": 1.5233333333333334,
      "grad_norm": 0.6713414192199707,
      "learning_rate": 1.1916666666666667e-05,
      "loss": 0.0029,
      "step": 13710
    },
    {
      "epoch": 1.5244444444444445,
      "grad_norm": 0.6404886245727539,
      "learning_rate": 1.188888888888889e-05,
      "loss": 0.0025,
      "step": 13720
    },
    {
      "epoch": 1.5255555555555556,
      "grad_norm": 0.3710271716117859,
      "learning_rate": 1.1861111111111111e-05,
      "loss": 0.0024,
      "step": 13730
    },
    {
      "epoch": 1.5266666666666666,
      "grad_norm": 0.2739790380001068,
      "learning_rate": 1.1833333333333334e-05,
      "loss": 0.0024,
      "step": 13740
    },
    {
      "epoch": 1.5277777777777777,
      "grad_norm": 0.2682341933250427,
      "learning_rate": 1.1805555555555555e-05,
      "loss": 0.0035,
      "step": 13750
    },
    {
      "epoch": 1.528888888888889,
      "grad_norm": 0.2946995198726654,
      "learning_rate": 1.1777777777777778e-05,
      "loss": 0.0022,
      "step": 13760
    },
    {
      "epoch": 1.53,
      "grad_norm": 0.4182482659816742,
      "learning_rate": 1.175e-05,
      "loss": 0.0023,
      "step": 13770
    },
    {
      "epoch": 1.531111111111111,
      "grad_norm": 0.6512100696563721,
      "learning_rate": 1.1722222222222224e-05,
      "loss": 0.0024,
      "step": 13780
    },
    {
      "epoch": 1.5322222222222224,
      "grad_norm": 0.8346366882324219,
      "learning_rate": 1.1694444444444445e-05,
      "loss": 0.0024,
      "step": 13790
    },
    {
      "epoch": 1.5333333333333332,
      "grad_norm": 1.479464054107666,
      "learning_rate": 1.1666666666666668e-05,
      "loss": 0.0029,
      "step": 13800
    },
    {
      "epoch": 1.5344444444444445,
      "grad_norm": 0.3900396525859833,
      "learning_rate": 1.1638888888888889e-05,
      "loss": 0.0013,
      "step": 13810
    },
    {
      "epoch": 1.5355555555555556,
      "grad_norm": 0.5041794776916504,
      "learning_rate": 1.1611111111111112e-05,
      "loss": 0.0037,
      "step": 13820
    },
    {
      "epoch": 1.5366666666666666,
      "grad_norm": 1.239874243736267,
      "learning_rate": 1.1583333333333333e-05,
      "loss": 0.0025,
      "step": 13830
    },
    {
      "epoch": 1.537777777777778,
      "grad_norm": 1.5900087356567383,
      "learning_rate": 1.1555555555555556e-05,
      "loss": 0.0019,
      "step": 13840
    },
    {
      "epoch": 1.5388888888888888,
      "grad_norm": 0.5007908344268799,
      "learning_rate": 1.1527777777777779e-05,
      "loss": 0.002,
      "step": 13850
    },
    {
      "epoch": 1.54,
      "grad_norm": 0.2703244090080261,
      "learning_rate": 1.1500000000000002e-05,
      "loss": 0.0027,
      "step": 13860
    },
    {
      "epoch": 1.541111111111111,
      "grad_norm": 0.5580028891563416,
      "learning_rate": 1.1472222222222223e-05,
      "loss": 0.0022,
      "step": 13870
    },
    {
      "epoch": 1.5422222222222222,
      "grad_norm": 0.2981624901294708,
      "learning_rate": 1.1444444444444446e-05,
      "loss": 0.0023,
      "step": 13880
    },
    {
      "epoch": 1.5433333333333334,
      "grad_norm": 0.7779520153999329,
      "learning_rate": 1.1416666666666667e-05,
      "loss": 0.0022,
      "step": 13890
    },
    {
      "epoch": 1.5444444444444443,
      "grad_norm": 1.284947395324707,
      "learning_rate": 1.138888888888889e-05,
      "loss": 0.0027,
      "step": 13900
    },
    {
      "epoch": 1.5455555555555556,
      "grad_norm": 1.004805088043213,
      "learning_rate": 1.1361111111111111e-05,
      "loss": 0.003,
      "step": 13910
    },
    {
      "epoch": 1.5466666666666666,
      "grad_norm": 0.33986398577690125,
      "learning_rate": 1.1333333333333334e-05,
      "loss": 0.0027,
      "step": 13920
    },
    {
      "epoch": 1.5477777777777777,
      "grad_norm": 0.8317112922668457,
      "learning_rate": 1.1305555555555557e-05,
      "loss": 0.0015,
      "step": 13930
    },
    {
      "epoch": 1.548888888888889,
      "grad_norm": 0.42815637588500977,
      "learning_rate": 1.127777777777778e-05,
      "loss": 0.003,
      "step": 13940
    },
    {
      "epoch": 1.55,
      "grad_norm": 0.17641890048980713,
      "learning_rate": 1.125e-05,
      "loss": 0.0024,
      "step": 13950
    },
    {
      "epoch": 1.551111111111111,
      "grad_norm": 0.5012568235397339,
      "learning_rate": 1.1222222222222224e-05,
      "loss": 0.0019,
      "step": 13960
    },
    {
      "epoch": 1.5522222222222222,
      "grad_norm": 0.2858293056488037,
      "learning_rate": 1.1194444444444445e-05,
      "loss": 0.0032,
      "step": 13970
    },
    {
      "epoch": 1.5533333333333332,
      "grad_norm": 0.274883896112442,
      "learning_rate": 1.1166666666666668e-05,
      "loss": 0.0015,
      "step": 13980
    },
    {
      "epoch": 1.5544444444444445,
      "grad_norm": 0.32803234457969666,
      "learning_rate": 1.1138888888888889e-05,
      "loss": 0.0016,
      "step": 13990
    },
    {
      "epoch": 1.5555555555555556,
      "grad_norm": 0.817411482334137,
      "learning_rate": 1.1111111111111112e-05,
      "loss": 0.0025,
      "step": 14000
    },
    {
      "epoch": 1.5566666666666666,
      "grad_norm": 1.5864150524139404,
      "learning_rate": 1.1083333333333335e-05,
      "loss": 0.0022,
      "step": 14010
    },
    {
      "epoch": 1.557777777777778,
      "grad_norm": 0.4310859739780426,
      "learning_rate": 1.1055555555555556e-05,
      "loss": 0.0034,
      "step": 14020
    },
    {
      "epoch": 1.5588888888888888,
      "grad_norm": 1.180784821510315,
      "learning_rate": 1.1027777777777779e-05,
      "loss": 0.0023,
      "step": 14030
    },
    {
      "epoch": 1.56,
      "grad_norm": 0.4552641212940216,
      "learning_rate": 1.1000000000000001e-05,
      "loss": 0.0025,
      "step": 14040
    },
    {
      "epoch": 1.5611111111111111,
      "grad_norm": 0.27846428751945496,
      "learning_rate": 1.0972222222222223e-05,
      "loss": 0.0033,
      "step": 14050
    },
    {
      "epoch": 1.5622222222222222,
      "grad_norm": 0.41166114807128906,
      "learning_rate": 1.0944444444444445e-05,
      "loss": 0.0019,
      "step": 14060
    },
    {
      "epoch": 1.5633333333333335,
      "grad_norm": 0.9783207178115845,
      "learning_rate": 1.0916666666666667e-05,
      "loss": 0.0033,
      "step": 14070
    },
    {
      "epoch": 1.5644444444444443,
      "grad_norm": 0.1749398112297058,
      "learning_rate": 1.088888888888889e-05,
      "loss": 0.0026,
      "step": 14080
    },
    {
      "epoch": 1.5655555555555556,
      "grad_norm": 0.6179569363594055,
      "learning_rate": 1.0861111111111112e-05,
      "loss": 0.0029,
      "step": 14090
    },
    {
      "epoch": 1.5666666666666667,
      "grad_norm": 0.19352006912231445,
      "learning_rate": 1.0833333333333334e-05,
      "loss": 0.0016,
      "step": 14100
    },
    {
      "epoch": 1.5677777777777777,
      "grad_norm": 0.320142924785614,
      "learning_rate": 1.0805555555555556e-05,
      "loss": 0.0027,
      "step": 14110
    },
    {
      "epoch": 1.568888888888889,
      "grad_norm": 0.5237976908683777,
      "learning_rate": 1.0777777777777778e-05,
      "loss": 0.0014,
      "step": 14120
    },
    {
      "epoch": 1.5699999999999998,
      "grad_norm": 0.5087485909461975,
      "learning_rate": 1.075e-05,
      "loss": 0.0017,
      "step": 14130
    },
    {
      "epoch": 1.5711111111111111,
      "grad_norm": 0.23116406798362732,
      "learning_rate": 1.0722222222222222e-05,
      "loss": 0.0011,
      "step": 14140
    },
    {
      "epoch": 1.5722222222222222,
      "grad_norm": 0.13821600377559662,
      "learning_rate": 1.0694444444444444e-05,
      "loss": 0.0022,
      "step": 14150
    },
    {
      "epoch": 1.5733333333333333,
      "grad_norm": 0.35179761052131653,
      "learning_rate": 1.0666666666666667e-05,
      "loss": 0.0015,
      "step": 14160
    },
    {
      "epoch": 1.5744444444444445,
      "grad_norm": 0.6893221139907837,
      "learning_rate": 1.063888888888889e-05,
      "loss": 0.0017,
      "step": 14170
    },
    {
      "epoch": 1.5755555555555556,
      "grad_norm": 1.3366234302520752,
      "learning_rate": 1.0611111111111111e-05,
      "loss": 0.0033,
      "step": 14180
    },
    {
      "epoch": 1.5766666666666667,
      "grad_norm": 0.6274850964546204,
      "learning_rate": 1.0583333333333334e-05,
      "loss": 0.0028,
      "step": 14190
    },
    {
      "epoch": 1.5777777777777777,
      "grad_norm": 0.6515049934387207,
      "learning_rate": 1.0555555555555555e-05,
      "loss": 0.002,
      "step": 14200
    },
    {
      "epoch": 1.5788888888888888,
      "grad_norm": 0.21138399839401245,
      "learning_rate": 1.0527777777777778e-05,
      "loss": 0.0019,
      "step": 14210
    },
    {
      "epoch": 1.58,
      "grad_norm": 0.5002020597457886,
      "learning_rate": 1.05e-05,
      "loss": 0.002,
      "step": 14220
    },
    {
      "epoch": 1.5811111111111111,
      "grad_norm": 0.4202241599559784,
      "learning_rate": 1.0472222222222222e-05,
      "loss": 0.0026,
      "step": 14230
    },
    {
      "epoch": 1.5822222222222222,
      "grad_norm": 0.7615541815757751,
      "learning_rate": 1.0444444444444445e-05,
      "loss": 0.0018,
      "step": 14240
    },
    {
      "epoch": 1.5833333333333335,
      "grad_norm": 0.31521493196487427,
      "learning_rate": 1.0416666666666668e-05,
      "loss": 0.0023,
      "step": 14250
    },
    {
      "epoch": 1.5844444444444443,
      "grad_norm": 0.39857539534568787,
      "learning_rate": 1.038888888888889e-05,
      "loss": 0.0013,
      "step": 14260
    },
    {
      "epoch": 1.5855555555555556,
      "grad_norm": 0.4940643608570099,
      "learning_rate": 1.0361111111111112e-05,
      "loss": 0.0033,
      "step": 14270
    },
    {
      "epoch": 1.5866666666666667,
      "grad_norm": 0.9612625241279602,
      "learning_rate": 1.0333333333333333e-05,
      "loss": 0.0033,
      "step": 14280
    },
    {
      "epoch": 1.5877777777777777,
      "grad_norm": 0.40268373489379883,
      "learning_rate": 1.0305555555555556e-05,
      "loss": 0.0019,
      "step": 14290
    },
    {
      "epoch": 1.588888888888889,
      "grad_norm": 0.6478251814842224,
      "learning_rate": 1.0277777777777777e-05,
      "loss": 0.0021,
      "step": 14300
    },
    {
      "epoch": 1.5899999999999999,
      "grad_norm": 0.5735090970993042,
      "learning_rate": 1.025e-05,
      "loss": 0.0027,
      "step": 14310
    },
    {
      "epoch": 1.5911111111111111,
      "grad_norm": 0.3081718385219574,
      "learning_rate": 1.0222222222222223e-05,
      "loss": 0.001,
      "step": 14320
    },
    {
      "epoch": 1.5922222222222222,
      "grad_norm": 0.2788177728652954,
      "learning_rate": 1.0194444444444446e-05,
      "loss": 0.0037,
      "step": 14330
    },
    {
      "epoch": 1.5933333333333333,
      "grad_norm": 0.6114049553871155,
      "learning_rate": 1.0166666666666667e-05,
      "loss": 0.0023,
      "step": 14340
    },
    {
      "epoch": 1.5944444444444446,
      "grad_norm": 0.7342247366905212,
      "learning_rate": 1.013888888888889e-05,
      "loss": 0.003,
      "step": 14350
    },
    {
      "epoch": 1.5955555555555554,
      "grad_norm": 0.9176725745201111,
      "learning_rate": 1.0111111111111111e-05,
      "loss": 0.003,
      "step": 14360
    },
    {
      "epoch": 1.5966666666666667,
      "grad_norm": 0.4849715530872345,
      "learning_rate": 1.0083333333333334e-05,
      "loss": 0.0017,
      "step": 14370
    },
    {
      "epoch": 1.5977777777777777,
      "grad_norm": 0.36156874895095825,
      "learning_rate": 1.0055555555555555e-05,
      "loss": 0.0045,
      "step": 14380
    },
    {
      "epoch": 1.5988888888888888,
      "grad_norm": 0.589320957660675,
      "learning_rate": 1.0027777777777778e-05,
      "loss": 0.002,
      "step": 14390
    },
    {
      "epoch": 1.6,
      "grad_norm": 0.34271660447120667,
      "learning_rate": 1e-05,
      "loss": 0.0023,
      "step": 14400
    },
    {
      "epoch": 1.6011111111111112,
      "grad_norm": 0.5153077840805054,
      "learning_rate": 9.972222222222224e-06,
      "loss": 0.0047,
      "step": 14410
    },
    {
      "epoch": 1.6022222222222222,
      "grad_norm": 0.7412295937538147,
      "learning_rate": 9.944444444444445e-06,
      "loss": 0.0028,
      "step": 14420
    },
    {
      "epoch": 1.6033333333333335,
      "grad_norm": 1.3944323062896729,
      "learning_rate": 9.916666666666668e-06,
      "loss": 0.0025,
      "step": 14430
    },
    {
      "epoch": 1.6044444444444443,
      "grad_norm": 0.5657523274421692,
      "learning_rate": 9.888888888888889e-06,
      "loss": 0.0022,
      "step": 14440
    },
    {
      "epoch": 1.6055555555555556,
      "grad_norm": 0.31388071179389954,
      "learning_rate": 9.861111111111112e-06,
      "loss": 0.0026,
      "step": 14450
    },
    {
      "epoch": 1.6066666666666667,
      "grad_norm": 0.7155650854110718,
      "learning_rate": 9.833333333333333e-06,
      "loss": 0.0029,
      "step": 14460
    },
    {
      "epoch": 1.6077777777777778,
      "grad_norm": 0.4496398866176605,
      "learning_rate": 9.805555555555557e-06,
      "loss": 0.0032,
      "step": 14470
    },
    {
      "epoch": 1.608888888888889,
      "grad_norm": 0.4213491976261139,
      "learning_rate": 9.777777777777779e-06,
      "loss": 0.003,
      "step": 14480
    },
    {
      "epoch": 1.6099999999999999,
      "grad_norm": 0.6455119252204895,
      "learning_rate": 9.750000000000002e-06,
      "loss": 0.0027,
      "step": 14490
    },
    {
      "epoch": 1.6111111111111112,
      "grad_norm": 0.5843939185142517,
      "learning_rate": 9.722222222222223e-06,
      "loss": 0.0024,
      "step": 14500
    },
    {
      "epoch": 1.6122222222222222,
      "grad_norm": 0.6594114899635315,
      "learning_rate": 9.694444444444446e-06,
      "loss": 0.003,
      "step": 14510
    },
    {
      "epoch": 1.6133333333333333,
      "grad_norm": 0.2745671272277832,
      "learning_rate": 9.666666666666667e-06,
      "loss": 0.0036,
      "step": 14520
    },
    {
      "epoch": 1.6144444444444446,
      "grad_norm": 0.18499203026294708,
      "learning_rate": 9.63888888888889e-06,
      "loss": 0.0019,
      "step": 14530
    },
    {
      "epoch": 1.6155555555555554,
      "grad_norm": 0.7462162971496582,
      "learning_rate": 9.61111111111111e-06,
      "loss": 0.0031,
      "step": 14540
    },
    {
      "epoch": 1.6166666666666667,
      "grad_norm": 0.1668214052915573,
      "learning_rate": 9.583333333333334e-06,
      "loss": 0.003,
      "step": 14550
    },
    {
      "epoch": 1.6177777777777778,
      "grad_norm": 0.5486371517181396,
      "learning_rate": 9.555555555555556e-06,
      "loss": 0.0013,
      "step": 14560
    },
    {
      "epoch": 1.6188888888888888,
      "grad_norm": 0.5014028549194336,
      "learning_rate": 9.52777777777778e-06,
      "loss": 0.0046,
      "step": 14570
    },
    {
      "epoch": 1.62,
      "grad_norm": 0.4911749064922333,
      "learning_rate": 9.5e-06,
      "loss": 0.0031,
      "step": 14580
    },
    {
      "epoch": 1.621111111111111,
      "grad_norm": 0.7538961172103882,
      "learning_rate": 9.472222222222223e-06,
      "loss": 0.0023,
      "step": 14590
    },
    {
      "epoch": 1.6222222222222222,
      "grad_norm": 0.8067880868911743,
      "learning_rate": 9.444444444444445e-06,
      "loss": 0.0023,
      "step": 14600
    },
    {
      "epoch": 1.6233333333333333,
      "grad_norm": 0.39204534888267517,
      "learning_rate": 9.416666666666667e-06,
      "loss": 0.0024,
      "step": 14610
    },
    {
      "epoch": 1.6244444444444444,
      "grad_norm": 0.46801072359085083,
      "learning_rate": 9.388888888888889e-06,
      "loss": 0.004,
      "step": 14620
    },
    {
      "epoch": 1.6255555555555556,
      "grad_norm": 0.6361063718795776,
      "learning_rate": 9.361111111111111e-06,
      "loss": 0.0022,
      "step": 14630
    },
    {
      "epoch": 1.6266666666666667,
      "grad_norm": 0.22249315679073334,
      "learning_rate": 9.333333333333334e-06,
      "loss": 0.0016,
      "step": 14640
    },
    {
      "epoch": 1.6277777777777778,
      "grad_norm": 0.3360172510147095,
      "learning_rate": 9.305555555555555e-06,
      "loss": 0.0015,
      "step": 14650
    },
    {
      "epoch": 1.628888888888889,
      "grad_norm": 0.4802514314651489,
      "learning_rate": 9.277777777777778e-06,
      "loss": 0.0014,
      "step": 14660
    },
    {
      "epoch": 1.63,
      "grad_norm": 0.3593539595603943,
      "learning_rate": 9.25e-06,
      "loss": 0.0016,
      "step": 14670
    },
    {
      "epoch": 1.6311111111111112,
      "grad_norm": 0.5328670740127563,
      "learning_rate": 9.222222222222222e-06,
      "loss": 0.0013,
      "step": 14680
    },
    {
      "epoch": 1.6322222222222222,
      "grad_norm": 0.28497886657714844,
      "learning_rate": 9.194444444444445e-06,
      "loss": 0.0029,
      "step": 14690
    },
    {
      "epoch": 1.6333333333333333,
      "grad_norm": 0.22751885652542114,
      "learning_rate": 9.166666666666666e-06,
      "loss": 0.0027,
      "step": 14700
    },
    {
      "epoch": 1.6344444444444446,
      "grad_norm": 0.8668749332427979,
      "learning_rate": 9.13888888888889e-06,
      "loss": 0.0019,
      "step": 14710
    },
    {
      "epoch": 1.6355555555555554,
      "grad_norm": 0.9343793988227844,
      "learning_rate": 9.111111111111112e-06,
      "loss": 0.0021,
      "step": 14720
    },
    {
      "epoch": 1.6366666666666667,
      "grad_norm": 0.2527836263179779,
      "learning_rate": 9.083333333333333e-06,
      "loss": 0.0016,
      "step": 14730
    },
    {
      "epoch": 1.6377777777777778,
      "grad_norm": 0.39140376448631287,
      "learning_rate": 9.055555555555556e-06,
      "loss": 0.0027,
      "step": 14740
    },
    {
      "epoch": 1.6388888888888888,
      "grad_norm": 0.2476392686367035,
      "learning_rate": 9.027777777777777e-06,
      "loss": 0.002,
      "step": 14750
    },
    {
      "epoch": 1.6400000000000001,
      "grad_norm": 0.8923712968826294,
      "learning_rate": 9e-06,
      "loss": 0.0015,
      "step": 14760
    },
    {
      "epoch": 1.641111111111111,
      "grad_norm": 0.6082444787025452,
      "learning_rate": 8.972222222222221e-06,
      "loss": 0.0014,
      "step": 14770
    },
    {
      "epoch": 1.6422222222222222,
      "grad_norm": 0.28267964720726013,
      "learning_rate": 8.944444444444444e-06,
      "loss": 0.0023,
      "step": 14780
    },
    {
      "epoch": 1.6433333333333333,
      "grad_norm": 0.43843546509742737,
      "learning_rate": 8.916666666666667e-06,
      "loss": 0.0019,
      "step": 14790
    },
    {
      "epoch": 1.6444444444444444,
      "grad_norm": 1.0928394794464111,
      "learning_rate": 8.88888888888889e-06,
      "loss": 0.0029,
      "step": 14800
    },
    {
      "epoch": 1.6455555555555557,
      "grad_norm": 0.615380585193634,
      "learning_rate": 8.861111111111111e-06,
      "loss": 0.0025,
      "step": 14810
    },
    {
      "epoch": 1.6466666666666665,
      "grad_norm": 0.657038688659668,
      "learning_rate": 8.833333333333334e-06,
      "loss": 0.003,
      "step": 14820
    },
    {
      "epoch": 1.6477777777777778,
      "grad_norm": 0.5877869129180908,
      "learning_rate": 8.805555555555555e-06,
      "loss": 0.0032,
      "step": 14830
    },
    {
      "epoch": 1.6488888888888888,
      "grad_norm": 0.7578235864639282,
      "learning_rate": 8.777777777777778e-06,
      "loss": 0.0016,
      "step": 14840
    },
    {
      "epoch": 1.65,
      "grad_norm": 0.4948684871196747,
      "learning_rate": 8.75e-06,
      "loss": 0.0009,
      "step": 14850
    },
    {
      "epoch": 1.6511111111111112,
      "grad_norm": 0.2733738422393799,
      "learning_rate": 8.722222222222224e-06,
      "loss": 0.0026,
      "step": 14860
    },
    {
      "epoch": 1.6522222222222223,
      "grad_norm": 0.35703155398368835,
      "learning_rate": 8.694444444444445e-06,
      "loss": 0.0019,
      "step": 14870
    },
    {
      "epoch": 1.6533333333333333,
      "grad_norm": 1.1105012893676758,
      "learning_rate": 8.666666666666668e-06,
      "loss": 0.0027,
      "step": 14880
    },
    {
      "epoch": 1.6544444444444446,
      "grad_norm": 1.025303840637207,
      "learning_rate": 8.638888888888889e-06,
      "loss": 0.0017,
      "step": 14890
    },
    {
      "epoch": 1.6555555555555554,
      "grad_norm": 0.40667250752449036,
      "learning_rate": 8.611111111111112e-06,
      "loss": 0.0031,
      "step": 14900
    },
    {
      "epoch": 1.6566666666666667,
      "grad_norm": 0.2577289640903473,
      "learning_rate": 8.583333333333333e-06,
      "loss": 0.0025,
      "step": 14910
    },
    {
      "epoch": 1.6577777777777778,
      "grad_norm": 0.6029127240180969,
      "learning_rate": 8.555555555555556e-06,
      "loss": 0.0033,
      "step": 14920
    },
    {
      "epoch": 1.6588888888888889,
      "grad_norm": 0.20530419051647186,
      "learning_rate": 8.527777777777777e-06,
      "loss": 0.0019,
      "step": 14930
    },
    {
      "epoch": 1.6600000000000001,
      "grad_norm": 0.9733384847640991,
      "learning_rate": 8.500000000000002e-06,
      "loss": 0.0021,
      "step": 14940
    },
    {
      "epoch": 1.661111111111111,
      "grad_norm": 1.3467456102371216,
      "learning_rate": 8.472222222222223e-06,
      "loss": 0.0018,
      "step": 14950
    },
    {
      "epoch": 1.6622222222222223,
      "grad_norm": 0.734142541885376,
      "learning_rate": 8.444444444444446e-06,
      "loss": 0.0023,
      "step": 14960
    },
    {
      "epoch": 1.6633333333333333,
      "grad_norm": 0.25399109721183777,
      "learning_rate": 8.416666666666667e-06,
      "loss": 0.0012,
      "step": 14970
    },
    {
      "epoch": 1.6644444444444444,
      "grad_norm": 0.7290153503417969,
      "learning_rate": 8.38888888888889e-06,
      "loss": 0.0024,
      "step": 14980
    },
    {
      "epoch": 1.6655555555555557,
      "grad_norm": 0.17989641427993774,
      "learning_rate": 8.361111111111111e-06,
      "loss": 0.0024,
      "step": 14990
    },
    {
      "epoch": 1.6666666666666665,
      "grad_norm": 0.35263487696647644,
      "learning_rate": 8.333333333333334e-06,
      "loss": 0.0024,
      "step": 15000
    },
    {
      "epoch": 1.6677777777777778,
      "grad_norm": 0.21220357716083527,
      "learning_rate": 8.305555555555555e-06,
      "loss": 0.0016,
      "step": 15010
    },
    {
      "epoch": 1.6688888888888889,
      "grad_norm": 0.33915865421295166,
      "learning_rate": 8.27777777777778e-06,
      "loss": 0.0028,
      "step": 15020
    },
    {
      "epoch": 1.67,
      "grad_norm": 0.36128759384155273,
      "learning_rate": 8.25e-06,
      "loss": 0.0012,
      "step": 15030
    },
    {
      "epoch": 1.6711111111111112,
      "grad_norm": 0.3088211119174957,
      "learning_rate": 8.222222222222223e-06,
      "loss": 0.004,
      "step": 15040
    },
    {
      "epoch": 1.6722222222222223,
      "grad_norm": 0.20130008459091187,
      "learning_rate": 8.194444444444445e-06,
      "loss": 0.0017,
      "step": 15050
    },
    {
      "epoch": 1.6733333333333333,
      "grad_norm": 0.4336485266685486,
      "learning_rate": 8.166666666666668e-06,
      "loss": 0.0013,
      "step": 15060
    },
    {
      "epoch": 1.6744444444444444,
      "grad_norm": 0.37082168459892273,
      "learning_rate": 8.138888888888889e-06,
      "loss": 0.0013,
      "step": 15070
    },
    {
      "epoch": 1.6755555555555555,
      "grad_norm": 0.8216164708137512,
      "learning_rate": 8.111111111111112e-06,
      "loss": 0.0024,
      "step": 15080
    },
    {
      "epoch": 1.6766666666666667,
      "grad_norm": 0.8110600709915161,
      "learning_rate": 8.083333333333333e-06,
      "loss": 0.0024,
      "step": 15090
    },
    {
      "epoch": 1.6777777777777778,
      "grad_norm": 0.13667231798171997,
      "learning_rate": 8.055555555555557e-06,
      "loss": 0.0031,
      "step": 15100
    },
    {
      "epoch": 1.6788888888888889,
      "grad_norm": 0.6438019275665283,
      "learning_rate": 8.027777777777778e-06,
      "loss": 0.0017,
      "step": 15110
    },
    {
      "epoch": 1.6800000000000002,
      "grad_norm": 0.3408648371696472,
      "learning_rate": 8.000000000000001e-06,
      "loss": 0.0021,
      "step": 15120
    },
    {
      "epoch": 1.681111111111111,
      "grad_norm": 0.3425265848636627,
      "learning_rate": 7.972222222222223e-06,
      "loss": 0.0018,
      "step": 15130
    },
    {
      "epoch": 1.6822222222222223,
      "grad_norm": 0.3038727343082428,
      "learning_rate": 7.944444444444445e-06,
      "loss": 0.0024,
      "step": 15140
    },
    {
      "epoch": 1.6833333333333333,
      "grad_norm": 0.2986544370651245,
      "learning_rate": 7.916666666666667e-06,
      "loss": 0.0025,
      "step": 15150
    },
    {
      "epoch": 1.6844444444444444,
      "grad_norm": 0.34708139300346375,
      "learning_rate": 7.88888888888889e-06,
      "loss": 0.0023,
      "step": 15160
    },
    {
      "epoch": 1.6855555555555557,
      "grad_norm": 0.22684259712696075,
      "learning_rate": 7.861111111111112e-06,
      "loss": 0.0017,
      "step": 15170
    },
    {
      "epoch": 1.6866666666666665,
      "grad_norm": 0.35720422863960266,
      "learning_rate": 7.833333333333333e-06,
      "loss": 0.0026,
      "step": 15180
    },
    {
      "epoch": 1.6877777777777778,
      "grad_norm": 0.25551658868789673,
      "learning_rate": 7.805555555555556e-06,
      "loss": 0.0035,
      "step": 15190
    },
    {
      "epoch": 1.6888888888888889,
      "grad_norm": 0.28718137741088867,
      "learning_rate": 7.777777777777777e-06,
      "loss": 0.0019,
      "step": 15200
    },
    {
      "epoch": 1.69,
      "grad_norm": 0.31838372349739075,
      "learning_rate": 7.75e-06,
      "loss": 0.0019,
      "step": 15210
    },
    {
      "epoch": 1.6911111111111112,
      "grad_norm": 0.2609904110431671,
      "learning_rate": 7.722222222222223e-06,
      "loss": 0.0017,
      "step": 15220
    },
    {
      "epoch": 1.692222222222222,
      "grad_norm": 0.3942948281764984,
      "learning_rate": 7.694444444444444e-06,
      "loss": 0.0025,
      "step": 15230
    },
    {
      "epoch": 1.6933333333333334,
      "grad_norm": 0.18373410403728485,
      "learning_rate": 7.666666666666667e-06,
      "loss": 0.0036,
      "step": 15240
    },
    {
      "epoch": 1.6944444444444444,
      "grad_norm": 0.568283200263977,
      "learning_rate": 7.63888888888889e-06,
      "loss": 0.0034,
      "step": 15250
    },
    {
      "epoch": 1.6955555555555555,
      "grad_norm": 0.2587410509586334,
      "learning_rate": 7.611111111111112e-06,
      "loss": 0.0021,
      "step": 15260
    },
    {
      "epoch": 1.6966666666666668,
      "grad_norm": 1.1668163537979126,
      "learning_rate": 7.583333333333334e-06,
      "loss": 0.0029,
      "step": 15270
    },
    {
      "epoch": 1.6977777777777778,
      "grad_norm": 0.2684750258922577,
      "learning_rate": 7.555555555555556e-06,
      "loss": 0.0032,
      "step": 15280
    },
    {
      "epoch": 1.698888888888889,
      "grad_norm": 0.3493596613407135,
      "learning_rate": 7.527777777777778e-06,
      "loss": 0.0035,
      "step": 15290
    },
    {
      "epoch": 1.7,
      "grad_norm": 0.49775463342666626,
      "learning_rate": 7.5e-06,
      "loss": 0.0015,
      "step": 15300
    },
    {
      "epoch": 1.701111111111111,
      "grad_norm": 0.4004571735858917,
      "learning_rate": 7.472222222222222e-06,
      "loss": 0.0022,
      "step": 15310
    },
    {
      "epoch": 1.7022222222222223,
      "grad_norm": 0.2841630280017853,
      "learning_rate": 7.444444444444444e-06,
      "loss": 0.0013,
      "step": 15320
    },
    {
      "epoch": 1.7033333333333334,
      "grad_norm": 0.25795993208885193,
      "learning_rate": 7.416666666666668e-06,
      "loss": 0.0024,
      "step": 15330
    },
    {
      "epoch": 1.7044444444444444,
      "grad_norm": 0.6417917013168335,
      "learning_rate": 7.38888888888889e-06,
      "loss": 0.002,
      "step": 15340
    },
    {
      "epoch": 1.7055555555555557,
      "grad_norm": 0.5784346461296082,
      "learning_rate": 7.361111111111112e-06,
      "loss": 0.0018,
      "step": 15350
    },
    {
      "epoch": 1.7066666666666666,
      "grad_norm": 0.49003100395202637,
      "learning_rate": 7.333333333333334e-06,
      "loss": 0.0024,
      "step": 15360
    },
    {
      "epoch": 1.7077777777777778,
      "grad_norm": 0.52621990442276,
      "learning_rate": 7.305555555555556e-06,
      "loss": 0.0031,
      "step": 15370
    },
    {
      "epoch": 1.708888888888889,
      "grad_norm": 0.3430420756340027,
      "learning_rate": 7.277777777777778e-06,
      "loss": 0.0023,
      "step": 15380
    },
    {
      "epoch": 1.71,
      "grad_norm": 0.6028760671615601,
      "learning_rate": 7.25e-06,
      "loss": 0.0024,
      "step": 15390
    },
    {
      "epoch": 1.7111111111111112,
      "grad_norm": 0.6709629893302917,
      "learning_rate": 7.222222222222222e-06,
      "loss": 0.0023,
      "step": 15400
    },
    {
      "epoch": 1.712222222222222,
      "grad_norm": 0.40423455834388733,
      "learning_rate": 7.194444444444445e-06,
      "loss": 0.0013,
      "step": 15410
    },
    {
      "epoch": 1.7133333333333334,
      "grad_norm": 0.2716628313064575,
      "learning_rate": 7.166666666666667e-06,
      "loss": 0.0024,
      "step": 15420
    },
    {
      "epoch": 1.7144444444444444,
      "grad_norm": 0.3171285390853882,
      "learning_rate": 7.13888888888889e-06,
      "loss": 0.0018,
      "step": 15430
    },
    {
      "epoch": 1.7155555555555555,
      "grad_norm": 0.5455465316772461,
      "learning_rate": 7.111111111111112e-06,
      "loss": 0.0031,
      "step": 15440
    },
    {
      "epoch": 1.7166666666666668,
      "grad_norm": 0.4855049252510071,
      "learning_rate": 7.083333333333334e-06,
      "loss": 0.0031,
      "step": 15450
    },
    {
      "epoch": 1.7177777777777776,
      "grad_norm": 0.17765100300312042,
      "learning_rate": 7.055555555555556e-06,
      "loss": 0.0028,
      "step": 15460
    },
    {
      "epoch": 1.718888888888889,
      "grad_norm": 0.6015178561210632,
      "learning_rate": 7.027777777777778e-06,
      "loss": 0.0014,
      "step": 15470
    },
    {
      "epoch": 1.72,
      "grad_norm": 0.4042428731918335,
      "learning_rate": 7.000000000000001e-06,
      "loss": 0.0033,
      "step": 15480
    },
    {
      "epoch": 1.721111111111111,
      "grad_norm": 0.4125613570213318,
      "learning_rate": 6.972222222222223e-06,
      "loss": 0.0034,
      "step": 15490
    },
    {
      "epoch": 1.7222222222222223,
      "grad_norm": 0.29986751079559326,
      "learning_rate": 6.944444444444445e-06,
      "loss": 0.0032,
      "step": 15500
    },
    {
      "epoch": 1.7233333333333334,
      "grad_norm": 0.9115161299705505,
      "learning_rate": 6.916666666666667e-06,
      "loss": 0.0025,
      "step": 15510
    },
    {
      "epoch": 1.7244444444444444,
      "grad_norm": 0.5264206528663635,
      "learning_rate": 6.888888888888889e-06,
      "loss": 0.0012,
      "step": 15520
    },
    {
      "epoch": 1.7255555555555555,
      "grad_norm": 0.3862886130809784,
      "learning_rate": 6.861111111111111e-06,
      "loss": 0.0017,
      "step": 15530
    },
    {
      "epoch": 1.7266666666666666,
      "grad_norm": 1.2800629138946533,
      "learning_rate": 6.833333333333333e-06,
      "loss": 0.0007,
      "step": 15540
    },
    {
      "epoch": 1.7277777777777779,
      "grad_norm": 0.906322717666626,
      "learning_rate": 6.805555555555556e-06,
      "loss": 0.0017,
      "step": 15550
    },
    {
      "epoch": 1.728888888888889,
      "grad_norm": 0.20227231085300446,
      "learning_rate": 6.777777777777779e-06,
      "loss": 0.0032,
      "step": 15560
    },
    {
      "epoch": 1.73,
      "grad_norm": 0.27032342553138733,
      "learning_rate": 6.750000000000001e-06,
      "loss": 0.0022,
      "step": 15570
    },
    {
      "epoch": 1.7311111111111113,
      "grad_norm": 0.38377320766448975,
      "learning_rate": 6.722222222222223e-06,
      "loss": 0.0012,
      "step": 15580
    },
    {
      "epoch": 1.732222222222222,
      "grad_norm": 0.2649197578430176,
      "learning_rate": 6.694444444444445e-06,
      "loss": 0.0026,
      "step": 15590
    },
    {
      "epoch": 1.7333333333333334,
      "grad_norm": 0.5698938965797424,
      "learning_rate": 6.666666666666667e-06,
      "loss": 0.0013,
      "step": 15600
    },
    {
      "epoch": 1.7344444444444445,
      "grad_norm": 0.5408680438995361,
      "learning_rate": 6.638888888888889e-06,
      "loss": 0.0023,
      "step": 15610
    },
    {
      "epoch": 1.7355555555555555,
      "grad_norm": 0.5291547179222107,
      "learning_rate": 6.611111111111111e-06,
      "loss": 0.0023,
      "step": 15620
    },
    {
      "epoch": 1.7366666666666668,
      "grad_norm": 0.4551160931587219,
      "learning_rate": 6.583333333333333e-06,
      "loss": 0.0022,
      "step": 15630
    },
    {
      "epoch": 1.7377777777777776,
      "grad_norm": 0.29656511545181274,
      "learning_rate": 6.555555555555556e-06,
      "loss": 0.0025,
      "step": 15640
    },
    {
      "epoch": 1.738888888888889,
      "grad_norm": 1.071432113647461,
      "learning_rate": 6.5277777777777784e-06,
      "loss": 0.0031,
      "step": 15650
    },
    {
      "epoch": 1.74,
      "grad_norm": 0.20284859836101532,
      "learning_rate": 6.5000000000000004e-06,
      "loss": 0.0012,
      "step": 15660
    },
    {
      "epoch": 1.741111111111111,
      "grad_norm": 0.4394410252571106,
      "learning_rate": 6.4722222222222225e-06,
      "loss": 0.0025,
      "step": 15670
    },
    {
      "epoch": 1.7422222222222223,
      "grad_norm": 1.114891529083252,
      "learning_rate": 6.4444444444444445e-06,
      "loss": 0.0021,
      "step": 15680
    },
    {
      "epoch": 1.7433333333333332,
      "grad_norm": 0.27093979716300964,
      "learning_rate": 6.4166666666666665e-06,
      "loss": 0.0021,
      "step": 15690
    },
    {
      "epoch": 1.7444444444444445,
      "grad_norm": 0.8775978088378906,
      "learning_rate": 6.3888888888888885e-06,
      "loss": 0.0017,
      "step": 15700
    },
    {
      "epoch": 1.7455555555555555,
      "grad_norm": 0.44018739461898804,
      "learning_rate": 6.3611111111111105e-06,
      "loss": 0.0035,
      "step": 15710
    },
    {
      "epoch": 1.7466666666666666,
      "grad_norm": 0.30558934807777405,
      "learning_rate": 6.333333333333334e-06,
      "loss": 0.0017,
      "step": 15720
    },
    {
      "epoch": 1.7477777777777779,
      "grad_norm": 0.6497005224227905,
      "learning_rate": 6.305555555555556e-06,
      "loss": 0.0016,
      "step": 15730
    },
    {
      "epoch": 1.748888888888889,
      "grad_norm": 0.5298800468444824,
      "learning_rate": 6.277777777777778e-06,
      "loss": 0.0016,
      "step": 15740
    },
    {
      "epoch": 1.75,
      "grad_norm": 0.6635417938232422,
      "learning_rate": 6.25e-06,
      "loss": 0.0018,
      "step": 15750
    },
    {
      "epoch": 1.751111111111111,
      "grad_norm": 0.7149456143379211,
      "learning_rate": 6.222222222222222e-06,
      "loss": 0.0012,
      "step": 15760
    },
    {
      "epoch": 1.7522222222222221,
      "grad_norm": 0.24641238152980804,
      "learning_rate": 6.194444444444445e-06,
      "loss": 0.0031,
      "step": 15770
    },
    {
      "epoch": 1.7533333333333334,
      "grad_norm": 0.7639614343643188,
      "learning_rate": 6.166666666666667e-06,
      "loss": 0.0019,
      "step": 15780
    },
    {
      "epoch": 1.7544444444444445,
      "grad_norm": 0.19853663444519043,
      "learning_rate": 6.138888888888889e-06,
      "loss": 0.0026,
      "step": 15790
    },
    {
      "epoch": 1.7555555555555555,
      "grad_norm": 0.4557218849658966,
      "learning_rate": 6.111111111111111e-06,
      "loss": 0.0025,
      "step": 15800
    },
    {
      "epoch": 1.7566666666666668,
      "grad_norm": 0.3897673189640045,
      "learning_rate": 6.083333333333334e-06,
      "loss": 0.002,
      "step": 15810
    },
    {
      "epoch": 1.7577777777777777,
      "grad_norm": 1.291654109954834,
      "learning_rate": 6.055555555555556e-06,
      "loss": 0.003,
      "step": 15820
    },
    {
      "epoch": 1.758888888888889,
      "grad_norm": 0.47262969613075256,
      "learning_rate": 6.027777777777778e-06,
      "loss": 0.0034,
      "step": 15830
    },
    {
      "epoch": 1.76,
      "grad_norm": 0.3808540105819702,
      "learning_rate": 6e-06,
      "loss": 0.0017,
      "step": 15840
    },
    {
      "epoch": 1.761111111111111,
      "grad_norm": 0.8038859367370605,
      "learning_rate": 5.972222222222223e-06,
      "loss": 0.0008,
      "step": 15850
    },
    {
      "epoch": 1.7622222222222224,
      "grad_norm": 0.30164849758148193,
      "learning_rate": 5.944444444444445e-06,
      "loss": 0.0021,
      "step": 15860
    },
    {
      "epoch": 1.7633333333333332,
      "grad_norm": 0.43840157985687256,
      "learning_rate": 5.916666666666667e-06,
      "loss": 0.0027,
      "step": 15870
    },
    {
      "epoch": 1.7644444444444445,
      "grad_norm": 0.6842778921127319,
      "learning_rate": 5.888888888888889e-06,
      "loss": 0.0016,
      "step": 15880
    },
    {
      "epoch": 1.7655555555555555,
      "grad_norm": 0.4245891869068146,
      "learning_rate": 5.861111111111112e-06,
      "loss": 0.0027,
      "step": 15890
    },
    {
      "epoch": 1.7666666666666666,
      "grad_norm": 1.1052711009979248,
      "learning_rate": 5.833333333333334e-06,
      "loss": 0.0025,
      "step": 15900
    },
    {
      "epoch": 1.767777777777778,
      "grad_norm": 0.3440837264060974,
      "learning_rate": 5.805555555555556e-06,
      "loss": 0.0025,
      "step": 15910
    },
    {
      "epoch": 1.7688888888888887,
      "grad_norm": 0.7036147713661194,
      "learning_rate": 5.777777777777778e-06,
      "loss": 0.0036,
      "step": 15920
    },
    {
      "epoch": 1.77,
      "grad_norm": 0.4146295189857483,
      "learning_rate": 5.750000000000001e-06,
      "loss": 0.0035,
      "step": 15930
    },
    {
      "epoch": 1.771111111111111,
      "grad_norm": 0.4855811297893524,
      "learning_rate": 5.722222222222223e-06,
      "loss": 0.004,
      "step": 15940
    },
    {
      "epoch": 1.7722222222222221,
      "grad_norm": 0.28327953815460205,
      "learning_rate": 5.694444444444445e-06,
      "loss": 0.0018,
      "step": 15950
    },
    {
      "epoch": 1.7733333333333334,
      "grad_norm": 0.263367623090744,
      "learning_rate": 5.666666666666667e-06,
      "loss": 0.0017,
      "step": 15960
    },
    {
      "epoch": 1.7744444444444445,
      "grad_norm": 0.2425830066204071,
      "learning_rate": 5.63888888888889e-06,
      "loss": 0.0027,
      "step": 15970
    },
    {
      "epoch": 1.7755555555555556,
      "grad_norm": 0.27807679772377014,
      "learning_rate": 5.611111111111112e-06,
      "loss": 0.0022,
      "step": 15980
    },
    {
      "epoch": 1.7766666666666666,
      "grad_norm": 0.5425857901573181,
      "learning_rate": 5.583333333333334e-06,
      "loss": 0.0023,
      "step": 15990
    },
    {
      "epoch": 1.7777777777777777,
      "grad_norm": 0.2966984510421753,
      "learning_rate": 5.555555555555556e-06,
      "loss": 0.0038,
      "step": 16000
    },
    {
      "epoch": 1.778888888888889,
      "grad_norm": 0.49159902334213257,
      "learning_rate": 5.527777777777778e-06,
      "loss": 0.0027,
      "step": 16010
    },
    {
      "epoch": 1.78,
      "grad_norm": 0.8110247254371643,
      "learning_rate": 5.500000000000001e-06,
      "loss": 0.0035,
      "step": 16020
    },
    {
      "epoch": 1.781111111111111,
      "grad_norm": 0.5972563624382019,
      "learning_rate": 5.472222222222223e-06,
      "loss": 0.0034,
      "step": 16030
    },
    {
      "epoch": 1.7822222222222224,
      "grad_norm": 0.22965209186077118,
      "learning_rate": 5.444444444444445e-06,
      "loss": 0.0024,
      "step": 16040
    },
    {
      "epoch": 1.7833333333333332,
      "grad_norm": 0.307145893573761,
      "learning_rate": 5.416666666666667e-06,
      "loss": 0.0026,
      "step": 16050
    },
    {
      "epoch": 1.7844444444444445,
      "grad_norm": 0.15148726105690002,
      "learning_rate": 5.388888888888889e-06,
      "loss": 0.0013,
      "step": 16060
    },
    {
      "epoch": 1.7855555555555556,
      "grad_norm": 0.346400648355484,
      "learning_rate": 5.361111111111111e-06,
      "loss": 0.003,
      "step": 16070
    },
    {
      "epoch": 1.7866666666666666,
      "grad_norm": 0.7857241630554199,
      "learning_rate": 5.333333333333334e-06,
      "loss": 0.0023,
      "step": 16080
    },
    {
      "epoch": 1.787777777777778,
      "grad_norm": 0.869484007358551,
      "learning_rate": 5.305555555555556e-06,
      "loss": 0.0015,
      "step": 16090
    },
    {
      "epoch": 1.7888888888888888,
      "grad_norm": 0.44168439507484436,
      "learning_rate": 5.277777777777778e-06,
      "loss": 0.0016,
      "step": 16100
    },
    {
      "epoch": 1.79,
      "grad_norm": 0.6723362803459167,
      "learning_rate": 5.25e-06,
      "loss": 0.0029,
      "step": 16110
    },
    {
      "epoch": 1.791111111111111,
      "grad_norm": 0.4600897431373596,
      "learning_rate": 5.2222222222222226e-06,
      "loss": 0.0019,
      "step": 16120
    },
    {
      "epoch": 1.7922222222222222,
      "grad_norm": 0.960418701171875,
      "learning_rate": 5.194444444444445e-06,
      "loss": 0.0026,
      "step": 16130
    },
    {
      "epoch": 1.7933333333333334,
      "grad_norm": 0.6635540127754211,
      "learning_rate": 5.166666666666667e-06,
      "loss": 0.0023,
      "step": 16140
    },
    {
      "epoch": 1.7944444444444443,
      "grad_norm": 0.2972864508628845,
      "learning_rate": 5.138888888888889e-06,
      "loss": 0.003,
      "step": 16150
    },
    {
      "epoch": 1.7955555555555556,
      "grad_norm": 0.2669748067855835,
      "learning_rate": 5.1111111111111115e-06,
      "loss": 0.0022,
      "step": 16160
    },
    {
      "epoch": 1.7966666666666666,
      "grad_norm": 0.27123042941093445,
      "learning_rate": 5.0833333333333335e-06,
      "loss": 0.0024,
      "step": 16170
    },
    {
      "epoch": 1.7977777777777777,
      "grad_norm": 0.3615154027938843,
      "learning_rate": 5.0555555555555555e-06,
      "loss": 0.002,
      "step": 16180
    },
    {
      "epoch": 1.798888888888889,
      "grad_norm": 0.21823453903198242,
      "learning_rate": 5.0277777777777775e-06,
      "loss": 0.0009,
      "step": 16190
    },
    {
      "epoch": 1.8,
      "grad_norm": 0.10799463093280792,
      "learning_rate": 5e-06,
      "loss": 0.0025,
      "step": 16200
    },
    {
      "epoch": 1.801111111111111,
      "grad_norm": 0.7292820811271667,
      "learning_rate": 4.9722222222222224e-06,
      "loss": 0.0017,
      "step": 16210
    },
    {
      "epoch": 1.8022222222222222,
      "grad_norm": 0.20322681963443756,
      "learning_rate": 4.9444444444444444e-06,
      "loss": 0.0019,
      "step": 16220
    },
    {
      "epoch": 1.8033333333333332,
      "grad_norm": 0.7086018323898315,
      "learning_rate": 4.9166666666666665e-06,
      "loss": 0.0013,
      "step": 16230
    },
    {
      "epoch": 1.8044444444444445,
      "grad_norm": 0.15163663029670715,
      "learning_rate": 4.888888888888889e-06,
      "loss": 0.0021,
      "step": 16240
    },
    {
      "epoch": 1.8055555555555556,
      "grad_norm": 0.3313368260860443,
      "learning_rate": 4.861111111111111e-06,
      "loss": 0.0011,
      "step": 16250
    },
    {
      "epoch": 1.8066666666666666,
      "grad_norm": 0.49003854393959045,
      "learning_rate": 4.833333333333333e-06,
      "loss": 0.003,
      "step": 16260
    },
    {
      "epoch": 1.807777777777778,
      "grad_norm": 0.2697077989578247,
      "learning_rate": 4.805555555555555e-06,
      "loss": 0.003,
      "step": 16270
    },
    {
      "epoch": 1.8088888888888888,
      "grad_norm": 0.2296627312898636,
      "learning_rate": 4.777777777777778e-06,
      "loss": 0.0027,
      "step": 16280
    },
    {
      "epoch": 1.81,
      "grad_norm": 0.3245994448661804,
      "learning_rate": 4.75e-06,
      "loss": 0.0033,
      "step": 16290
    },
    {
      "epoch": 1.8111111111111111,
      "grad_norm": 0.9581416845321655,
      "learning_rate": 4.722222222222222e-06,
      "loss": 0.0029,
      "step": 16300
    },
    {
      "epoch": 1.8122222222222222,
      "grad_norm": 0.19815899431705475,
      "learning_rate": 4.694444444444444e-06,
      "loss": 0.0014,
      "step": 16310
    },
    {
      "epoch": 1.8133333333333335,
      "grad_norm": 0.1452503800392151,
      "learning_rate": 4.666666666666667e-06,
      "loss": 0.0026,
      "step": 16320
    },
    {
      "epoch": 1.8144444444444443,
      "grad_norm": 0.458631694316864,
      "learning_rate": 4.638888888888889e-06,
      "loss": 0.0025,
      "step": 16330
    },
    {
      "epoch": 1.8155555555555556,
      "grad_norm": 0.38911113142967224,
      "learning_rate": 4.611111111111111e-06,
      "loss": 0.0027,
      "step": 16340
    },
    {
      "epoch": 1.8166666666666667,
      "grad_norm": 0.7188231945037842,
      "learning_rate": 4.583333333333333e-06,
      "loss": 0.0013,
      "step": 16350
    },
    {
      "epoch": 1.8177777777777777,
      "grad_norm": 0.4633062481880188,
      "learning_rate": 4.555555555555556e-06,
      "loss": 0.0018,
      "step": 16360
    },
    {
      "epoch": 1.818888888888889,
      "grad_norm": 0.6238868236541748,
      "learning_rate": 4.527777777777778e-06,
      "loss": 0.0017,
      "step": 16370
    },
    {
      "epoch": 1.8199999999999998,
      "grad_norm": 0.5123087763786316,
      "learning_rate": 4.5e-06,
      "loss": 0.0018,
      "step": 16380
    },
    {
      "epoch": 1.8211111111111111,
      "grad_norm": 0.1383524090051651,
      "learning_rate": 4.472222222222222e-06,
      "loss": 0.002,
      "step": 16390
    },
    {
      "epoch": 1.8222222222222222,
      "grad_norm": 0.14617808163166046,
      "learning_rate": 4.444444444444445e-06,
      "loss": 0.0026,
      "step": 16400
    },
    {
      "epoch": 1.8233333333333333,
      "grad_norm": 0.30549323558807373,
      "learning_rate": 4.416666666666667e-06,
      "loss": 0.0022,
      "step": 16410
    },
    {
      "epoch": 1.8244444444444445,
      "grad_norm": 0.3349529206752777,
      "learning_rate": 4.388888888888889e-06,
      "loss": 0.0025,
      "step": 16420
    },
    {
      "epoch": 1.8255555555555556,
      "grad_norm": 0.27810972929000854,
      "learning_rate": 4.361111111111112e-06,
      "loss": 0.0039,
      "step": 16430
    },
    {
      "epoch": 1.8266666666666667,
      "grad_norm": 0.3152710795402527,
      "learning_rate": 4.333333333333334e-06,
      "loss": 0.0015,
      "step": 16440
    },
    {
      "epoch": 1.8277777777777777,
      "grad_norm": 0.26407429575920105,
      "learning_rate": 4.305555555555556e-06,
      "loss": 0.0018,
      "step": 16450
    },
    {
      "epoch": 1.8288888888888888,
      "grad_norm": 0.7270357608795166,
      "learning_rate": 4.277777777777778e-06,
      "loss": 0.0022,
      "step": 16460
    },
    {
      "epoch": 1.83,
      "grad_norm": 1.0660430192947388,
      "learning_rate": 4.250000000000001e-06,
      "loss": 0.002,
      "step": 16470
    },
    {
      "epoch": 1.8311111111111111,
      "grad_norm": 0.4486388862133026,
      "learning_rate": 4.222222222222223e-06,
      "loss": 0.0014,
      "step": 16480
    },
    {
      "epoch": 1.8322222222222222,
      "grad_norm": 0.4910155236721039,
      "learning_rate": 4.194444444444445e-06,
      "loss": 0.0015,
      "step": 16490
    },
    {
      "epoch": 1.8333333333333335,
      "grad_norm": 0.2833501696586609,
      "learning_rate": 4.166666666666667e-06,
      "loss": 0.0035,
      "step": 16500
    },
    {
      "epoch": 1.8344444444444443,
      "grad_norm": 0.36134645342826843,
      "learning_rate": 4.13888888888889e-06,
      "loss": 0.0022,
      "step": 16510
    },
    {
      "epoch": 1.8355555555555556,
      "grad_norm": 0.7911608815193176,
      "learning_rate": 4.111111111111112e-06,
      "loss": 0.0024,
      "step": 16520
    },
    {
      "epoch": 1.8366666666666667,
      "grad_norm": 0.5734459757804871,
      "learning_rate": 4.083333333333334e-06,
      "loss": 0.0028,
      "step": 16530
    },
    {
      "epoch": 1.8377777777777777,
      "grad_norm": 0.26969361305236816,
      "learning_rate": 4.055555555555556e-06,
      "loss": 0.0031,
      "step": 16540
    },
    {
      "epoch": 1.838888888888889,
      "grad_norm": 0.7437275648117065,
      "learning_rate": 4.027777777777779e-06,
      "loss": 0.0021,
      "step": 16550
    },
    {
      "epoch": 1.8399999999999999,
      "grad_norm": 0.34509921073913574,
      "learning_rate": 4.000000000000001e-06,
      "loss": 0.0034,
      "step": 16560
    },
    {
      "epoch": 1.8411111111111111,
      "grad_norm": 0.7477442026138306,
      "learning_rate": 3.972222222222223e-06,
      "loss": 0.0031,
      "step": 16570
    },
    {
      "epoch": 1.8422222222222222,
      "grad_norm": 0.4712662696838379,
      "learning_rate": 3.944444444444445e-06,
      "loss": 0.0019,
      "step": 16580
    },
    {
      "epoch": 1.8433333333333333,
      "grad_norm": 0.5338204503059387,
      "learning_rate": 3.916666666666667e-06,
      "loss": 0.0018,
      "step": 16590
    },
    {
      "epoch": 1.8444444444444446,
      "grad_norm": 0.5123492479324341,
      "learning_rate": 3.888888888888889e-06,
      "loss": 0.0037,
      "step": 16600
    },
    {
      "epoch": 1.8455555555555554,
      "grad_norm": 0.4961800277233124,
      "learning_rate": 3.861111111111112e-06,
      "loss": 0.0015,
      "step": 16610
    },
    {
      "epoch": 1.8466666666666667,
      "grad_norm": 0.39829331636428833,
      "learning_rate": 3.833333333333334e-06,
      "loss": 0.0018,
      "step": 16620
    },
    {
      "epoch": 1.8477777777777777,
      "grad_norm": 0.9413049817085266,
      "learning_rate": 3.805555555555556e-06,
      "loss": 0.0019,
      "step": 16630
    },
    {
      "epoch": 1.8488888888888888,
      "grad_norm": 0.45871856808662415,
      "learning_rate": 3.777777777777778e-06,
      "loss": 0.0016,
      "step": 16640
    },
    {
      "epoch": 1.85,
      "grad_norm": 0.468048632144928,
      "learning_rate": 3.75e-06,
      "loss": 0.0023,
      "step": 16650
    },
    {
      "epoch": 1.8511111111111112,
      "grad_norm": 0.5334010124206543,
      "learning_rate": 3.722222222222222e-06,
      "loss": 0.0029,
      "step": 16660
    },
    {
      "epoch": 1.8522222222222222,
      "grad_norm": 0.3661935329437256,
      "learning_rate": 3.694444444444445e-06,
      "loss": 0.0025,
      "step": 16670
    },
    {
      "epoch": 1.8533333333333335,
      "grad_norm": 0.56401526927948,
      "learning_rate": 3.666666666666667e-06,
      "loss": 0.0019,
      "step": 16680
    },
    {
      "epoch": 1.8544444444444443,
      "grad_norm": 0.39608752727508545,
      "learning_rate": 3.638888888888889e-06,
      "loss": 0.0024,
      "step": 16690
    },
    {
      "epoch": 1.8555555555555556,
      "grad_norm": 0.2924528419971466,
      "learning_rate": 3.611111111111111e-06,
      "loss": 0.0024,
      "step": 16700
    },
    {
      "epoch": 1.8566666666666667,
      "grad_norm": 1.191626787185669,
      "learning_rate": 3.5833333333333335e-06,
      "loss": 0.003,
      "step": 16710
    },
    {
      "epoch": 1.8577777777777778,
      "grad_norm": 0.1796972006559372,
      "learning_rate": 3.555555555555556e-06,
      "loss": 0.0019,
      "step": 16720
    },
    {
      "epoch": 1.858888888888889,
      "grad_norm": 0.9587514996528625,
      "learning_rate": 3.527777777777778e-06,
      "loss": 0.0028,
      "step": 16730
    },
    {
      "epoch": 1.8599999999999999,
      "grad_norm": 0.2698626220226288,
      "learning_rate": 3.5000000000000004e-06,
      "loss": 0.0028,
      "step": 16740
    },
    {
      "epoch": 1.8611111111111112,
      "grad_norm": 0.15969504415988922,
      "learning_rate": 3.4722222222222224e-06,
      "loss": 0.0022,
      "step": 16750
    },
    {
      "epoch": 1.8622222222222222,
      "grad_norm": 0.19337759912014008,
      "learning_rate": 3.4444444444444444e-06,
      "loss": 0.0014,
      "step": 16760
    },
    {
      "epoch": 1.8633333333333333,
      "grad_norm": 0.37435153126716614,
      "learning_rate": 3.4166666666666664e-06,
      "loss": 0.0026,
      "step": 16770
    },
    {
      "epoch": 1.8644444444444446,
      "grad_norm": 0.637656033039093,
      "learning_rate": 3.3888888888888893e-06,
      "loss": 0.0031,
      "step": 16780
    },
    {
      "epoch": 1.8655555555555554,
      "grad_norm": 0.7265974283218384,
      "learning_rate": 3.3611111111111113e-06,
      "loss": 0.0027,
      "step": 16790
    },
    {
      "epoch": 1.8666666666666667,
      "grad_norm": 0.6577197909355164,
      "learning_rate": 3.3333333333333333e-06,
      "loss": 0.0034,
      "step": 16800
    },
    {
      "epoch": 1.8677777777777778,
      "grad_norm": 0.3989836871623993,
      "learning_rate": 3.3055555555555553e-06,
      "loss": 0.0032,
      "step": 16810
    },
    {
      "epoch": 1.8688888888888888,
      "grad_norm": 0.5966213345527649,
      "learning_rate": 3.277777777777778e-06,
      "loss": 0.0017,
      "step": 16820
    },
    {
      "epoch": 1.87,
      "grad_norm": 0.409417062997818,
      "learning_rate": 3.2500000000000002e-06,
      "loss": 0.0033,
      "step": 16830
    },
    {
      "epoch": 1.871111111111111,
      "grad_norm": 0.312898725271225,
      "learning_rate": 3.2222222222222222e-06,
      "loss": 0.0017,
      "step": 16840
    },
    {
      "epoch": 1.8722222222222222,
      "grad_norm": 0.7798598408699036,
      "learning_rate": 3.1944444444444443e-06,
      "loss": 0.0019,
      "step": 16850
    },
    {
      "epoch": 1.8733333333333333,
      "grad_norm": 0.7437363862991333,
      "learning_rate": 3.166666666666667e-06,
      "loss": 0.0017,
      "step": 16860
    },
    {
      "epoch": 1.8744444444444444,
      "grad_norm": 0.33563852310180664,
      "learning_rate": 3.138888888888889e-06,
      "loss": 0.0023,
      "step": 16870
    },
    {
      "epoch": 1.8755555555555556,
      "grad_norm": 0.27109891176223755,
      "learning_rate": 3.111111111111111e-06,
      "loss": 0.0027,
      "step": 16880
    },
    {
      "epoch": 1.8766666666666667,
      "grad_norm": 0.23800690472126007,
      "learning_rate": 3.0833333333333336e-06,
      "loss": 0.0025,
      "step": 16890
    },
    {
      "epoch": 1.8777777777777778,
      "grad_norm": 0.5625856518745422,
      "learning_rate": 3.0555555555555556e-06,
      "loss": 0.0024,
      "step": 16900
    },
    {
      "epoch": 1.878888888888889,
      "grad_norm": 0.5582743287086487,
      "learning_rate": 3.027777777777778e-06,
      "loss": 0.0018,
      "step": 16910
    },
    {
      "epoch": 1.88,
      "grad_norm": 0.5875440835952759,
      "learning_rate": 3e-06,
      "loss": 0.0023,
      "step": 16920
    },
    {
      "epoch": 1.8811111111111112,
      "grad_norm": 0.4105493128299713,
      "learning_rate": 2.9722222222222225e-06,
      "loss": 0.0029,
      "step": 16930
    },
    {
      "epoch": 1.8822222222222222,
      "grad_norm": 0.279805451631546,
      "learning_rate": 2.9444444444444445e-06,
      "loss": 0.0016,
      "step": 16940
    },
    {
      "epoch": 1.8833333333333333,
      "grad_norm": 0.6285015940666199,
      "learning_rate": 2.916666666666667e-06,
      "loss": 0.0023,
      "step": 16950
    },
    {
      "epoch": 1.8844444444444446,
      "grad_norm": 0.5321731567382812,
      "learning_rate": 2.888888888888889e-06,
      "loss": 0.0035,
      "step": 16960
    },
    {
      "epoch": 1.8855555555555554,
      "grad_norm": 0.3683848977088928,
      "learning_rate": 2.8611111111111114e-06,
      "loss": 0.0022,
      "step": 16970
    },
    {
      "epoch": 1.8866666666666667,
      "grad_norm": 0.5182863473892212,
      "learning_rate": 2.8333333333333335e-06,
      "loss": 0.002,
      "step": 16980
    },
    {
      "epoch": 1.8877777777777778,
      "grad_norm": 0.188028946518898,
      "learning_rate": 2.805555555555556e-06,
      "loss": 0.0032,
      "step": 16990
    },
    {
      "epoch": 1.8888888888888888,
      "grad_norm": 0.49626368284225464,
      "learning_rate": 2.777777777777778e-06,
      "loss": 0.0021,
      "step": 17000
    },
    {
      "epoch": 1.8900000000000001,
      "grad_norm": 0.1974266767501831,
      "learning_rate": 2.7500000000000004e-06,
      "loss": 0.0022,
      "step": 17010
    },
    {
      "epoch": 1.891111111111111,
      "grad_norm": 0.34979718923568726,
      "learning_rate": 2.7222222222222224e-06,
      "loss": 0.0026,
      "step": 17020
    },
    {
      "epoch": 1.8922222222222222,
      "grad_norm": 0.20323283970355988,
      "learning_rate": 2.6944444444444444e-06,
      "loss": 0.0034,
      "step": 17030
    },
    {
      "epoch": 1.8933333333333333,
      "grad_norm": 0.3391413390636444,
      "learning_rate": 2.666666666666667e-06,
      "loss": 0.003,
      "step": 17040
    },
    {
      "epoch": 1.8944444444444444,
      "grad_norm": 0.15369965136051178,
      "learning_rate": 2.638888888888889e-06,
      "loss": 0.0029,
      "step": 17050
    },
    {
      "epoch": 1.8955555555555557,
      "grad_norm": 0.2067296802997589,
      "learning_rate": 2.6111111111111113e-06,
      "loss": 0.0028,
      "step": 17060
    },
    {
      "epoch": 1.8966666666666665,
      "grad_norm": 0.49020156264305115,
      "learning_rate": 2.5833333333333333e-06,
      "loss": 0.0031,
      "step": 17070
    },
    {
      "epoch": 1.8977777777777778,
      "grad_norm": 0.1708267331123352,
      "learning_rate": 2.5555555555555557e-06,
      "loss": 0.0028,
      "step": 17080
    },
    {
      "epoch": 1.8988888888888888,
      "grad_norm": 0.46583080291748047,
      "learning_rate": 2.5277777777777778e-06,
      "loss": 0.0032,
      "step": 17090
    },
    {
      "epoch": 1.9,
      "grad_norm": 0.424832284450531,
      "learning_rate": 2.5e-06,
      "loss": 0.0013,
      "step": 17100
    },
    {
      "epoch": 1.9011111111111112,
      "grad_norm": 0.3290906846523285,
      "learning_rate": 2.4722222222222222e-06,
      "loss": 0.0024,
      "step": 17110
    },
    {
      "epoch": 1.9022222222222223,
      "grad_norm": 0.28293171525001526,
      "learning_rate": 2.4444444444444447e-06,
      "loss": 0.0026,
      "step": 17120
    },
    {
      "epoch": 1.9033333333333333,
      "grad_norm": 0.276562362909317,
      "learning_rate": 2.4166666666666667e-06,
      "loss": 0.0034,
      "step": 17130
    },
    {
      "epoch": 1.9044444444444446,
      "grad_norm": 0.44975653290748596,
      "learning_rate": 2.388888888888889e-06,
      "loss": 0.0009,
      "step": 17140
    },
    {
      "epoch": 1.9055555555555554,
      "grad_norm": 0.12088882923126221,
      "learning_rate": 2.361111111111111e-06,
      "loss": 0.0023,
      "step": 17150
    },
    {
      "epoch": 1.9066666666666667,
      "grad_norm": 0.5212171077728271,
      "learning_rate": 2.3333333333333336e-06,
      "loss": 0.0015,
      "step": 17160
    },
    {
      "epoch": 1.9077777777777778,
      "grad_norm": 0.3464483618736267,
      "learning_rate": 2.3055555555555556e-06,
      "loss": 0.0024,
      "step": 17170
    },
    {
      "epoch": 1.9088888888888889,
      "grad_norm": 0.48539936542510986,
      "learning_rate": 2.277777777777778e-06,
      "loss": 0.001,
      "step": 17180
    },
    {
      "epoch": 1.9100000000000001,
      "grad_norm": 0.19059036672115326,
      "learning_rate": 2.25e-06,
      "loss": 0.0021,
      "step": 17190
    },
    {
      "epoch": 1.911111111111111,
      "grad_norm": 0.41392090916633606,
      "learning_rate": 2.2222222222222225e-06,
      "loss": 0.0024,
      "step": 17200
    },
    {
      "epoch": 1.9122222222222223,
      "grad_norm": 0.3211159110069275,
      "learning_rate": 2.1944444444444445e-06,
      "loss": 0.0013,
      "step": 17210
    },
    {
      "epoch": 1.9133333333333333,
      "grad_norm": 0.33048921823501587,
      "learning_rate": 2.166666666666667e-06,
      "loss": 0.0019,
      "step": 17220
    },
    {
      "epoch": 1.9144444444444444,
      "grad_norm": 0.4314902126789093,
      "learning_rate": 2.138888888888889e-06,
      "loss": 0.003,
      "step": 17230
    },
    {
      "epoch": 1.9155555555555557,
      "grad_norm": 0.41198065876960754,
      "learning_rate": 2.1111111111111114e-06,
      "loss": 0.0028,
      "step": 17240
    },
    {
      "epoch": 1.9166666666666665,
      "grad_norm": 0.5112873911857605,
      "learning_rate": 2.0833333333333334e-06,
      "loss": 0.002,
      "step": 17250
    },
    {
      "epoch": 1.9177777777777778,
      "grad_norm": 0.5442096590995789,
      "learning_rate": 2.055555555555556e-06,
      "loss": 0.0019,
      "step": 17260
    },
    {
      "epoch": 1.9188888888888889,
      "grad_norm": 1.34091317653656,
      "learning_rate": 2.027777777777778e-06,
      "loss": 0.0024,
      "step": 17270
    },
    {
      "epoch": 1.92,
      "grad_norm": 0.38654249906539917,
      "learning_rate": 2.0000000000000003e-06,
      "loss": 0.0042,
      "step": 17280
    },
    {
      "epoch": 1.9211111111111112,
      "grad_norm": 0.6559975147247314,
      "learning_rate": 1.9722222222222224e-06,
      "loss": 0.0021,
      "step": 17290
    },
    {
      "epoch": 1.9222222222222223,
      "grad_norm": 0.19332405924797058,
      "learning_rate": 1.9444444444444444e-06,
      "loss": 0.0019,
      "step": 17300
    },
    {
      "epoch": 1.9233333333333333,
      "grad_norm": 0.6259360909461975,
      "learning_rate": 1.916666666666667e-06,
      "loss": 0.0031,
      "step": 17310
    },
    {
      "epoch": 1.9244444444444444,
      "grad_norm": 0.8756705522537231,
      "learning_rate": 1.888888888888889e-06,
      "loss": 0.0013,
      "step": 17320
    },
    {
      "epoch": 1.9255555555555555,
      "grad_norm": 0.36224761605262756,
      "learning_rate": 1.861111111111111e-06,
      "loss": 0.0032,
      "step": 17330
    },
    {
      "epoch": 1.9266666666666667,
      "grad_norm": 0.35104236006736755,
      "learning_rate": 1.8333333333333335e-06,
      "loss": 0.0012,
      "step": 17340
    },
    {
      "epoch": 1.9277777777777778,
      "grad_norm": 0.3236118257045746,
      "learning_rate": 1.8055555555555555e-06,
      "loss": 0.0036,
      "step": 17350
    },
    {
      "epoch": 1.9288888888888889,
      "grad_norm": 0.18343906104564667,
      "learning_rate": 1.777777777777778e-06,
      "loss": 0.0021,
      "step": 17360
    },
    {
      "epoch": 1.9300000000000002,
      "grad_norm": 0.71523517370224,
      "learning_rate": 1.7500000000000002e-06,
      "loss": 0.0021,
      "step": 17370
    },
    {
      "epoch": 1.931111111111111,
      "grad_norm": 0.42516028881073,
      "learning_rate": 1.7222222222222222e-06,
      "loss": 0.0027,
      "step": 17380
    },
    {
      "epoch": 1.9322222222222223,
      "grad_norm": 0.883488118648529,
      "learning_rate": 1.6944444444444446e-06,
      "loss": 0.002,
      "step": 17390
    },
    {
      "epoch": 1.9333333333333333,
      "grad_norm": 0.492817759513855,
      "learning_rate": 1.6666666666666667e-06,
      "loss": 0.0027,
      "step": 17400
    },
    {
      "epoch": 1.9344444444444444,
      "grad_norm": 0.46203476190567017,
      "learning_rate": 1.638888888888889e-06,
      "loss": 0.0031,
      "step": 17410
    },
    {
      "epoch": 1.9355555555555557,
      "grad_norm": 0.20677302777767181,
      "learning_rate": 1.6111111111111111e-06,
      "loss": 0.0027,
      "step": 17420
    },
    {
      "epoch": 1.9366666666666665,
      "grad_norm": 0.16991250216960907,
      "learning_rate": 1.5833333333333336e-06,
      "loss": 0.0015,
      "step": 17430
    },
    {
      "epoch": 1.9377777777777778,
      "grad_norm": 0.28538283705711365,
      "learning_rate": 1.5555555555555556e-06,
      "loss": 0.0026,
      "step": 17440
    },
    {
      "epoch": 1.9388888888888889,
      "grad_norm": 0.49125826358795166,
      "learning_rate": 1.5277777777777778e-06,
      "loss": 0.0036,
      "step": 17450
    },
    {
      "epoch": 1.94,
      "grad_norm": 0.5098103880882263,
      "learning_rate": 1.5e-06,
      "loss": 0.0037,
      "step": 17460
    },
    {
      "epoch": 1.9411111111111112,
      "grad_norm": 0.7868731021881104,
      "learning_rate": 1.4722222222222223e-06,
      "loss": 0.0037,
      "step": 17470
    },
    {
      "epoch": 1.942222222222222,
      "grad_norm": 0.18227757513523102,
      "learning_rate": 1.4444444444444445e-06,
      "loss": 0.0042,
      "step": 17480
    },
    {
      "epoch": 1.9433333333333334,
      "grad_norm": 0.24078664183616638,
      "learning_rate": 1.4166666666666667e-06,
      "loss": 0.0026,
      "step": 17490
    },
    {
      "epoch": 1.9444444444444444,
      "grad_norm": 0.18012267351150513,
      "learning_rate": 1.388888888888889e-06,
      "loss": 0.0022,
      "step": 17500
    },
    {
      "epoch": 1.9455555555555555,
      "grad_norm": 0.586293637752533,
      "learning_rate": 1.3611111111111112e-06,
      "loss": 0.0015,
      "step": 17510
    },
    {
      "epoch": 1.9466666666666668,
      "grad_norm": 0.3575997054576874,
      "learning_rate": 1.3333333333333334e-06,
      "loss": 0.0026,
      "step": 17520
    },
    {
      "epoch": 1.9477777777777778,
      "grad_norm": 0.4153517484664917,
      "learning_rate": 1.3055555555555556e-06,
      "loss": 0.002,
      "step": 17530
    },
    {
      "epoch": 1.948888888888889,
      "grad_norm": 0.3108445703983307,
      "learning_rate": 1.2777777777777779e-06,
      "loss": 0.0014,
      "step": 17540
    },
    {
      "epoch": 1.95,
      "grad_norm": 0.22913305461406708,
      "learning_rate": 1.25e-06,
      "loss": 0.0028,
      "step": 17550
    },
    {
      "epoch": 1.951111111111111,
      "grad_norm": 0.5517066717147827,
      "learning_rate": 1.2222222222222223e-06,
      "loss": 0.0033,
      "step": 17560
    },
    {
      "epoch": 1.9522222222222223,
      "grad_norm": 0.2695887088775635,
      "learning_rate": 1.1944444444444446e-06,
      "loss": 0.0038,
      "step": 17570
    },
    {
      "epoch": 1.9533333333333334,
      "grad_norm": 0.39132726192474365,
      "learning_rate": 1.1666666666666668e-06,
      "loss": 0.0016,
      "step": 17580
    },
    {
      "epoch": 1.9544444444444444,
      "grad_norm": 0.13922066986560822,
      "learning_rate": 1.138888888888889e-06,
      "loss": 0.0017,
      "step": 17590
    },
    {
      "epoch": 1.9555555555555557,
      "grad_norm": 0.3817038834095001,
      "learning_rate": 1.1111111111111112e-06,
      "loss": 0.0017,
      "step": 17600
    },
    {
      "epoch": 1.9566666666666666,
      "grad_norm": 0.4389275908470154,
      "learning_rate": 1.0833333333333335e-06,
      "loss": 0.0026,
      "step": 17610
    },
    {
      "epoch": 1.9577777777777778,
      "grad_norm": 0.42147189378738403,
      "learning_rate": 1.0555555555555557e-06,
      "loss": 0.0016,
      "step": 17620
    },
    {
      "epoch": 1.958888888888889,
      "grad_norm": 0.7364291548728943,
      "learning_rate": 1.027777777777778e-06,
      "loss": 0.0022,
      "step": 17630
    },
    {
      "epoch": 1.96,
      "grad_norm": 0.11509072035551071,
      "learning_rate": 1.0000000000000002e-06,
      "loss": 0.0015,
      "step": 17640
    },
    {
      "epoch": 1.9611111111111112,
      "grad_norm": 0.3957689702510834,
      "learning_rate": 9.722222222222222e-07,
      "loss": 0.0015,
      "step": 17650
    },
    {
      "epoch": 1.962222222222222,
      "grad_norm": 0.3714418411254883,
      "learning_rate": 9.444444444444445e-07,
      "loss": 0.0026,
      "step": 17660
    },
    {
      "epoch": 1.9633333333333334,
      "grad_norm": 0.3293681740760803,
      "learning_rate": 9.166666666666667e-07,
      "loss": 0.0028,
      "step": 17670
    },
    {
      "epoch": 1.9644444444444444,
      "grad_norm": 0.3109782934188843,
      "learning_rate": 8.88888888888889e-07,
      "loss": 0.0021,
      "step": 17680
    },
    {
      "epoch": 1.9655555555555555,
      "grad_norm": 0.163434237241745,
      "learning_rate": 8.611111111111111e-07,
      "loss": 0.0027,
      "step": 17690
    },
    {
      "epoch": 1.9666666666666668,
      "grad_norm": 0.35121744871139526,
      "learning_rate": 8.333333333333333e-07,
      "loss": 0.0024,
      "step": 17700
    },
    {
      "epoch": 1.9677777777777776,
      "grad_norm": 0.3218249976634979,
      "learning_rate": 8.055555555555556e-07,
      "loss": 0.0017,
      "step": 17710
    },
    {
      "epoch": 1.968888888888889,
      "grad_norm": 0.2431802600622177,
      "learning_rate": 7.777777777777778e-07,
      "loss": 0.0017,
      "step": 17720
    },
    {
      "epoch": 1.97,
      "grad_norm": 0.15330830216407776,
      "learning_rate": 7.5e-07,
      "loss": 0.0021,
      "step": 17730
    },
    {
      "epoch": 1.971111111111111,
      "grad_norm": 1.0778065919876099,
      "learning_rate": 7.222222222222222e-07,
      "loss": 0.0022,
      "step": 17740
    },
    {
      "epoch": 1.9722222222222223,
      "grad_norm": 0.3279748857021332,
      "learning_rate": 6.944444444444445e-07,
      "loss": 0.0022,
      "step": 17750
    },
    {
      "epoch": 1.9733333333333334,
      "grad_norm": 0.7090138792991638,
      "learning_rate": 6.666666666666667e-07,
      "loss": 0.001,
      "step": 17760
    },
    {
      "epoch": 1.9744444444444444,
      "grad_norm": 0.8752836585044861,
      "learning_rate": 6.388888888888889e-07,
      "loss": 0.0017,
      "step": 17770
    },
    {
      "epoch": 1.9755555555555555,
      "grad_norm": 0.2163708209991455,
      "learning_rate": 6.111111111111112e-07,
      "loss": 0.0024,
      "step": 17780
    },
    {
      "epoch": 1.9766666666666666,
      "grad_norm": 0.5070322155952454,
      "learning_rate": 5.833333333333334e-07,
      "loss": 0.0023,
      "step": 17790
    },
    {
      "epoch": 1.9777777777777779,
      "grad_norm": 0.2117144912481308,
      "learning_rate": 5.555555555555556e-07,
      "loss": 0.0029,
      "step": 17800
    },
    {
      "epoch": 1.978888888888889,
      "grad_norm": 0.2578089237213135,
      "learning_rate": 5.277777777777779e-07,
      "loss": 0.0025,
      "step": 17810
    },
    {
      "epoch": 1.98,
      "grad_norm": 0.3816550672054291,
      "learning_rate": 5.000000000000001e-07,
      "loss": 0.0022,
      "step": 17820
    },
    {
      "epoch": 1.9811111111111113,
      "grad_norm": 0.2224263846874237,
      "learning_rate": 4.7222222222222226e-07,
      "loss": 0.0015,
      "step": 17830
    },
    {
      "epoch": 1.982222222222222,
      "grad_norm": 0.7727233171463013,
      "learning_rate": 4.444444444444445e-07,
      "loss": 0.0021,
      "step": 17840
    },
    {
      "epoch": 1.9833333333333334,
      "grad_norm": 0.34785670042037964,
      "learning_rate": 4.1666666666666667e-07,
      "loss": 0.0018,
      "step": 17850
    },
    {
      "epoch": 1.9844444444444445,
      "grad_norm": 0.20804528892040253,
      "learning_rate": 3.888888888888889e-07,
      "loss": 0.0025,
      "step": 17860
    },
    {
      "epoch": 1.9855555555555555,
      "grad_norm": 0.30038291215896606,
      "learning_rate": 3.611111111111111e-07,
      "loss": 0.0028,
      "step": 17870
    },
    {
      "epoch": 1.9866666666666668,
      "grad_norm": 0.3902417719364166,
      "learning_rate": 3.3333333333333335e-07,
      "loss": 0.0025,
      "step": 17880
    },
    {
      "epoch": 1.9877777777777776,
      "grad_norm": 0.18567338585853577,
      "learning_rate": 3.055555555555556e-07,
      "loss": 0.0011,
      "step": 17890
    },
    {
      "epoch": 1.988888888888889,
      "grad_norm": 0.22658158838748932,
      "learning_rate": 2.777777777777778e-07,
      "loss": 0.0031,
      "step": 17900
    },
    {
      "epoch": 1.99,
      "grad_norm": 0.1872597634792328,
      "learning_rate": 2.5000000000000004e-07,
      "loss": 0.0041,
      "step": 17910
    },
    {
      "epoch": 1.991111111111111,
      "grad_norm": 0.4238176643848419,
      "learning_rate": 2.2222222222222224e-07,
      "loss": 0.0014,
      "step": 17920
    },
    {
      "epoch": 1.9922222222222223,
      "grad_norm": 0.39876240491867065,
      "learning_rate": 1.9444444444444445e-07,
      "loss": 0.0019,
      "step": 17930
    },
    {
      "epoch": 1.9933333333333332,
      "grad_norm": 0.40008744597435,
      "learning_rate": 1.6666666666666668e-07,
      "loss": 0.0016,
      "step": 17940
    },
    {
      "epoch": 1.9944444444444445,
      "grad_norm": 0.25270339846611023,
      "learning_rate": 1.388888888888889e-07,
      "loss": 0.0028,
      "step": 17950
    },
    {
      "epoch": 1.9955555555555555,
      "grad_norm": 0.3164058029651642,
      "learning_rate": 1.1111111111111112e-07,
      "loss": 0.0017,
      "step": 17960
    },
    {
      "epoch": 1.9966666666666666,
      "grad_norm": 0.33292174339294434,
      "learning_rate": 8.333333333333334e-08,
      "loss": 0.0028,
      "step": 17970
    },
    {
      "epoch": 1.9977777777777779,
      "grad_norm": 0.3028453290462494,
      "learning_rate": 5.555555555555556e-08,
      "loss": 0.0023,
      "step": 17980
    },
    {
      "epoch": 1.998888888888889,
      "grad_norm": 0.5542542338371277,
      "learning_rate": 2.777777777777778e-08,
      "loss": 0.0024,
      "step": 17990
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.15428763628005981,
      "learning_rate": 0.0,
      "loss": 0.002,
      "step": 18000
    }
  ],
  "logging_steps": 10,
  "max_steps": 18000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 0.0,
  "train_batch_size": 40,
  "trial_name": null,
  "trial_params": null
}
