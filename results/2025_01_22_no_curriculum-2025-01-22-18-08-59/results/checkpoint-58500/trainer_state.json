{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 4.991893506271866,
  "eval_steps": 500,
  "global_step": 58500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0008533151292772421,
      "grad_norm": 0.3435513377189636,
      "learning_rate": 4.999146684870723e-05,
      "loss": 0.0108,
      "step": 10
    },
    {
      "epoch": 0.0017066302585544842,
      "grad_norm": 0.9027496576309204,
      "learning_rate": 4.998293369741446e-05,
      "loss": 0.0078,
      "step": 20
    },
    {
      "epoch": 0.0025599453878317265,
      "grad_norm": 0.787561297416687,
      "learning_rate": 4.997440054612169e-05,
      "loss": 0.0064,
      "step": 30
    },
    {
      "epoch": 0.0034132605171089685,
      "grad_norm": 0.11942397803068161,
      "learning_rate": 4.9965867394828916e-05,
      "loss": 0.0062,
      "step": 40
    },
    {
      "epoch": 0.00426657564638621,
      "grad_norm": 0.4499424397945404,
      "learning_rate": 4.995733424353614e-05,
      "loss": 0.0069,
      "step": 50
    },
    {
      "epoch": 0.005119890775663453,
      "grad_norm": 0.6002669334411621,
      "learning_rate": 4.9948801092243367e-05,
      "loss": 0.0076,
      "step": 60
    },
    {
      "epoch": 0.005973205904940695,
      "grad_norm": 0.22451400756835938,
      "learning_rate": 4.9940267940950595e-05,
      "loss": 0.0052,
      "step": 70
    },
    {
      "epoch": 0.006826521034217937,
      "grad_norm": 0.1549064666032791,
      "learning_rate": 4.9931734789657823e-05,
      "loss": 0.0075,
      "step": 80
    },
    {
      "epoch": 0.007679836163495179,
      "grad_norm": 0.03016527369618416,
      "learning_rate": 4.992320163836505e-05,
      "loss": 0.0055,
      "step": 90
    },
    {
      "epoch": 0.00853315129277242,
      "grad_norm": 0.15792280435562134,
      "learning_rate": 4.991466848707228e-05,
      "loss": 0.0075,
      "step": 100
    },
    {
      "epoch": 0.009386466422049662,
      "grad_norm": 0.10082748532295227,
      "learning_rate": 4.990613533577951e-05,
      "loss": 0.0057,
      "step": 110
    },
    {
      "epoch": 0.010239781551326906,
      "grad_norm": 0.08491910994052887,
      "learning_rate": 4.989760218448674e-05,
      "loss": 0.0074,
      "step": 120
    },
    {
      "epoch": 0.011093096680604148,
      "grad_norm": 0.30292490124702454,
      "learning_rate": 4.9889069033193966e-05,
      "loss": 0.0068,
      "step": 130
    },
    {
      "epoch": 0.01194641180988139,
      "grad_norm": 0.23177824914455414,
      "learning_rate": 4.988053588190119e-05,
      "loss": 0.0069,
      "step": 140
    },
    {
      "epoch": 0.012799726939158632,
      "grad_norm": 0.055244725197553635,
      "learning_rate": 4.9872002730608416e-05,
      "loss": 0.0063,
      "step": 150
    },
    {
      "epoch": 0.013653042068435874,
      "grad_norm": 0.04098409041762352,
      "learning_rate": 4.9863469579315645e-05,
      "loss": 0.0058,
      "step": 160
    },
    {
      "epoch": 0.014506357197713116,
      "grad_norm": 0.5996240973472595,
      "learning_rate": 4.9854936428022866e-05,
      "loss": 0.007,
      "step": 170
    },
    {
      "epoch": 0.015359672326990358,
      "grad_norm": 0.19312041997909546,
      "learning_rate": 4.9846403276730095e-05,
      "loss": 0.0079,
      "step": 180
    },
    {
      "epoch": 0.016212987456267598,
      "grad_norm": 0.30173423886299133,
      "learning_rate": 4.983787012543732e-05,
      "loss": 0.006,
      "step": 190
    },
    {
      "epoch": 0.01706630258554484,
      "grad_norm": 0.26358217000961304,
      "learning_rate": 4.982933697414455e-05,
      "loss": 0.0057,
      "step": 200
    },
    {
      "epoch": 0.017919617714822082,
      "grad_norm": 0.07651466131210327,
      "learning_rate": 4.982080382285178e-05,
      "loss": 0.0069,
      "step": 210
    },
    {
      "epoch": 0.018772932844099324,
      "grad_norm": 0.08672987669706345,
      "learning_rate": 4.981227067155901e-05,
      "loss": 0.0067,
      "step": 220
    },
    {
      "epoch": 0.019626247973376566,
      "grad_norm": 0.2620886564254761,
      "learning_rate": 4.980373752026624e-05,
      "loss": 0.0073,
      "step": 230
    },
    {
      "epoch": 0.020479563102653812,
      "grad_norm": 0.2660823464393616,
      "learning_rate": 4.9795204368973466e-05,
      "loss": 0.0078,
      "step": 240
    },
    {
      "epoch": 0.021332878231931054,
      "grad_norm": 0.1571832299232483,
      "learning_rate": 4.9786671217680694e-05,
      "loss": 0.0068,
      "step": 250
    },
    {
      "epoch": 0.022186193361208296,
      "grad_norm": 0.11606469005346298,
      "learning_rate": 4.977813806638792e-05,
      "loss": 0.0054,
      "step": 260
    },
    {
      "epoch": 0.023039508490485538,
      "grad_norm": 0.44959646463394165,
      "learning_rate": 4.9769604915095144e-05,
      "loss": 0.0062,
      "step": 270
    },
    {
      "epoch": 0.02389282361976278,
      "grad_norm": 0.4865899980068207,
      "learning_rate": 4.976107176380237e-05,
      "loss": 0.0059,
      "step": 280
    },
    {
      "epoch": 0.024746138749040022,
      "grad_norm": 0.5601457357406616,
      "learning_rate": 4.97525386125096e-05,
      "loss": 0.0056,
      "step": 290
    },
    {
      "epoch": 0.025599453878317264,
      "grad_norm": 0.04259732365608215,
      "learning_rate": 4.974400546121683e-05,
      "loss": 0.0055,
      "step": 300
    },
    {
      "epoch": 0.026452769007594506,
      "grad_norm": 0.4134604334831238,
      "learning_rate": 4.973547230992406e-05,
      "loss": 0.0072,
      "step": 310
    },
    {
      "epoch": 0.027306084136871748,
      "grad_norm": 0.6705853343009949,
      "learning_rate": 4.972693915863129e-05,
      "loss": 0.005,
      "step": 320
    },
    {
      "epoch": 0.02815939926614899,
      "grad_norm": 0.37391331791877747,
      "learning_rate": 4.9718406007338515e-05,
      "loss": 0.0065,
      "step": 330
    },
    {
      "epoch": 0.029012714395426232,
      "grad_norm": 0.5219361186027527,
      "learning_rate": 4.9709872856045744e-05,
      "loss": 0.0059,
      "step": 340
    },
    {
      "epoch": 0.029866029524703474,
      "grad_norm": 0.1194443628191948,
      "learning_rate": 4.970133970475297e-05,
      "loss": 0.0062,
      "step": 350
    },
    {
      "epoch": 0.030719344653980716,
      "grad_norm": 0.15463416278362274,
      "learning_rate": 4.9692806553460194e-05,
      "loss": 0.0076,
      "step": 360
    },
    {
      "epoch": 0.031572659783257954,
      "grad_norm": 0.11758828908205032,
      "learning_rate": 4.968427340216742e-05,
      "loss": 0.006,
      "step": 370
    },
    {
      "epoch": 0.032425974912535196,
      "grad_norm": 0.2990463674068451,
      "learning_rate": 4.967574025087465e-05,
      "loss": 0.0078,
      "step": 380
    },
    {
      "epoch": 0.03327929004181244,
      "grad_norm": 0.0870482325553894,
      "learning_rate": 4.966720709958188e-05,
      "loss": 0.006,
      "step": 390
    },
    {
      "epoch": 0.03413260517108968,
      "grad_norm": 0.11626201122999191,
      "learning_rate": 4.96586739482891e-05,
      "loss": 0.0066,
      "step": 400
    },
    {
      "epoch": 0.03498592030036692,
      "grad_norm": 0.3747614324092865,
      "learning_rate": 4.965014079699633e-05,
      "loss": 0.0055,
      "step": 410
    },
    {
      "epoch": 0.035839235429644165,
      "grad_norm": 0.11554791033267975,
      "learning_rate": 4.964160764570356e-05,
      "loss": 0.0059,
      "step": 420
    },
    {
      "epoch": 0.03669255055892141,
      "grad_norm": 0.4490782618522644,
      "learning_rate": 4.9633074494410786e-05,
      "loss": 0.0065,
      "step": 430
    },
    {
      "epoch": 0.03754586568819865,
      "grad_norm": 0.8182787299156189,
      "learning_rate": 4.9624541343118015e-05,
      "loss": 0.0066,
      "step": 440
    },
    {
      "epoch": 0.03839918081747589,
      "grad_norm": 0.18927502632141113,
      "learning_rate": 4.9616008191825243e-05,
      "loss": 0.0062,
      "step": 450
    },
    {
      "epoch": 0.03925249594675313,
      "grad_norm": 0.4108584523200989,
      "learning_rate": 4.960747504053247e-05,
      "loss": 0.0058,
      "step": 460
    },
    {
      "epoch": 0.040105811076030375,
      "grad_norm": 0.2996463477611542,
      "learning_rate": 4.95989418892397e-05,
      "loss": 0.0062,
      "step": 470
    },
    {
      "epoch": 0.040959126205307624,
      "grad_norm": 0.3366895616054535,
      "learning_rate": 4.959040873794692e-05,
      "loss": 0.0074,
      "step": 480
    },
    {
      "epoch": 0.041812441334584866,
      "grad_norm": 0.29792141914367676,
      "learning_rate": 4.958187558665415e-05,
      "loss": 0.0062,
      "step": 490
    },
    {
      "epoch": 0.04266575646386211,
      "grad_norm": 0.12232738733291626,
      "learning_rate": 4.957334243536138e-05,
      "loss": 0.0056,
      "step": 500
    },
    {
      "epoch": 0.04351907159313935,
      "grad_norm": 0.08060164004564285,
      "learning_rate": 4.956480928406861e-05,
      "loss": 0.0063,
      "step": 510
    },
    {
      "epoch": 0.04437238672241659,
      "grad_norm": 0.26229387521743774,
      "learning_rate": 4.9556276132775836e-05,
      "loss": 0.0061,
      "step": 520
    },
    {
      "epoch": 0.045225701851693834,
      "grad_norm": 0.37231117486953735,
      "learning_rate": 4.9547742981483065e-05,
      "loss": 0.0063,
      "step": 530
    },
    {
      "epoch": 0.046079016980971076,
      "grad_norm": 0.25979307293891907,
      "learning_rate": 4.953920983019029e-05,
      "loss": 0.0057,
      "step": 540
    },
    {
      "epoch": 0.04693233211024832,
      "grad_norm": 0.12047650665044785,
      "learning_rate": 4.953067667889752e-05,
      "loss": 0.0073,
      "step": 550
    },
    {
      "epoch": 0.04778564723952556,
      "grad_norm": 0.3350106477737427,
      "learning_rate": 4.952214352760475e-05,
      "loss": 0.0061,
      "step": 560
    },
    {
      "epoch": 0.0486389623688028,
      "grad_norm": 0.37201666831970215,
      "learning_rate": 4.951361037631198e-05,
      "loss": 0.0056,
      "step": 570
    },
    {
      "epoch": 0.049492277498080044,
      "grad_norm": 0.04569033533334732,
      "learning_rate": 4.95050772250192e-05,
      "loss": 0.0057,
      "step": 580
    },
    {
      "epoch": 0.050345592627357286,
      "grad_norm": 0.4092884063720703,
      "learning_rate": 4.949654407372643e-05,
      "loss": 0.0072,
      "step": 590
    },
    {
      "epoch": 0.05119890775663453,
      "grad_norm": 0.2979699671268463,
      "learning_rate": 4.948801092243366e-05,
      "loss": 0.0076,
      "step": 600
    },
    {
      "epoch": 0.05205222288591177,
      "grad_norm": 0.26093775033950806,
      "learning_rate": 4.9479477771140886e-05,
      "loss": 0.0078,
      "step": 610
    },
    {
      "epoch": 0.05290553801518901,
      "grad_norm": 0.05712886527180672,
      "learning_rate": 4.9470944619848114e-05,
      "loss": 0.0048,
      "step": 620
    },
    {
      "epoch": 0.053758853144466254,
      "grad_norm": 0.04199603199958801,
      "learning_rate": 4.946241146855534e-05,
      "loss": 0.0054,
      "step": 630
    },
    {
      "epoch": 0.054612168273743496,
      "grad_norm": 0.12036421149969101,
      "learning_rate": 4.945387831726257e-05,
      "loss": 0.0057,
      "step": 640
    },
    {
      "epoch": 0.05546548340302074,
      "grad_norm": 0.33542898297309875,
      "learning_rate": 4.94453451659698e-05,
      "loss": 0.0072,
      "step": 650
    },
    {
      "epoch": 0.05631879853229798,
      "grad_norm": 0.079131580889225,
      "learning_rate": 4.943681201467703e-05,
      "loss": 0.0076,
      "step": 660
    },
    {
      "epoch": 0.05717211366157522,
      "grad_norm": 0.015191066078841686,
      "learning_rate": 4.942827886338425e-05,
      "loss": 0.0056,
      "step": 670
    },
    {
      "epoch": 0.058025428790852464,
      "grad_norm": 0.05956003814935684,
      "learning_rate": 4.941974571209148e-05,
      "loss": 0.0059,
      "step": 680
    },
    {
      "epoch": 0.058878743920129706,
      "grad_norm": 0.5577184557914734,
      "learning_rate": 4.94112125607987e-05,
      "loss": 0.0065,
      "step": 690
    },
    {
      "epoch": 0.05973205904940695,
      "grad_norm": 0.15088754892349243,
      "learning_rate": 4.940267940950593e-05,
      "loss": 0.0063,
      "step": 700
    },
    {
      "epoch": 0.06058537417868419,
      "grad_norm": 0.33373141288757324,
      "learning_rate": 4.939414625821316e-05,
      "loss": 0.0065,
      "step": 710
    },
    {
      "epoch": 0.06143868930796143,
      "grad_norm": 0.3726257383823395,
      "learning_rate": 4.9385613106920385e-05,
      "loss": 0.0061,
      "step": 720
    },
    {
      "epoch": 0.062292004437238674,
      "grad_norm": 0.18779166042804718,
      "learning_rate": 4.9377079955627614e-05,
      "loss": 0.007,
      "step": 730
    },
    {
      "epoch": 0.06314531956651591,
      "grad_norm": 0.41031718254089355,
      "learning_rate": 4.936854680433484e-05,
      "loss": 0.0058,
      "step": 740
    },
    {
      "epoch": 0.06399863469579316,
      "grad_norm": 0.11712770909070969,
      "learning_rate": 4.936001365304207e-05,
      "loss": 0.0076,
      "step": 750
    },
    {
      "epoch": 0.06485194982507039,
      "grad_norm": 0.3745777904987335,
      "learning_rate": 4.93514805017493e-05,
      "loss": 0.0057,
      "step": 760
    },
    {
      "epoch": 0.06570526495434764,
      "grad_norm": 0.33940693736076355,
      "learning_rate": 4.934294735045653e-05,
      "loss": 0.006,
      "step": 770
    },
    {
      "epoch": 0.06655858008362488,
      "grad_norm": 0.40835481882095337,
      "learning_rate": 4.9334414199163756e-05,
      "loss": 0.007,
      "step": 780
    },
    {
      "epoch": 0.06741189521290213,
      "grad_norm": 0.9274289011955261,
      "learning_rate": 4.932588104787098e-05,
      "loss": 0.0064,
      "step": 790
    },
    {
      "epoch": 0.06826521034217936,
      "grad_norm": 0.026858732104301453,
      "learning_rate": 4.9317347896578206e-05,
      "loss": 0.0064,
      "step": 800
    },
    {
      "epoch": 0.06911852547145661,
      "grad_norm": 0.22443725168704987,
      "learning_rate": 4.9308814745285435e-05,
      "loss": 0.0068,
      "step": 810
    },
    {
      "epoch": 0.06997184060073385,
      "grad_norm": 0.22355715930461884,
      "learning_rate": 4.930028159399266e-05,
      "loss": 0.0067,
      "step": 820
    },
    {
      "epoch": 0.0708251557300111,
      "grad_norm": 0.18515825271606445,
      "learning_rate": 4.929174844269989e-05,
      "loss": 0.006,
      "step": 830
    },
    {
      "epoch": 0.07167847085928833,
      "grad_norm": 0.4095180332660675,
      "learning_rate": 4.928321529140712e-05,
      "loss": 0.007,
      "step": 840
    },
    {
      "epoch": 0.07253178598856558,
      "grad_norm": 0.26143449544906616,
      "learning_rate": 4.927468214011435e-05,
      "loss": 0.0063,
      "step": 850
    },
    {
      "epoch": 0.07338510111784281,
      "grad_norm": 0.14930854737758636,
      "learning_rate": 4.926614898882158e-05,
      "loss": 0.0054,
      "step": 860
    },
    {
      "epoch": 0.07423841624712006,
      "grad_norm": 0.29746460914611816,
      "learning_rate": 4.9257615837528806e-05,
      "loss": 0.0079,
      "step": 870
    },
    {
      "epoch": 0.0750917313763973,
      "grad_norm": 0.37343961000442505,
      "learning_rate": 4.9249082686236034e-05,
      "loss": 0.0057,
      "step": 880
    },
    {
      "epoch": 0.07594504650567455,
      "grad_norm": 0.19350312650203705,
      "learning_rate": 4.9240549534943256e-05,
      "loss": 0.0063,
      "step": 890
    },
    {
      "epoch": 0.07679836163495178,
      "grad_norm": 0.4082346260547638,
      "learning_rate": 4.9232016383650484e-05,
      "loss": 0.0068,
      "step": 900
    },
    {
      "epoch": 0.07765167676422903,
      "grad_norm": 0.15325146913528442,
      "learning_rate": 4.922348323235771e-05,
      "loss": 0.0047,
      "step": 910
    },
    {
      "epoch": 0.07850499189350627,
      "grad_norm": 0.40709638595581055,
      "learning_rate": 4.921495008106494e-05,
      "loss": 0.0071,
      "step": 920
    },
    {
      "epoch": 0.07935830702278351,
      "grad_norm": 0.7035790681838989,
      "learning_rate": 4.920641692977217e-05,
      "loss": 0.006,
      "step": 930
    },
    {
      "epoch": 0.08021162215206075,
      "grad_norm": 0.44689592719078064,
      "learning_rate": 4.919788377847939e-05,
      "loss": 0.0074,
      "step": 940
    },
    {
      "epoch": 0.081064937281338,
      "grad_norm": 0.4810551106929779,
      "learning_rate": 4.918935062718662e-05,
      "loss": 0.006,
      "step": 950
    },
    {
      "epoch": 0.08191825241061525,
      "grad_norm": 0.4439643919467926,
      "learning_rate": 4.918081747589385e-05,
      "loss": 0.0052,
      "step": 960
    },
    {
      "epoch": 0.08277156753989248,
      "grad_norm": 0.11396554112434387,
      "learning_rate": 4.917228432460108e-05,
      "loss": 0.0053,
      "step": 970
    },
    {
      "epoch": 0.08362488266916973,
      "grad_norm": 0.40586620569229126,
      "learning_rate": 4.9163751173308306e-05,
      "loss": 0.0068,
      "step": 980
    },
    {
      "epoch": 0.08447819779844697,
      "grad_norm": 0.1520366221666336,
      "learning_rate": 4.9155218022015534e-05,
      "loss": 0.0063,
      "step": 990
    },
    {
      "epoch": 0.08533151292772422,
      "grad_norm": 0.0405258946120739,
      "learning_rate": 4.9146684870722756e-05,
      "loss": 0.0069,
      "step": 1000
    },
    {
      "epoch": 0.08618482805700145,
      "grad_norm": 0.04755713790655136,
      "learning_rate": 4.9138151719429984e-05,
      "loss": 0.0051,
      "step": 1010
    },
    {
      "epoch": 0.0870381431862787,
      "grad_norm": 0.6267527341842651,
      "learning_rate": 4.912961856813721e-05,
      "loss": 0.0055,
      "step": 1020
    },
    {
      "epoch": 0.08789145831555593,
      "grad_norm": 0.40796712040901184,
      "learning_rate": 4.912108541684444e-05,
      "loss": 0.0051,
      "step": 1030
    },
    {
      "epoch": 0.08874477344483318,
      "grad_norm": 0.3714756965637207,
      "learning_rate": 4.911255226555167e-05,
      "loss": 0.0059,
      "step": 1040
    },
    {
      "epoch": 0.08959808857411042,
      "grad_norm": 0.1501789093017578,
      "learning_rate": 4.91040191142589e-05,
      "loss": 0.0085,
      "step": 1050
    },
    {
      "epoch": 0.09045140370338767,
      "grad_norm": 0.2955632209777832,
      "learning_rate": 4.909548596296613e-05,
      "loss": 0.0052,
      "step": 1060
    },
    {
      "epoch": 0.0913047188326649,
      "grad_norm": 0.07439953088760376,
      "learning_rate": 4.9086952811673355e-05,
      "loss": 0.006,
      "step": 1070
    },
    {
      "epoch": 0.09215803396194215,
      "grad_norm": 0.589794397354126,
      "learning_rate": 4.9078419660380584e-05,
      "loss": 0.006,
      "step": 1080
    },
    {
      "epoch": 0.09301134909121939,
      "grad_norm": 0.5533512234687805,
      "learning_rate": 4.906988650908781e-05,
      "loss": 0.0065,
      "step": 1090
    },
    {
      "epoch": 0.09386466422049664,
      "grad_norm": 0.2226184606552124,
      "learning_rate": 4.9061353357795034e-05,
      "loss": 0.0062,
      "step": 1100
    },
    {
      "epoch": 0.09471797934977387,
      "grad_norm": 0.11234150826931,
      "learning_rate": 4.905282020650226e-05,
      "loss": 0.0075,
      "step": 1110
    },
    {
      "epoch": 0.09557129447905112,
      "grad_norm": 0.36951974034309387,
      "learning_rate": 4.904428705520949e-05,
      "loss": 0.0053,
      "step": 1120
    },
    {
      "epoch": 0.09642460960832835,
      "grad_norm": 0.4053725302219391,
      "learning_rate": 4.903575390391672e-05,
      "loss": 0.0087,
      "step": 1130
    },
    {
      "epoch": 0.0972779247376056,
      "grad_norm": 0.8477174639701843,
      "learning_rate": 4.902722075262395e-05,
      "loss": 0.0055,
      "step": 1140
    },
    {
      "epoch": 0.09813123986688284,
      "grad_norm": 0.04151206091046333,
      "learning_rate": 4.9018687601331176e-05,
      "loss": 0.0069,
      "step": 1150
    },
    {
      "epoch": 0.09898455499616009,
      "grad_norm": 0.22314096987247467,
      "learning_rate": 4.9010154450038405e-05,
      "loss": 0.0054,
      "step": 1160
    },
    {
      "epoch": 0.09983787012543732,
      "grad_norm": 0.08267924189567566,
      "learning_rate": 4.900162129874563e-05,
      "loss": 0.005,
      "step": 1170
    },
    {
      "epoch": 0.10069118525471457,
      "grad_norm": 0.1481405645608902,
      "learning_rate": 4.899308814745286e-05,
      "loss": 0.0052,
      "step": 1180
    },
    {
      "epoch": 0.1015445003839918,
      "grad_norm": 0.1505470871925354,
      "learning_rate": 4.898455499616009e-05,
      "loss": 0.0063,
      "step": 1190
    },
    {
      "epoch": 0.10239781551326906,
      "grad_norm": 0.22335311770439148,
      "learning_rate": 4.897602184486731e-05,
      "loss": 0.0067,
      "step": 1200
    },
    {
      "epoch": 0.10325113064254629,
      "grad_norm": 0.04090109094977379,
      "learning_rate": 4.896748869357454e-05,
      "loss": 0.0056,
      "step": 1210
    },
    {
      "epoch": 0.10410444577182354,
      "grad_norm": 0.40595024824142456,
      "learning_rate": 4.895895554228176e-05,
      "loss": 0.0054,
      "step": 1220
    },
    {
      "epoch": 0.10495776090110077,
      "grad_norm": 0.48049166798591614,
      "learning_rate": 4.895042239098899e-05,
      "loss": 0.0064,
      "step": 1230
    },
    {
      "epoch": 0.10581107603037802,
      "grad_norm": 0.04129048436880112,
      "learning_rate": 4.894188923969622e-05,
      "loss": 0.0055,
      "step": 1240
    },
    {
      "epoch": 0.10666439115965526,
      "grad_norm": 0.1864011287689209,
      "learning_rate": 4.893335608840345e-05,
      "loss": 0.0074,
      "step": 1250
    },
    {
      "epoch": 0.10751770628893251,
      "grad_norm": 0.14904308319091797,
      "learning_rate": 4.8924822937110676e-05,
      "loss": 0.0055,
      "step": 1260
    },
    {
      "epoch": 0.10837102141820974,
      "grad_norm": 0.479696124792099,
      "learning_rate": 4.8916289785817904e-05,
      "loss": 0.0066,
      "step": 1270
    },
    {
      "epoch": 0.10922433654748699,
      "grad_norm": 0.3312278985977173,
      "learning_rate": 4.890775663452513e-05,
      "loss": 0.0064,
      "step": 1280
    },
    {
      "epoch": 0.11007765167676423,
      "grad_norm": 0.7727564573287964,
      "learning_rate": 4.889922348323236e-05,
      "loss": 0.0064,
      "step": 1290
    },
    {
      "epoch": 0.11093096680604148,
      "grad_norm": 0.11684614419937134,
      "learning_rate": 4.889069033193959e-05,
      "loss": 0.0059,
      "step": 1300
    },
    {
      "epoch": 0.11178428193531871,
      "grad_norm": 0.2951471507549286,
      "learning_rate": 4.888215718064681e-05,
      "loss": 0.0054,
      "step": 1310
    },
    {
      "epoch": 0.11263759706459596,
      "grad_norm": 0.07653111219406128,
      "learning_rate": 4.887362402935404e-05,
      "loss": 0.006,
      "step": 1320
    },
    {
      "epoch": 0.1134909121938732,
      "grad_norm": 0.4783628284931183,
      "learning_rate": 4.886509087806127e-05,
      "loss": 0.005,
      "step": 1330
    },
    {
      "epoch": 0.11434422732315044,
      "grad_norm": 0.04652181267738342,
      "learning_rate": 4.88565577267685e-05,
      "loss": 0.008,
      "step": 1340
    },
    {
      "epoch": 0.11519754245242768,
      "grad_norm": 0.6250180006027222,
      "learning_rate": 4.8848024575475725e-05,
      "loss": 0.0067,
      "step": 1350
    },
    {
      "epoch": 0.11605085758170493,
      "grad_norm": 0.052793122828006744,
      "learning_rate": 4.8839491424182954e-05,
      "loss": 0.0059,
      "step": 1360
    },
    {
      "epoch": 0.11690417271098216,
      "grad_norm": 0.29370859265327454,
      "learning_rate": 4.883095827289018e-05,
      "loss": 0.0056,
      "step": 1370
    },
    {
      "epoch": 0.11775748784025941,
      "grad_norm": 0.4778110384941101,
      "learning_rate": 4.882242512159741e-05,
      "loss": 0.0063,
      "step": 1380
    },
    {
      "epoch": 0.11861080296953665,
      "grad_norm": 0.045107875019311905,
      "learning_rate": 4.881389197030464e-05,
      "loss": 0.0078,
      "step": 1390
    },
    {
      "epoch": 0.1194641180988139,
      "grad_norm": 0.1134345754981041,
      "learning_rate": 4.880535881901187e-05,
      "loss": 0.0069,
      "step": 1400
    },
    {
      "epoch": 0.12031743322809113,
      "grad_norm": 0.041971027851104736,
      "learning_rate": 4.879682566771909e-05,
      "loss": 0.0057,
      "step": 1410
    },
    {
      "epoch": 0.12117074835736838,
      "grad_norm": 0.0767960324883461,
      "learning_rate": 4.878829251642632e-05,
      "loss": 0.0065,
      "step": 1420
    },
    {
      "epoch": 0.12202406348664561,
      "grad_norm": 0.2944508492946625,
      "learning_rate": 4.8779759365133547e-05,
      "loss": 0.007,
      "step": 1430
    },
    {
      "epoch": 0.12287737861592286,
      "grad_norm": 0.22147740423679352,
      "learning_rate": 4.8771226213840775e-05,
      "loss": 0.0061,
      "step": 1440
    },
    {
      "epoch": 0.1237306937452001,
      "grad_norm": 0.4783708155155182,
      "learning_rate": 4.8762693062548004e-05,
      "loss": 0.0059,
      "step": 1450
    },
    {
      "epoch": 0.12458400887447735,
      "grad_norm": 0.07684524357318878,
      "learning_rate": 4.875415991125523e-05,
      "loss": 0.0077,
      "step": 1460
    },
    {
      "epoch": 0.1254373240037546,
      "grad_norm": 0.15058423578739166,
      "learning_rate": 4.8745626759962454e-05,
      "loss": 0.006,
      "step": 1470
    },
    {
      "epoch": 0.12629063913303182,
      "grad_norm": 0.02275203727185726,
      "learning_rate": 4.873709360866968e-05,
      "loss": 0.0074,
      "step": 1480
    },
    {
      "epoch": 0.12714395426230907,
      "grad_norm": 0.22149629890918732,
      "learning_rate": 4.872856045737691e-05,
      "loss": 0.0058,
      "step": 1490
    },
    {
      "epoch": 0.12799726939158632,
      "grad_norm": 0.07498425245285034,
      "learning_rate": 4.872002730608414e-05,
      "loss": 0.0066,
      "step": 1500
    },
    {
      "epoch": 0.12885058452086356,
      "grad_norm": 0.4039076864719391,
      "learning_rate": 4.871149415479137e-05,
      "loss": 0.0064,
      "step": 1510
    },
    {
      "epoch": 0.12970389965014079,
      "grad_norm": 0.29448506236076355,
      "learning_rate": 4.8702961003498596e-05,
      "loss": 0.0088,
      "step": 1520
    },
    {
      "epoch": 0.13055721477941803,
      "grad_norm": 0.11431065946817398,
      "learning_rate": 4.869442785220582e-05,
      "loss": 0.0054,
      "step": 1530
    },
    {
      "epoch": 0.13141052990869528,
      "grad_norm": 0.6982829570770264,
      "learning_rate": 4.8685894700913046e-05,
      "loss": 0.0073,
      "step": 1540
    },
    {
      "epoch": 0.13226384503797253,
      "grad_norm": 0.11499663442373276,
      "learning_rate": 4.8677361549620275e-05,
      "loss": 0.0052,
      "step": 1550
    },
    {
      "epoch": 0.13311716016724975,
      "grad_norm": 0.1854245513677597,
      "learning_rate": 4.86688283983275e-05,
      "loss": 0.0063,
      "step": 1560
    },
    {
      "epoch": 0.133970475296527,
      "grad_norm": 0.22011350095272064,
      "learning_rate": 4.866029524703473e-05,
      "loss": 0.0065,
      "step": 1570
    },
    {
      "epoch": 0.13482379042580425,
      "grad_norm": 0.07649020105600357,
      "learning_rate": 4.865176209574196e-05,
      "loss": 0.0072,
      "step": 1580
    },
    {
      "epoch": 0.1356771055550815,
      "grad_norm": 0.18829280138015747,
      "learning_rate": 4.864322894444919e-05,
      "loss": 0.0056,
      "step": 1590
    },
    {
      "epoch": 0.13653042068435872,
      "grad_norm": 0.11410623788833618,
      "learning_rate": 4.863469579315642e-05,
      "loss": 0.0051,
      "step": 1600
    },
    {
      "epoch": 0.13738373581363597,
      "grad_norm": 0.18734513223171234,
      "learning_rate": 4.8626162641863646e-05,
      "loss": 0.0059,
      "step": 1610
    },
    {
      "epoch": 0.13823705094291322,
      "grad_norm": 0.11230313777923584,
      "learning_rate": 4.861762949057087e-05,
      "loss": 0.0068,
      "step": 1620
    },
    {
      "epoch": 0.13909036607219047,
      "grad_norm": 0.01622435450553894,
      "learning_rate": 4.8609096339278096e-05,
      "loss": 0.0057,
      "step": 1630
    },
    {
      "epoch": 0.1399436812014677,
      "grad_norm": 0.024553555995225906,
      "learning_rate": 4.8600563187985324e-05,
      "loss": 0.0066,
      "step": 1640
    },
    {
      "epoch": 0.14079699633074494,
      "grad_norm": 0.14981791377067566,
      "learning_rate": 4.859203003669255e-05,
      "loss": 0.0066,
      "step": 1650
    },
    {
      "epoch": 0.1416503114600222,
      "grad_norm": 0.5145184397697449,
      "learning_rate": 4.858349688539978e-05,
      "loss": 0.0058,
      "step": 1660
    },
    {
      "epoch": 0.14250362658929944,
      "grad_norm": 0.1473812758922577,
      "learning_rate": 4.857496373410701e-05,
      "loss": 0.0062,
      "step": 1670
    },
    {
      "epoch": 0.14335694171857666,
      "grad_norm": 0.022021153941750526,
      "learning_rate": 4.856643058281424e-05,
      "loss": 0.0055,
      "step": 1680
    },
    {
      "epoch": 0.1442102568478539,
      "grad_norm": 0.11316012591123581,
      "learning_rate": 4.855789743152147e-05,
      "loss": 0.0065,
      "step": 1690
    },
    {
      "epoch": 0.14506357197713116,
      "grad_norm": 0.3668689727783203,
      "learning_rate": 4.8549364280228695e-05,
      "loss": 0.0062,
      "step": 1700
    },
    {
      "epoch": 0.1459168871064084,
      "grad_norm": 0.1841685175895691,
      "learning_rate": 4.8540831128935924e-05,
      "loss": 0.0049,
      "step": 1710
    },
    {
      "epoch": 0.14677020223568563,
      "grad_norm": 0.14784173667430878,
      "learning_rate": 4.8532297977643145e-05,
      "loss": 0.0061,
      "step": 1720
    },
    {
      "epoch": 0.14762351736496288,
      "grad_norm": 0.3672330975532532,
      "learning_rate": 4.8523764826350374e-05,
      "loss": 0.0068,
      "step": 1730
    },
    {
      "epoch": 0.14847683249424012,
      "grad_norm": 0.22050689160823822,
      "learning_rate": 4.8515231675057596e-05,
      "loss": 0.0047,
      "step": 1740
    },
    {
      "epoch": 0.14933014762351737,
      "grad_norm": 0.5141350626945496,
      "learning_rate": 4.8506698523764824e-05,
      "loss": 0.0071,
      "step": 1750
    },
    {
      "epoch": 0.1501834627527946,
      "grad_norm": 0.07554313540458679,
      "learning_rate": 4.849816537247205e-05,
      "loss": 0.0059,
      "step": 1760
    },
    {
      "epoch": 0.15103677788207184,
      "grad_norm": 0.024375712499022484,
      "learning_rate": 4.848963222117928e-05,
      "loss": 0.0069,
      "step": 1770
    },
    {
      "epoch": 0.1518900930113491,
      "grad_norm": 0.14890296757221222,
      "learning_rate": 4.848109906988651e-05,
      "loss": 0.0078,
      "step": 1780
    },
    {
      "epoch": 0.15274340814062634,
      "grad_norm": 0.07586835324764252,
      "learning_rate": 4.847256591859374e-05,
      "loss": 0.0054,
      "step": 1790
    },
    {
      "epoch": 0.15359672326990356,
      "grad_norm": 0.440524160861969,
      "learning_rate": 4.8464032767300967e-05,
      "loss": 0.0053,
      "step": 1800
    },
    {
      "epoch": 0.1544500383991808,
      "grad_norm": 0.3310585916042328,
      "learning_rate": 4.8455499616008195e-05,
      "loss": 0.0057,
      "step": 1810
    },
    {
      "epoch": 0.15530335352845806,
      "grad_norm": 0.0777953639626503,
      "learning_rate": 4.8446966464715423e-05,
      "loss": 0.0053,
      "step": 1820
    },
    {
      "epoch": 0.1561566686577353,
      "grad_norm": 0.40296196937561035,
      "learning_rate": 4.843843331342265e-05,
      "loss": 0.0065,
      "step": 1830
    },
    {
      "epoch": 0.15700998378701253,
      "grad_norm": 0.11065080761909485,
      "learning_rate": 4.8429900162129874e-05,
      "loss": 0.0073,
      "step": 1840
    },
    {
      "epoch": 0.15786329891628978,
      "grad_norm": 0.18488594889640808,
      "learning_rate": 4.84213670108371e-05,
      "loss": 0.0057,
      "step": 1850
    },
    {
      "epoch": 0.15871661404556703,
      "grad_norm": 0.1126706525683403,
      "learning_rate": 4.841283385954433e-05,
      "loss": 0.0054,
      "step": 1860
    },
    {
      "epoch": 0.15956992917484428,
      "grad_norm": 0.3701472580432892,
      "learning_rate": 4.840430070825156e-05,
      "loss": 0.006,
      "step": 1870
    },
    {
      "epoch": 0.1604232443041215,
      "grad_norm": 0.07930353283882141,
      "learning_rate": 4.839576755695879e-05,
      "loss": 0.0062,
      "step": 1880
    },
    {
      "epoch": 0.16127655943339875,
      "grad_norm": 0.5497108697891235,
      "learning_rate": 4.8387234405666016e-05,
      "loss": 0.0062,
      "step": 1890
    },
    {
      "epoch": 0.162129874562676,
      "grad_norm": 0.5132192969322205,
      "learning_rate": 4.8378701254373245e-05,
      "loss": 0.0053,
      "step": 1900
    },
    {
      "epoch": 0.16298318969195325,
      "grad_norm": 0.1849955916404724,
      "learning_rate": 4.837016810308047e-05,
      "loss": 0.0061,
      "step": 1910
    },
    {
      "epoch": 0.1638365048212305,
      "grad_norm": 0.01349809393286705,
      "learning_rate": 4.83616349517877e-05,
      "loss": 0.0057,
      "step": 1920
    },
    {
      "epoch": 0.16468981995050772,
      "grad_norm": 0.014310822822153568,
      "learning_rate": 4.835310180049492e-05,
      "loss": 0.0059,
      "step": 1930
    },
    {
      "epoch": 0.16554313507978496,
      "grad_norm": 0.2933960556983948,
      "learning_rate": 4.834456864920215e-05,
      "loss": 0.0059,
      "step": 1940
    },
    {
      "epoch": 0.1663964502090622,
      "grad_norm": 0.039205241948366165,
      "learning_rate": 4.833603549790938e-05,
      "loss": 0.008,
      "step": 1950
    },
    {
      "epoch": 0.16724976533833946,
      "grad_norm": 0.549710750579834,
      "learning_rate": 4.832750234661661e-05,
      "loss": 0.0051,
      "step": 1960
    },
    {
      "epoch": 0.16810308046761668,
      "grad_norm": 0.039627499878406525,
      "learning_rate": 4.831896919532384e-05,
      "loss": 0.0073,
      "step": 1970
    },
    {
      "epoch": 0.16895639559689393,
      "grad_norm": 0.14700719714164734,
      "learning_rate": 4.8310436044031066e-05,
      "loss": 0.005,
      "step": 1980
    },
    {
      "epoch": 0.16980971072617118,
      "grad_norm": 0.3664418160915375,
      "learning_rate": 4.8301902892738294e-05,
      "loss": 0.006,
      "step": 1990
    },
    {
      "epoch": 0.17066302585544843,
      "grad_norm": 0.5509564280509949,
      "learning_rate": 4.8293369741445516e-05,
      "loss": 0.0065,
      "step": 2000
    },
    {
      "epoch": 0.17151634098472565,
      "grad_norm": 0.013012312352657318,
      "learning_rate": 4.8284836590152744e-05,
      "loss": 0.006,
      "step": 2010
    },
    {
      "epoch": 0.1723696561140029,
      "grad_norm": 0.11365195363759995,
      "learning_rate": 4.827630343885997e-05,
      "loss": 0.0065,
      "step": 2020
    },
    {
      "epoch": 0.17322297124328015,
      "grad_norm": 0.3302225172519684,
      "learning_rate": 4.82677702875672e-05,
      "loss": 0.0072,
      "step": 2030
    },
    {
      "epoch": 0.1740762863725574,
      "grad_norm": 0.013793702237308025,
      "learning_rate": 4.825923713627443e-05,
      "loss": 0.0064,
      "step": 2040
    },
    {
      "epoch": 0.17492960150183462,
      "grad_norm": 0.14868898689746857,
      "learning_rate": 4.825070398498165e-05,
      "loss": 0.0054,
      "step": 2050
    },
    {
      "epoch": 0.17578291663111187,
      "grad_norm": 0.3660691976547241,
      "learning_rate": 4.824217083368888e-05,
      "loss": 0.0062,
      "step": 2060
    },
    {
      "epoch": 0.17663623176038912,
      "grad_norm": 0.4405147135257721,
      "learning_rate": 4.823363768239611e-05,
      "loss": 0.0066,
      "step": 2070
    },
    {
      "epoch": 0.17748954688966637,
      "grad_norm": 0.29315659403800964,
      "learning_rate": 4.822510453110334e-05,
      "loss": 0.0049,
      "step": 2080
    },
    {
      "epoch": 0.1783428620189436,
      "grad_norm": 0.5138176679611206,
      "learning_rate": 4.8216571379810565e-05,
      "loss": 0.0075,
      "step": 2090
    },
    {
      "epoch": 0.17919617714822084,
      "grad_norm": 0.6951965689659119,
      "learning_rate": 4.8208038228517794e-05,
      "loss": 0.0055,
      "step": 2100
    },
    {
      "epoch": 0.18004949227749809,
      "grad_norm": 0.18454203009605408,
      "learning_rate": 4.819950507722502e-05,
      "loss": 0.0056,
      "step": 2110
    },
    {
      "epoch": 0.18090280740677533,
      "grad_norm": 0.07601648569107056,
      "learning_rate": 4.819097192593225e-05,
      "loss": 0.0054,
      "step": 2120
    },
    {
      "epoch": 0.18175612253605256,
      "grad_norm": 0.1830279380083084,
      "learning_rate": 4.818243877463948e-05,
      "loss": 0.0068,
      "step": 2130
    },
    {
      "epoch": 0.1826094376653298,
      "grad_norm": 0.11060457676649094,
      "learning_rate": 4.817390562334671e-05,
      "loss": 0.0081,
      "step": 2140
    },
    {
      "epoch": 0.18346275279460705,
      "grad_norm": 0.018505482003092766,
      "learning_rate": 4.816537247205393e-05,
      "loss": 0.0059,
      "step": 2150
    },
    {
      "epoch": 0.1843160679238843,
      "grad_norm": 0.40258312225341797,
      "learning_rate": 4.815683932076116e-05,
      "loss": 0.0048,
      "step": 2160
    },
    {
      "epoch": 0.18516938305316152,
      "grad_norm": 0.5848596096038818,
      "learning_rate": 4.8148306169468386e-05,
      "loss": 0.0077,
      "step": 2170
    },
    {
      "epoch": 0.18602269818243877,
      "grad_norm": 0.07793435454368591,
      "learning_rate": 4.8139773018175615e-05,
      "loss": 0.007,
      "step": 2180
    },
    {
      "epoch": 0.18687601331171602,
      "grad_norm": 0.25739046931266785,
      "learning_rate": 4.8131239866882843e-05,
      "loss": 0.006,
      "step": 2190
    },
    {
      "epoch": 0.18772932844099327,
      "grad_norm": 0.11093004792928696,
      "learning_rate": 4.812270671559007e-05,
      "loss": 0.0058,
      "step": 2200
    },
    {
      "epoch": 0.1885826435702705,
      "grad_norm": 0.1495787799358368,
      "learning_rate": 4.81141735642973e-05,
      "loss": 0.0068,
      "step": 2210
    },
    {
      "epoch": 0.18943595869954774,
      "grad_norm": 0.3658798635005951,
      "learning_rate": 4.810564041300453e-05,
      "loss": 0.0064,
      "step": 2220
    },
    {
      "epoch": 0.190289273828825,
      "grad_norm": 0.019105765968561172,
      "learning_rate": 4.809710726171176e-05,
      "loss": 0.005,
      "step": 2230
    },
    {
      "epoch": 0.19114258895810224,
      "grad_norm": 0.07796373963356018,
      "learning_rate": 4.808857411041898e-05,
      "loss": 0.007,
      "step": 2240
    },
    {
      "epoch": 0.19199590408737946,
      "grad_norm": 0.08026768267154694,
      "learning_rate": 4.808004095912621e-05,
      "loss": 0.0059,
      "step": 2250
    },
    {
      "epoch": 0.1928492192166567,
      "grad_norm": 0.1842290312051773,
      "learning_rate": 4.807150780783343e-05,
      "loss": 0.0065,
      "step": 2260
    },
    {
      "epoch": 0.19370253434593396,
      "grad_norm": 0.5866492986679077,
      "learning_rate": 4.806297465654066e-05,
      "loss": 0.0075,
      "step": 2270
    },
    {
      "epoch": 0.1945558494752112,
      "grad_norm": 0.5850450992584229,
      "learning_rate": 4.8054441505247886e-05,
      "loss": 0.0049,
      "step": 2280
    },
    {
      "epoch": 0.19540916460448843,
      "grad_norm": 0.2563982307910919,
      "learning_rate": 4.8045908353955115e-05,
      "loss": 0.0068,
      "step": 2290
    },
    {
      "epoch": 0.19626247973376568,
      "grad_norm": 0.04611356928944588,
      "learning_rate": 4.803737520266234e-05,
      "loss": 0.0053,
      "step": 2300
    },
    {
      "epoch": 0.19711579486304293,
      "grad_norm": 0.22040249407291412,
      "learning_rate": 4.802884205136957e-05,
      "loss": 0.0057,
      "step": 2310
    },
    {
      "epoch": 0.19796910999232017,
      "grad_norm": 0.7675521969795227,
      "learning_rate": 4.80203089000768e-05,
      "loss": 0.0061,
      "step": 2320
    },
    {
      "epoch": 0.1988224251215974,
      "grad_norm": 0.08061004430055618,
      "learning_rate": 4.801177574878403e-05,
      "loss": 0.0061,
      "step": 2330
    },
    {
      "epoch": 0.19967574025087464,
      "grad_norm": 0.5860881805419922,
      "learning_rate": 4.800324259749126e-05,
      "loss": 0.0063,
      "step": 2340
    },
    {
      "epoch": 0.2005290553801519,
      "grad_norm": 0.29374709725379944,
      "learning_rate": 4.7994709446198486e-05,
      "loss": 0.0056,
      "step": 2350
    },
    {
      "epoch": 0.20138237050942914,
      "grad_norm": 0.1823197901248932,
      "learning_rate": 4.798617629490571e-05,
      "loss": 0.0064,
      "step": 2360
    },
    {
      "epoch": 0.20223568563870636,
      "grad_norm": 0.25598976016044617,
      "learning_rate": 4.7977643143612936e-05,
      "loss": 0.007,
      "step": 2370
    },
    {
      "epoch": 0.2030890007679836,
      "grad_norm": 0.36705446243286133,
      "learning_rate": 4.7969109992320164e-05,
      "loss": 0.0055,
      "step": 2380
    },
    {
      "epoch": 0.20394231589726086,
      "grad_norm": 0.1465005725622177,
      "learning_rate": 4.796057684102739e-05,
      "loss": 0.0061,
      "step": 2390
    },
    {
      "epoch": 0.2047956310265381,
      "grad_norm": 0.04810256138443947,
      "learning_rate": 4.795204368973462e-05,
      "loss": 0.0068,
      "step": 2400
    },
    {
      "epoch": 0.20564894615581533,
      "grad_norm": 0.1840500384569168,
      "learning_rate": 4.794351053844185e-05,
      "loss": 0.0064,
      "step": 2410
    },
    {
      "epoch": 0.20650226128509258,
      "grad_norm": 0.11126331239938736,
      "learning_rate": 4.793497738714908e-05,
      "loss": 0.0072,
      "step": 2420
    },
    {
      "epoch": 0.20735557641436983,
      "grad_norm": 0.07675020396709442,
      "learning_rate": 4.792644423585631e-05,
      "loss": 0.0081,
      "step": 2430
    },
    {
      "epoch": 0.20820889154364708,
      "grad_norm": 0.11123037338256836,
      "learning_rate": 4.7917911084563535e-05,
      "loss": 0.0075,
      "step": 2440
    },
    {
      "epoch": 0.2090622066729243,
      "grad_norm": 0.32972952723503113,
      "learning_rate": 4.7909377933270764e-05,
      "loss": 0.006,
      "step": 2450
    },
    {
      "epoch": 0.20991552180220155,
      "grad_norm": 0.11228194087743759,
      "learning_rate": 4.7900844781977985e-05,
      "loss": 0.0072,
      "step": 2460
    },
    {
      "epoch": 0.2107688369314788,
      "grad_norm": 0.1477433145046234,
      "learning_rate": 4.7892311630685214e-05,
      "loss": 0.0046,
      "step": 2470
    },
    {
      "epoch": 0.21162215206075605,
      "grad_norm": 0.04278493672609329,
      "learning_rate": 4.788377847939244e-05,
      "loss": 0.0069,
      "step": 2480
    },
    {
      "epoch": 0.21247546719003327,
      "grad_norm": 0.07928258925676346,
      "learning_rate": 4.787524532809967e-05,
      "loss": 0.0055,
      "step": 2490
    },
    {
      "epoch": 0.21332878231931052,
      "grad_norm": 0.1849779337644577,
      "learning_rate": 4.78667121768069e-05,
      "loss": 0.0072,
      "step": 2500
    },
    {
      "epoch": 0.21418209744858777,
      "grad_norm": 0.04265633597970009,
      "learning_rate": 4.785817902551413e-05,
      "loss": 0.0039,
      "step": 2510
    },
    {
      "epoch": 0.21503541257786501,
      "grad_norm": 0.18579193949699402,
      "learning_rate": 4.7849645874221356e-05,
      "loss": 0.0051,
      "step": 2520
    },
    {
      "epoch": 0.21588872770714224,
      "grad_norm": 0.1304657906293869,
      "learning_rate": 4.784111272292858e-05,
      "loss": 0.0052,
      "step": 2530
    },
    {
      "epoch": 0.21674204283641949,
      "grad_norm": 0.11538718640804291,
      "learning_rate": 4.7832579571635806e-05,
      "loss": 0.0058,
      "step": 2540
    },
    {
      "epoch": 0.21759535796569673,
      "grad_norm": 0.1530001014471054,
      "learning_rate": 4.7824046420343035e-05,
      "loss": 0.0056,
      "step": 2550
    },
    {
      "epoch": 0.21844867309497398,
      "grad_norm": 0.7711682319641113,
      "learning_rate": 4.781551326905026e-05,
      "loss": 0.0051,
      "step": 2560
    },
    {
      "epoch": 0.2193019882242512,
      "grad_norm": 0.049538709223270416,
      "learning_rate": 4.7806980117757485e-05,
      "loss": 0.0056,
      "step": 2570
    },
    {
      "epoch": 0.22015530335352845,
      "grad_norm": 0.2967904210090637,
      "learning_rate": 4.7798446966464714e-05,
      "loss": 0.0052,
      "step": 2580
    },
    {
      "epoch": 0.2210086184828057,
      "grad_norm": 0.3691006600856781,
      "learning_rate": 4.778991381517194e-05,
      "loss": 0.0069,
      "step": 2590
    },
    {
      "epoch": 0.22186193361208295,
      "grad_norm": 0.3299610912799835,
      "learning_rate": 4.778138066387917e-05,
      "loss": 0.0053,
      "step": 2600
    },
    {
      "epoch": 0.22271524874136017,
      "grad_norm": 0.12139656394720078,
      "learning_rate": 4.77728475125864e-05,
      "loss": 0.0058,
      "step": 2610
    },
    {
      "epoch": 0.22356856387063742,
      "grad_norm": 0.07337906956672668,
      "learning_rate": 4.776431436129363e-05,
      "loss": 0.0046,
      "step": 2620
    },
    {
      "epoch": 0.22442187899991467,
      "grad_norm": 0.6234703063964844,
      "learning_rate": 4.7755781210000856e-05,
      "loss": 0.0051,
      "step": 2630
    },
    {
      "epoch": 0.22527519412919192,
      "grad_norm": 0.19052556157112122,
      "learning_rate": 4.7747248058708084e-05,
      "loss": 0.0043,
      "step": 2640
    },
    {
      "epoch": 0.22612850925846914,
      "grad_norm": 0.25781458616256714,
      "learning_rate": 4.773871490741531e-05,
      "loss": 0.0055,
      "step": 2650
    },
    {
      "epoch": 0.2269818243877464,
      "grad_norm": 0.20458531379699707,
      "learning_rate": 4.773018175612254e-05,
      "loss": 0.0055,
      "step": 2660
    },
    {
      "epoch": 0.22783513951702364,
      "grad_norm": 0.11325589567422867,
      "learning_rate": 4.772164860482976e-05,
      "loss": 0.0067,
      "step": 2670
    },
    {
      "epoch": 0.2286884546463009,
      "grad_norm": 0.6846793293952942,
      "learning_rate": 4.771311545353699e-05,
      "loss": 0.0058,
      "step": 2680
    },
    {
      "epoch": 0.2295417697755781,
      "grad_norm": 0.061516448855400085,
      "learning_rate": 4.770458230224422e-05,
      "loss": 0.0049,
      "step": 2690
    },
    {
      "epoch": 0.23039508490485536,
      "grad_norm": 0.44407564401626587,
      "learning_rate": 4.769604915095145e-05,
      "loss": 0.0049,
      "step": 2700
    },
    {
      "epoch": 0.2312484000341326,
      "grad_norm": 0.1154354140162468,
      "learning_rate": 4.768751599965868e-05,
      "loss": 0.0058,
      "step": 2710
    },
    {
      "epoch": 0.23210171516340986,
      "grad_norm": 0.24313846230506897,
      "learning_rate": 4.7678982848365906e-05,
      "loss": 0.0049,
      "step": 2720
    },
    {
      "epoch": 0.23295503029268708,
      "grad_norm": 0.042185310274362564,
      "learning_rate": 4.7670449697073134e-05,
      "loss": 0.0054,
      "step": 2730
    },
    {
      "epoch": 0.23380834542196433,
      "grad_norm": 0.11538085341453552,
      "learning_rate": 4.766191654578036e-05,
      "loss": 0.0043,
      "step": 2740
    },
    {
      "epoch": 0.23466166055124157,
      "grad_norm": 0.17100456357002258,
      "learning_rate": 4.765338339448759e-05,
      "loss": 0.0062,
      "step": 2750
    },
    {
      "epoch": 0.23551497568051882,
      "grad_norm": 0.49988994002342224,
      "learning_rate": 4.764485024319482e-05,
      "loss": 0.0058,
      "step": 2760
    },
    {
      "epoch": 0.23636829080979604,
      "grad_norm": 0.2620043158531189,
      "learning_rate": 4.763631709190204e-05,
      "loss": 0.0056,
      "step": 2770
    },
    {
      "epoch": 0.2372216059390733,
      "grad_norm": 0.289699524641037,
      "learning_rate": 4.762778394060927e-05,
      "loss": 0.0074,
      "step": 2780
    },
    {
      "epoch": 0.23807492106835054,
      "grad_norm": 0.6281153559684753,
      "learning_rate": 4.76192507893165e-05,
      "loss": 0.0067,
      "step": 2790
    },
    {
      "epoch": 0.2389282361976278,
      "grad_norm": 0.07589057832956314,
      "learning_rate": 4.761071763802372e-05,
      "loss": 0.0064,
      "step": 2800
    },
    {
      "epoch": 0.239781551326905,
      "grad_norm": 0.26701873540878296,
      "learning_rate": 4.760218448673095e-05,
      "loss": 0.0065,
      "step": 2810
    },
    {
      "epoch": 0.24063486645618226,
      "grad_norm": 0.3899495303630829,
      "learning_rate": 4.759365133543818e-05,
      "loss": 0.0048,
      "step": 2820
    },
    {
      "epoch": 0.2414881815854595,
      "grad_norm": 0.29853567481040955,
      "learning_rate": 4.7585118184145405e-05,
      "loss": 0.0048,
      "step": 2830
    },
    {
      "epoch": 0.24234149671473676,
      "grad_norm": 0.0555981881916523,
      "learning_rate": 4.7576585032852634e-05,
      "loss": 0.0048,
      "step": 2840
    },
    {
      "epoch": 0.24319481184401398,
      "grad_norm": 0.08237271755933762,
      "learning_rate": 4.756805188155986e-05,
      "loss": 0.0048,
      "step": 2850
    },
    {
      "epoch": 0.24404812697329123,
      "grad_norm": 0.47974273562431335,
      "learning_rate": 4.755951873026709e-05,
      "loss": 0.0045,
      "step": 2860
    },
    {
      "epoch": 0.24490144210256848,
      "grad_norm": 0.18924890458583832,
      "learning_rate": 4.755098557897432e-05,
      "loss": 0.0045,
      "step": 2870
    },
    {
      "epoch": 0.24575475723184573,
      "grad_norm": 0.3185204863548279,
      "learning_rate": 4.754245242768154e-05,
      "loss": 0.0053,
      "step": 2880
    },
    {
      "epoch": 0.24660807236112298,
      "grad_norm": 0.036350928246974945,
      "learning_rate": 4.753391927638877e-05,
      "loss": 0.0046,
      "step": 2890
    },
    {
      "epoch": 0.2474613874904002,
      "grad_norm": 0.09024453163146973,
      "learning_rate": 4.7525386125096e-05,
      "loss": 0.0062,
      "step": 2900
    },
    {
      "epoch": 0.24831470261967745,
      "grad_norm": 0.5549489855766296,
      "learning_rate": 4.7516852973803226e-05,
      "loss": 0.0046,
      "step": 2910
    },
    {
      "epoch": 0.2491680177489547,
      "grad_norm": 0.11764134466648102,
      "learning_rate": 4.7508319822510455e-05,
      "loss": 0.0061,
      "step": 2920
    },
    {
      "epoch": 0.2500213328782319,
      "grad_norm": 0.16910287737846375,
      "learning_rate": 4.749978667121768e-05,
      "loss": 0.0051,
      "step": 2930
    },
    {
      "epoch": 0.2508746480075092,
      "grad_norm": 0.11271443963050842,
      "learning_rate": 4.749125351992491e-05,
      "loss": 0.0055,
      "step": 2940
    },
    {
      "epoch": 0.2517279631367864,
      "grad_norm": 0.2809467017650604,
      "learning_rate": 4.748272036863214e-05,
      "loss": 0.0043,
      "step": 2950
    },
    {
      "epoch": 0.25258127826606364,
      "grad_norm": 0.4444855749607086,
      "learning_rate": 4.747418721733937e-05,
      "loss": 0.0048,
      "step": 2960
    },
    {
      "epoch": 0.2534345933953409,
      "grad_norm": 0.24127577245235443,
      "learning_rate": 4.74656540660466e-05,
      "loss": 0.0042,
      "step": 2970
    },
    {
      "epoch": 0.25428790852461813,
      "grad_norm": 0.057118870317935944,
      "learning_rate": 4.745712091475382e-05,
      "loss": 0.0039,
      "step": 2980
    },
    {
      "epoch": 0.2551412236538954,
      "grad_norm": 0.13873682916164398,
      "learning_rate": 4.744858776346105e-05,
      "loss": 0.0051,
      "step": 2990
    },
    {
      "epoch": 0.25599453878317263,
      "grad_norm": 0.38815903663635254,
      "learning_rate": 4.7440054612168276e-05,
      "loss": 0.0057,
      "step": 3000
    },
    {
      "epoch": 0.25684785391244985,
      "grad_norm": 0.5889831185340881,
      "learning_rate": 4.7431521460875504e-05,
      "loss": 0.0043,
      "step": 3010
    },
    {
      "epoch": 0.25770116904172713,
      "grad_norm": 0.16261403262615204,
      "learning_rate": 4.742298830958273e-05,
      "loss": 0.0053,
      "step": 3020
    },
    {
      "epoch": 0.25855448417100435,
      "grad_norm": 0.22770479321479797,
      "learning_rate": 4.741445515828996e-05,
      "loss": 0.0059,
      "step": 3030
    },
    {
      "epoch": 0.25940779930028157,
      "grad_norm": 0.664757490158081,
      "learning_rate": 4.740592200699719e-05,
      "loss": 0.0045,
      "step": 3040
    },
    {
      "epoch": 0.26026111442955885,
      "grad_norm": 0.44221118092536926,
      "learning_rate": 4.739738885570442e-05,
      "loss": 0.0052,
      "step": 3050
    },
    {
      "epoch": 0.26111442955883607,
      "grad_norm": 0.4046976566314697,
      "learning_rate": 4.738885570441164e-05,
      "loss": 0.0062,
      "step": 3060
    },
    {
      "epoch": 0.26196774468811335,
      "grad_norm": 0.33570677042007446,
      "learning_rate": 4.738032255311887e-05,
      "loss": 0.0059,
      "step": 3070
    },
    {
      "epoch": 0.26282105981739057,
      "grad_norm": 0.061897408217191696,
      "learning_rate": 4.73717894018261e-05,
      "loss": 0.0051,
      "step": 3080
    },
    {
      "epoch": 0.2636743749466678,
      "grad_norm": 0.08589724451303482,
      "learning_rate": 4.7363256250533325e-05,
      "loss": 0.0054,
      "step": 3090
    },
    {
      "epoch": 0.26452769007594507,
      "grad_norm": 0.3364790976047516,
      "learning_rate": 4.735472309924055e-05,
      "loss": 0.0049,
      "step": 3100
    },
    {
      "epoch": 0.2653810052052223,
      "grad_norm": 0.2597815692424774,
      "learning_rate": 4.7346189947947776e-05,
      "loss": 0.0063,
      "step": 3110
    },
    {
      "epoch": 0.2662343203344995,
      "grad_norm": 0.12639391422271729,
      "learning_rate": 4.7337656796655004e-05,
      "loss": 0.0046,
      "step": 3120
    },
    {
      "epoch": 0.2670876354637768,
      "grad_norm": 0.06645799428224564,
      "learning_rate": 4.732912364536223e-05,
      "loss": 0.0043,
      "step": 3130
    },
    {
      "epoch": 0.267940950593054,
      "grad_norm": 0.35253623127937317,
      "learning_rate": 4.732059049406946e-05,
      "loss": 0.0051,
      "step": 3140
    },
    {
      "epoch": 0.2687942657223313,
      "grad_norm": 0.07513978332281113,
      "learning_rate": 4.731205734277669e-05,
      "loss": 0.0062,
      "step": 3150
    },
    {
      "epoch": 0.2696475808516085,
      "grad_norm": 0.0997529998421669,
      "learning_rate": 4.730352419148392e-05,
      "loss": 0.0062,
      "step": 3160
    },
    {
      "epoch": 0.2705008959808857,
      "grad_norm": 0.20836187899112701,
      "learning_rate": 4.7294991040191147e-05,
      "loss": 0.0057,
      "step": 3170
    },
    {
      "epoch": 0.271354211110163,
      "grad_norm": 0.33385321497917175,
      "learning_rate": 4.7286457888898375e-05,
      "loss": 0.0044,
      "step": 3180
    },
    {
      "epoch": 0.2722075262394402,
      "grad_norm": 0.22595319151878357,
      "learning_rate": 4.72779247376056e-05,
      "loss": 0.0042,
      "step": 3190
    },
    {
      "epoch": 0.27306084136871744,
      "grad_norm": 0.09124191850423813,
      "learning_rate": 4.7269391586312825e-05,
      "loss": 0.0044,
      "step": 3200
    },
    {
      "epoch": 0.2739141564979947,
      "grad_norm": 0.06619644910097122,
      "learning_rate": 4.7260858435020054e-05,
      "loss": 0.0053,
      "step": 3210
    },
    {
      "epoch": 0.27476747162727194,
      "grad_norm": 0.4530750513076782,
      "learning_rate": 4.725232528372728e-05,
      "loss": 0.0046,
      "step": 3220
    },
    {
      "epoch": 0.2756207867565492,
      "grad_norm": 0.1148037537932396,
      "learning_rate": 4.724379213243451e-05,
      "loss": 0.0048,
      "step": 3230
    },
    {
      "epoch": 0.27647410188582644,
      "grad_norm": 0.29924580454826355,
      "learning_rate": 4.723525898114174e-05,
      "loss": 0.006,
      "step": 3240
    },
    {
      "epoch": 0.27732741701510366,
      "grad_norm": 0.13034576177597046,
      "learning_rate": 4.722672582984897e-05,
      "loss": 0.0047,
      "step": 3250
    },
    {
      "epoch": 0.27818073214438094,
      "grad_norm": 0.3027571737766266,
      "learning_rate": 4.7218192678556196e-05,
      "loss": 0.0047,
      "step": 3260
    },
    {
      "epoch": 0.27903404727365816,
      "grad_norm": 0.032723359763622284,
      "learning_rate": 4.7209659527263425e-05,
      "loss": 0.0047,
      "step": 3270
    },
    {
      "epoch": 0.2798873624029354,
      "grad_norm": 0.1766570806503296,
      "learning_rate": 4.720112637597065e-05,
      "loss": 0.0054,
      "step": 3280
    },
    {
      "epoch": 0.28074067753221266,
      "grad_norm": 0.2955736517906189,
      "learning_rate": 4.7192593224677875e-05,
      "loss": 0.0049,
      "step": 3290
    },
    {
      "epoch": 0.2815939926614899,
      "grad_norm": 0.06052947789430618,
      "learning_rate": 4.71840600733851e-05,
      "loss": 0.0058,
      "step": 3300
    },
    {
      "epoch": 0.28244730779076715,
      "grad_norm": 0.22230510413646698,
      "learning_rate": 4.717552692209233e-05,
      "loss": 0.0043,
      "step": 3310
    },
    {
      "epoch": 0.2833006229200444,
      "grad_norm": 0.07980544120073318,
      "learning_rate": 4.716699377079956e-05,
      "loss": 0.0052,
      "step": 3320
    },
    {
      "epoch": 0.2841539380493216,
      "grad_norm": 0.4107753336429596,
      "learning_rate": 4.715846061950678e-05,
      "loss": 0.0064,
      "step": 3330
    },
    {
      "epoch": 0.2850072531785989,
      "grad_norm": 0.2262134999036789,
      "learning_rate": 4.714992746821401e-05,
      "loss": 0.0055,
      "step": 3340
    },
    {
      "epoch": 0.2858605683078761,
      "grad_norm": 0.4278511106967926,
      "learning_rate": 4.714139431692124e-05,
      "loss": 0.0049,
      "step": 3350
    },
    {
      "epoch": 0.2867138834371533,
      "grad_norm": 0.12936612963676453,
      "learning_rate": 4.713286116562847e-05,
      "loss": 0.0047,
      "step": 3360
    },
    {
      "epoch": 0.2875671985664306,
      "grad_norm": 0.12079697102308273,
      "learning_rate": 4.7124328014335696e-05,
      "loss": 0.0046,
      "step": 3370
    },
    {
      "epoch": 0.2884205136957078,
      "grad_norm": 0.14843957126140594,
      "learning_rate": 4.7115794863042924e-05,
      "loss": 0.0047,
      "step": 3380
    },
    {
      "epoch": 0.2892738288249851,
      "grad_norm": 0.044671304523944855,
      "learning_rate": 4.710726171175015e-05,
      "loss": 0.0051,
      "step": 3390
    },
    {
      "epoch": 0.2901271439542623,
      "grad_norm": 0.11358928680419922,
      "learning_rate": 4.709872856045738e-05,
      "loss": 0.0048,
      "step": 3400
    },
    {
      "epoch": 0.29098045908353953,
      "grad_norm": 0.42624661326408386,
      "learning_rate": 4.70901954091646e-05,
      "loss": 0.004,
      "step": 3410
    },
    {
      "epoch": 0.2918337742128168,
      "grad_norm": 0.28456035256385803,
      "learning_rate": 4.708166225787183e-05,
      "loss": 0.0051,
      "step": 3420
    },
    {
      "epoch": 0.29268708934209403,
      "grad_norm": 0.07983238250017166,
      "learning_rate": 4.707312910657906e-05,
      "loss": 0.0052,
      "step": 3430
    },
    {
      "epoch": 0.29354040447137125,
      "grad_norm": 0.15121687948703766,
      "learning_rate": 4.706459595528629e-05,
      "loss": 0.0043,
      "step": 3440
    },
    {
      "epoch": 0.29439371960064853,
      "grad_norm": 0.37633296847343445,
      "learning_rate": 4.705606280399352e-05,
      "loss": 0.0056,
      "step": 3450
    },
    {
      "epoch": 0.29524703472992575,
      "grad_norm": 0.10103651881217957,
      "learning_rate": 4.7047529652700745e-05,
      "loss": 0.0052,
      "step": 3460
    },
    {
      "epoch": 0.296100349859203,
      "grad_norm": 0.5395042300224304,
      "learning_rate": 4.7038996501407974e-05,
      "loss": 0.0052,
      "step": 3470
    },
    {
      "epoch": 0.29695366498848025,
      "grad_norm": 0.3004615008831024,
      "learning_rate": 4.70304633501152e-05,
      "loss": 0.0049,
      "step": 3480
    },
    {
      "epoch": 0.29780698011775747,
      "grad_norm": 0.0324520580470562,
      "learning_rate": 4.702193019882243e-05,
      "loss": 0.0049,
      "step": 3490
    },
    {
      "epoch": 0.29866029524703475,
      "grad_norm": 0.48215451836586,
      "learning_rate": 4.701339704752965e-05,
      "loss": 0.0046,
      "step": 3500
    },
    {
      "epoch": 0.29951361037631197,
      "grad_norm": 0.07163707166910172,
      "learning_rate": 4.700486389623688e-05,
      "loss": 0.0057,
      "step": 3510
    },
    {
      "epoch": 0.3003669255055892,
      "grad_norm": 0.18720583617687225,
      "learning_rate": 4.699633074494411e-05,
      "loss": 0.0053,
      "step": 3520
    },
    {
      "epoch": 0.30122024063486647,
      "grad_norm": 0.4066576361656189,
      "learning_rate": 4.698779759365134e-05,
      "loss": 0.0043,
      "step": 3530
    },
    {
      "epoch": 0.3020735557641437,
      "grad_norm": 0.02948349341750145,
      "learning_rate": 4.6979264442358567e-05,
      "loss": 0.006,
      "step": 3540
    },
    {
      "epoch": 0.30292687089342096,
      "grad_norm": 0.016571762040257454,
      "learning_rate": 4.6970731291065795e-05,
      "loss": 0.0043,
      "step": 3550
    },
    {
      "epoch": 0.3037801860226982,
      "grad_norm": 0.08232516795396805,
      "learning_rate": 4.6962198139773023e-05,
      "loss": 0.006,
      "step": 3560
    },
    {
      "epoch": 0.3046335011519754,
      "grad_norm": 0.37437668442726135,
      "learning_rate": 4.695366498848025e-05,
      "loss": 0.0057,
      "step": 3570
    },
    {
      "epoch": 0.3054868162812527,
      "grad_norm": 0.22414730489253998,
      "learning_rate": 4.694513183718748e-05,
      "loss": 0.0058,
      "step": 3580
    },
    {
      "epoch": 0.3063401314105299,
      "grad_norm": 0.12020375579595566,
      "learning_rate": 4.69365986858947e-05,
      "loss": 0.0049,
      "step": 3590
    },
    {
      "epoch": 0.3071934465398071,
      "grad_norm": 0.12526915967464447,
      "learning_rate": 4.692806553460193e-05,
      "loss": 0.0048,
      "step": 3600
    },
    {
      "epoch": 0.3080467616690844,
      "grad_norm": 0.04481462016701698,
      "learning_rate": 4.691953238330916e-05,
      "loss": 0.0054,
      "step": 3610
    },
    {
      "epoch": 0.3089000767983616,
      "grad_norm": 0.5173119902610779,
      "learning_rate": 4.691099923201638e-05,
      "loss": 0.0046,
      "step": 3620
    },
    {
      "epoch": 0.3097533919276389,
      "grad_norm": 0.13664516806602478,
      "learning_rate": 4.690246608072361e-05,
      "loss": 0.005,
      "step": 3630
    },
    {
      "epoch": 0.3106067070569161,
      "grad_norm": 0.265907883644104,
      "learning_rate": 4.689393292943084e-05,
      "loss": 0.0058,
      "step": 3640
    },
    {
      "epoch": 0.31146002218619334,
      "grad_norm": 0.249297633767128,
      "learning_rate": 4.6885399778138066e-05,
      "loss": 0.0063,
      "step": 3650
    },
    {
      "epoch": 0.3123133373154706,
      "grad_norm": 0.26173609495162964,
      "learning_rate": 4.6876866626845295e-05,
      "loss": 0.0055,
      "step": 3660
    },
    {
      "epoch": 0.31316665244474784,
      "grad_norm": 0.09731022268533707,
      "learning_rate": 4.686833347555252e-05,
      "loss": 0.0046,
      "step": 3670
    },
    {
      "epoch": 0.31401996757402506,
      "grad_norm": 0.22880282998085022,
      "learning_rate": 4.685980032425975e-05,
      "loss": 0.0055,
      "step": 3680
    },
    {
      "epoch": 0.31487328270330234,
      "grad_norm": 0.21568594872951508,
      "learning_rate": 4.685126717296698e-05,
      "loss": 0.0058,
      "step": 3690
    },
    {
      "epoch": 0.31572659783257956,
      "grad_norm": 0.2691507637500763,
      "learning_rate": 4.684273402167421e-05,
      "loss": 0.005,
      "step": 3700
    },
    {
      "epoch": 0.31657991296185684,
      "grad_norm": 0.26728418469429016,
      "learning_rate": 4.683420087038144e-05,
      "loss": 0.0035,
      "step": 3710
    },
    {
      "epoch": 0.31743322809113406,
      "grad_norm": 0.31964269280433655,
      "learning_rate": 4.682566771908866e-05,
      "loss": 0.004,
      "step": 3720
    },
    {
      "epoch": 0.3182865432204113,
      "grad_norm": 0.11657934635877609,
      "learning_rate": 4.681713456779589e-05,
      "loss": 0.0052,
      "step": 3730
    },
    {
      "epoch": 0.31913985834968855,
      "grad_norm": 0.23496538400650024,
      "learning_rate": 4.6808601416503116e-05,
      "loss": 0.0048,
      "step": 3740
    },
    {
      "epoch": 0.3199931734789658,
      "grad_norm": 0.35631605982780457,
      "learning_rate": 4.6800068265210344e-05,
      "loss": 0.0052,
      "step": 3750
    },
    {
      "epoch": 0.320846488608243,
      "grad_norm": 0.2099716067314148,
      "learning_rate": 4.679153511391757e-05,
      "loss": 0.0044,
      "step": 3760
    },
    {
      "epoch": 0.3216998037375203,
      "grad_norm": 0.21959814429283142,
      "learning_rate": 4.67830019626248e-05,
      "loss": 0.0055,
      "step": 3770
    },
    {
      "epoch": 0.3225531188667975,
      "grad_norm": 0.1223553717136383,
      "learning_rate": 4.677446881133203e-05,
      "loss": 0.0045,
      "step": 3780
    },
    {
      "epoch": 0.32340643399607477,
      "grad_norm": 0.32031387090682983,
      "learning_rate": 4.676593566003926e-05,
      "loss": 0.0046,
      "step": 3790
    },
    {
      "epoch": 0.324259749125352,
      "grad_norm": 0.4542677104473114,
      "learning_rate": 4.675740250874649e-05,
      "loss": 0.0053,
      "step": 3800
    },
    {
      "epoch": 0.3251130642546292,
      "grad_norm": 0.11976392567157745,
      "learning_rate": 4.674886935745371e-05,
      "loss": 0.0052,
      "step": 3810
    },
    {
      "epoch": 0.3259663793839065,
      "grad_norm": 0.15655362606048584,
      "learning_rate": 4.674033620616094e-05,
      "loss": 0.005,
      "step": 3820
    },
    {
      "epoch": 0.3268196945131837,
      "grad_norm": 0.6522917747497559,
      "learning_rate": 4.6731803054868165e-05,
      "loss": 0.0047,
      "step": 3830
    },
    {
      "epoch": 0.327673009642461,
      "grad_norm": 0.2825736105442047,
      "learning_rate": 4.6723269903575394e-05,
      "loss": 0.0043,
      "step": 3840
    },
    {
      "epoch": 0.3285263247717382,
      "grad_norm": 0.14917592704296112,
      "learning_rate": 4.671473675228262e-05,
      "loss": 0.0047,
      "step": 3850
    },
    {
      "epoch": 0.32937963990101543,
      "grad_norm": 0.4502727687358856,
      "learning_rate": 4.6706203600989844e-05,
      "loss": 0.0048,
      "step": 3860
    },
    {
      "epoch": 0.3302329550302927,
      "grad_norm": 0.07999192178249359,
      "learning_rate": 4.669767044969707e-05,
      "loss": 0.006,
      "step": 3870
    },
    {
      "epoch": 0.33108627015956993,
      "grad_norm": 0.4150938093662262,
      "learning_rate": 4.66891372984043e-05,
      "loss": 0.0047,
      "step": 3880
    },
    {
      "epoch": 0.33193958528884715,
      "grad_norm": 0.05942646414041519,
      "learning_rate": 4.668060414711153e-05,
      "loss": 0.0055,
      "step": 3890
    },
    {
      "epoch": 0.3327929004181244,
      "grad_norm": 0.21948309242725372,
      "learning_rate": 4.667207099581876e-05,
      "loss": 0.0045,
      "step": 3900
    },
    {
      "epoch": 0.33364621554740165,
      "grad_norm": 0.31763094663619995,
      "learning_rate": 4.6663537844525986e-05,
      "loss": 0.0057,
      "step": 3910
    },
    {
      "epoch": 0.3344995306766789,
      "grad_norm": 0.2992003858089447,
      "learning_rate": 4.6655004693233215e-05,
      "loss": 0.0046,
      "step": 3920
    },
    {
      "epoch": 0.33535284580595615,
      "grad_norm": 0.23082438111305237,
      "learning_rate": 4.664647154194044e-05,
      "loss": 0.0052,
      "step": 3930
    },
    {
      "epoch": 0.33620616093523337,
      "grad_norm": 0.3753383159637451,
      "learning_rate": 4.6637938390647665e-05,
      "loss": 0.0064,
      "step": 3940
    },
    {
      "epoch": 0.33705947606451064,
      "grad_norm": 0.2540079653263092,
      "learning_rate": 4.6629405239354894e-05,
      "loss": 0.0051,
      "step": 3950
    },
    {
      "epoch": 0.33791279119378786,
      "grad_norm": 0.6174007058143616,
      "learning_rate": 4.662087208806212e-05,
      "loss": 0.0046,
      "step": 3960
    },
    {
      "epoch": 0.3387661063230651,
      "grad_norm": 0.15567737817764282,
      "learning_rate": 4.661233893676935e-05,
      "loss": 0.0054,
      "step": 3970
    },
    {
      "epoch": 0.33961942145234236,
      "grad_norm": 0.06043403968214989,
      "learning_rate": 4.660380578547658e-05,
      "loss": 0.0041,
      "step": 3980
    },
    {
      "epoch": 0.3404727365816196,
      "grad_norm": 0.541199266910553,
      "learning_rate": 4.659527263418381e-05,
      "loss": 0.0055,
      "step": 3990
    },
    {
      "epoch": 0.34132605171089686,
      "grad_norm": 0.18881171941757202,
      "learning_rate": 4.6586739482891036e-05,
      "loss": 0.0053,
      "step": 4000
    },
    {
      "epoch": 0.3421793668401741,
      "grad_norm": 0.13234923779964447,
      "learning_rate": 4.6578206331598265e-05,
      "loss": 0.0047,
      "step": 4010
    },
    {
      "epoch": 0.3430326819694513,
      "grad_norm": 0.21151117980480194,
      "learning_rate": 4.656967318030549e-05,
      "loss": 0.0045,
      "step": 4020
    },
    {
      "epoch": 0.3438859970987286,
      "grad_norm": 0.02607964538037777,
      "learning_rate": 4.6561140029012715e-05,
      "loss": 0.0041,
      "step": 4030
    },
    {
      "epoch": 0.3447393122280058,
      "grad_norm": 0.19500160217285156,
      "learning_rate": 4.655260687771994e-05,
      "loss": 0.003,
      "step": 4040
    },
    {
      "epoch": 0.345592627357283,
      "grad_norm": 0.2442512959241867,
      "learning_rate": 4.654407372642717e-05,
      "loss": 0.0059,
      "step": 4050
    },
    {
      "epoch": 0.3464459424865603,
      "grad_norm": 0.0974610447883606,
      "learning_rate": 4.65355405751344e-05,
      "loss": 0.0049,
      "step": 4060
    },
    {
      "epoch": 0.3472992576158375,
      "grad_norm": 0.26204222440719604,
      "learning_rate": 4.652700742384163e-05,
      "loss": 0.0042,
      "step": 4070
    },
    {
      "epoch": 0.3481525727451148,
      "grad_norm": 0.22887150943279266,
      "learning_rate": 4.651847427254886e-05,
      "loss": 0.0048,
      "step": 4080
    },
    {
      "epoch": 0.349005887874392,
      "grad_norm": 0.3800404667854309,
      "learning_rate": 4.6509941121256086e-05,
      "loss": 0.0043,
      "step": 4090
    },
    {
      "epoch": 0.34985920300366924,
      "grad_norm": 0.17768584191799164,
      "learning_rate": 4.6501407969963314e-05,
      "loss": 0.0052,
      "step": 4100
    },
    {
      "epoch": 0.3507125181329465,
      "grad_norm": 0.7923965454101562,
      "learning_rate": 4.649287481867054e-05,
      "loss": 0.0047,
      "step": 4110
    },
    {
      "epoch": 0.35156583326222374,
      "grad_norm": 0.37696677446365356,
      "learning_rate": 4.6484341667377764e-05,
      "loss": 0.0054,
      "step": 4120
    },
    {
      "epoch": 0.35241914839150096,
      "grad_norm": 0.07955992221832275,
      "learning_rate": 4.647580851608499e-05,
      "loss": 0.0055,
      "step": 4130
    },
    {
      "epoch": 0.35327246352077823,
      "grad_norm": 0.35874444246292114,
      "learning_rate": 4.6467275364792214e-05,
      "loss": 0.0054,
      "step": 4140
    },
    {
      "epoch": 0.35412577865005546,
      "grad_norm": 0.20698218047618866,
      "learning_rate": 4.645874221349944e-05,
      "loss": 0.0044,
      "step": 4150
    },
    {
      "epoch": 0.35497909377933273,
      "grad_norm": 0.36108309030532837,
      "learning_rate": 4.645020906220667e-05,
      "loss": 0.0052,
      "step": 4160
    },
    {
      "epoch": 0.35583240890860995,
      "grad_norm": 0.5612637400627136,
      "learning_rate": 4.64416759109139e-05,
      "loss": 0.0055,
      "step": 4170
    },
    {
      "epoch": 0.3566857240378872,
      "grad_norm": 0.09276269376277924,
      "learning_rate": 4.643314275962113e-05,
      "loss": 0.0045,
      "step": 4180
    },
    {
      "epoch": 0.35753903916716445,
      "grad_norm": 0.3062191307544708,
      "learning_rate": 4.642460960832836e-05,
      "loss": 0.005,
      "step": 4190
    },
    {
      "epoch": 0.3583923542964417,
      "grad_norm": 0.05643994361162186,
      "learning_rate": 4.6416076457035585e-05,
      "loss": 0.0046,
      "step": 4200
    },
    {
      "epoch": 0.3592456694257189,
      "grad_norm": 0.2764403522014618,
      "learning_rate": 4.6407543305742814e-05,
      "loss": 0.0031,
      "step": 4210
    },
    {
      "epoch": 0.36009898455499617,
      "grad_norm": 0.3408753573894501,
      "learning_rate": 4.639901015445004e-05,
      "loss": 0.0043,
      "step": 4220
    },
    {
      "epoch": 0.3609522996842734,
      "grad_norm": 0.19464607536792755,
      "learning_rate": 4.639047700315727e-05,
      "loss": 0.0041,
      "step": 4230
    },
    {
      "epoch": 0.36180561481355067,
      "grad_norm": 0.16193415224552155,
      "learning_rate": 4.638194385186449e-05,
      "loss": 0.0067,
      "step": 4240
    },
    {
      "epoch": 0.3626589299428279,
      "grad_norm": 0.09890756756067276,
      "learning_rate": 4.637341070057172e-05,
      "loss": 0.0048,
      "step": 4250
    },
    {
      "epoch": 0.3635122450721051,
      "grad_norm": 0.07767641544342041,
      "learning_rate": 4.636487754927895e-05,
      "loss": 0.0054,
      "step": 4260
    },
    {
      "epoch": 0.3643655602013824,
      "grad_norm": 0.15781639516353607,
      "learning_rate": 4.635634439798618e-05,
      "loss": 0.0056,
      "step": 4270
    },
    {
      "epoch": 0.3652188753306596,
      "grad_norm": 0.11332152783870697,
      "learning_rate": 4.6347811246693406e-05,
      "loss": 0.0048,
      "step": 4280
    },
    {
      "epoch": 0.36607219045993683,
      "grad_norm": 0.2449532151222229,
      "learning_rate": 4.6339278095400635e-05,
      "loss": 0.0053,
      "step": 4290
    },
    {
      "epoch": 0.3669255055892141,
      "grad_norm": 0.08139332383871078,
      "learning_rate": 4.633074494410786e-05,
      "loss": 0.004,
      "step": 4300
    },
    {
      "epoch": 0.36777882071849133,
      "grad_norm": 0.22608180344104767,
      "learning_rate": 4.632221179281509e-05,
      "loss": 0.0047,
      "step": 4310
    },
    {
      "epoch": 0.3686321358477686,
      "grad_norm": 0.05510925129055977,
      "learning_rate": 4.631367864152232e-05,
      "loss": 0.0063,
      "step": 4320
    },
    {
      "epoch": 0.3694854509770458,
      "grad_norm": 0.7330483794212341,
      "learning_rate": 4.630514549022955e-05,
      "loss": 0.0045,
      "step": 4330
    },
    {
      "epoch": 0.37033876610632305,
      "grad_norm": 0.36991697549819946,
      "learning_rate": 4.629661233893677e-05,
      "loss": 0.0048,
      "step": 4340
    },
    {
      "epoch": 0.3711920812356003,
      "grad_norm": 0.11180213838815689,
      "learning_rate": 4.6288079187644e-05,
      "loss": 0.0048,
      "step": 4350
    },
    {
      "epoch": 0.37204539636487755,
      "grad_norm": 0.1501602828502655,
      "learning_rate": 4.627954603635123e-05,
      "loss": 0.005,
      "step": 4360
    },
    {
      "epoch": 0.37289871149415477,
      "grad_norm": 0.5246448516845703,
      "learning_rate": 4.6271012885058456e-05,
      "loss": 0.0043,
      "step": 4370
    },
    {
      "epoch": 0.37375202662343204,
      "grad_norm": 0.4127773344516754,
      "learning_rate": 4.6262479733765684e-05,
      "loss": 0.0041,
      "step": 4380
    },
    {
      "epoch": 0.37460534175270926,
      "grad_norm": 0.3002069592475891,
      "learning_rate": 4.6253946582472906e-05,
      "loss": 0.0049,
      "step": 4390
    },
    {
      "epoch": 0.37545865688198654,
      "grad_norm": 0.06138721853494644,
      "learning_rate": 4.6245413431180135e-05,
      "loss": 0.0053,
      "step": 4400
    },
    {
      "epoch": 0.37631197201126376,
      "grad_norm": 0.109555184841156,
      "learning_rate": 4.623688027988736e-05,
      "loss": 0.0042,
      "step": 4410
    },
    {
      "epoch": 0.377165287140541,
      "grad_norm": 0.1263173520565033,
      "learning_rate": 4.622834712859459e-05,
      "loss": 0.0048,
      "step": 4420
    },
    {
      "epoch": 0.37801860226981826,
      "grad_norm": 0.6359121799468994,
      "learning_rate": 4.621981397730182e-05,
      "loss": 0.005,
      "step": 4430
    },
    {
      "epoch": 0.3788719173990955,
      "grad_norm": 0.18599066138267517,
      "learning_rate": 4.621128082600905e-05,
      "loss": 0.0053,
      "step": 4440
    },
    {
      "epoch": 0.3797252325283727,
      "grad_norm": 0.6931917071342468,
      "learning_rate": 4.620274767471627e-05,
      "loss": 0.0047,
      "step": 4450
    },
    {
      "epoch": 0.38057854765765,
      "grad_norm": 0.13375094532966614,
      "learning_rate": 4.61942145234235e-05,
      "loss": 0.0053,
      "step": 4460
    },
    {
      "epoch": 0.3814318627869272,
      "grad_norm": 0.38575324416160583,
      "learning_rate": 4.618568137213073e-05,
      "loss": 0.0043,
      "step": 4470
    },
    {
      "epoch": 0.3822851779162045,
      "grad_norm": 0.5383170247077942,
      "learning_rate": 4.6177148220837956e-05,
      "loss": 0.0042,
      "step": 4480
    },
    {
      "epoch": 0.3831384930454817,
      "grad_norm": 0.3760001063346863,
      "learning_rate": 4.6168615069545184e-05,
      "loss": 0.0043,
      "step": 4490
    },
    {
      "epoch": 0.3839918081747589,
      "grad_norm": 0.5596762299537659,
      "learning_rate": 4.616008191825241e-05,
      "loss": 0.0043,
      "step": 4500
    },
    {
      "epoch": 0.3848451233040362,
      "grad_norm": 0.6734135746955872,
      "learning_rate": 4.615154876695964e-05,
      "loss": 0.0059,
      "step": 4510
    },
    {
      "epoch": 0.3856984384333134,
      "grad_norm": 0.1182858869433403,
      "learning_rate": 4.614301561566687e-05,
      "loss": 0.005,
      "step": 4520
    },
    {
      "epoch": 0.38655175356259064,
      "grad_norm": 0.118707574903965,
      "learning_rate": 4.61344824643741e-05,
      "loss": 0.0043,
      "step": 4530
    },
    {
      "epoch": 0.3874050686918679,
      "grad_norm": 0.3020711839199066,
      "learning_rate": 4.612594931308133e-05,
      "loss": 0.0055,
      "step": 4540
    },
    {
      "epoch": 0.38825838382114514,
      "grad_norm": 0.34354400634765625,
      "learning_rate": 4.611741616178855e-05,
      "loss": 0.0046,
      "step": 4550
    },
    {
      "epoch": 0.3891116989504224,
      "grad_norm": 0.22950129210948944,
      "learning_rate": 4.610888301049578e-05,
      "loss": 0.0044,
      "step": 4560
    },
    {
      "epoch": 0.38996501407969963,
      "grad_norm": 0.20581091940402985,
      "learning_rate": 4.6100349859203005e-05,
      "loss": 0.0054,
      "step": 4570
    },
    {
      "epoch": 0.39081832920897686,
      "grad_norm": 0.232652485370636,
      "learning_rate": 4.6091816707910234e-05,
      "loss": 0.005,
      "step": 4580
    },
    {
      "epoch": 0.39167164433825413,
      "grad_norm": 0.07332009077072144,
      "learning_rate": 4.608328355661746e-05,
      "loss": 0.0063,
      "step": 4590
    },
    {
      "epoch": 0.39252495946753135,
      "grad_norm": 0.0955384373664856,
      "learning_rate": 4.607475040532469e-05,
      "loss": 0.0043,
      "step": 4600
    },
    {
      "epoch": 0.3933782745968086,
      "grad_norm": 0.3026178181171417,
      "learning_rate": 4.606621725403192e-05,
      "loss": 0.006,
      "step": 4610
    },
    {
      "epoch": 0.39423158972608585,
      "grad_norm": 0.02862359955906868,
      "learning_rate": 4.605768410273915e-05,
      "loss": 0.0036,
      "step": 4620
    },
    {
      "epoch": 0.3950849048553631,
      "grad_norm": 0.0959986224770546,
      "learning_rate": 4.6049150951446376e-05,
      "loss": 0.0044,
      "step": 4630
    },
    {
      "epoch": 0.39593821998464035,
      "grad_norm": 0.3770315945148468,
      "learning_rate": 4.6040617800153605e-05,
      "loss": 0.0059,
      "step": 4640
    },
    {
      "epoch": 0.39679153511391757,
      "grad_norm": 0.19304156303405762,
      "learning_rate": 4.6032084648860826e-05,
      "loss": 0.0053,
      "step": 4650
    },
    {
      "epoch": 0.3976448502431948,
      "grad_norm": 0.30212217569351196,
      "learning_rate": 4.6023551497568055e-05,
      "loss": 0.0055,
      "step": 4660
    },
    {
      "epoch": 0.39849816537247207,
      "grad_norm": 0.24241691827774048,
      "learning_rate": 4.6015018346275277e-05,
      "loss": 0.0053,
      "step": 4670
    },
    {
      "epoch": 0.3993514805017493,
      "grad_norm": 0.3926009237766266,
      "learning_rate": 4.6006485194982505e-05,
      "loss": 0.0057,
      "step": 4680
    },
    {
      "epoch": 0.4002047956310265,
      "grad_norm": 0.22509394586086273,
      "learning_rate": 4.5997952043689734e-05,
      "loss": 0.0052,
      "step": 4690
    },
    {
      "epoch": 0.4010581107603038,
      "grad_norm": 0.4365385174751282,
      "learning_rate": 4.598941889239696e-05,
      "loss": 0.0046,
      "step": 4700
    },
    {
      "epoch": 0.401911425889581,
      "grad_norm": 0.29807791113853455,
      "learning_rate": 4.598088574110419e-05,
      "loss": 0.0036,
      "step": 4710
    },
    {
      "epoch": 0.4027647410188583,
      "grad_norm": 0.1381881833076477,
      "learning_rate": 4.597235258981142e-05,
      "loss": 0.0035,
      "step": 4720
    },
    {
      "epoch": 0.4036180561481355,
      "grad_norm": 0.15157029032707214,
      "learning_rate": 4.596381943851865e-05,
      "loss": 0.005,
      "step": 4730
    },
    {
      "epoch": 0.40447137127741273,
      "grad_norm": 0.06252489238977432,
      "learning_rate": 4.5955286287225876e-05,
      "loss": 0.0036,
      "step": 4740
    },
    {
      "epoch": 0.40532468640669,
      "grad_norm": 0.14978523552417755,
      "learning_rate": 4.5946753135933104e-05,
      "loss": 0.0043,
      "step": 4750
    },
    {
      "epoch": 0.4061780015359672,
      "grad_norm": 0.06524677574634552,
      "learning_rate": 4.5938219984640326e-05,
      "loss": 0.0046,
      "step": 4760
    },
    {
      "epoch": 0.4070313166652445,
      "grad_norm": 0.3991450369358063,
      "learning_rate": 4.5929686833347555e-05,
      "loss": 0.005,
      "step": 4770
    },
    {
      "epoch": 0.4078846317945217,
      "grad_norm": 0.28448280692100525,
      "learning_rate": 4.592115368205478e-05,
      "loss": 0.0045,
      "step": 4780
    },
    {
      "epoch": 0.40873794692379894,
      "grad_norm": 0.6399480104446411,
      "learning_rate": 4.591262053076201e-05,
      "loss": 0.0049,
      "step": 4790
    },
    {
      "epoch": 0.4095912620530762,
      "grad_norm": 0.5066084265708923,
      "learning_rate": 4.590408737946924e-05,
      "loss": 0.0055,
      "step": 4800
    },
    {
      "epoch": 0.41044457718235344,
      "grad_norm": 0.4001074731349945,
      "learning_rate": 4.589555422817647e-05,
      "loss": 0.0038,
      "step": 4810
    },
    {
      "epoch": 0.41129789231163066,
      "grad_norm": 0.24427688121795654,
      "learning_rate": 4.58870210768837e-05,
      "loss": 0.0047,
      "step": 4820
    },
    {
      "epoch": 0.41215120744090794,
      "grad_norm": 0.6240692138671875,
      "learning_rate": 4.5878487925590925e-05,
      "loss": 0.0044,
      "step": 4830
    },
    {
      "epoch": 0.41300452257018516,
      "grad_norm": 0.2838514447212219,
      "learning_rate": 4.5869954774298154e-05,
      "loss": 0.0041,
      "step": 4840
    },
    {
      "epoch": 0.41385783769946244,
      "grad_norm": 0.15138909220695496,
      "learning_rate": 4.586142162300538e-05,
      "loss": 0.0042,
      "step": 4850
    },
    {
      "epoch": 0.41471115282873966,
      "grad_norm": 0.30048510432243347,
      "learning_rate": 4.5852888471712604e-05,
      "loss": 0.0051,
      "step": 4860
    },
    {
      "epoch": 0.4155644679580169,
      "grad_norm": 0.06395724415779114,
      "learning_rate": 4.584435532041983e-05,
      "loss": 0.0051,
      "step": 4870
    },
    {
      "epoch": 0.41641778308729416,
      "grad_norm": 0.14117683470249176,
      "learning_rate": 4.583582216912706e-05,
      "loss": 0.0052,
      "step": 4880
    },
    {
      "epoch": 0.4172710982165714,
      "grad_norm": 0.15174147486686707,
      "learning_rate": 4.582728901783429e-05,
      "loss": 0.004,
      "step": 4890
    },
    {
      "epoch": 0.4181244133458486,
      "grad_norm": 0.03911806643009186,
      "learning_rate": 4.581875586654152e-05,
      "loss": 0.0049,
      "step": 4900
    },
    {
      "epoch": 0.4189777284751259,
      "grad_norm": 0.2653891146183014,
      "learning_rate": 4.5810222715248747e-05,
      "loss": 0.0038,
      "step": 4910
    },
    {
      "epoch": 0.4198310436044031,
      "grad_norm": 0.17250829935073853,
      "learning_rate": 4.580168956395597e-05,
      "loss": 0.004,
      "step": 4920
    },
    {
      "epoch": 0.4206843587336804,
      "grad_norm": 0.09613165259361267,
      "learning_rate": 4.57931564126632e-05,
      "loss": 0.0043,
      "step": 4930
    },
    {
      "epoch": 0.4215376738629576,
      "grad_norm": 0.03968704864382744,
      "learning_rate": 4.5784623261370425e-05,
      "loss": 0.0043,
      "step": 4940
    },
    {
      "epoch": 0.4223909889922348,
      "grad_norm": 0.04769296944141388,
      "learning_rate": 4.5776090110077654e-05,
      "loss": 0.0046,
      "step": 4950
    },
    {
      "epoch": 0.4232443041215121,
      "grad_norm": 0.507037878036499,
      "learning_rate": 4.576755695878488e-05,
      "loss": 0.0041,
      "step": 4960
    },
    {
      "epoch": 0.4240976192507893,
      "grad_norm": 0.18819089233875275,
      "learning_rate": 4.575902380749211e-05,
      "loss": 0.0039,
      "step": 4970
    },
    {
      "epoch": 0.42495093438006654,
      "grad_norm": 0.32574066519737244,
      "learning_rate": 4.575049065619933e-05,
      "loss": 0.0045,
      "step": 4980
    },
    {
      "epoch": 0.4258042495093438,
      "grad_norm": 0.18686944246292114,
      "learning_rate": 4.574195750490656e-05,
      "loss": 0.0041,
      "step": 4990
    },
    {
      "epoch": 0.42665756463862103,
      "grad_norm": 0.5249878168106079,
      "learning_rate": 4.573342435361379e-05,
      "loss": 0.0053,
      "step": 5000
    },
    {
      "epoch": 0.4275108797678983,
      "grad_norm": 0.07153335958719254,
      "learning_rate": 4.572489120232102e-05,
      "loss": 0.0037,
      "step": 5010
    },
    {
      "epoch": 0.42836419489717553,
      "grad_norm": 0.19129082560539246,
      "learning_rate": 4.5716358051028246e-05,
      "loss": 0.0052,
      "step": 5020
    },
    {
      "epoch": 0.42921751002645275,
      "grad_norm": 0.19110223650932312,
      "learning_rate": 4.5707824899735475e-05,
      "loss": 0.0045,
      "step": 5030
    },
    {
      "epoch": 0.43007082515573003,
      "grad_norm": 0.1624225378036499,
      "learning_rate": 4.56992917484427e-05,
      "loss": 0.0037,
      "step": 5040
    },
    {
      "epoch": 0.43092414028500725,
      "grad_norm": 0.09993060678243637,
      "learning_rate": 4.569075859714993e-05,
      "loss": 0.0042,
      "step": 5050
    },
    {
      "epoch": 0.4317774554142845,
      "grad_norm": 0.3744085431098938,
      "learning_rate": 4.568222544585716e-05,
      "loss": 0.0047,
      "step": 5060
    },
    {
      "epoch": 0.43263077054356175,
      "grad_norm": 0.8294803500175476,
      "learning_rate": 4.567369229456438e-05,
      "loss": 0.0037,
      "step": 5070
    },
    {
      "epoch": 0.43348408567283897,
      "grad_norm": 0.059159230440855026,
      "learning_rate": 4.566515914327161e-05,
      "loss": 0.0043,
      "step": 5080
    },
    {
      "epoch": 0.43433740080211625,
      "grad_norm": 0.2988108694553375,
      "learning_rate": 4.565662599197884e-05,
      "loss": 0.0053,
      "step": 5090
    },
    {
      "epoch": 0.43519071593139347,
      "grad_norm": 0.624390184879303,
      "learning_rate": 4.564809284068607e-05,
      "loss": 0.004,
      "step": 5100
    },
    {
      "epoch": 0.4360440310606707,
      "grad_norm": 0.2610344886779785,
      "learning_rate": 4.5639559689393296e-05,
      "loss": 0.0048,
      "step": 5110
    },
    {
      "epoch": 0.43689734618994797,
      "grad_norm": 0.434465616941452,
      "learning_rate": 4.5631026538100524e-05,
      "loss": 0.0038,
      "step": 5120
    },
    {
      "epoch": 0.4377506613192252,
      "grad_norm": 0.46974045038223267,
      "learning_rate": 4.562249338680775e-05,
      "loss": 0.0049,
      "step": 5130
    },
    {
      "epoch": 0.4386039764485024,
      "grad_norm": 0.054496586322784424,
      "learning_rate": 4.561396023551498e-05,
      "loss": 0.005,
      "step": 5140
    },
    {
      "epoch": 0.4394572915777797,
      "grad_norm": 0.20908468961715698,
      "learning_rate": 4.560542708422221e-05,
      "loss": 0.0044,
      "step": 5150
    },
    {
      "epoch": 0.4403106067070569,
      "grad_norm": 0.4888530969619751,
      "learning_rate": 4.559689393292944e-05,
      "loss": 0.0046,
      "step": 5160
    },
    {
      "epoch": 0.4411639218363342,
      "grad_norm": 0.10331632196903229,
      "learning_rate": 4.558836078163666e-05,
      "loss": 0.0047,
      "step": 5170
    },
    {
      "epoch": 0.4420172369656114,
      "grad_norm": 0.23334501683712006,
      "learning_rate": 4.557982763034389e-05,
      "loss": 0.0045,
      "step": 5180
    },
    {
      "epoch": 0.4428705520948886,
      "grad_norm": 0.035527829080820084,
      "learning_rate": 4.557129447905111e-05,
      "loss": 0.0048,
      "step": 5190
    },
    {
      "epoch": 0.4437238672241659,
      "grad_norm": 0.1879224330186844,
      "learning_rate": 4.556276132775834e-05,
      "loss": 0.0051,
      "step": 5200
    },
    {
      "epoch": 0.4445771823534431,
      "grad_norm": 0.30537739396095276,
      "learning_rate": 4.555422817646557e-05,
      "loss": 0.0027,
      "step": 5210
    },
    {
      "epoch": 0.44543049748272034,
      "grad_norm": 0.07643461972475052,
      "learning_rate": 4.5545695025172796e-05,
      "loss": 0.0051,
      "step": 5220
    },
    {
      "epoch": 0.4462838126119976,
      "grad_norm": 0.3981775939464569,
      "learning_rate": 4.5537161873880024e-05,
      "loss": 0.0051,
      "step": 5230
    },
    {
      "epoch": 0.44713712774127484,
      "grad_norm": 0.5669418573379517,
      "learning_rate": 4.552862872258725e-05,
      "loss": 0.0054,
      "step": 5240
    },
    {
      "epoch": 0.4479904428705521,
      "grad_norm": 0.31266602873802185,
      "learning_rate": 4.552009557129448e-05,
      "loss": 0.004,
      "step": 5250
    },
    {
      "epoch": 0.44884375799982934,
      "grad_norm": 0.11806134879589081,
      "learning_rate": 4.551156242000171e-05,
      "loss": 0.0038,
      "step": 5260
    },
    {
      "epoch": 0.44969707312910656,
      "grad_norm": 0.23634566366672516,
      "learning_rate": 4.550302926870894e-05,
      "loss": 0.0039,
      "step": 5270
    },
    {
      "epoch": 0.45055038825838384,
      "grad_norm": 0.24576367437839508,
      "learning_rate": 4.5494496117416167e-05,
      "loss": 0.0053,
      "step": 5280
    },
    {
      "epoch": 0.45140370338766106,
      "grad_norm": 0.2786614000797272,
      "learning_rate": 4.548596296612339e-05,
      "loss": 0.0038,
      "step": 5290
    },
    {
      "epoch": 0.4522570185169383,
      "grad_norm": 0.07705108076334,
      "learning_rate": 4.547742981483062e-05,
      "loss": 0.0045,
      "step": 5300
    },
    {
      "epoch": 0.45311033364621556,
      "grad_norm": 0.2421102523803711,
      "learning_rate": 4.5468896663537845e-05,
      "loss": 0.004,
      "step": 5310
    },
    {
      "epoch": 0.4539636487754928,
      "grad_norm": 0.43953555822372437,
      "learning_rate": 4.5460363512245074e-05,
      "loss": 0.0042,
      "step": 5320
    },
    {
      "epoch": 0.45481696390477006,
      "grad_norm": 0.07600962370634079,
      "learning_rate": 4.54518303609523e-05,
      "loss": 0.0052,
      "step": 5330
    },
    {
      "epoch": 0.4556702790340473,
      "grad_norm": 0.1222047209739685,
      "learning_rate": 4.544329720965953e-05,
      "loss": 0.0043,
      "step": 5340
    },
    {
      "epoch": 0.4565235941633245,
      "grad_norm": 0.3513698875904083,
      "learning_rate": 4.543476405836676e-05,
      "loss": 0.0046,
      "step": 5350
    },
    {
      "epoch": 0.4573769092926018,
      "grad_norm": 0.1342882513999939,
      "learning_rate": 4.542623090707399e-05,
      "loss": 0.006,
      "step": 5360
    },
    {
      "epoch": 0.458230224421879,
      "grad_norm": 0.280225545167923,
      "learning_rate": 4.5417697755781216e-05,
      "loss": 0.0047,
      "step": 5370
    },
    {
      "epoch": 0.4590835395511562,
      "grad_norm": 0.23062966763973236,
      "learning_rate": 4.540916460448844e-05,
      "loss": 0.0046,
      "step": 5380
    },
    {
      "epoch": 0.4599368546804335,
      "grad_norm": 0.029164321720600128,
      "learning_rate": 4.5400631453195666e-05,
      "loss": 0.0049,
      "step": 5390
    },
    {
      "epoch": 0.4607901698097107,
      "grad_norm": 0.047049734741449356,
      "learning_rate": 4.5392098301902895e-05,
      "loss": 0.0049,
      "step": 5400
    },
    {
      "epoch": 0.461643484938988,
      "grad_norm": 0.41373923420906067,
      "learning_rate": 4.538356515061012e-05,
      "loss": 0.0044,
      "step": 5410
    },
    {
      "epoch": 0.4624968000682652,
      "grad_norm": 0.4395546317100525,
      "learning_rate": 4.537503199931735e-05,
      "loss": 0.004,
      "step": 5420
    },
    {
      "epoch": 0.46335011519754243,
      "grad_norm": 0.05011925846338272,
      "learning_rate": 4.536649884802458e-05,
      "loss": 0.0046,
      "step": 5430
    },
    {
      "epoch": 0.4642034303268197,
      "grad_norm": 0.2301894724369049,
      "learning_rate": 4.535796569673181e-05,
      "loss": 0.0044,
      "step": 5440
    },
    {
      "epoch": 0.46505674545609693,
      "grad_norm": 0.17171843349933624,
      "learning_rate": 4.534943254543903e-05,
      "loss": 0.0038,
      "step": 5450
    },
    {
      "epoch": 0.46591006058537415,
      "grad_norm": 0.21912966668605804,
      "learning_rate": 4.534089939414626e-05,
      "loss": 0.0029,
      "step": 5460
    },
    {
      "epoch": 0.46676337571465143,
      "grad_norm": 0.6228298544883728,
      "learning_rate": 4.533236624285349e-05,
      "loss": 0.0041,
      "step": 5470
    },
    {
      "epoch": 0.46761669084392865,
      "grad_norm": 0.39662307500839233,
      "learning_rate": 4.5323833091560716e-05,
      "loss": 0.0045,
      "step": 5480
    },
    {
      "epoch": 0.4684700059732059,
      "grad_norm": 0.3083992898464203,
      "learning_rate": 4.5315299940267944e-05,
      "loss": 0.0041,
      "step": 5490
    },
    {
      "epoch": 0.46932332110248315,
      "grad_norm": 0.2066495567560196,
      "learning_rate": 4.5306766788975166e-05,
      "loss": 0.0059,
      "step": 5500
    },
    {
      "epoch": 0.47017663623176037,
      "grad_norm": 0.12577605247497559,
      "learning_rate": 4.5298233637682394e-05,
      "loss": 0.0038,
      "step": 5510
    },
    {
      "epoch": 0.47102995136103765,
      "grad_norm": 0.6096168160438538,
      "learning_rate": 4.528970048638962e-05,
      "loss": 0.004,
      "step": 5520
    },
    {
      "epoch": 0.47188326649031487,
      "grad_norm": 0.5056401491165161,
      "learning_rate": 4.528116733509685e-05,
      "loss": 0.0043,
      "step": 5530
    },
    {
      "epoch": 0.4727365816195921,
      "grad_norm": 0.08659976720809937,
      "learning_rate": 4.527263418380408e-05,
      "loss": 0.0047,
      "step": 5540
    },
    {
      "epoch": 0.47358989674886937,
      "grad_norm": 0.2784484028816223,
      "learning_rate": 4.526410103251131e-05,
      "loss": 0.0047,
      "step": 5550
    },
    {
      "epoch": 0.4744432118781466,
      "grad_norm": 0.11412517726421356,
      "learning_rate": 4.525556788121854e-05,
      "loss": 0.0035,
      "step": 5560
    },
    {
      "epoch": 0.47529652700742386,
      "grad_norm": 0.10897360742092133,
      "learning_rate": 4.5247034729925765e-05,
      "loss": 0.0037,
      "step": 5570
    },
    {
      "epoch": 0.4761498421367011,
      "grad_norm": 0.06778985261917114,
      "learning_rate": 4.5238501578632994e-05,
      "loss": 0.0046,
      "step": 5580
    },
    {
      "epoch": 0.4770031572659783,
      "grad_norm": 0.7164618372917175,
      "learning_rate": 4.522996842734022e-05,
      "loss": 0.0044,
      "step": 5590
    },
    {
      "epoch": 0.4778564723952556,
      "grad_norm": 0.08984304964542389,
      "learning_rate": 4.5221435276047444e-05,
      "loss": 0.0041,
      "step": 5600
    },
    {
      "epoch": 0.4787097875245328,
      "grad_norm": 0.045761216431856155,
      "learning_rate": 4.521290212475467e-05,
      "loss": 0.0053,
      "step": 5610
    },
    {
      "epoch": 0.47956310265381,
      "grad_norm": 0.3997855484485626,
      "learning_rate": 4.52043689734619e-05,
      "loss": 0.0053,
      "step": 5620
    },
    {
      "epoch": 0.4804164177830873,
      "grad_norm": 0.2472909688949585,
      "learning_rate": 4.519583582216913e-05,
      "loss": 0.003,
      "step": 5630
    },
    {
      "epoch": 0.4812697329123645,
      "grad_norm": 0.3237578570842743,
      "learning_rate": 4.518730267087636e-05,
      "loss": 0.0042,
      "step": 5640
    },
    {
      "epoch": 0.4821230480416418,
      "grad_norm": 0.1380106657743454,
      "learning_rate": 4.5178769519583586e-05,
      "loss": 0.0044,
      "step": 5650
    },
    {
      "epoch": 0.482976363170919,
      "grad_norm": 0.1922779530286789,
      "learning_rate": 4.5170236368290815e-05,
      "loss": 0.0039,
      "step": 5660
    },
    {
      "epoch": 0.48382967830019624,
      "grad_norm": 0.585454523563385,
      "learning_rate": 4.5161703216998043e-05,
      "loss": 0.0046,
      "step": 5670
    },
    {
      "epoch": 0.4846829934294735,
      "grad_norm": 0.4192892909049988,
      "learning_rate": 4.515317006570527e-05,
      "loss": 0.0048,
      "step": 5680
    },
    {
      "epoch": 0.48553630855875074,
      "grad_norm": 0.21823708713054657,
      "learning_rate": 4.5144636914412494e-05,
      "loss": 0.0038,
      "step": 5690
    },
    {
      "epoch": 0.48638962368802796,
      "grad_norm": 0.09197346866130829,
      "learning_rate": 4.513610376311972e-05,
      "loss": 0.004,
      "step": 5700
    },
    {
      "epoch": 0.48724293881730524,
      "grad_norm": 0.058873556554317474,
      "learning_rate": 4.512757061182695e-05,
      "loss": 0.0049,
      "step": 5710
    },
    {
      "epoch": 0.48809625394658246,
      "grad_norm": 0.17441900074481964,
      "learning_rate": 4.511903746053417e-05,
      "loss": 0.004,
      "step": 5720
    },
    {
      "epoch": 0.48894956907585974,
      "grad_norm": 0.47217246890068054,
      "learning_rate": 4.51105043092414e-05,
      "loss": 0.0036,
      "step": 5730
    },
    {
      "epoch": 0.48980288420513696,
      "grad_norm": 0.1953100711107254,
      "learning_rate": 4.510197115794863e-05,
      "loss": 0.0044,
      "step": 5740
    },
    {
      "epoch": 0.4906561993344142,
      "grad_norm": 0.14799967408180237,
      "learning_rate": 4.509343800665586e-05,
      "loss": 0.0041,
      "step": 5750
    },
    {
      "epoch": 0.49150951446369145,
      "grad_norm": 0.10227658599615097,
      "learning_rate": 4.5084904855363086e-05,
      "loss": 0.0045,
      "step": 5760
    },
    {
      "epoch": 0.4923628295929687,
      "grad_norm": 0.3574662208557129,
      "learning_rate": 4.5076371704070315e-05,
      "loss": 0.0043,
      "step": 5770
    },
    {
      "epoch": 0.49321614472224595,
      "grad_norm": 0.27453407645225525,
      "learning_rate": 4.506783855277754e-05,
      "loss": 0.0049,
      "step": 5780
    },
    {
      "epoch": 0.4940694598515232,
      "grad_norm": 0.6284732818603516,
      "learning_rate": 4.505930540148477e-05,
      "loss": 0.0043,
      "step": 5790
    },
    {
      "epoch": 0.4949227749808004,
      "grad_norm": 0.1799331158399582,
      "learning_rate": 4.5050772250192e-05,
      "loss": 0.0047,
      "step": 5800
    },
    {
      "epoch": 0.49577609011007767,
      "grad_norm": 0.4409872889518738,
      "learning_rate": 4.504223909889922e-05,
      "loss": 0.0049,
      "step": 5810
    },
    {
      "epoch": 0.4966294052393549,
      "grad_norm": 0.17039142549037933,
      "learning_rate": 4.503370594760645e-05,
      "loss": 0.0048,
      "step": 5820
    },
    {
      "epoch": 0.4974827203686321,
      "grad_norm": 0.23600684106349945,
      "learning_rate": 4.502517279631368e-05,
      "loss": 0.0042,
      "step": 5830
    },
    {
      "epoch": 0.4983360354979094,
      "grad_norm": 0.3751240670681,
      "learning_rate": 4.501663964502091e-05,
      "loss": 0.0049,
      "step": 5840
    },
    {
      "epoch": 0.4991893506271866,
      "grad_norm": 0.18869885802268982,
      "learning_rate": 4.5008106493728136e-05,
      "loss": 0.0048,
      "step": 5850
    },
    {
      "epoch": 0.5000426657564638,
      "grad_norm": 0.2264876663684845,
      "learning_rate": 4.4999573342435364e-05,
      "loss": 0.0032,
      "step": 5860
    },
    {
      "epoch": 0.500895980885741,
      "grad_norm": 0.26816070079803467,
      "learning_rate": 4.499104019114259e-05,
      "loss": 0.0048,
      "step": 5870
    },
    {
      "epoch": 0.5017492960150184,
      "grad_norm": 0.24423262476921082,
      "learning_rate": 4.498250703984982e-05,
      "loss": 0.0035,
      "step": 5880
    },
    {
      "epoch": 0.5026026111442956,
      "grad_norm": 0.030851319432258606,
      "learning_rate": 4.497397388855705e-05,
      "loss": 0.0039,
      "step": 5890
    },
    {
      "epoch": 0.5034559262735728,
      "grad_norm": 0.10016550868749619,
      "learning_rate": 4.496544073726428e-05,
      "loss": 0.0038,
      "step": 5900
    },
    {
      "epoch": 0.50430924140285,
      "grad_norm": 0.2353120893239975,
      "learning_rate": 4.49569075859715e-05,
      "loss": 0.0039,
      "step": 5910
    },
    {
      "epoch": 0.5051625565321273,
      "grad_norm": 0.1787850707769394,
      "learning_rate": 4.494837443467873e-05,
      "loss": 0.0039,
      "step": 5920
    },
    {
      "epoch": 0.5060158716614046,
      "grad_norm": 0.23245394229888916,
      "learning_rate": 4.493984128338596e-05,
      "loss": 0.0046,
      "step": 5930
    },
    {
      "epoch": 0.5068691867906818,
      "grad_norm": 0.24526971578598022,
      "learning_rate": 4.4931308132093185e-05,
      "loss": 0.0054,
      "step": 5940
    },
    {
      "epoch": 0.507722501919959,
      "grad_norm": 0.2630149722099304,
      "learning_rate": 4.4922774980800414e-05,
      "loss": 0.0039,
      "step": 5950
    },
    {
      "epoch": 0.5085758170492363,
      "grad_norm": 0.24118809401988983,
      "learning_rate": 4.491424182950764e-05,
      "loss": 0.0041,
      "step": 5960
    },
    {
      "epoch": 0.5094291321785135,
      "grad_norm": 0.10085863620042801,
      "learning_rate": 4.490570867821487e-05,
      "loss": 0.0031,
      "step": 5970
    },
    {
      "epoch": 0.5102824473077908,
      "grad_norm": 0.06911402940750122,
      "learning_rate": 4.489717552692209e-05,
      "loss": 0.0041,
      "step": 5980
    },
    {
      "epoch": 0.511135762437068,
      "grad_norm": 0.19856005907058716,
      "learning_rate": 4.488864237562932e-05,
      "loss": 0.0025,
      "step": 5990
    },
    {
      "epoch": 0.5119890775663453,
      "grad_norm": 0.20970410108566284,
      "learning_rate": 4.488010922433655e-05,
      "loss": 0.0037,
      "step": 6000
    },
    {
      "epoch": 0.5128423926956225,
      "grad_norm": 0.16190384328365326,
      "learning_rate": 4.487157607304378e-05,
      "loss": 0.004,
      "step": 6010
    },
    {
      "epoch": 0.5136957078248997,
      "grad_norm": 0.13659945130348206,
      "learning_rate": 4.4863042921751e-05,
      "loss": 0.0043,
      "step": 6020
    },
    {
      "epoch": 0.5145490229541769,
      "grad_norm": 0.38351789116859436,
      "learning_rate": 4.485450977045823e-05,
      "loss": 0.0042,
      "step": 6030
    },
    {
      "epoch": 0.5154023380834543,
      "grad_norm": 0.06021047383546829,
      "learning_rate": 4.4845976619165457e-05,
      "loss": 0.0034,
      "step": 6040
    },
    {
      "epoch": 0.5162556532127315,
      "grad_norm": 0.16292785108089447,
      "learning_rate": 4.4837443467872685e-05,
      "loss": 0.0036,
      "step": 6050
    },
    {
      "epoch": 0.5171089683420087,
      "grad_norm": 0.2691764235496521,
      "learning_rate": 4.4828910316579914e-05,
      "loss": 0.0054,
      "step": 6060
    },
    {
      "epoch": 0.5179622834712859,
      "grad_norm": 0.14713191986083984,
      "learning_rate": 4.482037716528714e-05,
      "loss": 0.0051,
      "step": 6070
    },
    {
      "epoch": 0.5188155986005631,
      "grad_norm": 0.32229483127593994,
      "learning_rate": 4.481184401399437e-05,
      "loss": 0.0039,
      "step": 6080
    },
    {
      "epoch": 0.5196689137298405,
      "grad_norm": 0.3826300799846649,
      "learning_rate": 4.48033108627016e-05,
      "loss": 0.0038,
      "step": 6090
    },
    {
      "epoch": 0.5205222288591177,
      "grad_norm": 0.33760878443717957,
      "learning_rate": 4.479477771140883e-05,
      "loss": 0.004,
      "step": 6100
    },
    {
      "epoch": 0.5213755439883949,
      "grad_norm": 0.0493207648396492,
      "learning_rate": 4.4786244560116056e-05,
      "loss": 0.0042,
      "step": 6110
    },
    {
      "epoch": 0.5222288591176721,
      "grad_norm": 0.1303984373807907,
      "learning_rate": 4.477771140882328e-05,
      "loss": 0.0034,
      "step": 6120
    },
    {
      "epoch": 0.5230821742469494,
      "grad_norm": 0.23160569369792938,
      "learning_rate": 4.4769178257530506e-05,
      "loss": 0.0037,
      "step": 6130
    },
    {
      "epoch": 0.5239354893762267,
      "grad_norm": 0.27629607915878296,
      "learning_rate": 4.4760645106237735e-05,
      "loss": 0.005,
      "step": 6140
    },
    {
      "epoch": 0.5247888045055039,
      "grad_norm": 0.1177874356508255,
      "learning_rate": 4.475211195494496e-05,
      "loss": 0.0044,
      "step": 6150
    },
    {
      "epoch": 0.5256421196347811,
      "grad_norm": 0.04674229770898819,
      "learning_rate": 4.474357880365219e-05,
      "loss": 0.0048,
      "step": 6160
    },
    {
      "epoch": 0.5264954347640584,
      "grad_norm": 0.3177761137485504,
      "learning_rate": 4.473504565235942e-05,
      "loss": 0.0049,
      "step": 6170
    },
    {
      "epoch": 0.5273487498933356,
      "grad_norm": 0.13297708332538605,
      "learning_rate": 4.472651250106665e-05,
      "loss": 0.0051,
      "step": 6180
    },
    {
      "epoch": 0.5282020650226128,
      "grad_norm": 0.4445377290248871,
      "learning_rate": 4.471797934977388e-05,
      "loss": 0.004,
      "step": 6190
    },
    {
      "epoch": 0.5290553801518901,
      "grad_norm": 0.1719983071088791,
      "learning_rate": 4.4709446198481106e-05,
      "loss": 0.0041,
      "step": 6200
    },
    {
      "epoch": 0.5299086952811674,
      "grad_norm": 0.49920815229415894,
      "learning_rate": 4.4700913047188334e-05,
      "loss": 0.0051,
      "step": 6210
    },
    {
      "epoch": 0.5307620104104446,
      "grad_norm": 0.24269962310791016,
      "learning_rate": 4.4692379895895556e-05,
      "loss": 0.004,
      "step": 6220
    },
    {
      "epoch": 0.5316153255397218,
      "grad_norm": 0.4967130124568939,
      "learning_rate": 4.4683846744602784e-05,
      "loss": 0.0039,
      "step": 6230
    },
    {
      "epoch": 0.532468640668999,
      "grad_norm": 0.35596978664398193,
      "learning_rate": 4.467531359331001e-05,
      "loss": 0.0044,
      "step": 6240
    },
    {
      "epoch": 0.5333219557982763,
      "grad_norm": 0.07570573687553406,
      "learning_rate": 4.4666780442017234e-05,
      "loss": 0.0058,
      "step": 6250
    },
    {
      "epoch": 0.5341752709275536,
      "grad_norm": 0.2258102148771286,
      "learning_rate": 4.465824729072446e-05,
      "loss": 0.0044,
      "step": 6260
    },
    {
      "epoch": 0.5350285860568308,
      "grad_norm": 0.11674632132053375,
      "learning_rate": 4.464971413943169e-05,
      "loss": 0.0041,
      "step": 6270
    },
    {
      "epoch": 0.535881901186108,
      "grad_norm": 0.11066339164972305,
      "learning_rate": 4.464118098813892e-05,
      "loss": 0.0048,
      "step": 6280
    },
    {
      "epoch": 0.5367352163153852,
      "grad_norm": 0.17916998267173767,
      "learning_rate": 4.463264783684615e-05,
      "loss": 0.0047,
      "step": 6290
    },
    {
      "epoch": 0.5375885314446626,
      "grad_norm": 0.17585024237632751,
      "learning_rate": 4.462411468555338e-05,
      "loss": 0.0037,
      "step": 6300
    },
    {
      "epoch": 0.5384418465739398,
      "grad_norm": 0.4165200889110565,
      "learning_rate": 4.4615581534260605e-05,
      "loss": 0.0043,
      "step": 6310
    },
    {
      "epoch": 0.539295161703217,
      "grad_norm": 0.1990559697151184,
      "learning_rate": 4.4607048382967834e-05,
      "loss": 0.0026,
      "step": 6320
    },
    {
      "epoch": 0.5401484768324942,
      "grad_norm": 0.3157794177532196,
      "learning_rate": 4.4598515231675055e-05,
      "loss": 0.0035,
      "step": 6330
    },
    {
      "epoch": 0.5410017919617714,
      "grad_norm": 0.26537811756134033,
      "learning_rate": 4.4589982080382284e-05,
      "loss": 0.0037,
      "step": 6340
    },
    {
      "epoch": 0.5418551070910487,
      "grad_norm": 0.13324099779129028,
      "learning_rate": 4.458144892908951e-05,
      "loss": 0.0048,
      "step": 6350
    },
    {
      "epoch": 0.542708422220326,
      "grad_norm": 0.23039081692695618,
      "learning_rate": 4.457291577779674e-05,
      "loss": 0.005,
      "step": 6360
    },
    {
      "epoch": 0.5435617373496032,
      "grad_norm": 0.038503434509038925,
      "learning_rate": 4.456438262650397e-05,
      "loss": 0.0037,
      "step": 6370
    },
    {
      "epoch": 0.5444150524788804,
      "grad_norm": 0.15239526331424713,
      "learning_rate": 4.45558494752112e-05,
      "loss": 0.0037,
      "step": 6380
    },
    {
      "epoch": 0.5452683676081577,
      "grad_norm": 0.11867695301771164,
      "learning_rate": 4.4547316323918426e-05,
      "loss": 0.0039,
      "step": 6390
    },
    {
      "epoch": 0.5461216827374349,
      "grad_norm": 0.21431633830070496,
      "learning_rate": 4.4538783172625655e-05,
      "loss": 0.0041,
      "step": 6400
    },
    {
      "epoch": 0.5469749978667122,
      "grad_norm": 0.26451507210731506,
      "learning_rate": 4.453025002133288e-05,
      "loss": 0.0033,
      "step": 6410
    },
    {
      "epoch": 0.5478283129959894,
      "grad_norm": 0.34460294246673584,
      "learning_rate": 4.452171687004011e-05,
      "loss": 0.0039,
      "step": 6420
    },
    {
      "epoch": 0.5486816281252667,
      "grad_norm": 0.26125359535217285,
      "learning_rate": 4.4513183718747334e-05,
      "loss": 0.0044,
      "step": 6430
    },
    {
      "epoch": 0.5495349432545439,
      "grad_norm": 0.11145086586475372,
      "learning_rate": 4.450465056745456e-05,
      "loss": 0.0044,
      "step": 6440
    },
    {
      "epoch": 0.5503882583838211,
      "grad_norm": 0.10864902287721634,
      "learning_rate": 4.449611741616179e-05,
      "loss": 0.0052,
      "step": 6450
    },
    {
      "epoch": 0.5512415735130984,
      "grad_norm": 0.1541326642036438,
      "learning_rate": 4.448758426486902e-05,
      "loss": 0.0048,
      "step": 6460
    },
    {
      "epoch": 0.5520948886423757,
      "grad_norm": 0.35533562302589417,
      "learning_rate": 4.447905111357625e-05,
      "loss": 0.0048,
      "step": 6470
    },
    {
      "epoch": 0.5529482037716529,
      "grad_norm": 0.36559098958969116,
      "learning_rate": 4.4470517962283476e-05,
      "loss": 0.0031,
      "step": 6480
    },
    {
      "epoch": 0.5538015189009301,
      "grad_norm": 0.06688373535871506,
      "learning_rate": 4.4461984810990704e-05,
      "loss": 0.0056,
      "step": 6490
    },
    {
      "epoch": 0.5546548340302073,
      "grad_norm": 0.37788933515548706,
      "learning_rate": 4.445345165969793e-05,
      "loss": 0.0036,
      "step": 6500
    },
    {
      "epoch": 0.5555081491594845,
      "grad_norm": 0.21653635799884796,
      "learning_rate": 4.444491850840516e-05,
      "loss": 0.0043,
      "step": 6510
    },
    {
      "epoch": 0.5563614642887619,
      "grad_norm": 0.19913466274738312,
      "learning_rate": 4.443638535711238e-05,
      "loss": 0.0044,
      "step": 6520
    },
    {
      "epoch": 0.5572147794180391,
      "grad_norm": 0.3179871439933777,
      "learning_rate": 4.442785220581961e-05,
      "loss": 0.0033,
      "step": 6530
    },
    {
      "epoch": 0.5580680945473163,
      "grad_norm": 0.19102653861045837,
      "learning_rate": 4.441931905452684e-05,
      "loss": 0.0044,
      "step": 6540
    },
    {
      "epoch": 0.5589214096765935,
      "grad_norm": 0.08183563500642776,
      "learning_rate": 4.441078590323406e-05,
      "loss": 0.0041,
      "step": 6550
    },
    {
      "epoch": 0.5597747248058708,
      "grad_norm": 0.10505373030900955,
      "learning_rate": 4.440225275194129e-05,
      "loss": 0.0041,
      "step": 6560
    },
    {
      "epoch": 0.5606280399351481,
      "grad_norm": 0.30150106549263,
      "learning_rate": 4.439371960064852e-05,
      "loss": 0.0036,
      "step": 6570
    },
    {
      "epoch": 0.5614813550644253,
      "grad_norm": 0.4548809826374054,
      "learning_rate": 4.438518644935575e-05,
      "loss": 0.0036,
      "step": 6580
    },
    {
      "epoch": 0.5623346701937025,
      "grad_norm": 0.19611401855945587,
      "learning_rate": 4.4376653298062976e-05,
      "loss": 0.0046,
      "step": 6590
    },
    {
      "epoch": 0.5631879853229798,
      "grad_norm": 0.11798770725727081,
      "learning_rate": 4.4368120146770204e-05,
      "loss": 0.0035,
      "step": 6600
    },
    {
      "epoch": 0.564041300452257,
      "grad_norm": 0.1555814892053604,
      "learning_rate": 4.435958699547743e-05,
      "loss": 0.0039,
      "step": 6610
    },
    {
      "epoch": 0.5648946155815343,
      "grad_norm": 0.12110356241464615,
      "learning_rate": 4.435105384418466e-05,
      "loss": 0.0058,
      "step": 6620
    },
    {
      "epoch": 0.5657479307108115,
      "grad_norm": 0.04280715435743332,
      "learning_rate": 4.434252069289189e-05,
      "loss": 0.0044,
      "step": 6630
    },
    {
      "epoch": 0.5666012458400888,
      "grad_norm": 0.19966380298137665,
      "learning_rate": 4.433398754159911e-05,
      "loss": 0.0035,
      "step": 6640
    },
    {
      "epoch": 0.567454560969366,
      "grad_norm": 0.2344004213809967,
      "learning_rate": 4.432545439030634e-05,
      "loss": 0.0036,
      "step": 6650
    },
    {
      "epoch": 0.5683078760986432,
      "grad_norm": 0.04399040341377258,
      "learning_rate": 4.431692123901357e-05,
      "loss": 0.0029,
      "step": 6660
    },
    {
      "epoch": 0.5691611912279205,
      "grad_norm": 0.07044096291065216,
      "learning_rate": 4.43083880877208e-05,
      "loss": 0.0039,
      "step": 6670
    },
    {
      "epoch": 0.5700145063571977,
      "grad_norm": 0.1744767278432846,
      "learning_rate": 4.4299854936428025e-05,
      "loss": 0.0031,
      "step": 6680
    },
    {
      "epoch": 0.570867821486475,
      "grad_norm": 0.3097182512283325,
      "learning_rate": 4.4291321785135254e-05,
      "loss": 0.0038,
      "step": 6690
    },
    {
      "epoch": 0.5717211366157522,
      "grad_norm": 0.21168509125709534,
      "learning_rate": 4.428278863384248e-05,
      "loss": 0.0047,
      "step": 6700
    },
    {
      "epoch": 0.5725744517450294,
      "grad_norm": 0.5315428376197815,
      "learning_rate": 4.427425548254971e-05,
      "loss": 0.0044,
      "step": 6710
    },
    {
      "epoch": 0.5734277668743066,
      "grad_norm": 0.41334354877471924,
      "learning_rate": 4.426572233125694e-05,
      "loss": 0.0042,
      "step": 6720
    },
    {
      "epoch": 0.574281082003584,
      "grad_norm": 0.04942934587597847,
      "learning_rate": 4.425718917996417e-05,
      "loss": 0.0042,
      "step": 6730
    },
    {
      "epoch": 0.5751343971328612,
      "grad_norm": 0.38295701146125793,
      "learning_rate": 4.424865602867139e-05,
      "loss": 0.0045,
      "step": 6740
    },
    {
      "epoch": 0.5759877122621384,
      "grad_norm": 0.09995394945144653,
      "learning_rate": 4.424012287737862e-05,
      "loss": 0.0043,
      "step": 6750
    },
    {
      "epoch": 0.5768410273914156,
      "grad_norm": 0.036376189440488815,
      "learning_rate": 4.4231589726085846e-05,
      "loss": 0.0035,
      "step": 6760
    },
    {
      "epoch": 0.5776943425206928,
      "grad_norm": 0.15120258927345276,
      "learning_rate": 4.4223056574793075e-05,
      "loss": 0.0048,
      "step": 6770
    },
    {
      "epoch": 0.5785476576499702,
      "grad_norm": 0.09613329917192459,
      "learning_rate": 4.4214523423500297e-05,
      "loss": 0.004,
      "step": 6780
    },
    {
      "epoch": 0.5794009727792474,
      "grad_norm": 0.1309322565793991,
      "learning_rate": 4.4205990272207525e-05,
      "loss": 0.0038,
      "step": 6790
    },
    {
      "epoch": 0.5802542879085246,
      "grad_norm": 0.06343614310026169,
      "learning_rate": 4.4197457120914753e-05,
      "loss": 0.0043,
      "step": 6800
    },
    {
      "epoch": 0.5811076030378018,
      "grad_norm": 0.07371925562620163,
      "learning_rate": 4.418892396962198e-05,
      "loss": 0.0036,
      "step": 6810
    },
    {
      "epoch": 0.5819609181670791,
      "grad_norm": 0.39981305599212646,
      "learning_rate": 4.418039081832921e-05,
      "loss": 0.0045,
      "step": 6820
    },
    {
      "epoch": 0.5828142332963564,
      "grad_norm": 0.3283025622367859,
      "learning_rate": 4.417185766703644e-05,
      "loss": 0.0043,
      "step": 6830
    },
    {
      "epoch": 0.5836675484256336,
      "grad_norm": 0.45762643218040466,
      "learning_rate": 4.416332451574367e-05,
      "loss": 0.0042,
      "step": 6840
    },
    {
      "epoch": 0.5845208635549108,
      "grad_norm": 0.4948960542678833,
      "learning_rate": 4.4154791364450896e-05,
      "loss": 0.0041,
      "step": 6850
    },
    {
      "epoch": 0.5853741786841881,
      "grad_norm": 0.4178204834461212,
      "learning_rate": 4.414625821315812e-05,
      "loss": 0.0031,
      "step": 6860
    },
    {
      "epoch": 0.5862274938134653,
      "grad_norm": 0.38118478655815125,
      "learning_rate": 4.4137725061865346e-05,
      "loss": 0.0048,
      "step": 6870
    },
    {
      "epoch": 0.5870808089427425,
      "grad_norm": 0.21174699068069458,
      "learning_rate": 4.4129191910572575e-05,
      "loss": 0.0042,
      "step": 6880
    },
    {
      "epoch": 0.5879341240720198,
      "grad_norm": 0.3949102461338043,
      "learning_rate": 4.41206587592798e-05,
      "loss": 0.0036,
      "step": 6890
    },
    {
      "epoch": 0.5887874392012971,
      "grad_norm": 0.1094500795006752,
      "learning_rate": 4.411212560798703e-05,
      "loss": 0.0035,
      "step": 6900
    },
    {
      "epoch": 0.5896407543305743,
      "grad_norm": 0.35876378417015076,
      "learning_rate": 4.410359245669426e-05,
      "loss": 0.0044,
      "step": 6910
    },
    {
      "epoch": 0.5904940694598515,
      "grad_norm": 0.3501070737838745,
      "learning_rate": 4.409505930540149e-05,
      "loss": 0.0037,
      "step": 6920
    },
    {
      "epoch": 0.5913473845891287,
      "grad_norm": 0.18696175515651703,
      "learning_rate": 4.408652615410872e-05,
      "loss": 0.0035,
      "step": 6930
    },
    {
      "epoch": 0.592200699718406,
      "grad_norm": 0.38513392210006714,
      "learning_rate": 4.4077993002815945e-05,
      "loss": 0.0048,
      "step": 6940
    },
    {
      "epoch": 0.5930540148476833,
      "grad_norm": 0.3628044128417969,
      "learning_rate": 4.406945985152317e-05,
      "loss": 0.0038,
      "step": 6950
    },
    {
      "epoch": 0.5939073299769605,
      "grad_norm": 0.1487112045288086,
      "learning_rate": 4.4060926700230396e-05,
      "loss": 0.0044,
      "step": 6960
    },
    {
      "epoch": 0.5947606451062377,
      "grad_norm": 0.5153161287307739,
      "learning_rate": 4.4052393548937624e-05,
      "loss": 0.0042,
      "step": 6970
    },
    {
      "epoch": 0.5956139602355149,
      "grad_norm": 0.09321154654026031,
      "learning_rate": 4.404386039764485e-05,
      "loss": 0.0044,
      "step": 6980
    },
    {
      "epoch": 0.5964672753647923,
      "grad_norm": 0.6450955867767334,
      "learning_rate": 4.403532724635208e-05,
      "loss": 0.0047,
      "step": 6990
    },
    {
      "epoch": 0.5973205904940695,
      "grad_norm": 0.12148437649011612,
      "learning_rate": 4.402679409505931e-05,
      "loss": 0.0039,
      "step": 7000
    },
    {
      "epoch": 0.5981739056233467,
      "grad_norm": 0.1325235217809677,
      "learning_rate": 4.401826094376654e-05,
      "loss": 0.004,
      "step": 7010
    },
    {
      "epoch": 0.5990272207526239,
      "grad_norm": 0.06961306929588318,
      "learning_rate": 4.4009727792473767e-05,
      "loss": 0.0043,
      "step": 7020
    },
    {
      "epoch": 0.5998805358819012,
      "grad_norm": 0.09774825721979141,
      "learning_rate": 4.4001194641180995e-05,
      "loss": 0.0048,
      "step": 7030
    },
    {
      "epoch": 0.6007338510111784,
      "grad_norm": 0.0410425029695034,
      "learning_rate": 4.3992661489888223e-05,
      "loss": 0.0055,
      "step": 7040
    },
    {
      "epoch": 0.6015871661404557,
      "grad_norm": 0.26549381017684937,
      "learning_rate": 4.3984128338595445e-05,
      "loss": 0.0036,
      "step": 7050
    },
    {
      "epoch": 0.6024404812697329,
      "grad_norm": 0.15366804599761963,
      "learning_rate": 4.3975595187302674e-05,
      "loss": 0.0035,
      "step": 7060
    },
    {
      "epoch": 0.6032937963990102,
      "grad_norm": 0.4358033239841461,
      "learning_rate": 4.3967062036009895e-05,
      "loss": 0.0034,
      "step": 7070
    },
    {
      "epoch": 0.6041471115282874,
      "grad_norm": 0.186818465590477,
      "learning_rate": 4.3958528884717124e-05,
      "loss": 0.0031,
      "step": 7080
    },
    {
      "epoch": 0.6050004266575646,
      "grad_norm": 0.04907885938882828,
      "learning_rate": 4.394999573342435e-05,
      "loss": 0.0052,
      "step": 7090
    },
    {
      "epoch": 0.6058537417868419,
      "grad_norm": 0.12992939352989197,
      "learning_rate": 4.394146258213158e-05,
      "loss": 0.0035,
      "step": 7100
    },
    {
      "epoch": 0.6067070569161191,
      "grad_norm": 0.46506088972091675,
      "learning_rate": 4.393292943083881e-05,
      "loss": 0.0038,
      "step": 7110
    },
    {
      "epoch": 0.6075603720453964,
      "grad_norm": 0.21002215147018433,
      "learning_rate": 4.392439627954604e-05,
      "loss": 0.0034,
      "step": 7120
    },
    {
      "epoch": 0.6084136871746736,
      "grad_norm": 0.4884741008281708,
      "learning_rate": 4.3915863128253266e-05,
      "loss": 0.0038,
      "step": 7130
    },
    {
      "epoch": 0.6092670023039508,
      "grad_norm": 0.1377786248922348,
      "learning_rate": 4.3907329976960495e-05,
      "loss": 0.0049,
      "step": 7140
    },
    {
      "epoch": 0.6101203174332281,
      "grad_norm": 0.043744705617427826,
      "learning_rate": 4.389879682566772e-05,
      "loss": 0.0026,
      "step": 7150
    },
    {
      "epoch": 0.6109736325625054,
      "grad_norm": 0.1416628062725067,
      "learning_rate": 4.389026367437495e-05,
      "loss": 0.0046,
      "step": 7160
    },
    {
      "epoch": 0.6118269476917826,
      "grad_norm": 0.280467689037323,
      "learning_rate": 4.3881730523082173e-05,
      "loss": 0.0047,
      "step": 7170
    },
    {
      "epoch": 0.6126802628210598,
      "grad_norm": 0.16885636746883392,
      "learning_rate": 4.38731973717894e-05,
      "loss": 0.0037,
      "step": 7180
    },
    {
      "epoch": 0.613533577950337,
      "grad_norm": 0.28715869784355164,
      "learning_rate": 4.386466422049663e-05,
      "loss": 0.0049,
      "step": 7190
    },
    {
      "epoch": 0.6143868930796142,
      "grad_norm": 0.23283988237380981,
      "learning_rate": 4.385613106920386e-05,
      "loss": 0.0035,
      "step": 7200
    },
    {
      "epoch": 0.6152402082088916,
      "grad_norm": 0.2626006603240967,
      "learning_rate": 4.384759791791109e-05,
      "loss": 0.0036,
      "step": 7210
    },
    {
      "epoch": 0.6160935233381688,
      "grad_norm": 0.15963388979434967,
      "learning_rate": 4.3839064766618316e-05,
      "loss": 0.0029,
      "step": 7220
    },
    {
      "epoch": 0.616946838467446,
      "grad_norm": 0.1359572857618332,
      "learning_rate": 4.3830531615325544e-05,
      "loss": 0.0041,
      "step": 7230
    },
    {
      "epoch": 0.6178001535967232,
      "grad_norm": 0.1273714303970337,
      "learning_rate": 4.382199846403277e-05,
      "loss": 0.0038,
      "step": 7240
    },
    {
      "epoch": 0.6186534687260005,
      "grad_norm": 0.23822569847106934,
      "learning_rate": 4.381346531274e-05,
      "loss": 0.0047,
      "step": 7250
    },
    {
      "epoch": 0.6195067838552778,
      "grad_norm": 0.586978018283844,
      "learning_rate": 4.380493216144722e-05,
      "loss": 0.0047,
      "step": 7260
    },
    {
      "epoch": 0.620360098984555,
      "grad_norm": 0.1768456995487213,
      "learning_rate": 4.379639901015445e-05,
      "loss": 0.0046,
      "step": 7270
    },
    {
      "epoch": 0.6212134141138322,
      "grad_norm": 0.1452440321445465,
      "learning_rate": 4.378786585886168e-05,
      "loss": 0.0037,
      "step": 7280
    },
    {
      "epoch": 0.6220667292431095,
      "grad_norm": 0.10920263826847076,
      "learning_rate": 4.377933270756891e-05,
      "loss": 0.0046,
      "step": 7290
    },
    {
      "epoch": 0.6229200443723867,
      "grad_norm": 0.23509730398654938,
      "learning_rate": 4.377079955627614e-05,
      "loss": 0.0038,
      "step": 7300
    },
    {
      "epoch": 0.623773359501664,
      "grad_norm": 0.11513768136501312,
      "learning_rate": 4.376226640498336e-05,
      "loss": 0.004,
      "step": 7310
    },
    {
      "epoch": 0.6246266746309412,
      "grad_norm": 0.13467825949192047,
      "learning_rate": 4.375373325369059e-05,
      "loss": 0.004,
      "step": 7320
    },
    {
      "epoch": 0.6254799897602185,
      "grad_norm": 0.22667458653450012,
      "learning_rate": 4.3745200102397816e-05,
      "loss": 0.0046,
      "step": 7330
    },
    {
      "epoch": 0.6263333048894957,
      "grad_norm": 0.23994797468185425,
      "learning_rate": 4.3736666951105044e-05,
      "loss": 0.0034,
      "step": 7340
    },
    {
      "epoch": 0.6271866200187729,
      "grad_norm": 0.1288996934890747,
      "learning_rate": 4.372813379981227e-05,
      "loss": 0.004,
      "step": 7350
    },
    {
      "epoch": 0.6280399351480501,
      "grad_norm": 0.07724670320749283,
      "learning_rate": 4.37196006485195e-05,
      "loss": 0.0039,
      "step": 7360
    },
    {
      "epoch": 0.6288932502773275,
      "grad_norm": 0.19269540905952454,
      "learning_rate": 4.371106749722673e-05,
      "loss": 0.0038,
      "step": 7370
    },
    {
      "epoch": 0.6297465654066047,
      "grad_norm": 0.06544008105993271,
      "learning_rate": 4.370253434593395e-05,
      "loss": 0.0043,
      "step": 7380
    },
    {
      "epoch": 0.6305998805358819,
      "grad_norm": 0.1381095051765442,
      "learning_rate": 4.369400119464118e-05,
      "loss": 0.0034,
      "step": 7390
    },
    {
      "epoch": 0.6314531956651591,
      "grad_norm": 0.062446121126413345,
      "learning_rate": 4.368546804334841e-05,
      "loss": 0.003,
      "step": 7400
    },
    {
      "epoch": 0.6323065107944363,
      "grad_norm": 0.30422264337539673,
      "learning_rate": 4.367693489205564e-05,
      "loss": 0.0043,
      "step": 7410
    },
    {
      "epoch": 0.6331598259237137,
      "grad_norm": 0.2601213753223419,
      "learning_rate": 4.3668401740762865e-05,
      "loss": 0.0039,
      "step": 7420
    },
    {
      "epoch": 0.6340131410529909,
      "grad_norm": 0.3099112808704376,
      "learning_rate": 4.3659868589470094e-05,
      "loss": 0.0042,
      "step": 7430
    },
    {
      "epoch": 0.6348664561822681,
      "grad_norm": 0.10919885337352753,
      "learning_rate": 4.365133543817732e-05,
      "loss": 0.0042,
      "step": 7440
    },
    {
      "epoch": 0.6357197713115453,
      "grad_norm": 0.3036782443523407,
      "learning_rate": 4.364280228688455e-05,
      "loss": 0.0039,
      "step": 7450
    },
    {
      "epoch": 0.6365730864408226,
      "grad_norm": 0.16951806843280792,
      "learning_rate": 4.363426913559178e-05,
      "loss": 0.005,
      "step": 7460
    },
    {
      "epoch": 0.6374264015700999,
      "grad_norm": 0.5145863890647888,
      "learning_rate": 4.362573598429901e-05,
      "loss": 0.0031,
      "step": 7470
    },
    {
      "epoch": 0.6382797166993771,
      "grad_norm": 0.28242674469947815,
      "learning_rate": 4.361720283300623e-05,
      "loss": 0.0028,
      "step": 7480
    },
    {
      "epoch": 0.6391330318286543,
      "grad_norm": 0.03604155778884888,
      "learning_rate": 4.360866968171346e-05,
      "loss": 0.0035,
      "step": 7490
    },
    {
      "epoch": 0.6399863469579316,
      "grad_norm": 0.07921707630157471,
      "learning_rate": 4.3600136530420686e-05,
      "loss": 0.0036,
      "step": 7500
    },
    {
      "epoch": 0.6408396620872088,
      "grad_norm": 0.14683875441551208,
      "learning_rate": 4.3591603379127915e-05,
      "loss": 0.0047,
      "step": 7510
    },
    {
      "epoch": 0.641692977216486,
      "grad_norm": 0.11307011544704437,
      "learning_rate": 4.358307022783514e-05,
      "loss": 0.0032,
      "step": 7520
    },
    {
      "epoch": 0.6425462923457633,
      "grad_norm": 0.243171826004982,
      "learning_rate": 4.357453707654237e-05,
      "loss": 0.0045,
      "step": 7530
    },
    {
      "epoch": 0.6433996074750405,
      "grad_norm": 0.1067580059170723,
      "learning_rate": 4.35660039252496e-05,
      "loss": 0.0034,
      "step": 7540
    },
    {
      "epoch": 0.6442529226043178,
      "grad_norm": 0.10779447853565216,
      "learning_rate": 4.355747077395683e-05,
      "loss": 0.0037,
      "step": 7550
    },
    {
      "epoch": 0.645106237733595,
      "grad_norm": 0.031564753502607346,
      "learning_rate": 4.354893762266406e-05,
      "loss": 0.0039,
      "step": 7560
    },
    {
      "epoch": 0.6459595528628722,
      "grad_norm": 0.26201683282852173,
      "learning_rate": 4.354040447137128e-05,
      "loss": 0.0043,
      "step": 7570
    },
    {
      "epoch": 0.6468128679921495,
      "grad_norm": 0.21709397435188293,
      "learning_rate": 4.353187132007851e-05,
      "loss": 0.0039,
      "step": 7580
    },
    {
      "epoch": 0.6476661831214268,
      "grad_norm": 0.3238089084625244,
      "learning_rate": 4.352333816878573e-05,
      "loss": 0.0042,
      "step": 7590
    },
    {
      "epoch": 0.648519498250704,
      "grad_norm": 0.22717738151550293,
      "learning_rate": 4.351480501749296e-05,
      "loss": 0.0029,
      "step": 7600
    },
    {
      "epoch": 0.6493728133799812,
      "grad_norm": 0.19187067449092865,
      "learning_rate": 4.3506271866200186e-05,
      "loss": 0.0044,
      "step": 7610
    },
    {
      "epoch": 0.6502261285092584,
      "grad_norm": 0.4971295893192291,
      "learning_rate": 4.3497738714907414e-05,
      "loss": 0.0038,
      "step": 7620
    },
    {
      "epoch": 0.6510794436385358,
      "grad_norm": 0.5494133234024048,
      "learning_rate": 4.348920556361464e-05,
      "loss": 0.0041,
      "step": 7630
    },
    {
      "epoch": 0.651932758767813,
      "grad_norm": 0.15712188184261322,
      "learning_rate": 4.348067241232187e-05,
      "loss": 0.0039,
      "step": 7640
    },
    {
      "epoch": 0.6527860738970902,
      "grad_norm": 0.22095683217048645,
      "learning_rate": 4.34721392610291e-05,
      "loss": 0.0045,
      "step": 7650
    },
    {
      "epoch": 0.6536393890263674,
      "grad_norm": 0.2701907157897949,
      "learning_rate": 4.346360610973633e-05,
      "loss": 0.0044,
      "step": 7660
    },
    {
      "epoch": 0.6544927041556446,
      "grad_norm": 0.6477449536323547,
      "learning_rate": 4.345507295844356e-05,
      "loss": 0.0035,
      "step": 7670
    },
    {
      "epoch": 0.655346019284922,
      "grad_norm": 0.21811355650424957,
      "learning_rate": 4.3446539807150785e-05,
      "loss": 0.0047,
      "step": 7680
    },
    {
      "epoch": 0.6561993344141992,
      "grad_norm": 0.17048808932304382,
      "learning_rate": 4.343800665585801e-05,
      "loss": 0.0044,
      "step": 7690
    },
    {
      "epoch": 0.6570526495434764,
      "grad_norm": 0.6099584102630615,
      "learning_rate": 4.3429473504565236e-05,
      "loss": 0.004,
      "step": 7700
    },
    {
      "epoch": 0.6579059646727536,
      "grad_norm": 0.12419679760932922,
      "learning_rate": 4.3420940353272464e-05,
      "loss": 0.0032,
      "step": 7710
    },
    {
      "epoch": 0.6587592798020309,
      "grad_norm": 0.0796467512845993,
      "learning_rate": 4.341240720197969e-05,
      "loss": 0.0038,
      "step": 7720
    },
    {
      "epoch": 0.6596125949313081,
      "grad_norm": 0.1912260353565216,
      "learning_rate": 4.340387405068692e-05,
      "loss": 0.0033,
      "step": 7730
    },
    {
      "epoch": 0.6604659100605854,
      "grad_norm": 0.09784656763076782,
      "learning_rate": 4.339534089939415e-05,
      "loss": 0.0038,
      "step": 7740
    },
    {
      "epoch": 0.6613192251898626,
      "grad_norm": 0.35709884762763977,
      "learning_rate": 4.338680774810138e-05,
      "loss": 0.0049,
      "step": 7750
    },
    {
      "epoch": 0.6621725403191399,
      "grad_norm": 0.05910428240895271,
      "learning_rate": 4.3378274596808606e-05,
      "loss": 0.0043,
      "step": 7760
    },
    {
      "epoch": 0.6630258554484171,
      "grad_norm": 0.4178234934806824,
      "learning_rate": 4.3369741445515835e-05,
      "loss": 0.0039,
      "step": 7770
    },
    {
      "epoch": 0.6638791705776943,
      "grad_norm": 0.03492951765656471,
      "learning_rate": 4.336120829422306e-05,
      "loss": 0.0027,
      "step": 7780
    },
    {
      "epoch": 0.6647324857069716,
      "grad_norm": 0.07828591763973236,
      "learning_rate": 4.3352675142930285e-05,
      "loss": 0.0029,
      "step": 7790
    },
    {
      "epoch": 0.6655858008362489,
      "grad_norm": 0.11532644182443619,
      "learning_rate": 4.3344141991637514e-05,
      "loss": 0.0037,
      "step": 7800
    },
    {
      "epoch": 0.6664391159655261,
      "grad_norm": 0.2498990297317505,
      "learning_rate": 4.333560884034474e-05,
      "loss": 0.0042,
      "step": 7810
    },
    {
      "epoch": 0.6672924310948033,
      "grad_norm": 0.45752590894699097,
      "learning_rate": 4.332707568905197e-05,
      "loss": 0.0034,
      "step": 7820
    },
    {
      "epoch": 0.6681457462240805,
      "grad_norm": 0.2332083284854889,
      "learning_rate": 4.33185425377592e-05,
      "loss": 0.005,
      "step": 7830
    },
    {
      "epoch": 0.6689990613533578,
      "grad_norm": 0.2320227324962616,
      "learning_rate": 4.331000938646642e-05,
      "loss": 0.004,
      "step": 7840
    },
    {
      "epoch": 0.6698523764826351,
      "grad_norm": 0.06275017559528351,
      "learning_rate": 4.330147623517365e-05,
      "loss": 0.0033,
      "step": 7850
    },
    {
      "epoch": 0.6707056916119123,
      "grad_norm": 0.39491498470306396,
      "learning_rate": 4.329294308388088e-05,
      "loss": 0.0029,
      "step": 7860
    },
    {
      "epoch": 0.6715590067411895,
      "grad_norm": 0.06446567922830582,
      "learning_rate": 4.3284409932588106e-05,
      "loss": 0.0045,
      "step": 7870
    },
    {
      "epoch": 0.6724123218704667,
      "grad_norm": 0.09609342366456985,
      "learning_rate": 4.3275876781295335e-05,
      "loss": 0.0034,
      "step": 7880
    },
    {
      "epoch": 0.673265636999744,
      "grad_norm": 0.21826209127902985,
      "learning_rate": 4.326734363000256e-05,
      "loss": 0.0041,
      "step": 7890
    },
    {
      "epoch": 0.6741189521290213,
      "grad_norm": 0.1416645050048828,
      "learning_rate": 4.3258810478709785e-05,
      "loss": 0.0045,
      "step": 7900
    },
    {
      "epoch": 0.6749722672582985,
      "grad_norm": 0.13713614642620087,
      "learning_rate": 4.325027732741701e-05,
      "loss": 0.0037,
      "step": 7910
    },
    {
      "epoch": 0.6758255823875757,
      "grad_norm": 0.06292959302663803,
      "learning_rate": 4.324174417612424e-05,
      "loss": 0.0033,
      "step": 7920
    },
    {
      "epoch": 0.676678897516853,
      "grad_norm": 0.1337200254201889,
      "learning_rate": 4.323321102483147e-05,
      "loss": 0.0037,
      "step": 7930
    },
    {
      "epoch": 0.6775322126461302,
      "grad_norm": 0.059527382254600525,
      "learning_rate": 4.32246778735387e-05,
      "loss": 0.0037,
      "step": 7940
    },
    {
      "epoch": 0.6783855277754075,
      "grad_norm": 0.10417638719081879,
      "learning_rate": 4.321614472224593e-05,
      "loss": 0.0042,
      "step": 7950
    },
    {
      "epoch": 0.6792388429046847,
      "grad_norm": 0.4472084045410156,
      "learning_rate": 4.3207611570953156e-05,
      "loss": 0.0033,
      "step": 7960
    },
    {
      "epoch": 0.680092158033962,
      "grad_norm": 0.464028924703598,
      "learning_rate": 4.3199078419660384e-05,
      "loss": 0.003,
      "step": 7970
    },
    {
      "epoch": 0.6809454731632392,
      "grad_norm": 0.058854054659605026,
      "learning_rate": 4.319054526836761e-05,
      "loss": 0.0032,
      "step": 7980
    },
    {
      "epoch": 0.6817987882925164,
      "grad_norm": 0.3969036638736725,
      "learning_rate": 4.318201211707484e-05,
      "loss": 0.004,
      "step": 7990
    },
    {
      "epoch": 0.6826521034217937,
      "grad_norm": 0.367551326751709,
      "learning_rate": 4.317347896578206e-05,
      "loss": 0.0043,
      "step": 8000
    },
    {
      "epoch": 0.6835054185510709,
      "grad_norm": 0.18313051760196686,
      "learning_rate": 4.316494581448929e-05,
      "loss": 0.0042,
      "step": 8010
    },
    {
      "epoch": 0.6843587336803482,
      "grad_norm": 0.41820940375328064,
      "learning_rate": 4.315641266319652e-05,
      "loss": 0.004,
      "step": 8020
    },
    {
      "epoch": 0.6852120488096254,
      "grad_norm": 0.33196085691452026,
      "learning_rate": 4.314787951190375e-05,
      "loss": 0.0038,
      "step": 8030
    },
    {
      "epoch": 0.6860653639389026,
      "grad_norm": 0.20189733803272247,
      "learning_rate": 4.313934636061098e-05,
      "loss": 0.0036,
      "step": 8040
    },
    {
      "epoch": 0.6869186790681798,
      "grad_norm": 0.06164073944091797,
      "learning_rate": 4.3130813209318205e-05,
      "loss": 0.0031,
      "step": 8050
    },
    {
      "epoch": 0.6877719941974572,
      "grad_norm": 0.14992444217205048,
      "learning_rate": 4.3122280058025434e-05,
      "loss": 0.004,
      "step": 8060
    },
    {
      "epoch": 0.6886253093267344,
      "grad_norm": 0.45362842082977295,
      "learning_rate": 4.311374690673266e-05,
      "loss": 0.0033,
      "step": 8070
    },
    {
      "epoch": 0.6894786244560116,
      "grad_norm": 0.5206012725830078,
      "learning_rate": 4.310521375543989e-05,
      "loss": 0.003,
      "step": 8080
    },
    {
      "epoch": 0.6903319395852888,
      "grad_norm": 0.08434048295021057,
      "learning_rate": 4.309668060414712e-05,
      "loss": 0.0037,
      "step": 8090
    },
    {
      "epoch": 0.691185254714566,
      "grad_norm": 0.4087781310081482,
      "learning_rate": 4.308814745285434e-05,
      "loss": 0.0032,
      "step": 8100
    },
    {
      "epoch": 0.6920385698438434,
      "grad_norm": 0.3030199110507965,
      "learning_rate": 4.307961430156157e-05,
      "loss": 0.0032,
      "step": 8110
    },
    {
      "epoch": 0.6928918849731206,
      "grad_norm": 0.21260236203670502,
      "learning_rate": 4.307108115026879e-05,
      "loss": 0.0035,
      "step": 8120
    },
    {
      "epoch": 0.6937452001023978,
      "grad_norm": 0.3430531919002533,
      "learning_rate": 4.306254799897602e-05,
      "loss": 0.0036,
      "step": 8130
    },
    {
      "epoch": 0.694598515231675,
      "grad_norm": 0.11837733536958694,
      "learning_rate": 4.305401484768325e-05,
      "loss": 0.0036,
      "step": 8140
    },
    {
      "epoch": 0.6954518303609523,
      "grad_norm": 0.049310460686683655,
      "learning_rate": 4.3045481696390477e-05,
      "loss": 0.0039,
      "step": 8150
    },
    {
      "epoch": 0.6963051454902296,
      "grad_norm": 0.06459418684244156,
      "learning_rate": 4.3036948545097705e-05,
      "loss": 0.004,
      "step": 8160
    },
    {
      "epoch": 0.6971584606195068,
      "grad_norm": 0.1056366115808487,
      "learning_rate": 4.3028415393804934e-05,
      "loss": 0.0037,
      "step": 8170
    },
    {
      "epoch": 0.698011775748784,
      "grad_norm": 0.30106183886528015,
      "learning_rate": 4.301988224251216e-05,
      "loss": 0.0045,
      "step": 8180
    },
    {
      "epoch": 0.6988650908780613,
      "grad_norm": 0.04065047204494476,
      "learning_rate": 4.301134909121939e-05,
      "loss": 0.0035,
      "step": 8190
    },
    {
      "epoch": 0.6997184060073385,
      "grad_norm": 0.31752365827560425,
      "learning_rate": 4.300281593992662e-05,
      "loss": 0.0041,
      "step": 8200
    },
    {
      "epoch": 0.7005717211366157,
      "grad_norm": 0.2330200970172882,
      "learning_rate": 4.299428278863384e-05,
      "loss": 0.0038,
      "step": 8210
    },
    {
      "epoch": 0.701425036265893,
      "grad_norm": 0.19428975880146027,
      "learning_rate": 4.298574963734107e-05,
      "loss": 0.0034,
      "step": 8220
    },
    {
      "epoch": 0.7022783513951703,
      "grad_norm": 0.16103950142860413,
      "learning_rate": 4.29772164860483e-05,
      "loss": 0.0033,
      "step": 8230
    },
    {
      "epoch": 0.7031316665244475,
      "grad_norm": 0.1146787479519844,
      "learning_rate": 4.2968683334755526e-05,
      "loss": 0.0035,
      "step": 8240
    },
    {
      "epoch": 0.7039849816537247,
      "grad_norm": 0.15035292506217957,
      "learning_rate": 4.2960150183462755e-05,
      "loss": 0.0039,
      "step": 8250
    },
    {
      "epoch": 0.7048382967830019,
      "grad_norm": 0.3128646910190582,
      "learning_rate": 4.295161703216998e-05,
      "loss": 0.004,
      "step": 8260
    },
    {
      "epoch": 0.7056916119122792,
      "grad_norm": 0.039689768105745316,
      "learning_rate": 4.294308388087721e-05,
      "loss": 0.0041,
      "step": 8270
    },
    {
      "epoch": 0.7065449270415565,
      "grad_norm": 0.2587141692638397,
      "learning_rate": 4.293455072958444e-05,
      "loss": 0.0038,
      "step": 8280
    },
    {
      "epoch": 0.7073982421708337,
      "grad_norm": 0.1780441701412201,
      "learning_rate": 4.292601757829167e-05,
      "loss": 0.0029,
      "step": 8290
    },
    {
      "epoch": 0.7082515573001109,
      "grad_norm": 0.29964566230773926,
      "learning_rate": 4.29174844269989e-05,
      "loss": 0.0034,
      "step": 8300
    },
    {
      "epoch": 0.7091048724293881,
      "grad_norm": 0.39535990357398987,
      "learning_rate": 4.290895127570612e-05,
      "loss": 0.0026,
      "step": 8310
    },
    {
      "epoch": 0.7099581875586655,
      "grad_norm": 0.3703102767467499,
      "learning_rate": 4.290041812441335e-05,
      "loss": 0.0043,
      "step": 8320
    },
    {
      "epoch": 0.7108115026879427,
      "grad_norm": 0.45663362741470337,
      "learning_rate": 4.2891884973120576e-05,
      "loss": 0.0042,
      "step": 8330
    },
    {
      "epoch": 0.7116648178172199,
      "grad_norm": 0.15942293405532837,
      "learning_rate": 4.2883351821827804e-05,
      "loss": 0.0037,
      "step": 8340
    },
    {
      "epoch": 0.7125181329464971,
      "grad_norm": 0.42001137137413025,
      "learning_rate": 4.287481867053503e-05,
      "loss": 0.0038,
      "step": 8350
    },
    {
      "epoch": 0.7133714480757744,
      "grad_norm": 0.08750122040510178,
      "learning_rate": 4.286628551924226e-05,
      "loss": 0.0038,
      "step": 8360
    },
    {
      "epoch": 0.7142247632050516,
      "grad_norm": 0.10890863090753555,
      "learning_rate": 4.285775236794949e-05,
      "loss": 0.0036,
      "step": 8370
    },
    {
      "epoch": 0.7150780783343289,
      "grad_norm": 0.237938791513443,
      "learning_rate": 4.284921921665671e-05,
      "loss": 0.003,
      "step": 8380
    },
    {
      "epoch": 0.7159313934636061,
      "grad_norm": 0.48647335171699524,
      "learning_rate": 4.284068606536394e-05,
      "loss": 0.0043,
      "step": 8390
    },
    {
      "epoch": 0.7167847085928833,
      "grad_norm": 0.051898736506700516,
      "learning_rate": 4.283215291407117e-05,
      "loss": 0.0028,
      "step": 8400
    },
    {
      "epoch": 0.7176380237221606,
      "grad_norm": 0.381004273891449,
      "learning_rate": 4.28236197627784e-05,
      "loss": 0.004,
      "step": 8410
    },
    {
      "epoch": 0.7184913388514378,
      "grad_norm": 0.3857693374156952,
      "learning_rate": 4.2815086611485625e-05,
      "loss": 0.0035,
      "step": 8420
    },
    {
      "epoch": 0.7193446539807151,
      "grad_norm": 0.2498859316110611,
      "learning_rate": 4.280655346019285e-05,
      "loss": 0.0028,
      "step": 8430
    },
    {
      "epoch": 0.7201979691099923,
      "grad_norm": 0.25240612030029297,
      "learning_rate": 4.2798020308900075e-05,
      "loss": 0.0028,
      "step": 8440
    },
    {
      "epoch": 0.7210512842392696,
      "grad_norm": 0.14249877631664276,
      "learning_rate": 4.2789487157607304e-05,
      "loss": 0.0042,
      "step": 8450
    },
    {
      "epoch": 0.7219045993685468,
      "grad_norm": 0.11854226142168045,
      "learning_rate": 4.278095400631453e-05,
      "loss": 0.0038,
      "step": 8460
    },
    {
      "epoch": 0.722757914497824,
      "grad_norm": 0.5114392042160034,
      "learning_rate": 4.277242085502176e-05,
      "loss": 0.0038,
      "step": 8470
    },
    {
      "epoch": 0.7236112296271013,
      "grad_norm": 0.5555722117424011,
      "learning_rate": 4.276388770372899e-05,
      "loss": 0.0029,
      "step": 8480
    },
    {
      "epoch": 0.7244645447563786,
      "grad_norm": 0.10005996376276016,
      "learning_rate": 4.275535455243622e-05,
      "loss": 0.0035,
      "step": 8490
    },
    {
      "epoch": 0.7253178598856558,
      "grad_norm": 0.07962840050458908,
      "learning_rate": 4.2746821401143446e-05,
      "loss": 0.003,
      "step": 8500
    },
    {
      "epoch": 0.726171175014933,
      "grad_norm": 0.17160296440124512,
      "learning_rate": 4.2738288249850675e-05,
      "loss": 0.0027,
      "step": 8510
    },
    {
      "epoch": 0.7270244901442102,
      "grad_norm": 0.07934699207544327,
      "learning_rate": 4.2729755098557897e-05,
      "loss": 0.0036,
      "step": 8520
    },
    {
      "epoch": 0.7278778052734874,
      "grad_norm": 0.6107863783836365,
      "learning_rate": 4.2721221947265125e-05,
      "loss": 0.0029,
      "step": 8530
    },
    {
      "epoch": 0.7287311204027648,
      "grad_norm": 0.10562875121831894,
      "learning_rate": 4.2712688795972353e-05,
      "loss": 0.0039,
      "step": 8540
    },
    {
      "epoch": 0.729584435532042,
      "grad_norm": 0.36734023690223694,
      "learning_rate": 4.270415564467958e-05,
      "loss": 0.0038,
      "step": 8550
    },
    {
      "epoch": 0.7304377506613192,
      "grad_norm": 0.14853475987911224,
      "learning_rate": 4.269562249338681e-05,
      "loss": 0.0032,
      "step": 8560
    },
    {
      "epoch": 0.7312910657905964,
      "grad_norm": 0.29337456822395325,
      "learning_rate": 4.268708934209404e-05,
      "loss": 0.0029,
      "step": 8570
    },
    {
      "epoch": 0.7321443809198737,
      "grad_norm": 0.2281324863433838,
      "learning_rate": 4.267855619080127e-05,
      "loss": 0.0046,
      "step": 8580
    },
    {
      "epoch": 0.732997696049151,
      "grad_norm": 0.053700532764196396,
      "learning_rate": 4.2670023039508496e-05,
      "loss": 0.0026,
      "step": 8590
    },
    {
      "epoch": 0.7338510111784282,
      "grad_norm": 0.09777206182479858,
      "learning_rate": 4.2661489888215724e-05,
      "loss": 0.0035,
      "step": 8600
    },
    {
      "epoch": 0.7347043263077054,
      "grad_norm": 0.5375396609306335,
      "learning_rate": 4.265295673692295e-05,
      "loss": 0.0028,
      "step": 8610
    },
    {
      "epoch": 0.7355576414369827,
      "grad_norm": 0.1568586528301239,
      "learning_rate": 4.2644423585630175e-05,
      "loss": 0.0041,
      "step": 8620
    },
    {
      "epoch": 0.7364109565662599,
      "grad_norm": 0.2453467845916748,
      "learning_rate": 4.26358904343374e-05,
      "loss": 0.0036,
      "step": 8630
    },
    {
      "epoch": 0.7372642716955372,
      "grad_norm": 0.1966240406036377,
      "learning_rate": 4.2627357283044625e-05,
      "loss": 0.0039,
      "step": 8640
    },
    {
      "epoch": 0.7381175868248144,
      "grad_norm": 0.38257917761802673,
      "learning_rate": 4.261882413175185e-05,
      "loss": 0.0043,
      "step": 8650
    },
    {
      "epoch": 0.7389709019540917,
      "grad_norm": 0.17707352340221405,
      "learning_rate": 4.261029098045908e-05,
      "loss": 0.0029,
      "step": 8660
    },
    {
      "epoch": 0.7398242170833689,
      "grad_norm": 0.1048017367720604,
      "learning_rate": 4.260175782916631e-05,
      "loss": 0.0039,
      "step": 8670
    },
    {
      "epoch": 0.7406775322126461,
      "grad_norm": 0.17648082971572876,
      "learning_rate": 4.259322467787354e-05,
      "loss": 0.005,
      "step": 8680
    },
    {
      "epoch": 0.7415308473419234,
      "grad_norm": 0.10283990949392319,
      "learning_rate": 4.258469152658077e-05,
      "loss": 0.0028,
      "step": 8690
    },
    {
      "epoch": 0.7423841624712006,
      "grad_norm": 0.04591764509677887,
      "learning_rate": 4.2576158375287996e-05,
      "loss": 0.003,
      "step": 8700
    },
    {
      "epoch": 0.7432374776004779,
      "grad_norm": 0.10641396790742874,
      "learning_rate": 4.2567625223995224e-05,
      "loss": 0.0039,
      "step": 8710
    },
    {
      "epoch": 0.7440907927297551,
      "grad_norm": 0.5888134241104126,
      "learning_rate": 4.255909207270245e-05,
      "loss": 0.003,
      "step": 8720
    },
    {
      "epoch": 0.7449441078590323,
      "grad_norm": 0.4477408528327942,
      "learning_rate": 4.255055892140968e-05,
      "loss": 0.0036,
      "step": 8730
    },
    {
      "epoch": 0.7457974229883095,
      "grad_norm": 0.162953719496727,
      "learning_rate": 4.25420257701169e-05,
      "loss": 0.003,
      "step": 8740
    },
    {
      "epoch": 0.7466507381175869,
      "grad_norm": 0.1679866909980774,
      "learning_rate": 4.253349261882413e-05,
      "loss": 0.003,
      "step": 8750
    },
    {
      "epoch": 0.7475040532468641,
      "grad_norm": 0.20172449946403503,
      "learning_rate": 4.252495946753136e-05,
      "loss": 0.0036,
      "step": 8760
    },
    {
      "epoch": 0.7483573683761413,
      "grad_norm": 0.17645983397960663,
      "learning_rate": 4.251642631623859e-05,
      "loss": 0.004,
      "step": 8770
    },
    {
      "epoch": 0.7492106835054185,
      "grad_norm": 0.31828147172927856,
      "learning_rate": 4.250789316494582e-05,
      "loss": 0.0031,
      "step": 8780
    },
    {
      "epoch": 0.7500639986346957,
      "grad_norm": 0.17815767228603363,
      "learning_rate": 4.2499360013653045e-05,
      "loss": 0.003,
      "step": 8790
    },
    {
      "epoch": 0.7509173137639731,
      "grad_norm": 0.1379082351922989,
      "learning_rate": 4.2490826862360274e-05,
      "loss": 0.0038,
      "step": 8800
    },
    {
      "epoch": 0.7517706288932503,
      "grad_norm": 0.2636435031890869,
      "learning_rate": 4.24822937110675e-05,
      "loss": 0.0034,
      "step": 8810
    },
    {
      "epoch": 0.7526239440225275,
      "grad_norm": 0.16900603473186493,
      "learning_rate": 4.247376055977473e-05,
      "loss": 0.0032,
      "step": 8820
    },
    {
      "epoch": 0.7534772591518047,
      "grad_norm": 0.07615119963884354,
      "learning_rate": 4.246522740848195e-05,
      "loss": 0.0043,
      "step": 8830
    },
    {
      "epoch": 0.754330574281082,
      "grad_norm": 0.14476969838142395,
      "learning_rate": 4.245669425718918e-05,
      "loss": 0.0029,
      "step": 8840
    },
    {
      "epoch": 0.7551838894103593,
      "grad_norm": 0.5513371825218201,
      "learning_rate": 4.244816110589641e-05,
      "loss": 0.0042,
      "step": 8850
    },
    {
      "epoch": 0.7560372045396365,
      "grad_norm": 0.5223378539085388,
      "learning_rate": 4.243962795460364e-05,
      "loss": 0.0033,
      "step": 8860
    },
    {
      "epoch": 0.7568905196689137,
      "grad_norm": 0.5064072012901306,
      "learning_rate": 4.2431094803310866e-05,
      "loss": 0.0032,
      "step": 8870
    },
    {
      "epoch": 0.757743834798191,
      "grad_norm": 0.1967136710882187,
      "learning_rate": 4.2422561652018095e-05,
      "loss": 0.003,
      "step": 8880
    },
    {
      "epoch": 0.7585971499274682,
      "grad_norm": 0.06830655783414841,
      "learning_rate": 4.241402850072532e-05,
      "loss": 0.0034,
      "step": 8890
    },
    {
      "epoch": 0.7594504650567454,
      "grad_norm": 0.0454544760286808,
      "learning_rate": 4.240549534943255e-05,
      "loss": 0.0031,
      "step": 8900
    },
    {
      "epoch": 0.7603037801860227,
      "grad_norm": 0.04208198934793472,
      "learning_rate": 4.2396962198139773e-05,
      "loss": 0.0045,
      "step": 8910
    },
    {
      "epoch": 0.7611570953153,
      "grad_norm": 0.234024316072464,
      "learning_rate": 4.2388429046847e-05,
      "loss": 0.0029,
      "step": 8920
    },
    {
      "epoch": 0.7620104104445772,
      "grad_norm": 0.22819161415100098,
      "learning_rate": 4.237989589555423e-05,
      "loss": 0.0046,
      "step": 8930
    },
    {
      "epoch": 0.7628637255738544,
      "grad_norm": 0.133487731218338,
      "learning_rate": 4.237136274426146e-05,
      "loss": 0.0028,
      "step": 8940
    },
    {
      "epoch": 0.7637170407031316,
      "grad_norm": 0.10508343577384949,
      "learning_rate": 4.236282959296868e-05,
      "loss": 0.0038,
      "step": 8950
    },
    {
      "epoch": 0.764570355832409,
      "grad_norm": 0.37406376004219055,
      "learning_rate": 4.235429644167591e-05,
      "loss": 0.003,
      "step": 8960
    },
    {
      "epoch": 0.7654236709616862,
      "grad_norm": 0.05455869436264038,
      "learning_rate": 4.234576329038314e-05,
      "loss": 0.0025,
      "step": 8970
    },
    {
      "epoch": 0.7662769860909634,
      "grad_norm": 0.479277640581131,
      "learning_rate": 4.2337230139090366e-05,
      "loss": 0.0033,
      "step": 8980
    },
    {
      "epoch": 0.7671303012202406,
      "grad_norm": 0.09483863413333893,
      "learning_rate": 4.2328696987797594e-05,
      "loss": 0.0025,
      "step": 8990
    },
    {
      "epoch": 0.7679836163495178,
      "grad_norm": 0.6215285062789917,
      "learning_rate": 4.232016383650482e-05,
      "loss": 0.0034,
      "step": 9000
    },
    {
      "epoch": 0.7688369314787952,
      "grad_norm": 0.11774024367332458,
      "learning_rate": 4.231163068521205e-05,
      "loss": 0.0035,
      "step": 9010
    },
    {
      "epoch": 0.7696902466080724,
      "grad_norm": 0.051550865173339844,
      "learning_rate": 4.230309753391928e-05,
      "loss": 0.0029,
      "step": 9020
    },
    {
      "epoch": 0.7705435617373496,
      "grad_norm": 0.25058892369270325,
      "learning_rate": 4.229456438262651e-05,
      "loss": 0.0036,
      "step": 9030
    },
    {
      "epoch": 0.7713968768666268,
      "grad_norm": 0.06786695122718811,
      "learning_rate": 4.228603123133374e-05,
      "loss": 0.0023,
      "step": 9040
    },
    {
      "epoch": 0.7722501919959041,
      "grad_norm": 0.10542303323745728,
      "learning_rate": 4.227749808004096e-05,
      "loss": 0.0032,
      "step": 9050
    },
    {
      "epoch": 0.7731035071251813,
      "grad_norm": 0.10647916048765182,
      "learning_rate": 4.226896492874819e-05,
      "loss": 0.0023,
      "step": 9060
    },
    {
      "epoch": 0.7739568222544586,
      "grad_norm": 0.09295015782117844,
      "learning_rate": 4.2260431777455416e-05,
      "loss": 0.0042,
      "step": 9070
    },
    {
      "epoch": 0.7748101373837358,
      "grad_norm": 0.05153515562415123,
      "learning_rate": 4.2251898626162644e-05,
      "loss": 0.0032,
      "step": 9080
    },
    {
      "epoch": 0.775663452513013,
      "grad_norm": 0.09026982635259628,
      "learning_rate": 4.224336547486987e-05,
      "loss": 0.004,
      "step": 9090
    },
    {
      "epoch": 0.7765167676422903,
      "grad_norm": 0.20489342510700226,
      "learning_rate": 4.22348323235771e-05,
      "loss": 0.0027,
      "step": 9100
    },
    {
      "epoch": 0.7773700827715675,
      "grad_norm": 0.1325407475233078,
      "learning_rate": 4.222629917228433e-05,
      "loss": 0.0035,
      "step": 9110
    },
    {
      "epoch": 0.7782233979008448,
      "grad_norm": 0.33897748589515686,
      "learning_rate": 4.221776602099156e-05,
      "loss": 0.0023,
      "step": 9120
    },
    {
      "epoch": 0.779076713030122,
      "grad_norm": 0.3880351781845093,
      "learning_rate": 4.2209232869698786e-05,
      "loss": 0.0032,
      "step": 9130
    },
    {
      "epoch": 0.7799300281593993,
      "grad_norm": 0.30339542031288147,
      "learning_rate": 4.220069971840601e-05,
      "loss": 0.0028,
      "step": 9140
    },
    {
      "epoch": 0.7807833432886765,
      "grad_norm": 0.03724522516131401,
      "learning_rate": 4.219216656711324e-05,
      "loss": 0.0036,
      "step": 9150
    },
    {
      "epoch": 0.7816366584179537,
      "grad_norm": 0.20909477770328522,
      "learning_rate": 4.2183633415820465e-05,
      "loss": 0.0031,
      "step": 9160
    },
    {
      "epoch": 0.782489973547231,
      "grad_norm": 0.19005495309829712,
      "learning_rate": 4.217510026452769e-05,
      "loss": 0.0036,
      "step": 9170
    },
    {
      "epoch": 0.7833432886765083,
      "grad_norm": 0.06506294757127762,
      "learning_rate": 4.2166567113234915e-05,
      "loss": 0.0031,
      "step": 9180
    },
    {
      "epoch": 0.7841966038057855,
      "grad_norm": 0.19155344367027283,
      "learning_rate": 4.2158033961942144e-05,
      "loss": 0.003,
      "step": 9190
    },
    {
      "epoch": 0.7850499189350627,
      "grad_norm": 0.23156842589378357,
      "learning_rate": 4.214950081064937e-05,
      "loss": 0.003,
      "step": 9200
    },
    {
      "epoch": 0.7859032340643399,
      "grad_norm": 0.18016506731510162,
      "learning_rate": 4.21409676593566e-05,
      "loss": 0.0028,
      "step": 9210
    },
    {
      "epoch": 0.7867565491936171,
      "grad_norm": 0.09808872640132904,
      "learning_rate": 4.213243450806383e-05,
      "loss": 0.0034,
      "step": 9220
    },
    {
      "epoch": 0.7876098643228945,
      "grad_norm": 0.05117072910070419,
      "learning_rate": 4.212390135677106e-05,
      "loss": 0.0032,
      "step": 9230
    },
    {
      "epoch": 0.7884631794521717,
      "grad_norm": 0.47125935554504395,
      "learning_rate": 4.2115368205478286e-05,
      "loss": 0.0033,
      "step": 9240
    },
    {
      "epoch": 0.7893164945814489,
      "grad_norm": 0.0888555645942688,
      "learning_rate": 4.2106835054185515e-05,
      "loss": 0.003,
      "step": 9250
    },
    {
      "epoch": 0.7901698097107261,
      "grad_norm": 0.0668647363781929,
      "learning_rate": 4.2098301902892736e-05,
      "loss": 0.0027,
      "step": 9260
    },
    {
      "epoch": 0.7910231248400034,
      "grad_norm": 0.39177700877189636,
      "learning_rate": 4.2089768751599965e-05,
      "loss": 0.0031,
      "step": 9270
    },
    {
      "epoch": 0.7918764399692807,
      "grad_norm": 0.36191466450691223,
      "learning_rate": 4.208123560030719e-05,
      "loss": 0.0037,
      "step": 9280
    },
    {
      "epoch": 0.7927297550985579,
      "grad_norm": 0.5652673244476318,
      "learning_rate": 4.207270244901442e-05,
      "loss": 0.0031,
      "step": 9290
    },
    {
      "epoch": 0.7935830702278351,
      "grad_norm": 0.09091708809137344,
      "learning_rate": 4.206416929772165e-05,
      "loss": 0.0036,
      "step": 9300
    },
    {
      "epoch": 0.7944363853571124,
      "grad_norm": 0.2839202284812927,
      "learning_rate": 4.205563614642888e-05,
      "loss": 0.0029,
      "step": 9310
    },
    {
      "epoch": 0.7952897004863896,
      "grad_norm": 0.2284006029367447,
      "learning_rate": 4.204710299513611e-05,
      "loss": 0.0031,
      "step": 9320
    },
    {
      "epoch": 0.7961430156156669,
      "grad_norm": 0.6253634691238403,
      "learning_rate": 4.2038569843843336e-05,
      "loss": 0.0039,
      "step": 9330
    },
    {
      "epoch": 0.7969963307449441,
      "grad_norm": 0.8125067353248596,
      "learning_rate": 4.2030036692550564e-05,
      "loss": 0.0042,
      "step": 9340
    },
    {
      "epoch": 0.7978496458742214,
      "grad_norm": 0.28841543197631836,
      "learning_rate": 4.202150354125779e-05,
      "loss": 0.003,
      "step": 9350
    },
    {
      "epoch": 0.7987029610034986,
      "grad_norm": 0.49633026123046875,
      "learning_rate": 4.2012970389965014e-05,
      "loss": 0.0034,
      "step": 9360
    },
    {
      "epoch": 0.7995562761327758,
      "grad_norm": 0.03415413945913315,
      "learning_rate": 4.200443723867224e-05,
      "loss": 0.0035,
      "step": 9370
    },
    {
      "epoch": 0.800409591262053,
      "grad_norm": 0.17436861991882324,
      "learning_rate": 4.199590408737947e-05,
      "loss": 0.0036,
      "step": 9380
    },
    {
      "epoch": 0.8012629063913304,
      "grad_norm": 0.150431826710701,
      "learning_rate": 4.19873709360867e-05,
      "loss": 0.0029,
      "step": 9390
    },
    {
      "epoch": 0.8021162215206076,
      "grad_norm": 0.41871604323387146,
      "learning_rate": 4.197883778479393e-05,
      "loss": 0.0024,
      "step": 9400
    },
    {
      "epoch": 0.8029695366498848,
      "grad_norm": 0.3471721112728119,
      "learning_rate": 4.197030463350116e-05,
      "loss": 0.0043,
      "step": 9410
    },
    {
      "epoch": 0.803822851779162,
      "grad_norm": 0.15042921900749207,
      "learning_rate": 4.1961771482208385e-05,
      "loss": 0.0031,
      "step": 9420
    },
    {
      "epoch": 0.8046761669084392,
      "grad_norm": 0.08877348154783249,
      "learning_rate": 4.1953238330915614e-05,
      "loss": 0.0039,
      "step": 9430
    },
    {
      "epoch": 0.8055294820377166,
      "grad_norm": 0.21583615243434906,
      "learning_rate": 4.1944705179622836e-05,
      "loss": 0.0026,
      "step": 9440
    },
    {
      "epoch": 0.8063827971669938,
      "grad_norm": 0.1328478306531906,
      "learning_rate": 4.1936172028330064e-05,
      "loss": 0.003,
      "step": 9450
    },
    {
      "epoch": 0.807236112296271,
      "grad_norm": 0.3412352204322815,
      "learning_rate": 4.192763887703729e-05,
      "loss": 0.0027,
      "step": 9460
    },
    {
      "epoch": 0.8080894274255482,
      "grad_norm": 0.3258824348449707,
      "learning_rate": 4.1919105725744514e-05,
      "loss": 0.0024,
      "step": 9470
    },
    {
      "epoch": 0.8089427425548255,
      "grad_norm": 0.13423070311546326,
      "learning_rate": 4.191057257445174e-05,
      "loss": 0.003,
      "step": 9480
    },
    {
      "epoch": 0.8097960576841028,
      "grad_norm": 0.11935412883758545,
      "learning_rate": 4.190203942315897e-05,
      "loss": 0.0034,
      "step": 9490
    },
    {
      "epoch": 0.81064937281338,
      "grad_norm": 0.2739199101924896,
      "learning_rate": 4.18935062718662e-05,
      "loss": 0.0032,
      "step": 9500
    },
    {
      "epoch": 0.8115026879426572,
      "grad_norm": 0.06003453955054283,
      "learning_rate": 4.188497312057343e-05,
      "loss": 0.0026,
      "step": 9510
    },
    {
      "epoch": 0.8123560030719345,
      "grad_norm": 0.21469911932945251,
      "learning_rate": 4.1876439969280657e-05,
      "loss": 0.0035,
      "step": 9520
    },
    {
      "epoch": 0.8132093182012117,
      "grad_norm": 0.04468928277492523,
      "learning_rate": 4.1867906817987885e-05,
      "loss": 0.0031,
      "step": 9530
    },
    {
      "epoch": 0.814062633330489,
      "grad_norm": 0.21632947027683258,
      "learning_rate": 4.1859373666695114e-05,
      "loss": 0.0026,
      "step": 9540
    },
    {
      "epoch": 0.8149159484597662,
      "grad_norm": 0.23491701483726501,
      "learning_rate": 4.185084051540234e-05,
      "loss": 0.004,
      "step": 9550
    },
    {
      "epoch": 0.8157692635890434,
      "grad_norm": 0.13688862323760986,
      "learning_rate": 4.184230736410957e-05,
      "loss": 0.0029,
      "step": 9560
    },
    {
      "epoch": 0.8166225787183207,
      "grad_norm": 0.2457718849182129,
      "learning_rate": 4.183377421281679e-05,
      "loss": 0.0032,
      "step": 9570
    },
    {
      "epoch": 0.8174758938475979,
      "grad_norm": 0.12888047099113464,
      "learning_rate": 4.182524106152402e-05,
      "loss": 0.0035,
      "step": 9580
    },
    {
      "epoch": 0.8183292089768751,
      "grad_norm": 0.14118343591690063,
      "learning_rate": 4.181670791023125e-05,
      "loss": 0.0029,
      "step": 9590
    },
    {
      "epoch": 0.8191825241061524,
      "grad_norm": 0.386746883392334,
      "learning_rate": 4.180817475893848e-05,
      "loss": 0.0036,
      "step": 9600
    },
    {
      "epoch": 0.8200358392354297,
      "grad_norm": 0.2510189116001129,
      "learning_rate": 4.1799641607645706e-05,
      "loss": 0.0029,
      "step": 9610
    },
    {
      "epoch": 0.8208891543647069,
      "grad_norm": 0.3491670787334442,
      "learning_rate": 4.1791108456352935e-05,
      "loss": 0.0042,
      "step": 9620
    },
    {
      "epoch": 0.8217424694939841,
      "grad_norm": 0.5956284999847412,
      "learning_rate": 4.178257530506016e-05,
      "loss": 0.0042,
      "step": 9630
    },
    {
      "epoch": 0.8225957846232613,
      "grad_norm": 0.16931259632110596,
      "learning_rate": 4.177404215376739e-05,
      "loss": 0.004,
      "step": 9640
    },
    {
      "epoch": 0.8234490997525387,
      "grad_norm": 0.5183017253875732,
      "learning_rate": 4.176550900247462e-05,
      "loss": 0.0038,
      "step": 9650
    },
    {
      "epoch": 0.8243024148818159,
      "grad_norm": 0.13470864295959473,
      "learning_rate": 4.175697585118185e-05,
      "loss": 0.0036,
      "step": 9660
    },
    {
      "epoch": 0.8251557300110931,
      "grad_norm": 0.3909040093421936,
      "learning_rate": 4.174844269988907e-05,
      "loss": 0.0026,
      "step": 9670
    },
    {
      "epoch": 0.8260090451403703,
      "grad_norm": 0.4475584030151367,
      "learning_rate": 4.17399095485963e-05,
      "loss": 0.0028,
      "step": 9680
    },
    {
      "epoch": 0.8268623602696475,
      "grad_norm": 0.1432565599679947,
      "learning_rate": 4.173137639730353e-05,
      "loss": 0.0024,
      "step": 9690
    },
    {
      "epoch": 0.8277156753989249,
      "grad_norm": 0.7083495855331421,
      "learning_rate": 4.172284324601075e-05,
      "loss": 0.0049,
      "step": 9700
    },
    {
      "epoch": 0.8285689905282021,
      "grad_norm": 0.5899199843406677,
      "learning_rate": 4.171431009471798e-05,
      "loss": 0.0037,
      "step": 9710
    },
    {
      "epoch": 0.8294223056574793,
      "grad_norm": 0.16853879392147064,
      "learning_rate": 4.1705776943425206e-05,
      "loss": 0.0024,
      "step": 9720
    },
    {
      "epoch": 0.8302756207867565,
      "grad_norm": 0.15636953711509705,
      "learning_rate": 4.1697243792132434e-05,
      "loss": 0.0032,
      "step": 9730
    },
    {
      "epoch": 0.8311289359160338,
      "grad_norm": 0.1761077344417572,
      "learning_rate": 4.168871064083966e-05,
      "loss": 0.0046,
      "step": 9740
    },
    {
      "epoch": 0.831982251045311,
      "grad_norm": 0.11824160814285278,
      "learning_rate": 4.168017748954689e-05,
      "loss": 0.0039,
      "step": 9750
    },
    {
      "epoch": 0.8328355661745883,
      "grad_norm": 0.08011302351951599,
      "learning_rate": 4.167164433825412e-05,
      "loss": 0.0038,
      "step": 9760
    },
    {
      "epoch": 0.8336888813038655,
      "grad_norm": 0.3899380564689636,
      "learning_rate": 4.166311118696135e-05,
      "loss": 0.003,
      "step": 9770
    },
    {
      "epoch": 0.8345421964331428,
      "grad_norm": 0.38444721698760986,
      "learning_rate": 4.165457803566857e-05,
      "loss": 0.003,
      "step": 9780
    },
    {
      "epoch": 0.83539551156242,
      "grad_norm": 0.17751707136631012,
      "learning_rate": 4.16460448843758e-05,
      "loss": 0.0027,
      "step": 9790
    },
    {
      "epoch": 0.8362488266916972,
      "grad_norm": 0.09542824327945709,
      "learning_rate": 4.163751173308303e-05,
      "loss": 0.0034,
      "step": 9800
    },
    {
      "epoch": 0.8371021418209745,
      "grad_norm": 0.29865968227386475,
      "learning_rate": 4.1628978581790255e-05,
      "loss": 0.0035,
      "step": 9810
    },
    {
      "epoch": 0.8379554569502518,
      "grad_norm": 0.24698904156684875,
      "learning_rate": 4.1620445430497484e-05,
      "loss": 0.0034,
      "step": 9820
    },
    {
      "epoch": 0.838808772079529,
      "grad_norm": 0.33101537823677063,
      "learning_rate": 4.161191227920471e-05,
      "loss": 0.0038,
      "step": 9830
    },
    {
      "epoch": 0.8396620872088062,
      "grad_norm": 0.12344340234994888,
      "learning_rate": 4.160337912791194e-05,
      "loss": 0.0035,
      "step": 9840
    },
    {
      "epoch": 0.8405154023380834,
      "grad_norm": 0.6166388392448425,
      "learning_rate": 4.159484597661917e-05,
      "loss": 0.0035,
      "step": 9850
    },
    {
      "epoch": 0.8413687174673607,
      "grad_norm": 0.09194017946720123,
      "learning_rate": 4.15863128253264e-05,
      "loss": 0.003,
      "step": 9860
    },
    {
      "epoch": 0.842222032596638,
      "grad_norm": 0.4957911968231201,
      "learning_rate": 4.1577779674033626e-05,
      "loss": 0.0032,
      "step": 9870
    },
    {
      "epoch": 0.8430753477259152,
      "grad_norm": 0.19350966811180115,
      "learning_rate": 4.156924652274085e-05,
      "loss": 0.0031,
      "step": 9880
    },
    {
      "epoch": 0.8439286628551924,
      "grad_norm": 0.24794718623161316,
      "learning_rate": 4.1560713371448077e-05,
      "loss": 0.0034,
      "step": 9890
    },
    {
      "epoch": 0.8447819779844696,
      "grad_norm": 0.3389284908771515,
      "learning_rate": 4.1552180220155305e-05,
      "loss": 0.0026,
      "step": 9900
    },
    {
      "epoch": 0.8456352931137469,
      "grad_norm": 0.2023165076971054,
      "learning_rate": 4.1543647068862534e-05,
      "loss": 0.0032,
      "step": 9910
    },
    {
      "epoch": 0.8464886082430242,
      "grad_norm": 0.40999892354011536,
      "learning_rate": 4.153511391756976e-05,
      "loss": 0.0045,
      "step": 9920
    },
    {
      "epoch": 0.8473419233723014,
      "grad_norm": 0.10059795528650284,
      "learning_rate": 4.152658076627699e-05,
      "loss": 0.0026,
      "step": 9930
    },
    {
      "epoch": 0.8481952385015786,
      "grad_norm": 0.1198851689696312,
      "learning_rate": 4.151804761498422e-05,
      "loss": 0.0038,
      "step": 9940
    },
    {
      "epoch": 0.8490485536308559,
      "grad_norm": 0.40111055970191956,
      "learning_rate": 4.150951446369145e-05,
      "loss": 0.0024,
      "step": 9950
    },
    {
      "epoch": 0.8499018687601331,
      "grad_norm": 0.19819322228431702,
      "learning_rate": 4.1500981312398676e-05,
      "loss": 0.0029,
      "step": 9960
    },
    {
      "epoch": 0.8507551838894104,
      "grad_norm": 0.3047338128089905,
      "learning_rate": 4.14924481611059e-05,
      "loss": 0.0028,
      "step": 9970
    },
    {
      "epoch": 0.8516084990186876,
      "grad_norm": 0.13007909059524536,
      "learning_rate": 4.1483915009813126e-05,
      "loss": 0.0036,
      "step": 9980
    },
    {
      "epoch": 0.8524618141479648,
      "grad_norm": 0.0713290199637413,
      "learning_rate": 4.1475381858520355e-05,
      "loss": 0.0038,
      "step": 9990
    },
    {
      "epoch": 0.8533151292772421,
      "grad_norm": 0.20641836524009705,
      "learning_rate": 4.1466848707227576e-05,
      "loss": 0.0035,
      "step": 10000
    },
    {
      "epoch": 0.8541684444065193,
      "grad_norm": 0.08007258176803589,
      "learning_rate": 4.1458315555934805e-05,
      "loss": 0.0035,
      "step": 10010
    },
    {
      "epoch": 0.8550217595357966,
      "grad_norm": 0.2164556086063385,
      "learning_rate": 4.144978240464203e-05,
      "loss": 0.0028,
      "step": 10020
    },
    {
      "epoch": 0.8558750746650738,
      "grad_norm": 0.1056755855679512,
      "learning_rate": 4.144124925334926e-05,
      "loss": 0.0034,
      "step": 10030
    },
    {
      "epoch": 0.8567283897943511,
      "grad_norm": 0.12514366209506989,
      "learning_rate": 4.143271610205649e-05,
      "loss": 0.0029,
      "step": 10040
    },
    {
      "epoch": 0.8575817049236283,
      "grad_norm": 0.29775547981262207,
      "learning_rate": 4.142418295076372e-05,
      "loss": 0.0027,
      "step": 10050
    },
    {
      "epoch": 0.8584350200529055,
      "grad_norm": 0.11988214403390884,
      "learning_rate": 4.141564979947095e-05,
      "loss": 0.0026,
      "step": 10060
    },
    {
      "epoch": 0.8592883351821827,
      "grad_norm": 0.2565414607524872,
      "learning_rate": 4.1407116648178176e-05,
      "loss": 0.003,
      "step": 10070
    },
    {
      "epoch": 0.8601416503114601,
      "grad_norm": 0.525168776512146,
      "learning_rate": 4.1398583496885404e-05,
      "loss": 0.0025,
      "step": 10080
    },
    {
      "epoch": 0.8609949654407373,
      "grad_norm": 0.35051655769348145,
      "learning_rate": 4.1390050345592626e-05,
      "loss": 0.0036,
      "step": 10090
    },
    {
      "epoch": 0.8618482805700145,
      "grad_norm": 0.2634693682193756,
      "learning_rate": 4.1381517194299854e-05,
      "loss": 0.0032,
      "step": 10100
    },
    {
      "epoch": 0.8627015956992917,
      "grad_norm": 0.04582696780562401,
      "learning_rate": 4.137298404300708e-05,
      "loss": 0.0026,
      "step": 10110
    },
    {
      "epoch": 0.863554910828569,
      "grad_norm": 0.11687411367893219,
      "learning_rate": 4.136445089171431e-05,
      "loss": 0.0034,
      "step": 10120
    },
    {
      "epoch": 0.8644082259578463,
      "grad_norm": 0.11245124042034149,
      "learning_rate": 4.135591774042154e-05,
      "loss": 0.003,
      "step": 10130
    },
    {
      "epoch": 0.8652615410871235,
      "grad_norm": 0.17791403830051422,
      "learning_rate": 4.134738458912877e-05,
      "loss": 0.0029,
      "step": 10140
    },
    {
      "epoch": 0.8661148562164007,
      "grad_norm": 0.15041042864322662,
      "learning_rate": 4.1338851437836e-05,
      "loss": 0.0034,
      "step": 10150
    },
    {
      "epoch": 0.8669681713456779,
      "grad_norm": 0.5951375365257263,
      "learning_rate": 4.1330318286543225e-05,
      "loss": 0.003,
      "step": 10160
    },
    {
      "epoch": 0.8678214864749552,
      "grad_norm": 0.25569820404052734,
      "learning_rate": 4.1321785135250454e-05,
      "loss": 0.0034,
      "step": 10170
    },
    {
      "epoch": 0.8686748016042325,
      "grad_norm": 0.2958354651927948,
      "learning_rate": 4.131325198395768e-05,
      "loss": 0.0026,
      "step": 10180
    },
    {
      "epoch": 0.8695281167335097,
      "grad_norm": 0.13439328968524933,
      "learning_rate": 4.1304718832664904e-05,
      "loss": 0.0033,
      "step": 10190
    },
    {
      "epoch": 0.8703814318627869,
      "grad_norm": 0.02864326722919941,
      "learning_rate": 4.129618568137213e-05,
      "loss": 0.0026,
      "step": 10200
    },
    {
      "epoch": 0.8712347469920642,
      "grad_norm": 0.18287542462348938,
      "learning_rate": 4.128765253007936e-05,
      "loss": 0.0024,
      "step": 10210
    },
    {
      "epoch": 0.8720880621213414,
      "grad_norm": 0.19358378648757935,
      "learning_rate": 4.127911937878659e-05,
      "loss": 0.0025,
      "step": 10220
    },
    {
      "epoch": 0.8729413772506186,
      "grad_norm": 0.06433640420436859,
      "learning_rate": 4.127058622749382e-05,
      "loss": 0.0033,
      "step": 10230
    },
    {
      "epoch": 0.8737946923798959,
      "grad_norm": 0.17554622888565063,
      "learning_rate": 4.126205307620104e-05,
      "loss": 0.0029,
      "step": 10240
    },
    {
      "epoch": 0.8746480075091732,
      "grad_norm": 0.10935249924659729,
      "learning_rate": 4.125351992490827e-05,
      "loss": 0.0037,
      "step": 10250
    },
    {
      "epoch": 0.8755013226384504,
      "grad_norm": 0.2418079376220703,
      "learning_rate": 4.1244986773615497e-05,
      "loss": 0.003,
      "step": 10260
    },
    {
      "epoch": 0.8763546377677276,
      "grad_norm": 0.12163970619440079,
      "learning_rate": 4.1236453622322725e-05,
      "loss": 0.0025,
      "step": 10270
    },
    {
      "epoch": 0.8772079528970048,
      "grad_norm": 0.08770789951086044,
      "learning_rate": 4.1227920471029953e-05,
      "loss": 0.0034,
      "step": 10280
    },
    {
      "epoch": 0.8780612680262821,
      "grad_norm": 0.3422952890396118,
      "learning_rate": 4.121938731973718e-05,
      "loss": 0.0035,
      "step": 10290
    },
    {
      "epoch": 0.8789145831555594,
      "grad_norm": 0.14331132173538208,
      "learning_rate": 4.121085416844441e-05,
      "loss": 0.0033,
      "step": 10300
    },
    {
      "epoch": 0.8797678982848366,
      "grad_norm": 0.4617859721183777,
      "learning_rate": 4.120232101715163e-05,
      "loss": 0.0028,
      "step": 10310
    },
    {
      "epoch": 0.8806212134141138,
      "grad_norm": 0.19119109213352203,
      "learning_rate": 4.119378786585886e-05,
      "loss": 0.0031,
      "step": 10320
    },
    {
      "epoch": 0.881474528543391,
      "grad_norm": 0.4010070860385895,
      "learning_rate": 4.118525471456609e-05,
      "loss": 0.0031,
      "step": 10330
    },
    {
      "epoch": 0.8823278436726684,
      "grad_norm": 0.26230815052986145,
      "learning_rate": 4.117672156327332e-05,
      "loss": 0.0026,
      "step": 10340
    },
    {
      "epoch": 0.8831811588019456,
      "grad_norm": 0.05031910911202431,
      "learning_rate": 4.1168188411980546e-05,
      "loss": 0.0031,
      "step": 10350
    },
    {
      "epoch": 0.8840344739312228,
      "grad_norm": 0.2312610000371933,
      "learning_rate": 4.1159655260687775e-05,
      "loss": 0.0025,
      "step": 10360
    },
    {
      "epoch": 0.8848877890605,
      "grad_norm": 0.03439990431070328,
      "learning_rate": 4.1151122109395e-05,
      "loss": 0.0036,
      "step": 10370
    },
    {
      "epoch": 0.8857411041897773,
      "grad_norm": 0.08240731805562973,
      "learning_rate": 4.114258895810223e-05,
      "loss": 0.0025,
      "step": 10380
    },
    {
      "epoch": 0.8865944193190545,
      "grad_norm": 0.3087630867958069,
      "learning_rate": 4.113405580680946e-05,
      "loss": 0.0026,
      "step": 10390
    },
    {
      "epoch": 0.8874477344483318,
      "grad_norm": 0.4267565608024597,
      "learning_rate": 4.112552265551668e-05,
      "loss": 0.0029,
      "step": 10400
    },
    {
      "epoch": 0.888301049577609,
      "grad_norm": 0.24841561913490295,
      "learning_rate": 4.111698950422391e-05,
      "loss": 0.0031,
      "step": 10410
    },
    {
      "epoch": 0.8891543647068862,
      "grad_norm": 0.18234536051750183,
      "learning_rate": 4.110845635293114e-05,
      "loss": 0.0036,
      "step": 10420
    },
    {
      "epoch": 0.8900076798361635,
      "grad_norm": 0.133778378367424,
      "learning_rate": 4.109992320163837e-05,
      "loss": 0.0022,
      "step": 10430
    },
    {
      "epoch": 0.8908609949654407,
      "grad_norm": 0.08761099725961685,
      "learning_rate": 4.1091390050345596e-05,
      "loss": 0.0031,
      "step": 10440
    },
    {
      "epoch": 0.891714310094718,
      "grad_norm": 0.15087023377418518,
      "learning_rate": 4.1082856899052824e-05,
      "loss": 0.0031,
      "step": 10450
    },
    {
      "epoch": 0.8925676252239952,
      "grad_norm": 0.2160951942205429,
      "learning_rate": 4.107432374776005e-05,
      "loss": 0.0041,
      "step": 10460
    },
    {
      "epoch": 0.8934209403532725,
      "grad_norm": 0.2103903889656067,
      "learning_rate": 4.106579059646728e-05,
      "loss": 0.0032,
      "step": 10470
    },
    {
      "epoch": 0.8942742554825497,
      "grad_norm": 0.15737293660640717,
      "learning_rate": 4.105725744517451e-05,
      "loss": 0.0025,
      "step": 10480
    },
    {
      "epoch": 0.8951275706118269,
      "grad_norm": 0.3258834779262543,
      "learning_rate": 4.104872429388174e-05,
      "loss": 0.0027,
      "step": 10490
    },
    {
      "epoch": 0.8959808857411042,
      "grad_norm": 0.17605526745319366,
      "learning_rate": 4.104019114258896e-05,
      "loss": 0.0039,
      "step": 10500
    },
    {
      "epoch": 0.8968342008703815,
      "grad_norm": 0.1372116059064865,
      "learning_rate": 4.103165799129619e-05,
      "loss": 0.0036,
      "step": 10510
    },
    {
      "epoch": 0.8976875159996587,
      "grad_norm": 0.06272324174642563,
      "learning_rate": 4.102312484000341e-05,
      "loss": 0.0033,
      "step": 10520
    },
    {
      "epoch": 0.8985408311289359,
      "grad_norm": 0.5076533555984497,
      "learning_rate": 4.101459168871064e-05,
      "loss": 0.0028,
      "step": 10530
    },
    {
      "epoch": 0.8993941462582131,
      "grad_norm": 0.4214712083339691,
      "learning_rate": 4.100605853741787e-05,
      "loss": 0.0033,
      "step": 10540
    },
    {
      "epoch": 0.9002474613874905,
      "grad_norm": 0.20886783301830292,
      "learning_rate": 4.0997525386125095e-05,
      "loss": 0.0035,
      "step": 10550
    },
    {
      "epoch": 0.9011007765167677,
      "grad_norm": 0.08383198082447052,
      "learning_rate": 4.0988992234832324e-05,
      "loss": 0.0031,
      "step": 10560
    },
    {
      "epoch": 0.9019540916460449,
      "grad_norm": 0.16486042737960815,
      "learning_rate": 4.098045908353955e-05,
      "loss": 0.0028,
      "step": 10570
    },
    {
      "epoch": 0.9028074067753221,
      "grad_norm": 0.5191769599914551,
      "learning_rate": 4.097192593224678e-05,
      "loss": 0.0043,
      "step": 10580
    },
    {
      "epoch": 0.9036607219045993,
      "grad_norm": 0.061496492475271225,
      "learning_rate": 4.096339278095401e-05,
      "loss": 0.0031,
      "step": 10590
    },
    {
      "epoch": 0.9045140370338766,
      "grad_norm": 0.30654940009117126,
      "learning_rate": 4.095485962966124e-05,
      "loss": 0.0029,
      "step": 10600
    },
    {
      "epoch": 0.9053673521631539,
      "grad_norm": 0.3168245553970337,
      "learning_rate": 4.0946326478368466e-05,
      "loss": 0.004,
      "step": 10610
    },
    {
      "epoch": 0.9062206672924311,
      "grad_norm": 0.07332052290439606,
      "learning_rate": 4.093779332707569e-05,
      "loss": 0.0029,
      "step": 10620
    },
    {
      "epoch": 0.9070739824217083,
      "grad_norm": 0.2097536325454712,
      "learning_rate": 4.0929260175782916e-05,
      "loss": 0.0036,
      "step": 10630
    },
    {
      "epoch": 0.9079272975509856,
      "grad_norm": 0.09538383781909943,
      "learning_rate": 4.0920727024490145e-05,
      "loss": 0.0032,
      "step": 10640
    },
    {
      "epoch": 0.9087806126802628,
      "grad_norm": 0.05524119734764099,
      "learning_rate": 4.0912193873197373e-05,
      "loss": 0.0032,
      "step": 10650
    },
    {
      "epoch": 0.9096339278095401,
      "grad_norm": 0.1269630342721939,
      "learning_rate": 4.09036607219046e-05,
      "loss": 0.0026,
      "step": 10660
    },
    {
      "epoch": 0.9104872429388173,
      "grad_norm": 0.10205639153718948,
      "learning_rate": 4.089512757061183e-05,
      "loss": 0.0034,
      "step": 10670
    },
    {
      "epoch": 0.9113405580680946,
      "grad_norm": 0.13598155975341797,
      "learning_rate": 4.088659441931906e-05,
      "loss": 0.0034,
      "step": 10680
    },
    {
      "epoch": 0.9121938731973718,
      "grad_norm": 0.1256973296403885,
      "learning_rate": 4.087806126802629e-05,
      "loss": 0.0032,
      "step": 10690
    },
    {
      "epoch": 0.913047188326649,
      "grad_norm": 0.18332402408123016,
      "learning_rate": 4.0869528116733516e-05,
      "loss": 0.0029,
      "step": 10700
    },
    {
      "epoch": 0.9139005034559263,
      "grad_norm": 0.15848857164382935,
      "learning_rate": 4.086099496544074e-05,
      "loss": 0.0027,
      "step": 10710
    },
    {
      "epoch": 0.9147538185852035,
      "grad_norm": 0.5393656492233276,
      "learning_rate": 4.0852461814147966e-05,
      "loss": 0.0033,
      "step": 10720
    },
    {
      "epoch": 0.9156071337144808,
      "grad_norm": 0.6555090546607971,
      "learning_rate": 4.0843928662855195e-05,
      "loss": 0.0029,
      "step": 10730
    },
    {
      "epoch": 0.916460448843758,
      "grad_norm": 0.12767933309078217,
      "learning_rate": 4.083539551156242e-05,
      "loss": 0.0031,
      "step": 10740
    },
    {
      "epoch": 0.9173137639730352,
      "grad_norm": 0.3754398822784424,
      "learning_rate": 4.082686236026965e-05,
      "loss": 0.0033,
      "step": 10750
    },
    {
      "epoch": 0.9181670791023124,
      "grad_norm": 0.15487205982208252,
      "learning_rate": 4.081832920897688e-05,
      "loss": 0.003,
      "step": 10760
    },
    {
      "epoch": 0.9190203942315898,
      "grad_norm": 0.1953226625919342,
      "learning_rate": 4.08097960576841e-05,
      "loss": 0.0033,
      "step": 10770
    },
    {
      "epoch": 0.919873709360867,
      "grad_norm": 0.15683409571647644,
      "learning_rate": 4.080126290639133e-05,
      "loss": 0.0031,
      "step": 10780
    },
    {
      "epoch": 0.9207270244901442,
      "grad_norm": 0.44071370363235474,
      "learning_rate": 4.079272975509856e-05,
      "loss": 0.0027,
      "step": 10790
    },
    {
      "epoch": 0.9215803396194214,
      "grad_norm": 0.39400023221969604,
      "learning_rate": 4.078419660380579e-05,
      "loss": 0.0029,
      "step": 10800
    },
    {
      "epoch": 0.9224336547486987,
      "grad_norm": 0.483792245388031,
      "learning_rate": 4.0775663452513016e-05,
      "loss": 0.0023,
      "step": 10810
    },
    {
      "epoch": 0.923286969877976,
      "grad_norm": 0.15999484062194824,
      "learning_rate": 4.0767130301220244e-05,
      "loss": 0.0032,
      "step": 10820
    },
    {
      "epoch": 0.9241402850072532,
      "grad_norm": 0.04873650148510933,
      "learning_rate": 4.0758597149927466e-05,
      "loss": 0.0035,
      "step": 10830
    },
    {
      "epoch": 0.9249936001365304,
      "grad_norm": 0.29463818669319153,
      "learning_rate": 4.0750063998634694e-05,
      "loss": 0.0033,
      "step": 10840
    },
    {
      "epoch": 0.9258469152658076,
      "grad_norm": 0.8182419538497925,
      "learning_rate": 4.074153084734192e-05,
      "loss": 0.0029,
      "step": 10850
    },
    {
      "epoch": 0.9267002303950849,
      "grad_norm": 0.32840561866760254,
      "learning_rate": 4.073299769604915e-05,
      "loss": 0.0028,
      "step": 10860
    },
    {
      "epoch": 0.9275535455243622,
      "grad_norm": 0.5819991230964661,
      "learning_rate": 4.072446454475638e-05,
      "loss": 0.0038,
      "step": 10870
    },
    {
      "epoch": 0.9284068606536394,
      "grad_norm": 0.6209667921066284,
      "learning_rate": 4.071593139346361e-05,
      "loss": 0.004,
      "step": 10880
    },
    {
      "epoch": 0.9292601757829166,
      "grad_norm": 0.06613528728485107,
      "learning_rate": 4.070739824217084e-05,
      "loss": 0.0031,
      "step": 10890
    },
    {
      "epoch": 0.9301134909121939,
      "grad_norm": 0.3345825672149658,
      "learning_rate": 4.0698865090878065e-05,
      "loss": 0.0023,
      "step": 10900
    },
    {
      "epoch": 0.9309668060414711,
      "grad_norm": 0.08249755203723907,
      "learning_rate": 4.0690331939585294e-05,
      "loss": 0.0033,
      "step": 10910
    },
    {
      "epoch": 0.9318201211707483,
      "grad_norm": 0.7436190843582153,
      "learning_rate": 4.068179878829252e-05,
      "loss": 0.0031,
      "step": 10920
    },
    {
      "epoch": 0.9326734363000256,
      "grad_norm": 0.2034437656402588,
      "learning_rate": 4.0673265636999744e-05,
      "loss": 0.0027,
      "step": 10930
    },
    {
      "epoch": 0.9335267514293029,
      "grad_norm": 0.34204038977622986,
      "learning_rate": 4.066473248570697e-05,
      "loss": 0.0043,
      "step": 10940
    },
    {
      "epoch": 0.9343800665585801,
      "grad_norm": 0.12093208730220795,
      "learning_rate": 4.06561993344142e-05,
      "loss": 0.0028,
      "step": 10950
    },
    {
      "epoch": 0.9352333816878573,
      "grad_norm": 0.28154870867729187,
      "learning_rate": 4.064766618312143e-05,
      "loss": 0.0029,
      "step": 10960
    },
    {
      "epoch": 0.9360866968171345,
      "grad_norm": 0.07601258158683777,
      "learning_rate": 4.063913303182866e-05,
      "loss": 0.0041,
      "step": 10970
    },
    {
      "epoch": 0.9369400119464119,
      "grad_norm": 0.32960060238838196,
      "learning_rate": 4.0630599880535886e-05,
      "loss": 0.0034,
      "step": 10980
    },
    {
      "epoch": 0.9377933270756891,
      "grad_norm": 0.4981513023376465,
      "learning_rate": 4.0622066729243115e-05,
      "loss": 0.0038,
      "step": 10990
    },
    {
      "epoch": 0.9386466422049663,
      "grad_norm": 0.3623938262462616,
      "learning_rate": 4.061353357795034e-05,
      "loss": 0.0031,
      "step": 11000
    },
    {
      "epoch": 0.9394999573342435,
      "grad_norm": 0.21968460083007812,
      "learning_rate": 4.060500042665757e-05,
      "loss": 0.0037,
      "step": 11010
    },
    {
      "epoch": 0.9403532724635207,
      "grad_norm": 0.23289547860622406,
      "learning_rate": 4.05964672753648e-05,
      "loss": 0.0031,
      "step": 11020
    },
    {
      "epoch": 0.9412065875927981,
      "grad_norm": 0.2142481952905655,
      "learning_rate": 4.058793412407202e-05,
      "loss": 0.0029,
      "step": 11030
    },
    {
      "epoch": 0.9420599027220753,
      "grad_norm": 0.10654813796281815,
      "learning_rate": 4.0579400972779244e-05,
      "loss": 0.0026,
      "step": 11040
    },
    {
      "epoch": 0.9429132178513525,
      "grad_norm": 0.08195021003484726,
      "learning_rate": 4.057086782148647e-05,
      "loss": 0.0033,
      "step": 11050
    },
    {
      "epoch": 0.9437665329806297,
      "grad_norm": 0.21813522279262543,
      "learning_rate": 4.05623346701937e-05,
      "loss": 0.0032,
      "step": 11060
    },
    {
      "epoch": 0.944619848109907,
      "grad_norm": 0.2329491674900055,
      "learning_rate": 4.055380151890093e-05,
      "loss": 0.0034,
      "step": 11070
    },
    {
      "epoch": 0.9454731632391842,
      "grad_norm": 0.14311927556991577,
      "learning_rate": 4.054526836760816e-05,
      "loss": 0.0026,
      "step": 11080
    },
    {
      "epoch": 0.9463264783684615,
      "grad_norm": 0.41032376885414124,
      "learning_rate": 4.0536735216315386e-05,
      "loss": 0.0029,
      "step": 11090
    },
    {
      "epoch": 0.9471797934977387,
      "grad_norm": 0.4679606854915619,
      "learning_rate": 4.0528202065022614e-05,
      "loss": 0.0026,
      "step": 11100
    },
    {
      "epoch": 0.948033108627016,
      "grad_norm": 0.11521412432193756,
      "learning_rate": 4.051966891372984e-05,
      "loss": 0.0027,
      "step": 11110
    },
    {
      "epoch": 0.9488864237562932,
      "grad_norm": 0.3332231640815735,
      "learning_rate": 4.051113576243707e-05,
      "loss": 0.0034,
      "step": 11120
    },
    {
      "epoch": 0.9497397388855704,
      "grad_norm": 0.5424078702926636,
      "learning_rate": 4.05026026111443e-05,
      "loss": 0.0037,
      "step": 11130
    },
    {
      "epoch": 0.9505930540148477,
      "grad_norm": 0.1150173544883728,
      "learning_rate": 4.049406945985152e-05,
      "loss": 0.0028,
      "step": 11140
    },
    {
      "epoch": 0.951446369144125,
      "grad_norm": 0.03896544501185417,
      "learning_rate": 4.048553630855875e-05,
      "loss": 0.0029,
      "step": 11150
    },
    {
      "epoch": 0.9522996842734022,
      "grad_norm": 0.2417750060558319,
      "learning_rate": 4.047700315726598e-05,
      "loss": 0.0029,
      "step": 11160
    },
    {
      "epoch": 0.9531529994026794,
      "grad_norm": 0.4879295527935028,
      "learning_rate": 4.046847000597321e-05,
      "loss": 0.0032,
      "step": 11170
    },
    {
      "epoch": 0.9540063145319566,
      "grad_norm": 0.11008409410715103,
      "learning_rate": 4.0459936854680436e-05,
      "loss": 0.0034,
      "step": 11180
    },
    {
      "epoch": 0.9548596296612339,
      "grad_norm": 0.46755385398864746,
      "learning_rate": 4.0451403703387664e-05,
      "loss": 0.0041,
      "step": 11190
    },
    {
      "epoch": 0.9557129447905112,
      "grad_norm": 0.21428179740905762,
      "learning_rate": 4.044287055209489e-05,
      "loss": 0.0032,
      "step": 11200
    },
    {
      "epoch": 0.9565662599197884,
      "grad_norm": 0.5062347650527954,
      "learning_rate": 4.043433740080212e-05,
      "loss": 0.0034,
      "step": 11210
    },
    {
      "epoch": 0.9574195750490656,
      "grad_norm": 0.09458843618631363,
      "learning_rate": 4.042580424950935e-05,
      "loss": 0.0035,
      "step": 11220
    },
    {
      "epoch": 0.9582728901783428,
      "grad_norm": 0.2966957688331604,
      "learning_rate": 4.041727109821658e-05,
      "loss": 0.0023,
      "step": 11230
    },
    {
      "epoch": 0.95912620530762,
      "grad_norm": 0.2620347738265991,
      "learning_rate": 4.04087379469238e-05,
      "loss": 0.0038,
      "step": 11240
    },
    {
      "epoch": 0.9599795204368974,
      "grad_norm": 0.2243102341890335,
      "learning_rate": 4.040020479563103e-05,
      "loss": 0.0033,
      "step": 11250
    },
    {
      "epoch": 0.9608328355661746,
      "grad_norm": 0.1401246339082718,
      "learning_rate": 4.0391671644338257e-05,
      "loss": 0.0027,
      "step": 11260
    },
    {
      "epoch": 0.9616861506954518,
      "grad_norm": 0.3602477014064789,
      "learning_rate": 4.0383138493045485e-05,
      "loss": 0.0033,
      "step": 11270
    },
    {
      "epoch": 0.962539465824729,
      "grad_norm": 0.1340133398771286,
      "learning_rate": 4.0374605341752714e-05,
      "loss": 0.0031,
      "step": 11280
    },
    {
      "epoch": 0.9633927809540063,
      "grad_norm": 0.06805774569511414,
      "learning_rate": 4.036607219045994e-05,
      "loss": 0.0034,
      "step": 11290
    },
    {
      "epoch": 0.9642460960832836,
      "grad_norm": 0.5263454914093018,
      "learning_rate": 4.0357539039167164e-05,
      "loss": 0.0035,
      "step": 11300
    },
    {
      "epoch": 0.9650994112125608,
      "grad_norm": 0.2906067669391632,
      "learning_rate": 4.034900588787439e-05,
      "loss": 0.0028,
      "step": 11310
    },
    {
      "epoch": 0.965952726341838,
      "grad_norm": 0.05161571502685547,
      "learning_rate": 4.034047273658162e-05,
      "loss": 0.0032,
      "step": 11320
    },
    {
      "epoch": 0.9668060414711153,
      "grad_norm": 0.2762705385684967,
      "learning_rate": 4.033193958528885e-05,
      "loss": 0.0025,
      "step": 11330
    },
    {
      "epoch": 0.9676593566003925,
      "grad_norm": 0.06059889867901802,
      "learning_rate": 4.032340643399608e-05,
      "loss": 0.0026,
      "step": 11340
    },
    {
      "epoch": 0.9685126717296698,
      "grad_norm": 0.17667663097381592,
      "learning_rate": 4.03148732827033e-05,
      "loss": 0.0035,
      "step": 11350
    },
    {
      "epoch": 0.969365986858947,
      "grad_norm": 0.2680177688598633,
      "learning_rate": 4.030634013141053e-05,
      "loss": 0.0045,
      "step": 11360
    },
    {
      "epoch": 0.9702193019882243,
      "grad_norm": 0.2207629233598709,
      "learning_rate": 4.0297806980117756e-05,
      "loss": 0.0024,
      "step": 11370
    },
    {
      "epoch": 0.9710726171175015,
      "grad_norm": 0.06857438385486603,
      "learning_rate": 4.0289273828824985e-05,
      "loss": 0.0031,
      "step": 11380
    },
    {
      "epoch": 0.9719259322467787,
      "grad_norm": 0.20608949661254883,
      "learning_rate": 4.028074067753221e-05,
      "loss": 0.0026,
      "step": 11390
    },
    {
      "epoch": 0.9727792473760559,
      "grad_norm": 0.284418523311615,
      "learning_rate": 4.027220752623944e-05,
      "loss": 0.0032,
      "step": 11400
    },
    {
      "epoch": 0.9736325625053333,
      "grad_norm": 0.31376326084136963,
      "learning_rate": 4.026367437494667e-05,
      "loss": 0.0032,
      "step": 11410
    },
    {
      "epoch": 0.9744858776346105,
      "grad_norm": 0.27049362659454346,
      "learning_rate": 4.02551412236539e-05,
      "loss": 0.0026,
      "step": 11420
    },
    {
      "epoch": 0.9753391927638877,
      "grad_norm": 0.3385254144668579,
      "learning_rate": 4.024660807236113e-05,
      "loss": 0.0026,
      "step": 11430
    },
    {
      "epoch": 0.9761925078931649,
      "grad_norm": 0.06293632835149765,
      "learning_rate": 4.0238074921068356e-05,
      "loss": 0.0033,
      "step": 11440
    },
    {
      "epoch": 0.9770458230224421,
      "grad_norm": 0.05607645958662033,
      "learning_rate": 4.022954176977558e-05,
      "loss": 0.0027,
      "step": 11450
    },
    {
      "epoch": 0.9778991381517195,
      "grad_norm": 0.1916564404964447,
      "learning_rate": 4.0221008618482806e-05,
      "loss": 0.0027,
      "step": 11460
    },
    {
      "epoch": 0.9787524532809967,
      "grad_norm": 0.06188346445560455,
      "learning_rate": 4.0212475467190034e-05,
      "loss": 0.0034,
      "step": 11470
    },
    {
      "epoch": 0.9796057684102739,
      "grad_norm": 0.12820659577846527,
      "learning_rate": 4.020394231589726e-05,
      "loss": 0.0035,
      "step": 11480
    },
    {
      "epoch": 0.9804590835395511,
      "grad_norm": 0.16338828206062317,
      "learning_rate": 4.019540916460449e-05,
      "loss": 0.0026,
      "step": 11490
    },
    {
      "epoch": 0.9813123986688284,
      "grad_norm": 0.11046882718801498,
      "learning_rate": 4.018687601331172e-05,
      "loss": 0.0034,
      "step": 11500
    },
    {
      "epoch": 0.9821657137981057,
      "grad_norm": 0.215978741645813,
      "learning_rate": 4.017834286201895e-05,
      "loss": 0.0029,
      "step": 11510
    },
    {
      "epoch": 0.9830190289273829,
      "grad_norm": 0.2530033588409424,
      "learning_rate": 4.016980971072618e-05,
      "loss": 0.0033,
      "step": 11520
    },
    {
      "epoch": 0.9838723440566601,
      "grad_norm": 0.24257124960422516,
      "learning_rate": 4.0161276559433405e-05,
      "loss": 0.0034,
      "step": 11530
    },
    {
      "epoch": 0.9847256591859374,
      "grad_norm": 0.3656938970088959,
      "learning_rate": 4.0152743408140634e-05,
      "loss": 0.0038,
      "step": 11540
    },
    {
      "epoch": 0.9855789743152146,
      "grad_norm": 0.7500118017196655,
      "learning_rate": 4.0144210256847855e-05,
      "loss": 0.0029,
      "step": 11550
    },
    {
      "epoch": 0.9864322894444919,
      "grad_norm": 0.2913965880870819,
      "learning_rate": 4.0135677105555084e-05,
      "loss": 0.0034,
      "step": 11560
    },
    {
      "epoch": 0.9872856045737691,
      "grad_norm": 0.4482349157333374,
      "learning_rate": 4.0127143954262306e-05,
      "loss": 0.0035,
      "step": 11570
    },
    {
      "epoch": 0.9881389197030463,
      "grad_norm": 0.037535410374403,
      "learning_rate": 4.0118610802969534e-05,
      "loss": 0.0028,
      "step": 11580
    },
    {
      "epoch": 0.9889922348323236,
      "grad_norm": 0.13752463459968567,
      "learning_rate": 4.011007765167676e-05,
      "loss": 0.0024,
      "step": 11590
    },
    {
      "epoch": 0.9898455499616008,
      "grad_norm": 0.13589437305927277,
      "learning_rate": 4.010154450038399e-05,
      "loss": 0.0029,
      "step": 11600
    },
    {
      "epoch": 0.990698865090878,
      "grad_norm": 0.2738831043243408,
      "learning_rate": 4.009301134909122e-05,
      "loss": 0.0024,
      "step": 11610
    },
    {
      "epoch": 0.9915521802201553,
      "grad_norm": 0.5306028723716736,
      "learning_rate": 4.008447819779845e-05,
      "loss": 0.0024,
      "step": 11620
    },
    {
      "epoch": 0.9924054953494326,
      "grad_norm": 0.23480823636054993,
      "learning_rate": 4.0075945046505677e-05,
      "loss": 0.0034,
      "step": 11630
    },
    {
      "epoch": 0.9932588104787098,
      "grad_norm": 0.3521096706390381,
      "learning_rate": 4.0067411895212905e-05,
      "loss": 0.0035,
      "step": 11640
    },
    {
      "epoch": 0.994112125607987,
      "grad_norm": 0.46663957834243774,
      "learning_rate": 4.0058878743920134e-05,
      "loss": 0.0028,
      "step": 11650
    },
    {
      "epoch": 0.9949654407372642,
      "grad_norm": 0.1296703815460205,
      "learning_rate": 4.0050345592627355e-05,
      "loss": 0.0032,
      "step": 11660
    },
    {
      "epoch": 0.9958187558665416,
      "grad_norm": 0.10732828825712204,
      "learning_rate": 4.0041812441334584e-05,
      "loss": 0.003,
      "step": 11670
    },
    {
      "epoch": 0.9966720709958188,
      "grad_norm": 0.2766496539115906,
      "learning_rate": 4.003327929004181e-05,
      "loss": 0.0028,
      "step": 11680
    },
    {
      "epoch": 0.997525386125096,
      "grad_norm": 0.12552712857723236,
      "learning_rate": 4.002474613874904e-05,
      "loss": 0.0031,
      "step": 11690
    },
    {
      "epoch": 0.9983787012543732,
      "grad_norm": 0.1526240110397339,
      "learning_rate": 4.001621298745627e-05,
      "loss": 0.0033,
      "step": 11700
    },
    {
      "epoch": 0.9992320163836504,
      "grad_norm": 0.2153492569923401,
      "learning_rate": 4.00076798361635e-05,
      "loss": 0.0035,
      "step": 11710
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.002971032401546836,
      "eval_runtime": 103.7552,
      "eval_samples_per_second": 1445.711,
      "eval_steps_per_second": 22.592,
      "step": 11719
    },
    {
      "epoch": 1.0000853315129277,
      "grad_norm": 0.03600744530558586,
      "learning_rate": 3.9999146684870726e-05,
      "loss": 0.0034,
      "step": 11720
    },
    {
      "epoch": 1.000938646642205,
      "grad_norm": 0.16465213894844055,
      "learning_rate": 3.9990613533577955e-05,
      "loss": 0.0027,
      "step": 11730
    },
    {
      "epoch": 1.001791961771482,
      "grad_norm": 0.1930130571126938,
      "learning_rate": 3.998208038228518e-05,
      "loss": 0.0031,
      "step": 11740
    },
    {
      "epoch": 1.0026452769007594,
      "grad_norm": 0.15601082146167755,
      "learning_rate": 3.997354723099241e-05,
      "loss": 0.0032,
      "step": 11750
    },
    {
      "epoch": 1.0034985920300368,
      "grad_norm": 0.14988629519939423,
      "learning_rate": 3.996501407969963e-05,
      "loss": 0.0029,
      "step": 11760
    },
    {
      "epoch": 1.0043519071593139,
      "grad_norm": 0.17354170978069305,
      "learning_rate": 3.995648092840686e-05,
      "loss": 0.0028,
      "step": 11770
    },
    {
      "epoch": 1.0052052222885912,
      "grad_norm": 0.3923473656177521,
      "learning_rate": 3.994794777711409e-05,
      "loss": 0.003,
      "step": 11780
    },
    {
      "epoch": 1.0060585374178683,
      "grad_norm": 0.5303754806518555,
      "learning_rate": 3.993941462582132e-05,
      "loss": 0.0029,
      "step": 11790
    },
    {
      "epoch": 1.0069118525471457,
      "grad_norm": 0.2591894567012787,
      "learning_rate": 3.993088147452855e-05,
      "loss": 0.0041,
      "step": 11800
    },
    {
      "epoch": 1.007765167676423,
      "grad_norm": 0.5100566148757935,
      "learning_rate": 3.9922348323235776e-05,
      "loss": 0.004,
      "step": 11810
    },
    {
      "epoch": 1.0086184828057,
      "grad_norm": 0.3618808388710022,
      "learning_rate": 3.9913815171943004e-05,
      "loss": 0.0034,
      "step": 11820
    },
    {
      "epoch": 1.0094717979349774,
      "grad_norm": 0.13519559800624847,
      "learning_rate": 3.9905282020650226e-05,
      "loss": 0.0036,
      "step": 11830
    },
    {
      "epoch": 1.0103251130642545,
      "grad_norm": 0.10885532200336456,
      "learning_rate": 3.9896748869357454e-05,
      "loss": 0.0021,
      "step": 11840
    },
    {
      "epoch": 1.0111784281935319,
      "grad_norm": 0.2534075379371643,
      "learning_rate": 3.988821571806468e-05,
      "loss": 0.0035,
      "step": 11850
    },
    {
      "epoch": 1.0120317433228092,
      "grad_norm": 0.504142165184021,
      "learning_rate": 3.987968256677191e-05,
      "loss": 0.0026,
      "step": 11860
    },
    {
      "epoch": 1.0128850584520863,
      "grad_norm": 0.5037612915039062,
      "learning_rate": 3.987114941547914e-05,
      "loss": 0.0028,
      "step": 11870
    },
    {
      "epoch": 1.0137383735813636,
      "grad_norm": 0.0858311727643013,
      "learning_rate": 3.986261626418636e-05,
      "loss": 0.0027,
      "step": 11880
    },
    {
      "epoch": 1.0145916887106408,
      "grad_norm": 0.2505277395248413,
      "learning_rate": 3.985408311289359e-05,
      "loss": 0.0037,
      "step": 11890
    },
    {
      "epoch": 1.015445003839918,
      "grad_norm": 0.09157592803239822,
      "learning_rate": 3.984554996160082e-05,
      "loss": 0.0028,
      "step": 11900
    },
    {
      "epoch": 1.0162983189691954,
      "grad_norm": 0.13813558220863342,
      "learning_rate": 3.983701681030805e-05,
      "loss": 0.0029,
      "step": 11910
    },
    {
      "epoch": 1.0171516340984725,
      "grad_norm": 0.13744106888771057,
      "learning_rate": 3.9828483659015275e-05,
      "loss": 0.0022,
      "step": 11920
    },
    {
      "epoch": 1.0180049492277499,
      "grad_norm": 0.17351078987121582,
      "learning_rate": 3.9819950507722504e-05,
      "loss": 0.0028,
      "step": 11930
    },
    {
      "epoch": 1.018858264357027,
      "grad_norm": 0.17532840371131897,
      "learning_rate": 3.981141735642973e-05,
      "loss": 0.0029,
      "step": 11940
    },
    {
      "epoch": 1.0197115794863043,
      "grad_norm": 0.12547823786735535,
      "learning_rate": 3.980288420513696e-05,
      "loss": 0.0036,
      "step": 11950
    },
    {
      "epoch": 1.0205648946155816,
      "grad_norm": 0.2046700268983841,
      "learning_rate": 3.979435105384419e-05,
      "loss": 0.0024,
      "step": 11960
    },
    {
      "epoch": 1.0214182097448588,
      "grad_norm": 0.4743146300315857,
      "learning_rate": 3.978581790255141e-05,
      "loss": 0.0034,
      "step": 11970
    },
    {
      "epoch": 1.022271524874136,
      "grad_norm": 0.17667177319526672,
      "learning_rate": 3.977728475125864e-05,
      "loss": 0.0024,
      "step": 11980
    },
    {
      "epoch": 1.0231248400034132,
      "grad_norm": 0.714126467704773,
      "learning_rate": 3.976875159996587e-05,
      "loss": 0.0025,
      "step": 11990
    },
    {
      "epoch": 1.0239781551326905,
      "grad_norm": 0.46895697712898254,
      "learning_rate": 3.9760218448673097e-05,
      "loss": 0.004,
      "step": 12000
    },
    {
      "epoch": 1.0248314702619676,
      "grad_norm": 0.3294745087623596,
      "learning_rate": 3.9751685297380325e-05,
      "loss": 0.0025,
      "step": 12010
    },
    {
      "epoch": 1.025684785391245,
      "grad_norm": 0.1579936295747757,
      "learning_rate": 3.9743152146087553e-05,
      "loss": 0.0028,
      "step": 12020
    },
    {
      "epoch": 1.0265381005205223,
      "grad_norm": 0.3710043430328369,
      "learning_rate": 3.973461899479478e-05,
      "loss": 0.0028,
      "step": 12030
    },
    {
      "epoch": 1.0273914156497994,
      "grad_norm": 0.5090431571006775,
      "learning_rate": 3.972608584350201e-05,
      "loss": 0.0037,
      "step": 12040
    },
    {
      "epoch": 1.0282447307790767,
      "grad_norm": 0.6765609979629517,
      "learning_rate": 3.971755269220924e-05,
      "loss": 0.0023,
      "step": 12050
    },
    {
      "epoch": 1.0290980459083539,
      "grad_norm": 0.0914757251739502,
      "learning_rate": 3.970901954091647e-05,
      "loss": 0.0026,
      "step": 12060
    },
    {
      "epoch": 1.0299513610376312,
      "grad_norm": 0.10221890360116959,
      "learning_rate": 3.970048638962369e-05,
      "loss": 0.0029,
      "step": 12070
    },
    {
      "epoch": 1.0308046761669085,
      "grad_norm": 0.17700056731700897,
      "learning_rate": 3.969195323833092e-05,
      "loss": 0.0037,
      "step": 12080
    },
    {
      "epoch": 1.0316579912961856,
      "grad_norm": 0.14302374422550201,
      "learning_rate": 3.9683420087038146e-05,
      "loss": 0.0029,
      "step": 12090
    },
    {
      "epoch": 1.032511306425463,
      "grad_norm": 0.2106713056564331,
      "learning_rate": 3.967488693574537e-05,
      "loss": 0.0023,
      "step": 12100
    },
    {
      "epoch": 1.03336462155474,
      "grad_norm": 0.3295775353908539,
      "learning_rate": 3.9666353784452596e-05,
      "loss": 0.0029,
      "step": 12110
    },
    {
      "epoch": 1.0342179366840174,
      "grad_norm": 0.059710901230573654,
      "learning_rate": 3.9657820633159825e-05,
      "loss": 0.0026,
      "step": 12120
    },
    {
      "epoch": 1.0350712518132947,
      "grad_norm": 0.11319532245397568,
      "learning_rate": 3.964928748186705e-05,
      "loss": 0.0024,
      "step": 12130
    },
    {
      "epoch": 1.0359245669425718,
      "grad_norm": 0.15666703879833221,
      "learning_rate": 3.964075433057428e-05,
      "loss": 0.0029,
      "step": 12140
    },
    {
      "epoch": 1.0367778820718492,
      "grad_norm": 0.08169879764318466,
      "learning_rate": 3.963222117928151e-05,
      "loss": 0.0036,
      "step": 12150
    },
    {
      "epoch": 1.0376311972011263,
      "grad_norm": 0.15742862224578857,
      "learning_rate": 3.962368802798874e-05,
      "loss": 0.0036,
      "step": 12160
    },
    {
      "epoch": 1.0384845123304036,
      "grad_norm": 0.24220630526542664,
      "learning_rate": 3.961515487669597e-05,
      "loss": 0.0035,
      "step": 12170
    },
    {
      "epoch": 1.039337827459681,
      "grad_norm": 0.2179301232099533,
      "learning_rate": 3.9606621725403196e-05,
      "loss": 0.0026,
      "step": 12180
    },
    {
      "epoch": 1.040191142588958,
      "grad_norm": 0.25806450843811035,
      "learning_rate": 3.959808857411042e-05,
      "loss": 0.0037,
      "step": 12190
    },
    {
      "epoch": 1.0410444577182354,
      "grad_norm": 0.19207437336444855,
      "learning_rate": 3.9589555422817646e-05,
      "loss": 0.0023,
      "step": 12200
    },
    {
      "epoch": 1.0418977728475125,
      "grad_norm": 0.185215026140213,
      "learning_rate": 3.9581022271524874e-05,
      "loss": 0.0032,
      "step": 12210
    },
    {
      "epoch": 1.0427510879767898,
      "grad_norm": 0.28916096687316895,
      "learning_rate": 3.95724891202321e-05,
      "loss": 0.0039,
      "step": 12220
    },
    {
      "epoch": 1.0436044031060672,
      "grad_norm": 0.40695077180862427,
      "learning_rate": 3.956395596893933e-05,
      "loss": 0.0034,
      "step": 12230
    },
    {
      "epoch": 1.0444577182353443,
      "grad_norm": 0.15950387716293335,
      "learning_rate": 3.955542281764656e-05,
      "loss": 0.0032,
      "step": 12240
    },
    {
      "epoch": 1.0453110333646216,
      "grad_norm": 0.18108007311820984,
      "learning_rate": 3.954688966635379e-05,
      "loss": 0.0033,
      "step": 12250
    },
    {
      "epoch": 1.0461643484938987,
      "grad_norm": 0.17673000693321228,
      "learning_rate": 3.953835651506102e-05,
      "loss": 0.0038,
      "step": 12260
    },
    {
      "epoch": 1.047017663623176,
      "grad_norm": 0.21311312913894653,
      "learning_rate": 3.9529823363768245e-05,
      "loss": 0.0029,
      "step": 12270
    },
    {
      "epoch": 1.0478709787524534,
      "grad_norm": 0.27344974875450134,
      "learning_rate": 3.952129021247547e-05,
      "loss": 0.0025,
      "step": 12280
    },
    {
      "epoch": 1.0487242938817305,
      "grad_norm": 0.22164921462535858,
      "learning_rate": 3.9512757061182695e-05,
      "loss": 0.0041,
      "step": 12290
    },
    {
      "epoch": 1.0495776090110078,
      "grad_norm": 0.5959066152572632,
      "learning_rate": 3.9504223909889924e-05,
      "loss": 0.0032,
      "step": 12300
    },
    {
      "epoch": 1.050430924140285,
      "grad_norm": 0.819561779499054,
      "learning_rate": 3.949569075859715e-05,
      "loss": 0.003,
      "step": 12310
    },
    {
      "epoch": 1.0512842392695623,
      "grad_norm": 0.05625538155436516,
      "learning_rate": 3.948715760730438e-05,
      "loss": 0.0023,
      "step": 12320
    },
    {
      "epoch": 1.0521375543988394,
      "grad_norm": 0.04784858971834183,
      "learning_rate": 3.947862445601161e-05,
      "loss": 0.0041,
      "step": 12330
    },
    {
      "epoch": 1.0529908695281167,
      "grad_norm": 0.17206069827079773,
      "learning_rate": 3.947009130471884e-05,
      "loss": 0.0026,
      "step": 12340
    },
    {
      "epoch": 1.053844184657394,
      "grad_norm": 0.17884108424186707,
      "learning_rate": 3.9461558153426066e-05,
      "loss": 0.0031,
      "step": 12350
    },
    {
      "epoch": 1.0546974997866712,
      "grad_norm": 0.12336894124746323,
      "learning_rate": 3.945302500213329e-05,
      "loss": 0.0033,
      "step": 12360
    },
    {
      "epoch": 1.0555508149159485,
      "grad_norm": 0.33626455068588257,
      "learning_rate": 3.9444491850840516e-05,
      "loss": 0.0025,
      "step": 12370
    },
    {
      "epoch": 1.0564041300452256,
      "grad_norm": 0.08153095841407776,
      "learning_rate": 3.9435958699547745e-05,
      "loss": 0.0033,
      "step": 12380
    },
    {
      "epoch": 1.057257445174503,
      "grad_norm": 0.15996311604976654,
      "learning_rate": 3.9427425548254973e-05,
      "loss": 0.0029,
      "step": 12390
    },
    {
      "epoch": 1.0581107603037803,
      "grad_norm": 0.38714396953582764,
      "learning_rate": 3.9418892396962195e-05,
      "loss": 0.0036,
      "step": 12400
    },
    {
      "epoch": 1.0589640754330574,
      "grad_norm": 0.27316927909851074,
      "learning_rate": 3.9410359245669424e-05,
      "loss": 0.0025,
      "step": 12410
    },
    {
      "epoch": 1.0598173905623347,
      "grad_norm": 0.27138036489486694,
      "learning_rate": 3.940182609437665e-05,
      "loss": 0.0031,
      "step": 12420
    },
    {
      "epoch": 1.0606707056916118,
      "grad_norm": 0.4421950876712799,
      "learning_rate": 3.939329294308388e-05,
      "loss": 0.0025,
      "step": 12430
    },
    {
      "epoch": 1.0615240208208891,
      "grad_norm": 0.23670998215675354,
      "learning_rate": 3.938475979179111e-05,
      "loss": 0.0031,
      "step": 12440
    },
    {
      "epoch": 1.0623773359501665,
      "grad_norm": 0.2278699278831482,
      "learning_rate": 3.937622664049834e-05,
      "loss": 0.0029,
      "step": 12450
    },
    {
      "epoch": 1.0632306510794436,
      "grad_norm": 0.1976337730884552,
      "learning_rate": 3.9367693489205566e-05,
      "loss": 0.0035,
      "step": 12460
    },
    {
      "epoch": 1.064083966208721,
      "grad_norm": 0.5862188935279846,
      "learning_rate": 3.9359160337912795e-05,
      "loss": 0.0034,
      "step": 12470
    },
    {
      "epoch": 1.064937281337998,
      "grad_norm": 0.3518064618110657,
      "learning_rate": 3.935062718662002e-05,
      "loss": 0.0026,
      "step": 12480
    },
    {
      "epoch": 1.0657905964672754,
      "grad_norm": 0.5619802474975586,
      "learning_rate": 3.934209403532725e-05,
      "loss": 0.0042,
      "step": 12490
    },
    {
      "epoch": 1.0666439115965527,
      "grad_norm": 0.17579121887683868,
      "learning_rate": 3.933356088403447e-05,
      "loss": 0.0025,
      "step": 12500
    },
    {
      "epoch": 1.0674972267258298,
      "grad_norm": 0.09991823881864548,
      "learning_rate": 3.93250277327417e-05,
      "loss": 0.0024,
      "step": 12510
    },
    {
      "epoch": 1.0683505418551071,
      "grad_norm": 0.1832122653722763,
      "learning_rate": 3.931649458144893e-05,
      "loss": 0.0033,
      "step": 12520
    },
    {
      "epoch": 1.0692038569843842,
      "grad_norm": 0.37988826632499695,
      "learning_rate": 3.930796143015616e-05,
      "loss": 0.0027,
      "step": 12530
    },
    {
      "epoch": 1.0700571721136616,
      "grad_norm": 0.3704422116279602,
      "learning_rate": 3.929942827886339e-05,
      "loss": 0.0033,
      "step": 12540
    },
    {
      "epoch": 1.070910487242939,
      "grad_norm": 0.09830161184072495,
      "learning_rate": 3.9290895127570616e-05,
      "loss": 0.0025,
      "step": 12550
    },
    {
      "epoch": 1.071763802372216,
      "grad_norm": 0.22666527330875397,
      "learning_rate": 3.9282361976277844e-05,
      "loss": 0.0031,
      "step": 12560
    },
    {
      "epoch": 1.0726171175014934,
      "grad_norm": 0.35770896077156067,
      "learning_rate": 3.927382882498507e-05,
      "loss": 0.0024,
      "step": 12570
    },
    {
      "epoch": 1.0734704326307705,
      "grad_norm": 0.6262360215187073,
      "learning_rate": 3.92652956736923e-05,
      "loss": 0.0032,
      "step": 12580
    },
    {
      "epoch": 1.0743237477600478,
      "grad_norm": 0.2978818714618683,
      "learning_rate": 3.925676252239953e-05,
      "loss": 0.0041,
      "step": 12590
    },
    {
      "epoch": 1.0751770628893251,
      "grad_norm": 0.4436773359775543,
      "learning_rate": 3.924822937110675e-05,
      "loss": 0.0042,
      "step": 12600
    },
    {
      "epoch": 1.0760303780186022,
      "grad_norm": 0.35589784383773804,
      "learning_rate": 3.923969621981398e-05,
      "loss": 0.0026,
      "step": 12610
    },
    {
      "epoch": 1.0768836931478796,
      "grad_norm": 0.2552669942378998,
      "learning_rate": 3.923116306852121e-05,
      "loss": 0.003,
      "step": 12620
    },
    {
      "epoch": 1.0777370082771567,
      "grad_norm": 0.23381407558918,
      "learning_rate": 3.922262991722843e-05,
      "loss": 0.0029,
      "step": 12630
    },
    {
      "epoch": 1.078590323406434,
      "grad_norm": 0.3052460253238678,
      "learning_rate": 3.921409676593566e-05,
      "loss": 0.0025,
      "step": 12640
    },
    {
      "epoch": 1.0794436385357113,
      "grad_norm": 0.2254217565059662,
      "learning_rate": 3.920556361464289e-05,
      "loss": 0.0035,
      "step": 12650
    },
    {
      "epoch": 1.0802969536649885,
      "grad_norm": 0.3037703335285187,
      "learning_rate": 3.9197030463350115e-05,
      "loss": 0.0028,
      "step": 12660
    },
    {
      "epoch": 1.0811502687942658,
      "grad_norm": 0.8580294847488403,
      "learning_rate": 3.9188497312057344e-05,
      "loss": 0.003,
      "step": 12670
    },
    {
      "epoch": 1.082003583923543,
      "grad_norm": 0.4514671266078949,
      "learning_rate": 3.917996416076457e-05,
      "loss": 0.0026,
      "step": 12680
    },
    {
      "epoch": 1.0828568990528202,
      "grad_norm": 0.2016017884016037,
      "learning_rate": 3.91714310094718e-05,
      "loss": 0.0035,
      "step": 12690
    },
    {
      "epoch": 1.0837102141820973,
      "grad_norm": 0.34257686138153076,
      "learning_rate": 3.916289785817903e-05,
      "loss": 0.0039,
      "step": 12700
    },
    {
      "epoch": 1.0845635293113747,
      "grad_norm": 0.295348584651947,
      "learning_rate": 3.915436470688625e-05,
      "loss": 0.0033,
      "step": 12710
    },
    {
      "epoch": 1.085416844440652,
      "grad_norm": 0.7484064102172852,
      "learning_rate": 3.914583155559348e-05,
      "loss": 0.0034,
      "step": 12720
    },
    {
      "epoch": 1.0862701595699291,
      "grad_norm": 0.039599671959877014,
      "learning_rate": 3.913729840430071e-05,
      "loss": 0.0029,
      "step": 12730
    },
    {
      "epoch": 1.0871234746992064,
      "grad_norm": 0.4473130404949188,
      "learning_rate": 3.9128765253007936e-05,
      "loss": 0.0032,
      "step": 12740
    },
    {
      "epoch": 1.0879767898284836,
      "grad_norm": 0.15621893107891083,
      "learning_rate": 3.9120232101715165e-05,
      "loss": 0.0028,
      "step": 12750
    },
    {
      "epoch": 1.088830104957761,
      "grad_norm": 0.3114675283432007,
      "learning_rate": 3.911169895042239e-05,
      "loss": 0.0033,
      "step": 12760
    },
    {
      "epoch": 1.0896834200870382,
      "grad_norm": 0.2930071949958801,
      "learning_rate": 3.910316579912962e-05,
      "loss": 0.0034,
      "step": 12770
    },
    {
      "epoch": 1.0905367352163153,
      "grad_norm": 0.16139966249465942,
      "learning_rate": 3.909463264783685e-05,
      "loss": 0.0039,
      "step": 12780
    },
    {
      "epoch": 1.0913900503455927,
      "grad_norm": 0.2427281141281128,
      "learning_rate": 3.908609949654408e-05,
      "loss": 0.0028,
      "step": 12790
    },
    {
      "epoch": 1.0922433654748698,
      "grad_norm": 0.35638901591300964,
      "learning_rate": 3.907756634525131e-05,
      "loss": 0.0027,
      "step": 12800
    },
    {
      "epoch": 1.093096680604147,
      "grad_norm": 0.13932502269744873,
      "learning_rate": 3.906903319395853e-05,
      "loss": 0.0043,
      "step": 12810
    },
    {
      "epoch": 1.0939499957334244,
      "grad_norm": 0.406694233417511,
      "learning_rate": 3.906050004266576e-05,
      "loss": 0.0024,
      "step": 12820
    },
    {
      "epoch": 1.0948033108627016,
      "grad_norm": 0.11912955343723297,
      "learning_rate": 3.9051966891372986e-05,
      "loss": 0.0035,
      "step": 12830
    },
    {
      "epoch": 1.0956566259919789,
      "grad_norm": 0.07987751811742783,
      "learning_rate": 3.9043433740080214e-05,
      "loss": 0.0022,
      "step": 12840
    },
    {
      "epoch": 1.096509941121256,
      "grad_norm": 0.1475639045238495,
      "learning_rate": 3.903490058878744e-05,
      "loss": 0.0042,
      "step": 12850
    },
    {
      "epoch": 1.0973632562505333,
      "grad_norm": 0.3156386613845825,
      "learning_rate": 3.902636743749467e-05,
      "loss": 0.0042,
      "step": 12860
    },
    {
      "epoch": 1.0982165713798107,
      "grad_norm": 0.4481709599494934,
      "learning_rate": 3.90178342862019e-05,
      "loss": 0.0036,
      "step": 12870
    },
    {
      "epoch": 1.0990698865090878,
      "grad_norm": 0.13607312738895416,
      "learning_rate": 3.900930113490913e-05,
      "loss": 0.0028,
      "step": 12880
    },
    {
      "epoch": 1.099923201638365,
      "grad_norm": 0.05711841210722923,
      "learning_rate": 3.900076798361635e-05,
      "loss": 0.0031,
      "step": 12890
    },
    {
      "epoch": 1.1007765167676422,
      "grad_norm": 0.2626691162586212,
      "learning_rate": 3.899223483232358e-05,
      "loss": 0.0027,
      "step": 12900
    },
    {
      "epoch": 1.1016298318969195,
      "grad_norm": 0.05734385922551155,
      "learning_rate": 3.898370168103081e-05,
      "loss": 0.0032,
      "step": 12910
    },
    {
      "epoch": 1.1024831470261969,
      "grad_norm": 0.16899214684963226,
      "learning_rate": 3.897516852973803e-05,
      "loss": 0.0034,
      "step": 12920
    },
    {
      "epoch": 1.103336462155474,
      "grad_norm": 0.45875537395477295,
      "learning_rate": 3.896663537844526e-05,
      "loss": 0.0038,
      "step": 12930
    },
    {
      "epoch": 1.1041897772847513,
      "grad_norm": 0.11936751008033752,
      "learning_rate": 3.8958102227152486e-05,
      "loss": 0.0027,
      "step": 12940
    },
    {
      "epoch": 1.1050430924140284,
      "grad_norm": 0.08732251822948456,
      "learning_rate": 3.8949569075859714e-05,
      "loss": 0.0034,
      "step": 12950
    },
    {
      "epoch": 1.1058964075433058,
      "grad_norm": 0.22252993285655975,
      "learning_rate": 3.894103592456694e-05,
      "loss": 0.0033,
      "step": 12960
    },
    {
      "epoch": 1.1067497226725829,
      "grad_norm": 0.36889806389808655,
      "learning_rate": 3.893250277327417e-05,
      "loss": 0.004,
      "step": 12970
    },
    {
      "epoch": 1.1076030378018602,
      "grad_norm": 0.21496690809726715,
      "learning_rate": 3.89239696219814e-05,
      "loss": 0.0034,
      "step": 12980
    },
    {
      "epoch": 1.1084563529311375,
      "grad_norm": 0.0708138719201088,
      "learning_rate": 3.891543647068863e-05,
      "loss": 0.0033,
      "step": 12990
    },
    {
      "epoch": 1.1093096680604146,
      "grad_norm": 0.6297526359558105,
      "learning_rate": 3.8906903319395857e-05,
      "loss": 0.0025,
      "step": 13000
    },
    {
      "epoch": 1.110162983189692,
      "grad_norm": 0.1772727519273758,
      "learning_rate": 3.8898370168103085e-05,
      "loss": 0.0035,
      "step": 13010
    },
    {
      "epoch": 1.1110162983189693,
      "grad_norm": 0.4752415120601654,
      "learning_rate": 3.888983701681031e-05,
      "loss": 0.0039,
      "step": 13020
    },
    {
      "epoch": 1.1118696134482464,
      "grad_norm": 0.5233013033866882,
      "learning_rate": 3.8881303865517535e-05,
      "loss": 0.0031,
      "step": 13030
    },
    {
      "epoch": 1.1127229285775238,
      "grad_norm": 0.042096324265003204,
      "learning_rate": 3.8872770714224764e-05,
      "loss": 0.004,
      "step": 13040
    },
    {
      "epoch": 1.1135762437068009,
      "grad_norm": 0.3755713999271393,
      "learning_rate": 3.886423756293199e-05,
      "loss": 0.0032,
      "step": 13050
    },
    {
      "epoch": 1.1144295588360782,
      "grad_norm": 0.23292802274227142,
      "learning_rate": 3.885570441163922e-05,
      "loss": 0.0029,
      "step": 13060
    },
    {
      "epoch": 1.1152828739653553,
      "grad_norm": 0.21436557173728943,
      "learning_rate": 3.884717126034645e-05,
      "loss": 0.0021,
      "step": 13070
    },
    {
      "epoch": 1.1161361890946326,
      "grad_norm": 0.2588265538215637,
      "learning_rate": 3.883863810905368e-05,
      "loss": 0.0026,
      "step": 13080
    },
    {
      "epoch": 1.11698950422391,
      "grad_norm": 0.1831987202167511,
      "learning_rate": 3.8830104957760906e-05,
      "loss": 0.0036,
      "step": 13090
    },
    {
      "epoch": 1.117842819353187,
      "grad_norm": 0.11709966510534286,
      "learning_rate": 3.8821571806468135e-05,
      "loss": 0.0032,
      "step": 13100
    },
    {
      "epoch": 1.1186961344824644,
      "grad_norm": 0.24087932705879211,
      "learning_rate": 3.881303865517536e-05,
      "loss": 0.0027,
      "step": 13110
    },
    {
      "epoch": 1.1195494496117415,
      "grad_norm": 0.6932083964347839,
      "learning_rate": 3.8804505503882585e-05,
      "loss": 0.0027,
      "step": 13120
    },
    {
      "epoch": 1.1204027647410189,
      "grad_norm": 0.06733781099319458,
      "learning_rate": 3.879597235258981e-05,
      "loss": 0.0034,
      "step": 13130
    },
    {
      "epoch": 1.1212560798702962,
      "grad_norm": 0.1468130648136139,
      "learning_rate": 3.878743920129704e-05,
      "loss": 0.0028,
      "step": 13140
    },
    {
      "epoch": 1.1221093949995733,
      "grad_norm": 0.07892368733882904,
      "learning_rate": 3.877890605000427e-05,
      "loss": 0.0024,
      "step": 13150
    },
    {
      "epoch": 1.1229627101288506,
      "grad_norm": 0.0840672180056572,
      "learning_rate": 3.877037289871149e-05,
      "loss": 0.0028,
      "step": 13160
    },
    {
      "epoch": 1.1238160252581277,
      "grad_norm": 0.2399744689464569,
      "learning_rate": 3.876183974741872e-05,
      "loss": 0.0032,
      "step": 13170
    },
    {
      "epoch": 1.124669340387405,
      "grad_norm": 0.12147564440965652,
      "learning_rate": 3.875330659612595e-05,
      "loss": 0.0031,
      "step": 13180
    },
    {
      "epoch": 1.1255226555166824,
      "grad_norm": 0.0927698165178299,
      "learning_rate": 3.874477344483318e-05,
      "loss": 0.0035,
      "step": 13190
    },
    {
      "epoch": 1.1263759706459595,
      "grad_norm": 0.17251603305339813,
      "learning_rate": 3.8736240293540406e-05,
      "loss": 0.0022,
      "step": 13200
    },
    {
      "epoch": 1.1272292857752368,
      "grad_norm": 0.053755320608615875,
      "learning_rate": 3.8727707142247634e-05,
      "loss": 0.0031,
      "step": 13210
    },
    {
      "epoch": 1.128082600904514,
      "grad_norm": 0.3128202259540558,
      "learning_rate": 3.871917399095486e-05,
      "loss": 0.0027,
      "step": 13220
    },
    {
      "epoch": 1.1289359160337913,
      "grad_norm": 0.09220195561647415,
      "learning_rate": 3.8710640839662085e-05,
      "loss": 0.0039,
      "step": 13230
    },
    {
      "epoch": 1.1297892311630684,
      "grad_norm": 0.32234740257263184,
      "learning_rate": 3.870210768836931e-05,
      "loss": 0.003,
      "step": 13240
    },
    {
      "epoch": 1.1306425462923457,
      "grad_norm": 0.3649863600730896,
      "learning_rate": 3.869357453707654e-05,
      "loss": 0.0025,
      "step": 13250
    },
    {
      "epoch": 1.131495861421623,
      "grad_norm": 0.27818700671195984,
      "learning_rate": 3.868504138578377e-05,
      "loss": 0.0026,
      "step": 13260
    },
    {
      "epoch": 1.1323491765509002,
      "grad_norm": 0.3316008150577545,
      "learning_rate": 3.8676508234491e-05,
      "loss": 0.0033,
      "step": 13270
    },
    {
      "epoch": 1.1332024916801775,
      "grad_norm": 0.1809578686952591,
      "learning_rate": 3.866797508319823e-05,
      "loss": 0.0025,
      "step": 13280
    },
    {
      "epoch": 1.1340558068094548,
      "grad_norm": 0.04361535608768463,
      "learning_rate": 3.8659441931905455e-05,
      "loss": 0.0026,
      "step": 13290
    },
    {
      "epoch": 1.134909121938732,
      "grad_norm": 0.08621393889188766,
      "learning_rate": 3.8650908780612684e-05,
      "loss": 0.003,
      "step": 13300
    },
    {
      "epoch": 1.1357624370680093,
      "grad_norm": 0.3744443953037262,
      "learning_rate": 3.864237562931991e-05,
      "loss": 0.0035,
      "step": 13310
    },
    {
      "epoch": 1.1366157521972864,
      "grad_norm": 0.5392798185348511,
      "learning_rate": 3.863384247802714e-05,
      "loss": 0.0029,
      "step": 13320
    },
    {
      "epoch": 1.1374690673265637,
      "grad_norm": 0.11317967623472214,
      "learning_rate": 3.862530932673436e-05,
      "loss": 0.0026,
      "step": 13330
    },
    {
      "epoch": 1.1383223824558408,
      "grad_norm": 0.15646114945411682,
      "learning_rate": 3.861677617544159e-05,
      "loss": 0.0033,
      "step": 13340
    },
    {
      "epoch": 1.1391756975851182,
      "grad_norm": 0.08707030117511749,
      "learning_rate": 3.860824302414882e-05,
      "loss": 0.002,
      "step": 13350
    },
    {
      "epoch": 1.1400290127143955,
      "grad_norm": 0.5217140913009644,
      "learning_rate": 3.859970987285605e-05,
      "loss": 0.0031,
      "step": 13360
    },
    {
      "epoch": 1.1408823278436726,
      "grad_norm": 0.2268613576889038,
      "learning_rate": 3.8591176721563277e-05,
      "loss": 0.0032,
      "step": 13370
    },
    {
      "epoch": 1.14173564297295,
      "grad_norm": 0.12786228954792023,
      "learning_rate": 3.8582643570270505e-05,
      "loss": 0.003,
      "step": 13380
    },
    {
      "epoch": 1.1425889581022273,
      "grad_norm": 0.14821110665798187,
      "learning_rate": 3.8574110418977734e-05,
      "loss": 0.0028,
      "step": 13390
    },
    {
      "epoch": 1.1434422732315044,
      "grad_norm": 0.24012555181980133,
      "learning_rate": 3.856557726768496e-05,
      "loss": 0.0031,
      "step": 13400
    },
    {
      "epoch": 1.1442955883607817,
      "grad_norm": 0.18485739827156067,
      "learning_rate": 3.855704411639219e-05,
      "loss": 0.0025,
      "step": 13410
    },
    {
      "epoch": 1.1451489034900588,
      "grad_norm": 0.13311323523521423,
      "learning_rate": 3.854851096509941e-05,
      "loss": 0.003,
      "step": 13420
    },
    {
      "epoch": 1.1460022186193362,
      "grad_norm": 0.05724954232573509,
      "learning_rate": 3.853997781380664e-05,
      "loss": 0.0023,
      "step": 13430
    },
    {
      "epoch": 1.1468555337486133,
      "grad_norm": 0.23464815318584442,
      "learning_rate": 3.853144466251387e-05,
      "loss": 0.0025,
      "step": 13440
    },
    {
      "epoch": 1.1477088488778906,
      "grad_norm": 0.28393033146858215,
      "learning_rate": 3.852291151122109e-05,
      "loss": 0.0027,
      "step": 13450
    },
    {
      "epoch": 1.148562164007168,
      "grad_norm": 0.3177129924297333,
      "learning_rate": 3.851437835992832e-05,
      "loss": 0.0033,
      "step": 13460
    },
    {
      "epoch": 1.149415479136445,
      "grad_norm": 0.12136445939540863,
      "learning_rate": 3.850584520863555e-05,
      "loss": 0.0036,
      "step": 13470
    },
    {
      "epoch": 1.1502687942657224,
      "grad_norm": 0.3429967761039734,
      "learning_rate": 3.8497312057342776e-05,
      "loss": 0.0031,
      "step": 13480
    },
    {
      "epoch": 1.1511221093949995,
      "grad_norm": 0.018963558599352837,
      "learning_rate": 3.8488778906050005e-05,
      "loss": 0.0024,
      "step": 13490
    },
    {
      "epoch": 1.1519754245242768,
      "grad_norm": 0.4698740243911743,
      "learning_rate": 3.848024575475723e-05,
      "loss": 0.0023,
      "step": 13500
    },
    {
      "epoch": 1.1528287396535541,
      "grad_norm": 0.3956633508205414,
      "learning_rate": 3.847171260346446e-05,
      "loss": 0.0029,
      "step": 13510
    },
    {
      "epoch": 1.1536820547828313,
      "grad_norm": 0.43479683995246887,
      "learning_rate": 3.846317945217169e-05,
      "loss": 0.0031,
      "step": 13520
    },
    {
      "epoch": 1.1545353699121086,
      "grad_norm": 0.36015474796295166,
      "learning_rate": 3.845464630087892e-05,
      "loss": 0.002,
      "step": 13530
    },
    {
      "epoch": 1.1553886850413857,
      "grad_norm": 0.12696117162704468,
      "learning_rate": 3.844611314958614e-05,
      "loss": 0.0034,
      "step": 13540
    },
    {
      "epoch": 1.156242000170663,
      "grad_norm": 0.2134874165058136,
      "learning_rate": 3.843757999829337e-05,
      "loss": 0.0034,
      "step": 13550
    },
    {
      "epoch": 1.1570953152999404,
      "grad_norm": 0.4755818247795105,
      "learning_rate": 3.84290468470006e-05,
      "loss": 0.0027,
      "step": 13560
    },
    {
      "epoch": 1.1579486304292175,
      "grad_norm": 0.1851361244916916,
      "learning_rate": 3.8420513695707826e-05,
      "loss": 0.0036,
      "step": 13570
    },
    {
      "epoch": 1.1588019455584948,
      "grad_norm": 0.1801576465368271,
      "learning_rate": 3.8411980544415054e-05,
      "loss": 0.0036,
      "step": 13580
    },
    {
      "epoch": 1.159655260687772,
      "grad_norm": 0.24071837961673737,
      "learning_rate": 3.840344739312228e-05,
      "loss": 0.0025,
      "step": 13590
    },
    {
      "epoch": 1.1605085758170492,
      "grad_norm": 0.33673006296157837,
      "learning_rate": 3.839491424182951e-05,
      "loss": 0.0029,
      "step": 13600
    },
    {
      "epoch": 1.1613618909463264,
      "grad_norm": 0.1836273968219757,
      "learning_rate": 3.838638109053674e-05,
      "loss": 0.0028,
      "step": 13610
    },
    {
      "epoch": 1.1622152060756037,
      "grad_norm": 0.06511911749839783,
      "learning_rate": 3.837784793924397e-05,
      "loss": 0.0027,
      "step": 13620
    },
    {
      "epoch": 1.163068521204881,
      "grad_norm": 0.1725499927997589,
      "learning_rate": 3.83693147879512e-05,
      "loss": 0.0028,
      "step": 13630
    },
    {
      "epoch": 1.1639218363341581,
      "grad_norm": 0.06620904803276062,
      "learning_rate": 3.836078163665842e-05,
      "loss": 0.0028,
      "step": 13640
    },
    {
      "epoch": 1.1647751514634355,
      "grad_norm": 0.04159589484333992,
      "learning_rate": 3.835224848536565e-05,
      "loss": 0.0029,
      "step": 13650
    },
    {
      "epoch": 1.1656284665927128,
      "grad_norm": 0.17461234331130981,
      "learning_rate": 3.8343715334072875e-05,
      "loss": 0.0025,
      "step": 13660
    },
    {
      "epoch": 1.16648178172199,
      "grad_norm": 0.08148115128278732,
      "learning_rate": 3.8335182182780104e-05,
      "loss": 0.0028,
      "step": 13670
    },
    {
      "epoch": 1.1673350968512672,
      "grad_norm": 0.10380479693412781,
      "learning_rate": 3.832664903148733e-05,
      "loss": 0.0024,
      "step": 13680
    },
    {
      "epoch": 1.1681884119805444,
      "grad_norm": 0.2149057239294052,
      "learning_rate": 3.8318115880194554e-05,
      "loss": 0.0028,
      "step": 13690
    },
    {
      "epoch": 1.1690417271098217,
      "grad_norm": 0.3073020279407501,
      "learning_rate": 3.830958272890178e-05,
      "loss": 0.0023,
      "step": 13700
    },
    {
      "epoch": 1.1698950422390988,
      "grad_norm": 0.1352541595697403,
      "learning_rate": 3.830104957760901e-05,
      "loss": 0.0026,
      "step": 13710
    },
    {
      "epoch": 1.1707483573683761,
      "grad_norm": 0.10535549372434616,
      "learning_rate": 3.829251642631624e-05,
      "loss": 0.0029,
      "step": 13720
    },
    {
      "epoch": 1.1716016724976535,
      "grad_norm": 0.1663455218076706,
      "learning_rate": 3.828398327502347e-05,
      "loss": 0.0034,
      "step": 13730
    },
    {
      "epoch": 1.1724549876269306,
      "grad_norm": 0.23774583637714386,
      "learning_rate": 3.8275450123730697e-05,
      "loss": 0.0031,
      "step": 13740
    },
    {
      "epoch": 1.173308302756208,
      "grad_norm": 0.16549676656723022,
      "learning_rate": 3.8266916972437925e-05,
      "loss": 0.0025,
      "step": 13750
    },
    {
      "epoch": 1.1741616178854852,
      "grad_norm": 0.3582212030887604,
      "learning_rate": 3.825838382114515e-05,
      "loss": 0.0034,
      "step": 13760
    },
    {
      "epoch": 1.1750149330147623,
      "grad_norm": 0.03853786736726761,
      "learning_rate": 3.8249850669852375e-05,
      "loss": 0.0036,
      "step": 13770
    },
    {
      "epoch": 1.1758682481440397,
      "grad_norm": 0.18334127962589264,
      "learning_rate": 3.8241317518559604e-05,
      "loss": 0.0026,
      "step": 13780
    },
    {
      "epoch": 1.1767215632733168,
      "grad_norm": 0.3865438401699066,
      "learning_rate": 3.823278436726683e-05,
      "loss": 0.0036,
      "step": 13790
    },
    {
      "epoch": 1.1775748784025941,
      "grad_norm": 0.1779506504535675,
      "learning_rate": 3.822425121597406e-05,
      "loss": 0.0031,
      "step": 13800
    },
    {
      "epoch": 1.1784281935318712,
      "grad_norm": 0.2527247667312622,
      "learning_rate": 3.821571806468129e-05,
      "loss": 0.0029,
      "step": 13810
    },
    {
      "epoch": 1.1792815086611486,
      "grad_norm": 0.21718177199363708,
      "learning_rate": 3.820718491338852e-05,
      "loss": 0.0024,
      "step": 13820
    },
    {
      "epoch": 1.180134823790426,
      "grad_norm": 0.5164987444877625,
      "learning_rate": 3.8198651762095746e-05,
      "loss": 0.0035,
      "step": 13830
    },
    {
      "epoch": 1.180988138919703,
      "grad_norm": 0.1483626514673233,
      "learning_rate": 3.8190118610802975e-05,
      "loss": 0.0041,
      "step": 13840
    },
    {
      "epoch": 1.1818414540489803,
      "grad_norm": 0.0371963195502758,
      "learning_rate": 3.8181585459510196e-05,
      "loss": 0.0031,
      "step": 13850
    },
    {
      "epoch": 1.1826947691782574,
      "grad_norm": 0.21768026053905487,
      "learning_rate": 3.8173052308217425e-05,
      "loss": 0.0028,
      "step": 13860
    },
    {
      "epoch": 1.1835480843075348,
      "grad_norm": 0.046062368899583817,
      "learning_rate": 3.816451915692465e-05,
      "loss": 0.0024,
      "step": 13870
    },
    {
      "epoch": 1.184401399436812,
      "grad_norm": 0.044403910636901855,
      "learning_rate": 3.815598600563188e-05,
      "loss": 0.0026,
      "step": 13880
    },
    {
      "epoch": 1.1852547145660892,
      "grad_norm": 0.1335943639278412,
      "learning_rate": 3.814745285433911e-05,
      "loss": 0.0032,
      "step": 13890
    },
    {
      "epoch": 1.1861080296953666,
      "grad_norm": 0.15332528948783875,
      "learning_rate": 3.813891970304634e-05,
      "loss": 0.0032,
      "step": 13900
    },
    {
      "epoch": 1.1869613448246437,
      "grad_norm": 0.17512476444244385,
      "learning_rate": 3.813038655175357e-05,
      "loss": 0.0029,
      "step": 13910
    },
    {
      "epoch": 1.187814659953921,
      "grad_norm": 0.17525021731853485,
      "learning_rate": 3.8121853400460796e-05,
      "loss": 0.0028,
      "step": 13920
    },
    {
      "epoch": 1.1886679750831983,
      "grad_norm": 0.20390437543392181,
      "learning_rate": 3.8113320249168024e-05,
      "loss": 0.004,
      "step": 13930
    },
    {
      "epoch": 1.1895212902124754,
      "grad_norm": 0.4997246265411377,
      "learning_rate": 3.810478709787525e-05,
      "loss": 0.003,
      "step": 13940
    },
    {
      "epoch": 1.1903746053417528,
      "grad_norm": 0.15095695853233337,
      "learning_rate": 3.8096253946582474e-05,
      "loss": 0.0026,
      "step": 13950
    },
    {
      "epoch": 1.1912279204710299,
      "grad_norm": 0.10452540963888168,
      "learning_rate": 3.80877207952897e-05,
      "loss": 0.0033,
      "step": 13960
    },
    {
      "epoch": 1.1920812356003072,
      "grad_norm": 0.7283254861831665,
      "learning_rate": 3.8079187643996924e-05,
      "loss": 0.0031,
      "step": 13970
    },
    {
      "epoch": 1.1929345507295843,
      "grad_norm": 0.24192923307418823,
      "learning_rate": 3.807065449270415e-05,
      "loss": 0.0032,
      "step": 13980
    },
    {
      "epoch": 1.1937878658588617,
      "grad_norm": 0.3289581835269928,
      "learning_rate": 3.806212134141138e-05,
      "loss": 0.0031,
      "step": 13990
    },
    {
      "epoch": 1.194641180988139,
      "grad_norm": 0.21710757911205292,
      "learning_rate": 3.805358819011861e-05,
      "loss": 0.003,
      "step": 14000
    },
    {
      "epoch": 1.195494496117416,
      "grad_norm": 0.3160970211029053,
      "learning_rate": 3.804505503882584e-05,
      "loss": 0.0026,
      "step": 14010
    },
    {
      "epoch": 1.1963478112466934,
      "grad_norm": 0.3172430694103241,
      "learning_rate": 3.803652188753307e-05,
      "loss": 0.0031,
      "step": 14020
    },
    {
      "epoch": 1.1972011263759708,
      "grad_norm": 0.16638197004795074,
      "learning_rate": 3.8027988736240295e-05,
      "loss": 0.0033,
      "step": 14030
    },
    {
      "epoch": 1.1980544415052479,
      "grad_norm": 0.5128727555274963,
      "learning_rate": 3.8019455584947524e-05,
      "loss": 0.0028,
      "step": 14040
    },
    {
      "epoch": 1.1989077566345252,
      "grad_norm": 0.14431384205818176,
      "learning_rate": 3.801092243365475e-05,
      "loss": 0.0026,
      "step": 14050
    },
    {
      "epoch": 1.1997610717638023,
      "grad_norm": 0.1059572696685791,
      "learning_rate": 3.800238928236198e-05,
      "loss": 0.0027,
      "step": 14060
    },
    {
      "epoch": 1.2006143868930796,
      "grad_norm": 0.3375895023345947,
      "learning_rate": 3.79938561310692e-05,
      "loss": 0.0036,
      "step": 14070
    },
    {
      "epoch": 1.2014677020223568,
      "grad_norm": 0.11715031415224075,
      "learning_rate": 3.798532297977643e-05,
      "loss": 0.0035,
      "step": 14080
    },
    {
      "epoch": 1.202321017151634,
      "grad_norm": 0.11615149676799774,
      "learning_rate": 3.797678982848366e-05,
      "loss": 0.0027,
      "step": 14090
    },
    {
      "epoch": 1.2031743322809114,
      "grad_norm": 0.45278069376945496,
      "learning_rate": 3.796825667719089e-05,
      "loss": 0.0022,
      "step": 14100
    },
    {
      "epoch": 1.2040276474101885,
      "grad_norm": 0.31703636050224304,
      "learning_rate": 3.7959723525898116e-05,
      "loss": 0.0026,
      "step": 14110
    },
    {
      "epoch": 1.2048809625394659,
      "grad_norm": 0.25778478384017944,
      "learning_rate": 3.7951190374605345e-05,
      "loss": 0.0036,
      "step": 14120
    },
    {
      "epoch": 1.205734277668743,
      "grad_norm": 0.30795082449913025,
      "learning_rate": 3.7942657223312573e-05,
      "loss": 0.0031,
      "step": 14130
    },
    {
      "epoch": 1.2065875927980203,
      "grad_norm": 0.3087606132030487,
      "learning_rate": 3.79341240720198e-05,
      "loss": 0.0033,
      "step": 14140
    },
    {
      "epoch": 1.2074409079272976,
      "grad_norm": 0.32436713576316833,
      "learning_rate": 3.792559092072703e-05,
      "loss": 0.0035,
      "step": 14150
    },
    {
      "epoch": 1.2082942230565747,
      "grad_norm": 0.3926122486591339,
      "learning_rate": 3.791705776943425e-05,
      "loss": 0.0028,
      "step": 14160
    },
    {
      "epoch": 1.209147538185852,
      "grad_norm": 0.08726922422647476,
      "learning_rate": 3.790852461814148e-05,
      "loss": 0.0031,
      "step": 14170
    },
    {
      "epoch": 1.2100008533151292,
      "grad_norm": 0.39682164788246155,
      "learning_rate": 3.789999146684871e-05,
      "loss": 0.0028,
      "step": 14180
    },
    {
      "epoch": 1.2108541684444065,
      "grad_norm": 0.06556133180856705,
      "learning_rate": 3.789145831555594e-05,
      "loss": 0.0025,
      "step": 14190
    },
    {
      "epoch": 1.2117074835736839,
      "grad_norm": 0.1885441094636917,
      "learning_rate": 3.7882925164263166e-05,
      "loss": 0.0037,
      "step": 14200
    },
    {
      "epoch": 1.212560798702961,
      "grad_norm": 0.33323195576667786,
      "learning_rate": 3.7874392012970395e-05,
      "loss": 0.003,
      "step": 14210
    },
    {
      "epoch": 1.2134141138322383,
      "grad_norm": 0.21556024253368378,
      "learning_rate": 3.7865858861677616e-05,
      "loss": 0.0028,
      "step": 14220
    },
    {
      "epoch": 1.2142674289615154,
      "grad_norm": 0.5477121472358704,
      "learning_rate": 3.7857325710384845e-05,
      "loss": 0.0031,
      "step": 14230
    },
    {
      "epoch": 1.2151207440907927,
      "grad_norm": 0.22125524282455444,
      "learning_rate": 3.784879255909207e-05,
      "loss": 0.0022,
      "step": 14240
    },
    {
      "epoch": 1.2159740592200698,
      "grad_norm": 0.35007432103157043,
      "learning_rate": 3.78402594077993e-05,
      "loss": 0.0038,
      "step": 14250
    },
    {
      "epoch": 1.2168273743493472,
      "grad_norm": 0.15787744522094727,
      "learning_rate": 3.783172625650653e-05,
      "loss": 0.0041,
      "step": 14260
    },
    {
      "epoch": 1.2176806894786245,
      "grad_norm": 0.15868358314037323,
      "learning_rate": 3.782319310521376e-05,
      "loss": 0.0027,
      "step": 14270
    },
    {
      "epoch": 1.2185340046079016,
      "grad_norm": 0.031167039647698402,
      "learning_rate": 3.781465995392098e-05,
      "loss": 0.0034,
      "step": 14280
    },
    {
      "epoch": 1.219387319737179,
      "grad_norm": 0.13901683688163757,
      "learning_rate": 3.780612680262821e-05,
      "loss": 0.0029,
      "step": 14290
    },
    {
      "epoch": 1.2202406348664563,
      "grad_norm": 0.10099277645349503,
      "learning_rate": 3.779759365133544e-05,
      "loss": 0.0032,
      "step": 14300
    },
    {
      "epoch": 1.2210939499957334,
      "grad_norm": 0.14144004881381989,
      "learning_rate": 3.7789060500042666e-05,
      "loss": 0.0027,
      "step": 14310
    },
    {
      "epoch": 1.2219472651250107,
      "grad_norm": 0.22940312325954437,
      "learning_rate": 3.7780527348749894e-05,
      "loss": 0.0025,
      "step": 14320
    },
    {
      "epoch": 1.2228005802542878,
      "grad_norm": 0.09807081520557404,
      "learning_rate": 3.777199419745712e-05,
      "loss": 0.0027,
      "step": 14330
    },
    {
      "epoch": 1.2236538953835652,
      "grad_norm": 0.1545526683330536,
      "learning_rate": 3.776346104616435e-05,
      "loss": 0.0028,
      "step": 14340
    },
    {
      "epoch": 1.2245072105128423,
      "grad_norm": 0.27817502617836,
      "learning_rate": 3.775492789487158e-05,
      "loss": 0.0028,
      "step": 14350
    },
    {
      "epoch": 1.2253605256421196,
      "grad_norm": 0.23917166888713837,
      "learning_rate": 3.774639474357881e-05,
      "loss": 0.0027,
      "step": 14360
    },
    {
      "epoch": 1.226213840771397,
      "grad_norm": 0.12453016638755798,
      "learning_rate": 3.773786159228604e-05,
      "loss": 0.0031,
      "step": 14370
    },
    {
      "epoch": 1.227067155900674,
      "grad_norm": 0.24485747516155243,
      "learning_rate": 3.772932844099326e-05,
      "loss": 0.0032,
      "step": 14380
    },
    {
      "epoch": 1.2279204710299514,
      "grad_norm": 0.6776448488235474,
      "learning_rate": 3.772079528970049e-05,
      "loss": 0.0028,
      "step": 14390
    },
    {
      "epoch": 1.2287737861592287,
      "grad_norm": 0.27244630455970764,
      "learning_rate": 3.7712262138407715e-05,
      "loss": 0.0027,
      "step": 14400
    },
    {
      "epoch": 1.2296271012885058,
      "grad_norm": 0.39169710874557495,
      "learning_rate": 3.7703728987114944e-05,
      "loss": 0.0026,
      "step": 14410
    },
    {
      "epoch": 1.2304804164177832,
      "grad_norm": 0.08014126867055893,
      "learning_rate": 3.769519583582217e-05,
      "loss": 0.0025,
      "step": 14420
    },
    {
      "epoch": 1.2313337315470603,
      "grad_norm": 0.17187738418579102,
      "learning_rate": 3.76866626845294e-05,
      "loss": 0.0034,
      "step": 14430
    },
    {
      "epoch": 1.2321870466763376,
      "grad_norm": 0.10432726889848709,
      "learning_rate": 3.767812953323663e-05,
      "loss": 0.0035,
      "step": 14440
    },
    {
      "epoch": 1.2330403618056147,
      "grad_norm": 0.12858504056930542,
      "learning_rate": 3.766959638194386e-05,
      "loss": 0.0024,
      "step": 14450
    },
    {
      "epoch": 1.233893676934892,
      "grad_norm": 0.3169875741004944,
      "learning_rate": 3.7661063230651086e-05,
      "loss": 0.0027,
      "step": 14460
    },
    {
      "epoch": 1.2347469920641694,
      "grad_norm": 0.14603880047798157,
      "learning_rate": 3.7652530079358315e-05,
      "loss": 0.0032,
      "step": 14470
    },
    {
      "epoch": 1.2356003071934465,
      "grad_norm": 0.06508397310972214,
      "learning_rate": 3.7643996928065536e-05,
      "loss": 0.0026,
      "step": 14480
    },
    {
      "epoch": 1.2364536223227238,
      "grad_norm": 0.1615860015153885,
      "learning_rate": 3.763546377677276e-05,
      "loss": 0.0025,
      "step": 14490
    },
    {
      "epoch": 1.237306937452001,
      "grad_norm": 0.6097245812416077,
      "learning_rate": 3.7626930625479987e-05,
      "loss": 0.0035,
      "step": 14500
    },
    {
      "epoch": 1.2381602525812783,
      "grad_norm": 0.5226854681968689,
      "learning_rate": 3.7618397474187215e-05,
      "loss": 0.0037,
      "step": 14510
    },
    {
      "epoch": 1.2390135677105556,
      "grad_norm": 0.03500162810087204,
      "learning_rate": 3.7609864322894444e-05,
      "loss": 0.0022,
      "step": 14520
    },
    {
      "epoch": 1.2398668828398327,
      "grad_norm": 0.28907015919685364,
      "learning_rate": 3.760133117160167e-05,
      "loss": 0.0022,
      "step": 14530
    },
    {
      "epoch": 1.24072019796911,
      "grad_norm": 0.05004904046654701,
      "learning_rate": 3.75927980203089e-05,
      "loss": 0.0033,
      "step": 14540
    },
    {
      "epoch": 1.2415735130983871,
      "grad_norm": 0.6972662806510925,
      "learning_rate": 3.758426486901613e-05,
      "loss": 0.0027,
      "step": 14550
    },
    {
      "epoch": 1.2424268282276645,
      "grad_norm": 0.40566298365592957,
      "learning_rate": 3.757573171772336e-05,
      "loss": 0.0029,
      "step": 14560
    },
    {
      "epoch": 1.2432801433569418,
      "grad_norm": 0.12674783170223236,
      "learning_rate": 3.7567198566430586e-05,
      "loss": 0.0031,
      "step": 14570
    },
    {
      "epoch": 1.244133458486219,
      "grad_norm": 0.18690460920333862,
      "learning_rate": 3.7558665415137814e-05,
      "loss": 0.0031,
      "step": 14580
    },
    {
      "epoch": 1.2449867736154963,
      "grad_norm": 0.7207849621772766,
      "learning_rate": 3.7550132263845036e-05,
      "loss": 0.0025,
      "step": 14590
    },
    {
      "epoch": 1.2458400887447734,
      "grad_norm": 0.42355236411094666,
      "learning_rate": 3.7541599112552265e-05,
      "loss": 0.0022,
      "step": 14600
    },
    {
      "epoch": 1.2466934038740507,
      "grad_norm": 0.07709086686372757,
      "learning_rate": 3.753306596125949e-05,
      "loss": 0.003,
      "step": 14610
    },
    {
      "epoch": 1.2475467190033278,
      "grad_norm": 0.10118233412504196,
      "learning_rate": 3.752453280996672e-05,
      "loss": 0.0029,
      "step": 14620
    },
    {
      "epoch": 1.2484000341326051,
      "grad_norm": 0.40904656052589417,
      "learning_rate": 3.751599965867395e-05,
      "loss": 0.0024,
      "step": 14630
    },
    {
      "epoch": 1.2492533492618825,
      "grad_norm": 0.050827521830797195,
      "learning_rate": 3.750746650738118e-05,
      "loss": 0.0036,
      "step": 14640
    },
    {
      "epoch": 1.2501066643911596,
      "grad_norm": 0.04655657336115837,
      "learning_rate": 3.749893335608841e-05,
      "loss": 0.0024,
      "step": 14650
    },
    {
      "epoch": 1.250959979520437,
      "grad_norm": 0.1982305943965912,
      "learning_rate": 3.7490400204795636e-05,
      "loss": 0.0031,
      "step": 14660
    },
    {
      "epoch": 1.2518132946497142,
      "grad_norm": 0.11947289854288101,
      "learning_rate": 3.7481867053502864e-05,
      "loss": 0.0021,
      "step": 14670
    },
    {
      "epoch": 1.2526666097789914,
      "grad_norm": 0.22510582208633423,
      "learning_rate": 3.747333390221009e-05,
      "loss": 0.0034,
      "step": 14680
    },
    {
      "epoch": 1.2535199249082687,
      "grad_norm": 0.0858442485332489,
      "learning_rate": 3.7464800750917314e-05,
      "loss": 0.0025,
      "step": 14690
    },
    {
      "epoch": 1.2543732400375458,
      "grad_norm": 0.2878839373588562,
      "learning_rate": 3.745626759962454e-05,
      "loss": 0.0032,
      "step": 14700
    },
    {
      "epoch": 1.2552265551668231,
      "grad_norm": 0.09545599669218063,
      "learning_rate": 3.744773444833177e-05,
      "loss": 0.0032,
      "step": 14710
    },
    {
      "epoch": 1.2560798702961002,
      "grad_norm": 0.19228343665599823,
      "learning_rate": 3.7439201297039e-05,
      "loss": 0.0033,
      "step": 14720
    },
    {
      "epoch": 1.2569331854253776,
      "grad_norm": 0.35556405782699585,
      "learning_rate": 3.743066814574623e-05,
      "loss": 0.0031,
      "step": 14730
    },
    {
      "epoch": 1.257786500554655,
      "grad_norm": 0.16926905512809753,
      "learning_rate": 3.742213499445346e-05,
      "loss": 0.0024,
      "step": 14740
    },
    {
      "epoch": 1.258639815683932,
      "grad_norm": 0.22028067708015442,
      "learning_rate": 3.741360184316068e-05,
      "loss": 0.0024,
      "step": 14750
    },
    {
      "epoch": 1.2594931308132093,
      "grad_norm": 0.3313046991825104,
      "learning_rate": 3.740506869186791e-05,
      "loss": 0.0021,
      "step": 14760
    },
    {
      "epoch": 1.2603464459424867,
      "grad_norm": 0.1260126382112503,
      "learning_rate": 3.7396535540575135e-05,
      "loss": 0.0031,
      "step": 14770
    },
    {
      "epoch": 1.2611997610717638,
      "grad_norm": 0.24038399755954742,
      "learning_rate": 3.7388002389282364e-05,
      "loss": 0.0026,
      "step": 14780
    },
    {
      "epoch": 1.2620530762010411,
      "grad_norm": 0.13782422244548798,
      "learning_rate": 3.737946923798959e-05,
      "loss": 0.0029,
      "step": 14790
    },
    {
      "epoch": 1.2629063913303182,
      "grad_norm": 0.27459582686424255,
      "learning_rate": 3.7370936086696814e-05,
      "loss": 0.0031,
      "step": 14800
    },
    {
      "epoch": 1.2637597064595956,
      "grad_norm": 0.3772895038127899,
      "learning_rate": 3.736240293540404e-05,
      "loss": 0.0023,
      "step": 14810
    },
    {
      "epoch": 1.2646130215888727,
      "grad_norm": 0.4228235185146332,
      "learning_rate": 3.735386978411127e-05,
      "loss": 0.0032,
      "step": 14820
    },
    {
      "epoch": 1.26546633671815,
      "grad_norm": 0.3706866502761841,
      "learning_rate": 3.73453366328185e-05,
      "loss": 0.0035,
      "step": 14830
    },
    {
      "epoch": 1.2663196518474273,
      "grad_norm": 0.5029727816581726,
      "learning_rate": 3.733680348152573e-05,
      "loss": 0.0023,
      "step": 14840
    },
    {
      "epoch": 1.2671729669767045,
      "grad_norm": 0.11675050109624863,
      "learning_rate": 3.7328270330232956e-05,
      "loss": 0.0042,
      "step": 14850
    },
    {
      "epoch": 1.2680262821059818,
      "grad_norm": 0.10685175657272339,
      "learning_rate": 3.7319737178940185e-05,
      "loss": 0.0029,
      "step": 14860
    },
    {
      "epoch": 1.2688795972352591,
      "grad_norm": 0.23959557712078094,
      "learning_rate": 3.731120402764741e-05,
      "loss": 0.0024,
      "step": 14870
    },
    {
      "epoch": 1.2697329123645362,
      "grad_norm": 0.04351704567670822,
      "learning_rate": 3.730267087635464e-05,
      "loss": 0.0032,
      "step": 14880
    },
    {
      "epoch": 1.2705862274938133,
      "grad_norm": 0.07953330874443054,
      "learning_rate": 3.729413772506187e-05,
      "loss": 0.0037,
      "step": 14890
    },
    {
      "epoch": 1.2714395426230907,
      "grad_norm": 0.4044579863548279,
      "learning_rate": 3.728560457376909e-05,
      "loss": 0.0028,
      "step": 14900
    },
    {
      "epoch": 1.272292857752368,
      "grad_norm": 0.14283353090286255,
      "learning_rate": 3.727707142247632e-05,
      "loss": 0.002,
      "step": 14910
    },
    {
      "epoch": 1.273146172881645,
      "grad_norm": 0.0698285847902298,
      "learning_rate": 3.726853827118355e-05,
      "loss": 0.0034,
      "step": 14920
    },
    {
      "epoch": 1.2739994880109224,
      "grad_norm": 0.1731627881526947,
      "learning_rate": 3.726000511989078e-05,
      "loss": 0.0027,
      "step": 14930
    },
    {
      "epoch": 1.2748528031401998,
      "grad_norm": 0.3340184688568115,
      "learning_rate": 3.7251471968598006e-05,
      "loss": 0.0033,
      "step": 14940
    },
    {
      "epoch": 1.2757061182694769,
      "grad_norm": 0.5285572409629822,
      "learning_rate": 3.7242938817305234e-05,
      "loss": 0.0025,
      "step": 14950
    },
    {
      "epoch": 1.2765594333987542,
      "grad_norm": 0.29657313227653503,
      "learning_rate": 3.723440566601246e-05,
      "loss": 0.0027,
      "step": 14960
    },
    {
      "epoch": 1.2774127485280313,
      "grad_norm": 0.17976394295692444,
      "learning_rate": 3.722587251471969e-05,
      "loss": 0.0032,
      "step": 14970
    },
    {
      "epoch": 1.2782660636573087,
      "grad_norm": 0.3709810972213745,
      "learning_rate": 3.721733936342692e-05,
      "loss": 0.0034,
      "step": 14980
    },
    {
      "epoch": 1.2791193787865858,
      "grad_norm": 0.08697467297315598,
      "learning_rate": 3.720880621213415e-05,
      "loss": 0.003,
      "step": 14990
    },
    {
      "epoch": 1.279972693915863,
      "grad_norm": 0.44810181856155396,
      "learning_rate": 3.720027306084137e-05,
      "loss": 0.003,
      "step": 15000
    },
    {
      "epoch": 1.2808260090451404,
      "grad_norm": 0.1357232928276062,
      "learning_rate": 3.71917399095486e-05,
      "loss": 0.0036,
      "step": 15010
    },
    {
      "epoch": 1.2816793241744175,
      "grad_norm": 0.27415889501571655,
      "learning_rate": 3.718320675825582e-05,
      "loss": 0.0031,
      "step": 15020
    },
    {
      "epoch": 1.2825326393036949,
      "grad_norm": 0.3291172385215759,
      "learning_rate": 3.717467360696305e-05,
      "loss": 0.0034,
      "step": 15030
    },
    {
      "epoch": 1.2833859544329722,
      "grad_norm": 0.2634839713573456,
      "learning_rate": 3.716614045567028e-05,
      "loss": 0.0029,
      "step": 15040
    },
    {
      "epoch": 1.2842392695622493,
      "grad_norm": 0.3325766921043396,
      "learning_rate": 3.7157607304377506e-05,
      "loss": 0.0021,
      "step": 15050
    },
    {
      "epoch": 1.2850925846915267,
      "grad_norm": 0.3673890233039856,
      "learning_rate": 3.7149074153084734e-05,
      "loss": 0.0025,
      "step": 15060
    },
    {
      "epoch": 1.2859458998208038,
      "grad_norm": 0.3523184657096863,
      "learning_rate": 3.714054100179196e-05,
      "loss": 0.0023,
      "step": 15070
    },
    {
      "epoch": 1.286799214950081,
      "grad_norm": 0.08086691796779633,
      "learning_rate": 3.713200785049919e-05,
      "loss": 0.0031,
      "step": 15080
    },
    {
      "epoch": 1.2876525300793582,
      "grad_norm": 0.18277475237846375,
      "learning_rate": 3.712347469920642e-05,
      "loss": 0.0023,
      "step": 15090
    },
    {
      "epoch": 1.2885058452086355,
      "grad_norm": 0.2533385753631592,
      "learning_rate": 3.711494154791365e-05,
      "loss": 0.0025,
      "step": 15100
    },
    {
      "epoch": 1.2893591603379129,
      "grad_norm": 0.18147172033786774,
      "learning_rate": 3.710640839662087e-05,
      "loss": 0.0024,
      "step": 15110
    },
    {
      "epoch": 1.29021247546719,
      "grad_norm": 0.22240351140499115,
      "learning_rate": 3.70978752453281e-05,
      "loss": 0.0027,
      "step": 15120
    },
    {
      "epoch": 1.2910657905964673,
      "grad_norm": 0.2170344740152359,
      "learning_rate": 3.708934209403533e-05,
      "loss": 0.0023,
      "step": 15130
    },
    {
      "epoch": 1.2919191057257446,
      "grad_norm": 0.35648590326309204,
      "learning_rate": 3.7080808942742555e-05,
      "loss": 0.003,
      "step": 15140
    },
    {
      "epoch": 1.2927724208550218,
      "grad_norm": 0.2516787648200989,
      "learning_rate": 3.7072275791449784e-05,
      "loss": 0.0029,
      "step": 15150
    },
    {
      "epoch": 1.2936257359842989,
      "grad_norm": 0.311598002910614,
      "learning_rate": 3.706374264015701e-05,
      "loss": 0.0028,
      "step": 15160
    },
    {
      "epoch": 1.2944790511135762,
      "grad_norm": 0.3554156422615051,
      "learning_rate": 3.705520948886424e-05,
      "loss": 0.0024,
      "step": 15170
    },
    {
      "epoch": 1.2953323662428535,
      "grad_norm": 0.2360323965549469,
      "learning_rate": 3.704667633757147e-05,
      "loss": 0.0019,
      "step": 15180
    },
    {
      "epoch": 1.2961856813721306,
      "grad_norm": 0.5448867678642273,
      "learning_rate": 3.70381431862787e-05,
      "loss": 0.0027,
      "step": 15190
    },
    {
      "epoch": 1.297038996501408,
      "grad_norm": 0.2804250121116638,
      "learning_rate": 3.7029610034985926e-05,
      "loss": 0.0031,
      "step": 15200
    },
    {
      "epoch": 1.2978923116306853,
      "grad_norm": 0.21975423395633698,
      "learning_rate": 3.702107688369315e-05,
      "loss": 0.0029,
      "step": 15210
    },
    {
      "epoch": 1.2987456267599624,
      "grad_norm": 0.14296479523181915,
      "learning_rate": 3.7012543732400376e-05,
      "loss": 0.0025,
      "step": 15220
    },
    {
      "epoch": 1.2995989418892397,
      "grad_norm": 0.17354469001293182,
      "learning_rate": 3.7004010581107605e-05,
      "loss": 0.0027,
      "step": 15230
    },
    {
      "epoch": 1.3004522570185169,
      "grad_norm": 0.14068929851055145,
      "learning_rate": 3.699547742981483e-05,
      "loss": 0.0024,
      "step": 15240
    },
    {
      "epoch": 1.3013055721477942,
      "grad_norm": 0.6358838081359863,
      "learning_rate": 3.698694427852206e-05,
      "loss": 0.0032,
      "step": 15250
    },
    {
      "epoch": 1.3021588872770713,
      "grad_norm": 0.528924822807312,
      "learning_rate": 3.697841112722929e-05,
      "loss": 0.0021,
      "step": 15260
    },
    {
      "epoch": 1.3030122024063486,
      "grad_norm": 0.38970598578453064,
      "learning_rate": 3.696987797593652e-05,
      "loss": 0.0024,
      "step": 15270
    },
    {
      "epoch": 1.303865517535626,
      "grad_norm": 0.2542320787906647,
      "learning_rate": 3.696134482464374e-05,
      "loss": 0.0027,
      "step": 15280
    },
    {
      "epoch": 1.304718832664903,
      "grad_norm": 0.03306018188595772,
      "learning_rate": 3.695281167335097e-05,
      "loss": 0.0027,
      "step": 15290
    },
    {
      "epoch": 1.3055721477941804,
      "grad_norm": 0.30245476961135864,
      "learning_rate": 3.69442785220582e-05,
      "loss": 0.0027,
      "step": 15300
    },
    {
      "epoch": 1.3064254629234577,
      "grad_norm": 0.0717073604464531,
      "learning_rate": 3.6935745370765426e-05,
      "loss": 0.003,
      "step": 15310
    },
    {
      "epoch": 1.3072787780527348,
      "grad_norm": 0.17540901899337769,
      "learning_rate": 3.6927212219472654e-05,
      "loss": 0.0035,
      "step": 15320
    },
    {
      "epoch": 1.3081320931820122,
      "grad_norm": 0.273028165102005,
      "learning_rate": 3.6918679068179876e-05,
      "loss": 0.0033,
      "step": 15330
    },
    {
      "epoch": 1.3089854083112893,
      "grad_norm": 0.36872971057891846,
      "learning_rate": 3.6910145916887105e-05,
      "loss": 0.0027,
      "step": 15340
    },
    {
      "epoch": 1.3098387234405666,
      "grad_norm": 0.29377686977386475,
      "learning_rate": 3.690161276559433e-05,
      "loss": 0.0029,
      "step": 15350
    },
    {
      "epoch": 1.3106920385698437,
      "grad_norm": 0.1592419147491455,
      "learning_rate": 3.689307961430156e-05,
      "loss": 0.0026,
      "step": 15360
    },
    {
      "epoch": 1.311545353699121,
      "grad_norm": 0.33589819073677063,
      "learning_rate": 3.688454646300879e-05,
      "loss": 0.0029,
      "step": 15370
    },
    {
      "epoch": 1.3123986688283984,
      "grad_norm": 0.1694013476371765,
      "learning_rate": 3.687601331171602e-05,
      "loss": 0.0026,
      "step": 15380
    },
    {
      "epoch": 1.3132519839576755,
      "grad_norm": 0.22727841138839722,
      "learning_rate": 3.686748016042325e-05,
      "loss": 0.0031,
      "step": 15390
    },
    {
      "epoch": 1.3141052990869528,
      "grad_norm": 0.18288636207580566,
      "learning_rate": 3.6858947009130475e-05,
      "loss": 0.003,
      "step": 15400
    },
    {
      "epoch": 1.3149586142162302,
      "grad_norm": 0.14553527534008026,
      "learning_rate": 3.6850413857837704e-05,
      "loss": 0.0026,
      "step": 15410
    },
    {
      "epoch": 1.3158119293455073,
      "grad_norm": 0.3464382588863373,
      "learning_rate": 3.6841880706544926e-05,
      "loss": 0.0023,
      "step": 15420
    },
    {
      "epoch": 1.3166652444747846,
      "grad_norm": 0.5846827030181885,
      "learning_rate": 3.6833347555252154e-05,
      "loss": 0.002,
      "step": 15430
    },
    {
      "epoch": 1.3175185596040617,
      "grad_norm": 0.37777435779571533,
      "learning_rate": 3.682481440395938e-05,
      "loss": 0.0025,
      "step": 15440
    },
    {
      "epoch": 1.318371874733339,
      "grad_norm": 0.36522072553634644,
      "learning_rate": 3.681628125266661e-05,
      "loss": 0.0036,
      "step": 15450
    },
    {
      "epoch": 1.3192251898626162,
      "grad_norm": 0.4422679841518402,
      "learning_rate": 3.680774810137384e-05,
      "loss": 0.0036,
      "step": 15460
    },
    {
      "epoch": 1.3200785049918935,
      "grad_norm": 0.18617509305477142,
      "learning_rate": 3.679921495008107e-05,
      "loss": 0.0024,
      "step": 15470
    },
    {
      "epoch": 1.3209318201211708,
      "grad_norm": 0.029091523960232735,
      "learning_rate": 3.6790681798788297e-05,
      "loss": 0.0032,
      "step": 15480
    },
    {
      "epoch": 1.321785135250448,
      "grad_norm": 0.31541934609413147,
      "learning_rate": 3.6782148647495525e-05,
      "loss": 0.0035,
      "step": 15490
    },
    {
      "epoch": 1.3226384503797253,
      "grad_norm": 0.22159186005592346,
      "learning_rate": 3.6773615496202753e-05,
      "loss": 0.0029,
      "step": 15500
    },
    {
      "epoch": 1.3234917655090026,
      "grad_norm": 0.2249142974615097,
      "learning_rate": 3.676508234490998e-05,
      "loss": 0.0034,
      "step": 15510
    },
    {
      "epoch": 1.3243450806382797,
      "grad_norm": 0.528895378112793,
      "learning_rate": 3.6756549193617204e-05,
      "loss": 0.004,
      "step": 15520
    },
    {
      "epoch": 1.3251983957675568,
      "grad_norm": 0.4763745665550232,
      "learning_rate": 3.674801604232443e-05,
      "loss": 0.0029,
      "step": 15530
    },
    {
      "epoch": 1.3260517108968342,
      "grad_norm": 0.35569390654563904,
      "learning_rate": 3.673948289103166e-05,
      "loss": 0.0028,
      "step": 15540
    },
    {
      "epoch": 1.3269050260261115,
      "grad_norm": 0.2134067863225937,
      "learning_rate": 3.673094973973888e-05,
      "loss": 0.003,
      "step": 15550
    },
    {
      "epoch": 1.3277583411553886,
      "grad_norm": 0.21382510662078857,
      "learning_rate": 3.672241658844611e-05,
      "loss": 0.0025,
      "step": 15560
    },
    {
      "epoch": 1.328611656284666,
      "grad_norm": 0.2153310775756836,
      "learning_rate": 3.671388343715334e-05,
      "loss": 0.0038,
      "step": 15570
    },
    {
      "epoch": 1.3294649714139433,
      "grad_norm": 0.6836147308349609,
      "learning_rate": 3.670535028586057e-05,
      "loss": 0.0036,
      "step": 15580
    },
    {
      "epoch": 1.3303182865432204,
      "grad_norm": 0.4202641248703003,
      "learning_rate": 3.6696817134567796e-05,
      "loss": 0.0023,
      "step": 15590
    },
    {
      "epoch": 1.3311716016724977,
      "grad_norm": 0.21978460252285004,
      "learning_rate": 3.6688283983275025e-05,
      "loss": 0.0031,
      "step": 15600
    },
    {
      "epoch": 1.3320249168017748,
      "grad_norm": 0.031002629548311234,
      "learning_rate": 3.667975083198225e-05,
      "loss": 0.0033,
      "step": 15610
    },
    {
      "epoch": 1.3328782319310521,
      "grad_norm": 0.23884806036949158,
      "learning_rate": 3.667121768068948e-05,
      "loss": 0.0025,
      "step": 15620
    },
    {
      "epoch": 1.3337315470603293,
      "grad_norm": 0.15333135426044464,
      "learning_rate": 3.666268452939671e-05,
      "loss": 0.0022,
      "step": 15630
    },
    {
      "epoch": 1.3345848621896066,
      "grad_norm": 0.08640138804912567,
      "learning_rate": 3.665415137810393e-05,
      "loss": 0.003,
      "step": 15640
    },
    {
      "epoch": 1.335438177318884,
      "grad_norm": 0.09229462593793869,
      "learning_rate": 3.664561822681116e-05,
      "loss": 0.0018,
      "step": 15650
    },
    {
      "epoch": 1.336291492448161,
      "grad_norm": 0.13618271052837372,
      "learning_rate": 3.663708507551839e-05,
      "loss": 0.0032,
      "step": 15660
    },
    {
      "epoch": 1.3371448075774384,
      "grad_norm": 0.4128698706626892,
      "learning_rate": 3.662855192422562e-05,
      "loss": 0.0026,
      "step": 15670
    },
    {
      "epoch": 1.3379981227067157,
      "grad_norm": 0.3364425003528595,
      "learning_rate": 3.6620018772932846e-05,
      "loss": 0.0029,
      "step": 15680
    },
    {
      "epoch": 1.3388514378359928,
      "grad_norm": 0.7182196378707886,
      "learning_rate": 3.6611485621640074e-05,
      "loss": 0.0025,
      "step": 15690
    },
    {
      "epoch": 1.3397047529652701,
      "grad_norm": 0.6882862448692322,
      "learning_rate": 3.66029524703473e-05,
      "loss": 0.0029,
      "step": 15700
    },
    {
      "epoch": 1.3405580680945473,
      "grad_norm": 0.2613595426082611,
      "learning_rate": 3.659441931905453e-05,
      "loss": 0.003,
      "step": 15710
    },
    {
      "epoch": 1.3414113832238246,
      "grad_norm": 0.4333573877811432,
      "learning_rate": 3.658588616776176e-05,
      "loss": 0.0025,
      "step": 15720
    },
    {
      "epoch": 1.3422646983531017,
      "grad_norm": 0.5620585680007935,
      "learning_rate": 3.657735301646898e-05,
      "loss": 0.0025,
      "step": 15730
    },
    {
      "epoch": 1.343118013482379,
      "grad_norm": 0.20290924608707428,
      "learning_rate": 3.656881986517621e-05,
      "loss": 0.0028,
      "step": 15740
    },
    {
      "epoch": 1.3439713286116564,
      "grad_norm": 0.24246475100517273,
      "learning_rate": 3.656028671388344e-05,
      "loss": 0.0029,
      "step": 15750
    },
    {
      "epoch": 1.3448246437409335,
      "grad_norm": 0.14429551362991333,
      "learning_rate": 3.655175356259067e-05,
      "loss": 0.0027,
      "step": 15760
    },
    {
      "epoch": 1.3456779588702108,
      "grad_norm": 0.146684929728508,
      "learning_rate": 3.6543220411297895e-05,
      "loss": 0.0036,
      "step": 15770
    },
    {
      "epoch": 1.3465312739994881,
      "grad_norm": 0.01848202757537365,
      "learning_rate": 3.6534687260005124e-05,
      "loss": 0.0037,
      "step": 15780
    },
    {
      "epoch": 1.3473845891287652,
      "grad_norm": 0.6671838164329529,
      "learning_rate": 3.652615410871235e-05,
      "loss": 0.0028,
      "step": 15790
    },
    {
      "epoch": 1.3482379042580426,
      "grad_norm": 0.1087699830532074,
      "learning_rate": 3.651762095741958e-05,
      "loss": 0.0039,
      "step": 15800
    },
    {
      "epoch": 1.3490912193873197,
      "grad_norm": 0.31954869627952576,
      "learning_rate": 3.650908780612681e-05,
      "loss": 0.003,
      "step": 15810
    },
    {
      "epoch": 1.349944534516597,
      "grad_norm": 0.2748681902885437,
      "learning_rate": 3.650055465483403e-05,
      "loss": 0.0033,
      "step": 15820
    },
    {
      "epoch": 1.3507978496458741,
      "grad_norm": 0.16916611790657043,
      "learning_rate": 3.649202150354126e-05,
      "loss": 0.003,
      "step": 15830
    },
    {
      "epoch": 1.3516511647751515,
      "grad_norm": 0.5275400280952454,
      "learning_rate": 3.648348835224849e-05,
      "loss": 0.0023,
      "step": 15840
    },
    {
      "epoch": 1.3525044799044288,
      "grad_norm": 0.11606045067310333,
      "learning_rate": 3.647495520095571e-05,
      "loss": 0.0033,
      "step": 15850
    },
    {
      "epoch": 1.353357795033706,
      "grad_norm": 0.35557568073272705,
      "learning_rate": 3.646642204966294e-05,
      "loss": 0.0035,
      "step": 15860
    },
    {
      "epoch": 1.3542111101629832,
      "grad_norm": 0.06083196401596069,
      "learning_rate": 3.645788889837017e-05,
      "loss": 0.0035,
      "step": 15870
    },
    {
      "epoch": 1.3550644252922606,
      "grad_norm": 0.05168307200074196,
      "learning_rate": 3.6449355747077395e-05,
      "loss": 0.0023,
      "step": 15880
    },
    {
      "epoch": 1.3559177404215377,
      "grad_norm": 0.03838961198925972,
      "learning_rate": 3.6440822595784624e-05,
      "loss": 0.0028,
      "step": 15890
    },
    {
      "epoch": 1.3567710555508148,
      "grad_norm": 0.03197060897946358,
      "learning_rate": 3.643228944449185e-05,
      "loss": 0.0034,
      "step": 15900
    },
    {
      "epoch": 1.3576243706800921,
      "grad_norm": 0.2687320411205292,
      "learning_rate": 3.642375629319908e-05,
      "loss": 0.0033,
      "step": 15910
    },
    {
      "epoch": 1.3584776858093695,
      "grad_norm": 0.24159549176692963,
      "learning_rate": 3.641522314190631e-05,
      "loss": 0.0029,
      "step": 15920
    },
    {
      "epoch": 1.3593310009386466,
      "grad_norm": 0.08562027662992477,
      "learning_rate": 3.640668999061354e-05,
      "loss": 0.003,
      "step": 15930
    },
    {
      "epoch": 1.360184316067924,
      "grad_norm": 0.051390472799539566,
      "learning_rate": 3.6398156839320766e-05,
      "loss": 0.0033,
      "step": 15940
    },
    {
      "epoch": 1.3610376311972012,
      "grad_norm": 0.10410449653863907,
      "learning_rate": 3.638962368802799e-05,
      "loss": 0.0027,
      "step": 15950
    },
    {
      "epoch": 1.3618909463264783,
      "grad_norm": 0.09432028979063034,
      "learning_rate": 3.6381090536735216e-05,
      "loss": 0.0027,
      "step": 15960
    },
    {
      "epoch": 1.3627442614557557,
      "grad_norm": 0.1659446805715561,
      "learning_rate": 3.6372557385442445e-05,
      "loss": 0.0017,
      "step": 15970
    },
    {
      "epoch": 1.3635975765850328,
      "grad_norm": 0.1363299936056137,
      "learning_rate": 3.636402423414967e-05,
      "loss": 0.002,
      "step": 15980
    },
    {
      "epoch": 1.36445089171431,
      "grad_norm": 0.03234871104359627,
      "learning_rate": 3.63554910828569e-05,
      "loss": 0.0027,
      "step": 15990
    },
    {
      "epoch": 1.3653042068435872,
      "grad_norm": 0.2507423162460327,
      "learning_rate": 3.634695793156413e-05,
      "loss": 0.0032,
      "step": 16000
    },
    {
      "epoch": 1.3661575219728646,
      "grad_norm": 0.40500015020370483,
      "learning_rate": 3.633842478027136e-05,
      "loss": 0.0022,
      "step": 16010
    },
    {
      "epoch": 1.3670108371021419,
      "grad_norm": 0.14625215530395508,
      "learning_rate": 3.632989162897859e-05,
      "loss": 0.003,
      "step": 16020
    },
    {
      "epoch": 1.367864152231419,
      "grad_norm": 0.39039063453674316,
      "learning_rate": 3.6321358477685816e-05,
      "loss": 0.0019,
      "step": 16030
    },
    {
      "epoch": 1.3687174673606963,
      "grad_norm": 0.3470519483089447,
      "learning_rate": 3.6312825326393044e-05,
      "loss": 0.0022,
      "step": 16040
    },
    {
      "epoch": 1.3695707824899737,
      "grad_norm": 0.028903797268867493,
      "learning_rate": 3.6304292175100266e-05,
      "loss": 0.0021,
      "step": 16050
    },
    {
      "epoch": 1.3704240976192508,
      "grad_norm": 0.3336857259273529,
      "learning_rate": 3.6295759023807494e-05,
      "loss": 0.003,
      "step": 16060
    },
    {
      "epoch": 1.371277412748528,
      "grad_norm": 0.12223172932863235,
      "learning_rate": 3.628722587251472e-05,
      "loss": 0.003,
      "step": 16070
    },
    {
      "epoch": 1.3721307278778052,
      "grad_norm": 0.042303215712308884,
      "learning_rate": 3.6278692721221944e-05,
      "loss": 0.0021,
      "step": 16080
    },
    {
      "epoch": 1.3729840430070825,
      "grad_norm": 0.08142903447151184,
      "learning_rate": 3.627015956992917e-05,
      "loss": 0.0027,
      "step": 16090
    },
    {
      "epoch": 1.3738373581363597,
      "grad_norm": 0.15522503852844238,
      "learning_rate": 3.62616264186364e-05,
      "loss": 0.0025,
      "step": 16100
    },
    {
      "epoch": 1.374690673265637,
      "grad_norm": 0.09685999900102615,
      "learning_rate": 3.625309326734363e-05,
      "loss": 0.0024,
      "step": 16110
    },
    {
      "epoch": 1.3755439883949143,
      "grad_norm": 0.06974416226148605,
      "learning_rate": 3.624456011605086e-05,
      "loss": 0.0029,
      "step": 16120
    },
    {
      "epoch": 1.3763973035241914,
      "grad_norm": 0.14955608546733856,
      "learning_rate": 3.623602696475809e-05,
      "loss": 0.0028,
      "step": 16130
    },
    {
      "epoch": 1.3772506186534688,
      "grad_norm": 0.11613741517066956,
      "learning_rate": 3.6227493813465315e-05,
      "loss": 0.0026,
      "step": 16140
    },
    {
      "epoch": 1.378103933782746,
      "grad_norm": 0.06568388640880585,
      "learning_rate": 3.6218960662172544e-05,
      "loss": 0.0024,
      "step": 16150
    },
    {
      "epoch": 1.3789572489120232,
      "grad_norm": 0.2171180099248886,
      "learning_rate": 3.6210427510879766e-05,
      "loss": 0.0025,
      "step": 16160
    },
    {
      "epoch": 1.3798105640413003,
      "grad_norm": 0.12084668129682541,
      "learning_rate": 3.6201894359586994e-05,
      "loss": 0.0034,
      "step": 16170
    },
    {
      "epoch": 1.3806638791705776,
      "grad_norm": 0.1553049087524414,
      "learning_rate": 3.619336120829422e-05,
      "loss": 0.0028,
      "step": 16180
    },
    {
      "epoch": 1.381517194299855,
      "grad_norm": 0.10578033328056335,
      "learning_rate": 3.618482805700145e-05,
      "loss": 0.0024,
      "step": 16190
    },
    {
      "epoch": 1.382370509429132,
      "grad_norm": 0.234654039144516,
      "learning_rate": 3.617629490570868e-05,
      "loss": 0.0021,
      "step": 16200
    },
    {
      "epoch": 1.3832238245584094,
      "grad_norm": 0.06200476735830307,
      "learning_rate": 3.616776175441591e-05,
      "loss": 0.0038,
      "step": 16210
    },
    {
      "epoch": 1.3840771396876868,
      "grad_norm": 0.4005563259124756,
      "learning_rate": 3.6159228603123136e-05,
      "loss": 0.0039,
      "step": 16220
    },
    {
      "epoch": 1.3849304548169639,
      "grad_norm": 0.09822157770395279,
      "learning_rate": 3.6150695451830365e-05,
      "loss": 0.003,
      "step": 16230
    },
    {
      "epoch": 1.3857837699462412,
      "grad_norm": 0.34681761264801025,
      "learning_rate": 3.614216230053759e-05,
      "loss": 0.0033,
      "step": 16240
    },
    {
      "epoch": 1.3866370850755185,
      "grad_norm": 0.2512120008468628,
      "learning_rate": 3.613362914924482e-05,
      "loss": 0.0024,
      "step": 16250
    },
    {
      "epoch": 1.3874904002047956,
      "grad_norm": 0.10781024396419525,
      "learning_rate": 3.6125095997952044e-05,
      "loss": 0.0029,
      "step": 16260
    },
    {
      "epoch": 1.3883437153340727,
      "grad_norm": 0.20536847412586212,
      "learning_rate": 3.611656284665927e-05,
      "loss": 0.0027,
      "step": 16270
    },
    {
      "epoch": 1.38919703046335,
      "grad_norm": 0.17783963680267334,
      "learning_rate": 3.61080296953665e-05,
      "loss": 0.003,
      "step": 16280
    },
    {
      "epoch": 1.3900503455926274,
      "grad_norm": 0.2166130691766739,
      "learning_rate": 3.609949654407373e-05,
      "loss": 0.0028,
      "step": 16290
    },
    {
      "epoch": 1.3909036607219045,
      "grad_norm": 0.24241219460964203,
      "learning_rate": 3.609096339278096e-05,
      "loss": 0.0023,
      "step": 16300
    },
    {
      "epoch": 1.3917569758511819,
      "grad_norm": 0.27508896589279175,
      "learning_rate": 3.6082430241488186e-05,
      "loss": 0.0023,
      "step": 16310
    },
    {
      "epoch": 1.3926102909804592,
      "grad_norm": 0.3506682217121124,
      "learning_rate": 3.6073897090195414e-05,
      "loss": 0.0027,
      "step": 16320
    },
    {
      "epoch": 1.3934636061097363,
      "grad_norm": 0.06631607562303543,
      "learning_rate": 3.606536393890264e-05,
      "loss": 0.0017,
      "step": 16330
    },
    {
      "epoch": 1.3943169212390136,
      "grad_norm": 0.11017132550477982,
      "learning_rate": 3.605683078760987e-05,
      "loss": 0.0031,
      "step": 16340
    },
    {
      "epoch": 1.3951702363682907,
      "grad_norm": 0.19531433284282684,
      "learning_rate": 3.604829763631709e-05,
      "loss": 0.0031,
      "step": 16350
    },
    {
      "epoch": 1.396023551497568,
      "grad_norm": 0.23575294017791748,
      "learning_rate": 3.603976448502432e-05,
      "loss": 0.0027,
      "step": 16360
    },
    {
      "epoch": 1.3968768666268452,
      "grad_norm": 0.24923503398895264,
      "learning_rate": 3.603123133373154e-05,
      "loss": 0.0022,
      "step": 16370
    },
    {
      "epoch": 1.3977301817561225,
      "grad_norm": 0.21605150401592255,
      "learning_rate": 3.602269818243877e-05,
      "loss": 0.0021,
      "step": 16380
    },
    {
      "epoch": 1.3985834968853998,
      "grad_norm": 0.04722375050187111,
      "learning_rate": 3.6014165031146e-05,
      "loss": 0.003,
      "step": 16390
    },
    {
      "epoch": 1.399436812014677,
      "grad_norm": 0.3657889664173126,
      "learning_rate": 3.600563187985323e-05,
      "loss": 0.0027,
      "step": 16400
    },
    {
      "epoch": 1.4002901271439543,
      "grad_norm": 0.25992393493652344,
      "learning_rate": 3.599709872856046e-05,
      "loss": 0.0031,
      "step": 16410
    },
    {
      "epoch": 1.4011434422732316,
      "grad_norm": 0.13414131104946136,
      "learning_rate": 3.5988565577267686e-05,
      "loss": 0.0027,
      "step": 16420
    },
    {
      "epoch": 1.4019967574025087,
      "grad_norm": 0.4125201404094696,
      "learning_rate": 3.5980032425974914e-05,
      "loss": 0.0033,
      "step": 16430
    },
    {
      "epoch": 1.402850072531786,
      "grad_norm": 0.06221800297498703,
      "learning_rate": 3.597149927468214e-05,
      "loss": 0.0025,
      "step": 16440
    },
    {
      "epoch": 1.4037033876610632,
      "grad_norm": 0.29594045877456665,
      "learning_rate": 3.596296612338937e-05,
      "loss": 0.0029,
      "step": 16450
    },
    {
      "epoch": 1.4045567027903405,
      "grad_norm": 0.549302339553833,
      "learning_rate": 3.59544329720966e-05,
      "loss": 0.0026,
      "step": 16460
    },
    {
      "epoch": 1.4054100179196176,
      "grad_norm": 0.46865010261535645,
      "learning_rate": 3.594589982080382e-05,
      "loss": 0.0029,
      "step": 16470
    },
    {
      "epoch": 1.406263333048895,
      "grad_norm": 0.13845312595367432,
      "learning_rate": 3.593736666951105e-05,
      "loss": 0.0029,
      "step": 16480
    },
    {
      "epoch": 1.4071166481781723,
      "grad_norm": 0.1613345444202423,
      "learning_rate": 3.592883351821828e-05,
      "loss": 0.0029,
      "step": 16490
    },
    {
      "epoch": 1.4079699633074494,
      "grad_norm": 0.12841913104057312,
      "learning_rate": 3.592030036692551e-05,
      "loss": 0.0025,
      "step": 16500
    },
    {
      "epoch": 1.4088232784367267,
      "grad_norm": 0.1812727451324463,
      "learning_rate": 3.5911767215632735e-05,
      "loss": 0.0033,
      "step": 16510
    },
    {
      "epoch": 1.409676593566004,
      "grad_norm": 0.12749142944812775,
      "learning_rate": 3.5903234064339964e-05,
      "loss": 0.0028,
      "step": 16520
    },
    {
      "epoch": 1.4105299086952812,
      "grad_norm": 0.11784884333610535,
      "learning_rate": 3.589470091304719e-05,
      "loss": 0.0031,
      "step": 16530
    },
    {
      "epoch": 1.4113832238245583,
      "grad_norm": 0.0479622408747673,
      "learning_rate": 3.588616776175442e-05,
      "loss": 0.0032,
      "step": 16540
    },
    {
      "epoch": 1.4122365389538356,
      "grad_norm": 0.2749193012714386,
      "learning_rate": 3.587763461046165e-05,
      "loss": 0.0031,
      "step": 16550
    },
    {
      "epoch": 1.413089854083113,
      "grad_norm": 0.36230185627937317,
      "learning_rate": 3.586910145916888e-05,
      "loss": 0.0019,
      "step": 16560
    },
    {
      "epoch": 1.41394316921239,
      "grad_norm": 0.23402413725852966,
      "learning_rate": 3.58605683078761e-05,
      "loss": 0.0027,
      "step": 16570
    },
    {
      "epoch": 1.4147964843416674,
      "grad_norm": 0.08077021688222885,
      "learning_rate": 3.585203515658333e-05,
      "loss": 0.0025,
      "step": 16580
    },
    {
      "epoch": 1.4156497994709447,
      "grad_norm": 0.14862309396266937,
      "learning_rate": 3.5843502005290556e-05,
      "loss": 0.0034,
      "step": 16590
    },
    {
      "epoch": 1.4165031146002218,
      "grad_norm": 0.1785542368888855,
      "learning_rate": 3.5834968853997785e-05,
      "loss": 0.0024,
      "step": 16600
    },
    {
      "epoch": 1.4173564297294992,
      "grad_norm": 0.24538780748844147,
      "learning_rate": 3.5826435702705007e-05,
      "loss": 0.0023,
      "step": 16610
    },
    {
      "epoch": 1.4182097448587763,
      "grad_norm": 0.18462708592414856,
      "learning_rate": 3.5817902551412235e-05,
      "loss": 0.0028,
      "step": 16620
    },
    {
      "epoch": 1.4190630599880536,
      "grad_norm": 0.19664935767650604,
      "learning_rate": 3.5809369400119464e-05,
      "loss": 0.0026,
      "step": 16630
    },
    {
      "epoch": 1.4199163751173307,
      "grad_norm": 0.08227211236953735,
      "learning_rate": 3.580083624882669e-05,
      "loss": 0.0033,
      "step": 16640
    },
    {
      "epoch": 1.420769690246608,
      "grad_norm": 0.3855157196521759,
      "learning_rate": 3.579230309753392e-05,
      "loss": 0.003,
      "step": 16650
    },
    {
      "epoch": 1.4216230053758854,
      "grad_norm": 0.06920172274112701,
      "learning_rate": 3.578376994624115e-05,
      "loss": 0.0028,
      "step": 16660
    },
    {
      "epoch": 1.4224763205051625,
      "grad_norm": 0.10264594852924347,
      "learning_rate": 3.577523679494838e-05,
      "loss": 0.0035,
      "step": 16670
    },
    {
      "epoch": 1.4233296356344398,
      "grad_norm": 0.1765429675579071,
      "learning_rate": 3.57667036436556e-05,
      "loss": 0.0028,
      "step": 16680
    },
    {
      "epoch": 1.4241829507637171,
      "grad_norm": 0.27811384201049805,
      "learning_rate": 3.575817049236283e-05,
      "loss": 0.004,
      "step": 16690
    },
    {
      "epoch": 1.4250362658929943,
      "grad_norm": 0.15546824038028717,
      "learning_rate": 3.5749637341070056e-05,
      "loss": 0.003,
      "step": 16700
    },
    {
      "epoch": 1.4258895810222716,
      "grad_norm": 0.2783152461051941,
      "learning_rate": 3.5741104189777285e-05,
      "loss": 0.0028,
      "step": 16710
    },
    {
      "epoch": 1.4267428961515487,
      "grad_norm": 0.24177291989326477,
      "learning_rate": 3.573257103848451e-05,
      "loss": 0.0033,
      "step": 16720
    },
    {
      "epoch": 1.427596211280826,
      "grad_norm": 0.31717750430107117,
      "learning_rate": 3.572403788719174e-05,
      "loss": 0.0026,
      "step": 16730
    },
    {
      "epoch": 1.4284495264101031,
      "grad_norm": 0.08217266947031021,
      "learning_rate": 3.571550473589897e-05,
      "loss": 0.0023,
      "step": 16740
    },
    {
      "epoch": 1.4293028415393805,
      "grad_norm": 0.3907323479652405,
      "learning_rate": 3.57069715846062e-05,
      "loss": 0.0035,
      "step": 16750
    },
    {
      "epoch": 1.4301561566686578,
      "grad_norm": 0.05440939590334892,
      "learning_rate": 3.569843843331343e-05,
      "loss": 0.0028,
      "step": 16760
    },
    {
      "epoch": 1.431009471797935,
      "grad_norm": 0.045756738632917404,
      "learning_rate": 3.5689905282020655e-05,
      "loss": 0.0034,
      "step": 16770
    },
    {
      "epoch": 1.4318627869272122,
      "grad_norm": 0.1059073954820633,
      "learning_rate": 3.568137213072788e-05,
      "loss": 0.0031,
      "step": 16780
    },
    {
      "epoch": 1.4327161020564896,
      "grad_norm": 0.1639391928911209,
      "learning_rate": 3.5672838979435106e-05,
      "loss": 0.0031,
      "step": 16790
    },
    {
      "epoch": 1.4335694171857667,
      "grad_norm": 0.18377631902694702,
      "learning_rate": 3.5664305828142334e-05,
      "loss": 0.0035,
      "step": 16800
    },
    {
      "epoch": 1.434422732315044,
      "grad_norm": 0.2874739468097687,
      "learning_rate": 3.565577267684956e-05,
      "loss": 0.0032,
      "step": 16810
    },
    {
      "epoch": 1.4352760474443211,
      "grad_norm": 0.31815069913864136,
      "learning_rate": 3.564723952555679e-05,
      "loss": 0.0027,
      "step": 16820
    },
    {
      "epoch": 1.4361293625735985,
      "grad_norm": 0.3381425142288208,
      "learning_rate": 3.563870637426402e-05,
      "loss": 0.0026,
      "step": 16830
    },
    {
      "epoch": 1.4369826777028756,
      "grad_norm": 0.0855727344751358,
      "learning_rate": 3.563017322297125e-05,
      "loss": 0.0027,
      "step": 16840
    },
    {
      "epoch": 1.437835992832153,
      "grad_norm": 0.17725007236003876,
      "learning_rate": 3.5621640071678477e-05,
      "loss": 0.003,
      "step": 16850
    },
    {
      "epoch": 1.4386893079614302,
      "grad_norm": 0.2045830935239792,
      "learning_rate": 3.5613106920385705e-05,
      "loss": 0.0024,
      "step": 16860
    },
    {
      "epoch": 1.4395426230907074,
      "grad_norm": 0.47661736607551575,
      "learning_rate": 3.5604573769092934e-05,
      "loss": 0.0026,
      "step": 16870
    },
    {
      "epoch": 1.4403959382199847,
      "grad_norm": 0.07865151762962341,
      "learning_rate": 3.5596040617800155e-05,
      "loss": 0.0029,
      "step": 16880
    },
    {
      "epoch": 1.441249253349262,
      "grad_norm": 0.2377103716135025,
      "learning_rate": 3.5587507466507384e-05,
      "loss": 0.003,
      "step": 16890
    },
    {
      "epoch": 1.4421025684785391,
      "grad_norm": 0.07030730694532394,
      "learning_rate": 3.5578974315214605e-05,
      "loss": 0.0021,
      "step": 16900
    },
    {
      "epoch": 1.4429558836078162,
      "grad_norm": 0.16181211173534393,
      "learning_rate": 3.5570441163921834e-05,
      "loss": 0.0023,
      "step": 16910
    },
    {
      "epoch": 1.4438091987370936,
      "grad_norm": 0.16753990948200226,
      "learning_rate": 3.556190801262906e-05,
      "loss": 0.0026,
      "step": 16920
    },
    {
      "epoch": 1.444662513866371,
      "grad_norm": 0.527738094329834,
      "learning_rate": 3.555337486133629e-05,
      "loss": 0.0033,
      "step": 16930
    },
    {
      "epoch": 1.445515828995648,
      "grad_norm": 0.3249228298664093,
      "learning_rate": 3.554484171004352e-05,
      "loss": 0.0033,
      "step": 16940
    },
    {
      "epoch": 1.4463691441249253,
      "grad_norm": 0.6143775582313538,
      "learning_rate": 3.553630855875075e-05,
      "loss": 0.0037,
      "step": 16950
    },
    {
      "epoch": 1.4472224592542027,
      "grad_norm": 0.06498256325721741,
      "learning_rate": 3.5527775407457976e-05,
      "loss": 0.0022,
      "step": 16960
    },
    {
      "epoch": 1.4480757743834798,
      "grad_norm": 0.20348471403121948,
      "learning_rate": 3.5519242256165205e-05,
      "loss": 0.0025,
      "step": 16970
    },
    {
      "epoch": 1.4489290895127571,
      "grad_norm": 0.05217494070529938,
      "learning_rate": 3.551070910487243e-05,
      "loss": 0.0034,
      "step": 16980
    },
    {
      "epoch": 1.4497824046420342,
      "grad_norm": 0.10205649584531784,
      "learning_rate": 3.5502175953579655e-05,
      "loss": 0.0027,
      "step": 16990
    },
    {
      "epoch": 1.4506357197713116,
      "grad_norm": 0.3438892066478729,
      "learning_rate": 3.5493642802286883e-05,
      "loss": 0.0034,
      "step": 17000
    },
    {
      "epoch": 1.4514890349005887,
      "grad_norm": 0.07264065742492676,
      "learning_rate": 3.548510965099411e-05,
      "loss": 0.0036,
      "step": 17010
    },
    {
      "epoch": 1.452342350029866,
      "grad_norm": 0.26276305317878723,
      "learning_rate": 3.547657649970134e-05,
      "loss": 0.0027,
      "step": 17020
    },
    {
      "epoch": 1.4531956651591433,
      "grad_norm": 0.14065243303775787,
      "learning_rate": 3.546804334840857e-05,
      "loss": 0.003,
      "step": 17030
    },
    {
      "epoch": 1.4540489802884204,
      "grad_norm": 0.2213655710220337,
      "learning_rate": 3.54595101971158e-05,
      "loss": 0.0025,
      "step": 17040
    },
    {
      "epoch": 1.4549022954176978,
      "grad_norm": 0.1365944743156433,
      "learning_rate": 3.5450977045823026e-05,
      "loss": 0.0026,
      "step": 17050
    },
    {
      "epoch": 1.455755610546975,
      "grad_norm": 0.19687223434448242,
      "learning_rate": 3.5442443894530254e-05,
      "loss": 0.0032,
      "step": 17060
    },
    {
      "epoch": 1.4566089256762522,
      "grad_norm": 0.17229096591472626,
      "learning_rate": 3.543391074323748e-05,
      "loss": 0.0035,
      "step": 17070
    },
    {
      "epoch": 1.4574622408055296,
      "grad_norm": 0.1199953481554985,
      "learning_rate": 3.542537759194471e-05,
      "loss": 0.0028,
      "step": 17080
    },
    {
      "epoch": 1.4583155559348067,
      "grad_norm": 0.2607237994670868,
      "learning_rate": 3.541684444065193e-05,
      "loss": 0.0029,
      "step": 17090
    },
    {
      "epoch": 1.459168871064084,
      "grad_norm": 0.4044407904148102,
      "learning_rate": 3.540831128935916e-05,
      "loss": 0.0032,
      "step": 17100
    },
    {
      "epoch": 1.460022186193361,
      "grad_norm": 0.17891548573970795,
      "learning_rate": 3.539977813806639e-05,
      "loss": 0.0032,
      "step": 17110
    },
    {
      "epoch": 1.4608755013226384,
      "grad_norm": 0.10574200004339218,
      "learning_rate": 3.539124498677362e-05,
      "loss": 0.0031,
      "step": 17120
    },
    {
      "epoch": 1.4617288164519158,
      "grad_norm": 0.17025183141231537,
      "learning_rate": 3.538271183548085e-05,
      "loss": 0.0032,
      "step": 17130
    },
    {
      "epoch": 1.4625821315811929,
      "grad_norm": 0.30803853273391724,
      "learning_rate": 3.5374178684188075e-05,
      "loss": 0.0037,
      "step": 17140
    },
    {
      "epoch": 1.4634354467104702,
      "grad_norm": 0.36863991618156433,
      "learning_rate": 3.53656455328953e-05,
      "loss": 0.0032,
      "step": 17150
    },
    {
      "epoch": 1.4642887618397475,
      "grad_norm": 0.4656836688518524,
      "learning_rate": 3.5357112381602526e-05,
      "loss": 0.0029,
      "step": 17160
    },
    {
      "epoch": 1.4651420769690247,
      "grad_norm": 0.36309558153152466,
      "learning_rate": 3.5348579230309754e-05,
      "loss": 0.003,
      "step": 17170
    },
    {
      "epoch": 1.465995392098302,
      "grad_norm": 0.15866729617118835,
      "learning_rate": 3.534004607901698e-05,
      "loss": 0.0037,
      "step": 17180
    },
    {
      "epoch": 1.466848707227579,
      "grad_norm": 0.3519277572631836,
      "learning_rate": 3.533151292772421e-05,
      "loss": 0.0034,
      "step": 17190
    },
    {
      "epoch": 1.4677020223568564,
      "grad_norm": 0.16600319743156433,
      "learning_rate": 3.532297977643144e-05,
      "loss": 0.0035,
      "step": 17200
    },
    {
      "epoch": 1.4685553374861335,
      "grad_norm": 0.34991464018821716,
      "learning_rate": 3.531444662513866e-05,
      "loss": 0.0033,
      "step": 17210
    },
    {
      "epoch": 1.4694086526154109,
      "grad_norm": 0.46670591831207275,
      "learning_rate": 3.530591347384589e-05,
      "loss": 0.0036,
      "step": 17220
    },
    {
      "epoch": 1.4702619677446882,
      "grad_norm": 0.11946026980876923,
      "learning_rate": 3.529738032255312e-05,
      "loss": 0.0039,
      "step": 17230
    },
    {
      "epoch": 1.4711152828739653,
      "grad_norm": 0.05997883901000023,
      "learning_rate": 3.528884717126035e-05,
      "loss": 0.0035,
      "step": 17240
    },
    {
      "epoch": 1.4719685980032426,
      "grad_norm": 0.08456844091415405,
      "learning_rate": 3.5280314019967575e-05,
      "loss": 0.0023,
      "step": 17250
    },
    {
      "epoch": 1.47282191313252,
      "grad_norm": 0.14422661066055298,
      "learning_rate": 3.5271780868674804e-05,
      "loss": 0.0026,
      "step": 17260
    },
    {
      "epoch": 1.473675228261797,
      "grad_norm": 0.038480594754219055,
      "learning_rate": 3.526324771738203e-05,
      "loss": 0.0025,
      "step": 17270
    },
    {
      "epoch": 1.4745285433910742,
      "grad_norm": 0.1063343957066536,
      "learning_rate": 3.525471456608926e-05,
      "loss": 0.0026,
      "step": 17280
    },
    {
      "epoch": 1.4753818585203515,
      "grad_norm": 0.12544727325439453,
      "learning_rate": 3.524618141479649e-05,
      "loss": 0.0017,
      "step": 17290
    },
    {
      "epoch": 1.4762351736496289,
      "grad_norm": 0.053155407309532166,
      "learning_rate": 3.523764826350371e-05,
      "loss": 0.0023,
      "step": 17300
    },
    {
      "epoch": 1.477088488778906,
      "grad_norm": 0.23663073778152466,
      "learning_rate": 3.522911511221094e-05,
      "loss": 0.0032,
      "step": 17310
    },
    {
      "epoch": 1.4779418039081833,
      "grad_norm": 0.12783528864383698,
      "learning_rate": 3.522058196091817e-05,
      "loss": 0.0032,
      "step": 17320
    },
    {
      "epoch": 1.4787951190374606,
      "grad_norm": 0.1799362748861313,
      "learning_rate": 3.5212048809625396e-05,
      "loss": 0.0022,
      "step": 17330
    },
    {
      "epoch": 1.4796484341667377,
      "grad_norm": 0.24920517206192017,
      "learning_rate": 3.5203515658332625e-05,
      "loss": 0.0035,
      "step": 17340
    },
    {
      "epoch": 1.480501749296015,
      "grad_norm": 0.04239670932292938,
      "learning_rate": 3.519498250703985e-05,
      "loss": 0.003,
      "step": 17350
    },
    {
      "epoch": 1.4813550644252922,
      "grad_norm": 0.31006163358688354,
      "learning_rate": 3.518644935574708e-05,
      "loss": 0.003,
      "step": 17360
    },
    {
      "epoch": 1.4822083795545695,
      "grad_norm": 0.179945707321167,
      "learning_rate": 3.517791620445431e-05,
      "loss": 0.0029,
      "step": 17370
    },
    {
      "epoch": 1.4830616946838466,
      "grad_norm": 0.8981379270553589,
      "learning_rate": 3.516938305316154e-05,
      "loss": 0.0029,
      "step": 17380
    },
    {
      "epoch": 1.483915009813124,
      "grad_norm": 0.4063461422920227,
      "learning_rate": 3.516084990186877e-05,
      "loss": 0.0044,
      "step": 17390
    },
    {
      "epoch": 1.4847683249424013,
      "grad_norm": 0.26208269596099854,
      "learning_rate": 3.515231675057599e-05,
      "loss": 0.0024,
      "step": 17400
    },
    {
      "epoch": 1.4856216400716784,
      "grad_norm": 0.3887152671813965,
      "learning_rate": 3.514378359928322e-05,
      "loss": 0.0035,
      "step": 17410
    },
    {
      "epoch": 1.4864749552009557,
      "grad_norm": 0.15807098150253296,
      "learning_rate": 3.513525044799044e-05,
      "loss": 0.0034,
      "step": 17420
    },
    {
      "epoch": 1.487328270330233,
      "grad_norm": 0.28494328260421753,
      "learning_rate": 3.512671729669767e-05,
      "loss": 0.0028,
      "step": 17430
    },
    {
      "epoch": 1.4881815854595102,
      "grad_norm": 0.18135160207748413,
      "learning_rate": 3.5118184145404896e-05,
      "loss": 0.0029,
      "step": 17440
    },
    {
      "epoch": 1.4890349005887875,
      "grad_norm": 0.15457271039485931,
      "learning_rate": 3.5109650994112124e-05,
      "loss": 0.0036,
      "step": 17450
    },
    {
      "epoch": 1.4898882157180646,
      "grad_norm": 0.3356689214706421,
      "learning_rate": 3.510111784281935e-05,
      "loss": 0.0021,
      "step": 17460
    },
    {
      "epoch": 1.490741530847342,
      "grad_norm": 0.07885845005512238,
      "learning_rate": 3.509258469152658e-05,
      "loss": 0.0025,
      "step": 17470
    },
    {
      "epoch": 1.491594845976619,
      "grad_norm": 0.1534460037946701,
      "learning_rate": 3.508405154023381e-05,
      "loss": 0.0031,
      "step": 17480
    },
    {
      "epoch": 1.4924481611058964,
      "grad_norm": 0.20456767082214355,
      "learning_rate": 3.507551838894104e-05,
      "loss": 0.0028,
      "step": 17490
    },
    {
      "epoch": 1.4933014762351737,
      "grad_norm": 0.14023050665855408,
      "learning_rate": 3.506698523764827e-05,
      "loss": 0.0024,
      "step": 17500
    },
    {
      "epoch": 1.4941547913644508,
      "grad_norm": 0.037584807723760605,
      "learning_rate": 3.5058452086355495e-05,
      "loss": 0.0025,
      "step": 17510
    },
    {
      "epoch": 1.4950081064937282,
      "grad_norm": 0.2002386897802353,
      "learning_rate": 3.504991893506272e-05,
      "loss": 0.0026,
      "step": 17520
    },
    {
      "epoch": 1.4958614216230055,
      "grad_norm": 0.31688687205314636,
      "learning_rate": 3.5041385783769946e-05,
      "loss": 0.0026,
      "step": 17530
    },
    {
      "epoch": 1.4967147367522826,
      "grad_norm": 0.10185899585485458,
      "learning_rate": 3.5032852632477174e-05,
      "loss": 0.0031,
      "step": 17540
    },
    {
      "epoch": 1.4975680518815597,
      "grad_norm": 0.2883843183517456,
      "learning_rate": 3.50243194811844e-05,
      "loss": 0.0028,
      "step": 17550
    },
    {
      "epoch": 1.498421367010837,
      "grad_norm": 0.22337286174297333,
      "learning_rate": 3.501578632989163e-05,
      "loss": 0.0033,
      "step": 17560
    },
    {
      "epoch": 1.4992746821401144,
      "grad_norm": 0.06478379666805267,
      "learning_rate": 3.500725317859886e-05,
      "loss": 0.003,
      "step": 17570
    },
    {
      "epoch": 1.5001279972693915,
      "grad_norm": 0.11945157498121262,
      "learning_rate": 3.499872002730609e-05,
      "loss": 0.0032,
      "step": 17580
    },
    {
      "epoch": 1.5009813123986688,
      "grad_norm": 0.1696096509695053,
      "learning_rate": 3.4990186876013316e-05,
      "loss": 0.0025,
      "step": 17590
    },
    {
      "epoch": 1.5018346275279462,
      "grad_norm": 0.33926403522491455,
      "learning_rate": 3.4981653724720545e-05,
      "loss": 0.0032,
      "step": 17600
    },
    {
      "epoch": 1.5026879426572233,
      "grad_norm": 0.17090581357479095,
      "learning_rate": 3.4973120573427773e-05,
      "loss": 0.0027,
      "step": 17610
    },
    {
      "epoch": 1.5035412577865006,
      "grad_norm": 0.449001669883728,
      "learning_rate": 3.4964587422134995e-05,
      "loss": 0.003,
      "step": 17620
    },
    {
      "epoch": 1.504394572915778,
      "grad_norm": 0.4980100691318512,
      "learning_rate": 3.4956054270842224e-05,
      "loss": 0.0026,
      "step": 17630
    },
    {
      "epoch": 1.505247888045055,
      "grad_norm": 0.11878158897161484,
      "learning_rate": 3.494752111954945e-05,
      "loss": 0.0023,
      "step": 17640
    },
    {
      "epoch": 1.5061012031743322,
      "grad_norm": 0.3015371561050415,
      "learning_rate": 3.493898796825668e-05,
      "loss": 0.0026,
      "step": 17650
    },
    {
      "epoch": 1.5069545183036095,
      "grad_norm": 0.0953449010848999,
      "learning_rate": 3.493045481696391e-05,
      "loss": 0.0025,
      "step": 17660
    },
    {
      "epoch": 1.5078078334328868,
      "grad_norm": 0.35956403613090515,
      "learning_rate": 3.492192166567114e-05,
      "loss": 0.0029,
      "step": 17670
    },
    {
      "epoch": 1.508661148562164,
      "grad_norm": 0.40955978631973267,
      "learning_rate": 3.491338851437836e-05,
      "loss": 0.0027,
      "step": 17680
    },
    {
      "epoch": 1.5095144636914413,
      "grad_norm": 0.359833300113678,
      "learning_rate": 3.490485536308559e-05,
      "loss": 0.0028,
      "step": 17690
    },
    {
      "epoch": 1.5103677788207186,
      "grad_norm": 0.21882446110248566,
      "learning_rate": 3.4896322211792816e-05,
      "loss": 0.0027,
      "step": 17700
    },
    {
      "epoch": 1.5112210939499957,
      "grad_norm": 0.27900347113609314,
      "learning_rate": 3.4887789060500045e-05,
      "loss": 0.0033,
      "step": 17710
    },
    {
      "epoch": 1.5120744090792728,
      "grad_norm": 0.41786566376686096,
      "learning_rate": 3.487925590920727e-05,
      "loss": 0.003,
      "step": 17720
    },
    {
      "epoch": 1.5129277242085504,
      "grad_norm": 0.14351022243499756,
      "learning_rate": 3.4870722757914495e-05,
      "loss": 0.0037,
      "step": 17730
    },
    {
      "epoch": 1.5137810393378275,
      "grad_norm": 0.4816267490386963,
      "learning_rate": 3.486218960662172e-05,
      "loss": 0.0024,
      "step": 17740
    },
    {
      "epoch": 1.5146343544671046,
      "grad_norm": 0.21327196061611176,
      "learning_rate": 3.485365645532895e-05,
      "loss": 0.003,
      "step": 17750
    },
    {
      "epoch": 1.515487669596382,
      "grad_norm": 0.16323354840278625,
      "learning_rate": 3.484512330403618e-05,
      "loss": 0.0025,
      "step": 17760
    },
    {
      "epoch": 1.5163409847256593,
      "grad_norm": 0.21346515417099,
      "learning_rate": 3.483659015274341e-05,
      "loss": 0.0024,
      "step": 17770
    },
    {
      "epoch": 1.5171942998549364,
      "grad_norm": 0.7879459261894226,
      "learning_rate": 3.482805700145064e-05,
      "loss": 0.0022,
      "step": 17780
    },
    {
      "epoch": 1.5180476149842137,
      "grad_norm": 0.12641772627830505,
      "learning_rate": 3.4819523850157866e-05,
      "loss": 0.0026,
      "step": 17790
    },
    {
      "epoch": 1.518900930113491,
      "grad_norm": 0.40924590826034546,
      "learning_rate": 3.4810990698865094e-05,
      "loss": 0.0028,
      "step": 17800
    },
    {
      "epoch": 1.5197542452427681,
      "grad_norm": 0.10222689062356949,
      "learning_rate": 3.480245754757232e-05,
      "loss": 0.003,
      "step": 17810
    },
    {
      "epoch": 1.5206075603720453,
      "grad_norm": 0.05221274122595787,
      "learning_rate": 3.479392439627955e-05,
      "loss": 0.0027,
      "step": 17820
    },
    {
      "epoch": 1.5214608755013226,
      "grad_norm": 0.06498154997825623,
      "learning_rate": 3.478539124498677e-05,
      "loss": 0.0028,
      "step": 17830
    },
    {
      "epoch": 1.5223141906306,
      "grad_norm": 0.5094783306121826,
      "learning_rate": 3.4776858093694e-05,
      "loss": 0.0026,
      "step": 17840
    },
    {
      "epoch": 1.523167505759877,
      "grad_norm": 0.13546337187290192,
      "learning_rate": 3.476832494240123e-05,
      "loss": 0.003,
      "step": 17850
    },
    {
      "epoch": 1.5240208208891544,
      "grad_norm": 0.2922300696372986,
      "learning_rate": 3.475979179110846e-05,
      "loss": 0.0026,
      "step": 17860
    },
    {
      "epoch": 1.5248741360184317,
      "grad_norm": 0.1608075648546219,
      "learning_rate": 3.475125863981569e-05,
      "loss": 0.0023,
      "step": 17870
    },
    {
      "epoch": 1.5257274511477088,
      "grad_norm": 0.1412443071603775,
      "learning_rate": 3.4742725488522915e-05,
      "loss": 0.0024,
      "step": 17880
    },
    {
      "epoch": 1.5265807662769861,
      "grad_norm": 0.1058589369058609,
      "learning_rate": 3.4734192337230144e-05,
      "loss": 0.0022,
      "step": 17890
    },
    {
      "epoch": 1.5274340814062635,
      "grad_norm": 0.2518582046031952,
      "learning_rate": 3.472565918593737e-05,
      "loss": 0.0028,
      "step": 17900
    },
    {
      "epoch": 1.5282873965355406,
      "grad_norm": 0.1742643415927887,
      "learning_rate": 3.47171260346446e-05,
      "loss": 0.0029,
      "step": 17910
    },
    {
      "epoch": 1.5291407116648177,
      "grad_norm": 0.08512232452630997,
      "learning_rate": 3.470859288335183e-05,
      "loss": 0.0028,
      "step": 17920
    },
    {
      "epoch": 1.529994026794095,
      "grad_norm": 0.13965269923210144,
      "learning_rate": 3.470005973205905e-05,
      "loss": 0.0032,
      "step": 17930
    },
    {
      "epoch": 1.5308473419233724,
      "grad_norm": 0.19501380622386932,
      "learning_rate": 3.469152658076627e-05,
      "loss": 0.0022,
      "step": 17940
    },
    {
      "epoch": 1.5317006570526495,
      "grad_norm": 0.18177731335163116,
      "learning_rate": 3.46829934294735e-05,
      "loss": 0.003,
      "step": 17950
    },
    {
      "epoch": 1.5325539721819268,
      "grad_norm": 0.1229557916522026,
      "learning_rate": 3.467446027818073e-05,
      "loss": 0.0025,
      "step": 17960
    },
    {
      "epoch": 1.5334072873112041,
      "grad_norm": 0.17120681703090668,
      "learning_rate": 3.466592712688796e-05,
      "loss": 0.0031,
      "step": 17970
    },
    {
      "epoch": 1.5342606024404812,
      "grad_norm": 0.36558493971824646,
      "learning_rate": 3.4657393975595187e-05,
      "loss": 0.0032,
      "step": 17980
    },
    {
      "epoch": 1.5351139175697583,
      "grad_norm": 0.19543518126010895,
      "learning_rate": 3.4648860824302415e-05,
      "loss": 0.0027,
      "step": 17990
    },
    {
      "epoch": 1.535967232699036,
      "grad_norm": 0.340049684047699,
      "learning_rate": 3.4640327673009644e-05,
      "loss": 0.0027,
      "step": 18000
    },
    {
      "epoch": 1.536820547828313,
      "grad_norm": 0.2334708571434021,
      "learning_rate": 3.463179452171687e-05,
      "loss": 0.0025,
      "step": 18010
    },
    {
      "epoch": 1.5376738629575901,
      "grad_norm": 0.08937010914087296,
      "learning_rate": 3.46232613704241e-05,
      "loss": 0.0026,
      "step": 18020
    },
    {
      "epoch": 1.5385271780868675,
      "grad_norm": 0.07074588537216187,
      "learning_rate": 3.461472821913133e-05,
      "loss": 0.0022,
      "step": 18030
    },
    {
      "epoch": 1.5393804932161448,
      "grad_norm": 0.3462737500667572,
      "learning_rate": 3.460619506783855e-05,
      "loss": 0.0026,
      "step": 18040
    },
    {
      "epoch": 1.540233808345422,
      "grad_norm": 0.056056175380945206,
      "learning_rate": 3.459766191654578e-05,
      "loss": 0.0032,
      "step": 18050
    },
    {
      "epoch": 1.5410871234746992,
      "grad_norm": 0.22106049954891205,
      "learning_rate": 3.458912876525301e-05,
      "loss": 0.0027,
      "step": 18060
    },
    {
      "epoch": 1.5419404386039766,
      "grad_norm": 0.22929434478282928,
      "learning_rate": 3.4580595613960236e-05,
      "loss": 0.0025,
      "step": 18070
    },
    {
      "epoch": 1.5427937537332537,
      "grad_norm": 0.12919636070728302,
      "learning_rate": 3.4572062462667465e-05,
      "loss": 0.0022,
      "step": 18080
    },
    {
      "epoch": 1.5436470688625308,
      "grad_norm": 0.27701592445373535,
      "learning_rate": 3.456352931137469e-05,
      "loss": 0.0026,
      "step": 18090
    },
    {
      "epoch": 1.5445003839918083,
      "grad_norm": 0.07667474448680878,
      "learning_rate": 3.455499616008192e-05,
      "loss": 0.003,
      "step": 18100
    },
    {
      "epoch": 1.5453536991210854,
      "grad_norm": 0.1532278209924698,
      "learning_rate": 3.454646300878915e-05,
      "loss": 0.0029,
      "step": 18110
    },
    {
      "epoch": 1.5462070142503626,
      "grad_norm": 0.05299258232116699,
      "learning_rate": 3.453792985749638e-05,
      "loss": 0.0025,
      "step": 18120
    },
    {
      "epoch": 1.5470603293796399,
      "grad_norm": 0.042204998433589935,
      "learning_rate": 3.452939670620361e-05,
      "loss": 0.0026,
      "step": 18130
    },
    {
      "epoch": 1.5479136445089172,
      "grad_norm": 0.03188445419073105,
      "learning_rate": 3.452086355491083e-05,
      "loss": 0.0033,
      "step": 18140
    },
    {
      "epoch": 1.5487669596381943,
      "grad_norm": 0.4293272793292999,
      "learning_rate": 3.451233040361806e-05,
      "loss": 0.0026,
      "step": 18150
    },
    {
      "epoch": 1.5496202747674717,
      "grad_norm": 0.14029991626739502,
      "learning_rate": 3.4503797252325286e-05,
      "loss": 0.0037,
      "step": 18160
    },
    {
      "epoch": 1.550473589896749,
      "grad_norm": 0.4019988477230072,
      "learning_rate": 3.4495264101032514e-05,
      "loss": 0.0024,
      "step": 18170
    },
    {
      "epoch": 1.551326905026026,
      "grad_norm": 0.18048414587974548,
      "learning_rate": 3.448673094973974e-05,
      "loss": 0.0021,
      "step": 18180
    },
    {
      "epoch": 1.5521802201553032,
      "grad_norm": 0.18085996806621552,
      "learning_rate": 3.447819779844697e-05,
      "loss": 0.0024,
      "step": 18190
    },
    {
      "epoch": 1.5530335352845805,
      "grad_norm": 0.12793809175491333,
      "learning_rate": 3.44696646471542e-05,
      "loss": 0.0021,
      "step": 18200
    },
    {
      "epoch": 1.5538868504138579,
      "grad_norm": 0.03480512648820877,
      "learning_rate": 3.446113149586142e-05,
      "loss": 0.0029,
      "step": 18210
    },
    {
      "epoch": 1.554740165543135,
      "grad_norm": 0.2187715619802475,
      "learning_rate": 3.445259834456865e-05,
      "loss": 0.0019,
      "step": 18220
    },
    {
      "epoch": 1.5555934806724123,
      "grad_norm": 0.3005541265010834,
      "learning_rate": 3.444406519327588e-05,
      "loss": 0.0027,
      "step": 18230
    },
    {
      "epoch": 1.5564467958016897,
      "grad_norm": 0.24579675495624542,
      "learning_rate": 3.443553204198311e-05,
      "loss": 0.0027,
      "step": 18240
    },
    {
      "epoch": 1.5573001109309668,
      "grad_norm": 0.48797711730003357,
      "learning_rate": 3.442699889069033e-05,
      "loss": 0.0029,
      "step": 18250
    },
    {
      "epoch": 1.558153426060244,
      "grad_norm": 0.12656506896018982,
      "learning_rate": 3.441846573939756e-05,
      "loss": 0.0028,
      "step": 18260
    },
    {
      "epoch": 1.5590067411895214,
      "grad_norm": 0.15364138782024384,
      "learning_rate": 3.4409932588104785e-05,
      "loss": 0.0028,
      "step": 18270
    },
    {
      "epoch": 1.5598600563187985,
      "grad_norm": 0.1339520812034607,
      "learning_rate": 3.4401399436812014e-05,
      "loss": 0.0022,
      "step": 18280
    },
    {
      "epoch": 1.5607133714480756,
      "grad_norm": 0.421529084444046,
      "learning_rate": 3.439286628551924e-05,
      "loss": 0.0029,
      "step": 18290
    },
    {
      "epoch": 1.561566686577353,
      "grad_norm": 0.6088448166847229,
      "learning_rate": 3.438433313422647e-05,
      "loss": 0.0021,
      "step": 18300
    },
    {
      "epoch": 1.5624200017066303,
      "grad_norm": 0.44971999526023865,
      "learning_rate": 3.43757999829337e-05,
      "loss": 0.0022,
      "step": 18310
    },
    {
      "epoch": 1.5632733168359074,
      "grad_norm": 0.10596675425767899,
      "learning_rate": 3.436726683164093e-05,
      "loss": 0.0033,
      "step": 18320
    },
    {
      "epoch": 1.5641266319651848,
      "grad_norm": 0.2849124073982239,
      "learning_rate": 3.4358733680348156e-05,
      "loss": 0.0038,
      "step": 18330
    },
    {
      "epoch": 1.564979947094462,
      "grad_norm": 0.22811003029346466,
      "learning_rate": 3.4350200529055385e-05,
      "loss": 0.0032,
      "step": 18340
    },
    {
      "epoch": 1.5658332622237392,
      "grad_norm": 0.1267573982477188,
      "learning_rate": 3.4341667377762607e-05,
      "loss": 0.0026,
      "step": 18350
    },
    {
      "epoch": 1.5666865773530163,
      "grad_norm": 0.1707814782857895,
      "learning_rate": 3.4333134226469835e-05,
      "loss": 0.0027,
      "step": 18360
    },
    {
      "epoch": 1.5675398924822939,
      "grad_norm": 0.17005300521850586,
      "learning_rate": 3.4324601075177064e-05,
      "loss": 0.0034,
      "step": 18370
    },
    {
      "epoch": 1.568393207611571,
      "grad_norm": 0.17797334492206573,
      "learning_rate": 3.431606792388429e-05,
      "loss": 0.0031,
      "step": 18380
    },
    {
      "epoch": 1.569246522740848,
      "grad_norm": 0.09952604025602341,
      "learning_rate": 3.430753477259152e-05,
      "loss": 0.0026,
      "step": 18390
    },
    {
      "epoch": 1.5700998378701254,
      "grad_norm": 0.10376889258623123,
      "learning_rate": 3.429900162129875e-05,
      "loss": 0.0021,
      "step": 18400
    },
    {
      "epoch": 1.5709531529994027,
      "grad_norm": 0.15550604462623596,
      "learning_rate": 3.429046847000598e-05,
      "loss": 0.0023,
      "step": 18410
    },
    {
      "epoch": 1.5718064681286799,
      "grad_norm": 0.06473345309495926,
      "learning_rate": 3.4281935318713206e-05,
      "loss": 0.0024,
      "step": 18420
    },
    {
      "epoch": 1.5726597832579572,
      "grad_norm": 0.07332873344421387,
      "learning_rate": 3.4273402167420434e-05,
      "loss": 0.003,
      "step": 18430
    },
    {
      "epoch": 1.5735130983872345,
      "grad_norm": 0.446262001991272,
      "learning_rate": 3.426486901612766e-05,
      "loss": 0.002,
      "step": 18440
    },
    {
      "epoch": 1.5743664135165116,
      "grad_norm": 0.07247616350650787,
      "learning_rate": 3.4256335864834885e-05,
      "loss": 0.0026,
      "step": 18450
    },
    {
      "epoch": 1.5752197286457887,
      "grad_norm": 0.3711763024330139,
      "learning_rate": 3.424780271354211e-05,
      "loss": 0.0024,
      "step": 18460
    },
    {
      "epoch": 1.5760730437750663,
      "grad_norm": 0.3179957866668701,
      "learning_rate": 3.4239269562249335e-05,
      "loss": 0.0029,
      "step": 18470
    },
    {
      "epoch": 1.5769263589043434,
      "grad_norm": 0.502937912940979,
      "learning_rate": 3.423073641095656e-05,
      "loss": 0.003,
      "step": 18480
    },
    {
      "epoch": 1.5777796740336205,
      "grad_norm": 0.19283093512058258,
      "learning_rate": 3.422220325966379e-05,
      "loss": 0.0028,
      "step": 18490
    },
    {
      "epoch": 1.5786329891628978,
      "grad_norm": 0.06332878768444061,
      "learning_rate": 3.421367010837102e-05,
      "loss": 0.003,
      "step": 18500
    },
    {
      "epoch": 1.5794863042921752,
      "grad_norm": 0.09904337674379349,
      "learning_rate": 3.420513695707825e-05,
      "loss": 0.004,
      "step": 18510
    },
    {
      "epoch": 1.5803396194214523,
      "grad_norm": 0.05602354183793068,
      "learning_rate": 3.419660380578548e-05,
      "loss": 0.0027,
      "step": 18520
    },
    {
      "epoch": 1.5811929345507296,
      "grad_norm": 0.32899558544158936,
      "learning_rate": 3.4188070654492706e-05,
      "loss": 0.0025,
      "step": 18530
    },
    {
      "epoch": 1.582046249680007,
      "grad_norm": 0.17171616852283478,
      "learning_rate": 3.4179537503199934e-05,
      "loss": 0.0026,
      "step": 18540
    },
    {
      "epoch": 1.582899564809284,
      "grad_norm": 0.08890605717897415,
      "learning_rate": 3.417100435190716e-05,
      "loss": 0.0027,
      "step": 18550
    },
    {
      "epoch": 1.5837528799385612,
      "grad_norm": 0.3753800094127655,
      "learning_rate": 3.4162471200614384e-05,
      "loss": 0.0035,
      "step": 18560
    },
    {
      "epoch": 1.5846061950678385,
      "grad_norm": 0.26969340443611145,
      "learning_rate": 3.415393804932161e-05,
      "loss": 0.0029,
      "step": 18570
    },
    {
      "epoch": 1.5854595101971158,
      "grad_norm": 0.08520599454641342,
      "learning_rate": 3.414540489802884e-05,
      "loss": 0.0024,
      "step": 18580
    },
    {
      "epoch": 1.586312825326393,
      "grad_norm": 0.1644812375307083,
      "learning_rate": 3.413687174673607e-05,
      "loss": 0.0024,
      "step": 18590
    },
    {
      "epoch": 1.5871661404556703,
      "grad_norm": 0.1382025182247162,
      "learning_rate": 3.41283385954433e-05,
      "loss": 0.0033,
      "step": 18600
    },
    {
      "epoch": 1.5880194555849476,
      "grad_norm": 0.22127367556095123,
      "learning_rate": 3.411980544415053e-05,
      "loss": 0.0018,
      "step": 18610
    },
    {
      "epoch": 1.5888727707142247,
      "grad_norm": 0.10516788810491562,
      "learning_rate": 3.4111272292857755e-05,
      "loss": 0.0031,
      "step": 18620
    },
    {
      "epoch": 1.589726085843502,
      "grad_norm": 0.2644321620464325,
      "learning_rate": 3.4102739141564984e-05,
      "loss": 0.003,
      "step": 18630
    },
    {
      "epoch": 1.5905794009727794,
      "grad_norm": 0.08247119188308716,
      "learning_rate": 3.409420599027221e-05,
      "loss": 0.002,
      "step": 18640
    },
    {
      "epoch": 1.5914327161020565,
      "grad_norm": 0.37059107422828674,
      "learning_rate": 3.408567283897944e-05,
      "loss": 0.0026,
      "step": 18650
    },
    {
      "epoch": 1.5922860312313336,
      "grad_norm": 0.2565113604068756,
      "learning_rate": 3.407713968768666e-05,
      "loss": 0.0032,
      "step": 18660
    },
    {
      "epoch": 1.593139346360611,
      "grad_norm": 0.42134690284729004,
      "learning_rate": 3.406860653639389e-05,
      "loss": 0.0018,
      "step": 18670
    },
    {
      "epoch": 1.5939926614898883,
      "grad_norm": 0.22481125593185425,
      "learning_rate": 3.406007338510112e-05,
      "loss": 0.0033,
      "step": 18680
    },
    {
      "epoch": 1.5948459766191654,
      "grad_norm": 0.7062350511550903,
      "learning_rate": 3.405154023380835e-05,
      "loss": 0.0029,
      "step": 18690
    },
    {
      "epoch": 1.5956992917484427,
      "grad_norm": 0.681071400642395,
      "learning_rate": 3.4043007082515576e-05,
      "loss": 0.0027,
      "step": 18700
    },
    {
      "epoch": 1.59655260687772,
      "grad_norm": 0.4262010455131531,
      "learning_rate": 3.4034473931222805e-05,
      "loss": 0.0024,
      "step": 18710
    },
    {
      "epoch": 1.5974059220069972,
      "grad_norm": 0.12316281348466873,
      "learning_rate": 3.402594077993003e-05,
      "loss": 0.0022,
      "step": 18720
    },
    {
      "epoch": 1.5982592371362743,
      "grad_norm": 0.17273151874542236,
      "learning_rate": 3.401740762863726e-05,
      "loss": 0.0026,
      "step": 18730
    },
    {
      "epoch": 1.5991125522655518,
      "grad_norm": 0.2151031345129013,
      "learning_rate": 3.4008874477344483e-05,
      "loss": 0.0029,
      "step": 18740
    },
    {
      "epoch": 1.599965867394829,
      "grad_norm": 0.16274096071720123,
      "learning_rate": 3.400034132605171e-05,
      "loss": 0.0027,
      "step": 18750
    },
    {
      "epoch": 1.600819182524106,
      "grad_norm": 0.07323119044303894,
      "learning_rate": 3.399180817475894e-05,
      "loss": 0.0026,
      "step": 18760
    },
    {
      "epoch": 1.6016724976533834,
      "grad_norm": 0.06184389814734459,
      "learning_rate": 3.398327502346617e-05,
      "loss": 0.003,
      "step": 18770
    },
    {
      "epoch": 1.6025258127826607,
      "grad_norm": 0.05530568212270737,
      "learning_rate": 3.397474187217339e-05,
      "loss": 0.0029,
      "step": 18780
    },
    {
      "epoch": 1.6033791279119378,
      "grad_norm": 0.07063069939613342,
      "learning_rate": 3.396620872088062e-05,
      "loss": 0.0025,
      "step": 18790
    },
    {
      "epoch": 1.6042324430412152,
      "grad_norm": 0.0818590372800827,
      "learning_rate": 3.395767556958785e-05,
      "loss": 0.003,
      "step": 18800
    },
    {
      "epoch": 1.6050857581704925,
      "grad_norm": 0.099391870200634,
      "learning_rate": 3.3949142418295076e-05,
      "loss": 0.0022,
      "step": 18810
    },
    {
      "epoch": 1.6059390732997696,
      "grad_norm": 0.23838479816913605,
      "learning_rate": 3.3940609267002305e-05,
      "loss": 0.0028,
      "step": 18820
    },
    {
      "epoch": 1.6067923884290467,
      "grad_norm": 0.2010735720396042,
      "learning_rate": 3.393207611570953e-05,
      "loss": 0.002,
      "step": 18830
    },
    {
      "epoch": 1.607645703558324,
      "grad_norm": 0.057067785412073135,
      "learning_rate": 3.392354296441676e-05,
      "loss": 0.0026,
      "step": 18840
    },
    {
      "epoch": 1.6084990186876014,
      "grad_norm": 0.0206005796790123,
      "learning_rate": 3.391500981312399e-05,
      "loss": 0.0026,
      "step": 18850
    },
    {
      "epoch": 1.6093523338168785,
      "grad_norm": 0.31400009989738464,
      "learning_rate": 3.390647666183122e-05,
      "loss": 0.0025,
      "step": 18860
    },
    {
      "epoch": 1.6102056489461558,
      "grad_norm": 0.029812250286340714,
      "learning_rate": 3.389794351053844e-05,
      "loss": 0.0028,
      "step": 18870
    },
    {
      "epoch": 1.6110589640754331,
      "grad_norm": 0.3969697952270508,
      "learning_rate": 3.388941035924567e-05,
      "loss": 0.0031,
      "step": 18880
    },
    {
      "epoch": 1.6119122792047103,
      "grad_norm": 0.04534108564257622,
      "learning_rate": 3.38808772079529e-05,
      "loss": 0.0024,
      "step": 18890
    },
    {
      "epoch": 1.6127655943339876,
      "grad_norm": 0.7704368233680725,
      "learning_rate": 3.3872344056660126e-05,
      "loss": 0.0029,
      "step": 18900
    },
    {
      "epoch": 1.613618909463265,
      "grad_norm": 0.5010420083999634,
      "learning_rate": 3.3863810905367354e-05,
      "loss": 0.0022,
      "step": 18910
    },
    {
      "epoch": 1.614472224592542,
      "grad_norm": 0.5191513299942017,
      "learning_rate": 3.385527775407458e-05,
      "loss": 0.0031,
      "step": 18920
    },
    {
      "epoch": 1.6153255397218191,
      "grad_norm": 0.17351648211479187,
      "learning_rate": 3.384674460278181e-05,
      "loss": 0.0027,
      "step": 18930
    },
    {
      "epoch": 1.6161788548510965,
      "grad_norm": 0.07338264584541321,
      "learning_rate": 3.383821145148904e-05,
      "loss": 0.0025,
      "step": 18940
    },
    {
      "epoch": 1.6170321699803738,
      "grad_norm": 0.2733106315135956,
      "learning_rate": 3.382967830019627e-05,
      "loss": 0.0031,
      "step": 18950
    },
    {
      "epoch": 1.617885485109651,
      "grad_norm": 0.06295725703239441,
      "learning_rate": 3.3821145148903497e-05,
      "loss": 0.0026,
      "step": 18960
    },
    {
      "epoch": 1.6187388002389282,
      "grad_norm": 0.18113288283348083,
      "learning_rate": 3.381261199761072e-05,
      "loss": 0.0031,
      "step": 18970
    },
    {
      "epoch": 1.6195921153682056,
      "grad_norm": 0.39679691195487976,
      "learning_rate": 3.380407884631795e-05,
      "loss": 0.0038,
      "step": 18980
    },
    {
      "epoch": 1.6204454304974827,
      "grad_norm": 0.13780435919761658,
      "learning_rate": 3.3795545695025175e-05,
      "loss": 0.0027,
      "step": 18990
    },
    {
      "epoch": 1.6212987456267598,
      "grad_norm": 0.09340669214725494,
      "learning_rate": 3.3787012543732404e-05,
      "loss": 0.0022,
      "step": 19000
    },
    {
      "epoch": 1.6221520607560374,
      "grad_norm": 0.0856153815984726,
      "learning_rate": 3.3778479392439625e-05,
      "loss": 0.0024,
      "step": 19010
    },
    {
      "epoch": 1.6230053758853145,
      "grad_norm": 0.21096515655517578,
      "learning_rate": 3.3769946241146854e-05,
      "loss": 0.0028,
      "step": 19020
    },
    {
      "epoch": 1.6238586910145916,
      "grad_norm": 0.23075522482395172,
      "learning_rate": 3.376141308985408e-05,
      "loss": 0.0027,
      "step": 19030
    },
    {
      "epoch": 1.624712006143869,
      "grad_norm": 0.15449240803718567,
      "learning_rate": 3.375287993856131e-05,
      "loss": 0.0027,
      "step": 19040
    },
    {
      "epoch": 1.6255653212731462,
      "grad_norm": 0.4008585214614868,
      "learning_rate": 3.374434678726854e-05,
      "loss": 0.0023,
      "step": 19050
    },
    {
      "epoch": 1.6264186364024233,
      "grad_norm": 0.3953748941421509,
      "learning_rate": 3.373581363597577e-05,
      "loss": 0.0029,
      "step": 19060
    },
    {
      "epoch": 1.6272719515317007,
      "grad_norm": 0.14714932441711426,
      "learning_rate": 3.3727280484682996e-05,
      "loss": 0.0029,
      "step": 19070
    },
    {
      "epoch": 1.628125266660978,
      "grad_norm": 0.11046304553747177,
      "learning_rate": 3.3718747333390225e-05,
      "loss": 0.0029,
      "step": 19080
    },
    {
      "epoch": 1.6289785817902551,
      "grad_norm": 0.4888201951980591,
      "learning_rate": 3.3710214182097446e-05,
      "loss": 0.0036,
      "step": 19090
    },
    {
      "epoch": 1.6298318969195322,
      "grad_norm": 0.29114800691604614,
      "learning_rate": 3.3701681030804675e-05,
      "loss": 0.0028,
      "step": 19100
    },
    {
      "epoch": 1.6306852120488098,
      "grad_norm": 0.3886828124523163,
      "learning_rate": 3.3693147879511903e-05,
      "loss": 0.0026,
      "step": 19110
    },
    {
      "epoch": 1.631538527178087,
      "grad_norm": 0.24180039763450623,
      "learning_rate": 3.368461472821913e-05,
      "loss": 0.0024,
      "step": 19120
    },
    {
      "epoch": 1.632391842307364,
      "grad_norm": 0.2955448627471924,
      "learning_rate": 3.367608157692636e-05,
      "loss": 0.0029,
      "step": 19130
    },
    {
      "epoch": 1.6332451574366413,
      "grad_norm": 0.16320720314979553,
      "learning_rate": 3.366754842563359e-05,
      "loss": 0.0033,
      "step": 19140
    },
    {
      "epoch": 1.6340984725659187,
      "grad_norm": 0.17938309907913208,
      "learning_rate": 3.365901527434082e-05,
      "loss": 0.002,
      "step": 19150
    },
    {
      "epoch": 1.6349517876951958,
      "grad_norm": 0.3710870146751404,
      "learning_rate": 3.3650482123048046e-05,
      "loss": 0.0031,
      "step": 19160
    },
    {
      "epoch": 1.6358051028244731,
      "grad_norm": 0.11901070177555084,
      "learning_rate": 3.3641948971755274e-05,
      "loss": 0.0028,
      "step": 19170
    },
    {
      "epoch": 1.6366584179537504,
      "grad_norm": 0.4376000165939331,
      "learning_rate": 3.3633415820462496e-05,
      "loss": 0.0023,
      "step": 19180
    },
    {
      "epoch": 1.6375117330830276,
      "grad_norm": 0.3627465069293976,
      "learning_rate": 3.3624882669169724e-05,
      "loss": 0.0029,
      "step": 19190
    },
    {
      "epoch": 1.6383650482123047,
      "grad_norm": 0.26458844542503357,
      "learning_rate": 3.361634951787695e-05,
      "loss": 0.002,
      "step": 19200
    },
    {
      "epoch": 1.639218363341582,
      "grad_norm": 0.23594582080841064,
      "learning_rate": 3.360781636658418e-05,
      "loss": 0.0025,
      "step": 19210
    },
    {
      "epoch": 1.6400716784708593,
      "grad_norm": 0.17534463107585907,
      "learning_rate": 3.359928321529141e-05,
      "loss": 0.0027,
      "step": 19220
    },
    {
      "epoch": 1.6409249936001364,
      "grad_norm": 0.16268765926361084,
      "learning_rate": 3.359075006399864e-05,
      "loss": 0.0025,
      "step": 19230
    },
    {
      "epoch": 1.6417783087294138,
      "grad_norm": 0.08603708446025848,
      "learning_rate": 3.358221691270587e-05,
      "loss": 0.0026,
      "step": 19240
    },
    {
      "epoch": 1.642631623858691,
      "grad_norm": 0.37273353338241577,
      "learning_rate": 3.3573683761413095e-05,
      "loss": 0.0025,
      "step": 19250
    },
    {
      "epoch": 1.6434849389879682,
      "grad_norm": 0.4043944776058197,
      "learning_rate": 3.3565150610120324e-05,
      "loss": 0.0029,
      "step": 19260
    },
    {
      "epoch": 1.6443382541172455,
      "grad_norm": 0.3083491623401642,
      "learning_rate": 3.3556617458827546e-05,
      "loss": 0.0033,
      "step": 19270
    },
    {
      "epoch": 1.6451915692465229,
      "grad_norm": 0.27128615975379944,
      "learning_rate": 3.3548084307534774e-05,
      "loss": 0.0023,
      "step": 19280
    },
    {
      "epoch": 1.6460448843758,
      "grad_norm": 0.34718796610832214,
      "learning_rate": 3.3539551156242e-05,
      "loss": 0.0023,
      "step": 19290
    },
    {
      "epoch": 1.646898199505077,
      "grad_norm": 0.1458180695772171,
      "learning_rate": 3.3531018004949224e-05,
      "loss": 0.0043,
      "step": 19300
    },
    {
      "epoch": 1.6477515146343544,
      "grad_norm": 0.29907700419425964,
      "learning_rate": 3.352248485365645e-05,
      "loss": 0.0032,
      "step": 19310
    },
    {
      "epoch": 1.6486048297636318,
      "grad_norm": 0.3213030993938446,
      "learning_rate": 3.351395170236368e-05,
      "loss": 0.0032,
      "step": 19320
    },
    {
      "epoch": 1.6494581448929089,
      "grad_norm": 0.5920148491859436,
      "learning_rate": 3.350541855107091e-05,
      "loss": 0.0033,
      "step": 19330
    },
    {
      "epoch": 1.6503114600221862,
      "grad_norm": 0.08369138091802597,
      "learning_rate": 3.349688539977814e-05,
      "loss": 0.0038,
      "step": 19340
    },
    {
      "epoch": 1.6511647751514635,
      "grad_norm": 0.03723372519016266,
      "learning_rate": 3.348835224848537e-05,
      "loss": 0.0029,
      "step": 19350
    },
    {
      "epoch": 1.6520180902807406,
      "grad_norm": 0.2518247961997986,
      "learning_rate": 3.3479819097192595e-05,
      "loss": 0.0023,
      "step": 19360
    },
    {
      "epoch": 1.6528714054100178,
      "grad_norm": 0.053567156195640564,
      "learning_rate": 3.3471285945899824e-05,
      "loss": 0.0029,
      "step": 19370
    },
    {
      "epoch": 1.6537247205392953,
      "grad_norm": 0.18259786069393158,
      "learning_rate": 3.346275279460705e-05,
      "loss": 0.0034,
      "step": 19380
    },
    {
      "epoch": 1.6545780356685724,
      "grad_norm": 0.07303701341152191,
      "learning_rate": 3.345421964331428e-05,
      "loss": 0.0023,
      "step": 19390
    },
    {
      "epoch": 1.6554313507978495,
      "grad_norm": 0.07851465791463852,
      "learning_rate": 3.34456864920215e-05,
      "loss": 0.0028,
      "step": 19400
    },
    {
      "epoch": 1.6562846659271269,
      "grad_norm": 0.2880931496620178,
      "learning_rate": 3.343715334072873e-05,
      "loss": 0.003,
      "step": 19410
    },
    {
      "epoch": 1.6571379810564042,
      "grad_norm": 0.0630408525466919,
      "learning_rate": 3.342862018943596e-05,
      "loss": 0.0025,
      "step": 19420
    },
    {
      "epoch": 1.6579912961856813,
      "grad_norm": 0.03626642003655434,
      "learning_rate": 3.342008703814319e-05,
      "loss": 0.0025,
      "step": 19430
    },
    {
      "epoch": 1.6588446113149586,
      "grad_norm": 0.127585306763649,
      "learning_rate": 3.3411553886850416e-05,
      "loss": 0.0033,
      "step": 19440
    },
    {
      "epoch": 1.659697926444236,
      "grad_norm": 0.16799190640449524,
      "learning_rate": 3.3403020735557645e-05,
      "loss": 0.0035,
      "step": 19450
    },
    {
      "epoch": 1.660551241573513,
      "grad_norm": 0.16101984679698944,
      "learning_rate": 3.339448758426487e-05,
      "loss": 0.0028,
      "step": 19460
    },
    {
      "epoch": 1.6614045567027902,
      "grad_norm": 0.4700371325016022,
      "learning_rate": 3.33859544329721e-05,
      "loss": 0.0028,
      "step": 19470
    },
    {
      "epoch": 1.6622578718320677,
      "grad_norm": 0.2946777939796448,
      "learning_rate": 3.337742128167933e-05,
      "loss": 0.003,
      "step": 19480
    },
    {
      "epoch": 1.6631111869613449,
      "grad_norm": 0.26970335841178894,
      "learning_rate": 3.336888813038656e-05,
      "loss": 0.002,
      "step": 19490
    },
    {
      "epoch": 1.663964502090622,
      "grad_norm": 0.15695436298847198,
      "learning_rate": 3.336035497909378e-05,
      "loss": 0.0024,
      "step": 19500
    },
    {
      "epoch": 1.6648178172198993,
      "grad_norm": 0.2576564848423004,
      "learning_rate": 3.335182182780101e-05,
      "loss": 0.0028,
      "step": 19510
    },
    {
      "epoch": 1.6656711323491766,
      "grad_norm": 0.4863317608833313,
      "learning_rate": 3.334328867650824e-05,
      "loss": 0.0028,
      "step": 19520
    },
    {
      "epoch": 1.6665244474784537,
      "grad_norm": 0.0629415363073349,
      "learning_rate": 3.3334755525215466e-05,
      "loss": 0.003,
      "step": 19530
    },
    {
      "epoch": 1.667377762607731,
      "grad_norm": 0.46892663836479187,
      "learning_rate": 3.332622237392269e-05,
      "loss": 0.0023,
      "step": 19540
    },
    {
      "epoch": 1.6682310777370084,
      "grad_norm": 0.1728563904762268,
      "learning_rate": 3.3317689222629916e-05,
      "loss": 0.003,
      "step": 19550
    },
    {
      "epoch": 1.6690843928662855,
      "grad_norm": 0.20192770659923553,
      "learning_rate": 3.3309156071337144e-05,
      "loss": 0.0025,
      "step": 19560
    },
    {
      "epoch": 1.6699377079955626,
      "grad_norm": 0.3207043409347534,
      "learning_rate": 3.330062292004437e-05,
      "loss": 0.0033,
      "step": 19570
    },
    {
      "epoch": 1.67079102312484,
      "grad_norm": 0.10230987519025803,
      "learning_rate": 3.32920897687516e-05,
      "loss": 0.0027,
      "step": 19580
    },
    {
      "epoch": 1.6716443382541173,
      "grad_norm": 0.12868599593639374,
      "learning_rate": 3.328355661745883e-05,
      "loss": 0.0028,
      "step": 19590
    },
    {
      "epoch": 1.6724976533833944,
      "grad_norm": 0.19866272807121277,
      "learning_rate": 3.327502346616606e-05,
      "loss": 0.0026,
      "step": 19600
    },
    {
      "epoch": 1.6733509685126717,
      "grad_norm": 0.14860308170318604,
      "learning_rate": 3.326649031487328e-05,
      "loss": 0.0035,
      "step": 19610
    },
    {
      "epoch": 1.674204283641949,
      "grad_norm": 0.232207790017128,
      "learning_rate": 3.325795716358051e-05,
      "loss": 0.0024,
      "step": 19620
    },
    {
      "epoch": 1.6750575987712262,
      "grad_norm": 0.2592196762561798,
      "learning_rate": 3.324942401228774e-05,
      "loss": 0.0027,
      "step": 19630
    },
    {
      "epoch": 1.6759109139005035,
      "grad_norm": 0.23626099526882172,
      "learning_rate": 3.3240890860994966e-05,
      "loss": 0.0029,
      "step": 19640
    },
    {
      "epoch": 1.6767642290297808,
      "grad_norm": 0.46864497661590576,
      "learning_rate": 3.3232357709702194e-05,
      "loss": 0.0039,
      "step": 19650
    },
    {
      "epoch": 1.677617544159058,
      "grad_norm": 0.1267659068107605,
      "learning_rate": 3.322382455840942e-05,
      "loss": 0.0023,
      "step": 19660
    },
    {
      "epoch": 1.678470859288335,
      "grad_norm": 0.051334019750356674,
      "learning_rate": 3.321529140711665e-05,
      "loss": 0.0027,
      "step": 19670
    },
    {
      "epoch": 1.6793241744176124,
      "grad_norm": 0.3902798593044281,
      "learning_rate": 3.320675825582388e-05,
      "loss": 0.0022,
      "step": 19680
    },
    {
      "epoch": 1.6801774895468897,
      "grad_norm": 0.28749269247055054,
      "learning_rate": 3.319822510453111e-05,
      "loss": 0.003,
      "step": 19690
    },
    {
      "epoch": 1.6810308046761668,
      "grad_norm": 0.11964860558509827,
      "learning_rate": 3.3189691953238336e-05,
      "loss": 0.003,
      "step": 19700
    },
    {
      "epoch": 1.6818841198054442,
      "grad_norm": 0.1466124951839447,
      "learning_rate": 3.318115880194556e-05,
      "loss": 0.0024,
      "step": 19710
    },
    {
      "epoch": 1.6827374349347215,
      "grad_norm": 0.13869427144527435,
      "learning_rate": 3.3172625650652787e-05,
      "loss": 0.0019,
      "step": 19720
    },
    {
      "epoch": 1.6835907500639986,
      "grad_norm": 0.3190361559391022,
      "learning_rate": 3.3164092499360015e-05,
      "loss": 0.003,
      "step": 19730
    },
    {
      "epoch": 1.6844440651932757,
      "grad_norm": 0.09899304807186127,
      "learning_rate": 3.3155559348067244e-05,
      "loss": 0.0031,
      "step": 19740
    },
    {
      "epoch": 1.6852973803225533,
      "grad_norm": 0.10988041013479233,
      "learning_rate": 3.314702619677447e-05,
      "loss": 0.0022,
      "step": 19750
    },
    {
      "epoch": 1.6861506954518304,
      "grad_norm": 0.14398980140686035,
      "learning_rate": 3.31384930454817e-05,
      "loss": 0.0021,
      "step": 19760
    },
    {
      "epoch": 1.6870040105811075,
      "grad_norm": 0.19996458292007446,
      "learning_rate": 3.312995989418893e-05,
      "loss": 0.0024,
      "step": 19770
    },
    {
      "epoch": 1.6878573257103848,
      "grad_norm": 0.06607147306203842,
      "learning_rate": 3.312142674289616e-05,
      "loss": 0.0027,
      "step": 19780
    },
    {
      "epoch": 1.6887106408396622,
      "grad_norm": 0.06499143689870834,
      "learning_rate": 3.3112893591603386e-05,
      "loss": 0.003,
      "step": 19790
    },
    {
      "epoch": 1.6895639559689393,
      "grad_norm": 0.45216619968414307,
      "learning_rate": 3.310436044031061e-05,
      "loss": 0.0022,
      "step": 19800
    },
    {
      "epoch": 1.6904172710982166,
      "grad_norm": 0.3587774932384491,
      "learning_rate": 3.3095827289017836e-05,
      "loss": 0.0021,
      "step": 19810
    },
    {
      "epoch": 1.691270586227494,
      "grad_norm": 0.8077167868614197,
      "learning_rate": 3.308729413772506e-05,
      "loss": 0.0036,
      "step": 19820
    },
    {
      "epoch": 1.692123901356771,
      "grad_norm": 0.17496907711029053,
      "learning_rate": 3.3078760986432286e-05,
      "loss": 0.0023,
      "step": 19830
    },
    {
      "epoch": 1.6929772164860482,
      "grad_norm": 0.17801611125469208,
      "learning_rate": 3.3070227835139515e-05,
      "loss": 0.0036,
      "step": 19840
    },
    {
      "epoch": 1.6938305316153255,
      "grad_norm": 0.06499551981687546,
      "learning_rate": 3.306169468384674e-05,
      "loss": 0.0027,
      "step": 19850
    },
    {
      "epoch": 1.6946838467446028,
      "grad_norm": 0.2914641201496124,
      "learning_rate": 3.305316153255397e-05,
      "loss": 0.0033,
      "step": 19860
    },
    {
      "epoch": 1.69553716187388,
      "grad_norm": 0.4614875614643097,
      "learning_rate": 3.30446283812612e-05,
      "loss": 0.0039,
      "step": 19870
    },
    {
      "epoch": 1.6963904770031573,
      "grad_norm": 0.0941455140709877,
      "learning_rate": 3.303609522996843e-05,
      "loss": 0.0037,
      "step": 19880
    },
    {
      "epoch": 1.6972437921324346,
      "grad_norm": 0.4271979033946991,
      "learning_rate": 3.302756207867566e-05,
      "loss": 0.0028,
      "step": 19890
    },
    {
      "epoch": 1.6980971072617117,
      "grad_norm": 0.23593704402446747,
      "learning_rate": 3.3019028927382886e-05,
      "loss": 0.0026,
      "step": 19900
    },
    {
      "epoch": 1.698950422390989,
      "grad_norm": 0.02598108910024166,
      "learning_rate": 3.3010495776090114e-05,
      "loss": 0.0031,
      "step": 19910
    },
    {
      "epoch": 1.6998037375202664,
      "grad_norm": 0.2536436915397644,
      "learning_rate": 3.3001962624797336e-05,
      "loss": 0.002,
      "step": 19920
    },
    {
      "epoch": 1.7006570526495435,
      "grad_norm": 0.11539937555789948,
      "learning_rate": 3.2993429473504564e-05,
      "loss": 0.0033,
      "step": 19930
    },
    {
      "epoch": 1.7015103677788206,
      "grad_norm": 0.07710909098386765,
      "learning_rate": 3.298489632221179e-05,
      "loss": 0.0027,
      "step": 19940
    },
    {
      "epoch": 1.702363682908098,
      "grad_norm": 0.1546975076198578,
      "learning_rate": 3.297636317091902e-05,
      "loss": 0.0029,
      "step": 19950
    },
    {
      "epoch": 1.7032169980373753,
      "grad_norm": 0.12585440278053284,
      "learning_rate": 3.296783001962625e-05,
      "loss": 0.0023,
      "step": 19960
    },
    {
      "epoch": 1.7040703131666524,
      "grad_norm": 0.052760567516088486,
      "learning_rate": 3.295929686833348e-05,
      "loss": 0.0024,
      "step": 19970
    },
    {
      "epoch": 1.7049236282959297,
      "grad_norm": 0.19565610587596893,
      "learning_rate": 3.295076371704071e-05,
      "loss": 0.0034,
      "step": 19980
    },
    {
      "epoch": 1.705776943425207,
      "grad_norm": 0.08228326588869095,
      "learning_rate": 3.2942230565747935e-05,
      "loss": 0.0033,
      "step": 19990
    },
    {
      "epoch": 1.7066302585544841,
      "grad_norm": 0.06803740561008453,
      "learning_rate": 3.2933697414455164e-05,
      "loss": 0.0032,
      "step": 20000
    },
    {
      "epoch": 1.7074835736837615,
      "grad_norm": 0.09915295243263245,
      "learning_rate": 3.292516426316239e-05,
      "loss": 0.0026,
      "step": 20010
    },
    {
      "epoch": 1.7083368888130388,
      "grad_norm": 0.21391363441944122,
      "learning_rate": 3.2916631111869614e-05,
      "loss": 0.0028,
      "step": 20020
    },
    {
      "epoch": 1.709190203942316,
      "grad_norm": 0.12144605070352554,
      "learning_rate": 3.290809796057684e-05,
      "loss": 0.0035,
      "step": 20030
    },
    {
      "epoch": 1.710043519071593,
      "grad_norm": 0.09706731885671616,
      "learning_rate": 3.289956480928407e-05,
      "loss": 0.0025,
      "step": 20040
    },
    {
      "epoch": 1.7108968342008704,
      "grad_norm": 0.17485114932060242,
      "learning_rate": 3.28910316579913e-05,
      "loss": 0.0023,
      "step": 20050
    },
    {
      "epoch": 1.7117501493301477,
      "grad_norm": 0.16142991185188293,
      "learning_rate": 3.288249850669853e-05,
      "loss": 0.0026,
      "step": 20060
    },
    {
      "epoch": 1.7126034644594248,
      "grad_norm": 0.20574802160263062,
      "learning_rate": 3.287396535540575e-05,
      "loss": 0.0024,
      "step": 20070
    },
    {
      "epoch": 1.7134567795887021,
      "grad_norm": 0.15521664917469025,
      "learning_rate": 3.286543220411298e-05,
      "loss": 0.0023,
      "step": 20080
    },
    {
      "epoch": 1.7143100947179795,
      "grad_norm": 0.1726287454366684,
      "learning_rate": 3.2856899052820207e-05,
      "loss": 0.0027,
      "step": 20090
    },
    {
      "epoch": 1.7151634098472566,
      "grad_norm": 0.18892064690589905,
      "learning_rate": 3.2848365901527435e-05,
      "loss": 0.0023,
      "step": 20100
    },
    {
      "epoch": 1.7160167249765337,
      "grad_norm": 0.0696323961019516,
      "learning_rate": 3.2839832750234664e-05,
      "loss": 0.0026,
      "step": 20110
    },
    {
      "epoch": 1.7168700401058112,
      "grad_norm": 0.16171696782112122,
      "learning_rate": 3.283129959894189e-05,
      "loss": 0.0029,
      "step": 20120
    },
    {
      "epoch": 1.7177233552350883,
      "grad_norm": 0.20070917904376984,
      "learning_rate": 3.2822766447649114e-05,
      "loss": 0.003,
      "step": 20130
    },
    {
      "epoch": 1.7185766703643655,
      "grad_norm": 0.236012265086174,
      "learning_rate": 3.281423329635634e-05,
      "loss": 0.0032,
      "step": 20140
    },
    {
      "epoch": 1.7194299854936428,
      "grad_norm": 0.21086721122264862,
      "learning_rate": 3.280570014506357e-05,
      "loss": 0.0034,
      "step": 20150
    },
    {
      "epoch": 1.7202833006229201,
      "grad_norm": 0.2278718650341034,
      "learning_rate": 3.27971669937708e-05,
      "loss": 0.0033,
      "step": 20160
    },
    {
      "epoch": 1.7211366157521972,
      "grad_norm": 0.18470709025859833,
      "learning_rate": 3.278863384247803e-05,
      "loss": 0.0031,
      "step": 20170
    },
    {
      "epoch": 1.7219899308814746,
      "grad_norm": 0.2134769707918167,
      "learning_rate": 3.2780100691185256e-05,
      "loss": 0.0025,
      "step": 20180
    },
    {
      "epoch": 1.722843246010752,
      "grad_norm": 0.033520184457302094,
      "learning_rate": 3.2771567539892485e-05,
      "loss": 0.0031,
      "step": 20190
    },
    {
      "epoch": 1.723696561140029,
      "grad_norm": 0.1770476996898651,
      "learning_rate": 3.276303438859971e-05,
      "loss": 0.0033,
      "step": 20200
    },
    {
      "epoch": 1.7245498762693061,
      "grad_norm": 0.18961657583713531,
      "learning_rate": 3.275450123730694e-05,
      "loss": 0.003,
      "step": 20210
    },
    {
      "epoch": 1.7254031913985834,
      "grad_norm": 0.26111283898353577,
      "learning_rate": 3.274596808601417e-05,
      "loss": 0.0032,
      "step": 20220
    },
    {
      "epoch": 1.7262565065278608,
      "grad_norm": 0.20629195868968964,
      "learning_rate": 3.273743493472139e-05,
      "loss": 0.0034,
      "step": 20230
    },
    {
      "epoch": 1.727109821657138,
      "grad_norm": 0.3498983383178711,
      "learning_rate": 3.272890178342862e-05,
      "loss": 0.0035,
      "step": 20240
    },
    {
      "epoch": 1.7279631367864152,
      "grad_norm": 0.2807387709617615,
      "learning_rate": 3.272036863213585e-05,
      "loss": 0.0022,
      "step": 20250
    },
    {
      "epoch": 1.7288164519156926,
      "grad_norm": 0.891812801361084,
      "learning_rate": 3.271183548084308e-05,
      "loss": 0.0031,
      "step": 20260
    },
    {
      "epoch": 1.7296697670449697,
      "grad_norm": 0.3378596603870392,
      "learning_rate": 3.2703302329550306e-05,
      "loss": 0.0031,
      "step": 20270
    },
    {
      "epoch": 1.730523082174247,
      "grad_norm": 0.2721599042415619,
      "learning_rate": 3.2694769178257534e-05,
      "loss": 0.0028,
      "step": 20280
    },
    {
      "epoch": 1.7313763973035243,
      "grad_norm": 0.2883119583129883,
      "learning_rate": 3.268623602696476e-05,
      "loss": 0.0026,
      "step": 20290
    },
    {
      "epoch": 1.7322297124328014,
      "grad_norm": 0.23987582325935364,
      "learning_rate": 3.267770287567199e-05,
      "loss": 0.003,
      "step": 20300
    },
    {
      "epoch": 1.7330830275620785,
      "grad_norm": 0.44502124190330505,
      "learning_rate": 3.266916972437922e-05,
      "loss": 0.0029,
      "step": 20310
    },
    {
      "epoch": 1.7339363426913559,
      "grad_norm": 0.582996666431427,
      "learning_rate": 3.266063657308645e-05,
      "loss": 0.0031,
      "step": 20320
    },
    {
      "epoch": 1.7347896578206332,
      "grad_norm": 0.1600179821252823,
      "learning_rate": 3.265210342179367e-05,
      "loss": 0.0026,
      "step": 20330
    },
    {
      "epoch": 1.7356429729499103,
      "grad_norm": 0.5578855276107788,
      "learning_rate": 3.26435702705009e-05,
      "loss": 0.003,
      "step": 20340
    },
    {
      "epoch": 1.7364962880791877,
      "grad_norm": 0.12262417376041412,
      "learning_rate": 3.263503711920812e-05,
      "loss": 0.003,
      "step": 20350
    },
    {
      "epoch": 1.737349603208465,
      "grad_norm": 0.08368087559938431,
      "learning_rate": 3.262650396791535e-05,
      "loss": 0.0024,
      "step": 20360
    },
    {
      "epoch": 1.738202918337742,
      "grad_norm": 0.08024346828460693,
      "learning_rate": 3.261797081662258e-05,
      "loss": 0.0025,
      "step": 20370
    },
    {
      "epoch": 1.7390562334670192,
      "grad_norm": 0.06237928941845894,
      "learning_rate": 3.2609437665329805e-05,
      "loss": 0.0033,
      "step": 20380
    },
    {
      "epoch": 1.7399095485962968,
      "grad_norm": 0.25078779458999634,
      "learning_rate": 3.2600904514037034e-05,
      "loss": 0.0026,
      "step": 20390
    },
    {
      "epoch": 1.7407628637255739,
      "grad_norm": 0.19608552753925323,
      "learning_rate": 3.259237136274426e-05,
      "loss": 0.0029,
      "step": 20400
    },
    {
      "epoch": 1.741616178854851,
      "grad_norm": 0.10057687014341354,
      "learning_rate": 3.258383821145149e-05,
      "loss": 0.0028,
      "step": 20410
    },
    {
      "epoch": 1.7424694939841283,
      "grad_norm": 0.21268205344676971,
      "learning_rate": 3.257530506015872e-05,
      "loss": 0.003,
      "step": 20420
    },
    {
      "epoch": 1.7433228091134056,
      "grad_norm": 0.08117768168449402,
      "learning_rate": 3.256677190886595e-05,
      "loss": 0.0022,
      "step": 20430
    },
    {
      "epoch": 1.7441761242426828,
      "grad_norm": 0.1369335800409317,
      "learning_rate": 3.255823875757317e-05,
      "loss": 0.0025,
      "step": 20440
    },
    {
      "epoch": 1.74502943937196,
      "grad_norm": 0.17380037903785706,
      "learning_rate": 3.25497056062804e-05,
      "loss": 0.0028,
      "step": 20450
    },
    {
      "epoch": 1.7458827545012374,
      "grad_norm": 0.20740768313407898,
      "learning_rate": 3.2541172454987627e-05,
      "loss": 0.0031,
      "step": 20460
    },
    {
      "epoch": 1.7467360696305145,
      "grad_norm": 0.07346393167972565,
      "learning_rate": 3.2532639303694855e-05,
      "loss": 0.0023,
      "step": 20470
    },
    {
      "epoch": 1.7475893847597916,
      "grad_norm": 0.6556084752082825,
      "learning_rate": 3.2524106152402083e-05,
      "loss": 0.0026,
      "step": 20480
    },
    {
      "epoch": 1.7484426998890692,
      "grad_norm": 0.5639222860336304,
      "learning_rate": 3.251557300110931e-05,
      "loss": 0.0027,
      "step": 20490
    },
    {
      "epoch": 1.7492960150183463,
      "grad_norm": 0.13849754631519318,
      "learning_rate": 3.250703984981654e-05,
      "loss": 0.0029,
      "step": 20500
    },
    {
      "epoch": 1.7501493301476234,
      "grad_norm": 0.08546099811792374,
      "learning_rate": 3.249850669852377e-05,
      "loss": 0.0016,
      "step": 20510
    },
    {
      "epoch": 1.7510026452769007,
      "grad_norm": 0.2115441858768463,
      "learning_rate": 3.2489973547231e-05,
      "loss": 0.0024,
      "step": 20520
    },
    {
      "epoch": 1.751855960406178,
      "grad_norm": 0.24340294301509857,
      "learning_rate": 3.2481440395938226e-05,
      "loss": 0.0022,
      "step": 20530
    },
    {
      "epoch": 1.7527092755354552,
      "grad_norm": 0.1366775929927826,
      "learning_rate": 3.247290724464545e-05,
      "loss": 0.0022,
      "step": 20540
    },
    {
      "epoch": 1.7535625906647325,
      "grad_norm": 0.14666590094566345,
      "learning_rate": 3.2464374093352676e-05,
      "loss": 0.0028,
      "step": 20550
    },
    {
      "epoch": 1.7544159057940099,
      "grad_norm": 0.17586649954319,
      "learning_rate": 3.2455840942059905e-05,
      "loss": 0.0021,
      "step": 20560
    },
    {
      "epoch": 1.755269220923287,
      "grad_norm": 0.16626009345054626,
      "learning_rate": 3.244730779076713e-05,
      "loss": 0.003,
      "step": 20570
    },
    {
      "epoch": 1.756122536052564,
      "grad_norm": 0.5330649614334106,
      "learning_rate": 3.243877463947436e-05,
      "loss": 0.0028,
      "step": 20580
    },
    {
      "epoch": 1.7569758511818414,
      "grad_norm": 0.039041176438331604,
      "learning_rate": 3.243024148818159e-05,
      "loss": 0.0028,
      "step": 20590
    },
    {
      "epoch": 1.7578291663111187,
      "grad_norm": 0.245059534907341,
      "learning_rate": 3.242170833688881e-05,
      "loss": 0.002,
      "step": 20600
    },
    {
      "epoch": 1.7586824814403959,
      "grad_norm": 0.15703654289245605,
      "learning_rate": 3.241317518559604e-05,
      "loss": 0.0033,
      "step": 20610
    },
    {
      "epoch": 1.7595357965696732,
      "grad_norm": 0.18164624273777008,
      "learning_rate": 3.240464203430327e-05,
      "loss": 0.0024,
      "step": 20620
    },
    {
      "epoch": 1.7603891116989505,
      "grad_norm": 0.299561083316803,
      "learning_rate": 3.23961088830105e-05,
      "loss": 0.003,
      "step": 20630
    },
    {
      "epoch": 1.7612424268282276,
      "grad_norm": 0.15781071782112122,
      "learning_rate": 3.2387575731717726e-05,
      "loss": 0.0032,
      "step": 20640
    },
    {
      "epoch": 1.762095741957505,
      "grad_norm": 0.17064408957958221,
      "learning_rate": 3.2379042580424954e-05,
      "loss": 0.0025,
      "step": 20650
    },
    {
      "epoch": 1.7629490570867823,
      "grad_norm": 0.29375311732292175,
      "learning_rate": 3.2370509429132176e-05,
      "loss": 0.0028,
      "step": 20660
    },
    {
      "epoch": 1.7638023722160594,
      "grad_norm": 0.11286284029483795,
      "learning_rate": 3.2361976277839404e-05,
      "loss": 0.0022,
      "step": 20670
    },
    {
      "epoch": 1.7646556873453365,
      "grad_norm": 0.2032661736011505,
      "learning_rate": 3.235344312654663e-05,
      "loss": 0.0031,
      "step": 20680
    },
    {
      "epoch": 1.7655090024746138,
      "grad_norm": 0.2979834973812103,
      "learning_rate": 3.234490997525386e-05,
      "loss": 0.003,
      "step": 20690
    },
    {
      "epoch": 1.7663623176038912,
      "grad_norm": 0.21711890399456024,
      "learning_rate": 3.233637682396109e-05,
      "loss": 0.0025,
      "step": 20700
    },
    {
      "epoch": 1.7672156327331683,
      "grad_norm": 0.20865163207054138,
      "learning_rate": 3.232784367266832e-05,
      "loss": 0.0034,
      "step": 20710
    },
    {
      "epoch": 1.7680689478624456,
      "grad_norm": 0.24797971546649933,
      "learning_rate": 3.231931052137555e-05,
      "loss": 0.0023,
      "step": 20720
    },
    {
      "epoch": 1.768922262991723,
      "grad_norm": 0.04895751550793648,
      "learning_rate": 3.2310777370082775e-05,
      "loss": 0.002,
      "step": 20730
    },
    {
      "epoch": 1.769775578121,
      "grad_norm": 0.2349400371313095,
      "learning_rate": 3.2302244218790004e-05,
      "loss": 0.0025,
      "step": 20740
    },
    {
      "epoch": 1.7706288932502772,
      "grad_norm": 0.2139279842376709,
      "learning_rate": 3.2293711067497225e-05,
      "loss": 0.0028,
      "step": 20750
    },
    {
      "epoch": 1.7714822083795547,
      "grad_norm": 0.10313640534877777,
      "learning_rate": 3.2285177916204454e-05,
      "loss": 0.0029,
      "step": 20760
    },
    {
      "epoch": 1.7723355235088318,
      "grad_norm": 0.3164045214653015,
      "learning_rate": 3.227664476491168e-05,
      "loss": 0.0033,
      "step": 20770
    },
    {
      "epoch": 1.773188838638109,
      "grad_norm": 0.10491256415843964,
      "learning_rate": 3.226811161361891e-05,
      "loss": 0.0028,
      "step": 20780
    },
    {
      "epoch": 1.7740421537673863,
      "grad_norm": 0.1043190211057663,
      "learning_rate": 3.225957846232614e-05,
      "loss": 0.0027,
      "step": 20790
    },
    {
      "epoch": 1.7748954688966636,
      "grad_norm": 0.29047393798828125,
      "learning_rate": 3.225104531103337e-05,
      "loss": 0.0024,
      "step": 20800
    },
    {
      "epoch": 1.7757487840259407,
      "grad_norm": 0.22011974453926086,
      "learning_rate": 3.2242512159740596e-05,
      "loss": 0.0033,
      "step": 20810
    },
    {
      "epoch": 1.776602099155218,
      "grad_norm": 0.09801433980464935,
      "learning_rate": 3.2233979008447825e-05,
      "loss": 0.0033,
      "step": 20820
    },
    {
      "epoch": 1.7774554142844954,
      "grad_norm": 0.2844068706035614,
      "learning_rate": 3.222544585715505e-05,
      "loss": 0.0034,
      "step": 20830
    },
    {
      "epoch": 1.7783087294137725,
      "grad_norm": 0.09909092634916306,
      "learning_rate": 3.221691270586228e-05,
      "loss": 0.0028,
      "step": 20840
    },
    {
      "epoch": 1.7791620445430496,
      "grad_norm": 0.27796289324760437,
      "learning_rate": 3.2208379554569503e-05,
      "loss": 0.0028,
      "step": 20850
    },
    {
      "epoch": 1.780015359672327,
      "grad_norm": 0.10933675616979599,
      "learning_rate": 3.219984640327673e-05,
      "loss": 0.0024,
      "step": 20860
    },
    {
      "epoch": 1.7808686748016043,
      "grad_norm": 0.2022402435541153,
      "learning_rate": 3.2191313251983954e-05,
      "loss": 0.0024,
      "step": 20870
    },
    {
      "epoch": 1.7817219899308814,
      "grad_norm": 0.15467871725559235,
      "learning_rate": 3.218278010069118e-05,
      "loss": 0.0025,
      "step": 20880
    },
    {
      "epoch": 1.7825753050601587,
      "grad_norm": 0.30251044034957886,
      "learning_rate": 3.217424694939841e-05,
      "loss": 0.002,
      "step": 20890
    },
    {
      "epoch": 1.783428620189436,
      "grad_norm": 0.29094985127449036,
      "learning_rate": 3.216571379810564e-05,
      "loss": 0.0029,
      "step": 20900
    },
    {
      "epoch": 1.7842819353187132,
      "grad_norm": 0.5894515514373779,
      "learning_rate": 3.215718064681287e-05,
      "loss": 0.0025,
      "step": 20910
    },
    {
      "epoch": 1.7851352504479905,
      "grad_norm": 0.3570621907711029,
      "learning_rate": 3.2148647495520096e-05,
      "loss": 0.0031,
      "step": 20920
    },
    {
      "epoch": 1.7859885655772678,
      "grad_norm": 0.09735105186700821,
      "learning_rate": 3.2140114344227324e-05,
      "loss": 0.0028,
      "step": 20930
    },
    {
      "epoch": 1.786841880706545,
      "grad_norm": 0.11749517917633057,
      "learning_rate": 3.213158119293455e-05,
      "loss": 0.002,
      "step": 20940
    },
    {
      "epoch": 1.787695195835822,
      "grad_norm": 0.046509090811014175,
      "learning_rate": 3.212304804164178e-05,
      "loss": 0.0023,
      "step": 20950
    },
    {
      "epoch": 1.7885485109650994,
      "grad_norm": 0.30099624395370483,
      "learning_rate": 3.211451489034901e-05,
      "loss": 0.0036,
      "step": 20960
    },
    {
      "epoch": 1.7894018260943767,
      "grad_norm": 0.18288545310497284,
      "learning_rate": 3.210598173905623e-05,
      "loss": 0.002,
      "step": 20970
    },
    {
      "epoch": 1.7902551412236538,
      "grad_norm": 0.0418255515396595,
      "learning_rate": 3.209744858776346e-05,
      "loss": 0.0026,
      "step": 20980
    },
    {
      "epoch": 1.7911084563529311,
      "grad_norm": 0.1215103343129158,
      "learning_rate": 3.208891543647069e-05,
      "loss": 0.003,
      "step": 20990
    },
    {
      "epoch": 1.7919617714822085,
      "grad_norm": 0.2909039855003357,
      "learning_rate": 3.208038228517792e-05,
      "loss": 0.0025,
      "step": 21000
    },
    {
      "epoch": 1.7928150866114856,
      "grad_norm": 0.22093991935253143,
      "learning_rate": 3.2071849133885146e-05,
      "loss": 0.0023,
      "step": 21010
    },
    {
      "epoch": 1.793668401740763,
      "grad_norm": 0.28167539834976196,
      "learning_rate": 3.2063315982592374e-05,
      "loss": 0.0026,
      "step": 21020
    },
    {
      "epoch": 1.7945217168700403,
      "grad_norm": 0.518851101398468,
      "learning_rate": 3.20547828312996e-05,
      "loss": 0.0021,
      "step": 21030
    },
    {
      "epoch": 1.7953750319993174,
      "grad_norm": 0.0579138919711113,
      "learning_rate": 3.204624968000683e-05,
      "loss": 0.0032,
      "step": 21040
    },
    {
      "epoch": 1.7962283471285945,
      "grad_norm": 0.27263331413269043,
      "learning_rate": 3.203771652871406e-05,
      "loss": 0.0022,
      "step": 21050
    },
    {
      "epoch": 1.7970816622578718,
      "grad_norm": 0.24651016294956207,
      "learning_rate": 3.202918337742129e-05,
      "loss": 0.0029,
      "step": 21060
    },
    {
      "epoch": 1.7979349773871491,
      "grad_norm": 0.24888953566551208,
      "learning_rate": 3.202065022612851e-05,
      "loss": 0.0026,
      "step": 21070
    },
    {
      "epoch": 1.7987882925164262,
      "grad_norm": 0.12631537020206451,
      "learning_rate": 3.201211707483574e-05,
      "loss": 0.0019,
      "step": 21080
    },
    {
      "epoch": 1.7996416076457036,
      "grad_norm": 0.2873072624206543,
      "learning_rate": 3.200358392354297e-05,
      "loss": 0.0023,
      "step": 21090
    },
    {
      "epoch": 1.800494922774981,
      "grad_norm": 0.09205218404531479,
      "learning_rate": 3.1995050772250195e-05,
      "loss": 0.0032,
      "step": 21100
    },
    {
      "epoch": 1.801348237904258,
      "grad_norm": 0.313969224691391,
      "learning_rate": 3.1986517620957424e-05,
      "loss": 0.0026,
      "step": 21110
    },
    {
      "epoch": 1.8022015530335351,
      "grad_norm": 0.036274462938308716,
      "learning_rate": 3.197798446966465e-05,
      "loss": 0.003,
      "step": 21120
    },
    {
      "epoch": 1.8030548681628127,
      "grad_norm": 0.2899029552936554,
      "learning_rate": 3.1969451318371874e-05,
      "loss": 0.0024,
      "step": 21130
    },
    {
      "epoch": 1.8039081832920898,
      "grad_norm": 0.08396884053945541,
      "learning_rate": 3.19609181670791e-05,
      "loss": 0.0026,
      "step": 21140
    },
    {
      "epoch": 1.804761498421367,
      "grad_norm": 0.15992295742034912,
      "learning_rate": 3.195238501578633e-05,
      "loss": 0.0032,
      "step": 21150
    },
    {
      "epoch": 1.8056148135506442,
      "grad_norm": 0.3035835921764374,
      "learning_rate": 3.194385186449356e-05,
      "loss": 0.0026,
      "step": 21160
    },
    {
      "epoch": 1.8064681286799216,
      "grad_norm": 0.03816496580839157,
      "learning_rate": 3.193531871320079e-05,
      "loss": 0.0027,
      "step": 21170
    },
    {
      "epoch": 1.8073214438091987,
      "grad_norm": 0.19168221950531006,
      "learning_rate": 3.192678556190801e-05,
      "loss": 0.0022,
      "step": 21180
    },
    {
      "epoch": 1.808174758938476,
      "grad_norm": 0.2752250134944916,
      "learning_rate": 3.191825241061524e-05,
      "loss": 0.0022,
      "step": 21190
    },
    {
      "epoch": 1.8090280740677533,
      "grad_norm": 0.1587408185005188,
      "learning_rate": 3.1909719259322466e-05,
      "loss": 0.0028,
      "step": 21200
    },
    {
      "epoch": 1.8098813891970305,
      "grad_norm": 0.21726655960083008,
      "learning_rate": 3.1901186108029695e-05,
      "loss": 0.0029,
      "step": 21210
    },
    {
      "epoch": 1.8107347043263076,
      "grad_norm": 0.26662296056747437,
      "learning_rate": 3.189265295673692e-05,
      "loss": 0.0029,
      "step": 21220
    },
    {
      "epoch": 1.811588019455585,
      "grad_norm": 0.3104148209095001,
      "learning_rate": 3.188411980544415e-05,
      "loss": 0.0031,
      "step": 21230
    },
    {
      "epoch": 1.8124413345848622,
      "grad_norm": 0.7014244198799133,
      "learning_rate": 3.187558665415138e-05,
      "loss": 0.0026,
      "step": 21240
    },
    {
      "epoch": 1.8132946497141393,
      "grad_norm": 0.2947412133216858,
      "learning_rate": 3.186705350285861e-05,
      "loss": 0.0018,
      "step": 21250
    },
    {
      "epoch": 1.8141479648434167,
      "grad_norm": 0.2710200250148773,
      "learning_rate": 3.185852035156584e-05,
      "loss": 0.0019,
      "step": 21260
    },
    {
      "epoch": 1.815001279972694,
      "grad_norm": 0.06605250388383865,
      "learning_rate": 3.1849987200273066e-05,
      "loss": 0.0028,
      "step": 21270
    },
    {
      "epoch": 1.8158545951019711,
      "grad_norm": 0.1761532872915268,
      "learning_rate": 3.184145404898029e-05,
      "loss": 0.0021,
      "step": 21280
    },
    {
      "epoch": 1.8167079102312484,
      "grad_norm": 0.15716999769210815,
      "learning_rate": 3.1832920897687516e-05,
      "loss": 0.0027,
      "step": 21290
    },
    {
      "epoch": 1.8175612253605258,
      "grad_norm": 0.20491251349449158,
      "learning_rate": 3.1824387746394744e-05,
      "loss": 0.0021,
      "step": 21300
    },
    {
      "epoch": 1.8184145404898029,
      "grad_norm": 0.17340581119060516,
      "learning_rate": 3.181585459510197e-05,
      "loss": 0.0025,
      "step": 21310
    },
    {
      "epoch": 1.81926785561908,
      "grad_norm": 0.046588774770498276,
      "learning_rate": 3.18073214438092e-05,
      "loss": 0.0033,
      "step": 21320
    },
    {
      "epoch": 1.8201211707483573,
      "grad_norm": 0.03870317339897156,
      "learning_rate": 3.179878829251643e-05,
      "loss": 0.0015,
      "step": 21330
    },
    {
      "epoch": 1.8209744858776347,
      "grad_norm": 0.14075356721878052,
      "learning_rate": 3.179025514122366e-05,
      "loss": 0.0023,
      "step": 21340
    },
    {
      "epoch": 1.8218278010069118,
      "grad_norm": 0.13839296996593475,
      "learning_rate": 3.178172198993089e-05,
      "loss": 0.002,
      "step": 21350
    },
    {
      "epoch": 1.822681116136189,
      "grad_norm": 0.12348569929599762,
      "learning_rate": 3.1773188838638115e-05,
      "loss": 0.0031,
      "step": 21360
    },
    {
      "epoch": 1.8235344312654664,
      "grad_norm": 0.10007426887750626,
      "learning_rate": 3.1764655687345344e-05,
      "loss": 0.0026,
      "step": 21370
    },
    {
      "epoch": 1.8243877463947435,
      "grad_norm": 0.36256253719329834,
      "learning_rate": 3.1756122536052566e-05,
      "loss": 0.0021,
      "step": 21380
    },
    {
      "epoch": 1.8252410615240207,
      "grad_norm": 0.306837260723114,
      "learning_rate": 3.1747589384759794e-05,
      "loss": 0.0024,
      "step": 21390
    },
    {
      "epoch": 1.8260943766532982,
      "grad_norm": 0.15550625324249268,
      "learning_rate": 3.1739056233467016e-05,
      "loss": 0.0017,
      "step": 21400
    },
    {
      "epoch": 1.8269476917825753,
      "grad_norm": 0.5087082982063293,
      "learning_rate": 3.1730523082174244e-05,
      "loss": 0.0021,
      "step": 21410
    },
    {
      "epoch": 1.8278010069118524,
      "grad_norm": 0.4983047544956207,
      "learning_rate": 3.172198993088147e-05,
      "loss": 0.0024,
      "step": 21420
    },
    {
      "epoch": 1.8286543220411298,
      "grad_norm": 0.25140002369880676,
      "learning_rate": 3.17134567795887e-05,
      "loss": 0.0021,
      "step": 21430
    },
    {
      "epoch": 1.829507637170407,
      "grad_norm": 0.10891346633434296,
      "learning_rate": 3.170492362829593e-05,
      "loss": 0.0037,
      "step": 21440
    },
    {
      "epoch": 1.8303609522996842,
      "grad_norm": 0.15597757697105408,
      "learning_rate": 3.169639047700316e-05,
      "loss": 0.0024,
      "step": 21450
    },
    {
      "epoch": 1.8312142674289615,
      "grad_norm": 0.27456897497177124,
      "learning_rate": 3.1687857325710387e-05,
      "loss": 0.0023,
      "step": 21460
    },
    {
      "epoch": 1.8320675825582389,
      "grad_norm": 0.06327039748430252,
      "learning_rate": 3.1679324174417615e-05,
      "loss": 0.0033,
      "step": 21470
    },
    {
      "epoch": 1.832920897687516,
      "grad_norm": 0.34566548466682434,
      "learning_rate": 3.1670791023124844e-05,
      "loss": 0.003,
      "step": 21480
    },
    {
      "epoch": 1.833774212816793,
      "grad_norm": 0.36869016289711,
      "learning_rate": 3.1662257871832065e-05,
      "loss": 0.0025,
      "step": 21490
    },
    {
      "epoch": 1.8346275279460706,
      "grad_norm": 0.1364257037639618,
      "learning_rate": 3.1653724720539294e-05,
      "loss": 0.0029,
      "step": 21500
    },
    {
      "epoch": 1.8354808430753478,
      "grad_norm": 0.21412894129753113,
      "learning_rate": 3.164519156924652e-05,
      "loss": 0.0025,
      "step": 21510
    },
    {
      "epoch": 1.8363341582046249,
      "grad_norm": 0.2790246903896332,
      "learning_rate": 3.163665841795375e-05,
      "loss": 0.0032,
      "step": 21520
    },
    {
      "epoch": 1.8371874733339022,
      "grad_norm": 0.2513352632522583,
      "learning_rate": 3.162812526666098e-05,
      "loss": 0.0028,
      "step": 21530
    },
    {
      "epoch": 1.8380407884631795,
      "grad_norm": 0.1743336170911789,
      "learning_rate": 3.161959211536821e-05,
      "loss": 0.0023,
      "step": 21540
    },
    {
      "epoch": 1.8388941035924566,
      "grad_norm": 0.5607197880744934,
      "learning_rate": 3.1611058964075436e-05,
      "loss": 0.0026,
      "step": 21550
    },
    {
      "epoch": 1.839747418721734,
      "grad_norm": 0.5350931882858276,
      "learning_rate": 3.1602525812782665e-05,
      "loss": 0.0024,
      "step": 21560
    },
    {
      "epoch": 1.8406007338510113,
      "grad_norm": 0.5616837739944458,
      "learning_rate": 3.159399266148989e-05,
      "loss": 0.0029,
      "step": 21570
    },
    {
      "epoch": 1.8414540489802884,
      "grad_norm": 0.2920485734939575,
      "learning_rate": 3.158545951019712e-05,
      "loss": 0.0024,
      "step": 21580
    },
    {
      "epoch": 1.8423073641095655,
      "grad_norm": 0.15349282324314117,
      "learning_rate": 3.157692635890434e-05,
      "loss": 0.0031,
      "step": 21590
    },
    {
      "epoch": 1.8431606792388429,
      "grad_norm": 0.2714601159095764,
      "learning_rate": 3.156839320761157e-05,
      "loss": 0.0033,
      "step": 21600
    },
    {
      "epoch": 1.8440139943681202,
      "grad_norm": 0.06623344868421555,
      "learning_rate": 3.15598600563188e-05,
      "loss": 0.0023,
      "step": 21610
    },
    {
      "epoch": 1.8448673094973973,
      "grad_norm": 0.39720430970191956,
      "learning_rate": 3.155132690502603e-05,
      "loss": 0.0028,
      "step": 21620
    },
    {
      "epoch": 1.8457206246266746,
      "grad_norm": 0.05100676417350769,
      "learning_rate": 3.154279375373326e-05,
      "loss": 0.0028,
      "step": 21630
    },
    {
      "epoch": 1.846573939755952,
      "grad_norm": 0.19433850049972534,
      "learning_rate": 3.1534260602440486e-05,
      "loss": 0.003,
      "step": 21640
    },
    {
      "epoch": 1.847427254885229,
      "grad_norm": 0.293134480714798,
      "learning_rate": 3.1525727451147714e-05,
      "loss": 0.0029,
      "step": 21650
    },
    {
      "epoch": 1.8482805700145064,
      "grad_norm": 0.2135888934135437,
      "learning_rate": 3.1517194299854936e-05,
      "loss": 0.0027,
      "step": 21660
    },
    {
      "epoch": 1.8491338851437837,
      "grad_norm": 0.20093022286891937,
      "learning_rate": 3.1508661148562164e-05,
      "loss": 0.0027,
      "step": 21670
    },
    {
      "epoch": 1.8499872002730609,
      "grad_norm": 0.21818700432777405,
      "learning_rate": 3.150012799726939e-05,
      "loss": 0.0026,
      "step": 21680
    },
    {
      "epoch": 1.850840515402338,
      "grad_norm": 0.07785773277282715,
      "learning_rate": 3.149159484597662e-05,
      "loss": 0.0026,
      "step": 21690
    },
    {
      "epoch": 1.8516938305316153,
      "grad_norm": 0.39205092191696167,
      "learning_rate": 3.148306169468384e-05,
      "loss": 0.0032,
      "step": 21700
    },
    {
      "epoch": 1.8525471456608926,
      "grad_norm": 0.08403662592172623,
      "learning_rate": 3.147452854339107e-05,
      "loss": 0.0024,
      "step": 21710
    },
    {
      "epoch": 1.8534004607901697,
      "grad_norm": 0.15818320214748383,
      "learning_rate": 3.14659953920983e-05,
      "loss": 0.0027,
      "step": 21720
    },
    {
      "epoch": 1.854253775919447,
      "grad_norm": 0.1919334977865219,
      "learning_rate": 3.145746224080553e-05,
      "loss": 0.0023,
      "step": 21730
    },
    {
      "epoch": 1.8551070910487244,
      "grad_norm": 0.3003915548324585,
      "learning_rate": 3.144892908951276e-05,
      "loss": 0.003,
      "step": 21740
    },
    {
      "epoch": 1.8559604061780015,
      "grad_norm": 0.21263913810253143,
      "learning_rate": 3.1440395938219985e-05,
      "loss": 0.0024,
      "step": 21750
    },
    {
      "epoch": 1.8568137213072786,
      "grad_norm": 0.07612328231334686,
      "learning_rate": 3.1431862786927214e-05,
      "loss": 0.003,
      "step": 21760
    },
    {
      "epoch": 1.8576670364365562,
      "grad_norm": 0.6224063038825989,
      "learning_rate": 3.142332963563444e-05,
      "loss": 0.0026,
      "step": 21770
    },
    {
      "epoch": 1.8585203515658333,
      "grad_norm": 0.461363285779953,
      "learning_rate": 3.141479648434167e-05,
      "loss": 0.0029,
      "step": 21780
    },
    {
      "epoch": 1.8593736666951104,
      "grad_norm": 0.20005029439926147,
      "learning_rate": 3.14062633330489e-05,
      "loss": 0.0037,
      "step": 21790
    },
    {
      "epoch": 1.8602269818243877,
      "grad_norm": 0.0654517337679863,
      "learning_rate": 3.139773018175612e-05,
      "loss": 0.0023,
      "step": 21800
    },
    {
      "epoch": 1.861080296953665,
      "grad_norm": 0.07681786268949509,
      "learning_rate": 3.138919703046335e-05,
      "loss": 0.0032,
      "step": 21810
    },
    {
      "epoch": 1.8619336120829422,
      "grad_norm": 0.07415749877691269,
      "learning_rate": 3.138066387917058e-05,
      "loss": 0.0029,
      "step": 21820
    },
    {
      "epoch": 1.8627869272122195,
      "grad_norm": 0.31361499428749084,
      "learning_rate": 3.1372130727877807e-05,
      "loss": 0.002,
      "step": 21830
    },
    {
      "epoch": 1.8636402423414968,
      "grad_norm": 0.17540699243545532,
      "learning_rate": 3.1363597576585035e-05,
      "loss": 0.0031,
      "step": 21840
    },
    {
      "epoch": 1.864493557470774,
      "grad_norm": 0.1924862116575241,
      "learning_rate": 3.1355064425292264e-05,
      "loss": 0.0029,
      "step": 21850
    },
    {
      "epoch": 1.865346872600051,
      "grad_norm": 0.09926531463861465,
      "learning_rate": 3.134653127399949e-05,
      "loss": 0.0021,
      "step": 21860
    },
    {
      "epoch": 1.8662001877293284,
      "grad_norm": 0.08534907549619675,
      "learning_rate": 3.133799812270672e-05,
      "loss": 0.0028,
      "step": 21870
    },
    {
      "epoch": 1.8670535028586057,
      "grad_norm": 0.1815682202577591,
      "learning_rate": 3.132946497141395e-05,
      "loss": 0.0026,
      "step": 21880
    },
    {
      "epoch": 1.8679068179878828,
      "grad_norm": 0.030730558559298515,
      "learning_rate": 3.132093182012118e-05,
      "loss": 0.0024,
      "step": 21890
    },
    {
      "epoch": 1.8687601331171602,
      "grad_norm": 0.07087162137031555,
      "learning_rate": 3.13123986688284e-05,
      "loss": 0.0022,
      "step": 21900
    },
    {
      "epoch": 1.8696134482464375,
      "grad_norm": 0.3672451972961426,
      "learning_rate": 3.130386551753563e-05,
      "loss": 0.0032,
      "step": 21910
    },
    {
      "epoch": 1.8704667633757146,
      "grad_norm": 0.09235097467899323,
      "learning_rate": 3.1295332366242856e-05,
      "loss": 0.0026,
      "step": 21920
    },
    {
      "epoch": 1.871320078504992,
      "grad_norm": 0.25329259037971497,
      "learning_rate": 3.128679921495008e-05,
      "loss": 0.0019,
      "step": 21930
    },
    {
      "epoch": 1.8721733936342693,
      "grad_norm": 0.292685329914093,
      "learning_rate": 3.1278266063657306e-05,
      "loss": 0.0023,
      "step": 21940
    },
    {
      "epoch": 1.8730267087635464,
      "grad_norm": 0.49450913071632385,
      "learning_rate": 3.1269732912364535e-05,
      "loss": 0.0023,
      "step": 21950
    },
    {
      "epoch": 1.8738800238928235,
      "grad_norm": 0.21560323238372803,
      "learning_rate": 3.126119976107176e-05,
      "loss": 0.0025,
      "step": 21960
    },
    {
      "epoch": 1.8747333390221008,
      "grad_norm": 0.48434966802597046,
      "learning_rate": 3.125266660977899e-05,
      "loss": 0.0028,
      "step": 21970
    },
    {
      "epoch": 1.8755866541513782,
      "grad_norm": 0.43007147312164307,
      "learning_rate": 3.124413345848622e-05,
      "loss": 0.0021,
      "step": 21980
    },
    {
      "epoch": 1.8764399692806553,
      "grad_norm": 0.06210062652826309,
      "learning_rate": 3.123560030719345e-05,
      "loss": 0.0023,
      "step": 21990
    },
    {
      "epoch": 1.8772932844099326,
      "grad_norm": 0.21028779447078705,
      "learning_rate": 3.122706715590068e-05,
      "loss": 0.0031,
      "step": 22000
    },
    {
      "epoch": 1.87814659953921,
      "grad_norm": 0.19062867760658264,
      "learning_rate": 3.12185340046079e-05,
      "loss": 0.0023,
      "step": 22010
    },
    {
      "epoch": 1.878999914668487,
      "grad_norm": 0.06457493454217911,
      "learning_rate": 3.121000085331513e-05,
      "loss": 0.0035,
      "step": 22020
    },
    {
      "epoch": 1.8798532297977644,
      "grad_norm": 0.11942604929208755,
      "learning_rate": 3.1201467702022356e-05,
      "loss": 0.0034,
      "step": 22030
    },
    {
      "epoch": 1.8807065449270417,
      "grad_norm": 0.11880669742822647,
      "learning_rate": 3.1192934550729584e-05,
      "loss": 0.0028,
      "step": 22040
    },
    {
      "epoch": 1.8815598600563188,
      "grad_norm": 0.18624693155288696,
      "learning_rate": 3.118440139943681e-05,
      "loss": 0.0029,
      "step": 22050
    },
    {
      "epoch": 1.882413175185596,
      "grad_norm": 0.49287745356559753,
      "learning_rate": 3.117586824814404e-05,
      "loss": 0.0026,
      "step": 22060
    },
    {
      "epoch": 1.8832664903148733,
      "grad_norm": 0.5161958932876587,
      "learning_rate": 3.116733509685127e-05,
      "loss": 0.0032,
      "step": 22070
    },
    {
      "epoch": 1.8841198054441506,
      "grad_norm": 0.10703640431165695,
      "learning_rate": 3.11588019455585e-05,
      "loss": 0.0027,
      "step": 22080
    },
    {
      "epoch": 1.8849731205734277,
      "grad_norm": 0.05008542165160179,
      "learning_rate": 3.115026879426573e-05,
      "loss": 0.0024,
      "step": 22090
    },
    {
      "epoch": 1.885826435702705,
      "grad_norm": 0.11366545408964157,
      "learning_rate": 3.1141735642972955e-05,
      "loss": 0.0029,
      "step": 22100
    },
    {
      "epoch": 1.8866797508319824,
      "grad_norm": 0.10593222081661224,
      "learning_rate": 3.113320249168018e-05,
      "loss": 0.0027,
      "step": 22110
    },
    {
      "epoch": 1.8875330659612595,
      "grad_norm": 0.1556025892496109,
      "learning_rate": 3.1124669340387405e-05,
      "loss": 0.003,
      "step": 22120
    },
    {
      "epoch": 1.8883863810905366,
      "grad_norm": 0.26954102516174316,
      "learning_rate": 3.1116136189094634e-05,
      "loss": 0.0017,
      "step": 22130
    },
    {
      "epoch": 1.8892396962198141,
      "grad_norm": 0.17338456213474274,
      "learning_rate": 3.110760303780186e-05,
      "loss": 0.0017,
      "step": 22140
    },
    {
      "epoch": 1.8900930113490912,
      "grad_norm": 0.30623626708984375,
      "learning_rate": 3.109906988650909e-05,
      "loss": 0.0026,
      "step": 22150
    },
    {
      "epoch": 1.8909463264783684,
      "grad_norm": 0.05361349508166313,
      "learning_rate": 3.109053673521632e-05,
      "loss": 0.0026,
      "step": 22160
    },
    {
      "epoch": 1.8917996416076457,
      "grad_norm": 0.257069855928421,
      "learning_rate": 3.108200358392355e-05,
      "loss": 0.0024,
      "step": 22170
    },
    {
      "epoch": 1.892652956736923,
      "grad_norm": 0.06694386899471283,
      "learning_rate": 3.1073470432630776e-05,
      "loss": 0.0025,
      "step": 22180
    },
    {
      "epoch": 1.8935062718662001,
      "grad_norm": 0.15070827305316925,
      "learning_rate": 3.1064937281338e-05,
      "loss": 0.0037,
      "step": 22190
    },
    {
      "epoch": 1.8943595869954775,
      "grad_norm": 0.03646070510149002,
      "learning_rate": 3.1056404130045227e-05,
      "loss": 0.0026,
      "step": 22200
    },
    {
      "epoch": 1.8952129021247548,
      "grad_norm": 0.211500346660614,
      "learning_rate": 3.1047870978752455e-05,
      "loss": 0.0028,
      "step": 22210
    },
    {
      "epoch": 1.896066217254032,
      "grad_norm": 0.15722016990184784,
      "learning_rate": 3.1039337827459683e-05,
      "loss": 0.0021,
      "step": 22220
    },
    {
      "epoch": 1.896919532383309,
      "grad_norm": 0.4242366850376129,
      "learning_rate": 3.1030804676166905e-05,
      "loss": 0.0023,
      "step": 22230
    },
    {
      "epoch": 1.8977728475125863,
      "grad_norm": 0.29640069603919983,
      "learning_rate": 3.1022271524874134e-05,
      "loss": 0.0032,
      "step": 22240
    },
    {
      "epoch": 1.8986261626418637,
      "grad_norm": 0.3278518617153168,
      "learning_rate": 3.101373837358136e-05,
      "loss": 0.0024,
      "step": 22250
    },
    {
      "epoch": 1.8994794777711408,
      "grad_norm": 0.2618659734725952,
      "learning_rate": 3.100520522228859e-05,
      "loss": 0.0022,
      "step": 22260
    },
    {
      "epoch": 1.9003327929004181,
      "grad_norm": 0.34632328152656555,
      "learning_rate": 3.099667207099582e-05,
      "loss": 0.0025,
      "step": 22270
    },
    {
      "epoch": 1.9011861080296955,
      "grad_norm": 0.04267974570393562,
      "learning_rate": 3.098813891970305e-05,
      "loss": 0.0023,
      "step": 22280
    },
    {
      "epoch": 1.9020394231589726,
      "grad_norm": 0.13525140285491943,
      "learning_rate": 3.0979605768410276e-05,
      "loss": 0.003,
      "step": 22290
    },
    {
      "epoch": 1.90289273828825,
      "grad_norm": 0.2093064934015274,
      "learning_rate": 3.0971072617117505e-05,
      "loss": 0.0027,
      "step": 22300
    },
    {
      "epoch": 1.9037460534175272,
      "grad_norm": 0.18813881278038025,
      "learning_rate": 3.096253946582473e-05,
      "loss": 0.0028,
      "step": 22310
    },
    {
      "epoch": 1.9045993685468043,
      "grad_norm": 0.06860450655221939,
      "learning_rate": 3.0954006314531955e-05,
      "loss": 0.0022,
      "step": 22320
    },
    {
      "epoch": 1.9054526836760814,
      "grad_norm": 0.29554229974746704,
      "learning_rate": 3.094547316323918e-05,
      "loss": 0.0025,
      "step": 22330
    },
    {
      "epoch": 1.9063059988053588,
      "grad_norm": 0.3460446298122406,
      "learning_rate": 3.093694001194641e-05,
      "loss": 0.003,
      "step": 22340
    },
    {
      "epoch": 1.9071593139346361,
      "grad_norm": 0.36457809805870056,
      "learning_rate": 3.092840686065364e-05,
      "loss": 0.0025,
      "step": 22350
    },
    {
      "epoch": 1.9080126290639132,
      "grad_norm": 0.12190493196249008,
      "learning_rate": 3.091987370936087e-05,
      "loss": 0.0028,
      "step": 22360
    },
    {
      "epoch": 1.9088659441931906,
      "grad_norm": 0.48469752073287964,
      "learning_rate": 3.09113405580681e-05,
      "loss": 0.0021,
      "step": 22370
    },
    {
      "epoch": 1.9097192593224679,
      "grad_norm": 0.30643516778945923,
      "learning_rate": 3.0902807406775326e-05,
      "loss": 0.0022,
      "step": 22380
    },
    {
      "epoch": 1.910572574451745,
      "grad_norm": 0.1019262820482254,
      "learning_rate": 3.0894274255482554e-05,
      "loss": 0.0032,
      "step": 22390
    },
    {
      "epoch": 1.911425889581022,
      "grad_norm": 0.2186717987060547,
      "learning_rate": 3.088574110418978e-05,
      "loss": 0.0032,
      "step": 22400
    },
    {
      "epoch": 1.9122792047102997,
      "grad_norm": 0.2502758502960205,
      "learning_rate": 3.087720795289701e-05,
      "loss": 0.0023,
      "step": 22410
    },
    {
      "epoch": 1.9131325198395768,
      "grad_norm": 0.1820799708366394,
      "learning_rate": 3.086867480160423e-05,
      "loss": 0.0028,
      "step": 22420
    },
    {
      "epoch": 1.9139858349688539,
      "grad_norm": 0.2746397852897644,
      "learning_rate": 3.086014165031146e-05,
      "loss": 0.0034,
      "step": 22430
    },
    {
      "epoch": 1.9148391500981312,
      "grad_norm": 0.14091132581233978,
      "learning_rate": 3.085160849901869e-05,
      "loss": 0.0029,
      "step": 22440
    },
    {
      "epoch": 1.9156924652274085,
      "grad_norm": 0.1534264236688614,
      "learning_rate": 3.084307534772592e-05,
      "loss": 0.0027,
      "step": 22450
    },
    {
      "epoch": 1.9165457803566857,
      "grad_norm": 0.26499509811401367,
      "learning_rate": 3.083454219643314e-05,
      "loss": 0.0021,
      "step": 22460
    },
    {
      "epoch": 1.917399095485963,
      "grad_norm": 0.09902649372816086,
      "learning_rate": 3.082600904514037e-05,
      "loss": 0.0019,
      "step": 22470
    },
    {
      "epoch": 1.9182524106152403,
      "grad_norm": 0.4050838053226471,
      "learning_rate": 3.08174758938476e-05,
      "loss": 0.0022,
      "step": 22480
    },
    {
      "epoch": 1.9191057257445174,
      "grad_norm": 0.4808467924594879,
      "learning_rate": 3.0808942742554825e-05,
      "loss": 0.0025,
      "step": 22490
    },
    {
      "epoch": 1.9199590408737945,
      "grad_norm": 0.13585199415683746,
      "learning_rate": 3.0800409591262054e-05,
      "loss": 0.0029,
      "step": 22500
    },
    {
      "epoch": 1.920812356003072,
      "grad_norm": 0.07751889526844025,
      "learning_rate": 3.079187643996928e-05,
      "loss": 0.0026,
      "step": 22510
    },
    {
      "epoch": 1.9216656711323492,
      "grad_norm": 0.05568211153149605,
      "learning_rate": 3.078334328867651e-05,
      "loss": 0.0024,
      "step": 22520
    },
    {
      "epoch": 1.9225189862616263,
      "grad_norm": 0.13759158551692963,
      "learning_rate": 3.077481013738374e-05,
      "loss": 0.0025,
      "step": 22530
    },
    {
      "epoch": 1.9233723013909036,
      "grad_norm": 0.32600709795951843,
      "learning_rate": 3.076627698609096e-05,
      "loss": 0.0038,
      "step": 22540
    },
    {
      "epoch": 1.924225616520181,
      "grad_norm": 0.05663534253835678,
      "learning_rate": 3.075774383479819e-05,
      "loss": 0.0027,
      "step": 22550
    },
    {
      "epoch": 1.925078931649458,
      "grad_norm": 0.13655604422092438,
      "learning_rate": 3.074921068350542e-05,
      "loss": 0.0025,
      "step": 22560
    },
    {
      "epoch": 1.9259322467787354,
      "grad_norm": 0.15401555597782135,
      "learning_rate": 3.0740677532212646e-05,
      "loss": 0.0024,
      "step": 22570
    },
    {
      "epoch": 1.9267855619080128,
      "grad_norm": 0.19965693354606628,
      "learning_rate": 3.0732144380919875e-05,
      "loss": 0.0028,
      "step": 22580
    },
    {
      "epoch": 1.9276388770372899,
      "grad_norm": 0.10513429343700409,
      "learning_rate": 3.0723611229627103e-05,
      "loss": 0.0029,
      "step": 22590
    },
    {
      "epoch": 1.928492192166567,
      "grad_norm": 0.28397566080093384,
      "learning_rate": 3.071507807833433e-05,
      "loss": 0.0036,
      "step": 22600
    },
    {
      "epoch": 1.9293455072958443,
      "grad_norm": 0.059818334877491,
      "learning_rate": 3.070654492704156e-05,
      "loss": 0.0028,
      "step": 22610
    },
    {
      "epoch": 1.9301988224251216,
      "grad_norm": 0.21962209045886993,
      "learning_rate": 3.069801177574879e-05,
      "loss": 0.0021,
      "step": 22620
    },
    {
      "epoch": 1.9310521375543988,
      "grad_norm": 0.12331461161375046,
      "learning_rate": 3.068947862445602e-05,
      "loss": 0.0026,
      "step": 22630
    },
    {
      "epoch": 1.931905452683676,
      "grad_norm": 0.44265639781951904,
      "learning_rate": 3.068094547316324e-05,
      "loss": 0.0032,
      "step": 22640
    },
    {
      "epoch": 1.9327587678129534,
      "grad_norm": 0.5035596489906311,
      "learning_rate": 3.067241232187047e-05,
      "loss": 0.0023,
      "step": 22650
    },
    {
      "epoch": 1.9336120829422305,
      "grad_norm": 0.23816730082035065,
      "learning_rate": 3.0663879170577696e-05,
      "loss": 0.0027,
      "step": 22660
    },
    {
      "epoch": 1.9344653980715079,
      "grad_norm": 0.3101682960987091,
      "learning_rate": 3.0655346019284924e-05,
      "loss": 0.002,
      "step": 22670
    },
    {
      "epoch": 1.9353187132007852,
      "grad_norm": 0.1363983005285263,
      "learning_rate": 3.064681286799215e-05,
      "loss": 0.0039,
      "step": 22680
    },
    {
      "epoch": 1.9361720283300623,
      "grad_norm": 0.38267216086387634,
      "learning_rate": 3.063827971669938e-05,
      "loss": 0.0025,
      "step": 22690
    },
    {
      "epoch": 1.9370253434593394,
      "grad_norm": 0.0963214859366417,
      "learning_rate": 3.062974656540661e-05,
      "loss": 0.0028,
      "step": 22700
    },
    {
      "epoch": 1.9378786585886167,
      "grad_norm": 0.19855563342571259,
      "learning_rate": 3.062121341411384e-05,
      "loss": 0.0034,
      "step": 22710
    },
    {
      "epoch": 1.938731973717894,
      "grad_norm": 0.11199720948934555,
      "learning_rate": 3.061268026282107e-05,
      "loss": 0.0022,
      "step": 22720
    },
    {
      "epoch": 1.9395852888471712,
      "grad_norm": 0.0674595981836319,
      "learning_rate": 3.060414711152829e-05,
      "loss": 0.0023,
      "step": 22730
    },
    {
      "epoch": 1.9404386039764485,
      "grad_norm": 0.041318513453006744,
      "learning_rate": 3.059561396023552e-05,
      "loss": 0.0023,
      "step": 22740
    },
    {
      "epoch": 1.9412919191057258,
      "grad_norm": 0.3067317008972168,
      "learning_rate": 3.058708080894274e-05,
      "loss": 0.0022,
      "step": 22750
    },
    {
      "epoch": 1.942145234235003,
      "grad_norm": 0.2114986926317215,
      "learning_rate": 3.057854765764997e-05,
      "loss": 0.0022,
      "step": 22760
    },
    {
      "epoch": 1.94299854936428,
      "grad_norm": 0.22310367226600647,
      "learning_rate": 3.0570014506357196e-05,
      "loss": 0.0025,
      "step": 22770
    },
    {
      "epoch": 1.9438518644935576,
      "grad_norm": 0.17115242779254913,
      "learning_rate": 3.0561481355064424e-05,
      "loss": 0.0018,
      "step": 22780
    },
    {
      "epoch": 1.9447051796228347,
      "grad_norm": 0.07293028384447098,
      "learning_rate": 3.055294820377165e-05,
      "loss": 0.0025,
      "step": 22790
    },
    {
      "epoch": 1.9455584947521118,
      "grad_norm": 0.11470065265893936,
      "learning_rate": 3.054441505247888e-05,
      "loss": 0.0028,
      "step": 22800
    },
    {
      "epoch": 1.9464118098813892,
      "grad_norm": 0.040000658482313156,
      "learning_rate": 3.053588190118611e-05,
      "loss": 0.0026,
      "step": 22810
    },
    {
      "epoch": 1.9472651250106665,
      "grad_norm": 0.08749505877494812,
      "learning_rate": 3.052734874989334e-05,
      "loss": 0.0023,
      "step": 22820
    },
    {
      "epoch": 1.9481184401399436,
      "grad_norm": 0.15325438976287842,
      "learning_rate": 3.051881559860057e-05,
      "loss": 0.0029,
      "step": 22830
    },
    {
      "epoch": 1.948971755269221,
      "grad_norm": 0.16693221032619476,
      "learning_rate": 3.0510282447307792e-05,
      "loss": 0.0022,
      "step": 22840
    },
    {
      "epoch": 1.9498250703984983,
      "grad_norm": 0.3471677899360657,
      "learning_rate": 3.050174929601502e-05,
      "loss": 0.0032,
      "step": 22850
    },
    {
      "epoch": 1.9506783855277754,
      "grad_norm": 0.19344216585159302,
      "learning_rate": 3.049321614472225e-05,
      "loss": 0.0028,
      "step": 22860
    },
    {
      "epoch": 1.9515317006570525,
      "grad_norm": 0.06666615605354309,
      "learning_rate": 3.0484682993429474e-05,
      "loss": 0.0023,
      "step": 22870
    },
    {
      "epoch": 1.95238501578633,
      "grad_norm": 0.2480751872062683,
      "learning_rate": 3.0476149842136702e-05,
      "loss": 0.0023,
      "step": 22880
    },
    {
      "epoch": 1.9532383309156072,
      "grad_norm": 0.4850504994392395,
      "learning_rate": 3.046761669084393e-05,
      "loss": 0.0032,
      "step": 22890
    },
    {
      "epoch": 1.9540916460448843,
      "grad_norm": 0.2431584894657135,
      "learning_rate": 3.045908353955116e-05,
      "loss": 0.0021,
      "step": 22900
    },
    {
      "epoch": 1.9549449611741616,
      "grad_norm": 0.14608608186244965,
      "learning_rate": 3.0450550388258388e-05,
      "loss": 0.0034,
      "step": 22910
    },
    {
      "epoch": 1.955798276303439,
      "grad_norm": 0.5760728120803833,
      "learning_rate": 3.0442017236965613e-05,
      "loss": 0.0026,
      "step": 22920
    },
    {
      "epoch": 1.956651591432716,
      "grad_norm": 0.2513940632343292,
      "learning_rate": 3.043348408567284e-05,
      "loss": 0.0027,
      "step": 22930
    },
    {
      "epoch": 1.9575049065619934,
      "grad_norm": 0.4110165536403656,
      "learning_rate": 3.042495093438007e-05,
      "loss": 0.0036,
      "step": 22940
    },
    {
      "epoch": 1.9583582216912707,
      "grad_norm": 0.5213162899017334,
      "learning_rate": 3.0416417783087298e-05,
      "loss": 0.0022,
      "step": 22950
    },
    {
      "epoch": 1.9592115368205478,
      "grad_norm": 0.2182103991508484,
      "learning_rate": 3.0407884631794527e-05,
      "loss": 0.002,
      "step": 22960
    },
    {
      "epoch": 1.960064851949825,
      "grad_norm": 0.03734090179204941,
      "learning_rate": 3.0399351480501752e-05,
      "loss": 0.0027,
      "step": 22970
    },
    {
      "epoch": 1.9609181670791023,
      "grad_norm": 0.40273404121398926,
      "learning_rate": 3.039081832920898e-05,
      "loss": 0.004,
      "step": 22980
    },
    {
      "epoch": 1.9617714822083796,
      "grad_norm": 0.044780366122722626,
      "learning_rate": 3.0382285177916202e-05,
      "loss": 0.0021,
      "step": 22990
    },
    {
      "epoch": 1.9626247973376567,
      "grad_norm": 0.156965970993042,
      "learning_rate": 3.037375202662343e-05,
      "loss": 0.0024,
      "step": 23000
    },
    {
      "epoch": 1.963478112466934,
      "grad_norm": 0.22158515453338623,
      "learning_rate": 3.036521887533066e-05,
      "loss": 0.002,
      "step": 23010
    },
    {
      "epoch": 1.9643314275962114,
      "grad_norm": 0.2015695571899414,
      "learning_rate": 3.0356685724037887e-05,
      "loss": 0.0019,
      "step": 23020
    },
    {
      "epoch": 1.9651847427254885,
      "grad_norm": 0.1724226176738739,
      "learning_rate": 3.0348152572745116e-05,
      "loss": 0.0032,
      "step": 23030
    },
    {
      "epoch": 1.9660380578547658,
      "grad_norm": 0.20174911618232727,
      "learning_rate": 3.033961942145234e-05,
      "loss": 0.0032,
      "step": 23040
    },
    {
      "epoch": 1.9668913729840432,
      "grad_norm": 0.08353573083877563,
      "learning_rate": 3.033108627015957e-05,
      "loss": 0.0029,
      "step": 23050
    },
    {
      "epoch": 1.9677446881133203,
      "grad_norm": 0.22069309651851654,
      "learning_rate": 3.0322553118866798e-05,
      "loss": 0.002,
      "step": 23060
    },
    {
      "epoch": 1.9685980032425974,
      "grad_norm": 0.2931056022644043,
      "learning_rate": 3.0314019967574027e-05,
      "loss": 0.0029,
      "step": 23070
    },
    {
      "epoch": 1.9694513183718747,
      "grad_norm": 0.07998503744602203,
      "learning_rate": 3.0305486816281255e-05,
      "loss": 0.0025,
      "step": 23080
    },
    {
      "epoch": 1.970304633501152,
      "grad_norm": 0.0436309315264225,
      "learning_rate": 3.029695366498848e-05,
      "loss": 0.0031,
      "step": 23090
    },
    {
      "epoch": 1.9711579486304291,
      "grad_norm": 0.08995899558067322,
      "learning_rate": 3.028842051369571e-05,
      "loss": 0.0025,
      "step": 23100
    },
    {
      "epoch": 1.9720112637597065,
      "grad_norm": 0.07529615610837936,
      "learning_rate": 3.0279887362402937e-05,
      "loss": 0.002,
      "step": 23110
    },
    {
      "epoch": 1.9728645788889838,
      "grad_norm": 0.050091058015823364,
      "learning_rate": 3.0271354211110166e-05,
      "loss": 0.0023,
      "step": 23120
    },
    {
      "epoch": 1.973717894018261,
      "grad_norm": 0.23103374242782593,
      "learning_rate": 3.026282105981739e-05,
      "loss": 0.0032,
      "step": 23130
    },
    {
      "epoch": 1.974571209147538,
      "grad_norm": 0.04124391824007034,
      "learning_rate": 3.025428790852462e-05,
      "loss": 0.0034,
      "step": 23140
    },
    {
      "epoch": 1.9754245242768156,
      "grad_norm": 0.0338871143758297,
      "learning_rate": 3.0245754757231848e-05,
      "loss": 0.0024,
      "step": 23150
    },
    {
      "epoch": 1.9762778394060927,
      "grad_norm": 0.3302111327648163,
      "learning_rate": 3.0237221605939076e-05,
      "loss": 0.0027,
      "step": 23160
    },
    {
      "epoch": 1.9771311545353698,
      "grad_norm": 0.12060213834047318,
      "learning_rate": 3.0228688454646305e-05,
      "loss": 0.003,
      "step": 23170
    },
    {
      "epoch": 1.9779844696646471,
      "grad_norm": 0.22924180328845978,
      "learning_rate": 3.022015530335353e-05,
      "loss": 0.0027,
      "step": 23180
    },
    {
      "epoch": 1.9788377847939245,
      "grad_norm": 0.2910570204257965,
      "learning_rate": 3.0211622152060758e-05,
      "loss": 0.0031,
      "step": 23190
    },
    {
      "epoch": 1.9796910999232016,
      "grad_norm": 0.10802372545003891,
      "learning_rate": 3.0203089000767987e-05,
      "loss": 0.003,
      "step": 23200
    },
    {
      "epoch": 1.980544415052479,
      "grad_norm": 0.13743902742862701,
      "learning_rate": 3.0194555849475215e-05,
      "loss": 0.0023,
      "step": 23210
    },
    {
      "epoch": 1.9813977301817562,
      "grad_norm": 0.10360890626907349,
      "learning_rate": 3.0186022698182444e-05,
      "loss": 0.0028,
      "step": 23220
    },
    {
      "epoch": 1.9822510453110334,
      "grad_norm": 0.12209852039813995,
      "learning_rate": 3.017748954688967e-05,
      "loss": 0.002,
      "step": 23230
    },
    {
      "epoch": 1.9831043604403105,
      "grad_norm": 0.030445728451013565,
      "learning_rate": 3.0168956395596897e-05,
      "loss": 0.0026,
      "step": 23240
    },
    {
      "epoch": 1.9839576755695878,
      "grad_norm": 0.08100911974906921,
      "learning_rate": 3.0160423244304126e-05,
      "loss": 0.0032,
      "step": 23250
    },
    {
      "epoch": 1.9848109906988651,
      "grad_norm": 0.2937699854373932,
      "learning_rate": 3.0151890093011347e-05,
      "loss": 0.0029,
      "step": 23260
    },
    {
      "epoch": 1.9856643058281422,
      "grad_norm": 0.28792938590049744,
      "learning_rate": 3.0143356941718576e-05,
      "loss": 0.0028,
      "step": 23270
    },
    {
      "epoch": 1.9865176209574196,
      "grad_norm": 0.11729101091623306,
      "learning_rate": 3.0134823790425804e-05,
      "loss": 0.0024,
      "step": 23280
    },
    {
      "epoch": 1.987370936086697,
      "grad_norm": 0.25651079416275024,
      "learning_rate": 3.0126290639133033e-05,
      "loss": 0.0025,
      "step": 23290
    },
    {
      "epoch": 1.988224251215974,
      "grad_norm": 0.27505016326904297,
      "learning_rate": 3.0117757487840258e-05,
      "loss": 0.0028,
      "step": 23300
    },
    {
      "epoch": 1.9890775663452513,
      "grad_norm": 0.21518829464912415,
      "learning_rate": 3.0109224336547486e-05,
      "loss": 0.0032,
      "step": 23310
    },
    {
      "epoch": 1.9899308814745287,
      "grad_norm": 0.08715155720710754,
      "learning_rate": 3.0100691185254715e-05,
      "loss": 0.0024,
      "step": 23320
    },
    {
      "epoch": 1.9907841966038058,
      "grad_norm": 0.2562527358531952,
      "learning_rate": 3.0092158033961943e-05,
      "loss": 0.0022,
      "step": 23330
    },
    {
      "epoch": 1.991637511733083,
      "grad_norm": 0.05314893648028374,
      "learning_rate": 3.0083624882669172e-05,
      "loss": 0.0023,
      "step": 23340
    },
    {
      "epoch": 1.9924908268623602,
      "grad_norm": 0.25763699412345886,
      "learning_rate": 3.0075091731376397e-05,
      "loss": 0.0025,
      "step": 23350
    },
    {
      "epoch": 1.9933441419916376,
      "grad_norm": 0.12364229559898376,
      "learning_rate": 3.0066558580083625e-05,
      "loss": 0.0029,
      "step": 23360
    },
    {
      "epoch": 1.9941974571209147,
      "grad_norm": 0.2924642562866211,
      "learning_rate": 3.0058025428790854e-05,
      "loss": 0.0025,
      "step": 23370
    },
    {
      "epoch": 1.995050772250192,
      "grad_norm": 0.16979649662971497,
      "learning_rate": 3.0049492277498082e-05,
      "loss": 0.0026,
      "step": 23380
    },
    {
      "epoch": 1.9959040873794693,
      "grad_norm": 0.09840501844882965,
      "learning_rate": 3.004095912620531e-05,
      "loss": 0.003,
      "step": 23390
    },
    {
      "epoch": 1.9967574025087464,
      "grad_norm": 0.08591669797897339,
      "learning_rate": 3.0032425974912536e-05,
      "loss": 0.0025,
      "step": 23400
    },
    {
      "epoch": 1.9976107176380236,
      "grad_norm": 0.28072378039360046,
      "learning_rate": 3.0023892823619764e-05,
      "loss": 0.0028,
      "step": 23410
    },
    {
      "epoch": 1.9984640327673011,
      "grad_norm": 0.09850146621465683,
      "learning_rate": 3.0015359672326993e-05,
      "loss": 0.0026,
      "step": 23420
    },
    {
      "epoch": 1.9993173478965782,
      "grad_norm": 0.05519896000623703,
      "learning_rate": 3.000682652103422e-05,
      "loss": 0.0032,
      "step": 23430
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.002591182477772236,
      "eval_runtime": 108.0073,
      "eval_samples_per_second": 1388.795,
      "eval_steps_per_second": 21.702,
      "step": 23438
    },
    {
      "epoch": 2.0001706630258553,
      "grad_norm": 0.16962483525276184,
      "learning_rate": 2.9998293369741446e-05,
      "loss": 0.0023,
      "step": 23440
    },
    {
      "epoch": 2.001023978155133,
      "grad_norm": 0.2804461419582367,
      "learning_rate": 2.9989760218448675e-05,
      "loss": 0.0028,
      "step": 23450
    },
    {
      "epoch": 2.00187729328441,
      "grad_norm": 0.14068493247032166,
      "learning_rate": 2.9981227067155903e-05,
      "loss": 0.0026,
      "step": 23460
    },
    {
      "epoch": 2.002730608413687,
      "grad_norm": 0.3363780975341797,
      "learning_rate": 2.9972693915863132e-05,
      "loss": 0.0037,
      "step": 23470
    },
    {
      "epoch": 2.003583923542964,
      "grad_norm": 0.39334243535995483,
      "learning_rate": 2.996416076457036e-05,
      "loss": 0.0031,
      "step": 23480
    },
    {
      "epoch": 2.0044372386722418,
      "grad_norm": 0.25668349862098694,
      "learning_rate": 2.9955627613277585e-05,
      "loss": 0.0032,
      "step": 23490
    },
    {
      "epoch": 2.005290553801519,
      "grad_norm": 0.37973493337631226,
      "learning_rate": 2.9947094461984814e-05,
      "loss": 0.0032,
      "step": 23500
    },
    {
      "epoch": 2.006143868930796,
      "grad_norm": 0.49651262164115906,
      "learning_rate": 2.9938561310692042e-05,
      "loss": 0.0018,
      "step": 23510
    },
    {
      "epoch": 2.0069971840600735,
      "grad_norm": 0.2938813269138336,
      "learning_rate": 2.9930028159399264e-05,
      "loss": 0.0021,
      "step": 23520
    },
    {
      "epoch": 2.0078504991893507,
      "grad_norm": 0.21360482275485992,
      "learning_rate": 2.9921495008106493e-05,
      "loss": 0.0028,
      "step": 23530
    },
    {
      "epoch": 2.0087038143186278,
      "grad_norm": 0.23121511936187744,
      "learning_rate": 2.991296185681372e-05,
      "loss": 0.0031,
      "step": 23540
    },
    {
      "epoch": 2.0095571294479053,
      "grad_norm": 0.22566603124141693,
      "learning_rate": 2.990442870552095e-05,
      "loss": 0.0018,
      "step": 23550
    },
    {
      "epoch": 2.0104104445771824,
      "grad_norm": 0.22304478287696838,
      "learning_rate": 2.9895895554228175e-05,
      "loss": 0.0015,
      "step": 23560
    },
    {
      "epoch": 2.0112637597064595,
      "grad_norm": 0.09790756553411484,
      "learning_rate": 2.9887362402935403e-05,
      "loss": 0.0032,
      "step": 23570
    },
    {
      "epoch": 2.0121170748357367,
      "grad_norm": 0.08174479007720947,
      "learning_rate": 2.987882925164263e-05,
      "loss": 0.0024,
      "step": 23580
    },
    {
      "epoch": 2.012970389965014,
      "grad_norm": 0.11488410830497742,
      "learning_rate": 2.987029610034986e-05,
      "loss": 0.0022,
      "step": 23590
    },
    {
      "epoch": 2.0138237050942913,
      "grad_norm": 0.16975057125091553,
      "learning_rate": 2.986176294905709e-05,
      "loss": 0.0018,
      "step": 23600
    },
    {
      "epoch": 2.0146770202235684,
      "grad_norm": 0.25071972608566284,
      "learning_rate": 2.9853229797764314e-05,
      "loss": 0.003,
      "step": 23610
    },
    {
      "epoch": 2.015530335352846,
      "grad_norm": 0.13590672612190247,
      "learning_rate": 2.9844696646471542e-05,
      "loss": 0.0025,
      "step": 23620
    },
    {
      "epoch": 2.016383650482123,
      "grad_norm": 0.17120976746082306,
      "learning_rate": 2.983616349517877e-05,
      "loss": 0.0021,
      "step": 23630
    },
    {
      "epoch": 2.0172369656114,
      "grad_norm": 0.18007385730743408,
      "learning_rate": 2.9827630343886e-05,
      "loss": 0.0031,
      "step": 23640
    },
    {
      "epoch": 2.0180902807406778,
      "grad_norm": 0.23384790122509003,
      "learning_rate": 2.9819097192593228e-05,
      "loss": 0.0021,
      "step": 23650
    },
    {
      "epoch": 2.018943595869955,
      "grad_norm": 0.1332949995994568,
      "learning_rate": 2.9810564041300453e-05,
      "loss": 0.0023,
      "step": 23660
    },
    {
      "epoch": 2.019796910999232,
      "grad_norm": 0.07183874398469925,
      "learning_rate": 2.980203089000768e-05,
      "loss": 0.0022,
      "step": 23670
    },
    {
      "epoch": 2.020650226128509,
      "grad_norm": 0.09070102125406265,
      "learning_rate": 2.979349773871491e-05,
      "loss": 0.0026,
      "step": 23680
    },
    {
      "epoch": 2.0215035412577866,
      "grad_norm": 0.45742061734199524,
      "learning_rate": 2.9784964587422138e-05,
      "loss": 0.0032,
      "step": 23690
    },
    {
      "epoch": 2.0223568563870638,
      "grad_norm": 0.08001542836427689,
      "learning_rate": 2.9776431436129367e-05,
      "loss": 0.0033,
      "step": 23700
    },
    {
      "epoch": 2.023210171516341,
      "grad_norm": 0.07068311423063278,
      "learning_rate": 2.9767898284836592e-05,
      "loss": 0.003,
      "step": 23710
    },
    {
      "epoch": 2.0240634866456184,
      "grad_norm": 0.048985354602336884,
      "learning_rate": 2.975936513354382e-05,
      "loss": 0.0023,
      "step": 23720
    },
    {
      "epoch": 2.0249168017748955,
      "grad_norm": 0.17378364503383636,
      "learning_rate": 2.975083198225105e-05,
      "loss": 0.0029,
      "step": 23730
    },
    {
      "epoch": 2.0257701169041726,
      "grad_norm": 0.3344428241252899,
      "learning_rate": 2.9742298830958277e-05,
      "loss": 0.0017,
      "step": 23740
    },
    {
      "epoch": 2.0266234320334497,
      "grad_norm": 0.2673044204711914,
      "learning_rate": 2.9733765679665502e-05,
      "loss": 0.0032,
      "step": 23750
    },
    {
      "epoch": 2.0274767471627273,
      "grad_norm": 0.1469123363494873,
      "learning_rate": 2.972523252837273e-05,
      "loss": 0.0023,
      "step": 23760
    },
    {
      "epoch": 2.0283300622920044,
      "grad_norm": 0.026513781398534775,
      "learning_rate": 2.971669937707996e-05,
      "loss": 0.0032,
      "step": 23770
    },
    {
      "epoch": 2.0291833774212815,
      "grad_norm": 0.09550844132900238,
      "learning_rate": 2.9708166225787188e-05,
      "loss": 0.0021,
      "step": 23780
    },
    {
      "epoch": 2.030036692550559,
      "grad_norm": 0.07858295738697052,
      "learning_rate": 2.969963307449441e-05,
      "loss": 0.0028,
      "step": 23790
    },
    {
      "epoch": 2.030890007679836,
      "grad_norm": 0.11493939161300659,
      "learning_rate": 2.9691099923201638e-05,
      "loss": 0.0022,
      "step": 23800
    },
    {
      "epoch": 2.0317433228091133,
      "grad_norm": 0.2153087854385376,
      "learning_rate": 2.9682566771908866e-05,
      "loss": 0.0026,
      "step": 23810
    },
    {
      "epoch": 2.032596637938391,
      "grad_norm": 0.26211419701576233,
      "learning_rate": 2.967403362061609e-05,
      "loss": 0.0024,
      "step": 23820
    },
    {
      "epoch": 2.033449953067668,
      "grad_norm": 0.039335962384939194,
      "learning_rate": 2.966550046932332e-05,
      "loss": 0.0026,
      "step": 23830
    },
    {
      "epoch": 2.034303268196945,
      "grad_norm": 0.35080817341804504,
      "learning_rate": 2.965696731803055e-05,
      "loss": 0.0024,
      "step": 23840
    },
    {
      "epoch": 2.035156583326222,
      "grad_norm": 0.34186288714408875,
      "learning_rate": 2.9648434166737777e-05,
      "loss": 0.0025,
      "step": 23850
    },
    {
      "epoch": 2.0360098984554997,
      "grad_norm": 0.11793994158506393,
      "learning_rate": 2.9639901015445005e-05,
      "loss": 0.0029,
      "step": 23860
    },
    {
      "epoch": 2.036863213584777,
      "grad_norm": 0.2360747903585434,
      "learning_rate": 2.963136786415223e-05,
      "loss": 0.0018,
      "step": 23870
    },
    {
      "epoch": 2.037716528714054,
      "grad_norm": 0.26972976326942444,
      "learning_rate": 2.962283471285946e-05,
      "loss": 0.0022,
      "step": 23880
    },
    {
      "epoch": 2.0385698438433315,
      "grad_norm": 0.13254497945308685,
      "learning_rate": 2.9614301561566687e-05,
      "loss": 0.0027,
      "step": 23890
    },
    {
      "epoch": 2.0394231589726086,
      "grad_norm": 0.2135302722454071,
      "learning_rate": 2.9605768410273916e-05,
      "loss": 0.003,
      "step": 23900
    },
    {
      "epoch": 2.0402764741018857,
      "grad_norm": 0.35265907645225525,
      "learning_rate": 2.9597235258981144e-05,
      "loss": 0.0024,
      "step": 23910
    },
    {
      "epoch": 2.0411297892311633,
      "grad_norm": 0.2725391685962677,
      "learning_rate": 2.958870210768837e-05,
      "loss": 0.0019,
      "step": 23920
    },
    {
      "epoch": 2.0419831043604404,
      "grad_norm": 0.0847197026014328,
      "learning_rate": 2.9580168956395598e-05,
      "loss": 0.0018,
      "step": 23930
    },
    {
      "epoch": 2.0428364194897175,
      "grad_norm": 0.28914937376976013,
      "learning_rate": 2.9571635805102827e-05,
      "loss": 0.0027,
      "step": 23940
    },
    {
      "epoch": 2.0436897346189946,
      "grad_norm": 0.21394865214824677,
      "learning_rate": 2.9563102653810055e-05,
      "loss": 0.0025,
      "step": 23950
    },
    {
      "epoch": 2.044543049748272,
      "grad_norm": 0.05594777688384056,
      "learning_rate": 2.9554569502517283e-05,
      "loss": 0.0028,
      "step": 23960
    },
    {
      "epoch": 2.0453963648775493,
      "grad_norm": 0.07174781709909439,
      "learning_rate": 2.954603635122451e-05,
      "loss": 0.002,
      "step": 23970
    },
    {
      "epoch": 2.0462496800068264,
      "grad_norm": 0.09914639592170715,
      "learning_rate": 2.9537503199931737e-05,
      "loss": 0.0031,
      "step": 23980
    },
    {
      "epoch": 2.047102995136104,
      "grad_norm": 0.03481530025601387,
      "learning_rate": 2.9528970048638966e-05,
      "loss": 0.0032,
      "step": 23990
    },
    {
      "epoch": 2.047956310265381,
      "grad_norm": 0.236125648021698,
      "learning_rate": 2.9520436897346194e-05,
      "loss": 0.0034,
      "step": 24000
    },
    {
      "epoch": 2.048809625394658,
      "grad_norm": 0.05748912692070007,
      "learning_rate": 2.9511903746053422e-05,
      "loss": 0.0027,
      "step": 24010
    },
    {
      "epoch": 2.0496629405239353,
      "grad_norm": 0.10254746675491333,
      "learning_rate": 2.9503370594760648e-05,
      "loss": 0.002,
      "step": 24020
    },
    {
      "epoch": 2.050516255653213,
      "grad_norm": 0.20295009016990662,
      "learning_rate": 2.9494837443467876e-05,
      "loss": 0.0027,
      "step": 24030
    },
    {
      "epoch": 2.05136957078249,
      "grad_norm": 0.25157806277275085,
      "learning_rate": 2.9486304292175105e-05,
      "loss": 0.0023,
      "step": 24040
    },
    {
      "epoch": 2.052222885911767,
      "grad_norm": 0.10913776606321335,
      "learning_rate": 2.9477771140882326e-05,
      "loss": 0.0037,
      "step": 24050
    },
    {
      "epoch": 2.0530762010410446,
      "grad_norm": 0.23271897435188293,
      "learning_rate": 2.9469237989589555e-05,
      "loss": 0.0025,
      "step": 24060
    },
    {
      "epoch": 2.0539295161703217,
      "grad_norm": 0.11889103055000305,
      "learning_rate": 2.9460704838296783e-05,
      "loss": 0.0025,
      "step": 24070
    },
    {
      "epoch": 2.054782831299599,
      "grad_norm": 0.07886182516813278,
      "learning_rate": 2.945217168700401e-05,
      "loss": 0.0024,
      "step": 24080
    },
    {
      "epoch": 2.0556361464288764,
      "grad_norm": 0.3888942003250122,
      "learning_rate": 2.9443638535711237e-05,
      "loss": 0.0029,
      "step": 24090
    },
    {
      "epoch": 2.0564894615581535,
      "grad_norm": 0.45699217915534973,
      "learning_rate": 2.9435105384418465e-05,
      "loss": 0.0025,
      "step": 24100
    },
    {
      "epoch": 2.0573427766874306,
      "grad_norm": 0.4672437012195587,
      "learning_rate": 2.9426572233125694e-05,
      "loss": 0.002,
      "step": 24110
    },
    {
      "epoch": 2.0581960918167077,
      "grad_norm": 0.06419451534748077,
      "learning_rate": 2.9418039081832922e-05,
      "loss": 0.0022,
      "step": 24120
    },
    {
      "epoch": 2.0590494069459853,
      "grad_norm": 0.34085965156555176,
      "learning_rate": 2.9409505930540147e-05,
      "loss": 0.0028,
      "step": 24130
    },
    {
      "epoch": 2.0599027220752624,
      "grad_norm": 0.2474902719259262,
      "learning_rate": 2.9400972779247376e-05,
      "loss": 0.0022,
      "step": 24140
    },
    {
      "epoch": 2.0607560372045395,
      "grad_norm": 0.0672110915184021,
      "learning_rate": 2.9392439627954604e-05,
      "loss": 0.0024,
      "step": 24150
    },
    {
      "epoch": 2.061609352333817,
      "grad_norm": 0.1560879945755005,
      "learning_rate": 2.9383906476661833e-05,
      "loss": 0.0026,
      "step": 24160
    },
    {
      "epoch": 2.062462667463094,
      "grad_norm": 0.06973902881145477,
      "learning_rate": 2.937537332536906e-05,
      "loss": 0.0023,
      "step": 24170
    },
    {
      "epoch": 2.0633159825923713,
      "grad_norm": 0.04336729645729065,
      "learning_rate": 2.9366840174076286e-05,
      "loss": 0.0033,
      "step": 24180
    },
    {
      "epoch": 2.064169297721649,
      "grad_norm": 0.08938287198543549,
      "learning_rate": 2.9358307022783515e-05,
      "loss": 0.0026,
      "step": 24190
    },
    {
      "epoch": 2.065022612850926,
      "grad_norm": 0.4630647301673889,
      "learning_rate": 2.9349773871490743e-05,
      "loss": 0.0022,
      "step": 24200
    },
    {
      "epoch": 2.065875927980203,
      "grad_norm": 0.1260087639093399,
      "learning_rate": 2.9341240720197972e-05,
      "loss": 0.0028,
      "step": 24210
    },
    {
      "epoch": 2.06672924310948,
      "grad_norm": 0.06408180296421051,
      "learning_rate": 2.93327075689052e-05,
      "loss": 0.0026,
      "step": 24220
    },
    {
      "epoch": 2.0675825582387577,
      "grad_norm": 0.11921054124832153,
      "learning_rate": 2.9324174417612425e-05,
      "loss": 0.0023,
      "step": 24230
    },
    {
      "epoch": 2.068435873368035,
      "grad_norm": 0.49903246760368347,
      "learning_rate": 2.9315641266319654e-05,
      "loss": 0.0027,
      "step": 24240
    },
    {
      "epoch": 2.069289188497312,
      "grad_norm": 0.47676774859428406,
      "learning_rate": 2.9307108115026882e-05,
      "loss": 0.0026,
      "step": 24250
    },
    {
      "epoch": 2.0701425036265895,
      "grad_norm": 0.25061318278312683,
      "learning_rate": 2.929857496373411e-05,
      "loss": 0.0019,
      "step": 24260
    },
    {
      "epoch": 2.0709958187558666,
      "grad_norm": 0.24236132204532623,
      "learning_rate": 2.929004181244134e-05,
      "loss": 0.0025,
      "step": 24270
    },
    {
      "epoch": 2.0718491338851437,
      "grad_norm": 0.24523791670799255,
      "learning_rate": 2.9281508661148564e-05,
      "loss": 0.0025,
      "step": 24280
    },
    {
      "epoch": 2.072702449014421,
      "grad_norm": 0.23802423477172852,
      "learning_rate": 2.9272975509855793e-05,
      "loss": 0.002,
      "step": 24290
    },
    {
      "epoch": 2.0735557641436984,
      "grad_norm": 0.3333505392074585,
      "learning_rate": 2.926444235856302e-05,
      "loss": 0.0026,
      "step": 24300
    },
    {
      "epoch": 2.0744090792729755,
      "grad_norm": 0.23699955642223358,
      "learning_rate": 2.925590920727025e-05,
      "loss": 0.0029,
      "step": 24310
    },
    {
      "epoch": 2.0752623944022526,
      "grad_norm": 0.2632453739643097,
      "learning_rate": 2.924737605597747e-05,
      "loss": 0.0027,
      "step": 24320
    },
    {
      "epoch": 2.07611570953153,
      "grad_norm": 0.392954558134079,
      "learning_rate": 2.92388429046847e-05,
      "loss": 0.0029,
      "step": 24330
    },
    {
      "epoch": 2.0769690246608072,
      "grad_norm": 0.04184732958674431,
      "learning_rate": 2.9230309753391925e-05,
      "loss": 0.0022,
      "step": 24340
    },
    {
      "epoch": 2.0778223397900843,
      "grad_norm": 0.10708621144294739,
      "learning_rate": 2.9221776602099154e-05,
      "loss": 0.0031,
      "step": 24350
    },
    {
      "epoch": 2.078675654919362,
      "grad_norm": 0.2512860596179962,
      "learning_rate": 2.9213243450806382e-05,
      "loss": 0.0028,
      "step": 24360
    },
    {
      "epoch": 2.079528970048639,
      "grad_norm": 0.028846504166722298,
      "learning_rate": 2.920471029951361e-05,
      "loss": 0.0023,
      "step": 24370
    },
    {
      "epoch": 2.080382285177916,
      "grad_norm": 0.3625882565975189,
      "learning_rate": 2.919617714822084e-05,
      "loss": 0.0034,
      "step": 24380
    },
    {
      "epoch": 2.0812356003071932,
      "grad_norm": 0.19909223914146423,
      "learning_rate": 2.9187643996928064e-05,
      "loss": 0.0023,
      "step": 24390
    },
    {
      "epoch": 2.082088915436471,
      "grad_norm": 0.6455572247505188,
      "learning_rate": 2.9179110845635293e-05,
      "loss": 0.0021,
      "step": 24400
    },
    {
      "epoch": 2.082942230565748,
      "grad_norm": 0.49830880761146545,
      "learning_rate": 2.917057769434252e-05,
      "loss": 0.0025,
      "step": 24410
    },
    {
      "epoch": 2.083795545695025,
      "grad_norm": 0.13332760334014893,
      "learning_rate": 2.916204454304975e-05,
      "loss": 0.0028,
      "step": 24420
    },
    {
      "epoch": 2.0846488608243026,
      "grad_norm": 0.19714005291461945,
      "learning_rate": 2.9153511391756978e-05,
      "loss": 0.0028,
      "step": 24430
    },
    {
      "epoch": 2.0855021759535797,
      "grad_norm": 0.4118764102458954,
      "learning_rate": 2.9144978240464203e-05,
      "loss": 0.0028,
      "step": 24440
    },
    {
      "epoch": 2.086355491082857,
      "grad_norm": 0.03265757113695145,
      "learning_rate": 2.913644508917143e-05,
      "loss": 0.0026,
      "step": 24450
    },
    {
      "epoch": 2.0872088062121343,
      "grad_norm": 0.06641381233930588,
      "learning_rate": 2.912791193787866e-05,
      "loss": 0.003,
      "step": 24460
    },
    {
      "epoch": 2.0880621213414114,
      "grad_norm": 0.11576074361801147,
      "learning_rate": 2.911937878658589e-05,
      "loss": 0.0019,
      "step": 24470
    },
    {
      "epoch": 2.0889154364706886,
      "grad_norm": 0.17468483746051788,
      "learning_rate": 2.9110845635293117e-05,
      "loss": 0.0032,
      "step": 24480
    },
    {
      "epoch": 2.0897687515999657,
      "grad_norm": 0.04747850075364113,
      "learning_rate": 2.9102312484000342e-05,
      "loss": 0.003,
      "step": 24490
    },
    {
      "epoch": 2.0906220667292432,
      "grad_norm": 0.12229887396097183,
      "learning_rate": 2.909377933270757e-05,
      "loss": 0.0023,
      "step": 24500
    },
    {
      "epoch": 2.0914753818585203,
      "grad_norm": 0.11397718638181686,
      "learning_rate": 2.90852461814148e-05,
      "loss": 0.0025,
      "step": 24510
    },
    {
      "epoch": 2.0923286969877974,
      "grad_norm": 0.44508275389671326,
      "learning_rate": 2.9076713030122028e-05,
      "loss": 0.003,
      "step": 24520
    },
    {
      "epoch": 2.093182012117075,
      "grad_norm": 0.24335813522338867,
      "learning_rate": 2.9068179878829256e-05,
      "loss": 0.002,
      "step": 24530
    },
    {
      "epoch": 2.094035327246352,
      "grad_norm": 0.08909834921360016,
      "learning_rate": 2.905964672753648e-05,
      "loss": 0.0038,
      "step": 24540
    },
    {
      "epoch": 2.094888642375629,
      "grad_norm": 0.19148209691047668,
      "learning_rate": 2.905111357624371e-05,
      "loss": 0.0023,
      "step": 24550
    },
    {
      "epoch": 2.0957419575049068,
      "grad_norm": 0.5299301147460938,
      "learning_rate": 2.9042580424950938e-05,
      "loss": 0.0028,
      "step": 24560
    },
    {
      "epoch": 2.096595272634184,
      "grad_norm": 0.24819684028625488,
      "learning_rate": 2.9034047273658167e-05,
      "loss": 0.0026,
      "step": 24570
    },
    {
      "epoch": 2.097448587763461,
      "grad_norm": 0.3374202251434326,
      "learning_rate": 2.9025514122365395e-05,
      "loss": 0.0037,
      "step": 24580
    },
    {
      "epoch": 2.098301902892738,
      "grad_norm": 0.0581054762005806,
      "learning_rate": 2.9016980971072617e-05,
      "loss": 0.0024,
      "step": 24590
    },
    {
      "epoch": 2.0991552180220157,
      "grad_norm": 0.04317115992307663,
      "learning_rate": 2.9008447819779845e-05,
      "loss": 0.0027,
      "step": 24600
    },
    {
      "epoch": 2.1000085331512928,
      "grad_norm": 0.24370819330215454,
      "learning_rate": 2.899991466848707e-05,
      "loss": 0.0028,
      "step": 24610
    },
    {
      "epoch": 2.10086184828057,
      "grad_norm": 0.17644184827804565,
      "learning_rate": 2.89913815171943e-05,
      "loss": 0.0024,
      "step": 24620
    },
    {
      "epoch": 2.1017151634098474,
      "grad_norm": 0.26902222633361816,
      "learning_rate": 2.8982848365901527e-05,
      "loss": 0.0023,
      "step": 24630
    },
    {
      "epoch": 2.1025684785391245,
      "grad_norm": 0.16565269231796265,
      "learning_rate": 2.8974315214608756e-05,
      "loss": 0.0024,
      "step": 24640
    },
    {
      "epoch": 2.1034217936684017,
      "grad_norm": 0.34964877367019653,
      "learning_rate": 2.896578206331598e-05,
      "loss": 0.0027,
      "step": 24650
    },
    {
      "epoch": 2.1042751087976788,
      "grad_norm": 0.1526457667350769,
      "learning_rate": 2.895724891202321e-05,
      "loss": 0.0031,
      "step": 24660
    },
    {
      "epoch": 2.1051284239269563,
      "grad_norm": 0.15368297696113586,
      "learning_rate": 2.8948715760730438e-05,
      "loss": 0.0037,
      "step": 24670
    },
    {
      "epoch": 2.1059817390562334,
      "grad_norm": 0.07384930551052094,
      "learning_rate": 2.8940182609437666e-05,
      "loss": 0.0023,
      "step": 24680
    },
    {
      "epoch": 2.1068350541855105,
      "grad_norm": 0.07285767048597336,
      "learning_rate": 2.8931649458144895e-05,
      "loss": 0.0028,
      "step": 24690
    },
    {
      "epoch": 2.107688369314788,
      "grad_norm": 0.02971365675330162,
      "learning_rate": 2.892311630685212e-05,
      "loss": 0.002,
      "step": 24700
    },
    {
      "epoch": 2.108541684444065,
      "grad_norm": 0.05320051684975624,
      "learning_rate": 2.891458315555935e-05,
      "loss": 0.0018,
      "step": 24710
    },
    {
      "epoch": 2.1093949995733423,
      "grad_norm": 0.0794227123260498,
      "learning_rate": 2.8906050004266577e-05,
      "loss": 0.0023,
      "step": 24720
    },
    {
      "epoch": 2.11024831470262,
      "grad_norm": 0.15047788619995117,
      "learning_rate": 2.8897516852973805e-05,
      "loss": 0.0033,
      "step": 24730
    },
    {
      "epoch": 2.111101629831897,
      "grad_norm": 0.5599736571311951,
      "learning_rate": 2.8888983701681034e-05,
      "loss": 0.0033,
      "step": 24740
    },
    {
      "epoch": 2.111954944961174,
      "grad_norm": 0.2927360236644745,
      "learning_rate": 2.888045055038826e-05,
      "loss": 0.0034,
      "step": 24750
    },
    {
      "epoch": 2.112808260090451,
      "grad_norm": 0.1746387928724289,
      "learning_rate": 2.8871917399095487e-05,
      "loss": 0.0028,
      "step": 24760
    },
    {
      "epoch": 2.1136615752197287,
      "grad_norm": 0.34823352098464966,
      "learning_rate": 2.8863384247802716e-05,
      "loss": 0.0026,
      "step": 24770
    },
    {
      "epoch": 2.114514890349006,
      "grad_norm": 0.3346409499645233,
      "learning_rate": 2.8854851096509944e-05,
      "loss": 0.0027,
      "step": 24780
    },
    {
      "epoch": 2.115368205478283,
      "grad_norm": 0.06310941278934479,
      "learning_rate": 2.8846317945217173e-05,
      "loss": 0.002,
      "step": 24790
    },
    {
      "epoch": 2.1162215206075605,
      "grad_norm": 0.2509462833404541,
      "learning_rate": 2.8837784793924398e-05,
      "loss": 0.0034,
      "step": 24800
    },
    {
      "epoch": 2.1170748357368376,
      "grad_norm": 0.06759624928236008,
      "learning_rate": 2.8829251642631627e-05,
      "loss": 0.0022,
      "step": 24810
    },
    {
      "epoch": 2.1179281508661147,
      "grad_norm": 0.10039638727903366,
      "learning_rate": 2.8820718491338855e-05,
      "loss": 0.0028,
      "step": 24820
    },
    {
      "epoch": 2.1187814659953923,
      "grad_norm": 0.37698453664779663,
      "learning_rate": 2.8812185340046083e-05,
      "loss": 0.0022,
      "step": 24830
    },
    {
      "epoch": 2.1196347811246694,
      "grad_norm": 0.0569981150329113,
      "learning_rate": 2.8803652188753312e-05,
      "loss": 0.0031,
      "step": 24840
    },
    {
      "epoch": 2.1204880962539465,
      "grad_norm": 0.5303184986114502,
      "learning_rate": 2.8795119037460534e-05,
      "loss": 0.0022,
      "step": 24850
    },
    {
      "epoch": 2.1213414113832236,
      "grad_norm": 0.0353710912168026,
      "learning_rate": 2.8786585886167762e-05,
      "loss": 0.0021,
      "step": 24860
    },
    {
      "epoch": 2.122194726512501,
      "grad_norm": 0.20916558802127838,
      "learning_rate": 2.8778052734874987e-05,
      "loss": 0.0025,
      "step": 24870
    },
    {
      "epoch": 2.1230480416417783,
      "grad_norm": 0.25293534994125366,
      "learning_rate": 2.8769519583582216e-05,
      "loss": 0.002,
      "step": 24880
    },
    {
      "epoch": 2.1239013567710554,
      "grad_norm": 0.34555262327194214,
      "learning_rate": 2.8760986432289444e-05,
      "loss": 0.0026,
      "step": 24890
    },
    {
      "epoch": 2.124754671900333,
      "grad_norm": 0.5943088531494141,
      "learning_rate": 2.8752453280996673e-05,
      "loss": 0.0026,
      "step": 24900
    },
    {
      "epoch": 2.12560798702961,
      "grad_norm": 0.2747868597507477,
      "learning_rate": 2.87439201297039e-05,
      "loss": 0.0029,
      "step": 24910
    },
    {
      "epoch": 2.126461302158887,
      "grad_norm": 0.19030489027500153,
      "learning_rate": 2.8735386978411126e-05,
      "loss": 0.0034,
      "step": 24920
    },
    {
      "epoch": 2.1273146172881647,
      "grad_norm": 0.08294733613729477,
      "learning_rate": 2.8726853827118355e-05,
      "loss": 0.0025,
      "step": 24930
    },
    {
      "epoch": 2.128167932417442,
      "grad_norm": 0.2597103416919708,
      "learning_rate": 2.8718320675825583e-05,
      "loss": 0.0023,
      "step": 24940
    },
    {
      "epoch": 2.129021247546719,
      "grad_norm": 0.14288154244422913,
      "learning_rate": 2.8709787524532812e-05,
      "loss": 0.0022,
      "step": 24950
    },
    {
      "epoch": 2.129874562675996,
      "grad_norm": 0.17842663824558258,
      "learning_rate": 2.870125437324004e-05,
      "loss": 0.0018,
      "step": 24960
    },
    {
      "epoch": 2.1307278778052736,
      "grad_norm": 0.5702424049377441,
      "learning_rate": 2.8692721221947265e-05,
      "loss": 0.0021,
      "step": 24970
    },
    {
      "epoch": 2.1315811929345507,
      "grad_norm": 0.29357582330703735,
      "learning_rate": 2.8684188070654494e-05,
      "loss": 0.0024,
      "step": 24980
    },
    {
      "epoch": 2.132434508063828,
      "grad_norm": 0.10189066082239151,
      "learning_rate": 2.8675654919361722e-05,
      "loss": 0.0027,
      "step": 24990
    },
    {
      "epoch": 2.1332878231931054,
      "grad_norm": 0.08469556272029877,
      "learning_rate": 2.866712176806895e-05,
      "loss": 0.002,
      "step": 25000
    },
    {
      "epoch": 2.1341411383223825,
      "grad_norm": 0.07777503877878189,
      "learning_rate": 2.8658588616776176e-05,
      "loss": 0.0026,
      "step": 25010
    },
    {
      "epoch": 2.1349944534516596,
      "grad_norm": 0.18407054245471954,
      "learning_rate": 2.8650055465483404e-05,
      "loss": 0.0029,
      "step": 25020
    },
    {
      "epoch": 2.1358477685809367,
      "grad_norm": 0.2914942800998688,
      "learning_rate": 2.8641522314190633e-05,
      "loss": 0.002,
      "step": 25030
    },
    {
      "epoch": 2.1367010837102143,
      "grad_norm": 0.10897702723741531,
      "learning_rate": 2.863298916289786e-05,
      "loss": 0.0032,
      "step": 25040
    },
    {
      "epoch": 2.1375543988394914,
      "grad_norm": 0.2631436884403229,
      "learning_rate": 2.862445601160509e-05,
      "loss": 0.0023,
      "step": 25050
    },
    {
      "epoch": 2.1384077139687685,
      "grad_norm": 0.0635695829987526,
      "learning_rate": 2.8615922860312315e-05,
      "loss": 0.0021,
      "step": 25060
    },
    {
      "epoch": 2.139261029098046,
      "grad_norm": 0.03909687325358391,
      "learning_rate": 2.8607389709019543e-05,
      "loss": 0.0021,
      "step": 25070
    },
    {
      "epoch": 2.140114344227323,
      "grad_norm": 0.28720036149024963,
      "learning_rate": 2.8598856557726772e-05,
      "loss": 0.0032,
      "step": 25080
    },
    {
      "epoch": 2.1409676593566003,
      "grad_norm": 0.04844304174184799,
      "learning_rate": 2.8590323406434e-05,
      "loss": 0.0024,
      "step": 25090
    },
    {
      "epoch": 2.141820974485878,
      "grad_norm": 0.05914061516523361,
      "learning_rate": 2.858179025514123e-05,
      "loss": 0.0021,
      "step": 25100
    },
    {
      "epoch": 2.142674289615155,
      "grad_norm": 0.06752382218837738,
      "learning_rate": 2.8573257103848454e-05,
      "loss": 0.0027,
      "step": 25110
    },
    {
      "epoch": 2.143527604744432,
      "grad_norm": 0.06815279275178909,
      "learning_rate": 2.856472395255568e-05,
      "loss": 0.0026,
      "step": 25120
    },
    {
      "epoch": 2.144380919873709,
      "grad_norm": 0.2465851753950119,
      "learning_rate": 2.8556190801262904e-05,
      "loss": 0.0018,
      "step": 25130
    },
    {
      "epoch": 2.1452342350029867,
      "grad_norm": 0.20768208801746368,
      "learning_rate": 2.8547657649970133e-05,
      "loss": 0.0027,
      "step": 25140
    },
    {
      "epoch": 2.146087550132264,
      "grad_norm": 0.43415188789367676,
      "learning_rate": 2.853912449867736e-05,
      "loss": 0.0023,
      "step": 25150
    },
    {
      "epoch": 2.146940865261541,
      "grad_norm": 0.031188789755105972,
      "learning_rate": 2.853059134738459e-05,
      "loss": 0.0026,
      "step": 25160
    },
    {
      "epoch": 2.1477941803908185,
      "grad_norm": 0.039702191948890686,
      "learning_rate": 2.8522058196091818e-05,
      "loss": 0.0024,
      "step": 25170
    },
    {
      "epoch": 2.1486474955200956,
      "grad_norm": 0.38162609934806824,
      "learning_rate": 2.8513525044799043e-05,
      "loss": 0.0027,
      "step": 25180
    },
    {
      "epoch": 2.1495008106493727,
      "grad_norm": 0.30399394035339355,
      "learning_rate": 2.850499189350627e-05,
      "loss": 0.0026,
      "step": 25190
    },
    {
      "epoch": 2.1503541257786503,
      "grad_norm": 0.0651647225022316,
      "learning_rate": 2.84964587422135e-05,
      "loss": 0.0027,
      "step": 25200
    },
    {
      "epoch": 2.1512074409079274,
      "grad_norm": 0.07930578291416168,
      "learning_rate": 2.848792559092073e-05,
      "loss": 0.0027,
      "step": 25210
    },
    {
      "epoch": 2.1520607560372045,
      "grad_norm": 0.35836175084114075,
      "learning_rate": 2.8479392439627957e-05,
      "loss": 0.0028,
      "step": 25220
    },
    {
      "epoch": 2.1529140711664816,
      "grad_norm": 0.09323465079069138,
      "learning_rate": 2.8470859288335182e-05,
      "loss": 0.0025,
      "step": 25230
    },
    {
      "epoch": 2.153767386295759,
      "grad_norm": 0.1577043980360031,
      "learning_rate": 2.846232613704241e-05,
      "loss": 0.0029,
      "step": 25240
    },
    {
      "epoch": 2.1546207014250363,
      "grad_norm": 0.20516733825206757,
      "learning_rate": 2.845379298574964e-05,
      "loss": 0.0031,
      "step": 25250
    },
    {
      "epoch": 2.1554740165543134,
      "grad_norm": 0.2218208760023117,
      "learning_rate": 2.8445259834456868e-05,
      "loss": 0.0038,
      "step": 25260
    },
    {
      "epoch": 2.156327331683591,
      "grad_norm": 0.1934020072221756,
      "learning_rate": 2.8436726683164096e-05,
      "loss": 0.0027,
      "step": 25270
    },
    {
      "epoch": 2.157180646812868,
      "grad_norm": 0.11724625527858734,
      "learning_rate": 2.842819353187132e-05,
      "loss": 0.0021,
      "step": 25280
    },
    {
      "epoch": 2.158033961942145,
      "grad_norm": 0.19951479136943817,
      "learning_rate": 2.841966038057855e-05,
      "loss": 0.0021,
      "step": 25290
    },
    {
      "epoch": 2.1588872770714227,
      "grad_norm": 0.4715918302536011,
      "learning_rate": 2.8411127229285778e-05,
      "loss": 0.0025,
      "step": 25300
    },
    {
      "epoch": 2.1597405922007,
      "grad_norm": 0.10097548365592957,
      "learning_rate": 2.8402594077993007e-05,
      "loss": 0.0023,
      "step": 25310
    },
    {
      "epoch": 2.160593907329977,
      "grad_norm": 0.04107324033975601,
      "learning_rate": 2.839406092670023e-05,
      "loss": 0.0017,
      "step": 25320
    },
    {
      "epoch": 2.161447222459254,
      "grad_norm": 0.2736627757549286,
      "learning_rate": 2.838552777540746e-05,
      "loss": 0.003,
      "step": 25330
    },
    {
      "epoch": 2.1623005375885316,
      "grad_norm": 0.46340087056159973,
      "learning_rate": 2.837699462411469e-05,
      "loss": 0.0028,
      "step": 25340
    },
    {
      "epoch": 2.1631538527178087,
      "grad_norm": 0.14154265820980072,
      "learning_rate": 2.8368461472821917e-05,
      "loss": 0.0024,
      "step": 25350
    },
    {
      "epoch": 2.164007167847086,
      "grad_norm": 0.04484689608216286,
      "learning_rate": 2.8359928321529146e-05,
      "loss": 0.0033,
      "step": 25360
    },
    {
      "epoch": 2.1648604829763634,
      "grad_norm": 0.20501914620399475,
      "learning_rate": 2.835139517023637e-05,
      "loss": 0.0037,
      "step": 25370
    },
    {
      "epoch": 2.1657137981056405,
      "grad_norm": 0.254806786775589,
      "learning_rate": 2.8342862018943596e-05,
      "loss": 0.0025,
      "step": 25380
    },
    {
      "epoch": 2.1665671132349176,
      "grad_norm": 0.33747243881225586,
      "learning_rate": 2.833432886765082e-05,
      "loss": 0.0023,
      "step": 25390
    },
    {
      "epoch": 2.1674204283641947,
      "grad_norm": 0.17716394364833832,
      "learning_rate": 2.832579571635805e-05,
      "loss": 0.0021,
      "step": 25400
    },
    {
      "epoch": 2.1682737434934722,
      "grad_norm": 0.15409156680107117,
      "learning_rate": 2.8317262565065278e-05,
      "loss": 0.002,
      "step": 25410
    },
    {
      "epoch": 2.1691270586227493,
      "grad_norm": 0.14293360710144043,
      "learning_rate": 2.8308729413772506e-05,
      "loss": 0.0021,
      "step": 25420
    },
    {
      "epoch": 2.1699803737520265,
      "grad_norm": 0.4246026277542114,
      "learning_rate": 2.8300196262479735e-05,
      "loss": 0.002,
      "step": 25430
    },
    {
      "epoch": 2.170833688881304,
      "grad_norm": 0.1629127711057663,
      "learning_rate": 2.829166311118696e-05,
      "loss": 0.002,
      "step": 25440
    },
    {
      "epoch": 2.171687004010581,
      "grad_norm": 0.044997721910476685,
      "learning_rate": 2.828312995989419e-05,
      "loss": 0.0024,
      "step": 25450
    },
    {
      "epoch": 2.1725403191398582,
      "grad_norm": 0.2585335969924927,
      "learning_rate": 2.8274596808601417e-05,
      "loss": 0.0019,
      "step": 25460
    },
    {
      "epoch": 2.173393634269136,
      "grad_norm": 0.04946989193558693,
      "learning_rate": 2.8266063657308645e-05,
      "loss": 0.0036,
      "step": 25470
    },
    {
      "epoch": 2.174246949398413,
      "grad_norm": 0.2107783555984497,
      "learning_rate": 2.8257530506015874e-05,
      "loss": 0.0028,
      "step": 25480
    },
    {
      "epoch": 2.17510026452769,
      "grad_norm": 0.08472820371389389,
      "learning_rate": 2.82489973547231e-05,
      "loss": 0.0026,
      "step": 25490
    },
    {
      "epoch": 2.175953579656967,
      "grad_norm": 0.4468083381652832,
      "learning_rate": 2.8240464203430327e-05,
      "loss": 0.0025,
      "step": 25500
    },
    {
      "epoch": 2.1768068947862447,
      "grad_norm": 0.0477115772664547,
      "learning_rate": 2.8231931052137556e-05,
      "loss": 0.0022,
      "step": 25510
    },
    {
      "epoch": 2.177660209915522,
      "grad_norm": 0.1260662078857422,
      "learning_rate": 2.8223397900844784e-05,
      "loss": 0.0027,
      "step": 25520
    },
    {
      "epoch": 2.178513525044799,
      "grad_norm": 0.21782070398330688,
      "learning_rate": 2.8214864749552013e-05,
      "loss": 0.0025,
      "step": 25530
    },
    {
      "epoch": 2.1793668401740764,
      "grad_norm": 0.18023967742919922,
      "learning_rate": 2.8206331598259238e-05,
      "loss": 0.0025,
      "step": 25540
    },
    {
      "epoch": 2.1802201553033536,
      "grad_norm": 0.15731535851955414,
      "learning_rate": 2.8197798446966466e-05,
      "loss": 0.0023,
      "step": 25550
    },
    {
      "epoch": 2.1810734704326307,
      "grad_norm": 0.1347120702266693,
      "learning_rate": 2.8189265295673695e-05,
      "loss": 0.0024,
      "step": 25560
    },
    {
      "epoch": 2.1819267855619078,
      "grad_norm": 0.027145255357027054,
      "learning_rate": 2.8180732144380923e-05,
      "loss": 0.0024,
      "step": 25570
    },
    {
      "epoch": 2.1827801006911853,
      "grad_norm": 0.10779107362031937,
      "learning_rate": 2.8172198993088152e-05,
      "loss": 0.0023,
      "step": 25580
    },
    {
      "epoch": 2.1836334158204624,
      "grad_norm": 0.135384663939476,
      "learning_rate": 2.8163665841795377e-05,
      "loss": 0.002,
      "step": 25590
    },
    {
      "epoch": 2.1844867309497396,
      "grad_norm": 0.10427984595298767,
      "learning_rate": 2.8155132690502605e-05,
      "loss": 0.0022,
      "step": 25600
    },
    {
      "epoch": 2.185340046079017,
      "grad_norm": 0.42475542426109314,
      "learning_rate": 2.8146599539209834e-05,
      "loss": 0.003,
      "step": 25610
    },
    {
      "epoch": 2.186193361208294,
      "grad_norm": 0.15508119761943817,
      "learning_rate": 2.8138066387917062e-05,
      "loss": 0.0028,
      "step": 25620
    },
    {
      "epoch": 2.1870466763375713,
      "grad_norm": 0.05505633354187012,
      "learning_rate": 2.812953323662429e-05,
      "loss": 0.0025,
      "step": 25630
    },
    {
      "epoch": 2.187899991466849,
      "grad_norm": 0.09442908316850662,
      "learning_rate": 2.8121000085331516e-05,
      "loss": 0.0028,
      "step": 25640
    },
    {
      "epoch": 2.188753306596126,
      "grad_norm": 0.06266772747039795,
      "learning_rate": 2.8112466934038738e-05,
      "loss": 0.0023,
      "step": 25650
    },
    {
      "epoch": 2.189606621725403,
      "grad_norm": 0.10696573555469513,
      "learning_rate": 2.8103933782745966e-05,
      "loss": 0.0018,
      "step": 25660
    },
    {
      "epoch": 2.1904599368546807,
      "grad_norm": 0.061500806361436844,
      "learning_rate": 2.8095400631453195e-05,
      "loss": 0.0029,
      "step": 25670
    },
    {
      "epoch": 2.1913132519839578,
      "grad_norm": 0.3109040856361389,
      "learning_rate": 2.8086867480160423e-05,
      "loss": 0.002,
      "step": 25680
    },
    {
      "epoch": 2.192166567113235,
      "grad_norm": 0.2107294797897339,
      "learning_rate": 2.807833432886765e-05,
      "loss": 0.0027,
      "step": 25690
    },
    {
      "epoch": 2.193019882242512,
      "grad_norm": 0.05121166631579399,
      "learning_rate": 2.8069801177574877e-05,
      "loss": 0.0025,
      "step": 25700
    },
    {
      "epoch": 2.1938731973717895,
      "grad_norm": 0.17165057361125946,
      "learning_rate": 2.8061268026282105e-05,
      "loss": 0.0031,
      "step": 25710
    },
    {
      "epoch": 2.1947265125010667,
      "grad_norm": 0.20442871749401093,
      "learning_rate": 2.8052734874989334e-05,
      "loss": 0.0022,
      "step": 25720
    },
    {
      "epoch": 2.1955798276303438,
      "grad_norm": 0.10810046643018723,
      "learning_rate": 2.8044201723696562e-05,
      "loss": 0.0024,
      "step": 25730
    },
    {
      "epoch": 2.1964331427596213,
      "grad_norm": 0.2562709450721741,
      "learning_rate": 2.803566857240379e-05,
      "loss": 0.0022,
      "step": 25740
    },
    {
      "epoch": 2.1972864578888984,
      "grad_norm": 0.21988040208816528,
      "learning_rate": 2.8027135421111016e-05,
      "loss": 0.0025,
      "step": 25750
    },
    {
      "epoch": 2.1981397730181755,
      "grad_norm": 0.06696817278862,
      "learning_rate": 2.8018602269818244e-05,
      "loss": 0.0023,
      "step": 25760
    },
    {
      "epoch": 2.1989930881474526,
      "grad_norm": 0.4203200042247772,
      "learning_rate": 2.8010069118525473e-05,
      "loss": 0.0026,
      "step": 25770
    },
    {
      "epoch": 2.19984640327673,
      "grad_norm": 0.12138106673955917,
      "learning_rate": 2.80015359672327e-05,
      "loss": 0.0026,
      "step": 25780
    },
    {
      "epoch": 2.2006997184060073,
      "grad_norm": 0.13675963878631592,
      "learning_rate": 2.799300281593993e-05,
      "loss": 0.0021,
      "step": 25790
    },
    {
      "epoch": 2.2015530335352844,
      "grad_norm": 0.4280359745025635,
      "learning_rate": 2.7984469664647155e-05,
      "loss": 0.0029,
      "step": 25800
    },
    {
      "epoch": 2.202406348664562,
      "grad_norm": 0.5044546127319336,
      "learning_rate": 2.7975936513354383e-05,
      "loss": 0.0023,
      "step": 25810
    },
    {
      "epoch": 2.203259663793839,
      "grad_norm": 0.10780586302280426,
      "learning_rate": 2.7967403362061612e-05,
      "loss": 0.003,
      "step": 25820
    },
    {
      "epoch": 2.204112978923116,
      "grad_norm": 0.44489234685897827,
      "learning_rate": 2.795887021076884e-05,
      "loss": 0.0029,
      "step": 25830
    },
    {
      "epoch": 2.2049662940523937,
      "grad_norm": 0.2341727465391159,
      "learning_rate": 2.795033705947607e-05,
      "loss": 0.0026,
      "step": 25840
    },
    {
      "epoch": 2.205819609181671,
      "grad_norm": 0.17534856498241425,
      "learning_rate": 2.7941803908183294e-05,
      "loss": 0.0029,
      "step": 25850
    },
    {
      "epoch": 2.206672924310948,
      "grad_norm": 0.3265678584575653,
      "learning_rate": 2.7933270756890522e-05,
      "loss": 0.0023,
      "step": 25860
    },
    {
      "epoch": 2.207526239440225,
      "grad_norm": 0.32368552684783936,
      "learning_rate": 2.792473760559775e-05,
      "loss": 0.0029,
      "step": 25870
    },
    {
      "epoch": 2.2083795545695026,
      "grad_norm": 0.24377529323101044,
      "learning_rate": 2.791620445430498e-05,
      "loss": 0.0022,
      "step": 25880
    },
    {
      "epoch": 2.2092328696987797,
      "grad_norm": 0.30416229367256165,
      "learning_rate": 2.7907671303012208e-05,
      "loss": 0.0026,
      "step": 25890
    },
    {
      "epoch": 2.210086184828057,
      "grad_norm": 0.21055899560451508,
      "learning_rate": 2.7899138151719433e-05,
      "loss": 0.0023,
      "step": 25900
    },
    {
      "epoch": 2.2109394999573344,
      "grad_norm": 0.21272717416286469,
      "learning_rate": 2.7890605000426654e-05,
      "loss": 0.0022,
      "step": 25910
    },
    {
      "epoch": 2.2117928150866115,
      "grad_norm": 0.04038257896900177,
      "learning_rate": 2.7882071849133883e-05,
      "loss": 0.0029,
      "step": 25920
    },
    {
      "epoch": 2.2126461302158886,
      "grad_norm": 0.0667029321193695,
      "learning_rate": 2.787353869784111e-05,
      "loss": 0.0022,
      "step": 25930
    },
    {
      "epoch": 2.2134994453451657,
      "grad_norm": 0.056977324187755585,
      "learning_rate": 2.786500554654834e-05,
      "loss": 0.0022,
      "step": 25940
    },
    {
      "epoch": 2.2143527604744433,
      "grad_norm": 0.2880763113498688,
      "learning_rate": 2.785647239525557e-05,
      "loss": 0.0028,
      "step": 25950
    },
    {
      "epoch": 2.2152060756037204,
      "grad_norm": 0.1549345850944519,
      "learning_rate": 2.7847939243962794e-05,
      "loss": 0.0025,
      "step": 25960
    },
    {
      "epoch": 2.2160593907329975,
      "grad_norm": 0.16228742897510529,
      "learning_rate": 2.7839406092670022e-05,
      "loss": 0.0022,
      "step": 25970
    },
    {
      "epoch": 2.216912705862275,
      "grad_norm": 0.09680440276861191,
      "learning_rate": 2.783087294137725e-05,
      "loss": 0.0021,
      "step": 25980
    },
    {
      "epoch": 2.217766020991552,
      "grad_norm": 0.19407102465629578,
      "learning_rate": 2.782233979008448e-05,
      "loss": 0.0026,
      "step": 25990
    },
    {
      "epoch": 2.2186193361208293,
      "grad_norm": 0.26898932456970215,
      "learning_rate": 2.7813806638791707e-05,
      "loss": 0.0021,
      "step": 26000
    },
    {
      "epoch": 2.219472651250107,
      "grad_norm": 0.25852712988853455,
      "learning_rate": 2.7805273487498933e-05,
      "loss": 0.0024,
      "step": 26010
    },
    {
      "epoch": 2.220325966379384,
      "grad_norm": 0.20978453755378723,
      "learning_rate": 2.779674033620616e-05,
      "loss": 0.0028,
      "step": 26020
    },
    {
      "epoch": 2.221179281508661,
      "grad_norm": 0.29235759377479553,
      "learning_rate": 2.778820718491339e-05,
      "loss": 0.0022,
      "step": 26030
    },
    {
      "epoch": 2.2220325966379386,
      "grad_norm": 0.5459120869636536,
      "learning_rate": 2.7779674033620618e-05,
      "loss": 0.0019,
      "step": 26040
    },
    {
      "epoch": 2.2228859117672157,
      "grad_norm": 0.32879528403282166,
      "learning_rate": 2.7771140882327846e-05,
      "loss": 0.0025,
      "step": 26050
    },
    {
      "epoch": 2.223739226896493,
      "grad_norm": 0.4598052501678467,
      "learning_rate": 2.776260773103507e-05,
      "loss": 0.003,
      "step": 26060
    },
    {
      "epoch": 2.22459254202577,
      "grad_norm": 0.21636268496513367,
      "learning_rate": 2.77540745797423e-05,
      "loss": 0.0026,
      "step": 26070
    },
    {
      "epoch": 2.2254458571550475,
      "grad_norm": 0.08748691529035568,
      "learning_rate": 2.774554142844953e-05,
      "loss": 0.0025,
      "step": 26080
    },
    {
      "epoch": 2.2262991722843246,
      "grad_norm": 0.2737863063812256,
      "learning_rate": 2.7737008277156757e-05,
      "loss": 0.0028,
      "step": 26090
    },
    {
      "epoch": 2.2271524874136017,
      "grad_norm": 0.46411535143852234,
      "learning_rate": 2.7728475125863985e-05,
      "loss": 0.0025,
      "step": 26100
    },
    {
      "epoch": 2.2280058025428793,
      "grad_norm": 0.40325865149497986,
      "learning_rate": 2.771994197457121e-05,
      "loss": 0.0026,
      "step": 26110
    },
    {
      "epoch": 2.2288591176721564,
      "grad_norm": 0.2951625883579254,
      "learning_rate": 2.771140882327844e-05,
      "loss": 0.0029,
      "step": 26120
    },
    {
      "epoch": 2.2297124328014335,
      "grad_norm": 0.17088080942630768,
      "learning_rate": 2.7702875671985668e-05,
      "loss": 0.0023,
      "step": 26130
    },
    {
      "epoch": 2.2305657479307106,
      "grad_norm": 0.2106528878211975,
      "learning_rate": 2.7694342520692896e-05,
      "loss": 0.0026,
      "step": 26140
    },
    {
      "epoch": 2.231419063059988,
      "grad_norm": 0.2732454240322113,
      "learning_rate": 2.7685809369400125e-05,
      "loss": 0.0017,
      "step": 26150
    },
    {
      "epoch": 2.2322723781892653,
      "grad_norm": 0.05626672878861427,
      "learning_rate": 2.767727621810735e-05,
      "loss": 0.0025,
      "step": 26160
    },
    {
      "epoch": 2.2331256933185424,
      "grad_norm": 0.26045218110084534,
      "learning_rate": 2.7668743066814578e-05,
      "loss": 0.0022,
      "step": 26170
    },
    {
      "epoch": 2.23397900844782,
      "grad_norm": 0.135380357503891,
      "learning_rate": 2.76602099155218e-05,
      "loss": 0.0022,
      "step": 26180
    },
    {
      "epoch": 2.234832323577097,
      "grad_norm": 0.1543373316526413,
      "learning_rate": 2.7651676764229028e-05,
      "loss": 0.0028,
      "step": 26190
    },
    {
      "epoch": 2.235685638706374,
      "grad_norm": 0.09742200374603271,
      "learning_rate": 2.7643143612936257e-05,
      "loss": 0.0022,
      "step": 26200
    },
    {
      "epoch": 2.2365389538356517,
      "grad_norm": 0.5097301006317139,
      "learning_rate": 2.7634610461643485e-05,
      "loss": 0.002,
      "step": 26210
    },
    {
      "epoch": 2.237392268964929,
      "grad_norm": 0.5559921264648438,
      "learning_rate": 2.762607731035071e-05,
      "loss": 0.0024,
      "step": 26220
    },
    {
      "epoch": 2.238245584094206,
      "grad_norm": 0.11717667430639267,
      "learning_rate": 2.761754415905794e-05,
      "loss": 0.0027,
      "step": 26230
    },
    {
      "epoch": 2.239098899223483,
      "grad_norm": 0.05820837616920471,
      "learning_rate": 2.7609011007765167e-05,
      "loss": 0.0019,
      "step": 26240
    },
    {
      "epoch": 2.2399522143527606,
      "grad_norm": 0.3307991325855255,
      "learning_rate": 2.7600477856472396e-05,
      "loss": 0.0023,
      "step": 26250
    },
    {
      "epoch": 2.2408055294820377,
      "grad_norm": 0.2666311264038086,
      "learning_rate": 2.7591944705179624e-05,
      "loss": 0.0028,
      "step": 26260
    },
    {
      "epoch": 2.241658844611315,
      "grad_norm": 0.05189163237810135,
      "learning_rate": 2.758341155388685e-05,
      "loss": 0.0021,
      "step": 26270
    },
    {
      "epoch": 2.2425121597405924,
      "grad_norm": 0.49647432565689087,
      "learning_rate": 2.7574878402594078e-05,
      "loss": 0.0025,
      "step": 26280
    },
    {
      "epoch": 2.2433654748698695,
      "grad_norm": 0.13841407001018524,
      "learning_rate": 2.7566345251301306e-05,
      "loss": 0.0019,
      "step": 26290
    },
    {
      "epoch": 2.2442187899991466,
      "grad_norm": 0.1871272325515747,
      "learning_rate": 2.7557812100008535e-05,
      "loss": 0.0032,
      "step": 26300
    },
    {
      "epoch": 2.2450721051284237,
      "grad_norm": 0.2126634120941162,
      "learning_rate": 2.7549278948715763e-05,
      "loss": 0.0026,
      "step": 26310
    },
    {
      "epoch": 2.2459254202577013,
      "grad_norm": 0.041566021740436554,
      "learning_rate": 2.754074579742299e-05,
      "loss": 0.0026,
      "step": 26320
    },
    {
      "epoch": 2.2467787353869784,
      "grad_norm": 0.19725938141345978,
      "learning_rate": 2.7532212646130217e-05,
      "loss": 0.0019,
      "step": 26330
    },
    {
      "epoch": 2.2476320505162555,
      "grad_norm": 0.17548473179340363,
      "learning_rate": 2.7523679494837445e-05,
      "loss": 0.0027,
      "step": 26340
    },
    {
      "epoch": 2.248485365645533,
      "grad_norm": 0.30640745162963867,
      "learning_rate": 2.7515146343544674e-05,
      "loss": 0.0027,
      "step": 26350
    },
    {
      "epoch": 2.24933868077481,
      "grad_norm": 0.23498886823654175,
      "learning_rate": 2.7506613192251902e-05,
      "loss": 0.0022,
      "step": 26360
    },
    {
      "epoch": 2.2501919959040872,
      "grad_norm": 0.12312738597393036,
      "learning_rate": 2.7498080040959127e-05,
      "loss": 0.0023,
      "step": 26370
    },
    {
      "epoch": 2.251045311033365,
      "grad_norm": 0.30925485491752625,
      "learning_rate": 2.7489546889666356e-05,
      "loss": 0.0022,
      "step": 26380
    },
    {
      "epoch": 2.251898626162642,
      "grad_norm": 0.6607723832130432,
      "learning_rate": 2.7481013738373584e-05,
      "loss": 0.0026,
      "step": 26390
    },
    {
      "epoch": 2.252751941291919,
      "grad_norm": 0.14822827279567719,
      "learning_rate": 2.7472480587080813e-05,
      "loss": 0.0023,
      "step": 26400
    },
    {
      "epoch": 2.2536052564211966,
      "grad_norm": 0.0796336829662323,
      "learning_rate": 2.746394743578804e-05,
      "loss": 0.0023,
      "step": 26410
    },
    {
      "epoch": 2.2544585715504737,
      "grad_norm": 0.4268726408481598,
      "learning_rate": 2.7455414284495266e-05,
      "loss": 0.0023,
      "step": 26420
    },
    {
      "epoch": 2.255311886679751,
      "grad_norm": 0.42496809363365173,
      "learning_rate": 2.7446881133202495e-05,
      "loss": 0.0025,
      "step": 26430
    },
    {
      "epoch": 2.256165201809028,
      "grad_norm": 0.21972377598285675,
      "learning_rate": 2.7438347981909723e-05,
      "loss": 0.0028,
      "step": 26440
    },
    {
      "epoch": 2.2570185169383055,
      "grad_norm": 0.11979734152555466,
      "learning_rate": 2.7429814830616945e-05,
      "loss": 0.0029,
      "step": 26450
    },
    {
      "epoch": 2.2578718320675826,
      "grad_norm": 0.30039307475090027,
      "learning_rate": 2.7421281679324174e-05,
      "loss": 0.0026,
      "step": 26460
    },
    {
      "epoch": 2.2587251471968597,
      "grad_norm": 0.3820483386516571,
      "learning_rate": 2.7412748528031402e-05,
      "loss": 0.0022,
      "step": 26470
    },
    {
      "epoch": 2.259578462326137,
      "grad_norm": 0.35301315784454346,
      "learning_rate": 2.740421537673863e-05,
      "loss": 0.003,
      "step": 26480
    },
    {
      "epoch": 2.2604317774554143,
      "grad_norm": 0.3697212338447571,
      "learning_rate": 2.7395682225445856e-05,
      "loss": 0.0017,
      "step": 26490
    },
    {
      "epoch": 2.2612850925846915,
      "grad_norm": 0.27213191986083984,
      "learning_rate": 2.7387149074153084e-05,
      "loss": 0.0028,
      "step": 26500
    },
    {
      "epoch": 2.2621384077139686,
      "grad_norm": 0.33121615648269653,
      "learning_rate": 2.7378615922860313e-05,
      "loss": 0.003,
      "step": 26510
    },
    {
      "epoch": 2.262991722843246,
      "grad_norm": 0.09647464007139206,
      "learning_rate": 2.737008277156754e-05,
      "loss": 0.0021,
      "step": 26520
    },
    {
      "epoch": 2.2638450379725232,
      "grad_norm": 0.04421881586313248,
      "learning_rate": 2.736154962027477e-05,
      "loss": 0.0022,
      "step": 26530
    },
    {
      "epoch": 2.2646983531018003,
      "grad_norm": 0.3115185499191284,
      "learning_rate": 2.7353016468981995e-05,
      "loss": 0.0031,
      "step": 26540
    },
    {
      "epoch": 2.265551668231078,
      "grad_norm": 0.26730915904045105,
      "learning_rate": 2.7344483317689223e-05,
      "loss": 0.0033,
      "step": 26550
    },
    {
      "epoch": 2.266404983360355,
      "grad_norm": 0.08637253940105438,
      "learning_rate": 2.733595016639645e-05,
      "loss": 0.0023,
      "step": 26560
    },
    {
      "epoch": 2.267258298489632,
      "grad_norm": 0.04797431826591492,
      "learning_rate": 2.732741701510368e-05,
      "loss": 0.0026,
      "step": 26570
    },
    {
      "epoch": 2.2681116136189097,
      "grad_norm": 0.25505882501602173,
      "learning_rate": 2.7318883863810905e-05,
      "loss": 0.0033,
      "step": 26580
    },
    {
      "epoch": 2.268964928748187,
      "grad_norm": 0.04597977548837662,
      "learning_rate": 2.7310350712518134e-05,
      "loss": 0.0018,
      "step": 26590
    },
    {
      "epoch": 2.269818243877464,
      "grad_norm": 0.10687942057847977,
      "learning_rate": 2.7301817561225362e-05,
      "loss": 0.002,
      "step": 26600
    },
    {
      "epoch": 2.270671559006741,
      "grad_norm": 0.290485143661499,
      "learning_rate": 2.729328440993259e-05,
      "loss": 0.0022,
      "step": 26610
    },
    {
      "epoch": 2.2715248741360186,
      "grad_norm": 0.1274174004793167,
      "learning_rate": 2.728475125863982e-05,
      "loss": 0.0027,
      "step": 26620
    },
    {
      "epoch": 2.2723781892652957,
      "grad_norm": 0.32156458497047424,
      "learning_rate": 2.7276218107347044e-05,
      "loss": 0.0021,
      "step": 26630
    },
    {
      "epoch": 2.2732315043945728,
      "grad_norm": 0.1780845820903778,
      "learning_rate": 2.7267684956054273e-05,
      "loss": 0.0027,
      "step": 26640
    },
    {
      "epoch": 2.2740848195238503,
      "grad_norm": 0.15369912981987,
      "learning_rate": 2.72591518047615e-05,
      "loss": 0.0024,
      "step": 26650
    },
    {
      "epoch": 2.2749381346531274,
      "grad_norm": 0.3658001124858856,
      "learning_rate": 2.725061865346873e-05,
      "loss": 0.0026,
      "step": 26660
    },
    {
      "epoch": 2.2757914497824046,
      "grad_norm": 0.30834004282951355,
      "learning_rate": 2.7242085502175958e-05,
      "loss": 0.0025,
      "step": 26670
    },
    {
      "epoch": 2.2766447649116817,
      "grad_norm": 0.7637386322021484,
      "learning_rate": 2.7233552350883183e-05,
      "loss": 0.0024,
      "step": 26680
    },
    {
      "epoch": 2.277498080040959,
      "grad_norm": 0.15830112993717194,
      "learning_rate": 2.7225019199590412e-05,
      "loss": 0.0027,
      "step": 26690
    },
    {
      "epoch": 2.2783513951702363,
      "grad_norm": 0.19826743006706238,
      "learning_rate": 2.721648604829764e-05,
      "loss": 0.0027,
      "step": 26700
    },
    {
      "epoch": 2.2792047102995134,
      "grad_norm": 0.10585717856884003,
      "learning_rate": 2.7207952897004862e-05,
      "loss": 0.0029,
      "step": 26710
    },
    {
      "epoch": 2.280058025428791,
      "grad_norm": 0.04028566926717758,
      "learning_rate": 2.719941974571209e-05,
      "loss": 0.0023,
      "step": 26720
    },
    {
      "epoch": 2.280911340558068,
      "grad_norm": 0.047352153807878494,
      "learning_rate": 2.719088659441932e-05,
      "loss": 0.0022,
      "step": 26730
    },
    {
      "epoch": 2.281764655687345,
      "grad_norm": 0.24452528357505798,
      "learning_rate": 2.7182353443126547e-05,
      "loss": 0.0028,
      "step": 26740
    },
    {
      "epoch": 2.2826179708166228,
      "grad_norm": 0.35711079835891724,
      "learning_rate": 2.7173820291833772e-05,
      "loss": 0.0028,
      "step": 26750
    },
    {
      "epoch": 2.2834712859459,
      "grad_norm": 0.1328400820493698,
      "learning_rate": 2.7165287140541e-05,
      "loss": 0.0032,
      "step": 26760
    },
    {
      "epoch": 2.284324601075177,
      "grad_norm": 0.16086076200008392,
      "learning_rate": 2.715675398924823e-05,
      "loss": 0.0023,
      "step": 26770
    },
    {
      "epoch": 2.2851779162044545,
      "grad_norm": 0.4337252974510193,
      "learning_rate": 2.7148220837955458e-05,
      "loss": 0.002,
      "step": 26780
    },
    {
      "epoch": 2.2860312313337317,
      "grad_norm": 0.07712767273187637,
      "learning_rate": 2.7139687686662686e-05,
      "loss": 0.0026,
      "step": 26790
    },
    {
      "epoch": 2.2868845464630088,
      "grad_norm": 0.0666307583451271,
      "learning_rate": 2.713115453536991e-05,
      "loss": 0.0027,
      "step": 26800
    },
    {
      "epoch": 2.287737861592286,
      "grad_norm": 0.23489679396152496,
      "learning_rate": 2.712262138407714e-05,
      "loss": 0.0024,
      "step": 26810
    },
    {
      "epoch": 2.2885911767215634,
      "grad_norm": 0.1178986206650734,
      "learning_rate": 2.711408823278437e-05,
      "loss": 0.0022,
      "step": 26820
    },
    {
      "epoch": 2.2894444918508405,
      "grad_norm": 0.4635445177555084,
      "learning_rate": 2.7105555081491597e-05,
      "loss": 0.0025,
      "step": 26830
    },
    {
      "epoch": 2.2902978069801176,
      "grad_norm": 0.2732052206993103,
      "learning_rate": 2.7097021930198825e-05,
      "loss": 0.0019,
      "step": 26840
    },
    {
      "epoch": 2.2911511221093948,
      "grad_norm": 0.10484375059604645,
      "learning_rate": 2.708848877890605e-05,
      "loss": 0.002,
      "step": 26850
    },
    {
      "epoch": 2.2920044372386723,
      "grad_norm": 0.17392335832118988,
      "learning_rate": 2.707995562761328e-05,
      "loss": 0.0023,
      "step": 26860
    },
    {
      "epoch": 2.2928577523679494,
      "grad_norm": 0.15568988025188446,
      "learning_rate": 2.7071422476320507e-05,
      "loss": 0.0027,
      "step": 26870
    },
    {
      "epoch": 2.2937110674972265,
      "grad_norm": 0.11617500334978104,
      "learning_rate": 2.7062889325027736e-05,
      "loss": 0.0024,
      "step": 26880
    },
    {
      "epoch": 2.294564382626504,
      "grad_norm": 0.1821681559085846,
      "learning_rate": 2.705435617373496e-05,
      "loss": 0.0019,
      "step": 26890
    },
    {
      "epoch": 2.295417697755781,
      "grad_norm": 0.04876793920993805,
      "learning_rate": 2.704582302244219e-05,
      "loss": 0.0023,
      "step": 26900
    },
    {
      "epoch": 2.2962710128850583,
      "grad_norm": 0.08408545702695847,
      "learning_rate": 2.7037289871149418e-05,
      "loss": 0.0025,
      "step": 26910
    },
    {
      "epoch": 2.297124328014336,
      "grad_norm": 0.19437870383262634,
      "learning_rate": 2.7028756719856646e-05,
      "loss": 0.0026,
      "step": 26920
    },
    {
      "epoch": 2.297977643143613,
      "grad_norm": 0.18884910643100739,
      "learning_rate": 2.7020223568563875e-05,
      "loss": 0.0018,
      "step": 26930
    },
    {
      "epoch": 2.29883095827289,
      "grad_norm": 0.2495609074831009,
      "learning_rate": 2.70116904172711e-05,
      "loss": 0.0025,
      "step": 26940
    },
    {
      "epoch": 2.2996842734021676,
      "grad_norm": 0.06671211868524551,
      "learning_rate": 2.700315726597833e-05,
      "loss": 0.0026,
      "step": 26950
    },
    {
      "epoch": 2.3005375885314447,
      "grad_norm": 0.102313332259655,
      "learning_rate": 2.6994624114685557e-05,
      "loss": 0.0031,
      "step": 26960
    },
    {
      "epoch": 2.301390903660722,
      "grad_norm": 0.1607932299375534,
      "learning_rate": 2.6986090963392785e-05,
      "loss": 0.0017,
      "step": 26970
    },
    {
      "epoch": 2.302244218789999,
      "grad_norm": 0.07437778264284134,
      "learning_rate": 2.6977557812100007e-05,
      "loss": 0.0023,
      "step": 26980
    },
    {
      "epoch": 2.3030975339192765,
      "grad_norm": 0.14299918711185455,
      "learning_rate": 2.6969024660807236e-05,
      "loss": 0.0023,
      "step": 26990
    },
    {
      "epoch": 2.3039508490485536,
      "grad_norm": 0.48158466815948486,
      "learning_rate": 2.6960491509514464e-05,
      "loss": 0.0027,
      "step": 27000
    },
    {
      "epoch": 2.3048041641778307,
      "grad_norm": 0.1489717811346054,
      "learning_rate": 2.695195835822169e-05,
      "loss": 0.0036,
      "step": 27010
    },
    {
      "epoch": 2.3056574793071083,
      "grad_norm": 0.12083055078983307,
      "learning_rate": 2.6943425206928918e-05,
      "loss": 0.0026,
      "step": 27020
    },
    {
      "epoch": 2.3065107944363854,
      "grad_norm": 0.203982412815094,
      "learning_rate": 2.6934892055636146e-05,
      "loss": 0.0025,
      "step": 27030
    },
    {
      "epoch": 2.3073641095656625,
      "grad_norm": 0.23043669760227203,
      "learning_rate": 2.6926358904343375e-05,
      "loss": 0.0023,
      "step": 27040
    },
    {
      "epoch": 2.3082174246949396,
      "grad_norm": 0.06730225682258606,
      "learning_rate": 2.6917825753050603e-05,
      "loss": 0.0021,
      "step": 27050
    },
    {
      "epoch": 2.309070739824217,
      "grad_norm": 0.3163955807685852,
      "learning_rate": 2.6909292601757828e-05,
      "loss": 0.0024,
      "step": 27060
    },
    {
      "epoch": 2.3099240549534943,
      "grad_norm": 0.248797208070755,
      "learning_rate": 2.6900759450465057e-05,
      "loss": 0.0021,
      "step": 27070
    },
    {
      "epoch": 2.3107773700827714,
      "grad_norm": 0.18191802501678467,
      "learning_rate": 2.6892226299172285e-05,
      "loss": 0.0018,
      "step": 27080
    },
    {
      "epoch": 2.311630685212049,
      "grad_norm": 0.4896332323551178,
      "learning_rate": 2.6883693147879514e-05,
      "loss": 0.0022,
      "step": 27090
    },
    {
      "epoch": 2.312484000341326,
      "grad_norm": 0.130079448223114,
      "learning_rate": 2.6875159996586742e-05,
      "loss": 0.0023,
      "step": 27100
    },
    {
      "epoch": 2.313337315470603,
      "grad_norm": 0.1371799111366272,
      "learning_rate": 2.6866626845293967e-05,
      "loss": 0.0025,
      "step": 27110
    },
    {
      "epoch": 2.3141906305998807,
      "grad_norm": 0.04355489835143089,
      "learning_rate": 2.6858093694001196e-05,
      "loss": 0.003,
      "step": 27120
    },
    {
      "epoch": 2.315043945729158,
      "grad_norm": 0.039421115070581436,
      "learning_rate": 2.6849560542708424e-05,
      "loss": 0.0025,
      "step": 27130
    },
    {
      "epoch": 2.315897260858435,
      "grad_norm": 0.18016797304153442,
      "learning_rate": 2.6841027391415653e-05,
      "loss": 0.002,
      "step": 27140
    },
    {
      "epoch": 2.3167505759877125,
      "grad_norm": 0.06540045142173767,
      "learning_rate": 2.683249424012288e-05,
      "loss": 0.0025,
      "step": 27150
    },
    {
      "epoch": 2.3176038911169896,
      "grad_norm": 0.0468248687684536,
      "learning_rate": 2.6823961088830106e-05,
      "loss": 0.0028,
      "step": 27160
    },
    {
      "epoch": 2.3184572062462667,
      "grad_norm": 0.4415656626224518,
      "learning_rate": 2.6815427937537335e-05,
      "loss": 0.0034,
      "step": 27170
    },
    {
      "epoch": 2.319310521375544,
      "grad_norm": 0.1392095685005188,
      "learning_rate": 2.6806894786244563e-05,
      "loss": 0.0023,
      "step": 27180
    },
    {
      "epoch": 2.3201638365048214,
      "grad_norm": 0.19520485401153564,
      "learning_rate": 2.6798361634951792e-05,
      "loss": 0.0029,
      "step": 27190
    },
    {
      "epoch": 2.3210171516340985,
      "grad_norm": 0.32732367515563965,
      "learning_rate": 2.6789828483659017e-05,
      "loss": 0.0023,
      "step": 27200
    },
    {
      "epoch": 2.3218704667633756,
      "grad_norm": 0.04931226745247841,
      "learning_rate": 2.6781295332366245e-05,
      "loss": 0.0024,
      "step": 27210
    },
    {
      "epoch": 2.3227237818926527,
      "grad_norm": 0.043585680425167084,
      "learning_rate": 2.6772762181073474e-05,
      "loss": 0.0021,
      "step": 27220
    },
    {
      "epoch": 2.3235770970219303,
      "grad_norm": 0.10371609032154083,
      "learning_rate": 2.6764229029780702e-05,
      "loss": 0.0024,
      "step": 27230
    },
    {
      "epoch": 2.3244304121512074,
      "grad_norm": 0.1740315556526184,
      "learning_rate": 2.6755695878487924e-05,
      "loss": 0.0022,
      "step": 27240
    },
    {
      "epoch": 2.3252837272804845,
      "grad_norm": 0.0669647604227066,
      "learning_rate": 2.6747162727195152e-05,
      "loss": 0.0025,
      "step": 27250
    },
    {
      "epoch": 2.326137042409762,
      "grad_norm": 0.04818020015954971,
      "learning_rate": 2.673862957590238e-05,
      "loss": 0.0028,
      "step": 27260
    },
    {
      "epoch": 2.326990357539039,
      "grad_norm": 0.219781294465065,
      "learning_rate": 2.6730096424609606e-05,
      "loss": 0.0029,
      "step": 27270
    },
    {
      "epoch": 2.3278436726683163,
      "grad_norm": 0.21391233801841736,
      "learning_rate": 2.6721563273316835e-05,
      "loss": 0.0019,
      "step": 27280
    },
    {
      "epoch": 2.328696987797594,
      "grad_norm": 0.403444766998291,
      "learning_rate": 2.6713030122024063e-05,
      "loss": 0.0023,
      "step": 27290
    },
    {
      "epoch": 2.329550302926871,
      "grad_norm": 0.38382789492607117,
      "learning_rate": 2.670449697073129e-05,
      "loss": 0.0025,
      "step": 27300
    },
    {
      "epoch": 2.330403618056148,
      "grad_norm": 0.581253170967102,
      "learning_rate": 2.669596381943852e-05,
      "loss": 0.0026,
      "step": 27310
    },
    {
      "epoch": 2.3312569331854256,
      "grad_norm": 0.427633136510849,
      "learning_rate": 2.6687430668145745e-05,
      "loss": 0.0025,
      "step": 27320
    },
    {
      "epoch": 2.3321102483147027,
      "grad_norm": 0.10259215533733368,
      "learning_rate": 2.6678897516852974e-05,
      "loss": 0.0022,
      "step": 27330
    },
    {
      "epoch": 2.33296356344398,
      "grad_norm": 0.15798939764499664,
      "learning_rate": 2.6670364365560202e-05,
      "loss": 0.0025,
      "step": 27340
    },
    {
      "epoch": 2.333816878573257,
      "grad_norm": 0.11919120699167252,
      "learning_rate": 2.666183121426743e-05,
      "loss": 0.0021,
      "step": 27350
    },
    {
      "epoch": 2.3346701937025345,
      "grad_norm": 0.385117769241333,
      "learning_rate": 2.665329806297466e-05,
      "loss": 0.0027,
      "step": 27360
    },
    {
      "epoch": 2.3355235088318116,
      "grad_norm": 0.2339707762002945,
      "learning_rate": 2.6644764911681884e-05,
      "loss": 0.0025,
      "step": 27370
    },
    {
      "epoch": 2.3363768239610887,
      "grad_norm": 0.23659084737300873,
      "learning_rate": 2.6636231760389113e-05,
      "loss": 0.0018,
      "step": 27380
    },
    {
      "epoch": 2.3372301390903663,
      "grad_norm": 0.05263325199484825,
      "learning_rate": 2.662769860909634e-05,
      "loss": 0.0023,
      "step": 27390
    },
    {
      "epoch": 2.3380834542196434,
      "grad_norm": 0.15905746817588806,
      "learning_rate": 2.661916545780357e-05,
      "loss": 0.0024,
      "step": 27400
    },
    {
      "epoch": 2.3389367693489205,
      "grad_norm": 0.06742935627698898,
      "learning_rate": 2.6610632306510798e-05,
      "loss": 0.0027,
      "step": 27410
    },
    {
      "epoch": 2.3397900844781976,
      "grad_norm": 0.21621228754520416,
      "learning_rate": 2.6602099155218023e-05,
      "loss": 0.0025,
      "step": 27420
    },
    {
      "epoch": 2.340643399607475,
      "grad_norm": 0.2131902575492859,
      "learning_rate": 2.659356600392525e-05,
      "loss": 0.0024,
      "step": 27430
    },
    {
      "epoch": 2.3414967147367522,
      "grad_norm": 0.3091139793395996,
      "learning_rate": 2.658503285263248e-05,
      "loss": 0.0023,
      "step": 27440
    },
    {
      "epoch": 2.3423500298660294,
      "grad_norm": 0.2887164354324341,
      "learning_rate": 2.657649970133971e-05,
      "loss": 0.0027,
      "step": 27450
    },
    {
      "epoch": 2.343203344995307,
      "grad_norm": 0.07986252009868622,
      "learning_rate": 2.6567966550046937e-05,
      "loss": 0.0027,
      "step": 27460
    },
    {
      "epoch": 2.344056660124584,
      "grad_norm": 0.5942451357841492,
      "learning_rate": 2.6559433398754162e-05,
      "loss": 0.0022,
      "step": 27470
    },
    {
      "epoch": 2.344909975253861,
      "grad_norm": 0.294210821390152,
      "learning_rate": 2.655090024746139e-05,
      "loss": 0.0027,
      "step": 27480
    },
    {
      "epoch": 2.3457632903831387,
      "grad_norm": 0.04278598353266716,
      "learning_rate": 2.654236709616862e-05,
      "loss": 0.0022,
      "step": 27490
    },
    {
      "epoch": 2.346616605512416,
      "grad_norm": 0.2128985971212387,
      "learning_rate": 2.6533833944875848e-05,
      "loss": 0.0029,
      "step": 27500
    },
    {
      "epoch": 2.347469920641693,
      "grad_norm": 0.07078062742948532,
      "learning_rate": 2.652530079358307e-05,
      "loss": 0.0023,
      "step": 27510
    },
    {
      "epoch": 2.3483232357709705,
      "grad_norm": 0.2703394889831543,
      "learning_rate": 2.6516767642290298e-05,
      "loss": 0.002,
      "step": 27520
    },
    {
      "epoch": 2.3491765509002476,
      "grad_norm": 0.14351347088813782,
      "learning_rate": 2.6508234490997523e-05,
      "loss": 0.0016,
      "step": 27530
    },
    {
      "epoch": 2.3500298660295247,
      "grad_norm": 0.18804867565631866,
      "learning_rate": 2.649970133970475e-05,
      "loss": 0.0034,
      "step": 27540
    },
    {
      "epoch": 2.350883181158802,
      "grad_norm": 0.21109427511692047,
      "learning_rate": 2.649116818841198e-05,
      "loss": 0.0022,
      "step": 27550
    },
    {
      "epoch": 2.3517364962880793,
      "grad_norm": 0.195260688662529,
      "learning_rate": 2.648263503711921e-05,
      "loss": 0.0018,
      "step": 27560
    },
    {
      "epoch": 2.3525898114173565,
      "grad_norm": 0.19827453792095184,
      "learning_rate": 2.6474101885826437e-05,
      "loss": 0.0026,
      "step": 27570
    },
    {
      "epoch": 2.3534431265466336,
      "grad_norm": 0.0703997015953064,
      "learning_rate": 2.6465568734533662e-05,
      "loss": 0.0032,
      "step": 27580
    },
    {
      "epoch": 2.3542964416759107,
      "grad_norm": 0.2549374997615814,
      "learning_rate": 2.645703558324089e-05,
      "loss": 0.0024,
      "step": 27590
    },
    {
      "epoch": 2.3551497568051882,
      "grad_norm": 0.40494534373283386,
      "learning_rate": 2.644850243194812e-05,
      "loss": 0.0023,
      "step": 27600
    },
    {
      "epoch": 2.3560030719344653,
      "grad_norm": 0.23662301898002625,
      "learning_rate": 2.6439969280655347e-05,
      "loss": 0.0021,
      "step": 27610
    },
    {
      "epoch": 2.3568563870637425,
      "grad_norm": 0.21883520483970642,
      "learning_rate": 2.6431436129362576e-05,
      "loss": 0.0019,
      "step": 27620
    },
    {
      "epoch": 2.35770970219302,
      "grad_norm": 0.22035887837409973,
      "learning_rate": 2.64229029780698e-05,
      "loss": 0.0023,
      "step": 27630
    },
    {
      "epoch": 2.358563017322297,
      "grad_norm": 0.10139673948287964,
      "learning_rate": 2.641436982677703e-05,
      "loss": 0.0026,
      "step": 27640
    },
    {
      "epoch": 2.3594163324515742,
      "grad_norm": 0.1944112926721573,
      "learning_rate": 2.6405836675484258e-05,
      "loss": 0.0027,
      "step": 27650
    },
    {
      "epoch": 2.360269647580852,
      "grad_norm": 0.13192486763000488,
      "learning_rate": 2.6397303524191486e-05,
      "loss": 0.0021,
      "step": 27660
    },
    {
      "epoch": 2.361122962710129,
      "grad_norm": 0.21118740737438202,
      "learning_rate": 2.6388770372898715e-05,
      "loss": 0.0027,
      "step": 27670
    },
    {
      "epoch": 2.361976277839406,
      "grad_norm": 0.25350451469421387,
      "learning_rate": 2.638023722160594e-05,
      "loss": 0.002,
      "step": 27680
    },
    {
      "epoch": 2.3628295929686836,
      "grad_norm": 0.0846455916762352,
      "learning_rate": 2.637170407031317e-05,
      "loss": 0.0023,
      "step": 27690
    },
    {
      "epoch": 2.3636829080979607,
      "grad_norm": 0.04843541234731674,
      "learning_rate": 2.6363170919020397e-05,
      "loss": 0.0022,
      "step": 27700
    },
    {
      "epoch": 2.3645362232272378,
      "grad_norm": 0.38693299889564514,
      "learning_rate": 2.6354637767727625e-05,
      "loss": 0.002,
      "step": 27710
    },
    {
      "epoch": 2.365389538356515,
      "grad_norm": 0.07985667139291763,
      "learning_rate": 2.6346104616434854e-05,
      "loss": 0.0021,
      "step": 27720
    },
    {
      "epoch": 2.3662428534857924,
      "grad_norm": 0.2673099637031555,
      "learning_rate": 2.633757146514208e-05,
      "loss": 0.0022,
      "step": 27730
    },
    {
      "epoch": 2.3670961686150696,
      "grad_norm": 0.18747682869434357,
      "learning_rate": 2.6329038313849307e-05,
      "loss": 0.0022,
      "step": 27740
    },
    {
      "epoch": 2.3679494837443467,
      "grad_norm": 0.4330116808414459,
      "learning_rate": 2.6320505162556536e-05,
      "loss": 0.0026,
      "step": 27750
    },
    {
      "epoch": 2.368802798873624,
      "grad_norm": 0.12664835155010223,
      "learning_rate": 2.6311972011263764e-05,
      "loss": 0.0019,
      "step": 27760
    },
    {
      "epoch": 2.3696561140029013,
      "grad_norm": 0.21635310351848602,
      "learning_rate": 2.6303438859970986e-05,
      "loss": 0.0027,
      "step": 27770
    },
    {
      "epoch": 2.3705094291321784,
      "grad_norm": 0.5760804414749146,
      "learning_rate": 2.6294905708678215e-05,
      "loss": 0.0028,
      "step": 27780
    },
    {
      "epoch": 2.3713627442614555,
      "grad_norm": 0.3485852777957916,
      "learning_rate": 2.628637255738544e-05,
      "loss": 0.0024,
      "step": 27790
    },
    {
      "epoch": 2.372216059390733,
      "grad_norm": 0.21053873002529144,
      "learning_rate": 2.6277839406092668e-05,
      "loss": 0.0018,
      "step": 27800
    },
    {
      "epoch": 2.37306937452001,
      "grad_norm": 0.15479810535907745,
      "learning_rate": 2.6269306254799897e-05,
      "loss": 0.0023,
      "step": 27810
    },
    {
      "epoch": 2.3739226896492873,
      "grad_norm": 0.23387575149536133,
      "learning_rate": 2.6260773103507125e-05,
      "loss": 0.0024,
      "step": 27820
    },
    {
      "epoch": 2.374776004778565,
      "grad_norm": 0.1718216985464096,
      "learning_rate": 2.6252239952214354e-05,
      "loss": 0.0017,
      "step": 27830
    },
    {
      "epoch": 2.375629319907842,
      "grad_norm": 0.11120639741420746,
      "learning_rate": 2.624370680092158e-05,
      "loss": 0.0026,
      "step": 27840
    },
    {
      "epoch": 2.376482635037119,
      "grad_norm": 0.16534695029258728,
      "learning_rate": 2.6235173649628807e-05,
      "loss": 0.0026,
      "step": 27850
    },
    {
      "epoch": 2.3773359501663966,
      "grad_norm": 0.23249468207359314,
      "learning_rate": 2.6226640498336036e-05,
      "loss": 0.0028,
      "step": 27860
    },
    {
      "epoch": 2.3781892652956738,
      "grad_norm": 0.4818371832370758,
      "learning_rate": 2.6218107347043264e-05,
      "loss": 0.0023,
      "step": 27870
    },
    {
      "epoch": 2.379042580424951,
      "grad_norm": 0.04000883549451828,
      "learning_rate": 2.6209574195750493e-05,
      "loss": 0.0024,
      "step": 27880
    },
    {
      "epoch": 2.3798958955542284,
      "grad_norm": 0.20995616912841797,
      "learning_rate": 2.6201041044457718e-05,
      "loss": 0.0019,
      "step": 27890
    },
    {
      "epoch": 2.3807492106835055,
      "grad_norm": 0.24901513755321503,
      "learning_rate": 2.6192507893164946e-05,
      "loss": 0.0026,
      "step": 27900
    },
    {
      "epoch": 2.3816025258127826,
      "grad_norm": 0.1020352840423584,
      "learning_rate": 2.6183974741872175e-05,
      "loss": 0.0033,
      "step": 27910
    },
    {
      "epoch": 2.3824558409420598,
      "grad_norm": 0.09831516444683075,
      "learning_rate": 2.6175441590579403e-05,
      "loss": 0.002,
      "step": 27920
    },
    {
      "epoch": 2.3833091560713373,
      "grad_norm": 0.07448121160268784,
      "learning_rate": 2.616690843928663e-05,
      "loss": 0.0016,
      "step": 27930
    },
    {
      "epoch": 2.3841624712006144,
      "grad_norm": 0.1987631618976593,
      "learning_rate": 2.6158375287993857e-05,
      "loss": 0.002,
      "step": 27940
    },
    {
      "epoch": 2.3850157863298915,
      "grad_norm": 0.32861199975013733,
      "learning_rate": 2.6149842136701085e-05,
      "loss": 0.0025,
      "step": 27950
    },
    {
      "epoch": 2.3858691014591686,
      "grad_norm": 0.2582605481147766,
      "learning_rate": 2.6141308985408314e-05,
      "loss": 0.0026,
      "step": 27960
    },
    {
      "epoch": 2.386722416588446,
      "grad_norm": 0.03346738964319229,
      "learning_rate": 2.6132775834115542e-05,
      "loss": 0.0018,
      "step": 27970
    },
    {
      "epoch": 2.3875757317177233,
      "grad_norm": 0.1925792396068573,
      "learning_rate": 2.612424268282277e-05,
      "loss": 0.0027,
      "step": 27980
    },
    {
      "epoch": 2.3884290468470004,
      "grad_norm": 0.19110730290412903,
      "learning_rate": 2.6115709531529996e-05,
      "loss": 0.0021,
      "step": 27990
    },
    {
      "epoch": 2.389282361976278,
      "grad_norm": 0.4057082235813141,
      "learning_rate": 2.6107176380237224e-05,
      "loss": 0.0025,
      "step": 28000
    },
    {
      "epoch": 2.390135677105555,
      "grad_norm": 0.20537249743938446,
      "learning_rate": 2.6098643228944453e-05,
      "loss": 0.0022,
      "step": 28010
    },
    {
      "epoch": 2.390988992234832,
      "grad_norm": 0.18913763761520386,
      "learning_rate": 2.609011007765168e-05,
      "loss": 0.0021,
      "step": 28020
    },
    {
      "epoch": 2.3918423073641097,
      "grad_norm": 0.20058509707450867,
      "learning_rate": 2.608157692635891e-05,
      "loss": 0.0025,
      "step": 28030
    },
    {
      "epoch": 2.392695622493387,
      "grad_norm": 0.12076379358768463,
      "learning_rate": 2.607304377506613e-05,
      "loss": 0.0026,
      "step": 28040
    },
    {
      "epoch": 2.393548937622664,
      "grad_norm": 0.3496400713920593,
      "learning_rate": 2.606451062377336e-05,
      "loss": 0.0026,
      "step": 28050
    },
    {
      "epoch": 2.3944022527519415,
      "grad_norm": 0.13060717284679413,
      "learning_rate": 2.6055977472480585e-05,
      "loss": 0.0022,
      "step": 28060
    },
    {
      "epoch": 2.3952555678812186,
      "grad_norm": 0.06446926295757294,
      "learning_rate": 2.6047444321187813e-05,
      "loss": 0.0026,
      "step": 28070
    },
    {
      "epoch": 2.3961088830104957,
      "grad_norm": 0.27848169207572937,
      "learning_rate": 2.6038911169895042e-05,
      "loss": 0.0029,
      "step": 28080
    },
    {
      "epoch": 2.396962198139773,
      "grad_norm": 0.2162092924118042,
      "learning_rate": 2.603037801860227e-05,
      "loss": 0.0028,
      "step": 28090
    },
    {
      "epoch": 2.3978155132690504,
      "grad_norm": 0.16830430924892426,
      "learning_rate": 2.60218448673095e-05,
      "loss": 0.0021,
      "step": 28100
    },
    {
      "epoch": 2.3986688283983275,
      "grad_norm": 0.11104273051023483,
      "learning_rate": 2.6013311716016724e-05,
      "loss": 0.0023,
      "step": 28110
    },
    {
      "epoch": 2.3995221435276046,
      "grad_norm": 0.3507801592350006,
      "learning_rate": 2.6004778564723952e-05,
      "loss": 0.0022,
      "step": 28120
    },
    {
      "epoch": 2.400375458656882,
      "grad_norm": 0.08580449223518372,
      "learning_rate": 2.599624541343118e-05,
      "loss": 0.0026,
      "step": 28130
    },
    {
      "epoch": 2.4012287737861593,
      "grad_norm": 0.21336233615875244,
      "learning_rate": 2.598771226213841e-05,
      "loss": 0.0023,
      "step": 28140
    },
    {
      "epoch": 2.4020820889154364,
      "grad_norm": 0.04886409640312195,
      "learning_rate": 2.5979179110845635e-05,
      "loss": 0.0021,
      "step": 28150
    },
    {
      "epoch": 2.4029354040447135,
      "grad_norm": 0.1383233368396759,
      "learning_rate": 2.5970645959552863e-05,
      "loss": 0.0021,
      "step": 28160
    },
    {
      "epoch": 2.403788719173991,
      "grad_norm": 0.2028726488351822,
      "learning_rate": 2.596211280826009e-05,
      "loss": 0.0026,
      "step": 28170
    },
    {
      "epoch": 2.404642034303268,
      "grad_norm": 0.1271706521511078,
      "learning_rate": 2.595357965696732e-05,
      "loss": 0.0018,
      "step": 28180
    },
    {
      "epoch": 2.4054953494325453,
      "grad_norm": 0.43955475091934204,
      "learning_rate": 2.594504650567455e-05,
      "loss": 0.0018,
      "step": 28190
    },
    {
      "epoch": 2.406348664561823,
      "grad_norm": 0.3494986593723297,
      "learning_rate": 2.5936513354381774e-05,
      "loss": 0.0031,
      "step": 28200
    },
    {
      "epoch": 2.4072019796911,
      "grad_norm": 0.3770281970500946,
      "learning_rate": 2.5927980203089002e-05,
      "loss": 0.0022,
      "step": 28210
    },
    {
      "epoch": 2.408055294820377,
      "grad_norm": 0.12292013317346573,
      "learning_rate": 2.591944705179623e-05,
      "loss": 0.0018,
      "step": 28220
    },
    {
      "epoch": 2.4089086099496546,
      "grad_norm": 0.12762413918972015,
      "learning_rate": 2.591091390050346e-05,
      "loss": 0.0019,
      "step": 28230
    },
    {
      "epoch": 2.4097619250789317,
      "grad_norm": 0.2793990671634674,
      "learning_rate": 2.5902380749210687e-05,
      "loss": 0.0023,
      "step": 28240
    },
    {
      "epoch": 2.410615240208209,
      "grad_norm": 0.1962469071149826,
      "learning_rate": 2.5893847597917913e-05,
      "loss": 0.0018,
      "step": 28250
    },
    {
      "epoch": 2.411468555337486,
      "grad_norm": 0.1083480641245842,
      "learning_rate": 2.588531444662514e-05,
      "loss": 0.0027,
      "step": 28260
    },
    {
      "epoch": 2.4123218704667635,
      "grad_norm": 0.0459161214530468,
      "learning_rate": 2.587678129533237e-05,
      "loss": 0.0017,
      "step": 28270
    },
    {
      "epoch": 2.4131751855960406,
      "grad_norm": 0.14132995903491974,
      "learning_rate": 2.5868248144039598e-05,
      "loss": 0.0028,
      "step": 28280
    },
    {
      "epoch": 2.4140285007253177,
      "grad_norm": 0.17971786856651306,
      "learning_rate": 2.5859714992746827e-05,
      "loss": 0.0028,
      "step": 28290
    },
    {
      "epoch": 2.4148818158545953,
      "grad_norm": 0.3116186261177063,
      "learning_rate": 2.585118184145405e-05,
      "loss": 0.0028,
      "step": 28300
    },
    {
      "epoch": 2.4157351309838724,
      "grad_norm": 0.1572483330965042,
      "learning_rate": 2.5842648690161277e-05,
      "loss": 0.0026,
      "step": 28310
    },
    {
      "epoch": 2.4165884461131495,
      "grad_norm": 0.06596094369888306,
      "learning_rate": 2.5834115538868502e-05,
      "loss": 0.002,
      "step": 28320
    },
    {
      "epoch": 2.4174417612424266,
      "grad_norm": 0.26837944984436035,
      "learning_rate": 2.582558238757573e-05,
      "loss": 0.0019,
      "step": 28330
    },
    {
      "epoch": 2.418295076371704,
      "grad_norm": 0.2692921459674835,
      "learning_rate": 2.581704923628296e-05,
      "loss": 0.002,
      "step": 28340
    },
    {
      "epoch": 2.4191483915009813,
      "grad_norm": 0.19160661101341248,
      "learning_rate": 2.5808516084990187e-05,
      "loss": 0.0023,
      "step": 28350
    },
    {
      "epoch": 2.4200017066302584,
      "grad_norm": 0.18182170391082764,
      "learning_rate": 2.5799982933697416e-05,
      "loss": 0.0021,
      "step": 28360
    },
    {
      "epoch": 2.420855021759536,
      "grad_norm": 0.23214106261730194,
      "learning_rate": 2.579144978240464e-05,
      "loss": 0.0026,
      "step": 28370
    },
    {
      "epoch": 2.421708336888813,
      "grad_norm": 0.3584219217300415,
      "learning_rate": 2.578291663111187e-05,
      "loss": 0.0024,
      "step": 28380
    },
    {
      "epoch": 2.42256165201809,
      "grad_norm": 0.06341954320669174,
      "learning_rate": 2.5774383479819098e-05,
      "loss": 0.003,
      "step": 28390
    },
    {
      "epoch": 2.4234149671473677,
      "grad_norm": 0.12042852491140366,
      "learning_rate": 2.5765850328526326e-05,
      "loss": 0.0021,
      "step": 28400
    },
    {
      "epoch": 2.424268282276645,
      "grad_norm": 0.33323198556900024,
      "learning_rate": 2.5757317177233555e-05,
      "loss": 0.0035,
      "step": 28410
    },
    {
      "epoch": 2.425121597405922,
      "grad_norm": 0.3715222179889679,
      "learning_rate": 2.574878402594078e-05,
      "loss": 0.0024,
      "step": 28420
    },
    {
      "epoch": 2.4259749125351995,
      "grad_norm": 0.39489689469337463,
      "learning_rate": 2.574025087464801e-05,
      "loss": 0.0019,
      "step": 28430
    },
    {
      "epoch": 2.4268282276644766,
      "grad_norm": 0.09890078008174896,
      "learning_rate": 2.5731717723355237e-05,
      "loss": 0.0017,
      "step": 28440
    },
    {
      "epoch": 2.4276815427937537,
      "grad_norm": 0.06404772400856018,
      "learning_rate": 2.5723184572062465e-05,
      "loss": 0.0022,
      "step": 28450
    },
    {
      "epoch": 2.428534857923031,
      "grad_norm": 0.14594843983650208,
      "learning_rate": 2.571465142076969e-05,
      "loss": 0.0031,
      "step": 28460
    },
    {
      "epoch": 2.4293881730523084,
      "grad_norm": 0.0436314158141613,
      "learning_rate": 2.570611826947692e-05,
      "loss": 0.0024,
      "step": 28470
    },
    {
      "epoch": 2.4302414881815855,
      "grad_norm": 0.2286001294851303,
      "learning_rate": 2.5697585118184147e-05,
      "loss": 0.0026,
      "step": 28480
    },
    {
      "epoch": 2.4310948033108626,
      "grad_norm": 0.07018397748470306,
      "learning_rate": 2.5689051966891376e-05,
      "loss": 0.0023,
      "step": 28490
    },
    {
      "epoch": 2.4319481184401397,
      "grad_norm": 0.2648997902870178,
      "learning_rate": 2.5680518815598604e-05,
      "loss": 0.0023,
      "step": 28500
    },
    {
      "epoch": 2.4328014335694172,
      "grad_norm": 0.38590285181999207,
      "learning_rate": 2.567198566430583e-05,
      "loss": 0.0027,
      "step": 28510
    },
    {
      "epoch": 2.4336547486986944,
      "grad_norm": 0.11915948241949081,
      "learning_rate": 2.5663452513013058e-05,
      "loss": 0.0021,
      "step": 28520
    },
    {
      "epoch": 2.4345080638279715,
      "grad_norm": 0.15332543849945068,
      "learning_rate": 2.5654919361720286e-05,
      "loss": 0.0018,
      "step": 28530
    },
    {
      "epoch": 2.435361378957249,
      "grad_norm": 0.420624315738678,
      "learning_rate": 2.5646386210427515e-05,
      "loss": 0.0016,
      "step": 28540
    },
    {
      "epoch": 2.436214694086526,
      "grad_norm": 0.26214906573295593,
      "learning_rate": 2.5637853059134743e-05,
      "loss": 0.0018,
      "step": 28550
    },
    {
      "epoch": 2.4370680092158032,
      "grad_norm": 0.10850720852613449,
      "learning_rate": 2.562931990784197e-05,
      "loss": 0.0014,
      "step": 28560
    },
    {
      "epoch": 2.437921324345081,
      "grad_norm": 0.4021517336368561,
      "learning_rate": 2.5620786756549194e-05,
      "loss": 0.0015,
      "step": 28570
    },
    {
      "epoch": 2.438774639474358,
      "grad_norm": 0.07291720807552338,
      "learning_rate": 2.561225360525642e-05,
      "loss": 0.0025,
      "step": 28580
    },
    {
      "epoch": 2.439627954603635,
      "grad_norm": 0.594431459903717,
      "learning_rate": 2.5603720453963647e-05,
      "loss": 0.0028,
      "step": 28590
    },
    {
      "epoch": 2.4404812697329126,
      "grad_norm": 0.2681707739830017,
      "learning_rate": 2.5595187302670876e-05,
      "loss": 0.0026,
      "step": 28600
    },
    {
      "epoch": 2.4413345848621897,
      "grad_norm": 0.47615817189216614,
      "learning_rate": 2.5586654151378104e-05,
      "loss": 0.0023,
      "step": 28610
    },
    {
      "epoch": 2.442187899991467,
      "grad_norm": 0.17951516807079315,
      "learning_rate": 2.5578121000085333e-05,
      "loss": 0.0024,
      "step": 28620
    },
    {
      "epoch": 2.443041215120744,
      "grad_norm": 0.28816479444503784,
      "learning_rate": 2.5569587848792558e-05,
      "loss": 0.0027,
      "step": 28630
    },
    {
      "epoch": 2.4438945302500215,
      "grad_norm": 0.297839492559433,
      "learning_rate": 2.5561054697499786e-05,
      "loss": 0.0022,
      "step": 28640
    },
    {
      "epoch": 2.4447478453792986,
      "grad_norm": 0.286300927400589,
      "learning_rate": 2.5552521546207015e-05,
      "loss": 0.0026,
      "step": 28650
    },
    {
      "epoch": 2.4456011605085757,
      "grad_norm": 0.21303650736808777,
      "learning_rate": 2.5543988394914243e-05,
      "loss": 0.0033,
      "step": 28660
    },
    {
      "epoch": 2.4464544756378532,
      "grad_norm": 0.033304113894701004,
      "learning_rate": 2.553545524362147e-05,
      "loss": 0.0028,
      "step": 28670
    },
    {
      "epoch": 2.4473077907671303,
      "grad_norm": 0.331908255815506,
      "learning_rate": 2.5526922092328697e-05,
      "loss": 0.0018,
      "step": 28680
    },
    {
      "epoch": 2.4481611058964075,
      "grad_norm": 0.16364659368991852,
      "learning_rate": 2.5518388941035925e-05,
      "loss": 0.0024,
      "step": 28690
    },
    {
      "epoch": 2.4490144210256846,
      "grad_norm": 0.2677280306816101,
      "learning_rate": 2.5509855789743154e-05,
      "loss": 0.0026,
      "step": 28700
    },
    {
      "epoch": 2.449867736154962,
      "grad_norm": 0.3875722587108612,
      "learning_rate": 2.5501322638450382e-05,
      "loss": 0.0022,
      "step": 28710
    },
    {
      "epoch": 2.4507210512842392,
      "grad_norm": 0.16581079363822937,
      "learning_rate": 2.549278948715761e-05,
      "loss": 0.0032,
      "step": 28720
    },
    {
      "epoch": 2.4515743664135163,
      "grad_norm": 0.19341498613357544,
      "learning_rate": 2.5484256335864836e-05,
      "loss": 0.0027,
      "step": 28730
    },
    {
      "epoch": 2.452427681542794,
      "grad_norm": 0.0379340797662735,
      "learning_rate": 2.5475723184572064e-05,
      "loss": 0.0029,
      "step": 28740
    },
    {
      "epoch": 2.453280996672071,
      "grad_norm": 0.28733348846435547,
      "learning_rate": 2.5467190033279293e-05,
      "loss": 0.0023,
      "step": 28750
    },
    {
      "epoch": 2.454134311801348,
      "grad_norm": 0.23047877848148346,
      "learning_rate": 2.545865688198652e-05,
      "loss": 0.0021,
      "step": 28760
    },
    {
      "epoch": 2.4549876269306257,
      "grad_norm": 0.15955008566379547,
      "learning_rate": 2.5450123730693746e-05,
      "loss": 0.0029,
      "step": 28770
    },
    {
      "epoch": 2.4558409420599028,
      "grad_norm": 0.09884221851825714,
      "learning_rate": 2.5441590579400975e-05,
      "loss": 0.0025,
      "step": 28780
    },
    {
      "epoch": 2.45669425718918,
      "grad_norm": 0.1533726453781128,
      "learning_rate": 2.5433057428108203e-05,
      "loss": 0.0019,
      "step": 28790
    },
    {
      "epoch": 2.4575475723184574,
      "grad_norm": 0.09865882247686386,
      "learning_rate": 2.542452427681543e-05,
      "loss": 0.0029,
      "step": 28800
    },
    {
      "epoch": 2.4584008874477346,
      "grad_norm": 0.28803983330726624,
      "learning_rate": 2.541599112552266e-05,
      "loss": 0.0033,
      "step": 28810
    },
    {
      "epoch": 2.4592542025770117,
      "grad_norm": 0.1944742649793625,
      "learning_rate": 2.5407457974229885e-05,
      "loss": 0.0028,
      "step": 28820
    },
    {
      "epoch": 2.4601075177062888,
      "grad_norm": 0.33245277404785156,
      "learning_rate": 2.5398924822937114e-05,
      "loss": 0.0033,
      "step": 28830
    },
    {
      "epoch": 2.4609608328355663,
      "grad_norm": 0.3225249648094177,
      "learning_rate": 2.5390391671644335e-05,
      "loss": 0.0024,
      "step": 28840
    },
    {
      "epoch": 2.4618141479648434,
      "grad_norm": 0.03569377586245537,
      "learning_rate": 2.5381858520351564e-05,
      "loss": 0.0028,
      "step": 28850
    },
    {
      "epoch": 2.4626674630941205,
      "grad_norm": 0.3536437451839447,
      "learning_rate": 2.5373325369058792e-05,
      "loss": 0.0029,
      "step": 28860
    },
    {
      "epoch": 2.4635207782233977,
      "grad_norm": 0.1488548368215561,
      "learning_rate": 2.536479221776602e-05,
      "loss": 0.0022,
      "step": 28870
    },
    {
      "epoch": 2.464374093352675,
      "grad_norm": 0.0969754308462143,
      "learning_rate": 2.535625906647325e-05,
      "loss": 0.0025,
      "step": 28880
    },
    {
      "epoch": 2.4652274084819523,
      "grad_norm": 0.12614330649375916,
      "learning_rate": 2.5347725915180474e-05,
      "loss": 0.0026,
      "step": 28890
    },
    {
      "epoch": 2.4660807236112294,
      "grad_norm": 0.15096110105514526,
      "learning_rate": 2.5339192763887703e-05,
      "loss": 0.0024,
      "step": 28900
    },
    {
      "epoch": 2.466934038740507,
      "grad_norm": 0.04235608130693436,
      "learning_rate": 2.533065961259493e-05,
      "loss": 0.0027,
      "step": 28910
    },
    {
      "epoch": 2.467787353869784,
      "grad_norm": 0.05402641370892525,
      "learning_rate": 2.532212646130216e-05,
      "loss": 0.0026,
      "step": 28920
    },
    {
      "epoch": 2.468640668999061,
      "grad_norm": 0.049496665596961975,
      "learning_rate": 2.531359331000939e-05,
      "loss": 0.002,
      "step": 28930
    },
    {
      "epoch": 2.4694939841283388,
      "grad_norm": 0.12671364843845367,
      "learning_rate": 2.5305060158716613e-05,
      "loss": 0.0026,
      "step": 28940
    },
    {
      "epoch": 2.470347299257616,
      "grad_norm": 0.12112777680158615,
      "learning_rate": 2.5296527007423842e-05,
      "loss": 0.0024,
      "step": 28950
    },
    {
      "epoch": 2.471200614386893,
      "grad_norm": 0.348244845867157,
      "learning_rate": 2.528799385613107e-05,
      "loss": 0.0026,
      "step": 28960
    },
    {
      "epoch": 2.4720539295161705,
      "grad_norm": 0.05539415776729584,
      "learning_rate": 2.52794607048383e-05,
      "loss": 0.0026,
      "step": 28970
    },
    {
      "epoch": 2.4729072446454476,
      "grad_norm": 0.057739585638046265,
      "learning_rate": 2.5270927553545527e-05,
      "loss": 0.0019,
      "step": 28980
    },
    {
      "epoch": 2.4737605597747248,
      "grad_norm": 0.06003905460238457,
      "learning_rate": 2.5262394402252752e-05,
      "loss": 0.0025,
      "step": 28990
    },
    {
      "epoch": 2.474613874904002,
      "grad_norm": 0.3305260241031647,
      "learning_rate": 2.525386125095998e-05,
      "loss": 0.0027,
      "step": 29000
    },
    {
      "epoch": 2.4754671900332794,
      "grad_norm": 0.11857633292675018,
      "learning_rate": 2.524532809966721e-05,
      "loss": 0.0021,
      "step": 29010
    },
    {
      "epoch": 2.4763205051625565,
      "grad_norm": 0.07488258928060532,
      "learning_rate": 2.5236794948374438e-05,
      "loss": 0.0018,
      "step": 29020
    },
    {
      "epoch": 2.4771738202918336,
      "grad_norm": 0.0681496262550354,
      "learning_rate": 2.5228261797081666e-05,
      "loss": 0.0027,
      "step": 29030
    },
    {
      "epoch": 2.478027135421111,
      "grad_norm": 0.07187659293413162,
      "learning_rate": 2.521972864578889e-05,
      "loss": 0.0024,
      "step": 29040
    },
    {
      "epoch": 2.4788804505503883,
      "grad_norm": 0.3879636228084564,
      "learning_rate": 2.521119549449612e-05,
      "loss": 0.0018,
      "step": 29050
    },
    {
      "epoch": 2.4797337656796654,
      "grad_norm": 0.05592895671725273,
      "learning_rate": 2.520266234320335e-05,
      "loss": 0.0021,
      "step": 29060
    },
    {
      "epoch": 2.4805870808089425,
      "grad_norm": 0.2911965847015381,
      "learning_rate": 2.5194129191910577e-05,
      "loss": 0.0019,
      "step": 29070
    },
    {
      "epoch": 2.48144039593822,
      "grad_norm": 0.3434448540210724,
      "learning_rate": 2.5185596040617805e-05,
      "loss": 0.0023,
      "step": 29080
    },
    {
      "epoch": 2.482293711067497,
      "grad_norm": 0.29337310791015625,
      "learning_rate": 2.517706288932503e-05,
      "loss": 0.0028,
      "step": 29090
    },
    {
      "epoch": 2.4831470261967743,
      "grad_norm": 0.4852522909641266,
      "learning_rate": 2.5168529738032252e-05,
      "loss": 0.0028,
      "step": 29100
    },
    {
      "epoch": 2.484000341326052,
      "grad_norm": 0.18366333842277527,
      "learning_rate": 2.515999658673948e-05,
      "loss": 0.0024,
      "step": 29110
    },
    {
      "epoch": 2.484853656455329,
      "grad_norm": 0.19755522906780243,
      "learning_rate": 2.515146343544671e-05,
      "loss": 0.002,
      "step": 29120
    },
    {
      "epoch": 2.485706971584606,
      "grad_norm": 0.15683984756469727,
      "learning_rate": 2.5142930284153938e-05,
      "loss": 0.0023,
      "step": 29130
    },
    {
      "epoch": 2.4865602867138836,
      "grad_norm": 0.43735283613204956,
      "learning_rate": 2.5134397132861166e-05,
      "loss": 0.003,
      "step": 29140
    },
    {
      "epoch": 2.4874136018431607,
      "grad_norm": 0.13676044344902039,
      "learning_rate": 2.512586398156839e-05,
      "loss": 0.0024,
      "step": 29150
    },
    {
      "epoch": 2.488266916972438,
      "grad_norm": 0.055314503610134125,
      "learning_rate": 2.511733083027562e-05,
      "loss": 0.002,
      "step": 29160
    },
    {
      "epoch": 2.4891202321017154,
      "grad_norm": 0.16007289290428162,
      "learning_rate": 2.5108797678982848e-05,
      "loss": 0.0032,
      "step": 29170
    },
    {
      "epoch": 2.4899735472309925,
      "grad_norm": 0.18397179245948792,
      "learning_rate": 2.5100264527690077e-05,
      "loss": 0.0022,
      "step": 29180
    },
    {
      "epoch": 2.4908268623602696,
      "grad_norm": 0.2225145548582077,
      "learning_rate": 2.5091731376397305e-05,
      "loss": 0.0023,
      "step": 29190
    },
    {
      "epoch": 2.4916801774895467,
      "grad_norm": 0.1988351196050644,
      "learning_rate": 2.508319822510453e-05,
      "loss": 0.0026,
      "step": 29200
    },
    {
      "epoch": 2.4925334926188243,
      "grad_norm": 0.28716182708740234,
      "learning_rate": 2.507466507381176e-05,
      "loss": 0.0026,
      "step": 29210
    },
    {
      "epoch": 2.4933868077481014,
      "grad_norm": 0.12675441801548004,
      "learning_rate": 2.5066131922518987e-05,
      "loss": 0.0023,
      "step": 29220
    },
    {
      "epoch": 2.4942401228773785,
      "grad_norm": 0.23616430163383484,
      "learning_rate": 2.5057598771226216e-05,
      "loss": 0.002,
      "step": 29230
    },
    {
      "epoch": 2.4950934380066556,
      "grad_norm": 0.18536324799060822,
      "learning_rate": 2.5049065619933444e-05,
      "loss": 0.0022,
      "step": 29240
    },
    {
      "epoch": 2.495946753135933,
      "grad_norm": 0.2456490397453308,
      "learning_rate": 2.504053246864067e-05,
      "loss": 0.002,
      "step": 29250
    },
    {
      "epoch": 2.4968000682652103,
      "grad_norm": 0.28424495458602905,
      "learning_rate": 2.5031999317347898e-05,
      "loss": 0.0023,
      "step": 29260
    },
    {
      "epoch": 2.4976533833944874,
      "grad_norm": 0.23033034801483154,
      "learning_rate": 2.5023466166055126e-05,
      "loss": 0.0023,
      "step": 29270
    },
    {
      "epoch": 2.498506698523765,
      "grad_norm": 0.19768579304218292,
      "learning_rate": 2.5014933014762355e-05,
      "loss": 0.0022,
      "step": 29280
    },
    {
      "epoch": 2.499360013653042,
      "grad_norm": 0.3373168110847473,
      "learning_rate": 2.5006399863469583e-05,
      "loss": 0.0018,
      "step": 29290
    },
    {
      "epoch": 2.500213328782319,
      "grad_norm": 0.28933125734329224,
      "learning_rate": 2.499786671217681e-05,
      "loss": 0.0033,
      "step": 29300
    },
    {
      "epoch": 2.5010666439115967,
      "grad_norm": 0.24943850934505463,
      "learning_rate": 2.4989333560884033e-05,
      "loss": 0.0033,
      "step": 29310
    },
    {
      "epoch": 2.501919959040874,
      "grad_norm": 0.2772562503814697,
      "learning_rate": 2.4980800409591262e-05,
      "loss": 0.0024,
      "step": 29320
    },
    {
      "epoch": 2.502773274170151,
      "grad_norm": 0.18106508255004883,
      "learning_rate": 2.497226725829849e-05,
      "loss": 0.0026,
      "step": 29330
    },
    {
      "epoch": 2.5036265892994285,
      "grad_norm": 0.033018529415130615,
      "learning_rate": 2.496373410700572e-05,
      "loss": 0.0017,
      "step": 29340
    },
    {
      "epoch": 2.5044799044287056,
      "grad_norm": 0.12220178544521332,
      "learning_rate": 2.4955200955712947e-05,
      "loss": 0.0022,
      "step": 29350
    },
    {
      "epoch": 2.5053332195579827,
      "grad_norm": 0.05948397144675255,
      "learning_rate": 2.4946667804420172e-05,
      "loss": 0.002,
      "step": 29360
    },
    {
      "epoch": 2.5061865346872603,
      "grad_norm": 0.3501908779144287,
      "learning_rate": 2.49381346531274e-05,
      "loss": 0.0015,
      "step": 29370
    },
    {
      "epoch": 2.5070398498165374,
      "grad_norm": 0.08835441619157791,
      "learning_rate": 2.492960150183463e-05,
      "loss": 0.0025,
      "step": 29380
    },
    {
      "epoch": 2.5078931649458145,
      "grad_norm": 0.06588518619537354,
      "learning_rate": 2.4921068350541858e-05,
      "loss": 0.0023,
      "step": 29390
    },
    {
      "epoch": 2.5087464800750916,
      "grad_norm": 0.13838443160057068,
      "learning_rate": 2.4912535199249083e-05,
      "loss": 0.0024,
      "step": 29400
    },
    {
      "epoch": 2.5095997952043687,
      "grad_norm": 0.13617043197155,
      "learning_rate": 2.490400204795631e-05,
      "loss": 0.0021,
      "step": 29410
    },
    {
      "epoch": 2.5104531103336463,
      "grad_norm": 0.03837669640779495,
      "learning_rate": 2.489546889666354e-05,
      "loss": 0.0028,
      "step": 29420
    },
    {
      "epoch": 2.5113064254629234,
      "grad_norm": 0.21538691222667694,
      "learning_rate": 2.488693574537077e-05,
      "loss": 0.0021,
      "step": 29430
    },
    {
      "epoch": 2.5121597405922005,
      "grad_norm": 0.285748690366745,
      "learning_rate": 2.4878402594077994e-05,
      "loss": 0.0023,
      "step": 29440
    },
    {
      "epoch": 2.513013055721478,
      "grad_norm": 0.12212991714477539,
      "learning_rate": 2.4869869442785222e-05,
      "loss": 0.0025,
      "step": 29450
    },
    {
      "epoch": 2.513866370850755,
      "grad_norm": 0.4405609965324402,
      "learning_rate": 2.4861336291492447e-05,
      "loss": 0.0019,
      "step": 29460
    },
    {
      "epoch": 2.5147196859800323,
      "grad_norm": 0.4670673906803131,
      "learning_rate": 2.4852803140199676e-05,
      "loss": 0.003,
      "step": 29470
    },
    {
      "epoch": 2.51557300110931,
      "grad_norm": 0.34259724617004395,
      "learning_rate": 2.4844269988906904e-05,
      "loss": 0.0024,
      "step": 29480
    },
    {
      "epoch": 2.516426316238587,
      "grad_norm": 0.38625773787498474,
      "learning_rate": 2.4835736837614133e-05,
      "loss": 0.0031,
      "step": 29490
    },
    {
      "epoch": 2.517279631367864,
      "grad_norm": 0.5137980580329895,
      "learning_rate": 2.482720368632136e-05,
      "loss": 0.0021,
      "step": 29500
    },
    {
      "epoch": 2.5181329464971416,
      "grad_norm": 0.1399696171283722,
      "learning_rate": 2.4818670535028586e-05,
      "loss": 0.0019,
      "step": 29510
    },
    {
      "epoch": 2.5189862616264187,
      "grad_norm": 0.04672233760356903,
      "learning_rate": 2.4810137383735815e-05,
      "loss": 0.002,
      "step": 29520
    },
    {
      "epoch": 2.519839576755696,
      "grad_norm": 0.13563689589500427,
      "learning_rate": 2.4801604232443043e-05,
      "loss": 0.0023,
      "step": 29530
    },
    {
      "epoch": 2.5206928918849734,
      "grad_norm": 0.19609655439853668,
      "learning_rate": 2.479307108115027e-05,
      "loss": 0.0025,
      "step": 29540
    },
    {
      "epoch": 2.5215462070142505,
      "grad_norm": 0.19582581520080566,
      "learning_rate": 2.47845379298575e-05,
      "loss": 0.002,
      "step": 29550
    },
    {
      "epoch": 2.5223995221435276,
      "grad_norm": 0.19112345576286316,
      "learning_rate": 2.4776004778564725e-05,
      "loss": 0.002,
      "step": 29560
    },
    {
      "epoch": 2.5232528372728047,
      "grad_norm": 0.028880396857857704,
      "learning_rate": 2.476747162727195e-05,
      "loss": 0.0023,
      "step": 29570
    },
    {
      "epoch": 2.5241061524020822,
      "grad_norm": 0.28865498304367065,
      "learning_rate": 2.475893847597918e-05,
      "loss": 0.0021,
      "step": 29580
    },
    {
      "epoch": 2.5249594675313594,
      "grad_norm": 0.07352527230978012,
      "learning_rate": 2.4750405324686407e-05,
      "loss": 0.0022,
      "step": 29590
    },
    {
      "epoch": 2.5258127826606365,
      "grad_norm": 0.3863024413585663,
      "learning_rate": 2.4741872173393636e-05,
      "loss": 0.0019,
      "step": 29600
    },
    {
      "epoch": 2.5266660977899136,
      "grad_norm": 0.2514192759990692,
      "learning_rate": 2.4733339022100864e-05,
      "loss": 0.0034,
      "step": 29610
    },
    {
      "epoch": 2.527519412919191,
      "grad_norm": 0.2465248852968216,
      "learning_rate": 2.472480587080809e-05,
      "loss": 0.003,
      "step": 29620
    },
    {
      "epoch": 2.5283727280484682,
      "grad_norm": 0.2744848430156708,
      "learning_rate": 2.4716272719515318e-05,
      "loss": 0.0023,
      "step": 29630
    },
    {
      "epoch": 2.5292260431777454,
      "grad_norm": 0.4873793125152588,
      "learning_rate": 2.4707739568222546e-05,
      "loss": 0.0021,
      "step": 29640
    },
    {
      "epoch": 2.530079358307023,
      "grad_norm": 0.08924444764852524,
      "learning_rate": 2.4699206416929775e-05,
      "loss": 0.0024,
      "step": 29650
    },
    {
      "epoch": 2.5309326734363,
      "grad_norm": 0.27315160632133484,
      "learning_rate": 2.4690673265637003e-05,
      "loss": 0.0018,
      "step": 29660
    },
    {
      "epoch": 2.531785988565577,
      "grad_norm": 0.19044974446296692,
      "learning_rate": 2.4682140114344228e-05,
      "loss": 0.0022,
      "step": 29670
    },
    {
      "epoch": 2.5326393036948547,
      "grad_norm": 0.054978836327791214,
      "learning_rate": 2.4673606963051457e-05,
      "loss": 0.0019,
      "step": 29680
    },
    {
      "epoch": 2.533492618824132,
      "grad_norm": 0.25653138756752014,
      "learning_rate": 2.4665073811758685e-05,
      "loss": 0.002,
      "step": 29690
    },
    {
      "epoch": 2.534345933953409,
      "grad_norm": 0.32202985882759094,
      "learning_rate": 2.465654066046591e-05,
      "loss": 0.0027,
      "step": 29700
    },
    {
      "epoch": 2.5351992490826865,
      "grad_norm": 0.1809365153312683,
      "learning_rate": 2.464800750917314e-05,
      "loss": 0.0022,
      "step": 29710
    },
    {
      "epoch": 2.5360525642119636,
      "grad_norm": 0.17363929748535156,
      "learning_rate": 2.4639474357880364e-05,
      "loss": 0.0028,
      "step": 29720
    },
    {
      "epoch": 2.5369058793412407,
      "grad_norm": 0.06654015928506851,
      "learning_rate": 2.4630941206587592e-05,
      "loss": 0.0019,
      "step": 29730
    },
    {
      "epoch": 2.5377591944705182,
      "grad_norm": 0.2582152187824249,
      "learning_rate": 2.462240805529482e-05,
      "loss": 0.002,
      "step": 29740
    },
    {
      "epoch": 2.5386125095997953,
      "grad_norm": 0.15647734701633453,
      "learning_rate": 2.461387490400205e-05,
      "loss": 0.0017,
      "step": 29750
    },
    {
      "epoch": 2.5394658247290725,
      "grad_norm": 0.036802805960178375,
      "learning_rate": 2.4605341752709278e-05,
      "loss": 0.0017,
      "step": 29760
    },
    {
      "epoch": 2.5403191398583496,
      "grad_norm": 0.2567257881164551,
      "learning_rate": 2.4596808601416503e-05,
      "loss": 0.0024,
      "step": 29770
    },
    {
      "epoch": 2.5411724549876267,
      "grad_norm": 0.19599667191505432,
      "learning_rate": 2.458827545012373e-05,
      "loss": 0.0026,
      "step": 29780
    },
    {
      "epoch": 2.5420257701169042,
      "grad_norm": 0.27551475167274475,
      "learning_rate": 2.457974229883096e-05,
      "loss": 0.0024,
      "step": 29790
    },
    {
      "epoch": 2.5428790852461813,
      "grad_norm": 0.1532723307609558,
      "learning_rate": 2.457120914753819e-05,
      "loss": 0.0022,
      "step": 29800
    },
    {
      "epoch": 2.5437324003754584,
      "grad_norm": 0.18673214316368103,
      "learning_rate": 2.4562675996245417e-05,
      "loss": 0.0024,
      "step": 29810
    },
    {
      "epoch": 2.544585715504736,
      "grad_norm": 0.08800110965967178,
      "learning_rate": 2.4554142844952642e-05,
      "loss": 0.0025,
      "step": 29820
    },
    {
      "epoch": 2.545439030634013,
      "grad_norm": 0.44224050641059875,
      "learning_rate": 2.4545609693659867e-05,
      "loss": 0.0027,
      "step": 29830
    },
    {
      "epoch": 2.54629234576329,
      "grad_norm": 0.36536046862602234,
      "learning_rate": 2.4537076542367096e-05,
      "loss": 0.0023,
      "step": 29840
    },
    {
      "epoch": 2.5471456608925678,
      "grad_norm": 0.29395946860313416,
      "learning_rate": 2.4528543391074324e-05,
      "loss": 0.0027,
      "step": 29850
    },
    {
      "epoch": 2.547998976021845,
      "grad_norm": 0.13751038908958435,
      "learning_rate": 2.4520010239781552e-05,
      "loss": 0.0022,
      "step": 29860
    },
    {
      "epoch": 2.548852291151122,
      "grad_norm": 0.25956037640571594,
      "learning_rate": 2.451147708848878e-05,
      "loss": 0.0025,
      "step": 29870
    },
    {
      "epoch": 2.5497056062803996,
      "grad_norm": 0.29374682903289795,
      "learning_rate": 2.4502943937196006e-05,
      "loss": 0.0029,
      "step": 29880
    },
    {
      "epoch": 2.5505589214096767,
      "grad_norm": 0.0493391714990139,
      "learning_rate": 2.4494410785903235e-05,
      "loss": 0.0023,
      "step": 29890
    },
    {
      "epoch": 2.5514122365389538,
      "grad_norm": 0.246546670794487,
      "learning_rate": 2.4485877634610463e-05,
      "loss": 0.0022,
      "step": 29900
    },
    {
      "epoch": 2.5522655516682313,
      "grad_norm": 0.27572181820869446,
      "learning_rate": 2.447734448331769e-05,
      "loss": 0.002,
      "step": 29910
    },
    {
      "epoch": 2.5531188667975084,
      "grad_norm": 0.06655095517635345,
      "learning_rate": 2.446881133202492e-05,
      "loss": 0.0023,
      "step": 29920
    },
    {
      "epoch": 2.5539721819267855,
      "grad_norm": 0.14214280247688293,
      "learning_rate": 2.4460278180732145e-05,
      "loss": 0.0026,
      "step": 29930
    },
    {
      "epoch": 2.5548254970560627,
      "grad_norm": 0.12239207327365875,
      "learning_rate": 2.4451745029439374e-05,
      "loss": 0.0023,
      "step": 29940
    },
    {
      "epoch": 2.55567881218534,
      "grad_norm": 0.11728096753358841,
      "learning_rate": 2.4443211878146602e-05,
      "loss": 0.0018,
      "step": 29950
    },
    {
      "epoch": 2.5565321273146173,
      "grad_norm": 0.04703797772526741,
      "learning_rate": 2.443467872685383e-05,
      "loss": 0.0014,
      "step": 29960
    },
    {
      "epoch": 2.5573854424438944,
      "grad_norm": 0.07987070828676224,
      "learning_rate": 2.4426145575561056e-05,
      "loss": 0.002,
      "step": 29970
    },
    {
      "epoch": 2.5582387575731715,
      "grad_norm": 0.06102406233549118,
      "learning_rate": 2.4417612424268284e-05,
      "loss": 0.0025,
      "step": 29980
    },
    {
      "epoch": 2.559092072702449,
      "grad_norm": 0.38154977560043335,
      "learning_rate": 2.440907927297551e-05,
      "loss": 0.0022,
      "step": 29990
    },
    {
      "epoch": 2.559945387831726,
      "grad_norm": 0.14262941479682922,
      "learning_rate": 2.4400546121682738e-05,
      "loss": 0.003,
      "step": 30000
    },
    {
      "epoch": 2.5607987029610033,
      "grad_norm": 0.17059127986431122,
      "learning_rate": 2.4392012970389966e-05,
      "loss": 0.002,
      "step": 30010
    },
    {
      "epoch": 2.561652018090281,
      "grad_norm": 0.26451367139816284,
      "learning_rate": 2.4383479819097195e-05,
      "loss": 0.0021,
      "step": 30020
    },
    {
      "epoch": 2.562505333219558,
      "grad_norm": 0.05373280122876167,
      "learning_rate": 2.437494666780442e-05,
      "loss": 0.002,
      "step": 30030
    },
    {
      "epoch": 2.563358648348835,
      "grad_norm": 0.13098081946372986,
      "learning_rate": 2.4366413516511648e-05,
      "loss": 0.002,
      "step": 30040
    },
    {
      "epoch": 2.5642119634781126,
      "grad_norm": 0.10114181786775589,
      "learning_rate": 2.4357880365218877e-05,
      "loss": 0.0021,
      "step": 30050
    },
    {
      "epoch": 2.5650652786073898,
      "grad_norm": 0.04673624038696289,
      "learning_rate": 2.4349347213926105e-05,
      "loss": 0.0025,
      "step": 30060
    },
    {
      "epoch": 2.565918593736667,
      "grad_norm": 0.060006074607372284,
      "learning_rate": 2.4340814062633334e-05,
      "loss": 0.0024,
      "step": 30070
    },
    {
      "epoch": 2.5667719088659444,
      "grad_norm": 0.27575987577438354,
      "learning_rate": 2.433228091134056e-05,
      "loss": 0.0025,
      "step": 30080
    },
    {
      "epoch": 2.5676252239952215,
      "grad_norm": 0.14721529185771942,
      "learning_rate": 2.4323747760047787e-05,
      "loss": 0.0024,
      "step": 30090
    },
    {
      "epoch": 2.5684785391244986,
      "grad_norm": 0.06441298872232437,
      "learning_rate": 2.4315214608755012e-05,
      "loss": 0.0021,
      "step": 30100
    },
    {
      "epoch": 2.569331854253776,
      "grad_norm": 0.34412792325019836,
      "learning_rate": 2.430668145746224e-05,
      "loss": 0.0027,
      "step": 30110
    },
    {
      "epoch": 2.5701851693830533,
      "grad_norm": 0.060139961540699005,
      "learning_rate": 2.429814830616947e-05,
      "loss": 0.0026,
      "step": 30120
    },
    {
      "epoch": 2.5710384845123304,
      "grad_norm": 0.03616759553551674,
      "learning_rate": 2.4289615154876698e-05,
      "loss": 0.003,
      "step": 30130
    },
    {
      "epoch": 2.5718917996416075,
      "grad_norm": 0.3195911645889282,
      "learning_rate": 2.4281082003583923e-05,
      "loss": 0.0022,
      "step": 30140
    },
    {
      "epoch": 2.5727451147708846,
      "grad_norm": 0.05170907452702522,
      "learning_rate": 2.427254885229115e-05,
      "loss": 0.0025,
      "step": 30150
    },
    {
      "epoch": 2.573598429900162,
      "grad_norm": 0.19932778179645538,
      "learning_rate": 2.426401570099838e-05,
      "loss": 0.0029,
      "step": 30160
    },
    {
      "epoch": 2.5744517450294393,
      "grad_norm": 0.08578328788280487,
      "learning_rate": 2.425548254970561e-05,
      "loss": 0.0024,
      "step": 30170
    },
    {
      "epoch": 2.5753050601587164,
      "grad_norm": 0.5700049996376038,
      "learning_rate": 2.4246949398412837e-05,
      "loss": 0.002,
      "step": 30180
    },
    {
      "epoch": 2.576158375287994,
      "grad_norm": 0.19514848291873932,
      "learning_rate": 2.4238416247120062e-05,
      "loss": 0.0024,
      "step": 30190
    },
    {
      "epoch": 2.577011690417271,
      "grad_norm": 0.17113779485225677,
      "learning_rate": 2.422988309582729e-05,
      "loss": 0.0021,
      "step": 30200
    },
    {
      "epoch": 2.577865005546548,
      "grad_norm": 0.06691411137580872,
      "learning_rate": 2.422134994453452e-05,
      "loss": 0.0018,
      "step": 30210
    },
    {
      "epoch": 2.5787183206758257,
      "grad_norm": 0.226642444729805,
      "learning_rate": 2.4212816793241747e-05,
      "loss": 0.0022,
      "step": 30220
    },
    {
      "epoch": 2.579571635805103,
      "grad_norm": 0.10271621495485306,
      "learning_rate": 2.4204283641948972e-05,
      "loss": 0.0023,
      "step": 30230
    },
    {
      "epoch": 2.58042495093438,
      "grad_norm": 0.09099409729242325,
      "learning_rate": 2.41957504906562e-05,
      "loss": 0.0024,
      "step": 30240
    },
    {
      "epoch": 2.5812782660636575,
      "grad_norm": 0.31854572892189026,
      "learning_rate": 2.4187217339363426e-05,
      "loss": 0.0025,
      "step": 30250
    },
    {
      "epoch": 2.5821315811929346,
      "grad_norm": 0.1337585598230362,
      "learning_rate": 2.4178684188070654e-05,
      "loss": 0.0019,
      "step": 30260
    },
    {
      "epoch": 2.5829848963222117,
      "grad_norm": 0.39760443568229675,
      "learning_rate": 2.4170151036777883e-05,
      "loss": 0.0021,
      "step": 30270
    },
    {
      "epoch": 2.5838382114514893,
      "grad_norm": 0.4678851068019867,
      "learning_rate": 2.416161788548511e-05,
      "loss": 0.0028,
      "step": 30280
    },
    {
      "epoch": 2.5846915265807664,
      "grad_norm": 0.1507399082183838,
      "learning_rate": 2.415308473419234e-05,
      "loss": 0.0019,
      "step": 30290
    },
    {
      "epoch": 2.5855448417100435,
      "grad_norm": 0.3825507164001465,
      "learning_rate": 2.4144551582899565e-05,
      "loss": 0.0025,
      "step": 30300
    },
    {
      "epoch": 2.5863981568393206,
      "grad_norm": 0.15535806119441986,
      "learning_rate": 2.4136018431606794e-05,
      "loss": 0.0028,
      "step": 30310
    },
    {
      "epoch": 2.5872514719685977,
      "grad_norm": 0.12321481853723526,
      "learning_rate": 2.4127485280314022e-05,
      "loss": 0.0021,
      "step": 30320
    },
    {
      "epoch": 2.5881047870978753,
      "grad_norm": 0.09214913100004196,
      "learning_rate": 2.411895212902125e-05,
      "loss": 0.0026,
      "step": 30330
    },
    {
      "epoch": 2.5889581022271524,
      "grad_norm": 0.1932622492313385,
      "learning_rate": 2.4110418977728476e-05,
      "loss": 0.0016,
      "step": 30340
    },
    {
      "epoch": 2.5898114173564295,
      "grad_norm": 0.1682463437318802,
      "learning_rate": 2.4101885826435704e-05,
      "loss": 0.0022,
      "step": 30350
    },
    {
      "epoch": 2.590664732485707,
      "grad_norm": 0.07386134564876556,
      "learning_rate": 2.4093352675142933e-05,
      "loss": 0.0028,
      "step": 30360
    },
    {
      "epoch": 2.591518047614984,
      "grad_norm": 0.10056726634502411,
      "learning_rate": 2.4084819523850158e-05,
      "loss": 0.0019,
      "step": 30370
    },
    {
      "epoch": 2.5923713627442613,
      "grad_norm": 0.27110549807548523,
      "learning_rate": 2.4076286372557386e-05,
      "loss": 0.002,
      "step": 30380
    },
    {
      "epoch": 2.593224677873539,
      "grad_norm": 0.20990943908691406,
      "learning_rate": 2.4067753221264615e-05,
      "loss": 0.0018,
      "step": 30390
    },
    {
      "epoch": 2.594077993002816,
      "grad_norm": 0.11999816447496414,
      "learning_rate": 2.405922006997184e-05,
      "loss": 0.002,
      "step": 30400
    },
    {
      "epoch": 2.594931308132093,
      "grad_norm": 0.05693841725587845,
      "learning_rate": 2.4050686918679068e-05,
      "loss": 0.0027,
      "step": 30410
    },
    {
      "epoch": 2.5957846232613706,
      "grad_norm": 0.3326417803764343,
      "learning_rate": 2.4042153767386297e-05,
      "loss": 0.0026,
      "step": 30420
    },
    {
      "epoch": 2.5966379383906477,
      "grad_norm": 0.11987423151731491,
      "learning_rate": 2.4033620616093525e-05,
      "loss": 0.0025,
      "step": 30430
    },
    {
      "epoch": 2.597491253519925,
      "grad_norm": 0.14391416311264038,
      "learning_rate": 2.4025087464800754e-05,
      "loss": 0.002,
      "step": 30440
    },
    {
      "epoch": 2.5983445686492024,
      "grad_norm": 0.22188697755336761,
      "learning_rate": 2.401655431350798e-05,
      "loss": 0.002,
      "step": 30450
    },
    {
      "epoch": 2.5991978837784795,
      "grad_norm": 0.1608627587556839,
      "learning_rate": 2.4008021162215207e-05,
      "loss": 0.0025,
      "step": 30460
    },
    {
      "epoch": 2.6000511989077566,
      "grad_norm": 0.07042389363050461,
      "learning_rate": 2.3999488010922436e-05,
      "loss": 0.0022,
      "step": 30470
    },
    {
      "epoch": 2.6009045140370337,
      "grad_norm": 0.6621741652488708,
      "learning_rate": 2.3990954859629664e-05,
      "loss": 0.0019,
      "step": 30480
    },
    {
      "epoch": 2.6017578291663113,
      "grad_norm": 0.34511250257492065,
      "learning_rate": 2.3982421708336893e-05,
      "loss": 0.0023,
      "step": 30490
    },
    {
      "epoch": 2.6026111442955884,
      "grad_norm": 0.3983405828475952,
      "learning_rate": 2.3973888557044118e-05,
      "loss": 0.0021,
      "step": 30500
    },
    {
      "epoch": 2.6034644594248655,
      "grad_norm": 0.19476476311683655,
      "learning_rate": 2.3965355405751343e-05,
      "loss": 0.0026,
      "step": 30510
    },
    {
      "epoch": 2.6043177745541426,
      "grad_norm": 0.12588666379451752,
      "learning_rate": 2.395682225445857e-05,
      "loss": 0.0017,
      "step": 30520
    },
    {
      "epoch": 2.60517108968342,
      "grad_norm": 0.08184994757175446,
      "learning_rate": 2.39482891031658e-05,
      "loss": 0.0021,
      "step": 30530
    },
    {
      "epoch": 2.6060244048126973,
      "grad_norm": 0.14056678116321564,
      "learning_rate": 2.3939755951873028e-05,
      "loss": 0.0025,
      "step": 30540
    },
    {
      "epoch": 2.6068777199419744,
      "grad_norm": 0.37921321392059326,
      "learning_rate": 2.3931222800580257e-05,
      "loss": 0.0026,
      "step": 30550
    },
    {
      "epoch": 2.607731035071252,
      "grad_norm": 0.0825217142701149,
      "learning_rate": 2.3922689649287482e-05,
      "loss": 0.002,
      "step": 30560
    },
    {
      "epoch": 2.608584350200529,
      "grad_norm": 0.11075903475284576,
      "learning_rate": 2.391415649799471e-05,
      "loss": 0.0019,
      "step": 30570
    },
    {
      "epoch": 2.609437665329806,
      "grad_norm": 0.23716558516025543,
      "learning_rate": 2.390562334670194e-05,
      "loss": 0.0025,
      "step": 30580
    },
    {
      "epoch": 2.6102909804590837,
      "grad_norm": 0.07065358012914658,
      "learning_rate": 2.3897090195409167e-05,
      "loss": 0.0015,
      "step": 30590
    },
    {
      "epoch": 2.611144295588361,
      "grad_norm": 0.26032352447509766,
      "learning_rate": 2.3888557044116396e-05,
      "loss": 0.002,
      "step": 30600
    },
    {
      "epoch": 2.611997610717638,
      "grad_norm": 0.05213351175189018,
      "learning_rate": 2.388002389282362e-05,
      "loss": 0.0023,
      "step": 30610
    },
    {
      "epoch": 2.6128509258469155,
      "grad_norm": 0.3467349708080292,
      "learning_rate": 2.387149074153085e-05,
      "loss": 0.0021,
      "step": 30620
    },
    {
      "epoch": 2.6137042409761926,
      "grad_norm": 0.1766691356897354,
      "learning_rate": 2.3862957590238074e-05,
      "loss": 0.0023,
      "step": 30630
    },
    {
      "epoch": 2.6145575561054697,
      "grad_norm": 0.18600884079933167,
      "learning_rate": 2.3854424438945303e-05,
      "loss": 0.0022,
      "step": 30640
    },
    {
      "epoch": 2.6154108712347472,
      "grad_norm": 0.21937230229377747,
      "learning_rate": 2.384589128765253e-05,
      "loss": 0.0025,
      "step": 30650
    },
    {
      "epoch": 2.6162641863640244,
      "grad_norm": 0.4140183627605438,
      "learning_rate": 2.3837358136359757e-05,
      "loss": 0.0022,
      "step": 30660
    },
    {
      "epoch": 2.6171175014933015,
      "grad_norm": 0.23493626713752747,
      "learning_rate": 2.3828824985066985e-05,
      "loss": 0.0026,
      "step": 30670
    },
    {
      "epoch": 2.6179708166225786,
      "grad_norm": 0.1512112021446228,
      "learning_rate": 2.3820291833774213e-05,
      "loss": 0.0026,
      "step": 30680
    },
    {
      "epoch": 2.6188241317518557,
      "grad_norm": 0.25595399737358093,
      "learning_rate": 2.3811758682481442e-05,
      "loss": 0.0021,
      "step": 30690
    },
    {
      "epoch": 2.6196774468811332,
      "grad_norm": 0.23465684056282043,
      "learning_rate": 2.380322553118867e-05,
      "loss": 0.0022,
      "step": 30700
    },
    {
      "epoch": 2.6205307620104104,
      "grad_norm": 0.17203418910503387,
      "learning_rate": 2.3794692379895896e-05,
      "loss": 0.0023,
      "step": 30710
    },
    {
      "epoch": 2.6213840771396875,
      "grad_norm": 0.2297845035791397,
      "learning_rate": 2.3786159228603124e-05,
      "loss": 0.0019,
      "step": 30720
    },
    {
      "epoch": 2.622237392268965,
      "grad_norm": 0.031930483877658844,
      "learning_rate": 2.3777626077310352e-05,
      "loss": 0.0029,
      "step": 30730
    },
    {
      "epoch": 2.623090707398242,
      "grad_norm": 0.10170943289995193,
      "learning_rate": 2.376909292601758e-05,
      "loss": 0.0021,
      "step": 30740
    },
    {
      "epoch": 2.6239440225275192,
      "grad_norm": 0.07193353772163391,
      "learning_rate": 2.376055977472481e-05,
      "loss": 0.0019,
      "step": 30750
    },
    {
      "epoch": 2.624797337656797,
      "grad_norm": 0.08126217871904373,
      "learning_rate": 2.3752026623432035e-05,
      "loss": 0.0027,
      "step": 30760
    },
    {
      "epoch": 2.625650652786074,
      "grad_norm": 0.3627164363861084,
      "learning_rate": 2.374349347213926e-05,
      "loss": 0.0026,
      "step": 30770
    },
    {
      "epoch": 2.626503967915351,
      "grad_norm": 0.052393268793821335,
      "learning_rate": 2.3734960320846488e-05,
      "loss": 0.0022,
      "step": 30780
    },
    {
      "epoch": 2.6273572830446286,
      "grad_norm": 0.16449621319770813,
      "learning_rate": 2.3726427169553717e-05,
      "loss": 0.0031,
      "step": 30790
    },
    {
      "epoch": 2.6282105981739057,
      "grad_norm": 0.35480767488479614,
      "learning_rate": 2.3717894018260945e-05,
      "loss": 0.0028,
      "step": 30800
    },
    {
      "epoch": 2.629063913303183,
      "grad_norm": 0.10079232603311539,
      "learning_rate": 2.3709360866968174e-05,
      "loss": 0.0019,
      "step": 30810
    },
    {
      "epoch": 2.6299172284324603,
      "grad_norm": 0.34640568494796753,
      "learning_rate": 2.37008277156754e-05,
      "loss": 0.0024,
      "step": 30820
    },
    {
      "epoch": 2.6307705435617375,
      "grad_norm": 0.47900182008743286,
      "learning_rate": 2.3692294564382627e-05,
      "loss": 0.0022,
      "step": 30830
    },
    {
      "epoch": 2.6316238586910146,
      "grad_norm": 0.026819845661520958,
      "learning_rate": 2.3683761413089856e-05,
      "loss": 0.0023,
      "step": 30840
    },
    {
      "epoch": 2.6324771738202917,
      "grad_norm": 0.31868091225624084,
      "learning_rate": 2.3675228261797084e-05,
      "loss": 0.0022,
      "step": 30850
    },
    {
      "epoch": 2.6333304889495692,
      "grad_norm": 0.04086930304765701,
      "learning_rate": 2.3666695110504313e-05,
      "loss": 0.0019,
      "step": 30860
    },
    {
      "epoch": 2.6341838040788463,
      "grad_norm": 0.19275856018066406,
      "learning_rate": 2.3658161959211538e-05,
      "loss": 0.0021,
      "step": 30870
    },
    {
      "epoch": 2.6350371192081234,
      "grad_norm": 0.2886941134929657,
      "learning_rate": 2.3649628807918766e-05,
      "loss": 0.0018,
      "step": 30880
    },
    {
      "epoch": 2.6358904343374006,
      "grad_norm": 0.18223844468593597,
      "learning_rate": 2.3641095656625995e-05,
      "loss": 0.0025,
      "step": 30890
    },
    {
      "epoch": 2.636743749466678,
      "grad_norm": 0.382236123085022,
      "learning_rate": 2.363256250533322e-05,
      "loss": 0.003,
      "step": 30900
    },
    {
      "epoch": 2.637597064595955,
      "grad_norm": 0.15040923655033112,
      "learning_rate": 2.3624029354040448e-05,
      "loss": 0.0027,
      "step": 30910
    },
    {
      "epoch": 2.6384503797252323,
      "grad_norm": 0.539691686630249,
      "learning_rate": 2.3615496202747677e-05,
      "loss": 0.0028,
      "step": 30920
    },
    {
      "epoch": 2.63930369485451,
      "grad_norm": 0.07079439610242844,
      "learning_rate": 2.3606963051454902e-05,
      "loss": 0.0022,
      "step": 30930
    },
    {
      "epoch": 2.640157009983787,
      "grad_norm": 0.18219585716724396,
      "learning_rate": 2.359842990016213e-05,
      "loss": 0.0026,
      "step": 30940
    },
    {
      "epoch": 2.641010325113064,
      "grad_norm": 0.05900135636329651,
      "learning_rate": 2.358989674886936e-05,
      "loss": 0.0023,
      "step": 30950
    },
    {
      "epoch": 2.6418636402423417,
      "grad_norm": 0.19270022213459015,
      "learning_rate": 2.3581363597576587e-05,
      "loss": 0.0021,
      "step": 30960
    },
    {
      "epoch": 2.6427169553716188,
      "grad_norm": 0.16847816109657288,
      "learning_rate": 2.3572830446283812e-05,
      "loss": 0.0018,
      "step": 30970
    },
    {
      "epoch": 2.643570270500896,
      "grad_norm": 0.21310880780220032,
      "learning_rate": 2.356429729499104e-05,
      "loss": 0.0024,
      "step": 30980
    },
    {
      "epoch": 2.6444235856301734,
      "grad_norm": 0.449769526720047,
      "learning_rate": 2.355576414369827e-05,
      "loss": 0.0023,
      "step": 30990
    },
    {
      "epoch": 2.6452769007594505,
      "grad_norm": 0.19638827443122864,
      "learning_rate": 2.3547230992405498e-05,
      "loss": 0.0024,
      "step": 31000
    },
    {
      "epoch": 2.6461302158887277,
      "grad_norm": 0.20152603089809418,
      "learning_rate": 2.3538697841112726e-05,
      "loss": 0.0022,
      "step": 31010
    },
    {
      "epoch": 2.646983531018005,
      "grad_norm": 0.09976935386657715,
      "learning_rate": 2.353016468981995e-05,
      "loss": 0.002,
      "step": 31020
    },
    {
      "epoch": 2.6478368461472823,
      "grad_norm": 0.06517782807350159,
      "learning_rate": 2.3521631538527176e-05,
      "loss": 0.0021,
      "step": 31030
    },
    {
      "epoch": 2.6486901612765594,
      "grad_norm": 0.12177053093910217,
      "learning_rate": 2.3513098387234405e-05,
      "loss": 0.002,
      "step": 31040
    },
    {
      "epoch": 2.6495434764058365,
      "grad_norm": 0.17562243342399597,
      "learning_rate": 2.3504565235941633e-05,
      "loss": 0.0025,
      "step": 31050
    },
    {
      "epoch": 2.6503967915351136,
      "grad_norm": 0.05856337398290634,
      "learning_rate": 2.3496032084648862e-05,
      "loss": 0.0022,
      "step": 31060
    },
    {
      "epoch": 2.651250106664391,
      "grad_norm": 0.223713219165802,
      "learning_rate": 2.348749893335609e-05,
      "loss": 0.0019,
      "step": 31070
    },
    {
      "epoch": 2.6521034217936683,
      "grad_norm": 0.46202343702316284,
      "learning_rate": 2.3478965782063315e-05,
      "loss": 0.0023,
      "step": 31080
    },
    {
      "epoch": 2.6529567369229454,
      "grad_norm": 0.24548105895519257,
      "learning_rate": 2.3470432630770544e-05,
      "loss": 0.0027,
      "step": 31090
    },
    {
      "epoch": 2.653810052052223,
      "grad_norm": 0.21192128956317902,
      "learning_rate": 2.3461899479477772e-05,
      "loss": 0.0017,
      "step": 31100
    },
    {
      "epoch": 2.6546633671815,
      "grad_norm": 0.08820582181215286,
      "learning_rate": 2.3453366328185e-05,
      "loss": 0.0028,
      "step": 31110
    },
    {
      "epoch": 2.655516682310777,
      "grad_norm": 0.2775237560272217,
      "learning_rate": 2.344483317689223e-05,
      "loss": 0.0019,
      "step": 31120
    },
    {
      "epoch": 2.6563699974400548,
      "grad_norm": 0.04953170195221901,
      "learning_rate": 2.3436300025599454e-05,
      "loss": 0.0024,
      "step": 31130
    },
    {
      "epoch": 2.657223312569332,
      "grad_norm": 0.06428077816963196,
      "learning_rate": 2.3427766874306683e-05,
      "loss": 0.0024,
      "step": 31140
    },
    {
      "epoch": 2.658076627698609,
      "grad_norm": 0.1861022412776947,
      "learning_rate": 2.341923372301391e-05,
      "loss": 0.0025,
      "step": 31150
    },
    {
      "epoch": 2.6589299428278865,
      "grad_norm": 0.20373478531837463,
      "learning_rate": 2.3410700571721137e-05,
      "loss": 0.0021,
      "step": 31160
    },
    {
      "epoch": 2.6597832579571636,
      "grad_norm": 0.2685139775276184,
      "learning_rate": 2.3402167420428365e-05,
      "loss": 0.0023,
      "step": 31170
    },
    {
      "epoch": 2.6606365730864407,
      "grad_norm": 0.24658532440662384,
      "learning_rate": 2.3393634269135594e-05,
      "loss": 0.0027,
      "step": 31180
    },
    {
      "epoch": 2.6614898882157183,
      "grad_norm": 0.1727384626865387,
      "learning_rate": 2.338510111784282e-05,
      "loss": 0.002,
      "step": 31190
    },
    {
      "epoch": 2.6623432033449954,
      "grad_norm": 0.05980750918388367,
      "learning_rate": 2.3376567966550047e-05,
      "loss": 0.0022,
      "step": 31200
    },
    {
      "epoch": 2.6631965184742725,
      "grad_norm": 0.1931302547454834,
      "learning_rate": 2.3368034815257276e-05,
      "loss": 0.0022,
      "step": 31210
    },
    {
      "epoch": 2.6640498336035496,
      "grad_norm": 0.24059370160102844,
      "learning_rate": 2.3359501663964504e-05,
      "loss": 0.0026,
      "step": 31220
    },
    {
      "epoch": 2.664903148732827,
      "grad_norm": 0.13176187872886658,
      "learning_rate": 2.3350968512671733e-05,
      "loss": 0.0019,
      "step": 31230
    },
    {
      "epoch": 2.6657564638621043,
      "grad_norm": 0.08591948449611664,
      "learning_rate": 2.3342435361378958e-05,
      "loss": 0.0023,
      "step": 31240
    },
    {
      "epoch": 2.6666097789913814,
      "grad_norm": 0.1375105232000351,
      "learning_rate": 2.3333902210086186e-05,
      "loss": 0.0016,
      "step": 31250
    },
    {
      "epoch": 2.6674630941206585,
      "grad_norm": 0.514541745185852,
      "learning_rate": 2.3325369058793415e-05,
      "loss": 0.002,
      "step": 31260
    },
    {
      "epoch": 2.668316409249936,
      "grad_norm": 0.05906080827116966,
      "learning_rate": 2.3316835907500643e-05,
      "loss": 0.0021,
      "step": 31270
    },
    {
      "epoch": 2.669169724379213,
      "grad_norm": 0.2737799286842346,
      "learning_rate": 2.3308302756207868e-05,
      "loss": 0.0016,
      "step": 31280
    },
    {
      "epoch": 2.6700230395084903,
      "grad_norm": 0.1584063321352005,
      "learning_rate": 2.3299769604915097e-05,
      "loss": 0.0024,
      "step": 31290
    },
    {
      "epoch": 2.670876354637768,
      "grad_norm": 0.04368821904063225,
      "learning_rate": 2.3291236453622322e-05,
      "loss": 0.0025,
      "step": 31300
    },
    {
      "epoch": 2.671729669767045,
      "grad_norm": 0.10818114876747131,
      "learning_rate": 2.328270330232955e-05,
      "loss": 0.0017,
      "step": 31310
    },
    {
      "epoch": 2.672582984896322,
      "grad_norm": 0.2287241518497467,
      "learning_rate": 2.327417015103678e-05,
      "loss": 0.0018,
      "step": 31320
    },
    {
      "epoch": 2.6734363000255996,
      "grad_norm": 0.09364207088947296,
      "learning_rate": 2.3265636999744007e-05,
      "loss": 0.0018,
      "step": 31330
    },
    {
      "epoch": 2.6742896151548767,
      "grad_norm": 0.0456746444106102,
      "learning_rate": 2.3257103848451232e-05,
      "loss": 0.0022,
      "step": 31340
    },
    {
      "epoch": 2.675142930284154,
      "grad_norm": 0.15462340414524078,
      "learning_rate": 2.324857069715846e-05,
      "loss": 0.0023,
      "step": 31350
    },
    {
      "epoch": 2.6759962454134314,
      "grad_norm": 0.11059630662202835,
      "learning_rate": 2.324003754586569e-05,
      "loss": 0.0019,
      "step": 31360
    },
    {
      "epoch": 2.6768495605427085,
      "grad_norm": 0.09793765842914581,
      "learning_rate": 2.3231504394572918e-05,
      "loss": 0.0026,
      "step": 31370
    },
    {
      "epoch": 2.6777028756719856,
      "grad_norm": 0.1904502511024475,
      "learning_rate": 2.3222971243280146e-05,
      "loss": 0.0023,
      "step": 31380
    },
    {
      "epoch": 2.678556190801263,
      "grad_norm": 0.06757763773202896,
      "learning_rate": 2.321443809198737e-05,
      "loss": 0.0024,
      "step": 31390
    },
    {
      "epoch": 2.6794095059305403,
      "grad_norm": 0.21400807797908783,
      "learning_rate": 2.32059049406946e-05,
      "loss": 0.0019,
      "step": 31400
    },
    {
      "epoch": 2.6802628210598174,
      "grad_norm": 0.13215452432632446,
      "learning_rate": 2.3197371789401828e-05,
      "loss": 0.002,
      "step": 31410
    },
    {
      "epoch": 2.6811161361890945,
      "grad_norm": 0.049620822072029114,
      "learning_rate": 2.3188838638109057e-05,
      "loss": 0.0025,
      "step": 31420
    },
    {
      "epoch": 2.6819694513183716,
      "grad_norm": 0.2507483661174774,
      "learning_rate": 2.3180305486816282e-05,
      "loss": 0.003,
      "step": 31430
    },
    {
      "epoch": 2.682822766447649,
      "grad_norm": 0.1628136783838272,
      "learning_rate": 2.317177233552351e-05,
      "loss": 0.0031,
      "step": 31440
    },
    {
      "epoch": 2.6836760815769263,
      "grad_norm": 0.3271261155605316,
      "learning_rate": 2.3163239184230735e-05,
      "loss": 0.0021,
      "step": 31450
    },
    {
      "epoch": 2.6845293967062034,
      "grad_norm": 0.1271091103553772,
      "learning_rate": 2.3154706032937964e-05,
      "loss": 0.0029,
      "step": 31460
    },
    {
      "epoch": 2.685382711835481,
      "grad_norm": 0.3630407750606537,
      "learning_rate": 2.3146172881645192e-05,
      "loss": 0.0022,
      "step": 31470
    },
    {
      "epoch": 2.686236026964758,
      "grad_norm": 0.1943717747926712,
      "learning_rate": 2.313763973035242e-05,
      "loss": 0.0022,
      "step": 31480
    },
    {
      "epoch": 2.687089342094035,
      "grad_norm": 0.45035871863365173,
      "learning_rate": 2.312910657905965e-05,
      "loss": 0.0018,
      "step": 31490
    },
    {
      "epoch": 2.6879426572233127,
      "grad_norm": 0.30644533038139343,
      "learning_rate": 2.3120573427766874e-05,
      "loss": 0.0021,
      "step": 31500
    },
    {
      "epoch": 2.68879597235259,
      "grad_norm": 0.3646656274795532,
      "learning_rate": 2.3112040276474103e-05,
      "loss": 0.0027,
      "step": 31510
    },
    {
      "epoch": 2.689649287481867,
      "grad_norm": 0.2184644192457199,
      "learning_rate": 2.310350712518133e-05,
      "loss": 0.0021,
      "step": 31520
    },
    {
      "epoch": 2.6905026026111445,
      "grad_norm": 0.1262626200914383,
      "learning_rate": 2.309497397388856e-05,
      "loss": 0.0027,
      "step": 31530
    },
    {
      "epoch": 2.6913559177404216,
      "grad_norm": 0.1209893599152565,
      "learning_rate": 2.308644082259579e-05,
      "loss": 0.0022,
      "step": 31540
    },
    {
      "epoch": 2.6922092328696987,
      "grad_norm": 0.2004971206188202,
      "learning_rate": 2.3077907671303013e-05,
      "loss": 0.0029,
      "step": 31550
    },
    {
      "epoch": 2.6930625479989763,
      "grad_norm": 0.07110987603664398,
      "learning_rate": 2.306937452001024e-05,
      "loss": 0.0024,
      "step": 31560
    },
    {
      "epoch": 2.6939158631282534,
      "grad_norm": 0.0436599925160408,
      "learning_rate": 2.3060841368717467e-05,
      "loss": 0.002,
      "step": 31570
    },
    {
      "epoch": 2.6947691782575305,
      "grad_norm": 0.3103092908859253,
      "learning_rate": 2.3052308217424696e-05,
      "loss": 0.0021,
      "step": 31580
    },
    {
      "epoch": 2.6956224933868076,
      "grad_norm": 0.3722224235534668,
      "learning_rate": 2.3043775066131924e-05,
      "loss": 0.0028,
      "step": 31590
    },
    {
      "epoch": 2.696475808516085,
      "grad_norm": 0.11855614185333252,
      "learning_rate": 2.303524191483915e-05,
      "loss": 0.0024,
      "step": 31600
    },
    {
      "epoch": 2.6973291236453623,
      "grad_norm": 0.08409267663955688,
      "learning_rate": 2.3026708763546378e-05,
      "loss": 0.0016,
      "step": 31610
    },
    {
      "epoch": 2.6981824387746394,
      "grad_norm": 0.12305466830730438,
      "learning_rate": 2.3018175612253606e-05,
      "loss": 0.0024,
      "step": 31620
    },
    {
      "epoch": 2.6990357539039165,
      "grad_norm": 0.06235214322805405,
      "learning_rate": 2.3009642460960835e-05,
      "loss": 0.0022,
      "step": 31630
    },
    {
      "epoch": 2.699889069033194,
      "grad_norm": 0.3471144437789917,
      "learning_rate": 2.3001109309668063e-05,
      "loss": 0.002,
      "step": 31640
    },
    {
      "epoch": 2.700742384162471,
      "grad_norm": 0.17666614055633545,
      "learning_rate": 2.2992576158375288e-05,
      "loss": 0.0023,
      "step": 31650
    },
    {
      "epoch": 2.7015956992917483,
      "grad_norm": 0.21454522013664246,
      "learning_rate": 2.2984043007082517e-05,
      "loss": 0.0024,
      "step": 31660
    },
    {
      "epoch": 2.702449014421026,
      "grad_norm": 0.21960346400737762,
      "learning_rate": 2.2975509855789745e-05,
      "loss": 0.0027,
      "step": 31670
    },
    {
      "epoch": 2.703302329550303,
      "grad_norm": 0.19922035932540894,
      "learning_rate": 2.2966976704496974e-05,
      "loss": 0.0019,
      "step": 31680
    },
    {
      "epoch": 2.70415564467958,
      "grad_norm": 0.03058195300400257,
      "learning_rate": 2.29584435532042e-05,
      "loss": 0.0017,
      "step": 31690
    },
    {
      "epoch": 2.7050089598088576,
      "grad_norm": 0.07905125617980957,
      "learning_rate": 2.2949910401911427e-05,
      "loss": 0.0025,
      "step": 31700
    },
    {
      "epoch": 2.7058622749381347,
      "grad_norm": 0.1403639167547226,
      "learning_rate": 2.2941377250618652e-05,
      "loss": 0.0021,
      "step": 31710
    },
    {
      "epoch": 2.706715590067412,
      "grad_norm": 0.5445010662078857,
      "learning_rate": 2.293284409932588e-05,
      "loss": 0.0021,
      "step": 31720
    },
    {
      "epoch": 2.7075689051966894,
      "grad_norm": 0.07679042965173721,
      "learning_rate": 2.292431094803311e-05,
      "loss": 0.002,
      "step": 31730
    },
    {
      "epoch": 2.7084222203259665,
      "grad_norm": 0.16527505218982697,
      "learning_rate": 2.2915777796740338e-05,
      "loss": 0.0021,
      "step": 31740
    },
    {
      "epoch": 2.7092755354552436,
      "grad_norm": 0.22288523614406586,
      "learning_rate": 2.2907244645447566e-05,
      "loss": 0.0021,
      "step": 31750
    },
    {
      "epoch": 2.710128850584521,
      "grad_norm": 0.3021271228790283,
      "learning_rate": 2.289871149415479e-05,
      "loss": 0.0015,
      "step": 31760
    },
    {
      "epoch": 2.7109821657137982,
      "grad_norm": 0.07826010882854462,
      "learning_rate": 2.289017834286202e-05,
      "loss": 0.0024,
      "step": 31770
    },
    {
      "epoch": 2.7118354808430754,
      "grad_norm": 0.14234000444412231,
      "learning_rate": 2.2881645191569248e-05,
      "loss": 0.0023,
      "step": 31780
    },
    {
      "epoch": 2.7126887959723525,
      "grad_norm": 0.07042153179645538,
      "learning_rate": 2.2873112040276477e-05,
      "loss": 0.0025,
      "step": 31790
    },
    {
      "epoch": 2.7135421111016296,
      "grad_norm": 0.4436758756637573,
      "learning_rate": 2.2864578888983705e-05,
      "loss": 0.0019,
      "step": 31800
    },
    {
      "epoch": 2.714395426230907,
      "grad_norm": 0.20884902775287628,
      "learning_rate": 2.285604573769093e-05,
      "loss": 0.0021,
      "step": 31810
    },
    {
      "epoch": 2.7152487413601842,
      "grad_norm": 0.20721837878227234,
      "learning_rate": 2.284751258639816e-05,
      "loss": 0.0023,
      "step": 31820
    },
    {
      "epoch": 2.7161020564894613,
      "grad_norm": 0.1511644721031189,
      "learning_rate": 2.2838979435105384e-05,
      "loss": 0.0019,
      "step": 31830
    },
    {
      "epoch": 2.716955371618739,
      "grad_norm": 0.07169605046510696,
      "learning_rate": 2.2830446283812612e-05,
      "loss": 0.002,
      "step": 31840
    },
    {
      "epoch": 2.717808686748016,
      "grad_norm": 0.10584016889333725,
      "learning_rate": 2.282191313251984e-05,
      "loss": 0.0026,
      "step": 31850
    },
    {
      "epoch": 2.718662001877293,
      "grad_norm": 0.05578991770744324,
      "learning_rate": 2.281337998122707e-05,
      "loss": 0.002,
      "step": 31860
    },
    {
      "epoch": 2.7195153170065707,
      "grad_norm": 0.21934597194194794,
      "learning_rate": 2.2804846829934294e-05,
      "loss": 0.0023,
      "step": 31870
    },
    {
      "epoch": 2.720368632135848,
      "grad_norm": 0.10097872465848923,
      "learning_rate": 2.2796313678641523e-05,
      "loss": 0.0033,
      "step": 31880
    },
    {
      "epoch": 2.721221947265125,
      "grad_norm": 0.053671080619096756,
      "learning_rate": 2.278778052734875e-05,
      "loss": 0.0021,
      "step": 31890
    },
    {
      "epoch": 2.7220752623944025,
      "grad_norm": 0.17769981920719147,
      "learning_rate": 2.277924737605598e-05,
      "loss": 0.0019,
      "step": 31900
    },
    {
      "epoch": 2.7229285775236796,
      "grad_norm": 0.20179587602615356,
      "learning_rate": 2.2770714224763205e-05,
      "loss": 0.002,
      "step": 31910
    },
    {
      "epoch": 2.7237818926529567,
      "grad_norm": 0.10015317052602768,
      "learning_rate": 2.2762181073470433e-05,
      "loss": 0.0025,
      "step": 31920
    },
    {
      "epoch": 2.7246352077822342,
      "grad_norm": 0.29425710439682007,
      "learning_rate": 2.2753647922177662e-05,
      "loss": 0.0022,
      "step": 31930
    },
    {
      "epoch": 2.7254885229115113,
      "grad_norm": 0.06955724209547043,
      "learning_rate": 2.274511477088489e-05,
      "loss": 0.0024,
      "step": 31940
    },
    {
      "epoch": 2.7263418380407884,
      "grad_norm": 0.30491355061531067,
      "learning_rate": 2.273658161959212e-05,
      "loss": 0.0025,
      "step": 31950
    },
    {
      "epoch": 2.7271951531700656,
      "grad_norm": 0.13411472737789154,
      "learning_rate": 2.2728048468299344e-05,
      "loss": 0.0018,
      "step": 31960
    },
    {
      "epoch": 2.728048468299343,
      "grad_norm": 0.27349579334259033,
      "learning_rate": 2.271951531700657e-05,
      "loss": 0.0022,
      "step": 31970
    },
    {
      "epoch": 2.72890178342862,
      "grad_norm": 0.09812131524085999,
      "learning_rate": 2.2710982165713798e-05,
      "loss": 0.002,
      "step": 31980
    },
    {
      "epoch": 2.7297550985578973,
      "grad_norm": 0.1649569869041443,
      "learning_rate": 2.2702449014421026e-05,
      "loss": 0.0026,
      "step": 31990
    },
    {
      "epoch": 2.7306084136871744,
      "grad_norm": 0.2678442895412445,
      "learning_rate": 2.2693915863128254e-05,
      "loss": 0.0023,
      "step": 32000
    },
    {
      "epoch": 2.731461728816452,
      "grad_norm": 0.0823376476764679,
      "learning_rate": 2.2685382711835483e-05,
      "loss": 0.0018,
      "step": 32010
    },
    {
      "epoch": 2.732315043945729,
      "grad_norm": 0.21092459559440613,
      "learning_rate": 2.2676849560542708e-05,
      "loss": 0.0028,
      "step": 32020
    },
    {
      "epoch": 2.733168359075006,
      "grad_norm": 0.037133559584617615,
      "learning_rate": 2.2668316409249937e-05,
      "loss": 0.0023,
      "step": 32030
    },
    {
      "epoch": 2.7340216742042838,
      "grad_norm": 0.2858138084411621,
      "learning_rate": 2.2659783257957165e-05,
      "loss": 0.002,
      "step": 32040
    },
    {
      "epoch": 2.734874989333561,
      "grad_norm": 0.14225198328495026,
      "learning_rate": 2.2651250106664394e-05,
      "loss": 0.0026,
      "step": 32050
    },
    {
      "epoch": 2.735728304462838,
      "grad_norm": 0.40455445647239685,
      "learning_rate": 2.2642716955371622e-05,
      "loss": 0.0019,
      "step": 32060
    },
    {
      "epoch": 2.7365816195921155,
      "grad_norm": 0.05730221047997475,
      "learning_rate": 2.2634183804078847e-05,
      "loss": 0.0019,
      "step": 32070
    },
    {
      "epoch": 2.7374349347213927,
      "grad_norm": 0.16137199103832245,
      "learning_rate": 2.2625650652786076e-05,
      "loss": 0.0024,
      "step": 32080
    },
    {
      "epoch": 2.7382882498506698,
      "grad_norm": 0.236781507730484,
      "learning_rate": 2.26171175014933e-05,
      "loss": 0.0028,
      "step": 32090
    },
    {
      "epoch": 2.7391415649799473,
      "grad_norm": 0.06401403993368149,
      "learning_rate": 2.260858435020053e-05,
      "loss": 0.0014,
      "step": 32100
    },
    {
      "epoch": 2.7399948801092244,
      "grad_norm": 0.21262326836585999,
      "learning_rate": 2.2600051198907758e-05,
      "loss": 0.0022,
      "step": 32110
    },
    {
      "epoch": 2.7408481952385015,
      "grad_norm": 0.25579598546028137,
      "learning_rate": 2.2591518047614986e-05,
      "loss": 0.0019,
      "step": 32120
    },
    {
      "epoch": 2.741701510367779,
      "grad_norm": 0.044457513839006424,
      "learning_rate": 2.258298489632221e-05,
      "loss": 0.0026,
      "step": 32130
    },
    {
      "epoch": 2.742554825497056,
      "grad_norm": 0.3066946566104889,
      "learning_rate": 2.257445174502944e-05,
      "loss": 0.0023,
      "step": 32140
    },
    {
      "epoch": 2.7434081406263333,
      "grad_norm": 0.2684060335159302,
      "learning_rate": 2.2565918593736668e-05,
      "loss": 0.0027,
      "step": 32150
    },
    {
      "epoch": 2.7442614557556104,
      "grad_norm": 0.2939833998680115,
      "learning_rate": 2.2557385442443897e-05,
      "loss": 0.0021,
      "step": 32160
    },
    {
      "epoch": 2.7451147708848875,
      "grad_norm": 0.1609954684972763,
      "learning_rate": 2.2548852291151125e-05,
      "loss": 0.0024,
      "step": 32170
    },
    {
      "epoch": 2.745968086014165,
      "grad_norm": 0.13639630377292633,
      "learning_rate": 2.254031913985835e-05,
      "loss": 0.0019,
      "step": 32180
    },
    {
      "epoch": 2.746821401143442,
      "grad_norm": 0.19423532485961914,
      "learning_rate": 2.253178598856558e-05,
      "loss": 0.0018,
      "step": 32190
    },
    {
      "epoch": 2.7476747162727193,
      "grad_norm": 0.14152219891548157,
      "learning_rate": 2.2523252837272807e-05,
      "loss": 0.0023,
      "step": 32200
    },
    {
      "epoch": 2.748528031401997,
      "grad_norm": 0.10804855078458786,
      "learning_rate": 2.2514719685980036e-05,
      "loss": 0.0021,
      "step": 32210
    },
    {
      "epoch": 2.749381346531274,
      "grad_norm": 0.2360346019268036,
      "learning_rate": 2.250618653468726e-05,
      "loss": 0.0021,
      "step": 32220
    },
    {
      "epoch": 2.750234661660551,
      "grad_norm": 0.19756731390953064,
      "learning_rate": 2.2497653383394486e-05,
      "loss": 0.0017,
      "step": 32230
    },
    {
      "epoch": 2.7510879767898286,
      "grad_norm": 0.24842162430286407,
      "learning_rate": 2.2489120232101714e-05,
      "loss": 0.0024,
      "step": 32240
    },
    {
      "epoch": 2.7519412919191057,
      "grad_norm": 0.3930649757385254,
      "learning_rate": 2.2480587080808943e-05,
      "loss": 0.0023,
      "step": 32250
    },
    {
      "epoch": 2.752794607048383,
      "grad_norm": 0.30917075276374817,
      "learning_rate": 2.247205392951617e-05,
      "loss": 0.0025,
      "step": 32260
    },
    {
      "epoch": 2.7536479221776604,
      "grad_norm": 0.17075538635253906,
      "learning_rate": 2.24635207782234e-05,
      "loss": 0.0024,
      "step": 32270
    },
    {
      "epoch": 2.7545012373069375,
      "grad_norm": 0.13754726946353912,
      "learning_rate": 2.2454987626930625e-05,
      "loss": 0.0029,
      "step": 32280
    },
    {
      "epoch": 2.7553545524362146,
      "grad_norm": 0.4627932608127594,
      "learning_rate": 2.2446454475637853e-05,
      "loss": 0.0024,
      "step": 32290
    },
    {
      "epoch": 2.756207867565492,
      "grad_norm": 0.053221963346004486,
      "learning_rate": 2.2437921324345082e-05,
      "loss": 0.0016,
      "step": 32300
    },
    {
      "epoch": 2.7570611826947693,
      "grad_norm": 0.25285714864730835,
      "learning_rate": 2.242938817305231e-05,
      "loss": 0.0026,
      "step": 32310
    },
    {
      "epoch": 2.7579144978240464,
      "grad_norm": 0.20512206852436066,
      "learning_rate": 2.242085502175954e-05,
      "loss": 0.0024,
      "step": 32320
    },
    {
      "epoch": 2.7587678129533235,
      "grad_norm": 0.2964670956134796,
      "learning_rate": 2.2412321870466764e-05,
      "loss": 0.0021,
      "step": 32330
    },
    {
      "epoch": 2.7596211280826006,
      "grad_norm": 0.125181183218956,
      "learning_rate": 2.2403788719173992e-05,
      "loss": 0.0018,
      "step": 32340
    },
    {
      "epoch": 2.760474443211878,
      "grad_norm": 0.06866970658302307,
      "learning_rate": 2.239525556788122e-05,
      "loss": 0.0028,
      "step": 32350
    },
    {
      "epoch": 2.7613277583411553,
      "grad_norm": 0.2696549594402313,
      "learning_rate": 2.2386722416588446e-05,
      "loss": 0.0026,
      "step": 32360
    },
    {
      "epoch": 2.7621810734704324,
      "grad_norm": 0.07884648442268372,
      "learning_rate": 2.2378189265295674e-05,
      "loss": 0.0021,
      "step": 32370
    },
    {
      "epoch": 2.76303438859971,
      "grad_norm": 0.19852645695209503,
      "learning_rate": 2.2369656114002903e-05,
      "loss": 0.0022,
      "step": 32380
    },
    {
      "epoch": 2.763887703728987,
      "grad_norm": 0.1238837018609047,
      "learning_rate": 2.2361122962710128e-05,
      "loss": 0.0021,
      "step": 32390
    },
    {
      "epoch": 2.764741018858264,
      "grad_norm": 0.1166561096906662,
      "learning_rate": 2.2352589811417357e-05,
      "loss": 0.0025,
      "step": 32400
    },
    {
      "epoch": 2.7655943339875417,
      "grad_norm": 0.18927867710590363,
      "learning_rate": 2.2344056660124585e-05,
      "loss": 0.0024,
      "step": 32410
    },
    {
      "epoch": 2.766447649116819,
      "grad_norm": 0.21700872480869293,
      "learning_rate": 2.2335523508831813e-05,
      "loss": 0.0022,
      "step": 32420
    },
    {
      "epoch": 2.767300964246096,
      "grad_norm": 0.20782619714736938,
      "learning_rate": 2.2326990357539042e-05,
      "loss": 0.0024,
      "step": 32430
    },
    {
      "epoch": 2.7681542793753735,
      "grad_norm": 0.40778300166130066,
      "learning_rate": 2.2318457206246267e-05,
      "loss": 0.0027,
      "step": 32440
    },
    {
      "epoch": 2.7690075945046506,
      "grad_norm": 0.09320887178182602,
      "learning_rate": 2.2309924054953496e-05,
      "loss": 0.0019,
      "step": 32450
    },
    {
      "epoch": 2.7698609096339277,
      "grad_norm": 0.3134993612766266,
      "learning_rate": 2.2301390903660724e-05,
      "loss": 0.0025,
      "step": 32460
    },
    {
      "epoch": 2.7707142247632053,
      "grad_norm": 0.15464553236961365,
      "learning_rate": 2.2292857752367952e-05,
      "loss": 0.0019,
      "step": 32470
    },
    {
      "epoch": 2.7715675398924824,
      "grad_norm": 0.2380390167236328,
      "learning_rate": 2.228432460107518e-05,
      "loss": 0.0022,
      "step": 32480
    },
    {
      "epoch": 2.7724208550217595,
      "grad_norm": 0.1367098093032837,
      "learning_rate": 2.2275791449782406e-05,
      "loss": 0.0023,
      "step": 32490
    },
    {
      "epoch": 2.773274170151037,
      "grad_norm": 0.18919597566127777,
      "learning_rate": 2.226725829848963e-05,
      "loss": 0.0019,
      "step": 32500
    },
    {
      "epoch": 2.774127485280314,
      "grad_norm": 0.06670501083135605,
      "learning_rate": 2.225872514719686e-05,
      "loss": 0.0019,
      "step": 32510
    },
    {
      "epoch": 2.7749808004095913,
      "grad_norm": 0.2971089482307434,
      "learning_rate": 2.2250191995904088e-05,
      "loss": 0.0023,
      "step": 32520
    },
    {
      "epoch": 2.7758341155388684,
      "grad_norm": 0.13363461196422577,
      "learning_rate": 2.2241658844611317e-05,
      "loss": 0.002,
      "step": 32530
    },
    {
      "epoch": 2.7766874306681455,
      "grad_norm": 0.18339897692203522,
      "learning_rate": 2.2233125693318542e-05,
      "loss": 0.0021,
      "step": 32540
    },
    {
      "epoch": 2.777540745797423,
      "grad_norm": 0.07824491709470749,
      "learning_rate": 2.222459254202577e-05,
      "loss": 0.0022,
      "step": 32550
    },
    {
      "epoch": 2.7783940609267,
      "grad_norm": 0.10856445878744125,
      "learning_rate": 2.2216059390733e-05,
      "loss": 0.0024,
      "step": 32560
    },
    {
      "epoch": 2.7792473760559773,
      "grad_norm": 0.17678870260715485,
      "learning_rate": 2.2207526239440227e-05,
      "loss": 0.0018,
      "step": 32570
    },
    {
      "epoch": 2.780100691185255,
      "grad_norm": 0.08062716573476791,
      "learning_rate": 2.2198993088147456e-05,
      "loss": 0.0015,
      "step": 32580
    },
    {
      "epoch": 2.780954006314532,
      "grad_norm": 0.1408766806125641,
      "learning_rate": 2.219045993685468e-05,
      "loss": 0.0017,
      "step": 32590
    },
    {
      "epoch": 2.781807321443809,
      "grad_norm": 0.3402969241142273,
      "learning_rate": 2.218192678556191e-05,
      "loss": 0.0025,
      "step": 32600
    },
    {
      "epoch": 2.7826606365730866,
      "grad_norm": 0.5224072337150574,
      "learning_rate": 2.2173393634269138e-05,
      "loss": 0.0015,
      "step": 32610
    },
    {
      "epoch": 2.7835139517023637,
      "grad_norm": 0.40012863278388977,
      "learning_rate": 2.2164860482976363e-05,
      "loss": 0.0023,
      "step": 32620
    },
    {
      "epoch": 2.784367266831641,
      "grad_norm": 0.36427590250968933,
      "learning_rate": 2.215632733168359e-05,
      "loss": 0.002,
      "step": 32630
    },
    {
      "epoch": 2.7852205819609184,
      "grad_norm": 0.18704596161842346,
      "learning_rate": 2.214779418039082e-05,
      "loss": 0.0021,
      "step": 32640
    },
    {
      "epoch": 2.7860738970901955,
      "grad_norm": 0.2656824588775635,
      "learning_rate": 2.2139261029098045e-05,
      "loss": 0.002,
      "step": 32650
    },
    {
      "epoch": 2.7869272122194726,
      "grad_norm": 0.21348923444747925,
      "learning_rate": 2.2130727877805273e-05,
      "loss": 0.0017,
      "step": 32660
    },
    {
      "epoch": 2.78778052734875,
      "grad_norm": 0.24696286022663116,
      "learning_rate": 2.2122194726512502e-05,
      "loss": 0.0021,
      "step": 32670
    },
    {
      "epoch": 2.7886338424780273,
      "grad_norm": 0.25374552607536316,
      "learning_rate": 2.211366157521973e-05,
      "loss": 0.0022,
      "step": 32680
    },
    {
      "epoch": 2.7894871576073044,
      "grad_norm": 0.2154296189546585,
      "learning_rate": 2.210512842392696e-05,
      "loss": 0.0017,
      "step": 32690
    },
    {
      "epoch": 2.7903404727365815,
      "grad_norm": 0.18618200719356537,
      "learning_rate": 2.2096595272634184e-05,
      "loss": 0.0019,
      "step": 32700
    },
    {
      "epoch": 2.7911937878658586,
      "grad_norm": 0.3316202163696289,
      "learning_rate": 2.2088062121341412e-05,
      "loss": 0.0024,
      "step": 32710
    },
    {
      "epoch": 2.792047102995136,
      "grad_norm": 0.12219303101301193,
      "learning_rate": 2.207952897004864e-05,
      "loss": 0.0021,
      "step": 32720
    },
    {
      "epoch": 2.7929004181244133,
      "grad_norm": 0.1379278004169464,
      "learning_rate": 2.207099581875587e-05,
      "loss": 0.0017,
      "step": 32730
    },
    {
      "epoch": 2.7937537332536904,
      "grad_norm": 0.15925978124141693,
      "learning_rate": 2.2062462667463098e-05,
      "loss": 0.0017,
      "step": 32740
    },
    {
      "epoch": 2.794607048382968,
      "grad_norm": 0.462446004152298,
      "learning_rate": 2.2053929516170323e-05,
      "loss": 0.002,
      "step": 32750
    },
    {
      "epoch": 2.795460363512245,
      "grad_norm": 0.29237544536590576,
      "learning_rate": 2.2045396364877548e-05,
      "loss": 0.0021,
      "step": 32760
    },
    {
      "epoch": 2.796313678641522,
      "grad_norm": 0.20970529317855835,
      "learning_rate": 2.2036863213584776e-05,
      "loss": 0.0018,
      "step": 32770
    },
    {
      "epoch": 2.7971669937707997,
      "grad_norm": 0.0741487443447113,
      "learning_rate": 2.2028330062292005e-05,
      "loss": 0.002,
      "step": 32780
    },
    {
      "epoch": 2.798020308900077,
      "grad_norm": 0.1118086501955986,
      "learning_rate": 2.2019796910999233e-05,
      "loss": 0.0023,
      "step": 32790
    },
    {
      "epoch": 2.798873624029354,
      "grad_norm": 0.16671685874462128,
      "learning_rate": 2.2011263759706462e-05,
      "loss": 0.0019,
      "step": 32800
    },
    {
      "epoch": 2.7997269391586315,
      "grad_norm": 0.2693365514278412,
      "learning_rate": 2.2002730608413687e-05,
      "loss": 0.0026,
      "step": 32810
    },
    {
      "epoch": 2.8005802542879086,
      "grad_norm": 0.10109621286392212,
      "learning_rate": 2.1994197457120915e-05,
      "loss": 0.0025,
      "step": 32820
    },
    {
      "epoch": 2.8014335694171857,
      "grad_norm": 0.28628334403038025,
      "learning_rate": 2.1985664305828144e-05,
      "loss": 0.0028,
      "step": 32830
    },
    {
      "epoch": 2.8022868845464632,
      "grad_norm": 0.10343118757009506,
      "learning_rate": 2.1977131154535372e-05,
      "loss": 0.0025,
      "step": 32840
    },
    {
      "epoch": 2.8031401996757404,
      "grad_norm": 0.2974083721637726,
      "learning_rate": 2.1968598003242598e-05,
      "loss": 0.0025,
      "step": 32850
    },
    {
      "epoch": 2.8039935148050175,
      "grad_norm": 0.06892649829387665,
      "learning_rate": 2.1960064851949826e-05,
      "loss": 0.0023,
      "step": 32860
    },
    {
      "epoch": 2.8048468299342946,
      "grad_norm": 0.14132951200008392,
      "learning_rate": 2.1951531700657054e-05,
      "loss": 0.0028,
      "step": 32870
    },
    {
      "epoch": 2.805700145063572,
      "grad_norm": 0.155363991856575,
      "learning_rate": 2.1942998549364283e-05,
      "loss": 0.002,
      "step": 32880
    },
    {
      "epoch": 2.8065534601928492,
      "grad_norm": 0.1956339031457901,
      "learning_rate": 2.1934465398071508e-05,
      "loss": 0.0017,
      "step": 32890
    },
    {
      "epoch": 2.8074067753221263,
      "grad_norm": 0.3574775457382202,
      "learning_rate": 2.1925932246778737e-05,
      "loss": 0.0021,
      "step": 32900
    },
    {
      "epoch": 2.8082600904514035,
      "grad_norm": 0.22077730298042297,
      "learning_rate": 2.191739909548596e-05,
      "loss": 0.0022,
      "step": 32910
    },
    {
      "epoch": 2.809113405580681,
      "grad_norm": 0.15795116126537323,
      "learning_rate": 2.190886594419319e-05,
      "loss": 0.0019,
      "step": 32920
    },
    {
      "epoch": 2.809966720709958,
      "grad_norm": 0.22422738373279572,
      "learning_rate": 2.190033279290042e-05,
      "loss": 0.002,
      "step": 32930
    },
    {
      "epoch": 2.8108200358392352,
      "grad_norm": 0.15644706785678864,
      "learning_rate": 2.1891799641607647e-05,
      "loss": 0.002,
      "step": 32940
    },
    {
      "epoch": 2.811673350968513,
      "grad_norm": 0.047148242592811584,
      "learning_rate": 2.1883266490314876e-05,
      "loss": 0.0025,
      "step": 32950
    },
    {
      "epoch": 2.81252666609779,
      "grad_norm": 0.19415464997291565,
      "learning_rate": 2.18747333390221e-05,
      "loss": 0.0028,
      "step": 32960
    },
    {
      "epoch": 2.813379981227067,
      "grad_norm": 0.15443900227546692,
      "learning_rate": 2.186620018772933e-05,
      "loss": 0.0021,
      "step": 32970
    },
    {
      "epoch": 2.8142332963563446,
      "grad_norm": 0.1841641217470169,
      "learning_rate": 2.1857667036436558e-05,
      "loss": 0.0023,
      "step": 32980
    },
    {
      "epoch": 2.8150866114856217,
      "grad_norm": 0.12320389598608017,
      "learning_rate": 2.1849133885143786e-05,
      "loss": 0.0024,
      "step": 32990
    },
    {
      "epoch": 2.815939926614899,
      "grad_norm": 0.3048589527606964,
      "learning_rate": 2.1840600733851015e-05,
      "loss": 0.0017,
      "step": 33000
    },
    {
      "epoch": 2.8167932417441763,
      "grad_norm": 0.038828566670417786,
      "learning_rate": 2.183206758255824e-05,
      "loss": 0.0019,
      "step": 33010
    },
    {
      "epoch": 2.8176465568734534,
      "grad_norm": 0.03846202418208122,
      "learning_rate": 2.1823534431265465e-05,
      "loss": 0.0021,
      "step": 33020
    },
    {
      "epoch": 2.8184998720027306,
      "grad_norm": 0.36863312125205994,
      "learning_rate": 2.1815001279972693e-05,
      "loss": 0.0022,
      "step": 33030
    },
    {
      "epoch": 2.819353187132008,
      "grad_norm": 0.3655598759651184,
      "learning_rate": 2.1806468128679922e-05,
      "loss": 0.0018,
      "step": 33040
    },
    {
      "epoch": 2.820206502261285,
      "grad_norm": 0.15298622846603394,
      "learning_rate": 2.179793497738715e-05,
      "loss": 0.0024,
      "step": 33050
    },
    {
      "epoch": 2.8210598173905623,
      "grad_norm": 0.23529580235481262,
      "learning_rate": 2.178940182609438e-05,
      "loss": 0.0023,
      "step": 33060
    },
    {
      "epoch": 2.8219131325198394,
      "grad_norm": 0.30308592319488525,
      "learning_rate": 2.1780868674801604e-05,
      "loss": 0.0024,
      "step": 33070
    },
    {
      "epoch": 2.8227664476491166,
      "grad_norm": 0.2853851318359375,
      "learning_rate": 2.1772335523508832e-05,
      "loss": 0.0022,
      "step": 33080
    },
    {
      "epoch": 2.823619762778394,
      "grad_norm": 0.2910078465938568,
      "learning_rate": 2.176380237221606e-05,
      "loss": 0.0023,
      "step": 33090
    },
    {
      "epoch": 2.824473077907671,
      "grad_norm": 0.19191686809062958,
      "learning_rate": 2.175526922092329e-05,
      "loss": 0.0019,
      "step": 33100
    },
    {
      "epoch": 2.8253263930369483,
      "grad_norm": 0.09591107070446014,
      "learning_rate": 2.1746736069630518e-05,
      "loss": 0.0015,
      "step": 33110
    },
    {
      "epoch": 2.826179708166226,
      "grad_norm": 0.2725171744823456,
      "learning_rate": 2.1738202918337743e-05,
      "loss": 0.0024,
      "step": 33120
    },
    {
      "epoch": 2.827033023295503,
      "grad_norm": 0.29318541288375854,
      "learning_rate": 2.172966976704497e-05,
      "loss": 0.0023,
      "step": 33130
    },
    {
      "epoch": 2.82788633842478,
      "grad_norm": 0.12642571330070496,
      "learning_rate": 2.17211366157522e-05,
      "loss": 0.0017,
      "step": 33140
    },
    {
      "epoch": 2.8287396535540577,
      "grad_norm": 0.20913052558898926,
      "learning_rate": 2.1712603464459428e-05,
      "loss": 0.0018,
      "step": 33150
    },
    {
      "epoch": 2.8295929686833348,
      "grad_norm": 0.07825390249490738,
      "learning_rate": 2.1704070313166653e-05,
      "loss": 0.0016,
      "step": 33160
    },
    {
      "epoch": 2.830446283812612,
      "grad_norm": 0.14183910191059113,
      "learning_rate": 2.169553716187388e-05,
      "loss": 0.0019,
      "step": 33170
    },
    {
      "epoch": 2.8312995989418894,
      "grad_norm": 0.2244340181350708,
      "learning_rate": 2.1687004010581107e-05,
      "loss": 0.0021,
      "step": 33180
    },
    {
      "epoch": 2.8321529140711665,
      "grad_norm": 0.23498128354549408,
      "learning_rate": 2.1678470859288335e-05,
      "loss": 0.0016,
      "step": 33190
    },
    {
      "epoch": 2.8330062292004436,
      "grad_norm": 0.12786899507045746,
      "learning_rate": 2.1669937707995564e-05,
      "loss": 0.0021,
      "step": 33200
    },
    {
      "epoch": 2.833859544329721,
      "grad_norm": 0.16411066055297852,
      "learning_rate": 2.1661404556702792e-05,
      "loss": 0.0022,
      "step": 33210
    },
    {
      "epoch": 2.8347128594589983,
      "grad_norm": 0.03963487595319748,
      "learning_rate": 2.1652871405410017e-05,
      "loss": 0.0019,
      "step": 33220
    },
    {
      "epoch": 2.8355661745882754,
      "grad_norm": 0.11992470175027847,
      "learning_rate": 2.1644338254117246e-05,
      "loss": 0.0016,
      "step": 33230
    },
    {
      "epoch": 2.8364194897175525,
      "grad_norm": 0.1064707487821579,
      "learning_rate": 2.1635805102824474e-05,
      "loss": 0.0019,
      "step": 33240
    },
    {
      "epoch": 2.83727280484683,
      "grad_norm": 0.17715486884117126,
      "learning_rate": 2.1627271951531703e-05,
      "loss": 0.0023,
      "step": 33250
    },
    {
      "epoch": 2.838126119976107,
      "grad_norm": 0.08584257960319519,
      "learning_rate": 2.161873880023893e-05,
      "loss": 0.0017,
      "step": 33260
    },
    {
      "epoch": 2.8389794351053843,
      "grad_norm": 0.2726283371448517,
      "learning_rate": 2.1610205648946157e-05,
      "loss": 0.002,
      "step": 33270
    },
    {
      "epoch": 2.8398327502346614,
      "grad_norm": 0.16172116994857788,
      "learning_rate": 2.1601672497653385e-05,
      "loss": 0.0017,
      "step": 33280
    },
    {
      "epoch": 2.840686065363939,
      "grad_norm": 0.25169140100479126,
      "learning_rate": 2.159313934636061e-05,
      "loss": 0.0017,
      "step": 33290
    },
    {
      "epoch": 2.841539380493216,
      "grad_norm": 0.02935345657169819,
      "learning_rate": 2.158460619506784e-05,
      "loss": 0.0024,
      "step": 33300
    },
    {
      "epoch": 2.842392695622493,
      "grad_norm": 0.17708058655261993,
      "learning_rate": 2.1576073043775067e-05,
      "loss": 0.0024,
      "step": 33310
    },
    {
      "epoch": 2.8432460107517707,
      "grad_norm": 0.4451676607131958,
      "learning_rate": 2.1567539892482296e-05,
      "loss": 0.002,
      "step": 33320
    },
    {
      "epoch": 2.844099325881048,
      "grad_norm": 0.08940277248620987,
      "learning_rate": 2.155900674118952e-05,
      "loss": 0.002,
      "step": 33330
    },
    {
      "epoch": 2.844952641010325,
      "grad_norm": 0.15143534541130066,
      "learning_rate": 2.155047358989675e-05,
      "loss": 0.0025,
      "step": 33340
    },
    {
      "epoch": 2.8458059561396025,
      "grad_norm": 0.2360333353281021,
      "learning_rate": 2.1541940438603978e-05,
      "loss": 0.0018,
      "step": 33350
    },
    {
      "epoch": 2.8466592712688796,
      "grad_norm": 0.15407170355319977,
      "learning_rate": 2.1533407287311206e-05,
      "loss": 0.0021,
      "step": 33360
    },
    {
      "epoch": 2.8475125863981567,
      "grad_norm": 0.5538232326507568,
      "learning_rate": 2.1524874136018435e-05,
      "loss": 0.0022,
      "step": 33370
    },
    {
      "epoch": 2.8483659015274343,
      "grad_norm": 0.30482038855552673,
      "learning_rate": 2.151634098472566e-05,
      "loss": 0.0014,
      "step": 33380
    },
    {
      "epoch": 2.8492192166567114,
      "grad_norm": 0.07519636303186417,
      "learning_rate": 2.1507807833432888e-05,
      "loss": 0.0026,
      "step": 33390
    },
    {
      "epoch": 2.8500725317859885,
      "grad_norm": 0.3659084141254425,
      "learning_rate": 2.1499274682140117e-05,
      "loss": 0.0019,
      "step": 33400
    },
    {
      "epoch": 2.850925846915266,
      "grad_norm": 0.30681008100509644,
      "learning_rate": 2.1490741530847345e-05,
      "loss": 0.0017,
      "step": 33410
    },
    {
      "epoch": 2.851779162044543,
      "grad_norm": 0.3038903474807739,
      "learning_rate": 2.148220837955457e-05,
      "loss": 0.0025,
      "step": 33420
    },
    {
      "epoch": 2.8526324771738203,
      "grad_norm": 0.30988553166389465,
      "learning_rate": 2.14736752282618e-05,
      "loss": 0.0022,
      "step": 33430
    },
    {
      "epoch": 2.8534857923030974,
      "grad_norm": 0.11612774431705475,
      "learning_rate": 2.1465142076969024e-05,
      "loss": 0.0015,
      "step": 33440
    },
    {
      "epoch": 2.8543391074323745,
      "grad_norm": 0.4904920756816864,
      "learning_rate": 2.1456608925676252e-05,
      "loss": 0.0024,
      "step": 33450
    },
    {
      "epoch": 2.855192422561652,
      "grad_norm": 0.25694870948791504,
      "learning_rate": 2.144807577438348e-05,
      "loss": 0.0022,
      "step": 33460
    },
    {
      "epoch": 2.856045737690929,
      "grad_norm": 0.04905625060200691,
      "learning_rate": 2.143954262309071e-05,
      "loss": 0.0022,
      "step": 33470
    },
    {
      "epoch": 2.8568990528202063,
      "grad_norm": 0.1143093928694725,
      "learning_rate": 2.1431009471797934e-05,
      "loss": 0.0021,
      "step": 33480
    },
    {
      "epoch": 2.857752367949484,
      "grad_norm": 0.04617385193705559,
      "learning_rate": 2.1422476320505163e-05,
      "loss": 0.0024,
      "step": 33490
    },
    {
      "epoch": 2.858605683078761,
      "grad_norm": 0.1959436684846878,
      "learning_rate": 2.141394316921239e-05,
      "loss": 0.0019,
      "step": 33500
    },
    {
      "epoch": 2.859458998208038,
      "grad_norm": 0.3463095426559448,
      "learning_rate": 2.140541001791962e-05,
      "loss": 0.0025,
      "step": 33510
    },
    {
      "epoch": 2.8603123133373156,
      "grad_norm": 0.21603529155254364,
      "learning_rate": 2.1396876866626848e-05,
      "loss": 0.0025,
      "step": 33520
    },
    {
      "epoch": 2.8611656284665927,
      "grad_norm": 0.183467835187912,
      "learning_rate": 2.1388343715334073e-05,
      "loss": 0.0016,
      "step": 33530
    },
    {
      "epoch": 2.86201894359587,
      "grad_norm": 0.29469555616378784,
      "learning_rate": 2.1379810564041302e-05,
      "loss": 0.0026,
      "step": 33540
    },
    {
      "epoch": 2.8628722587251474,
      "grad_norm": 0.16859562695026398,
      "learning_rate": 2.1371277412748527e-05,
      "loss": 0.0019,
      "step": 33550
    },
    {
      "epoch": 2.8637255738544245,
      "grad_norm": 0.024679552763700485,
      "learning_rate": 2.1362744261455755e-05,
      "loss": 0.0027,
      "step": 33560
    },
    {
      "epoch": 2.8645788889837016,
      "grad_norm": 0.17616909742355347,
      "learning_rate": 2.1354211110162984e-05,
      "loss": 0.0019,
      "step": 33570
    },
    {
      "epoch": 2.865432204112979,
      "grad_norm": 0.16086167097091675,
      "learning_rate": 2.1345677958870212e-05,
      "loss": 0.0019,
      "step": 33580
    },
    {
      "epoch": 2.8662855192422563,
      "grad_norm": 0.040593940764665604,
      "learning_rate": 2.1337144807577437e-05,
      "loss": 0.0018,
      "step": 33590
    },
    {
      "epoch": 2.8671388343715334,
      "grad_norm": 0.21288815140724182,
      "learning_rate": 2.1328611656284666e-05,
      "loss": 0.0023,
      "step": 33600
    },
    {
      "epoch": 2.8679921495008105,
      "grad_norm": 0.30699422955513,
      "learning_rate": 2.1320078504991894e-05,
      "loss": 0.0023,
      "step": 33610
    },
    {
      "epoch": 2.868845464630088,
      "grad_norm": 0.07924985140562057,
      "learning_rate": 2.1311545353699123e-05,
      "loss": 0.0022,
      "step": 33620
    },
    {
      "epoch": 2.869698779759365,
      "grad_norm": 0.09333507716655731,
      "learning_rate": 2.130301220240635e-05,
      "loss": 0.0023,
      "step": 33630
    },
    {
      "epoch": 2.8705520948886423,
      "grad_norm": 0.1807953417301178,
      "learning_rate": 2.1294479051113576e-05,
      "loss": 0.002,
      "step": 33640
    },
    {
      "epoch": 2.8714054100179194,
      "grad_norm": 0.09059763699769974,
      "learning_rate": 2.1285945899820805e-05,
      "loss": 0.002,
      "step": 33650
    },
    {
      "epoch": 2.872258725147197,
      "grad_norm": 0.05149611830711365,
      "learning_rate": 2.1277412748528033e-05,
      "loss": 0.0018,
      "step": 33660
    },
    {
      "epoch": 2.873112040276474,
      "grad_norm": 0.1060531884431839,
      "learning_rate": 2.1268879597235262e-05,
      "loss": 0.0032,
      "step": 33670
    },
    {
      "epoch": 2.873965355405751,
      "grad_norm": 0.24517709016799927,
      "learning_rate": 2.126034644594249e-05,
      "loss": 0.0019,
      "step": 33680
    },
    {
      "epoch": 2.8748186705350287,
      "grad_norm": 0.040912725031375885,
      "learning_rate": 2.1251813294649715e-05,
      "loss": 0.0017,
      "step": 33690
    },
    {
      "epoch": 2.875671985664306,
      "grad_norm": 0.10778568685054779,
      "learning_rate": 2.124328014335694e-05,
      "loss": 0.0017,
      "step": 33700
    },
    {
      "epoch": 2.876525300793583,
      "grad_norm": 0.08450233936309814,
      "learning_rate": 2.123474699206417e-05,
      "loss": 0.0021,
      "step": 33710
    },
    {
      "epoch": 2.8773786159228605,
      "grad_norm": 0.17090976238250732,
      "learning_rate": 2.1226213840771398e-05,
      "loss": 0.0021,
      "step": 33720
    },
    {
      "epoch": 2.8782319310521376,
      "grad_norm": 0.3419216573238373,
      "learning_rate": 2.1217680689478626e-05,
      "loss": 0.0028,
      "step": 33730
    },
    {
      "epoch": 2.8790852461814147,
      "grad_norm": 0.37089526653289795,
      "learning_rate": 2.1209147538185854e-05,
      "loss": 0.0018,
      "step": 33740
    },
    {
      "epoch": 2.8799385613106923,
      "grad_norm": 0.11142788827419281,
      "learning_rate": 2.120061438689308e-05,
      "loss": 0.0024,
      "step": 33750
    },
    {
      "epoch": 2.8807918764399694,
      "grad_norm": 0.3036842346191406,
      "learning_rate": 2.1192081235600308e-05,
      "loss": 0.0019,
      "step": 33760
    },
    {
      "epoch": 2.8816451915692465,
      "grad_norm": 0.0459665022790432,
      "learning_rate": 2.1183548084307537e-05,
      "loss": 0.0019,
      "step": 33770
    },
    {
      "epoch": 2.882498506698524,
      "grad_norm": 0.2889023721218109,
      "learning_rate": 2.1175014933014765e-05,
      "loss": 0.0022,
      "step": 33780
    },
    {
      "epoch": 2.883351821827801,
      "grad_norm": 0.19378355145454407,
      "learning_rate": 2.116648178172199e-05,
      "loss": 0.0018,
      "step": 33790
    },
    {
      "epoch": 2.8842051369570783,
      "grad_norm": 0.1461196094751358,
      "learning_rate": 2.115794863042922e-05,
      "loss": 0.002,
      "step": 33800
    },
    {
      "epoch": 2.8850584520863554,
      "grad_norm": 0.2236003875732422,
      "learning_rate": 2.1149415479136447e-05,
      "loss": 0.0024,
      "step": 33810
    },
    {
      "epoch": 2.8859117672156325,
      "grad_norm": 0.16990946233272552,
      "learning_rate": 2.1140882327843672e-05,
      "loss": 0.002,
      "step": 33820
    },
    {
      "epoch": 2.88676508234491,
      "grad_norm": 0.03851314261555672,
      "learning_rate": 2.11323491765509e-05,
      "loss": 0.0019,
      "step": 33830
    },
    {
      "epoch": 2.887618397474187,
      "grad_norm": 0.28364336490631104,
      "learning_rate": 2.112381602525813e-05,
      "loss": 0.0026,
      "step": 33840
    },
    {
      "epoch": 2.8884717126034642,
      "grad_norm": 0.17544826865196228,
      "learning_rate": 2.1115282873965354e-05,
      "loss": 0.0017,
      "step": 33850
    },
    {
      "epoch": 2.889325027732742,
      "grad_norm": 0.3946843147277832,
      "learning_rate": 2.1106749722672583e-05,
      "loss": 0.0018,
      "step": 33860
    },
    {
      "epoch": 2.890178342862019,
      "grad_norm": 0.4618128836154938,
      "learning_rate": 2.109821657137981e-05,
      "loss": 0.0023,
      "step": 33870
    },
    {
      "epoch": 2.891031657991296,
      "grad_norm": 0.3091152012348175,
      "learning_rate": 2.108968342008704e-05,
      "loss": 0.0024,
      "step": 33880
    },
    {
      "epoch": 2.8918849731205736,
      "grad_norm": 0.44140639901161194,
      "learning_rate": 2.1081150268794268e-05,
      "loss": 0.002,
      "step": 33890
    },
    {
      "epoch": 2.8927382882498507,
      "grad_norm": 0.20162682235240936,
      "learning_rate": 2.1072617117501493e-05,
      "loss": 0.0022,
      "step": 33900
    },
    {
      "epoch": 2.893591603379128,
      "grad_norm": 0.06807689368724823,
      "learning_rate": 2.1064083966208722e-05,
      "loss": 0.0019,
      "step": 33910
    },
    {
      "epoch": 2.8944449185084054,
      "grad_norm": 0.09870199859142303,
      "learning_rate": 2.105555081491595e-05,
      "loss": 0.002,
      "step": 33920
    },
    {
      "epoch": 2.8952982336376825,
      "grad_norm": 0.3812987506389618,
      "learning_rate": 2.104701766362318e-05,
      "loss": 0.0019,
      "step": 33930
    },
    {
      "epoch": 2.8961515487669596,
      "grad_norm": 0.24894151091575623,
      "learning_rate": 2.1038484512330407e-05,
      "loss": 0.0018,
      "step": 33940
    },
    {
      "epoch": 2.897004863896237,
      "grad_norm": 0.17120608687400818,
      "learning_rate": 2.1029951361037632e-05,
      "loss": 0.0015,
      "step": 33950
    },
    {
      "epoch": 2.8978581790255142,
      "grad_norm": 0.21048206090927124,
      "learning_rate": 2.1021418209744857e-05,
      "loss": 0.002,
      "step": 33960
    },
    {
      "epoch": 2.8987114941547913,
      "grad_norm": 0.34960559010505676,
      "learning_rate": 2.1012885058452086e-05,
      "loss": 0.0025,
      "step": 33970
    },
    {
      "epoch": 2.8995648092840685,
      "grad_norm": 0.30450305342674255,
      "learning_rate": 2.1004351907159314e-05,
      "loss": 0.0018,
      "step": 33980
    },
    {
      "epoch": 2.900418124413346,
      "grad_norm": 0.1746176779270172,
      "learning_rate": 2.0995818755866543e-05,
      "loss": 0.0023,
      "step": 33990
    },
    {
      "epoch": 2.901271439542623,
      "grad_norm": 0.272977739572525,
      "learning_rate": 2.098728560457377e-05,
      "loss": 0.0025,
      "step": 34000
    },
    {
      "epoch": 2.9021247546719002,
      "grad_norm": 0.42160677909851074,
      "learning_rate": 2.0978752453280996e-05,
      "loss": 0.0024,
      "step": 34010
    },
    {
      "epoch": 2.9029780698011773,
      "grad_norm": 0.31091809272766113,
      "learning_rate": 2.0970219301988225e-05,
      "loss": 0.0019,
      "step": 34020
    },
    {
      "epoch": 2.903831384930455,
      "grad_norm": 0.12917974591255188,
      "learning_rate": 2.0961686150695453e-05,
      "loss": 0.0023,
      "step": 34030
    },
    {
      "epoch": 2.904684700059732,
      "grad_norm": 0.07475966215133667,
      "learning_rate": 2.0953152999402682e-05,
      "loss": 0.0017,
      "step": 34040
    },
    {
      "epoch": 2.905538015189009,
      "grad_norm": 0.21135137975215912,
      "learning_rate": 2.094461984810991e-05,
      "loss": 0.0019,
      "step": 34050
    },
    {
      "epoch": 2.9063913303182867,
      "grad_norm": 0.32288190722465515,
      "learning_rate": 2.0936086696817135e-05,
      "loss": 0.0018,
      "step": 34060
    },
    {
      "epoch": 2.907244645447564,
      "grad_norm": 0.2529461681842804,
      "learning_rate": 2.0927553545524364e-05,
      "loss": 0.0024,
      "step": 34070
    },
    {
      "epoch": 2.908097960576841,
      "grad_norm": 0.19413697719573975,
      "learning_rate": 2.0919020394231592e-05,
      "loss": 0.0023,
      "step": 34080
    },
    {
      "epoch": 2.9089512757061184,
      "grad_norm": 0.31659525632858276,
      "learning_rate": 2.0910487242938817e-05,
      "loss": 0.0022,
      "step": 34090
    },
    {
      "epoch": 2.9098045908353956,
      "grad_norm": 0.2008669376373291,
      "learning_rate": 2.0901954091646046e-05,
      "loss": 0.002,
      "step": 34100
    },
    {
      "epoch": 2.9106579059646727,
      "grad_norm": 0.15847691893577576,
      "learning_rate": 2.089342094035327e-05,
      "loss": 0.0019,
      "step": 34110
    },
    {
      "epoch": 2.91151122109395,
      "grad_norm": 0.12157784402370453,
      "learning_rate": 2.08848877890605e-05,
      "loss": 0.0021,
      "step": 34120
    },
    {
      "epoch": 2.9123645362232273,
      "grad_norm": 0.48090919852256775,
      "learning_rate": 2.0876354637767728e-05,
      "loss": 0.0022,
      "step": 34130
    },
    {
      "epoch": 2.9132178513525044,
      "grad_norm": 0.045212551951408386,
      "learning_rate": 2.0867821486474957e-05,
      "loss": 0.0023,
      "step": 34140
    },
    {
      "epoch": 2.914071166481782,
      "grad_norm": 0.3094727396965027,
      "learning_rate": 2.0859288335182185e-05,
      "loss": 0.0026,
      "step": 34150
    },
    {
      "epoch": 2.914924481611059,
      "grad_norm": 0.25207585096359253,
      "learning_rate": 2.085075518388941e-05,
      "loss": 0.0018,
      "step": 34160
    },
    {
      "epoch": 2.915777796740336,
      "grad_norm": 0.04528305307030678,
      "learning_rate": 2.084222203259664e-05,
      "loss": 0.0016,
      "step": 34170
    },
    {
      "epoch": 2.9166311118696133,
      "grad_norm": 0.527166485786438,
      "learning_rate": 2.0833688881303867e-05,
      "loss": 0.0017,
      "step": 34180
    },
    {
      "epoch": 2.9174844269988904,
      "grad_norm": 0.329282283782959,
      "learning_rate": 2.0825155730011096e-05,
      "loss": 0.002,
      "step": 34190
    },
    {
      "epoch": 2.918337742128168,
      "grad_norm": 0.04680579528212547,
      "learning_rate": 2.0816622578718324e-05,
      "loss": 0.0022,
      "step": 34200
    },
    {
      "epoch": 2.919191057257445,
      "grad_norm": 0.10056398063898087,
      "learning_rate": 2.080808942742555e-05,
      "loss": 0.0024,
      "step": 34210
    },
    {
      "epoch": 2.920044372386722,
      "grad_norm": 0.24713687598705292,
      "learning_rate": 2.0799556276132774e-05,
      "loss": 0.0024,
      "step": 34220
    },
    {
      "epoch": 2.9208976875159998,
      "grad_norm": 0.30920180678367615,
      "learning_rate": 2.0791023124840003e-05,
      "loss": 0.0025,
      "step": 34230
    },
    {
      "epoch": 2.921751002645277,
      "grad_norm": 0.5205692648887634,
      "learning_rate": 2.078248997354723e-05,
      "loss": 0.0024,
      "step": 34240
    },
    {
      "epoch": 2.922604317774554,
      "grad_norm": 0.026809465140104294,
      "learning_rate": 2.077395682225446e-05,
      "loss": 0.0017,
      "step": 34250
    },
    {
      "epoch": 2.9234576329038315,
      "grad_norm": 0.15840448439121246,
      "learning_rate": 2.0765423670961688e-05,
      "loss": 0.0021,
      "step": 34260
    },
    {
      "epoch": 2.9243109480331086,
      "grad_norm": 0.19482749700546265,
      "learning_rate": 2.0756890519668913e-05,
      "loss": 0.0024,
      "step": 34270
    },
    {
      "epoch": 2.9251642631623858,
      "grad_norm": 0.3043246865272522,
      "learning_rate": 2.0748357368376142e-05,
      "loss": 0.0021,
      "step": 34280
    },
    {
      "epoch": 2.9260175782916633,
      "grad_norm": 0.28372183442115784,
      "learning_rate": 2.073982421708337e-05,
      "loss": 0.002,
      "step": 34290
    },
    {
      "epoch": 2.9268708934209404,
      "grad_norm": 0.11524131894111633,
      "learning_rate": 2.07312910657906e-05,
      "loss": 0.0022,
      "step": 34300
    },
    {
      "epoch": 2.9277242085502175,
      "grad_norm": 0.07491636276245117,
      "learning_rate": 2.0722757914497827e-05,
      "loss": 0.002,
      "step": 34310
    },
    {
      "epoch": 2.928577523679495,
      "grad_norm": 0.11113748699426651,
      "learning_rate": 2.0714224763205052e-05,
      "loss": 0.0017,
      "step": 34320
    },
    {
      "epoch": 2.929430838808772,
      "grad_norm": 0.07910461723804474,
      "learning_rate": 2.070569161191228e-05,
      "loss": 0.0028,
      "step": 34330
    },
    {
      "epoch": 2.9302841539380493,
      "grad_norm": 0.36742091178894043,
      "learning_rate": 2.069715846061951e-05,
      "loss": 0.0016,
      "step": 34340
    },
    {
      "epoch": 2.9311374690673264,
      "grad_norm": 0.27041399478912354,
      "learning_rate": 2.0688625309326734e-05,
      "loss": 0.0017,
      "step": 34350
    },
    {
      "epoch": 2.931990784196604,
      "grad_norm": 0.2866652011871338,
      "learning_rate": 2.0680092158033963e-05,
      "loss": 0.0023,
      "step": 34360
    },
    {
      "epoch": 2.932844099325881,
      "grad_norm": 0.16704493761062622,
      "learning_rate": 2.067155900674119e-05,
      "loss": 0.0017,
      "step": 34370
    },
    {
      "epoch": 2.933697414455158,
      "grad_norm": 0.3792482614517212,
      "learning_rate": 2.0663025855448416e-05,
      "loss": 0.0024,
      "step": 34380
    },
    {
      "epoch": 2.9345507295844353,
      "grad_norm": 0.11486147344112396,
      "learning_rate": 2.0654492704155645e-05,
      "loss": 0.0016,
      "step": 34390
    },
    {
      "epoch": 2.935404044713713,
      "grad_norm": 0.051257144659757614,
      "learning_rate": 2.0645959552862873e-05,
      "loss": 0.0019,
      "step": 34400
    },
    {
      "epoch": 2.93625735984299,
      "grad_norm": 0.4819623827934265,
      "learning_rate": 2.0637426401570102e-05,
      "loss": 0.002,
      "step": 34410
    },
    {
      "epoch": 2.937110674972267,
      "grad_norm": 0.19549961388111115,
      "learning_rate": 2.0628893250277327e-05,
      "loss": 0.002,
      "step": 34420
    },
    {
      "epoch": 2.9379639901015446,
      "grad_norm": 0.13091689348220825,
      "learning_rate": 2.0620360098984555e-05,
      "loss": 0.0015,
      "step": 34430
    },
    {
      "epoch": 2.9388173052308217,
      "grad_norm": 0.13826416432857513,
      "learning_rate": 2.0611826947691784e-05,
      "loss": 0.0019,
      "step": 34440
    },
    {
      "epoch": 2.939670620360099,
      "grad_norm": 0.06552913039922714,
      "learning_rate": 2.0603293796399012e-05,
      "loss": 0.0019,
      "step": 34450
    },
    {
      "epoch": 2.9405239354893764,
      "grad_norm": 0.05840130150318146,
      "learning_rate": 2.059476064510624e-05,
      "loss": 0.002,
      "step": 34460
    },
    {
      "epoch": 2.9413772506186535,
      "grad_norm": 0.2197340428829193,
      "learning_rate": 2.0586227493813466e-05,
      "loss": 0.0018,
      "step": 34470
    },
    {
      "epoch": 2.9422305657479306,
      "grad_norm": 0.21087177097797394,
      "learning_rate": 2.057769434252069e-05,
      "loss": 0.0023,
      "step": 34480
    },
    {
      "epoch": 2.943083880877208,
      "grad_norm": 0.05829664692282677,
      "learning_rate": 2.056916119122792e-05,
      "loss": 0.002,
      "step": 34490
    },
    {
      "epoch": 2.9439371960064853,
      "grad_norm": 0.28940707445144653,
      "learning_rate": 2.0560628039935148e-05,
      "loss": 0.0022,
      "step": 34500
    },
    {
      "epoch": 2.9447905111357624,
      "grad_norm": 0.06924954801797867,
      "learning_rate": 2.0552094888642376e-05,
      "loss": 0.0021,
      "step": 34510
    },
    {
      "epoch": 2.94564382626504,
      "grad_norm": 0.0840664803981781,
      "learning_rate": 2.0543561737349605e-05,
      "loss": 0.0019,
      "step": 34520
    },
    {
      "epoch": 2.946497141394317,
      "grad_norm": 0.1438048928976059,
      "learning_rate": 2.053502858605683e-05,
      "loss": 0.0019,
      "step": 34530
    },
    {
      "epoch": 2.947350456523594,
      "grad_norm": 0.2124437540769577,
      "learning_rate": 2.052649543476406e-05,
      "loss": 0.0026,
      "step": 34540
    },
    {
      "epoch": 2.9482037716528713,
      "grad_norm": 0.19478170573711395,
      "learning_rate": 2.0517962283471287e-05,
      "loss": 0.0016,
      "step": 34550
    },
    {
      "epoch": 2.9490570867821484,
      "grad_norm": 0.23873929679393768,
      "learning_rate": 2.0509429132178515e-05,
      "loss": 0.002,
      "step": 34560
    },
    {
      "epoch": 2.949910401911426,
      "grad_norm": 0.061147913336753845,
      "learning_rate": 2.0500895980885744e-05,
      "loss": 0.0021,
      "step": 34570
    },
    {
      "epoch": 2.950763717040703,
      "grad_norm": 0.034965239465236664,
      "learning_rate": 2.049236282959297e-05,
      "loss": 0.0017,
      "step": 34580
    },
    {
      "epoch": 2.95161703216998,
      "grad_norm": 0.12485400587320328,
      "learning_rate": 2.0483829678300198e-05,
      "loss": 0.0014,
      "step": 34590
    },
    {
      "epoch": 2.9524703472992577,
      "grad_norm": 0.2648462951183319,
      "learning_rate": 2.0475296527007426e-05,
      "loss": 0.002,
      "step": 34600
    },
    {
      "epoch": 2.953323662428535,
      "grad_norm": 0.23266834020614624,
      "learning_rate": 2.0466763375714654e-05,
      "loss": 0.0022,
      "step": 34610
    },
    {
      "epoch": 2.954176977557812,
      "grad_norm": 0.13706660270690918,
      "learning_rate": 2.045823022442188e-05,
      "loss": 0.002,
      "step": 34620
    },
    {
      "epoch": 2.9550302926870895,
      "grad_norm": 0.033787406980991364,
      "learning_rate": 2.0449697073129108e-05,
      "loss": 0.0019,
      "step": 34630
    },
    {
      "epoch": 2.9558836078163666,
      "grad_norm": 0.09839162975549698,
      "learning_rate": 2.0441163921836333e-05,
      "loss": 0.002,
      "step": 34640
    },
    {
      "epoch": 2.9567369229456437,
      "grad_norm": 0.18921451270580292,
      "learning_rate": 2.043263077054356e-05,
      "loss": 0.0021,
      "step": 34650
    },
    {
      "epoch": 2.9575902380749213,
      "grad_norm": 0.19415347278118134,
      "learning_rate": 2.042409761925079e-05,
      "loss": 0.002,
      "step": 34660
    },
    {
      "epoch": 2.9584435532041984,
      "grad_norm": 0.1169237270951271,
      "learning_rate": 2.041556446795802e-05,
      "loss": 0.0016,
      "step": 34670
    },
    {
      "epoch": 2.9592968683334755,
      "grad_norm": 0.18006616830825806,
      "learning_rate": 2.0407031316665247e-05,
      "loss": 0.0021,
      "step": 34680
    },
    {
      "epoch": 2.960150183462753,
      "grad_norm": 0.2131209671497345,
      "learning_rate": 2.0398498165372472e-05,
      "loss": 0.0023,
      "step": 34690
    },
    {
      "epoch": 2.96100349859203,
      "grad_norm": 0.18449640274047852,
      "learning_rate": 2.03899650140797e-05,
      "loss": 0.0025,
      "step": 34700
    },
    {
      "epoch": 2.9618568137213073,
      "grad_norm": 0.06848899275064468,
      "learning_rate": 2.038143186278693e-05,
      "loss": 0.002,
      "step": 34710
    },
    {
      "epoch": 2.9627101288505844,
      "grad_norm": 0.20758356153964996,
      "learning_rate": 2.0372898711494158e-05,
      "loss": 0.0016,
      "step": 34720
    },
    {
      "epoch": 2.9635634439798615,
      "grad_norm": 0.3336525857448578,
      "learning_rate": 2.0364365560201383e-05,
      "loss": 0.0018,
      "step": 34730
    },
    {
      "epoch": 2.964416759109139,
      "grad_norm": 0.12004981189966202,
      "learning_rate": 2.035583240890861e-05,
      "loss": 0.0017,
      "step": 34740
    },
    {
      "epoch": 2.965270074238416,
      "grad_norm": 0.17463691532611847,
      "learning_rate": 2.0347299257615836e-05,
      "loss": 0.0018,
      "step": 34750
    },
    {
      "epoch": 2.9661233893676933,
      "grad_norm": 0.46464645862579346,
      "learning_rate": 2.0338766106323065e-05,
      "loss": 0.0025,
      "step": 34760
    },
    {
      "epoch": 2.966976704496971,
      "grad_norm": 0.21583029627799988,
      "learning_rate": 2.0330232955030293e-05,
      "loss": 0.0021,
      "step": 34770
    },
    {
      "epoch": 2.967830019626248,
      "grad_norm": 0.25407129526138306,
      "learning_rate": 2.0321699803737522e-05,
      "loss": 0.0022,
      "step": 34780
    },
    {
      "epoch": 2.968683334755525,
      "grad_norm": 0.06890737265348434,
      "learning_rate": 2.0313166652444747e-05,
      "loss": 0.0019,
      "step": 34790
    },
    {
      "epoch": 2.9695366498848026,
      "grad_norm": 0.04462534934282303,
      "learning_rate": 2.0304633501151975e-05,
      "loss": 0.0022,
      "step": 34800
    },
    {
      "epoch": 2.9703899650140797,
      "grad_norm": 0.49333786964416504,
      "learning_rate": 2.0296100349859204e-05,
      "loss": 0.0025,
      "step": 34810
    },
    {
      "epoch": 2.971243280143357,
      "grad_norm": 0.17471031844615936,
      "learning_rate": 2.0287567198566432e-05,
      "loss": 0.0019,
      "step": 34820
    },
    {
      "epoch": 2.9720965952726344,
      "grad_norm": 0.2096092849969864,
      "learning_rate": 2.027903404727366e-05,
      "loss": 0.0018,
      "step": 34830
    },
    {
      "epoch": 2.9729499104019115,
      "grad_norm": 0.08339594304561615,
      "learning_rate": 2.0270500895980886e-05,
      "loss": 0.0021,
      "step": 34840
    },
    {
      "epoch": 2.9738032255311886,
      "grad_norm": 0.060552261769771576,
      "learning_rate": 2.0261967744688114e-05,
      "loss": 0.0015,
      "step": 34850
    },
    {
      "epoch": 2.974656540660466,
      "grad_norm": 0.26268696784973145,
      "learning_rate": 2.0253434593395343e-05,
      "loss": 0.0021,
      "step": 34860
    },
    {
      "epoch": 2.9755098557897433,
      "grad_norm": 0.5373743772506714,
      "learning_rate": 2.024490144210257e-05,
      "loss": 0.0017,
      "step": 34870
    },
    {
      "epoch": 2.9763631709190204,
      "grad_norm": 0.06263068318367004,
      "learning_rate": 2.0236368290809796e-05,
      "loss": 0.002,
      "step": 34880
    },
    {
      "epoch": 2.9772164860482975,
      "grad_norm": 0.06265532970428467,
      "learning_rate": 2.0227835139517025e-05,
      "loss": 0.0017,
      "step": 34890
    },
    {
      "epoch": 2.978069801177575,
      "grad_norm": 0.28700390458106995,
      "learning_rate": 2.021930198822425e-05,
      "loss": 0.0015,
      "step": 34900
    },
    {
      "epoch": 2.978923116306852,
      "grad_norm": 0.21008096635341644,
      "learning_rate": 2.021076883693148e-05,
      "loss": 0.0021,
      "step": 34910
    },
    {
      "epoch": 2.9797764314361292,
      "grad_norm": 0.3271506726741791,
      "learning_rate": 2.0202235685638707e-05,
      "loss": 0.003,
      "step": 34920
    },
    {
      "epoch": 2.9806297465654064,
      "grad_norm": 0.18830318748950958,
      "learning_rate": 2.0193702534345935e-05,
      "loss": 0.002,
      "step": 34930
    },
    {
      "epoch": 2.981483061694684,
      "grad_norm": 0.044564466923475266,
      "learning_rate": 2.0185169383053164e-05,
      "loss": 0.0017,
      "step": 34940
    },
    {
      "epoch": 2.982336376823961,
      "grad_norm": 0.3372677266597748,
      "learning_rate": 2.017663623176039e-05,
      "loss": 0.0021,
      "step": 34950
    },
    {
      "epoch": 2.983189691953238,
      "grad_norm": 0.3148208558559418,
      "learning_rate": 2.0168103080467617e-05,
      "loss": 0.0025,
      "step": 34960
    },
    {
      "epoch": 2.9840430070825157,
      "grad_norm": 0.4272496700286865,
      "learning_rate": 2.0159569929174846e-05,
      "loss": 0.0025,
      "step": 34970
    },
    {
      "epoch": 2.984896322211793,
      "grad_norm": 0.0804569199681282,
      "learning_rate": 2.0151036777882074e-05,
      "loss": 0.0028,
      "step": 34980
    },
    {
      "epoch": 2.98574963734107,
      "grad_norm": 0.1906091421842575,
      "learning_rate": 2.0142503626589303e-05,
      "loss": 0.0026,
      "step": 34990
    },
    {
      "epoch": 2.9866029524703475,
      "grad_norm": 0.13362076878547668,
      "learning_rate": 2.0133970475296528e-05,
      "loss": 0.0023,
      "step": 35000
    },
    {
      "epoch": 2.9874562675996246,
      "grad_norm": 0.03291714936494827,
      "learning_rate": 2.0125437324003757e-05,
      "loss": 0.0021,
      "step": 35010
    },
    {
      "epoch": 2.9883095827289017,
      "grad_norm": 0.10250303149223328,
      "learning_rate": 2.011690417271098e-05,
      "loss": 0.0019,
      "step": 35020
    },
    {
      "epoch": 2.9891628978581792,
      "grad_norm": 0.05283571034669876,
      "learning_rate": 2.010837102141821e-05,
      "loss": 0.0016,
      "step": 35030
    },
    {
      "epoch": 2.9900162129874563,
      "grad_norm": 0.23023512959480286,
      "learning_rate": 2.009983787012544e-05,
      "loss": 0.0023,
      "step": 35040
    },
    {
      "epoch": 2.9908695281167335,
      "grad_norm": 0.3417961001396179,
      "learning_rate": 2.0091304718832664e-05,
      "loss": 0.0016,
      "step": 35050
    },
    {
      "epoch": 2.991722843246011,
      "grad_norm": 0.128659188747406,
      "learning_rate": 2.0082771567539892e-05,
      "loss": 0.0025,
      "step": 35060
    },
    {
      "epoch": 2.992576158375288,
      "grad_norm": 0.15003865957260132,
      "learning_rate": 2.007423841624712e-05,
      "loss": 0.0021,
      "step": 35070
    },
    {
      "epoch": 2.9934294735045652,
      "grad_norm": 0.04904894158244133,
      "learning_rate": 2.006570526495435e-05,
      "loss": 0.0016,
      "step": 35080
    },
    {
      "epoch": 2.9942827886338423,
      "grad_norm": 0.22301076352596283,
      "learning_rate": 2.0057172113661578e-05,
      "loss": 0.0022,
      "step": 35090
    },
    {
      "epoch": 2.9951361037631195,
      "grad_norm": 0.19242741167545319,
      "learning_rate": 2.0048638962368803e-05,
      "loss": 0.0017,
      "step": 35100
    },
    {
      "epoch": 2.995989418892397,
      "grad_norm": 0.15736959874629974,
      "learning_rate": 2.004010581107603e-05,
      "loss": 0.0019,
      "step": 35110
    },
    {
      "epoch": 2.996842734021674,
      "grad_norm": 0.12730054557323456,
      "learning_rate": 2.003157265978326e-05,
      "loss": 0.0021,
      "step": 35120
    },
    {
      "epoch": 2.9976960491509512,
      "grad_norm": 0.0642179325222969,
      "learning_rate": 2.0023039508490488e-05,
      "loss": 0.0025,
      "step": 35130
    },
    {
      "epoch": 2.998549364280229,
      "grad_norm": 0.2451150268316269,
      "learning_rate": 2.0014506357197717e-05,
      "loss": 0.0021,
      "step": 35140
    },
    {
      "epoch": 2.999402679409506,
      "grad_norm": 0.15716686844825745,
      "learning_rate": 2.0005973205904942e-05,
      "loss": 0.0019,
      "step": 35150
    },
    {
      "epoch": 3.0,
      "eval_loss": 0.0019645323045551777,
      "eval_runtime": 101.3628,
      "eval_samples_per_second": 1479.832,
      "eval_steps_per_second": 23.125,
      "step": 35157
    },
    {
      "epoch": 3.000255994538783,
      "grad_norm": 0.18369562923908234,
      "learning_rate": 1.9997440054612167e-05,
      "loss": 0.0023,
      "step": 35160
    },
    {
      "epoch": 3.0011093096680606,
      "grad_norm": 0.19742873311042786,
      "learning_rate": 1.9988906903319395e-05,
      "loss": 0.0016,
      "step": 35170
    },
    {
      "epoch": 3.0019626247973377,
      "grad_norm": 0.37215086817741394,
      "learning_rate": 1.9980373752026624e-05,
      "loss": 0.0016,
      "step": 35180
    },
    {
      "epoch": 3.0028159399266148,
      "grad_norm": 0.14537598192691803,
      "learning_rate": 1.9971840600733852e-05,
      "loss": 0.0019,
      "step": 35190
    },
    {
      "epoch": 3.0036692550558923,
      "grad_norm": 0.33919599652290344,
      "learning_rate": 1.996330744944108e-05,
      "loss": 0.0023,
      "step": 35200
    },
    {
      "epoch": 3.0045225701851694,
      "grad_norm": 0.44217556715011597,
      "learning_rate": 1.9954774298148306e-05,
      "loss": 0.0023,
      "step": 35210
    },
    {
      "epoch": 3.0053758853144465,
      "grad_norm": 0.3066554069519043,
      "learning_rate": 1.9946241146855534e-05,
      "loss": 0.0018,
      "step": 35220
    },
    {
      "epoch": 3.0062292004437237,
      "grad_norm": 0.5495848655700684,
      "learning_rate": 1.9937707995562763e-05,
      "loss": 0.002,
      "step": 35230
    },
    {
      "epoch": 3.007082515573001,
      "grad_norm": 0.21928490698337555,
      "learning_rate": 1.992917484426999e-05,
      "loss": 0.0024,
      "step": 35240
    },
    {
      "epoch": 3.0079358307022783,
      "grad_norm": 0.22011642158031464,
      "learning_rate": 1.992064169297722e-05,
      "loss": 0.0018,
      "step": 35250
    },
    {
      "epoch": 3.0087891458315554,
      "grad_norm": 0.19008062779903412,
      "learning_rate": 1.9912108541684445e-05,
      "loss": 0.0022,
      "step": 35260
    },
    {
      "epoch": 3.009642460960833,
      "grad_norm": 0.07772159576416016,
      "learning_rate": 1.9903575390391673e-05,
      "loss": 0.0019,
      "step": 35270
    },
    {
      "epoch": 3.01049577609011,
      "grad_norm": 0.08310511708259583,
      "learning_rate": 1.98950422390989e-05,
      "loss": 0.002,
      "step": 35280
    },
    {
      "epoch": 3.011349091219387,
      "grad_norm": 0.15761888027191162,
      "learning_rate": 1.9886509087806127e-05,
      "loss": 0.0017,
      "step": 35290
    },
    {
      "epoch": 3.0122024063486648,
      "grad_norm": 0.10285162925720215,
      "learning_rate": 1.9877975936513355e-05,
      "loss": 0.0022,
      "step": 35300
    },
    {
      "epoch": 3.013055721477942,
      "grad_norm": 0.2720462679862976,
      "learning_rate": 1.9869442785220584e-05,
      "loss": 0.0021,
      "step": 35310
    },
    {
      "epoch": 3.013909036607219,
      "grad_norm": 0.4770500063896179,
      "learning_rate": 1.986090963392781e-05,
      "loss": 0.0017,
      "step": 35320
    },
    {
      "epoch": 3.014762351736496,
      "grad_norm": 0.22950658202171326,
      "learning_rate": 1.9852376482635037e-05,
      "loss": 0.0019,
      "step": 35330
    },
    {
      "epoch": 3.0156156668657736,
      "grad_norm": 0.12651601433753967,
      "learning_rate": 1.9843843331342266e-05,
      "loss": 0.0021,
      "step": 35340
    },
    {
      "epoch": 3.0164689819950508,
      "grad_norm": 0.03824992850422859,
      "learning_rate": 1.9835310180049494e-05,
      "loss": 0.0027,
      "step": 35350
    },
    {
      "epoch": 3.017322297124328,
      "grad_norm": 0.23586691915988922,
      "learning_rate": 1.982677702875672e-05,
      "loss": 0.0022,
      "step": 35360
    },
    {
      "epoch": 3.0181756122536054,
      "grad_norm": 0.0811893567442894,
      "learning_rate": 1.9818243877463948e-05,
      "loss": 0.0021,
      "step": 35370
    },
    {
      "epoch": 3.0190289273828825,
      "grad_norm": 0.07106690853834152,
      "learning_rate": 1.9809710726171176e-05,
      "loss": 0.0017,
      "step": 35380
    },
    {
      "epoch": 3.0198822425121596,
      "grad_norm": 0.17671488225460052,
      "learning_rate": 1.9801177574878405e-05,
      "loss": 0.0022,
      "step": 35390
    },
    {
      "epoch": 3.020735557641437,
      "grad_norm": 0.06720887124538422,
      "learning_rate": 1.9792644423585633e-05,
      "loss": 0.0018,
      "step": 35400
    },
    {
      "epoch": 3.0215888727707143,
      "grad_norm": 0.13727985322475433,
      "learning_rate": 1.978411127229286e-05,
      "loss": 0.0023,
      "step": 35410
    },
    {
      "epoch": 3.0224421878999914,
      "grad_norm": 0.08419118076562881,
      "learning_rate": 1.9775578121000084e-05,
      "loss": 0.0015,
      "step": 35420
    },
    {
      "epoch": 3.0232955030292685,
      "grad_norm": 0.43364670872688293,
      "learning_rate": 1.9767044969707312e-05,
      "loss": 0.0022,
      "step": 35430
    },
    {
      "epoch": 3.024148818158546,
      "grad_norm": 0.04489656910300255,
      "learning_rate": 1.975851181841454e-05,
      "loss": 0.0024,
      "step": 35440
    },
    {
      "epoch": 3.025002133287823,
      "grad_norm": 0.2965102195739746,
      "learning_rate": 1.974997866712177e-05,
      "loss": 0.0018,
      "step": 35450
    },
    {
      "epoch": 3.0258554484171003,
      "grad_norm": 0.04021424800157547,
      "learning_rate": 1.9741445515828998e-05,
      "loss": 0.0023,
      "step": 35460
    },
    {
      "epoch": 3.026708763546378,
      "grad_norm": 0.40179550647735596,
      "learning_rate": 1.9732912364536223e-05,
      "loss": 0.0014,
      "step": 35470
    },
    {
      "epoch": 3.027562078675655,
      "grad_norm": 0.18061117827892303,
      "learning_rate": 1.972437921324345e-05,
      "loss": 0.0019,
      "step": 35480
    },
    {
      "epoch": 3.028415393804932,
      "grad_norm": 0.07005685567855835,
      "learning_rate": 1.971584606195068e-05,
      "loss": 0.0021,
      "step": 35490
    },
    {
      "epoch": 3.029268708934209,
      "grad_norm": 0.3326908051967621,
      "learning_rate": 1.9707312910657908e-05,
      "loss": 0.0021,
      "step": 35500
    },
    {
      "epoch": 3.0301220240634867,
      "grad_norm": 0.2125231921672821,
      "learning_rate": 1.9698779759365137e-05,
      "loss": 0.0016,
      "step": 35510
    },
    {
      "epoch": 3.030975339192764,
      "grad_norm": 0.2029854655265808,
      "learning_rate": 1.969024660807236e-05,
      "loss": 0.0025,
      "step": 35520
    },
    {
      "epoch": 3.031828654322041,
      "grad_norm": 0.30199629068374634,
      "learning_rate": 1.968171345677959e-05,
      "loss": 0.0016,
      "step": 35530
    },
    {
      "epoch": 3.0326819694513185,
      "grad_norm": 0.44818389415740967,
      "learning_rate": 1.967318030548682e-05,
      "loss": 0.0016,
      "step": 35540
    },
    {
      "epoch": 3.0335352845805956,
      "grad_norm": 0.10659657418727875,
      "learning_rate": 1.9664647154194044e-05,
      "loss": 0.0022,
      "step": 35550
    },
    {
      "epoch": 3.0343885997098727,
      "grad_norm": 0.06487918645143509,
      "learning_rate": 1.9656114002901272e-05,
      "loss": 0.0019,
      "step": 35560
    },
    {
      "epoch": 3.0352419148391503,
      "grad_norm": 0.1283343881368637,
      "learning_rate": 1.96475808516085e-05,
      "loss": 0.0024,
      "step": 35570
    },
    {
      "epoch": 3.0360952299684274,
      "grad_norm": 0.05849466845393181,
      "learning_rate": 1.9639047700315726e-05,
      "loss": 0.0015,
      "step": 35580
    },
    {
      "epoch": 3.0369485450977045,
      "grad_norm": 0.2520041763782501,
      "learning_rate": 1.9630514549022954e-05,
      "loss": 0.0019,
      "step": 35590
    },
    {
      "epoch": 3.0378018602269816,
      "grad_norm": 0.07519695907831192,
      "learning_rate": 1.9621981397730183e-05,
      "loss": 0.0021,
      "step": 35600
    },
    {
      "epoch": 3.038655175356259,
      "grad_norm": 0.1737801432609558,
      "learning_rate": 1.961344824643741e-05,
      "loss": 0.0019,
      "step": 35610
    },
    {
      "epoch": 3.0395084904855363,
      "grad_norm": 0.21749871969223022,
      "learning_rate": 1.960491509514464e-05,
      "loss": 0.0022,
      "step": 35620
    },
    {
      "epoch": 3.0403618056148134,
      "grad_norm": 0.09421942383050919,
      "learning_rate": 1.9596381943851865e-05,
      "loss": 0.0021,
      "step": 35630
    },
    {
      "epoch": 3.041215120744091,
      "grad_norm": 0.21047236025333405,
      "learning_rate": 1.9587848792559093e-05,
      "loss": 0.0019,
      "step": 35640
    },
    {
      "epoch": 3.042068435873368,
      "grad_norm": 0.06951284408569336,
      "learning_rate": 1.9579315641266322e-05,
      "loss": 0.0019,
      "step": 35650
    },
    {
      "epoch": 3.042921751002645,
      "grad_norm": 0.6849100589752197,
      "learning_rate": 1.957078248997355e-05,
      "loss": 0.0025,
      "step": 35660
    },
    {
      "epoch": 3.0437750661319227,
      "grad_norm": 0.12348781526088715,
      "learning_rate": 1.956224933868078e-05,
      "loss": 0.0017,
      "step": 35670
    },
    {
      "epoch": 3.0446283812612,
      "grad_norm": 0.3759547770023346,
      "learning_rate": 1.9553716187388e-05,
      "loss": 0.0015,
      "step": 35680
    },
    {
      "epoch": 3.045481696390477,
      "grad_norm": 0.2626243829727173,
      "learning_rate": 1.954518303609523e-05,
      "loss": 0.0018,
      "step": 35690
    },
    {
      "epoch": 3.046335011519754,
      "grad_norm": 0.194809690117836,
      "learning_rate": 1.9536649884802457e-05,
      "loss": 0.0022,
      "step": 35700
    },
    {
      "epoch": 3.0471883266490316,
      "grad_norm": 0.0936843678355217,
      "learning_rate": 1.9528116733509686e-05,
      "loss": 0.0021,
      "step": 35710
    },
    {
      "epoch": 3.0480416417783087,
      "grad_norm": 0.19568045437335968,
      "learning_rate": 1.9519583582216914e-05,
      "loss": 0.0017,
      "step": 35720
    },
    {
      "epoch": 3.048894956907586,
      "grad_norm": 0.04681887850165367,
      "learning_rate": 1.951105043092414e-05,
      "loss": 0.0019,
      "step": 35730
    },
    {
      "epoch": 3.0497482720368634,
      "grad_norm": 0.10040783137083054,
      "learning_rate": 1.9502517279631368e-05,
      "loss": 0.0019,
      "step": 35740
    },
    {
      "epoch": 3.0506015871661405,
      "grad_norm": 0.06301914155483246,
      "learning_rate": 1.9493984128338596e-05,
      "loss": 0.0019,
      "step": 35750
    },
    {
      "epoch": 3.0514549022954176,
      "grad_norm": 0.1916540414094925,
      "learning_rate": 1.9485450977045825e-05,
      "loss": 0.0024,
      "step": 35760
    },
    {
      "epoch": 3.052308217424695,
      "grad_norm": 0.08418720960617065,
      "learning_rate": 1.9476917825753053e-05,
      "loss": 0.0018,
      "step": 35770
    },
    {
      "epoch": 3.0531615325539723,
      "grad_norm": 0.1261250227689743,
      "learning_rate": 1.946838467446028e-05,
      "loss": 0.0024,
      "step": 35780
    },
    {
      "epoch": 3.0540148476832494,
      "grad_norm": 0.15617620944976807,
      "learning_rate": 1.9459851523167507e-05,
      "loss": 0.0023,
      "step": 35790
    },
    {
      "epoch": 3.0548681628125265,
      "grad_norm": 0.1668534129858017,
      "learning_rate": 1.9451318371874735e-05,
      "loss": 0.0025,
      "step": 35800
    },
    {
      "epoch": 3.055721477941804,
      "grad_norm": 0.0612679198384285,
      "learning_rate": 1.944278522058196e-05,
      "loss": 0.002,
      "step": 35810
    },
    {
      "epoch": 3.056574793071081,
      "grad_norm": 0.1373717486858368,
      "learning_rate": 1.943425206928919e-05,
      "loss": 0.0016,
      "step": 35820
    },
    {
      "epoch": 3.0574281082003583,
      "grad_norm": 0.2601858079433441,
      "learning_rate": 1.9425718917996417e-05,
      "loss": 0.0018,
      "step": 35830
    },
    {
      "epoch": 3.058281423329636,
      "grad_norm": 0.19772423803806305,
      "learning_rate": 1.9417185766703643e-05,
      "loss": 0.0021,
      "step": 35840
    },
    {
      "epoch": 3.059134738458913,
      "grad_norm": 0.2509748041629791,
      "learning_rate": 1.940865261541087e-05,
      "loss": 0.0015,
      "step": 35850
    },
    {
      "epoch": 3.05998805358819,
      "grad_norm": 0.08236344158649445,
      "learning_rate": 1.94001194641181e-05,
      "loss": 0.0019,
      "step": 35860
    },
    {
      "epoch": 3.060841368717467,
      "grad_norm": 0.2319524586200714,
      "learning_rate": 1.9391586312825328e-05,
      "loss": 0.0022,
      "step": 35870
    },
    {
      "epoch": 3.0616946838467447,
      "grad_norm": 0.12728509306907654,
      "learning_rate": 1.9383053161532557e-05,
      "loss": 0.0019,
      "step": 35880
    },
    {
      "epoch": 3.062547998976022,
      "grad_norm": 0.17557545006275177,
      "learning_rate": 1.937452001023978e-05,
      "loss": 0.0016,
      "step": 35890
    },
    {
      "epoch": 3.063401314105299,
      "grad_norm": 0.2287723273038864,
      "learning_rate": 1.936598685894701e-05,
      "loss": 0.0021,
      "step": 35900
    },
    {
      "epoch": 3.0642546292345765,
      "grad_norm": 0.3784467577934265,
      "learning_rate": 1.935745370765424e-05,
      "loss": 0.0018,
      "step": 35910
    },
    {
      "epoch": 3.0651079443638536,
      "grad_norm": 0.25134986639022827,
      "learning_rate": 1.9348920556361467e-05,
      "loss": 0.0026,
      "step": 35920
    },
    {
      "epoch": 3.0659612594931307,
      "grad_norm": 0.23303990066051483,
      "learning_rate": 1.9340387405068696e-05,
      "loss": 0.002,
      "step": 35930
    },
    {
      "epoch": 3.0668145746224083,
      "grad_norm": 0.06806433200836182,
      "learning_rate": 1.933185425377592e-05,
      "loss": 0.0019,
      "step": 35940
    },
    {
      "epoch": 3.0676678897516854,
      "grad_norm": 0.13879773020744324,
      "learning_rate": 1.9323321102483146e-05,
      "loss": 0.0021,
      "step": 35950
    },
    {
      "epoch": 3.0685212048809625,
      "grad_norm": 0.32663872838020325,
      "learning_rate": 1.9314787951190374e-05,
      "loss": 0.0018,
      "step": 35960
    },
    {
      "epoch": 3.0693745200102396,
      "grad_norm": 0.4750979244709015,
      "learning_rate": 1.9306254799897603e-05,
      "loss": 0.0018,
      "step": 35970
    },
    {
      "epoch": 3.070227835139517,
      "grad_norm": 0.1723683774471283,
      "learning_rate": 1.929772164860483e-05,
      "loss": 0.0018,
      "step": 35980
    },
    {
      "epoch": 3.0710811502687942,
      "grad_norm": 0.07014741003513336,
      "learning_rate": 1.9289188497312056e-05,
      "loss": 0.0019,
      "step": 35990
    },
    {
      "epoch": 3.0719344653980714,
      "grad_norm": 0.07251572608947754,
      "learning_rate": 1.9280655346019285e-05,
      "loss": 0.0024,
      "step": 36000
    },
    {
      "epoch": 3.072787780527349,
      "grad_norm": 0.21705175936222076,
      "learning_rate": 1.9272122194726513e-05,
      "loss": 0.0019,
      "step": 36010
    },
    {
      "epoch": 3.073641095656626,
      "grad_norm": 0.36309656500816345,
      "learning_rate": 1.9263589043433742e-05,
      "loss": 0.0022,
      "step": 36020
    },
    {
      "epoch": 3.074494410785903,
      "grad_norm": 0.19644370675086975,
      "learning_rate": 1.925505589214097e-05,
      "loss": 0.0014,
      "step": 36030
    },
    {
      "epoch": 3.0753477259151807,
      "grad_norm": 0.15685994923114777,
      "learning_rate": 1.9246522740848195e-05,
      "loss": 0.0022,
      "step": 36040
    },
    {
      "epoch": 3.076201041044458,
      "grad_norm": 0.15626968443393707,
      "learning_rate": 1.9237989589555424e-05,
      "loss": 0.002,
      "step": 36050
    },
    {
      "epoch": 3.077054356173735,
      "grad_norm": 0.32926589250564575,
      "learning_rate": 1.9229456438262652e-05,
      "loss": 0.0018,
      "step": 36060
    },
    {
      "epoch": 3.077907671303012,
      "grad_norm": 0.2583919167518616,
      "learning_rate": 1.922092328696988e-05,
      "loss": 0.0014,
      "step": 36070
    },
    {
      "epoch": 3.0787609864322896,
      "grad_norm": 0.06336668878793716,
      "learning_rate": 1.9212390135677106e-05,
      "loss": 0.0024,
      "step": 36080
    },
    {
      "epoch": 3.0796143015615667,
      "grad_norm": 0.09918655455112457,
      "learning_rate": 1.9203856984384334e-05,
      "loss": 0.0018,
      "step": 36090
    },
    {
      "epoch": 3.080467616690844,
      "grad_norm": 0.33823734521865845,
      "learning_rate": 1.919532383309156e-05,
      "loss": 0.0019,
      "step": 36100
    },
    {
      "epoch": 3.0813209318201213,
      "grad_norm": 0.1937132626771927,
      "learning_rate": 1.9186790681798788e-05,
      "loss": 0.0016,
      "step": 36110
    },
    {
      "epoch": 3.0821742469493985,
      "grad_norm": 0.03304506465792656,
      "learning_rate": 1.9178257530506016e-05,
      "loss": 0.002,
      "step": 36120
    },
    {
      "epoch": 3.0830275620786756,
      "grad_norm": 0.2109888792037964,
      "learning_rate": 1.9169724379213245e-05,
      "loss": 0.0017,
      "step": 36130
    },
    {
      "epoch": 3.083880877207953,
      "grad_norm": 0.20787832140922546,
      "learning_rate": 1.9161191227920473e-05,
      "loss": 0.0015,
      "step": 36140
    },
    {
      "epoch": 3.0847341923372302,
      "grad_norm": 0.1729111671447754,
      "learning_rate": 1.91526580766277e-05,
      "loss": 0.0019,
      "step": 36150
    },
    {
      "epoch": 3.0855875074665073,
      "grad_norm": 0.49383339285850525,
      "learning_rate": 1.9144124925334927e-05,
      "loss": 0.0023,
      "step": 36160
    },
    {
      "epoch": 3.0864408225957845,
      "grad_norm": 0.4361412227153778,
      "learning_rate": 1.9135591774042155e-05,
      "loss": 0.0021,
      "step": 36170
    },
    {
      "epoch": 3.087294137725062,
      "grad_norm": 0.16990698873996735,
      "learning_rate": 1.9127058622749384e-05,
      "loss": 0.0027,
      "step": 36180
    },
    {
      "epoch": 3.088147452854339,
      "grad_norm": 0.23380452394485474,
      "learning_rate": 1.9118525471456612e-05,
      "loss": 0.0018,
      "step": 36190
    },
    {
      "epoch": 3.0890007679836162,
      "grad_norm": 0.2433222085237503,
      "learning_rate": 1.9109992320163837e-05,
      "loss": 0.0018,
      "step": 36200
    },
    {
      "epoch": 3.089854083112894,
      "grad_norm": 0.40564489364624023,
      "learning_rate": 1.9101459168871063e-05,
      "loss": 0.002,
      "step": 36210
    },
    {
      "epoch": 3.090707398242171,
      "grad_norm": 0.13229988515377045,
      "learning_rate": 1.909292601757829e-05,
      "loss": 0.002,
      "step": 36220
    },
    {
      "epoch": 3.091560713371448,
      "grad_norm": 0.19374839961528778,
      "learning_rate": 1.908439286628552e-05,
      "loss": 0.0022,
      "step": 36230
    },
    {
      "epoch": 3.092414028500725,
      "grad_norm": 0.1754026561975479,
      "learning_rate": 1.9075859714992748e-05,
      "loss": 0.0016,
      "step": 36240
    },
    {
      "epoch": 3.0932673436300027,
      "grad_norm": 0.07042262703180313,
      "learning_rate": 1.9067326563699976e-05,
      "loss": 0.0015,
      "step": 36250
    },
    {
      "epoch": 3.0941206587592798,
      "grad_norm": 0.2543536424636841,
      "learning_rate": 1.90587934124072e-05,
      "loss": 0.002,
      "step": 36260
    },
    {
      "epoch": 3.094973973888557,
      "grad_norm": 0.13693219423294067,
      "learning_rate": 1.905026026111443e-05,
      "loss": 0.0026,
      "step": 36270
    },
    {
      "epoch": 3.0958272890178344,
      "grad_norm": 0.27429839968681335,
      "learning_rate": 1.904172710982166e-05,
      "loss": 0.0021,
      "step": 36280
    },
    {
      "epoch": 3.0966806041471115,
      "grad_norm": 0.40459325909614563,
      "learning_rate": 1.9033193958528887e-05,
      "loss": 0.0019,
      "step": 36290
    },
    {
      "epoch": 3.0975339192763887,
      "grad_norm": 0.1944727897644043,
      "learning_rate": 1.9024660807236112e-05,
      "loss": 0.0017,
      "step": 36300
    },
    {
      "epoch": 3.098387234405666,
      "grad_norm": 0.20257499814033508,
      "learning_rate": 1.901612765594334e-05,
      "loss": 0.0025,
      "step": 36310
    },
    {
      "epoch": 3.0992405495349433,
      "grad_norm": 0.4406144320964813,
      "learning_rate": 1.900759450465057e-05,
      "loss": 0.002,
      "step": 36320
    },
    {
      "epoch": 3.1000938646642204,
      "grad_norm": 0.15782147645950317,
      "learning_rate": 1.8999061353357798e-05,
      "loss": 0.0018,
      "step": 36330
    },
    {
      "epoch": 3.1009471797934975,
      "grad_norm": 0.03935703635215759,
      "learning_rate": 1.8990528202065023e-05,
      "loss": 0.0018,
      "step": 36340
    },
    {
      "epoch": 3.101800494922775,
      "grad_norm": 0.3398382067680359,
      "learning_rate": 1.898199505077225e-05,
      "loss": 0.0018,
      "step": 36350
    },
    {
      "epoch": 3.102653810052052,
      "grad_norm": 0.5876237750053406,
      "learning_rate": 1.8973461899479476e-05,
      "loss": 0.0024,
      "step": 36360
    },
    {
      "epoch": 3.1035071251813293,
      "grad_norm": 0.15737061202526093,
      "learning_rate": 1.8964928748186705e-05,
      "loss": 0.0027,
      "step": 36370
    },
    {
      "epoch": 3.104360440310607,
      "grad_norm": 0.18763764202594757,
      "learning_rate": 1.8956395596893933e-05,
      "loss": 0.0021,
      "step": 36380
    },
    {
      "epoch": 3.105213755439884,
      "grad_norm": 0.12419460713863373,
      "learning_rate": 1.894786244560116e-05,
      "loss": 0.0021,
      "step": 36390
    },
    {
      "epoch": 3.106067070569161,
      "grad_norm": 0.040745027363300323,
      "learning_rate": 1.893932929430839e-05,
      "loss": 0.0017,
      "step": 36400
    },
    {
      "epoch": 3.1069203856984386,
      "grad_norm": 0.19195297360420227,
      "learning_rate": 1.8930796143015615e-05,
      "loss": 0.0019,
      "step": 36410
    },
    {
      "epoch": 3.1077737008277158,
      "grad_norm": 0.05485684797167778,
      "learning_rate": 1.8922262991722844e-05,
      "loss": 0.0014,
      "step": 36420
    },
    {
      "epoch": 3.108627015956993,
      "grad_norm": 0.1547955870628357,
      "learning_rate": 1.8913729840430072e-05,
      "loss": 0.0022,
      "step": 36430
    },
    {
      "epoch": 3.10948033108627,
      "grad_norm": 0.13883577287197113,
      "learning_rate": 1.89051966891373e-05,
      "loss": 0.002,
      "step": 36440
    },
    {
      "epoch": 3.1103336462155475,
      "grad_norm": 0.15628021955490112,
      "learning_rate": 1.889666353784453e-05,
      "loss": 0.0022,
      "step": 36450
    },
    {
      "epoch": 3.1111869613448246,
      "grad_norm": 0.16163218021392822,
      "learning_rate": 1.8888130386551754e-05,
      "loss": 0.0018,
      "step": 36460
    },
    {
      "epoch": 3.1120402764741018,
      "grad_norm": 0.21306267380714417,
      "learning_rate": 1.8879597235258983e-05,
      "loss": 0.0025,
      "step": 36470
    },
    {
      "epoch": 3.1128935916033793,
      "grad_norm": 0.11278745532035828,
      "learning_rate": 1.8871064083966208e-05,
      "loss": 0.002,
      "step": 36480
    },
    {
      "epoch": 3.1137469067326564,
      "grad_norm": 0.06470336765050888,
      "learning_rate": 1.8862530932673436e-05,
      "loss": 0.0014,
      "step": 36490
    },
    {
      "epoch": 3.1146002218619335,
      "grad_norm": 0.500260055065155,
      "learning_rate": 1.8853997781380665e-05,
      "loss": 0.0018,
      "step": 36500
    },
    {
      "epoch": 3.115453536991211,
      "grad_norm": 0.4888830780982971,
      "learning_rate": 1.8845464630087893e-05,
      "loss": 0.0015,
      "step": 36510
    },
    {
      "epoch": 3.116306852120488,
      "grad_norm": 0.08993224799633026,
      "learning_rate": 1.883693147879512e-05,
      "loss": 0.0017,
      "step": 36520
    },
    {
      "epoch": 3.1171601672497653,
      "grad_norm": 0.21054072678089142,
      "learning_rate": 1.8828398327502347e-05,
      "loss": 0.0021,
      "step": 36530
    },
    {
      "epoch": 3.1180134823790424,
      "grad_norm": 0.16517668962478638,
      "learning_rate": 1.8819865176209575e-05,
      "loss": 0.0022,
      "step": 36540
    },
    {
      "epoch": 3.11886679750832,
      "grad_norm": 0.38409024477005005,
      "learning_rate": 1.8811332024916804e-05,
      "loss": 0.0015,
      "step": 36550
    },
    {
      "epoch": 3.119720112637597,
      "grad_norm": 0.10672557353973389,
      "learning_rate": 1.8802798873624032e-05,
      "loss": 0.002,
      "step": 36560
    },
    {
      "epoch": 3.120573427766874,
      "grad_norm": 0.19369441270828247,
      "learning_rate": 1.8794265722331257e-05,
      "loss": 0.0019,
      "step": 36570
    },
    {
      "epoch": 3.1214267428961517,
      "grad_norm": 0.30323511362075806,
      "learning_rate": 1.8785732571038486e-05,
      "loss": 0.0021,
      "step": 36580
    },
    {
      "epoch": 3.122280058025429,
      "grad_norm": 0.19096998870372772,
      "learning_rate": 1.8777199419745714e-05,
      "loss": 0.0018,
      "step": 36590
    },
    {
      "epoch": 3.123133373154706,
      "grad_norm": 0.10958470404148102,
      "learning_rate": 1.8768666268452943e-05,
      "loss": 0.0018,
      "step": 36600
    },
    {
      "epoch": 3.123986688283983,
      "grad_norm": 0.03827826678752899,
      "learning_rate": 1.8760133117160168e-05,
      "loss": 0.0024,
      "step": 36610
    },
    {
      "epoch": 3.1248400034132606,
      "grad_norm": 0.0689486414194107,
      "learning_rate": 1.8751599965867393e-05,
      "loss": 0.0024,
      "step": 36620
    },
    {
      "epoch": 3.1256933185425377,
      "grad_norm": 0.2295301854610443,
      "learning_rate": 1.874306681457462e-05,
      "loss": 0.0015,
      "step": 36630
    },
    {
      "epoch": 3.126546633671815,
      "grad_norm": 0.2127632200717926,
      "learning_rate": 1.873453366328185e-05,
      "loss": 0.0022,
      "step": 36640
    },
    {
      "epoch": 3.1273999488010924,
      "grad_norm": 0.13671891391277313,
      "learning_rate": 1.872600051198908e-05,
      "loss": 0.0017,
      "step": 36650
    },
    {
      "epoch": 3.1282532639303695,
      "grad_norm": 0.1571163535118103,
      "learning_rate": 1.8717467360696307e-05,
      "loss": 0.0018,
      "step": 36660
    },
    {
      "epoch": 3.1291065790596466,
      "grad_norm": 0.087254099547863,
      "learning_rate": 1.8708934209403532e-05,
      "loss": 0.002,
      "step": 36670
    },
    {
      "epoch": 3.129959894188924,
      "grad_norm": 0.25834277272224426,
      "learning_rate": 1.870040105811076e-05,
      "loss": 0.0016,
      "step": 36680
    },
    {
      "epoch": 3.1308132093182013,
      "grad_norm": 0.1399746686220169,
      "learning_rate": 1.869186790681799e-05,
      "loss": 0.0022,
      "step": 36690
    },
    {
      "epoch": 3.1316665244474784,
      "grad_norm": 0.10997655242681503,
      "learning_rate": 1.8683334755525217e-05,
      "loss": 0.0025,
      "step": 36700
    },
    {
      "epoch": 3.1325198395767555,
      "grad_norm": 0.492005318403244,
      "learning_rate": 1.8674801604232446e-05,
      "loss": 0.0015,
      "step": 36710
    },
    {
      "epoch": 3.133373154706033,
      "grad_norm": 0.1690433770418167,
      "learning_rate": 1.866626845293967e-05,
      "loss": 0.0017,
      "step": 36720
    },
    {
      "epoch": 3.13422646983531,
      "grad_norm": 0.07000989466905594,
      "learning_rate": 1.86577353016469e-05,
      "loss": 0.0023,
      "step": 36730
    },
    {
      "epoch": 3.1350797849645873,
      "grad_norm": 0.2687132954597473,
      "learning_rate": 1.8649202150354125e-05,
      "loss": 0.0024,
      "step": 36740
    },
    {
      "epoch": 3.135933100093865,
      "grad_norm": 0.08162066340446472,
      "learning_rate": 1.8640668999061353e-05,
      "loss": 0.0018,
      "step": 36750
    },
    {
      "epoch": 3.136786415223142,
      "grad_norm": 0.4284623861312866,
      "learning_rate": 1.863213584776858e-05,
      "loss": 0.0016,
      "step": 36760
    },
    {
      "epoch": 3.137639730352419,
      "grad_norm": 0.2917848229408264,
      "learning_rate": 1.862360269647581e-05,
      "loss": 0.002,
      "step": 36770
    },
    {
      "epoch": 3.138493045481696,
      "grad_norm": 0.13769938051700592,
      "learning_rate": 1.8615069545183035e-05,
      "loss": 0.0021,
      "step": 36780
    },
    {
      "epoch": 3.1393463606109737,
      "grad_norm": 0.23561033606529236,
      "learning_rate": 1.8606536393890264e-05,
      "loss": 0.0022,
      "step": 36790
    },
    {
      "epoch": 3.140199675740251,
      "grad_norm": 0.14809918403625488,
      "learning_rate": 1.8598003242597492e-05,
      "loss": 0.002,
      "step": 36800
    },
    {
      "epoch": 3.141052990869528,
      "grad_norm": 0.2635992169380188,
      "learning_rate": 1.858947009130472e-05,
      "loss": 0.0015,
      "step": 36810
    },
    {
      "epoch": 3.1419063059988055,
      "grad_norm": 0.22908909618854523,
      "learning_rate": 1.858093694001195e-05,
      "loss": 0.0022,
      "step": 36820
    },
    {
      "epoch": 3.1427596211280826,
      "grad_norm": 0.17168612778186798,
      "learning_rate": 1.8572403788719174e-05,
      "loss": 0.0018,
      "step": 36830
    },
    {
      "epoch": 3.1436129362573597,
      "grad_norm": 0.3134748041629791,
      "learning_rate": 1.8563870637426403e-05,
      "loss": 0.0018,
      "step": 36840
    },
    {
      "epoch": 3.1444662513866373,
      "grad_norm": 0.16129142045974731,
      "learning_rate": 1.855533748613363e-05,
      "loss": 0.0021,
      "step": 36850
    },
    {
      "epoch": 3.1453195665159144,
      "grad_norm": 0.30780309438705444,
      "learning_rate": 1.854680433484086e-05,
      "loss": 0.0026,
      "step": 36860
    },
    {
      "epoch": 3.1461728816451915,
      "grad_norm": 0.1727779358625412,
      "learning_rate": 1.8538271183548088e-05,
      "loss": 0.0016,
      "step": 36870
    },
    {
      "epoch": 3.147026196774469,
      "grad_norm": 0.2485119253396988,
      "learning_rate": 1.8529738032255313e-05,
      "loss": 0.0018,
      "step": 36880
    },
    {
      "epoch": 3.147879511903746,
      "grad_norm": 0.23608683049678802,
      "learning_rate": 1.852120488096254e-05,
      "loss": 0.0017,
      "step": 36890
    },
    {
      "epoch": 3.1487328270330233,
      "grad_norm": 0.16891683638095856,
      "learning_rate": 1.8512671729669767e-05,
      "loss": 0.0017,
      "step": 36900
    },
    {
      "epoch": 3.1495861421623004,
      "grad_norm": 0.20099526643753052,
      "learning_rate": 1.8504138578376995e-05,
      "loss": 0.0021,
      "step": 36910
    },
    {
      "epoch": 3.150439457291578,
      "grad_norm": 0.06739320605993271,
      "learning_rate": 1.8495605427084224e-05,
      "loss": 0.0023,
      "step": 36920
    },
    {
      "epoch": 3.151292772420855,
      "grad_norm": 0.3206839859485626,
      "learning_rate": 1.848707227579145e-05,
      "loss": 0.002,
      "step": 36930
    },
    {
      "epoch": 3.152146087550132,
      "grad_norm": 0.23181480169296265,
      "learning_rate": 1.8478539124498677e-05,
      "loss": 0.0025,
      "step": 36940
    },
    {
      "epoch": 3.1529994026794097,
      "grad_norm": 0.10917948931455612,
      "learning_rate": 1.8470005973205906e-05,
      "loss": 0.0017,
      "step": 36950
    },
    {
      "epoch": 3.153852717808687,
      "grad_norm": 0.11517465859651566,
      "learning_rate": 1.8461472821913134e-05,
      "loss": 0.0014,
      "step": 36960
    },
    {
      "epoch": 3.154706032937964,
      "grad_norm": 0.2062525749206543,
      "learning_rate": 1.8452939670620363e-05,
      "loss": 0.0016,
      "step": 36970
    },
    {
      "epoch": 3.155559348067241,
      "grad_norm": 0.14051969349384308,
      "learning_rate": 1.8444406519327588e-05,
      "loss": 0.0022,
      "step": 36980
    },
    {
      "epoch": 3.1564126631965186,
      "grad_norm": 0.08213818818330765,
      "learning_rate": 1.8435873368034816e-05,
      "loss": 0.0017,
      "step": 36990
    },
    {
      "epoch": 3.1572659783257957,
      "grad_norm": 0.24617613852024078,
      "learning_rate": 1.8427340216742045e-05,
      "loss": 0.0022,
      "step": 37000
    },
    {
      "epoch": 3.158119293455073,
      "grad_norm": 0.17790555953979492,
      "learning_rate": 1.841880706544927e-05,
      "loss": 0.0026,
      "step": 37010
    },
    {
      "epoch": 3.1589726085843504,
      "grad_norm": 0.11285063624382019,
      "learning_rate": 1.84102739141565e-05,
      "loss": 0.0021,
      "step": 37020
    },
    {
      "epoch": 3.1598259237136275,
      "grad_norm": 0.06290385127067566,
      "learning_rate": 1.8401740762863727e-05,
      "loss": 0.0019,
      "step": 37030
    },
    {
      "epoch": 3.1606792388429046,
      "grad_norm": 0.03022363968193531,
      "learning_rate": 1.8393207611570952e-05,
      "loss": 0.0018,
      "step": 37040
    },
    {
      "epoch": 3.161532553972182,
      "grad_norm": 0.18374669551849365,
      "learning_rate": 1.838467446027818e-05,
      "loss": 0.0015,
      "step": 37050
    },
    {
      "epoch": 3.1623858691014592,
      "grad_norm": 0.07851387560367584,
      "learning_rate": 1.837614130898541e-05,
      "loss": 0.0018,
      "step": 37060
    },
    {
      "epoch": 3.1632391842307364,
      "grad_norm": 0.2305726408958435,
      "learning_rate": 1.8367608157692637e-05,
      "loss": 0.0018,
      "step": 37070
    },
    {
      "epoch": 3.1640924993600135,
      "grad_norm": 0.06166654825210571,
      "learning_rate": 1.8359075006399866e-05,
      "loss": 0.0023,
      "step": 37080
    },
    {
      "epoch": 3.164945814489291,
      "grad_norm": 0.2561793029308319,
      "learning_rate": 1.835054185510709e-05,
      "loss": 0.0019,
      "step": 37090
    },
    {
      "epoch": 3.165799129618568,
      "grad_norm": 0.056827180087566376,
      "learning_rate": 1.834200870381432e-05,
      "loss": 0.0021,
      "step": 37100
    },
    {
      "epoch": 3.1666524447478452,
      "grad_norm": 0.17459431290626526,
      "learning_rate": 1.8333475552521548e-05,
      "loss": 0.002,
      "step": 37110
    },
    {
      "epoch": 3.167505759877123,
      "grad_norm": 0.31860029697418213,
      "learning_rate": 1.8324942401228776e-05,
      "loss": 0.0021,
      "step": 37120
    },
    {
      "epoch": 3.1683590750064,
      "grad_norm": 0.05961460992693901,
      "learning_rate": 1.8316409249936005e-05,
      "loss": 0.002,
      "step": 37130
    },
    {
      "epoch": 3.169212390135677,
      "grad_norm": 0.1692337989807129,
      "learning_rate": 1.830787609864323e-05,
      "loss": 0.0017,
      "step": 37140
    },
    {
      "epoch": 3.170065705264954,
      "grad_norm": 0.0777125284075737,
      "learning_rate": 1.8299342947350455e-05,
      "loss": 0.0026,
      "step": 37150
    },
    {
      "epoch": 3.1709190203942317,
      "grad_norm": 0.22205856442451477,
      "learning_rate": 1.8290809796057684e-05,
      "loss": 0.0026,
      "step": 37160
    },
    {
      "epoch": 3.171772335523509,
      "grad_norm": 0.26581424474716187,
      "learning_rate": 1.8282276644764912e-05,
      "loss": 0.0018,
      "step": 37170
    },
    {
      "epoch": 3.172625650652786,
      "grad_norm": 0.16824857890605927,
      "learning_rate": 1.827374349347214e-05,
      "loss": 0.0023,
      "step": 37180
    },
    {
      "epoch": 3.1734789657820635,
      "grad_norm": 0.15897832810878754,
      "learning_rate": 1.826521034217937e-05,
      "loss": 0.0018,
      "step": 37190
    },
    {
      "epoch": 3.1743322809113406,
      "grad_norm": 0.16228123009204865,
      "learning_rate": 1.8256677190886594e-05,
      "loss": 0.0019,
      "step": 37200
    },
    {
      "epoch": 3.1751855960406177,
      "grad_norm": 0.06339389085769653,
      "learning_rate": 1.8248144039593823e-05,
      "loss": 0.0018,
      "step": 37210
    },
    {
      "epoch": 3.1760389111698952,
      "grad_norm": 0.3888002634048462,
      "learning_rate": 1.823961088830105e-05,
      "loss": 0.002,
      "step": 37220
    },
    {
      "epoch": 3.1768922262991723,
      "grad_norm": 0.03659491986036301,
      "learning_rate": 1.823107773700828e-05,
      "loss": 0.0021,
      "step": 37230
    },
    {
      "epoch": 3.1777455414284494,
      "grad_norm": 0.07434087991714478,
      "learning_rate": 1.8222544585715505e-05,
      "loss": 0.0019,
      "step": 37240
    },
    {
      "epoch": 3.178598856557727,
      "grad_norm": 0.40166112780570984,
      "learning_rate": 1.8214011434422733e-05,
      "loss": 0.0016,
      "step": 37250
    },
    {
      "epoch": 3.179452171687004,
      "grad_norm": 0.07723166048526764,
      "learning_rate": 1.820547828312996e-05,
      "loss": 0.0023,
      "step": 37260
    },
    {
      "epoch": 3.1803054868162812,
      "grad_norm": 0.043652597814798355,
      "learning_rate": 1.8196945131837187e-05,
      "loss": 0.0017,
      "step": 37270
    },
    {
      "epoch": 3.1811588019455583,
      "grad_norm": 0.19765536487102509,
      "learning_rate": 1.8188411980544415e-05,
      "loss": 0.0023,
      "step": 37280
    },
    {
      "epoch": 3.182012117074836,
      "grad_norm": 0.09402568638324738,
      "learning_rate": 1.8179878829251644e-05,
      "loss": 0.0017,
      "step": 37290
    },
    {
      "epoch": 3.182865432204113,
      "grad_norm": 0.08678560703992844,
      "learning_rate": 1.817134567795887e-05,
      "loss": 0.0027,
      "step": 37300
    },
    {
      "epoch": 3.18371874733339,
      "grad_norm": 0.04735540598630905,
      "learning_rate": 1.8162812526666097e-05,
      "loss": 0.0021,
      "step": 37310
    },
    {
      "epoch": 3.1845720624626677,
      "grad_norm": 0.2874261438846588,
      "learning_rate": 1.8154279375373326e-05,
      "loss": 0.0019,
      "step": 37320
    },
    {
      "epoch": 3.1854253775919448,
      "grad_norm": 0.14317503571510315,
      "learning_rate": 1.8145746224080554e-05,
      "loss": 0.0021,
      "step": 37330
    },
    {
      "epoch": 3.186278692721222,
      "grad_norm": 0.17756503820419312,
      "learning_rate": 1.8137213072787783e-05,
      "loss": 0.0023,
      "step": 37340
    },
    {
      "epoch": 3.187132007850499,
      "grad_norm": 0.4659939408302307,
      "learning_rate": 1.8128679921495008e-05,
      "loss": 0.0022,
      "step": 37350
    },
    {
      "epoch": 3.1879853229797765,
      "grad_norm": 0.20051760971546173,
      "learning_rate": 1.8120146770202236e-05,
      "loss": 0.0017,
      "step": 37360
    },
    {
      "epoch": 3.1888386381090537,
      "grad_norm": 0.23778226971626282,
      "learning_rate": 1.8111613618909465e-05,
      "loss": 0.0016,
      "step": 37370
    },
    {
      "epoch": 3.1896919532383308,
      "grad_norm": 0.19615662097930908,
      "learning_rate": 1.8103080467616693e-05,
      "loss": 0.0018,
      "step": 37380
    },
    {
      "epoch": 3.1905452683676083,
      "grad_norm": 0.2244914323091507,
      "learning_rate": 1.8094547316323922e-05,
      "loss": 0.0022,
      "step": 37390
    },
    {
      "epoch": 3.1913985834968854,
      "grad_norm": 0.28982365131378174,
      "learning_rate": 1.8086014165031147e-05,
      "loss": 0.0018,
      "step": 37400
    },
    {
      "epoch": 3.1922518986261625,
      "grad_norm": 0.31944936513900757,
      "learning_rate": 1.8077481013738372e-05,
      "loss": 0.0023,
      "step": 37410
    },
    {
      "epoch": 3.19310521375544,
      "grad_norm": 0.11320670694112778,
      "learning_rate": 1.80689478624456e-05,
      "loss": 0.0023,
      "step": 37420
    },
    {
      "epoch": 3.193958528884717,
      "grad_norm": 0.08803076297044754,
      "learning_rate": 1.806041471115283e-05,
      "loss": 0.0017,
      "step": 37430
    },
    {
      "epoch": 3.1948118440139943,
      "grad_norm": 0.0769834965467453,
      "learning_rate": 1.8051881559860057e-05,
      "loss": 0.0015,
      "step": 37440
    },
    {
      "epoch": 3.1956651591432714,
      "grad_norm": 0.1623745560646057,
      "learning_rate": 1.8043348408567286e-05,
      "loss": 0.0018,
      "step": 37450
    },
    {
      "epoch": 3.196518474272549,
      "grad_norm": 0.05113164335489273,
      "learning_rate": 1.803481525727451e-05,
      "loss": 0.0015,
      "step": 37460
    },
    {
      "epoch": 3.197371789401826,
      "grad_norm": 0.3170934021472931,
      "learning_rate": 1.802628210598174e-05,
      "loss": 0.002,
      "step": 37470
    },
    {
      "epoch": 3.198225104531103,
      "grad_norm": 0.1454530954360962,
      "learning_rate": 1.8017748954688968e-05,
      "loss": 0.0015,
      "step": 37480
    },
    {
      "epoch": 3.1990784196603808,
      "grad_norm": 0.13430403172969818,
      "learning_rate": 1.8009215803396196e-05,
      "loss": 0.0025,
      "step": 37490
    },
    {
      "epoch": 3.199931734789658,
      "grad_norm": 0.44085362553596497,
      "learning_rate": 1.8000682652103425e-05,
      "loss": 0.0016,
      "step": 37500
    },
    {
      "epoch": 3.200785049918935,
      "grad_norm": 0.24300973117351532,
      "learning_rate": 1.799214950081065e-05,
      "loss": 0.002,
      "step": 37510
    },
    {
      "epoch": 3.201638365048212,
      "grad_norm": 0.32552167773246765,
      "learning_rate": 1.798361634951788e-05,
      "loss": 0.0024,
      "step": 37520
    },
    {
      "epoch": 3.2024916801774896,
      "grad_norm": 0.09824348241090775,
      "learning_rate": 1.7975083198225107e-05,
      "loss": 0.0025,
      "step": 37530
    },
    {
      "epoch": 3.2033449953067668,
      "grad_norm": 0.2095491737127304,
      "learning_rate": 1.7966550046932332e-05,
      "loss": 0.0021,
      "step": 37540
    },
    {
      "epoch": 3.204198310436044,
      "grad_norm": 0.06932505965232849,
      "learning_rate": 1.795801689563956e-05,
      "loss": 0.002,
      "step": 37550
    },
    {
      "epoch": 3.2050516255653214,
      "grad_norm": 0.17206713557243347,
      "learning_rate": 1.7949483744346786e-05,
      "loss": 0.0024,
      "step": 37560
    },
    {
      "epoch": 3.2059049406945985,
      "grad_norm": 0.2691679000854492,
      "learning_rate": 1.7940950593054014e-05,
      "loss": 0.0017,
      "step": 37570
    },
    {
      "epoch": 3.2067582558238756,
      "grad_norm": 0.1390407681465149,
      "learning_rate": 1.7932417441761243e-05,
      "loss": 0.0016,
      "step": 37580
    },
    {
      "epoch": 3.207611570953153,
      "grad_norm": 0.06845810264348984,
      "learning_rate": 1.792388429046847e-05,
      "loss": 0.0016,
      "step": 37590
    },
    {
      "epoch": 3.2084648860824303,
      "grad_norm": 0.5085766911506653,
      "learning_rate": 1.79153511391757e-05,
      "loss": 0.002,
      "step": 37600
    },
    {
      "epoch": 3.2093182012117074,
      "grad_norm": 0.08152598887681961,
      "learning_rate": 1.7906817987882925e-05,
      "loss": 0.0025,
      "step": 37610
    },
    {
      "epoch": 3.2101715163409845,
      "grad_norm": 0.37737900018692017,
      "learning_rate": 1.7898284836590153e-05,
      "loss": 0.0018,
      "step": 37620
    },
    {
      "epoch": 3.211024831470262,
      "grad_norm": 0.13375282287597656,
      "learning_rate": 1.788975168529738e-05,
      "loss": 0.002,
      "step": 37630
    },
    {
      "epoch": 3.211878146599539,
      "grad_norm": 0.16707472503185272,
      "learning_rate": 1.788121853400461e-05,
      "loss": 0.0018,
      "step": 37640
    },
    {
      "epoch": 3.2127314617288163,
      "grad_norm": 0.21013155579566956,
      "learning_rate": 1.787268538271184e-05,
      "loss": 0.0021,
      "step": 37650
    },
    {
      "epoch": 3.213584776858094,
      "grad_norm": 0.24724924564361572,
      "learning_rate": 1.7864152231419064e-05,
      "loss": 0.0021,
      "step": 37660
    },
    {
      "epoch": 3.214438091987371,
      "grad_norm": 0.15663747489452362,
      "learning_rate": 1.785561908012629e-05,
      "loss": 0.0017,
      "step": 37670
    },
    {
      "epoch": 3.215291407116648,
      "grad_norm": 0.04616029933094978,
      "learning_rate": 1.7847085928833517e-05,
      "loss": 0.0022,
      "step": 37680
    },
    {
      "epoch": 3.2161447222459256,
      "grad_norm": 0.11592870950698853,
      "learning_rate": 1.7838552777540746e-05,
      "loss": 0.0022,
      "step": 37690
    },
    {
      "epoch": 3.2169980373752027,
      "grad_norm": 0.04219336807727814,
      "learning_rate": 1.7830019626247974e-05,
      "loss": 0.0017,
      "step": 37700
    },
    {
      "epoch": 3.21785135250448,
      "grad_norm": 0.21942977607250214,
      "learning_rate": 1.7821486474955203e-05,
      "loss": 0.002,
      "step": 37710
    },
    {
      "epoch": 3.218704667633757,
      "grad_norm": 0.1133631020784378,
      "learning_rate": 1.7812953323662428e-05,
      "loss": 0.0015,
      "step": 37720
    },
    {
      "epoch": 3.2195579827630345,
      "grad_norm": 0.11981304734945297,
      "learning_rate": 1.7804420172369656e-05,
      "loss": 0.002,
      "step": 37730
    },
    {
      "epoch": 3.2204112978923116,
      "grad_norm": 0.1361706405878067,
      "learning_rate": 1.7795887021076885e-05,
      "loss": 0.002,
      "step": 37740
    },
    {
      "epoch": 3.2212646130215887,
      "grad_norm": 0.24732589721679688,
      "learning_rate": 1.7787353869784113e-05,
      "loss": 0.0014,
      "step": 37750
    },
    {
      "epoch": 3.2221179281508663,
      "grad_norm": 0.45232394337654114,
      "learning_rate": 1.7778820718491342e-05,
      "loss": 0.0015,
      "step": 37760
    },
    {
      "epoch": 3.2229712432801434,
      "grad_norm": 0.20876923203468323,
      "learning_rate": 1.7770287567198567e-05,
      "loss": 0.0026,
      "step": 37770
    },
    {
      "epoch": 3.2238245584094205,
      "grad_norm": 0.23027759790420532,
      "learning_rate": 1.7761754415905795e-05,
      "loss": 0.0022,
      "step": 37780
    },
    {
      "epoch": 3.224677873538698,
      "grad_norm": 0.21539488434791565,
      "learning_rate": 1.7753221264613024e-05,
      "loss": 0.0019,
      "step": 37790
    },
    {
      "epoch": 3.225531188667975,
      "grad_norm": 0.03617195039987564,
      "learning_rate": 1.7744688113320252e-05,
      "loss": 0.0014,
      "step": 37800
    },
    {
      "epoch": 3.2263845037972523,
      "grad_norm": 0.15853050351142883,
      "learning_rate": 1.7736154962027477e-05,
      "loss": 0.0018,
      "step": 37810
    },
    {
      "epoch": 3.2272378189265294,
      "grad_norm": 0.17178446054458618,
      "learning_rate": 1.7727621810734706e-05,
      "loss": 0.002,
      "step": 37820
    },
    {
      "epoch": 3.228091134055807,
      "grad_norm": 0.2858539819717407,
      "learning_rate": 1.771908865944193e-05,
      "loss": 0.0021,
      "step": 37830
    },
    {
      "epoch": 3.228944449185084,
      "grad_norm": 0.06429828703403473,
      "learning_rate": 1.771055550814916e-05,
      "loss": 0.0015,
      "step": 37840
    },
    {
      "epoch": 3.229797764314361,
      "grad_norm": 0.15711191296577454,
      "learning_rate": 1.7702022356856388e-05,
      "loss": 0.0018,
      "step": 37850
    },
    {
      "epoch": 3.2306510794436387,
      "grad_norm": 0.133970245718956,
      "learning_rate": 1.7693489205563616e-05,
      "loss": 0.0018,
      "step": 37860
    },
    {
      "epoch": 3.231504394572916,
      "grad_norm": 0.20488514006137848,
      "learning_rate": 1.768495605427084e-05,
      "loss": 0.002,
      "step": 37870
    },
    {
      "epoch": 3.232357709702193,
      "grad_norm": 0.24353814125061035,
      "learning_rate": 1.767642290297807e-05,
      "loss": 0.002,
      "step": 37880
    },
    {
      "epoch": 3.23321102483147,
      "grad_norm": 0.2846422493457794,
      "learning_rate": 1.76678897516853e-05,
      "loss": 0.002,
      "step": 37890
    },
    {
      "epoch": 3.2340643399607476,
      "grad_norm": 0.1558839976787567,
      "learning_rate": 1.7659356600392527e-05,
      "loss": 0.0024,
      "step": 37900
    },
    {
      "epoch": 3.2349176550900247,
      "grad_norm": 0.04493952915072441,
      "learning_rate": 1.7650823449099755e-05,
      "loss": 0.0022,
      "step": 37910
    },
    {
      "epoch": 3.235770970219302,
      "grad_norm": 0.09439978003501892,
      "learning_rate": 1.764229029780698e-05,
      "loss": 0.0021,
      "step": 37920
    },
    {
      "epoch": 3.2366242853485794,
      "grad_norm": 0.14451995491981506,
      "learning_rate": 1.763375714651421e-05,
      "loss": 0.0023,
      "step": 37930
    },
    {
      "epoch": 3.2374776004778565,
      "grad_norm": 0.0330166295170784,
      "learning_rate": 1.7625223995221434e-05,
      "loss": 0.0021,
      "step": 37940
    },
    {
      "epoch": 3.2383309156071336,
      "grad_norm": 0.14031995832920074,
      "learning_rate": 1.7616690843928663e-05,
      "loss": 0.0021,
      "step": 37950
    },
    {
      "epoch": 3.239184230736411,
      "grad_norm": 0.12308245897293091,
      "learning_rate": 1.760815769263589e-05,
      "loss": 0.0024,
      "step": 37960
    },
    {
      "epoch": 3.2400375458656883,
      "grad_norm": 0.18451596796512604,
      "learning_rate": 1.759962454134312e-05,
      "loss": 0.0017,
      "step": 37970
    },
    {
      "epoch": 3.2408908609949654,
      "grad_norm": 0.15351717174053192,
      "learning_rate": 1.7591091390050345e-05,
      "loss": 0.0021,
      "step": 37980
    },
    {
      "epoch": 3.2417441761242425,
      "grad_norm": 0.17075879871845245,
      "learning_rate": 1.7582558238757573e-05,
      "loss": 0.0018,
      "step": 37990
    },
    {
      "epoch": 3.24259749125352,
      "grad_norm": 0.07073820382356644,
      "learning_rate": 1.75740250874648e-05,
      "loss": 0.0017,
      "step": 38000
    },
    {
      "epoch": 3.243450806382797,
      "grad_norm": 0.15954452753067017,
      "learning_rate": 1.756549193617203e-05,
      "loss": 0.0012,
      "step": 38010
    },
    {
      "epoch": 3.2443041215120743,
      "grad_norm": 0.17360356450080872,
      "learning_rate": 1.755695878487926e-05,
      "loss": 0.0019,
      "step": 38020
    },
    {
      "epoch": 3.245157436641352,
      "grad_norm": 0.168760284781456,
      "learning_rate": 1.7548425633586484e-05,
      "loss": 0.0015,
      "step": 38030
    },
    {
      "epoch": 3.246010751770629,
      "grad_norm": 0.22546601295471191,
      "learning_rate": 1.7539892482293712e-05,
      "loss": 0.0021,
      "step": 38040
    },
    {
      "epoch": 3.246864066899906,
      "grad_norm": 0.06330516934394836,
      "learning_rate": 1.753135933100094e-05,
      "loss": 0.0023,
      "step": 38050
    },
    {
      "epoch": 3.247717382029183,
      "grad_norm": 0.04484758526086807,
      "learning_rate": 1.752282617970817e-05,
      "loss": 0.0016,
      "step": 38060
    },
    {
      "epoch": 3.2485706971584607,
      "grad_norm": 0.1555667221546173,
      "learning_rate": 1.7514293028415394e-05,
      "loss": 0.002,
      "step": 38070
    },
    {
      "epoch": 3.249424012287738,
      "grad_norm": 0.08067969977855682,
      "learning_rate": 1.7505759877122623e-05,
      "loss": 0.0028,
      "step": 38080
    },
    {
      "epoch": 3.250277327417015,
      "grad_norm": 0.2036179155111313,
      "learning_rate": 1.7497226725829848e-05,
      "loss": 0.0017,
      "step": 38090
    },
    {
      "epoch": 3.2511306425462925,
      "grad_norm": 0.05425308272242546,
      "learning_rate": 1.7488693574537076e-05,
      "loss": 0.0021,
      "step": 38100
    },
    {
      "epoch": 3.2519839576755696,
      "grad_norm": 0.08734516054391861,
      "learning_rate": 1.7480160423244305e-05,
      "loss": 0.0024,
      "step": 38110
    },
    {
      "epoch": 3.2528372728048467,
      "grad_norm": 0.2989809513092041,
      "learning_rate": 1.7471627271951533e-05,
      "loss": 0.0015,
      "step": 38120
    },
    {
      "epoch": 3.2536905879341242,
      "grad_norm": 0.24577198922634125,
      "learning_rate": 1.746309412065876e-05,
      "loss": 0.0018,
      "step": 38130
    },
    {
      "epoch": 3.2545439030634014,
      "grad_norm": 0.03463022783398628,
      "learning_rate": 1.7454560969365987e-05,
      "loss": 0.002,
      "step": 38140
    },
    {
      "epoch": 3.2553972181926785,
      "grad_norm": 0.10144653171300888,
      "learning_rate": 1.7446027818073215e-05,
      "loss": 0.0022,
      "step": 38150
    },
    {
      "epoch": 3.256250533321956,
      "grad_norm": 0.11239875853061676,
      "learning_rate": 1.7437494666780444e-05,
      "loss": 0.0019,
      "step": 38160
    },
    {
      "epoch": 3.257103848451233,
      "grad_norm": 0.0762423500418663,
      "learning_rate": 1.7428961515487672e-05,
      "loss": 0.0021,
      "step": 38170
    },
    {
      "epoch": 3.2579571635805102,
      "grad_norm": 0.3378373682498932,
      "learning_rate": 1.74204283641949e-05,
      "loss": 0.002,
      "step": 38180
    },
    {
      "epoch": 3.2588104787097874,
      "grad_norm": 0.19543780386447906,
      "learning_rate": 1.7411895212902126e-05,
      "loss": 0.0018,
      "step": 38190
    },
    {
      "epoch": 3.259663793839065,
      "grad_norm": 0.34624558687210083,
      "learning_rate": 1.740336206160935e-05,
      "loss": 0.0018,
      "step": 38200
    },
    {
      "epoch": 3.260517108968342,
      "grad_norm": 0.2337021827697754,
      "learning_rate": 1.739482891031658e-05,
      "loss": 0.0017,
      "step": 38210
    },
    {
      "epoch": 3.261370424097619,
      "grad_norm": 0.11033280938863754,
      "learning_rate": 1.7386295759023808e-05,
      "loss": 0.002,
      "step": 38220
    },
    {
      "epoch": 3.2622237392268967,
      "grad_norm": 0.4193124771118164,
      "learning_rate": 1.7377762607731036e-05,
      "loss": 0.0023,
      "step": 38230
    },
    {
      "epoch": 3.263077054356174,
      "grad_norm": 0.034868158400058746,
      "learning_rate": 1.736922945643826e-05,
      "loss": 0.002,
      "step": 38240
    },
    {
      "epoch": 3.263930369485451,
      "grad_norm": 0.1837836056947708,
      "learning_rate": 1.736069630514549e-05,
      "loss": 0.0017,
      "step": 38250
    },
    {
      "epoch": 3.264783684614728,
      "grad_norm": 0.035145945847034454,
      "learning_rate": 1.735216315385272e-05,
      "loss": 0.0018,
      "step": 38260
    },
    {
      "epoch": 3.2656369997440056,
      "grad_norm": 0.10431590676307678,
      "learning_rate": 1.7343630002559947e-05,
      "loss": 0.0019,
      "step": 38270
    },
    {
      "epoch": 3.2664903148732827,
      "grad_norm": 0.09984248876571655,
      "learning_rate": 1.7335096851267175e-05,
      "loss": 0.0019,
      "step": 38280
    },
    {
      "epoch": 3.26734363000256,
      "grad_norm": 0.08165881782770157,
      "learning_rate": 1.73265636999744e-05,
      "loss": 0.0018,
      "step": 38290
    },
    {
      "epoch": 3.2681969451318373,
      "grad_norm": 0.19562862813472748,
      "learning_rate": 1.731803054868163e-05,
      "loss": 0.0019,
      "step": 38300
    },
    {
      "epoch": 3.2690502602611144,
      "grad_norm": 0.4248477518558502,
      "learning_rate": 1.7309497397388857e-05,
      "loss": 0.002,
      "step": 38310
    },
    {
      "epoch": 3.2699035753903916,
      "grad_norm": 0.15769602358341217,
      "learning_rate": 1.7300964246096086e-05,
      "loss": 0.0021,
      "step": 38320
    },
    {
      "epoch": 3.270756890519669,
      "grad_norm": 0.3023330569267273,
      "learning_rate": 1.7292431094803314e-05,
      "loss": 0.0026,
      "step": 38330
    },
    {
      "epoch": 3.2716102056489462,
      "grad_norm": 0.1585700809955597,
      "learning_rate": 1.728389794351054e-05,
      "loss": 0.0016,
      "step": 38340
    },
    {
      "epoch": 3.2724635207782233,
      "grad_norm": 0.06228012964129448,
      "learning_rate": 1.7275364792217765e-05,
      "loss": 0.0016,
      "step": 38350
    },
    {
      "epoch": 3.273316835907501,
      "grad_norm": 0.10704224556684494,
      "learning_rate": 1.7266831640924993e-05,
      "loss": 0.002,
      "step": 38360
    },
    {
      "epoch": 3.274170151036778,
      "grad_norm": 0.2732142210006714,
      "learning_rate": 1.725829848963222e-05,
      "loss": 0.0018,
      "step": 38370
    },
    {
      "epoch": 3.275023466166055,
      "grad_norm": 0.30394870042800903,
      "learning_rate": 1.724976533833945e-05,
      "loss": 0.0019,
      "step": 38380
    },
    {
      "epoch": 3.275876781295332,
      "grad_norm": 0.08109378814697266,
      "learning_rate": 1.724123218704668e-05,
      "loss": 0.0023,
      "step": 38390
    },
    {
      "epoch": 3.2767300964246098,
      "grad_norm": 0.2682493031024933,
      "learning_rate": 1.7232699035753904e-05,
      "loss": 0.0019,
      "step": 38400
    },
    {
      "epoch": 3.277583411553887,
      "grad_norm": 0.09687892347574234,
      "learning_rate": 1.7224165884461132e-05,
      "loss": 0.0021,
      "step": 38410
    },
    {
      "epoch": 3.278436726683164,
      "grad_norm": 0.3765852451324463,
      "learning_rate": 1.721563273316836e-05,
      "loss": 0.0018,
      "step": 38420
    },
    {
      "epoch": 3.279290041812441,
      "grad_norm": 0.17325685918331146,
      "learning_rate": 1.720709958187559e-05,
      "loss": 0.0021,
      "step": 38430
    },
    {
      "epoch": 3.2801433569417187,
      "grad_norm": 0.36108097434043884,
      "learning_rate": 1.7198566430582817e-05,
      "loss": 0.0022,
      "step": 38440
    },
    {
      "epoch": 3.2809966720709958,
      "grad_norm": 0.0769168883562088,
      "learning_rate": 1.7190033279290043e-05,
      "loss": 0.0018,
      "step": 38450
    },
    {
      "epoch": 3.281849987200273,
      "grad_norm": 0.2344197779893875,
      "learning_rate": 1.718150012799727e-05,
      "loss": 0.0017,
      "step": 38460
    },
    {
      "epoch": 3.2827033023295504,
      "grad_norm": 0.03180287778377533,
      "learning_rate": 1.7172966976704496e-05,
      "loss": 0.0025,
      "step": 38470
    },
    {
      "epoch": 3.2835566174588275,
      "grad_norm": 0.20463484525680542,
      "learning_rate": 1.7164433825411725e-05,
      "loss": 0.002,
      "step": 38480
    },
    {
      "epoch": 3.2844099325881047,
      "grad_norm": 0.285052090883255,
      "learning_rate": 1.7155900674118953e-05,
      "loss": 0.0023,
      "step": 38490
    },
    {
      "epoch": 3.285263247717382,
      "grad_norm": 0.11835639923810959,
      "learning_rate": 1.7147367522826178e-05,
      "loss": 0.0019,
      "step": 38500
    },
    {
      "epoch": 3.2861165628466593,
      "grad_norm": 0.13253790140151978,
      "learning_rate": 1.7138834371533407e-05,
      "loss": 0.0019,
      "step": 38510
    },
    {
      "epoch": 3.2869698779759364,
      "grad_norm": 0.30750349164009094,
      "learning_rate": 1.7130301220240635e-05,
      "loss": 0.0018,
      "step": 38520
    },
    {
      "epoch": 3.287823193105214,
      "grad_norm": 0.07739497721195221,
      "learning_rate": 1.7121768068947864e-05,
      "loss": 0.0018,
      "step": 38530
    },
    {
      "epoch": 3.288676508234491,
      "grad_norm": 0.1388450562953949,
      "learning_rate": 1.7113234917655092e-05,
      "loss": 0.0018,
      "step": 38540
    },
    {
      "epoch": 3.289529823363768,
      "grad_norm": 0.03752867132425308,
      "learning_rate": 1.7104701766362317e-05,
      "loss": 0.0016,
      "step": 38550
    },
    {
      "epoch": 3.2903831384930453,
      "grad_norm": 0.34299436211586,
      "learning_rate": 1.7096168615069546e-05,
      "loss": 0.0018,
      "step": 38560
    },
    {
      "epoch": 3.291236453622323,
      "grad_norm": 0.04752446338534355,
      "learning_rate": 1.7087635463776774e-05,
      "loss": 0.0017,
      "step": 38570
    },
    {
      "epoch": 3.2920897687516,
      "grad_norm": 0.36754217743873596,
      "learning_rate": 1.7079102312484003e-05,
      "loss": 0.0023,
      "step": 38580
    },
    {
      "epoch": 3.292943083880877,
      "grad_norm": 0.19424386322498322,
      "learning_rate": 1.707056916119123e-05,
      "loss": 0.0019,
      "step": 38590
    },
    {
      "epoch": 3.2937963990101546,
      "grad_norm": 0.06719012558460236,
      "learning_rate": 1.7062036009898456e-05,
      "loss": 0.0019,
      "step": 38600
    },
    {
      "epoch": 3.2946497141394318,
      "grad_norm": 0.07326260954141617,
      "learning_rate": 1.705350285860568e-05,
      "loss": 0.0018,
      "step": 38610
    },
    {
      "epoch": 3.295503029268709,
      "grad_norm": 0.11695762723684311,
      "learning_rate": 1.704496970731291e-05,
      "loss": 0.0023,
      "step": 38620
    },
    {
      "epoch": 3.296356344397986,
      "grad_norm": 0.09144031256437302,
      "learning_rate": 1.703643655602014e-05,
      "loss": 0.0019,
      "step": 38630
    },
    {
      "epoch": 3.2972096595272635,
      "grad_norm": 0.12013902515172958,
      "learning_rate": 1.7027903404727367e-05,
      "loss": 0.0021,
      "step": 38640
    },
    {
      "epoch": 3.2980629746565406,
      "grad_norm": 0.17644312977790833,
      "learning_rate": 1.7019370253434595e-05,
      "loss": 0.0019,
      "step": 38650
    },
    {
      "epoch": 3.2989162897858177,
      "grad_norm": 0.3780609667301178,
      "learning_rate": 1.701083710214182e-05,
      "loss": 0.002,
      "step": 38660
    },
    {
      "epoch": 3.2997696049150953,
      "grad_norm": 0.19730712473392487,
      "learning_rate": 1.700230395084905e-05,
      "loss": 0.0021,
      "step": 38670
    },
    {
      "epoch": 3.3006229200443724,
      "grad_norm": 0.18837302923202515,
      "learning_rate": 1.6993770799556277e-05,
      "loss": 0.0024,
      "step": 38680
    },
    {
      "epoch": 3.3014762351736495,
      "grad_norm": 0.14759305119514465,
      "learning_rate": 1.6985237648263506e-05,
      "loss": 0.0014,
      "step": 38690
    },
    {
      "epoch": 3.302329550302927,
      "grad_norm": 0.3057859241962433,
      "learning_rate": 1.6976704496970734e-05,
      "loss": 0.0018,
      "step": 38700
    },
    {
      "epoch": 3.303182865432204,
      "grad_norm": 0.2153872847557068,
      "learning_rate": 1.696817134567796e-05,
      "loss": 0.0014,
      "step": 38710
    },
    {
      "epoch": 3.3040361805614813,
      "grad_norm": 0.1929827332496643,
      "learning_rate": 1.6959638194385188e-05,
      "loss": 0.0022,
      "step": 38720
    },
    {
      "epoch": 3.3048894956907584,
      "grad_norm": 0.06771176308393478,
      "learning_rate": 1.6951105043092416e-05,
      "loss": 0.0015,
      "step": 38730
    },
    {
      "epoch": 3.305742810820036,
      "grad_norm": 0.04795967787504196,
      "learning_rate": 1.694257189179964e-05,
      "loss": 0.002,
      "step": 38740
    },
    {
      "epoch": 3.306596125949313,
      "grad_norm": 0.06317287683486938,
      "learning_rate": 1.693403874050687e-05,
      "loss": 0.0019,
      "step": 38750
    },
    {
      "epoch": 3.30744944107859,
      "grad_norm": 0.20897039771080017,
      "learning_rate": 1.69255055892141e-05,
      "loss": 0.0016,
      "step": 38760
    },
    {
      "epoch": 3.3083027562078677,
      "grad_norm": 0.11714936047792435,
      "learning_rate": 1.6916972437921324e-05,
      "loss": 0.0022,
      "step": 38770
    },
    {
      "epoch": 3.309156071337145,
      "grad_norm": 0.1506594568490982,
      "learning_rate": 1.6908439286628552e-05,
      "loss": 0.0022,
      "step": 38780
    },
    {
      "epoch": 3.310009386466422,
      "grad_norm": 0.17963862419128418,
      "learning_rate": 1.689990613533578e-05,
      "loss": 0.0019,
      "step": 38790
    },
    {
      "epoch": 3.310862701595699,
      "grad_norm": 0.4080515205860138,
      "learning_rate": 1.689137298404301e-05,
      "loss": 0.002,
      "step": 38800
    },
    {
      "epoch": 3.3117160167249766,
      "grad_norm": 0.23360095918178558,
      "learning_rate": 1.6882839832750234e-05,
      "loss": 0.002,
      "step": 38810
    },
    {
      "epoch": 3.3125693318542537,
      "grad_norm": 0.03782983496785164,
      "learning_rate": 1.6874306681457463e-05,
      "loss": 0.002,
      "step": 38820
    },
    {
      "epoch": 3.313422646983531,
      "grad_norm": 0.06464595347642899,
      "learning_rate": 1.686577353016469e-05,
      "loss": 0.0018,
      "step": 38830
    },
    {
      "epoch": 3.3142759621128084,
      "grad_norm": 0.13673578202724457,
      "learning_rate": 1.685724037887192e-05,
      "loss": 0.0018,
      "step": 38840
    },
    {
      "epoch": 3.3151292772420855,
      "grad_norm": 0.08877324312925339,
      "learning_rate": 1.6848707227579148e-05,
      "loss": 0.0021,
      "step": 38850
    },
    {
      "epoch": 3.3159825923713626,
      "grad_norm": 0.08125565201044083,
      "learning_rate": 1.6840174076286373e-05,
      "loss": 0.0013,
      "step": 38860
    },
    {
      "epoch": 3.31683590750064,
      "grad_norm": 0.17534096539020538,
      "learning_rate": 1.6831640924993598e-05,
      "loss": 0.002,
      "step": 38870
    },
    {
      "epoch": 3.3176892226299173,
      "grad_norm": 0.11961255222558975,
      "learning_rate": 1.6823107773700827e-05,
      "loss": 0.0015,
      "step": 38880
    },
    {
      "epoch": 3.3185425377591944,
      "grad_norm": 0.18060089647769928,
      "learning_rate": 1.6814574622408055e-05,
      "loss": 0.002,
      "step": 38890
    },
    {
      "epoch": 3.319395852888472,
      "grad_norm": 0.20324723422527313,
      "learning_rate": 1.6806041471115284e-05,
      "loss": 0.0022,
      "step": 38900
    },
    {
      "epoch": 3.320249168017749,
      "grad_norm": 0.24577926099300385,
      "learning_rate": 1.6797508319822512e-05,
      "loss": 0.002,
      "step": 38910
    },
    {
      "epoch": 3.321102483147026,
      "grad_norm": 0.23140741884708405,
      "learning_rate": 1.6788975168529737e-05,
      "loss": 0.0019,
      "step": 38920
    },
    {
      "epoch": 3.3219557982763033,
      "grad_norm": 0.15478579699993134,
      "learning_rate": 1.6780442017236966e-05,
      "loss": 0.0019,
      "step": 38930
    },
    {
      "epoch": 3.322809113405581,
      "grad_norm": 0.09099254757165909,
      "learning_rate": 1.6771908865944194e-05,
      "loss": 0.0019,
      "step": 38940
    },
    {
      "epoch": 3.323662428534858,
      "grad_norm": 0.286554753780365,
      "learning_rate": 1.6763375714651423e-05,
      "loss": 0.0022,
      "step": 38950
    },
    {
      "epoch": 3.324515743664135,
      "grad_norm": 0.2894477844238281,
      "learning_rate": 1.675484256335865e-05,
      "loss": 0.0024,
      "step": 38960
    },
    {
      "epoch": 3.325369058793412,
      "grad_norm": 0.17290975153446198,
      "learning_rate": 1.6746309412065876e-05,
      "loss": 0.0022,
      "step": 38970
    },
    {
      "epoch": 3.3262223739226897,
      "grad_norm": 0.09674473106861115,
      "learning_rate": 1.6737776260773105e-05,
      "loss": 0.002,
      "step": 38980
    },
    {
      "epoch": 3.327075689051967,
      "grad_norm": 0.15641583502292633,
      "learning_rate": 1.6729243109480333e-05,
      "loss": 0.0019,
      "step": 38990
    },
    {
      "epoch": 3.327929004181244,
      "grad_norm": 0.06791535019874573,
      "learning_rate": 1.6720709958187558e-05,
      "loss": 0.002,
      "step": 39000
    },
    {
      "epoch": 3.3287823193105215,
      "grad_norm": 0.13843366503715515,
      "learning_rate": 1.6712176806894787e-05,
      "loss": 0.0024,
      "step": 39010
    },
    {
      "epoch": 3.3296356344397986,
      "grad_norm": 0.09870471060276031,
      "learning_rate": 1.6703643655602015e-05,
      "loss": 0.0017,
      "step": 39020
    },
    {
      "epoch": 3.3304889495690757,
      "grad_norm": 0.0606057271361351,
      "learning_rate": 1.669511050430924e-05,
      "loss": 0.002,
      "step": 39030
    },
    {
      "epoch": 3.3313422646983533,
      "grad_norm": 0.22385381162166595,
      "learning_rate": 1.668657735301647e-05,
      "loss": 0.0027,
      "step": 39040
    },
    {
      "epoch": 3.3321955798276304,
      "grad_norm": 0.17470350861549377,
      "learning_rate": 1.6678044201723697e-05,
      "loss": 0.0017,
      "step": 39050
    },
    {
      "epoch": 3.3330488949569075,
      "grad_norm": 0.1195167750120163,
      "learning_rate": 1.6669511050430926e-05,
      "loss": 0.0019,
      "step": 39060
    },
    {
      "epoch": 3.333902210086185,
      "grad_norm": 0.2930220365524292,
      "learning_rate": 1.6660977899138154e-05,
      "loss": 0.0017,
      "step": 39070
    },
    {
      "epoch": 3.334755525215462,
      "grad_norm": 0.27169322967529297,
      "learning_rate": 1.665244474784538e-05,
      "loss": 0.0017,
      "step": 39080
    },
    {
      "epoch": 3.3356088403447393,
      "grad_norm": 0.041114989668130875,
      "learning_rate": 1.6643911596552608e-05,
      "loss": 0.0016,
      "step": 39090
    },
    {
      "epoch": 3.3364621554740164,
      "grad_norm": 0.06327951699495316,
      "learning_rate": 1.6635378445259836e-05,
      "loss": 0.0019,
      "step": 39100
    },
    {
      "epoch": 3.337315470603294,
      "grad_norm": 0.27708128094673157,
      "learning_rate": 1.6626845293967065e-05,
      "loss": 0.0021,
      "step": 39110
    },
    {
      "epoch": 3.338168785732571,
      "grad_norm": 0.19738997519016266,
      "learning_rate": 1.6618312142674293e-05,
      "loss": 0.0019,
      "step": 39120
    },
    {
      "epoch": 3.339022100861848,
      "grad_norm": 0.1553235501050949,
      "learning_rate": 1.6609778991381515e-05,
      "loss": 0.0024,
      "step": 39130
    },
    {
      "epoch": 3.3398754159911257,
      "grad_norm": 0.23057417571544647,
      "learning_rate": 1.6601245840088743e-05,
      "loss": 0.0022,
      "step": 39140
    },
    {
      "epoch": 3.340728731120403,
      "grad_norm": 0.045933663845062256,
      "learning_rate": 1.6592712688795972e-05,
      "loss": 0.002,
      "step": 39150
    },
    {
      "epoch": 3.34158204624968,
      "grad_norm": 0.21495039761066437,
      "learning_rate": 1.65841795375032e-05,
      "loss": 0.0016,
      "step": 39160
    },
    {
      "epoch": 3.342435361378957,
      "grad_norm": 0.21464784443378448,
      "learning_rate": 1.657564638621043e-05,
      "loss": 0.0022,
      "step": 39170
    },
    {
      "epoch": 3.3432886765082346,
      "grad_norm": 0.3093326985836029,
      "learning_rate": 1.6567113234917654e-05,
      "loss": 0.0017,
      "step": 39180
    },
    {
      "epoch": 3.3441419916375117,
      "grad_norm": 0.308390736579895,
      "learning_rate": 1.6558580083624882e-05,
      "loss": 0.002,
      "step": 39190
    },
    {
      "epoch": 3.344995306766789,
      "grad_norm": 0.06346834450960159,
      "learning_rate": 1.655004693233211e-05,
      "loss": 0.0019,
      "step": 39200
    },
    {
      "epoch": 3.3458486218960664,
      "grad_norm": 0.2782435417175293,
      "learning_rate": 1.654151378103934e-05,
      "loss": 0.002,
      "step": 39210
    },
    {
      "epoch": 3.3467019370253435,
      "grad_norm": 0.3600866496562958,
      "learning_rate": 1.6532980629746568e-05,
      "loss": 0.0021,
      "step": 39220
    },
    {
      "epoch": 3.3475552521546206,
      "grad_norm": 0.24165113270282745,
      "learning_rate": 1.6524447478453793e-05,
      "loss": 0.002,
      "step": 39230
    },
    {
      "epoch": 3.348408567283898,
      "grad_norm": 0.047298964112997055,
      "learning_rate": 1.651591432716102e-05,
      "loss": 0.002,
      "step": 39240
    },
    {
      "epoch": 3.3492618824131752,
      "grad_norm": 0.1797240823507309,
      "learning_rate": 1.650738117586825e-05,
      "loss": 0.0018,
      "step": 39250
    },
    {
      "epoch": 3.3501151975424523,
      "grad_norm": 0.19697852432727814,
      "learning_rate": 1.649884802457548e-05,
      "loss": 0.0023,
      "step": 39260
    },
    {
      "epoch": 3.35096851267173,
      "grad_norm": 0.11420845985412598,
      "learning_rate": 1.6490314873282704e-05,
      "loss": 0.0014,
      "step": 39270
    },
    {
      "epoch": 3.351821827801007,
      "grad_norm": 0.19559909403324127,
      "learning_rate": 1.6481781721989932e-05,
      "loss": 0.0017,
      "step": 39280
    },
    {
      "epoch": 3.352675142930284,
      "grad_norm": 0.03222707286477089,
      "learning_rate": 1.6473248570697157e-05,
      "loss": 0.0015,
      "step": 39290
    },
    {
      "epoch": 3.3535284580595612,
      "grad_norm": 0.21710942685604095,
      "learning_rate": 1.6464715419404386e-05,
      "loss": 0.0014,
      "step": 39300
    },
    {
      "epoch": 3.354381773188839,
      "grad_norm": 0.09267694503068924,
      "learning_rate": 1.6456182268111614e-05,
      "loss": 0.0019,
      "step": 39310
    },
    {
      "epoch": 3.355235088318116,
      "grad_norm": 0.15440250933170319,
      "learning_rate": 1.6447649116818843e-05,
      "loss": 0.0021,
      "step": 39320
    },
    {
      "epoch": 3.356088403447393,
      "grad_norm": 0.09889228641986847,
      "learning_rate": 1.643911596552607e-05,
      "loss": 0.0019,
      "step": 39330
    },
    {
      "epoch": 3.35694171857667,
      "grad_norm": 0.07316001504659653,
      "learning_rate": 1.6430582814233296e-05,
      "loss": 0.0019,
      "step": 39340
    },
    {
      "epoch": 3.3577950337059477,
      "grad_norm": 0.16104164719581604,
      "learning_rate": 1.6422049662940525e-05,
      "loss": 0.0021,
      "step": 39350
    },
    {
      "epoch": 3.358648348835225,
      "grad_norm": 0.3426528871059418,
      "learning_rate": 1.6413516511647753e-05,
      "loss": 0.0019,
      "step": 39360
    },
    {
      "epoch": 3.359501663964502,
      "grad_norm": 0.17424000799655914,
      "learning_rate": 1.640498336035498e-05,
      "loss": 0.002,
      "step": 39370
    },
    {
      "epoch": 3.3603549790937794,
      "grad_norm": 0.3090157210826874,
      "learning_rate": 1.639645020906221e-05,
      "loss": 0.0014,
      "step": 39380
    },
    {
      "epoch": 3.3612082942230566,
      "grad_norm": 0.12006674706935883,
      "learning_rate": 1.6387917057769435e-05,
      "loss": 0.002,
      "step": 39390
    },
    {
      "epoch": 3.3620616093523337,
      "grad_norm": 0.035855285823345184,
      "learning_rate": 1.637938390647666e-05,
      "loss": 0.0022,
      "step": 39400
    },
    {
      "epoch": 3.3629149244816112,
      "grad_norm": 0.13969935476779938,
      "learning_rate": 1.637085075518389e-05,
      "loss": 0.0022,
      "step": 39410
    },
    {
      "epoch": 3.3637682396108883,
      "grad_norm": 0.06230911612510681,
      "learning_rate": 1.6362317603891117e-05,
      "loss": 0.0018,
      "step": 39420
    },
    {
      "epoch": 3.3646215547401654,
      "grad_norm": 0.0325232557952404,
      "learning_rate": 1.6353784452598346e-05,
      "loss": 0.0014,
      "step": 39430
    },
    {
      "epoch": 3.365474869869443,
      "grad_norm": 0.12441254407167435,
      "learning_rate": 1.634525130130557e-05,
      "loss": 0.0015,
      "step": 39440
    },
    {
      "epoch": 3.36632818499872,
      "grad_norm": 0.18268954753875732,
      "learning_rate": 1.63367181500128e-05,
      "loss": 0.0021,
      "step": 39450
    },
    {
      "epoch": 3.367181500127997,
      "grad_norm": 0.1991916298866272,
      "learning_rate": 1.6328184998720028e-05,
      "loss": 0.0018,
      "step": 39460
    },
    {
      "epoch": 3.3680348152572743,
      "grad_norm": 0.12871383130550385,
      "learning_rate": 1.6319651847427256e-05,
      "loss": 0.0024,
      "step": 39470
    },
    {
      "epoch": 3.368888130386552,
      "grad_norm": 0.1785036027431488,
      "learning_rate": 1.6311118696134485e-05,
      "loss": 0.002,
      "step": 39480
    },
    {
      "epoch": 3.369741445515829,
      "grad_norm": 0.2750619649887085,
      "learning_rate": 1.630258554484171e-05,
      "loss": 0.0016,
      "step": 39490
    },
    {
      "epoch": 3.370594760645106,
      "grad_norm": 0.09385190904140472,
      "learning_rate": 1.629405239354894e-05,
      "loss": 0.0022,
      "step": 39500
    },
    {
      "epoch": 3.3714480757743837,
      "grad_norm": 0.19762271642684937,
      "learning_rate": 1.6285519242256167e-05,
      "loss": 0.0024,
      "step": 39510
    },
    {
      "epoch": 3.3723013909036608,
      "grad_norm": 0.3281848728656769,
      "learning_rate": 1.6276986090963395e-05,
      "loss": 0.0016,
      "step": 39520
    },
    {
      "epoch": 3.373154706032938,
      "grad_norm": 0.429098516702652,
      "learning_rate": 1.626845293967062e-05,
      "loss": 0.0023,
      "step": 39530
    },
    {
      "epoch": 3.374008021162215,
      "grad_norm": 0.11466287076473236,
      "learning_rate": 1.625991978837785e-05,
      "loss": 0.0016,
      "step": 39540
    },
    {
      "epoch": 3.3748613362914925,
      "grad_norm": 0.2738663852214813,
      "learning_rate": 1.6251386637085074e-05,
      "loss": 0.0017,
      "step": 39550
    },
    {
      "epoch": 3.3757146514207697,
      "grad_norm": 0.21358633041381836,
      "learning_rate": 1.6242853485792302e-05,
      "loss": 0.0019,
      "step": 39560
    },
    {
      "epoch": 3.3765679665500468,
      "grad_norm": 0.31537026166915894,
      "learning_rate": 1.623432033449953e-05,
      "loss": 0.0021,
      "step": 39570
    },
    {
      "epoch": 3.3774212816793243,
      "grad_norm": 0.17966412007808685,
      "learning_rate": 1.622578718320676e-05,
      "loss": 0.0014,
      "step": 39580
    },
    {
      "epoch": 3.3782745968086014,
      "grad_norm": 0.07849105447530746,
      "learning_rate": 1.6217254031913988e-05,
      "loss": 0.002,
      "step": 39590
    },
    {
      "epoch": 3.3791279119378785,
      "grad_norm": 0.1468925178050995,
      "learning_rate": 1.6208720880621213e-05,
      "loss": 0.0021,
      "step": 39600
    },
    {
      "epoch": 3.379981227067156,
      "grad_norm": 0.1920105218887329,
      "learning_rate": 1.620018772932844e-05,
      "loss": 0.0018,
      "step": 39610
    },
    {
      "epoch": 3.380834542196433,
      "grad_norm": 0.2260906994342804,
      "learning_rate": 1.619165457803567e-05,
      "loss": 0.0021,
      "step": 39620
    },
    {
      "epoch": 3.3816878573257103,
      "grad_norm": 0.22787588834762573,
      "learning_rate": 1.61831214267429e-05,
      "loss": 0.0019,
      "step": 39630
    },
    {
      "epoch": 3.382541172454988,
      "grad_norm": 0.3732689619064331,
      "learning_rate": 1.6174588275450127e-05,
      "loss": 0.0019,
      "step": 39640
    },
    {
      "epoch": 3.383394487584265,
      "grad_norm": 0.2640458941459656,
      "learning_rate": 1.6166055124157352e-05,
      "loss": 0.0022,
      "step": 39650
    },
    {
      "epoch": 3.384247802713542,
      "grad_norm": 0.3401327431201935,
      "learning_rate": 1.615752197286458e-05,
      "loss": 0.0016,
      "step": 39660
    },
    {
      "epoch": 3.385101117842819,
      "grad_norm": 0.15711471438407898,
      "learning_rate": 1.6148988821571806e-05,
      "loss": 0.0022,
      "step": 39670
    },
    {
      "epoch": 3.3859544329720968,
      "grad_norm": 0.1881003975868225,
      "learning_rate": 1.6140455670279034e-05,
      "loss": 0.0019,
      "step": 39680
    },
    {
      "epoch": 3.386807748101374,
      "grad_norm": 0.1919092833995819,
      "learning_rate": 1.6131922518986263e-05,
      "loss": 0.0019,
      "step": 39690
    },
    {
      "epoch": 3.387661063230651,
      "grad_norm": 0.12047925591468811,
      "learning_rate": 1.612338936769349e-05,
      "loss": 0.002,
      "step": 39700
    },
    {
      "epoch": 3.388514378359928,
      "grad_norm": 0.2807557284832001,
      "learning_rate": 1.6114856216400716e-05,
      "loss": 0.0019,
      "step": 39710
    },
    {
      "epoch": 3.3893676934892056,
      "grad_norm": 0.15929855406284332,
      "learning_rate": 1.6106323065107945e-05,
      "loss": 0.0022,
      "step": 39720
    },
    {
      "epoch": 3.3902210086184827,
      "grad_norm": 0.18155571818351746,
      "learning_rate": 1.6097789913815173e-05,
      "loss": 0.0021,
      "step": 39730
    },
    {
      "epoch": 3.39107432374776,
      "grad_norm": 0.1463010460138321,
      "learning_rate": 1.60892567625224e-05,
      "loss": 0.0018,
      "step": 39740
    },
    {
      "epoch": 3.3919276388770374,
      "grad_norm": 0.1169990822672844,
      "learning_rate": 1.6080723611229627e-05,
      "loss": 0.0018,
      "step": 39750
    },
    {
      "epoch": 3.3927809540063145,
      "grad_norm": 0.061738088726997375,
      "learning_rate": 1.6072190459936855e-05,
      "loss": 0.0014,
      "step": 39760
    },
    {
      "epoch": 3.3936342691355916,
      "grad_norm": 0.0686836987733841,
      "learning_rate": 1.6063657308644084e-05,
      "loss": 0.0018,
      "step": 39770
    },
    {
      "epoch": 3.394487584264869,
      "grad_norm": 0.07964672148227692,
      "learning_rate": 1.6055124157351312e-05,
      "loss": 0.0015,
      "step": 39780
    },
    {
      "epoch": 3.3953408993941463,
      "grad_norm": 0.15142053365707397,
      "learning_rate": 1.604659100605854e-05,
      "loss": 0.0024,
      "step": 39790
    },
    {
      "epoch": 3.3961942145234234,
      "grad_norm": 0.25528669357299805,
      "learning_rate": 1.6038057854765766e-05,
      "loss": 0.0022,
      "step": 39800
    },
    {
      "epoch": 3.397047529652701,
      "grad_norm": 0.10112055391073227,
      "learning_rate": 1.602952470347299e-05,
      "loss": 0.002,
      "step": 39810
    },
    {
      "epoch": 3.397900844781978,
      "grad_norm": 0.06142936274409294,
      "learning_rate": 1.602099155218022e-05,
      "loss": 0.0018,
      "step": 39820
    },
    {
      "epoch": 3.398754159911255,
      "grad_norm": 0.10223054140806198,
      "learning_rate": 1.6012458400887448e-05,
      "loss": 0.0016,
      "step": 39830
    },
    {
      "epoch": 3.3996074750405323,
      "grad_norm": 0.07877413183450699,
      "learning_rate": 1.6003925249594676e-05,
      "loss": 0.0016,
      "step": 39840
    },
    {
      "epoch": 3.40046079016981,
      "grad_norm": 0.16143281757831573,
      "learning_rate": 1.5995392098301905e-05,
      "loss": 0.0018,
      "step": 39850
    },
    {
      "epoch": 3.401314105299087,
      "grad_norm": 0.3135577440261841,
      "learning_rate": 1.598685894700913e-05,
      "loss": 0.0017,
      "step": 39860
    },
    {
      "epoch": 3.402167420428364,
      "grad_norm": 0.07781045138835907,
      "learning_rate": 1.5978325795716358e-05,
      "loss": 0.0024,
      "step": 39870
    },
    {
      "epoch": 3.4030207355576416,
      "grad_norm": 0.240535169839859,
      "learning_rate": 1.5969792644423587e-05,
      "loss": 0.0021,
      "step": 39880
    },
    {
      "epoch": 3.4038740506869187,
      "grad_norm": 0.24991895258426666,
      "learning_rate": 1.5961259493130815e-05,
      "loss": 0.0021,
      "step": 39890
    },
    {
      "epoch": 3.404727365816196,
      "grad_norm": 0.4345472753047943,
      "learning_rate": 1.5952726341838044e-05,
      "loss": 0.0017,
      "step": 39900
    },
    {
      "epoch": 3.405580680945473,
      "grad_norm": 0.08268910646438599,
      "learning_rate": 1.594419319054527e-05,
      "loss": 0.0014,
      "step": 39910
    },
    {
      "epoch": 3.4064339960747505,
      "grad_norm": 0.3270184099674225,
      "learning_rate": 1.5935660039252497e-05,
      "loss": 0.0016,
      "step": 39920
    },
    {
      "epoch": 3.4072873112040276,
      "grad_norm": 0.06001961603760719,
      "learning_rate": 1.5927126887959722e-05,
      "loss": 0.0014,
      "step": 39930
    },
    {
      "epoch": 3.4081406263333047,
      "grad_norm": 0.08111382275819778,
      "learning_rate": 1.591859373666695e-05,
      "loss": 0.0021,
      "step": 39940
    },
    {
      "epoch": 3.4089939414625823,
      "grad_norm": 0.18952742218971252,
      "learning_rate": 1.591006058537418e-05,
      "loss": 0.0022,
      "step": 39950
    },
    {
      "epoch": 3.4098472565918594,
      "grad_norm": 0.039451636373996735,
      "learning_rate": 1.5901527434081408e-05,
      "loss": 0.0017,
      "step": 39960
    },
    {
      "epoch": 3.4107005717211365,
      "grad_norm": 0.19135895371437073,
      "learning_rate": 1.5892994282788633e-05,
      "loss": 0.0018,
      "step": 39970
    },
    {
      "epoch": 3.411553886850414,
      "grad_norm": 0.2782607972621918,
      "learning_rate": 1.588446113149586e-05,
      "loss": 0.0016,
      "step": 39980
    },
    {
      "epoch": 3.412407201979691,
      "grad_norm": 0.2103203982114792,
      "learning_rate": 1.587592798020309e-05,
      "loss": 0.0021,
      "step": 39990
    },
    {
      "epoch": 3.4132605171089683,
      "grad_norm": 0.08302810788154602,
      "learning_rate": 1.586739482891032e-05,
      "loss": 0.0018,
      "step": 40000
    },
    {
      "epoch": 3.414113832238246,
      "grad_norm": 0.37851014733314514,
      "learning_rate": 1.5858861677617547e-05,
      "loss": 0.0016,
      "step": 40010
    },
    {
      "epoch": 3.414967147367523,
      "grad_norm": 0.28676798939704895,
      "learning_rate": 1.5850328526324772e-05,
      "loss": 0.0021,
      "step": 40020
    },
    {
      "epoch": 3.4158204624968,
      "grad_norm": 0.114780493080616,
      "learning_rate": 1.5841795375032e-05,
      "loss": 0.0022,
      "step": 40030
    },
    {
      "epoch": 3.416673777626077,
      "grad_norm": 0.3646046221256256,
      "learning_rate": 1.583326222373923e-05,
      "loss": 0.0014,
      "step": 40040
    },
    {
      "epoch": 3.4175270927553547,
      "grad_norm": 0.18417540192604065,
      "learning_rate": 1.5824729072446457e-05,
      "loss": 0.0025,
      "step": 40050
    },
    {
      "epoch": 3.418380407884632,
      "grad_norm": 0.03237943723797798,
      "learning_rate": 1.5816195921153682e-05,
      "loss": 0.002,
      "step": 40060
    },
    {
      "epoch": 3.419233723013909,
      "grad_norm": 0.2912272810935974,
      "learning_rate": 1.5807662769860908e-05,
      "loss": 0.0015,
      "step": 40070
    },
    {
      "epoch": 3.420087038143186,
      "grad_norm": 0.24532155692577362,
      "learning_rate": 1.5799129618568136e-05,
      "loss": 0.0025,
      "step": 40080
    },
    {
      "epoch": 3.4209403532724636,
      "grad_norm": 0.20924650132656097,
      "learning_rate": 1.5790596467275365e-05,
      "loss": 0.0021,
      "step": 40090
    },
    {
      "epoch": 3.4217936684017407,
      "grad_norm": 0.3610862195491791,
      "learning_rate": 1.5782063315982593e-05,
      "loss": 0.0029,
      "step": 40100
    },
    {
      "epoch": 3.422646983531018,
      "grad_norm": 0.16634716093540192,
      "learning_rate": 1.577353016468982e-05,
      "loss": 0.0019,
      "step": 40110
    },
    {
      "epoch": 3.4235002986602954,
      "grad_norm": 0.14274127781391144,
      "learning_rate": 1.5764997013397047e-05,
      "loss": 0.0021,
      "step": 40120
    },
    {
      "epoch": 3.4243536137895725,
      "grad_norm": 0.10443007200956345,
      "learning_rate": 1.5756463862104275e-05,
      "loss": 0.0022,
      "step": 40130
    },
    {
      "epoch": 3.4252069289188496,
      "grad_norm": 0.30122238397598267,
      "learning_rate": 1.5747930710811504e-05,
      "loss": 0.0019,
      "step": 40140
    },
    {
      "epoch": 3.426060244048127,
      "grad_norm": 0.04525376111268997,
      "learning_rate": 1.5739397559518732e-05,
      "loss": 0.0019,
      "step": 40150
    },
    {
      "epoch": 3.4269135591774043,
      "grad_norm": 0.19868673384189606,
      "learning_rate": 1.573086440822596e-05,
      "loss": 0.0023,
      "step": 40160
    },
    {
      "epoch": 3.4277668743066814,
      "grad_norm": 0.15450887382030487,
      "learning_rate": 1.5722331256933186e-05,
      "loss": 0.0016,
      "step": 40170
    },
    {
      "epoch": 3.428620189435959,
      "grad_norm": 0.14438645541667938,
      "learning_rate": 1.5713798105640414e-05,
      "loss": 0.0019,
      "step": 40180
    },
    {
      "epoch": 3.429473504565236,
      "grad_norm": 0.06633541733026505,
      "learning_rate": 1.5705264954347643e-05,
      "loss": 0.0018,
      "step": 40190
    },
    {
      "epoch": 3.430326819694513,
      "grad_norm": 0.08165499567985535,
      "learning_rate": 1.5696731803054868e-05,
      "loss": 0.0017,
      "step": 40200
    },
    {
      "epoch": 3.4311801348237903,
      "grad_norm": 0.18158498406410217,
      "learning_rate": 1.5688198651762096e-05,
      "loss": 0.0017,
      "step": 40210
    },
    {
      "epoch": 3.432033449953068,
      "grad_norm": 0.03748001530766487,
      "learning_rate": 1.5679665500469325e-05,
      "loss": 0.0023,
      "step": 40220
    },
    {
      "epoch": 3.432886765082345,
      "grad_norm": 0.12213567644357681,
      "learning_rate": 1.567113234917655e-05,
      "loss": 0.0017,
      "step": 40230
    },
    {
      "epoch": 3.433740080211622,
      "grad_norm": 0.11839397251605988,
      "learning_rate": 1.5662599197883778e-05,
      "loss": 0.0016,
      "step": 40240
    },
    {
      "epoch": 3.4345933953408996,
      "grad_norm": 0.23112620413303375,
      "learning_rate": 1.5654066046591007e-05,
      "loss": 0.0014,
      "step": 40250
    },
    {
      "epoch": 3.4354467104701767,
      "grad_norm": 0.06167535111308098,
      "learning_rate": 1.5645532895298235e-05,
      "loss": 0.0022,
      "step": 40260
    },
    {
      "epoch": 3.436300025599454,
      "grad_norm": 0.25301408767700195,
      "learning_rate": 1.5636999744005464e-05,
      "loss": 0.0024,
      "step": 40270
    },
    {
      "epoch": 3.437153340728731,
      "grad_norm": 0.057078395038843155,
      "learning_rate": 1.562846659271269e-05,
      "loss": 0.0023,
      "step": 40280
    },
    {
      "epoch": 3.4380066558580085,
      "grad_norm": 0.0521286278963089,
      "learning_rate": 1.5619933441419917e-05,
      "loss": 0.0022,
      "step": 40290
    },
    {
      "epoch": 3.4388599709872856,
      "grad_norm": 0.0894477367401123,
      "learning_rate": 1.5611400290127146e-05,
      "loss": 0.0023,
      "step": 40300
    },
    {
      "epoch": 3.4397132861165627,
      "grad_norm": 0.20495127141475677,
      "learning_rate": 1.5602867138834374e-05,
      "loss": 0.002,
      "step": 40310
    },
    {
      "epoch": 3.4405666012458402,
      "grad_norm": 0.06809065490961075,
      "learning_rate": 1.5594333987541603e-05,
      "loss": 0.0018,
      "step": 40320
    },
    {
      "epoch": 3.4414199163751173,
      "grad_norm": 0.085232675075531,
      "learning_rate": 1.5585800836248828e-05,
      "loss": 0.0015,
      "step": 40330
    },
    {
      "epoch": 3.4422732315043945,
      "grad_norm": 0.06602764129638672,
      "learning_rate": 1.5577267684956053e-05,
      "loss": 0.0021,
      "step": 40340
    },
    {
      "epoch": 3.443126546633672,
      "grad_norm": 0.1641468107700348,
      "learning_rate": 1.556873453366328e-05,
      "loss": 0.0017,
      "step": 40350
    },
    {
      "epoch": 3.443979861762949,
      "grad_norm": 0.1438147872686386,
      "learning_rate": 1.556020138237051e-05,
      "loss": 0.0021,
      "step": 40360
    },
    {
      "epoch": 3.4448331768922262,
      "grad_norm": 0.17725370824337006,
      "learning_rate": 1.555166823107774e-05,
      "loss": 0.0022,
      "step": 40370
    },
    {
      "epoch": 3.445686492021504,
      "grad_norm": 0.07846148312091827,
      "learning_rate": 1.5543135079784963e-05,
      "loss": 0.0016,
      "step": 40380
    },
    {
      "epoch": 3.446539807150781,
      "grad_norm": 0.07632458955049515,
      "learning_rate": 1.5534601928492192e-05,
      "loss": 0.002,
      "step": 40390
    },
    {
      "epoch": 3.447393122280058,
      "grad_norm": 0.26307088136672974,
      "learning_rate": 1.552606877719942e-05,
      "loss": 0.0018,
      "step": 40400
    },
    {
      "epoch": 3.448246437409335,
      "grad_norm": 0.0828285664319992,
      "learning_rate": 1.551753562590665e-05,
      "loss": 0.0018,
      "step": 40410
    },
    {
      "epoch": 3.4490997525386127,
      "grad_norm": 0.2275446504354477,
      "learning_rate": 1.5509002474613877e-05,
      "loss": 0.0017,
      "step": 40420
    },
    {
      "epoch": 3.44995306766789,
      "grad_norm": 0.2902159094810486,
      "learning_rate": 1.5500469323321102e-05,
      "loss": 0.0017,
      "step": 40430
    },
    {
      "epoch": 3.450806382797167,
      "grad_norm": 0.221410870552063,
      "learning_rate": 1.549193617202833e-05,
      "loss": 0.0018,
      "step": 40440
    },
    {
      "epoch": 3.451659697926444,
      "grad_norm": 0.17700526118278503,
      "learning_rate": 1.548340302073556e-05,
      "loss": 0.0024,
      "step": 40450
    },
    {
      "epoch": 3.4525130130557216,
      "grad_norm": 0.42739424109458923,
      "learning_rate": 1.5474869869442784e-05,
      "loss": 0.0016,
      "step": 40460
    },
    {
      "epoch": 3.4533663281849987,
      "grad_norm": 0.05447961017489433,
      "learning_rate": 1.5466336718150013e-05,
      "loss": 0.0023,
      "step": 40470
    },
    {
      "epoch": 3.454219643314276,
      "grad_norm": 0.4000526964664459,
      "learning_rate": 1.545780356685724e-05,
      "loss": 0.0016,
      "step": 40480
    },
    {
      "epoch": 3.4550729584435533,
      "grad_norm": 0.24851305782794952,
      "learning_rate": 1.5449270415564467e-05,
      "loss": 0.0023,
      "step": 40490
    },
    {
      "epoch": 3.4559262735728304,
      "grad_norm": 0.030770964920520782,
      "learning_rate": 1.5440737264271695e-05,
      "loss": 0.0024,
      "step": 40500
    },
    {
      "epoch": 3.4567795887021076,
      "grad_norm": 0.2696317732334137,
      "learning_rate": 1.5432204112978924e-05,
      "loss": 0.0015,
      "step": 40510
    },
    {
      "epoch": 3.457632903831385,
      "grad_norm": 0.06424054503440857,
      "learning_rate": 1.5423670961686152e-05,
      "loss": 0.0019,
      "step": 40520
    },
    {
      "epoch": 3.458486218960662,
      "grad_norm": 0.13865876197814941,
      "learning_rate": 1.541513781039338e-05,
      "loss": 0.0018,
      "step": 40530
    },
    {
      "epoch": 3.4593395340899393,
      "grad_norm": 0.23368878662586212,
      "learning_rate": 1.5406604659100606e-05,
      "loss": 0.0019,
      "step": 40540
    },
    {
      "epoch": 3.460192849219217,
      "grad_norm": 0.2638118267059326,
      "learning_rate": 1.5398071507807834e-05,
      "loss": 0.0017,
      "step": 40550
    },
    {
      "epoch": 3.461046164348494,
      "grad_norm": 0.19260966777801514,
      "learning_rate": 1.5389538356515063e-05,
      "loss": 0.0016,
      "step": 40560
    },
    {
      "epoch": 3.461899479477771,
      "grad_norm": 0.19348260760307312,
      "learning_rate": 1.538100520522229e-05,
      "loss": 0.0023,
      "step": 40570
    },
    {
      "epoch": 3.462752794607048,
      "grad_norm": 0.14126725494861603,
      "learning_rate": 1.537247205392952e-05,
      "loss": 0.0016,
      "step": 40580
    },
    {
      "epoch": 3.4636061097363258,
      "grad_norm": 0.12373317778110504,
      "learning_rate": 1.5363938902636745e-05,
      "loss": 0.0018,
      "step": 40590
    },
    {
      "epoch": 3.464459424865603,
      "grad_norm": 0.051585882902145386,
      "learning_rate": 1.535540575134397e-05,
      "loss": 0.0017,
      "step": 40600
    },
    {
      "epoch": 3.46531273999488,
      "grad_norm": 0.14734257757663727,
      "learning_rate": 1.5346872600051198e-05,
      "loss": 0.0024,
      "step": 40610
    },
    {
      "epoch": 3.4661660551241575,
      "grad_norm": 0.2694825530052185,
      "learning_rate": 1.5338339448758427e-05,
      "loss": 0.0018,
      "step": 40620
    },
    {
      "epoch": 3.4670193702534347,
      "grad_norm": 0.056008562445640564,
      "learning_rate": 1.5329806297465655e-05,
      "loss": 0.0021,
      "step": 40630
    },
    {
      "epoch": 3.4678726853827118,
      "grad_norm": 0.1408611238002777,
      "learning_rate": 1.5321273146172884e-05,
      "loss": 0.0022,
      "step": 40640
    },
    {
      "epoch": 3.468726000511989,
      "grad_norm": 0.127539724111557,
      "learning_rate": 1.531273999488011e-05,
      "loss": 0.0015,
      "step": 40650
    },
    {
      "epoch": 3.4695793156412664,
      "grad_norm": 0.07539939880371094,
      "learning_rate": 1.5304206843587337e-05,
      "loss": 0.0018,
      "step": 40660
    },
    {
      "epoch": 3.4704326307705435,
      "grad_norm": 0.26733699440956116,
      "learning_rate": 1.5295673692294566e-05,
      "loss": 0.0017,
      "step": 40670
    },
    {
      "epoch": 3.4712859458998206,
      "grad_norm": 0.15355010330677032,
      "learning_rate": 1.5287140541001794e-05,
      "loss": 0.0023,
      "step": 40680
    },
    {
      "epoch": 3.472139261029098,
      "grad_norm": 0.11960230022668839,
      "learning_rate": 1.5278607389709023e-05,
      "loss": 0.0023,
      "step": 40690
    },
    {
      "epoch": 3.4729925761583753,
      "grad_norm": 0.07195686548948288,
      "learning_rate": 1.5270074238416248e-05,
      "loss": 0.0022,
      "step": 40700
    },
    {
      "epoch": 3.4738458912876524,
      "grad_norm": 0.25909778475761414,
      "learning_rate": 1.5261541087123476e-05,
      "loss": 0.0022,
      "step": 40710
    },
    {
      "epoch": 3.47469920641693,
      "grad_norm": 0.1801573634147644,
      "learning_rate": 1.5253007935830705e-05,
      "loss": 0.0019,
      "step": 40720
    },
    {
      "epoch": 3.475552521546207,
      "grad_norm": 0.08688674867153168,
      "learning_rate": 1.524447478453793e-05,
      "loss": 0.0025,
      "step": 40730
    },
    {
      "epoch": 3.476405836675484,
      "grad_norm": 0.15929670631885529,
      "learning_rate": 1.5235941633245157e-05,
      "loss": 0.0021,
      "step": 40740
    },
    {
      "epoch": 3.4772591518047613,
      "grad_norm": 0.2163393199443817,
      "learning_rate": 1.5227408481952385e-05,
      "loss": 0.0016,
      "step": 40750
    },
    {
      "epoch": 3.478112466934039,
      "grad_norm": 0.21916937828063965,
      "learning_rate": 1.5218875330659612e-05,
      "loss": 0.0027,
      "step": 40760
    },
    {
      "epoch": 3.478965782063316,
      "grad_norm": 0.4355003833770752,
      "learning_rate": 1.521034217936684e-05,
      "loss": 0.0019,
      "step": 40770
    },
    {
      "epoch": 3.479819097192593,
      "grad_norm": 0.0795971006155014,
      "learning_rate": 1.5201809028074069e-05,
      "loss": 0.0014,
      "step": 40780
    },
    {
      "epoch": 3.4806724123218706,
      "grad_norm": 0.35990607738494873,
      "learning_rate": 1.5193275876781296e-05,
      "loss": 0.0018,
      "step": 40790
    },
    {
      "epoch": 3.4815257274511477,
      "grad_norm": 0.07922740280628204,
      "learning_rate": 1.5184742725488524e-05,
      "loss": 0.002,
      "step": 40800
    },
    {
      "epoch": 3.482379042580425,
      "grad_norm": 0.037687208503484726,
      "learning_rate": 1.5176209574195751e-05,
      "loss": 0.0022,
      "step": 40810
    },
    {
      "epoch": 3.483232357709702,
      "grad_norm": 0.25040560960769653,
      "learning_rate": 1.516767642290298e-05,
      "loss": 0.0019,
      "step": 40820
    },
    {
      "epoch": 3.4840856728389795,
      "grad_norm": 0.3733783960342407,
      "learning_rate": 1.5159143271610208e-05,
      "loss": 0.0021,
      "step": 40830
    },
    {
      "epoch": 3.4849389879682566,
      "grad_norm": 0.031441133469343185,
      "learning_rate": 1.5150610120317435e-05,
      "loss": 0.002,
      "step": 40840
    },
    {
      "epoch": 3.4857923030975337,
      "grad_norm": 0.13398824632167816,
      "learning_rate": 1.5142076969024663e-05,
      "loss": 0.0015,
      "step": 40850
    },
    {
      "epoch": 3.4866456182268113,
      "grad_norm": 0.14682447910308838,
      "learning_rate": 1.5133543817731888e-05,
      "loss": 0.0025,
      "step": 40860
    },
    {
      "epoch": 3.4874989333560884,
      "grad_norm": 0.2596394717693329,
      "learning_rate": 1.5125010666439115e-05,
      "loss": 0.0017,
      "step": 40870
    },
    {
      "epoch": 3.4883522484853655,
      "grad_norm": 0.2582031190395355,
      "learning_rate": 1.5116477515146343e-05,
      "loss": 0.0018,
      "step": 40880
    },
    {
      "epoch": 3.489205563614643,
      "grad_norm": 0.21227596700191498,
      "learning_rate": 1.5107944363853572e-05,
      "loss": 0.0019,
      "step": 40890
    },
    {
      "epoch": 3.49005887874392,
      "grad_norm": 0.22808022797107697,
      "learning_rate": 1.5099411212560799e-05,
      "loss": 0.0014,
      "step": 40900
    },
    {
      "epoch": 3.4909121938731973,
      "grad_norm": 0.18068064749240875,
      "learning_rate": 1.5090878061268027e-05,
      "loss": 0.0018,
      "step": 40910
    },
    {
      "epoch": 3.491765509002475,
      "grad_norm": 0.25010091066360474,
      "learning_rate": 1.5082344909975254e-05,
      "loss": 0.0014,
      "step": 40920
    },
    {
      "epoch": 3.492618824131752,
      "grad_norm": 0.23024879395961761,
      "learning_rate": 1.5073811758682482e-05,
      "loss": 0.0025,
      "step": 40930
    },
    {
      "epoch": 3.493472139261029,
      "grad_norm": 0.2997528314590454,
      "learning_rate": 1.506527860738971e-05,
      "loss": 0.0017,
      "step": 40940
    },
    {
      "epoch": 3.494325454390306,
      "grad_norm": 0.12974654138088226,
      "learning_rate": 1.5056745456096938e-05,
      "loss": 0.002,
      "step": 40950
    },
    {
      "epoch": 3.4951787695195837,
      "grad_norm": 0.2541626989841461,
      "learning_rate": 1.5048212304804166e-05,
      "loss": 0.0019,
      "step": 40960
    },
    {
      "epoch": 3.496032084648861,
      "grad_norm": 0.042459532618522644,
      "learning_rate": 1.5039679153511393e-05,
      "loss": 0.0026,
      "step": 40970
    },
    {
      "epoch": 3.496885399778138,
      "grad_norm": 0.09745338559150696,
      "learning_rate": 1.5031146002218622e-05,
      "loss": 0.0019,
      "step": 40980
    },
    {
      "epoch": 3.4977387149074155,
      "grad_norm": 0.19047483801841736,
      "learning_rate": 1.5022612850925847e-05,
      "loss": 0.0018,
      "step": 40990
    },
    {
      "epoch": 3.4985920300366926,
      "grad_norm": 0.044392988085746765,
      "learning_rate": 1.5014079699633073e-05,
      "loss": 0.0021,
      "step": 41000
    },
    {
      "epoch": 3.4994453451659697,
      "grad_norm": 0.29442548751831055,
      "learning_rate": 1.5005546548340302e-05,
      "loss": 0.0022,
      "step": 41010
    },
    {
      "epoch": 3.500298660295247,
      "grad_norm": 0.3992565870285034,
      "learning_rate": 1.499701339704753e-05,
      "loss": 0.002,
      "step": 41020
    },
    {
      "epoch": 3.5011519754245244,
      "grad_norm": 0.04300787299871445,
      "learning_rate": 1.4988480245754757e-05,
      "loss": 0.0019,
      "step": 41030
    },
    {
      "epoch": 3.5020052905538015,
      "grad_norm": 0.097285695374012,
      "learning_rate": 1.4979947094461986e-05,
      "loss": 0.0017,
      "step": 41040
    },
    {
      "epoch": 3.5028586056830786,
      "grad_norm": 0.19104917347431183,
      "learning_rate": 1.4971413943169212e-05,
      "loss": 0.0018,
      "step": 41050
    },
    {
      "epoch": 3.503711920812356,
      "grad_norm": 0.20174849033355713,
      "learning_rate": 1.4962880791876441e-05,
      "loss": 0.0019,
      "step": 41060
    },
    {
      "epoch": 3.5045652359416333,
      "grad_norm": 0.23998641967773438,
      "learning_rate": 1.495434764058367e-05,
      "loss": 0.0021,
      "step": 41070
    },
    {
      "epoch": 3.5054185510709104,
      "grad_norm": 0.22219955921173096,
      "learning_rate": 1.4945814489290896e-05,
      "loss": 0.0023,
      "step": 41080
    },
    {
      "epoch": 3.506271866200188,
      "grad_norm": 0.11803579330444336,
      "learning_rate": 1.4937281337998125e-05,
      "loss": 0.0015,
      "step": 41090
    },
    {
      "epoch": 3.507125181329465,
      "grad_norm": 0.14950059354305267,
      "learning_rate": 1.4928748186705351e-05,
      "loss": 0.0017,
      "step": 41100
    },
    {
      "epoch": 3.507978496458742,
      "grad_norm": 0.14400210976600647,
      "learning_rate": 1.492021503541258e-05,
      "loss": 0.0022,
      "step": 41110
    },
    {
      "epoch": 3.5088318115880197,
      "grad_norm": 0.13046535849571228,
      "learning_rate": 1.4911681884119807e-05,
      "loss": 0.0017,
      "step": 41120
    },
    {
      "epoch": 3.509685126717297,
      "grad_norm": 0.30040374398231506,
      "learning_rate": 1.4903148732827032e-05,
      "loss": 0.0019,
      "step": 41130
    },
    {
      "epoch": 3.510538441846574,
      "grad_norm": 0.07456901669502258,
      "learning_rate": 1.489461558153426e-05,
      "loss": 0.0022,
      "step": 41140
    },
    {
      "epoch": 3.511391756975851,
      "grad_norm": 0.08166498690843582,
      "learning_rate": 1.4886082430241489e-05,
      "loss": 0.0018,
      "step": 41150
    },
    {
      "epoch": 3.512245072105128,
      "grad_norm": 0.14663347601890564,
      "learning_rate": 1.4877549278948716e-05,
      "loss": 0.0017,
      "step": 41160
    },
    {
      "epoch": 3.5130983872344057,
      "grad_norm": 0.12616603076457977,
      "learning_rate": 1.4869016127655944e-05,
      "loss": 0.0019,
      "step": 41170
    },
    {
      "epoch": 3.513951702363683,
      "grad_norm": 0.15757176280021667,
      "learning_rate": 1.486048297636317e-05,
      "loss": 0.0024,
      "step": 41180
    },
    {
      "epoch": 3.51480501749296,
      "grad_norm": 0.07261555641889572,
      "learning_rate": 1.48519498250704e-05,
      "loss": 0.0024,
      "step": 41190
    },
    {
      "epoch": 3.5156583326222375,
      "grad_norm": 0.06358157843351364,
      "learning_rate": 1.4843416673777628e-05,
      "loss": 0.0016,
      "step": 41200
    },
    {
      "epoch": 3.5165116477515146,
      "grad_norm": 0.19656315445899963,
      "learning_rate": 1.4834883522484855e-05,
      "loss": 0.002,
      "step": 41210
    },
    {
      "epoch": 3.5173649628807917,
      "grad_norm": 0.17601604759693146,
      "learning_rate": 1.4826350371192083e-05,
      "loss": 0.0016,
      "step": 41220
    },
    {
      "epoch": 3.5182182780100693,
      "grad_norm": 0.05714885890483856,
      "learning_rate": 1.481781721989931e-05,
      "loss": 0.0015,
      "step": 41230
    },
    {
      "epoch": 3.5190715931393464,
      "grad_norm": 0.1527993232011795,
      "learning_rate": 1.4809284068606538e-05,
      "loss": 0.0014,
      "step": 41240
    },
    {
      "epoch": 3.5199249082686235,
      "grad_norm": 0.2291661649942398,
      "learning_rate": 1.4800750917313767e-05,
      "loss": 0.0014,
      "step": 41250
    },
    {
      "epoch": 3.520778223397901,
      "grad_norm": 0.22042213380336761,
      "learning_rate": 1.479221776602099e-05,
      "loss": 0.0023,
      "step": 41260
    },
    {
      "epoch": 3.521631538527178,
      "grad_norm": 0.052509453147649765,
      "learning_rate": 1.4783684614728219e-05,
      "loss": 0.0019,
      "step": 41270
    },
    {
      "epoch": 3.5224848536564553,
      "grad_norm": 0.07403524219989777,
      "learning_rate": 1.4775151463435447e-05,
      "loss": 0.0017,
      "step": 41280
    },
    {
      "epoch": 3.523338168785733,
      "grad_norm": 0.15894459187984467,
      "learning_rate": 1.4766618312142674e-05,
      "loss": 0.0017,
      "step": 41290
    },
    {
      "epoch": 3.52419148391501,
      "grad_norm": 0.08344754576683044,
      "learning_rate": 1.4758085160849902e-05,
      "loss": 0.0018,
      "step": 41300
    },
    {
      "epoch": 3.525044799044287,
      "grad_norm": 0.25365498661994934,
      "learning_rate": 1.474955200955713e-05,
      "loss": 0.0017,
      "step": 41310
    },
    {
      "epoch": 3.525898114173564,
      "grad_norm": 0.28736674785614014,
      "learning_rate": 1.4741018858264358e-05,
      "loss": 0.0024,
      "step": 41320
    },
    {
      "epoch": 3.5267514293028417,
      "grad_norm": 0.10291534662246704,
      "learning_rate": 1.4732485706971586e-05,
      "loss": 0.002,
      "step": 41330
    },
    {
      "epoch": 3.527604744432119,
      "grad_norm": 0.1945239156484604,
      "learning_rate": 1.4723952555678813e-05,
      "loss": 0.0019,
      "step": 41340
    },
    {
      "epoch": 3.528458059561396,
      "grad_norm": 0.06850617378950119,
      "learning_rate": 1.4715419404386041e-05,
      "loss": 0.0019,
      "step": 41350
    },
    {
      "epoch": 3.529311374690673,
      "grad_norm": 0.1683042198419571,
      "learning_rate": 1.4706886253093268e-05,
      "loss": 0.0017,
      "step": 41360
    },
    {
      "epoch": 3.5301646898199506,
      "grad_norm": 0.4185662567615509,
      "learning_rate": 1.4698353101800497e-05,
      "loss": 0.0018,
      "step": 41370
    },
    {
      "epoch": 3.5310180049492277,
      "grad_norm": 0.02847830392420292,
      "learning_rate": 1.4689819950507725e-05,
      "loss": 0.0016,
      "step": 41380
    },
    {
      "epoch": 3.531871320078505,
      "grad_norm": 0.42489418387413025,
      "learning_rate": 1.4681286799214949e-05,
      "loss": 0.0017,
      "step": 41390
    },
    {
      "epoch": 3.5327246352077823,
      "grad_norm": 0.20257999002933502,
      "learning_rate": 1.4672753647922177e-05,
      "loss": 0.002,
      "step": 41400
    },
    {
      "epoch": 3.5335779503370595,
      "grad_norm": 0.15650196373462677,
      "learning_rate": 1.4664220496629406e-05,
      "loss": 0.0021,
      "step": 41410
    },
    {
      "epoch": 3.5344312654663366,
      "grad_norm": 0.3852485418319702,
      "learning_rate": 1.4655687345336632e-05,
      "loss": 0.0018,
      "step": 41420
    },
    {
      "epoch": 3.535284580595614,
      "grad_norm": 0.08150258660316467,
      "learning_rate": 1.464715419404386e-05,
      "loss": 0.0015,
      "step": 41430
    },
    {
      "epoch": 3.5361378957248912,
      "grad_norm": 0.1529178023338318,
      "learning_rate": 1.4638621042751088e-05,
      "loss": 0.0021,
      "step": 41440
    },
    {
      "epoch": 3.5369912108541683,
      "grad_norm": 0.16029687225818634,
      "learning_rate": 1.4630087891458316e-05,
      "loss": 0.0021,
      "step": 41450
    },
    {
      "epoch": 3.537844525983446,
      "grad_norm": 0.18324477970600128,
      "learning_rate": 1.4621554740165545e-05,
      "loss": 0.0023,
      "step": 41460
    },
    {
      "epoch": 3.538697841112723,
      "grad_norm": 0.1995997577905655,
      "learning_rate": 1.4613021588872771e-05,
      "loss": 0.0026,
      "step": 41470
    },
    {
      "epoch": 3.539551156242,
      "grad_norm": 0.11454999446868896,
      "learning_rate": 1.460448843758e-05,
      "loss": 0.0023,
      "step": 41480
    },
    {
      "epoch": 3.5404044713712777,
      "grad_norm": 0.03779163211584091,
      "learning_rate": 1.4595955286287227e-05,
      "loss": 0.0019,
      "step": 41490
    },
    {
      "epoch": 3.541257786500555,
      "grad_norm": 0.08287286758422852,
      "learning_rate": 1.4587422134994455e-05,
      "loss": 0.0019,
      "step": 41500
    },
    {
      "epoch": 3.542111101629832,
      "grad_norm": 0.26763540506362915,
      "learning_rate": 1.4578888983701684e-05,
      "loss": 0.0022,
      "step": 41510
    },
    {
      "epoch": 3.542964416759109,
      "grad_norm": 0.1808619201183319,
      "learning_rate": 1.457035583240891e-05,
      "loss": 0.0019,
      "step": 41520
    },
    {
      "epoch": 3.543817731888386,
      "grad_norm": 0.1858161985874176,
      "learning_rate": 1.4561822681116135e-05,
      "loss": 0.002,
      "step": 41530
    },
    {
      "epoch": 3.5446710470176637,
      "grad_norm": 0.43641921877861023,
      "learning_rate": 1.4553289529823364e-05,
      "loss": 0.0022,
      "step": 41540
    },
    {
      "epoch": 3.5455243621469408,
      "grad_norm": 0.23184554278850555,
      "learning_rate": 1.454475637853059e-05,
      "loss": 0.0027,
      "step": 41550
    },
    {
      "epoch": 3.546377677276218,
      "grad_norm": 0.2489209622144699,
      "learning_rate": 1.453622322723782e-05,
      "loss": 0.002,
      "step": 41560
    },
    {
      "epoch": 3.5472309924054954,
      "grad_norm": 0.2168949544429779,
      "learning_rate": 1.4527690075945046e-05,
      "loss": 0.0019,
      "step": 41570
    },
    {
      "epoch": 3.5480843075347726,
      "grad_norm": 0.30314624309539795,
      "learning_rate": 1.4519156924652275e-05,
      "loss": 0.0019,
      "step": 41580
    },
    {
      "epoch": 3.5489376226640497,
      "grad_norm": 0.30654481053352356,
      "learning_rate": 1.4510623773359503e-05,
      "loss": 0.0019,
      "step": 41590
    },
    {
      "epoch": 3.549790937793327,
      "grad_norm": 0.2425897866487503,
      "learning_rate": 1.450209062206673e-05,
      "loss": 0.0018,
      "step": 41600
    },
    {
      "epoch": 3.5506442529226043,
      "grad_norm": 0.07822447270154953,
      "learning_rate": 1.4493557470773958e-05,
      "loss": 0.002,
      "step": 41610
    },
    {
      "epoch": 3.5514975680518814,
      "grad_norm": 0.3893716633319855,
      "learning_rate": 1.4485024319481185e-05,
      "loss": 0.0017,
      "step": 41620
    },
    {
      "epoch": 3.552350883181159,
      "grad_norm": 0.052605945616960526,
      "learning_rate": 1.4476491168188414e-05,
      "loss": 0.0021,
      "step": 41630
    },
    {
      "epoch": 3.553204198310436,
      "grad_norm": 0.1911315768957138,
      "learning_rate": 1.4467958016895642e-05,
      "loss": 0.0019,
      "step": 41640
    },
    {
      "epoch": 3.554057513439713,
      "grad_norm": 0.1821710467338562,
      "learning_rate": 1.4459424865602869e-05,
      "loss": 0.0017,
      "step": 41650
    },
    {
      "epoch": 3.5549108285689908,
      "grad_norm": 0.2928665280342102,
      "learning_rate": 1.4450891714310094e-05,
      "loss": 0.0018,
      "step": 41660
    },
    {
      "epoch": 3.555764143698268,
      "grad_norm": 0.14052170515060425,
      "learning_rate": 1.4442358563017322e-05,
      "loss": 0.0019,
      "step": 41670
    },
    {
      "epoch": 3.556617458827545,
      "grad_norm": 0.1739928275346756,
      "learning_rate": 1.443382541172455e-05,
      "loss": 0.0018,
      "step": 41680
    },
    {
      "epoch": 3.557470773956822,
      "grad_norm": 0.3672617971897125,
      "learning_rate": 1.4425292260431778e-05,
      "loss": 0.0019,
      "step": 41690
    },
    {
      "epoch": 3.5583240890860997,
      "grad_norm": 0.2289317548274994,
      "learning_rate": 1.4416759109139006e-05,
      "loss": 0.0016,
      "step": 41700
    },
    {
      "epoch": 3.5591774042153768,
      "grad_norm": 0.18808583915233612,
      "learning_rate": 1.4408225957846233e-05,
      "loss": 0.0022,
      "step": 41710
    },
    {
      "epoch": 3.560030719344654,
      "grad_norm": 0.07710380107164383,
      "learning_rate": 1.4399692806553461e-05,
      "loss": 0.002,
      "step": 41720
    },
    {
      "epoch": 3.560884034473931,
      "grad_norm": 0.3017733097076416,
      "learning_rate": 1.4391159655260688e-05,
      "loss": 0.0019,
      "step": 41730
    },
    {
      "epoch": 3.5617373496032085,
      "grad_norm": 0.2123386263847351,
      "learning_rate": 1.4382626503967917e-05,
      "loss": 0.002,
      "step": 41740
    },
    {
      "epoch": 3.5625906647324856,
      "grad_norm": 0.043028395622968674,
      "learning_rate": 1.4374093352675143e-05,
      "loss": 0.002,
      "step": 41750
    },
    {
      "epoch": 3.5634439798617628,
      "grad_norm": 0.15267214179039001,
      "learning_rate": 1.4365560201382372e-05,
      "loss": 0.0019,
      "step": 41760
    },
    {
      "epoch": 3.5642972949910403,
      "grad_norm": 0.3646217882633209,
      "learning_rate": 1.43570270500896e-05,
      "loss": 0.0018,
      "step": 41770
    },
    {
      "epoch": 3.5651506101203174,
      "grad_norm": 0.2104511708021164,
      "learning_rate": 1.4348493898796827e-05,
      "loss": 0.0021,
      "step": 41780
    },
    {
      "epoch": 3.5660039252495945,
      "grad_norm": 0.3010503649711609,
      "learning_rate": 1.4339960747504052e-05,
      "loss": 0.0021,
      "step": 41790
    },
    {
      "epoch": 3.566857240378872,
      "grad_norm": 0.044574569910764694,
      "learning_rate": 1.433142759621128e-05,
      "loss": 0.0018,
      "step": 41800
    },
    {
      "epoch": 3.567710555508149,
      "grad_norm": 0.054342444986104965,
      "learning_rate": 1.4322894444918508e-05,
      "loss": 0.0017,
      "step": 41810
    },
    {
      "epoch": 3.5685638706374263,
      "grad_norm": 0.058686234056949615,
      "learning_rate": 1.4314361293625736e-05,
      "loss": 0.002,
      "step": 41820
    },
    {
      "epoch": 3.569417185766704,
      "grad_norm": 0.17637990415096283,
      "learning_rate": 1.4305828142332965e-05,
      "loss": 0.0024,
      "step": 41830
    },
    {
      "epoch": 3.570270500895981,
      "grad_norm": 0.11757122725248337,
      "learning_rate": 1.4297294991040191e-05,
      "loss": 0.0019,
      "step": 41840
    },
    {
      "epoch": 3.571123816025258,
      "grad_norm": 0.35987037420272827,
      "learning_rate": 1.428876183974742e-05,
      "loss": 0.002,
      "step": 41850
    },
    {
      "epoch": 3.5719771311545356,
      "grad_norm": 0.03939606994390488,
      "learning_rate": 1.4280228688454647e-05,
      "loss": 0.0021,
      "step": 41860
    },
    {
      "epoch": 3.5728304462838127,
      "grad_norm": 0.3775196671485901,
      "learning_rate": 1.4271695537161875e-05,
      "loss": 0.0022,
      "step": 41870
    },
    {
      "epoch": 3.57368376141309,
      "grad_norm": 0.13049139082431793,
      "learning_rate": 1.4263162385869102e-05,
      "loss": 0.0018,
      "step": 41880
    },
    {
      "epoch": 3.574537076542367,
      "grad_norm": 0.10378461331129074,
      "learning_rate": 1.425462923457633e-05,
      "loss": 0.0018,
      "step": 41890
    },
    {
      "epoch": 3.575390391671644,
      "grad_norm": 0.1119910404086113,
      "learning_rate": 1.4246096083283559e-05,
      "loss": 0.0017,
      "step": 41900
    },
    {
      "epoch": 3.5762437068009216,
      "grad_norm": 0.17472591996192932,
      "learning_rate": 1.4237562931990786e-05,
      "loss": 0.0019,
      "step": 41910
    },
    {
      "epoch": 3.5770970219301987,
      "grad_norm": 0.09177844971418381,
      "learning_rate": 1.4229029780698014e-05,
      "loss": 0.0021,
      "step": 41920
    },
    {
      "epoch": 3.577950337059476,
      "grad_norm": 0.4053047001361847,
      "learning_rate": 1.422049662940524e-05,
      "loss": 0.0016,
      "step": 41930
    },
    {
      "epoch": 3.5788036521887534,
      "grad_norm": 0.10398101061582565,
      "learning_rate": 1.4211963478112466e-05,
      "loss": 0.002,
      "step": 41940
    },
    {
      "epoch": 3.5796569673180305,
      "grad_norm": 0.13447287678718567,
      "learning_rate": 1.4203430326819694e-05,
      "loss": 0.0015,
      "step": 41950
    },
    {
      "epoch": 3.5805102824473076,
      "grad_norm": 0.24844154715538025,
      "learning_rate": 1.4194897175526923e-05,
      "loss": 0.0016,
      "step": 41960
    },
    {
      "epoch": 3.581363597576585,
      "grad_norm": 0.29048874974250793,
      "learning_rate": 1.418636402423415e-05,
      "loss": 0.0014,
      "step": 41970
    },
    {
      "epoch": 3.5822169127058623,
      "grad_norm": 0.10150690376758575,
      "learning_rate": 1.4177830872941378e-05,
      "loss": 0.0018,
      "step": 41980
    },
    {
      "epoch": 3.5830702278351394,
      "grad_norm": 0.18582211434841156,
      "learning_rate": 1.4169297721648605e-05,
      "loss": 0.0016,
      "step": 41990
    },
    {
      "epoch": 3.583923542964417,
      "grad_norm": 0.2716324031352997,
      "learning_rate": 1.4160764570355833e-05,
      "loss": 0.0019,
      "step": 42000
    },
    {
      "epoch": 3.584776858093694,
      "grad_norm": 0.13466398417949677,
      "learning_rate": 1.4152231419063062e-05,
      "loss": 0.0021,
      "step": 42010
    },
    {
      "epoch": 3.585630173222971,
      "grad_norm": 0.21651805937290192,
      "learning_rate": 1.4143698267770289e-05,
      "loss": 0.0028,
      "step": 42020
    },
    {
      "epoch": 3.5864834883522487,
      "grad_norm": 0.06639250367879868,
      "learning_rate": 1.4135165116477517e-05,
      "loss": 0.0021,
      "step": 42030
    },
    {
      "epoch": 3.587336803481526,
      "grad_norm": 0.1344318389892578,
      "learning_rate": 1.4126631965184744e-05,
      "loss": 0.0017,
      "step": 42040
    },
    {
      "epoch": 3.588190118610803,
      "grad_norm": 0.13579827547073364,
      "learning_rate": 1.4118098813891973e-05,
      "loss": 0.0024,
      "step": 42050
    },
    {
      "epoch": 3.58904343374008,
      "grad_norm": 0.16334976255893707,
      "learning_rate": 1.4109565662599198e-05,
      "loss": 0.0017,
      "step": 42060
    },
    {
      "epoch": 3.5898967488693576,
      "grad_norm": 0.05736732482910156,
      "learning_rate": 1.4101032511306424e-05,
      "loss": 0.0014,
      "step": 42070
    },
    {
      "epoch": 3.5907500639986347,
      "grad_norm": 0.11564531922340393,
      "learning_rate": 1.4092499360013653e-05,
      "loss": 0.0016,
      "step": 42080
    },
    {
      "epoch": 3.591603379127912,
      "grad_norm": 0.30593815445899963,
      "learning_rate": 1.4083966208720881e-05,
      "loss": 0.0017,
      "step": 42090
    },
    {
      "epoch": 3.592456694257189,
      "grad_norm": 0.04894675686955452,
      "learning_rate": 1.4075433057428108e-05,
      "loss": 0.0019,
      "step": 42100
    },
    {
      "epoch": 3.5933100093864665,
      "grad_norm": 0.3560974597930908,
      "learning_rate": 1.4066899906135337e-05,
      "loss": 0.0022,
      "step": 42110
    },
    {
      "epoch": 3.5941633245157436,
      "grad_norm": 0.0792243555188179,
      "learning_rate": 1.4058366754842563e-05,
      "loss": 0.0016,
      "step": 42120
    },
    {
      "epoch": 3.5950166396450207,
      "grad_norm": 0.3267112672328949,
      "learning_rate": 1.4049833603549792e-05,
      "loss": 0.0022,
      "step": 42130
    },
    {
      "epoch": 3.5958699547742983,
      "grad_norm": 0.17460674047470093,
      "learning_rate": 1.404130045225702e-05,
      "loss": 0.0021,
      "step": 42140
    },
    {
      "epoch": 3.5967232699035754,
      "grad_norm": 0.10135751217603683,
      "learning_rate": 1.4032767300964247e-05,
      "loss": 0.0019,
      "step": 42150
    },
    {
      "epoch": 3.5975765850328525,
      "grad_norm": 0.47011318802833557,
      "learning_rate": 1.4024234149671476e-05,
      "loss": 0.0017,
      "step": 42160
    },
    {
      "epoch": 3.59842990016213,
      "grad_norm": 0.47427353262901306,
      "learning_rate": 1.4015700998378702e-05,
      "loss": 0.0022,
      "step": 42170
    },
    {
      "epoch": 3.599283215291407,
      "grad_norm": 0.2141123265028,
      "learning_rate": 1.4007167847085931e-05,
      "loss": 0.0023,
      "step": 42180
    },
    {
      "epoch": 3.6001365304206843,
      "grad_norm": 0.4331306219100952,
      "learning_rate": 1.3998634695793156e-05,
      "loss": 0.0015,
      "step": 42190
    },
    {
      "epoch": 3.600989845549962,
      "grad_norm": 0.21061190962791443,
      "learning_rate": 1.3990101544500383e-05,
      "loss": 0.0019,
      "step": 42200
    },
    {
      "epoch": 3.601843160679239,
      "grad_norm": 0.551425039768219,
      "learning_rate": 1.3981568393207611e-05,
      "loss": 0.0024,
      "step": 42210
    },
    {
      "epoch": 3.602696475808516,
      "grad_norm": 0.04446256160736084,
      "learning_rate": 1.397303524191484e-05,
      "loss": 0.0016,
      "step": 42220
    },
    {
      "epoch": 3.6035497909377936,
      "grad_norm": 0.18987438082695007,
      "learning_rate": 1.3964502090622067e-05,
      "loss": 0.0016,
      "step": 42230
    },
    {
      "epoch": 3.6044031060670707,
      "grad_norm": 0.45485225319862366,
      "learning_rate": 1.3955968939329295e-05,
      "loss": 0.0017,
      "step": 42240
    },
    {
      "epoch": 3.605256421196348,
      "grad_norm": 0.116315558552742,
      "learning_rate": 1.3947435788036522e-05,
      "loss": 0.0024,
      "step": 42250
    },
    {
      "epoch": 3.606109736325625,
      "grad_norm": 0.20741873979568481,
      "learning_rate": 1.393890263674375e-05,
      "loss": 0.0016,
      "step": 42260
    },
    {
      "epoch": 3.606963051454902,
      "grad_norm": 0.13065390288829803,
      "learning_rate": 1.3930369485450979e-05,
      "loss": 0.0019,
      "step": 42270
    },
    {
      "epoch": 3.6078163665841796,
      "grad_norm": 0.085320383310318,
      "learning_rate": 1.3921836334158206e-05,
      "loss": 0.0018,
      "step": 42280
    },
    {
      "epoch": 3.6086696817134567,
      "grad_norm": 0.22824737429618835,
      "learning_rate": 1.3913303182865434e-05,
      "loss": 0.0023,
      "step": 42290
    },
    {
      "epoch": 3.609522996842734,
      "grad_norm": 0.33919477462768555,
      "learning_rate": 1.390477003157266e-05,
      "loss": 0.0021,
      "step": 42300
    },
    {
      "epoch": 3.6103763119720114,
      "grad_norm": 0.26431092619895935,
      "learning_rate": 1.389623688027989e-05,
      "loss": 0.0021,
      "step": 42310
    },
    {
      "epoch": 3.6112296271012885,
      "grad_norm": 0.21046769618988037,
      "learning_rate": 1.3887703728987114e-05,
      "loss": 0.0014,
      "step": 42320
    },
    {
      "epoch": 3.6120829422305656,
      "grad_norm": 0.16772323846817017,
      "learning_rate": 1.3879170577694341e-05,
      "loss": 0.0018,
      "step": 42330
    },
    {
      "epoch": 3.612936257359843,
      "grad_norm": 0.03293351083993912,
      "learning_rate": 1.387063742640157e-05,
      "loss": 0.0019,
      "step": 42340
    },
    {
      "epoch": 3.6137895724891202,
      "grad_norm": 0.12522919476032257,
      "learning_rate": 1.3862104275108798e-05,
      "loss": 0.0015,
      "step": 42350
    },
    {
      "epoch": 3.6146428876183974,
      "grad_norm": 0.06365824490785599,
      "learning_rate": 1.3853571123816025e-05,
      "loss": 0.0019,
      "step": 42360
    },
    {
      "epoch": 3.615496202747675,
      "grad_norm": 0.090598464012146,
      "learning_rate": 1.3845037972523253e-05,
      "loss": 0.0022,
      "step": 42370
    },
    {
      "epoch": 3.616349517876952,
      "grad_norm": 0.04857901856303215,
      "learning_rate": 1.383650482123048e-05,
      "loss": 0.0017,
      "step": 42380
    },
    {
      "epoch": 3.617202833006229,
      "grad_norm": 0.21139802038669586,
      "learning_rate": 1.3827971669937709e-05,
      "loss": 0.0016,
      "step": 42390
    },
    {
      "epoch": 3.6180561481355067,
      "grad_norm": 0.15583471953868866,
      "learning_rate": 1.3819438518644937e-05,
      "loss": 0.0017,
      "step": 42400
    },
    {
      "epoch": 3.618909463264784,
      "grad_norm": 0.13763445615768433,
      "learning_rate": 1.3810905367352164e-05,
      "loss": 0.0021,
      "step": 42410
    },
    {
      "epoch": 3.619762778394061,
      "grad_norm": 0.13287585973739624,
      "learning_rate": 1.3802372216059392e-05,
      "loss": 0.0026,
      "step": 42420
    },
    {
      "epoch": 3.620616093523338,
      "grad_norm": 0.03939395397901535,
      "learning_rate": 1.379383906476662e-05,
      "loss": 0.0023,
      "step": 42430
    },
    {
      "epoch": 3.6214694086526156,
      "grad_norm": 0.06401482224464417,
      "learning_rate": 1.3785305913473848e-05,
      "loss": 0.0021,
      "step": 42440
    },
    {
      "epoch": 3.6223227237818927,
      "grad_norm": 0.05696416646242142,
      "learning_rate": 1.3776772762181076e-05,
      "loss": 0.0022,
      "step": 42450
    },
    {
      "epoch": 3.62317603891117,
      "grad_norm": 0.18728846311569214,
      "learning_rate": 1.3768239610888301e-05,
      "loss": 0.0021,
      "step": 42460
    },
    {
      "epoch": 3.624029354040447,
      "grad_norm": 0.25231194496154785,
      "learning_rate": 1.3759706459595528e-05,
      "loss": 0.0017,
      "step": 42470
    },
    {
      "epoch": 3.6248826691697245,
      "grad_norm": 0.0711895003914833,
      "learning_rate": 1.3751173308302757e-05,
      "loss": 0.0019,
      "step": 42480
    },
    {
      "epoch": 3.6257359842990016,
      "grad_norm": 0.22112548351287842,
      "learning_rate": 1.3742640157009983e-05,
      "loss": 0.0022,
      "step": 42490
    },
    {
      "epoch": 3.6265892994282787,
      "grad_norm": 0.05800370126962662,
      "learning_rate": 1.3734107005717212e-05,
      "loss": 0.0022,
      "step": 42500
    },
    {
      "epoch": 3.6274426145575562,
      "grad_norm": 0.21594356000423431,
      "learning_rate": 1.3725573854424439e-05,
      "loss": 0.0016,
      "step": 42510
    },
    {
      "epoch": 3.6282959296868333,
      "grad_norm": 0.10092581063508987,
      "learning_rate": 1.3717040703131667e-05,
      "loss": 0.0017,
      "step": 42520
    },
    {
      "epoch": 3.6291492448161105,
      "grad_norm": 0.15260376036167145,
      "learning_rate": 1.3708507551838896e-05,
      "loss": 0.0019,
      "step": 42530
    },
    {
      "epoch": 3.630002559945388,
      "grad_norm": 0.21164554357528687,
      "learning_rate": 1.3699974400546122e-05,
      "loss": 0.0017,
      "step": 42540
    },
    {
      "epoch": 3.630855875074665,
      "grad_norm": 0.15457764267921448,
      "learning_rate": 1.3691441249253351e-05,
      "loss": 0.0021,
      "step": 42550
    },
    {
      "epoch": 3.6317091902039422,
      "grad_norm": 0.45566701889038086,
      "learning_rate": 1.3682908097960578e-05,
      "loss": 0.0017,
      "step": 42560
    },
    {
      "epoch": 3.63256250533322,
      "grad_norm": 0.15144191682338715,
      "learning_rate": 1.3674374946667806e-05,
      "loss": 0.0019,
      "step": 42570
    },
    {
      "epoch": 3.633415820462497,
      "grad_norm": 0.06921372562646866,
      "learning_rate": 1.3665841795375035e-05,
      "loss": 0.0024,
      "step": 42580
    },
    {
      "epoch": 3.634269135591774,
      "grad_norm": 0.23545008897781372,
      "learning_rate": 1.365730864408226e-05,
      "loss": 0.0018,
      "step": 42590
    },
    {
      "epoch": 3.6351224507210516,
      "grad_norm": 0.44122016429901123,
      "learning_rate": 1.3648775492789486e-05,
      "loss": 0.0021,
      "step": 42600
    },
    {
      "epoch": 3.6359757658503287,
      "grad_norm": 0.05224210396409035,
      "learning_rate": 1.3640242341496715e-05,
      "loss": 0.0021,
      "step": 42610
    },
    {
      "epoch": 3.6368290809796058,
      "grad_norm": 0.0428365021944046,
      "learning_rate": 1.3631709190203942e-05,
      "loss": 0.0027,
      "step": 42620
    },
    {
      "epoch": 3.637682396108883,
      "grad_norm": 0.04614940285682678,
      "learning_rate": 1.362317603891117e-05,
      "loss": 0.002,
      "step": 42630
    },
    {
      "epoch": 3.63853571123816,
      "grad_norm": 0.0909491777420044,
      "learning_rate": 1.3614642887618399e-05,
      "loss": 0.0018,
      "step": 42640
    },
    {
      "epoch": 3.6393890263674376,
      "grad_norm": 0.2898649275302887,
      "learning_rate": 1.3606109736325626e-05,
      "loss": 0.0023,
      "step": 42650
    },
    {
      "epoch": 3.6402423414967147,
      "grad_norm": 0.044137369841337204,
      "learning_rate": 1.3597576585032854e-05,
      "loss": 0.002,
      "step": 42660
    },
    {
      "epoch": 3.6410956566259918,
      "grad_norm": 0.12247451394796371,
      "learning_rate": 1.358904343374008e-05,
      "loss": 0.0028,
      "step": 42670
    },
    {
      "epoch": 3.6419489717552693,
      "grad_norm": 0.3077492117881775,
      "learning_rate": 1.358051028244731e-05,
      "loss": 0.0023,
      "step": 42680
    },
    {
      "epoch": 3.6428022868845464,
      "grad_norm": 0.061452824622392654,
      "learning_rate": 1.3571977131154536e-05,
      "loss": 0.0018,
      "step": 42690
    },
    {
      "epoch": 3.6436556020138235,
      "grad_norm": 0.23257507383823395,
      "learning_rate": 1.3563443979861765e-05,
      "loss": 0.0015,
      "step": 42700
    },
    {
      "epoch": 3.644508917143101,
      "grad_norm": 0.03486574441194534,
      "learning_rate": 1.3554910828568993e-05,
      "loss": 0.0022,
      "step": 42710
    },
    {
      "epoch": 3.645362232272378,
      "grad_norm": 0.13023218512535095,
      "learning_rate": 1.3546377677276218e-05,
      "loss": 0.0022,
      "step": 42720
    },
    {
      "epoch": 3.6462155474016553,
      "grad_norm": 0.2070552110671997,
      "learning_rate": 1.3537844525983445e-05,
      "loss": 0.0019,
      "step": 42730
    },
    {
      "epoch": 3.647068862530933,
      "grad_norm": 0.07832533866167068,
      "learning_rate": 1.3529311374690673e-05,
      "loss": 0.0021,
      "step": 42740
    },
    {
      "epoch": 3.64792217766021,
      "grad_norm": 0.13106127083301544,
      "learning_rate": 1.35207782233979e-05,
      "loss": 0.0015,
      "step": 42750
    },
    {
      "epoch": 3.648775492789487,
      "grad_norm": 0.16522696614265442,
      "learning_rate": 1.3512245072105129e-05,
      "loss": 0.0021,
      "step": 42760
    },
    {
      "epoch": 3.6496288079187647,
      "grad_norm": 0.32575276494026184,
      "learning_rate": 1.3503711920812357e-05,
      "loss": 0.0016,
      "step": 42770
    },
    {
      "epoch": 3.6504821230480418,
      "grad_norm": 0.21516190469264984,
      "learning_rate": 1.3495178769519584e-05,
      "loss": 0.0017,
      "step": 42780
    },
    {
      "epoch": 3.651335438177319,
      "grad_norm": 0.44727033376693726,
      "learning_rate": 1.3486645618226812e-05,
      "loss": 0.0017,
      "step": 42790
    },
    {
      "epoch": 3.652188753306596,
      "grad_norm": 0.3002748191356659,
      "learning_rate": 1.347811246693404e-05,
      "loss": 0.0015,
      "step": 42800
    },
    {
      "epoch": 3.653042068435873,
      "grad_norm": 0.1958344429731369,
      "learning_rate": 1.3469579315641268e-05,
      "loss": 0.0018,
      "step": 42810
    },
    {
      "epoch": 3.6538953835651506,
      "grad_norm": 0.11959298700094223,
      "learning_rate": 1.3461046164348494e-05,
      "loss": 0.0019,
      "step": 42820
    },
    {
      "epoch": 3.6547486986944278,
      "grad_norm": 0.10606119781732559,
      "learning_rate": 1.3452513013055723e-05,
      "loss": 0.0012,
      "step": 42830
    },
    {
      "epoch": 3.655602013823705,
      "grad_norm": 0.03650331869721413,
      "learning_rate": 1.3443979861762951e-05,
      "loss": 0.0023,
      "step": 42840
    },
    {
      "epoch": 3.6564553289529824,
      "grad_norm": 0.3223631978034973,
      "learning_rate": 1.3435446710470178e-05,
      "loss": 0.002,
      "step": 42850
    },
    {
      "epoch": 3.6573086440822595,
      "grad_norm": 0.14242194592952728,
      "learning_rate": 1.3426913559177403e-05,
      "loss": 0.0017,
      "step": 42860
    },
    {
      "epoch": 3.6581619592115366,
      "grad_norm": 0.20843490958213806,
      "learning_rate": 1.3418380407884632e-05,
      "loss": 0.0016,
      "step": 42870
    },
    {
      "epoch": 3.659015274340814,
      "grad_norm": 0.12120555341243744,
      "learning_rate": 1.3409847256591859e-05,
      "loss": 0.0021,
      "step": 42880
    },
    {
      "epoch": 3.6598685894700913,
      "grad_norm": 0.3142109513282776,
      "learning_rate": 1.3401314105299087e-05,
      "loss": 0.0023,
      "step": 42890
    },
    {
      "epoch": 3.6607219045993684,
      "grad_norm": 0.11830218136310577,
      "learning_rate": 1.3392780954006316e-05,
      "loss": 0.0022,
      "step": 42900
    },
    {
      "epoch": 3.661575219728646,
      "grad_norm": 0.10201647877693176,
      "learning_rate": 1.3384247802713542e-05,
      "loss": 0.0013,
      "step": 42910
    },
    {
      "epoch": 3.662428534857923,
      "grad_norm": 0.3025868535041809,
      "learning_rate": 1.337571465142077e-05,
      "loss": 0.0017,
      "step": 42920
    },
    {
      "epoch": 3.6632818499872,
      "grad_norm": 0.19989940524101257,
      "learning_rate": 1.3367181500127998e-05,
      "loss": 0.0018,
      "step": 42930
    },
    {
      "epoch": 3.6641351651164777,
      "grad_norm": 0.0675792396068573,
      "learning_rate": 1.3358648348835226e-05,
      "loss": 0.0015,
      "step": 42940
    },
    {
      "epoch": 3.664988480245755,
      "grad_norm": 0.3893229365348816,
      "learning_rate": 1.3350115197542455e-05,
      "loss": 0.002,
      "step": 42950
    },
    {
      "epoch": 3.665841795375032,
      "grad_norm": 0.20561738312244415,
      "learning_rate": 1.3341582046249681e-05,
      "loss": 0.0019,
      "step": 42960
    },
    {
      "epoch": 3.6666951105043095,
      "grad_norm": 0.1705811321735382,
      "learning_rate": 1.333304889495691e-05,
      "loss": 0.0021,
      "step": 42970
    },
    {
      "epoch": 3.6675484256335866,
      "grad_norm": 0.15188726782798767,
      "learning_rate": 1.3324515743664137e-05,
      "loss": 0.0023,
      "step": 42980
    },
    {
      "epoch": 3.6684017407628637,
      "grad_norm": 0.04851701483130455,
      "learning_rate": 1.3315982592371362e-05,
      "loss": 0.0019,
      "step": 42990
    },
    {
      "epoch": 3.669255055892141,
      "grad_norm": 0.23897208273410797,
      "learning_rate": 1.330744944107859e-05,
      "loss": 0.0015,
      "step": 43000
    },
    {
      "epoch": 3.670108371021418,
      "grad_norm": 0.2664925158023834,
      "learning_rate": 1.3298916289785817e-05,
      "loss": 0.0013,
      "step": 43010
    },
    {
      "epoch": 3.6709616861506955,
      "grad_norm": 0.056638382375240326,
      "learning_rate": 1.3290383138493045e-05,
      "loss": 0.0016,
      "step": 43020
    },
    {
      "epoch": 3.6718150012799726,
      "grad_norm": 0.2689039707183838,
      "learning_rate": 1.3281849987200274e-05,
      "loss": 0.002,
      "step": 43030
    },
    {
      "epoch": 3.6726683164092497,
      "grad_norm": 0.13145096600055695,
      "learning_rate": 1.32733168359075e-05,
      "loss": 0.0015,
      "step": 43040
    },
    {
      "epoch": 3.6735216315385273,
      "grad_norm": 0.06308390945196152,
      "learning_rate": 1.326478368461473e-05,
      "loss": 0.0021,
      "step": 43050
    },
    {
      "epoch": 3.6743749466678044,
      "grad_norm": 0.17787130177021027,
      "learning_rate": 1.3256250533321956e-05,
      "loss": 0.0023,
      "step": 43060
    },
    {
      "epoch": 3.6752282617970815,
      "grad_norm": 0.15708403289318085,
      "learning_rate": 1.3247717382029184e-05,
      "loss": 0.0016,
      "step": 43070
    },
    {
      "epoch": 3.676081576926359,
      "grad_norm": 0.25940534472465515,
      "learning_rate": 1.3239184230736413e-05,
      "loss": 0.0017,
      "step": 43080
    },
    {
      "epoch": 3.676934892055636,
      "grad_norm": 0.10071999579668045,
      "learning_rate": 1.323065107944364e-05,
      "loss": 0.0015,
      "step": 43090
    },
    {
      "epoch": 3.6777882071849133,
      "grad_norm": 0.10642846673727036,
      "learning_rate": 1.3222117928150868e-05,
      "loss": 0.0021,
      "step": 43100
    },
    {
      "epoch": 3.678641522314191,
      "grad_norm": 0.053881336003541946,
      "learning_rate": 1.3213584776858095e-05,
      "loss": 0.0016,
      "step": 43110
    },
    {
      "epoch": 3.679494837443468,
      "grad_norm": 0.23083654046058655,
      "learning_rate": 1.320505162556532e-05,
      "loss": 0.0018,
      "step": 43120
    },
    {
      "epoch": 3.680348152572745,
      "grad_norm": 0.3084832429885864,
      "learning_rate": 1.3196518474272549e-05,
      "loss": 0.002,
      "step": 43130
    },
    {
      "epoch": 3.6812014677020226,
      "grad_norm": 0.17122219502925873,
      "learning_rate": 1.3187985322979775e-05,
      "loss": 0.0021,
      "step": 43140
    },
    {
      "epoch": 3.6820547828312997,
      "grad_norm": 0.18873851001262665,
      "learning_rate": 1.3179452171687004e-05,
      "loss": 0.002,
      "step": 43150
    },
    {
      "epoch": 3.682908097960577,
      "grad_norm": 0.30201634764671326,
      "learning_rate": 1.3170919020394232e-05,
      "loss": 0.0017,
      "step": 43160
    },
    {
      "epoch": 3.683761413089854,
      "grad_norm": 0.05398485064506531,
      "learning_rate": 1.3162385869101459e-05,
      "loss": 0.0018,
      "step": 43170
    },
    {
      "epoch": 3.684614728219131,
      "grad_norm": 0.19347558915615082,
      "learning_rate": 1.3153852717808688e-05,
      "loss": 0.002,
      "step": 43180
    },
    {
      "epoch": 3.6854680433484086,
      "grad_norm": 0.08046898245811462,
      "learning_rate": 1.3145319566515914e-05,
      "loss": 0.0016,
      "step": 43190
    },
    {
      "epoch": 3.6863213584776857,
      "grad_norm": 0.3120633065700531,
      "learning_rate": 1.3136786415223143e-05,
      "loss": 0.002,
      "step": 43200
    },
    {
      "epoch": 3.687174673606963,
      "grad_norm": 0.1499314159154892,
      "learning_rate": 1.3128253263930371e-05,
      "loss": 0.0015,
      "step": 43210
    },
    {
      "epoch": 3.6880279887362404,
      "grad_norm": 0.34030622243881226,
      "learning_rate": 1.3119720112637598e-05,
      "loss": 0.0018,
      "step": 43220
    },
    {
      "epoch": 3.6888813038655175,
      "grad_norm": 0.3264947235584259,
      "learning_rate": 1.3111186961344827e-05,
      "loss": 0.0015,
      "step": 43230
    },
    {
      "epoch": 3.6897346189947946,
      "grad_norm": 0.06858165562152863,
      "learning_rate": 1.3102653810052053e-05,
      "loss": 0.0016,
      "step": 43240
    },
    {
      "epoch": 3.690587934124072,
      "grad_norm": 0.0628824532032013,
      "learning_rate": 1.3094120658759279e-05,
      "loss": 0.0023,
      "step": 43250
    },
    {
      "epoch": 3.6914412492533493,
      "grad_norm": 0.23850956559181213,
      "learning_rate": 1.3085587507466507e-05,
      "loss": 0.0021,
      "step": 43260
    },
    {
      "epoch": 3.6922945643826264,
      "grad_norm": 0.04984657093882561,
      "learning_rate": 1.3077054356173734e-05,
      "loss": 0.0016,
      "step": 43270
    },
    {
      "epoch": 3.693147879511904,
      "grad_norm": 0.20041362941265106,
      "learning_rate": 1.3068521204880962e-05,
      "loss": 0.0019,
      "step": 43280
    },
    {
      "epoch": 3.694001194641181,
      "grad_norm": 0.0360836498439312,
      "learning_rate": 1.305998805358819e-05,
      "loss": 0.0017,
      "step": 43290
    },
    {
      "epoch": 3.694854509770458,
      "grad_norm": 0.26487451791763306,
      "learning_rate": 1.3051454902295418e-05,
      "loss": 0.0017,
      "step": 43300
    },
    {
      "epoch": 3.6957078248997357,
      "grad_norm": 0.028715914115309715,
      "learning_rate": 1.3042921751002646e-05,
      "loss": 0.0017,
      "step": 43310
    },
    {
      "epoch": 3.696561140029013,
      "grad_norm": 0.2311372309923172,
      "learning_rate": 1.3034388599709873e-05,
      "loss": 0.0014,
      "step": 43320
    },
    {
      "epoch": 3.69741445515829,
      "grad_norm": 0.2936563491821289,
      "learning_rate": 1.3025855448417101e-05,
      "loss": 0.0018,
      "step": 43330
    },
    {
      "epoch": 3.698267770287567,
      "grad_norm": 0.15351273119449615,
      "learning_rate": 1.301732229712433e-05,
      "loss": 0.0017,
      "step": 43340
    },
    {
      "epoch": 3.6991210854168446,
      "grad_norm": 0.10243295133113861,
      "learning_rate": 1.3008789145831557e-05,
      "loss": 0.0018,
      "step": 43350
    },
    {
      "epoch": 3.6999744005461217,
      "grad_norm": 0.037973590195178986,
      "learning_rate": 1.3000255994538785e-05,
      "loss": 0.0015,
      "step": 43360
    },
    {
      "epoch": 3.700827715675399,
      "grad_norm": 0.04918989911675453,
      "learning_rate": 1.2991722843246012e-05,
      "loss": 0.0023,
      "step": 43370
    },
    {
      "epoch": 3.701681030804676,
      "grad_norm": 0.48260101675987244,
      "learning_rate": 1.298318969195324e-05,
      "loss": 0.0019,
      "step": 43380
    },
    {
      "epoch": 3.7025343459339535,
      "grad_norm": 0.3055538535118103,
      "learning_rate": 1.2974656540660465e-05,
      "loss": 0.0017,
      "step": 43390
    },
    {
      "epoch": 3.7033876610632306,
      "grad_norm": 0.13078677654266357,
      "learning_rate": 1.2966123389367694e-05,
      "loss": 0.0025,
      "step": 43400
    },
    {
      "epoch": 3.7042409761925077,
      "grad_norm": 0.044800374656915665,
      "learning_rate": 1.295759023807492e-05,
      "loss": 0.0019,
      "step": 43410
    },
    {
      "epoch": 3.7050942913217852,
      "grad_norm": 0.1211053654551506,
      "learning_rate": 1.294905708678215e-05,
      "loss": 0.0018,
      "step": 43420
    },
    {
      "epoch": 3.7059476064510624,
      "grad_norm": 0.33941134810447693,
      "learning_rate": 1.2940523935489376e-05,
      "loss": 0.0023,
      "step": 43430
    },
    {
      "epoch": 3.7068009215803395,
      "grad_norm": 0.1831609457731247,
      "learning_rate": 1.2931990784196604e-05,
      "loss": 0.002,
      "step": 43440
    },
    {
      "epoch": 3.707654236709617,
      "grad_norm": 0.21032708883285522,
      "learning_rate": 1.2923457632903831e-05,
      "loss": 0.0015,
      "step": 43450
    },
    {
      "epoch": 3.708507551838894,
      "grad_norm": 0.24410036206245422,
      "learning_rate": 1.291492448161106e-05,
      "loss": 0.0022,
      "step": 43460
    },
    {
      "epoch": 3.7093608669681712,
      "grad_norm": 0.041938137263059616,
      "learning_rate": 1.2906391330318288e-05,
      "loss": 0.0017,
      "step": 43470
    },
    {
      "epoch": 3.710214182097449,
      "grad_norm": 0.1714136153459549,
      "learning_rate": 1.2897858179025515e-05,
      "loss": 0.002,
      "step": 43480
    },
    {
      "epoch": 3.711067497226726,
      "grad_norm": 0.18623407185077667,
      "learning_rate": 1.2889325027732743e-05,
      "loss": 0.0015,
      "step": 43490
    },
    {
      "epoch": 3.711920812356003,
      "grad_norm": 0.2461010217666626,
      "learning_rate": 1.288079187643997e-05,
      "loss": 0.0015,
      "step": 43500
    },
    {
      "epoch": 3.7127741274852806,
      "grad_norm": 0.057663485407829285,
      "learning_rate": 1.2872258725147199e-05,
      "loss": 0.0017,
      "step": 43510
    },
    {
      "epoch": 3.7136274426145577,
      "grad_norm": 0.08217264711856842,
      "learning_rate": 1.2863725573854424e-05,
      "loss": 0.0018,
      "step": 43520
    },
    {
      "epoch": 3.714480757743835,
      "grad_norm": 0.08903118968009949,
      "learning_rate": 1.2855192422561652e-05,
      "loss": 0.002,
      "step": 43530
    },
    {
      "epoch": 3.715334072873112,
      "grad_norm": 0.1742209941148758,
      "learning_rate": 1.2846659271268879e-05,
      "loss": 0.0017,
      "step": 43540
    },
    {
      "epoch": 3.716187388002389,
      "grad_norm": 0.2107117474079132,
      "learning_rate": 1.2838126119976108e-05,
      "loss": 0.0023,
      "step": 43550
    },
    {
      "epoch": 3.7170407031316666,
      "grad_norm": 0.36742958426475525,
      "learning_rate": 1.2829592968683334e-05,
      "loss": 0.0021,
      "step": 43560
    },
    {
      "epoch": 3.7178940182609437,
      "grad_norm": 0.03722653537988663,
      "learning_rate": 1.2821059817390563e-05,
      "loss": 0.0024,
      "step": 43570
    },
    {
      "epoch": 3.718747333390221,
      "grad_norm": 0.20550259947776794,
      "learning_rate": 1.2812526666097791e-05,
      "loss": 0.0016,
      "step": 43580
    },
    {
      "epoch": 3.7196006485194983,
      "grad_norm": 0.025710295885801315,
      "learning_rate": 1.2803993514805018e-05,
      "loss": 0.0017,
      "step": 43590
    },
    {
      "epoch": 3.7204539636487755,
      "grad_norm": 0.1345582902431488,
      "learning_rate": 1.2795460363512247e-05,
      "loss": 0.0016,
      "step": 43600
    },
    {
      "epoch": 3.7213072787780526,
      "grad_norm": 0.25068235397338867,
      "learning_rate": 1.2786927212219473e-05,
      "loss": 0.0016,
      "step": 43610
    },
    {
      "epoch": 3.72216059390733,
      "grad_norm": 0.12412384152412415,
      "learning_rate": 1.2778394060926702e-05,
      "loss": 0.0016,
      "step": 43620
    },
    {
      "epoch": 3.7230139090366072,
      "grad_norm": 0.03235898166894913,
      "learning_rate": 1.2769860909633929e-05,
      "loss": 0.0022,
      "step": 43630
    },
    {
      "epoch": 3.7238672241658843,
      "grad_norm": 0.17592690885066986,
      "learning_rate": 1.2761327758341157e-05,
      "loss": 0.002,
      "step": 43640
    },
    {
      "epoch": 3.724720539295162,
      "grad_norm": 0.07885811477899551,
      "learning_rate": 1.2752794607048382e-05,
      "loss": 0.0018,
      "step": 43650
    },
    {
      "epoch": 3.725573854424439,
      "grad_norm": 0.1262233704328537,
      "learning_rate": 1.274426145575561e-05,
      "loss": 0.0019,
      "step": 43660
    },
    {
      "epoch": 3.726427169553716,
      "grad_norm": 0.06294923275709152,
      "learning_rate": 1.2735728304462838e-05,
      "loss": 0.002,
      "step": 43670
    },
    {
      "epoch": 3.7272804846829937,
      "grad_norm": 0.10533682256937027,
      "learning_rate": 1.2727195153170066e-05,
      "loss": 0.0018,
      "step": 43680
    },
    {
      "epoch": 3.7281337998122708,
      "grad_norm": 0.2133564054965973,
      "learning_rate": 1.2718662001877293e-05,
      "loss": 0.0018,
      "step": 43690
    },
    {
      "epoch": 3.728987114941548,
      "grad_norm": 0.24771814048290253,
      "learning_rate": 1.2710128850584521e-05,
      "loss": 0.0022,
      "step": 43700
    },
    {
      "epoch": 3.729840430070825,
      "grad_norm": 0.05710020661354065,
      "learning_rate": 1.270159569929175e-05,
      "loss": 0.0019,
      "step": 43710
    },
    {
      "epoch": 3.7306937452001026,
      "grad_norm": 0.20044830441474915,
      "learning_rate": 1.2693062547998977e-05,
      "loss": 0.002,
      "step": 43720
    },
    {
      "epoch": 3.7315470603293797,
      "grad_norm": 0.19131118059158325,
      "learning_rate": 1.2684529396706205e-05,
      "loss": 0.0018,
      "step": 43730
    },
    {
      "epoch": 3.7324003754586568,
      "grad_norm": 0.05659075826406479,
      "learning_rate": 1.2675996245413432e-05,
      "loss": 0.0017,
      "step": 43740
    },
    {
      "epoch": 3.733253690587934,
      "grad_norm": 0.23114734888076782,
      "learning_rate": 1.266746309412066e-05,
      "loss": 0.0027,
      "step": 43750
    },
    {
      "epoch": 3.7341070057172114,
      "grad_norm": 0.21216246485710144,
      "learning_rate": 1.2658929942827889e-05,
      "loss": 0.0019,
      "step": 43760
    },
    {
      "epoch": 3.7349603208464885,
      "grad_norm": 0.05025289207696915,
      "learning_rate": 1.2650396791535116e-05,
      "loss": 0.002,
      "step": 43770
    },
    {
      "epoch": 3.7358136359757657,
      "grad_norm": 0.08396575599908829,
      "learning_rate": 1.2641863640242344e-05,
      "loss": 0.0019,
      "step": 43780
    },
    {
      "epoch": 3.736666951105043,
      "grad_norm": 0.2502710223197937,
      "learning_rate": 1.2633330488949569e-05,
      "loss": 0.0016,
      "step": 43790
    },
    {
      "epoch": 3.7375202662343203,
      "grad_norm": 0.041242461651563644,
      "learning_rate": 1.2624797337656796e-05,
      "loss": 0.0021,
      "step": 43800
    },
    {
      "epoch": 3.7383735813635974,
      "grad_norm": 0.2465430498123169,
      "learning_rate": 1.2616264186364024e-05,
      "loss": 0.0023,
      "step": 43810
    },
    {
      "epoch": 3.739226896492875,
      "grad_norm": 0.4427661597728729,
      "learning_rate": 1.2607731035071251e-05,
      "loss": 0.0016,
      "step": 43820
    },
    {
      "epoch": 3.740080211622152,
      "grad_norm": 0.14789676666259766,
      "learning_rate": 1.259919788377848e-05,
      "loss": 0.0021,
      "step": 43830
    },
    {
      "epoch": 3.740933526751429,
      "grad_norm": 0.13516463339328766,
      "learning_rate": 1.2590664732485708e-05,
      "loss": 0.0018,
      "step": 43840
    },
    {
      "epoch": 3.7417868418807068,
      "grad_norm": 0.12287288159132004,
      "learning_rate": 1.2582131581192935e-05,
      "loss": 0.002,
      "step": 43850
    },
    {
      "epoch": 3.742640157009984,
      "grad_norm": 0.2965671122074127,
      "learning_rate": 1.2573598429900163e-05,
      "loss": 0.0014,
      "step": 43860
    },
    {
      "epoch": 3.743493472139261,
      "grad_norm": 0.16296066343784332,
      "learning_rate": 1.256506527860739e-05,
      "loss": 0.0017,
      "step": 43870
    },
    {
      "epoch": 3.7443467872685385,
      "grad_norm": 0.18538399040699005,
      "learning_rate": 1.2556532127314619e-05,
      "loss": 0.0022,
      "step": 43880
    },
    {
      "epoch": 3.7452001023978156,
      "grad_norm": 0.050526320934295654,
      "learning_rate": 1.2547998976021847e-05,
      "loss": 0.0016,
      "step": 43890
    },
    {
      "epoch": 3.7460534175270928,
      "grad_norm": 0.12973445653915405,
      "learning_rate": 1.2539465824729074e-05,
      "loss": 0.0021,
      "step": 43900
    },
    {
      "epoch": 3.74690673265637,
      "grad_norm": 0.12337153404951096,
      "learning_rate": 1.2530932673436302e-05,
      "loss": 0.002,
      "step": 43910
    },
    {
      "epoch": 3.747760047785647,
      "grad_norm": 0.47219955921173096,
      "learning_rate": 1.2522399522143528e-05,
      "loss": 0.0019,
      "step": 43920
    },
    {
      "epoch": 3.7486133629149245,
      "grad_norm": 0.21393145620822906,
      "learning_rate": 1.2513866370850754e-05,
      "loss": 0.0019,
      "step": 43930
    },
    {
      "epoch": 3.7494666780442016,
      "grad_norm": 0.07972581684589386,
      "learning_rate": 1.2505333219557983e-05,
      "loss": 0.0015,
      "step": 43940
    },
    {
      "epoch": 3.7503199931734787,
      "grad_norm": 0.06659740954637527,
      "learning_rate": 1.249680006826521e-05,
      "loss": 0.0019,
      "step": 43950
    },
    {
      "epoch": 3.7511733083027563,
      "grad_norm": 0.3054448366165161,
      "learning_rate": 1.2488266916972438e-05,
      "loss": 0.0016,
      "step": 43960
    },
    {
      "epoch": 3.7520266234320334,
      "grad_norm": 0.09872476011514664,
      "learning_rate": 1.2479733765679667e-05,
      "loss": 0.0017,
      "step": 43970
    },
    {
      "epoch": 3.7528799385613105,
      "grad_norm": 0.1749773621559143,
      "learning_rate": 1.2471200614386893e-05,
      "loss": 0.002,
      "step": 43980
    },
    {
      "epoch": 3.753733253690588,
      "grad_norm": 0.04306831955909729,
      "learning_rate": 1.2462667463094122e-05,
      "loss": 0.0017,
      "step": 43990
    },
    {
      "epoch": 3.754586568819865,
      "grad_norm": 0.10865234583616257,
      "learning_rate": 1.2454134311801349e-05,
      "loss": 0.0019,
      "step": 44000
    },
    {
      "epoch": 3.7554398839491423,
      "grad_norm": 0.17761193215847015,
      "learning_rate": 1.2445601160508577e-05,
      "loss": 0.002,
      "step": 44010
    },
    {
      "epoch": 3.75629319907842,
      "grad_norm": 0.029599830508232117,
      "learning_rate": 1.2437068009215804e-05,
      "loss": 0.0018,
      "step": 44020
    },
    {
      "epoch": 3.757146514207697,
      "grad_norm": 0.19634373486042023,
      "learning_rate": 1.242853485792303e-05,
      "loss": 0.0018,
      "step": 44030
    },
    {
      "epoch": 3.757999829336974,
      "grad_norm": 0.1409258395433426,
      "learning_rate": 1.2420001706630259e-05,
      "loss": 0.0016,
      "step": 44040
    },
    {
      "epoch": 3.7588531444662516,
      "grad_norm": 0.10477399080991745,
      "learning_rate": 1.2411468555337488e-05,
      "loss": 0.0016,
      "step": 44050
    },
    {
      "epoch": 3.7597064595955287,
      "grad_norm": 0.029843803495168686,
      "learning_rate": 1.2402935404044714e-05,
      "loss": 0.002,
      "step": 44060
    },
    {
      "epoch": 3.760559774724806,
      "grad_norm": 0.4356920123100281,
      "learning_rate": 1.2394402252751943e-05,
      "loss": 0.0017,
      "step": 44070
    },
    {
      "epoch": 3.761413089854083,
      "grad_norm": 0.10325054824352264,
      "learning_rate": 1.2385869101459168e-05,
      "loss": 0.0018,
      "step": 44080
    },
    {
      "epoch": 3.7622664049833605,
      "grad_norm": 0.13713020086288452,
      "learning_rate": 1.2377335950166396e-05,
      "loss": 0.0018,
      "step": 44090
    },
    {
      "epoch": 3.7631197201126376,
      "grad_norm": 0.04194840416312218,
      "learning_rate": 1.2368802798873625e-05,
      "loss": 0.0022,
      "step": 44100
    },
    {
      "epoch": 3.7639730352419147,
      "grad_norm": 0.07409306615591049,
      "learning_rate": 1.2360269647580852e-05,
      "loss": 0.0018,
      "step": 44110
    },
    {
      "epoch": 3.764826350371192,
      "grad_norm": 0.12397316098213196,
      "learning_rate": 1.235173649628808e-05,
      "loss": 0.0018,
      "step": 44120
    },
    {
      "epoch": 3.7656796655004694,
      "grad_norm": 0.08186991512775421,
      "learning_rate": 1.2343203344995307e-05,
      "loss": 0.0018,
      "step": 44130
    },
    {
      "epoch": 3.7665329806297465,
      "grad_norm": 0.361919641494751,
      "learning_rate": 1.2334670193702535e-05,
      "loss": 0.0019,
      "step": 44140
    },
    {
      "epoch": 3.7673862957590236,
      "grad_norm": 0.1474122256040573,
      "learning_rate": 1.2326137042409762e-05,
      "loss": 0.0018,
      "step": 44150
    },
    {
      "epoch": 3.768239610888301,
      "grad_norm": 0.174872487783432,
      "learning_rate": 1.2317603891116989e-05,
      "loss": 0.0019,
      "step": 44160
    },
    {
      "epoch": 3.7690929260175783,
      "grad_norm": 0.19101271033287048,
      "learning_rate": 1.2309070739824218e-05,
      "loss": 0.0018,
      "step": 44170
    },
    {
      "epoch": 3.7699462411468554,
      "grad_norm": 0.11424616724252701,
      "learning_rate": 1.2300537588531446e-05,
      "loss": 0.002,
      "step": 44180
    },
    {
      "epoch": 3.770799556276133,
      "grad_norm": 0.04611900821328163,
      "learning_rate": 1.2292004437238673e-05,
      "loss": 0.0017,
      "step": 44190
    },
    {
      "epoch": 3.77165287140541,
      "grad_norm": 0.08929800242185593,
      "learning_rate": 1.2283471285945901e-05,
      "loss": 0.0019,
      "step": 44200
    },
    {
      "epoch": 3.772506186534687,
      "grad_norm": 0.11548743396997452,
      "learning_rate": 1.2274938134653128e-05,
      "loss": 0.0018,
      "step": 44210
    },
    {
      "epoch": 3.7733595016639647,
      "grad_norm": 0.07802997529506683,
      "learning_rate": 1.2266404983360355e-05,
      "loss": 0.0026,
      "step": 44220
    },
    {
      "epoch": 3.774212816793242,
      "grad_norm": 0.13053372502326965,
      "learning_rate": 1.2257871832067583e-05,
      "loss": 0.002,
      "step": 44230
    },
    {
      "epoch": 3.775066131922519,
      "grad_norm": 0.21304364502429962,
      "learning_rate": 1.224933868077481e-05,
      "loss": 0.0021,
      "step": 44240
    },
    {
      "epoch": 3.7759194470517965,
      "grad_norm": 0.20781084895133972,
      "learning_rate": 1.2240805529482039e-05,
      "loss": 0.0021,
      "step": 44250
    },
    {
      "epoch": 3.7767727621810736,
      "grad_norm": 0.1685725301504135,
      "learning_rate": 1.2232272378189265e-05,
      "loss": 0.0023,
      "step": 44260
    },
    {
      "epoch": 3.7776260773103507,
      "grad_norm": 0.21139520406723022,
      "learning_rate": 1.2223739226896494e-05,
      "loss": 0.0017,
      "step": 44270
    },
    {
      "epoch": 3.778479392439628,
      "grad_norm": 0.05445897579193115,
      "learning_rate": 1.221520607560372e-05,
      "loss": 0.0016,
      "step": 44280
    },
    {
      "epoch": 3.779332707568905,
      "grad_norm": 0.24738287925720215,
      "learning_rate": 1.2206672924310947e-05,
      "loss": 0.0022,
      "step": 44290
    },
    {
      "epoch": 3.7801860226981825,
      "grad_norm": 0.21526093780994415,
      "learning_rate": 1.2198139773018176e-05,
      "loss": 0.0021,
      "step": 44300
    },
    {
      "epoch": 3.7810393378274596,
      "grad_norm": 0.059795081615448,
      "learning_rate": 1.2189606621725404e-05,
      "loss": 0.0017,
      "step": 44310
    },
    {
      "epoch": 3.7818926529567367,
      "grad_norm": 0.12081723660230637,
      "learning_rate": 1.2181073470432631e-05,
      "loss": 0.0015,
      "step": 44320
    },
    {
      "epoch": 3.7827459680860143,
      "grad_norm": 0.20299285650253296,
      "learning_rate": 1.217254031913986e-05,
      "loss": 0.0016,
      "step": 44330
    },
    {
      "epoch": 3.7835992832152914,
      "grad_norm": 0.038286447525024414,
      "learning_rate": 1.2164007167847086e-05,
      "loss": 0.0014,
      "step": 44340
    },
    {
      "epoch": 3.7844525983445685,
      "grad_norm": 0.2760193645954132,
      "learning_rate": 1.2155474016554313e-05,
      "loss": 0.0014,
      "step": 44350
    },
    {
      "epoch": 3.785305913473846,
      "grad_norm": 0.04025751352310181,
      "learning_rate": 1.2146940865261542e-05,
      "loss": 0.0018,
      "step": 44360
    },
    {
      "epoch": 3.786159228603123,
      "grad_norm": 0.23206727206707,
      "learning_rate": 1.2138407713968769e-05,
      "loss": 0.0018,
      "step": 44370
    },
    {
      "epoch": 3.7870125437324003,
      "grad_norm": 0.15462669730186462,
      "learning_rate": 1.2129874562675997e-05,
      "loss": 0.002,
      "step": 44380
    },
    {
      "epoch": 3.787865858861678,
      "grad_norm": 0.15822193026542664,
      "learning_rate": 1.2121341411383224e-05,
      "loss": 0.0019,
      "step": 44390
    },
    {
      "epoch": 3.788719173990955,
      "grad_norm": 0.13818112015724182,
      "learning_rate": 1.2112808260090452e-05,
      "loss": 0.0017,
      "step": 44400
    },
    {
      "epoch": 3.789572489120232,
      "grad_norm": 0.21336427330970764,
      "learning_rate": 1.210427510879768e-05,
      "loss": 0.0019,
      "step": 44410
    },
    {
      "epoch": 3.7904258042495096,
      "grad_norm": 0.06581731140613556,
      "learning_rate": 1.2095741957504906e-05,
      "loss": 0.0017,
      "step": 44420
    },
    {
      "epoch": 3.7912791193787867,
      "grad_norm": 0.09783139079809189,
      "learning_rate": 1.2087208806212134e-05,
      "loss": 0.002,
      "step": 44430
    },
    {
      "epoch": 3.792132434508064,
      "grad_norm": 0.11313804239034653,
      "learning_rate": 1.2078675654919363e-05,
      "loss": 0.0015,
      "step": 44440
    },
    {
      "epoch": 3.792985749637341,
      "grad_norm": 0.21591170132160187,
      "learning_rate": 1.207014250362659e-05,
      "loss": 0.0022,
      "step": 44450
    },
    {
      "epoch": 3.7938390647666185,
      "grad_norm": 0.21366922557353973,
      "learning_rate": 1.2061609352333818e-05,
      "loss": 0.0014,
      "step": 44460
    },
    {
      "epoch": 3.7946923798958956,
      "grad_norm": 0.32208284735679626,
      "learning_rate": 1.2053076201041045e-05,
      "loss": 0.0017,
      "step": 44470
    },
    {
      "epoch": 3.7955456950251727,
      "grad_norm": 0.21867451071739197,
      "learning_rate": 1.2044543049748272e-05,
      "loss": 0.0019,
      "step": 44480
    },
    {
      "epoch": 3.79639901015445,
      "grad_norm": 0.1072697639465332,
      "learning_rate": 1.20360098984555e-05,
      "loss": 0.002,
      "step": 44490
    },
    {
      "epoch": 3.7972523252837274,
      "grad_norm": 0.05794331431388855,
      "learning_rate": 1.2027476747162727e-05,
      "loss": 0.0022,
      "step": 44500
    },
    {
      "epoch": 3.7981056404130045,
      "grad_norm": 0.04594358801841736,
      "learning_rate": 1.2018943595869955e-05,
      "loss": 0.0018,
      "step": 44510
    },
    {
      "epoch": 3.7989589555422816,
      "grad_norm": 0.1904502809047699,
      "learning_rate": 1.2010410444577184e-05,
      "loss": 0.0018,
      "step": 44520
    },
    {
      "epoch": 3.799812270671559,
      "grad_norm": 0.32681986689567566,
      "learning_rate": 1.200187729328441e-05,
      "loss": 0.0017,
      "step": 44530
    },
    {
      "epoch": 3.8006655858008362,
      "grad_norm": 0.04708155617117882,
      "learning_rate": 1.199334414199164e-05,
      "loss": 0.002,
      "step": 44540
    },
    {
      "epoch": 3.8015189009301134,
      "grad_norm": 0.23628085851669312,
      "learning_rate": 1.1984810990698864e-05,
      "loss": 0.0017,
      "step": 44550
    },
    {
      "epoch": 3.802372216059391,
      "grad_norm": 0.13644249737262726,
      "learning_rate": 1.1976277839406093e-05,
      "loss": 0.0023,
      "step": 44560
    },
    {
      "epoch": 3.803225531188668,
      "grad_norm": 0.10349147766828537,
      "learning_rate": 1.1967744688113321e-05,
      "loss": 0.0021,
      "step": 44570
    },
    {
      "epoch": 3.804078846317945,
      "grad_norm": 0.0723041445016861,
      "learning_rate": 1.1959211536820548e-05,
      "loss": 0.0013,
      "step": 44580
    },
    {
      "epoch": 3.8049321614472227,
      "grad_norm": 0.15941934287548065,
      "learning_rate": 1.1950678385527777e-05,
      "loss": 0.0017,
      "step": 44590
    },
    {
      "epoch": 3.8057854765765,
      "grad_norm": 0.2090175598859787,
      "learning_rate": 1.1942145234235003e-05,
      "loss": 0.0026,
      "step": 44600
    },
    {
      "epoch": 3.806638791705777,
      "grad_norm": 0.26829153299331665,
      "learning_rate": 1.1933612082942232e-05,
      "loss": 0.0022,
      "step": 44610
    },
    {
      "epoch": 3.8074921068350545,
      "grad_norm": 0.2634485065937042,
      "learning_rate": 1.1925078931649459e-05,
      "loss": 0.0022,
      "step": 44620
    },
    {
      "epoch": 3.8083454219643316,
      "grad_norm": 0.09355895221233368,
      "learning_rate": 1.1916545780356685e-05,
      "loss": 0.002,
      "step": 44630
    },
    {
      "epoch": 3.8091987370936087,
      "grad_norm": 0.2109563648700714,
      "learning_rate": 1.1908012629063914e-05,
      "loss": 0.0017,
      "step": 44640
    },
    {
      "epoch": 3.810052052222886,
      "grad_norm": 0.06748627871274948,
      "learning_rate": 1.1899479477771142e-05,
      "loss": 0.0021,
      "step": 44650
    },
    {
      "epoch": 3.810905367352163,
      "grad_norm": 0.15150903165340424,
      "learning_rate": 1.1890946326478369e-05,
      "loss": 0.0018,
      "step": 44660
    },
    {
      "epoch": 3.8117586824814405,
      "grad_norm": 0.33957478404045105,
      "learning_rate": 1.1882413175185598e-05,
      "loss": 0.0015,
      "step": 44670
    },
    {
      "epoch": 3.8126119976107176,
      "grad_norm": 0.04916420578956604,
      "learning_rate": 1.1873880023892824e-05,
      "loss": 0.0017,
      "step": 44680
    },
    {
      "epoch": 3.8134653127399947,
      "grad_norm": 0.20620359480381012,
      "learning_rate": 1.1865346872600051e-05,
      "loss": 0.0015,
      "step": 44690
    },
    {
      "epoch": 3.8143186278692722,
      "grad_norm": 0.09283629804849625,
      "learning_rate": 1.185681372130728e-05,
      "loss": 0.0017,
      "step": 44700
    },
    {
      "epoch": 3.8151719429985493,
      "grad_norm": 0.1326683908700943,
      "learning_rate": 1.1848280570014506e-05,
      "loss": 0.0015,
      "step": 44710
    },
    {
      "epoch": 3.8160252581278264,
      "grad_norm": 0.38835668563842773,
      "learning_rate": 1.1839747418721735e-05,
      "loss": 0.0018,
      "step": 44720
    },
    {
      "epoch": 3.816878573257104,
      "grad_norm": 0.15681254863739014,
      "learning_rate": 1.1831214267428962e-05,
      "loss": 0.0018,
      "step": 44730
    },
    {
      "epoch": 3.817731888386381,
      "grad_norm": 0.19959449768066406,
      "learning_rate": 1.182268111613619e-05,
      "loss": 0.0019,
      "step": 44740
    },
    {
      "epoch": 3.818585203515658,
      "grad_norm": 0.22784429788589478,
      "learning_rate": 1.1814147964843417e-05,
      "loss": 0.0023,
      "step": 44750
    },
    {
      "epoch": 3.8194385186449358,
      "grad_norm": 0.050984591245651245,
      "learning_rate": 1.1805614813550644e-05,
      "loss": 0.0017,
      "step": 44760
    },
    {
      "epoch": 3.820291833774213,
      "grad_norm": 0.1098848432302475,
      "learning_rate": 1.1797081662257872e-05,
      "loss": 0.0021,
      "step": 44770
    },
    {
      "epoch": 3.82114514890349,
      "grad_norm": 0.24220921099185944,
      "learning_rate": 1.17885485109651e-05,
      "loss": 0.0021,
      "step": 44780
    },
    {
      "epoch": 3.8219984640327676,
      "grad_norm": 0.16977089643478394,
      "learning_rate": 1.1780015359672328e-05,
      "loss": 0.0017,
      "step": 44790
    },
    {
      "epoch": 3.8228517791620447,
      "grad_norm": 0.32507824897766113,
      "learning_rate": 1.1771482208379556e-05,
      "loss": 0.0016,
      "step": 44800
    },
    {
      "epoch": 3.8237050942913218,
      "grad_norm": 0.2830860912799835,
      "learning_rate": 1.1762949057086783e-05,
      "loss": 0.0015,
      "step": 44810
    },
    {
      "epoch": 3.824558409420599,
      "grad_norm": 0.04481196030974388,
      "learning_rate": 1.175441590579401e-05,
      "loss": 0.0026,
      "step": 44820
    },
    {
      "epoch": 3.8254117245498764,
      "grad_norm": 0.042415551841259,
      "learning_rate": 1.1745882754501238e-05,
      "loss": 0.0024,
      "step": 44830
    },
    {
      "epoch": 3.8262650396791535,
      "grad_norm": 0.07038702815771103,
      "learning_rate": 1.1737349603208465e-05,
      "loss": 0.0022,
      "step": 44840
    },
    {
      "epoch": 3.8271183548084307,
      "grad_norm": 0.32216376066207886,
      "learning_rate": 1.1728816451915693e-05,
      "loss": 0.002,
      "step": 44850
    },
    {
      "epoch": 3.8279716699377078,
      "grad_norm": 0.11820206046104431,
      "learning_rate": 1.172028330062292e-05,
      "loss": 0.0024,
      "step": 44860
    },
    {
      "epoch": 3.8288249850669853,
      "grad_norm": 0.04523646458983421,
      "learning_rate": 1.1711750149330149e-05,
      "loss": 0.002,
      "step": 44870
    },
    {
      "epoch": 3.8296783001962624,
      "grad_norm": 0.17981098592281342,
      "learning_rate": 1.1703216998037375e-05,
      "loss": 0.0021,
      "step": 44880
    },
    {
      "epoch": 3.8305316153255395,
      "grad_norm": 0.09353725612163544,
      "learning_rate": 1.1694683846744602e-05,
      "loss": 0.0018,
      "step": 44890
    },
    {
      "epoch": 3.831384930454817,
      "grad_norm": 0.1315874457359314,
      "learning_rate": 1.168615069545183e-05,
      "loss": 0.0019,
      "step": 44900
    },
    {
      "epoch": 3.832238245584094,
      "grad_norm": 0.24814260005950928,
      "learning_rate": 1.1677617544159059e-05,
      "loss": 0.0017,
      "step": 44910
    },
    {
      "epoch": 3.8330915607133713,
      "grad_norm": 0.09758078306913376,
      "learning_rate": 1.1669084392866286e-05,
      "loss": 0.0023,
      "step": 44920
    },
    {
      "epoch": 3.833944875842649,
      "grad_norm": 0.09765034914016724,
      "learning_rate": 1.1660551241573514e-05,
      "loss": 0.0018,
      "step": 44930
    },
    {
      "epoch": 3.834798190971926,
      "grad_norm": 0.1962674856185913,
      "learning_rate": 1.1652018090280741e-05,
      "loss": 0.0022,
      "step": 44940
    },
    {
      "epoch": 3.835651506101203,
      "grad_norm": 0.1876717209815979,
      "learning_rate": 1.1643484938987968e-05,
      "loss": 0.0023,
      "step": 44950
    },
    {
      "epoch": 3.8365048212304806,
      "grad_norm": 0.15767496824264526,
      "learning_rate": 1.1634951787695196e-05,
      "loss": 0.0021,
      "step": 44960
    },
    {
      "epoch": 3.8373581363597578,
      "grad_norm": 0.12931586802005768,
      "learning_rate": 1.1626418636402423e-05,
      "loss": 0.0022,
      "step": 44970
    },
    {
      "epoch": 3.838211451489035,
      "grad_norm": 0.13746246695518494,
      "learning_rate": 1.1617885485109652e-05,
      "loss": 0.002,
      "step": 44980
    },
    {
      "epoch": 3.8390647666183124,
      "grad_norm": 0.06451266258955002,
      "learning_rate": 1.160935233381688e-05,
      "loss": 0.0015,
      "step": 44990
    },
    {
      "epoch": 3.8399180817475895,
      "grad_norm": 0.19936516880989075,
      "learning_rate": 1.1600819182524107e-05,
      "loss": 0.002,
      "step": 45000
    },
    {
      "epoch": 3.8407713968768666,
      "grad_norm": 0.11720418184995651,
      "learning_rate": 1.1592286031231334e-05,
      "loss": 0.0017,
      "step": 45010
    },
    {
      "epoch": 3.8416247120061437,
      "grad_norm": 0.2969854176044464,
      "learning_rate": 1.158375287993856e-05,
      "loss": 0.0016,
      "step": 45020
    },
    {
      "epoch": 3.842478027135421,
      "grad_norm": 0.2423674315214157,
      "learning_rate": 1.1575219728645789e-05,
      "loss": 0.0019,
      "step": 45030
    },
    {
      "epoch": 3.8433313422646984,
      "grad_norm": 0.35114380717277527,
      "learning_rate": 1.1566686577353018e-05,
      "loss": 0.0018,
      "step": 45040
    },
    {
      "epoch": 3.8441846573939755,
      "grad_norm": 0.2844613194465637,
      "learning_rate": 1.1558153426060244e-05,
      "loss": 0.0018,
      "step": 45050
    },
    {
      "epoch": 3.8450379725232526,
      "grad_norm": 0.1009950265288353,
      "learning_rate": 1.1549620274767473e-05,
      "loss": 0.002,
      "step": 45060
    },
    {
      "epoch": 3.84589128765253,
      "grad_norm": 0.2081001251935959,
      "learning_rate": 1.15410871234747e-05,
      "loss": 0.0019,
      "step": 45070
    },
    {
      "epoch": 3.8467446027818073,
      "grad_norm": 0.25630703568458557,
      "learning_rate": 1.1532553972181926e-05,
      "loss": 0.0017,
      "step": 45080
    },
    {
      "epoch": 3.8475979179110844,
      "grad_norm": 0.32539865374565125,
      "learning_rate": 1.1524020820889155e-05,
      "loss": 0.0016,
      "step": 45090
    },
    {
      "epoch": 3.848451233040362,
      "grad_norm": 0.0892043188214302,
      "learning_rate": 1.1515487669596382e-05,
      "loss": 0.0018,
      "step": 45100
    },
    {
      "epoch": 3.849304548169639,
      "grad_norm": 0.1388222575187683,
      "learning_rate": 1.150695451830361e-05,
      "loss": 0.0021,
      "step": 45110
    },
    {
      "epoch": 3.850157863298916,
      "grad_norm": 0.08647745102643967,
      "learning_rate": 1.1498421367010839e-05,
      "loss": 0.0022,
      "step": 45120
    },
    {
      "epoch": 3.8510111784281937,
      "grad_norm": 0.06263905018568039,
      "learning_rate": 1.1489888215718065e-05,
      "loss": 0.0022,
      "step": 45130
    },
    {
      "epoch": 3.851864493557471,
      "grad_norm": 0.11733204871416092,
      "learning_rate": 1.1481355064425294e-05,
      "loss": 0.0017,
      "step": 45140
    },
    {
      "epoch": 3.852717808686748,
      "grad_norm": 0.3236220180988312,
      "learning_rate": 1.147282191313252e-05,
      "loss": 0.0022,
      "step": 45150
    },
    {
      "epoch": 3.8535711238160255,
      "grad_norm": 0.06269585341215134,
      "learning_rate": 1.1464288761839747e-05,
      "loss": 0.0017,
      "step": 45160
    },
    {
      "epoch": 3.8544244389453026,
      "grad_norm": 0.15894560515880585,
      "learning_rate": 1.1455755610546976e-05,
      "loss": 0.002,
      "step": 45170
    },
    {
      "epoch": 3.8552777540745797,
      "grad_norm": 0.1967034786939621,
      "learning_rate": 1.1447222459254203e-05,
      "loss": 0.0017,
      "step": 45180
    },
    {
      "epoch": 3.856131069203857,
      "grad_norm": 0.24962756037712097,
      "learning_rate": 1.1438689307961431e-05,
      "loss": 0.002,
      "step": 45190
    },
    {
      "epoch": 3.856984384333134,
      "grad_norm": 0.05369551479816437,
      "learning_rate": 1.1430156156668658e-05,
      "loss": 0.0016,
      "step": 45200
    },
    {
      "epoch": 3.8578376994624115,
      "grad_norm": 0.17701999843120575,
      "learning_rate": 1.1421623005375885e-05,
      "loss": 0.0019,
      "step": 45210
    },
    {
      "epoch": 3.8586910145916886,
      "grad_norm": 0.06397508829832077,
      "learning_rate": 1.1413089854083113e-05,
      "loss": 0.0019,
      "step": 45220
    },
    {
      "epoch": 3.8595443297209657,
      "grad_norm": 0.044752053916454315,
      "learning_rate": 1.140455670279034e-05,
      "loss": 0.0015,
      "step": 45230
    },
    {
      "epoch": 3.8603976448502433,
      "grad_norm": 0.24492579698562622,
      "learning_rate": 1.1396023551497569e-05,
      "loss": 0.0017,
      "step": 45240
    },
    {
      "epoch": 3.8612509599795204,
      "grad_norm": 0.08531785756349564,
      "learning_rate": 1.1387490400204797e-05,
      "loss": 0.002,
      "step": 45250
    },
    {
      "epoch": 3.8621042751087975,
      "grad_norm": 0.2620885670185089,
      "learning_rate": 1.1378957248912024e-05,
      "loss": 0.0022,
      "step": 45260
    },
    {
      "epoch": 3.862957590238075,
      "grad_norm": 0.14802515506744385,
      "learning_rate": 1.1370424097619252e-05,
      "loss": 0.0013,
      "step": 45270
    },
    {
      "epoch": 3.863810905367352,
      "grad_norm": 0.3294457495212555,
      "learning_rate": 1.1361890946326479e-05,
      "loss": 0.0017,
      "step": 45280
    },
    {
      "epoch": 3.8646642204966293,
      "grad_norm": 0.047942306846380234,
      "learning_rate": 1.1353357795033706e-05,
      "loss": 0.0013,
      "step": 45290
    },
    {
      "epoch": 3.865517535625907,
      "grad_norm": 0.2259063869714737,
      "learning_rate": 1.1344824643740934e-05,
      "loss": 0.0017,
      "step": 45300
    },
    {
      "epoch": 3.866370850755184,
      "grad_norm": 0.09553468972444534,
      "learning_rate": 1.1336291492448161e-05,
      "loss": 0.0014,
      "step": 45310
    },
    {
      "epoch": 3.867224165884461,
      "grad_norm": 0.11763909459114075,
      "learning_rate": 1.132775834115539e-05,
      "loss": 0.0023,
      "step": 45320
    },
    {
      "epoch": 3.8680774810137386,
      "grad_norm": 0.10698315501213074,
      "learning_rate": 1.1319225189862616e-05,
      "loss": 0.0013,
      "step": 45330
    },
    {
      "epoch": 3.8689307961430157,
      "grad_norm": 0.20525334775447845,
      "learning_rate": 1.1310692038569845e-05,
      "loss": 0.0021,
      "step": 45340
    },
    {
      "epoch": 3.869784111272293,
      "grad_norm": 0.2202569544315338,
      "learning_rate": 1.1302158887277072e-05,
      "loss": 0.0021,
      "step": 45350
    },
    {
      "epoch": 3.87063742640157,
      "grad_norm": 0.30397212505340576,
      "learning_rate": 1.1293625735984298e-05,
      "loss": 0.0016,
      "step": 45360
    },
    {
      "epoch": 3.8714907415308475,
      "grad_norm": 0.31444746255874634,
      "learning_rate": 1.1285092584691527e-05,
      "loss": 0.0018,
      "step": 45370
    },
    {
      "epoch": 3.8723440566601246,
      "grad_norm": 0.118988536298275,
      "learning_rate": 1.1276559433398755e-05,
      "loss": 0.0018,
      "step": 45380
    },
    {
      "epoch": 3.8731973717894017,
      "grad_norm": 0.028655564412474632,
      "learning_rate": 1.1268026282105982e-05,
      "loss": 0.0016,
      "step": 45390
    },
    {
      "epoch": 3.874050686918679,
      "grad_norm": 0.08371862769126892,
      "learning_rate": 1.125949313081321e-05,
      "loss": 0.0017,
      "step": 45400
    },
    {
      "epoch": 3.8749040020479564,
      "grad_norm": 0.21182802319526672,
      "learning_rate": 1.1250959979520438e-05,
      "loss": 0.0022,
      "step": 45410
    },
    {
      "epoch": 3.8757573171772335,
      "grad_norm": 0.15695230662822723,
      "learning_rate": 1.1242426828227664e-05,
      "loss": 0.0017,
      "step": 45420
    },
    {
      "epoch": 3.8766106323065106,
      "grad_norm": 0.1148964911699295,
      "learning_rate": 1.1233893676934893e-05,
      "loss": 0.0021,
      "step": 45430
    },
    {
      "epoch": 3.877463947435788,
      "grad_norm": 0.1280268281698227,
      "learning_rate": 1.122536052564212e-05,
      "loss": 0.0017,
      "step": 45440
    },
    {
      "epoch": 3.8783172625650653,
      "grad_norm": 0.32909566164016724,
      "learning_rate": 1.1216827374349348e-05,
      "loss": 0.002,
      "step": 45450
    },
    {
      "epoch": 3.8791705776943424,
      "grad_norm": 0.07979752868413925,
      "learning_rate": 1.1208294223056577e-05,
      "loss": 0.0016,
      "step": 45460
    },
    {
      "epoch": 3.88002389282362,
      "grad_norm": 0.16062365472316742,
      "learning_rate": 1.1199761071763803e-05,
      "loss": 0.0016,
      "step": 45470
    },
    {
      "epoch": 3.880877207952897,
      "grad_norm": 0.0958518236875534,
      "learning_rate": 1.119122792047103e-05,
      "loss": 0.0015,
      "step": 45480
    },
    {
      "epoch": 3.881730523082174,
      "grad_norm": 0.056170523166656494,
      "learning_rate": 1.1182694769178257e-05,
      "loss": 0.0019,
      "step": 45490
    },
    {
      "epoch": 3.8825838382114517,
      "grad_norm": 0.31345561146736145,
      "learning_rate": 1.1174161617885485e-05,
      "loss": 0.0019,
      "step": 45500
    },
    {
      "epoch": 3.883437153340729,
      "grad_norm": 0.1232437789440155,
      "learning_rate": 1.1165628466592714e-05,
      "loss": 0.0021,
      "step": 45510
    },
    {
      "epoch": 3.884290468470006,
      "grad_norm": 0.1599908173084259,
      "learning_rate": 1.115709531529994e-05,
      "loss": 0.0021,
      "step": 45520
    },
    {
      "epoch": 3.8851437835992835,
      "grad_norm": 0.2091284543275833,
      "learning_rate": 1.1148562164007169e-05,
      "loss": 0.0025,
      "step": 45530
    },
    {
      "epoch": 3.8859970987285606,
      "grad_norm": 0.049637798219919205,
      "learning_rate": 1.1140029012714396e-05,
      "loss": 0.0019,
      "step": 45540
    },
    {
      "epoch": 3.8868504138578377,
      "grad_norm": 0.530138373374939,
      "learning_rate": 1.1131495861421623e-05,
      "loss": 0.0014,
      "step": 45550
    },
    {
      "epoch": 3.887703728987115,
      "grad_norm": 0.2655985653400421,
      "learning_rate": 1.1122962710128851e-05,
      "loss": 0.0021,
      "step": 45560
    },
    {
      "epoch": 3.888557044116392,
      "grad_norm": 0.2915019690990448,
      "learning_rate": 1.1114429558836078e-05,
      "loss": 0.0017,
      "step": 45570
    },
    {
      "epoch": 3.8894103592456695,
      "grad_norm": 0.1458016335964203,
      "learning_rate": 1.1105896407543306e-05,
      "loss": 0.0015,
      "step": 45580
    },
    {
      "epoch": 3.8902636743749466,
      "grad_norm": 0.04961076378822327,
      "learning_rate": 1.1097363256250535e-05,
      "loss": 0.0028,
      "step": 45590
    },
    {
      "epoch": 3.8911169895042237,
      "grad_norm": 0.24727532267570496,
      "learning_rate": 1.1088830104957762e-05,
      "loss": 0.0015,
      "step": 45600
    },
    {
      "epoch": 3.8919703046335012,
      "grad_norm": 0.25503674149513245,
      "learning_rate": 1.1080296953664989e-05,
      "loss": 0.0021,
      "step": 45610
    },
    {
      "epoch": 3.8928236197627784,
      "grad_norm": 0.13595904409885406,
      "learning_rate": 1.1071763802372217e-05,
      "loss": 0.0021,
      "step": 45620
    },
    {
      "epoch": 3.8936769348920555,
      "grad_norm": 0.17551055550575256,
      "learning_rate": 1.1063230651079444e-05,
      "loss": 0.0019,
      "step": 45630
    },
    {
      "epoch": 3.894530250021333,
      "grad_norm": 0.05741118639707565,
      "learning_rate": 1.1054697499786672e-05,
      "loss": 0.002,
      "step": 45640
    },
    {
      "epoch": 3.89538356515061,
      "grad_norm": 0.4956730306148529,
      "learning_rate": 1.1046164348493899e-05,
      "loss": 0.002,
      "step": 45650
    },
    {
      "epoch": 3.8962368802798872,
      "grad_norm": 0.436535507440567,
      "learning_rate": 1.1037631197201128e-05,
      "loss": 0.0024,
      "step": 45660
    },
    {
      "epoch": 3.897090195409165,
      "grad_norm": 0.2571478486061096,
      "learning_rate": 1.1029098045908354e-05,
      "loss": 0.0018,
      "step": 45670
    },
    {
      "epoch": 3.897943510538442,
      "grad_norm": 0.11189701408147812,
      "learning_rate": 1.1020564894615581e-05,
      "loss": 0.0024,
      "step": 45680
    },
    {
      "epoch": 3.898796825667719,
      "grad_norm": 0.36890941858291626,
      "learning_rate": 1.101203174332281e-05,
      "loss": 0.0022,
      "step": 45690
    },
    {
      "epoch": 3.8996501407969966,
      "grad_norm": 0.3933425843715668,
      "learning_rate": 1.1003498592030036e-05,
      "loss": 0.0021,
      "step": 45700
    },
    {
      "epoch": 3.9005034559262737,
      "grad_norm": 0.11250955611467361,
      "learning_rate": 1.0994965440737265e-05,
      "loss": 0.0019,
      "step": 45710
    },
    {
      "epoch": 3.901356771055551,
      "grad_norm": 0.40557608008384705,
      "learning_rate": 1.0986432289444493e-05,
      "loss": 0.0016,
      "step": 45720
    },
    {
      "epoch": 3.902210086184828,
      "grad_norm": 0.062590591609478,
      "learning_rate": 1.097789913815172e-05,
      "loss": 0.0019,
      "step": 45730
    },
    {
      "epoch": 3.9030634013141055,
      "grad_norm": 0.09888904541730881,
      "learning_rate": 1.0969365986858947e-05,
      "loss": 0.0016,
      "step": 45740
    },
    {
      "epoch": 3.9039167164433826,
      "grad_norm": 0.08127252012491226,
      "learning_rate": 1.0960832835566175e-05,
      "loss": 0.0025,
      "step": 45750
    },
    {
      "epoch": 3.9047700315726597,
      "grad_norm": 0.09483706206083298,
      "learning_rate": 1.0952299684273402e-05,
      "loss": 0.0017,
      "step": 45760
    },
    {
      "epoch": 3.905623346701937,
      "grad_norm": 0.415254145860672,
      "learning_rate": 1.094376653298063e-05,
      "loss": 0.0017,
      "step": 45770
    },
    {
      "epoch": 3.9064766618312143,
      "grad_norm": 0.3369053900241852,
      "learning_rate": 1.0935233381687857e-05,
      "loss": 0.0021,
      "step": 45780
    },
    {
      "epoch": 3.9073299769604914,
      "grad_norm": 0.16922108829021454,
      "learning_rate": 1.0926700230395086e-05,
      "loss": 0.0017,
      "step": 45790
    },
    {
      "epoch": 3.9081832920897686,
      "grad_norm": 0.1558363437652588,
      "learning_rate": 1.0918167079102313e-05,
      "loss": 0.0018,
      "step": 45800
    },
    {
      "epoch": 3.909036607219046,
      "grad_norm": 0.3552726209163666,
      "learning_rate": 1.090963392780954e-05,
      "loss": 0.0018,
      "step": 45810
    },
    {
      "epoch": 3.909889922348323,
      "grad_norm": 0.05221829190850258,
      "learning_rate": 1.0901100776516768e-05,
      "loss": 0.0022,
      "step": 45820
    },
    {
      "epoch": 3.9107432374776003,
      "grad_norm": 0.052132390439510345,
      "learning_rate": 1.0892567625223995e-05,
      "loss": 0.0019,
      "step": 45830
    },
    {
      "epoch": 3.911596552606878,
      "grad_norm": 0.08019976317882538,
      "learning_rate": 1.0884034473931223e-05,
      "loss": 0.0019,
      "step": 45840
    },
    {
      "epoch": 3.912449867736155,
      "grad_norm": 0.1616745889186859,
      "learning_rate": 1.0875501322638452e-05,
      "loss": 0.0019,
      "step": 45850
    },
    {
      "epoch": 3.913303182865432,
      "grad_norm": 0.05106035992503166,
      "learning_rate": 1.0866968171345679e-05,
      "loss": 0.0018,
      "step": 45860
    },
    {
      "epoch": 3.9141564979947097,
      "grad_norm": 0.3354564905166626,
      "learning_rate": 1.0858435020052907e-05,
      "loss": 0.002,
      "step": 45870
    },
    {
      "epoch": 3.9150098131239868,
      "grad_norm": 0.06233171373605728,
      "learning_rate": 1.0849901868760134e-05,
      "loss": 0.0016,
      "step": 45880
    },
    {
      "epoch": 3.915863128253264,
      "grad_norm": 0.13984039425849915,
      "learning_rate": 1.084136871746736e-05,
      "loss": 0.0022,
      "step": 45890
    },
    {
      "epoch": 3.9167164433825414,
      "grad_norm": 0.03342285379767418,
      "learning_rate": 1.0832835566174589e-05,
      "loss": 0.0017,
      "step": 45900
    },
    {
      "epoch": 3.9175697585118185,
      "grad_norm": 0.09873601049184799,
      "learning_rate": 1.0824302414881816e-05,
      "loss": 0.0015,
      "step": 45910
    },
    {
      "epoch": 3.9184230736410957,
      "grad_norm": 0.09767544269561768,
      "learning_rate": 1.0815769263589044e-05,
      "loss": 0.0017,
      "step": 45920
    },
    {
      "epoch": 3.9192763887703728,
      "grad_norm": 0.14042137563228607,
      "learning_rate": 1.0807236112296273e-05,
      "loss": 0.0016,
      "step": 45930
    },
    {
      "epoch": 3.92012970389965,
      "grad_norm": 0.187223881483078,
      "learning_rate": 1.0798702961003498e-05,
      "loss": 0.0017,
      "step": 45940
    },
    {
      "epoch": 3.9209830190289274,
      "grad_norm": 0.1443214863538742,
      "learning_rate": 1.0790169809710726e-05,
      "loss": 0.0017,
      "step": 45950
    },
    {
      "epoch": 3.9218363341582045,
      "grad_norm": 0.058050256222486496,
      "learning_rate": 1.0781636658417953e-05,
      "loss": 0.0016,
      "step": 45960
    },
    {
      "epoch": 3.9226896492874817,
      "grad_norm": 0.3201320767402649,
      "learning_rate": 1.0773103507125182e-05,
      "loss": 0.0018,
      "step": 45970
    },
    {
      "epoch": 3.923542964416759,
      "grad_norm": 0.25606679916381836,
      "learning_rate": 1.076457035583241e-05,
      "loss": 0.0018,
      "step": 45980
    },
    {
      "epoch": 3.9243962795460363,
      "grad_norm": 0.07740070670843124,
      "learning_rate": 1.0756037204539637e-05,
      "loss": 0.0017,
      "step": 45990
    },
    {
      "epoch": 3.9252495946753134,
      "grad_norm": 0.19079355895519257,
      "learning_rate": 1.0747504053246865e-05,
      "loss": 0.0015,
      "step": 46000
    },
    {
      "epoch": 3.926102909804591,
      "grad_norm": 0.14281302690505981,
      "learning_rate": 1.0738970901954092e-05,
      "loss": 0.0021,
      "step": 46010
    },
    {
      "epoch": 3.926956224933868,
      "grad_norm": 0.1528877317905426,
      "learning_rate": 1.0730437750661319e-05,
      "loss": 0.0017,
      "step": 46020
    },
    {
      "epoch": 3.927809540063145,
      "grad_norm": 0.0760754719376564,
      "learning_rate": 1.0721904599368547e-05,
      "loss": 0.002,
      "step": 46030
    },
    {
      "epoch": 3.9286628551924228,
      "grad_norm": 0.14040204882621765,
      "learning_rate": 1.0713371448075774e-05,
      "loss": 0.0016,
      "step": 46040
    },
    {
      "epoch": 3.9295161703217,
      "grad_norm": 0.13580068945884705,
      "learning_rate": 1.0704838296783003e-05,
      "loss": 0.0019,
      "step": 46050
    },
    {
      "epoch": 3.930369485450977,
      "grad_norm": 0.16018004715442657,
      "learning_rate": 1.0696305145490231e-05,
      "loss": 0.0017,
      "step": 46060
    },
    {
      "epoch": 3.9312228005802545,
      "grad_norm": 0.15607285499572754,
      "learning_rate": 1.0687771994197458e-05,
      "loss": 0.0016,
      "step": 46070
    },
    {
      "epoch": 3.9320761157095316,
      "grad_norm": 0.28840482234954834,
      "learning_rate": 1.0679238842904685e-05,
      "loss": 0.0019,
      "step": 46080
    },
    {
      "epoch": 3.9329294308388087,
      "grad_norm": 0.10776235908269882,
      "learning_rate": 1.0670705691611913e-05,
      "loss": 0.0016,
      "step": 46090
    },
    {
      "epoch": 3.933782745968086,
      "grad_norm": 0.21093547344207764,
      "learning_rate": 1.066217254031914e-05,
      "loss": 0.0018,
      "step": 46100
    },
    {
      "epoch": 3.9346360610973634,
      "grad_norm": 0.22658495604991913,
      "learning_rate": 1.0653639389026369e-05,
      "loss": 0.0024,
      "step": 46110
    },
    {
      "epoch": 3.9354893762266405,
      "grad_norm": 0.047375503927469254,
      "learning_rate": 1.0645106237733595e-05,
      "loss": 0.0022,
      "step": 46120
    },
    {
      "epoch": 3.9363426913559176,
      "grad_norm": 0.1422835886478424,
      "learning_rate": 1.0636573086440824e-05,
      "loss": 0.0023,
      "step": 46130
    },
    {
      "epoch": 3.9371960064851947,
      "grad_norm": 0.35615280270576477,
      "learning_rate": 1.062803993514805e-05,
      "loss": 0.002,
      "step": 46140
    },
    {
      "epoch": 3.9380493216144723,
      "grad_norm": 0.0793546736240387,
      "learning_rate": 1.0619506783855277e-05,
      "loss": 0.0017,
      "step": 46150
    },
    {
      "epoch": 3.9389026367437494,
      "grad_norm": 0.26722878217697144,
      "learning_rate": 1.0610973632562506e-05,
      "loss": 0.0024,
      "step": 46160
    },
    {
      "epoch": 3.9397559518730265,
      "grad_norm": 0.29676124453544617,
      "learning_rate": 1.0602440481269733e-05,
      "loss": 0.0022,
      "step": 46170
    },
    {
      "epoch": 3.940609267002304,
      "grad_norm": 0.21155397593975067,
      "learning_rate": 1.0593907329976961e-05,
      "loss": 0.0019,
      "step": 46180
    },
    {
      "epoch": 3.941462582131581,
      "grad_norm": 0.17569313943386078,
      "learning_rate": 1.058537417868419e-05,
      "loss": 0.0023,
      "step": 46190
    },
    {
      "epoch": 3.9423158972608583,
      "grad_norm": 0.28669923543930054,
      "learning_rate": 1.0576841027391416e-05,
      "loss": 0.0021,
      "step": 46200
    },
    {
      "epoch": 3.943169212390136,
      "grad_norm": 0.30443060398101807,
      "learning_rate": 1.0568307876098643e-05,
      "loss": 0.0019,
      "step": 46210
    },
    {
      "epoch": 3.944022527519413,
      "grad_norm": 0.0677594318985939,
      "learning_rate": 1.0559774724805872e-05,
      "loss": 0.0017,
      "step": 46220
    },
    {
      "epoch": 3.94487584264869,
      "grad_norm": 0.2927255928516388,
      "learning_rate": 1.0551241573513098e-05,
      "loss": 0.0017,
      "step": 46230
    },
    {
      "epoch": 3.9457291577779676,
      "grad_norm": 0.06242671236395836,
      "learning_rate": 1.0542708422220327e-05,
      "loss": 0.0021,
      "step": 46240
    },
    {
      "epoch": 3.9465824729072447,
      "grad_norm": 0.17027387022972107,
      "learning_rate": 1.0534175270927554e-05,
      "loss": 0.0016,
      "step": 46250
    },
    {
      "epoch": 3.947435788036522,
      "grad_norm": 0.25588327646255493,
      "learning_rate": 1.0525642119634782e-05,
      "loss": 0.0026,
      "step": 46260
    },
    {
      "epoch": 3.9482891031657994,
      "grad_norm": 0.2519969344139099,
      "learning_rate": 1.051710896834201e-05,
      "loss": 0.0013,
      "step": 46270
    },
    {
      "epoch": 3.9491424182950765,
      "grad_norm": 0.050397127866744995,
      "learning_rate": 1.0508575817049236e-05,
      "loss": 0.002,
      "step": 46280
    },
    {
      "epoch": 3.9499957334243536,
      "grad_norm": 0.18889939785003662,
      "learning_rate": 1.0500042665756464e-05,
      "loss": 0.0018,
      "step": 46290
    },
    {
      "epoch": 3.9508490485536307,
      "grad_norm": 0.19407281279563904,
      "learning_rate": 1.0491509514463691e-05,
      "loss": 0.0021,
      "step": 46300
    },
    {
      "epoch": 3.951702363682908,
      "grad_norm": 0.10110368579626083,
      "learning_rate": 1.048297636317092e-05,
      "loss": 0.0021,
      "step": 46310
    },
    {
      "epoch": 3.9525556788121854,
      "grad_norm": 0.197952002286911,
      "learning_rate": 1.0474443211878148e-05,
      "loss": 0.0021,
      "step": 46320
    },
    {
      "epoch": 3.9534089939414625,
      "grad_norm": 0.054514747112989426,
      "learning_rate": 1.0465910060585375e-05,
      "loss": 0.0022,
      "step": 46330
    },
    {
      "epoch": 3.9542623090707396,
      "grad_norm": 0.1382659524679184,
      "learning_rate": 1.0457376909292602e-05,
      "loss": 0.0015,
      "step": 46340
    },
    {
      "epoch": 3.955115624200017,
      "grad_norm": 0.17528857290744781,
      "learning_rate": 1.044884375799983e-05,
      "loss": 0.0016,
      "step": 46350
    },
    {
      "epoch": 3.9559689393292943,
      "grad_norm": 0.23639580607414246,
      "learning_rate": 1.0440310606707057e-05,
      "loss": 0.0023,
      "step": 46360
    },
    {
      "epoch": 3.9568222544585714,
      "grad_norm": 0.15850038826465607,
      "learning_rate": 1.0431777455414285e-05,
      "loss": 0.0016,
      "step": 46370
    },
    {
      "epoch": 3.957675569587849,
      "grad_norm": 0.23221616446971893,
      "learning_rate": 1.0423244304121512e-05,
      "loss": 0.0018,
      "step": 46380
    },
    {
      "epoch": 3.958528884717126,
      "grad_norm": 0.09131920337677002,
      "learning_rate": 1.041471115282874e-05,
      "loss": 0.0018,
      "step": 46390
    },
    {
      "epoch": 3.959382199846403,
      "grad_norm": 0.1759122759103775,
      "learning_rate": 1.0406178001535969e-05,
      "loss": 0.0021,
      "step": 46400
    },
    {
      "epoch": 3.9602355149756807,
      "grad_norm": 0.145342156291008,
      "learning_rate": 1.0397644850243194e-05,
      "loss": 0.0017,
      "step": 46410
    },
    {
      "epoch": 3.961088830104958,
      "grad_norm": 0.18762482702732086,
      "learning_rate": 1.0389111698950423e-05,
      "loss": 0.0017,
      "step": 46420
    },
    {
      "epoch": 3.961942145234235,
      "grad_norm": 0.10873346030712128,
      "learning_rate": 1.038057854765765e-05,
      "loss": 0.0019,
      "step": 46430
    },
    {
      "epoch": 3.9627954603635125,
      "grad_norm": 0.12223648279905319,
      "learning_rate": 1.0372045396364878e-05,
      "loss": 0.0018,
      "step": 46440
    },
    {
      "epoch": 3.9636487754927896,
      "grad_norm": 0.20389904081821442,
      "learning_rate": 1.0363512245072106e-05,
      "loss": 0.0019,
      "step": 46450
    },
    {
      "epoch": 3.9645020906220667,
      "grad_norm": 0.03813305124640465,
      "learning_rate": 1.0354979093779333e-05,
      "loss": 0.0013,
      "step": 46460
    },
    {
      "epoch": 3.965355405751344,
      "grad_norm": 0.33432337641716003,
      "learning_rate": 1.0346445942486562e-05,
      "loss": 0.0019,
      "step": 46470
    },
    {
      "epoch": 3.9662087208806214,
      "grad_norm": 0.04588335007429123,
      "learning_rate": 1.0337912791193789e-05,
      "loss": 0.002,
      "step": 46480
    },
    {
      "epoch": 3.9670620360098985,
      "grad_norm": 0.2129589170217514,
      "learning_rate": 1.0329379639901015e-05,
      "loss": 0.0017,
      "step": 46490
    },
    {
      "epoch": 3.9679153511391756,
      "grad_norm": 0.10100246220827103,
      "learning_rate": 1.0320846488608244e-05,
      "loss": 0.0017,
      "step": 46500
    },
    {
      "epoch": 3.9687686662684527,
      "grad_norm": 0.295334130525589,
      "learning_rate": 1.031231333731547e-05,
      "loss": 0.0017,
      "step": 46510
    },
    {
      "epoch": 3.9696219813977303,
      "grad_norm": 0.06767246872186661,
      "learning_rate": 1.0303780186022699e-05,
      "loss": 0.0018,
      "step": 46520
    },
    {
      "epoch": 3.9704752965270074,
      "grad_norm": 0.18896032869815826,
      "learning_rate": 1.0295247034729928e-05,
      "loss": 0.0013,
      "step": 46530
    },
    {
      "epoch": 3.9713286116562845,
      "grad_norm": 0.07072396576404572,
      "learning_rate": 1.0286713883437153e-05,
      "loss": 0.0021,
      "step": 46540
    },
    {
      "epoch": 3.972181926785562,
      "grad_norm": 0.19898448884487152,
      "learning_rate": 1.0278180732144381e-05,
      "loss": 0.0018,
      "step": 46550
    },
    {
      "epoch": 3.973035241914839,
      "grad_norm": 0.13986346125602722,
      "learning_rate": 1.026964758085161e-05,
      "loss": 0.0017,
      "step": 46560
    },
    {
      "epoch": 3.9738885570441163,
      "grad_norm": 0.27330365777015686,
      "learning_rate": 1.0261114429558836e-05,
      "loss": 0.0021,
      "step": 46570
    },
    {
      "epoch": 3.974741872173394,
      "grad_norm": 0.25805389881134033,
      "learning_rate": 1.0252581278266065e-05,
      "loss": 0.0018,
      "step": 46580
    },
    {
      "epoch": 3.975595187302671,
      "grad_norm": 0.4802449941635132,
      "learning_rate": 1.0244048126973292e-05,
      "loss": 0.0018,
      "step": 46590
    },
    {
      "epoch": 3.976448502431948,
      "grad_norm": 0.1472555249929428,
      "learning_rate": 1.023551497568052e-05,
      "loss": 0.0016,
      "step": 46600
    },
    {
      "epoch": 3.9773018175612256,
      "grad_norm": 0.3266619145870209,
      "learning_rate": 1.0226981824387747e-05,
      "loss": 0.0017,
      "step": 46610
    },
    {
      "epoch": 3.9781551326905027,
      "grad_norm": 0.326092928647995,
      "learning_rate": 1.0218448673094974e-05,
      "loss": 0.0021,
      "step": 46620
    },
    {
      "epoch": 3.97900844781978,
      "grad_norm": 0.32560935616493225,
      "learning_rate": 1.0209915521802202e-05,
      "loss": 0.002,
      "step": 46630
    },
    {
      "epoch": 3.9798617629490574,
      "grad_norm": 0.1271456927061081,
      "learning_rate": 1.0201382370509429e-05,
      "loss": 0.002,
      "step": 46640
    },
    {
      "epoch": 3.9807150780783345,
      "grad_norm": 0.09905190020799637,
      "learning_rate": 1.0192849219216657e-05,
      "loss": 0.0015,
      "step": 46650
    },
    {
      "epoch": 3.9815683932076116,
      "grad_norm": 0.25238272547721863,
      "learning_rate": 1.0184316067923886e-05,
      "loss": 0.0015,
      "step": 46660
    },
    {
      "epoch": 3.9824217083368887,
      "grad_norm": 0.082993283867836,
      "learning_rate": 1.0175782916631113e-05,
      "loss": 0.0018,
      "step": 46670
    },
    {
      "epoch": 3.983275023466166,
      "grad_norm": 0.15155215561389923,
      "learning_rate": 1.016724976533834e-05,
      "loss": 0.0023,
      "step": 46680
    },
    {
      "epoch": 3.9841283385954434,
      "grad_norm": 0.3052743971347809,
      "learning_rate": 1.0158716614045568e-05,
      "loss": 0.0017,
      "step": 46690
    },
    {
      "epoch": 3.9849816537247205,
      "grad_norm": 0.16010963916778564,
      "learning_rate": 1.0150183462752795e-05,
      "loss": 0.0015,
      "step": 46700
    },
    {
      "epoch": 3.9858349688539976,
      "grad_norm": 0.3255698084831238,
      "learning_rate": 1.0141650311460023e-05,
      "loss": 0.0021,
      "step": 46710
    },
    {
      "epoch": 3.986688283983275,
      "grad_norm": 0.10671631246805191,
      "learning_rate": 1.013311716016725e-05,
      "loss": 0.0019,
      "step": 46720
    },
    {
      "epoch": 3.9875415991125522,
      "grad_norm": 0.29523956775665283,
      "learning_rate": 1.0124584008874479e-05,
      "loss": 0.0017,
      "step": 46730
    },
    {
      "epoch": 3.9883949142418293,
      "grad_norm": 0.11712020635604858,
      "learning_rate": 1.0116050857581705e-05,
      "loss": 0.0019,
      "step": 46740
    },
    {
      "epoch": 3.989248229371107,
      "grad_norm": 0.10761822760105133,
      "learning_rate": 1.0107517706288932e-05,
      "loss": 0.0022,
      "step": 46750
    },
    {
      "epoch": 3.990101544500384,
      "grad_norm": 0.07885336875915527,
      "learning_rate": 1.009898455499616e-05,
      "loss": 0.0016,
      "step": 46760
    },
    {
      "epoch": 3.990954859629661,
      "grad_norm": 0.056540172547101974,
      "learning_rate": 1.0090451403703387e-05,
      "loss": 0.0017,
      "step": 46770
    },
    {
      "epoch": 3.9918081747589387,
      "grad_norm": 0.36314380168914795,
      "learning_rate": 1.0081918252410616e-05,
      "loss": 0.0017,
      "step": 46780
    },
    {
      "epoch": 3.992661489888216,
      "grad_norm": 0.10662317276000977,
      "learning_rate": 1.0073385101117844e-05,
      "loss": 0.0014,
      "step": 46790
    },
    {
      "epoch": 3.993514805017493,
      "grad_norm": 0.079047791659832,
      "learning_rate": 1.0064851949825071e-05,
      "loss": 0.0018,
      "step": 46800
    },
    {
      "epoch": 3.9943681201467705,
      "grad_norm": 0.045507676899433136,
      "learning_rate": 1.0056318798532298e-05,
      "loss": 0.0021,
      "step": 46810
    },
    {
      "epoch": 3.9952214352760476,
      "grad_norm": 0.24928626418113708,
      "learning_rate": 1.0047785647239526e-05,
      "loss": 0.0021,
      "step": 46820
    },
    {
      "epoch": 3.9960747504053247,
      "grad_norm": 0.3221053183078766,
      "learning_rate": 1.0039252495946753e-05,
      "loss": 0.0018,
      "step": 46830
    },
    {
      "epoch": 3.996928065534602,
      "grad_norm": 0.17500513792037964,
      "learning_rate": 1.0030719344653982e-05,
      "loss": 0.0016,
      "step": 46840
    },
    {
      "epoch": 3.9977813806638793,
      "grad_norm": 0.30039578676223755,
      "learning_rate": 1.0022186193361208e-05,
      "loss": 0.0018,
      "step": 46850
    },
    {
      "epoch": 3.9986346957931564,
      "grad_norm": 0.04601747915148735,
      "learning_rate": 1.0013653042068437e-05,
      "loss": 0.0017,
      "step": 46860
    },
    {
      "epoch": 3.9994880109224336,
      "grad_norm": 0.25385183095932007,
      "learning_rate": 1.0005119890775664e-05,
      "loss": 0.002,
      "step": 46870
    },
    {
      "epoch": 4.0,
      "eval_loss": 0.0018310141749680042,
      "eval_runtime": 103.6188,
      "eval_samples_per_second": 1447.614,
      "eval_steps_per_second": 22.621,
      "step": 46876
    },
    {
      "epoch": 4.000341326051711,
      "grad_norm": 0.1786932796239853,
      "learning_rate": 9.99658673948289e-06,
      "loss": 0.0017,
      "step": 46880
    },
    {
      "epoch": 4.001194641180988,
      "grad_norm": 0.15114547312259674,
      "learning_rate": 9.988053588190119e-06,
      "loss": 0.0018,
      "step": 46890
    },
    {
      "epoch": 4.002047956310266,
      "grad_norm": 0.06569670885801315,
      "learning_rate": 9.979520436897346e-06,
      "loss": 0.0012,
      "step": 46900
    },
    {
      "epoch": 4.002901271439542,
      "grad_norm": 0.1541220098733902,
      "learning_rate": 9.970987285604574e-06,
      "loss": 0.0016,
      "step": 46910
    },
    {
      "epoch": 4.00375458656882,
      "grad_norm": 0.18981069326400757,
      "learning_rate": 9.962454134311803e-06,
      "loss": 0.0017,
      "step": 46920
    },
    {
      "epoch": 4.0046079016980975,
      "grad_norm": 0.1935490071773529,
      "learning_rate": 9.95392098301903e-06,
      "loss": 0.0021,
      "step": 46930
    },
    {
      "epoch": 4.005461216827374,
      "grad_norm": 0.08858563005924225,
      "learning_rate": 9.945387831726256e-06,
      "loss": 0.0016,
      "step": 46940
    },
    {
      "epoch": 4.006314531956652,
      "grad_norm": 0.2303287386894226,
      "learning_rate": 9.936854680433485e-06,
      "loss": 0.0024,
      "step": 46950
    },
    {
      "epoch": 4.007167847085928,
      "grad_norm": 0.12014725059270859,
      "learning_rate": 9.928321529140712e-06,
      "loss": 0.0019,
      "step": 46960
    },
    {
      "epoch": 4.008021162215206,
      "grad_norm": 0.36249303817749023,
      "learning_rate": 9.91978837784794e-06,
      "loss": 0.0011,
      "step": 46970
    },
    {
      "epoch": 4.0088744773444835,
      "grad_norm": 0.5101792812347412,
      "learning_rate": 9.911255226555167e-06,
      "loss": 0.0022,
      "step": 46980
    },
    {
      "epoch": 4.00972779247376,
      "grad_norm": 0.39200976490974426,
      "learning_rate": 9.902722075262395e-06,
      "loss": 0.0018,
      "step": 46990
    },
    {
      "epoch": 4.010581107603038,
      "grad_norm": 0.06960731744766235,
      "learning_rate": 9.894188923969624e-06,
      "loss": 0.0017,
      "step": 47000
    },
    {
      "epoch": 4.011434422732315,
      "grad_norm": 0.1078341081738472,
      "learning_rate": 9.885655772676849e-06,
      "loss": 0.0018,
      "step": 47010
    },
    {
      "epoch": 4.012287737861592,
      "grad_norm": 0.19017180800437927,
      "learning_rate": 9.877122621384077e-06,
      "loss": 0.002,
      "step": 47020
    },
    {
      "epoch": 4.0131410529908695,
      "grad_norm": 0.2324027419090271,
      "learning_rate": 9.868589470091306e-06,
      "loss": 0.0018,
      "step": 47030
    },
    {
      "epoch": 4.013994368120147,
      "grad_norm": 0.07627416402101517,
      "learning_rate": 9.860056318798533e-06,
      "loss": 0.0015,
      "step": 47040
    },
    {
      "epoch": 4.014847683249424,
      "grad_norm": 0.32522818446159363,
      "learning_rate": 9.851523167505761e-06,
      "loss": 0.0017,
      "step": 47050
    },
    {
      "epoch": 4.015700998378701,
      "grad_norm": 0.193119615316391,
      "learning_rate": 9.842990016212988e-06,
      "loss": 0.0017,
      "step": 47060
    },
    {
      "epoch": 4.016554313507979,
      "grad_norm": 0.039423808455467224,
      "learning_rate": 9.834456864920215e-06,
      "loss": 0.0019,
      "step": 47070
    },
    {
      "epoch": 4.0174076286372555,
      "grad_norm": 0.5136952996253967,
      "learning_rate": 9.825923713627443e-06,
      "loss": 0.0022,
      "step": 47080
    },
    {
      "epoch": 4.018260943766533,
      "grad_norm": 0.3034372925758362,
      "learning_rate": 9.81739056233467e-06,
      "loss": 0.0019,
      "step": 47090
    },
    {
      "epoch": 4.019114258895811,
      "grad_norm": 0.23119749128818512,
      "learning_rate": 9.808857411041898e-06,
      "loss": 0.0019,
      "step": 47100
    },
    {
      "epoch": 4.019967574025087,
      "grad_norm": 0.08356945961713791,
      "learning_rate": 9.800324259749125e-06,
      "loss": 0.0019,
      "step": 47110
    },
    {
      "epoch": 4.020820889154365,
      "grad_norm": 0.11933664977550507,
      "learning_rate": 9.791791108456354e-06,
      "loss": 0.0012,
      "step": 47120
    },
    {
      "epoch": 4.0216742042836415,
      "grad_norm": 0.06417077034711838,
      "learning_rate": 9.783257957163582e-06,
      "loss": 0.0024,
      "step": 47130
    },
    {
      "epoch": 4.022527519412919,
      "grad_norm": 0.05022461339831352,
      "learning_rate": 9.774724805870807e-06,
      "loss": 0.002,
      "step": 47140
    },
    {
      "epoch": 4.023380834542197,
      "grad_norm": 0.07360254228115082,
      "learning_rate": 9.766191654578036e-06,
      "loss": 0.0015,
      "step": 47150
    },
    {
      "epoch": 4.024234149671473,
      "grad_norm": 0.21498683094978333,
      "learning_rate": 9.757658503285264e-06,
      "loss": 0.0021,
      "step": 47160
    },
    {
      "epoch": 4.025087464800751,
      "grad_norm": 0.15749043226242065,
      "learning_rate": 9.749125351992491e-06,
      "loss": 0.0023,
      "step": 47170
    },
    {
      "epoch": 4.025940779930028,
      "grad_norm": 0.08757312595844269,
      "learning_rate": 9.74059220069972e-06,
      "loss": 0.0018,
      "step": 47180
    },
    {
      "epoch": 4.026794095059305,
      "grad_norm": 0.2682935297489166,
      "learning_rate": 9.732059049406946e-06,
      "loss": 0.0021,
      "step": 47190
    },
    {
      "epoch": 4.027647410188583,
      "grad_norm": 0.32927271723747253,
      "learning_rate": 9.723525898114175e-06,
      "loss": 0.0017,
      "step": 47200
    },
    {
      "epoch": 4.02850072531786,
      "grad_norm": 0.1021648645401001,
      "learning_rate": 9.714992746821402e-06,
      "loss": 0.0017,
      "step": 47210
    },
    {
      "epoch": 4.029354040447137,
      "grad_norm": 0.4704894721508026,
      "learning_rate": 9.706459595528628e-06,
      "loss": 0.0021,
      "step": 47220
    },
    {
      "epoch": 4.030207355576414,
      "grad_norm": 0.2707916498184204,
      "learning_rate": 9.697926444235857e-06,
      "loss": 0.0017,
      "step": 47230
    },
    {
      "epoch": 4.031060670705692,
      "grad_norm": 0.11035183072090149,
      "learning_rate": 9.689393292943084e-06,
      "loss": 0.0026,
      "step": 47240
    },
    {
      "epoch": 4.031913985834969,
      "grad_norm": 0.06354052573442459,
      "learning_rate": 9.680860141650312e-06,
      "loss": 0.0016,
      "step": 47250
    },
    {
      "epoch": 4.032767300964246,
      "grad_norm": 0.09751076996326447,
      "learning_rate": 9.67232699035754e-06,
      "loss": 0.002,
      "step": 47260
    },
    {
      "epoch": 4.033620616093524,
      "grad_norm": 0.09425126761198044,
      "learning_rate": 9.663793839064766e-06,
      "loss": 0.0018,
      "step": 47270
    },
    {
      "epoch": 4.0344739312228,
      "grad_norm": 0.07533884048461914,
      "learning_rate": 9.655260687771994e-06,
      "loss": 0.0016,
      "step": 47280
    },
    {
      "epoch": 4.035327246352078,
      "grad_norm": 0.0581473670899868,
      "learning_rate": 9.646727536479223e-06,
      "loss": 0.0017,
      "step": 47290
    },
    {
      "epoch": 4.0361805614813555,
      "grad_norm": 0.34058982133865356,
      "learning_rate": 9.63819438518645e-06,
      "loss": 0.0017,
      "step": 47300
    },
    {
      "epoch": 4.037033876610632,
      "grad_norm": 0.0917847529053688,
      "learning_rate": 9.629661233893678e-06,
      "loss": 0.0019,
      "step": 47310
    },
    {
      "epoch": 4.03788719173991,
      "grad_norm": 0.24061569571495056,
      "learning_rate": 9.621128082600905e-06,
      "loss": 0.0022,
      "step": 47320
    },
    {
      "epoch": 4.038740506869186,
      "grad_norm": 0.36485567688941956,
      "learning_rate": 9.612594931308133e-06,
      "loss": 0.0022,
      "step": 47330
    },
    {
      "epoch": 4.039593821998464,
      "grad_norm": 0.2145904004573822,
      "learning_rate": 9.60406178001536e-06,
      "loss": 0.0019,
      "step": 47340
    },
    {
      "epoch": 4.0404471371277415,
      "grad_norm": 0.383297860622406,
      "learning_rate": 9.595528628722587e-06,
      "loss": 0.0016,
      "step": 47350
    },
    {
      "epoch": 4.041300452257018,
      "grad_norm": 0.414717435836792,
      "learning_rate": 9.586995477429815e-06,
      "loss": 0.0023,
      "step": 47360
    },
    {
      "epoch": 4.042153767386296,
      "grad_norm": 0.4036000072956085,
      "learning_rate": 9.578462326137042e-06,
      "loss": 0.0017,
      "step": 47370
    },
    {
      "epoch": 4.043007082515573,
      "grad_norm": 0.1442742496728897,
      "learning_rate": 9.56992917484427e-06,
      "loss": 0.0016,
      "step": 47380
    },
    {
      "epoch": 4.04386039764485,
      "grad_norm": 0.060295626521110535,
      "learning_rate": 9.561396023551499e-06,
      "loss": 0.0017,
      "step": 47390
    },
    {
      "epoch": 4.0447137127741275,
      "grad_norm": 0.2535441517829895,
      "learning_rate": 9.552862872258726e-06,
      "loss": 0.0019,
      "step": 47400
    },
    {
      "epoch": 4.045567027903405,
      "grad_norm": 0.1881474107503891,
      "learning_rate": 9.544329720965953e-06,
      "loss": 0.0019,
      "step": 47410
    },
    {
      "epoch": 4.046420343032682,
      "grad_norm": 0.15465112030506134,
      "learning_rate": 9.535796569673181e-06,
      "loss": 0.0015,
      "step": 47420
    },
    {
      "epoch": 4.047273658161959,
      "grad_norm": 0.24245606362819672,
      "learning_rate": 9.527263418380408e-06,
      "loss": 0.0023,
      "step": 47430
    },
    {
      "epoch": 4.048126973291237,
      "grad_norm": 0.05065798759460449,
      "learning_rate": 9.518730267087636e-06,
      "loss": 0.0016,
      "step": 47440
    },
    {
      "epoch": 4.0489802884205135,
      "grad_norm": 0.17076323926448822,
      "learning_rate": 9.510197115794863e-06,
      "loss": 0.0019,
      "step": 47450
    },
    {
      "epoch": 4.049833603549791,
      "grad_norm": 0.06044906750321388,
      "learning_rate": 9.501663964502092e-06,
      "loss": 0.0016,
      "step": 47460
    },
    {
      "epoch": 4.050686918679069,
      "grad_norm": 0.208979994058609,
      "learning_rate": 9.493130813209318e-06,
      "loss": 0.0019,
      "step": 47470
    },
    {
      "epoch": 4.051540233808345,
      "grad_norm": 0.09945859014987946,
      "learning_rate": 9.484597661916545e-06,
      "loss": 0.0016,
      "step": 47480
    },
    {
      "epoch": 4.052393548937623,
      "grad_norm": 0.23087187111377716,
      "learning_rate": 9.476064510623774e-06,
      "loss": 0.0018,
      "step": 47490
    },
    {
      "epoch": 4.0532468640668995,
      "grad_norm": 0.21132728457450867,
      "learning_rate": 9.467531359331002e-06,
      "loss": 0.0017,
      "step": 47500
    },
    {
      "epoch": 4.054100179196177,
      "grad_norm": 0.06652530282735825,
      "learning_rate": 9.458998208038229e-06,
      "loss": 0.0019,
      "step": 47510
    },
    {
      "epoch": 4.054953494325455,
      "grad_norm": 0.39795923233032227,
      "learning_rate": 9.450465056745457e-06,
      "loss": 0.0021,
      "step": 47520
    },
    {
      "epoch": 4.055806809454731,
      "grad_norm": 0.19197624921798706,
      "learning_rate": 9.441931905452684e-06,
      "loss": 0.0022,
      "step": 47530
    },
    {
      "epoch": 4.056660124584009,
      "grad_norm": 0.10795113444328308,
      "learning_rate": 9.433398754159911e-06,
      "loss": 0.0021,
      "step": 47540
    },
    {
      "epoch": 4.057513439713286,
      "grad_norm": 0.4187620282173157,
      "learning_rate": 9.42486560286714e-06,
      "loss": 0.0018,
      "step": 47550
    },
    {
      "epoch": 4.058366754842563,
      "grad_norm": 0.06453147530555725,
      "learning_rate": 9.416332451574366e-06,
      "loss": 0.0021,
      "step": 47560
    },
    {
      "epoch": 4.059220069971841,
      "grad_norm": 0.08711522817611694,
      "learning_rate": 9.407799300281595e-06,
      "loss": 0.0017,
      "step": 47570
    },
    {
      "epoch": 4.060073385101118,
      "grad_norm": 0.18331268429756165,
      "learning_rate": 9.399266148988822e-06,
      "loss": 0.0023,
      "step": 47580
    },
    {
      "epoch": 4.060926700230395,
      "grad_norm": 0.19578778743743896,
      "learning_rate": 9.39073299769605e-06,
      "loss": 0.0019,
      "step": 47590
    },
    {
      "epoch": 4.061780015359672,
      "grad_norm": 0.2519509494304657,
      "learning_rate": 9.382199846403279e-06,
      "loss": 0.0021,
      "step": 47600
    },
    {
      "epoch": 4.06263333048895,
      "grad_norm": 0.44587528705596924,
      "learning_rate": 9.373666695110504e-06,
      "loss": 0.0019,
      "step": 47610
    },
    {
      "epoch": 4.063486645618227,
      "grad_norm": 0.4351961314678192,
      "learning_rate": 9.365133543817732e-06,
      "loss": 0.0016,
      "step": 47620
    },
    {
      "epoch": 4.064339960747504,
      "grad_norm": 0.18224354088306427,
      "learning_rate": 9.35660039252496e-06,
      "loss": 0.0017,
      "step": 47630
    },
    {
      "epoch": 4.065193275876782,
      "grad_norm": 0.0664963498711586,
      "learning_rate": 9.348067241232187e-06,
      "loss": 0.0018,
      "step": 47640
    },
    {
      "epoch": 4.066046591006058,
      "grad_norm": 0.09961384534835815,
      "learning_rate": 9.339534089939416e-06,
      "loss": 0.0017,
      "step": 47650
    },
    {
      "epoch": 4.066899906135336,
      "grad_norm": 0.036618106067180634,
      "learning_rate": 9.331000938646643e-06,
      "loss": 0.0021,
      "step": 47660
    },
    {
      "epoch": 4.0677532212646135,
      "grad_norm": 0.10404694080352783,
      "learning_rate": 9.32246778735387e-06,
      "loss": 0.0017,
      "step": 47670
    },
    {
      "epoch": 4.06860653639389,
      "grad_norm": 0.10231117159128189,
      "learning_rate": 9.313934636061098e-06,
      "loss": 0.0019,
      "step": 47680
    },
    {
      "epoch": 4.069459851523168,
      "grad_norm": 0.08742877095937729,
      "learning_rate": 9.305401484768325e-06,
      "loss": 0.0019,
      "step": 47690
    },
    {
      "epoch": 4.070313166652444,
      "grad_norm": 0.19699956476688385,
      "learning_rate": 9.296868333475553e-06,
      "loss": 0.002,
      "step": 47700
    },
    {
      "epoch": 4.071166481781722,
      "grad_norm": 0.06949731707572937,
      "learning_rate": 9.28833518218278e-06,
      "loss": 0.0017,
      "step": 47710
    },
    {
      "epoch": 4.0720197969109995,
      "grad_norm": 0.05472325533628464,
      "learning_rate": 9.279802030890008e-06,
      "loss": 0.0029,
      "step": 47720
    },
    {
      "epoch": 4.072873112040276,
      "grad_norm": 0.055898267775774,
      "learning_rate": 9.271268879597237e-06,
      "loss": 0.0015,
      "step": 47730
    },
    {
      "epoch": 4.073726427169554,
      "grad_norm": 0.03803226724267006,
      "learning_rate": 9.262735728304462e-06,
      "loss": 0.002,
      "step": 47740
    },
    {
      "epoch": 4.074579742298831,
      "grad_norm": 0.24921108782291412,
      "learning_rate": 9.25420257701169e-06,
      "loss": 0.0019,
      "step": 47750
    },
    {
      "epoch": 4.075433057428108,
      "grad_norm": 0.41538289189338684,
      "learning_rate": 9.245669425718919e-06,
      "loss": 0.0014,
      "step": 47760
    },
    {
      "epoch": 4.0762863725573855,
      "grad_norm": 0.15450327098369598,
      "learning_rate": 9.237136274426146e-06,
      "loss": 0.002,
      "step": 47770
    },
    {
      "epoch": 4.077139687686663,
      "grad_norm": 0.06119369715452194,
      "learning_rate": 9.228603123133374e-06,
      "loss": 0.0016,
      "step": 47780
    },
    {
      "epoch": 4.07799300281594,
      "grad_norm": 0.06635214388370514,
      "learning_rate": 9.220069971840601e-06,
      "loss": 0.0013,
      "step": 47790
    },
    {
      "epoch": 4.078846317945217,
      "grad_norm": 0.0513949990272522,
      "learning_rate": 9.211536820547828e-06,
      "loss": 0.002,
      "step": 47800
    },
    {
      "epoch": 4.079699633074495,
      "grad_norm": 0.04108002036809921,
      "learning_rate": 9.203003669255056e-06,
      "loss": 0.0021,
      "step": 47810
    },
    {
      "epoch": 4.0805529482037715,
      "grad_norm": 0.06982165575027466,
      "learning_rate": 9.194470517962283e-06,
      "loss": 0.0016,
      "step": 47820
    },
    {
      "epoch": 4.081406263333049,
      "grad_norm": 0.07234624773263931,
      "learning_rate": 9.185937366669512e-06,
      "loss": 0.002,
      "step": 47830
    },
    {
      "epoch": 4.082259578462327,
      "grad_norm": 0.15504856407642365,
      "learning_rate": 9.177404215376738e-06,
      "loss": 0.0019,
      "step": 47840
    },
    {
      "epoch": 4.083112893591603,
      "grad_norm": 0.23423635959625244,
      "learning_rate": 9.168871064083967e-06,
      "loss": 0.0015,
      "step": 47850
    },
    {
      "epoch": 4.083966208720881,
      "grad_norm": 0.09698636084794998,
      "learning_rate": 9.160337912791195e-06,
      "loss": 0.0015,
      "step": 47860
    },
    {
      "epoch": 4.0848195238501575,
      "grad_norm": 0.13745975494384766,
      "learning_rate": 9.15180476149842e-06,
      "loss": 0.0019,
      "step": 47870
    },
    {
      "epoch": 4.085672838979435,
      "grad_norm": 0.283797949552536,
      "learning_rate": 9.143271610205649e-06,
      "loss": 0.0019,
      "step": 47880
    },
    {
      "epoch": 4.086526154108713,
      "grad_norm": 0.3429277539253235,
      "learning_rate": 9.134738458912877e-06,
      "loss": 0.0021,
      "step": 47890
    },
    {
      "epoch": 4.087379469237989,
      "grad_norm": 0.19943228363990784,
      "learning_rate": 9.126205307620104e-06,
      "loss": 0.0017,
      "step": 47900
    },
    {
      "epoch": 4.088232784367267,
      "grad_norm": 0.10486702620983124,
      "learning_rate": 9.117672156327333e-06,
      "loss": 0.0014,
      "step": 47910
    },
    {
      "epoch": 4.089086099496544,
      "grad_norm": 0.06797366589307785,
      "learning_rate": 9.10913900503456e-06,
      "loss": 0.0021,
      "step": 47920
    },
    {
      "epoch": 4.089939414625821,
      "grad_norm": 0.17673465609550476,
      "learning_rate": 9.100605853741788e-06,
      "loss": 0.0018,
      "step": 47930
    },
    {
      "epoch": 4.0907927297550986,
      "grad_norm": 0.06191852688789368,
      "learning_rate": 9.092072702449015e-06,
      "loss": 0.0021,
      "step": 47940
    },
    {
      "epoch": 4.091646044884376,
      "grad_norm": 0.4385700523853302,
      "learning_rate": 9.083539551156242e-06,
      "loss": 0.002,
      "step": 47950
    },
    {
      "epoch": 4.092499360013653,
      "grad_norm": 0.18679246306419373,
      "learning_rate": 9.07500639986347e-06,
      "loss": 0.0016,
      "step": 47960
    },
    {
      "epoch": 4.09335267514293,
      "grad_norm": 0.12837405502796173,
      "learning_rate": 9.066473248570698e-06,
      "loss": 0.0019,
      "step": 47970
    },
    {
      "epoch": 4.094205990272208,
      "grad_norm": 0.4341789782047272,
      "learning_rate": 9.057940097277925e-06,
      "loss": 0.0019,
      "step": 47980
    },
    {
      "epoch": 4.0950593054014846,
      "grad_norm": 0.1378064751625061,
      "learning_rate": 9.049406945985154e-06,
      "loss": 0.0016,
      "step": 47990
    },
    {
      "epoch": 4.095912620530762,
      "grad_norm": 0.047259941697120667,
      "learning_rate": 9.040873794692379e-06,
      "loss": 0.0022,
      "step": 48000
    },
    {
      "epoch": 4.09676593566004,
      "grad_norm": 0.1630207896232605,
      "learning_rate": 9.032340643399607e-06,
      "loss": 0.0017,
      "step": 48010
    },
    {
      "epoch": 4.097619250789316,
      "grad_norm": 0.10719355940818787,
      "learning_rate": 9.023807492106836e-06,
      "loss": 0.0018,
      "step": 48020
    },
    {
      "epoch": 4.098472565918594,
      "grad_norm": 0.1021750345826149,
      "learning_rate": 9.015274340814063e-06,
      "loss": 0.0018,
      "step": 48030
    },
    {
      "epoch": 4.0993258810478705,
      "grad_norm": 0.08677620440721512,
      "learning_rate": 9.006741189521291e-06,
      "loss": 0.0012,
      "step": 48040
    },
    {
      "epoch": 4.100179196177148,
      "grad_norm": 0.22442762553691864,
      "learning_rate": 8.998208038228518e-06,
      "loss": 0.0016,
      "step": 48050
    },
    {
      "epoch": 4.101032511306426,
      "grad_norm": 0.2286204695701599,
      "learning_rate": 8.989674886935746e-06,
      "loss": 0.0019,
      "step": 48060
    },
    {
      "epoch": 4.101885826435702,
      "grad_norm": 0.03523976355791092,
      "learning_rate": 8.981141735642973e-06,
      "loss": 0.0017,
      "step": 48070
    },
    {
      "epoch": 4.10273914156498,
      "grad_norm": 0.23298068344593048,
      "learning_rate": 8.9726085843502e-06,
      "loss": 0.0026,
      "step": 48080
    },
    {
      "epoch": 4.103592456694257,
      "grad_norm": 0.16722019016742706,
      "learning_rate": 8.964075433057428e-06,
      "loss": 0.0015,
      "step": 48090
    },
    {
      "epoch": 4.104445771823534,
      "grad_norm": 0.08745937049388885,
      "learning_rate": 8.955542281764657e-06,
      "loss": 0.0018,
      "step": 48100
    },
    {
      "epoch": 4.105299086952812,
      "grad_norm": 0.059757597744464874,
      "learning_rate": 8.947009130471884e-06,
      "loss": 0.002,
      "step": 48110
    },
    {
      "epoch": 4.106152402082089,
      "grad_norm": 0.2312547266483307,
      "learning_rate": 8.938475979179112e-06,
      "loss": 0.0018,
      "step": 48120
    },
    {
      "epoch": 4.107005717211366,
      "grad_norm": 0.0974341630935669,
      "learning_rate": 8.929942827886339e-06,
      "loss": 0.0018,
      "step": 48130
    },
    {
      "epoch": 4.107859032340643,
      "grad_norm": 0.16840796172618866,
      "learning_rate": 8.921409676593566e-06,
      "loss": 0.0019,
      "step": 48140
    },
    {
      "epoch": 4.108712347469921,
      "grad_norm": 0.11097627133131027,
      "learning_rate": 8.912876525300794e-06,
      "loss": 0.0014,
      "step": 48150
    },
    {
      "epoch": 4.109565662599198,
      "grad_norm": 0.2079814076423645,
      "learning_rate": 8.904343374008021e-06,
      "loss": 0.0016,
      "step": 48160
    },
    {
      "epoch": 4.110418977728475,
      "grad_norm": 0.06386800855398178,
      "learning_rate": 8.89581022271525e-06,
      "loss": 0.0015,
      "step": 48170
    },
    {
      "epoch": 4.111272292857753,
      "grad_norm": 0.26335474848747253,
      "learning_rate": 8.887277071422476e-06,
      "loss": 0.0022,
      "step": 48180
    },
    {
      "epoch": 4.112125607987029,
      "grad_norm": 0.15323540568351746,
      "learning_rate": 8.878743920129705e-06,
      "loss": 0.0021,
      "step": 48190
    },
    {
      "epoch": 4.112978923116307,
      "grad_norm": 0.07955852895975113,
      "learning_rate": 8.870210768836932e-06,
      "loss": 0.0014,
      "step": 48200
    },
    {
      "epoch": 4.1138322382455845,
      "grad_norm": 0.14882318675518036,
      "learning_rate": 8.861677617544158e-06,
      "loss": 0.0016,
      "step": 48210
    },
    {
      "epoch": 4.114685553374861,
      "grad_norm": 0.12178581207990646,
      "learning_rate": 8.853144466251387e-06,
      "loss": 0.0015,
      "step": 48220
    },
    {
      "epoch": 4.115538868504139,
      "grad_norm": 0.10064104944467545,
      "learning_rate": 8.844611314958615e-06,
      "loss": 0.0022,
      "step": 48230
    },
    {
      "epoch": 4.116392183633415,
      "grad_norm": 0.08537864685058594,
      "learning_rate": 8.836078163665842e-06,
      "loss": 0.0014,
      "step": 48240
    },
    {
      "epoch": 4.117245498762693,
      "grad_norm": 0.24827544391155243,
      "learning_rate": 8.82754501237307e-06,
      "loss": 0.0021,
      "step": 48250
    },
    {
      "epoch": 4.1180988138919705,
      "grad_norm": 0.18880721926689148,
      "learning_rate": 8.819011861080297e-06,
      "loss": 0.002,
      "step": 48260
    },
    {
      "epoch": 4.118952129021247,
      "grad_norm": 0.037854861468076706,
      "learning_rate": 8.810478709787524e-06,
      "loss": 0.0017,
      "step": 48270
    },
    {
      "epoch": 4.119805444150525,
      "grad_norm": 0.19532093405723572,
      "learning_rate": 8.801945558494753e-06,
      "loss": 0.002,
      "step": 48280
    },
    {
      "epoch": 4.120658759279802,
      "grad_norm": 0.17841395735740662,
      "learning_rate": 8.79341240720198e-06,
      "loss": 0.0018,
      "step": 48290
    },
    {
      "epoch": 4.121512074409079,
      "grad_norm": 0.17290741205215454,
      "learning_rate": 8.784879255909208e-06,
      "loss": 0.0016,
      "step": 48300
    },
    {
      "epoch": 4.1223653895383565,
      "grad_norm": 0.2708681523799896,
      "learning_rate": 8.776346104616435e-06,
      "loss": 0.002,
      "step": 48310
    },
    {
      "epoch": 4.123218704667634,
      "grad_norm": 0.32661885023117065,
      "learning_rate": 8.767812953323663e-06,
      "loss": 0.0017,
      "step": 48320
    },
    {
      "epoch": 4.124072019796911,
      "grad_norm": 0.25015172362327576,
      "learning_rate": 8.759279802030892e-06,
      "loss": 0.002,
      "step": 48330
    },
    {
      "epoch": 4.124925334926188,
      "grad_norm": 0.2889931797981262,
      "learning_rate": 8.750746650738117e-06,
      "loss": 0.0022,
      "step": 48340
    },
    {
      "epoch": 4.125778650055466,
      "grad_norm": 0.13462382555007935,
      "learning_rate": 8.742213499445345e-06,
      "loss": 0.0018,
      "step": 48350
    },
    {
      "epoch": 4.1266319651847425,
      "grad_norm": 0.15251493453979492,
      "learning_rate": 8.733680348152574e-06,
      "loss": 0.002,
      "step": 48360
    },
    {
      "epoch": 4.12748528031402,
      "grad_norm": 0.16891302168369293,
      "learning_rate": 8.7251471968598e-06,
      "loss": 0.0017,
      "step": 48370
    },
    {
      "epoch": 4.128338595443298,
      "grad_norm": 0.056568603962659836,
      "learning_rate": 8.716614045567029e-06,
      "loss": 0.0014,
      "step": 48380
    },
    {
      "epoch": 4.129191910572574,
      "grad_norm": 0.13783757388591766,
      "learning_rate": 8.708080894274256e-06,
      "loss": 0.0018,
      "step": 48390
    },
    {
      "epoch": 4.130045225701852,
      "grad_norm": 0.13950756192207336,
      "learning_rate": 8.699547742981483e-06,
      "loss": 0.0018,
      "step": 48400
    },
    {
      "epoch": 4.1308985408311285,
      "grad_norm": 0.10709885507822037,
      "learning_rate": 8.691014591688711e-06,
      "loss": 0.0014,
      "step": 48410
    },
    {
      "epoch": 4.131751855960406,
      "grad_norm": 0.1384338140487671,
      "learning_rate": 8.682481440395938e-06,
      "loss": 0.0016,
      "step": 48420
    },
    {
      "epoch": 4.132605171089684,
      "grad_norm": 0.22628292441368103,
      "learning_rate": 8.673948289103166e-06,
      "loss": 0.0017,
      "step": 48430
    },
    {
      "epoch": 4.13345848621896,
      "grad_norm": 0.23148030042648315,
      "learning_rate": 8.665415137810395e-06,
      "loss": 0.0022,
      "step": 48440
    },
    {
      "epoch": 4.134311801348238,
      "grad_norm": 0.0843508392572403,
      "learning_rate": 8.656881986517622e-06,
      "loss": 0.0021,
      "step": 48450
    },
    {
      "epoch": 4.135165116477515,
      "grad_norm": 0.33050450682640076,
      "learning_rate": 8.64834883522485e-06,
      "loss": 0.0015,
      "step": 48460
    },
    {
      "epoch": 4.136018431606792,
      "grad_norm": 0.11672437191009521,
      "learning_rate": 8.639815683932075e-06,
      "loss": 0.0021,
      "step": 48470
    },
    {
      "epoch": 4.13687174673607,
      "grad_norm": 0.20949676632881165,
      "learning_rate": 8.631282532639304e-06,
      "loss": 0.0018,
      "step": 48480
    },
    {
      "epoch": 4.137725061865347,
      "grad_norm": 0.27470138669013977,
      "learning_rate": 8.622749381346532e-06,
      "loss": 0.0017,
      "step": 48490
    },
    {
      "epoch": 4.138578376994624,
      "grad_norm": 0.05953023582696915,
      "learning_rate": 8.614216230053759e-06,
      "loss": 0.0023,
      "step": 48500
    },
    {
      "epoch": 4.139431692123901,
      "grad_norm": 0.2231321632862091,
      "learning_rate": 8.605683078760987e-06,
      "loss": 0.0015,
      "step": 48510
    },
    {
      "epoch": 4.140285007253179,
      "grad_norm": 0.17543059587478638,
      "learning_rate": 8.597149927468214e-06,
      "loss": 0.0019,
      "step": 48520
    },
    {
      "epoch": 4.141138322382456,
      "grad_norm": 0.11217054724693298,
      "learning_rate": 8.588616776175443e-06,
      "loss": 0.0015,
      "step": 48530
    },
    {
      "epoch": 4.141991637511733,
      "grad_norm": 0.2673395276069641,
      "learning_rate": 8.58008362488267e-06,
      "loss": 0.0014,
      "step": 48540
    },
    {
      "epoch": 4.142844952641011,
      "grad_norm": 0.03983232006430626,
      "learning_rate": 8.571550473589896e-06,
      "loss": 0.0019,
      "step": 48550
    },
    {
      "epoch": 4.143698267770287,
      "grad_norm": 0.21816907823085785,
      "learning_rate": 8.563017322297125e-06,
      "loss": 0.0019,
      "step": 48560
    },
    {
      "epoch": 4.144551582899565,
      "grad_norm": 0.07102640718221664,
      "learning_rate": 8.554484171004353e-06,
      "loss": 0.0014,
      "step": 48570
    },
    {
      "epoch": 4.145404898028842,
      "grad_norm": 0.1544036567211151,
      "learning_rate": 8.54595101971158e-06,
      "loss": 0.002,
      "step": 48580
    },
    {
      "epoch": 4.146258213158119,
      "grad_norm": 0.05899830907583237,
      "learning_rate": 8.537417868418808e-06,
      "loss": 0.0014,
      "step": 48590
    },
    {
      "epoch": 4.147111528287397,
      "grad_norm": 0.2934041917324066,
      "learning_rate": 8.528884717126035e-06,
      "loss": 0.0019,
      "step": 48600
    },
    {
      "epoch": 4.147964843416673,
      "grad_norm": 0.3783862590789795,
      "learning_rate": 8.520351565833262e-06,
      "loss": 0.0019,
      "step": 48610
    },
    {
      "epoch": 4.148818158545951,
      "grad_norm": 0.4382224678993225,
      "learning_rate": 8.51181841454049e-06,
      "loss": 0.0021,
      "step": 48620
    },
    {
      "epoch": 4.1496714736752285,
      "grad_norm": 0.1871957927942276,
      "learning_rate": 8.503285263247717e-06,
      "loss": 0.0017,
      "step": 48630
    },
    {
      "epoch": 4.150524788804505,
      "grad_norm": 0.1377749890089035,
      "learning_rate": 8.494752111954946e-06,
      "loss": 0.0017,
      "step": 48640
    },
    {
      "epoch": 4.151378103933783,
      "grad_norm": 0.4330919682979584,
      "learning_rate": 8.486218960662173e-06,
      "loss": 0.0017,
      "step": 48650
    },
    {
      "epoch": 4.15223141906306,
      "grad_norm": 0.10703931748867035,
      "learning_rate": 8.477685809369401e-06,
      "loss": 0.0022,
      "step": 48660
    },
    {
      "epoch": 4.153084734192337,
      "grad_norm": 0.18757988512516022,
      "learning_rate": 8.469152658076628e-06,
      "loss": 0.0018,
      "step": 48670
    },
    {
      "epoch": 4.1539380493216145,
      "grad_norm": 0.13742023706436157,
      "learning_rate": 8.460619506783855e-06,
      "loss": 0.0017,
      "step": 48680
    },
    {
      "epoch": 4.154791364450892,
      "grad_norm": 0.23585250973701477,
      "learning_rate": 8.452086355491083e-06,
      "loss": 0.0019,
      "step": 48690
    },
    {
      "epoch": 4.155644679580169,
      "grad_norm": 0.04578535258769989,
      "learning_rate": 8.443553204198312e-06,
      "loss": 0.0022,
      "step": 48700
    },
    {
      "epoch": 4.156497994709446,
      "grad_norm": 0.17586910724639893,
      "learning_rate": 8.435020052905538e-06,
      "loss": 0.0015,
      "step": 48710
    },
    {
      "epoch": 4.157351309838724,
      "grad_norm": 0.15481457114219666,
      "learning_rate": 8.426486901612767e-06,
      "loss": 0.002,
      "step": 48720
    },
    {
      "epoch": 4.1582046249680005,
      "grad_norm": 0.04780305549502373,
      "learning_rate": 8.417953750319994e-06,
      "loss": 0.0018,
      "step": 48730
    },
    {
      "epoch": 4.159057940097278,
      "grad_norm": 0.2061920464038849,
      "learning_rate": 8.40942059902722e-06,
      "loss": 0.0017,
      "step": 48740
    },
    {
      "epoch": 4.159911255226556,
      "grad_norm": 0.45220062136650085,
      "learning_rate": 8.400887447734449e-06,
      "loss": 0.0019,
      "step": 48750
    },
    {
      "epoch": 4.160764570355832,
      "grad_norm": 0.08130321651697159,
      "learning_rate": 8.392354296441676e-06,
      "loss": 0.0016,
      "step": 48760
    },
    {
      "epoch": 4.16161788548511,
      "grad_norm": 0.14027152955532074,
      "learning_rate": 8.383821145148904e-06,
      "loss": 0.0023,
      "step": 48770
    },
    {
      "epoch": 4.1624712006143865,
      "grad_norm": 0.23433758318424225,
      "learning_rate": 8.375287993856133e-06,
      "loss": 0.0018,
      "step": 48780
    },
    {
      "epoch": 4.163324515743664,
      "grad_norm": 0.12369883060455322,
      "learning_rate": 8.36675484256336e-06,
      "loss": 0.0013,
      "step": 48790
    },
    {
      "epoch": 4.164177830872942,
      "grad_norm": 0.09001782536506653,
      "learning_rate": 8.358221691270586e-06,
      "loss": 0.0016,
      "step": 48800
    },
    {
      "epoch": 4.165031146002218,
      "grad_norm": 0.06385740637779236,
      "learning_rate": 8.349688539977813e-06,
      "loss": 0.0017,
      "step": 48810
    },
    {
      "epoch": 4.165884461131496,
      "grad_norm": 0.08580858260393143,
      "learning_rate": 8.341155388685042e-06,
      "loss": 0.002,
      "step": 48820
    },
    {
      "epoch": 4.166737776260773,
      "grad_norm": 0.12764544785022736,
      "learning_rate": 8.33262223739227e-06,
      "loss": 0.0021,
      "step": 48830
    },
    {
      "epoch": 4.16759109139005,
      "grad_norm": 0.04859628155827522,
      "learning_rate": 8.324089086099497e-06,
      "loss": 0.0018,
      "step": 48840
    },
    {
      "epoch": 4.168444406519328,
      "grad_norm": 0.19509072601795197,
      "learning_rate": 8.315555934806725e-06,
      "loss": 0.0016,
      "step": 48850
    },
    {
      "epoch": 4.169297721648605,
      "grad_norm": 0.24627341330051422,
      "learning_rate": 8.307022783513952e-06,
      "loss": 0.0017,
      "step": 48860
    },
    {
      "epoch": 4.170151036777882,
      "grad_norm": 0.1356874704360962,
      "learning_rate": 8.298489632221179e-06,
      "loss": 0.0021,
      "step": 48870
    },
    {
      "epoch": 4.171004351907159,
      "grad_norm": 0.32030850648880005,
      "learning_rate": 8.289956480928407e-06,
      "loss": 0.0016,
      "step": 48880
    },
    {
      "epoch": 4.171857667036437,
      "grad_norm": 0.21266356110572815,
      "learning_rate": 8.281423329635634e-06,
      "loss": 0.0018,
      "step": 48890
    },
    {
      "epoch": 4.172710982165714,
      "grad_norm": 0.062163833528757095,
      "learning_rate": 8.272890178342863e-06,
      "loss": 0.0018,
      "step": 48900
    },
    {
      "epoch": 4.173564297294991,
      "grad_norm": 0.2552681565284729,
      "learning_rate": 8.264357027050091e-06,
      "loss": 0.0017,
      "step": 48910
    },
    {
      "epoch": 4.174417612424269,
      "grad_norm": 0.15504057705402374,
      "learning_rate": 8.255823875757318e-06,
      "loss": 0.0017,
      "step": 48920
    },
    {
      "epoch": 4.175270927553545,
      "grad_norm": 0.06795790791511536,
      "learning_rate": 8.247290724464545e-06,
      "loss": 0.0016,
      "step": 48930
    },
    {
      "epoch": 4.176124242682823,
      "grad_norm": 0.17239469289779663,
      "learning_rate": 8.238757573171771e-06,
      "loss": 0.0019,
      "step": 48940
    },
    {
      "epoch": 4.1769775578121,
      "grad_norm": 0.26476234197616577,
      "learning_rate": 8.230224421879e-06,
      "loss": 0.0017,
      "step": 48950
    },
    {
      "epoch": 4.177830872941377,
      "grad_norm": 0.2144336849451065,
      "learning_rate": 8.221691270586228e-06,
      "loss": 0.002,
      "step": 48960
    },
    {
      "epoch": 4.178684188070655,
      "grad_norm": 0.07811007648706436,
      "learning_rate": 8.213158119293455e-06,
      "loss": 0.0017,
      "step": 48970
    },
    {
      "epoch": 4.179537503199931,
      "grad_norm": 0.07919246703386307,
      "learning_rate": 8.204624968000684e-06,
      "loss": 0.0017,
      "step": 48980
    },
    {
      "epoch": 4.180390818329209,
      "grad_norm": 0.041840989142656326,
      "learning_rate": 8.19609181670791e-06,
      "loss": 0.0022,
      "step": 48990
    },
    {
      "epoch": 4.1812441334584864,
      "grad_norm": 0.15730233490467072,
      "learning_rate": 8.187558665415137e-06,
      "loss": 0.0021,
      "step": 49000
    },
    {
      "epoch": 4.182097448587763,
      "grad_norm": 0.30885961651802063,
      "learning_rate": 8.179025514122366e-06,
      "loss": 0.0016,
      "step": 49010
    },
    {
      "epoch": 4.182950763717041,
      "grad_norm": 0.12007692456245422,
      "learning_rate": 8.170492362829593e-06,
      "loss": 0.0016,
      "step": 49020
    },
    {
      "epoch": 4.183804078846318,
      "grad_norm": 0.11149724572896957,
      "learning_rate": 8.161959211536821e-06,
      "loss": 0.002,
      "step": 49030
    },
    {
      "epoch": 4.184657393975595,
      "grad_norm": 0.04150216281414032,
      "learning_rate": 8.15342606024405e-06,
      "loss": 0.0021,
      "step": 49040
    },
    {
      "epoch": 4.185510709104872,
      "grad_norm": 0.1747739017009735,
      "learning_rate": 8.144892908951276e-06,
      "loss": 0.0023,
      "step": 49050
    },
    {
      "epoch": 4.18636402423415,
      "grad_norm": 0.29010438919067383,
      "learning_rate": 8.136359757658505e-06,
      "loss": 0.0018,
      "step": 49060
    },
    {
      "epoch": 4.187217339363427,
      "grad_norm": 0.21901963651180267,
      "learning_rate": 8.127826606365732e-06,
      "loss": 0.0016,
      "step": 49070
    },
    {
      "epoch": 4.188070654492704,
      "grad_norm": 0.14061713218688965,
      "learning_rate": 8.119293455072958e-06,
      "loss": 0.0014,
      "step": 49080
    },
    {
      "epoch": 4.188923969621982,
      "grad_norm": 0.18692483007907867,
      "learning_rate": 8.110760303780187e-06,
      "loss": 0.0014,
      "step": 49090
    },
    {
      "epoch": 4.189777284751258,
      "grad_norm": 0.039221931248903275,
      "learning_rate": 8.102227152487414e-06,
      "loss": 0.0017,
      "step": 49100
    },
    {
      "epoch": 4.190630599880536,
      "grad_norm": 0.12078280001878738,
      "learning_rate": 8.093694001194642e-06,
      "loss": 0.0022,
      "step": 49110
    },
    {
      "epoch": 4.1914839150098135,
      "grad_norm": 0.11571860313415527,
      "learning_rate": 8.085160849901869e-06,
      "loss": 0.002,
      "step": 49120
    },
    {
      "epoch": 4.19233723013909,
      "grad_norm": 0.17334939539432526,
      "learning_rate": 8.076627698609096e-06,
      "loss": 0.0019,
      "step": 49130
    },
    {
      "epoch": 4.193190545268368,
      "grad_norm": 0.06683158129453659,
      "learning_rate": 8.068094547316324e-06,
      "loss": 0.0022,
      "step": 49140
    },
    {
      "epoch": 4.194043860397644,
      "grad_norm": 0.4804445505142212,
      "learning_rate": 8.059561396023551e-06,
      "loss": 0.0016,
      "step": 49150
    },
    {
      "epoch": 4.194897175526922,
      "grad_norm": 0.2286357581615448,
      "learning_rate": 8.05102824473078e-06,
      "loss": 0.002,
      "step": 49160
    },
    {
      "epoch": 4.1957504906561995,
      "grad_norm": 0.18886755406856537,
      "learning_rate": 8.042495093438008e-06,
      "loss": 0.0018,
      "step": 49170
    },
    {
      "epoch": 4.196603805785476,
      "grad_norm": 0.09159047901630402,
      "learning_rate": 8.033961942145235e-06,
      "loss": 0.0021,
      "step": 49180
    },
    {
      "epoch": 4.197457120914754,
      "grad_norm": 0.2319161593914032,
      "learning_rate": 8.025428790852463e-06,
      "loss": 0.0018,
      "step": 49190
    },
    {
      "epoch": 4.198310436044031,
      "grad_norm": 0.3343679904937744,
      "learning_rate": 8.01689563955969e-06,
      "loss": 0.0018,
      "step": 49200
    },
    {
      "epoch": 4.199163751173308,
      "grad_norm": 0.15236353874206543,
      "learning_rate": 8.008362488266917e-06,
      "loss": 0.0014,
      "step": 49210
    },
    {
      "epoch": 4.2000170663025855,
      "grad_norm": 0.10234632343053818,
      "learning_rate": 7.999829336974145e-06,
      "loss": 0.0014,
      "step": 49220
    },
    {
      "epoch": 4.200870381431863,
      "grad_norm": 0.23065140843391418,
      "learning_rate": 7.991296185681372e-06,
      "loss": 0.0024,
      "step": 49230
    },
    {
      "epoch": 4.20172369656114,
      "grad_norm": 0.10473625361919403,
      "learning_rate": 7.9827630343886e-06,
      "loss": 0.0023,
      "step": 49240
    },
    {
      "epoch": 4.202577011690417,
      "grad_norm": 0.09639593213796616,
      "learning_rate": 7.974229883095829e-06,
      "loss": 0.0017,
      "step": 49250
    },
    {
      "epoch": 4.203430326819695,
      "grad_norm": 0.05892317742109299,
      "learning_rate": 7.965696731803056e-06,
      "loss": 0.0019,
      "step": 49260
    },
    {
      "epoch": 4.2042836419489715,
      "grad_norm": 0.18790967762470245,
      "learning_rate": 7.957163580510283e-06,
      "loss": 0.0016,
      "step": 49270
    },
    {
      "epoch": 4.205136957078249,
      "grad_norm": 0.11833377927541733,
      "learning_rate": 7.94863042921751e-06,
      "loss": 0.0021,
      "step": 49280
    },
    {
      "epoch": 4.205990272207527,
      "grad_norm": 0.04359789192676544,
      "learning_rate": 7.940097277924738e-06,
      "loss": 0.0017,
      "step": 49290
    },
    {
      "epoch": 4.206843587336803,
      "grad_norm": 0.13854074478149414,
      "learning_rate": 7.931564126631966e-06,
      "loss": 0.0019,
      "step": 49300
    },
    {
      "epoch": 4.207696902466081,
      "grad_norm": 0.15861496329307556,
      "learning_rate": 7.923030975339193e-06,
      "loss": 0.0018,
      "step": 49310
    },
    {
      "epoch": 4.2085502175953575,
      "grad_norm": 0.3233918845653534,
      "learning_rate": 7.914497824046422e-06,
      "loss": 0.0018,
      "step": 49320
    },
    {
      "epoch": 4.209403532724635,
      "grad_norm": 0.04796866327524185,
      "learning_rate": 7.905964672753648e-06,
      "loss": 0.0019,
      "step": 49330
    },
    {
      "epoch": 4.210256847853913,
      "grad_norm": 0.04686817526817322,
      "learning_rate": 7.897431521460875e-06,
      "loss": 0.0022,
      "step": 49340
    },
    {
      "epoch": 4.211110162983189,
      "grad_norm": 0.2394876331090927,
      "learning_rate": 7.888898370168104e-06,
      "loss": 0.0019,
      "step": 49350
    },
    {
      "epoch": 4.211963478112467,
      "grad_norm": 0.13670086860656738,
      "learning_rate": 7.88036521887533e-06,
      "loss": 0.0019,
      "step": 49360
    },
    {
      "epoch": 4.212816793241744,
      "grad_norm": 0.15799838304519653,
      "learning_rate": 7.871832067582559e-06,
      "loss": 0.0018,
      "step": 49370
    },
    {
      "epoch": 4.213670108371021,
      "grad_norm": 0.3019740879535675,
      "learning_rate": 7.863298916289787e-06,
      "loss": 0.0018,
      "step": 49380
    },
    {
      "epoch": 4.214523423500299,
      "grad_norm": 0.08798027783632278,
      "learning_rate": 7.854765764997014e-06,
      "loss": 0.002,
      "step": 49390
    },
    {
      "epoch": 4.215376738629576,
      "grad_norm": 0.2677602767944336,
      "learning_rate": 7.846232613704241e-06,
      "loss": 0.0018,
      "step": 49400
    },
    {
      "epoch": 4.216230053758853,
      "grad_norm": 0.05545736849308014,
      "learning_rate": 7.837699462411468e-06,
      "loss": 0.002,
      "step": 49410
    },
    {
      "epoch": 4.21708336888813,
      "grad_norm": 0.13768085837364197,
      "learning_rate": 7.829166311118696e-06,
      "loss": 0.0019,
      "step": 49420
    },
    {
      "epoch": 4.217936684017408,
      "grad_norm": 0.12370440363883972,
      "learning_rate": 7.820633159825925e-06,
      "loss": 0.0017,
      "step": 49430
    },
    {
      "epoch": 4.218789999146685,
      "grad_norm": 0.030050190165638924,
      "learning_rate": 7.812100008533151e-06,
      "loss": 0.002,
      "step": 49440
    },
    {
      "epoch": 4.219643314275962,
      "grad_norm": 0.0801837369799614,
      "learning_rate": 7.80356685724038e-06,
      "loss": 0.002,
      "step": 49450
    },
    {
      "epoch": 4.22049662940524,
      "grad_norm": 0.084305040538311,
      "learning_rate": 7.795033705947607e-06,
      "loss": 0.0018,
      "step": 49460
    },
    {
      "epoch": 4.221349944534516,
      "grad_norm": 0.2511396110057831,
      "learning_rate": 7.786500554654834e-06,
      "loss": 0.0019,
      "step": 49470
    },
    {
      "epoch": 4.222203259663794,
      "grad_norm": 0.18547099828720093,
      "learning_rate": 7.777967403362062e-06,
      "loss": 0.0018,
      "step": 49480
    },
    {
      "epoch": 4.2230565747930715,
      "grad_norm": 0.18952807784080505,
      "learning_rate": 7.769434252069289e-06,
      "loss": 0.0018,
      "step": 49490
    },
    {
      "epoch": 4.223909889922348,
      "grad_norm": 0.2950287163257599,
      "learning_rate": 7.760901100776517e-06,
      "loss": 0.002,
      "step": 49500
    },
    {
      "epoch": 4.224763205051626,
      "grad_norm": 0.07032269984483719,
      "learning_rate": 7.752367949483746e-06,
      "loss": 0.0017,
      "step": 49510
    },
    {
      "epoch": 4.225616520180902,
      "grad_norm": 0.12976393103599548,
      "learning_rate": 7.743834798190973e-06,
      "loss": 0.0017,
      "step": 49520
    },
    {
      "epoch": 4.22646983531018,
      "grad_norm": 0.16175124049186707,
      "learning_rate": 7.7353016468982e-06,
      "loss": 0.0021,
      "step": 49530
    },
    {
      "epoch": 4.2273231504394575,
      "grad_norm": 0.06265687197446823,
      "learning_rate": 7.726768495605428e-06,
      "loss": 0.002,
      "step": 49540
    },
    {
      "epoch": 4.228176465568734,
      "grad_norm": 0.28043827414512634,
      "learning_rate": 7.718235344312655e-06,
      "loss": 0.0019,
      "step": 49550
    },
    {
      "epoch": 4.229029780698012,
      "grad_norm": 0.19638527929782867,
      "learning_rate": 7.709702193019883e-06,
      "loss": 0.0017,
      "step": 49560
    },
    {
      "epoch": 4.229883095827289,
      "grad_norm": 0.08474749326705933,
      "learning_rate": 7.70116904172711e-06,
      "loss": 0.0016,
      "step": 49570
    },
    {
      "epoch": 4.230736410956566,
      "grad_norm": 0.05203419178724289,
      "learning_rate": 7.692635890434338e-06,
      "loss": 0.0019,
      "step": 49580
    },
    {
      "epoch": 4.2315897260858435,
      "grad_norm": 0.3415677547454834,
      "learning_rate": 7.684102739141565e-06,
      "loss": 0.0019,
      "step": 49590
    },
    {
      "epoch": 4.232443041215121,
      "grad_norm": 0.0834597572684288,
      "learning_rate": 7.675569587848792e-06,
      "loss": 0.0018,
      "step": 49600
    },
    {
      "epoch": 4.233296356344398,
      "grad_norm": 0.35749000310897827,
      "learning_rate": 7.66703643655602e-06,
      "loss": 0.002,
      "step": 49610
    },
    {
      "epoch": 4.234149671473675,
      "grad_norm": 0.2589403986930847,
      "learning_rate": 7.658503285263247e-06,
      "loss": 0.0018,
      "step": 49620
    },
    {
      "epoch": 4.235002986602953,
      "grad_norm": 0.08780317008495331,
      "learning_rate": 7.649970133970476e-06,
      "loss": 0.002,
      "step": 49630
    },
    {
      "epoch": 4.2358563017322295,
      "grad_norm": 0.09593646973371506,
      "learning_rate": 7.641436982677704e-06,
      "loss": 0.0014,
      "step": 49640
    },
    {
      "epoch": 4.236709616861507,
      "grad_norm": 0.17988814413547516,
      "learning_rate": 7.632903831384931e-06,
      "loss": 0.0014,
      "step": 49650
    },
    {
      "epoch": 4.237562931990785,
      "grad_norm": 0.04967190697789192,
      "learning_rate": 7.624370680092158e-06,
      "loss": 0.0017,
      "step": 49660
    },
    {
      "epoch": 4.238416247120061,
      "grad_norm": 0.32489433884620667,
      "learning_rate": 7.615837528799385e-06,
      "loss": 0.0022,
      "step": 49670
    },
    {
      "epoch": 4.239269562249339,
      "grad_norm": 0.22867034375667572,
      "learning_rate": 7.607304377506613e-06,
      "loss": 0.0025,
      "step": 49680
    },
    {
      "epoch": 4.2401228773786155,
      "grad_norm": 0.06442394107580185,
      "learning_rate": 7.598771226213841e-06,
      "loss": 0.0016,
      "step": 49690
    },
    {
      "epoch": 4.240976192507893,
      "grad_norm": 0.3302181661128998,
      "learning_rate": 7.590238074921069e-06,
      "loss": 0.0019,
      "step": 49700
    },
    {
      "epoch": 4.241829507637171,
      "grad_norm": 0.06172802671790123,
      "learning_rate": 7.581704923628297e-06,
      "loss": 0.0019,
      "step": 49710
    },
    {
      "epoch": 4.242682822766447,
      "grad_norm": 0.29865583777427673,
      "learning_rate": 7.5731717723355244e-06,
      "loss": 0.0016,
      "step": 49720
    },
    {
      "epoch": 4.243536137895725,
      "grad_norm": 0.1703009307384491,
      "learning_rate": 7.564638621042751e-06,
      "loss": 0.0018,
      "step": 49730
    },
    {
      "epoch": 4.244389453025002,
      "grad_norm": 0.06144241988658905,
      "learning_rate": 7.556105469749979e-06,
      "loss": 0.0019,
      "step": 49740
    },
    {
      "epoch": 4.245242768154279,
      "grad_norm": 0.24726678431034088,
      "learning_rate": 7.5475723184572065e-06,
      "loss": 0.0012,
      "step": 49750
    },
    {
      "epoch": 4.246096083283557,
      "grad_norm": 0.10239368677139282,
      "learning_rate": 7.539039167164434e-06,
      "loss": 0.0019,
      "step": 49760
    },
    {
      "epoch": 4.246949398412834,
      "grad_norm": 0.19020675122737885,
      "learning_rate": 7.530506015871662e-06,
      "loss": 0.0017,
      "step": 49770
    },
    {
      "epoch": 4.247802713542111,
      "grad_norm": 0.2710193693637848,
      "learning_rate": 7.521972864578889e-06,
      "loss": 0.0019,
      "step": 49780
    },
    {
      "epoch": 4.248656028671388,
      "grad_norm": 0.08203858137130737,
      "learning_rate": 7.513439713286118e-06,
      "loss": 0.0016,
      "step": 49790
    },
    {
      "epoch": 4.249509343800666,
      "grad_norm": 0.08976496756076813,
      "learning_rate": 7.504906561993344e-06,
      "loss": 0.0021,
      "step": 49800
    },
    {
      "epoch": 4.250362658929943,
      "grad_norm": 0.29388436675071716,
      "learning_rate": 7.4963734107005714e-06,
      "loss": 0.0018,
      "step": 49810
    },
    {
      "epoch": 4.25121597405922,
      "grad_norm": 0.029644586145877838,
      "learning_rate": 7.4878402594078e-06,
      "loss": 0.002,
      "step": 49820
    },
    {
      "epoch": 4.252069289188498,
      "grad_norm": 0.04033650457859039,
      "learning_rate": 7.4793071081150276e-06,
      "loss": 0.0016,
      "step": 49830
    },
    {
      "epoch": 4.252922604317774,
      "grad_norm": 0.15007542073726654,
      "learning_rate": 7.470773956822255e-06,
      "loss": 0.002,
      "step": 49840
    },
    {
      "epoch": 4.253775919447052,
      "grad_norm": 0.2475384622812271,
      "learning_rate": 7.462240805529483e-06,
      "loss": 0.0017,
      "step": 49850
    },
    {
      "epoch": 4.2546292345763295,
      "grad_norm": 0.040881820023059845,
      "learning_rate": 7.45370765423671e-06,
      "loss": 0.0013,
      "step": 49860
    },
    {
      "epoch": 4.255482549705606,
      "grad_norm": 0.17785906791687012,
      "learning_rate": 7.445174502943937e-06,
      "loss": 0.0018,
      "step": 49870
    },
    {
      "epoch": 4.256335864834884,
      "grad_norm": 0.2217397689819336,
      "learning_rate": 7.436641351651165e-06,
      "loss": 0.0016,
      "step": 49880
    },
    {
      "epoch": 4.25718917996416,
      "grad_norm": 0.2613059878349304,
      "learning_rate": 7.4281082003583925e-06,
      "loss": 0.0018,
      "step": 49890
    },
    {
      "epoch": 4.258042495093438,
      "grad_norm": 0.2640771269798279,
      "learning_rate": 7.41957504906562e-06,
      "loss": 0.0019,
      "step": 49900
    },
    {
      "epoch": 4.2588958102227155,
      "grad_norm": 0.19535067677497864,
      "learning_rate": 7.411041897772849e-06,
      "loss": 0.0023,
      "step": 49910
    },
    {
      "epoch": 4.259749125351992,
      "grad_norm": 0.15649837255477905,
      "learning_rate": 7.402508746480076e-06,
      "loss": 0.0021,
      "step": 49920
    },
    {
      "epoch": 4.26060244048127,
      "grad_norm": 0.45530378818511963,
      "learning_rate": 7.393975595187302e-06,
      "loss": 0.0024,
      "step": 49930
    },
    {
      "epoch": 4.261455755610547,
      "grad_norm": 0.21949781477451324,
      "learning_rate": 7.38544244389453e-06,
      "loss": 0.0022,
      "step": 49940
    },
    {
      "epoch": 4.262309070739824,
      "grad_norm": 0.11545560508966446,
      "learning_rate": 7.376909292601758e-06,
      "loss": 0.0024,
      "step": 49950
    },
    {
      "epoch": 4.2631623858691015,
      "grad_norm": 0.04866650700569153,
      "learning_rate": 7.368376141308986e-06,
      "loss": 0.0018,
      "step": 49960
    },
    {
      "epoch": 4.264015700998379,
      "grad_norm": 0.03984365239739418,
      "learning_rate": 7.359842990016214e-06,
      "loss": 0.0021,
      "step": 49970
    },
    {
      "epoch": 4.264869016127656,
      "grad_norm": 0.22625358402729034,
      "learning_rate": 7.351309838723441e-06,
      "loss": 0.0013,
      "step": 49980
    },
    {
      "epoch": 4.265722331256933,
      "grad_norm": 0.1362827569246292,
      "learning_rate": 7.342776687430669e-06,
      "loss": 0.0016,
      "step": 49990
    },
    {
      "epoch": 4.266575646386211,
      "grad_norm": 0.2825293242931366,
      "learning_rate": 7.334243536137896e-06,
      "loss": 0.0016,
      "step": 50000
    },
    {
      "epoch": 4.2674289615154875,
      "grad_norm": 0.3942122459411621,
      "learning_rate": 7.325710384845123e-06,
      "loss": 0.0015,
      "step": 50010
    },
    {
      "epoch": 4.268282276644765,
      "grad_norm": 0.08682098984718323,
      "learning_rate": 7.317177233552351e-06,
      "loss": 0.0018,
      "step": 50020
    },
    {
      "epoch": 4.269135591774043,
      "grad_norm": 0.31606411933898926,
      "learning_rate": 7.3086440822595786e-06,
      "loss": 0.0018,
      "step": 50030
    },
    {
      "epoch": 4.269988906903319,
      "grad_norm": 0.29046711325645447,
      "learning_rate": 7.300110930966807e-06,
      "loss": 0.0017,
      "step": 50040
    },
    {
      "epoch": 4.270842222032597,
      "grad_norm": 0.44682276248931885,
      "learning_rate": 7.291577779674035e-06,
      "loss": 0.0019,
      "step": 50050
    },
    {
      "epoch": 4.2716955371618734,
      "grad_norm": 0.20611296594142914,
      "learning_rate": 7.283044628381261e-06,
      "loss": 0.0018,
      "step": 50060
    },
    {
      "epoch": 4.272548852291151,
      "grad_norm": 0.24619357287883759,
      "learning_rate": 7.274511477088488e-06,
      "loss": 0.002,
      "step": 50070
    },
    {
      "epoch": 4.2734021674204286,
      "grad_norm": 0.13957519829273224,
      "learning_rate": 7.265978325795717e-06,
      "loss": 0.0018,
      "step": 50080
    },
    {
      "epoch": 4.274255482549705,
      "grad_norm": 0.3996846377849579,
      "learning_rate": 7.257445174502944e-06,
      "loss": 0.0017,
      "step": 50090
    },
    {
      "epoch": 4.275108797678983,
      "grad_norm": 0.3482362627983093,
      "learning_rate": 7.248912023210172e-06,
      "loss": 0.0015,
      "step": 50100
    },
    {
      "epoch": 4.27596211280826,
      "grad_norm": 0.2592250108718872,
      "learning_rate": 7.2403788719174e-06,
      "loss": 0.0019,
      "step": 50110
    },
    {
      "epoch": 4.276815427937537,
      "grad_norm": 0.06519391387701035,
      "learning_rate": 7.231845720624627e-06,
      "loss": 0.0023,
      "step": 50120
    },
    {
      "epoch": 4.2776687430668145,
      "grad_norm": 0.10735002905130386,
      "learning_rate": 7.223312569331854e-06,
      "loss": 0.0019,
      "step": 50130
    },
    {
      "epoch": 4.278522058196092,
      "grad_norm": 0.10085618495941162,
      "learning_rate": 7.214779418039082e-06,
      "loss": 0.0021,
      "step": 50140
    },
    {
      "epoch": 4.279375373325369,
      "grad_norm": 0.06252676248550415,
      "learning_rate": 7.206246266746309e-06,
      "loss": 0.0022,
      "step": 50150
    },
    {
      "epoch": 4.280228688454646,
      "grad_norm": 0.2450043261051178,
      "learning_rate": 7.197713115453537e-06,
      "loss": 0.0017,
      "step": 50160
    },
    {
      "epoch": 4.281082003583924,
      "grad_norm": 0.09652440994977951,
      "learning_rate": 7.1891799641607655e-06,
      "loss": 0.0017,
      "step": 50170
    },
    {
      "epoch": 4.2819353187132005,
      "grad_norm": 0.16879329085350037,
      "learning_rate": 7.180646812867993e-06,
      "loss": 0.0017,
      "step": 50180
    },
    {
      "epoch": 4.282788633842478,
      "grad_norm": 0.04022859036922455,
      "learning_rate": 7.172113661575221e-06,
      "loss": 0.0019,
      "step": 50190
    },
    {
      "epoch": 4.283641948971756,
      "grad_norm": 0.17469662427902222,
      "learning_rate": 7.1635805102824475e-06,
      "loss": 0.0018,
      "step": 50200
    },
    {
      "epoch": 4.284495264101032,
      "grad_norm": 0.045461397618055344,
      "learning_rate": 7.155047358989675e-06,
      "loss": 0.0018,
      "step": 50210
    },
    {
      "epoch": 4.28534857923031,
      "grad_norm": 0.07185900956392288,
      "learning_rate": 7.146514207696903e-06,
      "loss": 0.0017,
      "step": 50220
    },
    {
      "epoch": 4.286201894359587,
      "grad_norm": 0.06716553121805191,
      "learning_rate": 7.13798105640413e-06,
      "loss": 0.0018,
      "step": 50230
    },
    {
      "epoch": 4.287055209488864,
      "grad_norm": 0.23957477509975433,
      "learning_rate": 7.129447905111358e-06,
      "loss": 0.0019,
      "step": 50240
    },
    {
      "epoch": 4.287908524618142,
      "grad_norm": 0.17082807421684265,
      "learning_rate": 7.120914753818586e-06,
      "loss": 0.0017,
      "step": 50250
    },
    {
      "epoch": 4.288761839747418,
      "grad_norm": 0.3015460669994354,
      "learning_rate": 7.1123816025258125e-06,
      "loss": 0.0017,
      "step": 50260
    },
    {
      "epoch": 4.289615154876696,
      "grad_norm": 0.26722094416618347,
      "learning_rate": 7.10384845123304e-06,
      "loss": 0.002,
      "step": 50270
    },
    {
      "epoch": 4.290468470005973,
      "grad_norm": 0.24602407217025757,
      "learning_rate": 7.095315299940268e-06,
      "loss": 0.0014,
      "step": 50280
    },
    {
      "epoch": 4.29132178513525,
      "grad_norm": 0.1943315714597702,
      "learning_rate": 7.086782148647496e-06,
      "loss": 0.0018,
      "step": 50290
    },
    {
      "epoch": 4.292175100264528,
      "grad_norm": 0.18165412545204163,
      "learning_rate": 7.078248997354724e-06,
      "loss": 0.002,
      "step": 50300
    },
    {
      "epoch": 4.293028415393805,
      "grad_norm": 0.10861249268054962,
      "learning_rate": 7.0697158460619515e-06,
      "loss": 0.0024,
      "step": 50310
    },
    {
      "epoch": 4.293881730523082,
      "grad_norm": 0.17500390112400055,
      "learning_rate": 7.061182694769179e-06,
      "loss": 0.0019,
      "step": 50320
    },
    {
      "epoch": 4.294735045652359,
      "grad_norm": 0.2984810769557953,
      "learning_rate": 7.052649543476406e-06,
      "loss": 0.0014,
      "step": 50330
    },
    {
      "epoch": 4.295588360781637,
      "grad_norm": 0.2961916923522949,
      "learning_rate": 7.0441163921836336e-06,
      "loss": 0.0019,
      "step": 50340
    },
    {
      "epoch": 4.296441675910914,
      "grad_norm": 0.3011440336704254,
      "learning_rate": 7.035583240890861e-06,
      "loss": 0.003,
      "step": 50350
    },
    {
      "epoch": 4.297294991040191,
      "grad_norm": 0.13008415699005127,
      "learning_rate": 7.027050089598089e-06,
      "loss": 0.0021,
      "step": 50360
    },
    {
      "epoch": 4.298148306169469,
      "grad_norm": 0.13555368781089783,
      "learning_rate": 7.0185169383053165e-06,
      "loss": 0.0019,
      "step": 50370
    },
    {
      "epoch": 4.299001621298745,
      "grad_norm": 0.17871014773845673,
      "learning_rate": 7.009983787012545e-06,
      "loss": 0.002,
      "step": 50380
    },
    {
      "epoch": 4.299854936428023,
      "grad_norm": 0.06478866934776306,
      "learning_rate": 7.001450635719773e-06,
      "loss": 0.0018,
      "step": 50390
    },
    {
      "epoch": 4.3007082515573005,
      "grad_norm": 0.09892292320728302,
      "learning_rate": 6.9929174844269985e-06,
      "loss": 0.0016,
      "step": 50400
    },
    {
      "epoch": 4.301561566686577,
      "grad_norm": 0.06881792098283768,
      "learning_rate": 6.984384333134226e-06,
      "loss": 0.0023,
      "step": 50410
    },
    {
      "epoch": 4.302414881815855,
      "grad_norm": 0.06475473195314407,
      "learning_rate": 6.975851181841455e-06,
      "loss": 0.0016,
      "step": 50420
    },
    {
      "epoch": 4.303268196945131,
      "grad_norm": 0.04568856582045555,
      "learning_rate": 6.967318030548682e-06,
      "loss": 0.0018,
      "step": 50430
    },
    {
      "epoch": 4.304121512074409,
      "grad_norm": 0.135978564620018,
      "learning_rate": 6.95878487925591e-06,
      "loss": 0.0018,
      "step": 50440
    },
    {
      "epoch": 4.3049748272036865,
      "grad_norm": 0.19141843914985657,
      "learning_rate": 6.9502517279631375e-06,
      "loss": 0.0016,
      "step": 50450
    },
    {
      "epoch": 4.305828142332963,
      "grad_norm": 0.3108678162097931,
      "learning_rate": 6.941718576670364e-06,
      "loss": 0.0019,
      "step": 50460
    },
    {
      "epoch": 4.306681457462241,
      "grad_norm": 0.11637000739574432,
      "learning_rate": 6.933185425377592e-06,
      "loss": 0.0013,
      "step": 50470
    },
    {
      "epoch": 4.307534772591518,
      "grad_norm": 0.20622247457504272,
      "learning_rate": 6.92465227408482e-06,
      "loss": 0.0017,
      "step": 50480
    },
    {
      "epoch": 4.308388087720795,
      "grad_norm": 0.12088999897241592,
      "learning_rate": 6.916119122792047e-06,
      "loss": 0.0017,
      "step": 50490
    },
    {
      "epoch": 4.3092414028500725,
      "grad_norm": 0.3406608998775482,
      "learning_rate": 6.907585971499275e-06,
      "loss": 0.0019,
      "step": 50500
    },
    {
      "epoch": 4.31009471797935,
      "grad_norm": 0.2940325438976288,
      "learning_rate": 6.899052820206503e-06,
      "loss": 0.0018,
      "step": 50510
    },
    {
      "epoch": 4.310948033108627,
      "grad_norm": 0.40036165714263916,
      "learning_rate": 6.890519668913731e-06,
      "loss": 0.002,
      "step": 50520
    },
    {
      "epoch": 4.311801348237904,
      "grad_norm": 0.1761091649532318,
      "learning_rate": 6.881986517620957e-06,
      "loss": 0.0021,
      "step": 50530
    },
    {
      "epoch": 4.312654663367182,
      "grad_norm": 0.08408346772193909,
      "learning_rate": 6.873453366328185e-06,
      "loss": 0.0019,
      "step": 50540
    },
    {
      "epoch": 4.3135079784964585,
      "grad_norm": 0.1386520266532898,
      "learning_rate": 6.864920215035413e-06,
      "loss": 0.0021,
      "step": 50550
    },
    {
      "epoch": 4.314361293625736,
      "grad_norm": 0.24812005460262299,
      "learning_rate": 6.856387063742641e-06,
      "loss": 0.0021,
      "step": 50560
    },
    {
      "epoch": 4.315214608755014,
      "grad_norm": 0.12291041016578674,
      "learning_rate": 6.847853912449868e-06,
      "loss": 0.0016,
      "step": 50570
    },
    {
      "epoch": 4.31606792388429,
      "grad_norm": 0.03840876743197441,
      "learning_rate": 6.839320761157096e-06,
      "loss": 0.0017,
      "step": 50580
    },
    {
      "epoch": 4.316921239013568,
      "grad_norm": 0.2469758838415146,
      "learning_rate": 6.830787609864323e-06,
      "loss": 0.0016,
      "step": 50590
    },
    {
      "epoch": 4.317774554142845,
      "grad_norm": 0.196142315864563,
      "learning_rate": 6.82225445857155e-06,
      "loss": 0.0021,
      "step": 50600
    },
    {
      "epoch": 4.318627869272122,
      "grad_norm": 0.1896667331457138,
      "learning_rate": 6.813721307278778e-06,
      "loss": 0.0023,
      "step": 50610
    },
    {
      "epoch": 4.3194811844014,
      "grad_norm": 0.05095125734806061,
      "learning_rate": 6.805188155986006e-06,
      "loss": 0.0015,
      "step": 50620
    },
    {
      "epoch": 4.320334499530676,
      "grad_norm": 0.10585406422615051,
      "learning_rate": 6.796655004693233e-06,
      "loss": 0.002,
      "step": 50630
    },
    {
      "epoch": 4.321187814659954,
      "grad_norm": 0.12558536231517792,
      "learning_rate": 6.788121853400462e-06,
      "loss": 0.0016,
      "step": 50640
    },
    {
      "epoch": 4.322041129789231,
      "grad_norm": 0.12801481783390045,
      "learning_rate": 6.779588702107689e-06,
      "loss": 0.0016,
      "step": 50650
    },
    {
      "epoch": 4.322894444918508,
      "grad_norm": 0.14220423996448517,
      "learning_rate": 6.771055550814915e-06,
      "loss": 0.0018,
      "step": 50660
    },
    {
      "epoch": 4.323747760047786,
      "grad_norm": 0.397849440574646,
      "learning_rate": 6.762522399522144e-06,
      "loss": 0.0014,
      "step": 50670
    },
    {
      "epoch": 4.324601075177063,
      "grad_norm": 0.34497398138046265,
      "learning_rate": 6.7539892482293714e-06,
      "loss": 0.002,
      "step": 50680
    },
    {
      "epoch": 4.32545439030634,
      "grad_norm": 0.23533032834529877,
      "learning_rate": 6.745456096936599e-06,
      "loss": 0.0018,
      "step": 50690
    },
    {
      "epoch": 4.326307705435617,
      "grad_norm": 0.15750233829021454,
      "learning_rate": 6.736922945643827e-06,
      "loss": 0.0018,
      "step": 50700
    },
    {
      "epoch": 4.327161020564895,
      "grad_norm": 0.1886097937822342,
      "learning_rate": 6.728389794351054e-06,
      "loss": 0.0015,
      "step": 50710
    },
    {
      "epoch": 4.328014335694172,
      "grad_norm": 0.14959874749183655,
      "learning_rate": 6.719856643058282e-06,
      "loss": 0.0021,
      "step": 50720
    },
    {
      "epoch": 4.328867650823449,
      "grad_norm": 0.32273122668266296,
      "learning_rate": 6.711323491765509e-06,
      "loss": 0.0018,
      "step": 50730
    },
    {
      "epoch": 4.329720965952727,
      "grad_norm": 0.09101363271474838,
      "learning_rate": 6.702790340472736e-06,
      "loss": 0.0021,
      "step": 50740
    },
    {
      "epoch": 4.330574281082003,
      "grad_norm": 0.21111002564430237,
      "learning_rate": 6.694257189179964e-06,
      "loss": 0.0018,
      "step": 50750
    },
    {
      "epoch": 4.331427596211281,
      "grad_norm": 0.25102975964546204,
      "learning_rate": 6.6857240378871925e-06,
      "loss": 0.0019,
      "step": 50760
    },
    {
      "epoch": 4.3322809113405585,
      "grad_norm": 0.11215771734714508,
      "learning_rate": 6.67719088659442e-06,
      "loss": 0.0021,
      "step": 50770
    },
    {
      "epoch": 4.333134226469835,
      "grad_norm": 0.05278551205992699,
      "learning_rate": 6.668657735301648e-06,
      "loss": 0.0025,
      "step": 50780
    },
    {
      "epoch": 4.333987541599113,
      "grad_norm": 0.2147417813539505,
      "learning_rate": 6.660124584008874e-06,
      "loss": 0.0021,
      "step": 50790
    },
    {
      "epoch": 4.334840856728389,
      "grad_norm": 0.1031264066696167,
      "learning_rate": 6.651591432716102e-06,
      "loss": 0.0019,
      "step": 50800
    },
    {
      "epoch": 4.335694171857667,
      "grad_norm": 0.11675652861595154,
      "learning_rate": 6.64305828142333e-06,
      "loss": 0.0014,
      "step": 50810
    },
    {
      "epoch": 4.3365474869869445,
      "grad_norm": 0.20790964365005493,
      "learning_rate": 6.6345251301305575e-06,
      "loss": 0.0016,
      "step": 50820
    },
    {
      "epoch": 4.337400802116221,
      "grad_norm": 0.17695166170597076,
      "learning_rate": 6.625991978837785e-06,
      "loss": 0.002,
      "step": 50830
    },
    {
      "epoch": 4.338254117245499,
      "grad_norm": 0.10193054378032684,
      "learning_rate": 6.617458827545013e-06,
      "loss": 0.0014,
      "step": 50840
    },
    {
      "epoch": 4.339107432374776,
      "grad_norm": 0.11822067201137543,
      "learning_rate": 6.608925676252241e-06,
      "loss": 0.0018,
      "step": 50850
    },
    {
      "epoch": 4.339960747504053,
      "grad_norm": 0.32689353823661804,
      "learning_rate": 6.600392524959467e-06,
      "loss": 0.0016,
      "step": 50860
    },
    {
      "epoch": 4.3408140626333305,
      "grad_norm": 0.2365032583475113,
      "learning_rate": 6.591859373666695e-06,
      "loss": 0.002,
      "step": 50870
    },
    {
      "epoch": 4.341667377762608,
      "grad_norm": 0.10250280052423477,
      "learning_rate": 6.5833262223739225e-06,
      "loss": 0.002,
      "step": 50880
    },
    {
      "epoch": 4.342520692891885,
      "grad_norm": 0.24745407700538635,
      "learning_rate": 6.574793071081151e-06,
      "loss": 0.0016,
      "step": 50890
    },
    {
      "epoch": 4.343374008021162,
      "grad_norm": 0.16309930384159088,
      "learning_rate": 6.5662599197883786e-06,
      "loss": 0.0018,
      "step": 50900
    },
    {
      "epoch": 4.34422732315044,
      "grad_norm": 0.09353791177272797,
      "learning_rate": 6.557726768495606e-06,
      "loss": 0.0017,
      "step": 50910
    },
    {
      "epoch": 4.3450806382797165,
      "grad_norm": 0.16198603808879852,
      "learning_rate": 6.549193617202834e-06,
      "loss": 0.0017,
      "step": 50920
    },
    {
      "epoch": 4.345933953408994,
      "grad_norm": 0.2869809567928314,
      "learning_rate": 6.540660465910061e-06,
      "loss": 0.0022,
      "step": 50930
    },
    {
      "epoch": 4.346787268538272,
      "grad_norm": 0.18761838972568512,
      "learning_rate": 6.532127314617288e-06,
      "loss": 0.0015,
      "step": 50940
    },
    {
      "epoch": 4.347640583667548,
      "grad_norm": 0.26847484707832336,
      "learning_rate": 6.523594163324516e-06,
      "loss": 0.0016,
      "step": 50950
    },
    {
      "epoch": 4.348493898796826,
      "grad_norm": 0.08241229504346848,
      "learning_rate": 6.5150610120317435e-06,
      "loss": 0.0016,
      "step": 50960
    },
    {
      "epoch": 4.349347213926103,
      "grad_norm": 0.10888893902301788,
      "learning_rate": 6.506527860738971e-06,
      "loss": 0.0018,
      "step": 50970
    },
    {
      "epoch": 4.35020052905538,
      "grad_norm": 0.15375475585460663,
      "learning_rate": 6.4979947094462e-06,
      "loss": 0.0016,
      "step": 50980
    },
    {
      "epoch": 4.351053844184658,
      "grad_norm": 0.1454395353794098,
      "learning_rate": 6.489461558153426e-06,
      "loss": 0.0021,
      "step": 50990
    },
    {
      "epoch": 4.351907159313934,
      "grad_norm": 0.16010427474975586,
      "learning_rate": 6.480928406860653e-06,
      "loss": 0.002,
      "step": 51000
    },
    {
      "epoch": 4.352760474443212,
      "grad_norm": 0.09479546546936035,
      "learning_rate": 6.472395255567882e-06,
      "loss": 0.002,
      "step": 51010
    },
    {
      "epoch": 4.353613789572489,
      "grad_norm": 0.3373713493347168,
      "learning_rate": 6.463862104275109e-06,
      "loss": 0.0016,
      "step": 51020
    },
    {
      "epoch": 4.354467104701766,
      "grad_norm": 0.44034427404403687,
      "learning_rate": 6.455328952982337e-06,
      "loss": 0.0014,
      "step": 51030
    },
    {
      "epoch": 4.355320419831044,
      "grad_norm": 0.06129199638962746,
      "learning_rate": 6.446795801689565e-06,
      "loss": 0.0019,
      "step": 51040
    },
    {
      "epoch": 4.356173734960321,
      "grad_norm": 0.04376061260700226,
      "learning_rate": 6.438262650396792e-06,
      "loss": 0.0018,
      "step": 51050
    },
    {
      "epoch": 4.357027050089598,
      "grad_norm": 0.039885737001895905,
      "learning_rate": 6.429729499104019e-06,
      "loss": 0.0022,
      "step": 51060
    },
    {
      "epoch": 4.357880365218875,
      "grad_norm": 0.24383658170700073,
      "learning_rate": 6.421196347811247e-06,
      "loss": 0.0016,
      "step": 51070
    },
    {
      "epoch": 4.358733680348153,
      "grad_norm": 0.07429203391075134,
      "learning_rate": 6.412663196518474e-06,
      "loss": 0.0021,
      "step": 51080
    },
    {
      "epoch": 4.35958699547743,
      "grad_norm": 0.15246941149234772,
      "learning_rate": 6.404130045225702e-06,
      "loss": 0.0021,
      "step": 51090
    },
    {
      "epoch": 4.360440310606707,
      "grad_norm": 0.05268074944615364,
      "learning_rate": 6.3955968939329296e-06,
      "loss": 0.0018,
      "step": 51100
    },
    {
      "epoch": 4.361293625735985,
      "grad_norm": 0.02867656573653221,
      "learning_rate": 6.387063742640158e-06,
      "loss": 0.0016,
      "step": 51110
    },
    {
      "epoch": 4.362146940865261,
      "grad_norm": 0.05227131396532059,
      "learning_rate": 6.378530591347386e-06,
      "loss": 0.0017,
      "step": 51120
    },
    {
      "epoch": 4.363000255994539,
      "grad_norm": 0.0631721243262291,
      "learning_rate": 6.369997440054612e-06,
      "loss": 0.0015,
      "step": 51130
    },
    {
      "epoch": 4.3638535711238156,
      "grad_norm": 0.09265757352113724,
      "learning_rate": 6.36146428876184e-06,
      "loss": 0.002,
      "step": 51140
    },
    {
      "epoch": 4.364706886253093,
      "grad_norm": 0.2013646811246872,
      "learning_rate": 6.352931137469068e-06,
      "loss": 0.0018,
      "step": 51150
    },
    {
      "epoch": 4.365560201382371,
      "grad_norm": 0.23010608553886414,
      "learning_rate": 6.344397986176295e-06,
      "loss": 0.002,
      "step": 51160
    },
    {
      "epoch": 4.366413516511647,
      "grad_norm": 0.25079435110092163,
      "learning_rate": 6.335864834883523e-06,
      "loss": 0.0018,
      "step": 51170
    },
    {
      "epoch": 4.367266831640925,
      "grad_norm": 0.05157209187746048,
      "learning_rate": 6.327331683590751e-06,
      "loss": 0.0023,
      "step": 51180
    },
    {
      "epoch": 4.368120146770202,
      "grad_norm": 0.14243397116661072,
      "learning_rate": 6.3187985322979774e-06,
      "loss": 0.0016,
      "step": 51190
    },
    {
      "epoch": 4.368973461899479,
      "grad_norm": 0.14647376537322998,
      "learning_rate": 6.310265381005205e-06,
      "loss": 0.0015,
      "step": 51200
    },
    {
      "epoch": 4.369826777028757,
      "grad_norm": 0.03961577266454697,
      "learning_rate": 6.301732229712433e-06,
      "loss": 0.0018,
      "step": 51210
    },
    {
      "epoch": 4.370680092158034,
      "grad_norm": 0.22304576635360718,
      "learning_rate": 6.29319907841966e-06,
      "loss": 0.0021,
      "step": 51220
    },
    {
      "epoch": 4.371533407287311,
      "grad_norm": 0.1010359451174736,
      "learning_rate": 6.284665927126889e-06,
      "loss": 0.0018,
      "step": 51230
    },
    {
      "epoch": 4.372386722416588,
      "grad_norm": 0.05808987841010094,
      "learning_rate": 6.2761327758341165e-06,
      "loss": 0.0019,
      "step": 51240
    },
    {
      "epoch": 4.373240037545866,
      "grad_norm": 0.24606452882289886,
      "learning_rate": 6.267599624541344e-06,
      "loss": 0.0018,
      "step": 51250
    },
    {
      "epoch": 4.374093352675143,
      "grad_norm": 0.060620419681072235,
      "learning_rate": 6.25906647324857e-06,
      "loss": 0.0017,
      "step": 51260
    },
    {
      "epoch": 4.37494666780442,
      "grad_norm": 0.20105619728565216,
      "learning_rate": 6.2505333219557985e-06,
      "loss": 0.0015,
      "step": 51270
    },
    {
      "epoch": 4.375799982933698,
      "grad_norm": 0.1032213494181633,
      "learning_rate": 6.242000170663026e-06,
      "loss": 0.0018,
      "step": 51280
    },
    {
      "epoch": 4.376653298062974,
      "grad_norm": 0.03590640798211098,
      "learning_rate": 6.233467019370254e-06,
      "loss": 0.0017,
      "step": 51290
    },
    {
      "epoch": 4.377506613192252,
      "grad_norm": 0.0668986588716507,
      "learning_rate": 6.2249338680774814e-06,
      "loss": 0.0023,
      "step": 51300
    },
    {
      "epoch": 4.3783599283215295,
      "grad_norm": 0.28806787729263306,
      "learning_rate": 6.216400716784709e-06,
      "loss": 0.0019,
      "step": 51310
    },
    {
      "epoch": 4.379213243450806,
      "grad_norm": 0.24958479404449463,
      "learning_rate": 6.207867565491937e-06,
      "loss": 0.0021,
      "step": 51320
    },
    {
      "epoch": 4.380066558580084,
      "grad_norm": 0.29251402616500854,
      "learning_rate": 6.199334414199164e-06,
      "loss": 0.0018,
      "step": 51330
    },
    {
      "epoch": 4.380919873709361,
      "grad_norm": 0.19038686156272888,
      "learning_rate": 6.190801262906391e-06,
      "loss": 0.0016,
      "step": 51340
    },
    {
      "epoch": 4.381773188838638,
      "grad_norm": 0.1179145872592926,
      "learning_rate": 6.182268111613619e-06,
      "loss": 0.002,
      "step": 51350
    },
    {
      "epoch": 4.3826265039679155,
      "grad_norm": 0.07428605109453201,
      "learning_rate": 6.173734960320847e-06,
      "loss": 0.0023,
      "step": 51360
    },
    {
      "epoch": 4.383479819097192,
      "grad_norm": 0.23920151591300964,
      "learning_rate": 6.165201809028075e-06,
      "loss": 0.0015,
      "step": 51370
    },
    {
      "epoch": 4.38433313422647,
      "grad_norm": 0.19573257863521576,
      "learning_rate": 6.156668657735302e-06,
      "loss": 0.0015,
      "step": 51380
    },
    {
      "epoch": 4.385186449355747,
      "grad_norm": 0.08710053563117981,
      "learning_rate": 6.148135506442529e-06,
      "loss": 0.0017,
      "step": 51390
    },
    {
      "epoch": 4.386039764485024,
      "grad_norm": 0.1462564915418625,
      "learning_rate": 6.139602355149758e-06,
      "loss": 0.0016,
      "step": 51400
    },
    {
      "epoch": 4.3868930796143015,
      "grad_norm": 0.22136493027210236,
      "learning_rate": 6.1310692038569846e-06,
      "loss": 0.0019,
      "step": 51410
    },
    {
      "epoch": 4.387746394743579,
      "grad_norm": 0.3966018855571747,
      "learning_rate": 6.122536052564212e-06,
      "loss": 0.0018,
      "step": 51420
    },
    {
      "epoch": 4.388599709872856,
      "grad_norm": 0.2738153636455536,
      "learning_rate": 6.11400290127144e-06,
      "loss": 0.0021,
      "step": 51430
    },
    {
      "epoch": 4.389453025002133,
      "grad_norm": 0.19343791902065277,
      "learning_rate": 6.1054697499786675e-06,
      "loss": 0.0019,
      "step": 51440
    },
    {
      "epoch": 4.390306340131411,
      "grad_norm": 0.13286206126213074,
      "learning_rate": 6.096936598685895e-06,
      "loss": 0.0022,
      "step": 51450
    },
    {
      "epoch": 4.3911596552606875,
      "grad_norm": 0.1921733319759369,
      "learning_rate": 6.088403447393123e-06,
      "loss": 0.0016,
      "step": 51460
    },
    {
      "epoch": 4.392012970389965,
      "grad_norm": 0.06271743774414062,
      "learning_rate": 6.0798702961003495e-06,
      "loss": 0.002,
      "step": 51470
    },
    {
      "epoch": 4.392866285519243,
      "grad_norm": 0.13566188514232635,
      "learning_rate": 6.071337144807578e-06,
      "loss": 0.0018,
      "step": 51480
    },
    {
      "epoch": 4.393719600648519,
      "grad_norm": 0.039864491671323776,
      "learning_rate": 6.062803993514806e-06,
      "loss": 0.0018,
      "step": 51490
    },
    {
      "epoch": 4.394572915777797,
      "grad_norm": 0.40541383624076843,
      "learning_rate": 6.054270842222033e-06,
      "loss": 0.0021,
      "step": 51500
    },
    {
      "epoch": 4.3954262309070735,
      "grad_norm": 0.05405808612704277,
      "learning_rate": 6.04573769092926e-06,
      "loss": 0.0017,
      "step": 51510
    },
    {
      "epoch": 4.396279546036351,
      "grad_norm": 0.33995068073272705,
      "learning_rate": 6.037204539636488e-06,
      "loss": 0.0018,
      "step": 51520
    },
    {
      "epoch": 4.397132861165629,
      "grad_norm": 0.09627792984247208,
      "learning_rate": 6.028671388343716e-06,
      "loss": 0.0016,
      "step": 51530
    },
    {
      "epoch": 4.397986176294905,
      "grad_norm": 0.035572536289691925,
      "learning_rate": 6.020138237050943e-06,
      "loss": 0.0013,
      "step": 51540
    },
    {
      "epoch": 4.398839491424183,
      "grad_norm": 0.1307893693447113,
      "learning_rate": 6.011605085758171e-06,
      "loss": 0.0021,
      "step": 51550
    },
    {
      "epoch": 4.39969280655346,
      "grad_norm": 0.04085661843419075,
      "learning_rate": 6.003071934465398e-06,
      "loss": 0.0014,
      "step": 51560
    },
    {
      "epoch": 4.400546121682737,
      "grad_norm": 0.19730375707149506,
      "learning_rate": 5.994538783172626e-06,
      "loss": 0.0016,
      "step": 51570
    },
    {
      "epoch": 4.401399436812015,
      "grad_norm": 0.05411788821220398,
      "learning_rate": 5.9860056318798535e-06,
      "loss": 0.002,
      "step": 51580
    },
    {
      "epoch": 4.402252751941292,
      "grad_norm": 0.0685541108250618,
      "learning_rate": 5.977472480587081e-06,
      "loss": 0.0024,
      "step": 51590
    },
    {
      "epoch": 4.403106067070569,
      "grad_norm": 0.19526562094688416,
      "learning_rate": 5.968939329294309e-06,
      "loss": 0.002,
      "step": 51600
    },
    {
      "epoch": 4.403959382199846,
      "grad_norm": 0.07313897460699081,
      "learning_rate": 5.960406178001536e-06,
      "loss": 0.0012,
      "step": 51610
    },
    {
      "epoch": 4.404812697329124,
      "grad_norm": 0.23045849800109863,
      "learning_rate": 5.951873026708764e-06,
      "loss": 0.0016,
      "step": 51620
    },
    {
      "epoch": 4.405666012458401,
      "grad_norm": 0.047212354838848114,
      "learning_rate": 5.943339875415992e-06,
      "loss": 0.0016,
      "step": 51630
    },
    {
      "epoch": 4.406519327587678,
      "grad_norm": 0.08073918521404266,
      "learning_rate": 5.9348067241232185e-06,
      "loss": 0.0017,
      "step": 51640
    },
    {
      "epoch": 4.407372642716956,
      "grad_norm": 0.03548833355307579,
      "learning_rate": 5.926273572830446e-06,
      "loss": 0.0015,
      "step": 51650
    },
    {
      "epoch": 4.408225957846232,
      "grad_norm": 0.230608269572258,
      "learning_rate": 5.917740421537675e-06,
      "loss": 0.0017,
      "step": 51660
    },
    {
      "epoch": 4.40907927297551,
      "grad_norm": 0.3381136357784271,
      "learning_rate": 5.909207270244901e-06,
      "loss": 0.0017,
      "step": 51670
    },
    {
      "epoch": 4.4099325881047875,
      "grad_norm": 0.12730753421783447,
      "learning_rate": 5.900674118952129e-06,
      "loss": 0.0015,
      "step": 51680
    },
    {
      "epoch": 4.410785903234064,
      "grad_norm": 0.15457972884178162,
      "learning_rate": 5.892140967659357e-06,
      "loss": 0.0015,
      "step": 51690
    },
    {
      "epoch": 4.411639218363342,
      "grad_norm": 0.1385808140039444,
      "learning_rate": 5.883607816366585e-06,
      "loss": 0.0023,
      "step": 51700
    },
    {
      "epoch": 4.412492533492619,
      "grad_norm": 0.07780635356903076,
      "learning_rate": 5.875074665073812e-06,
      "loss": 0.002,
      "step": 51710
    },
    {
      "epoch": 4.413345848621896,
      "grad_norm": 0.18957768380641937,
      "learning_rate": 5.8665415137810395e-06,
      "loss": 0.002,
      "step": 51720
    },
    {
      "epoch": 4.4141991637511735,
      "grad_norm": 0.13254335522651672,
      "learning_rate": 5.858008362488267e-06,
      "loss": 0.0018,
      "step": 51730
    },
    {
      "epoch": 4.41505247888045,
      "grad_norm": 0.1659252643585205,
      "learning_rate": 5.849475211195495e-06,
      "loss": 0.0022,
      "step": 51740
    },
    {
      "epoch": 4.415905794009728,
      "grad_norm": 0.15366649627685547,
      "learning_rate": 5.8409420599027225e-06,
      "loss": 0.0017,
      "step": 51750
    },
    {
      "epoch": 4.416759109139005,
      "grad_norm": 0.06673121452331543,
      "learning_rate": 5.83240890860995e-06,
      "loss": 0.0017,
      "step": 51760
    },
    {
      "epoch": 4.417612424268282,
      "grad_norm": 0.09891820698976517,
      "learning_rate": 5.823875757317177e-06,
      "loss": 0.002,
      "step": 51770
    },
    {
      "epoch": 4.4184657393975595,
      "grad_norm": 0.10682467371225357,
      "learning_rate": 5.815342606024405e-06,
      "loss": 0.0018,
      "step": 51780
    },
    {
      "epoch": 4.419319054526837,
      "grad_norm": 0.13444805145263672,
      "learning_rate": 5.806809454731633e-06,
      "loss": 0.0016,
      "step": 51790
    },
    {
      "epoch": 4.420172369656114,
      "grad_norm": 0.15284253656864166,
      "learning_rate": 5.798276303438861e-06,
      "loss": 0.0021,
      "step": 51800
    },
    {
      "epoch": 4.421025684785391,
      "grad_norm": 0.23470740020275116,
      "learning_rate": 5.789743152146087e-06,
      "loss": 0.0016,
      "step": 51810
    },
    {
      "epoch": 4.421878999914669,
      "grad_norm": 0.15354709327220917,
      "learning_rate": 5.781210000853315e-06,
      "loss": 0.002,
      "step": 51820
    },
    {
      "epoch": 4.4227323150439455,
      "grad_norm": 0.1439664363861084,
      "learning_rate": 5.7726768495605435e-06,
      "loss": 0.0022,
      "step": 51830
    },
    {
      "epoch": 4.423585630173223,
      "grad_norm": 0.08037567138671875,
      "learning_rate": 5.76414369826777e-06,
      "loss": 0.0018,
      "step": 51840
    },
    {
      "epoch": 4.424438945302501,
      "grad_norm": 0.15515415370464325,
      "learning_rate": 5.755610546974998e-06,
      "loss": 0.002,
      "step": 51850
    },
    {
      "epoch": 4.425292260431777,
      "grad_norm": 0.2747971713542938,
      "learning_rate": 5.747077395682226e-06,
      "loss": 0.0019,
      "step": 51860
    },
    {
      "epoch": 4.426145575561055,
      "grad_norm": 0.2503329813480377,
      "learning_rate": 5.738544244389453e-06,
      "loss": 0.0023,
      "step": 51870
    },
    {
      "epoch": 4.4269988906903315,
      "grad_norm": 0.11876555532217026,
      "learning_rate": 5.730011093096681e-06,
      "loss": 0.0023,
      "step": 51880
    },
    {
      "epoch": 4.427852205819609,
      "grad_norm": 0.17303921282291412,
      "learning_rate": 5.7214779418039085e-06,
      "loss": 0.0017,
      "step": 51890
    },
    {
      "epoch": 4.428705520948887,
      "grad_norm": 0.13752974569797516,
      "learning_rate": 5.712944790511136e-06,
      "loss": 0.0016,
      "step": 51900
    },
    {
      "epoch": 4.429558836078163,
      "grad_norm": 0.10155568271875381,
      "learning_rate": 5.704411639218364e-06,
      "loss": 0.0018,
      "step": 51910
    },
    {
      "epoch": 4.430412151207441,
      "grad_norm": 0.052205175161361694,
      "learning_rate": 5.695878487925591e-06,
      "loss": 0.0018,
      "step": 51920
    },
    {
      "epoch": 4.431265466336718,
      "grad_norm": 0.3797558546066284,
      "learning_rate": 5.687345336632819e-06,
      "loss": 0.0019,
      "step": 51930
    },
    {
      "epoch": 4.432118781465995,
      "grad_norm": 0.09435850381851196,
      "learning_rate": 5.678812185340046e-06,
      "loss": 0.0016,
      "step": 51940
    },
    {
      "epoch": 4.432972096595273,
      "grad_norm": 0.1199217438697815,
      "learning_rate": 5.670279034047274e-06,
      "loss": 0.0018,
      "step": 51950
    },
    {
      "epoch": 4.43382541172455,
      "grad_norm": 0.035722214728593826,
      "learning_rate": 5.661745882754502e-06,
      "loss": 0.0025,
      "step": 51960
    },
    {
      "epoch": 4.434678726853827,
      "grad_norm": 0.21272973716259003,
      "learning_rate": 5.653212731461729e-06,
      "loss": 0.0017,
      "step": 51970
    },
    {
      "epoch": 4.435532041983104,
      "grad_norm": 0.23065173625946045,
      "learning_rate": 5.644679580168956e-06,
      "loss": 0.0015,
      "step": 51980
    },
    {
      "epoch": 4.436385357112382,
      "grad_norm": 0.188578262925148,
      "learning_rate": 5.636146428876184e-06,
      "loss": 0.0018,
      "step": 51990
    },
    {
      "epoch": 4.437238672241659,
      "grad_norm": 0.17126110196113586,
      "learning_rate": 5.6276132775834125e-06,
      "loss": 0.0016,
      "step": 52000
    },
    {
      "epoch": 4.438091987370936,
      "grad_norm": 0.19373169541358948,
      "learning_rate": 5.619080126290639e-06,
      "loss": 0.0019,
      "step": 52010
    },
    {
      "epoch": 4.438945302500214,
      "grad_norm": 0.1358518898487091,
      "learning_rate": 5.610546974997867e-06,
      "loss": 0.0019,
      "step": 52020
    },
    {
      "epoch": 4.43979861762949,
      "grad_norm": 0.05652158334851265,
      "learning_rate": 5.6020138237050945e-06,
      "loss": 0.0019,
      "step": 52030
    },
    {
      "epoch": 4.440651932758768,
      "grad_norm": 0.07392733544111252,
      "learning_rate": 5.593480672412322e-06,
      "loss": 0.0016,
      "step": 52040
    },
    {
      "epoch": 4.4415052478880455,
      "grad_norm": 0.2503897249698639,
      "learning_rate": 5.58494752111955e-06,
      "loss": 0.0015,
      "step": 52050
    },
    {
      "epoch": 4.442358563017322,
      "grad_norm": 0.08957851678133011,
      "learning_rate": 5.5764143698267774e-06,
      "loss": 0.0019,
      "step": 52060
    },
    {
      "epoch": 4.4432118781466,
      "grad_norm": 0.18371790647506714,
      "learning_rate": 5.567881218534004e-06,
      "loss": 0.0016,
      "step": 52070
    },
    {
      "epoch": 4.444065193275877,
      "grad_norm": 0.21893839538097382,
      "learning_rate": 5.559348067241233e-06,
      "loss": 0.0018,
      "step": 52080
    },
    {
      "epoch": 4.444918508405154,
      "grad_norm": 0.16810785233974457,
      "learning_rate": 5.55081491594846e-06,
      "loss": 0.0014,
      "step": 52090
    },
    {
      "epoch": 4.4457718235344315,
      "grad_norm": 0.041442837566137314,
      "learning_rate": 5.542281764655688e-06,
      "loss": 0.0019,
      "step": 52100
    },
    {
      "epoch": 4.446625138663708,
      "grad_norm": 0.11028802394866943,
      "learning_rate": 5.533748613362915e-06,
      "loss": 0.0014,
      "step": 52110
    },
    {
      "epoch": 4.447478453792986,
      "grad_norm": 0.26602157950401306,
      "learning_rate": 5.525215462070142e-06,
      "loss": 0.0016,
      "step": 52120
    },
    {
      "epoch": 4.448331768922263,
      "grad_norm": 0.1413808912038803,
      "learning_rate": 5.516682310777371e-06,
      "loss": 0.0016,
      "step": 52130
    },
    {
      "epoch": 4.44918508405154,
      "grad_norm": 0.09569282829761505,
      "learning_rate": 5.508149159484598e-06,
      "loss": 0.0016,
      "step": 52140
    },
    {
      "epoch": 4.4500383991808174,
      "grad_norm": 0.07696960866451263,
      "learning_rate": 5.499616008191825e-06,
      "loss": 0.0018,
      "step": 52150
    },
    {
      "epoch": 4.450891714310095,
      "grad_norm": 0.06117904558777809,
      "learning_rate": 5.491082856899053e-06,
      "loss": 0.002,
      "step": 52160
    },
    {
      "epoch": 4.451745029439372,
      "grad_norm": 0.3223899304866791,
      "learning_rate": 5.482549705606281e-06,
      "loss": 0.0019,
      "step": 52170
    },
    {
      "epoch": 4.452598344568649,
      "grad_norm": 0.13075807690620422,
      "learning_rate": 5.474016554313508e-06,
      "loss": 0.002,
      "step": 52180
    },
    {
      "epoch": 4.453451659697927,
      "grad_norm": 0.2380242496728897,
      "learning_rate": 5.465483403020736e-06,
      "loss": 0.0017,
      "step": 52190
    },
    {
      "epoch": 4.4543049748272034,
      "grad_norm": 0.08825811743736267,
      "learning_rate": 5.4569502517279635e-06,
      "loss": 0.0017,
      "step": 52200
    },
    {
      "epoch": 4.455158289956481,
      "grad_norm": 0.17356310784816742,
      "learning_rate": 5.448417100435191e-06,
      "loss": 0.0016,
      "step": 52210
    },
    {
      "epoch": 4.4560116050857586,
      "grad_norm": 0.09886441379785538,
      "learning_rate": 5.439883949142419e-06,
      "loss": 0.0018,
      "step": 52220
    },
    {
      "epoch": 4.456864920215035,
      "grad_norm": 0.23474717140197754,
      "learning_rate": 5.431350797849646e-06,
      "loss": 0.0022,
      "step": 52230
    },
    {
      "epoch": 4.457718235344313,
      "grad_norm": 0.1728539615869522,
      "learning_rate": 5.422817646556873e-06,
      "loss": 0.0016,
      "step": 52240
    },
    {
      "epoch": 4.458571550473589,
      "grad_norm": 0.1147802472114563,
      "learning_rate": 5.414284495264102e-06,
      "loss": 0.0014,
      "step": 52250
    },
    {
      "epoch": 4.459424865602867,
      "grad_norm": 0.16923768818378448,
      "learning_rate": 5.405751343971329e-06,
      "loss": 0.0018,
      "step": 52260
    },
    {
      "epoch": 4.4602781807321445,
      "grad_norm": 0.033987902104854584,
      "learning_rate": 5.397218192678556e-06,
      "loss": 0.0022,
      "step": 52270
    },
    {
      "epoch": 4.461131495861421,
      "grad_norm": 0.05911144241690636,
      "learning_rate": 5.388685041385784e-06,
      "loss": 0.0022,
      "step": 52280
    },
    {
      "epoch": 4.461984810990699,
      "grad_norm": 0.3042401075363159,
      "learning_rate": 5.380151890093011e-06,
      "loss": 0.0016,
      "step": 52290
    },
    {
      "epoch": 4.462838126119976,
      "grad_norm": 0.19386506080627441,
      "learning_rate": 5.37161873880024e-06,
      "loss": 0.0012,
      "step": 52300
    },
    {
      "epoch": 4.463691441249253,
      "grad_norm": 0.2354726940393448,
      "learning_rate": 5.363085587507467e-06,
      "loss": 0.002,
      "step": 52310
    },
    {
      "epoch": 4.4645447563785305,
      "grad_norm": 0.2651805579662323,
      "learning_rate": 5.354552436214694e-06,
      "loss": 0.0019,
      "step": 52320
    },
    {
      "epoch": 4.465398071507808,
      "grad_norm": 0.09093816578388214,
      "learning_rate": 5.346019284921922e-06,
      "loss": 0.0013,
      "step": 52330
    },
    {
      "epoch": 4.466251386637085,
      "grad_norm": 0.1652594953775406,
      "learning_rate": 5.3374861336291495e-06,
      "loss": 0.0019,
      "step": 52340
    },
    {
      "epoch": 4.467104701766362,
      "grad_norm": 0.12620221078395844,
      "learning_rate": 5.328952982336377e-06,
      "loss": 0.0015,
      "step": 52350
    },
    {
      "epoch": 4.46795801689564,
      "grad_norm": 0.2947872579097748,
      "learning_rate": 5.320419831043605e-06,
      "loss": 0.0018,
      "step": 52360
    },
    {
      "epoch": 4.4688113320249165,
      "grad_norm": 0.25913503766059875,
      "learning_rate": 5.311886679750832e-06,
      "loss": 0.0016,
      "step": 52370
    },
    {
      "epoch": 4.469664647154194,
      "grad_norm": 0.12179314345121384,
      "learning_rate": 5.30335352845806e-06,
      "loss": 0.0018,
      "step": 52380
    },
    {
      "epoch": 4.470517962283472,
      "grad_norm": 0.3428466320037842,
      "learning_rate": 5.294820377165288e-06,
      "loss": 0.002,
      "step": 52390
    },
    {
      "epoch": 4.471371277412748,
      "grad_norm": 0.11189410090446472,
      "learning_rate": 5.286287225872515e-06,
      "loss": 0.002,
      "step": 52400
    },
    {
      "epoch": 4.472224592542026,
      "grad_norm": 0.3469752371311188,
      "learning_rate": 5.277754074579742e-06,
      "loss": 0.0017,
      "step": 52410
    },
    {
      "epoch": 4.473077907671303,
      "grad_norm": 0.08638711273670197,
      "learning_rate": 5.269220923286971e-06,
      "loss": 0.0016,
      "step": 52420
    },
    {
      "epoch": 4.47393122280058,
      "grad_norm": 0.15308235585689545,
      "learning_rate": 5.260687771994198e-06,
      "loss": 0.0016,
      "step": 52430
    },
    {
      "epoch": 4.474784537929858,
      "grad_norm": 0.30353420972824097,
      "learning_rate": 5.252154620701425e-06,
      "loss": 0.0022,
      "step": 52440
    },
    {
      "epoch": 4.475637853059135,
      "grad_norm": 0.07578118145465851,
      "learning_rate": 5.243621469408653e-06,
      "loss": 0.0019,
      "step": 52450
    },
    {
      "epoch": 4.476491168188412,
      "grad_norm": 0.26783013343811035,
      "learning_rate": 5.23508831811588e-06,
      "loss": 0.0019,
      "step": 52460
    },
    {
      "epoch": 4.477344483317689,
      "grad_norm": 0.134863942861557,
      "learning_rate": 5.226555166823108e-06,
      "loss": 0.002,
      "step": 52470
    },
    {
      "epoch": 4.478197798446966,
      "grad_norm": 0.32727792859077454,
      "learning_rate": 5.2180220155303356e-06,
      "loss": 0.0019,
      "step": 52480
    },
    {
      "epoch": 4.479051113576244,
      "grad_norm": 0.10548319667577744,
      "learning_rate": 5.209488864237563e-06,
      "loss": 0.0017,
      "step": 52490
    },
    {
      "epoch": 4.479904428705521,
      "grad_norm": 0.08837558329105377,
      "learning_rate": 5.200955712944791e-06,
      "loss": 0.0018,
      "step": 52500
    },
    {
      "epoch": 4.480757743834798,
      "grad_norm": 0.2516006827354431,
      "learning_rate": 5.1924225616520185e-06,
      "loss": 0.002,
      "step": 52510
    },
    {
      "epoch": 4.481611058964075,
      "grad_norm": 0.06276274472475052,
      "learning_rate": 5.183889410359246e-06,
      "loss": 0.0016,
      "step": 52520
    },
    {
      "epoch": 4.482464374093353,
      "grad_norm": 0.1948980689048767,
      "learning_rate": 5.175356259066474e-06,
      "loss": 0.0017,
      "step": 52530
    },
    {
      "epoch": 4.48331768922263,
      "grad_norm": 0.12581594288349152,
      "learning_rate": 5.1668231077737005e-06,
      "loss": 0.0017,
      "step": 52540
    },
    {
      "epoch": 4.484171004351907,
      "grad_norm": 0.1039639487862587,
      "learning_rate": 5.158289956480929e-06,
      "loss": 0.0019,
      "step": 52550
    },
    {
      "epoch": 4.485024319481185,
      "grad_norm": 0.08769136667251587,
      "learning_rate": 5.149756805188157e-06,
      "loss": 0.0017,
      "step": 52560
    },
    {
      "epoch": 4.485877634610461,
      "grad_norm": 0.1803325116634369,
      "learning_rate": 5.1412236538953834e-06,
      "loss": 0.0019,
      "step": 52570
    },
    {
      "epoch": 4.486730949739739,
      "grad_norm": 0.09702605754137039,
      "learning_rate": 5.132690502602611e-06,
      "loss": 0.0017,
      "step": 52580
    },
    {
      "epoch": 4.4875842648690165,
      "grad_norm": 0.21640518307685852,
      "learning_rate": 5.124157351309839e-06,
      "loss": 0.0021,
      "step": 52590
    },
    {
      "epoch": 4.488437579998293,
      "grad_norm": 0.11868073046207428,
      "learning_rate": 5.115624200017066e-06,
      "loss": 0.0019,
      "step": 52600
    },
    {
      "epoch": 4.489290895127571,
      "grad_norm": 0.22335220873355865,
      "learning_rate": 5.107091048724294e-06,
      "loss": 0.0017,
      "step": 52610
    },
    {
      "epoch": 4.490144210256847,
      "grad_norm": 0.1769804209470749,
      "learning_rate": 5.098557897431522e-06,
      "loss": 0.0018,
      "step": 52620
    },
    {
      "epoch": 4.490997525386125,
      "grad_norm": 0.1323545277118683,
      "learning_rate": 5.090024746138749e-06,
      "loss": 0.0015,
      "step": 52630
    },
    {
      "epoch": 4.4918508405154025,
      "grad_norm": 0.09073272347450256,
      "learning_rate": 5.081491594845977e-06,
      "loss": 0.002,
      "step": 52640
    },
    {
      "epoch": 4.492704155644679,
      "grad_norm": 0.19726666808128357,
      "learning_rate": 5.0729584435532045e-06,
      "loss": 0.0016,
      "step": 52650
    },
    {
      "epoch": 4.493557470773957,
      "grad_norm": 0.17602381110191345,
      "learning_rate": 5.064425292260432e-06,
      "loss": 0.0015,
      "step": 52660
    },
    {
      "epoch": 4.494410785903234,
      "grad_norm": 0.20986156165599823,
      "learning_rate": 5.055892140967659e-06,
      "loss": 0.0018,
      "step": 52670
    },
    {
      "epoch": 4.495264101032511,
      "grad_norm": 0.41492950916290283,
      "learning_rate": 5.047358989674887e-06,
      "loss": 0.0014,
      "step": 52680
    },
    {
      "epoch": 4.4961174161617885,
      "grad_norm": 0.3031346797943115,
      "learning_rate": 5.038825838382115e-06,
      "loss": 0.0019,
      "step": 52690
    },
    {
      "epoch": 4.496970731291066,
      "grad_norm": 0.06556404381990433,
      "learning_rate": 5.030292687089342e-06,
      "loss": 0.0021,
      "step": 52700
    },
    {
      "epoch": 4.497824046420343,
      "grad_norm": 0.20377112925052643,
      "learning_rate": 5.0217595357965695e-06,
      "loss": 0.0016,
      "step": 52710
    },
    {
      "epoch": 4.49867736154962,
      "grad_norm": 0.34551724791526794,
      "learning_rate": 5.013226384503798e-06,
      "loss": 0.0016,
      "step": 52720
    },
    {
      "epoch": 4.499530676678898,
      "grad_norm": 0.21364142000675201,
      "learning_rate": 5.004693233211026e-06,
      "loss": 0.0017,
      "step": 52730
    },
    {
      "epoch": 4.5003839918081745,
      "grad_norm": 0.15400715172290802,
      "learning_rate": 4.996160081918252e-06,
      "loss": 0.0018,
      "step": 52740
    },
    {
      "epoch": 4.501237306937452,
      "grad_norm": 0.24445179104804993,
      "learning_rate": 4.98762693062548e-06,
      "loss": 0.002,
      "step": 52750
    },
    {
      "epoch": 4.50209062206673,
      "grad_norm": 0.166733518242836,
      "learning_rate": 4.979093779332708e-06,
      "loss": 0.0024,
      "step": 52760
    },
    {
      "epoch": 4.502943937196006,
      "grad_norm": 0.4177272319793701,
      "learning_rate": 4.970560628039935e-06,
      "loss": 0.0018,
      "step": 52770
    },
    {
      "epoch": 4.503797252325284,
      "grad_norm": 0.3248419463634491,
      "learning_rate": 4.962027476747163e-06,
      "loss": 0.0017,
      "step": 52780
    },
    {
      "epoch": 4.504650567454561,
      "grad_norm": 0.21371549367904663,
      "learning_rate": 4.9534943254543906e-06,
      "loss": 0.0017,
      "step": 52790
    },
    {
      "epoch": 4.505503882583838,
      "grad_norm": 0.21134987473487854,
      "learning_rate": 4.944961174161618e-06,
      "loss": 0.0015,
      "step": 52800
    },
    {
      "epoch": 4.506357197713116,
      "grad_norm": 0.162168487906456,
      "learning_rate": 4.936428022868846e-06,
      "loss": 0.0017,
      "step": 52810
    },
    {
      "epoch": 4.507210512842393,
      "grad_norm": 0.2427728772163391,
      "learning_rate": 4.9278948715760735e-06,
      "loss": 0.0017,
      "step": 52820
    },
    {
      "epoch": 4.50806382797167,
      "grad_norm": 0.3058665096759796,
      "learning_rate": 4.919361720283301e-06,
      "loss": 0.0016,
      "step": 52830
    },
    {
      "epoch": 4.508917143100947,
      "grad_norm": 0.053916484117507935,
      "learning_rate": 4.910828568990528e-06,
      "loss": 0.0019,
      "step": 52840
    },
    {
      "epoch": 4.509770458230224,
      "grad_norm": 0.2655782997608185,
      "learning_rate": 4.902295417697756e-06,
      "loss": 0.0022,
      "step": 52850
    },
    {
      "epoch": 4.510623773359502,
      "grad_norm": 0.2299664169549942,
      "learning_rate": 4.893762266404984e-06,
      "loss": 0.0016,
      "step": 52860
    },
    {
      "epoch": 4.511477088488779,
      "grad_norm": 0.06628111004829407,
      "learning_rate": 4.885229115112211e-06,
      "loss": 0.0019,
      "step": 52870
    },
    {
      "epoch": 4.512330403618056,
      "grad_norm": 0.12058425694704056,
      "learning_rate": 4.876695963819438e-06,
      "loss": 0.0015,
      "step": 52880
    },
    {
      "epoch": 4.513183718747333,
      "grad_norm": 0.11291853338479996,
      "learning_rate": 4.868162812526667e-06,
      "loss": 0.0017,
      "step": 52890
    },
    {
      "epoch": 4.514037033876611,
      "grad_norm": 0.22955669462680817,
      "learning_rate": 4.859629661233894e-06,
      "loss": 0.002,
      "step": 52900
    },
    {
      "epoch": 4.514890349005888,
      "grad_norm": 0.24931234121322632,
      "learning_rate": 4.851096509941121e-06,
      "loss": 0.0015,
      "step": 52910
    },
    {
      "epoch": 4.515743664135165,
      "grad_norm": 0.09395579248666763,
      "learning_rate": 4.842563358648349e-06,
      "loss": 0.0018,
      "step": 52920
    },
    {
      "epoch": 4.516596979264443,
      "grad_norm": 0.29206717014312744,
      "learning_rate": 4.834030207355577e-06,
      "loss": 0.0022,
      "step": 52930
    },
    {
      "epoch": 4.517450294393719,
      "grad_norm": 0.17671893537044525,
      "learning_rate": 4.825497056062804e-06,
      "loss": 0.0015,
      "step": 52940
    },
    {
      "epoch": 4.518303609522997,
      "grad_norm": 0.13729165494441986,
      "learning_rate": 4.816963904770032e-06,
      "loss": 0.0018,
      "step": 52950
    },
    {
      "epoch": 4.519156924652274,
      "grad_norm": 0.06479436159133911,
      "learning_rate": 4.8084307534772595e-06,
      "loss": 0.0021,
      "step": 52960
    },
    {
      "epoch": 4.520010239781551,
      "grad_norm": 0.043813854455947876,
      "learning_rate": 4.799897602184487e-06,
      "loss": 0.0017,
      "step": 52970
    },
    {
      "epoch": 4.520863554910829,
      "grad_norm": 0.08776980638504028,
      "learning_rate": 4.791364450891715e-06,
      "loss": 0.0018,
      "step": 52980
    },
    {
      "epoch": 4.521716870040105,
      "grad_norm": 0.17080046236515045,
      "learning_rate": 4.782831299598942e-06,
      "loss": 0.0014,
      "step": 52990
    },
    {
      "epoch": 4.522570185169383,
      "grad_norm": 0.1905093640089035,
      "learning_rate": 4.774298148306169e-06,
      "loss": 0.0016,
      "step": 53000
    },
    {
      "epoch": 4.5234235002986605,
      "grad_norm": 0.04529198259115219,
      "learning_rate": 4.765764997013397e-06,
      "loss": 0.002,
      "step": 53010
    },
    {
      "epoch": 4.524276815427937,
      "grad_norm": 0.1754889339208603,
      "learning_rate": 4.757231845720625e-06,
      "loss": 0.0017,
      "step": 53020
    },
    {
      "epoch": 4.525130130557215,
      "grad_norm": 0.2991953492164612,
      "learning_rate": 4.748698694427853e-06,
      "loss": 0.0019,
      "step": 53030
    },
    {
      "epoch": 4.525983445686492,
      "grad_norm": 0.19417732954025269,
      "learning_rate": 4.74016554313508e-06,
      "loss": 0.0015,
      "step": 53040
    },
    {
      "epoch": 4.526836760815769,
      "grad_norm": 0.13922373950481415,
      "learning_rate": 4.731632391842307e-06,
      "loss": 0.0017,
      "step": 53050
    },
    {
      "epoch": 4.5276900759450465,
      "grad_norm": 0.3079110085964203,
      "learning_rate": 4.723099240549536e-06,
      "loss": 0.0015,
      "step": 53060
    },
    {
      "epoch": 4.528543391074324,
      "grad_norm": 0.3638240098953247,
      "learning_rate": 4.714566089256763e-06,
      "loss": 0.002,
      "step": 53070
    },
    {
      "epoch": 4.529396706203601,
      "grad_norm": 0.13224418461322784,
      "learning_rate": 4.70603293796399e-06,
      "loss": 0.0018,
      "step": 53080
    },
    {
      "epoch": 4.530250021332878,
      "grad_norm": 0.0797685906291008,
      "learning_rate": 4.697499786671218e-06,
      "loss": 0.0016,
      "step": 53090
    },
    {
      "epoch": 4.531103336462156,
      "grad_norm": 0.29323136806488037,
      "learning_rate": 4.6889666353784455e-06,
      "loss": 0.0015,
      "step": 53100
    },
    {
      "epoch": 4.5319566515914325,
      "grad_norm": 0.11144115030765533,
      "learning_rate": 4.680433484085673e-06,
      "loss": 0.0019,
      "step": 53110
    },
    {
      "epoch": 4.53280996672071,
      "grad_norm": 0.23626212775707245,
      "learning_rate": 4.671900332792901e-06,
      "loss": 0.0022,
      "step": 53120
    },
    {
      "epoch": 4.533663281849988,
      "grad_norm": 0.33643174171447754,
      "learning_rate": 4.6633671815001284e-06,
      "loss": 0.0019,
      "step": 53130
    },
    {
      "epoch": 4.534516596979264,
      "grad_norm": 0.14309260249137878,
      "learning_rate": 4.654834030207355e-06,
      "loss": 0.0019,
      "step": 53140
    },
    {
      "epoch": 4.535369912108542,
      "grad_norm": 0.09776921570301056,
      "learning_rate": 4.646300878914584e-06,
      "loss": 0.0014,
      "step": 53150
    },
    {
      "epoch": 4.536223227237819,
      "grad_norm": 0.0708862692117691,
      "learning_rate": 4.637767727621811e-06,
      "loss": 0.0026,
      "step": 53160
    },
    {
      "epoch": 4.537076542367096,
      "grad_norm": 0.0501004122197628,
      "learning_rate": 4.629234576329038e-06,
      "loss": 0.0015,
      "step": 53170
    },
    {
      "epoch": 4.537929857496374,
      "grad_norm": 0.30768755078315735,
      "learning_rate": 4.620701425036266e-06,
      "loss": 0.0019,
      "step": 53180
    },
    {
      "epoch": 4.538783172625651,
      "grad_norm": 0.11510875076055527,
      "learning_rate": 4.612168273743494e-06,
      "loss": 0.0017,
      "step": 53190
    },
    {
      "epoch": 4.539636487754928,
      "grad_norm": 0.3227817416191101,
      "learning_rate": 4.603635122450721e-06,
      "loss": 0.0018,
      "step": 53200
    },
    {
      "epoch": 4.540489802884205,
      "grad_norm": 0.21517407894134521,
      "learning_rate": 4.595101971157949e-06,
      "loss": 0.0017,
      "step": 53210
    },
    {
      "epoch": 4.541343118013482,
      "grad_norm": 0.30010849237442017,
      "learning_rate": 4.586568819865176e-06,
      "loss": 0.0014,
      "step": 53220
    },
    {
      "epoch": 4.54219643314276,
      "grad_norm": 0.37789833545684814,
      "learning_rate": 4.578035668572404e-06,
      "loss": 0.0016,
      "step": 53230
    },
    {
      "epoch": 4.543049748272037,
      "grad_norm": 0.04074721410870552,
      "learning_rate": 4.569502517279632e-06,
      "loss": 0.0013,
      "step": 53240
    },
    {
      "epoch": 4.543903063401314,
      "grad_norm": 0.15383072197437286,
      "learning_rate": 4.560969365986859e-06,
      "loss": 0.0017,
      "step": 53250
    },
    {
      "epoch": 4.544756378530591,
      "grad_norm": 0.038771841675043106,
      "learning_rate": 4.552436214694087e-06,
      "loss": 0.0017,
      "step": 53260
    },
    {
      "epoch": 4.545609693659869,
      "grad_norm": 0.10087202489376068,
      "learning_rate": 4.5439030634013145e-06,
      "loss": 0.0021,
      "step": 53270
    },
    {
      "epoch": 4.5464630087891456,
      "grad_norm": 0.2015298455953598,
      "learning_rate": 4.535369912108542e-06,
      "loss": 0.0014,
      "step": 53280
    },
    {
      "epoch": 4.547316323918423,
      "grad_norm": 0.07102074474096298,
      "learning_rate": 4.52683676081577e-06,
      "loss": 0.0024,
      "step": 53290
    },
    {
      "epoch": 4.548169639047701,
      "grad_norm": 0.09145423024892807,
      "learning_rate": 4.5183036095229965e-06,
      "loss": 0.0016,
      "step": 53300
    },
    {
      "epoch": 4.549022954176977,
      "grad_norm": 0.16897445917129517,
      "learning_rate": 4.509770458230224e-06,
      "loss": 0.0018,
      "step": 53310
    },
    {
      "epoch": 4.549876269306255,
      "grad_norm": 0.16967631876468658,
      "learning_rate": 4.501237306937453e-06,
      "loss": 0.0021,
      "step": 53320
    },
    {
      "epoch": 4.5507295844355315,
      "grad_norm": 0.09759379923343658,
      "learning_rate": 4.49270415564468e-06,
      "loss": 0.0017,
      "step": 53330
    },
    {
      "epoch": 4.551582899564809,
      "grad_norm": 0.2797267436981201,
      "learning_rate": 4.484171004351907e-06,
      "loss": 0.0022,
      "step": 53340
    },
    {
      "epoch": 4.552436214694087,
      "grad_norm": 0.04091905802488327,
      "learning_rate": 4.475637853059135e-06,
      "loss": 0.0017,
      "step": 53350
    },
    {
      "epoch": 4.553289529823363,
      "grad_norm": 0.08936476707458496,
      "learning_rate": 4.467104701766363e-06,
      "loss": 0.0019,
      "step": 53360
    },
    {
      "epoch": 4.554142844952641,
      "grad_norm": 0.21615661680698395,
      "learning_rate": 4.45857155047359e-06,
      "loss": 0.0017,
      "step": 53370
    },
    {
      "epoch": 4.554996160081918,
      "grad_norm": 0.14224621653556824,
      "learning_rate": 4.450038399180818e-06,
      "loss": 0.0017,
      "step": 53380
    },
    {
      "epoch": 4.555849475211195,
      "grad_norm": 0.08308297395706177,
      "learning_rate": 4.441505247888045e-06,
      "loss": 0.0021,
      "step": 53390
    },
    {
      "epoch": 4.556702790340473,
      "grad_norm": 0.10476028174161911,
      "learning_rate": 4.432972096595273e-06,
      "loss": 0.0016,
      "step": 53400
    },
    {
      "epoch": 4.55755610546975,
      "grad_norm": 0.08470543473958969,
      "learning_rate": 4.4244389453025005e-06,
      "loss": 0.0019,
      "step": 53410
    },
    {
      "epoch": 4.558409420599027,
      "grad_norm": 0.17047113180160522,
      "learning_rate": 4.415905794009728e-06,
      "loss": 0.0015,
      "step": 53420
    },
    {
      "epoch": 4.559262735728304,
      "grad_norm": 0.20416420698165894,
      "learning_rate": 4.407372642716955e-06,
      "loss": 0.0018,
      "step": 53430
    },
    {
      "epoch": 4.560116050857582,
      "grad_norm": 0.4547768831253052,
      "learning_rate": 4.3988394914241834e-06,
      "loss": 0.0016,
      "step": 53440
    },
    {
      "epoch": 4.560969365986859,
      "grad_norm": 0.16030636429786682,
      "learning_rate": 4.390306340131411e-06,
      "loss": 0.002,
      "step": 53450
    },
    {
      "epoch": 4.561822681116136,
      "grad_norm": 0.036930907517671585,
      "learning_rate": 4.381773188838639e-06,
      "loss": 0.0019,
      "step": 53460
    },
    {
      "epoch": 4.562675996245414,
      "grad_norm": 0.21192635595798492,
      "learning_rate": 4.3732400375458655e-06,
      "loss": 0.0018,
      "step": 53470
    },
    {
      "epoch": 4.56352931137469,
      "grad_norm": 0.23797491192817688,
      "learning_rate": 4.364706886253093e-06,
      "loss": 0.0016,
      "step": 53480
    },
    {
      "epoch": 4.564382626503968,
      "grad_norm": 0.05752949416637421,
      "learning_rate": 4.356173734960322e-06,
      "loss": 0.0021,
      "step": 53490
    },
    {
      "epoch": 4.5652359416332455,
      "grad_norm": 0.04559839516878128,
      "learning_rate": 4.347640583667548e-06,
      "loss": 0.0017,
      "step": 53500
    },
    {
      "epoch": 4.566089256762522,
      "grad_norm": 0.08735332638025284,
      "learning_rate": 4.339107432374776e-06,
      "loss": 0.0022,
      "step": 53510
    },
    {
      "epoch": 4.5669425718918,
      "grad_norm": 0.4059506356716156,
      "learning_rate": 4.330574281082004e-06,
      "loss": 0.002,
      "step": 53520
    },
    {
      "epoch": 4.567795887021077,
      "grad_norm": 0.1060715839266777,
      "learning_rate": 4.322041129789231e-06,
      "loss": 0.0021,
      "step": 53530
    },
    {
      "epoch": 4.568649202150354,
      "grad_norm": 0.11642991006374359,
      "learning_rate": 4.313507978496459e-06,
      "loss": 0.0016,
      "step": 53540
    },
    {
      "epoch": 4.5695025172796315,
      "grad_norm": 0.256507009267807,
      "learning_rate": 4.3049748272036866e-06,
      "loss": 0.0021,
      "step": 53550
    },
    {
      "epoch": 4.570355832408909,
      "grad_norm": 0.10258710384368896,
      "learning_rate": 4.296441675910914e-06,
      "loss": 0.0018,
      "step": 53560
    },
    {
      "epoch": 4.571209147538186,
      "grad_norm": 0.1040235161781311,
      "learning_rate": 4.287908524618142e-06,
      "loss": 0.0016,
      "step": 53570
    },
    {
      "epoch": 4.572062462667463,
      "grad_norm": 0.323648065328598,
      "learning_rate": 4.2793753733253695e-06,
      "loss": 0.0014,
      "step": 53580
    },
    {
      "epoch": 4.57291577779674,
      "grad_norm": 0.1766340583562851,
      "learning_rate": 4.270842222032597e-06,
      "loss": 0.0021,
      "step": 53590
    },
    {
      "epoch": 4.5737690929260175,
      "grad_norm": 0.13735409080982208,
      "learning_rate": 4.262309070739824e-06,
      "loss": 0.0016,
      "step": 53600
    },
    {
      "epoch": 4.574622408055295,
      "grad_norm": 0.04170198366045952,
      "learning_rate": 4.2537759194470515e-06,
      "loss": 0.0018,
      "step": 53610
    },
    {
      "epoch": 4.575475723184572,
      "grad_norm": 0.09906895458698273,
      "learning_rate": 4.24524276815428e-06,
      "loss": 0.0019,
      "step": 53620
    },
    {
      "epoch": 4.576329038313849,
      "grad_norm": 0.06490983068943024,
      "learning_rate": 4.236709616861507e-06,
      "loss": 0.0014,
      "step": 53630
    },
    {
      "epoch": 4.577182353443127,
      "grad_norm": 0.31083834171295166,
      "learning_rate": 4.2281764655687344e-06,
      "loss": 0.0018,
      "step": 53640
    },
    {
      "epoch": 4.5780356685724035,
      "grad_norm": 0.22879381477832794,
      "learning_rate": 4.219643314275962e-06,
      "loss": 0.0018,
      "step": 53650
    },
    {
      "epoch": 4.578888983701681,
      "grad_norm": 0.0761675164103508,
      "learning_rate": 4.2111101629831906e-06,
      "loss": 0.0018,
      "step": 53660
    },
    {
      "epoch": 4.579742298830959,
      "grad_norm": 0.12018252164125443,
      "learning_rate": 4.202577011690417e-06,
      "loss": 0.0019,
      "step": 53670
    },
    {
      "epoch": 4.580595613960235,
      "grad_norm": 0.05328943580389023,
      "learning_rate": 4.194043860397645e-06,
      "loss": 0.0014,
      "step": 53680
    },
    {
      "epoch": 4.581448929089513,
      "grad_norm": 0.34741589426994324,
      "learning_rate": 4.185510709104873e-06,
      "loss": 0.002,
      "step": 53690
    },
    {
      "epoch": 4.5823022442187895,
      "grad_norm": 0.14235135912895203,
      "learning_rate": 4.1769775578121e-06,
      "loss": 0.0014,
      "step": 53700
    },
    {
      "epoch": 4.583155559348067,
      "grad_norm": 0.3213454782962799,
      "learning_rate": 4.168444406519328e-06,
      "loss": 0.0015,
      "step": 53710
    },
    {
      "epoch": 4.584008874477345,
      "grad_norm": 0.04037639871239662,
      "learning_rate": 4.1599112552265555e-06,
      "loss": 0.0015,
      "step": 53720
    },
    {
      "epoch": 4.584862189606621,
      "grad_norm": 0.0982382595539093,
      "learning_rate": 4.151378103933782e-06,
      "loss": 0.0019,
      "step": 53730
    },
    {
      "epoch": 4.585715504735899,
      "grad_norm": 0.11724334955215454,
      "learning_rate": 4.142844952641011e-06,
      "loss": 0.0016,
      "step": 53740
    },
    {
      "epoch": 4.586568819865176,
      "grad_norm": 0.28541454672813416,
      "learning_rate": 4.134311801348238e-06,
      "loss": 0.0014,
      "step": 53750
    },
    {
      "epoch": 4.587422134994453,
      "grad_norm": 0.09077976644039154,
      "learning_rate": 4.125778650055466e-06,
      "loss": 0.002,
      "step": 53760
    },
    {
      "epoch": 4.588275450123731,
      "grad_norm": 0.1358311027288437,
      "learning_rate": 4.117245498762693e-06,
      "loss": 0.0019,
      "step": 53770
    },
    {
      "epoch": 4.589128765253008,
      "grad_norm": 0.03973965346813202,
      "learning_rate": 4.1087123474699205e-06,
      "loss": 0.0017,
      "step": 53780
    },
    {
      "epoch": 4.589982080382285,
      "grad_norm": 0.09643881767988205,
      "learning_rate": 4.100179196177149e-06,
      "loss": 0.0019,
      "step": 53790
    },
    {
      "epoch": 4.590835395511562,
      "grad_norm": 0.0663558766245842,
      "learning_rate": 4.091646044884376e-06,
      "loss": 0.0018,
      "step": 53800
    },
    {
      "epoch": 4.59168871064084,
      "grad_norm": 0.05636720359325409,
      "learning_rate": 4.083112893591603e-06,
      "loss": 0.0018,
      "step": 53810
    },
    {
      "epoch": 4.592542025770117,
      "grad_norm": 0.3571866750717163,
      "learning_rate": 4.074579742298831e-06,
      "loss": 0.0019,
      "step": 53820
    },
    {
      "epoch": 4.593395340899394,
      "grad_norm": 0.10882178694009781,
      "learning_rate": 4.066046591006059e-06,
      "loss": 0.0018,
      "step": 53830
    },
    {
      "epoch": 4.594248656028672,
      "grad_norm": 0.06473272293806076,
      "learning_rate": 4.057513439713286e-06,
      "loss": 0.0019,
      "step": 53840
    },
    {
      "epoch": 4.595101971157948,
      "grad_norm": 0.05085638538002968,
      "learning_rate": 4.048980288420514e-06,
      "loss": 0.0015,
      "step": 53850
    },
    {
      "epoch": 4.595955286287226,
      "grad_norm": 0.17198821902275085,
      "learning_rate": 4.0404471371277416e-06,
      "loss": 0.0017,
      "step": 53860
    },
    {
      "epoch": 4.5968086014165035,
      "grad_norm": 0.14128558337688446,
      "learning_rate": 4.031913985834969e-06,
      "loss": 0.0019,
      "step": 53870
    },
    {
      "epoch": 4.59766191654578,
      "grad_norm": 0.23085355758666992,
      "learning_rate": 4.023380834542197e-06,
      "loss": 0.0018,
      "step": 53880
    },
    {
      "epoch": 4.598515231675058,
      "grad_norm": 0.11414354294538498,
      "learning_rate": 4.0148476832494245e-06,
      "loss": 0.0016,
      "step": 53890
    },
    {
      "epoch": 4.599368546804335,
      "grad_norm": 0.04888399690389633,
      "learning_rate": 4.006314531956651e-06,
      "loss": 0.0021,
      "step": 53900
    },
    {
      "epoch": 4.600221861933612,
      "grad_norm": 0.2815512418746948,
      "learning_rate": 3.99778138066388e-06,
      "loss": 0.0016,
      "step": 53910
    },
    {
      "epoch": 4.6010751770628895,
      "grad_norm": 0.10701829940080643,
      "learning_rate": 3.989248229371107e-06,
      "loss": 0.0016,
      "step": 53920
    },
    {
      "epoch": 4.601928492192167,
      "grad_norm": 0.15931719541549683,
      "learning_rate": 3.980715078078334e-06,
      "loss": 0.0018,
      "step": 53930
    },
    {
      "epoch": 4.602781807321444,
      "grad_norm": 0.10317900031805038,
      "learning_rate": 3.972181926785562e-06,
      "loss": 0.0017,
      "step": 53940
    },
    {
      "epoch": 4.603635122450721,
      "grad_norm": 0.1108713299036026,
      "learning_rate": 3.9636487754927894e-06,
      "loss": 0.0021,
      "step": 53950
    },
    {
      "epoch": 4.604488437579998,
      "grad_norm": 0.07525520026683807,
      "learning_rate": 3.955115624200018e-06,
      "loss": 0.0017,
      "step": 53960
    },
    {
      "epoch": 4.6053417527092755,
      "grad_norm": 0.15896600484848022,
      "learning_rate": 3.946582472907245e-06,
      "loss": 0.0017,
      "step": 53970
    },
    {
      "epoch": 4.606195067838553,
      "grad_norm": 0.08443476259708405,
      "learning_rate": 3.938049321614472e-06,
      "loss": 0.0018,
      "step": 53980
    },
    {
      "epoch": 4.60704838296783,
      "grad_norm": 0.06219868361949921,
      "learning_rate": 3.9295161703217e-06,
      "loss": 0.0013,
      "step": 53990
    },
    {
      "epoch": 4.607901698097107,
      "grad_norm": 0.09348943829536438,
      "learning_rate": 3.920983019028928e-06,
      "loss": 0.0016,
      "step": 54000
    },
    {
      "epoch": 4.608755013226385,
      "grad_norm": 0.1602989286184311,
      "learning_rate": 3.912449867736155e-06,
      "loss": 0.0016,
      "step": 54010
    },
    {
      "epoch": 4.6096083283556615,
      "grad_norm": 0.0640883594751358,
      "learning_rate": 3.903916716443383e-06,
      "loss": 0.002,
      "step": 54020
    },
    {
      "epoch": 4.610461643484939,
      "grad_norm": 0.1740165650844574,
      "learning_rate": 3.89538356515061e-06,
      "loss": 0.0018,
      "step": 54030
    },
    {
      "epoch": 4.611314958614217,
      "grad_norm": 0.060164716094732285,
      "learning_rate": 3.886850413857838e-06,
      "loss": 0.0019,
      "step": 54040
    },
    {
      "epoch": 4.612168273743493,
      "grad_norm": 0.20907914638519287,
      "learning_rate": 3.878317262565066e-06,
      "loss": 0.0019,
      "step": 54050
    },
    {
      "epoch": 4.613021588872771,
      "grad_norm": 0.0862022340297699,
      "learning_rate": 3.869784111272293e-06,
      "loss": 0.0016,
      "step": 54060
    },
    {
      "epoch": 4.6138749040020475,
      "grad_norm": 0.1746159940958023,
      "learning_rate": 3.86125095997952e-06,
      "loss": 0.0021,
      "step": 54070
    },
    {
      "epoch": 4.614728219131325,
      "grad_norm": 0.15555383265018463,
      "learning_rate": 3.852717808686748e-06,
      "loss": 0.0018,
      "step": 54080
    },
    {
      "epoch": 4.615581534260603,
      "grad_norm": 0.15762080252170563,
      "learning_rate": 3.844184657393976e-06,
      "loss": 0.0021,
      "step": 54090
    },
    {
      "epoch": 4.616434849389879,
      "grad_norm": 0.08066925406455994,
      "learning_rate": 3.835651506101203e-06,
      "loss": 0.0016,
      "step": 54100
    },
    {
      "epoch": 4.617288164519157,
      "grad_norm": 0.10593598335981369,
      "learning_rate": 3.827118354808431e-06,
      "loss": 0.0015,
      "step": 54110
    },
    {
      "epoch": 4.618141479648434,
      "grad_norm": 0.27288153767585754,
      "learning_rate": 3.818585203515658e-06,
      "loss": 0.0019,
      "step": 54120
    },
    {
      "epoch": 4.618994794777711,
      "grad_norm": 0.28612735867500305,
      "learning_rate": 3.810052052222886e-06,
      "loss": 0.0015,
      "step": 54130
    },
    {
      "epoch": 4.619848109906989,
      "grad_norm": 0.11994774639606476,
      "learning_rate": 3.8015189009301136e-06,
      "loss": 0.0016,
      "step": 54140
    },
    {
      "epoch": 4.620701425036266,
      "grad_norm": 0.14191299676895142,
      "learning_rate": 3.7929857496373413e-06,
      "loss": 0.0015,
      "step": 54150
    },
    {
      "epoch": 4.621554740165543,
      "grad_norm": 0.19022662937641144,
      "learning_rate": 3.7844525983445693e-06,
      "loss": 0.0023,
      "step": 54160
    },
    {
      "epoch": 4.62240805529482,
      "grad_norm": 0.17743998765945435,
      "learning_rate": 3.775919447051796e-06,
      "loss": 0.0015,
      "step": 54170
    },
    {
      "epoch": 4.623261370424098,
      "grad_norm": 0.27620065212249756,
      "learning_rate": 3.767386295759024e-06,
      "loss": 0.002,
      "step": 54180
    },
    {
      "epoch": 4.624114685553375,
      "grad_norm": 0.052032388746738434,
      "learning_rate": 3.758853144466252e-06,
      "loss": 0.0014,
      "step": 54190
    },
    {
      "epoch": 4.624968000682652,
      "grad_norm": 0.46433988213539124,
      "learning_rate": 3.750319993173479e-06,
      "loss": 0.0018,
      "step": 54200
    },
    {
      "epoch": 4.62582131581193,
      "grad_norm": 0.0511399544775486,
      "learning_rate": 3.7417868418807067e-06,
      "loss": 0.0015,
      "step": 54210
    },
    {
      "epoch": 4.626674630941206,
      "grad_norm": 0.08367875963449478,
      "learning_rate": 3.7332536905879343e-06,
      "loss": 0.0016,
      "step": 54220
    },
    {
      "epoch": 4.627527946070484,
      "grad_norm": 0.051292117685079575,
      "learning_rate": 3.7247205392951615e-06,
      "loss": 0.0017,
      "step": 54230
    },
    {
      "epoch": 4.6283812611997615,
      "grad_norm": 0.034645359963178635,
      "learning_rate": 3.7161873880023896e-06,
      "loss": 0.0017,
      "step": 54240
    },
    {
      "epoch": 4.629234576329038,
      "grad_norm": 0.17222261428833008,
      "learning_rate": 3.707654236709617e-06,
      "loss": 0.0016,
      "step": 54250
    },
    {
      "epoch": 4.630087891458316,
      "grad_norm": 0.2116793692111969,
      "learning_rate": 3.699121085416845e-06,
      "loss": 0.0021,
      "step": 54260
    },
    {
      "epoch": 4.630941206587593,
      "grad_norm": 0.20551130175590515,
      "learning_rate": 3.690587934124072e-06,
      "loss": 0.0018,
      "step": 54270
    },
    {
      "epoch": 4.63179452171687,
      "grad_norm": 0.24740976095199585,
      "learning_rate": 3.6820547828312997e-06,
      "loss": 0.0018,
      "step": 54280
    },
    {
      "epoch": 4.6326478368461474,
      "grad_norm": 0.303888738155365,
      "learning_rate": 3.6735216315385277e-06,
      "loss": 0.0016,
      "step": 54290
    },
    {
      "epoch": 4.633501151975425,
      "grad_norm": 0.1194460466504097,
      "learning_rate": 3.6649884802457545e-06,
      "loss": 0.0021,
      "step": 54300
    },
    {
      "epoch": 4.634354467104702,
      "grad_norm": 0.13619829714298248,
      "learning_rate": 3.6564553289529826e-06,
      "loss": 0.0015,
      "step": 54310
    },
    {
      "epoch": 4.635207782233979,
      "grad_norm": 0.16256679594516754,
      "learning_rate": 3.6479221776602102e-06,
      "loss": 0.0019,
      "step": 54320
    },
    {
      "epoch": 4.636061097363256,
      "grad_norm": 0.23006729781627655,
      "learning_rate": 3.6393890263674374e-06,
      "loss": 0.0018,
      "step": 54330
    },
    {
      "epoch": 4.636914412492533,
      "grad_norm": 0.16824078559875488,
      "learning_rate": 3.630855875074665e-06,
      "loss": 0.0019,
      "step": 54340
    },
    {
      "epoch": 4.637767727621811,
      "grad_norm": 0.303885817527771,
      "learning_rate": 3.622322723781893e-06,
      "loss": 0.0014,
      "step": 54350
    },
    {
      "epoch": 4.638621042751088,
      "grad_norm": 0.1755603402853012,
      "learning_rate": 3.61378957248912e-06,
      "loss": 0.0015,
      "step": 54360
    },
    {
      "epoch": 4.639474357880365,
      "grad_norm": 0.15554296970367432,
      "learning_rate": 3.605256421196348e-06,
      "loss": 0.0021,
      "step": 54370
    },
    {
      "epoch": 4.640327673009643,
      "grad_norm": 0.36341893672943115,
      "learning_rate": 3.5967232699035756e-06,
      "loss": 0.0015,
      "step": 54380
    },
    {
      "epoch": 4.641180988138919,
      "grad_norm": 0.23007653653621674,
      "learning_rate": 3.5881901186108032e-06,
      "loss": 0.0017,
      "step": 54390
    },
    {
      "epoch": 4.642034303268197,
      "grad_norm": 0.06979449838399887,
      "learning_rate": 3.5796569673180305e-06,
      "loss": 0.0015,
      "step": 54400
    },
    {
      "epoch": 4.6428876183974745,
      "grad_norm": 0.4141288995742798,
      "learning_rate": 3.5711238160252585e-06,
      "loss": 0.002,
      "step": 54410
    },
    {
      "epoch": 4.643740933526751,
      "grad_norm": 0.07432441413402557,
      "learning_rate": 3.562590664732486e-06,
      "loss": 0.0025,
      "step": 54420
    },
    {
      "epoch": 4.644594248656029,
      "grad_norm": 0.18036796152591705,
      "learning_rate": 3.5540575134397134e-06,
      "loss": 0.0014,
      "step": 54430
    },
    {
      "epoch": 4.645447563785305,
      "grad_norm": 0.22828777134418488,
      "learning_rate": 3.545524362146941e-06,
      "loss": 0.0015,
      "step": 54440
    },
    {
      "epoch": 4.646300878914583,
      "grad_norm": 0.06374002993106842,
      "learning_rate": 3.5369912108541686e-06,
      "loss": 0.0014,
      "step": 54450
    },
    {
      "epoch": 4.6471541940438605,
      "grad_norm": 0.0924949049949646,
      "learning_rate": 3.528458059561396e-06,
      "loss": 0.0018,
      "step": 54460
    },
    {
      "epoch": 4.648007509173137,
      "grad_norm": 0.17088821530342102,
      "learning_rate": 3.5199249082686235e-06,
      "loss": 0.0016,
      "step": 54470
    },
    {
      "epoch": 4.648860824302415,
      "grad_norm": 0.1803114116191864,
      "learning_rate": 3.5113917569758515e-06,
      "loss": 0.0019,
      "step": 54480
    },
    {
      "epoch": 4.649714139431692,
      "grad_norm": 0.21053817868232727,
      "learning_rate": 3.502858605683079e-06,
      "loss": 0.0017,
      "step": 54490
    },
    {
      "epoch": 4.650567454560969,
      "grad_norm": 0.029973099008202553,
      "learning_rate": 3.4943254543903064e-06,
      "loss": 0.0017,
      "step": 54500
    },
    {
      "epoch": 4.6514207696902465,
      "grad_norm": 0.23675446212291718,
      "learning_rate": 3.485792303097534e-06,
      "loss": 0.0019,
      "step": 54510
    },
    {
      "epoch": 4.652274084819524,
      "grad_norm": 0.06605775654315948,
      "learning_rate": 3.477259151804762e-06,
      "loss": 0.0021,
      "step": 54520
    },
    {
      "epoch": 4.653127399948801,
      "grad_norm": 0.12229369580745697,
      "learning_rate": 3.468726000511989e-06,
      "loss": 0.002,
      "step": 54530
    },
    {
      "epoch": 4.653980715078078,
      "grad_norm": 0.1177452802658081,
      "learning_rate": 3.460192849219217e-06,
      "loss": 0.0017,
      "step": 54540
    },
    {
      "epoch": 4.654834030207356,
      "grad_norm": 0.10240467637777328,
      "learning_rate": 3.4516596979264446e-06,
      "loss": 0.0021,
      "step": 54550
    },
    {
      "epoch": 4.6556873453366325,
      "grad_norm": 0.2740238308906555,
      "learning_rate": 3.4431265466336718e-06,
      "loss": 0.0019,
      "step": 54560
    },
    {
      "epoch": 4.65654066046591,
      "grad_norm": 0.07614146173000336,
      "learning_rate": 3.4345933953408994e-06,
      "loss": 0.0018,
      "step": 54570
    },
    {
      "epoch": 4.657393975595188,
      "grad_norm": 0.3441113531589508,
      "learning_rate": 3.426060244048127e-06,
      "loss": 0.0017,
      "step": 54580
    },
    {
      "epoch": 4.658247290724464,
      "grad_norm": 0.19834566116333008,
      "learning_rate": 3.417527092755355e-06,
      "loss": 0.0016,
      "step": 54590
    },
    {
      "epoch": 4.659100605853742,
      "grad_norm": 0.17902638018131256,
      "learning_rate": 3.4089939414625823e-06,
      "loss": 0.0023,
      "step": 54600
    },
    {
      "epoch": 4.659953920983019,
      "grad_norm": 0.12368877232074738,
      "learning_rate": 3.40046079016981e-06,
      "loss": 0.0018,
      "step": 54610
    },
    {
      "epoch": 4.660807236112296,
      "grad_norm": 0.05578519403934479,
      "learning_rate": 3.3919276388770376e-06,
      "loss": 0.0018,
      "step": 54620
    },
    {
      "epoch": 4.661660551241574,
      "grad_norm": 0.13368336856365204,
      "learning_rate": 3.3833944875842648e-06,
      "loss": 0.0019,
      "step": 54630
    },
    {
      "epoch": 4.662513866370851,
      "grad_norm": 0.03642161935567856,
      "learning_rate": 3.3748613362914924e-06,
      "loss": 0.0017,
      "step": 54640
    },
    {
      "epoch": 4.663367181500128,
      "grad_norm": 0.4399140179157257,
      "learning_rate": 3.3663281849987205e-06,
      "loss": 0.0019,
      "step": 54650
    },
    {
      "epoch": 4.664220496629405,
      "grad_norm": 0.11720991134643555,
      "learning_rate": 3.3577950337059473e-06,
      "loss": 0.0017,
      "step": 54660
    },
    {
      "epoch": 4.665073811758683,
      "grad_norm": 0.09900186955928802,
      "learning_rate": 3.3492618824131753e-06,
      "loss": 0.0017,
      "step": 54670
    },
    {
      "epoch": 4.66592712688796,
      "grad_norm": 0.09706622362136841,
      "learning_rate": 3.340728731120403e-06,
      "loss": 0.0017,
      "step": 54680
    },
    {
      "epoch": 4.666780442017237,
      "grad_norm": 0.06687503308057785,
      "learning_rate": 3.332195579827631e-06,
      "loss": 0.0018,
      "step": 54690
    },
    {
      "epoch": 4.667633757146514,
      "grad_norm": 0.09777869284152985,
      "learning_rate": 3.323662428534858e-06,
      "loss": 0.0015,
      "step": 54700
    },
    {
      "epoch": 4.668487072275791,
      "grad_norm": 0.2728199064731598,
      "learning_rate": 3.315129277242086e-06,
      "loss": 0.0014,
      "step": 54710
    },
    {
      "epoch": 4.669340387405069,
      "grad_norm": 0.06525822728872299,
      "learning_rate": 3.3065961259493135e-06,
      "loss": 0.0016,
      "step": 54720
    },
    {
      "epoch": 4.670193702534346,
      "grad_norm": 0.053598739206790924,
      "learning_rate": 3.2980629746565407e-06,
      "loss": 0.0017,
      "step": 54730
    },
    {
      "epoch": 4.671047017663623,
      "grad_norm": 0.05341970920562744,
      "learning_rate": 3.2895298233637683e-06,
      "loss": 0.0018,
      "step": 54740
    },
    {
      "epoch": 4.671900332792901,
      "grad_norm": 0.05848843604326248,
      "learning_rate": 3.280996672070996e-06,
      "loss": 0.0012,
      "step": 54750
    },
    {
      "epoch": 4.672753647922177,
      "grad_norm": 0.42337995767593384,
      "learning_rate": 3.272463520778223e-06,
      "loss": 0.0018,
      "step": 54760
    },
    {
      "epoch": 4.673606963051455,
      "grad_norm": 0.11744067817926407,
      "learning_rate": 3.263930369485451e-06,
      "loss": 0.0014,
      "step": 54770
    },
    {
      "epoch": 4.6744602781807325,
      "grad_norm": 0.30850327014923096,
      "learning_rate": 3.255397218192679e-06,
      "loss": 0.0017,
      "step": 54780
    },
    {
      "epoch": 4.675313593310009,
      "grad_norm": 0.06903619319200516,
      "learning_rate": 3.2468640668999065e-06,
      "loss": 0.0016,
      "step": 54790
    },
    {
      "epoch": 4.676166908439287,
      "grad_norm": 0.21882496774196625,
      "learning_rate": 3.2383309156071337e-06,
      "loss": 0.0016,
      "step": 54800
    },
    {
      "epoch": 4.677020223568563,
      "grad_norm": 0.029093895107507706,
      "learning_rate": 3.2297977643143614e-06,
      "loss": 0.0015,
      "step": 54810
    },
    {
      "epoch": 4.677873538697841,
      "grad_norm": 0.0557594820857048,
      "learning_rate": 3.2212646130215894e-06,
      "loss": 0.0018,
      "step": 54820
    },
    {
      "epoch": 4.6787268538271185,
      "grad_norm": 0.03310629352927208,
      "learning_rate": 3.2127314617288162e-06,
      "loss": 0.0021,
      "step": 54830
    },
    {
      "epoch": 4.679580168956395,
      "grad_norm": 0.09112536162137985,
      "learning_rate": 3.2041983104360443e-06,
      "loss": 0.0017,
      "step": 54840
    },
    {
      "epoch": 4.680433484085673,
      "grad_norm": 0.28311389684677124,
      "learning_rate": 3.195665159143272e-06,
      "loss": 0.0017,
      "step": 54850
    },
    {
      "epoch": 4.68128679921495,
      "grad_norm": 0.04510867968201637,
      "learning_rate": 3.187132007850499e-06,
      "loss": 0.0018,
      "step": 54860
    },
    {
      "epoch": 4.682140114344227,
      "grad_norm": 0.16659390926361084,
      "learning_rate": 3.1785988565577268e-06,
      "loss": 0.0017,
      "step": 54870
    },
    {
      "epoch": 4.6829934294735045,
      "grad_norm": 0.0810684859752655,
      "learning_rate": 3.170065705264955e-06,
      "loss": 0.0017,
      "step": 54880
    },
    {
      "epoch": 4.683846744602782,
      "grad_norm": 0.12680773437023163,
      "learning_rate": 3.1615325539721824e-06,
      "loss": 0.0019,
      "step": 54890
    },
    {
      "epoch": 4.684700059732059,
      "grad_norm": 0.12078408896923065,
      "learning_rate": 3.1529994026794097e-06,
      "loss": 0.0018,
      "step": 54900
    },
    {
      "epoch": 4.685553374861336,
      "grad_norm": 0.38576969504356384,
      "learning_rate": 3.1444662513866373e-06,
      "loss": 0.0017,
      "step": 54910
    },
    {
      "epoch": 4.686406689990614,
      "grad_norm": 0.12379197776317596,
      "learning_rate": 3.135933100093865e-06,
      "loss": 0.0014,
      "step": 54920
    },
    {
      "epoch": 4.6872600051198905,
      "grad_norm": 0.12051420658826828,
      "learning_rate": 3.127399948801092e-06,
      "loss": 0.002,
      "step": 54930
    },
    {
      "epoch": 4.688113320249168,
      "grad_norm": 0.05646170303225517,
      "learning_rate": 3.1188667975083198e-06,
      "loss": 0.0017,
      "step": 54940
    },
    {
      "epoch": 4.688966635378446,
      "grad_norm": 0.26934579014778137,
      "learning_rate": 3.1103336462155474e-06,
      "loss": 0.0017,
      "step": 54950
    },
    {
      "epoch": 4.689819950507722,
      "grad_norm": 0.08197114616632462,
      "learning_rate": 3.101800494922775e-06,
      "loss": 0.0014,
      "step": 54960
    },
    {
      "epoch": 4.690673265637,
      "grad_norm": 0.13808907568454742,
      "learning_rate": 3.0932673436300027e-06,
      "loss": 0.0016,
      "step": 54970
    },
    {
      "epoch": 4.691526580766277,
      "grad_norm": 0.18716992437839508,
      "learning_rate": 3.0847341923372303e-06,
      "loss": 0.0018,
      "step": 54980
    },
    {
      "epoch": 4.692379895895554,
      "grad_norm": 0.07630898058414459,
      "learning_rate": 3.076201041044458e-06,
      "loss": 0.0014,
      "step": 54990
    },
    {
      "epoch": 4.693233211024832,
      "grad_norm": 0.20934928953647614,
      "learning_rate": 3.067667889751685e-06,
      "loss": 0.0018,
      "step": 55000
    },
    {
      "epoch": 4.694086526154109,
      "grad_norm": 0.2099187970161438,
      "learning_rate": 3.0591347384589132e-06,
      "loss": 0.0017,
      "step": 55010
    },
    {
      "epoch": 4.694939841283386,
      "grad_norm": 0.08044031262397766,
      "learning_rate": 3.0506015871661404e-06,
      "loss": 0.0015,
      "step": 55020
    },
    {
      "epoch": 4.695793156412663,
      "grad_norm": 0.12318499386310577,
      "learning_rate": 3.0420684358733685e-06,
      "loss": 0.0017,
      "step": 55030
    },
    {
      "epoch": 4.696646471541941,
      "grad_norm": 0.19785940647125244,
      "learning_rate": 3.0335352845805957e-06,
      "loss": 0.0014,
      "step": 55040
    },
    {
      "epoch": 4.697499786671218,
      "grad_norm": 0.17294767498970032,
      "learning_rate": 3.0250021332878233e-06,
      "loss": 0.0014,
      "step": 55050
    },
    {
      "epoch": 4.698353101800495,
      "grad_norm": 0.13551907241344452,
      "learning_rate": 3.016468981995051e-06,
      "loss": 0.0016,
      "step": 55060
    },
    {
      "epoch": 4.699206416929772,
      "grad_norm": 0.2448655068874359,
      "learning_rate": 3.0079358307022786e-06,
      "loss": 0.0021,
      "step": 55070
    },
    {
      "epoch": 4.700059732059049,
      "grad_norm": 0.3167441189289093,
      "learning_rate": 2.9994026794095062e-06,
      "loss": 0.0018,
      "step": 55080
    },
    {
      "epoch": 4.700913047188327,
      "grad_norm": 0.10169501602649689,
      "learning_rate": 2.9908695281167335e-06,
      "loss": 0.0015,
      "step": 55090
    },
    {
      "epoch": 4.701766362317604,
      "grad_norm": 0.07986638695001602,
      "learning_rate": 2.982336376823961e-06,
      "loss": 0.0018,
      "step": 55100
    },
    {
      "epoch": 4.702619677446881,
      "grad_norm": 0.29884737730026245,
      "learning_rate": 2.9738032255311887e-06,
      "loss": 0.0016,
      "step": 55110
    },
    {
      "epoch": 4.703472992576159,
      "grad_norm": 0.04029316082596779,
      "learning_rate": 2.9652700742384164e-06,
      "loss": 0.0015,
      "step": 55120
    },
    {
      "epoch": 4.704326307705435,
      "grad_norm": 0.38480108976364136,
      "learning_rate": 2.956736922945644e-06,
      "loss": 0.0017,
      "step": 55130
    },
    {
      "epoch": 4.705179622834713,
      "grad_norm": 0.12168052792549133,
      "learning_rate": 2.9482037716528716e-06,
      "loss": 0.0015,
      "step": 55140
    },
    {
      "epoch": 4.7060329379639905,
      "grad_norm": 0.18133904039859772,
      "learning_rate": 2.939670620360099e-06,
      "loss": 0.0018,
      "step": 55150
    },
    {
      "epoch": 4.706886253093267,
      "grad_norm": 0.06664983928203583,
      "learning_rate": 2.931137469067327e-06,
      "loss": 0.0016,
      "step": 55160
    },
    {
      "epoch": 4.707739568222545,
      "grad_norm": 0.11013314872980118,
      "learning_rate": 2.922604317774554e-06,
      "loss": 0.0017,
      "step": 55170
    },
    {
      "epoch": 4.708592883351821,
      "grad_norm": 0.05409528315067291,
      "learning_rate": 2.914071166481782e-06,
      "loss": 0.0018,
      "step": 55180
    },
    {
      "epoch": 4.709446198481099,
      "grad_norm": 0.3158668875694275,
      "learning_rate": 2.9055380151890094e-06,
      "loss": 0.0013,
      "step": 55190
    },
    {
      "epoch": 4.7102995136103765,
      "grad_norm": 0.19437555968761444,
      "learning_rate": 2.897004863896237e-06,
      "loss": 0.0015,
      "step": 55200
    },
    {
      "epoch": 4.711152828739653,
      "grad_norm": 0.10020609200000763,
      "learning_rate": 2.8884717126034646e-06,
      "loss": 0.0018,
      "step": 55210
    },
    {
      "epoch": 4.712006143868931,
      "grad_norm": 0.29819366335868835,
      "learning_rate": 2.8799385613106923e-06,
      "loss": 0.0019,
      "step": 55220
    },
    {
      "epoch": 4.712859458998208,
      "grad_norm": 0.04290437698364258,
      "learning_rate": 2.87140541001792e-06,
      "loss": 0.002,
      "step": 55230
    },
    {
      "epoch": 4.713712774127485,
      "grad_norm": 0.1046566590666771,
      "learning_rate": 2.862872258725147e-06,
      "loss": 0.0022,
      "step": 55240
    },
    {
      "epoch": 4.7145660892567625,
      "grad_norm": 0.12014391273260117,
      "learning_rate": 2.8543391074323748e-06,
      "loss": 0.002,
      "step": 55250
    },
    {
      "epoch": 4.71541940438604,
      "grad_norm": 0.04311315342783928,
      "learning_rate": 2.8458059561396024e-06,
      "loss": 0.0015,
      "step": 55260
    },
    {
      "epoch": 4.716272719515317,
      "grad_norm": 0.05205395817756653,
      "learning_rate": 2.83727280484683e-06,
      "loss": 0.0017,
      "step": 55270
    },
    {
      "epoch": 4.717126034644594,
      "grad_norm": 0.055090393871068954,
      "learning_rate": 2.8287396535540577e-06,
      "loss": 0.0015,
      "step": 55280
    },
    {
      "epoch": 4.717979349773872,
      "grad_norm": 0.41377633810043335,
      "learning_rate": 2.8202065022612853e-06,
      "loss": 0.0015,
      "step": 55290
    },
    {
      "epoch": 4.7188326649031485,
      "grad_norm": 0.05966690927743912,
      "learning_rate": 2.8116733509685125e-06,
      "loss": 0.0018,
      "step": 55300
    },
    {
      "epoch": 4.719685980032426,
      "grad_norm": 0.05347944423556328,
      "learning_rate": 2.8031401996757406e-06,
      "loss": 0.0016,
      "step": 55310
    },
    {
      "epoch": 4.720539295161704,
      "grad_norm": 0.21236799657344818,
      "learning_rate": 2.7946070483829678e-06,
      "loss": 0.002,
      "step": 55320
    },
    {
      "epoch": 4.72139261029098,
      "grad_norm": 0.24819965660572052,
      "learning_rate": 2.786073897090196e-06,
      "loss": 0.0013,
      "step": 55330
    },
    {
      "epoch": 4.722245925420258,
      "grad_norm": 0.08465518802404404,
      "learning_rate": 2.777540745797423e-06,
      "loss": 0.002,
      "step": 55340
    },
    {
      "epoch": 4.723099240549535,
      "grad_norm": 0.32226303219795227,
      "learning_rate": 2.7690075945046507e-06,
      "loss": 0.0018,
      "step": 55350
    },
    {
      "epoch": 4.723952555678812,
      "grad_norm": 0.13752131164073944,
      "learning_rate": 2.7604744432118783e-06,
      "loss": 0.0017,
      "step": 55360
    },
    {
      "epoch": 4.72480587080809,
      "grad_norm": 0.1414802223443985,
      "learning_rate": 2.751941291919106e-06,
      "loss": 0.0015,
      "step": 55370
    },
    {
      "epoch": 4.725659185937367,
      "grad_norm": 0.061221975833177567,
      "learning_rate": 2.7434081406263336e-06,
      "loss": 0.0016,
      "step": 55380
    },
    {
      "epoch": 4.726512501066644,
      "grad_norm": 0.3423200249671936,
      "learning_rate": 2.7348749893335612e-06,
      "loss": 0.0014,
      "step": 55390
    },
    {
      "epoch": 4.727365816195921,
      "grad_norm": 0.15539535880088806,
      "learning_rate": 2.7263418380407884e-06,
      "loss": 0.0015,
      "step": 55400
    },
    {
      "epoch": 4.728219131325199,
      "grad_norm": 0.18511700630187988,
      "learning_rate": 2.717808686748016e-06,
      "loss": 0.0013,
      "step": 55410
    },
    {
      "epoch": 4.7290724464544756,
      "grad_norm": 0.1787666231393814,
      "learning_rate": 2.7092755354552437e-06,
      "loss": 0.0019,
      "step": 55420
    },
    {
      "epoch": 4.729925761583753,
      "grad_norm": 0.2823520004749298,
      "learning_rate": 2.7007423841624713e-06,
      "loss": 0.0019,
      "step": 55430
    },
    {
      "epoch": 4.73077907671303,
      "grad_norm": 0.12514562904834747,
      "learning_rate": 2.692209232869699e-06,
      "loss": 0.0021,
      "step": 55440
    },
    {
      "epoch": 4.731632391842307,
      "grad_norm": 0.21013514697551727,
      "learning_rate": 2.683676081576926e-06,
      "loss": 0.0017,
      "step": 55450
    },
    {
      "epoch": 4.732485706971585,
      "grad_norm": 0.08566325157880783,
      "learning_rate": 2.6751429302841542e-06,
      "loss": 0.0021,
      "step": 55460
    },
    {
      "epoch": 4.7333390221008615,
      "grad_norm": 0.24181565642356873,
      "learning_rate": 2.6666097789913815e-06,
      "loss": 0.0019,
      "step": 55470
    },
    {
      "epoch": 4.734192337230139,
      "grad_norm": 0.2023056149482727,
      "learning_rate": 2.6580766276986095e-06,
      "loss": 0.0018,
      "step": 55480
    },
    {
      "epoch": 4.735045652359417,
      "grad_norm": 0.23441359400749207,
      "learning_rate": 2.6495434764058367e-06,
      "loss": 0.0016,
      "step": 55490
    },
    {
      "epoch": 4.735898967488693,
      "grad_norm": 0.1394137740135193,
      "learning_rate": 2.6410103251130644e-06,
      "loss": 0.0021,
      "step": 55500
    },
    {
      "epoch": 4.736752282617971,
      "grad_norm": 0.17935170233249664,
      "learning_rate": 2.632477173820292e-06,
      "loss": 0.0023,
      "step": 55510
    },
    {
      "epoch": 4.737605597747248,
      "grad_norm": 0.037779126316308975,
      "learning_rate": 2.6239440225275196e-06,
      "loss": 0.0016,
      "step": 55520
    },
    {
      "epoch": 4.738458912876525,
      "grad_norm": 0.4815036356449127,
      "learning_rate": 2.6154108712347473e-06,
      "loss": 0.0021,
      "step": 55530
    },
    {
      "epoch": 4.739312228005803,
      "grad_norm": 0.28021958470344543,
      "learning_rate": 2.606877719941975e-06,
      "loss": 0.0018,
      "step": 55540
    },
    {
      "epoch": 4.740165543135079,
      "grad_norm": 0.13790777325630188,
      "learning_rate": 2.598344568649202e-06,
      "loss": 0.0015,
      "step": 55550
    },
    {
      "epoch": 4.741018858264357,
      "grad_norm": 0.2122921347618103,
      "learning_rate": 2.5898114173564297e-06,
      "loss": 0.0017,
      "step": 55560
    },
    {
      "epoch": 4.741872173393634,
      "grad_norm": 0.13513332605361938,
      "learning_rate": 2.5812782660636574e-06,
      "loss": 0.0016,
      "step": 55570
    },
    {
      "epoch": 4.742725488522911,
      "grad_norm": 0.21723073720932007,
      "learning_rate": 2.572745114770885e-06,
      "loss": 0.0022,
      "step": 55580
    },
    {
      "epoch": 4.743578803652189,
      "grad_norm": 0.12921865284442902,
      "learning_rate": 2.5642119634781127e-06,
      "loss": 0.0019,
      "step": 55590
    },
    {
      "epoch": 4.744432118781466,
      "grad_norm": 0.236455038189888,
      "learning_rate": 2.55567881218534e-06,
      "loss": 0.0018,
      "step": 55600
    },
    {
      "epoch": 4.745285433910743,
      "grad_norm": 0.07995153963565826,
      "learning_rate": 2.547145660892568e-06,
      "loss": 0.0017,
      "step": 55610
    },
    {
      "epoch": 4.74613874904002,
      "grad_norm": 0.1818523406982422,
      "learning_rate": 2.538612509599795e-06,
      "loss": 0.002,
      "step": 55620
    },
    {
      "epoch": 4.746992064169298,
      "grad_norm": 0.17762164771556854,
      "learning_rate": 2.530079358307023e-06,
      "loss": 0.0021,
      "step": 55630
    },
    {
      "epoch": 4.747845379298575,
      "grad_norm": 0.1276823878288269,
      "learning_rate": 2.5215462070142504e-06,
      "loss": 0.0017,
      "step": 55640
    },
    {
      "epoch": 4.748698694427852,
      "grad_norm": 0.36488077044487,
      "learning_rate": 2.513013055721478e-06,
      "loss": 0.0024,
      "step": 55650
    },
    {
      "epoch": 4.74955200955713,
      "grad_norm": 0.3020630180835724,
      "learning_rate": 2.5044799044287057e-06,
      "loss": 0.0016,
      "step": 55660
    },
    {
      "epoch": 4.750405324686406,
      "grad_norm": 0.28448185324668884,
      "learning_rate": 2.4959467531359333e-06,
      "loss": 0.0019,
      "step": 55670
    },
    {
      "epoch": 4.751258639815684,
      "grad_norm": 0.035994309931993484,
      "learning_rate": 2.487413601843161e-06,
      "loss": 0.002,
      "step": 55680
    },
    {
      "epoch": 4.7521119549449615,
      "grad_norm": 0.10662522166967392,
      "learning_rate": 2.4788804505503886e-06,
      "loss": 0.0017,
      "step": 55690
    },
    {
      "epoch": 4.752965270074238,
      "grad_norm": 0.2719126343727112,
      "learning_rate": 2.470347299257616e-06,
      "loss": 0.0017,
      "step": 55700
    },
    {
      "epoch": 4.753818585203516,
      "grad_norm": 0.1935422420501709,
      "learning_rate": 2.4618141479648434e-06,
      "loss": 0.0019,
      "step": 55710
    },
    {
      "epoch": 4.754671900332793,
      "grad_norm": 0.1614406704902649,
      "learning_rate": 2.453280996672071e-06,
      "loss": 0.002,
      "step": 55720
    },
    {
      "epoch": 4.75552521546207,
      "grad_norm": 0.16430318355560303,
      "learning_rate": 2.4447478453792987e-06,
      "loss": 0.0019,
      "step": 55730
    },
    {
      "epoch": 4.7563785305913475,
      "grad_norm": 0.19936954975128174,
      "learning_rate": 2.4362146940865263e-06,
      "loss": 0.0016,
      "step": 55740
    },
    {
      "epoch": 4.757231845720625,
      "grad_norm": 0.12207154929637909,
      "learning_rate": 2.4276815427937535e-06,
      "loss": 0.0019,
      "step": 55750
    },
    {
      "epoch": 4.758085160849902,
      "grad_norm": 0.14847950637340546,
      "learning_rate": 2.4191483915009816e-06,
      "loss": 0.0019,
      "step": 55760
    },
    {
      "epoch": 4.758938475979179,
      "grad_norm": 0.12624716758728027,
      "learning_rate": 2.410615240208209e-06,
      "loss": 0.0017,
      "step": 55770
    },
    {
      "epoch": 4.759791791108457,
      "grad_norm": 0.03727485612034798,
      "learning_rate": 2.4020820889154364e-06,
      "loss": 0.0015,
      "step": 55780
    },
    {
      "epoch": 4.7606451062377335,
      "grad_norm": 0.08477693796157837,
      "learning_rate": 2.393548937622664e-06,
      "loss": 0.0017,
      "step": 55790
    },
    {
      "epoch": 4.761498421367011,
      "grad_norm": 0.09903620183467865,
      "learning_rate": 2.3850157863298917e-06,
      "loss": 0.0013,
      "step": 55800
    },
    {
      "epoch": 4.762351736496288,
      "grad_norm": 0.04111568257212639,
      "learning_rate": 2.3764826350371194e-06,
      "loss": 0.002,
      "step": 55810
    },
    {
      "epoch": 4.763205051625565,
      "grad_norm": 0.10339832305908203,
      "learning_rate": 2.367949483744347e-06,
      "loss": 0.0022,
      "step": 55820
    },
    {
      "epoch": 4.764058366754843,
      "grad_norm": 0.16262710094451904,
      "learning_rate": 2.359416332451574e-06,
      "loss": 0.0019,
      "step": 55830
    },
    {
      "epoch": 4.7649116818841195,
      "grad_norm": 0.11014494299888611,
      "learning_rate": 2.3508831811588023e-06,
      "loss": 0.0016,
      "step": 55840
    },
    {
      "epoch": 4.765764997013397,
      "grad_norm": 0.05115803703665733,
      "learning_rate": 2.3423500298660295e-06,
      "loss": 0.0018,
      "step": 55850
    },
    {
      "epoch": 4.766618312142675,
      "grad_norm": 0.04897652193903923,
      "learning_rate": 2.3338168785732575e-06,
      "loss": 0.0026,
      "step": 55860
    },
    {
      "epoch": 4.767471627271951,
      "grad_norm": 0.15137872099876404,
      "learning_rate": 2.3252837272804847e-06,
      "loss": 0.0016,
      "step": 55870
    },
    {
      "epoch": 4.768324942401229,
      "grad_norm": 0.062473732978105545,
      "learning_rate": 2.3167505759877124e-06,
      "loss": 0.0015,
      "step": 55880
    },
    {
      "epoch": 4.769178257530506,
      "grad_norm": 0.21340489387512207,
      "learning_rate": 2.30821742469494e-06,
      "loss": 0.0013,
      "step": 55890
    },
    {
      "epoch": 4.770031572659783,
      "grad_norm": 0.2520557940006256,
      "learning_rate": 2.2996842734021676e-06,
      "loss": 0.0015,
      "step": 55900
    },
    {
      "epoch": 4.770884887789061,
      "grad_norm": 0.1171095222234726,
      "learning_rate": 2.2911511221093953e-06,
      "loss": 0.002,
      "step": 55910
    },
    {
      "epoch": 4.771738202918337,
      "grad_norm": 0.15342962741851807,
      "learning_rate": 2.2826179708166225e-06,
      "loss": 0.0021,
      "step": 55920
    },
    {
      "epoch": 4.772591518047615,
      "grad_norm": 0.14893315732479095,
      "learning_rate": 2.27408481952385e-06,
      "loss": 0.0016,
      "step": 55930
    },
    {
      "epoch": 4.773444833176892,
      "grad_norm": 0.03670642897486687,
      "learning_rate": 2.2655516682310778e-06,
      "loss": 0.0016,
      "step": 55940
    },
    {
      "epoch": 4.774298148306169,
      "grad_norm": 0.10282344371080399,
      "learning_rate": 2.2570185169383054e-06,
      "loss": 0.0017,
      "step": 55950
    },
    {
      "epoch": 4.775151463435447,
      "grad_norm": 0.1429293304681778,
      "learning_rate": 2.248485365645533e-06,
      "loss": 0.0018,
      "step": 55960
    },
    {
      "epoch": 4.776004778564724,
      "grad_norm": 0.30028122663497925,
      "learning_rate": 2.2399522143527607e-06,
      "loss": 0.0017,
      "step": 55970
    },
    {
      "epoch": 4.776858093694001,
      "grad_norm": 0.034421078860759735,
      "learning_rate": 2.231419063059988e-06,
      "loss": 0.0017,
      "step": 55980
    },
    {
      "epoch": 4.777711408823278,
      "grad_norm": 0.0802752673625946,
      "learning_rate": 2.222885911767216e-06,
      "loss": 0.002,
      "step": 55990
    },
    {
      "epoch": 4.778564723952556,
      "grad_norm": 0.11765988171100616,
      "learning_rate": 2.214352760474443e-06,
      "loss": 0.0015,
      "step": 56000
    },
    {
      "epoch": 4.779418039081833,
      "grad_norm": 0.07481309771537781,
      "learning_rate": 2.205819609181671e-06,
      "loss": 0.0018,
      "step": 56010
    },
    {
      "epoch": 4.78027135421111,
      "grad_norm": 0.134729266166687,
      "learning_rate": 2.1972864578888984e-06,
      "loss": 0.0015,
      "step": 56020
    },
    {
      "epoch": 4.781124669340388,
      "grad_norm": 0.05487591028213501,
      "learning_rate": 2.188753306596126e-06,
      "loss": 0.0016,
      "step": 56030
    },
    {
      "epoch": 4.781977984469664,
      "grad_norm": 0.15661484003067017,
      "learning_rate": 2.1802201553033537e-06,
      "loss": 0.0015,
      "step": 56040
    },
    {
      "epoch": 4.782831299598942,
      "grad_norm": 0.1882462203502655,
      "learning_rate": 2.1716870040105813e-06,
      "loss": 0.0014,
      "step": 56050
    },
    {
      "epoch": 4.7836846147282195,
      "grad_norm": 0.14617928862571716,
      "learning_rate": 2.163153852717809e-06,
      "loss": 0.0015,
      "step": 56060
    },
    {
      "epoch": 4.784537929857496,
      "grad_norm": 0.21653306484222412,
      "learning_rate": 2.154620701425036e-06,
      "loss": 0.0017,
      "step": 56070
    },
    {
      "epoch": 4.785391244986774,
      "grad_norm": 0.15346938371658325,
      "learning_rate": 2.146087550132264e-06,
      "loss": 0.0018,
      "step": 56080
    },
    {
      "epoch": 4.786244560116051,
      "grad_norm": 0.17061316967010498,
      "learning_rate": 2.1375543988394914e-06,
      "loss": 0.0019,
      "step": 56090
    },
    {
      "epoch": 4.787097875245328,
      "grad_norm": 0.2297523319721222,
      "learning_rate": 2.129021247546719e-06,
      "loss": 0.0018,
      "step": 56100
    },
    {
      "epoch": 4.7879511903746055,
      "grad_norm": 0.17747190594673157,
      "learning_rate": 2.1204880962539467e-06,
      "loss": 0.0016,
      "step": 56110
    },
    {
      "epoch": 4.788804505503883,
      "grad_norm": 0.12751175463199615,
      "learning_rate": 2.1119549449611743e-06,
      "loss": 0.0015,
      "step": 56120
    },
    {
      "epoch": 4.78965782063316,
      "grad_norm": 0.22554565966129303,
      "learning_rate": 2.1034217936684016e-06,
      "loss": 0.0017,
      "step": 56130
    },
    {
      "epoch": 4.790511135762437,
      "grad_norm": 0.21674072742462158,
      "learning_rate": 2.0948886423756296e-06,
      "loss": 0.0019,
      "step": 56140
    },
    {
      "epoch": 4.791364450891714,
      "grad_norm": 0.22660531103610992,
      "learning_rate": 2.086355491082857e-06,
      "loss": 0.0015,
      "step": 56150
    },
    {
      "epoch": 4.7922177660209915,
      "grad_norm": 0.03750723600387573,
      "learning_rate": 2.077822339790085e-06,
      "loss": 0.0019,
      "step": 56160
    },
    {
      "epoch": 4.793071081150269,
      "grad_norm": 0.0871475487947464,
      "learning_rate": 2.069289188497312e-06,
      "loss": 0.0016,
      "step": 56170
    },
    {
      "epoch": 4.793924396279546,
      "grad_norm": 0.19605092704296112,
      "learning_rate": 2.0607560372045397e-06,
      "loss": 0.0018,
      "step": 56180
    },
    {
      "epoch": 4.794777711408823,
      "grad_norm": 0.11763854324817657,
      "learning_rate": 2.0522228859117674e-06,
      "loss": 0.0015,
      "step": 56190
    },
    {
      "epoch": 4.795631026538101,
      "grad_norm": 0.059043433517217636,
      "learning_rate": 2.043689734618995e-06,
      "loss": 0.0015,
      "step": 56200
    },
    {
      "epoch": 4.7964843416673775,
      "grad_norm": 0.06999346613883972,
      "learning_rate": 2.0351565833262226e-06,
      "loss": 0.0013,
      "step": 56210
    },
    {
      "epoch": 4.797337656796655,
      "grad_norm": 0.1767912060022354,
      "learning_rate": 2.02662343203345e-06,
      "loss": 0.0015,
      "step": 56220
    },
    {
      "epoch": 4.798190971925933,
      "grad_norm": 0.1273314356803894,
      "learning_rate": 2.0180902807406775e-06,
      "loss": 0.0015,
      "step": 56230
    },
    {
      "epoch": 4.799044287055209,
      "grad_norm": 0.21708011627197266,
      "learning_rate": 2.009557129447905e-06,
      "loss": 0.0018,
      "step": 56240
    },
    {
      "epoch": 4.799897602184487,
      "grad_norm": 0.05406593903899193,
      "learning_rate": 2.0010239781551327e-06,
      "loss": 0.0019,
      "step": 56250
    },
    {
      "epoch": 4.800750917313764,
      "grad_norm": 0.2188679575920105,
      "learning_rate": 1.9924908268623604e-06,
      "loss": 0.0022,
      "step": 56260
    },
    {
      "epoch": 4.801604232443041,
      "grad_norm": 0.1598169356584549,
      "learning_rate": 1.983957675569588e-06,
      "loss": 0.0017,
      "step": 56270
    },
    {
      "epoch": 4.802457547572319,
      "grad_norm": 0.13160622119903564,
      "learning_rate": 1.9754245242768152e-06,
      "loss": 0.0017,
      "step": 56280
    },
    {
      "epoch": 4.803310862701595,
      "grad_norm": 0.0835605040192604,
      "learning_rate": 1.9668913729840433e-06,
      "loss": 0.0019,
      "step": 56290
    },
    {
      "epoch": 4.804164177830873,
      "grad_norm": 0.08465007692575455,
      "learning_rate": 1.9583582216912705e-06,
      "loss": 0.0022,
      "step": 56300
    },
    {
      "epoch": 4.80501749296015,
      "grad_norm": 0.15783298015594482,
      "learning_rate": 1.9498250703984986e-06,
      "loss": 0.0018,
      "step": 56310
    },
    {
      "epoch": 4.805870808089427,
      "grad_norm": 0.03577654808759689,
      "learning_rate": 1.9412919191057258e-06,
      "loss": 0.0017,
      "step": 56320
    },
    {
      "epoch": 4.806724123218705,
      "grad_norm": 0.10510846227407455,
      "learning_rate": 1.9327587678129534e-06,
      "loss": 0.0015,
      "step": 56330
    },
    {
      "epoch": 4.807577438347982,
      "grad_norm": 0.39979979395866394,
      "learning_rate": 1.924225616520181e-06,
      "loss": 0.0015,
      "step": 56340
    },
    {
      "epoch": 4.808430753477259,
      "grad_norm": 0.13275626301765442,
      "learning_rate": 1.9156924652274087e-06,
      "loss": 0.0019,
      "step": 56350
    },
    {
      "epoch": 4.809284068606536,
      "grad_norm": 0.09357127547264099,
      "learning_rate": 1.9071593139346363e-06,
      "loss": 0.0014,
      "step": 56360
    },
    {
      "epoch": 4.810137383735814,
      "grad_norm": 0.3042527139186859,
      "learning_rate": 1.8986261626418637e-06,
      "loss": 0.0021,
      "step": 56370
    },
    {
      "epoch": 4.810990698865091,
      "grad_norm": 0.2541067600250244,
      "learning_rate": 1.8900930113490912e-06,
      "loss": 0.0017,
      "step": 56380
    },
    {
      "epoch": 4.811844013994368,
      "grad_norm": 0.08547724783420563,
      "learning_rate": 1.881559860056319e-06,
      "loss": 0.0017,
      "step": 56390
    },
    {
      "epoch": 4.812697329123646,
      "grad_norm": 0.17341415584087372,
      "learning_rate": 1.8730267087635464e-06,
      "loss": 0.0019,
      "step": 56400
    },
    {
      "epoch": 4.813550644252922,
      "grad_norm": 0.2266533076763153,
      "learning_rate": 1.8644935574707743e-06,
      "loss": 0.0019,
      "step": 56410
    },
    {
      "epoch": 4.8144039593822,
      "grad_norm": 0.16364139318466187,
      "learning_rate": 1.8559604061780017e-06,
      "loss": 0.0018,
      "step": 56420
    },
    {
      "epoch": 4.8152572745114774,
      "grad_norm": 0.11676311492919922,
      "learning_rate": 1.8474272548852291e-06,
      "loss": 0.0016,
      "step": 56430
    },
    {
      "epoch": 4.816110589640754,
      "grad_norm": 0.04738405719399452,
      "learning_rate": 1.838894103592457e-06,
      "loss": 0.0015,
      "step": 56440
    },
    {
      "epoch": 4.816963904770032,
      "grad_norm": 0.12277083098888397,
      "learning_rate": 1.8303609522996844e-06,
      "loss": 0.0016,
      "step": 56450
    },
    {
      "epoch": 4.817817219899309,
      "grad_norm": 0.2601582407951355,
      "learning_rate": 1.821827801006912e-06,
      "loss": 0.0015,
      "step": 56460
    },
    {
      "epoch": 4.818670535028586,
      "grad_norm": 0.2050938904285431,
      "learning_rate": 1.8132946497141394e-06,
      "loss": 0.0018,
      "step": 56470
    },
    {
      "epoch": 4.819523850157863,
      "grad_norm": 0.25155457854270935,
      "learning_rate": 1.804761498421367e-06,
      "loss": 0.0017,
      "step": 56480
    },
    {
      "epoch": 4.820377165287141,
      "grad_norm": 0.2645134925842285,
      "learning_rate": 1.7962283471285947e-06,
      "loss": 0.0019,
      "step": 56490
    },
    {
      "epoch": 4.821230480416418,
      "grad_norm": 0.06402400135993958,
      "learning_rate": 1.7876951958358221e-06,
      "loss": 0.0019,
      "step": 56500
    },
    {
      "epoch": 4.822083795545695,
      "grad_norm": 0.22538702189922333,
      "learning_rate": 1.77916204454305e-06,
      "loss": 0.0016,
      "step": 56510
    },
    {
      "epoch": 4.822937110674972,
      "grad_norm": 0.36603492498397827,
      "learning_rate": 1.7706288932502774e-06,
      "loss": 0.0013,
      "step": 56520
    },
    {
      "epoch": 4.823790425804249,
      "grad_norm": 0.17090359330177307,
      "learning_rate": 1.7620957419575048e-06,
      "loss": 0.0016,
      "step": 56530
    },
    {
      "epoch": 4.824643740933527,
      "grad_norm": 0.13379517197608948,
      "learning_rate": 1.7535625906647327e-06,
      "loss": 0.0016,
      "step": 56540
    },
    {
      "epoch": 4.825497056062804,
      "grad_norm": 0.15985997021198273,
      "learning_rate": 1.74502943937196e-06,
      "loss": 0.0013,
      "step": 56550
    },
    {
      "epoch": 4.826350371192081,
      "grad_norm": 0.17713217437267303,
      "learning_rate": 1.736496288079188e-06,
      "loss": 0.0016,
      "step": 56560
    },
    {
      "epoch": 4.827203686321359,
      "grad_norm": 0.39793872833251953,
      "learning_rate": 1.7279631367864154e-06,
      "loss": 0.0019,
      "step": 56570
    },
    {
      "epoch": 4.828057001450635,
      "grad_norm": 0.2300388216972351,
      "learning_rate": 1.7194299854936428e-06,
      "loss": 0.0019,
      "step": 56580
    },
    {
      "epoch": 4.828910316579913,
      "grad_norm": 0.13487599790096283,
      "learning_rate": 1.7108968342008706e-06,
      "loss": 0.0015,
      "step": 56590
    },
    {
      "epoch": 4.8297636317091905,
      "grad_norm": 0.22638390958309174,
      "learning_rate": 1.702363682908098e-06,
      "loss": 0.0022,
      "step": 56600
    },
    {
      "epoch": 4.830616946838467,
      "grad_norm": 0.2647165060043335,
      "learning_rate": 1.6938305316153257e-06,
      "loss": 0.0016,
      "step": 56610
    },
    {
      "epoch": 4.831470261967745,
      "grad_norm": 0.05988483875989914,
      "learning_rate": 1.6852973803225533e-06,
      "loss": 0.0013,
      "step": 56620
    },
    {
      "epoch": 4.832323577097022,
      "grad_norm": 0.06603580713272095,
      "learning_rate": 1.6767642290297808e-06,
      "loss": 0.0018,
      "step": 56630
    },
    {
      "epoch": 4.833176892226299,
      "grad_norm": 0.11965441703796387,
      "learning_rate": 1.6682310777370084e-06,
      "loss": 0.0017,
      "step": 56640
    },
    {
      "epoch": 4.8340302073555765,
      "grad_norm": 0.045975469052791595,
      "learning_rate": 1.6596979264442358e-06,
      "loss": 0.0017,
      "step": 56650
    },
    {
      "epoch": 4.834883522484853,
      "grad_norm": 0.2434735745191574,
      "learning_rate": 1.6511647751514637e-06,
      "loss": 0.0018,
      "step": 56660
    },
    {
      "epoch": 4.835736837614131,
      "grad_norm": 0.16853652894496918,
      "learning_rate": 1.642631623858691e-06,
      "loss": 0.0016,
      "step": 56670
    },
    {
      "epoch": 4.836590152743408,
      "grad_norm": 0.035729486495256424,
      "learning_rate": 1.6340984725659185e-06,
      "loss": 0.0015,
      "step": 56680
    },
    {
      "epoch": 4.837443467872685,
      "grad_norm": 0.15762461721897125,
      "learning_rate": 1.6255653212731464e-06,
      "loss": 0.0017,
      "step": 56690
    },
    {
      "epoch": 4.8382967830019625,
      "grad_norm": 0.04359851032495499,
      "learning_rate": 1.6170321699803738e-06,
      "loss": 0.0017,
      "step": 56700
    },
    {
      "epoch": 4.83915009813124,
      "grad_norm": 0.13292048871517181,
      "learning_rate": 1.6084990186876012e-06,
      "loss": 0.0019,
      "step": 56710
    },
    {
      "epoch": 4.840003413260517,
      "grad_norm": 0.08166768401861191,
      "learning_rate": 1.599965867394829e-06,
      "loss": 0.0013,
      "step": 56720
    },
    {
      "epoch": 4.840856728389794,
      "grad_norm": 0.05040078982710838,
      "learning_rate": 1.5914327161020565e-06,
      "loss": 0.0018,
      "step": 56730
    },
    {
      "epoch": 4.841710043519072,
      "grad_norm": 0.15513040125370026,
      "learning_rate": 1.5828995648092843e-06,
      "loss": 0.0018,
      "step": 56740
    },
    {
      "epoch": 4.8425633586483485,
      "grad_norm": 0.09705206751823425,
      "learning_rate": 1.5743664135165117e-06,
      "loss": 0.0017,
      "step": 56750
    },
    {
      "epoch": 4.843416673777626,
      "grad_norm": 0.21452294290065765,
      "learning_rate": 1.5658332622237392e-06,
      "loss": 0.0021,
      "step": 56760
    },
    {
      "epoch": 4.844269988906904,
      "grad_norm": 0.35897642374038696,
      "learning_rate": 1.557300110930967e-06,
      "loss": 0.002,
      "step": 56770
    },
    {
      "epoch": 4.84512330403618,
      "grad_norm": 0.17367693781852722,
      "learning_rate": 1.5487669596381944e-06,
      "loss": 0.0017,
      "step": 56780
    },
    {
      "epoch": 4.845976619165458,
      "grad_norm": 0.17308977246284485,
      "learning_rate": 1.540233808345422e-06,
      "loss": 0.0015,
      "step": 56790
    },
    {
      "epoch": 4.846829934294735,
      "grad_norm": 0.22096824645996094,
      "learning_rate": 1.5317006570526495e-06,
      "loss": 0.0015,
      "step": 56800
    },
    {
      "epoch": 4.847683249424012,
      "grad_norm": 0.23140405118465424,
      "learning_rate": 1.5231675057598771e-06,
      "loss": 0.0019,
      "step": 56810
    },
    {
      "epoch": 4.84853656455329,
      "grad_norm": 0.05960768833756447,
      "learning_rate": 1.5146343544671048e-06,
      "loss": 0.0018,
      "step": 56820
    },
    {
      "epoch": 4.849389879682567,
      "grad_norm": 0.24766859412193298,
      "learning_rate": 1.5061012031743324e-06,
      "loss": 0.0018,
      "step": 56830
    },
    {
      "epoch": 4.850243194811844,
      "grad_norm": 0.16108907759189606,
      "learning_rate": 1.4975680518815598e-06,
      "loss": 0.0016,
      "step": 56840
    },
    {
      "epoch": 4.851096509941121,
      "grad_norm": 0.07013999670743942,
      "learning_rate": 1.4890349005887875e-06,
      "loss": 0.0021,
      "step": 56850
    },
    {
      "epoch": 4.851949825070399,
      "grad_norm": 0.03426394611597061,
      "learning_rate": 1.480501749296015e-06,
      "loss": 0.0017,
      "step": 56860
    },
    {
      "epoch": 4.852803140199676,
      "grad_norm": 0.03306840360164642,
      "learning_rate": 1.4719685980032427e-06,
      "loss": 0.002,
      "step": 56870
    },
    {
      "epoch": 4.853656455328953,
      "grad_norm": 0.20479224622249603,
      "learning_rate": 1.4634354467104704e-06,
      "loss": 0.0017,
      "step": 56880
    },
    {
      "epoch": 4.85450977045823,
      "grad_norm": 0.2498096227645874,
      "learning_rate": 1.4549022954176978e-06,
      "loss": 0.0019,
      "step": 56890
    },
    {
      "epoch": 4.855363085587507,
      "grad_norm": 0.2800091803073883,
      "learning_rate": 1.4463691441249254e-06,
      "loss": 0.0021,
      "step": 56900
    },
    {
      "epoch": 4.856216400716785,
      "grad_norm": 0.3825582265853882,
      "learning_rate": 1.437835992832153e-06,
      "loss": 0.0019,
      "step": 56910
    },
    {
      "epoch": 4.857069715846062,
      "grad_norm": 0.32898256182670593,
      "learning_rate": 1.4293028415393807e-06,
      "loss": 0.0016,
      "step": 56920
    },
    {
      "epoch": 4.857923030975339,
      "grad_norm": 0.049390509724617004,
      "learning_rate": 1.4207696902466081e-06,
      "loss": 0.0017,
      "step": 56930
    },
    {
      "epoch": 4.858776346104617,
      "grad_norm": 0.21439118683338165,
      "learning_rate": 1.4122365389538357e-06,
      "loss": 0.0017,
      "step": 56940
    },
    {
      "epoch": 4.859629661233893,
      "grad_norm": 0.3046569526195526,
      "learning_rate": 1.4037033876610634e-06,
      "loss": 0.0018,
      "step": 56950
    },
    {
      "epoch": 4.860482976363171,
      "grad_norm": 0.08811607211828232,
      "learning_rate": 1.3951702363682908e-06,
      "loss": 0.0014,
      "step": 56960
    },
    {
      "epoch": 4.8613362914924485,
      "grad_norm": 0.09889399260282516,
      "learning_rate": 1.3866370850755184e-06,
      "loss": 0.002,
      "step": 56970
    },
    {
      "epoch": 4.862189606621725,
      "grad_norm": 0.18296301364898682,
      "learning_rate": 1.3781039337827459e-06,
      "loss": 0.0015,
      "step": 56980
    },
    {
      "epoch": 4.863042921751003,
      "grad_norm": 0.04259350523352623,
      "learning_rate": 1.3695707824899735e-06,
      "loss": 0.0017,
      "step": 56990
    },
    {
      "epoch": 4.863896236880279,
      "grad_norm": 0.14019672572612762,
      "learning_rate": 1.3610376311972011e-06,
      "loss": 0.0022,
      "step": 57000
    },
    {
      "epoch": 4.864749552009557,
      "grad_norm": 0.06737364083528519,
      "learning_rate": 1.3525044799044288e-06,
      "loss": 0.0016,
      "step": 57010
    },
    {
      "epoch": 4.8656028671388345,
      "grad_norm": 0.21410337090492249,
      "learning_rate": 1.3439713286116564e-06,
      "loss": 0.002,
      "step": 57020
    },
    {
      "epoch": 4.866456182268111,
      "grad_norm": 0.29351362586021423,
      "learning_rate": 1.3354381773188838e-06,
      "loss": 0.0015,
      "step": 57030
    },
    {
      "epoch": 4.867309497397389,
      "grad_norm": 0.16809605062007904,
      "learning_rate": 1.3269050260261115e-06,
      "loss": 0.0018,
      "step": 57040
    },
    {
      "epoch": 4.868162812526666,
      "grad_norm": 0.08888296037912369,
      "learning_rate": 1.318371874733339e-06,
      "loss": 0.0016,
      "step": 57050
    },
    {
      "epoch": 4.869016127655943,
      "grad_norm": 0.05267748981714249,
      "learning_rate": 1.3098387234405667e-06,
      "loss": 0.0015,
      "step": 57060
    },
    {
      "epoch": 4.8698694427852205,
      "grad_norm": 0.162458136677742,
      "learning_rate": 1.3013055721477944e-06,
      "loss": 0.0018,
      "step": 57070
    },
    {
      "epoch": 4.870722757914498,
      "grad_norm": 0.15573205053806305,
      "learning_rate": 1.2927724208550218e-06,
      "loss": 0.0019,
      "step": 57080
    },
    {
      "epoch": 4.871576073043775,
      "grad_norm": 0.12029661238193512,
      "learning_rate": 1.2842392695622494e-06,
      "loss": 0.0014,
      "step": 57090
    },
    {
      "epoch": 4.872429388173052,
      "grad_norm": 0.1909872591495514,
      "learning_rate": 1.275706118269477e-06,
      "loss": 0.0023,
      "step": 57100
    },
    {
      "epoch": 4.87328270330233,
      "grad_norm": 0.052108727395534515,
      "learning_rate": 1.2671729669767047e-06,
      "loss": 0.0016,
      "step": 57110
    },
    {
      "epoch": 4.8741360184316065,
      "grad_norm": 0.0407601073384285,
      "learning_rate": 1.2586398156839321e-06,
      "loss": 0.0018,
      "step": 57120
    },
    {
      "epoch": 4.874989333560884,
      "grad_norm": 0.12650522589683533,
      "learning_rate": 1.2501066643911597e-06,
      "loss": 0.0021,
      "step": 57130
    },
    {
      "epoch": 4.875842648690162,
      "grad_norm": 0.39385008811950684,
      "learning_rate": 1.2415735130983872e-06,
      "loss": 0.0015,
      "step": 57140
    },
    {
      "epoch": 4.876695963819438,
      "grad_norm": 0.14002956449985504,
      "learning_rate": 1.2330403618056148e-06,
      "loss": 0.0019,
      "step": 57150
    },
    {
      "epoch": 4.877549278948716,
      "grad_norm": 0.05741657689213753,
      "learning_rate": 1.2245072105128424e-06,
      "loss": 0.0016,
      "step": 57160
    },
    {
      "epoch": 4.878402594077993,
      "grad_norm": 0.04443371295928955,
      "learning_rate": 1.21597405922007e-06,
      "loss": 0.0019,
      "step": 57170
    },
    {
      "epoch": 4.87925590920727,
      "grad_norm": 0.36255088448524475,
      "learning_rate": 1.2074409079272975e-06,
      "loss": 0.0018,
      "step": 57180
    },
    {
      "epoch": 4.880109224336548,
      "grad_norm": 0.08298146724700928,
      "learning_rate": 1.1989077566345251e-06,
      "loss": 0.0015,
      "step": 57190
    },
    {
      "epoch": 4.880962539465825,
      "grad_norm": 0.14542241394519806,
      "learning_rate": 1.1903746053417528e-06,
      "loss": 0.0017,
      "step": 57200
    },
    {
      "epoch": 4.881815854595102,
      "grad_norm": 0.15323583781719208,
      "learning_rate": 1.1818414540489804e-06,
      "loss": 0.0017,
      "step": 57210
    },
    {
      "epoch": 4.882669169724379,
      "grad_norm": 0.17556031048297882,
      "learning_rate": 1.173308302756208e-06,
      "loss": 0.0016,
      "step": 57220
    },
    {
      "epoch": 4.883522484853657,
      "grad_norm": 0.22897425293922424,
      "learning_rate": 1.1647751514634355e-06,
      "loss": 0.0021,
      "step": 57230
    },
    {
      "epoch": 4.884375799982934,
      "grad_norm": 0.08816113322973251,
      "learning_rate": 1.156242000170663e-06,
      "loss": 0.0019,
      "step": 57240
    },
    {
      "epoch": 4.885229115112211,
      "grad_norm": 0.19793812930583954,
      "learning_rate": 1.1477088488778907e-06,
      "loss": 0.0013,
      "step": 57250
    },
    {
      "epoch": 4.886082430241488,
      "grad_norm": 0.22611987590789795,
      "learning_rate": 1.1391756975851184e-06,
      "loss": 0.0022,
      "step": 57260
    },
    {
      "epoch": 4.886935745370765,
      "grad_norm": 0.15189313888549805,
      "learning_rate": 1.130642546292346e-06,
      "loss": 0.002,
      "step": 57270
    },
    {
      "epoch": 4.887789060500043,
      "grad_norm": 0.11657559126615524,
      "learning_rate": 1.1221093949995734e-06,
      "loss": 0.0015,
      "step": 57280
    },
    {
      "epoch": 4.88864237562932,
      "grad_norm": 0.17319826781749725,
      "learning_rate": 1.1135762437068008e-06,
      "loss": 0.0019,
      "step": 57290
    },
    {
      "epoch": 4.889495690758597,
      "grad_norm": 0.06928195804357529,
      "learning_rate": 1.1050430924140285e-06,
      "loss": 0.0016,
      "step": 57300
    },
    {
      "epoch": 4.890349005887875,
      "grad_norm": 0.0351298525929451,
      "learning_rate": 1.0965099411212561e-06,
      "loss": 0.0018,
      "step": 57310
    },
    {
      "epoch": 4.891202321017151,
      "grad_norm": 0.3024922311306,
      "learning_rate": 1.0879767898284838e-06,
      "loss": 0.0017,
      "step": 57320
    },
    {
      "epoch": 4.892055636146429,
      "grad_norm": 0.38044336438179016,
      "learning_rate": 1.0794436385357112e-06,
      "loss": 0.0018,
      "step": 57330
    },
    {
      "epoch": 4.8929089512757065,
      "grad_norm": 0.049728699028491974,
      "learning_rate": 1.0709104872429388e-06,
      "loss": 0.0018,
      "step": 57340
    },
    {
      "epoch": 4.893762266404983,
      "grad_norm": 0.20220622420310974,
      "learning_rate": 1.0623773359501664e-06,
      "loss": 0.0015,
      "step": 57350
    },
    {
      "epoch": 4.894615581534261,
      "grad_norm": 0.3647676706314087,
      "learning_rate": 1.053844184657394e-06,
      "loss": 0.0015,
      "step": 57360
    },
    {
      "epoch": 4.895468896663537,
      "grad_norm": 0.26136159896850586,
      "learning_rate": 1.0453110333646217e-06,
      "loss": 0.0013,
      "step": 57370
    },
    {
      "epoch": 4.896322211792815,
      "grad_norm": 0.13293680548667908,
      "learning_rate": 1.0367778820718491e-06,
      "loss": 0.0018,
      "step": 57380
    },
    {
      "epoch": 4.8971755269220925,
      "grad_norm": 0.17130731046199799,
      "learning_rate": 1.0282447307790768e-06,
      "loss": 0.0016,
      "step": 57390
    },
    {
      "epoch": 4.898028842051369,
      "grad_norm": 0.09851612895727158,
      "learning_rate": 1.0197115794863044e-06,
      "loss": 0.0016,
      "step": 57400
    },
    {
      "epoch": 4.898882157180647,
      "grad_norm": 0.04938133433461189,
      "learning_rate": 1.011178428193532e-06,
      "loss": 0.0019,
      "step": 57410
    },
    {
      "epoch": 4.899735472309924,
      "grad_norm": 0.28291308879852295,
      "learning_rate": 1.0026452769007595e-06,
      "loss": 0.0016,
      "step": 57420
    },
    {
      "epoch": 4.900588787439201,
      "grad_norm": 0.0664013996720314,
      "learning_rate": 9.94112125607987e-07,
      "loss": 0.0018,
      "step": 57430
    },
    {
      "epoch": 4.9014421025684785,
      "grad_norm": 0.22492049634456635,
      "learning_rate": 9.855789743152147e-07,
      "loss": 0.0017,
      "step": 57440
    },
    {
      "epoch": 4.902295417697756,
      "grad_norm": 0.21628744900226593,
      "learning_rate": 9.770458230224422e-07,
      "loss": 0.0016,
      "step": 57450
    },
    {
      "epoch": 4.903148732827033,
      "grad_norm": 0.1028347760438919,
      "learning_rate": 9.685126717296698e-07,
      "loss": 0.0016,
      "step": 57460
    },
    {
      "epoch": 4.90400204795631,
      "grad_norm": 0.12288251519203186,
      "learning_rate": 9.599795204368972e-07,
      "loss": 0.0017,
      "step": 57470
    },
    {
      "epoch": 4.904855363085588,
      "grad_norm": 0.16681677103042603,
      "learning_rate": 9.51446369144125e-07,
      "loss": 0.0017,
      "step": 57480
    },
    {
      "epoch": 4.9057086782148644,
      "grad_norm": 0.051038991659879684,
      "learning_rate": 9.429132178513526e-07,
      "loss": 0.0016,
      "step": 57490
    },
    {
      "epoch": 4.906561993344142,
      "grad_norm": 0.09037824720144272,
      "learning_rate": 9.343800665585801e-07,
      "loss": 0.0016,
      "step": 57500
    },
    {
      "epoch": 4.90741530847342,
      "grad_norm": 0.05906222388148308,
      "learning_rate": 9.258469152658078e-07,
      "loss": 0.0017,
      "step": 57510
    },
    {
      "epoch": 4.908268623602696,
      "grad_norm": 0.26247692108154297,
      "learning_rate": 9.173137639730352e-07,
      "loss": 0.0019,
      "step": 57520
    },
    {
      "epoch": 4.909121938731974,
      "grad_norm": 0.2503449320793152,
      "learning_rate": 9.087806126802628e-07,
      "loss": 0.0019,
      "step": 57530
    },
    {
      "epoch": 4.909975253861251,
      "grad_norm": 0.17800000309944153,
      "learning_rate": 9.002474613874904e-07,
      "loss": 0.0019,
      "step": 57540
    },
    {
      "epoch": 4.910828568990528,
      "grad_norm": 0.0682266429066658,
      "learning_rate": 8.917143100947181e-07,
      "loss": 0.0015,
      "step": 57550
    },
    {
      "epoch": 4.9116818841198056,
      "grad_norm": 0.050415150821208954,
      "learning_rate": 8.831811588019456e-07,
      "loss": 0.0019,
      "step": 57560
    },
    {
      "epoch": 4.912535199249083,
      "grad_norm": 0.23974762856960297,
      "learning_rate": 8.746480075091731e-07,
      "loss": 0.0015,
      "step": 57570
    },
    {
      "epoch": 4.91338851437836,
      "grad_norm": 0.26864093542099,
      "learning_rate": 8.661148562164007e-07,
      "loss": 0.0015,
      "step": 57580
    },
    {
      "epoch": 4.914241829507637,
      "grad_norm": 0.14237746596336365,
      "learning_rate": 8.575817049236283e-07,
      "loss": 0.0015,
      "step": 57590
    },
    {
      "epoch": 4.915095144636915,
      "grad_norm": 0.031918011605739594,
      "learning_rate": 8.490485536308559e-07,
      "loss": 0.0016,
      "step": 57600
    },
    {
      "epoch": 4.9159484597661915,
      "grad_norm": 0.04772351682186127,
      "learning_rate": 8.405154023380836e-07,
      "loss": 0.0016,
      "step": 57610
    },
    {
      "epoch": 4.916801774895469,
      "grad_norm": 0.20108434557914734,
      "learning_rate": 8.31982251045311e-07,
      "loss": 0.0017,
      "step": 57620
    },
    {
      "epoch": 4.917655090024746,
      "grad_norm": 0.11098191142082214,
      "learning_rate": 8.234490997525386e-07,
      "loss": 0.0017,
      "step": 57630
    },
    {
      "epoch": 4.918508405154023,
      "grad_norm": 0.050218213349580765,
      "learning_rate": 8.149159484597663e-07,
      "loss": 0.0016,
      "step": 57640
    },
    {
      "epoch": 4.919361720283301,
      "grad_norm": 0.13842672109603882,
      "learning_rate": 8.063827971669938e-07,
      "loss": 0.0017,
      "step": 57650
    },
    {
      "epoch": 4.9202150354125775,
      "grad_norm": 0.09605196863412857,
      "learning_rate": 7.978496458742214e-07,
      "loss": 0.0015,
      "step": 57660
    },
    {
      "epoch": 4.921068350541855,
      "grad_norm": 0.12114205211400986,
      "learning_rate": 7.893164945814489e-07,
      "loss": 0.0019,
      "step": 57670
    },
    {
      "epoch": 4.921921665671133,
      "grad_norm": 0.09226348251104355,
      "learning_rate": 7.807833432886765e-07,
      "loss": 0.0019,
      "step": 57680
    },
    {
      "epoch": 4.922774980800409,
      "grad_norm": 0.10320518165826797,
      "learning_rate": 7.722501919959041e-07,
      "loss": 0.0017,
      "step": 57690
    },
    {
      "epoch": 4.923628295929687,
      "grad_norm": 0.2941068708896637,
      "learning_rate": 7.637170407031318e-07,
      "loss": 0.0017,
      "step": 57700
    },
    {
      "epoch": 4.924481611058964,
      "grad_norm": 0.09214042872190475,
      "learning_rate": 7.551838894103593e-07,
      "loss": 0.0012,
      "step": 57710
    },
    {
      "epoch": 4.925334926188241,
      "grad_norm": 0.04902191087603569,
      "learning_rate": 7.466507381175869e-07,
      "loss": 0.0019,
      "step": 57720
    },
    {
      "epoch": 4.926188241317519,
      "grad_norm": 0.2859996557235718,
      "learning_rate": 7.381175868248145e-07,
      "loss": 0.002,
      "step": 57730
    },
    {
      "epoch": 4.927041556446795,
      "grad_norm": 0.049003083258867264,
      "learning_rate": 7.29584435532042e-07,
      "loss": 0.0016,
      "step": 57740
    },
    {
      "epoch": 4.927894871576073,
      "grad_norm": 0.17491765320301056,
      "learning_rate": 7.210512842392696e-07,
      "loss": 0.0016,
      "step": 57750
    },
    {
      "epoch": 4.92874818670535,
      "grad_norm": 0.04256920889019966,
      "learning_rate": 7.125181329464971e-07,
      "loss": 0.0016,
      "step": 57760
    },
    {
      "epoch": 4.929601501834627,
      "grad_norm": 0.18965622782707214,
      "learning_rate": 7.039849816537248e-07,
      "loss": 0.0015,
      "step": 57770
    },
    {
      "epoch": 4.930454816963905,
      "grad_norm": 0.1504354029893875,
      "learning_rate": 6.954518303609523e-07,
      "loss": 0.0013,
      "step": 57780
    },
    {
      "epoch": 4.931308132093182,
      "grad_norm": 0.05379032343626022,
      "learning_rate": 6.869186790681799e-07,
      "loss": 0.0016,
      "step": 57790
    },
    {
      "epoch": 4.932161447222459,
      "grad_norm": 0.23383724689483643,
      "learning_rate": 6.783855277754075e-07,
      "loss": 0.0021,
      "step": 57800
    },
    {
      "epoch": 4.933014762351736,
      "grad_norm": 0.17444957792758942,
      "learning_rate": 6.698523764826351e-07,
      "loss": 0.0016,
      "step": 57810
    },
    {
      "epoch": 4.933868077481014,
      "grad_norm": 0.18565303087234497,
      "learning_rate": 6.613192251898626e-07,
      "loss": 0.0017,
      "step": 57820
    },
    {
      "epoch": 4.934721392610291,
      "grad_norm": 0.20961272716522217,
      "learning_rate": 6.527860738970902e-07,
      "loss": 0.0017,
      "step": 57830
    },
    {
      "epoch": 4.935574707739568,
      "grad_norm": 0.061306554824113846,
      "learning_rate": 6.442529226043178e-07,
      "loss": 0.0016,
      "step": 57840
    },
    {
      "epoch": 4.936428022868846,
      "grad_norm": 0.24114950001239777,
      "learning_rate": 6.357197713115453e-07,
      "loss": 0.0019,
      "step": 57850
    },
    {
      "epoch": 4.937281337998122,
      "grad_norm": 0.10211308300495148,
      "learning_rate": 6.27186620018773e-07,
      "loss": 0.0014,
      "step": 57860
    },
    {
      "epoch": 4.9381346531274,
      "grad_norm": 0.05802018567919731,
      "learning_rate": 6.186534687260006e-07,
      "loss": 0.0016,
      "step": 57870
    },
    {
      "epoch": 4.9389879682566775,
      "grad_norm": 0.07833970338106155,
      "learning_rate": 6.101203174332281e-07,
      "loss": 0.0014,
      "step": 57880
    },
    {
      "epoch": 4.939841283385954,
      "grad_norm": 0.1364925354719162,
      "learning_rate": 6.015871661404558e-07,
      "loss": 0.002,
      "step": 57890
    },
    {
      "epoch": 4.940694598515232,
      "grad_norm": 0.20906738936901093,
      "learning_rate": 5.930540148476833e-07,
      "loss": 0.0015,
      "step": 57900
    },
    {
      "epoch": 4.941547913644509,
      "grad_norm": 0.340717077255249,
      "learning_rate": 5.845208635549108e-07,
      "loss": 0.0024,
      "step": 57910
    },
    {
      "epoch": 4.942401228773786,
      "grad_norm": 0.13304367661476135,
      "learning_rate": 5.759877122621385e-07,
      "loss": 0.002,
      "step": 57920
    },
    {
      "epoch": 4.9432545439030635,
      "grad_norm": 0.1760842502117157,
      "learning_rate": 5.67454560969366e-07,
      "loss": 0.0018,
      "step": 57930
    },
    {
      "epoch": 4.944107859032341,
      "grad_norm": 0.24207186698913574,
      "learning_rate": 5.589214096765936e-07,
      "loss": 0.0018,
      "step": 57940
    },
    {
      "epoch": 4.944961174161618,
      "grad_norm": 0.25288599729537964,
      "learning_rate": 5.503882583838211e-07,
      "loss": 0.0019,
      "step": 57950
    },
    {
      "epoch": 4.945814489290895,
      "grad_norm": 0.13598044216632843,
      "learning_rate": 5.418551070910488e-07,
      "loss": 0.0017,
      "step": 57960
    },
    {
      "epoch": 4.946667804420173,
      "grad_norm": 0.33504223823547363,
      "learning_rate": 5.333219557982764e-07,
      "loss": 0.0012,
      "step": 57970
    },
    {
      "epoch": 4.9475211195494495,
      "grad_norm": 0.03339428827166557,
      "learning_rate": 5.24788804505504e-07,
      "loss": 0.0012,
      "step": 57980
    },
    {
      "epoch": 4.948374434678727,
      "grad_norm": 0.08054478466510773,
      "learning_rate": 5.162556532127315e-07,
      "loss": 0.0018,
      "step": 57990
    },
    {
      "epoch": 4.949227749808004,
      "grad_norm": 0.3687075972557068,
      "learning_rate": 5.07722501919959e-07,
      "loss": 0.0019,
      "step": 58000
    },
    {
      "epoch": 4.950081064937281,
      "grad_norm": 0.16987286508083344,
      "learning_rate": 4.991893506271866e-07,
      "loss": 0.0015,
      "step": 58010
    },
    {
      "epoch": 4.950934380066559,
      "grad_norm": 0.08074314147233963,
      "learning_rate": 4.906561993344142e-07,
      "loss": 0.0022,
      "step": 58020
    },
    {
      "epoch": 4.9517876951958355,
      "grad_norm": 0.23233704268932343,
      "learning_rate": 4.821230480416418e-07,
      "loss": 0.0017,
      "step": 58030
    },
    {
      "epoch": 4.952641010325113,
      "grad_norm": 0.08633500337600708,
      "learning_rate": 4.735898967488694e-07,
      "loss": 0.002,
      "step": 58040
    },
    {
      "epoch": 4.953494325454391,
      "grad_norm": 0.12263508886098862,
      "learning_rate": 4.650567454560969e-07,
      "loss": 0.0016,
      "step": 58050
    },
    {
      "epoch": 4.954347640583667,
      "grad_norm": 0.341342031955719,
      "learning_rate": 4.5652359416332455e-07,
      "loss": 0.0014,
      "step": 58060
    },
    {
      "epoch": 4.955200955712945,
      "grad_norm": 0.17006230354309082,
      "learning_rate": 4.479904428705521e-07,
      "loss": 0.0018,
      "step": 58070
    },
    {
      "epoch": 4.956054270842222,
      "grad_norm": 0.24592691659927368,
      "learning_rate": 4.394572915777797e-07,
      "loss": 0.0016,
      "step": 58080
    },
    {
      "epoch": 4.956907585971499,
      "grad_norm": 0.15896621346473694,
      "learning_rate": 4.309241402850073e-07,
      "loss": 0.002,
      "step": 58090
    },
    {
      "epoch": 4.957760901100777,
      "grad_norm": 0.11514347046613693,
      "learning_rate": 4.223909889922348e-07,
      "loss": 0.0016,
      "step": 58100
    },
    {
      "epoch": 4.958614216230053,
      "grad_norm": 0.0405983105301857,
      "learning_rate": 4.1385783769946246e-07,
      "loss": 0.002,
      "step": 58110
    },
    {
      "epoch": 4.959467531359331,
      "grad_norm": 0.1578989177942276,
      "learning_rate": 4.0532468640669e-07,
      "loss": 0.0018,
      "step": 58120
    },
    {
      "epoch": 4.960320846488608,
      "grad_norm": 0.04820089042186737,
      "learning_rate": 3.9679153511391757e-07,
      "loss": 0.002,
      "step": 58130
    },
    {
      "epoch": 4.961174161617885,
      "grad_norm": 0.045443348586559296,
      "learning_rate": 3.8825838382114515e-07,
      "loss": 0.0019,
      "step": 58140
    },
    {
      "epoch": 4.962027476747163,
      "grad_norm": 0.13496141135692596,
      "learning_rate": 3.7972523252837274e-07,
      "loss": 0.0015,
      "step": 58150
    },
    {
      "epoch": 4.96288079187644,
      "grad_norm": 0.0802064910531044,
      "learning_rate": 3.7119208123560037e-07,
      "loss": 0.0021,
      "step": 58160
    },
    {
      "epoch": 4.963734107005717,
      "grad_norm": 0.2873550057411194,
      "learning_rate": 3.626589299428279e-07,
      "loss": 0.0013,
      "step": 58170
    },
    {
      "epoch": 4.964587422134994,
      "grad_norm": 0.10022754967212677,
      "learning_rate": 3.541257786500555e-07,
      "loss": 0.0017,
      "step": 58180
    },
    {
      "epoch": 4.965440737264272,
      "grad_norm": 0.04336182028055191,
      "learning_rate": 3.4559262735728306e-07,
      "loss": 0.0016,
      "step": 58190
    },
    {
      "epoch": 4.966294052393549,
      "grad_norm": 0.05689080059528351,
      "learning_rate": 3.3705947606451065e-07,
      "loss": 0.0017,
      "step": 58200
    },
    {
      "epoch": 4.967147367522826,
      "grad_norm": 0.04138494282960892,
      "learning_rate": 3.285263247717382e-07,
      "loss": 0.0021,
      "step": 58210
    },
    {
      "epoch": 4.968000682652104,
      "grad_norm": 0.16590875387191772,
      "learning_rate": 3.199931734789658e-07,
      "loss": 0.0017,
      "step": 58220
    },
    {
      "epoch": 4.96885399778138,
      "grad_norm": 0.12121131271123886,
      "learning_rate": 3.114600221861934e-07,
      "loss": 0.0015,
      "step": 58230
    },
    {
      "epoch": 4.969707312910658,
      "grad_norm": 0.21257370710372925,
      "learning_rate": 3.0292687089342097e-07,
      "loss": 0.0019,
      "step": 58240
    },
    {
      "epoch": 4.9705606280399355,
      "grad_norm": 0.13756594061851501,
      "learning_rate": 2.943937196006485e-07,
      "loss": 0.0018,
      "step": 58250
    },
    {
      "epoch": 4.971413943169212,
      "grad_norm": 0.17930887639522552,
      "learning_rate": 2.858605683078761e-07,
      "loss": 0.0019,
      "step": 58260
    },
    {
      "epoch": 4.97226725829849,
      "grad_norm": 0.19137625396251678,
      "learning_rate": 2.773274170151037e-07,
      "loss": 0.0013,
      "step": 58270
    },
    {
      "epoch": 4.973120573427767,
      "grad_norm": 0.16897888481616974,
      "learning_rate": 2.687942657223313e-07,
      "loss": 0.0018,
      "step": 58280
    },
    {
      "epoch": 4.973973888557044,
      "grad_norm": 0.22836834192276,
      "learning_rate": 2.6026111442955883e-07,
      "loss": 0.0015,
      "step": 58290
    },
    {
      "epoch": 4.9748272036863215,
      "grad_norm": 0.4826018512248993,
      "learning_rate": 2.517279631367864e-07,
      "loss": 0.0014,
      "step": 58300
    },
    {
      "epoch": 4.975680518815599,
      "grad_norm": 0.0571293905377388,
      "learning_rate": 2.43194811844014e-07,
      "loss": 0.002,
      "step": 58310
    },
    {
      "epoch": 4.976533833944876,
      "grad_norm": 0.18767192959785461,
      "learning_rate": 2.3466166055124158e-07,
      "loss": 0.0014,
      "step": 58320
    },
    {
      "epoch": 4.977387149074153,
      "grad_norm": 0.0869375616312027,
      "learning_rate": 2.2612850925846918e-07,
      "loss": 0.0023,
      "step": 58330
    },
    {
      "epoch": 4.978240464203431,
      "grad_norm": 0.04539910703897476,
      "learning_rate": 2.1759535796569674e-07,
      "loss": 0.0016,
      "step": 58340
    },
    {
      "epoch": 4.9790937793327075,
      "grad_norm": 0.15204229950904846,
      "learning_rate": 2.0906220667292432e-07,
      "loss": 0.0019,
      "step": 58350
    },
    {
      "epoch": 4.979947094461985,
      "grad_norm": 0.09251171350479126,
      "learning_rate": 2.005290553801519e-07,
      "loss": 0.0017,
      "step": 58360
    },
    {
      "epoch": 4.980800409591262,
      "grad_norm": 0.09724551439285278,
      "learning_rate": 1.9199590408737949e-07,
      "loss": 0.0017,
      "step": 58370
    },
    {
      "epoch": 4.981653724720539,
      "grad_norm": 0.08439850062131882,
      "learning_rate": 1.8346275279460707e-07,
      "loss": 0.0016,
      "step": 58380
    },
    {
      "epoch": 4.982507039849817,
      "grad_norm": 0.30428650975227356,
      "learning_rate": 1.7492960150183462e-07,
      "loss": 0.0016,
      "step": 58390
    },
    {
      "epoch": 4.9833603549790935,
      "grad_norm": 0.10211866348981857,
      "learning_rate": 1.663964502090622e-07,
      "loss": 0.0018,
      "step": 58400
    },
    {
      "epoch": 4.984213670108371,
      "grad_norm": 0.07633934170007706,
      "learning_rate": 1.5786329891628979e-07,
      "loss": 0.0024,
      "step": 58410
    },
    {
      "epoch": 4.985066985237649,
      "grad_norm": 0.45085248351097107,
      "learning_rate": 1.4933014762351737e-07,
      "loss": 0.0018,
      "step": 58420
    },
    {
      "epoch": 4.985920300366925,
      "grad_norm": 0.19008761644363403,
      "learning_rate": 1.4079699633074495e-07,
      "loss": 0.0021,
      "step": 58430
    },
    {
      "epoch": 4.986773615496203,
      "grad_norm": 0.11995276063680649,
      "learning_rate": 1.3226384503797253e-07,
      "loss": 0.0017,
      "step": 58440
    },
    {
      "epoch": 4.98762693062548,
      "grad_norm": 0.10324280709028244,
      "learning_rate": 1.2373069374520011e-07,
      "loss": 0.0014,
      "step": 58450
    },
    {
      "epoch": 4.988480245754757,
      "grad_norm": 0.11950284242630005,
      "learning_rate": 1.1519754245242768e-07,
      "loss": 0.0013,
      "step": 58460
    },
    {
      "epoch": 4.989333560884035,
      "grad_norm": 0.15526534616947174,
      "learning_rate": 1.0666439115965525e-07,
      "loss": 0.0014,
      "step": 58470
    },
    {
      "epoch": 4.990186876013311,
      "grad_norm": 0.1845274567604065,
      "learning_rate": 9.813123986688285e-08,
      "loss": 0.0016,
      "step": 58480
    },
    {
      "epoch": 4.991040191142589,
      "grad_norm": 0.11289173364639282,
      "learning_rate": 8.959808857411042e-08,
      "loss": 0.0014,
      "step": 58490
    },
    {
      "epoch": 4.991893506271866,
      "grad_norm": 0.05027294531464577,
      "learning_rate": 8.1064937281338e-08,
      "loss": 0.0015,
      "step": 58500
    }
  ],
  "logging_steps": 10,
  "max_steps": 58595,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 0.0,
  "train_batch_size": 64,
  "trial_name": null,
  "trial_params": null
}
