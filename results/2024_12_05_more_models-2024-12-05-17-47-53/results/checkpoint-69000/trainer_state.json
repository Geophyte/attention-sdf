{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.9714285714285715,
  "eval_steps": 500,
  "global_step": 69000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.00028571428571428574,
      "grad_norm": 0.23406432569026947,
      "learning_rate": 4.9992857142857144e-05,
      "loss": 0.0036,
      "step": 10
    },
    {
      "epoch": 0.0005714285714285715,
      "grad_norm": 0.2729111611843109,
      "learning_rate": 4.9985714285714286e-05,
      "loss": 0.0051,
      "step": 20
    },
    {
      "epoch": 0.0008571428571428571,
      "grad_norm": 0.44081631302833557,
      "learning_rate": 4.997857142857143e-05,
      "loss": 0.0031,
      "step": 30
    },
    {
      "epoch": 0.001142857142857143,
      "grad_norm": 0.11503200978040695,
      "learning_rate": 4.9971428571428576e-05,
      "loss": 0.0024,
      "step": 40
    },
    {
      "epoch": 0.0014285714285714286,
      "grad_norm": 0.49212485551834106,
      "learning_rate": 4.996428571428572e-05,
      "loss": 0.0026,
      "step": 50
    },
    {
      "epoch": 0.0017142857142857142,
      "grad_norm": 0.5601756572723389,
      "learning_rate": 4.995714285714286e-05,
      "loss": 0.0035,
      "step": 60
    },
    {
      "epoch": 0.002,
      "grad_norm": 0.10799381136894226,
      "learning_rate": 4.995e-05,
      "loss": 0.0035,
      "step": 70
    },
    {
      "epoch": 0.002285714285714286,
      "grad_norm": 0.17547960579395294,
      "learning_rate": 4.994285714285715e-05,
      "loss": 0.0042,
      "step": 80
    },
    {
      "epoch": 0.0025714285714285713,
      "grad_norm": 0.25936540961265564,
      "learning_rate": 4.9935714285714285e-05,
      "loss": 0.0021,
      "step": 90
    },
    {
      "epoch": 0.002857142857142857,
      "grad_norm": 0.2653276026248932,
      "learning_rate": 4.992857142857143e-05,
      "loss": 0.0028,
      "step": 100
    },
    {
      "epoch": 0.003142857142857143,
      "grad_norm": 0.20962803065776825,
      "learning_rate": 4.9921428571428575e-05,
      "loss": 0.0031,
      "step": 110
    },
    {
      "epoch": 0.0034285714285714284,
      "grad_norm": 0.2809380888938904,
      "learning_rate": 4.9914285714285717e-05,
      "loss": 0.0016,
      "step": 120
    },
    {
      "epoch": 0.0037142857142857142,
      "grad_norm": 0.08974796533584595,
      "learning_rate": 4.990714285714286e-05,
      "loss": 0.0025,
      "step": 130
    },
    {
      "epoch": 0.004,
      "grad_norm": 0.13001742959022522,
      "learning_rate": 4.99e-05,
      "loss": 0.0018,
      "step": 140
    },
    {
      "epoch": 0.004285714285714286,
      "grad_norm": 0.2827798128128052,
      "learning_rate": 4.989285714285715e-05,
      "loss": 0.0033,
      "step": 150
    },
    {
      "epoch": 0.004571428571428572,
      "grad_norm": 0.08146125078201294,
      "learning_rate": 4.9885714285714283e-05,
      "loss": 0.0016,
      "step": 160
    },
    {
      "epoch": 0.004857142857142857,
      "grad_norm": 0.2233734428882599,
      "learning_rate": 4.987857142857143e-05,
      "loss": 0.0016,
      "step": 170
    },
    {
      "epoch": 0.005142857142857143,
      "grad_norm": 0.15637551248073578,
      "learning_rate": 4.9871428571428574e-05,
      "loss": 0.0025,
      "step": 180
    },
    {
      "epoch": 0.0054285714285714284,
      "grad_norm": 0.16520249843597412,
      "learning_rate": 4.986428571428572e-05,
      "loss": 0.0021,
      "step": 190
    },
    {
      "epoch": 0.005714285714285714,
      "grad_norm": 0.21186800301074982,
      "learning_rate": 4.985714285714286e-05,
      "loss": 0.0021,
      "step": 200
    },
    {
      "epoch": 0.006,
      "grad_norm": 0.4067218601703644,
      "learning_rate": 4.9850000000000006e-05,
      "loss": 0.0018,
      "step": 210
    },
    {
      "epoch": 0.006285714285714286,
      "grad_norm": 0.13644903898239136,
      "learning_rate": 4.984285714285715e-05,
      "loss": 0.0022,
      "step": 220
    },
    {
      "epoch": 0.006571428571428572,
      "grad_norm": 0.1996334344148636,
      "learning_rate": 4.983571428571429e-05,
      "loss": 0.0031,
      "step": 230
    },
    {
      "epoch": 0.006857142857142857,
      "grad_norm": 0.3241935074329376,
      "learning_rate": 4.982857142857143e-05,
      "loss": 0.0034,
      "step": 240
    },
    {
      "epoch": 0.007142857142857143,
      "grad_norm": 0.21539872884750366,
      "learning_rate": 4.982142857142857e-05,
      "loss": 0.0022,
      "step": 250
    },
    {
      "epoch": 0.0074285714285714285,
      "grad_norm": 0.18828821182250977,
      "learning_rate": 4.981428571428572e-05,
      "loss": 0.0023,
      "step": 260
    },
    {
      "epoch": 0.007714285714285714,
      "grad_norm": 0.2287067174911499,
      "learning_rate": 4.9807142857142856e-05,
      "loss": 0.0013,
      "step": 270
    },
    {
      "epoch": 0.008,
      "grad_norm": 0.15595902502536774,
      "learning_rate": 4.9800000000000004e-05,
      "loss": 0.0009,
      "step": 280
    },
    {
      "epoch": 0.008285714285714285,
      "grad_norm": 0.2337074726819992,
      "learning_rate": 4.9792857142857146e-05,
      "loss": 0.0034,
      "step": 290
    },
    {
      "epoch": 0.008571428571428572,
      "grad_norm": 0.21600869297981262,
      "learning_rate": 4.978571428571429e-05,
      "loss": 0.0016,
      "step": 300
    },
    {
      "epoch": 0.008857142857142857,
      "grad_norm": 0.0861327201128006,
      "learning_rate": 4.977857142857143e-05,
      "loss": 0.0014,
      "step": 310
    },
    {
      "epoch": 0.009142857142857144,
      "grad_norm": 0.15889303386211395,
      "learning_rate": 4.977142857142857e-05,
      "loss": 0.0024,
      "step": 320
    },
    {
      "epoch": 0.009428571428571429,
      "grad_norm": 0.29579004645347595,
      "learning_rate": 4.976428571428572e-05,
      "loss": 0.0021,
      "step": 330
    },
    {
      "epoch": 0.009714285714285713,
      "grad_norm": 0.13946783542633057,
      "learning_rate": 4.9757142857142855e-05,
      "loss": 0.0016,
      "step": 340
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.04741000756621361,
      "learning_rate": 4.975e-05,
      "loss": 0.0015,
      "step": 350
    },
    {
      "epoch": 0.010285714285714285,
      "grad_norm": 0.15125586092472076,
      "learning_rate": 4.9742857142857145e-05,
      "loss": 0.0017,
      "step": 360
    },
    {
      "epoch": 0.010571428571428572,
      "grad_norm": 0.1488247811794281,
      "learning_rate": 4.9735714285714287e-05,
      "loss": 0.0019,
      "step": 370
    },
    {
      "epoch": 0.010857142857142857,
      "grad_norm": 0.23023775219917297,
      "learning_rate": 4.972857142857143e-05,
      "loss": 0.0018,
      "step": 380
    },
    {
      "epoch": 0.011142857142857144,
      "grad_norm": 0.06555735319852829,
      "learning_rate": 4.972142857142858e-05,
      "loss": 0.0017,
      "step": 390
    },
    {
      "epoch": 0.011428571428571429,
      "grad_norm": 0.1717919111251831,
      "learning_rate": 4.971428571428572e-05,
      "loss": 0.002,
      "step": 400
    },
    {
      "epoch": 0.011714285714285714,
      "grad_norm": 0.1301734894514084,
      "learning_rate": 4.970714285714286e-05,
      "loss": 0.0026,
      "step": 410
    },
    {
      "epoch": 0.012,
      "grad_norm": 0.19242499768733978,
      "learning_rate": 4.97e-05,
      "loss": 0.0021,
      "step": 420
    },
    {
      "epoch": 0.012285714285714285,
      "grad_norm": 0.17570947110652924,
      "learning_rate": 4.9692857142857144e-05,
      "loss": 0.0015,
      "step": 430
    },
    {
      "epoch": 0.012571428571428572,
      "grad_norm": 0.21963340044021606,
      "learning_rate": 4.9685714285714285e-05,
      "loss": 0.0017,
      "step": 440
    },
    {
      "epoch": 0.012857142857142857,
      "grad_norm": 0.14060662686824799,
      "learning_rate": 4.967857142857143e-05,
      "loss": 0.0024,
      "step": 450
    },
    {
      "epoch": 0.013142857142857144,
      "grad_norm": 0.0636538490653038,
      "learning_rate": 4.9671428571428576e-05,
      "loss": 0.0018,
      "step": 460
    },
    {
      "epoch": 0.013428571428571429,
      "grad_norm": 0.04188661277294159,
      "learning_rate": 4.966428571428572e-05,
      "loss": 0.0015,
      "step": 470
    },
    {
      "epoch": 0.013714285714285714,
      "grad_norm": 0.09290523082017899,
      "learning_rate": 4.965714285714286e-05,
      "loss": 0.0027,
      "step": 480
    },
    {
      "epoch": 0.014,
      "grad_norm": 0.04076818376779556,
      "learning_rate": 4.965e-05,
      "loss": 0.0034,
      "step": 490
    },
    {
      "epoch": 0.014285714285714285,
      "grad_norm": 0.12949831783771515,
      "learning_rate": 4.964285714285715e-05,
      "loss": 0.0016,
      "step": 500
    },
    {
      "epoch": 0.014571428571428572,
      "grad_norm": 0.08930813521146774,
      "learning_rate": 4.9635714285714284e-05,
      "loss": 0.0012,
      "step": 510
    },
    {
      "epoch": 0.014857142857142857,
      "grad_norm": 0.0794719010591507,
      "learning_rate": 4.962857142857143e-05,
      "loss": 0.0003,
      "step": 520
    },
    {
      "epoch": 0.015142857142857144,
      "grad_norm": 0.19818322360515594,
      "learning_rate": 4.9621428571428574e-05,
      "loss": 0.0015,
      "step": 530
    },
    {
      "epoch": 0.015428571428571429,
      "grad_norm": 0.03628769889473915,
      "learning_rate": 4.9614285714285716e-05,
      "loss": 0.003,
      "step": 540
    },
    {
      "epoch": 0.015714285714285715,
      "grad_norm": 0.16402742266654968,
      "learning_rate": 4.960714285714286e-05,
      "loss": 0.0018,
      "step": 550
    },
    {
      "epoch": 0.016,
      "grad_norm": 0.021220462396740913,
      "learning_rate": 4.96e-05,
      "loss": 0.0019,
      "step": 560
    },
    {
      "epoch": 0.016285714285714285,
      "grad_norm": 0.17222921550273895,
      "learning_rate": 4.959285714285715e-05,
      "loss": 0.0023,
      "step": 570
    },
    {
      "epoch": 0.01657142857142857,
      "grad_norm": 0.14739848673343658,
      "learning_rate": 4.958571428571428e-05,
      "loss": 0.0022,
      "step": 580
    },
    {
      "epoch": 0.01685714285714286,
      "grad_norm": 0.05318509042263031,
      "learning_rate": 4.957857142857143e-05,
      "loss": 0.0024,
      "step": 590
    },
    {
      "epoch": 0.017142857142857144,
      "grad_norm": 0.11436120420694351,
      "learning_rate": 4.957142857142857e-05,
      "loss": 0.0028,
      "step": 600
    },
    {
      "epoch": 0.01742857142857143,
      "grad_norm": 0.1057240292429924,
      "learning_rate": 4.956428571428572e-05,
      "loss": 0.0015,
      "step": 610
    },
    {
      "epoch": 0.017714285714285714,
      "grad_norm": 0.2393341064453125,
      "learning_rate": 4.9557142857142857e-05,
      "loss": 0.0014,
      "step": 620
    },
    {
      "epoch": 0.018,
      "grad_norm": 0.3704698979854584,
      "learning_rate": 4.9550000000000005e-05,
      "loss": 0.0021,
      "step": 630
    },
    {
      "epoch": 0.018285714285714287,
      "grad_norm": 0.28725963830947876,
      "learning_rate": 4.954285714285715e-05,
      "loss": 0.0025,
      "step": 640
    },
    {
      "epoch": 0.018571428571428572,
      "grad_norm": 0.05566747486591339,
      "learning_rate": 4.953571428571429e-05,
      "loss": 0.0016,
      "step": 650
    },
    {
      "epoch": 0.018857142857142857,
      "grad_norm": 0.1126771941781044,
      "learning_rate": 4.952857142857143e-05,
      "loss": 0.0026,
      "step": 660
    },
    {
      "epoch": 0.019142857142857142,
      "grad_norm": 0.2474333941936493,
      "learning_rate": 4.952142857142857e-05,
      "loss": 0.0018,
      "step": 670
    },
    {
      "epoch": 0.019428571428571427,
      "grad_norm": 0.16951999068260193,
      "learning_rate": 4.951428571428572e-05,
      "loss": 0.0028,
      "step": 680
    },
    {
      "epoch": 0.019714285714285715,
      "grad_norm": 0.0,
      "learning_rate": 4.9507142857142855e-05,
      "loss": 0.0012,
      "step": 690
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.04581198841333389,
      "learning_rate": 4.9500000000000004e-05,
      "loss": 0.0019,
      "step": 700
    },
    {
      "epoch": 0.020285714285714285,
      "grad_norm": 0.14717057347297668,
      "learning_rate": 4.9492857142857146e-05,
      "loss": 0.0018,
      "step": 710
    },
    {
      "epoch": 0.02057142857142857,
      "grad_norm": 0.1331370770931244,
      "learning_rate": 4.9485714285714294e-05,
      "loss": 0.0004,
      "step": 720
    },
    {
      "epoch": 0.02085714285714286,
      "grad_norm": 0.16268450021743774,
      "learning_rate": 4.947857142857143e-05,
      "loss": 0.0016,
      "step": 730
    },
    {
      "epoch": 0.021142857142857144,
      "grad_norm": 0.3520859479904175,
      "learning_rate": 4.947142857142858e-05,
      "loss": 0.0025,
      "step": 740
    },
    {
      "epoch": 0.02142857142857143,
      "grad_norm": 0.13030898571014404,
      "learning_rate": 4.946428571428572e-05,
      "loss": 0.0025,
      "step": 750
    },
    {
      "epoch": 0.021714285714285714,
      "grad_norm": 0.045181721448898315,
      "learning_rate": 4.9457142857142854e-05,
      "loss": 0.0017,
      "step": 760
    },
    {
      "epoch": 0.022,
      "grad_norm": 0.09762449562549591,
      "learning_rate": 4.945e-05,
      "loss": 0.0013,
      "step": 770
    },
    {
      "epoch": 0.022285714285714287,
      "grad_norm": 0.05002830922603607,
      "learning_rate": 4.9442857142857144e-05,
      "loss": 0.0016,
      "step": 780
    },
    {
      "epoch": 0.022571428571428572,
      "grad_norm": 0.06928834319114685,
      "learning_rate": 4.943571428571429e-05,
      "loss": 0.0016,
      "step": 790
    },
    {
      "epoch": 0.022857142857142857,
      "grad_norm": 0.08357017487287521,
      "learning_rate": 4.942857142857143e-05,
      "loss": 0.0013,
      "step": 800
    },
    {
      "epoch": 0.023142857142857142,
      "grad_norm": 0.23210583627223969,
      "learning_rate": 4.9421428571428576e-05,
      "loss": 0.0026,
      "step": 810
    },
    {
      "epoch": 0.023428571428571427,
      "grad_norm": 0.21109868586063385,
      "learning_rate": 4.941428571428572e-05,
      "loss": 0.0008,
      "step": 820
    },
    {
      "epoch": 0.023714285714285716,
      "grad_norm": 0.08902180194854736,
      "learning_rate": 4.940714285714286e-05,
      "loss": 0.0023,
      "step": 830
    },
    {
      "epoch": 0.024,
      "grad_norm": 0.27642640471458435,
      "learning_rate": 4.94e-05,
      "loss": 0.0015,
      "step": 840
    },
    {
      "epoch": 0.024285714285714285,
      "grad_norm": 0.2598554193973541,
      "learning_rate": 4.939285714285714e-05,
      "loss": 0.0019,
      "step": 850
    },
    {
      "epoch": 0.02457142857142857,
      "grad_norm": 0.05681397393345833,
      "learning_rate": 4.938571428571429e-05,
      "loss": 0.0017,
      "step": 860
    },
    {
      "epoch": 0.024857142857142855,
      "grad_norm": 0.0943637490272522,
      "learning_rate": 4.9378571428571427e-05,
      "loss": 0.002,
      "step": 870
    },
    {
      "epoch": 0.025142857142857144,
      "grad_norm": 0.11663030087947845,
      "learning_rate": 4.9371428571428575e-05,
      "loss": 0.0017,
      "step": 880
    },
    {
      "epoch": 0.02542857142857143,
      "grad_norm": 0.0491911880671978,
      "learning_rate": 4.936428571428572e-05,
      "loss": 0.0018,
      "step": 890
    },
    {
      "epoch": 0.025714285714285714,
      "grad_norm": 0.15466608107089996,
      "learning_rate": 4.935714285714286e-05,
      "loss": 0.003,
      "step": 900
    },
    {
      "epoch": 0.026,
      "grad_norm": 0.17601054906845093,
      "learning_rate": 4.935e-05,
      "loss": 0.002,
      "step": 910
    },
    {
      "epoch": 0.026285714285714287,
      "grad_norm": 0.11529096961021423,
      "learning_rate": 4.934285714285715e-05,
      "loss": 0.0028,
      "step": 920
    },
    {
      "epoch": 0.026571428571428572,
      "grad_norm": 0.07762787491083145,
      "learning_rate": 4.933571428571429e-05,
      "loss": 0.0017,
      "step": 930
    },
    {
      "epoch": 0.026857142857142857,
      "grad_norm": 0.13285240530967712,
      "learning_rate": 4.932857142857143e-05,
      "loss": 0.0031,
      "step": 940
    },
    {
      "epoch": 0.027142857142857142,
      "grad_norm": 0.3180777132511139,
      "learning_rate": 4.9321428571428574e-05,
      "loss": 0.0035,
      "step": 950
    },
    {
      "epoch": 0.027428571428571427,
      "grad_norm": 0.15110723674297333,
      "learning_rate": 4.9314285714285716e-05,
      "loss": 0.0033,
      "step": 960
    },
    {
      "epoch": 0.027714285714285716,
      "grad_norm": 0.27393606305122375,
      "learning_rate": 4.930714285714286e-05,
      "loss": 0.0025,
      "step": 970
    },
    {
      "epoch": 0.028,
      "grad_norm": 0.21264000236988068,
      "learning_rate": 4.93e-05,
      "loss": 0.0031,
      "step": 980
    },
    {
      "epoch": 0.028285714285714286,
      "grad_norm": 0.05150899291038513,
      "learning_rate": 4.929285714285715e-05,
      "loss": 0.0017,
      "step": 990
    },
    {
      "epoch": 0.02857142857142857,
      "grad_norm": 0.21002066135406494,
      "learning_rate": 4.928571428571429e-05,
      "loss": 0.0016,
      "step": 1000
    },
    {
      "epoch": 0.028857142857142856,
      "grad_norm": 0.11604870110750198,
      "learning_rate": 4.927857142857143e-05,
      "loss": 0.0011,
      "step": 1010
    },
    {
      "epoch": 0.029142857142857144,
      "grad_norm": 0.25663891434669495,
      "learning_rate": 4.927142857142857e-05,
      "loss": 0.0017,
      "step": 1020
    },
    {
      "epoch": 0.02942857142857143,
      "grad_norm": 0.048702090978622437,
      "learning_rate": 4.926428571428572e-05,
      "loss": 0.0011,
      "step": 1030
    },
    {
      "epoch": 0.029714285714285714,
      "grad_norm": 0.1895003616809845,
      "learning_rate": 4.9257142857142856e-05,
      "loss": 0.003,
      "step": 1040
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.23259605467319489,
      "learning_rate": 4.9250000000000004e-05,
      "loss": 0.0008,
      "step": 1050
    },
    {
      "epoch": 0.030285714285714287,
      "grad_norm": 0.047182656824588776,
      "learning_rate": 4.9242857142857146e-05,
      "loss": 0.0011,
      "step": 1060
    },
    {
      "epoch": 0.030571428571428572,
      "grad_norm": 0.128143772482872,
      "learning_rate": 4.923571428571429e-05,
      "loss": 0.0011,
      "step": 1070
    },
    {
      "epoch": 0.030857142857142857,
      "grad_norm": 0.24440662562847137,
      "learning_rate": 4.922857142857143e-05,
      "loss": 0.0021,
      "step": 1080
    },
    {
      "epoch": 0.031142857142857142,
      "grad_norm": 0.23463666439056396,
      "learning_rate": 4.922142857142857e-05,
      "loss": 0.0018,
      "step": 1090
    },
    {
      "epoch": 0.03142857142857143,
      "grad_norm": 0.12258441746234894,
      "learning_rate": 4.921428571428572e-05,
      "loss": 0.0025,
      "step": 1100
    },
    {
      "epoch": 0.031714285714285716,
      "grad_norm": 0.16441583633422852,
      "learning_rate": 4.9207142857142855e-05,
      "loss": 0.0012,
      "step": 1110
    },
    {
      "epoch": 0.032,
      "grad_norm": 0.16214674711227417,
      "learning_rate": 4.92e-05,
      "loss": 0.0023,
      "step": 1120
    },
    {
      "epoch": 0.032285714285714286,
      "grad_norm": 0.19171620905399323,
      "learning_rate": 4.9192857142857145e-05,
      "loss": 0.003,
      "step": 1130
    },
    {
      "epoch": 0.03257142857142857,
      "grad_norm": 0.21841351687908173,
      "learning_rate": 4.9185714285714293e-05,
      "loss": 0.0023,
      "step": 1140
    },
    {
      "epoch": 0.032857142857142856,
      "grad_norm": 0.18011300265789032,
      "learning_rate": 4.917857142857143e-05,
      "loss": 0.0027,
      "step": 1150
    },
    {
      "epoch": 0.03314285714285714,
      "grad_norm": 0.11016420274972916,
      "learning_rate": 4.917142857142858e-05,
      "loss": 0.0021,
      "step": 1160
    },
    {
      "epoch": 0.033428571428571426,
      "grad_norm": 0.1776372343301773,
      "learning_rate": 4.916428571428572e-05,
      "loss": 0.0018,
      "step": 1170
    },
    {
      "epoch": 0.03371428571428572,
      "grad_norm": 0.20695438981056213,
      "learning_rate": 4.915714285714286e-05,
      "loss": 0.0025,
      "step": 1180
    },
    {
      "epoch": 0.034,
      "grad_norm": 0.13209669291973114,
      "learning_rate": 4.915e-05,
      "loss": 0.0014,
      "step": 1190
    },
    {
      "epoch": 0.03428571428571429,
      "grad_norm": 0.08127734810113907,
      "learning_rate": 4.9142857142857144e-05,
      "loss": 0.0016,
      "step": 1200
    },
    {
      "epoch": 0.03457142857142857,
      "grad_norm": 0.08631488680839539,
      "learning_rate": 4.913571428571429e-05,
      "loss": 0.0023,
      "step": 1210
    },
    {
      "epoch": 0.03485714285714286,
      "grad_norm": 0.08608827739953995,
      "learning_rate": 4.912857142857143e-05,
      "loss": 0.0011,
      "step": 1220
    },
    {
      "epoch": 0.03514285714285714,
      "grad_norm": 0.04442230239510536,
      "learning_rate": 4.9121428571428576e-05,
      "loss": 0.0015,
      "step": 1230
    },
    {
      "epoch": 0.03542857142857143,
      "grad_norm": 0.0,
      "learning_rate": 4.911428571428572e-05,
      "loss": 0.0017,
      "step": 1240
    },
    {
      "epoch": 0.03571428571428571,
      "grad_norm": 0.167751282453537,
      "learning_rate": 4.910714285714286e-05,
      "loss": 0.0012,
      "step": 1250
    },
    {
      "epoch": 0.036,
      "grad_norm": 0.1514350175857544,
      "learning_rate": 4.91e-05,
      "loss": 0.0019,
      "step": 1260
    },
    {
      "epoch": 0.03628571428571428,
      "grad_norm": 0.09183409810066223,
      "learning_rate": 4.909285714285715e-05,
      "loss": 0.0018,
      "step": 1270
    },
    {
      "epoch": 0.036571428571428574,
      "grad_norm": 0.044888272881507874,
      "learning_rate": 4.908571428571429e-05,
      "loss": 0.0008,
      "step": 1280
    },
    {
      "epoch": 0.03685714285714286,
      "grad_norm": 0.09378746151924133,
      "learning_rate": 4.9078571428571426e-05,
      "loss": 0.0037,
      "step": 1290
    },
    {
      "epoch": 0.037142857142857144,
      "grad_norm": 0.13082776963710785,
      "learning_rate": 4.9071428571428574e-05,
      "loss": 0.0014,
      "step": 1300
    },
    {
      "epoch": 0.03742857142857143,
      "grad_norm": 0.022859107702970505,
      "learning_rate": 4.9064285714285716e-05,
      "loss": 0.001,
      "step": 1310
    },
    {
      "epoch": 0.037714285714285714,
      "grad_norm": 0.20945316553115845,
      "learning_rate": 4.905714285714286e-05,
      "loss": 0.0026,
      "step": 1320
    },
    {
      "epoch": 0.038,
      "grad_norm": 0.15255548059940338,
      "learning_rate": 4.905e-05,
      "loss": 0.0018,
      "step": 1330
    },
    {
      "epoch": 0.038285714285714284,
      "grad_norm": 0.16254396736621857,
      "learning_rate": 4.904285714285715e-05,
      "loss": 0.0012,
      "step": 1340
    },
    {
      "epoch": 0.03857142857142857,
      "grad_norm": 0.043874986469745636,
      "learning_rate": 4.903571428571429e-05,
      "loss": 0.0016,
      "step": 1350
    },
    {
      "epoch": 0.038857142857142854,
      "grad_norm": 0.18611370027065277,
      "learning_rate": 4.902857142857143e-05,
      "loss": 0.0013,
      "step": 1360
    },
    {
      "epoch": 0.039142857142857146,
      "grad_norm": 0.21949335932731628,
      "learning_rate": 4.902142857142857e-05,
      "loss": 0.0015,
      "step": 1370
    },
    {
      "epoch": 0.03942857142857143,
      "grad_norm": 0.16053040325641632,
      "learning_rate": 4.9014285714285715e-05,
      "loss": 0.0015,
      "step": 1380
    },
    {
      "epoch": 0.039714285714285716,
      "grad_norm": 0.08828166127204895,
      "learning_rate": 4.900714285714286e-05,
      "loss": 0.0026,
      "step": 1390
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.11339032649993896,
      "learning_rate": 4.9e-05,
      "loss": 0.001,
      "step": 1400
    },
    {
      "epoch": 0.040285714285714286,
      "grad_norm": 0.045313604176044464,
      "learning_rate": 4.899285714285715e-05,
      "loss": 0.0028,
      "step": 1410
    },
    {
      "epoch": 0.04057142857142857,
      "grad_norm": 0.05471796914935112,
      "learning_rate": 4.898571428571429e-05,
      "loss": 0.0021,
      "step": 1420
    },
    {
      "epoch": 0.040857142857142856,
      "grad_norm": 0.12181860953569412,
      "learning_rate": 4.897857142857143e-05,
      "loss": 0.0021,
      "step": 1430
    },
    {
      "epoch": 0.04114285714285714,
      "grad_norm": 0.07648034393787384,
      "learning_rate": 4.897142857142857e-05,
      "loss": 0.0014,
      "step": 1440
    },
    {
      "epoch": 0.041428571428571426,
      "grad_norm": 0.026868151500821114,
      "learning_rate": 4.896428571428572e-05,
      "loss": 0.0013,
      "step": 1450
    },
    {
      "epoch": 0.04171428571428572,
      "grad_norm": 0.1754988133907318,
      "learning_rate": 4.8957142857142855e-05,
      "loss": 0.0021,
      "step": 1460
    },
    {
      "epoch": 0.042,
      "grad_norm": 0.08842118084430695,
      "learning_rate": 4.8950000000000004e-05,
      "loss": 0.0028,
      "step": 1470
    },
    {
      "epoch": 0.04228571428571429,
      "grad_norm": 0.056667860597372055,
      "learning_rate": 4.8942857142857146e-05,
      "loss": 0.0018,
      "step": 1480
    },
    {
      "epoch": 0.04257142857142857,
      "grad_norm": 0.05324999615550041,
      "learning_rate": 4.893571428571429e-05,
      "loss": 0.0016,
      "step": 1490
    },
    {
      "epoch": 0.04285714285714286,
      "grad_norm": 0.12693840265274048,
      "learning_rate": 4.892857142857143e-05,
      "loss": 0.0022,
      "step": 1500
    },
    {
      "epoch": 0.04314285714285714,
      "grad_norm": 0.18508997559547424,
      "learning_rate": 4.892142857142857e-05,
      "loss": 0.002,
      "step": 1510
    },
    {
      "epoch": 0.04342857142857143,
      "grad_norm": 0.07841238379478455,
      "learning_rate": 4.891428571428572e-05,
      "loss": 0.0022,
      "step": 1520
    },
    {
      "epoch": 0.04371428571428571,
      "grad_norm": 0.19184476137161255,
      "learning_rate": 4.8907142857142854e-05,
      "loss": 0.002,
      "step": 1530
    },
    {
      "epoch": 0.044,
      "grad_norm": 0.17600293457508087,
      "learning_rate": 4.89e-05,
      "loss": 0.0012,
      "step": 1540
    },
    {
      "epoch": 0.04428571428571428,
      "grad_norm": 0.042593520134687424,
      "learning_rate": 4.8892857142857144e-05,
      "loss": 0.0011,
      "step": 1550
    },
    {
      "epoch": 0.044571428571428574,
      "grad_norm": 0.06359272450208664,
      "learning_rate": 4.888571428571429e-05,
      "loss": 0.0033,
      "step": 1560
    },
    {
      "epoch": 0.04485714285714286,
      "grad_norm": 0.14826065301895142,
      "learning_rate": 4.887857142857143e-05,
      "loss": 0.003,
      "step": 1570
    },
    {
      "epoch": 0.045142857142857144,
      "grad_norm": 0.14611802995204926,
      "learning_rate": 4.8871428571428576e-05,
      "loss": 0.0025,
      "step": 1580
    },
    {
      "epoch": 0.04542857142857143,
      "grad_norm": 0.2563432455062866,
      "learning_rate": 4.886428571428572e-05,
      "loss": 0.002,
      "step": 1590
    },
    {
      "epoch": 0.045714285714285714,
      "grad_norm": 0.03351444751024246,
      "learning_rate": 4.885714285714286e-05,
      "loss": 0.0015,
      "step": 1600
    },
    {
      "epoch": 0.046,
      "grad_norm": 0.1856190413236618,
      "learning_rate": 4.885e-05,
      "loss": 0.0016,
      "step": 1610
    },
    {
      "epoch": 0.046285714285714284,
      "grad_norm": 0.05267919972538948,
      "learning_rate": 4.884285714285714e-05,
      "loss": 0.0011,
      "step": 1620
    },
    {
      "epoch": 0.04657142857142857,
      "grad_norm": 0.19219696521759033,
      "learning_rate": 4.883571428571429e-05,
      "loss": 0.0019,
      "step": 1630
    },
    {
      "epoch": 0.046857142857142854,
      "grad_norm": 0.18666988611221313,
      "learning_rate": 4.882857142857143e-05,
      "loss": 0.0025,
      "step": 1640
    },
    {
      "epoch": 0.047142857142857146,
      "grad_norm": 0.11717962473630905,
      "learning_rate": 4.8821428571428575e-05,
      "loss": 0.001,
      "step": 1650
    },
    {
      "epoch": 0.04742857142857143,
      "grad_norm": 0.029411980882287025,
      "learning_rate": 4.881428571428572e-05,
      "loss": 0.0016,
      "step": 1660
    },
    {
      "epoch": 0.047714285714285716,
      "grad_norm": 0.050543975085020065,
      "learning_rate": 4.880714285714286e-05,
      "loss": 0.0009,
      "step": 1670
    },
    {
      "epoch": 0.048,
      "grad_norm": 0.25576576590538025,
      "learning_rate": 4.88e-05,
      "loss": 0.0018,
      "step": 1680
    },
    {
      "epoch": 0.048285714285714286,
      "grad_norm": 0.058496247977018356,
      "learning_rate": 4.879285714285715e-05,
      "loss": 0.0019,
      "step": 1690
    },
    {
      "epoch": 0.04857142857142857,
      "grad_norm": 0.09549375623464584,
      "learning_rate": 4.878571428571429e-05,
      "loss": 0.0018,
      "step": 1700
    },
    {
      "epoch": 0.048857142857142856,
      "grad_norm": 0.04675159603357315,
      "learning_rate": 4.877857142857143e-05,
      "loss": 0.0032,
      "step": 1710
    },
    {
      "epoch": 0.04914285714285714,
      "grad_norm": 0.14982256293296814,
      "learning_rate": 4.8771428571428574e-05,
      "loss": 0.0016,
      "step": 1720
    },
    {
      "epoch": 0.049428571428571426,
      "grad_norm": 0.15089674293994904,
      "learning_rate": 4.8764285714285716e-05,
      "loss": 0.0015,
      "step": 1730
    },
    {
      "epoch": 0.04971428571428571,
      "grad_norm": 0.0,
      "learning_rate": 4.875714285714286e-05,
      "loss": 0.0023,
      "step": 1740
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.2083793580532074,
      "learning_rate": 4.875e-05,
      "loss": 0.0012,
      "step": 1750
    },
    {
      "epoch": 0.05028571428571429,
      "grad_norm": 0.26681140065193176,
      "learning_rate": 4.874285714285715e-05,
      "loss": 0.0022,
      "step": 1760
    },
    {
      "epoch": 0.05057142857142857,
      "grad_norm": 0.08210361748933792,
      "learning_rate": 4.873571428571429e-05,
      "loss": 0.0021,
      "step": 1770
    },
    {
      "epoch": 0.05085714285714286,
      "grad_norm": 0.1445501297712326,
      "learning_rate": 4.872857142857143e-05,
      "loss": 0.0018,
      "step": 1780
    },
    {
      "epoch": 0.05114285714285714,
      "grad_norm": 0.2082367241382599,
      "learning_rate": 4.872142857142857e-05,
      "loss": 0.003,
      "step": 1790
    },
    {
      "epoch": 0.05142857142857143,
      "grad_norm": 0.1260918378829956,
      "learning_rate": 4.8714285714285714e-05,
      "loss": 0.0013,
      "step": 1800
    },
    {
      "epoch": 0.05171428571428571,
      "grad_norm": 0.0,
      "learning_rate": 4.8707142857142856e-05,
      "loss": 0.0019,
      "step": 1810
    },
    {
      "epoch": 0.052,
      "grad_norm": 0.08462192863225937,
      "learning_rate": 4.87e-05,
      "loss": 0.0027,
      "step": 1820
    },
    {
      "epoch": 0.05228571428571428,
      "grad_norm": 0.21663400530815125,
      "learning_rate": 4.8692857142857146e-05,
      "loss": 0.0018,
      "step": 1830
    },
    {
      "epoch": 0.052571428571428575,
      "grad_norm": 0.12664756178855896,
      "learning_rate": 4.868571428571429e-05,
      "loss": 0.0014,
      "step": 1840
    },
    {
      "epoch": 0.05285714285714286,
      "grad_norm": 0.0465974397957325,
      "learning_rate": 4.867857142857143e-05,
      "loss": 0.0019,
      "step": 1850
    },
    {
      "epoch": 0.053142857142857144,
      "grad_norm": 0.11675550788640976,
      "learning_rate": 4.867142857142857e-05,
      "loss": 0.0027,
      "step": 1860
    },
    {
      "epoch": 0.05342857142857143,
      "grad_norm": 0.046232037246227264,
      "learning_rate": 4.866428571428572e-05,
      "loss": 0.0024,
      "step": 1870
    },
    {
      "epoch": 0.053714285714285714,
      "grad_norm": 0.2795998752117157,
      "learning_rate": 4.865714285714286e-05,
      "loss": 0.0015,
      "step": 1880
    },
    {
      "epoch": 0.054,
      "grad_norm": 0.21802552044391632,
      "learning_rate": 4.8650000000000003e-05,
      "loss": 0.0032,
      "step": 1890
    },
    {
      "epoch": 0.054285714285714284,
      "grad_norm": 0.2141382098197937,
      "learning_rate": 4.8642857142857145e-05,
      "loss": 0.0013,
      "step": 1900
    },
    {
      "epoch": 0.05457142857142857,
      "grad_norm": 0.12233882397413254,
      "learning_rate": 4.863571428571429e-05,
      "loss": 0.0009,
      "step": 1910
    },
    {
      "epoch": 0.054857142857142854,
      "grad_norm": 0.12356115132570267,
      "learning_rate": 4.862857142857143e-05,
      "loss": 0.0017,
      "step": 1920
    },
    {
      "epoch": 0.055142857142857146,
      "grad_norm": 0.2000482678413391,
      "learning_rate": 4.862142857142857e-05,
      "loss": 0.0014,
      "step": 1930
    },
    {
      "epoch": 0.05542857142857143,
      "grad_norm": 0.09167056530714035,
      "learning_rate": 4.861428571428572e-05,
      "loss": 0.0012,
      "step": 1940
    },
    {
      "epoch": 0.055714285714285716,
      "grad_norm": 0.08763916790485382,
      "learning_rate": 4.860714285714286e-05,
      "loss": 0.0006,
      "step": 1950
    },
    {
      "epoch": 0.056,
      "grad_norm": 0.09285308420658112,
      "learning_rate": 4.86e-05,
      "loss": 0.0018,
      "step": 1960
    },
    {
      "epoch": 0.056285714285714286,
      "grad_norm": 0.155623197555542,
      "learning_rate": 4.8592857142857144e-05,
      "loss": 0.002,
      "step": 1970
    },
    {
      "epoch": 0.05657142857142857,
      "grad_norm": 0.026415131986141205,
      "learning_rate": 4.858571428571429e-05,
      "loss": 0.0028,
      "step": 1980
    },
    {
      "epoch": 0.056857142857142856,
      "grad_norm": 0.23918958008289337,
      "learning_rate": 4.857857142857143e-05,
      "loss": 0.0021,
      "step": 1990
    },
    {
      "epoch": 0.05714285714285714,
      "grad_norm": 0.09524621069431305,
      "learning_rate": 4.8571428571428576e-05,
      "loss": 0.0026,
      "step": 2000
    },
    {
      "epoch": 0.057428571428571426,
      "grad_norm": 0.044206712394952774,
      "learning_rate": 4.856428571428572e-05,
      "loss": 0.0012,
      "step": 2010
    },
    {
      "epoch": 0.05771428571428571,
      "grad_norm": 0.06690099835395813,
      "learning_rate": 4.855714285714286e-05,
      "loss": 0.0011,
      "step": 2020
    },
    {
      "epoch": 0.058,
      "grad_norm": 0.17975862324237823,
      "learning_rate": 4.855e-05,
      "loss": 0.0018,
      "step": 2030
    },
    {
      "epoch": 0.05828571428571429,
      "grad_norm": 0.043523937463760376,
      "learning_rate": 4.854285714285714e-05,
      "loss": 0.0023,
      "step": 2040
    },
    {
      "epoch": 0.05857142857142857,
      "grad_norm": 0.08478832244873047,
      "learning_rate": 4.853571428571429e-05,
      "loss": 0.0026,
      "step": 2050
    },
    {
      "epoch": 0.05885714285714286,
      "grad_norm": 0.0,
      "learning_rate": 4.8528571428571426e-05,
      "loss": 0.0017,
      "step": 2060
    },
    {
      "epoch": 0.05914285714285714,
      "grad_norm": 0.09287992119789124,
      "learning_rate": 4.8521428571428575e-05,
      "loss": 0.0013,
      "step": 2070
    },
    {
      "epoch": 0.05942857142857143,
      "grad_norm": 0.1918850839138031,
      "learning_rate": 4.8514285714285716e-05,
      "loss": 0.0022,
      "step": 2080
    },
    {
      "epoch": 0.05971428571428571,
      "grad_norm": 0.04400726780295372,
      "learning_rate": 4.8507142857142865e-05,
      "loss": 0.0013,
      "step": 2090
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.32388922572135925,
      "learning_rate": 4.85e-05,
      "loss": 0.0021,
      "step": 2100
    },
    {
      "epoch": 0.06028571428571428,
      "grad_norm": 0.09054569154977798,
      "learning_rate": 4.849285714285715e-05,
      "loss": 0.002,
      "step": 2110
    },
    {
      "epoch": 0.060571428571428575,
      "grad_norm": 0.06580206006765366,
      "learning_rate": 4.848571428571429e-05,
      "loss": 0.0019,
      "step": 2120
    },
    {
      "epoch": 0.06085714285714286,
      "grad_norm": 0.19587869942188263,
      "learning_rate": 4.847857142857143e-05,
      "loss": 0.0023,
      "step": 2130
    },
    {
      "epoch": 0.061142857142857145,
      "grad_norm": 0.04485241696238518,
      "learning_rate": 4.8471428571428573e-05,
      "loss": 0.0014,
      "step": 2140
    },
    {
      "epoch": 0.06142857142857143,
      "grad_norm": 0.0488545186817646,
      "learning_rate": 4.8464285714285715e-05,
      "loss": 0.0027,
      "step": 2150
    },
    {
      "epoch": 0.061714285714285715,
      "grad_norm": 0.10117383301258087,
      "learning_rate": 4.8457142857142864e-05,
      "loss": 0.0011,
      "step": 2160
    },
    {
      "epoch": 0.062,
      "grad_norm": 0.24387824535369873,
      "learning_rate": 4.845e-05,
      "loss": 0.0015,
      "step": 2170
    },
    {
      "epoch": 0.062285714285714285,
      "grad_norm": 0.0,
      "learning_rate": 4.844285714285715e-05,
      "loss": 0.0034,
      "step": 2180
    },
    {
      "epoch": 0.06257142857142857,
      "grad_norm": 0.1193690299987793,
      "learning_rate": 4.843571428571429e-05,
      "loss": 0.0022,
      "step": 2190
    },
    {
      "epoch": 0.06285714285714286,
      "grad_norm": 0.04559260979294777,
      "learning_rate": 4.842857142857143e-05,
      "loss": 0.0021,
      "step": 2200
    },
    {
      "epoch": 0.06314285714285714,
      "grad_norm": 0.14394019544124603,
      "learning_rate": 4.842142857142857e-05,
      "loss": 0.0015,
      "step": 2210
    },
    {
      "epoch": 0.06342857142857143,
      "grad_norm": 0.08725965023040771,
      "learning_rate": 4.841428571428572e-05,
      "loss": 0.0019,
      "step": 2220
    },
    {
      "epoch": 0.06371428571428571,
      "grad_norm": 0.03640437871217728,
      "learning_rate": 4.840714285714286e-05,
      "loss": 0.0006,
      "step": 2230
    },
    {
      "epoch": 0.064,
      "grad_norm": 0.16459500789642334,
      "learning_rate": 4.8400000000000004e-05,
      "loss": 0.0041,
      "step": 2240
    },
    {
      "epoch": 0.06428571428571428,
      "grad_norm": 0.14659355580806732,
      "learning_rate": 4.8392857142857146e-05,
      "loss": 0.0031,
      "step": 2250
    },
    {
      "epoch": 0.06457142857142857,
      "grad_norm": 0.03771061450242996,
      "learning_rate": 4.838571428571429e-05,
      "loss": 0.0018,
      "step": 2260
    },
    {
      "epoch": 0.06485714285714286,
      "grad_norm": 0.3026392459869385,
      "learning_rate": 4.837857142857143e-05,
      "loss": 0.0017,
      "step": 2270
    },
    {
      "epoch": 0.06514285714285714,
      "grad_norm": 0.14105230569839478,
      "learning_rate": 4.837142857142857e-05,
      "loss": 0.0011,
      "step": 2280
    },
    {
      "epoch": 0.06542857142857143,
      "grad_norm": 0.03495199233293533,
      "learning_rate": 4.836428571428572e-05,
      "loss": 0.0019,
      "step": 2290
    },
    {
      "epoch": 0.06571428571428571,
      "grad_norm": 0.15488995611667633,
      "learning_rate": 4.835714285714286e-05,
      "loss": 0.0017,
      "step": 2300
    },
    {
      "epoch": 0.066,
      "grad_norm": 0.11546871811151505,
      "learning_rate": 4.835e-05,
      "loss": 0.002,
      "step": 2310
    },
    {
      "epoch": 0.06628571428571428,
      "grad_norm": 0.05854656547307968,
      "learning_rate": 4.8342857142857145e-05,
      "loss": 0.0026,
      "step": 2320
    },
    {
      "epoch": 0.06657142857142857,
      "grad_norm": 0.04182027652859688,
      "learning_rate": 4.8335714285714286e-05,
      "loss": 0.001,
      "step": 2330
    },
    {
      "epoch": 0.06685714285714285,
      "grad_norm": 0.18357424437999725,
      "learning_rate": 4.832857142857143e-05,
      "loss": 0.0016,
      "step": 2340
    },
    {
      "epoch": 0.06714285714285714,
      "grad_norm": 0.1310964822769165,
      "learning_rate": 4.832142857142857e-05,
      "loss": 0.001,
      "step": 2350
    },
    {
      "epoch": 0.06742857142857143,
      "grad_norm": 0.04660266637802124,
      "learning_rate": 4.831428571428572e-05,
      "loss": 0.0011,
      "step": 2360
    },
    {
      "epoch": 0.06771428571428571,
      "grad_norm": 0.09214048087596893,
      "learning_rate": 4.830714285714286e-05,
      "loss": 0.0018,
      "step": 2370
    },
    {
      "epoch": 0.068,
      "grad_norm": 0.0,
      "learning_rate": 4.83e-05,
      "loss": 0.0012,
      "step": 2380
    },
    {
      "epoch": 0.06828571428571428,
      "grad_norm": 0.06592899560928345,
      "learning_rate": 4.8292857142857143e-05,
      "loss": 0.0029,
      "step": 2390
    },
    {
      "epoch": 0.06857142857142857,
      "grad_norm": 0.23325024545192719,
      "learning_rate": 4.828571428571429e-05,
      "loss": 0.0012,
      "step": 2400
    },
    {
      "epoch": 0.06885714285714285,
      "grad_norm": 0.20343637466430664,
      "learning_rate": 4.827857142857143e-05,
      "loss": 0.0008,
      "step": 2410
    },
    {
      "epoch": 0.06914285714285714,
      "grad_norm": 0.0,
      "learning_rate": 4.8271428571428575e-05,
      "loss": 0.0012,
      "step": 2420
    },
    {
      "epoch": 0.06942857142857142,
      "grad_norm": 0.07295846194028854,
      "learning_rate": 4.826428571428572e-05,
      "loss": 0.0014,
      "step": 2430
    },
    {
      "epoch": 0.06971428571428571,
      "grad_norm": 0.2013038694858551,
      "learning_rate": 4.825714285714286e-05,
      "loss": 0.0024,
      "step": 2440
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.08180548250675201,
      "learning_rate": 4.825e-05,
      "loss": 0.0025,
      "step": 2450
    },
    {
      "epoch": 0.07028571428571428,
      "grad_norm": 0.20450156927108765,
      "learning_rate": 4.824285714285714e-05,
      "loss": 0.002,
      "step": 2460
    },
    {
      "epoch": 0.07057142857142858,
      "grad_norm": 0.0,
      "learning_rate": 4.823571428571429e-05,
      "loss": 0.0011,
      "step": 2470
    },
    {
      "epoch": 0.07085714285714285,
      "grad_norm": 0.2626681625843048,
      "learning_rate": 4.8228571428571426e-05,
      "loss": 0.0016,
      "step": 2480
    },
    {
      "epoch": 0.07114285714285715,
      "grad_norm": 0.057547204196453094,
      "learning_rate": 4.8221428571428574e-05,
      "loss": 0.0015,
      "step": 2490
    },
    {
      "epoch": 0.07142857142857142,
      "grad_norm": 0.0,
      "learning_rate": 4.8214285714285716e-05,
      "loss": 0.0013,
      "step": 2500
    },
    {
      "epoch": 0.07171428571428572,
      "grad_norm": 0.14449003338813782,
      "learning_rate": 4.8207142857142864e-05,
      "loss": 0.0011,
      "step": 2510
    },
    {
      "epoch": 0.072,
      "grad_norm": 0.054030466824769974,
      "learning_rate": 4.82e-05,
      "loss": 0.0021,
      "step": 2520
    },
    {
      "epoch": 0.07228571428571429,
      "grad_norm": 0.06734195351600647,
      "learning_rate": 4.819285714285715e-05,
      "loss": 0.0014,
      "step": 2530
    },
    {
      "epoch": 0.07257142857142856,
      "grad_norm": 0.03463778644800186,
      "learning_rate": 4.818571428571429e-05,
      "loss": 0.0019,
      "step": 2540
    },
    {
      "epoch": 0.07285714285714286,
      "grad_norm": 0.17616936564445496,
      "learning_rate": 4.817857142857143e-05,
      "loss": 0.0022,
      "step": 2550
    },
    {
      "epoch": 0.07314285714285715,
      "grad_norm": 0.19375182688236237,
      "learning_rate": 4.817142857142857e-05,
      "loss": 0.0026,
      "step": 2560
    },
    {
      "epoch": 0.07342857142857143,
      "grad_norm": 0.07742561399936676,
      "learning_rate": 4.8164285714285715e-05,
      "loss": 0.0011,
      "step": 2570
    },
    {
      "epoch": 0.07371428571428572,
      "grad_norm": 0.15737059712409973,
      "learning_rate": 4.815714285714286e-05,
      "loss": 0.0032,
      "step": 2580
    },
    {
      "epoch": 0.074,
      "grad_norm": 0.09591171145439148,
      "learning_rate": 4.815e-05,
      "loss": 0.0015,
      "step": 2590
    },
    {
      "epoch": 0.07428571428571429,
      "grad_norm": 0.07319078594446182,
      "learning_rate": 4.8142857142857147e-05,
      "loss": 0.0029,
      "step": 2600
    },
    {
      "epoch": 0.07457142857142857,
      "grad_norm": 0.18642373383045197,
      "learning_rate": 4.813571428571429e-05,
      "loss": 0.0014,
      "step": 2610
    },
    {
      "epoch": 0.07485714285714286,
      "grad_norm": 0.0,
      "learning_rate": 4.812857142857143e-05,
      "loss": 0.0017,
      "step": 2620
    },
    {
      "epoch": 0.07514285714285714,
      "grad_norm": 0.08867678791284561,
      "learning_rate": 4.812142857142857e-05,
      "loss": 0.0013,
      "step": 2630
    },
    {
      "epoch": 0.07542857142857143,
      "grad_norm": 0.0,
      "learning_rate": 4.811428571428572e-05,
      "loss": 0.001,
      "step": 2640
    },
    {
      "epoch": 0.07571428571428572,
      "grad_norm": 0.045502275228500366,
      "learning_rate": 4.810714285714286e-05,
      "loss": 0.0008,
      "step": 2650
    },
    {
      "epoch": 0.076,
      "grad_norm": 0.16895589232444763,
      "learning_rate": 4.8100000000000004e-05,
      "loss": 0.002,
      "step": 2660
    },
    {
      "epoch": 0.07628571428571429,
      "grad_norm": 0.21010561287403107,
      "learning_rate": 4.8092857142857145e-05,
      "loss": 0.003,
      "step": 2670
    },
    {
      "epoch": 0.07657142857142857,
      "grad_norm": 0.08998928219079971,
      "learning_rate": 4.808571428571429e-05,
      "loss": 0.0017,
      "step": 2680
    },
    {
      "epoch": 0.07685714285714286,
      "grad_norm": 0.3022308349609375,
      "learning_rate": 4.807857142857143e-05,
      "loss": 0.001,
      "step": 2690
    },
    {
      "epoch": 0.07714285714285714,
      "grad_norm": 0.10145621001720428,
      "learning_rate": 4.807142857142857e-05,
      "loss": 0.0025,
      "step": 2700
    },
    {
      "epoch": 0.07742857142857143,
      "grad_norm": 0.16794797778129578,
      "learning_rate": 4.806428571428572e-05,
      "loss": 0.0028,
      "step": 2710
    },
    {
      "epoch": 0.07771428571428571,
      "grad_norm": 0.22885949909687042,
      "learning_rate": 4.805714285714286e-05,
      "loss": 0.0021,
      "step": 2720
    },
    {
      "epoch": 0.078,
      "grad_norm": 0.15904547274112701,
      "learning_rate": 4.805e-05,
      "loss": 0.0009,
      "step": 2730
    },
    {
      "epoch": 0.07828571428571429,
      "grad_norm": 0.04445835202932358,
      "learning_rate": 4.8042857142857144e-05,
      "loss": 0.0024,
      "step": 2740
    },
    {
      "epoch": 0.07857142857142857,
      "grad_norm": 0.20894326269626617,
      "learning_rate": 4.803571428571429e-05,
      "loss": 0.0022,
      "step": 2750
    },
    {
      "epoch": 0.07885714285714286,
      "grad_norm": 0.18454767763614655,
      "learning_rate": 4.802857142857143e-05,
      "loss": 0.0021,
      "step": 2760
    },
    {
      "epoch": 0.07914285714285714,
      "grad_norm": 0.27565905451774597,
      "learning_rate": 4.8021428571428576e-05,
      "loss": 0.0018,
      "step": 2770
    },
    {
      "epoch": 0.07942857142857143,
      "grad_norm": 0.22902442514896393,
      "learning_rate": 4.801428571428572e-05,
      "loss": 0.0017,
      "step": 2780
    },
    {
      "epoch": 0.07971428571428571,
      "grad_norm": 0.09180385619401932,
      "learning_rate": 4.800714285714286e-05,
      "loss": 0.0025,
      "step": 2790
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.20809149742126465,
      "learning_rate": 4.8e-05,
      "loss": 0.0024,
      "step": 2800
    },
    {
      "epoch": 0.08028571428571428,
      "grad_norm": 0.0490860715508461,
      "learning_rate": 4.799285714285714e-05,
      "loss": 0.0014,
      "step": 2810
    },
    {
      "epoch": 0.08057142857142857,
      "grad_norm": 0.16548611223697662,
      "learning_rate": 4.798571428571429e-05,
      "loss": 0.0022,
      "step": 2820
    },
    {
      "epoch": 0.08085714285714286,
      "grad_norm": 0.12577618658542633,
      "learning_rate": 4.7978571428571426e-05,
      "loss": 0.0016,
      "step": 2830
    },
    {
      "epoch": 0.08114285714285714,
      "grad_norm": 0.16602732241153717,
      "learning_rate": 4.7971428571428575e-05,
      "loss": 0.0015,
      "step": 2840
    },
    {
      "epoch": 0.08142857142857143,
      "grad_norm": 0.042012184858322144,
      "learning_rate": 4.7964285714285717e-05,
      "loss": 0.0019,
      "step": 2850
    },
    {
      "epoch": 0.08171428571428571,
      "grad_norm": 0.09115349501371384,
      "learning_rate": 4.795714285714286e-05,
      "loss": 0.0026,
      "step": 2860
    },
    {
      "epoch": 0.082,
      "grad_norm": 0.1141246035695076,
      "learning_rate": 4.795e-05,
      "loss": 0.0021,
      "step": 2870
    },
    {
      "epoch": 0.08228571428571428,
      "grad_norm": 0.04660467430949211,
      "learning_rate": 4.794285714285714e-05,
      "loss": 0.0022,
      "step": 2880
    },
    {
      "epoch": 0.08257142857142857,
      "grad_norm": 0.06101829558610916,
      "learning_rate": 4.793571428571429e-05,
      "loss": 0.0012,
      "step": 2890
    },
    {
      "epoch": 0.08285714285714285,
      "grad_norm": 0.0,
      "learning_rate": 4.7928571428571425e-05,
      "loss": 0.0026,
      "step": 2900
    },
    {
      "epoch": 0.08314285714285714,
      "grad_norm": 0.08433610200881958,
      "learning_rate": 4.7921428571428574e-05,
      "loss": 0.0006,
      "step": 2910
    },
    {
      "epoch": 0.08342857142857144,
      "grad_norm": 0.045050546526908875,
      "learning_rate": 4.7914285714285715e-05,
      "loss": 0.0013,
      "step": 2920
    },
    {
      "epoch": 0.08371428571428571,
      "grad_norm": 0.04467367008328438,
      "learning_rate": 4.7907142857142864e-05,
      "loss": 0.0018,
      "step": 2930
    },
    {
      "epoch": 0.084,
      "grad_norm": 0.26028454303741455,
      "learning_rate": 4.79e-05,
      "loss": 0.0028,
      "step": 2940
    },
    {
      "epoch": 0.08428571428571428,
      "grad_norm": 0.04604005813598633,
      "learning_rate": 4.789285714285715e-05,
      "loss": 0.0016,
      "step": 2950
    },
    {
      "epoch": 0.08457142857142858,
      "grad_norm": 0.12491799890995026,
      "learning_rate": 4.788571428571429e-05,
      "loss": 0.0022,
      "step": 2960
    },
    {
      "epoch": 0.08485714285714285,
      "grad_norm": 0.0,
      "learning_rate": 4.787857142857143e-05,
      "loss": 0.0014,
      "step": 2970
    },
    {
      "epoch": 0.08514285714285715,
      "grad_norm": 0.058017563074827194,
      "learning_rate": 4.787142857142857e-05,
      "loss": 0.0015,
      "step": 2980
    },
    {
      "epoch": 0.08542857142857142,
      "grad_norm": 0.0558483712375164,
      "learning_rate": 4.7864285714285714e-05,
      "loss": 0.0022,
      "step": 2990
    },
    {
      "epoch": 0.08571428571428572,
      "grad_norm": 0.18364182114601135,
      "learning_rate": 4.785714285714286e-05,
      "loss": 0.0021,
      "step": 3000
    },
    {
      "epoch": 0.086,
      "grad_norm": 0.04915143921971321,
      "learning_rate": 4.785e-05,
      "loss": 0.003,
      "step": 3010
    },
    {
      "epoch": 0.08628571428571429,
      "grad_norm": 0.09466717392206192,
      "learning_rate": 4.7842857142857146e-05,
      "loss": 0.0022,
      "step": 3020
    },
    {
      "epoch": 0.08657142857142858,
      "grad_norm": 0.18086275458335876,
      "learning_rate": 4.783571428571429e-05,
      "loss": 0.0024,
      "step": 3030
    },
    {
      "epoch": 0.08685714285714285,
      "grad_norm": 0.06962678581476212,
      "learning_rate": 4.782857142857143e-05,
      "loss": 0.002,
      "step": 3040
    },
    {
      "epoch": 0.08714285714285715,
      "grad_norm": 0.1630479097366333,
      "learning_rate": 4.782142857142857e-05,
      "loss": 0.0018,
      "step": 3050
    },
    {
      "epoch": 0.08742857142857142,
      "grad_norm": 0.03822241351008415,
      "learning_rate": 4.781428571428572e-05,
      "loss": 0.0005,
      "step": 3060
    },
    {
      "epoch": 0.08771428571428572,
      "grad_norm": 0.08671543002128601,
      "learning_rate": 4.780714285714286e-05,
      "loss": 0.0021,
      "step": 3070
    },
    {
      "epoch": 0.088,
      "grad_norm": 0.09349337220191956,
      "learning_rate": 4.78e-05,
      "loss": 0.0017,
      "step": 3080
    },
    {
      "epoch": 0.08828571428571429,
      "grad_norm": 0.04249466955661774,
      "learning_rate": 4.7792857142857145e-05,
      "loss": 0.0023,
      "step": 3090
    },
    {
      "epoch": 0.08857142857142856,
      "grad_norm": 0.05184261500835419,
      "learning_rate": 4.7785714285714287e-05,
      "loss": 0.0018,
      "step": 3100
    },
    {
      "epoch": 0.08885714285714286,
      "grad_norm": 0.1582665741443634,
      "learning_rate": 4.777857142857143e-05,
      "loss": 0.0012,
      "step": 3110
    },
    {
      "epoch": 0.08914285714285715,
      "grad_norm": 0.05842515081167221,
      "learning_rate": 4.777142857142857e-05,
      "loss": 0.0022,
      "step": 3120
    },
    {
      "epoch": 0.08942857142857143,
      "grad_norm": 0.0,
      "learning_rate": 4.776428571428572e-05,
      "loss": 0.0006,
      "step": 3130
    },
    {
      "epoch": 0.08971428571428572,
      "grad_norm": 0.19066749513149261,
      "learning_rate": 4.775714285714286e-05,
      "loss": 0.0011,
      "step": 3140
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.19475767016410828,
      "learning_rate": 4.775e-05,
      "loss": 0.0015,
      "step": 3150
    },
    {
      "epoch": 0.09028571428571429,
      "grad_norm": 0.060884229838848114,
      "learning_rate": 4.7742857142857144e-05,
      "loss": 0.002,
      "step": 3160
    },
    {
      "epoch": 0.09057142857142857,
      "grad_norm": 0.08850041031837463,
      "learning_rate": 4.773571428571429e-05,
      "loss": 0.0029,
      "step": 3170
    },
    {
      "epoch": 0.09085714285714286,
      "grad_norm": 0.021357988938689232,
      "learning_rate": 4.7728571428571434e-05,
      "loss": 0.0026,
      "step": 3180
    },
    {
      "epoch": 0.09114285714285714,
      "grad_norm": 0.17818093299865723,
      "learning_rate": 4.7721428571428576e-05,
      "loss": 0.002,
      "step": 3190
    },
    {
      "epoch": 0.09142857142857143,
      "grad_norm": 0.051358677446842194,
      "learning_rate": 4.771428571428572e-05,
      "loss": 0.0024,
      "step": 3200
    },
    {
      "epoch": 0.09171428571428572,
      "grad_norm": 0.045043252408504486,
      "learning_rate": 4.770714285714286e-05,
      "loss": 0.0021,
      "step": 3210
    },
    {
      "epoch": 0.092,
      "grad_norm": 0.12707354128360748,
      "learning_rate": 4.77e-05,
      "loss": 0.0015,
      "step": 3220
    },
    {
      "epoch": 0.09228571428571429,
      "grad_norm": 0.08402294665575027,
      "learning_rate": 4.769285714285714e-05,
      "loss": 0.0011,
      "step": 3230
    },
    {
      "epoch": 0.09257142857142857,
      "grad_norm": 0.14321433007717133,
      "learning_rate": 4.768571428571429e-05,
      "loss": 0.0008,
      "step": 3240
    },
    {
      "epoch": 0.09285714285714286,
      "grad_norm": 0.13715839385986328,
      "learning_rate": 4.767857142857143e-05,
      "loss": 0.0013,
      "step": 3250
    },
    {
      "epoch": 0.09314285714285714,
      "grad_norm": 0.04951775074005127,
      "learning_rate": 4.7671428571428574e-05,
      "loss": 0.0023,
      "step": 3260
    },
    {
      "epoch": 0.09342857142857143,
      "grad_norm": 0.12975777685642242,
      "learning_rate": 4.7664285714285716e-05,
      "loss": 0.0028,
      "step": 3270
    },
    {
      "epoch": 0.09371428571428571,
      "grad_norm": 0.15610504150390625,
      "learning_rate": 4.7657142857142865e-05,
      "loss": 0.003,
      "step": 3280
    },
    {
      "epoch": 0.094,
      "grad_norm": 0.07488971203565598,
      "learning_rate": 4.765e-05,
      "loss": 0.0025,
      "step": 3290
    },
    {
      "epoch": 0.09428571428571429,
      "grad_norm": 0.3643341064453125,
      "learning_rate": 4.764285714285715e-05,
      "loss": 0.0015,
      "step": 3300
    },
    {
      "epoch": 0.09457142857142857,
      "grad_norm": 0.12461977452039719,
      "learning_rate": 4.763571428571429e-05,
      "loss": 0.002,
      "step": 3310
    },
    {
      "epoch": 0.09485714285714286,
      "grad_norm": 0.14833903312683105,
      "learning_rate": 4.762857142857143e-05,
      "loss": 0.0025,
      "step": 3320
    },
    {
      "epoch": 0.09514285714285714,
      "grad_norm": 0.16125328838825226,
      "learning_rate": 4.762142857142857e-05,
      "loss": 0.0016,
      "step": 3330
    },
    {
      "epoch": 0.09542857142857143,
      "grad_norm": 0.21643443405628204,
      "learning_rate": 4.7614285714285715e-05,
      "loss": 0.0014,
      "step": 3340
    },
    {
      "epoch": 0.09571428571428571,
      "grad_norm": 0.15425007045269012,
      "learning_rate": 4.760714285714286e-05,
      "loss": 0.0022,
      "step": 3350
    },
    {
      "epoch": 0.096,
      "grad_norm": 0.03214842826128006,
      "learning_rate": 4.76e-05,
      "loss": 0.0019,
      "step": 3360
    },
    {
      "epoch": 0.09628571428571428,
      "grad_norm": 0.0,
      "learning_rate": 4.759285714285715e-05,
      "loss": 0.0009,
      "step": 3370
    },
    {
      "epoch": 0.09657142857142857,
      "grad_norm": 0.022980038076639175,
      "learning_rate": 4.758571428571429e-05,
      "loss": 0.0013,
      "step": 3380
    },
    {
      "epoch": 0.09685714285714286,
      "grad_norm": 0.045797642320394516,
      "learning_rate": 4.757857142857143e-05,
      "loss": 0.0036,
      "step": 3390
    },
    {
      "epoch": 0.09714285714285714,
      "grad_norm": 0.07405342161655426,
      "learning_rate": 4.757142857142857e-05,
      "loss": 0.0015,
      "step": 3400
    },
    {
      "epoch": 0.09742857142857143,
      "grad_norm": 0.3224896192550659,
      "learning_rate": 4.7564285714285714e-05,
      "loss": 0.0013,
      "step": 3410
    },
    {
      "epoch": 0.09771428571428571,
      "grad_norm": 0.14234423637390137,
      "learning_rate": 4.755714285714286e-05,
      "loss": 0.0022,
      "step": 3420
    },
    {
      "epoch": 0.098,
      "grad_norm": 0.24315056204795837,
      "learning_rate": 4.755e-05,
      "loss": 0.0015,
      "step": 3430
    },
    {
      "epoch": 0.09828571428571428,
      "grad_norm": 0.0641031339764595,
      "learning_rate": 4.7542857142857146e-05,
      "loss": 0.0025,
      "step": 3440
    },
    {
      "epoch": 0.09857142857142857,
      "grad_norm": 0.0948571190237999,
      "learning_rate": 4.753571428571429e-05,
      "loss": 0.0018,
      "step": 3450
    },
    {
      "epoch": 0.09885714285714285,
      "grad_norm": 0.1820243000984192,
      "learning_rate": 4.7528571428571436e-05,
      "loss": 0.0022,
      "step": 3460
    },
    {
      "epoch": 0.09914285714285714,
      "grad_norm": 0.1352643221616745,
      "learning_rate": 4.752142857142857e-05,
      "loss": 0.0025,
      "step": 3470
    },
    {
      "epoch": 0.09942857142857142,
      "grad_norm": 0.26379385590553284,
      "learning_rate": 4.751428571428572e-05,
      "loss": 0.0017,
      "step": 3480
    },
    {
      "epoch": 0.09971428571428571,
      "grad_norm": 0.1436886042356491,
      "learning_rate": 4.750714285714286e-05,
      "loss": 0.0018,
      "step": 3490
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.2256944626569748,
      "learning_rate": 4.75e-05,
      "loss": 0.003,
      "step": 3500
    },
    {
      "epoch": 0.10028571428571428,
      "grad_norm": 0.2082005888223648,
      "learning_rate": 4.7492857142857144e-05,
      "loss": 0.0024,
      "step": 3510
    },
    {
      "epoch": 0.10057142857142858,
      "grad_norm": 0.23715771734714508,
      "learning_rate": 4.7485714285714286e-05,
      "loss": 0.0018,
      "step": 3520
    },
    {
      "epoch": 0.10085714285714285,
      "grad_norm": 0.05280441790819168,
      "learning_rate": 4.7478571428571435e-05,
      "loss": 0.0023,
      "step": 3530
    },
    {
      "epoch": 0.10114285714285715,
      "grad_norm": 0.10399480164051056,
      "learning_rate": 4.747142857142857e-05,
      "loss": 0.0014,
      "step": 3540
    },
    {
      "epoch": 0.10142857142857142,
      "grad_norm": 0.12487255036830902,
      "learning_rate": 4.746428571428572e-05,
      "loss": 0.0022,
      "step": 3550
    },
    {
      "epoch": 0.10171428571428572,
      "grad_norm": 0.07567532360553741,
      "learning_rate": 4.745714285714286e-05,
      "loss": 0.0035,
      "step": 3560
    },
    {
      "epoch": 0.102,
      "grad_norm": 0.04136049374938011,
      "learning_rate": 4.745e-05,
      "loss": 0.0005,
      "step": 3570
    },
    {
      "epoch": 0.10228571428571429,
      "grad_norm": 0.05772951617836952,
      "learning_rate": 4.744285714285714e-05,
      "loss": 0.0011,
      "step": 3580
    },
    {
      "epoch": 0.10257142857142858,
      "grad_norm": 0.1973366141319275,
      "learning_rate": 4.743571428571429e-05,
      "loss": 0.002,
      "step": 3590
    },
    {
      "epoch": 0.10285714285714286,
      "grad_norm": 0.14049823582172394,
      "learning_rate": 4.742857142857143e-05,
      "loss": 0.0017,
      "step": 3600
    },
    {
      "epoch": 0.10314285714285715,
      "grad_norm": 0.11752679944038391,
      "learning_rate": 4.7421428571428575e-05,
      "loss": 0.0013,
      "step": 3610
    },
    {
      "epoch": 0.10342857142857143,
      "grad_norm": 0.04710372909903526,
      "learning_rate": 4.741428571428572e-05,
      "loss": 0.0019,
      "step": 3620
    },
    {
      "epoch": 0.10371428571428572,
      "grad_norm": 0.13083891570568085,
      "learning_rate": 4.740714285714286e-05,
      "loss": 0.0015,
      "step": 3630
    },
    {
      "epoch": 0.104,
      "grad_norm": 0.01801522821187973,
      "learning_rate": 4.74e-05,
      "loss": 0.0019,
      "step": 3640
    },
    {
      "epoch": 0.10428571428571429,
      "grad_norm": 0.06848182529211044,
      "learning_rate": 4.739285714285714e-05,
      "loss": 0.0028,
      "step": 3650
    },
    {
      "epoch": 0.10457142857142857,
      "grad_norm": 0.04817004129290581,
      "learning_rate": 4.738571428571429e-05,
      "loss": 0.0024,
      "step": 3660
    },
    {
      "epoch": 0.10485714285714286,
      "grad_norm": 0.05276700481772423,
      "learning_rate": 4.737857142857143e-05,
      "loss": 0.0012,
      "step": 3670
    },
    {
      "epoch": 0.10514285714285715,
      "grad_norm": 0.07230861485004425,
      "learning_rate": 4.7371428571428574e-05,
      "loss": 0.0022,
      "step": 3680
    },
    {
      "epoch": 0.10542857142857143,
      "grad_norm": 0.11829517036676407,
      "learning_rate": 4.7364285714285716e-05,
      "loss": 0.0021,
      "step": 3690
    },
    {
      "epoch": 0.10571428571428572,
      "grad_norm": 0.06102133169770241,
      "learning_rate": 4.7357142857142864e-05,
      "loss": 0.0017,
      "step": 3700
    },
    {
      "epoch": 0.106,
      "grad_norm": 0.04157529026269913,
      "learning_rate": 4.735e-05,
      "loss": 0.0016,
      "step": 3710
    },
    {
      "epoch": 0.10628571428571429,
      "grad_norm": 0.10661909729242325,
      "learning_rate": 4.734285714285715e-05,
      "loss": 0.0009,
      "step": 3720
    },
    {
      "epoch": 0.10657142857142857,
      "grad_norm": 0.15832525491714478,
      "learning_rate": 4.733571428571429e-05,
      "loss": 0.005,
      "step": 3730
    },
    {
      "epoch": 0.10685714285714286,
      "grad_norm": 0.11267241835594177,
      "learning_rate": 4.732857142857143e-05,
      "loss": 0.0028,
      "step": 3740
    },
    {
      "epoch": 0.10714285714285714,
      "grad_norm": 0.15612703561782837,
      "learning_rate": 4.732142857142857e-05,
      "loss": 0.0015,
      "step": 3750
    },
    {
      "epoch": 0.10742857142857143,
      "grad_norm": 0.06368924677371979,
      "learning_rate": 4.7314285714285714e-05,
      "loss": 0.0018,
      "step": 3760
    },
    {
      "epoch": 0.10771428571428572,
      "grad_norm": 0.2761233150959015,
      "learning_rate": 4.730714285714286e-05,
      "loss": 0.0013,
      "step": 3770
    },
    {
      "epoch": 0.108,
      "grad_norm": 0.06703158468008041,
      "learning_rate": 4.73e-05,
      "loss": 0.0023,
      "step": 3780
    },
    {
      "epoch": 0.10828571428571429,
      "grad_norm": 0.04924507066607475,
      "learning_rate": 4.7292857142857146e-05,
      "loss": 0.0026,
      "step": 3790
    },
    {
      "epoch": 0.10857142857142857,
      "grad_norm": 0.20706883072853088,
      "learning_rate": 4.728571428571429e-05,
      "loss": 0.0012,
      "step": 3800
    },
    {
      "epoch": 0.10885714285714286,
      "grad_norm": 0.22472158074378967,
      "learning_rate": 4.7278571428571436e-05,
      "loss": 0.0017,
      "step": 3810
    },
    {
      "epoch": 0.10914285714285714,
      "grad_norm": 0.0499015748500824,
      "learning_rate": 4.727142857142857e-05,
      "loss": 0.0015,
      "step": 3820
    },
    {
      "epoch": 0.10942857142857143,
      "grad_norm": 0.0,
      "learning_rate": 4.726428571428572e-05,
      "loss": 0.0017,
      "step": 3830
    },
    {
      "epoch": 0.10971428571428571,
      "grad_norm": 0.084851935505867,
      "learning_rate": 4.725714285714286e-05,
      "loss": 0.0005,
      "step": 3840
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.0,
      "learning_rate": 4.7249999999999997e-05,
      "loss": 0.0018,
      "step": 3850
    },
    {
      "epoch": 0.11028571428571429,
      "grad_norm": 0.16505932807922363,
      "learning_rate": 4.7242857142857145e-05,
      "loss": 0.0014,
      "step": 3860
    },
    {
      "epoch": 0.11057142857142857,
      "grad_norm": 0.2664649486541748,
      "learning_rate": 4.723571428571429e-05,
      "loss": 0.0015,
      "step": 3870
    },
    {
      "epoch": 0.11085714285714286,
      "grad_norm": 0.04530045762658119,
      "learning_rate": 4.7228571428571435e-05,
      "loss": 0.0019,
      "step": 3880
    },
    {
      "epoch": 0.11114285714285714,
      "grad_norm": 0.057913146913051605,
      "learning_rate": 4.722142857142857e-05,
      "loss": 0.0018,
      "step": 3890
    },
    {
      "epoch": 0.11142857142857143,
      "grad_norm": 0.09400003403425217,
      "learning_rate": 4.721428571428572e-05,
      "loss": 0.0017,
      "step": 3900
    },
    {
      "epoch": 0.11171428571428571,
      "grad_norm": 0.04251454770565033,
      "learning_rate": 4.720714285714286e-05,
      "loss": 0.0014,
      "step": 3910
    },
    {
      "epoch": 0.112,
      "grad_norm": 0.06213811784982681,
      "learning_rate": 4.72e-05,
      "loss": 0.0023,
      "step": 3920
    },
    {
      "epoch": 0.11228571428571428,
      "grad_norm": 0.05716652795672417,
      "learning_rate": 4.7192857142857144e-05,
      "loss": 0.002,
      "step": 3930
    },
    {
      "epoch": 0.11257142857142857,
      "grad_norm": 0.24496112763881683,
      "learning_rate": 4.7185714285714286e-05,
      "loss": 0.0018,
      "step": 3940
    },
    {
      "epoch": 0.11285714285714285,
      "grad_norm": 0.2374303638935089,
      "learning_rate": 4.7178571428571434e-05,
      "loss": 0.0022,
      "step": 3950
    },
    {
      "epoch": 0.11314285714285714,
      "grad_norm": 0.22654688358306885,
      "learning_rate": 4.717142857142857e-05,
      "loss": 0.0024,
      "step": 3960
    },
    {
      "epoch": 0.11342857142857143,
      "grad_norm": 0.05696212127804756,
      "learning_rate": 4.716428571428572e-05,
      "loss": 0.002,
      "step": 3970
    },
    {
      "epoch": 0.11371428571428571,
      "grad_norm": 0.0,
      "learning_rate": 4.715714285714286e-05,
      "loss": 0.0019,
      "step": 3980
    },
    {
      "epoch": 0.114,
      "grad_norm": 0.11517704278230667,
      "learning_rate": 4.715e-05,
      "loss": 0.0011,
      "step": 3990
    },
    {
      "epoch": 0.11428571428571428,
      "grad_norm": 0.08143915981054306,
      "learning_rate": 4.714285714285714e-05,
      "loss": 0.0019,
      "step": 4000
    },
    {
      "epoch": 0.11457142857142857,
      "grad_norm": 0.12319929897785187,
      "learning_rate": 4.713571428571429e-05,
      "loss": 0.0021,
      "step": 4010
    },
    {
      "epoch": 0.11485714285714285,
      "grad_norm": 0.042555466294288635,
      "learning_rate": 4.712857142857143e-05,
      "loss": 0.0019,
      "step": 4020
    },
    {
      "epoch": 0.11514285714285714,
      "grad_norm": 0.11778342723846436,
      "learning_rate": 4.7121428571428575e-05,
      "loss": 0.0031,
      "step": 4030
    },
    {
      "epoch": 0.11542857142857142,
      "grad_norm": 0.2052161544561386,
      "learning_rate": 4.7114285714285716e-05,
      "loss": 0.002,
      "step": 4040
    },
    {
      "epoch": 0.11571428571428571,
      "grad_norm": 0.05207955464720726,
      "learning_rate": 4.710714285714286e-05,
      "loss": 0.0019,
      "step": 4050
    },
    {
      "epoch": 0.116,
      "grad_norm": 0.1231185644865036,
      "learning_rate": 4.71e-05,
      "loss": 0.0015,
      "step": 4060
    },
    {
      "epoch": 0.11628571428571428,
      "grad_norm": 0.0,
      "learning_rate": 4.709285714285714e-05,
      "loss": 0.0018,
      "step": 4070
    },
    {
      "epoch": 0.11657142857142858,
      "grad_norm": 0.1388581246137619,
      "learning_rate": 4.708571428571429e-05,
      "loss": 0.0026,
      "step": 4080
    },
    {
      "epoch": 0.11685714285714285,
      "grad_norm": 0.0561605766415596,
      "learning_rate": 4.707857142857143e-05,
      "loss": 0.0026,
      "step": 4090
    },
    {
      "epoch": 0.11714285714285715,
      "grad_norm": 0.04383847489953041,
      "learning_rate": 4.707142857142857e-05,
      "loss": 0.0024,
      "step": 4100
    },
    {
      "epoch": 0.11742857142857142,
      "grad_norm": 0.0,
      "learning_rate": 4.7064285714285715e-05,
      "loss": 0.0033,
      "step": 4110
    },
    {
      "epoch": 0.11771428571428572,
      "grad_norm": 0.026080023497343063,
      "learning_rate": 4.7057142857142864e-05,
      "loss": 0.002,
      "step": 4120
    },
    {
      "epoch": 0.118,
      "grad_norm": 0.13257206976413727,
      "learning_rate": 4.705e-05,
      "loss": 0.0022,
      "step": 4130
    },
    {
      "epoch": 0.11828571428571429,
      "grad_norm": 0.07356128841638565,
      "learning_rate": 4.704285714285715e-05,
      "loss": 0.0025,
      "step": 4140
    },
    {
      "epoch": 0.11857142857142858,
      "grad_norm": 0.3249359726905823,
      "learning_rate": 4.703571428571429e-05,
      "loss": 0.0024,
      "step": 4150
    },
    {
      "epoch": 0.11885714285714286,
      "grad_norm": 0.1374826282262802,
      "learning_rate": 4.702857142857143e-05,
      "loss": 0.0014,
      "step": 4160
    },
    {
      "epoch": 0.11914285714285715,
      "grad_norm": 0.028742069378495216,
      "learning_rate": 4.702142857142857e-05,
      "loss": 0.0009,
      "step": 4170
    },
    {
      "epoch": 0.11942857142857143,
      "grad_norm": 0.27449119091033936,
      "learning_rate": 4.7014285714285714e-05,
      "loss": 0.0025,
      "step": 4180
    },
    {
      "epoch": 0.11971428571428572,
      "grad_norm": 0.3193105161190033,
      "learning_rate": 4.700714285714286e-05,
      "loss": 0.0017,
      "step": 4190
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.0,
      "learning_rate": 4.7e-05,
      "loss": 0.0032,
      "step": 4200
    },
    {
      "epoch": 0.12028571428571429,
      "grad_norm": 0.05112338438630104,
      "learning_rate": 4.6992857142857146e-05,
      "loss": 0.0016,
      "step": 4210
    },
    {
      "epoch": 0.12057142857142857,
      "grad_norm": 0.0,
      "learning_rate": 4.698571428571429e-05,
      "loss": 0.0018,
      "step": 4220
    },
    {
      "epoch": 0.12085714285714286,
      "grad_norm": 0.05293507128953934,
      "learning_rate": 4.6978571428571436e-05,
      "loss": 0.0013,
      "step": 4230
    },
    {
      "epoch": 0.12114285714285715,
      "grad_norm": 0.041362009942531586,
      "learning_rate": 4.697142857142857e-05,
      "loss": 0.0017,
      "step": 4240
    },
    {
      "epoch": 0.12142857142857143,
      "grad_norm": 0.135885089635849,
      "learning_rate": 4.696428571428572e-05,
      "loss": 0.0017,
      "step": 4250
    },
    {
      "epoch": 0.12171428571428572,
      "grad_norm": 0.19081775844097137,
      "learning_rate": 4.695714285714286e-05,
      "loss": 0.0018,
      "step": 4260
    },
    {
      "epoch": 0.122,
      "grad_norm": 0.19665609300136566,
      "learning_rate": 4.695e-05,
      "loss": 0.0018,
      "step": 4270
    },
    {
      "epoch": 0.12228571428571429,
      "grad_norm": 0.1923135370016098,
      "learning_rate": 4.6942857142857145e-05,
      "loss": 0.0023,
      "step": 4280
    },
    {
      "epoch": 0.12257142857142857,
      "grad_norm": 0.14987710118293762,
      "learning_rate": 4.6935714285714286e-05,
      "loss": 0.0029,
      "step": 4290
    },
    {
      "epoch": 0.12285714285714286,
      "grad_norm": 0.04993809387087822,
      "learning_rate": 4.6928571428571435e-05,
      "loss": 0.0032,
      "step": 4300
    },
    {
      "epoch": 0.12314285714285714,
      "grad_norm": 0.07368628680706024,
      "learning_rate": 4.692142857142857e-05,
      "loss": 0.0014,
      "step": 4310
    },
    {
      "epoch": 0.12342857142857143,
      "grad_norm": 0.030059723183512688,
      "learning_rate": 4.691428571428572e-05,
      "loss": 0.0023,
      "step": 4320
    },
    {
      "epoch": 0.12371428571428572,
      "grad_norm": 0.05135360732674599,
      "learning_rate": 4.690714285714286e-05,
      "loss": 0.0013,
      "step": 4330
    },
    {
      "epoch": 0.124,
      "grad_norm": 0.22479046881198883,
      "learning_rate": 4.69e-05,
      "loss": 0.0017,
      "step": 4340
    },
    {
      "epoch": 0.12428571428571429,
      "grad_norm": 0.08514208346605301,
      "learning_rate": 4.689285714285714e-05,
      "loss": 0.0011,
      "step": 4350
    },
    {
      "epoch": 0.12457142857142857,
      "grad_norm": 0.040576186031103134,
      "learning_rate": 4.6885714285714285e-05,
      "loss": 0.0025,
      "step": 4360
    },
    {
      "epoch": 0.12485714285714286,
      "grad_norm": 0.06300005316734314,
      "learning_rate": 4.6878571428571434e-05,
      "loss": 0.0014,
      "step": 4370
    },
    {
      "epoch": 0.12514285714285714,
      "grad_norm": 0.15362946689128876,
      "learning_rate": 4.687142857142857e-05,
      "loss": 0.0013,
      "step": 4380
    },
    {
      "epoch": 0.12542857142857142,
      "grad_norm": 0.09524168819189072,
      "learning_rate": 4.686428571428572e-05,
      "loss": 0.0026,
      "step": 4390
    },
    {
      "epoch": 0.12571428571428572,
      "grad_norm": 0.04315682128071785,
      "learning_rate": 4.685714285714286e-05,
      "loss": 0.0017,
      "step": 4400
    },
    {
      "epoch": 0.126,
      "grad_norm": 0.0380580835044384,
      "learning_rate": 4.685000000000001e-05,
      "loss": 0.0018,
      "step": 4410
    },
    {
      "epoch": 0.12628571428571428,
      "grad_norm": 0.15065088868141174,
      "learning_rate": 4.684285714285714e-05,
      "loss": 0.0019,
      "step": 4420
    },
    {
      "epoch": 0.12657142857142858,
      "grad_norm": 0.04868829995393753,
      "learning_rate": 4.683571428571429e-05,
      "loss": 0.0022,
      "step": 4430
    },
    {
      "epoch": 0.12685714285714286,
      "grad_norm": 0.08141601085662842,
      "learning_rate": 4.682857142857143e-05,
      "loss": 0.0013,
      "step": 4440
    },
    {
      "epoch": 0.12714285714285714,
      "grad_norm": 0.07510121166706085,
      "learning_rate": 4.6821428571428574e-05,
      "loss": 0.0016,
      "step": 4450
    },
    {
      "epoch": 0.12742857142857142,
      "grad_norm": 0.2520475685596466,
      "learning_rate": 4.6814285714285716e-05,
      "loss": 0.0024,
      "step": 4460
    },
    {
      "epoch": 0.12771428571428572,
      "grad_norm": 0.1053328737616539,
      "learning_rate": 4.680714285714286e-05,
      "loss": 0.0024,
      "step": 4470
    },
    {
      "epoch": 0.128,
      "grad_norm": 0.17610405385494232,
      "learning_rate": 4.6800000000000006e-05,
      "loss": 0.0024,
      "step": 4480
    },
    {
      "epoch": 0.12828571428571428,
      "grad_norm": 0.13790713250637054,
      "learning_rate": 4.679285714285714e-05,
      "loss": 0.0011,
      "step": 4490
    },
    {
      "epoch": 0.12857142857142856,
      "grad_norm": 0.026175716891884804,
      "learning_rate": 4.678571428571429e-05,
      "loss": 0.0011,
      "step": 4500
    },
    {
      "epoch": 0.12885714285714286,
      "grad_norm": 0.1039256677031517,
      "learning_rate": 4.677857142857143e-05,
      "loss": 0.0016,
      "step": 4510
    },
    {
      "epoch": 0.12914285714285714,
      "grad_norm": 0.1635023057460785,
      "learning_rate": 4.677142857142857e-05,
      "loss": 0.0009,
      "step": 4520
    },
    {
      "epoch": 0.12942857142857142,
      "grad_norm": 0.3724144697189331,
      "learning_rate": 4.6764285714285715e-05,
      "loss": 0.0019,
      "step": 4530
    },
    {
      "epoch": 0.12971428571428573,
      "grad_norm": 0.2588599920272827,
      "learning_rate": 4.675714285714286e-05,
      "loss": 0.0016,
      "step": 4540
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.04215463995933533,
      "learning_rate": 4.6750000000000005e-05,
      "loss": 0.0013,
      "step": 4550
    },
    {
      "epoch": 0.13028571428571428,
      "grad_norm": 0.047059714794158936,
      "learning_rate": 4.6742857142857146e-05,
      "loss": 0.0017,
      "step": 4560
    },
    {
      "epoch": 0.13057142857142856,
      "grad_norm": 0.05424351990222931,
      "learning_rate": 4.673571428571429e-05,
      "loss": 0.0012,
      "step": 4570
    },
    {
      "epoch": 0.13085714285714287,
      "grad_norm": 0.09066706895828247,
      "learning_rate": 4.672857142857143e-05,
      "loss": 0.0009,
      "step": 4580
    },
    {
      "epoch": 0.13114285714285714,
      "grad_norm": 0.08304396271705627,
      "learning_rate": 4.672142857142857e-05,
      "loss": 0.0019,
      "step": 4590
    },
    {
      "epoch": 0.13142857142857142,
      "grad_norm": 0.06009078025817871,
      "learning_rate": 4.671428571428571e-05,
      "loss": 0.0026,
      "step": 4600
    },
    {
      "epoch": 0.1317142857142857,
      "grad_norm": 0.05649006366729736,
      "learning_rate": 4.670714285714286e-05,
      "loss": 0.0016,
      "step": 4610
    },
    {
      "epoch": 0.132,
      "grad_norm": 0.12807418406009674,
      "learning_rate": 4.6700000000000003e-05,
      "loss": 0.0017,
      "step": 4620
    },
    {
      "epoch": 0.13228571428571428,
      "grad_norm": 0.1936725676059723,
      "learning_rate": 4.6692857142857145e-05,
      "loss": 0.0012,
      "step": 4630
    },
    {
      "epoch": 0.13257142857142856,
      "grad_norm": 0.08811114728450775,
      "learning_rate": 4.668571428571429e-05,
      "loss": 0.0024,
      "step": 4640
    },
    {
      "epoch": 0.13285714285714287,
      "grad_norm": 0.08726859092712402,
      "learning_rate": 4.6678571428571435e-05,
      "loss": 0.0018,
      "step": 4650
    },
    {
      "epoch": 0.13314285714285715,
      "grad_norm": 0.16594307124614716,
      "learning_rate": 4.667142857142857e-05,
      "loss": 0.0018,
      "step": 4660
    },
    {
      "epoch": 0.13342857142857142,
      "grad_norm": 0.36031144857406616,
      "learning_rate": 4.666428571428572e-05,
      "loss": 0.0013,
      "step": 4670
    },
    {
      "epoch": 0.1337142857142857,
      "grad_norm": 0.26520222425460815,
      "learning_rate": 4.665714285714286e-05,
      "loss": 0.0028,
      "step": 4680
    },
    {
      "epoch": 0.134,
      "grad_norm": 0.051314324140548706,
      "learning_rate": 4.665e-05,
      "loss": 0.0031,
      "step": 4690
    },
    {
      "epoch": 0.13428571428571429,
      "grad_norm": 0.0,
      "learning_rate": 4.6642857142857144e-05,
      "loss": 0.0021,
      "step": 4700
    },
    {
      "epoch": 0.13457142857142856,
      "grad_norm": 0.08342468738555908,
      "learning_rate": 4.6635714285714286e-05,
      "loss": 0.0026,
      "step": 4710
    },
    {
      "epoch": 0.13485714285714287,
      "grad_norm": 0.043826401233673096,
      "learning_rate": 4.6628571428571434e-05,
      "loss": 0.001,
      "step": 4720
    },
    {
      "epoch": 0.13514285714285715,
      "grad_norm": 0.21750450134277344,
      "learning_rate": 4.662142857142857e-05,
      "loss": 0.0029,
      "step": 4730
    },
    {
      "epoch": 0.13542857142857143,
      "grad_norm": 0.13079075515270233,
      "learning_rate": 4.661428571428572e-05,
      "loss": 0.0017,
      "step": 4740
    },
    {
      "epoch": 0.1357142857142857,
      "grad_norm": 0.13909143209457397,
      "learning_rate": 4.660714285714286e-05,
      "loss": 0.0016,
      "step": 4750
    },
    {
      "epoch": 0.136,
      "grad_norm": 0.06397472321987152,
      "learning_rate": 4.660000000000001e-05,
      "loss": 0.0016,
      "step": 4760
    },
    {
      "epoch": 0.1362857142857143,
      "grad_norm": 0.11519724130630493,
      "learning_rate": 4.659285714285714e-05,
      "loss": 0.0023,
      "step": 4770
    },
    {
      "epoch": 0.13657142857142857,
      "grad_norm": 0.04495327174663544,
      "learning_rate": 4.658571428571429e-05,
      "loss": 0.0008,
      "step": 4780
    },
    {
      "epoch": 0.13685714285714284,
      "grad_norm": 0.0,
      "learning_rate": 4.657857142857143e-05,
      "loss": 0.0008,
      "step": 4790
    },
    {
      "epoch": 0.13714285714285715,
      "grad_norm": 0.01845897175371647,
      "learning_rate": 4.6571428571428575e-05,
      "loss": 0.0016,
      "step": 4800
    },
    {
      "epoch": 0.13742857142857143,
      "grad_norm": 0.1686626672744751,
      "learning_rate": 4.6564285714285716e-05,
      "loss": 0.0014,
      "step": 4810
    },
    {
      "epoch": 0.1377142857142857,
      "grad_norm": 0.043612539768218994,
      "learning_rate": 4.655714285714286e-05,
      "loss": 0.0025,
      "step": 4820
    },
    {
      "epoch": 0.138,
      "grad_norm": 0.07259734719991684,
      "learning_rate": 4.655000000000001e-05,
      "loss": 0.0014,
      "step": 4830
    },
    {
      "epoch": 0.1382857142857143,
      "grad_norm": 0.08461911231279373,
      "learning_rate": 4.654285714285714e-05,
      "loss": 0.0016,
      "step": 4840
    },
    {
      "epoch": 0.13857142857142857,
      "grad_norm": 0.3728161156177521,
      "learning_rate": 4.653571428571429e-05,
      "loss": 0.0032,
      "step": 4850
    },
    {
      "epoch": 0.13885714285714285,
      "grad_norm": 0.12438777834177017,
      "learning_rate": 4.652857142857143e-05,
      "loss": 0.0016,
      "step": 4860
    },
    {
      "epoch": 0.13914285714285715,
      "grad_norm": 0.21832603216171265,
      "learning_rate": 4.6521428571428573e-05,
      "loss": 0.003,
      "step": 4870
    },
    {
      "epoch": 0.13942857142857143,
      "grad_norm": 0.040967490524053574,
      "learning_rate": 4.6514285714285715e-05,
      "loss": 0.0016,
      "step": 4880
    },
    {
      "epoch": 0.1397142857142857,
      "grad_norm": 0.09873341023921967,
      "learning_rate": 4.650714285714286e-05,
      "loss": 0.002,
      "step": 4890
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.04356228932738304,
      "learning_rate": 4.6500000000000005e-05,
      "loss": 0.0022,
      "step": 4900
    },
    {
      "epoch": 0.1402857142857143,
      "grad_norm": 0.19536536931991577,
      "learning_rate": 4.649285714285714e-05,
      "loss": 0.0019,
      "step": 4910
    },
    {
      "epoch": 0.14057142857142857,
      "grad_norm": 0.047053538262844086,
      "learning_rate": 4.648571428571429e-05,
      "loss": 0.0024,
      "step": 4920
    },
    {
      "epoch": 0.14085714285714285,
      "grad_norm": 0.07617704570293427,
      "learning_rate": 4.647857142857143e-05,
      "loss": 0.0018,
      "step": 4930
    },
    {
      "epoch": 0.14114285714285715,
      "grad_norm": 0.13233590126037598,
      "learning_rate": 4.647142857142857e-05,
      "loss": 0.0017,
      "step": 4940
    },
    {
      "epoch": 0.14142857142857143,
      "grad_norm": 0.19511708617210388,
      "learning_rate": 4.6464285714285714e-05,
      "loss": 0.0015,
      "step": 4950
    },
    {
      "epoch": 0.1417142857142857,
      "grad_norm": 0.08095021545886993,
      "learning_rate": 4.645714285714286e-05,
      "loss": 0.0015,
      "step": 4960
    },
    {
      "epoch": 0.142,
      "grad_norm": 0.10342438519001007,
      "learning_rate": 4.6450000000000004e-05,
      "loss": 0.0022,
      "step": 4970
    },
    {
      "epoch": 0.1422857142857143,
      "grad_norm": 0.045748770236968994,
      "learning_rate": 4.6442857142857146e-05,
      "loss": 0.002,
      "step": 4980
    },
    {
      "epoch": 0.14257142857142857,
      "grad_norm": 0.18635228276252747,
      "learning_rate": 4.643571428571429e-05,
      "loss": 0.0026,
      "step": 4990
    },
    {
      "epoch": 0.14285714285714285,
      "grad_norm": 0.04531585052609444,
      "learning_rate": 4.642857142857143e-05,
      "loss": 0.0016,
      "step": 5000
    },
    {
      "epoch": 0.14314285714285716,
      "grad_norm": 0.0,
      "learning_rate": 4.642142857142857e-05,
      "loss": 0.0014,
      "step": 5010
    },
    {
      "epoch": 0.14342857142857143,
      "grad_norm": 0.05612548813223839,
      "learning_rate": 4.641428571428571e-05,
      "loss": 0.0017,
      "step": 5020
    },
    {
      "epoch": 0.1437142857142857,
      "grad_norm": 0.162197545170784,
      "learning_rate": 4.640714285714286e-05,
      "loss": 0.0019,
      "step": 5030
    },
    {
      "epoch": 0.144,
      "grad_norm": 0.18380112946033478,
      "learning_rate": 4.64e-05,
      "loss": 0.0018,
      "step": 5040
    },
    {
      "epoch": 0.1442857142857143,
      "grad_norm": 0.09136610478162766,
      "learning_rate": 4.6392857142857145e-05,
      "loss": 0.0016,
      "step": 5050
    },
    {
      "epoch": 0.14457142857142857,
      "grad_norm": 0.0,
      "learning_rate": 4.6385714285714286e-05,
      "loss": 0.0016,
      "step": 5060
    },
    {
      "epoch": 0.14485714285714285,
      "grad_norm": 0.323908269405365,
      "learning_rate": 4.6378571428571435e-05,
      "loss": 0.0015,
      "step": 5070
    },
    {
      "epoch": 0.14514285714285713,
      "grad_norm": 0.0,
      "learning_rate": 4.637142857142857e-05,
      "loss": 0.002,
      "step": 5080
    },
    {
      "epoch": 0.14542857142857143,
      "grad_norm": 0.05250774323940277,
      "learning_rate": 4.636428571428572e-05,
      "loss": 0.0011,
      "step": 5090
    },
    {
      "epoch": 0.1457142857142857,
      "grad_norm": 0.07240442931652069,
      "learning_rate": 4.635714285714286e-05,
      "loss": 0.003,
      "step": 5100
    },
    {
      "epoch": 0.146,
      "grad_norm": 0.2713005244731903,
      "learning_rate": 4.635e-05,
      "loss": 0.003,
      "step": 5110
    },
    {
      "epoch": 0.1462857142857143,
      "grad_norm": 0.0,
      "learning_rate": 4.6342857142857143e-05,
      "loss": 0.0015,
      "step": 5120
    },
    {
      "epoch": 0.14657142857142857,
      "grad_norm": 0.18509455025196075,
      "learning_rate": 4.6335714285714285e-05,
      "loss": 0.0023,
      "step": 5130
    },
    {
      "epoch": 0.14685714285714285,
      "grad_norm": 0.039840687066316605,
      "learning_rate": 4.6328571428571434e-05,
      "loss": 0.0018,
      "step": 5140
    },
    {
      "epoch": 0.14714285714285713,
      "grad_norm": 0.07576427608728409,
      "learning_rate": 4.632142857142857e-05,
      "loss": 0.0013,
      "step": 5150
    },
    {
      "epoch": 0.14742857142857144,
      "grad_norm": 0.21565859019756317,
      "learning_rate": 4.631428571428572e-05,
      "loss": 0.0016,
      "step": 5160
    },
    {
      "epoch": 0.14771428571428571,
      "grad_norm": 0.07412633299827576,
      "learning_rate": 4.630714285714286e-05,
      "loss": 0.0011,
      "step": 5170
    },
    {
      "epoch": 0.148,
      "grad_norm": 0.17500555515289307,
      "learning_rate": 4.630000000000001e-05,
      "loss": 0.0027,
      "step": 5180
    },
    {
      "epoch": 0.1482857142857143,
      "grad_norm": 0.0,
      "learning_rate": 4.629285714285714e-05,
      "loss": 0.0018,
      "step": 5190
    },
    {
      "epoch": 0.14857142857142858,
      "grad_norm": 0.06321905553340912,
      "learning_rate": 4.628571428571429e-05,
      "loss": 0.0015,
      "step": 5200
    },
    {
      "epoch": 0.14885714285714285,
      "grad_norm": 0.22001953423023224,
      "learning_rate": 4.627857142857143e-05,
      "loss": 0.0014,
      "step": 5210
    },
    {
      "epoch": 0.14914285714285713,
      "grad_norm": 0.15465469658374786,
      "learning_rate": 4.6271428571428574e-05,
      "loss": 0.0018,
      "step": 5220
    },
    {
      "epoch": 0.14942857142857144,
      "grad_norm": 0.10362992435693741,
      "learning_rate": 4.6264285714285716e-05,
      "loss": 0.0018,
      "step": 5230
    },
    {
      "epoch": 0.14971428571428572,
      "grad_norm": 0.13133665919303894,
      "learning_rate": 4.625714285714286e-05,
      "loss": 0.0021,
      "step": 5240
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.06226879730820656,
      "learning_rate": 4.6250000000000006e-05,
      "loss": 0.0012,
      "step": 5250
    },
    {
      "epoch": 0.15028571428571427,
      "grad_norm": 0.07123889029026031,
      "learning_rate": 4.624285714285714e-05,
      "loss": 0.0014,
      "step": 5260
    },
    {
      "epoch": 0.15057142857142858,
      "grad_norm": 0.1686531901359558,
      "learning_rate": 4.623571428571429e-05,
      "loss": 0.0018,
      "step": 5270
    },
    {
      "epoch": 0.15085714285714286,
      "grad_norm": 0.015572557225823402,
      "learning_rate": 4.622857142857143e-05,
      "loss": 0.0018,
      "step": 5280
    },
    {
      "epoch": 0.15114285714285713,
      "grad_norm": 0.24730193614959717,
      "learning_rate": 4.622142857142857e-05,
      "loss": 0.0028,
      "step": 5290
    },
    {
      "epoch": 0.15142857142857144,
      "grad_norm": 0.1714232861995697,
      "learning_rate": 4.6214285714285715e-05,
      "loss": 0.0017,
      "step": 5300
    },
    {
      "epoch": 0.15171428571428572,
      "grad_norm": 0.07873763144016266,
      "learning_rate": 4.620714285714286e-05,
      "loss": 0.0017,
      "step": 5310
    },
    {
      "epoch": 0.152,
      "grad_norm": 0.10296525061130524,
      "learning_rate": 4.6200000000000005e-05,
      "loss": 0.0023,
      "step": 5320
    },
    {
      "epoch": 0.15228571428571427,
      "grad_norm": 0.06824701279401779,
      "learning_rate": 4.619285714285715e-05,
      "loss": 0.0025,
      "step": 5330
    },
    {
      "epoch": 0.15257142857142858,
      "grad_norm": 0.04268824681639671,
      "learning_rate": 4.618571428571429e-05,
      "loss": 0.0019,
      "step": 5340
    },
    {
      "epoch": 0.15285714285714286,
      "grad_norm": 0.049130700528621674,
      "learning_rate": 4.617857142857143e-05,
      "loss": 0.002,
      "step": 5350
    },
    {
      "epoch": 0.15314285714285714,
      "grad_norm": 0.24490907788276672,
      "learning_rate": 4.617142857142857e-05,
      "loss": 0.001,
      "step": 5360
    },
    {
      "epoch": 0.15342857142857144,
      "grad_norm": 0.07843493670225143,
      "learning_rate": 4.6164285714285713e-05,
      "loss": 0.002,
      "step": 5370
    },
    {
      "epoch": 0.15371428571428572,
      "grad_norm": 0.04345141351222992,
      "learning_rate": 4.615714285714286e-05,
      "loss": 0.0009,
      "step": 5380
    },
    {
      "epoch": 0.154,
      "grad_norm": 0.08855515718460083,
      "learning_rate": 4.6150000000000004e-05,
      "loss": 0.0023,
      "step": 5390
    },
    {
      "epoch": 0.15428571428571428,
      "grad_norm": 0.18491484224796295,
      "learning_rate": 4.6142857142857145e-05,
      "loss": 0.0017,
      "step": 5400
    },
    {
      "epoch": 0.15457142857142858,
      "grad_norm": 0.30907049775123596,
      "learning_rate": 4.613571428571429e-05,
      "loss": 0.0012,
      "step": 5410
    },
    {
      "epoch": 0.15485714285714286,
      "grad_norm": 0.14908146858215332,
      "learning_rate": 4.612857142857143e-05,
      "loss": 0.0018,
      "step": 5420
    },
    {
      "epoch": 0.15514285714285714,
      "grad_norm": 0.1455337107181549,
      "learning_rate": 4.612142857142857e-05,
      "loss": 0.0017,
      "step": 5430
    },
    {
      "epoch": 0.15542857142857142,
      "grad_norm": 0.10804527997970581,
      "learning_rate": 4.611428571428571e-05,
      "loss": 0.0022,
      "step": 5440
    },
    {
      "epoch": 0.15571428571428572,
      "grad_norm": 0.0,
      "learning_rate": 4.610714285714286e-05,
      "loss": 0.0013,
      "step": 5450
    },
    {
      "epoch": 0.156,
      "grad_norm": 0.10710576176643372,
      "learning_rate": 4.61e-05,
      "loss": 0.0017,
      "step": 5460
    },
    {
      "epoch": 0.15628571428571428,
      "grad_norm": 0.1127329096198082,
      "learning_rate": 4.6092857142857144e-05,
      "loss": 0.0016,
      "step": 5470
    },
    {
      "epoch": 0.15657142857142858,
      "grad_norm": 0.06399989128112793,
      "learning_rate": 4.6085714285714286e-05,
      "loss": 0.0006,
      "step": 5480
    },
    {
      "epoch": 0.15685714285714286,
      "grad_norm": 0.12681585550308228,
      "learning_rate": 4.6078571428571434e-05,
      "loss": 0.0007,
      "step": 5490
    },
    {
      "epoch": 0.15714285714285714,
      "grad_norm": 0.15629155933856964,
      "learning_rate": 4.607142857142857e-05,
      "loss": 0.0022,
      "step": 5500
    },
    {
      "epoch": 0.15742857142857142,
      "grad_norm": 0.1621372401714325,
      "learning_rate": 4.606428571428572e-05,
      "loss": 0.0027,
      "step": 5510
    },
    {
      "epoch": 0.15771428571428572,
      "grad_norm": 0.10158916562795639,
      "learning_rate": 4.605714285714286e-05,
      "loss": 0.0023,
      "step": 5520
    },
    {
      "epoch": 0.158,
      "grad_norm": 0.12651897966861725,
      "learning_rate": 4.605e-05,
      "loss": 0.0007,
      "step": 5530
    },
    {
      "epoch": 0.15828571428571428,
      "grad_norm": 0.1363464593887329,
      "learning_rate": 4.604285714285714e-05,
      "loss": 0.0017,
      "step": 5540
    },
    {
      "epoch": 0.15857142857142856,
      "grad_norm": 0.22464005649089813,
      "learning_rate": 4.6035714285714285e-05,
      "loss": 0.0007,
      "step": 5550
    },
    {
      "epoch": 0.15885714285714286,
      "grad_norm": 0.2799260914325714,
      "learning_rate": 4.602857142857143e-05,
      "loss": 0.0017,
      "step": 5560
    },
    {
      "epoch": 0.15914285714285714,
      "grad_norm": 0.0854031965136528,
      "learning_rate": 4.602142857142857e-05,
      "loss": 0.0023,
      "step": 5570
    },
    {
      "epoch": 0.15942857142857142,
      "grad_norm": 0.08549492061138153,
      "learning_rate": 4.6014285714285717e-05,
      "loss": 0.0017,
      "step": 5580
    },
    {
      "epoch": 0.15971428571428573,
      "grad_norm": 0.20651324093341827,
      "learning_rate": 4.600714285714286e-05,
      "loss": 0.0031,
      "step": 5590
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.040631525218486786,
      "learning_rate": 4.600000000000001e-05,
      "loss": 0.002,
      "step": 5600
    },
    {
      "epoch": 0.16028571428571428,
      "grad_norm": 0.12663906812667847,
      "learning_rate": 4.599285714285714e-05,
      "loss": 0.0014,
      "step": 5610
    },
    {
      "epoch": 0.16057142857142856,
      "grad_norm": 0.0,
      "learning_rate": 4.598571428571429e-05,
      "loss": 0.0027,
      "step": 5620
    },
    {
      "epoch": 0.16085714285714287,
      "grad_norm": 0.04342512786388397,
      "learning_rate": 4.597857142857143e-05,
      "loss": 0.0015,
      "step": 5630
    },
    {
      "epoch": 0.16114285714285714,
      "grad_norm": 0.09436208754777908,
      "learning_rate": 4.5971428571428574e-05,
      "loss": 0.0028,
      "step": 5640
    },
    {
      "epoch": 0.16142857142857142,
      "grad_norm": 0.05528150871396065,
      "learning_rate": 4.5964285714285715e-05,
      "loss": 0.0017,
      "step": 5650
    },
    {
      "epoch": 0.16171428571428573,
      "grad_norm": 0.1944826990365982,
      "learning_rate": 4.595714285714286e-05,
      "loss": 0.0019,
      "step": 5660
    },
    {
      "epoch": 0.162,
      "grad_norm": 0.031448155641555786,
      "learning_rate": 4.5950000000000006e-05,
      "loss": 0.0015,
      "step": 5670
    },
    {
      "epoch": 0.16228571428571428,
      "grad_norm": 0.13699211180210114,
      "learning_rate": 4.594285714285714e-05,
      "loss": 0.0017,
      "step": 5680
    },
    {
      "epoch": 0.16257142857142856,
      "grad_norm": 0.20168015360832214,
      "learning_rate": 4.593571428571429e-05,
      "loss": 0.0016,
      "step": 5690
    },
    {
      "epoch": 0.16285714285714287,
      "grad_norm": 0.0,
      "learning_rate": 4.592857142857143e-05,
      "loss": 0.0022,
      "step": 5700
    },
    {
      "epoch": 0.16314285714285715,
      "grad_norm": 0.0347302183508873,
      "learning_rate": 4.592142857142858e-05,
      "loss": 0.0014,
      "step": 5710
    },
    {
      "epoch": 0.16342857142857142,
      "grad_norm": 0.0632607489824295,
      "learning_rate": 4.5914285714285714e-05,
      "loss": 0.0016,
      "step": 5720
    },
    {
      "epoch": 0.1637142857142857,
      "grad_norm": 0.08329463750123978,
      "learning_rate": 4.590714285714286e-05,
      "loss": 0.0017,
      "step": 5730
    },
    {
      "epoch": 0.164,
      "grad_norm": 0.04578237235546112,
      "learning_rate": 4.5900000000000004e-05,
      "loss": 0.0021,
      "step": 5740
    },
    {
      "epoch": 0.16428571428571428,
      "grad_norm": 0.0784212201833725,
      "learning_rate": 4.5892857142857146e-05,
      "loss": 0.0022,
      "step": 5750
    },
    {
      "epoch": 0.16457142857142856,
      "grad_norm": 0.14446142315864563,
      "learning_rate": 4.588571428571429e-05,
      "loss": 0.0022,
      "step": 5760
    },
    {
      "epoch": 0.16485714285714287,
      "grad_norm": 0.13195626437664032,
      "learning_rate": 4.587857142857143e-05,
      "loss": 0.0024,
      "step": 5770
    },
    {
      "epoch": 0.16514285714285715,
      "grad_norm": 0.08207795023918152,
      "learning_rate": 4.587142857142858e-05,
      "loss": 0.0016,
      "step": 5780
    },
    {
      "epoch": 0.16542857142857142,
      "grad_norm": 0.27062076330184937,
      "learning_rate": 4.586428571428571e-05,
      "loss": 0.0021,
      "step": 5790
    },
    {
      "epoch": 0.1657142857142857,
      "grad_norm": 0.11530110239982605,
      "learning_rate": 4.585714285714286e-05,
      "loss": 0.0034,
      "step": 5800
    },
    {
      "epoch": 0.166,
      "grad_norm": 0.12426315993070602,
      "learning_rate": 4.585e-05,
      "loss": 0.0015,
      "step": 5810
    },
    {
      "epoch": 0.1662857142857143,
      "grad_norm": 0.0489167645573616,
      "learning_rate": 4.5842857142857145e-05,
      "loss": 0.0017,
      "step": 5820
    },
    {
      "epoch": 0.16657142857142856,
      "grad_norm": 0.10520215332508087,
      "learning_rate": 4.5835714285714287e-05,
      "loss": 0.0015,
      "step": 5830
    },
    {
      "epoch": 0.16685714285714287,
      "grad_norm": 0.12871646881103516,
      "learning_rate": 4.5828571428571435e-05,
      "loss": 0.0015,
      "step": 5840
    },
    {
      "epoch": 0.16714285714285715,
      "grad_norm": 0.12058135122060776,
      "learning_rate": 4.582142857142858e-05,
      "loss": 0.0023,
      "step": 5850
    },
    {
      "epoch": 0.16742857142857143,
      "grad_norm": 0.1691521555185318,
      "learning_rate": 4.581428571428572e-05,
      "loss": 0.003,
      "step": 5860
    },
    {
      "epoch": 0.1677142857142857,
      "grad_norm": 0.23924599587917328,
      "learning_rate": 4.580714285714286e-05,
      "loss": 0.0021,
      "step": 5870
    },
    {
      "epoch": 0.168,
      "grad_norm": 0.08826082944869995,
      "learning_rate": 4.58e-05,
      "loss": 0.0019,
      "step": 5880
    },
    {
      "epoch": 0.1682857142857143,
      "grad_norm": 0.042293477803468704,
      "learning_rate": 4.5792857142857144e-05,
      "loss": 0.001,
      "step": 5890
    },
    {
      "epoch": 0.16857142857142857,
      "grad_norm": 0.056707073003053665,
      "learning_rate": 4.5785714285714285e-05,
      "loss": 0.0017,
      "step": 5900
    },
    {
      "epoch": 0.16885714285714284,
      "grad_norm": 0.17542432248592377,
      "learning_rate": 4.5778571428571434e-05,
      "loss": 0.0019,
      "step": 5910
    },
    {
      "epoch": 0.16914285714285715,
      "grad_norm": 0.29786285758018494,
      "learning_rate": 4.5771428571428576e-05,
      "loss": 0.0026,
      "step": 5920
    },
    {
      "epoch": 0.16942857142857143,
      "grad_norm": 0.15734367072582245,
      "learning_rate": 4.576428571428572e-05,
      "loss": 0.0017,
      "step": 5930
    },
    {
      "epoch": 0.1697142857142857,
      "grad_norm": 0.19944019615650177,
      "learning_rate": 4.575714285714286e-05,
      "loss": 0.0028,
      "step": 5940
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.058013901114463806,
      "learning_rate": 4.575e-05,
      "loss": 0.0008,
      "step": 5950
    },
    {
      "epoch": 0.1702857142857143,
      "grad_norm": 0.11932196468114853,
      "learning_rate": 4.574285714285714e-05,
      "loss": 0.0009,
      "step": 5960
    },
    {
      "epoch": 0.17057142857142857,
      "grad_norm": 0.08860956877470016,
      "learning_rate": 4.5735714285714284e-05,
      "loss": 0.002,
      "step": 5970
    },
    {
      "epoch": 0.17085714285714285,
      "grad_norm": 0.0,
      "learning_rate": 4.572857142857143e-05,
      "loss": 0.001,
      "step": 5980
    },
    {
      "epoch": 0.17114285714285715,
      "grad_norm": 0.02839011140167713,
      "learning_rate": 4.5721428571428574e-05,
      "loss": 0.0017,
      "step": 5990
    },
    {
      "epoch": 0.17142857142857143,
      "grad_norm": 0.04778585582971573,
      "learning_rate": 4.5714285714285716e-05,
      "loss": 0.0026,
      "step": 6000
    },
    {
      "epoch": 0.1717142857142857,
      "grad_norm": 0.08576327562332153,
      "learning_rate": 4.570714285714286e-05,
      "loss": 0.0009,
      "step": 6010
    },
    {
      "epoch": 0.172,
      "grad_norm": 0.04629264026880264,
      "learning_rate": 4.5700000000000006e-05,
      "loss": 0.0019,
      "step": 6020
    },
    {
      "epoch": 0.1722857142857143,
      "grad_norm": 0.045104872435331345,
      "learning_rate": 4.569285714285714e-05,
      "loss": 0.001,
      "step": 6030
    },
    {
      "epoch": 0.17257142857142857,
      "grad_norm": 0.04319889843463898,
      "learning_rate": 4.568571428571429e-05,
      "loss": 0.0015,
      "step": 6040
    },
    {
      "epoch": 0.17285714285714285,
      "grad_norm": 0.07693380117416382,
      "learning_rate": 4.567857142857143e-05,
      "loss": 0.0017,
      "step": 6050
    },
    {
      "epoch": 0.17314285714285715,
      "grad_norm": 0.1530310958623886,
      "learning_rate": 4.567142857142857e-05,
      "loss": 0.0025,
      "step": 6060
    },
    {
      "epoch": 0.17342857142857143,
      "grad_norm": 0.13962121307849884,
      "learning_rate": 4.5664285714285715e-05,
      "loss": 0.0011,
      "step": 6070
    },
    {
      "epoch": 0.1737142857142857,
      "grad_norm": 0.03809026628732681,
      "learning_rate": 4.5657142857142857e-05,
      "loss": 0.0017,
      "step": 6080
    },
    {
      "epoch": 0.174,
      "grad_norm": 0.0,
      "learning_rate": 4.5650000000000005e-05,
      "loss": 0.0019,
      "step": 6090
    },
    {
      "epoch": 0.1742857142857143,
      "grad_norm": 0.045516885817050934,
      "learning_rate": 4.564285714285714e-05,
      "loss": 0.0013,
      "step": 6100
    },
    {
      "epoch": 0.17457142857142857,
      "grad_norm": 0.184347465634346,
      "learning_rate": 4.563571428571429e-05,
      "loss": 0.001,
      "step": 6110
    },
    {
      "epoch": 0.17485714285714285,
      "grad_norm": 0.23457692563533783,
      "learning_rate": 4.562857142857143e-05,
      "loss": 0.0032,
      "step": 6120
    },
    {
      "epoch": 0.17514285714285716,
      "grad_norm": 0.13198581337928772,
      "learning_rate": 4.562142857142858e-05,
      "loss": 0.0022,
      "step": 6130
    },
    {
      "epoch": 0.17542857142857143,
      "grad_norm": 0.07478807121515274,
      "learning_rate": 4.5614285714285714e-05,
      "loss": 0.0012,
      "step": 6140
    },
    {
      "epoch": 0.1757142857142857,
      "grad_norm": 0.0,
      "learning_rate": 4.560714285714286e-05,
      "loss": 0.0023,
      "step": 6150
    },
    {
      "epoch": 0.176,
      "grad_norm": 0.26306283473968506,
      "learning_rate": 4.5600000000000004e-05,
      "loss": 0.003,
      "step": 6160
    },
    {
      "epoch": 0.1762857142857143,
      "grad_norm": 0.1929580718278885,
      "learning_rate": 4.5592857142857146e-05,
      "loss": 0.0016,
      "step": 6170
    },
    {
      "epoch": 0.17657142857142857,
      "grad_norm": 0.07740379869937897,
      "learning_rate": 4.558571428571429e-05,
      "loss": 0.0025,
      "step": 6180
    },
    {
      "epoch": 0.17685714285714285,
      "grad_norm": 0.0844108909368515,
      "learning_rate": 4.557857142857143e-05,
      "loss": 0.0012,
      "step": 6190
    },
    {
      "epoch": 0.17714285714285713,
      "grad_norm": 0.13222342729568481,
      "learning_rate": 4.557142857142858e-05,
      "loss": 0.001,
      "step": 6200
    },
    {
      "epoch": 0.17742857142857144,
      "grad_norm": 0.11611192673444748,
      "learning_rate": 4.556428571428571e-05,
      "loss": 0.0016,
      "step": 6210
    },
    {
      "epoch": 0.1777142857142857,
      "grad_norm": 0.16619214415550232,
      "learning_rate": 4.555714285714286e-05,
      "loss": 0.0024,
      "step": 6220
    },
    {
      "epoch": 0.178,
      "grad_norm": 0.2934296727180481,
      "learning_rate": 4.555e-05,
      "loss": 0.0017,
      "step": 6230
    },
    {
      "epoch": 0.1782857142857143,
      "grad_norm": 0.05004855617880821,
      "learning_rate": 4.5542857142857144e-05,
      "loss": 0.001,
      "step": 6240
    },
    {
      "epoch": 0.17857142857142858,
      "grad_norm": 0.20227859914302826,
      "learning_rate": 4.5535714285714286e-05,
      "loss": 0.0024,
      "step": 6250
    },
    {
      "epoch": 0.17885714285714285,
      "grad_norm": 0.13171052932739258,
      "learning_rate": 4.5528571428571435e-05,
      "loss": 0.0021,
      "step": 6260
    },
    {
      "epoch": 0.17914285714285713,
      "grad_norm": 0.07994498312473297,
      "learning_rate": 4.5521428571428576e-05,
      "loss": 0.0017,
      "step": 6270
    },
    {
      "epoch": 0.17942857142857144,
      "grad_norm": 0.08396341651678085,
      "learning_rate": 4.551428571428572e-05,
      "loss": 0.0012,
      "step": 6280
    },
    {
      "epoch": 0.17971428571428572,
      "grad_norm": 0.05735333636403084,
      "learning_rate": 4.550714285714286e-05,
      "loss": 0.0013,
      "step": 6290
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.08587915450334549,
      "learning_rate": 4.55e-05,
      "loss": 0.0021,
      "step": 6300
    },
    {
      "epoch": 0.1802857142857143,
      "grad_norm": 0.1285753697156906,
      "learning_rate": 4.549285714285714e-05,
      "loss": 0.0016,
      "step": 6310
    },
    {
      "epoch": 0.18057142857142858,
      "grad_norm": 0.05744561180472374,
      "learning_rate": 4.5485714285714285e-05,
      "loss": 0.0022,
      "step": 6320
    },
    {
      "epoch": 0.18085714285714286,
      "grad_norm": 0.07406201958656311,
      "learning_rate": 4.547857142857143e-05,
      "loss": 0.0013,
      "step": 6330
    },
    {
      "epoch": 0.18114285714285713,
      "grad_norm": 0.05883915349841118,
      "learning_rate": 4.5471428571428575e-05,
      "loss": 0.001,
      "step": 6340
    },
    {
      "epoch": 0.18142857142857144,
      "grad_norm": 0.0,
      "learning_rate": 4.546428571428572e-05,
      "loss": 0.0023,
      "step": 6350
    },
    {
      "epoch": 0.18171428571428572,
      "grad_norm": 0.06587819010019302,
      "learning_rate": 4.545714285714286e-05,
      "loss": 0.002,
      "step": 6360
    },
    {
      "epoch": 0.182,
      "grad_norm": 0.23642407357692719,
      "learning_rate": 4.545000000000001e-05,
      "loss": 0.0017,
      "step": 6370
    },
    {
      "epoch": 0.18228571428571427,
      "grad_norm": 0.0,
      "learning_rate": 4.544285714285714e-05,
      "loss": 0.0018,
      "step": 6380
    },
    {
      "epoch": 0.18257142857142858,
      "grad_norm": 0.18205879628658295,
      "learning_rate": 4.5435714285714284e-05,
      "loss": 0.0015,
      "step": 6390
    },
    {
      "epoch": 0.18285714285714286,
      "grad_norm": 0.09493745118379593,
      "learning_rate": 4.542857142857143e-05,
      "loss": 0.0021,
      "step": 6400
    },
    {
      "epoch": 0.18314285714285714,
      "grad_norm": 0.0,
      "learning_rate": 4.5421428571428574e-05,
      "loss": 0.0009,
      "step": 6410
    },
    {
      "epoch": 0.18342857142857144,
      "grad_norm": 0.04620850086212158,
      "learning_rate": 4.5414285714285716e-05,
      "loss": 0.0012,
      "step": 6420
    },
    {
      "epoch": 0.18371428571428572,
      "grad_norm": 0.042495787143707275,
      "learning_rate": 4.540714285714286e-05,
      "loss": 0.002,
      "step": 6430
    },
    {
      "epoch": 0.184,
      "grad_norm": 0.3523293435573578,
      "learning_rate": 4.5400000000000006e-05,
      "loss": 0.0029,
      "step": 6440
    },
    {
      "epoch": 0.18428571428571427,
      "grad_norm": 0.0,
      "learning_rate": 4.539285714285714e-05,
      "loss": 0.0023,
      "step": 6450
    },
    {
      "epoch": 0.18457142857142858,
      "grad_norm": 0.024901017546653748,
      "learning_rate": 4.538571428571429e-05,
      "loss": 0.0017,
      "step": 6460
    },
    {
      "epoch": 0.18485714285714286,
      "grad_norm": 0.2247992306947708,
      "learning_rate": 4.537857142857143e-05,
      "loss": 0.0017,
      "step": 6470
    },
    {
      "epoch": 0.18514285714285714,
      "grad_norm": 0.14092643558979034,
      "learning_rate": 4.537142857142857e-05,
      "loss": 0.0014,
      "step": 6480
    },
    {
      "epoch": 0.18542857142857141,
      "grad_norm": 0.09309261292219162,
      "learning_rate": 4.5364285714285714e-05,
      "loss": 0.0022,
      "step": 6490
    },
    {
      "epoch": 0.18571428571428572,
      "grad_norm": 0.03997797518968582,
      "learning_rate": 4.5357142857142856e-05,
      "loss": 0.002,
      "step": 6500
    },
    {
      "epoch": 0.186,
      "grad_norm": 0.054857343435287476,
      "learning_rate": 4.5350000000000005e-05,
      "loss": 0.0011,
      "step": 6510
    },
    {
      "epoch": 0.18628571428571428,
      "grad_norm": 0.0,
      "learning_rate": 4.534285714285714e-05,
      "loss": 0.0011,
      "step": 6520
    },
    {
      "epoch": 0.18657142857142858,
      "grad_norm": 0.08536027371883392,
      "learning_rate": 4.533571428571429e-05,
      "loss": 0.0027,
      "step": 6530
    },
    {
      "epoch": 0.18685714285714286,
      "grad_norm": 0.23260967433452606,
      "learning_rate": 4.532857142857143e-05,
      "loss": 0.003,
      "step": 6540
    },
    {
      "epoch": 0.18714285714285714,
      "grad_norm": 0.048936162143945694,
      "learning_rate": 4.532142857142858e-05,
      "loss": 0.001,
      "step": 6550
    },
    {
      "epoch": 0.18742857142857142,
      "grad_norm": 0.11447233706712723,
      "learning_rate": 4.531428571428571e-05,
      "loss": 0.0013,
      "step": 6560
    },
    {
      "epoch": 0.18771428571428572,
      "grad_norm": 0.05057763680815697,
      "learning_rate": 4.530714285714286e-05,
      "loss": 0.0017,
      "step": 6570
    },
    {
      "epoch": 0.188,
      "grad_norm": 0.0,
      "learning_rate": 4.53e-05,
      "loss": 0.0019,
      "step": 6580
    },
    {
      "epoch": 0.18828571428571428,
      "grad_norm": 0.12809067964553833,
      "learning_rate": 4.5292857142857145e-05,
      "loss": 0.001,
      "step": 6590
    },
    {
      "epoch": 0.18857142857142858,
      "grad_norm": 0.13255584239959717,
      "learning_rate": 4.528571428571429e-05,
      "loss": 0.0017,
      "step": 6600
    },
    {
      "epoch": 0.18885714285714286,
      "grad_norm": 0.20475229620933533,
      "learning_rate": 4.527857142857143e-05,
      "loss": 0.0024,
      "step": 6610
    },
    {
      "epoch": 0.18914285714285714,
      "grad_norm": 0.25808319449424744,
      "learning_rate": 4.527142857142858e-05,
      "loss": 0.0024,
      "step": 6620
    },
    {
      "epoch": 0.18942857142857142,
      "grad_norm": 0.06372993439435959,
      "learning_rate": 4.526428571428571e-05,
      "loss": 0.0015,
      "step": 6630
    },
    {
      "epoch": 0.18971428571428572,
      "grad_norm": 0.0,
      "learning_rate": 4.525714285714286e-05,
      "loss": 0.0018,
      "step": 6640
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.043351542204618454,
      "learning_rate": 4.525e-05,
      "loss": 0.0005,
      "step": 6650
    },
    {
      "epoch": 0.19028571428571428,
      "grad_norm": 0.0,
      "learning_rate": 4.5242857142857144e-05,
      "loss": 0.0011,
      "step": 6660
    },
    {
      "epoch": 0.19057142857142856,
      "grad_norm": 0.0,
      "learning_rate": 4.5235714285714286e-05,
      "loss": 0.0012,
      "step": 6670
    },
    {
      "epoch": 0.19085714285714286,
      "grad_norm": 0.17337074875831604,
      "learning_rate": 4.5228571428571434e-05,
      "loss": 0.002,
      "step": 6680
    },
    {
      "epoch": 0.19114285714285714,
      "grad_norm": 0.23642337322235107,
      "learning_rate": 4.5221428571428576e-05,
      "loss": 0.0018,
      "step": 6690
    },
    {
      "epoch": 0.19142857142857142,
      "grad_norm": 0.24476879835128784,
      "learning_rate": 4.521428571428572e-05,
      "loss": 0.0018,
      "step": 6700
    },
    {
      "epoch": 0.19171428571428573,
      "grad_norm": 0.08083269745111465,
      "learning_rate": 4.520714285714286e-05,
      "loss": 0.0017,
      "step": 6710
    },
    {
      "epoch": 0.192,
      "grad_norm": 0.10103696584701538,
      "learning_rate": 4.52e-05,
      "loss": 0.0032,
      "step": 6720
    },
    {
      "epoch": 0.19228571428571428,
      "grad_norm": 0.1274407058954239,
      "learning_rate": 4.519285714285714e-05,
      "loss": 0.0012,
      "step": 6730
    },
    {
      "epoch": 0.19257142857142856,
      "grad_norm": 0.12122265994548798,
      "learning_rate": 4.5185714285714284e-05,
      "loss": 0.0018,
      "step": 6740
    },
    {
      "epoch": 0.19285714285714287,
      "grad_norm": 0.13190914690494537,
      "learning_rate": 4.517857142857143e-05,
      "loss": 0.0012,
      "step": 6750
    },
    {
      "epoch": 0.19314285714285714,
      "grad_norm": 0.04745263233780861,
      "learning_rate": 4.5171428571428575e-05,
      "loss": 0.0028,
      "step": 6760
    },
    {
      "epoch": 0.19342857142857142,
      "grad_norm": 0.11859802901744843,
      "learning_rate": 4.5164285714285716e-05,
      "loss": 0.0013,
      "step": 6770
    },
    {
      "epoch": 0.19371428571428573,
      "grad_norm": 0.22303788363933563,
      "learning_rate": 4.515714285714286e-05,
      "loss": 0.0019,
      "step": 6780
    },
    {
      "epoch": 0.194,
      "grad_norm": 0.09833429008722305,
      "learning_rate": 4.5150000000000006e-05,
      "loss": 0.0009,
      "step": 6790
    },
    {
      "epoch": 0.19428571428571428,
      "grad_norm": 0.1208493784070015,
      "learning_rate": 4.514285714285714e-05,
      "loss": 0.0024,
      "step": 6800
    },
    {
      "epoch": 0.19457142857142856,
      "grad_norm": 0.0534592904150486,
      "learning_rate": 4.513571428571429e-05,
      "loss": 0.0008,
      "step": 6810
    },
    {
      "epoch": 0.19485714285714287,
      "grad_norm": 0.19479885697364807,
      "learning_rate": 4.512857142857143e-05,
      "loss": 0.0022,
      "step": 6820
    },
    {
      "epoch": 0.19514285714285715,
      "grad_norm": 0.04324240982532501,
      "learning_rate": 4.512142857142857e-05,
      "loss": 0.001,
      "step": 6830
    },
    {
      "epoch": 0.19542857142857142,
      "grad_norm": 0.0,
      "learning_rate": 4.5114285714285715e-05,
      "loss": 0.0012,
      "step": 6840
    },
    {
      "epoch": 0.1957142857142857,
      "grad_norm": 0.0,
      "learning_rate": 4.510714285714286e-05,
      "loss": 0.0025,
      "step": 6850
    },
    {
      "epoch": 0.196,
      "grad_norm": 0.09279700368642807,
      "learning_rate": 4.5100000000000005e-05,
      "loss": 0.0018,
      "step": 6860
    },
    {
      "epoch": 0.19628571428571429,
      "grad_norm": 0.09601034224033356,
      "learning_rate": 4.509285714285714e-05,
      "loss": 0.0018,
      "step": 6870
    },
    {
      "epoch": 0.19657142857142856,
      "grad_norm": 0.1635570526123047,
      "learning_rate": 4.508571428571429e-05,
      "loss": 0.0026,
      "step": 6880
    },
    {
      "epoch": 0.19685714285714287,
      "grad_norm": 0.19033919274806976,
      "learning_rate": 4.507857142857143e-05,
      "loss": 0.0026,
      "step": 6890
    },
    {
      "epoch": 0.19714285714285715,
      "grad_norm": 0.28810566663742065,
      "learning_rate": 4.507142857142858e-05,
      "loss": 0.0024,
      "step": 6900
    },
    {
      "epoch": 0.19742857142857143,
      "grad_norm": 0.08175459504127502,
      "learning_rate": 4.5064285714285714e-05,
      "loss": 0.0014,
      "step": 6910
    },
    {
      "epoch": 0.1977142857142857,
      "grad_norm": 0.12491965293884277,
      "learning_rate": 4.5057142857142856e-05,
      "loss": 0.0021,
      "step": 6920
    },
    {
      "epoch": 0.198,
      "grad_norm": 0.0,
      "learning_rate": 4.5050000000000004e-05,
      "loss": 0.0013,
      "step": 6930
    },
    {
      "epoch": 0.1982857142857143,
      "grad_norm": 0.12317156791687012,
      "learning_rate": 4.5042857142857146e-05,
      "loss": 0.0019,
      "step": 6940
    },
    {
      "epoch": 0.19857142857142857,
      "grad_norm": 0.0972830131649971,
      "learning_rate": 4.503571428571429e-05,
      "loss": 0.0028,
      "step": 6950
    },
    {
      "epoch": 0.19885714285714284,
      "grad_norm": 0.1574040651321411,
      "learning_rate": 4.502857142857143e-05,
      "loss": 0.0014,
      "step": 6960
    },
    {
      "epoch": 0.19914285714285715,
      "grad_norm": 0.13310128450393677,
      "learning_rate": 4.502142857142858e-05,
      "loss": 0.0009,
      "step": 6970
    },
    {
      "epoch": 0.19942857142857143,
      "grad_norm": 0.11416979879140854,
      "learning_rate": 4.501428571428571e-05,
      "loss": 0.0021,
      "step": 6980
    },
    {
      "epoch": 0.1997142857142857,
      "grad_norm": 0.0414857342839241,
      "learning_rate": 4.500714285714286e-05,
      "loss": 0.0018,
      "step": 6990
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.18851353228092194,
      "learning_rate": 4.5e-05,
      "loss": 0.0026,
      "step": 7000
    },
    {
      "epoch": 0.2002857142857143,
      "grad_norm": 0.2685549557209015,
      "learning_rate": 4.4992857142857145e-05,
      "loss": 0.0025,
      "step": 7010
    },
    {
      "epoch": 0.20057142857142857,
      "grad_norm": 0.17838121950626373,
      "learning_rate": 4.4985714285714286e-05,
      "loss": 0.0034,
      "step": 7020
    },
    {
      "epoch": 0.20085714285714285,
      "grad_norm": 0.17924010753631592,
      "learning_rate": 4.497857142857143e-05,
      "loss": 0.0028,
      "step": 7030
    },
    {
      "epoch": 0.20114285714285715,
      "grad_norm": 0.23299124836921692,
      "learning_rate": 4.4971428571428576e-05,
      "loss": 0.0033,
      "step": 7040
    },
    {
      "epoch": 0.20142857142857143,
      "grad_norm": 0.23259872198104858,
      "learning_rate": 4.496428571428571e-05,
      "loss": 0.0015,
      "step": 7050
    },
    {
      "epoch": 0.2017142857142857,
      "grad_norm": 0.10542947053909302,
      "learning_rate": 4.495714285714286e-05,
      "loss": 0.0025,
      "step": 7060
    },
    {
      "epoch": 0.202,
      "grad_norm": 0.10854438692331314,
      "learning_rate": 4.495e-05,
      "loss": 0.0029,
      "step": 7070
    },
    {
      "epoch": 0.2022857142857143,
      "grad_norm": 0.08729857951402664,
      "learning_rate": 4.494285714285715e-05,
      "loss": 0.0026,
      "step": 7080
    },
    {
      "epoch": 0.20257142857142857,
      "grad_norm": 0.0,
      "learning_rate": 4.4935714285714285e-05,
      "loss": 0.0018,
      "step": 7090
    },
    {
      "epoch": 0.20285714285714285,
      "grad_norm": 0.1949780136346817,
      "learning_rate": 4.4928571428571434e-05,
      "loss": 0.0023,
      "step": 7100
    },
    {
      "epoch": 0.20314285714285715,
      "grad_norm": 0.1764245182275772,
      "learning_rate": 4.4921428571428575e-05,
      "loss": 0.0025,
      "step": 7110
    },
    {
      "epoch": 0.20342857142857143,
      "grad_norm": 0.23869211971759796,
      "learning_rate": 4.491428571428572e-05,
      "loss": 0.0018,
      "step": 7120
    },
    {
      "epoch": 0.2037142857142857,
      "grad_norm": 0.23464106023311615,
      "learning_rate": 4.490714285714286e-05,
      "loss": 0.001,
      "step": 7130
    },
    {
      "epoch": 0.204,
      "grad_norm": 0.06802991777658463,
      "learning_rate": 4.49e-05,
      "loss": 0.0019,
      "step": 7140
    },
    {
      "epoch": 0.2042857142857143,
      "grad_norm": 0.1493154764175415,
      "learning_rate": 4.489285714285715e-05,
      "loss": 0.0025,
      "step": 7150
    },
    {
      "epoch": 0.20457142857142857,
      "grad_norm": 0.16202384233474731,
      "learning_rate": 4.4885714285714284e-05,
      "loss": 0.0024,
      "step": 7160
    },
    {
      "epoch": 0.20485714285714285,
      "grad_norm": 0.04718980938196182,
      "learning_rate": 4.487857142857143e-05,
      "loss": 0.0017,
      "step": 7170
    },
    {
      "epoch": 0.20514285714285715,
      "grad_norm": 0.04666445776820183,
      "learning_rate": 4.4871428571428574e-05,
      "loss": 0.0019,
      "step": 7180
    },
    {
      "epoch": 0.20542857142857143,
      "grad_norm": 0.13806897401809692,
      "learning_rate": 4.4864285714285716e-05,
      "loss": 0.0015,
      "step": 7190
    },
    {
      "epoch": 0.2057142857142857,
      "grad_norm": 0.23213979601860046,
      "learning_rate": 4.485714285714286e-05,
      "loss": 0.0015,
      "step": 7200
    },
    {
      "epoch": 0.206,
      "grad_norm": 0.03157316893339157,
      "learning_rate": 4.4850000000000006e-05,
      "loss": 0.002,
      "step": 7210
    },
    {
      "epoch": 0.2062857142857143,
      "grad_norm": 0.08237321674823761,
      "learning_rate": 4.484285714285715e-05,
      "loss": 0.0014,
      "step": 7220
    },
    {
      "epoch": 0.20657142857142857,
      "grad_norm": 0.0438598170876503,
      "learning_rate": 4.483571428571429e-05,
      "loss": 0.0022,
      "step": 7230
    },
    {
      "epoch": 0.20685714285714285,
      "grad_norm": 0.0,
      "learning_rate": 4.482857142857143e-05,
      "loss": 0.0015,
      "step": 7240
    },
    {
      "epoch": 0.20714285714285716,
      "grad_norm": 0.04108912870287895,
      "learning_rate": 4.482142857142857e-05,
      "loss": 0.0016,
      "step": 7250
    },
    {
      "epoch": 0.20742857142857143,
      "grad_norm": 0.04975642263889313,
      "learning_rate": 4.4814285714285715e-05,
      "loss": 0.0019,
      "step": 7260
    },
    {
      "epoch": 0.2077142857142857,
      "grad_norm": 0.04059336334466934,
      "learning_rate": 4.4807142857142856e-05,
      "loss": 0.0022,
      "step": 7270
    },
    {
      "epoch": 0.208,
      "grad_norm": 0.08993712812662125,
      "learning_rate": 4.4800000000000005e-05,
      "loss": 0.0032,
      "step": 7280
    },
    {
      "epoch": 0.2082857142857143,
      "grad_norm": 0.09912022203207016,
      "learning_rate": 4.4792857142857146e-05,
      "loss": 0.0018,
      "step": 7290
    },
    {
      "epoch": 0.20857142857142857,
      "grad_norm": 0.11354406177997589,
      "learning_rate": 4.478571428571429e-05,
      "loss": 0.0016,
      "step": 7300
    },
    {
      "epoch": 0.20885714285714285,
      "grad_norm": 0.23633253574371338,
      "learning_rate": 4.477857142857143e-05,
      "loss": 0.0026,
      "step": 7310
    },
    {
      "epoch": 0.20914285714285713,
      "grad_norm": 0.12008266896009445,
      "learning_rate": 4.477142857142858e-05,
      "loss": 0.001,
      "step": 7320
    },
    {
      "epoch": 0.20942857142857144,
      "grad_norm": 0.2180614471435547,
      "learning_rate": 4.476428571428571e-05,
      "loss": 0.0026,
      "step": 7330
    },
    {
      "epoch": 0.20971428571428571,
      "grad_norm": 0.2250114232301712,
      "learning_rate": 4.475714285714286e-05,
      "loss": 0.0016,
      "step": 7340
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.05013252794742584,
      "learning_rate": 4.4750000000000004e-05,
      "loss": 0.0011,
      "step": 7350
    },
    {
      "epoch": 0.2102857142857143,
      "grad_norm": 0.0,
      "learning_rate": 4.4742857142857145e-05,
      "loss": 0.0014,
      "step": 7360
    },
    {
      "epoch": 0.21057142857142858,
      "grad_norm": 0.04712149128317833,
      "learning_rate": 4.473571428571429e-05,
      "loss": 0.0016,
      "step": 7370
    },
    {
      "epoch": 0.21085714285714285,
      "grad_norm": 0.041056644171476364,
      "learning_rate": 4.472857142857143e-05,
      "loss": 0.0009,
      "step": 7380
    },
    {
      "epoch": 0.21114285714285713,
      "grad_norm": 0.0827745869755745,
      "learning_rate": 4.472142857142858e-05,
      "loss": 0.0013,
      "step": 7390
    },
    {
      "epoch": 0.21142857142857144,
      "grad_norm": 0.03276495635509491,
      "learning_rate": 4.471428571428571e-05,
      "loss": 0.0031,
      "step": 7400
    },
    {
      "epoch": 0.21171428571428572,
      "grad_norm": 0.041702620685100555,
      "learning_rate": 4.470714285714286e-05,
      "loss": 0.0017,
      "step": 7410
    },
    {
      "epoch": 0.212,
      "grad_norm": 0.08359406143426895,
      "learning_rate": 4.47e-05,
      "loss": 0.0012,
      "step": 7420
    },
    {
      "epoch": 0.21228571428571427,
      "grad_norm": 0.09352049976587296,
      "learning_rate": 4.469285714285715e-05,
      "loss": 0.0015,
      "step": 7430
    },
    {
      "epoch": 0.21257142857142858,
      "grad_norm": 0.08196866512298584,
      "learning_rate": 4.4685714285714286e-05,
      "loss": 0.0021,
      "step": 7440
    },
    {
      "epoch": 0.21285714285714286,
      "grad_norm": 0.11327317357063293,
      "learning_rate": 4.467857142857143e-05,
      "loss": 0.0015,
      "step": 7450
    },
    {
      "epoch": 0.21314285714285713,
      "grad_norm": 0.0783095732331276,
      "learning_rate": 4.4671428571428576e-05,
      "loss": 0.0008,
      "step": 7460
    },
    {
      "epoch": 0.21342857142857144,
      "grad_norm": 0.04097656533122063,
      "learning_rate": 4.466428571428571e-05,
      "loss": 0.0012,
      "step": 7470
    },
    {
      "epoch": 0.21371428571428572,
      "grad_norm": 0.14367437362670898,
      "learning_rate": 4.465714285714286e-05,
      "loss": 0.0025,
      "step": 7480
    },
    {
      "epoch": 0.214,
      "grad_norm": 0.04381655156612396,
      "learning_rate": 4.465e-05,
      "loss": 0.002,
      "step": 7490
    },
    {
      "epoch": 0.21428571428571427,
      "grad_norm": 0.17004097998142242,
      "learning_rate": 4.464285714285715e-05,
      "loss": 0.0023,
      "step": 7500
    },
    {
      "epoch": 0.21457142857142858,
      "grad_norm": 0.22147351503372192,
      "learning_rate": 4.4635714285714285e-05,
      "loss": 0.0021,
      "step": 7510
    },
    {
      "epoch": 0.21485714285714286,
      "grad_norm": 0.07888547331094742,
      "learning_rate": 4.462857142857143e-05,
      "loss": 0.0026,
      "step": 7520
    },
    {
      "epoch": 0.21514285714285714,
      "grad_norm": 0.14818258583545685,
      "learning_rate": 4.4621428571428575e-05,
      "loss": 0.002,
      "step": 7530
    },
    {
      "epoch": 0.21542857142857144,
      "grad_norm": 0.09337925165891647,
      "learning_rate": 4.4614285714285716e-05,
      "loss": 0.0017,
      "step": 7540
    },
    {
      "epoch": 0.21571428571428572,
      "grad_norm": 0.0445837639272213,
      "learning_rate": 4.460714285714286e-05,
      "loss": 0.0023,
      "step": 7550
    },
    {
      "epoch": 0.216,
      "grad_norm": 0.04294668883085251,
      "learning_rate": 4.46e-05,
      "loss": 0.0014,
      "step": 7560
    },
    {
      "epoch": 0.21628571428571428,
      "grad_norm": 0.03196899965405464,
      "learning_rate": 4.459285714285715e-05,
      "loss": 0.0009,
      "step": 7570
    },
    {
      "epoch": 0.21657142857142858,
      "grad_norm": 0.03197332099080086,
      "learning_rate": 4.458571428571428e-05,
      "loss": 0.0016,
      "step": 7580
    },
    {
      "epoch": 0.21685714285714286,
      "grad_norm": 0.041221510618925095,
      "learning_rate": 4.457857142857143e-05,
      "loss": 0.0025,
      "step": 7590
    },
    {
      "epoch": 0.21714285714285714,
      "grad_norm": 0.07907207310199738,
      "learning_rate": 4.4571428571428574e-05,
      "loss": 0.0028,
      "step": 7600
    },
    {
      "epoch": 0.21742857142857142,
      "grad_norm": 0.04062609747052193,
      "learning_rate": 4.4564285714285715e-05,
      "loss": 0.0017,
      "step": 7610
    },
    {
      "epoch": 0.21771428571428572,
      "grad_norm": 0.16275064647197723,
      "learning_rate": 4.455714285714286e-05,
      "loss": 0.0017,
      "step": 7620
    },
    {
      "epoch": 0.218,
      "grad_norm": 0.04799487814307213,
      "learning_rate": 4.4550000000000005e-05,
      "loss": 0.0024,
      "step": 7630
    },
    {
      "epoch": 0.21828571428571428,
      "grad_norm": 0.04902629926800728,
      "learning_rate": 4.454285714285715e-05,
      "loss": 0.0022,
      "step": 7640
    },
    {
      "epoch": 0.21857142857142858,
      "grad_norm": 0.03374104201793671,
      "learning_rate": 4.453571428571429e-05,
      "loss": 0.0021,
      "step": 7650
    },
    {
      "epoch": 0.21885714285714286,
      "grad_norm": 0.13631218671798706,
      "learning_rate": 4.452857142857143e-05,
      "loss": 0.0013,
      "step": 7660
    },
    {
      "epoch": 0.21914285714285714,
      "grad_norm": 0.0881836861371994,
      "learning_rate": 4.452142857142857e-05,
      "loss": 0.0015,
      "step": 7670
    },
    {
      "epoch": 0.21942857142857142,
      "grad_norm": 0.15293191373348236,
      "learning_rate": 4.4514285714285714e-05,
      "loss": 0.0021,
      "step": 7680
    },
    {
      "epoch": 0.21971428571428572,
      "grad_norm": 0.07198654860258102,
      "learning_rate": 4.4507142857142856e-05,
      "loss": 0.002,
      "step": 7690
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.03701939806342125,
      "learning_rate": 4.4500000000000004e-05,
      "loss": 0.0017,
      "step": 7700
    },
    {
      "epoch": 0.22028571428571428,
      "grad_norm": 0.19726815819740295,
      "learning_rate": 4.4492857142857146e-05,
      "loss": 0.0022,
      "step": 7710
    },
    {
      "epoch": 0.22057142857142858,
      "grad_norm": 0.042345672845840454,
      "learning_rate": 4.448571428571429e-05,
      "loss": 0.0008,
      "step": 7720
    },
    {
      "epoch": 0.22085714285714286,
      "grad_norm": 0.0954524576663971,
      "learning_rate": 4.447857142857143e-05,
      "loss": 0.0014,
      "step": 7730
    },
    {
      "epoch": 0.22114285714285714,
      "grad_norm": 0.15478187799453735,
      "learning_rate": 4.447142857142858e-05,
      "loss": 0.0014,
      "step": 7740
    },
    {
      "epoch": 0.22142857142857142,
      "grad_norm": 0.036940090358257294,
      "learning_rate": 4.446428571428571e-05,
      "loss": 0.0017,
      "step": 7750
    },
    {
      "epoch": 0.22171428571428572,
      "grad_norm": 0.20274442434310913,
      "learning_rate": 4.445714285714286e-05,
      "loss": 0.0023,
      "step": 7760
    },
    {
      "epoch": 0.222,
      "grad_norm": 0.17609085142612457,
      "learning_rate": 4.445e-05,
      "loss": 0.0015,
      "step": 7770
    },
    {
      "epoch": 0.22228571428571428,
      "grad_norm": 0.05150783434510231,
      "learning_rate": 4.4442857142857145e-05,
      "loss": 0.002,
      "step": 7780
    },
    {
      "epoch": 0.22257142857142856,
      "grad_norm": 0.026677614077925682,
      "learning_rate": 4.4435714285714286e-05,
      "loss": 0.0016,
      "step": 7790
    },
    {
      "epoch": 0.22285714285714286,
      "grad_norm": 0.1352306455373764,
      "learning_rate": 4.442857142857143e-05,
      "loss": 0.0028,
      "step": 7800
    },
    {
      "epoch": 0.22314285714285714,
      "grad_norm": 0.0,
      "learning_rate": 4.442142857142858e-05,
      "loss": 0.0013,
      "step": 7810
    },
    {
      "epoch": 0.22342857142857142,
      "grad_norm": 0.3434183597564697,
      "learning_rate": 4.441428571428571e-05,
      "loss": 0.0019,
      "step": 7820
    },
    {
      "epoch": 0.22371428571428573,
      "grad_norm": 0.12574045360088348,
      "learning_rate": 4.440714285714286e-05,
      "loss": 0.0021,
      "step": 7830
    },
    {
      "epoch": 0.224,
      "grad_norm": 0.053111542016267776,
      "learning_rate": 4.44e-05,
      "loss": 0.0012,
      "step": 7840
    },
    {
      "epoch": 0.22428571428571428,
      "grad_norm": 0.22145894169807434,
      "learning_rate": 4.439285714285715e-05,
      "loss": 0.0016,
      "step": 7850
    },
    {
      "epoch": 0.22457142857142856,
      "grad_norm": 0.045156221836805344,
      "learning_rate": 4.4385714285714285e-05,
      "loss": 0.0025,
      "step": 7860
    },
    {
      "epoch": 0.22485714285714287,
      "grad_norm": 0.047807756811380386,
      "learning_rate": 4.4378571428571434e-05,
      "loss": 0.0025,
      "step": 7870
    },
    {
      "epoch": 0.22514285714285714,
      "grad_norm": 0.08246809989213943,
      "learning_rate": 4.4371428571428575e-05,
      "loss": 0.0023,
      "step": 7880
    },
    {
      "epoch": 0.22542857142857142,
      "grad_norm": 0.2984786629676819,
      "learning_rate": 4.436428571428572e-05,
      "loss": 0.0018,
      "step": 7890
    },
    {
      "epoch": 0.2257142857142857,
      "grad_norm": 0.16463692486286163,
      "learning_rate": 4.435714285714286e-05,
      "loss": 0.0015,
      "step": 7900
    },
    {
      "epoch": 0.226,
      "grad_norm": 0.0,
      "learning_rate": 4.435e-05,
      "loss": 0.0009,
      "step": 7910
    },
    {
      "epoch": 0.22628571428571428,
      "grad_norm": 0.0,
      "learning_rate": 4.434285714285715e-05,
      "loss": 0.0016,
      "step": 7920
    },
    {
      "epoch": 0.22657142857142856,
      "grad_norm": 0.10687080770730972,
      "learning_rate": 4.4335714285714284e-05,
      "loss": 0.001,
      "step": 7930
    },
    {
      "epoch": 0.22685714285714287,
      "grad_norm": 0.0,
      "learning_rate": 4.432857142857143e-05,
      "loss": 0.0015,
      "step": 7940
    },
    {
      "epoch": 0.22714285714285715,
      "grad_norm": 0.0479155071079731,
      "learning_rate": 4.4321428571428574e-05,
      "loss": 0.0014,
      "step": 7950
    },
    {
      "epoch": 0.22742857142857142,
      "grad_norm": 0.09066040068864822,
      "learning_rate": 4.4314285714285716e-05,
      "loss": 0.0013,
      "step": 7960
    },
    {
      "epoch": 0.2277142857142857,
      "grad_norm": 0.08235155791044235,
      "learning_rate": 4.430714285714286e-05,
      "loss": 0.0022,
      "step": 7970
    },
    {
      "epoch": 0.228,
      "grad_norm": 0.19729666411876678,
      "learning_rate": 4.43e-05,
      "loss": 0.0016,
      "step": 7980
    },
    {
      "epoch": 0.2282857142857143,
      "grad_norm": 0.11873867362737656,
      "learning_rate": 4.429285714285715e-05,
      "loss": 0.0018,
      "step": 7990
    },
    {
      "epoch": 0.22857142857142856,
      "grad_norm": 0.04894676059484482,
      "learning_rate": 4.428571428571428e-05,
      "loss": 0.0016,
      "step": 8000
    },
    {
      "epoch": 0.22885714285714287,
      "grad_norm": 0.1669946163892746,
      "learning_rate": 4.427857142857143e-05,
      "loss": 0.002,
      "step": 8010
    },
    {
      "epoch": 0.22914285714285715,
      "grad_norm": 0.10740543901920319,
      "learning_rate": 4.427142857142857e-05,
      "loss": 0.001,
      "step": 8020
    },
    {
      "epoch": 0.22942857142857143,
      "grad_norm": 0.18460413813591003,
      "learning_rate": 4.4264285714285715e-05,
      "loss": 0.0035,
      "step": 8030
    },
    {
      "epoch": 0.2297142857142857,
      "grad_norm": 0.0,
      "learning_rate": 4.4257142857142856e-05,
      "loss": 0.0022,
      "step": 8040
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.12137935310602188,
      "learning_rate": 4.4250000000000005e-05,
      "loss": 0.0024,
      "step": 8050
    },
    {
      "epoch": 0.2302857142857143,
      "grad_norm": 0.13302962481975555,
      "learning_rate": 4.424285714285715e-05,
      "loss": 0.003,
      "step": 8060
    },
    {
      "epoch": 0.23057142857142857,
      "grad_norm": 0.05395889654755592,
      "learning_rate": 4.423571428571429e-05,
      "loss": 0.0019,
      "step": 8070
    },
    {
      "epoch": 0.23085714285714284,
      "grad_norm": 0.04506613686680794,
      "learning_rate": 4.422857142857143e-05,
      "loss": 0.0042,
      "step": 8080
    },
    {
      "epoch": 0.23114285714285715,
      "grad_norm": 0.06044257804751396,
      "learning_rate": 4.422142857142857e-05,
      "loss": 0.0011,
      "step": 8090
    },
    {
      "epoch": 0.23142857142857143,
      "grad_norm": 0.18662294745445251,
      "learning_rate": 4.4214285714285714e-05,
      "loss": 0.0016,
      "step": 8100
    },
    {
      "epoch": 0.2317142857142857,
      "grad_norm": 0.3080928325653076,
      "learning_rate": 4.4207142857142855e-05,
      "loss": 0.0031,
      "step": 8110
    },
    {
      "epoch": 0.232,
      "grad_norm": 0.045755986124277115,
      "learning_rate": 4.4200000000000004e-05,
      "loss": 0.0027,
      "step": 8120
    },
    {
      "epoch": 0.2322857142857143,
      "grad_norm": 0.04988335818052292,
      "learning_rate": 4.4192857142857145e-05,
      "loss": 0.0007,
      "step": 8130
    },
    {
      "epoch": 0.23257142857142857,
      "grad_norm": 0.0,
      "learning_rate": 4.418571428571429e-05,
      "loss": 0.0016,
      "step": 8140
    },
    {
      "epoch": 0.23285714285714285,
      "grad_norm": 0.04569404199719429,
      "learning_rate": 4.417857142857143e-05,
      "loss": 0.0017,
      "step": 8150
    },
    {
      "epoch": 0.23314285714285715,
      "grad_norm": 0.1897958219051361,
      "learning_rate": 4.417142857142858e-05,
      "loss": 0.0017,
      "step": 8160
    },
    {
      "epoch": 0.23342857142857143,
      "grad_norm": 0.06285188347101212,
      "learning_rate": 4.416428571428572e-05,
      "loss": 0.002,
      "step": 8170
    },
    {
      "epoch": 0.2337142857142857,
      "grad_norm": 0.1210038810968399,
      "learning_rate": 4.415714285714286e-05,
      "loss": 0.0008,
      "step": 8180
    },
    {
      "epoch": 0.234,
      "grad_norm": 0.05232298746705055,
      "learning_rate": 4.415e-05,
      "loss": 0.0013,
      "step": 8190
    },
    {
      "epoch": 0.2342857142857143,
      "grad_norm": 0.0,
      "learning_rate": 4.4142857142857144e-05,
      "loss": 0.0022,
      "step": 8200
    },
    {
      "epoch": 0.23457142857142857,
      "grad_norm": 0.2391567975282669,
      "learning_rate": 4.4135714285714286e-05,
      "loss": 0.0017,
      "step": 8210
    },
    {
      "epoch": 0.23485714285714285,
      "grad_norm": 0.05032794550061226,
      "learning_rate": 4.412857142857143e-05,
      "loss": 0.0011,
      "step": 8220
    },
    {
      "epoch": 0.23514285714285715,
      "grad_norm": 0.20865757763385773,
      "learning_rate": 4.4121428571428576e-05,
      "loss": 0.0025,
      "step": 8230
    },
    {
      "epoch": 0.23542857142857143,
      "grad_norm": 0.21093116700649261,
      "learning_rate": 4.411428571428572e-05,
      "loss": 0.0015,
      "step": 8240
    },
    {
      "epoch": 0.2357142857142857,
      "grad_norm": 0.31481653451919556,
      "learning_rate": 4.410714285714286e-05,
      "loss": 0.001,
      "step": 8250
    },
    {
      "epoch": 0.236,
      "grad_norm": 0.24833981692790985,
      "learning_rate": 4.41e-05,
      "loss": 0.0016,
      "step": 8260
    },
    {
      "epoch": 0.2362857142857143,
      "grad_norm": 0.13705162703990936,
      "learning_rate": 4.409285714285715e-05,
      "loss": 0.002,
      "step": 8270
    },
    {
      "epoch": 0.23657142857142857,
      "grad_norm": 0.3009003698825836,
      "learning_rate": 4.4085714285714285e-05,
      "loss": 0.0024,
      "step": 8280
    },
    {
      "epoch": 0.23685714285714285,
      "grad_norm": 0.07712099701166153,
      "learning_rate": 4.407857142857143e-05,
      "loss": 0.0025,
      "step": 8290
    },
    {
      "epoch": 0.23714285714285716,
      "grad_norm": 0.1334078311920166,
      "learning_rate": 4.4071428571428575e-05,
      "loss": 0.0018,
      "step": 8300
    },
    {
      "epoch": 0.23742857142857143,
      "grad_norm": 0.25080782175064087,
      "learning_rate": 4.406428571428572e-05,
      "loss": 0.0022,
      "step": 8310
    },
    {
      "epoch": 0.2377142857142857,
      "grad_norm": 0.12170843780040741,
      "learning_rate": 4.405714285714286e-05,
      "loss": 0.0019,
      "step": 8320
    },
    {
      "epoch": 0.238,
      "grad_norm": 0.2985185980796814,
      "learning_rate": 4.405e-05,
      "loss": 0.0027,
      "step": 8330
    },
    {
      "epoch": 0.2382857142857143,
      "grad_norm": 0.05250188708305359,
      "learning_rate": 4.404285714285715e-05,
      "loss": 0.0014,
      "step": 8340
    },
    {
      "epoch": 0.23857142857142857,
      "grad_norm": 0.050270237028598785,
      "learning_rate": 4.4035714285714284e-05,
      "loss": 0.0017,
      "step": 8350
    },
    {
      "epoch": 0.23885714285714285,
      "grad_norm": 0.0,
      "learning_rate": 4.402857142857143e-05,
      "loss": 0.001,
      "step": 8360
    },
    {
      "epoch": 0.23914285714285713,
      "grad_norm": 0.04434498772025108,
      "learning_rate": 4.4021428571428574e-05,
      "loss": 0.0016,
      "step": 8370
    },
    {
      "epoch": 0.23942857142857144,
      "grad_norm": 0.1271316558122635,
      "learning_rate": 4.401428571428572e-05,
      "loss": 0.001,
      "step": 8380
    },
    {
      "epoch": 0.2397142857142857,
      "grad_norm": 0.21815787255764008,
      "learning_rate": 4.400714285714286e-05,
      "loss": 0.0023,
      "step": 8390
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.04169168323278427,
      "learning_rate": 4.4000000000000006e-05,
      "loss": 0.0015,
      "step": 8400
    },
    {
      "epoch": 0.2402857142857143,
      "grad_norm": 0.041926100850105286,
      "learning_rate": 4.399285714285715e-05,
      "loss": 0.0014,
      "step": 8410
    },
    {
      "epoch": 0.24057142857142857,
      "grad_norm": 0.1828482747077942,
      "learning_rate": 4.398571428571428e-05,
      "loss": 0.0017,
      "step": 8420
    },
    {
      "epoch": 0.24085714285714285,
      "grad_norm": 0.07873737812042236,
      "learning_rate": 4.397857142857143e-05,
      "loss": 0.0012,
      "step": 8430
    },
    {
      "epoch": 0.24114285714285713,
      "grad_norm": 0.04536339268088341,
      "learning_rate": 4.397142857142857e-05,
      "loss": 0.0007,
      "step": 8440
    },
    {
      "epoch": 0.24142857142857144,
      "grad_norm": 0.0544113926589489,
      "learning_rate": 4.396428571428572e-05,
      "loss": 0.0016,
      "step": 8450
    },
    {
      "epoch": 0.24171428571428571,
      "grad_norm": 0.0,
      "learning_rate": 4.3957142857142856e-05,
      "loss": 0.0016,
      "step": 8460
    },
    {
      "epoch": 0.242,
      "grad_norm": 0.20849287509918213,
      "learning_rate": 4.3950000000000004e-05,
      "loss": 0.0015,
      "step": 8470
    },
    {
      "epoch": 0.2422857142857143,
      "grad_norm": 0.04371204599738121,
      "learning_rate": 4.3942857142857146e-05,
      "loss": 0.0015,
      "step": 8480
    },
    {
      "epoch": 0.24257142857142858,
      "grad_norm": 0.08782904595136642,
      "learning_rate": 4.393571428571429e-05,
      "loss": 0.0018,
      "step": 8490
    },
    {
      "epoch": 0.24285714285714285,
      "grad_norm": 0.04616311192512512,
      "learning_rate": 4.392857142857143e-05,
      "loss": 0.0019,
      "step": 8500
    },
    {
      "epoch": 0.24314285714285713,
      "grad_norm": 0.03729262202978134,
      "learning_rate": 4.392142857142857e-05,
      "loss": 0.0022,
      "step": 8510
    },
    {
      "epoch": 0.24342857142857144,
      "grad_norm": 0.051049407571554184,
      "learning_rate": 4.391428571428572e-05,
      "loss": 0.0005,
      "step": 8520
    },
    {
      "epoch": 0.24371428571428572,
      "grad_norm": 0.021467769518494606,
      "learning_rate": 4.3907142857142855e-05,
      "loss": 0.0025,
      "step": 8530
    },
    {
      "epoch": 0.244,
      "grad_norm": 0.04274189844727516,
      "learning_rate": 4.39e-05,
      "loss": 0.0012,
      "step": 8540
    },
    {
      "epoch": 0.24428571428571427,
      "grad_norm": 0.3572901785373688,
      "learning_rate": 4.3892857142857145e-05,
      "loss": 0.0012,
      "step": 8550
    },
    {
      "epoch": 0.24457142857142858,
      "grad_norm": 0.10768236964941025,
      "learning_rate": 4.388571428571429e-05,
      "loss": 0.0022,
      "step": 8560
    },
    {
      "epoch": 0.24485714285714286,
      "grad_norm": 0.16957144439220428,
      "learning_rate": 4.387857142857143e-05,
      "loss": 0.0004,
      "step": 8570
    },
    {
      "epoch": 0.24514285714285713,
      "grad_norm": 0.04245857521891594,
      "learning_rate": 4.387142857142858e-05,
      "loss": 0.0013,
      "step": 8580
    },
    {
      "epoch": 0.24542857142857144,
      "grad_norm": 0.04142642021179199,
      "learning_rate": 4.386428571428572e-05,
      "loss": 0.0017,
      "step": 8590
    },
    {
      "epoch": 0.24571428571428572,
      "grad_norm": 0.03282243385910988,
      "learning_rate": 4.385714285714286e-05,
      "loss": 0.0019,
      "step": 8600
    },
    {
      "epoch": 0.246,
      "grad_norm": 0.34773480892181396,
      "learning_rate": 4.385e-05,
      "loss": 0.0009,
      "step": 8610
    },
    {
      "epoch": 0.24628571428571427,
      "grad_norm": 0.0,
      "learning_rate": 4.3842857142857144e-05,
      "loss": 0.0024,
      "step": 8620
    },
    {
      "epoch": 0.24657142857142858,
      "grad_norm": 0.2467467188835144,
      "learning_rate": 4.3835714285714285e-05,
      "loss": 0.0022,
      "step": 8630
    },
    {
      "epoch": 0.24685714285714286,
      "grad_norm": 0.049978841096162796,
      "learning_rate": 4.382857142857143e-05,
      "loss": 0.0012,
      "step": 8640
    },
    {
      "epoch": 0.24714285714285714,
      "grad_norm": 0.04606065899133682,
      "learning_rate": 4.3821428571428576e-05,
      "loss": 0.0016,
      "step": 8650
    },
    {
      "epoch": 0.24742857142857144,
      "grad_norm": 0.15524165332317352,
      "learning_rate": 4.381428571428572e-05,
      "loss": 0.0017,
      "step": 8660
    },
    {
      "epoch": 0.24771428571428572,
      "grad_norm": 0.150590717792511,
      "learning_rate": 4.380714285714286e-05,
      "loss": 0.0018,
      "step": 8670
    },
    {
      "epoch": 0.248,
      "grad_norm": 0.07732155174016953,
      "learning_rate": 4.38e-05,
      "loss": 0.0032,
      "step": 8680
    },
    {
      "epoch": 0.24828571428571428,
      "grad_norm": 0.08054426312446594,
      "learning_rate": 4.379285714285715e-05,
      "loss": 0.0018,
      "step": 8690
    },
    {
      "epoch": 0.24857142857142858,
      "grad_norm": 0.1385687291622162,
      "learning_rate": 4.3785714285714284e-05,
      "loss": 0.0021,
      "step": 8700
    },
    {
      "epoch": 0.24885714285714286,
      "grad_norm": 0.19143015146255493,
      "learning_rate": 4.377857142857143e-05,
      "loss": 0.0017,
      "step": 8710
    },
    {
      "epoch": 0.24914285714285714,
      "grad_norm": 0.0,
      "learning_rate": 4.3771428571428574e-05,
      "loss": 0.0025,
      "step": 8720
    },
    {
      "epoch": 0.24942857142857142,
      "grad_norm": 0.16966493427753448,
      "learning_rate": 4.3764285714285716e-05,
      "loss": 0.0023,
      "step": 8730
    },
    {
      "epoch": 0.24971428571428572,
      "grad_norm": 0.1742265820503235,
      "learning_rate": 4.375714285714286e-05,
      "loss": 0.0021,
      "step": 8740
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.16146641969680786,
      "learning_rate": 4.375e-05,
      "loss": 0.0025,
      "step": 8750
    },
    {
      "epoch": 0.2502857142857143,
      "grad_norm": 0.07925345748662949,
      "learning_rate": 4.374285714285715e-05,
      "loss": 0.0021,
      "step": 8760
    },
    {
      "epoch": 0.25057142857142856,
      "grad_norm": 0.0,
      "learning_rate": 4.373571428571428e-05,
      "loss": 0.0015,
      "step": 8770
    },
    {
      "epoch": 0.25085714285714283,
      "grad_norm": 0.08599121868610382,
      "learning_rate": 4.372857142857143e-05,
      "loss": 0.0023,
      "step": 8780
    },
    {
      "epoch": 0.25114285714285717,
      "grad_norm": 0.08479460328817368,
      "learning_rate": 4.372142857142857e-05,
      "loss": 0.0012,
      "step": 8790
    },
    {
      "epoch": 0.25142857142857145,
      "grad_norm": 0.041133373975753784,
      "learning_rate": 4.371428571428572e-05,
      "loss": 0.002,
      "step": 8800
    },
    {
      "epoch": 0.2517142857142857,
      "grad_norm": 0.0415741428732872,
      "learning_rate": 4.370714285714286e-05,
      "loss": 0.0017,
      "step": 8810
    },
    {
      "epoch": 0.252,
      "grad_norm": 0.18862386047840118,
      "learning_rate": 4.3700000000000005e-05,
      "loss": 0.0021,
      "step": 8820
    },
    {
      "epoch": 0.2522857142857143,
      "grad_norm": 0.441316694021225,
      "learning_rate": 4.369285714285715e-05,
      "loss": 0.0021,
      "step": 8830
    },
    {
      "epoch": 0.25257142857142856,
      "grad_norm": 0.08555342257022858,
      "learning_rate": 4.368571428571429e-05,
      "loss": 0.002,
      "step": 8840
    },
    {
      "epoch": 0.25285714285714284,
      "grad_norm": 0.043633341789245605,
      "learning_rate": 4.367857142857143e-05,
      "loss": 0.0009,
      "step": 8850
    },
    {
      "epoch": 0.25314285714285717,
      "grad_norm": 0.22246743738651276,
      "learning_rate": 4.367142857142857e-05,
      "loss": 0.0015,
      "step": 8860
    },
    {
      "epoch": 0.25342857142857145,
      "grad_norm": 0.04147599637508392,
      "learning_rate": 4.366428571428572e-05,
      "loss": 0.0024,
      "step": 8870
    },
    {
      "epoch": 0.2537142857142857,
      "grad_norm": 0.11641038954257965,
      "learning_rate": 4.3657142857142855e-05,
      "loss": 0.0014,
      "step": 8880
    },
    {
      "epoch": 0.254,
      "grad_norm": 0.12074725329875946,
      "learning_rate": 4.3650000000000004e-05,
      "loss": 0.0014,
      "step": 8890
    },
    {
      "epoch": 0.2542857142857143,
      "grad_norm": 0.054197099059820175,
      "learning_rate": 4.3642857142857146e-05,
      "loss": 0.0017,
      "step": 8900
    },
    {
      "epoch": 0.25457142857142856,
      "grad_norm": 0.17054609954357147,
      "learning_rate": 4.363571428571429e-05,
      "loss": 0.0009,
      "step": 8910
    },
    {
      "epoch": 0.25485714285714284,
      "grad_norm": 0.09576286375522614,
      "learning_rate": 4.362857142857143e-05,
      "loss": 0.0024,
      "step": 8920
    },
    {
      "epoch": 0.2551428571428571,
      "grad_norm": 0.10513987392187119,
      "learning_rate": 4.362142857142858e-05,
      "loss": 0.002,
      "step": 8930
    },
    {
      "epoch": 0.25542857142857145,
      "grad_norm": 0.2076866775751114,
      "learning_rate": 4.361428571428572e-05,
      "loss": 0.0018,
      "step": 8940
    },
    {
      "epoch": 0.2557142857142857,
      "grad_norm": 0.21982523798942566,
      "learning_rate": 4.3607142857142854e-05,
      "loss": 0.0018,
      "step": 8950
    },
    {
      "epoch": 0.256,
      "grad_norm": 0.09046100825071335,
      "learning_rate": 4.36e-05,
      "loss": 0.0013,
      "step": 8960
    },
    {
      "epoch": 0.2562857142857143,
      "grad_norm": 0.054332319647073746,
      "learning_rate": 4.3592857142857144e-05,
      "loss": 0.0018,
      "step": 8970
    },
    {
      "epoch": 0.25657142857142856,
      "grad_norm": 0.0869254544377327,
      "learning_rate": 4.3585714285714286e-05,
      "loss": 0.0022,
      "step": 8980
    },
    {
      "epoch": 0.25685714285714284,
      "grad_norm": 0.21146860718727112,
      "learning_rate": 4.357857142857143e-05,
      "loss": 0.0026,
      "step": 8990
    },
    {
      "epoch": 0.2571428571428571,
      "grad_norm": 0.0,
      "learning_rate": 4.3571428571428576e-05,
      "loss": 0.0013,
      "step": 9000
    },
    {
      "epoch": 0.25742857142857145,
      "grad_norm": 0.0733640268445015,
      "learning_rate": 4.356428571428572e-05,
      "loss": 0.0022,
      "step": 9010
    },
    {
      "epoch": 0.25771428571428573,
      "grad_norm": 0.14875777065753937,
      "learning_rate": 4.355714285714286e-05,
      "loss": 0.002,
      "step": 9020
    },
    {
      "epoch": 0.258,
      "grad_norm": 0.10992617160081863,
      "learning_rate": 4.355e-05,
      "loss": 0.0016,
      "step": 9030
    },
    {
      "epoch": 0.2582857142857143,
      "grad_norm": 0.16672424972057343,
      "learning_rate": 4.354285714285714e-05,
      "loss": 0.0033,
      "step": 9040
    },
    {
      "epoch": 0.25857142857142856,
      "grad_norm": 0.04774361848831177,
      "learning_rate": 4.3535714285714285e-05,
      "loss": 0.0031,
      "step": 9050
    },
    {
      "epoch": 0.25885714285714284,
      "grad_norm": 0.046038493514060974,
      "learning_rate": 4.352857142857143e-05,
      "loss": 0.0019,
      "step": 9060
    },
    {
      "epoch": 0.2591428571428571,
      "grad_norm": 0.0,
      "learning_rate": 4.3521428571428575e-05,
      "loss": 0.0021,
      "step": 9070
    },
    {
      "epoch": 0.25942857142857145,
      "grad_norm": 0.1932247132062912,
      "learning_rate": 4.351428571428572e-05,
      "loss": 0.0013,
      "step": 9080
    },
    {
      "epoch": 0.25971428571428573,
      "grad_norm": 0.25834065675735474,
      "learning_rate": 4.350714285714286e-05,
      "loss": 0.0021,
      "step": 9090
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.1975393146276474,
      "learning_rate": 4.35e-05,
      "loss": 0.0022,
      "step": 9100
    },
    {
      "epoch": 0.2602857142857143,
      "grad_norm": 0.0,
      "learning_rate": 4.349285714285715e-05,
      "loss": 0.0013,
      "step": 9110
    },
    {
      "epoch": 0.26057142857142856,
      "grad_norm": 0.030279064550995827,
      "learning_rate": 4.3485714285714284e-05,
      "loss": 0.002,
      "step": 9120
    },
    {
      "epoch": 0.26085714285714284,
      "grad_norm": 0.03264734521508217,
      "learning_rate": 4.347857142857143e-05,
      "loss": 0.0017,
      "step": 9130
    },
    {
      "epoch": 0.2611428571428571,
      "grad_norm": 0.0489315390586853,
      "learning_rate": 4.3471428571428574e-05,
      "loss": 0.0018,
      "step": 9140
    },
    {
      "epoch": 0.26142857142857145,
      "grad_norm": 0.0,
      "learning_rate": 4.3464285714285716e-05,
      "loss": 0.0022,
      "step": 9150
    },
    {
      "epoch": 0.26171428571428573,
      "grad_norm": 0.04689010977745056,
      "learning_rate": 4.345714285714286e-05,
      "loss": 0.0026,
      "step": 9160
    },
    {
      "epoch": 0.262,
      "grad_norm": 0.30155134201049805,
      "learning_rate": 4.345e-05,
      "loss": 0.002,
      "step": 9170
    },
    {
      "epoch": 0.2622857142857143,
      "grad_norm": 0.04783831536769867,
      "learning_rate": 4.344285714285715e-05,
      "loss": 0.0009,
      "step": 9180
    },
    {
      "epoch": 0.26257142857142857,
      "grad_norm": 0.0424066036939621,
      "learning_rate": 4.343571428571428e-05,
      "loss": 0.0018,
      "step": 9190
    },
    {
      "epoch": 0.26285714285714284,
      "grad_norm": 0.047791510820388794,
      "learning_rate": 4.342857142857143e-05,
      "loss": 0.002,
      "step": 9200
    },
    {
      "epoch": 0.2631428571428571,
      "grad_norm": 0.24572314321994781,
      "learning_rate": 4.342142857142857e-05,
      "loss": 0.0025,
      "step": 9210
    },
    {
      "epoch": 0.2634285714285714,
      "grad_norm": 0.04517950490117073,
      "learning_rate": 4.341428571428572e-05,
      "loss": 0.0019,
      "step": 9220
    },
    {
      "epoch": 0.26371428571428573,
      "grad_norm": 0.24897152185440063,
      "learning_rate": 4.3407142857142856e-05,
      "loss": 0.0028,
      "step": 9230
    },
    {
      "epoch": 0.264,
      "grad_norm": 0.04334157332777977,
      "learning_rate": 4.3400000000000005e-05,
      "loss": 0.0016,
      "step": 9240
    },
    {
      "epoch": 0.2642857142857143,
      "grad_norm": 0.0,
      "learning_rate": 4.3392857142857146e-05,
      "loss": 0.0018,
      "step": 9250
    },
    {
      "epoch": 0.26457142857142857,
      "grad_norm": 0.046348828822374344,
      "learning_rate": 4.338571428571429e-05,
      "loss": 0.0022,
      "step": 9260
    },
    {
      "epoch": 0.26485714285714285,
      "grad_norm": 0.1113884374499321,
      "learning_rate": 4.337857142857143e-05,
      "loss": 0.0021,
      "step": 9270
    },
    {
      "epoch": 0.2651428571428571,
      "grad_norm": 0.07746590673923492,
      "learning_rate": 4.337142857142857e-05,
      "loss": 0.0016,
      "step": 9280
    },
    {
      "epoch": 0.2654285714285714,
      "grad_norm": 0.10030873119831085,
      "learning_rate": 4.336428571428572e-05,
      "loss": 0.001,
      "step": 9290
    },
    {
      "epoch": 0.26571428571428574,
      "grad_norm": 0.04355860874056816,
      "learning_rate": 4.3357142857142855e-05,
      "loss": 0.0015,
      "step": 9300
    },
    {
      "epoch": 0.266,
      "grad_norm": 0.27909550070762634,
      "learning_rate": 4.335e-05,
      "loss": 0.0014,
      "step": 9310
    },
    {
      "epoch": 0.2662857142857143,
      "grad_norm": 0.10927873104810715,
      "learning_rate": 4.3342857142857145e-05,
      "loss": 0.0015,
      "step": 9320
    },
    {
      "epoch": 0.26657142857142857,
      "grad_norm": 0.038340214639902115,
      "learning_rate": 4.333571428571429e-05,
      "loss": 0.0017,
      "step": 9330
    },
    {
      "epoch": 0.26685714285714285,
      "grad_norm": 0.08668146282434464,
      "learning_rate": 4.332857142857143e-05,
      "loss": 0.0019,
      "step": 9340
    },
    {
      "epoch": 0.2671428571428571,
      "grad_norm": 0.2868092954158783,
      "learning_rate": 4.332142857142858e-05,
      "loss": 0.0013,
      "step": 9350
    },
    {
      "epoch": 0.2674285714285714,
      "grad_norm": 0.1800672560930252,
      "learning_rate": 4.331428571428572e-05,
      "loss": 0.0026,
      "step": 9360
    },
    {
      "epoch": 0.26771428571428574,
      "grad_norm": 0.0,
      "learning_rate": 4.330714285714286e-05,
      "loss": 0.0013,
      "step": 9370
    },
    {
      "epoch": 0.268,
      "grad_norm": 0.15604743361473083,
      "learning_rate": 4.33e-05,
      "loss": 0.0014,
      "step": 9380
    },
    {
      "epoch": 0.2682857142857143,
      "grad_norm": 0.16077809035778046,
      "learning_rate": 4.3292857142857144e-05,
      "loss": 0.0013,
      "step": 9390
    },
    {
      "epoch": 0.26857142857142857,
      "grad_norm": 0.08543330430984497,
      "learning_rate": 4.328571428571429e-05,
      "loss": 0.0015,
      "step": 9400
    },
    {
      "epoch": 0.26885714285714285,
      "grad_norm": 0.040609147399663925,
      "learning_rate": 4.327857142857143e-05,
      "loss": 0.0027,
      "step": 9410
    },
    {
      "epoch": 0.26914285714285713,
      "grad_norm": 0.17235738039016724,
      "learning_rate": 4.3271428571428576e-05,
      "loss": 0.0025,
      "step": 9420
    },
    {
      "epoch": 0.2694285714285714,
      "grad_norm": 0.13894033432006836,
      "learning_rate": 4.326428571428572e-05,
      "loss": 0.0026,
      "step": 9430
    },
    {
      "epoch": 0.26971428571428574,
      "grad_norm": 0.04457773268222809,
      "learning_rate": 4.325714285714286e-05,
      "loss": 0.0017,
      "step": 9440
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.08625395596027374,
      "learning_rate": 4.325e-05,
      "loss": 0.0014,
      "step": 9450
    },
    {
      "epoch": 0.2702857142857143,
      "grad_norm": 0.037550006061792374,
      "learning_rate": 4.324285714285715e-05,
      "loss": 0.0027,
      "step": 9460
    },
    {
      "epoch": 0.2705714285714286,
      "grad_norm": 0.0,
      "learning_rate": 4.323571428571429e-05,
      "loss": 0.0015,
      "step": 9470
    },
    {
      "epoch": 0.27085714285714285,
      "grad_norm": 0.1648218333721161,
      "learning_rate": 4.3228571428571426e-05,
      "loss": 0.0019,
      "step": 9480
    },
    {
      "epoch": 0.27114285714285713,
      "grad_norm": 0.06408178061246872,
      "learning_rate": 4.3221428571428575e-05,
      "loss": 0.0005,
      "step": 9490
    },
    {
      "epoch": 0.2714285714285714,
      "grad_norm": 0.11114442348480225,
      "learning_rate": 4.3214285714285716e-05,
      "loss": 0.002,
      "step": 9500
    },
    {
      "epoch": 0.27171428571428574,
      "grad_norm": 0.09989310801029205,
      "learning_rate": 4.320714285714286e-05,
      "loss": 0.003,
      "step": 9510
    },
    {
      "epoch": 0.272,
      "grad_norm": 0.15910695493221283,
      "learning_rate": 4.32e-05,
      "loss": 0.0016,
      "step": 9520
    },
    {
      "epoch": 0.2722857142857143,
      "grad_norm": 0.058432165533304214,
      "learning_rate": 4.319285714285715e-05,
      "loss": 0.0019,
      "step": 9530
    },
    {
      "epoch": 0.2725714285714286,
      "grad_norm": 0.04780851677060127,
      "learning_rate": 4.318571428571429e-05,
      "loss": 0.0013,
      "step": 9540
    },
    {
      "epoch": 0.27285714285714285,
      "grad_norm": 0.034121397882699966,
      "learning_rate": 4.317857142857143e-05,
      "loss": 0.0012,
      "step": 9550
    },
    {
      "epoch": 0.27314285714285713,
      "grad_norm": 0.08401498943567276,
      "learning_rate": 4.317142857142857e-05,
      "loss": 0.0021,
      "step": 9560
    },
    {
      "epoch": 0.2734285714285714,
      "grad_norm": 0.16073009371757507,
      "learning_rate": 4.3164285714285715e-05,
      "loss": 0.0017,
      "step": 9570
    },
    {
      "epoch": 0.2737142857142857,
      "grad_norm": 0.12016995996236801,
      "learning_rate": 4.315714285714286e-05,
      "loss": 0.0008,
      "step": 9580
    },
    {
      "epoch": 0.274,
      "grad_norm": 0.029340950772166252,
      "learning_rate": 4.315e-05,
      "loss": 0.0009,
      "step": 9590
    },
    {
      "epoch": 0.2742857142857143,
      "grad_norm": 0.21353229880332947,
      "learning_rate": 4.314285714285715e-05,
      "loss": 0.0018,
      "step": 9600
    },
    {
      "epoch": 0.2745714285714286,
      "grad_norm": 0.09209137409925461,
      "learning_rate": 4.313571428571429e-05,
      "loss": 0.0017,
      "step": 9610
    },
    {
      "epoch": 0.27485714285714286,
      "grad_norm": 0.18523207306861877,
      "learning_rate": 4.312857142857143e-05,
      "loss": 0.0015,
      "step": 9620
    },
    {
      "epoch": 0.27514285714285713,
      "grad_norm": 0.08583983778953552,
      "learning_rate": 4.312142857142857e-05,
      "loss": 0.0009,
      "step": 9630
    },
    {
      "epoch": 0.2754285714285714,
      "grad_norm": 0.08411514759063721,
      "learning_rate": 4.311428571428572e-05,
      "loss": 0.0016,
      "step": 9640
    },
    {
      "epoch": 0.2757142857142857,
      "grad_norm": 0.07942376285791397,
      "learning_rate": 4.3107142857142856e-05,
      "loss": 0.0018,
      "step": 9650
    },
    {
      "epoch": 0.276,
      "grad_norm": 0.06568834185600281,
      "learning_rate": 4.3100000000000004e-05,
      "loss": 0.0029,
      "step": 9660
    },
    {
      "epoch": 0.2762857142857143,
      "grad_norm": 0.2531808316707611,
      "learning_rate": 4.3092857142857146e-05,
      "loss": 0.0024,
      "step": 9670
    },
    {
      "epoch": 0.2765714285714286,
      "grad_norm": 0.12505555152893066,
      "learning_rate": 4.308571428571429e-05,
      "loss": 0.0013,
      "step": 9680
    },
    {
      "epoch": 0.27685714285714286,
      "grad_norm": 0.08169129490852356,
      "learning_rate": 4.307857142857143e-05,
      "loss": 0.0024,
      "step": 9690
    },
    {
      "epoch": 0.27714285714285714,
      "grad_norm": 0.0,
      "learning_rate": 4.307142857142857e-05,
      "loss": 0.0009,
      "step": 9700
    },
    {
      "epoch": 0.2774285714285714,
      "grad_norm": 0.04232258349657059,
      "learning_rate": 4.306428571428572e-05,
      "loss": 0.0012,
      "step": 9710
    },
    {
      "epoch": 0.2777142857142857,
      "grad_norm": 0.15452738106250763,
      "learning_rate": 4.3057142857142854e-05,
      "loss": 0.0029,
      "step": 9720
    },
    {
      "epoch": 0.278,
      "grad_norm": 0.10505371540784836,
      "learning_rate": 4.305e-05,
      "loss": 0.0015,
      "step": 9730
    },
    {
      "epoch": 0.2782857142857143,
      "grad_norm": 0.2716851532459259,
      "learning_rate": 4.3042857142857145e-05,
      "loss": 0.0021,
      "step": 9740
    },
    {
      "epoch": 0.2785714285714286,
      "grad_norm": 0.12834738194942474,
      "learning_rate": 4.303571428571429e-05,
      "loss": 0.002,
      "step": 9750
    },
    {
      "epoch": 0.27885714285714286,
      "grad_norm": 0.05145985633134842,
      "learning_rate": 4.302857142857143e-05,
      "loss": 0.002,
      "step": 9760
    },
    {
      "epoch": 0.27914285714285714,
      "grad_norm": 0.0894722267985344,
      "learning_rate": 4.3021428571428577e-05,
      "loss": 0.0011,
      "step": 9770
    },
    {
      "epoch": 0.2794285714285714,
      "grad_norm": 0.04786427691578865,
      "learning_rate": 4.301428571428572e-05,
      "loss": 0.0023,
      "step": 9780
    },
    {
      "epoch": 0.2797142857142857,
      "grad_norm": 0.04280422255396843,
      "learning_rate": 4.300714285714286e-05,
      "loss": 0.0019,
      "step": 9790
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.16944296658039093,
      "learning_rate": 4.3e-05,
      "loss": 0.0025,
      "step": 9800
    },
    {
      "epoch": 0.2802857142857143,
      "grad_norm": 0.09739981591701508,
      "learning_rate": 4.299285714285714e-05,
      "loss": 0.0019,
      "step": 9810
    },
    {
      "epoch": 0.2805714285714286,
      "grad_norm": 0.17710092663764954,
      "learning_rate": 4.298571428571429e-05,
      "loss": 0.0022,
      "step": 9820
    },
    {
      "epoch": 0.28085714285714286,
      "grad_norm": 0.2176571637392044,
      "learning_rate": 4.297857142857143e-05,
      "loss": 0.003,
      "step": 9830
    },
    {
      "epoch": 0.28114285714285714,
      "grad_norm": 0.033369410783052444,
      "learning_rate": 4.2971428571428575e-05,
      "loss": 0.0011,
      "step": 9840
    },
    {
      "epoch": 0.2814285714285714,
      "grad_norm": 0.08703324943780899,
      "learning_rate": 4.296428571428572e-05,
      "loss": 0.0018,
      "step": 9850
    },
    {
      "epoch": 0.2817142857142857,
      "grad_norm": 0.05942206084728241,
      "learning_rate": 4.295714285714286e-05,
      "loss": 0.0017,
      "step": 9860
    },
    {
      "epoch": 0.282,
      "grad_norm": 0.0,
      "learning_rate": 4.295e-05,
      "loss": 0.0009,
      "step": 9870
    },
    {
      "epoch": 0.2822857142857143,
      "grad_norm": 0.0,
      "learning_rate": 4.294285714285715e-05,
      "loss": 0.0013,
      "step": 9880
    },
    {
      "epoch": 0.2825714285714286,
      "grad_norm": 0.22868624329566956,
      "learning_rate": 4.293571428571429e-05,
      "loss": 0.0021,
      "step": 9890
    },
    {
      "epoch": 0.28285714285714286,
      "grad_norm": 0.0,
      "learning_rate": 4.292857142857143e-05,
      "loss": 0.0013,
      "step": 9900
    },
    {
      "epoch": 0.28314285714285714,
      "grad_norm": 0.045186132192611694,
      "learning_rate": 4.2921428571428574e-05,
      "loss": 0.0008,
      "step": 9910
    },
    {
      "epoch": 0.2834285714285714,
      "grad_norm": 0.08474307507276535,
      "learning_rate": 4.2914285714285716e-05,
      "loss": 0.0005,
      "step": 9920
    },
    {
      "epoch": 0.2837142857142857,
      "grad_norm": 0.205733984708786,
      "learning_rate": 4.290714285714286e-05,
      "loss": 0.0009,
      "step": 9930
    },
    {
      "epoch": 0.284,
      "grad_norm": 0.1198936402797699,
      "learning_rate": 4.29e-05,
      "loss": 0.0019,
      "step": 9940
    },
    {
      "epoch": 0.2842857142857143,
      "grad_norm": 0.1357022374868393,
      "learning_rate": 4.289285714285715e-05,
      "loss": 0.0027,
      "step": 9950
    },
    {
      "epoch": 0.2845714285714286,
      "grad_norm": 0.0,
      "learning_rate": 4.288571428571429e-05,
      "loss": 0.0012,
      "step": 9960
    },
    {
      "epoch": 0.28485714285714286,
      "grad_norm": 0.19490088522434235,
      "learning_rate": 4.287857142857143e-05,
      "loss": 0.0026,
      "step": 9970
    },
    {
      "epoch": 0.28514285714285714,
      "grad_norm": 0.04190986230969429,
      "learning_rate": 4.287142857142857e-05,
      "loss": 0.0025,
      "step": 9980
    },
    {
      "epoch": 0.2854285714285714,
      "grad_norm": 0.042803093791007996,
      "learning_rate": 4.2864285714285715e-05,
      "loss": 0.0018,
      "step": 9990
    },
    {
      "epoch": 0.2857142857142857,
      "grad_norm": 0.2643677294254303,
      "learning_rate": 4.2857142857142856e-05,
      "loss": 0.0021,
      "step": 10000
    },
    {
      "epoch": 0.286,
      "grad_norm": 0.1416121870279312,
      "learning_rate": 4.285e-05,
      "loss": 0.0018,
      "step": 10010
    },
    {
      "epoch": 0.2862857142857143,
      "grad_norm": 0.0,
      "learning_rate": 4.2842857142857146e-05,
      "loss": 0.0016,
      "step": 10020
    },
    {
      "epoch": 0.2865714285714286,
      "grad_norm": 0.38355863094329834,
      "learning_rate": 4.283571428571429e-05,
      "loss": 0.0022,
      "step": 10030
    },
    {
      "epoch": 0.28685714285714287,
      "grad_norm": 0.12377005815505981,
      "learning_rate": 4.282857142857143e-05,
      "loss": 0.0019,
      "step": 10040
    },
    {
      "epoch": 0.28714285714285714,
      "grad_norm": 0.08150876313447952,
      "learning_rate": 4.282142857142857e-05,
      "loss": 0.0008,
      "step": 10050
    },
    {
      "epoch": 0.2874285714285714,
      "grad_norm": 0.0883500874042511,
      "learning_rate": 4.281428571428572e-05,
      "loss": 0.0017,
      "step": 10060
    },
    {
      "epoch": 0.2877142857142857,
      "grad_norm": 0.22607378661632538,
      "learning_rate": 4.2807142857142855e-05,
      "loss": 0.0012,
      "step": 10070
    },
    {
      "epoch": 0.288,
      "grad_norm": 0.041801098734140396,
      "learning_rate": 4.2800000000000004e-05,
      "loss": 0.0029,
      "step": 10080
    },
    {
      "epoch": 0.2882857142857143,
      "grad_norm": 0.061405524611473083,
      "learning_rate": 4.2792857142857145e-05,
      "loss": 0.0028,
      "step": 10090
    },
    {
      "epoch": 0.2885714285714286,
      "grad_norm": 0.08899272233247757,
      "learning_rate": 4.278571428571429e-05,
      "loss": 0.0023,
      "step": 10100
    },
    {
      "epoch": 0.28885714285714287,
      "grad_norm": 0.19849960505962372,
      "learning_rate": 4.277857142857143e-05,
      "loss": 0.0014,
      "step": 10110
    },
    {
      "epoch": 0.28914285714285715,
      "grad_norm": 0.3334752321243286,
      "learning_rate": 4.277142857142857e-05,
      "loss": 0.0029,
      "step": 10120
    },
    {
      "epoch": 0.2894285714285714,
      "grad_norm": 0.22509980201721191,
      "learning_rate": 4.276428571428572e-05,
      "loss": 0.002,
      "step": 10130
    },
    {
      "epoch": 0.2897142857142857,
      "grad_norm": 0.04515879973769188,
      "learning_rate": 4.2757142857142854e-05,
      "loss": 0.0008,
      "step": 10140
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.25416478514671326,
      "learning_rate": 4.275e-05,
      "loss": 0.0019,
      "step": 10150
    },
    {
      "epoch": 0.29028571428571426,
      "grad_norm": 0.03283347561955452,
      "learning_rate": 4.2742857142857144e-05,
      "loss": 0.0019,
      "step": 10160
    },
    {
      "epoch": 0.2905714285714286,
      "grad_norm": 0.09693963080644608,
      "learning_rate": 4.273571428571429e-05,
      "loss": 0.0024,
      "step": 10170
    },
    {
      "epoch": 0.29085714285714287,
      "grad_norm": 0.41042837500572205,
      "learning_rate": 4.272857142857143e-05,
      "loss": 0.0021,
      "step": 10180
    },
    {
      "epoch": 0.29114285714285715,
      "grad_norm": 0.24333840608596802,
      "learning_rate": 4.2721428571428576e-05,
      "loss": 0.0027,
      "step": 10190
    },
    {
      "epoch": 0.2914285714285714,
      "grad_norm": 0.11716185510158539,
      "learning_rate": 4.271428571428572e-05,
      "loss": 0.0028,
      "step": 10200
    },
    {
      "epoch": 0.2917142857142857,
      "grad_norm": 0.19592194259166718,
      "learning_rate": 4.270714285714286e-05,
      "loss": 0.0022,
      "step": 10210
    },
    {
      "epoch": 0.292,
      "grad_norm": 0.36815962195396423,
      "learning_rate": 4.27e-05,
      "loss": 0.0016,
      "step": 10220
    },
    {
      "epoch": 0.29228571428571426,
      "grad_norm": 0.12265676259994507,
      "learning_rate": 4.269285714285714e-05,
      "loss": 0.0027,
      "step": 10230
    },
    {
      "epoch": 0.2925714285714286,
      "grad_norm": 0.17465443909168243,
      "learning_rate": 4.268571428571429e-05,
      "loss": 0.002,
      "step": 10240
    },
    {
      "epoch": 0.29285714285714287,
      "grad_norm": 0.04897456616163254,
      "learning_rate": 4.2678571428571426e-05,
      "loss": 0.0019,
      "step": 10250
    },
    {
      "epoch": 0.29314285714285715,
      "grad_norm": 0.09370468556880951,
      "learning_rate": 4.2671428571428575e-05,
      "loss": 0.002,
      "step": 10260
    },
    {
      "epoch": 0.2934285714285714,
      "grad_norm": 0.1215902641415596,
      "learning_rate": 4.2664285714285716e-05,
      "loss": 0.0014,
      "step": 10270
    },
    {
      "epoch": 0.2937142857142857,
      "grad_norm": 0.05615287646651268,
      "learning_rate": 4.265714285714286e-05,
      "loss": 0.002,
      "step": 10280
    },
    {
      "epoch": 0.294,
      "grad_norm": 0.17315566539764404,
      "learning_rate": 4.265e-05,
      "loss": 0.0014,
      "step": 10290
    },
    {
      "epoch": 0.29428571428571426,
      "grad_norm": 0.17843976616859436,
      "learning_rate": 4.264285714285715e-05,
      "loss": 0.0025,
      "step": 10300
    },
    {
      "epoch": 0.2945714285714286,
      "grad_norm": 0.10584376752376556,
      "learning_rate": 4.263571428571429e-05,
      "loss": 0.0018,
      "step": 10310
    },
    {
      "epoch": 0.2948571428571429,
      "grad_norm": 0.16109508275985718,
      "learning_rate": 4.262857142857143e-05,
      "loss": 0.0012,
      "step": 10320
    },
    {
      "epoch": 0.29514285714285715,
      "grad_norm": 0.09313573688268661,
      "learning_rate": 4.2621428571428574e-05,
      "loss": 0.0004,
      "step": 10330
    },
    {
      "epoch": 0.29542857142857143,
      "grad_norm": 0.0,
      "learning_rate": 4.2614285714285715e-05,
      "loss": 0.0015,
      "step": 10340
    },
    {
      "epoch": 0.2957142857142857,
      "grad_norm": 0.04095320403575897,
      "learning_rate": 4.260714285714286e-05,
      "loss": 0.001,
      "step": 10350
    },
    {
      "epoch": 0.296,
      "grad_norm": 0.058886077255010605,
      "learning_rate": 4.26e-05,
      "loss": 0.0019,
      "step": 10360
    },
    {
      "epoch": 0.29628571428571426,
      "grad_norm": 0.0,
      "learning_rate": 4.259285714285715e-05,
      "loss": 0.0019,
      "step": 10370
    },
    {
      "epoch": 0.2965714285714286,
      "grad_norm": 0.039907731115818024,
      "learning_rate": 4.258571428571429e-05,
      "loss": 0.0011,
      "step": 10380
    },
    {
      "epoch": 0.2968571428571429,
      "grad_norm": 0.1673257201910019,
      "learning_rate": 4.257857142857143e-05,
      "loss": 0.0019,
      "step": 10390
    },
    {
      "epoch": 0.29714285714285715,
      "grad_norm": 0.0793660432100296,
      "learning_rate": 4.257142857142857e-05,
      "loss": 0.0019,
      "step": 10400
    },
    {
      "epoch": 0.29742857142857143,
      "grad_norm": 0.1712210476398468,
      "learning_rate": 4.256428571428572e-05,
      "loss": 0.0015,
      "step": 10410
    },
    {
      "epoch": 0.2977142857142857,
      "grad_norm": 0.12198808044195175,
      "learning_rate": 4.2557142857142856e-05,
      "loss": 0.0013,
      "step": 10420
    },
    {
      "epoch": 0.298,
      "grad_norm": 0.0,
      "learning_rate": 4.2550000000000004e-05,
      "loss": 0.001,
      "step": 10430
    },
    {
      "epoch": 0.29828571428571427,
      "grad_norm": 0.04945652186870575,
      "learning_rate": 4.2542857142857146e-05,
      "loss": 0.0015,
      "step": 10440
    },
    {
      "epoch": 0.2985714285714286,
      "grad_norm": 0.08226571977138519,
      "learning_rate": 4.253571428571429e-05,
      "loss": 0.0012,
      "step": 10450
    },
    {
      "epoch": 0.2988571428571429,
      "grad_norm": 0.12134603410959244,
      "learning_rate": 4.252857142857143e-05,
      "loss": 0.0018,
      "step": 10460
    },
    {
      "epoch": 0.29914285714285715,
      "grad_norm": 0.0,
      "learning_rate": 4.252142857142857e-05,
      "loss": 0.0009,
      "step": 10470
    },
    {
      "epoch": 0.29942857142857143,
      "grad_norm": 0.13562913239002228,
      "learning_rate": 4.251428571428572e-05,
      "loss": 0.0015,
      "step": 10480
    },
    {
      "epoch": 0.2997142857142857,
      "grad_norm": 0.053043559193611145,
      "learning_rate": 4.2507142857142855e-05,
      "loss": 0.0014,
      "step": 10490
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.24800053238868713,
      "learning_rate": 4.25e-05,
      "loss": 0.0022,
      "step": 10500
    },
    {
      "epoch": 0.30028571428571427,
      "grad_norm": 0.17896002531051636,
      "learning_rate": 4.2492857142857145e-05,
      "loss": 0.0013,
      "step": 10510
    },
    {
      "epoch": 0.30057142857142854,
      "grad_norm": 0.05849895998835564,
      "learning_rate": 4.2485714285714286e-05,
      "loss": 0.0018,
      "step": 10520
    },
    {
      "epoch": 0.3008571428571429,
      "grad_norm": 0.10672476887702942,
      "learning_rate": 4.247857142857143e-05,
      "loss": 0.0024,
      "step": 10530
    },
    {
      "epoch": 0.30114285714285716,
      "grad_norm": 0.0844368189573288,
      "learning_rate": 4.247142857142857e-05,
      "loss": 0.0024,
      "step": 10540
    },
    {
      "epoch": 0.30142857142857143,
      "grad_norm": 0.0533621720969677,
      "learning_rate": 4.246428571428572e-05,
      "loss": 0.002,
      "step": 10550
    },
    {
      "epoch": 0.3017142857142857,
      "grad_norm": 0.0,
      "learning_rate": 4.245714285714285e-05,
      "loss": 0.0009,
      "step": 10560
    },
    {
      "epoch": 0.302,
      "grad_norm": 0.17060619592666626,
      "learning_rate": 4.245e-05,
      "loss": 0.0019,
      "step": 10570
    },
    {
      "epoch": 0.30228571428571427,
      "grad_norm": 0.11940198391675949,
      "learning_rate": 4.2442857142857144e-05,
      "loss": 0.0013,
      "step": 10580
    },
    {
      "epoch": 0.30257142857142855,
      "grad_norm": 0.04361182823777199,
      "learning_rate": 4.243571428571429e-05,
      "loss": 0.001,
      "step": 10590
    },
    {
      "epoch": 0.3028571428571429,
      "grad_norm": 0.13770423829555511,
      "learning_rate": 4.242857142857143e-05,
      "loss": 0.0016,
      "step": 10600
    },
    {
      "epoch": 0.30314285714285716,
      "grad_norm": 0.04354401305317879,
      "learning_rate": 4.2421428571428575e-05,
      "loss": 0.0012,
      "step": 10610
    },
    {
      "epoch": 0.30342857142857144,
      "grad_norm": 0.044181764125823975,
      "learning_rate": 4.241428571428572e-05,
      "loss": 0.0015,
      "step": 10620
    },
    {
      "epoch": 0.3037142857142857,
      "grad_norm": 0.14770634472370148,
      "learning_rate": 4.240714285714286e-05,
      "loss": 0.0011,
      "step": 10630
    },
    {
      "epoch": 0.304,
      "grad_norm": 0.031532082706689835,
      "learning_rate": 4.24e-05,
      "loss": 0.0013,
      "step": 10640
    },
    {
      "epoch": 0.30428571428571427,
      "grad_norm": 0.08684651553630829,
      "learning_rate": 4.239285714285714e-05,
      "loss": 0.0013,
      "step": 10650
    },
    {
      "epoch": 0.30457142857142855,
      "grad_norm": 0.20600032806396484,
      "learning_rate": 4.238571428571429e-05,
      "loss": 0.002,
      "step": 10660
    },
    {
      "epoch": 0.3048571428571429,
      "grad_norm": 0.04503621906042099,
      "learning_rate": 4.2378571428571426e-05,
      "loss": 0.0015,
      "step": 10670
    },
    {
      "epoch": 0.30514285714285716,
      "grad_norm": 0.047085054218769073,
      "learning_rate": 4.2371428571428574e-05,
      "loss": 0.0016,
      "step": 10680
    },
    {
      "epoch": 0.30542857142857144,
      "grad_norm": 0.029354389756917953,
      "learning_rate": 4.2364285714285716e-05,
      "loss": 0.0007,
      "step": 10690
    },
    {
      "epoch": 0.3057142857142857,
      "grad_norm": 0.033567409962415695,
      "learning_rate": 4.2357142857142864e-05,
      "loss": 0.0013,
      "step": 10700
    },
    {
      "epoch": 0.306,
      "grad_norm": 0.14951583743095398,
      "learning_rate": 4.235e-05,
      "loss": 0.0016,
      "step": 10710
    },
    {
      "epoch": 0.3062857142857143,
      "grad_norm": 0.13238370418548584,
      "learning_rate": 4.234285714285715e-05,
      "loss": 0.0019,
      "step": 10720
    },
    {
      "epoch": 0.30657142857142855,
      "grad_norm": 0.11772128939628601,
      "learning_rate": 4.233571428571429e-05,
      "loss": 0.0013,
      "step": 10730
    },
    {
      "epoch": 0.3068571428571429,
      "grad_norm": 0.10171711444854736,
      "learning_rate": 4.232857142857143e-05,
      "loss": 0.0025,
      "step": 10740
    },
    {
      "epoch": 0.30714285714285716,
      "grad_norm": 0.03881501778960228,
      "learning_rate": 4.232142857142857e-05,
      "loss": 0.0025,
      "step": 10750
    },
    {
      "epoch": 0.30742857142857144,
      "grad_norm": 0.16797253489494324,
      "learning_rate": 4.2314285714285715e-05,
      "loss": 0.0009,
      "step": 10760
    },
    {
      "epoch": 0.3077142857142857,
      "grad_norm": 0.10067571699619293,
      "learning_rate": 4.230714285714286e-05,
      "loss": 0.0015,
      "step": 10770
    },
    {
      "epoch": 0.308,
      "grad_norm": 0.12201225757598877,
      "learning_rate": 4.23e-05,
      "loss": 0.0008,
      "step": 10780
    },
    {
      "epoch": 0.3082857142857143,
      "grad_norm": 0.1969408392906189,
      "learning_rate": 4.229285714285715e-05,
      "loss": 0.0025,
      "step": 10790
    },
    {
      "epoch": 0.30857142857142855,
      "grad_norm": 0.10110419243574142,
      "learning_rate": 4.228571428571429e-05,
      "loss": 0.001,
      "step": 10800
    },
    {
      "epoch": 0.30885714285714283,
      "grad_norm": 0.04073039069771767,
      "learning_rate": 4.227857142857143e-05,
      "loss": 0.0013,
      "step": 10810
    },
    {
      "epoch": 0.30914285714285716,
      "grad_norm": 0.08112764358520508,
      "learning_rate": 4.227142857142857e-05,
      "loss": 0.0017,
      "step": 10820
    },
    {
      "epoch": 0.30942857142857144,
      "grad_norm": 0.0,
      "learning_rate": 4.226428571428572e-05,
      "loss": 0.0016,
      "step": 10830
    },
    {
      "epoch": 0.3097142857142857,
      "grad_norm": 0.0440857857465744,
      "learning_rate": 4.225714285714286e-05,
      "loss": 0.0023,
      "step": 10840
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.23750039935112,
      "learning_rate": 4.2250000000000004e-05,
      "loss": 0.0015,
      "step": 10850
    },
    {
      "epoch": 0.3102857142857143,
      "grad_norm": 0.08589781075716019,
      "learning_rate": 4.2242857142857145e-05,
      "loss": 0.0013,
      "step": 10860
    },
    {
      "epoch": 0.31057142857142855,
      "grad_norm": 0.025633342564105988,
      "learning_rate": 4.223571428571429e-05,
      "loss": 0.0025,
      "step": 10870
    },
    {
      "epoch": 0.31085714285714283,
      "grad_norm": 0.041515227407217026,
      "learning_rate": 4.222857142857143e-05,
      "loss": 0.0012,
      "step": 10880
    },
    {
      "epoch": 0.31114285714285717,
      "grad_norm": 0.043429743498563766,
      "learning_rate": 4.222142857142857e-05,
      "loss": 0.0017,
      "step": 10890
    },
    {
      "epoch": 0.31142857142857144,
      "grad_norm": 0.0,
      "learning_rate": 4.221428571428572e-05,
      "loss": 0.0023,
      "step": 10900
    },
    {
      "epoch": 0.3117142857142857,
      "grad_norm": 0.34015586972236633,
      "learning_rate": 4.220714285714286e-05,
      "loss": 0.0025,
      "step": 10910
    },
    {
      "epoch": 0.312,
      "grad_norm": 0.11848873645067215,
      "learning_rate": 4.22e-05,
      "loss": 0.0019,
      "step": 10920
    },
    {
      "epoch": 0.3122857142857143,
      "grad_norm": 0.040159955620765686,
      "learning_rate": 4.2192857142857144e-05,
      "loss": 0.0018,
      "step": 10930
    },
    {
      "epoch": 0.31257142857142856,
      "grad_norm": 0.3985233008861542,
      "learning_rate": 4.218571428571429e-05,
      "loss": 0.0022,
      "step": 10940
    },
    {
      "epoch": 0.31285714285714283,
      "grad_norm": 0.05992523580789566,
      "learning_rate": 4.217857142857143e-05,
      "loss": 0.0015,
      "step": 10950
    },
    {
      "epoch": 0.31314285714285717,
      "grad_norm": 0.200627401471138,
      "learning_rate": 4.2171428571428576e-05,
      "loss": 0.0019,
      "step": 10960
    },
    {
      "epoch": 0.31342857142857145,
      "grad_norm": 0.13070641458034515,
      "learning_rate": 4.216428571428572e-05,
      "loss": 0.0025,
      "step": 10970
    },
    {
      "epoch": 0.3137142857142857,
      "grad_norm": 0.03407701849937439,
      "learning_rate": 4.215714285714286e-05,
      "loss": 0.0016,
      "step": 10980
    },
    {
      "epoch": 0.314,
      "grad_norm": 0.05279918760061264,
      "learning_rate": 4.215e-05,
      "loss": 0.0016,
      "step": 10990
    },
    {
      "epoch": 0.3142857142857143,
      "grad_norm": 0.20835745334625244,
      "learning_rate": 4.214285714285714e-05,
      "loss": 0.0015,
      "step": 11000
    },
    {
      "epoch": 0.31457142857142856,
      "grad_norm": 0.17021343111991882,
      "learning_rate": 4.213571428571429e-05,
      "loss": 0.0018,
      "step": 11010
    },
    {
      "epoch": 0.31485714285714284,
      "grad_norm": 0.08474413305521011,
      "learning_rate": 4.2128571428571426e-05,
      "loss": 0.0019,
      "step": 11020
    },
    {
      "epoch": 0.31514285714285717,
      "grad_norm": 0.045364465564489365,
      "learning_rate": 4.2121428571428575e-05,
      "loss": 0.0018,
      "step": 11030
    },
    {
      "epoch": 0.31542857142857145,
      "grad_norm": 0.09083424508571625,
      "learning_rate": 4.211428571428572e-05,
      "loss": 0.0018,
      "step": 11040
    },
    {
      "epoch": 0.3157142857142857,
      "grad_norm": 0.26705121994018555,
      "learning_rate": 4.210714285714286e-05,
      "loss": 0.0016,
      "step": 11050
    },
    {
      "epoch": 0.316,
      "grad_norm": 0.20114192366600037,
      "learning_rate": 4.21e-05,
      "loss": 0.0019,
      "step": 11060
    },
    {
      "epoch": 0.3162857142857143,
      "grad_norm": 0.05739015340805054,
      "learning_rate": 4.209285714285714e-05,
      "loss": 0.0014,
      "step": 11070
    },
    {
      "epoch": 0.31657142857142856,
      "grad_norm": 0.1731671839952469,
      "learning_rate": 4.208571428571429e-05,
      "loss": 0.0039,
      "step": 11080
    },
    {
      "epoch": 0.31685714285714284,
      "grad_norm": 0.23858191072940826,
      "learning_rate": 4.2078571428571425e-05,
      "loss": 0.0013,
      "step": 11090
    },
    {
      "epoch": 0.3171428571428571,
      "grad_norm": 0.04910573735833168,
      "learning_rate": 4.2071428571428574e-05,
      "loss": 0.0013,
      "step": 11100
    },
    {
      "epoch": 0.31742857142857145,
      "grad_norm": 0.04179416596889496,
      "learning_rate": 4.2064285714285715e-05,
      "loss": 0.0015,
      "step": 11110
    },
    {
      "epoch": 0.3177142857142857,
      "grad_norm": 0.03855332359671593,
      "learning_rate": 4.2057142857142864e-05,
      "loss": 0.0023,
      "step": 11120
    },
    {
      "epoch": 0.318,
      "grad_norm": 0.06394296884536743,
      "learning_rate": 4.205e-05,
      "loss": 0.0017,
      "step": 11130
    },
    {
      "epoch": 0.3182857142857143,
      "grad_norm": 0.0517260804772377,
      "learning_rate": 4.204285714285715e-05,
      "loss": 0.0022,
      "step": 11140
    },
    {
      "epoch": 0.31857142857142856,
      "grad_norm": 0.0,
      "learning_rate": 4.203571428571429e-05,
      "loss": 0.0014,
      "step": 11150
    },
    {
      "epoch": 0.31885714285714284,
      "grad_norm": 0.19447405636310577,
      "learning_rate": 4.202857142857143e-05,
      "loss": 0.002,
      "step": 11160
    },
    {
      "epoch": 0.3191428571428571,
      "grad_norm": 0.25502315163612366,
      "learning_rate": 4.202142857142857e-05,
      "loss": 0.0014,
      "step": 11170
    },
    {
      "epoch": 0.31942857142857145,
      "grad_norm": 0.026397209614515305,
      "learning_rate": 4.2014285714285714e-05,
      "loss": 0.0023,
      "step": 11180
    },
    {
      "epoch": 0.31971428571428573,
      "grad_norm": 0.1159663125872612,
      "learning_rate": 4.200714285714286e-05,
      "loss": 0.0023,
      "step": 11190
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.20960892736911774,
      "learning_rate": 4.2e-05,
      "loss": 0.0023,
      "step": 11200
    },
    {
      "epoch": 0.3202857142857143,
      "grad_norm": 0.15235672891139984,
      "learning_rate": 4.1992857142857146e-05,
      "loss": 0.0019,
      "step": 11210
    },
    {
      "epoch": 0.32057142857142856,
      "grad_norm": 0.0,
      "learning_rate": 4.198571428571429e-05,
      "loss": 0.002,
      "step": 11220
    },
    {
      "epoch": 0.32085714285714284,
      "grad_norm": 0.08420310169458389,
      "learning_rate": 4.197857142857143e-05,
      "loss": 0.0021,
      "step": 11230
    },
    {
      "epoch": 0.3211428571428571,
      "grad_norm": 0.045477285981178284,
      "learning_rate": 4.197142857142857e-05,
      "loss": 0.002,
      "step": 11240
    },
    {
      "epoch": 0.32142857142857145,
      "grad_norm": 0.11203618347644806,
      "learning_rate": 4.196428571428572e-05,
      "loss": 0.001,
      "step": 11250
    },
    {
      "epoch": 0.32171428571428573,
      "grad_norm": 0.06078808009624481,
      "learning_rate": 4.195714285714286e-05,
      "loss": 0.0013,
      "step": 11260
    },
    {
      "epoch": 0.322,
      "grad_norm": 0.0,
      "learning_rate": 4.195e-05,
      "loss": 0.0015,
      "step": 11270
    },
    {
      "epoch": 0.3222857142857143,
      "grad_norm": 0.09995944052934647,
      "learning_rate": 4.1942857142857145e-05,
      "loss": 0.0014,
      "step": 11280
    },
    {
      "epoch": 0.32257142857142856,
      "grad_norm": 0.26740673184394836,
      "learning_rate": 4.193571428571429e-05,
      "loss": 0.0012,
      "step": 11290
    },
    {
      "epoch": 0.32285714285714284,
      "grad_norm": 0.044957246631383896,
      "learning_rate": 4.192857142857143e-05,
      "loss": 0.0018,
      "step": 11300
    },
    {
      "epoch": 0.3231428571428571,
      "grad_norm": 0.19704052805900574,
      "learning_rate": 4.192142857142857e-05,
      "loss": 0.0011,
      "step": 11310
    },
    {
      "epoch": 0.32342857142857145,
      "grad_norm": 0.128225177526474,
      "learning_rate": 4.191428571428572e-05,
      "loss": 0.0017,
      "step": 11320
    },
    {
      "epoch": 0.32371428571428573,
      "grad_norm": 0.04529866576194763,
      "learning_rate": 4.190714285714286e-05,
      "loss": 0.0019,
      "step": 11330
    },
    {
      "epoch": 0.324,
      "grad_norm": 0.10384196043014526,
      "learning_rate": 4.19e-05,
      "loss": 0.0015,
      "step": 11340
    },
    {
      "epoch": 0.3242857142857143,
      "grad_norm": 0.04366167262196541,
      "learning_rate": 4.1892857142857144e-05,
      "loss": 0.0017,
      "step": 11350
    },
    {
      "epoch": 0.32457142857142857,
      "grad_norm": 0.3575323820114136,
      "learning_rate": 4.188571428571429e-05,
      "loss": 0.0019,
      "step": 11360
    },
    {
      "epoch": 0.32485714285714284,
      "grad_norm": 0.5078763961791992,
      "learning_rate": 4.187857142857143e-05,
      "loss": 0.0024,
      "step": 11370
    },
    {
      "epoch": 0.3251428571428571,
      "grad_norm": 0.06698212027549744,
      "learning_rate": 4.1871428571428576e-05,
      "loss": 0.0018,
      "step": 11380
    },
    {
      "epoch": 0.32542857142857146,
      "grad_norm": 0.0,
      "learning_rate": 4.186428571428572e-05,
      "loss": 0.0014,
      "step": 11390
    },
    {
      "epoch": 0.32571428571428573,
      "grad_norm": 0.025035185739398003,
      "learning_rate": 4.185714285714286e-05,
      "loss": 0.0033,
      "step": 11400
    },
    {
      "epoch": 0.326,
      "grad_norm": 0.07796577364206314,
      "learning_rate": 4.185e-05,
      "loss": 0.0023,
      "step": 11410
    },
    {
      "epoch": 0.3262857142857143,
      "grad_norm": 0.0,
      "learning_rate": 4.184285714285714e-05,
      "loss": 0.0022,
      "step": 11420
    },
    {
      "epoch": 0.32657142857142857,
      "grad_norm": 0.03357621654868126,
      "learning_rate": 4.183571428571429e-05,
      "loss": 0.0013,
      "step": 11430
    },
    {
      "epoch": 0.32685714285714285,
      "grad_norm": 0.08739510178565979,
      "learning_rate": 4.1828571428571426e-05,
      "loss": 0.0013,
      "step": 11440
    },
    {
      "epoch": 0.3271428571428571,
      "grad_norm": 0.2693220376968384,
      "learning_rate": 4.1821428571428574e-05,
      "loss": 0.002,
      "step": 11450
    },
    {
      "epoch": 0.3274285714285714,
      "grad_norm": 0.05171907693147659,
      "learning_rate": 4.1814285714285716e-05,
      "loss": 0.0026,
      "step": 11460
    },
    {
      "epoch": 0.32771428571428574,
      "grad_norm": 0.0,
      "learning_rate": 4.1807142857142865e-05,
      "loss": 0.0023,
      "step": 11470
    },
    {
      "epoch": 0.328,
      "grad_norm": 0.16544286906719208,
      "learning_rate": 4.18e-05,
      "loss": 0.0014,
      "step": 11480
    },
    {
      "epoch": 0.3282857142857143,
      "grad_norm": 0.054640013724565506,
      "learning_rate": 4.179285714285715e-05,
      "loss": 0.0018,
      "step": 11490
    },
    {
      "epoch": 0.32857142857142857,
      "grad_norm": 0.1713598668575287,
      "learning_rate": 4.178571428571429e-05,
      "loss": 0.0014,
      "step": 11500
    },
    {
      "epoch": 0.32885714285714285,
      "grad_norm": 0.19099237024784088,
      "learning_rate": 4.1778571428571425e-05,
      "loss": 0.0008,
      "step": 11510
    },
    {
      "epoch": 0.3291428571428571,
      "grad_norm": 0.0,
      "learning_rate": 4.177142857142857e-05,
      "loss": 0.0009,
      "step": 11520
    },
    {
      "epoch": 0.3294285714285714,
      "grad_norm": 0.0,
      "learning_rate": 4.1764285714285715e-05,
      "loss": 0.0011,
      "step": 11530
    },
    {
      "epoch": 0.32971428571428574,
      "grad_norm": 0.07177426666021347,
      "learning_rate": 4.1757142857142863e-05,
      "loss": 0.0013,
      "step": 11540
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.03531316667795181,
      "learning_rate": 4.175e-05,
      "loss": 0.0018,
      "step": 11550
    },
    {
      "epoch": 0.3302857142857143,
      "grad_norm": 0.0,
      "learning_rate": 4.174285714285715e-05,
      "loss": 0.0023,
      "step": 11560
    },
    {
      "epoch": 0.33057142857142857,
      "grad_norm": 0.06200632452964783,
      "learning_rate": 4.173571428571429e-05,
      "loss": 0.002,
      "step": 11570
    },
    {
      "epoch": 0.33085714285714285,
      "grad_norm": 0.0,
      "learning_rate": 4.172857142857143e-05,
      "loss": 0.0015,
      "step": 11580
    },
    {
      "epoch": 0.3311428571428571,
      "grad_norm": 0.13252000510692596,
      "learning_rate": 4.172142857142857e-05,
      "loss": 0.0006,
      "step": 11590
    },
    {
      "epoch": 0.3314285714285714,
      "grad_norm": 0.17354047298431396,
      "learning_rate": 4.1714285714285714e-05,
      "loss": 0.0027,
      "step": 11600
    },
    {
      "epoch": 0.33171428571428574,
      "grad_norm": 0.21390773355960846,
      "learning_rate": 4.170714285714286e-05,
      "loss": 0.0026,
      "step": 11610
    },
    {
      "epoch": 0.332,
      "grad_norm": 0.18412280082702637,
      "learning_rate": 4.17e-05,
      "loss": 0.0017,
      "step": 11620
    },
    {
      "epoch": 0.3322857142857143,
      "grad_norm": 0.044867563992738724,
      "learning_rate": 4.1692857142857146e-05,
      "loss": 0.0018,
      "step": 11630
    },
    {
      "epoch": 0.3325714285714286,
      "grad_norm": 0.039930399507284164,
      "learning_rate": 4.168571428571429e-05,
      "loss": 0.0021,
      "step": 11640
    },
    {
      "epoch": 0.33285714285714285,
      "grad_norm": 0.0,
      "learning_rate": 4.167857142857143e-05,
      "loss": 0.0014,
      "step": 11650
    },
    {
      "epoch": 0.33314285714285713,
      "grad_norm": 0.2766903042793274,
      "learning_rate": 4.167142857142857e-05,
      "loss": 0.0017,
      "step": 11660
    },
    {
      "epoch": 0.3334285714285714,
      "grad_norm": 0.12354280054569244,
      "learning_rate": 4.166428571428572e-05,
      "loss": 0.0025,
      "step": 11670
    },
    {
      "epoch": 0.33371428571428574,
      "grad_norm": 0.04138560965657234,
      "learning_rate": 4.165714285714286e-05,
      "loss": 0.0006,
      "step": 11680
    },
    {
      "epoch": 0.334,
      "grad_norm": 0.0,
      "learning_rate": 4.165e-05,
      "loss": 0.0017,
      "step": 11690
    },
    {
      "epoch": 0.3342857142857143,
      "grad_norm": 0.03043309971690178,
      "learning_rate": 4.1642857142857144e-05,
      "loss": 0.001,
      "step": 11700
    },
    {
      "epoch": 0.3345714285714286,
      "grad_norm": 0.0,
      "learning_rate": 4.1635714285714286e-05,
      "loss": 0.0015,
      "step": 11710
    },
    {
      "epoch": 0.33485714285714285,
      "grad_norm": 0.1292841136455536,
      "learning_rate": 4.162857142857143e-05,
      "loss": 0.0018,
      "step": 11720
    },
    {
      "epoch": 0.33514285714285713,
      "grad_norm": 0.0,
      "learning_rate": 4.162142857142857e-05,
      "loss": 0.0017,
      "step": 11730
    },
    {
      "epoch": 0.3354285714285714,
      "grad_norm": 0.12560683488845825,
      "learning_rate": 4.161428571428572e-05,
      "loss": 0.0017,
      "step": 11740
    },
    {
      "epoch": 0.3357142857142857,
      "grad_norm": 0.0,
      "learning_rate": 4.160714285714286e-05,
      "loss": 0.0015,
      "step": 11750
    },
    {
      "epoch": 0.336,
      "grad_norm": 0.2588771879673004,
      "learning_rate": 4.16e-05,
      "loss": 0.0014,
      "step": 11760
    },
    {
      "epoch": 0.3362857142857143,
      "grad_norm": 0.06670320779085159,
      "learning_rate": 4.159285714285714e-05,
      "loss": 0.0015,
      "step": 11770
    },
    {
      "epoch": 0.3365714285714286,
      "grad_norm": 0.12896457314491272,
      "learning_rate": 4.158571428571429e-05,
      "loss": 0.0021,
      "step": 11780
    },
    {
      "epoch": 0.33685714285714285,
      "grad_norm": 0.0,
      "learning_rate": 4.157857142857143e-05,
      "loss": 0.0011,
      "step": 11790
    },
    {
      "epoch": 0.33714285714285713,
      "grad_norm": 0.0,
      "learning_rate": 4.1571428571428575e-05,
      "loss": 0.0012,
      "step": 11800
    },
    {
      "epoch": 0.3374285714285714,
      "grad_norm": 0.04049604386091232,
      "learning_rate": 4.156428571428572e-05,
      "loss": 0.0018,
      "step": 11810
    },
    {
      "epoch": 0.3377142857142857,
      "grad_norm": 0.04674498364329338,
      "learning_rate": 4.155714285714286e-05,
      "loss": 0.0014,
      "step": 11820
    },
    {
      "epoch": 0.338,
      "grad_norm": 0.09196745604276657,
      "learning_rate": 4.155e-05,
      "loss": 0.0021,
      "step": 11830
    },
    {
      "epoch": 0.3382857142857143,
      "grad_norm": 0.14845231175422668,
      "learning_rate": 4.154285714285714e-05,
      "loss": 0.0013,
      "step": 11840
    },
    {
      "epoch": 0.3385714285714286,
      "grad_norm": 0.0,
      "learning_rate": 4.153571428571429e-05,
      "loss": 0.0016,
      "step": 11850
    },
    {
      "epoch": 0.33885714285714286,
      "grad_norm": 0.14631077647209167,
      "learning_rate": 4.1528571428571425e-05,
      "loss": 0.0012,
      "step": 11860
    },
    {
      "epoch": 0.33914285714285713,
      "grad_norm": 0.19085200130939484,
      "learning_rate": 4.1521428571428574e-05,
      "loss": 0.0018,
      "step": 11870
    },
    {
      "epoch": 0.3394285714285714,
      "grad_norm": 0.10256248712539673,
      "learning_rate": 4.1514285714285716e-05,
      "loss": 0.0011,
      "step": 11880
    },
    {
      "epoch": 0.3397142857142857,
      "grad_norm": 0.23319844901561737,
      "learning_rate": 4.1507142857142864e-05,
      "loss": 0.0024,
      "step": 11890
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.0,
      "learning_rate": 4.15e-05,
      "loss": 0.001,
      "step": 11900
    },
    {
      "epoch": 0.3402857142857143,
      "grad_norm": 0.018814582377672195,
      "learning_rate": 4.149285714285715e-05,
      "loss": 0.0013,
      "step": 11910
    },
    {
      "epoch": 0.3405714285714286,
      "grad_norm": 0.04328980669379234,
      "learning_rate": 4.148571428571429e-05,
      "loss": 0.0015,
      "step": 11920
    },
    {
      "epoch": 0.34085714285714286,
      "grad_norm": 0.08655812591314316,
      "learning_rate": 4.147857142857143e-05,
      "loss": 0.0025,
      "step": 11930
    },
    {
      "epoch": 0.34114285714285714,
      "grad_norm": 0.0,
      "learning_rate": 4.147142857142857e-05,
      "loss": 0.0015,
      "step": 11940
    },
    {
      "epoch": 0.3414285714285714,
      "grad_norm": 0.0,
      "learning_rate": 4.1464285714285714e-05,
      "loss": 0.0009,
      "step": 11950
    },
    {
      "epoch": 0.3417142857142857,
      "grad_norm": 0.037256501615047455,
      "learning_rate": 4.145714285714286e-05,
      "loss": 0.0012,
      "step": 11960
    },
    {
      "epoch": 0.342,
      "grad_norm": 0.049933236092329025,
      "learning_rate": 4.145e-05,
      "loss": 0.0015,
      "step": 11970
    },
    {
      "epoch": 0.3422857142857143,
      "grad_norm": 0.0,
      "learning_rate": 4.1442857142857146e-05,
      "loss": 0.0024,
      "step": 11980
    },
    {
      "epoch": 0.3425714285714286,
      "grad_norm": 0.11741538345813751,
      "learning_rate": 4.143571428571429e-05,
      "loss": 0.0018,
      "step": 11990
    },
    {
      "epoch": 0.34285714285714286,
      "grad_norm": 0.2045222818851471,
      "learning_rate": 4.1428571428571437e-05,
      "loss": 0.0016,
      "step": 12000
    },
    {
      "epoch": 0.34314285714285714,
      "grad_norm": 0.0960821658372879,
      "learning_rate": 4.142142857142857e-05,
      "loss": 0.002,
      "step": 12010
    },
    {
      "epoch": 0.3434285714285714,
      "grad_norm": 0.030805343762040138,
      "learning_rate": 4.141428571428571e-05,
      "loss": 0.0013,
      "step": 12020
    },
    {
      "epoch": 0.3437142857142857,
      "grad_norm": 0.04237253591418266,
      "learning_rate": 4.140714285714286e-05,
      "loss": 0.0014,
      "step": 12030
    },
    {
      "epoch": 0.344,
      "grad_norm": 0.1567755490541458,
      "learning_rate": 4.14e-05,
      "loss": 0.0037,
      "step": 12040
    },
    {
      "epoch": 0.3442857142857143,
      "grad_norm": 0.039182789623737335,
      "learning_rate": 4.1392857142857145e-05,
      "loss": 0.001,
      "step": 12050
    },
    {
      "epoch": 0.3445714285714286,
      "grad_norm": 0.0,
      "learning_rate": 4.138571428571429e-05,
      "loss": 0.0018,
      "step": 12060
    },
    {
      "epoch": 0.34485714285714286,
      "grad_norm": 0.0641942098736763,
      "learning_rate": 4.1378571428571435e-05,
      "loss": 0.0019,
      "step": 12070
    },
    {
      "epoch": 0.34514285714285714,
      "grad_norm": 0.0,
      "learning_rate": 4.137142857142857e-05,
      "loss": 0.0013,
      "step": 12080
    },
    {
      "epoch": 0.3454285714285714,
      "grad_norm": 0.11021628230810165,
      "learning_rate": 4.136428571428572e-05,
      "loss": 0.0023,
      "step": 12090
    },
    {
      "epoch": 0.3457142857142857,
      "grad_norm": 0.19792644679546356,
      "learning_rate": 4.135714285714286e-05,
      "loss": 0.0024,
      "step": 12100
    },
    {
      "epoch": 0.346,
      "grad_norm": 0.0422213189303875,
      "learning_rate": 4.135e-05,
      "loss": 0.0023,
      "step": 12110
    },
    {
      "epoch": 0.3462857142857143,
      "grad_norm": 0.042285896837711334,
      "learning_rate": 4.1342857142857144e-05,
      "loss": 0.0026,
      "step": 12120
    },
    {
      "epoch": 0.3465714285714286,
      "grad_norm": 0.19527146220207214,
      "learning_rate": 4.1335714285714286e-05,
      "loss": 0.0008,
      "step": 12130
    },
    {
      "epoch": 0.34685714285714286,
      "grad_norm": 0.0,
      "learning_rate": 4.1328571428571434e-05,
      "loss": 0.0015,
      "step": 12140
    },
    {
      "epoch": 0.34714285714285714,
      "grad_norm": 0.09328470379114151,
      "learning_rate": 4.132142857142857e-05,
      "loss": 0.001,
      "step": 12150
    },
    {
      "epoch": 0.3474285714285714,
      "grad_norm": 0.04745117947459221,
      "learning_rate": 4.131428571428572e-05,
      "loss": 0.002,
      "step": 12160
    },
    {
      "epoch": 0.3477142857142857,
      "grad_norm": 0.27182796597480774,
      "learning_rate": 4.130714285714286e-05,
      "loss": 0.0015,
      "step": 12170
    },
    {
      "epoch": 0.348,
      "grad_norm": 0.0,
      "learning_rate": 4.13e-05,
      "loss": 0.0024,
      "step": 12180
    },
    {
      "epoch": 0.3482857142857143,
      "grad_norm": 0.1359911859035492,
      "learning_rate": 4.129285714285714e-05,
      "loss": 0.0013,
      "step": 12190
    },
    {
      "epoch": 0.3485714285714286,
      "grad_norm": 0.0314752496778965,
      "learning_rate": 4.128571428571429e-05,
      "loss": 0.0026,
      "step": 12200
    },
    {
      "epoch": 0.34885714285714287,
      "grad_norm": 0.11807138472795486,
      "learning_rate": 4.127857142857143e-05,
      "loss": 0.0013,
      "step": 12210
    },
    {
      "epoch": 0.34914285714285714,
      "grad_norm": 0.061617858707904816,
      "learning_rate": 4.1271428571428575e-05,
      "loss": 0.001,
      "step": 12220
    },
    {
      "epoch": 0.3494285714285714,
      "grad_norm": 0.07689216732978821,
      "learning_rate": 4.1264285714285716e-05,
      "loss": 0.002,
      "step": 12230
    },
    {
      "epoch": 0.3497142857142857,
      "grad_norm": 0.05112859606742859,
      "learning_rate": 4.125714285714286e-05,
      "loss": 0.0013,
      "step": 12240
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.04175322502851486,
      "learning_rate": 4.125e-05,
      "loss": 0.0018,
      "step": 12250
    },
    {
      "epoch": 0.3502857142857143,
      "grad_norm": 0.044312287122011185,
      "learning_rate": 4.124285714285714e-05,
      "loss": 0.0013,
      "step": 12260
    },
    {
      "epoch": 0.3505714285714286,
      "grad_norm": 0.0,
      "learning_rate": 4.123571428571429e-05,
      "loss": 0.001,
      "step": 12270
    },
    {
      "epoch": 0.35085714285714287,
      "grad_norm": 0.12124823778867722,
      "learning_rate": 4.122857142857143e-05,
      "loss": 0.0026,
      "step": 12280
    },
    {
      "epoch": 0.35114285714285715,
      "grad_norm": 0.04058837890625,
      "learning_rate": 4.1221428571428573e-05,
      "loss": 0.0007,
      "step": 12290
    },
    {
      "epoch": 0.3514285714285714,
      "grad_norm": 0.040839940309524536,
      "learning_rate": 4.1214285714285715e-05,
      "loss": 0.0011,
      "step": 12300
    },
    {
      "epoch": 0.3517142857142857,
      "grad_norm": 0.06364632397890091,
      "learning_rate": 4.1207142857142864e-05,
      "loss": 0.0013,
      "step": 12310
    },
    {
      "epoch": 0.352,
      "grad_norm": 0.1523314118385315,
      "learning_rate": 4.12e-05,
      "loss": 0.0016,
      "step": 12320
    },
    {
      "epoch": 0.3522857142857143,
      "grad_norm": 0.2071232795715332,
      "learning_rate": 4.119285714285715e-05,
      "loss": 0.0015,
      "step": 12330
    },
    {
      "epoch": 0.3525714285714286,
      "grad_norm": 0.17708855867385864,
      "learning_rate": 4.118571428571429e-05,
      "loss": 0.0022,
      "step": 12340
    },
    {
      "epoch": 0.35285714285714287,
      "grad_norm": 0.14411333203315735,
      "learning_rate": 4.117857142857143e-05,
      "loss": 0.0022,
      "step": 12350
    },
    {
      "epoch": 0.35314285714285715,
      "grad_norm": 0.29578131437301636,
      "learning_rate": 4.117142857142857e-05,
      "loss": 0.0014,
      "step": 12360
    },
    {
      "epoch": 0.3534285714285714,
      "grad_norm": 0.15339715778827667,
      "learning_rate": 4.1164285714285714e-05,
      "loss": 0.0013,
      "step": 12370
    },
    {
      "epoch": 0.3537142857142857,
      "grad_norm": 0.06816986203193665,
      "learning_rate": 4.115714285714286e-05,
      "loss": 0.0019,
      "step": 12380
    },
    {
      "epoch": 0.354,
      "grad_norm": 0.04619614779949188,
      "learning_rate": 4.115e-05,
      "loss": 0.0009,
      "step": 12390
    },
    {
      "epoch": 0.35428571428571426,
      "grad_norm": 0.04387076571583748,
      "learning_rate": 4.1142857142857146e-05,
      "loss": 0.0013,
      "step": 12400
    },
    {
      "epoch": 0.3545714285714286,
      "grad_norm": 0.030698811635375023,
      "learning_rate": 4.113571428571429e-05,
      "loss": 0.001,
      "step": 12410
    },
    {
      "epoch": 0.35485714285714287,
      "grad_norm": 0.34273242950439453,
      "learning_rate": 4.1128571428571436e-05,
      "loss": 0.0007,
      "step": 12420
    },
    {
      "epoch": 0.35514285714285715,
      "grad_norm": 0.2105855494737625,
      "learning_rate": 4.112142857142857e-05,
      "loss": 0.002,
      "step": 12430
    },
    {
      "epoch": 0.3554285714285714,
      "grad_norm": 0.1213330328464508,
      "learning_rate": 4.111428571428572e-05,
      "loss": 0.0018,
      "step": 12440
    },
    {
      "epoch": 0.3557142857142857,
      "grad_norm": 0.042958471924066544,
      "learning_rate": 4.110714285714286e-05,
      "loss": 0.0011,
      "step": 12450
    },
    {
      "epoch": 0.356,
      "grad_norm": 0.3300413191318512,
      "learning_rate": 4.11e-05,
      "loss": 0.001,
      "step": 12460
    },
    {
      "epoch": 0.35628571428571426,
      "grad_norm": 0.04034576937556267,
      "learning_rate": 4.1092857142857145e-05,
      "loss": 0.0026,
      "step": 12470
    },
    {
      "epoch": 0.3565714285714286,
      "grad_norm": 0.24933244287967682,
      "learning_rate": 4.1085714285714286e-05,
      "loss": 0.0019,
      "step": 12480
    },
    {
      "epoch": 0.3568571428571429,
      "grad_norm": 0.04971590265631676,
      "learning_rate": 4.1078571428571435e-05,
      "loss": 0.0013,
      "step": 12490
    },
    {
      "epoch": 0.35714285714285715,
      "grad_norm": 0.08325472474098206,
      "learning_rate": 4.107142857142857e-05,
      "loss": 0.0017,
      "step": 12500
    },
    {
      "epoch": 0.35742857142857143,
      "grad_norm": 0.056034281849861145,
      "learning_rate": 4.106428571428572e-05,
      "loss": 0.0019,
      "step": 12510
    },
    {
      "epoch": 0.3577142857142857,
      "grad_norm": 0.25432252883911133,
      "learning_rate": 4.105714285714286e-05,
      "loss": 0.0023,
      "step": 12520
    },
    {
      "epoch": 0.358,
      "grad_norm": 0.08547553420066833,
      "learning_rate": 4.105e-05,
      "loss": 0.0012,
      "step": 12530
    },
    {
      "epoch": 0.35828571428571426,
      "grad_norm": 0.1013387143611908,
      "learning_rate": 4.1042857142857143e-05,
      "loss": 0.0014,
      "step": 12540
    },
    {
      "epoch": 0.3585714285714286,
      "grad_norm": 0.07329017668962479,
      "learning_rate": 4.1035714285714285e-05,
      "loss": 0.0017,
      "step": 12550
    },
    {
      "epoch": 0.3588571428571429,
      "grad_norm": 0.04300590977072716,
      "learning_rate": 4.1028571428571434e-05,
      "loss": 0.001,
      "step": 12560
    },
    {
      "epoch": 0.35914285714285715,
      "grad_norm": 0.0,
      "learning_rate": 4.102142857142857e-05,
      "loss": 0.0023,
      "step": 12570
    },
    {
      "epoch": 0.35942857142857143,
      "grad_norm": 0.0872517004609108,
      "learning_rate": 4.101428571428572e-05,
      "loss": 0.0022,
      "step": 12580
    },
    {
      "epoch": 0.3597142857142857,
      "grad_norm": 0.05162692070007324,
      "learning_rate": 4.100714285714286e-05,
      "loss": 0.0022,
      "step": 12590
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.10452202707529068,
      "learning_rate": 4.1e-05,
      "loss": 0.0023,
      "step": 12600
    },
    {
      "epoch": 0.36028571428571426,
      "grad_norm": 0.06983793526887894,
      "learning_rate": 4.099285714285714e-05,
      "loss": 0.0011,
      "step": 12610
    },
    {
      "epoch": 0.3605714285714286,
      "grad_norm": 0.28539398312568665,
      "learning_rate": 4.098571428571429e-05,
      "loss": 0.0017,
      "step": 12620
    },
    {
      "epoch": 0.3608571428571429,
      "grad_norm": 0.0446305014193058,
      "learning_rate": 4.097857142857143e-05,
      "loss": 0.0019,
      "step": 12630
    },
    {
      "epoch": 0.36114285714285715,
      "grad_norm": 0.343374639749527,
      "learning_rate": 4.0971428571428574e-05,
      "loss": 0.0008,
      "step": 12640
    },
    {
      "epoch": 0.36142857142857143,
      "grad_norm": 0.05954161286354065,
      "learning_rate": 4.0964285714285716e-05,
      "loss": 0.003,
      "step": 12650
    },
    {
      "epoch": 0.3617142857142857,
      "grad_norm": 0.019474176689982414,
      "learning_rate": 4.095714285714286e-05,
      "loss": 0.0033,
      "step": 12660
    },
    {
      "epoch": 0.362,
      "grad_norm": 0.15114232897758484,
      "learning_rate": 4.095e-05,
      "loss": 0.0016,
      "step": 12670
    },
    {
      "epoch": 0.36228571428571427,
      "grad_norm": 0.0,
      "learning_rate": 4.094285714285714e-05,
      "loss": 0.0017,
      "step": 12680
    },
    {
      "epoch": 0.36257142857142854,
      "grad_norm": 0.13122503459453583,
      "learning_rate": 4.093571428571429e-05,
      "loss": 0.0023,
      "step": 12690
    },
    {
      "epoch": 0.3628571428571429,
      "grad_norm": 0.027534466236829758,
      "learning_rate": 4.092857142857143e-05,
      "loss": 0.0015,
      "step": 12700
    },
    {
      "epoch": 0.36314285714285716,
      "grad_norm": 0.04180751368403435,
      "learning_rate": 4.092142857142857e-05,
      "loss": 0.0021,
      "step": 12710
    },
    {
      "epoch": 0.36342857142857143,
      "grad_norm": 0.13826239109039307,
      "learning_rate": 4.0914285714285715e-05,
      "loss": 0.0018,
      "step": 12720
    },
    {
      "epoch": 0.3637142857142857,
      "grad_norm": 0.20956461131572723,
      "learning_rate": 4.090714285714286e-05,
      "loss": 0.0022,
      "step": 12730
    },
    {
      "epoch": 0.364,
      "grad_norm": 0.060531135648489,
      "learning_rate": 4.09e-05,
      "loss": 0.0013,
      "step": 12740
    },
    {
      "epoch": 0.36428571428571427,
      "grad_norm": 0.048090096563100815,
      "learning_rate": 4.0892857142857147e-05,
      "loss": 0.0013,
      "step": 12750
    },
    {
      "epoch": 0.36457142857142855,
      "grad_norm": 0.09096954017877579,
      "learning_rate": 4.088571428571429e-05,
      "loss": 0.0018,
      "step": 12760
    },
    {
      "epoch": 0.3648571428571429,
      "grad_norm": 0.042006541043519974,
      "learning_rate": 4.087857142857143e-05,
      "loss": 0.0011,
      "step": 12770
    },
    {
      "epoch": 0.36514285714285716,
      "grad_norm": 0.060988783836364746,
      "learning_rate": 4.087142857142857e-05,
      "loss": 0.0023,
      "step": 12780
    },
    {
      "epoch": 0.36542857142857144,
      "grad_norm": 0.1688031107187271,
      "learning_rate": 4.0864285714285713e-05,
      "loss": 0.0018,
      "step": 12790
    },
    {
      "epoch": 0.3657142857142857,
      "grad_norm": 0.0592467375099659,
      "learning_rate": 4.085714285714286e-05,
      "loss": 0.0019,
      "step": 12800
    },
    {
      "epoch": 0.366,
      "grad_norm": 0.17530933022499084,
      "learning_rate": 4.085e-05,
      "loss": 0.0011,
      "step": 12810
    },
    {
      "epoch": 0.36628571428571427,
      "grad_norm": 0.05120816454291344,
      "learning_rate": 4.0842857142857145e-05,
      "loss": 0.0012,
      "step": 12820
    },
    {
      "epoch": 0.36657142857142855,
      "grad_norm": 0.16785773634910583,
      "learning_rate": 4.083571428571429e-05,
      "loss": 0.0011,
      "step": 12830
    },
    {
      "epoch": 0.3668571428571429,
      "grad_norm": 0.03259150683879852,
      "learning_rate": 4.0828571428571436e-05,
      "loss": 0.0016,
      "step": 12840
    },
    {
      "epoch": 0.36714285714285716,
      "grad_norm": 0.21241043508052826,
      "learning_rate": 4.082142857142857e-05,
      "loss": 0.001,
      "step": 12850
    },
    {
      "epoch": 0.36742857142857144,
      "grad_norm": 0.04557783529162407,
      "learning_rate": 4.081428571428572e-05,
      "loss": 0.0016,
      "step": 12860
    },
    {
      "epoch": 0.3677142857142857,
      "grad_norm": 0.1520029753446579,
      "learning_rate": 4.080714285714286e-05,
      "loss": 0.0022,
      "step": 12870
    },
    {
      "epoch": 0.368,
      "grad_norm": 0.2502734959125519,
      "learning_rate": 4.08e-05,
      "loss": 0.0027,
      "step": 12880
    },
    {
      "epoch": 0.36828571428571427,
      "grad_norm": 0.08143080025911331,
      "learning_rate": 4.0792857142857144e-05,
      "loss": 0.0023,
      "step": 12890
    },
    {
      "epoch": 0.36857142857142855,
      "grad_norm": 0.07890696823596954,
      "learning_rate": 4.0785714285714286e-05,
      "loss": 0.0021,
      "step": 12900
    },
    {
      "epoch": 0.3688571428571429,
      "grad_norm": 0.035172536969184875,
      "learning_rate": 4.0778571428571434e-05,
      "loss": 0.0018,
      "step": 12910
    },
    {
      "epoch": 0.36914285714285716,
      "grad_norm": 0.21978607773780823,
      "learning_rate": 4.077142857142857e-05,
      "loss": 0.0015,
      "step": 12920
    },
    {
      "epoch": 0.36942857142857144,
      "grad_norm": 0.17578744888305664,
      "learning_rate": 4.076428571428572e-05,
      "loss": 0.0022,
      "step": 12930
    },
    {
      "epoch": 0.3697142857142857,
      "grad_norm": 0.18484345078468323,
      "learning_rate": 4.075714285714286e-05,
      "loss": 0.0014,
      "step": 12940
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.2635814845561981,
      "learning_rate": 4.075e-05,
      "loss": 0.0017,
      "step": 12950
    },
    {
      "epoch": 0.3702857142857143,
      "grad_norm": 0.1729721575975418,
      "learning_rate": 4.074285714285714e-05,
      "loss": 0.0015,
      "step": 12960
    },
    {
      "epoch": 0.37057142857142855,
      "grad_norm": 0.14853587746620178,
      "learning_rate": 4.073571428571429e-05,
      "loss": 0.0026,
      "step": 12970
    },
    {
      "epoch": 0.37085714285714283,
      "grad_norm": 0.0,
      "learning_rate": 4.072857142857143e-05,
      "loss": 0.0009,
      "step": 12980
    },
    {
      "epoch": 0.37114285714285716,
      "grad_norm": 0.051208194345235825,
      "learning_rate": 4.0721428571428575e-05,
      "loss": 0.0023,
      "step": 12990
    },
    {
      "epoch": 0.37142857142857144,
      "grad_norm": 0.12748096883296967,
      "learning_rate": 4.0714285714285717e-05,
      "loss": 0.003,
      "step": 13000
    },
    {
      "epoch": 0.3717142857142857,
      "grad_norm": 0.06173110380768776,
      "learning_rate": 4.070714285714286e-05,
      "loss": 0.002,
      "step": 13010
    },
    {
      "epoch": 0.372,
      "grad_norm": 0.2235102653503418,
      "learning_rate": 4.07e-05,
      "loss": 0.0022,
      "step": 13020
    },
    {
      "epoch": 0.3722857142857143,
      "grad_norm": 0.0764685645699501,
      "learning_rate": 4.069285714285714e-05,
      "loss": 0.002,
      "step": 13030
    },
    {
      "epoch": 0.37257142857142855,
      "grad_norm": 0.04458582028746605,
      "learning_rate": 4.068571428571429e-05,
      "loss": 0.0015,
      "step": 13040
    },
    {
      "epoch": 0.37285714285714283,
      "grad_norm": 0.2855948507785797,
      "learning_rate": 4.067857142857143e-05,
      "loss": 0.0026,
      "step": 13050
    },
    {
      "epoch": 0.37314285714285716,
      "grad_norm": 0.11033498495817184,
      "learning_rate": 4.0671428571428574e-05,
      "loss": 0.001,
      "step": 13060
    },
    {
      "epoch": 0.37342857142857144,
      "grad_norm": 0.2588745355606079,
      "learning_rate": 4.0664285714285715e-05,
      "loss": 0.0011,
      "step": 13070
    },
    {
      "epoch": 0.3737142857142857,
      "grad_norm": 0.088722363114357,
      "learning_rate": 4.065714285714286e-05,
      "loss": 0.0016,
      "step": 13080
    },
    {
      "epoch": 0.374,
      "grad_norm": 0.0,
      "learning_rate": 4.065e-05,
      "loss": 0.0018,
      "step": 13090
    },
    {
      "epoch": 0.3742857142857143,
      "grad_norm": 0.04715937376022339,
      "learning_rate": 4.064285714285714e-05,
      "loss": 0.0014,
      "step": 13100
    },
    {
      "epoch": 0.37457142857142856,
      "grad_norm": 0.502400815486908,
      "learning_rate": 4.063571428571429e-05,
      "loss": 0.0021,
      "step": 13110
    },
    {
      "epoch": 0.37485714285714283,
      "grad_norm": 0.08503299206495285,
      "learning_rate": 4.062857142857143e-05,
      "loss": 0.0011,
      "step": 13120
    },
    {
      "epoch": 0.37514285714285717,
      "grad_norm": 0.0,
      "learning_rate": 4.062142857142857e-05,
      "loss": 0.0017,
      "step": 13130
    },
    {
      "epoch": 0.37542857142857144,
      "grad_norm": 0.2589886784553528,
      "learning_rate": 4.0614285714285714e-05,
      "loss": 0.002,
      "step": 13140
    },
    {
      "epoch": 0.3757142857142857,
      "grad_norm": 0.2703128457069397,
      "learning_rate": 4.060714285714286e-05,
      "loss": 0.0017,
      "step": 13150
    },
    {
      "epoch": 0.376,
      "grad_norm": 0.24078214168548584,
      "learning_rate": 4.0600000000000004e-05,
      "loss": 0.0017,
      "step": 13160
    },
    {
      "epoch": 0.3762857142857143,
      "grad_norm": 0.1054062694311142,
      "learning_rate": 4.0592857142857146e-05,
      "loss": 0.0022,
      "step": 13170
    },
    {
      "epoch": 0.37657142857142856,
      "grad_norm": 0.3350631594657898,
      "learning_rate": 4.058571428571429e-05,
      "loss": 0.0022,
      "step": 13180
    },
    {
      "epoch": 0.37685714285714284,
      "grad_norm": 0.16059119999408722,
      "learning_rate": 4.057857142857143e-05,
      "loss": 0.0019,
      "step": 13190
    },
    {
      "epoch": 0.37714285714285717,
      "grad_norm": 0.12845467031002045,
      "learning_rate": 4.057142857142857e-05,
      "loss": 0.0024,
      "step": 13200
    },
    {
      "epoch": 0.37742857142857145,
      "grad_norm": 0.07286908477544785,
      "learning_rate": 4.056428571428571e-05,
      "loss": 0.0022,
      "step": 13210
    },
    {
      "epoch": 0.3777142857142857,
      "grad_norm": 0.1622338891029358,
      "learning_rate": 4.055714285714286e-05,
      "loss": 0.0012,
      "step": 13220
    },
    {
      "epoch": 0.378,
      "grad_norm": 0.0,
      "learning_rate": 4.055e-05,
      "loss": 0.001,
      "step": 13230
    },
    {
      "epoch": 0.3782857142857143,
      "grad_norm": 0.07849202305078506,
      "learning_rate": 4.0542857142857145e-05,
      "loss": 0.0016,
      "step": 13240
    },
    {
      "epoch": 0.37857142857142856,
      "grad_norm": 0.24083837866783142,
      "learning_rate": 4.0535714285714287e-05,
      "loss": 0.0019,
      "step": 13250
    },
    {
      "epoch": 0.37885714285714284,
      "grad_norm": 0.08526264131069183,
      "learning_rate": 4.0528571428571435e-05,
      "loss": 0.002,
      "step": 13260
    },
    {
      "epoch": 0.37914285714285717,
      "grad_norm": 0.0408690981566906,
      "learning_rate": 4.052142857142857e-05,
      "loss": 0.0021,
      "step": 13270
    },
    {
      "epoch": 0.37942857142857145,
      "grad_norm": 0.0747794657945633,
      "learning_rate": 4.051428571428572e-05,
      "loss": 0.0013,
      "step": 13280
    },
    {
      "epoch": 0.3797142857142857,
      "grad_norm": 0.12003270536661148,
      "learning_rate": 4.050714285714286e-05,
      "loss": 0.002,
      "step": 13290
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.2202795296907425,
      "learning_rate": 4.05e-05,
      "loss": 0.0016,
      "step": 13300
    },
    {
      "epoch": 0.3802857142857143,
      "grad_norm": 0.06997276097536087,
      "learning_rate": 4.0492857142857144e-05,
      "loss": 0.0013,
      "step": 13310
    },
    {
      "epoch": 0.38057142857142856,
      "grad_norm": 0.05352257564663887,
      "learning_rate": 4.0485714285714285e-05,
      "loss": 0.0021,
      "step": 13320
    },
    {
      "epoch": 0.38085714285714284,
      "grad_norm": 0.040070220828056335,
      "learning_rate": 4.0478571428571434e-05,
      "loss": 0.0011,
      "step": 13330
    },
    {
      "epoch": 0.3811428571428571,
      "grad_norm": 0.0,
      "learning_rate": 4.047142857142857e-05,
      "loss": 0.0023,
      "step": 13340
    },
    {
      "epoch": 0.38142857142857145,
      "grad_norm": 0.0978684276342392,
      "learning_rate": 4.046428571428572e-05,
      "loss": 0.0013,
      "step": 13350
    },
    {
      "epoch": 0.38171428571428573,
      "grad_norm": 0.08157643675804138,
      "learning_rate": 4.045714285714286e-05,
      "loss": 0.0015,
      "step": 13360
    },
    {
      "epoch": 0.382,
      "grad_norm": 0.16418687999248505,
      "learning_rate": 4.045000000000001e-05,
      "loss": 0.0017,
      "step": 13370
    },
    {
      "epoch": 0.3822857142857143,
      "grad_norm": 0.06241561844944954,
      "learning_rate": 4.044285714285714e-05,
      "loss": 0.0016,
      "step": 13380
    },
    {
      "epoch": 0.38257142857142856,
      "grad_norm": 0.15027518570423126,
      "learning_rate": 4.043571428571429e-05,
      "loss": 0.002,
      "step": 13390
    },
    {
      "epoch": 0.38285714285714284,
      "grad_norm": 0.06374186277389526,
      "learning_rate": 4.042857142857143e-05,
      "loss": 0.002,
      "step": 13400
    },
    {
      "epoch": 0.3831428571428571,
      "grad_norm": 0.05551987141370773,
      "learning_rate": 4.0421428571428574e-05,
      "loss": 0.0025,
      "step": 13410
    },
    {
      "epoch": 0.38342857142857145,
      "grad_norm": 0.08575018495321274,
      "learning_rate": 4.0414285714285716e-05,
      "loss": 0.0017,
      "step": 13420
    },
    {
      "epoch": 0.38371428571428573,
      "grad_norm": 0.18504954874515533,
      "learning_rate": 4.040714285714286e-05,
      "loss": 0.0023,
      "step": 13430
    },
    {
      "epoch": 0.384,
      "grad_norm": 0.04454183578491211,
      "learning_rate": 4.0400000000000006e-05,
      "loss": 0.0027,
      "step": 13440
    },
    {
      "epoch": 0.3842857142857143,
      "grad_norm": 0.03997783735394478,
      "learning_rate": 4.039285714285714e-05,
      "loss": 0.0015,
      "step": 13450
    },
    {
      "epoch": 0.38457142857142856,
      "grad_norm": 0.11704583466053009,
      "learning_rate": 4.038571428571429e-05,
      "loss": 0.0019,
      "step": 13460
    },
    {
      "epoch": 0.38485714285714284,
      "grad_norm": 0.04590976983308792,
      "learning_rate": 4.037857142857143e-05,
      "loss": 0.0027,
      "step": 13470
    },
    {
      "epoch": 0.3851428571428571,
      "grad_norm": 0.2103695571422577,
      "learning_rate": 4.037142857142857e-05,
      "loss": 0.0022,
      "step": 13480
    },
    {
      "epoch": 0.38542857142857145,
      "grad_norm": 0.20608726143836975,
      "learning_rate": 4.0364285714285715e-05,
      "loss": 0.0009,
      "step": 13490
    },
    {
      "epoch": 0.38571428571428573,
      "grad_norm": 0.26509496569633484,
      "learning_rate": 4.035714285714286e-05,
      "loss": 0.0015,
      "step": 13500
    },
    {
      "epoch": 0.386,
      "grad_norm": 0.05490000918507576,
      "learning_rate": 4.0350000000000005e-05,
      "loss": 0.0016,
      "step": 13510
    },
    {
      "epoch": 0.3862857142857143,
      "grad_norm": 0.034569982439279556,
      "learning_rate": 4.034285714285715e-05,
      "loss": 0.0017,
      "step": 13520
    },
    {
      "epoch": 0.38657142857142857,
      "grad_norm": 0.19186848402023315,
      "learning_rate": 4.033571428571429e-05,
      "loss": 0.0019,
      "step": 13530
    },
    {
      "epoch": 0.38685714285714284,
      "grad_norm": 0.07842396199703217,
      "learning_rate": 4.032857142857143e-05,
      "loss": 0.0017,
      "step": 13540
    },
    {
      "epoch": 0.3871428571428571,
      "grad_norm": 0.04199618101119995,
      "learning_rate": 4.032142857142857e-05,
      "loss": 0.0017,
      "step": 13550
    },
    {
      "epoch": 0.38742857142857146,
      "grad_norm": 0.0,
      "learning_rate": 4.0314285714285714e-05,
      "loss": 0.002,
      "step": 13560
    },
    {
      "epoch": 0.38771428571428573,
      "grad_norm": 0.2075604945421219,
      "learning_rate": 4.030714285714286e-05,
      "loss": 0.0011,
      "step": 13570
    },
    {
      "epoch": 0.388,
      "grad_norm": 0.04377410560846329,
      "learning_rate": 4.0300000000000004e-05,
      "loss": 0.0018,
      "step": 13580
    },
    {
      "epoch": 0.3882857142857143,
      "grad_norm": 0.08207278698682785,
      "learning_rate": 4.0292857142857146e-05,
      "loss": 0.0022,
      "step": 13590
    },
    {
      "epoch": 0.38857142857142857,
      "grad_norm": 0.0492442362010479,
      "learning_rate": 4.028571428571429e-05,
      "loss": 0.0011,
      "step": 13600
    },
    {
      "epoch": 0.38885714285714285,
      "grad_norm": 0.0,
      "learning_rate": 4.027857142857143e-05,
      "loss": 0.0012,
      "step": 13610
    },
    {
      "epoch": 0.3891428571428571,
      "grad_norm": 0.04049605876207352,
      "learning_rate": 4.027142857142857e-05,
      "loss": 0.0012,
      "step": 13620
    },
    {
      "epoch": 0.3894285714285714,
      "grad_norm": 0.11723688989877701,
      "learning_rate": 4.026428571428571e-05,
      "loss": 0.0013,
      "step": 13630
    },
    {
      "epoch": 0.38971428571428574,
      "grad_norm": 0.25672033429145813,
      "learning_rate": 4.025714285714286e-05,
      "loss": 0.0018,
      "step": 13640
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.068531833589077,
      "learning_rate": 4.025e-05,
      "loss": 0.0019,
      "step": 13650
    },
    {
      "epoch": 0.3902857142857143,
      "grad_norm": 0.04117020219564438,
      "learning_rate": 4.0242857142857144e-05,
      "loss": 0.0015,
      "step": 13660
    },
    {
      "epoch": 0.39057142857142857,
      "grad_norm": 0.7650088667869568,
      "learning_rate": 4.0235714285714286e-05,
      "loss": 0.0015,
      "step": 13670
    },
    {
      "epoch": 0.39085714285714285,
      "grad_norm": 0.12440171092748642,
      "learning_rate": 4.0228571428571434e-05,
      "loss": 0.0021,
      "step": 13680
    },
    {
      "epoch": 0.3911428571428571,
      "grad_norm": 0.29252302646636963,
      "learning_rate": 4.022142857142857e-05,
      "loss": 0.0017,
      "step": 13690
    },
    {
      "epoch": 0.3914285714285714,
      "grad_norm": 0.029064351692795753,
      "learning_rate": 4.021428571428572e-05,
      "loss": 0.0015,
      "step": 13700
    },
    {
      "epoch": 0.39171428571428574,
      "grad_norm": 0.12695471942424774,
      "learning_rate": 4.020714285714286e-05,
      "loss": 0.0033,
      "step": 13710
    },
    {
      "epoch": 0.392,
      "grad_norm": 0.15424048900604248,
      "learning_rate": 4.02e-05,
      "loss": 0.0019,
      "step": 13720
    },
    {
      "epoch": 0.3922857142857143,
      "grad_norm": 0.24126283824443817,
      "learning_rate": 4.019285714285714e-05,
      "loss": 0.0021,
      "step": 13730
    },
    {
      "epoch": 0.39257142857142857,
      "grad_norm": 0.08659268170595169,
      "learning_rate": 4.0185714285714285e-05,
      "loss": 0.0023,
      "step": 13740
    },
    {
      "epoch": 0.39285714285714285,
      "grad_norm": 0.10697559267282486,
      "learning_rate": 4.017857142857143e-05,
      "loss": 0.0011,
      "step": 13750
    },
    {
      "epoch": 0.3931428571428571,
      "grad_norm": 0.05001874640583992,
      "learning_rate": 4.017142857142857e-05,
      "loss": 0.0027,
      "step": 13760
    },
    {
      "epoch": 0.3934285714285714,
      "grad_norm": 0.08174919337034225,
      "learning_rate": 4.016428571428572e-05,
      "loss": 0.0015,
      "step": 13770
    },
    {
      "epoch": 0.39371428571428574,
      "grad_norm": 0.070240318775177,
      "learning_rate": 4.015714285714286e-05,
      "loss": 0.0008,
      "step": 13780
    },
    {
      "epoch": 0.394,
      "grad_norm": 0.16967888176441193,
      "learning_rate": 4.015000000000001e-05,
      "loss": 0.0017,
      "step": 13790
    },
    {
      "epoch": 0.3942857142857143,
      "grad_norm": 0.08175376802682877,
      "learning_rate": 4.014285714285714e-05,
      "loss": 0.0013,
      "step": 13800
    },
    {
      "epoch": 0.3945714285714286,
      "grad_norm": 0.06534139066934586,
      "learning_rate": 4.013571428571429e-05,
      "loss": 0.0024,
      "step": 13810
    },
    {
      "epoch": 0.39485714285714285,
      "grad_norm": 0.044911906123161316,
      "learning_rate": 4.012857142857143e-05,
      "loss": 0.0015,
      "step": 13820
    },
    {
      "epoch": 0.39514285714285713,
      "grad_norm": 0.04123647138476372,
      "learning_rate": 4.0121428571428574e-05,
      "loss": 0.0009,
      "step": 13830
    },
    {
      "epoch": 0.3954285714285714,
      "grad_norm": 0.25329670310020447,
      "learning_rate": 4.0114285714285715e-05,
      "loss": 0.0018,
      "step": 13840
    },
    {
      "epoch": 0.39571428571428574,
      "grad_norm": 0.05508505553007126,
      "learning_rate": 4.010714285714286e-05,
      "loss": 0.0021,
      "step": 13850
    },
    {
      "epoch": 0.396,
      "grad_norm": 0.09152772277593613,
      "learning_rate": 4.0100000000000006e-05,
      "loss": 0.0011,
      "step": 13860
    },
    {
      "epoch": 0.3962857142857143,
      "grad_norm": 0.04483205825090408,
      "learning_rate": 4.009285714285714e-05,
      "loss": 0.0026,
      "step": 13870
    },
    {
      "epoch": 0.3965714285714286,
      "grad_norm": 0.2686811685562134,
      "learning_rate": 4.008571428571429e-05,
      "loss": 0.0019,
      "step": 13880
    },
    {
      "epoch": 0.39685714285714285,
      "grad_norm": 0.04230441153049469,
      "learning_rate": 4.007857142857143e-05,
      "loss": 0.0023,
      "step": 13890
    },
    {
      "epoch": 0.39714285714285713,
      "grad_norm": 0.29011276364326477,
      "learning_rate": 4.007142857142857e-05,
      "loss": 0.0017,
      "step": 13900
    },
    {
      "epoch": 0.3974285714285714,
      "grad_norm": 0.0943983942270279,
      "learning_rate": 4.0064285714285714e-05,
      "loss": 0.0023,
      "step": 13910
    },
    {
      "epoch": 0.3977142857142857,
      "grad_norm": 0.10720515251159668,
      "learning_rate": 4.005714285714286e-05,
      "loss": 0.002,
      "step": 13920
    },
    {
      "epoch": 0.398,
      "grad_norm": 0.2583409547805786,
      "learning_rate": 4.0050000000000004e-05,
      "loss": 0.002,
      "step": 13930
    },
    {
      "epoch": 0.3982857142857143,
      "grad_norm": 0.0,
      "learning_rate": 4.0042857142857146e-05,
      "loss": 0.002,
      "step": 13940
    },
    {
      "epoch": 0.3985714285714286,
      "grad_norm": 0.3074309825897217,
      "learning_rate": 4.003571428571429e-05,
      "loss": 0.0016,
      "step": 13950
    },
    {
      "epoch": 0.39885714285714285,
      "grad_norm": 0.0,
      "learning_rate": 4.002857142857143e-05,
      "loss": 0.0008,
      "step": 13960
    },
    {
      "epoch": 0.39914285714285713,
      "grad_norm": 0.15011684596538544,
      "learning_rate": 4.002142857142857e-05,
      "loss": 0.0022,
      "step": 13970
    },
    {
      "epoch": 0.3994285714285714,
      "grad_norm": 0.09273810684680939,
      "learning_rate": 4.001428571428571e-05,
      "loss": 0.0018,
      "step": 13980
    },
    {
      "epoch": 0.3997142857142857,
      "grad_norm": 0.03894152492284775,
      "learning_rate": 4.000714285714286e-05,
      "loss": 0.0018,
      "step": 13990
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.08961842954158783,
      "learning_rate": 4e-05,
      "loss": 0.0017,
      "step": 14000
    },
    {
      "epoch": 0.4002857142857143,
      "grad_norm": 0.16415700316429138,
      "learning_rate": 3.9992857142857145e-05,
      "loss": 0.0008,
      "step": 14010
    },
    {
      "epoch": 0.4005714285714286,
      "grad_norm": 0.0799478143453598,
      "learning_rate": 3.998571428571429e-05,
      "loss": 0.0017,
      "step": 14020
    },
    {
      "epoch": 0.40085714285714286,
      "grad_norm": 0.07831823080778122,
      "learning_rate": 3.9978571428571435e-05,
      "loss": 0.0022,
      "step": 14030
    },
    {
      "epoch": 0.40114285714285713,
      "grad_norm": 0.4580683708190918,
      "learning_rate": 3.997142857142857e-05,
      "loss": 0.0017,
      "step": 14040
    },
    {
      "epoch": 0.4014285714285714,
      "grad_norm": 0.07736416161060333,
      "learning_rate": 3.996428571428571e-05,
      "loss": 0.0022,
      "step": 14050
    },
    {
      "epoch": 0.4017142857142857,
      "grad_norm": 0.046651728451251984,
      "learning_rate": 3.995714285714286e-05,
      "loss": 0.0021,
      "step": 14060
    },
    {
      "epoch": 0.402,
      "grad_norm": 0.06503791362047195,
      "learning_rate": 3.995e-05,
      "loss": 0.0006,
      "step": 14070
    },
    {
      "epoch": 0.4022857142857143,
      "grad_norm": 0.052947454154491425,
      "learning_rate": 3.9942857142857144e-05,
      "loss": 0.0017,
      "step": 14080
    },
    {
      "epoch": 0.4025714285714286,
      "grad_norm": 0.04885326698422432,
      "learning_rate": 3.9935714285714285e-05,
      "loss": 0.0031,
      "step": 14090
    },
    {
      "epoch": 0.40285714285714286,
      "grad_norm": 0.24461811780929565,
      "learning_rate": 3.9928571428571434e-05,
      "loss": 0.0023,
      "step": 14100
    },
    {
      "epoch": 0.40314285714285714,
      "grad_norm": 0.04689110815525055,
      "learning_rate": 3.992142857142857e-05,
      "loss": 0.0028,
      "step": 14110
    },
    {
      "epoch": 0.4034285714285714,
      "grad_norm": 0.11010999232530594,
      "learning_rate": 3.991428571428572e-05,
      "loss": 0.0018,
      "step": 14120
    },
    {
      "epoch": 0.4037142857142857,
      "grad_norm": 0.03315640985965729,
      "learning_rate": 3.990714285714286e-05,
      "loss": 0.0023,
      "step": 14130
    },
    {
      "epoch": 0.404,
      "grad_norm": 0.22196029126644135,
      "learning_rate": 3.99e-05,
      "loss": 0.0017,
      "step": 14140
    },
    {
      "epoch": 0.4042857142857143,
      "grad_norm": 0.0,
      "learning_rate": 3.989285714285714e-05,
      "loss": 0.0015,
      "step": 14150
    },
    {
      "epoch": 0.4045714285714286,
      "grad_norm": 0.06277792900800705,
      "learning_rate": 3.9885714285714284e-05,
      "loss": 0.0026,
      "step": 14160
    },
    {
      "epoch": 0.40485714285714286,
      "grad_norm": 0.0631493479013443,
      "learning_rate": 3.987857142857143e-05,
      "loss": 0.0028,
      "step": 14170
    },
    {
      "epoch": 0.40514285714285714,
      "grad_norm": 0.17260314524173737,
      "learning_rate": 3.987142857142857e-05,
      "loss": 0.0021,
      "step": 14180
    },
    {
      "epoch": 0.4054285714285714,
      "grad_norm": 0.028889598324894905,
      "learning_rate": 3.9864285714285716e-05,
      "loss": 0.0013,
      "step": 14190
    },
    {
      "epoch": 0.4057142857142857,
      "grad_norm": 0.043291252106428146,
      "learning_rate": 3.985714285714286e-05,
      "loss": 0.0023,
      "step": 14200
    },
    {
      "epoch": 0.406,
      "grad_norm": 0.08749502152204514,
      "learning_rate": 3.9850000000000006e-05,
      "loss": 0.0007,
      "step": 14210
    },
    {
      "epoch": 0.4062857142857143,
      "grad_norm": 0.04357023909687996,
      "learning_rate": 3.984285714285714e-05,
      "loss": 0.0011,
      "step": 14220
    },
    {
      "epoch": 0.4065714285714286,
      "grad_norm": 0.0394938699901104,
      "learning_rate": 3.983571428571429e-05,
      "loss": 0.0012,
      "step": 14230
    },
    {
      "epoch": 0.40685714285714286,
      "grad_norm": 0.046219293028116226,
      "learning_rate": 3.982857142857143e-05,
      "loss": 0.0017,
      "step": 14240
    },
    {
      "epoch": 0.40714285714285714,
      "grad_norm": 0.18018600344657898,
      "learning_rate": 3.982142857142857e-05,
      "loss": 0.0023,
      "step": 14250
    },
    {
      "epoch": 0.4074285714285714,
      "grad_norm": 0.09981100261211395,
      "learning_rate": 3.9814285714285715e-05,
      "loss": 0.0011,
      "step": 14260
    },
    {
      "epoch": 0.4077142857142857,
      "grad_norm": 0.30419519543647766,
      "learning_rate": 3.980714285714286e-05,
      "loss": 0.0028,
      "step": 14270
    },
    {
      "epoch": 0.408,
      "grad_norm": 0.11577259004116058,
      "learning_rate": 3.9800000000000005e-05,
      "loss": 0.0013,
      "step": 14280
    },
    {
      "epoch": 0.4082857142857143,
      "grad_norm": 0.04294613003730774,
      "learning_rate": 3.979285714285714e-05,
      "loss": 0.0015,
      "step": 14290
    },
    {
      "epoch": 0.4085714285714286,
      "grad_norm": 0.0,
      "learning_rate": 3.978571428571429e-05,
      "loss": 0.0022,
      "step": 14300
    },
    {
      "epoch": 0.40885714285714286,
      "grad_norm": 0.21833951771259308,
      "learning_rate": 3.977857142857143e-05,
      "loss": 0.0023,
      "step": 14310
    },
    {
      "epoch": 0.40914285714285714,
      "grad_norm": 0.0,
      "learning_rate": 3.977142857142857e-05,
      "loss": 0.002,
      "step": 14320
    },
    {
      "epoch": 0.4094285714285714,
      "grad_norm": 0.12389436364173889,
      "learning_rate": 3.9764285714285714e-05,
      "loss": 0.0022,
      "step": 14330
    },
    {
      "epoch": 0.4097142857142857,
      "grad_norm": 0.15619894862174988,
      "learning_rate": 3.975714285714286e-05,
      "loss": 0.002,
      "step": 14340
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.19627995789051056,
      "learning_rate": 3.9750000000000004e-05,
      "loss": 0.0022,
      "step": 14350
    },
    {
      "epoch": 0.4102857142857143,
      "grad_norm": 0.2311268299818039,
      "learning_rate": 3.9742857142857146e-05,
      "loss": 0.0017,
      "step": 14360
    },
    {
      "epoch": 0.4105714285714286,
      "grad_norm": 0.25900042057037354,
      "learning_rate": 3.973571428571429e-05,
      "loss": 0.0024,
      "step": 14370
    },
    {
      "epoch": 0.41085714285714287,
      "grad_norm": 0.07593303173780441,
      "learning_rate": 3.972857142857143e-05,
      "loss": 0.0024,
      "step": 14380
    },
    {
      "epoch": 0.41114285714285714,
      "grad_norm": 0.04387373849749565,
      "learning_rate": 3.972142857142858e-05,
      "loss": 0.0015,
      "step": 14390
    },
    {
      "epoch": 0.4114285714285714,
      "grad_norm": 0.14810502529144287,
      "learning_rate": 3.971428571428571e-05,
      "loss": 0.0021,
      "step": 14400
    },
    {
      "epoch": 0.4117142857142857,
      "grad_norm": 0.13851459324359894,
      "learning_rate": 3.970714285714286e-05,
      "loss": 0.0009,
      "step": 14410
    },
    {
      "epoch": 0.412,
      "grad_norm": 0.08621517568826675,
      "learning_rate": 3.97e-05,
      "loss": 0.0028,
      "step": 14420
    },
    {
      "epoch": 0.4122857142857143,
      "grad_norm": 0.07908838987350464,
      "learning_rate": 3.9692857142857144e-05,
      "loss": 0.0017,
      "step": 14430
    },
    {
      "epoch": 0.4125714285714286,
      "grad_norm": 0.03578153997659683,
      "learning_rate": 3.9685714285714286e-05,
      "loss": 0.0024,
      "step": 14440
    },
    {
      "epoch": 0.41285714285714287,
      "grad_norm": 0.0,
      "learning_rate": 3.9678571428571435e-05,
      "loss": 0.0022,
      "step": 14450
    },
    {
      "epoch": 0.41314285714285715,
      "grad_norm": 0.05380014702677727,
      "learning_rate": 3.9671428571428576e-05,
      "loss": 0.0016,
      "step": 14460
    },
    {
      "epoch": 0.4134285714285714,
      "grad_norm": 0.04999016970396042,
      "learning_rate": 3.966428571428572e-05,
      "loss": 0.0021,
      "step": 14470
    },
    {
      "epoch": 0.4137142857142857,
      "grad_norm": 0.043782979249954224,
      "learning_rate": 3.965714285714286e-05,
      "loss": 0.0009,
      "step": 14480
    },
    {
      "epoch": 0.414,
      "grad_norm": 0.2009168416261673,
      "learning_rate": 3.965e-05,
      "loss": 0.0028,
      "step": 14490
    },
    {
      "epoch": 0.4142857142857143,
      "grad_norm": 0.14482057094573975,
      "learning_rate": 3.964285714285714e-05,
      "loss": 0.0023,
      "step": 14500
    },
    {
      "epoch": 0.4145714285714286,
      "grad_norm": 0.0,
      "learning_rate": 3.9635714285714285e-05,
      "loss": 0.001,
      "step": 14510
    },
    {
      "epoch": 0.41485714285714287,
      "grad_norm": 0.0442691296339035,
      "learning_rate": 3.9628571428571433e-05,
      "loss": 0.0018,
      "step": 14520
    },
    {
      "epoch": 0.41514285714285715,
      "grad_norm": 0.3023360073566437,
      "learning_rate": 3.9621428571428575e-05,
      "loss": 0.0023,
      "step": 14530
    },
    {
      "epoch": 0.4154285714285714,
      "grad_norm": 0.04174022376537323,
      "learning_rate": 3.961428571428572e-05,
      "loss": 0.001,
      "step": 14540
    },
    {
      "epoch": 0.4157142857142857,
      "grad_norm": 0.2398994117975235,
      "learning_rate": 3.960714285714286e-05,
      "loss": 0.0019,
      "step": 14550
    },
    {
      "epoch": 0.416,
      "grad_norm": 0.07422123849391937,
      "learning_rate": 3.960000000000001e-05,
      "loss": 0.0022,
      "step": 14560
    },
    {
      "epoch": 0.41628571428571426,
      "grad_norm": 0.08961909264326096,
      "learning_rate": 3.959285714285714e-05,
      "loss": 0.0015,
      "step": 14570
    },
    {
      "epoch": 0.4165714285714286,
      "grad_norm": 0.20968516170978546,
      "learning_rate": 3.9585714285714284e-05,
      "loss": 0.0017,
      "step": 14580
    },
    {
      "epoch": 0.41685714285714287,
      "grad_norm": 0.03505602851510048,
      "learning_rate": 3.957857142857143e-05,
      "loss": 0.0022,
      "step": 14590
    },
    {
      "epoch": 0.41714285714285715,
      "grad_norm": 0.3487602174282074,
      "learning_rate": 3.9571428571428574e-05,
      "loss": 0.0015,
      "step": 14600
    },
    {
      "epoch": 0.4174285714285714,
      "grad_norm": 0.0,
      "learning_rate": 3.9564285714285716e-05,
      "loss": 0.001,
      "step": 14610
    },
    {
      "epoch": 0.4177142857142857,
      "grad_norm": 0.05321183055639267,
      "learning_rate": 3.955714285714286e-05,
      "loss": 0.0025,
      "step": 14620
    },
    {
      "epoch": 0.418,
      "grad_norm": 0.09395140409469604,
      "learning_rate": 3.9550000000000006e-05,
      "loss": 0.002,
      "step": 14630
    },
    {
      "epoch": 0.41828571428571426,
      "grad_norm": 0.07739361375570297,
      "learning_rate": 3.954285714285714e-05,
      "loss": 0.0021,
      "step": 14640
    },
    {
      "epoch": 0.4185714285714286,
      "grad_norm": 0.13635998964309692,
      "learning_rate": 3.953571428571429e-05,
      "loss": 0.0011,
      "step": 14650
    },
    {
      "epoch": 0.4188571428571429,
      "grad_norm": 0.04058358818292618,
      "learning_rate": 3.952857142857143e-05,
      "loss": 0.002,
      "step": 14660
    },
    {
      "epoch": 0.41914285714285715,
      "grad_norm": 0.23245671391487122,
      "learning_rate": 3.952142857142857e-05,
      "loss": 0.0018,
      "step": 14670
    },
    {
      "epoch": 0.41942857142857143,
      "grad_norm": 0.16158166527748108,
      "learning_rate": 3.9514285714285714e-05,
      "loss": 0.0022,
      "step": 14680
    },
    {
      "epoch": 0.4197142857142857,
      "grad_norm": 0.08515194803476334,
      "learning_rate": 3.9507142857142856e-05,
      "loss": 0.0013,
      "step": 14690
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.10534743964672089,
      "learning_rate": 3.9500000000000005e-05,
      "loss": 0.0021,
      "step": 14700
    },
    {
      "epoch": 0.42028571428571426,
      "grad_norm": 0.0448533371090889,
      "learning_rate": 3.949285714285714e-05,
      "loss": 0.0007,
      "step": 14710
    },
    {
      "epoch": 0.4205714285714286,
      "grad_norm": 0.049988288432359695,
      "learning_rate": 3.948571428571429e-05,
      "loss": 0.0012,
      "step": 14720
    },
    {
      "epoch": 0.4208571428571429,
      "grad_norm": 0.044830791652202606,
      "learning_rate": 3.947857142857143e-05,
      "loss": 0.0015,
      "step": 14730
    },
    {
      "epoch": 0.42114285714285715,
      "grad_norm": 0.14904002845287323,
      "learning_rate": 3.947142857142858e-05,
      "loss": 0.0023,
      "step": 14740
    },
    {
      "epoch": 0.42142857142857143,
      "grad_norm": 0.21391215920448303,
      "learning_rate": 3.946428571428571e-05,
      "loss": 0.0016,
      "step": 14750
    },
    {
      "epoch": 0.4217142857142857,
      "grad_norm": 0.21220093965530396,
      "learning_rate": 3.945714285714286e-05,
      "loss": 0.0021,
      "step": 14760
    },
    {
      "epoch": 0.422,
      "grad_norm": 0.19848710298538208,
      "learning_rate": 3.9450000000000003e-05,
      "loss": 0.0013,
      "step": 14770
    },
    {
      "epoch": 0.42228571428571426,
      "grad_norm": 0.0,
      "learning_rate": 3.9442857142857145e-05,
      "loss": 0.0012,
      "step": 14780
    },
    {
      "epoch": 0.4225714285714286,
      "grad_norm": 0.06848441064357758,
      "learning_rate": 3.943571428571429e-05,
      "loss": 0.0023,
      "step": 14790
    },
    {
      "epoch": 0.4228571428571429,
      "grad_norm": 0.18046002089977264,
      "learning_rate": 3.942857142857143e-05,
      "loss": 0.0018,
      "step": 14800
    },
    {
      "epoch": 0.42314285714285715,
      "grad_norm": 0.0,
      "learning_rate": 3.942142857142858e-05,
      "loss": 0.0013,
      "step": 14810
    },
    {
      "epoch": 0.42342857142857143,
      "grad_norm": 0.024689340963959694,
      "learning_rate": 3.941428571428571e-05,
      "loss": 0.0019,
      "step": 14820
    },
    {
      "epoch": 0.4237142857142857,
      "grad_norm": 0.06762257218360901,
      "learning_rate": 3.940714285714286e-05,
      "loss": 0.0021,
      "step": 14830
    },
    {
      "epoch": 0.424,
      "grad_norm": 0.032635223120450974,
      "learning_rate": 3.94e-05,
      "loss": 0.0019,
      "step": 14840
    },
    {
      "epoch": 0.42428571428571427,
      "grad_norm": 0.16595910489559174,
      "learning_rate": 3.9392857142857144e-05,
      "loss": 0.0016,
      "step": 14850
    },
    {
      "epoch": 0.42457142857142854,
      "grad_norm": 0.0,
      "learning_rate": 3.9385714285714286e-05,
      "loss": 0.0009,
      "step": 14860
    },
    {
      "epoch": 0.4248571428571429,
      "grad_norm": 0.05258282646536827,
      "learning_rate": 3.9378571428571434e-05,
      "loss": 0.0014,
      "step": 14870
    },
    {
      "epoch": 0.42514285714285716,
      "grad_norm": 0.3140513002872467,
      "learning_rate": 3.9371428571428576e-05,
      "loss": 0.0012,
      "step": 14880
    },
    {
      "epoch": 0.42542857142857143,
      "grad_norm": 0.04036526381969452,
      "learning_rate": 3.936428571428572e-05,
      "loss": 0.0019,
      "step": 14890
    },
    {
      "epoch": 0.4257142857142857,
      "grad_norm": 0.0,
      "learning_rate": 3.935714285714286e-05,
      "loss": 0.0014,
      "step": 14900
    },
    {
      "epoch": 0.426,
      "grad_norm": 0.031108921393752098,
      "learning_rate": 3.935e-05,
      "loss": 0.0013,
      "step": 14910
    },
    {
      "epoch": 0.42628571428571427,
      "grad_norm": 0.0,
      "learning_rate": 3.934285714285714e-05,
      "loss": 0.0016,
      "step": 14920
    },
    {
      "epoch": 0.42657142857142855,
      "grad_norm": 0.08958917111158371,
      "learning_rate": 3.9335714285714284e-05,
      "loss": 0.001,
      "step": 14930
    },
    {
      "epoch": 0.4268571428571429,
      "grad_norm": 0.12074902653694153,
      "learning_rate": 3.932857142857143e-05,
      "loss": 0.0004,
      "step": 14940
    },
    {
      "epoch": 0.42714285714285716,
      "grad_norm": 0.0,
      "learning_rate": 3.9321428571428575e-05,
      "loss": 0.002,
      "step": 14950
    },
    {
      "epoch": 0.42742857142857144,
      "grad_norm": 0.036501720547676086,
      "learning_rate": 3.9314285714285716e-05,
      "loss": 0.0011,
      "step": 14960
    },
    {
      "epoch": 0.4277142857142857,
      "grad_norm": 0.08018690347671509,
      "learning_rate": 3.930714285714286e-05,
      "loss": 0.0008,
      "step": 14970
    },
    {
      "epoch": 0.428,
      "grad_norm": 0.0571216456592083,
      "learning_rate": 3.9300000000000007e-05,
      "loss": 0.0015,
      "step": 14980
    },
    {
      "epoch": 0.42828571428571427,
      "grad_norm": 0.040261995047330856,
      "learning_rate": 3.929285714285714e-05,
      "loss": 0.0017,
      "step": 14990
    },
    {
      "epoch": 0.42857142857142855,
      "grad_norm": 0.11191567778587341,
      "learning_rate": 3.928571428571429e-05,
      "loss": 0.0026,
      "step": 15000
    },
    {
      "epoch": 0.4288571428571429,
      "grad_norm": 0.045003827661275864,
      "learning_rate": 3.927857142857143e-05,
      "loss": 0.0013,
      "step": 15010
    },
    {
      "epoch": 0.42914285714285716,
      "grad_norm": 0.09760001301765442,
      "learning_rate": 3.9271428571428573e-05,
      "loss": 0.0019,
      "step": 15020
    },
    {
      "epoch": 0.42942857142857144,
      "grad_norm": 0.14264625310897827,
      "learning_rate": 3.9264285714285715e-05,
      "loss": 0.0016,
      "step": 15030
    },
    {
      "epoch": 0.4297142857142857,
      "grad_norm": 0.16569116711616516,
      "learning_rate": 3.925714285714286e-05,
      "loss": 0.0013,
      "step": 15040
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.10164467245340347,
      "learning_rate": 3.9250000000000005e-05,
      "loss": 0.0011,
      "step": 15050
    },
    {
      "epoch": 0.43028571428571427,
      "grad_norm": 0.0,
      "learning_rate": 3.924285714285714e-05,
      "loss": 0.0014,
      "step": 15060
    },
    {
      "epoch": 0.43057142857142855,
      "grad_norm": 0.0,
      "learning_rate": 3.923571428571429e-05,
      "loss": 0.0018,
      "step": 15070
    },
    {
      "epoch": 0.4308571428571429,
      "grad_norm": 0.1693442165851593,
      "learning_rate": 3.922857142857143e-05,
      "loss": 0.0015,
      "step": 15080
    },
    {
      "epoch": 0.43114285714285716,
      "grad_norm": 0.08666034042835236,
      "learning_rate": 3.922142857142858e-05,
      "loss": 0.0013,
      "step": 15090
    },
    {
      "epoch": 0.43142857142857144,
      "grad_norm": 0.04808605834841728,
      "learning_rate": 3.9214285714285714e-05,
      "loss": 0.0019,
      "step": 15100
    },
    {
      "epoch": 0.4317142857142857,
      "grad_norm": 0.11147825419902802,
      "learning_rate": 3.9207142857142856e-05,
      "loss": 0.0015,
      "step": 15110
    },
    {
      "epoch": 0.432,
      "grad_norm": 0.27317172288894653,
      "learning_rate": 3.9200000000000004e-05,
      "loss": 0.0033,
      "step": 15120
    },
    {
      "epoch": 0.4322857142857143,
      "grad_norm": 0.1978200227022171,
      "learning_rate": 3.919285714285714e-05,
      "loss": 0.0017,
      "step": 15130
    },
    {
      "epoch": 0.43257142857142855,
      "grad_norm": 0.04134364426136017,
      "learning_rate": 3.918571428571429e-05,
      "loss": 0.0017,
      "step": 15140
    },
    {
      "epoch": 0.4328571428571429,
      "grad_norm": 0.33455121517181396,
      "learning_rate": 3.917857142857143e-05,
      "loss": 0.0024,
      "step": 15150
    },
    {
      "epoch": 0.43314285714285716,
      "grad_norm": 0.08186172693967819,
      "learning_rate": 3.917142857142858e-05,
      "loss": 0.0011,
      "step": 15160
    },
    {
      "epoch": 0.43342857142857144,
      "grad_norm": 0.06440276652574539,
      "learning_rate": 3.916428571428571e-05,
      "loss": 0.002,
      "step": 15170
    },
    {
      "epoch": 0.4337142857142857,
      "grad_norm": 0.28828978538513184,
      "learning_rate": 3.915714285714286e-05,
      "loss": 0.0024,
      "step": 15180
    },
    {
      "epoch": 0.434,
      "grad_norm": 0.12316986173391342,
      "learning_rate": 3.915e-05,
      "loss": 0.0013,
      "step": 15190
    },
    {
      "epoch": 0.4342857142857143,
      "grad_norm": 0.017474962398409843,
      "learning_rate": 3.9142857142857145e-05,
      "loss": 0.0018,
      "step": 15200
    },
    {
      "epoch": 0.43457142857142855,
      "grad_norm": 0.08339686691761017,
      "learning_rate": 3.9135714285714286e-05,
      "loss": 0.0014,
      "step": 15210
    },
    {
      "epoch": 0.43485714285714283,
      "grad_norm": 0.07917896658182144,
      "learning_rate": 3.912857142857143e-05,
      "loss": 0.0016,
      "step": 15220
    },
    {
      "epoch": 0.43514285714285716,
      "grad_norm": 0.15087105333805084,
      "learning_rate": 3.9121428571428577e-05,
      "loss": 0.0015,
      "step": 15230
    },
    {
      "epoch": 0.43542857142857144,
      "grad_norm": 0.14096365869045258,
      "learning_rate": 3.911428571428571e-05,
      "loss": 0.0021,
      "step": 15240
    },
    {
      "epoch": 0.4357142857142857,
      "grad_norm": 0.14684784412384033,
      "learning_rate": 3.910714285714286e-05,
      "loss": 0.0029,
      "step": 15250
    },
    {
      "epoch": 0.436,
      "grad_norm": 0.0,
      "learning_rate": 3.91e-05,
      "loss": 0.0015,
      "step": 15260
    },
    {
      "epoch": 0.4362857142857143,
      "grad_norm": 0.04107635095715523,
      "learning_rate": 3.9092857142857143e-05,
      "loss": 0.0022,
      "step": 15270
    },
    {
      "epoch": 0.43657142857142855,
      "grad_norm": 0.0,
      "learning_rate": 3.9085714285714285e-05,
      "loss": 0.0014,
      "step": 15280
    },
    {
      "epoch": 0.43685714285714283,
      "grad_norm": 0.15811912715435028,
      "learning_rate": 3.9078571428571434e-05,
      "loss": 0.0015,
      "step": 15290
    },
    {
      "epoch": 0.43714285714285717,
      "grad_norm": 0.048959288746118546,
      "learning_rate": 3.9071428571428575e-05,
      "loss": 0.0013,
      "step": 15300
    },
    {
      "epoch": 0.43742857142857144,
      "grad_norm": 0.052020903676748276,
      "learning_rate": 3.906428571428572e-05,
      "loss": 0.0017,
      "step": 15310
    },
    {
      "epoch": 0.4377142857142857,
      "grad_norm": 0.12606778740882874,
      "learning_rate": 3.905714285714286e-05,
      "loss": 0.0028,
      "step": 15320
    },
    {
      "epoch": 0.438,
      "grad_norm": 0.2824013829231262,
      "learning_rate": 3.905e-05,
      "loss": 0.0014,
      "step": 15330
    },
    {
      "epoch": 0.4382857142857143,
      "grad_norm": 0.061329472810029984,
      "learning_rate": 3.904285714285714e-05,
      "loss": 0.0021,
      "step": 15340
    },
    {
      "epoch": 0.43857142857142856,
      "grad_norm": 0.08054187148809433,
      "learning_rate": 3.9035714285714284e-05,
      "loss": 0.0011,
      "step": 15350
    },
    {
      "epoch": 0.43885714285714283,
      "grad_norm": 0.04402533546090126,
      "learning_rate": 3.902857142857143e-05,
      "loss": 0.0023,
      "step": 15360
    },
    {
      "epoch": 0.43914285714285717,
      "grad_norm": 0.0451241172850132,
      "learning_rate": 3.9021428571428574e-05,
      "loss": 0.0008,
      "step": 15370
    },
    {
      "epoch": 0.43942857142857145,
      "grad_norm": 0.0,
      "learning_rate": 3.9014285714285716e-05,
      "loss": 0.0018,
      "step": 15380
    },
    {
      "epoch": 0.4397142857142857,
      "grad_norm": 0.0855337530374527,
      "learning_rate": 3.900714285714286e-05,
      "loss": 0.0024,
      "step": 15390
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.05321116000413895,
      "learning_rate": 3.9000000000000006e-05,
      "loss": 0.0024,
      "step": 15400
    },
    {
      "epoch": 0.4402857142857143,
      "grad_norm": 0.040563568472862244,
      "learning_rate": 3.899285714285714e-05,
      "loss": 0.0008,
      "step": 15410
    },
    {
      "epoch": 0.44057142857142856,
      "grad_norm": 0.08470151573419571,
      "learning_rate": 3.898571428571429e-05,
      "loss": 0.0017,
      "step": 15420
    },
    {
      "epoch": 0.44085714285714284,
      "grad_norm": 0.07322560250759125,
      "learning_rate": 3.897857142857143e-05,
      "loss": 0.0022,
      "step": 15430
    },
    {
      "epoch": 0.44114285714285717,
      "grad_norm": 0.2706758975982666,
      "learning_rate": 3.897142857142857e-05,
      "loss": 0.0016,
      "step": 15440
    },
    {
      "epoch": 0.44142857142857145,
      "grad_norm": 0.2606445252895355,
      "learning_rate": 3.8964285714285715e-05,
      "loss": 0.0013,
      "step": 15450
    },
    {
      "epoch": 0.4417142857142857,
      "grad_norm": 0.0689244270324707,
      "learning_rate": 3.8957142857142856e-05,
      "loss": 0.001,
      "step": 15460
    },
    {
      "epoch": 0.442,
      "grad_norm": 0.0,
      "learning_rate": 3.8950000000000005e-05,
      "loss": 0.0011,
      "step": 15470
    },
    {
      "epoch": 0.4422857142857143,
      "grad_norm": 0.0456186905503273,
      "learning_rate": 3.894285714285714e-05,
      "loss": 0.0014,
      "step": 15480
    },
    {
      "epoch": 0.44257142857142856,
      "grad_norm": 0.0,
      "learning_rate": 3.893571428571429e-05,
      "loss": 0.0014,
      "step": 15490
    },
    {
      "epoch": 0.44285714285714284,
      "grad_norm": 0.2619617283344269,
      "learning_rate": 3.892857142857143e-05,
      "loss": 0.0022,
      "step": 15500
    },
    {
      "epoch": 0.4431428571428571,
      "grad_norm": 0.25486427545547485,
      "learning_rate": 3.892142857142858e-05,
      "loss": 0.0024,
      "step": 15510
    },
    {
      "epoch": 0.44342857142857145,
      "grad_norm": 0.04123083874583244,
      "learning_rate": 3.8914285714285713e-05,
      "loss": 0.0022,
      "step": 15520
    },
    {
      "epoch": 0.4437142857142857,
      "grad_norm": 0.04950936883687973,
      "learning_rate": 3.890714285714286e-05,
      "loss": 0.0023,
      "step": 15530
    },
    {
      "epoch": 0.444,
      "grad_norm": 0.0436430349946022,
      "learning_rate": 3.8900000000000004e-05,
      "loss": 0.0018,
      "step": 15540
    },
    {
      "epoch": 0.4442857142857143,
      "grad_norm": 0.08703029900789261,
      "learning_rate": 3.8892857142857145e-05,
      "loss": 0.0011,
      "step": 15550
    },
    {
      "epoch": 0.44457142857142856,
      "grad_norm": 0.08251812309026718,
      "learning_rate": 3.888571428571429e-05,
      "loss": 0.002,
      "step": 15560
    },
    {
      "epoch": 0.44485714285714284,
      "grad_norm": 0.025003701448440552,
      "learning_rate": 3.887857142857143e-05,
      "loss": 0.0024,
      "step": 15570
    },
    {
      "epoch": 0.4451428571428571,
      "grad_norm": 0.04410839080810547,
      "learning_rate": 3.887142857142858e-05,
      "loss": 0.0013,
      "step": 15580
    },
    {
      "epoch": 0.44542857142857145,
      "grad_norm": 0.0471152700483799,
      "learning_rate": 3.886428571428571e-05,
      "loss": 0.0016,
      "step": 15590
    },
    {
      "epoch": 0.44571428571428573,
      "grad_norm": 0.0,
      "learning_rate": 3.885714285714286e-05,
      "loss": 0.0021,
      "step": 15600
    },
    {
      "epoch": 0.446,
      "grad_norm": 0.04676658660173416,
      "learning_rate": 3.885e-05,
      "loss": 0.0022,
      "step": 15610
    },
    {
      "epoch": 0.4462857142857143,
      "grad_norm": 0.12272939831018448,
      "learning_rate": 3.8842857142857144e-05,
      "loss": 0.0028,
      "step": 15620
    },
    {
      "epoch": 0.44657142857142856,
      "grad_norm": 0.06013880670070648,
      "learning_rate": 3.8835714285714286e-05,
      "loss": 0.0012,
      "step": 15630
    },
    {
      "epoch": 0.44685714285714284,
      "grad_norm": 0.04439177364110947,
      "learning_rate": 3.882857142857143e-05,
      "loss": 0.0012,
      "step": 15640
    },
    {
      "epoch": 0.4471428571428571,
      "grad_norm": 0.042274173349142075,
      "learning_rate": 3.8821428571428576e-05,
      "loss": 0.0016,
      "step": 15650
    },
    {
      "epoch": 0.44742857142857145,
      "grad_norm": 0.0917007327079773,
      "learning_rate": 3.881428571428571e-05,
      "loss": 0.0022,
      "step": 15660
    },
    {
      "epoch": 0.44771428571428573,
      "grad_norm": 0.03217625617980957,
      "learning_rate": 3.880714285714286e-05,
      "loss": 0.0022,
      "step": 15670
    },
    {
      "epoch": 0.448,
      "grad_norm": 0.0,
      "learning_rate": 3.88e-05,
      "loss": 0.0007,
      "step": 15680
    },
    {
      "epoch": 0.4482857142857143,
      "grad_norm": 0.12071818858385086,
      "learning_rate": 3.879285714285715e-05,
      "loss": 0.0018,
      "step": 15690
    },
    {
      "epoch": 0.44857142857142857,
      "grad_norm": 0.16941285133361816,
      "learning_rate": 3.8785714285714285e-05,
      "loss": 0.0014,
      "step": 15700
    },
    {
      "epoch": 0.44885714285714284,
      "grad_norm": 0.04923807084560394,
      "learning_rate": 3.877857142857143e-05,
      "loss": 0.0006,
      "step": 15710
    },
    {
      "epoch": 0.4491428571428571,
      "grad_norm": 0.0,
      "learning_rate": 3.8771428571428575e-05,
      "loss": 0.0013,
      "step": 15720
    },
    {
      "epoch": 0.44942857142857146,
      "grad_norm": 0.3857468068599701,
      "learning_rate": 3.8764285714285717e-05,
      "loss": 0.0019,
      "step": 15730
    },
    {
      "epoch": 0.44971428571428573,
      "grad_norm": 0.21946965157985687,
      "learning_rate": 3.875714285714286e-05,
      "loss": 0.0022,
      "step": 15740
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.043494708836078644,
      "learning_rate": 3.875e-05,
      "loss": 0.0011,
      "step": 15750
    },
    {
      "epoch": 0.4502857142857143,
      "grad_norm": 0.0,
      "learning_rate": 3.874285714285715e-05,
      "loss": 0.0012,
      "step": 15760
    },
    {
      "epoch": 0.45057142857142857,
      "grad_norm": 0.09706925600767136,
      "learning_rate": 3.8735714285714283e-05,
      "loss": 0.002,
      "step": 15770
    },
    {
      "epoch": 0.45085714285714285,
      "grad_norm": 0.07311509549617767,
      "learning_rate": 3.872857142857143e-05,
      "loss": 0.0021,
      "step": 15780
    },
    {
      "epoch": 0.4511428571428571,
      "grad_norm": 0.04329558089375496,
      "learning_rate": 3.8721428571428574e-05,
      "loss": 0.002,
      "step": 15790
    },
    {
      "epoch": 0.4514285714285714,
      "grad_norm": 0.05695183947682381,
      "learning_rate": 3.8714285714285715e-05,
      "loss": 0.0018,
      "step": 15800
    },
    {
      "epoch": 0.45171428571428573,
      "grad_norm": 0.04907510429620743,
      "learning_rate": 3.870714285714286e-05,
      "loss": 0.0019,
      "step": 15810
    },
    {
      "epoch": 0.452,
      "grad_norm": 0.04945497214794159,
      "learning_rate": 3.8700000000000006e-05,
      "loss": 0.0016,
      "step": 15820
    },
    {
      "epoch": 0.4522857142857143,
      "grad_norm": 0.04168408364057541,
      "learning_rate": 3.869285714285715e-05,
      "loss": 0.0014,
      "step": 15830
    },
    {
      "epoch": 0.45257142857142857,
      "grad_norm": 0.041319623589515686,
      "learning_rate": 3.868571428571429e-05,
      "loss": 0.0019,
      "step": 15840
    },
    {
      "epoch": 0.45285714285714285,
      "grad_norm": 0.23358626663684845,
      "learning_rate": 3.867857142857143e-05,
      "loss": 0.0013,
      "step": 15850
    },
    {
      "epoch": 0.4531428571428571,
      "grad_norm": 0.17384351789951324,
      "learning_rate": 3.867142857142857e-05,
      "loss": 0.0018,
      "step": 15860
    },
    {
      "epoch": 0.4534285714285714,
      "grad_norm": 0.0546581968665123,
      "learning_rate": 3.8664285714285714e-05,
      "loss": 0.001,
      "step": 15870
    },
    {
      "epoch": 0.45371428571428574,
      "grad_norm": 0.045968376100063324,
      "learning_rate": 3.8657142857142856e-05,
      "loss": 0.0012,
      "step": 15880
    },
    {
      "epoch": 0.454,
      "grad_norm": 0.0,
      "learning_rate": 3.8650000000000004e-05,
      "loss": 0.0013,
      "step": 15890
    },
    {
      "epoch": 0.4542857142857143,
      "grad_norm": 0.07640159130096436,
      "learning_rate": 3.8642857142857146e-05,
      "loss": 0.0014,
      "step": 15900
    },
    {
      "epoch": 0.45457142857142857,
      "grad_norm": 0.05060487985610962,
      "learning_rate": 3.863571428571429e-05,
      "loss": 0.0012,
      "step": 15910
    },
    {
      "epoch": 0.45485714285714285,
      "grad_norm": 0.04282394051551819,
      "learning_rate": 3.862857142857143e-05,
      "loss": 0.0008,
      "step": 15920
    },
    {
      "epoch": 0.4551428571428571,
      "grad_norm": 0.044823259115219116,
      "learning_rate": 3.862142857142858e-05,
      "loss": 0.0019,
      "step": 15930
    },
    {
      "epoch": 0.4554285714285714,
      "grad_norm": 0.0,
      "learning_rate": 3.861428571428571e-05,
      "loss": 0.0024,
      "step": 15940
    },
    {
      "epoch": 0.45571428571428574,
      "grad_norm": 0.06036856770515442,
      "learning_rate": 3.860714285714286e-05,
      "loss": 0.0024,
      "step": 15950
    },
    {
      "epoch": 0.456,
      "grad_norm": 0.03829775005578995,
      "learning_rate": 3.86e-05,
      "loss": 0.0009,
      "step": 15960
    },
    {
      "epoch": 0.4562857142857143,
      "grad_norm": 0.0,
      "learning_rate": 3.8592857142857145e-05,
      "loss": 0.0023,
      "step": 15970
    },
    {
      "epoch": 0.4565714285714286,
      "grad_norm": 0.05039674788713455,
      "learning_rate": 3.8585714285714287e-05,
      "loss": 0.0035,
      "step": 15980
    },
    {
      "epoch": 0.45685714285714285,
      "grad_norm": 0.13249701261520386,
      "learning_rate": 3.857857142857143e-05,
      "loss": 0.0017,
      "step": 15990
    },
    {
      "epoch": 0.45714285714285713,
      "grad_norm": 0.21446870267391205,
      "learning_rate": 3.857142857142858e-05,
      "loss": 0.0014,
      "step": 16000
    },
    {
      "epoch": 0.4574285714285714,
      "grad_norm": 0.07277590781450272,
      "learning_rate": 3.856428571428571e-05,
      "loss": 0.0024,
      "step": 16010
    },
    {
      "epoch": 0.45771428571428574,
      "grad_norm": 0.170943945646286,
      "learning_rate": 3.855714285714286e-05,
      "loss": 0.0012,
      "step": 16020
    },
    {
      "epoch": 0.458,
      "grad_norm": 0.043394580483436584,
      "learning_rate": 3.855e-05,
      "loss": 0.0018,
      "step": 16030
    },
    {
      "epoch": 0.4582857142857143,
      "grad_norm": 0.08273543417453766,
      "learning_rate": 3.854285714285715e-05,
      "loss": 0.0021,
      "step": 16040
    },
    {
      "epoch": 0.4585714285714286,
      "grad_norm": 0.20256222784519196,
      "learning_rate": 3.8535714285714285e-05,
      "loss": 0.0028,
      "step": 16050
    },
    {
      "epoch": 0.45885714285714285,
      "grad_norm": 0.020090414211153984,
      "learning_rate": 3.8528571428571434e-05,
      "loss": 0.0023,
      "step": 16060
    },
    {
      "epoch": 0.45914285714285713,
      "grad_norm": 0.038959890604019165,
      "learning_rate": 3.8521428571428576e-05,
      "loss": 0.0019,
      "step": 16070
    },
    {
      "epoch": 0.4594285714285714,
      "grad_norm": 0.26449382305145264,
      "learning_rate": 3.851428571428571e-05,
      "loss": 0.0031,
      "step": 16080
    },
    {
      "epoch": 0.45971428571428574,
      "grad_norm": 0.21593450009822845,
      "learning_rate": 3.850714285714286e-05,
      "loss": 0.001,
      "step": 16090
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.11525271087884903,
      "learning_rate": 3.85e-05,
      "loss": 0.0017,
      "step": 16100
    },
    {
      "epoch": 0.4602857142857143,
      "grad_norm": 0.10191038250923157,
      "learning_rate": 3.849285714285715e-05,
      "loss": 0.0028,
      "step": 16110
    },
    {
      "epoch": 0.4605714285714286,
      "grad_norm": 0.052509937435388565,
      "learning_rate": 3.8485714285714284e-05,
      "loss": 0.0009,
      "step": 16120
    },
    {
      "epoch": 0.46085714285714285,
      "grad_norm": 0.16532127559185028,
      "learning_rate": 3.847857142857143e-05,
      "loss": 0.0016,
      "step": 16130
    },
    {
      "epoch": 0.46114285714285713,
      "grad_norm": 0.06248109042644501,
      "learning_rate": 3.8471428571428574e-05,
      "loss": 0.0014,
      "step": 16140
    },
    {
      "epoch": 0.4614285714285714,
      "grad_norm": 0.13245199620723724,
      "learning_rate": 3.8464285714285716e-05,
      "loss": 0.0017,
      "step": 16150
    },
    {
      "epoch": 0.4617142857142857,
      "grad_norm": 0.0,
      "learning_rate": 3.845714285714286e-05,
      "loss": 0.0014,
      "step": 16160
    },
    {
      "epoch": 0.462,
      "grad_norm": 0.043607376515865326,
      "learning_rate": 3.845e-05,
      "loss": 0.0019,
      "step": 16170
    },
    {
      "epoch": 0.4622857142857143,
      "grad_norm": 0.04712555557489395,
      "learning_rate": 3.844285714285715e-05,
      "loss": 0.0008,
      "step": 16180
    },
    {
      "epoch": 0.4625714285714286,
      "grad_norm": 0.06972309947013855,
      "learning_rate": 3.843571428571428e-05,
      "loss": 0.0018,
      "step": 16190
    },
    {
      "epoch": 0.46285714285714286,
      "grad_norm": 0.23936164379119873,
      "learning_rate": 3.842857142857143e-05,
      "loss": 0.0022,
      "step": 16200
    },
    {
      "epoch": 0.46314285714285713,
      "grad_norm": 0.05893896892666817,
      "learning_rate": 3.842142857142857e-05,
      "loss": 0.002,
      "step": 16210
    },
    {
      "epoch": 0.4634285714285714,
      "grad_norm": 0.087467260658741,
      "learning_rate": 3.8414285714285715e-05,
      "loss": 0.0009,
      "step": 16220
    },
    {
      "epoch": 0.4637142857142857,
      "grad_norm": 0.04423520341515541,
      "learning_rate": 3.8407142857142857e-05,
      "loss": 0.0007,
      "step": 16230
    },
    {
      "epoch": 0.464,
      "grad_norm": 0.044553108513355255,
      "learning_rate": 3.8400000000000005e-05,
      "loss": 0.0011,
      "step": 16240
    },
    {
      "epoch": 0.4642857142857143,
      "grad_norm": 0.15671053528785706,
      "learning_rate": 3.839285714285715e-05,
      "loss": 0.0028,
      "step": 16250
    },
    {
      "epoch": 0.4645714285714286,
      "grad_norm": 0.14385539293289185,
      "learning_rate": 3.838571428571429e-05,
      "loss": 0.0008,
      "step": 16260
    },
    {
      "epoch": 0.46485714285714286,
      "grad_norm": 0.09257788211107254,
      "learning_rate": 3.837857142857143e-05,
      "loss": 0.0019,
      "step": 16270
    },
    {
      "epoch": 0.46514285714285714,
      "grad_norm": 0.06839001178741455,
      "learning_rate": 3.837142857142857e-05,
      "loss": 0.0029,
      "step": 16280
    },
    {
      "epoch": 0.4654285714285714,
      "grad_norm": 0.0,
      "learning_rate": 3.8364285714285714e-05,
      "loss": 0.0011,
      "step": 16290
    },
    {
      "epoch": 0.4657142857142857,
      "grad_norm": 0.3475343585014343,
      "learning_rate": 3.8357142857142855e-05,
      "loss": 0.0012,
      "step": 16300
    },
    {
      "epoch": 0.466,
      "grad_norm": 0.04598472639918327,
      "learning_rate": 3.8350000000000004e-05,
      "loss": 0.0009,
      "step": 16310
    },
    {
      "epoch": 0.4662857142857143,
      "grad_norm": 0.2932273745536804,
      "learning_rate": 3.8342857142857146e-05,
      "loss": 0.0015,
      "step": 16320
    },
    {
      "epoch": 0.4665714285714286,
      "grad_norm": 0.0,
      "learning_rate": 3.833571428571429e-05,
      "loss": 0.0012,
      "step": 16330
    },
    {
      "epoch": 0.46685714285714286,
      "grad_norm": 0.17716430127620697,
      "learning_rate": 3.832857142857143e-05,
      "loss": 0.0014,
      "step": 16340
    },
    {
      "epoch": 0.46714285714285714,
      "grad_norm": 0.0,
      "learning_rate": 3.832142857142858e-05,
      "loss": 0.0016,
      "step": 16350
    },
    {
      "epoch": 0.4674285714285714,
      "grad_norm": 0.04922272637486458,
      "learning_rate": 3.831428571428571e-05,
      "loss": 0.0009,
      "step": 16360
    },
    {
      "epoch": 0.4677142857142857,
      "grad_norm": 0.08574289083480835,
      "learning_rate": 3.830714285714286e-05,
      "loss": 0.0012,
      "step": 16370
    },
    {
      "epoch": 0.468,
      "grad_norm": 0.050751324743032455,
      "learning_rate": 3.83e-05,
      "loss": 0.0012,
      "step": 16380
    },
    {
      "epoch": 0.4682857142857143,
      "grad_norm": 0.0,
      "learning_rate": 3.8292857142857144e-05,
      "loss": 0.0014,
      "step": 16390
    },
    {
      "epoch": 0.4685714285714286,
      "grad_norm": 0.08809154480695724,
      "learning_rate": 3.8285714285714286e-05,
      "loss": 0.0012,
      "step": 16400
    },
    {
      "epoch": 0.46885714285714286,
      "grad_norm": 0.045933328568935394,
      "learning_rate": 3.827857142857143e-05,
      "loss": 0.0007,
      "step": 16410
    },
    {
      "epoch": 0.46914285714285714,
      "grad_norm": 0.0,
      "learning_rate": 3.8271428571428576e-05,
      "loss": 0.0012,
      "step": 16420
    },
    {
      "epoch": 0.4694285714285714,
      "grad_norm": 0.15950997173786163,
      "learning_rate": 3.826428571428571e-05,
      "loss": 0.0015,
      "step": 16430
    },
    {
      "epoch": 0.4697142857142857,
      "grad_norm": 0.07868938148021698,
      "learning_rate": 3.825714285714286e-05,
      "loss": 0.0017,
      "step": 16440
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.08094430714845657,
      "learning_rate": 3.825e-05,
      "loss": 0.0013,
      "step": 16450
    },
    {
      "epoch": 0.4702857142857143,
      "grad_norm": 0.08189929276704788,
      "learning_rate": 3.824285714285715e-05,
      "loss": 0.002,
      "step": 16460
    },
    {
      "epoch": 0.4705714285714286,
      "grad_norm": 0.22878599166870117,
      "learning_rate": 3.8235714285714285e-05,
      "loss": 0.0008,
      "step": 16470
    },
    {
      "epoch": 0.47085714285714286,
      "grad_norm": 0.2077457308769226,
      "learning_rate": 3.822857142857143e-05,
      "loss": 0.0013,
      "step": 16480
    },
    {
      "epoch": 0.47114285714285714,
      "grad_norm": 0.0,
      "learning_rate": 3.8221428571428575e-05,
      "loss": 0.0012,
      "step": 16490
    },
    {
      "epoch": 0.4714285714285714,
      "grad_norm": 0.04525987058877945,
      "learning_rate": 3.821428571428572e-05,
      "loss": 0.0021,
      "step": 16500
    },
    {
      "epoch": 0.4717142857142857,
      "grad_norm": 0.16536539793014526,
      "learning_rate": 3.820714285714286e-05,
      "loss": 0.0029,
      "step": 16510
    },
    {
      "epoch": 0.472,
      "grad_norm": 0.2875537574291229,
      "learning_rate": 3.82e-05,
      "loss": 0.0025,
      "step": 16520
    },
    {
      "epoch": 0.4722857142857143,
      "grad_norm": 0.0,
      "learning_rate": 3.819285714285715e-05,
      "loss": 0.0012,
      "step": 16530
    },
    {
      "epoch": 0.4725714285714286,
      "grad_norm": 0.1802654266357422,
      "learning_rate": 3.8185714285714284e-05,
      "loss": 0.0023,
      "step": 16540
    },
    {
      "epoch": 0.47285714285714286,
      "grad_norm": 0.04023582488298416,
      "learning_rate": 3.817857142857143e-05,
      "loss": 0.001,
      "step": 16550
    },
    {
      "epoch": 0.47314285714285714,
      "grad_norm": 0.04843640699982643,
      "learning_rate": 3.8171428571428574e-05,
      "loss": 0.0021,
      "step": 16560
    },
    {
      "epoch": 0.4734285714285714,
      "grad_norm": 0.05068136379122734,
      "learning_rate": 3.8164285714285716e-05,
      "loss": 0.0009,
      "step": 16570
    },
    {
      "epoch": 0.4737142857142857,
      "grad_norm": 0.04281895235180855,
      "learning_rate": 3.815714285714286e-05,
      "loss": 0.0018,
      "step": 16580
    },
    {
      "epoch": 0.474,
      "grad_norm": 0.07363622635602951,
      "learning_rate": 3.8150000000000006e-05,
      "loss": 0.0017,
      "step": 16590
    },
    {
      "epoch": 0.4742857142857143,
      "grad_norm": 0.0,
      "learning_rate": 3.814285714285715e-05,
      "loss": 0.0013,
      "step": 16600
    },
    {
      "epoch": 0.4745714285714286,
      "grad_norm": 0.0,
      "learning_rate": 3.813571428571428e-05,
      "loss": 0.0013,
      "step": 16610
    },
    {
      "epoch": 0.47485714285714287,
      "grad_norm": 0.24544695019721985,
      "learning_rate": 3.812857142857143e-05,
      "loss": 0.0019,
      "step": 16620
    },
    {
      "epoch": 0.47514285714285714,
      "grad_norm": 0.05125861242413521,
      "learning_rate": 3.812142857142857e-05,
      "loss": 0.0023,
      "step": 16630
    },
    {
      "epoch": 0.4754285714285714,
      "grad_norm": 0.0,
      "learning_rate": 3.8114285714285714e-05,
      "loss": 0.0012,
      "step": 16640
    },
    {
      "epoch": 0.4757142857142857,
      "grad_norm": 0.2582377791404724,
      "learning_rate": 3.8107142857142856e-05,
      "loss": 0.0016,
      "step": 16650
    },
    {
      "epoch": 0.476,
      "grad_norm": 0.1071237251162529,
      "learning_rate": 3.8100000000000005e-05,
      "loss": 0.0021,
      "step": 16660
    },
    {
      "epoch": 0.4762857142857143,
      "grad_norm": 0.2572179138660431,
      "learning_rate": 3.8092857142857146e-05,
      "loss": 0.002,
      "step": 16670
    },
    {
      "epoch": 0.4765714285714286,
      "grad_norm": 0.058900680392980576,
      "learning_rate": 3.808571428571429e-05,
      "loss": 0.0019,
      "step": 16680
    },
    {
      "epoch": 0.47685714285714287,
      "grad_norm": 0.08157283812761307,
      "learning_rate": 3.807857142857143e-05,
      "loss": 0.0015,
      "step": 16690
    },
    {
      "epoch": 0.47714285714285715,
      "grad_norm": 0.0,
      "learning_rate": 3.807142857142857e-05,
      "loss": 0.0014,
      "step": 16700
    },
    {
      "epoch": 0.4774285714285714,
      "grad_norm": 0.2312302142381668,
      "learning_rate": 3.806428571428571e-05,
      "loss": 0.001,
      "step": 16710
    },
    {
      "epoch": 0.4777142857142857,
      "grad_norm": 0.06558153033256531,
      "learning_rate": 3.8057142857142855e-05,
      "loss": 0.0017,
      "step": 16720
    },
    {
      "epoch": 0.478,
      "grad_norm": 0.05725283548235893,
      "learning_rate": 3.805e-05,
      "loss": 0.0016,
      "step": 16730
    },
    {
      "epoch": 0.47828571428571426,
      "grad_norm": 0.13547049462795258,
      "learning_rate": 3.8042857142857145e-05,
      "loss": 0.0014,
      "step": 16740
    },
    {
      "epoch": 0.4785714285714286,
      "grad_norm": 0.10928434878587723,
      "learning_rate": 3.803571428571429e-05,
      "loss": 0.0013,
      "step": 16750
    },
    {
      "epoch": 0.47885714285714287,
      "grad_norm": 0.041817523539066315,
      "learning_rate": 3.802857142857143e-05,
      "loss": 0.0027,
      "step": 16760
    },
    {
      "epoch": 0.47914285714285715,
      "grad_norm": 0.038404714316129684,
      "learning_rate": 3.802142857142858e-05,
      "loss": 0.0025,
      "step": 16770
    },
    {
      "epoch": 0.4794285714285714,
      "grad_norm": 0.0,
      "learning_rate": 3.801428571428571e-05,
      "loss": 0.0023,
      "step": 16780
    },
    {
      "epoch": 0.4797142857142857,
      "grad_norm": 0.16826801002025604,
      "learning_rate": 3.800714285714286e-05,
      "loss": 0.001,
      "step": 16790
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.16106724739074707,
      "learning_rate": 3.8e-05,
      "loss": 0.001,
      "step": 16800
    },
    {
      "epoch": 0.48028571428571426,
      "grad_norm": 0.13976770639419556,
      "learning_rate": 3.7992857142857144e-05,
      "loss": 0.0006,
      "step": 16810
    },
    {
      "epoch": 0.4805714285714286,
      "grad_norm": 0.060523003339767456,
      "learning_rate": 3.7985714285714286e-05,
      "loss": 0.0008,
      "step": 16820
    },
    {
      "epoch": 0.48085714285714287,
      "grad_norm": 0.13680939376354218,
      "learning_rate": 3.797857142857143e-05,
      "loss": 0.0013,
      "step": 16830
    },
    {
      "epoch": 0.48114285714285715,
      "grad_norm": 0.04509468749165535,
      "learning_rate": 3.7971428571428576e-05,
      "loss": 0.0011,
      "step": 16840
    },
    {
      "epoch": 0.48142857142857143,
      "grad_norm": 0.23181693255901337,
      "learning_rate": 3.796428571428571e-05,
      "loss": 0.0019,
      "step": 16850
    },
    {
      "epoch": 0.4817142857142857,
      "grad_norm": 0.34104692935943604,
      "learning_rate": 3.795714285714286e-05,
      "loss": 0.0014,
      "step": 16860
    },
    {
      "epoch": 0.482,
      "grad_norm": 0.08427111804485321,
      "learning_rate": 3.795e-05,
      "loss": 0.0024,
      "step": 16870
    },
    {
      "epoch": 0.48228571428571426,
      "grad_norm": 0.04757310822606087,
      "learning_rate": 3.794285714285715e-05,
      "loss": 0.0016,
      "step": 16880
    },
    {
      "epoch": 0.4825714285714286,
      "grad_norm": 0.07204118371009827,
      "learning_rate": 3.7935714285714284e-05,
      "loss": 0.0011,
      "step": 16890
    },
    {
      "epoch": 0.4828571428571429,
      "grad_norm": 0.04468357563018799,
      "learning_rate": 3.792857142857143e-05,
      "loss": 0.0021,
      "step": 16900
    },
    {
      "epoch": 0.48314285714285715,
      "grad_norm": 0.04886181280016899,
      "learning_rate": 3.7921428571428575e-05,
      "loss": 0.0022,
      "step": 16910
    },
    {
      "epoch": 0.48342857142857143,
      "grad_norm": 0.16377651691436768,
      "learning_rate": 3.7914285714285716e-05,
      "loss": 0.0022,
      "step": 16920
    },
    {
      "epoch": 0.4837142857142857,
      "grad_norm": 0.3520636558532715,
      "learning_rate": 3.790714285714286e-05,
      "loss": 0.0023,
      "step": 16930
    },
    {
      "epoch": 0.484,
      "grad_norm": 0.0,
      "learning_rate": 3.79e-05,
      "loss": 0.0019,
      "step": 16940
    },
    {
      "epoch": 0.48428571428571426,
      "grad_norm": 0.0,
      "learning_rate": 3.789285714285715e-05,
      "loss": 0.0018,
      "step": 16950
    },
    {
      "epoch": 0.4845714285714286,
      "grad_norm": 0.04557941108942032,
      "learning_rate": 3.788571428571428e-05,
      "loss": 0.0012,
      "step": 16960
    },
    {
      "epoch": 0.4848571428571429,
      "grad_norm": 0.08144663274288177,
      "learning_rate": 3.787857142857143e-05,
      "loss": 0.0009,
      "step": 16970
    },
    {
      "epoch": 0.48514285714285715,
      "grad_norm": 0.0406234934926033,
      "learning_rate": 3.787142857142857e-05,
      "loss": 0.0016,
      "step": 16980
    },
    {
      "epoch": 0.48542857142857143,
      "grad_norm": 0.13468781113624573,
      "learning_rate": 3.786428571428572e-05,
      "loss": 0.0025,
      "step": 16990
    },
    {
      "epoch": 0.4857142857142857,
      "grad_norm": 0.27353882789611816,
      "learning_rate": 3.785714285714286e-05,
      "loss": 0.0025,
      "step": 17000
    },
    {
      "epoch": 0.486,
      "grad_norm": 0.04640362784266472,
      "learning_rate": 3.7850000000000005e-05,
      "loss": 0.0004,
      "step": 17010
    },
    {
      "epoch": 0.48628571428571427,
      "grad_norm": 0.3066549003124237,
      "learning_rate": 3.784285714285715e-05,
      "loss": 0.0033,
      "step": 17020
    },
    {
      "epoch": 0.4865714285714286,
      "grad_norm": 0.1628981977701187,
      "learning_rate": 3.783571428571429e-05,
      "loss": 0.002,
      "step": 17030
    },
    {
      "epoch": 0.4868571428571429,
      "grad_norm": 0.09448214620351791,
      "learning_rate": 3.782857142857143e-05,
      "loss": 0.0013,
      "step": 17040
    },
    {
      "epoch": 0.48714285714285716,
      "grad_norm": 0.04644162207841873,
      "learning_rate": 3.782142857142857e-05,
      "loss": 0.0009,
      "step": 17050
    },
    {
      "epoch": 0.48742857142857143,
      "grad_norm": 0.05837126076221466,
      "learning_rate": 3.781428571428572e-05,
      "loss": 0.002,
      "step": 17060
    },
    {
      "epoch": 0.4877142857142857,
      "grad_norm": 0.37861311435699463,
      "learning_rate": 3.7807142857142856e-05,
      "loss": 0.0008,
      "step": 17070
    },
    {
      "epoch": 0.488,
      "grad_norm": 0.0,
      "learning_rate": 3.7800000000000004e-05,
      "loss": 0.0011,
      "step": 17080
    },
    {
      "epoch": 0.48828571428571427,
      "grad_norm": 0.08487775176763535,
      "learning_rate": 3.7792857142857146e-05,
      "loss": 0.0018,
      "step": 17090
    },
    {
      "epoch": 0.48857142857142855,
      "grad_norm": 0.03846823424100876,
      "learning_rate": 3.778571428571429e-05,
      "loss": 0.0008,
      "step": 17100
    },
    {
      "epoch": 0.4888571428571429,
      "grad_norm": 0.0,
      "learning_rate": 3.777857142857143e-05,
      "loss": 0.0012,
      "step": 17110
    },
    {
      "epoch": 0.48914285714285716,
      "grad_norm": 0.0490645207464695,
      "learning_rate": 3.777142857142858e-05,
      "loss": 0.0009,
      "step": 17120
    },
    {
      "epoch": 0.48942857142857144,
      "grad_norm": 0.13291771709918976,
      "learning_rate": 3.776428571428572e-05,
      "loss": 0.0021,
      "step": 17130
    },
    {
      "epoch": 0.4897142857142857,
      "grad_norm": 0.09220029413700104,
      "learning_rate": 3.7757142857142854e-05,
      "loss": 0.0009,
      "step": 17140
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.0,
      "learning_rate": 3.775e-05,
      "loss": 0.0023,
      "step": 17150
    },
    {
      "epoch": 0.49028571428571427,
      "grad_norm": 0.07791287451982498,
      "learning_rate": 3.7742857142857145e-05,
      "loss": 0.0017,
      "step": 17160
    },
    {
      "epoch": 0.49057142857142855,
      "grad_norm": 0.0946931317448616,
      "learning_rate": 3.7735714285714286e-05,
      "loss": 0.0012,
      "step": 17170
    },
    {
      "epoch": 0.4908571428571429,
      "grad_norm": 0.2632857859134674,
      "learning_rate": 3.772857142857143e-05,
      "loss": 0.0014,
      "step": 17180
    },
    {
      "epoch": 0.49114285714285716,
      "grad_norm": 0.08119747787714005,
      "learning_rate": 3.7721428571428576e-05,
      "loss": 0.001,
      "step": 17190
    },
    {
      "epoch": 0.49142857142857144,
      "grad_norm": 0.13275037705898285,
      "learning_rate": 3.771428571428572e-05,
      "loss": 0.0013,
      "step": 17200
    },
    {
      "epoch": 0.4917142857142857,
      "grad_norm": 0.04399317130446434,
      "learning_rate": 3.770714285714286e-05,
      "loss": 0.0017,
      "step": 17210
    },
    {
      "epoch": 0.492,
      "grad_norm": 0.0,
      "learning_rate": 3.77e-05,
      "loss": 0.0015,
      "step": 17220
    },
    {
      "epoch": 0.49228571428571427,
      "grad_norm": 0.08491618931293488,
      "learning_rate": 3.769285714285714e-05,
      "loss": 0.0012,
      "step": 17230
    },
    {
      "epoch": 0.49257142857142855,
      "grad_norm": 0.0,
      "learning_rate": 3.7685714285714285e-05,
      "loss": 0.0019,
      "step": 17240
    },
    {
      "epoch": 0.4928571428571429,
      "grad_norm": 0.0,
      "learning_rate": 3.767857142857143e-05,
      "loss": 0.0014,
      "step": 17250
    },
    {
      "epoch": 0.49314285714285716,
      "grad_norm": 0.0,
      "learning_rate": 3.7671428571428575e-05,
      "loss": 0.0011,
      "step": 17260
    },
    {
      "epoch": 0.49342857142857144,
      "grad_norm": 0.038674790412187576,
      "learning_rate": 3.766428571428572e-05,
      "loss": 0.0024,
      "step": 17270
    },
    {
      "epoch": 0.4937142857142857,
      "grad_norm": 0.04517500847578049,
      "learning_rate": 3.765714285714286e-05,
      "loss": 0.0017,
      "step": 17280
    },
    {
      "epoch": 0.494,
      "grad_norm": 0.04177356883883476,
      "learning_rate": 3.765e-05,
      "loss": 0.0012,
      "step": 17290
    },
    {
      "epoch": 0.4942857142857143,
      "grad_norm": 0.19461756944656372,
      "learning_rate": 3.764285714285715e-05,
      "loss": 0.0005,
      "step": 17300
    },
    {
      "epoch": 0.49457142857142855,
      "grad_norm": 0.09032028168439865,
      "learning_rate": 3.7635714285714284e-05,
      "loss": 0.001,
      "step": 17310
    },
    {
      "epoch": 0.4948571428571429,
      "grad_norm": 0.06066341698169708,
      "learning_rate": 3.762857142857143e-05,
      "loss": 0.0019,
      "step": 17320
    },
    {
      "epoch": 0.49514285714285716,
      "grad_norm": 0.027571728453040123,
      "learning_rate": 3.7621428571428574e-05,
      "loss": 0.0033,
      "step": 17330
    },
    {
      "epoch": 0.49542857142857144,
      "grad_norm": 0.25640398263931274,
      "learning_rate": 3.7614285714285716e-05,
      "loss": 0.0023,
      "step": 17340
    },
    {
      "epoch": 0.4957142857142857,
      "grad_norm": 0.03367361053824425,
      "learning_rate": 3.760714285714286e-05,
      "loss": 0.0018,
      "step": 17350
    },
    {
      "epoch": 0.496,
      "grad_norm": 0.1527666449546814,
      "learning_rate": 3.76e-05,
      "loss": 0.0012,
      "step": 17360
    },
    {
      "epoch": 0.4962857142857143,
      "grad_norm": 0.0490184985101223,
      "learning_rate": 3.759285714285715e-05,
      "loss": 0.0017,
      "step": 17370
    },
    {
      "epoch": 0.49657142857142855,
      "grad_norm": 0.39298784732818604,
      "learning_rate": 3.758571428571428e-05,
      "loss": 0.0013,
      "step": 17380
    },
    {
      "epoch": 0.49685714285714283,
      "grad_norm": 0.08186192065477371,
      "learning_rate": 3.757857142857143e-05,
      "loss": 0.0011,
      "step": 17390
    },
    {
      "epoch": 0.49714285714285716,
      "grad_norm": 0.04727257043123245,
      "learning_rate": 3.757142857142857e-05,
      "loss": 0.0026,
      "step": 17400
    },
    {
      "epoch": 0.49742857142857144,
      "grad_norm": 0.03027844801545143,
      "learning_rate": 3.756428571428572e-05,
      "loss": 0.0016,
      "step": 17410
    },
    {
      "epoch": 0.4977142857142857,
      "grad_norm": 0.22706440091133118,
      "learning_rate": 3.7557142857142856e-05,
      "loss": 0.0019,
      "step": 17420
    },
    {
      "epoch": 0.498,
      "grad_norm": 0.08564688265323639,
      "learning_rate": 3.7550000000000005e-05,
      "loss": 0.0013,
      "step": 17430
    },
    {
      "epoch": 0.4982857142857143,
      "grad_norm": 0.050276871770620346,
      "learning_rate": 3.7542857142857146e-05,
      "loss": 0.0018,
      "step": 17440
    },
    {
      "epoch": 0.49857142857142855,
      "grad_norm": 0.08637603372335434,
      "learning_rate": 3.753571428571429e-05,
      "loss": 0.0003,
      "step": 17450
    },
    {
      "epoch": 0.49885714285714283,
      "grad_norm": 0.0,
      "learning_rate": 3.752857142857143e-05,
      "loss": 0.0012,
      "step": 17460
    },
    {
      "epoch": 0.49914285714285717,
      "grad_norm": 0.03604792430996895,
      "learning_rate": 3.752142857142857e-05,
      "loss": 0.0018,
      "step": 17470
    },
    {
      "epoch": 0.49942857142857144,
      "grad_norm": 0.08127475529909134,
      "learning_rate": 3.751428571428572e-05,
      "loss": 0.0018,
      "step": 17480
    },
    {
      "epoch": 0.4997142857142857,
      "grad_norm": 0.04152364656329155,
      "learning_rate": 3.7507142857142855e-05,
      "loss": 0.001,
      "step": 17490
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.042898379266262054,
      "learning_rate": 3.7500000000000003e-05,
      "loss": 0.0023,
      "step": 17500
    },
    {
      "epoch": 0.5002857142857143,
      "grad_norm": 0.0,
      "learning_rate": 3.7492857142857145e-05,
      "loss": 0.0015,
      "step": 17510
    },
    {
      "epoch": 0.5005714285714286,
      "grad_norm": 0.22717979550361633,
      "learning_rate": 3.748571428571429e-05,
      "loss": 0.0022,
      "step": 17520
    },
    {
      "epoch": 0.5008571428571429,
      "grad_norm": 0.0,
      "learning_rate": 3.747857142857143e-05,
      "loss": 0.0013,
      "step": 17530
    },
    {
      "epoch": 0.5011428571428571,
      "grad_norm": 0.04416399821639061,
      "learning_rate": 3.747142857142858e-05,
      "loss": 0.0019,
      "step": 17540
    },
    {
      "epoch": 0.5014285714285714,
      "grad_norm": 0.03826955705881119,
      "learning_rate": 3.746428571428572e-05,
      "loss": 0.0008,
      "step": 17550
    },
    {
      "epoch": 0.5017142857142857,
      "grad_norm": 0.02524852193892002,
      "learning_rate": 3.745714285714286e-05,
      "loss": 0.002,
      "step": 17560
    },
    {
      "epoch": 0.502,
      "grad_norm": 0.08725244551897049,
      "learning_rate": 3.745e-05,
      "loss": 0.0024,
      "step": 17570
    },
    {
      "epoch": 0.5022857142857143,
      "grad_norm": 0.046557292342185974,
      "learning_rate": 3.7442857142857144e-05,
      "loss": 0.0017,
      "step": 17580
    },
    {
      "epoch": 0.5025714285714286,
      "grad_norm": 0.08111676573753357,
      "learning_rate": 3.7435714285714286e-05,
      "loss": 0.0017,
      "step": 17590
    },
    {
      "epoch": 0.5028571428571429,
      "grad_norm": 0.03683202713727951,
      "learning_rate": 3.742857142857143e-05,
      "loss": 0.002,
      "step": 17600
    },
    {
      "epoch": 0.5031428571428571,
      "grad_norm": 0.0415932796895504,
      "learning_rate": 3.7421428571428576e-05,
      "loss": 0.0012,
      "step": 17610
    },
    {
      "epoch": 0.5034285714285714,
      "grad_norm": 0.06037825718522072,
      "learning_rate": 3.741428571428572e-05,
      "loss": 0.0017,
      "step": 17620
    },
    {
      "epoch": 0.5037142857142857,
      "grad_norm": 0.053846120834350586,
      "learning_rate": 3.740714285714286e-05,
      "loss": 0.0016,
      "step": 17630
    },
    {
      "epoch": 0.504,
      "grad_norm": 0.0,
      "learning_rate": 3.74e-05,
      "loss": 0.0015,
      "step": 17640
    },
    {
      "epoch": 0.5042857142857143,
      "grad_norm": 0.0,
      "learning_rate": 3.739285714285714e-05,
      "loss": 0.0015,
      "step": 17650
    },
    {
      "epoch": 0.5045714285714286,
      "grad_norm": 0.04559524357318878,
      "learning_rate": 3.7385714285714284e-05,
      "loss": 0.0018,
      "step": 17660
    },
    {
      "epoch": 0.5048571428571429,
      "grad_norm": 0.03402179107069969,
      "learning_rate": 3.7378571428571426e-05,
      "loss": 0.0022,
      "step": 17670
    },
    {
      "epoch": 0.5051428571428571,
      "grad_norm": 0.16801580786705017,
      "learning_rate": 3.7371428571428575e-05,
      "loss": 0.0022,
      "step": 17680
    },
    {
      "epoch": 0.5054285714285714,
      "grad_norm": 0.08392497152090073,
      "learning_rate": 3.7364285714285716e-05,
      "loss": 0.0018,
      "step": 17690
    },
    {
      "epoch": 0.5057142857142857,
      "grad_norm": 0.045528993010520935,
      "learning_rate": 3.735714285714286e-05,
      "loss": 0.0021,
      "step": 17700
    },
    {
      "epoch": 0.506,
      "grad_norm": 0.038742389529943466,
      "learning_rate": 3.735e-05,
      "loss": 0.0021,
      "step": 17710
    },
    {
      "epoch": 0.5062857142857143,
      "grad_norm": 0.25851210951805115,
      "learning_rate": 3.734285714285715e-05,
      "loss": 0.0016,
      "step": 17720
    },
    {
      "epoch": 0.5065714285714286,
      "grad_norm": 0.0,
      "learning_rate": 3.733571428571428e-05,
      "loss": 0.001,
      "step": 17730
    },
    {
      "epoch": 0.5068571428571429,
      "grad_norm": 0.04404079541563988,
      "learning_rate": 3.732857142857143e-05,
      "loss": 0.0009,
      "step": 17740
    },
    {
      "epoch": 0.5071428571428571,
      "grad_norm": 0.0,
      "learning_rate": 3.7321428571428573e-05,
      "loss": 0.0007,
      "step": 17750
    },
    {
      "epoch": 0.5074285714285715,
      "grad_norm": 0.13278722763061523,
      "learning_rate": 3.7314285714285715e-05,
      "loss": 0.0044,
      "step": 17760
    },
    {
      "epoch": 0.5077142857142857,
      "grad_norm": 0.23269376158714294,
      "learning_rate": 3.730714285714286e-05,
      "loss": 0.0024,
      "step": 17770
    },
    {
      "epoch": 0.508,
      "grad_norm": 0.13882087171077728,
      "learning_rate": 3.73e-05,
      "loss": 0.0015,
      "step": 17780
    },
    {
      "epoch": 0.5082857142857143,
      "grad_norm": 0.04176022857427597,
      "learning_rate": 3.729285714285715e-05,
      "loss": 0.0015,
      "step": 17790
    },
    {
      "epoch": 0.5085714285714286,
      "grad_norm": 0.08000372350215912,
      "learning_rate": 3.728571428571428e-05,
      "loss": 0.001,
      "step": 17800
    },
    {
      "epoch": 0.5088571428571429,
      "grad_norm": 0.23537136614322662,
      "learning_rate": 3.727857142857143e-05,
      "loss": 0.001,
      "step": 17810
    },
    {
      "epoch": 0.5091428571428571,
      "grad_norm": 0.0,
      "learning_rate": 3.727142857142857e-05,
      "loss": 0.0012,
      "step": 17820
    },
    {
      "epoch": 0.5094285714285715,
      "grad_norm": 0.043187759816646576,
      "learning_rate": 3.726428571428572e-05,
      "loss": 0.0004,
      "step": 17830
    },
    {
      "epoch": 0.5097142857142857,
      "grad_norm": 0.0845770314335823,
      "learning_rate": 3.7257142857142856e-05,
      "loss": 0.0004,
      "step": 17840
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.0,
      "learning_rate": 3.7250000000000004e-05,
      "loss": 0.0008,
      "step": 17850
    },
    {
      "epoch": 0.5102857142857142,
      "grad_norm": 0.04593745991587639,
      "learning_rate": 3.7242857142857146e-05,
      "loss": 0.0015,
      "step": 17860
    },
    {
      "epoch": 0.5105714285714286,
      "grad_norm": 0.08855559676885605,
      "learning_rate": 3.723571428571429e-05,
      "loss": 0.0018,
      "step": 17870
    },
    {
      "epoch": 0.5108571428571429,
      "grad_norm": 0.04823225736618042,
      "learning_rate": 3.722857142857143e-05,
      "loss": 0.0012,
      "step": 17880
    },
    {
      "epoch": 0.5111428571428571,
      "grad_norm": 0.0792091116309166,
      "learning_rate": 3.722142857142857e-05,
      "loss": 0.0012,
      "step": 17890
    },
    {
      "epoch": 0.5114285714285715,
      "grad_norm": 0.047140829265117645,
      "learning_rate": 3.721428571428572e-05,
      "loss": 0.0012,
      "step": 17900
    },
    {
      "epoch": 0.5117142857142857,
      "grad_norm": 0.07432875782251358,
      "learning_rate": 3.7207142857142854e-05,
      "loss": 0.0015,
      "step": 17910
    },
    {
      "epoch": 0.512,
      "grad_norm": 0.08923347294330597,
      "learning_rate": 3.72e-05,
      "loss": 0.0012,
      "step": 17920
    },
    {
      "epoch": 0.5122857142857142,
      "grad_norm": 0.08351695537567139,
      "learning_rate": 3.7192857142857145e-05,
      "loss": 0.0014,
      "step": 17930
    },
    {
      "epoch": 0.5125714285714286,
      "grad_norm": 0.03730666637420654,
      "learning_rate": 3.7185714285714286e-05,
      "loss": 0.0019,
      "step": 17940
    },
    {
      "epoch": 0.5128571428571429,
      "grad_norm": 0.09187684208154678,
      "learning_rate": 3.717857142857143e-05,
      "loss": 0.001,
      "step": 17950
    },
    {
      "epoch": 0.5131428571428571,
      "grad_norm": 0.0,
      "learning_rate": 3.717142857142858e-05,
      "loss": 0.0017,
      "step": 17960
    },
    {
      "epoch": 0.5134285714285715,
      "grad_norm": 0.09014556556940079,
      "learning_rate": 3.716428571428572e-05,
      "loss": 0.0013,
      "step": 17970
    },
    {
      "epoch": 0.5137142857142857,
      "grad_norm": 0.0230014156550169,
      "learning_rate": 3.715714285714286e-05,
      "loss": 0.0033,
      "step": 17980
    },
    {
      "epoch": 0.514,
      "grad_norm": 0.24282485246658325,
      "learning_rate": 3.715e-05,
      "loss": 0.001,
      "step": 17990
    },
    {
      "epoch": 0.5142857142857142,
      "grad_norm": 0.0,
      "learning_rate": 3.7142857142857143e-05,
      "loss": 0.001,
      "step": 18000
    },
    {
      "epoch": 0.5145714285714286,
      "grad_norm": 0.03693673014640808,
      "learning_rate": 3.7135714285714285e-05,
      "loss": 0.0009,
      "step": 18010
    },
    {
      "epoch": 0.5148571428571429,
      "grad_norm": 0.1937772035598755,
      "learning_rate": 3.712857142857143e-05,
      "loss": 0.0008,
      "step": 18020
    },
    {
      "epoch": 0.5151428571428571,
      "grad_norm": 0.08145999163389206,
      "learning_rate": 3.7121428571428575e-05,
      "loss": 0.0012,
      "step": 18030
    },
    {
      "epoch": 0.5154285714285715,
      "grad_norm": 0.0,
      "learning_rate": 3.711428571428572e-05,
      "loss": 0.0006,
      "step": 18040
    },
    {
      "epoch": 0.5157142857142857,
      "grad_norm": 0.04303094744682312,
      "learning_rate": 3.710714285714286e-05,
      "loss": 0.0019,
      "step": 18050
    },
    {
      "epoch": 0.516,
      "grad_norm": 0.169732466340065,
      "learning_rate": 3.71e-05,
      "loss": 0.0027,
      "step": 18060
    },
    {
      "epoch": 0.5162857142857142,
      "grad_norm": 0.04271100088953972,
      "learning_rate": 3.709285714285715e-05,
      "loss": 0.0029,
      "step": 18070
    },
    {
      "epoch": 0.5165714285714286,
      "grad_norm": 0.10953480005264282,
      "learning_rate": 3.7085714285714284e-05,
      "loss": 0.0029,
      "step": 18080
    },
    {
      "epoch": 0.5168571428571429,
      "grad_norm": 0.1948709338903427,
      "learning_rate": 3.707857142857143e-05,
      "loss": 0.0019,
      "step": 18090
    },
    {
      "epoch": 0.5171428571428571,
      "grad_norm": 0.10790552943944931,
      "learning_rate": 3.7071428571428574e-05,
      "loss": 0.0027,
      "step": 18100
    },
    {
      "epoch": 0.5174285714285715,
      "grad_norm": 0.05842962861061096,
      "learning_rate": 3.7064285714285716e-05,
      "loss": 0.0025,
      "step": 18110
    },
    {
      "epoch": 0.5177142857142857,
      "grad_norm": 0.03605417162179947,
      "learning_rate": 3.705714285714286e-05,
      "loss": 0.0016,
      "step": 18120
    },
    {
      "epoch": 0.518,
      "grad_norm": 0.10489314794540405,
      "learning_rate": 3.705e-05,
      "loss": 0.0019,
      "step": 18130
    },
    {
      "epoch": 0.5182857142857142,
      "grad_norm": 0.11745688319206238,
      "learning_rate": 3.704285714285715e-05,
      "loss": 0.0014,
      "step": 18140
    },
    {
      "epoch": 0.5185714285714286,
      "grad_norm": 0.0,
      "learning_rate": 3.703571428571429e-05,
      "loss": 0.0028,
      "step": 18150
    },
    {
      "epoch": 0.5188571428571429,
      "grad_norm": 0.18009117245674133,
      "learning_rate": 3.702857142857143e-05,
      "loss": 0.0016,
      "step": 18160
    },
    {
      "epoch": 0.5191428571428571,
      "grad_norm": 0.15291179716587067,
      "learning_rate": 3.702142857142857e-05,
      "loss": 0.0022,
      "step": 18170
    },
    {
      "epoch": 0.5194285714285715,
      "grad_norm": 0.05061466991901398,
      "learning_rate": 3.7014285714285715e-05,
      "loss": 0.001,
      "step": 18180
    },
    {
      "epoch": 0.5197142857142857,
      "grad_norm": 0.2897188067436218,
      "learning_rate": 3.7007142857142856e-05,
      "loss": 0.0008,
      "step": 18190
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.0,
      "learning_rate": 3.7e-05,
      "loss": 0.001,
      "step": 18200
    },
    {
      "epoch": 0.5202857142857142,
      "grad_norm": 0.08805686235427856,
      "learning_rate": 3.6992857142857147e-05,
      "loss": 0.0006,
      "step": 18210
    },
    {
      "epoch": 0.5205714285714286,
      "grad_norm": 0.2655373513698578,
      "learning_rate": 3.698571428571429e-05,
      "loss": 0.0014,
      "step": 18220
    },
    {
      "epoch": 0.5208571428571429,
      "grad_norm": 0.21311649680137634,
      "learning_rate": 3.697857142857143e-05,
      "loss": 0.0016,
      "step": 18230
    },
    {
      "epoch": 0.5211428571428571,
      "grad_norm": 0.08029623329639435,
      "learning_rate": 3.697142857142857e-05,
      "loss": 0.0016,
      "step": 18240
    },
    {
      "epoch": 0.5214285714285715,
      "grad_norm": 0.08593548834323883,
      "learning_rate": 3.696428571428572e-05,
      "loss": 0.0025,
      "step": 18250
    },
    {
      "epoch": 0.5217142857142857,
      "grad_norm": 0.20460757613182068,
      "learning_rate": 3.6957142857142855e-05,
      "loss": 0.0018,
      "step": 18260
    },
    {
      "epoch": 0.522,
      "grad_norm": 0.1211315467953682,
      "learning_rate": 3.6950000000000004e-05,
      "loss": 0.002,
      "step": 18270
    },
    {
      "epoch": 0.5222857142857142,
      "grad_norm": 0.17990683019161224,
      "learning_rate": 3.6942857142857145e-05,
      "loss": 0.002,
      "step": 18280
    },
    {
      "epoch": 0.5225714285714286,
      "grad_norm": 0.19971489906311035,
      "learning_rate": 3.693571428571429e-05,
      "loss": 0.001,
      "step": 18290
    },
    {
      "epoch": 0.5228571428571429,
      "grad_norm": 0.13419650495052338,
      "learning_rate": 3.692857142857143e-05,
      "loss": 0.0015,
      "step": 18300
    },
    {
      "epoch": 0.5231428571428571,
      "grad_norm": 0.23704791069030762,
      "learning_rate": 3.692142857142857e-05,
      "loss": 0.002,
      "step": 18310
    },
    {
      "epoch": 0.5234285714285715,
      "grad_norm": 0.0842660591006279,
      "learning_rate": 3.691428571428572e-05,
      "loss": 0.0027,
      "step": 18320
    },
    {
      "epoch": 0.5237142857142857,
      "grad_norm": 0.0,
      "learning_rate": 3.6907142857142854e-05,
      "loss": 0.0015,
      "step": 18330
    },
    {
      "epoch": 0.524,
      "grad_norm": 0.21065552532672882,
      "learning_rate": 3.69e-05,
      "loss": 0.002,
      "step": 18340
    },
    {
      "epoch": 0.5242857142857142,
      "grad_norm": 0.08567317575216293,
      "learning_rate": 3.6892857142857144e-05,
      "loss": 0.0028,
      "step": 18350
    },
    {
      "epoch": 0.5245714285714286,
      "grad_norm": 0.04337110370397568,
      "learning_rate": 3.688571428571429e-05,
      "loss": 0.001,
      "step": 18360
    },
    {
      "epoch": 0.5248571428571429,
      "grad_norm": 0.12783193588256836,
      "learning_rate": 3.687857142857143e-05,
      "loss": 0.0019,
      "step": 18370
    },
    {
      "epoch": 0.5251428571428571,
      "grad_norm": 0.1394917219877243,
      "learning_rate": 3.6871428571428576e-05,
      "loss": 0.0016,
      "step": 18380
    },
    {
      "epoch": 0.5254285714285715,
      "grad_norm": 0.056772444397211075,
      "learning_rate": 3.686428571428572e-05,
      "loss": 0.0021,
      "step": 18390
    },
    {
      "epoch": 0.5257142857142857,
      "grad_norm": 0.11774760484695435,
      "learning_rate": 3.685714285714286e-05,
      "loss": 0.0017,
      "step": 18400
    },
    {
      "epoch": 0.526,
      "grad_norm": 0.04805190488696098,
      "learning_rate": 3.685e-05,
      "loss": 0.0011,
      "step": 18410
    },
    {
      "epoch": 0.5262857142857142,
      "grad_norm": 0.0271854680031538,
      "learning_rate": 3.684285714285714e-05,
      "loss": 0.0009,
      "step": 18420
    },
    {
      "epoch": 0.5265714285714286,
      "grad_norm": 0.0,
      "learning_rate": 3.683571428571429e-05,
      "loss": 0.0021,
      "step": 18430
    },
    {
      "epoch": 0.5268571428571428,
      "grad_norm": 0.04007689282298088,
      "learning_rate": 3.6828571428571426e-05,
      "loss": 0.0013,
      "step": 18440
    },
    {
      "epoch": 0.5271428571428571,
      "grad_norm": 0.04252118989825249,
      "learning_rate": 3.6821428571428575e-05,
      "loss": 0.0016,
      "step": 18450
    },
    {
      "epoch": 0.5274285714285715,
      "grad_norm": 0.09708801656961441,
      "learning_rate": 3.6814285714285717e-05,
      "loss": 0.0015,
      "step": 18460
    },
    {
      "epoch": 0.5277142857142857,
      "grad_norm": 0.08288289606571198,
      "learning_rate": 3.680714285714286e-05,
      "loss": 0.0016,
      "step": 18470
    },
    {
      "epoch": 0.528,
      "grad_norm": 0.05790344253182411,
      "learning_rate": 3.68e-05,
      "loss": 0.0014,
      "step": 18480
    },
    {
      "epoch": 0.5282857142857142,
      "grad_norm": 0.19765430688858032,
      "learning_rate": 3.679285714285715e-05,
      "loss": 0.0007,
      "step": 18490
    },
    {
      "epoch": 0.5285714285714286,
      "grad_norm": 0.0,
      "learning_rate": 3.678571428571429e-05,
      "loss": 0.0015,
      "step": 18500
    },
    {
      "epoch": 0.5288571428571428,
      "grad_norm": 0.08390112221240997,
      "learning_rate": 3.677857142857143e-05,
      "loss": 0.0016,
      "step": 18510
    },
    {
      "epoch": 0.5291428571428571,
      "grad_norm": 0.08577603101730347,
      "learning_rate": 3.6771428571428574e-05,
      "loss": 0.0013,
      "step": 18520
    },
    {
      "epoch": 0.5294285714285715,
      "grad_norm": 0.16186121106147766,
      "learning_rate": 3.6764285714285715e-05,
      "loss": 0.0037,
      "step": 18530
    },
    {
      "epoch": 0.5297142857142857,
      "grad_norm": 0.18617813289165497,
      "learning_rate": 3.675714285714286e-05,
      "loss": 0.0025,
      "step": 18540
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.04106346145272255,
      "learning_rate": 3.675e-05,
      "loss": 0.0015,
      "step": 18550
    },
    {
      "epoch": 0.5302857142857142,
      "grad_norm": 0.05818261206150055,
      "learning_rate": 3.674285714285715e-05,
      "loss": 0.0022,
      "step": 18560
    },
    {
      "epoch": 0.5305714285714286,
      "grad_norm": 0.06663700938224792,
      "learning_rate": 3.673571428571429e-05,
      "loss": 0.0018,
      "step": 18570
    },
    {
      "epoch": 0.5308571428571428,
      "grad_norm": 0.4445053040981293,
      "learning_rate": 3.672857142857143e-05,
      "loss": 0.0024,
      "step": 18580
    },
    {
      "epoch": 0.5311428571428571,
      "grad_norm": 0.03413810953497887,
      "learning_rate": 3.672142857142857e-05,
      "loss": 0.0014,
      "step": 18590
    },
    {
      "epoch": 0.5314285714285715,
      "grad_norm": 0.14088767766952515,
      "learning_rate": 3.671428571428572e-05,
      "loss": 0.0018,
      "step": 18600
    },
    {
      "epoch": 0.5317142857142857,
      "grad_norm": 0.35639843344688416,
      "learning_rate": 3.6707142857142856e-05,
      "loss": 0.0026,
      "step": 18610
    },
    {
      "epoch": 0.532,
      "grad_norm": 0.045805733650922775,
      "learning_rate": 3.6700000000000004e-05,
      "loss": 0.0013,
      "step": 18620
    },
    {
      "epoch": 0.5322857142857143,
      "grad_norm": 0.08506692945957184,
      "learning_rate": 3.6692857142857146e-05,
      "loss": 0.0017,
      "step": 18630
    },
    {
      "epoch": 0.5325714285714286,
      "grad_norm": 0.0,
      "learning_rate": 3.668571428571429e-05,
      "loss": 0.0012,
      "step": 18640
    },
    {
      "epoch": 0.5328571428571428,
      "grad_norm": 0.08708900213241577,
      "learning_rate": 3.667857142857143e-05,
      "loss": 0.0011,
      "step": 18650
    },
    {
      "epoch": 0.5331428571428571,
      "grad_norm": 0.14798016846179962,
      "learning_rate": 3.667142857142857e-05,
      "loss": 0.0012,
      "step": 18660
    },
    {
      "epoch": 0.5334285714285715,
      "grad_norm": 0.1721656173467636,
      "learning_rate": 3.666428571428572e-05,
      "loss": 0.0021,
      "step": 18670
    },
    {
      "epoch": 0.5337142857142857,
      "grad_norm": 0.0,
      "learning_rate": 3.6657142857142855e-05,
      "loss": 0.0018,
      "step": 18680
    },
    {
      "epoch": 0.534,
      "grad_norm": 0.02842189185321331,
      "learning_rate": 3.665e-05,
      "loss": 0.0003,
      "step": 18690
    },
    {
      "epoch": 0.5342857142857143,
      "grad_norm": 0.11355847865343094,
      "learning_rate": 3.6642857142857145e-05,
      "loss": 0.0021,
      "step": 18700
    },
    {
      "epoch": 0.5345714285714286,
      "grad_norm": 0.05156947299838066,
      "learning_rate": 3.6635714285714287e-05,
      "loss": 0.0013,
      "step": 18710
    },
    {
      "epoch": 0.5348571428571428,
      "grad_norm": 0.20045597851276398,
      "learning_rate": 3.662857142857143e-05,
      "loss": 0.0024,
      "step": 18720
    },
    {
      "epoch": 0.5351428571428571,
      "grad_norm": 0.03463181108236313,
      "learning_rate": 3.662142857142857e-05,
      "loss": 0.0027,
      "step": 18730
    },
    {
      "epoch": 0.5354285714285715,
      "grad_norm": 0.04136247932910919,
      "learning_rate": 3.661428571428572e-05,
      "loss": 0.0008,
      "step": 18740
    },
    {
      "epoch": 0.5357142857142857,
      "grad_norm": 0.12613673508167267,
      "learning_rate": 3.6607142857142853e-05,
      "loss": 0.0014,
      "step": 18750
    },
    {
      "epoch": 0.536,
      "grad_norm": 0.04371342062950134,
      "learning_rate": 3.66e-05,
      "loss": 0.0016,
      "step": 18760
    },
    {
      "epoch": 0.5362857142857143,
      "grad_norm": 0.043411985039711,
      "learning_rate": 3.6592857142857144e-05,
      "loss": 0.0011,
      "step": 18770
    },
    {
      "epoch": 0.5365714285714286,
      "grad_norm": 0.12520602345466614,
      "learning_rate": 3.658571428571429e-05,
      "loss": 0.0015,
      "step": 18780
    },
    {
      "epoch": 0.5368571428571428,
      "grad_norm": 0.05397526174783707,
      "learning_rate": 3.657857142857143e-05,
      "loss": 0.0011,
      "step": 18790
    },
    {
      "epoch": 0.5371428571428571,
      "grad_norm": 0.038542989641427994,
      "learning_rate": 3.6571428571428576e-05,
      "loss": 0.0015,
      "step": 18800
    },
    {
      "epoch": 0.5374285714285715,
      "grad_norm": 0.12451013922691345,
      "learning_rate": 3.656428571428572e-05,
      "loss": 0.0014,
      "step": 18810
    },
    {
      "epoch": 0.5377142857142857,
      "grad_norm": 0.1278877705335617,
      "learning_rate": 3.655714285714286e-05,
      "loss": 0.002,
      "step": 18820
    },
    {
      "epoch": 0.538,
      "grad_norm": 0.09674624353647232,
      "learning_rate": 3.655e-05,
      "loss": 0.0016,
      "step": 18830
    },
    {
      "epoch": 0.5382857142857143,
      "grad_norm": 0.0,
      "learning_rate": 3.654285714285714e-05,
      "loss": 0.0007,
      "step": 18840
    },
    {
      "epoch": 0.5385714285714286,
      "grad_norm": 0.4059492349624634,
      "learning_rate": 3.653571428571429e-05,
      "loss": 0.0021,
      "step": 18850
    },
    {
      "epoch": 0.5388571428571428,
      "grad_norm": 0.07573174685239792,
      "learning_rate": 3.6528571428571426e-05,
      "loss": 0.002,
      "step": 18860
    },
    {
      "epoch": 0.5391428571428571,
      "grad_norm": 0.04798616096377373,
      "learning_rate": 3.6521428571428574e-05,
      "loss": 0.0013,
      "step": 18870
    },
    {
      "epoch": 0.5394285714285715,
      "grad_norm": 0.0831351950764656,
      "learning_rate": 3.6514285714285716e-05,
      "loss": 0.0018,
      "step": 18880
    },
    {
      "epoch": 0.5397142857142857,
      "grad_norm": 0.022441189736127853,
      "learning_rate": 3.650714285714286e-05,
      "loss": 0.0022,
      "step": 18890
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.0,
      "learning_rate": 3.65e-05,
      "loss": 0.0015,
      "step": 18900
    },
    {
      "epoch": 0.5402857142857143,
      "grad_norm": 0.2535949647426605,
      "learning_rate": 3.649285714285715e-05,
      "loss": 0.0014,
      "step": 18910
    },
    {
      "epoch": 0.5405714285714286,
      "grad_norm": 0.03546447306871414,
      "learning_rate": 3.648571428571429e-05,
      "loss": 0.0018,
      "step": 18920
    },
    {
      "epoch": 0.5408571428571428,
      "grad_norm": 0.06037401035428047,
      "learning_rate": 3.647857142857143e-05,
      "loss": 0.0029,
      "step": 18930
    },
    {
      "epoch": 0.5411428571428571,
      "grad_norm": 0.2019040584564209,
      "learning_rate": 3.647142857142857e-05,
      "loss": 0.0011,
      "step": 18940
    },
    {
      "epoch": 0.5414285714285715,
      "grad_norm": 0.046739835292100906,
      "learning_rate": 3.6464285714285715e-05,
      "loss": 0.0016,
      "step": 18950
    },
    {
      "epoch": 0.5417142857142857,
      "grad_norm": 0.26651856303215027,
      "learning_rate": 3.6457142857142857e-05,
      "loss": 0.0016,
      "step": 18960
    },
    {
      "epoch": 0.542,
      "grad_norm": 0.0,
      "learning_rate": 3.645e-05,
      "loss": 0.002,
      "step": 18970
    },
    {
      "epoch": 0.5422857142857143,
      "grad_norm": 0.11662071943283081,
      "learning_rate": 3.644285714285715e-05,
      "loss": 0.0017,
      "step": 18980
    },
    {
      "epoch": 0.5425714285714286,
      "grad_norm": 0.0,
      "learning_rate": 3.643571428571429e-05,
      "loss": 0.0022,
      "step": 18990
    },
    {
      "epoch": 0.5428571428571428,
      "grad_norm": 0.06172609329223633,
      "learning_rate": 3.642857142857143e-05,
      "loss": 0.0024,
      "step": 19000
    },
    {
      "epoch": 0.5431428571428571,
      "grad_norm": 0.23006632924079895,
      "learning_rate": 3.642142857142857e-05,
      "loss": 0.0028,
      "step": 19010
    },
    {
      "epoch": 0.5434285714285715,
      "grad_norm": 0.0,
      "learning_rate": 3.641428571428572e-05,
      "loss": 0.002,
      "step": 19020
    },
    {
      "epoch": 0.5437142857142857,
      "grad_norm": 0.0794515386223793,
      "learning_rate": 3.6407142857142855e-05,
      "loss": 0.0019,
      "step": 19030
    },
    {
      "epoch": 0.544,
      "grad_norm": 0.08704710751771927,
      "learning_rate": 3.6400000000000004e-05,
      "loss": 0.0019,
      "step": 19040
    },
    {
      "epoch": 0.5442857142857143,
      "grad_norm": 0.04351868852972984,
      "learning_rate": 3.6392857142857146e-05,
      "loss": 0.0017,
      "step": 19050
    },
    {
      "epoch": 0.5445714285714286,
      "grad_norm": 0.0,
      "learning_rate": 3.638571428571429e-05,
      "loss": 0.0008,
      "step": 19060
    },
    {
      "epoch": 0.5448571428571428,
      "grad_norm": 0.0,
      "learning_rate": 3.637857142857143e-05,
      "loss": 0.0015,
      "step": 19070
    },
    {
      "epoch": 0.5451428571428572,
      "grad_norm": 0.2229280024766922,
      "learning_rate": 3.637142857142857e-05,
      "loss": 0.0021,
      "step": 19080
    },
    {
      "epoch": 0.5454285714285714,
      "grad_norm": 0.16459721326828003,
      "learning_rate": 3.636428571428572e-05,
      "loss": 0.0021,
      "step": 19090
    },
    {
      "epoch": 0.5457142857142857,
      "grad_norm": 0.0400579497218132,
      "learning_rate": 3.6357142857142854e-05,
      "loss": 0.0012,
      "step": 19100
    },
    {
      "epoch": 0.546,
      "grad_norm": 0.041504260152578354,
      "learning_rate": 3.635e-05,
      "loss": 0.0015,
      "step": 19110
    },
    {
      "epoch": 0.5462857142857143,
      "grad_norm": 0.04724657163023949,
      "learning_rate": 3.6342857142857144e-05,
      "loss": 0.0017,
      "step": 19120
    },
    {
      "epoch": 0.5465714285714286,
      "grad_norm": 0.0848773941397667,
      "learning_rate": 3.633571428571429e-05,
      "loss": 0.0023,
      "step": 19130
    },
    {
      "epoch": 0.5468571428571428,
      "grad_norm": 0.11607266962528229,
      "learning_rate": 3.632857142857143e-05,
      "loss": 0.0026,
      "step": 19140
    },
    {
      "epoch": 0.5471428571428572,
      "grad_norm": 0.04220571741461754,
      "learning_rate": 3.6321428571428576e-05,
      "loss": 0.0014,
      "step": 19150
    },
    {
      "epoch": 0.5474285714285714,
      "grad_norm": 0.13230963051319122,
      "learning_rate": 3.631428571428572e-05,
      "loss": 0.0023,
      "step": 19160
    },
    {
      "epoch": 0.5477142857142857,
      "grad_norm": 0.15609772503376007,
      "learning_rate": 3.630714285714285e-05,
      "loss": 0.0028,
      "step": 19170
    },
    {
      "epoch": 0.548,
      "grad_norm": 0.0,
      "learning_rate": 3.63e-05,
      "loss": 0.002,
      "step": 19180
    },
    {
      "epoch": 0.5482857142857143,
      "grad_norm": 0.1280745416879654,
      "learning_rate": 3.629285714285714e-05,
      "loss": 0.0028,
      "step": 19190
    },
    {
      "epoch": 0.5485714285714286,
      "grad_norm": 0.052117060869932175,
      "learning_rate": 3.628571428571429e-05,
      "loss": 0.0013,
      "step": 19200
    },
    {
      "epoch": 0.5488571428571428,
      "grad_norm": 0.19839617609977722,
      "learning_rate": 3.6278571428571427e-05,
      "loss": 0.0023,
      "step": 19210
    },
    {
      "epoch": 0.5491428571428572,
      "grad_norm": 0.15368059277534485,
      "learning_rate": 3.6271428571428575e-05,
      "loss": 0.0018,
      "step": 19220
    },
    {
      "epoch": 0.5494285714285714,
      "grad_norm": 0.19479896128177643,
      "learning_rate": 3.626428571428572e-05,
      "loss": 0.0015,
      "step": 19230
    },
    {
      "epoch": 0.5497142857142857,
      "grad_norm": 0.22422485053539276,
      "learning_rate": 3.625714285714286e-05,
      "loss": 0.0018,
      "step": 19240
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.04408764839172363,
      "learning_rate": 3.625e-05,
      "loss": 0.002,
      "step": 19250
    },
    {
      "epoch": 0.5502857142857143,
      "grad_norm": 0.03485279530286789,
      "learning_rate": 3.624285714285714e-05,
      "loss": 0.0018,
      "step": 19260
    },
    {
      "epoch": 0.5505714285714286,
      "grad_norm": 0.08243755251169205,
      "learning_rate": 3.623571428571429e-05,
      "loss": 0.0014,
      "step": 19270
    },
    {
      "epoch": 0.5508571428571428,
      "grad_norm": 0.08440292626619339,
      "learning_rate": 3.6228571428571425e-05,
      "loss": 0.0009,
      "step": 19280
    },
    {
      "epoch": 0.5511428571428572,
      "grad_norm": 0.04227156937122345,
      "learning_rate": 3.6221428571428574e-05,
      "loss": 0.0019,
      "step": 19290
    },
    {
      "epoch": 0.5514285714285714,
      "grad_norm": 0.039832502603530884,
      "learning_rate": 3.6214285714285716e-05,
      "loss": 0.0011,
      "step": 19300
    },
    {
      "epoch": 0.5517142857142857,
      "grad_norm": 0.0,
      "learning_rate": 3.620714285714286e-05,
      "loss": 0.0021,
      "step": 19310
    },
    {
      "epoch": 0.552,
      "grad_norm": 0.038091856986284256,
      "learning_rate": 3.62e-05,
      "loss": 0.0012,
      "step": 19320
    },
    {
      "epoch": 0.5522857142857143,
      "grad_norm": 0.17758654057979584,
      "learning_rate": 3.619285714285715e-05,
      "loss": 0.0014,
      "step": 19330
    },
    {
      "epoch": 0.5525714285714286,
      "grad_norm": 0.08938571810722351,
      "learning_rate": 3.618571428571429e-05,
      "loss": 0.0021,
      "step": 19340
    },
    {
      "epoch": 0.5528571428571428,
      "grad_norm": 0.0,
      "learning_rate": 3.617857142857143e-05,
      "loss": 0.0022,
      "step": 19350
    },
    {
      "epoch": 0.5531428571428572,
      "grad_norm": 0.036102622747421265,
      "learning_rate": 3.617142857142857e-05,
      "loss": 0.0007,
      "step": 19360
    },
    {
      "epoch": 0.5534285714285714,
      "grad_norm": 0.12204411625862122,
      "learning_rate": 3.6164285714285714e-05,
      "loss": 0.0015,
      "step": 19370
    },
    {
      "epoch": 0.5537142857142857,
      "grad_norm": 0.03382321819663048,
      "learning_rate": 3.615714285714286e-05,
      "loss": 0.0024,
      "step": 19380
    },
    {
      "epoch": 0.554,
      "grad_norm": 0.0,
      "learning_rate": 3.615e-05,
      "loss": 0.0011,
      "step": 19390
    },
    {
      "epoch": 0.5542857142857143,
      "grad_norm": 0.04410460218787193,
      "learning_rate": 3.6142857142857146e-05,
      "loss": 0.0014,
      "step": 19400
    },
    {
      "epoch": 0.5545714285714286,
      "grad_norm": 0.31560009717941284,
      "learning_rate": 3.613571428571429e-05,
      "loss": 0.0035,
      "step": 19410
    },
    {
      "epoch": 0.5548571428571428,
      "grad_norm": 0.10180849581956863,
      "learning_rate": 3.612857142857143e-05,
      "loss": 0.0023,
      "step": 19420
    },
    {
      "epoch": 0.5551428571428572,
      "grad_norm": 0.037494249641895294,
      "learning_rate": 3.612142857142857e-05,
      "loss": 0.0011,
      "step": 19430
    },
    {
      "epoch": 0.5554285714285714,
      "grad_norm": 0.07243870198726654,
      "learning_rate": 3.611428571428572e-05,
      "loss": 0.0017,
      "step": 19440
    },
    {
      "epoch": 0.5557142857142857,
      "grad_norm": 0.05909803509712219,
      "learning_rate": 3.610714285714286e-05,
      "loss": 0.0017,
      "step": 19450
    },
    {
      "epoch": 0.556,
      "grad_norm": 0.16184690594673157,
      "learning_rate": 3.61e-05,
      "loss": 0.0023,
      "step": 19460
    },
    {
      "epoch": 0.5562857142857143,
      "grad_norm": 0.026973992586135864,
      "learning_rate": 3.6092857142857145e-05,
      "loss": 0.0017,
      "step": 19470
    },
    {
      "epoch": 0.5565714285714286,
      "grad_norm": 0.11571307480335236,
      "learning_rate": 3.608571428571429e-05,
      "loss": 0.0013,
      "step": 19480
    },
    {
      "epoch": 0.5568571428571428,
      "grad_norm": 0.06180210039019585,
      "learning_rate": 3.607857142857143e-05,
      "loss": 0.0013,
      "step": 19490
    },
    {
      "epoch": 0.5571428571428572,
      "grad_norm": 0.07066899538040161,
      "learning_rate": 3.607142857142857e-05,
      "loss": 0.0011,
      "step": 19500
    },
    {
      "epoch": 0.5574285714285714,
      "grad_norm": 0.04691560938954353,
      "learning_rate": 3.606428571428572e-05,
      "loss": 0.0021,
      "step": 19510
    },
    {
      "epoch": 0.5577142857142857,
      "grad_norm": 0.19980695843696594,
      "learning_rate": 3.605714285714286e-05,
      "loss": 0.001,
      "step": 19520
    },
    {
      "epoch": 0.558,
      "grad_norm": 0.07738958299160004,
      "learning_rate": 3.605e-05,
      "loss": 0.0014,
      "step": 19530
    },
    {
      "epoch": 0.5582857142857143,
      "grad_norm": 0.0330214686691761,
      "learning_rate": 3.6042857142857144e-05,
      "loss": 0.0011,
      "step": 19540
    },
    {
      "epoch": 0.5585714285714286,
      "grad_norm": 0.1330120712518692,
      "learning_rate": 3.603571428571429e-05,
      "loss": 0.0019,
      "step": 19550
    },
    {
      "epoch": 0.5588571428571428,
      "grad_norm": 0.044785529375076294,
      "learning_rate": 3.602857142857143e-05,
      "loss": 0.001,
      "step": 19560
    },
    {
      "epoch": 0.5591428571428572,
      "grad_norm": 0.050518132746219635,
      "learning_rate": 3.6021428571428576e-05,
      "loss": 0.002,
      "step": 19570
    },
    {
      "epoch": 0.5594285714285714,
      "grad_norm": 0.0,
      "learning_rate": 3.601428571428572e-05,
      "loss": 0.0005,
      "step": 19580
    },
    {
      "epoch": 0.5597142857142857,
      "grad_norm": 0.15073125064373016,
      "learning_rate": 3.600714285714286e-05,
      "loss": 0.0022,
      "step": 19590
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.040784500539302826,
      "learning_rate": 3.6e-05,
      "loss": 0.0013,
      "step": 19600
    },
    {
      "epoch": 0.5602857142857143,
      "grad_norm": 0.0,
      "learning_rate": 3.599285714285714e-05,
      "loss": 0.0005,
      "step": 19610
    },
    {
      "epoch": 0.5605714285714286,
      "grad_norm": 0.0,
      "learning_rate": 3.598571428571429e-05,
      "loss": 0.0012,
      "step": 19620
    },
    {
      "epoch": 0.5608571428571428,
      "grad_norm": 0.14745846390724182,
      "learning_rate": 3.5978571428571426e-05,
      "loss": 0.0022,
      "step": 19630
    },
    {
      "epoch": 0.5611428571428572,
      "grad_norm": 0.06952547281980515,
      "learning_rate": 3.5971428571428575e-05,
      "loss": 0.0015,
      "step": 19640
    },
    {
      "epoch": 0.5614285714285714,
      "grad_norm": 0.030302630737423897,
      "learning_rate": 3.5964285714285716e-05,
      "loss": 0.0009,
      "step": 19650
    },
    {
      "epoch": 0.5617142857142857,
      "grad_norm": 0.0459589920938015,
      "learning_rate": 3.5957142857142865e-05,
      "loss": 0.0025,
      "step": 19660
    },
    {
      "epoch": 0.562,
      "grad_norm": 0.2098323404788971,
      "learning_rate": 3.595e-05,
      "loss": 0.0023,
      "step": 19670
    },
    {
      "epoch": 0.5622857142857143,
      "grad_norm": 0.26439371705055237,
      "learning_rate": 3.594285714285714e-05,
      "loss": 0.0021,
      "step": 19680
    },
    {
      "epoch": 0.5625714285714286,
      "grad_norm": 0.019604284316301346,
      "learning_rate": 3.593571428571429e-05,
      "loss": 0.0021,
      "step": 19690
    },
    {
      "epoch": 0.5628571428571428,
      "grad_norm": 0.06052099168300629,
      "learning_rate": 3.5928571428571425e-05,
      "loss": 0.0015,
      "step": 19700
    },
    {
      "epoch": 0.5631428571428572,
      "grad_norm": 0.3127346336841583,
      "learning_rate": 3.592142857142857e-05,
      "loss": 0.0011,
      "step": 19710
    },
    {
      "epoch": 0.5634285714285714,
      "grad_norm": 0.0,
      "learning_rate": 3.5914285714285715e-05,
      "loss": 0.001,
      "step": 19720
    },
    {
      "epoch": 0.5637142857142857,
      "grad_norm": 0.1404838114976883,
      "learning_rate": 3.5907142857142864e-05,
      "loss": 0.0011,
      "step": 19730
    },
    {
      "epoch": 0.564,
      "grad_norm": 0.11836311221122742,
      "learning_rate": 3.59e-05,
      "loss": 0.0028,
      "step": 19740
    },
    {
      "epoch": 0.5642857142857143,
      "grad_norm": 0.21685078740119934,
      "learning_rate": 3.589285714285715e-05,
      "loss": 0.0012,
      "step": 19750
    },
    {
      "epoch": 0.5645714285714286,
      "grad_norm": 0.08789333701133728,
      "learning_rate": 3.588571428571429e-05,
      "loss": 0.0011,
      "step": 19760
    },
    {
      "epoch": 0.5648571428571428,
      "grad_norm": 0.08869775384664536,
      "learning_rate": 3.587857142857143e-05,
      "loss": 0.0019,
      "step": 19770
    },
    {
      "epoch": 0.5651428571428572,
      "grad_norm": 0.04633510485291481,
      "learning_rate": 3.587142857142857e-05,
      "loss": 0.0024,
      "step": 19780
    },
    {
      "epoch": 0.5654285714285714,
      "grad_norm": 0.14902850985527039,
      "learning_rate": 3.5864285714285714e-05,
      "loss": 0.0015,
      "step": 19790
    },
    {
      "epoch": 0.5657142857142857,
      "grad_norm": 0.04419402778148651,
      "learning_rate": 3.585714285714286e-05,
      "loss": 0.0016,
      "step": 19800
    },
    {
      "epoch": 0.566,
      "grad_norm": 0.043267447501420975,
      "learning_rate": 3.585e-05,
      "loss": 0.0007,
      "step": 19810
    },
    {
      "epoch": 0.5662857142857143,
      "grad_norm": 0.09881272912025452,
      "learning_rate": 3.5842857142857146e-05,
      "loss": 0.0024,
      "step": 19820
    },
    {
      "epoch": 0.5665714285714286,
      "grad_norm": 0.04143576696515083,
      "learning_rate": 3.583571428571429e-05,
      "loss": 0.0026,
      "step": 19830
    },
    {
      "epoch": 0.5668571428571428,
      "grad_norm": 0.4005666673183441,
      "learning_rate": 3.582857142857143e-05,
      "loss": 0.0025,
      "step": 19840
    },
    {
      "epoch": 0.5671428571428572,
      "grad_norm": 0.13949459791183472,
      "learning_rate": 3.582142857142857e-05,
      "loss": 0.0015,
      "step": 19850
    },
    {
      "epoch": 0.5674285714285714,
      "grad_norm": 0.08401055634021759,
      "learning_rate": 3.581428571428572e-05,
      "loss": 0.0007,
      "step": 19860
    },
    {
      "epoch": 0.5677142857142857,
      "grad_norm": 0.1305513083934784,
      "learning_rate": 3.580714285714286e-05,
      "loss": 0.0006,
      "step": 19870
    },
    {
      "epoch": 0.568,
      "grad_norm": 0.21212439239025116,
      "learning_rate": 3.58e-05,
      "loss": 0.0021,
      "step": 19880
    },
    {
      "epoch": 0.5682857142857143,
      "grad_norm": 0.21657833456993103,
      "learning_rate": 3.5792857142857145e-05,
      "loss": 0.0013,
      "step": 19890
    },
    {
      "epoch": 0.5685714285714286,
      "grad_norm": 0.05204835161566734,
      "learning_rate": 3.5785714285714286e-05,
      "loss": 0.001,
      "step": 19900
    },
    {
      "epoch": 0.5688571428571428,
      "grad_norm": 0.1331598460674286,
      "learning_rate": 3.577857142857143e-05,
      "loss": 0.0014,
      "step": 19910
    },
    {
      "epoch": 0.5691428571428572,
      "grad_norm": 0.0,
      "learning_rate": 3.577142857142857e-05,
      "loss": 0.0012,
      "step": 19920
    },
    {
      "epoch": 0.5694285714285714,
      "grad_norm": 0.0,
      "learning_rate": 3.576428571428572e-05,
      "loss": 0.0013,
      "step": 19930
    },
    {
      "epoch": 0.5697142857142857,
      "grad_norm": 0.04350905120372772,
      "learning_rate": 3.575714285714286e-05,
      "loss": 0.0012,
      "step": 19940
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.04339047148823738,
      "learning_rate": 3.575e-05,
      "loss": 0.0009,
      "step": 19950
    },
    {
      "epoch": 0.5702857142857143,
      "grad_norm": 0.0,
      "learning_rate": 3.574285714285714e-05,
      "loss": 0.0005,
      "step": 19960
    },
    {
      "epoch": 0.5705714285714286,
      "grad_norm": 0.04943821206688881,
      "learning_rate": 3.573571428571429e-05,
      "loss": 0.0015,
      "step": 19970
    },
    {
      "epoch": 0.5708571428571428,
      "grad_norm": 0.094083771109581,
      "learning_rate": 3.572857142857143e-05,
      "loss": 0.0015,
      "step": 19980
    },
    {
      "epoch": 0.5711428571428572,
      "grad_norm": 0.0,
      "learning_rate": 3.5721428571428575e-05,
      "loss": 0.0009,
      "step": 19990
    },
    {
      "epoch": 0.5714285714285714,
      "grad_norm": 0.07135343551635742,
      "learning_rate": 3.571428571428572e-05,
      "loss": 0.0012,
      "step": 20000
    },
    {
      "epoch": 0.5717142857142857,
      "grad_norm": 0.2722316384315491,
      "learning_rate": 3.570714285714286e-05,
      "loss": 0.0024,
      "step": 20010
    },
    {
      "epoch": 0.572,
      "grad_norm": 0.17128394544124603,
      "learning_rate": 3.57e-05,
      "loss": 0.0022,
      "step": 20020
    },
    {
      "epoch": 0.5722857142857143,
      "grad_norm": 0.051052726805210114,
      "learning_rate": 3.569285714285714e-05,
      "loss": 0.0013,
      "step": 20030
    },
    {
      "epoch": 0.5725714285714286,
      "grad_norm": 0.09847690165042877,
      "learning_rate": 3.568571428571429e-05,
      "loss": 0.0009,
      "step": 20040
    },
    {
      "epoch": 0.5728571428571428,
      "grad_norm": 0.0,
      "learning_rate": 3.5678571428571426e-05,
      "loss": 0.0016,
      "step": 20050
    },
    {
      "epoch": 0.5731428571428572,
      "grad_norm": 0.3376084268093109,
      "learning_rate": 3.5671428571428574e-05,
      "loss": 0.0016,
      "step": 20060
    },
    {
      "epoch": 0.5734285714285714,
      "grad_norm": 0.20008082687854767,
      "learning_rate": 3.5664285714285716e-05,
      "loss": 0.0019,
      "step": 20070
    },
    {
      "epoch": 0.5737142857142857,
      "grad_norm": 0.0,
      "learning_rate": 3.5657142857142864e-05,
      "loss": 0.0009,
      "step": 20080
    },
    {
      "epoch": 0.574,
      "grad_norm": 0.05840497091412544,
      "learning_rate": 3.565e-05,
      "loss": 0.0019,
      "step": 20090
    },
    {
      "epoch": 0.5742857142857143,
      "grad_norm": 0.041442494839429855,
      "learning_rate": 3.564285714285715e-05,
      "loss": 0.0004,
      "step": 20100
    },
    {
      "epoch": 0.5745714285714286,
      "grad_norm": 0.18845419585704803,
      "learning_rate": 3.563571428571429e-05,
      "loss": 0.0029,
      "step": 20110
    },
    {
      "epoch": 0.5748571428571428,
      "grad_norm": 0.1997753083705902,
      "learning_rate": 3.562857142857143e-05,
      "loss": 0.0018,
      "step": 20120
    },
    {
      "epoch": 0.5751428571428572,
      "grad_norm": 0.054337840527296066,
      "learning_rate": 3.562142857142857e-05,
      "loss": 0.0012,
      "step": 20130
    },
    {
      "epoch": 0.5754285714285714,
      "grad_norm": 0.17254281044006348,
      "learning_rate": 3.5614285714285715e-05,
      "loss": 0.0023,
      "step": 20140
    },
    {
      "epoch": 0.5757142857142857,
      "grad_norm": 0.05149129778146744,
      "learning_rate": 3.560714285714286e-05,
      "loss": 0.0028,
      "step": 20150
    },
    {
      "epoch": 0.576,
      "grad_norm": 0.1414690464735031,
      "learning_rate": 3.56e-05,
      "loss": 0.0021,
      "step": 20160
    },
    {
      "epoch": 0.5762857142857143,
      "grad_norm": 0.07959190011024475,
      "learning_rate": 3.5592857142857146e-05,
      "loss": 0.0012,
      "step": 20170
    },
    {
      "epoch": 0.5765714285714286,
      "grad_norm": 0.07954146713018417,
      "learning_rate": 3.558571428571429e-05,
      "loss": 0.0032,
      "step": 20180
    },
    {
      "epoch": 0.5768571428571428,
      "grad_norm": 0.09194350987672806,
      "learning_rate": 3.557857142857143e-05,
      "loss": 0.001,
      "step": 20190
    },
    {
      "epoch": 0.5771428571428572,
      "grad_norm": 0.18301910161972046,
      "learning_rate": 3.557142857142857e-05,
      "loss": 0.0011,
      "step": 20200
    },
    {
      "epoch": 0.5774285714285714,
      "grad_norm": 0.3036964237689972,
      "learning_rate": 3.556428571428571e-05,
      "loss": 0.0014,
      "step": 20210
    },
    {
      "epoch": 0.5777142857142857,
      "grad_norm": 0.12536029517650604,
      "learning_rate": 3.555714285714286e-05,
      "loss": 0.0014,
      "step": 20220
    },
    {
      "epoch": 0.578,
      "grad_norm": 0.12273280322551727,
      "learning_rate": 3.555e-05,
      "loss": 0.0019,
      "step": 20230
    },
    {
      "epoch": 0.5782857142857143,
      "grad_norm": 0.11303611844778061,
      "learning_rate": 3.5542857142857145e-05,
      "loss": 0.002,
      "step": 20240
    },
    {
      "epoch": 0.5785714285714286,
      "grad_norm": 0.20834627747535706,
      "learning_rate": 3.553571428571429e-05,
      "loss": 0.0023,
      "step": 20250
    },
    {
      "epoch": 0.5788571428571428,
      "grad_norm": 0.10022863000631332,
      "learning_rate": 3.552857142857143e-05,
      "loss": 0.0024,
      "step": 20260
    },
    {
      "epoch": 0.5791428571428572,
      "grad_norm": 0.04754335433244705,
      "learning_rate": 3.552142857142857e-05,
      "loss": 0.0015,
      "step": 20270
    },
    {
      "epoch": 0.5794285714285714,
      "grad_norm": 0.13493436574935913,
      "learning_rate": 3.551428571428572e-05,
      "loss": 0.0016,
      "step": 20280
    },
    {
      "epoch": 0.5797142857142857,
      "grad_norm": 0.04422008991241455,
      "learning_rate": 3.550714285714286e-05,
      "loss": 0.0012,
      "step": 20290
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.3447577953338623,
      "learning_rate": 3.55e-05,
      "loss": 0.0007,
      "step": 20300
    },
    {
      "epoch": 0.5802857142857143,
      "grad_norm": 0.10021942108869553,
      "learning_rate": 3.5492857142857144e-05,
      "loss": 0.0012,
      "step": 20310
    },
    {
      "epoch": 0.5805714285714285,
      "grad_norm": 0.046615634113550186,
      "learning_rate": 3.5485714285714286e-05,
      "loss": 0.0014,
      "step": 20320
    },
    {
      "epoch": 0.5808571428571428,
      "grad_norm": 0.15009747445583344,
      "learning_rate": 3.547857142857143e-05,
      "loss": 0.0011,
      "step": 20330
    },
    {
      "epoch": 0.5811428571428572,
      "grad_norm": 0.04439149796962738,
      "learning_rate": 3.547142857142857e-05,
      "loss": 0.0011,
      "step": 20340
    },
    {
      "epoch": 0.5814285714285714,
      "grad_norm": 0.0,
      "learning_rate": 3.546428571428572e-05,
      "loss": 0.0012,
      "step": 20350
    },
    {
      "epoch": 0.5817142857142857,
      "grad_norm": 0.19662806391716003,
      "learning_rate": 3.545714285714286e-05,
      "loss": 0.0016,
      "step": 20360
    },
    {
      "epoch": 0.582,
      "grad_norm": 0.1251346468925476,
      "learning_rate": 3.545e-05,
      "loss": 0.0013,
      "step": 20370
    },
    {
      "epoch": 0.5822857142857143,
      "grad_norm": 0.0,
      "learning_rate": 3.544285714285714e-05,
      "loss": 0.001,
      "step": 20380
    },
    {
      "epoch": 0.5825714285714285,
      "grad_norm": 0.12447797507047653,
      "learning_rate": 3.543571428571429e-05,
      "loss": 0.0023,
      "step": 20390
    },
    {
      "epoch": 0.5828571428571429,
      "grad_norm": 0.08098261058330536,
      "learning_rate": 3.5428571428571426e-05,
      "loss": 0.0019,
      "step": 20400
    },
    {
      "epoch": 0.5831428571428572,
      "grad_norm": 0.040298931300640106,
      "learning_rate": 3.5421428571428575e-05,
      "loss": 0.0007,
      "step": 20410
    },
    {
      "epoch": 0.5834285714285714,
      "grad_norm": 0.047104742377996445,
      "learning_rate": 3.5414285714285716e-05,
      "loss": 0.002,
      "step": 20420
    },
    {
      "epoch": 0.5837142857142857,
      "grad_norm": 0.0,
      "learning_rate": 3.540714285714286e-05,
      "loss": 0.0017,
      "step": 20430
    },
    {
      "epoch": 0.584,
      "grad_norm": 0.04372094199061394,
      "learning_rate": 3.54e-05,
      "loss": 0.0018,
      "step": 20440
    },
    {
      "epoch": 0.5842857142857143,
      "grad_norm": 0.042656995356082916,
      "learning_rate": 3.539285714285714e-05,
      "loss": 0.0016,
      "step": 20450
    },
    {
      "epoch": 0.5845714285714285,
      "grad_norm": 0.14019529521465302,
      "learning_rate": 3.538571428571429e-05,
      "loss": 0.0016,
      "step": 20460
    },
    {
      "epoch": 0.5848571428571429,
      "grad_norm": 0.06068199872970581,
      "learning_rate": 3.5378571428571425e-05,
      "loss": 0.0023,
      "step": 20470
    },
    {
      "epoch": 0.5851428571428572,
      "grad_norm": 0.16855046153068542,
      "learning_rate": 3.5371428571428574e-05,
      "loss": 0.0012,
      "step": 20480
    },
    {
      "epoch": 0.5854285714285714,
      "grad_norm": 0.2785327136516571,
      "learning_rate": 3.5364285714285715e-05,
      "loss": 0.0019,
      "step": 20490
    },
    {
      "epoch": 0.5857142857142857,
      "grad_norm": 0.08557936549186707,
      "learning_rate": 3.5357142857142864e-05,
      "loss": 0.0021,
      "step": 20500
    },
    {
      "epoch": 0.586,
      "grad_norm": 0.04125990346074104,
      "learning_rate": 3.535e-05,
      "loss": 0.0024,
      "step": 20510
    },
    {
      "epoch": 0.5862857142857143,
      "grad_norm": 0.05670586973428726,
      "learning_rate": 3.534285714285715e-05,
      "loss": 0.0028,
      "step": 20520
    },
    {
      "epoch": 0.5865714285714285,
      "grad_norm": 0.06818859279155731,
      "learning_rate": 3.533571428571429e-05,
      "loss": 0.0025,
      "step": 20530
    },
    {
      "epoch": 0.5868571428571429,
      "grad_norm": 0.040082208812236786,
      "learning_rate": 3.532857142857143e-05,
      "loss": 0.0011,
      "step": 20540
    },
    {
      "epoch": 0.5871428571428572,
      "grad_norm": 0.04329705238342285,
      "learning_rate": 3.532142857142857e-05,
      "loss": 0.0013,
      "step": 20550
    },
    {
      "epoch": 0.5874285714285714,
      "grad_norm": 0.14800924062728882,
      "learning_rate": 3.5314285714285714e-05,
      "loss": 0.0014,
      "step": 20560
    },
    {
      "epoch": 0.5877142857142857,
      "grad_norm": 0.07798223197460175,
      "learning_rate": 3.530714285714286e-05,
      "loss": 0.0018,
      "step": 20570
    },
    {
      "epoch": 0.588,
      "grad_norm": 0.04319489374756813,
      "learning_rate": 3.53e-05,
      "loss": 0.0023,
      "step": 20580
    },
    {
      "epoch": 0.5882857142857143,
      "grad_norm": 0.09899235516786575,
      "learning_rate": 3.5292857142857146e-05,
      "loss": 0.0012,
      "step": 20590
    },
    {
      "epoch": 0.5885714285714285,
      "grad_norm": 0.03516693413257599,
      "learning_rate": 3.528571428571429e-05,
      "loss": 0.0011,
      "step": 20600
    },
    {
      "epoch": 0.5888571428571429,
      "grad_norm": 0.20325063169002533,
      "learning_rate": 3.527857142857143e-05,
      "loss": 0.0023,
      "step": 20610
    },
    {
      "epoch": 0.5891428571428572,
      "grad_norm": 0.04000082612037659,
      "learning_rate": 3.527142857142857e-05,
      "loss": 0.0009,
      "step": 20620
    },
    {
      "epoch": 0.5894285714285714,
      "grad_norm": 0.0457933284342289,
      "learning_rate": 3.526428571428572e-05,
      "loss": 0.0005,
      "step": 20630
    },
    {
      "epoch": 0.5897142857142857,
      "grad_norm": 0.0576147586107254,
      "learning_rate": 3.525714285714286e-05,
      "loss": 0.002,
      "step": 20640
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.1507205367088318,
      "learning_rate": 3.525e-05,
      "loss": 0.0018,
      "step": 20650
    },
    {
      "epoch": 0.5902857142857143,
      "grad_norm": 0.1834346354007721,
      "learning_rate": 3.5242857142857145e-05,
      "loss": 0.0016,
      "step": 20660
    },
    {
      "epoch": 0.5905714285714285,
      "grad_norm": 0.07312890142202377,
      "learning_rate": 3.5235714285714286e-05,
      "loss": 0.0012,
      "step": 20670
    },
    {
      "epoch": 0.5908571428571429,
      "grad_norm": 0.148506760597229,
      "learning_rate": 3.5228571428571435e-05,
      "loss": 0.0022,
      "step": 20680
    },
    {
      "epoch": 0.5911428571428572,
      "grad_norm": 0.04099676012992859,
      "learning_rate": 3.522142857142857e-05,
      "loss": 0.0012,
      "step": 20690
    },
    {
      "epoch": 0.5914285714285714,
      "grad_norm": 0.042602844536304474,
      "learning_rate": 3.521428571428572e-05,
      "loss": 0.0017,
      "step": 20700
    },
    {
      "epoch": 0.5917142857142857,
      "grad_norm": 0.2513214349746704,
      "learning_rate": 3.520714285714286e-05,
      "loss": 0.001,
      "step": 20710
    },
    {
      "epoch": 0.592,
      "grad_norm": 0.0864214226603508,
      "learning_rate": 3.52e-05,
      "loss": 0.002,
      "step": 20720
    },
    {
      "epoch": 0.5922857142857143,
      "grad_norm": 0.15670281648635864,
      "learning_rate": 3.5192857142857144e-05,
      "loss": 0.0017,
      "step": 20730
    },
    {
      "epoch": 0.5925714285714285,
      "grad_norm": 0.05506625771522522,
      "learning_rate": 3.5185714285714285e-05,
      "loss": 0.0012,
      "step": 20740
    },
    {
      "epoch": 0.5928571428571429,
      "grad_norm": 0.09074331820011139,
      "learning_rate": 3.5178571428571434e-05,
      "loss": 0.0009,
      "step": 20750
    },
    {
      "epoch": 0.5931428571428572,
      "grad_norm": 0.03618982061743736,
      "learning_rate": 3.517142857142857e-05,
      "loss": 0.0013,
      "step": 20760
    },
    {
      "epoch": 0.5934285714285714,
      "grad_norm": 0.12451653182506561,
      "learning_rate": 3.516428571428572e-05,
      "loss": 0.0012,
      "step": 20770
    },
    {
      "epoch": 0.5937142857142857,
      "grad_norm": 0.0,
      "learning_rate": 3.515714285714286e-05,
      "loss": 0.0021,
      "step": 20780
    },
    {
      "epoch": 0.594,
      "grad_norm": 0.0,
      "learning_rate": 3.515e-05,
      "loss": 0.0007,
      "step": 20790
    },
    {
      "epoch": 0.5942857142857143,
      "grad_norm": 0.0523209273815155,
      "learning_rate": 3.514285714285714e-05,
      "loss": 0.0016,
      "step": 20800
    },
    {
      "epoch": 0.5945714285714285,
      "grad_norm": 0.03051401674747467,
      "learning_rate": 3.513571428571429e-05,
      "loss": 0.0018,
      "step": 20810
    },
    {
      "epoch": 0.5948571428571429,
      "grad_norm": 0.2782464325428009,
      "learning_rate": 3.512857142857143e-05,
      "loss": 0.0024,
      "step": 20820
    },
    {
      "epoch": 0.5951428571428572,
      "grad_norm": 0.0,
      "learning_rate": 3.5121428571428574e-05,
      "loss": 0.0011,
      "step": 20830
    },
    {
      "epoch": 0.5954285714285714,
      "grad_norm": 0.05382877588272095,
      "learning_rate": 3.5114285714285716e-05,
      "loss": 0.0018,
      "step": 20840
    },
    {
      "epoch": 0.5957142857142858,
      "grad_norm": 0.042110756039619446,
      "learning_rate": 3.510714285714286e-05,
      "loss": 0.0012,
      "step": 20850
    },
    {
      "epoch": 0.596,
      "grad_norm": 0.19443514943122864,
      "learning_rate": 3.51e-05,
      "loss": 0.0023,
      "step": 20860
    },
    {
      "epoch": 0.5962857142857143,
      "grad_norm": 0.08265329152345657,
      "learning_rate": 3.509285714285714e-05,
      "loss": 0.0018,
      "step": 20870
    },
    {
      "epoch": 0.5965714285714285,
      "grad_norm": 0.08761831372976303,
      "learning_rate": 3.508571428571429e-05,
      "loss": 0.0011,
      "step": 20880
    },
    {
      "epoch": 0.5968571428571429,
      "grad_norm": 0.03291339427232742,
      "learning_rate": 3.507857142857143e-05,
      "loss": 0.0019,
      "step": 20890
    },
    {
      "epoch": 0.5971428571428572,
      "grad_norm": 0.0416734516620636,
      "learning_rate": 3.507142857142857e-05,
      "loss": 0.0014,
      "step": 20900
    },
    {
      "epoch": 0.5974285714285714,
      "grad_norm": 0.055169858038425446,
      "learning_rate": 3.5064285714285715e-05,
      "loss": 0.0018,
      "step": 20910
    },
    {
      "epoch": 0.5977142857142858,
      "grad_norm": 0.025298967957496643,
      "learning_rate": 3.505714285714286e-05,
      "loss": 0.0026,
      "step": 20920
    },
    {
      "epoch": 0.598,
      "grad_norm": 0.07993347197771072,
      "learning_rate": 3.505e-05,
      "loss": 0.0014,
      "step": 20930
    },
    {
      "epoch": 0.5982857142857143,
      "grad_norm": 0.19473686814308167,
      "learning_rate": 3.504285714285715e-05,
      "loss": 0.002,
      "step": 20940
    },
    {
      "epoch": 0.5985714285714285,
      "grad_norm": 0.22454537451267242,
      "learning_rate": 3.503571428571429e-05,
      "loss": 0.0019,
      "step": 20950
    },
    {
      "epoch": 0.5988571428571429,
      "grad_norm": 0.13679008185863495,
      "learning_rate": 3.502857142857143e-05,
      "loss": 0.001,
      "step": 20960
    },
    {
      "epoch": 0.5991428571428571,
      "grad_norm": 0.30294492840766907,
      "learning_rate": 3.502142857142857e-05,
      "loss": 0.0013,
      "step": 20970
    },
    {
      "epoch": 0.5994285714285714,
      "grad_norm": 0.31663915514945984,
      "learning_rate": 3.5014285714285714e-05,
      "loss": 0.0022,
      "step": 20980
    },
    {
      "epoch": 0.5997142857142858,
      "grad_norm": 0.10313940793275833,
      "learning_rate": 3.500714285714286e-05,
      "loss": 0.0012,
      "step": 20990
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.10599350184202194,
      "learning_rate": 3.5e-05,
      "loss": 0.0024,
      "step": 21000
    },
    {
      "epoch": 0.6002857142857143,
      "grad_norm": 0.16198109090328217,
      "learning_rate": 3.4992857142857145e-05,
      "loss": 0.0014,
      "step": 21010
    },
    {
      "epoch": 0.6005714285714285,
      "grad_norm": 0.1342109888792038,
      "learning_rate": 3.498571428571429e-05,
      "loss": 0.0013,
      "step": 21020
    },
    {
      "epoch": 0.6008571428571429,
      "grad_norm": 0.08450672775506973,
      "learning_rate": 3.4978571428571436e-05,
      "loss": 0.0022,
      "step": 21030
    },
    {
      "epoch": 0.6011428571428571,
      "grad_norm": 0.0,
      "learning_rate": 3.497142857142857e-05,
      "loss": 0.0013,
      "step": 21040
    },
    {
      "epoch": 0.6014285714285714,
      "grad_norm": 0.0,
      "learning_rate": 3.496428571428572e-05,
      "loss": 0.0006,
      "step": 21050
    },
    {
      "epoch": 0.6017142857142858,
      "grad_norm": 0.04670096933841705,
      "learning_rate": 3.495714285714286e-05,
      "loss": 0.001,
      "step": 21060
    },
    {
      "epoch": 0.602,
      "grad_norm": 0.031627003103494644,
      "learning_rate": 3.495e-05,
      "loss": 0.0024,
      "step": 21070
    },
    {
      "epoch": 0.6022857142857143,
      "grad_norm": 0.07047084718942642,
      "learning_rate": 3.4942857142857144e-05,
      "loss": 0.003,
      "step": 21080
    },
    {
      "epoch": 0.6025714285714285,
      "grad_norm": 0.04051446169614792,
      "learning_rate": 3.4935714285714286e-05,
      "loss": 0.0021,
      "step": 21090
    },
    {
      "epoch": 0.6028571428571429,
      "grad_norm": 0.17196668684482574,
      "learning_rate": 3.4928571428571434e-05,
      "loss": 0.0007,
      "step": 21100
    },
    {
      "epoch": 0.6031428571428571,
      "grad_norm": 0.31735286116600037,
      "learning_rate": 3.492142857142857e-05,
      "loss": 0.0023,
      "step": 21110
    },
    {
      "epoch": 0.6034285714285714,
      "grad_norm": 0.06545227766036987,
      "learning_rate": 3.491428571428572e-05,
      "loss": 0.0031,
      "step": 21120
    },
    {
      "epoch": 0.6037142857142858,
      "grad_norm": 0.04774943366646767,
      "learning_rate": 3.490714285714286e-05,
      "loss": 0.0021,
      "step": 21130
    },
    {
      "epoch": 0.604,
      "grad_norm": 0.0,
      "learning_rate": 3.49e-05,
      "loss": 0.0012,
      "step": 21140
    },
    {
      "epoch": 0.6042857142857143,
      "grad_norm": 0.04742005467414856,
      "learning_rate": 3.489285714285714e-05,
      "loss": 0.0011,
      "step": 21150
    },
    {
      "epoch": 0.6045714285714285,
      "grad_norm": 0.11791350692510605,
      "learning_rate": 3.488571428571429e-05,
      "loss": 0.0013,
      "step": 21160
    },
    {
      "epoch": 0.6048571428571429,
      "grad_norm": 0.2097223550081253,
      "learning_rate": 3.487857142857143e-05,
      "loss": 0.0025,
      "step": 21170
    },
    {
      "epoch": 0.6051428571428571,
      "grad_norm": 0.037335436791181564,
      "learning_rate": 3.4871428571428575e-05,
      "loss": 0.0012,
      "step": 21180
    },
    {
      "epoch": 0.6054285714285714,
      "grad_norm": 0.14473146200180054,
      "learning_rate": 3.486428571428572e-05,
      "loss": 0.0015,
      "step": 21190
    },
    {
      "epoch": 0.6057142857142858,
      "grad_norm": 0.04098772630095482,
      "learning_rate": 3.485714285714286e-05,
      "loss": 0.0016,
      "step": 21200
    },
    {
      "epoch": 0.606,
      "grad_norm": 0.09616617858409882,
      "learning_rate": 3.485e-05,
      "loss": 0.0013,
      "step": 21210
    },
    {
      "epoch": 0.6062857142857143,
      "grad_norm": 0.2140204906463623,
      "learning_rate": 3.484285714285714e-05,
      "loss": 0.0016,
      "step": 21220
    },
    {
      "epoch": 0.6065714285714285,
      "grad_norm": 0.08982455730438232,
      "learning_rate": 3.483571428571429e-05,
      "loss": 0.0016,
      "step": 21230
    },
    {
      "epoch": 0.6068571428571429,
      "grad_norm": 0.0,
      "learning_rate": 3.482857142857143e-05,
      "loss": 0.001,
      "step": 21240
    },
    {
      "epoch": 0.6071428571428571,
      "grad_norm": 0.10532640665769577,
      "learning_rate": 3.4821428571428574e-05,
      "loss": 0.0016,
      "step": 21250
    },
    {
      "epoch": 0.6074285714285714,
      "grad_norm": 0.0390043705701828,
      "learning_rate": 3.4814285714285715e-05,
      "loss": 0.0024,
      "step": 21260
    },
    {
      "epoch": 0.6077142857142858,
      "grad_norm": 0.053124845027923584,
      "learning_rate": 3.480714285714286e-05,
      "loss": 0.0009,
      "step": 21270
    },
    {
      "epoch": 0.608,
      "grad_norm": 0.0394560806453228,
      "learning_rate": 3.48e-05,
      "loss": 0.0012,
      "step": 21280
    },
    {
      "epoch": 0.6082857142857143,
      "grad_norm": 0.04780358076095581,
      "learning_rate": 3.479285714285714e-05,
      "loss": 0.0019,
      "step": 21290
    },
    {
      "epoch": 0.6085714285714285,
      "grad_norm": 0.0,
      "learning_rate": 3.478571428571429e-05,
      "loss": 0.0008,
      "step": 21300
    },
    {
      "epoch": 0.6088571428571429,
      "grad_norm": 0.18423189222812653,
      "learning_rate": 3.477857142857143e-05,
      "loss": 0.0018,
      "step": 21310
    },
    {
      "epoch": 0.6091428571428571,
      "grad_norm": 0.0,
      "learning_rate": 3.477142857142857e-05,
      "loss": 0.0014,
      "step": 21320
    },
    {
      "epoch": 0.6094285714285714,
      "grad_norm": 0.04895850643515587,
      "learning_rate": 3.4764285714285714e-05,
      "loss": 0.0022,
      "step": 21330
    },
    {
      "epoch": 0.6097142857142858,
      "grad_norm": 0.050400711596012115,
      "learning_rate": 3.475714285714286e-05,
      "loss": 0.0022,
      "step": 21340
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.03768317773938179,
      "learning_rate": 3.475e-05,
      "loss": 0.0006,
      "step": 21350
    },
    {
      "epoch": 0.6102857142857143,
      "grad_norm": 0.16100867092609406,
      "learning_rate": 3.4742857142857146e-05,
      "loss": 0.0027,
      "step": 21360
    },
    {
      "epoch": 0.6105714285714285,
      "grad_norm": 0.2398640364408493,
      "learning_rate": 3.473571428571429e-05,
      "loss": 0.0015,
      "step": 21370
    },
    {
      "epoch": 0.6108571428571429,
      "grad_norm": 0.02840842492878437,
      "learning_rate": 3.472857142857143e-05,
      "loss": 0.0014,
      "step": 21380
    },
    {
      "epoch": 0.6111428571428571,
      "grad_norm": 0.24283207952976227,
      "learning_rate": 3.472142857142857e-05,
      "loss": 0.0015,
      "step": 21390
    },
    {
      "epoch": 0.6114285714285714,
      "grad_norm": 0.11686740070581436,
      "learning_rate": 3.471428571428571e-05,
      "loss": 0.001,
      "step": 21400
    },
    {
      "epoch": 0.6117142857142858,
      "grad_norm": 0.12092392891645432,
      "learning_rate": 3.470714285714286e-05,
      "loss": 0.002,
      "step": 21410
    },
    {
      "epoch": 0.612,
      "grad_norm": 0.15551875531673431,
      "learning_rate": 3.4699999999999996e-05,
      "loss": 0.0015,
      "step": 21420
    },
    {
      "epoch": 0.6122857142857143,
      "grad_norm": 0.0420449934899807,
      "learning_rate": 3.4692857142857145e-05,
      "loss": 0.001,
      "step": 21430
    },
    {
      "epoch": 0.6125714285714285,
      "grad_norm": 0.0,
      "learning_rate": 3.468571428571429e-05,
      "loss": 0.0019,
      "step": 21440
    },
    {
      "epoch": 0.6128571428571429,
      "grad_norm": 0.0,
      "learning_rate": 3.4678571428571435e-05,
      "loss": 0.001,
      "step": 21450
    },
    {
      "epoch": 0.6131428571428571,
      "grad_norm": 0.06125407665967941,
      "learning_rate": 3.467142857142857e-05,
      "loss": 0.0016,
      "step": 21460
    },
    {
      "epoch": 0.6134285714285714,
      "grad_norm": 0.0,
      "learning_rate": 3.466428571428572e-05,
      "loss": 0.0003,
      "step": 21470
    },
    {
      "epoch": 0.6137142857142858,
      "grad_norm": 0.08744160085916519,
      "learning_rate": 3.465714285714286e-05,
      "loss": 0.001,
      "step": 21480
    },
    {
      "epoch": 0.614,
      "grad_norm": 0.04028342664241791,
      "learning_rate": 3.465e-05,
      "loss": 0.0006,
      "step": 21490
    },
    {
      "epoch": 0.6142857142857143,
      "grad_norm": 0.24469885230064392,
      "learning_rate": 3.4642857142857144e-05,
      "loss": 0.0016,
      "step": 21500
    },
    {
      "epoch": 0.6145714285714285,
      "grad_norm": 0.0,
      "learning_rate": 3.4635714285714285e-05,
      "loss": 0.0015,
      "step": 21510
    },
    {
      "epoch": 0.6148571428571429,
      "grad_norm": 0.047860730439424515,
      "learning_rate": 3.4628571428571434e-05,
      "loss": 0.0012,
      "step": 21520
    },
    {
      "epoch": 0.6151428571428571,
      "grad_norm": 0.08091498166322708,
      "learning_rate": 3.462142857142857e-05,
      "loss": 0.0028,
      "step": 21530
    },
    {
      "epoch": 0.6154285714285714,
      "grad_norm": 0.0827006921172142,
      "learning_rate": 3.461428571428572e-05,
      "loss": 0.0008,
      "step": 21540
    },
    {
      "epoch": 0.6157142857142858,
      "grad_norm": 0.081192746758461,
      "learning_rate": 3.460714285714286e-05,
      "loss": 0.0014,
      "step": 21550
    },
    {
      "epoch": 0.616,
      "grad_norm": 0.08438166975975037,
      "learning_rate": 3.46e-05,
      "loss": 0.0024,
      "step": 21560
    },
    {
      "epoch": 0.6162857142857143,
      "grad_norm": 0.2260349541902542,
      "learning_rate": 3.459285714285714e-05,
      "loss": 0.002,
      "step": 21570
    },
    {
      "epoch": 0.6165714285714285,
      "grad_norm": 0.0,
      "learning_rate": 3.458571428571429e-05,
      "loss": 0.0015,
      "step": 21580
    },
    {
      "epoch": 0.6168571428571429,
      "grad_norm": 0.12197861820459366,
      "learning_rate": 3.457857142857143e-05,
      "loss": 0.0019,
      "step": 21590
    },
    {
      "epoch": 0.6171428571428571,
      "grad_norm": 0.09424298256635666,
      "learning_rate": 3.4571428571428574e-05,
      "loss": 0.0018,
      "step": 21600
    },
    {
      "epoch": 0.6174285714285714,
      "grad_norm": 0.13180530071258545,
      "learning_rate": 3.4564285714285716e-05,
      "loss": 0.0026,
      "step": 21610
    },
    {
      "epoch": 0.6177142857142857,
      "grad_norm": 0.13375148177146912,
      "learning_rate": 3.455714285714286e-05,
      "loss": 0.0014,
      "step": 21620
    },
    {
      "epoch": 0.618,
      "grad_norm": 0.198824942111969,
      "learning_rate": 3.455e-05,
      "loss": 0.0016,
      "step": 21630
    },
    {
      "epoch": 0.6182857142857143,
      "grad_norm": 0.0,
      "learning_rate": 3.454285714285714e-05,
      "loss": 0.0016,
      "step": 21640
    },
    {
      "epoch": 0.6185714285714285,
      "grad_norm": 0.041344791650772095,
      "learning_rate": 3.453571428571429e-05,
      "loss": 0.0016,
      "step": 21650
    },
    {
      "epoch": 0.6188571428571429,
      "grad_norm": 0.0,
      "learning_rate": 3.452857142857143e-05,
      "loss": 0.0015,
      "step": 21660
    },
    {
      "epoch": 0.6191428571428571,
      "grad_norm": 0.2853224575519562,
      "learning_rate": 3.452142857142857e-05,
      "loss": 0.0017,
      "step": 21670
    },
    {
      "epoch": 0.6194285714285714,
      "grad_norm": 0.14532159268856049,
      "learning_rate": 3.4514285714285715e-05,
      "loss": 0.0015,
      "step": 21680
    },
    {
      "epoch": 0.6197142857142857,
      "grad_norm": 0.20650506019592285,
      "learning_rate": 3.4507142857142863e-05,
      "loss": 0.002,
      "step": 21690
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.04533575847744942,
      "learning_rate": 3.45e-05,
      "loss": 0.0005,
      "step": 21700
    },
    {
      "epoch": 0.6202857142857143,
      "grad_norm": 0.16055837273597717,
      "learning_rate": 3.449285714285714e-05,
      "loss": 0.0017,
      "step": 21710
    },
    {
      "epoch": 0.6205714285714286,
      "grad_norm": 0.0,
      "learning_rate": 3.448571428571429e-05,
      "loss": 0.0031,
      "step": 21720
    },
    {
      "epoch": 0.6208571428571429,
      "grad_norm": 0.18474461138248444,
      "learning_rate": 3.447857142857143e-05,
      "loss": 0.0016,
      "step": 21730
    },
    {
      "epoch": 0.6211428571428571,
      "grad_norm": 0.11810484528541565,
      "learning_rate": 3.447142857142857e-05,
      "loss": 0.0021,
      "step": 21740
    },
    {
      "epoch": 0.6214285714285714,
      "grad_norm": 0.08327261358499527,
      "learning_rate": 3.4464285714285714e-05,
      "loss": 0.0014,
      "step": 21750
    },
    {
      "epoch": 0.6217142857142857,
      "grad_norm": 0.04441932961344719,
      "learning_rate": 3.445714285714286e-05,
      "loss": 0.0027,
      "step": 21760
    },
    {
      "epoch": 0.622,
      "grad_norm": 0.05651275813579559,
      "learning_rate": 3.445e-05,
      "loss": 0.002,
      "step": 21770
    },
    {
      "epoch": 0.6222857142857143,
      "grad_norm": 0.07779762148857117,
      "learning_rate": 3.4442857142857146e-05,
      "loss": 0.0018,
      "step": 21780
    },
    {
      "epoch": 0.6225714285714286,
      "grad_norm": 0.0,
      "learning_rate": 3.443571428571429e-05,
      "loss": 0.0023,
      "step": 21790
    },
    {
      "epoch": 0.6228571428571429,
      "grad_norm": 0.1003527045249939,
      "learning_rate": 3.442857142857143e-05,
      "loss": 0.0013,
      "step": 21800
    },
    {
      "epoch": 0.6231428571428571,
      "grad_norm": 0.17561276257038116,
      "learning_rate": 3.442142857142857e-05,
      "loss": 0.0015,
      "step": 21810
    },
    {
      "epoch": 0.6234285714285714,
      "grad_norm": 0.31994742155075073,
      "learning_rate": 3.441428571428571e-05,
      "loss": 0.0015,
      "step": 21820
    },
    {
      "epoch": 0.6237142857142857,
      "grad_norm": 0.4019028842449188,
      "learning_rate": 3.440714285714286e-05,
      "loss": 0.0017,
      "step": 21830
    },
    {
      "epoch": 0.624,
      "grad_norm": 0.12172889709472656,
      "learning_rate": 3.4399999999999996e-05,
      "loss": 0.0019,
      "step": 21840
    },
    {
      "epoch": 0.6242857142857143,
      "grad_norm": 0.04563814774155617,
      "learning_rate": 3.4392857142857144e-05,
      "loss": 0.0016,
      "step": 21850
    },
    {
      "epoch": 0.6245714285714286,
      "grad_norm": 0.06635207682847977,
      "learning_rate": 3.4385714285714286e-05,
      "loss": 0.0017,
      "step": 21860
    },
    {
      "epoch": 0.6248571428571429,
      "grad_norm": 0.051939453929662704,
      "learning_rate": 3.4378571428571435e-05,
      "loss": 0.0025,
      "step": 21870
    },
    {
      "epoch": 0.6251428571428571,
      "grad_norm": 0.2813059091567993,
      "learning_rate": 3.437142857142857e-05,
      "loss": 0.0016,
      "step": 21880
    },
    {
      "epoch": 0.6254285714285714,
      "grad_norm": 0.03496575355529785,
      "learning_rate": 3.436428571428572e-05,
      "loss": 0.0017,
      "step": 21890
    },
    {
      "epoch": 0.6257142857142857,
      "grad_norm": 0.049199387431144714,
      "learning_rate": 3.435714285714286e-05,
      "loss": 0.0005,
      "step": 21900
    },
    {
      "epoch": 0.626,
      "grad_norm": 0.16442422568798065,
      "learning_rate": 3.435e-05,
      "loss": 0.0016,
      "step": 21910
    },
    {
      "epoch": 0.6262857142857143,
      "grad_norm": 0.0,
      "learning_rate": 3.434285714285714e-05,
      "loss": 0.0017,
      "step": 21920
    },
    {
      "epoch": 0.6265714285714286,
      "grad_norm": 0.17703427374362946,
      "learning_rate": 3.4335714285714285e-05,
      "loss": 0.0014,
      "step": 21930
    },
    {
      "epoch": 0.6268571428571429,
      "grad_norm": 0.18958479166030884,
      "learning_rate": 3.432857142857143e-05,
      "loss": 0.0018,
      "step": 21940
    },
    {
      "epoch": 0.6271428571428571,
      "grad_norm": 0.04619685187935829,
      "learning_rate": 3.432142857142857e-05,
      "loss": 0.001,
      "step": 21950
    },
    {
      "epoch": 0.6274285714285714,
      "grad_norm": 0.08726397156715393,
      "learning_rate": 3.431428571428572e-05,
      "loss": 0.0025,
      "step": 21960
    },
    {
      "epoch": 0.6277142857142857,
      "grad_norm": 0.05352599918842316,
      "learning_rate": 3.430714285714286e-05,
      "loss": 0.0021,
      "step": 21970
    },
    {
      "epoch": 0.628,
      "grad_norm": 0.04253682866692543,
      "learning_rate": 3.430000000000001e-05,
      "loss": 0.0023,
      "step": 21980
    },
    {
      "epoch": 0.6282857142857143,
      "grad_norm": 0.12498138099908829,
      "learning_rate": 3.429285714285714e-05,
      "loss": 0.0034,
      "step": 21990
    },
    {
      "epoch": 0.6285714285714286,
      "grad_norm": 0.04236459359526634,
      "learning_rate": 3.428571428571429e-05,
      "loss": 0.0015,
      "step": 22000
    },
    {
      "epoch": 0.6288571428571429,
      "grad_norm": 0.09005861729383469,
      "learning_rate": 3.427857142857143e-05,
      "loss": 0.0017,
      "step": 22010
    },
    {
      "epoch": 0.6291428571428571,
      "grad_norm": 0.042568139731884,
      "learning_rate": 3.4271428571428574e-05,
      "loss": 0.0012,
      "step": 22020
    },
    {
      "epoch": 0.6294285714285714,
      "grad_norm": 0.06365462392568588,
      "learning_rate": 3.4264285714285716e-05,
      "loss": 0.0022,
      "step": 22030
    },
    {
      "epoch": 0.6297142857142857,
      "grad_norm": 0.0803164467215538,
      "learning_rate": 3.425714285714286e-05,
      "loss": 0.0024,
      "step": 22040
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.04232485592365265,
      "learning_rate": 3.4250000000000006e-05,
      "loss": 0.001,
      "step": 22050
    },
    {
      "epoch": 0.6302857142857143,
      "grad_norm": 0.04759591445326805,
      "learning_rate": 3.424285714285714e-05,
      "loss": 0.001,
      "step": 22060
    },
    {
      "epoch": 0.6305714285714286,
      "grad_norm": 0.09074360132217407,
      "learning_rate": 3.423571428571429e-05,
      "loss": 0.0016,
      "step": 22070
    },
    {
      "epoch": 0.6308571428571429,
      "grad_norm": 0.061314091086387634,
      "learning_rate": 3.422857142857143e-05,
      "loss": 0.0022,
      "step": 22080
    },
    {
      "epoch": 0.6311428571428571,
      "grad_norm": 0.19011308252811432,
      "learning_rate": 3.422142857142857e-05,
      "loss": 0.0026,
      "step": 22090
    },
    {
      "epoch": 0.6314285714285715,
      "grad_norm": 0.15336623787879944,
      "learning_rate": 3.4214285714285714e-05,
      "loss": 0.0018,
      "step": 22100
    },
    {
      "epoch": 0.6317142857142857,
      "grad_norm": 0.09273344278335571,
      "learning_rate": 3.420714285714286e-05,
      "loss": 0.0006,
      "step": 22110
    },
    {
      "epoch": 0.632,
      "grad_norm": 0.15767128765583038,
      "learning_rate": 3.4200000000000005e-05,
      "loss": 0.0013,
      "step": 22120
    },
    {
      "epoch": 0.6322857142857143,
      "grad_norm": 0.0,
      "learning_rate": 3.4192857142857146e-05,
      "loss": 0.0023,
      "step": 22130
    },
    {
      "epoch": 0.6325714285714286,
      "grad_norm": 0.23672518134117126,
      "learning_rate": 3.418571428571429e-05,
      "loss": 0.002,
      "step": 22140
    },
    {
      "epoch": 0.6328571428571429,
      "grad_norm": 0.08337046205997467,
      "learning_rate": 3.417857142857143e-05,
      "loss": 0.0018,
      "step": 22150
    },
    {
      "epoch": 0.6331428571428571,
      "grad_norm": 0.02819838561117649,
      "learning_rate": 3.417142857142857e-05,
      "loss": 0.001,
      "step": 22160
    },
    {
      "epoch": 0.6334285714285715,
      "grad_norm": 0.06551705300807953,
      "learning_rate": 3.416428571428571e-05,
      "loss": 0.0023,
      "step": 22170
    },
    {
      "epoch": 0.6337142857142857,
      "grad_norm": 0.3964008688926697,
      "learning_rate": 3.415714285714286e-05,
      "loss": 0.0033,
      "step": 22180
    },
    {
      "epoch": 0.634,
      "grad_norm": 0.035761766135692596,
      "learning_rate": 3.415e-05,
      "loss": 0.0008,
      "step": 22190
    },
    {
      "epoch": 0.6342857142857142,
      "grad_norm": 0.11577693372964859,
      "learning_rate": 3.4142857142857145e-05,
      "loss": 0.0018,
      "step": 22200
    },
    {
      "epoch": 0.6345714285714286,
      "grad_norm": 0.12415234744548798,
      "learning_rate": 3.413571428571429e-05,
      "loss": 0.0018,
      "step": 22210
    },
    {
      "epoch": 0.6348571428571429,
      "grad_norm": 0.24431446194648743,
      "learning_rate": 3.4128571428571435e-05,
      "loss": 0.0015,
      "step": 22220
    },
    {
      "epoch": 0.6351428571428571,
      "grad_norm": 0.0,
      "learning_rate": 3.412142857142857e-05,
      "loss": 0.0014,
      "step": 22230
    },
    {
      "epoch": 0.6354285714285715,
      "grad_norm": 0.04209243506193161,
      "learning_rate": 3.411428571428571e-05,
      "loss": 0.0016,
      "step": 22240
    },
    {
      "epoch": 0.6357142857142857,
      "grad_norm": 0.2212182581424713,
      "learning_rate": 3.410714285714286e-05,
      "loss": 0.0019,
      "step": 22250
    },
    {
      "epoch": 0.636,
      "grad_norm": 0.043829064816236496,
      "learning_rate": 3.41e-05,
      "loss": 0.0012,
      "step": 22260
    },
    {
      "epoch": 0.6362857142857142,
      "grad_norm": 0.0,
      "learning_rate": 3.4092857142857144e-05,
      "loss": 0.0013,
      "step": 22270
    },
    {
      "epoch": 0.6365714285714286,
      "grad_norm": 0.0,
      "learning_rate": 3.4085714285714286e-05,
      "loss": 0.0012,
      "step": 22280
    },
    {
      "epoch": 0.6368571428571429,
      "grad_norm": 0.21654459834098816,
      "learning_rate": 3.4078571428571434e-05,
      "loss": 0.0017,
      "step": 22290
    },
    {
      "epoch": 0.6371428571428571,
      "grad_norm": 0.1643235832452774,
      "learning_rate": 3.407142857142857e-05,
      "loss": 0.0022,
      "step": 22300
    },
    {
      "epoch": 0.6374285714285715,
      "grad_norm": 0.18404071033000946,
      "learning_rate": 3.406428571428572e-05,
      "loss": 0.0023,
      "step": 22310
    },
    {
      "epoch": 0.6377142857142857,
      "grad_norm": 0.09340590238571167,
      "learning_rate": 3.405714285714286e-05,
      "loss": 0.0016,
      "step": 22320
    },
    {
      "epoch": 0.638,
      "grad_norm": 0.0,
      "learning_rate": 3.405e-05,
      "loss": 0.0013,
      "step": 22330
    },
    {
      "epoch": 0.6382857142857142,
      "grad_norm": 0.04029488563537598,
      "learning_rate": 3.404285714285714e-05,
      "loss": 0.0013,
      "step": 22340
    },
    {
      "epoch": 0.6385714285714286,
      "grad_norm": 0.04084442928433418,
      "learning_rate": 3.4035714285714284e-05,
      "loss": 0.0028,
      "step": 22350
    },
    {
      "epoch": 0.6388571428571429,
      "grad_norm": 0.07097344100475311,
      "learning_rate": 3.402857142857143e-05,
      "loss": 0.0008,
      "step": 22360
    },
    {
      "epoch": 0.6391428571428571,
      "grad_norm": 0.0,
      "learning_rate": 3.402142857142857e-05,
      "loss": 0.0025,
      "step": 22370
    },
    {
      "epoch": 0.6394285714285715,
      "grad_norm": 0.226859912276268,
      "learning_rate": 3.4014285714285716e-05,
      "loss": 0.002,
      "step": 22380
    },
    {
      "epoch": 0.6397142857142857,
      "grad_norm": 0.047229062765836716,
      "learning_rate": 3.400714285714286e-05,
      "loss": 0.0011,
      "step": 22390
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.18061146140098572,
      "learning_rate": 3.4000000000000007e-05,
      "loss": 0.0021,
      "step": 22400
    },
    {
      "epoch": 0.6402857142857142,
      "grad_norm": 0.0,
      "learning_rate": 3.399285714285714e-05,
      "loss": 0.0016,
      "step": 22410
    },
    {
      "epoch": 0.6405714285714286,
      "grad_norm": 0.060921669006347656,
      "learning_rate": 3.398571428571429e-05,
      "loss": 0.0015,
      "step": 22420
    },
    {
      "epoch": 0.6408571428571429,
      "grad_norm": 0.13885058462619781,
      "learning_rate": 3.397857142857143e-05,
      "loss": 0.0021,
      "step": 22430
    },
    {
      "epoch": 0.6411428571428571,
      "grad_norm": 0.0,
      "learning_rate": 3.397142857142857e-05,
      "loss": 0.0019,
      "step": 22440
    },
    {
      "epoch": 0.6414285714285715,
      "grad_norm": 0.031153587624430656,
      "learning_rate": 3.3964285714285715e-05,
      "loss": 0.0018,
      "step": 22450
    },
    {
      "epoch": 0.6417142857142857,
      "grad_norm": 0.0,
      "learning_rate": 3.395714285714286e-05,
      "loss": 0.0011,
      "step": 22460
    },
    {
      "epoch": 0.642,
      "grad_norm": 0.02988450415432453,
      "learning_rate": 3.3950000000000005e-05,
      "loss": 0.0017,
      "step": 22470
    },
    {
      "epoch": 0.6422857142857142,
      "grad_norm": 0.19013045728206635,
      "learning_rate": 3.394285714285714e-05,
      "loss": 0.0014,
      "step": 22480
    },
    {
      "epoch": 0.6425714285714286,
      "grad_norm": 0.021125808358192444,
      "learning_rate": 3.393571428571429e-05,
      "loss": 0.0018,
      "step": 22490
    },
    {
      "epoch": 0.6428571428571429,
      "grad_norm": 0.042529065161943436,
      "learning_rate": 3.392857142857143e-05,
      "loss": 0.0003,
      "step": 22500
    },
    {
      "epoch": 0.6431428571428571,
      "grad_norm": 0.12785157561302185,
      "learning_rate": 3.392142857142857e-05,
      "loss": 0.003,
      "step": 22510
    },
    {
      "epoch": 0.6434285714285715,
      "grad_norm": 0.041078295558691025,
      "learning_rate": 3.3914285714285714e-05,
      "loss": 0.0015,
      "step": 22520
    },
    {
      "epoch": 0.6437142857142857,
      "grad_norm": 0.396072119474411,
      "learning_rate": 3.390714285714286e-05,
      "loss": 0.0014,
      "step": 22530
    },
    {
      "epoch": 0.644,
      "grad_norm": 0.11894344538450241,
      "learning_rate": 3.3900000000000004e-05,
      "loss": 0.001,
      "step": 22540
    },
    {
      "epoch": 0.6442857142857142,
      "grad_norm": 0.0,
      "learning_rate": 3.3892857142857146e-05,
      "loss": 0.0015,
      "step": 22550
    },
    {
      "epoch": 0.6445714285714286,
      "grad_norm": 0.08279433101415634,
      "learning_rate": 3.388571428571429e-05,
      "loss": 0.0004,
      "step": 22560
    },
    {
      "epoch": 0.6448571428571429,
      "grad_norm": 0.26580020785331726,
      "learning_rate": 3.387857142857143e-05,
      "loss": 0.0007,
      "step": 22570
    },
    {
      "epoch": 0.6451428571428571,
      "grad_norm": 0.046440500766038895,
      "learning_rate": 3.387142857142857e-05,
      "loss": 0.0014,
      "step": 22580
    },
    {
      "epoch": 0.6454285714285715,
      "grad_norm": 0.0831407904624939,
      "learning_rate": 3.386428571428571e-05,
      "loss": 0.0015,
      "step": 22590
    },
    {
      "epoch": 0.6457142857142857,
      "grad_norm": 0.21618705987930298,
      "learning_rate": 3.385714285714286e-05,
      "loss": 0.0016,
      "step": 22600
    },
    {
      "epoch": 0.646,
      "grad_norm": 0.046218641102313995,
      "learning_rate": 3.385e-05,
      "loss": 0.0014,
      "step": 22610
    },
    {
      "epoch": 0.6462857142857142,
      "grad_norm": 0.25728869438171387,
      "learning_rate": 3.3842857142857145e-05,
      "loss": 0.0021,
      "step": 22620
    },
    {
      "epoch": 0.6465714285714286,
      "grad_norm": 0.08120577037334442,
      "learning_rate": 3.3835714285714286e-05,
      "loss": 0.0017,
      "step": 22630
    },
    {
      "epoch": 0.6468571428571429,
      "grad_norm": 0.13310810923576355,
      "learning_rate": 3.3828571428571435e-05,
      "loss": 0.0008,
      "step": 22640
    },
    {
      "epoch": 0.6471428571428571,
      "grad_norm": 0.03539165481925011,
      "learning_rate": 3.382142857142857e-05,
      "loss": 0.0009,
      "step": 22650
    },
    {
      "epoch": 0.6474285714285715,
      "grad_norm": 0.08762898296117783,
      "learning_rate": 3.381428571428572e-05,
      "loss": 0.0012,
      "step": 22660
    },
    {
      "epoch": 0.6477142857142857,
      "grad_norm": 0.03943588212132454,
      "learning_rate": 3.380714285714286e-05,
      "loss": 0.0022,
      "step": 22670
    },
    {
      "epoch": 0.648,
      "grad_norm": 0.0842694416642189,
      "learning_rate": 3.38e-05,
      "loss": 0.0015,
      "step": 22680
    },
    {
      "epoch": 0.6482857142857142,
      "grad_norm": 0.0,
      "learning_rate": 3.379285714285714e-05,
      "loss": 0.0008,
      "step": 22690
    },
    {
      "epoch": 0.6485714285714286,
      "grad_norm": 0.0,
      "learning_rate": 3.3785714285714285e-05,
      "loss": 0.0009,
      "step": 22700
    },
    {
      "epoch": 0.6488571428571429,
      "grad_norm": 0.08815233409404755,
      "learning_rate": 3.3778571428571434e-05,
      "loss": 0.0022,
      "step": 22710
    },
    {
      "epoch": 0.6491428571428571,
      "grad_norm": 0.0987352728843689,
      "learning_rate": 3.377142857142857e-05,
      "loss": 0.0022,
      "step": 22720
    },
    {
      "epoch": 0.6494285714285715,
      "grad_norm": 0.08417320251464844,
      "learning_rate": 3.376428571428572e-05,
      "loss": 0.0011,
      "step": 22730
    },
    {
      "epoch": 0.6497142857142857,
      "grad_norm": 0.06429820507764816,
      "learning_rate": 3.375714285714286e-05,
      "loss": 0.0015,
      "step": 22740
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.03589784726500511,
      "learning_rate": 3.375000000000001e-05,
      "loss": 0.0017,
      "step": 22750
    },
    {
      "epoch": 0.6502857142857142,
      "grad_norm": 0.15616841614246368,
      "learning_rate": 3.374285714285714e-05,
      "loss": 0.0009,
      "step": 22760
    },
    {
      "epoch": 0.6505714285714286,
      "grad_norm": 0.04317350313067436,
      "learning_rate": 3.3735714285714284e-05,
      "loss": 0.0011,
      "step": 22770
    },
    {
      "epoch": 0.6508571428571429,
      "grad_norm": 0.06716570258140564,
      "learning_rate": 3.372857142857143e-05,
      "loss": 0.0013,
      "step": 22780
    },
    {
      "epoch": 0.6511428571428571,
      "grad_norm": 0.04476281255483627,
      "learning_rate": 3.372142857142857e-05,
      "loss": 0.0018,
      "step": 22790
    },
    {
      "epoch": 0.6514285714285715,
      "grad_norm": 0.027393851429224014,
      "learning_rate": 3.3714285714285716e-05,
      "loss": 0.0022,
      "step": 22800
    },
    {
      "epoch": 0.6517142857142857,
      "grad_norm": 0.04512780159711838,
      "learning_rate": 3.370714285714286e-05,
      "loss": 0.0015,
      "step": 22810
    },
    {
      "epoch": 0.652,
      "grad_norm": 0.0,
      "learning_rate": 3.3700000000000006e-05,
      "loss": 0.0024,
      "step": 22820
    },
    {
      "epoch": 0.6522857142857142,
      "grad_norm": 0.11924010515213013,
      "learning_rate": 3.369285714285714e-05,
      "loss": 0.0018,
      "step": 22830
    },
    {
      "epoch": 0.6525714285714286,
      "grad_norm": 0.04227437451481819,
      "learning_rate": 3.368571428571429e-05,
      "loss": 0.0016,
      "step": 22840
    },
    {
      "epoch": 0.6528571428571428,
      "grad_norm": 0.033662356436252594,
      "learning_rate": 3.367857142857143e-05,
      "loss": 0.0009,
      "step": 22850
    },
    {
      "epoch": 0.6531428571428571,
      "grad_norm": 0.04271484166383743,
      "learning_rate": 3.367142857142857e-05,
      "loss": 0.0025,
      "step": 22860
    },
    {
      "epoch": 0.6534285714285715,
      "grad_norm": 0.08107567578554153,
      "learning_rate": 3.3664285714285715e-05,
      "loss": 0.0017,
      "step": 22870
    },
    {
      "epoch": 0.6537142857142857,
      "grad_norm": 0.1468898206949234,
      "learning_rate": 3.3657142857142856e-05,
      "loss": 0.0027,
      "step": 22880
    },
    {
      "epoch": 0.654,
      "grad_norm": 0.0,
      "learning_rate": 3.3650000000000005e-05,
      "loss": 0.0007,
      "step": 22890
    },
    {
      "epoch": 0.6542857142857142,
      "grad_norm": 0.06001433730125427,
      "learning_rate": 3.364285714285714e-05,
      "loss": 0.0015,
      "step": 22900
    },
    {
      "epoch": 0.6545714285714286,
      "grad_norm": 0.1371019035577774,
      "learning_rate": 3.363571428571429e-05,
      "loss": 0.002,
      "step": 22910
    },
    {
      "epoch": 0.6548571428571428,
      "grad_norm": 0.21926893293857574,
      "learning_rate": 3.362857142857143e-05,
      "loss": 0.0021,
      "step": 22920
    },
    {
      "epoch": 0.6551428571428571,
      "grad_norm": 0.129323348402977,
      "learning_rate": 3.362142857142857e-05,
      "loss": 0.0008,
      "step": 22930
    },
    {
      "epoch": 0.6554285714285715,
      "grad_norm": 0.08537158370018005,
      "learning_rate": 3.361428571428571e-05,
      "loss": 0.0015,
      "step": 22940
    },
    {
      "epoch": 0.6557142857142857,
      "grad_norm": 0.18570618331432343,
      "learning_rate": 3.360714285714286e-05,
      "loss": 0.0016,
      "step": 22950
    },
    {
      "epoch": 0.656,
      "grad_norm": 0.07006173580884933,
      "learning_rate": 3.3600000000000004e-05,
      "loss": 0.0022,
      "step": 22960
    },
    {
      "epoch": 0.6562857142857143,
      "grad_norm": 0.11716001480817795,
      "learning_rate": 3.3592857142857145e-05,
      "loss": 0.0017,
      "step": 22970
    },
    {
      "epoch": 0.6565714285714286,
      "grad_norm": 0.04414881020784378,
      "learning_rate": 3.358571428571429e-05,
      "loss": 0.0013,
      "step": 22980
    },
    {
      "epoch": 0.6568571428571428,
      "grad_norm": 0.07728530466556549,
      "learning_rate": 3.357857142857143e-05,
      "loss": 0.0019,
      "step": 22990
    },
    {
      "epoch": 0.6571428571428571,
      "grad_norm": 0.3056863248348236,
      "learning_rate": 3.357142857142857e-05,
      "loss": 0.0019,
      "step": 23000
    },
    {
      "epoch": 0.6574285714285715,
      "grad_norm": 0.26178762316703796,
      "learning_rate": 3.356428571428571e-05,
      "loss": 0.0018,
      "step": 23010
    },
    {
      "epoch": 0.6577142857142857,
      "grad_norm": 0.045005302876234055,
      "learning_rate": 3.355714285714286e-05,
      "loss": 0.0017,
      "step": 23020
    },
    {
      "epoch": 0.658,
      "grad_norm": 0.057870443910360336,
      "learning_rate": 3.355e-05,
      "loss": 0.0008,
      "step": 23030
    },
    {
      "epoch": 0.6582857142857143,
      "grad_norm": 0.08446202427148819,
      "learning_rate": 3.3542857142857144e-05,
      "loss": 0.0018,
      "step": 23040
    },
    {
      "epoch": 0.6585714285714286,
      "grad_norm": 0.04970859736204147,
      "learning_rate": 3.3535714285714286e-05,
      "loss": 0.0011,
      "step": 23050
    },
    {
      "epoch": 0.6588571428571428,
      "grad_norm": 0.0,
      "learning_rate": 3.3528571428571434e-05,
      "loss": 0.0008,
      "step": 23060
    },
    {
      "epoch": 0.6591428571428571,
      "grad_norm": 0.03481903672218323,
      "learning_rate": 3.352142857142857e-05,
      "loss": 0.0007,
      "step": 23070
    },
    {
      "epoch": 0.6594285714285715,
      "grad_norm": 0.06565602123737335,
      "learning_rate": 3.351428571428572e-05,
      "loss": 0.0007,
      "step": 23080
    },
    {
      "epoch": 0.6597142857142857,
      "grad_norm": 0.0,
      "learning_rate": 3.350714285714286e-05,
      "loss": 0.0013,
      "step": 23090
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.12253989279270172,
      "learning_rate": 3.35e-05,
      "loss": 0.0008,
      "step": 23100
    },
    {
      "epoch": 0.6602857142857143,
      "grad_norm": 0.04224270582199097,
      "learning_rate": 3.349285714285714e-05,
      "loss": 0.0007,
      "step": 23110
    },
    {
      "epoch": 0.6605714285714286,
      "grad_norm": 0.04279003292322159,
      "learning_rate": 3.3485714285714285e-05,
      "loss": 0.0016,
      "step": 23120
    },
    {
      "epoch": 0.6608571428571428,
      "grad_norm": 0.0804806649684906,
      "learning_rate": 3.347857142857143e-05,
      "loss": 0.002,
      "step": 23130
    },
    {
      "epoch": 0.6611428571428571,
      "grad_norm": 0.04731361195445061,
      "learning_rate": 3.3471428571428575e-05,
      "loss": 0.0019,
      "step": 23140
    },
    {
      "epoch": 0.6614285714285715,
      "grad_norm": 0.041771188378334045,
      "learning_rate": 3.3464285714285716e-05,
      "loss": 0.0016,
      "step": 23150
    },
    {
      "epoch": 0.6617142857142857,
      "grad_norm": 0.04835917800664902,
      "learning_rate": 3.345714285714286e-05,
      "loss": 0.0014,
      "step": 23160
    },
    {
      "epoch": 0.662,
      "grad_norm": 0.1431019902229309,
      "learning_rate": 3.345000000000001e-05,
      "loss": 0.0011,
      "step": 23170
    },
    {
      "epoch": 0.6622857142857143,
      "grad_norm": 0.042784109711647034,
      "learning_rate": 3.344285714285714e-05,
      "loss": 0.0019,
      "step": 23180
    },
    {
      "epoch": 0.6625714285714286,
      "grad_norm": 0.0,
      "learning_rate": 3.343571428571429e-05,
      "loss": 0.0016,
      "step": 23190
    },
    {
      "epoch": 0.6628571428571428,
      "grad_norm": 0.03961913660168648,
      "learning_rate": 3.342857142857143e-05,
      "loss": 0.0013,
      "step": 23200
    },
    {
      "epoch": 0.6631428571428571,
      "grad_norm": 0.12149786949157715,
      "learning_rate": 3.3421428571428574e-05,
      "loss": 0.0007,
      "step": 23210
    },
    {
      "epoch": 0.6634285714285715,
      "grad_norm": 0.04481456056237221,
      "learning_rate": 3.3414285714285715e-05,
      "loss": 0.0016,
      "step": 23220
    },
    {
      "epoch": 0.6637142857142857,
      "grad_norm": 0.2277732491493225,
      "learning_rate": 3.340714285714286e-05,
      "loss": 0.0019,
      "step": 23230
    },
    {
      "epoch": 0.664,
      "grad_norm": 0.12202150374650955,
      "learning_rate": 3.3400000000000005e-05,
      "loss": 0.0016,
      "step": 23240
    },
    {
      "epoch": 0.6642857142857143,
      "grad_norm": 0.19276393949985504,
      "learning_rate": 3.339285714285714e-05,
      "loss": 0.0013,
      "step": 23250
    },
    {
      "epoch": 0.6645714285714286,
      "grad_norm": 0.2960992157459259,
      "learning_rate": 3.338571428571429e-05,
      "loss": 0.0019,
      "step": 23260
    },
    {
      "epoch": 0.6648571428571428,
      "grad_norm": 0.27569130063056946,
      "learning_rate": 3.337857142857143e-05,
      "loss": 0.0013,
      "step": 23270
    },
    {
      "epoch": 0.6651428571428571,
      "grad_norm": 0.05822829529643059,
      "learning_rate": 3.337142857142857e-05,
      "loss": 0.0005,
      "step": 23280
    },
    {
      "epoch": 0.6654285714285715,
      "grad_norm": 0.04198719561100006,
      "learning_rate": 3.3364285714285714e-05,
      "loss": 0.0008,
      "step": 23290
    },
    {
      "epoch": 0.6657142857142857,
      "grad_norm": 0.030540265142917633,
      "learning_rate": 3.3357142857142856e-05,
      "loss": 0.0017,
      "step": 23300
    },
    {
      "epoch": 0.666,
      "grad_norm": 0.33049800992012024,
      "learning_rate": 3.3350000000000004e-05,
      "loss": 0.0009,
      "step": 23310
    },
    {
      "epoch": 0.6662857142857143,
      "grad_norm": 0.12902159988880157,
      "learning_rate": 3.334285714285714e-05,
      "loss": 0.0016,
      "step": 23320
    },
    {
      "epoch": 0.6665714285714286,
      "grad_norm": 0.4518388509750366,
      "learning_rate": 3.333571428571429e-05,
      "loss": 0.002,
      "step": 23330
    },
    {
      "epoch": 0.6668571428571428,
      "grad_norm": 0.08367642760276794,
      "learning_rate": 3.332857142857143e-05,
      "loss": 0.001,
      "step": 23340
    },
    {
      "epoch": 0.6671428571428571,
      "grad_norm": 0.08179996907711029,
      "learning_rate": 3.332142857142858e-05,
      "loss": 0.0012,
      "step": 23350
    },
    {
      "epoch": 0.6674285714285715,
      "grad_norm": 0.05745641887187958,
      "learning_rate": 3.331428571428571e-05,
      "loss": 0.0015,
      "step": 23360
    },
    {
      "epoch": 0.6677142857142857,
      "grad_norm": 0.07174941897392273,
      "learning_rate": 3.330714285714286e-05,
      "loss": 0.0011,
      "step": 23370
    },
    {
      "epoch": 0.668,
      "grad_norm": 0.045330341905355453,
      "learning_rate": 3.33e-05,
      "loss": 0.0011,
      "step": 23380
    },
    {
      "epoch": 0.6682857142857143,
      "grad_norm": 0.05306611582636833,
      "learning_rate": 3.3292857142857145e-05,
      "loss": 0.0022,
      "step": 23390
    },
    {
      "epoch": 0.6685714285714286,
      "grad_norm": 0.3874591588973999,
      "learning_rate": 3.3285714285714286e-05,
      "loss": 0.0016,
      "step": 23400
    },
    {
      "epoch": 0.6688571428571428,
      "grad_norm": 0.08606478571891785,
      "learning_rate": 3.327857142857143e-05,
      "loss": 0.0007,
      "step": 23410
    },
    {
      "epoch": 0.6691428571428572,
      "grad_norm": 0.043205320835113525,
      "learning_rate": 3.327142857142858e-05,
      "loss": 0.0035,
      "step": 23420
    },
    {
      "epoch": 0.6694285714285715,
      "grad_norm": 0.15683744847774506,
      "learning_rate": 3.326428571428571e-05,
      "loss": 0.0022,
      "step": 23430
    },
    {
      "epoch": 0.6697142857142857,
      "grad_norm": 0.0,
      "learning_rate": 3.325714285714286e-05,
      "loss": 0.0018,
      "step": 23440
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.09232264012098312,
      "learning_rate": 3.325e-05,
      "loss": 0.0019,
      "step": 23450
    },
    {
      "epoch": 0.6702857142857143,
      "grad_norm": 0.02811076119542122,
      "learning_rate": 3.3242857142857144e-05,
      "loss": 0.0028,
      "step": 23460
    },
    {
      "epoch": 0.6705714285714286,
      "grad_norm": 0.0,
      "learning_rate": 3.3235714285714285e-05,
      "loss": 0.0019,
      "step": 23470
    },
    {
      "epoch": 0.6708571428571428,
      "grad_norm": 0.041257504373788834,
      "learning_rate": 3.3228571428571434e-05,
      "loss": 0.0022,
      "step": 23480
    },
    {
      "epoch": 0.6711428571428572,
      "grad_norm": 0.08859999477863312,
      "learning_rate": 3.3221428571428575e-05,
      "loss": 0.0012,
      "step": 23490
    },
    {
      "epoch": 0.6714285714285714,
      "grad_norm": 0.0,
      "learning_rate": 3.321428571428572e-05,
      "loss": 0.0013,
      "step": 23500
    },
    {
      "epoch": 0.6717142857142857,
      "grad_norm": 0.09385187178850174,
      "learning_rate": 3.320714285714286e-05,
      "loss": 0.0013,
      "step": 23510
    },
    {
      "epoch": 0.672,
      "grad_norm": 0.1595030128955841,
      "learning_rate": 3.32e-05,
      "loss": 0.0029,
      "step": 23520
    },
    {
      "epoch": 0.6722857142857143,
      "grad_norm": 0.041129618883132935,
      "learning_rate": 3.319285714285714e-05,
      "loss": 0.0011,
      "step": 23530
    },
    {
      "epoch": 0.6725714285714286,
      "grad_norm": 0.08751066774129868,
      "learning_rate": 3.3185714285714284e-05,
      "loss": 0.0017,
      "step": 23540
    },
    {
      "epoch": 0.6728571428571428,
      "grad_norm": 0.11668810993432999,
      "learning_rate": 3.317857142857143e-05,
      "loss": 0.0028,
      "step": 23550
    },
    {
      "epoch": 0.6731428571428572,
      "grad_norm": 0.08503410965204239,
      "learning_rate": 3.3171428571428574e-05,
      "loss": 0.003,
      "step": 23560
    },
    {
      "epoch": 0.6734285714285714,
      "grad_norm": 0.12521663308143616,
      "learning_rate": 3.3164285714285716e-05,
      "loss": 0.0013,
      "step": 23570
    },
    {
      "epoch": 0.6737142857142857,
      "grad_norm": 0.1553649604320526,
      "learning_rate": 3.315714285714286e-05,
      "loss": 0.0011,
      "step": 23580
    },
    {
      "epoch": 0.674,
      "grad_norm": 0.04374440759420395,
      "learning_rate": 3.3150000000000006e-05,
      "loss": 0.0017,
      "step": 23590
    },
    {
      "epoch": 0.6742857142857143,
      "grad_norm": 0.0406978465616703,
      "learning_rate": 3.314285714285714e-05,
      "loss": 0.0007,
      "step": 23600
    },
    {
      "epoch": 0.6745714285714286,
      "grad_norm": 0.04654952138662338,
      "learning_rate": 3.313571428571429e-05,
      "loss": 0.0003,
      "step": 23610
    },
    {
      "epoch": 0.6748571428571428,
      "grad_norm": 0.11448875814676285,
      "learning_rate": 3.312857142857143e-05,
      "loss": 0.0018,
      "step": 23620
    },
    {
      "epoch": 0.6751428571428572,
      "grad_norm": 0.0,
      "learning_rate": 3.312142857142857e-05,
      "loss": 0.0007,
      "step": 23630
    },
    {
      "epoch": 0.6754285714285714,
      "grad_norm": 0.09840235114097595,
      "learning_rate": 3.3114285714285715e-05,
      "loss": 0.0015,
      "step": 23640
    },
    {
      "epoch": 0.6757142857142857,
      "grad_norm": 0.11581702530384064,
      "learning_rate": 3.3107142857142856e-05,
      "loss": 0.001,
      "step": 23650
    },
    {
      "epoch": 0.676,
      "grad_norm": 0.17732009291648865,
      "learning_rate": 3.3100000000000005e-05,
      "loss": 0.0013,
      "step": 23660
    },
    {
      "epoch": 0.6762857142857143,
      "grad_norm": 0.0,
      "learning_rate": 3.309285714285714e-05,
      "loss": 0.0008,
      "step": 23670
    },
    {
      "epoch": 0.6765714285714286,
      "grad_norm": 0.0260213240981102,
      "learning_rate": 3.308571428571429e-05,
      "loss": 0.0016,
      "step": 23680
    },
    {
      "epoch": 0.6768571428571428,
      "grad_norm": 0.0,
      "learning_rate": 3.307857142857143e-05,
      "loss": 0.0007,
      "step": 23690
    },
    {
      "epoch": 0.6771428571428572,
      "grad_norm": 0.04095422476530075,
      "learning_rate": 3.307142857142858e-05,
      "loss": 0.0011,
      "step": 23700
    },
    {
      "epoch": 0.6774285714285714,
      "grad_norm": 0.12042940407991409,
      "learning_rate": 3.3064285714285714e-05,
      "loss": 0.0013,
      "step": 23710
    },
    {
      "epoch": 0.6777142857142857,
      "grad_norm": 0.04417307302355766,
      "learning_rate": 3.305714285714286e-05,
      "loss": 0.0014,
      "step": 23720
    },
    {
      "epoch": 0.678,
      "grad_norm": 0.09370959550142288,
      "learning_rate": 3.3050000000000004e-05,
      "loss": 0.0006,
      "step": 23730
    },
    {
      "epoch": 0.6782857142857143,
      "grad_norm": 0.0,
      "learning_rate": 3.304285714285714e-05,
      "loss": 0.001,
      "step": 23740
    },
    {
      "epoch": 0.6785714285714286,
      "grad_norm": 0.048007458448410034,
      "learning_rate": 3.303571428571429e-05,
      "loss": 0.0029,
      "step": 23750
    },
    {
      "epoch": 0.6788571428571428,
      "grad_norm": 0.08776697516441345,
      "learning_rate": 3.302857142857143e-05,
      "loss": 0.0005,
      "step": 23760
    },
    {
      "epoch": 0.6791428571428572,
      "grad_norm": 0.18832992017269135,
      "learning_rate": 3.302142857142858e-05,
      "loss": 0.0016,
      "step": 23770
    },
    {
      "epoch": 0.6794285714285714,
      "grad_norm": 0.07050886005163193,
      "learning_rate": 3.301428571428571e-05,
      "loss": 0.0024,
      "step": 23780
    },
    {
      "epoch": 0.6797142857142857,
      "grad_norm": 0.14265260100364685,
      "learning_rate": 3.300714285714286e-05,
      "loss": 0.002,
      "step": 23790
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.1610838621854782,
      "learning_rate": 3.3e-05,
      "loss": 0.0011,
      "step": 23800
    },
    {
      "epoch": 0.6802857142857143,
      "grad_norm": 0.054046183824539185,
      "learning_rate": 3.2992857142857144e-05,
      "loss": 0.0015,
      "step": 23810
    },
    {
      "epoch": 0.6805714285714286,
      "grad_norm": 0.0,
      "learning_rate": 3.2985714285714286e-05,
      "loss": 0.0006,
      "step": 23820
    },
    {
      "epoch": 0.6808571428571428,
      "grad_norm": 0.0,
      "learning_rate": 3.297857142857143e-05,
      "loss": 0.0006,
      "step": 23830
    },
    {
      "epoch": 0.6811428571428572,
      "grad_norm": 0.04208628460764885,
      "learning_rate": 3.2971428571428576e-05,
      "loss": 0.0013,
      "step": 23840
    },
    {
      "epoch": 0.6814285714285714,
      "grad_norm": 0.04384396970272064,
      "learning_rate": 3.296428571428571e-05,
      "loss": 0.0007,
      "step": 23850
    },
    {
      "epoch": 0.6817142857142857,
      "grad_norm": 0.06278197467327118,
      "learning_rate": 3.295714285714286e-05,
      "loss": 0.002,
      "step": 23860
    },
    {
      "epoch": 0.682,
      "grad_norm": 0.0,
      "learning_rate": 3.295e-05,
      "loss": 0.0014,
      "step": 23870
    },
    {
      "epoch": 0.6822857142857143,
      "grad_norm": 0.020560501143336296,
      "learning_rate": 3.294285714285714e-05,
      "loss": 0.0017,
      "step": 23880
    },
    {
      "epoch": 0.6825714285714286,
      "grad_norm": 0.13238708674907684,
      "learning_rate": 3.2935714285714285e-05,
      "loss": 0.0013,
      "step": 23890
    },
    {
      "epoch": 0.6828571428571428,
      "grad_norm": 0.05431932955980301,
      "learning_rate": 3.292857142857143e-05,
      "loss": 0.0013,
      "step": 23900
    },
    {
      "epoch": 0.6831428571428572,
      "grad_norm": 0.04441920667886734,
      "learning_rate": 3.2921428571428575e-05,
      "loss": 0.0019,
      "step": 23910
    },
    {
      "epoch": 0.6834285714285714,
      "grad_norm": 0.18225891888141632,
      "learning_rate": 3.291428571428572e-05,
      "loss": 0.0014,
      "step": 23920
    },
    {
      "epoch": 0.6837142857142857,
      "grad_norm": 0.2884913980960846,
      "learning_rate": 3.290714285714286e-05,
      "loss": 0.0012,
      "step": 23930
    },
    {
      "epoch": 0.684,
      "grad_norm": 0.042112354189157486,
      "learning_rate": 3.29e-05,
      "loss": 0.0011,
      "step": 23940
    },
    {
      "epoch": 0.6842857142857143,
      "grad_norm": 0.07241960614919662,
      "learning_rate": 3.289285714285714e-05,
      "loss": 0.0021,
      "step": 23950
    },
    {
      "epoch": 0.6845714285714286,
      "grad_norm": 0.24425163865089417,
      "learning_rate": 3.2885714285714284e-05,
      "loss": 0.0022,
      "step": 23960
    },
    {
      "epoch": 0.6848571428571428,
      "grad_norm": 0.0,
      "learning_rate": 3.287857142857143e-05,
      "loss": 0.0021,
      "step": 23970
    },
    {
      "epoch": 0.6851428571428572,
      "grad_norm": 0.0,
      "learning_rate": 3.2871428571428574e-05,
      "loss": 0.0009,
      "step": 23980
    },
    {
      "epoch": 0.6854285714285714,
      "grad_norm": 0.043056804686784744,
      "learning_rate": 3.2864285714285715e-05,
      "loss": 0.0022,
      "step": 23990
    },
    {
      "epoch": 0.6857142857142857,
      "grad_norm": 0.09321770817041397,
      "learning_rate": 3.285714285714286e-05,
      "loss": 0.0013,
      "step": 24000
    },
    {
      "epoch": 0.686,
      "grad_norm": 0.0484640896320343,
      "learning_rate": 3.2850000000000006e-05,
      "loss": 0.0018,
      "step": 24010
    },
    {
      "epoch": 0.6862857142857143,
      "grad_norm": 0.07589181512594223,
      "learning_rate": 3.284285714285714e-05,
      "loss": 0.0015,
      "step": 24020
    },
    {
      "epoch": 0.6865714285714286,
      "grad_norm": 0.399621844291687,
      "learning_rate": 3.283571428571429e-05,
      "loss": 0.0017,
      "step": 24030
    },
    {
      "epoch": 0.6868571428571428,
      "grad_norm": 0.05232662707567215,
      "learning_rate": 3.282857142857143e-05,
      "loss": 0.0023,
      "step": 24040
    },
    {
      "epoch": 0.6871428571428572,
      "grad_norm": 0.23641131818294525,
      "learning_rate": 3.282142857142857e-05,
      "loss": 0.0014,
      "step": 24050
    },
    {
      "epoch": 0.6874285714285714,
      "grad_norm": 0.04858340695500374,
      "learning_rate": 3.2814285714285714e-05,
      "loss": 0.0014,
      "step": 24060
    },
    {
      "epoch": 0.6877142857142857,
      "grad_norm": 0.03130638599395752,
      "learning_rate": 3.2807142857142856e-05,
      "loss": 0.0015,
      "step": 24070
    },
    {
      "epoch": 0.688,
      "grad_norm": 0.23517803847789764,
      "learning_rate": 3.2800000000000004e-05,
      "loss": 0.0011,
      "step": 24080
    },
    {
      "epoch": 0.6882857142857143,
      "grad_norm": 0.02261984720826149,
      "learning_rate": 3.279285714285714e-05,
      "loss": 0.0024,
      "step": 24090
    },
    {
      "epoch": 0.6885714285714286,
      "grad_norm": 0.032675813883543015,
      "learning_rate": 3.278571428571429e-05,
      "loss": 0.0012,
      "step": 24100
    },
    {
      "epoch": 0.6888571428571428,
      "grad_norm": 0.0316605418920517,
      "learning_rate": 3.277857142857143e-05,
      "loss": 0.0005,
      "step": 24110
    },
    {
      "epoch": 0.6891428571428572,
      "grad_norm": 0.046285055577754974,
      "learning_rate": 3.277142857142858e-05,
      "loss": 0.0014,
      "step": 24120
    },
    {
      "epoch": 0.6894285714285714,
      "grad_norm": 0.0479859858751297,
      "learning_rate": 3.276428571428571e-05,
      "loss": 0.0017,
      "step": 24130
    },
    {
      "epoch": 0.6897142857142857,
      "grad_norm": 0.0,
      "learning_rate": 3.275714285714286e-05,
      "loss": 0.002,
      "step": 24140
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.0,
      "learning_rate": 3.275e-05,
      "loss": 0.0016,
      "step": 24150
    },
    {
      "epoch": 0.6902857142857143,
      "grad_norm": 0.0,
      "learning_rate": 3.2742857142857145e-05,
      "loss": 0.0011,
      "step": 24160
    },
    {
      "epoch": 0.6905714285714286,
      "grad_norm": 0.04053041711449623,
      "learning_rate": 3.273571428571429e-05,
      "loss": 0.0012,
      "step": 24170
    },
    {
      "epoch": 0.6908571428571428,
      "grad_norm": 0.0,
      "learning_rate": 3.272857142857143e-05,
      "loss": 0.0016,
      "step": 24180
    },
    {
      "epoch": 0.6911428571428572,
      "grad_norm": 0.04053626209497452,
      "learning_rate": 3.272142857142858e-05,
      "loss": 0.0012,
      "step": 24190
    },
    {
      "epoch": 0.6914285714285714,
      "grad_norm": 0.08397452533245087,
      "learning_rate": 3.271428571428571e-05,
      "loss": 0.0011,
      "step": 24200
    },
    {
      "epoch": 0.6917142857142857,
      "grad_norm": 0.1353151947259903,
      "learning_rate": 3.270714285714286e-05,
      "loss": 0.001,
      "step": 24210
    },
    {
      "epoch": 0.692,
      "grad_norm": 0.07686245441436768,
      "learning_rate": 3.27e-05,
      "loss": 0.0014,
      "step": 24220
    },
    {
      "epoch": 0.6922857142857143,
      "grad_norm": 0.0,
      "learning_rate": 3.2692857142857144e-05,
      "loss": 0.0008,
      "step": 24230
    },
    {
      "epoch": 0.6925714285714286,
      "grad_norm": 0.0993901938199997,
      "learning_rate": 3.2685714285714285e-05,
      "loss": 0.0012,
      "step": 24240
    },
    {
      "epoch": 0.6928571428571428,
      "grad_norm": 0.06279543787240982,
      "learning_rate": 3.2678571428571434e-05,
      "loss": 0.0014,
      "step": 24250
    },
    {
      "epoch": 0.6931428571428572,
      "grad_norm": 0.12691757082939148,
      "learning_rate": 3.2671428571428576e-05,
      "loss": 0.0015,
      "step": 24260
    },
    {
      "epoch": 0.6934285714285714,
      "grad_norm": 0.20557749271392822,
      "learning_rate": 3.266428571428571e-05,
      "loss": 0.0023,
      "step": 24270
    },
    {
      "epoch": 0.6937142857142857,
      "grad_norm": 0.042451802641153336,
      "learning_rate": 3.265714285714286e-05,
      "loss": 0.002,
      "step": 24280
    },
    {
      "epoch": 0.694,
      "grad_norm": 0.04628313332796097,
      "learning_rate": 3.265e-05,
      "loss": 0.0012,
      "step": 24290
    },
    {
      "epoch": 0.6942857142857143,
      "grad_norm": 0.08914081007242203,
      "learning_rate": 3.264285714285714e-05,
      "loss": 0.0016,
      "step": 24300
    },
    {
      "epoch": 0.6945714285714286,
      "grad_norm": 0.31445813179016113,
      "learning_rate": 3.2635714285714284e-05,
      "loss": 0.0014,
      "step": 24310
    },
    {
      "epoch": 0.6948571428571428,
      "grad_norm": 0.251748263835907,
      "learning_rate": 3.262857142857143e-05,
      "loss": 0.0025,
      "step": 24320
    },
    {
      "epoch": 0.6951428571428572,
      "grad_norm": 0.30613869428634644,
      "learning_rate": 3.2621428571428574e-05,
      "loss": 0.0009,
      "step": 24330
    },
    {
      "epoch": 0.6954285714285714,
      "grad_norm": 0.14568744599819183,
      "learning_rate": 3.2614285714285716e-05,
      "loss": 0.001,
      "step": 24340
    },
    {
      "epoch": 0.6957142857142857,
      "grad_norm": 0.2192537635564804,
      "learning_rate": 3.260714285714286e-05,
      "loss": 0.0016,
      "step": 24350
    },
    {
      "epoch": 0.696,
      "grad_norm": 0.04268726706504822,
      "learning_rate": 3.26e-05,
      "loss": 0.001,
      "step": 24360
    },
    {
      "epoch": 0.6962857142857143,
      "grad_norm": 0.09825685620307922,
      "learning_rate": 3.259285714285714e-05,
      "loss": 0.0024,
      "step": 24370
    },
    {
      "epoch": 0.6965714285714286,
      "grad_norm": 0.07851076871156693,
      "learning_rate": 3.258571428571428e-05,
      "loss": 0.0014,
      "step": 24380
    },
    {
      "epoch": 0.6968571428571428,
      "grad_norm": 0.05205816775560379,
      "learning_rate": 3.257857142857143e-05,
      "loss": 0.0017,
      "step": 24390
    },
    {
      "epoch": 0.6971428571428572,
      "grad_norm": 0.04163871333003044,
      "learning_rate": 3.257142857142857e-05,
      "loss": 0.0015,
      "step": 24400
    },
    {
      "epoch": 0.6974285714285714,
      "grad_norm": 0.07565157860517502,
      "learning_rate": 3.2564285714285715e-05,
      "loss": 0.0008,
      "step": 24410
    },
    {
      "epoch": 0.6977142857142857,
      "grad_norm": 0.0,
      "learning_rate": 3.255714285714286e-05,
      "loss": 0.0014,
      "step": 24420
    },
    {
      "epoch": 0.698,
      "grad_norm": 0.1503915935754776,
      "learning_rate": 3.2550000000000005e-05,
      "loss": 0.0015,
      "step": 24430
    },
    {
      "epoch": 0.6982857142857143,
      "grad_norm": 0.0,
      "learning_rate": 3.254285714285715e-05,
      "loss": 0.0015,
      "step": 24440
    },
    {
      "epoch": 0.6985714285714286,
      "grad_norm": 0.027138205245137215,
      "learning_rate": 3.253571428571429e-05,
      "loss": 0.0015,
      "step": 24450
    },
    {
      "epoch": 0.6988571428571428,
      "grad_norm": 0.0,
      "learning_rate": 3.252857142857143e-05,
      "loss": 0.0005,
      "step": 24460
    },
    {
      "epoch": 0.6991428571428572,
      "grad_norm": 0.0,
      "learning_rate": 3.252142857142857e-05,
      "loss": 0.0015,
      "step": 24470
    },
    {
      "epoch": 0.6994285714285714,
      "grad_norm": 0.057252127677202225,
      "learning_rate": 3.2514285714285714e-05,
      "loss": 0.0019,
      "step": 24480
    },
    {
      "epoch": 0.6997142857142857,
      "grad_norm": 0.08016350865364075,
      "learning_rate": 3.2507142857142855e-05,
      "loss": 0.0016,
      "step": 24490
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.08326035737991333,
      "learning_rate": 3.2500000000000004e-05,
      "loss": 0.0015,
      "step": 24500
    },
    {
      "epoch": 0.7002857142857143,
      "grad_norm": 0.07123905420303345,
      "learning_rate": 3.2492857142857146e-05,
      "loss": 0.0018,
      "step": 24510
    },
    {
      "epoch": 0.7005714285714286,
      "grad_norm": 0.30397430062294006,
      "learning_rate": 3.248571428571429e-05,
      "loss": 0.0005,
      "step": 24520
    },
    {
      "epoch": 0.7008571428571428,
      "grad_norm": 0.0,
      "learning_rate": 3.247857142857143e-05,
      "loss": 0.0014,
      "step": 24530
    },
    {
      "epoch": 0.7011428571428572,
      "grad_norm": 0.0,
      "learning_rate": 3.247142857142858e-05,
      "loss": 0.0017,
      "step": 24540
    },
    {
      "epoch": 0.7014285714285714,
      "grad_norm": 0.24260374903678894,
      "learning_rate": 3.246428571428571e-05,
      "loss": 0.0015,
      "step": 24550
    },
    {
      "epoch": 0.7017142857142857,
      "grad_norm": 0.04166960343718529,
      "learning_rate": 3.245714285714286e-05,
      "loss": 0.0012,
      "step": 24560
    },
    {
      "epoch": 0.702,
      "grad_norm": 0.07468166202306747,
      "learning_rate": 3.245e-05,
      "loss": 0.0012,
      "step": 24570
    },
    {
      "epoch": 0.7022857142857143,
      "grad_norm": 0.11353787779808044,
      "learning_rate": 3.2442857142857144e-05,
      "loss": 0.0023,
      "step": 24580
    },
    {
      "epoch": 0.7025714285714286,
      "grad_norm": 0.19449009001255035,
      "learning_rate": 3.2435714285714286e-05,
      "loss": 0.0022,
      "step": 24590
    },
    {
      "epoch": 0.7028571428571428,
      "grad_norm": 0.0520789660513401,
      "learning_rate": 3.242857142857143e-05,
      "loss": 0.0009,
      "step": 24600
    },
    {
      "epoch": 0.7031428571428572,
      "grad_norm": 0.2988669276237488,
      "learning_rate": 3.2421428571428576e-05,
      "loss": 0.0011,
      "step": 24610
    },
    {
      "epoch": 0.7034285714285714,
      "grad_norm": 0.0,
      "learning_rate": 3.241428571428571e-05,
      "loss": 0.0014,
      "step": 24620
    },
    {
      "epoch": 0.7037142857142857,
      "grad_norm": 0.10086945444345474,
      "learning_rate": 3.240714285714286e-05,
      "loss": 0.0023,
      "step": 24630
    },
    {
      "epoch": 0.704,
      "grad_norm": 0.0,
      "learning_rate": 3.24e-05,
      "loss": 0.0023,
      "step": 24640
    },
    {
      "epoch": 0.7042857142857143,
      "grad_norm": 0.0,
      "learning_rate": 3.239285714285715e-05,
      "loss": 0.0014,
      "step": 24650
    },
    {
      "epoch": 0.7045714285714286,
      "grad_norm": 0.07755736261606216,
      "learning_rate": 3.2385714285714285e-05,
      "loss": 0.0012,
      "step": 24660
    },
    {
      "epoch": 0.7048571428571428,
      "grad_norm": 0.050750378519296646,
      "learning_rate": 3.2378571428571433e-05,
      "loss": 0.0021,
      "step": 24670
    },
    {
      "epoch": 0.7051428571428572,
      "grad_norm": 0.11735694110393524,
      "learning_rate": 3.2371428571428575e-05,
      "loss": 0.0016,
      "step": 24680
    },
    {
      "epoch": 0.7054285714285714,
      "grad_norm": 0.30802762508392334,
      "learning_rate": 3.236428571428572e-05,
      "loss": 0.0013,
      "step": 24690
    },
    {
      "epoch": 0.7057142857142857,
      "grad_norm": 0.042943648993968964,
      "learning_rate": 3.235714285714286e-05,
      "loss": 0.0012,
      "step": 24700
    },
    {
      "epoch": 0.706,
      "grad_norm": 0.18145732581615448,
      "learning_rate": 3.235e-05,
      "loss": 0.0016,
      "step": 24710
    },
    {
      "epoch": 0.7062857142857143,
      "grad_norm": 0.44308802485466003,
      "learning_rate": 3.234285714285715e-05,
      "loss": 0.0012,
      "step": 24720
    },
    {
      "epoch": 0.7065714285714285,
      "grad_norm": 0.041211389005184174,
      "learning_rate": 3.2335714285714284e-05,
      "loss": 0.0019,
      "step": 24730
    },
    {
      "epoch": 0.7068571428571429,
      "grad_norm": 0.0,
      "learning_rate": 3.232857142857143e-05,
      "loss": 0.0022,
      "step": 24740
    },
    {
      "epoch": 0.7071428571428572,
      "grad_norm": 0.1199454739689827,
      "learning_rate": 3.2321428571428574e-05,
      "loss": 0.0012,
      "step": 24750
    },
    {
      "epoch": 0.7074285714285714,
      "grad_norm": 0.08590678125619888,
      "learning_rate": 3.2314285714285716e-05,
      "loss": 0.0026,
      "step": 24760
    },
    {
      "epoch": 0.7077142857142857,
      "grad_norm": 0.04331644997000694,
      "learning_rate": 3.230714285714286e-05,
      "loss": 0.0022,
      "step": 24770
    },
    {
      "epoch": 0.708,
      "grad_norm": 0.24351246654987335,
      "learning_rate": 3.2300000000000006e-05,
      "loss": 0.0015,
      "step": 24780
    },
    {
      "epoch": 0.7082857142857143,
      "grad_norm": 0.04841787740588188,
      "learning_rate": 3.229285714285715e-05,
      "loss": 0.0019,
      "step": 24790
    },
    {
      "epoch": 0.7085714285714285,
      "grad_norm": 0.0,
      "learning_rate": 3.228571428571428e-05,
      "loss": 0.0008,
      "step": 24800
    },
    {
      "epoch": 0.7088571428571429,
      "grad_norm": 0.04314934089779854,
      "learning_rate": 3.227857142857143e-05,
      "loss": 0.0012,
      "step": 24810
    },
    {
      "epoch": 0.7091428571428572,
      "grad_norm": 0.0868869498372078,
      "learning_rate": 3.227142857142857e-05,
      "loss": 0.0012,
      "step": 24820
    },
    {
      "epoch": 0.7094285714285714,
      "grad_norm": 0.04516015574336052,
      "learning_rate": 3.2264285714285714e-05,
      "loss": 0.0011,
      "step": 24830
    },
    {
      "epoch": 0.7097142857142857,
      "grad_norm": 0.0,
      "learning_rate": 3.2257142857142856e-05,
      "loss": 0.0008,
      "step": 24840
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.09786331653594971,
      "learning_rate": 3.2250000000000005e-05,
      "loss": 0.0014,
      "step": 24850
    },
    {
      "epoch": 0.7102857142857143,
      "grad_norm": 0.04008176922798157,
      "learning_rate": 3.2242857142857146e-05,
      "loss": 0.0015,
      "step": 24860
    },
    {
      "epoch": 0.7105714285714285,
      "grad_norm": 0.0,
      "learning_rate": 3.223571428571429e-05,
      "loss": 0.0011,
      "step": 24870
    },
    {
      "epoch": 0.7108571428571429,
      "grad_norm": 0.043071188032627106,
      "learning_rate": 3.222857142857143e-05,
      "loss": 0.0017,
      "step": 24880
    },
    {
      "epoch": 0.7111428571428572,
      "grad_norm": 0.052436940371990204,
      "learning_rate": 3.222142857142857e-05,
      "loss": 0.0013,
      "step": 24890
    },
    {
      "epoch": 0.7114285714285714,
      "grad_norm": 0.054145924746990204,
      "learning_rate": 3.221428571428571e-05,
      "loss": 0.0024,
      "step": 24900
    },
    {
      "epoch": 0.7117142857142857,
      "grad_norm": 0.32566961646080017,
      "learning_rate": 3.2207142857142855e-05,
      "loss": 0.0027,
      "step": 24910
    },
    {
      "epoch": 0.712,
      "grad_norm": 0.04810648411512375,
      "learning_rate": 3.2200000000000003e-05,
      "loss": 0.0016,
      "step": 24920
    },
    {
      "epoch": 0.7122857142857143,
      "grad_norm": 0.0822894275188446,
      "learning_rate": 3.2192857142857145e-05,
      "loss": 0.0019,
      "step": 24930
    },
    {
      "epoch": 0.7125714285714285,
      "grad_norm": 0.21417957544326782,
      "learning_rate": 3.218571428571429e-05,
      "loss": 0.002,
      "step": 24940
    },
    {
      "epoch": 0.7128571428571429,
      "grad_norm": 0.1810564398765564,
      "learning_rate": 3.217857142857143e-05,
      "loss": 0.0006,
      "step": 24950
    },
    {
      "epoch": 0.7131428571428572,
      "grad_norm": 0.04669693484902382,
      "learning_rate": 3.217142857142858e-05,
      "loss": 0.0018,
      "step": 24960
    },
    {
      "epoch": 0.7134285714285714,
      "grad_norm": 0.1210915595293045,
      "learning_rate": 3.216428571428571e-05,
      "loss": 0.0013,
      "step": 24970
    },
    {
      "epoch": 0.7137142857142857,
      "grad_norm": 0.0,
      "learning_rate": 3.215714285714286e-05,
      "loss": 0.002,
      "step": 24980
    },
    {
      "epoch": 0.714,
      "grad_norm": 0.12341564148664474,
      "learning_rate": 3.215e-05,
      "loss": 0.0021,
      "step": 24990
    },
    {
      "epoch": 0.7142857142857143,
      "grad_norm": 0.0,
      "learning_rate": 3.2142857142857144e-05,
      "loss": 0.0024,
      "step": 25000
    },
    {
      "epoch": 0.7145714285714285,
      "grad_norm": 0.2639305591583252,
      "learning_rate": 3.2135714285714286e-05,
      "loss": 0.0023,
      "step": 25010
    },
    {
      "epoch": 0.7148571428571429,
      "grad_norm": 0.1320551335811615,
      "learning_rate": 3.212857142857143e-05,
      "loss": 0.0011,
      "step": 25020
    },
    {
      "epoch": 0.7151428571428572,
      "grad_norm": 0.30119678378105164,
      "learning_rate": 3.2121428571428576e-05,
      "loss": 0.0017,
      "step": 25030
    },
    {
      "epoch": 0.7154285714285714,
      "grad_norm": 0.0,
      "learning_rate": 3.211428571428571e-05,
      "loss": 0.0009,
      "step": 25040
    },
    {
      "epoch": 0.7157142857142857,
      "grad_norm": 0.05320487543940544,
      "learning_rate": 3.210714285714286e-05,
      "loss": 0.0017,
      "step": 25050
    },
    {
      "epoch": 0.716,
      "grad_norm": 0.2427883744239807,
      "learning_rate": 3.21e-05,
      "loss": 0.0014,
      "step": 25060
    },
    {
      "epoch": 0.7162857142857143,
      "grad_norm": 0.07748916000127792,
      "learning_rate": 3.209285714285715e-05,
      "loss": 0.0024,
      "step": 25070
    },
    {
      "epoch": 0.7165714285714285,
      "grad_norm": 0.049944039434194565,
      "learning_rate": 3.2085714285714284e-05,
      "loss": 0.0013,
      "step": 25080
    },
    {
      "epoch": 0.7168571428571429,
      "grad_norm": 0.0,
      "learning_rate": 3.207857142857143e-05,
      "loss": 0.0018,
      "step": 25090
    },
    {
      "epoch": 0.7171428571428572,
      "grad_norm": 0.0,
      "learning_rate": 3.2071428571428575e-05,
      "loss": 0.0017,
      "step": 25100
    },
    {
      "epoch": 0.7174285714285714,
      "grad_norm": 0.12123395502567291,
      "learning_rate": 3.2064285714285716e-05,
      "loss": 0.0016,
      "step": 25110
    },
    {
      "epoch": 0.7177142857142857,
      "grad_norm": 0.0,
      "learning_rate": 3.205714285714286e-05,
      "loss": 0.0021,
      "step": 25120
    },
    {
      "epoch": 0.718,
      "grad_norm": 0.22308073937892914,
      "learning_rate": 3.205e-05,
      "loss": 0.002,
      "step": 25130
    },
    {
      "epoch": 0.7182857142857143,
      "grad_norm": 0.03773660212755203,
      "learning_rate": 3.204285714285715e-05,
      "loss": 0.002,
      "step": 25140
    },
    {
      "epoch": 0.7185714285714285,
      "grad_norm": 0.03244973346590996,
      "learning_rate": 3.203571428571428e-05,
      "loss": 0.0013,
      "step": 25150
    },
    {
      "epoch": 0.7188571428571429,
      "grad_norm": 0.05335446819663048,
      "learning_rate": 3.202857142857143e-05,
      "loss": 0.0011,
      "step": 25160
    },
    {
      "epoch": 0.7191428571428572,
      "grad_norm": 0.06357815116643906,
      "learning_rate": 3.2021428571428573e-05,
      "loss": 0.0021,
      "step": 25170
    },
    {
      "epoch": 0.7194285714285714,
      "grad_norm": 0.04996214807033539,
      "learning_rate": 3.2014285714285715e-05,
      "loss": 0.0025,
      "step": 25180
    },
    {
      "epoch": 0.7197142857142858,
      "grad_norm": 0.044923942536115646,
      "learning_rate": 3.200714285714286e-05,
      "loss": 0.0019,
      "step": 25190
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.047839246690273285,
      "learning_rate": 3.2000000000000005e-05,
      "loss": 0.0017,
      "step": 25200
    },
    {
      "epoch": 0.7202857142857143,
      "grad_norm": 0.09669917076826096,
      "learning_rate": 3.199285714285715e-05,
      "loss": 0.0027,
      "step": 25210
    },
    {
      "epoch": 0.7205714285714285,
      "grad_norm": 0.0,
      "learning_rate": 3.198571428571429e-05,
      "loss": 0.0019,
      "step": 25220
    },
    {
      "epoch": 0.7208571428571429,
      "grad_norm": 0.03900405392050743,
      "learning_rate": 3.197857142857143e-05,
      "loss": 0.0011,
      "step": 25230
    },
    {
      "epoch": 0.7211428571428572,
      "grad_norm": 0.12995880842208862,
      "learning_rate": 3.197142857142857e-05,
      "loss": 0.0018,
      "step": 25240
    },
    {
      "epoch": 0.7214285714285714,
      "grad_norm": 0.2331758588552475,
      "learning_rate": 3.1964285714285714e-05,
      "loss": 0.0016,
      "step": 25250
    },
    {
      "epoch": 0.7217142857142858,
      "grad_norm": 0.07215566188097,
      "learning_rate": 3.1957142857142856e-05,
      "loss": 0.0014,
      "step": 25260
    },
    {
      "epoch": 0.722,
      "grad_norm": 0.054971788078546524,
      "learning_rate": 3.1950000000000004e-05,
      "loss": 0.0009,
      "step": 25270
    },
    {
      "epoch": 0.7222857142857143,
      "grad_norm": 0.0,
      "learning_rate": 3.1942857142857146e-05,
      "loss": 0.0011,
      "step": 25280
    },
    {
      "epoch": 0.7225714285714285,
      "grad_norm": 0.04238184168934822,
      "learning_rate": 3.193571428571429e-05,
      "loss": 0.0009,
      "step": 25290
    },
    {
      "epoch": 0.7228571428571429,
      "grad_norm": 0.04664701595902443,
      "learning_rate": 3.192857142857143e-05,
      "loss": 0.0007,
      "step": 25300
    },
    {
      "epoch": 0.7231428571428572,
      "grad_norm": 0.09400879591703415,
      "learning_rate": 3.192142857142857e-05,
      "loss": 0.0014,
      "step": 25310
    },
    {
      "epoch": 0.7234285714285714,
      "grad_norm": 0.0,
      "learning_rate": 3.191428571428571e-05,
      "loss": 0.0012,
      "step": 25320
    },
    {
      "epoch": 0.7237142857142858,
      "grad_norm": 0.0,
      "learning_rate": 3.1907142857142854e-05,
      "loss": 0.0015,
      "step": 25330
    },
    {
      "epoch": 0.724,
      "grad_norm": 0.11071470379829407,
      "learning_rate": 3.19e-05,
      "loss": 0.0016,
      "step": 25340
    },
    {
      "epoch": 0.7242857142857143,
      "grad_norm": 0.0,
      "learning_rate": 3.1892857142857145e-05,
      "loss": 0.0013,
      "step": 25350
    },
    {
      "epoch": 0.7245714285714285,
      "grad_norm": 0.28544723987579346,
      "learning_rate": 3.1885714285714286e-05,
      "loss": 0.0013,
      "step": 25360
    },
    {
      "epoch": 0.7248571428571429,
      "grad_norm": 0.11058841645717621,
      "learning_rate": 3.187857142857143e-05,
      "loss": 0.0014,
      "step": 25370
    },
    {
      "epoch": 0.7251428571428571,
      "grad_norm": 0.11084257811307907,
      "learning_rate": 3.1871428571428577e-05,
      "loss": 0.0015,
      "step": 25380
    },
    {
      "epoch": 0.7254285714285714,
      "grad_norm": 0.08594821393489838,
      "learning_rate": 3.186428571428571e-05,
      "loss": 0.0026,
      "step": 25390
    },
    {
      "epoch": 0.7257142857142858,
      "grad_norm": 0.07930870354175568,
      "learning_rate": 3.185714285714286e-05,
      "loss": 0.0017,
      "step": 25400
    },
    {
      "epoch": 0.726,
      "grad_norm": 0.09542100131511688,
      "learning_rate": 3.185e-05,
      "loss": 0.0018,
      "step": 25410
    },
    {
      "epoch": 0.7262857142857143,
      "grad_norm": 0.08705759048461914,
      "learning_rate": 3.1842857142857143e-05,
      "loss": 0.0013,
      "step": 25420
    },
    {
      "epoch": 0.7265714285714285,
      "grad_norm": 0.252441942691803,
      "learning_rate": 3.1835714285714285e-05,
      "loss": 0.0015,
      "step": 25430
    },
    {
      "epoch": 0.7268571428571429,
      "grad_norm": 0.08321350067853928,
      "learning_rate": 3.182857142857143e-05,
      "loss": 0.0015,
      "step": 25440
    },
    {
      "epoch": 0.7271428571428571,
      "grad_norm": 0.04133662208914757,
      "learning_rate": 3.1821428571428575e-05,
      "loss": 0.0012,
      "step": 25450
    },
    {
      "epoch": 0.7274285714285714,
      "grad_norm": 0.0,
      "learning_rate": 3.181428571428571e-05,
      "loss": 0.0017,
      "step": 25460
    },
    {
      "epoch": 0.7277142857142858,
      "grad_norm": 0.03200768679380417,
      "learning_rate": 3.180714285714286e-05,
      "loss": 0.002,
      "step": 25470
    },
    {
      "epoch": 0.728,
      "grad_norm": 0.1342526078224182,
      "learning_rate": 3.18e-05,
      "loss": 0.0005,
      "step": 25480
    },
    {
      "epoch": 0.7282857142857143,
      "grad_norm": 0.03678140044212341,
      "learning_rate": 3.179285714285715e-05,
      "loss": 0.0012,
      "step": 25490
    },
    {
      "epoch": 0.7285714285714285,
      "grad_norm": 0.06107300519943237,
      "learning_rate": 3.1785714285714284e-05,
      "loss": 0.001,
      "step": 25500
    },
    {
      "epoch": 0.7288571428571429,
      "grad_norm": 0.1689036637544632,
      "learning_rate": 3.177857142857143e-05,
      "loss": 0.0008,
      "step": 25510
    },
    {
      "epoch": 0.7291428571428571,
      "grad_norm": 0.3034670352935791,
      "learning_rate": 3.1771428571428574e-05,
      "loss": 0.0014,
      "step": 25520
    },
    {
      "epoch": 0.7294285714285714,
      "grad_norm": 0.08127147704362869,
      "learning_rate": 3.1764285714285716e-05,
      "loss": 0.0018,
      "step": 25530
    },
    {
      "epoch": 0.7297142857142858,
      "grad_norm": 0.02932976931333542,
      "learning_rate": 3.175714285714286e-05,
      "loss": 0.0017,
      "step": 25540
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.023839866742491722,
      "learning_rate": 3.175e-05,
      "loss": 0.001,
      "step": 25550
    },
    {
      "epoch": 0.7302857142857143,
      "grad_norm": 0.0,
      "learning_rate": 3.174285714285715e-05,
      "loss": 0.0009,
      "step": 25560
    },
    {
      "epoch": 0.7305714285714285,
      "grad_norm": 0.13223065435886383,
      "learning_rate": 3.173571428571428e-05,
      "loss": 0.0019,
      "step": 25570
    },
    {
      "epoch": 0.7308571428571429,
      "grad_norm": 0.09779772907495499,
      "learning_rate": 3.172857142857143e-05,
      "loss": 0.0018,
      "step": 25580
    },
    {
      "epoch": 0.7311428571428571,
      "grad_norm": 0.0,
      "learning_rate": 3.172142857142857e-05,
      "loss": 0.0017,
      "step": 25590
    },
    {
      "epoch": 0.7314285714285714,
      "grad_norm": 0.13017098605632782,
      "learning_rate": 3.1714285714285715e-05,
      "loss": 0.0008,
      "step": 25600
    },
    {
      "epoch": 0.7317142857142858,
      "grad_norm": 0.04500875249505043,
      "learning_rate": 3.1707142857142856e-05,
      "loss": 0.001,
      "step": 25610
    },
    {
      "epoch": 0.732,
      "grad_norm": 0.1926959604024887,
      "learning_rate": 3.1700000000000005e-05,
      "loss": 0.0016,
      "step": 25620
    },
    {
      "epoch": 0.7322857142857143,
      "grad_norm": 0.16730140149593353,
      "learning_rate": 3.1692857142857147e-05,
      "loss": 0.0015,
      "step": 25630
    },
    {
      "epoch": 0.7325714285714285,
      "grad_norm": 0.04560720548033714,
      "learning_rate": 3.168571428571429e-05,
      "loss": 0.0009,
      "step": 25640
    },
    {
      "epoch": 0.7328571428571429,
      "grad_norm": 0.13938093185424805,
      "learning_rate": 3.167857142857143e-05,
      "loss": 0.0037,
      "step": 25650
    },
    {
      "epoch": 0.7331428571428571,
      "grad_norm": 0.18105532228946686,
      "learning_rate": 3.167142857142857e-05,
      "loss": 0.0018,
      "step": 25660
    },
    {
      "epoch": 0.7334285714285714,
      "grad_norm": 0.03389536961913109,
      "learning_rate": 3.166428571428572e-05,
      "loss": 0.0005,
      "step": 25670
    },
    {
      "epoch": 0.7337142857142858,
      "grad_norm": 0.0,
      "learning_rate": 3.1657142857142855e-05,
      "loss": 0.0014,
      "step": 25680
    },
    {
      "epoch": 0.734,
      "grad_norm": 0.039613429456949234,
      "learning_rate": 3.1650000000000004e-05,
      "loss": 0.0012,
      "step": 25690
    },
    {
      "epoch": 0.7342857142857143,
      "grad_norm": 0.048672907054424286,
      "learning_rate": 3.1642857142857145e-05,
      "loss": 0.0017,
      "step": 25700
    },
    {
      "epoch": 0.7345714285714285,
      "grad_norm": 0.04782022908329964,
      "learning_rate": 3.163571428571429e-05,
      "loss": 0.0018,
      "step": 25710
    },
    {
      "epoch": 0.7348571428571429,
      "grad_norm": 0.06036858633160591,
      "learning_rate": 3.162857142857143e-05,
      "loss": 0.0015,
      "step": 25720
    },
    {
      "epoch": 0.7351428571428571,
      "grad_norm": 0.032645128667354584,
      "learning_rate": 3.162142857142858e-05,
      "loss": 0.0015,
      "step": 25730
    },
    {
      "epoch": 0.7354285714285714,
      "grad_norm": 0.0,
      "learning_rate": 3.161428571428572e-05,
      "loss": 0.0013,
      "step": 25740
    },
    {
      "epoch": 0.7357142857142858,
      "grad_norm": 0.16041624546051025,
      "learning_rate": 3.160714285714286e-05,
      "loss": 0.0015,
      "step": 25750
    },
    {
      "epoch": 0.736,
      "grad_norm": 0.24691860377788544,
      "learning_rate": 3.16e-05,
      "loss": 0.0015,
      "step": 25760
    },
    {
      "epoch": 0.7362857142857143,
      "grad_norm": 0.0,
      "learning_rate": 3.1592857142857144e-05,
      "loss": 0.0015,
      "step": 25770
    },
    {
      "epoch": 0.7365714285714285,
      "grad_norm": 0.03286649286746979,
      "learning_rate": 3.1585714285714286e-05,
      "loss": 0.0018,
      "step": 25780
    },
    {
      "epoch": 0.7368571428571429,
      "grad_norm": 0.044813916087150574,
      "learning_rate": 3.157857142857143e-05,
      "loss": 0.0031,
      "step": 25790
    },
    {
      "epoch": 0.7371428571428571,
      "grad_norm": 0.04350391402840614,
      "learning_rate": 3.1571428571428576e-05,
      "loss": 0.001,
      "step": 25800
    },
    {
      "epoch": 0.7374285714285714,
      "grad_norm": 0.04362405091524124,
      "learning_rate": 3.156428571428572e-05,
      "loss": 0.0004,
      "step": 25810
    },
    {
      "epoch": 0.7377142857142858,
      "grad_norm": 0.0,
      "learning_rate": 3.155714285714286e-05,
      "loss": 0.0007,
      "step": 25820
    },
    {
      "epoch": 0.738,
      "grad_norm": 0.04217246174812317,
      "learning_rate": 3.155e-05,
      "loss": 0.0016,
      "step": 25830
    },
    {
      "epoch": 0.7382857142857143,
      "grad_norm": 0.04224272072315216,
      "learning_rate": 3.154285714285714e-05,
      "loss": 0.0023,
      "step": 25840
    },
    {
      "epoch": 0.7385714285714285,
      "grad_norm": 0.08683203160762787,
      "learning_rate": 3.1535714285714285e-05,
      "loss": 0.0017,
      "step": 25850
    },
    {
      "epoch": 0.7388571428571429,
      "grad_norm": 0.041306547820568085,
      "learning_rate": 3.1528571428571426e-05,
      "loss": 0.0019,
      "step": 25860
    },
    {
      "epoch": 0.7391428571428571,
      "grad_norm": 0.022147007286548615,
      "learning_rate": 3.1521428571428575e-05,
      "loss": 0.0021,
      "step": 25870
    },
    {
      "epoch": 0.7394285714285714,
      "grad_norm": 0.08144903928041458,
      "learning_rate": 3.1514285714285717e-05,
      "loss": 0.0015,
      "step": 25880
    },
    {
      "epoch": 0.7397142857142858,
      "grad_norm": 0.11867611855268478,
      "learning_rate": 3.150714285714286e-05,
      "loss": 0.0025,
      "step": 25890
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.36866164207458496,
      "learning_rate": 3.15e-05,
      "loss": 0.0013,
      "step": 25900
    },
    {
      "epoch": 0.7402857142857143,
      "grad_norm": 0.09736261516809464,
      "learning_rate": 3.149285714285715e-05,
      "loss": 0.0019,
      "step": 25910
    },
    {
      "epoch": 0.7405714285714285,
      "grad_norm": 0.06068120151758194,
      "learning_rate": 3.148571428571428e-05,
      "loss": 0.0014,
      "step": 25920
    },
    {
      "epoch": 0.7408571428571429,
      "grad_norm": 0.04065106436610222,
      "learning_rate": 3.147857142857143e-05,
      "loss": 0.0016,
      "step": 25930
    },
    {
      "epoch": 0.7411428571428571,
      "grad_norm": 0.27363646030426025,
      "learning_rate": 3.1471428571428574e-05,
      "loss": 0.0018,
      "step": 25940
    },
    {
      "epoch": 0.7414285714285714,
      "grad_norm": 0.2513330578804016,
      "learning_rate": 3.1464285714285715e-05,
      "loss": 0.0015,
      "step": 25950
    },
    {
      "epoch": 0.7417142857142857,
      "grad_norm": 0.09196095168590546,
      "learning_rate": 3.145714285714286e-05,
      "loss": 0.0019,
      "step": 25960
    },
    {
      "epoch": 0.742,
      "grad_norm": 0.04534170776605606,
      "learning_rate": 3.145e-05,
      "loss": 0.002,
      "step": 25970
    },
    {
      "epoch": 0.7422857142857143,
      "grad_norm": 0.1621970385313034,
      "learning_rate": 3.144285714285715e-05,
      "loss": 0.0021,
      "step": 25980
    },
    {
      "epoch": 0.7425714285714285,
      "grad_norm": 0.24516846239566803,
      "learning_rate": 3.143571428571428e-05,
      "loss": 0.0014,
      "step": 25990
    },
    {
      "epoch": 0.7428571428571429,
      "grad_norm": 0.060504041612148285,
      "learning_rate": 3.142857142857143e-05,
      "loss": 0.0019,
      "step": 26000
    },
    {
      "epoch": 0.7431428571428571,
      "grad_norm": 0.125675231218338,
      "learning_rate": 3.142142857142857e-05,
      "loss": 0.0018,
      "step": 26010
    },
    {
      "epoch": 0.7434285714285714,
      "grad_norm": 0.06543254107236862,
      "learning_rate": 3.141428571428572e-05,
      "loss": 0.0013,
      "step": 26020
    },
    {
      "epoch": 0.7437142857142857,
      "grad_norm": 0.03333175927400589,
      "learning_rate": 3.1407142857142856e-05,
      "loss": 0.001,
      "step": 26030
    },
    {
      "epoch": 0.744,
      "grad_norm": 0.04984160512685776,
      "learning_rate": 3.1400000000000004e-05,
      "loss": 0.0021,
      "step": 26040
    },
    {
      "epoch": 0.7442857142857143,
      "grad_norm": 0.015148156322538853,
      "learning_rate": 3.1392857142857146e-05,
      "loss": 0.0013,
      "step": 26050
    },
    {
      "epoch": 0.7445714285714286,
      "grad_norm": 0.04525889456272125,
      "learning_rate": 3.138571428571429e-05,
      "loss": 0.0027,
      "step": 26060
    },
    {
      "epoch": 0.7448571428571429,
      "grad_norm": 0.26175349950790405,
      "learning_rate": 3.137857142857143e-05,
      "loss": 0.0019,
      "step": 26070
    },
    {
      "epoch": 0.7451428571428571,
      "grad_norm": 0.0,
      "learning_rate": 3.137142857142857e-05,
      "loss": 0.0016,
      "step": 26080
    },
    {
      "epoch": 0.7454285714285714,
      "grad_norm": 0.09251593798398972,
      "learning_rate": 3.136428571428572e-05,
      "loss": 0.0015,
      "step": 26090
    },
    {
      "epoch": 0.7457142857142857,
      "grad_norm": 0.22676706314086914,
      "learning_rate": 3.1357142857142855e-05,
      "loss": 0.0014,
      "step": 26100
    },
    {
      "epoch": 0.746,
      "grad_norm": 0.029568705707788467,
      "learning_rate": 3.135e-05,
      "loss": 0.0017,
      "step": 26110
    },
    {
      "epoch": 0.7462857142857143,
      "grad_norm": 0.13297565281391144,
      "learning_rate": 3.1342857142857145e-05,
      "loss": 0.0014,
      "step": 26120
    },
    {
      "epoch": 0.7465714285714286,
      "grad_norm": 0.047176193445920944,
      "learning_rate": 3.1335714285714287e-05,
      "loss": 0.001,
      "step": 26130
    },
    {
      "epoch": 0.7468571428571429,
      "grad_norm": 0.05122465640306473,
      "learning_rate": 3.132857142857143e-05,
      "loss": 0.0013,
      "step": 26140
    },
    {
      "epoch": 0.7471428571428571,
      "grad_norm": 0.08294381201267242,
      "learning_rate": 3.132142857142858e-05,
      "loss": 0.0012,
      "step": 26150
    },
    {
      "epoch": 0.7474285714285714,
      "grad_norm": 0.04134482517838478,
      "learning_rate": 3.131428571428572e-05,
      "loss": 0.0016,
      "step": 26160
    },
    {
      "epoch": 0.7477142857142857,
      "grad_norm": 0.08346463739871979,
      "learning_rate": 3.130714285714286e-05,
      "loss": 0.0007,
      "step": 26170
    },
    {
      "epoch": 0.748,
      "grad_norm": 0.04680435732007027,
      "learning_rate": 3.13e-05,
      "loss": 0.0006,
      "step": 26180
    },
    {
      "epoch": 0.7482857142857143,
      "grad_norm": 0.0,
      "learning_rate": 3.1292857142857144e-05,
      "loss": 0.0003,
      "step": 26190
    },
    {
      "epoch": 0.7485714285714286,
      "grad_norm": 0.04586344212293625,
      "learning_rate": 3.1285714285714285e-05,
      "loss": 0.0022,
      "step": 26200
    },
    {
      "epoch": 0.7488571428571429,
      "grad_norm": 0.047068797051906586,
      "learning_rate": 3.127857142857143e-05,
      "loss": 0.0011,
      "step": 26210
    },
    {
      "epoch": 0.7491428571428571,
      "grad_norm": 0.05823785811662674,
      "learning_rate": 3.1271428571428576e-05,
      "loss": 0.0012,
      "step": 26220
    },
    {
      "epoch": 0.7494285714285714,
      "grad_norm": 0.0,
      "learning_rate": 3.126428571428572e-05,
      "loss": 0.0013,
      "step": 26230
    },
    {
      "epoch": 0.7497142857142857,
      "grad_norm": 0.048305753618478775,
      "learning_rate": 3.125714285714286e-05,
      "loss": 0.0018,
      "step": 26240
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.22535736858844757,
      "learning_rate": 3.125e-05,
      "loss": 0.0013,
      "step": 26250
    },
    {
      "epoch": 0.7502857142857143,
      "grad_norm": 0.12714378535747528,
      "learning_rate": 3.124285714285715e-05,
      "loss": 0.0019,
      "step": 26260
    },
    {
      "epoch": 0.7505714285714286,
      "grad_norm": 0.1836935132741928,
      "learning_rate": 3.1235714285714284e-05,
      "loss": 0.0028,
      "step": 26270
    },
    {
      "epoch": 0.7508571428571429,
      "grad_norm": 0.0406307727098465,
      "learning_rate": 3.122857142857143e-05,
      "loss": 0.003,
      "step": 26280
    },
    {
      "epoch": 0.7511428571428571,
      "grad_norm": 0.03267151489853859,
      "learning_rate": 3.1221428571428574e-05,
      "loss": 0.0018,
      "step": 26290
    },
    {
      "epoch": 0.7514285714285714,
      "grad_norm": 0.056329358369112015,
      "learning_rate": 3.1214285714285716e-05,
      "loss": 0.0029,
      "step": 26300
    },
    {
      "epoch": 0.7517142857142857,
      "grad_norm": 0.06538457423448563,
      "learning_rate": 3.120714285714286e-05,
      "loss": 0.0019,
      "step": 26310
    },
    {
      "epoch": 0.752,
      "grad_norm": 0.1380513310432434,
      "learning_rate": 3.12e-05,
      "loss": 0.0021,
      "step": 26320
    },
    {
      "epoch": 0.7522857142857143,
      "grad_norm": 0.0,
      "learning_rate": 3.119285714285715e-05,
      "loss": 0.001,
      "step": 26330
    },
    {
      "epoch": 0.7525714285714286,
      "grad_norm": 0.05454335734248161,
      "learning_rate": 3.118571428571428e-05,
      "loss": 0.0009,
      "step": 26340
    },
    {
      "epoch": 0.7528571428571429,
      "grad_norm": 0.04436728358268738,
      "learning_rate": 3.117857142857143e-05,
      "loss": 0.0012,
      "step": 26350
    },
    {
      "epoch": 0.7531428571428571,
      "grad_norm": 0.04899289086461067,
      "learning_rate": 3.117142857142857e-05,
      "loss": 0.0019,
      "step": 26360
    },
    {
      "epoch": 0.7534285714285714,
      "grad_norm": 0.07089515030384064,
      "learning_rate": 3.1164285714285715e-05,
      "loss": 0.0013,
      "step": 26370
    },
    {
      "epoch": 0.7537142857142857,
      "grad_norm": 0.043268729001283646,
      "learning_rate": 3.1157142857142857e-05,
      "loss": 0.0018,
      "step": 26380
    },
    {
      "epoch": 0.754,
      "grad_norm": 0.23239204287528992,
      "learning_rate": 3.115e-05,
      "loss": 0.0008,
      "step": 26390
    },
    {
      "epoch": 0.7542857142857143,
      "grad_norm": 0.22630225121974945,
      "learning_rate": 3.114285714285715e-05,
      "loss": 0.0004,
      "step": 26400
    },
    {
      "epoch": 0.7545714285714286,
      "grad_norm": 0.0,
      "learning_rate": 3.113571428571428e-05,
      "loss": 0.001,
      "step": 26410
    },
    {
      "epoch": 0.7548571428571429,
      "grad_norm": 0.0,
      "learning_rate": 3.112857142857143e-05,
      "loss": 0.0013,
      "step": 26420
    },
    {
      "epoch": 0.7551428571428571,
      "grad_norm": 0.01908169686794281,
      "learning_rate": 3.112142857142857e-05,
      "loss": 0.0016,
      "step": 26430
    },
    {
      "epoch": 0.7554285714285714,
      "grad_norm": 0.08451426029205322,
      "learning_rate": 3.111428571428572e-05,
      "loss": 0.0017,
      "step": 26440
    },
    {
      "epoch": 0.7557142857142857,
      "grad_norm": 0.04420440271496773,
      "learning_rate": 3.1107142857142855e-05,
      "loss": 0.0022,
      "step": 26450
    },
    {
      "epoch": 0.756,
      "grad_norm": 0.0,
      "learning_rate": 3.1100000000000004e-05,
      "loss": 0.0014,
      "step": 26460
    },
    {
      "epoch": 0.7562857142857143,
      "grad_norm": 0.054294224828481674,
      "learning_rate": 3.1092857142857145e-05,
      "loss": 0.0016,
      "step": 26470
    },
    {
      "epoch": 0.7565714285714286,
      "grad_norm": 0.08344126492738724,
      "learning_rate": 3.108571428571429e-05,
      "loss": 0.0012,
      "step": 26480
    },
    {
      "epoch": 0.7568571428571429,
      "grad_norm": 0.14273902773857117,
      "learning_rate": 3.107857142857143e-05,
      "loss": 0.0018,
      "step": 26490
    },
    {
      "epoch": 0.7571428571428571,
      "grad_norm": 0.11724399030208588,
      "learning_rate": 3.107142857142857e-05,
      "loss": 0.0018,
      "step": 26500
    },
    {
      "epoch": 0.7574285714285715,
      "grad_norm": 0.28977248072624207,
      "learning_rate": 3.106428571428572e-05,
      "loss": 0.0012,
      "step": 26510
    },
    {
      "epoch": 0.7577142857142857,
      "grad_norm": 0.08339273184537888,
      "learning_rate": 3.1057142857142854e-05,
      "loss": 0.0011,
      "step": 26520
    },
    {
      "epoch": 0.758,
      "grad_norm": 0.13399147987365723,
      "learning_rate": 3.105e-05,
      "loss": 0.0012,
      "step": 26530
    },
    {
      "epoch": 0.7582857142857143,
      "grad_norm": 0.08638959378004074,
      "learning_rate": 3.1042857142857144e-05,
      "loss": 0.0026,
      "step": 26540
    },
    {
      "epoch": 0.7585714285714286,
      "grad_norm": 0.06720227003097534,
      "learning_rate": 3.1035714285714286e-05,
      "loss": 0.0021,
      "step": 26550
    },
    {
      "epoch": 0.7588571428571429,
      "grad_norm": 0.0,
      "learning_rate": 3.102857142857143e-05,
      "loss": 0.0011,
      "step": 26560
    },
    {
      "epoch": 0.7591428571428571,
      "grad_norm": 0.0,
      "learning_rate": 3.1021428571428576e-05,
      "loss": 0.0009,
      "step": 26570
    },
    {
      "epoch": 0.7594285714285715,
      "grad_norm": 0.08947687596082687,
      "learning_rate": 3.101428571428572e-05,
      "loss": 0.0019,
      "step": 26580
    },
    {
      "epoch": 0.7597142857142857,
      "grad_norm": 0.2944616973400116,
      "learning_rate": 3.100714285714286e-05,
      "loss": 0.0014,
      "step": 26590
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.08171933889389038,
      "learning_rate": 3.1e-05,
      "loss": 0.0022,
      "step": 26600
    },
    {
      "epoch": 0.7602857142857142,
      "grad_norm": 0.03731356933712959,
      "learning_rate": 3.099285714285714e-05,
      "loss": 0.0017,
      "step": 26610
    },
    {
      "epoch": 0.7605714285714286,
      "grad_norm": 0.1434459388256073,
      "learning_rate": 3.0985714285714285e-05,
      "loss": 0.0016,
      "step": 26620
    },
    {
      "epoch": 0.7608571428571429,
      "grad_norm": 0.05473316088318825,
      "learning_rate": 3.0978571428571426e-05,
      "loss": 0.0014,
      "step": 26630
    },
    {
      "epoch": 0.7611428571428571,
      "grad_norm": 0.02298334240913391,
      "learning_rate": 3.0971428571428575e-05,
      "loss": 0.0024,
      "step": 26640
    },
    {
      "epoch": 0.7614285714285715,
      "grad_norm": 0.13260126113891602,
      "learning_rate": 3.096428571428572e-05,
      "loss": 0.0016,
      "step": 26650
    },
    {
      "epoch": 0.7617142857142857,
      "grad_norm": 0.10354763269424438,
      "learning_rate": 3.095714285714286e-05,
      "loss": 0.0013,
      "step": 26660
    },
    {
      "epoch": 0.762,
      "grad_norm": 0.12583966553211212,
      "learning_rate": 3.095e-05,
      "loss": 0.0019,
      "step": 26670
    },
    {
      "epoch": 0.7622857142857142,
      "grad_norm": 0.040310703217983246,
      "learning_rate": 3.094285714285715e-05,
      "loss": 0.0005,
      "step": 26680
    },
    {
      "epoch": 0.7625714285714286,
      "grad_norm": 0.04647122696042061,
      "learning_rate": 3.0935714285714284e-05,
      "loss": 0.0015,
      "step": 26690
    },
    {
      "epoch": 0.7628571428571429,
      "grad_norm": 0.048240650445222855,
      "learning_rate": 3.092857142857143e-05,
      "loss": 0.0006,
      "step": 26700
    },
    {
      "epoch": 0.7631428571428571,
      "grad_norm": 0.220209538936615,
      "learning_rate": 3.0921428571428574e-05,
      "loss": 0.0011,
      "step": 26710
    },
    {
      "epoch": 0.7634285714285715,
      "grad_norm": 0.20776818692684174,
      "learning_rate": 3.0914285714285715e-05,
      "loss": 0.0013,
      "step": 26720
    },
    {
      "epoch": 0.7637142857142857,
      "grad_norm": 0.1959095001220703,
      "learning_rate": 3.090714285714286e-05,
      "loss": 0.0016,
      "step": 26730
    },
    {
      "epoch": 0.764,
      "grad_norm": 0.0,
      "learning_rate": 3.09e-05,
      "loss": 0.0011,
      "step": 26740
    },
    {
      "epoch": 0.7642857142857142,
      "grad_norm": 0.050143755972385406,
      "learning_rate": 3.089285714285715e-05,
      "loss": 0.002,
      "step": 26750
    },
    {
      "epoch": 0.7645714285714286,
      "grad_norm": 0.042908377945423126,
      "learning_rate": 3.088571428571428e-05,
      "loss": 0.0021,
      "step": 26760
    },
    {
      "epoch": 0.7648571428571429,
      "grad_norm": 0.0,
      "learning_rate": 3.087857142857143e-05,
      "loss": 0.0011,
      "step": 26770
    },
    {
      "epoch": 0.7651428571428571,
      "grad_norm": 0.24163134396076202,
      "learning_rate": 3.087142857142857e-05,
      "loss": 0.002,
      "step": 26780
    },
    {
      "epoch": 0.7654285714285715,
      "grad_norm": 0.13124066591262817,
      "learning_rate": 3.086428571428572e-05,
      "loss": 0.0009,
      "step": 26790
    },
    {
      "epoch": 0.7657142857142857,
      "grad_norm": 0.09256763011217117,
      "learning_rate": 3.0857142857142856e-05,
      "loss": 0.0013,
      "step": 26800
    },
    {
      "epoch": 0.766,
      "grad_norm": 0.18599936366081238,
      "learning_rate": 3.0850000000000004e-05,
      "loss": 0.0016,
      "step": 26810
    },
    {
      "epoch": 0.7662857142857142,
      "grad_norm": 0.1974838674068451,
      "learning_rate": 3.0842857142857146e-05,
      "loss": 0.0031,
      "step": 26820
    },
    {
      "epoch": 0.7665714285714286,
      "grad_norm": 0.04044225439429283,
      "learning_rate": 3.083571428571428e-05,
      "loss": 0.001,
      "step": 26830
    },
    {
      "epoch": 0.7668571428571429,
      "grad_norm": 0.09453025460243225,
      "learning_rate": 3.082857142857143e-05,
      "loss": 0.0022,
      "step": 26840
    },
    {
      "epoch": 0.7671428571428571,
      "grad_norm": 0.04367835074663162,
      "learning_rate": 3.082142857142857e-05,
      "loss": 0.004,
      "step": 26850
    },
    {
      "epoch": 0.7674285714285715,
      "grad_norm": 0.28952717781066895,
      "learning_rate": 3.081428571428572e-05,
      "loss": 0.0016,
      "step": 26860
    },
    {
      "epoch": 0.7677142857142857,
      "grad_norm": 0.11634089797735214,
      "learning_rate": 3.0807142857142855e-05,
      "loss": 0.0018,
      "step": 26870
    },
    {
      "epoch": 0.768,
      "grad_norm": 0.2843077778816223,
      "learning_rate": 3.08e-05,
      "loss": 0.001,
      "step": 26880
    },
    {
      "epoch": 0.7682857142857142,
      "grad_norm": 0.16535711288452148,
      "learning_rate": 3.0792857142857145e-05,
      "loss": 0.001,
      "step": 26890
    },
    {
      "epoch": 0.7685714285714286,
      "grad_norm": 0.08463361859321594,
      "learning_rate": 3.078571428571429e-05,
      "loss": 0.0014,
      "step": 26900
    },
    {
      "epoch": 0.7688571428571429,
      "grad_norm": 0.042426593601703644,
      "learning_rate": 3.077857142857143e-05,
      "loss": 0.002,
      "step": 26910
    },
    {
      "epoch": 0.7691428571428571,
      "grad_norm": 0.08928580582141876,
      "learning_rate": 3.077142857142857e-05,
      "loss": 0.0025,
      "step": 26920
    },
    {
      "epoch": 0.7694285714285715,
      "grad_norm": 0.1266132891178131,
      "learning_rate": 3.076428571428572e-05,
      "loss": 0.0015,
      "step": 26930
    },
    {
      "epoch": 0.7697142857142857,
      "grad_norm": 0.04234623536467552,
      "learning_rate": 3.0757142857142854e-05,
      "loss": 0.0012,
      "step": 26940
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.13018275797367096,
      "learning_rate": 3.075e-05,
      "loss": 0.0017,
      "step": 26950
    },
    {
      "epoch": 0.7702857142857142,
      "grad_norm": 0.04734884575009346,
      "learning_rate": 3.0742857142857144e-05,
      "loss": 0.0019,
      "step": 26960
    },
    {
      "epoch": 0.7705714285714286,
      "grad_norm": 0.0454789362847805,
      "learning_rate": 3.073571428571429e-05,
      "loss": 0.0013,
      "step": 26970
    },
    {
      "epoch": 0.7708571428571429,
      "grad_norm": 0.04018621891736984,
      "learning_rate": 3.072857142857143e-05,
      "loss": 0.0015,
      "step": 26980
    },
    {
      "epoch": 0.7711428571428571,
      "grad_norm": 0.0,
      "learning_rate": 3.0721428571428576e-05,
      "loss": 0.0013,
      "step": 26990
    },
    {
      "epoch": 0.7714285714285715,
      "grad_norm": 0.2067301720380783,
      "learning_rate": 3.071428571428572e-05,
      "loss": 0.0017,
      "step": 27000
    },
    {
      "epoch": 0.7717142857142857,
      "grad_norm": 0.16424916684627533,
      "learning_rate": 3.070714285714286e-05,
      "loss": 0.0016,
      "step": 27010
    },
    {
      "epoch": 0.772,
      "grad_norm": 0.04566802829504013,
      "learning_rate": 3.07e-05,
      "loss": 0.0014,
      "step": 27020
    },
    {
      "epoch": 0.7722857142857142,
      "grad_norm": 0.13168635964393616,
      "learning_rate": 3.069285714285714e-05,
      "loss": 0.0019,
      "step": 27030
    },
    {
      "epoch": 0.7725714285714286,
      "grad_norm": 0.10894818603992462,
      "learning_rate": 3.068571428571429e-05,
      "loss": 0.0015,
      "step": 27040
    },
    {
      "epoch": 0.7728571428571429,
      "grad_norm": 0.029408665373921394,
      "learning_rate": 3.0678571428571426e-05,
      "loss": 0.0013,
      "step": 27050
    },
    {
      "epoch": 0.7731428571428571,
      "grad_norm": 0.0,
      "learning_rate": 3.0671428571428574e-05,
      "loss": 0.001,
      "step": 27060
    },
    {
      "epoch": 0.7734285714285715,
      "grad_norm": 0.18821580708026886,
      "learning_rate": 3.0664285714285716e-05,
      "loss": 0.001,
      "step": 27070
    },
    {
      "epoch": 0.7737142857142857,
      "grad_norm": 0.08157699555158615,
      "learning_rate": 3.065714285714286e-05,
      "loss": 0.0012,
      "step": 27080
    },
    {
      "epoch": 0.774,
      "grad_norm": 0.02811276726424694,
      "learning_rate": 3.065e-05,
      "loss": 0.0016,
      "step": 27090
    },
    {
      "epoch": 0.7742857142857142,
      "grad_norm": 0.260728657245636,
      "learning_rate": 3.064285714285715e-05,
      "loss": 0.0021,
      "step": 27100
    },
    {
      "epoch": 0.7745714285714286,
      "grad_norm": 0.1482694149017334,
      "learning_rate": 3.063571428571429e-05,
      "loss": 0.0021,
      "step": 27110
    },
    {
      "epoch": 0.7748571428571429,
      "grad_norm": 0.0,
      "learning_rate": 3.062857142857143e-05,
      "loss": 0.0014,
      "step": 27120
    },
    {
      "epoch": 0.7751428571428571,
      "grad_norm": 0.1555272787809372,
      "learning_rate": 3.062142857142857e-05,
      "loss": 0.0017,
      "step": 27130
    },
    {
      "epoch": 0.7754285714285715,
      "grad_norm": 0.0475451834499836,
      "learning_rate": 3.0614285714285715e-05,
      "loss": 0.0014,
      "step": 27140
    },
    {
      "epoch": 0.7757142857142857,
      "grad_norm": 0.0,
      "learning_rate": 3.060714285714286e-05,
      "loss": 0.0008,
      "step": 27150
    },
    {
      "epoch": 0.776,
      "grad_norm": 0.19896699488162994,
      "learning_rate": 3.06e-05,
      "loss": 0.0017,
      "step": 27160
    },
    {
      "epoch": 0.7762857142857142,
      "grad_norm": 0.21395857632160187,
      "learning_rate": 3.059285714285715e-05,
      "loss": 0.0011,
      "step": 27170
    },
    {
      "epoch": 0.7765714285714286,
      "grad_norm": 0.2878507673740387,
      "learning_rate": 3.058571428571429e-05,
      "loss": 0.0028,
      "step": 27180
    },
    {
      "epoch": 0.7768571428571428,
      "grad_norm": 0.2098793387413025,
      "learning_rate": 3.057857142857143e-05,
      "loss": 0.0019,
      "step": 27190
    },
    {
      "epoch": 0.7771428571428571,
      "grad_norm": 0.0,
      "learning_rate": 3.057142857142857e-05,
      "loss": 0.0015,
      "step": 27200
    },
    {
      "epoch": 0.7774285714285715,
      "grad_norm": 0.0837741270661354,
      "learning_rate": 3.056428571428572e-05,
      "loss": 0.0016,
      "step": 27210
    },
    {
      "epoch": 0.7777142857142857,
      "grad_norm": 0.05201166868209839,
      "learning_rate": 3.0557142857142855e-05,
      "loss": 0.0012,
      "step": 27220
    },
    {
      "epoch": 0.778,
      "grad_norm": 0.03304353356361389,
      "learning_rate": 3.0550000000000004e-05,
      "loss": 0.0006,
      "step": 27230
    },
    {
      "epoch": 0.7782857142857142,
      "grad_norm": 0.12284065783023834,
      "learning_rate": 3.0542857142857146e-05,
      "loss": 0.0013,
      "step": 27240
    },
    {
      "epoch": 0.7785714285714286,
      "grad_norm": 0.13713720440864563,
      "learning_rate": 3.053571428571429e-05,
      "loss": 0.0008,
      "step": 27250
    },
    {
      "epoch": 0.7788571428571428,
      "grad_norm": 0.0,
      "learning_rate": 3.052857142857143e-05,
      "loss": 0.0018,
      "step": 27260
    },
    {
      "epoch": 0.7791428571428571,
      "grad_norm": 0.08433490246534348,
      "learning_rate": 3.052142857142857e-05,
      "loss": 0.0014,
      "step": 27270
    },
    {
      "epoch": 0.7794285714285715,
      "grad_norm": 0.09215456247329712,
      "learning_rate": 3.0514285714285716e-05,
      "loss": 0.0013,
      "step": 27280
    },
    {
      "epoch": 0.7797142857142857,
      "grad_norm": 0.12381108105182648,
      "learning_rate": 3.0507142857142858e-05,
      "loss": 0.0025,
      "step": 27290
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.1503438502550125,
      "learning_rate": 3.05e-05,
      "loss": 0.0017,
      "step": 27300
    },
    {
      "epoch": 0.7802857142857142,
      "grad_norm": 0.12086635828018188,
      "learning_rate": 3.0492857142857144e-05,
      "loss": 0.001,
      "step": 27310
    },
    {
      "epoch": 0.7805714285714286,
      "grad_norm": 0.09981893748044968,
      "learning_rate": 3.048571428571429e-05,
      "loss": 0.0015,
      "step": 27320
    },
    {
      "epoch": 0.7808571428571428,
      "grad_norm": 0.16327649354934692,
      "learning_rate": 3.0478571428571428e-05,
      "loss": 0.0011,
      "step": 27330
    },
    {
      "epoch": 0.7811428571428571,
      "grad_norm": 0.1299455165863037,
      "learning_rate": 3.0471428571428573e-05,
      "loss": 0.0018,
      "step": 27340
    },
    {
      "epoch": 0.7814285714285715,
      "grad_norm": 0.04609411209821701,
      "learning_rate": 3.0464285714285718e-05,
      "loss": 0.002,
      "step": 27350
    },
    {
      "epoch": 0.7817142857142857,
      "grad_norm": 0.060848262161016464,
      "learning_rate": 3.0457142857142856e-05,
      "loss": 0.0007,
      "step": 27360
    },
    {
      "epoch": 0.782,
      "grad_norm": 0.1617942601442337,
      "learning_rate": 3.045e-05,
      "loss": 0.0008,
      "step": 27370
    },
    {
      "epoch": 0.7822857142857143,
      "grad_norm": 0.0,
      "learning_rate": 3.0442857142857147e-05,
      "loss": 0.0005,
      "step": 27380
    },
    {
      "epoch": 0.7825714285714286,
      "grad_norm": 0.0,
      "learning_rate": 3.043571428571429e-05,
      "loss": 0.0019,
      "step": 27390
    },
    {
      "epoch": 0.7828571428571428,
      "grad_norm": 0.08814539760351181,
      "learning_rate": 3.042857142857143e-05,
      "loss": 0.0017,
      "step": 27400
    },
    {
      "epoch": 0.7831428571428571,
      "grad_norm": 0.2560984492301941,
      "learning_rate": 3.0421428571428572e-05,
      "loss": 0.001,
      "step": 27410
    },
    {
      "epoch": 0.7834285714285715,
      "grad_norm": 0.0,
      "learning_rate": 3.0414285714285717e-05,
      "loss": 0.0008,
      "step": 27420
    },
    {
      "epoch": 0.7837142857142857,
      "grad_norm": 0.0455746091902256,
      "learning_rate": 3.0407142857142855e-05,
      "loss": 0.0012,
      "step": 27430
    },
    {
      "epoch": 0.784,
      "grad_norm": 0.09722453355789185,
      "learning_rate": 3.04e-05,
      "loss": 0.0009,
      "step": 27440
    },
    {
      "epoch": 0.7842857142857143,
      "grad_norm": 0.1281667947769165,
      "learning_rate": 3.0392857142857145e-05,
      "loss": 0.0029,
      "step": 27450
    },
    {
      "epoch": 0.7845714285714286,
      "grad_norm": 0.09013105928897858,
      "learning_rate": 3.038571428571429e-05,
      "loss": 0.0018,
      "step": 27460
    },
    {
      "epoch": 0.7848571428571428,
      "grad_norm": 0.0,
      "learning_rate": 3.037857142857143e-05,
      "loss": 0.0016,
      "step": 27470
    },
    {
      "epoch": 0.7851428571428571,
      "grad_norm": 0.0,
      "learning_rate": 3.0371428571428574e-05,
      "loss": 0.001,
      "step": 27480
    },
    {
      "epoch": 0.7854285714285715,
      "grad_norm": 0.2180575430393219,
      "learning_rate": 3.0364285714285716e-05,
      "loss": 0.0019,
      "step": 27490
    },
    {
      "epoch": 0.7857142857142857,
      "grad_norm": 0.0508715957403183,
      "learning_rate": 3.0357142857142857e-05,
      "loss": 0.0016,
      "step": 27500
    },
    {
      "epoch": 0.786,
      "grad_norm": 0.04067079350352287,
      "learning_rate": 3.035e-05,
      "loss": 0.0018,
      "step": 27510
    },
    {
      "epoch": 0.7862857142857143,
      "grad_norm": 0.06687826663255692,
      "learning_rate": 3.0342857142857144e-05,
      "loss": 0.0015,
      "step": 27520
    },
    {
      "epoch": 0.7865714285714286,
      "grad_norm": 0.3453424572944641,
      "learning_rate": 3.033571428571429e-05,
      "loss": 0.003,
      "step": 27530
    },
    {
      "epoch": 0.7868571428571428,
      "grad_norm": 0.05444597080349922,
      "learning_rate": 3.0328571428571428e-05,
      "loss": 0.001,
      "step": 27540
    },
    {
      "epoch": 0.7871428571428571,
      "grad_norm": 0.037805136293172836,
      "learning_rate": 3.0321428571428573e-05,
      "loss": 0.0013,
      "step": 27550
    },
    {
      "epoch": 0.7874285714285715,
      "grad_norm": 0.16426227986812592,
      "learning_rate": 3.0314285714285718e-05,
      "loss": 0.0013,
      "step": 27560
    },
    {
      "epoch": 0.7877142857142857,
      "grad_norm": 0.23745408654212952,
      "learning_rate": 3.0307142857142856e-05,
      "loss": 0.0011,
      "step": 27570
    },
    {
      "epoch": 0.788,
      "grad_norm": 0.22977283596992493,
      "learning_rate": 3.03e-05,
      "loss": 0.0016,
      "step": 27580
    },
    {
      "epoch": 0.7882857142857143,
      "grad_norm": 0.0,
      "learning_rate": 3.0292857142857146e-05,
      "loss": 0.001,
      "step": 27590
    },
    {
      "epoch": 0.7885714285714286,
      "grad_norm": 0.1971862018108368,
      "learning_rate": 3.0285714285714288e-05,
      "loss": 0.0015,
      "step": 27600
    },
    {
      "epoch": 0.7888571428571428,
      "grad_norm": 0.06027618795633316,
      "learning_rate": 3.027857142857143e-05,
      "loss": 0.0016,
      "step": 27610
    },
    {
      "epoch": 0.7891428571428571,
      "grad_norm": 0.0,
      "learning_rate": 3.027142857142857e-05,
      "loss": 0.0012,
      "step": 27620
    },
    {
      "epoch": 0.7894285714285715,
      "grad_norm": 0.038229987025260925,
      "learning_rate": 3.0264285714285717e-05,
      "loss": 0.0025,
      "step": 27630
    },
    {
      "epoch": 0.7897142857142857,
      "grad_norm": 0.2851494252681732,
      "learning_rate": 3.0257142857142855e-05,
      "loss": 0.0014,
      "step": 27640
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.12462741881608963,
      "learning_rate": 3.025e-05,
      "loss": 0.0023,
      "step": 27650
    },
    {
      "epoch": 0.7902857142857143,
      "grad_norm": 0.36949464678764343,
      "learning_rate": 3.0242857142857145e-05,
      "loss": 0.0012,
      "step": 27660
    },
    {
      "epoch": 0.7905714285714286,
      "grad_norm": 0.1251821368932724,
      "learning_rate": 3.023571428571429e-05,
      "loss": 0.0016,
      "step": 27670
    },
    {
      "epoch": 0.7908571428571428,
      "grad_norm": 0.08142980188131332,
      "learning_rate": 3.022857142857143e-05,
      "loss": 0.0026,
      "step": 27680
    },
    {
      "epoch": 0.7911428571428571,
      "grad_norm": 0.048183564096689224,
      "learning_rate": 3.0221428571428574e-05,
      "loss": 0.0016,
      "step": 27690
    },
    {
      "epoch": 0.7914285714285715,
      "grad_norm": 0.06025756895542145,
      "learning_rate": 3.021428571428572e-05,
      "loss": 0.001,
      "step": 27700
    },
    {
      "epoch": 0.7917142857142857,
      "grad_norm": 0.04168785363435745,
      "learning_rate": 3.0207142857142857e-05,
      "loss": 0.0022,
      "step": 27710
    },
    {
      "epoch": 0.792,
      "grad_norm": 0.09024576097726822,
      "learning_rate": 3.02e-05,
      "loss": 0.0018,
      "step": 27720
    },
    {
      "epoch": 0.7922857142857143,
      "grad_norm": 0.060779869556427,
      "learning_rate": 3.0192857142857144e-05,
      "loss": 0.0017,
      "step": 27730
    },
    {
      "epoch": 0.7925714285714286,
      "grad_norm": 0.17314110696315765,
      "learning_rate": 3.018571428571429e-05,
      "loss": 0.0008,
      "step": 27740
    },
    {
      "epoch": 0.7928571428571428,
      "grad_norm": 0.040255505591630936,
      "learning_rate": 3.0178571428571427e-05,
      "loss": 0.0012,
      "step": 27750
    },
    {
      "epoch": 0.7931428571428571,
      "grad_norm": 0.07938611507415771,
      "learning_rate": 3.0171428571428572e-05,
      "loss": 0.0019,
      "step": 27760
    },
    {
      "epoch": 0.7934285714285715,
      "grad_norm": 0.0438171811401844,
      "learning_rate": 3.0164285714285718e-05,
      "loss": 0.0022,
      "step": 27770
    },
    {
      "epoch": 0.7937142857142857,
      "grad_norm": 0.02436729334294796,
      "learning_rate": 3.0157142857142856e-05,
      "loss": 0.002,
      "step": 27780
    },
    {
      "epoch": 0.794,
      "grad_norm": 0.18306420743465424,
      "learning_rate": 3.015e-05,
      "loss": 0.0011,
      "step": 27790
    },
    {
      "epoch": 0.7942857142857143,
      "grad_norm": 0.2773217558860779,
      "learning_rate": 3.0142857142857146e-05,
      "loss": 0.0013,
      "step": 27800
    },
    {
      "epoch": 0.7945714285714286,
      "grad_norm": 0.43120431900024414,
      "learning_rate": 3.0135714285714288e-05,
      "loss": 0.0018,
      "step": 27810
    },
    {
      "epoch": 0.7948571428571428,
      "grad_norm": 0.11864544451236725,
      "learning_rate": 3.012857142857143e-05,
      "loss": 0.0019,
      "step": 27820
    },
    {
      "epoch": 0.7951428571428572,
      "grad_norm": 0.09067277610301971,
      "learning_rate": 3.012142857142857e-05,
      "loss": 0.0013,
      "step": 27830
    },
    {
      "epoch": 0.7954285714285714,
      "grad_norm": 0.2678738832473755,
      "learning_rate": 3.0114285714285716e-05,
      "loss": 0.0008,
      "step": 27840
    },
    {
      "epoch": 0.7957142857142857,
      "grad_norm": 0.26060041785240173,
      "learning_rate": 3.0107142857142855e-05,
      "loss": 0.0008,
      "step": 27850
    },
    {
      "epoch": 0.796,
      "grad_norm": 0.12360404431819916,
      "learning_rate": 3.01e-05,
      "loss": 0.001,
      "step": 27860
    },
    {
      "epoch": 0.7962857142857143,
      "grad_norm": 0.1361759454011917,
      "learning_rate": 3.0092857142857145e-05,
      "loss": 0.0015,
      "step": 27870
    },
    {
      "epoch": 0.7965714285714286,
      "grad_norm": 0.04073984548449516,
      "learning_rate": 3.008571428571429e-05,
      "loss": 0.0015,
      "step": 27880
    },
    {
      "epoch": 0.7968571428571428,
      "grad_norm": 0.3275403678417206,
      "learning_rate": 3.007857142857143e-05,
      "loss": 0.0016,
      "step": 27890
    },
    {
      "epoch": 0.7971428571428572,
      "grad_norm": 0.21113614737987518,
      "learning_rate": 3.0071428571428573e-05,
      "loss": 0.0015,
      "step": 27900
    },
    {
      "epoch": 0.7974285714285714,
      "grad_norm": 0.1608547866344452,
      "learning_rate": 3.006428571428572e-05,
      "loss": 0.0014,
      "step": 27910
    },
    {
      "epoch": 0.7977142857142857,
      "grad_norm": 0.09831668436527252,
      "learning_rate": 3.0057142857142857e-05,
      "loss": 0.0009,
      "step": 27920
    },
    {
      "epoch": 0.798,
      "grad_norm": 0.12029606848955154,
      "learning_rate": 3.0050000000000002e-05,
      "loss": 0.0026,
      "step": 27930
    },
    {
      "epoch": 0.7982857142857143,
      "grad_norm": 0.13089381158351898,
      "learning_rate": 3.0042857142857144e-05,
      "loss": 0.0014,
      "step": 27940
    },
    {
      "epoch": 0.7985714285714286,
      "grad_norm": 0.0,
      "learning_rate": 3.003571428571429e-05,
      "loss": 0.0016,
      "step": 27950
    },
    {
      "epoch": 0.7988571428571428,
      "grad_norm": 0.04533477872610092,
      "learning_rate": 3.0028571428571427e-05,
      "loss": 0.0012,
      "step": 27960
    },
    {
      "epoch": 0.7991428571428572,
      "grad_norm": 0.08435586094856262,
      "learning_rate": 3.0021428571428572e-05,
      "loss": 0.0016,
      "step": 27970
    },
    {
      "epoch": 0.7994285714285714,
      "grad_norm": 0.0,
      "learning_rate": 3.0014285714285717e-05,
      "loss": 0.0007,
      "step": 27980
    },
    {
      "epoch": 0.7997142857142857,
      "grad_norm": 0.059059999883174896,
      "learning_rate": 3.0007142857142856e-05,
      "loss": 0.001,
      "step": 27990
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.056881438940763474,
      "learning_rate": 3e-05,
      "loss": 0.0027,
      "step": 28000
    },
    {
      "epoch": 0.8002857142857143,
      "grad_norm": 0.08638878166675568,
      "learning_rate": 2.9992857142857146e-05,
      "loss": 0.0012,
      "step": 28010
    },
    {
      "epoch": 0.8005714285714286,
      "grad_norm": 0.0,
      "learning_rate": 2.9985714285714288e-05,
      "loss": 0.0012,
      "step": 28020
    },
    {
      "epoch": 0.8008571428571428,
      "grad_norm": 0.0,
      "learning_rate": 2.997857142857143e-05,
      "loss": 0.0011,
      "step": 28030
    },
    {
      "epoch": 0.8011428571428572,
      "grad_norm": 0.0,
      "learning_rate": 2.997142857142857e-05,
      "loss": 0.0014,
      "step": 28040
    },
    {
      "epoch": 0.8014285714285714,
      "grad_norm": 0.04224037379026413,
      "learning_rate": 2.9964285714285716e-05,
      "loss": 0.0019,
      "step": 28050
    },
    {
      "epoch": 0.8017142857142857,
      "grad_norm": 0.0,
      "learning_rate": 2.9957142857142854e-05,
      "loss": 0.0013,
      "step": 28060
    },
    {
      "epoch": 0.802,
      "grad_norm": 0.0,
      "learning_rate": 2.995e-05,
      "loss": 0.0008,
      "step": 28070
    },
    {
      "epoch": 0.8022857142857143,
      "grad_norm": 0.15102706849575043,
      "learning_rate": 2.9942857142857145e-05,
      "loss": 0.0011,
      "step": 28080
    },
    {
      "epoch": 0.8025714285714286,
      "grad_norm": 0.32237815856933594,
      "learning_rate": 2.993571428571429e-05,
      "loss": 0.0024,
      "step": 28090
    },
    {
      "epoch": 0.8028571428571428,
      "grad_norm": 0.11179423332214355,
      "learning_rate": 2.9928571428571428e-05,
      "loss": 0.0018,
      "step": 28100
    },
    {
      "epoch": 0.8031428571428572,
      "grad_norm": 0.04263579845428467,
      "learning_rate": 2.9921428571428573e-05,
      "loss": 0.0018,
      "step": 28110
    },
    {
      "epoch": 0.8034285714285714,
      "grad_norm": 0.045251231640577316,
      "learning_rate": 2.9914285714285718e-05,
      "loss": 0.0016,
      "step": 28120
    },
    {
      "epoch": 0.8037142857142857,
      "grad_norm": 0.07699313014745712,
      "learning_rate": 2.990714285714286e-05,
      "loss": 0.0027,
      "step": 28130
    },
    {
      "epoch": 0.804,
      "grad_norm": 0.25836971402168274,
      "learning_rate": 2.9900000000000002e-05,
      "loss": 0.0019,
      "step": 28140
    },
    {
      "epoch": 0.8042857142857143,
      "grad_norm": 0.2221052497625351,
      "learning_rate": 2.9892857142857143e-05,
      "loss": 0.0012,
      "step": 28150
    },
    {
      "epoch": 0.8045714285714286,
      "grad_norm": 0.03127320483326912,
      "learning_rate": 2.988571428571429e-05,
      "loss": 0.0018,
      "step": 28160
    },
    {
      "epoch": 0.8048571428571428,
      "grad_norm": 0.11883910000324249,
      "learning_rate": 2.9878571428571427e-05,
      "loss": 0.0015,
      "step": 28170
    },
    {
      "epoch": 0.8051428571428572,
      "grad_norm": 0.1230052039027214,
      "learning_rate": 2.9871428571428572e-05,
      "loss": 0.0005,
      "step": 28180
    },
    {
      "epoch": 0.8054285714285714,
      "grad_norm": 0.17094366252422333,
      "learning_rate": 2.9864285714285717e-05,
      "loss": 0.0019,
      "step": 28190
    },
    {
      "epoch": 0.8057142857142857,
      "grad_norm": 0.0,
      "learning_rate": 2.9857142857142862e-05,
      "loss": 0.0005,
      "step": 28200
    },
    {
      "epoch": 0.806,
      "grad_norm": 0.0,
      "learning_rate": 2.985e-05,
      "loss": 0.001,
      "step": 28210
    },
    {
      "epoch": 0.8062857142857143,
      "grad_norm": 0.04391804337501526,
      "learning_rate": 2.9842857142857146e-05,
      "loss": 0.0011,
      "step": 28220
    },
    {
      "epoch": 0.8065714285714286,
      "grad_norm": 0.11257965117692947,
      "learning_rate": 2.983571428571429e-05,
      "loss": 0.0026,
      "step": 28230
    },
    {
      "epoch": 0.8068571428571428,
      "grad_norm": 0.07329171150922775,
      "learning_rate": 2.982857142857143e-05,
      "loss": 0.0008,
      "step": 28240
    },
    {
      "epoch": 0.8071428571428572,
      "grad_norm": 0.1572636514902115,
      "learning_rate": 2.982142857142857e-05,
      "loss": 0.002,
      "step": 28250
    },
    {
      "epoch": 0.8074285714285714,
      "grad_norm": 0.12458916008472443,
      "learning_rate": 2.9814285714285716e-05,
      "loss": 0.0011,
      "step": 28260
    },
    {
      "epoch": 0.8077142857142857,
      "grad_norm": 0.023918846622109413,
      "learning_rate": 2.980714285714286e-05,
      "loss": 0.0018,
      "step": 28270
    },
    {
      "epoch": 0.808,
      "grad_norm": 0.08830326050519943,
      "learning_rate": 2.98e-05,
      "loss": 0.0014,
      "step": 28280
    },
    {
      "epoch": 0.8082857142857143,
      "grad_norm": 0.0,
      "learning_rate": 2.9792857142857144e-05,
      "loss": 0.0008,
      "step": 28290
    },
    {
      "epoch": 0.8085714285714286,
      "grad_norm": 0.11761800944805145,
      "learning_rate": 2.978571428571429e-05,
      "loss": 0.0012,
      "step": 28300
    },
    {
      "epoch": 0.8088571428571428,
      "grad_norm": 0.08872783929109573,
      "learning_rate": 2.9778571428571428e-05,
      "loss": 0.001,
      "step": 28310
    },
    {
      "epoch": 0.8091428571428572,
      "grad_norm": 0.053020115941762924,
      "learning_rate": 2.9771428571428573e-05,
      "loss": 0.0009,
      "step": 28320
    },
    {
      "epoch": 0.8094285714285714,
      "grad_norm": 0.11530977487564087,
      "learning_rate": 2.9764285714285718e-05,
      "loss": 0.0013,
      "step": 28330
    },
    {
      "epoch": 0.8097142857142857,
      "grad_norm": 0.0415707565844059,
      "learning_rate": 2.975714285714286e-05,
      "loss": 0.0009,
      "step": 28340
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.0453171506524086,
      "learning_rate": 2.975e-05,
      "loss": 0.0014,
      "step": 28350
    },
    {
      "epoch": 0.8102857142857143,
      "grad_norm": 0.09503152966499329,
      "learning_rate": 2.9742857142857143e-05,
      "loss": 0.0008,
      "step": 28360
    },
    {
      "epoch": 0.8105714285714286,
      "grad_norm": 0.29870471358299255,
      "learning_rate": 2.9735714285714288e-05,
      "loss": 0.0011,
      "step": 28370
    },
    {
      "epoch": 0.8108571428571428,
      "grad_norm": 0.04361720383167267,
      "learning_rate": 2.9728571428571427e-05,
      "loss": 0.0011,
      "step": 28380
    },
    {
      "epoch": 0.8111428571428572,
      "grad_norm": 0.04315411299467087,
      "learning_rate": 2.9721428571428572e-05,
      "loss": 0.002,
      "step": 28390
    },
    {
      "epoch": 0.8114285714285714,
      "grad_norm": 0.2451682835817337,
      "learning_rate": 2.9714285714285717e-05,
      "loss": 0.0004,
      "step": 28400
    },
    {
      "epoch": 0.8117142857142857,
      "grad_norm": 0.03076436184346676,
      "learning_rate": 2.9707142857142862e-05,
      "loss": 0.0026,
      "step": 28410
    },
    {
      "epoch": 0.812,
      "grad_norm": 0.2662731409072876,
      "learning_rate": 2.97e-05,
      "loss": 0.0014,
      "step": 28420
    },
    {
      "epoch": 0.8122857142857143,
      "grad_norm": 0.0,
      "learning_rate": 2.9692857142857145e-05,
      "loss": 0.0019,
      "step": 28430
    },
    {
      "epoch": 0.8125714285714286,
      "grad_norm": 0.08362637460231781,
      "learning_rate": 2.968571428571429e-05,
      "loss": 0.0023,
      "step": 28440
    },
    {
      "epoch": 0.8128571428571428,
      "grad_norm": 0.06737838685512543,
      "learning_rate": 2.967857142857143e-05,
      "loss": 0.001,
      "step": 28450
    },
    {
      "epoch": 0.8131428571428572,
      "grad_norm": 0.08085127919912338,
      "learning_rate": 2.9671428571428574e-05,
      "loss": 0.0017,
      "step": 28460
    },
    {
      "epoch": 0.8134285714285714,
      "grad_norm": 0.0,
      "learning_rate": 2.9664285714285716e-05,
      "loss": 0.0014,
      "step": 28470
    },
    {
      "epoch": 0.8137142857142857,
      "grad_norm": 0.04179719090461731,
      "learning_rate": 2.965714285714286e-05,
      "loss": 0.0011,
      "step": 28480
    },
    {
      "epoch": 0.814,
      "grad_norm": 0.1983327567577362,
      "learning_rate": 2.965e-05,
      "loss": 0.0025,
      "step": 28490
    },
    {
      "epoch": 0.8142857142857143,
      "grad_norm": 0.0,
      "learning_rate": 2.9642857142857144e-05,
      "loss": 0.0006,
      "step": 28500
    },
    {
      "epoch": 0.8145714285714286,
      "grad_norm": 0.08895725011825562,
      "learning_rate": 2.963571428571429e-05,
      "loss": 0.0007,
      "step": 28510
    },
    {
      "epoch": 0.8148571428571428,
      "grad_norm": 0.03658699616789818,
      "learning_rate": 2.9628571428571428e-05,
      "loss": 0.0013,
      "step": 28520
    },
    {
      "epoch": 0.8151428571428572,
      "grad_norm": 0.0,
      "learning_rate": 2.9621428571428573e-05,
      "loss": 0.001,
      "step": 28530
    },
    {
      "epoch": 0.8154285714285714,
      "grad_norm": 0.04264722391963005,
      "learning_rate": 2.9614285714285718e-05,
      "loss": 0.0005,
      "step": 28540
    },
    {
      "epoch": 0.8157142857142857,
      "grad_norm": 0.08025367558002472,
      "learning_rate": 2.960714285714286e-05,
      "loss": 0.0021,
      "step": 28550
    },
    {
      "epoch": 0.816,
      "grad_norm": 0.046363502740859985,
      "learning_rate": 2.96e-05,
      "loss": 0.0024,
      "step": 28560
    },
    {
      "epoch": 0.8162857142857143,
      "grad_norm": 0.05662456527352333,
      "learning_rate": 2.9592857142857143e-05,
      "loss": 0.0014,
      "step": 28570
    },
    {
      "epoch": 0.8165714285714286,
      "grad_norm": 0.10864578932523727,
      "learning_rate": 2.9585714285714288e-05,
      "loss": 0.0005,
      "step": 28580
    },
    {
      "epoch": 0.8168571428571428,
      "grad_norm": 0.08118456602096558,
      "learning_rate": 2.9578571428571426e-05,
      "loss": 0.0017,
      "step": 28590
    },
    {
      "epoch": 0.8171428571428572,
      "grad_norm": 0.04546481370925903,
      "learning_rate": 2.957142857142857e-05,
      "loss": 0.001,
      "step": 28600
    },
    {
      "epoch": 0.8174285714285714,
      "grad_norm": 0.03765163570642471,
      "learning_rate": 2.9564285714285717e-05,
      "loss": 0.0014,
      "step": 28610
    },
    {
      "epoch": 0.8177142857142857,
      "grad_norm": 0.08162691444158554,
      "learning_rate": 2.955714285714286e-05,
      "loss": 0.0014,
      "step": 28620
    },
    {
      "epoch": 0.818,
      "grad_norm": 0.0439508818089962,
      "learning_rate": 2.955e-05,
      "loss": 0.0032,
      "step": 28630
    },
    {
      "epoch": 0.8182857142857143,
      "grad_norm": 0.0,
      "learning_rate": 2.9542857142857145e-05,
      "loss": 0.0012,
      "step": 28640
    },
    {
      "epoch": 0.8185714285714286,
      "grad_norm": 0.34198445081710815,
      "learning_rate": 2.953571428571429e-05,
      "loss": 0.0021,
      "step": 28650
    },
    {
      "epoch": 0.8188571428571428,
      "grad_norm": 0.020253773778676987,
      "learning_rate": 2.952857142857143e-05,
      "loss": 0.0026,
      "step": 28660
    },
    {
      "epoch": 0.8191428571428572,
      "grad_norm": 0.07141122221946716,
      "learning_rate": 2.9521428571428574e-05,
      "loss": 0.0013,
      "step": 28670
    },
    {
      "epoch": 0.8194285714285714,
      "grad_norm": 0.0,
      "learning_rate": 2.9514285714285715e-05,
      "loss": 0.0023,
      "step": 28680
    },
    {
      "epoch": 0.8197142857142857,
      "grad_norm": 0.0,
      "learning_rate": 2.950714285714286e-05,
      "loss": 0.001,
      "step": 28690
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.10166749358177185,
      "learning_rate": 2.95e-05,
      "loss": 0.0009,
      "step": 28700
    },
    {
      "epoch": 0.8202857142857143,
      "grad_norm": 0.12209460139274597,
      "learning_rate": 2.9492857142857144e-05,
      "loss": 0.002,
      "step": 28710
    },
    {
      "epoch": 0.8205714285714286,
      "grad_norm": 0.04767613485455513,
      "learning_rate": 2.948571428571429e-05,
      "loss": 0.0006,
      "step": 28720
    },
    {
      "epoch": 0.8208571428571428,
      "grad_norm": 0.04588291049003601,
      "learning_rate": 2.9478571428571427e-05,
      "loss": 0.0011,
      "step": 28730
    },
    {
      "epoch": 0.8211428571428572,
      "grad_norm": 0.0,
      "learning_rate": 2.9471428571428572e-05,
      "loss": 0.0027,
      "step": 28740
    },
    {
      "epoch": 0.8214285714285714,
      "grad_norm": 0.20257575809955597,
      "learning_rate": 2.9464285714285718e-05,
      "loss": 0.0005,
      "step": 28750
    },
    {
      "epoch": 0.8217142857142857,
      "grad_norm": 0.0,
      "learning_rate": 2.9457142857142863e-05,
      "loss": 0.0009,
      "step": 28760
    },
    {
      "epoch": 0.822,
      "grad_norm": 0.04350997880101204,
      "learning_rate": 2.945e-05,
      "loss": 0.0011,
      "step": 28770
    },
    {
      "epoch": 0.8222857142857143,
      "grad_norm": 0.0462961420416832,
      "learning_rate": 2.9442857142857143e-05,
      "loss": 0.0022,
      "step": 28780
    },
    {
      "epoch": 0.8225714285714286,
      "grad_norm": 0.17208679020404816,
      "learning_rate": 2.9435714285714288e-05,
      "loss": 0.0013,
      "step": 28790
    },
    {
      "epoch": 0.8228571428571428,
      "grad_norm": 0.029848024249076843,
      "learning_rate": 2.9428571428571426e-05,
      "loss": 0.0015,
      "step": 28800
    },
    {
      "epoch": 0.8231428571428572,
      "grad_norm": 0.08591927587985992,
      "learning_rate": 2.942142857142857e-05,
      "loss": 0.0011,
      "step": 28810
    },
    {
      "epoch": 0.8234285714285714,
      "grad_norm": 0.03906413912773132,
      "learning_rate": 2.9414285714285716e-05,
      "loss": 0.0018,
      "step": 28820
    },
    {
      "epoch": 0.8237142857142857,
      "grad_norm": 0.018468566238880157,
      "learning_rate": 2.940714285714286e-05,
      "loss": 0.0011,
      "step": 28830
    },
    {
      "epoch": 0.824,
      "grad_norm": 0.04114441201090813,
      "learning_rate": 2.94e-05,
      "loss": 0.0019,
      "step": 28840
    },
    {
      "epoch": 0.8242857142857143,
      "grad_norm": 0.15196213126182556,
      "learning_rate": 2.9392857142857145e-05,
      "loss": 0.0011,
      "step": 28850
    },
    {
      "epoch": 0.8245714285714286,
      "grad_norm": 0.14674872159957886,
      "learning_rate": 2.938571428571429e-05,
      "loss": 0.0014,
      "step": 28860
    },
    {
      "epoch": 0.8248571428571428,
      "grad_norm": 0.3382347822189331,
      "learning_rate": 2.9378571428571428e-05,
      "loss": 0.001,
      "step": 28870
    },
    {
      "epoch": 0.8251428571428572,
      "grad_norm": 0.25385501980781555,
      "learning_rate": 2.9371428571428573e-05,
      "loss": 0.0014,
      "step": 28880
    },
    {
      "epoch": 0.8254285714285714,
      "grad_norm": 0.047506242990493774,
      "learning_rate": 2.9364285714285715e-05,
      "loss": 0.0022,
      "step": 28890
    },
    {
      "epoch": 0.8257142857142857,
      "grad_norm": 0.09361643344163895,
      "learning_rate": 2.935714285714286e-05,
      "loss": 0.0007,
      "step": 28900
    },
    {
      "epoch": 0.826,
      "grad_norm": 0.17877577245235443,
      "learning_rate": 2.935e-05,
      "loss": 0.0015,
      "step": 28910
    },
    {
      "epoch": 0.8262857142857143,
      "grad_norm": 0.083042211830616,
      "learning_rate": 2.9342857142857144e-05,
      "loss": 0.002,
      "step": 28920
    },
    {
      "epoch": 0.8265714285714286,
      "grad_norm": 0.08576834201812744,
      "learning_rate": 2.933571428571429e-05,
      "loss": 0.002,
      "step": 28930
    },
    {
      "epoch": 0.8268571428571428,
      "grad_norm": 0.249745711684227,
      "learning_rate": 2.9328571428571427e-05,
      "loss": 0.0019,
      "step": 28940
    },
    {
      "epoch": 0.8271428571428572,
      "grad_norm": 0.02098134718835354,
      "learning_rate": 2.9321428571428572e-05,
      "loss": 0.0022,
      "step": 28950
    },
    {
      "epoch": 0.8274285714285714,
      "grad_norm": 0.046495482325553894,
      "learning_rate": 2.9314285714285717e-05,
      "loss": 0.0019,
      "step": 28960
    },
    {
      "epoch": 0.8277142857142857,
      "grad_norm": 0.09045209735631943,
      "learning_rate": 2.9307142857142862e-05,
      "loss": 0.0031,
      "step": 28970
    },
    {
      "epoch": 0.828,
      "grad_norm": 0.07479462027549744,
      "learning_rate": 2.93e-05,
      "loss": 0.0009,
      "step": 28980
    },
    {
      "epoch": 0.8282857142857143,
      "grad_norm": 0.058209557086229324,
      "learning_rate": 2.9292857142857146e-05,
      "loss": 0.0011,
      "step": 28990
    },
    {
      "epoch": 0.8285714285714286,
      "grad_norm": 0.057901930063962936,
      "learning_rate": 2.9285714285714288e-05,
      "loss": 0.0011,
      "step": 29000
    },
    {
      "epoch": 0.8288571428571428,
      "grad_norm": 0.08491700887680054,
      "learning_rate": 2.9278571428571426e-05,
      "loss": 0.002,
      "step": 29010
    },
    {
      "epoch": 0.8291428571428572,
      "grad_norm": 0.0,
      "learning_rate": 2.927142857142857e-05,
      "loss": 0.0012,
      "step": 29020
    },
    {
      "epoch": 0.8294285714285714,
      "grad_norm": 0.048038795590400696,
      "learning_rate": 2.9264285714285716e-05,
      "loss": 0.0013,
      "step": 29030
    },
    {
      "epoch": 0.8297142857142857,
      "grad_norm": 0.0,
      "learning_rate": 2.925714285714286e-05,
      "loss": 0.0017,
      "step": 29040
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.2788091003894806,
      "learning_rate": 2.925e-05,
      "loss": 0.0015,
      "step": 29050
    },
    {
      "epoch": 0.8302857142857143,
      "grad_norm": 0.0,
      "learning_rate": 2.9242857142857145e-05,
      "loss": 0.0016,
      "step": 29060
    },
    {
      "epoch": 0.8305714285714285,
      "grad_norm": 0.052065905183553696,
      "learning_rate": 2.923571428571429e-05,
      "loss": 0.0012,
      "step": 29070
    },
    {
      "epoch": 0.8308571428571428,
      "grad_norm": 0.13866111636161804,
      "learning_rate": 2.9228571428571428e-05,
      "loss": 0.001,
      "step": 29080
    },
    {
      "epoch": 0.8311428571428572,
      "grad_norm": 0.052066609263420105,
      "learning_rate": 2.9221428571428573e-05,
      "loss": 0.0012,
      "step": 29090
    },
    {
      "epoch": 0.8314285714285714,
      "grad_norm": 0.10346358269453049,
      "learning_rate": 2.9214285714285715e-05,
      "loss": 0.0008,
      "step": 29100
    },
    {
      "epoch": 0.8317142857142857,
      "grad_norm": 0.04632309079170227,
      "learning_rate": 2.920714285714286e-05,
      "loss": 0.001,
      "step": 29110
    },
    {
      "epoch": 0.832,
      "grad_norm": 0.15245184302330017,
      "learning_rate": 2.9199999999999998e-05,
      "loss": 0.0024,
      "step": 29120
    },
    {
      "epoch": 0.8322857142857143,
      "grad_norm": 0.044525448232889175,
      "learning_rate": 2.9192857142857143e-05,
      "loss": 0.0006,
      "step": 29130
    },
    {
      "epoch": 0.8325714285714285,
      "grad_norm": 0.0,
      "learning_rate": 2.918571428571429e-05,
      "loss": 0.0019,
      "step": 29140
    },
    {
      "epoch": 0.8328571428571429,
      "grad_norm": 0.24690057337284088,
      "learning_rate": 2.9178571428571427e-05,
      "loss": 0.0015,
      "step": 29150
    },
    {
      "epoch": 0.8331428571428572,
      "grad_norm": 0.0,
      "learning_rate": 2.9171428571428572e-05,
      "loss": 0.0005,
      "step": 29160
    },
    {
      "epoch": 0.8334285714285714,
      "grad_norm": 0.0,
      "learning_rate": 2.9164285714285717e-05,
      "loss": 0.0021,
      "step": 29170
    },
    {
      "epoch": 0.8337142857142857,
      "grad_norm": 0.08579089492559433,
      "learning_rate": 2.9157142857142862e-05,
      "loss": 0.0025,
      "step": 29180
    },
    {
      "epoch": 0.834,
      "grad_norm": 0.0720515325665474,
      "learning_rate": 2.915e-05,
      "loss": 0.0006,
      "step": 29190
    },
    {
      "epoch": 0.8342857142857143,
      "grad_norm": 0.0,
      "learning_rate": 2.9142857142857146e-05,
      "loss": 0.0015,
      "step": 29200
    },
    {
      "epoch": 0.8345714285714285,
      "grad_norm": 0.0,
      "learning_rate": 2.9135714285714287e-05,
      "loss": 0.0014,
      "step": 29210
    },
    {
      "epoch": 0.8348571428571429,
      "grad_norm": 0.11912043392658234,
      "learning_rate": 2.912857142857143e-05,
      "loss": 0.001,
      "step": 29220
    },
    {
      "epoch": 0.8351428571428572,
      "grad_norm": 0.046751245856285095,
      "learning_rate": 2.912142857142857e-05,
      "loss": 0.0016,
      "step": 29230
    },
    {
      "epoch": 0.8354285714285714,
      "grad_norm": 0.17833222448825836,
      "learning_rate": 2.9114285714285716e-05,
      "loss": 0.001,
      "step": 29240
    },
    {
      "epoch": 0.8357142857142857,
      "grad_norm": 0.04582955315709114,
      "learning_rate": 2.910714285714286e-05,
      "loss": 0.002,
      "step": 29250
    },
    {
      "epoch": 0.836,
      "grad_norm": 0.25213173031806946,
      "learning_rate": 2.91e-05,
      "loss": 0.0016,
      "step": 29260
    },
    {
      "epoch": 0.8362857142857143,
      "grad_norm": 0.0,
      "learning_rate": 2.9092857142857144e-05,
      "loss": 0.0012,
      "step": 29270
    },
    {
      "epoch": 0.8365714285714285,
      "grad_norm": 0.0,
      "learning_rate": 2.908571428571429e-05,
      "loss": 0.0009,
      "step": 29280
    },
    {
      "epoch": 0.8368571428571429,
      "grad_norm": 0.042851146310567856,
      "learning_rate": 2.9078571428571428e-05,
      "loss": 0.0009,
      "step": 29290
    },
    {
      "epoch": 0.8371428571428572,
      "grad_norm": 0.08369540423154831,
      "learning_rate": 2.9071428571428573e-05,
      "loss": 0.0013,
      "step": 29300
    },
    {
      "epoch": 0.8374285714285714,
      "grad_norm": 0.3887632489204407,
      "learning_rate": 2.9064285714285715e-05,
      "loss": 0.0022,
      "step": 29310
    },
    {
      "epoch": 0.8377142857142857,
      "grad_norm": 0.0,
      "learning_rate": 2.905714285714286e-05,
      "loss": 0.0012,
      "step": 29320
    },
    {
      "epoch": 0.838,
      "grad_norm": 0.0,
      "learning_rate": 2.9049999999999998e-05,
      "loss": 0.0014,
      "step": 29330
    },
    {
      "epoch": 0.8382857142857143,
      "grad_norm": 0.13365064561367035,
      "learning_rate": 2.9042857142857143e-05,
      "loss": 0.0011,
      "step": 29340
    },
    {
      "epoch": 0.8385714285714285,
      "grad_norm": 0.10327041894197464,
      "learning_rate": 2.9035714285714288e-05,
      "loss": 0.0012,
      "step": 29350
    },
    {
      "epoch": 0.8388571428571429,
      "grad_norm": 0.18284901976585388,
      "learning_rate": 2.9028571428571427e-05,
      "loss": 0.0009,
      "step": 29360
    },
    {
      "epoch": 0.8391428571428572,
      "grad_norm": 0.041326507925987244,
      "learning_rate": 2.902142857142857e-05,
      "loss": 0.0013,
      "step": 29370
    },
    {
      "epoch": 0.8394285714285714,
      "grad_norm": 0.045787930488586426,
      "learning_rate": 2.9014285714285717e-05,
      "loss": 0.001,
      "step": 29380
    },
    {
      "epoch": 0.8397142857142857,
      "grad_norm": 0.0,
      "learning_rate": 2.9007142857142862e-05,
      "loss": 0.0013,
      "step": 29390
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.0,
      "learning_rate": 2.9e-05,
      "loss": 0.001,
      "step": 29400
    },
    {
      "epoch": 0.8402857142857143,
      "grad_norm": 0.1992952674627304,
      "learning_rate": 2.8992857142857145e-05,
      "loss": 0.0021,
      "step": 29410
    },
    {
      "epoch": 0.8405714285714285,
      "grad_norm": 0.044269368052482605,
      "learning_rate": 2.8985714285714287e-05,
      "loss": 0.0009,
      "step": 29420
    },
    {
      "epoch": 0.8408571428571429,
      "grad_norm": 0.16007167100906372,
      "learning_rate": 2.8978571428571432e-05,
      "loss": 0.0014,
      "step": 29430
    },
    {
      "epoch": 0.8411428571428572,
      "grad_norm": 0.18316049873828888,
      "learning_rate": 2.897142857142857e-05,
      "loss": 0.0011,
      "step": 29440
    },
    {
      "epoch": 0.8414285714285714,
      "grad_norm": 0.024744002148509026,
      "learning_rate": 2.8964285714285716e-05,
      "loss": 0.0005,
      "step": 29450
    },
    {
      "epoch": 0.8417142857142857,
      "grad_norm": 0.30439794063568115,
      "learning_rate": 2.895714285714286e-05,
      "loss": 0.0015,
      "step": 29460
    },
    {
      "epoch": 0.842,
      "grad_norm": 0.041782278567552567,
      "learning_rate": 2.895e-05,
      "loss": 0.0024,
      "step": 29470
    },
    {
      "epoch": 0.8422857142857143,
      "grad_norm": 0.12938469648361206,
      "learning_rate": 2.8942857142857144e-05,
      "loss": 0.0011,
      "step": 29480
    },
    {
      "epoch": 0.8425714285714285,
      "grad_norm": 0.12243478000164032,
      "learning_rate": 2.893571428571429e-05,
      "loss": 0.0024,
      "step": 29490
    },
    {
      "epoch": 0.8428571428571429,
      "grad_norm": 0.040860556066036224,
      "learning_rate": 2.8928571428571434e-05,
      "loss": 0.0009,
      "step": 29500
    },
    {
      "epoch": 0.8431428571428572,
      "grad_norm": 0.2158542424440384,
      "learning_rate": 2.8921428571428573e-05,
      "loss": 0.0009,
      "step": 29510
    },
    {
      "epoch": 0.8434285714285714,
      "grad_norm": 0.02570461854338646,
      "learning_rate": 2.8914285714285714e-05,
      "loss": 0.0019,
      "step": 29520
    },
    {
      "epoch": 0.8437142857142857,
      "grad_norm": 0.08445653319358826,
      "learning_rate": 2.890714285714286e-05,
      "loss": 0.0019,
      "step": 29530
    },
    {
      "epoch": 0.844,
      "grad_norm": 0.0783315971493721,
      "learning_rate": 2.8899999999999998e-05,
      "loss": 0.0024,
      "step": 29540
    },
    {
      "epoch": 0.8442857142857143,
      "grad_norm": 0.04970340430736542,
      "learning_rate": 2.8892857142857143e-05,
      "loss": 0.0021,
      "step": 29550
    },
    {
      "epoch": 0.8445714285714285,
      "grad_norm": 0.0,
      "learning_rate": 2.8885714285714288e-05,
      "loss": 0.0015,
      "step": 29560
    },
    {
      "epoch": 0.8448571428571429,
      "grad_norm": 0.0,
      "learning_rate": 2.8878571428571433e-05,
      "loss": 0.0009,
      "step": 29570
    },
    {
      "epoch": 0.8451428571428572,
      "grad_norm": 0.03965688496828079,
      "learning_rate": 2.887142857142857e-05,
      "loss": 0.0016,
      "step": 29580
    },
    {
      "epoch": 0.8454285714285714,
      "grad_norm": 0.0,
      "learning_rate": 2.8864285714285716e-05,
      "loss": 0.0005,
      "step": 29590
    },
    {
      "epoch": 0.8457142857142858,
      "grad_norm": 0.05485452711582184,
      "learning_rate": 2.885714285714286e-05,
      "loss": 0.001,
      "step": 29600
    },
    {
      "epoch": 0.846,
      "grad_norm": 0.03225145488977432,
      "learning_rate": 2.885e-05,
      "loss": 0.002,
      "step": 29610
    },
    {
      "epoch": 0.8462857142857143,
      "grad_norm": 0.3876517117023468,
      "learning_rate": 2.8842857142857145e-05,
      "loss": 0.0016,
      "step": 29620
    },
    {
      "epoch": 0.8465714285714285,
      "grad_norm": 0.0,
      "learning_rate": 2.8835714285714287e-05,
      "loss": 0.0022,
      "step": 29630
    },
    {
      "epoch": 0.8468571428571429,
      "grad_norm": 0.13260899484157562,
      "learning_rate": 2.8828571428571432e-05,
      "loss": 0.0016,
      "step": 29640
    },
    {
      "epoch": 0.8471428571428572,
      "grad_norm": 0.0743078887462616,
      "learning_rate": 2.882142857142857e-05,
      "loss": 0.0016,
      "step": 29650
    },
    {
      "epoch": 0.8474285714285714,
      "grad_norm": 0.20568479597568512,
      "learning_rate": 2.8814285714285715e-05,
      "loss": 0.002,
      "step": 29660
    },
    {
      "epoch": 0.8477142857142858,
      "grad_norm": 0.087100088596344,
      "learning_rate": 2.880714285714286e-05,
      "loss": 0.0016,
      "step": 29670
    },
    {
      "epoch": 0.848,
      "grad_norm": 0.1669464260339737,
      "learning_rate": 2.88e-05,
      "loss": 0.0017,
      "step": 29680
    },
    {
      "epoch": 0.8482857142857143,
      "grad_norm": 0.0,
      "learning_rate": 2.8792857142857144e-05,
      "loss": 0.0013,
      "step": 29690
    },
    {
      "epoch": 0.8485714285714285,
      "grad_norm": 0.21505993604660034,
      "learning_rate": 2.878571428571429e-05,
      "loss": 0.001,
      "step": 29700
    },
    {
      "epoch": 0.8488571428571429,
      "grad_norm": 0.08526188880205154,
      "learning_rate": 2.8778571428571434e-05,
      "loss": 0.0018,
      "step": 29710
    },
    {
      "epoch": 0.8491428571428571,
      "grad_norm": 0.03442627564072609,
      "learning_rate": 2.8771428571428572e-05,
      "loss": 0.0012,
      "step": 29720
    },
    {
      "epoch": 0.8494285714285714,
      "grad_norm": 0.11908821016550064,
      "learning_rate": 2.8764285714285717e-05,
      "loss": 0.0011,
      "step": 29730
    },
    {
      "epoch": 0.8497142857142858,
      "grad_norm": 0.04115765169262886,
      "learning_rate": 2.875714285714286e-05,
      "loss": 0.0015,
      "step": 29740
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.05244961008429527,
      "learning_rate": 2.8749999999999997e-05,
      "loss": 0.002,
      "step": 29750
    },
    {
      "epoch": 0.8502857142857143,
      "grad_norm": 0.31039661169052124,
      "learning_rate": 2.8742857142857143e-05,
      "loss": 0.001,
      "step": 29760
    },
    {
      "epoch": 0.8505714285714285,
      "grad_norm": 0.04818275570869446,
      "learning_rate": 2.8735714285714288e-05,
      "loss": 0.0006,
      "step": 29770
    },
    {
      "epoch": 0.8508571428571429,
      "grad_norm": 0.09141724556684494,
      "learning_rate": 2.8728571428571433e-05,
      "loss": 0.0016,
      "step": 29780
    },
    {
      "epoch": 0.8511428571428571,
      "grad_norm": 0.04701203480362892,
      "learning_rate": 2.872142857142857e-05,
      "loss": 0.0007,
      "step": 29790
    },
    {
      "epoch": 0.8514285714285714,
      "grad_norm": 0.0,
      "learning_rate": 2.8714285714285716e-05,
      "loss": 0.0014,
      "step": 29800
    },
    {
      "epoch": 0.8517142857142858,
      "grad_norm": 0.11056211590766907,
      "learning_rate": 2.870714285714286e-05,
      "loss": 0.0015,
      "step": 29810
    },
    {
      "epoch": 0.852,
      "grad_norm": 0.031285591423511505,
      "learning_rate": 2.87e-05,
      "loss": 0.0014,
      "step": 29820
    },
    {
      "epoch": 0.8522857142857143,
      "grad_norm": 0.12110854685306549,
      "learning_rate": 2.8692857142857145e-05,
      "loss": 0.0009,
      "step": 29830
    },
    {
      "epoch": 0.8525714285714285,
      "grad_norm": 0.04674861580133438,
      "learning_rate": 2.8685714285714286e-05,
      "loss": 0.0011,
      "step": 29840
    },
    {
      "epoch": 0.8528571428571429,
      "grad_norm": 0.05607118457555771,
      "learning_rate": 2.867857142857143e-05,
      "loss": 0.0021,
      "step": 29850
    },
    {
      "epoch": 0.8531428571428571,
      "grad_norm": 0.043815065175294876,
      "learning_rate": 2.867142857142857e-05,
      "loss": 0.0013,
      "step": 29860
    },
    {
      "epoch": 0.8534285714285714,
      "grad_norm": 0.08627429604530334,
      "learning_rate": 2.8664285714285715e-05,
      "loss": 0.001,
      "step": 29870
    },
    {
      "epoch": 0.8537142857142858,
      "grad_norm": 0.031144728884100914,
      "learning_rate": 2.865714285714286e-05,
      "loss": 0.0007,
      "step": 29880
    },
    {
      "epoch": 0.854,
      "grad_norm": 0.08905603736639023,
      "learning_rate": 2.865e-05,
      "loss": 0.0016,
      "step": 29890
    },
    {
      "epoch": 0.8542857142857143,
      "grad_norm": 0.08874664455652237,
      "learning_rate": 2.8642857142857144e-05,
      "loss": 0.001,
      "step": 29900
    },
    {
      "epoch": 0.8545714285714285,
      "grad_norm": 0.041401129215955734,
      "learning_rate": 2.863571428571429e-05,
      "loss": 0.0012,
      "step": 29910
    },
    {
      "epoch": 0.8548571428571429,
      "grad_norm": 0.034689392894506454,
      "learning_rate": 2.8628571428571434e-05,
      "loss": 0.0018,
      "step": 29920
    },
    {
      "epoch": 0.8551428571428571,
      "grad_norm": 0.0,
      "learning_rate": 2.8621428571428572e-05,
      "loss": 0.001,
      "step": 29930
    },
    {
      "epoch": 0.8554285714285714,
      "grad_norm": 0.11657946556806564,
      "learning_rate": 2.8614285714285717e-05,
      "loss": 0.0012,
      "step": 29940
    },
    {
      "epoch": 0.8557142857142858,
      "grad_norm": 0.11880061775445938,
      "learning_rate": 2.860714285714286e-05,
      "loss": 0.0029,
      "step": 29950
    },
    {
      "epoch": 0.856,
      "grad_norm": 0.17877763509750366,
      "learning_rate": 2.86e-05,
      "loss": 0.0037,
      "step": 29960
    },
    {
      "epoch": 0.8562857142857143,
      "grad_norm": 0.2214287519454956,
      "learning_rate": 2.8592857142857142e-05,
      "loss": 0.0018,
      "step": 29970
    },
    {
      "epoch": 0.8565714285714285,
      "grad_norm": 0.04322507604956627,
      "learning_rate": 2.8585714285714287e-05,
      "loss": 0.0012,
      "step": 29980
    },
    {
      "epoch": 0.8568571428571429,
      "grad_norm": 0.08911871165037155,
      "learning_rate": 2.8578571428571433e-05,
      "loss": 0.0016,
      "step": 29990
    },
    {
      "epoch": 0.8571428571428571,
      "grad_norm": 0.03271603584289551,
      "learning_rate": 2.857142857142857e-05,
      "loss": 0.002,
      "step": 30000
    },
    {
      "epoch": 0.8574285714285714,
      "grad_norm": 0.02428044192492962,
      "learning_rate": 2.8564285714285716e-05,
      "loss": 0.0002,
      "step": 30010
    },
    {
      "epoch": 0.8577142857142858,
      "grad_norm": 0.32412514090538025,
      "learning_rate": 2.855714285714286e-05,
      "loss": 0.0013,
      "step": 30020
    },
    {
      "epoch": 0.858,
      "grad_norm": 0.0,
      "learning_rate": 2.855e-05,
      "loss": 0.0009,
      "step": 30030
    },
    {
      "epoch": 0.8582857142857143,
      "grad_norm": 0.0,
      "learning_rate": 2.8542857142857144e-05,
      "loss": 0.001,
      "step": 30040
    },
    {
      "epoch": 0.8585714285714285,
      "grad_norm": 0.07920167595148087,
      "learning_rate": 2.8535714285714286e-05,
      "loss": 0.0017,
      "step": 30050
    },
    {
      "epoch": 0.8588571428571429,
      "grad_norm": 0.12224201112985611,
      "learning_rate": 2.852857142857143e-05,
      "loss": 0.0021,
      "step": 30060
    },
    {
      "epoch": 0.8591428571428571,
      "grad_norm": 0.0,
      "learning_rate": 2.852142857142857e-05,
      "loss": 0.0009,
      "step": 30070
    },
    {
      "epoch": 0.8594285714285714,
      "grad_norm": 0.09348475188016891,
      "learning_rate": 2.8514285714285715e-05,
      "loss": 0.0011,
      "step": 30080
    },
    {
      "epoch": 0.8597142857142858,
      "grad_norm": 0.05487048253417015,
      "learning_rate": 2.850714285714286e-05,
      "loss": 0.0016,
      "step": 30090
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.0,
      "learning_rate": 2.8499999999999998e-05,
      "loss": 0.0013,
      "step": 30100
    },
    {
      "epoch": 0.8602857142857143,
      "grad_norm": 0.04994121566414833,
      "learning_rate": 2.8492857142857143e-05,
      "loss": 0.0011,
      "step": 30110
    },
    {
      "epoch": 0.8605714285714285,
      "grad_norm": 0.044373076409101486,
      "learning_rate": 2.848571428571429e-05,
      "loss": 0.0036,
      "step": 30120
    },
    {
      "epoch": 0.8608571428571429,
      "grad_norm": 0.14616265892982483,
      "learning_rate": 2.8478571428571433e-05,
      "loss": 0.0014,
      "step": 30130
    },
    {
      "epoch": 0.8611428571428571,
      "grad_norm": 0.08602002263069153,
      "learning_rate": 2.8471428571428572e-05,
      "loss": 0.0015,
      "step": 30140
    },
    {
      "epoch": 0.8614285714285714,
      "grad_norm": 0.283225417137146,
      "learning_rate": 2.8464285714285717e-05,
      "loss": 0.0026,
      "step": 30150
    },
    {
      "epoch": 0.8617142857142858,
      "grad_norm": 0.03974825516343117,
      "learning_rate": 2.845714285714286e-05,
      "loss": 0.001,
      "step": 30160
    },
    {
      "epoch": 0.862,
      "grad_norm": 0.0453081876039505,
      "learning_rate": 2.845e-05,
      "loss": 0.002,
      "step": 30170
    },
    {
      "epoch": 0.8622857142857143,
      "grad_norm": 0.040608543902635574,
      "learning_rate": 2.8442857142857142e-05,
      "loss": 0.001,
      "step": 30180
    },
    {
      "epoch": 0.8625714285714285,
      "grad_norm": 0.0,
      "learning_rate": 2.8435714285714287e-05,
      "loss": 0.0006,
      "step": 30190
    },
    {
      "epoch": 0.8628571428571429,
      "grad_norm": 0.04761014133691788,
      "learning_rate": 2.8428571428571432e-05,
      "loss": 0.0003,
      "step": 30200
    },
    {
      "epoch": 0.8631428571428571,
      "grad_norm": 0.0,
      "learning_rate": 2.842142857142857e-05,
      "loss": 0.002,
      "step": 30210
    },
    {
      "epoch": 0.8634285714285714,
      "grad_norm": 0.060351382941007614,
      "learning_rate": 2.8414285714285716e-05,
      "loss": 0.0018,
      "step": 30220
    },
    {
      "epoch": 0.8637142857142858,
      "grad_norm": 0.310693621635437,
      "learning_rate": 2.840714285714286e-05,
      "loss": 0.0024,
      "step": 30230
    },
    {
      "epoch": 0.864,
      "grad_norm": 0.1220552921295166,
      "learning_rate": 2.84e-05,
      "loss": 0.002,
      "step": 30240
    },
    {
      "epoch": 0.8642857142857143,
      "grad_norm": 0.12205497920513153,
      "learning_rate": 2.8392857142857144e-05,
      "loss": 0.0013,
      "step": 30250
    },
    {
      "epoch": 0.8645714285714285,
      "grad_norm": 0.24072349071502686,
      "learning_rate": 2.838571428571429e-05,
      "loss": 0.0012,
      "step": 30260
    },
    {
      "epoch": 0.8648571428571429,
      "grad_norm": 0.04380565881729126,
      "learning_rate": 2.837857142857143e-05,
      "loss": 0.0015,
      "step": 30270
    },
    {
      "epoch": 0.8651428571428571,
      "grad_norm": 0.30533966422080994,
      "learning_rate": 2.837142857142857e-05,
      "loss": 0.001,
      "step": 30280
    },
    {
      "epoch": 0.8654285714285714,
      "grad_norm": 0.050079528242349625,
      "learning_rate": 2.8364285714285714e-05,
      "loss": 0.0012,
      "step": 30290
    },
    {
      "epoch": 0.8657142857142858,
      "grad_norm": 0.35011231899261475,
      "learning_rate": 2.835714285714286e-05,
      "loss": 0.0025,
      "step": 30300
    },
    {
      "epoch": 0.866,
      "grad_norm": 0.24062232673168182,
      "learning_rate": 2.8349999999999998e-05,
      "loss": 0.002,
      "step": 30310
    },
    {
      "epoch": 0.8662857142857143,
      "grad_norm": 0.0,
      "learning_rate": 2.8342857142857143e-05,
      "loss": 0.0015,
      "step": 30320
    },
    {
      "epoch": 0.8665714285714285,
      "grad_norm": 0.030008666217327118,
      "learning_rate": 2.8335714285714288e-05,
      "loss": 0.0015,
      "step": 30330
    },
    {
      "epoch": 0.8668571428571429,
      "grad_norm": 0.11851591616868973,
      "learning_rate": 2.8328571428571433e-05,
      "loss": 0.0026,
      "step": 30340
    },
    {
      "epoch": 0.8671428571428571,
      "grad_norm": 0.20325390994548798,
      "learning_rate": 2.832142857142857e-05,
      "loss": 0.0013,
      "step": 30350
    },
    {
      "epoch": 0.8674285714285714,
      "grad_norm": 0.0,
      "learning_rate": 2.8314285714285717e-05,
      "loss": 0.0023,
      "step": 30360
    },
    {
      "epoch": 0.8677142857142857,
      "grad_norm": 0.0,
      "learning_rate": 2.830714285714286e-05,
      "loss": 0.001,
      "step": 30370
    },
    {
      "epoch": 0.868,
      "grad_norm": 0.4187546372413635,
      "learning_rate": 2.83e-05,
      "loss": 0.0005,
      "step": 30380
    },
    {
      "epoch": 0.8682857142857143,
      "grad_norm": 0.02200818620622158,
      "learning_rate": 2.8292857142857142e-05,
      "loss": 0.0014,
      "step": 30390
    },
    {
      "epoch": 0.8685714285714285,
      "grad_norm": 0.04483325034379959,
      "learning_rate": 2.8285714285714287e-05,
      "loss": 0.0022,
      "step": 30400
    },
    {
      "epoch": 0.8688571428571429,
      "grad_norm": 0.18008136749267578,
      "learning_rate": 2.8278571428571432e-05,
      "loss": 0.0015,
      "step": 30410
    },
    {
      "epoch": 0.8691428571428571,
      "grad_norm": 0.03815315291285515,
      "learning_rate": 2.827142857142857e-05,
      "loss": 0.0016,
      "step": 30420
    },
    {
      "epoch": 0.8694285714285714,
      "grad_norm": 0.0439029298722744,
      "learning_rate": 2.8264285714285715e-05,
      "loss": 0.0024,
      "step": 30430
    },
    {
      "epoch": 0.8697142857142857,
      "grad_norm": 0.07965609431266785,
      "learning_rate": 2.825714285714286e-05,
      "loss": 0.0013,
      "step": 30440
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.06706064939498901,
      "learning_rate": 2.825e-05,
      "loss": 0.0025,
      "step": 30450
    },
    {
      "epoch": 0.8702857142857143,
      "grad_norm": 0.044974297285079956,
      "learning_rate": 2.8242857142857144e-05,
      "loss": 0.0018,
      "step": 30460
    },
    {
      "epoch": 0.8705714285714286,
      "grad_norm": 0.09813833236694336,
      "learning_rate": 2.823571428571429e-05,
      "loss": 0.0022,
      "step": 30470
    },
    {
      "epoch": 0.8708571428571429,
      "grad_norm": 0.07234307378530502,
      "learning_rate": 2.822857142857143e-05,
      "loss": 0.0006,
      "step": 30480
    },
    {
      "epoch": 0.8711428571428571,
      "grad_norm": 0.04625140503048897,
      "learning_rate": 2.8221428571428573e-05,
      "loss": 0.0007,
      "step": 30490
    },
    {
      "epoch": 0.8714285714285714,
      "grad_norm": 0.04253959655761719,
      "learning_rate": 2.8214285714285714e-05,
      "loss": 0.0011,
      "step": 30500
    },
    {
      "epoch": 0.8717142857142857,
      "grad_norm": 0.0,
      "learning_rate": 2.820714285714286e-05,
      "loss": 0.0016,
      "step": 30510
    },
    {
      "epoch": 0.872,
      "grad_norm": 0.0467878133058548,
      "learning_rate": 2.8199999999999998e-05,
      "loss": 0.0017,
      "step": 30520
    },
    {
      "epoch": 0.8722857142857143,
      "grad_norm": 0.22225432097911835,
      "learning_rate": 2.8192857142857143e-05,
      "loss": 0.0018,
      "step": 30530
    },
    {
      "epoch": 0.8725714285714286,
      "grad_norm": 0.23955242335796356,
      "learning_rate": 2.8185714285714288e-05,
      "loss": 0.0011,
      "step": 30540
    },
    {
      "epoch": 0.8728571428571429,
      "grad_norm": 0.0841720923781395,
      "learning_rate": 2.8178571428571433e-05,
      "loss": 0.0018,
      "step": 30550
    },
    {
      "epoch": 0.8731428571428571,
      "grad_norm": 0.23805385828018188,
      "learning_rate": 2.817142857142857e-05,
      "loss": 0.0013,
      "step": 30560
    },
    {
      "epoch": 0.8734285714285714,
      "grad_norm": 0.08278250694274902,
      "learning_rate": 2.8164285714285716e-05,
      "loss": 0.0008,
      "step": 30570
    },
    {
      "epoch": 0.8737142857142857,
      "grad_norm": 0.03899269551038742,
      "learning_rate": 2.8157142857142858e-05,
      "loss": 0.0008,
      "step": 30580
    },
    {
      "epoch": 0.874,
      "grad_norm": 0.2538315951824188,
      "learning_rate": 2.815e-05,
      "loss": 0.0007,
      "step": 30590
    },
    {
      "epoch": 0.8742857142857143,
      "grad_norm": 0.27268630266189575,
      "learning_rate": 2.814285714285714e-05,
      "loss": 0.0017,
      "step": 30600
    },
    {
      "epoch": 0.8745714285714286,
      "grad_norm": 0.0,
      "learning_rate": 2.8135714285714287e-05,
      "loss": 0.0015,
      "step": 30610
    },
    {
      "epoch": 0.8748571428571429,
      "grad_norm": 0.05699186399579048,
      "learning_rate": 2.8128571428571432e-05,
      "loss": 0.001,
      "step": 30620
    },
    {
      "epoch": 0.8751428571428571,
      "grad_norm": 0.10881361365318298,
      "learning_rate": 2.812142857142857e-05,
      "loss": 0.0021,
      "step": 30630
    },
    {
      "epoch": 0.8754285714285714,
      "grad_norm": 0.37387973070144653,
      "learning_rate": 2.8114285714285715e-05,
      "loss": 0.0011,
      "step": 30640
    },
    {
      "epoch": 0.8757142857142857,
      "grad_norm": 0.05469929799437523,
      "learning_rate": 2.810714285714286e-05,
      "loss": 0.0012,
      "step": 30650
    },
    {
      "epoch": 0.876,
      "grad_norm": 0.0,
      "learning_rate": 2.8100000000000005e-05,
      "loss": 0.0007,
      "step": 30660
    },
    {
      "epoch": 0.8762857142857143,
      "grad_norm": 0.28323569893836975,
      "learning_rate": 2.8092857142857144e-05,
      "loss": 0.0015,
      "step": 30670
    },
    {
      "epoch": 0.8765714285714286,
      "grad_norm": 0.0,
      "learning_rate": 2.808571428571429e-05,
      "loss": 0.0011,
      "step": 30680
    },
    {
      "epoch": 0.8768571428571429,
      "grad_norm": 0.42644035816192627,
      "learning_rate": 2.807857142857143e-05,
      "loss": 0.0008,
      "step": 30690
    },
    {
      "epoch": 0.8771428571428571,
      "grad_norm": 0.0,
      "learning_rate": 2.8071428571428572e-05,
      "loss": 0.0013,
      "step": 30700
    },
    {
      "epoch": 0.8774285714285714,
      "grad_norm": 0.0464436300098896,
      "learning_rate": 2.8064285714285714e-05,
      "loss": 0.001,
      "step": 30710
    },
    {
      "epoch": 0.8777142857142857,
      "grad_norm": 0.27080944180488586,
      "learning_rate": 2.805714285714286e-05,
      "loss": 0.0018,
      "step": 30720
    },
    {
      "epoch": 0.878,
      "grad_norm": 0.0,
      "learning_rate": 2.8050000000000004e-05,
      "loss": 0.0013,
      "step": 30730
    },
    {
      "epoch": 0.8782857142857143,
      "grad_norm": 0.0,
      "learning_rate": 2.8042857142857143e-05,
      "loss": 0.0012,
      "step": 30740
    },
    {
      "epoch": 0.8785714285714286,
      "grad_norm": 0.18281853199005127,
      "learning_rate": 2.8035714285714288e-05,
      "loss": 0.0012,
      "step": 30750
    },
    {
      "epoch": 0.8788571428571429,
      "grad_norm": 0.0,
      "learning_rate": 2.8028571428571433e-05,
      "loss": 0.002,
      "step": 30760
    },
    {
      "epoch": 0.8791428571428571,
      "grad_norm": 0.12742123007774353,
      "learning_rate": 2.802142857142857e-05,
      "loss": 0.0016,
      "step": 30770
    },
    {
      "epoch": 0.8794285714285714,
      "grad_norm": 0.16652874648571014,
      "learning_rate": 2.8014285714285716e-05,
      "loss": 0.001,
      "step": 30780
    },
    {
      "epoch": 0.8797142857142857,
      "grad_norm": 0.05884862318634987,
      "learning_rate": 2.800714285714286e-05,
      "loss": 0.0017,
      "step": 30790
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.0,
      "learning_rate": 2.8000000000000003e-05,
      "loss": 0.0018,
      "step": 30800
    },
    {
      "epoch": 0.8802857142857143,
      "grad_norm": 0.16655349731445312,
      "learning_rate": 2.799285714285714e-05,
      "loss": 0.0013,
      "step": 30810
    },
    {
      "epoch": 0.8805714285714286,
      "grad_norm": 0.0,
      "learning_rate": 2.7985714285714286e-05,
      "loss": 0.0017,
      "step": 30820
    },
    {
      "epoch": 0.8808571428571429,
      "grad_norm": 0.0,
      "learning_rate": 2.797857142857143e-05,
      "loss": 0.0011,
      "step": 30830
    },
    {
      "epoch": 0.8811428571428571,
      "grad_norm": 0.11871100962162018,
      "learning_rate": 2.797142857142857e-05,
      "loss": 0.0014,
      "step": 30840
    },
    {
      "epoch": 0.8814285714285715,
      "grad_norm": 0.0,
      "learning_rate": 2.7964285714285715e-05,
      "loss": 0.0012,
      "step": 30850
    },
    {
      "epoch": 0.8817142857142857,
      "grad_norm": 0.045378949493169785,
      "learning_rate": 2.795714285714286e-05,
      "loss": 0.0007,
      "step": 30860
    },
    {
      "epoch": 0.882,
      "grad_norm": 0.04698304831981659,
      "learning_rate": 2.7950000000000005e-05,
      "loss": 0.0013,
      "step": 30870
    },
    {
      "epoch": 0.8822857142857143,
      "grad_norm": 0.0765417292714119,
      "learning_rate": 2.7942857142857143e-05,
      "loss": 0.001,
      "step": 30880
    },
    {
      "epoch": 0.8825714285714286,
      "grad_norm": 0.0,
      "learning_rate": 2.793571428571429e-05,
      "loss": 0.0016,
      "step": 30890
    },
    {
      "epoch": 0.8828571428571429,
      "grad_norm": 0.04422210529446602,
      "learning_rate": 2.792857142857143e-05,
      "loss": 0.0028,
      "step": 30900
    },
    {
      "epoch": 0.8831428571428571,
      "grad_norm": 0.03297588601708412,
      "learning_rate": 2.7921428571428572e-05,
      "loss": 0.0006,
      "step": 30910
    },
    {
      "epoch": 0.8834285714285715,
      "grad_norm": 0.0,
      "learning_rate": 2.7914285714285714e-05,
      "loss": 0.0007,
      "step": 30920
    },
    {
      "epoch": 0.8837142857142857,
      "grad_norm": 0.1142120286822319,
      "learning_rate": 2.790714285714286e-05,
      "loss": 0.0014,
      "step": 30930
    },
    {
      "epoch": 0.884,
      "grad_norm": 0.2229205220937729,
      "learning_rate": 2.7900000000000004e-05,
      "loss": 0.002,
      "step": 30940
    },
    {
      "epoch": 0.8842857142857142,
      "grad_norm": 0.0,
      "learning_rate": 2.7892857142857142e-05,
      "loss": 0.0013,
      "step": 30950
    },
    {
      "epoch": 0.8845714285714286,
      "grad_norm": 0.032653436064720154,
      "learning_rate": 2.7885714285714287e-05,
      "loss": 0.0008,
      "step": 30960
    },
    {
      "epoch": 0.8848571428571429,
      "grad_norm": 0.23941092193126678,
      "learning_rate": 2.7878571428571432e-05,
      "loss": 0.0023,
      "step": 30970
    },
    {
      "epoch": 0.8851428571428571,
      "grad_norm": 0.11052118241786957,
      "learning_rate": 2.787142857142857e-05,
      "loss": 0.0021,
      "step": 30980
    },
    {
      "epoch": 0.8854285714285715,
      "grad_norm": 0.07227218151092529,
      "learning_rate": 2.7864285714285716e-05,
      "loss": 0.0016,
      "step": 30990
    },
    {
      "epoch": 0.8857142857142857,
      "grad_norm": 0.15484994649887085,
      "learning_rate": 2.785714285714286e-05,
      "loss": 0.0016,
      "step": 31000
    },
    {
      "epoch": 0.886,
      "grad_norm": 0.1729573756456375,
      "learning_rate": 2.7850000000000003e-05,
      "loss": 0.0016,
      "step": 31010
    },
    {
      "epoch": 0.8862857142857142,
      "grad_norm": 0.0538945272564888,
      "learning_rate": 2.7842857142857144e-05,
      "loss": 0.0009,
      "step": 31020
    },
    {
      "epoch": 0.8865714285714286,
      "grad_norm": 0.04420114681124687,
      "learning_rate": 2.7835714285714286e-05,
      "loss": 0.0012,
      "step": 31030
    },
    {
      "epoch": 0.8868571428571429,
      "grad_norm": 0.04397003725171089,
      "learning_rate": 2.782857142857143e-05,
      "loss": 0.0017,
      "step": 31040
    },
    {
      "epoch": 0.8871428571428571,
      "grad_norm": 0.126363143324852,
      "learning_rate": 2.782142857142857e-05,
      "loss": 0.0012,
      "step": 31050
    },
    {
      "epoch": 0.8874285714285715,
      "grad_norm": 0.0,
      "learning_rate": 2.7814285714285715e-05,
      "loss": 0.0011,
      "step": 31060
    },
    {
      "epoch": 0.8877142857142857,
      "grad_norm": 0.04273663088679314,
      "learning_rate": 2.780714285714286e-05,
      "loss": 0.0013,
      "step": 31070
    },
    {
      "epoch": 0.888,
      "grad_norm": 0.042903702706098557,
      "learning_rate": 2.7800000000000005e-05,
      "loss": 0.0008,
      "step": 31080
    },
    {
      "epoch": 0.8882857142857142,
      "grad_norm": 0.11974481493234634,
      "learning_rate": 2.7792857142857143e-05,
      "loss": 0.0014,
      "step": 31090
    },
    {
      "epoch": 0.8885714285714286,
      "grad_norm": 0.09096697717905045,
      "learning_rate": 2.778571428571429e-05,
      "loss": 0.0014,
      "step": 31100
    },
    {
      "epoch": 0.8888571428571429,
      "grad_norm": 0.0,
      "learning_rate": 2.777857142857143e-05,
      "loss": 0.0011,
      "step": 31110
    },
    {
      "epoch": 0.8891428571428571,
      "grad_norm": 0.06432276219129562,
      "learning_rate": 2.7771428571428572e-05,
      "loss": 0.001,
      "step": 31120
    },
    {
      "epoch": 0.8894285714285715,
      "grad_norm": 0.04079710692167282,
      "learning_rate": 2.7764285714285713e-05,
      "loss": 0.0017,
      "step": 31130
    },
    {
      "epoch": 0.8897142857142857,
      "grad_norm": 0.0,
      "learning_rate": 2.775714285714286e-05,
      "loss": 0.002,
      "step": 31140
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.08447343111038208,
      "learning_rate": 2.7750000000000004e-05,
      "loss": 0.0018,
      "step": 31150
    },
    {
      "epoch": 0.8902857142857142,
      "grad_norm": 0.2079228162765503,
      "learning_rate": 2.7742857142857142e-05,
      "loss": 0.0019,
      "step": 31160
    },
    {
      "epoch": 0.8905714285714286,
      "grad_norm": 0.26409125328063965,
      "learning_rate": 2.7735714285714287e-05,
      "loss": 0.0014,
      "step": 31170
    },
    {
      "epoch": 0.8908571428571429,
      "grad_norm": 0.041977155953645706,
      "learning_rate": 2.7728571428571432e-05,
      "loss": 0.0016,
      "step": 31180
    },
    {
      "epoch": 0.8911428571428571,
      "grad_norm": 0.0526394359767437,
      "learning_rate": 2.772142857142857e-05,
      "loss": 0.0009,
      "step": 31190
    },
    {
      "epoch": 0.8914285714285715,
      "grad_norm": 0.02048111893236637,
      "learning_rate": 2.7714285714285716e-05,
      "loss": 0.0022,
      "step": 31200
    },
    {
      "epoch": 0.8917142857142857,
      "grad_norm": 0.05715058743953705,
      "learning_rate": 2.770714285714286e-05,
      "loss": 0.0012,
      "step": 31210
    },
    {
      "epoch": 0.892,
      "grad_norm": 0.05207561329007149,
      "learning_rate": 2.7700000000000002e-05,
      "loss": 0.0013,
      "step": 31220
    },
    {
      "epoch": 0.8922857142857142,
      "grad_norm": 0.0,
      "learning_rate": 2.7692857142857144e-05,
      "loss": 0.0011,
      "step": 31230
    },
    {
      "epoch": 0.8925714285714286,
      "grad_norm": 0.05623820051550865,
      "learning_rate": 2.7685714285714286e-05,
      "loss": 0.0007,
      "step": 31240
    },
    {
      "epoch": 0.8928571428571429,
      "grad_norm": 0.045788154006004333,
      "learning_rate": 2.767857142857143e-05,
      "loss": 0.001,
      "step": 31250
    },
    {
      "epoch": 0.8931428571428571,
      "grad_norm": 0.08402612805366516,
      "learning_rate": 2.767142857142857e-05,
      "loss": 0.001,
      "step": 31260
    },
    {
      "epoch": 0.8934285714285715,
      "grad_norm": 0.07118596136569977,
      "learning_rate": 2.7664285714285714e-05,
      "loss": 0.0022,
      "step": 31270
    },
    {
      "epoch": 0.8937142857142857,
      "grad_norm": 0.19725127518177032,
      "learning_rate": 2.765714285714286e-05,
      "loss": 0.0014,
      "step": 31280
    },
    {
      "epoch": 0.894,
      "grad_norm": 0.1708705872297287,
      "learning_rate": 2.7650000000000005e-05,
      "loss": 0.0016,
      "step": 31290
    },
    {
      "epoch": 0.8942857142857142,
      "grad_norm": 0.12582816183567047,
      "learning_rate": 2.7642857142857143e-05,
      "loss": 0.0017,
      "step": 31300
    },
    {
      "epoch": 0.8945714285714286,
      "grad_norm": 0.06324467062950134,
      "learning_rate": 2.7635714285714288e-05,
      "loss": 0.0016,
      "step": 31310
    },
    {
      "epoch": 0.8948571428571429,
      "grad_norm": 0.08111636340618134,
      "learning_rate": 2.762857142857143e-05,
      "loss": 0.0006,
      "step": 31320
    },
    {
      "epoch": 0.8951428571428571,
      "grad_norm": 0.03226015716791153,
      "learning_rate": 2.762142857142857e-05,
      "loss": 0.001,
      "step": 31330
    },
    {
      "epoch": 0.8954285714285715,
      "grad_norm": 0.031615328043699265,
      "learning_rate": 2.7614285714285713e-05,
      "loss": 0.0008,
      "step": 31340
    },
    {
      "epoch": 0.8957142857142857,
      "grad_norm": 0.06879103183746338,
      "learning_rate": 2.760714285714286e-05,
      "loss": 0.0009,
      "step": 31350
    },
    {
      "epoch": 0.896,
      "grad_norm": 0.097090944647789,
      "learning_rate": 2.7600000000000003e-05,
      "loss": 0.0011,
      "step": 31360
    },
    {
      "epoch": 0.8962857142857142,
      "grad_norm": 0.04758067429065704,
      "learning_rate": 2.7592857142857142e-05,
      "loss": 0.002,
      "step": 31370
    },
    {
      "epoch": 0.8965714285714286,
      "grad_norm": 0.0,
      "learning_rate": 2.7585714285714287e-05,
      "loss": 0.0035,
      "step": 31380
    },
    {
      "epoch": 0.8968571428571429,
      "grad_norm": 0.12678836286067963,
      "learning_rate": 2.7578571428571432e-05,
      "loss": 0.0014,
      "step": 31390
    },
    {
      "epoch": 0.8971428571428571,
      "grad_norm": 0.038893599063158035,
      "learning_rate": 2.757142857142857e-05,
      "loss": 0.0011,
      "step": 31400
    },
    {
      "epoch": 0.8974285714285715,
      "grad_norm": 0.16390381753444672,
      "learning_rate": 2.7564285714285715e-05,
      "loss": 0.0016,
      "step": 31410
    },
    {
      "epoch": 0.8977142857142857,
      "grad_norm": 0.051486194133758545,
      "learning_rate": 2.755714285714286e-05,
      "loss": 0.002,
      "step": 31420
    },
    {
      "epoch": 0.898,
      "grad_norm": 0.05740555748343468,
      "learning_rate": 2.7550000000000002e-05,
      "loss": 0.0014,
      "step": 31430
    },
    {
      "epoch": 0.8982857142857142,
      "grad_norm": 0.25968021154403687,
      "learning_rate": 2.7542857142857144e-05,
      "loss": 0.0014,
      "step": 31440
    },
    {
      "epoch": 0.8985714285714286,
      "grad_norm": 0.0,
      "learning_rate": 2.7535714285714286e-05,
      "loss": 0.0008,
      "step": 31450
    },
    {
      "epoch": 0.8988571428571429,
      "grad_norm": 0.06733216345310211,
      "learning_rate": 2.752857142857143e-05,
      "loss": 0.0008,
      "step": 31460
    },
    {
      "epoch": 0.8991428571428571,
      "grad_norm": 0.0904044583439827,
      "learning_rate": 2.752142857142857e-05,
      "loss": 0.0013,
      "step": 31470
    },
    {
      "epoch": 0.8994285714285715,
      "grad_norm": 0.052563246339559555,
      "learning_rate": 2.7514285714285714e-05,
      "loss": 0.0011,
      "step": 31480
    },
    {
      "epoch": 0.8997142857142857,
      "grad_norm": 0.22445015609264374,
      "learning_rate": 2.750714285714286e-05,
      "loss": 0.0008,
      "step": 31490
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.04055937007069588,
      "learning_rate": 2.7500000000000004e-05,
      "loss": 0.0017,
      "step": 31500
    },
    {
      "epoch": 0.9002857142857142,
      "grad_norm": 0.16027098894119263,
      "learning_rate": 2.7492857142857143e-05,
      "loss": 0.0013,
      "step": 31510
    },
    {
      "epoch": 0.9005714285714286,
      "grad_norm": 0.04798528924584389,
      "learning_rate": 2.7485714285714288e-05,
      "loss": 0.0015,
      "step": 31520
    },
    {
      "epoch": 0.9008571428571429,
      "grad_norm": 0.21363745629787445,
      "learning_rate": 2.7478571428571433e-05,
      "loss": 0.0017,
      "step": 31530
    },
    {
      "epoch": 0.9011428571428571,
      "grad_norm": 0.09846906363964081,
      "learning_rate": 2.747142857142857e-05,
      "loss": 0.0009,
      "step": 31540
    },
    {
      "epoch": 0.9014285714285715,
      "grad_norm": 0.08994060754776001,
      "learning_rate": 2.7464285714285713e-05,
      "loss": 0.0016,
      "step": 31550
    },
    {
      "epoch": 0.9017142857142857,
      "grad_norm": 0.11053422093391418,
      "learning_rate": 2.7457142857142858e-05,
      "loss": 0.001,
      "step": 31560
    },
    {
      "epoch": 0.902,
      "grad_norm": 0.040383972227573395,
      "learning_rate": 2.7450000000000003e-05,
      "loss": 0.0006,
      "step": 31570
    },
    {
      "epoch": 0.9022857142857142,
      "grad_norm": 0.04643435403704643,
      "learning_rate": 2.744285714285714e-05,
      "loss": 0.0012,
      "step": 31580
    },
    {
      "epoch": 0.9025714285714286,
      "grad_norm": 0.18701256811618805,
      "learning_rate": 2.7435714285714287e-05,
      "loss": 0.0021,
      "step": 31590
    },
    {
      "epoch": 0.9028571428571428,
      "grad_norm": 0.08507469296455383,
      "learning_rate": 2.742857142857143e-05,
      "loss": 0.0011,
      "step": 31600
    },
    {
      "epoch": 0.9031428571428571,
      "grad_norm": 0.1282755583524704,
      "learning_rate": 2.742142857142857e-05,
      "loss": 0.0008,
      "step": 31610
    },
    {
      "epoch": 0.9034285714285715,
      "grad_norm": 0.19994308054447174,
      "learning_rate": 2.7414285714285715e-05,
      "loss": 0.0015,
      "step": 31620
    },
    {
      "epoch": 0.9037142857142857,
      "grad_norm": 0.0905735120177269,
      "learning_rate": 2.740714285714286e-05,
      "loss": 0.0014,
      "step": 31630
    },
    {
      "epoch": 0.904,
      "grad_norm": 0.12695547938346863,
      "learning_rate": 2.7400000000000002e-05,
      "loss": 0.0011,
      "step": 31640
    },
    {
      "epoch": 0.9042857142857142,
      "grad_norm": 0.16167402267456055,
      "learning_rate": 2.7392857142857144e-05,
      "loss": 0.0019,
      "step": 31650
    },
    {
      "epoch": 0.9045714285714286,
      "grad_norm": 0.051286838948726654,
      "learning_rate": 2.7385714285714285e-05,
      "loss": 0.0013,
      "step": 31660
    },
    {
      "epoch": 0.9048571428571428,
      "grad_norm": 0.0,
      "learning_rate": 2.737857142857143e-05,
      "loss": 0.0013,
      "step": 31670
    },
    {
      "epoch": 0.9051428571428571,
      "grad_norm": 0.0,
      "learning_rate": 2.737142857142857e-05,
      "loss": 0.0009,
      "step": 31680
    },
    {
      "epoch": 0.9054285714285715,
      "grad_norm": 0.07850246131420135,
      "learning_rate": 2.7364285714285714e-05,
      "loss": 0.002,
      "step": 31690
    },
    {
      "epoch": 0.9057142857142857,
      "grad_norm": 0.05968952924013138,
      "learning_rate": 2.735714285714286e-05,
      "loss": 0.0021,
      "step": 31700
    },
    {
      "epoch": 0.906,
      "grad_norm": 0.10789860039949417,
      "learning_rate": 2.7350000000000004e-05,
      "loss": 0.0006,
      "step": 31710
    },
    {
      "epoch": 0.9062857142857143,
      "grad_norm": 0.055772311985492706,
      "learning_rate": 2.7342857142857142e-05,
      "loss": 0.0017,
      "step": 31720
    },
    {
      "epoch": 0.9065714285714286,
      "grad_norm": 0.0780167207121849,
      "learning_rate": 2.7335714285714288e-05,
      "loss": 0.0011,
      "step": 31730
    },
    {
      "epoch": 0.9068571428571428,
      "grad_norm": 0.11987466365098953,
      "learning_rate": 2.7328571428571433e-05,
      "loss": 0.0018,
      "step": 31740
    },
    {
      "epoch": 0.9071428571428571,
      "grad_norm": 0.08074023574590683,
      "learning_rate": 2.732142857142857e-05,
      "loss": 0.0016,
      "step": 31750
    },
    {
      "epoch": 0.9074285714285715,
      "grad_norm": 0.09114355593919754,
      "learning_rate": 2.7314285714285716e-05,
      "loss": 0.0011,
      "step": 31760
    },
    {
      "epoch": 0.9077142857142857,
      "grad_norm": 0.12096261978149414,
      "learning_rate": 2.7307142857142858e-05,
      "loss": 0.002,
      "step": 31770
    },
    {
      "epoch": 0.908,
      "grad_norm": 0.0,
      "learning_rate": 2.7300000000000003e-05,
      "loss": 0.0013,
      "step": 31780
    },
    {
      "epoch": 0.9082857142857143,
      "grad_norm": 0.0,
      "learning_rate": 2.729285714285714e-05,
      "loss": 0.0003,
      "step": 31790
    },
    {
      "epoch": 0.9085714285714286,
      "grad_norm": 0.04119409620761871,
      "learning_rate": 2.7285714285714286e-05,
      "loss": 0.0003,
      "step": 31800
    },
    {
      "epoch": 0.9088571428571428,
      "grad_norm": 0.0,
      "learning_rate": 2.727857142857143e-05,
      "loss": 0.0015,
      "step": 31810
    },
    {
      "epoch": 0.9091428571428571,
      "grad_norm": 0.05158614367246628,
      "learning_rate": 2.727142857142857e-05,
      "loss": 0.0024,
      "step": 31820
    },
    {
      "epoch": 0.9094285714285715,
      "grad_norm": 0.25677239894866943,
      "learning_rate": 2.7264285714285715e-05,
      "loss": 0.0016,
      "step": 31830
    },
    {
      "epoch": 0.9097142857142857,
      "grad_norm": 0.07811395078897476,
      "learning_rate": 2.725714285714286e-05,
      "loss": 0.0008,
      "step": 31840
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.057563666254282,
      "learning_rate": 2.725e-05,
      "loss": 0.0016,
      "step": 31850
    },
    {
      "epoch": 0.9102857142857143,
      "grad_norm": 0.04004327580332756,
      "learning_rate": 2.7242857142857143e-05,
      "loss": 0.001,
      "step": 31860
    },
    {
      "epoch": 0.9105714285714286,
      "grad_norm": 0.020847879350185394,
      "learning_rate": 2.7235714285714285e-05,
      "loss": 0.0016,
      "step": 31870
    },
    {
      "epoch": 0.9108571428571428,
      "grad_norm": 0.1087561771273613,
      "learning_rate": 2.722857142857143e-05,
      "loss": 0.0027,
      "step": 31880
    },
    {
      "epoch": 0.9111428571428571,
      "grad_norm": 0.21119199693202972,
      "learning_rate": 2.7221428571428575e-05,
      "loss": 0.0013,
      "step": 31890
    },
    {
      "epoch": 0.9114285714285715,
      "grad_norm": 0.06585267931222916,
      "learning_rate": 2.7214285714285714e-05,
      "loss": 0.0022,
      "step": 31900
    },
    {
      "epoch": 0.9117142857142857,
      "grad_norm": 0.033423393964767456,
      "learning_rate": 2.720714285714286e-05,
      "loss": 0.0016,
      "step": 31910
    },
    {
      "epoch": 0.912,
      "grad_norm": 0.11797186732292175,
      "learning_rate": 2.7200000000000004e-05,
      "loss": 0.0019,
      "step": 31920
    },
    {
      "epoch": 0.9122857142857143,
      "grad_norm": 0.17699755728244781,
      "learning_rate": 2.7192857142857142e-05,
      "loss": 0.0005,
      "step": 31930
    },
    {
      "epoch": 0.9125714285714286,
      "grad_norm": 0.03988766297698021,
      "learning_rate": 2.7185714285714287e-05,
      "loss": 0.0011,
      "step": 31940
    },
    {
      "epoch": 0.9128571428571428,
      "grad_norm": 0.04262632876634598,
      "learning_rate": 2.7178571428571432e-05,
      "loss": 0.0014,
      "step": 31950
    },
    {
      "epoch": 0.9131428571428571,
      "grad_norm": 0.08652196824550629,
      "learning_rate": 2.7171428571428574e-05,
      "loss": 0.0008,
      "step": 31960
    },
    {
      "epoch": 0.9134285714285715,
      "grad_norm": 0.041366178542375565,
      "learning_rate": 2.7164285714285716e-05,
      "loss": 0.0013,
      "step": 31970
    },
    {
      "epoch": 0.9137142857142857,
      "grad_norm": 0.0,
      "learning_rate": 2.7157142857142858e-05,
      "loss": 0.002,
      "step": 31980
    },
    {
      "epoch": 0.914,
      "grad_norm": 0.2114841341972351,
      "learning_rate": 2.7150000000000003e-05,
      "loss": 0.0013,
      "step": 31990
    },
    {
      "epoch": 0.9142857142857143,
      "grad_norm": 0.0877421423792839,
      "learning_rate": 2.714285714285714e-05,
      "loss": 0.0011,
      "step": 32000
    },
    {
      "epoch": 0.9145714285714286,
      "grad_norm": 0.05657516419887543,
      "learning_rate": 2.7135714285714286e-05,
      "loss": 0.002,
      "step": 32010
    },
    {
      "epoch": 0.9148571428571428,
      "grad_norm": 0.0,
      "learning_rate": 2.712857142857143e-05,
      "loss": 0.0009,
      "step": 32020
    },
    {
      "epoch": 0.9151428571428571,
      "grad_norm": 0.04001189395785332,
      "learning_rate": 2.7121428571428576e-05,
      "loss": 0.0012,
      "step": 32030
    },
    {
      "epoch": 0.9154285714285715,
      "grad_norm": 0.09090328216552734,
      "learning_rate": 2.7114285714285715e-05,
      "loss": 0.003,
      "step": 32040
    },
    {
      "epoch": 0.9157142857142857,
      "grad_norm": 0.078604556620121,
      "learning_rate": 2.710714285714286e-05,
      "loss": 0.0012,
      "step": 32050
    },
    {
      "epoch": 0.916,
      "grad_norm": 0.026690587401390076,
      "learning_rate": 2.7100000000000005e-05,
      "loss": 0.001,
      "step": 32060
    },
    {
      "epoch": 0.9162857142857143,
      "grad_norm": 0.049593403935432434,
      "learning_rate": 2.7092857142857143e-05,
      "loss": 0.0018,
      "step": 32070
    },
    {
      "epoch": 0.9165714285714286,
      "grad_norm": 0.0,
      "learning_rate": 2.7085714285714285e-05,
      "loss": 0.0019,
      "step": 32080
    },
    {
      "epoch": 0.9168571428571428,
      "grad_norm": 0.04896293208003044,
      "learning_rate": 2.707857142857143e-05,
      "loss": 0.0011,
      "step": 32090
    },
    {
      "epoch": 0.9171428571428571,
      "grad_norm": 0.0,
      "learning_rate": 2.7071428571428575e-05,
      "loss": 0.0008,
      "step": 32100
    },
    {
      "epoch": 0.9174285714285715,
      "grad_norm": 0.033756136894226074,
      "learning_rate": 2.7064285714285713e-05,
      "loss": 0.0008,
      "step": 32110
    },
    {
      "epoch": 0.9177142857142857,
      "grad_norm": 0.2816769778728485,
      "learning_rate": 2.705714285714286e-05,
      "loss": 0.0007,
      "step": 32120
    },
    {
      "epoch": 0.918,
      "grad_norm": 0.03294099122285843,
      "learning_rate": 2.7050000000000004e-05,
      "loss": 0.0019,
      "step": 32130
    },
    {
      "epoch": 0.9182857142857143,
      "grad_norm": 0.07798904180526733,
      "learning_rate": 2.7042857142857142e-05,
      "loss": 0.0006,
      "step": 32140
    },
    {
      "epoch": 0.9185714285714286,
      "grad_norm": 0.29462119936943054,
      "learning_rate": 2.7035714285714287e-05,
      "loss": 0.0024,
      "step": 32150
    },
    {
      "epoch": 0.9188571428571428,
      "grad_norm": 0.09895340353250504,
      "learning_rate": 2.7028571428571432e-05,
      "loss": 0.0007,
      "step": 32160
    },
    {
      "epoch": 0.9191428571428572,
      "grad_norm": 0.04237080737948418,
      "learning_rate": 2.7021428571428574e-05,
      "loss": 0.001,
      "step": 32170
    },
    {
      "epoch": 0.9194285714285715,
      "grad_norm": 0.06327732652425766,
      "learning_rate": 2.7014285714285716e-05,
      "loss": 0.0013,
      "step": 32180
    },
    {
      "epoch": 0.9197142857142857,
      "grad_norm": 0.25856462121009827,
      "learning_rate": 2.7007142857142857e-05,
      "loss": 0.0025,
      "step": 32190
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.09388355165719986,
      "learning_rate": 2.7000000000000002e-05,
      "loss": 0.0017,
      "step": 32200
    },
    {
      "epoch": 0.9202857142857143,
      "grad_norm": 0.030661627650260925,
      "learning_rate": 2.699285714285714e-05,
      "loss": 0.0005,
      "step": 32210
    },
    {
      "epoch": 0.9205714285714286,
      "grad_norm": 0.06026863306760788,
      "learning_rate": 2.6985714285714286e-05,
      "loss": 0.0016,
      "step": 32220
    },
    {
      "epoch": 0.9208571428571428,
      "grad_norm": 0.38696858286857605,
      "learning_rate": 2.697857142857143e-05,
      "loss": 0.0005,
      "step": 32230
    },
    {
      "epoch": 0.9211428571428572,
      "grad_norm": 0.22063098847866058,
      "learning_rate": 2.6971428571428576e-05,
      "loss": 0.0015,
      "step": 32240
    },
    {
      "epoch": 0.9214285714285714,
      "grad_norm": 0.0,
      "learning_rate": 2.6964285714285714e-05,
      "loss": 0.0018,
      "step": 32250
    },
    {
      "epoch": 0.9217142857142857,
      "grad_norm": 0.0,
      "learning_rate": 2.695714285714286e-05,
      "loss": 0.0008,
      "step": 32260
    },
    {
      "epoch": 0.922,
      "grad_norm": 0.4041888415813446,
      "learning_rate": 2.6950000000000005e-05,
      "loss": 0.0021,
      "step": 32270
    },
    {
      "epoch": 0.9222857142857143,
      "grad_norm": 0.04110055789351463,
      "learning_rate": 2.6942857142857143e-05,
      "loss": 0.0015,
      "step": 32280
    },
    {
      "epoch": 0.9225714285714286,
      "grad_norm": 0.043712981045246124,
      "learning_rate": 2.6935714285714288e-05,
      "loss": 0.0014,
      "step": 32290
    },
    {
      "epoch": 0.9228571428571428,
      "grad_norm": 0.06198592111468315,
      "learning_rate": 2.692857142857143e-05,
      "loss": 0.0009,
      "step": 32300
    },
    {
      "epoch": 0.9231428571428572,
      "grad_norm": 0.09797733277082443,
      "learning_rate": 2.6921428571428575e-05,
      "loss": 0.0004,
      "step": 32310
    },
    {
      "epoch": 0.9234285714285714,
      "grad_norm": 0.36369824409484863,
      "learning_rate": 2.6914285714285713e-05,
      "loss": 0.0019,
      "step": 32320
    },
    {
      "epoch": 0.9237142857142857,
      "grad_norm": 0.047915976494550705,
      "learning_rate": 2.6907142857142858e-05,
      "loss": 0.0014,
      "step": 32330
    },
    {
      "epoch": 0.924,
      "grad_norm": 0.1707068681716919,
      "learning_rate": 2.6900000000000003e-05,
      "loss": 0.0019,
      "step": 32340
    },
    {
      "epoch": 0.9242857142857143,
      "grad_norm": 0.053807079792022705,
      "learning_rate": 2.689285714285714e-05,
      "loss": 0.0008,
      "step": 32350
    },
    {
      "epoch": 0.9245714285714286,
      "grad_norm": 0.29839539527893066,
      "learning_rate": 2.6885714285714287e-05,
      "loss": 0.0018,
      "step": 32360
    },
    {
      "epoch": 0.9248571428571428,
      "grad_norm": 0.19152061641216278,
      "learning_rate": 2.6878571428571432e-05,
      "loss": 0.0009,
      "step": 32370
    },
    {
      "epoch": 0.9251428571428572,
      "grad_norm": 0.08132923394441605,
      "learning_rate": 2.6871428571428574e-05,
      "loss": 0.0011,
      "step": 32380
    },
    {
      "epoch": 0.9254285714285714,
      "grad_norm": 0.07150159776210785,
      "learning_rate": 2.6864285714285715e-05,
      "loss": 0.0008,
      "step": 32390
    },
    {
      "epoch": 0.9257142857142857,
      "grad_norm": 0.0,
      "learning_rate": 2.6857142857142857e-05,
      "loss": 0.0014,
      "step": 32400
    },
    {
      "epoch": 0.926,
      "grad_norm": 0.04251681640744209,
      "learning_rate": 2.6850000000000002e-05,
      "loss": 0.0013,
      "step": 32410
    },
    {
      "epoch": 0.9262857142857143,
      "grad_norm": 0.0,
      "learning_rate": 2.684285714285714e-05,
      "loss": 0.002,
      "step": 32420
    },
    {
      "epoch": 0.9265714285714286,
      "grad_norm": 0.12224316596984863,
      "learning_rate": 2.6835714285714286e-05,
      "loss": 0.0026,
      "step": 32430
    },
    {
      "epoch": 0.9268571428571428,
      "grad_norm": 0.19379518926143646,
      "learning_rate": 2.682857142857143e-05,
      "loss": 0.0023,
      "step": 32440
    },
    {
      "epoch": 0.9271428571428572,
      "grad_norm": 0.06188485398888588,
      "learning_rate": 2.6821428571428576e-05,
      "loss": 0.0013,
      "step": 32450
    },
    {
      "epoch": 0.9274285714285714,
      "grad_norm": 0.17808417975902557,
      "learning_rate": 2.6814285714285714e-05,
      "loss": 0.0015,
      "step": 32460
    },
    {
      "epoch": 0.9277142857142857,
      "grad_norm": 0.06197243183851242,
      "learning_rate": 2.680714285714286e-05,
      "loss": 0.0007,
      "step": 32470
    },
    {
      "epoch": 0.928,
      "grad_norm": 0.0445912666618824,
      "learning_rate": 2.6800000000000004e-05,
      "loss": 0.001,
      "step": 32480
    },
    {
      "epoch": 0.9282857142857143,
      "grad_norm": 0.2606537342071533,
      "learning_rate": 2.6792857142857143e-05,
      "loss": 0.0013,
      "step": 32490
    },
    {
      "epoch": 0.9285714285714286,
      "grad_norm": 0.04774151369929314,
      "learning_rate": 2.6785714285714288e-05,
      "loss": 0.0018,
      "step": 32500
    },
    {
      "epoch": 0.9288571428571428,
      "grad_norm": 0.0,
      "learning_rate": 2.677857142857143e-05,
      "loss": 0.0015,
      "step": 32510
    },
    {
      "epoch": 0.9291428571428572,
      "grad_norm": 0.08138523995876312,
      "learning_rate": 2.6771428571428575e-05,
      "loss": 0.0013,
      "step": 32520
    },
    {
      "epoch": 0.9294285714285714,
      "grad_norm": 0.0,
      "learning_rate": 2.6764285714285713e-05,
      "loss": 0.0008,
      "step": 32530
    },
    {
      "epoch": 0.9297142857142857,
      "grad_norm": 0.0,
      "learning_rate": 2.6757142857142858e-05,
      "loss": 0.0013,
      "step": 32540
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.0,
      "learning_rate": 2.6750000000000003e-05,
      "loss": 0.0007,
      "step": 32550
    },
    {
      "epoch": 0.9302857142857143,
      "grad_norm": 0.03707003965973854,
      "learning_rate": 2.674285714285714e-05,
      "loss": 0.0012,
      "step": 32560
    },
    {
      "epoch": 0.9305714285714286,
      "grad_norm": 0.03838727995753288,
      "learning_rate": 2.6735714285714287e-05,
      "loss": 0.0011,
      "step": 32570
    },
    {
      "epoch": 0.9308571428571428,
      "grad_norm": 0.0,
      "learning_rate": 2.672857142857143e-05,
      "loss": 0.0018,
      "step": 32580
    },
    {
      "epoch": 0.9311428571428572,
      "grad_norm": 0.42146018147468567,
      "learning_rate": 2.6721428571428577e-05,
      "loss": 0.0021,
      "step": 32590
    },
    {
      "epoch": 0.9314285714285714,
      "grad_norm": 0.04595891386270523,
      "learning_rate": 2.6714285714285715e-05,
      "loss": 0.001,
      "step": 32600
    },
    {
      "epoch": 0.9317142857142857,
      "grad_norm": 0.04239753633737564,
      "learning_rate": 2.6707142857142857e-05,
      "loss": 0.0007,
      "step": 32610
    },
    {
      "epoch": 0.932,
      "grad_norm": 0.04420512169599533,
      "learning_rate": 2.6700000000000002e-05,
      "loss": 0.0022,
      "step": 32620
    },
    {
      "epoch": 0.9322857142857143,
      "grad_norm": 0.053716279566287994,
      "learning_rate": 2.669285714285714e-05,
      "loss": 0.0003,
      "step": 32630
    },
    {
      "epoch": 0.9325714285714286,
      "grad_norm": 0.0,
      "learning_rate": 2.6685714285714285e-05,
      "loss": 0.0014,
      "step": 32640
    },
    {
      "epoch": 0.9328571428571428,
      "grad_norm": 0.1855897307395935,
      "learning_rate": 2.667857142857143e-05,
      "loss": 0.0024,
      "step": 32650
    },
    {
      "epoch": 0.9331428571428572,
      "grad_norm": 0.14794306457042694,
      "learning_rate": 2.6671428571428576e-05,
      "loss": 0.0012,
      "step": 32660
    },
    {
      "epoch": 0.9334285714285714,
      "grad_norm": 0.048509158194065094,
      "learning_rate": 2.6664285714285714e-05,
      "loss": 0.0018,
      "step": 32670
    },
    {
      "epoch": 0.9337142857142857,
      "grad_norm": 0.06017759069800377,
      "learning_rate": 2.665714285714286e-05,
      "loss": 0.001,
      "step": 32680
    },
    {
      "epoch": 0.934,
      "grad_norm": 0.28637030720710754,
      "learning_rate": 2.6650000000000004e-05,
      "loss": 0.0019,
      "step": 32690
    },
    {
      "epoch": 0.9342857142857143,
      "grad_norm": 0.0542631521821022,
      "learning_rate": 2.6642857142857142e-05,
      "loss": 0.002,
      "step": 32700
    },
    {
      "epoch": 0.9345714285714286,
      "grad_norm": 0.04408716782927513,
      "learning_rate": 2.6635714285714287e-05,
      "loss": 0.0014,
      "step": 32710
    },
    {
      "epoch": 0.9348571428571428,
      "grad_norm": 0.040384359657764435,
      "learning_rate": 2.662857142857143e-05,
      "loss": 0.0003,
      "step": 32720
    },
    {
      "epoch": 0.9351428571428572,
      "grad_norm": 0.0387302041053772,
      "learning_rate": 2.6621428571428574e-05,
      "loss": 0.0018,
      "step": 32730
    },
    {
      "epoch": 0.9354285714285714,
      "grad_norm": 0.08612940460443497,
      "learning_rate": 2.6614285714285713e-05,
      "loss": 0.0012,
      "step": 32740
    },
    {
      "epoch": 0.9357142857142857,
      "grad_norm": 0.11299124360084534,
      "learning_rate": 2.6607142857142858e-05,
      "loss": 0.0013,
      "step": 32750
    },
    {
      "epoch": 0.936,
      "grad_norm": 0.0,
      "learning_rate": 2.6600000000000003e-05,
      "loss": 0.0013,
      "step": 32760
    },
    {
      "epoch": 0.9362857142857143,
      "grad_norm": 0.2407417595386505,
      "learning_rate": 2.659285714285714e-05,
      "loss": 0.0009,
      "step": 32770
    },
    {
      "epoch": 0.9365714285714286,
      "grad_norm": 0.0,
      "learning_rate": 2.6585714285714286e-05,
      "loss": 0.0011,
      "step": 32780
    },
    {
      "epoch": 0.9368571428571428,
      "grad_norm": 0.042259324342012405,
      "learning_rate": 2.657857142857143e-05,
      "loss": 0.0009,
      "step": 32790
    },
    {
      "epoch": 0.9371428571428572,
      "grad_norm": 0.12043078243732452,
      "learning_rate": 2.6571428571428576e-05,
      "loss": 0.0015,
      "step": 32800
    },
    {
      "epoch": 0.9374285714285714,
      "grad_norm": 0.0,
      "learning_rate": 2.6564285714285715e-05,
      "loss": 0.0013,
      "step": 32810
    },
    {
      "epoch": 0.9377142857142857,
      "grad_norm": 0.08419937640428543,
      "learning_rate": 2.655714285714286e-05,
      "loss": 0.0014,
      "step": 32820
    },
    {
      "epoch": 0.938,
      "grad_norm": 0.0,
      "learning_rate": 2.655e-05,
      "loss": 0.0014,
      "step": 32830
    },
    {
      "epoch": 0.9382857142857143,
      "grad_norm": 0.04443569481372833,
      "learning_rate": 2.654285714285714e-05,
      "loss": 0.0016,
      "step": 32840
    },
    {
      "epoch": 0.9385714285714286,
      "grad_norm": 0.09086208790540695,
      "learning_rate": 2.6535714285714285e-05,
      "loss": 0.0013,
      "step": 32850
    },
    {
      "epoch": 0.9388571428571428,
      "grad_norm": 0.047716137021780014,
      "learning_rate": 2.652857142857143e-05,
      "loss": 0.0018,
      "step": 32860
    },
    {
      "epoch": 0.9391428571428572,
      "grad_norm": 0.12658150494098663,
      "learning_rate": 2.6521428571428575e-05,
      "loss": 0.0018,
      "step": 32870
    },
    {
      "epoch": 0.9394285714285714,
      "grad_norm": 0.23675841093063354,
      "learning_rate": 2.6514285714285714e-05,
      "loss": 0.0012,
      "step": 32880
    },
    {
      "epoch": 0.9397142857142857,
      "grad_norm": 0.0,
      "learning_rate": 2.650714285714286e-05,
      "loss": 0.001,
      "step": 32890
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.0,
      "learning_rate": 2.6500000000000004e-05,
      "loss": 0.0021,
      "step": 32900
    },
    {
      "epoch": 0.9402857142857143,
      "grad_norm": 0.0326935313642025,
      "learning_rate": 2.6492857142857142e-05,
      "loss": 0.0028,
      "step": 32910
    },
    {
      "epoch": 0.9405714285714286,
      "grad_norm": 0.10203003138303757,
      "learning_rate": 2.6485714285714287e-05,
      "loss": 0.0011,
      "step": 32920
    },
    {
      "epoch": 0.9408571428571428,
      "grad_norm": 0.05991151183843613,
      "learning_rate": 2.647857142857143e-05,
      "loss": 0.0019,
      "step": 32930
    },
    {
      "epoch": 0.9411428571428572,
      "grad_norm": 0.08396297693252563,
      "learning_rate": 2.6471428571428574e-05,
      "loss": 0.0017,
      "step": 32940
    },
    {
      "epoch": 0.9414285714285714,
      "grad_norm": 0.17164656519889832,
      "learning_rate": 2.6464285714285712e-05,
      "loss": 0.0017,
      "step": 32950
    },
    {
      "epoch": 0.9417142857142857,
      "grad_norm": 0.08579786866903305,
      "learning_rate": 2.6457142857142857e-05,
      "loss": 0.0012,
      "step": 32960
    },
    {
      "epoch": 0.942,
      "grad_norm": 0.0,
      "learning_rate": 2.6450000000000003e-05,
      "loss": 0.0008,
      "step": 32970
    },
    {
      "epoch": 0.9422857142857143,
      "grad_norm": 0.0,
      "learning_rate": 2.644285714285714e-05,
      "loss": 0.0008,
      "step": 32980
    },
    {
      "epoch": 0.9425714285714286,
      "grad_norm": 0.07182127237319946,
      "learning_rate": 2.6435714285714286e-05,
      "loss": 0.0015,
      "step": 32990
    },
    {
      "epoch": 0.9428571428571428,
      "grad_norm": 0.16844600439071655,
      "learning_rate": 2.642857142857143e-05,
      "loss": 0.0015,
      "step": 33000
    },
    {
      "epoch": 0.9431428571428572,
      "grad_norm": 0.081719309091568,
      "learning_rate": 2.6421428571428576e-05,
      "loss": 0.0012,
      "step": 33010
    },
    {
      "epoch": 0.9434285714285714,
      "grad_norm": 0.08017340302467346,
      "learning_rate": 2.6414285714285715e-05,
      "loss": 0.0022,
      "step": 33020
    },
    {
      "epoch": 0.9437142857142857,
      "grad_norm": 0.14321553707122803,
      "learning_rate": 2.640714285714286e-05,
      "loss": 0.0009,
      "step": 33030
    },
    {
      "epoch": 0.944,
      "grad_norm": 0.060096193104982376,
      "learning_rate": 2.64e-05,
      "loss": 0.0018,
      "step": 33040
    },
    {
      "epoch": 0.9442857142857143,
      "grad_norm": 0.04464463144540787,
      "learning_rate": 2.6392857142857143e-05,
      "loss": 0.001,
      "step": 33050
    },
    {
      "epoch": 0.9445714285714286,
      "grad_norm": 0.06117701902985573,
      "learning_rate": 2.6385714285714285e-05,
      "loss": 0.0006,
      "step": 33060
    },
    {
      "epoch": 0.9448571428571428,
      "grad_norm": 0.08160358667373657,
      "learning_rate": 2.637857142857143e-05,
      "loss": 0.0014,
      "step": 33070
    },
    {
      "epoch": 0.9451428571428572,
      "grad_norm": 0.037497229874134064,
      "learning_rate": 2.6371428571428575e-05,
      "loss": 0.001,
      "step": 33080
    },
    {
      "epoch": 0.9454285714285714,
      "grad_norm": 0.08347346633672714,
      "learning_rate": 2.6364285714285713e-05,
      "loss": 0.0017,
      "step": 33090
    },
    {
      "epoch": 0.9457142857142857,
      "grad_norm": 0.0,
      "learning_rate": 2.635714285714286e-05,
      "loss": 0.001,
      "step": 33100
    },
    {
      "epoch": 0.946,
      "grad_norm": 0.0,
      "learning_rate": 2.6350000000000004e-05,
      "loss": 0.0025,
      "step": 33110
    },
    {
      "epoch": 0.9462857142857143,
      "grad_norm": 0.23094123601913452,
      "learning_rate": 2.6342857142857142e-05,
      "loss": 0.0024,
      "step": 33120
    },
    {
      "epoch": 0.9465714285714286,
      "grad_norm": 0.15616489946842194,
      "learning_rate": 2.6335714285714287e-05,
      "loss": 0.0016,
      "step": 33130
    },
    {
      "epoch": 0.9468571428571428,
      "grad_norm": 0.0,
      "learning_rate": 2.632857142857143e-05,
      "loss": 0.001,
      "step": 33140
    },
    {
      "epoch": 0.9471428571428572,
      "grad_norm": 0.03942849859595299,
      "learning_rate": 2.6321428571428574e-05,
      "loss": 0.0013,
      "step": 33150
    },
    {
      "epoch": 0.9474285714285714,
      "grad_norm": 0.044598519802093506,
      "learning_rate": 2.6314285714285712e-05,
      "loss": 0.0006,
      "step": 33160
    },
    {
      "epoch": 0.9477142857142857,
      "grad_norm": 0.25159192085266113,
      "learning_rate": 2.6307142857142857e-05,
      "loss": 0.0016,
      "step": 33170
    },
    {
      "epoch": 0.948,
      "grad_norm": 0.048046860843896866,
      "learning_rate": 2.6300000000000002e-05,
      "loss": 0.001,
      "step": 33180
    },
    {
      "epoch": 0.9482857142857143,
      "grad_norm": 0.045072849839925766,
      "learning_rate": 2.6292857142857147e-05,
      "loss": 0.002,
      "step": 33190
    },
    {
      "epoch": 0.9485714285714286,
      "grad_norm": 0.22949832677841187,
      "learning_rate": 2.6285714285714286e-05,
      "loss": 0.0006,
      "step": 33200
    },
    {
      "epoch": 0.9488571428571428,
      "grad_norm": 0.0,
      "learning_rate": 2.627857142857143e-05,
      "loss": 0.0011,
      "step": 33210
    },
    {
      "epoch": 0.9491428571428572,
      "grad_norm": 0.039594147354364395,
      "learning_rate": 2.6271428571428576e-05,
      "loss": 0.0016,
      "step": 33220
    },
    {
      "epoch": 0.9494285714285714,
      "grad_norm": 0.0,
      "learning_rate": 2.6264285714285714e-05,
      "loss": 0.002,
      "step": 33230
    },
    {
      "epoch": 0.9497142857142857,
      "grad_norm": 0.09503840655088425,
      "learning_rate": 2.625714285714286e-05,
      "loss": 0.0034,
      "step": 33240
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.2082146555185318,
      "learning_rate": 2.625e-05,
      "loss": 0.0018,
      "step": 33250
    },
    {
      "epoch": 0.9502857142857143,
      "grad_norm": 0.04894560948014259,
      "learning_rate": 2.6242857142857146e-05,
      "loss": 0.0009,
      "step": 33260
    },
    {
      "epoch": 0.9505714285714286,
      "grad_norm": 0.04402559995651245,
      "learning_rate": 2.6235714285714285e-05,
      "loss": 0.0009,
      "step": 33270
    },
    {
      "epoch": 0.9508571428571428,
      "grad_norm": 0.06145186722278595,
      "learning_rate": 2.622857142857143e-05,
      "loss": 0.0025,
      "step": 33280
    },
    {
      "epoch": 0.9511428571428572,
      "grad_norm": 0.04277978092432022,
      "learning_rate": 2.6221428571428575e-05,
      "loss": 0.0009,
      "step": 33290
    },
    {
      "epoch": 0.9514285714285714,
      "grad_norm": 0.08903370797634125,
      "learning_rate": 2.6214285714285713e-05,
      "loss": 0.0009,
      "step": 33300
    },
    {
      "epoch": 0.9517142857142857,
      "grad_norm": 0.08384475857019424,
      "learning_rate": 2.6207142857142858e-05,
      "loss": 0.0013,
      "step": 33310
    },
    {
      "epoch": 0.952,
      "grad_norm": 0.08842048048973083,
      "learning_rate": 2.6200000000000003e-05,
      "loss": 0.0005,
      "step": 33320
    },
    {
      "epoch": 0.9522857142857143,
      "grad_norm": 0.13586540520191193,
      "learning_rate": 2.619285714285715e-05,
      "loss": 0.0015,
      "step": 33330
    },
    {
      "epoch": 0.9525714285714286,
      "grad_norm": 0.049252353608608246,
      "learning_rate": 2.6185714285714287e-05,
      "loss": 0.0014,
      "step": 33340
    },
    {
      "epoch": 0.9528571428571428,
      "grad_norm": 0.14948628842830658,
      "learning_rate": 2.617857142857143e-05,
      "loss": 0.0014,
      "step": 33350
    },
    {
      "epoch": 0.9531428571428572,
      "grad_norm": 0.07161218672990799,
      "learning_rate": 2.6171428571428574e-05,
      "loss": 0.0015,
      "step": 33360
    },
    {
      "epoch": 0.9534285714285714,
      "grad_norm": 0.04146599397063255,
      "learning_rate": 2.6164285714285712e-05,
      "loss": 0.0006,
      "step": 33370
    },
    {
      "epoch": 0.9537142857142857,
      "grad_norm": 0.04006270691752434,
      "learning_rate": 2.6157142857142857e-05,
      "loss": 0.0013,
      "step": 33380
    },
    {
      "epoch": 0.954,
      "grad_norm": 0.09360966831445694,
      "learning_rate": 2.6150000000000002e-05,
      "loss": 0.0018,
      "step": 33390
    },
    {
      "epoch": 0.9542857142857143,
      "grad_norm": 0.0,
      "learning_rate": 2.6142857142857147e-05,
      "loss": 0.002,
      "step": 33400
    },
    {
      "epoch": 0.9545714285714286,
      "grad_norm": 0.08828810602426529,
      "learning_rate": 2.6135714285714285e-05,
      "loss": 0.0008,
      "step": 33410
    },
    {
      "epoch": 0.9548571428571428,
      "grad_norm": 0.08138299733400345,
      "learning_rate": 2.612857142857143e-05,
      "loss": 0.0007,
      "step": 33420
    },
    {
      "epoch": 0.9551428571428572,
      "grad_norm": 0.2942240238189697,
      "learning_rate": 2.6121428571428576e-05,
      "loss": 0.002,
      "step": 33430
    },
    {
      "epoch": 0.9554285714285714,
      "grad_norm": 0.04570198431611061,
      "learning_rate": 2.6114285714285714e-05,
      "loss": 0.0009,
      "step": 33440
    },
    {
      "epoch": 0.9557142857142857,
      "grad_norm": 0.12085922807455063,
      "learning_rate": 2.610714285714286e-05,
      "loss": 0.0011,
      "step": 33450
    },
    {
      "epoch": 0.956,
      "grad_norm": 0.031693581491708755,
      "learning_rate": 2.61e-05,
      "loss": 0.0018,
      "step": 33460
    },
    {
      "epoch": 0.9562857142857143,
      "grad_norm": 0.05541679263114929,
      "learning_rate": 2.6092857142857146e-05,
      "loss": 0.0008,
      "step": 33470
    },
    {
      "epoch": 0.9565714285714285,
      "grad_norm": 0.0,
      "learning_rate": 2.6085714285714284e-05,
      "loss": 0.0009,
      "step": 33480
    },
    {
      "epoch": 0.9568571428571429,
      "grad_norm": 0.0,
      "learning_rate": 2.607857142857143e-05,
      "loss": 0.0024,
      "step": 33490
    },
    {
      "epoch": 0.9571428571428572,
      "grad_norm": 0.06208442151546478,
      "learning_rate": 2.6071428571428574e-05,
      "loss": 0.0014,
      "step": 33500
    },
    {
      "epoch": 0.9574285714285714,
      "grad_norm": 0.0,
      "learning_rate": 2.6064285714285713e-05,
      "loss": 0.0012,
      "step": 33510
    },
    {
      "epoch": 0.9577142857142857,
      "grad_norm": 0.04636986553668976,
      "learning_rate": 2.6057142857142858e-05,
      "loss": 0.0021,
      "step": 33520
    },
    {
      "epoch": 0.958,
      "grad_norm": 0.04448513314127922,
      "learning_rate": 2.6050000000000003e-05,
      "loss": 0.001,
      "step": 33530
    },
    {
      "epoch": 0.9582857142857143,
      "grad_norm": 0.11053422093391418,
      "learning_rate": 2.6042857142857148e-05,
      "loss": 0.0013,
      "step": 33540
    },
    {
      "epoch": 0.9585714285714285,
      "grad_norm": 0.08793666213750839,
      "learning_rate": 2.6035714285714286e-05,
      "loss": 0.0009,
      "step": 33550
    },
    {
      "epoch": 0.9588571428571429,
      "grad_norm": 0.0,
      "learning_rate": 2.602857142857143e-05,
      "loss": 0.0015,
      "step": 33560
    },
    {
      "epoch": 0.9591428571428572,
      "grad_norm": 0.05041082575917244,
      "learning_rate": 2.6021428571428573e-05,
      "loss": 0.0008,
      "step": 33570
    },
    {
      "epoch": 0.9594285714285714,
      "grad_norm": 0.04671051725745201,
      "learning_rate": 2.601428571428571e-05,
      "loss": 0.0019,
      "step": 33580
    },
    {
      "epoch": 0.9597142857142857,
      "grad_norm": 0.04611898213624954,
      "learning_rate": 2.6007142857142857e-05,
      "loss": 0.0012,
      "step": 33590
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.03958726301789284,
      "learning_rate": 2.6000000000000002e-05,
      "loss": 0.0019,
      "step": 33600
    },
    {
      "epoch": 0.9602857142857143,
      "grad_norm": 0.20693759620189667,
      "learning_rate": 2.5992857142857147e-05,
      "loss": 0.0023,
      "step": 33610
    },
    {
      "epoch": 0.9605714285714285,
      "grad_norm": 0.17280177772045135,
      "learning_rate": 2.5985714285714285e-05,
      "loss": 0.0014,
      "step": 33620
    },
    {
      "epoch": 0.9608571428571429,
      "grad_norm": 0.04220754653215408,
      "learning_rate": 2.597857142857143e-05,
      "loss": 0.0016,
      "step": 33630
    },
    {
      "epoch": 0.9611428571428572,
      "grad_norm": 0.0780782625079155,
      "learning_rate": 2.5971428571428575e-05,
      "loss": 0.0016,
      "step": 33640
    },
    {
      "epoch": 0.9614285714285714,
      "grad_norm": 0.0457891970872879,
      "learning_rate": 2.5964285714285714e-05,
      "loss": 0.0013,
      "step": 33650
    },
    {
      "epoch": 0.9617142857142857,
      "grad_norm": 0.0,
      "learning_rate": 2.595714285714286e-05,
      "loss": 0.001,
      "step": 33660
    },
    {
      "epoch": 0.962,
      "grad_norm": 0.0,
      "learning_rate": 2.595e-05,
      "loss": 0.0006,
      "step": 33670
    },
    {
      "epoch": 0.9622857142857143,
      "grad_norm": 0.047440409660339355,
      "learning_rate": 2.5942857142857146e-05,
      "loss": 0.0012,
      "step": 33680
    },
    {
      "epoch": 0.9625714285714285,
      "grad_norm": 0.11095460504293442,
      "learning_rate": 2.5935714285714284e-05,
      "loss": 0.0007,
      "step": 33690
    },
    {
      "epoch": 0.9628571428571429,
      "grad_norm": 0.05468474701046944,
      "learning_rate": 2.592857142857143e-05,
      "loss": 0.0014,
      "step": 33700
    },
    {
      "epoch": 0.9631428571428572,
      "grad_norm": 0.08253256976604462,
      "learning_rate": 2.5921428571428574e-05,
      "loss": 0.0019,
      "step": 33710
    },
    {
      "epoch": 0.9634285714285714,
      "grad_norm": 0.0871233269572258,
      "learning_rate": 2.5914285714285713e-05,
      "loss": 0.0011,
      "step": 33720
    },
    {
      "epoch": 0.9637142857142857,
      "grad_norm": 0.07156644761562347,
      "learning_rate": 2.5907142857142858e-05,
      "loss": 0.0008,
      "step": 33730
    },
    {
      "epoch": 0.964,
      "grad_norm": 0.16616623103618622,
      "learning_rate": 2.5900000000000003e-05,
      "loss": 0.0011,
      "step": 33740
    },
    {
      "epoch": 0.9642857142857143,
      "grad_norm": 0.0,
      "learning_rate": 2.5892857142857148e-05,
      "loss": 0.001,
      "step": 33750
    },
    {
      "epoch": 0.9645714285714285,
      "grad_norm": 0.07916303724050522,
      "learning_rate": 2.5885714285714286e-05,
      "loss": 0.0025,
      "step": 33760
    },
    {
      "epoch": 0.9648571428571429,
      "grad_norm": 0.19048835337162018,
      "learning_rate": 2.587857142857143e-05,
      "loss": 0.0014,
      "step": 33770
    },
    {
      "epoch": 0.9651428571428572,
      "grad_norm": 0.09074932336807251,
      "learning_rate": 2.5871428571428573e-05,
      "loss": 0.0014,
      "step": 33780
    },
    {
      "epoch": 0.9654285714285714,
      "grad_norm": 0.0,
      "learning_rate": 2.5864285714285715e-05,
      "loss": 0.0011,
      "step": 33790
    },
    {
      "epoch": 0.9657142857142857,
      "grad_norm": 0.2782142162322998,
      "learning_rate": 2.5857142857142856e-05,
      "loss": 0.0012,
      "step": 33800
    },
    {
      "epoch": 0.966,
      "grad_norm": 0.08188115805387497,
      "learning_rate": 2.585e-05,
      "loss": 0.0013,
      "step": 33810
    },
    {
      "epoch": 0.9662857142857143,
      "grad_norm": 0.0,
      "learning_rate": 2.5842857142857147e-05,
      "loss": 0.0012,
      "step": 33820
    },
    {
      "epoch": 0.9665714285714285,
      "grad_norm": 0.0664265900850296,
      "learning_rate": 2.5835714285714285e-05,
      "loss": 0.002,
      "step": 33830
    },
    {
      "epoch": 0.9668571428571429,
      "grad_norm": 0.0150519460439682,
      "learning_rate": 2.582857142857143e-05,
      "loss": 0.0011,
      "step": 33840
    },
    {
      "epoch": 0.9671428571428572,
      "grad_norm": 0.08771199733018875,
      "learning_rate": 2.5821428571428575e-05,
      "loss": 0.0006,
      "step": 33850
    },
    {
      "epoch": 0.9674285714285714,
      "grad_norm": 0.3471158444881439,
      "learning_rate": 2.5814285714285713e-05,
      "loss": 0.0009,
      "step": 33860
    },
    {
      "epoch": 0.9677142857142857,
      "grad_norm": 0.08716588467359543,
      "learning_rate": 2.580714285714286e-05,
      "loss": 0.0016,
      "step": 33870
    },
    {
      "epoch": 0.968,
      "grad_norm": 0.3119482398033142,
      "learning_rate": 2.58e-05,
      "loss": 0.0013,
      "step": 33880
    },
    {
      "epoch": 0.9682857142857143,
      "grad_norm": 0.04278402775526047,
      "learning_rate": 2.5792857142857145e-05,
      "loss": 0.0007,
      "step": 33890
    },
    {
      "epoch": 0.9685714285714285,
      "grad_norm": 0.03249397501349449,
      "learning_rate": 2.5785714285714284e-05,
      "loss": 0.0019,
      "step": 33900
    },
    {
      "epoch": 0.9688571428571429,
      "grad_norm": 0.28304460644721985,
      "learning_rate": 2.577857142857143e-05,
      "loss": 0.0026,
      "step": 33910
    },
    {
      "epoch": 0.9691428571428572,
      "grad_norm": 0.04485148563981056,
      "learning_rate": 2.5771428571428574e-05,
      "loss": 0.0018,
      "step": 33920
    },
    {
      "epoch": 0.9694285714285714,
      "grad_norm": 0.058667805045843124,
      "learning_rate": 2.5764285714285712e-05,
      "loss": 0.0028,
      "step": 33930
    },
    {
      "epoch": 0.9697142857142858,
      "grad_norm": 0.04721450433135033,
      "learning_rate": 2.5757142857142857e-05,
      "loss": 0.0009,
      "step": 33940
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.03142017498612404,
      "learning_rate": 2.5750000000000002e-05,
      "loss": 0.0023,
      "step": 33950
    },
    {
      "epoch": 0.9702857142857143,
      "grad_norm": 0.0,
      "learning_rate": 2.5742857142857148e-05,
      "loss": 0.0011,
      "step": 33960
    },
    {
      "epoch": 0.9705714285714285,
      "grad_norm": 0.05413481965661049,
      "learning_rate": 2.5735714285714286e-05,
      "loss": 0.0025,
      "step": 33970
    },
    {
      "epoch": 0.9708571428571429,
      "grad_norm": 0.10392062366008759,
      "learning_rate": 2.572857142857143e-05,
      "loss": 0.0012,
      "step": 33980
    },
    {
      "epoch": 0.9711428571428572,
      "grad_norm": 0.0604231096804142,
      "learning_rate": 2.5721428571428573e-05,
      "loss": 0.0017,
      "step": 33990
    },
    {
      "epoch": 0.9714285714285714,
      "grad_norm": 0.09674517065286636,
      "learning_rate": 2.5714285714285714e-05,
      "loss": 0.0023,
      "step": 34000
    },
    {
      "epoch": 0.9717142857142858,
      "grad_norm": 0.46771419048309326,
      "learning_rate": 2.5707142857142856e-05,
      "loss": 0.002,
      "step": 34010
    },
    {
      "epoch": 0.972,
      "grad_norm": 0.053916722536087036,
      "learning_rate": 2.57e-05,
      "loss": 0.0011,
      "step": 34020
    },
    {
      "epoch": 0.9722857142857143,
      "grad_norm": 0.0,
      "learning_rate": 2.5692857142857146e-05,
      "loss": 0.0017,
      "step": 34030
    },
    {
      "epoch": 0.9725714285714285,
      "grad_norm": 0.03324315696954727,
      "learning_rate": 2.5685714285714285e-05,
      "loss": 0.0026,
      "step": 34040
    },
    {
      "epoch": 0.9728571428571429,
      "grad_norm": 0.025049250572919846,
      "learning_rate": 2.567857142857143e-05,
      "loss": 0.0009,
      "step": 34050
    },
    {
      "epoch": 0.9731428571428572,
      "grad_norm": 0.0,
      "learning_rate": 2.5671428571428575e-05,
      "loss": 0.0021,
      "step": 34060
    },
    {
      "epoch": 0.9734285714285714,
      "grad_norm": 0.0481327660381794,
      "learning_rate": 2.5664285714285713e-05,
      "loss": 0.0009,
      "step": 34070
    },
    {
      "epoch": 0.9737142857142858,
      "grad_norm": 0.11496980488300323,
      "learning_rate": 2.565714285714286e-05,
      "loss": 0.0018,
      "step": 34080
    },
    {
      "epoch": 0.974,
      "grad_norm": 0.08572401851415634,
      "learning_rate": 2.5650000000000003e-05,
      "loss": 0.0018,
      "step": 34090
    },
    {
      "epoch": 0.9742857142857143,
      "grad_norm": 0.059140317142009735,
      "learning_rate": 2.5642857142857145e-05,
      "loss": 0.0006,
      "step": 34100
    },
    {
      "epoch": 0.9745714285714285,
      "grad_norm": 0.04135860502719879,
      "learning_rate": 2.5635714285714283e-05,
      "loss": 0.001,
      "step": 34110
    },
    {
      "epoch": 0.9748571428571429,
      "grad_norm": 0.039385195821523666,
      "learning_rate": 2.562857142857143e-05,
      "loss": 0.0006,
      "step": 34120
    },
    {
      "epoch": 0.9751428571428571,
      "grad_norm": 0.032780639827251434,
      "learning_rate": 2.5621428571428574e-05,
      "loss": 0.0021,
      "step": 34130
    },
    {
      "epoch": 0.9754285714285714,
      "grad_norm": 0.04650696739554405,
      "learning_rate": 2.5614285714285712e-05,
      "loss": 0.0011,
      "step": 34140
    },
    {
      "epoch": 0.9757142857142858,
      "grad_norm": 0.1386718451976776,
      "learning_rate": 2.5607142857142857e-05,
      "loss": 0.0012,
      "step": 34150
    },
    {
      "epoch": 0.976,
      "grad_norm": 0.04952433705329895,
      "learning_rate": 2.5600000000000002e-05,
      "loss": 0.0025,
      "step": 34160
    },
    {
      "epoch": 0.9762857142857143,
      "grad_norm": 0.041277870535850525,
      "learning_rate": 2.5592857142857147e-05,
      "loss": 0.001,
      "step": 34170
    },
    {
      "epoch": 0.9765714285714285,
      "grad_norm": 0.04272332414984703,
      "learning_rate": 2.5585714285714286e-05,
      "loss": 0.0015,
      "step": 34180
    },
    {
      "epoch": 0.9768571428571429,
      "grad_norm": 0.04336828365921974,
      "learning_rate": 2.557857142857143e-05,
      "loss": 0.0018,
      "step": 34190
    },
    {
      "epoch": 0.9771428571428571,
      "grad_norm": 0.041289012879133224,
      "learning_rate": 2.5571428571428572e-05,
      "loss": 0.0012,
      "step": 34200
    },
    {
      "epoch": 0.9774285714285714,
      "grad_norm": 0.3119278848171234,
      "learning_rate": 2.5564285714285714e-05,
      "loss": 0.0011,
      "step": 34210
    },
    {
      "epoch": 0.9777142857142858,
      "grad_norm": 0.0489773228764534,
      "learning_rate": 2.5557142857142856e-05,
      "loss": 0.0013,
      "step": 34220
    },
    {
      "epoch": 0.978,
      "grad_norm": 0.045071106404066086,
      "learning_rate": 2.555e-05,
      "loss": 0.003,
      "step": 34230
    },
    {
      "epoch": 0.9782857142857143,
      "grad_norm": 0.27501365542411804,
      "learning_rate": 2.5542857142857146e-05,
      "loss": 0.0013,
      "step": 34240
    },
    {
      "epoch": 0.9785714285714285,
      "grad_norm": 0.1082199215888977,
      "learning_rate": 2.5535714285714284e-05,
      "loss": 0.0024,
      "step": 34250
    },
    {
      "epoch": 0.9788571428571429,
      "grad_norm": 0.0865602120757103,
      "learning_rate": 2.552857142857143e-05,
      "loss": 0.0021,
      "step": 34260
    },
    {
      "epoch": 0.9791428571428571,
      "grad_norm": 0.15298861265182495,
      "learning_rate": 2.5521428571428575e-05,
      "loss": 0.003,
      "step": 34270
    },
    {
      "epoch": 0.9794285714285714,
      "grad_norm": 0.18323910236358643,
      "learning_rate": 2.5514285714285713e-05,
      "loss": 0.0007,
      "step": 34280
    },
    {
      "epoch": 0.9797142857142858,
      "grad_norm": 0.13092002272605896,
      "learning_rate": 2.5507142857142858e-05,
      "loss": 0.0013,
      "step": 34290
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.09243252873420715,
      "learning_rate": 2.5500000000000003e-05,
      "loss": 0.0007,
      "step": 34300
    },
    {
      "epoch": 0.9802857142857143,
      "grad_norm": 0.0,
      "learning_rate": 2.5492857142857145e-05,
      "loss": 0.0019,
      "step": 34310
    },
    {
      "epoch": 0.9805714285714285,
      "grad_norm": 0.2106933444738388,
      "learning_rate": 2.5485714285714287e-05,
      "loss": 0.0022,
      "step": 34320
    },
    {
      "epoch": 0.9808571428571429,
      "grad_norm": 0.04512403532862663,
      "learning_rate": 2.547857142857143e-05,
      "loss": 0.0013,
      "step": 34330
    },
    {
      "epoch": 0.9811428571428571,
      "grad_norm": 0.22095824778079987,
      "learning_rate": 2.5471428571428573e-05,
      "loss": 0.0012,
      "step": 34340
    },
    {
      "epoch": 0.9814285714285714,
      "grad_norm": 0.08060384541749954,
      "learning_rate": 2.5464285714285712e-05,
      "loss": 0.001,
      "step": 34350
    },
    {
      "epoch": 0.9817142857142858,
      "grad_norm": 0.04349739849567413,
      "learning_rate": 2.5457142857142857e-05,
      "loss": 0.0015,
      "step": 34360
    },
    {
      "epoch": 0.982,
      "grad_norm": 0.12103749811649323,
      "learning_rate": 2.5450000000000002e-05,
      "loss": 0.0015,
      "step": 34370
    },
    {
      "epoch": 0.9822857142857143,
      "grad_norm": 0.05420893803238869,
      "learning_rate": 2.5442857142857147e-05,
      "loss": 0.0005,
      "step": 34380
    },
    {
      "epoch": 0.9825714285714285,
      "grad_norm": 0.039583850651979446,
      "learning_rate": 2.5435714285714285e-05,
      "loss": 0.0006,
      "step": 34390
    },
    {
      "epoch": 0.9828571428571429,
      "grad_norm": 0.29813480377197266,
      "learning_rate": 2.542857142857143e-05,
      "loss": 0.0004,
      "step": 34400
    },
    {
      "epoch": 0.9831428571428571,
      "grad_norm": 0.0782749205827713,
      "learning_rate": 2.5421428571428572e-05,
      "loss": 0.0012,
      "step": 34410
    },
    {
      "epoch": 0.9834285714285714,
      "grad_norm": 0.05995915085077286,
      "learning_rate": 2.5414285714285717e-05,
      "loss": 0.0018,
      "step": 34420
    },
    {
      "epoch": 0.9837142857142858,
      "grad_norm": 0.04574268311262131,
      "learning_rate": 2.5407142857142856e-05,
      "loss": 0.002,
      "step": 34430
    },
    {
      "epoch": 0.984,
      "grad_norm": 0.052987463772296906,
      "learning_rate": 2.54e-05,
      "loss": 0.0005,
      "step": 34440
    },
    {
      "epoch": 0.9842857142857143,
      "grad_norm": 0.07643342018127441,
      "learning_rate": 2.5392857142857146e-05,
      "loss": 0.0013,
      "step": 34450
    },
    {
      "epoch": 0.9845714285714285,
      "grad_norm": 0.04311222583055496,
      "learning_rate": 2.5385714285714284e-05,
      "loss": 0.0019,
      "step": 34460
    },
    {
      "epoch": 0.9848571428571429,
      "grad_norm": 0.03815116733312607,
      "learning_rate": 2.537857142857143e-05,
      "loss": 0.0018,
      "step": 34470
    },
    {
      "epoch": 0.9851428571428571,
      "grad_norm": 0.25686103105545044,
      "learning_rate": 2.5371428571428574e-05,
      "loss": 0.0022,
      "step": 34480
    },
    {
      "epoch": 0.9854285714285714,
      "grad_norm": 0.0431954488158226,
      "learning_rate": 2.536428571428572e-05,
      "loss": 0.0012,
      "step": 34490
    },
    {
      "epoch": 0.9857142857142858,
      "grad_norm": 0.042997539043426514,
      "learning_rate": 2.5357142857142858e-05,
      "loss": 0.002,
      "step": 34500
    },
    {
      "epoch": 0.986,
      "grad_norm": 0.04054221138358116,
      "learning_rate": 2.5350000000000003e-05,
      "loss": 0.0014,
      "step": 34510
    },
    {
      "epoch": 0.9862857142857143,
      "grad_norm": 0.040118180215358734,
      "learning_rate": 2.5342857142857145e-05,
      "loss": 0.0013,
      "step": 34520
    },
    {
      "epoch": 0.9865714285714285,
      "grad_norm": 0.047396671026945114,
      "learning_rate": 2.5335714285714286e-05,
      "loss": 0.0024,
      "step": 34530
    },
    {
      "epoch": 0.9868571428571429,
      "grad_norm": 0.0,
      "learning_rate": 2.5328571428571428e-05,
      "loss": 0.0017,
      "step": 34540
    },
    {
      "epoch": 0.9871428571428571,
      "grad_norm": 0.04298932105302811,
      "learning_rate": 2.5321428571428573e-05,
      "loss": 0.0016,
      "step": 34550
    },
    {
      "epoch": 0.9874285714285714,
      "grad_norm": 0.05222282186150551,
      "learning_rate": 2.5314285714285718e-05,
      "loss": 0.0004,
      "step": 34560
    },
    {
      "epoch": 0.9877142857142858,
      "grad_norm": 0.12475427985191345,
      "learning_rate": 2.5307142857142857e-05,
      "loss": 0.0009,
      "step": 34570
    },
    {
      "epoch": 0.988,
      "grad_norm": 0.03911697119474411,
      "learning_rate": 2.5300000000000002e-05,
      "loss": 0.0019,
      "step": 34580
    },
    {
      "epoch": 0.9882857142857143,
      "grad_norm": 0.04337088763713837,
      "learning_rate": 2.5292857142857147e-05,
      "loss": 0.0028,
      "step": 34590
    },
    {
      "epoch": 0.9885714285714285,
      "grad_norm": 0.0,
      "learning_rate": 2.5285714285714285e-05,
      "loss": 0.0016,
      "step": 34600
    },
    {
      "epoch": 0.9888571428571429,
      "grad_norm": 0.15273064374923706,
      "learning_rate": 2.527857142857143e-05,
      "loss": 0.0012,
      "step": 34610
    },
    {
      "epoch": 0.9891428571428571,
      "grad_norm": 0.0,
      "learning_rate": 2.5271428571428575e-05,
      "loss": 0.0027,
      "step": 34620
    },
    {
      "epoch": 0.9894285714285714,
      "grad_norm": 0.03611402586102486,
      "learning_rate": 2.5264285714285717e-05,
      "loss": 0.0011,
      "step": 34630
    },
    {
      "epoch": 0.9897142857142858,
      "grad_norm": 0.1656741052865982,
      "learning_rate": 2.5257142857142855e-05,
      "loss": 0.0014,
      "step": 34640
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.04144657775759697,
      "learning_rate": 2.525e-05,
      "loss": 0.0013,
      "step": 34650
    },
    {
      "epoch": 0.9902857142857143,
      "grad_norm": 0.024364272132515907,
      "learning_rate": 2.5242857142857146e-05,
      "loss": 0.0014,
      "step": 34660
    },
    {
      "epoch": 0.9905714285714285,
      "grad_norm": 0.22701309621334076,
      "learning_rate": 2.5235714285714284e-05,
      "loss": 0.0028,
      "step": 34670
    },
    {
      "epoch": 0.9908571428571429,
      "grad_norm": 0.18486469984054565,
      "learning_rate": 2.522857142857143e-05,
      "loss": 0.0018,
      "step": 34680
    },
    {
      "epoch": 0.9911428571428571,
      "grad_norm": 0.034391120076179504,
      "learning_rate": 2.5221428571428574e-05,
      "loss": 0.0005,
      "step": 34690
    },
    {
      "epoch": 0.9914285714285714,
      "grad_norm": 0.055915363132953644,
      "learning_rate": 2.521428571428572e-05,
      "loss": 0.0022,
      "step": 34700
    },
    {
      "epoch": 0.9917142857142857,
      "grad_norm": 0.0385143980383873,
      "learning_rate": 2.5207142857142858e-05,
      "loss": 0.0023,
      "step": 34710
    },
    {
      "epoch": 0.992,
      "grad_norm": 0.0586974062025547,
      "learning_rate": 2.5200000000000003e-05,
      "loss": 0.0011,
      "step": 34720
    },
    {
      "epoch": 0.9922857142857143,
      "grad_norm": 0.0,
      "learning_rate": 2.5192857142857144e-05,
      "loss": 0.0007,
      "step": 34730
    },
    {
      "epoch": 0.9925714285714285,
      "grad_norm": 0.04751184582710266,
      "learning_rate": 2.5185714285714286e-05,
      "loss": 0.0014,
      "step": 34740
    },
    {
      "epoch": 0.9928571428571429,
      "grad_norm": 0.16216416656970978,
      "learning_rate": 2.5178571428571428e-05,
      "loss": 0.003,
      "step": 34750
    },
    {
      "epoch": 0.9931428571428571,
      "grad_norm": 0.16733865439891815,
      "learning_rate": 2.5171428571428573e-05,
      "loss": 0.0018,
      "step": 34760
    },
    {
      "epoch": 0.9934285714285714,
      "grad_norm": 0.05068473517894745,
      "learning_rate": 2.5164285714285718e-05,
      "loss": 0.0018,
      "step": 34770
    },
    {
      "epoch": 0.9937142857142857,
      "grad_norm": 0.04037744179368019,
      "learning_rate": 2.5157142857142856e-05,
      "loss": 0.0019,
      "step": 34780
    },
    {
      "epoch": 0.994,
      "grad_norm": 0.1714431792497635,
      "learning_rate": 2.515e-05,
      "loss": 0.0016,
      "step": 34790
    },
    {
      "epoch": 0.9942857142857143,
      "grad_norm": 0.11154141277074814,
      "learning_rate": 2.5142857142857147e-05,
      "loss": 0.0016,
      "step": 34800
    },
    {
      "epoch": 0.9945714285714286,
      "grad_norm": 0.044533681124448776,
      "learning_rate": 2.5135714285714285e-05,
      "loss": 0.0019,
      "step": 34810
    },
    {
      "epoch": 0.9948571428571429,
      "grad_norm": 0.040978286415338516,
      "learning_rate": 2.512857142857143e-05,
      "loss": 0.0009,
      "step": 34820
    },
    {
      "epoch": 0.9951428571428571,
      "grad_norm": 0.047182608395814896,
      "learning_rate": 2.5121428571428575e-05,
      "loss": 0.0009,
      "step": 34830
    },
    {
      "epoch": 0.9954285714285714,
      "grad_norm": 0.03523266315460205,
      "learning_rate": 2.5114285714285717e-05,
      "loss": 0.0004,
      "step": 34840
    },
    {
      "epoch": 0.9957142857142857,
      "grad_norm": 0.044272612780332565,
      "learning_rate": 2.510714285714286e-05,
      "loss": 0.0012,
      "step": 34850
    },
    {
      "epoch": 0.996,
      "grad_norm": 0.047954365611076355,
      "learning_rate": 2.51e-05,
      "loss": 0.0009,
      "step": 34860
    },
    {
      "epoch": 0.9962857142857143,
      "grad_norm": 0.0805635005235672,
      "learning_rate": 2.5092857142857145e-05,
      "loss": 0.0007,
      "step": 34870
    },
    {
      "epoch": 0.9965714285714286,
      "grad_norm": 0.0,
      "learning_rate": 2.5085714285714284e-05,
      "loss": 0.0015,
      "step": 34880
    },
    {
      "epoch": 0.9968571428571429,
      "grad_norm": 0.04247123375535011,
      "learning_rate": 2.507857142857143e-05,
      "loss": 0.0013,
      "step": 34890
    },
    {
      "epoch": 0.9971428571428571,
      "grad_norm": 0.05680415779352188,
      "learning_rate": 2.5071428571428574e-05,
      "loss": 0.0014,
      "step": 34900
    },
    {
      "epoch": 0.9974285714285714,
      "grad_norm": 0.0,
      "learning_rate": 2.506428571428572e-05,
      "loss": 0.0014,
      "step": 34910
    },
    {
      "epoch": 0.9977142857142857,
      "grad_norm": 0.04452025517821312,
      "learning_rate": 2.5057142857142857e-05,
      "loss": 0.0009,
      "step": 34920
    },
    {
      "epoch": 0.998,
      "grad_norm": 0.3208107650279999,
      "learning_rate": 2.5050000000000002e-05,
      "loss": 0.0015,
      "step": 34930
    },
    {
      "epoch": 0.9982857142857143,
      "grad_norm": 0.18433792889118195,
      "learning_rate": 2.5042857142857144e-05,
      "loss": 0.0022,
      "step": 34940
    },
    {
      "epoch": 0.9985714285714286,
      "grad_norm": 0.20353545248508453,
      "learning_rate": 2.5035714285714286e-05,
      "loss": 0.0012,
      "step": 34950
    },
    {
      "epoch": 0.9988571428571429,
      "grad_norm": 0.0,
      "learning_rate": 2.5028571428571428e-05,
      "loss": 0.0007,
      "step": 34960
    },
    {
      "epoch": 0.9991428571428571,
      "grad_norm": 0.041116539388895035,
      "learning_rate": 2.5021428571428573e-05,
      "loss": 0.0016,
      "step": 34970
    },
    {
      "epoch": 0.9994285714285714,
      "grad_norm": 0.10747411847114563,
      "learning_rate": 2.5014285714285718e-05,
      "loss": 0.0022,
      "step": 34980
    },
    {
      "epoch": 0.9997142857142857,
      "grad_norm": 0.0795016959309578,
      "learning_rate": 2.5007142857142856e-05,
      "loss": 0.0015,
      "step": 34990
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.06363096088171005,
      "learning_rate": 2.5e-05,
      "loss": 0.0021,
      "step": 35000
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.0013504013186320662,
      "eval_runtime": 86.6045,
      "eval_samples_per_second": 1616.544,
      "eval_steps_per_second": 40.414,
      "step": 35000
    },
    {
      "epoch": 1.0002857142857142,
      "grad_norm": 0.3072049617767334,
      "learning_rate": 2.4992857142857143e-05,
      "loss": 0.0017,
      "step": 35010
    },
    {
      "epoch": 1.0005714285714287,
      "grad_norm": 0.09020135551691055,
      "learning_rate": 2.4985714285714288e-05,
      "loss": 0.0016,
      "step": 35020
    },
    {
      "epoch": 1.000857142857143,
      "grad_norm": 0.07659859210252762,
      "learning_rate": 2.497857142857143e-05,
      "loss": 0.0006,
      "step": 35030
    },
    {
      "epoch": 1.0011428571428571,
      "grad_norm": 0.04355199262499809,
      "learning_rate": 2.4971428571428575e-05,
      "loss": 0.0009,
      "step": 35040
    },
    {
      "epoch": 1.0014285714285713,
      "grad_norm": 0.04935068264603615,
      "learning_rate": 2.4964285714285717e-05,
      "loss": 0.0004,
      "step": 35050
    },
    {
      "epoch": 1.0017142857142858,
      "grad_norm": 0.05353044718503952,
      "learning_rate": 2.4957142857142858e-05,
      "loss": 0.0013,
      "step": 35060
    },
    {
      "epoch": 1.002,
      "grad_norm": 0.11705190688371658,
      "learning_rate": 2.495e-05,
      "loss": 0.0014,
      "step": 35070
    },
    {
      "epoch": 1.0022857142857142,
      "grad_norm": 0.0,
      "learning_rate": 2.4942857142857142e-05,
      "loss": 0.0008,
      "step": 35080
    },
    {
      "epoch": 1.0025714285714287,
      "grad_norm": 0.13738900423049927,
      "learning_rate": 2.4935714285714287e-05,
      "loss": 0.001,
      "step": 35090
    },
    {
      "epoch": 1.002857142857143,
      "grad_norm": 0.0,
      "learning_rate": 2.492857142857143e-05,
      "loss": 0.0014,
      "step": 35100
    },
    {
      "epoch": 1.0031428571428571,
      "grad_norm": 0.0,
      "learning_rate": 2.4921428571428574e-05,
      "loss": 0.0002,
      "step": 35110
    },
    {
      "epoch": 1.0034285714285713,
      "grad_norm": 0.0,
      "learning_rate": 2.4914285714285715e-05,
      "loss": 0.0014,
      "step": 35120
    },
    {
      "epoch": 1.0037142857142858,
      "grad_norm": 0.0,
      "learning_rate": 2.490714285714286e-05,
      "loss": 0.0016,
      "step": 35130
    },
    {
      "epoch": 1.004,
      "grad_norm": 0.041508134454488754,
      "learning_rate": 2.4900000000000002e-05,
      "loss": 0.0008,
      "step": 35140
    },
    {
      "epoch": 1.0042857142857142,
      "grad_norm": 0.0,
      "learning_rate": 2.4892857142857144e-05,
      "loss": 0.0011,
      "step": 35150
    },
    {
      "epoch": 1.0045714285714287,
      "grad_norm": 0.03495018929243088,
      "learning_rate": 2.4885714285714286e-05,
      "loss": 0.0012,
      "step": 35160
    },
    {
      "epoch": 1.004857142857143,
      "grad_norm": 0.0,
      "learning_rate": 2.4878571428571427e-05,
      "loss": 0.0014,
      "step": 35170
    },
    {
      "epoch": 1.0051428571428571,
      "grad_norm": 0.06123453751206398,
      "learning_rate": 2.4871428571428572e-05,
      "loss": 0.002,
      "step": 35180
    },
    {
      "epoch": 1.0054285714285713,
      "grad_norm": 0.09395898133516312,
      "learning_rate": 2.4864285714285714e-05,
      "loss": 0.0012,
      "step": 35190
    },
    {
      "epoch": 1.0057142857142858,
      "grad_norm": 0.08865035325288773,
      "learning_rate": 2.485714285714286e-05,
      "loss": 0.0017,
      "step": 35200
    },
    {
      "epoch": 1.006,
      "grad_norm": 0.076502725481987,
      "learning_rate": 2.485e-05,
      "loss": 0.0024,
      "step": 35210
    },
    {
      "epoch": 1.0062857142857142,
      "grad_norm": 0.24774682521820068,
      "learning_rate": 2.4842857142857143e-05,
      "loss": 0.0019,
      "step": 35220
    },
    {
      "epoch": 1.0065714285714287,
      "grad_norm": 0.04670839384198189,
      "learning_rate": 2.4835714285714288e-05,
      "loss": 0.0012,
      "step": 35230
    },
    {
      "epoch": 1.006857142857143,
      "grad_norm": 0.08362496644258499,
      "learning_rate": 2.482857142857143e-05,
      "loss": 0.0005,
      "step": 35240
    },
    {
      "epoch": 1.0071428571428571,
      "grad_norm": 0.013835592195391655,
      "learning_rate": 2.4821428571428575e-05,
      "loss": 0.0021,
      "step": 35250
    },
    {
      "epoch": 1.0074285714285713,
      "grad_norm": 0.03840937465429306,
      "learning_rate": 2.4814285714285716e-05,
      "loss": 0.0012,
      "step": 35260
    },
    {
      "epoch": 1.0077142857142858,
      "grad_norm": 0.1524890512228012,
      "learning_rate": 2.4807142857142858e-05,
      "loss": 0.0015,
      "step": 35270
    },
    {
      "epoch": 1.008,
      "grad_norm": 0.2612549960613251,
      "learning_rate": 2.48e-05,
      "loss": 0.0014,
      "step": 35280
    },
    {
      "epoch": 1.0082857142857142,
      "grad_norm": 0.1707819104194641,
      "learning_rate": 2.479285714285714e-05,
      "loss": 0.0011,
      "step": 35290
    },
    {
      "epoch": 1.0085714285714287,
      "grad_norm": 0.04442228004336357,
      "learning_rate": 2.4785714285714287e-05,
      "loss": 0.0005,
      "step": 35300
    },
    {
      "epoch": 1.008857142857143,
      "grad_norm": 0.04019628465175629,
      "learning_rate": 2.4778571428571428e-05,
      "loss": 0.0011,
      "step": 35310
    },
    {
      "epoch": 1.0091428571428571,
      "grad_norm": 0.11165199428796768,
      "learning_rate": 2.4771428571428573e-05,
      "loss": 0.0011,
      "step": 35320
    },
    {
      "epoch": 1.0094285714285713,
      "grad_norm": 0.22260573506355286,
      "learning_rate": 2.4764285714285715e-05,
      "loss": 0.0019,
      "step": 35330
    },
    {
      "epoch": 1.0097142857142858,
      "grad_norm": 0.0470484159886837,
      "learning_rate": 2.475714285714286e-05,
      "loss": 0.002,
      "step": 35340
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.12625205516815186,
      "learning_rate": 2.4750000000000002e-05,
      "loss": 0.0012,
      "step": 35350
    },
    {
      "epoch": 1.0102857142857142,
      "grad_norm": 0.0,
      "learning_rate": 2.4742857142857147e-05,
      "loss": 0.001,
      "step": 35360
    },
    {
      "epoch": 1.0105714285714287,
      "grad_norm": 0.09064595401287079,
      "learning_rate": 2.473571428571429e-05,
      "loss": 0.001,
      "step": 35370
    },
    {
      "epoch": 1.010857142857143,
      "grad_norm": 0.0,
      "learning_rate": 2.4728571428571427e-05,
      "loss": 0.0003,
      "step": 35380
    },
    {
      "epoch": 1.0111428571428571,
      "grad_norm": 0.0,
      "learning_rate": 2.4721428571428572e-05,
      "loss": 0.0012,
      "step": 35390
    },
    {
      "epoch": 1.0114285714285713,
      "grad_norm": 0.18107005953788757,
      "learning_rate": 2.4714285714285714e-05,
      "loss": 0.0018,
      "step": 35400
    },
    {
      "epoch": 1.0117142857142858,
      "grad_norm": 0.0,
      "learning_rate": 2.470714285714286e-05,
      "loss": 0.0011,
      "step": 35410
    },
    {
      "epoch": 1.012,
      "grad_norm": 0.23925024271011353,
      "learning_rate": 2.47e-05,
      "loss": 0.0022,
      "step": 35420
    },
    {
      "epoch": 1.0122857142857142,
      "grad_norm": 0.2336394190788269,
      "learning_rate": 2.4692857142857146e-05,
      "loss": 0.0004,
      "step": 35430
    },
    {
      "epoch": 1.0125714285714287,
      "grad_norm": 0.058777205646038055,
      "learning_rate": 2.4685714285714288e-05,
      "loss": 0.0013,
      "step": 35440
    },
    {
      "epoch": 1.012857142857143,
      "grad_norm": 0.22589074075222015,
      "learning_rate": 2.467857142857143e-05,
      "loss": 0.002,
      "step": 35450
    },
    {
      "epoch": 1.0131428571428571,
      "grad_norm": 0.3008711040019989,
      "learning_rate": 2.4671428571428574e-05,
      "loss": 0.0005,
      "step": 35460
    },
    {
      "epoch": 1.0134285714285713,
      "grad_norm": 0.0948781743645668,
      "learning_rate": 2.4664285714285716e-05,
      "loss": 0.002,
      "step": 35470
    },
    {
      "epoch": 1.0137142857142858,
      "grad_norm": 0.0,
      "learning_rate": 2.4657142857142858e-05,
      "loss": 0.0007,
      "step": 35480
    },
    {
      "epoch": 1.014,
      "grad_norm": 0.16010597348213196,
      "learning_rate": 2.465e-05,
      "loss": 0.0012,
      "step": 35490
    },
    {
      "epoch": 1.0142857142857142,
      "grad_norm": 0.08262575417757034,
      "learning_rate": 2.4642857142857145e-05,
      "loss": 0.0024,
      "step": 35500
    },
    {
      "epoch": 1.0145714285714287,
      "grad_norm": 0.08545619994401932,
      "learning_rate": 2.4635714285714286e-05,
      "loss": 0.0008,
      "step": 35510
    },
    {
      "epoch": 1.014857142857143,
      "grad_norm": 0.2239454835653305,
      "learning_rate": 2.4628571428571428e-05,
      "loss": 0.0017,
      "step": 35520
    },
    {
      "epoch": 1.0151428571428571,
      "grad_norm": 0.04455955699086189,
      "learning_rate": 2.4621428571428573e-05,
      "loss": 0.0011,
      "step": 35530
    },
    {
      "epoch": 1.0154285714285713,
      "grad_norm": 0.3420041799545288,
      "learning_rate": 2.4614285714285715e-05,
      "loss": 0.0024,
      "step": 35540
    },
    {
      "epoch": 1.0157142857142858,
      "grad_norm": 0.09406794607639313,
      "learning_rate": 2.460714285714286e-05,
      "loss": 0.0012,
      "step": 35550
    },
    {
      "epoch": 1.016,
      "grad_norm": 0.06005837395787239,
      "learning_rate": 2.46e-05,
      "loss": 0.0019,
      "step": 35560
    },
    {
      "epoch": 1.0162857142857142,
      "grad_norm": 0.044778529554605484,
      "learning_rate": 2.4592857142857147e-05,
      "loss": 0.0008,
      "step": 35570
    },
    {
      "epoch": 1.0165714285714285,
      "grad_norm": 0.04177243635058403,
      "learning_rate": 2.458571428571429e-05,
      "loss": 0.0011,
      "step": 35580
    },
    {
      "epoch": 1.016857142857143,
      "grad_norm": 0.03791552782058716,
      "learning_rate": 2.457857142857143e-05,
      "loss": 0.0011,
      "step": 35590
    },
    {
      "epoch": 1.0171428571428571,
      "grad_norm": 0.08813836425542831,
      "learning_rate": 2.4571428571428572e-05,
      "loss": 0.0002,
      "step": 35600
    },
    {
      "epoch": 1.0174285714285713,
      "grad_norm": 0.28942549228668213,
      "learning_rate": 2.4564285714285714e-05,
      "loss": 0.0019,
      "step": 35610
    },
    {
      "epoch": 1.0177142857142858,
      "grad_norm": 0.0,
      "learning_rate": 2.455714285714286e-05,
      "loss": 0.0012,
      "step": 35620
    },
    {
      "epoch": 1.018,
      "grad_norm": 0.04817589372396469,
      "learning_rate": 2.455e-05,
      "loss": 0.0013,
      "step": 35630
    },
    {
      "epoch": 1.0182857142857142,
      "grad_norm": 0.04650460556149483,
      "learning_rate": 2.4542857142857146e-05,
      "loss": 0.0011,
      "step": 35640
    },
    {
      "epoch": 1.0185714285714287,
      "grad_norm": 0.0,
      "learning_rate": 2.4535714285714287e-05,
      "loss": 0.0005,
      "step": 35650
    },
    {
      "epoch": 1.018857142857143,
      "grad_norm": 0.08201270550489426,
      "learning_rate": 2.452857142857143e-05,
      "loss": 0.0013,
      "step": 35660
    },
    {
      "epoch": 1.0191428571428571,
      "grad_norm": 0.057799194008111954,
      "learning_rate": 2.4521428571428574e-05,
      "loss": 0.0009,
      "step": 35670
    },
    {
      "epoch": 1.0194285714285714,
      "grad_norm": 0.09788550436496735,
      "learning_rate": 2.4514285714285716e-05,
      "loss": 0.0015,
      "step": 35680
    },
    {
      "epoch": 1.0197142857142858,
      "grad_norm": 0.04372743144631386,
      "learning_rate": 2.4507142857142857e-05,
      "loss": 0.0022,
      "step": 35690
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.038021743297576904,
      "learning_rate": 2.45e-05,
      "loss": 0.0015,
      "step": 35700
    },
    {
      "epoch": 1.0202857142857142,
      "grad_norm": 0.0,
      "learning_rate": 2.4492857142857144e-05,
      "loss": 0.0015,
      "step": 35710
    },
    {
      "epoch": 1.0205714285714285,
      "grad_norm": 0.0,
      "learning_rate": 2.4485714285714286e-05,
      "loss": 0.0015,
      "step": 35720
    },
    {
      "epoch": 1.020857142857143,
      "grad_norm": 0.039047833532094955,
      "learning_rate": 2.4478571428571428e-05,
      "loss": 0.0012,
      "step": 35730
    },
    {
      "epoch": 1.0211428571428571,
      "grad_norm": 0.17859375476837158,
      "learning_rate": 2.4471428571428573e-05,
      "loss": 0.0024,
      "step": 35740
    },
    {
      "epoch": 1.0214285714285714,
      "grad_norm": 0.08784301578998566,
      "learning_rate": 2.4464285714285715e-05,
      "loss": 0.0005,
      "step": 35750
    },
    {
      "epoch": 1.0217142857142858,
      "grad_norm": 0.03578438237309456,
      "learning_rate": 2.445714285714286e-05,
      "loss": 0.0008,
      "step": 35760
    },
    {
      "epoch": 1.022,
      "grad_norm": 0.11819930374622345,
      "learning_rate": 2.445e-05,
      "loss": 0.0015,
      "step": 35770
    },
    {
      "epoch": 1.0222857142857142,
      "grad_norm": 0.0,
      "learning_rate": 2.4442857142857146e-05,
      "loss": 0.001,
      "step": 35780
    },
    {
      "epoch": 1.0225714285714285,
      "grad_norm": 0.13461121916770935,
      "learning_rate": 2.4435714285714288e-05,
      "loss": 0.0015,
      "step": 35790
    },
    {
      "epoch": 1.022857142857143,
      "grad_norm": 0.04012828692793846,
      "learning_rate": 2.442857142857143e-05,
      "loss": 0.0009,
      "step": 35800
    },
    {
      "epoch": 1.0231428571428571,
      "grad_norm": 0.045868370682001114,
      "learning_rate": 2.442142857142857e-05,
      "loss": 0.0012,
      "step": 35810
    },
    {
      "epoch": 1.0234285714285714,
      "grad_norm": 0.20667342841625214,
      "learning_rate": 2.4414285714285713e-05,
      "loss": 0.0013,
      "step": 35820
    },
    {
      "epoch": 1.0237142857142858,
      "grad_norm": 0.22415055334568024,
      "learning_rate": 2.440714285714286e-05,
      "loss": 0.0017,
      "step": 35830
    },
    {
      "epoch": 1.024,
      "grad_norm": 0.48255687952041626,
      "learning_rate": 2.44e-05,
      "loss": 0.0018,
      "step": 35840
    },
    {
      "epoch": 1.0242857142857142,
      "grad_norm": 0.0,
      "learning_rate": 2.4392857142857145e-05,
      "loss": 0.0008,
      "step": 35850
    },
    {
      "epoch": 1.0245714285714285,
      "grad_norm": 0.03603390231728554,
      "learning_rate": 2.4385714285714287e-05,
      "loss": 0.0018,
      "step": 35860
    },
    {
      "epoch": 1.024857142857143,
      "grad_norm": 0.030228717252612114,
      "learning_rate": 2.437857142857143e-05,
      "loss": 0.0019,
      "step": 35870
    },
    {
      "epoch": 1.0251428571428571,
      "grad_norm": 0.1283881962299347,
      "learning_rate": 2.4371428571428574e-05,
      "loss": 0.001,
      "step": 35880
    },
    {
      "epoch": 1.0254285714285714,
      "grad_norm": 0.097699373960495,
      "learning_rate": 2.4364285714285716e-05,
      "loss": 0.0015,
      "step": 35890
    },
    {
      "epoch": 1.0257142857142858,
      "grad_norm": 0.04233486205339432,
      "learning_rate": 2.4357142857142857e-05,
      "loss": 0.0015,
      "step": 35900
    },
    {
      "epoch": 1.026,
      "grad_norm": 0.17395465075969696,
      "learning_rate": 2.435e-05,
      "loss": 0.0009,
      "step": 35910
    },
    {
      "epoch": 1.0262857142857142,
      "grad_norm": 0.05659607797861099,
      "learning_rate": 2.4342857142857144e-05,
      "loss": 0.001,
      "step": 35920
    },
    {
      "epoch": 1.0265714285714285,
      "grad_norm": 0.1214434877038002,
      "learning_rate": 2.4335714285714286e-05,
      "loss": 0.0014,
      "step": 35930
    },
    {
      "epoch": 1.026857142857143,
      "grad_norm": 0.04428773373365402,
      "learning_rate": 2.432857142857143e-05,
      "loss": 0.0015,
      "step": 35940
    },
    {
      "epoch": 1.0271428571428571,
      "grad_norm": 0.04457145556807518,
      "learning_rate": 2.4321428571428573e-05,
      "loss": 0.0007,
      "step": 35950
    },
    {
      "epoch": 1.0274285714285714,
      "grad_norm": 0.07380019128322601,
      "learning_rate": 2.4314285714285714e-05,
      "loss": 0.0017,
      "step": 35960
    },
    {
      "epoch": 1.0277142857142858,
      "grad_norm": 0.04849616810679436,
      "learning_rate": 2.430714285714286e-05,
      "loss": 0.0016,
      "step": 35970
    },
    {
      "epoch": 1.028,
      "grad_norm": 0.03181397542357445,
      "learning_rate": 2.43e-05,
      "loss": 0.0015,
      "step": 35980
    },
    {
      "epoch": 1.0282857142857142,
      "grad_norm": 0.028993818908929825,
      "learning_rate": 2.4292857142857146e-05,
      "loss": 0.0027,
      "step": 35990
    },
    {
      "epoch": 1.0285714285714285,
      "grad_norm": 0.09895111620426178,
      "learning_rate": 2.4285714285714288e-05,
      "loss": 0.0019,
      "step": 36000
    },
    {
      "epoch": 1.028857142857143,
      "grad_norm": 0.0,
      "learning_rate": 2.427857142857143e-05,
      "loss": 0.0019,
      "step": 36010
    },
    {
      "epoch": 1.0291428571428571,
      "grad_norm": 0.04180026054382324,
      "learning_rate": 2.427142857142857e-05,
      "loss": 0.0009,
      "step": 36020
    },
    {
      "epoch": 1.0294285714285714,
      "grad_norm": 0.0,
      "learning_rate": 2.4264285714285713e-05,
      "loss": 0.0022,
      "step": 36030
    },
    {
      "epoch": 1.0297142857142858,
      "grad_norm": 0.08171012997627258,
      "learning_rate": 2.4257142857142858e-05,
      "loss": 0.0014,
      "step": 36040
    },
    {
      "epoch": 1.03,
      "grad_norm": 0.0,
      "learning_rate": 2.425e-05,
      "loss": 0.0013,
      "step": 36050
    },
    {
      "epoch": 1.0302857142857142,
      "grad_norm": 0.045941151678562164,
      "learning_rate": 2.4242857142857145e-05,
      "loss": 0.0011,
      "step": 36060
    },
    {
      "epoch": 1.0305714285714285,
      "grad_norm": 0.14072126150131226,
      "learning_rate": 2.4235714285714287e-05,
      "loss": 0.001,
      "step": 36070
    },
    {
      "epoch": 1.030857142857143,
      "grad_norm": 0.07781895250082016,
      "learning_rate": 2.4228571428571432e-05,
      "loss": 0.0012,
      "step": 36080
    },
    {
      "epoch": 1.0311428571428571,
      "grad_norm": 0.0,
      "learning_rate": 2.4221428571428574e-05,
      "loss": 0.0016,
      "step": 36090
    },
    {
      "epoch": 1.0314285714285714,
      "grad_norm": 0.0424414798617363,
      "learning_rate": 2.4214285714285715e-05,
      "loss": 0.002,
      "step": 36100
    },
    {
      "epoch": 1.0317142857142858,
      "grad_norm": 0.13819622993469238,
      "learning_rate": 2.420714285714286e-05,
      "loss": 0.0008,
      "step": 36110
    },
    {
      "epoch": 1.032,
      "grad_norm": 0.05219944193959236,
      "learning_rate": 2.4200000000000002e-05,
      "loss": 0.0022,
      "step": 36120
    },
    {
      "epoch": 1.0322857142857143,
      "grad_norm": 0.0,
      "learning_rate": 2.4192857142857144e-05,
      "loss": 0.0015,
      "step": 36130
    },
    {
      "epoch": 1.0325714285714285,
      "grad_norm": 0.0,
      "learning_rate": 2.4185714285714286e-05,
      "loss": 0.0017,
      "step": 36140
    },
    {
      "epoch": 1.032857142857143,
      "grad_norm": 0.0,
      "learning_rate": 2.417857142857143e-05,
      "loss": 0.0023,
      "step": 36150
    },
    {
      "epoch": 1.0331428571428571,
      "grad_norm": 0.16708491742610931,
      "learning_rate": 2.4171428571428572e-05,
      "loss": 0.0017,
      "step": 36160
    },
    {
      "epoch": 1.0334285714285714,
      "grad_norm": 0.08674145489931107,
      "learning_rate": 2.4164285714285714e-05,
      "loss": 0.0019,
      "step": 36170
    },
    {
      "epoch": 1.0337142857142858,
      "grad_norm": 0.24809697270393372,
      "learning_rate": 2.415714285714286e-05,
      "loss": 0.0012,
      "step": 36180
    },
    {
      "epoch": 1.034,
      "grad_norm": 0.1822836846113205,
      "learning_rate": 2.415e-05,
      "loss": 0.0012,
      "step": 36190
    },
    {
      "epoch": 1.0342857142857143,
      "grad_norm": 0.3333193063735962,
      "learning_rate": 2.4142857142857146e-05,
      "loss": 0.0009,
      "step": 36200
    },
    {
      "epoch": 1.0345714285714285,
      "grad_norm": 0.2383767068386078,
      "learning_rate": 2.4135714285714288e-05,
      "loss": 0.0011,
      "step": 36210
    },
    {
      "epoch": 1.034857142857143,
      "grad_norm": 0.26381418108940125,
      "learning_rate": 2.412857142857143e-05,
      "loss": 0.0012,
      "step": 36220
    },
    {
      "epoch": 1.0351428571428571,
      "grad_norm": 0.060333557426929474,
      "learning_rate": 2.412142857142857e-05,
      "loss": 0.0007,
      "step": 36230
    },
    {
      "epoch": 1.0354285714285714,
      "grad_norm": 0.08539813756942749,
      "learning_rate": 2.4114285714285713e-05,
      "loss": 0.0006,
      "step": 36240
    },
    {
      "epoch": 1.0357142857142858,
      "grad_norm": 0.15366461873054504,
      "learning_rate": 2.4107142857142858e-05,
      "loss": 0.0013,
      "step": 36250
    },
    {
      "epoch": 1.036,
      "grad_norm": 0.04678426682949066,
      "learning_rate": 2.41e-05,
      "loss": 0.001,
      "step": 36260
    },
    {
      "epoch": 1.0362857142857143,
      "grad_norm": 0.04475614055991173,
      "learning_rate": 2.4092857142857145e-05,
      "loss": 0.0016,
      "step": 36270
    },
    {
      "epoch": 1.0365714285714285,
      "grad_norm": 0.07960677891969681,
      "learning_rate": 2.4085714285714286e-05,
      "loss": 0.0012,
      "step": 36280
    },
    {
      "epoch": 1.036857142857143,
      "grad_norm": 0.04553497955203056,
      "learning_rate": 2.407857142857143e-05,
      "loss": 0.0021,
      "step": 36290
    },
    {
      "epoch": 1.0371428571428571,
      "grad_norm": 0.0,
      "learning_rate": 2.4071428571428573e-05,
      "loss": 0.0016,
      "step": 36300
    },
    {
      "epoch": 1.0374285714285714,
      "grad_norm": 0.04610271751880646,
      "learning_rate": 2.4064285714285715e-05,
      "loss": 0.0017,
      "step": 36310
    },
    {
      "epoch": 1.0377142857142858,
      "grad_norm": 0.0,
      "learning_rate": 2.405714285714286e-05,
      "loss": 0.0011,
      "step": 36320
    },
    {
      "epoch": 1.038,
      "grad_norm": 0.07616990804672241,
      "learning_rate": 2.4050000000000002e-05,
      "loss": 0.0012,
      "step": 36330
    },
    {
      "epoch": 1.0382857142857143,
      "grad_norm": 0.0657726302742958,
      "learning_rate": 2.4042857142857144e-05,
      "loss": 0.0016,
      "step": 36340
    },
    {
      "epoch": 1.0385714285714285,
      "grad_norm": 0.0,
      "learning_rate": 2.4035714285714285e-05,
      "loss": 0.0015,
      "step": 36350
    },
    {
      "epoch": 1.038857142857143,
      "grad_norm": 0.11253821849822998,
      "learning_rate": 2.402857142857143e-05,
      "loss": 0.002,
      "step": 36360
    },
    {
      "epoch": 1.0391428571428571,
      "grad_norm": 0.10224314779043198,
      "learning_rate": 2.4021428571428572e-05,
      "loss": 0.0031,
      "step": 36370
    },
    {
      "epoch": 1.0394285714285714,
      "grad_norm": 0.12123531103134155,
      "learning_rate": 2.4014285714285714e-05,
      "loss": 0.0015,
      "step": 36380
    },
    {
      "epoch": 1.0397142857142858,
      "grad_norm": 0.19308531284332275,
      "learning_rate": 2.400714285714286e-05,
      "loss": 0.0011,
      "step": 36390
    },
    {
      "epoch": 1.04,
      "grad_norm": 0.10522328317165375,
      "learning_rate": 2.4e-05,
      "loss": 0.0012,
      "step": 36400
    },
    {
      "epoch": 1.0402857142857143,
      "grad_norm": 0.0438431091606617,
      "learning_rate": 2.3992857142857146e-05,
      "loss": 0.0012,
      "step": 36410
    },
    {
      "epoch": 1.0405714285714285,
      "grad_norm": 0.08124125748872757,
      "learning_rate": 2.3985714285714287e-05,
      "loss": 0.0015,
      "step": 36420
    },
    {
      "epoch": 1.040857142857143,
      "grad_norm": 0.034770216792821884,
      "learning_rate": 2.397857142857143e-05,
      "loss": 0.002,
      "step": 36430
    },
    {
      "epoch": 1.0411428571428571,
      "grad_norm": 0.06085288152098656,
      "learning_rate": 2.397142857142857e-05,
      "loss": 0.0011,
      "step": 36440
    },
    {
      "epoch": 1.0414285714285714,
      "grad_norm": 0.0,
      "learning_rate": 2.3964285714285713e-05,
      "loss": 0.0013,
      "step": 36450
    },
    {
      "epoch": 1.0417142857142858,
      "grad_norm": 0.07408182322978973,
      "learning_rate": 2.3957142857142858e-05,
      "loss": 0.0015,
      "step": 36460
    },
    {
      "epoch": 1.042,
      "grad_norm": 0.028843170031905174,
      "learning_rate": 2.395e-05,
      "loss": 0.0008,
      "step": 36470
    },
    {
      "epoch": 1.0422857142857143,
      "grad_norm": 0.0,
      "learning_rate": 2.3942857142857144e-05,
      "loss": 0.0014,
      "step": 36480
    },
    {
      "epoch": 1.0425714285714285,
      "grad_norm": 0.07346448302268982,
      "learning_rate": 2.3935714285714286e-05,
      "loss": 0.0009,
      "step": 36490
    },
    {
      "epoch": 1.042857142857143,
      "grad_norm": 0.0,
      "learning_rate": 2.392857142857143e-05,
      "loss": 0.0016,
      "step": 36500
    },
    {
      "epoch": 1.0431428571428571,
      "grad_norm": 0.26777124404907227,
      "learning_rate": 2.3921428571428573e-05,
      "loss": 0.0009,
      "step": 36510
    },
    {
      "epoch": 1.0434285714285714,
      "grad_norm": 0.0398726724088192,
      "learning_rate": 2.3914285714285715e-05,
      "loss": 0.001,
      "step": 36520
    },
    {
      "epoch": 1.0437142857142858,
      "grad_norm": 0.030858559533953667,
      "learning_rate": 2.390714285714286e-05,
      "loss": 0.001,
      "step": 36530
    },
    {
      "epoch": 1.044,
      "grad_norm": 0.044905439019203186,
      "learning_rate": 2.39e-05,
      "loss": 0.0019,
      "step": 36540
    },
    {
      "epoch": 1.0442857142857143,
      "grad_norm": 0.08061515539884567,
      "learning_rate": 2.3892857142857143e-05,
      "loss": 0.0013,
      "step": 36550
    },
    {
      "epoch": 1.0445714285714285,
      "grad_norm": 0.249581441283226,
      "learning_rate": 2.3885714285714285e-05,
      "loss": 0.0026,
      "step": 36560
    },
    {
      "epoch": 1.044857142857143,
      "grad_norm": 0.06576406210660934,
      "learning_rate": 2.387857142857143e-05,
      "loss": 0.0014,
      "step": 36570
    },
    {
      "epoch": 1.0451428571428572,
      "grad_norm": 0.0444367490708828,
      "learning_rate": 2.3871428571428572e-05,
      "loss": 0.0012,
      "step": 36580
    },
    {
      "epoch": 1.0454285714285714,
      "grad_norm": 0.12359385192394257,
      "learning_rate": 2.3864285714285717e-05,
      "loss": 0.0014,
      "step": 36590
    },
    {
      "epoch": 1.0457142857142858,
      "grad_norm": 0.10411515831947327,
      "learning_rate": 2.385714285714286e-05,
      "loss": 0.0003,
      "step": 36600
    },
    {
      "epoch": 1.046,
      "grad_norm": 0.05302269011735916,
      "learning_rate": 2.385e-05,
      "loss": 0.0013,
      "step": 36610
    },
    {
      "epoch": 1.0462857142857143,
      "grad_norm": 0.040877263993024826,
      "learning_rate": 2.3842857142857145e-05,
      "loss": 0.0016,
      "step": 36620
    },
    {
      "epoch": 1.0465714285714285,
      "grad_norm": 0.0440375842154026,
      "learning_rate": 2.3835714285714287e-05,
      "loss": 0.0026,
      "step": 36630
    },
    {
      "epoch": 1.046857142857143,
      "grad_norm": 0.057737551629543304,
      "learning_rate": 2.3828571428571432e-05,
      "loss": 0.0012,
      "step": 36640
    },
    {
      "epoch": 1.0471428571428572,
      "grad_norm": 0.0,
      "learning_rate": 2.3821428571428574e-05,
      "loss": 0.0014,
      "step": 36650
    },
    {
      "epoch": 1.0474285714285714,
      "grad_norm": 0.06166869029402733,
      "learning_rate": 2.3814285714285716e-05,
      "loss": 0.0006,
      "step": 36660
    },
    {
      "epoch": 1.0477142857142858,
      "grad_norm": 0.05769087374210358,
      "learning_rate": 2.3807142857142857e-05,
      "loss": 0.0009,
      "step": 36670
    },
    {
      "epoch": 1.048,
      "grad_norm": 0.0416557714343071,
      "learning_rate": 2.38e-05,
      "loss": 0.001,
      "step": 36680
    },
    {
      "epoch": 1.0482857142857143,
      "grad_norm": 0.11133939772844315,
      "learning_rate": 2.3792857142857144e-05,
      "loss": 0.0008,
      "step": 36690
    },
    {
      "epoch": 1.0485714285714285,
      "grad_norm": 0.0,
      "learning_rate": 2.3785714285714286e-05,
      "loss": 0.0016,
      "step": 36700
    },
    {
      "epoch": 1.048857142857143,
      "grad_norm": 0.042490120977163315,
      "learning_rate": 2.377857142857143e-05,
      "loss": 0.0017,
      "step": 36710
    },
    {
      "epoch": 1.0491428571428572,
      "grad_norm": 0.04817613586783409,
      "learning_rate": 2.3771428571428573e-05,
      "loss": 0.001,
      "step": 36720
    },
    {
      "epoch": 1.0494285714285714,
      "grad_norm": 0.05331912264227867,
      "learning_rate": 2.3764285714285718e-05,
      "loss": 0.0003,
      "step": 36730
    },
    {
      "epoch": 1.0497142857142858,
      "grad_norm": 0.06750845909118652,
      "learning_rate": 2.375714285714286e-05,
      "loss": 0.0012,
      "step": 36740
    },
    {
      "epoch": 1.05,
      "grad_norm": 0.4978044033050537,
      "learning_rate": 2.375e-05,
      "loss": 0.0025,
      "step": 36750
    },
    {
      "epoch": 1.0502857142857143,
      "grad_norm": 0.1142868623137474,
      "learning_rate": 2.3742857142857143e-05,
      "loss": 0.002,
      "step": 36760
    },
    {
      "epoch": 1.0505714285714285,
      "grad_norm": 0.2564452588558197,
      "learning_rate": 2.3735714285714285e-05,
      "loss": 0.0017,
      "step": 36770
    },
    {
      "epoch": 1.050857142857143,
      "grad_norm": 0.3066585958003998,
      "learning_rate": 2.372857142857143e-05,
      "loss": 0.0021,
      "step": 36780
    },
    {
      "epoch": 1.0511428571428572,
      "grad_norm": 0.05025012418627739,
      "learning_rate": 2.372142857142857e-05,
      "loss": 0.0009,
      "step": 36790
    },
    {
      "epoch": 1.0514285714285714,
      "grad_norm": 0.06763254106044769,
      "learning_rate": 2.3714285714285717e-05,
      "loss": 0.0017,
      "step": 36800
    },
    {
      "epoch": 1.0517142857142856,
      "grad_norm": 0.04508180543780327,
      "learning_rate": 2.370714285714286e-05,
      "loss": 0.0011,
      "step": 36810
    },
    {
      "epoch": 1.052,
      "grad_norm": 0.10236142575740814,
      "learning_rate": 2.37e-05,
      "loss": 0.0011,
      "step": 36820
    },
    {
      "epoch": 1.0522857142857143,
      "grad_norm": 0.04088839516043663,
      "learning_rate": 2.3692857142857145e-05,
      "loss": 0.0009,
      "step": 36830
    },
    {
      "epoch": 1.0525714285714285,
      "grad_norm": 0.04188006371259689,
      "learning_rate": 2.3685714285714287e-05,
      "loss": 0.0031,
      "step": 36840
    },
    {
      "epoch": 1.052857142857143,
      "grad_norm": 0.300777792930603,
      "learning_rate": 2.3678571428571432e-05,
      "loss": 0.0016,
      "step": 36850
    },
    {
      "epoch": 1.0531428571428572,
      "grad_norm": 0.08641684055328369,
      "learning_rate": 2.3671428571428574e-05,
      "loss": 0.0013,
      "step": 36860
    },
    {
      "epoch": 1.0534285714285714,
      "grad_norm": 0.07061564922332764,
      "learning_rate": 2.3664285714285715e-05,
      "loss": 0.0004,
      "step": 36870
    },
    {
      "epoch": 1.0537142857142858,
      "grad_norm": 0.2371794879436493,
      "learning_rate": 2.3657142857142857e-05,
      "loss": 0.002,
      "step": 36880
    },
    {
      "epoch": 1.054,
      "grad_norm": 0.04393193870782852,
      "learning_rate": 2.365e-05,
      "loss": 0.0011,
      "step": 36890
    },
    {
      "epoch": 1.0542857142857143,
      "grad_norm": 0.0,
      "learning_rate": 2.3642857142857144e-05,
      "loss": 0.0019,
      "step": 36900
    },
    {
      "epoch": 1.0545714285714285,
      "grad_norm": 0.09326248615980148,
      "learning_rate": 2.3635714285714286e-05,
      "loss": 0.0017,
      "step": 36910
    },
    {
      "epoch": 1.054857142857143,
      "grad_norm": 0.15719638764858246,
      "learning_rate": 2.362857142857143e-05,
      "loss": 0.0013,
      "step": 36920
    },
    {
      "epoch": 1.0551428571428572,
      "grad_norm": 0.0,
      "learning_rate": 2.3621428571428573e-05,
      "loss": 0.0015,
      "step": 36930
    },
    {
      "epoch": 1.0554285714285714,
      "grad_norm": 0.040099434554576874,
      "learning_rate": 2.3614285714285718e-05,
      "loss": 0.0007,
      "step": 36940
    },
    {
      "epoch": 1.0557142857142856,
      "grad_norm": 0.056230634450912476,
      "learning_rate": 2.360714285714286e-05,
      "loss": 0.0018,
      "step": 36950
    },
    {
      "epoch": 1.056,
      "grad_norm": 0.0,
      "learning_rate": 2.36e-05,
      "loss": 0.0025,
      "step": 36960
    },
    {
      "epoch": 1.0562857142857143,
      "grad_norm": 0.041444819420576096,
      "learning_rate": 2.3592857142857143e-05,
      "loss": 0.0011,
      "step": 36970
    },
    {
      "epoch": 1.0565714285714285,
      "grad_norm": 0.08027036488056183,
      "learning_rate": 2.3585714285714284e-05,
      "loss": 0.0015,
      "step": 36980
    },
    {
      "epoch": 1.056857142857143,
      "grad_norm": 0.08923570811748505,
      "learning_rate": 2.357857142857143e-05,
      "loss": 0.0014,
      "step": 36990
    },
    {
      "epoch": 1.0571428571428572,
      "grad_norm": 0.0,
      "learning_rate": 2.357142857142857e-05,
      "loss": 0.0006,
      "step": 37000
    },
    {
      "epoch": 1.0574285714285714,
      "grad_norm": 0.06530860811471939,
      "learning_rate": 2.3564285714285716e-05,
      "loss": 0.0019,
      "step": 37010
    },
    {
      "epoch": 1.0577142857142856,
      "grad_norm": 0.3547966182231903,
      "learning_rate": 2.3557142857142858e-05,
      "loss": 0.0012,
      "step": 37020
    },
    {
      "epoch": 1.058,
      "grad_norm": 0.051497701555490494,
      "learning_rate": 2.355e-05,
      "loss": 0.0004,
      "step": 37030
    },
    {
      "epoch": 1.0582857142857143,
      "grad_norm": 0.10167238116264343,
      "learning_rate": 2.3542857142857145e-05,
      "loss": 0.001,
      "step": 37040
    },
    {
      "epoch": 1.0585714285714285,
      "grad_norm": 0.046161677688360214,
      "learning_rate": 2.3535714285714287e-05,
      "loss": 0.0013,
      "step": 37050
    },
    {
      "epoch": 1.058857142857143,
      "grad_norm": 0.043809469789266586,
      "learning_rate": 2.3528571428571432e-05,
      "loss": 0.0009,
      "step": 37060
    },
    {
      "epoch": 1.0591428571428572,
      "grad_norm": 0.16166497766971588,
      "learning_rate": 2.3521428571428573e-05,
      "loss": 0.001,
      "step": 37070
    },
    {
      "epoch": 1.0594285714285714,
      "grad_norm": 0.14134427905082703,
      "learning_rate": 2.3514285714285715e-05,
      "loss": 0.001,
      "step": 37080
    },
    {
      "epoch": 1.0597142857142856,
      "grad_norm": 0.0,
      "learning_rate": 2.3507142857142857e-05,
      "loss": 0.0008,
      "step": 37090
    },
    {
      "epoch": 1.06,
      "grad_norm": 0.0,
      "learning_rate": 2.35e-05,
      "loss": 0.0007,
      "step": 37100
    },
    {
      "epoch": 1.0602857142857143,
      "grad_norm": 0.0,
      "learning_rate": 2.3492857142857144e-05,
      "loss": 0.0015,
      "step": 37110
    },
    {
      "epoch": 1.0605714285714285,
      "grad_norm": 0.04439419507980347,
      "learning_rate": 2.3485714285714285e-05,
      "loss": 0.0004,
      "step": 37120
    },
    {
      "epoch": 1.060857142857143,
      "grad_norm": 0.0,
      "learning_rate": 2.347857142857143e-05,
      "loss": 0.0009,
      "step": 37130
    },
    {
      "epoch": 1.0611428571428572,
      "grad_norm": 0.04250957444310188,
      "learning_rate": 2.3471428571428572e-05,
      "loss": 0.0008,
      "step": 37140
    },
    {
      "epoch": 1.0614285714285714,
      "grad_norm": 0.0,
      "learning_rate": 2.3464285714285717e-05,
      "loss": 0.001,
      "step": 37150
    },
    {
      "epoch": 1.0617142857142856,
      "grad_norm": 0.04541365057229996,
      "learning_rate": 2.345714285714286e-05,
      "loss": 0.002,
      "step": 37160
    },
    {
      "epoch": 1.062,
      "grad_norm": 0.13859570026397705,
      "learning_rate": 2.345e-05,
      "loss": 0.0018,
      "step": 37170
    },
    {
      "epoch": 1.0622857142857143,
      "grad_norm": 0.13238179683685303,
      "learning_rate": 2.3442857142857143e-05,
      "loss": 0.0011,
      "step": 37180
    },
    {
      "epoch": 1.0625714285714285,
      "grad_norm": 0.09205270558595657,
      "learning_rate": 2.3435714285714284e-05,
      "loss": 0.0015,
      "step": 37190
    },
    {
      "epoch": 1.062857142857143,
      "grad_norm": 0.05324356257915497,
      "learning_rate": 2.342857142857143e-05,
      "loss": 0.0017,
      "step": 37200
    },
    {
      "epoch": 1.0631428571428572,
      "grad_norm": 0.0896957740187645,
      "learning_rate": 2.342142857142857e-05,
      "loss": 0.0005,
      "step": 37210
    },
    {
      "epoch": 1.0634285714285714,
      "grad_norm": 0.048675697296857834,
      "learning_rate": 2.3414285714285716e-05,
      "loss": 0.0011,
      "step": 37220
    },
    {
      "epoch": 1.0637142857142856,
      "grad_norm": 0.04501127079129219,
      "learning_rate": 2.3407142857142858e-05,
      "loss": 0.0013,
      "step": 37230
    },
    {
      "epoch": 1.064,
      "grad_norm": 0.0,
      "learning_rate": 2.3400000000000003e-05,
      "loss": 0.0009,
      "step": 37240
    },
    {
      "epoch": 1.0642857142857143,
      "grad_norm": 0.29144570231437683,
      "learning_rate": 2.3392857142857145e-05,
      "loss": 0.0009,
      "step": 37250
    },
    {
      "epoch": 1.0645714285714285,
      "grad_norm": 0.07997948676347733,
      "learning_rate": 2.3385714285714286e-05,
      "loss": 0.0006,
      "step": 37260
    },
    {
      "epoch": 1.064857142857143,
      "grad_norm": 0.2243659645318985,
      "learning_rate": 2.337857142857143e-05,
      "loss": 0.0024,
      "step": 37270
    },
    {
      "epoch": 1.0651428571428572,
      "grad_norm": 0.08014298975467682,
      "learning_rate": 2.3371428571428573e-05,
      "loss": 0.0018,
      "step": 37280
    },
    {
      "epoch": 1.0654285714285714,
      "grad_norm": 0.04541625827550888,
      "learning_rate": 2.3364285714285715e-05,
      "loss": 0.0013,
      "step": 37290
    },
    {
      "epoch": 1.0657142857142856,
      "grad_norm": 0.05112050846219063,
      "learning_rate": 2.3357142857142857e-05,
      "loss": 0.002,
      "step": 37300
    },
    {
      "epoch": 1.066,
      "grad_norm": 0.0,
      "learning_rate": 2.3350000000000002e-05,
      "loss": 0.0009,
      "step": 37310
    },
    {
      "epoch": 1.0662857142857143,
      "grad_norm": 0.09424321353435516,
      "learning_rate": 2.3342857142857143e-05,
      "loss": 0.0013,
      "step": 37320
    },
    {
      "epoch": 1.0665714285714285,
      "grad_norm": 0.042325906455516815,
      "learning_rate": 2.3335714285714285e-05,
      "loss": 0.0008,
      "step": 37330
    },
    {
      "epoch": 1.066857142857143,
      "grad_norm": 0.03384953737258911,
      "learning_rate": 2.332857142857143e-05,
      "loss": 0.0008,
      "step": 37340
    },
    {
      "epoch": 1.0671428571428572,
      "grad_norm": 0.08199214935302734,
      "learning_rate": 2.3321428571428572e-05,
      "loss": 0.0006,
      "step": 37350
    },
    {
      "epoch": 1.0674285714285714,
      "grad_norm": 0.19071444869041443,
      "learning_rate": 2.3314285714285717e-05,
      "loss": 0.0013,
      "step": 37360
    },
    {
      "epoch": 1.0677142857142856,
      "grad_norm": 0.11687423288822174,
      "learning_rate": 2.330714285714286e-05,
      "loss": 0.0016,
      "step": 37370
    },
    {
      "epoch": 1.068,
      "grad_norm": 0.1995842158794403,
      "learning_rate": 2.3300000000000004e-05,
      "loss": 0.0011,
      "step": 37380
    },
    {
      "epoch": 1.0682857142857143,
      "grad_norm": 0.16568374633789062,
      "learning_rate": 2.3292857142857146e-05,
      "loss": 0.0016,
      "step": 37390
    },
    {
      "epoch": 1.0685714285714285,
      "grad_norm": 0.05130122974514961,
      "learning_rate": 2.3285714285714287e-05,
      "loss": 0.0022,
      "step": 37400
    },
    {
      "epoch": 1.068857142857143,
      "grad_norm": 0.045972585678100586,
      "learning_rate": 2.327857142857143e-05,
      "loss": 0.002,
      "step": 37410
    },
    {
      "epoch": 1.0691428571428572,
      "grad_norm": 0.0,
      "learning_rate": 2.327142857142857e-05,
      "loss": 0.0024,
      "step": 37420
    },
    {
      "epoch": 1.0694285714285714,
      "grad_norm": 0.09339962899684906,
      "learning_rate": 2.3264285714285716e-05,
      "loss": 0.0026,
      "step": 37430
    },
    {
      "epoch": 1.0697142857142856,
      "grad_norm": 0.1016436368227005,
      "learning_rate": 2.3257142857142858e-05,
      "loss": 0.0008,
      "step": 37440
    },
    {
      "epoch": 1.07,
      "grad_norm": 0.047839850187301636,
      "learning_rate": 2.3250000000000003e-05,
      "loss": 0.0008,
      "step": 37450
    },
    {
      "epoch": 1.0702857142857143,
      "grad_norm": 0.04539091885089874,
      "learning_rate": 2.3242857142857144e-05,
      "loss": 0.001,
      "step": 37460
    },
    {
      "epoch": 1.0705714285714285,
      "grad_norm": 0.0589129813015461,
      "learning_rate": 2.3235714285714286e-05,
      "loss": 0.0025,
      "step": 37470
    },
    {
      "epoch": 1.070857142857143,
      "grad_norm": 0.18358172476291656,
      "learning_rate": 2.322857142857143e-05,
      "loss": 0.0013,
      "step": 37480
    },
    {
      "epoch": 1.0711428571428572,
      "grad_norm": 0.07903070747852325,
      "learning_rate": 2.3221428571428573e-05,
      "loss": 0.0009,
      "step": 37490
    },
    {
      "epoch": 1.0714285714285714,
      "grad_norm": 0.19039466977119446,
      "learning_rate": 2.3214285714285715e-05,
      "loss": 0.0018,
      "step": 37500
    },
    {
      "epoch": 1.0717142857142856,
      "grad_norm": 0.05161311849951744,
      "learning_rate": 2.3207142857142856e-05,
      "loss": 0.002,
      "step": 37510
    },
    {
      "epoch": 1.072,
      "grad_norm": 0.0,
      "learning_rate": 2.32e-05,
      "loss": 0.0012,
      "step": 37520
    },
    {
      "epoch": 1.0722857142857143,
      "grad_norm": 0.05120021477341652,
      "learning_rate": 2.3192857142857143e-05,
      "loss": 0.0008,
      "step": 37530
    },
    {
      "epoch": 1.0725714285714285,
      "grad_norm": 0.0,
      "learning_rate": 2.3185714285714285e-05,
      "loss": 0.001,
      "step": 37540
    },
    {
      "epoch": 1.072857142857143,
      "grad_norm": 0.0,
      "learning_rate": 2.317857142857143e-05,
      "loss": 0.0013,
      "step": 37550
    },
    {
      "epoch": 1.0731428571428572,
      "grad_norm": 0.05533319711685181,
      "learning_rate": 2.3171428571428572e-05,
      "loss": 0.0008,
      "step": 37560
    },
    {
      "epoch": 1.0734285714285714,
      "grad_norm": 0.13539528846740723,
      "learning_rate": 2.3164285714285717e-05,
      "loss": 0.0023,
      "step": 37570
    },
    {
      "epoch": 1.0737142857142856,
      "grad_norm": 0.0,
      "learning_rate": 2.315714285714286e-05,
      "loss": 0.0009,
      "step": 37580
    },
    {
      "epoch": 1.074,
      "grad_norm": 0.08697587251663208,
      "learning_rate": 2.3150000000000004e-05,
      "loss": 0.0012,
      "step": 37590
    },
    {
      "epoch": 1.0742857142857143,
      "grad_norm": 0.23427215218544006,
      "learning_rate": 2.3142857142857145e-05,
      "loss": 0.0009,
      "step": 37600
    },
    {
      "epoch": 1.0745714285714285,
      "grad_norm": 0.08806546777486801,
      "learning_rate": 2.3135714285714287e-05,
      "loss": 0.0012,
      "step": 37610
    },
    {
      "epoch": 1.074857142857143,
      "grad_norm": 0.0,
      "learning_rate": 2.312857142857143e-05,
      "loss": 0.0008,
      "step": 37620
    },
    {
      "epoch": 1.0751428571428572,
      "grad_norm": 0.08850826323032379,
      "learning_rate": 2.312142857142857e-05,
      "loss": 0.0015,
      "step": 37630
    },
    {
      "epoch": 1.0754285714285714,
      "grad_norm": 0.0,
      "learning_rate": 2.3114285714285716e-05,
      "loss": 0.0009,
      "step": 37640
    },
    {
      "epoch": 1.0757142857142856,
      "grad_norm": 0.1306830197572708,
      "learning_rate": 2.3107142857142857e-05,
      "loss": 0.0006,
      "step": 37650
    },
    {
      "epoch": 1.076,
      "grad_norm": 0.11503861844539642,
      "learning_rate": 2.3100000000000002e-05,
      "loss": 0.0012,
      "step": 37660
    },
    {
      "epoch": 1.0762857142857143,
      "grad_norm": 0.04362921044230461,
      "learning_rate": 2.3092857142857144e-05,
      "loss": 0.0017,
      "step": 37670
    },
    {
      "epoch": 1.0765714285714285,
      "grad_norm": 0.044999655336141586,
      "learning_rate": 2.3085714285714286e-05,
      "loss": 0.0018,
      "step": 37680
    },
    {
      "epoch": 1.076857142857143,
      "grad_norm": 0.20079176127910614,
      "learning_rate": 2.307857142857143e-05,
      "loss": 0.0013,
      "step": 37690
    },
    {
      "epoch": 1.0771428571428572,
      "grad_norm": 0.04118168354034424,
      "learning_rate": 2.3071428571428573e-05,
      "loss": 0.0006,
      "step": 37700
    },
    {
      "epoch": 1.0774285714285714,
      "grad_norm": 0.20274080336093903,
      "learning_rate": 2.3064285714285714e-05,
      "loss": 0.001,
      "step": 37710
    },
    {
      "epoch": 1.0777142857142856,
      "grad_norm": 0.0,
      "learning_rate": 2.3057142857142856e-05,
      "loss": 0.0008,
      "step": 37720
    },
    {
      "epoch": 1.078,
      "grad_norm": 0.042265333235263824,
      "learning_rate": 2.305e-05,
      "loss": 0.0018,
      "step": 37730
    },
    {
      "epoch": 1.0782857142857143,
      "grad_norm": 0.040083467960357666,
      "learning_rate": 2.3042857142857143e-05,
      "loss": 0.0014,
      "step": 37740
    },
    {
      "epoch": 1.0785714285714285,
      "grad_norm": 0.1973150074481964,
      "learning_rate": 2.3035714285714285e-05,
      "loss": 0.0014,
      "step": 37750
    },
    {
      "epoch": 1.078857142857143,
      "grad_norm": 0.2033805400133133,
      "learning_rate": 2.302857142857143e-05,
      "loss": 0.001,
      "step": 37760
    },
    {
      "epoch": 1.0791428571428572,
      "grad_norm": 0.05602161958813667,
      "learning_rate": 2.302142857142857e-05,
      "loss": 0.0005,
      "step": 37770
    },
    {
      "epoch": 1.0794285714285714,
      "grad_norm": 0.2878071367740631,
      "learning_rate": 2.3014285714285717e-05,
      "loss": 0.0004,
      "step": 37780
    },
    {
      "epoch": 1.0797142857142856,
      "grad_norm": 0.23665057122707367,
      "learning_rate": 2.3007142857142858e-05,
      "loss": 0.0022,
      "step": 37790
    },
    {
      "epoch": 1.08,
      "grad_norm": 0.11660941690206528,
      "learning_rate": 2.3000000000000003e-05,
      "loss": 0.0021,
      "step": 37800
    },
    {
      "epoch": 1.0802857142857143,
      "grad_norm": 0.08617692440748215,
      "learning_rate": 2.2992857142857145e-05,
      "loss": 0.0014,
      "step": 37810
    },
    {
      "epoch": 1.0805714285714285,
      "grad_norm": 0.02782134898006916,
      "learning_rate": 2.2985714285714287e-05,
      "loss": 0.0015,
      "step": 37820
    },
    {
      "epoch": 1.080857142857143,
      "grad_norm": 0.048346955329179764,
      "learning_rate": 2.297857142857143e-05,
      "loss": 0.0017,
      "step": 37830
    },
    {
      "epoch": 1.0811428571428572,
      "grad_norm": 0.0,
      "learning_rate": 2.297142857142857e-05,
      "loss": 0.0011,
      "step": 37840
    },
    {
      "epoch": 1.0814285714285714,
      "grad_norm": 0.0,
      "learning_rate": 2.2964285714285715e-05,
      "loss": 0.0011,
      "step": 37850
    },
    {
      "epoch": 1.0817142857142856,
      "grad_norm": 0.04187649115920067,
      "learning_rate": 2.2957142857142857e-05,
      "loss": 0.0022,
      "step": 37860
    },
    {
      "epoch": 1.082,
      "grad_norm": 0.2257646769285202,
      "learning_rate": 2.2950000000000002e-05,
      "loss": 0.0002,
      "step": 37870
    },
    {
      "epoch": 1.0822857142857143,
      "grad_norm": 0.18406644463539124,
      "learning_rate": 2.2942857142857144e-05,
      "loss": 0.0014,
      "step": 37880
    },
    {
      "epoch": 1.0825714285714285,
      "grad_norm": 0.04383100941777229,
      "learning_rate": 2.293571428571429e-05,
      "loss": 0.0014,
      "step": 37890
    },
    {
      "epoch": 1.0828571428571427,
      "grad_norm": 0.0,
      "learning_rate": 2.292857142857143e-05,
      "loss": 0.0012,
      "step": 37900
    },
    {
      "epoch": 1.0831428571428572,
      "grad_norm": 0.0899934321641922,
      "learning_rate": 2.2921428571428572e-05,
      "loss": 0.0022,
      "step": 37910
    },
    {
      "epoch": 1.0834285714285714,
      "grad_norm": 0.15721867978572845,
      "learning_rate": 2.2914285714285718e-05,
      "loss": 0.0014,
      "step": 37920
    },
    {
      "epoch": 1.0837142857142856,
      "grad_norm": 0.06661511212587357,
      "learning_rate": 2.290714285714286e-05,
      "loss": 0.0021,
      "step": 37930
    },
    {
      "epoch": 1.084,
      "grad_norm": 0.046632859855890274,
      "learning_rate": 2.29e-05,
      "loss": 0.0015,
      "step": 37940
    },
    {
      "epoch": 1.0842857142857143,
      "grad_norm": 0.11009043455123901,
      "learning_rate": 2.2892857142857143e-05,
      "loss": 0.0014,
      "step": 37950
    },
    {
      "epoch": 1.0845714285714285,
      "grad_norm": 0.0,
      "learning_rate": 2.2885714285714288e-05,
      "loss": 0.001,
      "step": 37960
    },
    {
      "epoch": 1.084857142857143,
      "grad_norm": 0.0,
      "learning_rate": 2.287857142857143e-05,
      "loss": 0.0005,
      "step": 37970
    },
    {
      "epoch": 1.0851428571428572,
      "grad_norm": 0.24339479207992554,
      "learning_rate": 2.287142857142857e-05,
      "loss": 0.001,
      "step": 37980
    },
    {
      "epoch": 1.0854285714285714,
      "grad_norm": 0.13972368836402893,
      "learning_rate": 2.2864285714285716e-05,
      "loss": 0.0019,
      "step": 37990
    },
    {
      "epoch": 1.0857142857142856,
      "grad_norm": 0.07233802229166031,
      "learning_rate": 2.2857142857142858e-05,
      "loss": 0.002,
      "step": 38000
    },
    {
      "epoch": 1.086,
      "grad_norm": 0.040527429431676865,
      "learning_rate": 2.2850000000000003e-05,
      "loss": 0.0018,
      "step": 38010
    },
    {
      "epoch": 1.0862857142857143,
      "grad_norm": 0.0,
      "learning_rate": 2.2842857142857145e-05,
      "loss": 0.0006,
      "step": 38020
    },
    {
      "epoch": 1.0865714285714285,
      "grad_norm": 0.0,
      "learning_rate": 2.2835714285714287e-05,
      "loss": 0.0008,
      "step": 38030
    },
    {
      "epoch": 1.0868571428571427,
      "grad_norm": 0.24620847404003143,
      "learning_rate": 2.2828571428571428e-05,
      "loss": 0.0014,
      "step": 38040
    },
    {
      "epoch": 1.0871428571428572,
      "grad_norm": 0.13718274235725403,
      "learning_rate": 2.282142857142857e-05,
      "loss": 0.0016,
      "step": 38050
    },
    {
      "epoch": 1.0874285714285714,
      "grad_norm": 0.04610324651002884,
      "learning_rate": 2.2814285714285715e-05,
      "loss": 0.0012,
      "step": 38060
    },
    {
      "epoch": 1.0877142857142856,
      "grad_norm": 0.15523098409175873,
      "learning_rate": 2.2807142857142857e-05,
      "loss": 0.0011,
      "step": 38070
    },
    {
      "epoch": 1.088,
      "grad_norm": 0.11707888543605804,
      "learning_rate": 2.2800000000000002e-05,
      "loss": 0.0015,
      "step": 38080
    },
    {
      "epoch": 1.0882857142857143,
      "grad_norm": 0.0,
      "learning_rate": 2.2792857142857144e-05,
      "loss": 0.0004,
      "step": 38090
    },
    {
      "epoch": 1.0885714285714285,
      "grad_norm": 0.16239234805107117,
      "learning_rate": 2.278571428571429e-05,
      "loss": 0.002,
      "step": 38100
    },
    {
      "epoch": 1.088857142857143,
      "grad_norm": 0.366949200630188,
      "learning_rate": 2.277857142857143e-05,
      "loss": 0.0014,
      "step": 38110
    },
    {
      "epoch": 1.0891428571428572,
      "grad_norm": 0.24206854403018951,
      "learning_rate": 2.2771428571428572e-05,
      "loss": 0.0024,
      "step": 38120
    },
    {
      "epoch": 1.0894285714285714,
      "grad_norm": 0.065435990691185,
      "learning_rate": 2.2764285714285717e-05,
      "loss": 0.001,
      "step": 38130
    },
    {
      "epoch": 1.0897142857142856,
      "grad_norm": 0.13394635915756226,
      "learning_rate": 2.275714285714286e-05,
      "loss": 0.002,
      "step": 38140
    },
    {
      "epoch": 1.09,
      "grad_norm": 0.03635348752140999,
      "learning_rate": 2.275e-05,
      "loss": 0.0017,
      "step": 38150
    },
    {
      "epoch": 1.0902857142857143,
      "grad_norm": 0.1537279486656189,
      "learning_rate": 2.2742857142857142e-05,
      "loss": 0.0013,
      "step": 38160
    },
    {
      "epoch": 1.0905714285714285,
      "grad_norm": 0.15299995243549347,
      "learning_rate": 2.2735714285714288e-05,
      "loss": 0.0013,
      "step": 38170
    },
    {
      "epoch": 1.0908571428571427,
      "grad_norm": 0.09848038852214813,
      "learning_rate": 2.272857142857143e-05,
      "loss": 0.0017,
      "step": 38180
    },
    {
      "epoch": 1.0911428571428572,
      "grad_norm": 0.09391182661056519,
      "learning_rate": 2.272142857142857e-05,
      "loss": 0.0012,
      "step": 38190
    },
    {
      "epoch": 1.0914285714285714,
      "grad_norm": 0.032555848360061646,
      "learning_rate": 2.2714285714285716e-05,
      "loss": 0.0011,
      "step": 38200
    },
    {
      "epoch": 1.0917142857142856,
      "grad_norm": 0.07513856887817383,
      "learning_rate": 2.2707142857142858e-05,
      "loss": 0.0018,
      "step": 38210
    },
    {
      "epoch": 1.092,
      "grad_norm": 0.0,
      "learning_rate": 2.2700000000000003e-05,
      "loss": 0.0011,
      "step": 38220
    },
    {
      "epoch": 1.0922857142857143,
      "grad_norm": 0.0,
      "learning_rate": 2.2692857142857145e-05,
      "loss": 0.0018,
      "step": 38230
    },
    {
      "epoch": 1.0925714285714285,
      "grad_norm": 0.35181427001953125,
      "learning_rate": 2.2685714285714286e-05,
      "loss": 0.0008,
      "step": 38240
    },
    {
      "epoch": 1.092857142857143,
      "grad_norm": 0.3023087680339813,
      "learning_rate": 2.2678571428571428e-05,
      "loss": 0.0004,
      "step": 38250
    },
    {
      "epoch": 1.0931428571428572,
      "grad_norm": 0.257631778717041,
      "learning_rate": 2.267142857142857e-05,
      "loss": 0.0031,
      "step": 38260
    },
    {
      "epoch": 1.0934285714285714,
      "grad_norm": 0.08137800544500351,
      "learning_rate": 2.2664285714285715e-05,
      "loss": 0.0008,
      "step": 38270
    },
    {
      "epoch": 1.0937142857142856,
      "grad_norm": 0.1430504471063614,
      "learning_rate": 2.2657142857142857e-05,
      "loss": 0.0013,
      "step": 38280
    },
    {
      "epoch": 1.094,
      "grad_norm": 0.23671451210975647,
      "learning_rate": 2.265e-05,
      "loss": 0.0007,
      "step": 38290
    },
    {
      "epoch": 1.0942857142857143,
      "grad_norm": 0.04272288456559181,
      "learning_rate": 2.2642857142857143e-05,
      "loss": 0.0016,
      "step": 38300
    },
    {
      "epoch": 1.0945714285714285,
      "grad_norm": 0.04273192211985588,
      "learning_rate": 2.263571428571429e-05,
      "loss": 0.0015,
      "step": 38310
    },
    {
      "epoch": 1.0948571428571428,
      "grad_norm": 0.09097395837306976,
      "learning_rate": 2.262857142857143e-05,
      "loss": 0.0004,
      "step": 38320
    },
    {
      "epoch": 1.0951428571428572,
      "grad_norm": 0.044891729950904846,
      "learning_rate": 2.2621428571428572e-05,
      "loss": 0.0007,
      "step": 38330
    },
    {
      "epoch": 1.0954285714285714,
      "grad_norm": 0.2279103398323059,
      "learning_rate": 2.2614285714285717e-05,
      "loss": 0.0027,
      "step": 38340
    },
    {
      "epoch": 1.0957142857142856,
      "grad_norm": 0.3353097438812256,
      "learning_rate": 2.260714285714286e-05,
      "loss": 0.0013,
      "step": 38350
    },
    {
      "epoch": 1.096,
      "grad_norm": 0.3242398202419281,
      "learning_rate": 2.26e-05,
      "loss": 0.0012,
      "step": 38360
    },
    {
      "epoch": 1.0962857142857143,
      "grad_norm": 0.05014685168862343,
      "learning_rate": 2.2592857142857142e-05,
      "loss": 0.0016,
      "step": 38370
    },
    {
      "epoch": 1.0965714285714285,
      "grad_norm": 0.04081929102540016,
      "learning_rate": 2.2585714285714287e-05,
      "loss": 0.0007,
      "step": 38380
    },
    {
      "epoch": 1.096857142857143,
      "grad_norm": 0.0,
      "learning_rate": 2.257857142857143e-05,
      "loss": 0.0007,
      "step": 38390
    },
    {
      "epoch": 1.0971428571428572,
      "grad_norm": 0.332474023103714,
      "learning_rate": 2.257142857142857e-05,
      "loss": 0.0021,
      "step": 38400
    },
    {
      "epoch": 1.0974285714285714,
      "grad_norm": 0.0,
      "learning_rate": 2.2564285714285716e-05,
      "loss": 0.0005,
      "step": 38410
    },
    {
      "epoch": 1.0977142857142856,
      "grad_norm": 0.0,
      "learning_rate": 2.2557142857142858e-05,
      "loss": 0.0007,
      "step": 38420
    },
    {
      "epoch": 1.098,
      "grad_norm": 0.3122289478778839,
      "learning_rate": 2.2550000000000003e-05,
      "loss": 0.001,
      "step": 38430
    },
    {
      "epoch": 1.0982857142857143,
      "grad_norm": 0.0,
      "learning_rate": 2.2542857142857144e-05,
      "loss": 0.0006,
      "step": 38440
    },
    {
      "epoch": 1.0985714285714285,
      "grad_norm": 0.19601303339004517,
      "learning_rate": 2.253571428571429e-05,
      "loss": 0.0004,
      "step": 38450
    },
    {
      "epoch": 1.0988571428571428,
      "grad_norm": 0.14030632376670837,
      "learning_rate": 2.2528571428571428e-05,
      "loss": 0.0019,
      "step": 38460
    },
    {
      "epoch": 1.0991428571428572,
      "grad_norm": 0.0,
      "learning_rate": 2.2521428571428573e-05,
      "loss": 0.0017,
      "step": 38470
    },
    {
      "epoch": 1.0994285714285714,
      "grad_norm": 0.08250053226947784,
      "learning_rate": 2.2514285714285715e-05,
      "loss": 0.0025,
      "step": 38480
    },
    {
      "epoch": 1.0997142857142856,
      "grad_norm": 0.04011227563023567,
      "learning_rate": 2.2507142857142856e-05,
      "loss": 0.0012,
      "step": 38490
    },
    {
      "epoch": 1.1,
      "grad_norm": 0.2254970818758011,
      "learning_rate": 2.25e-05,
      "loss": 0.0024,
      "step": 38500
    },
    {
      "epoch": 1.1002857142857143,
      "grad_norm": 0.3699411153793335,
      "learning_rate": 2.2492857142857143e-05,
      "loss": 0.0021,
      "step": 38510
    },
    {
      "epoch": 1.1005714285714285,
      "grad_norm": 0.22843490540981293,
      "learning_rate": 2.2485714285714288e-05,
      "loss": 0.0018,
      "step": 38520
    },
    {
      "epoch": 1.1008571428571428,
      "grad_norm": 0.12447496503591537,
      "learning_rate": 2.247857142857143e-05,
      "loss": 0.0018,
      "step": 38530
    },
    {
      "epoch": 1.1011428571428572,
      "grad_norm": 0.08242959529161453,
      "learning_rate": 2.2471428571428575e-05,
      "loss": 0.0025,
      "step": 38540
    },
    {
      "epoch": 1.1014285714285714,
      "grad_norm": 0.04810596629977226,
      "learning_rate": 2.2464285714285717e-05,
      "loss": 0.0007,
      "step": 38550
    },
    {
      "epoch": 1.1017142857142856,
      "grad_norm": 0.24197249114513397,
      "learning_rate": 2.245714285714286e-05,
      "loss": 0.0022,
      "step": 38560
    },
    {
      "epoch": 1.102,
      "grad_norm": 0.08033820986747742,
      "learning_rate": 2.245e-05,
      "loss": 0.0008,
      "step": 38570
    },
    {
      "epoch": 1.1022857142857143,
      "grad_norm": 0.096783347427845,
      "learning_rate": 2.2442857142857142e-05,
      "loss": 0.0021,
      "step": 38580
    },
    {
      "epoch": 1.1025714285714285,
      "grad_norm": 0.08819270879030228,
      "learning_rate": 2.2435714285714287e-05,
      "loss": 0.0014,
      "step": 38590
    },
    {
      "epoch": 1.1028571428571428,
      "grad_norm": 0.3201049864292145,
      "learning_rate": 2.242857142857143e-05,
      "loss": 0.0013,
      "step": 38600
    },
    {
      "epoch": 1.1031428571428572,
      "grad_norm": 0.052587829530239105,
      "learning_rate": 2.2421428571428574e-05,
      "loss": 0.0011,
      "step": 38610
    },
    {
      "epoch": 1.1034285714285714,
      "grad_norm": 0.06323808431625366,
      "learning_rate": 2.2414285714285716e-05,
      "loss": 0.0014,
      "step": 38620
    },
    {
      "epoch": 1.1037142857142856,
      "grad_norm": 0.04897022247314453,
      "learning_rate": 2.2407142857142857e-05,
      "loss": 0.001,
      "step": 38630
    },
    {
      "epoch": 1.104,
      "grad_norm": 0.17805115878582,
      "learning_rate": 2.2400000000000002e-05,
      "loss": 0.0021,
      "step": 38640
    },
    {
      "epoch": 1.1042857142857143,
      "grad_norm": 0.10870551317930222,
      "learning_rate": 2.2392857142857144e-05,
      "loss": 0.0014,
      "step": 38650
    },
    {
      "epoch": 1.1045714285714285,
      "grad_norm": 0.049137722700834274,
      "learning_rate": 2.238571428571429e-05,
      "loss": 0.0013,
      "step": 38660
    },
    {
      "epoch": 1.1048571428571428,
      "grad_norm": 0.04183513671159744,
      "learning_rate": 2.237857142857143e-05,
      "loss": 0.0008,
      "step": 38670
    },
    {
      "epoch": 1.1051428571428572,
      "grad_norm": 0.04265034943819046,
      "learning_rate": 2.2371428571428573e-05,
      "loss": 0.0013,
      "step": 38680
    },
    {
      "epoch": 1.1054285714285714,
      "grad_norm": 0.20577509701251984,
      "learning_rate": 2.2364285714285714e-05,
      "loss": 0.0011,
      "step": 38690
    },
    {
      "epoch": 1.1057142857142856,
      "grad_norm": 0.05526493489742279,
      "learning_rate": 2.2357142857142856e-05,
      "loss": 0.0018,
      "step": 38700
    },
    {
      "epoch": 1.106,
      "grad_norm": 0.04294487088918686,
      "learning_rate": 2.235e-05,
      "loss": 0.0011,
      "step": 38710
    },
    {
      "epoch": 1.1062857142857143,
      "grad_norm": 0.1475761979818344,
      "learning_rate": 2.2342857142857143e-05,
      "loss": 0.001,
      "step": 38720
    },
    {
      "epoch": 1.1065714285714285,
      "grad_norm": 0.04205336794257164,
      "learning_rate": 2.2335714285714288e-05,
      "loss": 0.0024,
      "step": 38730
    },
    {
      "epoch": 1.1068571428571428,
      "grad_norm": 0.045481327921152115,
      "learning_rate": 2.232857142857143e-05,
      "loss": 0.001,
      "step": 38740
    },
    {
      "epoch": 1.1071428571428572,
      "grad_norm": 0.0,
      "learning_rate": 2.2321428571428575e-05,
      "loss": 0.0016,
      "step": 38750
    },
    {
      "epoch": 1.1074285714285714,
      "grad_norm": 0.0,
      "learning_rate": 2.2314285714285717e-05,
      "loss": 0.0011,
      "step": 38760
    },
    {
      "epoch": 1.1077142857142857,
      "grad_norm": 0.05335240438580513,
      "learning_rate": 2.2307142857142858e-05,
      "loss": 0.0019,
      "step": 38770
    },
    {
      "epoch": 1.108,
      "grad_norm": 0.045244935899972916,
      "learning_rate": 2.23e-05,
      "loss": 0.0018,
      "step": 38780
    },
    {
      "epoch": 1.1082857142857143,
      "grad_norm": 0.04370938241481781,
      "learning_rate": 2.229285714285714e-05,
      "loss": 0.0012,
      "step": 38790
    },
    {
      "epoch": 1.1085714285714285,
      "grad_norm": 0.04724877327680588,
      "learning_rate": 2.2285714285714287e-05,
      "loss": 0.0013,
      "step": 38800
    },
    {
      "epoch": 1.1088571428571428,
      "grad_norm": 0.08419618755578995,
      "learning_rate": 2.227857142857143e-05,
      "loss": 0.0013,
      "step": 38810
    },
    {
      "epoch": 1.1091428571428572,
      "grad_norm": 0.04294434189796448,
      "learning_rate": 2.2271428571428574e-05,
      "loss": 0.0003,
      "step": 38820
    },
    {
      "epoch": 1.1094285714285714,
      "grad_norm": 0.058198653161525726,
      "learning_rate": 2.2264285714285715e-05,
      "loss": 0.0021,
      "step": 38830
    },
    {
      "epoch": 1.1097142857142857,
      "grad_norm": 0.5183829069137573,
      "learning_rate": 2.2257142857142857e-05,
      "loss": 0.0029,
      "step": 38840
    },
    {
      "epoch": 1.11,
      "grad_norm": 0.02701624669134617,
      "learning_rate": 2.2250000000000002e-05,
      "loss": 0.0019,
      "step": 38850
    },
    {
      "epoch": 1.1102857142857143,
      "grad_norm": 0.23045602440834045,
      "learning_rate": 2.2242857142857144e-05,
      "loss": 0.0017,
      "step": 38860
    },
    {
      "epoch": 1.1105714285714285,
      "grad_norm": 0.07152746617794037,
      "learning_rate": 2.223571428571429e-05,
      "loss": 0.0011,
      "step": 38870
    },
    {
      "epoch": 1.1108571428571428,
      "grad_norm": 0.047049276530742645,
      "learning_rate": 2.222857142857143e-05,
      "loss": 0.0014,
      "step": 38880
    },
    {
      "epoch": 1.1111428571428572,
      "grad_norm": 0.08381807804107666,
      "learning_rate": 2.2221428571428572e-05,
      "loss": 0.001,
      "step": 38890
    },
    {
      "epoch": 1.1114285714285714,
      "grad_norm": 0.1203499585390091,
      "learning_rate": 2.2214285714285714e-05,
      "loss": 0.0006,
      "step": 38900
    },
    {
      "epoch": 1.1117142857142857,
      "grad_norm": 0.06498415768146515,
      "learning_rate": 2.2207142857142856e-05,
      "loss": 0.0018,
      "step": 38910
    },
    {
      "epoch": 1.112,
      "grad_norm": 0.18987403810024261,
      "learning_rate": 2.22e-05,
      "loss": 0.0009,
      "step": 38920
    },
    {
      "epoch": 1.1122857142857143,
      "grad_norm": 0.0,
      "learning_rate": 2.2192857142857143e-05,
      "loss": 0.0006,
      "step": 38930
    },
    {
      "epoch": 1.1125714285714285,
      "grad_norm": 0.04031962901353836,
      "learning_rate": 2.2185714285714288e-05,
      "loss": 0.001,
      "step": 38940
    },
    {
      "epoch": 1.1128571428571428,
      "grad_norm": 0.04039105027914047,
      "learning_rate": 2.217857142857143e-05,
      "loss": 0.0011,
      "step": 38950
    },
    {
      "epoch": 1.1131428571428572,
      "grad_norm": 0.0,
      "learning_rate": 2.2171428571428575e-05,
      "loss": 0.0012,
      "step": 38960
    },
    {
      "epoch": 1.1134285714285714,
      "grad_norm": 0.22628188133239746,
      "learning_rate": 2.2164285714285716e-05,
      "loss": 0.0009,
      "step": 38970
    },
    {
      "epoch": 1.1137142857142857,
      "grad_norm": 0.05869068205356598,
      "learning_rate": 2.2157142857142858e-05,
      "loss": 0.0013,
      "step": 38980
    },
    {
      "epoch": 1.114,
      "grad_norm": 0.04126446321606636,
      "learning_rate": 2.215e-05,
      "loss": 0.0011,
      "step": 38990
    },
    {
      "epoch": 1.1142857142857143,
      "grad_norm": 0.0,
      "learning_rate": 2.214285714285714e-05,
      "loss": 0.0011,
      "step": 39000
    },
    {
      "epoch": 1.1145714285714285,
      "grad_norm": 0.20599918067455292,
      "learning_rate": 2.2135714285714287e-05,
      "loss": 0.0013,
      "step": 39010
    },
    {
      "epoch": 1.1148571428571428,
      "grad_norm": 0.0411565825343132,
      "learning_rate": 2.2128571428571428e-05,
      "loss": 0.0008,
      "step": 39020
    },
    {
      "epoch": 1.1151428571428572,
      "grad_norm": 0.0,
      "learning_rate": 2.2121428571428573e-05,
      "loss": 0.001,
      "step": 39030
    },
    {
      "epoch": 1.1154285714285714,
      "grad_norm": 0.0,
      "learning_rate": 2.2114285714285715e-05,
      "loss": 0.0011,
      "step": 39040
    },
    {
      "epoch": 1.1157142857142857,
      "grad_norm": 0.10119006782770157,
      "learning_rate": 2.2107142857142857e-05,
      "loss": 0.0007,
      "step": 39050
    },
    {
      "epoch": 1.116,
      "grad_norm": 0.039417486637830734,
      "learning_rate": 2.2100000000000002e-05,
      "loss": 0.001,
      "step": 39060
    },
    {
      "epoch": 1.1162857142857143,
      "grad_norm": 0.0,
      "learning_rate": 2.2092857142857144e-05,
      "loss": 0.0012,
      "step": 39070
    },
    {
      "epoch": 1.1165714285714285,
      "grad_norm": 0.04251914098858833,
      "learning_rate": 2.208571428571429e-05,
      "loss": 0.0015,
      "step": 39080
    },
    {
      "epoch": 1.1168571428571428,
      "grad_norm": 0.0,
      "learning_rate": 2.207857142857143e-05,
      "loss": 0.0004,
      "step": 39090
    },
    {
      "epoch": 1.1171428571428572,
      "grad_norm": 0.050548702478408813,
      "learning_rate": 2.2071428571428572e-05,
      "loss": 0.0013,
      "step": 39100
    },
    {
      "epoch": 1.1174285714285714,
      "grad_norm": 0.2660726308822632,
      "learning_rate": 2.2064285714285714e-05,
      "loss": 0.0025,
      "step": 39110
    },
    {
      "epoch": 1.1177142857142857,
      "grad_norm": 0.11943241208791733,
      "learning_rate": 2.205714285714286e-05,
      "loss": 0.0009,
      "step": 39120
    },
    {
      "epoch": 1.1179999999999999,
      "grad_norm": 0.0,
      "learning_rate": 2.205e-05,
      "loss": 0.001,
      "step": 39130
    },
    {
      "epoch": 1.1182857142857143,
      "grad_norm": 0.08229323476552963,
      "learning_rate": 2.2042857142857142e-05,
      "loss": 0.0013,
      "step": 39140
    },
    {
      "epoch": 1.1185714285714285,
      "grad_norm": 0.09296272695064545,
      "learning_rate": 2.2035714285714287e-05,
      "loss": 0.0015,
      "step": 39150
    },
    {
      "epoch": 1.1188571428571428,
      "grad_norm": 0.09889518469572067,
      "learning_rate": 2.202857142857143e-05,
      "loss": 0.0019,
      "step": 39160
    },
    {
      "epoch": 1.1191428571428572,
      "grad_norm": 0.039201006293296814,
      "learning_rate": 2.2021428571428574e-05,
      "loss": 0.0012,
      "step": 39170
    },
    {
      "epoch": 1.1194285714285714,
      "grad_norm": 0.0,
      "learning_rate": 2.2014285714285716e-05,
      "loss": 0.001,
      "step": 39180
    },
    {
      "epoch": 1.1197142857142857,
      "grad_norm": 0.2398894727230072,
      "learning_rate": 2.200714285714286e-05,
      "loss": 0.0025,
      "step": 39190
    },
    {
      "epoch": 1.12,
      "grad_norm": 0.05151248723268509,
      "learning_rate": 2.2000000000000003e-05,
      "loss": 0.0006,
      "step": 39200
    },
    {
      "epoch": 1.1202857142857143,
      "grad_norm": 0.03352732211351395,
      "learning_rate": 2.199285714285714e-05,
      "loss": 0.0008,
      "step": 39210
    },
    {
      "epoch": 1.1205714285714286,
      "grad_norm": 0.054001614451408386,
      "learning_rate": 2.1985714285714286e-05,
      "loss": 0.0019,
      "step": 39220
    },
    {
      "epoch": 1.1208571428571428,
      "grad_norm": 0.04127955064177513,
      "learning_rate": 2.1978571428571428e-05,
      "loss": 0.001,
      "step": 39230
    },
    {
      "epoch": 1.1211428571428572,
      "grad_norm": 0.0,
      "learning_rate": 2.1971428571428573e-05,
      "loss": 0.0007,
      "step": 39240
    },
    {
      "epoch": 1.1214285714285714,
      "grad_norm": 0.0,
      "learning_rate": 2.1964285714285715e-05,
      "loss": 0.0014,
      "step": 39250
    },
    {
      "epoch": 1.1217142857142857,
      "grad_norm": 0.2513420581817627,
      "learning_rate": 2.195714285714286e-05,
      "loss": 0.0018,
      "step": 39260
    },
    {
      "epoch": 1.1219999999999999,
      "grad_norm": 0.06000461429357529,
      "learning_rate": 2.195e-05,
      "loss": 0.0008,
      "step": 39270
    },
    {
      "epoch": 1.1222857142857143,
      "grad_norm": 0.19170689582824707,
      "learning_rate": 2.1942857142857143e-05,
      "loss": 0.0008,
      "step": 39280
    },
    {
      "epoch": 1.1225714285714286,
      "grad_norm": 0.15037524700164795,
      "learning_rate": 2.193571428571429e-05,
      "loss": 0.0007,
      "step": 39290
    },
    {
      "epoch": 1.1228571428571428,
      "grad_norm": 0.07213467359542847,
      "learning_rate": 2.192857142857143e-05,
      "loss": 0.001,
      "step": 39300
    },
    {
      "epoch": 1.1231428571428572,
      "grad_norm": 0.0,
      "learning_rate": 2.1921428571428572e-05,
      "loss": 0.0012,
      "step": 39310
    },
    {
      "epoch": 1.1234285714285714,
      "grad_norm": 0.05190860480070114,
      "learning_rate": 2.1914285714285714e-05,
      "loss": 0.0017,
      "step": 39320
    },
    {
      "epoch": 1.1237142857142857,
      "grad_norm": 0.07744349539279938,
      "learning_rate": 2.190714285714286e-05,
      "loss": 0.0034,
      "step": 39330
    },
    {
      "epoch": 1.124,
      "grad_norm": 0.05767473950982094,
      "learning_rate": 2.19e-05,
      "loss": 0.0004,
      "step": 39340
    },
    {
      "epoch": 1.1242857142857143,
      "grad_norm": 0.08292686194181442,
      "learning_rate": 2.1892857142857142e-05,
      "loss": 0.0013,
      "step": 39350
    },
    {
      "epoch": 1.1245714285714286,
      "grad_norm": 0.09054659307003021,
      "learning_rate": 2.1885714285714287e-05,
      "loss": 0.0012,
      "step": 39360
    },
    {
      "epoch": 1.1248571428571428,
      "grad_norm": 0.09028889983892441,
      "learning_rate": 2.187857142857143e-05,
      "loss": 0.0013,
      "step": 39370
    },
    {
      "epoch": 1.1251428571428572,
      "grad_norm": 0.04379568621516228,
      "learning_rate": 2.1871428571428574e-05,
      "loss": 0.0008,
      "step": 39380
    },
    {
      "epoch": 1.1254285714285714,
      "grad_norm": 0.041083212941884995,
      "learning_rate": 2.1864285714285716e-05,
      "loss": 0.0007,
      "step": 39390
    },
    {
      "epoch": 1.1257142857142857,
      "grad_norm": 0.2822949290275574,
      "learning_rate": 2.185714285714286e-05,
      "loss": 0.0019,
      "step": 39400
    },
    {
      "epoch": 1.126,
      "grad_norm": 0.2450394332408905,
      "learning_rate": 2.1850000000000003e-05,
      "loss": 0.0013,
      "step": 39410
    },
    {
      "epoch": 1.1262857142857143,
      "grad_norm": 0.1697426438331604,
      "learning_rate": 2.1842857142857144e-05,
      "loss": 0.0009,
      "step": 39420
    },
    {
      "epoch": 1.1265714285714286,
      "grad_norm": 0.05377998575568199,
      "learning_rate": 2.1835714285714286e-05,
      "loss": 0.0016,
      "step": 39430
    },
    {
      "epoch": 1.1268571428571428,
      "grad_norm": 0.0,
      "learning_rate": 2.1828571428571428e-05,
      "loss": 0.0011,
      "step": 39440
    },
    {
      "epoch": 1.1271428571428572,
      "grad_norm": 0.07920782268047333,
      "learning_rate": 2.1821428571428573e-05,
      "loss": 0.0011,
      "step": 39450
    },
    {
      "epoch": 1.1274285714285714,
      "grad_norm": 0.09092880040407181,
      "learning_rate": 2.1814285714285715e-05,
      "loss": 0.0015,
      "step": 39460
    },
    {
      "epoch": 1.1277142857142857,
      "grad_norm": 0.046690307557582855,
      "learning_rate": 2.180714285714286e-05,
      "loss": 0.002,
      "step": 39470
    },
    {
      "epoch": 1.1280000000000001,
      "grad_norm": 0.13898594677448273,
      "learning_rate": 2.18e-05,
      "loss": 0.0014,
      "step": 39480
    },
    {
      "epoch": 1.1282857142857143,
      "grad_norm": 0.0,
      "learning_rate": 2.1792857142857143e-05,
      "loss": 0.0013,
      "step": 39490
    },
    {
      "epoch": 1.1285714285714286,
      "grad_norm": 0.08391092717647552,
      "learning_rate": 2.1785714285714288e-05,
      "loss": 0.001,
      "step": 39500
    },
    {
      "epoch": 1.1288571428571428,
      "grad_norm": 0.0,
      "learning_rate": 2.177857142857143e-05,
      "loss": 0.0016,
      "step": 39510
    },
    {
      "epoch": 1.1291428571428572,
      "grad_norm": 0.4289049208164215,
      "learning_rate": 2.177142857142857e-05,
      "loss": 0.002,
      "step": 39520
    },
    {
      "epoch": 1.1294285714285714,
      "grad_norm": 0.03197808191180229,
      "learning_rate": 2.1764285714285713e-05,
      "loss": 0.0007,
      "step": 39530
    },
    {
      "epoch": 1.1297142857142857,
      "grad_norm": 0.1283959001302719,
      "learning_rate": 2.175714285714286e-05,
      "loss": 0.001,
      "step": 39540
    },
    {
      "epoch": 1.13,
      "grad_norm": 0.0,
      "learning_rate": 2.175e-05,
      "loss": 0.0014,
      "step": 39550
    },
    {
      "epoch": 1.1302857142857143,
      "grad_norm": 0.14568756520748138,
      "learning_rate": 2.1742857142857142e-05,
      "loss": 0.0012,
      "step": 39560
    },
    {
      "epoch": 1.1305714285714286,
      "grad_norm": 0.04035545140504837,
      "learning_rate": 2.1735714285714287e-05,
      "loss": 0.0009,
      "step": 39570
    },
    {
      "epoch": 1.1308571428571428,
      "grad_norm": 0.03423241525888443,
      "learning_rate": 2.172857142857143e-05,
      "loss": 0.002,
      "step": 39580
    },
    {
      "epoch": 1.1311428571428572,
      "grad_norm": 0.27290645241737366,
      "learning_rate": 2.1721428571428574e-05,
      "loss": 0.0017,
      "step": 39590
    },
    {
      "epoch": 1.1314285714285715,
      "grad_norm": 0.044773612171411514,
      "learning_rate": 2.1714285714285715e-05,
      "loss": 0.0015,
      "step": 39600
    },
    {
      "epoch": 1.1317142857142857,
      "grad_norm": 0.02211078070104122,
      "learning_rate": 2.170714285714286e-05,
      "loss": 0.001,
      "step": 39610
    },
    {
      "epoch": 1.1320000000000001,
      "grad_norm": 0.03842049092054367,
      "learning_rate": 2.1700000000000002e-05,
      "loss": 0.0025,
      "step": 39620
    },
    {
      "epoch": 1.1322857142857143,
      "grad_norm": 0.04103653505444527,
      "learning_rate": 2.1692857142857144e-05,
      "loss": 0.0018,
      "step": 39630
    },
    {
      "epoch": 1.1325714285714286,
      "grad_norm": 0.0,
      "learning_rate": 2.1685714285714286e-05,
      "loss": 0.0019,
      "step": 39640
    },
    {
      "epoch": 1.1328571428571428,
      "grad_norm": 0.04684150964021683,
      "learning_rate": 2.1678571428571427e-05,
      "loss": 0.0014,
      "step": 39650
    },
    {
      "epoch": 1.1331428571428572,
      "grad_norm": 0.038792651146650314,
      "learning_rate": 2.1671428571428573e-05,
      "loss": 0.0013,
      "step": 39660
    },
    {
      "epoch": 1.1334285714285715,
      "grad_norm": 0.025886673480272293,
      "learning_rate": 2.1664285714285714e-05,
      "loss": 0.0024,
      "step": 39670
    },
    {
      "epoch": 1.1337142857142857,
      "grad_norm": 0.04884805530309677,
      "learning_rate": 2.165714285714286e-05,
      "loss": 0.0025,
      "step": 39680
    },
    {
      "epoch": 1.134,
      "grad_norm": 0.11020110547542572,
      "learning_rate": 2.165e-05,
      "loss": 0.0011,
      "step": 39690
    },
    {
      "epoch": 1.1342857142857143,
      "grad_norm": 0.04119550809264183,
      "learning_rate": 2.1642857142857146e-05,
      "loss": 0.0006,
      "step": 39700
    },
    {
      "epoch": 1.1345714285714286,
      "grad_norm": 0.0,
      "learning_rate": 2.1635714285714288e-05,
      "loss": 0.0012,
      "step": 39710
    },
    {
      "epoch": 1.1348571428571428,
      "grad_norm": 0.06063656136393547,
      "learning_rate": 2.162857142857143e-05,
      "loss": 0.001,
      "step": 39720
    },
    {
      "epoch": 1.1351428571428572,
      "grad_norm": 0.28830015659332275,
      "learning_rate": 2.1621428571428575e-05,
      "loss": 0.0017,
      "step": 39730
    },
    {
      "epoch": 1.1354285714285715,
      "grad_norm": 0.041610267013311386,
      "learning_rate": 2.1614285714285713e-05,
      "loss": 0.001,
      "step": 39740
    },
    {
      "epoch": 1.1357142857142857,
      "grad_norm": 0.3099193871021271,
      "learning_rate": 2.1607142857142858e-05,
      "loss": 0.0024,
      "step": 39750
    },
    {
      "epoch": 1.1360000000000001,
      "grad_norm": 0.0,
      "learning_rate": 2.16e-05,
      "loss": 0.0015,
      "step": 39760
    },
    {
      "epoch": 1.1362857142857143,
      "grad_norm": 0.13313770294189453,
      "learning_rate": 2.1592857142857145e-05,
      "loss": 0.0016,
      "step": 39770
    },
    {
      "epoch": 1.1365714285714286,
      "grad_norm": 0.04856915399432182,
      "learning_rate": 2.1585714285714287e-05,
      "loss": 0.0006,
      "step": 39780
    },
    {
      "epoch": 1.1368571428571428,
      "grad_norm": 0.035462502390146255,
      "learning_rate": 2.157857142857143e-05,
      "loss": 0.0011,
      "step": 39790
    },
    {
      "epoch": 1.1371428571428572,
      "grad_norm": 0.0,
      "learning_rate": 2.1571428571428574e-05,
      "loss": 0.0007,
      "step": 39800
    },
    {
      "epoch": 1.1374285714285715,
      "grad_norm": 0.04342598840594292,
      "learning_rate": 2.1564285714285715e-05,
      "loss": 0.0015,
      "step": 39810
    },
    {
      "epoch": 1.1377142857142857,
      "grad_norm": 0.04805849492549896,
      "learning_rate": 2.155714285714286e-05,
      "loss": 0.0005,
      "step": 39820
    },
    {
      "epoch": 1.138,
      "grad_norm": 0.04566569626331329,
      "learning_rate": 2.1550000000000002e-05,
      "loss": 0.0015,
      "step": 39830
    },
    {
      "epoch": 1.1382857142857143,
      "grad_norm": 0.01964816264808178,
      "learning_rate": 2.1542857142857144e-05,
      "loss": 0.0017,
      "step": 39840
    },
    {
      "epoch": 1.1385714285714286,
      "grad_norm": 0.2030317783355713,
      "learning_rate": 2.1535714285714285e-05,
      "loss": 0.0014,
      "step": 39850
    },
    {
      "epoch": 1.1388571428571428,
      "grad_norm": 0.357166588306427,
      "learning_rate": 2.1528571428571427e-05,
      "loss": 0.0016,
      "step": 39860
    },
    {
      "epoch": 1.1391428571428572,
      "grad_norm": 0.10733632743358612,
      "learning_rate": 2.1521428571428572e-05,
      "loss": 0.0011,
      "step": 39870
    },
    {
      "epoch": 1.1394285714285715,
      "grad_norm": 0.20754165947437286,
      "learning_rate": 2.1514285714285714e-05,
      "loss": 0.0007,
      "step": 39880
    },
    {
      "epoch": 1.1397142857142857,
      "grad_norm": 0.39987337589263916,
      "learning_rate": 2.150714285714286e-05,
      "loss": 0.0009,
      "step": 39890
    },
    {
      "epoch": 1.1400000000000001,
      "grad_norm": 0.04377666860818863,
      "learning_rate": 2.15e-05,
      "loss": 0.0017,
      "step": 39900
    },
    {
      "epoch": 1.1402857142857143,
      "grad_norm": 0.05772847682237625,
      "learning_rate": 2.1492857142857146e-05,
      "loss": 0.0015,
      "step": 39910
    },
    {
      "epoch": 1.1405714285714286,
      "grad_norm": 0.0444880835711956,
      "learning_rate": 2.1485714285714288e-05,
      "loss": 0.0014,
      "step": 39920
    },
    {
      "epoch": 1.1408571428571428,
      "grad_norm": 0.06757808476686478,
      "learning_rate": 2.147857142857143e-05,
      "loss": 0.0013,
      "step": 39930
    },
    {
      "epoch": 1.1411428571428572,
      "grad_norm": 0.0391196683049202,
      "learning_rate": 2.1471428571428574e-05,
      "loss": 0.0009,
      "step": 39940
    },
    {
      "epoch": 1.1414285714285715,
      "grad_norm": 0.040182121098041534,
      "learning_rate": 2.1464285714285716e-05,
      "loss": 0.0006,
      "step": 39950
    },
    {
      "epoch": 1.1417142857142857,
      "grad_norm": 0.0,
      "learning_rate": 2.1457142857142858e-05,
      "loss": 0.0019,
      "step": 39960
    },
    {
      "epoch": 1.142,
      "grad_norm": 0.23874808847904205,
      "learning_rate": 2.145e-05,
      "loss": 0.0012,
      "step": 39970
    },
    {
      "epoch": 1.1422857142857143,
      "grad_norm": 0.040305010974407196,
      "learning_rate": 2.1442857142857145e-05,
      "loss": 0.0024,
      "step": 39980
    },
    {
      "epoch": 1.1425714285714286,
      "grad_norm": 0.047296058386564255,
      "learning_rate": 2.1435714285714286e-05,
      "loss": 0.0018,
      "step": 39990
    },
    {
      "epoch": 1.1428571428571428,
      "grad_norm": 0.22582308948040009,
      "learning_rate": 2.1428571428571428e-05,
      "loss": 0.0011,
      "step": 40000
    },
    {
      "epoch": 1.1431428571428572,
      "grad_norm": 0.21795298159122467,
      "learning_rate": 2.1421428571428573e-05,
      "loss": 0.0015,
      "step": 40010
    },
    {
      "epoch": 1.1434285714285715,
      "grad_norm": 0.06080453470349312,
      "learning_rate": 2.1414285714285715e-05,
      "loss": 0.0024,
      "step": 40020
    },
    {
      "epoch": 1.1437142857142857,
      "grad_norm": 0.12319834530353546,
      "learning_rate": 2.140714285714286e-05,
      "loss": 0.0003,
      "step": 40030
    },
    {
      "epoch": 1.144,
      "grad_norm": 0.04729171097278595,
      "learning_rate": 2.1400000000000002e-05,
      "loss": 0.0012,
      "step": 40040
    },
    {
      "epoch": 1.1442857142857144,
      "grad_norm": 0.0,
      "learning_rate": 2.1392857142857143e-05,
      "loss": 0.0013,
      "step": 40050
    },
    {
      "epoch": 1.1445714285714286,
      "grad_norm": 0.08571049571037292,
      "learning_rate": 2.1385714285714285e-05,
      "loss": 0.0007,
      "step": 40060
    },
    {
      "epoch": 1.1448571428571428,
      "grad_norm": 0.05040833353996277,
      "learning_rate": 2.1378571428571427e-05,
      "loss": 0.001,
      "step": 40070
    },
    {
      "epoch": 1.145142857142857,
      "grad_norm": 0.0,
      "learning_rate": 2.1371428571428572e-05,
      "loss": 0.0009,
      "step": 40080
    },
    {
      "epoch": 1.1454285714285715,
      "grad_norm": 0.0,
      "learning_rate": 2.1364285714285714e-05,
      "loss": 0.0007,
      "step": 40090
    },
    {
      "epoch": 1.1457142857142857,
      "grad_norm": 0.0,
      "learning_rate": 2.135714285714286e-05,
      "loss": 0.0025,
      "step": 40100
    },
    {
      "epoch": 1.146,
      "grad_norm": 0.12199787050485611,
      "learning_rate": 2.135e-05,
      "loss": 0.0024,
      "step": 40110
    },
    {
      "epoch": 1.1462857142857144,
      "grad_norm": 0.0,
      "learning_rate": 2.1342857142857146e-05,
      "loss": 0.0009,
      "step": 40120
    },
    {
      "epoch": 1.1465714285714286,
      "grad_norm": 0.15187428891658783,
      "learning_rate": 2.1335714285714287e-05,
      "loss": 0.002,
      "step": 40130
    },
    {
      "epoch": 1.1468571428571428,
      "grad_norm": 0.04574494808912277,
      "learning_rate": 2.132857142857143e-05,
      "loss": 0.0013,
      "step": 40140
    },
    {
      "epoch": 1.1471428571428572,
      "grad_norm": 0.04576141759753227,
      "learning_rate": 2.1321428571428574e-05,
      "loss": 0.0014,
      "step": 40150
    },
    {
      "epoch": 1.1474285714285715,
      "grad_norm": 0.16116924583911896,
      "learning_rate": 2.1314285714285716e-05,
      "loss": 0.0012,
      "step": 40160
    },
    {
      "epoch": 1.1477142857142857,
      "grad_norm": 0.056201767176389694,
      "learning_rate": 2.1307142857142858e-05,
      "loss": 0.0011,
      "step": 40170
    },
    {
      "epoch": 1.148,
      "grad_norm": 0.0,
      "learning_rate": 2.13e-05,
      "loss": 0.0013,
      "step": 40180
    },
    {
      "epoch": 1.1482857142857144,
      "grad_norm": 0.0,
      "learning_rate": 2.1292857142857144e-05,
      "loss": 0.0009,
      "step": 40190
    },
    {
      "epoch": 1.1485714285714286,
      "grad_norm": 0.0,
      "learning_rate": 2.1285714285714286e-05,
      "loss": 0.0011,
      "step": 40200
    },
    {
      "epoch": 1.1488571428571428,
      "grad_norm": 0.13045716285705566,
      "learning_rate": 2.1278571428571428e-05,
      "loss": 0.0015,
      "step": 40210
    },
    {
      "epoch": 1.149142857142857,
      "grad_norm": 0.06662482768297195,
      "learning_rate": 2.1271428571428573e-05,
      "loss": 0.0013,
      "step": 40220
    },
    {
      "epoch": 1.1494285714285715,
      "grad_norm": 0.2567777633666992,
      "learning_rate": 2.1264285714285715e-05,
      "loss": 0.0008,
      "step": 40230
    },
    {
      "epoch": 1.1497142857142857,
      "grad_norm": 0.05133156478404999,
      "learning_rate": 2.125714285714286e-05,
      "loss": 0.0009,
      "step": 40240
    },
    {
      "epoch": 1.15,
      "grad_norm": 0.04239506646990776,
      "learning_rate": 2.125e-05,
      "loss": 0.0014,
      "step": 40250
    },
    {
      "epoch": 1.1502857142857144,
      "grad_norm": 0.0598822645843029,
      "learning_rate": 2.1242857142857143e-05,
      "loss": 0.0014,
      "step": 40260
    },
    {
      "epoch": 1.1505714285714286,
      "grad_norm": 0.0,
      "learning_rate": 2.1235714285714285e-05,
      "loss": 0.0017,
      "step": 40270
    },
    {
      "epoch": 1.1508571428571428,
      "grad_norm": 0.2764681279659271,
      "learning_rate": 2.1228571428571427e-05,
      "loss": 0.0011,
      "step": 40280
    },
    {
      "epoch": 1.1511428571428572,
      "grad_norm": 0.08983846753835678,
      "learning_rate": 2.1221428571428572e-05,
      "loss": 0.0019,
      "step": 40290
    },
    {
      "epoch": 1.1514285714285715,
      "grad_norm": 0.09383273869752884,
      "learning_rate": 2.1214285714285713e-05,
      "loss": 0.0013,
      "step": 40300
    },
    {
      "epoch": 1.1517142857142857,
      "grad_norm": 0.056403014808893204,
      "learning_rate": 2.120714285714286e-05,
      "loss": 0.0015,
      "step": 40310
    },
    {
      "epoch": 1.152,
      "grad_norm": 0.05223533511161804,
      "learning_rate": 2.12e-05,
      "loss": 0.0016,
      "step": 40320
    },
    {
      "epoch": 1.1522857142857144,
      "grad_norm": 0.08899295330047607,
      "learning_rate": 2.1192857142857145e-05,
      "loss": 0.0008,
      "step": 40330
    },
    {
      "epoch": 1.1525714285714286,
      "grad_norm": 0.23585432767868042,
      "learning_rate": 2.1185714285714287e-05,
      "loss": 0.0025,
      "step": 40340
    },
    {
      "epoch": 1.1528571428571428,
      "grad_norm": 0.08686257153749466,
      "learning_rate": 2.1178571428571432e-05,
      "loss": 0.0013,
      "step": 40350
    },
    {
      "epoch": 1.153142857142857,
      "grad_norm": 0.04433240741491318,
      "learning_rate": 2.1171428571428574e-05,
      "loss": 0.0014,
      "step": 40360
    },
    {
      "epoch": 1.1534285714285715,
      "grad_norm": 0.08082445710897446,
      "learning_rate": 2.1164285714285716e-05,
      "loss": 0.0006,
      "step": 40370
    },
    {
      "epoch": 1.1537142857142857,
      "grad_norm": 0.05640600621700287,
      "learning_rate": 2.1157142857142857e-05,
      "loss": 0.0011,
      "step": 40380
    },
    {
      "epoch": 1.154,
      "grad_norm": 0.20213690400123596,
      "learning_rate": 2.115e-05,
      "loss": 0.0016,
      "step": 40390
    },
    {
      "epoch": 1.1542857142857144,
      "grad_norm": 0.15176227688789368,
      "learning_rate": 2.1142857142857144e-05,
      "loss": 0.0016,
      "step": 40400
    },
    {
      "epoch": 1.1545714285714286,
      "grad_norm": 0.08551542460918427,
      "learning_rate": 2.1135714285714286e-05,
      "loss": 0.0014,
      "step": 40410
    },
    {
      "epoch": 1.1548571428571428,
      "grad_norm": 0.04700508713722229,
      "learning_rate": 2.112857142857143e-05,
      "loss": 0.0001,
      "step": 40420
    },
    {
      "epoch": 1.1551428571428572,
      "grad_norm": 0.04424797371029854,
      "learning_rate": 2.1121428571428573e-05,
      "loss": 0.0011,
      "step": 40430
    },
    {
      "epoch": 1.1554285714285715,
      "grad_norm": 0.11890675127506256,
      "learning_rate": 2.1114285714285714e-05,
      "loss": 0.0023,
      "step": 40440
    },
    {
      "epoch": 1.1557142857142857,
      "grad_norm": 0.04341588541865349,
      "learning_rate": 2.110714285714286e-05,
      "loss": 0.0019,
      "step": 40450
    },
    {
      "epoch": 1.156,
      "grad_norm": 0.09013466536998749,
      "learning_rate": 2.11e-05,
      "loss": 0.0014,
      "step": 40460
    },
    {
      "epoch": 1.1562857142857144,
      "grad_norm": 0.02709527499973774,
      "learning_rate": 2.1092857142857146e-05,
      "loss": 0.0018,
      "step": 40470
    },
    {
      "epoch": 1.1565714285714286,
      "grad_norm": 0.13887923955917358,
      "learning_rate": 2.1085714285714288e-05,
      "loss": 0.0015,
      "step": 40480
    },
    {
      "epoch": 1.1568571428571428,
      "grad_norm": 0.2714408040046692,
      "learning_rate": 2.107857142857143e-05,
      "loss": 0.0019,
      "step": 40490
    },
    {
      "epoch": 1.157142857142857,
      "grad_norm": 0.0,
      "learning_rate": 2.107142857142857e-05,
      "loss": 0.0006,
      "step": 40500
    },
    {
      "epoch": 1.1574285714285715,
      "grad_norm": 0.0,
      "learning_rate": 2.1064285714285713e-05,
      "loss": 0.0012,
      "step": 40510
    },
    {
      "epoch": 1.1577142857142857,
      "grad_norm": 0.0,
      "learning_rate": 2.105714285714286e-05,
      "loss": 0.0017,
      "step": 40520
    },
    {
      "epoch": 1.158,
      "grad_norm": 0.04763258621096611,
      "learning_rate": 2.105e-05,
      "loss": 0.0015,
      "step": 40530
    },
    {
      "epoch": 1.1582857142857144,
      "grad_norm": 0.0,
      "learning_rate": 2.1042857142857145e-05,
      "loss": 0.0008,
      "step": 40540
    },
    {
      "epoch": 1.1585714285714286,
      "grad_norm": 0.0,
      "learning_rate": 2.1035714285714287e-05,
      "loss": 0.0005,
      "step": 40550
    },
    {
      "epoch": 1.1588571428571428,
      "grad_norm": 0.0,
      "learning_rate": 2.1028571428571432e-05,
      "loss": 0.0015,
      "step": 40560
    },
    {
      "epoch": 1.1591428571428573,
      "grad_norm": 0.0,
      "learning_rate": 2.1021428571428574e-05,
      "loss": 0.0009,
      "step": 40570
    },
    {
      "epoch": 1.1594285714285715,
      "grad_norm": 0.0,
      "learning_rate": 2.1014285714285715e-05,
      "loss": 0.0018,
      "step": 40580
    },
    {
      "epoch": 1.1597142857142857,
      "grad_norm": 0.0,
      "learning_rate": 2.1007142857142857e-05,
      "loss": 0.002,
      "step": 40590
    },
    {
      "epoch": 1.16,
      "grad_norm": 0.12735553085803986,
      "learning_rate": 2.1e-05,
      "loss": 0.0012,
      "step": 40600
    },
    {
      "epoch": 1.1602857142857144,
      "grad_norm": 0.0,
      "learning_rate": 2.0992857142857144e-05,
      "loss": 0.0013,
      "step": 40610
    },
    {
      "epoch": 1.1605714285714286,
      "grad_norm": 0.04663223400712013,
      "learning_rate": 2.0985714285714286e-05,
      "loss": 0.0012,
      "step": 40620
    },
    {
      "epoch": 1.1608571428571428,
      "grad_norm": 0.0,
      "learning_rate": 2.097857142857143e-05,
      "loss": 0.0011,
      "step": 40630
    },
    {
      "epoch": 1.161142857142857,
      "grad_norm": 0.03959667682647705,
      "learning_rate": 2.0971428571428572e-05,
      "loss": 0.0018,
      "step": 40640
    },
    {
      "epoch": 1.1614285714285715,
      "grad_norm": 0.29958003759384155,
      "learning_rate": 2.0964285714285714e-05,
      "loss": 0.0009,
      "step": 40650
    },
    {
      "epoch": 1.1617142857142857,
      "grad_norm": 0.051137473434209824,
      "learning_rate": 2.095714285714286e-05,
      "loss": 0.0026,
      "step": 40660
    },
    {
      "epoch": 1.162,
      "grad_norm": 0.04149080067873001,
      "learning_rate": 2.095e-05,
      "loss": 0.0011,
      "step": 40670
    },
    {
      "epoch": 1.1622857142857144,
      "grad_norm": 0.30169057846069336,
      "learning_rate": 2.0942857142857146e-05,
      "loss": 0.0007,
      "step": 40680
    },
    {
      "epoch": 1.1625714285714286,
      "grad_norm": 0.10443191230297089,
      "learning_rate": 2.0935714285714288e-05,
      "loss": 0.0016,
      "step": 40690
    },
    {
      "epoch": 1.1628571428571428,
      "grad_norm": 0.0584687739610672,
      "learning_rate": 2.092857142857143e-05,
      "loss": 0.0009,
      "step": 40700
    },
    {
      "epoch": 1.1631428571428573,
      "grad_norm": 0.347039133310318,
      "learning_rate": 2.092142857142857e-05,
      "loss": 0.0014,
      "step": 40710
    },
    {
      "epoch": 1.1634285714285715,
      "grad_norm": 0.03432908281683922,
      "learning_rate": 2.0914285714285713e-05,
      "loss": 0.0012,
      "step": 40720
    },
    {
      "epoch": 1.1637142857142857,
      "grad_norm": 0.1336803287267685,
      "learning_rate": 2.0907142857142858e-05,
      "loss": 0.0011,
      "step": 40730
    },
    {
      "epoch": 1.164,
      "grad_norm": 0.16209053993225098,
      "learning_rate": 2.09e-05,
      "loss": 0.0011,
      "step": 40740
    },
    {
      "epoch": 1.1642857142857144,
      "grad_norm": 0.03197651356458664,
      "learning_rate": 2.0892857142857145e-05,
      "loss": 0.0018,
      "step": 40750
    },
    {
      "epoch": 1.1645714285714286,
      "grad_norm": 0.17756153643131256,
      "learning_rate": 2.0885714285714287e-05,
      "loss": 0.0019,
      "step": 40760
    },
    {
      "epoch": 1.1648571428571428,
      "grad_norm": 0.03948822617530823,
      "learning_rate": 2.0878571428571432e-05,
      "loss": 0.0016,
      "step": 40770
    },
    {
      "epoch": 1.165142857142857,
      "grad_norm": 0.14287197589874268,
      "learning_rate": 2.0871428571428573e-05,
      "loss": 0.0014,
      "step": 40780
    },
    {
      "epoch": 1.1654285714285715,
      "grad_norm": 0.04921611398458481,
      "learning_rate": 2.0864285714285715e-05,
      "loss": 0.0011,
      "step": 40790
    },
    {
      "epoch": 1.1657142857142857,
      "grad_norm": 0.04240850731730461,
      "learning_rate": 2.0857142857142857e-05,
      "loss": 0.0026,
      "step": 40800
    },
    {
      "epoch": 1.166,
      "grad_norm": 0.0,
      "learning_rate": 2.085e-05,
      "loss": 0.002,
      "step": 40810
    },
    {
      "epoch": 1.1662857142857144,
      "grad_norm": 0.051666490733623505,
      "learning_rate": 2.0842857142857144e-05,
      "loss": 0.0009,
      "step": 40820
    },
    {
      "epoch": 1.1665714285714286,
      "grad_norm": 0.09365826100111008,
      "learning_rate": 2.0835714285714285e-05,
      "loss": 0.0013,
      "step": 40830
    },
    {
      "epoch": 1.1668571428571428,
      "grad_norm": 0.0,
      "learning_rate": 2.082857142857143e-05,
      "loss": 0.0018,
      "step": 40840
    },
    {
      "epoch": 1.1671428571428573,
      "grad_norm": 0.0,
      "learning_rate": 2.0821428571428572e-05,
      "loss": 0.0009,
      "step": 40850
    },
    {
      "epoch": 1.1674285714285715,
      "grad_norm": 0.11876442283391953,
      "learning_rate": 2.0814285714285714e-05,
      "loss": 0.0011,
      "step": 40860
    },
    {
      "epoch": 1.1677142857142857,
      "grad_norm": 0.042229361832141876,
      "learning_rate": 2.080714285714286e-05,
      "loss": 0.0007,
      "step": 40870
    },
    {
      "epoch": 1.168,
      "grad_norm": 0.0,
      "learning_rate": 2.08e-05,
      "loss": 0.0014,
      "step": 40880
    },
    {
      "epoch": 1.1682857142857144,
      "grad_norm": 0.0766822099685669,
      "learning_rate": 2.0792857142857146e-05,
      "loss": 0.001,
      "step": 40890
    },
    {
      "epoch": 1.1685714285714286,
      "grad_norm": 0.05031172186136246,
      "learning_rate": 2.0785714285714288e-05,
      "loss": 0.0019,
      "step": 40900
    },
    {
      "epoch": 1.1688571428571428,
      "grad_norm": 0.03290661424398422,
      "learning_rate": 2.077857142857143e-05,
      "loss": 0.001,
      "step": 40910
    },
    {
      "epoch": 1.169142857142857,
      "grad_norm": 0.09822738170623779,
      "learning_rate": 2.077142857142857e-05,
      "loss": 0.002,
      "step": 40920
    },
    {
      "epoch": 1.1694285714285715,
      "grad_norm": 0.05472773686051369,
      "learning_rate": 2.0764285714285713e-05,
      "loss": 0.0025,
      "step": 40930
    },
    {
      "epoch": 1.1697142857142857,
      "grad_norm": 0.08648773282766342,
      "learning_rate": 2.0757142857142858e-05,
      "loss": 0.0017,
      "step": 40940
    },
    {
      "epoch": 1.17,
      "grad_norm": 0.08577807247638702,
      "learning_rate": 2.075e-05,
      "loss": 0.0006,
      "step": 40950
    },
    {
      "epoch": 1.1702857142857144,
      "grad_norm": 0.05411122739315033,
      "learning_rate": 2.0742857142857145e-05,
      "loss": 0.0009,
      "step": 40960
    },
    {
      "epoch": 1.1705714285714286,
      "grad_norm": 0.05040302500128746,
      "learning_rate": 2.0735714285714286e-05,
      "loss": 0.0023,
      "step": 40970
    },
    {
      "epoch": 1.1708571428571428,
      "grad_norm": 0.054438039660453796,
      "learning_rate": 2.072857142857143e-05,
      "loss": 0.0006,
      "step": 40980
    },
    {
      "epoch": 1.1711428571428573,
      "grad_norm": 0.05117952823638916,
      "learning_rate": 2.0721428571428573e-05,
      "loss": 0.0022,
      "step": 40990
    },
    {
      "epoch": 1.1714285714285715,
      "grad_norm": 0.0546998530626297,
      "learning_rate": 2.0714285714285718e-05,
      "loss": 0.0009,
      "step": 41000
    },
    {
      "epoch": 1.1717142857142857,
      "grad_norm": 0.10532710701227188,
      "learning_rate": 2.0707142857142857e-05,
      "loss": 0.002,
      "step": 41010
    },
    {
      "epoch": 1.172,
      "grad_norm": 0.0,
      "learning_rate": 2.07e-05,
      "loss": 0.0011,
      "step": 41020
    },
    {
      "epoch": 1.1722857142857144,
      "grad_norm": 0.0,
      "learning_rate": 2.0692857142857143e-05,
      "loss": 0.001,
      "step": 41030
    },
    {
      "epoch": 1.1725714285714286,
      "grad_norm": 0.10357539355754852,
      "learning_rate": 2.0685714285714285e-05,
      "loss": 0.0021,
      "step": 41040
    },
    {
      "epoch": 1.1728571428571428,
      "grad_norm": 0.0,
      "learning_rate": 2.067857142857143e-05,
      "loss": 0.0008,
      "step": 41050
    },
    {
      "epoch": 1.173142857142857,
      "grad_norm": 0.04747433587908745,
      "learning_rate": 2.0671428571428572e-05,
      "loss": 0.001,
      "step": 41060
    },
    {
      "epoch": 1.1734285714285715,
      "grad_norm": 0.28299376368522644,
      "learning_rate": 2.0664285714285717e-05,
      "loss": 0.0014,
      "step": 41070
    },
    {
      "epoch": 1.1737142857142857,
      "grad_norm": 0.03806336596608162,
      "learning_rate": 2.065714285714286e-05,
      "loss": 0.0008,
      "step": 41080
    },
    {
      "epoch": 1.174,
      "grad_norm": 0.22538024187088013,
      "learning_rate": 2.065e-05,
      "loss": 0.002,
      "step": 41090
    },
    {
      "epoch": 1.1742857142857144,
      "grad_norm": 0.04248591884970665,
      "learning_rate": 2.0642857142857146e-05,
      "loss": 0.0021,
      "step": 41100
    },
    {
      "epoch": 1.1745714285714286,
      "grad_norm": 0.05124998465180397,
      "learning_rate": 2.0635714285714287e-05,
      "loss": 0.0019,
      "step": 41110
    },
    {
      "epoch": 1.1748571428571428,
      "grad_norm": 0.0,
      "learning_rate": 2.062857142857143e-05,
      "loss": 0.0011,
      "step": 41120
    },
    {
      "epoch": 1.1751428571428573,
      "grad_norm": 0.03660938888788223,
      "learning_rate": 2.062142857142857e-05,
      "loss": 0.0006,
      "step": 41130
    },
    {
      "epoch": 1.1754285714285715,
      "grad_norm": 0.03944314643740654,
      "learning_rate": 2.0614285714285716e-05,
      "loss": 0.0012,
      "step": 41140
    },
    {
      "epoch": 1.1757142857142857,
      "grad_norm": 0.0,
      "learning_rate": 2.0607142857142858e-05,
      "loss": 0.0015,
      "step": 41150
    },
    {
      "epoch": 1.176,
      "grad_norm": 0.0,
      "learning_rate": 2.06e-05,
      "loss": 0.0003,
      "step": 41160
    },
    {
      "epoch": 1.1762857142857144,
      "grad_norm": 0.04093751683831215,
      "learning_rate": 2.0592857142857144e-05,
      "loss": 0.0015,
      "step": 41170
    },
    {
      "epoch": 1.1765714285714286,
      "grad_norm": 0.04334915056824684,
      "learning_rate": 2.0585714285714286e-05,
      "loss": 0.0016,
      "step": 41180
    },
    {
      "epoch": 1.1768571428571428,
      "grad_norm": 0.036075569689273834,
      "learning_rate": 2.057857142857143e-05,
      "loss": 0.0018,
      "step": 41190
    },
    {
      "epoch": 1.177142857142857,
      "grad_norm": 0.2398601770401001,
      "learning_rate": 2.0571428571428573e-05,
      "loss": 0.0013,
      "step": 41200
    },
    {
      "epoch": 1.1774285714285715,
      "grad_norm": 0.3647204339504242,
      "learning_rate": 2.0564285714285718e-05,
      "loss": 0.0011,
      "step": 41210
    },
    {
      "epoch": 1.1777142857142857,
      "grad_norm": 0.08410834521055222,
      "learning_rate": 2.055714285714286e-05,
      "loss": 0.0017,
      "step": 41220
    },
    {
      "epoch": 1.178,
      "grad_norm": 0.047159045934677124,
      "learning_rate": 2.055e-05,
      "loss": 0.0016,
      "step": 41230
    },
    {
      "epoch": 1.1782857142857144,
      "grad_norm": 0.07214348763227463,
      "learning_rate": 2.0542857142857143e-05,
      "loss": 0.002,
      "step": 41240
    },
    {
      "epoch": 1.1785714285714286,
      "grad_norm": 0.0,
      "learning_rate": 2.0535714285714285e-05,
      "loss": 0.0023,
      "step": 41250
    },
    {
      "epoch": 1.1788571428571428,
      "grad_norm": 0.030199389904737473,
      "learning_rate": 2.052857142857143e-05,
      "loss": 0.0022,
      "step": 41260
    },
    {
      "epoch": 1.179142857142857,
      "grad_norm": 0.04780510067939758,
      "learning_rate": 2.0521428571428572e-05,
      "loss": 0.0021,
      "step": 41270
    },
    {
      "epoch": 1.1794285714285715,
      "grad_norm": 0.11435102671384811,
      "learning_rate": 2.0514285714285717e-05,
      "loss": 0.0011,
      "step": 41280
    },
    {
      "epoch": 1.1797142857142857,
      "grad_norm": 0.19997334480285645,
      "learning_rate": 2.050714285714286e-05,
      "loss": 0.0008,
      "step": 41290
    },
    {
      "epoch": 1.18,
      "grad_norm": 0.06725305318832397,
      "learning_rate": 2.05e-05,
      "loss": 0.0013,
      "step": 41300
    },
    {
      "epoch": 1.1802857142857144,
      "grad_norm": 0.0,
      "learning_rate": 2.0492857142857145e-05,
      "loss": 0.0004,
      "step": 41310
    },
    {
      "epoch": 1.1805714285714286,
      "grad_norm": 0.08463593572378159,
      "learning_rate": 2.0485714285714287e-05,
      "loss": 0.0019,
      "step": 41320
    },
    {
      "epoch": 1.1808571428571428,
      "grad_norm": 0.1249970868229866,
      "learning_rate": 2.047857142857143e-05,
      "loss": 0.0018,
      "step": 41330
    },
    {
      "epoch": 1.181142857142857,
      "grad_norm": 0.04768122732639313,
      "learning_rate": 2.047142857142857e-05,
      "loss": 0.001,
      "step": 41340
    },
    {
      "epoch": 1.1814285714285715,
      "grad_norm": 0.08838945627212524,
      "learning_rate": 2.0464285714285716e-05,
      "loss": 0.0014,
      "step": 41350
    },
    {
      "epoch": 1.1817142857142857,
      "grad_norm": 0.08127231150865555,
      "learning_rate": 2.0457142857142857e-05,
      "loss": 0.0018,
      "step": 41360
    },
    {
      "epoch": 1.182,
      "grad_norm": 0.08756428956985474,
      "learning_rate": 2.045e-05,
      "loss": 0.0015,
      "step": 41370
    },
    {
      "epoch": 1.1822857142857144,
      "grad_norm": 0.0,
      "learning_rate": 2.0442857142857144e-05,
      "loss": 0.001,
      "step": 41380
    },
    {
      "epoch": 1.1825714285714286,
      "grad_norm": 0.047275952994823456,
      "learning_rate": 2.0435714285714286e-05,
      "loss": 0.0011,
      "step": 41390
    },
    {
      "epoch": 1.1828571428571428,
      "grad_norm": 0.0,
      "learning_rate": 2.042857142857143e-05,
      "loss": 0.0007,
      "step": 41400
    },
    {
      "epoch": 1.183142857142857,
      "grad_norm": 0.0,
      "learning_rate": 2.0421428571428573e-05,
      "loss": 0.0006,
      "step": 41410
    },
    {
      "epoch": 1.1834285714285715,
      "grad_norm": 0.19571281969547272,
      "learning_rate": 2.0414285714285718e-05,
      "loss": 0.0007,
      "step": 41420
    },
    {
      "epoch": 1.1837142857142857,
      "grad_norm": 0.0,
      "learning_rate": 2.040714285714286e-05,
      "loss": 0.0016,
      "step": 41430
    },
    {
      "epoch": 1.184,
      "grad_norm": 0.24961413443088531,
      "learning_rate": 2.04e-05,
      "loss": 0.0011,
      "step": 41440
    },
    {
      "epoch": 1.1842857142857142,
      "grad_norm": 0.08892739564180374,
      "learning_rate": 2.0392857142857143e-05,
      "loss": 0.002,
      "step": 41450
    },
    {
      "epoch": 1.1845714285714286,
      "grad_norm": 0.05573853850364685,
      "learning_rate": 2.0385714285714285e-05,
      "loss": 0.0007,
      "step": 41460
    },
    {
      "epoch": 1.1848571428571428,
      "grad_norm": 0.04796154052019119,
      "learning_rate": 2.037857142857143e-05,
      "loss": 0.0012,
      "step": 41470
    },
    {
      "epoch": 1.185142857142857,
      "grad_norm": 0.043879952281713486,
      "learning_rate": 2.037142857142857e-05,
      "loss": 0.0012,
      "step": 41480
    },
    {
      "epoch": 1.1854285714285715,
      "grad_norm": 0.039887696504592896,
      "learning_rate": 2.0364285714285717e-05,
      "loss": 0.0008,
      "step": 41490
    },
    {
      "epoch": 1.1857142857142857,
      "grad_norm": 0.0,
      "learning_rate": 2.0357142857142858e-05,
      "loss": 0.0008,
      "step": 41500
    },
    {
      "epoch": 1.186,
      "grad_norm": 0.2689478099346161,
      "learning_rate": 2.035e-05,
      "loss": 0.001,
      "step": 41510
    },
    {
      "epoch": 1.1862857142857144,
      "grad_norm": 0.273739218711853,
      "learning_rate": 2.0342857142857145e-05,
      "loss": 0.0014,
      "step": 41520
    },
    {
      "epoch": 1.1865714285714286,
      "grad_norm": 0.0,
      "learning_rate": 2.0335714285714287e-05,
      "loss": 0.0008,
      "step": 41530
    },
    {
      "epoch": 1.1868571428571428,
      "grad_norm": 0.045364025980234146,
      "learning_rate": 2.032857142857143e-05,
      "loss": 0.001,
      "step": 41540
    },
    {
      "epoch": 1.187142857142857,
      "grad_norm": 0.045278921723365784,
      "learning_rate": 2.032142857142857e-05,
      "loss": 0.0015,
      "step": 41550
    },
    {
      "epoch": 1.1874285714285715,
      "grad_norm": 0.04337451979517937,
      "learning_rate": 2.0314285714285715e-05,
      "loss": 0.0012,
      "step": 41560
    },
    {
      "epoch": 1.1877142857142857,
      "grad_norm": 0.18051737546920776,
      "learning_rate": 2.0307142857142857e-05,
      "loss": 0.0012,
      "step": 41570
    },
    {
      "epoch": 1.188,
      "grad_norm": 0.053554046899080276,
      "learning_rate": 2.0300000000000002e-05,
      "loss": 0.0014,
      "step": 41580
    },
    {
      "epoch": 1.1882857142857142,
      "grad_norm": 0.2214929312467575,
      "learning_rate": 2.0292857142857144e-05,
      "loss": 0.0012,
      "step": 41590
    },
    {
      "epoch": 1.1885714285714286,
      "grad_norm": 0.03569592162966728,
      "learning_rate": 2.0285714285714286e-05,
      "loss": 0.0008,
      "step": 41600
    },
    {
      "epoch": 1.1888571428571428,
      "grad_norm": 0.13113757967948914,
      "learning_rate": 2.027857142857143e-05,
      "loss": 0.0011,
      "step": 41610
    },
    {
      "epoch": 1.189142857142857,
      "grad_norm": 0.04731910303235054,
      "learning_rate": 2.0271428571428572e-05,
      "loss": 0.0004,
      "step": 41620
    },
    {
      "epoch": 1.1894285714285715,
      "grad_norm": 0.051822975277900696,
      "learning_rate": 2.0264285714285718e-05,
      "loss": 0.0006,
      "step": 41630
    },
    {
      "epoch": 1.1897142857142857,
      "grad_norm": 0.0,
      "learning_rate": 2.025714285714286e-05,
      "loss": 0.0011,
      "step": 41640
    },
    {
      "epoch": 1.19,
      "grad_norm": 0.043674543499946594,
      "learning_rate": 2.025e-05,
      "loss": 0.0016,
      "step": 41650
    },
    {
      "epoch": 1.1902857142857144,
      "grad_norm": 0.22499839961528778,
      "learning_rate": 2.0242857142857143e-05,
      "loss": 0.001,
      "step": 41660
    },
    {
      "epoch": 1.1905714285714286,
      "grad_norm": 0.16075009107589722,
      "learning_rate": 2.0235714285714284e-05,
      "loss": 0.0012,
      "step": 41670
    },
    {
      "epoch": 1.1908571428571428,
      "grad_norm": 0.28259697556495667,
      "learning_rate": 2.022857142857143e-05,
      "loss": 0.0015,
      "step": 41680
    },
    {
      "epoch": 1.191142857142857,
      "grad_norm": 0.05529215559363365,
      "learning_rate": 2.022142857142857e-05,
      "loss": 0.0011,
      "step": 41690
    },
    {
      "epoch": 1.1914285714285715,
      "grad_norm": 0.31095051765441895,
      "learning_rate": 2.0214285714285716e-05,
      "loss": 0.0012,
      "step": 41700
    },
    {
      "epoch": 1.1917142857142857,
      "grad_norm": 0.11633476614952087,
      "learning_rate": 2.0207142857142858e-05,
      "loss": 0.001,
      "step": 41710
    },
    {
      "epoch": 1.192,
      "grad_norm": 0.04655548930168152,
      "learning_rate": 2.0200000000000003e-05,
      "loss": 0.0018,
      "step": 41720
    },
    {
      "epoch": 1.1922857142857142,
      "grad_norm": 0.05848117172718048,
      "learning_rate": 2.0192857142857145e-05,
      "loss": 0.0006,
      "step": 41730
    },
    {
      "epoch": 1.1925714285714286,
      "grad_norm": 0.3185107409954071,
      "learning_rate": 2.0185714285714287e-05,
      "loss": 0.0012,
      "step": 41740
    },
    {
      "epoch": 1.1928571428571428,
      "grad_norm": 0.08357362449169159,
      "learning_rate": 2.017857142857143e-05,
      "loss": 0.0008,
      "step": 41750
    },
    {
      "epoch": 1.193142857142857,
      "grad_norm": 0.11718323826789856,
      "learning_rate": 2.0171428571428573e-05,
      "loss": 0.0024,
      "step": 41760
    },
    {
      "epoch": 1.1934285714285715,
      "grad_norm": 0.15877556800842285,
      "learning_rate": 2.0164285714285715e-05,
      "loss": 0.0015,
      "step": 41770
    },
    {
      "epoch": 1.1937142857142857,
      "grad_norm": 0.08960426598787308,
      "learning_rate": 2.0157142857142857e-05,
      "loss": 0.0015,
      "step": 41780
    },
    {
      "epoch": 1.194,
      "grad_norm": 0.05020378902554512,
      "learning_rate": 2.0150000000000002e-05,
      "loss": 0.0019,
      "step": 41790
    },
    {
      "epoch": 1.1942857142857144,
      "grad_norm": 0.19045144319534302,
      "learning_rate": 2.0142857142857144e-05,
      "loss": 0.0029,
      "step": 41800
    },
    {
      "epoch": 1.1945714285714286,
      "grad_norm": 0.06982740014791489,
      "learning_rate": 2.0135714285714285e-05,
      "loss": 0.001,
      "step": 41810
    },
    {
      "epoch": 1.1948571428571428,
      "grad_norm": 0.19346733391284943,
      "learning_rate": 2.012857142857143e-05,
      "loss": 0.0008,
      "step": 41820
    },
    {
      "epoch": 1.195142857142857,
      "grad_norm": 0.047633182257413864,
      "learning_rate": 2.0121428571428572e-05,
      "loss": 0.0009,
      "step": 41830
    },
    {
      "epoch": 1.1954285714285715,
      "grad_norm": 0.04299061372876167,
      "learning_rate": 2.0114285714285717e-05,
      "loss": 0.0012,
      "step": 41840
    },
    {
      "epoch": 1.1957142857142857,
      "grad_norm": 0.046293966472148895,
      "learning_rate": 2.010714285714286e-05,
      "loss": 0.0009,
      "step": 41850
    },
    {
      "epoch": 1.196,
      "grad_norm": 0.048187121748924255,
      "learning_rate": 2.01e-05,
      "loss": 0.0018,
      "step": 41860
    },
    {
      "epoch": 1.1962857142857142,
      "grad_norm": 0.3166995048522949,
      "learning_rate": 2.0092857142857142e-05,
      "loss": 0.0011,
      "step": 41870
    },
    {
      "epoch": 1.1965714285714286,
      "grad_norm": 0.28373026847839355,
      "learning_rate": 2.0085714285714284e-05,
      "loss": 0.0017,
      "step": 41880
    },
    {
      "epoch": 1.1968571428571428,
      "grad_norm": 0.13396160304546356,
      "learning_rate": 2.007857142857143e-05,
      "loss": 0.0015,
      "step": 41890
    },
    {
      "epoch": 1.197142857142857,
      "grad_norm": 0.0,
      "learning_rate": 2.007142857142857e-05,
      "loss": 0.0012,
      "step": 41900
    },
    {
      "epoch": 1.1974285714285715,
      "grad_norm": 0.0,
      "learning_rate": 2.0064285714285716e-05,
      "loss": 0.0011,
      "step": 41910
    },
    {
      "epoch": 1.1977142857142857,
      "grad_norm": 0.04507565498352051,
      "learning_rate": 2.0057142857142858e-05,
      "loss": 0.0013,
      "step": 41920
    },
    {
      "epoch": 1.198,
      "grad_norm": 0.0,
      "learning_rate": 2.0050000000000003e-05,
      "loss": 0.0004,
      "step": 41930
    },
    {
      "epoch": 1.1982857142857144,
      "grad_norm": 0.04934589937329292,
      "learning_rate": 2.0042857142857145e-05,
      "loss": 0.0022,
      "step": 41940
    },
    {
      "epoch": 1.1985714285714286,
      "grad_norm": 0.03316015377640724,
      "learning_rate": 2.0035714285714286e-05,
      "loss": 0.0011,
      "step": 41950
    },
    {
      "epoch": 1.1988571428571428,
      "grad_norm": 0.10170558094978333,
      "learning_rate": 2.002857142857143e-05,
      "loss": 0.0029,
      "step": 41960
    },
    {
      "epoch": 1.199142857142857,
      "grad_norm": 0.21801266074180603,
      "learning_rate": 2.0021428571428573e-05,
      "loss": 0.0018,
      "step": 41970
    },
    {
      "epoch": 1.1994285714285715,
      "grad_norm": 0.0,
      "learning_rate": 2.0014285714285715e-05,
      "loss": 0.0015,
      "step": 41980
    },
    {
      "epoch": 1.1997142857142857,
      "grad_norm": 0.24085207283496857,
      "learning_rate": 2.0007142857142857e-05,
      "loss": 0.0021,
      "step": 41990
    },
    {
      "epoch": 1.2,
      "grad_norm": 0.06059424579143524,
      "learning_rate": 2e-05,
      "loss": 0.0012,
      "step": 42000
    },
    {
      "epoch": 1.2002857142857142,
      "grad_norm": 0.04564642906188965,
      "learning_rate": 1.9992857142857143e-05,
      "loss": 0.0008,
      "step": 42010
    },
    {
      "epoch": 1.2005714285714286,
      "grad_norm": 0.0,
      "learning_rate": 1.9985714285714285e-05,
      "loss": 0.0008,
      "step": 42020
    },
    {
      "epoch": 1.2008571428571428,
      "grad_norm": 0.049855660647153854,
      "learning_rate": 1.997857142857143e-05,
      "loss": 0.0011,
      "step": 42030
    },
    {
      "epoch": 1.201142857142857,
      "grad_norm": 0.07553549855947495,
      "learning_rate": 1.9971428571428572e-05,
      "loss": 0.0018,
      "step": 42040
    },
    {
      "epoch": 1.2014285714285715,
      "grad_norm": 0.09472476691007614,
      "learning_rate": 1.9964285714285717e-05,
      "loss": 0.0016,
      "step": 42050
    },
    {
      "epoch": 1.2017142857142857,
      "grad_norm": 0.045969754457473755,
      "learning_rate": 1.995714285714286e-05,
      "loss": 0.0013,
      "step": 42060
    },
    {
      "epoch": 1.202,
      "grad_norm": 0.15278260409832,
      "learning_rate": 1.995e-05,
      "loss": 0.0011,
      "step": 42070
    },
    {
      "epoch": 1.2022857142857144,
      "grad_norm": 0.10333243757486343,
      "learning_rate": 1.9942857142857142e-05,
      "loss": 0.0015,
      "step": 42080
    },
    {
      "epoch": 1.2025714285714286,
      "grad_norm": 0.09496479481458664,
      "learning_rate": 1.9935714285714284e-05,
      "loss": 0.001,
      "step": 42090
    },
    {
      "epoch": 1.2028571428571428,
      "grad_norm": 0.04525510594248772,
      "learning_rate": 1.992857142857143e-05,
      "loss": 0.0014,
      "step": 42100
    },
    {
      "epoch": 1.203142857142857,
      "grad_norm": 0.046122584491968155,
      "learning_rate": 1.992142857142857e-05,
      "loss": 0.0014,
      "step": 42110
    },
    {
      "epoch": 1.2034285714285715,
      "grad_norm": 0.046303655952215195,
      "learning_rate": 1.9914285714285716e-05,
      "loss": 0.0011,
      "step": 42120
    },
    {
      "epoch": 1.2037142857142857,
      "grad_norm": 0.24153347313404083,
      "learning_rate": 1.9907142857142857e-05,
      "loss": 0.0013,
      "step": 42130
    },
    {
      "epoch": 1.204,
      "grad_norm": 0.10953083634376526,
      "learning_rate": 1.9900000000000003e-05,
      "loss": 0.0004,
      "step": 42140
    },
    {
      "epoch": 1.2042857142857142,
      "grad_norm": 0.0,
      "learning_rate": 1.9892857142857144e-05,
      "loss": 0.0005,
      "step": 42150
    },
    {
      "epoch": 1.2045714285714286,
      "grad_norm": 0.04167092591524124,
      "learning_rate": 1.9885714285714286e-05,
      "loss": 0.0005,
      "step": 42160
    },
    {
      "epoch": 1.2048571428571428,
      "grad_norm": 0.03349594399333,
      "learning_rate": 1.987857142857143e-05,
      "loss": 0.0008,
      "step": 42170
    },
    {
      "epoch": 1.205142857142857,
      "grad_norm": 0.3058454096317291,
      "learning_rate": 1.9871428571428573e-05,
      "loss": 0.0015,
      "step": 42180
    },
    {
      "epoch": 1.2054285714285715,
      "grad_norm": 0.09748845547437668,
      "learning_rate": 1.9864285714285715e-05,
      "loss": 0.0022,
      "step": 42190
    },
    {
      "epoch": 1.2057142857142857,
      "grad_norm": 0.01803591661155224,
      "learning_rate": 1.9857142857142856e-05,
      "loss": 0.001,
      "step": 42200
    },
    {
      "epoch": 1.206,
      "grad_norm": 0.1439095288515091,
      "learning_rate": 1.985e-05,
      "loss": 0.0009,
      "step": 42210
    },
    {
      "epoch": 1.2062857142857144,
      "grad_norm": 0.04299616068601608,
      "learning_rate": 1.9842857142857143e-05,
      "loss": 0.0004,
      "step": 42220
    },
    {
      "epoch": 1.2065714285714286,
      "grad_norm": 0.0,
      "learning_rate": 1.9835714285714288e-05,
      "loss": 0.0018,
      "step": 42230
    },
    {
      "epoch": 1.2068571428571429,
      "grad_norm": 0.0,
      "learning_rate": 1.982857142857143e-05,
      "loss": 0.001,
      "step": 42240
    },
    {
      "epoch": 1.207142857142857,
      "grad_norm": 0.10583958774805069,
      "learning_rate": 1.982142857142857e-05,
      "loss": 0.0014,
      "step": 42250
    },
    {
      "epoch": 1.2074285714285715,
      "grad_norm": 0.04799862951040268,
      "learning_rate": 1.9814285714285717e-05,
      "loss": 0.0014,
      "step": 42260
    },
    {
      "epoch": 1.2077142857142857,
      "grad_norm": 0.09181918948888779,
      "learning_rate": 1.980714285714286e-05,
      "loss": 0.0006,
      "step": 42270
    },
    {
      "epoch": 1.208,
      "grad_norm": 0.08478599786758423,
      "learning_rate": 1.9800000000000004e-05,
      "loss": 0.0013,
      "step": 42280
    },
    {
      "epoch": 1.2082857142857142,
      "grad_norm": 0.11630991846323013,
      "learning_rate": 1.9792857142857142e-05,
      "loss": 0.001,
      "step": 42290
    },
    {
      "epoch": 1.2085714285714286,
      "grad_norm": 0.05288266763091087,
      "learning_rate": 1.9785714285714287e-05,
      "loss": 0.0012,
      "step": 42300
    },
    {
      "epoch": 1.2088571428571429,
      "grad_norm": 0.05343541130423546,
      "learning_rate": 1.977857142857143e-05,
      "loss": 0.001,
      "step": 42310
    },
    {
      "epoch": 1.209142857142857,
      "grad_norm": 0.041019950062036514,
      "learning_rate": 1.977142857142857e-05,
      "loss": 0.0009,
      "step": 42320
    },
    {
      "epoch": 1.2094285714285715,
      "grad_norm": 0.0,
      "learning_rate": 1.9764285714285716e-05,
      "loss": 0.001,
      "step": 42330
    },
    {
      "epoch": 1.2097142857142857,
      "grad_norm": 0.06859878450632095,
      "learning_rate": 1.9757142857142857e-05,
      "loss": 0.0009,
      "step": 42340
    },
    {
      "epoch": 1.21,
      "grad_norm": 0.04693185165524483,
      "learning_rate": 1.9750000000000002e-05,
      "loss": 0.0016,
      "step": 42350
    },
    {
      "epoch": 1.2102857142857144,
      "grad_norm": 0.21105130016803741,
      "learning_rate": 1.9742857142857144e-05,
      "loss": 0.0014,
      "step": 42360
    },
    {
      "epoch": 1.2105714285714286,
      "grad_norm": 0.4882684648036957,
      "learning_rate": 1.973571428571429e-05,
      "loss": 0.0014,
      "step": 42370
    },
    {
      "epoch": 1.2108571428571429,
      "grad_norm": 0.45446276664733887,
      "learning_rate": 1.972857142857143e-05,
      "loss": 0.0012,
      "step": 42380
    },
    {
      "epoch": 1.211142857142857,
      "grad_norm": 0.40252161026000977,
      "learning_rate": 1.9721428571428573e-05,
      "loss": 0.0016,
      "step": 42390
    },
    {
      "epoch": 1.2114285714285715,
      "grad_norm": 0.11302392184734344,
      "learning_rate": 1.9714285714285714e-05,
      "loss": 0.0012,
      "step": 42400
    },
    {
      "epoch": 1.2117142857142857,
      "grad_norm": 0.0,
      "learning_rate": 1.9707142857142856e-05,
      "loss": 0.0024,
      "step": 42410
    },
    {
      "epoch": 1.212,
      "grad_norm": 0.3952884376049042,
      "learning_rate": 1.97e-05,
      "loss": 0.0017,
      "step": 42420
    },
    {
      "epoch": 1.2122857142857142,
      "grad_norm": 0.08475865423679352,
      "learning_rate": 1.9692857142857143e-05,
      "loss": 0.0006,
      "step": 42430
    },
    {
      "epoch": 1.2125714285714286,
      "grad_norm": 0.20493267476558685,
      "learning_rate": 1.9685714285714288e-05,
      "loss": 0.0009,
      "step": 42440
    },
    {
      "epoch": 1.2128571428571429,
      "grad_norm": 0.03471197560429573,
      "learning_rate": 1.967857142857143e-05,
      "loss": 0.0009,
      "step": 42450
    },
    {
      "epoch": 1.213142857142857,
      "grad_norm": 0.0,
      "learning_rate": 1.967142857142857e-05,
      "loss": 0.0013,
      "step": 42460
    },
    {
      "epoch": 1.2134285714285715,
      "grad_norm": 0.03460940346121788,
      "learning_rate": 1.9664285714285716e-05,
      "loss": 0.0021,
      "step": 42470
    },
    {
      "epoch": 1.2137142857142857,
      "grad_norm": 0.04098990559577942,
      "learning_rate": 1.9657142857142858e-05,
      "loss": 0.0006,
      "step": 42480
    },
    {
      "epoch": 1.214,
      "grad_norm": 0.0,
      "learning_rate": 1.9650000000000003e-05,
      "loss": 0.0003,
      "step": 42490
    },
    {
      "epoch": 1.2142857142857142,
      "grad_norm": 0.041670698672533035,
      "learning_rate": 1.9642857142857145e-05,
      "loss": 0.001,
      "step": 42500
    },
    {
      "epoch": 1.2145714285714286,
      "grad_norm": 0.04179048910737038,
      "learning_rate": 1.9635714285714287e-05,
      "loss": 0.0017,
      "step": 42510
    },
    {
      "epoch": 1.2148571428571429,
      "grad_norm": 0.0,
      "learning_rate": 1.962857142857143e-05,
      "loss": 0.0009,
      "step": 42520
    },
    {
      "epoch": 1.215142857142857,
      "grad_norm": 0.041181255131959915,
      "learning_rate": 1.962142857142857e-05,
      "loss": 0.0024,
      "step": 42530
    },
    {
      "epoch": 1.2154285714285715,
      "grad_norm": 0.26213449239730835,
      "learning_rate": 1.9614285714285715e-05,
      "loss": 0.0012,
      "step": 42540
    },
    {
      "epoch": 1.2157142857142857,
      "grad_norm": 0.13190463185310364,
      "learning_rate": 1.9607142857142857e-05,
      "loss": 0.0012,
      "step": 42550
    },
    {
      "epoch": 1.216,
      "grad_norm": 0.11729443818330765,
      "learning_rate": 1.9600000000000002e-05,
      "loss": 0.0025,
      "step": 42560
    },
    {
      "epoch": 1.2162857142857142,
      "grad_norm": 0.08246991783380508,
      "learning_rate": 1.9592857142857144e-05,
      "loss": 0.0007,
      "step": 42570
    },
    {
      "epoch": 1.2165714285714286,
      "grad_norm": 0.0403418093919754,
      "learning_rate": 1.958571428571429e-05,
      "loss": 0.0015,
      "step": 42580
    },
    {
      "epoch": 1.2168571428571429,
      "grad_norm": 0.08409073948860168,
      "learning_rate": 1.957857142857143e-05,
      "loss": 0.0014,
      "step": 42590
    },
    {
      "epoch": 1.217142857142857,
      "grad_norm": 0.05009881407022476,
      "learning_rate": 1.9571428571428572e-05,
      "loss": 0.001,
      "step": 42600
    },
    {
      "epoch": 1.2174285714285715,
      "grad_norm": 0.051025327295064926,
      "learning_rate": 1.9564285714285714e-05,
      "loss": 0.0024,
      "step": 42610
    },
    {
      "epoch": 1.2177142857142857,
      "grad_norm": 0.0,
      "learning_rate": 1.9557142857142856e-05,
      "loss": 0.0009,
      "step": 42620
    },
    {
      "epoch": 1.218,
      "grad_norm": 0.24114690721035004,
      "learning_rate": 1.955e-05,
      "loss": 0.0006,
      "step": 42630
    },
    {
      "epoch": 1.2182857142857142,
      "grad_norm": 0.0564824715256691,
      "learning_rate": 1.9542857142857143e-05,
      "loss": 0.001,
      "step": 42640
    },
    {
      "epoch": 1.2185714285714286,
      "grad_norm": 0.22782930731773376,
      "learning_rate": 1.9535714285714288e-05,
      "loss": 0.0006,
      "step": 42650
    },
    {
      "epoch": 1.2188571428571429,
      "grad_norm": 0.13430152833461761,
      "learning_rate": 1.952857142857143e-05,
      "loss": 0.0023,
      "step": 42660
    },
    {
      "epoch": 1.219142857142857,
      "grad_norm": 0.038525789976119995,
      "learning_rate": 1.952142857142857e-05,
      "loss": 0.0008,
      "step": 42670
    },
    {
      "epoch": 1.2194285714285713,
      "grad_norm": 0.23785685002803802,
      "learning_rate": 1.9514285714285716e-05,
      "loss": 0.0015,
      "step": 42680
    },
    {
      "epoch": 1.2197142857142858,
      "grad_norm": 0.0,
      "learning_rate": 1.9507142857142858e-05,
      "loss": 0.0007,
      "step": 42690
    },
    {
      "epoch": 1.22,
      "grad_norm": 0.04339218512177467,
      "learning_rate": 1.9500000000000003e-05,
      "loss": 0.0004,
      "step": 42700
    },
    {
      "epoch": 1.2202857142857142,
      "grad_norm": 0.21073174476623535,
      "learning_rate": 1.9492857142857145e-05,
      "loss": 0.0019,
      "step": 42710
    },
    {
      "epoch": 1.2205714285714286,
      "grad_norm": 0.04555254429578781,
      "learning_rate": 1.9485714285714286e-05,
      "loss": 0.0012,
      "step": 42720
    },
    {
      "epoch": 1.2208571428571429,
      "grad_norm": 0.03157180920243263,
      "learning_rate": 1.9478571428571428e-05,
      "loss": 0.0011,
      "step": 42730
    },
    {
      "epoch": 1.221142857142857,
      "grad_norm": 0.04539377987384796,
      "learning_rate": 1.947142857142857e-05,
      "loss": 0.0014,
      "step": 42740
    },
    {
      "epoch": 1.2214285714285715,
      "grad_norm": 0.11047934740781784,
      "learning_rate": 1.9464285714285715e-05,
      "loss": 0.0007,
      "step": 42750
    },
    {
      "epoch": 1.2217142857142858,
      "grad_norm": 0.0,
      "learning_rate": 1.9457142857142857e-05,
      "loss": 0.0013,
      "step": 42760
    },
    {
      "epoch": 1.222,
      "grad_norm": 0.09520377963781357,
      "learning_rate": 1.9450000000000002e-05,
      "loss": 0.0014,
      "step": 42770
    },
    {
      "epoch": 1.2222857142857142,
      "grad_norm": 0.0760413110256195,
      "learning_rate": 1.9442857142857144e-05,
      "loss": 0.0015,
      "step": 42780
    },
    {
      "epoch": 1.2225714285714286,
      "grad_norm": 0.029971063137054443,
      "learning_rate": 1.943571428571429e-05,
      "loss": 0.0012,
      "step": 42790
    },
    {
      "epoch": 1.2228571428571429,
      "grad_norm": 0.0,
      "learning_rate": 1.942857142857143e-05,
      "loss": 0.0007,
      "step": 42800
    },
    {
      "epoch": 1.223142857142857,
      "grad_norm": 0.21402719616889954,
      "learning_rate": 1.9421428571428572e-05,
      "loss": 0.0018,
      "step": 42810
    },
    {
      "epoch": 1.2234285714285713,
      "grad_norm": 0.04263143613934517,
      "learning_rate": 1.9414285714285714e-05,
      "loss": 0.0013,
      "step": 42820
    },
    {
      "epoch": 1.2237142857142858,
      "grad_norm": 0.05155804008245468,
      "learning_rate": 1.9407142857142856e-05,
      "loss": 0.0015,
      "step": 42830
    },
    {
      "epoch": 1.224,
      "grad_norm": 0.4405117630958557,
      "learning_rate": 1.94e-05,
      "loss": 0.0031,
      "step": 42840
    },
    {
      "epoch": 1.2242857142857142,
      "grad_norm": 0.0,
      "learning_rate": 1.9392857142857142e-05,
      "loss": 0.0006,
      "step": 42850
    },
    {
      "epoch": 1.2245714285714286,
      "grad_norm": 0.09132260829210281,
      "learning_rate": 1.9385714285714287e-05,
      "loss": 0.0021,
      "step": 42860
    },
    {
      "epoch": 1.2248571428571429,
      "grad_norm": 0.04432284086942673,
      "learning_rate": 1.937857142857143e-05,
      "loss": 0.0015,
      "step": 42870
    },
    {
      "epoch": 1.225142857142857,
      "grad_norm": 0.02864687889814377,
      "learning_rate": 1.9371428571428574e-05,
      "loss": 0.0015,
      "step": 42880
    },
    {
      "epoch": 1.2254285714285715,
      "grad_norm": 0.19370701909065247,
      "learning_rate": 1.9364285714285716e-05,
      "loss": 0.0016,
      "step": 42890
    },
    {
      "epoch": 1.2257142857142858,
      "grad_norm": 0.04153178632259369,
      "learning_rate": 1.9357142857142858e-05,
      "loss": 0.0011,
      "step": 42900
    },
    {
      "epoch": 1.226,
      "grad_norm": 0.0406959243118763,
      "learning_rate": 1.9350000000000003e-05,
      "loss": 0.0008,
      "step": 42910
    },
    {
      "epoch": 1.2262857142857142,
      "grad_norm": 0.04982512816786766,
      "learning_rate": 1.9342857142857144e-05,
      "loss": 0.0012,
      "step": 42920
    },
    {
      "epoch": 1.2265714285714286,
      "grad_norm": 0.0,
      "learning_rate": 1.9335714285714286e-05,
      "loss": 0.0007,
      "step": 42930
    },
    {
      "epoch": 1.2268571428571429,
      "grad_norm": 0.15884023904800415,
      "learning_rate": 1.9328571428571428e-05,
      "loss": 0.0015,
      "step": 42940
    },
    {
      "epoch": 1.227142857142857,
      "grad_norm": 0.09382879734039307,
      "learning_rate": 1.9321428571428573e-05,
      "loss": 0.0015,
      "step": 42950
    },
    {
      "epoch": 1.2274285714285713,
      "grad_norm": 0.12501142919063568,
      "learning_rate": 1.9314285714285715e-05,
      "loss": 0.0018,
      "step": 42960
    },
    {
      "epoch": 1.2277142857142858,
      "grad_norm": 0.08756723999977112,
      "learning_rate": 1.9307142857142856e-05,
      "loss": 0.0016,
      "step": 42970
    },
    {
      "epoch": 1.228,
      "grad_norm": 0.2545517385005951,
      "learning_rate": 1.93e-05,
      "loss": 0.0015,
      "step": 42980
    },
    {
      "epoch": 1.2282857142857142,
      "grad_norm": 0.043106961995363235,
      "learning_rate": 1.9292857142857143e-05,
      "loss": 0.0011,
      "step": 42990
    },
    {
      "epoch": 1.2285714285714286,
      "grad_norm": 0.0,
      "learning_rate": 1.928571428571429e-05,
      "loss": 0.0004,
      "step": 43000
    },
    {
      "epoch": 1.2288571428571429,
      "grad_norm": 0.0473405122756958,
      "learning_rate": 1.927857142857143e-05,
      "loss": 0.0015,
      "step": 43010
    },
    {
      "epoch": 1.229142857142857,
      "grad_norm": 0.20350968837738037,
      "learning_rate": 1.9271428571428575e-05,
      "loss": 0.0017,
      "step": 43020
    },
    {
      "epoch": 1.2294285714285715,
      "grad_norm": 0.07322647422552109,
      "learning_rate": 1.9264285714285717e-05,
      "loss": 0.0015,
      "step": 43030
    },
    {
      "epoch": 1.2297142857142858,
      "grad_norm": 0.0,
      "learning_rate": 1.9257142857142855e-05,
      "loss": 0.0017,
      "step": 43040
    },
    {
      "epoch": 1.23,
      "grad_norm": 0.0,
      "learning_rate": 1.925e-05,
      "loss": 0.0017,
      "step": 43050
    },
    {
      "epoch": 1.2302857142857142,
      "grad_norm": 0.2914900481700897,
      "learning_rate": 1.9242857142857142e-05,
      "loss": 0.0016,
      "step": 43060
    },
    {
      "epoch": 1.2305714285714286,
      "grad_norm": 0.08770813047885895,
      "learning_rate": 1.9235714285714287e-05,
      "loss": 0.0018,
      "step": 43070
    },
    {
      "epoch": 1.2308571428571429,
      "grad_norm": 0.13248521089553833,
      "learning_rate": 1.922857142857143e-05,
      "loss": 0.0013,
      "step": 43080
    },
    {
      "epoch": 1.231142857142857,
      "grad_norm": 0.10853907465934753,
      "learning_rate": 1.9221428571428574e-05,
      "loss": 0.0008,
      "step": 43090
    },
    {
      "epoch": 1.2314285714285713,
      "grad_norm": 0.06612750142812729,
      "learning_rate": 1.9214285714285716e-05,
      "loss": 0.0015,
      "step": 43100
    },
    {
      "epoch": 1.2317142857142858,
      "grad_norm": 0.04166712984442711,
      "learning_rate": 1.9207142857142857e-05,
      "loss": 0.0006,
      "step": 43110
    },
    {
      "epoch": 1.232,
      "grad_norm": 0.11384788900613785,
      "learning_rate": 1.9200000000000003e-05,
      "loss": 0.0023,
      "step": 43120
    },
    {
      "epoch": 1.2322857142857142,
      "grad_norm": 0.03262803331017494,
      "learning_rate": 1.9192857142857144e-05,
      "loss": 0.0006,
      "step": 43130
    },
    {
      "epoch": 1.2325714285714287,
      "grad_norm": 0.07313994318246841,
      "learning_rate": 1.9185714285714286e-05,
      "loss": 0.0008,
      "step": 43140
    },
    {
      "epoch": 1.2328571428571429,
      "grad_norm": 0.22009989619255066,
      "learning_rate": 1.9178571428571428e-05,
      "loss": 0.0008,
      "step": 43150
    },
    {
      "epoch": 1.233142857142857,
      "grad_norm": 0.053758762776851654,
      "learning_rate": 1.9171428571428573e-05,
      "loss": 0.0008,
      "step": 43160
    },
    {
      "epoch": 1.2334285714285715,
      "grad_norm": 0.2381153106689453,
      "learning_rate": 1.9164285714285714e-05,
      "loss": 0.0006,
      "step": 43170
    },
    {
      "epoch": 1.2337142857142858,
      "grad_norm": 0.08996029198169708,
      "learning_rate": 1.9157142857142856e-05,
      "loss": 0.001,
      "step": 43180
    },
    {
      "epoch": 1.234,
      "grad_norm": 0.058157794177532196,
      "learning_rate": 1.915e-05,
      "loss": 0.0009,
      "step": 43190
    },
    {
      "epoch": 1.2342857142857142,
      "grad_norm": 0.0,
      "learning_rate": 1.9142857142857143e-05,
      "loss": 0.0008,
      "step": 43200
    },
    {
      "epoch": 1.2345714285714287,
      "grad_norm": 0.04465707764029503,
      "learning_rate": 1.9135714285714288e-05,
      "loss": 0.0022,
      "step": 43210
    },
    {
      "epoch": 1.2348571428571429,
      "grad_norm": 0.04262769594788551,
      "learning_rate": 1.912857142857143e-05,
      "loss": 0.001,
      "step": 43220
    },
    {
      "epoch": 1.235142857142857,
      "grad_norm": 0.0,
      "learning_rate": 1.9121428571428575e-05,
      "loss": 0.0008,
      "step": 43230
    },
    {
      "epoch": 1.2354285714285713,
      "grad_norm": 0.05033669248223305,
      "learning_rate": 1.9114285714285717e-05,
      "loss": 0.0012,
      "step": 43240
    },
    {
      "epoch": 1.2357142857142858,
      "grad_norm": 0.0,
      "learning_rate": 1.910714285714286e-05,
      "loss": 0.0026,
      "step": 43250
    },
    {
      "epoch": 1.236,
      "grad_norm": 0.0,
      "learning_rate": 1.91e-05,
      "loss": 0.0018,
      "step": 43260
    },
    {
      "epoch": 1.2362857142857142,
      "grad_norm": 0.04763542488217354,
      "learning_rate": 1.9092857142857142e-05,
      "loss": 0.0013,
      "step": 43270
    },
    {
      "epoch": 1.2365714285714287,
      "grad_norm": 0.0,
      "learning_rate": 1.9085714285714287e-05,
      "loss": 0.0007,
      "step": 43280
    },
    {
      "epoch": 1.2368571428571429,
      "grad_norm": 0.0,
      "learning_rate": 1.907857142857143e-05,
      "loss": 0.0015,
      "step": 43290
    },
    {
      "epoch": 1.237142857142857,
      "grad_norm": 0.13783521950244904,
      "learning_rate": 1.9071428571428574e-05,
      "loss": 0.0015,
      "step": 43300
    },
    {
      "epoch": 1.2374285714285715,
      "grad_norm": 0.16508419811725616,
      "learning_rate": 1.9064285714285715e-05,
      "loss": 0.0013,
      "step": 43310
    },
    {
      "epoch": 1.2377142857142858,
      "grad_norm": 0.0,
      "learning_rate": 1.9057142857142857e-05,
      "loss": 0.0009,
      "step": 43320
    },
    {
      "epoch": 1.238,
      "grad_norm": 0.05146120488643646,
      "learning_rate": 1.9050000000000002e-05,
      "loss": 0.0017,
      "step": 43330
    },
    {
      "epoch": 1.2382857142857142,
      "grad_norm": 0.0,
      "learning_rate": 1.9042857142857144e-05,
      "loss": 0.0025,
      "step": 43340
    },
    {
      "epoch": 1.2385714285714287,
      "grad_norm": 0.05131902918219566,
      "learning_rate": 1.9035714285714286e-05,
      "loss": 0.001,
      "step": 43350
    },
    {
      "epoch": 1.2388571428571429,
      "grad_norm": 0.026164351031184196,
      "learning_rate": 1.9028571428571427e-05,
      "loss": 0.0017,
      "step": 43360
    },
    {
      "epoch": 1.239142857142857,
      "grad_norm": 0.04875775799155235,
      "learning_rate": 1.9021428571428573e-05,
      "loss": 0.0013,
      "step": 43370
    },
    {
      "epoch": 1.2394285714285713,
      "grad_norm": 0.04777183383703232,
      "learning_rate": 1.9014285714285714e-05,
      "loss": 0.0013,
      "step": 43380
    },
    {
      "epoch": 1.2397142857142858,
      "grad_norm": 0.0,
      "learning_rate": 1.9007142857142856e-05,
      "loss": 0.0015,
      "step": 43390
    },
    {
      "epoch": 1.24,
      "grad_norm": 0.06744953989982605,
      "learning_rate": 1.9e-05,
      "loss": 0.0014,
      "step": 43400
    },
    {
      "epoch": 1.2402857142857142,
      "grad_norm": 0.16092053055763245,
      "learning_rate": 1.8992857142857143e-05,
      "loss": 0.0008,
      "step": 43410
    },
    {
      "epoch": 1.2405714285714287,
      "grad_norm": 0.12029077857732773,
      "learning_rate": 1.8985714285714288e-05,
      "loss": 0.0016,
      "step": 43420
    },
    {
      "epoch": 1.2408571428571429,
      "grad_norm": 0.04713460057973862,
      "learning_rate": 1.897857142857143e-05,
      "loss": 0.0015,
      "step": 43430
    },
    {
      "epoch": 1.241142857142857,
      "grad_norm": 0.1857881247997284,
      "learning_rate": 1.8971428571428575e-05,
      "loss": 0.0019,
      "step": 43440
    },
    {
      "epoch": 1.2414285714285715,
      "grad_norm": 0.06278377771377563,
      "learning_rate": 1.8964285714285716e-05,
      "loss": 0.0012,
      "step": 43450
    },
    {
      "epoch": 1.2417142857142858,
      "grad_norm": 0.04799016937613487,
      "learning_rate": 1.8957142857142858e-05,
      "loss": 0.0015,
      "step": 43460
    },
    {
      "epoch": 1.242,
      "grad_norm": 0.06022286415100098,
      "learning_rate": 1.895e-05,
      "loss": 0.0011,
      "step": 43470
    },
    {
      "epoch": 1.2422857142857142,
      "grad_norm": 0.04682468995451927,
      "learning_rate": 1.894285714285714e-05,
      "loss": 0.0012,
      "step": 43480
    },
    {
      "epoch": 1.2425714285714287,
      "grad_norm": 0.0,
      "learning_rate": 1.8935714285714287e-05,
      "loss": 0.0015,
      "step": 43490
    },
    {
      "epoch": 1.2428571428571429,
      "grad_norm": 0.08010895550251007,
      "learning_rate": 1.892857142857143e-05,
      "loss": 0.001,
      "step": 43500
    },
    {
      "epoch": 1.243142857142857,
      "grad_norm": 0.047477129846811295,
      "learning_rate": 1.8921428571428573e-05,
      "loss": 0.0012,
      "step": 43510
    },
    {
      "epoch": 1.2434285714285713,
      "grad_norm": 0.06012412905693054,
      "learning_rate": 1.8914285714285715e-05,
      "loss": 0.0007,
      "step": 43520
    },
    {
      "epoch": 1.2437142857142858,
      "grad_norm": 0.03852295130491257,
      "learning_rate": 1.890714285714286e-05,
      "loss": 0.0012,
      "step": 43530
    },
    {
      "epoch": 1.244,
      "grad_norm": 0.0,
      "learning_rate": 1.8900000000000002e-05,
      "loss": 0.0016,
      "step": 43540
    },
    {
      "epoch": 1.2442857142857142,
      "grad_norm": 0.05009214207530022,
      "learning_rate": 1.8892857142857144e-05,
      "loss": 0.0016,
      "step": 43550
    },
    {
      "epoch": 1.2445714285714287,
      "grad_norm": 0.30722612142562866,
      "learning_rate": 1.888571428571429e-05,
      "loss": 0.0011,
      "step": 43560
    },
    {
      "epoch": 1.2448571428571429,
      "grad_norm": 0.12118075042963028,
      "learning_rate": 1.8878571428571427e-05,
      "loss": 0.0017,
      "step": 43570
    },
    {
      "epoch": 1.245142857142857,
      "grad_norm": 0.09186173975467682,
      "learning_rate": 1.8871428571428572e-05,
      "loss": 0.0015,
      "step": 43580
    },
    {
      "epoch": 1.2454285714285716,
      "grad_norm": 0.07102357596158981,
      "learning_rate": 1.8864285714285714e-05,
      "loss": 0.0006,
      "step": 43590
    },
    {
      "epoch": 1.2457142857142858,
      "grad_norm": 0.046678267419338226,
      "learning_rate": 1.885714285714286e-05,
      "loss": 0.0003,
      "step": 43600
    },
    {
      "epoch": 1.246,
      "grad_norm": 0.05698182061314583,
      "learning_rate": 1.885e-05,
      "loss": 0.0015,
      "step": 43610
    },
    {
      "epoch": 1.2462857142857142,
      "grad_norm": 0.04721340537071228,
      "learning_rate": 1.8842857142857143e-05,
      "loss": 0.001,
      "step": 43620
    },
    {
      "epoch": 1.2465714285714287,
      "grad_norm": 0.04383100941777229,
      "learning_rate": 1.8835714285714288e-05,
      "loss": 0.0021,
      "step": 43630
    },
    {
      "epoch": 1.2468571428571429,
      "grad_norm": 0.03306940570473671,
      "learning_rate": 1.882857142857143e-05,
      "loss": 0.0014,
      "step": 43640
    },
    {
      "epoch": 1.247142857142857,
      "grad_norm": 0.046676572412252426,
      "learning_rate": 1.8821428571428574e-05,
      "loss": 0.0019,
      "step": 43650
    },
    {
      "epoch": 1.2474285714285713,
      "grad_norm": 0.04897738993167877,
      "learning_rate": 1.8814285714285716e-05,
      "loss": 0.0009,
      "step": 43660
    },
    {
      "epoch": 1.2477142857142858,
      "grad_norm": 0.1647985279560089,
      "learning_rate": 1.8807142857142858e-05,
      "loss": 0.0019,
      "step": 43670
    },
    {
      "epoch": 1.248,
      "grad_norm": 0.04339797422289848,
      "learning_rate": 1.88e-05,
      "loss": 0.002,
      "step": 43680
    },
    {
      "epoch": 1.2482857142857142,
      "grad_norm": 0.1465553641319275,
      "learning_rate": 1.879285714285714e-05,
      "loss": 0.0011,
      "step": 43690
    },
    {
      "epoch": 1.2485714285714287,
      "grad_norm": 0.04206843301653862,
      "learning_rate": 1.8785714285714286e-05,
      "loss": 0.0009,
      "step": 43700
    },
    {
      "epoch": 1.2488571428571429,
      "grad_norm": 0.08852626383304596,
      "learning_rate": 1.8778571428571428e-05,
      "loss": 0.0012,
      "step": 43710
    },
    {
      "epoch": 1.249142857142857,
      "grad_norm": 0.02843300625681877,
      "learning_rate": 1.8771428571428573e-05,
      "loss": 0.0007,
      "step": 43720
    },
    {
      "epoch": 1.2494285714285713,
      "grad_norm": 0.047114428132772446,
      "learning_rate": 1.8764285714285715e-05,
      "loss": 0.001,
      "step": 43730
    },
    {
      "epoch": 1.2497142857142858,
      "grad_norm": 0.2467212677001953,
      "learning_rate": 1.875714285714286e-05,
      "loss": 0.0013,
      "step": 43740
    },
    {
      "epoch": 1.25,
      "grad_norm": 0.1541970819234848,
      "learning_rate": 1.8750000000000002e-05,
      "loss": 0.0008,
      "step": 43750
    },
    {
      "epoch": 1.2502857142857142,
      "grad_norm": 0.0,
      "learning_rate": 1.8742857142857143e-05,
      "loss": 0.0009,
      "step": 43760
    },
    {
      "epoch": 1.2505714285714284,
      "grad_norm": 0.041881151497364044,
      "learning_rate": 1.873571428571429e-05,
      "loss": 0.0011,
      "step": 43770
    },
    {
      "epoch": 1.250857142857143,
      "grad_norm": 0.04490188881754875,
      "learning_rate": 1.872857142857143e-05,
      "loss": 0.0008,
      "step": 43780
    },
    {
      "epoch": 1.2511428571428571,
      "grad_norm": 0.1093909740447998,
      "learning_rate": 1.8721428571428572e-05,
      "loss": 0.0013,
      "step": 43790
    },
    {
      "epoch": 1.2514285714285713,
      "grad_norm": 0.12231173366308212,
      "learning_rate": 1.8714285714285714e-05,
      "loss": 0.0016,
      "step": 43800
    },
    {
      "epoch": 1.2517142857142858,
      "grad_norm": 0.0,
      "learning_rate": 1.870714285714286e-05,
      "loss": 0.0003,
      "step": 43810
    },
    {
      "epoch": 1.252,
      "grad_norm": 0.0,
      "learning_rate": 1.87e-05,
      "loss": 0.0009,
      "step": 43820
    },
    {
      "epoch": 1.2522857142857142,
      "grad_norm": 0.04814640432596207,
      "learning_rate": 1.8692857142857142e-05,
      "loss": 0.0011,
      "step": 43830
    },
    {
      "epoch": 1.2525714285714287,
      "grad_norm": 0.03165452927350998,
      "learning_rate": 1.8685714285714287e-05,
      "loss": 0.0006,
      "step": 43840
    },
    {
      "epoch": 1.252857142857143,
      "grad_norm": 0.33359017968177795,
      "learning_rate": 1.867857142857143e-05,
      "loss": 0.0028,
      "step": 43850
    },
    {
      "epoch": 1.2531428571428571,
      "grad_norm": 0.0,
      "learning_rate": 1.8671428571428574e-05,
      "loss": 0.0007,
      "step": 43860
    },
    {
      "epoch": 1.2534285714285716,
      "grad_norm": 0.04521981254220009,
      "learning_rate": 1.8664285714285716e-05,
      "loss": 0.0016,
      "step": 43870
    },
    {
      "epoch": 1.2537142857142858,
      "grad_norm": 0.09104546904563904,
      "learning_rate": 1.8657142857142858e-05,
      "loss": 0.0012,
      "step": 43880
    },
    {
      "epoch": 1.254,
      "grad_norm": 0.10415047407150269,
      "learning_rate": 1.865e-05,
      "loss": 0.002,
      "step": 43890
    },
    {
      "epoch": 1.2542857142857142,
      "grad_norm": 0.043884579092264175,
      "learning_rate": 1.864285714285714e-05,
      "loss": 0.002,
      "step": 43900
    },
    {
      "epoch": 1.2545714285714284,
      "grad_norm": 0.03084961697459221,
      "learning_rate": 1.8635714285714286e-05,
      "loss": 0.0019,
      "step": 43910
    },
    {
      "epoch": 1.254857142857143,
      "grad_norm": 0.2816501259803772,
      "learning_rate": 1.8628571428571428e-05,
      "loss": 0.0011,
      "step": 43920
    },
    {
      "epoch": 1.2551428571428571,
      "grad_norm": 0.07086346298456192,
      "learning_rate": 1.8621428571428573e-05,
      "loss": 0.0011,
      "step": 43930
    },
    {
      "epoch": 1.2554285714285713,
      "grad_norm": 0.052119798958301544,
      "learning_rate": 1.8614285714285715e-05,
      "loss": 0.0007,
      "step": 43940
    },
    {
      "epoch": 1.2557142857142858,
      "grad_norm": 0.08168055862188339,
      "learning_rate": 1.860714285714286e-05,
      "loss": 0.0019,
      "step": 43950
    },
    {
      "epoch": 1.256,
      "grad_norm": 0.04058127477765083,
      "learning_rate": 1.86e-05,
      "loss": 0.0012,
      "step": 43960
    },
    {
      "epoch": 1.2562857142857142,
      "grad_norm": 0.15575620532035828,
      "learning_rate": 1.8592857142857143e-05,
      "loss": 0.0023,
      "step": 43970
    },
    {
      "epoch": 1.2565714285714287,
      "grad_norm": 0.0,
      "learning_rate": 1.858571428571429e-05,
      "loss": 0.0004,
      "step": 43980
    },
    {
      "epoch": 1.256857142857143,
      "grad_norm": 0.0,
      "learning_rate": 1.857857142857143e-05,
      "loss": 0.0012,
      "step": 43990
    },
    {
      "epoch": 1.2571428571428571,
      "grad_norm": 0.0,
      "learning_rate": 1.8571428571428572e-05,
      "loss": 0.001,
      "step": 44000
    },
    {
      "epoch": 1.2574285714285716,
      "grad_norm": 0.08976330608129501,
      "learning_rate": 1.8564285714285713e-05,
      "loss": 0.0014,
      "step": 44010
    },
    {
      "epoch": 1.2577142857142858,
      "grad_norm": 0.04172687605023384,
      "learning_rate": 1.855714285714286e-05,
      "loss": 0.0013,
      "step": 44020
    },
    {
      "epoch": 1.258,
      "grad_norm": 0.050676725804805756,
      "learning_rate": 1.855e-05,
      "loss": 0.0018,
      "step": 44030
    },
    {
      "epoch": 1.2582857142857142,
      "grad_norm": 0.18006232380867004,
      "learning_rate": 1.8542857142857142e-05,
      "loss": 0.0011,
      "step": 44040
    },
    {
      "epoch": 1.2585714285714285,
      "grad_norm": 0.12659285962581635,
      "learning_rate": 1.8535714285714287e-05,
      "loss": 0.0003,
      "step": 44050
    },
    {
      "epoch": 1.258857142857143,
      "grad_norm": 0.2532365322113037,
      "learning_rate": 1.852857142857143e-05,
      "loss": 0.0023,
      "step": 44060
    },
    {
      "epoch": 1.2591428571428571,
      "grad_norm": 0.05352526903152466,
      "learning_rate": 1.8521428571428574e-05,
      "loss": 0.0013,
      "step": 44070
    },
    {
      "epoch": 1.2594285714285713,
      "grad_norm": 0.0458308607339859,
      "learning_rate": 1.8514285714285716e-05,
      "loss": 0.0005,
      "step": 44080
    },
    {
      "epoch": 1.2597142857142858,
      "grad_norm": 0.14443109929561615,
      "learning_rate": 1.8507142857142857e-05,
      "loss": 0.0007,
      "step": 44090
    },
    {
      "epoch": 1.26,
      "grad_norm": 0.09728182107210159,
      "learning_rate": 1.85e-05,
      "loss": 0.0018,
      "step": 44100
    },
    {
      "epoch": 1.2602857142857142,
      "grad_norm": 0.06315156072378159,
      "learning_rate": 1.8492857142857144e-05,
      "loss": 0.0012,
      "step": 44110
    },
    {
      "epoch": 1.2605714285714287,
      "grad_norm": 0.0,
      "learning_rate": 1.8485714285714286e-05,
      "loss": 0.0011,
      "step": 44120
    },
    {
      "epoch": 1.260857142857143,
      "grad_norm": 0.048630502074956894,
      "learning_rate": 1.8478571428571428e-05,
      "loss": 0.0008,
      "step": 44130
    },
    {
      "epoch": 1.2611428571428571,
      "grad_norm": 0.0,
      "learning_rate": 1.8471428571428573e-05,
      "loss": 0.0006,
      "step": 44140
    },
    {
      "epoch": 1.2614285714285716,
      "grad_norm": 0.09210259467363358,
      "learning_rate": 1.8464285714285714e-05,
      "loss": 0.001,
      "step": 44150
    },
    {
      "epoch": 1.2617142857142858,
      "grad_norm": 0.0,
      "learning_rate": 1.845714285714286e-05,
      "loss": 0.0015,
      "step": 44160
    },
    {
      "epoch": 1.262,
      "grad_norm": 0.05627705529332161,
      "learning_rate": 1.845e-05,
      "loss": 0.0014,
      "step": 44170
    },
    {
      "epoch": 1.2622857142857142,
      "grad_norm": 0.0,
      "learning_rate": 1.8442857142857146e-05,
      "loss": 0.0022,
      "step": 44180
    },
    {
      "epoch": 1.2625714285714285,
      "grad_norm": 0.05528177320957184,
      "learning_rate": 1.8435714285714288e-05,
      "loss": 0.0013,
      "step": 44190
    },
    {
      "epoch": 1.262857142857143,
      "grad_norm": 0.03963540121912956,
      "learning_rate": 1.842857142857143e-05,
      "loss": 0.002,
      "step": 44200
    },
    {
      "epoch": 1.2631428571428571,
      "grad_norm": 0.2897281050682068,
      "learning_rate": 1.842142857142857e-05,
      "loss": 0.0013,
      "step": 44210
    },
    {
      "epoch": 1.2634285714285713,
      "grad_norm": 0.09342358261346817,
      "learning_rate": 1.8414285714285713e-05,
      "loss": 0.001,
      "step": 44220
    },
    {
      "epoch": 1.2637142857142858,
      "grad_norm": 0.10962158441543579,
      "learning_rate": 1.8407142857142858e-05,
      "loss": 0.0027,
      "step": 44230
    },
    {
      "epoch": 1.264,
      "grad_norm": 0.09354212880134583,
      "learning_rate": 1.84e-05,
      "loss": 0.0007,
      "step": 44240
    },
    {
      "epoch": 1.2642857142857142,
      "grad_norm": 0.0803666040301323,
      "learning_rate": 1.8392857142857145e-05,
      "loss": 0.0007,
      "step": 44250
    },
    {
      "epoch": 1.2645714285714287,
      "grad_norm": 0.0,
      "learning_rate": 1.8385714285714287e-05,
      "loss": 0.0015,
      "step": 44260
    },
    {
      "epoch": 1.264857142857143,
      "grad_norm": 0.04669779911637306,
      "learning_rate": 1.837857142857143e-05,
      "loss": 0.0014,
      "step": 44270
    },
    {
      "epoch": 1.2651428571428571,
      "grad_norm": 0.0,
      "learning_rate": 1.8371428571428574e-05,
      "loss": 0.0017,
      "step": 44280
    },
    {
      "epoch": 1.2654285714285713,
      "grad_norm": 0.03870902955532074,
      "learning_rate": 1.8364285714285715e-05,
      "loss": 0.0017,
      "step": 44290
    },
    {
      "epoch": 1.2657142857142858,
      "grad_norm": 0.05275863781571388,
      "learning_rate": 1.835714285714286e-05,
      "loss": 0.0006,
      "step": 44300
    },
    {
      "epoch": 1.266,
      "grad_norm": 0.08130660653114319,
      "learning_rate": 1.8350000000000002e-05,
      "loss": 0.0012,
      "step": 44310
    },
    {
      "epoch": 1.2662857142857142,
      "grad_norm": 0.0,
      "learning_rate": 1.8342857142857144e-05,
      "loss": 0.0004,
      "step": 44320
    },
    {
      "epoch": 1.2665714285714285,
      "grad_norm": 0.048515934497117996,
      "learning_rate": 1.8335714285714286e-05,
      "loss": 0.0004,
      "step": 44330
    },
    {
      "epoch": 1.266857142857143,
      "grad_norm": 0.1704970747232437,
      "learning_rate": 1.8328571428571427e-05,
      "loss": 0.0005,
      "step": 44340
    },
    {
      "epoch": 1.2671428571428571,
      "grad_norm": 0.2305457592010498,
      "learning_rate": 1.8321428571428572e-05,
      "loss": 0.0018,
      "step": 44350
    },
    {
      "epoch": 1.2674285714285713,
      "grad_norm": 0.08473242819309235,
      "learning_rate": 1.8314285714285714e-05,
      "loss": 0.0015,
      "step": 44360
    },
    {
      "epoch": 1.2677142857142858,
      "grad_norm": 0.08227868378162384,
      "learning_rate": 1.830714285714286e-05,
      "loss": 0.0008,
      "step": 44370
    },
    {
      "epoch": 1.268,
      "grad_norm": 0.37455427646636963,
      "learning_rate": 1.83e-05,
      "loss": 0.0023,
      "step": 44380
    },
    {
      "epoch": 1.2682857142857142,
      "grad_norm": 0.07895810157060623,
      "learning_rate": 1.8292857142857146e-05,
      "loss": 0.0011,
      "step": 44390
    },
    {
      "epoch": 1.2685714285714287,
      "grad_norm": 0.23367762565612793,
      "learning_rate": 1.8285714285714288e-05,
      "loss": 0.0015,
      "step": 44400
    },
    {
      "epoch": 1.268857142857143,
      "grad_norm": 0.08480589091777802,
      "learning_rate": 1.827857142857143e-05,
      "loss": 0.0006,
      "step": 44410
    },
    {
      "epoch": 1.2691428571428571,
      "grad_norm": 0.08897630125284195,
      "learning_rate": 1.827142857142857e-05,
      "loss": 0.0013,
      "step": 44420
    },
    {
      "epoch": 1.2694285714285714,
      "grad_norm": 0.09379763156175613,
      "learning_rate": 1.8264285714285713e-05,
      "loss": 0.0018,
      "step": 44430
    },
    {
      "epoch": 1.2697142857142858,
      "grad_norm": 0.09720668941736221,
      "learning_rate": 1.8257142857142858e-05,
      "loss": 0.0022,
      "step": 44440
    },
    {
      "epoch": 1.27,
      "grad_norm": 0.05405885726213455,
      "learning_rate": 1.825e-05,
      "loss": 0.0015,
      "step": 44450
    },
    {
      "epoch": 1.2702857142857142,
      "grad_norm": 0.06797794997692108,
      "learning_rate": 1.8242857142857145e-05,
      "loss": 0.0016,
      "step": 44460
    },
    {
      "epoch": 1.2705714285714285,
      "grad_norm": 0.20337334275245667,
      "learning_rate": 1.8235714285714287e-05,
      "loss": 0.0013,
      "step": 44470
    },
    {
      "epoch": 1.270857142857143,
      "grad_norm": 0.18178056180477142,
      "learning_rate": 1.8228571428571428e-05,
      "loss": 0.0008,
      "step": 44480
    },
    {
      "epoch": 1.2711428571428571,
      "grad_norm": 0.0,
      "learning_rate": 1.8221428571428573e-05,
      "loss": 0.0006,
      "step": 44490
    },
    {
      "epoch": 1.2714285714285714,
      "grad_norm": 0.0,
      "learning_rate": 1.8214285714285715e-05,
      "loss": 0.0016,
      "step": 44500
    },
    {
      "epoch": 1.2717142857142858,
      "grad_norm": 0.08503210544586182,
      "learning_rate": 1.820714285714286e-05,
      "loss": 0.0012,
      "step": 44510
    },
    {
      "epoch": 1.272,
      "grad_norm": 0.0,
      "learning_rate": 1.8200000000000002e-05,
      "loss": 0.0009,
      "step": 44520
    },
    {
      "epoch": 1.2722857142857142,
      "grad_norm": 0.05638919398188591,
      "learning_rate": 1.8192857142857144e-05,
      "loss": 0.0011,
      "step": 44530
    },
    {
      "epoch": 1.2725714285714287,
      "grad_norm": 0.13832104206085205,
      "learning_rate": 1.8185714285714285e-05,
      "loss": 0.0007,
      "step": 44540
    },
    {
      "epoch": 1.272857142857143,
      "grad_norm": 0.0,
      "learning_rate": 1.8178571428571427e-05,
      "loss": 0.0015,
      "step": 44550
    },
    {
      "epoch": 1.2731428571428571,
      "grad_norm": 0.04872501268982887,
      "learning_rate": 1.8171428571428572e-05,
      "loss": 0.0012,
      "step": 44560
    },
    {
      "epoch": 1.2734285714285714,
      "grad_norm": 0.19898679852485657,
      "learning_rate": 1.8164285714285714e-05,
      "loss": 0.0018,
      "step": 44570
    },
    {
      "epoch": 1.2737142857142856,
      "grad_norm": 0.1577790379524231,
      "learning_rate": 1.815714285714286e-05,
      "loss": 0.0015,
      "step": 44580
    },
    {
      "epoch": 1.274,
      "grad_norm": 0.11375976353883743,
      "learning_rate": 1.815e-05,
      "loss": 0.0009,
      "step": 44590
    },
    {
      "epoch": 1.2742857142857142,
      "grad_norm": 0.05322541669011116,
      "learning_rate": 1.8142857142857146e-05,
      "loss": 0.0012,
      "step": 44600
    },
    {
      "epoch": 1.2745714285714285,
      "grad_norm": 0.0516035333275795,
      "learning_rate": 1.8135714285714288e-05,
      "loss": 0.0013,
      "step": 44610
    },
    {
      "epoch": 1.274857142857143,
      "grad_norm": 0.04477822035551071,
      "learning_rate": 1.812857142857143e-05,
      "loss": 0.0013,
      "step": 44620
    },
    {
      "epoch": 1.2751428571428571,
      "grad_norm": 0.08243987709283829,
      "learning_rate": 1.812142857142857e-05,
      "loss": 0.0013,
      "step": 44630
    },
    {
      "epoch": 1.2754285714285714,
      "grad_norm": 0.29842767119407654,
      "learning_rate": 1.8114285714285713e-05,
      "loss": 0.0011,
      "step": 44640
    },
    {
      "epoch": 1.2757142857142858,
      "grad_norm": 0.09430551528930664,
      "learning_rate": 1.8107142857142858e-05,
      "loss": 0.0015,
      "step": 44650
    },
    {
      "epoch": 1.276,
      "grad_norm": 0.04056202992796898,
      "learning_rate": 1.81e-05,
      "loss": 0.0011,
      "step": 44660
    },
    {
      "epoch": 1.2762857142857142,
      "grad_norm": 0.12122408300638199,
      "learning_rate": 1.8092857142857145e-05,
      "loss": 0.0018,
      "step": 44670
    },
    {
      "epoch": 1.2765714285714287,
      "grad_norm": 0.29906103014945984,
      "learning_rate": 1.8085714285714286e-05,
      "loss": 0.0016,
      "step": 44680
    },
    {
      "epoch": 1.276857142857143,
      "grad_norm": 0.12843813002109528,
      "learning_rate": 1.807857142857143e-05,
      "loss": 0.0019,
      "step": 44690
    },
    {
      "epoch": 1.2771428571428571,
      "grad_norm": 0.09374408423900604,
      "learning_rate": 1.8071428571428573e-05,
      "loss": 0.0011,
      "step": 44700
    },
    {
      "epoch": 1.2774285714285714,
      "grad_norm": 0.0,
      "learning_rate": 1.8064285714285715e-05,
      "loss": 0.0006,
      "step": 44710
    },
    {
      "epoch": 1.2777142857142856,
      "grad_norm": 0.08136656880378723,
      "learning_rate": 1.805714285714286e-05,
      "loss": 0.0013,
      "step": 44720
    },
    {
      "epoch": 1.278,
      "grad_norm": 0.12982569634914398,
      "learning_rate": 1.805e-05,
      "loss": 0.0016,
      "step": 44730
    },
    {
      "epoch": 1.2782857142857142,
      "grad_norm": 0.03629793971776962,
      "learning_rate": 1.8042857142857143e-05,
      "loss": 0.0008,
      "step": 44740
    },
    {
      "epoch": 1.2785714285714285,
      "grad_norm": 0.10479647666215897,
      "learning_rate": 1.8035714285714285e-05,
      "loss": 0.0006,
      "step": 44750
    },
    {
      "epoch": 1.278857142857143,
      "grad_norm": 0.04192885756492615,
      "learning_rate": 1.802857142857143e-05,
      "loss": 0.0006,
      "step": 44760
    },
    {
      "epoch": 1.2791428571428571,
      "grad_norm": 0.23634745180606842,
      "learning_rate": 1.8021428571428572e-05,
      "loss": 0.0011,
      "step": 44770
    },
    {
      "epoch": 1.2794285714285714,
      "grad_norm": 0.06140386313199997,
      "learning_rate": 1.8014285714285714e-05,
      "loss": 0.0014,
      "step": 44780
    },
    {
      "epoch": 1.2797142857142858,
      "grad_norm": 0.12534576654434204,
      "learning_rate": 1.800714285714286e-05,
      "loss": 0.0012,
      "step": 44790
    },
    {
      "epoch": 1.28,
      "grad_norm": 0.19747395813465118,
      "learning_rate": 1.8e-05,
      "loss": 0.0014,
      "step": 44800
    },
    {
      "epoch": 1.2802857142857142,
      "grad_norm": 0.0,
      "learning_rate": 1.7992857142857146e-05,
      "loss": 0.0001,
      "step": 44810
    },
    {
      "epoch": 1.2805714285714287,
      "grad_norm": 0.266634464263916,
      "learning_rate": 1.7985714285714287e-05,
      "loss": 0.0022,
      "step": 44820
    },
    {
      "epoch": 1.280857142857143,
      "grad_norm": 0.10288072377443314,
      "learning_rate": 1.7978571428571432e-05,
      "loss": 0.001,
      "step": 44830
    },
    {
      "epoch": 1.2811428571428571,
      "grad_norm": 0.26813048124313354,
      "learning_rate": 1.797142857142857e-05,
      "loss": 0.0017,
      "step": 44840
    },
    {
      "epoch": 1.2814285714285714,
      "grad_norm": 0.14230096340179443,
      "learning_rate": 1.7964285714285712e-05,
      "loss": 0.0006,
      "step": 44850
    },
    {
      "epoch": 1.2817142857142856,
      "grad_norm": 0.04715404659509659,
      "learning_rate": 1.7957142857142858e-05,
      "loss": 0.0006,
      "step": 44860
    },
    {
      "epoch": 1.282,
      "grad_norm": 0.256308376789093,
      "learning_rate": 1.795e-05,
      "loss": 0.001,
      "step": 44870
    },
    {
      "epoch": 1.2822857142857143,
      "grad_norm": 0.3652494251728058,
      "learning_rate": 1.7942857142857144e-05,
      "loss": 0.0016,
      "step": 44880
    },
    {
      "epoch": 1.2825714285714285,
      "grad_norm": 0.09419142454862595,
      "learning_rate": 1.7935714285714286e-05,
      "loss": 0.0029,
      "step": 44890
    },
    {
      "epoch": 1.282857142857143,
      "grad_norm": 0.028998641297221184,
      "learning_rate": 1.792857142857143e-05,
      "loss": 0.0015,
      "step": 44900
    },
    {
      "epoch": 1.2831428571428571,
      "grad_norm": 0.3890568017959595,
      "learning_rate": 1.7921428571428573e-05,
      "loss": 0.0013,
      "step": 44910
    },
    {
      "epoch": 1.2834285714285714,
      "grad_norm": 0.05444774031639099,
      "learning_rate": 1.7914285714285715e-05,
      "loss": 0.0012,
      "step": 44920
    },
    {
      "epoch": 1.2837142857142858,
      "grad_norm": 0.2872622013092041,
      "learning_rate": 1.790714285714286e-05,
      "loss": 0.0016,
      "step": 44930
    },
    {
      "epoch": 1.284,
      "grad_norm": 0.10495752841234207,
      "learning_rate": 1.79e-05,
      "loss": 0.001,
      "step": 44940
    },
    {
      "epoch": 1.2842857142857143,
      "grad_norm": 0.05253106355667114,
      "learning_rate": 1.7892857142857143e-05,
      "loss": 0.002,
      "step": 44950
    },
    {
      "epoch": 1.2845714285714287,
      "grad_norm": 0.06203534081578255,
      "learning_rate": 1.7885714285714285e-05,
      "loss": 0.0012,
      "step": 44960
    },
    {
      "epoch": 1.284857142857143,
      "grad_norm": 0.0,
      "learning_rate": 1.787857142857143e-05,
      "loss": 0.0007,
      "step": 44970
    },
    {
      "epoch": 1.2851428571428571,
      "grad_norm": 0.042945556342601776,
      "learning_rate": 1.787142857142857e-05,
      "loss": 0.0014,
      "step": 44980
    },
    {
      "epoch": 1.2854285714285714,
      "grad_norm": 0.04298052936792374,
      "learning_rate": 1.7864285714285713e-05,
      "loss": 0.0009,
      "step": 44990
    },
    {
      "epoch": 1.2857142857142856,
      "grad_norm": 0.0,
      "learning_rate": 1.785714285714286e-05,
      "loss": 0.002,
      "step": 45000
    },
    {
      "epoch": 1.286,
      "grad_norm": 0.0,
      "learning_rate": 1.785e-05,
      "loss": 0.0008,
      "step": 45010
    },
    {
      "epoch": 1.2862857142857143,
      "grad_norm": 0.0,
      "learning_rate": 1.7842857142857145e-05,
      "loss": 0.001,
      "step": 45020
    },
    {
      "epoch": 1.2865714285714285,
      "grad_norm": 0.20073211193084717,
      "learning_rate": 1.7835714285714287e-05,
      "loss": 0.001,
      "step": 45030
    },
    {
      "epoch": 1.286857142857143,
      "grad_norm": 0.08435455709695816,
      "learning_rate": 1.7828571428571432e-05,
      "loss": 0.0009,
      "step": 45040
    },
    {
      "epoch": 1.2871428571428571,
      "grad_norm": 0.11729231476783752,
      "learning_rate": 1.7821428571428574e-05,
      "loss": 0.002,
      "step": 45050
    },
    {
      "epoch": 1.2874285714285714,
      "grad_norm": 0.0,
      "learning_rate": 1.7814285714285716e-05,
      "loss": 0.0006,
      "step": 45060
    },
    {
      "epoch": 1.2877142857142858,
      "grad_norm": 0.05117809772491455,
      "learning_rate": 1.7807142857142857e-05,
      "loss": 0.002,
      "step": 45070
    },
    {
      "epoch": 1.288,
      "grad_norm": 0.041812244802713394,
      "learning_rate": 1.78e-05,
      "loss": 0.0006,
      "step": 45080
    },
    {
      "epoch": 1.2882857142857143,
      "grad_norm": 0.14795753359794617,
      "learning_rate": 1.7792857142857144e-05,
      "loss": 0.0009,
      "step": 45090
    },
    {
      "epoch": 1.2885714285714287,
      "grad_norm": 0.07108896225690842,
      "learning_rate": 1.7785714285714286e-05,
      "loss": 0.0012,
      "step": 45100
    },
    {
      "epoch": 1.288857142857143,
      "grad_norm": 0.05722861737012863,
      "learning_rate": 1.777857142857143e-05,
      "loss": 0.0016,
      "step": 45110
    },
    {
      "epoch": 1.2891428571428571,
      "grad_norm": 0.028614573180675507,
      "learning_rate": 1.7771428571428573e-05,
      "loss": 0.0017,
      "step": 45120
    },
    {
      "epoch": 1.2894285714285714,
      "grad_norm": 0.20142124593257904,
      "learning_rate": 1.7764285714285714e-05,
      "loss": 0.0009,
      "step": 45130
    },
    {
      "epoch": 1.2897142857142856,
      "grad_norm": 0.040816131979227066,
      "learning_rate": 1.775714285714286e-05,
      "loss": 0.001,
      "step": 45140
    },
    {
      "epoch": 1.29,
      "grad_norm": 0.3523719608783722,
      "learning_rate": 1.775e-05,
      "loss": 0.0013,
      "step": 45150
    },
    {
      "epoch": 1.2902857142857143,
      "grad_norm": 0.0960976779460907,
      "learning_rate": 1.7742857142857143e-05,
      "loss": 0.0011,
      "step": 45160
    },
    {
      "epoch": 1.2905714285714285,
      "grad_norm": 0.056638848036527634,
      "learning_rate": 1.7735714285714285e-05,
      "loss": 0.001,
      "step": 45170
    },
    {
      "epoch": 1.290857142857143,
      "grad_norm": 0.0941653624176979,
      "learning_rate": 1.772857142857143e-05,
      "loss": 0.0014,
      "step": 45180
    },
    {
      "epoch": 1.2911428571428571,
      "grad_norm": 0.02808663435280323,
      "learning_rate": 1.772142857142857e-05,
      "loss": 0.0019,
      "step": 45190
    },
    {
      "epoch": 1.2914285714285714,
      "grad_norm": 0.023711929097771645,
      "learning_rate": 1.7714285714285713e-05,
      "loss": 0.0017,
      "step": 45200
    },
    {
      "epoch": 1.2917142857142858,
      "grad_norm": 0.0,
      "learning_rate": 1.7707142857142858e-05,
      "loss": 0.0022,
      "step": 45210
    },
    {
      "epoch": 1.292,
      "grad_norm": 0.06322451680898666,
      "learning_rate": 1.77e-05,
      "loss": 0.0014,
      "step": 45220
    },
    {
      "epoch": 1.2922857142857143,
      "grad_norm": 0.04671282321214676,
      "learning_rate": 1.7692857142857145e-05,
      "loss": 0.0009,
      "step": 45230
    },
    {
      "epoch": 1.2925714285714287,
      "grad_norm": 0.0,
      "learning_rate": 1.7685714285714287e-05,
      "loss": 0.0009,
      "step": 45240
    },
    {
      "epoch": 1.292857142857143,
      "grad_norm": 0.08528164774179459,
      "learning_rate": 1.7678571428571432e-05,
      "loss": 0.0015,
      "step": 45250
    },
    {
      "epoch": 1.2931428571428571,
      "grad_norm": 0.04383229464292526,
      "learning_rate": 1.7671428571428574e-05,
      "loss": 0.0019,
      "step": 45260
    },
    {
      "epoch": 1.2934285714285714,
      "grad_norm": 0.06359933316707611,
      "learning_rate": 1.7664285714285715e-05,
      "loss": 0.0013,
      "step": 45270
    },
    {
      "epoch": 1.2937142857142856,
      "grad_norm": 0.087193064391613,
      "learning_rate": 1.7657142857142857e-05,
      "loss": 0.0014,
      "step": 45280
    },
    {
      "epoch": 1.294,
      "grad_norm": 0.05296208709478378,
      "learning_rate": 1.765e-05,
      "loss": 0.0017,
      "step": 45290
    },
    {
      "epoch": 1.2942857142857143,
      "grad_norm": 0.03879169002175331,
      "learning_rate": 1.7642857142857144e-05,
      "loss": 0.001,
      "step": 45300
    },
    {
      "epoch": 1.2945714285714285,
      "grad_norm": 0.04426703229546547,
      "learning_rate": 1.7635714285714286e-05,
      "loss": 0.0016,
      "step": 45310
    },
    {
      "epoch": 1.294857142857143,
      "grad_norm": 0.0,
      "learning_rate": 1.762857142857143e-05,
      "loss": 0.0007,
      "step": 45320
    },
    {
      "epoch": 1.2951428571428572,
      "grad_norm": 0.05002798140048981,
      "learning_rate": 1.7621428571428572e-05,
      "loss": 0.001,
      "step": 45330
    },
    {
      "epoch": 1.2954285714285714,
      "grad_norm": 0.08113657683134079,
      "learning_rate": 1.7614285714285717e-05,
      "loss": 0.0009,
      "step": 45340
    },
    {
      "epoch": 1.2957142857142858,
      "grad_norm": 0.11981888115406036,
      "learning_rate": 1.760714285714286e-05,
      "loss": 0.0009,
      "step": 45350
    },
    {
      "epoch": 1.296,
      "grad_norm": 0.0656803697347641,
      "learning_rate": 1.76e-05,
      "loss": 0.0016,
      "step": 45360
    },
    {
      "epoch": 1.2962857142857143,
      "grad_norm": 0.32301580905914307,
      "learning_rate": 1.7592857142857143e-05,
      "loss": 0.0015,
      "step": 45370
    },
    {
      "epoch": 1.2965714285714287,
      "grad_norm": 0.0463281013071537,
      "learning_rate": 1.7585714285714284e-05,
      "loss": 0.0018,
      "step": 45380
    },
    {
      "epoch": 1.296857142857143,
      "grad_norm": 0.023485803976655006,
      "learning_rate": 1.757857142857143e-05,
      "loss": 0.0019,
      "step": 45390
    },
    {
      "epoch": 1.2971428571428572,
      "grad_norm": 0.29925864934921265,
      "learning_rate": 1.757142857142857e-05,
      "loss": 0.0013,
      "step": 45400
    },
    {
      "epoch": 1.2974285714285714,
      "grad_norm": 0.03736911714076996,
      "learning_rate": 1.7564285714285716e-05,
      "loss": 0.002,
      "step": 45410
    },
    {
      "epoch": 1.2977142857142856,
      "grad_norm": 0.1060873344540596,
      "learning_rate": 1.7557142857142858e-05,
      "loss": 0.0005,
      "step": 45420
    },
    {
      "epoch": 1.298,
      "grad_norm": 0.07398445159196854,
      "learning_rate": 1.755e-05,
      "loss": 0.0012,
      "step": 45430
    },
    {
      "epoch": 1.2982857142857143,
      "grad_norm": 0.1602512001991272,
      "learning_rate": 1.7542857142857145e-05,
      "loss": 0.0018,
      "step": 45440
    },
    {
      "epoch": 1.2985714285714285,
      "grad_norm": 0.08195177465677261,
      "learning_rate": 1.7535714285714287e-05,
      "loss": 0.0007,
      "step": 45450
    },
    {
      "epoch": 1.298857142857143,
      "grad_norm": 0.0,
      "learning_rate": 1.752857142857143e-05,
      "loss": 0.0012,
      "step": 45460
    },
    {
      "epoch": 1.2991428571428572,
      "grad_norm": 0.09124035388231277,
      "learning_rate": 1.7521428571428573e-05,
      "loss": 0.001,
      "step": 45470
    },
    {
      "epoch": 1.2994285714285714,
      "grad_norm": 0.175777405500412,
      "learning_rate": 1.7514285714285715e-05,
      "loss": 0.0019,
      "step": 45480
    },
    {
      "epoch": 1.2997142857142858,
      "grad_norm": 0.04178136587142944,
      "learning_rate": 1.7507142857142857e-05,
      "loss": 0.0015,
      "step": 45490
    },
    {
      "epoch": 1.3,
      "grad_norm": 0.08670667558908463,
      "learning_rate": 1.75e-05,
      "loss": 0.0013,
      "step": 45500
    },
    {
      "epoch": 1.3002857142857143,
      "grad_norm": 0.028736218810081482,
      "learning_rate": 1.7492857142857144e-05,
      "loss": 0.0014,
      "step": 45510
    },
    {
      "epoch": 1.3005714285714285,
      "grad_norm": 0.0947425439953804,
      "learning_rate": 1.7485714285714285e-05,
      "loss": 0.0005,
      "step": 45520
    },
    {
      "epoch": 1.300857142857143,
      "grad_norm": 0.31795865297317505,
      "learning_rate": 1.747857142857143e-05,
      "loss": 0.0011,
      "step": 45530
    },
    {
      "epoch": 1.3011428571428572,
      "grad_norm": 0.04444868490099907,
      "learning_rate": 1.7471428571428572e-05,
      "loss": 0.0011,
      "step": 45540
    },
    {
      "epoch": 1.3014285714285714,
      "grad_norm": 0.085394486784935,
      "learning_rate": 1.7464285714285717e-05,
      "loss": 0.0013,
      "step": 45550
    },
    {
      "epoch": 1.3017142857142856,
      "grad_norm": 0.05032749101519585,
      "learning_rate": 1.745714285714286e-05,
      "loss": 0.0008,
      "step": 45560
    },
    {
      "epoch": 1.302,
      "grad_norm": 0.03817679360508919,
      "learning_rate": 1.745e-05,
      "loss": 0.0013,
      "step": 45570
    },
    {
      "epoch": 1.3022857142857143,
      "grad_norm": 0.06440265476703644,
      "learning_rate": 1.7442857142857146e-05,
      "loss": 0.0011,
      "step": 45580
    },
    {
      "epoch": 1.3025714285714285,
      "grad_norm": 0.0,
      "learning_rate": 1.7435714285714287e-05,
      "loss": 0.0015,
      "step": 45590
    },
    {
      "epoch": 1.302857142857143,
      "grad_norm": 0.0659026950597763,
      "learning_rate": 1.742857142857143e-05,
      "loss": 0.0021,
      "step": 45600
    },
    {
      "epoch": 1.3031428571428572,
      "grad_norm": 0.0601532869040966,
      "learning_rate": 1.742142857142857e-05,
      "loss": 0.002,
      "step": 45610
    },
    {
      "epoch": 1.3034285714285714,
      "grad_norm": 0.05001208186149597,
      "learning_rate": 1.7414285714285716e-05,
      "loss": 0.0013,
      "step": 45620
    },
    {
      "epoch": 1.3037142857142858,
      "grad_norm": 0.12106137722730637,
      "learning_rate": 1.7407142857142858e-05,
      "loss": 0.0012,
      "step": 45630
    },
    {
      "epoch": 1.304,
      "grad_norm": 0.3743393123149872,
      "learning_rate": 1.74e-05,
      "loss": 0.0016,
      "step": 45640
    },
    {
      "epoch": 1.3042857142857143,
      "grad_norm": 0.08695518970489502,
      "learning_rate": 1.7392857142857145e-05,
      "loss": 0.0009,
      "step": 45650
    },
    {
      "epoch": 1.3045714285714285,
      "grad_norm": 0.10358629375696182,
      "learning_rate": 1.7385714285714286e-05,
      "loss": 0.0015,
      "step": 45660
    },
    {
      "epoch": 1.304857142857143,
      "grad_norm": 0.06650205701589584,
      "learning_rate": 1.737857142857143e-05,
      "loss": 0.0016,
      "step": 45670
    },
    {
      "epoch": 1.3051428571428572,
      "grad_norm": 0.044316694140434265,
      "learning_rate": 1.7371428571428573e-05,
      "loss": 0.0008,
      "step": 45680
    },
    {
      "epoch": 1.3054285714285714,
      "grad_norm": 0.0575072318315506,
      "learning_rate": 1.7364285714285715e-05,
      "loss": 0.0008,
      "step": 45690
    },
    {
      "epoch": 1.3057142857142856,
      "grad_norm": 0.12251997739076614,
      "learning_rate": 1.7357142857142856e-05,
      "loss": 0.0016,
      "step": 45700
    },
    {
      "epoch": 1.306,
      "grad_norm": 0.04152696952223778,
      "learning_rate": 1.7349999999999998e-05,
      "loss": 0.0013,
      "step": 45710
    },
    {
      "epoch": 1.3062857142857143,
      "grad_norm": 0.2210809737443924,
      "learning_rate": 1.7342857142857143e-05,
      "loss": 0.0019,
      "step": 45720
    },
    {
      "epoch": 1.3065714285714285,
      "grad_norm": 0.0,
      "learning_rate": 1.7335714285714285e-05,
      "loss": 0.001,
      "step": 45730
    },
    {
      "epoch": 1.306857142857143,
      "grad_norm": 0.050244495272636414,
      "learning_rate": 1.732857142857143e-05,
      "loss": 0.0017,
      "step": 45740
    },
    {
      "epoch": 1.3071428571428572,
      "grad_norm": 0.23348534107208252,
      "learning_rate": 1.7321428571428572e-05,
      "loss": 0.0017,
      "step": 45750
    },
    {
      "epoch": 1.3074285714285714,
      "grad_norm": 0.0,
      "learning_rate": 1.7314285714285717e-05,
      "loss": 0.0022,
      "step": 45760
    },
    {
      "epoch": 1.3077142857142858,
      "grad_norm": 0.12996134161949158,
      "learning_rate": 1.730714285714286e-05,
      "loss": 0.0009,
      "step": 45770
    },
    {
      "epoch": 1.308,
      "grad_norm": 0.041842974722385406,
      "learning_rate": 1.73e-05,
      "loss": 0.0012,
      "step": 45780
    },
    {
      "epoch": 1.3082857142857143,
      "grad_norm": 0.0,
      "learning_rate": 1.7292857142857145e-05,
      "loss": 0.0004,
      "step": 45790
    },
    {
      "epoch": 1.3085714285714285,
      "grad_norm": 0.030117833986878395,
      "learning_rate": 1.7285714285714287e-05,
      "loss": 0.0003,
      "step": 45800
    },
    {
      "epoch": 1.3088571428571427,
      "grad_norm": 0.0,
      "learning_rate": 1.727857142857143e-05,
      "loss": 0.0007,
      "step": 45810
    },
    {
      "epoch": 1.3091428571428572,
      "grad_norm": 0.21401235461235046,
      "learning_rate": 1.727142857142857e-05,
      "loss": 0.0009,
      "step": 45820
    },
    {
      "epoch": 1.3094285714285714,
      "grad_norm": 0.04873744398355484,
      "learning_rate": 1.7264285714285716e-05,
      "loss": 0.0009,
      "step": 45830
    },
    {
      "epoch": 1.3097142857142856,
      "grad_norm": 0.06811898201704025,
      "learning_rate": 1.7257142857142857e-05,
      "loss": 0.0005,
      "step": 45840
    },
    {
      "epoch": 1.31,
      "grad_norm": 0.16046249866485596,
      "learning_rate": 1.725e-05,
      "loss": 0.001,
      "step": 45850
    },
    {
      "epoch": 1.3102857142857143,
      "grad_norm": 0.04162197932600975,
      "learning_rate": 1.7242857142857144e-05,
      "loss": 0.0017,
      "step": 45860
    },
    {
      "epoch": 1.3105714285714285,
      "grad_norm": 0.04853416606783867,
      "learning_rate": 1.7235714285714286e-05,
      "loss": 0.0007,
      "step": 45870
    },
    {
      "epoch": 1.310857142857143,
      "grad_norm": 0.029270680621266365,
      "learning_rate": 1.722857142857143e-05,
      "loss": 0.0019,
      "step": 45880
    },
    {
      "epoch": 1.3111428571428572,
      "grad_norm": 0.0,
      "learning_rate": 1.7221428571428573e-05,
      "loss": 0.0001,
      "step": 45890
    },
    {
      "epoch": 1.3114285714285714,
      "grad_norm": 0.0,
      "learning_rate": 1.7214285714285715e-05,
      "loss": 0.0006,
      "step": 45900
    },
    {
      "epoch": 1.3117142857142858,
      "grad_norm": 0.09452244639396667,
      "learning_rate": 1.7207142857142856e-05,
      "loss": 0.0007,
      "step": 45910
    },
    {
      "epoch": 1.312,
      "grad_norm": 0.0,
      "learning_rate": 1.7199999999999998e-05,
      "loss": 0.0014,
      "step": 45920
    },
    {
      "epoch": 1.3122857142857143,
      "grad_norm": 0.08193177729845047,
      "learning_rate": 1.7192857142857143e-05,
      "loss": 0.0017,
      "step": 45930
    },
    {
      "epoch": 1.3125714285714285,
      "grad_norm": 0.2602635324001312,
      "learning_rate": 1.7185714285714285e-05,
      "loss": 0.0005,
      "step": 45940
    },
    {
      "epoch": 1.3128571428571427,
      "grad_norm": 0.0,
      "learning_rate": 1.717857142857143e-05,
      "loss": 0.0013,
      "step": 45950
    },
    {
      "epoch": 1.3131428571428572,
      "grad_norm": 0.0,
      "learning_rate": 1.717142857142857e-05,
      "loss": 0.001,
      "step": 45960
    },
    {
      "epoch": 1.3134285714285714,
      "grad_norm": 0.043171465396881104,
      "learning_rate": 1.7164285714285717e-05,
      "loss": 0.0009,
      "step": 45970
    },
    {
      "epoch": 1.3137142857142856,
      "grad_norm": 0.20893779397010803,
      "learning_rate": 1.715714285714286e-05,
      "loss": 0.0012,
      "step": 45980
    },
    {
      "epoch": 1.314,
      "grad_norm": 0.052817925810813904,
      "learning_rate": 1.7150000000000004e-05,
      "loss": 0.001,
      "step": 45990
    },
    {
      "epoch": 1.3142857142857143,
      "grad_norm": 0.0,
      "learning_rate": 1.7142857142857145e-05,
      "loss": 0.0011,
      "step": 46000
    },
    {
      "epoch": 1.3145714285714285,
      "grad_norm": 0.27944323420524597,
      "learning_rate": 1.7135714285714287e-05,
      "loss": 0.0018,
      "step": 46010
    },
    {
      "epoch": 1.314857142857143,
      "grad_norm": 0.02924646995961666,
      "learning_rate": 1.712857142857143e-05,
      "loss": 0.001,
      "step": 46020
    },
    {
      "epoch": 1.3151428571428572,
      "grad_norm": 0.23278523981571198,
      "learning_rate": 1.712142857142857e-05,
      "loss": 0.001,
      "step": 46030
    },
    {
      "epoch": 1.3154285714285714,
      "grad_norm": 0.18224075436592102,
      "learning_rate": 1.7114285714285715e-05,
      "loss": 0.0014,
      "step": 46040
    },
    {
      "epoch": 1.3157142857142858,
      "grad_norm": 0.09957573562860489,
      "learning_rate": 1.7107142857142857e-05,
      "loss": 0.0012,
      "step": 46050
    },
    {
      "epoch": 1.316,
      "grad_norm": 0.0,
      "learning_rate": 1.7100000000000002e-05,
      "loss": 0.0015,
      "step": 46060
    },
    {
      "epoch": 1.3162857142857143,
      "grad_norm": 0.2062116116285324,
      "learning_rate": 1.7092857142857144e-05,
      "loss": 0.0016,
      "step": 46070
    },
    {
      "epoch": 1.3165714285714285,
      "grad_norm": 0.04299933835864067,
      "learning_rate": 1.7085714285714286e-05,
      "loss": 0.0014,
      "step": 46080
    },
    {
      "epoch": 1.3168571428571427,
      "grad_norm": 0.0,
      "learning_rate": 1.707857142857143e-05,
      "loss": 0.0004,
      "step": 46090
    },
    {
      "epoch": 1.3171428571428572,
      "grad_norm": 0.0,
      "learning_rate": 1.7071428571428573e-05,
      "loss": 0.0009,
      "step": 46100
    },
    {
      "epoch": 1.3174285714285714,
      "grad_norm": 0.0,
      "learning_rate": 1.7064285714285718e-05,
      "loss": 0.0005,
      "step": 46110
    },
    {
      "epoch": 1.3177142857142856,
      "grad_norm": 0.045937854796648026,
      "learning_rate": 1.7057142857142856e-05,
      "loss": 0.0008,
      "step": 46120
    },
    {
      "epoch": 1.318,
      "grad_norm": 0.14918957650661469,
      "learning_rate": 1.705e-05,
      "loss": 0.001,
      "step": 46130
    },
    {
      "epoch": 1.3182857142857143,
      "grad_norm": 0.0,
      "learning_rate": 1.7042857142857143e-05,
      "loss": 0.0014,
      "step": 46140
    },
    {
      "epoch": 1.3185714285714285,
      "grad_norm": 0.0,
      "learning_rate": 1.7035714285714285e-05,
      "loss": 0.0017,
      "step": 46150
    },
    {
      "epoch": 1.318857142857143,
      "grad_norm": 0.14749379456043243,
      "learning_rate": 1.702857142857143e-05,
      "loss": 0.0021,
      "step": 46160
    },
    {
      "epoch": 1.3191428571428572,
      "grad_norm": 0.0,
      "learning_rate": 1.702142857142857e-05,
      "loss": 0.0013,
      "step": 46170
    },
    {
      "epoch": 1.3194285714285714,
      "grad_norm": 0.04114857688546181,
      "learning_rate": 1.7014285714285716e-05,
      "loss": 0.0006,
      "step": 46180
    },
    {
      "epoch": 1.3197142857142858,
      "grad_norm": 0.04844321310520172,
      "learning_rate": 1.7007142857142858e-05,
      "loss": 0.0015,
      "step": 46190
    },
    {
      "epoch": 1.32,
      "grad_norm": 0.04555482044816017,
      "learning_rate": 1.7000000000000003e-05,
      "loss": 0.0012,
      "step": 46200
    },
    {
      "epoch": 1.3202857142857143,
      "grad_norm": 0.07425062358379364,
      "learning_rate": 1.6992857142857145e-05,
      "loss": 0.0019,
      "step": 46210
    },
    {
      "epoch": 1.3205714285714285,
      "grad_norm": 0.0,
      "learning_rate": 1.6985714285714287e-05,
      "loss": 0.0017,
      "step": 46220
    },
    {
      "epoch": 1.3208571428571427,
      "grad_norm": 0.09413643181324005,
      "learning_rate": 1.697857142857143e-05,
      "loss": 0.0015,
      "step": 46230
    },
    {
      "epoch": 1.3211428571428572,
      "grad_norm": 0.047135449945926666,
      "learning_rate": 1.697142857142857e-05,
      "loss": 0.0018,
      "step": 46240
    },
    {
      "epoch": 1.3214285714285714,
      "grad_norm": 0.048285894095897675,
      "learning_rate": 1.6964285714285715e-05,
      "loss": 0.0014,
      "step": 46250
    },
    {
      "epoch": 1.3217142857142856,
      "grad_norm": 0.09712855517864227,
      "learning_rate": 1.6957142857142857e-05,
      "loss": 0.0021,
      "step": 46260
    },
    {
      "epoch": 1.322,
      "grad_norm": 0.13909727334976196,
      "learning_rate": 1.6950000000000002e-05,
      "loss": 0.0009,
      "step": 46270
    },
    {
      "epoch": 1.3222857142857143,
      "grad_norm": 0.0,
      "learning_rate": 1.6942857142857144e-05,
      "loss": 0.0009,
      "step": 46280
    },
    {
      "epoch": 1.3225714285714285,
      "grad_norm": 0.08830459415912628,
      "learning_rate": 1.6935714285714285e-05,
      "loss": 0.0015,
      "step": 46290
    },
    {
      "epoch": 1.322857142857143,
      "grad_norm": 0.04236733168363571,
      "learning_rate": 1.692857142857143e-05,
      "loss": 0.0014,
      "step": 46300
    },
    {
      "epoch": 1.3231428571428572,
      "grad_norm": 0.23482564091682434,
      "learning_rate": 1.6921428571428572e-05,
      "loss": 0.0005,
      "step": 46310
    },
    {
      "epoch": 1.3234285714285714,
      "grad_norm": 0.08312112838029861,
      "learning_rate": 1.6914285714285717e-05,
      "loss": 0.0008,
      "step": 46320
    },
    {
      "epoch": 1.3237142857142858,
      "grad_norm": 0.0,
      "learning_rate": 1.690714285714286e-05,
      "loss": 0.0015,
      "step": 46330
    },
    {
      "epoch": 1.324,
      "grad_norm": 0.06770680844783783,
      "learning_rate": 1.69e-05,
      "loss": 0.0013,
      "step": 46340
    },
    {
      "epoch": 1.3242857142857143,
      "grad_norm": 0.09813198447227478,
      "learning_rate": 1.6892857142857143e-05,
      "loss": 0.0015,
      "step": 46350
    },
    {
      "epoch": 1.3245714285714285,
      "grad_norm": 0.04993455484509468,
      "learning_rate": 1.6885714285714284e-05,
      "loss": 0.0015,
      "step": 46360
    },
    {
      "epoch": 1.3248571428571427,
      "grad_norm": 0.13163867592811584,
      "learning_rate": 1.687857142857143e-05,
      "loss": 0.0003,
      "step": 46370
    },
    {
      "epoch": 1.3251428571428572,
      "grad_norm": 0.03368418663740158,
      "learning_rate": 1.687142857142857e-05,
      "loss": 0.0011,
      "step": 46380
    },
    {
      "epoch": 1.3254285714285714,
      "grad_norm": 0.04765841364860535,
      "learning_rate": 1.6864285714285716e-05,
      "loss": 0.001,
      "step": 46390
    },
    {
      "epoch": 1.3257142857142856,
      "grad_norm": 0.10637681186199188,
      "learning_rate": 1.6857142857142858e-05,
      "loss": 0.0018,
      "step": 46400
    },
    {
      "epoch": 1.326,
      "grad_norm": 0.0,
      "learning_rate": 1.6850000000000003e-05,
      "loss": 0.0015,
      "step": 46410
    },
    {
      "epoch": 1.3262857142857143,
      "grad_norm": 0.0,
      "learning_rate": 1.6842857142857145e-05,
      "loss": 0.0003,
      "step": 46420
    },
    {
      "epoch": 1.3265714285714285,
      "grad_norm": 0.15224917232990265,
      "learning_rate": 1.6835714285714286e-05,
      "loss": 0.0014,
      "step": 46430
    },
    {
      "epoch": 1.326857142857143,
      "grad_norm": 0.046492800116539,
      "learning_rate": 1.6828571428571428e-05,
      "loss": 0.0011,
      "step": 46440
    },
    {
      "epoch": 1.3271428571428572,
      "grad_norm": 0.3026636242866516,
      "learning_rate": 1.682142857142857e-05,
      "loss": 0.0015,
      "step": 46450
    },
    {
      "epoch": 1.3274285714285714,
      "grad_norm": 0.15341471135616302,
      "learning_rate": 1.6814285714285715e-05,
      "loss": 0.001,
      "step": 46460
    },
    {
      "epoch": 1.3277142857142858,
      "grad_norm": 0.3034113049507141,
      "learning_rate": 1.6807142857142857e-05,
      "loss": 0.0007,
      "step": 46470
    },
    {
      "epoch": 1.328,
      "grad_norm": 0.19673478603363037,
      "learning_rate": 1.6800000000000002e-05,
      "loss": 0.0015,
      "step": 46480
    },
    {
      "epoch": 1.3282857142857143,
      "grad_norm": 0.055181119590997696,
      "learning_rate": 1.6792857142857143e-05,
      "loss": 0.0014,
      "step": 46490
    },
    {
      "epoch": 1.3285714285714285,
      "grad_norm": 0.14253643155097961,
      "learning_rate": 1.6785714285714285e-05,
      "loss": 0.0012,
      "step": 46500
    },
    {
      "epoch": 1.3288571428571427,
      "grad_norm": 0.06826996058225632,
      "learning_rate": 1.677857142857143e-05,
      "loss": 0.0014,
      "step": 46510
    },
    {
      "epoch": 1.3291428571428572,
      "grad_norm": 0.0,
      "learning_rate": 1.6771428571428572e-05,
      "loss": 0.0014,
      "step": 46520
    },
    {
      "epoch": 1.3294285714285714,
      "grad_norm": 0.052178435027599335,
      "learning_rate": 1.6764285714285717e-05,
      "loss": 0.0016,
      "step": 46530
    },
    {
      "epoch": 1.3297142857142856,
      "grad_norm": 0.22827734053134918,
      "learning_rate": 1.675714285714286e-05,
      "loss": 0.0008,
      "step": 46540
    },
    {
      "epoch": 1.33,
      "grad_norm": 0.03451846167445183,
      "learning_rate": 1.675e-05,
      "loss": 0.0004,
      "step": 46550
    },
    {
      "epoch": 1.3302857142857143,
      "grad_norm": 0.0,
      "learning_rate": 1.6742857142857142e-05,
      "loss": 0.0004,
      "step": 46560
    },
    {
      "epoch": 1.3305714285714285,
      "grad_norm": 0.1341516077518463,
      "learning_rate": 1.6735714285714287e-05,
      "loss": 0.001,
      "step": 46570
    },
    {
      "epoch": 1.330857142857143,
      "grad_norm": 0.047214869409799576,
      "learning_rate": 1.672857142857143e-05,
      "loss": 0.0006,
      "step": 46580
    },
    {
      "epoch": 1.3311428571428572,
      "grad_norm": 0.051868122071027756,
      "learning_rate": 1.672142857142857e-05,
      "loss": 0.0019,
      "step": 46590
    },
    {
      "epoch": 1.3314285714285714,
      "grad_norm": 0.0,
      "learning_rate": 1.6714285714285716e-05,
      "loss": 0.001,
      "step": 46600
    },
    {
      "epoch": 1.3317142857142859,
      "grad_norm": 0.06534557789564133,
      "learning_rate": 1.6707142857142858e-05,
      "loss": 0.0009,
      "step": 46610
    },
    {
      "epoch": 1.332,
      "grad_norm": 0.0,
      "learning_rate": 1.6700000000000003e-05,
      "loss": 0.0016,
      "step": 46620
    },
    {
      "epoch": 1.3322857142857143,
      "grad_norm": 0.056642092764377594,
      "learning_rate": 1.6692857142857144e-05,
      "loss": 0.0013,
      "step": 46630
    },
    {
      "epoch": 1.3325714285714285,
      "grad_norm": 0.08525817096233368,
      "learning_rate": 1.6685714285714286e-05,
      "loss": 0.0009,
      "step": 46640
    },
    {
      "epoch": 1.3328571428571427,
      "grad_norm": 0.21766377985477448,
      "learning_rate": 1.6678571428571428e-05,
      "loss": 0.0014,
      "step": 46650
    },
    {
      "epoch": 1.3331428571428572,
      "grad_norm": 0.08127959072589874,
      "learning_rate": 1.667142857142857e-05,
      "loss": 0.0004,
      "step": 46660
    },
    {
      "epoch": 1.3334285714285714,
      "grad_norm": 0.0,
      "learning_rate": 1.6664285714285715e-05,
      "loss": 0.0012,
      "step": 46670
    },
    {
      "epoch": 1.3337142857142856,
      "grad_norm": 0.08013138175010681,
      "learning_rate": 1.6657142857142856e-05,
      "loss": 0.0008,
      "step": 46680
    },
    {
      "epoch": 1.334,
      "grad_norm": 0.0566299632191658,
      "learning_rate": 1.665e-05,
      "loss": 0.0008,
      "step": 46690
    },
    {
      "epoch": 1.3342857142857143,
      "grad_norm": 0.041536349803209305,
      "learning_rate": 1.6642857142857143e-05,
      "loss": 0.0012,
      "step": 46700
    },
    {
      "epoch": 1.3345714285714285,
      "grad_norm": 0.38593950867652893,
      "learning_rate": 1.663571428571429e-05,
      "loss": 0.0011,
      "step": 46710
    },
    {
      "epoch": 1.334857142857143,
      "grad_norm": 0.3879564106464386,
      "learning_rate": 1.662857142857143e-05,
      "loss": 0.0022,
      "step": 46720
    },
    {
      "epoch": 1.3351428571428572,
      "grad_norm": 0.03781412914395332,
      "learning_rate": 1.6621428571428572e-05,
      "loss": 0.0011,
      "step": 46730
    },
    {
      "epoch": 1.3354285714285714,
      "grad_norm": 0.3143862187862396,
      "learning_rate": 1.6614285714285717e-05,
      "loss": 0.0015,
      "step": 46740
    },
    {
      "epoch": 1.3357142857142856,
      "grad_norm": 0.3095909655094147,
      "learning_rate": 1.660714285714286e-05,
      "loss": 0.0019,
      "step": 46750
    },
    {
      "epoch": 1.336,
      "grad_norm": 0.038671430200338364,
      "learning_rate": 1.66e-05,
      "loss": 0.0011,
      "step": 46760
    },
    {
      "epoch": 1.3362857142857143,
      "grad_norm": 0.0,
      "learning_rate": 1.6592857142857142e-05,
      "loss": 0.0012,
      "step": 46770
    },
    {
      "epoch": 1.3365714285714285,
      "grad_norm": 0.0,
      "learning_rate": 1.6585714285714287e-05,
      "loss": 0.0016,
      "step": 46780
    },
    {
      "epoch": 1.3368571428571427,
      "grad_norm": 0.04754237085580826,
      "learning_rate": 1.657857142857143e-05,
      "loss": 0.0006,
      "step": 46790
    },
    {
      "epoch": 1.3371428571428572,
      "grad_norm": 0.044547487050294876,
      "learning_rate": 1.657142857142857e-05,
      "loss": 0.0005,
      "step": 46800
    },
    {
      "epoch": 1.3374285714285714,
      "grad_norm": 0.04692188277840614,
      "learning_rate": 1.6564285714285716e-05,
      "loss": 0.0008,
      "step": 46810
    },
    {
      "epoch": 1.3377142857142856,
      "grad_norm": 0.15034180879592896,
      "learning_rate": 1.6557142857142857e-05,
      "loss": 0.0015,
      "step": 46820
    },
    {
      "epoch": 1.338,
      "grad_norm": 0.0,
      "learning_rate": 1.6550000000000002e-05,
      "loss": 0.0012,
      "step": 46830
    },
    {
      "epoch": 1.3382857142857143,
      "grad_norm": 0.042517874389886856,
      "learning_rate": 1.6542857142857144e-05,
      "loss": 0.0007,
      "step": 46840
    },
    {
      "epoch": 1.3385714285714285,
      "grad_norm": 0.07561446726322174,
      "learning_rate": 1.653571428571429e-05,
      "loss": 0.0013,
      "step": 46850
    },
    {
      "epoch": 1.338857142857143,
      "grad_norm": 0.12338460981845856,
      "learning_rate": 1.652857142857143e-05,
      "loss": 0.0018,
      "step": 46860
    },
    {
      "epoch": 1.3391428571428572,
      "grad_norm": 0.0,
      "learning_rate": 1.652142857142857e-05,
      "loss": 0.0004,
      "step": 46870
    },
    {
      "epoch": 1.3394285714285714,
      "grad_norm": 0.45521169900894165,
      "learning_rate": 1.6514285714285714e-05,
      "loss": 0.0015,
      "step": 46880
    },
    {
      "epoch": 1.3397142857142856,
      "grad_norm": 0.08555955439805984,
      "learning_rate": 1.6507142857142856e-05,
      "loss": 0.0017,
      "step": 46890
    },
    {
      "epoch": 1.34,
      "grad_norm": 0.04351956769824028,
      "learning_rate": 1.65e-05,
      "loss": 0.0007,
      "step": 46900
    },
    {
      "epoch": 1.3402857142857143,
      "grad_norm": 0.26008015871047974,
      "learning_rate": 1.6492857142857143e-05,
      "loss": 0.0013,
      "step": 46910
    },
    {
      "epoch": 1.3405714285714285,
      "grad_norm": 0.29924747347831726,
      "learning_rate": 1.6485714285714288e-05,
      "loss": 0.0019,
      "step": 46920
    },
    {
      "epoch": 1.3408571428571427,
      "grad_norm": 0.0,
      "learning_rate": 1.647857142857143e-05,
      "loss": 0.0014,
      "step": 46930
    },
    {
      "epoch": 1.3411428571428572,
      "grad_norm": 0.07353498786687851,
      "learning_rate": 1.647142857142857e-05,
      "loss": 0.0015,
      "step": 46940
    },
    {
      "epoch": 1.3414285714285714,
      "grad_norm": 0.019639451056718826,
      "learning_rate": 1.6464285714285717e-05,
      "loss": 0.0023,
      "step": 46950
    },
    {
      "epoch": 1.3417142857142856,
      "grad_norm": 0.0,
      "learning_rate": 1.645714285714286e-05,
      "loss": 0.0005,
      "step": 46960
    },
    {
      "epoch": 1.342,
      "grad_norm": 0.07558577507734299,
      "learning_rate": 1.645e-05,
      "loss": 0.0011,
      "step": 46970
    },
    {
      "epoch": 1.3422857142857143,
      "grad_norm": 0.13729195296764374,
      "learning_rate": 1.6442857142857142e-05,
      "loss": 0.0012,
      "step": 46980
    },
    {
      "epoch": 1.3425714285714285,
      "grad_norm": 0.05377256125211716,
      "learning_rate": 1.6435714285714287e-05,
      "loss": 0.001,
      "step": 46990
    },
    {
      "epoch": 1.342857142857143,
      "grad_norm": 0.2585556209087372,
      "learning_rate": 1.642857142857143e-05,
      "loss": 0.002,
      "step": 47000
    },
    {
      "epoch": 1.3431428571428572,
      "grad_norm": 0.08327284455299377,
      "learning_rate": 1.642142857142857e-05,
      "loss": 0.0014,
      "step": 47010
    },
    {
      "epoch": 1.3434285714285714,
      "grad_norm": 0.29715511202812195,
      "learning_rate": 1.6414285714285715e-05,
      "loss": 0.0014,
      "step": 47020
    },
    {
      "epoch": 1.3437142857142856,
      "grad_norm": 0.0,
      "learning_rate": 1.6407142857142857e-05,
      "loss": 0.0016,
      "step": 47030
    },
    {
      "epoch": 1.3439999999999999,
      "grad_norm": 0.07409672439098358,
      "learning_rate": 1.6400000000000002e-05,
      "loss": 0.0011,
      "step": 47040
    },
    {
      "epoch": 1.3442857142857143,
      "grad_norm": 0.20349779725074768,
      "learning_rate": 1.6392857142857144e-05,
      "loss": 0.0011,
      "step": 47050
    },
    {
      "epoch": 1.3445714285714285,
      "grad_norm": 0.04262256622314453,
      "learning_rate": 1.638571428571429e-05,
      "loss": 0.0012,
      "step": 47060
    },
    {
      "epoch": 1.3448571428571428,
      "grad_norm": 0.046562500298023224,
      "learning_rate": 1.637857142857143e-05,
      "loss": 0.0009,
      "step": 47070
    },
    {
      "epoch": 1.3451428571428572,
      "grad_norm": 0.0,
      "learning_rate": 1.6371428571428572e-05,
      "loss": 0.0003,
      "step": 47080
    },
    {
      "epoch": 1.3454285714285714,
      "grad_norm": 0.0,
      "learning_rate": 1.6364285714285714e-05,
      "loss": 0.0009,
      "step": 47090
    },
    {
      "epoch": 1.3457142857142856,
      "grad_norm": 0.053491268306970596,
      "learning_rate": 1.6357142857142856e-05,
      "loss": 0.0016,
      "step": 47100
    },
    {
      "epoch": 1.346,
      "grad_norm": 0.04703288897871971,
      "learning_rate": 1.635e-05,
      "loss": 0.0011,
      "step": 47110
    },
    {
      "epoch": 1.3462857142857143,
      "grad_norm": 0.17529459297657013,
      "learning_rate": 1.6342857142857143e-05,
      "loss": 0.0007,
      "step": 47120
    },
    {
      "epoch": 1.3465714285714285,
      "grad_norm": 0.0,
      "learning_rate": 1.6335714285714288e-05,
      "loss": 0.0015,
      "step": 47130
    },
    {
      "epoch": 1.346857142857143,
      "grad_norm": 0.046754248440265656,
      "learning_rate": 1.632857142857143e-05,
      "loss": 0.0007,
      "step": 47140
    },
    {
      "epoch": 1.3471428571428572,
      "grad_norm": 0.0,
      "learning_rate": 1.632142857142857e-05,
      "loss": 0.0019,
      "step": 47150
    },
    {
      "epoch": 1.3474285714285714,
      "grad_norm": 0.07095976173877716,
      "learning_rate": 1.6314285714285716e-05,
      "loss": 0.0025,
      "step": 47160
    },
    {
      "epoch": 1.3477142857142856,
      "grad_norm": 0.11583121120929718,
      "learning_rate": 1.6307142857142858e-05,
      "loss": 0.0021,
      "step": 47170
    },
    {
      "epoch": 1.3479999999999999,
      "grad_norm": 0.04542265087366104,
      "learning_rate": 1.63e-05,
      "loss": 0.0013,
      "step": 47180
    },
    {
      "epoch": 1.3482857142857143,
      "grad_norm": 0.03936108201742172,
      "learning_rate": 1.629285714285714e-05,
      "loss": 0.0014,
      "step": 47190
    },
    {
      "epoch": 1.3485714285714285,
      "grad_norm": 0.4033322036266327,
      "learning_rate": 1.6285714285714287e-05,
      "loss": 0.0019,
      "step": 47200
    },
    {
      "epoch": 1.3488571428571428,
      "grad_norm": 0.12322843819856644,
      "learning_rate": 1.627857142857143e-05,
      "loss": 0.0015,
      "step": 47210
    },
    {
      "epoch": 1.3491428571428572,
      "grad_norm": 0.05341527983546257,
      "learning_rate": 1.6271428571428573e-05,
      "loss": 0.0018,
      "step": 47220
    },
    {
      "epoch": 1.3494285714285714,
      "grad_norm": 0.04556529223918915,
      "learning_rate": 1.6264285714285715e-05,
      "loss": 0.0015,
      "step": 47230
    },
    {
      "epoch": 1.3497142857142856,
      "grad_norm": 0.09131263941526413,
      "learning_rate": 1.6257142857142857e-05,
      "loss": 0.001,
      "step": 47240
    },
    {
      "epoch": 1.35,
      "grad_norm": 0.05434397608041763,
      "learning_rate": 1.6250000000000002e-05,
      "loss": 0.0017,
      "step": 47250
    },
    {
      "epoch": 1.3502857142857143,
      "grad_norm": 0.0856047123670578,
      "learning_rate": 1.6242857142857144e-05,
      "loss": 0.0009,
      "step": 47260
    },
    {
      "epoch": 1.3505714285714285,
      "grad_norm": 0.0,
      "learning_rate": 1.623571428571429e-05,
      "loss": 0.0014,
      "step": 47270
    },
    {
      "epoch": 1.350857142857143,
      "grad_norm": 0.0,
      "learning_rate": 1.622857142857143e-05,
      "loss": 0.0011,
      "step": 47280
    },
    {
      "epoch": 1.3511428571428572,
      "grad_norm": 0.23527826368808746,
      "learning_rate": 1.6221428571428572e-05,
      "loss": 0.0016,
      "step": 47290
    },
    {
      "epoch": 1.3514285714285714,
      "grad_norm": 0.41185688972473145,
      "learning_rate": 1.6214285714285714e-05,
      "loss": 0.0011,
      "step": 47300
    },
    {
      "epoch": 1.3517142857142856,
      "grad_norm": 0.09032651036977768,
      "learning_rate": 1.6207142857142856e-05,
      "loss": 0.0011,
      "step": 47310
    },
    {
      "epoch": 1.3519999999999999,
      "grad_norm": 0.0,
      "learning_rate": 1.62e-05,
      "loss": 0.0018,
      "step": 47320
    },
    {
      "epoch": 1.3522857142857143,
      "grad_norm": 0.14551250636577606,
      "learning_rate": 1.6192857142857142e-05,
      "loss": 0.0009,
      "step": 47330
    },
    {
      "epoch": 1.3525714285714285,
      "grad_norm": 0.12503737211227417,
      "learning_rate": 1.6185714285714288e-05,
      "loss": 0.0014,
      "step": 47340
    },
    {
      "epoch": 1.3528571428571428,
      "grad_norm": 0.029185395687818527,
      "learning_rate": 1.617857142857143e-05,
      "loss": 0.0018,
      "step": 47350
    },
    {
      "epoch": 1.3531428571428572,
      "grad_norm": 0.3618965744972229,
      "learning_rate": 1.6171428571428574e-05,
      "loss": 0.0009,
      "step": 47360
    },
    {
      "epoch": 1.3534285714285714,
      "grad_norm": 0.0914665013551712,
      "learning_rate": 1.6164285714285716e-05,
      "loss": 0.0018,
      "step": 47370
    },
    {
      "epoch": 1.3537142857142856,
      "grad_norm": 0.22329780459403992,
      "learning_rate": 1.6157142857142858e-05,
      "loss": 0.0016,
      "step": 47380
    },
    {
      "epoch": 1.354,
      "grad_norm": 0.0776539146900177,
      "learning_rate": 1.6150000000000003e-05,
      "loss": 0.0007,
      "step": 47390
    },
    {
      "epoch": 1.3542857142857143,
      "grad_norm": 0.0,
      "learning_rate": 1.614285714285714e-05,
      "loss": 0.0014,
      "step": 47400
    },
    {
      "epoch": 1.3545714285714285,
      "grad_norm": 0.30532529950141907,
      "learning_rate": 1.6135714285714286e-05,
      "loss": 0.0017,
      "step": 47410
    },
    {
      "epoch": 1.354857142857143,
      "grad_norm": 0.07097753882408142,
      "learning_rate": 1.6128571428571428e-05,
      "loss": 0.0013,
      "step": 47420
    },
    {
      "epoch": 1.3551428571428572,
      "grad_norm": 0.07818575203418732,
      "learning_rate": 1.6121428571428573e-05,
      "loss": 0.0014,
      "step": 47430
    },
    {
      "epoch": 1.3554285714285714,
      "grad_norm": 0.25261345505714417,
      "learning_rate": 1.6114285714285715e-05,
      "loss": 0.0018,
      "step": 47440
    },
    {
      "epoch": 1.3557142857142856,
      "grad_norm": 0.0,
      "learning_rate": 1.6107142857142857e-05,
      "loss": 0.0004,
      "step": 47450
    },
    {
      "epoch": 1.3559999999999999,
      "grad_norm": 0.23653799295425415,
      "learning_rate": 1.6100000000000002e-05,
      "loss": 0.0007,
      "step": 47460
    },
    {
      "epoch": 1.3562857142857143,
      "grad_norm": 0.05935414135456085,
      "learning_rate": 1.6092857142857143e-05,
      "loss": 0.0015,
      "step": 47470
    },
    {
      "epoch": 1.3565714285714285,
      "grad_norm": 0.0,
      "learning_rate": 1.608571428571429e-05,
      "loss": 0.0009,
      "step": 47480
    },
    {
      "epoch": 1.3568571428571428,
      "grad_norm": 0.16102275252342224,
      "learning_rate": 1.607857142857143e-05,
      "loss": 0.0024,
      "step": 47490
    },
    {
      "epoch": 1.3571428571428572,
      "grad_norm": 0.1505080908536911,
      "learning_rate": 1.6071428571428572e-05,
      "loss": 0.0007,
      "step": 47500
    },
    {
      "epoch": 1.3574285714285714,
      "grad_norm": 0.03813326731324196,
      "learning_rate": 1.6064285714285714e-05,
      "loss": 0.0017,
      "step": 47510
    },
    {
      "epoch": 1.3577142857142857,
      "grad_norm": 0.04165561869740486,
      "learning_rate": 1.6057142857142855e-05,
      "loss": 0.0016,
      "step": 47520
    },
    {
      "epoch": 1.358,
      "grad_norm": 0.04593152180314064,
      "learning_rate": 1.605e-05,
      "loss": 0.0012,
      "step": 47530
    },
    {
      "epoch": 1.3582857142857143,
      "grad_norm": 0.0,
      "learning_rate": 1.6042857142857142e-05,
      "loss": 0.0014,
      "step": 47540
    },
    {
      "epoch": 1.3585714285714285,
      "grad_norm": 0.18527966737747192,
      "learning_rate": 1.6035714285714287e-05,
      "loss": 0.0019,
      "step": 47550
    },
    {
      "epoch": 1.358857142857143,
      "grad_norm": 0.0,
      "learning_rate": 1.602857142857143e-05,
      "loss": 0.001,
      "step": 47560
    },
    {
      "epoch": 1.3591428571428572,
      "grad_norm": 0.08090801537036896,
      "learning_rate": 1.6021428571428574e-05,
      "loss": 0.001,
      "step": 47570
    },
    {
      "epoch": 1.3594285714285714,
      "grad_norm": 0.08894769102334976,
      "learning_rate": 1.6014285714285716e-05,
      "loss": 0.0014,
      "step": 47580
    },
    {
      "epoch": 1.3597142857142857,
      "grad_norm": 0.0,
      "learning_rate": 1.6007142857142858e-05,
      "loss": 0.0014,
      "step": 47590
    },
    {
      "epoch": 1.3599999999999999,
      "grad_norm": 0.04346602410078049,
      "learning_rate": 1.6000000000000003e-05,
      "loss": 0.0011,
      "step": 47600
    },
    {
      "epoch": 1.3602857142857143,
      "grad_norm": 0.0,
      "learning_rate": 1.5992857142857144e-05,
      "loss": 0.0023,
      "step": 47610
    },
    {
      "epoch": 1.3605714285714285,
      "grad_norm": 0.2288898080587387,
      "learning_rate": 1.5985714285714286e-05,
      "loss": 0.0022,
      "step": 47620
    },
    {
      "epoch": 1.3608571428571428,
      "grad_norm": 0.09064540266990662,
      "learning_rate": 1.5978571428571428e-05,
      "loss": 0.001,
      "step": 47630
    },
    {
      "epoch": 1.3611428571428572,
      "grad_norm": 0.1240788921713829,
      "learning_rate": 1.5971428571428573e-05,
      "loss": 0.0012,
      "step": 47640
    },
    {
      "epoch": 1.3614285714285714,
      "grad_norm": 0.0,
      "learning_rate": 1.5964285714285715e-05,
      "loss": 0.0004,
      "step": 47650
    },
    {
      "epoch": 1.3617142857142857,
      "grad_norm": 0.0406060665845871,
      "learning_rate": 1.5957142857142856e-05,
      "loss": 0.0013,
      "step": 47660
    },
    {
      "epoch": 1.362,
      "grad_norm": 0.14938683807849884,
      "learning_rate": 1.595e-05,
      "loss": 0.0017,
      "step": 47670
    },
    {
      "epoch": 1.3622857142857143,
      "grad_norm": 0.060557298362255096,
      "learning_rate": 1.5942857142857143e-05,
      "loss": 0.0013,
      "step": 47680
    },
    {
      "epoch": 1.3625714285714285,
      "grad_norm": 0.0,
      "learning_rate": 1.5935714285714288e-05,
      "loss": 0.0011,
      "step": 47690
    },
    {
      "epoch": 1.362857142857143,
      "grad_norm": 0.22641171514987946,
      "learning_rate": 1.592857142857143e-05,
      "loss": 0.0012,
      "step": 47700
    },
    {
      "epoch": 1.3631428571428572,
      "grad_norm": 0.0,
      "learning_rate": 1.5921428571428572e-05,
      "loss": 0.0017,
      "step": 47710
    },
    {
      "epoch": 1.3634285714285714,
      "grad_norm": 0.11289215087890625,
      "learning_rate": 1.5914285714285713e-05,
      "loss": 0.0017,
      "step": 47720
    },
    {
      "epoch": 1.3637142857142857,
      "grad_norm": 0.0415683276951313,
      "learning_rate": 1.5907142857142855e-05,
      "loss": 0.0006,
      "step": 47730
    },
    {
      "epoch": 1.3639999999999999,
      "grad_norm": 0.0,
      "learning_rate": 1.59e-05,
      "loss": 0.0008,
      "step": 47740
    },
    {
      "epoch": 1.3642857142857143,
      "grad_norm": 0.04186556860804558,
      "learning_rate": 1.5892857142857142e-05,
      "loss": 0.0011,
      "step": 47750
    },
    {
      "epoch": 1.3645714285714285,
      "grad_norm": 0.20959249138832092,
      "learning_rate": 1.5885714285714287e-05,
      "loss": 0.0028,
      "step": 47760
    },
    {
      "epoch": 1.3648571428571428,
      "grad_norm": 0.041890162974596024,
      "learning_rate": 1.587857142857143e-05,
      "loss": 0.0008,
      "step": 47770
    },
    {
      "epoch": 1.3651428571428572,
      "grad_norm": 0.13379019498825073,
      "learning_rate": 1.5871428571428574e-05,
      "loss": 0.0014,
      "step": 47780
    },
    {
      "epoch": 1.3654285714285714,
      "grad_norm": 0.0,
      "learning_rate": 1.5864285714285716e-05,
      "loss": 0.0011,
      "step": 47790
    },
    {
      "epoch": 1.3657142857142857,
      "grad_norm": 0.044220224022865295,
      "learning_rate": 1.5857142857142857e-05,
      "loss": 0.0009,
      "step": 47800
    },
    {
      "epoch": 1.366,
      "grad_norm": 0.0779709666967392,
      "learning_rate": 1.5850000000000002e-05,
      "loss": 0.002,
      "step": 47810
    },
    {
      "epoch": 1.3662857142857143,
      "grad_norm": 0.2340676188468933,
      "learning_rate": 1.5842857142857144e-05,
      "loss": 0.0012,
      "step": 47820
    },
    {
      "epoch": 1.3665714285714285,
      "grad_norm": 0.07938391715288162,
      "learning_rate": 1.5835714285714286e-05,
      "loss": 0.0015,
      "step": 47830
    },
    {
      "epoch": 1.366857142857143,
      "grad_norm": 0.0,
      "learning_rate": 1.5828571428571428e-05,
      "loss": 0.0007,
      "step": 47840
    },
    {
      "epoch": 1.3671428571428572,
      "grad_norm": 0.0,
      "learning_rate": 1.5821428571428573e-05,
      "loss": 0.0008,
      "step": 47850
    },
    {
      "epoch": 1.3674285714285714,
      "grad_norm": 0.03153650835156441,
      "learning_rate": 1.5814285714285714e-05,
      "loss": 0.0007,
      "step": 47860
    },
    {
      "epoch": 1.3677142857142857,
      "grad_norm": 0.04480598494410515,
      "learning_rate": 1.580714285714286e-05,
      "loss": 0.0004,
      "step": 47870
    },
    {
      "epoch": 1.3679999999999999,
      "grad_norm": 0.0,
      "learning_rate": 1.58e-05,
      "loss": 0.0008,
      "step": 47880
    },
    {
      "epoch": 1.3682857142857143,
      "grad_norm": 0.05584726482629776,
      "learning_rate": 1.5792857142857143e-05,
      "loss": 0.002,
      "step": 47890
    },
    {
      "epoch": 1.3685714285714285,
      "grad_norm": 0.04298894852399826,
      "learning_rate": 1.5785714285714288e-05,
      "loss": 0.0016,
      "step": 47900
    },
    {
      "epoch": 1.3688571428571428,
      "grad_norm": 0.07246007770299911,
      "learning_rate": 1.577857142857143e-05,
      "loss": 0.0015,
      "step": 47910
    },
    {
      "epoch": 1.3691428571428572,
      "grad_norm": 0.15019243955612183,
      "learning_rate": 1.577142857142857e-05,
      "loss": 0.0014,
      "step": 47920
    },
    {
      "epoch": 1.3694285714285714,
      "grad_norm": 0.09707660228013992,
      "learning_rate": 1.5764285714285713e-05,
      "loss": 0.0009,
      "step": 47930
    },
    {
      "epoch": 1.3697142857142857,
      "grad_norm": 0.24140553176403046,
      "learning_rate": 1.5757142857142858e-05,
      "loss": 0.0013,
      "step": 47940
    },
    {
      "epoch": 1.37,
      "grad_norm": 0.0,
      "learning_rate": 1.575e-05,
      "loss": 0.0005,
      "step": 47950
    },
    {
      "epoch": 1.3702857142857143,
      "grad_norm": 0.34571290016174316,
      "learning_rate": 1.574285714285714e-05,
      "loss": 0.0008,
      "step": 47960
    },
    {
      "epoch": 1.3705714285714286,
      "grad_norm": 0.10724817216396332,
      "learning_rate": 1.5735714285714287e-05,
      "loss": 0.0023,
      "step": 47970
    },
    {
      "epoch": 1.3708571428571428,
      "grad_norm": 0.0,
      "learning_rate": 1.572857142857143e-05,
      "loss": 0.0014,
      "step": 47980
    },
    {
      "epoch": 1.3711428571428572,
      "grad_norm": 0.0462588295340538,
      "learning_rate": 1.5721428571428574e-05,
      "loss": 0.001,
      "step": 47990
    },
    {
      "epoch": 1.3714285714285714,
      "grad_norm": 0.04780846834182739,
      "learning_rate": 1.5714285714285715e-05,
      "loss": 0.0014,
      "step": 48000
    },
    {
      "epoch": 1.3717142857142857,
      "grad_norm": 0.0,
      "learning_rate": 1.570714285714286e-05,
      "loss": 0.0012,
      "step": 48010
    },
    {
      "epoch": 1.3719999999999999,
      "grad_norm": 0.17978647351264954,
      "learning_rate": 1.5700000000000002e-05,
      "loss": 0.0011,
      "step": 48020
    },
    {
      "epoch": 1.3722857142857143,
      "grad_norm": 0.038876891136169434,
      "learning_rate": 1.5692857142857144e-05,
      "loss": 0.0006,
      "step": 48030
    },
    {
      "epoch": 1.3725714285714286,
      "grad_norm": 0.17933912575244904,
      "learning_rate": 1.5685714285714286e-05,
      "loss": 0.0013,
      "step": 48040
    },
    {
      "epoch": 1.3728571428571428,
      "grad_norm": 0.1300545334815979,
      "learning_rate": 1.5678571428571427e-05,
      "loss": 0.001,
      "step": 48050
    },
    {
      "epoch": 1.3731428571428572,
      "grad_norm": 0.05258049815893173,
      "learning_rate": 1.5671428571428572e-05,
      "loss": 0.0014,
      "step": 48060
    },
    {
      "epoch": 1.3734285714285714,
      "grad_norm": 0.08669118583202362,
      "learning_rate": 1.5664285714285714e-05,
      "loss": 0.0021,
      "step": 48070
    },
    {
      "epoch": 1.3737142857142857,
      "grad_norm": 0.0,
      "learning_rate": 1.565714285714286e-05,
      "loss": 0.0008,
      "step": 48080
    },
    {
      "epoch": 1.374,
      "grad_norm": 0.0377776063978672,
      "learning_rate": 1.565e-05,
      "loss": 0.0015,
      "step": 48090
    },
    {
      "epoch": 1.3742857142857143,
      "grad_norm": 0.10929332673549652,
      "learning_rate": 1.5642857142857143e-05,
      "loss": 0.0014,
      "step": 48100
    },
    {
      "epoch": 1.3745714285714286,
      "grad_norm": 0.050011374056339264,
      "learning_rate": 1.5635714285714288e-05,
      "loss": 0.0011,
      "step": 48110
    },
    {
      "epoch": 1.3748571428571428,
      "grad_norm": 0.051161449402570724,
      "learning_rate": 1.562857142857143e-05,
      "loss": 0.0014,
      "step": 48120
    },
    {
      "epoch": 1.3751428571428572,
      "grad_norm": 0.08835771679878235,
      "learning_rate": 1.5621428571428575e-05,
      "loss": 0.0016,
      "step": 48130
    },
    {
      "epoch": 1.3754285714285714,
      "grad_norm": 0.043833084404468536,
      "learning_rate": 1.5614285714285716e-05,
      "loss": 0.001,
      "step": 48140
    },
    {
      "epoch": 1.3757142857142857,
      "grad_norm": 0.0,
      "learning_rate": 1.5607142857142858e-05,
      "loss": 0.0005,
      "step": 48150
    },
    {
      "epoch": 1.376,
      "grad_norm": 0.0,
      "learning_rate": 1.56e-05,
      "loss": 0.0007,
      "step": 48160
    },
    {
      "epoch": 1.3762857142857143,
      "grad_norm": 0.13701604306697845,
      "learning_rate": 1.559285714285714e-05,
      "loss": 0.0004,
      "step": 48170
    },
    {
      "epoch": 1.3765714285714286,
      "grad_norm": 0.060216452926397324,
      "learning_rate": 1.5585714285714287e-05,
      "loss": 0.001,
      "step": 48180
    },
    {
      "epoch": 1.3768571428571428,
      "grad_norm": 0.08776052296161652,
      "learning_rate": 1.5578571428571428e-05,
      "loss": 0.0008,
      "step": 48190
    },
    {
      "epoch": 1.3771428571428572,
      "grad_norm": 0.04880325123667717,
      "learning_rate": 1.5571428571428573e-05,
      "loss": 0.0016,
      "step": 48200
    },
    {
      "epoch": 1.3774285714285714,
      "grad_norm": 0.058677393943071365,
      "learning_rate": 1.5564285714285715e-05,
      "loss": 0.0028,
      "step": 48210
    },
    {
      "epoch": 1.3777142857142857,
      "grad_norm": 0.09653852880001068,
      "learning_rate": 1.555714285714286e-05,
      "loss": 0.0012,
      "step": 48220
    },
    {
      "epoch": 1.3780000000000001,
      "grad_norm": 0.0,
      "learning_rate": 1.5550000000000002e-05,
      "loss": 0.0009,
      "step": 48230
    },
    {
      "epoch": 1.3782857142857143,
      "grad_norm": 0.043637003749608994,
      "learning_rate": 1.5542857142857144e-05,
      "loss": 0.0012,
      "step": 48240
    },
    {
      "epoch": 1.3785714285714286,
      "grad_norm": 0.3011247515678406,
      "learning_rate": 1.5535714285714285e-05,
      "loss": 0.001,
      "step": 48250
    },
    {
      "epoch": 1.3788571428571428,
      "grad_norm": 0.26459723711013794,
      "learning_rate": 1.5528571428571427e-05,
      "loss": 0.0013,
      "step": 48260
    },
    {
      "epoch": 1.3791428571428572,
      "grad_norm": 0.2193560153245926,
      "learning_rate": 1.5521428571428572e-05,
      "loss": 0.0007,
      "step": 48270
    },
    {
      "epoch": 1.3794285714285714,
      "grad_norm": 0.3395095765590668,
      "learning_rate": 1.5514285714285714e-05,
      "loss": 0.0016,
      "step": 48280
    },
    {
      "epoch": 1.3797142857142857,
      "grad_norm": 0.04313598945736885,
      "learning_rate": 1.550714285714286e-05,
      "loss": 0.001,
      "step": 48290
    },
    {
      "epoch": 1.38,
      "grad_norm": 0.08036674559116364,
      "learning_rate": 1.55e-05,
      "loss": 0.0012,
      "step": 48300
    },
    {
      "epoch": 1.3802857142857143,
      "grad_norm": 0.0,
      "learning_rate": 1.5492857142857142e-05,
      "loss": 0.0009,
      "step": 48310
    },
    {
      "epoch": 1.3805714285714286,
      "grad_norm": 0.025403447449207306,
      "learning_rate": 1.5485714285714287e-05,
      "loss": 0.0014,
      "step": 48320
    },
    {
      "epoch": 1.3808571428571428,
      "grad_norm": 0.15684793889522552,
      "learning_rate": 1.547857142857143e-05,
      "loss": 0.0016,
      "step": 48330
    },
    {
      "epoch": 1.3811428571428572,
      "grad_norm": 0.05265157297253609,
      "learning_rate": 1.5471428571428574e-05,
      "loss": 0.0025,
      "step": 48340
    },
    {
      "epoch": 1.3814285714285715,
      "grad_norm": 0.20315884053707123,
      "learning_rate": 1.5464285714285716e-05,
      "loss": 0.0014,
      "step": 48350
    },
    {
      "epoch": 1.3817142857142857,
      "grad_norm": 0.04118796065449715,
      "learning_rate": 1.5457142857142858e-05,
      "loss": 0.0011,
      "step": 48360
    },
    {
      "epoch": 1.3820000000000001,
      "grad_norm": 0.09196646511554718,
      "learning_rate": 1.545e-05,
      "loss": 0.0014,
      "step": 48370
    },
    {
      "epoch": 1.3822857142857143,
      "grad_norm": 0.048283807933330536,
      "learning_rate": 1.544285714285714e-05,
      "loss": 0.0012,
      "step": 48380
    },
    {
      "epoch": 1.3825714285714286,
      "grad_norm": 0.2478436827659607,
      "learning_rate": 1.5435714285714286e-05,
      "loss": 0.0007,
      "step": 48390
    },
    {
      "epoch": 1.3828571428571428,
      "grad_norm": 0.0,
      "learning_rate": 1.5428571428571428e-05,
      "loss": 0.0008,
      "step": 48400
    },
    {
      "epoch": 1.383142857142857,
      "grad_norm": 0.0,
      "learning_rate": 1.5421428571428573e-05,
      "loss": 0.0009,
      "step": 48410
    },
    {
      "epoch": 1.3834285714285715,
      "grad_norm": 0.02798229642212391,
      "learning_rate": 1.5414285714285715e-05,
      "loss": 0.0026,
      "step": 48420
    },
    {
      "epoch": 1.3837142857142857,
      "grad_norm": 0.0,
      "learning_rate": 1.540714285714286e-05,
      "loss": 0.0012,
      "step": 48430
    },
    {
      "epoch": 1.384,
      "grad_norm": 0.0,
      "learning_rate": 1.54e-05,
      "loss": 0.0011,
      "step": 48440
    },
    {
      "epoch": 1.3842857142857143,
      "grad_norm": 0.043191567063331604,
      "learning_rate": 1.5392857142857143e-05,
      "loss": 0.0008,
      "step": 48450
    },
    {
      "epoch": 1.3845714285714286,
      "grad_norm": 0.07683785259723663,
      "learning_rate": 1.5385714285714285e-05,
      "loss": 0.0007,
      "step": 48460
    },
    {
      "epoch": 1.3848571428571428,
      "grad_norm": 0.30421969294548035,
      "learning_rate": 1.5378571428571427e-05,
      "loss": 0.0014,
      "step": 48470
    },
    {
      "epoch": 1.3851428571428572,
      "grad_norm": 0.04448947310447693,
      "learning_rate": 1.5371428571428572e-05,
      "loss": 0.0013,
      "step": 48480
    },
    {
      "epoch": 1.3854285714285715,
      "grad_norm": 0.07675652951002121,
      "learning_rate": 1.5364285714285714e-05,
      "loss": 0.0015,
      "step": 48490
    },
    {
      "epoch": 1.3857142857142857,
      "grad_norm": 0.0,
      "learning_rate": 1.535714285714286e-05,
      "loss": 0.001,
      "step": 48500
    },
    {
      "epoch": 1.3860000000000001,
      "grad_norm": 0.05526166409254074,
      "learning_rate": 1.535e-05,
      "loss": 0.0012,
      "step": 48510
    },
    {
      "epoch": 1.3862857142857143,
      "grad_norm": 0.0,
      "learning_rate": 1.5342857142857146e-05,
      "loss": 0.0009,
      "step": 48520
    },
    {
      "epoch": 1.3865714285714286,
      "grad_norm": 0.028666028752923012,
      "learning_rate": 1.5335714285714287e-05,
      "loss": 0.0015,
      "step": 48530
    },
    {
      "epoch": 1.3868571428571428,
      "grad_norm": 0.05977445840835571,
      "learning_rate": 1.532857142857143e-05,
      "loss": 0.0008,
      "step": 48540
    },
    {
      "epoch": 1.387142857142857,
      "grad_norm": 0.27632853388786316,
      "learning_rate": 1.5321428571428574e-05,
      "loss": 0.0012,
      "step": 48550
    },
    {
      "epoch": 1.3874285714285715,
      "grad_norm": 0.0,
      "learning_rate": 1.5314285714285716e-05,
      "loss": 0.001,
      "step": 48560
    },
    {
      "epoch": 1.3877142857142857,
      "grad_norm": 0.05146908015012741,
      "learning_rate": 1.5307142857142857e-05,
      "loss": 0.0013,
      "step": 48570
    },
    {
      "epoch": 1.388,
      "grad_norm": 0.06721848249435425,
      "learning_rate": 1.53e-05,
      "loss": 0.0022,
      "step": 48580
    },
    {
      "epoch": 1.3882857142857143,
      "grad_norm": 0.1308247596025467,
      "learning_rate": 1.5292857142857144e-05,
      "loss": 0.0009,
      "step": 48590
    },
    {
      "epoch": 1.3885714285714286,
      "grad_norm": 0.0,
      "learning_rate": 1.5285714285714286e-05,
      "loss": 0.0007,
      "step": 48600
    },
    {
      "epoch": 1.3888571428571428,
      "grad_norm": 0.13387198746204376,
      "learning_rate": 1.5278571428571428e-05,
      "loss": 0.0012,
      "step": 48610
    },
    {
      "epoch": 1.3891428571428572,
      "grad_norm": 0.05233030021190643,
      "learning_rate": 1.5271428571428573e-05,
      "loss": 0.0011,
      "step": 48620
    },
    {
      "epoch": 1.3894285714285715,
      "grad_norm": 0.1208692416548729,
      "learning_rate": 1.5264285714285715e-05,
      "loss": 0.0011,
      "step": 48630
    },
    {
      "epoch": 1.3897142857142857,
      "grad_norm": 0.0,
      "learning_rate": 1.5257142857142858e-05,
      "loss": 0.0016,
      "step": 48640
    },
    {
      "epoch": 1.3900000000000001,
      "grad_norm": 0.04353184625506401,
      "learning_rate": 1.525e-05,
      "loss": 0.0011,
      "step": 48650
    },
    {
      "epoch": 1.3902857142857143,
      "grad_norm": 0.04795253276824951,
      "learning_rate": 1.5242857142857145e-05,
      "loss": 0.0012,
      "step": 48660
    },
    {
      "epoch": 1.3905714285714286,
      "grad_norm": 0.26880988478660583,
      "learning_rate": 1.5235714285714286e-05,
      "loss": 0.0019,
      "step": 48670
    },
    {
      "epoch": 1.3908571428571428,
      "grad_norm": 0.0,
      "learning_rate": 1.5228571428571428e-05,
      "loss": 0.0011,
      "step": 48680
    },
    {
      "epoch": 1.391142857142857,
      "grad_norm": 0.4327557384967804,
      "learning_rate": 1.5221428571428573e-05,
      "loss": 0.0018,
      "step": 48690
    },
    {
      "epoch": 1.3914285714285715,
      "grad_norm": 0.0,
      "learning_rate": 1.5214285714285715e-05,
      "loss": 0.0013,
      "step": 48700
    },
    {
      "epoch": 1.3917142857142857,
      "grad_norm": 0.07472915202379227,
      "learning_rate": 1.5207142857142858e-05,
      "loss": 0.0021,
      "step": 48710
    },
    {
      "epoch": 1.392,
      "grad_norm": 0.046381883323192596,
      "learning_rate": 1.52e-05,
      "loss": 0.0014,
      "step": 48720
    },
    {
      "epoch": 1.3922857142857143,
      "grad_norm": 0.07920017093420029,
      "learning_rate": 1.5192857142857145e-05,
      "loss": 0.0011,
      "step": 48730
    },
    {
      "epoch": 1.3925714285714286,
      "grad_norm": 0.1171317920088768,
      "learning_rate": 1.5185714285714287e-05,
      "loss": 0.0012,
      "step": 48740
    },
    {
      "epoch": 1.3928571428571428,
      "grad_norm": 0.04894985258579254,
      "learning_rate": 1.5178571428571429e-05,
      "loss": 0.0022,
      "step": 48750
    },
    {
      "epoch": 1.3931428571428572,
      "grad_norm": 0.04391172155737877,
      "learning_rate": 1.5171428571428572e-05,
      "loss": 0.0012,
      "step": 48760
    },
    {
      "epoch": 1.3934285714285715,
      "grad_norm": 0.042047739028930664,
      "learning_rate": 1.5164285714285714e-05,
      "loss": 0.001,
      "step": 48770
    },
    {
      "epoch": 1.3937142857142857,
      "grad_norm": 0.0,
      "learning_rate": 1.5157142857142859e-05,
      "loss": 0.0004,
      "step": 48780
    },
    {
      "epoch": 1.3940000000000001,
      "grad_norm": 0.05519866198301315,
      "learning_rate": 1.515e-05,
      "loss": 0.0009,
      "step": 48790
    },
    {
      "epoch": 1.3942857142857144,
      "grad_norm": 0.0,
      "learning_rate": 1.5142857142857144e-05,
      "loss": 0.0012,
      "step": 48800
    },
    {
      "epoch": 1.3945714285714286,
      "grad_norm": 0.0,
      "learning_rate": 1.5135714285714286e-05,
      "loss": 0.0013,
      "step": 48810
    },
    {
      "epoch": 1.3948571428571428,
      "grad_norm": 0.3394140303134918,
      "learning_rate": 1.5128571428571427e-05,
      "loss": 0.0019,
      "step": 48820
    },
    {
      "epoch": 1.395142857142857,
      "grad_norm": 0.2536022365093231,
      "learning_rate": 1.5121428571428573e-05,
      "loss": 0.0011,
      "step": 48830
    },
    {
      "epoch": 1.3954285714285715,
      "grad_norm": 0.14111441373825073,
      "learning_rate": 1.5114285714285714e-05,
      "loss": 0.0019,
      "step": 48840
    },
    {
      "epoch": 1.3957142857142857,
      "grad_norm": 0.04507780820131302,
      "learning_rate": 1.510714285714286e-05,
      "loss": 0.0015,
      "step": 48850
    },
    {
      "epoch": 1.396,
      "grad_norm": 0.09102080762386322,
      "learning_rate": 1.51e-05,
      "loss": 0.0013,
      "step": 48860
    },
    {
      "epoch": 1.3962857142857144,
      "grad_norm": 0.045076414942741394,
      "learning_rate": 1.5092857142857145e-05,
      "loss": 0.0009,
      "step": 48870
    },
    {
      "epoch": 1.3965714285714286,
      "grad_norm": 0.0,
      "learning_rate": 1.5085714285714286e-05,
      "loss": 0.001,
      "step": 48880
    },
    {
      "epoch": 1.3968571428571428,
      "grad_norm": 0.04406052455306053,
      "learning_rate": 1.5078571428571428e-05,
      "loss": 0.0018,
      "step": 48890
    },
    {
      "epoch": 1.3971428571428572,
      "grad_norm": 0.055870041251182556,
      "learning_rate": 1.5071428571428573e-05,
      "loss": 0.0008,
      "step": 48900
    },
    {
      "epoch": 1.3974285714285715,
      "grad_norm": 0.1679793894290924,
      "learning_rate": 1.5064285714285715e-05,
      "loss": 0.0006,
      "step": 48910
    },
    {
      "epoch": 1.3977142857142857,
      "grad_norm": 0.09034477174282074,
      "learning_rate": 1.5057142857142858e-05,
      "loss": 0.0011,
      "step": 48920
    },
    {
      "epoch": 1.3980000000000001,
      "grad_norm": 0.18034933507442474,
      "learning_rate": 1.505e-05,
      "loss": 0.0006,
      "step": 48930
    },
    {
      "epoch": 1.3982857142857144,
      "grad_norm": 0.049633242189884186,
      "learning_rate": 1.5042857142857145e-05,
      "loss": 0.0005,
      "step": 48940
    },
    {
      "epoch": 1.3985714285714286,
      "grad_norm": 0.19981029629707336,
      "learning_rate": 1.5035714285714287e-05,
      "loss": 0.0016,
      "step": 48950
    },
    {
      "epoch": 1.3988571428571428,
      "grad_norm": 0.06464926898479462,
      "learning_rate": 1.5028571428571428e-05,
      "loss": 0.0017,
      "step": 48960
    },
    {
      "epoch": 1.399142857142857,
      "grad_norm": 0.0,
      "learning_rate": 1.5021428571428572e-05,
      "loss": 0.0005,
      "step": 48970
    },
    {
      "epoch": 1.3994285714285715,
      "grad_norm": 0.284536749124527,
      "learning_rate": 1.5014285714285714e-05,
      "loss": 0.001,
      "step": 48980
    },
    {
      "epoch": 1.3997142857142857,
      "grad_norm": 0.0,
      "learning_rate": 1.5007142857142859e-05,
      "loss": 0.0013,
      "step": 48990
    },
    {
      "epoch": 1.4,
      "grad_norm": 0.0,
      "learning_rate": 1.5e-05,
      "loss": 0.0006,
      "step": 49000
    },
    {
      "epoch": 1.4002857142857144,
      "grad_norm": 0.0487862229347229,
      "learning_rate": 1.4992857142857144e-05,
      "loss": 0.001,
      "step": 49010
    },
    {
      "epoch": 1.4005714285714286,
      "grad_norm": 0.0,
      "learning_rate": 1.4985714285714286e-05,
      "loss": 0.0011,
      "step": 49020
    },
    {
      "epoch": 1.4008571428571428,
      "grad_norm": 0.0,
      "learning_rate": 1.4978571428571427e-05,
      "loss": 0.0009,
      "step": 49030
    },
    {
      "epoch": 1.4011428571428572,
      "grad_norm": 0.20063993334770203,
      "learning_rate": 1.4971428571428572e-05,
      "loss": 0.0005,
      "step": 49040
    },
    {
      "epoch": 1.4014285714285715,
      "grad_norm": 0.0,
      "learning_rate": 1.4964285714285714e-05,
      "loss": 0.0007,
      "step": 49050
    },
    {
      "epoch": 1.4017142857142857,
      "grad_norm": 0.04159514978528023,
      "learning_rate": 1.4957142857142859e-05,
      "loss": 0.0025,
      "step": 49060
    },
    {
      "epoch": 1.4020000000000001,
      "grad_norm": 0.04465923458337784,
      "learning_rate": 1.4950000000000001e-05,
      "loss": 0.0011,
      "step": 49070
    },
    {
      "epoch": 1.4022857142857144,
      "grad_norm": 0.0,
      "learning_rate": 1.4942857142857144e-05,
      "loss": 0.0006,
      "step": 49080
    },
    {
      "epoch": 1.4025714285714286,
      "grad_norm": 0.05345365032553673,
      "learning_rate": 1.4935714285714286e-05,
      "loss": 0.001,
      "step": 49090
    },
    {
      "epoch": 1.4028571428571428,
      "grad_norm": 0.0395110622048378,
      "learning_rate": 1.4928571428571431e-05,
      "loss": 0.0014,
      "step": 49100
    },
    {
      "epoch": 1.403142857142857,
      "grad_norm": 0.0,
      "learning_rate": 1.4921428571428573e-05,
      "loss": 0.0011,
      "step": 49110
    },
    {
      "epoch": 1.4034285714285715,
      "grad_norm": 0.17364944517612457,
      "learning_rate": 1.4914285714285715e-05,
      "loss": 0.0011,
      "step": 49120
    },
    {
      "epoch": 1.4037142857142857,
      "grad_norm": 0.0,
      "learning_rate": 1.4907142857142858e-05,
      "loss": 0.0006,
      "step": 49130
    },
    {
      "epoch": 1.404,
      "grad_norm": 0.0,
      "learning_rate": 1.49e-05,
      "loss": 0.0006,
      "step": 49140
    },
    {
      "epoch": 1.4042857142857144,
      "grad_norm": 0.0,
      "learning_rate": 1.4892857142857145e-05,
      "loss": 0.0009,
      "step": 49150
    },
    {
      "epoch": 1.4045714285714286,
      "grad_norm": 0.0,
      "learning_rate": 1.4885714285714286e-05,
      "loss": 0.0015,
      "step": 49160
    },
    {
      "epoch": 1.4048571428571428,
      "grad_norm": 0.0,
      "learning_rate": 1.487857142857143e-05,
      "loss": 0.0004,
      "step": 49170
    },
    {
      "epoch": 1.4051428571428572,
      "grad_norm": 0.11591294407844543,
      "learning_rate": 1.4871428571428572e-05,
      "loss": 0.0007,
      "step": 49180
    },
    {
      "epoch": 1.4054285714285715,
      "grad_norm": 0.049490250647068024,
      "learning_rate": 1.4864285714285713e-05,
      "loss": 0.0022,
      "step": 49190
    },
    {
      "epoch": 1.4057142857142857,
      "grad_norm": 0.04537365213036537,
      "learning_rate": 1.4857142857142858e-05,
      "loss": 0.0008,
      "step": 49200
    },
    {
      "epoch": 1.4060000000000001,
      "grad_norm": 0.04721038043498993,
      "learning_rate": 1.485e-05,
      "loss": 0.0003,
      "step": 49210
    },
    {
      "epoch": 1.4062857142857144,
      "grad_norm": 0.0,
      "learning_rate": 1.4842857142857145e-05,
      "loss": 0.0011,
      "step": 49220
    },
    {
      "epoch": 1.4065714285714286,
      "grad_norm": 0.09081129729747772,
      "learning_rate": 1.4835714285714287e-05,
      "loss": 0.0015,
      "step": 49230
    },
    {
      "epoch": 1.4068571428571428,
      "grad_norm": 0.027931632474064827,
      "learning_rate": 1.482857142857143e-05,
      "loss": 0.0011,
      "step": 49240
    },
    {
      "epoch": 1.407142857142857,
      "grad_norm": 0.044277697801589966,
      "learning_rate": 1.4821428571428572e-05,
      "loss": 0.001,
      "step": 49250
    },
    {
      "epoch": 1.4074285714285715,
      "grad_norm": 0.09804710745811462,
      "learning_rate": 1.4814285714285714e-05,
      "loss": 0.0009,
      "step": 49260
    },
    {
      "epoch": 1.4077142857142857,
      "grad_norm": 0.038926102221012115,
      "learning_rate": 1.4807142857142859e-05,
      "loss": 0.0015,
      "step": 49270
    },
    {
      "epoch": 1.408,
      "grad_norm": 0.09791399538516998,
      "learning_rate": 1.48e-05,
      "loss": 0.0006,
      "step": 49280
    },
    {
      "epoch": 1.4082857142857144,
      "grad_norm": 0.04192102327942848,
      "learning_rate": 1.4792857142857144e-05,
      "loss": 0.0017,
      "step": 49290
    },
    {
      "epoch": 1.4085714285714286,
      "grad_norm": 0.17228955030441284,
      "learning_rate": 1.4785714285714286e-05,
      "loss": 0.0005,
      "step": 49300
    },
    {
      "epoch": 1.4088571428571428,
      "grad_norm": 0.27172645926475525,
      "learning_rate": 1.477857142857143e-05,
      "loss": 0.0015,
      "step": 49310
    },
    {
      "epoch": 1.4091428571428573,
      "grad_norm": 0.3208346664905548,
      "learning_rate": 1.4771428571428573e-05,
      "loss": 0.0009,
      "step": 49320
    },
    {
      "epoch": 1.4094285714285715,
      "grad_norm": 0.0,
      "learning_rate": 1.4764285714285714e-05,
      "loss": 0.001,
      "step": 49330
    },
    {
      "epoch": 1.4097142857142857,
      "grad_norm": 0.0651131197810173,
      "learning_rate": 1.4757142857142858e-05,
      "loss": 0.0006,
      "step": 49340
    },
    {
      "epoch": 1.41,
      "grad_norm": 0.18733686208724976,
      "learning_rate": 1.475e-05,
      "loss": 0.0013,
      "step": 49350
    },
    {
      "epoch": 1.4102857142857144,
      "grad_norm": 0.0,
      "learning_rate": 1.4742857142857144e-05,
      "loss": 0.0013,
      "step": 49360
    },
    {
      "epoch": 1.4105714285714286,
      "grad_norm": 0.0,
      "learning_rate": 1.4735714285714286e-05,
      "loss": 0.0019,
      "step": 49370
    },
    {
      "epoch": 1.4108571428571428,
      "grad_norm": 0.03230966255068779,
      "learning_rate": 1.4728571428571431e-05,
      "loss": 0.0012,
      "step": 49380
    },
    {
      "epoch": 1.411142857142857,
      "grad_norm": 0.08345477283000946,
      "learning_rate": 1.4721428571428571e-05,
      "loss": 0.0021,
      "step": 49390
    },
    {
      "epoch": 1.4114285714285715,
      "grad_norm": 0.10656508803367615,
      "learning_rate": 1.4714285714285713e-05,
      "loss": 0.0002,
      "step": 49400
    },
    {
      "epoch": 1.4117142857142857,
      "grad_norm": 0.27807578444480896,
      "learning_rate": 1.4707142857142858e-05,
      "loss": 0.0013,
      "step": 49410
    },
    {
      "epoch": 1.412,
      "grad_norm": 0.14346596598625183,
      "learning_rate": 1.47e-05,
      "loss": 0.0017,
      "step": 49420
    },
    {
      "epoch": 1.4122857142857144,
      "grad_norm": 0.04410947486758232,
      "learning_rate": 1.4692857142857145e-05,
      "loss": 0.0011,
      "step": 49430
    },
    {
      "epoch": 1.4125714285714286,
      "grad_norm": 0.05577991530299187,
      "learning_rate": 1.4685714285714287e-05,
      "loss": 0.0012,
      "step": 49440
    },
    {
      "epoch": 1.4128571428571428,
      "grad_norm": 0.0641452893614769,
      "learning_rate": 1.467857142857143e-05,
      "loss": 0.001,
      "step": 49450
    },
    {
      "epoch": 1.4131428571428573,
      "grad_norm": 0.06273000687360764,
      "learning_rate": 1.4671428571428572e-05,
      "loss": 0.0016,
      "step": 49460
    },
    {
      "epoch": 1.4134285714285715,
      "grad_norm": 0.037504903972148895,
      "learning_rate": 1.4664285714285714e-05,
      "loss": 0.0009,
      "step": 49470
    },
    {
      "epoch": 1.4137142857142857,
      "grad_norm": 0.0650261715054512,
      "learning_rate": 1.4657142857142859e-05,
      "loss": 0.0012,
      "step": 49480
    },
    {
      "epoch": 1.414,
      "grad_norm": 0.04179697483778,
      "learning_rate": 1.465e-05,
      "loss": 0.0013,
      "step": 49490
    },
    {
      "epoch": 1.4142857142857144,
      "grad_norm": 0.2265676110982895,
      "learning_rate": 1.4642857142857144e-05,
      "loss": 0.0014,
      "step": 49500
    },
    {
      "epoch": 1.4145714285714286,
      "grad_norm": 0.167399063706398,
      "learning_rate": 1.4635714285714285e-05,
      "loss": 0.0008,
      "step": 49510
    },
    {
      "epoch": 1.4148571428571428,
      "grad_norm": 0.09643833339214325,
      "learning_rate": 1.462857142857143e-05,
      "loss": 0.0016,
      "step": 49520
    },
    {
      "epoch": 1.415142857142857,
      "grad_norm": 0.23712798953056335,
      "learning_rate": 1.4621428571428572e-05,
      "loss": 0.0016,
      "step": 49530
    },
    {
      "epoch": 1.4154285714285715,
      "grad_norm": 0.22759662568569183,
      "learning_rate": 1.4614285714285714e-05,
      "loss": 0.002,
      "step": 49540
    },
    {
      "epoch": 1.4157142857142857,
      "grad_norm": 0.1127861812710762,
      "learning_rate": 1.4607142857142857e-05,
      "loss": 0.0006,
      "step": 49550
    },
    {
      "epoch": 1.416,
      "grad_norm": 0.3352985978126526,
      "learning_rate": 1.4599999999999999e-05,
      "loss": 0.0025,
      "step": 49560
    },
    {
      "epoch": 1.4162857142857144,
      "grad_norm": 0.0,
      "learning_rate": 1.4592857142857144e-05,
      "loss": 0.0016,
      "step": 49570
    },
    {
      "epoch": 1.4165714285714286,
      "grad_norm": 0.0786653533577919,
      "learning_rate": 1.4585714285714286e-05,
      "loss": 0.0014,
      "step": 49580
    },
    {
      "epoch": 1.4168571428571428,
      "grad_norm": 0.23969638347625732,
      "learning_rate": 1.4578571428571431e-05,
      "loss": 0.0016,
      "step": 49590
    },
    {
      "epoch": 1.4171428571428573,
      "grad_norm": 0.04542747884988785,
      "learning_rate": 1.4571428571428573e-05,
      "loss": 0.0018,
      "step": 49600
    },
    {
      "epoch": 1.4174285714285715,
      "grad_norm": 0.0,
      "learning_rate": 1.4564285714285714e-05,
      "loss": 0.0013,
      "step": 49610
    },
    {
      "epoch": 1.4177142857142857,
      "grad_norm": 0.0,
      "learning_rate": 1.4557142857142858e-05,
      "loss": 0.0003,
      "step": 49620
    },
    {
      "epoch": 1.418,
      "grad_norm": 0.03192852810025215,
      "learning_rate": 1.455e-05,
      "loss": 0.0013,
      "step": 49630
    },
    {
      "epoch": 1.4182857142857141,
      "grad_norm": 0.08399230986833572,
      "learning_rate": 1.4542857142857145e-05,
      "loss": 0.0007,
      "step": 49640
    },
    {
      "epoch": 1.4185714285714286,
      "grad_norm": 0.16933998465538025,
      "learning_rate": 1.4535714285714286e-05,
      "loss": 0.0009,
      "step": 49650
    },
    {
      "epoch": 1.4188571428571428,
      "grad_norm": 0.20501451194286346,
      "learning_rate": 1.452857142857143e-05,
      "loss": 0.0009,
      "step": 49660
    },
    {
      "epoch": 1.419142857142857,
      "grad_norm": 0.09186284989118576,
      "learning_rate": 1.4521428571428572e-05,
      "loss": 0.0006,
      "step": 49670
    },
    {
      "epoch": 1.4194285714285715,
      "grad_norm": 0.0,
      "learning_rate": 1.4514285714285713e-05,
      "loss": 0.0009,
      "step": 49680
    },
    {
      "epoch": 1.4197142857142857,
      "grad_norm": 0.0,
      "learning_rate": 1.4507142857142858e-05,
      "loss": 0.0016,
      "step": 49690
    },
    {
      "epoch": 1.42,
      "grad_norm": 0.0,
      "learning_rate": 1.45e-05,
      "loss": 0.0012,
      "step": 49700
    },
    {
      "epoch": 1.4202857142857144,
      "grad_norm": 0.22132202982902527,
      "learning_rate": 1.4492857142857143e-05,
      "loss": 0.0012,
      "step": 49710
    },
    {
      "epoch": 1.4205714285714286,
      "grad_norm": 0.2177448868751526,
      "learning_rate": 1.4485714285714285e-05,
      "loss": 0.0019,
      "step": 49720
    },
    {
      "epoch": 1.4208571428571428,
      "grad_norm": 0.3927748501300812,
      "learning_rate": 1.447857142857143e-05,
      "loss": 0.0033,
      "step": 49730
    },
    {
      "epoch": 1.4211428571428573,
      "grad_norm": 0.0659119114279747,
      "learning_rate": 1.4471428571428572e-05,
      "loss": 0.002,
      "step": 49740
    },
    {
      "epoch": 1.4214285714285715,
      "grad_norm": 0.061297766864299774,
      "learning_rate": 1.4464285714285717e-05,
      "loss": 0.0015,
      "step": 49750
    },
    {
      "epoch": 1.4217142857142857,
      "grad_norm": 0.1215740442276001,
      "learning_rate": 1.4457142857142857e-05,
      "loss": 0.001,
      "step": 49760
    },
    {
      "epoch": 1.422,
      "grad_norm": 0.08382219076156616,
      "learning_rate": 1.4449999999999999e-05,
      "loss": 0.0001,
      "step": 49770
    },
    {
      "epoch": 1.4222857142857142,
      "grad_norm": 0.2415955662727356,
      "learning_rate": 1.4442857142857144e-05,
      "loss": 0.001,
      "step": 49780
    },
    {
      "epoch": 1.4225714285714286,
      "grad_norm": 0.13139529526233673,
      "learning_rate": 1.4435714285714286e-05,
      "loss": 0.0014,
      "step": 49790
    },
    {
      "epoch": 1.4228571428571428,
      "grad_norm": 0.06282153725624084,
      "learning_rate": 1.442857142857143e-05,
      "loss": 0.0025,
      "step": 49800
    },
    {
      "epoch": 1.423142857142857,
      "grad_norm": 0.07110947370529175,
      "learning_rate": 1.4421428571428573e-05,
      "loss": 0.0015,
      "step": 49810
    },
    {
      "epoch": 1.4234285714285715,
      "grad_norm": 0.08916033804416656,
      "learning_rate": 1.4414285714285716e-05,
      "loss": 0.0023,
      "step": 49820
    },
    {
      "epoch": 1.4237142857142857,
      "grad_norm": 0.0534057691693306,
      "learning_rate": 1.4407142857142858e-05,
      "loss": 0.001,
      "step": 49830
    },
    {
      "epoch": 1.424,
      "grad_norm": 0.049330271780490875,
      "learning_rate": 1.44e-05,
      "loss": 0.0015,
      "step": 49840
    },
    {
      "epoch": 1.4242857142857144,
      "grad_norm": 0.1634688824415207,
      "learning_rate": 1.4392857142857144e-05,
      "loss": 0.0014,
      "step": 49850
    },
    {
      "epoch": 1.4245714285714286,
      "grad_norm": 0.04658099263906479,
      "learning_rate": 1.4385714285714286e-05,
      "loss": 0.0014,
      "step": 49860
    },
    {
      "epoch": 1.4248571428571428,
      "grad_norm": 0.17010535299777985,
      "learning_rate": 1.437857142857143e-05,
      "loss": 0.0008,
      "step": 49870
    },
    {
      "epoch": 1.4251428571428573,
      "grad_norm": 0.0837567001581192,
      "learning_rate": 1.4371428571428571e-05,
      "loss": 0.0012,
      "step": 49880
    },
    {
      "epoch": 1.4254285714285715,
      "grad_norm": 0.29998376965522766,
      "learning_rate": 1.4364285714285716e-05,
      "loss": 0.0011,
      "step": 49890
    },
    {
      "epoch": 1.4257142857142857,
      "grad_norm": 0.09100964665412903,
      "learning_rate": 1.4357142857142858e-05,
      "loss": 0.0008,
      "step": 49900
    },
    {
      "epoch": 1.426,
      "grad_norm": 0.13276800513267517,
      "learning_rate": 1.435e-05,
      "loss": 0.0012,
      "step": 49910
    },
    {
      "epoch": 1.4262857142857142,
      "grad_norm": 0.12107066810131073,
      "learning_rate": 1.4342857142857143e-05,
      "loss": 0.001,
      "step": 49920
    },
    {
      "epoch": 1.4265714285714286,
      "grad_norm": 0.041801270097494125,
      "learning_rate": 1.4335714285714285e-05,
      "loss": 0.0016,
      "step": 49930
    },
    {
      "epoch": 1.4268571428571428,
      "grad_norm": 0.08000780642032623,
      "learning_rate": 1.432857142857143e-05,
      "loss": 0.0018,
      "step": 49940
    },
    {
      "epoch": 1.427142857142857,
      "grad_norm": 0.0853644460439682,
      "learning_rate": 1.4321428571428572e-05,
      "loss": 0.001,
      "step": 49950
    },
    {
      "epoch": 1.4274285714285715,
      "grad_norm": 0.04561346769332886,
      "learning_rate": 1.4314285714285717e-05,
      "loss": 0.0009,
      "step": 49960
    },
    {
      "epoch": 1.4277142857142857,
      "grad_norm": 0.2792421877384186,
      "learning_rate": 1.4307142857142859e-05,
      "loss": 0.0017,
      "step": 49970
    },
    {
      "epoch": 1.428,
      "grad_norm": 0.1935529261827469,
      "learning_rate": 1.43e-05,
      "loss": 0.0013,
      "step": 49980
    },
    {
      "epoch": 1.4282857142857144,
      "grad_norm": 0.23165230453014374,
      "learning_rate": 1.4292857142857144e-05,
      "loss": 0.0002,
      "step": 49990
    },
    {
      "epoch": 1.4285714285714286,
      "grad_norm": 0.08884734660387039,
      "learning_rate": 1.4285714285714285e-05,
      "loss": 0.0013,
      "step": 50000
    },
    {
      "epoch": 1.4288571428571428,
      "grad_norm": 0.14421869814395905,
      "learning_rate": 1.427857142857143e-05,
      "loss": 0.0012,
      "step": 50010
    },
    {
      "epoch": 1.4291428571428573,
      "grad_norm": 0.0,
      "learning_rate": 1.4271428571428572e-05,
      "loss": 0.0006,
      "step": 50020
    },
    {
      "epoch": 1.4294285714285715,
      "grad_norm": 0.11816080659627914,
      "learning_rate": 1.4264285714285716e-05,
      "loss": 0.0009,
      "step": 50030
    },
    {
      "epoch": 1.4297142857142857,
      "grad_norm": 0.0,
      "learning_rate": 1.4257142857142857e-05,
      "loss": 0.0012,
      "step": 50040
    },
    {
      "epoch": 1.43,
      "grad_norm": 0.0,
      "learning_rate": 1.4249999999999999e-05,
      "loss": 0.0009,
      "step": 50050
    },
    {
      "epoch": 1.4302857142857142,
      "grad_norm": 0.15871022641658783,
      "learning_rate": 1.4242857142857144e-05,
      "loss": 0.0009,
      "step": 50060
    },
    {
      "epoch": 1.4305714285714286,
      "grad_norm": 0.04676251485943794,
      "learning_rate": 1.4235714285714286e-05,
      "loss": 0.001,
      "step": 50070
    },
    {
      "epoch": 1.4308571428571428,
      "grad_norm": 0.27208444476127625,
      "learning_rate": 1.422857142857143e-05,
      "loss": 0.0009,
      "step": 50080
    },
    {
      "epoch": 1.431142857142857,
      "grad_norm": 0.2257043868303299,
      "learning_rate": 1.4221428571428571e-05,
      "loss": 0.0009,
      "step": 50090
    },
    {
      "epoch": 1.4314285714285715,
      "grad_norm": 0.0,
      "learning_rate": 1.4214285714285716e-05,
      "loss": 0.0017,
      "step": 50100
    },
    {
      "epoch": 1.4317142857142857,
      "grad_norm": 0.04514819011092186,
      "learning_rate": 1.4207142857142858e-05,
      "loss": 0.0013,
      "step": 50110
    },
    {
      "epoch": 1.432,
      "grad_norm": 0.039479222148656845,
      "learning_rate": 1.42e-05,
      "loss": 0.0008,
      "step": 50120
    },
    {
      "epoch": 1.4322857142857144,
      "grad_norm": 0.04684421047568321,
      "learning_rate": 1.4192857142857145e-05,
      "loss": 0.0005,
      "step": 50130
    },
    {
      "epoch": 1.4325714285714286,
      "grad_norm": 0.28445562720298767,
      "learning_rate": 1.4185714285714285e-05,
      "loss": 0.0009,
      "step": 50140
    },
    {
      "epoch": 1.4328571428571428,
      "grad_norm": 0.04476885125041008,
      "learning_rate": 1.417857142857143e-05,
      "loss": 0.0017,
      "step": 50150
    },
    {
      "epoch": 1.4331428571428573,
      "grad_norm": 0.032819949090480804,
      "learning_rate": 1.4171428571428572e-05,
      "loss": 0.0018,
      "step": 50160
    },
    {
      "epoch": 1.4334285714285715,
      "grad_norm": 0.05222037434577942,
      "learning_rate": 1.4164285714285717e-05,
      "loss": 0.0018,
      "step": 50170
    },
    {
      "epoch": 1.4337142857142857,
      "grad_norm": 0.050299134105443954,
      "learning_rate": 1.4157142857142858e-05,
      "loss": 0.0005,
      "step": 50180
    },
    {
      "epoch": 1.434,
      "grad_norm": 0.04149052873253822,
      "learning_rate": 1.415e-05,
      "loss": 0.0007,
      "step": 50190
    },
    {
      "epoch": 1.4342857142857142,
      "grad_norm": 0.23448969423770905,
      "learning_rate": 1.4142857142857143e-05,
      "loss": 0.0014,
      "step": 50200
    },
    {
      "epoch": 1.4345714285714286,
      "grad_norm": 0.13056612014770508,
      "learning_rate": 1.4135714285714285e-05,
      "loss": 0.0016,
      "step": 50210
    },
    {
      "epoch": 1.4348571428571428,
      "grad_norm": 0.2585764229297638,
      "learning_rate": 1.412857142857143e-05,
      "loss": 0.0011,
      "step": 50220
    },
    {
      "epoch": 1.435142857142857,
      "grad_norm": 0.0,
      "learning_rate": 1.4121428571428572e-05,
      "loss": 0.0014,
      "step": 50230
    },
    {
      "epoch": 1.4354285714285715,
      "grad_norm": 0.30137699842453003,
      "learning_rate": 1.4114285714285715e-05,
      "loss": 0.0011,
      "step": 50240
    },
    {
      "epoch": 1.4357142857142857,
      "grad_norm": 0.0,
      "learning_rate": 1.4107142857142857e-05,
      "loss": 0.0017,
      "step": 50250
    },
    {
      "epoch": 1.436,
      "grad_norm": 0.06316732615232468,
      "learning_rate": 1.4099999999999999e-05,
      "loss": 0.0015,
      "step": 50260
    },
    {
      "epoch": 1.4362857142857144,
      "grad_norm": 0.0441964752972126,
      "learning_rate": 1.4092857142857144e-05,
      "loss": 0.0007,
      "step": 50270
    },
    {
      "epoch": 1.4365714285714286,
      "grad_norm": 0.0625225082039833,
      "learning_rate": 1.4085714285714286e-05,
      "loss": 0.0017,
      "step": 50280
    },
    {
      "epoch": 1.4368571428571428,
      "grad_norm": 0.05093859136104584,
      "learning_rate": 1.4078571428571429e-05,
      "loss": 0.0009,
      "step": 50290
    },
    {
      "epoch": 1.4371428571428573,
      "grad_norm": 0.2039477676153183,
      "learning_rate": 1.407142857142857e-05,
      "loss": 0.0022,
      "step": 50300
    },
    {
      "epoch": 1.4374285714285715,
      "grad_norm": 0.0,
      "learning_rate": 1.4064285714285716e-05,
      "loss": 0.0012,
      "step": 50310
    },
    {
      "epoch": 1.4377142857142857,
      "grad_norm": 0.07193084061145782,
      "learning_rate": 1.4057142857142858e-05,
      "loss": 0.0007,
      "step": 50320
    },
    {
      "epoch": 1.438,
      "grad_norm": 0.0,
      "learning_rate": 1.4050000000000003e-05,
      "loss": 0.0016,
      "step": 50330
    },
    {
      "epoch": 1.4382857142857142,
      "grad_norm": 0.0901891440153122,
      "learning_rate": 1.4042857142857144e-05,
      "loss": 0.0014,
      "step": 50340
    },
    {
      "epoch": 1.4385714285714286,
      "grad_norm": 0.04753852263092995,
      "learning_rate": 1.4035714285714286e-05,
      "loss": 0.0017,
      "step": 50350
    },
    {
      "epoch": 1.4388571428571428,
      "grad_norm": 0.3003118634223938,
      "learning_rate": 1.402857142857143e-05,
      "loss": 0.0011,
      "step": 50360
    },
    {
      "epoch": 1.439142857142857,
      "grad_norm": 0.10495618730783463,
      "learning_rate": 1.4021428571428571e-05,
      "loss": 0.001,
      "step": 50370
    },
    {
      "epoch": 1.4394285714285715,
      "grad_norm": 0.1640462875366211,
      "learning_rate": 1.4014285714285716e-05,
      "loss": 0.0007,
      "step": 50380
    },
    {
      "epoch": 1.4397142857142857,
      "grad_norm": 0.08386054635047913,
      "learning_rate": 1.4007142857142858e-05,
      "loss": 0.0016,
      "step": 50390
    },
    {
      "epoch": 1.44,
      "grad_norm": 0.3365764021873474,
      "learning_rate": 1.4000000000000001e-05,
      "loss": 0.001,
      "step": 50400
    },
    {
      "epoch": 1.4402857142857144,
      "grad_norm": 0.0,
      "learning_rate": 1.3992857142857143e-05,
      "loss": 0.0005,
      "step": 50410
    },
    {
      "epoch": 1.4405714285714286,
      "grad_norm": 0.0,
      "learning_rate": 1.3985714285714285e-05,
      "loss": 0.001,
      "step": 50420
    },
    {
      "epoch": 1.4408571428571428,
      "grad_norm": 0.0,
      "learning_rate": 1.397857142857143e-05,
      "loss": 0.0025,
      "step": 50430
    },
    {
      "epoch": 1.4411428571428573,
      "grad_norm": 0.04685555025935173,
      "learning_rate": 1.3971428571428572e-05,
      "loss": 0.001,
      "step": 50440
    },
    {
      "epoch": 1.4414285714285715,
      "grad_norm": 0.047307051718235016,
      "learning_rate": 1.3964285714285715e-05,
      "loss": 0.0015,
      "step": 50450
    },
    {
      "epoch": 1.4417142857142857,
      "grad_norm": 0.02804427780210972,
      "learning_rate": 1.3957142857142857e-05,
      "loss": 0.0013,
      "step": 50460
    },
    {
      "epoch": 1.442,
      "grad_norm": 0.0,
      "learning_rate": 1.3950000000000002e-05,
      "loss": 0.0011,
      "step": 50470
    },
    {
      "epoch": 1.4422857142857142,
      "grad_norm": 0.07881058007478714,
      "learning_rate": 1.3942857142857144e-05,
      "loss": 0.0014,
      "step": 50480
    },
    {
      "epoch": 1.4425714285714286,
      "grad_norm": 0.0675806850194931,
      "learning_rate": 1.3935714285714285e-05,
      "loss": 0.0008,
      "step": 50490
    },
    {
      "epoch": 1.4428571428571428,
      "grad_norm": 0.057985834777355194,
      "learning_rate": 1.392857142857143e-05,
      "loss": 0.001,
      "step": 50500
    },
    {
      "epoch": 1.443142857142857,
      "grad_norm": 0.04182730242609978,
      "learning_rate": 1.3921428571428572e-05,
      "loss": 0.0019,
      "step": 50510
    },
    {
      "epoch": 1.4434285714285715,
      "grad_norm": 0.05642354488372803,
      "learning_rate": 1.3914285714285716e-05,
      "loss": 0.0017,
      "step": 50520
    },
    {
      "epoch": 1.4437142857142857,
      "grad_norm": 0.0,
      "learning_rate": 1.3907142857142857e-05,
      "loss": 0.0015,
      "step": 50530
    },
    {
      "epoch": 1.444,
      "grad_norm": 0.0441453717648983,
      "learning_rate": 1.3900000000000002e-05,
      "loss": 0.0004,
      "step": 50540
    },
    {
      "epoch": 1.4442857142857144,
      "grad_norm": 0.029347863048315048,
      "learning_rate": 1.3892857142857144e-05,
      "loss": 0.0002,
      "step": 50550
    },
    {
      "epoch": 1.4445714285714286,
      "grad_norm": 0.046141888946294785,
      "learning_rate": 1.3885714285714286e-05,
      "loss": 0.0014,
      "step": 50560
    },
    {
      "epoch": 1.4448571428571428,
      "grad_norm": 0.04218713566660881,
      "learning_rate": 1.387857142857143e-05,
      "loss": 0.0009,
      "step": 50570
    },
    {
      "epoch": 1.445142857142857,
      "grad_norm": 0.0,
      "learning_rate": 1.3871428571428571e-05,
      "loss": 0.0011,
      "step": 50580
    },
    {
      "epoch": 1.4454285714285715,
      "grad_norm": 0.0,
      "learning_rate": 1.3864285714285716e-05,
      "loss": 0.0013,
      "step": 50590
    },
    {
      "epoch": 1.4457142857142857,
      "grad_norm": 0.0,
      "learning_rate": 1.3857142857142858e-05,
      "loss": 0.0004,
      "step": 50600
    },
    {
      "epoch": 1.446,
      "grad_norm": 0.043515317142009735,
      "learning_rate": 1.3850000000000001e-05,
      "loss": 0.0008,
      "step": 50610
    },
    {
      "epoch": 1.4462857142857142,
      "grad_norm": 0.0,
      "learning_rate": 1.3842857142857143e-05,
      "loss": 0.0015,
      "step": 50620
    },
    {
      "epoch": 1.4465714285714286,
      "grad_norm": 0.04216441139578819,
      "learning_rate": 1.3835714285714285e-05,
      "loss": 0.0005,
      "step": 50630
    },
    {
      "epoch": 1.4468571428571428,
      "grad_norm": 0.047939006239175797,
      "learning_rate": 1.382857142857143e-05,
      "loss": 0.0007,
      "step": 50640
    },
    {
      "epoch": 1.447142857142857,
      "grad_norm": 0.05521022528409958,
      "learning_rate": 1.3821428571428571e-05,
      "loss": 0.0009,
      "step": 50650
    },
    {
      "epoch": 1.4474285714285715,
      "grad_norm": 0.0,
      "learning_rate": 1.3814285714285715e-05,
      "loss": 0.0009,
      "step": 50660
    },
    {
      "epoch": 1.4477142857142857,
      "grad_norm": 0.04303143918514252,
      "learning_rate": 1.3807142857142857e-05,
      "loss": 0.001,
      "step": 50670
    },
    {
      "epoch": 1.448,
      "grad_norm": 0.0,
      "learning_rate": 1.3800000000000002e-05,
      "loss": 0.0005,
      "step": 50680
    },
    {
      "epoch": 1.4482857142857144,
      "grad_norm": 0.09381068497896194,
      "learning_rate": 1.3792857142857143e-05,
      "loss": 0.0011,
      "step": 50690
    },
    {
      "epoch": 1.4485714285714286,
      "grad_norm": 0.0,
      "learning_rate": 1.3785714285714285e-05,
      "loss": 0.0008,
      "step": 50700
    },
    {
      "epoch": 1.4488571428571428,
      "grad_norm": 0.1605699509382248,
      "learning_rate": 1.377857142857143e-05,
      "loss": 0.0005,
      "step": 50710
    },
    {
      "epoch": 1.449142857142857,
      "grad_norm": 0.04122266545891762,
      "learning_rate": 1.3771428571428572e-05,
      "loss": 0.0011,
      "step": 50720
    },
    {
      "epoch": 1.4494285714285715,
      "grad_norm": 0.0914638563990593,
      "learning_rate": 1.3764285714285715e-05,
      "loss": 0.0012,
      "step": 50730
    },
    {
      "epoch": 1.4497142857142857,
      "grad_norm": 0.20476020872592926,
      "learning_rate": 1.3757142857142857e-05,
      "loss": 0.0009,
      "step": 50740
    },
    {
      "epoch": 1.45,
      "grad_norm": 0.0,
      "learning_rate": 1.3750000000000002e-05,
      "loss": 0.0014,
      "step": 50750
    },
    {
      "epoch": 1.4502857142857142,
      "grad_norm": 0.16021770238876343,
      "learning_rate": 1.3742857142857144e-05,
      "loss": 0.001,
      "step": 50760
    },
    {
      "epoch": 1.4505714285714286,
      "grad_norm": 0.2384800910949707,
      "learning_rate": 1.3735714285714286e-05,
      "loss": 0.0012,
      "step": 50770
    },
    {
      "epoch": 1.4508571428571428,
      "grad_norm": 0.05302847921848297,
      "learning_rate": 1.3728571428571429e-05,
      "loss": 0.0028,
      "step": 50780
    },
    {
      "epoch": 1.451142857142857,
      "grad_norm": 0.0,
      "learning_rate": 1.372142857142857e-05,
      "loss": 0.0008,
      "step": 50790
    },
    {
      "epoch": 1.4514285714285715,
      "grad_norm": 0.07028060406446457,
      "learning_rate": 1.3714285714285716e-05,
      "loss": 0.0015,
      "step": 50800
    },
    {
      "epoch": 1.4517142857142857,
      "grad_norm": 0.028364507481455803,
      "learning_rate": 1.3707142857142858e-05,
      "loss": 0.0009,
      "step": 50810
    },
    {
      "epoch": 1.452,
      "grad_norm": 0.14388509094715118,
      "learning_rate": 1.3700000000000001e-05,
      "loss": 0.0007,
      "step": 50820
    },
    {
      "epoch": 1.4522857142857144,
      "grad_norm": 0.25399667024612427,
      "learning_rate": 1.3692857142857143e-05,
      "loss": 0.001,
      "step": 50830
    },
    {
      "epoch": 1.4525714285714286,
      "grad_norm": 0.2920248806476593,
      "learning_rate": 1.3685714285714284e-05,
      "loss": 0.0007,
      "step": 50840
    },
    {
      "epoch": 1.4528571428571428,
      "grad_norm": 0.27123820781707764,
      "learning_rate": 1.367857142857143e-05,
      "loss": 0.0008,
      "step": 50850
    },
    {
      "epoch": 1.453142857142857,
      "grad_norm": 0.24675899744033813,
      "learning_rate": 1.3671428571428571e-05,
      "loss": 0.0007,
      "step": 50860
    },
    {
      "epoch": 1.4534285714285713,
      "grad_norm": 0.11103277653455734,
      "learning_rate": 1.3664285714285716e-05,
      "loss": 0.0015,
      "step": 50870
    },
    {
      "epoch": 1.4537142857142857,
      "grad_norm": 0.09058769792318344,
      "learning_rate": 1.3657142857142858e-05,
      "loss": 0.0017,
      "step": 50880
    },
    {
      "epoch": 1.454,
      "grad_norm": 0.18563523888587952,
      "learning_rate": 1.3650000000000001e-05,
      "loss": 0.0013,
      "step": 50890
    },
    {
      "epoch": 1.4542857142857142,
      "grad_norm": 0.05860469490289688,
      "learning_rate": 1.3642857142857143e-05,
      "loss": 0.0011,
      "step": 50900
    },
    {
      "epoch": 1.4545714285714286,
      "grad_norm": 0.20957224071025848,
      "learning_rate": 1.3635714285714285e-05,
      "loss": 0.001,
      "step": 50910
    },
    {
      "epoch": 1.4548571428571428,
      "grad_norm": 0.04434157535433769,
      "learning_rate": 1.362857142857143e-05,
      "loss": 0.001,
      "step": 50920
    },
    {
      "epoch": 1.455142857142857,
      "grad_norm": 0.030876750126481056,
      "learning_rate": 1.3621428571428572e-05,
      "loss": 0.0008,
      "step": 50930
    },
    {
      "epoch": 1.4554285714285715,
      "grad_norm": 0.12758639454841614,
      "learning_rate": 1.3614285714285715e-05,
      "loss": 0.0012,
      "step": 50940
    },
    {
      "epoch": 1.4557142857142857,
      "grad_norm": 0.24719570577144623,
      "learning_rate": 1.3607142857142857e-05,
      "loss": 0.0014,
      "step": 50950
    },
    {
      "epoch": 1.456,
      "grad_norm": 0.08525998890399933,
      "learning_rate": 1.3600000000000002e-05,
      "loss": 0.0011,
      "step": 50960
    },
    {
      "epoch": 1.4562857142857144,
      "grad_norm": 0.19138242304325104,
      "learning_rate": 1.3592857142857144e-05,
      "loss": 0.0007,
      "step": 50970
    },
    {
      "epoch": 1.4565714285714286,
      "grad_norm": 0.06745879352092743,
      "learning_rate": 1.3585714285714287e-05,
      "loss": 0.0011,
      "step": 50980
    },
    {
      "epoch": 1.4568571428571429,
      "grad_norm": 0.12610958516597748,
      "learning_rate": 1.3578571428571429e-05,
      "loss": 0.0012,
      "step": 50990
    },
    {
      "epoch": 1.457142857142857,
      "grad_norm": 0.13617496192455292,
      "learning_rate": 1.357142857142857e-05,
      "loss": 0.002,
      "step": 51000
    },
    {
      "epoch": 1.4574285714285713,
      "grad_norm": 0.0,
      "learning_rate": 1.3564285714285716e-05,
      "loss": 0.0007,
      "step": 51010
    },
    {
      "epoch": 1.4577142857142857,
      "grad_norm": 0.1140720546245575,
      "learning_rate": 1.3557142857142857e-05,
      "loss": 0.0009,
      "step": 51020
    },
    {
      "epoch": 1.458,
      "grad_norm": 0.08253706246614456,
      "learning_rate": 1.3550000000000002e-05,
      "loss": 0.0005,
      "step": 51030
    },
    {
      "epoch": 1.4582857142857142,
      "grad_norm": 0.11973239481449127,
      "learning_rate": 1.3542857142857142e-05,
      "loss": 0.0014,
      "step": 51040
    },
    {
      "epoch": 1.4585714285714286,
      "grad_norm": 0.08111249655485153,
      "learning_rate": 1.3535714285714288e-05,
      "loss": 0.0009,
      "step": 51050
    },
    {
      "epoch": 1.4588571428571429,
      "grad_norm": 0.15938971936702728,
      "learning_rate": 1.352857142857143e-05,
      "loss": 0.0014,
      "step": 51060
    },
    {
      "epoch": 1.459142857142857,
      "grad_norm": 0.03680066764354706,
      "learning_rate": 1.3521428571428571e-05,
      "loss": 0.0016,
      "step": 51070
    },
    {
      "epoch": 1.4594285714285715,
      "grad_norm": 0.047600001096725464,
      "learning_rate": 1.3514285714285716e-05,
      "loss": 0.0014,
      "step": 51080
    },
    {
      "epoch": 1.4597142857142857,
      "grad_norm": 0.0,
      "learning_rate": 1.3507142857142858e-05,
      "loss": 0.0011,
      "step": 51090
    },
    {
      "epoch": 1.46,
      "grad_norm": 0.08620826154947281,
      "learning_rate": 1.3500000000000001e-05,
      "loss": 0.0016,
      "step": 51100
    },
    {
      "epoch": 1.4602857142857144,
      "grad_norm": 0.0417463444173336,
      "learning_rate": 1.3492857142857143e-05,
      "loss": 0.0008,
      "step": 51110
    },
    {
      "epoch": 1.4605714285714286,
      "grad_norm": 0.255791574716568,
      "learning_rate": 1.3485714285714288e-05,
      "loss": 0.0004,
      "step": 51120
    },
    {
      "epoch": 1.4608571428571429,
      "grad_norm": 0.05265875905752182,
      "learning_rate": 1.347857142857143e-05,
      "loss": 0.001,
      "step": 51130
    },
    {
      "epoch": 1.461142857142857,
      "grad_norm": 0.0,
      "learning_rate": 1.3471428571428571e-05,
      "loss": 0.0016,
      "step": 51140
    },
    {
      "epoch": 1.4614285714285713,
      "grad_norm": 0.27632787823677063,
      "learning_rate": 1.3464285714285715e-05,
      "loss": 0.0015,
      "step": 51150
    },
    {
      "epoch": 1.4617142857142857,
      "grad_norm": 0.10350924730300903,
      "learning_rate": 1.3457142857142857e-05,
      "loss": 0.001,
      "step": 51160
    },
    {
      "epoch": 1.462,
      "grad_norm": 0.051005151122808456,
      "learning_rate": 1.3450000000000002e-05,
      "loss": 0.0007,
      "step": 51170
    },
    {
      "epoch": 1.4622857142857142,
      "grad_norm": 0.3237364888191223,
      "learning_rate": 1.3442857142857143e-05,
      "loss": 0.0015,
      "step": 51180
    },
    {
      "epoch": 1.4625714285714286,
      "grad_norm": 0.1240404024720192,
      "learning_rate": 1.3435714285714287e-05,
      "loss": 0.0011,
      "step": 51190
    },
    {
      "epoch": 1.4628571428571429,
      "grad_norm": 0.0,
      "learning_rate": 1.3428571428571429e-05,
      "loss": 0.0012,
      "step": 51200
    },
    {
      "epoch": 1.463142857142857,
      "grad_norm": 0.05234900489449501,
      "learning_rate": 1.342142857142857e-05,
      "loss": 0.0013,
      "step": 51210
    },
    {
      "epoch": 1.4634285714285715,
      "grad_norm": 0.30203619599342346,
      "learning_rate": 1.3414285714285715e-05,
      "loss": 0.0007,
      "step": 51220
    },
    {
      "epoch": 1.4637142857142857,
      "grad_norm": 0.24298729002475739,
      "learning_rate": 1.3407142857142857e-05,
      "loss": 0.0006,
      "step": 51230
    },
    {
      "epoch": 1.464,
      "grad_norm": 0.046205099672079086,
      "learning_rate": 1.3400000000000002e-05,
      "loss": 0.0008,
      "step": 51240
    },
    {
      "epoch": 1.4642857142857144,
      "grad_norm": 0.0641137957572937,
      "learning_rate": 1.3392857142857144e-05,
      "loss": 0.0012,
      "step": 51250
    },
    {
      "epoch": 1.4645714285714286,
      "grad_norm": 0.20766180753707886,
      "learning_rate": 1.3385714285714287e-05,
      "loss": 0.0009,
      "step": 51260
    },
    {
      "epoch": 1.4648571428571429,
      "grad_norm": 0.0,
      "learning_rate": 1.3378571428571429e-05,
      "loss": 0.0004,
      "step": 51270
    },
    {
      "epoch": 1.465142857142857,
      "grad_norm": 0.04987909272313118,
      "learning_rate": 1.337142857142857e-05,
      "loss": 0.0015,
      "step": 51280
    },
    {
      "epoch": 1.4654285714285713,
      "grad_norm": 0.18564574420452118,
      "learning_rate": 1.3364285714285716e-05,
      "loss": 0.0022,
      "step": 51290
    },
    {
      "epoch": 1.4657142857142857,
      "grad_norm": 0.046998996287584305,
      "learning_rate": 1.3357142857142858e-05,
      "loss": 0.0008,
      "step": 51300
    },
    {
      "epoch": 1.466,
      "grad_norm": 0.0,
      "learning_rate": 1.3350000000000001e-05,
      "loss": 0.0008,
      "step": 51310
    },
    {
      "epoch": 1.4662857142857142,
      "grad_norm": 0.057372596114873886,
      "learning_rate": 1.3342857142857143e-05,
      "loss": 0.0019,
      "step": 51320
    },
    {
      "epoch": 1.4665714285714286,
      "grad_norm": 0.04300600662827492,
      "learning_rate": 1.3335714285714288e-05,
      "loss": 0.0016,
      "step": 51330
    },
    {
      "epoch": 1.4668571428571429,
      "grad_norm": 0.08621086925268173,
      "learning_rate": 1.332857142857143e-05,
      "loss": 0.001,
      "step": 51340
    },
    {
      "epoch": 1.467142857142857,
      "grad_norm": 0.0,
      "learning_rate": 1.3321428571428571e-05,
      "loss": 0.0013,
      "step": 51350
    },
    {
      "epoch": 1.4674285714285715,
      "grad_norm": 0.0,
      "learning_rate": 1.3314285714285715e-05,
      "loss": 0.0009,
      "step": 51360
    },
    {
      "epoch": 1.4677142857142857,
      "grad_norm": 0.11711163818836212,
      "learning_rate": 1.3307142857142856e-05,
      "loss": 0.0013,
      "step": 51370
    },
    {
      "epoch": 1.468,
      "grad_norm": 0.1738944798707962,
      "learning_rate": 1.3300000000000001e-05,
      "loss": 0.0015,
      "step": 51380
    },
    {
      "epoch": 1.4682857142857144,
      "grad_norm": 0.049744315445423126,
      "learning_rate": 1.3292857142857143e-05,
      "loss": 0.0012,
      "step": 51390
    },
    {
      "epoch": 1.4685714285714286,
      "grad_norm": 0.5004181861877441,
      "learning_rate": 1.3285714285714288e-05,
      "loss": 0.0013,
      "step": 51400
    },
    {
      "epoch": 1.4688571428571429,
      "grad_norm": 0.0,
      "learning_rate": 1.327857142857143e-05,
      "loss": 0.0009,
      "step": 51410
    },
    {
      "epoch": 1.469142857142857,
      "grad_norm": 0.0,
      "learning_rate": 1.327142857142857e-05,
      "loss": 0.0018,
      "step": 51420
    },
    {
      "epoch": 1.4694285714285713,
      "grad_norm": 0.41344141960144043,
      "learning_rate": 1.3264285714285715e-05,
      "loss": 0.0018,
      "step": 51430
    },
    {
      "epoch": 1.4697142857142858,
      "grad_norm": 0.1353880614042282,
      "learning_rate": 1.3257142857142857e-05,
      "loss": 0.0009,
      "step": 51440
    },
    {
      "epoch": 1.47,
      "grad_norm": 0.07974688708782196,
      "learning_rate": 1.3250000000000002e-05,
      "loss": 0.0007,
      "step": 51450
    },
    {
      "epoch": 1.4702857142857142,
      "grad_norm": 0.04620739445090294,
      "learning_rate": 1.3242857142857144e-05,
      "loss": 0.0008,
      "step": 51460
    },
    {
      "epoch": 1.4705714285714286,
      "grad_norm": 0.05007603019475937,
      "learning_rate": 1.3235714285714287e-05,
      "loss": 0.0012,
      "step": 51470
    },
    {
      "epoch": 1.4708571428571429,
      "grad_norm": 0.2629694640636444,
      "learning_rate": 1.3228571428571429e-05,
      "loss": 0.0011,
      "step": 51480
    },
    {
      "epoch": 1.471142857142857,
      "grad_norm": 0.041693806648254395,
      "learning_rate": 1.322142857142857e-05,
      "loss": 0.0011,
      "step": 51490
    },
    {
      "epoch": 1.4714285714285715,
      "grad_norm": 0.0,
      "learning_rate": 1.3214285714285716e-05,
      "loss": 0.0009,
      "step": 51500
    },
    {
      "epoch": 1.4717142857142858,
      "grad_norm": 0.040738366544246674,
      "learning_rate": 1.3207142857142857e-05,
      "loss": 0.002,
      "step": 51510
    },
    {
      "epoch": 1.472,
      "grad_norm": 0.07197507470846176,
      "learning_rate": 1.32e-05,
      "loss": 0.0016,
      "step": 51520
    },
    {
      "epoch": 1.4722857142857144,
      "grad_norm": 0.09212452918291092,
      "learning_rate": 1.3192857142857142e-05,
      "loss": 0.0013,
      "step": 51530
    },
    {
      "epoch": 1.4725714285714286,
      "grad_norm": 0.04898298159241676,
      "learning_rate": 1.3185714285714287e-05,
      "loss": 0.0011,
      "step": 51540
    },
    {
      "epoch": 1.4728571428571429,
      "grad_norm": 0.09315771609544754,
      "learning_rate": 1.317857142857143e-05,
      "loss": 0.0016,
      "step": 51550
    },
    {
      "epoch": 1.473142857142857,
      "grad_norm": 0.0,
      "learning_rate": 1.3171428571428571e-05,
      "loss": 0.0012,
      "step": 51560
    },
    {
      "epoch": 1.4734285714285713,
      "grad_norm": 0.0,
      "learning_rate": 1.3164285714285714e-05,
      "loss": 0.0003,
      "step": 51570
    },
    {
      "epoch": 1.4737142857142858,
      "grad_norm": 0.43432489037513733,
      "learning_rate": 1.3157142857142856e-05,
      "loss": 0.0014,
      "step": 51580
    },
    {
      "epoch": 1.474,
      "grad_norm": 0.0,
      "learning_rate": 1.3150000000000001e-05,
      "loss": 0.0006,
      "step": 51590
    },
    {
      "epoch": 1.4742857142857142,
      "grad_norm": 0.042738981544971466,
      "learning_rate": 1.3142857142857143e-05,
      "loss": 0.0016,
      "step": 51600
    },
    {
      "epoch": 1.4745714285714286,
      "grad_norm": 0.4090021252632141,
      "learning_rate": 1.3135714285714288e-05,
      "loss": 0.0011,
      "step": 51610
    },
    {
      "epoch": 1.4748571428571429,
      "grad_norm": 0.0,
      "learning_rate": 1.312857142857143e-05,
      "loss": 0.0006,
      "step": 51620
    },
    {
      "epoch": 1.475142857142857,
      "grad_norm": 0.04807029664516449,
      "learning_rate": 1.3121428571428573e-05,
      "loss": 0.0015,
      "step": 51630
    },
    {
      "epoch": 1.4754285714285715,
      "grad_norm": 0.0425284281373024,
      "learning_rate": 1.3114285714285715e-05,
      "loss": 0.001,
      "step": 51640
    },
    {
      "epoch": 1.4757142857142858,
      "grad_norm": 0.0,
      "learning_rate": 1.3107142857142857e-05,
      "loss": 0.0013,
      "step": 51650
    },
    {
      "epoch": 1.476,
      "grad_norm": 0.16271959245204926,
      "learning_rate": 1.3100000000000002e-05,
      "loss": 0.0015,
      "step": 51660
    },
    {
      "epoch": 1.4762857142857144,
      "grad_norm": 0.44738563895225525,
      "learning_rate": 1.3092857142857143e-05,
      "loss": 0.0016,
      "step": 51670
    },
    {
      "epoch": 1.4765714285714286,
      "grad_norm": 0.127600759267807,
      "learning_rate": 1.3085714285714287e-05,
      "loss": 0.0015,
      "step": 51680
    },
    {
      "epoch": 1.4768571428571429,
      "grad_norm": 0.10121585428714752,
      "learning_rate": 1.3078571428571428e-05,
      "loss": 0.0014,
      "step": 51690
    },
    {
      "epoch": 1.477142857142857,
      "grad_norm": 0.0872468575835228,
      "learning_rate": 1.3071428571428574e-05,
      "loss": 0.0018,
      "step": 51700
    },
    {
      "epoch": 1.4774285714285713,
      "grad_norm": 0.16659663617610931,
      "learning_rate": 1.3064285714285715e-05,
      "loss": 0.0023,
      "step": 51710
    },
    {
      "epoch": 1.4777142857142858,
      "grad_norm": 0.0,
      "learning_rate": 1.3057142857142857e-05,
      "loss": 0.001,
      "step": 51720
    },
    {
      "epoch": 1.478,
      "grad_norm": 0.04552234709262848,
      "learning_rate": 1.305e-05,
      "loss": 0.0013,
      "step": 51730
    },
    {
      "epoch": 1.4782857142857142,
      "grad_norm": 0.0,
      "learning_rate": 1.3042857142857142e-05,
      "loss": 0.0011,
      "step": 51740
    },
    {
      "epoch": 1.4785714285714286,
      "grad_norm": 0.0,
      "learning_rate": 1.3035714285714287e-05,
      "loss": 0.0012,
      "step": 51750
    },
    {
      "epoch": 1.4788571428571429,
      "grad_norm": 0.07098669558763504,
      "learning_rate": 1.3028571428571429e-05,
      "loss": 0.0005,
      "step": 51760
    },
    {
      "epoch": 1.479142857142857,
      "grad_norm": 0.04266568273305893,
      "learning_rate": 1.3021428571428574e-05,
      "loss": 0.001,
      "step": 51770
    },
    {
      "epoch": 1.4794285714285715,
      "grad_norm": 0.37771841883659363,
      "learning_rate": 1.3014285714285716e-05,
      "loss": 0.0012,
      "step": 51780
    },
    {
      "epoch": 1.4797142857142858,
      "grad_norm": 0.046020928770303726,
      "learning_rate": 1.3007142857142856e-05,
      "loss": 0.0015,
      "step": 51790
    },
    {
      "epoch": 1.48,
      "grad_norm": 0.06111369654536247,
      "learning_rate": 1.3000000000000001e-05,
      "loss": 0.0009,
      "step": 51800
    },
    {
      "epoch": 1.4802857142857142,
      "grad_norm": 0.021609466522932053,
      "learning_rate": 1.2992857142857143e-05,
      "loss": 0.0016,
      "step": 51810
    },
    {
      "epoch": 1.4805714285714286,
      "grad_norm": 0.0,
      "learning_rate": 1.2985714285714288e-05,
      "loss": 0.0007,
      "step": 51820
    },
    {
      "epoch": 1.4808571428571429,
      "grad_norm": 0.08094235509634018,
      "learning_rate": 1.297857142857143e-05,
      "loss": 0.0014,
      "step": 51830
    },
    {
      "epoch": 1.481142857142857,
      "grad_norm": 0.04427483677864075,
      "learning_rate": 1.2971428571428573e-05,
      "loss": 0.0014,
      "step": 51840
    },
    {
      "epoch": 1.4814285714285713,
      "grad_norm": 0.05586756765842438,
      "learning_rate": 1.2964285714285715e-05,
      "loss": 0.0011,
      "step": 51850
    },
    {
      "epoch": 1.4817142857142858,
      "grad_norm": 0.10346047580242157,
      "learning_rate": 1.2957142857142856e-05,
      "loss": 0.0004,
      "step": 51860
    },
    {
      "epoch": 1.482,
      "grad_norm": 0.3358008563518524,
      "learning_rate": 1.2950000000000001e-05,
      "loss": 0.0013,
      "step": 51870
    },
    {
      "epoch": 1.4822857142857142,
      "grad_norm": 0.0,
      "learning_rate": 1.2942857142857143e-05,
      "loss": 0.0008,
      "step": 51880
    },
    {
      "epoch": 1.4825714285714287,
      "grad_norm": 0.20407262444496155,
      "learning_rate": 1.2935714285714286e-05,
      "loss": 0.002,
      "step": 51890
    },
    {
      "epoch": 1.4828571428571429,
      "grad_norm": 0.04863090440630913,
      "learning_rate": 1.2928571428571428e-05,
      "loss": 0.0016,
      "step": 51900
    },
    {
      "epoch": 1.483142857142857,
      "grad_norm": 0.0456613227725029,
      "learning_rate": 1.2921428571428573e-05,
      "loss": 0.0012,
      "step": 51910
    },
    {
      "epoch": 1.4834285714285715,
      "grad_norm": 0.2093895673751831,
      "learning_rate": 1.2914285714285715e-05,
      "loss": 0.0017,
      "step": 51920
    },
    {
      "epoch": 1.4837142857142858,
      "grad_norm": 0.0859614834189415,
      "learning_rate": 1.2907142857142857e-05,
      "loss": 0.0008,
      "step": 51930
    },
    {
      "epoch": 1.484,
      "grad_norm": 0.04817478731274605,
      "learning_rate": 1.29e-05,
      "loss": 0.001,
      "step": 51940
    },
    {
      "epoch": 1.4842857142857142,
      "grad_norm": 0.07648202776908875,
      "learning_rate": 1.2892857142857142e-05,
      "loss": 0.0011,
      "step": 51950
    },
    {
      "epoch": 1.4845714285714287,
      "grad_norm": 0.04475519806146622,
      "learning_rate": 1.2885714285714287e-05,
      "loss": 0.0007,
      "step": 51960
    },
    {
      "epoch": 1.4848571428571429,
      "grad_norm": 0.0,
      "learning_rate": 1.2878571428571429e-05,
      "loss": 0.0011,
      "step": 51970
    },
    {
      "epoch": 1.485142857142857,
      "grad_norm": 0.0506436713039875,
      "learning_rate": 1.2871428571428574e-05,
      "loss": 0.0017,
      "step": 51980
    },
    {
      "epoch": 1.4854285714285713,
      "grad_norm": 0.1489572376012802,
      "learning_rate": 1.2864285714285716e-05,
      "loss": 0.0013,
      "step": 51990
    },
    {
      "epoch": 1.4857142857142858,
      "grad_norm": 0.10802073776721954,
      "learning_rate": 1.2857142857142857e-05,
      "loss": 0.0009,
      "step": 52000
    },
    {
      "epoch": 1.486,
      "grad_norm": 0.0,
      "learning_rate": 1.285e-05,
      "loss": 0.001,
      "step": 52010
    },
    {
      "epoch": 1.4862857142857142,
      "grad_norm": 0.283414751291275,
      "learning_rate": 1.2842857142857142e-05,
      "loss": 0.0017,
      "step": 52020
    },
    {
      "epoch": 1.4865714285714287,
      "grad_norm": 0.04816322401165962,
      "learning_rate": 1.2835714285714287e-05,
      "loss": 0.0012,
      "step": 52030
    },
    {
      "epoch": 1.4868571428571429,
      "grad_norm": 0.0,
      "learning_rate": 1.282857142857143e-05,
      "loss": 0.0015,
      "step": 52040
    },
    {
      "epoch": 1.487142857142857,
      "grad_norm": 0.04807249456644058,
      "learning_rate": 1.2821428571428573e-05,
      "loss": 0.0012,
      "step": 52050
    },
    {
      "epoch": 1.4874285714285715,
      "grad_norm": 0.04989740625023842,
      "learning_rate": 1.2814285714285714e-05,
      "loss": 0.0013,
      "step": 52060
    },
    {
      "epoch": 1.4877142857142858,
      "grad_norm": 0.0,
      "learning_rate": 1.2807142857142856e-05,
      "loss": 0.0004,
      "step": 52070
    },
    {
      "epoch": 1.488,
      "grad_norm": 0.0,
      "learning_rate": 1.2800000000000001e-05,
      "loss": 0.0008,
      "step": 52080
    },
    {
      "epoch": 1.4882857142857142,
      "grad_norm": 0.05133615434169769,
      "learning_rate": 1.2792857142857143e-05,
      "loss": 0.0012,
      "step": 52090
    },
    {
      "epoch": 1.4885714285714284,
      "grad_norm": 0.056966058909893036,
      "learning_rate": 1.2785714285714286e-05,
      "loss": 0.0004,
      "step": 52100
    },
    {
      "epoch": 1.4888571428571429,
      "grad_norm": 0.0,
      "learning_rate": 1.2778571428571428e-05,
      "loss": 0.0008,
      "step": 52110
    },
    {
      "epoch": 1.489142857142857,
      "grad_norm": 0.09493382275104523,
      "learning_rate": 1.2771428571428573e-05,
      "loss": 0.001,
      "step": 52120
    },
    {
      "epoch": 1.4894285714285713,
      "grad_norm": 0.09289143234491348,
      "learning_rate": 1.2764285714285715e-05,
      "loss": 0.002,
      "step": 52130
    },
    {
      "epoch": 1.4897142857142858,
      "grad_norm": 0.20937901735305786,
      "learning_rate": 1.2757142857142856e-05,
      "loss": 0.0013,
      "step": 52140
    },
    {
      "epoch": 1.49,
      "grad_norm": 0.12868891656398773,
      "learning_rate": 1.2750000000000002e-05,
      "loss": 0.001,
      "step": 52150
    },
    {
      "epoch": 1.4902857142857142,
      "grad_norm": 0.0,
      "learning_rate": 1.2742857142857143e-05,
      "loss": 0.0006,
      "step": 52160
    },
    {
      "epoch": 1.4905714285714287,
      "grad_norm": 0.03954174742102623,
      "learning_rate": 1.2735714285714287e-05,
      "loss": 0.0012,
      "step": 52170
    },
    {
      "epoch": 1.4908571428571429,
      "grad_norm": 0.05193693935871124,
      "learning_rate": 1.2728571428571428e-05,
      "loss": 0.0008,
      "step": 52180
    },
    {
      "epoch": 1.491142857142857,
      "grad_norm": 0.12668396532535553,
      "learning_rate": 1.2721428571428574e-05,
      "loss": 0.0008,
      "step": 52190
    },
    {
      "epoch": 1.4914285714285715,
      "grad_norm": 0.12297260016202927,
      "learning_rate": 1.2714285714285715e-05,
      "loss": 0.0019,
      "step": 52200
    },
    {
      "epoch": 1.4917142857142858,
      "grad_norm": 0.11980368196964264,
      "learning_rate": 1.2707142857142859e-05,
      "loss": 0.0017,
      "step": 52210
    },
    {
      "epoch": 1.492,
      "grad_norm": 0.05936158448457718,
      "learning_rate": 1.27e-05,
      "loss": 0.0011,
      "step": 52220
    },
    {
      "epoch": 1.4922857142857142,
      "grad_norm": 0.20782047510147095,
      "learning_rate": 1.2692857142857142e-05,
      "loss": 0.0008,
      "step": 52230
    },
    {
      "epoch": 1.4925714285714284,
      "grad_norm": 0.0,
      "learning_rate": 1.2685714285714287e-05,
      "loss": 0.0006,
      "step": 52240
    },
    {
      "epoch": 1.4928571428571429,
      "grad_norm": 0.04590994864702225,
      "learning_rate": 1.2678571428571429e-05,
      "loss": 0.0018,
      "step": 52250
    },
    {
      "epoch": 1.493142857142857,
      "grad_norm": 0.030621374025940895,
      "learning_rate": 1.2671428571428572e-05,
      "loss": 0.0009,
      "step": 52260
    },
    {
      "epoch": 1.4934285714285713,
      "grad_norm": 0.23194724321365356,
      "learning_rate": 1.2664285714285714e-05,
      "loss": 0.0016,
      "step": 52270
    },
    {
      "epoch": 1.4937142857142858,
      "grad_norm": 0.04107452556490898,
      "learning_rate": 1.2657142857142859e-05,
      "loss": 0.0012,
      "step": 52280
    },
    {
      "epoch": 1.494,
      "grad_norm": 0.08751744031906128,
      "learning_rate": 1.2650000000000001e-05,
      "loss": 0.0008,
      "step": 52290
    },
    {
      "epoch": 1.4942857142857142,
      "grad_norm": 0.0,
      "learning_rate": 1.2642857142857143e-05,
      "loss": 0.0008,
      "step": 52300
    },
    {
      "epoch": 1.4945714285714287,
      "grad_norm": 0.0,
      "learning_rate": 1.2635714285714288e-05,
      "loss": 0.0008,
      "step": 52310
    },
    {
      "epoch": 1.4948571428571429,
      "grad_norm": 0.0,
      "learning_rate": 1.2628571428571428e-05,
      "loss": 0.0017,
      "step": 52320
    },
    {
      "epoch": 1.495142857142857,
      "grad_norm": 0.051981184631586075,
      "learning_rate": 1.2621428571428573e-05,
      "loss": 0.0009,
      "step": 52330
    },
    {
      "epoch": 1.4954285714285716,
      "grad_norm": 0.04878270998597145,
      "learning_rate": 1.2614285714285715e-05,
      "loss": 0.0007,
      "step": 52340
    },
    {
      "epoch": 1.4957142857142858,
      "grad_norm": 0.06025272607803345,
      "learning_rate": 1.260714285714286e-05,
      "loss": 0.001,
      "step": 52350
    },
    {
      "epoch": 1.496,
      "grad_norm": 0.04608861356973648,
      "learning_rate": 1.2600000000000001e-05,
      "loss": 0.0015,
      "step": 52360
    },
    {
      "epoch": 1.4962857142857142,
      "grad_norm": 0.0,
      "learning_rate": 1.2592857142857143e-05,
      "loss": 0.0005,
      "step": 52370
    },
    {
      "epoch": 1.4965714285714284,
      "grad_norm": 0.08056876063346863,
      "learning_rate": 1.2585714285714286e-05,
      "loss": 0.0007,
      "step": 52380
    },
    {
      "epoch": 1.4968571428571429,
      "grad_norm": 0.11625253409147263,
      "learning_rate": 1.2578571428571428e-05,
      "loss": 0.0005,
      "step": 52390
    },
    {
      "epoch": 1.497142857142857,
      "grad_norm": 0.14274044334888458,
      "learning_rate": 1.2571428571428573e-05,
      "loss": 0.0012,
      "step": 52400
    },
    {
      "epoch": 1.4974285714285713,
      "grad_norm": 0.28491953015327454,
      "learning_rate": 1.2564285714285715e-05,
      "loss": 0.0009,
      "step": 52410
    },
    {
      "epoch": 1.4977142857142858,
      "grad_norm": 0.08837699890136719,
      "learning_rate": 1.2557142857142858e-05,
      "loss": 0.0019,
      "step": 52420
    },
    {
      "epoch": 1.498,
      "grad_norm": 0.10594652593135834,
      "learning_rate": 1.255e-05,
      "loss": 0.0013,
      "step": 52430
    },
    {
      "epoch": 1.4982857142857142,
      "grad_norm": 0.0,
      "learning_rate": 1.2542857142857142e-05,
      "loss": 0.001,
      "step": 52440
    },
    {
      "epoch": 1.4985714285714287,
      "grad_norm": 0.17700976133346558,
      "learning_rate": 1.2535714285714287e-05,
      "loss": 0.001,
      "step": 52450
    },
    {
      "epoch": 1.4988571428571429,
      "grad_norm": 0.05453141778707504,
      "learning_rate": 1.2528571428571429e-05,
      "loss": 0.001,
      "step": 52460
    },
    {
      "epoch": 1.499142857142857,
      "grad_norm": 0.040009453892707825,
      "learning_rate": 1.2521428571428572e-05,
      "loss": 0.0011,
      "step": 52470
    },
    {
      "epoch": 1.4994285714285716,
      "grad_norm": 0.0,
      "learning_rate": 1.2514285714285714e-05,
      "loss": 0.0008,
      "step": 52480
    },
    {
      "epoch": 1.4997142857142858,
      "grad_norm": 0.0484091155230999,
      "learning_rate": 1.2507142857142859e-05,
      "loss": 0.0014,
      "step": 52490
    },
    {
      "epoch": 1.5,
      "grad_norm": 0.040786828845739365,
      "learning_rate": 1.25e-05,
      "loss": 0.0011,
      "step": 52500
    },
    {
      "epoch": 1.5002857142857144,
      "grad_norm": 0.08388592302799225,
      "learning_rate": 1.2492857142857144e-05,
      "loss": 0.001,
      "step": 52510
    },
    {
      "epoch": 1.5005714285714284,
      "grad_norm": 0.21669776737689972,
      "learning_rate": 1.2485714285714287e-05,
      "loss": 0.0011,
      "step": 52520
    },
    {
      "epoch": 1.500857142857143,
      "grad_norm": 0.16749295592308044,
      "learning_rate": 1.2478571428571429e-05,
      "loss": 0.0011,
      "step": 52530
    },
    {
      "epoch": 1.5011428571428571,
      "grad_norm": 0.10996716469526291,
      "learning_rate": 1.2471428571428571e-05,
      "loss": 0.0005,
      "step": 52540
    },
    {
      "epoch": 1.5014285714285713,
      "grad_norm": 0.08194971829652786,
      "learning_rate": 1.2464285714285714e-05,
      "loss": 0.0004,
      "step": 52550
    },
    {
      "epoch": 1.5017142857142858,
      "grad_norm": 0.0,
      "learning_rate": 1.2457142857142858e-05,
      "loss": 0.0007,
      "step": 52560
    },
    {
      "epoch": 1.502,
      "grad_norm": 0.04614219814538956,
      "learning_rate": 1.2450000000000001e-05,
      "loss": 0.0009,
      "step": 52570
    },
    {
      "epoch": 1.5022857142857142,
      "grad_norm": 0.04127068817615509,
      "learning_rate": 1.2442857142857143e-05,
      "loss": 0.0011,
      "step": 52580
    },
    {
      "epoch": 1.5025714285714287,
      "grad_norm": 0.22380775213241577,
      "learning_rate": 1.2435714285714286e-05,
      "loss": 0.0018,
      "step": 52590
    },
    {
      "epoch": 1.502857142857143,
      "grad_norm": 0.059567805379629135,
      "learning_rate": 1.242857142857143e-05,
      "loss": 0.0014,
      "step": 52600
    },
    {
      "epoch": 1.5031428571428571,
      "grad_norm": 0.0,
      "learning_rate": 1.2421428571428571e-05,
      "loss": 0.0004,
      "step": 52610
    },
    {
      "epoch": 1.5034285714285716,
      "grad_norm": 0.08952756971120834,
      "learning_rate": 1.2414285714285715e-05,
      "loss": 0.0008,
      "step": 52620
    },
    {
      "epoch": 1.5037142857142856,
      "grad_norm": 0.11741860210895538,
      "learning_rate": 1.2407142857142858e-05,
      "loss": 0.0011,
      "step": 52630
    },
    {
      "epoch": 1.504,
      "grad_norm": 0.18171532452106476,
      "learning_rate": 1.24e-05,
      "loss": 0.0004,
      "step": 52640
    },
    {
      "epoch": 1.5042857142857144,
      "grad_norm": 0.0386977419257164,
      "learning_rate": 1.2392857142857143e-05,
      "loss": 0.0014,
      "step": 52650
    },
    {
      "epoch": 1.5045714285714284,
      "grad_norm": 0.0,
      "learning_rate": 1.2385714285714287e-05,
      "loss": 0.0007,
      "step": 52660
    },
    {
      "epoch": 1.504857142857143,
      "grad_norm": 0.0,
      "learning_rate": 1.237857142857143e-05,
      "loss": 0.0002,
      "step": 52670
    },
    {
      "epoch": 1.5051428571428571,
      "grad_norm": 0.0520341694355011,
      "learning_rate": 1.2371428571428574e-05,
      "loss": 0.0007,
      "step": 52680
    },
    {
      "epoch": 1.5054285714285713,
      "grad_norm": 0.04121044650673866,
      "learning_rate": 1.2364285714285714e-05,
      "loss": 0.0005,
      "step": 52690
    },
    {
      "epoch": 1.5057142857142858,
      "grad_norm": 0.06721855700016022,
      "learning_rate": 1.2357142857142857e-05,
      "loss": 0.0003,
      "step": 52700
    },
    {
      "epoch": 1.506,
      "grad_norm": 0.08500856161117554,
      "learning_rate": 1.235e-05,
      "loss": 0.0006,
      "step": 52710
    },
    {
      "epoch": 1.5062857142857142,
      "grad_norm": 0.05422145500779152,
      "learning_rate": 1.2342857142857144e-05,
      "loss": 0.0011,
      "step": 52720
    },
    {
      "epoch": 1.5065714285714287,
      "grad_norm": 0.0,
      "learning_rate": 1.2335714285714287e-05,
      "loss": 0.0004,
      "step": 52730
    },
    {
      "epoch": 1.506857142857143,
      "grad_norm": 0.28057196736335754,
      "learning_rate": 1.2328571428571429e-05,
      "loss": 0.0023,
      "step": 52740
    },
    {
      "epoch": 1.5071428571428571,
      "grad_norm": 0.0,
      "learning_rate": 1.2321428571428572e-05,
      "loss": 0.0013,
      "step": 52750
    },
    {
      "epoch": 1.5074285714285716,
      "grad_norm": 0.0,
      "learning_rate": 1.2314285714285714e-05,
      "loss": 0.0011,
      "step": 52760
    },
    {
      "epoch": 1.5077142857142856,
      "grad_norm": 0.22686311602592468,
      "learning_rate": 1.2307142857142857e-05,
      "loss": 0.0013,
      "step": 52770
    },
    {
      "epoch": 1.508,
      "grad_norm": 0.13233958184719086,
      "learning_rate": 1.23e-05,
      "loss": 0.001,
      "step": 52780
    },
    {
      "epoch": 1.5082857142857145,
      "grad_norm": 0.07134878635406494,
      "learning_rate": 1.2292857142857144e-05,
      "loss": 0.0012,
      "step": 52790
    },
    {
      "epoch": 1.5085714285714285,
      "grad_norm": 0.042412370443344116,
      "learning_rate": 1.2285714285714286e-05,
      "loss": 0.0005,
      "step": 52800
    },
    {
      "epoch": 1.508857142857143,
      "grad_norm": 0.0,
      "learning_rate": 1.227857142857143e-05,
      "loss": 0.0003,
      "step": 52810
    },
    {
      "epoch": 1.5091428571428571,
      "grad_norm": 0.10856593400239944,
      "learning_rate": 1.2271428571428573e-05,
      "loss": 0.0008,
      "step": 52820
    },
    {
      "epoch": 1.5094285714285713,
      "grad_norm": 0.20572586357593536,
      "learning_rate": 1.2264285714285714e-05,
      "loss": 0.0015,
      "step": 52830
    },
    {
      "epoch": 1.5097142857142858,
      "grad_norm": 0.17389845848083496,
      "learning_rate": 1.2257142857142858e-05,
      "loss": 0.001,
      "step": 52840
    },
    {
      "epoch": 1.51,
      "grad_norm": 0.0,
      "learning_rate": 1.225e-05,
      "loss": 0.0012,
      "step": 52850
    },
    {
      "epoch": 1.5102857142857142,
      "grad_norm": 0.04757744446396828,
      "learning_rate": 1.2242857142857143e-05,
      "loss": 0.0019,
      "step": 52860
    },
    {
      "epoch": 1.5105714285714287,
      "grad_norm": 0.044720545411109924,
      "learning_rate": 1.2235714285714286e-05,
      "loss": 0.0011,
      "step": 52870
    },
    {
      "epoch": 1.510857142857143,
      "grad_norm": 0.08154938369989395,
      "learning_rate": 1.222857142857143e-05,
      "loss": 0.0011,
      "step": 52880
    },
    {
      "epoch": 1.5111428571428571,
      "grad_norm": 0.28469187021255493,
      "learning_rate": 1.2221428571428573e-05,
      "loss": 0.002,
      "step": 52890
    },
    {
      "epoch": 1.5114285714285716,
      "grad_norm": 0.23459145426750183,
      "learning_rate": 1.2214285714285715e-05,
      "loss": 0.0008,
      "step": 52900
    },
    {
      "epoch": 1.5117142857142856,
      "grad_norm": 0.04746811464428902,
      "learning_rate": 1.2207142857142857e-05,
      "loss": 0.0013,
      "step": 52910
    },
    {
      "epoch": 1.512,
      "grad_norm": 0.21130602061748505,
      "learning_rate": 1.22e-05,
      "loss": 0.001,
      "step": 52920
    },
    {
      "epoch": 1.5122857142857142,
      "grad_norm": 0.0365055687725544,
      "learning_rate": 1.2192857142857143e-05,
      "loss": 0.0015,
      "step": 52930
    },
    {
      "epoch": 1.5125714285714285,
      "grad_norm": 0.05810711905360222,
      "learning_rate": 1.2185714285714287e-05,
      "loss": 0.0021,
      "step": 52940
    },
    {
      "epoch": 1.512857142857143,
      "grad_norm": 0.09653724730014801,
      "learning_rate": 1.2178571428571429e-05,
      "loss": 0.0009,
      "step": 52950
    },
    {
      "epoch": 1.5131428571428571,
      "grad_norm": 0.04407314211130142,
      "learning_rate": 1.2171428571428572e-05,
      "loss": 0.001,
      "step": 52960
    },
    {
      "epoch": 1.5134285714285713,
      "grad_norm": 0.0746857225894928,
      "learning_rate": 1.2164285714285715e-05,
      "loss": 0.0013,
      "step": 52970
    },
    {
      "epoch": 1.5137142857142858,
      "grad_norm": 0.0,
      "learning_rate": 1.2157142857142857e-05,
      "loss": 0.0012,
      "step": 52980
    },
    {
      "epoch": 1.514,
      "grad_norm": 0.04901622235774994,
      "learning_rate": 1.215e-05,
      "loss": 0.0007,
      "step": 52990
    },
    {
      "epoch": 1.5142857142857142,
      "grad_norm": 0.05522168427705765,
      "learning_rate": 1.2142857142857144e-05,
      "loss": 0.0012,
      "step": 53000
    },
    {
      "epoch": 1.5145714285714287,
      "grad_norm": 0.11730263382196426,
      "learning_rate": 1.2135714285714286e-05,
      "loss": 0.0009,
      "step": 53010
    },
    {
      "epoch": 1.514857142857143,
      "grad_norm": 0.20812641084194183,
      "learning_rate": 1.2128571428571429e-05,
      "loss": 0.0012,
      "step": 53020
    },
    {
      "epoch": 1.5151428571428571,
      "grad_norm": 0.3043856918811798,
      "learning_rate": 1.2121428571428573e-05,
      "loss": 0.0009,
      "step": 53030
    },
    {
      "epoch": 1.5154285714285716,
      "grad_norm": 0.04483960568904877,
      "learning_rate": 1.2114285714285716e-05,
      "loss": 0.0004,
      "step": 53040
    },
    {
      "epoch": 1.5157142857142856,
      "grad_norm": 0.17323239147663116,
      "learning_rate": 1.2107142857142858e-05,
      "loss": 0.0018,
      "step": 53050
    },
    {
      "epoch": 1.516,
      "grad_norm": 0.0,
      "learning_rate": 1.2100000000000001e-05,
      "loss": 0.0008,
      "step": 53060
    },
    {
      "epoch": 1.5162857142857142,
      "grad_norm": 0.054603688418865204,
      "learning_rate": 1.2092857142857143e-05,
      "loss": 0.0015,
      "step": 53070
    },
    {
      "epoch": 1.5165714285714285,
      "grad_norm": 0.0,
      "learning_rate": 1.2085714285714286e-05,
      "loss": 0.0003,
      "step": 53080
    },
    {
      "epoch": 1.516857142857143,
      "grad_norm": 0.0,
      "learning_rate": 1.207857142857143e-05,
      "loss": 0.0014,
      "step": 53090
    },
    {
      "epoch": 1.5171428571428571,
      "grad_norm": 0.12742294371128082,
      "learning_rate": 1.2071428571428573e-05,
      "loss": 0.0009,
      "step": 53100
    },
    {
      "epoch": 1.5174285714285713,
      "grad_norm": 0.10042737424373627,
      "learning_rate": 1.2064285714285715e-05,
      "loss": 0.0007,
      "step": 53110
    },
    {
      "epoch": 1.5177142857142858,
      "grad_norm": 0.0438806489109993,
      "learning_rate": 1.2057142857142856e-05,
      "loss": 0.0006,
      "step": 53120
    },
    {
      "epoch": 1.518,
      "grad_norm": 0.25031140446662903,
      "learning_rate": 1.205e-05,
      "loss": 0.0005,
      "step": 53130
    },
    {
      "epoch": 1.5182857142857142,
      "grad_norm": 0.08236440271139145,
      "learning_rate": 1.2042857142857143e-05,
      "loss": 0.0004,
      "step": 53140
    },
    {
      "epoch": 1.5185714285714287,
      "grad_norm": 0.059373777359724045,
      "learning_rate": 1.2035714285714287e-05,
      "loss": 0.0015,
      "step": 53150
    },
    {
      "epoch": 1.518857142857143,
      "grad_norm": 0.0,
      "learning_rate": 1.202857142857143e-05,
      "loss": 0.0013,
      "step": 53160
    },
    {
      "epoch": 1.5191428571428571,
      "grad_norm": 0.0,
      "learning_rate": 1.2021428571428572e-05,
      "loss": 0.0006,
      "step": 53170
    },
    {
      "epoch": 1.5194285714285716,
      "grad_norm": 0.052834074944257736,
      "learning_rate": 1.2014285714285715e-05,
      "loss": 0.0015,
      "step": 53180
    },
    {
      "epoch": 1.5197142857142856,
      "grad_norm": 0.0,
      "learning_rate": 1.2007142857142857e-05,
      "loss": 0.0011,
      "step": 53190
    },
    {
      "epoch": 1.52,
      "grad_norm": 0.14419761300086975,
      "learning_rate": 1.2e-05,
      "loss": 0.0017,
      "step": 53200
    },
    {
      "epoch": 1.5202857142857142,
      "grad_norm": 0.052273645997047424,
      "learning_rate": 1.1992857142857144e-05,
      "loss": 0.0012,
      "step": 53210
    },
    {
      "epoch": 1.5205714285714285,
      "grad_norm": 0.2030031830072403,
      "learning_rate": 1.1985714285714285e-05,
      "loss": 0.0015,
      "step": 53220
    },
    {
      "epoch": 1.520857142857143,
      "grad_norm": 0.09571363776922226,
      "learning_rate": 1.1978571428571429e-05,
      "loss": 0.0009,
      "step": 53230
    },
    {
      "epoch": 1.5211428571428571,
      "grad_norm": 0.0,
      "learning_rate": 1.1971428571428572e-05,
      "loss": 0.001,
      "step": 53240
    },
    {
      "epoch": 1.5214285714285714,
      "grad_norm": 0.11559534817934036,
      "learning_rate": 1.1964285714285716e-05,
      "loss": 0.0007,
      "step": 53250
    },
    {
      "epoch": 1.5217142857142858,
      "grad_norm": 0.06699115037918091,
      "learning_rate": 1.1957142857142857e-05,
      "loss": 0.002,
      "step": 53260
    },
    {
      "epoch": 1.522,
      "grad_norm": 0.1386127471923828,
      "learning_rate": 1.195e-05,
      "loss": 0.0012,
      "step": 53270
    },
    {
      "epoch": 1.5222857142857142,
      "grad_norm": 0.042152289301157,
      "learning_rate": 1.1942857142857142e-05,
      "loss": 0.0009,
      "step": 53280
    },
    {
      "epoch": 1.5225714285714287,
      "grad_norm": 0.11694667488336563,
      "learning_rate": 1.1935714285714286e-05,
      "loss": 0.0018,
      "step": 53290
    },
    {
      "epoch": 1.522857142857143,
      "grad_norm": 0.04038860276341438,
      "learning_rate": 1.192857142857143e-05,
      "loss": 0.0014,
      "step": 53300
    },
    {
      "epoch": 1.5231428571428571,
      "grad_norm": 0.0,
      "learning_rate": 1.1921428571428573e-05,
      "loss": 0.001,
      "step": 53310
    },
    {
      "epoch": 1.5234285714285716,
      "grad_norm": 0.04153380170464516,
      "learning_rate": 1.1914285714285716e-05,
      "loss": 0.0006,
      "step": 53320
    },
    {
      "epoch": 1.5237142857142856,
      "grad_norm": 0.04129984974861145,
      "learning_rate": 1.1907142857142858e-05,
      "loss": 0.0013,
      "step": 53330
    },
    {
      "epoch": 1.524,
      "grad_norm": 0.044340360909700394,
      "learning_rate": 1.19e-05,
      "loss": 0.0004,
      "step": 53340
    },
    {
      "epoch": 1.5242857142857142,
      "grad_norm": 0.027774382382631302,
      "learning_rate": 1.1892857142857143e-05,
      "loss": 0.0011,
      "step": 53350
    },
    {
      "epoch": 1.5245714285714285,
      "grad_norm": 0.15391279757022858,
      "learning_rate": 1.1885714285714286e-05,
      "loss": 0.0004,
      "step": 53360
    },
    {
      "epoch": 1.524857142857143,
      "grad_norm": 0.13469792902469635,
      "learning_rate": 1.187857142857143e-05,
      "loss": 0.0014,
      "step": 53370
    },
    {
      "epoch": 1.5251428571428571,
      "grad_norm": 0.057074494659900665,
      "learning_rate": 1.1871428571428572e-05,
      "loss": 0.0016,
      "step": 53380
    },
    {
      "epoch": 1.5254285714285714,
      "grad_norm": 0.08220607787370682,
      "learning_rate": 1.1864285714285715e-05,
      "loss": 0.0011,
      "step": 53390
    },
    {
      "epoch": 1.5257142857142858,
      "grad_norm": 0.40878596901893616,
      "learning_rate": 1.1857142857142858e-05,
      "loss": 0.0016,
      "step": 53400
    },
    {
      "epoch": 1.526,
      "grad_norm": 0.08040095120668411,
      "learning_rate": 1.185e-05,
      "loss": 0.0022,
      "step": 53410
    },
    {
      "epoch": 1.5262857142857142,
      "grad_norm": 0.04593626782298088,
      "learning_rate": 1.1842857142857143e-05,
      "loss": 0.0006,
      "step": 53420
    },
    {
      "epoch": 1.5265714285714287,
      "grad_norm": 0.04208781197667122,
      "learning_rate": 1.1835714285714287e-05,
      "loss": 0.0014,
      "step": 53430
    },
    {
      "epoch": 1.5268571428571427,
      "grad_norm": 0.0445840023458004,
      "learning_rate": 1.1828571428571429e-05,
      "loss": 0.001,
      "step": 53440
    },
    {
      "epoch": 1.5271428571428571,
      "grad_norm": 0.16543269157409668,
      "learning_rate": 1.1821428571428572e-05,
      "loss": 0.0011,
      "step": 53450
    },
    {
      "epoch": 1.5274285714285716,
      "grad_norm": 0.08849393576383591,
      "learning_rate": 1.1814285714285715e-05,
      "loss": 0.0015,
      "step": 53460
    },
    {
      "epoch": 1.5277142857142856,
      "grad_norm": 0.0,
      "learning_rate": 1.1807142857142859e-05,
      "loss": 0.0011,
      "step": 53470
    },
    {
      "epoch": 1.528,
      "grad_norm": 0.13237732648849487,
      "learning_rate": 1.18e-05,
      "loss": 0.0007,
      "step": 53480
    },
    {
      "epoch": 1.5282857142857142,
      "grad_norm": 0.0,
      "learning_rate": 1.1792857142857142e-05,
      "loss": 0.0014,
      "step": 53490
    },
    {
      "epoch": 1.5285714285714285,
      "grad_norm": 0.19187134504318237,
      "learning_rate": 1.1785714285714286e-05,
      "loss": 0.0013,
      "step": 53500
    },
    {
      "epoch": 1.528857142857143,
      "grad_norm": 0.2503291964530945,
      "learning_rate": 1.1778571428571429e-05,
      "loss": 0.0009,
      "step": 53510
    },
    {
      "epoch": 1.5291428571428571,
      "grad_norm": 0.0,
      "learning_rate": 1.1771428571428572e-05,
      "loss": 0.0015,
      "step": 53520
    },
    {
      "epoch": 1.5294285714285714,
      "grad_norm": 0.08979107439517975,
      "learning_rate": 1.1764285714285716e-05,
      "loss": 0.0015,
      "step": 53530
    },
    {
      "epoch": 1.5297142857142858,
      "grad_norm": 0.04504503682255745,
      "learning_rate": 1.1757142857142858e-05,
      "loss": 0.001,
      "step": 53540
    },
    {
      "epoch": 1.53,
      "grad_norm": 0.04925096035003662,
      "learning_rate": 1.175e-05,
      "loss": 0.0017,
      "step": 53550
    },
    {
      "epoch": 1.5302857142857142,
      "grad_norm": 0.0,
      "learning_rate": 1.1742857142857143e-05,
      "loss": 0.0011,
      "step": 53560
    },
    {
      "epoch": 1.5305714285714287,
      "grad_norm": 0.08072782307863235,
      "learning_rate": 1.1735714285714286e-05,
      "loss": 0.0011,
      "step": 53570
    },
    {
      "epoch": 1.5308571428571427,
      "grad_norm": 0.04558331146836281,
      "learning_rate": 1.172857142857143e-05,
      "loss": 0.002,
      "step": 53580
    },
    {
      "epoch": 1.5311428571428571,
      "grad_norm": 0.054150134325027466,
      "learning_rate": 1.1721428571428571e-05,
      "loss": 0.0009,
      "step": 53590
    },
    {
      "epoch": 1.5314285714285716,
      "grad_norm": 0.04132651910185814,
      "learning_rate": 1.1714285714285715e-05,
      "loss": 0.001,
      "step": 53600
    },
    {
      "epoch": 1.5317142857142856,
      "grad_norm": 0.0,
      "learning_rate": 1.1707142857142858e-05,
      "loss": 0.0018,
      "step": 53610
    },
    {
      "epoch": 1.532,
      "grad_norm": 0.0,
      "learning_rate": 1.1700000000000001e-05,
      "loss": 0.0006,
      "step": 53620
    },
    {
      "epoch": 1.5322857142857143,
      "grad_norm": 0.34329888224601746,
      "learning_rate": 1.1692857142857143e-05,
      "loss": 0.001,
      "step": 53630
    },
    {
      "epoch": 1.5325714285714285,
      "grad_norm": 0.059157103300094604,
      "learning_rate": 1.1685714285714287e-05,
      "loss": 0.0007,
      "step": 53640
    },
    {
      "epoch": 1.532857142857143,
      "grad_norm": 0.21293124556541443,
      "learning_rate": 1.1678571428571428e-05,
      "loss": 0.0017,
      "step": 53650
    },
    {
      "epoch": 1.5331428571428571,
      "grad_norm": 0.06853370368480682,
      "learning_rate": 1.1671428571428572e-05,
      "loss": 0.0011,
      "step": 53660
    },
    {
      "epoch": 1.5334285714285714,
      "grad_norm": 0.24569830298423767,
      "learning_rate": 1.1664285714285715e-05,
      "loss": 0.0003,
      "step": 53670
    },
    {
      "epoch": 1.5337142857142858,
      "grad_norm": 0.0,
      "learning_rate": 1.1657142857142859e-05,
      "loss": 0.0003,
      "step": 53680
    },
    {
      "epoch": 1.534,
      "grad_norm": 0.04617536813020706,
      "learning_rate": 1.1650000000000002e-05,
      "loss": 0.0004,
      "step": 53690
    },
    {
      "epoch": 1.5342857142857143,
      "grad_norm": 0.0637756735086441,
      "learning_rate": 1.1642857142857144e-05,
      "loss": 0.0015,
      "step": 53700
    },
    {
      "epoch": 1.5345714285714287,
      "grad_norm": 0.08124729990959167,
      "learning_rate": 1.1635714285714285e-05,
      "loss": 0.0025,
      "step": 53710
    },
    {
      "epoch": 1.5348571428571427,
      "grad_norm": 0.4274415969848633,
      "learning_rate": 1.1628571428571429e-05,
      "loss": 0.0019,
      "step": 53720
    },
    {
      "epoch": 1.5351428571428571,
      "grad_norm": 0.2881077229976654,
      "learning_rate": 1.1621428571428572e-05,
      "loss": 0.0014,
      "step": 53730
    },
    {
      "epoch": 1.5354285714285716,
      "grad_norm": 0.09010491520166397,
      "learning_rate": 1.1614285714285716e-05,
      "loss": 0.0012,
      "step": 53740
    },
    {
      "epoch": 1.5357142857142856,
      "grad_norm": 0.07757187634706497,
      "learning_rate": 1.1607142857142857e-05,
      "loss": 0.0008,
      "step": 53750
    },
    {
      "epoch": 1.536,
      "grad_norm": 0.0,
      "learning_rate": 1.16e-05,
      "loss": 0.001,
      "step": 53760
    },
    {
      "epoch": 1.5362857142857143,
      "grad_norm": 0.028471482917666435,
      "learning_rate": 1.1592857142857142e-05,
      "loss": 0.0011,
      "step": 53770
    },
    {
      "epoch": 1.5365714285714285,
      "grad_norm": 0.06223791837692261,
      "learning_rate": 1.1585714285714286e-05,
      "loss": 0.0014,
      "step": 53780
    },
    {
      "epoch": 1.536857142857143,
      "grad_norm": 0.0,
      "learning_rate": 1.157857142857143e-05,
      "loss": 0.0009,
      "step": 53790
    },
    {
      "epoch": 1.5371428571428571,
      "grad_norm": 0.0,
      "learning_rate": 1.1571428571428573e-05,
      "loss": 0.0004,
      "step": 53800
    },
    {
      "epoch": 1.5374285714285714,
      "grad_norm": 0.044660747051239014,
      "learning_rate": 1.1564285714285714e-05,
      "loss": 0.0005,
      "step": 53810
    },
    {
      "epoch": 1.5377142857142858,
      "grad_norm": 0.0,
      "learning_rate": 1.1557142857142858e-05,
      "loss": 0.001,
      "step": 53820
    },
    {
      "epoch": 1.538,
      "grad_norm": 0.050450555980205536,
      "learning_rate": 1.1550000000000001e-05,
      "loss": 0.0015,
      "step": 53830
    },
    {
      "epoch": 1.5382857142857143,
      "grad_norm": 0.31669485569000244,
      "learning_rate": 1.1542857142857143e-05,
      "loss": 0.0014,
      "step": 53840
    },
    {
      "epoch": 1.5385714285714287,
      "grad_norm": 0.049767207354307175,
      "learning_rate": 1.1535714285714286e-05,
      "loss": 0.0013,
      "step": 53850
    },
    {
      "epoch": 1.5388571428571427,
      "grad_norm": 0.21170100569725037,
      "learning_rate": 1.1528571428571428e-05,
      "loss": 0.0009,
      "step": 53860
    },
    {
      "epoch": 1.5391428571428571,
      "grad_norm": 0.07577238976955414,
      "learning_rate": 1.1521428571428571e-05,
      "loss": 0.0007,
      "step": 53870
    },
    {
      "epoch": 1.5394285714285716,
      "grad_norm": 0.16672788560390472,
      "learning_rate": 1.1514285714285715e-05,
      "loss": 0.0013,
      "step": 53880
    },
    {
      "epoch": 1.5397142857142856,
      "grad_norm": 0.04967830702662468,
      "learning_rate": 1.1507142857142858e-05,
      "loss": 0.0011,
      "step": 53890
    },
    {
      "epoch": 1.54,
      "grad_norm": 0.04143190383911133,
      "learning_rate": 1.1500000000000002e-05,
      "loss": 0.0016,
      "step": 53900
    },
    {
      "epoch": 1.5402857142857143,
      "grad_norm": 0.0,
      "learning_rate": 1.1492857142857143e-05,
      "loss": 0.0011,
      "step": 53910
    },
    {
      "epoch": 1.5405714285714285,
      "grad_norm": 0.12019645422697067,
      "learning_rate": 1.1485714285714285e-05,
      "loss": 0.0011,
      "step": 53920
    },
    {
      "epoch": 1.540857142857143,
      "grad_norm": 0.026452593505382538,
      "learning_rate": 1.1478571428571429e-05,
      "loss": 0.001,
      "step": 53930
    },
    {
      "epoch": 1.5411428571428571,
      "grad_norm": 0.0,
      "learning_rate": 1.1471428571428572e-05,
      "loss": 0.0007,
      "step": 53940
    },
    {
      "epoch": 1.5414285714285714,
      "grad_norm": 0.04827355965971947,
      "learning_rate": 1.1464285714285715e-05,
      "loss": 0.0002,
      "step": 53950
    },
    {
      "epoch": 1.5417142857142858,
      "grad_norm": 0.2143392562866211,
      "learning_rate": 1.1457142857142859e-05,
      "loss": 0.0018,
      "step": 53960
    },
    {
      "epoch": 1.542,
      "grad_norm": 0.16437214612960815,
      "learning_rate": 1.145e-05,
      "loss": 0.0012,
      "step": 53970
    },
    {
      "epoch": 1.5422857142857143,
      "grad_norm": 0.042984988540410995,
      "learning_rate": 1.1442857142857144e-05,
      "loss": 0.001,
      "step": 53980
    },
    {
      "epoch": 1.5425714285714287,
      "grad_norm": 0.0,
      "learning_rate": 1.1435714285714286e-05,
      "loss": 0.0011,
      "step": 53990
    },
    {
      "epoch": 1.5428571428571427,
      "grad_norm": 0.0,
      "learning_rate": 1.1428571428571429e-05,
      "loss": 0.0003,
      "step": 54000
    },
    {
      "epoch": 1.5431428571428571,
      "grad_norm": 0.10215868800878525,
      "learning_rate": 1.1421428571428572e-05,
      "loss": 0.0007,
      "step": 54010
    },
    {
      "epoch": 1.5434285714285716,
      "grad_norm": 0.1640034317970276,
      "learning_rate": 1.1414285714285714e-05,
      "loss": 0.0011,
      "step": 54020
    },
    {
      "epoch": 1.5437142857142856,
      "grad_norm": 0.05381527543067932,
      "learning_rate": 1.1407142857142858e-05,
      "loss": 0.0007,
      "step": 54030
    },
    {
      "epoch": 1.544,
      "grad_norm": 0.05086132138967514,
      "learning_rate": 1.1400000000000001e-05,
      "loss": 0.0012,
      "step": 54040
    },
    {
      "epoch": 1.5442857142857143,
      "grad_norm": 0.044152576476335526,
      "learning_rate": 1.1392857142857144e-05,
      "loss": 0.0014,
      "step": 54050
    },
    {
      "epoch": 1.5445714285714285,
      "grad_norm": 0.042502809315919876,
      "learning_rate": 1.1385714285714286e-05,
      "loss": 0.001,
      "step": 54060
    },
    {
      "epoch": 1.544857142857143,
      "grad_norm": 0.25964754819869995,
      "learning_rate": 1.137857142857143e-05,
      "loss": 0.0006,
      "step": 54070
    },
    {
      "epoch": 1.5451428571428572,
      "grad_norm": 0.33822908997535706,
      "learning_rate": 1.1371428571428571e-05,
      "loss": 0.0007,
      "step": 54080
    },
    {
      "epoch": 1.5454285714285714,
      "grad_norm": 0.07646527886390686,
      "learning_rate": 1.1364285714285715e-05,
      "loss": 0.001,
      "step": 54090
    },
    {
      "epoch": 1.5457142857142858,
      "grad_norm": 0.0,
      "learning_rate": 1.1357142857142858e-05,
      "loss": 0.0008,
      "step": 54100
    },
    {
      "epoch": 1.546,
      "grad_norm": 0.042167436331510544,
      "learning_rate": 1.1350000000000001e-05,
      "loss": 0.0007,
      "step": 54110
    },
    {
      "epoch": 1.5462857142857143,
      "grad_norm": 0.04935052618384361,
      "learning_rate": 1.1342857142857143e-05,
      "loss": 0.0011,
      "step": 54120
    },
    {
      "epoch": 1.5465714285714287,
      "grad_norm": 0.046323589980602264,
      "learning_rate": 1.1335714285714285e-05,
      "loss": 0.0015,
      "step": 54130
    },
    {
      "epoch": 1.5468571428571427,
      "grad_norm": 0.35859379172325134,
      "learning_rate": 1.1328571428571428e-05,
      "loss": 0.0019,
      "step": 54140
    },
    {
      "epoch": 1.5471428571428572,
      "grad_norm": 0.15411773324012756,
      "learning_rate": 1.1321428571428572e-05,
      "loss": 0.0007,
      "step": 54150
    },
    {
      "epoch": 1.5474285714285714,
      "grad_norm": 0.08671895414590836,
      "learning_rate": 1.1314285714285715e-05,
      "loss": 0.0011,
      "step": 54160
    },
    {
      "epoch": 1.5477142857142856,
      "grad_norm": 0.04062425717711449,
      "learning_rate": 1.1307142857142859e-05,
      "loss": 0.0006,
      "step": 54170
    },
    {
      "epoch": 1.548,
      "grad_norm": 0.04806673526763916,
      "learning_rate": 1.13e-05,
      "loss": 0.0008,
      "step": 54180
    },
    {
      "epoch": 1.5482857142857143,
      "grad_norm": 0.22713467478752136,
      "learning_rate": 1.1292857142857144e-05,
      "loss": 0.0016,
      "step": 54190
    },
    {
      "epoch": 1.5485714285714285,
      "grad_norm": 0.09675011038780212,
      "learning_rate": 1.1285714285714285e-05,
      "loss": 0.0012,
      "step": 54200
    },
    {
      "epoch": 1.548857142857143,
      "grad_norm": 0.06044619902968407,
      "learning_rate": 1.1278571428571429e-05,
      "loss": 0.0007,
      "step": 54210
    },
    {
      "epoch": 1.5491428571428572,
      "grad_norm": 0.04000936076045036,
      "learning_rate": 1.1271428571428572e-05,
      "loss": 0.0013,
      "step": 54220
    },
    {
      "epoch": 1.5494285714285714,
      "grad_norm": 0.0,
      "learning_rate": 1.1264285714285714e-05,
      "loss": 0.0005,
      "step": 54230
    },
    {
      "epoch": 1.5497142857142858,
      "grad_norm": 0.16362927854061127,
      "learning_rate": 1.1257142857142857e-05,
      "loss": 0.0005,
      "step": 54240
    },
    {
      "epoch": 1.55,
      "grad_norm": 0.2908701002597809,
      "learning_rate": 1.125e-05,
      "loss": 0.0008,
      "step": 54250
    },
    {
      "epoch": 1.5502857142857143,
      "grad_norm": 0.2944830656051636,
      "learning_rate": 1.1242857142857144e-05,
      "loss": 0.0017,
      "step": 54260
    },
    {
      "epoch": 1.5505714285714287,
      "grad_norm": 0.041686784476041794,
      "learning_rate": 1.1235714285714288e-05,
      "loss": 0.0015,
      "step": 54270
    },
    {
      "epoch": 1.5508571428571427,
      "grad_norm": 0.04976853355765343,
      "learning_rate": 1.122857142857143e-05,
      "loss": 0.0013,
      "step": 54280
    },
    {
      "epoch": 1.5511428571428572,
      "grad_norm": 0.20266999304294586,
      "learning_rate": 1.1221428571428571e-05,
      "loss": 0.0008,
      "step": 54290
    },
    {
      "epoch": 1.5514285714285714,
      "grad_norm": 0.19953317940235138,
      "learning_rate": 1.1214285714285714e-05,
      "loss": 0.0008,
      "step": 54300
    },
    {
      "epoch": 1.5517142857142856,
      "grad_norm": 0.13432571291923523,
      "learning_rate": 1.1207142857142858e-05,
      "loss": 0.0018,
      "step": 54310
    },
    {
      "epoch": 1.552,
      "grad_norm": 0.08227583020925522,
      "learning_rate": 1.1200000000000001e-05,
      "loss": 0.0003,
      "step": 54320
    },
    {
      "epoch": 1.5522857142857143,
      "grad_norm": 0.2118958830833435,
      "learning_rate": 1.1192857142857145e-05,
      "loss": 0.0011,
      "step": 54330
    },
    {
      "epoch": 1.5525714285714285,
      "grad_norm": 0.08654193580150604,
      "learning_rate": 1.1185714285714286e-05,
      "loss": 0.0018,
      "step": 54340
    },
    {
      "epoch": 1.552857142857143,
      "grad_norm": 0.0985708013176918,
      "learning_rate": 1.1178571428571428e-05,
      "loss": 0.0012,
      "step": 54350
    },
    {
      "epoch": 1.5531428571428572,
      "grad_norm": 0.11079951375722885,
      "learning_rate": 1.1171428571428571e-05,
      "loss": 0.001,
      "step": 54360
    },
    {
      "epoch": 1.5534285714285714,
      "grad_norm": 0.09797365218400955,
      "learning_rate": 1.1164285714285715e-05,
      "loss": 0.001,
      "step": 54370
    },
    {
      "epoch": 1.5537142857142858,
      "grad_norm": 0.0,
      "learning_rate": 1.1157142857142858e-05,
      "loss": 0.0009,
      "step": 54380
    },
    {
      "epoch": 1.554,
      "grad_norm": 0.0,
      "learning_rate": 1.115e-05,
      "loss": 0.0022,
      "step": 54390
    },
    {
      "epoch": 1.5542857142857143,
      "grad_norm": 0.05008941516280174,
      "learning_rate": 1.1142857142857143e-05,
      "loss": 0.0015,
      "step": 54400
    },
    {
      "epoch": 1.5545714285714287,
      "grad_norm": 0.0,
      "learning_rate": 1.1135714285714287e-05,
      "loss": 0.0015,
      "step": 54410
    },
    {
      "epoch": 1.5548571428571427,
      "grad_norm": 0.04756493121385574,
      "learning_rate": 1.1128571428571429e-05,
      "loss": 0.0004,
      "step": 54420
    },
    {
      "epoch": 1.5551428571428572,
      "grad_norm": 0.08057770133018494,
      "learning_rate": 1.1121428571428572e-05,
      "loss": 0.0013,
      "step": 54430
    },
    {
      "epoch": 1.5554285714285714,
      "grad_norm": 0.05764899402856827,
      "learning_rate": 1.1114285714285715e-05,
      "loss": 0.0006,
      "step": 54440
    },
    {
      "epoch": 1.5557142857142856,
      "grad_norm": 0.03733791038393974,
      "learning_rate": 1.1107142857142857e-05,
      "loss": 0.0011,
      "step": 54450
    },
    {
      "epoch": 1.556,
      "grad_norm": 0.03944983705878258,
      "learning_rate": 1.11e-05,
      "loss": 0.0007,
      "step": 54460
    },
    {
      "epoch": 1.5562857142857143,
      "grad_norm": 0.0,
      "learning_rate": 1.1092857142857144e-05,
      "loss": 0.0019,
      "step": 54470
    },
    {
      "epoch": 1.5565714285714285,
      "grad_norm": 0.2638104259967804,
      "learning_rate": 1.1085714285714287e-05,
      "loss": 0.0011,
      "step": 54480
    },
    {
      "epoch": 1.556857142857143,
      "grad_norm": 0.04425829276442528,
      "learning_rate": 1.1078571428571429e-05,
      "loss": 0.0014,
      "step": 54490
    },
    {
      "epoch": 1.5571428571428572,
      "grad_norm": 0.04235268384218216,
      "learning_rate": 1.107142857142857e-05,
      "loss": 0.0004,
      "step": 54500
    },
    {
      "epoch": 1.5574285714285714,
      "grad_norm": 0.0,
      "learning_rate": 1.1064285714285714e-05,
      "loss": 0.0014,
      "step": 54510
    },
    {
      "epoch": 1.5577142857142858,
      "grad_norm": 0.07769320160150528,
      "learning_rate": 1.1057142857142858e-05,
      "loss": 0.0014,
      "step": 54520
    },
    {
      "epoch": 1.558,
      "grad_norm": 0.257772296667099,
      "learning_rate": 1.1050000000000001e-05,
      "loss": 0.0008,
      "step": 54530
    },
    {
      "epoch": 1.5582857142857143,
      "grad_norm": 0.0,
      "learning_rate": 1.1042857142857144e-05,
      "loss": 0.0014,
      "step": 54540
    },
    {
      "epoch": 1.5585714285714287,
      "grad_norm": 0.04020426794886589,
      "learning_rate": 1.1035714285714286e-05,
      "loss": 0.0017,
      "step": 54550
    },
    {
      "epoch": 1.5588571428571427,
      "grad_norm": 0.16003797948360443,
      "learning_rate": 1.102857142857143e-05,
      "loss": 0.0016,
      "step": 54560
    },
    {
      "epoch": 1.5591428571428572,
      "grad_norm": 0.1993301510810852,
      "learning_rate": 1.1021428571428571e-05,
      "loss": 0.002,
      "step": 54570
    },
    {
      "epoch": 1.5594285714285714,
      "grad_norm": 0.0,
      "learning_rate": 1.1014285714285715e-05,
      "loss": 0.0014,
      "step": 54580
    },
    {
      "epoch": 1.5597142857142856,
      "grad_norm": 0.13979914784431458,
      "learning_rate": 1.1007142857142858e-05,
      "loss": 0.0017,
      "step": 54590
    },
    {
      "epoch": 1.56,
      "grad_norm": 0.05413627251982689,
      "learning_rate": 1.1000000000000001e-05,
      "loss": 0.0008,
      "step": 54600
    },
    {
      "epoch": 1.5602857142857143,
      "grad_norm": 0.08832494169473648,
      "learning_rate": 1.0992857142857143e-05,
      "loss": 0.0015,
      "step": 54610
    },
    {
      "epoch": 1.5605714285714285,
      "grad_norm": 0.0,
      "learning_rate": 1.0985714285714287e-05,
      "loss": 0.0008,
      "step": 54620
    },
    {
      "epoch": 1.560857142857143,
      "grad_norm": 0.12294729053974152,
      "learning_rate": 1.097857142857143e-05,
      "loss": 0.0022,
      "step": 54630
    },
    {
      "epoch": 1.5611428571428572,
      "grad_norm": 0.07712151110172272,
      "learning_rate": 1.0971428571428572e-05,
      "loss": 0.001,
      "step": 54640
    },
    {
      "epoch": 1.5614285714285714,
      "grad_norm": 0.07996205240488052,
      "learning_rate": 1.0964285714285715e-05,
      "loss": 0.0012,
      "step": 54650
    },
    {
      "epoch": 1.5617142857142858,
      "grad_norm": 0.0,
      "learning_rate": 1.0957142857142857e-05,
      "loss": 0.0013,
      "step": 54660
    },
    {
      "epoch": 1.562,
      "grad_norm": 0.22973906993865967,
      "learning_rate": 1.095e-05,
      "loss": 0.0016,
      "step": 54670
    },
    {
      "epoch": 1.5622857142857143,
      "grad_norm": 0.05103958025574684,
      "learning_rate": 1.0942857142857144e-05,
      "loss": 0.0017,
      "step": 54680
    },
    {
      "epoch": 1.5625714285714287,
      "grad_norm": 0.05131358280777931,
      "learning_rate": 1.0935714285714287e-05,
      "loss": 0.0006,
      "step": 54690
    },
    {
      "epoch": 1.5628571428571427,
      "grad_norm": 0.0,
      "learning_rate": 1.092857142857143e-05,
      "loss": 0.0001,
      "step": 54700
    },
    {
      "epoch": 1.5631428571428572,
      "grad_norm": 0.03664310276508331,
      "learning_rate": 1.0921428571428572e-05,
      "loss": 0.0021,
      "step": 54710
    },
    {
      "epoch": 1.5634285714285714,
      "grad_norm": 0.18120329082012177,
      "learning_rate": 1.0914285714285714e-05,
      "loss": 0.0012,
      "step": 54720
    },
    {
      "epoch": 1.5637142857142856,
      "grad_norm": 0.04588749259710312,
      "learning_rate": 1.0907142857142857e-05,
      "loss": 0.0016,
      "step": 54730
    },
    {
      "epoch": 1.564,
      "grad_norm": 0.10378182679414749,
      "learning_rate": 1.09e-05,
      "loss": 0.0017,
      "step": 54740
    },
    {
      "epoch": 1.5642857142857143,
      "grad_norm": 0.04164131358265877,
      "learning_rate": 1.0892857142857144e-05,
      "loss": 0.0018,
      "step": 54750
    },
    {
      "epoch": 1.5645714285714285,
      "grad_norm": 0.0,
      "learning_rate": 1.0885714285714286e-05,
      "loss": 0.0012,
      "step": 54760
    },
    {
      "epoch": 1.564857142857143,
      "grad_norm": 0.0511590801179409,
      "learning_rate": 1.087857142857143e-05,
      "loss": 0.0015,
      "step": 54770
    },
    {
      "epoch": 1.5651428571428572,
      "grad_norm": 0.05854594707489014,
      "learning_rate": 1.0871428571428571e-05,
      "loss": 0.0004,
      "step": 54780
    },
    {
      "epoch": 1.5654285714285714,
      "grad_norm": 0.042845144867897034,
      "learning_rate": 1.0864285714285714e-05,
      "loss": 0.0009,
      "step": 54790
    },
    {
      "epoch": 1.5657142857142858,
      "grad_norm": 0.053143180906772614,
      "learning_rate": 1.0857142857142858e-05,
      "loss": 0.0003,
      "step": 54800
    },
    {
      "epoch": 1.5659999999999998,
      "grad_norm": 0.09683975577354431,
      "learning_rate": 1.0850000000000001e-05,
      "loss": 0.0009,
      "step": 54810
    },
    {
      "epoch": 1.5662857142857143,
      "grad_norm": 0.0,
      "learning_rate": 1.0842857142857143e-05,
      "loss": 0.0006,
      "step": 54820
    },
    {
      "epoch": 1.5665714285714287,
      "grad_norm": 0.18723616003990173,
      "learning_rate": 1.0835714285714286e-05,
      "loss": 0.0025,
      "step": 54830
    },
    {
      "epoch": 1.5668571428571427,
      "grad_norm": 0.052368782460689545,
      "learning_rate": 1.082857142857143e-05,
      "loss": 0.0008,
      "step": 54840
    },
    {
      "epoch": 1.5671428571428572,
      "grad_norm": 0.10882224142551422,
      "learning_rate": 1.0821428571428573e-05,
      "loss": 0.0016,
      "step": 54850
    },
    {
      "epoch": 1.5674285714285714,
      "grad_norm": 0.05913504958152771,
      "learning_rate": 1.0814285714285715e-05,
      "loss": 0.0006,
      "step": 54860
    },
    {
      "epoch": 1.5677142857142856,
      "grad_norm": 0.0,
      "learning_rate": 1.0807142857142857e-05,
      "loss": 0.0011,
      "step": 54870
    },
    {
      "epoch": 1.568,
      "grad_norm": 0.0,
      "learning_rate": 1.08e-05,
      "loss": 0.0012,
      "step": 54880
    },
    {
      "epoch": 1.5682857142857143,
      "grad_norm": 0.04302637651562691,
      "learning_rate": 1.0792857142857143e-05,
      "loss": 0.0004,
      "step": 54890
    },
    {
      "epoch": 1.5685714285714285,
      "grad_norm": 0.046682845801115036,
      "learning_rate": 1.0785714285714287e-05,
      "loss": 0.0008,
      "step": 54900
    },
    {
      "epoch": 1.568857142857143,
      "grad_norm": 0.17191781103610992,
      "learning_rate": 1.077857142857143e-05,
      "loss": 0.0013,
      "step": 54910
    },
    {
      "epoch": 1.5691428571428572,
      "grad_norm": 0.04197482019662857,
      "learning_rate": 1.0771428571428572e-05,
      "loss": 0.0006,
      "step": 54920
    },
    {
      "epoch": 1.5694285714285714,
      "grad_norm": 0.0,
      "learning_rate": 1.0764285714285714e-05,
      "loss": 0.0006,
      "step": 54930
    },
    {
      "epoch": 1.5697142857142858,
      "grad_norm": 0.0,
      "learning_rate": 1.0757142857142857e-05,
      "loss": 0.0018,
      "step": 54940
    },
    {
      "epoch": 1.5699999999999998,
      "grad_norm": 0.06345805525779724,
      "learning_rate": 1.075e-05,
      "loss": 0.0009,
      "step": 54950
    },
    {
      "epoch": 1.5702857142857143,
      "grad_norm": 0.0,
      "learning_rate": 1.0742857142857144e-05,
      "loss": 0.0016,
      "step": 54960
    },
    {
      "epoch": 1.5705714285714287,
      "grad_norm": 0.11782762408256531,
      "learning_rate": 1.0735714285714287e-05,
      "loss": 0.0015,
      "step": 54970
    },
    {
      "epoch": 1.5708571428571427,
      "grad_norm": 0.25797703862190247,
      "learning_rate": 1.0728571428571429e-05,
      "loss": 0.0017,
      "step": 54980
    },
    {
      "epoch": 1.5711428571428572,
      "grad_norm": 0.09280537813901901,
      "learning_rate": 1.0721428571428572e-05,
      "loss": 0.0009,
      "step": 54990
    },
    {
      "epoch": 1.5714285714285714,
      "grad_norm": 0.048993803560733795,
      "learning_rate": 1.0714285714285714e-05,
      "loss": 0.0012,
      "step": 55000
    },
    {
      "epoch": 1.5717142857142856,
      "grad_norm": 0.0,
      "learning_rate": 1.0707142857142857e-05,
      "loss": 0.0011,
      "step": 55010
    },
    {
      "epoch": 1.572,
      "grad_norm": 0.0,
      "learning_rate": 1.0700000000000001e-05,
      "loss": 0.001,
      "step": 55020
    },
    {
      "epoch": 1.5722857142857143,
      "grad_norm": 0.04522460326552391,
      "learning_rate": 1.0692857142857143e-05,
      "loss": 0.0008,
      "step": 55030
    },
    {
      "epoch": 1.5725714285714285,
      "grad_norm": 0.0,
      "learning_rate": 1.0685714285714286e-05,
      "loss": 0.0003,
      "step": 55040
    },
    {
      "epoch": 1.572857142857143,
      "grad_norm": 0.2103438377380371,
      "learning_rate": 1.067857142857143e-05,
      "loss": 0.0009,
      "step": 55050
    },
    {
      "epoch": 1.5731428571428572,
      "grad_norm": 0.03843694552779198,
      "learning_rate": 1.0671428571428573e-05,
      "loss": 0.0022,
      "step": 55060
    },
    {
      "epoch": 1.5734285714285714,
      "grad_norm": 0.042090535163879395,
      "learning_rate": 1.0664285714285715e-05,
      "loss": 0.0011,
      "step": 55070
    },
    {
      "epoch": 1.5737142857142858,
      "grad_norm": 0.0429745577275753,
      "learning_rate": 1.0657142857142858e-05,
      "loss": 0.0013,
      "step": 55080
    },
    {
      "epoch": 1.5739999999999998,
      "grad_norm": 0.048146747052669525,
      "learning_rate": 1.065e-05,
      "loss": 0.0013,
      "step": 55090
    },
    {
      "epoch": 1.5742857142857143,
      "grad_norm": 0.04959576576948166,
      "learning_rate": 1.0642857142857143e-05,
      "loss": 0.0017,
      "step": 55100
    },
    {
      "epoch": 1.5745714285714287,
      "grad_norm": 0.1298006772994995,
      "learning_rate": 1.0635714285714286e-05,
      "loss": 0.001,
      "step": 55110
    },
    {
      "epoch": 1.5748571428571427,
      "grad_norm": 0.0910324826836586,
      "learning_rate": 1.062857142857143e-05,
      "loss": 0.0006,
      "step": 55120
    },
    {
      "epoch": 1.5751428571428572,
      "grad_norm": 0.0,
      "learning_rate": 1.0621428571428572e-05,
      "loss": 0.0008,
      "step": 55130
    },
    {
      "epoch": 1.5754285714285714,
      "grad_norm": 0.10695548355579376,
      "learning_rate": 1.0614285714285713e-05,
      "loss": 0.0013,
      "step": 55140
    },
    {
      "epoch": 1.5757142857142856,
      "grad_norm": 0.2748602628707886,
      "learning_rate": 1.0607142857142857e-05,
      "loss": 0.0006,
      "step": 55150
    },
    {
      "epoch": 1.576,
      "grad_norm": 0.053889866918325424,
      "learning_rate": 1.06e-05,
      "loss": 0.0012,
      "step": 55160
    },
    {
      "epoch": 1.5762857142857143,
      "grad_norm": 0.0,
      "learning_rate": 1.0592857142857144e-05,
      "loss": 0.0008,
      "step": 55170
    },
    {
      "epoch": 1.5765714285714285,
      "grad_norm": 0.08670535683631897,
      "learning_rate": 1.0585714285714287e-05,
      "loss": 0.002,
      "step": 55180
    },
    {
      "epoch": 1.576857142857143,
      "grad_norm": 0.05100357159972191,
      "learning_rate": 1.0578571428571429e-05,
      "loss": 0.0012,
      "step": 55190
    },
    {
      "epoch": 1.5771428571428572,
      "grad_norm": 0.0,
      "learning_rate": 1.0571428571428572e-05,
      "loss": 0.0007,
      "step": 55200
    },
    {
      "epoch": 1.5774285714285714,
      "grad_norm": 0.08041214197874069,
      "learning_rate": 1.0564285714285716e-05,
      "loss": 0.0018,
      "step": 55210
    },
    {
      "epoch": 1.5777142857142858,
      "grad_norm": 0.19164107739925385,
      "learning_rate": 1.0557142857142857e-05,
      "loss": 0.0006,
      "step": 55220
    },
    {
      "epoch": 1.5779999999999998,
      "grad_norm": 0.25277549028396606,
      "learning_rate": 1.055e-05,
      "loss": 0.0008,
      "step": 55230
    },
    {
      "epoch": 1.5782857142857143,
      "grad_norm": 0.0,
      "learning_rate": 1.0542857142857144e-05,
      "loss": 0.0004,
      "step": 55240
    },
    {
      "epoch": 1.5785714285714287,
      "grad_norm": 0.047383539378643036,
      "learning_rate": 1.0535714285714286e-05,
      "loss": 0.0003,
      "step": 55250
    },
    {
      "epoch": 1.5788571428571427,
      "grad_norm": 0.06352454423904419,
      "learning_rate": 1.052857142857143e-05,
      "loss": 0.0008,
      "step": 55260
    },
    {
      "epoch": 1.5791428571428572,
      "grad_norm": 0.04676910862326622,
      "learning_rate": 1.0521428571428573e-05,
      "loss": 0.0017,
      "step": 55270
    },
    {
      "epoch": 1.5794285714285714,
      "grad_norm": 0.047498930245637894,
      "learning_rate": 1.0514285714285716e-05,
      "loss": 0.0012,
      "step": 55280
    },
    {
      "epoch": 1.5797142857142856,
      "grad_norm": 0.07542440295219421,
      "learning_rate": 1.0507142857142858e-05,
      "loss": 0.0009,
      "step": 55290
    },
    {
      "epoch": 1.58,
      "grad_norm": 0.1258261650800705,
      "learning_rate": 1.05e-05,
      "loss": 0.0013,
      "step": 55300
    },
    {
      "epoch": 1.5802857142857143,
      "grad_norm": 0.042762644588947296,
      "learning_rate": 1.0492857142857143e-05,
      "loss": 0.0014,
      "step": 55310
    },
    {
      "epoch": 1.5805714285714285,
      "grad_norm": 0.0,
      "learning_rate": 1.0485714285714286e-05,
      "loss": 0.0006,
      "step": 55320
    },
    {
      "epoch": 1.580857142857143,
      "grad_norm": 0.08669129759073257,
      "learning_rate": 1.047857142857143e-05,
      "loss": 0.0003,
      "step": 55330
    },
    {
      "epoch": 1.5811428571428572,
      "grad_norm": 0.044365294277668,
      "learning_rate": 1.0471428571428573e-05,
      "loss": 0.0015,
      "step": 55340
    },
    {
      "epoch": 1.5814285714285714,
      "grad_norm": 0.2033889889717102,
      "learning_rate": 1.0464285714285715e-05,
      "loss": 0.0012,
      "step": 55350
    },
    {
      "epoch": 1.5817142857142859,
      "grad_norm": 0.0,
      "learning_rate": 1.0457142857142856e-05,
      "loss": 0.0017,
      "step": 55360
    },
    {
      "epoch": 1.5819999999999999,
      "grad_norm": 0.04631100967526436,
      "learning_rate": 1.045e-05,
      "loss": 0.0007,
      "step": 55370
    },
    {
      "epoch": 1.5822857142857143,
      "grad_norm": 0.0,
      "learning_rate": 1.0442857142857143e-05,
      "loss": 0.0007,
      "step": 55380
    },
    {
      "epoch": 1.5825714285714285,
      "grad_norm": 0.0,
      "learning_rate": 1.0435714285714287e-05,
      "loss": 0.0019,
      "step": 55390
    },
    {
      "epoch": 1.5828571428571427,
      "grad_norm": 0.051888495683670044,
      "learning_rate": 1.0428571428571428e-05,
      "loss": 0.0003,
      "step": 55400
    },
    {
      "epoch": 1.5831428571428572,
      "grad_norm": 0.36755090951919556,
      "learning_rate": 1.0421428571428572e-05,
      "loss": 0.0016,
      "step": 55410
    },
    {
      "epoch": 1.5834285714285714,
      "grad_norm": 0.05096406489610672,
      "learning_rate": 1.0414285714285715e-05,
      "loss": 0.0012,
      "step": 55420
    },
    {
      "epoch": 1.5837142857142856,
      "grad_norm": 0.04212474822998047,
      "learning_rate": 1.0407142857142857e-05,
      "loss": 0.0008,
      "step": 55430
    },
    {
      "epoch": 1.584,
      "grad_norm": 0.0,
      "learning_rate": 1.04e-05,
      "loss": 0.0007,
      "step": 55440
    },
    {
      "epoch": 1.5842857142857143,
      "grad_norm": 0.04884698987007141,
      "learning_rate": 1.0392857142857144e-05,
      "loss": 0.0011,
      "step": 55450
    },
    {
      "epoch": 1.5845714285714285,
      "grad_norm": 0.09013968706130981,
      "learning_rate": 1.0385714285714286e-05,
      "loss": 0.002,
      "step": 55460
    },
    {
      "epoch": 1.584857142857143,
      "grad_norm": 0.16489842534065247,
      "learning_rate": 1.0378571428571429e-05,
      "loss": 0.0005,
      "step": 55470
    },
    {
      "epoch": 1.5851428571428572,
      "grad_norm": 0.07105836272239685,
      "learning_rate": 1.0371428571428572e-05,
      "loss": 0.002,
      "step": 55480
    },
    {
      "epoch": 1.5854285714285714,
      "grad_norm": 0.11764641851186752,
      "learning_rate": 1.0364285714285716e-05,
      "loss": 0.0009,
      "step": 55490
    },
    {
      "epoch": 1.5857142857142859,
      "grad_norm": 0.10081882029771805,
      "learning_rate": 1.0357142857142859e-05,
      "loss": 0.0013,
      "step": 55500
    },
    {
      "epoch": 1.5859999999999999,
      "grad_norm": 0.0,
      "learning_rate": 1.035e-05,
      "loss": 0.0008,
      "step": 55510
    },
    {
      "epoch": 1.5862857142857143,
      "grad_norm": 0.02883279323577881,
      "learning_rate": 1.0342857142857143e-05,
      "loss": 0.001,
      "step": 55520
    },
    {
      "epoch": 1.5865714285714285,
      "grad_norm": 0.12319943308830261,
      "learning_rate": 1.0335714285714286e-05,
      "loss": 0.0018,
      "step": 55530
    },
    {
      "epoch": 1.5868571428571427,
      "grad_norm": 0.11891546100378036,
      "learning_rate": 1.032857142857143e-05,
      "loss": 0.0024,
      "step": 55540
    },
    {
      "epoch": 1.5871428571428572,
      "grad_norm": 0.363873153924942,
      "learning_rate": 1.0321428571428573e-05,
      "loss": 0.001,
      "step": 55550
    },
    {
      "epoch": 1.5874285714285714,
      "grad_norm": 0.08430366218090057,
      "learning_rate": 1.0314285714285715e-05,
      "loss": 0.0008,
      "step": 55560
    },
    {
      "epoch": 1.5877142857142856,
      "grad_norm": 0.04548247158527374,
      "learning_rate": 1.0307142857142858e-05,
      "loss": 0.0007,
      "step": 55570
    },
    {
      "epoch": 1.588,
      "grad_norm": 0.09295663982629776,
      "learning_rate": 1.03e-05,
      "loss": 0.0011,
      "step": 55580
    },
    {
      "epoch": 1.5882857142857143,
      "grad_norm": 0.045980196446180344,
      "learning_rate": 1.0292857142857143e-05,
      "loss": 0.0026,
      "step": 55590
    },
    {
      "epoch": 1.5885714285714285,
      "grad_norm": 0.09446375072002411,
      "learning_rate": 1.0285714285714286e-05,
      "loss": 0.0012,
      "step": 55600
    },
    {
      "epoch": 1.588857142857143,
      "grad_norm": 0.1663120836019516,
      "learning_rate": 1.027857142857143e-05,
      "loss": 0.0011,
      "step": 55610
    },
    {
      "epoch": 1.5891428571428572,
      "grad_norm": 0.0954594761133194,
      "learning_rate": 1.0271428571428572e-05,
      "loss": 0.0019,
      "step": 55620
    },
    {
      "epoch": 1.5894285714285714,
      "grad_norm": 0.05876578390598297,
      "learning_rate": 1.0264285714285715e-05,
      "loss": 0.0006,
      "step": 55630
    },
    {
      "epoch": 1.5897142857142859,
      "grad_norm": 0.06194278225302696,
      "learning_rate": 1.0257142857142858e-05,
      "loss": 0.0018,
      "step": 55640
    },
    {
      "epoch": 1.5899999999999999,
      "grad_norm": 0.07721877098083496,
      "learning_rate": 1.025e-05,
      "loss": 0.0008,
      "step": 55650
    },
    {
      "epoch": 1.5902857142857143,
      "grad_norm": 0.0,
      "learning_rate": 1.0242857142857144e-05,
      "loss": 0.0009,
      "step": 55660
    },
    {
      "epoch": 1.5905714285714285,
      "grad_norm": 0.29833507537841797,
      "learning_rate": 1.0235714285714285e-05,
      "loss": 0.0005,
      "step": 55670
    },
    {
      "epoch": 1.5908571428571427,
      "grad_norm": 0.0498109795153141,
      "learning_rate": 1.0228571428571429e-05,
      "loss": 0.0007,
      "step": 55680
    },
    {
      "epoch": 1.5911428571428572,
      "grad_norm": 0.05561453476548195,
      "learning_rate": 1.0221428571428572e-05,
      "loss": 0.0012,
      "step": 55690
    },
    {
      "epoch": 1.5914285714285714,
      "grad_norm": 0.047293029725551605,
      "learning_rate": 1.0214285714285715e-05,
      "loss": 0.001,
      "step": 55700
    },
    {
      "epoch": 1.5917142857142856,
      "grad_norm": 0.0,
      "learning_rate": 1.0207142857142859e-05,
      "loss": 0.0005,
      "step": 55710
    },
    {
      "epoch": 1.592,
      "grad_norm": 0.0,
      "learning_rate": 1.02e-05,
      "loss": 0.0019,
      "step": 55720
    },
    {
      "epoch": 1.5922857142857143,
      "grad_norm": 0.0,
      "learning_rate": 1.0192857142857142e-05,
      "loss": 0.0007,
      "step": 55730
    },
    {
      "epoch": 1.5925714285714285,
      "grad_norm": 0.055076345801353455,
      "learning_rate": 1.0185714285714286e-05,
      "loss": 0.0012,
      "step": 55740
    },
    {
      "epoch": 1.592857142857143,
      "grad_norm": 0.06082816794514656,
      "learning_rate": 1.0178571428571429e-05,
      "loss": 0.0007,
      "step": 55750
    },
    {
      "epoch": 1.5931428571428572,
      "grad_norm": 0.07095316052436829,
      "learning_rate": 1.0171428571428573e-05,
      "loss": 0.001,
      "step": 55760
    },
    {
      "epoch": 1.5934285714285714,
      "grad_norm": 0.0,
      "learning_rate": 1.0164285714285714e-05,
      "loss": 0.0008,
      "step": 55770
    },
    {
      "epoch": 1.5937142857142859,
      "grad_norm": 0.1318047046661377,
      "learning_rate": 1.0157142857142858e-05,
      "loss": 0.0014,
      "step": 55780
    },
    {
      "epoch": 1.5939999999999999,
      "grad_norm": 0.34308069944381714,
      "learning_rate": 1.0150000000000001e-05,
      "loss": 0.001,
      "step": 55790
    },
    {
      "epoch": 1.5942857142857143,
      "grad_norm": 0.0,
      "learning_rate": 1.0142857142857143e-05,
      "loss": 0.002,
      "step": 55800
    },
    {
      "epoch": 1.5945714285714285,
      "grad_norm": 0.06683047860860825,
      "learning_rate": 1.0135714285714286e-05,
      "loss": 0.0009,
      "step": 55810
    },
    {
      "epoch": 1.5948571428571428,
      "grad_norm": 0.08721759915351868,
      "learning_rate": 1.012857142857143e-05,
      "loss": 0.002,
      "step": 55820
    },
    {
      "epoch": 1.5951428571428572,
      "grad_norm": 0.04180720075964928,
      "learning_rate": 1.0121428571428571e-05,
      "loss": 0.0008,
      "step": 55830
    },
    {
      "epoch": 1.5954285714285714,
      "grad_norm": 0.07864054292440414,
      "learning_rate": 1.0114285714285715e-05,
      "loss": 0.0008,
      "step": 55840
    },
    {
      "epoch": 1.5957142857142856,
      "grad_norm": 0.14353147149085999,
      "learning_rate": 1.0107142857142858e-05,
      "loss": 0.0015,
      "step": 55850
    },
    {
      "epoch": 1.596,
      "grad_norm": 0.0568111278116703,
      "learning_rate": 1.0100000000000002e-05,
      "loss": 0.0008,
      "step": 55860
    },
    {
      "epoch": 1.5962857142857143,
      "grad_norm": 0.0,
      "learning_rate": 1.0092857142857143e-05,
      "loss": 0.001,
      "step": 55870
    },
    {
      "epoch": 1.5965714285714285,
      "grad_norm": 0.0,
      "learning_rate": 1.0085714285714287e-05,
      "loss": 0.0005,
      "step": 55880
    },
    {
      "epoch": 1.596857142857143,
      "grad_norm": 0.06761112809181213,
      "learning_rate": 1.0078571428571428e-05,
      "loss": 0.0013,
      "step": 55890
    },
    {
      "epoch": 1.5971428571428572,
      "grad_norm": 0.16771063208580017,
      "learning_rate": 1.0071428571428572e-05,
      "loss": 0.0014,
      "step": 55900
    },
    {
      "epoch": 1.5974285714285714,
      "grad_norm": 0.08204814791679382,
      "learning_rate": 1.0064285714285715e-05,
      "loss": 0.0017,
      "step": 55910
    },
    {
      "epoch": 1.5977142857142859,
      "grad_norm": 0.06706622242927551,
      "learning_rate": 1.0057142857142859e-05,
      "loss": 0.0009,
      "step": 55920
    },
    {
      "epoch": 1.5979999999999999,
      "grad_norm": 0.04721468687057495,
      "learning_rate": 1.005e-05,
      "loss": 0.0008,
      "step": 55930
    },
    {
      "epoch": 1.5982857142857143,
      "grad_norm": 0.04998374357819557,
      "learning_rate": 1.0042857142857142e-05,
      "loss": 0.0017,
      "step": 55940
    },
    {
      "epoch": 1.5985714285714285,
      "grad_norm": 0.3219551742076874,
      "learning_rate": 1.0035714285714285e-05,
      "loss": 0.0007,
      "step": 55950
    },
    {
      "epoch": 1.5988571428571428,
      "grad_norm": 0.14750297367572784,
      "learning_rate": 1.0028571428571429e-05,
      "loss": 0.0009,
      "step": 55960
    },
    {
      "epoch": 1.5991428571428572,
      "grad_norm": 0.17440401017665863,
      "learning_rate": 1.0021428571428572e-05,
      "loss": 0.0007,
      "step": 55970
    },
    {
      "epoch": 1.5994285714285714,
      "grad_norm": 0.0,
      "learning_rate": 1.0014285714285716e-05,
      "loss": 0.0023,
      "step": 55980
    },
    {
      "epoch": 1.5997142857142856,
      "grad_norm": 0.053941354155540466,
      "learning_rate": 1.0007142857142857e-05,
      "loss": 0.0012,
      "step": 55990
    },
    {
      "epoch": 1.6,
      "grad_norm": 0.0,
      "learning_rate": 1e-05,
      "loss": 0.0006,
      "step": 56000
    },
    {
      "epoch": 1.6002857142857143,
      "grad_norm": 0.05916649475693703,
      "learning_rate": 9.992857142857143e-06,
      "loss": 0.0011,
      "step": 56010
    },
    {
      "epoch": 1.6005714285714285,
      "grad_norm": 0.0,
      "learning_rate": 9.985714285714286e-06,
      "loss": 0.0014,
      "step": 56020
    },
    {
      "epoch": 1.600857142857143,
      "grad_norm": 0.053318239748477936,
      "learning_rate": 9.97857142857143e-06,
      "loss": 0.0021,
      "step": 56030
    },
    {
      "epoch": 1.601142857142857,
      "grad_norm": 0.09127850085496902,
      "learning_rate": 9.971428571428571e-06,
      "loss": 0.001,
      "step": 56040
    },
    {
      "epoch": 1.6014285714285714,
      "grad_norm": 0.08236854523420334,
      "learning_rate": 9.964285714285714e-06,
      "loss": 0.0011,
      "step": 56050
    },
    {
      "epoch": 1.6017142857142859,
      "grad_norm": 0.16937392950057983,
      "learning_rate": 9.957142857142858e-06,
      "loss": 0.0004,
      "step": 56060
    },
    {
      "epoch": 1.6019999999999999,
      "grad_norm": 0.05909321829676628,
      "learning_rate": 9.950000000000001e-06,
      "loss": 0.0018,
      "step": 56070
    },
    {
      "epoch": 1.6022857142857143,
      "grad_norm": 0.07052376866340637,
      "learning_rate": 9.942857142857143e-06,
      "loss": 0.0008,
      "step": 56080
    },
    {
      "epoch": 1.6025714285714285,
      "grad_norm": 0.0,
      "learning_rate": 9.935714285714286e-06,
      "loss": 0.0018,
      "step": 56090
    },
    {
      "epoch": 1.6028571428571428,
      "grad_norm": 0.0326244980096817,
      "learning_rate": 9.928571428571428e-06,
      "loss": 0.0013,
      "step": 56100
    },
    {
      "epoch": 1.6031428571428572,
      "grad_norm": 0.08214322477579117,
      "learning_rate": 9.921428571428572e-06,
      "loss": 0.0011,
      "step": 56110
    },
    {
      "epoch": 1.6034285714285714,
      "grad_norm": 0.0,
      "learning_rate": 9.914285714285715e-06,
      "loss": 0.0008,
      "step": 56120
    },
    {
      "epoch": 1.6037142857142856,
      "grad_norm": 0.063025563955307,
      "learning_rate": 9.907142857142858e-06,
      "loss": 0.0009,
      "step": 56130
    },
    {
      "epoch": 1.604,
      "grad_norm": 0.14630340039730072,
      "learning_rate": 9.900000000000002e-06,
      "loss": 0.001,
      "step": 56140
    },
    {
      "epoch": 1.6042857142857143,
      "grad_norm": 0.33276796340942383,
      "learning_rate": 9.892857142857143e-06,
      "loss": 0.0012,
      "step": 56150
    },
    {
      "epoch": 1.6045714285714285,
      "grad_norm": 0.0461074598133564,
      "learning_rate": 9.885714285714285e-06,
      "loss": 0.0009,
      "step": 56160
    },
    {
      "epoch": 1.604857142857143,
      "grad_norm": 0.06445181369781494,
      "learning_rate": 9.878571428571429e-06,
      "loss": 0.0015,
      "step": 56170
    },
    {
      "epoch": 1.605142857142857,
      "grad_norm": 0.34723326563835144,
      "learning_rate": 9.871428571428572e-06,
      "loss": 0.0008,
      "step": 56180
    },
    {
      "epoch": 1.6054285714285714,
      "grad_norm": 0.2213297337293625,
      "learning_rate": 9.864285714285715e-06,
      "loss": 0.0004,
      "step": 56190
    },
    {
      "epoch": 1.6057142857142859,
      "grad_norm": 0.08225611597299576,
      "learning_rate": 9.857142857142857e-06,
      "loss": 0.0009,
      "step": 56200
    },
    {
      "epoch": 1.6059999999999999,
      "grad_norm": 0.09101907908916473,
      "learning_rate": 9.85e-06,
      "loss": 0.0013,
      "step": 56210
    },
    {
      "epoch": 1.6062857142857143,
      "grad_norm": 0.35661202669143677,
      "learning_rate": 9.842857142857144e-06,
      "loss": 0.0006,
      "step": 56220
    },
    {
      "epoch": 1.6065714285714285,
      "grad_norm": 0.3333202302455902,
      "learning_rate": 9.835714285714286e-06,
      "loss": 0.0011,
      "step": 56230
    },
    {
      "epoch": 1.6068571428571428,
      "grad_norm": 0.0425180085003376,
      "learning_rate": 9.828571428571429e-06,
      "loss": 0.0009,
      "step": 56240
    },
    {
      "epoch": 1.6071428571428572,
      "grad_norm": 0.04287244379520416,
      "learning_rate": 9.821428571428573e-06,
      "loss": 0.0014,
      "step": 56250
    },
    {
      "epoch": 1.6074285714285714,
      "grad_norm": 0.050076764076948166,
      "learning_rate": 9.814285714285714e-06,
      "loss": 0.0009,
      "step": 56260
    },
    {
      "epoch": 1.6077142857142857,
      "grad_norm": 0.04504501447081566,
      "learning_rate": 9.807142857142858e-06,
      "loss": 0.0026,
      "step": 56270
    },
    {
      "epoch": 1.608,
      "grad_norm": 0.05501335486769676,
      "learning_rate": 9.800000000000001e-06,
      "loss": 0.0009,
      "step": 56280
    },
    {
      "epoch": 1.6082857142857143,
      "grad_norm": 0.04796246439218521,
      "learning_rate": 9.792857142857144e-06,
      "loss": 0.0016,
      "step": 56290
    },
    {
      "epoch": 1.6085714285714285,
      "grad_norm": 0.0,
      "learning_rate": 9.785714285714286e-06,
      "loss": 0.0007,
      "step": 56300
    },
    {
      "epoch": 1.608857142857143,
      "grad_norm": 0.040840037167072296,
      "learning_rate": 9.778571428571428e-06,
      "loss": 0.0014,
      "step": 56310
    },
    {
      "epoch": 1.609142857142857,
      "grad_norm": 0.09220899641513824,
      "learning_rate": 9.771428571428571e-06,
      "loss": 0.0009,
      "step": 56320
    },
    {
      "epoch": 1.6094285714285714,
      "grad_norm": 0.10115121304988861,
      "learning_rate": 9.764285714285715e-06,
      "loss": 0.0005,
      "step": 56330
    },
    {
      "epoch": 1.6097142857142859,
      "grad_norm": 0.0,
      "learning_rate": 9.757142857142858e-06,
      "loss": 0.001,
      "step": 56340
    },
    {
      "epoch": 1.6099999999999999,
      "grad_norm": 0.1434294432401657,
      "learning_rate": 9.750000000000002e-06,
      "loss": 0.0008,
      "step": 56350
    },
    {
      "epoch": 1.6102857142857143,
      "grad_norm": 0.06479542702436447,
      "learning_rate": 9.742857142857143e-06,
      "loss": 0.0009,
      "step": 56360
    },
    {
      "epoch": 1.6105714285714285,
      "grad_norm": 0.12067223340272903,
      "learning_rate": 9.735714285714285e-06,
      "loss": 0.0009,
      "step": 56370
    },
    {
      "epoch": 1.6108571428571428,
      "grad_norm": 0.0,
      "learning_rate": 9.728571428571428e-06,
      "loss": 0.0004,
      "step": 56380
    },
    {
      "epoch": 1.6111428571428572,
      "grad_norm": 0.11890125274658203,
      "learning_rate": 9.721428571428572e-06,
      "loss": 0.0016,
      "step": 56390
    },
    {
      "epoch": 1.6114285714285714,
      "grad_norm": 0.09282202273607254,
      "learning_rate": 9.714285714285715e-06,
      "loss": 0.0007,
      "step": 56400
    },
    {
      "epoch": 1.6117142857142857,
      "grad_norm": 0.05640532821416855,
      "learning_rate": 9.707142857142857e-06,
      "loss": 0.0015,
      "step": 56410
    },
    {
      "epoch": 1.612,
      "grad_norm": 0.04434980824589729,
      "learning_rate": 9.7e-06,
      "loss": 0.002,
      "step": 56420
    },
    {
      "epoch": 1.6122857142857143,
      "grad_norm": 0.0,
      "learning_rate": 9.692857142857144e-06,
      "loss": 0.0012,
      "step": 56430
    },
    {
      "epoch": 1.6125714285714285,
      "grad_norm": 0.06128272786736488,
      "learning_rate": 9.685714285714287e-06,
      "loss": 0.0013,
      "step": 56440
    },
    {
      "epoch": 1.612857142857143,
      "grad_norm": 0.048675332218408585,
      "learning_rate": 9.678571428571429e-06,
      "loss": 0.0009,
      "step": 56450
    },
    {
      "epoch": 1.613142857142857,
      "grad_norm": 0.19716711342334747,
      "learning_rate": 9.671428571428572e-06,
      "loss": 0.0009,
      "step": 56460
    },
    {
      "epoch": 1.6134285714285714,
      "grad_norm": 0.045577991753816605,
      "learning_rate": 9.664285714285714e-06,
      "loss": 0.0004,
      "step": 56470
    },
    {
      "epoch": 1.6137142857142859,
      "grad_norm": 0.0,
      "learning_rate": 9.657142857142857e-06,
      "loss": 0.0009,
      "step": 56480
    },
    {
      "epoch": 1.6139999999999999,
      "grad_norm": 0.05163523927330971,
      "learning_rate": 9.65e-06,
      "loss": 0.0009,
      "step": 56490
    },
    {
      "epoch": 1.6142857142857143,
      "grad_norm": 0.0,
      "learning_rate": 9.642857142857144e-06,
      "loss": 0.001,
      "step": 56500
    },
    {
      "epoch": 1.6145714285714285,
      "grad_norm": 0.08153937757015228,
      "learning_rate": 9.635714285714288e-06,
      "loss": 0.0005,
      "step": 56510
    },
    {
      "epoch": 1.6148571428571428,
      "grad_norm": 0.0,
      "learning_rate": 9.628571428571428e-06,
      "loss": 0.002,
      "step": 56520
    },
    {
      "epoch": 1.6151428571428572,
      "grad_norm": 0.0,
      "learning_rate": 9.621428571428571e-06,
      "loss": 0.0008,
      "step": 56530
    },
    {
      "epoch": 1.6154285714285714,
      "grad_norm": 0.09085831791162491,
      "learning_rate": 9.614285714285714e-06,
      "loss": 0.001,
      "step": 56540
    },
    {
      "epoch": 1.6157142857142857,
      "grad_norm": 0.14811138808727264,
      "learning_rate": 9.607142857142858e-06,
      "loss": 0.002,
      "step": 56550
    },
    {
      "epoch": 1.616,
      "grad_norm": 0.3261122405529022,
      "learning_rate": 9.600000000000001e-06,
      "loss": 0.0008,
      "step": 56560
    },
    {
      "epoch": 1.6162857142857143,
      "grad_norm": 0.04425322264432907,
      "learning_rate": 9.592857142857143e-06,
      "loss": 0.001,
      "step": 56570
    },
    {
      "epoch": 1.6165714285714285,
      "grad_norm": 0.433075487613678,
      "learning_rate": 9.585714285714286e-06,
      "loss": 0.0012,
      "step": 56580
    },
    {
      "epoch": 1.616857142857143,
      "grad_norm": 0.05895743519067764,
      "learning_rate": 9.578571428571428e-06,
      "loss": 0.0013,
      "step": 56590
    },
    {
      "epoch": 1.617142857142857,
      "grad_norm": 0.05087639391422272,
      "learning_rate": 9.571428571428572e-06,
      "loss": 0.0008,
      "step": 56600
    },
    {
      "epoch": 1.6174285714285714,
      "grad_norm": 0.3344047963619232,
      "learning_rate": 9.564285714285715e-06,
      "loss": 0.0017,
      "step": 56610
    },
    {
      "epoch": 1.6177142857142857,
      "grad_norm": 0.0,
      "learning_rate": 9.557142857142858e-06,
      "loss": 0.0005,
      "step": 56620
    },
    {
      "epoch": 1.6179999999999999,
      "grad_norm": 0.08643534779548645,
      "learning_rate": 9.55e-06,
      "loss": 0.0009,
      "step": 56630
    },
    {
      "epoch": 1.6182857142857143,
      "grad_norm": 0.5168713331222534,
      "learning_rate": 9.542857142857143e-06,
      "loss": 0.0015,
      "step": 56640
    },
    {
      "epoch": 1.6185714285714285,
      "grad_norm": 0.052312836050987244,
      "learning_rate": 9.535714285714287e-06,
      "loss": 0.0016,
      "step": 56650
    },
    {
      "epoch": 1.6188571428571428,
      "grad_norm": 0.22083622217178345,
      "learning_rate": 9.528571428571429e-06,
      "loss": 0.0005,
      "step": 56660
    },
    {
      "epoch": 1.6191428571428572,
      "grad_norm": 0.0,
      "learning_rate": 9.521428571428572e-06,
      "loss": 0.0016,
      "step": 56670
    },
    {
      "epoch": 1.6194285714285714,
      "grad_norm": 0.0,
      "learning_rate": 9.514285714285714e-06,
      "loss": 0.0006,
      "step": 56680
    },
    {
      "epoch": 1.6197142857142857,
      "grad_norm": 0.273387610912323,
      "learning_rate": 9.507142857142857e-06,
      "loss": 0.0015,
      "step": 56690
    },
    {
      "epoch": 1.62,
      "grad_norm": 0.043555788695812225,
      "learning_rate": 9.5e-06,
      "loss": 0.0005,
      "step": 56700
    },
    {
      "epoch": 1.6202857142857143,
      "grad_norm": 0.10444062203168869,
      "learning_rate": 9.492857142857144e-06,
      "loss": 0.0013,
      "step": 56710
    },
    {
      "epoch": 1.6205714285714286,
      "grad_norm": 0.12206604331731796,
      "learning_rate": 9.485714285714287e-06,
      "loss": 0.002,
      "step": 56720
    },
    {
      "epoch": 1.620857142857143,
      "grad_norm": 0.16636304557323456,
      "learning_rate": 9.478571428571429e-06,
      "loss": 0.0014,
      "step": 56730
    },
    {
      "epoch": 1.621142857142857,
      "grad_norm": 0.15273192524909973,
      "learning_rate": 9.47142857142857e-06,
      "loss": 0.0009,
      "step": 56740
    },
    {
      "epoch": 1.6214285714285714,
      "grad_norm": 0.10912957042455673,
      "learning_rate": 9.464285714285714e-06,
      "loss": 0.0004,
      "step": 56750
    },
    {
      "epoch": 1.6217142857142857,
      "grad_norm": 0.295074999332428,
      "learning_rate": 9.457142857142858e-06,
      "loss": 0.0008,
      "step": 56760
    },
    {
      "epoch": 1.6219999999999999,
      "grad_norm": 0.048470161855220795,
      "learning_rate": 9.450000000000001e-06,
      "loss": 0.0009,
      "step": 56770
    },
    {
      "epoch": 1.6222857142857143,
      "grad_norm": 0.12481372058391571,
      "learning_rate": 9.442857142857144e-06,
      "loss": 0.0019,
      "step": 56780
    },
    {
      "epoch": 1.6225714285714286,
      "grad_norm": 0.05080131068825722,
      "learning_rate": 9.435714285714286e-06,
      "loss": 0.0011,
      "step": 56790
    },
    {
      "epoch": 1.6228571428571428,
      "grad_norm": 0.04790510609745979,
      "learning_rate": 9.42857142857143e-06,
      "loss": 0.001,
      "step": 56800
    },
    {
      "epoch": 1.6231428571428572,
      "grad_norm": 0.04207906499505043,
      "learning_rate": 9.421428571428571e-06,
      "loss": 0.0011,
      "step": 56810
    },
    {
      "epoch": 1.6234285714285714,
      "grad_norm": 0.08044904470443726,
      "learning_rate": 9.414285714285715e-06,
      "loss": 0.0009,
      "step": 56820
    },
    {
      "epoch": 1.6237142857142857,
      "grad_norm": 0.0,
      "learning_rate": 9.407142857142858e-06,
      "loss": 0.0009,
      "step": 56830
    },
    {
      "epoch": 1.624,
      "grad_norm": 0.046682242304086685,
      "learning_rate": 9.4e-06,
      "loss": 0.0015,
      "step": 56840
    },
    {
      "epoch": 1.6242857142857143,
      "grad_norm": 0.1493382602930069,
      "learning_rate": 9.392857142857143e-06,
      "loss": 0.0007,
      "step": 56850
    },
    {
      "epoch": 1.6245714285714286,
      "grad_norm": 0.15307381749153137,
      "learning_rate": 9.385714285714287e-06,
      "loss": 0.0013,
      "step": 56860
    },
    {
      "epoch": 1.624857142857143,
      "grad_norm": 0.08178293704986572,
      "learning_rate": 9.37857142857143e-06,
      "loss": 0.0008,
      "step": 56870
    },
    {
      "epoch": 1.625142857142857,
      "grad_norm": 0.04208489879965782,
      "learning_rate": 9.371428571428572e-06,
      "loss": 0.0005,
      "step": 56880
    },
    {
      "epoch": 1.6254285714285714,
      "grad_norm": 0.052949752658605576,
      "learning_rate": 9.364285714285715e-06,
      "loss": 0.0012,
      "step": 56890
    },
    {
      "epoch": 1.6257142857142857,
      "grad_norm": 0.0,
      "learning_rate": 9.357142857142857e-06,
      "loss": 0.0014,
      "step": 56900
    },
    {
      "epoch": 1.626,
      "grad_norm": 0.0,
      "learning_rate": 9.35e-06,
      "loss": 0.0008,
      "step": 56910
    },
    {
      "epoch": 1.6262857142857143,
      "grad_norm": 0.09010668098926544,
      "learning_rate": 9.342857142857144e-06,
      "loss": 0.0018,
      "step": 56920
    },
    {
      "epoch": 1.6265714285714286,
      "grad_norm": 0.0,
      "learning_rate": 9.335714285714287e-06,
      "loss": 0.0011,
      "step": 56930
    },
    {
      "epoch": 1.6268571428571428,
      "grad_norm": 0.0478593148291111,
      "learning_rate": 9.328571428571429e-06,
      "loss": 0.0008,
      "step": 56940
    },
    {
      "epoch": 1.6271428571428572,
      "grad_norm": 0.12888860702514648,
      "learning_rate": 9.32142857142857e-06,
      "loss": 0.0011,
      "step": 56950
    },
    {
      "epoch": 1.6274285714285714,
      "grad_norm": 0.061653051525354385,
      "learning_rate": 9.314285714285714e-06,
      "loss": 0.0024,
      "step": 56960
    },
    {
      "epoch": 1.6277142857142857,
      "grad_norm": 0.04169144853949547,
      "learning_rate": 9.307142857142857e-06,
      "loss": 0.001,
      "step": 56970
    },
    {
      "epoch": 1.6280000000000001,
      "grad_norm": 0.0,
      "learning_rate": 9.3e-06,
      "loss": 0.0011,
      "step": 56980
    },
    {
      "epoch": 1.6282857142857143,
      "grad_norm": 0.0,
      "learning_rate": 9.292857142857144e-06,
      "loss": 0.0007,
      "step": 56990
    },
    {
      "epoch": 1.6285714285714286,
      "grad_norm": 0.09878778457641602,
      "learning_rate": 9.285714285714286e-06,
      "loss": 0.0012,
      "step": 57000
    },
    {
      "epoch": 1.628857142857143,
      "grad_norm": 0.04729731008410454,
      "learning_rate": 9.27857142857143e-06,
      "loss": 0.0006,
      "step": 57010
    },
    {
      "epoch": 1.629142857142857,
      "grad_norm": 0.06283249706029892,
      "learning_rate": 9.271428571428571e-06,
      "loss": 0.0021,
      "step": 57020
    },
    {
      "epoch": 1.6294285714285714,
      "grad_norm": 0.0,
      "learning_rate": 9.264285714285714e-06,
      "loss": 0.0008,
      "step": 57030
    },
    {
      "epoch": 1.6297142857142857,
      "grad_norm": 0.36530545353889465,
      "learning_rate": 9.257142857142858e-06,
      "loss": 0.0013,
      "step": 57040
    },
    {
      "epoch": 1.63,
      "grad_norm": 0.10574934631586075,
      "learning_rate": 9.25e-06,
      "loss": 0.0012,
      "step": 57050
    },
    {
      "epoch": 1.6302857142857143,
      "grad_norm": 0.07712648063898087,
      "learning_rate": 9.242857142857143e-06,
      "loss": 0.0003,
      "step": 57060
    },
    {
      "epoch": 1.6305714285714286,
      "grad_norm": 0.09780869632959366,
      "learning_rate": 9.235714285714286e-06,
      "loss": 0.0009,
      "step": 57070
    },
    {
      "epoch": 1.6308571428571428,
      "grad_norm": 0.1870315819978714,
      "learning_rate": 9.22857142857143e-06,
      "loss": 0.0012,
      "step": 57080
    },
    {
      "epoch": 1.6311428571428572,
      "grad_norm": 0.0,
      "learning_rate": 9.221428571428573e-06,
      "loss": 0.0006,
      "step": 57090
    },
    {
      "epoch": 1.6314285714285715,
      "grad_norm": 0.0,
      "learning_rate": 9.214285714285715e-06,
      "loss": 0.002,
      "step": 57100
    },
    {
      "epoch": 1.6317142857142857,
      "grad_norm": 0.0,
      "learning_rate": 9.207142857142857e-06,
      "loss": 0.0003,
      "step": 57110
    },
    {
      "epoch": 1.6320000000000001,
      "grad_norm": 0.2846490144729614,
      "learning_rate": 9.2e-06,
      "loss": 0.0008,
      "step": 57120
    },
    {
      "epoch": 1.6322857142857143,
      "grad_norm": 0.07319355010986328,
      "learning_rate": 9.192857142857143e-06,
      "loss": 0.0013,
      "step": 57130
    },
    {
      "epoch": 1.6325714285714286,
      "grad_norm": 0.22749541699886322,
      "learning_rate": 9.185714285714287e-06,
      "loss": 0.0013,
      "step": 57140
    },
    {
      "epoch": 1.632857142857143,
      "grad_norm": 0.05053265392780304,
      "learning_rate": 9.17857142857143e-06,
      "loss": 0.0013,
      "step": 57150
    },
    {
      "epoch": 1.633142857142857,
      "grad_norm": 0.0,
      "learning_rate": 9.171428571428572e-06,
      "loss": 0.0007,
      "step": 57160
    },
    {
      "epoch": 1.6334285714285715,
      "grad_norm": 0.0,
      "learning_rate": 9.164285714285714e-06,
      "loss": 0.0015,
      "step": 57170
    },
    {
      "epoch": 1.6337142857142857,
      "grad_norm": 0.0,
      "learning_rate": 9.157142857142857e-06,
      "loss": 0.0009,
      "step": 57180
    },
    {
      "epoch": 1.634,
      "grad_norm": 0.043368078768253326,
      "learning_rate": 9.15e-06,
      "loss": 0.0031,
      "step": 57190
    },
    {
      "epoch": 1.6342857142857143,
      "grad_norm": 0.04724256694316864,
      "learning_rate": 9.142857142857144e-06,
      "loss": 0.0008,
      "step": 57200
    },
    {
      "epoch": 1.6345714285714286,
      "grad_norm": 0.0468846894800663,
      "learning_rate": 9.135714285714286e-06,
      "loss": 0.0013,
      "step": 57210
    },
    {
      "epoch": 1.6348571428571428,
      "grad_norm": 0.24255599081516266,
      "learning_rate": 9.128571428571429e-06,
      "loss": 0.0014,
      "step": 57220
    },
    {
      "epoch": 1.6351428571428572,
      "grad_norm": 0.0,
      "learning_rate": 9.121428571428572e-06,
      "loss": 0.0007,
      "step": 57230
    },
    {
      "epoch": 1.6354285714285715,
      "grad_norm": 0.04531671851873398,
      "learning_rate": 9.114285714285714e-06,
      "loss": 0.0009,
      "step": 57240
    },
    {
      "epoch": 1.6357142857142857,
      "grad_norm": 0.0,
      "learning_rate": 9.107142857142858e-06,
      "loss": 0.0007,
      "step": 57250
    },
    {
      "epoch": 1.6360000000000001,
      "grad_norm": 0.05345914885401726,
      "learning_rate": 9.100000000000001e-06,
      "loss": 0.0013,
      "step": 57260
    },
    {
      "epoch": 1.6362857142857141,
      "grad_norm": 0.09144742786884308,
      "learning_rate": 9.092857142857143e-06,
      "loss": 0.0008,
      "step": 57270
    },
    {
      "epoch": 1.6365714285714286,
      "grad_norm": 0.10477053374052048,
      "learning_rate": 9.085714285714286e-06,
      "loss": 0.0013,
      "step": 57280
    },
    {
      "epoch": 1.636857142857143,
      "grad_norm": 0.22175946831703186,
      "learning_rate": 9.07857142857143e-06,
      "loss": 0.0011,
      "step": 57290
    },
    {
      "epoch": 1.637142857142857,
      "grad_norm": 0.04335739463567734,
      "learning_rate": 9.071428571428573e-06,
      "loss": 0.0014,
      "step": 57300
    },
    {
      "epoch": 1.6374285714285715,
      "grad_norm": 0.02987227402627468,
      "learning_rate": 9.064285714285715e-06,
      "loss": 0.0005,
      "step": 57310
    },
    {
      "epoch": 1.6377142857142857,
      "grad_norm": 0.052734341472387314,
      "learning_rate": 9.057142857142856e-06,
      "loss": 0.0006,
      "step": 57320
    },
    {
      "epoch": 1.638,
      "grad_norm": 0.0908423587679863,
      "learning_rate": 9.05e-06,
      "loss": 0.0011,
      "step": 57330
    },
    {
      "epoch": 1.6382857142857143,
      "grad_norm": 0.05247551575303078,
      "learning_rate": 9.042857142857143e-06,
      "loss": 0.0008,
      "step": 57340
    },
    {
      "epoch": 1.6385714285714286,
      "grad_norm": 0.05401694029569626,
      "learning_rate": 9.035714285714287e-06,
      "loss": 0.0009,
      "step": 57350
    },
    {
      "epoch": 1.6388571428571428,
      "grad_norm": 0.06124909594655037,
      "learning_rate": 9.02857142857143e-06,
      "loss": 0.0017,
      "step": 57360
    },
    {
      "epoch": 1.6391428571428572,
      "grad_norm": 0.0,
      "learning_rate": 9.021428571428572e-06,
      "loss": 0.001,
      "step": 57370
    },
    {
      "epoch": 1.6394285714285715,
      "grad_norm": 0.08936075121164322,
      "learning_rate": 9.014285714285715e-06,
      "loss": 0.0019,
      "step": 57380
    },
    {
      "epoch": 1.6397142857142857,
      "grad_norm": 0.29496312141418457,
      "learning_rate": 9.007142857142857e-06,
      "loss": 0.0012,
      "step": 57390
    },
    {
      "epoch": 1.6400000000000001,
      "grad_norm": 0.07732886075973511,
      "learning_rate": 9e-06,
      "loss": 0.0009,
      "step": 57400
    },
    {
      "epoch": 1.6402857142857141,
      "grad_norm": 0.0,
      "learning_rate": 8.992857142857144e-06,
      "loss": 0.0006,
      "step": 57410
    },
    {
      "epoch": 1.6405714285714286,
      "grad_norm": 0.15429618954658508,
      "learning_rate": 8.985714285714285e-06,
      "loss": 0.0009,
      "step": 57420
    },
    {
      "epoch": 1.640857142857143,
      "grad_norm": 0.21157383918762207,
      "learning_rate": 8.978571428571429e-06,
      "loss": 0.002,
      "step": 57430
    },
    {
      "epoch": 1.641142857142857,
      "grad_norm": 0.04662122577428818,
      "learning_rate": 8.971428571428572e-06,
      "loss": 0.0015,
      "step": 57440
    },
    {
      "epoch": 1.6414285714285715,
      "grad_norm": 0.3110995590686798,
      "learning_rate": 8.964285714285716e-06,
      "loss": 0.0012,
      "step": 57450
    },
    {
      "epoch": 1.6417142857142857,
      "grad_norm": 0.05362464115023613,
      "learning_rate": 8.957142857142857e-06,
      "loss": 0.0011,
      "step": 57460
    },
    {
      "epoch": 1.642,
      "grad_norm": 0.08639930933713913,
      "learning_rate": 8.95e-06,
      "loss": 0.0018,
      "step": 57470
    },
    {
      "epoch": 1.6422857142857143,
      "grad_norm": 0.13382405042648315,
      "learning_rate": 8.942857142857142e-06,
      "loss": 0.0006,
      "step": 57480
    },
    {
      "epoch": 1.6425714285714286,
      "grad_norm": 0.0,
      "learning_rate": 8.935714285714286e-06,
      "loss": 0.0003,
      "step": 57490
    },
    {
      "epoch": 1.6428571428571428,
      "grad_norm": 0.0,
      "learning_rate": 8.92857142857143e-06,
      "loss": 0.0007,
      "step": 57500
    },
    {
      "epoch": 1.6431428571428572,
      "grad_norm": 0.04063388705253601,
      "learning_rate": 8.921428571428573e-06,
      "loss": 0.0016,
      "step": 57510
    },
    {
      "epoch": 1.6434285714285715,
      "grad_norm": 0.29826802015304565,
      "learning_rate": 8.914285714285716e-06,
      "loss": 0.0007,
      "step": 57520
    },
    {
      "epoch": 1.6437142857142857,
      "grad_norm": 0.04295888543128967,
      "learning_rate": 8.907142857142858e-06,
      "loss": 0.0009,
      "step": 57530
    },
    {
      "epoch": 1.6440000000000001,
      "grad_norm": 0.14223350584506989,
      "learning_rate": 8.9e-06,
      "loss": 0.0011,
      "step": 57540
    },
    {
      "epoch": 1.6442857142857141,
      "grad_norm": 0.4354533553123474,
      "learning_rate": 8.892857142857143e-06,
      "loss": 0.0012,
      "step": 57550
    },
    {
      "epoch": 1.6445714285714286,
      "grad_norm": 0.04898333176970482,
      "learning_rate": 8.885714285714286e-06,
      "loss": 0.001,
      "step": 57560
    },
    {
      "epoch": 1.644857142857143,
      "grad_norm": 0.04961403086781502,
      "learning_rate": 8.87857142857143e-06,
      "loss": 0.001,
      "step": 57570
    },
    {
      "epoch": 1.645142857142857,
      "grad_norm": 0.04411531239748001,
      "learning_rate": 8.871428571428571e-06,
      "loss": 0.0009,
      "step": 57580
    },
    {
      "epoch": 1.6454285714285715,
      "grad_norm": 0.0,
      "learning_rate": 8.864285714285715e-06,
      "loss": 0.002,
      "step": 57590
    },
    {
      "epoch": 1.6457142857142857,
      "grad_norm": 0.05213969573378563,
      "learning_rate": 8.857142857142857e-06,
      "loss": 0.0007,
      "step": 57600
    },
    {
      "epoch": 1.646,
      "grad_norm": 0.27956101298332214,
      "learning_rate": 8.85e-06,
      "loss": 0.0013,
      "step": 57610
    },
    {
      "epoch": 1.6462857142857144,
      "grad_norm": 0.048718590289354324,
      "learning_rate": 8.842857142857143e-06,
      "loss": 0.0016,
      "step": 57620
    },
    {
      "epoch": 1.6465714285714286,
      "grad_norm": 0.0,
      "learning_rate": 8.835714285714287e-06,
      "loss": 0.0012,
      "step": 57630
    },
    {
      "epoch": 1.6468571428571428,
      "grad_norm": 0.09018943458795547,
      "learning_rate": 8.828571428571429e-06,
      "loss": 0.0008,
      "step": 57640
    },
    {
      "epoch": 1.6471428571428572,
      "grad_norm": 0.041700053960084915,
      "learning_rate": 8.821428571428572e-06,
      "loss": 0.0007,
      "step": 57650
    },
    {
      "epoch": 1.6474285714285715,
      "grad_norm": 0.11234050989151001,
      "learning_rate": 8.814285714285715e-06,
      "loss": 0.0003,
      "step": 57660
    },
    {
      "epoch": 1.6477142857142857,
      "grad_norm": 0.05228692293167114,
      "learning_rate": 8.807142857142859e-06,
      "loss": 0.0016,
      "step": 57670
    },
    {
      "epoch": 1.6480000000000001,
      "grad_norm": 0.4563891887664795,
      "learning_rate": 8.8e-06,
      "loss": 0.0018,
      "step": 57680
    },
    {
      "epoch": 1.6482857142857141,
      "grad_norm": 0.0,
      "learning_rate": 8.792857142857142e-06,
      "loss": 0.0008,
      "step": 57690
    },
    {
      "epoch": 1.6485714285714286,
      "grad_norm": 0.31099429726600647,
      "learning_rate": 8.785714285714286e-06,
      "loss": 0.0019,
      "step": 57700
    },
    {
      "epoch": 1.648857142857143,
      "grad_norm": 0.04766743630170822,
      "learning_rate": 8.778571428571429e-06,
      "loss": 0.0004,
      "step": 57710
    },
    {
      "epoch": 1.649142857142857,
      "grad_norm": 0.0,
      "learning_rate": 8.771428571428572e-06,
      "loss": 0.0005,
      "step": 57720
    },
    {
      "epoch": 1.6494285714285715,
      "grad_norm": 0.0,
      "learning_rate": 8.764285714285716e-06,
      "loss": 0.0016,
      "step": 57730
    },
    {
      "epoch": 1.6497142857142857,
      "grad_norm": 0.046376727521419525,
      "learning_rate": 8.757142857142858e-06,
      "loss": 0.0008,
      "step": 57740
    },
    {
      "epoch": 1.65,
      "grad_norm": 0.06502892822027206,
      "learning_rate": 8.75e-06,
      "loss": 0.0008,
      "step": 57750
    },
    {
      "epoch": 1.6502857142857144,
      "grad_norm": 0.25973397493362427,
      "learning_rate": 8.742857142857143e-06,
      "loss": 0.0012,
      "step": 57760
    },
    {
      "epoch": 1.6505714285714286,
      "grad_norm": 0.058698393404483795,
      "learning_rate": 8.735714285714286e-06,
      "loss": 0.0009,
      "step": 57770
    },
    {
      "epoch": 1.6508571428571428,
      "grad_norm": 0.0,
      "learning_rate": 8.72857142857143e-06,
      "loss": 0.0012,
      "step": 57780
    },
    {
      "epoch": 1.6511428571428572,
      "grad_norm": 0.0,
      "learning_rate": 8.721428571428573e-06,
      "loss": 0.0007,
      "step": 57790
    },
    {
      "epoch": 1.6514285714285715,
      "grad_norm": 0.05146460607647896,
      "learning_rate": 8.714285714285715e-06,
      "loss": 0.0007,
      "step": 57800
    },
    {
      "epoch": 1.6517142857142857,
      "grad_norm": 0.16050483286380768,
      "learning_rate": 8.707142857142858e-06,
      "loss": 0.001,
      "step": 57810
    },
    {
      "epoch": 1.6520000000000001,
      "grad_norm": 0.0,
      "learning_rate": 8.7e-06,
      "loss": 0.0015,
      "step": 57820
    },
    {
      "epoch": 1.6522857142857141,
      "grad_norm": 0.0,
      "learning_rate": 8.692857142857143e-06,
      "loss": 0.0013,
      "step": 57830
    },
    {
      "epoch": 1.6525714285714286,
      "grad_norm": 0.0,
      "learning_rate": 8.685714285714287e-06,
      "loss": 0.0007,
      "step": 57840
    },
    {
      "epoch": 1.6528571428571428,
      "grad_norm": 0.04307463392615318,
      "learning_rate": 8.678571428571428e-06,
      "loss": 0.0007,
      "step": 57850
    },
    {
      "epoch": 1.653142857142857,
      "grad_norm": 0.09730000048875809,
      "learning_rate": 8.671428571428572e-06,
      "loss": 0.0003,
      "step": 57860
    },
    {
      "epoch": 1.6534285714285715,
      "grad_norm": 0.0,
      "learning_rate": 8.664285714285715e-06,
      "loss": 0.0011,
      "step": 57870
    },
    {
      "epoch": 1.6537142857142857,
      "grad_norm": 0.21078814566135406,
      "learning_rate": 8.657142857142858e-06,
      "loss": 0.0004,
      "step": 57880
    },
    {
      "epoch": 1.654,
      "grad_norm": 0.0494898185133934,
      "learning_rate": 8.65e-06,
      "loss": 0.001,
      "step": 57890
    },
    {
      "epoch": 1.6542857142857144,
      "grad_norm": 0.2753245234489441,
      "learning_rate": 8.642857142857144e-06,
      "loss": 0.0006,
      "step": 57900
    },
    {
      "epoch": 1.6545714285714286,
      "grad_norm": 0.3185337781906128,
      "learning_rate": 8.635714285714285e-06,
      "loss": 0.0011,
      "step": 57910
    },
    {
      "epoch": 1.6548571428571428,
      "grad_norm": 0.280317097902298,
      "learning_rate": 8.628571428571429e-06,
      "loss": 0.0006,
      "step": 57920
    },
    {
      "epoch": 1.6551428571428572,
      "grad_norm": 0.0,
      "learning_rate": 8.621428571428572e-06,
      "loss": 0.0006,
      "step": 57930
    },
    {
      "epoch": 1.6554285714285715,
      "grad_norm": 0.04093730077147484,
      "learning_rate": 8.614285714285716e-06,
      "loss": 0.0012,
      "step": 57940
    },
    {
      "epoch": 1.6557142857142857,
      "grad_norm": 0.0,
      "learning_rate": 8.607142857142857e-06,
      "loss": 0.0005,
      "step": 57950
    },
    {
      "epoch": 1.6560000000000001,
      "grad_norm": 0.05812973529100418,
      "learning_rate": 8.599999999999999e-06,
      "loss": 0.0012,
      "step": 57960
    },
    {
      "epoch": 1.6562857142857141,
      "grad_norm": 0.04595599323511124,
      "learning_rate": 8.592857142857142e-06,
      "loss": 0.0008,
      "step": 57970
    },
    {
      "epoch": 1.6565714285714286,
      "grad_norm": 0.0,
      "learning_rate": 8.585714285714286e-06,
      "loss": 0.0016,
      "step": 57980
    },
    {
      "epoch": 1.6568571428571428,
      "grad_norm": 0.050974056124687195,
      "learning_rate": 8.57857142857143e-06,
      "loss": 0.0019,
      "step": 57990
    },
    {
      "epoch": 1.657142857142857,
      "grad_norm": 0.0,
      "learning_rate": 8.571428571428573e-06,
      "loss": 0.0014,
      "step": 58000
    },
    {
      "epoch": 1.6574285714285715,
      "grad_norm": 0.0,
      "learning_rate": 8.564285714285714e-06,
      "loss": 0.0009,
      "step": 58010
    },
    {
      "epoch": 1.6577142857142857,
      "grad_norm": 0.04655705764889717,
      "learning_rate": 8.557142857142858e-06,
      "loss": 0.0012,
      "step": 58020
    },
    {
      "epoch": 1.658,
      "grad_norm": 0.051322516053915024,
      "learning_rate": 8.550000000000001e-06,
      "loss": 0.0008,
      "step": 58030
    },
    {
      "epoch": 1.6582857142857144,
      "grad_norm": 0.0,
      "learning_rate": 8.542857142857143e-06,
      "loss": 0.0021,
      "step": 58040
    },
    {
      "epoch": 1.6585714285714286,
      "grad_norm": 0.041591934859752655,
      "learning_rate": 8.535714285714286e-06,
      "loss": 0.001,
      "step": 58050
    },
    {
      "epoch": 1.6588571428571428,
      "grad_norm": 0.06206752732396126,
      "learning_rate": 8.528571428571428e-06,
      "loss": 0.0017,
      "step": 58060
    },
    {
      "epoch": 1.6591428571428573,
      "grad_norm": 0.0764583945274353,
      "learning_rate": 8.521428571428571e-06,
      "loss": 0.0009,
      "step": 58070
    },
    {
      "epoch": 1.6594285714285715,
      "grad_norm": 0.0,
      "learning_rate": 8.514285714285715e-06,
      "loss": 0.0004,
      "step": 58080
    },
    {
      "epoch": 1.6597142857142857,
      "grad_norm": 0.060776785016059875,
      "learning_rate": 8.507142857142858e-06,
      "loss": 0.0007,
      "step": 58090
    },
    {
      "epoch": 1.6600000000000001,
      "grad_norm": 0.0,
      "learning_rate": 8.500000000000002e-06,
      "loss": 0.0011,
      "step": 58100
    },
    {
      "epoch": 1.6602857142857141,
      "grad_norm": 0.0,
      "learning_rate": 8.492857142857143e-06,
      "loss": 0.0012,
      "step": 58110
    },
    {
      "epoch": 1.6605714285714286,
      "grad_norm": 0.02313782460987568,
      "learning_rate": 8.485714285714285e-06,
      "loss": 0.0008,
      "step": 58120
    },
    {
      "epoch": 1.6608571428571428,
      "grad_norm": 0.27037253975868225,
      "learning_rate": 8.478571428571428e-06,
      "loss": 0.0015,
      "step": 58130
    },
    {
      "epoch": 1.661142857142857,
      "grad_norm": 0.1625644415616989,
      "learning_rate": 8.471428571428572e-06,
      "loss": 0.0011,
      "step": 58140
    },
    {
      "epoch": 1.6614285714285715,
      "grad_norm": 0.17686787247657776,
      "learning_rate": 8.464285714285715e-06,
      "loss": 0.0009,
      "step": 58150
    },
    {
      "epoch": 1.6617142857142857,
      "grad_norm": 0.09377464652061462,
      "learning_rate": 8.457142857142859e-06,
      "loss": 0.0014,
      "step": 58160
    },
    {
      "epoch": 1.662,
      "grad_norm": 0.04959817975759506,
      "learning_rate": 8.45e-06,
      "loss": 0.0012,
      "step": 58170
    },
    {
      "epoch": 1.6622857142857144,
      "grad_norm": 0.0,
      "learning_rate": 8.442857142857142e-06,
      "loss": 0.0005,
      "step": 58180
    },
    {
      "epoch": 1.6625714285714286,
      "grad_norm": 0.10044726729393005,
      "learning_rate": 8.435714285714286e-06,
      "loss": 0.002,
      "step": 58190
    },
    {
      "epoch": 1.6628571428571428,
      "grad_norm": 0.1759163737297058,
      "learning_rate": 8.428571428571429e-06,
      "loss": 0.0005,
      "step": 58200
    },
    {
      "epoch": 1.6631428571428573,
      "grad_norm": 0.0,
      "learning_rate": 8.421428571428572e-06,
      "loss": 0.0007,
      "step": 58210
    },
    {
      "epoch": 1.6634285714285715,
      "grad_norm": 0.03597971424460411,
      "learning_rate": 8.414285714285714e-06,
      "loss": 0.0011,
      "step": 58220
    },
    {
      "epoch": 1.6637142857142857,
      "grad_norm": 0.12494046986103058,
      "learning_rate": 8.407142857142857e-06,
      "loss": 0.0021,
      "step": 58230
    },
    {
      "epoch": 1.6640000000000001,
      "grad_norm": 0.13900606334209442,
      "learning_rate": 8.400000000000001e-06,
      "loss": 0.0011,
      "step": 58240
    },
    {
      "epoch": 1.6642857142857141,
      "grad_norm": 0.1324417144060135,
      "learning_rate": 8.392857142857143e-06,
      "loss": 0.0016,
      "step": 58250
    },
    {
      "epoch": 1.6645714285714286,
      "grad_norm": 0.23067229986190796,
      "learning_rate": 8.385714285714286e-06,
      "loss": 0.0014,
      "step": 58260
    },
    {
      "epoch": 1.6648571428571428,
      "grad_norm": 0.0,
      "learning_rate": 8.37857142857143e-06,
      "loss": 0.0004,
      "step": 58270
    },
    {
      "epoch": 1.665142857142857,
      "grad_norm": 0.04965309426188469,
      "learning_rate": 8.371428571428571e-06,
      "loss": 0.0008,
      "step": 58280
    },
    {
      "epoch": 1.6654285714285715,
      "grad_norm": 0.044280849397182465,
      "learning_rate": 8.364285714285715e-06,
      "loss": 0.0004,
      "step": 58290
    },
    {
      "epoch": 1.6657142857142857,
      "grad_norm": 0.05673018470406532,
      "learning_rate": 8.357142857142858e-06,
      "loss": 0.0002,
      "step": 58300
    },
    {
      "epoch": 1.666,
      "grad_norm": 0.211532324552536,
      "learning_rate": 8.350000000000001e-06,
      "loss": 0.0007,
      "step": 58310
    },
    {
      "epoch": 1.6662857142857144,
      "grad_norm": 0.0,
      "learning_rate": 8.342857142857143e-06,
      "loss": 0.0008,
      "step": 58320
    },
    {
      "epoch": 1.6665714285714286,
      "grad_norm": 0.05783594772219658,
      "learning_rate": 8.335714285714285e-06,
      "loss": 0.002,
      "step": 58330
    },
    {
      "epoch": 1.6668571428571428,
      "grad_norm": 0.0,
      "learning_rate": 8.328571428571428e-06,
      "loss": 0.0011,
      "step": 58340
    },
    {
      "epoch": 1.6671428571428573,
      "grad_norm": 0.04414084181189537,
      "learning_rate": 8.321428571428572e-06,
      "loss": 0.0016,
      "step": 58350
    },
    {
      "epoch": 1.6674285714285715,
      "grad_norm": 0.291058212518692,
      "learning_rate": 8.314285714285715e-06,
      "loss": 0.0017,
      "step": 58360
    },
    {
      "epoch": 1.6677142857142857,
      "grad_norm": 0.0,
      "learning_rate": 8.307142857142858e-06,
      "loss": 0.0022,
      "step": 58370
    },
    {
      "epoch": 1.6680000000000001,
      "grad_norm": 0.07175958156585693,
      "learning_rate": 8.3e-06,
      "loss": 0.0013,
      "step": 58380
    },
    {
      "epoch": 1.6682857142857141,
      "grad_norm": 0.05094752460718155,
      "learning_rate": 8.292857142857144e-06,
      "loss": 0.0011,
      "step": 58390
    },
    {
      "epoch": 1.6685714285714286,
      "grad_norm": 0.0828196108341217,
      "learning_rate": 8.285714285714285e-06,
      "loss": 0.0014,
      "step": 58400
    },
    {
      "epoch": 1.6688571428571428,
      "grad_norm": 0.0,
      "learning_rate": 8.278571428571429e-06,
      "loss": 0.0013,
      "step": 58410
    },
    {
      "epoch": 1.669142857142857,
      "grad_norm": 0.04755869135260582,
      "learning_rate": 8.271428571428572e-06,
      "loss": 0.0009,
      "step": 58420
    },
    {
      "epoch": 1.6694285714285715,
      "grad_norm": 0.0,
      "learning_rate": 8.264285714285716e-06,
      "loss": 0.0011,
      "step": 58430
    },
    {
      "epoch": 1.6697142857142857,
      "grad_norm": 0.41950729489326477,
      "learning_rate": 8.257142857142857e-06,
      "loss": 0.001,
      "step": 58440
    },
    {
      "epoch": 1.67,
      "grad_norm": 0.08300837129354477,
      "learning_rate": 8.25e-06,
      "loss": 0.0013,
      "step": 58450
    },
    {
      "epoch": 1.6702857142857144,
      "grad_norm": 0.07106800377368927,
      "learning_rate": 8.242857142857144e-06,
      "loss": 0.001,
      "step": 58460
    },
    {
      "epoch": 1.6705714285714286,
      "grad_norm": 0.10202375799417496,
      "learning_rate": 8.235714285714286e-06,
      "loss": 0.0008,
      "step": 58470
    },
    {
      "epoch": 1.6708571428571428,
      "grad_norm": 0.04399404674768448,
      "learning_rate": 8.22857142857143e-06,
      "loss": 0.0005,
      "step": 58480
    },
    {
      "epoch": 1.6711428571428573,
      "grad_norm": 0.0,
      "learning_rate": 8.221428571428571e-06,
      "loss": 0.0007,
      "step": 58490
    },
    {
      "epoch": 1.6714285714285713,
      "grad_norm": 0.045517079532146454,
      "learning_rate": 8.214285714285714e-06,
      "loss": 0.0013,
      "step": 58500
    },
    {
      "epoch": 1.6717142857142857,
      "grad_norm": 0.426803320646286,
      "learning_rate": 8.207142857142858e-06,
      "loss": 0.0007,
      "step": 58510
    },
    {
      "epoch": 1.6720000000000002,
      "grad_norm": 0.04316972568631172,
      "learning_rate": 8.200000000000001e-06,
      "loss": 0.0012,
      "step": 58520
    },
    {
      "epoch": 1.6722857142857142,
      "grad_norm": 0.07843604683876038,
      "learning_rate": 8.192857142857145e-06,
      "loss": 0.0018,
      "step": 58530
    },
    {
      "epoch": 1.6725714285714286,
      "grad_norm": 0.0,
      "learning_rate": 8.185714285714286e-06,
      "loss": 0.0012,
      "step": 58540
    },
    {
      "epoch": 1.6728571428571428,
      "grad_norm": 0.04512876272201538,
      "learning_rate": 8.178571428571428e-06,
      "loss": 0.0009,
      "step": 58550
    },
    {
      "epoch": 1.673142857142857,
      "grad_norm": 0.08242137730121613,
      "learning_rate": 8.171428571428571e-06,
      "loss": 0.0005,
      "step": 58560
    },
    {
      "epoch": 1.6734285714285715,
      "grad_norm": 0.11208730190992355,
      "learning_rate": 8.164285714285715e-06,
      "loss": 0.0009,
      "step": 58570
    },
    {
      "epoch": 1.6737142857142857,
      "grad_norm": 0.12635862827301025,
      "learning_rate": 8.157142857142858e-06,
      "loss": 0.0011,
      "step": 58580
    },
    {
      "epoch": 1.674,
      "grad_norm": 0.2807082533836365,
      "learning_rate": 8.15e-06,
      "loss": 0.0007,
      "step": 58590
    },
    {
      "epoch": 1.6742857142857144,
      "grad_norm": 0.20120543241500854,
      "learning_rate": 8.142857142857143e-06,
      "loss": 0.0015,
      "step": 58600
    },
    {
      "epoch": 1.6745714285714286,
      "grad_norm": 0.07311087846755981,
      "learning_rate": 8.135714285714287e-06,
      "loss": 0.0012,
      "step": 58610
    },
    {
      "epoch": 1.6748571428571428,
      "grad_norm": 0.11285919696092606,
      "learning_rate": 8.128571428571428e-06,
      "loss": 0.0008,
      "step": 58620
    },
    {
      "epoch": 1.6751428571428573,
      "grad_norm": 0.24725161492824554,
      "learning_rate": 8.121428571428572e-06,
      "loss": 0.0012,
      "step": 58630
    },
    {
      "epoch": 1.6754285714285713,
      "grad_norm": 0.06741577386856079,
      "learning_rate": 8.114285714285715e-06,
      "loss": 0.001,
      "step": 58640
    },
    {
      "epoch": 1.6757142857142857,
      "grad_norm": 0.29754698276519775,
      "learning_rate": 8.107142857142857e-06,
      "loss": 0.0002,
      "step": 58650
    },
    {
      "epoch": 1.6760000000000002,
      "grad_norm": 0.06949155032634735,
      "learning_rate": 8.1e-06,
      "loss": 0.0011,
      "step": 58660
    },
    {
      "epoch": 1.6762857142857142,
      "grad_norm": 0.0,
      "learning_rate": 8.092857142857144e-06,
      "loss": 0.0005,
      "step": 58670
    },
    {
      "epoch": 1.6765714285714286,
      "grad_norm": 0.0,
      "learning_rate": 8.085714285714287e-06,
      "loss": 0.0026,
      "step": 58680
    },
    {
      "epoch": 1.6768571428571428,
      "grad_norm": 0.041604045778512955,
      "learning_rate": 8.078571428571429e-06,
      "loss": 0.0005,
      "step": 58690
    },
    {
      "epoch": 1.677142857142857,
      "grad_norm": 0.0,
      "learning_rate": 8.07142857142857e-06,
      "loss": 0.0011,
      "step": 58700
    },
    {
      "epoch": 1.6774285714285715,
      "grad_norm": 0.043279506266117096,
      "learning_rate": 8.064285714285714e-06,
      "loss": 0.0012,
      "step": 58710
    },
    {
      "epoch": 1.6777142857142857,
      "grad_norm": 0.09157544374465942,
      "learning_rate": 8.057142857142857e-06,
      "loss": 0.0007,
      "step": 58720
    },
    {
      "epoch": 1.678,
      "grad_norm": 0.04841119050979614,
      "learning_rate": 8.050000000000001e-06,
      "loss": 0.0018,
      "step": 58730
    },
    {
      "epoch": 1.6782857142857144,
      "grad_norm": 0.08290649950504303,
      "learning_rate": 8.042857142857144e-06,
      "loss": 0.0019,
      "step": 58740
    },
    {
      "epoch": 1.6785714285714286,
      "grad_norm": 0.0,
      "learning_rate": 8.035714285714286e-06,
      "loss": 0.0012,
      "step": 58750
    },
    {
      "epoch": 1.6788571428571428,
      "grad_norm": 0.08028056472539902,
      "learning_rate": 8.028571428571428e-06,
      "loss": 0.0012,
      "step": 58760
    },
    {
      "epoch": 1.6791428571428573,
      "grad_norm": 0.09638465195894241,
      "learning_rate": 8.021428571428571e-06,
      "loss": 0.0005,
      "step": 58770
    },
    {
      "epoch": 1.6794285714285713,
      "grad_norm": 0.07093221694231033,
      "learning_rate": 8.014285714285715e-06,
      "loss": 0.0006,
      "step": 58780
    },
    {
      "epoch": 1.6797142857142857,
      "grad_norm": 0.077043317258358,
      "learning_rate": 8.007142857142858e-06,
      "loss": 0.0017,
      "step": 58790
    },
    {
      "epoch": 1.6800000000000002,
      "grad_norm": 0.05949254333972931,
      "learning_rate": 8.000000000000001e-06,
      "loss": 0.0011,
      "step": 58800
    },
    {
      "epoch": 1.6802857142857142,
      "grad_norm": 0.0,
      "learning_rate": 7.992857142857143e-06,
      "loss": 0.0005,
      "step": 58810
    },
    {
      "epoch": 1.6805714285714286,
      "grad_norm": 0.04679109901189804,
      "learning_rate": 7.985714285714286e-06,
      "loss": 0.0008,
      "step": 58820
    },
    {
      "epoch": 1.6808571428571428,
      "grad_norm": 0.11569542437791824,
      "learning_rate": 7.978571428571428e-06,
      "loss": 0.0017,
      "step": 58830
    },
    {
      "epoch": 1.681142857142857,
      "grad_norm": 0.2223958671092987,
      "learning_rate": 7.971428571428572e-06,
      "loss": 0.0014,
      "step": 58840
    },
    {
      "epoch": 1.6814285714285715,
      "grad_norm": 0.04754965007305145,
      "learning_rate": 7.964285714285715e-06,
      "loss": 0.0005,
      "step": 58850
    },
    {
      "epoch": 1.6817142857142857,
      "grad_norm": 0.09373985975980759,
      "learning_rate": 7.957142857142857e-06,
      "loss": 0.0016,
      "step": 58860
    },
    {
      "epoch": 1.682,
      "grad_norm": 0.0,
      "learning_rate": 7.95e-06,
      "loss": 0.0009,
      "step": 58870
    },
    {
      "epoch": 1.6822857142857144,
      "grad_norm": 0.11709580570459366,
      "learning_rate": 7.942857142857144e-06,
      "loss": 0.0014,
      "step": 58880
    },
    {
      "epoch": 1.6825714285714286,
      "grad_norm": 0.05120357125997543,
      "learning_rate": 7.935714285714287e-06,
      "loss": 0.0014,
      "step": 58890
    },
    {
      "epoch": 1.6828571428571428,
      "grad_norm": 0.0,
      "learning_rate": 7.928571428571429e-06,
      "loss": 0.0007,
      "step": 58900
    },
    {
      "epoch": 1.6831428571428573,
      "grad_norm": 0.0,
      "learning_rate": 7.921428571428572e-06,
      "loss": 0.0005,
      "step": 58910
    },
    {
      "epoch": 1.6834285714285713,
      "grad_norm": 0.04171207174658775,
      "learning_rate": 7.914285714285714e-06,
      "loss": 0.001,
      "step": 58920
    },
    {
      "epoch": 1.6837142857142857,
      "grad_norm": 0.0891372412443161,
      "learning_rate": 7.907142857142857e-06,
      "loss": 0.0006,
      "step": 58930
    },
    {
      "epoch": 1.6840000000000002,
      "grad_norm": 0.05001603066921234,
      "learning_rate": 7.9e-06,
      "loss": 0.0016,
      "step": 58940
    },
    {
      "epoch": 1.6842857142857142,
      "grad_norm": 0.04166736826300621,
      "learning_rate": 7.892857142857144e-06,
      "loss": 0.0002,
      "step": 58950
    },
    {
      "epoch": 1.6845714285714286,
      "grad_norm": 0.0,
      "learning_rate": 7.885714285714286e-06,
      "loss": 0.0009,
      "step": 58960
    },
    {
      "epoch": 1.6848571428571428,
      "grad_norm": 0.04809654876589775,
      "learning_rate": 7.878571428571429e-06,
      "loss": 0.002,
      "step": 58970
    },
    {
      "epoch": 1.685142857142857,
      "grad_norm": 0.19370724260807037,
      "learning_rate": 7.87142857142857e-06,
      "loss": 0.0019,
      "step": 58980
    },
    {
      "epoch": 1.6854285714285715,
      "grad_norm": 0.11611951887607574,
      "learning_rate": 7.864285714285714e-06,
      "loss": 0.0007,
      "step": 58990
    },
    {
      "epoch": 1.6857142857142857,
      "grad_norm": 0.056762367486953735,
      "learning_rate": 7.857142857142858e-06,
      "loss": 0.0011,
      "step": 59000
    },
    {
      "epoch": 1.686,
      "grad_norm": 0.04544908553361893,
      "learning_rate": 7.850000000000001e-06,
      "loss": 0.0007,
      "step": 59010
    },
    {
      "epoch": 1.6862857142857144,
      "grad_norm": 0.06169649958610535,
      "learning_rate": 7.842857142857143e-06,
      "loss": 0.001,
      "step": 59020
    },
    {
      "epoch": 1.6865714285714286,
      "grad_norm": 0.06032581254839897,
      "learning_rate": 7.835714285714286e-06,
      "loss": 0.0011,
      "step": 59030
    },
    {
      "epoch": 1.6868571428571428,
      "grad_norm": 0.05421516299247742,
      "learning_rate": 7.82857142857143e-06,
      "loss": 0.0008,
      "step": 59040
    },
    {
      "epoch": 1.6871428571428573,
      "grad_norm": 0.10849275439977646,
      "learning_rate": 7.821428571428571e-06,
      "loss": 0.0007,
      "step": 59050
    },
    {
      "epoch": 1.6874285714285713,
      "grad_norm": 0.06618664413690567,
      "learning_rate": 7.814285714285715e-06,
      "loss": 0.001,
      "step": 59060
    },
    {
      "epoch": 1.6877142857142857,
      "grad_norm": 0.08236192911863327,
      "learning_rate": 7.807142857142858e-06,
      "loss": 0.0017,
      "step": 59070
    },
    {
      "epoch": 1.688,
      "grad_norm": 0.0,
      "learning_rate": 7.8e-06,
      "loss": 0.0011,
      "step": 59080
    },
    {
      "epoch": 1.6882857142857142,
      "grad_norm": 0.059605009853839874,
      "learning_rate": 7.792857142857143e-06,
      "loss": 0.0009,
      "step": 59090
    },
    {
      "epoch": 1.6885714285714286,
      "grad_norm": 0.08999231457710266,
      "learning_rate": 7.785714285714287e-06,
      "loss": 0.0008,
      "step": 59100
    },
    {
      "epoch": 1.6888571428571428,
      "grad_norm": 0.09770135581493378,
      "learning_rate": 7.77857142857143e-06,
      "loss": 0.0014,
      "step": 59110
    },
    {
      "epoch": 1.689142857142857,
      "grad_norm": 0.030896203592419624,
      "learning_rate": 7.771428571428572e-06,
      "loss": 0.0009,
      "step": 59120
    },
    {
      "epoch": 1.6894285714285715,
      "grad_norm": 0.1366616040468216,
      "learning_rate": 7.764285714285714e-06,
      "loss": 0.0011,
      "step": 59130
    },
    {
      "epoch": 1.6897142857142857,
      "grad_norm": 0.06426849961280823,
      "learning_rate": 7.757142857142857e-06,
      "loss": 0.0004,
      "step": 59140
    },
    {
      "epoch": 1.69,
      "grad_norm": 0.27843180298805237,
      "learning_rate": 7.75e-06,
      "loss": 0.0009,
      "step": 59150
    },
    {
      "epoch": 1.6902857142857144,
      "grad_norm": 0.0,
      "learning_rate": 7.742857142857144e-06,
      "loss": 0.0012,
      "step": 59160
    },
    {
      "epoch": 1.6905714285714286,
      "grad_norm": 0.12718112766742706,
      "learning_rate": 7.735714285714287e-06,
      "loss": 0.0006,
      "step": 59170
    },
    {
      "epoch": 1.6908571428571428,
      "grad_norm": 0.06906875967979431,
      "learning_rate": 7.728571428571429e-06,
      "loss": 0.0009,
      "step": 59180
    },
    {
      "epoch": 1.6911428571428573,
      "grad_norm": 0.16643263399600983,
      "learning_rate": 7.72142857142857e-06,
      "loss": 0.0011,
      "step": 59190
    },
    {
      "epoch": 1.6914285714285713,
      "grad_norm": 0.10454665124416351,
      "learning_rate": 7.714285714285714e-06,
      "loss": 0.0001,
      "step": 59200
    },
    {
      "epoch": 1.6917142857142857,
      "grad_norm": 0.09161200374364853,
      "learning_rate": 7.707142857142857e-06,
      "loss": 0.0008,
      "step": 59210
    },
    {
      "epoch": 1.692,
      "grad_norm": 0.0,
      "learning_rate": 7.7e-06,
      "loss": 0.0002,
      "step": 59220
    },
    {
      "epoch": 1.6922857142857142,
      "grad_norm": 0.04123414680361748,
      "learning_rate": 7.692857142857143e-06,
      "loss": 0.0011,
      "step": 59230
    },
    {
      "epoch": 1.6925714285714286,
      "grad_norm": 0.0413183867931366,
      "learning_rate": 7.685714285714286e-06,
      "loss": 0.0008,
      "step": 59240
    },
    {
      "epoch": 1.6928571428571428,
      "grad_norm": 0.15169569849967957,
      "learning_rate": 7.67857142857143e-06,
      "loss": 0.0014,
      "step": 59250
    },
    {
      "epoch": 1.693142857142857,
      "grad_norm": 0.0865858718752861,
      "learning_rate": 7.671428571428573e-06,
      "loss": 0.0015,
      "step": 59260
    },
    {
      "epoch": 1.6934285714285715,
      "grad_norm": 0.042019013315439224,
      "learning_rate": 7.664285714285714e-06,
      "loss": 0.001,
      "step": 59270
    },
    {
      "epoch": 1.6937142857142857,
      "grad_norm": 0.0,
      "learning_rate": 7.657142857142858e-06,
      "loss": 0.0012,
      "step": 59280
    },
    {
      "epoch": 1.694,
      "grad_norm": 0.13585713505744934,
      "learning_rate": 7.65e-06,
      "loss": 0.0007,
      "step": 59290
    },
    {
      "epoch": 1.6942857142857144,
      "grad_norm": 0.04592173546552658,
      "learning_rate": 7.642857142857143e-06,
      "loss": 0.0005,
      "step": 59300
    },
    {
      "epoch": 1.6945714285714286,
      "grad_norm": 0.08465873450040817,
      "learning_rate": 7.635714285714286e-06,
      "loss": 0.0024,
      "step": 59310
    },
    {
      "epoch": 1.6948571428571428,
      "grad_norm": 0.0,
      "learning_rate": 7.628571428571429e-06,
      "loss": 0.0011,
      "step": 59320
    },
    {
      "epoch": 1.6951428571428573,
      "grad_norm": 0.0,
      "learning_rate": 7.621428571428572e-06,
      "loss": 0.0013,
      "step": 59330
    },
    {
      "epoch": 1.6954285714285713,
      "grad_norm": 0.30845341086387634,
      "learning_rate": 7.614285714285714e-06,
      "loss": 0.0015,
      "step": 59340
    },
    {
      "epoch": 1.6957142857142857,
      "grad_norm": 0.0,
      "learning_rate": 7.6071428571428575e-06,
      "loss": 0.0008,
      "step": 59350
    },
    {
      "epoch": 1.696,
      "grad_norm": 0.0,
      "learning_rate": 7.6e-06,
      "loss": 0.0003,
      "step": 59360
    },
    {
      "epoch": 1.6962857142857142,
      "grad_norm": 0.0,
      "learning_rate": 7.5928571428571435e-06,
      "loss": 0.0019,
      "step": 59370
    },
    {
      "epoch": 1.6965714285714286,
      "grad_norm": 0.32903677225112915,
      "learning_rate": 7.585714285714286e-06,
      "loss": 0.0015,
      "step": 59380
    },
    {
      "epoch": 1.6968571428571428,
      "grad_norm": 0.04189629852771759,
      "learning_rate": 7.5785714285714295e-06,
      "loss": 0.0015,
      "step": 59390
    },
    {
      "epoch": 1.697142857142857,
      "grad_norm": 0.0,
      "learning_rate": 7.571428571428572e-06,
      "loss": 0.0014,
      "step": 59400
    },
    {
      "epoch": 1.6974285714285715,
      "grad_norm": 0.0,
      "learning_rate": 7.564285714285714e-06,
      "loss": 0.001,
      "step": 59410
    },
    {
      "epoch": 1.6977142857142857,
      "grad_norm": 0.08951134234666824,
      "learning_rate": 7.557142857142857e-06,
      "loss": 0.0007,
      "step": 59420
    },
    {
      "epoch": 1.698,
      "grad_norm": 0.08667675405740738,
      "learning_rate": 7.55e-06,
      "loss": 0.001,
      "step": 59430
    },
    {
      "epoch": 1.6982857142857144,
      "grad_norm": 0.0,
      "learning_rate": 7.542857142857143e-06,
      "loss": 0.0012,
      "step": 59440
    },
    {
      "epoch": 1.6985714285714286,
      "grad_norm": 0.0,
      "learning_rate": 7.5357142857142865e-06,
      "loss": 0.0007,
      "step": 59450
    },
    {
      "epoch": 1.6988571428571428,
      "grad_norm": 0.26738959550857544,
      "learning_rate": 7.528571428571429e-06,
      "loss": 0.0004,
      "step": 59460
    },
    {
      "epoch": 1.6991428571428573,
      "grad_norm": 0.029394933953881264,
      "learning_rate": 7.5214285714285725e-06,
      "loss": 0.002,
      "step": 59470
    },
    {
      "epoch": 1.6994285714285713,
      "grad_norm": 0.04619374871253967,
      "learning_rate": 7.514285714285714e-06,
      "loss": 0.001,
      "step": 59480
    },
    {
      "epoch": 1.6997142857142857,
      "grad_norm": 0.0525614470243454,
      "learning_rate": 7.507142857142857e-06,
      "loss": 0.001,
      "step": 59490
    },
    {
      "epoch": 1.7,
      "grad_norm": 0.04917527735233307,
      "learning_rate": 7.5e-06,
      "loss": 0.0004,
      "step": 59500
    },
    {
      "epoch": 1.7002857142857142,
      "grad_norm": 0.04657033085823059,
      "learning_rate": 7.492857142857143e-06,
      "loss": 0.0014,
      "step": 59510
    },
    {
      "epoch": 1.7005714285714286,
      "grad_norm": 0.24350981414318085,
      "learning_rate": 7.485714285714286e-06,
      "loss": 0.0007,
      "step": 59520
    },
    {
      "epoch": 1.7008571428571428,
      "grad_norm": 0.0,
      "learning_rate": 7.4785714285714296e-06,
      "loss": 0.0012,
      "step": 59530
    },
    {
      "epoch": 1.701142857142857,
      "grad_norm": 0.0,
      "learning_rate": 7.471428571428572e-06,
      "loss": 0.0016,
      "step": 59540
    },
    {
      "epoch": 1.7014285714285715,
      "grad_norm": 0.11238235235214233,
      "learning_rate": 7.4642857142857155e-06,
      "loss": 0.0022,
      "step": 59550
    },
    {
      "epoch": 1.7017142857142857,
      "grad_norm": 0.046501047909259796,
      "learning_rate": 7.457142857142857e-06,
      "loss": 0.001,
      "step": 59560
    },
    {
      "epoch": 1.702,
      "grad_norm": 0.18786628544330597,
      "learning_rate": 7.45e-06,
      "loss": 0.001,
      "step": 59570
    },
    {
      "epoch": 1.7022857142857144,
      "grad_norm": 0.0,
      "learning_rate": 7.442857142857143e-06,
      "loss": 0.0015,
      "step": 59580
    },
    {
      "epoch": 1.7025714285714286,
      "grad_norm": 0.13424864411354065,
      "learning_rate": 7.435714285714286e-06,
      "loss": 0.0011,
      "step": 59590
    },
    {
      "epoch": 1.7028571428571428,
      "grad_norm": 0.28885549306869507,
      "learning_rate": 7.428571428571429e-06,
      "loss": 0.0012,
      "step": 59600
    },
    {
      "epoch": 1.7031428571428573,
      "grad_norm": 0.05615738034248352,
      "learning_rate": 7.421428571428573e-06,
      "loss": 0.0011,
      "step": 59610
    },
    {
      "epoch": 1.7034285714285713,
      "grad_norm": 0.0,
      "learning_rate": 7.414285714285715e-06,
      "loss": 0.0017,
      "step": 59620
    },
    {
      "epoch": 1.7037142857142857,
      "grad_norm": 0.0,
      "learning_rate": 7.407142857142857e-06,
      "loss": 0.0006,
      "step": 59630
    },
    {
      "epoch": 1.704,
      "grad_norm": 0.04871249943971634,
      "learning_rate": 7.4e-06,
      "loss": 0.0009,
      "step": 59640
    },
    {
      "epoch": 1.7042857142857142,
      "grad_norm": 0.04368724673986435,
      "learning_rate": 7.392857142857143e-06,
      "loss": 0.0005,
      "step": 59650
    },
    {
      "epoch": 1.7045714285714286,
      "grad_norm": 0.035908617079257965,
      "learning_rate": 7.385714285714286e-06,
      "loss": 0.0008,
      "step": 59660
    },
    {
      "epoch": 1.7048571428571428,
      "grad_norm": 0.055807676166296005,
      "learning_rate": 7.378571428571429e-06,
      "loss": 0.0014,
      "step": 59670
    },
    {
      "epoch": 1.705142857142857,
      "grad_norm": 0.23467551171779633,
      "learning_rate": 7.371428571428572e-06,
      "loss": 0.0014,
      "step": 59680
    },
    {
      "epoch": 1.7054285714285715,
      "grad_norm": 0.07537399977445602,
      "learning_rate": 7.364285714285716e-06,
      "loss": 0.0009,
      "step": 59690
    },
    {
      "epoch": 1.7057142857142857,
      "grad_norm": 0.04075461998581886,
      "learning_rate": 7.3571428571428565e-06,
      "loss": 0.0021,
      "step": 59700
    },
    {
      "epoch": 1.706,
      "grad_norm": 0.0,
      "learning_rate": 7.35e-06,
      "loss": 0.0003,
      "step": 59710
    },
    {
      "epoch": 1.7062857142857144,
      "grad_norm": 0.08825326710939407,
      "learning_rate": 7.342857142857143e-06,
      "loss": 0.0005,
      "step": 59720
    },
    {
      "epoch": 1.7065714285714284,
      "grad_norm": 0.0464508980512619,
      "learning_rate": 7.335714285714286e-06,
      "loss": 0.0015,
      "step": 59730
    },
    {
      "epoch": 1.7068571428571429,
      "grad_norm": 0.05623948201537132,
      "learning_rate": 7.328571428571429e-06,
      "loss": 0.0006,
      "step": 59740
    },
    {
      "epoch": 1.7071428571428573,
      "grad_norm": 0.04494405910372734,
      "learning_rate": 7.321428571428572e-06,
      "loss": 0.0006,
      "step": 59750
    },
    {
      "epoch": 1.7074285714285713,
      "grad_norm": 0.29320868849754333,
      "learning_rate": 7.314285714285715e-06,
      "loss": 0.0004,
      "step": 59760
    },
    {
      "epoch": 1.7077142857142857,
      "grad_norm": 0.04355061054229736,
      "learning_rate": 7.307142857142857e-06,
      "loss": 0.0013,
      "step": 59770
    },
    {
      "epoch": 1.708,
      "grad_norm": 0.04762817919254303,
      "learning_rate": 7.2999999999999996e-06,
      "loss": 0.0013,
      "step": 59780
    },
    {
      "epoch": 1.7082857142857142,
      "grad_norm": 0.0,
      "learning_rate": 7.292857142857143e-06,
      "loss": 0.0006,
      "step": 59790
    },
    {
      "epoch": 1.7085714285714286,
      "grad_norm": 0.049773264676332474,
      "learning_rate": 7.285714285714286e-06,
      "loss": 0.0011,
      "step": 59800
    },
    {
      "epoch": 1.7088571428571429,
      "grad_norm": 0.0432514064013958,
      "learning_rate": 7.278571428571429e-06,
      "loss": 0.0017,
      "step": 59810
    },
    {
      "epoch": 1.709142857142857,
      "grad_norm": 0.1850869208574295,
      "learning_rate": 7.271428571428572e-06,
      "loss": 0.0004,
      "step": 59820
    },
    {
      "epoch": 1.7094285714285715,
      "grad_norm": 0.048196155577898026,
      "learning_rate": 7.264285714285715e-06,
      "loss": 0.0006,
      "step": 59830
    },
    {
      "epoch": 1.7097142857142857,
      "grad_norm": 0.0,
      "learning_rate": 7.257142857142857e-06,
      "loss": 0.0019,
      "step": 59840
    },
    {
      "epoch": 1.71,
      "grad_norm": 0.0,
      "learning_rate": 7.25e-06,
      "loss": 0.0006,
      "step": 59850
    },
    {
      "epoch": 1.7102857142857144,
      "grad_norm": 0.04128187149763107,
      "learning_rate": 7.242857142857143e-06,
      "loss": 0.0013,
      "step": 59860
    },
    {
      "epoch": 1.7105714285714284,
      "grad_norm": 0.0,
      "learning_rate": 7.235714285714286e-06,
      "loss": 0.0013,
      "step": 59870
    },
    {
      "epoch": 1.7108571428571429,
      "grad_norm": 0.15830738842487335,
      "learning_rate": 7.228571428571429e-06,
      "loss": 0.002,
      "step": 59880
    },
    {
      "epoch": 1.7111428571428573,
      "grad_norm": 0.0635610818862915,
      "learning_rate": 7.221428571428572e-06,
      "loss": 0.0011,
      "step": 59890
    },
    {
      "epoch": 1.7114285714285713,
      "grad_norm": 0.0,
      "learning_rate": 7.214285714285715e-06,
      "loss": 0.0011,
      "step": 59900
    },
    {
      "epoch": 1.7117142857142857,
      "grad_norm": 0.04658302292227745,
      "learning_rate": 7.207142857142858e-06,
      "loss": 0.0014,
      "step": 59910
    },
    {
      "epoch": 1.712,
      "grad_norm": 0.04296182096004486,
      "learning_rate": 7.2e-06,
      "loss": 0.0006,
      "step": 59920
    },
    {
      "epoch": 1.7122857142857142,
      "grad_norm": 0.08820545673370361,
      "learning_rate": 7.192857142857143e-06,
      "loss": 0.0013,
      "step": 59930
    },
    {
      "epoch": 1.7125714285714286,
      "grad_norm": 0.16539685428142548,
      "learning_rate": 7.185714285714286e-06,
      "loss": 0.0011,
      "step": 59940
    },
    {
      "epoch": 1.7128571428571429,
      "grad_norm": 0.0,
      "learning_rate": 7.178571428571429e-06,
      "loss": 0.001,
      "step": 59950
    },
    {
      "epoch": 1.713142857142857,
      "grad_norm": 0.04572386294603348,
      "learning_rate": 7.171428571428572e-06,
      "loss": 0.0014,
      "step": 59960
    },
    {
      "epoch": 1.7134285714285715,
      "grad_norm": 0.07956380397081375,
      "learning_rate": 7.164285714285715e-06,
      "loss": 0.0013,
      "step": 59970
    },
    {
      "epoch": 1.7137142857142857,
      "grad_norm": 0.046904612332582474,
      "learning_rate": 7.1571428571428584e-06,
      "loss": 0.0007,
      "step": 59980
    },
    {
      "epoch": 1.714,
      "grad_norm": 0.31946316361427307,
      "learning_rate": 7.15e-06,
      "loss": 0.0017,
      "step": 59990
    },
    {
      "epoch": 1.7142857142857144,
      "grad_norm": 0.15442654490470886,
      "learning_rate": 7.142857142857143e-06,
      "loss": 0.0013,
      "step": 60000
    },
    {
      "epoch": 1.7145714285714284,
      "grad_norm": 0.0,
      "learning_rate": 7.135714285714286e-06,
      "loss": 0.001,
      "step": 60010
    },
    {
      "epoch": 1.7148571428571429,
      "grad_norm": 0.1324732005596161,
      "learning_rate": 7.128571428571429e-06,
      "loss": 0.0007,
      "step": 60020
    },
    {
      "epoch": 1.7151428571428573,
      "grad_norm": 0.0,
      "learning_rate": 7.121428571428572e-06,
      "loss": 0.0009,
      "step": 60030
    },
    {
      "epoch": 1.7154285714285713,
      "grad_norm": 0.08643484115600586,
      "learning_rate": 7.114285714285715e-06,
      "loss": 0.0004,
      "step": 60040
    },
    {
      "epoch": 1.7157142857142857,
      "grad_norm": 0.08908829838037491,
      "learning_rate": 7.107142857142858e-06,
      "loss": 0.0012,
      "step": 60050
    },
    {
      "epoch": 1.716,
      "grad_norm": 0.25323009490966797,
      "learning_rate": 7.1e-06,
      "loss": 0.0014,
      "step": 60060
    },
    {
      "epoch": 1.7162857142857142,
      "grad_norm": 0.08619213849306107,
      "learning_rate": 7.092857142857142e-06,
      "loss": 0.0008,
      "step": 60070
    },
    {
      "epoch": 1.7165714285714286,
      "grad_norm": 0.060726482421159744,
      "learning_rate": 7.085714285714286e-06,
      "loss": 0.001,
      "step": 60080
    },
    {
      "epoch": 1.7168571428571429,
      "grad_norm": 0.04073984548449516,
      "learning_rate": 7.078571428571429e-06,
      "loss": 0.0008,
      "step": 60090
    },
    {
      "epoch": 1.717142857142857,
      "grad_norm": 0.06127993389964104,
      "learning_rate": 7.071428571428572e-06,
      "loss": 0.0021,
      "step": 60100
    },
    {
      "epoch": 1.7174285714285715,
      "grad_norm": 0.0446121022105217,
      "learning_rate": 7.064285714285715e-06,
      "loss": 0.001,
      "step": 60110
    },
    {
      "epoch": 1.7177142857142857,
      "grad_norm": 0.0,
      "learning_rate": 7.057142857142858e-06,
      "loss": 0.0009,
      "step": 60120
    },
    {
      "epoch": 1.718,
      "grad_norm": 0.0454423688352108,
      "learning_rate": 7.049999999999999e-06,
      "loss": 0.0011,
      "step": 60130
    },
    {
      "epoch": 1.7182857142857144,
      "grad_norm": 0.136750727891922,
      "learning_rate": 7.042857142857143e-06,
      "loss": 0.0011,
      "step": 60140
    },
    {
      "epoch": 1.7185714285714284,
      "grad_norm": 0.12584398686885834,
      "learning_rate": 7.035714285714285e-06,
      "loss": 0.0009,
      "step": 60150
    },
    {
      "epoch": 1.7188571428571429,
      "grad_norm": 0.12616626918315887,
      "learning_rate": 7.028571428571429e-06,
      "loss": 0.0012,
      "step": 60160
    },
    {
      "epoch": 1.7191428571428573,
      "grad_norm": 0.043615441769361496,
      "learning_rate": 7.021428571428572e-06,
      "loss": 0.0006,
      "step": 60170
    },
    {
      "epoch": 1.7194285714285713,
      "grad_norm": 0.0,
      "learning_rate": 7.014285714285715e-06,
      "loss": 0.001,
      "step": 60180
    },
    {
      "epoch": 1.7197142857142858,
      "grad_norm": 0.09885509312152863,
      "learning_rate": 7.007142857142858e-06,
      "loss": 0.0004,
      "step": 60190
    },
    {
      "epoch": 1.72,
      "grad_norm": 0.0,
      "learning_rate": 7.000000000000001e-06,
      "loss": 0.0004,
      "step": 60200
    },
    {
      "epoch": 1.7202857142857142,
      "grad_norm": 0.04450303316116333,
      "learning_rate": 6.9928571428571425e-06,
      "loss": 0.0015,
      "step": 60210
    },
    {
      "epoch": 1.7205714285714286,
      "grad_norm": 0.0,
      "learning_rate": 6.985714285714286e-06,
      "loss": 0.0029,
      "step": 60220
    },
    {
      "epoch": 1.7208571428571429,
      "grad_norm": 0.14218218624591827,
      "learning_rate": 6.9785714285714284e-06,
      "loss": 0.0008,
      "step": 60230
    },
    {
      "epoch": 1.721142857142857,
      "grad_norm": 0.06028803810477257,
      "learning_rate": 6.971428571428572e-06,
      "loss": 0.0011,
      "step": 60240
    },
    {
      "epoch": 1.7214285714285715,
      "grad_norm": 0.05135823413729668,
      "learning_rate": 6.964285714285715e-06,
      "loss": 0.0008,
      "step": 60250
    },
    {
      "epoch": 1.7217142857142858,
      "grad_norm": 0.0,
      "learning_rate": 6.957142857142858e-06,
      "loss": 0.0015,
      "step": 60260
    },
    {
      "epoch": 1.722,
      "grad_norm": 0.0881410464644432,
      "learning_rate": 6.950000000000001e-06,
      "loss": 0.0014,
      "step": 60270
    },
    {
      "epoch": 1.7222857142857144,
      "grad_norm": 0.0900396853685379,
      "learning_rate": 6.942857142857143e-06,
      "loss": 0.0009,
      "step": 60280
    },
    {
      "epoch": 1.7225714285714284,
      "grad_norm": 0.05267065763473511,
      "learning_rate": 6.9357142857142855e-06,
      "loss": 0.0015,
      "step": 60290
    },
    {
      "epoch": 1.7228571428571429,
      "grad_norm": 0.08116254210472107,
      "learning_rate": 6.928571428571429e-06,
      "loss": 0.0016,
      "step": 60300
    },
    {
      "epoch": 1.7231428571428573,
      "grad_norm": 0.07289184629917145,
      "learning_rate": 6.9214285714285715e-06,
      "loss": 0.0012,
      "step": 60310
    },
    {
      "epoch": 1.7234285714285713,
      "grad_norm": 0.05660964176058769,
      "learning_rate": 6.914285714285715e-06,
      "loss": 0.0012,
      "step": 60320
    },
    {
      "epoch": 1.7237142857142858,
      "grad_norm": 0.07809213548898697,
      "learning_rate": 6.9071428571428574e-06,
      "loss": 0.0006,
      "step": 60330
    },
    {
      "epoch": 1.724,
      "grad_norm": 0.0,
      "learning_rate": 6.900000000000001e-06,
      "loss": 0.0007,
      "step": 60340
    },
    {
      "epoch": 1.7242857142857142,
      "grad_norm": 0.0573083758354187,
      "learning_rate": 6.8928571428571426e-06,
      "loss": 0.0006,
      "step": 60350
    },
    {
      "epoch": 1.7245714285714286,
      "grad_norm": 0.0,
      "learning_rate": 6.885714285714286e-06,
      "loss": 0.0017,
      "step": 60360
    },
    {
      "epoch": 1.7248571428571429,
      "grad_norm": 0.03240405395627022,
      "learning_rate": 6.8785714285714285e-06,
      "loss": 0.0008,
      "step": 60370
    },
    {
      "epoch": 1.725142857142857,
      "grad_norm": 0.0,
      "learning_rate": 6.871428571428572e-06,
      "loss": 0.0011,
      "step": 60380
    },
    {
      "epoch": 1.7254285714285715,
      "grad_norm": 0.0,
      "learning_rate": 6.8642857142857145e-06,
      "loss": 0.0022,
      "step": 60390
    },
    {
      "epoch": 1.7257142857142858,
      "grad_norm": 0.042667124420404434,
      "learning_rate": 6.857142857142858e-06,
      "loss": 0.0011,
      "step": 60400
    },
    {
      "epoch": 1.726,
      "grad_norm": 0.1211751326918602,
      "learning_rate": 6.8500000000000005e-06,
      "loss": 0.0006,
      "step": 60410
    },
    {
      "epoch": 1.7262857142857144,
      "grad_norm": 0.053016532212495804,
      "learning_rate": 6.842857142857142e-06,
      "loss": 0.0013,
      "step": 60420
    },
    {
      "epoch": 1.7265714285714284,
      "grad_norm": 0.09033868461847305,
      "learning_rate": 6.835714285714286e-06,
      "loss": 0.0016,
      "step": 60430
    },
    {
      "epoch": 1.7268571428571429,
      "grad_norm": 0.04401750862598419,
      "learning_rate": 6.828571428571429e-06,
      "loss": 0.0013,
      "step": 60440
    },
    {
      "epoch": 1.727142857142857,
      "grad_norm": 0.04911264404654503,
      "learning_rate": 6.821428571428572e-06,
      "loss": 0.0021,
      "step": 60450
    },
    {
      "epoch": 1.7274285714285713,
      "grad_norm": 0.054802607744932175,
      "learning_rate": 6.814285714285715e-06,
      "loss": 0.0013,
      "step": 60460
    },
    {
      "epoch": 1.7277142857142858,
      "grad_norm": 0.08917049318552017,
      "learning_rate": 6.8071428571428576e-06,
      "loss": 0.0008,
      "step": 60470
    },
    {
      "epoch": 1.728,
      "grad_norm": 0.04537401348352432,
      "learning_rate": 6.800000000000001e-06,
      "loss": 0.0012,
      "step": 60480
    },
    {
      "epoch": 1.7282857142857142,
      "grad_norm": 0.09406636655330658,
      "learning_rate": 6.7928571428571435e-06,
      "loss": 0.0019,
      "step": 60490
    },
    {
      "epoch": 1.7285714285714286,
      "grad_norm": 0.0,
      "learning_rate": 6.785714285714285e-06,
      "loss": 0.0005,
      "step": 60500
    },
    {
      "epoch": 1.7288571428571429,
      "grad_norm": 0.042565733194351196,
      "learning_rate": 6.778571428571429e-06,
      "loss": 0.0009,
      "step": 60510
    },
    {
      "epoch": 1.729142857142857,
      "grad_norm": 0.04342107102274895,
      "learning_rate": 6.771428571428571e-06,
      "loss": 0.001,
      "step": 60520
    },
    {
      "epoch": 1.7294285714285715,
      "grad_norm": 0.05151030793786049,
      "learning_rate": 6.764285714285715e-06,
      "loss": 0.0011,
      "step": 60530
    },
    {
      "epoch": 1.7297142857142858,
      "grad_norm": 0.10000953823328018,
      "learning_rate": 6.757142857142858e-06,
      "loss": 0.0002,
      "step": 60540
    },
    {
      "epoch": 1.73,
      "grad_norm": 0.09111826866865158,
      "learning_rate": 6.750000000000001e-06,
      "loss": 0.0015,
      "step": 60550
    },
    {
      "epoch": 1.7302857142857144,
      "grad_norm": 0.04779942333698273,
      "learning_rate": 6.742857142857144e-06,
      "loss": 0.001,
      "step": 60560
    },
    {
      "epoch": 1.7305714285714284,
      "grad_norm": 0.04434457793831825,
      "learning_rate": 6.735714285714286e-06,
      "loss": 0.0008,
      "step": 60570
    },
    {
      "epoch": 1.7308571428571429,
      "grad_norm": 0.05511292815208435,
      "learning_rate": 6.728571428571428e-06,
      "loss": 0.0003,
      "step": 60580
    },
    {
      "epoch": 1.731142857142857,
      "grad_norm": 0.041853081434965134,
      "learning_rate": 6.721428571428572e-06,
      "loss": 0.0006,
      "step": 60590
    },
    {
      "epoch": 1.7314285714285713,
      "grad_norm": 0.044289231300354004,
      "learning_rate": 6.714285714285714e-06,
      "loss": 0.0009,
      "step": 60600
    },
    {
      "epoch": 1.7317142857142858,
      "grad_norm": 0.04602806270122528,
      "learning_rate": 6.707142857142858e-06,
      "loss": 0.0005,
      "step": 60610
    },
    {
      "epoch": 1.732,
      "grad_norm": 0.0,
      "learning_rate": 6.700000000000001e-06,
      "loss": 0.0003,
      "step": 60620
    },
    {
      "epoch": 1.7322857142857142,
      "grad_norm": 0.03594715893268585,
      "learning_rate": 6.692857142857144e-06,
      "loss": 0.0008,
      "step": 60630
    },
    {
      "epoch": 1.7325714285714287,
      "grad_norm": 0.0,
      "learning_rate": 6.685714285714285e-06,
      "loss": 0.0012,
      "step": 60640
    },
    {
      "epoch": 1.7328571428571429,
      "grad_norm": 0.047240931540727615,
      "learning_rate": 6.678571428571429e-06,
      "loss": 0.0016,
      "step": 60650
    },
    {
      "epoch": 1.733142857142857,
      "grad_norm": 0.21714355051517487,
      "learning_rate": 6.671428571428571e-06,
      "loss": 0.0006,
      "step": 60660
    },
    {
      "epoch": 1.7334285714285715,
      "grad_norm": 0.08516474068164825,
      "learning_rate": 6.664285714285715e-06,
      "loss": 0.0025,
      "step": 60670
    },
    {
      "epoch": 1.7337142857142858,
      "grad_norm": 0.0,
      "learning_rate": 6.657142857142857e-06,
      "loss": 0.0009,
      "step": 60680
    },
    {
      "epoch": 1.734,
      "grad_norm": 0.04915756732225418,
      "learning_rate": 6.650000000000001e-06,
      "loss": 0.0003,
      "step": 60690
    },
    {
      "epoch": 1.7342857142857144,
      "grad_norm": 0.043687500059604645,
      "learning_rate": 6.642857142857144e-06,
      "loss": 0.0011,
      "step": 60700
    },
    {
      "epoch": 1.7345714285714284,
      "grad_norm": 0.2042805403470993,
      "learning_rate": 6.635714285714285e-06,
      "loss": 0.0008,
      "step": 60710
    },
    {
      "epoch": 1.7348571428571429,
      "grad_norm": 0.08204919844865799,
      "learning_rate": 6.628571428571428e-06,
      "loss": 0.0011,
      "step": 60720
    },
    {
      "epoch": 1.735142857142857,
      "grad_norm": 0.04172000288963318,
      "learning_rate": 6.621428571428572e-06,
      "loss": 0.0005,
      "step": 60730
    },
    {
      "epoch": 1.7354285714285713,
      "grad_norm": 0.0,
      "learning_rate": 6.614285714285714e-06,
      "loss": 0.0011,
      "step": 60740
    },
    {
      "epoch": 1.7357142857142858,
      "grad_norm": 0.06271552294492722,
      "learning_rate": 6.607142857142858e-06,
      "loss": 0.0002,
      "step": 60750
    },
    {
      "epoch": 1.736,
      "grad_norm": 0.12358321249485016,
      "learning_rate": 6.6e-06,
      "loss": 0.0019,
      "step": 60760
    },
    {
      "epoch": 1.7362857142857142,
      "grad_norm": 0.08938293159008026,
      "learning_rate": 6.592857142857144e-06,
      "loss": 0.0015,
      "step": 60770
    },
    {
      "epoch": 1.7365714285714287,
      "grad_norm": 0.04080471768975258,
      "learning_rate": 6.5857142857142855e-06,
      "loss": 0.0005,
      "step": 60780
    },
    {
      "epoch": 1.7368571428571429,
      "grad_norm": 0.0,
      "learning_rate": 6.578571428571428e-06,
      "loss": 0.0013,
      "step": 60790
    },
    {
      "epoch": 1.737142857142857,
      "grad_norm": 0.16354890167713165,
      "learning_rate": 6.5714285714285714e-06,
      "loss": 0.0012,
      "step": 60800
    },
    {
      "epoch": 1.7374285714285715,
      "grad_norm": 0.0509989932179451,
      "learning_rate": 6.564285714285715e-06,
      "loss": 0.0004,
      "step": 60810
    },
    {
      "epoch": 1.7377142857142858,
      "grad_norm": 0.05446450412273407,
      "learning_rate": 6.557142857142857e-06,
      "loss": 0.0016,
      "step": 60820
    },
    {
      "epoch": 1.738,
      "grad_norm": 0.046328768134117126,
      "learning_rate": 6.550000000000001e-06,
      "loss": 0.001,
      "step": 60830
    },
    {
      "epoch": 1.7382857142857144,
      "grad_norm": 0.0,
      "learning_rate": 6.542857142857143e-06,
      "loss": 0.0005,
      "step": 60840
    },
    {
      "epoch": 1.7385714285714284,
      "grad_norm": 0.045861709862947464,
      "learning_rate": 6.535714285714287e-06,
      "loss": 0.0009,
      "step": 60850
    },
    {
      "epoch": 1.7388571428571429,
      "grad_norm": 0.0,
      "learning_rate": 6.5285714285714285e-06,
      "loss": 0.0015,
      "step": 60860
    },
    {
      "epoch": 1.739142857142857,
      "grad_norm": 0.041031330823898315,
      "learning_rate": 6.521428571428571e-06,
      "loss": 0.0004,
      "step": 60870
    },
    {
      "epoch": 1.7394285714285713,
      "grad_norm": 0.12226226180791855,
      "learning_rate": 6.5142857142857145e-06,
      "loss": 0.0013,
      "step": 60880
    },
    {
      "epoch": 1.7397142857142858,
      "grad_norm": 0.05325867235660553,
      "learning_rate": 6.507142857142858e-06,
      "loss": 0.0008,
      "step": 60890
    },
    {
      "epoch": 1.74,
      "grad_norm": 0.27896058559417725,
      "learning_rate": 6.5000000000000004e-06,
      "loss": 0.0014,
      "step": 60900
    },
    {
      "epoch": 1.7402857142857142,
      "grad_norm": 0.045882001519203186,
      "learning_rate": 6.492857142857144e-06,
      "loss": 0.0005,
      "step": 60910
    },
    {
      "epoch": 1.7405714285714287,
      "grad_norm": 0.1325070559978485,
      "learning_rate": 6.485714285714286e-06,
      "loss": 0.001,
      "step": 60920
    },
    {
      "epoch": 1.7408571428571429,
      "grad_norm": 0.042664144188165665,
      "learning_rate": 6.478571428571428e-06,
      "loss": 0.0012,
      "step": 60930
    },
    {
      "epoch": 1.741142857142857,
      "grad_norm": 0.038324519991874695,
      "learning_rate": 6.4714285714285715e-06,
      "loss": 0.0004,
      "step": 60940
    },
    {
      "epoch": 1.7414285714285715,
      "grad_norm": 0.0,
      "learning_rate": 6.464285714285714e-06,
      "loss": 0.0003,
      "step": 60950
    },
    {
      "epoch": 1.7417142857142855,
      "grad_norm": 0.0,
      "learning_rate": 6.4571428571428575e-06,
      "loss": 0.0017,
      "step": 60960
    },
    {
      "epoch": 1.742,
      "grad_norm": 0.0907081663608551,
      "learning_rate": 6.45e-06,
      "loss": 0.0013,
      "step": 60970
    },
    {
      "epoch": 1.7422857142857144,
      "grad_norm": 0.07837414741516113,
      "learning_rate": 6.4428571428571435e-06,
      "loss": 0.0013,
      "step": 60980
    },
    {
      "epoch": 1.7425714285714284,
      "grad_norm": 0.1442973017692566,
      "learning_rate": 6.435714285714287e-06,
      "loss": 0.0015,
      "step": 60990
    },
    {
      "epoch": 1.7428571428571429,
      "grad_norm": 0.0,
      "learning_rate": 6.428571428571429e-06,
      "loss": 0.0007,
      "step": 61000
    },
    {
      "epoch": 1.743142857142857,
      "grad_norm": 0.1336408108472824,
      "learning_rate": 6.421428571428571e-06,
      "loss": 0.0006,
      "step": 61010
    },
    {
      "epoch": 1.7434285714285713,
      "grad_norm": 0.30474910140037537,
      "learning_rate": 6.414285714285715e-06,
      "loss": 0.0009,
      "step": 61020
    },
    {
      "epoch": 1.7437142857142858,
      "grad_norm": 0.12838774919509888,
      "learning_rate": 6.407142857142857e-06,
      "loss": 0.0014,
      "step": 61030
    },
    {
      "epoch": 1.744,
      "grad_norm": 0.08470974117517471,
      "learning_rate": 6.4000000000000006e-06,
      "loss": 0.0015,
      "step": 61040
    },
    {
      "epoch": 1.7442857142857142,
      "grad_norm": 0.04327761009335518,
      "learning_rate": 6.392857142857143e-06,
      "loss": 0.001,
      "step": 61050
    },
    {
      "epoch": 1.7445714285714287,
      "grad_norm": 0.10414344072341919,
      "learning_rate": 6.3857142857142865e-06,
      "loss": 0.0012,
      "step": 61060
    },
    {
      "epoch": 1.7448571428571429,
      "grad_norm": 0.044175099581480026,
      "learning_rate": 6.378571428571428e-06,
      "loss": 0.0004,
      "step": 61070
    },
    {
      "epoch": 1.745142857142857,
      "grad_norm": 0.23659656941890717,
      "learning_rate": 6.371428571428572e-06,
      "loss": 0.0015,
      "step": 61080
    },
    {
      "epoch": 1.7454285714285716,
      "grad_norm": 0.041420213878154755,
      "learning_rate": 6.364285714285714e-06,
      "loss": 0.0005,
      "step": 61090
    },
    {
      "epoch": 1.7457142857142856,
      "grad_norm": 0.0,
      "learning_rate": 6.357142857142858e-06,
      "loss": 0.0011,
      "step": 61100
    },
    {
      "epoch": 1.746,
      "grad_norm": 0.04153973236680031,
      "learning_rate": 6.35e-06,
      "loss": 0.0025,
      "step": 61110
    },
    {
      "epoch": 1.7462857142857144,
      "grad_norm": 0.22553066909313202,
      "learning_rate": 6.342857142857144e-06,
      "loss": 0.0003,
      "step": 61120
    },
    {
      "epoch": 1.7465714285714284,
      "grad_norm": 0.22870297729969025,
      "learning_rate": 6.335714285714286e-06,
      "loss": 0.0014,
      "step": 61130
    },
    {
      "epoch": 1.7468571428571429,
      "grad_norm": 0.0,
      "learning_rate": 6.3285714285714296e-06,
      "loss": 0.001,
      "step": 61140
    },
    {
      "epoch": 1.747142857142857,
      "grad_norm": 0.0,
      "learning_rate": 6.321428571428571e-06,
      "loss": 0.0011,
      "step": 61150
    },
    {
      "epoch": 1.7474285714285713,
      "grad_norm": 0.19007840752601624,
      "learning_rate": 6.314285714285714e-06,
      "loss": 0.0008,
      "step": 61160
    },
    {
      "epoch": 1.7477142857142858,
      "grad_norm": 0.057493939995765686,
      "learning_rate": 6.307142857142857e-06,
      "loss": 0.0015,
      "step": 61170
    },
    {
      "epoch": 1.748,
      "grad_norm": 0.0,
      "learning_rate": 6.300000000000001e-06,
      "loss": 0.0013,
      "step": 61180
    },
    {
      "epoch": 1.7482857142857142,
      "grad_norm": 0.09732168912887573,
      "learning_rate": 6.292857142857143e-06,
      "loss": 0.0008,
      "step": 61190
    },
    {
      "epoch": 1.7485714285714287,
      "grad_norm": 0.05096573010087013,
      "learning_rate": 6.285714285714287e-06,
      "loss": 0.001,
      "step": 61200
    },
    {
      "epoch": 1.7488571428571429,
      "grad_norm": 0.08127372711896896,
      "learning_rate": 6.278571428571429e-06,
      "loss": 0.0005,
      "step": 61210
    },
    {
      "epoch": 1.749142857142857,
      "grad_norm": 0.0,
      "learning_rate": 6.271428571428571e-06,
      "loss": 0.0013,
      "step": 61220
    },
    {
      "epoch": 1.7494285714285716,
      "grad_norm": 0.246473491191864,
      "learning_rate": 6.264285714285714e-06,
      "loss": 0.0011,
      "step": 61230
    },
    {
      "epoch": 1.7497142857142856,
      "grad_norm": 0.04783163592219353,
      "learning_rate": 6.257142857142857e-06,
      "loss": 0.0006,
      "step": 61240
    },
    {
      "epoch": 1.75,
      "grad_norm": 0.29496487975120544,
      "learning_rate": 6.25e-06,
      "loss": 0.0019,
      "step": 61250
    },
    {
      "epoch": 1.7502857142857144,
      "grad_norm": 0.2883267402648926,
      "learning_rate": 6.242857142857144e-06,
      "loss": 0.0014,
      "step": 61260
    },
    {
      "epoch": 1.7505714285714284,
      "grad_norm": 0.0,
      "learning_rate": 6.2357142857142854e-06,
      "loss": 0.0014,
      "step": 61270
    },
    {
      "epoch": 1.750857142857143,
      "grad_norm": 0.05413040146231651,
      "learning_rate": 6.228571428571429e-06,
      "loss": 0.0012,
      "step": 61280
    },
    {
      "epoch": 1.7511428571428571,
      "grad_norm": 0.10331112891435623,
      "learning_rate": 6.221428571428571e-06,
      "loss": 0.0019,
      "step": 61290
    },
    {
      "epoch": 1.7514285714285713,
      "grad_norm": 0.04465483874082565,
      "learning_rate": 6.214285714285715e-06,
      "loss": 0.0014,
      "step": 61300
    },
    {
      "epoch": 1.7517142857142858,
      "grad_norm": 0.055969785898923874,
      "learning_rate": 6.207142857142857e-06,
      "loss": 0.0006,
      "step": 61310
    },
    {
      "epoch": 1.752,
      "grad_norm": 0.041043613106012344,
      "learning_rate": 6.2e-06,
      "loss": 0.0005,
      "step": 61320
    },
    {
      "epoch": 1.7522857142857142,
      "grad_norm": 0.03951912000775337,
      "learning_rate": 6.192857142857143e-06,
      "loss": 0.001,
      "step": 61330
    },
    {
      "epoch": 1.7525714285714287,
      "grad_norm": 0.0,
      "learning_rate": 6.185714285714287e-06,
      "loss": 0.001,
      "step": 61340
    },
    {
      "epoch": 1.752857142857143,
      "grad_norm": 0.10369864851236343,
      "learning_rate": 6.1785714285714285e-06,
      "loss": 0.0011,
      "step": 61350
    },
    {
      "epoch": 1.7531428571428571,
      "grad_norm": 0.044232964515686035,
      "learning_rate": 6.171428571428572e-06,
      "loss": 0.0016,
      "step": 61360
    },
    {
      "epoch": 1.7534285714285716,
      "grad_norm": 0.043314579874277115,
      "learning_rate": 6.1642857142857144e-06,
      "loss": 0.001,
      "step": 61370
    },
    {
      "epoch": 1.7537142857142856,
      "grad_norm": 0.05572345107793808,
      "learning_rate": 6.157142857142857e-06,
      "loss": 0.0005,
      "step": 61380
    },
    {
      "epoch": 1.754,
      "grad_norm": 0.07182278484106064,
      "learning_rate": 6.15e-06,
      "loss": 0.001,
      "step": 61390
    },
    {
      "epoch": 1.7542857142857144,
      "grad_norm": 0.10385190695524216,
      "learning_rate": 6.142857142857143e-06,
      "loss": 0.0011,
      "step": 61400
    },
    {
      "epoch": 1.7545714285714284,
      "grad_norm": 0.1001003235578537,
      "learning_rate": 6.135714285714286e-06,
      "loss": 0.0017,
      "step": 61410
    },
    {
      "epoch": 1.754857142857143,
      "grad_norm": 0.25408264994621277,
      "learning_rate": 6.128571428571429e-06,
      "loss": 0.0008,
      "step": 61420
    },
    {
      "epoch": 1.7551428571428571,
      "grad_norm": 0.09960336983203888,
      "learning_rate": 6.1214285714285715e-06,
      "loss": 0.0015,
      "step": 61430
    },
    {
      "epoch": 1.7554285714285713,
      "grad_norm": 0.050581298768520355,
      "learning_rate": 6.114285714285715e-06,
      "loss": 0.0011,
      "step": 61440
    },
    {
      "epoch": 1.7557142857142858,
      "grad_norm": 0.04797375574707985,
      "learning_rate": 6.1071428571428575e-06,
      "loss": 0.0016,
      "step": 61450
    },
    {
      "epoch": 1.756,
      "grad_norm": 0.3350302577018738,
      "learning_rate": 6.1e-06,
      "loss": 0.0015,
      "step": 61460
    },
    {
      "epoch": 1.7562857142857142,
      "grad_norm": 0.12919563055038452,
      "learning_rate": 6.0928571428571435e-06,
      "loss": 0.0007,
      "step": 61470
    },
    {
      "epoch": 1.7565714285714287,
      "grad_norm": 0.14046311378479004,
      "learning_rate": 6.085714285714286e-06,
      "loss": 0.0015,
      "step": 61480
    },
    {
      "epoch": 1.756857142857143,
      "grad_norm": 0.0,
      "learning_rate": 6.0785714285714286e-06,
      "loss": 0.0015,
      "step": 61490
    },
    {
      "epoch": 1.7571428571428571,
      "grad_norm": 0.385658860206604,
      "learning_rate": 6.071428571428572e-06,
      "loss": 0.0011,
      "step": 61500
    },
    {
      "epoch": 1.7574285714285716,
      "grad_norm": 0.07592514902353287,
      "learning_rate": 6.0642857142857145e-06,
      "loss": 0.0014,
      "step": 61510
    },
    {
      "epoch": 1.7577142857142856,
      "grad_norm": 0.0397973395884037,
      "learning_rate": 6.057142857142858e-06,
      "loss": 0.0008,
      "step": 61520
    },
    {
      "epoch": 1.758,
      "grad_norm": 0.0,
      "learning_rate": 6.0500000000000005e-06,
      "loss": 0.0008,
      "step": 61530
    },
    {
      "epoch": 1.7582857142857145,
      "grad_norm": 0.04583660885691643,
      "learning_rate": 6.042857142857143e-06,
      "loss": 0.0007,
      "step": 61540
    },
    {
      "epoch": 1.7585714285714285,
      "grad_norm": 0.07489806413650513,
      "learning_rate": 6.0357142857142865e-06,
      "loss": 0.0013,
      "step": 61550
    },
    {
      "epoch": 1.758857142857143,
      "grad_norm": 0.07829297333955765,
      "learning_rate": 6.028571428571428e-06,
      "loss": 0.0007,
      "step": 61560
    },
    {
      "epoch": 1.7591428571428571,
      "grad_norm": 0.048151589930057526,
      "learning_rate": 6.021428571428572e-06,
      "loss": 0.0015,
      "step": 61570
    },
    {
      "epoch": 1.7594285714285713,
      "grad_norm": 0.042061660438776016,
      "learning_rate": 6.014285714285715e-06,
      "loss": 0.0012,
      "step": 61580
    },
    {
      "epoch": 1.7597142857142858,
      "grad_norm": 0.0,
      "learning_rate": 6.007142857142858e-06,
      "loss": 0.0015,
      "step": 61590
    },
    {
      "epoch": 1.76,
      "grad_norm": 0.044799476861953735,
      "learning_rate": 6e-06,
      "loss": 0.0009,
      "step": 61600
    },
    {
      "epoch": 1.7602857142857142,
      "grad_norm": 0.2359544038772583,
      "learning_rate": 5.992857142857143e-06,
      "loss": 0.0002,
      "step": 61610
    },
    {
      "epoch": 1.7605714285714287,
      "grad_norm": 0.35651925206184387,
      "learning_rate": 5.985714285714286e-06,
      "loss": 0.0012,
      "step": 61620
    },
    {
      "epoch": 1.760857142857143,
      "grad_norm": 0.05195538327097893,
      "learning_rate": 5.978571428571429e-06,
      "loss": 0.0018,
      "step": 61630
    },
    {
      "epoch": 1.7611428571428571,
      "grad_norm": 0.04221373051404953,
      "learning_rate": 5.971428571428571e-06,
      "loss": 0.0012,
      "step": 61640
    },
    {
      "epoch": 1.7614285714285716,
      "grad_norm": 0.0,
      "learning_rate": 5.964285714285715e-06,
      "loss": 0.0009,
      "step": 61650
    },
    {
      "epoch": 1.7617142857142856,
      "grad_norm": 0.04134373739361763,
      "learning_rate": 5.957142857142858e-06,
      "loss": 0.001,
      "step": 61660
    },
    {
      "epoch": 1.762,
      "grad_norm": 0.05235064774751663,
      "learning_rate": 5.95e-06,
      "loss": 0.0013,
      "step": 61670
    },
    {
      "epoch": 1.7622857142857142,
      "grad_norm": 0.2791789174079895,
      "learning_rate": 5.942857142857143e-06,
      "loss": 0.0004,
      "step": 61680
    },
    {
      "epoch": 1.7625714285714285,
      "grad_norm": 0.2145734578371048,
      "learning_rate": 5.935714285714286e-06,
      "loss": 0.0007,
      "step": 61690
    },
    {
      "epoch": 1.762857142857143,
      "grad_norm": 0.044970352202653885,
      "learning_rate": 5.928571428571429e-06,
      "loss": 0.0008,
      "step": 61700
    },
    {
      "epoch": 1.7631428571428571,
      "grad_norm": 0.06390976905822754,
      "learning_rate": 5.921428571428572e-06,
      "loss": 0.0009,
      "step": 61710
    },
    {
      "epoch": 1.7634285714285713,
      "grad_norm": 0.0,
      "learning_rate": 5.914285714285714e-06,
      "loss": 0.0006,
      "step": 61720
    },
    {
      "epoch": 1.7637142857142858,
      "grad_norm": 0.05105188488960266,
      "learning_rate": 5.907142857142858e-06,
      "loss": 0.0013,
      "step": 61730
    },
    {
      "epoch": 1.764,
      "grad_norm": 0.0,
      "learning_rate": 5.9e-06,
      "loss": 0.0008,
      "step": 61740
    },
    {
      "epoch": 1.7642857142857142,
      "grad_norm": 0.0,
      "learning_rate": 5.892857142857143e-06,
      "loss": 0.0011,
      "step": 61750
    },
    {
      "epoch": 1.7645714285714287,
      "grad_norm": 0.0,
      "learning_rate": 5.885714285714286e-06,
      "loss": 0.0008,
      "step": 61760
    },
    {
      "epoch": 1.764857142857143,
      "grad_norm": 0.0,
      "learning_rate": 5.878571428571429e-06,
      "loss": 0.0009,
      "step": 61770
    },
    {
      "epoch": 1.7651428571428571,
      "grad_norm": 0.0,
      "learning_rate": 5.871428571428571e-06,
      "loss": 0.0005,
      "step": 61780
    },
    {
      "epoch": 1.7654285714285716,
      "grad_norm": 0.0,
      "learning_rate": 5.864285714285715e-06,
      "loss": 0.0002,
      "step": 61790
    },
    {
      "epoch": 1.7657142857142856,
      "grad_norm": 0.09529081732034683,
      "learning_rate": 5.857142857142857e-06,
      "loss": 0.0011,
      "step": 61800
    },
    {
      "epoch": 1.766,
      "grad_norm": 0.08682428300380707,
      "learning_rate": 5.850000000000001e-06,
      "loss": 0.0006,
      "step": 61810
    },
    {
      "epoch": 1.7662857142857142,
      "grad_norm": 0.05967175215482712,
      "learning_rate": 5.842857142857143e-06,
      "loss": 0.0016,
      "step": 61820
    },
    {
      "epoch": 1.7665714285714285,
      "grad_norm": 0.0773889496922493,
      "learning_rate": 5.835714285714286e-06,
      "loss": 0.0011,
      "step": 61830
    },
    {
      "epoch": 1.766857142857143,
      "grad_norm": 0.1550217866897583,
      "learning_rate": 5.828571428571429e-06,
      "loss": 0.0004,
      "step": 61840
    },
    {
      "epoch": 1.7671428571428571,
      "grad_norm": 0.046220362186431885,
      "learning_rate": 5.821428571428572e-06,
      "loss": 0.0004,
      "step": 61850
    },
    {
      "epoch": 1.7674285714285713,
      "grad_norm": 0.08879952877759933,
      "learning_rate": 5.814285714285714e-06,
      "loss": 0.0009,
      "step": 61860
    },
    {
      "epoch": 1.7677142857142858,
      "grad_norm": 0.041392918676137924,
      "learning_rate": 5.807142857142858e-06,
      "loss": 0.0025,
      "step": 61870
    },
    {
      "epoch": 1.768,
      "grad_norm": 0.24001523852348328,
      "learning_rate": 5.8e-06,
      "loss": 0.0007,
      "step": 61880
    },
    {
      "epoch": 1.7682857142857142,
      "grad_norm": 0.10805534571409225,
      "learning_rate": 5.792857142857143e-06,
      "loss": 0.0011,
      "step": 61890
    },
    {
      "epoch": 1.7685714285714287,
      "grad_norm": 0.0,
      "learning_rate": 5.785714285714286e-06,
      "loss": 0.0017,
      "step": 61900
    },
    {
      "epoch": 1.768857142857143,
      "grad_norm": 0.17129337787628174,
      "learning_rate": 5.778571428571429e-06,
      "loss": 0.0019,
      "step": 61910
    },
    {
      "epoch": 1.7691428571428571,
      "grad_norm": 0.06688748300075531,
      "learning_rate": 5.7714285714285715e-06,
      "loss": 0.0022,
      "step": 61920
    },
    {
      "epoch": 1.7694285714285716,
      "grad_norm": 0.047830116003751755,
      "learning_rate": 5.764285714285714e-06,
      "loss": 0.0004,
      "step": 61930
    },
    {
      "epoch": 1.7697142857142856,
      "grad_norm": 0.23155564069747925,
      "learning_rate": 5.7571428571428574e-06,
      "loss": 0.0009,
      "step": 61940
    },
    {
      "epoch": 1.77,
      "grad_norm": 0.1993352472782135,
      "learning_rate": 5.750000000000001e-06,
      "loss": 0.0011,
      "step": 61950
    },
    {
      "epoch": 1.7702857142857142,
      "grad_norm": 0.09848147630691528,
      "learning_rate": 5.7428571428571426e-06,
      "loss": 0.0015,
      "step": 61960
    },
    {
      "epoch": 1.7705714285714285,
      "grad_norm": 0.09186021983623505,
      "learning_rate": 5.735714285714286e-06,
      "loss": 0.0015,
      "step": 61970
    },
    {
      "epoch": 1.770857142857143,
      "grad_norm": 0.05938396602869034,
      "learning_rate": 5.728571428571429e-06,
      "loss": 0.0021,
      "step": 61980
    },
    {
      "epoch": 1.7711428571428571,
      "grad_norm": 0.33115872740745544,
      "learning_rate": 5.721428571428572e-06,
      "loss": 0.0009,
      "step": 61990
    },
    {
      "epoch": 1.7714285714285714,
      "grad_norm": 0.04630861431360245,
      "learning_rate": 5.7142857142857145e-06,
      "loss": 0.0003,
      "step": 62000
    },
    {
      "epoch": 1.7717142857142858,
      "grad_norm": 0.04389362409710884,
      "learning_rate": 5.707142857142857e-06,
      "loss": 0.0016,
      "step": 62010
    },
    {
      "epoch": 1.772,
      "grad_norm": 0.0,
      "learning_rate": 5.7000000000000005e-06,
      "loss": 0.0009,
      "step": 62020
    },
    {
      "epoch": 1.7722857142857142,
      "grad_norm": 0.059611156582832336,
      "learning_rate": 5.692857142857143e-06,
      "loss": 0.0018,
      "step": 62030
    },
    {
      "epoch": 1.7725714285714287,
      "grad_norm": 0.09649647772312164,
      "learning_rate": 5.685714285714286e-06,
      "loss": 0.0014,
      "step": 62040
    },
    {
      "epoch": 1.772857142857143,
      "grad_norm": 0.1350032389163971,
      "learning_rate": 5.678571428571429e-06,
      "loss": 0.0012,
      "step": 62050
    },
    {
      "epoch": 1.7731428571428571,
      "grad_norm": 0.24432611465454102,
      "learning_rate": 5.671428571428572e-06,
      "loss": 0.0012,
      "step": 62060
    },
    {
      "epoch": 1.7734285714285716,
      "grad_norm": 0.13724513351917267,
      "learning_rate": 5.664285714285714e-06,
      "loss": 0.0011,
      "step": 62070
    },
    {
      "epoch": 1.7737142857142856,
      "grad_norm": 0.11673711985349655,
      "learning_rate": 5.6571428571428576e-06,
      "loss": 0.0009,
      "step": 62080
    },
    {
      "epoch": 1.774,
      "grad_norm": 0.0,
      "learning_rate": 5.65e-06,
      "loss": 0.0013,
      "step": 62090
    },
    {
      "epoch": 1.7742857142857142,
      "grad_norm": 0.05352744460105896,
      "learning_rate": 5.642857142857143e-06,
      "loss": 0.0014,
      "step": 62100
    },
    {
      "epoch": 1.7745714285714285,
      "grad_norm": 0.0,
      "learning_rate": 5.635714285714286e-06,
      "loss": 0.0003,
      "step": 62110
    },
    {
      "epoch": 1.774857142857143,
      "grad_norm": 0.0,
      "learning_rate": 5.628571428571429e-06,
      "loss": 0.0012,
      "step": 62120
    },
    {
      "epoch": 1.7751428571428571,
      "grad_norm": 0.3468170464038849,
      "learning_rate": 5.621428571428572e-06,
      "loss": 0.0007,
      "step": 62130
    },
    {
      "epoch": 1.7754285714285714,
      "grad_norm": 0.05104336887598038,
      "learning_rate": 5.614285714285715e-06,
      "loss": 0.0009,
      "step": 62140
    },
    {
      "epoch": 1.7757142857142858,
      "grad_norm": 0.0,
      "learning_rate": 5.607142857142857e-06,
      "loss": 0.0006,
      "step": 62150
    },
    {
      "epoch": 1.776,
      "grad_norm": 0.18580330908298492,
      "learning_rate": 5.600000000000001e-06,
      "loss": 0.0015,
      "step": 62160
    },
    {
      "epoch": 1.7762857142857142,
      "grad_norm": 0.22622303664684296,
      "learning_rate": 5.592857142857143e-06,
      "loss": 0.0015,
      "step": 62170
    },
    {
      "epoch": 1.7765714285714287,
      "grad_norm": 0.0,
      "learning_rate": 5.585714285714286e-06,
      "loss": 0.0004,
      "step": 62180
    },
    {
      "epoch": 1.7768571428571427,
      "grad_norm": 0.06103832274675369,
      "learning_rate": 5.578571428571429e-06,
      "loss": 0.0004,
      "step": 62190
    },
    {
      "epoch": 1.7771428571428571,
      "grad_norm": 0.04874474182724953,
      "learning_rate": 5.571428571428572e-06,
      "loss": 0.0008,
      "step": 62200
    },
    {
      "epoch": 1.7774285714285716,
      "grad_norm": 0.05217662453651428,
      "learning_rate": 5.564285714285714e-06,
      "loss": 0.0006,
      "step": 62210
    },
    {
      "epoch": 1.7777142857142856,
      "grad_norm": 0.03509322926402092,
      "learning_rate": 5.557142857142858e-06,
      "loss": 0.0004,
      "step": 62220
    },
    {
      "epoch": 1.778,
      "grad_norm": 0.0,
      "learning_rate": 5.55e-06,
      "loss": 0.0012,
      "step": 62230
    },
    {
      "epoch": 1.7782857142857142,
      "grad_norm": 0.05465725436806679,
      "learning_rate": 5.542857142857144e-06,
      "loss": 0.0005,
      "step": 62240
    },
    {
      "epoch": 1.7785714285714285,
      "grad_norm": 0.11061245203018188,
      "learning_rate": 5.535714285714285e-06,
      "loss": 0.0023,
      "step": 62250
    },
    {
      "epoch": 1.778857142857143,
      "grad_norm": 0.2815324068069458,
      "learning_rate": 5.528571428571429e-06,
      "loss": 0.0011,
      "step": 62260
    },
    {
      "epoch": 1.7791428571428571,
      "grad_norm": 0.0,
      "learning_rate": 5.521428571428572e-06,
      "loss": 0.001,
      "step": 62270
    },
    {
      "epoch": 1.7794285714285714,
      "grad_norm": 0.1214282214641571,
      "learning_rate": 5.514285714285715e-06,
      "loss": 0.0009,
      "step": 62280
    },
    {
      "epoch": 1.7797142857142858,
      "grad_norm": 0.06791377067565918,
      "learning_rate": 5.507142857142857e-06,
      "loss": 0.0002,
      "step": 62290
    },
    {
      "epoch": 1.78,
      "grad_norm": 0.1291263848543167,
      "learning_rate": 5.500000000000001e-06,
      "loss": 0.0009,
      "step": 62300
    },
    {
      "epoch": 1.7802857142857142,
      "grad_norm": 0.06341367214918137,
      "learning_rate": 5.492857142857143e-06,
      "loss": 0.0015,
      "step": 62310
    },
    {
      "epoch": 1.7805714285714287,
      "grad_norm": 0.0,
      "learning_rate": 5.485714285714286e-06,
      "loss": 0.001,
      "step": 62320
    },
    {
      "epoch": 1.7808571428571427,
      "grad_norm": 0.0,
      "learning_rate": 5.478571428571428e-06,
      "loss": 0.0013,
      "step": 62330
    },
    {
      "epoch": 1.7811428571428571,
      "grad_norm": 0.2685425579547882,
      "learning_rate": 5.471428571428572e-06,
      "loss": 0.0014,
      "step": 62340
    },
    {
      "epoch": 1.7814285714285716,
      "grad_norm": 0.08038043230772018,
      "learning_rate": 5.464285714285715e-06,
      "loss": 0.0014,
      "step": 62350
    },
    {
      "epoch": 1.7817142857142856,
      "grad_norm": 0.04408550262451172,
      "learning_rate": 5.457142857142857e-06,
      "loss": 0.0009,
      "step": 62360
    },
    {
      "epoch": 1.782,
      "grad_norm": 0.0,
      "learning_rate": 5.45e-06,
      "loss": 0.0013,
      "step": 62370
    },
    {
      "epoch": 1.7822857142857143,
      "grad_norm": 0.0,
      "learning_rate": 5.442857142857143e-06,
      "loss": 0.0011,
      "step": 62380
    },
    {
      "epoch": 1.7825714285714285,
      "grad_norm": 0.06130117177963257,
      "learning_rate": 5.4357142857142855e-06,
      "loss": 0.0007,
      "step": 62390
    },
    {
      "epoch": 1.782857142857143,
      "grad_norm": 0.0653739646077156,
      "learning_rate": 5.428571428571429e-06,
      "loss": 0.0008,
      "step": 62400
    },
    {
      "epoch": 1.7831428571428571,
      "grad_norm": 0.0,
      "learning_rate": 5.4214285714285714e-06,
      "loss": 0.0011,
      "step": 62410
    },
    {
      "epoch": 1.7834285714285714,
      "grad_norm": 0.05476103723049164,
      "learning_rate": 5.414285714285715e-06,
      "loss": 0.0015,
      "step": 62420
    },
    {
      "epoch": 1.7837142857142858,
      "grad_norm": 0.04918432608246803,
      "learning_rate": 5.407142857142857e-06,
      "loss": 0.0013,
      "step": 62430
    },
    {
      "epoch": 1.784,
      "grad_norm": 0.2181166410446167,
      "learning_rate": 5.4e-06,
      "loss": 0.0019,
      "step": 62440
    },
    {
      "epoch": 1.7842857142857143,
      "grad_norm": 0.34090980887413025,
      "learning_rate": 5.392857142857143e-06,
      "loss": 0.0015,
      "step": 62450
    },
    {
      "epoch": 1.7845714285714287,
      "grad_norm": 0.0,
      "learning_rate": 5.385714285714286e-06,
      "loss": 0.0011,
      "step": 62460
    },
    {
      "epoch": 1.7848571428571427,
      "grad_norm": 0.04639732837677002,
      "learning_rate": 5.3785714285714285e-06,
      "loss": 0.002,
      "step": 62470
    },
    {
      "epoch": 1.7851428571428571,
      "grad_norm": 0.0682208463549614,
      "learning_rate": 5.371428571428572e-06,
      "loss": 0.0014,
      "step": 62480
    },
    {
      "epoch": 1.7854285714285716,
      "grad_norm": 0.09035657346248627,
      "learning_rate": 5.3642857142857145e-06,
      "loss": 0.0012,
      "step": 62490
    },
    {
      "epoch": 1.7857142857142856,
      "grad_norm": 0.0543372817337513,
      "learning_rate": 5.357142857142857e-06,
      "loss": 0.0016,
      "step": 62500
    },
    {
      "epoch": 1.786,
      "grad_norm": 0.28695809841156006,
      "learning_rate": 5.3500000000000004e-06,
      "loss": 0.001,
      "step": 62510
    },
    {
      "epoch": 1.7862857142857143,
      "grad_norm": 0.049206607043743134,
      "learning_rate": 5.342857142857143e-06,
      "loss": 0.001,
      "step": 62520
    },
    {
      "epoch": 1.7865714285714285,
      "grad_norm": 0.2786421775817871,
      "learning_rate": 5.335714285714286e-06,
      "loss": 0.002,
      "step": 62530
    },
    {
      "epoch": 1.786857142857143,
      "grad_norm": 0.14448922872543335,
      "learning_rate": 5.328571428571429e-06,
      "loss": 0.0023,
      "step": 62540
    },
    {
      "epoch": 1.7871428571428571,
      "grad_norm": 0.08826268464326859,
      "learning_rate": 5.3214285714285715e-06,
      "loss": 0.001,
      "step": 62550
    },
    {
      "epoch": 1.7874285714285714,
      "grad_norm": 0.0,
      "learning_rate": 5.314285714285715e-06,
      "loss": 0.0005,
      "step": 62560
    },
    {
      "epoch": 1.7877142857142858,
      "grad_norm": 0.37553930282592773,
      "learning_rate": 5.307142857142857e-06,
      "loss": 0.002,
      "step": 62570
    },
    {
      "epoch": 1.788,
      "grad_norm": 0.050149787217378616,
      "learning_rate": 5.3e-06,
      "loss": 0.0008,
      "step": 62580
    },
    {
      "epoch": 1.7882857142857143,
      "grad_norm": 0.23622539639472961,
      "learning_rate": 5.2928571428571435e-06,
      "loss": 0.0011,
      "step": 62590
    },
    {
      "epoch": 1.7885714285714287,
      "grad_norm": 0.04096211493015289,
      "learning_rate": 5.285714285714286e-06,
      "loss": 0.0007,
      "step": 62600
    },
    {
      "epoch": 1.7888571428571427,
      "grad_norm": 0.04831349849700928,
      "learning_rate": 5.278571428571429e-06,
      "loss": 0.0005,
      "step": 62610
    },
    {
      "epoch": 1.7891428571428571,
      "grad_norm": 0.0,
      "learning_rate": 5.271428571428572e-06,
      "loss": 0.0009,
      "step": 62620
    },
    {
      "epoch": 1.7894285714285716,
      "grad_norm": 0.08237167447805405,
      "learning_rate": 5.264285714285715e-06,
      "loss": 0.0008,
      "step": 62630
    },
    {
      "epoch": 1.7897142857142856,
      "grad_norm": 0.10352983325719833,
      "learning_rate": 5.257142857142858e-06,
      "loss": 0.001,
      "step": 62640
    },
    {
      "epoch": 1.79,
      "grad_norm": 0.12388450652360916,
      "learning_rate": 5.25e-06,
      "loss": 0.0007,
      "step": 62650
    },
    {
      "epoch": 1.7902857142857143,
      "grad_norm": 0.0,
      "learning_rate": 5.242857142857143e-06,
      "loss": 0.0009,
      "step": 62660
    },
    {
      "epoch": 1.7905714285714285,
      "grad_norm": 0.0,
      "learning_rate": 5.2357142857142865e-06,
      "loss": 0.0007,
      "step": 62670
    },
    {
      "epoch": 1.790857142857143,
      "grad_norm": 0.25351351499557495,
      "learning_rate": 5.228571428571428e-06,
      "loss": 0.0017,
      "step": 62680
    },
    {
      "epoch": 1.7911428571428571,
      "grad_norm": 0.0,
      "learning_rate": 5.221428571428572e-06,
      "loss": 0.0023,
      "step": 62690
    },
    {
      "epoch": 1.7914285714285714,
      "grad_norm": 0.03894387558102608,
      "learning_rate": 5.214285714285714e-06,
      "loss": 0.0002,
      "step": 62700
    },
    {
      "epoch": 1.7917142857142858,
      "grad_norm": 0.1574224978685379,
      "learning_rate": 5.207142857142858e-06,
      "loss": 0.0007,
      "step": 62710
    },
    {
      "epoch": 1.792,
      "grad_norm": 0.0,
      "learning_rate": 5.2e-06,
      "loss": 0.0009,
      "step": 62720
    },
    {
      "epoch": 1.7922857142857143,
      "grad_norm": 0.043164294213056564,
      "learning_rate": 5.192857142857143e-06,
      "loss": 0.0004,
      "step": 62730
    },
    {
      "epoch": 1.7925714285714287,
      "grad_norm": 0.0,
      "learning_rate": 5.185714285714286e-06,
      "loss": 0.0008,
      "step": 62740
    },
    {
      "epoch": 1.7928571428571427,
      "grad_norm": 0.08065088093280792,
      "learning_rate": 5.1785714285714296e-06,
      "loss": 0.0006,
      "step": 62750
    },
    {
      "epoch": 1.7931428571428571,
      "grad_norm": 0.11861073225736618,
      "learning_rate": 5.171428571428571e-06,
      "loss": 0.0015,
      "step": 62760
    },
    {
      "epoch": 1.7934285714285716,
      "grad_norm": 0.050082188099622726,
      "learning_rate": 5.164285714285715e-06,
      "loss": 0.0009,
      "step": 62770
    },
    {
      "epoch": 1.7937142857142856,
      "grad_norm": 0.048679254949092865,
      "learning_rate": 5.157142857142857e-06,
      "loss": 0.0007,
      "step": 62780
    },
    {
      "epoch": 1.794,
      "grad_norm": 0.0749889463186264,
      "learning_rate": 5.15e-06,
      "loss": 0.0006,
      "step": 62790
    },
    {
      "epoch": 1.7942857142857143,
      "grad_norm": 0.0630967766046524,
      "learning_rate": 5.142857142857143e-06,
      "loss": 0.0015,
      "step": 62800
    },
    {
      "epoch": 1.7945714285714285,
      "grad_norm": 0.040048882365226746,
      "learning_rate": 5.135714285714286e-06,
      "loss": 0.0012,
      "step": 62810
    },
    {
      "epoch": 1.794857142857143,
      "grad_norm": 0.04915427789092064,
      "learning_rate": 5.128571428571429e-06,
      "loss": 0.0007,
      "step": 62820
    },
    {
      "epoch": 1.7951428571428572,
      "grad_norm": 0.1274762600660324,
      "learning_rate": 5.121428571428572e-06,
      "loss": 0.0013,
      "step": 62830
    },
    {
      "epoch": 1.7954285714285714,
      "grad_norm": 0.06677290797233582,
      "learning_rate": 5.114285714285714e-06,
      "loss": 0.0013,
      "step": 62840
    },
    {
      "epoch": 1.7957142857142858,
      "grad_norm": 0.2735913395881653,
      "learning_rate": 5.107142857142858e-06,
      "loss": 0.0008,
      "step": 62850
    },
    {
      "epoch": 1.796,
      "grad_norm": 0.0,
      "learning_rate": 5.1e-06,
      "loss": 0.001,
      "step": 62860
    },
    {
      "epoch": 1.7962857142857143,
      "grad_norm": 0.18341979384422302,
      "learning_rate": 5.092857142857143e-06,
      "loss": 0.0021,
      "step": 62870
    },
    {
      "epoch": 1.7965714285714287,
      "grad_norm": 0.04256703332066536,
      "learning_rate": 5.085714285714286e-06,
      "loss": 0.001,
      "step": 62880
    },
    {
      "epoch": 1.7968571428571427,
      "grad_norm": 0.0,
      "learning_rate": 5.078571428571429e-06,
      "loss": 0.0009,
      "step": 62890
    },
    {
      "epoch": 1.7971428571428572,
      "grad_norm": 0.04556939750909805,
      "learning_rate": 5.071428571428571e-06,
      "loss": 0.0006,
      "step": 62900
    },
    {
      "epoch": 1.7974285714285714,
      "grad_norm": 0.0,
      "learning_rate": 5.064285714285715e-06,
      "loss": 0.0013,
      "step": 62910
    },
    {
      "epoch": 1.7977142857142856,
      "grad_norm": 0.04398324340581894,
      "learning_rate": 5.057142857142857e-06,
      "loss": 0.0014,
      "step": 62920
    },
    {
      "epoch": 1.798,
      "grad_norm": 0.1643502563238144,
      "learning_rate": 5.050000000000001e-06,
      "loss": 0.0009,
      "step": 62930
    },
    {
      "epoch": 1.7982857142857143,
      "grad_norm": 0.22716213762760162,
      "learning_rate": 5.042857142857143e-06,
      "loss": 0.0007,
      "step": 62940
    },
    {
      "epoch": 1.7985714285714285,
      "grad_norm": 0.061119429767131805,
      "learning_rate": 5.035714285714286e-06,
      "loss": 0.0012,
      "step": 62950
    },
    {
      "epoch": 1.798857142857143,
      "grad_norm": 0.12638312578201294,
      "learning_rate": 5.028571428571429e-06,
      "loss": 0.0013,
      "step": 62960
    },
    {
      "epoch": 1.7991428571428572,
      "grad_norm": 0.04863712564110756,
      "learning_rate": 5.021428571428571e-06,
      "loss": 0.0008,
      "step": 62970
    },
    {
      "epoch": 1.7994285714285714,
      "grad_norm": 0.0,
      "learning_rate": 5.0142857142857144e-06,
      "loss": 0.0007,
      "step": 62980
    },
    {
      "epoch": 1.7997142857142858,
      "grad_norm": 0.272360235452652,
      "learning_rate": 5.007142857142858e-06,
      "loss": 0.001,
      "step": 62990
    },
    {
      "epoch": 1.8,
      "grad_norm": 0.0,
      "learning_rate": 5e-06,
      "loss": 0.0007,
      "step": 63000
    },
    {
      "epoch": 1.8002857142857143,
      "grad_norm": 0.24950237572193146,
      "learning_rate": 4.992857142857143e-06,
      "loss": 0.002,
      "step": 63010
    },
    {
      "epoch": 1.8005714285714287,
      "grad_norm": 0.19922491908073425,
      "learning_rate": 4.9857142857142855e-06,
      "loss": 0.0013,
      "step": 63020
    },
    {
      "epoch": 1.8008571428571427,
      "grad_norm": 0.0,
      "learning_rate": 4.978571428571429e-06,
      "loss": 0.0008,
      "step": 63030
    },
    {
      "epoch": 1.8011428571428572,
      "grad_norm": 0.04338347166776657,
      "learning_rate": 4.9714285714285715e-06,
      "loss": 0.0012,
      "step": 63040
    },
    {
      "epoch": 1.8014285714285714,
      "grad_norm": 0.08611542731523514,
      "learning_rate": 4.964285714285714e-06,
      "loss": 0.0012,
      "step": 63050
    },
    {
      "epoch": 1.8017142857142856,
      "grad_norm": 0.04372710362076759,
      "learning_rate": 4.9571428571428575e-06,
      "loss": 0.0022,
      "step": 63060
    },
    {
      "epoch": 1.802,
      "grad_norm": 0.2788870632648468,
      "learning_rate": 4.950000000000001e-06,
      "loss": 0.0007,
      "step": 63070
    },
    {
      "epoch": 1.8022857142857143,
      "grad_norm": 0.0,
      "learning_rate": 4.942857142857143e-06,
      "loss": 0.0007,
      "step": 63080
    },
    {
      "epoch": 1.8025714285714285,
      "grad_norm": 0.03563784435391426,
      "learning_rate": 4.935714285714286e-06,
      "loss": 0.0003,
      "step": 63090
    },
    {
      "epoch": 1.802857142857143,
      "grad_norm": 0.08482611924409866,
      "learning_rate": 4.9285714285714286e-06,
      "loss": 0.0016,
      "step": 63100
    },
    {
      "epoch": 1.8031428571428572,
      "grad_norm": 0.049279775470495224,
      "learning_rate": 4.921428571428572e-06,
      "loss": 0.0007,
      "step": 63110
    },
    {
      "epoch": 1.8034285714285714,
      "grad_norm": 0.0,
      "learning_rate": 4.9142857142857145e-06,
      "loss": 0.0013,
      "step": 63120
    },
    {
      "epoch": 1.8037142857142858,
      "grad_norm": 0.1304004043340683,
      "learning_rate": 4.907142857142857e-06,
      "loss": 0.001,
      "step": 63130
    },
    {
      "epoch": 1.804,
      "grad_norm": 0.05103861540555954,
      "learning_rate": 4.9000000000000005e-06,
      "loss": 0.0008,
      "step": 63140
    },
    {
      "epoch": 1.8042857142857143,
      "grad_norm": 0.0,
      "learning_rate": 4.892857142857143e-06,
      "loss": 0.0005,
      "step": 63150
    },
    {
      "epoch": 1.8045714285714287,
      "grad_norm": 0.0,
      "learning_rate": 4.885714285714286e-06,
      "loss": 0.0007,
      "step": 63160
    },
    {
      "epoch": 1.8048571428571427,
      "grad_norm": 0.05424196273088455,
      "learning_rate": 4.878571428571429e-06,
      "loss": 0.0012,
      "step": 63170
    },
    {
      "epoch": 1.8051428571428572,
      "grad_norm": 0.1589355170726776,
      "learning_rate": 4.871428571428572e-06,
      "loss": 0.0007,
      "step": 63180
    },
    {
      "epoch": 1.8054285714285714,
      "grad_norm": 0.1371898055076599,
      "learning_rate": 4.864285714285714e-06,
      "loss": 0.0016,
      "step": 63190
    },
    {
      "epoch": 1.8057142857142856,
      "grad_norm": 0.273335725069046,
      "learning_rate": 4.857142857142858e-06,
      "loss": 0.0018,
      "step": 63200
    },
    {
      "epoch": 1.806,
      "grad_norm": 0.0,
      "learning_rate": 4.85e-06,
      "loss": 0.002,
      "step": 63210
    },
    {
      "epoch": 1.8062857142857143,
      "grad_norm": 0.09723036736249924,
      "learning_rate": 4.8428571428571436e-06,
      "loss": 0.0009,
      "step": 63220
    },
    {
      "epoch": 1.8065714285714285,
      "grad_norm": 0.049715396016836166,
      "learning_rate": 4.835714285714286e-06,
      "loss": 0.0015,
      "step": 63230
    },
    {
      "epoch": 1.806857142857143,
      "grad_norm": 0.047962531447410583,
      "learning_rate": 4.828571428571429e-06,
      "loss": 0.0007,
      "step": 63240
    },
    {
      "epoch": 1.8071428571428572,
      "grad_norm": 0.08536677062511444,
      "learning_rate": 4.821428571428572e-06,
      "loss": 0.0011,
      "step": 63250
    },
    {
      "epoch": 1.8074285714285714,
      "grad_norm": 0.2826363146305084,
      "learning_rate": 4.814285714285714e-06,
      "loss": 0.0013,
      "step": 63260
    },
    {
      "epoch": 1.8077142857142858,
      "grad_norm": 0.0,
      "learning_rate": 4.807142857142857e-06,
      "loss": 0.0011,
      "step": 63270
    },
    {
      "epoch": 1.808,
      "grad_norm": 0.04442625120282173,
      "learning_rate": 4.800000000000001e-06,
      "loss": 0.0004,
      "step": 63280
    },
    {
      "epoch": 1.8082857142857143,
      "grad_norm": 0.05827314406633377,
      "learning_rate": 4.792857142857143e-06,
      "loss": 0.001,
      "step": 63290
    },
    {
      "epoch": 1.8085714285714287,
      "grad_norm": 0.0,
      "learning_rate": 4.785714285714286e-06,
      "loss": 0.0008,
      "step": 63300
    },
    {
      "epoch": 1.8088571428571427,
      "grad_norm": 0.16817770898342133,
      "learning_rate": 4.778571428571429e-06,
      "loss": 0.0011,
      "step": 63310
    },
    {
      "epoch": 1.8091428571428572,
      "grad_norm": 0.0,
      "learning_rate": 4.771428571428572e-06,
      "loss": 0.001,
      "step": 63320
    },
    {
      "epoch": 1.8094285714285714,
      "grad_norm": 0.10835763812065125,
      "learning_rate": 4.764285714285714e-06,
      "loss": 0.0004,
      "step": 63330
    },
    {
      "epoch": 1.8097142857142856,
      "grad_norm": 0.2120896577835083,
      "learning_rate": 4.757142857142857e-06,
      "loss": 0.0012,
      "step": 63340
    },
    {
      "epoch": 1.81,
      "grad_norm": 0.23639678955078125,
      "learning_rate": 4.75e-06,
      "loss": 0.001,
      "step": 63350
    },
    {
      "epoch": 1.8102857142857143,
      "grad_norm": 0.201040580868721,
      "learning_rate": 4.742857142857144e-06,
      "loss": 0.0014,
      "step": 63360
    },
    {
      "epoch": 1.8105714285714285,
      "grad_norm": 0.0,
      "learning_rate": 4.735714285714285e-06,
      "loss": 0.001,
      "step": 63370
    },
    {
      "epoch": 1.810857142857143,
      "grad_norm": 0.15485988557338715,
      "learning_rate": 4.728571428571429e-06,
      "loss": 0.0013,
      "step": 63380
    },
    {
      "epoch": 1.8111428571428572,
      "grad_norm": 0.04690044745802879,
      "learning_rate": 4.721428571428572e-06,
      "loss": 0.0011,
      "step": 63390
    },
    {
      "epoch": 1.8114285714285714,
      "grad_norm": 0.2240760624408722,
      "learning_rate": 4.714285714285715e-06,
      "loss": 0.0012,
      "step": 63400
    },
    {
      "epoch": 1.8117142857142858,
      "grad_norm": 0.0,
      "learning_rate": 4.707142857142857e-06,
      "loss": 0.0007,
      "step": 63410
    },
    {
      "epoch": 1.812,
      "grad_norm": 0.07927257567644119,
      "learning_rate": 4.7e-06,
      "loss": 0.0014,
      "step": 63420
    },
    {
      "epoch": 1.8122857142857143,
      "grad_norm": 0.0,
      "learning_rate": 4.692857142857143e-06,
      "loss": 0.0005,
      "step": 63430
    },
    {
      "epoch": 1.8125714285714287,
      "grad_norm": 0.27442458271980286,
      "learning_rate": 4.685714285714286e-06,
      "loss": 0.0009,
      "step": 63440
    },
    {
      "epoch": 1.8128571428571427,
      "grad_norm": 0.09359931945800781,
      "learning_rate": 4.6785714285714284e-06,
      "loss": 0.0014,
      "step": 63450
    },
    {
      "epoch": 1.8131428571428572,
      "grad_norm": 0.057129424065351486,
      "learning_rate": 4.671428571428572e-06,
      "loss": 0.0013,
      "step": 63460
    },
    {
      "epoch": 1.8134285714285714,
      "grad_norm": 0.20964710414409637,
      "learning_rate": 4.664285714285714e-06,
      "loss": 0.0009,
      "step": 63470
    },
    {
      "epoch": 1.8137142857142856,
      "grad_norm": 0.0,
      "learning_rate": 4.657142857142857e-06,
      "loss": 0.0006,
      "step": 63480
    },
    {
      "epoch": 1.814,
      "grad_norm": 0.08957058191299438,
      "learning_rate": 4.65e-06,
      "loss": 0.0018,
      "step": 63490
    },
    {
      "epoch": 1.8142857142857143,
      "grad_norm": 0.22703319787979126,
      "learning_rate": 4.642857142857143e-06,
      "loss": 0.0005,
      "step": 63500
    },
    {
      "epoch": 1.8145714285714285,
      "grad_norm": 0.0,
      "learning_rate": 4.6357142857142855e-06,
      "loss": 0.0009,
      "step": 63510
    },
    {
      "epoch": 1.814857142857143,
      "grad_norm": 0.2885003983974457,
      "learning_rate": 4.628571428571429e-06,
      "loss": 0.0009,
      "step": 63520
    },
    {
      "epoch": 1.8151428571428572,
      "grad_norm": 0.0,
      "learning_rate": 4.6214285714285715e-06,
      "loss": 0.0012,
      "step": 63530
    },
    {
      "epoch": 1.8154285714285714,
      "grad_norm": 0.1712835729122162,
      "learning_rate": 4.614285714285715e-06,
      "loss": 0.0009,
      "step": 63540
    },
    {
      "epoch": 1.8157142857142858,
      "grad_norm": 0.36804261803627014,
      "learning_rate": 4.6071428571428574e-06,
      "loss": 0.0013,
      "step": 63550
    },
    {
      "epoch": 1.8159999999999998,
      "grad_norm": 0.16188248991966248,
      "learning_rate": 4.6e-06,
      "loss": 0.0005,
      "step": 63560
    },
    {
      "epoch": 1.8162857142857143,
      "grad_norm": 0.0,
      "learning_rate": 4.592857142857143e-06,
      "loss": 0.0008,
      "step": 63570
    },
    {
      "epoch": 1.8165714285714287,
      "grad_norm": 0.04909660294651985,
      "learning_rate": 4.585714285714286e-06,
      "loss": 0.0004,
      "step": 63580
    },
    {
      "epoch": 1.8168571428571427,
      "grad_norm": 0.19283322989940643,
      "learning_rate": 4.5785714285714285e-06,
      "loss": 0.0014,
      "step": 63590
    },
    {
      "epoch": 1.8171428571428572,
      "grad_norm": 0.04207757115364075,
      "learning_rate": 4.571428571428572e-06,
      "loss": 0.0007,
      "step": 63600
    },
    {
      "epoch": 1.8174285714285714,
      "grad_norm": 0.04212639108300209,
      "learning_rate": 4.5642857142857145e-06,
      "loss": 0.0006,
      "step": 63610
    },
    {
      "epoch": 1.8177142857142856,
      "grad_norm": 0.05947975441813469,
      "learning_rate": 4.557142857142857e-06,
      "loss": 0.0012,
      "step": 63620
    },
    {
      "epoch": 1.818,
      "grad_norm": 0.043643392622470856,
      "learning_rate": 4.5500000000000005e-06,
      "loss": 0.0006,
      "step": 63630
    },
    {
      "epoch": 1.8182857142857143,
      "grad_norm": 0.1878586709499359,
      "learning_rate": 4.542857142857143e-06,
      "loss": 0.0006,
      "step": 63640
    },
    {
      "epoch": 1.8185714285714285,
      "grad_norm": 0.0,
      "learning_rate": 4.5357142857142865e-06,
      "loss": 0.0013,
      "step": 63650
    },
    {
      "epoch": 1.818857142857143,
      "grad_norm": 0.0,
      "learning_rate": 4.528571428571428e-06,
      "loss": 0.0003,
      "step": 63660
    },
    {
      "epoch": 1.8191428571428572,
      "grad_norm": 0.2815974950790405,
      "learning_rate": 4.521428571428572e-06,
      "loss": 0.0023,
      "step": 63670
    },
    {
      "epoch": 1.8194285714285714,
      "grad_norm": 0.2099548578262329,
      "learning_rate": 4.514285714285715e-06,
      "loss": 0.0011,
      "step": 63680
    },
    {
      "epoch": 1.8197142857142858,
      "grad_norm": 0.0,
      "learning_rate": 4.5071428571428576e-06,
      "loss": 0.0009,
      "step": 63690
    },
    {
      "epoch": 1.8199999999999998,
      "grad_norm": 0.04182841256260872,
      "learning_rate": 4.5e-06,
      "loss": 0.0013,
      "step": 63700
    },
    {
      "epoch": 1.8202857142857143,
      "grad_norm": 0.2475275695323944,
      "learning_rate": 4.492857142857143e-06,
      "loss": 0.001,
      "step": 63710
    },
    {
      "epoch": 1.8205714285714287,
      "grad_norm": 0.0,
      "learning_rate": 4.485714285714286e-06,
      "loss": 0.0006,
      "step": 63720
    },
    {
      "epoch": 1.8208571428571427,
      "grad_norm": 0.07420812547206879,
      "learning_rate": 4.478571428571429e-06,
      "loss": 0.0009,
      "step": 63730
    },
    {
      "epoch": 1.8211428571428572,
      "grad_norm": 0.1687292456626892,
      "learning_rate": 4.471428571428571e-06,
      "loss": 0.0009,
      "step": 63740
    },
    {
      "epoch": 1.8214285714285714,
      "grad_norm": 0.04550563171505928,
      "learning_rate": 4.464285714285715e-06,
      "loss": 0.0006,
      "step": 63750
    },
    {
      "epoch": 1.8217142857142856,
      "grad_norm": 0.1582852005958557,
      "learning_rate": 4.457142857142858e-06,
      "loss": 0.0004,
      "step": 63760
    },
    {
      "epoch": 1.822,
      "grad_norm": 0.23509743809700012,
      "learning_rate": 4.45e-06,
      "loss": 0.0008,
      "step": 63770
    },
    {
      "epoch": 1.8222857142857143,
      "grad_norm": 0.15223641693592072,
      "learning_rate": 4.442857142857143e-06,
      "loss": 0.0013,
      "step": 63780
    },
    {
      "epoch": 1.8225714285714285,
      "grad_norm": 0.11241649091243744,
      "learning_rate": 4.435714285714286e-06,
      "loss": 0.0014,
      "step": 63790
    },
    {
      "epoch": 1.822857142857143,
      "grad_norm": 0.0775865986943245,
      "learning_rate": 4.428571428571428e-06,
      "loss": 0.002,
      "step": 63800
    },
    {
      "epoch": 1.8231428571428572,
      "grad_norm": 0.05647619441151619,
      "learning_rate": 4.421428571428572e-06,
      "loss": 0.0005,
      "step": 63810
    },
    {
      "epoch": 1.8234285714285714,
      "grad_norm": 0.0,
      "learning_rate": 4.414285714285714e-06,
      "loss": 0.0005,
      "step": 63820
    },
    {
      "epoch": 1.8237142857142858,
      "grad_norm": 0.057733405381441116,
      "learning_rate": 4.407142857142858e-06,
      "loss": 0.0015,
      "step": 63830
    },
    {
      "epoch": 1.8239999999999998,
      "grad_norm": 0.0459996834397316,
      "learning_rate": 4.4e-06,
      "loss": 0.0013,
      "step": 63840
    },
    {
      "epoch": 1.8242857142857143,
      "grad_norm": 0.09089583158493042,
      "learning_rate": 4.392857142857143e-06,
      "loss": 0.001,
      "step": 63850
    },
    {
      "epoch": 1.8245714285714287,
      "grad_norm": 0.05214931443333626,
      "learning_rate": 4.385714285714286e-06,
      "loss": 0.0012,
      "step": 63860
    },
    {
      "epoch": 1.8248571428571427,
      "grad_norm": 0.04515382647514343,
      "learning_rate": 4.378571428571429e-06,
      "loss": 0.0009,
      "step": 63870
    },
    {
      "epoch": 1.8251428571428572,
      "grad_norm": 0.0,
      "learning_rate": 4.371428571428571e-06,
      "loss": 0.0014,
      "step": 63880
    },
    {
      "epoch": 1.8254285714285714,
      "grad_norm": 0.16683998703956604,
      "learning_rate": 4.364285714285715e-06,
      "loss": 0.0003,
      "step": 63890
    },
    {
      "epoch": 1.8257142857142856,
      "grad_norm": 0.04740172252058983,
      "learning_rate": 4.357142857142857e-06,
      "loss": 0.0005,
      "step": 63900
    },
    {
      "epoch": 1.826,
      "grad_norm": 0.09540913999080658,
      "learning_rate": 4.35e-06,
      "loss": 0.0014,
      "step": 63910
    },
    {
      "epoch": 1.8262857142857143,
      "grad_norm": 0.3639967143535614,
      "learning_rate": 4.342857142857143e-06,
      "loss": 0.0015,
      "step": 63920
    },
    {
      "epoch": 1.8265714285714285,
      "grad_norm": 0.09274998307228088,
      "learning_rate": 4.335714285714286e-06,
      "loss": 0.001,
      "step": 63930
    },
    {
      "epoch": 1.826857142857143,
      "grad_norm": 0.0459592379629612,
      "learning_rate": 4.328571428571429e-06,
      "loss": 0.0007,
      "step": 63940
    },
    {
      "epoch": 1.8271428571428572,
      "grad_norm": 0.2980012595653534,
      "learning_rate": 4.321428571428572e-06,
      "loss": 0.0009,
      "step": 63950
    },
    {
      "epoch": 1.8274285714285714,
      "grad_norm": 0.0600614994764328,
      "learning_rate": 4.314285714285714e-06,
      "loss": 0.0017,
      "step": 63960
    },
    {
      "epoch": 1.8277142857142858,
      "grad_norm": 0.18437209725379944,
      "learning_rate": 4.307142857142858e-06,
      "loss": 0.0011,
      "step": 63970
    },
    {
      "epoch": 1.8279999999999998,
      "grad_norm": 0.0,
      "learning_rate": 4.2999999999999995e-06,
      "loss": 0.001,
      "step": 63980
    },
    {
      "epoch": 1.8282857142857143,
      "grad_norm": 0.18840304017066956,
      "learning_rate": 4.292857142857143e-06,
      "loss": 0.0012,
      "step": 63990
    },
    {
      "epoch": 1.8285714285714287,
      "grad_norm": 0.05181669816374779,
      "learning_rate": 4.285714285714286e-06,
      "loss": 0.001,
      "step": 64000
    },
    {
      "epoch": 1.8288571428571427,
      "grad_norm": 0.0,
      "learning_rate": 4.278571428571429e-06,
      "loss": 0.0008,
      "step": 64010
    },
    {
      "epoch": 1.8291428571428572,
      "grad_norm": 0.10719774663448334,
      "learning_rate": 4.2714285714285714e-06,
      "loss": 0.0018,
      "step": 64020
    },
    {
      "epoch": 1.8294285714285714,
      "grad_norm": 0.1261463612318039,
      "learning_rate": 4.264285714285714e-06,
      "loss": 0.0007,
      "step": 64030
    },
    {
      "epoch": 1.8297142857142856,
      "grad_norm": 0.10239730030298233,
      "learning_rate": 4.257142857142857e-06,
      "loss": 0.0018,
      "step": 64040
    },
    {
      "epoch": 1.83,
      "grad_norm": 0.03755325451493263,
      "learning_rate": 4.250000000000001e-06,
      "loss": 0.0012,
      "step": 64050
    },
    {
      "epoch": 1.8302857142857143,
      "grad_norm": 0.05892697721719742,
      "learning_rate": 4.2428571428571425e-06,
      "loss": 0.0016,
      "step": 64060
    },
    {
      "epoch": 1.8305714285714285,
      "grad_norm": 0.22673183679580688,
      "learning_rate": 4.235714285714286e-06,
      "loss": 0.002,
      "step": 64070
    },
    {
      "epoch": 1.830857142857143,
      "grad_norm": 0.03987157344818115,
      "learning_rate": 4.228571428571429e-06,
      "loss": 0.0001,
      "step": 64080
    },
    {
      "epoch": 1.8311428571428572,
      "grad_norm": 0.0533779077231884,
      "learning_rate": 4.221428571428571e-06,
      "loss": 0.0009,
      "step": 64090
    },
    {
      "epoch": 1.8314285714285714,
      "grad_norm": 0.08144677430391312,
      "learning_rate": 4.2142857142857145e-06,
      "loss": 0.0012,
      "step": 64100
    },
    {
      "epoch": 1.8317142857142859,
      "grad_norm": 0.13851064443588257,
      "learning_rate": 4.207142857142857e-06,
      "loss": 0.0015,
      "step": 64110
    },
    {
      "epoch": 1.8319999999999999,
      "grad_norm": 0.24521329998970032,
      "learning_rate": 4.2000000000000004e-06,
      "loss": 0.0014,
      "step": 64120
    },
    {
      "epoch": 1.8322857142857143,
      "grad_norm": 0.18627847731113434,
      "learning_rate": 4.192857142857143e-06,
      "loss": 0.0009,
      "step": 64130
    },
    {
      "epoch": 1.8325714285714285,
      "grad_norm": 0.04279692843556404,
      "learning_rate": 4.1857142857142856e-06,
      "loss": 0.0014,
      "step": 64140
    },
    {
      "epoch": 1.8328571428571427,
      "grad_norm": 0.059705063700675964,
      "learning_rate": 4.178571428571429e-06,
      "loss": 0.0009,
      "step": 64150
    },
    {
      "epoch": 1.8331428571428572,
      "grad_norm": 0.10274233669042587,
      "learning_rate": 4.1714285714285715e-06,
      "loss": 0.0007,
      "step": 64160
    },
    {
      "epoch": 1.8334285714285714,
      "grad_norm": 0.05097786337137222,
      "learning_rate": 4.164285714285714e-06,
      "loss": 0.0006,
      "step": 64170
    },
    {
      "epoch": 1.8337142857142856,
      "grad_norm": 0.22372280061244965,
      "learning_rate": 4.1571428571428575e-06,
      "loss": 0.0007,
      "step": 64180
    },
    {
      "epoch": 1.834,
      "grad_norm": 0.07084492594003677,
      "learning_rate": 4.15e-06,
      "loss": 0.0019,
      "step": 64190
    },
    {
      "epoch": 1.8342857142857143,
      "grad_norm": 0.24319171905517578,
      "learning_rate": 4.142857142857143e-06,
      "loss": 0.0017,
      "step": 64200
    },
    {
      "epoch": 1.8345714285714285,
      "grad_norm": 0.0,
      "learning_rate": 4.135714285714286e-06,
      "loss": 0.0011,
      "step": 64210
    },
    {
      "epoch": 1.834857142857143,
      "grad_norm": 0.04923403635621071,
      "learning_rate": 4.128571428571429e-06,
      "loss": 0.0013,
      "step": 64220
    },
    {
      "epoch": 1.8351428571428572,
      "grad_norm": 0.1712586134672165,
      "learning_rate": 4.121428571428572e-06,
      "loss": 0.0008,
      "step": 64230
    },
    {
      "epoch": 1.8354285714285714,
      "grad_norm": 0.04179181158542633,
      "learning_rate": 4.114285714285715e-06,
      "loss": 0.0008,
      "step": 64240
    },
    {
      "epoch": 1.8357142857142859,
      "grad_norm": 0.12527517974376678,
      "learning_rate": 4.107142857142857e-06,
      "loss": 0.0008,
      "step": 64250
    },
    {
      "epoch": 1.8359999999999999,
      "grad_norm": 0.041155483573675156,
      "learning_rate": 4.1000000000000006e-06,
      "loss": 0.0005,
      "step": 64260
    },
    {
      "epoch": 1.8362857142857143,
      "grad_norm": 0.04347826540470123,
      "learning_rate": 4.092857142857143e-06,
      "loss": 0.0006,
      "step": 64270
    },
    {
      "epoch": 1.8365714285714285,
      "grad_norm": 0.0,
      "learning_rate": 4.085714285714286e-06,
      "loss": 0.0009,
      "step": 64280
    },
    {
      "epoch": 1.8368571428571427,
      "grad_norm": 0.21336576342582703,
      "learning_rate": 4.078571428571429e-06,
      "loss": 0.001,
      "step": 64290
    },
    {
      "epoch": 1.8371428571428572,
      "grad_norm": 0.03915603831410408,
      "learning_rate": 4.071428571428572e-06,
      "loss": 0.0004,
      "step": 64300
    },
    {
      "epoch": 1.8374285714285714,
      "grad_norm": 0.04723918065428734,
      "learning_rate": 4.064285714285714e-06,
      "loss": 0.0009,
      "step": 64310
    },
    {
      "epoch": 1.8377142857142856,
      "grad_norm": 0.18016041815280914,
      "learning_rate": 4.057142857142858e-06,
      "loss": 0.0016,
      "step": 64320
    },
    {
      "epoch": 1.838,
      "grad_norm": 0.10561225563287735,
      "learning_rate": 4.05e-06,
      "loss": 0.0005,
      "step": 64330
    },
    {
      "epoch": 1.8382857142857143,
      "grad_norm": 0.14376719295978546,
      "learning_rate": 4.042857142857144e-06,
      "loss": 0.0014,
      "step": 64340
    },
    {
      "epoch": 1.8385714285714285,
      "grad_norm": 0.3032446801662445,
      "learning_rate": 4.035714285714285e-06,
      "loss": 0.0005,
      "step": 64350
    },
    {
      "epoch": 1.838857142857143,
      "grad_norm": 0.04057937487959862,
      "learning_rate": 4.028571428571429e-06,
      "loss": 0.0003,
      "step": 64360
    },
    {
      "epoch": 1.8391428571428572,
      "grad_norm": 0.03172526881098747,
      "learning_rate": 4.021428571428572e-06,
      "loss": 0.0014,
      "step": 64370
    },
    {
      "epoch": 1.8394285714285714,
      "grad_norm": 0.0,
      "learning_rate": 4.014285714285714e-06,
      "loss": 0.0007,
      "step": 64380
    },
    {
      "epoch": 1.8397142857142859,
      "grad_norm": 0.044207677245140076,
      "learning_rate": 4.007142857142857e-06,
      "loss": 0.0008,
      "step": 64390
    },
    {
      "epoch": 1.8399999999999999,
      "grad_norm": 0.06117747351527214,
      "learning_rate": 4.000000000000001e-06,
      "loss": 0.0009,
      "step": 64400
    },
    {
      "epoch": 1.8402857142857143,
      "grad_norm": 0.07195516675710678,
      "learning_rate": 3.992857142857143e-06,
      "loss": 0.0013,
      "step": 64410
    },
    {
      "epoch": 1.8405714285714285,
      "grad_norm": 0.08273106813430786,
      "learning_rate": 3.985714285714286e-06,
      "loss": 0.0016,
      "step": 64420
    },
    {
      "epoch": 1.8408571428571427,
      "grad_norm": 0.04461558163166046,
      "learning_rate": 3.978571428571428e-06,
      "loss": 0.0007,
      "step": 64430
    },
    {
      "epoch": 1.8411428571428572,
      "grad_norm": 0.06272523105144501,
      "learning_rate": 3.971428571428572e-06,
      "loss": 0.0012,
      "step": 64440
    },
    {
      "epoch": 1.8414285714285714,
      "grad_norm": 0.276633620262146,
      "learning_rate": 3.964285714285714e-06,
      "loss": 0.0013,
      "step": 64450
    },
    {
      "epoch": 1.8417142857142856,
      "grad_norm": 0.09908126294612885,
      "learning_rate": 3.957142857142857e-06,
      "loss": 0.0011,
      "step": 64460
    },
    {
      "epoch": 1.842,
      "grad_norm": 0.14463989436626434,
      "learning_rate": 3.95e-06,
      "loss": 0.0011,
      "step": 64470
    },
    {
      "epoch": 1.8422857142857143,
      "grad_norm": 0.05555392801761627,
      "learning_rate": 3.942857142857143e-06,
      "loss": 0.001,
      "step": 64480
    },
    {
      "epoch": 1.8425714285714285,
      "grad_norm": 0.0,
      "learning_rate": 3.935714285714285e-06,
      "loss": 0.0014,
      "step": 64490
    },
    {
      "epoch": 1.842857142857143,
      "grad_norm": 0.09119430929422379,
      "learning_rate": 3.928571428571429e-06,
      "loss": 0.0005,
      "step": 64500
    },
    {
      "epoch": 1.8431428571428572,
      "grad_norm": 0.08566369116306305,
      "learning_rate": 3.921428571428571e-06,
      "loss": 0.0017,
      "step": 64510
    },
    {
      "epoch": 1.8434285714285714,
      "grad_norm": 0.23797674477100372,
      "learning_rate": 3.914285714285715e-06,
      "loss": 0.0013,
      "step": 64520
    },
    {
      "epoch": 1.8437142857142859,
      "grad_norm": 0.0,
      "learning_rate": 3.907142857142857e-06,
      "loss": 0.0003,
      "step": 64530
    },
    {
      "epoch": 1.8439999999999999,
      "grad_norm": 0.0,
      "learning_rate": 3.9e-06,
      "loss": 0.0006,
      "step": 64540
    },
    {
      "epoch": 1.8442857142857143,
      "grad_norm": 0.0,
      "learning_rate": 3.892857142857143e-06,
      "loss": 0.0003,
      "step": 64550
    },
    {
      "epoch": 1.8445714285714285,
      "grad_norm": 0.05913877114653587,
      "learning_rate": 3.885714285714286e-06,
      "loss": 0.0008,
      "step": 64560
    },
    {
      "epoch": 1.8448571428571428,
      "grad_norm": 0.037608303129673004,
      "learning_rate": 3.8785714285714285e-06,
      "loss": 0.0005,
      "step": 64570
    },
    {
      "epoch": 1.8451428571428572,
      "grad_norm": 0.21245615184307098,
      "learning_rate": 3.871428571428572e-06,
      "loss": 0.0008,
      "step": 64580
    },
    {
      "epoch": 1.8454285714285714,
      "grad_norm": 0.05164545401930809,
      "learning_rate": 3.8642857142857144e-06,
      "loss": 0.0009,
      "step": 64590
    },
    {
      "epoch": 1.8457142857142856,
      "grad_norm": 0.059820011258125305,
      "learning_rate": 3.857142857142857e-06,
      "loss": 0.0008,
      "step": 64600
    },
    {
      "epoch": 1.846,
      "grad_norm": 0.08965212851762772,
      "learning_rate": 3.85e-06,
      "loss": 0.0016,
      "step": 64610
    },
    {
      "epoch": 1.8462857142857143,
      "grad_norm": 0.16838902235031128,
      "learning_rate": 3.842857142857143e-06,
      "loss": 0.0021,
      "step": 64620
    },
    {
      "epoch": 1.8465714285714285,
      "grad_norm": 0.0,
      "learning_rate": 3.835714285714286e-06,
      "loss": 0.0014,
      "step": 64630
    },
    {
      "epoch": 1.846857142857143,
      "grad_norm": 0.04488779976963997,
      "learning_rate": 3.828571428571429e-06,
      "loss": 0.0008,
      "step": 64640
    },
    {
      "epoch": 1.8471428571428572,
      "grad_norm": 0.2758227288722992,
      "learning_rate": 3.8214285714285715e-06,
      "loss": 0.0013,
      "step": 64650
    },
    {
      "epoch": 1.8474285714285714,
      "grad_norm": 0.30553027987480164,
      "learning_rate": 3.8142857142857145e-06,
      "loss": 0.0007,
      "step": 64660
    },
    {
      "epoch": 1.8477142857142859,
      "grad_norm": 0.07345563918352127,
      "learning_rate": 3.807142857142857e-06,
      "loss": 0.0016,
      "step": 64670
    },
    {
      "epoch": 1.8479999999999999,
      "grad_norm": 0.0,
      "learning_rate": 3.8e-06,
      "loss": 0.0008,
      "step": 64680
    },
    {
      "epoch": 1.8482857142857143,
      "grad_norm": 0.0,
      "learning_rate": 3.792857142857143e-06,
      "loss": 0.0016,
      "step": 64690
    },
    {
      "epoch": 1.8485714285714285,
      "grad_norm": 0.03829183429479599,
      "learning_rate": 3.785714285714286e-06,
      "loss": 0.0003,
      "step": 64700
    },
    {
      "epoch": 1.8488571428571428,
      "grad_norm": 0.05962143465876579,
      "learning_rate": 3.7785714285714286e-06,
      "loss": 0.0013,
      "step": 64710
    },
    {
      "epoch": 1.8491428571428572,
      "grad_norm": 0.06752027571201324,
      "learning_rate": 3.7714285714285716e-06,
      "loss": 0.0008,
      "step": 64720
    },
    {
      "epoch": 1.8494285714285714,
      "grad_norm": 0.05736568197607994,
      "learning_rate": 3.7642857142857145e-06,
      "loss": 0.0013,
      "step": 64730
    },
    {
      "epoch": 1.8497142857142856,
      "grad_norm": 0.0611703060567379,
      "learning_rate": 3.757142857142857e-06,
      "loss": 0.0003,
      "step": 64740
    },
    {
      "epoch": 1.85,
      "grad_norm": 0.10232874751091003,
      "learning_rate": 3.75e-06,
      "loss": 0.0018,
      "step": 64750
    },
    {
      "epoch": 1.8502857142857143,
      "grad_norm": 0.12663690745830536,
      "learning_rate": 3.742857142857143e-06,
      "loss": 0.0016,
      "step": 64760
    },
    {
      "epoch": 1.8505714285714285,
      "grad_norm": 0.09122643619775772,
      "learning_rate": 3.735714285714286e-06,
      "loss": 0.0006,
      "step": 64770
    },
    {
      "epoch": 1.850857142857143,
      "grad_norm": 0.21371027827262878,
      "learning_rate": 3.7285714285714286e-06,
      "loss": 0.0006,
      "step": 64780
    },
    {
      "epoch": 1.851142857142857,
      "grad_norm": 0.19179147481918335,
      "learning_rate": 3.7214285714285716e-06,
      "loss": 0.0012,
      "step": 64790
    },
    {
      "epoch": 1.8514285714285714,
      "grad_norm": 0.08375056833028793,
      "learning_rate": 3.7142857142857146e-06,
      "loss": 0.0007,
      "step": 64800
    },
    {
      "epoch": 1.8517142857142859,
      "grad_norm": 0.045786719769239426,
      "learning_rate": 3.7071428571428576e-06,
      "loss": 0.0006,
      "step": 64810
    },
    {
      "epoch": 1.8519999999999999,
      "grad_norm": 0.04664425551891327,
      "learning_rate": 3.7e-06,
      "loss": 0.0004,
      "step": 64820
    },
    {
      "epoch": 1.8522857142857143,
      "grad_norm": 0.0,
      "learning_rate": 3.692857142857143e-06,
      "loss": 0.0009,
      "step": 64830
    },
    {
      "epoch": 1.8525714285714285,
      "grad_norm": 0.09835762530565262,
      "learning_rate": 3.685714285714286e-06,
      "loss": 0.0005,
      "step": 64840
    },
    {
      "epoch": 1.8528571428571428,
      "grad_norm": 0.0,
      "learning_rate": 3.6785714285714283e-06,
      "loss": 0.0006,
      "step": 64850
    },
    {
      "epoch": 1.8531428571428572,
      "grad_norm": 0.0,
      "learning_rate": 3.6714285714285717e-06,
      "loss": 0.0008,
      "step": 64860
    },
    {
      "epoch": 1.8534285714285714,
      "grad_norm": 0.2665596604347229,
      "learning_rate": 3.6642857142857147e-06,
      "loss": 0.0004,
      "step": 64870
    },
    {
      "epoch": 1.8537142857142856,
      "grad_norm": 0.1163942813873291,
      "learning_rate": 3.6571428571428576e-06,
      "loss": 0.0013,
      "step": 64880
    },
    {
      "epoch": 1.854,
      "grad_norm": 0.1259174644947052,
      "learning_rate": 3.6499999999999998e-06,
      "loss": 0.0002,
      "step": 64890
    },
    {
      "epoch": 1.8542857142857143,
      "grad_norm": 0.04993860051035881,
      "learning_rate": 3.642857142857143e-06,
      "loss": 0.0007,
      "step": 64900
    },
    {
      "epoch": 1.8545714285714285,
      "grad_norm": 0.24561205506324768,
      "learning_rate": 3.635714285714286e-06,
      "loss": 0.0009,
      "step": 64910
    },
    {
      "epoch": 1.854857142857143,
      "grad_norm": 0.04739808663725853,
      "learning_rate": 3.6285714285714283e-06,
      "loss": 0.001,
      "step": 64920
    },
    {
      "epoch": 1.855142857142857,
      "grad_norm": 0.09367011487483978,
      "learning_rate": 3.6214285714285713e-06,
      "loss": 0.001,
      "step": 64930
    },
    {
      "epoch": 1.8554285714285714,
      "grad_norm": 0.05163697153329849,
      "learning_rate": 3.6142857142857143e-06,
      "loss": 0.0012,
      "step": 64940
    },
    {
      "epoch": 1.8557142857142859,
      "grad_norm": 0.0,
      "learning_rate": 3.6071428571428577e-06,
      "loss": 0.0008,
      "step": 64950
    },
    {
      "epoch": 1.8559999999999999,
      "grad_norm": 0.056174054741859436,
      "learning_rate": 3.6e-06,
      "loss": 0.0007,
      "step": 64960
    },
    {
      "epoch": 1.8562857142857143,
      "grad_norm": 0.07182132452726364,
      "learning_rate": 3.592857142857143e-06,
      "loss": 0.0018,
      "step": 64970
    },
    {
      "epoch": 1.8565714285714285,
      "grad_norm": 0.12300533056259155,
      "learning_rate": 3.585714285714286e-06,
      "loss": 0.0012,
      "step": 64980
    },
    {
      "epoch": 1.8568571428571428,
      "grad_norm": 0.046695273369550705,
      "learning_rate": 3.5785714285714292e-06,
      "loss": 0.0007,
      "step": 64990
    },
    {
      "epoch": 1.8571428571428572,
      "grad_norm": 0.0,
      "learning_rate": 3.5714285714285714e-06,
      "loss": 0.0005,
      "step": 65000
    },
    {
      "epoch": 1.8574285714285714,
      "grad_norm": 0.08498629182577133,
      "learning_rate": 3.5642857142857143e-06,
      "loss": 0.0013,
      "step": 65010
    },
    {
      "epoch": 1.8577142857142857,
      "grad_norm": 0.0,
      "learning_rate": 3.5571428571428573e-06,
      "loss": 0.0013,
      "step": 65020
    },
    {
      "epoch": 1.858,
      "grad_norm": 0.03352527320384979,
      "learning_rate": 3.55e-06,
      "loss": 0.0011,
      "step": 65030
    },
    {
      "epoch": 1.8582857142857143,
      "grad_norm": 0.09152548015117645,
      "learning_rate": 3.542857142857143e-06,
      "loss": 0.0006,
      "step": 65040
    },
    {
      "epoch": 1.8585714285714285,
      "grad_norm": 0.06646523624658585,
      "learning_rate": 3.535714285714286e-06,
      "loss": 0.0015,
      "step": 65050
    },
    {
      "epoch": 1.858857142857143,
      "grad_norm": 0.04309293255209923,
      "learning_rate": 3.528571428571429e-06,
      "loss": 0.001,
      "step": 65060
    },
    {
      "epoch": 1.859142857142857,
      "grad_norm": 0.04161212965846062,
      "learning_rate": 3.5214285714285714e-06,
      "loss": 0.0006,
      "step": 65070
    },
    {
      "epoch": 1.8594285714285714,
      "grad_norm": 0.041034627705812454,
      "learning_rate": 3.5142857142857144e-06,
      "loss": 0.0008,
      "step": 65080
    },
    {
      "epoch": 1.8597142857142859,
      "grad_norm": 0.0516098290681839,
      "learning_rate": 3.5071428571428574e-06,
      "loss": 0.001,
      "step": 65090
    },
    {
      "epoch": 1.8599999999999999,
      "grad_norm": 0.0,
      "learning_rate": 3.5000000000000004e-06,
      "loss": 0.0004,
      "step": 65100
    },
    {
      "epoch": 1.8602857142857143,
      "grad_norm": 0.29661446809768677,
      "learning_rate": 3.492857142857143e-06,
      "loss": 0.0016,
      "step": 65110
    },
    {
      "epoch": 1.8605714285714285,
      "grad_norm": 0.17602117359638214,
      "learning_rate": 3.485714285714286e-06,
      "loss": 0.0008,
      "step": 65120
    },
    {
      "epoch": 1.8608571428571428,
      "grad_norm": 0.0405883826315403,
      "learning_rate": 3.478571428571429e-06,
      "loss": 0.0017,
      "step": 65130
    },
    {
      "epoch": 1.8611428571428572,
      "grad_norm": 0.19109144806861877,
      "learning_rate": 3.4714285714285715e-06,
      "loss": 0.0013,
      "step": 65140
    },
    {
      "epoch": 1.8614285714285714,
      "grad_norm": 0.0646653026342392,
      "learning_rate": 3.4642857142857145e-06,
      "loss": 0.0009,
      "step": 65150
    },
    {
      "epoch": 1.8617142857142857,
      "grad_norm": 0.033860716968774796,
      "learning_rate": 3.4571428571428574e-06,
      "loss": 0.0006,
      "step": 65160
    },
    {
      "epoch": 1.862,
      "grad_norm": 0.0,
      "learning_rate": 3.4500000000000004e-06,
      "loss": 0.0011,
      "step": 65170
    },
    {
      "epoch": 1.8622857142857143,
      "grad_norm": 0.0,
      "learning_rate": 3.442857142857143e-06,
      "loss": 0.0012,
      "step": 65180
    },
    {
      "epoch": 1.8625714285714285,
      "grad_norm": 0.05834852531552315,
      "learning_rate": 3.435714285714286e-06,
      "loss": 0.001,
      "step": 65190
    },
    {
      "epoch": 1.862857142857143,
      "grad_norm": 0.0,
      "learning_rate": 3.428571428571429e-06,
      "loss": 0.0015,
      "step": 65200
    },
    {
      "epoch": 1.863142857142857,
      "grad_norm": 0.0,
      "learning_rate": 3.421428571428571e-06,
      "loss": 0.0013,
      "step": 65210
    },
    {
      "epoch": 1.8634285714285714,
      "grad_norm": 0.26177576184272766,
      "learning_rate": 3.4142857142857145e-06,
      "loss": 0.0008,
      "step": 65220
    },
    {
      "epoch": 1.8637142857142859,
      "grad_norm": 0.3105953335762024,
      "learning_rate": 3.4071428571428575e-06,
      "loss": 0.0011,
      "step": 65230
    },
    {
      "epoch": 1.8639999999999999,
      "grad_norm": 0.0,
      "learning_rate": 3.4000000000000005e-06,
      "loss": 0.0002,
      "step": 65240
    },
    {
      "epoch": 1.8642857142857143,
      "grad_norm": 0.0,
      "learning_rate": 3.3928571428571426e-06,
      "loss": 0.0009,
      "step": 65250
    },
    {
      "epoch": 1.8645714285714285,
      "grad_norm": 0.133466899394989,
      "learning_rate": 3.3857142857142856e-06,
      "loss": 0.0018,
      "step": 65260
    },
    {
      "epoch": 1.8648571428571428,
      "grad_norm": 0.05019545927643776,
      "learning_rate": 3.378571428571429e-06,
      "loss": 0.001,
      "step": 65270
    },
    {
      "epoch": 1.8651428571428572,
      "grad_norm": 0.10558611154556274,
      "learning_rate": 3.371428571428572e-06,
      "loss": 0.001,
      "step": 65280
    },
    {
      "epoch": 1.8654285714285714,
      "grad_norm": 0.17480577528476715,
      "learning_rate": 3.364285714285714e-06,
      "loss": 0.0014,
      "step": 65290
    },
    {
      "epoch": 1.8657142857142857,
      "grad_norm": 0.0938137024641037,
      "learning_rate": 3.357142857142857e-06,
      "loss": 0.0006,
      "step": 65300
    },
    {
      "epoch": 1.866,
      "grad_norm": 0.0884934812784195,
      "learning_rate": 3.3500000000000005e-06,
      "loss": 0.0007,
      "step": 65310
    },
    {
      "epoch": 1.8662857142857143,
      "grad_norm": 0.04840553551912308,
      "learning_rate": 3.3428571428571427e-06,
      "loss": 0.0018,
      "step": 65320
    },
    {
      "epoch": 1.8665714285714285,
      "grad_norm": 0.2099938541650772,
      "learning_rate": 3.3357142857142857e-06,
      "loss": 0.0013,
      "step": 65330
    },
    {
      "epoch": 1.866857142857143,
      "grad_norm": 0.15953339636325836,
      "learning_rate": 3.3285714285714286e-06,
      "loss": 0.0007,
      "step": 65340
    },
    {
      "epoch": 1.867142857142857,
      "grad_norm": 0.0,
      "learning_rate": 3.321428571428572e-06,
      "loss": 0.0012,
      "step": 65350
    },
    {
      "epoch": 1.8674285714285714,
      "grad_norm": 0.06487955898046494,
      "learning_rate": 3.314285714285714e-06,
      "loss": 0.0008,
      "step": 65360
    },
    {
      "epoch": 1.8677142857142857,
      "grad_norm": 0.0,
      "learning_rate": 3.307142857142857e-06,
      "loss": 0.0012,
      "step": 65370
    },
    {
      "epoch": 1.8679999999999999,
      "grad_norm": 0.04778395593166351,
      "learning_rate": 3.3e-06,
      "loss": 0.0003,
      "step": 65380
    },
    {
      "epoch": 1.8682857142857143,
      "grad_norm": 0.18542739748954773,
      "learning_rate": 3.2928571428571427e-06,
      "loss": 0.0013,
      "step": 65390
    },
    {
      "epoch": 1.8685714285714285,
      "grad_norm": 0.0,
      "learning_rate": 3.2857142857142857e-06,
      "loss": 0.0004,
      "step": 65400
    },
    {
      "epoch": 1.8688571428571428,
      "grad_norm": 0.07137807458639145,
      "learning_rate": 3.2785714285714287e-06,
      "loss": 0.0007,
      "step": 65410
    },
    {
      "epoch": 1.8691428571428572,
      "grad_norm": 0.045919645577669144,
      "learning_rate": 3.2714285714285717e-06,
      "loss": 0.001,
      "step": 65420
    },
    {
      "epoch": 1.8694285714285714,
      "grad_norm": 0.03341401740908623,
      "learning_rate": 3.2642857142857143e-06,
      "loss": 0.0005,
      "step": 65430
    },
    {
      "epoch": 1.8697142857142857,
      "grad_norm": 0.10469357669353485,
      "learning_rate": 3.2571428571428572e-06,
      "loss": 0.0006,
      "step": 65440
    },
    {
      "epoch": 1.87,
      "grad_norm": 0.18893349170684814,
      "learning_rate": 3.2500000000000002e-06,
      "loss": 0.0008,
      "step": 65450
    },
    {
      "epoch": 1.8702857142857143,
      "grad_norm": 0.0539746955037117,
      "learning_rate": 3.242857142857143e-06,
      "loss": 0.0011,
      "step": 65460
    },
    {
      "epoch": 1.8705714285714286,
      "grad_norm": 0.0,
      "learning_rate": 3.2357142857142858e-06,
      "loss": 0.0006,
      "step": 65470
    },
    {
      "epoch": 1.870857142857143,
      "grad_norm": 0.0,
      "learning_rate": 3.2285714285714288e-06,
      "loss": 0.0011,
      "step": 65480
    },
    {
      "epoch": 1.871142857142857,
      "grad_norm": 0.04250176250934601,
      "learning_rate": 3.2214285714285717e-06,
      "loss": 0.0001,
      "step": 65490
    },
    {
      "epoch": 1.8714285714285714,
      "grad_norm": 0.0907401293516159,
      "learning_rate": 3.2142857142857143e-06,
      "loss": 0.0009,
      "step": 65500
    },
    {
      "epoch": 1.8717142857142857,
      "grad_norm": 0.1684088557958603,
      "learning_rate": 3.2071428571428573e-06,
      "loss": 0.001,
      "step": 65510
    },
    {
      "epoch": 1.8719999999999999,
      "grad_norm": 0.044873856008052826,
      "learning_rate": 3.2000000000000003e-06,
      "loss": 0.0012,
      "step": 65520
    },
    {
      "epoch": 1.8722857142857143,
      "grad_norm": 0.08871510624885559,
      "learning_rate": 3.1928571428571433e-06,
      "loss": 0.0009,
      "step": 65530
    },
    {
      "epoch": 1.8725714285714286,
      "grad_norm": 0.04367690533399582,
      "learning_rate": 3.185714285714286e-06,
      "loss": 0.0008,
      "step": 65540
    },
    {
      "epoch": 1.8728571428571428,
      "grad_norm": 0.044099949300289154,
      "learning_rate": 3.178571428571429e-06,
      "loss": 0.0001,
      "step": 65550
    },
    {
      "epoch": 1.8731428571428572,
      "grad_norm": 0.09865826368331909,
      "learning_rate": 3.171428571428572e-06,
      "loss": 0.0015,
      "step": 65560
    },
    {
      "epoch": 1.8734285714285714,
      "grad_norm": 0.05233512073755264,
      "learning_rate": 3.1642857142857148e-06,
      "loss": 0.0009,
      "step": 65570
    },
    {
      "epoch": 1.8737142857142857,
      "grad_norm": 0.0,
      "learning_rate": 3.157142857142857e-06,
      "loss": 0.001,
      "step": 65580
    },
    {
      "epoch": 1.874,
      "grad_norm": 0.05242332071065903,
      "learning_rate": 3.1500000000000003e-06,
      "loss": 0.0005,
      "step": 65590
    },
    {
      "epoch": 1.8742857142857143,
      "grad_norm": 0.04097190126776695,
      "learning_rate": 3.1428571428571433e-06,
      "loss": 0.0015,
      "step": 65600
    },
    {
      "epoch": 1.8745714285714286,
      "grad_norm": 0.0,
      "learning_rate": 3.1357142857142855e-06,
      "loss": 0.0009,
      "step": 65610
    },
    {
      "epoch": 1.874857142857143,
      "grad_norm": 0.1415228396654129,
      "learning_rate": 3.1285714285714284e-06,
      "loss": 0.0017,
      "step": 65620
    },
    {
      "epoch": 1.875142857142857,
      "grad_norm": 0.05090983584523201,
      "learning_rate": 3.121428571428572e-06,
      "loss": 0.001,
      "step": 65630
    },
    {
      "epoch": 1.8754285714285714,
      "grad_norm": 0.0716484859585762,
      "learning_rate": 3.1142857142857144e-06,
      "loss": 0.0009,
      "step": 65640
    },
    {
      "epoch": 1.8757142857142857,
      "grad_norm": 0.0,
      "learning_rate": 3.1071428571428574e-06,
      "loss": 0.0004,
      "step": 65650
    },
    {
      "epoch": 1.876,
      "grad_norm": 0.10315843671560287,
      "learning_rate": 3.1e-06,
      "loss": 0.001,
      "step": 65660
    },
    {
      "epoch": 1.8762857142857143,
      "grad_norm": 0.03534698113799095,
      "learning_rate": 3.0928571428571434e-06,
      "loss": 0.0022,
      "step": 65670
    },
    {
      "epoch": 1.8765714285714286,
      "grad_norm": 0.13174182176589966,
      "learning_rate": 3.085714285714286e-06,
      "loss": 0.0004,
      "step": 65680
    },
    {
      "epoch": 1.8768571428571428,
      "grad_norm": 0.1608179360628128,
      "learning_rate": 3.0785714285714285e-06,
      "loss": 0.0021,
      "step": 65690
    },
    {
      "epoch": 1.8771428571428572,
      "grad_norm": 0.08073428273200989,
      "learning_rate": 3.0714285714285715e-06,
      "loss": 0.0004,
      "step": 65700
    },
    {
      "epoch": 1.8774285714285714,
      "grad_norm": 0.28325581550598145,
      "learning_rate": 3.0642857142857145e-06,
      "loss": 0.0011,
      "step": 65710
    },
    {
      "epoch": 1.8777142857142857,
      "grad_norm": 0.2552114427089691,
      "learning_rate": 3.0571428571428575e-06,
      "loss": 0.0008,
      "step": 65720
    },
    {
      "epoch": 1.8780000000000001,
      "grad_norm": 0.06061820685863495,
      "learning_rate": 3.05e-06,
      "loss": 0.0009,
      "step": 65730
    },
    {
      "epoch": 1.8782857142857143,
      "grad_norm": 0.14346455037593842,
      "learning_rate": 3.042857142857143e-06,
      "loss": 0.0005,
      "step": 65740
    },
    {
      "epoch": 1.8785714285714286,
      "grad_norm": 0.05114709213376045,
      "learning_rate": 3.035714285714286e-06,
      "loss": 0.0016,
      "step": 65750
    },
    {
      "epoch": 1.878857142857143,
      "grad_norm": 0.05205754563212395,
      "learning_rate": 3.028571428571429e-06,
      "loss": 0.0011,
      "step": 65760
    },
    {
      "epoch": 1.879142857142857,
      "grad_norm": 0.09685084968805313,
      "learning_rate": 3.0214285714285715e-06,
      "loss": 0.0005,
      "step": 65770
    },
    {
      "epoch": 1.8794285714285714,
      "grad_norm": 0.05562169849872589,
      "learning_rate": 3.014285714285714e-06,
      "loss": 0.0008,
      "step": 65780
    },
    {
      "epoch": 1.8797142857142857,
      "grad_norm": 0.04508056119084358,
      "learning_rate": 3.0071428571428575e-06,
      "loss": 0.0011,
      "step": 65790
    },
    {
      "epoch": 1.88,
      "grad_norm": 0.0,
      "learning_rate": 3e-06,
      "loss": 0.0014,
      "step": 65800
    },
    {
      "epoch": 1.8802857142857143,
      "grad_norm": 0.0399017296731472,
      "learning_rate": 2.992857142857143e-06,
      "loss": 0.0011,
      "step": 65810
    },
    {
      "epoch": 1.8805714285714286,
      "grad_norm": 0.03067162074148655,
      "learning_rate": 2.9857142857142856e-06,
      "loss": 0.0016,
      "step": 65820
    },
    {
      "epoch": 1.8808571428571428,
      "grad_norm": 0.0,
      "learning_rate": 2.978571428571429e-06,
      "loss": 0.0007,
      "step": 65830
    },
    {
      "epoch": 1.8811428571428572,
      "grad_norm": 0.04999959096312523,
      "learning_rate": 2.9714285714285716e-06,
      "loss": 0.0012,
      "step": 65840
    },
    {
      "epoch": 1.8814285714285715,
      "grad_norm": 0.0,
      "learning_rate": 2.9642857142857146e-06,
      "loss": 0.0009,
      "step": 65850
    },
    {
      "epoch": 1.8817142857142857,
      "grad_norm": 0.0,
      "learning_rate": 2.957142857142857e-06,
      "loss": 0.0018,
      "step": 65860
    },
    {
      "epoch": 1.8820000000000001,
      "grad_norm": 0.14781101047992706,
      "learning_rate": 2.95e-06,
      "loss": 0.0003,
      "step": 65870
    },
    {
      "epoch": 1.8822857142857143,
      "grad_norm": 0.0,
      "learning_rate": 2.942857142857143e-06,
      "loss": 0.0007,
      "step": 65880
    },
    {
      "epoch": 1.8825714285714286,
      "grad_norm": 0.0,
      "learning_rate": 2.9357142857142857e-06,
      "loss": 0.0,
      "step": 65890
    },
    {
      "epoch": 1.882857142857143,
      "grad_norm": 0.066808320581913,
      "learning_rate": 2.9285714285714287e-06,
      "loss": 0.0012,
      "step": 65900
    },
    {
      "epoch": 1.883142857142857,
      "grad_norm": 0.0,
      "learning_rate": 2.9214285714285717e-06,
      "loss": 0.0012,
      "step": 65910
    },
    {
      "epoch": 1.8834285714285715,
      "grad_norm": 0.0,
      "learning_rate": 2.9142857142857146e-06,
      "loss": 0.0009,
      "step": 65920
    },
    {
      "epoch": 1.8837142857142857,
      "grad_norm": 0.045537445694208145,
      "learning_rate": 2.907142857142857e-06,
      "loss": 0.0008,
      "step": 65930
    },
    {
      "epoch": 1.884,
      "grad_norm": 0.044808465987443924,
      "learning_rate": 2.9e-06,
      "loss": 0.0004,
      "step": 65940
    },
    {
      "epoch": 1.8842857142857143,
      "grad_norm": 0.0,
      "learning_rate": 2.892857142857143e-06,
      "loss": 0.0011,
      "step": 65950
    },
    {
      "epoch": 1.8845714285714286,
      "grad_norm": 0.0,
      "learning_rate": 2.8857142857142857e-06,
      "loss": 0.0011,
      "step": 65960
    },
    {
      "epoch": 1.8848571428571428,
      "grad_norm": 0.04260111227631569,
      "learning_rate": 2.8785714285714287e-06,
      "loss": 0.0007,
      "step": 65970
    },
    {
      "epoch": 1.8851428571428572,
      "grad_norm": 0.2764010727405548,
      "learning_rate": 2.8714285714285713e-06,
      "loss": 0.0017,
      "step": 65980
    },
    {
      "epoch": 1.8854285714285715,
      "grad_norm": 0.05031777545809746,
      "learning_rate": 2.8642857142857147e-06,
      "loss": 0.001,
      "step": 65990
    },
    {
      "epoch": 1.8857142857142857,
      "grad_norm": 0.05879167094826698,
      "learning_rate": 2.8571428571428573e-06,
      "loss": 0.0013,
      "step": 66000
    },
    {
      "epoch": 1.8860000000000001,
      "grad_norm": 0.0,
      "learning_rate": 2.8500000000000002e-06,
      "loss": 0.001,
      "step": 66010
    },
    {
      "epoch": 1.8862857142857141,
      "grad_norm": 0.24261002242565155,
      "learning_rate": 2.842857142857143e-06,
      "loss": 0.0011,
      "step": 66020
    },
    {
      "epoch": 1.8865714285714286,
      "grad_norm": 0.057939790189266205,
      "learning_rate": 2.835714285714286e-06,
      "loss": 0.0011,
      "step": 66030
    },
    {
      "epoch": 1.886857142857143,
      "grad_norm": 0.04573093354701996,
      "learning_rate": 2.8285714285714288e-06,
      "loss": 0.0006,
      "step": 66040
    },
    {
      "epoch": 1.887142857142857,
      "grad_norm": 0.06018928065896034,
      "learning_rate": 2.8214285714285713e-06,
      "loss": 0.0015,
      "step": 66050
    },
    {
      "epoch": 1.8874285714285715,
      "grad_norm": 0.0,
      "learning_rate": 2.8142857142857143e-06,
      "loss": 0.0008,
      "step": 66060
    },
    {
      "epoch": 1.8877142857142857,
      "grad_norm": 0.44684845209121704,
      "learning_rate": 2.8071428571428573e-06,
      "loss": 0.001,
      "step": 66070
    },
    {
      "epoch": 1.888,
      "grad_norm": 0.21012279391288757,
      "learning_rate": 2.8000000000000003e-06,
      "loss": 0.0009,
      "step": 66080
    },
    {
      "epoch": 1.8882857142857143,
      "grad_norm": 0.0,
      "learning_rate": 2.792857142857143e-06,
      "loss": 0.0005,
      "step": 66090
    },
    {
      "epoch": 1.8885714285714286,
      "grad_norm": 0.0,
      "learning_rate": 2.785714285714286e-06,
      "loss": 0.0015,
      "step": 66100
    },
    {
      "epoch": 1.8888571428571428,
      "grad_norm": 0.0,
      "learning_rate": 2.778571428571429e-06,
      "loss": 0.0014,
      "step": 66110
    },
    {
      "epoch": 1.8891428571428572,
      "grad_norm": 0.051699139177799225,
      "learning_rate": 2.771428571428572e-06,
      "loss": 0.001,
      "step": 66120
    },
    {
      "epoch": 1.8894285714285715,
      "grad_norm": 0.0,
      "learning_rate": 2.7642857142857144e-06,
      "loss": 0.0008,
      "step": 66130
    },
    {
      "epoch": 1.8897142857142857,
      "grad_norm": 0.0634152889251709,
      "learning_rate": 2.7571428571428574e-06,
      "loss": 0.0003,
      "step": 66140
    },
    {
      "epoch": 1.8900000000000001,
      "grad_norm": 0.2060306966304779,
      "learning_rate": 2.7500000000000004e-06,
      "loss": 0.0018,
      "step": 66150
    },
    {
      "epoch": 1.8902857142857141,
      "grad_norm": 0.0,
      "learning_rate": 2.742857142857143e-06,
      "loss": 0.0017,
      "step": 66160
    },
    {
      "epoch": 1.8905714285714286,
      "grad_norm": 0.07874351739883423,
      "learning_rate": 2.735714285714286e-06,
      "loss": 0.0006,
      "step": 66170
    },
    {
      "epoch": 1.890857142857143,
      "grad_norm": 0.06503584235906601,
      "learning_rate": 2.7285714285714285e-06,
      "loss": 0.0007,
      "step": 66180
    },
    {
      "epoch": 1.891142857142857,
      "grad_norm": 0.04409542679786682,
      "learning_rate": 2.7214285714285714e-06,
      "loss": 0.0007,
      "step": 66190
    },
    {
      "epoch": 1.8914285714285715,
      "grad_norm": 0.05336390808224678,
      "learning_rate": 2.7142857142857144e-06,
      "loss": 0.0007,
      "step": 66200
    },
    {
      "epoch": 1.8917142857142857,
      "grad_norm": 0.036039624363183975,
      "learning_rate": 2.7071428571428574e-06,
      "loss": 0.0005,
      "step": 66210
    },
    {
      "epoch": 1.892,
      "grad_norm": 0.0,
      "learning_rate": 2.7e-06,
      "loss": 0.0011,
      "step": 66220
    },
    {
      "epoch": 1.8922857142857143,
      "grad_norm": 0.03256838023662567,
      "learning_rate": 2.692857142857143e-06,
      "loss": 0.0004,
      "step": 66230
    },
    {
      "epoch": 1.8925714285714286,
      "grad_norm": 0.03517775237560272,
      "learning_rate": 2.685714285714286e-06,
      "loss": 0.0015,
      "step": 66240
    },
    {
      "epoch": 1.8928571428571428,
      "grad_norm": 0.0,
      "learning_rate": 2.6785714285714285e-06,
      "loss": 0.0021,
      "step": 66250
    },
    {
      "epoch": 1.8931428571428572,
      "grad_norm": 0.02968023717403412,
      "learning_rate": 2.6714285714285715e-06,
      "loss": 0.0005,
      "step": 66260
    },
    {
      "epoch": 1.8934285714285715,
      "grad_norm": 0.06346724927425385,
      "learning_rate": 2.6642857142857145e-06,
      "loss": 0.0011,
      "step": 66270
    },
    {
      "epoch": 1.8937142857142857,
      "grad_norm": 0.17734728753566742,
      "learning_rate": 2.6571428571428575e-06,
      "loss": 0.0005,
      "step": 66280
    },
    {
      "epoch": 1.8940000000000001,
      "grad_norm": 0.0,
      "learning_rate": 2.65e-06,
      "loss": 0.0013,
      "step": 66290
    },
    {
      "epoch": 1.8942857142857141,
      "grad_norm": 0.0,
      "learning_rate": 2.642857142857143e-06,
      "loss": 0.0009,
      "step": 66300
    },
    {
      "epoch": 1.8945714285714286,
      "grad_norm": 0.0,
      "learning_rate": 2.635714285714286e-06,
      "loss": 0.0016,
      "step": 66310
    },
    {
      "epoch": 1.894857142857143,
      "grad_norm": 0.05114538222551346,
      "learning_rate": 2.628571428571429e-06,
      "loss": 0.0005,
      "step": 66320
    },
    {
      "epoch": 1.895142857142857,
      "grad_norm": 0.30295997858047485,
      "learning_rate": 2.6214285714285716e-06,
      "loss": 0.0007,
      "step": 66330
    },
    {
      "epoch": 1.8954285714285715,
      "grad_norm": 0.044789012521505356,
      "learning_rate": 2.614285714285714e-06,
      "loss": 0.0017,
      "step": 66340
    },
    {
      "epoch": 1.8957142857142857,
      "grad_norm": 0.11246208101511002,
      "learning_rate": 2.607142857142857e-06,
      "loss": 0.0008,
      "step": 66350
    },
    {
      "epoch": 1.896,
      "grad_norm": 0.11600930988788605,
      "learning_rate": 2.6e-06,
      "loss": 0.0011,
      "step": 66360
    },
    {
      "epoch": 1.8962857142857144,
      "grad_norm": 0.07936921715736389,
      "learning_rate": 2.592857142857143e-06,
      "loss": 0.0009,
      "step": 66370
    },
    {
      "epoch": 1.8965714285714286,
      "grad_norm": 0.08139842003583908,
      "learning_rate": 2.5857142857142856e-06,
      "loss": 0.0006,
      "step": 66380
    },
    {
      "epoch": 1.8968571428571428,
      "grad_norm": 0.053550221025943756,
      "learning_rate": 2.5785714285714286e-06,
      "loss": 0.0012,
      "step": 66390
    },
    {
      "epoch": 1.8971428571428572,
      "grad_norm": 0.2155461311340332,
      "learning_rate": 2.5714285714285716e-06,
      "loss": 0.0007,
      "step": 66400
    },
    {
      "epoch": 1.8974285714285715,
      "grad_norm": 0.13817386329174042,
      "learning_rate": 2.5642857142857146e-06,
      "loss": 0.0017,
      "step": 66410
    },
    {
      "epoch": 1.8977142857142857,
      "grad_norm": 0.10008297115564346,
      "learning_rate": 2.557142857142857e-06,
      "loss": 0.0007,
      "step": 66420
    },
    {
      "epoch": 1.8980000000000001,
      "grad_norm": 0.049823321402072906,
      "learning_rate": 2.55e-06,
      "loss": 0.0014,
      "step": 66430
    },
    {
      "epoch": 1.8982857142857141,
      "grad_norm": 0.0,
      "learning_rate": 2.542857142857143e-06,
      "loss": 0.0018,
      "step": 66440
    },
    {
      "epoch": 1.8985714285714286,
      "grad_norm": 0.15320569276809692,
      "learning_rate": 2.5357142857142857e-06,
      "loss": 0.0003,
      "step": 66450
    },
    {
      "epoch": 1.898857142857143,
      "grad_norm": 0.08923626691102982,
      "learning_rate": 2.5285714285714287e-06,
      "loss": 0.0001,
      "step": 66460
    },
    {
      "epoch": 1.899142857142857,
      "grad_norm": 0.03635245934128761,
      "learning_rate": 2.5214285714285717e-06,
      "loss": 0.001,
      "step": 66470
    },
    {
      "epoch": 1.8994285714285715,
      "grad_norm": 0.04868674650788307,
      "learning_rate": 2.5142857142857147e-06,
      "loss": 0.0011,
      "step": 66480
    },
    {
      "epoch": 1.8997142857142857,
      "grad_norm": 0.2602110803127289,
      "learning_rate": 2.5071428571428572e-06,
      "loss": 0.0005,
      "step": 66490
    },
    {
      "epoch": 1.9,
      "grad_norm": 0.0,
      "learning_rate": 2.5e-06,
      "loss": 0.0019,
      "step": 66500
    },
    {
      "epoch": 1.9002857142857144,
      "grad_norm": 0.0,
      "learning_rate": 2.4928571428571428e-06,
      "loss": 0.0013,
      "step": 66510
    },
    {
      "epoch": 1.9005714285714286,
      "grad_norm": 0.17608053982257843,
      "learning_rate": 2.4857142857142858e-06,
      "loss": 0.0012,
      "step": 66520
    },
    {
      "epoch": 1.9008571428571428,
      "grad_norm": 0.0,
      "learning_rate": 2.4785714285714287e-06,
      "loss": 0.0008,
      "step": 66530
    },
    {
      "epoch": 1.9011428571428572,
      "grad_norm": 0.0857304260134697,
      "learning_rate": 2.4714285714285713e-06,
      "loss": 0.0013,
      "step": 66540
    },
    {
      "epoch": 1.9014285714285715,
      "grad_norm": 0.0,
      "learning_rate": 2.4642857142857143e-06,
      "loss": 0.0007,
      "step": 66550
    },
    {
      "epoch": 1.9017142857142857,
      "grad_norm": 0.3324872851371765,
      "learning_rate": 2.4571428571428573e-06,
      "loss": 0.0009,
      "step": 66560
    },
    {
      "epoch": 1.9020000000000001,
      "grad_norm": 0.08468887209892273,
      "learning_rate": 2.4500000000000003e-06,
      "loss": 0.0009,
      "step": 66570
    },
    {
      "epoch": 1.9022857142857141,
      "grad_norm": 0.10146880149841309,
      "learning_rate": 2.442857142857143e-06,
      "loss": 0.001,
      "step": 66580
    },
    {
      "epoch": 1.9025714285714286,
      "grad_norm": 0.0,
      "learning_rate": 2.435714285714286e-06,
      "loss": 0.0007,
      "step": 66590
    },
    {
      "epoch": 1.9028571428571428,
      "grad_norm": 0.0,
      "learning_rate": 2.428571428571429e-06,
      "loss": 0.0009,
      "step": 66600
    },
    {
      "epoch": 1.903142857142857,
      "grad_norm": 0.35640183091163635,
      "learning_rate": 2.4214285714285718e-06,
      "loss": 0.0009,
      "step": 66610
    },
    {
      "epoch": 1.9034285714285715,
      "grad_norm": 0.054921042174100876,
      "learning_rate": 2.4142857142857143e-06,
      "loss": 0.0019,
      "step": 66620
    },
    {
      "epoch": 1.9037142857142857,
      "grad_norm": 0.4551903307437897,
      "learning_rate": 2.407142857142857e-06,
      "loss": 0.0006,
      "step": 66630
    },
    {
      "epoch": 1.904,
      "grad_norm": 0.0,
      "learning_rate": 2.4000000000000003e-06,
      "loss": 0.001,
      "step": 66640
    },
    {
      "epoch": 1.9042857142857144,
      "grad_norm": 0.1316867172718048,
      "learning_rate": 2.392857142857143e-06,
      "loss": 0.0014,
      "step": 66650
    },
    {
      "epoch": 1.9045714285714286,
      "grad_norm": 0.0,
      "learning_rate": 2.385714285714286e-06,
      "loss": 0.0008,
      "step": 66660
    },
    {
      "epoch": 1.9048571428571428,
      "grad_norm": 0.42894718050956726,
      "learning_rate": 2.3785714285714284e-06,
      "loss": 0.0008,
      "step": 66670
    },
    {
      "epoch": 1.9051428571428572,
      "grad_norm": 0.0,
      "learning_rate": 2.371428571428572e-06,
      "loss": 0.0009,
      "step": 66680
    },
    {
      "epoch": 1.9054285714285715,
      "grad_norm": 0.05092976614832878,
      "learning_rate": 2.3642857142857144e-06,
      "loss": 0.0009,
      "step": 66690
    },
    {
      "epoch": 1.9057142857142857,
      "grad_norm": 0.0,
      "learning_rate": 2.3571428571428574e-06,
      "loss": 0.0022,
      "step": 66700
    },
    {
      "epoch": 1.9060000000000001,
      "grad_norm": 0.05332201346755028,
      "learning_rate": 2.35e-06,
      "loss": 0.0007,
      "step": 66710
    },
    {
      "epoch": 1.9062857142857141,
      "grad_norm": 0.08776271343231201,
      "learning_rate": 2.342857142857143e-06,
      "loss": 0.002,
      "step": 66720
    },
    {
      "epoch": 1.9065714285714286,
      "grad_norm": 0.0,
      "learning_rate": 2.335714285714286e-06,
      "loss": 0.0007,
      "step": 66730
    },
    {
      "epoch": 1.9068571428571428,
      "grad_norm": 0.10049492120742798,
      "learning_rate": 2.3285714285714285e-06,
      "loss": 0.001,
      "step": 66740
    },
    {
      "epoch": 1.907142857142857,
      "grad_norm": 0.049750350415706635,
      "learning_rate": 2.3214285714285715e-06,
      "loss": 0.0005,
      "step": 66750
    },
    {
      "epoch": 1.9074285714285715,
      "grad_norm": 0.0,
      "learning_rate": 2.3142857142857145e-06,
      "loss": 0.001,
      "step": 66760
    },
    {
      "epoch": 1.9077142857142857,
      "grad_norm": 0.30787187814712524,
      "learning_rate": 2.3071428571428574e-06,
      "loss": 0.0009,
      "step": 66770
    },
    {
      "epoch": 1.908,
      "grad_norm": 0.0,
      "learning_rate": 2.3e-06,
      "loss": 0.0003,
      "step": 66780
    },
    {
      "epoch": 1.9082857142857144,
      "grad_norm": 0.04129916802048683,
      "learning_rate": 2.292857142857143e-06,
      "loss": 0.0006,
      "step": 66790
    },
    {
      "epoch": 1.9085714285714286,
      "grad_norm": 0.0,
      "learning_rate": 2.285714285714286e-06,
      "loss": 0.0007,
      "step": 66800
    },
    {
      "epoch": 1.9088571428571428,
      "grad_norm": 0.17086023092269897,
      "learning_rate": 2.2785714285714285e-06,
      "loss": 0.0014,
      "step": 66810
    },
    {
      "epoch": 1.9091428571428573,
      "grad_norm": 0.05129339173436165,
      "learning_rate": 2.2714285714285715e-06,
      "loss": 0.0009,
      "step": 66820
    },
    {
      "epoch": 1.9094285714285715,
      "grad_norm": 0.0,
      "learning_rate": 2.264285714285714e-06,
      "loss": 0.001,
      "step": 66830
    },
    {
      "epoch": 1.9097142857142857,
      "grad_norm": 0.19080479443073273,
      "learning_rate": 2.2571428571428575e-06,
      "loss": 0.0012,
      "step": 66840
    },
    {
      "epoch": 1.9100000000000001,
      "grad_norm": 0.05629918351769447,
      "learning_rate": 2.25e-06,
      "loss": 0.0015,
      "step": 66850
    },
    {
      "epoch": 1.9102857142857141,
      "grad_norm": 0.2290741503238678,
      "learning_rate": 2.242857142857143e-06,
      "loss": 0.0011,
      "step": 66860
    },
    {
      "epoch": 1.9105714285714286,
      "grad_norm": 0.05900062993168831,
      "learning_rate": 2.2357142857142856e-06,
      "loss": 0.0011,
      "step": 66870
    },
    {
      "epoch": 1.9108571428571428,
      "grad_norm": 0.05157683417201042,
      "learning_rate": 2.228571428571429e-06,
      "loss": 0.0011,
      "step": 66880
    },
    {
      "epoch": 1.911142857142857,
      "grad_norm": 0.04423944652080536,
      "learning_rate": 2.2214285714285716e-06,
      "loss": 0.0007,
      "step": 66890
    },
    {
      "epoch": 1.9114285714285715,
      "grad_norm": 0.044673413038253784,
      "learning_rate": 2.214285714285714e-06,
      "loss": 0.001,
      "step": 66900
    },
    {
      "epoch": 1.9117142857142857,
      "grad_norm": 0.04671642556786537,
      "learning_rate": 2.207142857142857e-06,
      "loss": 0.0007,
      "step": 66910
    },
    {
      "epoch": 1.912,
      "grad_norm": 0.05947699397802353,
      "learning_rate": 2.2e-06,
      "loss": 0.0012,
      "step": 66920
    },
    {
      "epoch": 1.9122857142857144,
      "grad_norm": 0.04446740821003914,
      "learning_rate": 2.192857142857143e-06,
      "loss": 0.0006,
      "step": 66930
    },
    {
      "epoch": 1.9125714285714286,
      "grad_norm": 0.04172052443027496,
      "learning_rate": 2.1857142857142857e-06,
      "loss": 0.001,
      "step": 66940
    },
    {
      "epoch": 1.9128571428571428,
      "grad_norm": 0.0731201022863388,
      "learning_rate": 2.1785714285714286e-06,
      "loss": 0.0015,
      "step": 66950
    },
    {
      "epoch": 1.9131428571428573,
      "grad_norm": 0.06485993415117264,
      "learning_rate": 2.1714285714285716e-06,
      "loss": 0.0013,
      "step": 66960
    },
    {
      "epoch": 1.9134285714285715,
      "grad_norm": 0.0,
      "learning_rate": 2.1642857142857146e-06,
      "loss": 0.0003,
      "step": 66970
    },
    {
      "epoch": 1.9137142857142857,
      "grad_norm": 0.06855956465005875,
      "learning_rate": 2.157142857142857e-06,
      "loss": 0.0004,
      "step": 66980
    },
    {
      "epoch": 1.9140000000000001,
      "grad_norm": 0.07810067385435104,
      "learning_rate": 2.1499999999999997e-06,
      "loss": 0.0006,
      "step": 66990
    },
    {
      "epoch": 1.9142857142857141,
      "grad_norm": 0.47126835584640503,
      "learning_rate": 2.142857142857143e-06,
      "loss": 0.0022,
      "step": 67000
    },
    {
      "epoch": 1.9145714285714286,
      "grad_norm": 0.0,
      "learning_rate": 2.1357142857142857e-06,
      "loss": 0.0011,
      "step": 67010
    },
    {
      "epoch": 1.9148571428571428,
      "grad_norm": 0.0457284115254879,
      "learning_rate": 2.1285714285714287e-06,
      "loss": 0.0005,
      "step": 67020
    },
    {
      "epoch": 1.915142857142857,
      "grad_norm": 0.06697764992713928,
      "learning_rate": 2.1214285714285713e-06,
      "loss": 0.0014,
      "step": 67030
    },
    {
      "epoch": 1.9154285714285715,
      "grad_norm": 0.046556565910577774,
      "learning_rate": 2.1142857142857147e-06,
      "loss": 0.0011,
      "step": 67040
    },
    {
      "epoch": 1.9157142857142857,
      "grad_norm": 0.0,
      "learning_rate": 2.1071428571428572e-06,
      "loss": 0.0013,
      "step": 67050
    },
    {
      "epoch": 1.916,
      "grad_norm": 0.09205295890569687,
      "learning_rate": 2.1000000000000002e-06,
      "loss": 0.0005,
      "step": 67060
    },
    {
      "epoch": 1.9162857142857144,
      "grad_norm": 0.048531755805015564,
      "learning_rate": 2.0928571428571428e-06,
      "loss": 0.002,
      "step": 67070
    },
    {
      "epoch": 1.9165714285714286,
      "grad_norm": 0.16976940631866455,
      "learning_rate": 2.0857142857142858e-06,
      "loss": 0.0006,
      "step": 67080
    },
    {
      "epoch": 1.9168571428571428,
      "grad_norm": 0.04303305596113205,
      "learning_rate": 2.0785714285714288e-06,
      "loss": 0.001,
      "step": 67090
    },
    {
      "epoch": 1.9171428571428573,
      "grad_norm": 0.06298063695430756,
      "learning_rate": 2.0714285714285713e-06,
      "loss": 0.0021,
      "step": 67100
    },
    {
      "epoch": 1.9174285714285715,
      "grad_norm": 0.0,
      "learning_rate": 2.0642857142857143e-06,
      "loss": 0.0006,
      "step": 67110
    },
    {
      "epoch": 1.9177142857142857,
      "grad_norm": 0.05377789959311485,
      "learning_rate": 2.0571428571428573e-06,
      "loss": 0.0006,
      "step": 67120
    },
    {
      "epoch": 1.9180000000000001,
      "grad_norm": 0.04160688444972038,
      "learning_rate": 2.0500000000000003e-06,
      "loss": 0.0007,
      "step": 67130
    },
    {
      "epoch": 1.9182857142857141,
      "grad_norm": 0.0,
      "learning_rate": 2.042857142857143e-06,
      "loss": 0.0017,
      "step": 67140
    },
    {
      "epoch": 1.9185714285714286,
      "grad_norm": 0.0,
      "learning_rate": 2.035714285714286e-06,
      "loss": 0.0005,
      "step": 67150
    },
    {
      "epoch": 1.9188571428571428,
      "grad_norm": 0.09814140945672989,
      "learning_rate": 2.028571428571429e-06,
      "loss": 0.0003,
      "step": 67160
    },
    {
      "epoch": 1.919142857142857,
      "grad_norm": 0.0,
      "learning_rate": 2.021428571428572e-06,
      "loss": 0.0013,
      "step": 67170
    },
    {
      "epoch": 1.9194285714285715,
      "grad_norm": 0.04672062397003174,
      "learning_rate": 2.0142857142857144e-06,
      "loss": 0.0013,
      "step": 67180
    },
    {
      "epoch": 1.9197142857142857,
      "grad_norm": 0.047514092177152634,
      "learning_rate": 2.007142857142857e-06,
      "loss": 0.0014,
      "step": 67190
    },
    {
      "epoch": 1.92,
      "grad_norm": 0.0,
      "learning_rate": 2.0000000000000003e-06,
      "loss": 0.0008,
      "step": 67200
    },
    {
      "epoch": 1.9202857142857144,
      "grad_norm": 0.09218800812959671,
      "learning_rate": 1.992857142857143e-06,
      "loss": 0.0006,
      "step": 67210
    },
    {
      "epoch": 1.9205714285714286,
      "grad_norm": 0.052481312304735184,
      "learning_rate": 1.985714285714286e-06,
      "loss": 0.0007,
      "step": 67220
    },
    {
      "epoch": 1.9208571428571428,
      "grad_norm": 0.0,
      "learning_rate": 1.9785714285714284e-06,
      "loss": 0.0005,
      "step": 67230
    },
    {
      "epoch": 1.9211428571428573,
      "grad_norm": 0.11916369199752808,
      "learning_rate": 1.9714285714285714e-06,
      "loss": 0.0016,
      "step": 67240
    },
    {
      "epoch": 1.9214285714285713,
      "grad_norm": 0.04282664880156517,
      "learning_rate": 1.9642857142857144e-06,
      "loss": 0.0013,
      "step": 67250
    },
    {
      "epoch": 1.9217142857142857,
      "grad_norm": 0.056441426277160645,
      "learning_rate": 1.9571428571428574e-06,
      "loss": 0.0011,
      "step": 67260
    },
    {
      "epoch": 1.9220000000000002,
      "grad_norm": 0.09191323071718216,
      "learning_rate": 1.95e-06,
      "loss": 0.0019,
      "step": 67270
    },
    {
      "epoch": 1.9222857142857142,
      "grad_norm": 0.044447772204875946,
      "learning_rate": 1.942857142857143e-06,
      "loss": 0.001,
      "step": 67280
    },
    {
      "epoch": 1.9225714285714286,
      "grad_norm": 0.29309213161468506,
      "learning_rate": 1.935714285714286e-06,
      "loss": 0.0006,
      "step": 67290
    },
    {
      "epoch": 1.9228571428571428,
      "grad_norm": 0.09397861361503601,
      "learning_rate": 1.9285714285714285e-06,
      "loss": 0.0009,
      "step": 67300
    },
    {
      "epoch": 1.923142857142857,
      "grad_norm": 0.20203949511051178,
      "learning_rate": 1.9214285714285715e-06,
      "loss": 0.001,
      "step": 67310
    },
    {
      "epoch": 1.9234285714285715,
      "grad_norm": 0.1957228034734726,
      "learning_rate": 1.9142857142857145e-06,
      "loss": 0.0011,
      "step": 67320
    },
    {
      "epoch": 1.9237142857142857,
      "grad_norm": 0.05248868837952614,
      "learning_rate": 1.9071428571428572e-06,
      "loss": 0.001,
      "step": 67330
    },
    {
      "epoch": 1.924,
      "grad_norm": 0.09547284990549088,
      "learning_rate": 1.9e-06,
      "loss": 0.001,
      "step": 67340
    },
    {
      "epoch": 1.9242857142857144,
      "grad_norm": 0.06014126539230347,
      "learning_rate": 1.892857142857143e-06,
      "loss": 0.0015,
      "step": 67350
    },
    {
      "epoch": 1.9245714285714286,
      "grad_norm": 0.0,
      "learning_rate": 1.8857142857142858e-06,
      "loss": 0.0007,
      "step": 67360
    },
    {
      "epoch": 1.9248571428571428,
      "grad_norm": 0.1474980115890503,
      "learning_rate": 1.8785714285714286e-06,
      "loss": 0.0008,
      "step": 67370
    },
    {
      "epoch": 1.9251428571428573,
      "grad_norm": 0.04479096457362175,
      "learning_rate": 1.8714285714285715e-06,
      "loss": 0.0007,
      "step": 67380
    },
    {
      "epoch": 1.9254285714285713,
      "grad_norm": 0.04235242307186127,
      "learning_rate": 1.8642857142857143e-06,
      "loss": 0.0005,
      "step": 67390
    },
    {
      "epoch": 1.9257142857142857,
      "grad_norm": 0.04149862378835678,
      "learning_rate": 1.8571428571428573e-06,
      "loss": 0.0011,
      "step": 67400
    },
    {
      "epoch": 1.9260000000000002,
      "grad_norm": 0.06292562186717987,
      "learning_rate": 1.85e-06,
      "loss": 0.0008,
      "step": 67410
    },
    {
      "epoch": 1.9262857142857142,
      "grad_norm": 0.06341627985239029,
      "learning_rate": 1.842857142857143e-06,
      "loss": 0.001,
      "step": 67420
    },
    {
      "epoch": 1.9265714285714286,
      "grad_norm": 0.0,
      "learning_rate": 1.8357142857142858e-06,
      "loss": 0.0012,
      "step": 67430
    },
    {
      "epoch": 1.9268571428571428,
      "grad_norm": 0.06592877954244614,
      "learning_rate": 1.8285714285714288e-06,
      "loss": 0.0015,
      "step": 67440
    },
    {
      "epoch": 1.927142857142857,
      "grad_norm": 0.20356932282447815,
      "learning_rate": 1.8214285714285716e-06,
      "loss": 0.0022,
      "step": 67450
    },
    {
      "epoch": 1.9274285714285715,
      "grad_norm": 0.0979958176612854,
      "learning_rate": 1.8142857142857142e-06,
      "loss": 0.0009,
      "step": 67460
    },
    {
      "epoch": 1.9277142857142857,
      "grad_norm": 0.04276909679174423,
      "learning_rate": 1.8071428571428571e-06,
      "loss": 0.0008,
      "step": 67470
    },
    {
      "epoch": 1.928,
      "grad_norm": 0.0,
      "learning_rate": 1.8e-06,
      "loss": 0.0009,
      "step": 67480
    },
    {
      "epoch": 1.9282857142857144,
      "grad_norm": 0.044996775686740875,
      "learning_rate": 1.792857142857143e-06,
      "loss": 0.001,
      "step": 67490
    },
    {
      "epoch": 1.9285714285714286,
      "grad_norm": 0.04330293834209442,
      "learning_rate": 1.7857142857142857e-06,
      "loss": 0.0008,
      "step": 67500
    },
    {
      "epoch": 1.9288571428571428,
      "grad_norm": 0.054073963314294815,
      "learning_rate": 1.7785714285714287e-06,
      "loss": 0.001,
      "step": 67510
    },
    {
      "epoch": 1.9291428571428573,
      "grad_norm": 0.048489805310964584,
      "learning_rate": 1.7714285714285714e-06,
      "loss": 0.0011,
      "step": 67520
    },
    {
      "epoch": 1.9294285714285713,
      "grad_norm": 0.04759638011455536,
      "learning_rate": 1.7642857142857144e-06,
      "loss": 0.0005,
      "step": 67530
    },
    {
      "epoch": 1.9297142857142857,
      "grad_norm": 0.08517894148826599,
      "learning_rate": 1.7571428571428572e-06,
      "loss": 0.0009,
      "step": 67540
    },
    {
      "epoch": 1.9300000000000002,
      "grad_norm": 0.0,
      "learning_rate": 1.7500000000000002e-06,
      "loss": 0.0012,
      "step": 67550
    },
    {
      "epoch": 1.9302857142857142,
      "grad_norm": 0.04923606291413307,
      "learning_rate": 1.742857142857143e-06,
      "loss": 0.0004,
      "step": 67560
    },
    {
      "epoch": 1.9305714285714286,
      "grad_norm": 0.10611007362604141,
      "learning_rate": 1.7357142857142857e-06,
      "loss": 0.0012,
      "step": 67570
    },
    {
      "epoch": 1.9308571428571428,
      "grad_norm": 0.04967690259218216,
      "learning_rate": 1.7285714285714287e-06,
      "loss": 0.0011,
      "step": 67580
    },
    {
      "epoch": 1.931142857142857,
      "grad_norm": 0.09945830702781677,
      "learning_rate": 1.7214285714285715e-06,
      "loss": 0.0015,
      "step": 67590
    },
    {
      "epoch": 1.9314285714285715,
      "grad_norm": 0.0,
      "learning_rate": 1.7142857142857145e-06,
      "loss": 0.0006,
      "step": 67600
    },
    {
      "epoch": 1.9317142857142857,
      "grad_norm": 0.07143320143222809,
      "learning_rate": 1.7071428571428573e-06,
      "loss": 0.0011,
      "step": 67610
    },
    {
      "epoch": 1.932,
      "grad_norm": 0.11506206542253494,
      "learning_rate": 1.7000000000000002e-06,
      "loss": 0.0006,
      "step": 67620
    },
    {
      "epoch": 1.9322857142857144,
      "grad_norm": 0.0,
      "learning_rate": 1.6928571428571428e-06,
      "loss": 0.0016,
      "step": 67630
    },
    {
      "epoch": 1.9325714285714286,
      "grad_norm": 0.06783062219619751,
      "learning_rate": 1.685714285714286e-06,
      "loss": 0.0015,
      "step": 67640
    },
    {
      "epoch": 1.9328571428571428,
      "grad_norm": 0.31084755063056946,
      "learning_rate": 1.6785714285714286e-06,
      "loss": 0.0007,
      "step": 67650
    },
    {
      "epoch": 1.9331428571428573,
      "grad_norm": 0.0,
      "learning_rate": 1.6714285714285713e-06,
      "loss": 0.0007,
      "step": 67660
    },
    {
      "epoch": 1.9334285714285713,
      "grad_norm": 0.08750192075967789,
      "learning_rate": 1.6642857142857143e-06,
      "loss": 0.0019,
      "step": 67670
    },
    {
      "epoch": 1.9337142857142857,
      "grad_norm": 0.04106941074132919,
      "learning_rate": 1.657142857142857e-06,
      "loss": 0.0011,
      "step": 67680
    },
    {
      "epoch": 1.9340000000000002,
      "grad_norm": 0.038503628224134445,
      "learning_rate": 1.65e-06,
      "loss": 0.0014,
      "step": 67690
    },
    {
      "epoch": 1.9342857142857142,
      "grad_norm": 0.05101323872804642,
      "learning_rate": 1.6428571428571429e-06,
      "loss": 0.0009,
      "step": 67700
    },
    {
      "epoch": 1.9345714285714286,
      "grad_norm": 0.04806649684906006,
      "learning_rate": 1.6357142857142858e-06,
      "loss": 0.0007,
      "step": 67710
    },
    {
      "epoch": 1.9348571428571428,
      "grad_norm": 0.04866952449083328,
      "learning_rate": 1.6285714285714286e-06,
      "loss": 0.0009,
      "step": 67720
    },
    {
      "epoch": 1.935142857142857,
      "grad_norm": 0.04097224399447441,
      "learning_rate": 1.6214285714285716e-06,
      "loss": 0.0007,
      "step": 67730
    },
    {
      "epoch": 1.9354285714285715,
      "grad_norm": 0.13057613372802734,
      "learning_rate": 1.6142857142857144e-06,
      "loss": 0.002,
      "step": 67740
    },
    {
      "epoch": 1.9357142857142857,
      "grad_norm": 0.0,
      "learning_rate": 1.6071428571428572e-06,
      "loss": 0.0002,
      "step": 67750
    },
    {
      "epoch": 1.936,
      "grad_norm": 0.0,
      "learning_rate": 1.6000000000000001e-06,
      "loss": 0.0011,
      "step": 67760
    },
    {
      "epoch": 1.9362857142857144,
      "grad_norm": 0.09313768893480301,
      "learning_rate": 1.592857142857143e-06,
      "loss": 0.0012,
      "step": 67770
    },
    {
      "epoch": 1.9365714285714286,
      "grad_norm": 0.16734738647937775,
      "learning_rate": 1.585714285714286e-06,
      "loss": 0.0007,
      "step": 67780
    },
    {
      "epoch": 1.9368571428571428,
      "grad_norm": 0.05821662023663521,
      "learning_rate": 1.5785714285714285e-06,
      "loss": 0.0007,
      "step": 67790
    },
    {
      "epoch": 1.9371428571428573,
      "grad_norm": 0.04286133125424385,
      "learning_rate": 1.5714285714285717e-06,
      "loss": 0.0007,
      "step": 67800
    },
    {
      "epoch": 1.9374285714285713,
      "grad_norm": 0.2825974225997925,
      "learning_rate": 1.5642857142857142e-06,
      "loss": 0.0024,
      "step": 67810
    },
    {
      "epoch": 1.9377142857142857,
      "grad_norm": 0.0,
      "learning_rate": 1.5571428571428572e-06,
      "loss": 0.0009,
      "step": 67820
    },
    {
      "epoch": 1.938,
      "grad_norm": 0.0,
      "learning_rate": 1.55e-06,
      "loss": 0.0011,
      "step": 67830
    },
    {
      "epoch": 1.9382857142857142,
      "grad_norm": 0.0,
      "learning_rate": 1.542857142857143e-06,
      "loss": 0.0013,
      "step": 67840
    },
    {
      "epoch": 1.9385714285714286,
      "grad_norm": 0.05285898968577385,
      "learning_rate": 1.5357142857142857e-06,
      "loss": 0.0002,
      "step": 67850
    },
    {
      "epoch": 1.9388571428571428,
      "grad_norm": 0.15981896221637726,
      "learning_rate": 1.5285714285714287e-06,
      "loss": 0.0007,
      "step": 67860
    },
    {
      "epoch": 1.939142857142857,
      "grad_norm": 0.0,
      "learning_rate": 1.5214285714285715e-06,
      "loss": 0.0008,
      "step": 67870
    },
    {
      "epoch": 1.9394285714285715,
      "grad_norm": 0.0,
      "learning_rate": 1.5142857142857145e-06,
      "loss": 0.0,
      "step": 67880
    },
    {
      "epoch": 1.9397142857142857,
      "grad_norm": 0.0,
      "learning_rate": 1.507142857142857e-06,
      "loss": 0.0011,
      "step": 67890
    },
    {
      "epoch": 1.94,
      "grad_norm": 0.0,
      "learning_rate": 1.5e-06,
      "loss": 0.0017,
      "step": 67900
    },
    {
      "epoch": 1.9402857142857144,
      "grad_norm": 0.049632567912340164,
      "learning_rate": 1.4928571428571428e-06,
      "loss": 0.0013,
      "step": 67910
    },
    {
      "epoch": 1.9405714285714286,
      "grad_norm": 0.0,
      "learning_rate": 1.4857142857142858e-06,
      "loss": 0.0009,
      "step": 67920
    },
    {
      "epoch": 1.9408571428571428,
      "grad_norm": 0.044613804668188095,
      "learning_rate": 1.4785714285714286e-06,
      "loss": 0.0017,
      "step": 67930
    },
    {
      "epoch": 1.9411428571428573,
      "grad_norm": 0.2556475102901459,
      "learning_rate": 1.4714285714285716e-06,
      "loss": 0.0005,
      "step": 67940
    },
    {
      "epoch": 1.9414285714285713,
      "grad_norm": 0.11045394092798233,
      "learning_rate": 1.4642857142857143e-06,
      "loss": 0.0016,
      "step": 67950
    },
    {
      "epoch": 1.9417142857142857,
      "grad_norm": 0.0,
      "learning_rate": 1.4571428571428573e-06,
      "loss": 0.0013,
      "step": 67960
    },
    {
      "epoch": 1.942,
      "grad_norm": 0.04268117621541023,
      "learning_rate": 1.45e-06,
      "loss": 0.001,
      "step": 67970
    },
    {
      "epoch": 1.9422857142857142,
      "grad_norm": 0.0,
      "learning_rate": 1.4428571428571429e-06,
      "loss": 0.002,
      "step": 67980
    },
    {
      "epoch": 1.9425714285714286,
      "grad_norm": 0.12702783942222595,
      "learning_rate": 1.4357142857142856e-06,
      "loss": 0.0009,
      "step": 67990
    },
    {
      "epoch": 1.9428571428571428,
      "grad_norm": 0.040978141129016876,
      "learning_rate": 1.4285714285714286e-06,
      "loss": 0.001,
      "step": 68000
    },
    {
      "epoch": 1.943142857142857,
      "grad_norm": 0.03997320681810379,
      "learning_rate": 1.4214285714285714e-06,
      "loss": 0.0002,
      "step": 68010
    },
    {
      "epoch": 1.9434285714285715,
      "grad_norm": 0.06672775000333786,
      "learning_rate": 1.4142857142857144e-06,
      "loss": 0.0014,
      "step": 68020
    },
    {
      "epoch": 1.9437142857142857,
      "grad_norm": 0.0,
      "learning_rate": 1.4071428571428572e-06,
      "loss": 0.0006,
      "step": 68030
    },
    {
      "epoch": 1.944,
      "grad_norm": 0.10093985497951508,
      "learning_rate": 1.4000000000000001e-06,
      "loss": 0.001,
      "step": 68040
    },
    {
      "epoch": 1.9442857142857144,
      "grad_norm": 0.049559470266103745,
      "learning_rate": 1.392857142857143e-06,
      "loss": 0.0003,
      "step": 68050
    },
    {
      "epoch": 1.9445714285714286,
      "grad_norm": 0.04149391129612923,
      "learning_rate": 1.385714285714286e-06,
      "loss": 0.0002,
      "step": 68060
    },
    {
      "epoch": 1.9448571428571428,
      "grad_norm": 0.04878874868154526,
      "learning_rate": 1.3785714285714287e-06,
      "loss": 0.0011,
      "step": 68070
    },
    {
      "epoch": 1.9451428571428573,
      "grad_norm": 0.07527722418308258,
      "learning_rate": 1.3714285714285715e-06,
      "loss": 0.0003,
      "step": 68080
    },
    {
      "epoch": 1.9454285714285713,
      "grad_norm": 0.0,
      "learning_rate": 1.3642857142857142e-06,
      "loss": 0.0015,
      "step": 68090
    },
    {
      "epoch": 1.9457142857142857,
      "grad_norm": 0.2176738679409027,
      "learning_rate": 1.3571428571428572e-06,
      "loss": 0.0013,
      "step": 68100
    },
    {
      "epoch": 1.946,
      "grad_norm": 0.06288401782512665,
      "learning_rate": 1.35e-06,
      "loss": 0.0011,
      "step": 68110
    },
    {
      "epoch": 1.9462857142857142,
      "grad_norm": 0.1622154861688614,
      "learning_rate": 1.342857142857143e-06,
      "loss": 0.0007,
      "step": 68120
    },
    {
      "epoch": 1.9465714285714286,
      "grad_norm": 0.041255176067352295,
      "learning_rate": 1.3357142857142858e-06,
      "loss": 0.0005,
      "step": 68130
    },
    {
      "epoch": 1.9468571428571428,
      "grad_norm": 0.24704736471176147,
      "learning_rate": 1.3285714285714287e-06,
      "loss": 0.0018,
      "step": 68140
    },
    {
      "epoch": 1.947142857142857,
      "grad_norm": 0.14081282913684845,
      "learning_rate": 1.3214285714285715e-06,
      "loss": 0.0008,
      "step": 68150
    },
    {
      "epoch": 1.9474285714285715,
      "grad_norm": 0.0,
      "learning_rate": 1.3142857142857145e-06,
      "loss": 0.0008,
      "step": 68160
    },
    {
      "epoch": 1.9477142857142857,
      "grad_norm": 0.0628093034029007,
      "learning_rate": 1.307142857142857e-06,
      "loss": 0.0008,
      "step": 68170
    },
    {
      "epoch": 1.948,
      "grad_norm": 0.058497410267591476,
      "learning_rate": 1.3e-06,
      "loss": 0.0011,
      "step": 68180
    },
    {
      "epoch": 1.9482857142857144,
      "grad_norm": 0.0,
      "learning_rate": 1.2928571428571428e-06,
      "loss": 0.0004,
      "step": 68190
    },
    {
      "epoch": 1.9485714285714286,
      "grad_norm": 0.04811669886112213,
      "learning_rate": 1.2857142857142858e-06,
      "loss": 0.0014,
      "step": 68200
    },
    {
      "epoch": 1.9488571428571428,
      "grad_norm": 0.13719458878040314,
      "learning_rate": 1.2785714285714286e-06,
      "loss": 0.0013,
      "step": 68210
    },
    {
      "epoch": 1.9491428571428573,
      "grad_norm": 0.12392941862344742,
      "learning_rate": 1.2714285714285716e-06,
      "loss": 0.0015,
      "step": 68220
    },
    {
      "epoch": 1.9494285714285713,
      "grad_norm": 0.0,
      "learning_rate": 1.2642857142857143e-06,
      "loss": 0.0027,
      "step": 68230
    },
    {
      "epoch": 1.9497142857142857,
      "grad_norm": 0.046888720244169235,
      "learning_rate": 1.2571428571428573e-06,
      "loss": 0.0012,
      "step": 68240
    },
    {
      "epoch": 1.95,
      "grad_norm": 0.07878443598747253,
      "learning_rate": 1.25e-06,
      "loss": 0.002,
      "step": 68250
    },
    {
      "epoch": 1.9502857142857142,
      "grad_norm": 0.0,
      "learning_rate": 1.2428571428571429e-06,
      "loss": 0.0006,
      "step": 68260
    },
    {
      "epoch": 1.9505714285714286,
      "grad_norm": 0.051774270832538605,
      "learning_rate": 1.2357142857142857e-06,
      "loss": 0.0019,
      "step": 68270
    },
    {
      "epoch": 1.9508571428571428,
      "grad_norm": 0.03618328645825386,
      "learning_rate": 1.2285714285714286e-06,
      "loss": 0.0012,
      "step": 68280
    },
    {
      "epoch": 1.951142857142857,
      "grad_norm": 0.0,
      "learning_rate": 1.2214285714285714e-06,
      "loss": 0.0005,
      "step": 68290
    },
    {
      "epoch": 1.9514285714285715,
      "grad_norm": 0.08112726360559464,
      "learning_rate": 1.2142857142857144e-06,
      "loss": 0.0005,
      "step": 68300
    },
    {
      "epoch": 1.9517142857142857,
      "grad_norm": 0.05906013771891594,
      "learning_rate": 1.2071428571428572e-06,
      "loss": 0.002,
      "step": 68310
    },
    {
      "epoch": 1.952,
      "grad_norm": 0.06653618067502975,
      "learning_rate": 1.2000000000000002e-06,
      "loss": 0.001,
      "step": 68320
    },
    {
      "epoch": 1.9522857142857144,
      "grad_norm": 0.0,
      "learning_rate": 1.192857142857143e-06,
      "loss": 0.0015,
      "step": 68330
    },
    {
      "epoch": 1.9525714285714286,
      "grad_norm": 0.21287816762924194,
      "learning_rate": 1.185714285714286e-06,
      "loss": 0.0007,
      "step": 68340
    },
    {
      "epoch": 1.9528571428571428,
      "grad_norm": 0.046286795288324356,
      "learning_rate": 1.1785714285714287e-06,
      "loss": 0.0007,
      "step": 68350
    },
    {
      "epoch": 1.9531428571428573,
      "grad_norm": 0.05011877045035362,
      "learning_rate": 1.1714285714285715e-06,
      "loss": 0.001,
      "step": 68360
    },
    {
      "epoch": 1.9534285714285713,
      "grad_norm": 0.3804699182510376,
      "learning_rate": 1.1642857142857142e-06,
      "loss": 0.0012,
      "step": 68370
    },
    {
      "epoch": 1.9537142857142857,
      "grad_norm": 0.049481384456157684,
      "learning_rate": 1.1571428571428572e-06,
      "loss": 0.0008,
      "step": 68380
    },
    {
      "epoch": 1.954,
      "grad_norm": 0.20778216421604156,
      "learning_rate": 1.15e-06,
      "loss": 0.0003,
      "step": 68390
    },
    {
      "epoch": 1.9542857142857142,
      "grad_norm": 0.27835825085639954,
      "learning_rate": 1.142857142857143e-06,
      "loss": 0.0014,
      "step": 68400
    },
    {
      "epoch": 1.9545714285714286,
      "grad_norm": 0.09249871969223022,
      "learning_rate": 1.1357142857142858e-06,
      "loss": 0.001,
      "step": 68410
    },
    {
      "epoch": 1.9548571428571428,
      "grad_norm": 0.09837785363197327,
      "learning_rate": 1.1285714285714287e-06,
      "loss": 0.0009,
      "step": 68420
    },
    {
      "epoch": 1.955142857142857,
      "grad_norm": 0.029936842620372772,
      "learning_rate": 1.1214285714285715e-06,
      "loss": 0.0017,
      "step": 68430
    },
    {
      "epoch": 1.9554285714285715,
      "grad_norm": 0.0,
      "learning_rate": 1.1142857142857145e-06,
      "loss": 0.0009,
      "step": 68440
    },
    {
      "epoch": 1.9557142857142857,
      "grad_norm": 0.08442258089780807,
      "learning_rate": 1.107142857142857e-06,
      "loss": 0.0008,
      "step": 68450
    },
    {
      "epoch": 1.956,
      "grad_norm": 0.15856517851352692,
      "learning_rate": 1.1e-06,
      "loss": 0.0008,
      "step": 68460
    },
    {
      "epoch": 1.9562857142857144,
      "grad_norm": 0.0,
      "learning_rate": 1.0928571428571428e-06,
      "loss": 0.0017,
      "step": 68470
    },
    {
      "epoch": 1.9565714285714284,
      "grad_norm": 0.0539487823843956,
      "learning_rate": 1.0857142857142858e-06,
      "loss": 0.0007,
      "step": 68480
    },
    {
      "epoch": 1.9568571428571429,
      "grad_norm": 0.0,
      "learning_rate": 1.0785714285714286e-06,
      "loss": 0.0004,
      "step": 68490
    },
    {
      "epoch": 1.9571428571428573,
      "grad_norm": 0.188439279794693,
      "learning_rate": 1.0714285714285716e-06,
      "loss": 0.0011,
      "step": 68500
    },
    {
      "epoch": 1.9574285714285713,
      "grad_norm": 0.2156352698802948,
      "learning_rate": 1.0642857142857144e-06,
      "loss": 0.0009,
      "step": 68510
    },
    {
      "epoch": 1.9577142857142857,
      "grad_norm": 0.0,
      "learning_rate": 1.0571428571428573e-06,
      "loss": 0.0018,
      "step": 68520
    },
    {
      "epoch": 1.958,
      "grad_norm": 0.05309175327420235,
      "learning_rate": 1.0500000000000001e-06,
      "loss": 0.001,
      "step": 68530
    },
    {
      "epoch": 1.9582857142857142,
      "grad_norm": 0.16049914062023163,
      "learning_rate": 1.0428571428571429e-06,
      "loss": 0.0005,
      "step": 68540
    },
    {
      "epoch": 1.9585714285714286,
      "grad_norm": 0.17817430198192596,
      "learning_rate": 1.0357142857142857e-06,
      "loss": 0.0001,
      "step": 68550
    },
    {
      "epoch": 1.9588571428571429,
      "grad_norm": 0.05298898369073868,
      "learning_rate": 1.0285714285714286e-06,
      "loss": 0.0019,
      "step": 68560
    },
    {
      "epoch": 1.959142857142857,
      "grad_norm": 0.0,
      "learning_rate": 1.0214285714285714e-06,
      "loss": 0.0013,
      "step": 68570
    },
    {
      "epoch": 1.9594285714285715,
      "grad_norm": 0.21520954370498657,
      "learning_rate": 1.0142857142857144e-06,
      "loss": 0.0015,
      "step": 68580
    },
    {
      "epoch": 1.9597142857142857,
      "grad_norm": 0.0629047229886055,
      "learning_rate": 1.0071428571428572e-06,
      "loss": 0.0007,
      "step": 68590
    },
    {
      "epoch": 1.96,
      "grad_norm": 0.07660049945116043,
      "learning_rate": 1.0000000000000002e-06,
      "loss": 0.0009,
      "step": 68600
    },
    {
      "epoch": 1.9602857142857144,
      "grad_norm": 0.0,
      "learning_rate": 9.92857142857143e-07,
      "loss": 0.0013,
      "step": 68610
    },
    {
      "epoch": 1.9605714285714284,
      "grad_norm": 0.07192269712686539,
      "learning_rate": 9.857142857142857e-07,
      "loss": 0.0011,
      "step": 68620
    },
    {
      "epoch": 1.9608571428571429,
      "grad_norm": 0.04077746719121933,
      "learning_rate": 9.785714285714287e-07,
      "loss": 0.0003,
      "step": 68630
    },
    {
      "epoch": 1.9611428571428573,
      "grad_norm": 0.0,
      "learning_rate": 9.714285714285715e-07,
      "loss": 0.0007,
      "step": 68640
    },
    {
      "epoch": 1.9614285714285713,
      "grad_norm": 0.0379134826362133,
      "learning_rate": 9.642857142857142e-07,
      "loss": 0.0007,
      "step": 68650
    },
    {
      "epoch": 1.9617142857142857,
      "grad_norm": 0.10247039049863815,
      "learning_rate": 9.571428571428572e-07,
      "loss": 0.0015,
      "step": 68660
    },
    {
      "epoch": 1.962,
      "grad_norm": 0.16278468072414398,
      "learning_rate": 9.5e-07,
      "loss": 0.0023,
      "step": 68670
    },
    {
      "epoch": 1.9622857142857142,
      "grad_norm": 0.0609692707657814,
      "learning_rate": 9.428571428571429e-07,
      "loss": 0.0008,
      "step": 68680
    },
    {
      "epoch": 1.9625714285714286,
      "grad_norm": 0.0,
      "learning_rate": 9.357142857142858e-07,
      "loss": 0.0013,
      "step": 68690
    },
    {
      "epoch": 1.9628571428571429,
      "grad_norm": 0.07938944548368454,
      "learning_rate": 9.285714285714287e-07,
      "loss": 0.0011,
      "step": 68700
    },
    {
      "epoch": 1.963142857142857,
      "grad_norm": 0.08465136587619781,
      "learning_rate": 9.214285714285715e-07,
      "loss": 0.0004,
      "step": 68710
    },
    {
      "epoch": 1.9634285714285715,
      "grad_norm": 0.03995530307292938,
      "learning_rate": 9.142857142857144e-07,
      "loss": 0.0011,
      "step": 68720
    },
    {
      "epoch": 1.9637142857142857,
      "grad_norm": 0.043606970459222794,
      "learning_rate": 9.071428571428571e-07,
      "loss": 0.0001,
      "step": 68730
    },
    {
      "epoch": 1.964,
      "grad_norm": 0.0,
      "learning_rate": 9e-07,
      "loss": 0.0013,
      "step": 68740
    },
    {
      "epoch": 1.9642857142857144,
      "grad_norm": 0.0,
      "learning_rate": 8.928571428571428e-07,
      "loss": 0.0007,
      "step": 68750
    },
    {
      "epoch": 1.9645714285714284,
      "grad_norm": 0.05919308960437775,
      "learning_rate": 8.857142857142857e-07,
      "loss": 0.0008,
      "step": 68760
    },
    {
      "epoch": 1.9648571428571429,
      "grad_norm": 0.0,
      "learning_rate": 8.785714285714286e-07,
      "loss": 0.0008,
      "step": 68770
    },
    {
      "epoch": 1.9651428571428573,
      "grad_norm": 0.0,
      "learning_rate": 8.714285714285715e-07,
      "loss": 0.0004,
      "step": 68780
    },
    {
      "epoch": 1.9654285714285713,
      "grad_norm": 0.0,
      "learning_rate": 8.642857142857144e-07,
      "loss": 0.0011,
      "step": 68790
    },
    {
      "epoch": 1.9657142857142857,
      "grad_norm": 0.0,
      "learning_rate": 8.571428571428572e-07,
      "loss": 0.0008,
      "step": 68800
    },
    {
      "epoch": 1.966,
      "grad_norm": 0.36525997519493103,
      "learning_rate": 8.500000000000001e-07,
      "loss": 0.0016,
      "step": 68810
    },
    {
      "epoch": 1.9662857142857142,
      "grad_norm": 0.08175377547740936,
      "learning_rate": 8.42857142857143e-07,
      "loss": 0.0012,
      "step": 68820
    },
    {
      "epoch": 1.9665714285714286,
      "grad_norm": 0.05176244676113129,
      "learning_rate": 8.357142857142857e-07,
      "loss": 0.0016,
      "step": 68830
    },
    {
      "epoch": 1.9668571428571429,
      "grad_norm": 0.2768760621547699,
      "learning_rate": 8.285714285714285e-07,
      "loss": 0.001,
      "step": 68840
    },
    {
      "epoch": 1.967142857142857,
      "grad_norm": 0.15560342371463776,
      "learning_rate": 8.214285714285714e-07,
      "loss": 0.0016,
      "step": 68850
    },
    {
      "epoch": 1.9674285714285715,
      "grad_norm": 0.0,
      "learning_rate": 8.142857142857143e-07,
      "loss": 0.0012,
      "step": 68860
    },
    {
      "epoch": 1.9677142857142857,
      "grad_norm": 0.0543474517762661,
      "learning_rate": 8.071428571428572e-07,
      "loss": 0.0011,
      "step": 68870
    },
    {
      "epoch": 1.968,
      "grad_norm": 0.05030229315161705,
      "learning_rate": 8.000000000000001e-07,
      "loss": 0.0009,
      "step": 68880
    },
    {
      "epoch": 1.9682857142857144,
      "grad_norm": 0.06548210978507996,
      "learning_rate": 7.92857142857143e-07,
      "loss": 0.0005,
      "step": 68890
    },
    {
      "epoch": 1.9685714285714284,
      "grad_norm": 0.3629299998283386,
      "learning_rate": 7.857142857142858e-07,
      "loss": 0.0006,
      "step": 68900
    },
    {
      "epoch": 1.9688571428571429,
      "grad_norm": 0.04718638211488724,
      "learning_rate": 7.785714285714286e-07,
      "loss": 0.001,
      "step": 68910
    },
    {
      "epoch": 1.9691428571428573,
      "grad_norm": 0.09717190265655518,
      "learning_rate": 7.714285714285715e-07,
      "loss": 0.0012,
      "step": 68920
    },
    {
      "epoch": 1.9694285714285713,
      "grad_norm": 0.06509271264076233,
      "learning_rate": 7.642857142857144e-07,
      "loss": 0.0002,
      "step": 68930
    },
    {
      "epoch": 1.9697142857142858,
      "grad_norm": 0.3938003480434418,
      "learning_rate": 7.571428571428572e-07,
      "loss": 0.0003,
      "step": 68940
    },
    {
      "epoch": 1.97,
      "grad_norm": 0.1105635017156601,
      "learning_rate": 7.5e-07,
      "loss": 0.001,
      "step": 68950
    },
    {
      "epoch": 1.9702857142857142,
      "grad_norm": 0.0,
      "learning_rate": 7.428571428571429e-07,
      "loss": 0.0009,
      "step": 68960
    },
    {
      "epoch": 1.9705714285714286,
      "grad_norm": 0.1675778180360794,
      "learning_rate": 7.357142857142858e-07,
      "loss": 0.001,
      "step": 68970
    },
    {
      "epoch": 1.9708571428571429,
      "grad_norm": 0.26124808192253113,
      "learning_rate": 7.285714285714287e-07,
      "loss": 0.0009,
      "step": 68980
    },
    {
      "epoch": 1.971142857142857,
      "grad_norm": 0.2181025892496109,
      "learning_rate": 7.214285714285714e-07,
      "loss": 0.0005,
      "step": 68990
    },
    {
      "epoch": 1.9714285714285715,
      "grad_norm": 0.05472603440284729,
      "learning_rate": 7.142857142857143e-07,
      "loss": 0.0015,
      "step": 69000
    }
  ],
  "logging_steps": 10,
  "max_steps": 70000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 0.0,
  "train_batch_size": 40,
  "trial_name": null,
  "trial_params": null
}
