{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.0,
  "eval_steps": 500,
  "global_step": 23438,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0008533151292772421,
      "grad_norm": 1.0719325542449951,
      "learning_rate": 4.997866712176807e-05,
      "loss": 0.005,
      "step": 10
    },
    {
      "epoch": 0.0017066302585544842,
      "grad_norm": 1.0499838590621948,
      "learning_rate": 4.995733424353614e-05,
      "loss": 0.0055,
      "step": 20
    },
    {
      "epoch": 0.0025599453878317265,
      "grad_norm": 0.5277854204177856,
      "learning_rate": 4.993600136530421e-05,
      "loss": 0.0039,
      "step": 30
    },
    {
      "epoch": 0.0034132605171089685,
      "grad_norm": 0.8664485216140747,
      "learning_rate": 4.991466848707228e-05,
      "loss": 0.0045,
      "step": 40
    },
    {
      "epoch": 0.00426657564638621,
      "grad_norm": 0.5771036148071289,
      "learning_rate": 4.9893335608840345e-05,
      "loss": 0.0059,
      "step": 50
    },
    {
      "epoch": 0.005119890775663453,
      "grad_norm": 0.6369047164916992,
      "learning_rate": 4.9872002730608416e-05,
      "loss": 0.0058,
      "step": 60
    },
    {
      "epoch": 0.005973205904940695,
      "grad_norm": 0.7500748038291931,
      "learning_rate": 4.985066985237649e-05,
      "loss": 0.005,
      "step": 70
    },
    {
      "epoch": 0.006826521034217937,
      "grad_norm": 1.5703176259994507,
      "learning_rate": 4.982933697414455e-05,
      "loss": 0.0054,
      "step": 80
    },
    {
      "epoch": 0.007679836163495179,
      "grad_norm": 0.8181561231613159,
      "learning_rate": 4.980800409591262e-05,
      "loss": 0.0047,
      "step": 90
    },
    {
      "epoch": 0.00853315129277242,
      "grad_norm": 0.7091100215911865,
      "learning_rate": 4.9786671217680694e-05,
      "loss": 0.0048,
      "step": 100
    },
    {
      "epoch": 0.009386466422049662,
      "grad_norm": 0.6606809496879578,
      "learning_rate": 4.976533833944876e-05,
      "loss": 0.0061,
      "step": 110
    },
    {
      "epoch": 0.010239781551326906,
      "grad_norm": 0.7526068091392517,
      "learning_rate": 4.974400546121683e-05,
      "loss": 0.0057,
      "step": 120
    },
    {
      "epoch": 0.011093096680604148,
      "grad_norm": 0.9930639266967773,
      "learning_rate": 4.9722672582984894e-05,
      "loss": 0.0058,
      "step": 130
    },
    {
      "epoch": 0.01194641180988139,
      "grad_norm": 0.6644188165664673,
      "learning_rate": 4.970133970475297e-05,
      "loss": 0.0044,
      "step": 140
    },
    {
      "epoch": 0.012799726939158632,
      "grad_norm": 0.6500135660171509,
      "learning_rate": 4.9680006826521037e-05,
      "loss": 0.0033,
      "step": 150
    },
    {
      "epoch": 0.013653042068435874,
      "grad_norm": 1.0897976160049438,
      "learning_rate": 4.96586739482891e-05,
      "loss": 0.0047,
      "step": 160
    },
    {
      "epoch": 0.014506357197713116,
      "grad_norm": 0.6226781606674194,
      "learning_rate": 4.963734107005717e-05,
      "loss": 0.0056,
      "step": 170
    },
    {
      "epoch": 0.015359672326990358,
      "grad_norm": 1.1325533390045166,
      "learning_rate": 4.9616008191825243e-05,
      "loss": 0.0046,
      "step": 180
    },
    {
      "epoch": 0.016212987456267598,
      "grad_norm": 0.48789823055267334,
      "learning_rate": 4.9594675313593315e-05,
      "loss": 0.0052,
      "step": 190
    },
    {
      "epoch": 0.01706630258554484,
      "grad_norm": 1.1221662759780884,
      "learning_rate": 4.957334243536138e-05,
      "loss": 0.004,
      "step": 200
    },
    {
      "epoch": 0.017919617714822082,
      "grad_norm": 0.8686769604682922,
      "learning_rate": 4.955200955712945e-05,
      "loss": 0.0047,
      "step": 210
    },
    {
      "epoch": 0.018772932844099324,
      "grad_norm": 1.1590739488601685,
      "learning_rate": 4.953067667889752e-05,
      "loss": 0.0041,
      "step": 220
    },
    {
      "epoch": 0.019626247973376566,
      "grad_norm": 0.9205066561698914,
      "learning_rate": 4.9509343800665586e-05,
      "loss": 0.0052,
      "step": 230
    },
    {
      "epoch": 0.020479563102653812,
      "grad_norm": 0.8882866501808167,
      "learning_rate": 4.948801092243366e-05,
      "loss": 0.0045,
      "step": 240
    },
    {
      "epoch": 0.021332878231931054,
      "grad_norm": 1.0665992498397827,
      "learning_rate": 4.946667804420173e-05,
      "loss": 0.0049,
      "step": 250
    },
    {
      "epoch": 0.022186193361208296,
      "grad_norm": 1.3583563566207886,
      "learning_rate": 4.94453451659698e-05,
      "loss": 0.0037,
      "step": 260
    },
    {
      "epoch": 0.023039508490485538,
      "grad_norm": 1.6677353382110596,
      "learning_rate": 4.9424012287737864e-05,
      "loss": 0.0038,
      "step": 270
    },
    {
      "epoch": 0.02389282361976278,
      "grad_norm": 1.1032004356384277,
      "learning_rate": 4.940267940950593e-05,
      "loss": 0.0041,
      "step": 280
    },
    {
      "epoch": 0.024746138749040022,
      "grad_norm": 0.4352426826953888,
      "learning_rate": 4.9381346531274006e-05,
      "loss": 0.0038,
      "step": 290
    },
    {
      "epoch": 0.025599453878317264,
      "grad_norm": 0.5656377673149109,
      "learning_rate": 4.936001365304207e-05,
      "loss": 0.0042,
      "step": 300
    },
    {
      "epoch": 0.026452769007594506,
      "grad_norm": 0.9880087375640869,
      "learning_rate": 4.933868077481014e-05,
      "loss": 0.0046,
      "step": 310
    },
    {
      "epoch": 0.027306084136871748,
      "grad_norm": 0.6342949867248535,
      "learning_rate": 4.9317347896578206e-05,
      "loss": 0.0043,
      "step": 320
    },
    {
      "epoch": 0.02815939926614899,
      "grad_norm": 0.48767560720443726,
      "learning_rate": 4.929601501834628e-05,
      "loss": 0.0038,
      "step": 330
    },
    {
      "epoch": 0.029012714395426232,
      "grad_norm": 1.1576589345932007,
      "learning_rate": 4.927468214011435e-05,
      "loss": 0.0036,
      "step": 340
    },
    {
      "epoch": 0.029866029524703474,
      "grad_norm": 0.8183290958404541,
      "learning_rate": 4.925334926188241e-05,
      "loss": 0.0035,
      "step": 350
    },
    {
      "epoch": 0.030719344653980716,
      "grad_norm": 0.5307135581970215,
      "learning_rate": 4.9232016383650484e-05,
      "loss": 0.003,
      "step": 360
    },
    {
      "epoch": 0.031572659783257954,
      "grad_norm": 0.8852458000183105,
      "learning_rate": 4.9210683505418556e-05,
      "loss": 0.0033,
      "step": 370
    },
    {
      "epoch": 0.032425974912535196,
      "grad_norm": 1.1699293851852417,
      "learning_rate": 4.918935062718662e-05,
      "loss": 0.0036,
      "step": 380
    },
    {
      "epoch": 0.03327929004181244,
      "grad_norm": 1.2290395498275757,
      "learning_rate": 4.916801774895469e-05,
      "loss": 0.0034,
      "step": 390
    },
    {
      "epoch": 0.03413260517108968,
      "grad_norm": 1.1041507720947266,
      "learning_rate": 4.9146684870722756e-05,
      "loss": 0.0042,
      "step": 400
    },
    {
      "epoch": 0.03498592030036692,
      "grad_norm": 1.6328999996185303,
      "learning_rate": 4.9125351992490834e-05,
      "loss": 0.0038,
      "step": 410
    },
    {
      "epoch": 0.035839235429644165,
      "grad_norm": 1.229659914970398,
      "learning_rate": 4.91040191142589e-05,
      "loss": 0.0042,
      "step": 420
    },
    {
      "epoch": 0.03669255055892141,
      "grad_norm": 1.334348440170288,
      "learning_rate": 4.908268623602696e-05,
      "loss": 0.0037,
      "step": 430
    },
    {
      "epoch": 0.03754586568819865,
      "grad_norm": 1.0596123933792114,
      "learning_rate": 4.9061353357795034e-05,
      "loss": 0.0035,
      "step": 440
    },
    {
      "epoch": 0.03839918081747589,
      "grad_norm": 1.311870813369751,
      "learning_rate": 4.9040020479563105e-05,
      "loss": 0.0038,
      "step": 450
    },
    {
      "epoch": 0.03925249594675313,
      "grad_norm": 0.6634660959243774,
      "learning_rate": 4.9018687601331176e-05,
      "loss": 0.0035,
      "step": 460
    },
    {
      "epoch": 0.040105811076030375,
      "grad_norm": 0.5038687586784363,
      "learning_rate": 4.899735472309924e-05,
      "loss": 0.0034,
      "step": 470
    },
    {
      "epoch": 0.040959126205307624,
      "grad_norm": 0.693027675151825,
      "learning_rate": 4.897602184486731e-05,
      "loss": 0.0041,
      "step": 480
    },
    {
      "epoch": 0.041812441334584866,
      "grad_norm": 0.5725678205490112,
      "learning_rate": 4.895468896663538e-05,
      "loss": 0.0044,
      "step": 490
    },
    {
      "epoch": 0.04266575646386211,
      "grad_norm": 1.1729103326797485,
      "learning_rate": 4.893335608840345e-05,
      "loss": 0.0035,
      "step": 500
    },
    {
      "epoch": 0.04351907159313935,
      "grad_norm": 0.48238760232925415,
      "learning_rate": 4.891202321017152e-05,
      "loss": 0.0045,
      "step": 510
    },
    {
      "epoch": 0.04437238672241659,
      "grad_norm": 0.39689406752586365,
      "learning_rate": 4.889069033193959e-05,
      "loss": 0.0033,
      "step": 520
    },
    {
      "epoch": 0.045225701851693834,
      "grad_norm": 1.3148341178894043,
      "learning_rate": 4.886935745370766e-05,
      "loss": 0.004,
      "step": 530
    },
    {
      "epoch": 0.046079016980971076,
      "grad_norm": 0.8933978080749512,
      "learning_rate": 4.8848024575475725e-05,
      "loss": 0.0036,
      "step": 540
    },
    {
      "epoch": 0.04693233211024832,
      "grad_norm": 1.2296568155288696,
      "learning_rate": 4.882669169724379e-05,
      "loss": 0.0046,
      "step": 550
    },
    {
      "epoch": 0.04778564723952556,
      "grad_norm": 0.5563523173332214,
      "learning_rate": 4.880535881901187e-05,
      "loss": 0.0037,
      "step": 560
    },
    {
      "epoch": 0.0486389623688028,
      "grad_norm": 0.36233705282211304,
      "learning_rate": 4.878402594077993e-05,
      "loss": 0.0035,
      "step": 570
    },
    {
      "epoch": 0.049492277498080044,
      "grad_norm": 0.5818386077880859,
      "learning_rate": 4.8762693062548004e-05,
      "loss": 0.0037,
      "step": 580
    },
    {
      "epoch": 0.050345592627357286,
      "grad_norm": 0.3066668212413788,
      "learning_rate": 4.874136018431607e-05,
      "loss": 0.0035,
      "step": 590
    },
    {
      "epoch": 0.05119890775663453,
      "grad_norm": 0.5456568598747253,
      "learning_rate": 4.872002730608414e-05,
      "loss": 0.0033,
      "step": 600
    },
    {
      "epoch": 0.05205222288591177,
      "grad_norm": 0.7946589589118958,
      "learning_rate": 4.869869442785221e-05,
      "loss": 0.0036,
      "step": 610
    },
    {
      "epoch": 0.05290553801518901,
      "grad_norm": 0.5611127018928528,
      "learning_rate": 4.8677361549620275e-05,
      "loss": 0.0041,
      "step": 620
    },
    {
      "epoch": 0.053758853144466254,
      "grad_norm": 0.80417400598526,
      "learning_rate": 4.8656028671388346e-05,
      "loss": 0.0035,
      "step": 630
    },
    {
      "epoch": 0.054612168273743496,
      "grad_norm": 0.6157137155532837,
      "learning_rate": 4.863469579315642e-05,
      "loss": 0.0046,
      "step": 640
    },
    {
      "epoch": 0.05546548340302074,
      "grad_norm": 0.8816973567008972,
      "learning_rate": 4.861336291492448e-05,
      "loss": 0.0043,
      "step": 650
    },
    {
      "epoch": 0.05631879853229798,
      "grad_norm": 0.7822739481925964,
      "learning_rate": 4.859203003669255e-05,
      "loss": 0.0042,
      "step": 660
    },
    {
      "epoch": 0.05717211366157522,
      "grad_norm": 0.48879531025886536,
      "learning_rate": 4.8570697158460624e-05,
      "loss": 0.0037,
      "step": 670
    },
    {
      "epoch": 0.058025428790852464,
      "grad_norm": 0.8212478756904602,
      "learning_rate": 4.8549364280228695e-05,
      "loss": 0.0034,
      "step": 680
    },
    {
      "epoch": 0.058878743920129706,
      "grad_norm": 1.1531871557235718,
      "learning_rate": 4.852803140199676e-05,
      "loss": 0.0042,
      "step": 690
    },
    {
      "epoch": 0.05973205904940695,
      "grad_norm": 0.4167487323284149,
      "learning_rate": 4.8506698523764824e-05,
      "loss": 0.0037,
      "step": 700
    },
    {
      "epoch": 0.06058537417868419,
      "grad_norm": 1.0248730182647705,
      "learning_rate": 4.8485365645532895e-05,
      "loss": 0.0041,
      "step": 710
    },
    {
      "epoch": 0.06143868930796143,
      "grad_norm": 0.8244091272354126,
      "learning_rate": 4.8464032767300967e-05,
      "loss": 0.0038,
      "step": 720
    },
    {
      "epoch": 0.062292004437238674,
      "grad_norm": 0.6637094020843506,
      "learning_rate": 4.844269988906904e-05,
      "loss": 0.0042,
      "step": 730
    },
    {
      "epoch": 0.06314531956651591,
      "grad_norm": 0.9289597272872925,
      "learning_rate": 4.84213670108371e-05,
      "loss": 0.0031,
      "step": 740
    },
    {
      "epoch": 0.06399863469579316,
      "grad_norm": 0.5833656191825867,
      "learning_rate": 4.840003413260517e-05,
      "loss": 0.0042,
      "step": 750
    },
    {
      "epoch": 0.06485194982507039,
      "grad_norm": 1.2003729343414307,
      "learning_rate": 4.8378701254373245e-05,
      "loss": 0.0035,
      "step": 760
    },
    {
      "epoch": 0.06570526495434764,
      "grad_norm": 0.49593591690063477,
      "learning_rate": 4.835736837614131e-05,
      "loss": 0.0046,
      "step": 770
    },
    {
      "epoch": 0.06655858008362488,
      "grad_norm": 0.42206278443336487,
      "learning_rate": 4.833603549790938e-05,
      "loss": 0.004,
      "step": 780
    },
    {
      "epoch": 0.06741189521290213,
      "grad_norm": 0.7944209575653076,
      "learning_rate": 4.831470261967745e-05,
      "loss": 0.0032,
      "step": 790
    },
    {
      "epoch": 0.06826521034217936,
      "grad_norm": 0.8802010416984558,
      "learning_rate": 4.8293369741445516e-05,
      "loss": 0.0032,
      "step": 800
    },
    {
      "epoch": 0.06911852547145661,
      "grad_norm": 0.5317930579185486,
      "learning_rate": 4.827203686321359e-05,
      "loss": 0.0037,
      "step": 810
    },
    {
      "epoch": 0.06997184060073385,
      "grad_norm": 0.6864877939224243,
      "learning_rate": 4.825070398498165e-05,
      "loss": 0.0031,
      "step": 820
    },
    {
      "epoch": 0.0708251557300111,
      "grad_norm": 0.7090789675712585,
      "learning_rate": 4.822937110674973e-05,
      "loss": 0.0036,
      "step": 830
    },
    {
      "epoch": 0.07167847085928833,
      "grad_norm": 0.4777776002883911,
      "learning_rate": 4.8208038228517794e-05,
      "loss": 0.0036,
      "step": 840
    },
    {
      "epoch": 0.07253178598856558,
      "grad_norm": 0.4287325441837311,
      "learning_rate": 4.8186705350285865e-05,
      "loss": 0.0035,
      "step": 850
    },
    {
      "epoch": 0.07338510111784281,
      "grad_norm": 0.8195399045944214,
      "learning_rate": 4.816537247205393e-05,
      "loss": 0.0036,
      "step": 860
    },
    {
      "epoch": 0.07423841624712006,
      "grad_norm": 0.5502316355705261,
      "learning_rate": 4.8144039593822e-05,
      "loss": 0.0042,
      "step": 870
    },
    {
      "epoch": 0.0750917313763973,
      "grad_norm": 0.4495689272880554,
      "learning_rate": 4.812270671559007e-05,
      "loss": 0.0034,
      "step": 880
    },
    {
      "epoch": 0.07594504650567455,
      "grad_norm": 0.47335052490234375,
      "learning_rate": 4.8101373837358136e-05,
      "loss": 0.0043,
      "step": 890
    },
    {
      "epoch": 0.07679836163495178,
      "grad_norm": 0.673886239528656,
      "learning_rate": 4.808004095912621e-05,
      "loss": 0.0032,
      "step": 900
    },
    {
      "epoch": 0.07765167676422903,
      "grad_norm": 0.9640531539916992,
      "learning_rate": 4.805870808089428e-05,
      "loss": 0.0035,
      "step": 910
    },
    {
      "epoch": 0.07850499189350627,
      "grad_norm": 0.3839562237262726,
      "learning_rate": 4.803737520266234e-05,
      "loss": 0.0041,
      "step": 920
    },
    {
      "epoch": 0.07935830702278351,
      "grad_norm": 0.7409557104110718,
      "learning_rate": 4.8016042324430414e-05,
      "loss": 0.0039,
      "step": 930
    },
    {
      "epoch": 0.08021162215206075,
      "grad_norm": 1.0042506456375122,
      "learning_rate": 4.7994709446198486e-05,
      "loss": 0.0048,
      "step": 940
    },
    {
      "epoch": 0.081064937281338,
      "grad_norm": 0.7023481130599976,
      "learning_rate": 4.797337656796656e-05,
      "loss": 0.0041,
      "step": 950
    },
    {
      "epoch": 0.08191825241061525,
      "grad_norm": 0.4382609724998474,
      "learning_rate": 4.795204368973462e-05,
      "loss": 0.0045,
      "step": 960
    },
    {
      "epoch": 0.08277156753989248,
      "grad_norm": 0.5871294736862183,
      "learning_rate": 4.7930710811502686e-05,
      "loss": 0.0037,
      "step": 970
    },
    {
      "epoch": 0.08362488266916973,
      "grad_norm": 1.0735763311386108,
      "learning_rate": 4.7909377933270764e-05,
      "loss": 0.0044,
      "step": 980
    },
    {
      "epoch": 0.08447819779844697,
      "grad_norm": 0.9590064287185669,
      "learning_rate": 4.788804505503883e-05,
      "loss": 0.0037,
      "step": 990
    },
    {
      "epoch": 0.08533151292772422,
      "grad_norm": 0.730082631111145,
      "learning_rate": 4.78667121768069e-05,
      "loss": 0.0042,
      "step": 1000
    },
    {
      "epoch": 0.08618482805700145,
      "grad_norm": 0.9126313328742981,
      "learning_rate": 4.7845379298574964e-05,
      "loss": 0.0033,
      "step": 1010
    },
    {
      "epoch": 0.0870381431862787,
      "grad_norm": 0.8496209979057312,
      "learning_rate": 4.7824046420343035e-05,
      "loss": 0.0031,
      "step": 1020
    },
    {
      "epoch": 0.08789145831555593,
      "grad_norm": 0.3768619894981384,
      "learning_rate": 4.7802713542111106e-05,
      "loss": 0.0029,
      "step": 1030
    },
    {
      "epoch": 0.08874477344483318,
      "grad_norm": 1.401868462562561,
      "learning_rate": 4.778138066387917e-05,
      "loss": 0.0032,
      "step": 1040
    },
    {
      "epoch": 0.08959808857411042,
      "grad_norm": 0.6973714232444763,
      "learning_rate": 4.776004778564724e-05,
      "loss": 0.0039,
      "step": 1050
    },
    {
      "epoch": 0.09045140370338767,
      "grad_norm": 0.4094899892807007,
      "learning_rate": 4.773871490741531e-05,
      "loss": 0.0036,
      "step": 1060
    },
    {
      "epoch": 0.0913047188326649,
      "grad_norm": 0.42895597219467163,
      "learning_rate": 4.771738202918338e-05,
      "loss": 0.0037,
      "step": 1070
    },
    {
      "epoch": 0.09215803396194215,
      "grad_norm": 0.6194751262664795,
      "learning_rate": 4.769604915095145e-05,
      "loss": 0.003,
      "step": 1080
    },
    {
      "epoch": 0.09301134909121939,
      "grad_norm": 0.4479805529117584,
      "learning_rate": 4.767471627271951e-05,
      "loss": 0.0034,
      "step": 1090
    },
    {
      "epoch": 0.09386466422049664,
      "grad_norm": 0.5103634595870972,
      "learning_rate": 4.765338339448759e-05,
      "loss": 0.0032,
      "step": 1100
    },
    {
      "epoch": 0.09471797934977387,
      "grad_norm": 0.45945191383361816,
      "learning_rate": 4.7632050516255655e-05,
      "loss": 0.0043,
      "step": 1110
    },
    {
      "epoch": 0.09557129447905112,
      "grad_norm": 0.3987047076225281,
      "learning_rate": 4.761071763802372e-05,
      "loss": 0.0039,
      "step": 1120
    },
    {
      "epoch": 0.09642460960832835,
      "grad_norm": 0.25520262122154236,
      "learning_rate": 4.758938475979179e-05,
      "loss": 0.0041,
      "step": 1130
    },
    {
      "epoch": 0.0972779247376056,
      "grad_norm": 0.6187495589256287,
      "learning_rate": 4.756805188155986e-05,
      "loss": 0.0027,
      "step": 1140
    },
    {
      "epoch": 0.09813123986688284,
      "grad_norm": 0.42379939556121826,
      "learning_rate": 4.7546719003327933e-05,
      "loss": 0.0029,
      "step": 1150
    },
    {
      "epoch": 0.09898455499616009,
      "grad_norm": 0.5925807356834412,
      "learning_rate": 4.7525386125096e-05,
      "loss": 0.0029,
      "step": 1160
    },
    {
      "epoch": 0.09983787012543732,
      "grad_norm": 0.6753278374671936,
      "learning_rate": 4.750405324686407e-05,
      "loss": 0.0035,
      "step": 1170
    },
    {
      "epoch": 0.10069118525471457,
      "grad_norm": 0.6485944986343384,
      "learning_rate": 4.748272036863214e-05,
      "loss": 0.003,
      "step": 1180
    },
    {
      "epoch": 0.1015445003839918,
      "grad_norm": 0.5405668616294861,
      "learning_rate": 4.7461387490400205e-05,
      "loss": 0.0041,
      "step": 1190
    },
    {
      "epoch": 0.10239781551326906,
      "grad_norm": 0.5888096690177917,
      "learning_rate": 4.7440054612168276e-05,
      "loss": 0.0036,
      "step": 1200
    },
    {
      "epoch": 0.10325113064254629,
      "grad_norm": 1.2919923067092896,
      "learning_rate": 4.741872173393635e-05,
      "loss": 0.0039,
      "step": 1210
    },
    {
      "epoch": 0.10410444577182354,
      "grad_norm": 0.9144755005836487,
      "learning_rate": 4.739738885570442e-05,
      "loss": 0.0039,
      "step": 1220
    },
    {
      "epoch": 0.10495776090110077,
      "grad_norm": 0.9827257394790649,
      "learning_rate": 4.737605597747248e-05,
      "loss": 0.0034,
      "step": 1230
    },
    {
      "epoch": 0.10581107603037802,
      "grad_norm": 0.7703500390052795,
      "learning_rate": 4.735472309924055e-05,
      "loss": 0.0033,
      "step": 1240
    },
    {
      "epoch": 0.10666439115965526,
      "grad_norm": 0.9508578777313232,
      "learning_rate": 4.7333390221008625e-05,
      "loss": 0.0036,
      "step": 1250
    },
    {
      "epoch": 0.10751770628893251,
      "grad_norm": 0.7303270697593689,
      "learning_rate": 4.731205734277669e-05,
      "loss": 0.0033,
      "step": 1260
    },
    {
      "epoch": 0.10837102141820974,
      "grad_norm": 0.3791925311088562,
      "learning_rate": 4.729072446454476e-05,
      "loss": 0.0039,
      "step": 1270
    },
    {
      "epoch": 0.10922433654748699,
      "grad_norm": 0.4389730393886566,
      "learning_rate": 4.7269391586312825e-05,
      "loss": 0.0034,
      "step": 1280
    },
    {
      "epoch": 0.11007765167676423,
      "grad_norm": 0.6482002139091492,
      "learning_rate": 4.7248058708080896e-05,
      "loss": 0.0034,
      "step": 1290
    },
    {
      "epoch": 0.11093096680604148,
      "grad_norm": 0.7243409156799316,
      "learning_rate": 4.722672582984897e-05,
      "loss": 0.0034,
      "step": 1300
    },
    {
      "epoch": 0.11178428193531871,
      "grad_norm": 0.6313637495040894,
      "learning_rate": 4.720539295161703e-05,
      "loss": 0.0034,
      "step": 1310
    },
    {
      "epoch": 0.11263759706459596,
      "grad_norm": 1.0134197473526,
      "learning_rate": 4.71840600733851e-05,
      "loss": 0.0034,
      "step": 1320
    },
    {
      "epoch": 0.1134909121938732,
      "grad_norm": 1.3096897602081299,
      "learning_rate": 4.7162727195153174e-05,
      "loss": 0.0036,
      "step": 1330
    },
    {
      "epoch": 0.11434422732315044,
      "grad_norm": 0.9487703442573547,
      "learning_rate": 4.714139431692124e-05,
      "loss": 0.0033,
      "step": 1340
    },
    {
      "epoch": 0.11519754245242768,
      "grad_norm": 0.7748083472251892,
      "learning_rate": 4.712006143868931e-05,
      "loss": 0.0038,
      "step": 1350
    },
    {
      "epoch": 0.11605085758170493,
      "grad_norm": 0.40052226185798645,
      "learning_rate": 4.709872856045738e-05,
      "loss": 0.0036,
      "step": 1360
    },
    {
      "epoch": 0.11690417271098216,
      "grad_norm": 1.150795578956604,
      "learning_rate": 4.707739568222545e-05,
      "loss": 0.0031,
      "step": 1370
    },
    {
      "epoch": 0.11775748784025941,
      "grad_norm": 0.7335397005081177,
      "learning_rate": 4.705606280399352e-05,
      "loss": 0.003,
      "step": 1380
    },
    {
      "epoch": 0.11861080296953665,
      "grad_norm": 1.3986153602600098,
      "learning_rate": 4.703472992576158e-05,
      "loss": 0.0036,
      "step": 1390
    },
    {
      "epoch": 0.1194641180988139,
      "grad_norm": 0.6275387406349182,
      "learning_rate": 4.701339704752965e-05,
      "loss": 0.0039,
      "step": 1400
    },
    {
      "epoch": 0.12031743322809113,
      "grad_norm": 0.9334476590156555,
      "learning_rate": 4.6992064169297724e-05,
      "loss": 0.0031,
      "step": 1410
    },
    {
      "epoch": 0.12117074835736838,
      "grad_norm": 0.7312960624694824,
      "learning_rate": 4.6970731291065795e-05,
      "loss": 0.0034,
      "step": 1420
    },
    {
      "epoch": 0.12202406348664561,
      "grad_norm": 0.5031874775886536,
      "learning_rate": 4.694939841283386e-05,
      "loss": 0.0034,
      "step": 1430
    },
    {
      "epoch": 0.12287737861592286,
      "grad_norm": 0.5002655982971191,
      "learning_rate": 4.692806553460193e-05,
      "loss": 0.0039,
      "step": 1440
    },
    {
      "epoch": 0.1237306937452001,
      "grad_norm": 0.4217427372932434,
      "learning_rate": 4.690673265637e-05,
      "loss": 0.0031,
      "step": 1450
    },
    {
      "epoch": 0.12458400887447735,
      "grad_norm": 0.8175245523452759,
      "learning_rate": 4.6885399778138066e-05,
      "loss": 0.0037,
      "step": 1460
    },
    {
      "epoch": 0.1254373240037546,
      "grad_norm": 0.9873734712600708,
      "learning_rate": 4.686406689990614e-05,
      "loss": 0.003,
      "step": 1470
    },
    {
      "epoch": 0.12629063913303182,
      "grad_norm": 0.9614331126213074,
      "learning_rate": 4.684273402167421e-05,
      "loss": 0.0037,
      "step": 1480
    },
    {
      "epoch": 0.12714395426230907,
      "grad_norm": 0.47639667987823486,
      "learning_rate": 4.682140114344227e-05,
      "loss": 0.0033,
      "step": 1490
    },
    {
      "epoch": 0.12799726939158632,
      "grad_norm": 0.7925004363059998,
      "learning_rate": 4.6800068265210344e-05,
      "loss": 0.0038,
      "step": 1500
    },
    {
      "epoch": 0.12885058452086356,
      "grad_norm": 0.6464698314666748,
      "learning_rate": 4.677873538697841e-05,
      "loss": 0.0036,
      "step": 1510
    },
    {
      "epoch": 0.12970389965014079,
      "grad_norm": 0.5371158123016357,
      "learning_rate": 4.675740250874649e-05,
      "loss": 0.0042,
      "step": 1520
    },
    {
      "epoch": 0.13055721477941803,
      "grad_norm": 1.155392050743103,
      "learning_rate": 4.673606963051455e-05,
      "loss": 0.0037,
      "step": 1530
    },
    {
      "epoch": 0.13141052990869528,
      "grad_norm": 0.7292559146881104,
      "learning_rate": 4.671473675228262e-05,
      "loss": 0.0036,
      "step": 1540
    },
    {
      "epoch": 0.13226384503797253,
      "grad_norm": 0.8863909244537354,
      "learning_rate": 4.669340387405069e-05,
      "loss": 0.003,
      "step": 1550
    },
    {
      "epoch": 0.13311716016724975,
      "grad_norm": 0.9537979364395142,
      "learning_rate": 4.667207099581876e-05,
      "loss": 0.0037,
      "step": 1560
    },
    {
      "epoch": 0.133970475296527,
      "grad_norm": 0.4812053143978119,
      "learning_rate": 4.665073811758683e-05,
      "loss": 0.0027,
      "step": 1570
    },
    {
      "epoch": 0.13482379042580425,
      "grad_norm": 0.6538823843002319,
      "learning_rate": 4.6629405239354894e-05,
      "loss": 0.0043,
      "step": 1580
    },
    {
      "epoch": 0.1356771055550815,
      "grad_norm": 0.6850824952125549,
      "learning_rate": 4.6608072361122965e-05,
      "loss": 0.0041,
      "step": 1590
    },
    {
      "epoch": 0.13653042068435872,
      "grad_norm": 0.46041834354400635,
      "learning_rate": 4.6586739482891036e-05,
      "loss": 0.0031,
      "step": 1600
    },
    {
      "epoch": 0.13738373581363597,
      "grad_norm": 0.2853030264377594,
      "learning_rate": 4.65654066046591e-05,
      "loss": 0.0037,
      "step": 1610
    },
    {
      "epoch": 0.13823705094291322,
      "grad_norm": 1.0448977947235107,
      "learning_rate": 4.654407372642717e-05,
      "loss": 0.0044,
      "step": 1620
    },
    {
      "epoch": 0.13909036607219047,
      "grad_norm": 0.9792178869247437,
      "learning_rate": 4.652274084819524e-05,
      "loss": 0.0036,
      "step": 1630
    },
    {
      "epoch": 0.1399436812014677,
      "grad_norm": 0.6097936034202576,
      "learning_rate": 4.6501407969963314e-05,
      "loss": 0.0035,
      "step": 1640
    },
    {
      "epoch": 0.14079699633074494,
      "grad_norm": 0.6725119948387146,
      "learning_rate": 4.648007509173138e-05,
      "loss": 0.0034,
      "step": 1650
    },
    {
      "epoch": 0.1416503114600222,
      "grad_norm": 0.5576947927474976,
      "learning_rate": 4.645874221349944e-05,
      "loss": 0.0028,
      "step": 1660
    },
    {
      "epoch": 0.14250362658929944,
      "grad_norm": 0.3311666250228882,
      "learning_rate": 4.643740933526752e-05,
      "loss": 0.003,
      "step": 1670
    },
    {
      "epoch": 0.14335694171857666,
      "grad_norm": 0.6708070039749146,
      "learning_rate": 4.6416076457035585e-05,
      "loss": 0.0032,
      "step": 1680
    },
    {
      "epoch": 0.1442102568478539,
      "grad_norm": 0.4379252791404724,
      "learning_rate": 4.6394743578803657e-05,
      "loss": 0.0038,
      "step": 1690
    },
    {
      "epoch": 0.14506357197713116,
      "grad_norm": 0.3581112027168274,
      "learning_rate": 4.637341070057172e-05,
      "loss": 0.0036,
      "step": 1700
    },
    {
      "epoch": 0.1459168871064084,
      "grad_norm": 0.5870065689086914,
      "learning_rate": 4.635207782233979e-05,
      "loss": 0.003,
      "step": 1710
    },
    {
      "epoch": 0.14677020223568563,
      "grad_norm": 0.6591779589653015,
      "learning_rate": 4.633074494410786e-05,
      "loss": 0.0028,
      "step": 1720
    },
    {
      "epoch": 0.14762351736496288,
      "grad_norm": 0.5249132513999939,
      "learning_rate": 4.630941206587593e-05,
      "loss": 0.003,
      "step": 1730
    },
    {
      "epoch": 0.14847683249424012,
      "grad_norm": 1.44293212890625,
      "learning_rate": 4.6288079187644e-05,
      "loss": 0.0037,
      "step": 1740
    },
    {
      "epoch": 0.14933014762351737,
      "grad_norm": 0.9469432234764099,
      "learning_rate": 4.626674630941207e-05,
      "loss": 0.0037,
      "step": 1750
    },
    {
      "epoch": 0.1501834627527946,
      "grad_norm": 0.9895389676094055,
      "learning_rate": 4.6245413431180135e-05,
      "loss": 0.0038,
      "step": 1760
    },
    {
      "epoch": 0.15103677788207184,
      "grad_norm": 0.4731917083263397,
      "learning_rate": 4.6224080552948206e-05,
      "loss": 0.0031,
      "step": 1770
    },
    {
      "epoch": 0.1518900930113491,
      "grad_norm": 0.46413564682006836,
      "learning_rate": 4.620274767471627e-05,
      "loss": 0.004,
      "step": 1780
    },
    {
      "epoch": 0.15274340814062634,
      "grad_norm": 0.5693787932395935,
      "learning_rate": 4.618141479648435e-05,
      "loss": 0.0037,
      "step": 1790
    },
    {
      "epoch": 0.15359672326990356,
      "grad_norm": 0.4181789457798004,
      "learning_rate": 4.616008191825241e-05,
      "loss": 0.0036,
      "step": 1800
    },
    {
      "epoch": 0.1544500383991808,
      "grad_norm": 0.617337167263031,
      "learning_rate": 4.613874904002048e-05,
      "loss": 0.0038,
      "step": 1810
    },
    {
      "epoch": 0.15530335352845806,
      "grad_norm": 1.0318557024002075,
      "learning_rate": 4.611741616178855e-05,
      "loss": 0.0042,
      "step": 1820
    },
    {
      "epoch": 0.1561566686577353,
      "grad_norm": 1.5480256080627441,
      "learning_rate": 4.609608328355662e-05,
      "loss": 0.0034,
      "step": 1830
    },
    {
      "epoch": 0.15700998378701253,
      "grad_norm": 1.113618016242981,
      "learning_rate": 4.607475040532469e-05,
      "loss": 0.0033,
      "step": 1840
    },
    {
      "epoch": 0.15786329891628978,
      "grad_norm": 0.9406543970108032,
      "learning_rate": 4.6053417527092755e-05,
      "loss": 0.003,
      "step": 1850
    },
    {
      "epoch": 0.15871661404556703,
      "grad_norm": 0.6758801937103271,
      "learning_rate": 4.6032084648860826e-05,
      "loss": 0.0032,
      "step": 1860
    },
    {
      "epoch": 0.15956992917484428,
      "grad_norm": 0.5664254426956177,
      "learning_rate": 4.60107517706289e-05,
      "loss": 0.0029,
      "step": 1870
    },
    {
      "epoch": 0.1604232443041215,
      "grad_norm": 0.3002347946166992,
      "learning_rate": 4.598941889239696e-05,
      "loss": 0.0036,
      "step": 1880
    },
    {
      "epoch": 0.16127655943339875,
      "grad_norm": 0.23295952379703522,
      "learning_rate": 4.596808601416503e-05,
      "loss": 0.0034,
      "step": 1890
    },
    {
      "epoch": 0.162129874562676,
      "grad_norm": 0.614521324634552,
      "learning_rate": 4.5946753135933104e-05,
      "loss": 0.0024,
      "step": 1900
    },
    {
      "epoch": 0.16298318969195325,
      "grad_norm": 0.5579568147659302,
      "learning_rate": 4.5925420257701176e-05,
      "loss": 0.0032,
      "step": 1910
    },
    {
      "epoch": 0.1638365048212305,
      "grad_norm": 0.521301805973053,
      "learning_rate": 4.590408737946924e-05,
      "loss": 0.0033,
      "step": 1920
    },
    {
      "epoch": 0.16468981995050772,
      "grad_norm": 1.2637540102005005,
      "learning_rate": 4.5882754501237304e-05,
      "loss": 0.0028,
      "step": 1930
    },
    {
      "epoch": 0.16554313507978496,
      "grad_norm": 0.506543755531311,
      "learning_rate": 4.586142162300538e-05,
      "loss": 0.0031,
      "step": 1940
    },
    {
      "epoch": 0.1663964502090622,
      "grad_norm": 0.4887154698371887,
      "learning_rate": 4.584008874477345e-05,
      "loss": 0.0033,
      "step": 1950
    },
    {
      "epoch": 0.16724976533833946,
      "grad_norm": 0.7331807017326355,
      "learning_rate": 4.581875586654152e-05,
      "loss": 0.0026,
      "step": 1960
    },
    {
      "epoch": 0.16810308046761668,
      "grad_norm": 1.0229028463363647,
      "learning_rate": 4.579742298830958e-05,
      "loss": 0.0045,
      "step": 1970
    },
    {
      "epoch": 0.16895639559689393,
      "grad_norm": 0.5734522342681885,
      "learning_rate": 4.5776090110077654e-05,
      "loss": 0.0039,
      "step": 1980
    },
    {
      "epoch": 0.16980971072617118,
      "grad_norm": 0.5321812033653259,
      "learning_rate": 4.5754757231845725e-05,
      "loss": 0.004,
      "step": 1990
    },
    {
      "epoch": 0.17066302585544843,
      "grad_norm": 1.3210512399673462,
      "learning_rate": 4.573342435361379e-05,
      "loss": 0.0041,
      "step": 2000
    },
    {
      "epoch": 0.17151634098472565,
      "grad_norm": 0.41987141966819763,
      "learning_rate": 4.571209147538186e-05,
      "loss": 0.0036,
      "step": 2010
    },
    {
      "epoch": 0.1723696561140029,
      "grad_norm": 1.0265045166015625,
      "learning_rate": 4.569075859714993e-05,
      "loss": 0.0035,
      "step": 2020
    },
    {
      "epoch": 0.17322297124328015,
      "grad_norm": 0.7090888023376465,
      "learning_rate": 4.5669425718917996e-05,
      "loss": 0.0046,
      "step": 2030
    },
    {
      "epoch": 0.1740762863725574,
      "grad_norm": 0.6122565269470215,
      "learning_rate": 4.564809284068607e-05,
      "loss": 0.0031,
      "step": 2040
    },
    {
      "epoch": 0.17492960150183462,
      "grad_norm": 0.5295788645744324,
      "learning_rate": 4.562675996245414e-05,
      "loss": 0.0036,
      "step": 2050
    },
    {
      "epoch": 0.17578291663111187,
      "grad_norm": 0.35701504349708557,
      "learning_rate": 4.560542708422221e-05,
      "loss": 0.0032,
      "step": 2060
    },
    {
      "epoch": 0.17663623176038912,
      "grad_norm": 0.7170298099517822,
      "learning_rate": 4.5584094205990274e-05,
      "loss": 0.003,
      "step": 2070
    },
    {
      "epoch": 0.17748954688966637,
      "grad_norm": 0.48360535502433777,
      "learning_rate": 4.556276132775834e-05,
      "loss": 0.004,
      "step": 2080
    },
    {
      "epoch": 0.1783428620189436,
      "grad_norm": 0.2998022139072418,
      "learning_rate": 4.554142844952641e-05,
      "loss": 0.004,
      "step": 2090
    },
    {
      "epoch": 0.17919617714822084,
      "grad_norm": 1.6010982990264893,
      "learning_rate": 4.552009557129448e-05,
      "loss": 0.0041,
      "step": 2100
    },
    {
      "epoch": 0.18004949227749809,
      "grad_norm": 0.5603145956993103,
      "learning_rate": 4.549876269306255e-05,
      "loss": 0.0032,
      "step": 2110
    },
    {
      "epoch": 0.18090280740677533,
      "grad_norm": 0.3822663128376007,
      "learning_rate": 4.547742981483062e-05,
      "loss": 0.0031,
      "step": 2120
    },
    {
      "epoch": 0.18175612253605256,
      "grad_norm": 0.4404664933681488,
      "learning_rate": 4.545609693659869e-05,
      "loss": 0.0035,
      "step": 2130
    },
    {
      "epoch": 0.1826094376653298,
      "grad_norm": 0.5668055415153503,
      "learning_rate": 4.543476405836676e-05,
      "loss": 0.0033,
      "step": 2140
    },
    {
      "epoch": 0.18346275279460705,
      "grad_norm": 0.6089852452278137,
      "learning_rate": 4.5413431180134824e-05,
      "loss": 0.0036,
      "step": 2150
    },
    {
      "epoch": 0.1843160679238843,
      "grad_norm": 0.6820828318595886,
      "learning_rate": 4.5392098301902895e-05,
      "loss": 0.0028,
      "step": 2160
    },
    {
      "epoch": 0.18516938305316152,
      "grad_norm": 0.3841858208179474,
      "learning_rate": 4.5370765423670966e-05,
      "loss": 0.0035,
      "step": 2170
    },
    {
      "epoch": 0.18602269818243877,
      "grad_norm": 0.36201560497283936,
      "learning_rate": 4.534943254543903e-05,
      "loss": 0.0035,
      "step": 2180
    },
    {
      "epoch": 0.18687601331171602,
      "grad_norm": 0.6166860461235046,
      "learning_rate": 4.53280996672071e-05,
      "loss": 0.0038,
      "step": 2190
    },
    {
      "epoch": 0.18772932844099327,
      "grad_norm": 0.43660637736320496,
      "learning_rate": 4.5306766788975166e-05,
      "loss": 0.0033,
      "step": 2200
    },
    {
      "epoch": 0.1885826435702705,
      "grad_norm": 0.7627169489860535,
      "learning_rate": 4.5285433910743244e-05,
      "loss": 0.003,
      "step": 2210
    },
    {
      "epoch": 0.18943595869954774,
      "grad_norm": 0.6448982954025269,
      "learning_rate": 4.526410103251131e-05,
      "loss": 0.0039,
      "step": 2220
    },
    {
      "epoch": 0.190289273828825,
      "grad_norm": 0.6493468284606934,
      "learning_rate": 4.524276815427938e-05,
      "loss": 0.0034,
      "step": 2230
    },
    {
      "epoch": 0.19114258895810224,
      "grad_norm": 0.3957110345363617,
      "learning_rate": 4.5221435276047444e-05,
      "loss": 0.0033,
      "step": 2240
    },
    {
      "epoch": 0.19199590408737946,
      "grad_norm": 0.7819162011146545,
      "learning_rate": 4.5200102397815515e-05,
      "loss": 0.0027,
      "step": 2250
    },
    {
      "epoch": 0.1928492192166567,
      "grad_norm": 0.8508107662200928,
      "learning_rate": 4.5178769519583586e-05,
      "loss": 0.004,
      "step": 2260
    },
    {
      "epoch": 0.19370253434593396,
      "grad_norm": 0.6315616965293884,
      "learning_rate": 4.515743664135165e-05,
      "loss": 0.004,
      "step": 2270
    },
    {
      "epoch": 0.1945558494752112,
      "grad_norm": 0.8920135498046875,
      "learning_rate": 4.513610376311972e-05,
      "loss": 0.0035,
      "step": 2280
    },
    {
      "epoch": 0.19540916460448843,
      "grad_norm": 0.6317455172538757,
      "learning_rate": 4.511477088488779e-05,
      "loss": 0.0036,
      "step": 2290
    },
    {
      "epoch": 0.19626247973376568,
      "grad_norm": 1.1644271612167358,
      "learning_rate": 4.509343800665586e-05,
      "loss": 0.0036,
      "step": 2300
    },
    {
      "epoch": 0.19711579486304293,
      "grad_norm": 0.45883384346961975,
      "learning_rate": 4.507210512842393e-05,
      "loss": 0.0034,
      "step": 2310
    },
    {
      "epoch": 0.19796910999232017,
      "grad_norm": 0.7765164375305176,
      "learning_rate": 4.5050772250192e-05,
      "loss": 0.0035,
      "step": 2320
    },
    {
      "epoch": 0.1988224251215974,
      "grad_norm": 0.4247483015060425,
      "learning_rate": 4.502943937196007e-05,
      "loss": 0.0032,
      "step": 2330
    },
    {
      "epoch": 0.19967574025087464,
      "grad_norm": 0.4628179669380188,
      "learning_rate": 4.5008106493728136e-05,
      "loss": 0.0033,
      "step": 2340
    },
    {
      "epoch": 0.2005290553801519,
      "grad_norm": 0.4812142252922058,
      "learning_rate": 4.49867736154962e-05,
      "loss": 0.0033,
      "step": 2350
    },
    {
      "epoch": 0.20138237050942914,
      "grad_norm": 0.40030649304389954,
      "learning_rate": 4.496544073726428e-05,
      "loss": 0.0032,
      "step": 2360
    },
    {
      "epoch": 0.20223568563870636,
      "grad_norm": 0.5413777232170105,
      "learning_rate": 4.494410785903234e-05,
      "loss": 0.0032,
      "step": 2370
    },
    {
      "epoch": 0.2030890007679836,
      "grad_norm": 0.4822765290737152,
      "learning_rate": 4.4922774980800414e-05,
      "loss": 0.0028,
      "step": 2380
    },
    {
      "epoch": 0.20394231589726086,
      "grad_norm": 0.49941888451576233,
      "learning_rate": 4.490144210256848e-05,
      "loss": 0.0042,
      "step": 2390
    },
    {
      "epoch": 0.2047956310265381,
      "grad_norm": 0.6154882311820984,
      "learning_rate": 4.488010922433655e-05,
      "loss": 0.0034,
      "step": 2400
    },
    {
      "epoch": 0.20564894615581533,
      "grad_norm": 1.257270097732544,
      "learning_rate": 4.485877634610462e-05,
      "loss": 0.0036,
      "step": 2410
    },
    {
      "epoch": 0.20650226128509258,
      "grad_norm": 0.7061453461647034,
      "learning_rate": 4.4837443467872685e-05,
      "loss": 0.0037,
      "step": 2420
    },
    {
      "epoch": 0.20735557641436983,
      "grad_norm": 0.8640087246894836,
      "learning_rate": 4.4816110589640756e-05,
      "loss": 0.0031,
      "step": 2430
    },
    {
      "epoch": 0.20820889154364708,
      "grad_norm": 0.3701867163181305,
      "learning_rate": 4.479477771140883e-05,
      "loss": 0.0035,
      "step": 2440
    },
    {
      "epoch": 0.2090622066729243,
      "grad_norm": 0.34577926993370056,
      "learning_rate": 4.477344483317689e-05,
      "loss": 0.0033,
      "step": 2450
    },
    {
      "epoch": 0.20991552180220155,
      "grad_norm": 0.6586609482765198,
      "learning_rate": 4.475211195494496e-05,
      "loss": 0.0039,
      "step": 2460
    },
    {
      "epoch": 0.2107688369314788,
      "grad_norm": 0.47223401069641113,
      "learning_rate": 4.473077907671303e-05,
      "loss": 0.0028,
      "step": 2470
    },
    {
      "epoch": 0.21162215206075605,
      "grad_norm": 1.0937912464141846,
      "learning_rate": 4.4709446198481106e-05,
      "loss": 0.0032,
      "step": 2480
    },
    {
      "epoch": 0.21247546719003327,
      "grad_norm": 0.6188139319419861,
      "learning_rate": 4.468811332024917e-05,
      "loss": 0.0036,
      "step": 2490
    },
    {
      "epoch": 0.21332878231931052,
      "grad_norm": 0.86819988489151,
      "learning_rate": 4.4666780442017234e-05,
      "loss": 0.0034,
      "step": 2500
    },
    {
      "epoch": 0.21418209744858777,
      "grad_norm": 0.6113542318344116,
      "learning_rate": 4.4645447563785306e-05,
      "loss": 0.003,
      "step": 2510
    },
    {
      "epoch": 0.21503541257786501,
      "grad_norm": 0.94761723279953,
      "learning_rate": 4.462411468555338e-05,
      "loss": 0.003,
      "step": 2520
    },
    {
      "epoch": 0.21588872770714224,
      "grad_norm": 0.6714048385620117,
      "learning_rate": 4.460278180732145e-05,
      "loss": 0.0031,
      "step": 2530
    },
    {
      "epoch": 0.21674204283641949,
      "grad_norm": 0.509688675403595,
      "learning_rate": 4.458144892908951e-05,
      "loss": 0.0036,
      "step": 2540
    },
    {
      "epoch": 0.21759535796569673,
      "grad_norm": 0.3306552767753601,
      "learning_rate": 4.4560116050857584e-05,
      "loss": 0.0033,
      "step": 2550
    },
    {
      "epoch": 0.21844867309497398,
      "grad_norm": 0.6869361996650696,
      "learning_rate": 4.4538783172625655e-05,
      "loss": 0.003,
      "step": 2560
    },
    {
      "epoch": 0.2193019882242512,
      "grad_norm": 1.250944972038269,
      "learning_rate": 4.451745029439372e-05,
      "loss": 0.003,
      "step": 2570
    },
    {
      "epoch": 0.22015530335352845,
      "grad_norm": 0.6607838869094849,
      "learning_rate": 4.449611741616179e-05,
      "loss": 0.0035,
      "step": 2580
    },
    {
      "epoch": 0.2210086184828057,
      "grad_norm": 0.493567556142807,
      "learning_rate": 4.447478453792986e-05,
      "loss": 0.0032,
      "step": 2590
    },
    {
      "epoch": 0.22186193361208295,
      "grad_norm": 0.40690872073173523,
      "learning_rate": 4.445345165969793e-05,
      "loss": 0.0032,
      "step": 2600
    },
    {
      "epoch": 0.22271524874136017,
      "grad_norm": 0.36663833260536194,
      "learning_rate": 4.4432118781466e-05,
      "loss": 0.0029,
      "step": 2610
    },
    {
      "epoch": 0.22356856387063742,
      "grad_norm": 0.484401673078537,
      "learning_rate": 4.441078590323406e-05,
      "loss": 0.0028,
      "step": 2620
    },
    {
      "epoch": 0.22442187899991467,
      "grad_norm": 0.30792906880378723,
      "learning_rate": 4.438945302500214e-05,
      "loss": 0.0031,
      "step": 2630
    },
    {
      "epoch": 0.22527519412919192,
      "grad_norm": 1.4850027561187744,
      "learning_rate": 4.4368120146770204e-05,
      "loss": 0.0033,
      "step": 2640
    },
    {
      "epoch": 0.22612850925846914,
      "grad_norm": 0.48069778084754944,
      "learning_rate": 4.4346787268538275e-05,
      "loss": 0.0034,
      "step": 2650
    },
    {
      "epoch": 0.2269818243877464,
      "grad_norm": 0.6464304327964783,
      "learning_rate": 4.432545439030634e-05,
      "loss": 0.003,
      "step": 2660
    },
    {
      "epoch": 0.22783513951702364,
      "grad_norm": 1.4179824590682983,
      "learning_rate": 4.430412151207441e-05,
      "loss": 0.0035,
      "step": 2670
    },
    {
      "epoch": 0.2286884546463009,
      "grad_norm": 1.038554310798645,
      "learning_rate": 4.428278863384248e-05,
      "loss": 0.0035,
      "step": 2680
    },
    {
      "epoch": 0.2295417697755781,
      "grad_norm": 0.547406792640686,
      "learning_rate": 4.426145575561055e-05,
      "loss": 0.0031,
      "step": 2690
    },
    {
      "epoch": 0.23039508490485536,
      "grad_norm": 0.4279618263244629,
      "learning_rate": 4.424012287737862e-05,
      "loss": 0.0029,
      "step": 2700
    },
    {
      "epoch": 0.2312484000341326,
      "grad_norm": 0.5159862637519836,
      "learning_rate": 4.421878999914669e-05,
      "loss": 0.0035,
      "step": 2710
    },
    {
      "epoch": 0.23210171516340986,
      "grad_norm": 0.41935643553733826,
      "learning_rate": 4.4197457120914753e-05,
      "loss": 0.0037,
      "step": 2720
    },
    {
      "epoch": 0.23295503029268708,
      "grad_norm": 1.2563591003417969,
      "learning_rate": 4.4176124242682825e-05,
      "loss": 0.0029,
      "step": 2730
    },
    {
      "epoch": 0.23380834542196433,
      "grad_norm": 1.073738694190979,
      "learning_rate": 4.4154791364450896e-05,
      "loss": 0.0033,
      "step": 2740
    },
    {
      "epoch": 0.23466166055124157,
      "grad_norm": 0.4732429087162018,
      "learning_rate": 4.413345848621897e-05,
      "loss": 0.0028,
      "step": 2750
    },
    {
      "epoch": 0.23551497568051882,
      "grad_norm": 0.41758453845977783,
      "learning_rate": 4.411212560798703e-05,
      "loss": 0.0038,
      "step": 2760
    },
    {
      "epoch": 0.23636829080979604,
      "grad_norm": 1.1953566074371338,
      "learning_rate": 4.4090792729755096e-05,
      "loss": 0.004,
      "step": 2770
    },
    {
      "epoch": 0.2372216059390733,
      "grad_norm": 0.7051584720611572,
      "learning_rate": 4.406945985152317e-05,
      "loss": 0.0042,
      "step": 2780
    },
    {
      "epoch": 0.23807492106835054,
      "grad_norm": 0.9450438022613525,
      "learning_rate": 4.404812697329124e-05,
      "loss": 0.0034,
      "step": 2790
    },
    {
      "epoch": 0.2389282361976278,
      "grad_norm": 0.7913540005683899,
      "learning_rate": 4.402679409505931e-05,
      "loss": 0.0031,
      "step": 2800
    },
    {
      "epoch": 0.239781551326905,
      "grad_norm": 0.8833714127540588,
      "learning_rate": 4.4005461216827374e-05,
      "loss": 0.0035,
      "step": 2810
    },
    {
      "epoch": 0.24063486645618226,
      "grad_norm": 1.1028070449829102,
      "learning_rate": 4.3984128338595445e-05,
      "loss": 0.0041,
      "step": 2820
    },
    {
      "epoch": 0.2414881815854595,
      "grad_norm": 1.4005894660949707,
      "learning_rate": 4.3962795460363516e-05,
      "loss": 0.0038,
      "step": 2830
    },
    {
      "epoch": 0.24234149671473676,
      "grad_norm": 0.6358906030654907,
      "learning_rate": 4.394146258213158e-05,
      "loss": 0.0031,
      "step": 2840
    },
    {
      "epoch": 0.24319481184401398,
      "grad_norm": 0.5494458079338074,
      "learning_rate": 4.392012970389965e-05,
      "loss": 0.0032,
      "step": 2850
    },
    {
      "epoch": 0.24404812697329123,
      "grad_norm": 0.49103349447250366,
      "learning_rate": 4.389879682566772e-05,
      "loss": 0.0028,
      "step": 2860
    },
    {
      "epoch": 0.24490144210256848,
      "grad_norm": 0.584831178188324,
      "learning_rate": 4.387746394743579e-05,
      "loss": 0.0028,
      "step": 2870
    },
    {
      "epoch": 0.24575475723184573,
      "grad_norm": 0.9617826342582703,
      "learning_rate": 4.385613106920386e-05,
      "loss": 0.0033,
      "step": 2880
    },
    {
      "epoch": 0.24660807236112298,
      "grad_norm": 1.2500793933868408,
      "learning_rate": 4.383479819097192e-05,
      "loss": 0.0029,
      "step": 2890
    },
    {
      "epoch": 0.2474613874904002,
      "grad_norm": 0.9461565613746643,
      "learning_rate": 4.381346531274e-05,
      "loss": 0.0039,
      "step": 2900
    },
    {
      "epoch": 0.24831470261967745,
      "grad_norm": 0.7366710305213928,
      "learning_rate": 4.3792132434508066e-05,
      "loss": 0.0033,
      "step": 2910
    },
    {
      "epoch": 0.2491680177489547,
      "grad_norm": 0.41395625472068787,
      "learning_rate": 4.377079955627614e-05,
      "loss": 0.0035,
      "step": 2920
    },
    {
      "epoch": 0.2500213328782319,
      "grad_norm": 0.5438581705093384,
      "learning_rate": 4.37494666780442e-05,
      "loss": 0.0032,
      "step": 2930
    },
    {
      "epoch": 0.2508746480075092,
      "grad_norm": 0.9019702076911926,
      "learning_rate": 4.372813379981227e-05,
      "loss": 0.003,
      "step": 2940
    },
    {
      "epoch": 0.2517279631367864,
      "grad_norm": 0.7974106669425964,
      "learning_rate": 4.3706800921580344e-05,
      "loss": 0.0027,
      "step": 2950
    },
    {
      "epoch": 0.25258127826606364,
      "grad_norm": 0.4844851791858673,
      "learning_rate": 4.368546804334841e-05,
      "loss": 0.003,
      "step": 2960
    },
    {
      "epoch": 0.2534345933953409,
      "grad_norm": 0.5313310027122498,
      "learning_rate": 4.366413516511648e-05,
      "loss": 0.0032,
      "step": 2970
    },
    {
      "epoch": 0.25428790852461813,
      "grad_norm": 0.45664337277412415,
      "learning_rate": 4.364280228688455e-05,
      "loss": 0.0027,
      "step": 2980
    },
    {
      "epoch": 0.2551412236538954,
      "grad_norm": 0.4130775034427643,
      "learning_rate": 4.3621469408652615e-05,
      "loss": 0.0026,
      "step": 2990
    },
    {
      "epoch": 0.25599453878317263,
      "grad_norm": 0.9757259488105774,
      "learning_rate": 4.3600136530420686e-05,
      "loss": 0.0032,
      "step": 3000
    },
    {
      "epoch": 0.25684785391244985,
      "grad_norm": 1.424363136291504,
      "learning_rate": 4.357880365218876e-05,
      "loss": 0.0032,
      "step": 3010
    },
    {
      "epoch": 0.25770116904172713,
      "grad_norm": 0.6007434129714966,
      "learning_rate": 4.355747077395683e-05,
      "loss": 0.0037,
      "step": 3020
    },
    {
      "epoch": 0.25855448417100435,
      "grad_norm": 0.7983487844467163,
      "learning_rate": 4.353613789572489e-05,
      "loss": 0.003,
      "step": 3030
    },
    {
      "epoch": 0.25940779930028157,
      "grad_norm": 1.5405975580215454,
      "learning_rate": 4.351480501749296e-05,
      "loss": 0.0034,
      "step": 3040
    },
    {
      "epoch": 0.26026111442955885,
      "grad_norm": 1.7255232334136963,
      "learning_rate": 4.3493472139261035e-05,
      "loss": 0.0036,
      "step": 3050
    },
    {
      "epoch": 0.26111442955883607,
      "grad_norm": 1.4180763959884644,
      "learning_rate": 4.34721392610291e-05,
      "loss": 0.0036,
      "step": 3060
    },
    {
      "epoch": 0.26196774468811335,
      "grad_norm": 0.45467737317085266,
      "learning_rate": 4.345080638279717e-05,
      "loss": 0.0037,
      "step": 3070
    },
    {
      "epoch": 0.26282105981739057,
      "grad_norm": 0.4818494915962219,
      "learning_rate": 4.3429473504565236e-05,
      "loss": 0.0029,
      "step": 3080
    },
    {
      "epoch": 0.2636743749466678,
      "grad_norm": 0.4723193049430847,
      "learning_rate": 4.340814062633331e-05,
      "loss": 0.0034,
      "step": 3090
    },
    {
      "epoch": 0.26452769007594507,
      "grad_norm": 1.306296944618225,
      "learning_rate": 4.338680774810138e-05,
      "loss": 0.0035,
      "step": 3100
    },
    {
      "epoch": 0.2653810052052223,
      "grad_norm": 1.1421338319778442,
      "learning_rate": 4.336547486986944e-05,
      "loss": 0.0041,
      "step": 3110
    },
    {
      "epoch": 0.2662343203344995,
      "grad_norm": 0.8158200979232788,
      "learning_rate": 4.3344141991637514e-05,
      "loss": 0.0037,
      "step": 3120
    },
    {
      "epoch": 0.2670876354637768,
      "grad_norm": 0.31344902515411377,
      "learning_rate": 4.3322809113405585e-05,
      "loss": 0.0031,
      "step": 3130
    },
    {
      "epoch": 0.267940950593054,
      "grad_norm": 0.5690497159957886,
      "learning_rate": 4.330147623517365e-05,
      "loss": 0.0032,
      "step": 3140
    },
    {
      "epoch": 0.2687942657223313,
      "grad_norm": 0.3011581599712372,
      "learning_rate": 4.328014335694172e-05,
      "loss": 0.0039,
      "step": 3150
    },
    {
      "epoch": 0.2696475808516085,
      "grad_norm": 0.8837097883224487,
      "learning_rate": 4.3258810478709785e-05,
      "loss": 0.0035,
      "step": 3160
    },
    {
      "epoch": 0.2705008959808857,
      "grad_norm": 0.9140869975090027,
      "learning_rate": 4.323747760047786e-05,
      "loss": 0.0042,
      "step": 3170
    },
    {
      "epoch": 0.271354211110163,
      "grad_norm": 0.5796574354171753,
      "learning_rate": 4.321614472224593e-05,
      "loss": 0.0032,
      "step": 3180
    },
    {
      "epoch": 0.2722075262394402,
      "grad_norm": 0.5749656558036804,
      "learning_rate": 4.319481184401399e-05,
      "loss": 0.0029,
      "step": 3190
    },
    {
      "epoch": 0.27306084136871744,
      "grad_norm": 0.4063461720943451,
      "learning_rate": 4.317347896578206e-05,
      "loss": 0.0034,
      "step": 3200
    },
    {
      "epoch": 0.2739141564979947,
      "grad_norm": 0.6107733845710754,
      "learning_rate": 4.3152146087550134e-05,
      "loss": 0.0041,
      "step": 3210
    },
    {
      "epoch": 0.27476747162727194,
      "grad_norm": 0.6148707866668701,
      "learning_rate": 4.3130813209318205e-05,
      "loss": 0.003,
      "step": 3220
    },
    {
      "epoch": 0.2756207867565492,
      "grad_norm": 0.7773070931434631,
      "learning_rate": 4.310948033108627e-05,
      "loss": 0.0036,
      "step": 3230
    },
    {
      "epoch": 0.27647410188582644,
      "grad_norm": 0.29193115234375,
      "learning_rate": 4.308814745285434e-05,
      "loss": 0.0034,
      "step": 3240
    },
    {
      "epoch": 0.27732741701510366,
      "grad_norm": 0.4570556581020355,
      "learning_rate": 4.306681457462241e-05,
      "loss": 0.003,
      "step": 3250
    },
    {
      "epoch": 0.27818073214438094,
      "grad_norm": 0.9564114212989807,
      "learning_rate": 4.3045481696390477e-05,
      "loss": 0.0034,
      "step": 3260
    },
    {
      "epoch": 0.27903404727365816,
      "grad_norm": 1.063006043434143,
      "learning_rate": 4.302414881815855e-05,
      "loss": 0.0029,
      "step": 3270
    },
    {
      "epoch": 0.2798873624029354,
      "grad_norm": 0.7468780279159546,
      "learning_rate": 4.300281593992662e-05,
      "loss": 0.0038,
      "step": 3280
    },
    {
      "epoch": 0.28074067753221266,
      "grad_norm": 0.8244661688804626,
      "learning_rate": 4.298148306169469e-05,
      "loss": 0.0035,
      "step": 3290
    },
    {
      "epoch": 0.2815939926614899,
      "grad_norm": 0.5851455330848694,
      "learning_rate": 4.2960150183462755e-05,
      "loss": 0.0036,
      "step": 3300
    },
    {
      "epoch": 0.28244730779076715,
      "grad_norm": 0.7973712086677551,
      "learning_rate": 4.293881730523082e-05,
      "loss": 0.0032,
      "step": 3310
    },
    {
      "epoch": 0.2833006229200444,
      "grad_norm": 0.6045618653297424,
      "learning_rate": 4.29174844269989e-05,
      "loss": 0.0038,
      "step": 3320
    },
    {
      "epoch": 0.2841539380493216,
      "grad_norm": 0.7761490941047668,
      "learning_rate": 4.289615154876696e-05,
      "loss": 0.0043,
      "step": 3330
    },
    {
      "epoch": 0.2850072531785989,
      "grad_norm": 0.7104026079177856,
      "learning_rate": 4.287481867053503e-05,
      "loss": 0.0037,
      "step": 3340
    },
    {
      "epoch": 0.2858605683078761,
      "grad_norm": 0.5362383127212524,
      "learning_rate": 4.28534857923031e-05,
      "loss": 0.0037,
      "step": 3350
    },
    {
      "epoch": 0.2867138834371533,
      "grad_norm": 0.9696562886238098,
      "learning_rate": 4.283215291407117e-05,
      "loss": 0.0031,
      "step": 3360
    },
    {
      "epoch": 0.2875671985664306,
      "grad_norm": 1.1255284547805786,
      "learning_rate": 4.281082003583924e-05,
      "loss": 0.0032,
      "step": 3370
    },
    {
      "epoch": 0.2884205136957078,
      "grad_norm": 1.424850583076477,
      "learning_rate": 4.2789487157607304e-05,
      "loss": 0.0032,
      "step": 3380
    },
    {
      "epoch": 0.2892738288249851,
      "grad_norm": 0.5927885174751282,
      "learning_rate": 4.2768154279375375e-05,
      "loss": 0.0032,
      "step": 3390
    },
    {
      "epoch": 0.2901271439542623,
      "grad_norm": 0.8958282470703125,
      "learning_rate": 4.2746821401143446e-05,
      "loss": 0.0031,
      "step": 3400
    },
    {
      "epoch": 0.29098045908353953,
      "grad_norm": 0.6929870247840881,
      "learning_rate": 4.272548852291151e-05,
      "loss": 0.003,
      "step": 3410
    },
    {
      "epoch": 0.2918337742128168,
      "grad_norm": 0.45315083861351013,
      "learning_rate": 4.270415564467958e-05,
      "loss": 0.0033,
      "step": 3420
    },
    {
      "epoch": 0.29268708934209403,
      "grad_norm": 0.3654528260231018,
      "learning_rate": 4.268282276644765e-05,
      "loss": 0.0034,
      "step": 3430
    },
    {
      "epoch": 0.29354040447137125,
      "grad_norm": 0.4445076882839203,
      "learning_rate": 4.2661489888215724e-05,
      "loss": 0.0034,
      "step": 3440
    },
    {
      "epoch": 0.29439371960064853,
      "grad_norm": 0.8703927397727966,
      "learning_rate": 4.264015700998379e-05,
      "loss": 0.0034,
      "step": 3450
    },
    {
      "epoch": 0.29524703472992575,
      "grad_norm": 0.6296826004981995,
      "learning_rate": 4.261882413175185e-05,
      "loss": 0.0034,
      "step": 3460
    },
    {
      "epoch": 0.296100349859203,
      "grad_norm": 0.4459213614463806,
      "learning_rate": 4.2597491253519924e-05,
      "loss": 0.0025,
      "step": 3470
    },
    {
      "epoch": 0.29695366498848025,
      "grad_norm": 1.0380666255950928,
      "learning_rate": 4.2576158375287996e-05,
      "loss": 0.0026,
      "step": 3480
    },
    {
      "epoch": 0.29780698011775747,
      "grad_norm": 0.3188144266605377,
      "learning_rate": 4.255482549705607e-05,
      "loss": 0.0032,
      "step": 3490
    },
    {
      "epoch": 0.29866029524703475,
      "grad_norm": 0.7979175448417664,
      "learning_rate": 4.253349261882413e-05,
      "loss": 0.0033,
      "step": 3500
    },
    {
      "epoch": 0.29951361037631197,
      "grad_norm": 0.8913633227348328,
      "learning_rate": 4.25121597405922e-05,
      "loss": 0.0029,
      "step": 3510
    },
    {
      "epoch": 0.3003669255055892,
      "grad_norm": 0.5490108132362366,
      "learning_rate": 4.2490826862360274e-05,
      "loss": 0.0035,
      "step": 3520
    },
    {
      "epoch": 0.30122024063486647,
      "grad_norm": 1.8311285972595215,
      "learning_rate": 4.246949398412834e-05,
      "loss": 0.0031,
      "step": 3530
    },
    {
      "epoch": 0.3020735557641437,
      "grad_norm": 0.9189788103103638,
      "learning_rate": 4.244816110589641e-05,
      "loss": 0.004,
      "step": 3540
    },
    {
      "epoch": 0.30292687089342096,
      "grad_norm": 0.5676734447479248,
      "learning_rate": 4.242682822766448e-05,
      "loss": 0.0035,
      "step": 3550
    },
    {
      "epoch": 0.3037801860226982,
      "grad_norm": 0.47096601128578186,
      "learning_rate": 4.240549534943255e-05,
      "loss": 0.0028,
      "step": 3560
    },
    {
      "epoch": 0.3046335011519754,
      "grad_norm": 0.8675179481506348,
      "learning_rate": 4.2384162471200616e-05,
      "loss": 0.0032,
      "step": 3570
    },
    {
      "epoch": 0.3054868162812527,
      "grad_norm": 0.7465551495552063,
      "learning_rate": 4.236282959296868e-05,
      "loss": 0.0036,
      "step": 3580
    },
    {
      "epoch": 0.3063401314105299,
      "grad_norm": 0.7106583714485168,
      "learning_rate": 4.234149671473676e-05,
      "loss": 0.0031,
      "step": 3590
    },
    {
      "epoch": 0.3071934465398071,
      "grad_norm": 0.8832566142082214,
      "learning_rate": 4.232016383650482e-05,
      "loss": 0.0034,
      "step": 3600
    },
    {
      "epoch": 0.3080467616690844,
      "grad_norm": 1.036128044128418,
      "learning_rate": 4.2298830958272894e-05,
      "loss": 0.0034,
      "step": 3610
    },
    {
      "epoch": 0.3089000767983616,
      "grad_norm": 0.7990121245384216,
      "learning_rate": 4.227749808004096e-05,
      "loss": 0.0029,
      "step": 3620
    },
    {
      "epoch": 0.3097533919276389,
      "grad_norm": 0.40706050395965576,
      "learning_rate": 4.225616520180903e-05,
      "loss": 0.0034,
      "step": 3630
    },
    {
      "epoch": 0.3106067070569161,
      "grad_norm": 0.9055794477462769,
      "learning_rate": 4.22348323235771e-05,
      "loss": 0.0036,
      "step": 3640
    },
    {
      "epoch": 0.31146002218619334,
      "grad_norm": 0.48888757824897766,
      "learning_rate": 4.2213499445345165e-05,
      "loss": 0.0034,
      "step": 3650
    },
    {
      "epoch": 0.3123133373154706,
      "grad_norm": 0.5165049433708191,
      "learning_rate": 4.219216656711324e-05,
      "loss": 0.0035,
      "step": 3660
    },
    {
      "epoch": 0.31316665244474784,
      "grad_norm": 0.5425270199775696,
      "learning_rate": 4.217083368888131e-05,
      "loss": 0.0029,
      "step": 3670
    },
    {
      "epoch": 0.31401996757402506,
      "grad_norm": 0.7368423938751221,
      "learning_rate": 4.214950081064937e-05,
      "loss": 0.0034,
      "step": 3680
    },
    {
      "epoch": 0.31487328270330234,
      "grad_norm": 0.31692323088645935,
      "learning_rate": 4.2128167932417443e-05,
      "loss": 0.004,
      "step": 3690
    },
    {
      "epoch": 0.31572659783257956,
      "grad_norm": 0.5855145454406738,
      "learning_rate": 4.2106835054185515e-05,
      "loss": 0.0026,
      "step": 3700
    },
    {
      "epoch": 0.31657991296185684,
      "grad_norm": 0.5578538179397583,
      "learning_rate": 4.2085502175953586e-05,
      "loss": 0.0028,
      "step": 3710
    },
    {
      "epoch": 0.31743322809113406,
      "grad_norm": 0.5756290555000305,
      "learning_rate": 4.206416929772165e-05,
      "loss": 0.0028,
      "step": 3720
    },
    {
      "epoch": 0.3182865432204113,
      "grad_norm": 0.4780801236629486,
      "learning_rate": 4.2042836419489715e-05,
      "loss": 0.0034,
      "step": 3730
    },
    {
      "epoch": 0.31913985834968855,
      "grad_norm": 0.643983781337738,
      "learning_rate": 4.202150354125779e-05,
      "loss": 0.0041,
      "step": 3740
    },
    {
      "epoch": 0.3199931734789658,
      "grad_norm": 1.0589097738265991,
      "learning_rate": 4.200017066302586e-05,
      "loss": 0.0031,
      "step": 3750
    },
    {
      "epoch": 0.320846488608243,
      "grad_norm": 1.0359266996383667,
      "learning_rate": 4.197883778479393e-05,
      "loss": 0.0039,
      "step": 3760
    },
    {
      "epoch": 0.3216998037375203,
      "grad_norm": 0.9169808030128479,
      "learning_rate": 4.195750490656199e-05,
      "loss": 0.0035,
      "step": 3770
    },
    {
      "epoch": 0.3225531188667975,
      "grad_norm": 0.43898358941078186,
      "learning_rate": 4.1936172028330064e-05,
      "loss": 0.0033,
      "step": 3780
    },
    {
      "epoch": 0.32340643399607477,
      "grad_norm": 1.079075813293457,
      "learning_rate": 4.1914839150098135e-05,
      "loss": 0.0037,
      "step": 3790
    },
    {
      "epoch": 0.324259749125352,
      "grad_norm": 0.4173274338245392,
      "learning_rate": 4.18935062718662e-05,
      "loss": 0.0035,
      "step": 3800
    },
    {
      "epoch": 0.3251130642546292,
      "grad_norm": 0.4913158714771271,
      "learning_rate": 4.187217339363427e-05,
      "loss": 0.0035,
      "step": 3810
    },
    {
      "epoch": 0.3259663793839065,
      "grad_norm": 0.9665558934211731,
      "learning_rate": 4.185084051540234e-05,
      "loss": 0.0029,
      "step": 3820
    },
    {
      "epoch": 0.3268196945131837,
      "grad_norm": 0.6936064958572388,
      "learning_rate": 4.1829507637170406e-05,
      "loss": 0.0034,
      "step": 3830
    },
    {
      "epoch": 0.327673009642461,
      "grad_norm": 0.4144343435764313,
      "learning_rate": 4.180817475893848e-05,
      "loss": 0.0029,
      "step": 3840
    },
    {
      "epoch": 0.3285263247717382,
      "grad_norm": 0.7381332516670227,
      "learning_rate": 4.178684188070654e-05,
      "loss": 0.0032,
      "step": 3850
    },
    {
      "epoch": 0.32937963990101543,
      "grad_norm": 0.48312118649482727,
      "learning_rate": 4.176550900247462e-05,
      "loss": 0.0035,
      "step": 3860
    },
    {
      "epoch": 0.3302329550302927,
      "grad_norm": 0.5749539732933044,
      "learning_rate": 4.1744176124242685e-05,
      "loss": 0.003,
      "step": 3870
    },
    {
      "epoch": 0.33108627015956993,
      "grad_norm": 1.1967449188232422,
      "learning_rate": 4.172284324601075e-05,
      "loss": 0.0035,
      "step": 3880
    },
    {
      "epoch": 0.33193958528884715,
      "grad_norm": 0.41315701603889465,
      "learning_rate": 4.170151036777882e-05,
      "loss": 0.0036,
      "step": 3890
    },
    {
      "epoch": 0.3327929004181244,
      "grad_norm": 0.5574028491973877,
      "learning_rate": 4.168017748954689e-05,
      "loss": 0.0024,
      "step": 3900
    },
    {
      "epoch": 0.33364621554740165,
      "grad_norm": 0.49843257665634155,
      "learning_rate": 4.165884461131496e-05,
      "loss": 0.0035,
      "step": 3910
    },
    {
      "epoch": 0.3344995306766789,
      "grad_norm": 0.81097811460495,
      "learning_rate": 4.163751173308303e-05,
      "loss": 0.0038,
      "step": 3920
    },
    {
      "epoch": 0.33535284580595615,
      "grad_norm": 1.0992611646652222,
      "learning_rate": 4.16161788548511e-05,
      "loss": 0.0032,
      "step": 3930
    },
    {
      "epoch": 0.33620616093523337,
      "grad_norm": 0.39292779564857483,
      "learning_rate": 4.159484597661917e-05,
      "loss": 0.0037,
      "step": 3940
    },
    {
      "epoch": 0.33705947606451064,
      "grad_norm": 0.5431693196296692,
      "learning_rate": 4.1573513098387234e-05,
      "loss": 0.0038,
      "step": 3950
    },
    {
      "epoch": 0.33791279119378786,
      "grad_norm": 0.7553396224975586,
      "learning_rate": 4.1552180220155305e-05,
      "loss": 0.0034,
      "step": 3960
    },
    {
      "epoch": 0.3387661063230651,
      "grad_norm": 0.5779066681861877,
      "learning_rate": 4.1530847341923376e-05,
      "loss": 0.0036,
      "step": 3970
    },
    {
      "epoch": 0.33961942145234236,
      "grad_norm": 1.154732346534729,
      "learning_rate": 4.150951446369145e-05,
      "loss": 0.0034,
      "step": 3980
    },
    {
      "epoch": 0.3404727365816196,
      "grad_norm": 0.5863949060440063,
      "learning_rate": 4.148818158545951e-05,
      "loss": 0.0034,
      "step": 3990
    },
    {
      "epoch": 0.34132605171089686,
      "grad_norm": 0.7103731036186218,
      "learning_rate": 4.1466848707227576e-05,
      "loss": 0.0034,
      "step": 4000
    },
    {
      "epoch": 0.3421793668401741,
      "grad_norm": 0.9311535358428955,
      "learning_rate": 4.1445515828995654e-05,
      "loss": 0.0032,
      "step": 4010
    },
    {
      "epoch": 0.3430326819694513,
      "grad_norm": 0.408223420381546,
      "learning_rate": 4.142418295076372e-05,
      "loss": 0.0032,
      "step": 4020
    },
    {
      "epoch": 0.3438859970987286,
      "grad_norm": 0.7396490573883057,
      "learning_rate": 4.140285007253179e-05,
      "loss": 0.0036,
      "step": 4030
    },
    {
      "epoch": 0.3447393122280058,
      "grad_norm": 0.5698219537734985,
      "learning_rate": 4.1381517194299854e-05,
      "loss": 0.0029,
      "step": 4040
    },
    {
      "epoch": 0.345592627357283,
      "grad_norm": 0.5121170282363892,
      "learning_rate": 4.1360184316067926e-05,
      "loss": 0.0028,
      "step": 4050
    },
    {
      "epoch": 0.3464459424865603,
      "grad_norm": 0.5336513519287109,
      "learning_rate": 4.1338851437836e-05,
      "loss": 0.003,
      "step": 4060
    },
    {
      "epoch": 0.3472992576158375,
      "grad_norm": 0.7016482353210449,
      "learning_rate": 4.131751855960406e-05,
      "loss": 0.003,
      "step": 4070
    },
    {
      "epoch": 0.3481525727451148,
      "grad_norm": 0.36029472947120667,
      "learning_rate": 4.129618568137213e-05,
      "loss": 0.0037,
      "step": 4080
    },
    {
      "epoch": 0.349005887874392,
      "grad_norm": 1.1221041679382324,
      "learning_rate": 4.1274852803140204e-05,
      "loss": 0.0035,
      "step": 4090
    },
    {
      "epoch": 0.34985920300366924,
      "grad_norm": 0.625659704208374,
      "learning_rate": 4.125351992490827e-05,
      "loss": 0.0032,
      "step": 4100
    },
    {
      "epoch": 0.3507125181329465,
      "grad_norm": 1.2842236757278442,
      "learning_rate": 4.123218704667634e-05,
      "loss": 0.0039,
      "step": 4110
    },
    {
      "epoch": 0.35156583326222374,
      "grad_norm": 1.117317795753479,
      "learning_rate": 4.121085416844441e-05,
      "loss": 0.0039,
      "step": 4120
    },
    {
      "epoch": 0.35241914839150096,
      "grad_norm": 0.5357447266578674,
      "learning_rate": 4.118952129021248e-05,
      "loss": 0.0035,
      "step": 4130
    },
    {
      "epoch": 0.35327246352077823,
      "grad_norm": 1.2590371370315552,
      "learning_rate": 4.1168188411980546e-05,
      "loss": 0.0029,
      "step": 4140
    },
    {
      "epoch": 0.35412577865005546,
      "grad_norm": 0.41012778878211975,
      "learning_rate": 4.114685553374861e-05,
      "loss": 0.003,
      "step": 4150
    },
    {
      "epoch": 0.35497909377933273,
      "grad_norm": 0.5556837320327759,
      "learning_rate": 4.112552265551668e-05,
      "loss": 0.0031,
      "step": 4160
    },
    {
      "epoch": 0.35583240890860995,
      "grad_norm": 0.5379500985145569,
      "learning_rate": 4.110418977728475e-05,
      "loss": 0.0031,
      "step": 4170
    },
    {
      "epoch": 0.3566857240378872,
      "grad_norm": 1.1186602115631104,
      "learning_rate": 4.1082856899052824e-05,
      "loss": 0.0034,
      "step": 4180
    },
    {
      "epoch": 0.35753903916716445,
      "grad_norm": 0.3647712171077728,
      "learning_rate": 4.106152402082089e-05,
      "loss": 0.0037,
      "step": 4190
    },
    {
      "epoch": 0.3583923542964417,
      "grad_norm": 0.30052709579467773,
      "learning_rate": 4.104019114258896e-05,
      "loss": 0.0026,
      "step": 4200
    },
    {
      "epoch": 0.3592456694257189,
      "grad_norm": 0.7714018821716309,
      "learning_rate": 4.101885826435703e-05,
      "loss": 0.0025,
      "step": 4210
    },
    {
      "epoch": 0.36009898455499617,
      "grad_norm": 0.24900874495506287,
      "learning_rate": 4.0997525386125095e-05,
      "loss": 0.0025,
      "step": 4220
    },
    {
      "epoch": 0.3609522996842734,
      "grad_norm": 1.1249116659164429,
      "learning_rate": 4.0976192507893167e-05,
      "loss": 0.0032,
      "step": 4230
    },
    {
      "epoch": 0.36180561481355067,
      "grad_norm": 0.7738421559333801,
      "learning_rate": 4.095485962966124e-05,
      "loss": 0.0035,
      "step": 4240
    },
    {
      "epoch": 0.3626589299428279,
      "grad_norm": 0.381069153547287,
      "learning_rate": 4.093352675142931e-05,
      "loss": 0.003,
      "step": 4250
    },
    {
      "epoch": 0.3635122450721051,
      "grad_norm": 0.5608282089233398,
      "learning_rate": 4.0912193873197373e-05,
      "loss": 0.0031,
      "step": 4260
    },
    {
      "epoch": 0.3643655602013824,
      "grad_norm": 0.686169445514679,
      "learning_rate": 4.089086099496544e-05,
      "loss": 0.0033,
      "step": 4270
    },
    {
      "epoch": 0.3652188753306596,
      "grad_norm": 1.5671608448028564,
      "learning_rate": 4.0869528116733516e-05,
      "loss": 0.0033,
      "step": 4280
    },
    {
      "epoch": 0.36607219045993683,
      "grad_norm": 0.39263999462127686,
      "learning_rate": 4.084819523850158e-05,
      "loss": 0.0039,
      "step": 4290
    },
    {
      "epoch": 0.3669255055892141,
      "grad_norm": 1.5693663358688354,
      "learning_rate": 4.082686236026965e-05,
      "loss": 0.0031,
      "step": 4300
    },
    {
      "epoch": 0.36777882071849133,
      "grad_norm": 0.5926860570907593,
      "learning_rate": 4.0805529482037716e-05,
      "loss": 0.0031,
      "step": 4310
    },
    {
      "epoch": 0.3686321358477686,
      "grad_norm": 0.3058932423591614,
      "learning_rate": 4.078419660380579e-05,
      "loss": 0.0036,
      "step": 4320
    },
    {
      "epoch": 0.3694854509770458,
      "grad_norm": 0.5332676768302917,
      "learning_rate": 4.076286372557386e-05,
      "loss": 0.0032,
      "step": 4330
    },
    {
      "epoch": 0.37033876610632305,
      "grad_norm": 0.3891308307647705,
      "learning_rate": 4.074153084734192e-05,
      "loss": 0.0029,
      "step": 4340
    },
    {
      "epoch": 0.3711920812356003,
      "grad_norm": 0.38026919960975647,
      "learning_rate": 4.0720197969109994e-05,
      "loss": 0.0035,
      "step": 4350
    },
    {
      "epoch": 0.37204539636487755,
      "grad_norm": 1.1475712060928345,
      "learning_rate": 4.0698865090878065e-05,
      "loss": 0.0034,
      "step": 4360
    },
    {
      "epoch": 0.37289871149415477,
      "grad_norm": 0.4646157920360565,
      "learning_rate": 4.067753221264613e-05,
      "loss": 0.0036,
      "step": 4370
    },
    {
      "epoch": 0.37375202662343204,
      "grad_norm": 0.4010958969593048,
      "learning_rate": 4.06561993344142e-05,
      "loss": 0.0032,
      "step": 4380
    },
    {
      "epoch": 0.37460534175270926,
      "grad_norm": 0.7318801879882812,
      "learning_rate": 4.063486645618227e-05,
      "loss": 0.0036,
      "step": 4390
    },
    {
      "epoch": 0.37545865688198654,
      "grad_norm": 0.5208026170730591,
      "learning_rate": 4.061353357795034e-05,
      "loss": 0.0033,
      "step": 4400
    },
    {
      "epoch": 0.37631197201126376,
      "grad_norm": 0.3472996950149536,
      "learning_rate": 4.059220069971841e-05,
      "loss": 0.0033,
      "step": 4410
    },
    {
      "epoch": 0.377165287140541,
      "grad_norm": 1.4177829027175903,
      "learning_rate": 4.057086782148647e-05,
      "loss": 0.0033,
      "step": 4420
    },
    {
      "epoch": 0.37801860226981826,
      "grad_norm": 1.061428189277649,
      "learning_rate": 4.054953494325455e-05,
      "loss": 0.0037,
      "step": 4430
    },
    {
      "epoch": 0.3788719173990955,
      "grad_norm": 0.5539542436599731,
      "learning_rate": 4.0528202065022614e-05,
      "loss": 0.0033,
      "step": 4440
    },
    {
      "epoch": 0.3797252325283727,
      "grad_norm": 0.5456284880638123,
      "learning_rate": 4.0506869186790686e-05,
      "loss": 0.0031,
      "step": 4450
    },
    {
      "epoch": 0.38057854765765,
      "grad_norm": 0.609743595123291,
      "learning_rate": 4.048553630855875e-05,
      "loss": 0.0035,
      "step": 4460
    },
    {
      "epoch": 0.3814318627869272,
      "grad_norm": 0.5169225931167603,
      "learning_rate": 4.046420343032682e-05,
      "loss": 0.0027,
      "step": 4470
    },
    {
      "epoch": 0.3822851779162045,
      "grad_norm": 0.7082913517951965,
      "learning_rate": 4.044287055209489e-05,
      "loss": 0.0027,
      "step": 4480
    },
    {
      "epoch": 0.3831384930454817,
      "grad_norm": 1.421338438987732,
      "learning_rate": 4.042153767386296e-05,
      "loss": 0.0028,
      "step": 4490
    },
    {
      "epoch": 0.3839918081747589,
      "grad_norm": 0.814626157283783,
      "learning_rate": 4.040020479563103e-05,
      "loss": 0.0031,
      "step": 4500
    },
    {
      "epoch": 0.3848451233040362,
      "grad_norm": 0.5186693668365479,
      "learning_rate": 4.03788719173991e-05,
      "loss": 0.004,
      "step": 4510
    },
    {
      "epoch": 0.3856984384333134,
      "grad_norm": 0.30475282669067383,
      "learning_rate": 4.0357539039167164e-05,
      "loss": 0.0032,
      "step": 4520
    },
    {
      "epoch": 0.38655175356259064,
      "grad_norm": 0.7710021734237671,
      "learning_rate": 4.0336206160935235e-05,
      "loss": 0.0025,
      "step": 4530
    },
    {
      "epoch": 0.3874050686918679,
      "grad_norm": 0.8559244871139526,
      "learning_rate": 4.03148732827033e-05,
      "loss": 0.0037,
      "step": 4540
    },
    {
      "epoch": 0.38825838382114514,
      "grad_norm": 0.718881368637085,
      "learning_rate": 4.029354040447138e-05,
      "loss": 0.0036,
      "step": 4550
    },
    {
      "epoch": 0.3891116989504224,
      "grad_norm": 0.9058042764663696,
      "learning_rate": 4.027220752623944e-05,
      "loss": 0.0034,
      "step": 4560
    },
    {
      "epoch": 0.38996501407969963,
      "grad_norm": 0.32746586203575134,
      "learning_rate": 4.025087464800751e-05,
      "loss": 0.0037,
      "step": 4570
    },
    {
      "epoch": 0.39081832920897686,
      "grad_norm": 0.676544725894928,
      "learning_rate": 4.022954176977558e-05,
      "loss": 0.0036,
      "step": 4580
    },
    {
      "epoch": 0.39167164433825413,
      "grad_norm": 0.38714590668678284,
      "learning_rate": 4.020820889154365e-05,
      "loss": 0.0039,
      "step": 4590
    },
    {
      "epoch": 0.39252495946753135,
      "grad_norm": 0.6245841383934021,
      "learning_rate": 4.018687601331172e-05,
      "loss": 0.0028,
      "step": 4600
    },
    {
      "epoch": 0.3933782745968086,
      "grad_norm": 0.3227762281894684,
      "learning_rate": 4.0165543135079784e-05,
      "loss": 0.0036,
      "step": 4610
    },
    {
      "epoch": 0.39423158972608585,
      "grad_norm": 0.6635826826095581,
      "learning_rate": 4.0144210256847855e-05,
      "loss": 0.0029,
      "step": 4620
    },
    {
      "epoch": 0.3950849048553631,
      "grad_norm": 0.3653724193572998,
      "learning_rate": 4.012287737861593e-05,
      "loss": 0.0028,
      "step": 4630
    },
    {
      "epoch": 0.39593821998464035,
      "grad_norm": 0.45890629291534424,
      "learning_rate": 4.010154450038399e-05,
      "loss": 0.0034,
      "step": 4640
    },
    {
      "epoch": 0.39679153511391757,
      "grad_norm": 0.496588796377182,
      "learning_rate": 4.008021162215206e-05,
      "loss": 0.0036,
      "step": 4650
    },
    {
      "epoch": 0.3976448502431948,
      "grad_norm": 0.4548465609550476,
      "learning_rate": 4.0058878743920134e-05,
      "loss": 0.0034,
      "step": 4660
    },
    {
      "epoch": 0.39849816537247207,
      "grad_norm": 0.817298412322998,
      "learning_rate": 4.0037545865688205e-05,
      "loss": 0.0037,
      "step": 4670
    },
    {
      "epoch": 0.3993514805017493,
      "grad_norm": 0.8299728035926819,
      "learning_rate": 4.001621298745627e-05,
      "loss": 0.0038,
      "step": 4680
    },
    {
      "epoch": 0.4002047956310265,
      "grad_norm": 0.7582594156265259,
      "learning_rate": 3.9994880109224334e-05,
      "loss": 0.0039,
      "step": 4690
    },
    {
      "epoch": 0.4010581107603038,
      "grad_norm": 0.3677942156791687,
      "learning_rate": 3.997354723099241e-05,
      "loss": 0.0029,
      "step": 4700
    },
    {
      "epoch": 0.401911425889581,
      "grad_norm": 0.3507147431373596,
      "learning_rate": 3.9952214352760476e-05,
      "loss": 0.0029,
      "step": 4710
    },
    {
      "epoch": 0.4027647410188583,
      "grad_norm": 0.2984364628791809,
      "learning_rate": 3.993088147452855e-05,
      "loss": 0.003,
      "step": 4720
    },
    {
      "epoch": 0.4036180561481355,
      "grad_norm": 0.6377894282341003,
      "learning_rate": 3.990954859629661e-05,
      "loss": 0.0025,
      "step": 4730
    },
    {
      "epoch": 0.40447137127741273,
      "grad_norm": 0.9928591251373291,
      "learning_rate": 3.988821571806468e-05,
      "loss": 0.0029,
      "step": 4740
    },
    {
      "epoch": 0.40532468640669,
      "grad_norm": 0.4523872137069702,
      "learning_rate": 3.9866882839832754e-05,
      "loss": 0.0029,
      "step": 4750
    },
    {
      "epoch": 0.4061780015359672,
      "grad_norm": 0.5267877578735352,
      "learning_rate": 3.984554996160082e-05,
      "loss": 0.0035,
      "step": 4760
    },
    {
      "epoch": 0.4070313166652445,
      "grad_norm": 0.29283663630485535,
      "learning_rate": 3.982421708336889e-05,
      "loss": 0.0033,
      "step": 4770
    },
    {
      "epoch": 0.4078846317945217,
      "grad_norm": 1.106972575187683,
      "learning_rate": 3.980288420513696e-05,
      "loss": 0.0036,
      "step": 4780
    },
    {
      "epoch": 0.40873794692379894,
      "grad_norm": 0.7604977488517761,
      "learning_rate": 3.9781551326905025e-05,
      "loss": 0.0031,
      "step": 4790
    },
    {
      "epoch": 0.4095912620530762,
      "grad_norm": 0.7723094820976257,
      "learning_rate": 3.9760218448673097e-05,
      "loss": 0.0042,
      "step": 4800
    },
    {
      "epoch": 0.41044457718235344,
      "grad_norm": 0.9181318283081055,
      "learning_rate": 3.973888557044117e-05,
      "loss": 0.0029,
      "step": 4810
    },
    {
      "epoch": 0.41129789231163066,
      "grad_norm": 0.3206421136856079,
      "learning_rate": 3.971755269220924e-05,
      "loss": 0.0042,
      "step": 4820
    },
    {
      "epoch": 0.41215120744090794,
      "grad_norm": 1.1037492752075195,
      "learning_rate": 3.96962198139773e-05,
      "loss": 0.0035,
      "step": 4830
    },
    {
      "epoch": 0.41300452257018516,
      "grad_norm": 0.4397643506526947,
      "learning_rate": 3.967488693574537e-05,
      "loss": 0.0037,
      "step": 4840
    },
    {
      "epoch": 0.41385783769946244,
      "grad_norm": 0.6872718334197998,
      "learning_rate": 3.965355405751344e-05,
      "loss": 0.0035,
      "step": 4850
    },
    {
      "epoch": 0.41471115282873966,
      "grad_norm": 1.4043904542922974,
      "learning_rate": 3.963222117928151e-05,
      "loss": 0.0031,
      "step": 4860
    },
    {
      "epoch": 0.4155644679580169,
      "grad_norm": 0.4773804545402527,
      "learning_rate": 3.961088830104958e-05,
      "loss": 0.0032,
      "step": 4870
    },
    {
      "epoch": 0.41641778308729416,
      "grad_norm": 0.6407593488693237,
      "learning_rate": 3.9589555422817646e-05,
      "loss": 0.0034,
      "step": 4880
    },
    {
      "epoch": 0.4172710982165714,
      "grad_norm": 0.5022746324539185,
      "learning_rate": 3.956822254458572e-05,
      "loss": 0.0035,
      "step": 4890
    },
    {
      "epoch": 0.4181244133458486,
      "grad_norm": 0.44151169061660767,
      "learning_rate": 3.954688966635379e-05,
      "loss": 0.0035,
      "step": 4900
    },
    {
      "epoch": 0.4189777284751259,
      "grad_norm": 0.6821951270103455,
      "learning_rate": 3.952555678812185e-05,
      "loss": 0.0032,
      "step": 4910
    },
    {
      "epoch": 0.4198310436044031,
      "grad_norm": 1.0127735137939453,
      "learning_rate": 3.9504223909889924e-05,
      "loss": 0.0036,
      "step": 4920
    },
    {
      "epoch": 0.4206843587336804,
      "grad_norm": 0.30338290333747864,
      "learning_rate": 3.9482891031657995e-05,
      "loss": 0.0032,
      "step": 4930
    },
    {
      "epoch": 0.4215376738629576,
      "grad_norm": 0.3114473521709442,
      "learning_rate": 3.9461558153426066e-05,
      "loss": 0.0035,
      "step": 4940
    },
    {
      "epoch": 0.4223909889922348,
      "grad_norm": 0.3833343982696533,
      "learning_rate": 3.944022527519413e-05,
      "loss": 0.003,
      "step": 4950
    },
    {
      "epoch": 0.4232443041215121,
      "grad_norm": 0.6635791659355164,
      "learning_rate": 3.9418892396962195e-05,
      "loss": 0.0023,
      "step": 4960
    },
    {
      "epoch": 0.4240976192507893,
      "grad_norm": 0.39053478837013245,
      "learning_rate": 3.939755951873027e-05,
      "loss": 0.0037,
      "step": 4970
    },
    {
      "epoch": 0.42495093438006654,
      "grad_norm": 0.5773816704750061,
      "learning_rate": 3.937622664049834e-05,
      "loss": 0.003,
      "step": 4980
    },
    {
      "epoch": 0.4258042495093438,
      "grad_norm": 0.4964667558670044,
      "learning_rate": 3.935489376226641e-05,
      "loss": 0.0036,
      "step": 4990
    },
    {
      "epoch": 0.42665756463862103,
      "grad_norm": 1.2288895845413208,
      "learning_rate": 3.933356088403447e-05,
      "loss": 0.0041,
      "step": 5000
    },
    {
      "epoch": 0.4275108797678983,
      "grad_norm": 0.9338062405586243,
      "learning_rate": 3.9312228005802544e-05,
      "loss": 0.0031,
      "step": 5010
    },
    {
      "epoch": 0.42836419489717553,
      "grad_norm": 0.7520895600318909,
      "learning_rate": 3.9290895127570616e-05,
      "loss": 0.0031,
      "step": 5020
    },
    {
      "epoch": 0.42921751002645275,
      "grad_norm": 0.8635531067848206,
      "learning_rate": 3.926956224933868e-05,
      "loss": 0.0034,
      "step": 5030
    },
    {
      "epoch": 0.43007082515573003,
      "grad_norm": 0.7738524079322815,
      "learning_rate": 3.924822937110675e-05,
      "loss": 0.0037,
      "step": 5040
    },
    {
      "epoch": 0.43092414028500725,
      "grad_norm": 0.555303692817688,
      "learning_rate": 3.922689649287482e-05,
      "loss": 0.0035,
      "step": 5050
    },
    {
      "epoch": 0.4317774554142845,
      "grad_norm": 0.36464014649391174,
      "learning_rate": 3.920556361464289e-05,
      "loss": 0.0039,
      "step": 5060
    },
    {
      "epoch": 0.43263077054356175,
      "grad_norm": 1.6343756914138794,
      "learning_rate": 3.918423073641096e-05,
      "loss": 0.0029,
      "step": 5070
    },
    {
      "epoch": 0.43348408567283897,
      "grad_norm": 0.5824400186538696,
      "learning_rate": 3.916289785817903e-05,
      "loss": 0.0032,
      "step": 5080
    },
    {
      "epoch": 0.43433740080211625,
      "grad_norm": 0.6107860207557678,
      "learning_rate": 3.91415649799471e-05,
      "loss": 0.0037,
      "step": 5090
    },
    {
      "epoch": 0.43519071593139347,
      "grad_norm": 1.1541509628295898,
      "learning_rate": 3.9120232101715165e-05,
      "loss": 0.0037,
      "step": 5100
    },
    {
      "epoch": 0.4360440310606707,
      "grad_norm": 0.3178420662879944,
      "learning_rate": 3.909889922348323e-05,
      "loss": 0.0028,
      "step": 5110
    },
    {
      "epoch": 0.43689734618994797,
      "grad_norm": 0.32140445709228516,
      "learning_rate": 3.907756634525131e-05,
      "loss": 0.0029,
      "step": 5120
    },
    {
      "epoch": 0.4377506613192252,
      "grad_norm": 0.9395124316215515,
      "learning_rate": 3.905623346701937e-05,
      "loss": 0.0043,
      "step": 5130
    },
    {
      "epoch": 0.4386039764485024,
      "grad_norm": 0.6023940443992615,
      "learning_rate": 3.903490058878744e-05,
      "loss": 0.0036,
      "step": 5140
    },
    {
      "epoch": 0.4394572915777797,
      "grad_norm": 0.5754569172859192,
      "learning_rate": 3.901356771055551e-05,
      "loss": 0.0032,
      "step": 5150
    },
    {
      "epoch": 0.4403106067070569,
      "grad_norm": 0.767876148223877,
      "learning_rate": 3.899223483232358e-05,
      "loss": 0.003,
      "step": 5160
    },
    {
      "epoch": 0.4411639218363342,
      "grad_norm": 0.5806188583374023,
      "learning_rate": 3.897090195409165e-05,
      "loss": 0.0032,
      "step": 5170
    },
    {
      "epoch": 0.4420172369656114,
      "grad_norm": 0.28498706221580505,
      "learning_rate": 3.8949569075859714e-05,
      "loss": 0.0035,
      "step": 5180
    },
    {
      "epoch": 0.4428705520948886,
      "grad_norm": 0.46956586837768555,
      "learning_rate": 3.8928236197627785e-05,
      "loss": 0.0031,
      "step": 5190
    },
    {
      "epoch": 0.4437238672241659,
      "grad_norm": 0.4763587713241577,
      "learning_rate": 3.8906903319395857e-05,
      "loss": 0.0031,
      "step": 5200
    },
    {
      "epoch": 0.4445771823534431,
      "grad_norm": 0.44868502020835876,
      "learning_rate": 3.888557044116392e-05,
      "loss": 0.003,
      "step": 5210
    },
    {
      "epoch": 0.44543049748272034,
      "grad_norm": 0.542168915271759,
      "learning_rate": 3.886423756293199e-05,
      "loss": 0.0029,
      "step": 5220
    },
    {
      "epoch": 0.4462838126119976,
      "grad_norm": 0.9485021829605103,
      "learning_rate": 3.884290468470006e-05,
      "loss": 0.0039,
      "step": 5230
    },
    {
      "epoch": 0.44713712774127484,
      "grad_norm": 0.6584538817405701,
      "learning_rate": 3.8821571806468135e-05,
      "loss": 0.0035,
      "step": 5240
    },
    {
      "epoch": 0.4479904428705521,
      "grad_norm": 0.5437449812889099,
      "learning_rate": 3.88002389282362e-05,
      "loss": 0.003,
      "step": 5250
    },
    {
      "epoch": 0.44884375799982934,
      "grad_norm": 0.4418143928050995,
      "learning_rate": 3.877890605000427e-05,
      "loss": 0.0026,
      "step": 5260
    },
    {
      "epoch": 0.44969707312910656,
      "grad_norm": 0.850822925567627,
      "learning_rate": 3.8757573171772335e-05,
      "loss": 0.0026,
      "step": 5270
    },
    {
      "epoch": 0.45055038825838384,
      "grad_norm": 0.9608656167984009,
      "learning_rate": 3.8736240293540406e-05,
      "loss": 0.0034,
      "step": 5280
    },
    {
      "epoch": 0.45140370338766106,
      "grad_norm": 0.5783033967018127,
      "learning_rate": 3.871490741530848e-05,
      "loss": 0.0036,
      "step": 5290
    },
    {
      "epoch": 0.4522570185169383,
      "grad_norm": 0.3592212498188019,
      "learning_rate": 3.869357453707654e-05,
      "loss": 0.0027,
      "step": 5300
    },
    {
      "epoch": 0.45311033364621556,
      "grad_norm": 0.5160397887229919,
      "learning_rate": 3.867224165884461e-05,
      "loss": 0.0027,
      "step": 5310
    },
    {
      "epoch": 0.4539636487754928,
      "grad_norm": 0.9809336066246033,
      "learning_rate": 3.8650908780612684e-05,
      "loss": 0.0031,
      "step": 5320
    },
    {
      "epoch": 0.45481696390477006,
      "grad_norm": 0.4741017818450928,
      "learning_rate": 3.862957590238075e-05,
      "loss": 0.004,
      "step": 5330
    },
    {
      "epoch": 0.4556702790340473,
      "grad_norm": 0.6611291766166687,
      "learning_rate": 3.860824302414882e-05,
      "loss": 0.0035,
      "step": 5340
    },
    {
      "epoch": 0.4565235941633245,
      "grad_norm": 1.3415933847427368,
      "learning_rate": 3.858691014591689e-05,
      "loss": 0.0035,
      "step": 5350
    },
    {
      "epoch": 0.4573769092926018,
      "grad_norm": 0.5078350305557251,
      "learning_rate": 3.856557726768496e-05,
      "loss": 0.0035,
      "step": 5360
    },
    {
      "epoch": 0.458230224421879,
      "grad_norm": 0.5533518195152283,
      "learning_rate": 3.8544244389453026e-05,
      "loss": 0.003,
      "step": 5370
    },
    {
      "epoch": 0.4590835395511562,
      "grad_norm": 0.8998861908912659,
      "learning_rate": 3.852291151122109e-05,
      "loss": 0.0027,
      "step": 5380
    },
    {
      "epoch": 0.4599368546804335,
      "grad_norm": 0.5879747271537781,
      "learning_rate": 3.850157863298917e-05,
      "loss": 0.0029,
      "step": 5390
    },
    {
      "epoch": 0.4607901698097107,
      "grad_norm": 0.49561989307403564,
      "learning_rate": 3.848024575475723e-05,
      "loss": 0.0041,
      "step": 5400
    },
    {
      "epoch": 0.461643484938988,
      "grad_norm": 0.7732048034667969,
      "learning_rate": 3.8458912876525304e-05,
      "loss": 0.0037,
      "step": 5410
    },
    {
      "epoch": 0.4624968000682652,
      "grad_norm": 0.516526997089386,
      "learning_rate": 3.843757999829337e-05,
      "loss": 0.003,
      "step": 5420
    },
    {
      "epoch": 0.46335011519754243,
      "grad_norm": 0.6859993934631348,
      "learning_rate": 3.841624712006144e-05,
      "loss": 0.0029,
      "step": 5430
    },
    {
      "epoch": 0.4642034303268197,
      "grad_norm": 0.4107242524623871,
      "learning_rate": 3.839491424182951e-05,
      "loss": 0.0028,
      "step": 5440
    },
    {
      "epoch": 0.46505674545609693,
      "grad_norm": 0.6753810048103333,
      "learning_rate": 3.8373581363597576e-05,
      "loss": 0.0029,
      "step": 5450
    },
    {
      "epoch": 0.46591006058537415,
      "grad_norm": 0.5162524580955505,
      "learning_rate": 3.835224848536565e-05,
      "loss": 0.003,
      "step": 5460
    },
    {
      "epoch": 0.46676337571465143,
      "grad_norm": 0.6918936371803284,
      "learning_rate": 3.833091560713372e-05,
      "loss": 0.0035,
      "step": 5470
    },
    {
      "epoch": 0.46761669084392865,
      "grad_norm": 0.3593950569629669,
      "learning_rate": 3.830958272890178e-05,
      "loss": 0.003,
      "step": 5480
    },
    {
      "epoch": 0.4684700059732059,
      "grad_norm": 0.5969321727752686,
      "learning_rate": 3.8288249850669854e-05,
      "loss": 0.0032,
      "step": 5490
    },
    {
      "epoch": 0.46932332110248315,
      "grad_norm": 0.3427925705909729,
      "learning_rate": 3.8266916972437925e-05,
      "loss": 0.0036,
      "step": 5500
    },
    {
      "epoch": 0.47017663623176037,
      "grad_norm": 1.1649366617202759,
      "learning_rate": 3.8245584094205996e-05,
      "loss": 0.0034,
      "step": 5510
    },
    {
      "epoch": 0.47102995136103765,
      "grad_norm": 0.9327993988990784,
      "learning_rate": 3.822425121597406e-05,
      "loss": 0.0034,
      "step": 5520
    },
    {
      "epoch": 0.47188326649031487,
      "grad_norm": 1.3285263776779175,
      "learning_rate": 3.8202918337742125e-05,
      "loss": 0.0027,
      "step": 5530
    },
    {
      "epoch": 0.4727365816195921,
      "grad_norm": 0.5186344385147095,
      "learning_rate": 3.8181585459510196e-05,
      "loss": 0.0033,
      "step": 5540
    },
    {
      "epoch": 0.47358989674886937,
      "grad_norm": 1.035983681678772,
      "learning_rate": 3.816025258127827e-05,
      "loss": 0.0028,
      "step": 5550
    },
    {
      "epoch": 0.4744432118781466,
      "grad_norm": 1.4280009269714355,
      "learning_rate": 3.813891970304634e-05,
      "loss": 0.0029,
      "step": 5560
    },
    {
      "epoch": 0.47529652700742386,
      "grad_norm": 1.463999629020691,
      "learning_rate": 3.81175868248144e-05,
      "loss": 0.0032,
      "step": 5570
    },
    {
      "epoch": 0.4761498421367011,
      "grad_norm": 1.2810728549957275,
      "learning_rate": 3.8096253946582474e-05,
      "loss": 0.0035,
      "step": 5580
    },
    {
      "epoch": 0.4770031572659783,
      "grad_norm": 0.8746594190597534,
      "learning_rate": 3.8074921068350546e-05,
      "loss": 0.0029,
      "step": 5590
    },
    {
      "epoch": 0.4778564723952556,
      "grad_norm": 0.2251310497522354,
      "learning_rate": 3.805358819011861e-05,
      "loss": 0.003,
      "step": 5600
    },
    {
      "epoch": 0.4787097875245328,
      "grad_norm": 0.38672399520874023,
      "learning_rate": 3.803225531188668e-05,
      "loss": 0.0033,
      "step": 5610
    },
    {
      "epoch": 0.47956310265381,
      "grad_norm": 0.26648446917533875,
      "learning_rate": 3.801092243365475e-05,
      "loss": 0.0029,
      "step": 5620
    },
    {
      "epoch": 0.4804164177830873,
      "grad_norm": 0.9458388090133667,
      "learning_rate": 3.7989589555422824e-05,
      "loss": 0.0027,
      "step": 5630
    },
    {
      "epoch": 0.4812697329123645,
      "grad_norm": 0.4887259006500244,
      "learning_rate": 3.796825667719089e-05,
      "loss": 0.0028,
      "step": 5640
    },
    {
      "epoch": 0.4821230480416418,
      "grad_norm": 0.6772838830947876,
      "learning_rate": 3.794692379895895e-05,
      "loss": 0.0032,
      "step": 5650
    },
    {
      "epoch": 0.482976363170919,
      "grad_norm": 0.505025327205658,
      "learning_rate": 3.792559092072703e-05,
      "loss": 0.0028,
      "step": 5660
    },
    {
      "epoch": 0.48382967830019624,
      "grad_norm": 0.45988142490386963,
      "learning_rate": 3.7904258042495095e-05,
      "loss": 0.0035,
      "step": 5670
    },
    {
      "epoch": 0.4846829934294735,
      "grad_norm": 1.4514409303665161,
      "learning_rate": 3.7882925164263166e-05,
      "loss": 0.0026,
      "step": 5680
    },
    {
      "epoch": 0.48553630855875074,
      "grad_norm": 0.7831383943557739,
      "learning_rate": 3.786159228603123e-05,
      "loss": 0.0034,
      "step": 5690
    },
    {
      "epoch": 0.48638962368802796,
      "grad_norm": 0.37176018953323364,
      "learning_rate": 3.78402594077993e-05,
      "loss": 0.0033,
      "step": 5700
    },
    {
      "epoch": 0.48724293881730524,
      "grad_norm": 0.5658966898918152,
      "learning_rate": 3.781892652956737e-05,
      "loss": 0.0039,
      "step": 5710
    },
    {
      "epoch": 0.48809625394658246,
      "grad_norm": 0.32718488574028015,
      "learning_rate": 3.779759365133544e-05,
      "loss": 0.0036,
      "step": 5720
    },
    {
      "epoch": 0.48894956907585974,
      "grad_norm": 0.5984398722648621,
      "learning_rate": 3.777626077310351e-05,
      "loss": 0.0031,
      "step": 5730
    },
    {
      "epoch": 0.48980288420513696,
      "grad_norm": 0.7129507064819336,
      "learning_rate": 3.775492789487158e-05,
      "loss": 0.0029,
      "step": 5740
    },
    {
      "epoch": 0.4906561993344142,
      "grad_norm": 0.36475780606269836,
      "learning_rate": 3.7733595016639644e-05,
      "loss": 0.0036,
      "step": 5750
    },
    {
      "epoch": 0.49150951446369145,
      "grad_norm": 0.7017833590507507,
      "learning_rate": 3.7712262138407715e-05,
      "loss": 0.0028,
      "step": 5760
    },
    {
      "epoch": 0.4923628295929687,
      "grad_norm": 0.3422900140285492,
      "learning_rate": 3.7690929260175787e-05,
      "loss": 0.003,
      "step": 5770
    },
    {
      "epoch": 0.49321614472224595,
      "grad_norm": 0.7342694997787476,
      "learning_rate": 3.766959638194386e-05,
      "loss": 0.0032,
      "step": 5780
    },
    {
      "epoch": 0.4940694598515232,
      "grad_norm": 0.5363355278968811,
      "learning_rate": 3.764826350371192e-05,
      "loss": 0.0033,
      "step": 5790
    },
    {
      "epoch": 0.4949227749808004,
      "grad_norm": 0.5498247146606445,
      "learning_rate": 3.7626930625479987e-05,
      "loss": 0.0035,
      "step": 5800
    },
    {
      "epoch": 0.49577609011007767,
      "grad_norm": 0.7856852412223816,
      "learning_rate": 3.7605597747248065e-05,
      "loss": 0.0035,
      "step": 5810
    },
    {
      "epoch": 0.4966294052393549,
      "grad_norm": 0.5127819180488586,
      "learning_rate": 3.758426486901613e-05,
      "loss": 0.0037,
      "step": 5820
    },
    {
      "epoch": 0.4974827203686321,
      "grad_norm": 0.7538268566131592,
      "learning_rate": 3.75629319907842e-05,
      "loss": 0.0028,
      "step": 5830
    },
    {
      "epoch": 0.4983360354979094,
      "grad_norm": 0.5926212072372437,
      "learning_rate": 3.7541599112552265e-05,
      "loss": 0.0039,
      "step": 5840
    },
    {
      "epoch": 0.4991893506271866,
      "grad_norm": 0.7198783159255981,
      "learning_rate": 3.7520266234320336e-05,
      "loss": 0.0026,
      "step": 5850
    },
    {
      "epoch": 0.5000426657564638,
      "grad_norm": 0.3415478765964508,
      "learning_rate": 3.749893335608841e-05,
      "loss": 0.0029,
      "step": 5860
    },
    {
      "epoch": 0.500895980885741,
      "grad_norm": 0.4708556830883026,
      "learning_rate": 3.747760047785647e-05,
      "loss": 0.0037,
      "step": 5870
    },
    {
      "epoch": 0.5017492960150184,
      "grad_norm": 0.47936585545539856,
      "learning_rate": 3.745626759962454e-05,
      "loss": 0.0034,
      "step": 5880
    },
    {
      "epoch": 0.5026026111442956,
      "grad_norm": 0.3141303062438965,
      "learning_rate": 3.7434934721392614e-05,
      "loss": 0.0028,
      "step": 5890
    },
    {
      "epoch": 0.5034559262735728,
      "grad_norm": 0.422304630279541,
      "learning_rate": 3.741360184316068e-05,
      "loss": 0.0035,
      "step": 5900
    },
    {
      "epoch": 0.50430924140285,
      "grad_norm": 0.9574604034423828,
      "learning_rate": 3.739226896492875e-05,
      "loss": 0.0041,
      "step": 5910
    },
    {
      "epoch": 0.5051625565321273,
      "grad_norm": 0.6077239513397217,
      "learning_rate": 3.7370936086696814e-05,
      "loss": 0.0027,
      "step": 5920
    },
    {
      "epoch": 0.5060158716614046,
      "grad_norm": 0.43173813819885254,
      "learning_rate": 3.734960320846489e-05,
      "loss": 0.0033,
      "step": 5930
    },
    {
      "epoch": 0.5068691867906818,
      "grad_norm": 0.5477574467658997,
      "learning_rate": 3.7328270330232956e-05,
      "loss": 0.0038,
      "step": 5940
    },
    {
      "epoch": 0.507722501919959,
      "grad_norm": 0.2229824662208557,
      "learning_rate": 3.730693745200103e-05,
      "loss": 0.0027,
      "step": 5950
    },
    {
      "epoch": 0.5085758170492363,
      "grad_norm": 0.44735386967658997,
      "learning_rate": 3.728560457376909e-05,
      "loss": 0.0027,
      "step": 5960
    },
    {
      "epoch": 0.5094291321785135,
      "grad_norm": 0.35217002034187317,
      "learning_rate": 3.726427169553716e-05,
      "loss": 0.0027,
      "step": 5970
    },
    {
      "epoch": 0.5102824473077908,
      "grad_norm": 0.3069162368774414,
      "learning_rate": 3.7242938817305234e-05,
      "loss": 0.0041,
      "step": 5980
    },
    {
      "epoch": 0.511135762437068,
      "grad_norm": 0.226606547832489,
      "learning_rate": 3.72216059390733e-05,
      "loss": 0.0027,
      "step": 5990
    },
    {
      "epoch": 0.5119890775663453,
      "grad_norm": 0.38885387778282166,
      "learning_rate": 3.720027306084137e-05,
      "loss": 0.0032,
      "step": 6000
    },
    {
      "epoch": 0.5128423926956225,
      "grad_norm": 0.587234616279602,
      "learning_rate": 3.717894018260944e-05,
      "loss": 0.004,
      "step": 6010
    },
    {
      "epoch": 0.5136957078248997,
      "grad_norm": 0.3999837636947632,
      "learning_rate": 3.7157607304377506e-05,
      "loss": 0.0031,
      "step": 6020
    },
    {
      "epoch": 0.5145490229541769,
      "grad_norm": 1.0615496635437012,
      "learning_rate": 3.713627442614558e-05,
      "loss": 0.0034,
      "step": 6030
    },
    {
      "epoch": 0.5154023380834543,
      "grad_norm": 0.9263465404510498,
      "learning_rate": 3.711494154791365e-05,
      "loss": 0.003,
      "step": 6040
    },
    {
      "epoch": 0.5162556532127315,
      "grad_norm": 0.761277437210083,
      "learning_rate": 3.709360866968172e-05,
      "loss": 0.0029,
      "step": 6050
    },
    {
      "epoch": 0.5171089683420087,
      "grad_norm": 0.510239839553833,
      "learning_rate": 3.7072275791449784e-05,
      "loss": 0.0035,
      "step": 6060
    },
    {
      "epoch": 0.5179622834712859,
      "grad_norm": 0.49787744879722595,
      "learning_rate": 3.705094291321785e-05,
      "loss": 0.0038,
      "step": 6070
    },
    {
      "epoch": 0.5188155986005631,
      "grad_norm": 0.2631995975971222,
      "learning_rate": 3.7029610034985926e-05,
      "loss": 0.0025,
      "step": 6080
    },
    {
      "epoch": 0.5196689137298405,
      "grad_norm": 1.3186215162277222,
      "learning_rate": 3.700827715675399e-05,
      "loss": 0.0031,
      "step": 6090
    },
    {
      "epoch": 0.5205222288591177,
      "grad_norm": 0.7599903345108032,
      "learning_rate": 3.698694427852206e-05,
      "loss": 0.0026,
      "step": 6100
    },
    {
      "epoch": 0.5213755439883949,
      "grad_norm": 0.3917469084262848,
      "learning_rate": 3.6965611400290126e-05,
      "loss": 0.0035,
      "step": 6110
    },
    {
      "epoch": 0.5222288591176721,
      "grad_norm": 0.4686945378780365,
      "learning_rate": 3.69442785220582e-05,
      "loss": 0.003,
      "step": 6120
    },
    {
      "epoch": 0.5230821742469494,
      "grad_norm": 0.5445759892463684,
      "learning_rate": 3.692294564382627e-05,
      "loss": 0.0028,
      "step": 6130
    },
    {
      "epoch": 0.5239354893762267,
      "grad_norm": 0.36826303601264954,
      "learning_rate": 3.690161276559433e-05,
      "loss": 0.0031,
      "step": 6140
    },
    {
      "epoch": 0.5247888045055039,
      "grad_norm": 1.170114278793335,
      "learning_rate": 3.6880279887362404e-05,
      "loss": 0.0025,
      "step": 6150
    },
    {
      "epoch": 0.5256421196347811,
      "grad_norm": 0.4432010352611542,
      "learning_rate": 3.6858947009130475e-05,
      "loss": 0.003,
      "step": 6160
    },
    {
      "epoch": 0.5264954347640584,
      "grad_norm": 0.4284358620643616,
      "learning_rate": 3.683761413089854e-05,
      "loss": 0.0035,
      "step": 6170
    },
    {
      "epoch": 0.5273487498933356,
      "grad_norm": 0.5338163375854492,
      "learning_rate": 3.681628125266661e-05,
      "loss": 0.0035,
      "step": 6180
    },
    {
      "epoch": 0.5282020650226128,
      "grad_norm": 1.0644123554229736,
      "learning_rate": 3.679494837443468e-05,
      "loss": 0.0029,
      "step": 6190
    },
    {
      "epoch": 0.5290553801518901,
      "grad_norm": 0.9416512250900269,
      "learning_rate": 3.6773615496202753e-05,
      "loss": 0.0032,
      "step": 6200
    },
    {
      "epoch": 0.5299086952811674,
      "grad_norm": 0.514295220375061,
      "learning_rate": 3.675228261797082e-05,
      "loss": 0.0036,
      "step": 6210
    },
    {
      "epoch": 0.5307620104104446,
      "grad_norm": 0.3934021592140198,
      "learning_rate": 3.673094973973888e-05,
      "loss": 0.003,
      "step": 6220
    },
    {
      "epoch": 0.5316153255397218,
      "grad_norm": 0.5974399447441101,
      "learning_rate": 3.6709616861506954e-05,
      "loss": 0.0032,
      "step": 6230
    },
    {
      "epoch": 0.532468640668999,
      "grad_norm": 0.8806298971176147,
      "learning_rate": 3.6688283983275025e-05,
      "loss": 0.0035,
      "step": 6240
    },
    {
      "epoch": 0.5333219557982763,
      "grad_norm": 0.7257726192474365,
      "learning_rate": 3.6666951105043096e-05,
      "loss": 0.0037,
      "step": 6250
    },
    {
      "epoch": 0.5341752709275536,
      "grad_norm": 0.7430578470230103,
      "learning_rate": 3.664561822681116e-05,
      "loss": 0.0035,
      "step": 6260
    },
    {
      "epoch": 0.5350285860568308,
      "grad_norm": 0.43162301182746887,
      "learning_rate": 3.662428534857923e-05,
      "loss": 0.0035,
      "step": 6270
    },
    {
      "epoch": 0.535881901186108,
      "grad_norm": 0.7974700331687927,
      "learning_rate": 3.66029524703473e-05,
      "loss": 0.0028,
      "step": 6280
    },
    {
      "epoch": 0.5367352163153852,
      "grad_norm": 0.60072261095047,
      "learning_rate": 3.658161959211537e-05,
      "loss": 0.0029,
      "step": 6290
    },
    {
      "epoch": 0.5375885314446626,
      "grad_norm": 0.38670286536216736,
      "learning_rate": 3.656028671388344e-05,
      "loss": 0.0028,
      "step": 6300
    },
    {
      "epoch": 0.5384418465739398,
      "grad_norm": 0.29287320375442505,
      "learning_rate": 3.653895383565151e-05,
      "loss": 0.0032,
      "step": 6310
    },
    {
      "epoch": 0.539295161703217,
      "grad_norm": 0.7931998372077942,
      "learning_rate": 3.651762095741958e-05,
      "loss": 0.0026,
      "step": 6320
    },
    {
      "epoch": 0.5401484768324942,
      "grad_norm": 0.6971267461776733,
      "learning_rate": 3.6496288079187645e-05,
      "loss": 0.0024,
      "step": 6330
    },
    {
      "epoch": 0.5410017919617714,
      "grad_norm": 0.42185619473457336,
      "learning_rate": 3.647495520095571e-05,
      "loss": 0.0031,
      "step": 6340
    },
    {
      "epoch": 0.5418551070910487,
      "grad_norm": 0.3429628908634186,
      "learning_rate": 3.645362232272379e-05,
      "loss": 0.0029,
      "step": 6350
    },
    {
      "epoch": 0.542708422220326,
      "grad_norm": 0.7617835998535156,
      "learning_rate": 3.643228944449185e-05,
      "loss": 0.0034,
      "step": 6360
    },
    {
      "epoch": 0.5435617373496032,
      "grad_norm": 0.6026782989501953,
      "learning_rate": 3.641095656625992e-05,
      "loss": 0.003,
      "step": 6370
    },
    {
      "epoch": 0.5444150524788804,
      "grad_norm": 0.2931669056415558,
      "learning_rate": 3.638962368802799e-05,
      "loss": 0.0027,
      "step": 6380
    },
    {
      "epoch": 0.5452683676081577,
      "grad_norm": 0.24555517733097076,
      "learning_rate": 3.636829080979606e-05,
      "loss": 0.0026,
      "step": 6390
    },
    {
      "epoch": 0.5461216827374349,
      "grad_norm": 0.9551321864128113,
      "learning_rate": 3.634695793156413e-05,
      "loss": 0.0028,
      "step": 6400
    },
    {
      "epoch": 0.5469749978667122,
      "grad_norm": 0.21727904677391052,
      "learning_rate": 3.6325625053332195e-05,
      "loss": 0.0033,
      "step": 6410
    },
    {
      "epoch": 0.5478283129959894,
      "grad_norm": 0.7151391506195068,
      "learning_rate": 3.6304292175100266e-05,
      "loss": 0.003,
      "step": 6420
    },
    {
      "epoch": 0.5486816281252667,
      "grad_norm": 0.6878980994224548,
      "learning_rate": 3.628295929686834e-05,
      "loss": 0.003,
      "step": 6430
    },
    {
      "epoch": 0.5495349432545439,
      "grad_norm": 0.3627927005290985,
      "learning_rate": 3.62616264186364e-05,
      "loss": 0.0029,
      "step": 6440
    },
    {
      "epoch": 0.5503882583838211,
      "grad_norm": 0.410467267036438,
      "learning_rate": 3.624029354040447e-05,
      "loss": 0.0046,
      "step": 6450
    },
    {
      "epoch": 0.5512415735130984,
      "grad_norm": 0.4369701147079468,
      "learning_rate": 3.6218960662172544e-05,
      "loss": 0.0036,
      "step": 6460
    },
    {
      "epoch": 0.5520948886423757,
      "grad_norm": 0.3220246136188507,
      "learning_rate": 3.6197627783940615e-05,
      "loss": 0.0026,
      "step": 6470
    },
    {
      "epoch": 0.5529482037716529,
      "grad_norm": 0.8184534907341003,
      "learning_rate": 3.617629490570868e-05,
      "loss": 0.003,
      "step": 6480
    },
    {
      "epoch": 0.5538015189009301,
      "grad_norm": 1.0127941370010376,
      "learning_rate": 3.6154962027476744e-05,
      "loss": 0.0039,
      "step": 6490
    },
    {
      "epoch": 0.5546548340302073,
      "grad_norm": 0.6417165398597717,
      "learning_rate": 3.613362914924482e-05,
      "loss": 0.0029,
      "step": 6500
    },
    {
      "epoch": 0.5555081491594845,
      "grad_norm": 0.3604278862476349,
      "learning_rate": 3.6112296271012886e-05,
      "loss": 0.0031,
      "step": 6510
    },
    {
      "epoch": 0.5563614642887619,
      "grad_norm": 0.954407811164856,
      "learning_rate": 3.609096339278096e-05,
      "loss": 0.0034,
      "step": 6520
    },
    {
      "epoch": 0.5572147794180391,
      "grad_norm": 0.2354845106601715,
      "learning_rate": 3.606963051454902e-05,
      "loss": 0.0029,
      "step": 6530
    },
    {
      "epoch": 0.5580680945473163,
      "grad_norm": 0.7643390893936157,
      "learning_rate": 3.604829763631709e-05,
      "loss": 0.0026,
      "step": 6540
    },
    {
      "epoch": 0.5589214096765935,
      "grad_norm": 0.3542965352535248,
      "learning_rate": 3.6026964758085164e-05,
      "loss": 0.0031,
      "step": 6550
    },
    {
      "epoch": 0.5597747248058708,
      "grad_norm": 0.4915342330932617,
      "learning_rate": 3.600563187985323e-05,
      "loss": 0.0028,
      "step": 6560
    },
    {
      "epoch": 0.5606280399351481,
      "grad_norm": 0.5097110271453857,
      "learning_rate": 3.59842990016213e-05,
      "loss": 0.003,
      "step": 6570
    },
    {
      "epoch": 0.5614813550644253,
      "grad_norm": 0.25316983461380005,
      "learning_rate": 3.596296612338937e-05,
      "loss": 0.0028,
      "step": 6580
    },
    {
      "epoch": 0.5623346701937025,
      "grad_norm": 0.5430269241333008,
      "learning_rate": 3.594163324515744e-05,
      "loss": 0.0033,
      "step": 6590
    },
    {
      "epoch": 0.5631879853229798,
      "grad_norm": 0.4141264855861664,
      "learning_rate": 3.592030036692551e-05,
      "loss": 0.0031,
      "step": 6600
    },
    {
      "epoch": 0.564041300452257,
      "grad_norm": 0.9137091636657715,
      "learning_rate": 3.589896748869357e-05,
      "loss": 0.0032,
      "step": 6610
    },
    {
      "epoch": 0.5648946155815343,
      "grad_norm": 0.3951977789402008,
      "learning_rate": 3.587763461046165e-05,
      "loss": 0.0032,
      "step": 6620
    },
    {
      "epoch": 0.5657479307108115,
      "grad_norm": 0.6175712943077087,
      "learning_rate": 3.5856301732229714e-05,
      "loss": 0.0037,
      "step": 6630
    },
    {
      "epoch": 0.5666012458400888,
      "grad_norm": 0.353532075881958,
      "learning_rate": 3.5834968853997785e-05,
      "loss": 0.0029,
      "step": 6640
    },
    {
      "epoch": 0.567454560969366,
      "grad_norm": 0.5319976210594177,
      "learning_rate": 3.581363597576585e-05,
      "loss": 0.0031,
      "step": 6650
    },
    {
      "epoch": 0.5683078760986432,
      "grad_norm": 0.47539326548576355,
      "learning_rate": 3.579230309753392e-05,
      "loss": 0.0024,
      "step": 6660
    },
    {
      "epoch": 0.5691611912279205,
      "grad_norm": 0.5180617570877075,
      "learning_rate": 3.577097021930199e-05,
      "loss": 0.0034,
      "step": 6670
    },
    {
      "epoch": 0.5700145063571977,
      "grad_norm": 0.4772649109363556,
      "learning_rate": 3.5749637341070056e-05,
      "loss": 0.0027,
      "step": 6680
    },
    {
      "epoch": 0.570867821486475,
      "grad_norm": 0.547469437122345,
      "learning_rate": 3.572830446283813e-05,
      "loss": 0.0027,
      "step": 6690
    },
    {
      "epoch": 0.5717211366157522,
      "grad_norm": 0.3821086287498474,
      "learning_rate": 3.57069715846062e-05,
      "loss": 0.0028,
      "step": 6700
    },
    {
      "epoch": 0.5725744517450294,
      "grad_norm": 0.37675079703330994,
      "learning_rate": 3.568563870637426e-05,
      "loss": 0.0025,
      "step": 6710
    },
    {
      "epoch": 0.5734277668743066,
      "grad_norm": 0.23187679052352905,
      "learning_rate": 3.5664305828142334e-05,
      "loss": 0.003,
      "step": 6720
    },
    {
      "epoch": 0.574281082003584,
      "grad_norm": 0.5236838459968567,
      "learning_rate": 3.5642972949910405e-05,
      "loss": 0.0034,
      "step": 6730
    },
    {
      "epoch": 0.5751343971328612,
      "grad_norm": 0.6138004660606384,
      "learning_rate": 3.5621640071678477e-05,
      "loss": 0.0031,
      "step": 6740
    },
    {
      "epoch": 0.5759877122621384,
      "grad_norm": 0.9461520910263062,
      "learning_rate": 3.560030719344654e-05,
      "loss": 0.0036,
      "step": 6750
    },
    {
      "epoch": 0.5768410273914156,
      "grad_norm": 0.5983489751815796,
      "learning_rate": 3.5578974315214605e-05,
      "loss": 0.003,
      "step": 6760
    },
    {
      "epoch": 0.5776943425206928,
      "grad_norm": 0.4106384217739105,
      "learning_rate": 3.5557641436982683e-05,
      "loss": 0.0038,
      "step": 6770
    },
    {
      "epoch": 0.5785476576499702,
      "grad_norm": 0.48729828000068665,
      "learning_rate": 3.553630855875075e-05,
      "loss": 0.0035,
      "step": 6780
    },
    {
      "epoch": 0.5794009727792474,
      "grad_norm": 0.7490074038505554,
      "learning_rate": 3.551497568051882e-05,
      "loss": 0.0036,
      "step": 6790
    },
    {
      "epoch": 0.5802542879085246,
      "grad_norm": 0.3650979995727539,
      "learning_rate": 3.5493642802286883e-05,
      "loss": 0.0033,
      "step": 6800
    },
    {
      "epoch": 0.5811076030378018,
      "grad_norm": 0.4699944853782654,
      "learning_rate": 3.5472309924054955e-05,
      "loss": 0.0029,
      "step": 6810
    },
    {
      "epoch": 0.5819609181670791,
      "grad_norm": 0.8163537383079529,
      "learning_rate": 3.5450977045823026e-05,
      "loss": 0.0032,
      "step": 6820
    },
    {
      "epoch": 0.5828142332963564,
      "grad_norm": 0.5825024843215942,
      "learning_rate": 3.542964416759109e-05,
      "loss": 0.0035,
      "step": 6830
    },
    {
      "epoch": 0.5836675484256336,
      "grad_norm": 0.39508554339408875,
      "learning_rate": 3.540831128935916e-05,
      "loss": 0.0028,
      "step": 6840
    },
    {
      "epoch": 0.5845208635549108,
      "grad_norm": 0.7079001069068909,
      "learning_rate": 3.538697841112723e-05,
      "loss": 0.0033,
      "step": 6850
    },
    {
      "epoch": 0.5853741786841881,
      "grad_norm": 0.6904860138893127,
      "learning_rate": 3.53656455328953e-05,
      "loss": 0.0028,
      "step": 6860
    },
    {
      "epoch": 0.5862274938134653,
      "grad_norm": 0.41978731751441956,
      "learning_rate": 3.534431265466337e-05,
      "loss": 0.0035,
      "step": 6870
    },
    {
      "epoch": 0.5870808089427425,
      "grad_norm": 0.400052011013031,
      "learning_rate": 3.532297977643144e-05,
      "loss": 0.0031,
      "step": 6880
    },
    {
      "epoch": 0.5879341240720198,
      "grad_norm": 0.4816071391105652,
      "learning_rate": 3.530164689819951e-05,
      "loss": 0.0034,
      "step": 6890
    },
    {
      "epoch": 0.5887874392012971,
      "grad_norm": 0.4805317223072052,
      "learning_rate": 3.5280314019967575e-05,
      "loss": 0.0024,
      "step": 6900
    },
    {
      "epoch": 0.5896407543305743,
      "grad_norm": 0.2927531599998474,
      "learning_rate": 3.525898114173564e-05,
      "loss": 0.003,
      "step": 6910
    },
    {
      "epoch": 0.5904940694598515,
      "grad_norm": 0.5203568339347839,
      "learning_rate": 3.523764826350371e-05,
      "loss": 0.0027,
      "step": 6920
    },
    {
      "epoch": 0.5913473845891287,
      "grad_norm": 0.3295775353908539,
      "learning_rate": 3.521631538527178e-05,
      "loss": 0.0025,
      "step": 6930
    },
    {
      "epoch": 0.592200699718406,
      "grad_norm": 0.7721670866012573,
      "learning_rate": 3.519498250703985e-05,
      "loss": 0.0032,
      "step": 6940
    },
    {
      "epoch": 0.5930540148476833,
      "grad_norm": 0.45441174507141113,
      "learning_rate": 3.517364962880792e-05,
      "loss": 0.0036,
      "step": 6950
    },
    {
      "epoch": 0.5939073299769605,
      "grad_norm": 0.6297199726104736,
      "learning_rate": 3.515231675057599e-05,
      "loss": 0.0033,
      "step": 6960
    },
    {
      "epoch": 0.5947606451062377,
      "grad_norm": 0.8816103339195251,
      "learning_rate": 3.513098387234406e-05,
      "loss": 0.0028,
      "step": 6970
    },
    {
      "epoch": 0.5956139602355149,
      "grad_norm": 1.0078318119049072,
      "learning_rate": 3.5109650994112124e-05,
      "loss": 0.0032,
      "step": 6980
    },
    {
      "epoch": 0.5964672753647923,
      "grad_norm": 0.5845874547958374,
      "learning_rate": 3.5088318115880196e-05,
      "loss": 0.0033,
      "step": 6990
    },
    {
      "epoch": 0.5973205904940695,
      "grad_norm": 0.3117068111896515,
      "learning_rate": 3.506698523764827e-05,
      "loss": 0.0035,
      "step": 7000
    },
    {
      "epoch": 0.5981739056233467,
      "grad_norm": 0.32795318961143494,
      "learning_rate": 3.504565235941634e-05,
      "loss": 0.003,
      "step": 7010
    },
    {
      "epoch": 0.5990272207526239,
      "grad_norm": 0.8012953996658325,
      "learning_rate": 3.50243194811844e-05,
      "loss": 0.003,
      "step": 7020
    },
    {
      "epoch": 0.5998805358819012,
      "grad_norm": 0.6676518321037292,
      "learning_rate": 3.500298660295247e-05,
      "loss": 0.0036,
      "step": 7030
    },
    {
      "epoch": 0.6007338510111784,
      "grad_norm": 0.5548527836799622,
      "learning_rate": 3.4981653724720545e-05,
      "loss": 0.0029,
      "step": 7040
    },
    {
      "epoch": 0.6015871661404557,
      "grad_norm": 1.0804381370544434,
      "learning_rate": 3.496032084648861e-05,
      "loss": 0.0035,
      "step": 7050
    },
    {
      "epoch": 0.6024404812697329,
      "grad_norm": 0.7220786809921265,
      "learning_rate": 3.493898796825668e-05,
      "loss": 0.0033,
      "step": 7060
    },
    {
      "epoch": 0.6032937963990102,
      "grad_norm": 0.5456511378288269,
      "learning_rate": 3.4917655090024745e-05,
      "loss": 0.0033,
      "step": 7070
    },
    {
      "epoch": 0.6041471115282874,
      "grad_norm": 0.34242722392082214,
      "learning_rate": 3.4896322211792816e-05,
      "loss": 0.0025,
      "step": 7080
    },
    {
      "epoch": 0.6050004266575646,
      "grad_norm": 0.9693028330802917,
      "learning_rate": 3.487498933356089e-05,
      "loss": 0.0034,
      "step": 7090
    },
    {
      "epoch": 0.6058537417868419,
      "grad_norm": 0.6851106286048889,
      "learning_rate": 3.485365645532895e-05,
      "loss": 0.0033,
      "step": 7100
    },
    {
      "epoch": 0.6067070569161191,
      "grad_norm": 0.4353358745574951,
      "learning_rate": 3.483232357709702e-05,
      "loss": 0.0032,
      "step": 7110
    },
    {
      "epoch": 0.6075603720453964,
      "grad_norm": 0.5178712010383606,
      "learning_rate": 3.4810990698865094e-05,
      "loss": 0.0027,
      "step": 7120
    },
    {
      "epoch": 0.6084136871746736,
      "grad_norm": 0.28994229435920715,
      "learning_rate": 3.478965782063316e-05,
      "loss": 0.003,
      "step": 7130
    },
    {
      "epoch": 0.6092670023039508,
      "grad_norm": 0.52098149061203,
      "learning_rate": 3.476832494240123e-05,
      "loss": 0.0039,
      "step": 7140
    },
    {
      "epoch": 0.6101203174332281,
      "grad_norm": 0.33853965997695923,
      "learning_rate": 3.47469920641693e-05,
      "loss": 0.0027,
      "step": 7150
    },
    {
      "epoch": 0.6109736325625054,
      "grad_norm": 0.5440652370452881,
      "learning_rate": 3.472565918593737e-05,
      "loss": 0.0039,
      "step": 7160
    },
    {
      "epoch": 0.6118269476917826,
      "grad_norm": 0.8690264821052551,
      "learning_rate": 3.470432630770544e-05,
      "loss": 0.0033,
      "step": 7170
    },
    {
      "epoch": 0.6126802628210598,
      "grad_norm": 0.5105841755867004,
      "learning_rate": 3.46829934294735e-05,
      "loss": 0.0029,
      "step": 7180
    },
    {
      "epoch": 0.613533577950337,
      "grad_norm": 0.7056218981742859,
      "learning_rate": 3.466166055124158e-05,
      "loss": 0.0035,
      "step": 7190
    },
    {
      "epoch": 0.6143868930796142,
      "grad_norm": 0.5618733763694763,
      "learning_rate": 3.4640327673009644e-05,
      "loss": 0.0031,
      "step": 7200
    },
    {
      "epoch": 0.6152402082088916,
      "grad_norm": 0.5148186683654785,
      "learning_rate": 3.4618994794777715e-05,
      "loss": 0.0027,
      "step": 7210
    },
    {
      "epoch": 0.6160935233381688,
      "grad_norm": 0.6018281579017639,
      "learning_rate": 3.459766191654578e-05,
      "loss": 0.0027,
      "step": 7220
    },
    {
      "epoch": 0.616946838467446,
      "grad_norm": 0.40160930156707764,
      "learning_rate": 3.457632903831385e-05,
      "loss": 0.0028,
      "step": 7230
    },
    {
      "epoch": 0.6178001535967232,
      "grad_norm": 0.4207642376422882,
      "learning_rate": 3.455499616008192e-05,
      "loss": 0.0026,
      "step": 7240
    },
    {
      "epoch": 0.6186534687260005,
      "grad_norm": 0.8991296291351318,
      "learning_rate": 3.4533663281849986e-05,
      "loss": 0.003,
      "step": 7250
    },
    {
      "epoch": 0.6195067838552778,
      "grad_norm": 0.5226339101791382,
      "learning_rate": 3.451233040361806e-05,
      "loss": 0.0034,
      "step": 7260
    },
    {
      "epoch": 0.620360098984555,
      "grad_norm": 0.6169483065605164,
      "learning_rate": 3.449099752538613e-05,
      "loss": 0.0038,
      "step": 7270
    },
    {
      "epoch": 0.6212134141138322,
      "grad_norm": 0.24579092860221863,
      "learning_rate": 3.44696646471542e-05,
      "loss": 0.0029,
      "step": 7280
    },
    {
      "epoch": 0.6220667292431095,
      "grad_norm": 0.9802939295768738,
      "learning_rate": 3.4448331768922264e-05,
      "loss": 0.0032,
      "step": 7290
    },
    {
      "epoch": 0.6229200443723867,
      "grad_norm": 0.5167928338050842,
      "learning_rate": 3.442699889069033e-05,
      "loss": 0.0031,
      "step": 7300
    },
    {
      "epoch": 0.623773359501664,
      "grad_norm": 0.7078395485877991,
      "learning_rate": 3.4405666012458406e-05,
      "loss": 0.0029,
      "step": 7310
    },
    {
      "epoch": 0.6246266746309412,
      "grad_norm": 0.4997507929801941,
      "learning_rate": 3.438433313422647e-05,
      "loss": 0.0031,
      "step": 7320
    },
    {
      "epoch": 0.6254799897602185,
      "grad_norm": 0.4760391116142273,
      "learning_rate": 3.436300025599454e-05,
      "loss": 0.0029,
      "step": 7330
    },
    {
      "epoch": 0.6263333048894957,
      "grad_norm": 0.323996365070343,
      "learning_rate": 3.4341667377762607e-05,
      "loss": 0.0023,
      "step": 7340
    },
    {
      "epoch": 0.6271866200187729,
      "grad_norm": 0.6060218811035156,
      "learning_rate": 3.432033449953068e-05,
      "loss": 0.0026,
      "step": 7350
    },
    {
      "epoch": 0.6280399351480501,
      "grad_norm": 0.5492158532142639,
      "learning_rate": 3.429900162129875e-05,
      "loss": 0.0029,
      "step": 7360
    },
    {
      "epoch": 0.6288932502773275,
      "grad_norm": 0.721239447593689,
      "learning_rate": 3.4277668743066813e-05,
      "loss": 0.0028,
      "step": 7370
    },
    {
      "epoch": 0.6297465654066047,
      "grad_norm": 0.383592814207077,
      "learning_rate": 3.4256335864834885e-05,
      "loss": 0.0026,
      "step": 7380
    },
    {
      "epoch": 0.6305998805358819,
      "grad_norm": 0.23839214444160461,
      "learning_rate": 3.4235002986602956e-05,
      "loss": 0.003,
      "step": 7390
    },
    {
      "epoch": 0.6314531956651591,
      "grad_norm": 0.7346104383468628,
      "learning_rate": 3.421367010837102e-05,
      "loss": 0.0024,
      "step": 7400
    },
    {
      "epoch": 0.6323065107944363,
      "grad_norm": 0.46375471353530884,
      "learning_rate": 3.419233723013909e-05,
      "loss": 0.0031,
      "step": 7410
    },
    {
      "epoch": 0.6331598259237137,
      "grad_norm": 0.5008227229118347,
      "learning_rate": 3.417100435190716e-05,
      "loss": 0.0027,
      "step": 7420
    },
    {
      "epoch": 0.6340131410529909,
      "grad_norm": 0.6545124650001526,
      "learning_rate": 3.4149671473675234e-05,
      "loss": 0.003,
      "step": 7430
    },
    {
      "epoch": 0.6348664561822681,
      "grad_norm": 0.3750561773777008,
      "learning_rate": 3.41283385954433e-05,
      "loss": 0.0036,
      "step": 7440
    },
    {
      "epoch": 0.6357197713115453,
      "grad_norm": 0.4736555218696594,
      "learning_rate": 3.410700571721136e-05,
      "loss": 0.0029,
      "step": 7450
    },
    {
      "epoch": 0.6365730864408226,
      "grad_norm": 0.956009566783905,
      "learning_rate": 3.408567283897944e-05,
      "loss": 0.0034,
      "step": 7460
    },
    {
      "epoch": 0.6374264015700999,
      "grad_norm": 1.0607490539550781,
      "learning_rate": 3.4064339960747505e-05,
      "loss": 0.0025,
      "step": 7470
    },
    {
      "epoch": 0.6382797166993771,
      "grad_norm": 0.3621918857097626,
      "learning_rate": 3.4043007082515576e-05,
      "loss": 0.0024,
      "step": 7480
    },
    {
      "epoch": 0.6391330318286543,
      "grad_norm": 1.2817604541778564,
      "learning_rate": 3.402167420428364e-05,
      "loss": 0.0032,
      "step": 7490
    },
    {
      "epoch": 0.6399863469579316,
      "grad_norm": 0.46896472573280334,
      "learning_rate": 3.400034132605171e-05,
      "loss": 0.0033,
      "step": 7500
    },
    {
      "epoch": 0.6408396620872088,
      "grad_norm": 0.639708399772644,
      "learning_rate": 3.397900844781978e-05,
      "loss": 0.0034,
      "step": 7510
    },
    {
      "epoch": 0.641692977216486,
      "grad_norm": 0.4116690158843994,
      "learning_rate": 3.395767556958785e-05,
      "loss": 0.0028,
      "step": 7520
    },
    {
      "epoch": 0.6425462923457633,
      "grad_norm": 0.5339611172676086,
      "learning_rate": 3.393634269135592e-05,
      "loss": 0.0033,
      "step": 7530
    },
    {
      "epoch": 0.6433996074750405,
      "grad_norm": 0.40239307284355164,
      "learning_rate": 3.391500981312399e-05,
      "loss": 0.0031,
      "step": 7540
    },
    {
      "epoch": 0.6442529226043178,
      "grad_norm": 0.3889281749725342,
      "learning_rate": 3.3893676934892054e-05,
      "loss": 0.0033,
      "step": 7550
    },
    {
      "epoch": 0.645106237733595,
      "grad_norm": 0.8292297720909119,
      "learning_rate": 3.3872344056660126e-05,
      "loss": 0.003,
      "step": 7560
    },
    {
      "epoch": 0.6459595528628722,
      "grad_norm": 0.4862017035484314,
      "learning_rate": 3.38510111784282e-05,
      "loss": 0.0029,
      "step": 7570
    },
    {
      "epoch": 0.6468128679921495,
      "grad_norm": 0.6768351793289185,
      "learning_rate": 3.382967830019627e-05,
      "loss": 0.0028,
      "step": 7580
    },
    {
      "epoch": 0.6476661831214268,
      "grad_norm": 0.5577509999275208,
      "learning_rate": 3.380834542196433e-05,
      "loss": 0.0035,
      "step": 7590
    },
    {
      "epoch": 0.648519498250704,
      "grad_norm": 0.7139038443565369,
      "learning_rate": 3.3787012543732404e-05,
      "loss": 0.0026,
      "step": 7600
    },
    {
      "epoch": 0.6493728133799812,
      "grad_norm": 0.23408685624599457,
      "learning_rate": 3.376567966550047e-05,
      "loss": 0.003,
      "step": 7610
    },
    {
      "epoch": 0.6502261285092584,
      "grad_norm": 0.3032408356666565,
      "learning_rate": 3.374434678726854e-05,
      "loss": 0.0029,
      "step": 7620
    },
    {
      "epoch": 0.6510794436385358,
      "grad_norm": 0.6642066240310669,
      "learning_rate": 3.372301390903661e-05,
      "loss": 0.0027,
      "step": 7630
    },
    {
      "epoch": 0.651932758767813,
      "grad_norm": 0.8344379663467407,
      "learning_rate": 3.3701681030804675e-05,
      "loss": 0.003,
      "step": 7640
    },
    {
      "epoch": 0.6527860738970902,
      "grad_norm": 0.41493597626686096,
      "learning_rate": 3.3680348152572746e-05,
      "loss": 0.0036,
      "step": 7650
    },
    {
      "epoch": 0.6536393890263674,
      "grad_norm": 0.6888880729675293,
      "learning_rate": 3.365901527434082e-05,
      "loss": 0.0036,
      "step": 7660
    },
    {
      "epoch": 0.6544927041556446,
      "grad_norm": 0.9885112643241882,
      "learning_rate": 3.363768239610888e-05,
      "loss": 0.0027,
      "step": 7670
    },
    {
      "epoch": 0.655346019284922,
      "grad_norm": 0.4500976502895355,
      "learning_rate": 3.361634951787695e-05,
      "loss": 0.0031,
      "step": 7680
    },
    {
      "epoch": 0.6561993344141992,
      "grad_norm": 1.1526405811309814,
      "learning_rate": 3.3595016639645024e-05,
      "loss": 0.0036,
      "step": 7690
    },
    {
      "epoch": 0.6570526495434764,
      "grad_norm": 0.8825093507766724,
      "learning_rate": 3.3573683761413095e-05,
      "loss": 0.0031,
      "step": 7700
    },
    {
      "epoch": 0.6579059646727536,
      "grad_norm": 0.8429573774337769,
      "learning_rate": 3.355235088318116e-05,
      "loss": 0.0033,
      "step": 7710
    },
    {
      "epoch": 0.6587592798020309,
      "grad_norm": 0.3262811005115509,
      "learning_rate": 3.3531018004949224e-05,
      "loss": 0.0034,
      "step": 7720
    },
    {
      "epoch": 0.6596125949313081,
      "grad_norm": 0.381890207529068,
      "learning_rate": 3.35096851267173e-05,
      "loss": 0.0028,
      "step": 7730
    },
    {
      "epoch": 0.6604659100605854,
      "grad_norm": 0.8370246887207031,
      "learning_rate": 3.348835224848537e-05,
      "loss": 0.003,
      "step": 7740
    },
    {
      "epoch": 0.6613192251898626,
      "grad_norm": 0.9117323756217957,
      "learning_rate": 3.346701937025344e-05,
      "loss": 0.0035,
      "step": 7750
    },
    {
      "epoch": 0.6621725403191399,
      "grad_norm": 0.7907120585441589,
      "learning_rate": 3.34456864920215e-05,
      "loss": 0.0031,
      "step": 7760
    },
    {
      "epoch": 0.6630258554484171,
      "grad_norm": 0.4413933753967285,
      "learning_rate": 3.3424353613789573e-05,
      "loss": 0.0032,
      "step": 7770
    },
    {
      "epoch": 0.6638791705776943,
      "grad_norm": 0.5157666206359863,
      "learning_rate": 3.3403020735557645e-05,
      "loss": 0.0026,
      "step": 7780
    },
    {
      "epoch": 0.6647324857069716,
      "grad_norm": 0.4949461817741394,
      "learning_rate": 3.338168785732571e-05,
      "loss": 0.0029,
      "step": 7790
    },
    {
      "epoch": 0.6655858008362489,
      "grad_norm": 0.8926382064819336,
      "learning_rate": 3.336035497909378e-05,
      "loss": 0.0037,
      "step": 7800
    },
    {
      "epoch": 0.6664391159655261,
      "grad_norm": 0.3669931888580322,
      "learning_rate": 3.333902210086185e-05,
      "loss": 0.0027,
      "step": 7810
    },
    {
      "epoch": 0.6672924310948033,
      "grad_norm": 1.1419118642807007,
      "learning_rate": 3.3317689222629916e-05,
      "loss": 0.0031,
      "step": 7820
    },
    {
      "epoch": 0.6681457462240805,
      "grad_norm": 0.33806535601615906,
      "learning_rate": 3.329635634439799e-05,
      "loss": 0.0033,
      "step": 7830
    },
    {
      "epoch": 0.6689990613533578,
      "grad_norm": 0.7682209610939026,
      "learning_rate": 3.327502346616606e-05,
      "loss": 0.0033,
      "step": 7840
    },
    {
      "epoch": 0.6698523764826351,
      "grad_norm": 0.8441135287284851,
      "learning_rate": 3.325369058793413e-05,
      "loss": 0.003,
      "step": 7850
    },
    {
      "epoch": 0.6707056916119123,
      "grad_norm": 1.4413775205612183,
      "learning_rate": 3.3232357709702194e-05,
      "loss": 0.003,
      "step": 7860
    },
    {
      "epoch": 0.6715590067411895,
      "grad_norm": 0.41079404950141907,
      "learning_rate": 3.321102483147026e-05,
      "loss": 0.0032,
      "step": 7870
    },
    {
      "epoch": 0.6724123218704667,
      "grad_norm": 0.44660285115242004,
      "learning_rate": 3.3189691953238336e-05,
      "loss": 0.0025,
      "step": 7880
    },
    {
      "epoch": 0.673265636999744,
      "grad_norm": 1.076765537261963,
      "learning_rate": 3.31683590750064e-05,
      "loss": 0.0033,
      "step": 7890
    },
    {
      "epoch": 0.6741189521290213,
      "grad_norm": 0.9565998911857605,
      "learning_rate": 3.314702619677447e-05,
      "loss": 0.0028,
      "step": 7900
    },
    {
      "epoch": 0.6749722672582985,
      "grad_norm": 0.75,
      "learning_rate": 3.3125693318542536e-05,
      "loss": 0.0027,
      "step": 7910
    },
    {
      "epoch": 0.6758255823875757,
      "grad_norm": 0.2488553375005722,
      "learning_rate": 3.310436044031061e-05,
      "loss": 0.003,
      "step": 7920
    },
    {
      "epoch": 0.676678897516853,
      "grad_norm": 0.4875677525997162,
      "learning_rate": 3.308302756207868e-05,
      "loss": 0.0034,
      "step": 7930
    },
    {
      "epoch": 0.6775322126461302,
      "grad_norm": 0.5866875052452087,
      "learning_rate": 3.306169468384674e-05,
      "loss": 0.0034,
      "step": 7940
    },
    {
      "epoch": 0.6783855277754075,
      "grad_norm": 0.5375310778617859,
      "learning_rate": 3.3040361805614815e-05,
      "loss": 0.0034,
      "step": 7950
    },
    {
      "epoch": 0.6792388429046847,
      "grad_norm": 0.2857035994529724,
      "learning_rate": 3.3019028927382886e-05,
      "loss": 0.0031,
      "step": 7960
    },
    {
      "epoch": 0.680092158033962,
      "grad_norm": 0.5976600050926208,
      "learning_rate": 3.299769604915096e-05,
      "loss": 0.0027,
      "step": 7970
    },
    {
      "epoch": 0.6809454731632392,
      "grad_norm": 0.3594541549682617,
      "learning_rate": 3.297636317091902e-05,
      "loss": 0.0025,
      "step": 7980
    },
    {
      "epoch": 0.6817987882925164,
      "grad_norm": 1.1241568326950073,
      "learning_rate": 3.2955030292687086e-05,
      "loss": 0.003,
      "step": 7990
    },
    {
      "epoch": 0.6826521034217937,
      "grad_norm": 0.6479620337486267,
      "learning_rate": 3.2933697414455164e-05,
      "loss": 0.003,
      "step": 8000
    },
    {
      "epoch": 0.6835054185510709,
      "grad_norm": 0.922954261302948,
      "learning_rate": 3.291236453622323e-05,
      "loss": 0.0034,
      "step": 8010
    },
    {
      "epoch": 0.6843587336803482,
      "grad_norm": 1.21356999874115,
      "learning_rate": 3.28910316579913e-05,
      "loss": 0.0034,
      "step": 8020
    },
    {
      "epoch": 0.6852120488096254,
      "grad_norm": 0.4885656237602234,
      "learning_rate": 3.2869698779759364e-05,
      "loss": 0.0033,
      "step": 8030
    },
    {
      "epoch": 0.6860653639389026,
      "grad_norm": 0.5578579306602478,
      "learning_rate": 3.2848365901527435e-05,
      "loss": 0.0029,
      "step": 8040
    },
    {
      "epoch": 0.6869186790681798,
      "grad_norm": 0.6309863924980164,
      "learning_rate": 3.2827033023295506e-05,
      "loss": 0.0026,
      "step": 8050
    },
    {
      "epoch": 0.6877719941974572,
      "grad_norm": 0.7631620764732361,
      "learning_rate": 3.280570014506357e-05,
      "loss": 0.0027,
      "step": 8060
    },
    {
      "epoch": 0.6886253093267344,
      "grad_norm": 0.3108161687850952,
      "learning_rate": 3.278436726683164e-05,
      "loss": 0.0025,
      "step": 8070
    },
    {
      "epoch": 0.6894786244560116,
      "grad_norm": 0.8140296339988708,
      "learning_rate": 3.276303438859971e-05,
      "loss": 0.0024,
      "step": 8080
    },
    {
      "epoch": 0.6903319395852888,
      "grad_norm": 0.32125213742256165,
      "learning_rate": 3.274170151036778e-05,
      "loss": 0.0034,
      "step": 8090
    },
    {
      "epoch": 0.691185254714566,
      "grad_norm": 0.8552218079566956,
      "learning_rate": 3.272036863213585e-05,
      "loss": 0.0026,
      "step": 8100
    },
    {
      "epoch": 0.6920385698438434,
      "grad_norm": 0.2298068255186081,
      "learning_rate": 3.269903575390392e-05,
      "loss": 0.0032,
      "step": 8110
    },
    {
      "epoch": 0.6928918849731206,
      "grad_norm": 0.8791711330413818,
      "learning_rate": 3.267770287567199e-05,
      "loss": 0.0026,
      "step": 8120
    },
    {
      "epoch": 0.6937452001023978,
      "grad_norm": 0.40277329087257385,
      "learning_rate": 3.2656369997440056e-05,
      "loss": 0.0026,
      "step": 8130
    },
    {
      "epoch": 0.694598515231675,
      "grad_norm": 0.35327866673469543,
      "learning_rate": 3.263503711920812e-05,
      "loss": 0.0027,
      "step": 8140
    },
    {
      "epoch": 0.6954518303609523,
      "grad_norm": 0.5554769039154053,
      "learning_rate": 3.26137042409762e-05,
      "loss": 0.0029,
      "step": 8150
    },
    {
      "epoch": 0.6963051454902296,
      "grad_norm": 0.38908258080482483,
      "learning_rate": 3.259237136274426e-05,
      "loss": 0.003,
      "step": 8160
    },
    {
      "epoch": 0.6971584606195068,
      "grad_norm": 0.8215488195419312,
      "learning_rate": 3.2571038484512334e-05,
      "loss": 0.003,
      "step": 8170
    },
    {
      "epoch": 0.698011775748784,
      "grad_norm": 0.41868484020233154,
      "learning_rate": 3.25497056062804e-05,
      "loss": 0.0035,
      "step": 8180
    },
    {
      "epoch": 0.6988650908780613,
      "grad_norm": 0.4840156137943268,
      "learning_rate": 3.252837272804847e-05,
      "loss": 0.0028,
      "step": 8190
    },
    {
      "epoch": 0.6997184060073385,
      "grad_norm": 0.4107324182987213,
      "learning_rate": 3.250703984981654e-05,
      "loss": 0.0034,
      "step": 8200
    },
    {
      "epoch": 0.7005717211366157,
      "grad_norm": 1.0790419578552246,
      "learning_rate": 3.2485706971584605e-05,
      "loss": 0.0028,
      "step": 8210
    },
    {
      "epoch": 0.701425036265893,
      "grad_norm": 0.7711917757987976,
      "learning_rate": 3.2464374093352676e-05,
      "loss": 0.0031,
      "step": 8220
    },
    {
      "epoch": 0.7022783513951703,
      "grad_norm": 0.34428146481513977,
      "learning_rate": 3.244304121512075e-05,
      "loss": 0.0027,
      "step": 8230
    },
    {
      "epoch": 0.7031316665244475,
      "grad_norm": 0.40810713171958923,
      "learning_rate": 3.242170833688881e-05,
      "loss": 0.0031,
      "step": 8240
    },
    {
      "epoch": 0.7039849816537247,
      "grad_norm": 0.35205379128456116,
      "learning_rate": 3.240037545865688e-05,
      "loss": 0.0031,
      "step": 8250
    },
    {
      "epoch": 0.7048382967830019,
      "grad_norm": 0.5536567568778992,
      "learning_rate": 3.2379042580424954e-05,
      "loss": 0.003,
      "step": 8260
    },
    {
      "epoch": 0.7056916119122792,
      "grad_norm": 0.609943687915802,
      "learning_rate": 3.2357709702193025e-05,
      "loss": 0.0028,
      "step": 8270
    },
    {
      "epoch": 0.7065449270415565,
      "grad_norm": 0.5498648881912231,
      "learning_rate": 3.233637682396109e-05,
      "loss": 0.0032,
      "step": 8280
    },
    {
      "epoch": 0.7073982421708337,
      "grad_norm": 0.2985920011997223,
      "learning_rate": 3.231504394572916e-05,
      "loss": 0.0032,
      "step": 8290
    },
    {
      "epoch": 0.7082515573001109,
      "grad_norm": 0.8586247563362122,
      "learning_rate": 3.2293711067497225e-05,
      "loss": 0.0032,
      "step": 8300
    },
    {
      "epoch": 0.7091048724293881,
      "grad_norm": 0.3923432528972626,
      "learning_rate": 3.2272378189265297e-05,
      "loss": 0.0028,
      "step": 8310
    },
    {
      "epoch": 0.7099581875586655,
      "grad_norm": 0.6283879280090332,
      "learning_rate": 3.225104531103337e-05,
      "loss": 0.0036,
      "step": 8320
    },
    {
      "epoch": 0.7108115026879427,
      "grad_norm": 0.6397591829299927,
      "learning_rate": 3.222971243280143e-05,
      "loss": 0.0035,
      "step": 8330
    },
    {
      "epoch": 0.7116648178172199,
      "grad_norm": 0.7203267216682434,
      "learning_rate": 3.2208379554569503e-05,
      "loss": 0.0022,
      "step": 8340
    },
    {
      "epoch": 0.7125181329464971,
      "grad_norm": 0.5906945466995239,
      "learning_rate": 3.2187046676337575e-05,
      "loss": 0.0033,
      "step": 8350
    },
    {
      "epoch": 0.7133714480757744,
      "grad_norm": 0.8633604049682617,
      "learning_rate": 3.216571379810564e-05,
      "loss": 0.0031,
      "step": 8360
    },
    {
      "epoch": 0.7142247632050516,
      "grad_norm": 0.38938644528388977,
      "learning_rate": 3.214438091987371e-05,
      "loss": 0.0027,
      "step": 8370
    },
    {
      "epoch": 0.7150780783343289,
      "grad_norm": 0.9540579319000244,
      "learning_rate": 3.212304804164178e-05,
      "loss": 0.0028,
      "step": 8380
    },
    {
      "epoch": 0.7159313934636061,
      "grad_norm": 0.9255465865135193,
      "learning_rate": 3.210171516340985e-05,
      "loss": 0.0034,
      "step": 8390
    },
    {
      "epoch": 0.7167847085928833,
      "grad_norm": 0.4308972656726837,
      "learning_rate": 3.208038228517792e-05,
      "loss": 0.0029,
      "step": 8400
    },
    {
      "epoch": 0.7176380237221606,
      "grad_norm": 0.3929699957370758,
      "learning_rate": 3.205904940694598e-05,
      "loss": 0.0033,
      "step": 8410
    },
    {
      "epoch": 0.7184913388514378,
      "grad_norm": 0.5824798941612244,
      "learning_rate": 3.203771652871406e-05,
      "loss": 0.0029,
      "step": 8420
    },
    {
      "epoch": 0.7193446539807151,
      "grad_norm": 0.6170862317085266,
      "learning_rate": 3.2016383650482124e-05,
      "loss": 0.0027,
      "step": 8430
    },
    {
      "epoch": 0.7201979691099923,
      "grad_norm": 0.6099664568901062,
      "learning_rate": 3.1995050772250195e-05,
      "loss": 0.003,
      "step": 8440
    },
    {
      "epoch": 0.7210512842392696,
      "grad_norm": 1.0397624969482422,
      "learning_rate": 3.197371789401826e-05,
      "loss": 0.0033,
      "step": 8450
    },
    {
      "epoch": 0.7219045993685468,
      "grad_norm": 0.4200974106788635,
      "learning_rate": 3.195238501578633e-05,
      "loss": 0.0028,
      "step": 8460
    },
    {
      "epoch": 0.722757914497824,
      "grad_norm": 0.6387000679969788,
      "learning_rate": 3.19310521375544e-05,
      "loss": 0.0037,
      "step": 8470
    },
    {
      "epoch": 0.7236112296271013,
      "grad_norm": 0.6624653339385986,
      "learning_rate": 3.1909719259322466e-05,
      "loss": 0.0023,
      "step": 8480
    },
    {
      "epoch": 0.7244645447563786,
      "grad_norm": 0.41277655959129333,
      "learning_rate": 3.188838638109054e-05,
      "loss": 0.0028,
      "step": 8490
    },
    {
      "epoch": 0.7253178598856558,
      "grad_norm": 0.30345043540000916,
      "learning_rate": 3.186705350285861e-05,
      "loss": 0.003,
      "step": 8500
    },
    {
      "epoch": 0.726171175014933,
      "grad_norm": 0.5201341509819031,
      "learning_rate": 3.184572062462667e-05,
      "loss": 0.0025,
      "step": 8510
    },
    {
      "epoch": 0.7270244901442102,
      "grad_norm": 0.47209835052490234,
      "learning_rate": 3.1824387746394744e-05,
      "loss": 0.0031,
      "step": 8520
    },
    {
      "epoch": 0.7278778052734874,
      "grad_norm": 0.3399917781352997,
      "learning_rate": 3.1803054868162816e-05,
      "loss": 0.0022,
      "step": 8530
    },
    {
      "epoch": 0.7287311204027648,
      "grad_norm": 0.43957486748695374,
      "learning_rate": 3.178172198993089e-05,
      "loss": 0.0032,
      "step": 8540
    },
    {
      "epoch": 0.729584435532042,
      "grad_norm": 0.412331223487854,
      "learning_rate": 3.176038911169895e-05,
      "loss": 0.0031,
      "step": 8550
    },
    {
      "epoch": 0.7304377506613192,
      "grad_norm": 0.7293568253517151,
      "learning_rate": 3.1739056233467016e-05,
      "loss": 0.0029,
      "step": 8560
    },
    {
      "epoch": 0.7312910657905964,
      "grad_norm": 1.0694702863693237,
      "learning_rate": 3.1717723355235094e-05,
      "loss": 0.0028,
      "step": 8570
    },
    {
      "epoch": 0.7321443809198737,
      "grad_norm": 0.37124061584472656,
      "learning_rate": 3.169639047700316e-05,
      "loss": 0.0032,
      "step": 8580
    },
    {
      "epoch": 0.732997696049151,
      "grad_norm": 0.7335983514785767,
      "learning_rate": 3.167505759877123e-05,
      "loss": 0.0026,
      "step": 8590
    },
    {
      "epoch": 0.7338510111784282,
      "grad_norm": 0.5441038608551025,
      "learning_rate": 3.1653724720539294e-05,
      "loss": 0.0026,
      "step": 8600
    },
    {
      "epoch": 0.7347043263077054,
      "grad_norm": 0.7074642777442932,
      "learning_rate": 3.1632391842307365e-05,
      "loss": 0.0028,
      "step": 8610
    },
    {
      "epoch": 0.7355576414369827,
      "grad_norm": 1.0177689790725708,
      "learning_rate": 3.1611058964075436e-05,
      "loss": 0.0027,
      "step": 8620
    },
    {
      "epoch": 0.7364109565662599,
      "grad_norm": 0.5094059109687805,
      "learning_rate": 3.15897260858435e-05,
      "loss": 0.0031,
      "step": 8630
    },
    {
      "epoch": 0.7372642716955372,
      "grad_norm": 0.40740373730659485,
      "learning_rate": 3.156839320761157e-05,
      "loss": 0.0027,
      "step": 8640
    },
    {
      "epoch": 0.7381175868248144,
      "grad_norm": 0.4665921926498413,
      "learning_rate": 3.154706032937964e-05,
      "loss": 0.0031,
      "step": 8650
    },
    {
      "epoch": 0.7389709019540917,
      "grad_norm": 0.6053289175033569,
      "learning_rate": 3.1525727451147714e-05,
      "loss": 0.0027,
      "step": 8660
    },
    {
      "epoch": 0.7398242170833689,
      "grad_norm": 0.5021430850028992,
      "learning_rate": 3.150439457291578e-05,
      "loss": 0.0037,
      "step": 8670
    },
    {
      "epoch": 0.7406775322126461,
      "grad_norm": 0.4150630831718445,
      "learning_rate": 3.148306169468384e-05,
      "loss": 0.0041,
      "step": 8680
    },
    {
      "epoch": 0.7415308473419234,
      "grad_norm": 0.471331387758255,
      "learning_rate": 3.146172881645192e-05,
      "loss": 0.0028,
      "step": 8690
    },
    {
      "epoch": 0.7423841624712006,
      "grad_norm": 0.293057918548584,
      "learning_rate": 3.1440395938219985e-05,
      "loss": 0.0023,
      "step": 8700
    },
    {
      "epoch": 0.7432374776004779,
      "grad_norm": 0.2947864234447479,
      "learning_rate": 3.141906305998806e-05,
      "loss": 0.0033,
      "step": 8710
    },
    {
      "epoch": 0.7440907927297551,
      "grad_norm": 1.3082873821258545,
      "learning_rate": 3.139773018175612e-05,
      "loss": 0.0029,
      "step": 8720
    },
    {
      "epoch": 0.7449441078590323,
      "grad_norm": 0.2837911546230316,
      "learning_rate": 3.137639730352419e-05,
      "loss": 0.0031,
      "step": 8730
    },
    {
      "epoch": 0.7457974229883095,
      "grad_norm": 0.40697094798088074,
      "learning_rate": 3.1355064425292264e-05,
      "loss": 0.0028,
      "step": 8740
    },
    {
      "epoch": 0.7466507381175869,
      "grad_norm": 0.4869510233402252,
      "learning_rate": 3.133373154706033e-05,
      "loss": 0.003,
      "step": 8750
    },
    {
      "epoch": 0.7475040532468641,
      "grad_norm": 0.6242262721061707,
      "learning_rate": 3.13123986688284e-05,
      "loss": 0.0032,
      "step": 8760
    },
    {
      "epoch": 0.7483573683761413,
      "grad_norm": 0.669916033744812,
      "learning_rate": 3.129106579059647e-05,
      "loss": 0.0027,
      "step": 8770
    },
    {
      "epoch": 0.7492106835054185,
      "grad_norm": 0.6369458436965942,
      "learning_rate": 3.1269732912364535e-05,
      "loss": 0.0029,
      "step": 8780
    },
    {
      "epoch": 0.7500639986346957,
      "grad_norm": 0.2713164985179901,
      "learning_rate": 3.1248400034132606e-05,
      "loss": 0.0025,
      "step": 8790
    },
    {
      "epoch": 0.7509173137639731,
      "grad_norm": 0.4806941747665405,
      "learning_rate": 3.122706715590068e-05,
      "loss": 0.003,
      "step": 8800
    },
    {
      "epoch": 0.7517706288932503,
      "grad_norm": 0.7677857279777527,
      "learning_rate": 3.120573427766875e-05,
      "loss": 0.0031,
      "step": 8810
    },
    {
      "epoch": 0.7526239440225275,
      "grad_norm": 0.25759178400039673,
      "learning_rate": 3.118440139943681e-05,
      "loss": 0.0027,
      "step": 8820
    },
    {
      "epoch": 0.7534772591518047,
      "grad_norm": 0.3837921619415283,
      "learning_rate": 3.116306852120488e-05,
      "loss": 0.0022,
      "step": 8830
    },
    {
      "epoch": 0.754330574281082,
      "grad_norm": 0.37951743602752686,
      "learning_rate": 3.1141735642972955e-05,
      "loss": 0.0024,
      "step": 8840
    },
    {
      "epoch": 0.7551838894103593,
      "grad_norm": 0.5624663829803467,
      "learning_rate": 3.112040276474102e-05,
      "loss": 0.0037,
      "step": 8850
    },
    {
      "epoch": 0.7560372045396365,
      "grad_norm": 0.4532378911972046,
      "learning_rate": 3.109906988650909e-05,
      "loss": 0.0028,
      "step": 8860
    },
    {
      "epoch": 0.7568905196689137,
      "grad_norm": 0.4041806161403656,
      "learning_rate": 3.1077737008277155e-05,
      "loss": 0.0026,
      "step": 8870
    },
    {
      "epoch": 0.757743834798191,
      "grad_norm": 0.665644645690918,
      "learning_rate": 3.1056404130045227e-05,
      "loss": 0.0027,
      "step": 8880
    },
    {
      "epoch": 0.7585971499274682,
      "grad_norm": 0.41526657342910767,
      "learning_rate": 3.10350712518133e-05,
      "loss": 0.0027,
      "step": 8890
    },
    {
      "epoch": 0.7594504650567454,
      "grad_norm": 0.8743594288825989,
      "learning_rate": 3.101373837358136e-05,
      "loss": 0.0035,
      "step": 8900
    },
    {
      "epoch": 0.7603037801860227,
      "grad_norm": 0.7111926078796387,
      "learning_rate": 3.099240549534943e-05,
      "loss": 0.0031,
      "step": 8910
    },
    {
      "epoch": 0.7611570953153,
      "grad_norm": 0.4562377333641052,
      "learning_rate": 3.0971072617117505e-05,
      "loss": 0.0025,
      "step": 8920
    },
    {
      "epoch": 0.7620104104445772,
      "grad_norm": 0.43685382604599,
      "learning_rate": 3.094973973888557e-05,
      "loss": 0.0035,
      "step": 8930
    },
    {
      "epoch": 0.7628637255738544,
      "grad_norm": 0.8105562925338745,
      "learning_rate": 3.092840686065364e-05,
      "loss": 0.0027,
      "step": 8940
    },
    {
      "epoch": 0.7637170407031316,
      "grad_norm": 0.7313734889030457,
      "learning_rate": 3.090707398242171e-05,
      "loss": 0.0033,
      "step": 8950
    },
    {
      "epoch": 0.764570355832409,
      "grad_norm": 0.3173677325248718,
      "learning_rate": 3.088574110418978e-05,
      "loss": 0.0031,
      "step": 8960
    },
    {
      "epoch": 0.7654236709616862,
      "grad_norm": 0.43691927194595337,
      "learning_rate": 3.086440822595785e-05,
      "loss": 0.003,
      "step": 8970
    },
    {
      "epoch": 0.7662769860909634,
      "grad_norm": 0.5292736887931824,
      "learning_rate": 3.084307534772592e-05,
      "loss": 0.0027,
      "step": 8980
    },
    {
      "epoch": 0.7671303012202406,
      "grad_norm": 1.0341007709503174,
      "learning_rate": 3.082174246949398e-05,
      "loss": 0.0027,
      "step": 8990
    },
    {
      "epoch": 0.7679836163495178,
      "grad_norm": 0.5269879698753357,
      "learning_rate": 3.0800409591262054e-05,
      "loss": 0.0029,
      "step": 9000
    },
    {
      "epoch": 0.7688369314787952,
      "grad_norm": 0.26432350277900696,
      "learning_rate": 3.0779076713030125e-05,
      "loss": 0.0032,
      "step": 9010
    },
    {
      "epoch": 0.7696902466080724,
      "grad_norm": 0.6120054721832275,
      "learning_rate": 3.075774383479819e-05,
      "loss": 0.0029,
      "step": 9020
    },
    {
      "epoch": 0.7705435617373496,
      "grad_norm": 1.30785071849823,
      "learning_rate": 3.073641095656626e-05,
      "loss": 0.0034,
      "step": 9030
    },
    {
      "epoch": 0.7713968768666268,
      "grad_norm": 0.28844547271728516,
      "learning_rate": 3.071507807833433e-05,
      "loss": 0.0022,
      "step": 9040
    },
    {
      "epoch": 0.7722501919959041,
      "grad_norm": 0.35636448860168457,
      "learning_rate": 3.0693745200102396e-05,
      "loss": 0.0032,
      "step": 9050
    },
    {
      "epoch": 0.7731035071251813,
      "grad_norm": 0.5933456420898438,
      "learning_rate": 3.067241232187047e-05,
      "loss": 0.0027,
      "step": 9060
    },
    {
      "epoch": 0.7739568222544586,
      "grad_norm": 0.47464966773986816,
      "learning_rate": 3.065107944363854e-05,
      "loss": 0.0034,
      "step": 9070
    },
    {
      "epoch": 0.7748101373837358,
      "grad_norm": 0.3374938368797302,
      "learning_rate": 3.062974656540661e-05,
      "loss": 0.0027,
      "step": 9080
    },
    {
      "epoch": 0.775663452513013,
      "grad_norm": 0.6007347106933594,
      "learning_rate": 3.0608413687174674e-05,
      "loss": 0.0029,
      "step": 9090
    },
    {
      "epoch": 0.7765167676422903,
      "grad_norm": 0.4730364680290222,
      "learning_rate": 3.058708080894274e-05,
      "loss": 0.0025,
      "step": 9100
    },
    {
      "epoch": 0.7773700827715675,
      "grad_norm": 0.3465597927570343,
      "learning_rate": 3.056574793071082e-05,
      "loss": 0.0033,
      "step": 9110
    },
    {
      "epoch": 0.7782233979008448,
      "grad_norm": 0.46163052320480347,
      "learning_rate": 3.054441505247888e-05,
      "loss": 0.0027,
      "step": 9120
    },
    {
      "epoch": 0.779076713030122,
      "grad_norm": 1.5146360397338867,
      "learning_rate": 3.052308217424695e-05,
      "loss": 0.0032,
      "step": 9130
    },
    {
      "epoch": 0.7799300281593993,
      "grad_norm": 0.25251078605651855,
      "learning_rate": 3.050174929601502e-05,
      "loss": 0.0027,
      "step": 9140
    },
    {
      "epoch": 0.7807833432886765,
      "grad_norm": 0.4503468871116638,
      "learning_rate": 3.0480416417783088e-05,
      "loss": 0.0026,
      "step": 9150
    },
    {
      "epoch": 0.7816366584179537,
      "grad_norm": 1.1330487728118896,
      "learning_rate": 3.045908353955116e-05,
      "loss": 0.0026,
      "step": 9160
    },
    {
      "epoch": 0.782489973547231,
      "grad_norm": 0.9097617864608765,
      "learning_rate": 3.0437750661319224e-05,
      "loss": 0.0034,
      "step": 9170
    },
    {
      "epoch": 0.7833432886765083,
      "grad_norm": 0.35863974690437317,
      "learning_rate": 3.0416417783087298e-05,
      "loss": 0.0026,
      "step": 9180
    },
    {
      "epoch": 0.7841966038057855,
      "grad_norm": 0.4231196343898773,
      "learning_rate": 3.0395084904855363e-05,
      "loss": 0.0031,
      "step": 9190
    },
    {
      "epoch": 0.7850499189350627,
      "grad_norm": 0.37136590480804443,
      "learning_rate": 3.037375202662343e-05,
      "loss": 0.003,
      "step": 9200
    },
    {
      "epoch": 0.7859032340643399,
      "grad_norm": 0.6486530303955078,
      "learning_rate": 3.0352419148391502e-05,
      "loss": 0.0026,
      "step": 9210
    },
    {
      "epoch": 0.7867565491936171,
      "grad_norm": 0.34430068731307983,
      "learning_rate": 3.033108627015957e-05,
      "loss": 0.0028,
      "step": 9220
    },
    {
      "epoch": 0.7876098643228945,
      "grad_norm": 0.5163218975067139,
      "learning_rate": 3.030975339192764e-05,
      "loss": 0.0034,
      "step": 9230
    },
    {
      "epoch": 0.7884631794521717,
      "grad_norm": 0.9347741603851318,
      "learning_rate": 3.028842051369571e-05,
      "loss": 0.0025,
      "step": 9240
    },
    {
      "epoch": 0.7893164945814489,
      "grad_norm": 0.7897810339927673,
      "learning_rate": 3.0267087635463776e-05,
      "loss": 0.003,
      "step": 9250
    },
    {
      "epoch": 0.7901698097107261,
      "grad_norm": 0.5346342921257019,
      "learning_rate": 3.0245754757231848e-05,
      "loss": 0.0026,
      "step": 9260
    },
    {
      "epoch": 0.7910231248400034,
      "grad_norm": 0.46807944774627686,
      "learning_rate": 3.0224421878999915e-05,
      "loss": 0.0028,
      "step": 9270
    },
    {
      "epoch": 0.7918764399692807,
      "grad_norm": 0.3776074945926666,
      "learning_rate": 3.0203089000767987e-05,
      "loss": 0.0032,
      "step": 9280
    },
    {
      "epoch": 0.7927297550985579,
      "grad_norm": 0.5319949388504028,
      "learning_rate": 3.0181756122536054e-05,
      "loss": 0.0026,
      "step": 9290
    },
    {
      "epoch": 0.7935830702278351,
      "grad_norm": 0.7852982878684998,
      "learning_rate": 3.0160423244304126e-05,
      "loss": 0.0023,
      "step": 9300
    },
    {
      "epoch": 0.7944363853571124,
      "grad_norm": 0.8134033679962158,
      "learning_rate": 3.0139090366072193e-05,
      "loss": 0.0027,
      "step": 9310
    },
    {
      "epoch": 0.7952897004863896,
      "grad_norm": 0.5657973885536194,
      "learning_rate": 3.0117757487840258e-05,
      "loss": 0.0029,
      "step": 9320
    },
    {
      "epoch": 0.7961430156156669,
      "grad_norm": 1.49339759349823,
      "learning_rate": 3.0096424609608332e-05,
      "loss": 0.0029,
      "step": 9330
    },
    {
      "epoch": 0.7969963307449441,
      "grad_norm": 0.5736903548240662,
      "learning_rate": 3.0075091731376397e-05,
      "loss": 0.0026,
      "step": 9340
    },
    {
      "epoch": 0.7978496458742214,
      "grad_norm": 0.6599093079566956,
      "learning_rate": 3.005375885314447e-05,
      "loss": 0.0032,
      "step": 9350
    },
    {
      "epoch": 0.7987029610034986,
      "grad_norm": 0.9639307856559753,
      "learning_rate": 3.0032425974912536e-05,
      "loss": 0.0028,
      "step": 9360
    },
    {
      "epoch": 0.7995562761327758,
      "grad_norm": 0.8119968771934509,
      "learning_rate": 3.0011093096680604e-05,
      "loss": 0.0028,
      "step": 9370
    },
    {
      "epoch": 0.800409591262053,
      "grad_norm": 0.23833775520324707,
      "learning_rate": 2.9989760218448675e-05,
      "loss": 0.0034,
      "step": 9380
    },
    {
      "epoch": 0.8012629063913304,
      "grad_norm": 0.3198651969432831,
      "learning_rate": 2.9968427340216743e-05,
      "loss": 0.0027,
      "step": 9390
    },
    {
      "epoch": 0.8021162215206076,
      "grad_norm": 0.5061514377593994,
      "learning_rate": 2.9947094461984814e-05,
      "loss": 0.0027,
      "step": 9400
    },
    {
      "epoch": 0.8029695366498848,
      "grad_norm": 0.2867767810821533,
      "learning_rate": 2.9925761583752882e-05,
      "loss": 0.0033,
      "step": 9410
    },
    {
      "epoch": 0.803822851779162,
      "grad_norm": 0.4756493866443634,
      "learning_rate": 2.990442870552095e-05,
      "loss": 0.0025,
      "step": 9420
    },
    {
      "epoch": 0.8046761669084392,
      "grad_norm": 0.7150757908821106,
      "learning_rate": 2.988309582728902e-05,
      "loss": 0.003,
      "step": 9430
    },
    {
      "epoch": 0.8055294820377166,
      "grad_norm": 0.6480031609535217,
      "learning_rate": 2.986176294905709e-05,
      "loss": 0.0025,
      "step": 9440
    },
    {
      "epoch": 0.8063827971669938,
      "grad_norm": 0.6185547709465027,
      "learning_rate": 2.984043007082516e-05,
      "loss": 0.003,
      "step": 9450
    },
    {
      "epoch": 0.807236112296271,
      "grad_norm": 0.6645927429199219,
      "learning_rate": 2.9819097192593228e-05,
      "loss": 0.0026,
      "step": 9460
    },
    {
      "epoch": 0.8080894274255482,
      "grad_norm": 1.0110665559768677,
      "learning_rate": 2.9797764314361292e-05,
      "loss": 0.0023,
      "step": 9470
    },
    {
      "epoch": 0.8089427425548255,
      "grad_norm": 0.2955022156238556,
      "learning_rate": 2.9776431436129367e-05,
      "loss": 0.0029,
      "step": 9480
    },
    {
      "epoch": 0.8097960576841028,
      "grad_norm": 0.2736419439315796,
      "learning_rate": 2.975509855789743e-05,
      "loss": 0.0026,
      "step": 9490
    },
    {
      "epoch": 0.81064937281338,
      "grad_norm": 0.44118720293045044,
      "learning_rate": 2.9733765679665502e-05,
      "loss": 0.0029,
      "step": 9500
    },
    {
      "epoch": 0.8115026879426572,
      "grad_norm": 0.5145752429962158,
      "learning_rate": 2.971243280143357e-05,
      "loss": 0.0028,
      "step": 9510
    },
    {
      "epoch": 0.8123560030719345,
      "grad_norm": 0.6710206866264343,
      "learning_rate": 2.9691099923201638e-05,
      "loss": 0.0029,
      "step": 9520
    },
    {
      "epoch": 0.8132093182012117,
      "grad_norm": 0.37794870138168335,
      "learning_rate": 2.966976704496971e-05,
      "loss": 0.0029,
      "step": 9530
    },
    {
      "epoch": 0.814062633330489,
      "grad_norm": 0.43491876125335693,
      "learning_rate": 2.9648434166737777e-05,
      "loss": 0.0022,
      "step": 9540
    },
    {
      "epoch": 0.8149159484597662,
      "grad_norm": 0.46694979071617126,
      "learning_rate": 2.9627101288505848e-05,
      "loss": 0.0031,
      "step": 9550
    },
    {
      "epoch": 0.8157692635890434,
      "grad_norm": 0.2932458221912384,
      "learning_rate": 2.9605768410273916e-05,
      "loss": 0.0029,
      "step": 9560
    },
    {
      "epoch": 0.8166225787183207,
      "grad_norm": 0.40609028935432434,
      "learning_rate": 2.958443553204198e-05,
      "loss": 0.0027,
      "step": 9570
    },
    {
      "epoch": 0.8174758938475979,
      "grad_norm": 0.4625610411167145,
      "learning_rate": 2.9563102653810055e-05,
      "loss": 0.0036,
      "step": 9580
    },
    {
      "epoch": 0.8183292089768751,
      "grad_norm": 0.5872007012367249,
      "learning_rate": 2.954176977557812e-05,
      "loss": 0.0025,
      "step": 9590
    },
    {
      "epoch": 0.8191825241061524,
      "grad_norm": 1.0777785778045654,
      "learning_rate": 2.9520436897346194e-05,
      "loss": 0.003,
      "step": 9600
    },
    {
      "epoch": 0.8200358392354297,
      "grad_norm": 0.7038703560829163,
      "learning_rate": 2.949910401911426e-05,
      "loss": 0.003,
      "step": 9610
    },
    {
      "epoch": 0.8208891543647069,
      "grad_norm": 0.6989539265632629,
      "learning_rate": 2.9477771140882326e-05,
      "loss": 0.0031,
      "step": 9620
    },
    {
      "epoch": 0.8217424694939841,
      "grad_norm": 0.3286883234977722,
      "learning_rate": 2.9456438262650397e-05,
      "loss": 0.0035,
      "step": 9630
    },
    {
      "epoch": 0.8225957846232613,
      "grad_norm": 0.42230960726737976,
      "learning_rate": 2.9435105384418465e-05,
      "loss": 0.0038,
      "step": 9640
    },
    {
      "epoch": 0.8234490997525387,
      "grad_norm": 1.175321102142334,
      "learning_rate": 2.9413772506186536e-05,
      "loss": 0.0033,
      "step": 9650
    },
    {
      "epoch": 0.8243024148818159,
      "grad_norm": 0.5991268754005432,
      "learning_rate": 2.9392439627954604e-05,
      "loss": 0.0029,
      "step": 9660
    },
    {
      "epoch": 0.8251557300110931,
      "grad_norm": 0.8808721899986267,
      "learning_rate": 2.9371106749722676e-05,
      "loss": 0.0025,
      "step": 9670
    },
    {
      "epoch": 0.8260090451403703,
      "grad_norm": 0.7621424198150635,
      "learning_rate": 2.9349773871490743e-05,
      "loss": 0.0027,
      "step": 9680
    },
    {
      "epoch": 0.8268623602696475,
      "grad_norm": 0.34990572929382324,
      "learning_rate": 2.932844099325881e-05,
      "loss": 0.0029,
      "step": 9690
    },
    {
      "epoch": 0.8277156753989249,
      "grad_norm": 1.0358844995498657,
      "learning_rate": 2.9307108115026882e-05,
      "loss": 0.0036,
      "step": 9700
    },
    {
      "epoch": 0.8285689905282021,
      "grad_norm": 0.6214467883110046,
      "learning_rate": 2.928577523679495e-05,
      "loss": 0.003,
      "step": 9710
    },
    {
      "epoch": 0.8294223056574793,
      "grad_norm": 0.37730443477630615,
      "learning_rate": 2.926444235856302e-05,
      "loss": 0.0026,
      "step": 9720
    },
    {
      "epoch": 0.8302756207867565,
      "grad_norm": 0.36149173974990845,
      "learning_rate": 2.924310948033109e-05,
      "loss": 0.0035,
      "step": 9730
    },
    {
      "epoch": 0.8311289359160338,
      "grad_norm": 0.4513644874095917,
      "learning_rate": 2.9221776602099154e-05,
      "loss": 0.0033,
      "step": 9740
    },
    {
      "epoch": 0.831982251045311,
      "grad_norm": 0.2507188022136688,
      "learning_rate": 2.9200443723867228e-05,
      "loss": 0.0029,
      "step": 9750
    },
    {
      "epoch": 0.8328355661745883,
      "grad_norm": 0.7794542908668518,
      "learning_rate": 2.9179110845635293e-05,
      "loss": 0.0036,
      "step": 9760
    },
    {
      "epoch": 0.8336888813038655,
      "grad_norm": 0.42870014905929565,
      "learning_rate": 2.9157777967403367e-05,
      "loss": 0.0027,
      "step": 9770
    },
    {
      "epoch": 0.8345421964331428,
      "grad_norm": 0.9001891016960144,
      "learning_rate": 2.913644508917143e-05,
      "loss": 0.0029,
      "step": 9780
    },
    {
      "epoch": 0.83539551156242,
      "grad_norm": 0.5143696069717407,
      "learning_rate": 2.91151122109395e-05,
      "loss": 0.0027,
      "step": 9790
    },
    {
      "epoch": 0.8362488266916972,
      "grad_norm": 0.6205989718437195,
      "learning_rate": 2.909377933270757e-05,
      "loss": 0.0032,
      "step": 9800
    },
    {
      "epoch": 0.8371021418209745,
      "grad_norm": 0.5273516178131104,
      "learning_rate": 2.907244645447564e-05,
      "loss": 0.003,
      "step": 9810
    },
    {
      "epoch": 0.8379554569502518,
      "grad_norm": 0.4099820554256439,
      "learning_rate": 2.905111357624371e-05,
      "loss": 0.0032,
      "step": 9820
    },
    {
      "epoch": 0.838808772079529,
      "grad_norm": 0.6532618403434753,
      "learning_rate": 2.9029780698011778e-05,
      "loss": 0.0035,
      "step": 9830
    },
    {
      "epoch": 0.8396620872088062,
      "grad_norm": 0.382829874753952,
      "learning_rate": 2.9008447819779845e-05,
      "loss": 0.0022,
      "step": 9840
    },
    {
      "epoch": 0.8405154023380834,
      "grad_norm": 0.3977227807044983,
      "learning_rate": 2.8987114941547917e-05,
      "loss": 0.0027,
      "step": 9850
    },
    {
      "epoch": 0.8413687174673607,
      "grad_norm": 0.5319696068763733,
      "learning_rate": 2.896578206331598e-05,
      "loss": 0.003,
      "step": 9860
    },
    {
      "epoch": 0.842222032596638,
      "grad_norm": 0.8225969076156616,
      "learning_rate": 2.8944449185084056e-05,
      "loss": 0.0024,
      "step": 9870
    },
    {
      "epoch": 0.8430753477259152,
      "grad_norm": 0.8587256669998169,
      "learning_rate": 2.892311630685212e-05,
      "loss": 0.0027,
      "step": 9880
    },
    {
      "epoch": 0.8439286628551924,
      "grad_norm": 0.45197150111198425,
      "learning_rate": 2.8901783428620188e-05,
      "loss": 0.0034,
      "step": 9890
    },
    {
      "epoch": 0.8447819779844696,
      "grad_norm": 0.43586447834968567,
      "learning_rate": 2.888045055038826e-05,
      "loss": 0.0032,
      "step": 9900
    },
    {
      "epoch": 0.8456352931137469,
      "grad_norm": 0.4801836907863617,
      "learning_rate": 2.8859117672156327e-05,
      "loss": 0.0024,
      "step": 9910
    },
    {
      "epoch": 0.8464886082430242,
      "grad_norm": 0.7139121890068054,
      "learning_rate": 2.8837784793924398e-05,
      "loss": 0.0027,
      "step": 9920
    },
    {
      "epoch": 0.8473419233723014,
      "grad_norm": 1.0091172456741333,
      "learning_rate": 2.8816451915692466e-05,
      "loss": 0.0028,
      "step": 9930
    },
    {
      "epoch": 0.8481952385015786,
      "grad_norm": 0.8624526858329773,
      "learning_rate": 2.8795119037460534e-05,
      "loss": 0.0036,
      "step": 9940
    },
    {
      "epoch": 0.8490485536308559,
      "grad_norm": 0.24614714086055756,
      "learning_rate": 2.8773786159228605e-05,
      "loss": 0.0021,
      "step": 9950
    },
    {
      "epoch": 0.8499018687601331,
      "grad_norm": 0.819198489189148,
      "learning_rate": 2.8752453280996673e-05,
      "loss": 0.0029,
      "step": 9960
    },
    {
      "epoch": 0.8507551838894104,
      "grad_norm": 0.4065244495868683,
      "learning_rate": 2.8731120402764744e-05,
      "loss": 0.0028,
      "step": 9970
    },
    {
      "epoch": 0.8516084990186876,
      "grad_norm": 0.35109058022499084,
      "learning_rate": 2.8709787524532812e-05,
      "loss": 0.003,
      "step": 9980
    },
    {
      "epoch": 0.8524618141479648,
      "grad_norm": 0.5397046208381653,
      "learning_rate": 2.8688454646300883e-05,
      "loss": 0.0028,
      "step": 9990
    },
    {
      "epoch": 0.8533151292772421,
      "grad_norm": 0.44710424542427063,
      "learning_rate": 2.866712176806895e-05,
      "loss": 0.003,
      "step": 10000
    },
    {
      "epoch": 0.8541684444065193,
      "grad_norm": 0.2747822403907776,
      "learning_rate": 2.8645788889837015e-05,
      "loss": 0.0032,
      "step": 10010
    },
    {
      "epoch": 0.8550217595357966,
      "grad_norm": 0.6138347387313843,
      "learning_rate": 2.862445601160509e-05,
      "loss": 0.0022,
      "step": 10020
    },
    {
      "epoch": 0.8558750746650738,
      "grad_norm": 0.377492755651474,
      "learning_rate": 2.8603123133373154e-05,
      "loss": 0.0031,
      "step": 10030
    },
    {
      "epoch": 0.8567283897943511,
      "grad_norm": 0.48800128698349,
      "learning_rate": 2.858179025514123e-05,
      "loss": 0.0026,
      "step": 10040
    },
    {
      "epoch": 0.8575817049236283,
      "grad_norm": 0.3122875690460205,
      "learning_rate": 2.8560457376909293e-05,
      "loss": 0.003,
      "step": 10050
    },
    {
      "epoch": 0.8584350200529055,
      "grad_norm": 0.3062913715839386,
      "learning_rate": 2.853912449867736e-05,
      "loss": 0.0026,
      "step": 10060
    },
    {
      "epoch": 0.8592883351821827,
      "grad_norm": 0.5807976126670837,
      "learning_rate": 2.8517791620445432e-05,
      "loss": 0.0035,
      "step": 10070
    },
    {
      "epoch": 0.8601416503114601,
      "grad_norm": 0.7960125803947449,
      "learning_rate": 2.84964587422135e-05,
      "loss": 0.0023,
      "step": 10080
    },
    {
      "epoch": 0.8609949654407373,
      "grad_norm": 0.5725705623626709,
      "learning_rate": 2.847512586398157e-05,
      "loss": 0.0033,
      "step": 10090
    },
    {
      "epoch": 0.8618482805700145,
      "grad_norm": 0.39334049820899963,
      "learning_rate": 2.845379298574964e-05,
      "loss": 0.003,
      "step": 10100
    },
    {
      "epoch": 0.8627015956992917,
      "grad_norm": 0.4641698896884918,
      "learning_rate": 2.8432460107517707e-05,
      "loss": 0.0027,
      "step": 10110
    },
    {
      "epoch": 0.863554910828569,
      "grad_norm": 0.7865340113639832,
      "learning_rate": 2.8411127229285778e-05,
      "loss": 0.0029,
      "step": 10120
    },
    {
      "epoch": 0.8644082259578463,
      "grad_norm": 0.4219665229320526,
      "learning_rate": 2.8389794351053846e-05,
      "loss": 0.0023,
      "step": 10130
    },
    {
      "epoch": 0.8652615410871235,
      "grad_norm": 0.5379762649536133,
      "learning_rate": 2.8368461472821917e-05,
      "loss": 0.0024,
      "step": 10140
    },
    {
      "epoch": 0.8661148562164007,
      "grad_norm": 0.3621883988380432,
      "learning_rate": 2.8347128594589985e-05,
      "loss": 0.0027,
      "step": 10150
    },
    {
      "epoch": 0.8669681713456779,
      "grad_norm": 0.635636568069458,
      "learning_rate": 2.832579571635805e-05,
      "loss": 0.0028,
      "step": 10160
    },
    {
      "epoch": 0.8678214864749552,
      "grad_norm": 0.47206178307533264,
      "learning_rate": 2.8304462838126124e-05,
      "loss": 0.0032,
      "step": 10170
    },
    {
      "epoch": 0.8686748016042325,
      "grad_norm": 0.9096760749816895,
      "learning_rate": 2.828312995989419e-05,
      "loss": 0.0025,
      "step": 10180
    },
    {
      "epoch": 0.8695281167335097,
      "grad_norm": 0.530159592628479,
      "learning_rate": 2.826179708166226e-05,
      "loss": 0.0031,
      "step": 10190
    },
    {
      "epoch": 0.8703814318627869,
      "grad_norm": 0.49733608961105347,
      "learning_rate": 2.8240464203430327e-05,
      "loss": 0.0026,
      "step": 10200
    },
    {
      "epoch": 0.8712347469920642,
      "grad_norm": 0.6268317699432373,
      "learning_rate": 2.8219131325198395e-05,
      "loss": 0.0024,
      "step": 10210
    },
    {
      "epoch": 0.8720880621213414,
      "grad_norm": 0.4445286691188812,
      "learning_rate": 2.8197798446966466e-05,
      "loss": 0.003,
      "step": 10220
    },
    {
      "epoch": 0.8729413772506186,
      "grad_norm": 0.5929539799690247,
      "learning_rate": 2.8176465568734534e-05,
      "loss": 0.0029,
      "step": 10230
    },
    {
      "epoch": 0.8737946923798959,
      "grad_norm": 0.8792244791984558,
      "learning_rate": 2.8155132690502605e-05,
      "loss": 0.0031,
      "step": 10240
    },
    {
      "epoch": 0.8746480075091732,
      "grad_norm": 0.7838883996009827,
      "learning_rate": 2.8133799812270673e-05,
      "loss": 0.0036,
      "step": 10250
    },
    {
      "epoch": 0.8755013226384504,
      "grad_norm": 0.5578578114509583,
      "learning_rate": 2.8112466934038738e-05,
      "loss": 0.0029,
      "step": 10260
    },
    {
      "epoch": 0.8763546377677276,
      "grad_norm": 1.229743480682373,
      "learning_rate": 2.8091134055806812e-05,
      "loss": 0.0029,
      "step": 10270
    },
    {
      "epoch": 0.8772079528970048,
      "grad_norm": 0.6677802205085754,
      "learning_rate": 2.8069801177574877e-05,
      "loss": 0.0026,
      "step": 10280
    },
    {
      "epoch": 0.8780612680262821,
      "grad_norm": 0.8209224343299866,
      "learning_rate": 2.804846829934295e-05,
      "loss": 0.003,
      "step": 10290
    },
    {
      "epoch": 0.8789145831555594,
      "grad_norm": 0.4201257824897766,
      "learning_rate": 2.8027135421111016e-05,
      "loss": 0.0031,
      "step": 10300
    },
    {
      "epoch": 0.8797678982848366,
      "grad_norm": 0.9294293522834778,
      "learning_rate": 2.800580254287909e-05,
      "loss": 0.0027,
      "step": 10310
    },
    {
      "epoch": 0.8806212134141138,
      "grad_norm": 0.511751115322113,
      "learning_rate": 2.7984469664647155e-05,
      "loss": 0.0031,
      "step": 10320
    },
    {
      "epoch": 0.881474528543391,
      "grad_norm": 0.7230364680290222,
      "learning_rate": 2.7963136786415223e-05,
      "loss": 0.003,
      "step": 10330
    },
    {
      "epoch": 0.8823278436726684,
      "grad_norm": 0.555300772190094,
      "learning_rate": 2.7941803908183294e-05,
      "loss": 0.0031,
      "step": 10340
    },
    {
      "epoch": 0.8831811588019456,
      "grad_norm": 0.3594192564487457,
      "learning_rate": 2.792047102995136e-05,
      "loss": 0.0027,
      "step": 10350
    },
    {
      "epoch": 0.8840344739312228,
      "grad_norm": 0.29215458035469055,
      "learning_rate": 2.7899138151719433e-05,
      "loss": 0.0023,
      "step": 10360
    },
    {
      "epoch": 0.8848877890605,
      "grad_norm": 0.5614261627197266,
      "learning_rate": 2.78778052734875e-05,
      "loss": 0.0028,
      "step": 10370
    },
    {
      "epoch": 0.8857411041897773,
      "grad_norm": 0.3773361146450043,
      "learning_rate": 2.785647239525557e-05,
      "loss": 0.0026,
      "step": 10380
    },
    {
      "epoch": 0.8865944193190545,
      "grad_norm": 1.1276813745498657,
      "learning_rate": 2.783513951702364e-05,
      "loss": 0.0023,
      "step": 10390
    },
    {
      "epoch": 0.8874477344483318,
      "grad_norm": 0.5332100987434387,
      "learning_rate": 2.7813806638791707e-05,
      "loss": 0.0027,
      "step": 10400
    },
    {
      "epoch": 0.888301049577609,
      "grad_norm": 0.7976422309875488,
      "learning_rate": 2.779247376055978e-05,
      "loss": 0.0029,
      "step": 10410
    },
    {
      "epoch": 0.8891543647068862,
      "grad_norm": 1.2231709957122803,
      "learning_rate": 2.7771140882327846e-05,
      "loss": 0.0033,
      "step": 10420
    },
    {
      "epoch": 0.8900076798361635,
      "grad_norm": 0.5619739294052124,
      "learning_rate": 2.774980800409591e-05,
      "loss": 0.0027,
      "step": 10430
    },
    {
      "epoch": 0.8908609949654407,
      "grad_norm": 0.3879666030406952,
      "learning_rate": 2.7728475125863985e-05,
      "loss": 0.0031,
      "step": 10440
    },
    {
      "epoch": 0.891714310094718,
      "grad_norm": 0.4042624235153198,
      "learning_rate": 2.770714224763205e-05,
      "loss": 0.0028,
      "step": 10450
    },
    {
      "epoch": 0.8925676252239952,
      "grad_norm": 0.6578229069709778,
      "learning_rate": 2.7685809369400125e-05,
      "loss": 0.0036,
      "step": 10460
    },
    {
      "epoch": 0.8934209403532725,
      "grad_norm": 0.842664897441864,
      "learning_rate": 2.766447649116819e-05,
      "loss": 0.0034,
      "step": 10470
    },
    {
      "epoch": 0.8942742554825497,
      "grad_norm": 0.624100387096405,
      "learning_rate": 2.7643143612936257e-05,
      "loss": 0.0025,
      "step": 10480
    },
    {
      "epoch": 0.8951275706118269,
      "grad_norm": 1.2163829803466797,
      "learning_rate": 2.7621810734704328e-05,
      "loss": 0.0026,
      "step": 10490
    },
    {
      "epoch": 0.8959808857411042,
      "grad_norm": 0.8248667120933533,
      "learning_rate": 2.7600477856472396e-05,
      "loss": 0.0027,
      "step": 10500
    },
    {
      "epoch": 0.8968342008703815,
      "grad_norm": 0.6363745927810669,
      "learning_rate": 2.7579144978240467e-05,
      "loss": 0.0032,
      "step": 10510
    },
    {
      "epoch": 0.8976875159996587,
      "grad_norm": 0.48962724208831787,
      "learning_rate": 2.7557812100008535e-05,
      "loss": 0.0037,
      "step": 10520
    },
    {
      "epoch": 0.8985408311289359,
      "grad_norm": 1.323657512664795,
      "learning_rate": 2.7536479221776603e-05,
      "loss": 0.0033,
      "step": 10530
    },
    {
      "epoch": 0.8993941462582131,
      "grad_norm": 0.7532597780227661,
      "learning_rate": 2.7515146343544674e-05,
      "loss": 0.0029,
      "step": 10540
    },
    {
      "epoch": 0.9002474613874905,
      "grad_norm": 0.3515133857727051,
      "learning_rate": 2.749381346531274e-05,
      "loss": 0.0027,
      "step": 10550
    },
    {
      "epoch": 0.9011007765167677,
      "grad_norm": 0.5861603021621704,
      "learning_rate": 2.7472480587080813e-05,
      "loss": 0.0027,
      "step": 10560
    },
    {
      "epoch": 0.9019540916460449,
      "grad_norm": 0.9198058843612671,
      "learning_rate": 2.7451147708848877e-05,
      "loss": 0.0027,
      "step": 10570
    },
    {
      "epoch": 0.9028074067753221,
      "grad_norm": 1.0647472143173218,
      "learning_rate": 2.7429814830616945e-05,
      "loss": 0.0032,
      "step": 10580
    },
    {
      "epoch": 0.9036607219045993,
      "grad_norm": 0.5150646567344666,
      "learning_rate": 2.7408481952385016e-05,
      "loss": 0.0028,
      "step": 10590
    },
    {
      "epoch": 0.9045140370338766,
      "grad_norm": 0.41034451127052307,
      "learning_rate": 2.7387149074153084e-05,
      "loss": 0.003,
      "step": 10600
    },
    {
      "epoch": 0.9053673521631539,
      "grad_norm": 0.565560519695282,
      "learning_rate": 2.7365816195921155e-05,
      "loss": 0.004,
      "step": 10610
    },
    {
      "epoch": 0.9062206672924311,
      "grad_norm": 0.41520392894744873,
      "learning_rate": 2.7344483317689223e-05,
      "loss": 0.0026,
      "step": 10620
    },
    {
      "epoch": 0.9070739824217083,
      "grad_norm": 0.6690059900283813,
      "learning_rate": 2.732315043945729e-05,
      "loss": 0.0023,
      "step": 10630
    },
    {
      "epoch": 0.9079272975509856,
      "grad_norm": 0.4210352897644043,
      "learning_rate": 2.7301817561225362e-05,
      "loss": 0.0033,
      "step": 10640
    },
    {
      "epoch": 0.9087806126802628,
      "grad_norm": 0.30375757813453674,
      "learning_rate": 2.728048468299343e-05,
      "loss": 0.003,
      "step": 10650
    },
    {
      "epoch": 0.9096339278095401,
      "grad_norm": 0.557594358921051,
      "learning_rate": 2.72591518047615e-05,
      "loss": 0.0023,
      "step": 10660
    },
    {
      "epoch": 0.9104872429388173,
      "grad_norm": 0.43799352645874023,
      "learning_rate": 2.723781892652957e-05,
      "loss": 0.0027,
      "step": 10670
    },
    {
      "epoch": 0.9113405580680946,
      "grad_norm": 0.32669520378112793,
      "learning_rate": 2.721648604829764e-05,
      "loss": 0.0028,
      "step": 10680
    },
    {
      "epoch": 0.9121938731973718,
      "grad_norm": 0.3269958794116974,
      "learning_rate": 2.7195153170065708e-05,
      "loss": 0.0032,
      "step": 10690
    },
    {
      "epoch": 0.913047188326649,
      "grad_norm": 0.8070620894432068,
      "learning_rate": 2.7173820291833772e-05,
      "loss": 0.0023,
      "step": 10700
    },
    {
      "epoch": 0.9139005034559263,
      "grad_norm": 0.42461851239204407,
      "learning_rate": 2.7152487413601847e-05,
      "loss": 0.0026,
      "step": 10710
    },
    {
      "epoch": 0.9147538185852035,
      "grad_norm": 0.4478459060192108,
      "learning_rate": 2.713115453536991e-05,
      "loss": 0.0034,
      "step": 10720
    },
    {
      "epoch": 0.9156071337144808,
      "grad_norm": 1.0475255250930786,
      "learning_rate": 2.7109821657137986e-05,
      "loss": 0.0029,
      "step": 10730
    },
    {
      "epoch": 0.916460448843758,
      "grad_norm": 0.6756716370582581,
      "learning_rate": 2.708848877890605e-05,
      "loss": 0.0028,
      "step": 10740
    },
    {
      "epoch": 0.9173137639730352,
      "grad_norm": 0.699680745601654,
      "learning_rate": 2.7067155900674118e-05,
      "loss": 0.0036,
      "step": 10750
    },
    {
      "epoch": 0.9181670791023124,
      "grad_norm": 0.41106748580932617,
      "learning_rate": 2.704582302244219e-05,
      "loss": 0.0023,
      "step": 10760
    },
    {
      "epoch": 0.9190203942315898,
      "grad_norm": 1.0008468627929688,
      "learning_rate": 2.7024490144210257e-05,
      "loss": 0.0031,
      "step": 10770
    },
    {
      "epoch": 0.919873709360867,
      "grad_norm": 0.3852497935295105,
      "learning_rate": 2.700315726597833e-05,
      "loss": 0.0034,
      "step": 10780
    },
    {
      "epoch": 0.9207270244901442,
      "grad_norm": 0.9052222967147827,
      "learning_rate": 2.6981824387746396e-05,
      "loss": 0.0029,
      "step": 10790
    },
    {
      "epoch": 0.9215803396194214,
      "grad_norm": 0.3506653904914856,
      "learning_rate": 2.6960491509514464e-05,
      "loss": 0.0025,
      "step": 10800
    },
    {
      "epoch": 0.9224336547486987,
      "grad_norm": 0.6856386065483093,
      "learning_rate": 2.6939158631282535e-05,
      "loss": 0.0027,
      "step": 10810
    },
    {
      "epoch": 0.923286969877976,
      "grad_norm": 0.3397218585014343,
      "learning_rate": 2.6917825753050603e-05,
      "loss": 0.0028,
      "step": 10820
    },
    {
      "epoch": 0.9241402850072532,
      "grad_norm": 0.4042689800262451,
      "learning_rate": 2.6896492874818674e-05,
      "loss": 0.0033,
      "step": 10830
    },
    {
      "epoch": 0.9249936001365304,
      "grad_norm": 0.3285790979862213,
      "learning_rate": 2.6875159996586742e-05,
      "loss": 0.0032,
      "step": 10840
    },
    {
      "epoch": 0.9258469152658076,
      "grad_norm": 0.8519858121871948,
      "learning_rate": 2.6853827118354807e-05,
      "loss": 0.0028,
      "step": 10850
    },
    {
      "epoch": 0.9267002303950849,
      "grad_norm": 0.3409308195114136,
      "learning_rate": 2.683249424012288e-05,
      "loss": 0.002,
      "step": 10860
    },
    {
      "epoch": 0.9275535455243622,
      "grad_norm": 0.5741409659385681,
      "learning_rate": 2.6811161361890946e-05,
      "loss": 0.0031,
      "step": 10870
    },
    {
      "epoch": 0.9284068606536394,
      "grad_norm": 0.4308837056159973,
      "learning_rate": 2.6789828483659017e-05,
      "loss": 0.0027,
      "step": 10880
    },
    {
      "epoch": 0.9292601757829166,
      "grad_norm": 0.672417163848877,
      "learning_rate": 2.6768495605427085e-05,
      "loss": 0.0027,
      "step": 10890
    },
    {
      "epoch": 0.9301134909121939,
      "grad_norm": 0.3993225395679474,
      "learning_rate": 2.6747162727195152e-05,
      "loss": 0.0019,
      "step": 10900
    },
    {
      "epoch": 0.9309668060414711,
      "grad_norm": 0.7681950330734253,
      "learning_rate": 2.6725829848963224e-05,
      "loss": 0.0028,
      "step": 10910
    },
    {
      "epoch": 0.9318201211707483,
      "grad_norm": 1.266944408416748,
      "learning_rate": 2.670449697073129e-05,
      "loss": 0.0029,
      "step": 10920
    },
    {
      "epoch": 0.9326734363000256,
      "grad_norm": 0.8512232899665833,
      "learning_rate": 2.6683164092499363e-05,
      "loss": 0.0024,
      "step": 10930
    },
    {
      "epoch": 0.9335267514293029,
      "grad_norm": 1.193526268005371,
      "learning_rate": 2.666183121426743e-05,
      "loss": 0.0033,
      "step": 10940
    },
    {
      "epoch": 0.9343800665585801,
      "grad_norm": 0.4817515015602112,
      "learning_rate": 2.6640498336035495e-05,
      "loss": 0.0027,
      "step": 10950
    },
    {
      "epoch": 0.9352333816878573,
      "grad_norm": 1.0018484592437744,
      "learning_rate": 2.661916545780357e-05,
      "loss": 0.0027,
      "step": 10960
    },
    {
      "epoch": 0.9360866968171345,
      "grad_norm": 0.40670305490493774,
      "learning_rate": 2.6597832579571634e-05,
      "loss": 0.0038,
      "step": 10970
    },
    {
      "epoch": 0.9369400119464119,
      "grad_norm": 0.7801247239112854,
      "learning_rate": 2.657649970133971e-05,
      "loss": 0.0031,
      "step": 10980
    },
    {
      "epoch": 0.9377933270756891,
      "grad_norm": 0.7961857914924622,
      "learning_rate": 2.6555166823107773e-05,
      "loss": 0.0034,
      "step": 10990
    },
    {
      "epoch": 0.9386466422049663,
      "grad_norm": 0.3939465284347534,
      "learning_rate": 2.6533833944875848e-05,
      "loss": 0.0031,
      "step": 11000
    },
    {
      "epoch": 0.9394999573342435,
      "grad_norm": 0.5842464566230774,
      "learning_rate": 2.6512501066643912e-05,
      "loss": 0.0026,
      "step": 11010
    },
    {
      "epoch": 0.9403532724635207,
      "grad_norm": 0.6208440661430359,
      "learning_rate": 2.649116818841198e-05,
      "loss": 0.0031,
      "step": 11020
    },
    {
      "epoch": 0.9412065875927981,
      "grad_norm": 0.37241315841674805,
      "learning_rate": 2.646983531018005e-05,
      "loss": 0.003,
      "step": 11030
    },
    {
      "epoch": 0.9420599027220753,
      "grad_norm": 0.7168072462081909,
      "learning_rate": 2.644850243194812e-05,
      "loss": 0.0025,
      "step": 11040
    },
    {
      "epoch": 0.9429132178513525,
      "grad_norm": 0.40580251812934875,
      "learning_rate": 2.642716955371619e-05,
      "loss": 0.0024,
      "step": 11050
    },
    {
      "epoch": 0.9437665329806297,
      "grad_norm": 0.5111691355705261,
      "learning_rate": 2.6405836675484258e-05,
      "loss": 0.0034,
      "step": 11060
    },
    {
      "epoch": 0.944619848109907,
      "grad_norm": 0.27965161204338074,
      "learning_rate": 2.6384503797252326e-05,
      "loss": 0.0028,
      "step": 11070
    },
    {
      "epoch": 0.9454731632391842,
      "grad_norm": 0.6017305254936218,
      "learning_rate": 2.6363170919020397e-05,
      "loss": 0.0028,
      "step": 11080
    },
    {
      "epoch": 0.9463264783684615,
      "grad_norm": 0.5265887975692749,
      "learning_rate": 2.6341838040788465e-05,
      "loss": 0.0032,
      "step": 11090
    },
    {
      "epoch": 0.9471797934977387,
      "grad_norm": 0.3857116997241974,
      "learning_rate": 2.6320505162556536e-05,
      "loss": 0.0027,
      "step": 11100
    },
    {
      "epoch": 0.948033108627016,
      "grad_norm": 0.3393842875957489,
      "learning_rate": 2.6299172284324604e-05,
      "loss": 0.0027,
      "step": 11110
    },
    {
      "epoch": 0.9488864237562932,
      "grad_norm": 0.3390791118144989,
      "learning_rate": 2.6277839406092668e-05,
      "loss": 0.0028,
      "step": 11120
    },
    {
      "epoch": 0.9497397388855704,
      "grad_norm": 0.580825924873352,
      "learning_rate": 2.6256506527860743e-05,
      "loss": 0.0031,
      "step": 11130
    },
    {
      "epoch": 0.9505930540148477,
      "grad_norm": 0.3241152763366699,
      "learning_rate": 2.6235173649628807e-05,
      "loss": 0.0027,
      "step": 11140
    },
    {
      "epoch": 0.951446369144125,
      "grad_norm": 0.9193247556686401,
      "learning_rate": 2.6213840771396882e-05,
      "loss": 0.003,
      "step": 11150
    },
    {
      "epoch": 0.9522996842734022,
      "grad_norm": 0.38068637251853943,
      "learning_rate": 2.6192507893164946e-05,
      "loss": 0.0024,
      "step": 11160
    },
    {
      "epoch": 0.9531529994026794,
      "grad_norm": 1.2792459726333618,
      "learning_rate": 2.6171175014933014e-05,
      "loss": 0.0035,
      "step": 11170
    },
    {
      "epoch": 0.9540063145319566,
      "grad_norm": 0.6508353352546692,
      "learning_rate": 2.6149842136701085e-05,
      "loss": 0.0027,
      "step": 11180
    },
    {
      "epoch": 0.9548596296612339,
      "grad_norm": 0.32087182998657227,
      "learning_rate": 2.6128509258469153e-05,
      "loss": 0.0026,
      "step": 11190
    },
    {
      "epoch": 0.9557129447905112,
      "grad_norm": 0.35488349199295044,
      "learning_rate": 2.6107176380237224e-05,
      "loss": 0.0022,
      "step": 11200
    },
    {
      "epoch": 0.9565662599197884,
      "grad_norm": 0.47208768129348755,
      "learning_rate": 2.6085843502005292e-05,
      "loss": 0.0025,
      "step": 11210
    },
    {
      "epoch": 0.9574195750490656,
      "grad_norm": 0.5571088194847107,
      "learning_rate": 2.606451062377336e-05,
      "loss": 0.0028,
      "step": 11220
    },
    {
      "epoch": 0.9582728901783428,
      "grad_norm": 0.300006240606308,
      "learning_rate": 2.604317774554143e-05,
      "loss": 0.0027,
      "step": 11230
    },
    {
      "epoch": 0.95912620530762,
      "grad_norm": 0.43929991126060486,
      "learning_rate": 2.60218448673095e-05,
      "loss": 0.0028,
      "step": 11240
    },
    {
      "epoch": 0.9599795204368974,
      "grad_norm": 0.3910160958766937,
      "learning_rate": 2.600051198907757e-05,
      "loss": 0.003,
      "step": 11250
    },
    {
      "epoch": 0.9608328355661746,
      "grad_norm": 0.39123353362083435,
      "learning_rate": 2.5979179110845635e-05,
      "loss": 0.0029,
      "step": 11260
    },
    {
      "epoch": 0.9616861506954518,
      "grad_norm": 0.48552602529525757,
      "learning_rate": 2.5957846232613702e-05,
      "loss": 0.0031,
      "step": 11270
    },
    {
      "epoch": 0.962539465824729,
      "grad_norm": 1.592219352722168,
      "learning_rate": 2.5936513354381774e-05,
      "loss": 0.0029,
      "step": 11280
    },
    {
      "epoch": 0.9633927809540063,
      "grad_norm": 0.7494630813598633,
      "learning_rate": 2.591518047614984e-05,
      "loss": 0.0027,
      "step": 11290
    },
    {
      "epoch": 0.9642460960832836,
      "grad_norm": 1.0038498640060425,
      "learning_rate": 2.5893847597917913e-05,
      "loss": 0.0027,
      "step": 11300
    },
    {
      "epoch": 0.9650994112125608,
      "grad_norm": 0.27288568019866943,
      "learning_rate": 2.587251471968598e-05,
      "loss": 0.0024,
      "step": 11310
    },
    {
      "epoch": 0.965952726341838,
      "grad_norm": 0.8648324012756348,
      "learning_rate": 2.585118184145405e-05,
      "loss": 0.0031,
      "step": 11320
    },
    {
      "epoch": 0.9668060414711153,
      "grad_norm": 0.7595912218093872,
      "learning_rate": 2.582984896322212e-05,
      "loss": 0.0023,
      "step": 11330
    },
    {
      "epoch": 0.9676593566003925,
      "grad_norm": 0.6963320970535278,
      "learning_rate": 2.5808516084990187e-05,
      "loss": 0.0028,
      "step": 11340
    },
    {
      "epoch": 0.9685126717296698,
      "grad_norm": 0.8113873600959778,
      "learning_rate": 2.578718320675826e-05,
      "loss": 0.003,
      "step": 11350
    },
    {
      "epoch": 0.969365986858947,
      "grad_norm": 0.6721290349960327,
      "learning_rate": 2.5765850328526326e-05,
      "loss": 0.0035,
      "step": 11360
    },
    {
      "epoch": 0.9702193019882243,
      "grad_norm": 0.5176684856414795,
      "learning_rate": 2.5744517450294397e-05,
      "loss": 0.0027,
      "step": 11370
    },
    {
      "epoch": 0.9710726171175015,
      "grad_norm": 0.2601560950279236,
      "learning_rate": 2.5723184572062465e-05,
      "loss": 0.0028,
      "step": 11380
    },
    {
      "epoch": 0.9719259322467787,
      "grad_norm": 0.38572365045547485,
      "learning_rate": 2.570185169383053e-05,
      "loss": 0.0028,
      "step": 11390
    },
    {
      "epoch": 0.9727792473760559,
      "grad_norm": 0.5865038633346558,
      "learning_rate": 2.5680518815598604e-05,
      "loss": 0.0034,
      "step": 11400
    },
    {
      "epoch": 0.9736325625053333,
      "grad_norm": 0.6020400524139404,
      "learning_rate": 2.565918593736667e-05,
      "loss": 0.0029,
      "step": 11410
    },
    {
      "epoch": 0.9744858776346105,
      "grad_norm": 0.5292983651161194,
      "learning_rate": 2.5637853059134743e-05,
      "loss": 0.0028,
      "step": 11420
    },
    {
      "epoch": 0.9753391927638877,
      "grad_norm": 0.7790848612785339,
      "learning_rate": 2.5616520180902808e-05,
      "loss": 0.0025,
      "step": 11430
    },
    {
      "epoch": 0.9761925078931649,
      "grad_norm": 0.766072690486908,
      "learning_rate": 2.5595187302670876e-05,
      "loss": 0.0028,
      "step": 11440
    },
    {
      "epoch": 0.9770458230224421,
      "grad_norm": 0.3031196594238281,
      "learning_rate": 2.5573854424438947e-05,
      "loss": 0.003,
      "step": 11450
    },
    {
      "epoch": 0.9778991381517195,
      "grad_norm": 0.590925931930542,
      "learning_rate": 2.5552521546207015e-05,
      "loss": 0.0024,
      "step": 11460
    },
    {
      "epoch": 0.9787524532809967,
      "grad_norm": 0.28953203558921814,
      "learning_rate": 2.5531188667975086e-05,
      "loss": 0.0026,
      "step": 11470
    },
    {
      "epoch": 0.9796057684102739,
      "grad_norm": 0.7074145674705505,
      "learning_rate": 2.5509855789743154e-05,
      "loss": 0.0031,
      "step": 11480
    },
    {
      "epoch": 0.9804590835395511,
      "grad_norm": 0.536264955997467,
      "learning_rate": 2.548852291151122e-05,
      "loss": 0.0028,
      "step": 11490
    },
    {
      "epoch": 0.9813123986688284,
      "grad_norm": 0.3039558529853821,
      "learning_rate": 2.5467190033279293e-05,
      "loss": 0.0027,
      "step": 11500
    },
    {
      "epoch": 0.9821657137981057,
      "grad_norm": 0.41805464029312134,
      "learning_rate": 2.544585715504736e-05,
      "loss": 0.0025,
      "step": 11510
    },
    {
      "epoch": 0.9830190289273829,
      "grad_norm": 0.4867111146450043,
      "learning_rate": 2.542452427681543e-05,
      "loss": 0.0031,
      "step": 11520
    },
    {
      "epoch": 0.9838723440566601,
      "grad_norm": 0.4021455943584442,
      "learning_rate": 2.54031913985835e-05,
      "loss": 0.0031,
      "step": 11530
    },
    {
      "epoch": 0.9847256591859374,
      "grad_norm": 0.2747460603713989,
      "learning_rate": 2.5381858520351564e-05,
      "loss": 0.0028,
      "step": 11540
    },
    {
      "epoch": 0.9855789743152146,
      "grad_norm": 0.3766773045063019,
      "learning_rate": 2.536052564211964e-05,
      "loss": 0.0029,
      "step": 11550
    },
    {
      "epoch": 0.9864322894444919,
      "grad_norm": 0.2741992473602295,
      "learning_rate": 2.5339192763887703e-05,
      "loss": 0.0031,
      "step": 11560
    },
    {
      "epoch": 0.9872856045737691,
      "grad_norm": 0.4387126863002777,
      "learning_rate": 2.5317859885655778e-05,
      "loss": 0.0026,
      "step": 11570
    },
    {
      "epoch": 0.9881389197030463,
      "grad_norm": 0.4568924307823181,
      "learning_rate": 2.5296527007423842e-05,
      "loss": 0.0028,
      "step": 11580
    },
    {
      "epoch": 0.9889922348323236,
      "grad_norm": 0.6871903538703918,
      "learning_rate": 2.527519412919191e-05,
      "loss": 0.0033,
      "step": 11590
    },
    {
      "epoch": 0.9898455499616008,
      "grad_norm": 0.39005351066589355,
      "learning_rate": 2.525386125095998e-05,
      "loss": 0.0025,
      "step": 11600
    },
    {
      "epoch": 0.990698865090878,
      "grad_norm": 0.6681911945343018,
      "learning_rate": 2.523252837272805e-05,
      "loss": 0.0023,
      "step": 11610
    },
    {
      "epoch": 0.9915521802201553,
      "grad_norm": 0.3040989935398102,
      "learning_rate": 2.521119549449612e-05,
      "loss": 0.0022,
      "step": 11620
    },
    {
      "epoch": 0.9924054953494326,
      "grad_norm": 0.33444875478744507,
      "learning_rate": 2.5189862616264188e-05,
      "loss": 0.0031,
      "step": 11630
    },
    {
      "epoch": 0.9932588104787098,
      "grad_norm": 1.0620547533035278,
      "learning_rate": 2.5168529738032252e-05,
      "loss": 0.0034,
      "step": 11640
    },
    {
      "epoch": 0.994112125607987,
      "grad_norm": 0.8103609085083008,
      "learning_rate": 2.5147196859800327e-05,
      "loss": 0.003,
      "step": 11650
    },
    {
      "epoch": 0.9949654407372642,
      "grad_norm": 0.5020731091499329,
      "learning_rate": 2.512586398156839e-05,
      "loss": 0.0028,
      "step": 11660
    },
    {
      "epoch": 0.9958187558665416,
      "grad_norm": 0.33715593814849854,
      "learning_rate": 2.5104531103336466e-05,
      "loss": 0.0026,
      "step": 11670
    },
    {
      "epoch": 0.9966720709958188,
      "grad_norm": 0.3685566782951355,
      "learning_rate": 2.508319822510453e-05,
      "loss": 0.0024,
      "step": 11680
    },
    {
      "epoch": 0.997525386125096,
      "grad_norm": 0.5717846155166626,
      "learning_rate": 2.5061865346872605e-05,
      "loss": 0.003,
      "step": 11690
    },
    {
      "epoch": 0.9983787012543732,
      "grad_norm": 0.7690123915672302,
      "learning_rate": 2.504053246864067e-05,
      "loss": 0.0032,
      "step": 11700
    },
    {
      "epoch": 0.9992320163836504,
      "grad_norm": 0.7324155569076538,
      "learning_rate": 2.5019199590408737e-05,
      "loss": 0.0031,
      "step": 11710
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.003088662400841713,
      "eval_runtime": 95.8395,
      "eval_samples_per_second": 1565.116,
      "eval_steps_per_second": 24.458,
      "step": 11719
    },
    {
      "epoch": 1.0000853315129277,
      "grad_norm": 0.6017992496490479,
      "learning_rate": 2.499786671217681e-05,
      "loss": 0.003,
      "step": 11720
    },
    {
      "epoch": 1.000938646642205,
      "grad_norm": 0.8090529441833496,
      "learning_rate": 2.4976533833944876e-05,
      "loss": 0.0029,
      "step": 11730
    },
    {
      "epoch": 1.001791961771482,
      "grad_norm": 0.4184117317199707,
      "learning_rate": 2.4955200955712947e-05,
      "loss": 0.0028,
      "step": 11740
    },
    {
      "epoch": 1.0026452769007594,
      "grad_norm": 0.4053661525249481,
      "learning_rate": 2.4933868077481015e-05,
      "loss": 0.0031,
      "step": 11750
    },
    {
      "epoch": 1.0034985920300368,
      "grad_norm": 0.8452239632606506,
      "learning_rate": 2.4912535199249083e-05,
      "loss": 0.0028,
      "step": 11760
    },
    {
      "epoch": 1.0043519071593139,
      "grad_norm": 0.5299766659736633,
      "learning_rate": 2.4891202321017154e-05,
      "loss": 0.0028,
      "step": 11770
    },
    {
      "epoch": 1.0052052222885912,
      "grad_norm": 0.7916957139968872,
      "learning_rate": 2.4869869442785222e-05,
      "loss": 0.0029,
      "step": 11780
    },
    {
      "epoch": 1.0060585374178683,
      "grad_norm": 0.315470814704895,
      "learning_rate": 2.484853656455329e-05,
      "loss": 0.0026,
      "step": 11790
    },
    {
      "epoch": 1.0069118525471457,
      "grad_norm": 0.5856060981750488,
      "learning_rate": 2.482720368632136e-05,
      "loss": 0.0028,
      "step": 11800
    },
    {
      "epoch": 1.007765167676423,
      "grad_norm": 1.0076324939727783,
      "learning_rate": 2.480587080808943e-05,
      "loss": 0.0029,
      "step": 11810
    },
    {
      "epoch": 1.0086184828057,
      "grad_norm": 0.47856244444847107,
      "learning_rate": 2.47845379298575e-05,
      "loss": 0.0027,
      "step": 11820
    },
    {
      "epoch": 1.0094717979349774,
      "grad_norm": 0.716583788394928,
      "learning_rate": 2.4763205051625564e-05,
      "loss": 0.0035,
      "step": 11830
    },
    {
      "epoch": 1.0103251130642545,
      "grad_norm": 0.5394740700721741,
      "learning_rate": 2.4741872173393636e-05,
      "loss": 0.0024,
      "step": 11840
    },
    {
      "epoch": 1.0111784281935319,
      "grad_norm": 0.420590341091156,
      "learning_rate": 2.4720539295161703e-05,
      "loss": 0.0033,
      "step": 11850
    },
    {
      "epoch": 1.0120317433228092,
      "grad_norm": 0.7466127872467041,
      "learning_rate": 2.4699206416929775e-05,
      "loss": 0.0024,
      "step": 11860
    },
    {
      "epoch": 1.0128850584520863,
      "grad_norm": 0.7129500508308411,
      "learning_rate": 2.4677873538697843e-05,
      "loss": 0.0025,
      "step": 11870
    },
    {
      "epoch": 1.0137383735813636,
      "grad_norm": 0.28638213872909546,
      "learning_rate": 2.465654066046591e-05,
      "loss": 0.0028,
      "step": 11880
    },
    {
      "epoch": 1.0145916887106408,
      "grad_norm": 0.8513245582580566,
      "learning_rate": 2.4635207782233978e-05,
      "loss": 0.0028,
      "step": 11890
    },
    {
      "epoch": 1.015445003839918,
      "grad_norm": 0.415047287940979,
      "learning_rate": 2.461387490400205e-05,
      "loss": 0.0025,
      "step": 11900
    },
    {
      "epoch": 1.0162983189691954,
      "grad_norm": 0.6667255163192749,
      "learning_rate": 2.4592542025770117e-05,
      "loss": 0.0025,
      "step": 11910
    },
    {
      "epoch": 1.0171516340984725,
      "grad_norm": 0.42859455943107605,
      "learning_rate": 2.457120914753819e-05,
      "loss": 0.0025,
      "step": 11920
    },
    {
      "epoch": 1.0180049492277499,
      "grad_norm": 0.5418452620506287,
      "learning_rate": 2.4549876269306256e-05,
      "loss": 0.0028,
      "step": 11930
    },
    {
      "epoch": 1.018858264357027,
      "grad_norm": 0.314047247171402,
      "learning_rate": 2.4528543391074324e-05,
      "loss": 0.0029,
      "step": 11940
    },
    {
      "epoch": 1.0197115794863043,
      "grad_norm": 0.5989269018173218,
      "learning_rate": 2.4507210512842392e-05,
      "loss": 0.0031,
      "step": 11950
    },
    {
      "epoch": 1.0205648946155816,
      "grad_norm": 0.29189029335975647,
      "learning_rate": 2.4485877634610463e-05,
      "loss": 0.0026,
      "step": 11960
    },
    {
      "epoch": 1.0214182097448588,
      "grad_norm": 0.49791398644447327,
      "learning_rate": 2.446454475637853e-05,
      "loss": 0.0027,
      "step": 11970
    },
    {
      "epoch": 1.022271524874136,
      "grad_norm": 0.47861021757125854,
      "learning_rate": 2.4443211878146602e-05,
      "loss": 0.0025,
      "step": 11980
    },
    {
      "epoch": 1.0231248400034132,
      "grad_norm": 1.1835092306137085,
      "learning_rate": 2.442187899991467e-05,
      "loss": 0.0023,
      "step": 11990
    },
    {
      "epoch": 1.0239781551326905,
      "grad_norm": 0.6942030787467957,
      "learning_rate": 2.4400546121682738e-05,
      "loss": 0.0034,
      "step": 12000
    },
    {
      "epoch": 1.0248314702619676,
      "grad_norm": 0.3105308711528778,
      "learning_rate": 2.437921324345081e-05,
      "loss": 0.0026,
      "step": 12010
    },
    {
      "epoch": 1.025684785391245,
      "grad_norm": 0.5308855772018433,
      "learning_rate": 2.4357880365218877e-05,
      "loss": 0.0027,
      "step": 12020
    },
    {
      "epoch": 1.0265381005205223,
      "grad_norm": 0.40572434663772583,
      "learning_rate": 2.4336547486986948e-05,
      "loss": 0.0026,
      "step": 12030
    },
    {
      "epoch": 1.0273914156497994,
      "grad_norm": 0.9411085247993469,
      "learning_rate": 2.4315214608755012e-05,
      "loss": 0.0027,
      "step": 12040
    },
    {
      "epoch": 1.0282447307790767,
      "grad_norm": 0.9192519783973694,
      "learning_rate": 2.4293881730523084e-05,
      "loss": 0.003,
      "step": 12050
    },
    {
      "epoch": 1.0290980459083539,
      "grad_norm": 0.7198178768157959,
      "learning_rate": 2.427254885229115e-05,
      "loss": 0.0024,
      "step": 12060
    },
    {
      "epoch": 1.0299513610376312,
      "grad_norm": 0.43654993176460266,
      "learning_rate": 2.4251215974059223e-05,
      "loss": 0.0026,
      "step": 12070
    },
    {
      "epoch": 1.0308046761669085,
      "grad_norm": 0.38724780082702637,
      "learning_rate": 2.422988309582729e-05,
      "loss": 0.0035,
      "step": 12080
    },
    {
      "epoch": 1.0316579912961856,
      "grad_norm": 0.4610404968261719,
      "learning_rate": 2.420855021759536e-05,
      "loss": 0.0027,
      "step": 12090
    },
    {
      "epoch": 1.032511306425463,
      "grad_norm": 0.6208215355873108,
      "learning_rate": 2.4187217339363426e-05,
      "loss": 0.0028,
      "step": 12100
    },
    {
      "epoch": 1.03336462155474,
      "grad_norm": 0.45061782002449036,
      "learning_rate": 2.4165884461131497e-05,
      "loss": 0.0024,
      "step": 12110
    },
    {
      "epoch": 1.0342179366840174,
      "grad_norm": 0.4604783058166504,
      "learning_rate": 2.4144551582899565e-05,
      "loss": 0.0028,
      "step": 12120
    },
    {
      "epoch": 1.0350712518132947,
      "grad_norm": 0.2721257209777832,
      "learning_rate": 2.4123218704667636e-05,
      "loss": 0.0026,
      "step": 12130
    },
    {
      "epoch": 1.0359245669425718,
      "grad_norm": 0.3928365409374237,
      "learning_rate": 2.4101885826435704e-05,
      "loss": 0.003,
      "step": 12140
    },
    {
      "epoch": 1.0367778820718492,
      "grad_norm": 0.4726726710796356,
      "learning_rate": 2.4080552948203772e-05,
      "loss": 0.0033,
      "step": 12150
    },
    {
      "epoch": 1.0376311972011263,
      "grad_norm": 0.31023353338241577,
      "learning_rate": 2.405922006997184e-05,
      "loss": 0.0029,
      "step": 12160
    },
    {
      "epoch": 1.0384845123304036,
      "grad_norm": 0.33383336663246155,
      "learning_rate": 2.403788719173991e-05,
      "loss": 0.0036,
      "step": 12170
    },
    {
      "epoch": 1.039337827459681,
      "grad_norm": 0.4982950687408447,
      "learning_rate": 2.401655431350798e-05,
      "loss": 0.0025,
      "step": 12180
    },
    {
      "epoch": 1.040191142588958,
      "grad_norm": 1.2542061805725098,
      "learning_rate": 2.399522143527605e-05,
      "loss": 0.0034,
      "step": 12190
    },
    {
      "epoch": 1.0410444577182354,
      "grad_norm": 0.9718286395072937,
      "learning_rate": 2.3973888557044118e-05,
      "loss": 0.0025,
      "step": 12200
    },
    {
      "epoch": 1.0418977728475125,
      "grad_norm": 0.5934963226318359,
      "learning_rate": 2.3952555678812186e-05,
      "loss": 0.0033,
      "step": 12210
    },
    {
      "epoch": 1.0427510879767898,
      "grad_norm": 0.31267428398132324,
      "learning_rate": 2.3931222800580257e-05,
      "loss": 0.0034,
      "step": 12220
    },
    {
      "epoch": 1.0436044031060672,
      "grad_norm": 1.0316801071166992,
      "learning_rate": 2.3909889922348325e-05,
      "loss": 0.0024,
      "step": 12230
    },
    {
      "epoch": 1.0444577182353443,
      "grad_norm": 0.36903414130210876,
      "learning_rate": 2.3888557044116396e-05,
      "loss": 0.0028,
      "step": 12240
    },
    {
      "epoch": 1.0453110333646216,
      "grad_norm": 0.36000365018844604,
      "learning_rate": 2.3867224165884464e-05,
      "loss": 0.0026,
      "step": 12250
    },
    {
      "epoch": 1.0461643484938987,
      "grad_norm": 0.4552434980869293,
      "learning_rate": 2.384589128765253e-05,
      "loss": 0.0032,
      "step": 12260
    },
    {
      "epoch": 1.047017663623176,
      "grad_norm": 0.5053750276565552,
      "learning_rate": 2.38245584094206e-05,
      "loss": 0.0024,
      "step": 12270
    },
    {
      "epoch": 1.0478709787524534,
      "grad_norm": 0.6466477513313293,
      "learning_rate": 2.380322553118867e-05,
      "loss": 0.0028,
      "step": 12280
    },
    {
      "epoch": 1.0487242938817305,
      "grad_norm": 0.33663210272789,
      "learning_rate": 2.3781892652956738e-05,
      "loss": 0.0039,
      "step": 12290
    },
    {
      "epoch": 1.0495776090110078,
      "grad_norm": 0.6963198781013489,
      "learning_rate": 2.376055977472481e-05,
      "loss": 0.0026,
      "step": 12300
    },
    {
      "epoch": 1.050430924140285,
      "grad_norm": 0.6625941395759583,
      "learning_rate": 2.3739226896492874e-05,
      "loss": 0.003,
      "step": 12310
    },
    {
      "epoch": 1.0512842392695623,
      "grad_norm": 1.1566519737243652,
      "learning_rate": 2.3717894018260945e-05,
      "loss": 0.0022,
      "step": 12320
    },
    {
      "epoch": 1.0521375543988394,
      "grad_norm": 0.617957353591919,
      "learning_rate": 2.3696561140029013e-05,
      "loss": 0.0033,
      "step": 12330
    },
    {
      "epoch": 1.0529908695281167,
      "grad_norm": 0.38071784377098083,
      "learning_rate": 2.3675228261797084e-05,
      "loss": 0.0024,
      "step": 12340
    },
    {
      "epoch": 1.053844184657394,
      "grad_norm": 0.576279878616333,
      "learning_rate": 2.3653895383565152e-05,
      "loss": 0.003,
      "step": 12350
    },
    {
      "epoch": 1.0546974997866712,
      "grad_norm": 1.1876477003097534,
      "learning_rate": 2.363256250533322e-05,
      "loss": 0.0024,
      "step": 12360
    },
    {
      "epoch": 1.0555508149159485,
      "grad_norm": 0.5662810802459717,
      "learning_rate": 2.3611229627101288e-05,
      "loss": 0.003,
      "step": 12370
    },
    {
      "epoch": 1.0564041300452256,
      "grad_norm": 0.6768263578414917,
      "learning_rate": 2.358989674886936e-05,
      "loss": 0.0034,
      "step": 12380
    },
    {
      "epoch": 1.057257445174503,
      "grad_norm": 0.5192949175834656,
      "learning_rate": 2.3568563870637427e-05,
      "loss": 0.0025,
      "step": 12390
    },
    {
      "epoch": 1.0581107603037803,
      "grad_norm": 0.5742174386978149,
      "learning_rate": 2.3547230992405498e-05,
      "loss": 0.0023,
      "step": 12400
    },
    {
      "epoch": 1.0589640754330574,
      "grad_norm": 0.58220374584198,
      "learning_rate": 2.3525898114173566e-05,
      "loss": 0.0026,
      "step": 12410
    },
    {
      "epoch": 1.0598173905623347,
      "grad_norm": 0.33365312218666077,
      "learning_rate": 2.3504565235941633e-05,
      "loss": 0.003,
      "step": 12420
    },
    {
      "epoch": 1.0606707056916118,
      "grad_norm": 0.8568575382232666,
      "learning_rate": 2.3483232357709705e-05,
      "loss": 0.0028,
      "step": 12430
    },
    {
      "epoch": 1.0615240208208891,
      "grad_norm": 0.36938348412513733,
      "learning_rate": 2.3461899479477772e-05,
      "loss": 0.0028,
      "step": 12440
    },
    {
      "epoch": 1.0623773359501665,
      "grad_norm": 0.5409655570983887,
      "learning_rate": 2.344056660124584e-05,
      "loss": 0.0028,
      "step": 12450
    },
    {
      "epoch": 1.0632306510794436,
      "grad_norm": 0.45758363604545593,
      "learning_rate": 2.341923372301391e-05,
      "loss": 0.003,
      "step": 12460
    },
    {
      "epoch": 1.064083966208721,
      "grad_norm": 0.39484357833862305,
      "learning_rate": 2.339790084478198e-05,
      "loss": 0.0034,
      "step": 12470
    },
    {
      "epoch": 1.064937281337998,
      "grad_norm": 0.6230624914169312,
      "learning_rate": 2.3376567966550047e-05,
      "loss": 0.0028,
      "step": 12480
    },
    {
      "epoch": 1.0657905964672754,
      "grad_norm": 0.6949419379234314,
      "learning_rate": 2.3355235088318118e-05,
      "loss": 0.003,
      "step": 12490
    },
    {
      "epoch": 1.0666439115965527,
      "grad_norm": 0.4283760190010071,
      "learning_rate": 2.3333902210086186e-05,
      "loss": 0.0024,
      "step": 12500
    },
    {
      "epoch": 1.0674972267258298,
      "grad_norm": 0.795662522315979,
      "learning_rate": 2.3312569331854257e-05,
      "loss": 0.0027,
      "step": 12510
    },
    {
      "epoch": 1.0683505418551071,
      "grad_norm": 0.4357847273349762,
      "learning_rate": 2.3291236453622322e-05,
      "loss": 0.0034,
      "step": 12520
    },
    {
      "epoch": 1.0692038569843842,
      "grad_norm": 0.4683631956577301,
      "learning_rate": 2.3269903575390393e-05,
      "loss": 0.0025,
      "step": 12530
    },
    {
      "epoch": 1.0700571721136616,
      "grad_norm": 0.4091684818267822,
      "learning_rate": 2.324857069715846e-05,
      "loss": 0.0029,
      "step": 12540
    },
    {
      "epoch": 1.070910487242939,
      "grad_norm": 0.45632562041282654,
      "learning_rate": 2.3227237818926532e-05,
      "loss": 0.0021,
      "step": 12550
    },
    {
      "epoch": 1.071763802372216,
      "grad_norm": 0.28675681352615356,
      "learning_rate": 2.32059049406946e-05,
      "loss": 0.0027,
      "step": 12560
    },
    {
      "epoch": 1.0726171175014934,
      "grad_norm": 0.3428233861923218,
      "learning_rate": 2.3184572062462668e-05,
      "loss": 0.0022,
      "step": 12570
    },
    {
      "epoch": 1.0734704326307705,
      "grad_norm": 0.3827439546585083,
      "learning_rate": 2.3163239184230735e-05,
      "loss": 0.0026,
      "step": 12580
    },
    {
      "epoch": 1.0743237477600478,
      "grad_norm": 0.33369889855384827,
      "learning_rate": 2.3141906305998807e-05,
      "loss": 0.0035,
      "step": 12590
    },
    {
      "epoch": 1.0751770628893251,
      "grad_norm": 0.4548874795436859,
      "learning_rate": 2.3120573427766874e-05,
      "loss": 0.0038,
      "step": 12600
    },
    {
      "epoch": 1.0760303780186022,
      "grad_norm": 0.5942143797874451,
      "learning_rate": 2.3099240549534946e-05,
      "loss": 0.0026,
      "step": 12610
    },
    {
      "epoch": 1.0768836931478796,
      "grad_norm": 0.525799572467804,
      "learning_rate": 2.3077907671303013e-05,
      "loss": 0.003,
      "step": 12620
    },
    {
      "epoch": 1.0777370082771567,
      "grad_norm": 0.4698108434677124,
      "learning_rate": 2.305657479307108e-05,
      "loss": 0.0027,
      "step": 12630
    },
    {
      "epoch": 1.078590323406434,
      "grad_norm": 0.3900703191757202,
      "learning_rate": 2.303524191483915e-05,
      "loss": 0.0024,
      "step": 12640
    },
    {
      "epoch": 1.0794436385357113,
      "grad_norm": 0.5677585005760193,
      "learning_rate": 2.301390903660722e-05,
      "loss": 0.0028,
      "step": 12650
    },
    {
      "epoch": 1.0802969536649885,
      "grad_norm": 0.33531653881073,
      "learning_rate": 2.2992576158375288e-05,
      "loss": 0.0022,
      "step": 12660
    },
    {
      "epoch": 1.0811502687942658,
      "grad_norm": 1.1283155679702759,
      "learning_rate": 2.297124328014336e-05,
      "loss": 0.0024,
      "step": 12670
    },
    {
      "epoch": 1.082003583923543,
      "grad_norm": 0.9410445690155029,
      "learning_rate": 2.2949910401911427e-05,
      "loss": 0.0028,
      "step": 12680
    },
    {
      "epoch": 1.0828568990528202,
      "grad_norm": 0.6244096755981445,
      "learning_rate": 2.2928577523679495e-05,
      "loss": 0.0034,
      "step": 12690
    },
    {
      "epoch": 1.0837102141820973,
      "grad_norm": 0.6609607338905334,
      "learning_rate": 2.2907244645447566e-05,
      "loss": 0.0029,
      "step": 12700
    },
    {
      "epoch": 1.0845635293113747,
      "grad_norm": 0.4383033215999603,
      "learning_rate": 2.2885911767215634e-05,
      "loss": 0.0034,
      "step": 12710
    },
    {
      "epoch": 1.085416844440652,
      "grad_norm": 1.3809051513671875,
      "learning_rate": 2.2864578888983705e-05,
      "loss": 0.0029,
      "step": 12720
    },
    {
      "epoch": 1.0862701595699291,
      "grad_norm": 0.26194989681243896,
      "learning_rate": 2.284324601075177e-05,
      "loss": 0.0025,
      "step": 12730
    },
    {
      "epoch": 1.0871234746992064,
      "grad_norm": 0.6994422078132629,
      "learning_rate": 2.282191313251984e-05,
      "loss": 0.0029,
      "step": 12740
    },
    {
      "epoch": 1.0879767898284836,
      "grad_norm": 0.42299482226371765,
      "learning_rate": 2.280058025428791e-05,
      "loss": 0.0022,
      "step": 12750
    },
    {
      "epoch": 1.088830104957761,
      "grad_norm": 0.3826771378517151,
      "learning_rate": 2.277924737605598e-05,
      "loss": 0.0038,
      "step": 12760
    },
    {
      "epoch": 1.0896834200870382,
      "grad_norm": 0.6055174469947815,
      "learning_rate": 2.2757914497824048e-05,
      "loss": 0.0029,
      "step": 12770
    },
    {
      "epoch": 1.0905367352163153,
      "grad_norm": 0.741277277469635,
      "learning_rate": 2.273658161959212e-05,
      "loss": 0.0029,
      "step": 12780
    },
    {
      "epoch": 1.0913900503455927,
      "grad_norm": 0.4845224618911743,
      "learning_rate": 2.2715248741360183e-05,
      "loss": 0.0032,
      "step": 12790
    },
    {
      "epoch": 1.0922433654748698,
      "grad_norm": 0.9688615798950195,
      "learning_rate": 2.2693915863128254e-05,
      "loss": 0.0028,
      "step": 12800
    },
    {
      "epoch": 1.093096680604147,
      "grad_norm": 1.1261225938796997,
      "learning_rate": 2.2672582984896322e-05,
      "loss": 0.0037,
      "step": 12810
    },
    {
      "epoch": 1.0939499957334244,
      "grad_norm": 0.6602604985237122,
      "learning_rate": 2.2651250106664394e-05,
      "loss": 0.0024,
      "step": 12820
    },
    {
      "epoch": 1.0948033108627016,
      "grad_norm": 0.5005706548690796,
      "learning_rate": 2.262991722843246e-05,
      "loss": 0.0025,
      "step": 12830
    },
    {
      "epoch": 1.0956566259919789,
      "grad_norm": 0.6538063883781433,
      "learning_rate": 2.260858435020053e-05,
      "loss": 0.0024,
      "step": 12840
    },
    {
      "epoch": 1.096509941121256,
      "grad_norm": 0.35357746481895447,
      "learning_rate": 2.2587251471968597e-05,
      "loss": 0.0032,
      "step": 12850
    },
    {
      "epoch": 1.0973632562505333,
      "grad_norm": 0.6188015341758728,
      "learning_rate": 2.2565918593736668e-05,
      "loss": 0.0027,
      "step": 12860
    },
    {
      "epoch": 1.0982165713798107,
      "grad_norm": 0.4982094466686249,
      "learning_rate": 2.2544585715504736e-05,
      "loss": 0.0032,
      "step": 12870
    },
    {
      "epoch": 1.0990698865090878,
      "grad_norm": 0.2986776828765869,
      "learning_rate": 2.2523252837272807e-05,
      "loss": 0.0028,
      "step": 12880
    },
    {
      "epoch": 1.099923201638365,
      "grad_norm": 0.7075923085212708,
      "learning_rate": 2.2501919959040875e-05,
      "loss": 0.0032,
      "step": 12890
    },
    {
      "epoch": 1.1007765167676422,
      "grad_norm": 0.39006689190864563,
      "learning_rate": 2.2480587080808943e-05,
      "loss": 0.0023,
      "step": 12900
    },
    {
      "epoch": 1.1016298318969195,
      "grad_norm": 0.2844923436641693,
      "learning_rate": 2.2459254202577014e-05,
      "loss": 0.0028,
      "step": 12910
    },
    {
      "epoch": 1.1024831470261969,
      "grad_norm": 0.3293129503726959,
      "learning_rate": 2.2437921324345082e-05,
      "loss": 0.0028,
      "step": 12920
    },
    {
      "epoch": 1.103336462155474,
      "grad_norm": 0.4686945378780365,
      "learning_rate": 2.2416588446113153e-05,
      "loss": 0.0034,
      "step": 12930
    },
    {
      "epoch": 1.1041897772847513,
      "grad_norm": 0.3008614778518677,
      "learning_rate": 2.239525556788122e-05,
      "loss": 0.0034,
      "step": 12940
    },
    {
      "epoch": 1.1050430924140284,
      "grad_norm": 0.4845174252986908,
      "learning_rate": 2.237392268964929e-05,
      "loss": 0.003,
      "step": 12950
    },
    {
      "epoch": 1.1058964075433058,
      "grad_norm": 0.3274693191051483,
      "learning_rate": 2.2352589811417357e-05,
      "loss": 0.0024,
      "step": 12960
    },
    {
      "epoch": 1.1067497226725829,
      "grad_norm": 0.9137650728225708,
      "learning_rate": 2.2331256933185428e-05,
      "loss": 0.0029,
      "step": 12970
    },
    {
      "epoch": 1.1076030378018602,
      "grad_norm": 0.7730830311775208,
      "learning_rate": 2.2309924054953496e-05,
      "loss": 0.0032,
      "step": 12980
    },
    {
      "epoch": 1.1084563529311375,
      "grad_norm": 0.4668605625629425,
      "learning_rate": 2.2288591176721567e-05,
      "loss": 0.0034,
      "step": 12990
    },
    {
      "epoch": 1.1093096680604146,
      "grad_norm": 0.2675311863422394,
      "learning_rate": 2.226725829848963e-05,
      "loss": 0.0026,
      "step": 13000
    },
    {
      "epoch": 1.110162983189692,
      "grad_norm": 0.2837476432323456,
      "learning_rate": 2.2245925420257702e-05,
      "loss": 0.0023,
      "step": 13010
    },
    {
      "epoch": 1.1110162983189693,
      "grad_norm": 0.9128953218460083,
      "learning_rate": 2.222459254202577e-05,
      "loss": 0.0026,
      "step": 13020
    },
    {
      "epoch": 1.1118696134482464,
      "grad_norm": 1.089582085609436,
      "learning_rate": 2.220325966379384e-05,
      "loss": 0.0029,
      "step": 13030
    },
    {
      "epoch": 1.1127229285775238,
      "grad_norm": 0.48919689655303955,
      "learning_rate": 2.218192678556191e-05,
      "loss": 0.0029,
      "step": 13040
    },
    {
      "epoch": 1.1135762437068009,
      "grad_norm": 0.7593263983726501,
      "learning_rate": 2.2160593907329977e-05,
      "loss": 0.0026,
      "step": 13050
    },
    {
      "epoch": 1.1144295588360782,
      "grad_norm": 0.3840383291244507,
      "learning_rate": 2.2139261029098045e-05,
      "loss": 0.0027,
      "step": 13060
    },
    {
      "epoch": 1.1152828739653553,
      "grad_norm": 0.4456638693809509,
      "learning_rate": 2.2117928150866116e-05,
      "loss": 0.0023,
      "step": 13070
    },
    {
      "epoch": 1.1161361890946326,
      "grad_norm": 0.8459123969078064,
      "learning_rate": 2.2096595272634184e-05,
      "loss": 0.0026,
      "step": 13080
    },
    {
      "epoch": 1.11698950422391,
      "grad_norm": 0.4379960000514984,
      "learning_rate": 2.2075262394402255e-05,
      "loss": 0.0025,
      "step": 13090
    },
    {
      "epoch": 1.117842819353187,
      "grad_norm": 0.3924594521522522,
      "learning_rate": 2.2053929516170323e-05,
      "loss": 0.0029,
      "step": 13100
    },
    {
      "epoch": 1.1186961344824644,
      "grad_norm": 0.4407805800437927,
      "learning_rate": 2.203259663793839e-05,
      "loss": 0.0029,
      "step": 13110
    },
    {
      "epoch": 1.1195494496117415,
      "grad_norm": 0.7042405009269714,
      "learning_rate": 2.2011263759706462e-05,
      "loss": 0.0027,
      "step": 13120
    },
    {
      "epoch": 1.1204027647410189,
      "grad_norm": 0.6817304491996765,
      "learning_rate": 2.198993088147453e-05,
      "loss": 0.0025,
      "step": 13130
    },
    {
      "epoch": 1.1212560798702962,
      "grad_norm": 0.6462078094482422,
      "learning_rate": 2.1968598003242598e-05,
      "loss": 0.003,
      "step": 13140
    },
    {
      "epoch": 1.1221093949995733,
      "grad_norm": 0.30211779475212097,
      "learning_rate": 2.194726512501067e-05,
      "loss": 0.0027,
      "step": 13150
    },
    {
      "epoch": 1.1229627101288506,
      "grad_norm": 0.6400744915008545,
      "learning_rate": 2.1925932246778737e-05,
      "loss": 0.0028,
      "step": 13160
    },
    {
      "epoch": 1.1238160252581277,
      "grad_norm": 0.3854246437549591,
      "learning_rate": 2.1904599368546804e-05,
      "loss": 0.0026,
      "step": 13170
    },
    {
      "epoch": 1.124669340387405,
      "grad_norm": 0.43562155961990356,
      "learning_rate": 2.1883266490314876e-05,
      "loss": 0.0023,
      "step": 13180
    },
    {
      "epoch": 1.1255226555166824,
      "grad_norm": 0.39631640911102295,
      "learning_rate": 2.1861933612082943e-05,
      "loss": 0.0034,
      "step": 13190
    },
    {
      "epoch": 1.1263759706459595,
      "grad_norm": 0.21278640627861023,
      "learning_rate": 2.1840600733851015e-05,
      "loss": 0.0025,
      "step": 13200
    },
    {
      "epoch": 1.1272292857752368,
      "grad_norm": 0.4229649007320404,
      "learning_rate": 2.181926785561908e-05,
      "loss": 0.0026,
      "step": 13210
    },
    {
      "epoch": 1.128082600904514,
      "grad_norm": 0.3506737947463989,
      "learning_rate": 2.179793497738715e-05,
      "loss": 0.0028,
      "step": 13220
    },
    {
      "epoch": 1.1289359160337913,
      "grad_norm": 0.4525747001171112,
      "learning_rate": 2.1776602099155218e-05,
      "loss": 0.0037,
      "step": 13230
    },
    {
      "epoch": 1.1297892311630684,
      "grad_norm": 0.26358452439308167,
      "learning_rate": 2.175526922092329e-05,
      "loss": 0.0028,
      "step": 13240
    },
    {
      "epoch": 1.1306425462923457,
      "grad_norm": 0.8335546851158142,
      "learning_rate": 2.1733936342691357e-05,
      "loss": 0.0023,
      "step": 13250
    },
    {
      "epoch": 1.131495861421623,
      "grad_norm": 0.7677715420722961,
      "learning_rate": 2.1712603464459428e-05,
      "loss": 0.0024,
      "step": 13260
    },
    {
      "epoch": 1.1323491765509002,
      "grad_norm": 0.4638279378414154,
      "learning_rate": 2.1691270586227493e-05,
      "loss": 0.0028,
      "step": 13270
    },
    {
      "epoch": 1.1332024916801775,
      "grad_norm": 0.601256787776947,
      "learning_rate": 2.1669937707995564e-05,
      "loss": 0.0024,
      "step": 13280
    },
    {
      "epoch": 1.1340558068094548,
      "grad_norm": 0.8470929265022278,
      "learning_rate": 2.1648604829763632e-05,
      "loss": 0.0027,
      "step": 13290
    },
    {
      "epoch": 1.134909121938732,
      "grad_norm": 0.733335018157959,
      "learning_rate": 2.1627271951531703e-05,
      "loss": 0.0028,
      "step": 13300
    },
    {
      "epoch": 1.1357624370680093,
      "grad_norm": 0.5942078232765198,
      "learning_rate": 2.160593907329977e-05,
      "loss": 0.003,
      "step": 13310
    },
    {
      "epoch": 1.1366157521972864,
      "grad_norm": 1.0473872423171997,
      "learning_rate": 2.158460619506784e-05,
      "loss": 0.003,
      "step": 13320
    },
    {
      "epoch": 1.1374690673265637,
      "grad_norm": 0.3170332908630371,
      "learning_rate": 2.1563273316835906e-05,
      "loss": 0.0026,
      "step": 13330
    },
    {
      "epoch": 1.1383223824558408,
      "grad_norm": 0.5760937929153442,
      "learning_rate": 2.1541940438603978e-05,
      "loss": 0.0035,
      "step": 13340
    },
    {
      "epoch": 1.1391756975851182,
      "grad_norm": 0.5515437126159668,
      "learning_rate": 2.1520607560372045e-05,
      "loss": 0.0026,
      "step": 13350
    },
    {
      "epoch": 1.1400290127143955,
      "grad_norm": 1.2573332786560059,
      "learning_rate": 2.1499274682140117e-05,
      "loss": 0.0028,
      "step": 13360
    },
    {
      "epoch": 1.1408823278436726,
      "grad_norm": 0.646269679069519,
      "learning_rate": 2.1477941803908184e-05,
      "loss": 0.0027,
      "step": 13370
    },
    {
      "epoch": 1.14173564297295,
      "grad_norm": 0.44358426332473755,
      "learning_rate": 2.1456608925676252e-05,
      "loss": 0.0022,
      "step": 13380
    },
    {
      "epoch": 1.1425889581022273,
      "grad_norm": 0.4297768473625183,
      "learning_rate": 2.1435276047444323e-05,
      "loss": 0.002,
      "step": 13390
    },
    {
      "epoch": 1.1434422732315044,
      "grad_norm": 0.5723608136177063,
      "learning_rate": 2.141394316921239e-05,
      "loss": 0.003,
      "step": 13400
    },
    {
      "epoch": 1.1442955883607817,
      "grad_norm": 0.4133930802345276,
      "learning_rate": 2.1392610290980462e-05,
      "loss": 0.0024,
      "step": 13410
    },
    {
      "epoch": 1.1451489034900588,
      "grad_norm": 0.3327397108078003,
      "learning_rate": 2.1371277412748527e-05,
      "loss": 0.0035,
      "step": 13420
    },
    {
      "epoch": 1.1460022186193362,
      "grad_norm": 0.6230221390724182,
      "learning_rate": 2.1349944534516598e-05,
      "loss": 0.0023,
      "step": 13430
    },
    {
      "epoch": 1.1468555337486133,
      "grad_norm": 0.639369547367096,
      "learning_rate": 2.1328611656284666e-05,
      "loss": 0.0026,
      "step": 13440
    },
    {
      "epoch": 1.1477088488778906,
      "grad_norm": 0.5943740606307983,
      "learning_rate": 2.1307278778052737e-05,
      "loss": 0.0029,
      "step": 13450
    },
    {
      "epoch": 1.148562164007168,
      "grad_norm": 0.7875533699989319,
      "learning_rate": 2.1285945899820805e-05,
      "loss": 0.0032,
      "step": 13460
    },
    {
      "epoch": 1.149415479136445,
      "grad_norm": 0.38764411211013794,
      "learning_rate": 2.1264613021588876e-05,
      "loss": 0.0028,
      "step": 13470
    },
    {
      "epoch": 1.1502687942657224,
      "grad_norm": 0.36037448048591614,
      "learning_rate": 2.124328014335694e-05,
      "loss": 0.0029,
      "step": 13480
    },
    {
      "epoch": 1.1511221093949995,
      "grad_norm": 0.5179170370101929,
      "learning_rate": 2.1221947265125012e-05,
      "loss": 0.0024,
      "step": 13490
    },
    {
      "epoch": 1.1519754245242768,
      "grad_norm": 0.5010925531387329,
      "learning_rate": 2.120061438689308e-05,
      "loss": 0.0024,
      "step": 13500
    },
    {
      "epoch": 1.1528287396535541,
      "grad_norm": 0.49903517961502075,
      "learning_rate": 2.117928150866115e-05,
      "loss": 0.0033,
      "step": 13510
    },
    {
      "epoch": 1.1536820547828313,
      "grad_norm": 0.5007407665252686,
      "learning_rate": 2.115794863042922e-05,
      "loss": 0.0028,
      "step": 13520
    },
    {
      "epoch": 1.1545353699121086,
      "grad_norm": 0.34964242577552795,
      "learning_rate": 2.1136615752197286e-05,
      "loss": 0.0027,
      "step": 13530
    },
    {
      "epoch": 1.1553886850413857,
      "grad_norm": 0.49420827627182007,
      "learning_rate": 2.1115282873965354e-05,
      "loss": 0.0031,
      "step": 13540
    },
    {
      "epoch": 1.156242000170663,
      "grad_norm": 0.6687310338020325,
      "learning_rate": 2.1093949995733425e-05,
      "loss": 0.0032,
      "step": 13550
    },
    {
      "epoch": 1.1570953152999404,
      "grad_norm": 0.789810836315155,
      "learning_rate": 2.1072617117501493e-05,
      "loss": 0.0028,
      "step": 13560
    },
    {
      "epoch": 1.1579486304292175,
      "grad_norm": 0.7721160054206848,
      "learning_rate": 2.1051284239269564e-05,
      "loss": 0.0025,
      "step": 13570
    },
    {
      "epoch": 1.1588019455584948,
      "grad_norm": 0.6681352257728577,
      "learning_rate": 2.1029951361037632e-05,
      "loss": 0.0028,
      "step": 13580
    },
    {
      "epoch": 1.159655260687772,
      "grad_norm": 0.2853454053401947,
      "learning_rate": 2.10086184828057e-05,
      "loss": 0.0026,
      "step": 13590
    },
    {
      "epoch": 1.1605085758170492,
      "grad_norm": 0.6355891823768616,
      "learning_rate": 2.098728560457377e-05,
      "loss": 0.0024,
      "step": 13600
    },
    {
      "epoch": 1.1613618909463264,
      "grad_norm": 0.38157030940055847,
      "learning_rate": 2.096595272634184e-05,
      "loss": 0.0023,
      "step": 13610
    },
    {
      "epoch": 1.1622152060756037,
      "grad_norm": 1.026497483253479,
      "learning_rate": 2.094461984810991e-05,
      "loss": 0.0031,
      "step": 13620
    },
    {
      "epoch": 1.163068521204881,
      "grad_norm": 0.7373862266540527,
      "learning_rate": 2.0923286969877978e-05,
      "loss": 0.003,
      "step": 13630
    },
    {
      "epoch": 1.1639218363341581,
      "grad_norm": 0.3561934232711792,
      "learning_rate": 2.0901954091646046e-05,
      "loss": 0.0028,
      "step": 13640
    },
    {
      "epoch": 1.1647751514634355,
      "grad_norm": 0.3709695637226105,
      "learning_rate": 2.0880621213414114e-05,
      "loss": 0.0027,
      "step": 13650
    },
    {
      "epoch": 1.1656284665927128,
      "grad_norm": 0.413154661655426,
      "learning_rate": 2.0859288335182185e-05,
      "loss": 0.0025,
      "step": 13660
    },
    {
      "epoch": 1.16648178172199,
      "grad_norm": 0.4500811696052551,
      "learning_rate": 2.0837955456950253e-05,
      "loss": 0.003,
      "step": 13670
    },
    {
      "epoch": 1.1673350968512672,
      "grad_norm": 0.35763463377952576,
      "learning_rate": 2.0816622578718324e-05,
      "loss": 0.0025,
      "step": 13680
    },
    {
      "epoch": 1.1681884119805444,
      "grad_norm": 0.31795188784599304,
      "learning_rate": 2.079528970048639e-05,
      "loss": 0.003,
      "step": 13690
    },
    {
      "epoch": 1.1690417271098217,
      "grad_norm": 0.4415227770805359,
      "learning_rate": 2.077395682225446e-05,
      "loss": 0.0024,
      "step": 13700
    },
    {
      "epoch": 1.1698950422390988,
      "grad_norm": 0.38407906889915466,
      "learning_rate": 2.0752623944022527e-05,
      "loss": 0.0026,
      "step": 13710
    },
    {
      "epoch": 1.1707483573683761,
      "grad_norm": 0.3463484048843384,
      "learning_rate": 2.07312910657906e-05,
      "loss": 0.0026,
      "step": 13720
    },
    {
      "epoch": 1.1716016724976535,
      "grad_norm": 0.41149818897247314,
      "learning_rate": 2.0709958187558666e-05,
      "loss": 0.0028,
      "step": 13730
    },
    {
      "epoch": 1.1724549876269306,
      "grad_norm": 0.38189107179641724,
      "learning_rate": 2.0688625309326734e-05,
      "loss": 0.0029,
      "step": 13740
    },
    {
      "epoch": 1.173308302756208,
      "grad_norm": 0.4813639223575592,
      "learning_rate": 2.0667292431094802e-05,
      "loss": 0.003,
      "step": 13750
    },
    {
      "epoch": 1.1741616178854852,
      "grad_norm": 0.43214499950408936,
      "learning_rate": 2.0645959552862873e-05,
      "loss": 0.0026,
      "step": 13760
    },
    {
      "epoch": 1.1750149330147623,
      "grad_norm": 0.45386359095573425,
      "learning_rate": 2.062462667463094e-05,
      "loss": 0.0029,
      "step": 13770
    },
    {
      "epoch": 1.1758682481440397,
      "grad_norm": 0.4259430766105652,
      "learning_rate": 2.0603293796399012e-05,
      "loss": 0.0024,
      "step": 13780
    },
    {
      "epoch": 1.1767215632733168,
      "grad_norm": 0.5312954783439636,
      "learning_rate": 2.058196091816708e-05,
      "loss": 0.0037,
      "step": 13790
    },
    {
      "epoch": 1.1775748784025941,
      "grad_norm": 0.4905462861061096,
      "learning_rate": 2.0560628039935148e-05,
      "loss": 0.0027,
      "step": 13800
    },
    {
      "epoch": 1.1784281935318712,
      "grad_norm": 0.4815922975540161,
      "learning_rate": 2.053929516170322e-05,
      "loss": 0.0031,
      "step": 13810
    },
    {
      "epoch": 1.1792815086611486,
      "grad_norm": 0.6657596230506897,
      "learning_rate": 2.0517962283471287e-05,
      "loss": 0.0024,
      "step": 13820
    },
    {
      "epoch": 1.180134823790426,
      "grad_norm": 0.3678560256958008,
      "learning_rate": 2.0496629405239355e-05,
      "loss": 0.0026,
      "step": 13830
    },
    {
      "epoch": 1.180988138919703,
      "grad_norm": 0.6020975708961487,
      "learning_rate": 2.0475296527007426e-05,
      "loss": 0.0037,
      "step": 13840
    },
    {
      "epoch": 1.1818414540489803,
      "grad_norm": 0.7316983342170715,
      "learning_rate": 2.0453963648775494e-05,
      "loss": 0.0029,
      "step": 13850
    },
    {
      "epoch": 1.1826947691782574,
      "grad_norm": 0.6908197402954102,
      "learning_rate": 2.043263077054356e-05,
      "loss": 0.0028,
      "step": 13860
    },
    {
      "epoch": 1.1835480843075348,
      "grad_norm": 0.32441210746765137,
      "learning_rate": 2.0411297892311633e-05,
      "loss": 0.0024,
      "step": 13870
    },
    {
      "epoch": 1.184401399436812,
      "grad_norm": 0.22857442498207092,
      "learning_rate": 2.03899650140797e-05,
      "loss": 0.0023,
      "step": 13880
    },
    {
      "epoch": 1.1852547145660892,
      "grad_norm": 0.4190426170825958,
      "learning_rate": 2.0368632135847772e-05,
      "loss": 0.0028,
      "step": 13890
    },
    {
      "epoch": 1.1861080296953666,
      "grad_norm": 0.2930227220058441,
      "learning_rate": 2.0347299257615836e-05,
      "loss": 0.0029,
      "step": 13900
    },
    {
      "epoch": 1.1869613448246437,
      "grad_norm": 0.48596417903900146,
      "learning_rate": 2.0325966379383908e-05,
      "loss": 0.0025,
      "step": 13910
    },
    {
      "epoch": 1.187814659953921,
      "grad_norm": 0.5476276874542236,
      "learning_rate": 2.0304633501151975e-05,
      "loss": 0.0024,
      "step": 13920
    },
    {
      "epoch": 1.1886679750831983,
      "grad_norm": 0.2988174557685852,
      "learning_rate": 2.0283300622920047e-05,
      "loss": 0.0034,
      "step": 13930
    },
    {
      "epoch": 1.1895212902124754,
      "grad_norm": 0.4940645098686218,
      "learning_rate": 2.0261967744688114e-05,
      "loss": 0.0027,
      "step": 13940
    },
    {
      "epoch": 1.1903746053417528,
      "grad_norm": 0.6270349025726318,
      "learning_rate": 2.0240634866456186e-05,
      "loss": 0.0025,
      "step": 13950
    },
    {
      "epoch": 1.1912279204710299,
      "grad_norm": 0.2909659147262573,
      "learning_rate": 2.021930198822425e-05,
      "loss": 0.0031,
      "step": 13960
    },
    {
      "epoch": 1.1920812356003072,
      "grad_norm": 0.9431412816047668,
      "learning_rate": 2.019796910999232e-05,
      "loss": 0.003,
      "step": 13970
    },
    {
      "epoch": 1.1929345507295843,
      "grad_norm": 0.6811290383338928,
      "learning_rate": 2.017663623176039e-05,
      "loss": 0.0028,
      "step": 13980
    },
    {
      "epoch": 1.1937878658588617,
      "grad_norm": 0.4526704251766205,
      "learning_rate": 2.015530335352846e-05,
      "loss": 0.0024,
      "step": 13990
    },
    {
      "epoch": 1.194641180988139,
      "grad_norm": 0.3351852595806122,
      "learning_rate": 2.0133970475296528e-05,
      "loss": 0.0026,
      "step": 14000
    },
    {
      "epoch": 1.195494496117416,
      "grad_norm": 0.6222777962684631,
      "learning_rate": 2.0112637597064596e-05,
      "loss": 0.0025,
      "step": 14010
    },
    {
      "epoch": 1.1963478112466934,
      "grad_norm": 0.8233752846717834,
      "learning_rate": 2.0091304718832664e-05,
      "loss": 0.0022,
      "step": 14020
    },
    {
      "epoch": 1.1972011263759708,
      "grad_norm": 0.3995184600353241,
      "learning_rate": 2.0069971840600735e-05,
      "loss": 0.0027,
      "step": 14030
    },
    {
      "epoch": 1.1980544415052479,
      "grad_norm": 0.5644082427024841,
      "learning_rate": 2.0048638962368803e-05,
      "loss": 0.0026,
      "step": 14040
    },
    {
      "epoch": 1.1989077566345252,
      "grad_norm": 0.38078439235687256,
      "learning_rate": 2.0027306084136874e-05,
      "loss": 0.0028,
      "step": 14050
    },
    {
      "epoch": 1.1997610717638023,
      "grad_norm": 0.4893939793109894,
      "learning_rate": 2.0005973205904942e-05,
      "loss": 0.0023,
      "step": 14060
    },
    {
      "epoch": 1.2006143868930796,
      "grad_norm": 0.4513709545135498,
      "learning_rate": 1.998464032767301e-05,
      "loss": 0.0023,
      "step": 14070
    },
    {
      "epoch": 1.2014677020223568,
      "grad_norm": 0.2762565612792969,
      "learning_rate": 1.996330744944108e-05,
      "loss": 0.0027,
      "step": 14080
    },
    {
      "epoch": 1.202321017151634,
      "grad_norm": 0.4707765579223633,
      "learning_rate": 1.994197457120915e-05,
      "loss": 0.0025,
      "step": 14090
    },
    {
      "epoch": 1.2031743322809114,
      "grad_norm": 0.5553625822067261,
      "learning_rate": 1.992064169297722e-05,
      "loss": 0.0021,
      "step": 14100
    },
    {
      "epoch": 1.2040276474101885,
      "grad_norm": 0.4030512571334839,
      "learning_rate": 1.9899308814745288e-05,
      "loss": 0.0024,
      "step": 14110
    },
    {
      "epoch": 1.2048809625394659,
      "grad_norm": 0.26491567492485046,
      "learning_rate": 1.9877975936513355e-05,
      "loss": 0.0027,
      "step": 14120
    },
    {
      "epoch": 1.205734277668743,
      "grad_norm": 1.4469221830368042,
      "learning_rate": 1.9856643058281423e-05,
      "loss": 0.003,
      "step": 14130
    },
    {
      "epoch": 1.2065875927980203,
      "grad_norm": 0.6176366209983826,
      "learning_rate": 1.9835310180049494e-05,
      "loss": 0.0028,
      "step": 14140
    },
    {
      "epoch": 1.2074409079272976,
      "grad_norm": 0.432410329580307,
      "learning_rate": 1.9813977301817562e-05,
      "loss": 0.0028,
      "step": 14150
    },
    {
      "epoch": 1.2082942230565747,
      "grad_norm": 0.6726546287536621,
      "learning_rate": 1.9792644423585633e-05,
      "loss": 0.0021,
      "step": 14160
    },
    {
      "epoch": 1.209147538185852,
      "grad_norm": 0.48220914602279663,
      "learning_rate": 1.9771311545353698e-05,
      "loss": 0.0024,
      "step": 14170
    },
    {
      "epoch": 1.2100008533151292,
      "grad_norm": 0.6365231275558472,
      "learning_rate": 1.974997866712177e-05,
      "loss": 0.0027,
      "step": 14180
    },
    {
      "epoch": 1.2108541684444065,
      "grad_norm": 0.43147897720336914,
      "learning_rate": 1.9728645788889837e-05,
      "loss": 0.0025,
      "step": 14190
    },
    {
      "epoch": 1.2117074835736839,
      "grad_norm": 0.6201559901237488,
      "learning_rate": 1.9707312910657908e-05,
      "loss": 0.0021,
      "step": 14200
    },
    {
      "epoch": 1.212560798702961,
      "grad_norm": 0.41117459535598755,
      "learning_rate": 1.9685980032425976e-05,
      "loss": 0.003,
      "step": 14210
    },
    {
      "epoch": 1.2134141138322383,
      "grad_norm": 0.3715094327926636,
      "learning_rate": 1.9664647154194044e-05,
      "loss": 0.0024,
      "step": 14220
    },
    {
      "epoch": 1.2142674289615154,
      "grad_norm": 1.226141095161438,
      "learning_rate": 1.964331427596211e-05,
      "loss": 0.0026,
      "step": 14230
    },
    {
      "epoch": 1.2151207440907927,
      "grad_norm": 0.6511334180831909,
      "learning_rate": 1.9621981397730183e-05,
      "loss": 0.0022,
      "step": 14240
    },
    {
      "epoch": 1.2159740592200698,
      "grad_norm": 0.43543681502342224,
      "learning_rate": 1.960064851949825e-05,
      "loss": 0.0036,
      "step": 14250
    },
    {
      "epoch": 1.2168273743493472,
      "grad_norm": 0.5072833895683289,
      "learning_rate": 1.9579315641266322e-05,
      "loss": 0.0028,
      "step": 14260
    },
    {
      "epoch": 1.2176806894786245,
      "grad_norm": 0.570370614528656,
      "learning_rate": 1.955798276303439e-05,
      "loss": 0.003,
      "step": 14270
    },
    {
      "epoch": 1.2185340046079016,
      "grad_norm": 0.4575009346008301,
      "learning_rate": 1.9536649884802457e-05,
      "loss": 0.0027,
      "step": 14280
    },
    {
      "epoch": 1.219387319737179,
      "grad_norm": 0.8338397145271301,
      "learning_rate": 1.951531700657053e-05,
      "loss": 0.003,
      "step": 14290
    },
    {
      "epoch": 1.2202406348664563,
      "grad_norm": 0.4068557620048523,
      "learning_rate": 1.9493984128338596e-05,
      "loss": 0.0032,
      "step": 14300
    },
    {
      "epoch": 1.2210939499957334,
      "grad_norm": 0.31008753180503845,
      "learning_rate": 1.9472651250106668e-05,
      "loss": 0.0024,
      "step": 14310
    },
    {
      "epoch": 1.2219472651250107,
      "grad_norm": 0.7563788890838623,
      "learning_rate": 1.9451318371874735e-05,
      "loss": 0.0024,
      "step": 14320
    },
    {
      "epoch": 1.2228005802542878,
      "grad_norm": 0.9869131445884705,
      "learning_rate": 1.9429985493642803e-05,
      "loss": 0.0028,
      "step": 14330
    },
    {
      "epoch": 1.2236538953835652,
      "grad_norm": 0.4097331166267395,
      "learning_rate": 1.940865261541087e-05,
      "loss": 0.0025,
      "step": 14340
    },
    {
      "epoch": 1.2245072105128423,
      "grad_norm": 0.45120278000831604,
      "learning_rate": 1.9387319737178942e-05,
      "loss": 0.0028,
      "step": 14350
    },
    {
      "epoch": 1.2253605256421196,
      "grad_norm": 0.37503930926322937,
      "learning_rate": 1.936598685894701e-05,
      "loss": 0.0026,
      "step": 14360
    },
    {
      "epoch": 1.226213840771397,
      "grad_norm": 0.31624382734298706,
      "learning_rate": 1.934465398071508e-05,
      "loss": 0.0021,
      "step": 14370
    },
    {
      "epoch": 1.227067155900674,
      "grad_norm": 0.794908881187439,
      "learning_rate": 1.9323321102483146e-05,
      "loss": 0.0026,
      "step": 14380
    },
    {
      "epoch": 1.2279204710299514,
      "grad_norm": 0.5983086228370667,
      "learning_rate": 1.9301988224251217e-05,
      "loss": 0.0028,
      "step": 14390
    },
    {
      "epoch": 1.2287737861592287,
      "grad_norm": 0.22482265532016754,
      "learning_rate": 1.9280655346019285e-05,
      "loss": 0.0024,
      "step": 14400
    },
    {
      "epoch": 1.2296271012885058,
      "grad_norm": 0.8879818320274353,
      "learning_rate": 1.9259322467787356e-05,
      "loss": 0.003,
      "step": 14410
    },
    {
      "epoch": 1.2304804164177832,
      "grad_norm": 0.7627779245376587,
      "learning_rate": 1.9237989589555424e-05,
      "loss": 0.0024,
      "step": 14420
    },
    {
      "epoch": 1.2313337315470603,
      "grad_norm": 0.5824042558670044,
      "learning_rate": 1.921665671132349e-05,
      "loss": 0.0033,
      "step": 14430
    },
    {
      "epoch": 1.2321870466763376,
      "grad_norm": 0.7112154364585876,
      "learning_rate": 1.919532383309156e-05,
      "loss": 0.0025,
      "step": 14440
    },
    {
      "epoch": 1.2330403618056147,
      "grad_norm": 0.2728177607059479,
      "learning_rate": 1.917399095485963e-05,
      "loss": 0.0027,
      "step": 14450
    },
    {
      "epoch": 1.233893676934892,
      "grad_norm": 0.4507351219654083,
      "learning_rate": 1.91526580766277e-05,
      "loss": 0.0024,
      "step": 14460
    },
    {
      "epoch": 1.2347469920641694,
      "grad_norm": 0.6609231233596802,
      "learning_rate": 1.913132519839577e-05,
      "loss": 0.0028,
      "step": 14470
    },
    {
      "epoch": 1.2356003071934465,
      "grad_norm": 0.36864808201789856,
      "learning_rate": 1.9109992320163837e-05,
      "loss": 0.0029,
      "step": 14480
    },
    {
      "epoch": 1.2364536223227238,
      "grad_norm": 0.39255258440971375,
      "learning_rate": 1.9088659441931905e-05,
      "loss": 0.0028,
      "step": 14490
    },
    {
      "epoch": 1.237306937452001,
      "grad_norm": 0.5591742992401123,
      "learning_rate": 1.9067326563699976e-05,
      "loss": 0.0032,
      "step": 14500
    },
    {
      "epoch": 1.2381602525812783,
      "grad_norm": 0.42988505959510803,
      "learning_rate": 1.9045993685468044e-05,
      "loss": 0.0028,
      "step": 14510
    },
    {
      "epoch": 1.2390135677105556,
      "grad_norm": 0.4034114480018616,
      "learning_rate": 1.9024660807236112e-05,
      "loss": 0.0023,
      "step": 14520
    },
    {
      "epoch": 1.2398668828398327,
      "grad_norm": 0.7620894312858582,
      "learning_rate": 1.9003327929004183e-05,
      "loss": 0.0022,
      "step": 14530
    },
    {
      "epoch": 1.24072019796911,
      "grad_norm": 0.4122648537158966,
      "learning_rate": 1.898199505077225e-05,
      "loss": 0.0029,
      "step": 14540
    },
    {
      "epoch": 1.2415735130983871,
      "grad_norm": 0.2588067054748535,
      "learning_rate": 1.896066217254032e-05,
      "loss": 0.0027,
      "step": 14550
    },
    {
      "epoch": 1.2424268282276645,
      "grad_norm": 0.4593387246131897,
      "learning_rate": 1.893932929430839e-05,
      "loss": 0.0029,
      "step": 14560
    },
    {
      "epoch": 1.2432801433569418,
      "grad_norm": 0.7194259166717529,
      "learning_rate": 1.8917996416076458e-05,
      "loss": 0.003,
      "step": 14570
    },
    {
      "epoch": 1.244133458486219,
      "grad_norm": 0.4914554953575134,
      "learning_rate": 1.889666353784453e-05,
      "loss": 0.0025,
      "step": 14580
    },
    {
      "epoch": 1.2449867736154963,
      "grad_norm": 0.8393505811691284,
      "learning_rate": 1.8875330659612594e-05,
      "loss": 0.0029,
      "step": 14590
    },
    {
      "epoch": 1.2458400887447734,
      "grad_norm": 0.4143054187297821,
      "learning_rate": 1.8853997781380665e-05,
      "loss": 0.0027,
      "step": 14600
    },
    {
      "epoch": 1.2466934038740507,
      "grad_norm": 0.9461327195167542,
      "learning_rate": 1.8832664903148733e-05,
      "loss": 0.0029,
      "step": 14610
    },
    {
      "epoch": 1.2475467190033278,
      "grad_norm": 0.6475257277488708,
      "learning_rate": 1.8811332024916804e-05,
      "loss": 0.0023,
      "step": 14620
    },
    {
      "epoch": 1.2484000341326051,
      "grad_norm": 0.7508372068405151,
      "learning_rate": 1.878999914668487e-05,
      "loss": 0.0025,
      "step": 14630
    },
    {
      "epoch": 1.2492533492618825,
      "grad_norm": 0.5297216176986694,
      "learning_rate": 1.8768666268452943e-05,
      "loss": 0.0029,
      "step": 14640
    },
    {
      "epoch": 1.2501066643911596,
      "grad_norm": 0.32799628376960754,
      "learning_rate": 1.8747333390221007e-05,
      "loss": 0.0024,
      "step": 14650
    },
    {
      "epoch": 1.250959979520437,
      "grad_norm": 0.5521665811538696,
      "learning_rate": 1.872600051198908e-05,
      "loss": 0.0025,
      "step": 14660
    },
    {
      "epoch": 1.2518132946497142,
      "grad_norm": 0.4751882255077362,
      "learning_rate": 1.8704667633757146e-05,
      "loss": 0.0023,
      "step": 14670
    },
    {
      "epoch": 1.2526666097789914,
      "grad_norm": 0.35739201307296753,
      "learning_rate": 1.8683334755525217e-05,
      "loss": 0.0032,
      "step": 14680
    },
    {
      "epoch": 1.2535199249082687,
      "grad_norm": 0.32152530550956726,
      "learning_rate": 1.8662001877293285e-05,
      "loss": 0.0028,
      "step": 14690
    },
    {
      "epoch": 1.2543732400375458,
      "grad_norm": 0.22882190346717834,
      "learning_rate": 1.8640668999061353e-05,
      "loss": 0.0031,
      "step": 14700
    },
    {
      "epoch": 1.2552265551668231,
      "grad_norm": 0.2363821268081665,
      "learning_rate": 1.861933612082942e-05,
      "loss": 0.0025,
      "step": 14710
    },
    {
      "epoch": 1.2560798702961002,
      "grad_norm": 0.5514535307884216,
      "learning_rate": 1.8598003242597492e-05,
      "loss": 0.0029,
      "step": 14720
    },
    {
      "epoch": 1.2569331854253776,
      "grad_norm": 0.4474380910396576,
      "learning_rate": 1.857667036436556e-05,
      "loss": 0.0022,
      "step": 14730
    },
    {
      "epoch": 1.257786500554655,
      "grad_norm": 0.32705220580101013,
      "learning_rate": 1.855533748613363e-05,
      "loss": 0.0023,
      "step": 14740
    },
    {
      "epoch": 1.258639815683932,
      "grad_norm": 0.43141642212867737,
      "learning_rate": 1.85340046079017e-05,
      "loss": 0.0027,
      "step": 14750
    },
    {
      "epoch": 1.2594931308132093,
      "grad_norm": 0.5165871977806091,
      "learning_rate": 1.8512671729669767e-05,
      "loss": 0.0022,
      "step": 14760
    },
    {
      "epoch": 1.2603464459424867,
      "grad_norm": 0.8952826857566833,
      "learning_rate": 1.8491338851437838e-05,
      "loss": 0.0028,
      "step": 14770
    },
    {
      "epoch": 1.2611997610717638,
      "grad_norm": 1.0341651439666748,
      "learning_rate": 1.8470005973205906e-05,
      "loss": 0.0024,
      "step": 14780
    },
    {
      "epoch": 1.2620530762010411,
      "grad_norm": 0.3884109854698181,
      "learning_rate": 1.8448673094973977e-05,
      "loss": 0.0029,
      "step": 14790
    },
    {
      "epoch": 1.2629063913303182,
      "grad_norm": 0.64652019739151,
      "learning_rate": 1.8427340216742045e-05,
      "loss": 0.0027,
      "step": 14800
    },
    {
      "epoch": 1.2637597064595956,
      "grad_norm": 0.5243922472000122,
      "learning_rate": 1.8406007338510113e-05,
      "loss": 0.0029,
      "step": 14810
    },
    {
      "epoch": 1.2646130215888727,
      "grad_norm": 0.9246418476104736,
      "learning_rate": 1.838467446027818e-05,
      "loss": 0.0028,
      "step": 14820
    },
    {
      "epoch": 1.26546633671815,
      "grad_norm": 0.3011621832847595,
      "learning_rate": 1.836334158204625e-05,
      "loss": 0.0037,
      "step": 14830
    },
    {
      "epoch": 1.2663196518474273,
      "grad_norm": 1.0093048810958862,
      "learning_rate": 1.834200870381432e-05,
      "loss": 0.0026,
      "step": 14840
    },
    {
      "epoch": 1.2671729669767045,
      "grad_norm": 0.38357013463974,
      "learning_rate": 1.832067582558239e-05,
      "loss": 0.0035,
      "step": 14850
    },
    {
      "epoch": 1.2680262821059818,
      "grad_norm": 0.35204121470451355,
      "learning_rate": 1.8299342947350455e-05,
      "loss": 0.0026,
      "step": 14860
    },
    {
      "epoch": 1.2688795972352591,
      "grad_norm": 0.32955312728881836,
      "learning_rate": 1.8278010069118526e-05,
      "loss": 0.0024,
      "step": 14870
    },
    {
      "epoch": 1.2697329123645362,
      "grad_norm": 0.5815786719322205,
      "learning_rate": 1.8256677190886594e-05,
      "loss": 0.003,
      "step": 14880
    },
    {
      "epoch": 1.2705862274938133,
      "grad_norm": 0.39366573095321655,
      "learning_rate": 1.8235344312654665e-05,
      "loss": 0.0034,
      "step": 14890
    },
    {
      "epoch": 1.2714395426230907,
      "grad_norm": 0.23912504315376282,
      "learning_rate": 1.8214011434422733e-05,
      "loss": 0.0023,
      "step": 14900
    },
    {
      "epoch": 1.272292857752368,
      "grad_norm": 0.5239614248275757,
      "learning_rate": 1.81926785561908e-05,
      "loss": 0.0025,
      "step": 14910
    },
    {
      "epoch": 1.273146172881645,
      "grad_norm": 0.4956062436103821,
      "learning_rate": 1.817134567795887e-05,
      "loss": 0.0022,
      "step": 14920
    },
    {
      "epoch": 1.2739994880109224,
      "grad_norm": 0.9946135878562927,
      "learning_rate": 1.815001279972694e-05,
      "loss": 0.0026,
      "step": 14930
    },
    {
      "epoch": 1.2748528031401998,
      "grad_norm": 0.46220770478248596,
      "learning_rate": 1.8128679921495008e-05,
      "loss": 0.0028,
      "step": 14940
    },
    {
      "epoch": 1.2757061182694769,
      "grad_norm": 0.5485274791717529,
      "learning_rate": 1.810734704326308e-05,
      "loss": 0.0023,
      "step": 14950
    },
    {
      "epoch": 1.2765594333987542,
      "grad_norm": 0.8481668829917908,
      "learning_rate": 1.8086014165031147e-05,
      "loss": 0.0026,
      "step": 14960
    },
    {
      "epoch": 1.2774127485280313,
      "grad_norm": 0.3575691282749176,
      "learning_rate": 1.8064681286799215e-05,
      "loss": 0.0029,
      "step": 14970
    },
    {
      "epoch": 1.2782660636573087,
      "grad_norm": 0.3734840154647827,
      "learning_rate": 1.8043348408567286e-05,
      "loss": 0.0029,
      "step": 14980
    },
    {
      "epoch": 1.2791193787865858,
      "grad_norm": 0.5168085098266602,
      "learning_rate": 1.8022015530335354e-05,
      "loss": 0.0025,
      "step": 14990
    },
    {
      "epoch": 1.279972693915863,
      "grad_norm": 0.3291594088077545,
      "learning_rate": 1.8000682652103425e-05,
      "loss": 0.0026,
      "step": 15000
    },
    {
      "epoch": 1.2808260090451404,
      "grad_norm": 0.5630192756652832,
      "learning_rate": 1.7979349773871493e-05,
      "loss": 0.0035,
      "step": 15010
    },
    {
      "epoch": 1.2816793241744175,
      "grad_norm": 0.2529202401638031,
      "learning_rate": 1.795801689563956e-05,
      "loss": 0.0025,
      "step": 15020
    },
    {
      "epoch": 1.2825326393036949,
      "grad_norm": 0.45282819867134094,
      "learning_rate": 1.793668401740763e-05,
      "loss": 0.0028,
      "step": 15030
    },
    {
      "epoch": 1.2833859544329722,
      "grad_norm": 0.693892240524292,
      "learning_rate": 1.79153511391757e-05,
      "loss": 0.0025,
      "step": 15040
    },
    {
      "epoch": 1.2842392695622493,
      "grad_norm": 0.3143148720264435,
      "learning_rate": 1.7894018260943767e-05,
      "loss": 0.0024,
      "step": 15050
    },
    {
      "epoch": 1.2850925846915267,
      "grad_norm": 0.5553407669067383,
      "learning_rate": 1.787268538271184e-05,
      "loss": 0.0025,
      "step": 15060
    },
    {
      "epoch": 1.2859458998208038,
      "grad_norm": 0.7679038047790527,
      "learning_rate": 1.7851352504479903e-05,
      "loss": 0.002,
      "step": 15070
    },
    {
      "epoch": 1.286799214950081,
      "grad_norm": 0.41035178303718567,
      "learning_rate": 1.7830019626247974e-05,
      "loss": 0.002,
      "step": 15080
    },
    {
      "epoch": 1.2876525300793582,
      "grad_norm": 0.5287866592407227,
      "learning_rate": 1.7808686748016042e-05,
      "loss": 0.0025,
      "step": 15090
    },
    {
      "epoch": 1.2885058452086355,
      "grad_norm": 0.7710622549057007,
      "learning_rate": 1.7787353869784113e-05,
      "loss": 0.0026,
      "step": 15100
    },
    {
      "epoch": 1.2893591603379129,
      "grad_norm": 0.4551902413368225,
      "learning_rate": 1.776602099155218e-05,
      "loss": 0.0023,
      "step": 15110
    },
    {
      "epoch": 1.29021247546719,
      "grad_norm": 0.6375371813774109,
      "learning_rate": 1.7744688113320252e-05,
      "loss": 0.0025,
      "step": 15120
    },
    {
      "epoch": 1.2910657905964673,
      "grad_norm": 0.5102105736732483,
      "learning_rate": 1.7723355235088317e-05,
      "loss": 0.0028,
      "step": 15130
    },
    {
      "epoch": 1.2919191057257446,
      "grad_norm": 0.47787076234817505,
      "learning_rate": 1.7702022356856388e-05,
      "loss": 0.0032,
      "step": 15140
    },
    {
      "epoch": 1.2927724208550218,
      "grad_norm": 0.36172759532928467,
      "learning_rate": 1.7680689478624456e-05,
      "loss": 0.0025,
      "step": 15150
    },
    {
      "epoch": 1.2936257359842989,
      "grad_norm": 0.5807186961174011,
      "learning_rate": 1.7659356600392527e-05,
      "loss": 0.0027,
      "step": 15160
    },
    {
      "epoch": 1.2944790511135762,
      "grad_norm": 0.8874081969261169,
      "learning_rate": 1.7638023722160595e-05,
      "loss": 0.0028,
      "step": 15170
    },
    {
      "epoch": 1.2953323662428535,
      "grad_norm": 0.6340909004211426,
      "learning_rate": 1.7616690843928663e-05,
      "loss": 0.0022,
      "step": 15180
    },
    {
      "epoch": 1.2961856813721306,
      "grad_norm": 1.1773220300674438,
      "learning_rate": 1.7595357965696734e-05,
      "loss": 0.0024,
      "step": 15190
    },
    {
      "epoch": 1.297038996501408,
      "grad_norm": 0.5680809617042542,
      "learning_rate": 1.75740250874648e-05,
      "loss": 0.0021,
      "step": 15200
    },
    {
      "epoch": 1.2978923116306853,
      "grad_norm": 0.41338956356048584,
      "learning_rate": 1.755269220923287e-05,
      "loss": 0.0025,
      "step": 15210
    },
    {
      "epoch": 1.2987456267599624,
      "grad_norm": 0.4258681833744049,
      "learning_rate": 1.753135933100094e-05,
      "loss": 0.0025,
      "step": 15220
    },
    {
      "epoch": 1.2995989418892397,
      "grad_norm": 0.5687013864517212,
      "learning_rate": 1.751002645276901e-05,
      "loss": 0.0025,
      "step": 15230
    },
    {
      "epoch": 1.3004522570185169,
      "grad_norm": 0.583926260471344,
      "learning_rate": 1.7488693574537076e-05,
      "loss": 0.0024,
      "step": 15240
    },
    {
      "epoch": 1.3013055721477942,
      "grad_norm": 1.3675721883773804,
      "learning_rate": 1.7467360696305147e-05,
      "loss": 0.0027,
      "step": 15250
    },
    {
      "epoch": 1.3021588872770713,
      "grad_norm": 1.304163932800293,
      "learning_rate": 1.7446027818073215e-05,
      "loss": 0.0026,
      "step": 15260
    },
    {
      "epoch": 1.3030122024063486,
      "grad_norm": 1.0343023538589478,
      "learning_rate": 1.7424694939841286e-05,
      "loss": 0.0026,
      "step": 15270
    },
    {
      "epoch": 1.303865517535626,
      "grad_norm": 0.535498321056366,
      "learning_rate": 1.740336206160935e-05,
      "loss": 0.0025,
      "step": 15280
    },
    {
      "epoch": 1.304718832664903,
      "grad_norm": 0.4887421727180481,
      "learning_rate": 1.7382029183377422e-05,
      "loss": 0.0022,
      "step": 15290
    },
    {
      "epoch": 1.3055721477941804,
      "grad_norm": 0.867821216583252,
      "learning_rate": 1.736069630514549e-05,
      "loss": 0.0024,
      "step": 15300
    },
    {
      "epoch": 1.3064254629234577,
      "grad_norm": 0.5461855530738831,
      "learning_rate": 1.733936342691356e-05,
      "loss": 0.0029,
      "step": 15310
    },
    {
      "epoch": 1.3072787780527348,
      "grad_norm": 0.3902643918991089,
      "learning_rate": 1.731803054868163e-05,
      "loss": 0.0031,
      "step": 15320
    },
    {
      "epoch": 1.3081320931820122,
      "grad_norm": 0.4736923575401306,
      "learning_rate": 1.72966976704497e-05,
      "loss": 0.0027,
      "step": 15330
    },
    {
      "epoch": 1.3089854083112893,
      "grad_norm": 0.49309808015823364,
      "learning_rate": 1.7275364792217765e-05,
      "loss": 0.0031,
      "step": 15340
    },
    {
      "epoch": 1.3098387234405666,
      "grad_norm": 0.797868013381958,
      "learning_rate": 1.7254031913985836e-05,
      "loss": 0.0027,
      "step": 15350
    },
    {
      "epoch": 1.3106920385698437,
      "grad_norm": 0.3568468987941742,
      "learning_rate": 1.7232699035753904e-05,
      "loss": 0.0026,
      "step": 15360
    },
    {
      "epoch": 1.311545353699121,
      "grad_norm": 0.48199009895324707,
      "learning_rate": 1.7211366157521975e-05,
      "loss": 0.0024,
      "step": 15370
    },
    {
      "epoch": 1.3123986688283984,
      "grad_norm": 0.4836174249649048,
      "learning_rate": 1.7190033279290043e-05,
      "loss": 0.0026,
      "step": 15380
    },
    {
      "epoch": 1.3132519839576755,
      "grad_norm": 0.48630908131599426,
      "learning_rate": 1.716870040105811e-05,
      "loss": 0.0027,
      "step": 15390
    },
    {
      "epoch": 1.3141052990869528,
      "grad_norm": 0.31862443685531616,
      "learning_rate": 1.7147367522826178e-05,
      "loss": 0.0026,
      "step": 15400
    },
    {
      "epoch": 1.3149586142162302,
      "grad_norm": 0.253671795129776,
      "learning_rate": 1.712603464459425e-05,
      "loss": 0.0025,
      "step": 15410
    },
    {
      "epoch": 1.3158119293455073,
      "grad_norm": 0.9554276466369629,
      "learning_rate": 1.7104701766362317e-05,
      "loss": 0.0027,
      "step": 15420
    },
    {
      "epoch": 1.3166652444747846,
      "grad_norm": 1.3468663692474365,
      "learning_rate": 1.708336888813039e-05,
      "loss": 0.0028,
      "step": 15430
    },
    {
      "epoch": 1.3175185596040617,
      "grad_norm": 1.0553460121154785,
      "learning_rate": 1.7062036009898456e-05,
      "loss": 0.0026,
      "step": 15440
    },
    {
      "epoch": 1.318371874733339,
      "grad_norm": 0.319642573595047,
      "learning_rate": 1.7040703131666524e-05,
      "loss": 0.0032,
      "step": 15450
    },
    {
      "epoch": 1.3192251898626162,
      "grad_norm": 0.6608101725578308,
      "learning_rate": 1.7019370253434595e-05,
      "loss": 0.0033,
      "step": 15460
    },
    {
      "epoch": 1.3200785049918935,
      "grad_norm": 0.313739538192749,
      "learning_rate": 1.6998037375202663e-05,
      "loss": 0.0024,
      "step": 15470
    },
    {
      "epoch": 1.3209318201211708,
      "grad_norm": 0.370807945728302,
      "learning_rate": 1.6976704496970734e-05,
      "loss": 0.003,
      "step": 15480
    },
    {
      "epoch": 1.321785135250448,
      "grad_norm": 0.37468475103378296,
      "learning_rate": 1.6955371618738802e-05,
      "loss": 0.0034,
      "step": 15490
    },
    {
      "epoch": 1.3226384503797253,
      "grad_norm": 0.8301498889923096,
      "learning_rate": 1.693403874050687e-05,
      "loss": 0.0029,
      "step": 15500
    },
    {
      "epoch": 1.3234917655090026,
      "grad_norm": 0.5922481417655945,
      "learning_rate": 1.6912705862274938e-05,
      "loss": 0.0028,
      "step": 15510
    },
    {
      "epoch": 1.3243450806382797,
      "grad_norm": 0.8079132437705994,
      "learning_rate": 1.689137298404301e-05,
      "loss": 0.003,
      "step": 15520
    },
    {
      "epoch": 1.3251983957675568,
      "grad_norm": 0.5984886884689331,
      "learning_rate": 1.6870040105811077e-05,
      "loss": 0.0029,
      "step": 15530
    },
    {
      "epoch": 1.3260517108968342,
      "grad_norm": 0.7197954654693604,
      "learning_rate": 1.6848707227579148e-05,
      "loss": 0.0026,
      "step": 15540
    },
    {
      "epoch": 1.3269050260261115,
      "grad_norm": 0.6384324431419373,
      "learning_rate": 1.6827374349347212e-05,
      "loss": 0.0028,
      "step": 15550
    },
    {
      "epoch": 1.3277583411553886,
      "grad_norm": 0.849236249923706,
      "learning_rate": 1.6806041471115284e-05,
      "loss": 0.0025,
      "step": 15560
    },
    {
      "epoch": 1.328611656284666,
      "grad_norm": 0.41184112429618835,
      "learning_rate": 1.678470859288335e-05,
      "loss": 0.003,
      "step": 15570
    },
    {
      "epoch": 1.3294649714139433,
      "grad_norm": 0.797646701335907,
      "learning_rate": 1.6763375714651423e-05,
      "loss": 0.0033,
      "step": 15580
    },
    {
      "epoch": 1.3303182865432204,
      "grad_norm": 0.45528048276901245,
      "learning_rate": 1.674204283641949e-05,
      "loss": 0.0018,
      "step": 15590
    },
    {
      "epoch": 1.3311716016724977,
      "grad_norm": 0.4282810389995575,
      "learning_rate": 1.6720709958187558e-05,
      "loss": 0.0023,
      "step": 15600
    },
    {
      "epoch": 1.3320249168017748,
      "grad_norm": 0.5678562521934509,
      "learning_rate": 1.6699377079955626e-05,
      "loss": 0.0033,
      "step": 15610
    },
    {
      "epoch": 1.3328782319310521,
      "grad_norm": 0.3945228159427643,
      "learning_rate": 1.6678044201723697e-05,
      "loss": 0.0027,
      "step": 15620
    },
    {
      "epoch": 1.3337315470603293,
      "grad_norm": 0.5912140607833862,
      "learning_rate": 1.6656711323491765e-05,
      "loss": 0.0028,
      "step": 15630
    },
    {
      "epoch": 1.3345848621896066,
      "grad_norm": 0.7021328806877136,
      "learning_rate": 1.6635378445259836e-05,
      "loss": 0.0028,
      "step": 15640
    },
    {
      "epoch": 1.335438177318884,
      "grad_norm": 0.4836632311344147,
      "learning_rate": 1.6614045567027904e-05,
      "loss": 0.0024,
      "step": 15650
    },
    {
      "epoch": 1.336291492448161,
      "grad_norm": 0.3046024739742279,
      "learning_rate": 1.6592712688795972e-05,
      "loss": 0.0029,
      "step": 15660
    },
    {
      "epoch": 1.3371448075774384,
      "grad_norm": 0.4278564751148224,
      "learning_rate": 1.6571379810564043e-05,
      "loss": 0.0025,
      "step": 15670
    },
    {
      "epoch": 1.3379981227067157,
      "grad_norm": 0.6609926819801331,
      "learning_rate": 1.655004693233211e-05,
      "loss": 0.0025,
      "step": 15680
    },
    {
      "epoch": 1.3388514378359928,
      "grad_norm": 1.1374850273132324,
      "learning_rate": 1.6528714054100182e-05,
      "loss": 0.0023,
      "step": 15690
    },
    {
      "epoch": 1.3397047529652701,
      "grad_norm": 0.5027157068252563,
      "learning_rate": 1.650738117586825e-05,
      "loss": 0.0026,
      "step": 15700
    },
    {
      "epoch": 1.3405580680945473,
      "grad_norm": 0.3376319408416748,
      "learning_rate": 1.6486048297636318e-05,
      "loss": 0.0026,
      "step": 15710
    },
    {
      "epoch": 1.3414113832238246,
      "grad_norm": 1.044506549835205,
      "learning_rate": 1.6464715419404386e-05,
      "loss": 0.0023,
      "step": 15720
    },
    {
      "epoch": 1.3422646983531017,
      "grad_norm": 0.855320394039154,
      "learning_rate": 1.6443382541172457e-05,
      "loss": 0.0025,
      "step": 15730
    },
    {
      "epoch": 1.343118013482379,
      "grad_norm": 0.9448969960212708,
      "learning_rate": 1.6422049662940525e-05,
      "loss": 0.002,
      "step": 15740
    },
    {
      "epoch": 1.3439713286116564,
      "grad_norm": 0.6343815922737122,
      "learning_rate": 1.6400716784708596e-05,
      "loss": 0.0025,
      "step": 15750
    },
    {
      "epoch": 1.3448246437409335,
      "grad_norm": 0.3337540328502655,
      "learning_rate": 1.637938390647666e-05,
      "loss": 0.0023,
      "step": 15760
    },
    {
      "epoch": 1.3456779588702108,
      "grad_norm": 0.7079610824584961,
      "learning_rate": 1.635805102824473e-05,
      "loss": 0.0027,
      "step": 15770
    },
    {
      "epoch": 1.3465312739994881,
      "grad_norm": 0.3437941372394562,
      "learning_rate": 1.63367181500128e-05,
      "loss": 0.0029,
      "step": 15780
    },
    {
      "epoch": 1.3473845891287652,
      "grad_norm": 0.7737881541252136,
      "learning_rate": 1.631538527178087e-05,
      "loss": 0.0025,
      "step": 15790
    },
    {
      "epoch": 1.3482379042580426,
      "grad_norm": 0.587543249130249,
      "learning_rate": 1.629405239354894e-05,
      "loss": 0.003,
      "step": 15800
    },
    {
      "epoch": 1.3490912193873197,
      "grad_norm": 1.0535683631896973,
      "learning_rate": 1.627271951531701e-05,
      "loss": 0.0024,
      "step": 15810
    },
    {
      "epoch": 1.349944534516597,
      "grad_norm": 0.2989610433578491,
      "learning_rate": 1.6251386637085074e-05,
      "loss": 0.0029,
      "step": 15820
    },
    {
      "epoch": 1.3507978496458741,
      "grad_norm": 0.4235808253288269,
      "learning_rate": 1.6230053758853145e-05,
      "loss": 0.0024,
      "step": 15830
    },
    {
      "epoch": 1.3516511647751515,
      "grad_norm": 0.686782956123352,
      "learning_rate": 1.6208720880621213e-05,
      "loss": 0.0026,
      "step": 15840
    },
    {
      "epoch": 1.3525044799044288,
      "grad_norm": 0.6528340578079224,
      "learning_rate": 1.6187388002389284e-05,
      "loss": 0.0026,
      "step": 15850
    },
    {
      "epoch": 1.353357795033706,
      "grad_norm": 0.42160752415657043,
      "learning_rate": 1.6166055124157352e-05,
      "loss": 0.003,
      "step": 15860
    },
    {
      "epoch": 1.3542111101629832,
      "grad_norm": 0.39135071635246277,
      "learning_rate": 1.614472224592542e-05,
      "loss": 0.0035,
      "step": 15870
    },
    {
      "epoch": 1.3550644252922606,
      "grad_norm": 0.623188316822052,
      "learning_rate": 1.612338936769349e-05,
      "loss": 0.0021,
      "step": 15880
    },
    {
      "epoch": 1.3559177404215377,
      "grad_norm": 0.821395218372345,
      "learning_rate": 1.610205648946156e-05,
      "loss": 0.0028,
      "step": 15890
    },
    {
      "epoch": 1.3567710555508148,
      "grad_norm": 0.3301873207092285,
      "learning_rate": 1.6080723611229627e-05,
      "loss": 0.0029,
      "step": 15900
    },
    {
      "epoch": 1.3576243706800921,
      "grad_norm": 0.6330263614654541,
      "learning_rate": 1.6059390732997698e-05,
      "loss": 0.0028,
      "step": 15910
    },
    {
      "epoch": 1.3584776858093695,
      "grad_norm": 0.28117406368255615,
      "learning_rate": 1.6038057854765766e-05,
      "loss": 0.0024,
      "step": 15920
    },
    {
      "epoch": 1.3593310009386466,
      "grad_norm": 0.7605472803115845,
      "learning_rate": 1.6016724976533833e-05,
      "loss": 0.0023,
      "step": 15930
    },
    {
      "epoch": 1.360184316067924,
      "grad_norm": 0.3802673816680908,
      "learning_rate": 1.5995392098301905e-05,
      "loss": 0.0034,
      "step": 15940
    },
    {
      "epoch": 1.3610376311972012,
      "grad_norm": 0.5061033368110657,
      "learning_rate": 1.5974059220069973e-05,
      "loss": 0.0024,
      "step": 15950
    },
    {
      "epoch": 1.3618909463264783,
      "grad_norm": 0.46639132499694824,
      "learning_rate": 1.5952726341838044e-05,
      "loss": 0.0023,
      "step": 15960
    },
    {
      "epoch": 1.3627442614557557,
      "grad_norm": 0.24123866856098175,
      "learning_rate": 1.593139346360611e-05,
      "loss": 0.0021,
      "step": 15970
    },
    {
      "epoch": 1.3635975765850328,
      "grad_norm": 0.3957918882369995,
      "learning_rate": 1.591006058537418e-05,
      "loss": 0.0019,
      "step": 15980
    },
    {
      "epoch": 1.36445089171431,
      "grad_norm": 0.7140275239944458,
      "learning_rate": 1.5888727707142247e-05,
      "loss": 0.003,
      "step": 15990
    },
    {
      "epoch": 1.3653042068435872,
      "grad_norm": 0.8325151801109314,
      "learning_rate": 1.586739482891032e-05,
      "loss": 0.0032,
      "step": 16000
    },
    {
      "epoch": 1.3661575219728646,
      "grad_norm": 0.4316875636577606,
      "learning_rate": 1.5846061950678386e-05,
      "loss": 0.0022,
      "step": 16010
    },
    {
      "epoch": 1.3670108371021419,
      "grad_norm": 0.5705357193946838,
      "learning_rate": 1.5824729072446457e-05,
      "loss": 0.0025,
      "step": 16020
    },
    {
      "epoch": 1.367864152231419,
      "grad_norm": 1.124611735343933,
      "learning_rate": 1.5803396194214522e-05,
      "loss": 0.002,
      "step": 16030
    },
    {
      "epoch": 1.3687174673606963,
      "grad_norm": 1.0047495365142822,
      "learning_rate": 1.5782063315982593e-05,
      "loss": 0.0026,
      "step": 16040
    },
    {
      "epoch": 1.3695707824899737,
      "grad_norm": 0.2859611213207245,
      "learning_rate": 1.576073043775066e-05,
      "loss": 0.0024,
      "step": 16050
    },
    {
      "epoch": 1.3704240976192508,
      "grad_norm": 0.6872071027755737,
      "learning_rate": 1.5739397559518732e-05,
      "loss": 0.0028,
      "step": 16060
    },
    {
      "epoch": 1.371277412748528,
      "grad_norm": 0.7936309576034546,
      "learning_rate": 1.57180646812868e-05,
      "loss": 0.0026,
      "step": 16070
    },
    {
      "epoch": 1.3721307278778052,
      "grad_norm": 0.4143039286136627,
      "learning_rate": 1.5696731803054868e-05,
      "loss": 0.0023,
      "step": 16080
    },
    {
      "epoch": 1.3729840430070825,
      "grad_norm": 0.27621471881866455,
      "learning_rate": 1.5675398924822935e-05,
      "loss": 0.0025,
      "step": 16090
    },
    {
      "epoch": 1.3738373581363597,
      "grad_norm": 0.6429463624954224,
      "learning_rate": 1.5654066046591007e-05,
      "loss": 0.0023,
      "step": 16100
    },
    {
      "epoch": 1.374690673265637,
      "grad_norm": 0.47181209921836853,
      "learning_rate": 1.5632733168359075e-05,
      "loss": 0.0022,
      "step": 16110
    },
    {
      "epoch": 1.3755439883949143,
      "grad_norm": 0.8723412156105042,
      "learning_rate": 1.5611400290127146e-05,
      "loss": 0.0025,
      "step": 16120
    },
    {
      "epoch": 1.3763973035241914,
      "grad_norm": 0.6312959790229797,
      "learning_rate": 1.5590067411895214e-05,
      "loss": 0.0022,
      "step": 16130
    },
    {
      "epoch": 1.3772506186534688,
      "grad_norm": 0.5001000761985779,
      "learning_rate": 1.556873453366328e-05,
      "loss": 0.0023,
      "step": 16140
    },
    {
      "epoch": 1.378103933782746,
      "grad_norm": 0.3461109697818756,
      "learning_rate": 1.5547401655431353e-05,
      "loss": 0.0025,
      "step": 16150
    },
    {
      "epoch": 1.3789572489120232,
      "grad_norm": 0.30283549427986145,
      "learning_rate": 1.552606877719942e-05,
      "loss": 0.0026,
      "step": 16160
    },
    {
      "epoch": 1.3798105640413003,
      "grad_norm": 1.0431450605392456,
      "learning_rate": 1.550473589896749e-05,
      "loss": 0.0031,
      "step": 16170
    },
    {
      "epoch": 1.3806638791705776,
      "grad_norm": 0.29798761010169983,
      "learning_rate": 1.548340302073556e-05,
      "loss": 0.002,
      "step": 16180
    },
    {
      "epoch": 1.381517194299855,
      "grad_norm": 0.7261620759963989,
      "learning_rate": 1.5462070142503627e-05,
      "loss": 0.0024,
      "step": 16190
    },
    {
      "epoch": 1.382370509429132,
      "grad_norm": 0.30663180351257324,
      "learning_rate": 1.5440737264271695e-05,
      "loss": 0.0024,
      "step": 16200
    },
    {
      "epoch": 1.3832238245584094,
      "grad_norm": 0.4337622821331024,
      "learning_rate": 1.5419404386039766e-05,
      "loss": 0.0031,
      "step": 16210
    },
    {
      "epoch": 1.3840771396876868,
      "grad_norm": 0.5712806582450867,
      "learning_rate": 1.5398071507807834e-05,
      "loss": 0.0036,
      "step": 16220
    },
    {
      "epoch": 1.3849304548169639,
      "grad_norm": 0.5639180541038513,
      "learning_rate": 1.5376738629575905e-05,
      "loss": 0.0027,
      "step": 16230
    },
    {
      "epoch": 1.3857837699462412,
      "grad_norm": 0.6963082551956177,
      "learning_rate": 1.535540575134397e-05,
      "loss": 0.0026,
      "step": 16240
    },
    {
      "epoch": 1.3866370850755185,
      "grad_norm": 0.5122559666633606,
      "learning_rate": 1.533407287311204e-05,
      "loss": 0.0024,
      "step": 16250
    },
    {
      "epoch": 1.3874904002047956,
      "grad_norm": 0.470162034034729,
      "learning_rate": 1.531273999488011e-05,
      "loss": 0.0027,
      "step": 16260
    },
    {
      "epoch": 1.3883437153340727,
      "grad_norm": 0.42321449518203735,
      "learning_rate": 1.529140711664818e-05,
      "loss": 0.0026,
      "step": 16270
    },
    {
      "epoch": 1.38919703046335,
      "grad_norm": 0.527775228023529,
      "learning_rate": 1.5270074238416248e-05,
      "loss": 0.0025,
      "step": 16280
    },
    {
      "epoch": 1.3900503455926274,
      "grad_norm": 0.45419204235076904,
      "learning_rate": 1.5248741360184316e-05,
      "loss": 0.0027,
      "step": 16290
    },
    {
      "epoch": 1.3909036607219045,
      "grad_norm": 0.7249959707260132,
      "learning_rate": 1.5227408481952385e-05,
      "loss": 0.0025,
      "step": 16300
    },
    {
      "epoch": 1.3917569758511819,
      "grad_norm": 0.7998316884040833,
      "learning_rate": 1.5206075603720455e-05,
      "loss": 0.0023,
      "step": 16310
    },
    {
      "epoch": 1.3926102909804592,
      "grad_norm": 0.5542463064193726,
      "learning_rate": 1.5184742725488524e-05,
      "loss": 0.0025,
      "step": 16320
    },
    {
      "epoch": 1.3934636061097363,
      "grad_norm": 0.3005240559577942,
      "learning_rate": 1.5163409847256594e-05,
      "loss": 0.0023,
      "step": 16330
    },
    {
      "epoch": 1.3943169212390136,
      "grad_norm": 0.3775302767753601,
      "learning_rate": 1.5142076969024663e-05,
      "loss": 0.0028,
      "step": 16340
    },
    {
      "epoch": 1.3951702363682907,
      "grad_norm": 0.37497052550315857,
      "learning_rate": 1.512074409079273e-05,
      "loss": 0.0023,
      "step": 16350
    },
    {
      "epoch": 1.396023551497568,
      "grad_norm": 0.6468630433082581,
      "learning_rate": 1.5099411212560799e-05,
      "loss": 0.0024,
      "step": 16360
    },
    {
      "epoch": 1.3968768666268452,
      "grad_norm": 0.8051885366439819,
      "learning_rate": 1.5078078334328868e-05,
      "loss": 0.0021,
      "step": 16370
    },
    {
      "epoch": 1.3977301817561225,
      "grad_norm": 0.5802830457687378,
      "learning_rate": 1.5056745456096938e-05,
      "loss": 0.0023,
      "step": 16380
    },
    {
      "epoch": 1.3985834968853998,
      "grad_norm": 0.4702187478542328,
      "learning_rate": 1.5035412577865007e-05,
      "loss": 0.0025,
      "step": 16390
    },
    {
      "epoch": 1.399436812014677,
      "grad_norm": 0.631241500377655,
      "learning_rate": 1.5014079699633073e-05,
      "loss": 0.0022,
      "step": 16400
    },
    {
      "epoch": 1.4002901271439543,
      "grad_norm": 0.6316124796867371,
      "learning_rate": 1.4992746821401143e-05,
      "loss": 0.0028,
      "step": 16410
    },
    {
      "epoch": 1.4011434422732316,
      "grad_norm": 0.3014501929283142,
      "learning_rate": 1.4971413943169212e-05,
      "loss": 0.0027,
      "step": 16420
    },
    {
      "epoch": 1.4019967574025087,
      "grad_norm": 0.4691622257232666,
      "learning_rate": 1.4950081064937282e-05,
      "loss": 0.0029,
      "step": 16430
    },
    {
      "epoch": 1.402850072531786,
      "grad_norm": 0.32762759923934937,
      "learning_rate": 1.4928748186705351e-05,
      "loss": 0.0024,
      "step": 16440
    },
    {
      "epoch": 1.4037033876610632,
      "grad_norm": 0.42299652099609375,
      "learning_rate": 1.490741530847342e-05,
      "loss": 0.003,
      "step": 16450
    },
    {
      "epoch": 1.4045567027903405,
      "grad_norm": 0.6915460824966431,
      "learning_rate": 1.4886082430241489e-05,
      "loss": 0.0026,
      "step": 16460
    },
    {
      "epoch": 1.4054100179196176,
      "grad_norm": 0.5856719017028809,
      "learning_rate": 1.4864749552009558e-05,
      "loss": 0.0033,
      "step": 16470
    },
    {
      "epoch": 1.406263333048895,
      "grad_norm": 0.8132133483886719,
      "learning_rate": 1.4843416673777628e-05,
      "loss": 0.0024,
      "step": 16480
    },
    {
      "epoch": 1.4071166481781723,
      "grad_norm": 0.26570865511894226,
      "learning_rate": 1.4822083795545697e-05,
      "loss": 0.0024,
      "step": 16490
    },
    {
      "epoch": 1.4079699633074494,
      "grad_norm": 0.7123436331748962,
      "learning_rate": 1.4800750917313767e-05,
      "loss": 0.0024,
      "step": 16500
    },
    {
      "epoch": 1.4088232784367267,
      "grad_norm": 0.44813182950019836,
      "learning_rate": 1.4779418039081833e-05,
      "loss": 0.0024,
      "step": 16510
    },
    {
      "epoch": 1.409676593566004,
      "grad_norm": 0.32249847054481506,
      "learning_rate": 1.4758085160849902e-05,
      "loss": 0.0027,
      "step": 16520
    },
    {
      "epoch": 1.4105299086952812,
      "grad_norm": 0.4935389459133148,
      "learning_rate": 1.4736752282617972e-05,
      "loss": 0.0027,
      "step": 16530
    },
    {
      "epoch": 1.4113832238245583,
      "grad_norm": 0.23394803702831268,
      "learning_rate": 1.4715419404386041e-05,
      "loss": 0.0025,
      "step": 16540
    },
    {
      "epoch": 1.4122365389538356,
      "grad_norm": 0.5323529243469238,
      "learning_rate": 1.4694086526154111e-05,
      "loss": 0.0028,
      "step": 16550
    },
    {
      "epoch": 1.413089854083113,
      "grad_norm": 0.9652400612831116,
      "learning_rate": 1.4672753647922177e-05,
      "loss": 0.0022,
      "step": 16560
    },
    {
      "epoch": 1.41394316921239,
      "grad_norm": 0.29542991518974304,
      "learning_rate": 1.4651420769690247e-05,
      "loss": 0.0021,
      "step": 16570
    },
    {
      "epoch": 1.4147964843416674,
      "grad_norm": 0.38586339354515076,
      "learning_rate": 1.4630087891458316e-05,
      "loss": 0.0026,
      "step": 16580
    },
    {
      "epoch": 1.4156497994709447,
      "grad_norm": 0.5827307105064392,
      "learning_rate": 1.4608755013226386e-05,
      "loss": 0.0026,
      "step": 16590
    },
    {
      "epoch": 1.4165031146002218,
      "grad_norm": 0.7501968741416931,
      "learning_rate": 1.4587422134994455e-05,
      "loss": 0.0025,
      "step": 16600
    },
    {
      "epoch": 1.4173564297294992,
      "grad_norm": 0.22860294580459595,
      "learning_rate": 1.4566089256762521e-05,
      "loss": 0.0023,
      "step": 16610
    },
    {
      "epoch": 1.4182097448587763,
      "grad_norm": 0.4651419222354889,
      "learning_rate": 1.454475637853059e-05,
      "loss": 0.0025,
      "step": 16620
    },
    {
      "epoch": 1.4190630599880536,
      "grad_norm": 0.3728344142436981,
      "learning_rate": 1.452342350029866e-05,
      "loss": 0.0023,
      "step": 16630
    },
    {
      "epoch": 1.4199163751173307,
      "grad_norm": 0.31056347489356995,
      "learning_rate": 1.450209062206673e-05,
      "loss": 0.0032,
      "step": 16640
    },
    {
      "epoch": 1.420769690246608,
      "grad_norm": 0.35363370180130005,
      "learning_rate": 1.44807577438348e-05,
      "loss": 0.0025,
      "step": 16650
    },
    {
      "epoch": 1.4216230053758854,
      "grad_norm": 0.46191689372062683,
      "learning_rate": 1.4459424865602869e-05,
      "loss": 0.0027,
      "step": 16660
    },
    {
      "epoch": 1.4224763205051625,
      "grad_norm": 0.41447746753692627,
      "learning_rate": 1.4438091987370937e-05,
      "loss": 0.0027,
      "step": 16670
    },
    {
      "epoch": 1.4233296356344398,
      "grad_norm": 0.647635817527771,
      "learning_rate": 1.4416759109139006e-05,
      "loss": 0.0026,
      "step": 16680
    },
    {
      "epoch": 1.4241829507637171,
      "grad_norm": 0.3527001738548279,
      "learning_rate": 1.4395426230907074e-05,
      "loss": 0.0029,
      "step": 16690
    },
    {
      "epoch": 1.4250362658929943,
      "grad_norm": 0.338051438331604,
      "learning_rate": 1.4374093352675143e-05,
      "loss": 0.0028,
      "step": 16700
    },
    {
      "epoch": 1.4258895810222716,
      "grad_norm": 0.5350391864776611,
      "learning_rate": 1.4352760474443213e-05,
      "loss": 0.0027,
      "step": 16710
    },
    {
      "epoch": 1.4267428961515487,
      "grad_norm": 0.5517750382423401,
      "learning_rate": 1.433142759621128e-05,
      "loss": 0.0033,
      "step": 16720
    },
    {
      "epoch": 1.427596211280826,
      "grad_norm": 1.0311180353164673,
      "learning_rate": 1.431009471797935e-05,
      "loss": 0.0028,
      "step": 16730
    },
    {
      "epoch": 1.4284495264101031,
      "grad_norm": 0.8770322203636169,
      "learning_rate": 1.428876183974742e-05,
      "loss": 0.0024,
      "step": 16740
    },
    {
      "epoch": 1.4293028415393805,
      "grad_norm": 1.5040106773376465,
      "learning_rate": 1.426742896151549e-05,
      "loss": 0.0026,
      "step": 16750
    },
    {
      "epoch": 1.4301561566686578,
      "grad_norm": 0.796606183052063,
      "learning_rate": 1.4246096083283559e-05,
      "loss": 0.0029,
      "step": 16760
    },
    {
      "epoch": 1.431009471797935,
      "grad_norm": 0.5480188131332397,
      "learning_rate": 1.4224763205051625e-05,
      "loss": 0.0026,
      "step": 16770
    },
    {
      "epoch": 1.4318627869272122,
      "grad_norm": 0.2684108316898346,
      "learning_rate": 1.4203430326819694e-05,
      "loss": 0.0027,
      "step": 16780
    },
    {
      "epoch": 1.4327161020564896,
      "grad_norm": 0.33242687582969666,
      "learning_rate": 1.4182097448587764e-05,
      "loss": 0.0027,
      "step": 16790
    },
    {
      "epoch": 1.4335694171857667,
      "grad_norm": 0.3761216402053833,
      "learning_rate": 1.4160764570355833e-05,
      "loss": 0.0029,
      "step": 16800
    },
    {
      "epoch": 1.434422732315044,
      "grad_norm": 0.7849180102348328,
      "learning_rate": 1.4139431692123903e-05,
      "loss": 0.0026,
      "step": 16810
    },
    {
      "epoch": 1.4352760474443211,
      "grad_norm": 0.6407814621925354,
      "learning_rate": 1.4118098813891973e-05,
      "loss": 0.0027,
      "step": 16820
    },
    {
      "epoch": 1.4361293625735985,
      "grad_norm": 0.73542720079422,
      "learning_rate": 1.4096765935660039e-05,
      "loss": 0.0026,
      "step": 16830
    },
    {
      "epoch": 1.4369826777028756,
      "grad_norm": 0.3705226182937622,
      "learning_rate": 1.4075433057428108e-05,
      "loss": 0.0018,
      "step": 16840
    },
    {
      "epoch": 1.437835992832153,
      "grad_norm": 0.36315280199050903,
      "learning_rate": 1.4054100179196178e-05,
      "loss": 0.0022,
      "step": 16850
    },
    {
      "epoch": 1.4386893079614302,
      "grad_norm": 0.3077235817909241,
      "learning_rate": 1.4032767300964247e-05,
      "loss": 0.0026,
      "step": 16860
    },
    {
      "epoch": 1.4395426230907074,
      "grad_norm": 0.9499287009239197,
      "learning_rate": 1.4011434422732317e-05,
      "loss": 0.0023,
      "step": 16870
    },
    {
      "epoch": 1.4403959382199847,
      "grad_norm": 0.26728716492652893,
      "learning_rate": 1.3990101544500383e-05,
      "loss": 0.0021,
      "step": 16880
    },
    {
      "epoch": 1.441249253349262,
      "grad_norm": 0.7045181393623352,
      "learning_rate": 1.3968768666268452e-05,
      "loss": 0.0023,
      "step": 16890
    },
    {
      "epoch": 1.4421025684785391,
      "grad_norm": 0.4910210072994232,
      "learning_rate": 1.3947435788036522e-05,
      "loss": 0.0026,
      "step": 16900
    },
    {
      "epoch": 1.4429558836078162,
      "grad_norm": 0.25710856914520264,
      "learning_rate": 1.3926102909804591e-05,
      "loss": 0.0021,
      "step": 16910
    },
    {
      "epoch": 1.4438091987370936,
      "grad_norm": 0.5194988250732422,
      "learning_rate": 1.390477003157266e-05,
      "loss": 0.0027,
      "step": 16920
    },
    {
      "epoch": 1.444662513866371,
      "grad_norm": 0.7154885530471802,
      "learning_rate": 1.3883437153340729e-05,
      "loss": 0.0025,
      "step": 16930
    },
    {
      "epoch": 1.445515828995648,
      "grad_norm": 0.7196080684661865,
      "learning_rate": 1.3862104275108798e-05,
      "loss": 0.0028,
      "step": 16940
    },
    {
      "epoch": 1.4463691441249253,
      "grad_norm": 0.46147283911705017,
      "learning_rate": 1.3840771396876868e-05,
      "loss": 0.003,
      "step": 16950
    },
    {
      "epoch": 1.4472224592542027,
      "grad_norm": 0.3473919630050659,
      "learning_rate": 1.3819438518644937e-05,
      "loss": 0.0022,
      "step": 16960
    },
    {
      "epoch": 1.4480757743834798,
      "grad_norm": 0.4127586781978607,
      "learning_rate": 1.3798105640413007e-05,
      "loss": 0.0023,
      "step": 16970
    },
    {
      "epoch": 1.4489290895127571,
      "grad_norm": 0.580642580986023,
      "learning_rate": 1.3776772762181076e-05,
      "loss": 0.0029,
      "step": 16980
    },
    {
      "epoch": 1.4497824046420342,
      "grad_norm": 0.4155407249927521,
      "learning_rate": 1.3755439883949142e-05,
      "loss": 0.0032,
      "step": 16990
    },
    {
      "epoch": 1.4506357197713116,
      "grad_norm": 0.5944095253944397,
      "learning_rate": 1.3734107005717212e-05,
      "loss": 0.0025,
      "step": 17000
    },
    {
      "epoch": 1.4514890349005887,
      "grad_norm": 0.3395174741744995,
      "learning_rate": 1.3712774127485281e-05,
      "loss": 0.0027,
      "step": 17010
    },
    {
      "epoch": 1.452342350029866,
      "grad_norm": 0.32704460620880127,
      "learning_rate": 1.3691441249253351e-05,
      "loss": 0.0027,
      "step": 17020
    },
    {
      "epoch": 1.4531956651591433,
      "grad_norm": 0.7221459150314331,
      "learning_rate": 1.367010837102142e-05,
      "loss": 0.0026,
      "step": 17030
    },
    {
      "epoch": 1.4540489802884204,
      "grad_norm": 1.007651686668396,
      "learning_rate": 1.3648775492789486e-05,
      "loss": 0.0026,
      "step": 17040
    },
    {
      "epoch": 1.4549022954176978,
      "grad_norm": 0.3402780592441559,
      "learning_rate": 1.3627442614557556e-05,
      "loss": 0.0019,
      "step": 17050
    },
    {
      "epoch": 1.455755610546975,
      "grad_norm": 0.2679496705532074,
      "learning_rate": 1.3606109736325626e-05,
      "loss": 0.003,
      "step": 17060
    },
    {
      "epoch": 1.4566089256762522,
      "grad_norm": 0.5971206426620483,
      "learning_rate": 1.3584776858093695e-05,
      "loss": 0.0025,
      "step": 17070
    },
    {
      "epoch": 1.4574622408055296,
      "grad_norm": 0.4116703271865845,
      "learning_rate": 1.3563443979861765e-05,
      "loss": 0.0022,
      "step": 17080
    },
    {
      "epoch": 1.4583155559348067,
      "grad_norm": 0.343632310628891,
      "learning_rate": 1.354211110162983e-05,
      "loss": 0.0027,
      "step": 17090
    },
    {
      "epoch": 1.459168871064084,
      "grad_norm": 0.7793335318565369,
      "learning_rate": 1.35207782233979e-05,
      "loss": 0.0026,
      "step": 17100
    },
    {
      "epoch": 1.460022186193361,
      "grad_norm": 0.3916310966014862,
      "learning_rate": 1.349944534516597e-05,
      "loss": 0.0032,
      "step": 17110
    },
    {
      "epoch": 1.4608755013226384,
      "grad_norm": 0.3832285404205322,
      "learning_rate": 1.347811246693404e-05,
      "loss": 0.0029,
      "step": 17120
    },
    {
      "epoch": 1.4617288164519158,
      "grad_norm": 0.7088686227798462,
      "learning_rate": 1.3456779588702109e-05,
      "loss": 0.0024,
      "step": 17130
    },
    {
      "epoch": 1.4625821315811929,
      "grad_norm": 0.45892319083213806,
      "learning_rate": 1.3435446710470178e-05,
      "loss": 0.0029,
      "step": 17140
    },
    {
      "epoch": 1.4634354467104702,
      "grad_norm": 0.6661511063575745,
      "learning_rate": 1.3414113832238246e-05,
      "loss": 0.0027,
      "step": 17150
    },
    {
      "epoch": 1.4642887618397475,
      "grad_norm": 0.9959620237350464,
      "learning_rate": 1.3392780954006316e-05,
      "loss": 0.0025,
      "step": 17160
    },
    {
      "epoch": 1.4651420769690247,
      "grad_norm": 1.1238240003585815,
      "learning_rate": 1.3371448075774385e-05,
      "loss": 0.0024,
      "step": 17170
    },
    {
      "epoch": 1.465995392098302,
      "grad_norm": 0.6702448129653931,
      "learning_rate": 1.3350115197542455e-05,
      "loss": 0.0033,
      "step": 17180
    },
    {
      "epoch": 1.466848707227579,
      "grad_norm": 1.1986432075500488,
      "learning_rate": 1.3328782319310524e-05,
      "loss": 0.0029,
      "step": 17190
    },
    {
      "epoch": 1.4677020223568564,
      "grad_norm": 0.5363726019859314,
      "learning_rate": 1.330744944107859e-05,
      "loss": 0.0027,
      "step": 17200
    },
    {
      "epoch": 1.4685553374861335,
      "grad_norm": 0.22566145658493042,
      "learning_rate": 1.328611656284666e-05,
      "loss": 0.003,
      "step": 17210
    },
    {
      "epoch": 1.4694086526154109,
      "grad_norm": 0.3256700336933136,
      "learning_rate": 1.326478368461473e-05,
      "loss": 0.0029,
      "step": 17220
    },
    {
      "epoch": 1.4702619677446882,
      "grad_norm": 0.3859284222126007,
      "learning_rate": 1.3243450806382799e-05,
      "loss": 0.0032,
      "step": 17230
    },
    {
      "epoch": 1.4711152828739653,
      "grad_norm": 0.6436281204223633,
      "learning_rate": 1.3222117928150868e-05,
      "loss": 0.0029,
      "step": 17240
    },
    {
      "epoch": 1.4719685980032426,
      "grad_norm": 0.6176066398620605,
      "learning_rate": 1.3200785049918934e-05,
      "loss": 0.0023,
      "step": 17250
    },
    {
      "epoch": 1.47282191313252,
      "grad_norm": 0.4397971034049988,
      "learning_rate": 1.3179452171687004e-05,
      "loss": 0.0025,
      "step": 17260
    },
    {
      "epoch": 1.473675228261797,
      "grad_norm": 0.2691311538219452,
      "learning_rate": 1.3158119293455073e-05,
      "loss": 0.002,
      "step": 17270
    },
    {
      "epoch": 1.4745285433910742,
      "grad_norm": 0.2848552167415619,
      "learning_rate": 1.3136786415223143e-05,
      "loss": 0.0023,
      "step": 17280
    },
    {
      "epoch": 1.4753818585203515,
      "grad_norm": 0.3986710011959076,
      "learning_rate": 1.3115453536991212e-05,
      "loss": 0.002,
      "step": 17290
    },
    {
      "epoch": 1.4762351736496289,
      "grad_norm": 0.25486910343170166,
      "learning_rate": 1.3094120658759279e-05,
      "loss": 0.0021,
      "step": 17300
    },
    {
      "epoch": 1.477088488778906,
      "grad_norm": 0.7310732007026672,
      "learning_rate": 1.3072787780527348e-05,
      "loss": 0.0028,
      "step": 17310
    },
    {
      "epoch": 1.4779418039081833,
      "grad_norm": 0.41865918040275574,
      "learning_rate": 1.3051454902295418e-05,
      "loss": 0.0025,
      "step": 17320
    },
    {
      "epoch": 1.4787951190374606,
      "grad_norm": 0.40335822105407715,
      "learning_rate": 1.3030122024063487e-05,
      "loss": 0.0023,
      "step": 17330
    },
    {
      "epoch": 1.4796484341667377,
      "grad_norm": 0.6723252534866333,
      "learning_rate": 1.3008789145831557e-05,
      "loss": 0.0025,
      "step": 17340
    },
    {
      "epoch": 1.480501749296015,
      "grad_norm": 0.5258915424346924,
      "learning_rate": 1.2987456267599626e-05,
      "loss": 0.0024,
      "step": 17350
    },
    {
      "epoch": 1.4813550644252922,
      "grad_norm": 0.9739217758178711,
      "learning_rate": 1.2966123389367694e-05,
      "loss": 0.0021,
      "step": 17360
    },
    {
      "epoch": 1.4822083795545695,
      "grad_norm": 0.3725649416446686,
      "learning_rate": 1.2944790511135763e-05,
      "loss": 0.0029,
      "step": 17370
    },
    {
      "epoch": 1.4830616946838466,
      "grad_norm": 1.4241358041763306,
      "learning_rate": 1.2923457632903831e-05,
      "loss": 0.0024,
      "step": 17380
    },
    {
      "epoch": 1.483915009813124,
      "grad_norm": 0.5662397742271423,
      "learning_rate": 1.29021247546719e-05,
      "loss": 0.0032,
      "step": 17390
    },
    {
      "epoch": 1.4847683249424013,
      "grad_norm": 0.33051422238349915,
      "learning_rate": 1.288079187643997e-05,
      "loss": 0.0024,
      "step": 17400
    },
    {
      "epoch": 1.4856216400716784,
      "grad_norm": 0.4125024676322937,
      "learning_rate": 1.2859458998208038e-05,
      "loss": 0.0027,
      "step": 17410
    },
    {
      "epoch": 1.4864749552009557,
      "grad_norm": 0.41588377952575684,
      "learning_rate": 1.2838126119976108e-05,
      "loss": 0.0024,
      "step": 17420
    },
    {
      "epoch": 1.487328270330233,
      "grad_norm": 0.46624526381492615,
      "learning_rate": 1.2816793241744177e-05,
      "loss": 0.0029,
      "step": 17430
    },
    {
      "epoch": 1.4881815854595102,
      "grad_norm": 0.346445232629776,
      "learning_rate": 1.2795460363512247e-05,
      "loss": 0.0024,
      "step": 17440
    },
    {
      "epoch": 1.4890349005887875,
      "grad_norm": 0.5971452593803406,
      "learning_rate": 1.2774127485280316e-05,
      "loss": 0.0024,
      "step": 17450
    },
    {
      "epoch": 1.4898882157180646,
      "grad_norm": 0.6422424912452698,
      "learning_rate": 1.2752794607048382e-05,
      "loss": 0.0023,
      "step": 17460
    },
    {
      "epoch": 1.490741530847342,
      "grad_norm": 0.9477125406265259,
      "learning_rate": 1.2731461728816452e-05,
      "loss": 0.0025,
      "step": 17470
    },
    {
      "epoch": 1.491594845976619,
      "grad_norm": 0.5567263960838318,
      "learning_rate": 1.2710128850584521e-05,
      "loss": 0.0024,
      "step": 17480
    },
    {
      "epoch": 1.4924481611058964,
      "grad_norm": 0.45620596408843994,
      "learning_rate": 1.268879597235259e-05,
      "loss": 0.0027,
      "step": 17490
    },
    {
      "epoch": 1.4933014762351737,
      "grad_norm": 0.3253522217273712,
      "learning_rate": 1.266746309412066e-05,
      "loss": 0.0024,
      "step": 17500
    },
    {
      "epoch": 1.4941547913644508,
      "grad_norm": 0.7483838796615601,
      "learning_rate": 1.264613021588873e-05,
      "loss": 0.0026,
      "step": 17510
    },
    {
      "epoch": 1.4950081064937282,
      "grad_norm": 0.6337835788726807,
      "learning_rate": 1.2624797337656796e-05,
      "loss": 0.0022,
      "step": 17520
    },
    {
      "epoch": 1.4958614216230055,
      "grad_norm": 0.9621061086654663,
      "learning_rate": 1.2603464459424865e-05,
      "loss": 0.0024,
      "step": 17530
    },
    {
      "epoch": 1.4967147367522826,
      "grad_norm": 0.7642754912376404,
      "learning_rate": 1.2582131581192935e-05,
      "loss": 0.0029,
      "step": 17540
    },
    {
      "epoch": 1.4975680518815597,
      "grad_norm": 0.9650441408157349,
      "learning_rate": 1.2560798702961004e-05,
      "loss": 0.0026,
      "step": 17550
    },
    {
      "epoch": 1.498421367010837,
      "grad_norm": 0.6489644050598145,
      "learning_rate": 1.2539465824729074e-05,
      "loss": 0.0022,
      "step": 17560
    },
    {
      "epoch": 1.4992746821401144,
      "grad_norm": 0.7039718627929688,
      "learning_rate": 1.251813294649714e-05,
      "loss": 0.0025,
      "step": 17570
    },
    {
      "epoch": 1.5001279972693915,
      "grad_norm": 0.4903547763824463,
      "learning_rate": 1.249680006826521e-05,
      "loss": 0.0024,
      "step": 17580
    },
    {
      "epoch": 1.5009813123986688,
      "grad_norm": 0.34799084067344666,
      "learning_rate": 1.2475467190033279e-05,
      "loss": 0.0018,
      "step": 17590
    },
    {
      "epoch": 1.5018346275279462,
      "grad_norm": 0.33123117685317993,
      "learning_rate": 1.2454134311801349e-05,
      "loss": 0.0024,
      "step": 17600
    },
    {
      "epoch": 1.5026879426572233,
      "grad_norm": 0.6489579081535339,
      "learning_rate": 1.2432801433569418e-05,
      "loss": 0.0027,
      "step": 17610
    },
    {
      "epoch": 1.5035412577865006,
      "grad_norm": 0.3850865960121155,
      "learning_rate": 1.2411468555337488e-05,
      "loss": 0.0021,
      "step": 17620
    },
    {
      "epoch": 1.504394572915778,
      "grad_norm": 0.33562907576560974,
      "learning_rate": 1.2390135677105555e-05,
      "loss": 0.0024,
      "step": 17630
    },
    {
      "epoch": 1.505247888045055,
      "grad_norm": 0.4342482089996338,
      "learning_rate": 1.2368802798873625e-05,
      "loss": 0.0022,
      "step": 17640
    },
    {
      "epoch": 1.5061012031743322,
      "grad_norm": 0.4593501389026642,
      "learning_rate": 1.2347469920641694e-05,
      "loss": 0.0022,
      "step": 17650
    },
    {
      "epoch": 1.5069545183036095,
      "grad_norm": 0.677468478679657,
      "learning_rate": 1.2326137042409762e-05,
      "loss": 0.0023,
      "step": 17660
    },
    {
      "epoch": 1.5078078334328868,
      "grad_norm": 0.9545733332633972,
      "learning_rate": 1.2304804164177832e-05,
      "loss": 0.0028,
      "step": 17670
    },
    {
      "epoch": 1.508661148562164,
      "grad_norm": 0.5747771859169006,
      "learning_rate": 1.2283471285945901e-05,
      "loss": 0.0023,
      "step": 17680
    },
    {
      "epoch": 1.5095144636914413,
      "grad_norm": 0.4026346206665039,
      "learning_rate": 1.2262138407713969e-05,
      "loss": 0.0021,
      "step": 17690
    },
    {
      "epoch": 1.5103677788207186,
      "grad_norm": 0.5257400870323181,
      "learning_rate": 1.2240805529482039e-05,
      "loss": 0.0028,
      "step": 17700
    },
    {
      "epoch": 1.5112210939499957,
      "grad_norm": 0.5761452317237854,
      "learning_rate": 1.2219472651250108e-05,
      "loss": 0.0025,
      "step": 17710
    },
    {
      "epoch": 1.5120744090792728,
      "grad_norm": 0.8739908933639526,
      "learning_rate": 1.2198139773018176e-05,
      "loss": 0.0021,
      "step": 17720
    },
    {
      "epoch": 1.5129277242085504,
      "grad_norm": 0.5214393734931946,
      "learning_rate": 1.2176806894786245e-05,
      "loss": 0.0024,
      "step": 17730
    },
    {
      "epoch": 1.5137810393378275,
      "grad_norm": 0.5609651803970337,
      "learning_rate": 1.2155474016554313e-05,
      "loss": 0.0021,
      "step": 17740
    },
    {
      "epoch": 1.5146343544671046,
      "grad_norm": 0.5982450246810913,
      "learning_rate": 1.2134141138322383e-05,
      "loss": 0.0031,
      "step": 17750
    },
    {
      "epoch": 1.515487669596382,
      "grad_norm": 0.5632561445236206,
      "learning_rate": 1.2112808260090452e-05,
      "loss": 0.0024,
      "step": 17760
    },
    {
      "epoch": 1.5163409847256593,
      "grad_norm": 0.6685351729393005,
      "learning_rate": 1.209147538185852e-05,
      "loss": 0.0021,
      "step": 17770
    },
    {
      "epoch": 1.5171942998549364,
      "grad_norm": 0.7433534264564514,
      "learning_rate": 1.207014250362659e-05,
      "loss": 0.0021,
      "step": 17780
    },
    {
      "epoch": 1.5180476149842137,
      "grad_norm": 0.53407883644104,
      "learning_rate": 1.2048809625394659e-05,
      "loss": 0.0027,
      "step": 17790
    },
    {
      "epoch": 1.518900930113491,
      "grad_norm": 0.42753881216049194,
      "learning_rate": 1.2027476747162727e-05,
      "loss": 0.0029,
      "step": 17800
    },
    {
      "epoch": 1.5197542452427681,
      "grad_norm": 0.4541099965572357,
      "learning_rate": 1.2006143868930796e-05,
      "loss": 0.0026,
      "step": 17810
    },
    {
      "epoch": 1.5206075603720453,
      "grad_norm": 0.5547855496406555,
      "learning_rate": 1.1984810990698864e-05,
      "loss": 0.0026,
      "step": 17820
    },
    {
      "epoch": 1.5214608755013226,
      "grad_norm": 0.3497333526611328,
      "learning_rate": 1.1963478112466934e-05,
      "loss": 0.0022,
      "step": 17830
    },
    {
      "epoch": 1.5223141906306,
      "grad_norm": 0.7416269183158875,
      "learning_rate": 1.1942145234235003e-05,
      "loss": 0.002,
      "step": 17840
    },
    {
      "epoch": 1.523167505759877,
      "grad_norm": 0.4566836655139923,
      "learning_rate": 1.1920812356003073e-05,
      "loss": 0.0028,
      "step": 17850
    },
    {
      "epoch": 1.5240208208891544,
      "grad_norm": 0.3902420997619629,
      "learning_rate": 1.1899479477771142e-05,
      "loss": 0.0025,
      "step": 17860
    },
    {
      "epoch": 1.5248741360184317,
      "grad_norm": 0.6816417574882507,
      "learning_rate": 1.1878146599539212e-05,
      "loss": 0.0024,
      "step": 17870
    },
    {
      "epoch": 1.5257274511477088,
      "grad_norm": 0.3955368101596832,
      "learning_rate": 1.185681372130728e-05,
      "loss": 0.0023,
      "step": 17880
    },
    {
      "epoch": 1.5265807662769861,
      "grad_norm": 0.5394018888473511,
      "learning_rate": 1.183548084307535e-05,
      "loss": 0.002,
      "step": 17890
    },
    {
      "epoch": 1.5274340814062635,
      "grad_norm": 0.5308123826980591,
      "learning_rate": 1.1814147964843417e-05,
      "loss": 0.0027,
      "step": 17900
    },
    {
      "epoch": 1.5282873965355406,
      "grad_norm": 0.40337538719177246,
      "learning_rate": 1.1792815086611487e-05,
      "loss": 0.0031,
      "step": 17910
    },
    {
      "epoch": 1.5291407116648177,
      "grad_norm": 0.4773613512516022,
      "learning_rate": 1.1771482208379556e-05,
      "loss": 0.0029,
      "step": 17920
    },
    {
      "epoch": 1.529994026794095,
      "grad_norm": 0.45561984181404114,
      "learning_rate": 1.1750149330147624e-05,
      "loss": 0.0028,
      "step": 17930
    },
    {
      "epoch": 1.5308473419233724,
      "grad_norm": 0.29200565814971924,
      "learning_rate": 1.1728816451915693e-05,
      "loss": 0.0025,
      "step": 17940
    },
    {
      "epoch": 1.5317006570526495,
      "grad_norm": 0.4302803575992584,
      "learning_rate": 1.1707483573683763e-05,
      "loss": 0.0024,
      "step": 17950
    },
    {
      "epoch": 1.5325539721819268,
      "grad_norm": 0.28809815645217896,
      "learning_rate": 1.168615069545183e-05,
      "loss": 0.0024,
      "step": 17960
    },
    {
      "epoch": 1.5334072873112041,
      "grad_norm": 0.35248857736587524,
      "learning_rate": 1.16648178172199e-05,
      "loss": 0.0029,
      "step": 17970
    },
    {
      "epoch": 1.5342606024404812,
      "grad_norm": 0.7816165685653687,
      "learning_rate": 1.1643484938987968e-05,
      "loss": 0.0023,
      "step": 17980
    },
    {
      "epoch": 1.5351139175697583,
      "grad_norm": 0.49428829550743103,
      "learning_rate": 1.1622152060756038e-05,
      "loss": 0.0023,
      "step": 17990
    },
    {
      "epoch": 1.535967232699036,
      "grad_norm": 0.4894239008426666,
      "learning_rate": 1.1600819182524107e-05,
      "loss": 0.0026,
      "step": 18000
    },
    {
      "epoch": 1.536820547828313,
      "grad_norm": 0.38860976696014404,
      "learning_rate": 1.1579486304292175e-05,
      "loss": 0.0022,
      "step": 18010
    },
    {
      "epoch": 1.5376738629575901,
      "grad_norm": 0.5589771270751953,
      "learning_rate": 1.1558153426060244e-05,
      "loss": 0.0023,
      "step": 18020
    },
    {
      "epoch": 1.5385271780868675,
      "grad_norm": 0.6161841154098511,
      "learning_rate": 1.1536820547828314e-05,
      "loss": 0.0023,
      "step": 18030
    },
    {
      "epoch": 1.5393804932161448,
      "grad_norm": 0.7484769821166992,
      "learning_rate": 1.1515487669596382e-05,
      "loss": 0.0021,
      "step": 18040
    },
    {
      "epoch": 1.540233808345422,
      "grad_norm": 0.30122628808021545,
      "learning_rate": 1.1494154791364451e-05,
      "loss": 0.0021,
      "step": 18050
    },
    {
      "epoch": 1.5410871234746992,
      "grad_norm": 0.663232147693634,
      "learning_rate": 1.147282191313252e-05,
      "loss": 0.0026,
      "step": 18060
    },
    {
      "epoch": 1.5419404386039766,
      "grad_norm": 0.720171332359314,
      "learning_rate": 1.1451489034900589e-05,
      "loss": 0.0024,
      "step": 18070
    },
    {
      "epoch": 1.5427937537332537,
      "grad_norm": 0.4341948330402374,
      "learning_rate": 1.1430156156668658e-05,
      "loss": 0.0024,
      "step": 18080
    },
    {
      "epoch": 1.5436470688625308,
      "grad_norm": 0.25840961933135986,
      "learning_rate": 1.1408823278436728e-05,
      "loss": 0.0028,
      "step": 18090
    },
    {
      "epoch": 1.5445003839918083,
      "grad_norm": 0.42526522278785706,
      "learning_rate": 1.1387490400204797e-05,
      "loss": 0.0023,
      "step": 18100
    },
    {
      "epoch": 1.5453536991210854,
      "grad_norm": 0.4025077223777771,
      "learning_rate": 1.1366157521972865e-05,
      "loss": 0.0021,
      "step": 18110
    },
    {
      "epoch": 1.5462070142503626,
      "grad_norm": 0.38855376839637756,
      "learning_rate": 1.1344824643740934e-05,
      "loss": 0.0025,
      "step": 18120
    },
    {
      "epoch": 1.5470603293796399,
      "grad_norm": 0.3214995265007019,
      "learning_rate": 1.1323491765509004e-05,
      "loss": 0.0025,
      "step": 18130
    },
    {
      "epoch": 1.5479136445089172,
      "grad_norm": 0.4011683166027069,
      "learning_rate": 1.1302158887277072e-05,
      "loss": 0.0026,
      "step": 18140
    },
    {
      "epoch": 1.5487669596381943,
      "grad_norm": 0.3648810088634491,
      "learning_rate": 1.1280826009045141e-05,
      "loss": 0.0028,
      "step": 18150
    },
    {
      "epoch": 1.5496202747674717,
      "grad_norm": 0.49642983078956604,
      "learning_rate": 1.125949313081321e-05,
      "loss": 0.0025,
      "step": 18160
    },
    {
      "epoch": 1.550473589896749,
      "grad_norm": 0.5240218639373779,
      "learning_rate": 1.1238160252581279e-05,
      "loss": 0.0022,
      "step": 18170
    },
    {
      "epoch": 1.551326905026026,
      "grad_norm": 0.5705443620681763,
      "learning_rate": 1.1216827374349348e-05,
      "loss": 0.0025,
      "step": 18180
    },
    {
      "epoch": 1.5521802201553032,
      "grad_norm": 0.3181474208831787,
      "learning_rate": 1.1195494496117416e-05,
      "loss": 0.0021,
      "step": 18190
    },
    {
      "epoch": 1.5530335352845805,
      "grad_norm": 0.31825903058052063,
      "learning_rate": 1.1174161617885485e-05,
      "loss": 0.002,
      "step": 18200
    },
    {
      "epoch": 1.5538868504138579,
      "grad_norm": 0.5829784870147705,
      "learning_rate": 1.1152828739653555e-05,
      "loss": 0.0022,
      "step": 18210
    },
    {
      "epoch": 1.554740165543135,
      "grad_norm": 0.6785485148429871,
      "learning_rate": 1.1131495861421623e-05,
      "loss": 0.0019,
      "step": 18220
    },
    {
      "epoch": 1.5555934806724123,
      "grad_norm": 0.7958781123161316,
      "learning_rate": 1.1110162983189692e-05,
      "loss": 0.0024,
      "step": 18230
    },
    {
      "epoch": 1.5564467958016897,
      "grad_norm": 0.5577433109283447,
      "learning_rate": 1.1088830104957762e-05,
      "loss": 0.0025,
      "step": 18240
    },
    {
      "epoch": 1.5573001109309668,
      "grad_norm": 0.7972044348716736,
      "learning_rate": 1.106749722672583e-05,
      "loss": 0.0026,
      "step": 18250
    },
    {
      "epoch": 1.558153426060244,
      "grad_norm": 0.5387425422668457,
      "learning_rate": 1.1046164348493899e-05,
      "loss": 0.0023,
      "step": 18260
    },
    {
      "epoch": 1.5590067411895214,
      "grad_norm": 0.6027593016624451,
      "learning_rate": 1.1024831470261967e-05,
      "loss": 0.0026,
      "step": 18270
    },
    {
      "epoch": 1.5598600563187985,
      "grad_norm": 0.2736160457134247,
      "learning_rate": 1.1003498592030036e-05,
      "loss": 0.002,
      "step": 18280
    },
    {
      "epoch": 1.5607133714480756,
      "grad_norm": 0.3775973916053772,
      "learning_rate": 1.0982165713798106e-05,
      "loss": 0.0021,
      "step": 18290
    },
    {
      "epoch": 1.561566686577353,
      "grad_norm": 0.7637822031974792,
      "learning_rate": 1.0960832835566175e-05,
      "loss": 0.0022,
      "step": 18300
    },
    {
      "epoch": 1.5624200017066303,
      "grad_norm": 0.8658871054649353,
      "learning_rate": 1.0939499957334245e-05,
      "loss": 0.0023,
      "step": 18310
    },
    {
      "epoch": 1.5632733168359074,
      "grad_norm": 0.2705482840538025,
      "learning_rate": 1.0918167079102313e-05,
      "loss": 0.0023,
      "step": 18320
    },
    {
      "epoch": 1.5641266319651848,
      "grad_norm": 0.7673541903495789,
      "learning_rate": 1.0896834200870382e-05,
      "loss": 0.0027,
      "step": 18330
    },
    {
      "epoch": 1.564979947094462,
      "grad_norm": 0.564611554145813,
      "learning_rate": 1.0875501322638452e-05,
      "loss": 0.0022,
      "step": 18340
    },
    {
      "epoch": 1.5658332622237392,
      "grad_norm": 0.7435727119445801,
      "learning_rate": 1.085416844440652e-05,
      "loss": 0.0024,
      "step": 18350
    },
    {
      "epoch": 1.5666865773530163,
      "grad_norm": 0.7238205075263977,
      "learning_rate": 1.0832835566174589e-05,
      "loss": 0.0023,
      "step": 18360
    },
    {
      "epoch": 1.5675398924822939,
      "grad_norm": 0.4669042229652405,
      "learning_rate": 1.0811502687942659e-05,
      "loss": 0.0026,
      "step": 18370
    },
    {
      "epoch": 1.568393207611571,
      "grad_norm": 0.3309931457042694,
      "learning_rate": 1.0790169809710726e-05,
      "loss": 0.0025,
      "step": 18380
    },
    {
      "epoch": 1.569246522740848,
      "grad_norm": 0.31175321340560913,
      "learning_rate": 1.0768836931478796e-05,
      "loss": 0.0023,
      "step": 18390
    },
    {
      "epoch": 1.5700998378701254,
      "grad_norm": 0.40469008684158325,
      "learning_rate": 1.0747504053246865e-05,
      "loss": 0.0023,
      "step": 18400
    },
    {
      "epoch": 1.5709531529994027,
      "grad_norm": 0.550636351108551,
      "learning_rate": 1.0726171175014933e-05,
      "loss": 0.0022,
      "step": 18410
    },
    {
      "epoch": 1.5718064681286799,
      "grad_norm": 0.37517043948173523,
      "learning_rate": 1.0704838296783003e-05,
      "loss": 0.0023,
      "step": 18420
    },
    {
      "epoch": 1.5726597832579572,
      "grad_norm": 0.281835675239563,
      "learning_rate": 1.068350541855107e-05,
      "loss": 0.0022,
      "step": 18430
    },
    {
      "epoch": 1.5735130983872345,
      "grad_norm": 0.8832840323448181,
      "learning_rate": 1.066217254031914e-05,
      "loss": 0.0018,
      "step": 18440
    },
    {
      "epoch": 1.5743664135165116,
      "grad_norm": 0.4086085259914398,
      "learning_rate": 1.064083966208721e-05,
      "loss": 0.0021,
      "step": 18450
    },
    {
      "epoch": 1.5752197286457887,
      "grad_norm": 0.34912270307540894,
      "learning_rate": 1.0619506783855277e-05,
      "loss": 0.0028,
      "step": 18460
    },
    {
      "epoch": 1.5760730437750663,
      "grad_norm": 0.735278844833374,
      "learning_rate": 1.0598173905623347e-05,
      "loss": 0.0028,
      "step": 18470
    },
    {
      "epoch": 1.5769263589043434,
      "grad_norm": 0.8683604001998901,
      "learning_rate": 1.0576841027391416e-05,
      "loss": 0.0027,
      "step": 18480
    },
    {
      "epoch": 1.5777796740336205,
      "grad_norm": 0.49623796343803406,
      "learning_rate": 1.0555508149159484e-05,
      "loss": 0.0022,
      "step": 18490
    },
    {
      "epoch": 1.5786329891628978,
      "grad_norm": 0.3729683756828308,
      "learning_rate": 1.0534175270927554e-05,
      "loss": 0.0024,
      "step": 18500
    },
    {
      "epoch": 1.5794863042921752,
      "grad_norm": 0.2934393882751465,
      "learning_rate": 1.0512842392695622e-05,
      "loss": 0.0032,
      "step": 18510
    },
    {
      "epoch": 1.5803396194214523,
      "grad_norm": 0.4307105243206024,
      "learning_rate": 1.0491509514463691e-05,
      "loss": 0.0031,
      "step": 18520
    },
    {
      "epoch": 1.5811929345507296,
      "grad_norm": 1.108434796333313,
      "learning_rate": 1.047017663623176e-05,
      "loss": 0.0023,
      "step": 18530
    },
    {
      "epoch": 1.582046249680007,
      "grad_norm": 0.6358954310417175,
      "learning_rate": 1.044884375799983e-05,
      "loss": 0.0024,
      "step": 18540
    },
    {
      "epoch": 1.582899564809284,
      "grad_norm": 0.2584460377693176,
      "learning_rate": 1.04275108797679e-05,
      "loss": 0.0023,
      "step": 18550
    },
    {
      "epoch": 1.5837528799385612,
      "grad_norm": 0.7732084393501282,
      "learning_rate": 1.0406178001535969e-05,
      "loss": 0.0026,
      "step": 18560
    },
    {
      "epoch": 1.5846061950678385,
      "grad_norm": 0.34904730319976807,
      "learning_rate": 1.0384845123304037e-05,
      "loss": 0.0028,
      "step": 18570
    },
    {
      "epoch": 1.5854595101971158,
      "grad_norm": 0.537972629070282,
      "learning_rate": 1.0363512245072106e-05,
      "loss": 0.0018,
      "step": 18580
    },
    {
      "epoch": 1.586312825326393,
      "grad_norm": 0.5379706621170044,
      "learning_rate": 1.0342179366840174e-05,
      "loss": 0.0024,
      "step": 18590
    },
    {
      "epoch": 1.5871661404556703,
      "grad_norm": 0.40378889441490173,
      "learning_rate": 1.0320846488608244e-05,
      "loss": 0.0029,
      "step": 18600
    },
    {
      "epoch": 1.5880194555849476,
      "grad_norm": 0.8051246404647827,
      "learning_rate": 1.0299513610376313e-05,
      "loss": 0.0019,
      "step": 18610
    },
    {
      "epoch": 1.5888727707142247,
      "grad_norm": 0.339957594871521,
      "learning_rate": 1.0278180732144381e-05,
      "loss": 0.0025,
      "step": 18620
    },
    {
      "epoch": 1.589726085843502,
      "grad_norm": 0.3249185085296631,
      "learning_rate": 1.025684785391245e-05,
      "loss": 0.0025,
      "step": 18630
    },
    {
      "epoch": 1.5905794009727794,
      "grad_norm": 0.3847311735153198,
      "learning_rate": 1.023551497568052e-05,
      "loss": 0.0019,
      "step": 18640
    },
    {
      "epoch": 1.5914327161020565,
      "grad_norm": 0.4533410668373108,
      "learning_rate": 1.0214182097448588e-05,
      "loss": 0.0021,
      "step": 18650
    },
    {
      "epoch": 1.5922860312313336,
      "grad_norm": 0.9023982882499695,
      "learning_rate": 1.0192849219216657e-05,
      "loss": 0.0027,
      "step": 18660
    },
    {
      "epoch": 1.593139346360611,
      "grad_norm": 0.9187576174736023,
      "learning_rate": 1.0171516340984725e-05,
      "loss": 0.0022,
      "step": 18670
    },
    {
      "epoch": 1.5939926614898883,
      "grad_norm": 0.798980712890625,
      "learning_rate": 1.0150183462752795e-05,
      "loss": 0.0029,
      "step": 18680
    },
    {
      "epoch": 1.5948459766191654,
      "grad_norm": 0.8492259383201599,
      "learning_rate": 1.0128850584520864e-05,
      "loss": 0.0021,
      "step": 18690
    },
    {
      "epoch": 1.5956992917484427,
      "grad_norm": 0.30187422037124634,
      "learning_rate": 1.0107517706288932e-05,
      "loss": 0.0022,
      "step": 18700
    },
    {
      "epoch": 1.59655260687772,
      "grad_norm": 0.41932040452957153,
      "learning_rate": 1.0086184828057002e-05,
      "loss": 0.0021,
      "step": 18710
    },
    {
      "epoch": 1.5974059220069972,
      "grad_norm": 0.4867362380027771,
      "learning_rate": 1.0064851949825071e-05,
      "loss": 0.0018,
      "step": 18720
    },
    {
      "epoch": 1.5982592371362743,
      "grad_norm": 0.26734116673469543,
      "learning_rate": 1.0043519071593139e-05,
      "loss": 0.0025,
      "step": 18730
    },
    {
      "epoch": 1.5991125522655518,
      "grad_norm": 0.29744088649749756,
      "learning_rate": 1.0022186193361208e-05,
      "loss": 0.0022,
      "step": 18740
    },
    {
      "epoch": 1.599965867394829,
      "grad_norm": 0.3888024389743805,
      "learning_rate": 1.0000853315129278e-05,
      "loss": 0.0022,
      "step": 18750
    },
    {
      "epoch": 1.600819182524106,
      "grad_norm": 0.30033615231513977,
      "learning_rate": 9.979520436897346e-06,
      "loss": 0.0023,
      "step": 18760
    },
    {
      "epoch": 1.6016724976533834,
      "grad_norm": 0.6371391415596008,
      "learning_rate": 9.958187558665415e-06,
      "loss": 0.0022,
      "step": 18770
    },
    {
      "epoch": 1.6025258127826607,
      "grad_norm": 0.25944414734840393,
      "learning_rate": 9.936854680433485e-06,
      "loss": 0.0021,
      "step": 18780
    },
    {
      "epoch": 1.6033791279119378,
      "grad_norm": 0.352565735578537,
      "learning_rate": 9.915521802201554e-06,
      "loss": 0.0021,
      "step": 18790
    },
    {
      "epoch": 1.6042324430412152,
      "grad_norm": 0.612640917301178,
      "learning_rate": 9.894188923969624e-06,
      "loss": 0.0022,
      "step": 18800
    },
    {
      "epoch": 1.6050857581704925,
      "grad_norm": 0.47493332624435425,
      "learning_rate": 9.872856045737692e-06,
      "loss": 0.0019,
      "step": 18810
    },
    {
      "epoch": 1.6059390732997696,
      "grad_norm": 0.7874327898025513,
      "learning_rate": 9.851523167505761e-06,
      "loss": 0.0021,
      "step": 18820
    },
    {
      "epoch": 1.6067923884290467,
      "grad_norm": 0.5195109248161316,
      "learning_rate": 9.830190289273829e-06,
      "loss": 0.0023,
      "step": 18830
    },
    {
      "epoch": 1.607645703558324,
      "grad_norm": 0.43259045481681824,
      "learning_rate": 9.808857411041898e-06,
      "loss": 0.0026,
      "step": 18840
    },
    {
      "epoch": 1.6084990186876014,
      "grad_norm": 0.3101101517677307,
      "learning_rate": 9.787524532809968e-06,
      "loss": 0.002,
      "step": 18850
    },
    {
      "epoch": 1.6093523338168785,
      "grad_norm": 0.628308892250061,
      "learning_rate": 9.766191654578036e-06,
      "loss": 0.0019,
      "step": 18860
    },
    {
      "epoch": 1.6102056489461558,
      "grad_norm": 0.6276026368141174,
      "learning_rate": 9.744858776346105e-06,
      "loss": 0.0028,
      "step": 18870
    },
    {
      "epoch": 1.6110589640754331,
      "grad_norm": 0.4406374394893646,
      "learning_rate": 9.723525898114175e-06,
      "loss": 0.003,
      "step": 18880
    },
    {
      "epoch": 1.6119122792047103,
      "grad_norm": 0.7329137325286865,
      "learning_rate": 9.702193019882243e-06,
      "loss": 0.0023,
      "step": 18890
    },
    {
      "epoch": 1.6127655943339876,
      "grad_norm": 0.5255278944969177,
      "learning_rate": 9.680860141650312e-06,
      "loss": 0.002,
      "step": 18900
    },
    {
      "epoch": 1.613618909463265,
      "grad_norm": 0.27597394585609436,
      "learning_rate": 9.65952726341838e-06,
      "loss": 0.0021,
      "step": 18910
    },
    {
      "epoch": 1.614472224592542,
      "grad_norm": 0.4911248981952667,
      "learning_rate": 9.63819438518645e-06,
      "loss": 0.0028,
      "step": 18920
    },
    {
      "epoch": 1.6153255397218191,
      "grad_norm": 0.5007247924804688,
      "learning_rate": 9.616861506954519e-06,
      "loss": 0.0027,
      "step": 18930
    },
    {
      "epoch": 1.6161788548510965,
      "grad_norm": 0.2980450391769409,
      "learning_rate": 9.595528628722587e-06,
      "loss": 0.0024,
      "step": 18940
    },
    {
      "epoch": 1.6170321699803738,
      "grad_norm": 0.44060075283050537,
      "learning_rate": 9.574195750490656e-06,
      "loss": 0.0023,
      "step": 18950
    },
    {
      "epoch": 1.617885485109651,
      "grad_norm": 0.44115251302719116,
      "learning_rate": 9.552862872258726e-06,
      "loss": 0.0022,
      "step": 18960
    },
    {
      "epoch": 1.6187388002389282,
      "grad_norm": 0.5054399371147156,
      "learning_rate": 9.531529994026794e-06,
      "loss": 0.0026,
      "step": 18970
    },
    {
      "epoch": 1.6195921153682056,
      "grad_norm": 0.8631272315979004,
      "learning_rate": 9.510197115794863e-06,
      "loss": 0.0026,
      "step": 18980
    },
    {
      "epoch": 1.6204454304974827,
      "grad_norm": 0.6617306470870972,
      "learning_rate": 9.488864237562933e-06,
      "loss": 0.0023,
      "step": 18990
    },
    {
      "epoch": 1.6212987456267598,
      "grad_norm": 0.7631773352622986,
      "learning_rate": 9.467531359331002e-06,
      "loss": 0.0022,
      "step": 19000
    },
    {
      "epoch": 1.6221520607560374,
      "grad_norm": 0.4954945147037506,
      "learning_rate": 9.446198481099072e-06,
      "loss": 0.0016,
      "step": 19010
    },
    {
      "epoch": 1.6230053758853145,
      "grad_norm": 0.6767421960830688,
      "learning_rate": 9.42486560286714e-06,
      "loss": 0.0023,
      "step": 19020
    },
    {
      "epoch": 1.6238586910145916,
      "grad_norm": 0.46757346391677856,
      "learning_rate": 9.403532724635209e-06,
      "loss": 0.0022,
      "step": 19030
    },
    {
      "epoch": 1.624712006143869,
      "grad_norm": 0.6200387477874756,
      "learning_rate": 9.382199846403279e-06,
      "loss": 0.0026,
      "step": 19040
    },
    {
      "epoch": 1.6255653212731462,
      "grad_norm": 0.5250484943389893,
      "learning_rate": 9.360866968171346e-06,
      "loss": 0.0018,
      "step": 19050
    },
    {
      "epoch": 1.6264186364024233,
      "grad_norm": 0.5437905788421631,
      "learning_rate": 9.339534089939416e-06,
      "loss": 0.0027,
      "step": 19060
    },
    {
      "epoch": 1.6272719515317007,
      "grad_norm": 0.5507025718688965,
      "learning_rate": 9.318201211707484e-06,
      "loss": 0.0027,
      "step": 19070
    },
    {
      "epoch": 1.628125266660978,
      "grad_norm": 0.2776810824871063,
      "learning_rate": 9.296868333475553e-06,
      "loss": 0.0028,
      "step": 19080
    },
    {
      "epoch": 1.6289785817902551,
      "grad_norm": 0.9863263368606567,
      "learning_rate": 9.275535455243623e-06,
      "loss": 0.0024,
      "step": 19090
    },
    {
      "epoch": 1.6298318969195322,
      "grad_norm": 0.32240602374076843,
      "learning_rate": 9.25420257701169e-06,
      "loss": 0.0029,
      "step": 19100
    },
    {
      "epoch": 1.6306852120488098,
      "grad_norm": 0.536457896232605,
      "learning_rate": 9.23286969877976e-06,
      "loss": 0.0023,
      "step": 19110
    },
    {
      "epoch": 1.631538527178087,
      "grad_norm": 0.5258121490478516,
      "learning_rate": 9.211536820547828e-06,
      "loss": 0.0018,
      "step": 19120
    },
    {
      "epoch": 1.632391842307364,
      "grad_norm": 0.4899722635746002,
      "learning_rate": 9.190203942315897e-06,
      "loss": 0.0022,
      "step": 19130
    },
    {
      "epoch": 1.6332451574366413,
      "grad_norm": 0.3609989285469055,
      "learning_rate": 9.168871064083967e-06,
      "loss": 0.0022,
      "step": 19140
    },
    {
      "epoch": 1.6340984725659187,
      "grad_norm": 0.7481429576873779,
      "learning_rate": 9.147538185852035e-06,
      "loss": 0.002,
      "step": 19150
    },
    {
      "epoch": 1.6349517876951958,
      "grad_norm": 0.6244051456451416,
      "learning_rate": 9.126205307620104e-06,
      "loss": 0.0026,
      "step": 19160
    },
    {
      "epoch": 1.6358051028244731,
      "grad_norm": 0.3635586202144623,
      "learning_rate": 9.104872429388174e-06,
      "loss": 0.0025,
      "step": 19170
    },
    {
      "epoch": 1.6366584179537504,
      "grad_norm": 0.6045947670936584,
      "learning_rate": 9.083539551156242e-06,
      "loss": 0.0025,
      "step": 19180
    },
    {
      "epoch": 1.6375117330830276,
      "grad_norm": 0.503399670124054,
      "learning_rate": 9.062206672924311e-06,
      "loss": 0.0025,
      "step": 19190
    },
    {
      "epoch": 1.6383650482123047,
      "grad_norm": 0.4935946762561798,
      "learning_rate": 9.040873794692379e-06,
      "loss": 0.0023,
      "step": 19200
    },
    {
      "epoch": 1.639218363341582,
      "grad_norm": 0.2783045470714569,
      "learning_rate": 9.019540916460448e-06,
      "loss": 0.0024,
      "step": 19210
    },
    {
      "epoch": 1.6400716784708593,
      "grad_norm": 0.4560088813304901,
      "learning_rate": 8.998208038228518e-06,
      "loss": 0.0022,
      "step": 19220
    },
    {
      "epoch": 1.6409249936001364,
      "grad_norm": 0.5173938870429993,
      "learning_rate": 8.976875159996587e-06,
      "loss": 0.0028,
      "step": 19230
    },
    {
      "epoch": 1.6417783087294138,
      "grad_norm": 0.6025161147117615,
      "learning_rate": 8.955542281764657e-06,
      "loss": 0.0022,
      "step": 19240
    },
    {
      "epoch": 1.642631623858691,
      "grad_norm": 0.6557130217552185,
      "learning_rate": 8.934209403532726e-06,
      "loss": 0.0024,
      "step": 19250
    },
    {
      "epoch": 1.6434849389879682,
      "grad_norm": 0.36816149950027466,
      "learning_rate": 8.912876525300794e-06,
      "loss": 0.0023,
      "step": 19260
    },
    {
      "epoch": 1.6443382541172455,
      "grad_norm": 0.7272000312805176,
      "learning_rate": 8.891543647068864e-06,
      "loss": 0.0028,
      "step": 19270
    },
    {
      "epoch": 1.6451915692465229,
      "grad_norm": 0.7095859050750732,
      "learning_rate": 8.870210768836932e-06,
      "loss": 0.002,
      "step": 19280
    },
    {
      "epoch": 1.6460448843758,
      "grad_norm": 0.7667022943496704,
      "learning_rate": 8.848877890605001e-06,
      "loss": 0.0021,
      "step": 19290
    },
    {
      "epoch": 1.646898199505077,
      "grad_norm": 0.6522536277770996,
      "learning_rate": 8.82754501237307e-06,
      "loss": 0.0028,
      "step": 19300
    },
    {
      "epoch": 1.6477515146343544,
      "grad_norm": 0.3302496671676636,
      "learning_rate": 8.806212134141138e-06,
      "loss": 0.0026,
      "step": 19310
    },
    {
      "epoch": 1.6486048297636318,
      "grad_norm": 0.7295628786087036,
      "learning_rate": 8.784879255909208e-06,
      "loss": 0.0024,
      "step": 19320
    },
    {
      "epoch": 1.6494581448929089,
      "grad_norm": 0.33176061511039734,
      "learning_rate": 8.763546377677277e-06,
      "loss": 0.0025,
      "step": 19330
    },
    {
      "epoch": 1.6503114600221862,
      "grad_norm": 0.4328727424144745,
      "learning_rate": 8.742213499445345e-06,
      "loss": 0.0029,
      "step": 19340
    },
    {
      "epoch": 1.6511647751514635,
      "grad_norm": 0.5692546367645264,
      "learning_rate": 8.720880621213415e-06,
      "loss": 0.0024,
      "step": 19350
    },
    {
      "epoch": 1.6520180902807406,
      "grad_norm": 0.4040728509426117,
      "learning_rate": 8.699547742981483e-06,
      "loss": 0.0022,
      "step": 19360
    },
    {
      "epoch": 1.6528714054100178,
      "grad_norm": 0.6310096979141235,
      "learning_rate": 8.678214864749552e-06,
      "loss": 0.0022,
      "step": 19370
    },
    {
      "epoch": 1.6537247205392953,
      "grad_norm": 0.6593437790870667,
      "learning_rate": 8.656881986517622e-06,
      "loss": 0.0024,
      "step": 19380
    },
    {
      "epoch": 1.6545780356685724,
      "grad_norm": 0.7720935344696045,
      "learning_rate": 8.63554910828569e-06,
      "loss": 0.0024,
      "step": 19390
    },
    {
      "epoch": 1.6554313507978495,
      "grad_norm": 1.0030981302261353,
      "learning_rate": 8.614216230053759e-06,
      "loss": 0.0023,
      "step": 19400
    },
    {
      "epoch": 1.6562846659271269,
      "grad_norm": 0.4566360414028168,
      "learning_rate": 8.592883351821828e-06,
      "loss": 0.0027,
      "step": 19410
    },
    {
      "epoch": 1.6571379810564042,
      "grad_norm": 0.33027157187461853,
      "learning_rate": 8.571550473589896e-06,
      "loss": 0.0024,
      "step": 19420
    },
    {
      "epoch": 1.6579912961856813,
      "grad_norm": 0.2539351284503937,
      "learning_rate": 8.550217595357966e-06,
      "loss": 0.0024,
      "step": 19430
    },
    {
      "epoch": 1.6588446113149586,
      "grad_norm": 0.5220177173614502,
      "learning_rate": 8.528884717126035e-06,
      "loss": 0.0027,
      "step": 19440
    },
    {
      "epoch": 1.659697926444236,
      "grad_norm": 0.6353367567062378,
      "learning_rate": 8.507551838894103e-06,
      "loss": 0.0024,
      "step": 19450
    },
    {
      "epoch": 1.660551241573513,
      "grad_norm": 0.43748363852500916,
      "learning_rate": 8.486218960662173e-06,
      "loss": 0.0027,
      "step": 19460
    },
    {
      "epoch": 1.6614045567027902,
      "grad_norm": 0.23591946065425873,
      "learning_rate": 8.464886082430242e-06,
      "loss": 0.0025,
      "step": 19470
    },
    {
      "epoch": 1.6622578718320677,
      "grad_norm": 0.43827587366104126,
      "learning_rate": 8.443553204198312e-06,
      "loss": 0.0024,
      "step": 19480
    },
    {
      "epoch": 1.6631111869613449,
      "grad_norm": 0.28500473499298096,
      "learning_rate": 8.422220325966381e-06,
      "loss": 0.002,
      "step": 19490
    },
    {
      "epoch": 1.663964502090622,
      "grad_norm": 0.5839772820472717,
      "learning_rate": 8.400887447734449e-06,
      "loss": 0.0026,
      "step": 19500
    },
    {
      "epoch": 1.6648178172198993,
      "grad_norm": 0.7244295477867126,
      "learning_rate": 8.379554569502518e-06,
      "loss": 0.0021,
      "step": 19510
    },
    {
      "epoch": 1.6656711323491766,
      "grad_norm": 0.3326892554759979,
      "learning_rate": 8.358221691270586e-06,
      "loss": 0.0029,
      "step": 19520
    },
    {
      "epoch": 1.6665244474784537,
      "grad_norm": 0.5146840214729309,
      "learning_rate": 8.336888813038656e-06,
      "loss": 0.0028,
      "step": 19530
    },
    {
      "epoch": 1.667377762607731,
      "grad_norm": 0.9262595772743225,
      "learning_rate": 8.315555934806725e-06,
      "loss": 0.0021,
      "step": 19540
    },
    {
      "epoch": 1.6682310777370084,
      "grad_norm": 0.61662757396698,
      "learning_rate": 8.294223056574793e-06,
      "loss": 0.0032,
      "step": 19550
    },
    {
      "epoch": 1.6690843928662855,
      "grad_norm": 0.3562365472316742,
      "learning_rate": 8.272890178342863e-06,
      "loss": 0.0023,
      "step": 19560
    },
    {
      "epoch": 1.6699377079955626,
      "grad_norm": 0.7604597806930542,
      "learning_rate": 8.251557300110932e-06,
      "loss": 0.0028,
      "step": 19570
    },
    {
      "epoch": 1.67079102312484,
      "grad_norm": 0.387268990278244,
      "learning_rate": 8.230224421879e-06,
      "loss": 0.0026,
      "step": 19580
    },
    {
      "epoch": 1.6716443382541173,
      "grad_norm": 0.46101275086402893,
      "learning_rate": 8.20889154364707e-06,
      "loss": 0.0021,
      "step": 19590
    },
    {
      "epoch": 1.6724976533833944,
      "grad_norm": 0.635258674621582,
      "learning_rate": 8.187558665415137e-06,
      "loss": 0.0025,
      "step": 19600
    },
    {
      "epoch": 1.6733509685126717,
      "grad_norm": 0.48222315311431885,
      "learning_rate": 8.166225787183207e-06,
      "loss": 0.0027,
      "step": 19610
    },
    {
      "epoch": 1.674204283641949,
      "grad_norm": 0.2858859896659851,
      "learning_rate": 8.144892908951276e-06,
      "loss": 0.0026,
      "step": 19620
    },
    {
      "epoch": 1.6750575987712262,
      "grad_norm": 0.43885812163352966,
      "learning_rate": 8.123560030719344e-06,
      "loss": 0.0024,
      "step": 19630
    },
    {
      "epoch": 1.6759109139005035,
      "grad_norm": 0.9643447399139404,
      "learning_rate": 8.102227152487414e-06,
      "loss": 0.0025,
      "step": 19640
    },
    {
      "epoch": 1.6767642290297808,
      "grad_norm": 0.4536602199077606,
      "learning_rate": 8.080894274255483e-06,
      "loss": 0.0032,
      "step": 19650
    },
    {
      "epoch": 1.677617544159058,
      "grad_norm": 0.40561625361442566,
      "learning_rate": 8.059561396023551e-06,
      "loss": 0.0021,
      "step": 19660
    },
    {
      "epoch": 1.678470859288335,
      "grad_norm": 1.255752682685852,
      "learning_rate": 8.03822851779162e-06,
      "loss": 0.0024,
      "step": 19670
    },
    {
      "epoch": 1.6793241744176124,
      "grad_norm": 0.4535282552242279,
      "learning_rate": 8.01689563955969e-06,
      "loss": 0.002,
      "step": 19680
    },
    {
      "epoch": 1.6801774895468897,
      "grad_norm": 0.4790630340576172,
      "learning_rate": 7.99556276132776e-06,
      "loss": 0.0027,
      "step": 19690
    },
    {
      "epoch": 1.6810308046761668,
      "grad_norm": 0.4527166485786438,
      "learning_rate": 7.974229883095829e-06,
      "loss": 0.0025,
      "step": 19700
    },
    {
      "epoch": 1.6818841198054442,
      "grad_norm": 0.6731680631637573,
      "learning_rate": 7.952897004863897e-06,
      "loss": 0.0021,
      "step": 19710
    },
    {
      "epoch": 1.6827374349347215,
      "grad_norm": 0.3593416213989258,
      "learning_rate": 7.931564126631966e-06,
      "loss": 0.002,
      "step": 19720
    },
    {
      "epoch": 1.6835907500639986,
      "grad_norm": 0.44097375869750977,
      "learning_rate": 7.910231248400036e-06,
      "loss": 0.002,
      "step": 19730
    },
    {
      "epoch": 1.6844440651932757,
      "grad_norm": 0.5230991244316101,
      "learning_rate": 7.888898370168104e-06,
      "loss": 0.0025,
      "step": 19740
    },
    {
      "epoch": 1.6852973803225533,
      "grad_norm": 0.49535393714904785,
      "learning_rate": 7.867565491936173e-06,
      "loss": 0.0024,
      "step": 19750
    },
    {
      "epoch": 1.6861506954518304,
      "grad_norm": 0.3525557816028595,
      "learning_rate": 7.846232613704241e-06,
      "loss": 0.0019,
      "step": 19760
    },
    {
      "epoch": 1.6870040105811075,
      "grad_norm": 0.5465268492698669,
      "learning_rate": 7.82489973547231e-06,
      "loss": 0.002,
      "step": 19770
    },
    {
      "epoch": 1.6878573257103848,
      "grad_norm": 0.41420724987983704,
      "learning_rate": 7.80356685724038e-06,
      "loss": 0.0021,
      "step": 19780
    },
    {
      "epoch": 1.6887106408396622,
      "grad_norm": 0.7081345319747925,
      "learning_rate": 7.782233979008448e-06,
      "loss": 0.003,
      "step": 19790
    },
    {
      "epoch": 1.6895639559689393,
      "grad_norm": 0.7857732176780701,
      "learning_rate": 7.760901100776517e-06,
      "loss": 0.0021,
      "step": 19800
    },
    {
      "epoch": 1.6904172710982166,
      "grad_norm": 0.6197171807289124,
      "learning_rate": 7.739568222544587e-06,
      "loss": 0.0017,
      "step": 19810
    },
    {
      "epoch": 1.691270586227494,
      "grad_norm": 0.3886902332305908,
      "learning_rate": 7.718235344312655e-06,
      "loss": 0.0022,
      "step": 19820
    },
    {
      "epoch": 1.692123901356771,
      "grad_norm": 0.3739345967769623,
      "learning_rate": 7.696902466080724e-06,
      "loss": 0.0023,
      "step": 19830
    },
    {
      "epoch": 1.6929772164860482,
      "grad_norm": 0.4725199043750763,
      "learning_rate": 7.675569587848792e-06,
      "loss": 0.0027,
      "step": 19840
    },
    {
      "epoch": 1.6938305316153255,
      "grad_norm": 0.4223363995552063,
      "learning_rate": 7.654236709616861e-06,
      "loss": 0.0021,
      "step": 19850
    },
    {
      "epoch": 1.6946838467446028,
      "grad_norm": 0.43644335865974426,
      "learning_rate": 7.632903831384931e-06,
      "loss": 0.0022,
      "step": 19860
    },
    {
      "epoch": 1.69553716187388,
      "grad_norm": 0.8603776097297668,
      "learning_rate": 7.611570953153e-06,
      "loss": 0.0024,
      "step": 19870
    },
    {
      "epoch": 1.6963904770031573,
      "grad_norm": 0.3204793930053711,
      "learning_rate": 7.590238074921069e-06,
      "loss": 0.0026,
      "step": 19880
    },
    {
      "epoch": 1.6972437921324346,
      "grad_norm": 0.6010606288909912,
      "learning_rate": 7.568905196689139e-06,
      "loss": 0.0023,
      "step": 19890
    },
    {
      "epoch": 1.6980971072617117,
      "grad_norm": 0.3352406919002533,
      "learning_rate": 7.5475723184572065e-06,
      "loss": 0.0026,
      "step": 19900
    },
    {
      "epoch": 1.698950422390989,
      "grad_norm": 0.4051693379878998,
      "learning_rate": 7.526239440225276e-06,
      "loss": 0.0026,
      "step": 19910
    },
    {
      "epoch": 1.6998037375202664,
      "grad_norm": 0.6203566789627075,
      "learning_rate": 7.504906561993344e-06,
      "loss": 0.0021,
      "step": 19920
    },
    {
      "epoch": 1.7006570526495435,
      "grad_norm": 0.2869616746902466,
      "learning_rate": 7.483573683761413e-06,
      "loss": 0.0027,
      "step": 19930
    },
    {
      "epoch": 1.7015103677788206,
      "grad_norm": 0.2362995594739914,
      "learning_rate": 7.462240805529483e-06,
      "loss": 0.0025,
      "step": 19940
    },
    {
      "epoch": 1.702363682908098,
      "grad_norm": 0.4504574239253998,
      "learning_rate": 7.440907927297551e-06,
      "loss": 0.0022,
      "step": 19950
    },
    {
      "epoch": 1.7032169980373753,
      "grad_norm": 0.2831743359565735,
      "learning_rate": 7.41957504906562e-06,
      "loss": 0.0025,
      "step": 19960
    },
    {
      "epoch": 1.7040703131666524,
      "grad_norm": 0.41093653440475464,
      "learning_rate": 7.39824217083369e-06,
      "loss": 0.0024,
      "step": 19970
    },
    {
      "epoch": 1.7049236282959297,
      "grad_norm": 0.9798907041549683,
      "learning_rate": 7.376909292601758e-06,
      "loss": 0.0025,
      "step": 19980
    },
    {
      "epoch": 1.705776943425207,
      "grad_norm": 0.6204548478126526,
      "learning_rate": 7.355576414369828e-06,
      "loss": 0.0021,
      "step": 19990
    },
    {
      "epoch": 1.7066302585544841,
      "grad_norm": 0.5853431820869446,
      "learning_rate": 7.334243536137896e-06,
      "loss": 0.0026,
      "step": 20000
    },
    {
      "epoch": 1.7074835736837615,
      "grad_norm": 1.005110502243042,
      "learning_rate": 7.312910657905965e-06,
      "loss": 0.0025,
      "step": 20010
    },
    {
      "epoch": 1.7083368888130388,
      "grad_norm": 0.22828789055347443,
      "learning_rate": 7.291577779674035e-06,
      "loss": 0.0022,
      "step": 20020
    },
    {
      "epoch": 1.709190203942316,
      "grad_norm": 0.36603978276252747,
      "learning_rate": 7.2702449014421025e-06,
      "loss": 0.0027,
      "step": 20030
    },
    {
      "epoch": 1.710043519071593,
      "grad_norm": 0.2937096953392029,
      "learning_rate": 7.248912023210172e-06,
      "loss": 0.0023,
      "step": 20040
    },
    {
      "epoch": 1.7108968342008704,
      "grad_norm": 0.6562047004699707,
      "learning_rate": 7.22757914497824e-06,
      "loss": 0.0024,
      "step": 20050
    },
    {
      "epoch": 1.7117501493301477,
      "grad_norm": 0.5529852509498596,
      "learning_rate": 7.206246266746309e-06,
      "loss": 0.0021,
      "step": 20060
    },
    {
      "epoch": 1.7126034644594248,
      "grad_norm": 0.30457860231399536,
      "learning_rate": 7.184913388514379e-06,
      "loss": 0.0019,
      "step": 20070
    },
    {
      "epoch": 1.7134567795887021,
      "grad_norm": 0.3547450602054596,
      "learning_rate": 7.1635805102824475e-06,
      "loss": 0.0023,
      "step": 20080
    },
    {
      "epoch": 1.7143100947179795,
      "grad_norm": 0.9192308783531189,
      "learning_rate": 7.142247632050517e-06,
      "loss": 0.0028,
      "step": 20090
    },
    {
      "epoch": 1.7151634098472566,
      "grad_norm": 0.24923047423362732,
      "learning_rate": 7.120914753818586e-06,
      "loss": 0.0022,
      "step": 20100
    },
    {
      "epoch": 1.7160167249765337,
      "grad_norm": 0.3410167098045349,
      "learning_rate": 7.099581875586654e-06,
      "loss": 0.0024,
      "step": 20110
    },
    {
      "epoch": 1.7168700401058112,
      "grad_norm": 0.9591064453125,
      "learning_rate": 7.078248997354724e-06,
      "loss": 0.0024,
      "step": 20120
    },
    {
      "epoch": 1.7177233552350883,
      "grad_norm": 0.2173469066619873,
      "learning_rate": 7.056916119122792e-06,
      "loss": 0.0022,
      "step": 20130
    },
    {
      "epoch": 1.7185766703643655,
      "grad_norm": 0.9491832852363586,
      "learning_rate": 7.035583240890861e-06,
      "loss": 0.0021,
      "step": 20140
    },
    {
      "epoch": 1.7194299854936428,
      "grad_norm": 0.5714751482009888,
      "learning_rate": 7.014250362658931e-06,
      "loss": 0.0027,
      "step": 20150
    },
    {
      "epoch": 1.7202833006229201,
      "grad_norm": 0.5163178443908691,
      "learning_rate": 6.9929174844269985e-06,
      "loss": 0.0024,
      "step": 20160
    },
    {
      "epoch": 1.7211366157521972,
      "grad_norm": 0.545289158821106,
      "learning_rate": 6.971584606195068e-06,
      "loss": 0.002,
      "step": 20170
    },
    {
      "epoch": 1.7219899308814746,
      "grad_norm": 0.7318872809410095,
      "learning_rate": 6.9502517279631375e-06,
      "loss": 0.0026,
      "step": 20180
    },
    {
      "epoch": 1.722843246010752,
      "grad_norm": 0.5856772065162659,
      "learning_rate": 6.928918849731205e-06,
      "loss": 0.0023,
      "step": 20190
    },
    {
      "epoch": 1.723696561140029,
      "grad_norm": 0.4206734299659729,
      "learning_rate": 6.907585971499275e-06,
      "loss": 0.0034,
      "step": 20200
    },
    {
      "epoch": 1.7245498762693061,
      "grad_norm": 0.476898193359375,
      "learning_rate": 6.8862530932673435e-06,
      "loss": 0.002,
      "step": 20210
    },
    {
      "epoch": 1.7254031913985834,
      "grad_norm": 0.46521472930908203,
      "learning_rate": 6.864920215035413e-06,
      "loss": 0.0026,
      "step": 20220
    },
    {
      "epoch": 1.7262565065278608,
      "grad_norm": 0.4566769599914551,
      "learning_rate": 6.8435873368034826e-06,
      "loss": 0.0027,
      "step": 20230
    },
    {
      "epoch": 1.727109821657138,
      "grad_norm": 0.3261640965938568,
      "learning_rate": 6.82225445857155e-06,
      "loss": 0.0024,
      "step": 20240
    },
    {
      "epoch": 1.7279631367864152,
      "grad_norm": 0.46588778495788574,
      "learning_rate": 6.80092158033962e-06,
      "loss": 0.0023,
      "step": 20250
    },
    {
      "epoch": 1.7288164519156926,
      "grad_norm": 0.713758647441864,
      "learning_rate": 6.779588702107689e-06,
      "loss": 0.0025,
      "step": 20260
    },
    {
      "epoch": 1.7296697670449697,
      "grad_norm": 0.45305299758911133,
      "learning_rate": 6.758255823875757e-06,
      "loss": 0.0028,
      "step": 20270
    },
    {
      "epoch": 1.730523082174247,
      "grad_norm": 0.33114752173423767,
      "learning_rate": 6.736922945643827e-06,
      "loss": 0.0026,
      "step": 20280
    },
    {
      "epoch": 1.7313763973035243,
      "grad_norm": 0.45344603061676025,
      "learning_rate": 6.7155900674118945e-06,
      "loss": 0.0023,
      "step": 20290
    },
    {
      "epoch": 1.7322297124328014,
      "grad_norm": 0.4590517580509186,
      "learning_rate": 6.694257189179964e-06,
      "loss": 0.0028,
      "step": 20300
    },
    {
      "epoch": 1.7330830275620785,
      "grad_norm": 0.7027926445007324,
      "learning_rate": 6.6729243109480336e-06,
      "loss": 0.0023,
      "step": 20310
    },
    {
      "epoch": 1.7339363426913559,
      "grad_norm": 0.689770519733429,
      "learning_rate": 6.651591432716102e-06,
      "loss": 0.0026,
      "step": 20320
    },
    {
      "epoch": 1.7347896578206332,
      "grad_norm": 0.47332140803337097,
      "learning_rate": 6.630258554484172e-06,
      "loss": 0.0024,
      "step": 20330
    },
    {
      "epoch": 1.7356429729499103,
      "grad_norm": 1.0407761335372925,
      "learning_rate": 6.608925676252241e-06,
      "loss": 0.0024,
      "step": 20340
    },
    {
      "epoch": 1.7364962880791877,
      "grad_norm": 0.30919864773750305,
      "learning_rate": 6.587592798020309e-06,
      "loss": 0.0024,
      "step": 20350
    },
    {
      "epoch": 1.737349603208465,
      "grad_norm": 0.5403284430503845,
      "learning_rate": 6.5662599197883786e-06,
      "loss": 0.0022,
      "step": 20360
    },
    {
      "epoch": 1.738202918337742,
      "grad_norm": 0.2781966030597687,
      "learning_rate": 6.544927041556446e-06,
      "loss": 0.0027,
      "step": 20370
    },
    {
      "epoch": 1.7390562334670192,
      "grad_norm": 0.28127530217170715,
      "learning_rate": 6.523594163324516e-06,
      "loss": 0.0024,
      "step": 20380
    },
    {
      "epoch": 1.7399095485962968,
      "grad_norm": 0.32108187675476074,
      "learning_rate": 6.502261285092585e-06,
      "loss": 0.002,
      "step": 20390
    },
    {
      "epoch": 1.7407628637255739,
      "grad_norm": 0.22992171347141266,
      "learning_rate": 6.480928406860653e-06,
      "loss": 0.0022,
      "step": 20400
    },
    {
      "epoch": 1.741616178854851,
      "grad_norm": 0.764977753162384,
      "learning_rate": 6.459595528628723e-06,
      "loss": 0.0024,
      "step": 20410
    },
    {
      "epoch": 1.7424694939841283,
      "grad_norm": 0.3950660526752472,
      "learning_rate": 6.438262650396792e-06,
      "loss": 0.0026,
      "step": 20420
    },
    {
      "epoch": 1.7433228091134056,
      "grad_norm": 0.4311181306838989,
      "learning_rate": 6.416929772164861e-06,
      "loss": 0.0023,
      "step": 20430
    },
    {
      "epoch": 1.7441761242426828,
      "grad_norm": 0.3699403405189514,
      "learning_rate": 6.3955968939329296e-06,
      "loss": 0.0021,
      "step": 20440
    },
    {
      "epoch": 1.74502943937196,
      "grad_norm": 0.3354971706867218,
      "learning_rate": 6.374264015700998e-06,
      "loss": 0.002,
      "step": 20450
    },
    {
      "epoch": 1.7458827545012374,
      "grad_norm": 0.37225744128227234,
      "learning_rate": 6.352931137469068e-06,
      "loss": 0.0027,
      "step": 20460
    },
    {
      "epoch": 1.7467360696305145,
      "grad_norm": 0.5066323280334473,
      "learning_rate": 6.331598259237137e-06,
      "loss": 0.002,
      "step": 20470
    },
    {
      "epoch": 1.7475893847597916,
      "grad_norm": 0.5521654486656189,
      "learning_rate": 6.310265381005205e-06,
      "loss": 0.0023,
      "step": 20480
    },
    {
      "epoch": 1.7484426998890692,
      "grad_norm": 0.5061711668968201,
      "learning_rate": 6.288932502773275e-06,
      "loss": 0.0026,
      "step": 20490
    },
    {
      "epoch": 1.7492960150183463,
      "grad_norm": 0.5133992433547974,
      "learning_rate": 6.267599624541344e-06,
      "loss": 0.0029,
      "step": 20500
    },
    {
      "epoch": 1.7501493301476234,
      "grad_norm": 0.3036990463733673,
      "learning_rate": 6.246266746309412e-06,
      "loss": 0.0018,
      "step": 20510
    },
    {
      "epoch": 1.7510026452769007,
      "grad_norm": 0.3227674067020416,
      "learning_rate": 6.2249338680774814e-06,
      "loss": 0.002,
      "step": 20520
    },
    {
      "epoch": 1.751855960406178,
      "grad_norm": 0.487140953540802,
      "learning_rate": 6.20360098984555e-06,
      "loss": 0.0021,
      "step": 20530
    },
    {
      "epoch": 1.7527092755354552,
      "grad_norm": 0.3328464925289154,
      "learning_rate": 6.182268111613619e-06,
      "loss": 0.0022,
      "step": 20540
    },
    {
      "epoch": 1.7535625906647325,
      "grad_norm": 0.3573973476886749,
      "learning_rate": 6.160935233381688e-06,
      "loss": 0.003,
      "step": 20550
    },
    {
      "epoch": 1.7544159057940099,
      "grad_norm": 0.21951793134212494,
      "learning_rate": 6.139602355149758e-06,
      "loss": 0.0019,
      "step": 20560
    },
    {
      "epoch": 1.755269220923287,
      "grad_norm": 0.33789002895355225,
      "learning_rate": 6.1182694769178264e-06,
      "loss": 0.0024,
      "step": 20570
    },
    {
      "epoch": 1.756122536052564,
      "grad_norm": 0.7450705170631409,
      "learning_rate": 6.096936598685895e-06,
      "loss": 0.0021,
      "step": 20580
    },
    {
      "epoch": 1.7569758511818414,
      "grad_norm": 0.4554530680179596,
      "learning_rate": 6.075603720453964e-06,
      "loss": 0.0022,
      "step": 20590
    },
    {
      "epoch": 1.7578291663111187,
      "grad_norm": 0.7418405413627625,
      "learning_rate": 6.054270842222033e-06,
      "loss": 0.0018,
      "step": 20600
    },
    {
      "epoch": 1.7586824814403959,
      "grad_norm": 1.1302196979522705,
      "learning_rate": 6.032937963990102e-06,
      "loss": 0.0025,
      "step": 20610
    },
    {
      "epoch": 1.7595357965696732,
      "grad_norm": 0.39092621207237244,
      "learning_rate": 6.011605085758171e-06,
      "loss": 0.0021,
      "step": 20620
    },
    {
      "epoch": 1.7603891116989505,
      "grad_norm": 0.932314395904541,
      "learning_rate": 5.990272207526239e-06,
      "loss": 0.0023,
      "step": 20630
    },
    {
      "epoch": 1.7612424268282276,
      "grad_norm": 0.3747994601726532,
      "learning_rate": 5.968939329294309e-06,
      "loss": 0.0022,
      "step": 20640
    },
    {
      "epoch": 1.762095741957505,
      "grad_norm": 0.7849804162979126,
      "learning_rate": 5.9476064510623774e-06,
      "loss": 0.0022,
      "step": 20650
    },
    {
      "epoch": 1.7629490570867823,
      "grad_norm": 0.4652461111545563,
      "learning_rate": 5.926273572830446e-06,
      "loss": 0.0024,
      "step": 20660
    },
    {
      "epoch": 1.7638023722160594,
      "grad_norm": 0.2996911406517029,
      "learning_rate": 5.904940694598516e-06,
      "loss": 0.0019,
      "step": 20670
    },
    {
      "epoch": 1.7646556873453365,
      "grad_norm": 0.4056740999221802,
      "learning_rate": 5.883607816366585e-06,
      "loss": 0.0028,
      "step": 20680
    },
    {
      "epoch": 1.7655090024746138,
      "grad_norm": 0.34997421503067017,
      "learning_rate": 5.862274938134654e-06,
      "loss": 0.0021,
      "step": 20690
    },
    {
      "epoch": 1.7663623176038912,
      "grad_norm": 0.4936153292655945,
      "learning_rate": 5.8409420599027225e-06,
      "loss": 0.0023,
      "step": 20700
    },
    {
      "epoch": 1.7672156327331683,
      "grad_norm": 0.47972336411476135,
      "learning_rate": 5.819609181670791e-06,
      "loss": 0.0024,
      "step": 20710
    },
    {
      "epoch": 1.7680689478624456,
      "grad_norm": 0.3110755980014801,
      "learning_rate": 5.798276303438861e-06,
      "loss": 0.0026,
      "step": 20720
    },
    {
      "epoch": 1.768922262991723,
      "grad_norm": 0.3548352122306824,
      "learning_rate": 5.776943425206929e-06,
      "loss": 0.0016,
      "step": 20730
    },
    {
      "epoch": 1.769775578121,
      "grad_norm": 0.4061545729637146,
      "learning_rate": 5.755610546974998e-06,
      "loss": 0.0021,
      "step": 20740
    },
    {
      "epoch": 1.7706288932502772,
      "grad_norm": 0.746969997882843,
      "learning_rate": 5.734277668743067e-06,
      "loss": 0.003,
      "step": 20750
    },
    {
      "epoch": 1.7714822083795547,
      "grad_norm": 0.4711942970752716,
      "learning_rate": 5.712944790511136e-06,
      "loss": 0.0023,
      "step": 20760
    },
    {
      "epoch": 1.7723355235088318,
      "grad_norm": 0.6353955268859863,
      "learning_rate": 5.691611912279205e-06,
      "loss": 0.0031,
      "step": 20770
    },
    {
      "epoch": 1.773188838638109,
      "grad_norm": 0.3283804953098297,
      "learning_rate": 5.670279034047274e-06,
      "loss": 0.0022,
      "step": 20780
    },
    {
      "epoch": 1.7740421537673863,
      "grad_norm": 0.6181199550628662,
      "learning_rate": 5.648946155815343e-06,
      "loss": 0.0021,
      "step": 20790
    },
    {
      "epoch": 1.7748954688966636,
      "grad_norm": 0.9014390707015991,
      "learning_rate": 5.6276132775834125e-06,
      "loss": 0.0021,
      "step": 20800
    },
    {
      "epoch": 1.7757487840259407,
      "grad_norm": 0.3336348235607147,
      "learning_rate": 5.606280399351481e-06,
      "loss": 0.0026,
      "step": 20810
    },
    {
      "epoch": 1.776602099155218,
      "grad_norm": 0.44383105635643005,
      "learning_rate": 5.58494752111955e-06,
      "loss": 0.0027,
      "step": 20820
    },
    {
      "epoch": 1.7774554142844954,
      "grad_norm": 0.5383455157279968,
      "learning_rate": 5.5636146428876185e-06,
      "loss": 0.0022,
      "step": 20830
    },
    {
      "epoch": 1.7783087294137725,
      "grad_norm": 0.25782090425491333,
      "learning_rate": 5.542281764655688e-06,
      "loss": 0.002,
      "step": 20840
    },
    {
      "epoch": 1.7791620445430496,
      "grad_norm": 0.568520188331604,
      "learning_rate": 5.520948886423757e-06,
      "loss": 0.0023,
      "step": 20850
    },
    {
      "epoch": 1.780015359672327,
      "grad_norm": 0.3823254704475403,
      "learning_rate": 5.499616008191825e-06,
      "loss": 0.0021,
      "step": 20860
    },
    {
      "epoch": 1.7808686748016043,
      "grad_norm": 0.6752769947052002,
      "learning_rate": 5.478283129959894e-06,
      "loss": 0.0026,
      "step": 20870
    },
    {
      "epoch": 1.7817219899308814,
      "grad_norm": 0.3581295609474182,
      "learning_rate": 5.4569502517279635e-06,
      "loss": 0.002,
      "step": 20880
    },
    {
      "epoch": 1.7825753050601587,
      "grad_norm": 0.4638536274433136,
      "learning_rate": 5.435617373496032e-06,
      "loss": 0.0021,
      "step": 20890
    },
    {
      "epoch": 1.783428620189436,
      "grad_norm": 0.5410261154174805,
      "learning_rate": 5.414284495264102e-06,
      "loss": 0.0022,
      "step": 20900
    },
    {
      "epoch": 1.7842819353187132,
      "grad_norm": 0.4332806468009949,
      "learning_rate": 5.39295161703217e-06,
      "loss": 0.002,
      "step": 20910
    },
    {
      "epoch": 1.7851352504479905,
      "grad_norm": 0.6602604389190674,
      "learning_rate": 5.37161873880024e-06,
      "loss": 0.0026,
      "step": 20920
    },
    {
      "epoch": 1.7859885655772678,
      "grad_norm": 0.40412119030952454,
      "learning_rate": 5.3502858605683085e-06,
      "loss": 0.0021,
      "step": 20930
    },
    {
      "epoch": 1.786841880706545,
      "grad_norm": 0.291493684053421,
      "learning_rate": 5.328952982336377e-06,
      "loss": 0.0021,
      "step": 20940
    },
    {
      "epoch": 1.787695195835822,
      "grad_norm": 1.1070375442504883,
      "learning_rate": 5.307620104104446e-06,
      "loss": 0.0021,
      "step": 20950
    },
    {
      "epoch": 1.7885485109650994,
      "grad_norm": 0.3973150849342346,
      "learning_rate": 5.286287225872515e-06,
      "loss": 0.0027,
      "step": 20960
    },
    {
      "epoch": 1.7894018260943767,
      "grad_norm": 0.46149685978889465,
      "learning_rate": 5.264954347640584e-06,
      "loss": 0.0022,
      "step": 20970
    },
    {
      "epoch": 1.7902551412236538,
      "grad_norm": 0.7774399518966675,
      "learning_rate": 5.243621469408653e-06,
      "loss": 0.0025,
      "step": 20980
    },
    {
      "epoch": 1.7911084563529311,
      "grad_norm": 0.3224700689315796,
      "learning_rate": 5.222288591176721e-06,
      "loss": 0.003,
      "step": 20990
    },
    {
      "epoch": 1.7919617714822085,
      "grad_norm": 0.7156749367713928,
      "learning_rate": 5.200955712944791e-06,
      "loss": 0.0022,
      "step": 21000
    },
    {
      "epoch": 1.7928150866114856,
      "grad_norm": 0.7300676107406616,
      "learning_rate": 5.1796228347128595e-06,
      "loss": 0.002,
      "step": 21010
    },
    {
      "epoch": 1.793668401740763,
      "grad_norm": 0.5221664905548096,
      "learning_rate": 5.158289956480929e-06,
      "loss": 0.0023,
      "step": 21020
    },
    {
      "epoch": 1.7945217168700403,
      "grad_norm": 0.5306277275085449,
      "learning_rate": 5.136957078248998e-06,
      "loss": 0.0018,
      "step": 21030
    },
    {
      "epoch": 1.7953750319993174,
      "grad_norm": 0.4449136555194855,
      "learning_rate": 5.115624200017066e-06,
      "loss": 0.0024,
      "step": 21040
    },
    {
      "epoch": 1.7962283471285945,
      "grad_norm": 0.3714381158351898,
      "learning_rate": 5.094291321785136e-06,
      "loss": 0.0023,
      "step": 21050
    },
    {
      "epoch": 1.7970816622578718,
      "grad_norm": 0.4155972898006439,
      "learning_rate": 5.0729584435532045e-06,
      "loss": 0.0022,
      "step": 21060
    },
    {
      "epoch": 1.7979349773871491,
      "grad_norm": 0.6491264700889587,
      "learning_rate": 5.051625565321273e-06,
      "loss": 0.0022,
      "step": 21070
    },
    {
      "epoch": 1.7987882925164262,
      "grad_norm": 0.6028509140014648,
      "learning_rate": 5.030292687089342e-06,
      "loss": 0.0018,
      "step": 21080
    },
    {
      "epoch": 1.7996416076457036,
      "grad_norm": 0.827203094959259,
      "learning_rate": 5.008959808857411e-06,
      "loss": 0.002,
      "step": 21090
    },
    {
      "epoch": 1.800494922774981,
      "grad_norm": 0.6140664219856262,
      "learning_rate": 4.98762693062548e-06,
      "loss": 0.0025,
      "step": 21100
    },
    {
      "epoch": 1.801348237904258,
      "grad_norm": 0.9110571146011353,
      "learning_rate": 4.966294052393549e-06,
      "loss": 0.0023,
      "step": 21110
    },
    {
      "epoch": 1.8022015530335351,
      "grad_norm": 0.4073055386543274,
      "learning_rate": 4.944961174161618e-06,
      "loss": 0.0025,
      "step": 21120
    },
    {
      "epoch": 1.8030548681628127,
      "grad_norm": 0.37160196900367737,
      "learning_rate": 4.923628295929687e-06,
      "loss": 0.002,
      "step": 21130
    },
    {
      "epoch": 1.8039081832920898,
      "grad_norm": 0.42878565192222595,
      "learning_rate": 4.902295417697756e-06,
      "loss": 0.0023,
      "step": 21140
    },
    {
      "epoch": 1.804761498421367,
      "grad_norm": 0.6821472644805908,
      "learning_rate": 4.880962539465825e-06,
      "loss": 0.0031,
      "step": 21150
    },
    {
      "epoch": 1.8056148135506442,
      "grad_norm": 0.6637484431266785,
      "learning_rate": 4.859629661233894e-06,
      "loss": 0.0024,
      "step": 21160
    },
    {
      "epoch": 1.8064681286799216,
      "grad_norm": 0.406368225812912,
      "learning_rate": 4.838296783001963e-06,
      "loss": 0.0019,
      "step": 21170
    },
    {
      "epoch": 1.8073214438091987,
      "grad_norm": 0.9714093208312988,
      "learning_rate": 4.816963904770032e-06,
      "loss": 0.0024,
      "step": 21180
    },
    {
      "epoch": 1.808174758938476,
      "grad_norm": 0.2921590805053711,
      "learning_rate": 4.7956310265381005e-06,
      "loss": 0.0018,
      "step": 21190
    },
    {
      "epoch": 1.8090280740677533,
      "grad_norm": 0.3556121587753296,
      "learning_rate": 4.774298148306169e-06,
      "loss": 0.0021,
      "step": 21200
    },
    {
      "epoch": 1.8098813891970305,
      "grad_norm": 0.5291362404823303,
      "learning_rate": 4.752965270074239e-06,
      "loss": 0.0023,
      "step": 21210
    },
    {
      "epoch": 1.8107347043263076,
      "grad_norm": 0.755993664264679,
      "learning_rate": 4.731632391842307e-06,
      "loss": 0.0024,
      "step": 21220
    },
    {
      "epoch": 1.811588019455585,
      "grad_norm": 0.3990846574306488,
      "learning_rate": 4.710299513610376e-06,
      "loss": 0.0025,
      "step": 21230
    },
    {
      "epoch": 1.8124413345848622,
      "grad_norm": 0.49200156331062317,
      "learning_rate": 4.6889666353784455e-06,
      "loss": 0.0025,
      "step": 21240
    },
    {
      "epoch": 1.8132946497141393,
      "grad_norm": 0.3053910434246063,
      "learning_rate": 4.667633757146515e-06,
      "loss": 0.002,
      "step": 21250
    },
    {
      "epoch": 1.8141479648434167,
      "grad_norm": 0.3190067708492279,
      "learning_rate": 4.646300878914584e-06,
      "loss": 0.0019,
      "step": 21260
    },
    {
      "epoch": 1.815001279972694,
      "grad_norm": 0.23257902264595032,
      "learning_rate": 4.624968000682652e-06,
      "loss": 0.0022,
      "step": 21270
    },
    {
      "epoch": 1.8158545951019711,
      "grad_norm": 0.5277780294418335,
      "learning_rate": 4.603635122450721e-06,
      "loss": 0.0023,
      "step": 21280
    },
    {
      "epoch": 1.8167079102312484,
      "grad_norm": 0.33981284499168396,
      "learning_rate": 4.5823022442187906e-06,
      "loss": 0.002,
      "step": 21290
    },
    {
      "epoch": 1.8175612253605258,
      "grad_norm": 0.2570079267024994,
      "learning_rate": 4.560969365986859e-06,
      "loss": 0.002,
      "step": 21300
    },
    {
      "epoch": 1.8184145404898029,
      "grad_norm": 0.9085522294044495,
      "learning_rate": 4.539636487754928e-06,
      "loss": 0.0026,
      "step": 21310
    },
    {
      "epoch": 1.81926785561908,
      "grad_norm": 0.5011374354362488,
      "learning_rate": 4.5183036095229965e-06,
      "loss": 0.0025,
      "step": 21320
    },
    {
      "epoch": 1.8201211707483573,
      "grad_norm": 0.36425071954727173,
      "learning_rate": 4.496970731291066e-06,
      "loss": 0.0017,
      "step": 21330
    },
    {
      "epoch": 1.8209744858776347,
      "grad_norm": 0.40280988812446594,
      "learning_rate": 4.475637853059135e-06,
      "loss": 0.0021,
      "step": 21340
    },
    {
      "epoch": 1.8218278010069118,
      "grad_norm": 0.27537989616394043,
      "learning_rate": 4.454304974827203e-06,
      "loss": 0.0025,
      "step": 21350
    },
    {
      "epoch": 1.822681116136189,
      "grad_norm": 0.45847374200820923,
      "learning_rate": 4.432972096595273e-06,
      "loss": 0.0022,
      "step": 21360
    },
    {
      "epoch": 1.8235344312654664,
      "grad_norm": 0.6194558143615723,
      "learning_rate": 4.411639218363342e-06,
      "loss": 0.0026,
      "step": 21370
    },
    {
      "epoch": 1.8243877463947435,
      "grad_norm": 0.6414562463760376,
      "learning_rate": 4.390306340131411e-06,
      "loss": 0.0021,
      "step": 21380
    },
    {
      "epoch": 1.8252410615240207,
      "grad_norm": 0.8437119722366333,
      "learning_rate": 4.36897346189948e-06,
      "loss": 0.0025,
      "step": 21390
    },
    {
      "epoch": 1.8260943766532982,
      "grad_norm": 0.5850309133529663,
      "learning_rate": 4.347640583667548e-06,
      "loss": 0.0018,
      "step": 21400
    },
    {
      "epoch": 1.8269476917825753,
      "grad_norm": 0.5223584175109863,
      "learning_rate": 4.326307705435618e-06,
      "loss": 0.002,
      "step": 21410
    },
    {
      "epoch": 1.8278010069118524,
      "grad_norm": 0.39054930210113525,
      "learning_rate": 4.3049748272036866e-06,
      "loss": 0.0018,
      "step": 21420
    },
    {
      "epoch": 1.8286543220411298,
      "grad_norm": 0.3467487394809723,
      "learning_rate": 4.283641948971755e-06,
      "loss": 0.0022,
      "step": 21430
    },
    {
      "epoch": 1.829507637170407,
      "grad_norm": 0.3831985890865326,
      "learning_rate": 4.262309070739824e-06,
      "loss": 0.0023,
      "step": 21440
    },
    {
      "epoch": 1.8303609522996842,
      "grad_norm": 0.5920726656913757,
      "learning_rate": 4.240976192507893e-06,
      "loss": 0.0019,
      "step": 21450
    },
    {
      "epoch": 1.8312142674289615,
      "grad_norm": 0.25415390729904175,
      "learning_rate": 4.219643314275962e-06,
      "loss": 0.0024,
      "step": 21460
    },
    {
      "epoch": 1.8320675825582389,
      "grad_norm": 0.571649968624115,
      "learning_rate": 4.198310436044032e-06,
      "loss": 0.0029,
      "step": 21470
    },
    {
      "epoch": 1.832920897687516,
      "grad_norm": 1.1883918046951294,
      "learning_rate": 4.1769775578121e-06,
      "loss": 0.0029,
      "step": 21480
    },
    {
      "epoch": 1.833774212816793,
      "grad_norm": 0.4686598479747772,
      "learning_rate": 4.15564467958017e-06,
      "loss": 0.0021,
      "step": 21490
    },
    {
      "epoch": 1.8346275279460706,
      "grad_norm": 0.3523697853088379,
      "learning_rate": 4.134311801348238e-06,
      "loss": 0.0022,
      "step": 21500
    },
    {
      "epoch": 1.8354808430753478,
      "grad_norm": 0.5384892821311951,
      "learning_rate": 4.112978923116307e-06,
      "loss": 0.0023,
      "step": 21510
    },
    {
      "epoch": 1.8363341582046249,
      "grad_norm": 0.6936892867088318,
      "learning_rate": 4.091646044884376e-06,
      "loss": 0.0024,
      "step": 21520
    },
    {
      "epoch": 1.8371874733339022,
      "grad_norm": 0.7245490550994873,
      "learning_rate": 4.070313166652445e-06,
      "loss": 0.0022,
      "step": 21530
    },
    {
      "epoch": 1.8380407884631795,
      "grad_norm": 0.47319671511650085,
      "learning_rate": 4.048980288420514e-06,
      "loss": 0.002,
      "step": 21540
    },
    {
      "epoch": 1.8388941035924566,
      "grad_norm": 0.34129253029823303,
      "learning_rate": 4.027647410188583e-06,
      "loss": 0.0023,
      "step": 21550
    },
    {
      "epoch": 1.839747418721734,
      "grad_norm": 0.42677944898605347,
      "learning_rate": 4.006314531956651e-06,
      "loss": 0.0024,
      "step": 21560
    },
    {
      "epoch": 1.8406007338510113,
      "grad_norm": 0.22989456355571747,
      "learning_rate": 3.984981653724721e-06,
      "loss": 0.0027,
      "step": 21570
    },
    {
      "epoch": 1.8414540489802884,
      "grad_norm": 0.3279360234737396,
      "learning_rate": 3.9636487754927894e-06,
      "loss": 0.0019,
      "step": 21580
    },
    {
      "epoch": 1.8423073641095655,
      "grad_norm": 0.34441718459129333,
      "learning_rate": 3.942315897260859e-06,
      "loss": 0.0027,
      "step": 21590
    },
    {
      "epoch": 1.8431606792388429,
      "grad_norm": 0.4076184630393982,
      "learning_rate": 3.920983019028928e-06,
      "loss": 0.0027,
      "step": 21600
    },
    {
      "epoch": 1.8440139943681202,
      "grad_norm": 0.5155792832374573,
      "learning_rate": 3.899650140796997e-06,
      "loss": 0.0023,
      "step": 21610
    },
    {
      "epoch": 1.8448673094973973,
      "grad_norm": 0.6882057785987854,
      "learning_rate": 3.878317262565066e-06,
      "loss": 0.0022,
      "step": 21620
    },
    {
      "epoch": 1.8457206246266746,
      "grad_norm": 0.25077536702156067,
      "learning_rate": 3.8569843843331344e-06,
      "loss": 0.0024,
      "step": 21630
    },
    {
      "epoch": 1.846573939755952,
      "grad_norm": 0.2314317524433136,
      "learning_rate": 3.835651506101203e-06,
      "loss": 0.0029,
      "step": 21640
    },
    {
      "epoch": 1.847427254885229,
      "grad_norm": 0.3605634570121765,
      "learning_rate": 3.8143186278692726e-06,
      "loss": 0.0019,
      "step": 21650
    },
    {
      "epoch": 1.8482805700145064,
      "grad_norm": 0.3982689082622528,
      "learning_rate": 3.7929857496373413e-06,
      "loss": 0.0018,
      "step": 21660
    },
    {
      "epoch": 1.8491338851437837,
      "grad_norm": 0.9459050893783569,
      "learning_rate": 3.7716528714054104e-06,
      "loss": 0.0022,
      "step": 21670
    },
    {
      "epoch": 1.8499872002730609,
      "grad_norm": 0.555994987487793,
      "learning_rate": 3.750319993173479e-06,
      "loss": 0.0028,
      "step": 21680
    },
    {
      "epoch": 1.850840515402338,
      "grad_norm": 0.40502363443374634,
      "learning_rate": 3.7289871149415485e-06,
      "loss": 0.0027,
      "step": 21690
    },
    {
      "epoch": 1.8516938305316153,
      "grad_norm": 0.6576786637306213,
      "learning_rate": 3.707654236709617e-06,
      "loss": 0.0025,
      "step": 21700
    },
    {
      "epoch": 1.8525471456608926,
      "grad_norm": 0.5726467370986938,
      "learning_rate": 3.686321358477686e-06,
      "loss": 0.0023,
      "step": 21710
    },
    {
      "epoch": 1.8534004607901697,
      "grad_norm": 0.809672474861145,
      "learning_rate": 3.6649884802457545e-06,
      "loss": 0.002,
      "step": 21720
    },
    {
      "epoch": 1.854253775919447,
      "grad_norm": 0.5353370308876038,
      "learning_rate": 3.643655602013824e-06,
      "loss": 0.0029,
      "step": 21730
    },
    {
      "epoch": 1.8551070910487244,
      "grad_norm": 0.26344403624534607,
      "learning_rate": 3.622322723781893e-06,
      "loss": 0.0025,
      "step": 21740
    },
    {
      "epoch": 1.8559604061780015,
      "grad_norm": 0.48227375745773315,
      "learning_rate": 3.600989845549962e-06,
      "loss": 0.0018,
      "step": 21750
    },
    {
      "epoch": 1.8568137213072786,
      "grad_norm": 0.39269304275512695,
      "learning_rate": 3.5796569673180305e-06,
      "loss": 0.0023,
      "step": 21760
    },
    {
      "epoch": 1.8576670364365562,
      "grad_norm": 0.5812040567398071,
      "learning_rate": 3.5583240890861e-06,
      "loss": 0.002,
      "step": 21770
    },
    {
      "epoch": 1.8585203515658333,
      "grad_norm": 0.30857473611831665,
      "learning_rate": 3.5369912108541686e-06,
      "loss": 0.0027,
      "step": 21780
    },
    {
      "epoch": 1.8593736666951104,
      "grad_norm": 0.8925729393959045,
      "learning_rate": 3.5156583326222377e-06,
      "loss": 0.0026,
      "step": 21790
    },
    {
      "epoch": 1.8602269818243877,
      "grad_norm": 0.2320941537618637,
      "learning_rate": 3.4943254543903064e-06,
      "loss": 0.0022,
      "step": 21800
    },
    {
      "epoch": 1.861080296953665,
      "grad_norm": 0.40057843923568726,
      "learning_rate": 3.472992576158376e-06,
      "loss": 0.0022,
      "step": 21810
    },
    {
      "epoch": 1.8619336120829422,
      "grad_norm": 0.36446085572242737,
      "learning_rate": 3.4516596979264446e-06,
      "loss": 0.0026,
      "step": 21820
    },
    {
      "epoch": 1.8627869272122195,
      "grad_norm": 0.45368829369544983,
      "learning_rate": 3.4303268196945132e-06,
      "loss": 0.0019,
      "step": 21830
    },
    {
      "epoch": 1.8636402423414968,
      "grad_norm": 0.31792667508125305,
      "learning_rate": 3.4089939414625823e-06,
      "loss": 0.0028,
      "step": 21840
    },
    {
      "epoch": 1.864493557470774,
      "grad_norm": 0.7598996758460999,
      "learning_rate": 3.3876610632306514e-06,
      "loss": 0.0018,
      "step": 21850
    },
    {
      "epoch": 1.865346872600051,
      "grad_norm": 0.7451114058494568,
      "learning_rate": 3.3663281849987205e-06,
      "loss": 0.0024,
      "step": 21860
    },
    {
      "epoch": 1.8662001877293284,
      "grad_norm": 0.34358111023902893,
      "learning_rate": 3.344995306766789e-06,
      "loss": 0.0022,
      "step": 21870
    },
    {
      "epoch": 1.8670535028586057,
      "grad_norm": 0.3613528609275818,
      "learning_rate": 3.323662428534858e-06,
      "loss": 0.0026,
      "step": 21880
    },
    {
      "epoch": 1.8679068179878828,
      "grad_norm": 0.4320980906486511,
      "learning_rate": 3.3023295503029273e-06,
      "loss": 0.0021,
      "step": 21890
    },
    {
      "epoch": 1.8687601331171602,
      "grad_norm": 0.41089898347854614,
      "learning_rate": 3.280996672070996e-06,
      "loss": 0.0024,
      "step": 21900
    },
    {
      "epoch": 1.8696134482464375,
      "grad_norm": 0.39673149585723877,
      "learning_rate": 3.259663793839065e-06,
      "loss": 0.0024,
      "step": 21910
    },
    {
      "epoch": 1.8704667633757146,
      "grad_norm": 0.5541759729385376,
      "learning_rate": 3.2383309156071337e-06,
      "loss": 0.0024,
      "step": 21920
    },
    {
      "epoch": 1.871320078504992,
      "grad_norm": 0.35813459753990173,
      "learning_rate": 3.2169980373752024e-06,
      "loss": 0.0019,
      "step": 21930
    },
    {
      "epoch": 1.8721733936342693,
      "grad_norm": 0.5291851758956909,
      "learning_rate": 3.195665159143272e-06,
      "loss": 0.0019,
      "step": 21940
    },
    {
      "epoch": 1.8730267087635464,
      "grad_norm": 0.41605329513549805,
      "learning_rate": 3.1743322809113406e-06,
      "loss": 0.0022,
      "step": 21950
    },
    {
      "epoch": 1.8738800238928235,
      "grad_norm": 0.5612861514091492,
      "learning_rate": 3.1529994026794097e-06,
      "loss": 0.0026,
      "step": 21960
    },
    {
      "epoch": 1.8747333390221008,
      "grad_norm": 0.5167590975761414,
      "learning_rate": 3.1316665244474783e-06,
      "loss": 0.0022,
      "step": 21970
    },
    {
      "epoch": 1.8755866541513782,
      "grad_norm": 0.6444557905197144,
      "learning_rate": 3.1103336462155474e-06,
      "loss": 0.0021,
      "step": 21980
    },
    {
      "epoch": 1.8764399692806553,
      "grad_norm": 0.2904966175556183,
      "learning_rate": 3.0890007679836165e-06,
      "loss": 0.002,
      "step": 21990
    },
    {
      "epoch": 1.8772932844099326,
      "grad_norm": 0.5124147534370422,
      "learning_rate": 3.067667889751685e-06,
      "loss": 0.0022,
      "step": 22000
    },
    {
      "epoch": 1.87814659953921,
      "grad_norm": 0.329974502325058,
      "learning_rate": 3.0463350115197542e-06,
      "loss": 0.0021,
      "step": 22010
    },
    {
      "epoch": 1.878999914668487,
      "grad_norm": 0.7700622081756592,
      "learning_rate": 3.0250021332878233e-06,
      "loss": 0.0026,
      "step": 22020
    },
    {
      "epoch": 1.8798532297977644,
      "grad_norm": 0.5132250189781189,
      "learning_rate": 3.0036692550558924e-06,
      "loss": 0.0023,
      "step": 22030
    },
    {
      "epoch": 1.8807065449270417,
      "grad_norm": 0.16321256756782532,
      "learning_rate": 2.982336376823961e-06,
      "loss": 0.0026,
      "step": 22040
    },
    {
      "epoch": 1.8815598600563188,
      "grad_norm": 0.31603989005088806,
      "learning_rate": 2.96100349859203e-06,
      "loss": 0.002,
      "step": 22050
    },
    {
      "epoch": 1.882413175185596,
      "grad_norm": 0.4265122413635254,
      "learning_rate": 2.939670620360099e-06,
      "loss": 0.0019,
      "step": 22060
    },
    {
      "epoch": 1.8832664903148733,
      "grad_norm": 0.4657367765903473,
      "learning_rate": 2.918337742128168e-06,
      "loss": 0.0022,
      "step": 22070
    },
    {
      "epoch": 1.8841198054441506,
      "grad_norm": 0.5236397385597229,
      "learning_rate": 2.897004863896237e-06,
      "loss": 0.0022,
      "step": 22080
    },
    {
      "epoch": 1.8849731205734277,
      "grad_norm": 0.4357537031173706,
      "learning_rate": 2.875671985664306e-06,
      "loss": 0.0021,
      "step": 22090
    },
    {
      "epoch": 1.885826435702705,
      "grad_norm": 0.8061602115631104,
      "learning_rate": 2.8543391074323748e-06,
      "loss": 0.0021,
      "step": 22100
    },
    {
      "epoch": 1.8866797508319824,
      "grad_norm": 0.33991557359695435,
      "learning_rate": 2.833006229200444e-06,
      "loss": 0.0018,
      "step": 22110
    },
    {
      "epoch": 1.8875330659612595,
      "grad_norm": 0.35155758261680603,
      "learning_rate": 2.8116733509685125e-06,
      "loss": 0.002,
      "step": 22120
    },
    {
      "epoch": 1.8883863810905366,
      "grad_norm": 0.8574625849723816,
      "learning_rate": 2.7903404727365816e-06,
      "loss": 0.0015,
      "step": 22130
    },
    {
      "epoch": 1.8892396962198141,
      "grad_norm": 0.5506727695465088,
      "learning_rate": 2.7690075945046507e-06,
      "loss": 0.0019,
      "step": 22140
    },
    {
      "epoch": 1.8900930113490912,
      "grad_norm": 0.5663421750068665,
      "learning_rate": 2.7476747162727198e-06,
      "loss": 0.0022,
      "step": 22150
    },
    {
      "epoch": 1.8909463264783684,
      "grad_norm": 0.4194710850715637,
      "learning_rate": 2.7263418380407884e-06,
      "loss": 0.0018,
      "step": 22160
    },
    {
      "epoch": 1.8917996416076457,
      "grad_norm": 0.5852755308151245,
      "learning_rate": 2.7050089598088575e-06,
      "loss": 0.0024,
      "step": 22170
    },
    {
      "epoch": 1.892652956736923,
      "grad_norm": 0.5878811478614807,
      "learning_rate": 2.683676081576926e-06,
      "loss": 0.0027,
      "step": 22180
    },
    {
      "epoch": 1.8935062718662001,
      "grad_norm": 0.6158915162086487,
      "learning_rate": 2.6623432033449953e-06,
      "loss": 0.0026,
      "step": 22190
    },
    {
      "epoch": 1.8943595869954775,
      "grad_norm": 0.46755897998809814,
      "learning_rate": 2.6410103251130644e-06,
      "loss": 0.0022,
      "step": 22200
    },
    {
      "epoch": 1.8952129021247548,
      "grad_norm": 0.27524256706237793,
      "learning_rate": 2.6196774468811335e-06,
      "loss": 0.0026,
      "step": 22210
    },
    {
      "epoch": 1.896066217254032,
      "grad_norm": 0.3782805800437927,
      "learning_rate": 2.598344568649202e-06,
      "loss": 0.0019,
      "step": 22220
    },
    {
      "epoch": 1.896919532383309,
      "grad_norm": 0.6023581624031067,
      "learning_rate": 2.577011690417271e-06,
      "loss": 0.0017,
      "step": 22230
    },
    {
      "epoch": 1.8977728475125863,
      "grad_norm": 0.4273545742034912,
      "learning_rate": 2.55567881218534e-06,
      "loss": 0.0023,
      "step": 22240
    },
    {
      "epoch": 1.8986261626418637,
      "grad_norm": 0.7872413396835327,
      "learning_rate": 2.5343459339534094e-06,
      "loss": 0.0021,
      "step": 22250
    },
    {
      "epoch": 1.8994794777711408,
      "grad_norm": 0.23812896013259888,
      "learning_rate": 2.513013055721478e-06,
      "loss": 0.0022,
      "step": 22260
    },
    {
      "epoch": 1.9003327929004181,
      "grad_norm": 0.4986475110054016,
      "learning_rate": 2.491680177489547e-06,
      "loss": 0.0019,
      "step": 22270
    },
    {
      "epoch": 1.9011861080296955,
      "grad_norm": 0.38497111201286316,
      "learning_rate": 2.470347299257616e-06,
      "loss": 0.0023,
      "step": 22280
    },
    {
      "epoch": 1.9020394231589726,
      "grad_norm": 0.43477708101272583,
      "learning_rate": 2.449014421025685e-06,
      "loss": 0.0021,
      "step": 22290
    },
    {
      "epoch": 1.90289273828825,
      "grad_norm": 0.8252978920936584,
      "learning_rate": 2.4276815427937535e-06,
      "loss": 0.0021,
      "step": 22300
    },
    {
      "epoch": 1.9037460534175272,
      "grad_norm": 0.26760411262512207,
      "learning_rate": 2.406348664561823e-06,
      "loss": 0.0018,
      "step": 22310
    },
    {
      "epoch": 1.9045993685468043,
      "grad_norm": 0.3567514419555664,
      "learning_rate": 2.3850157863298917e-06,
      "loss": 0.002,
      "step": 22320
    },
    {
      "epoch": 1.9054526836760814,
      "grad_norm": 0.550273597240448,
      "learning_rate": 2.363682908097961e-06,
      "loss": 0.002,
      "step": 22330
    },
    {
      "epoch": 1.9063059988053588,
      "grad_norm": 0.24806007742881775,
      "learning_rate": 2.3423500298660295e-06,
      "loss": 0.0025,
      "step": 22340
    },
    {
      "epoch": 1.9071593139346361,
      "grad_norm": 0.4143655002117157,
      "learning_rate": 2.3210171516340986e-06,
      "loss": 0.0022,
      "step": 22350
    },
    {
      "epoch": 1.9080126290639132,
      "grad_norm": 0.2979452610015869,
      "learning_rate": 2.2996842734021676e-06,
      "loss": 0.0027,
      "step": 22360
    },
    {
      "epoch": 1.9088659441931906,
      "grad_norm": 0.39772048592567444,
      "learning_rate": 2.2783513951702367e-06,
      "loss": 0.0018,
      "step": 22370
    },
    {
      "epoch": 1.9097192593224679,
      "grad_norm": 0.5150018930435181,
      "learning_rate": 2.2570185169383054e-06,
      "loss": 0.0019,
      "step": 22380
    },
    {
      "epoch": 1.910572574451745,
      "grad_norm": 0.2376226931810379,
      "learning_rate": 2.2356856387063745e-06,
      "loss": 0.002,
      "step": 22390
    },
    {
      "epoch": 1.911425889581022,
      "grad_norm": 0.5298848748207092,
      "learning_rate": 2.214352760474443e-06,
      "loss": 0.0026,
      "step": 22400
    },
    {
      "epoch": 1.9122792047102997,
      "grad_norm": 0.8258524537086487,
      "learning_rate": 2.1930198822425122e-06,
      "loss": 0.0023,
      "step": 22410
    },
    {
      "epoch": 1.9131325198395768,
      "grad_norm": 0.5142456293106079,
      "learning_rate": 2.1716870040105813e-06,
      "loss": 0.0026,
      "step": 22420
    },
    {
      "epoch": 1.9139858349688539,
      "grad_norm": 0.6073898077011108,
      "learning_rate": 2.1503541257786504e-06,
      "loss": 0.0031,
      "step": 22430
    },
    {
      "epoch": 1.9148391500981312,
      "grad_norm": 0.352363258600235,
      "learning_rate": 2.129021247546719e-06,
      "loss": 0.0023,
      "step": 22440
    },
    {
      "epoch": 1.9156924652274085,
      "grad_norm": 0.42514750361442566,
      "learning_rate": 2.107688369314788e-06,
      "loss": 0.0023,
      "step": 22450
    },
    {
      "epoch": 1.9165457803566857,
      "grad_norm": 0.27429962158203125,
      "learning_rate": 2.086355491082857e-06,
      "loss": 0.0018,
      "step": 22460
    },
    {
      "epoch": 1.917399095485963,
      "grad_norm": 0.5540339946746826,
      "learning_rate": 2.065022612850926e-06,
      "loss": 0.0018,
      "step": 22470
    },
    {
      "epoch": 1.9182524106152403,
      "grad_norm": 0.4265638291835785,
      "learning_rate": 2.043689734618995e-06,
      "loss": 0.002,
      "step": 22480
    },
    {
      "epoch": 1.9191057257445174,
      "grad_norm": 0.5479768514633179,
      "learning_rate": 2.022356856387064e-06,
      "loss": 0.0021,
      "step": 22490
    },
    {
      "epoch": 1.9199590408737945,
      "grad_norm": 0.43057504296302795,
      "learning_rate": 2.0010239781551327e-06,
      "loss": 0.0021,
      "step": 22500
    },
    {
      "epoch": 1.920812356003072,
      "grad_norm": 0.3053314685821533,
      "learning_rate": 1.979691099923202e-06,
      "loss": 0.0025,
      "step": 22510
    },
    {
      "epoch": 1.9216656711323492,
      "grad_norm": 0.6412110328674316,
      "learning_rate": 1.9583582216912705e-06,
      "loss": 0.0021,
      "step": 22520
    },
    {
      "epoch": 1.9225189862616263,
      "grad_norm": 0.3750883638858795,
      "learning_rate": 1.9370253434593396e-06,
      "loss": 0.002,
      "step": 22530
    },
    {
      "epoch": 1.9233723013909036,
      "grad_norm": 0.6391909122467041,
      "learning_rate": 1.9156924652274087e-06,
      "loss": 0.0034,
      "step": 22540
    },
    {
      "epoch": 1.924225616520181,
      "grad_norm": 0.4604855179786682,
      "learning_rate": 1.8943595869954775e-06,
      "loss": 0.0024,
      "step": 22550
    },
    {
      "epoch": 1.925078931649458,
      "grad_norm": 0.7711873054504395,
      "learning_rate": 1.8730267087635464e-06,
      "loss": 0.0024,
      "step": 22560
    },
    {
      "epoch": 1.9259322467787354,
      "grad_norm": 0.4494408667087555,
      "learning_rate": 1.8516938305316155e-06,
      "loss": 0.002,
      "step": 22570
    },
    {
      "epoch": 1.9267855619080128,
      "grad_norm": 0.6974905133247375,
      "learning_rate": 1.8303609522996844e-06,
      "loss": 0.002,
      "step": 22580
    },
    {
      "epoch": 1.9276388770372899,
      "grad_norm": 0.2978277802467346,
      "learning_rate": 1.8090280740677535e-06,
      "loss": 0.0022,
      "step": 22590
    },
    {
      "epoch": 1.928492192166567,
      "grad_norm": 0.5056893229484558,
      "learning_rate": 1.7876951958358221e-06,
      "loss": 0.0023,
      "step": 22600
    },
    {
      "epoch": 1.9293455072958443,
      "grad_norm": 0.3651057481765747,
      "learning_rate": 1.7663623176038912e-06,
      "loss": 0.0022,
      "step": 22610
    },
    {
      "epoch": 1.9301988224251216,
      "grad_norm": 0.23633502423763275,
      "learning_rate": 1.74502943937196e-06,
      "loss": 0.002,
      "step": 22620
    },
    {
      "epoch": 1.9310521375543988,
      "grad_norm": 0.324299156665802,
      "learning_rate": 1.7236965611400292e-06,
      "loss": 0.0021,
      "step": 22630
    },
    {
      "epoch": 1.931905452683676,
      "grad_norm": 0.36281293630599976,
      "learning_rate": 1.702363682908098e-06,
      "loss": 0.0022,
      "step": 22640
    },
    {
      "epoch": 1.9327587678129534,
      "grad_norm": 0.33499646186828613,
      "learning_rate": 1.6810308046761671e-06,
      "loss": 0.002,
      "step": 22650
    },
    {
      "epoch": 1.9336120829422305,
      "grad_norm": 0.3129866123199463,
      "learning_rate": 1.6596979264442358e-06,
      "loss": 0.0022,
      "step": 22660
    },
    {
      "epoch": 1.9344653980715079,
      "grad_norm": 0.3665001094341278,
      "learning_rate": 1.6383650482123051e-06,
      "loss": 0.0021,
      "step": 22670
    },
    {
      "epoch": 1.9353187132007852,
      "grad_norm": 0.2959701418876648,
      "learning_rate": 1.6170321699803738e-06,
      "loss": 0.0026,
      "step": 22680
    },
    {
      "epoch": 1.9361720283300623,
      "grad_norm": 0.402057409286499,
      "learning_rate": 1.5956992917484429e-06,
      "loss": 0.0022,
      "step": 22690
    },
    {
      "epoch": 1.9370253434593394,
      "grad_norm": 0.39567360281944275,
      "learning_rate": 1.5743664135165117e-06,
      "loss": 0.0022,
      "step": 22700
    },
    {
      "epoch": 1.9378786585886167,
      "grad_norm": 0.3709232211112976,
      "learning_rate": 1.5530335352845806e-06,
      "loss": 0.002,
      "step": 22710
    },
    {
      "epoch": 1.938731973717894,
      "grad_norm": 0.2084277719259262,
      "learning_rate": 1.5317006570526495e-06,
      "loss": 0.0017,
      "step": 22720
    },
    {
      "epoch": 1.9395852888471712,
      "grad_norm": 0.15380999445915222,
      "learning_rate": 1.5103677788207186e-06,
      "loss": 0.0021,
      "step": 22730
    },
    {
      "epoch": 1.9404386039764485,
      "grad_norm": 0.308122843503952,
      "learning_rate": 1.4890349005887875e-06,
      "loss": 0.0016,
      "step": 22740
    },
    {
      "epoch": 1.9412919191057258,
      "grad_norm": 0.421144038438797,
      "learning_rate": 1.4677020223568565e-06,
      "loss": 0.002,
      "step": 22750
    },
    {
      "epoch": 1.942145234235003,
      "grad_norm": 0.6487307548522949,
      "learning_rate": 1.4463691441249254e-06,
      "loss": 0.0019,
      "step": 22760
    },
    {
      "epoch": 1.94299854936428,
      "grad_norm": 0.4318300187587738,
      "learning_rate": 1.4250362658929943e-06,
      "loss": 0.0026,
      "step": 22770
    },
    {
      "epoch": 1.9438518644935576,
      "grad_norm": 0.4078832268714905,
      "learning_rate": 1.4037033876610634e-06,
      "loss": 0.0021,
      "step": 22780
    },
    {
      "epoch": 1.9447051796228347,
      "grad_norm": 0.45221835374832153,
      "learning_rate": 1.3823705094291323e-06,
      "loss": 0.0025,
      "step": 22790
    },
    {
      "epoch": 1.9455584947521118,
      "grad_norm": 0.6882207989692688,
      "learning_rate": 1.3610376311972011e-06,
      "loss": 0.0025,
      "step": 22800
    },
    {
      "epoch": 1.9464118098813892,
      "grad_norm": 0.37653565406799316,
      "learning_rate": 1.3397047529652702e-06,
      "loss": 0.0019,
      "step": 22810
    },
    {
      "epoch": 1.9472651250106665,
      "grad_norm": 0.2632640302181244,
      "learning_rate": 1.318371874733339e-06,
      "loss": 0.0018,
      "step": 22820
    },
    {
      "epoch": 1.9481184401399436,
      "grad_norm": 0.3458627462387085,
      "learning_rate": 1.297038996501408e-06,
      "loss": 0.0029,
      "step": 22830
    },
    {
      "epoch": 1.948971755269221,
      "grad_norm": 0.43678346276283264,
      "learning_rate": 1.275706118269477e-06,
      "loss": 0.002,
      "step": 22840
    },
    {
      "epoch": 1.9498250703984983,
      "grad_norm": 0.37874022126197815,
      "learning_rate": 1.254373240037546e-06,
      "loss": 0.0019,
      "step": 22850
    },
    {
      "epoch": 1.9506783855277754,
      "grad_norm": 0.38064539432525635,
      "learning_rate": 1.2330403618056148e-06,
      "loss": 0.0023,
      "step": 22860
    },
    {
      "epoch": 1.9515317006570525,
      "grad_norm": 0.2767433822154999,
      "learning_rate": 1.2117074835736839e-06,
      "loss": 0.0021,
      "step": 22870
    },
    {
      "epoch": 1.95238501578633,
      "grad_norm": 0.5085839033126831,
      "learning_rate": 1.1903746053417528e-06,
      "loss": 0.0023,
      "step": 22880
    },
    {
      "epoch": 1.9532383309156072,
      "grad_norm": 0.2744891345500946,
      "learning_rate": 1.1690417271098216e-06,
      "loss": 0.0024,
      "step": 22890
    },
    {
      "epoch": 1.9540916460448843,
      "grad_norm": 0.33989062905311584,
      "learning_rate": 1.1477088488778907e-06,
      "loss": 0.002,
      "step": 22900
    },
    {
      "epoch": 1.9549449611741616,
      "grad_norm": 0.33112832903862,
      "learning_rate": 1.1263759706459596e-06,
      "loss": 0.0025,
      "step": 22910
    },
    {
      "epoch": 1.955798276303439,
      "grad_norm": 0.49839669466018677,
      "learning_rate": 1.1050430924140285e-06,
      "loss": 0.0024,
      "step": 22920
    },
    {
      "epoch": 1.956651591432716,
      "grad_norm": 0.7286969423294067,
      "learning_rate": 1.0837102141820976e-06,
      "loss": 0.0022,
      "step": 22930
    },
    {
      "epoch": 1.9575049065619934,
      "grad_norm": 0.3023507595062256,
      "learning_rate": 1.0623773359501664e-06,
      "loss": 0.0024,
      "step": 22940
    },
    {
      "epoch": 1.9583582216912707,
      "grad_norm": 0.6597108244895935,
      "learning_rate": 1.0410444577182353e-06,
      "loss": 0.0019,
      "step": 22950
    },
    {
      "epoch": 1.9592115368205478,
      "grad_norm": 0.4109460711479187,
      "learning_rate": 1.0197115794863044e-06,
      "loss": 0.0018,
      "step": 22960
    },
    {
      "epoch": 1.960064851949825,
      "grad_norm": 0.37883779406547546,
      "learning_rate": 9.983787012543733e-07,
      "loss": 0.0025,
      "step": 22970
    },
    {
      "epoch": 1.9609181670791023,
      "grad_norm": 0.38609546422958374,
      "learning_rate": 9.770458230224422e-07,
      "loss": 0.0032,
      "step": 22980
    },
    {
      "epoch": 1.9617714822083796,
      "grad_norm": 0.3733605146408081,
      "learning_rate": 9.557129447905112e-07,
      "loss": 0.0017,
      "step": 22990
    },
    {
      "epoch": 1.9626247973376567,
      "grad_norm": 0.27355554699897766,
      "learning_rate": 9.343800665585801e-07,
      "loss": 0.0017,
      "step": 23000
    },
    {
      "epoch": 1.963478112466934,
      "grad_norm": 0.2867414057254791,
      "learning_rate": 9.130471883266491e-07,
      "loss": 0.0022,
      "step": 23010
    },
    {
      "epoch": 1.9643314275962114,
      "grad_norm": 0.5040771961212158,
      "learning_rate": 8.917143100947181e-07,
      "loss": 0.0022,
      "step": 23020
    },
    {
      "epoch": 1.9651847427254885,
      "grad_norm": 0.42933139204978943,
      "learning_rate": 8.70381431862787e-07,
      "loss": 0.0021,
      "step": 23030
    },
    {
      "epoch": 1.9660380578547658,
      "grad_norm": 0.5513224005699158,
      "learning_rate": 8.490485536308559e-07,
      "loss": 0.0029,
      "step": 23040
    },
    {
      "epoch": 1.9668913729840432,
      "grad_norm": 0.562056303024292,
      "learning_rate": 8.277156753989249e-07,
      "loss": 0.0026,
      "step": 23050
    },
    {
      "epoch": 1.9677446881133203,
      "grad_norm": 0.2898026704788208,
      "learning_rate": 8.063827971669938e-07,
      "loss": 0.0022,
      "step": 23060
    },
    {
      "epoch": 1.9685980032425974,
      "grad_norm": 0.6350637078285217,
      "learning_rate": 7.850499189350628e-07,
      "loss": 0.0022,
      "step": 23070
    },
    {
      "epoch": 1.9694513183718747,
      "grad_norm": 0.38371413946151733,
      "learning_rate": 7.637170407031318e-07,
      "loss": 0.0024,
      "step": 23080
    },
    {
      "epoch": 1.970304633501152,
      "grad_norm": 0.5662734508514404,
      "learning_rate": 7.423841624712007e-07,
      "loss": 0.0022,
      "step": 23090
    },
    {
      "epoch": 1.9711579486304291,
      "grad_norm": 0.3916054964065552,
      "learning_rate": 7.210512842392696e-07,
      "loss": 0.002,
      "step": 23100
    },
    {
      "epoch": 1.9720112637597065,
      "grad_norm": 0.31536704301834106,
      "learning_rate": 6.997184060073385e-07,
      "loss": 0.0022,
      "step": 23110
    },
    {
      "epoch": 1.9728645788889838,
      "grad_norm": 0.31938761472702026,
      "learning_rate": 6.783855277754075e-07,
      "loss": 0.0023,
      "step": 23120
    },
    {
      "epoch": 1.973717894018261,
      "grad_norm": 0.28449124097824097,
      "learning_rate": 6.570526495434763e-07,
      "loss": 0.0024,
      "step": 23130
    },
    {
      "epoch": 1.974571209147538,
      "grad_norm": 0.22934095561504364,
      "learning_rate": 6.357197713115453e-07,
      "loss": 0.0021,
      "step": 23140
    },
    {
      "epoch": 1.9754245242768156,
      "grad_norm": 0.2808614671230316,
      "learning_rate": 6.143868930796143e-07,
      "loss": 0.0019,
      "step": 23150
    },
    {
      "epoch": 1.9762778394060927,
      "grad_norm": 0.43553951382637024,
      "learning_rate": 5.930540148476833e-07,
      "loss": 0.0023,
      "step": 23160
    },
    {
      "epoch": 1.9771311545353698,
      "grad_norm": 0.4783537983894348,
      "learning_rate": 5.717211366157522e-07,
      "loss": 0.0017,
      "step": 23170
    },
    {
      "epoch": 1.9779844696646471,
      "grad_norm": 0.3038454055786133,
      "learning_rate": 5.503882583838211e-07,
      "loss": 0.0021,
      "step": 23180
    },
    {
      "epoch": 1.9788377847939245,
      "grad_norm": 0.5736023187637329,
      "learning_rate": 5.290553801518901e-07,
      "loss": 0.0023,
      "step": 23190
    },
    {
      "epoch": 1.9796910999232016,
      "grad_norm": 0.4599931538105011,
      "learning_rate": 5.07722501919959e-07,
      "loss": 0.0023,
      "step": 23200
    },
    {
      "epoch": 1.980544415052479,
      "grad_norm": 0.33928439021110535,
      "learning_rate": 4.86389623688028e-07,
      "loss": 0.002,
      "step": 23210
    },
    {
      "epoch": 1.9813977301817562,
      "grad_norm": 0.4321948289871216,
      "learning_rate": 4.650567454560969e-07,
      "loss": 0.0022,
      "step": 23220
    },
    {
      "epoch": 1.9822510453110334,
      "grad_norm": 0.18908067047595978,
      "learning_rate": 4.437238672241659e-07,
      "loss": 0.0019,
      "step": 23230
    },
    {
      "epoch": 1.9831043604403105,
      "grad_norm": 0.43467336893081665,
      "learning_rate": 4.223909889922348e-07,
      "loss": 0.0025,
      "step": 23240
    },
    {
      "epoch": 1.9839576755695878,
      "grad_norm": 0.402120441198349,
      "learning_rate": 4.010581107603038e-07,
      "loss": 0.0024,
      "step": 23250
    },
    {
      "epoch": 1.9848109906988651,
      "grad_norm": 0.3936193585395813,
      "learning_rate": 3.7972523252837274e-07,
      "loss": 0.002,
      "step": 23260
    },
    {
      "epoch": 1.9856643058281422,
      "grad_norm": 0.4837620258331299,
      "learning_rate": 3.5839235429644166e-07,
      "loss": 0.0021,
      "step": 23270
    },
    {
      "epoch": 1.9865176209574196,
      "grad_norm": 0.1929418444633484,
      "learning_rate": 3.3705947606451065e-07,
      "loss": 0.0019,
      "step": 23280
    },
    {
      "epoch": 1.987370936086697,
      "grad_norm": 0.3305956721305847,
      "learning_rate": 3.1572659783257957e-07,
      "loss": 0.0018,
      "step": 23290
    },
    {
      "epoch": 1.988224251215974,
      "grad_norm": 0.40544459223747253,
      "learning_rate": 2.943937196006485e-07,
      "loss": 0.0026,
      "step": 23300
    },
    {
      "epoch": 1.9890775663452513,
      "grad_norm": 0.33628207445144653,
      "learning_rate": 2.730608413687175e-07,
      "loss": 0.0021,
      "step": 23310
    },
    {
      "epoch": 1.9899308814745287,
      "grad_norm": 0.47398579120635986,
      "learning_rate": 2.517279631367864e-07,
      "loss": 0.0018,
      "step": 23320
    },
    {
      "epoch": 1.9907841966038058,
      "grad_norm": 0.24910865724086761,
      "learning_rate": 2.3039508490485537e-07,
      "loss": 0.002,
      "step": 23330
    },
    {
      "epoch": 1.991637511733083,
      "grad_norm": 0.5542787313461304,
      "learning_rate": 2.0906220667292432e-07,
      "loss": 0.0024,
      "step": 23340
    },
    {
      "epoch": 1.9924908268623602,
      "grad_norm": 0.5577084422111511,
      "learning_rate": 1.8772932844099328e-07,
      "loss": 0.0019,
      "step": 23350
    },
    {
      "epoch": 1.9933441419916376,
      "grad_norm": 0.5062745213508606,
      "learning_rate": 1.663964502090622e-07,
      "loss": 0.002,
      "step": 23360
    },
    {
      "epoch": 1.9941974571209147,
      "grad_norm": 0.6112895011901855,
      "learning_rate": 1.4506357197713116e-07,
      "loss": 0.0023,
      "step": 23370
    },
    {
      "epoch": 1.995050772250192,
      "grad_norm": 0.4603157937526703,
      "learning_rate": 1.2373069374520011e-07,
      "loss": 0.002,
      "step": 23380
    },
    {
      "epoch": 1.9959040873794693,
      "grad_norm": 0.2987040877342224,
      "learning_rate": 1.0239781551326907e-07,
      "loss": 0.0027,
      "step": 23390
    },
    {
      "epoch": 1.9967574025087464,
      "grad_norm": 0.4730353057384491,
      "learning_rate": 8.1064937281338e-08,
      "loss": 0.002,
      "step": 23400
    },
    {
      "epoch": 1.9976107176380236,
      "grad_norm": 0.31120210886001587,
      "learning_rate": 5.973205904940695e-08,
      "loss": 0.0021,
      "step": 23410
    },
    {
      "epoch": 1.9984640327673011,
      "grad_norm": 0.3681582808494568,
      "learning_rate": 3.8399180817475894e-08,
      "loss": 0.002,
      "step": 23420
    },
    {
      "epoch": 1.9993173478965782,
      "grad_norm": 0.3599512279033661,
      "learning_rate": 1.7066302585544843e-08,
      "loss": 0.0026,
      "step": 23430
    }
  ],
  "logging_steps": 10,
  "max_steps": 23438,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 0.0,
  "train_batch_size": 64,
  "trial_name": null,
  "trial_params": null
}
