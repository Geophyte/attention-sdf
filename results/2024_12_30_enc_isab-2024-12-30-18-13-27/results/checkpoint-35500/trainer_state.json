{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.9722222222222223,
  "eval_steps": 500,
  "global_step": 35500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0005555555555555556,
      "grad_norm": 0.15049917995929718,
      "learning_rate": 4.9986111111111115e-05,
      "loss": 0.0032,
      "step": 10
    },
    {
      "epoch": 0.0011111111111111111,
      "grad_norm": 0.33315742015838623,
      "learning_rate": 4.997222222222223e-05,
      "loss": 0.0024,
      "step": 20
    },
    {
      "epoch": 0.0016666666666666668,
      "grad_norm": 0.3126916289329529,
      "learning_rate": 4.995833333333333e-05,
      "loss": 0.0023,
      "step": 30
    },
    {
      "epoch": 0.0022222222222222222,
      "grad_norm": 0.20247605443000793,
      "learning_rate": 4.994444444444445e-05,
      "loss": 0.0021,
      "step": 40
    },
    {
      "epoch": 0.002777777777777778,
      "grad_norm": 0.43217238783836365,
      "learning_rate": 4.993055555555556e-05,
      "loss": 0.0027,
      "step": 50
    },
    {
      "epoch": 0.0033333333333333335,
      "grad_norm": 0.29150664806365967,
      "learning_rate": 4.991666666666667e-05,
      "loss": 0.002,
      "step": 60
    },
    {
      "epoch": 0.0038888888888888888,
      "grad_norm": 0.09935284405946732,
      "learning_rate": 4.990277777777778e-05,
      "loss": 0.0024,
      "step": 70
    },
    {
      "epoch": 0.0044444444444444444,
      "grad_norm": 0.0844959169626236,
      "learning_rate": 4.9888888888888894e-05,
      "loss": 0.0021,
      "step": 80
    },
    {
      "epoch": 0.005,
      "grad_norm": 0.1254587024450302,
      "learning_rate": 4.9875000000000006e-05,
      "loss": 0.0009,
      "step": 90
    },
    {
      "epoch": 0.005555555555555556,
      "grad_norm": 0.04791836440563202,
      "learning_rate": 4.986111111111111e-05,
      "loss": 0.0013,
      "step": 100
    },
    {
      "epoch": 0.006111111111111111,
      "grad_norm": 0.04565320909023285,
      "learning_rate": 4.9847222222222224e-05,
      "loss": 0.0011,
      "step": 110
    },
    {
      "epoch": 0.006666666666666667,
      "grad_norm": 0.17130328714847565,
      "learning_rate": 4.9833333333333336e-05,
      "loss": 0.0009,
      "step": 120
    },
    {
      "epoch": 0.007222222222222222,
      "grad_norm": 0.13023224472999573,
      "learning_rate": 4.981944444444445e-05,
      "loss": 0.0009,
      "step": 130
    },
    {
      "epoch": 0.0077777777777777776,
      "grad_norm": 0.11304791271686554,
      "learning_rate": 4.9805555555555554e-05,
      "loss": 0.002,
      "step": 140
    },
    {
      "epoch": 0.008333333333333333,
      "grad_norm": 0.049360767006874084,
      "learning_rate": 4.979166666666667e-05,
      "loss": 0.0024,
      "step": 150
    },
    {
      "epoch": 0.008888888888888889,
      "grad_norm": 0.27822813391685486,
      "learning_rate": 4.977777777777778e-05,
      "loss": 0.0027,
      "step": 160
    },
    {
      "epoch": 0.009444444444444445,
      "grad_norm": 0.36602848768234253,
      "learning_rate": 4.976388888888889e-05,
      "loss": 0.0024,
      "step": 170
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.07265502214431763,
      "learning_rate": 4.975e-05,
      "loss": 0.0016,
      "step": 180
    },
    {
      "epoch": 0.010555555555555556,
      "grad_norm": 0.22690412402153015,
      "learning_rate": 4.973611111111111e-05,
      "loss": 0.0015,
      "step": 190
    },
    {
      "epoch": 0.011111111111111112,
      "grad_norm": 0.3461579382419586,
      "learning_rate": 4.972222222222223e-05,
      "loss": 0.0018,
      "step": 200
    },
    {
      "epoch": 0.011666666666666667,
      "grad_norm": 0.05859624594449997,
      "learning_rate": 4.970833333333333e-05,
      "loss": 0.0014,
      "step": 210
    },
    {
      "epoch": 0.012222222222222223,
      "grad_norm": 0.11916165053844452,
      "learning_rate": 4.969444444444445e-05,
      "loss": 0.0007,
      "step": 220
    },
    {
      "epoch": 0.012777777777777779,
      "grad_norm": 0.17086322605609894,
      "learning_rate": 4.968055555555556e-05,
      "loss": 0.0017,
      "step": 230
    },
    {
      "epoch": 0.013333333333333334,
      "grad_norm": 0.020826352760195732,
      "learning_rate": 4.966666666666667e-05,
      "loss": 0.0013,
      "step": 240
    },
    {
      "epoch": 0.013888888888888888,
      "grad_norm": 0.0718459039926529,
      "learning_rate": 4.965277777777778e-05,
      "loss": 0.0009,
      "step": 250
    },
    {
      "epoch": 0.014444444444444444,
      "grad_norm": 0.10516636818647385,
      "learning_rate": 4.963888888888889e-05,
      "loss": 0.0016,
      "step": 260
    },
    {
      "epoch": 0.015,
      "grad_norm": 0.0530853234231472,
      "learning_rate": 4.962500000000001e-05,
      "loss": 0.0027,
      "step": 270
    },
    {
      "epoch": 0.015555555555555555,
      "grad_norm": 0.22369055449962616,
      "learning_rate": 4.961111111111111e-05,
      "loss": 0.0011,
      "step": 280
    },
    {
      "epoch": 0.01611111111111111,
      "grad_norm": 0.1016777902841568,
      "learning_rate": 4.9597222222222225e-05,
      "loss": 0.001,
      "step": 290
    },
    {
      "epoch": 0.016666666666666666,
      "grad_norm": 0.07642453908920288,
      "learning_rate": 4.958333333333334e-05,
      "loss": 0.0013,
      "step": 300
    },
    {
      "epoch": 0.017222222222222222,
      "grad_norm": 0.35173600912094116,
      "learning_rate": 4.956944444444445e-05,
      "loss": 0.0015,
      "step": 310
    },
    {
      "epoch": 0.017777777777777778,
      "grad_norm": 0.10150524973869324,
      "learning_rate": 4.955555555555556e-05,
      "loss": 0.0031,
      "step": 320
    },
    {
      "epoch": 0.018333333333333333,
      "grad_norm": 0.11500357836484909,
      "learning_rate": 4.954166666666667e-05,
      "loss": 0.0002,
      "step": 330
    },
    {
      "epoch": 0.01888888888888889,
      "grad_norm": 0.04962015151977539,
      "learning_rate": 4.952777777777778e-05,
      "loss": 0.0015,
      "step": 340
    },
    {
      "epoch": 0.019444444444444445,
      "grad_norm": 0.2110886126756668,
      "learning_rate": 4.951388888888889e-05,
      "loss": 0.0019,
      "step": 350
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.4034527838230133,
      "learning_rate": 4.9500000000000004e-05,
      "loss": 0.0025,
      "step": 360
    },
    {
      "epoch": 0.020555555555555556,
      "grad_norm": 0.3944815397262573,
      "learning_rate": 4.948611111111111e-05,
      "loss": 0.0019,
      "step": 370
    },
    {
      "epoch": 0.021111111111111112,
      "grad_norm": 0.16424942016601562,
      "learning_rate": 4.947222222222223e-05,
      "loss": 0.002,
      "step": 380
    },
    {
      "epoch": 0.021666666666666667,
      "grad_norm": 0.11753223836421967,
      "learning_rate": 4.9458333333333334e-05,
      "loss": 0.0022,
      "step": 390
    },
    {
      "epoch": 0.022222222222222223,
      "grad_norm": 0.2600592076778412,
      "learning_rate": 4.9444444444444446e-05,
      "loss": 0.0016,
      "step": 400
    },
    {
      "epoch": 0.02277777777777778,
      "grad_norm": 0.05854858458042145,
      "learning_rate": 4.943055555555556e-05,
      "loss": 0.0015,
      "step": 410
    },
    {
      "epoch": 0.023333333333333334,
      "grad_norm": 0.05181233584880829,
      "learning_rate": 4.9416666666666664e-05,
      "loss": 0.0013,
      "step": 420
    },
    {
      "epoch": 0.02388888888888889,
      "grad_norm": 0.1889706701040268,
      "learning_rate": 4.940277777777778e-05,
      "loss": 0.0014,
      "step": 430
    },
    {
      "epoch": 0.024444444444444446,
      "grad_norm": 0.1347476840019226,
      "learning_rate": 4.938888888888889e-05,
      "loss": 0.0025,
      "step": 440
    },
    {
      "epoch": 0.025,
      "grad_norm": 0.21073544025421143,
      "learning_rate": 4.937500000000001e-05,
      "loss": 0.0014,
      "step": 450
    },
    {
      "epoch": 0.025555555555555557,
      "grad_norm": 0.08632209151983261,
      "learning_rate": 4.936111111111111e-05,
      "loss": 0.002,
      "step": 460
    },
    {
      "epoch": 0.026111111111111113,
      "grad_norm": 0.10864241421222687,
      "learning_rate": 4.9347222222222225e-05,
      "loss": 0.0011,
      "step": 470
    },
    {
      "epoch": 0.02666666666666667,
      "grad_norm": 0.08529824018478394,
      "learning_rate": 4.933333333333334e-05,
      "loss": 0.002,
      "step": 480
    },
    {
      "epoch": 0.02722222222222222,
      "grad_norm": 0.05430835857987404,
      "learning_rate": 4.931944444444444e-05,
      "loss": 0.0017,
      "step": 490
    },
    {
      "epoch": 0.027777777777777776,
      "grad_norm": 0.09273966401815414,
      "learning_rate": 4.930555555555556e-05,
      "loss": 0.0011,
      "step": 500
    },
    {
      "epoch": 0.028333333333333332,
      "grad_norm": 0.15179504454135895,
      "learning_rate": 4.929166666666667e-05,
      "loss": 0.0025,
      "step": 510
    },
    {
      "epoch": 0.028888888888888888,
      "grad_norm": 0.16926676034927368,
      "learning_rate": 4.927777777777778e-05,
      "loss": 0.0015,
      "step": 520
    },
    {
      "epoch": 0.029444444444444443,
      "grad_norm": 0.09093058109283447,
      "learning_rate": 4.926388888888889e-05,
      "loss": 0.0012,
      "step": 530
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.13820970058441162,
      "learning_rate": 4.9250000000000004e-05,
      "loss": 0.0022,
      "step": 540
    },
    {
      "epoch": 0.030555555555555555,
      "grad_norm": 0.1517735868692398,
      "learning_rate": 4.923611111111112e-05,
      "loss": 0.0008,
      "step": 550
    },
    {
      "epoch": 0.03111111111111111,
      "grad_norm": 0.09369909018278122,
      "learning_rate": 4.922222222222222e-05,
      "loss": 0.0026,
      "step": 560
    },
    {
      "epoch": 0.03166666666666667,
      "grad_norm": 0.23468366265296936,
      "learning_rate": 4.9208333333333335e-05,
      "loss": 0.002,
      "step": 570
    },
    {
      "epoch": 0.03222222222222222,
      "grad_norm": 0.19728705286979675,
      "learning_rate": 4.919444444444445e-05,
      "loss": 0.0015,
      "step": 580
    },
    {
      "epoch": 0.03277777777777778,
      "grad_norm": 0.10745009779930115,
      "learning_rate": 4.918055555555556e-05,
      "loss": 0.0017,
      "step": 590
    },
    {
      "epoch": 0.03333333333333333,
      "grad_norm": 0.10571596771478653,
      "learning_rate": 4.9166666666666665e-05,
      "loss": 0.0009,
      "step": 600
    },
    {
      "epoch": 0.03388888888888889,
      "grad_norm": 0.12340801954269409,
      "learning_rate": 4.9152777777777784e-05,
      "loss": 0.0016,
      "step": 610
    },
    {
      "epoch": 0.034444444444444444,
      "grad_norm": 0.06080186367034912,
      "learning_rate": 4.913888888888889e-05,
      "loss": 0.0005,
      "step": 620
    },
    {
      "epoch": 0.035,
      "grad_norm": 0.09517104178667068,
      "learning_rate": 4.9125e-05,
      "loss": 0.0012,
      "step": 630
    },
    {
      "epoch": 0.035555555555555556,
      "grad_norm": 0.22276124358177185,
      "learning_rate": 4.9111111111111114e-05,
      "loss": 0.0025,
      "step": 640
    },
    {
      "epoch": 0.03611111111111111,
      "grad_norm": 0.04428216069936752,
      "learning_rate": 4.909722222222222e-05,
      "loss": 0.0007,
      "step": 650
    },
    {
      "epoch": 0.03666666666666667,
      "grad_norm": 0.08673081547021866,
      "learning_rate": 4.908333333333334e-05,
      "loss": 0.0021,
      "step": 660
    },
    {
      "epoch": 0.03722222222222222,
      "grad_norm": 0.15716511011123657,
      "learning_rate": 4.9069444444444444e-05,
      "loss": 0.0011,
      "step": 670
    },
    {
      "epoch": 0.03777777777777778,
      "grad_norm": 0.2136443853378296,
      "learning_rate": 4.905555555555556e-05,
      "loss": 0.0026,
      "step": 680
    },
    {
      "epoch": 0.03833333333333333,
      "grad_norm": 0.42059841752052307,
      "learning_rate": 4.904166666666667e-05,
      "loss": 0.0014,
      "step": 690
    },
    {
      "epoch": 0.03888888888888889,
      "grad_norm": 0.03063947521150112,
      "learning_rate": 4.902777777777778e-05,
      "loss": 0.0013,
      "step": 700
    },
    {
      "epoch": 0.03944444444444444,
      "grad_norm": 0.22411693632602692,
      "learning_rate": 4.901388888888889e-05,
      "loss": 0.0011,
      "step": 710
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.09761777520179749,
      "learning_rate": 4.9e-05,
      "loss": 0.001,
      "step": 720
    },
    {
      "epoch": 0.04055555555555555,
      "grad_norm": 0.06964189559221268,
      "learning_rate": 4.898611111111112e-05,
      "loss": 0.0011,
      "step": 730
    },
    {
      "epoch": 0.04111111111111111,
      "grad_norm": 0.2209913283586502,
      "learning_rate": 4.897222222222222e-05,
      "loss": 0.0016,
      "step": 740
    },
    {
      "epoch": 0.041666666666666664,
      "grad_norm": 0.06572117656469345,
      "learning_rate": 4.8958333333333335e-05,
      "loss": 0.0012,
      "step": 750
    },
    {
      "epoch": 0.042222222222222223,
      "grad_norm": 0.1250351369380951,
      "learning_rate": 4.894444444444445e-05,
      "loss": 0.0012,
      "step": 760
    },
    {
      "epoch": 0.042777777777777776,
      "grad_norm": 0.0852312222123146,
      "learning_rate": 4.893055555555556e-05,
      "loss": 0.0018,
      "step": 770
    },
    {
      "epoch": 0.043333333333333335,
      "grad_norm": 0.07414595782756805,
      "learning_rate": 4.891666666666667e-05,
      "loss": 0.0019,
      "step": 780
    },
    {
      "epoch": 0.04388888888888889,
      "grad_norm": 0.1089588925242424,
      "learning_rate": 4.890277777777778e-05,
      "loss": 0.0014,
      "step": 790
    },
    {
      "epoch": 0.044444444444444446,
      "grad_norm": 0.16883088648319244,
      "learning_rate": 4.888888888888889e-05,
      "loss": 0.001,
      "step": 800
    },
    {
      "epoch": 0.045,
      "grad_norm": 0.06662166863679886,
      "learning_rate": 4.8875e-05,
      "loss": 0.0017,
      "step": 810
    },
    {
      "epoch": 0.04555555555555556,
      "grad_norm": 0.2813462018966675,
      "learning_rate": 4.8861111111111114e-05,
      "loss": 0.0003,
      "step": 820
    },
    {
      "epoch": 0.04611111111111111,
      "grad_norm": 0.044281113892793655,
      "learning_rate": 4.884722222222222e-05,
      "loss": 0.0015,
      "step": 830
    },
    {
      "epoch": 0.04666666666666667,
      "grad_norm": 0.11121097207069397,
      "learning_rate": 4.883333333333334e-05,
      "loss": 0.002,
      "step": 840
    },
    {
      "epoch": 0.04722222222222222,
      "grad_norm": 0.09461196511983871,
      "learning_rate": 4.8819444444444444e-05,
      "loss": 0.002,
      "step": 850
    },
    {
      "epoch": 0.04777777777777778,
      "grad_norm": 0.0,
      "learning_rate": 4.880555555555556e-05,
      "loss": 0.0008,
      "step": 860
    },
    {
      "epoch": 0.04833333333333333,
      "grad_norm": 0.12678997218608856,
      "learning_rate": 4.879166666666667e-05,
      "loss": 0.0016,
      "step": 870
    },
    {
      "epoch": 0.04888888888888889,
      "grad_norm": 0.19613070785999298,
      "learning_rate": 4.8777777777777775e-05,
      "loss": 0.0017,
      "step": 880
    },
    {
      "epoch": 0.049444444444444444,
      "grad_norm": 0.06245364993810654,
      "learning_rate": 4.8763888888888894e-05,
      "loss": 0.0017,
      "step": 890
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.23889274895191193,
      "learning_rate": 4.875e-05,
      "loss": 0.0018,
      "step": 900
    },
    {
      "epoch": 0.050555555555555555,
      "grad_norm": 0.0,
      "learning_rate": 4.873611111111112e-05,
      "loss": 0.0022,
      "step": 910
    },
    {
      "epoch": 0.051111111111111114,
      "grad_norm": 0.1562328040599823,
      "learning_rate": 4.8722222222222224e-05,
      "loss": 0.0007,
      "step": 920
    },
    {
      "epoch": 0.051666666666666666,
      "grad_norm": 0.1014988049864769,
      "learning_rate": 4.8708333333333336e-05,
      "loss": 0.0019,
      "step": 930
    },
    {
      "epoch": 0.052222222222222225,
      "grad_norm": 0.0799972340464592,
      "learning_rate": 4.869444444444445e-05,
      "loss": 0.0009,
      "step": 940
    },
    {
      "epoch": 0.05277777777777778,
      "grad_norm": 0.20550045371055603,
      "learning_rate": 4.8680555555555554e-05,
      "loss": 0.0014,
      "step": 950
    },
    {
      "epoch": 0.05333333333333334,
      "grad_norm": 0.17414310574531555,
      "learning_rate": 4.866666666666667e-05,
      "loss": 0.0018,
      "step": 960
    },
    {
      "epoch": 0.05388888888888889,
      "grad_norm": 0.23818045854568481,
      "learning_rate": 4.865277777777778e-05,
      "loss": 0.0006,
      "step": 970
    },
    {
      "epoch": 0.05444444444444444,
      "grad_norm": 0.1263587772846222,
      "learning_rate": 4.863888888888889e-05,
      "loss": 0.0011,
      "step": 980
    },
    {
      "epoch": 0.055,
      "grad_norm": 0.14170043170452118,
      "learning_rate": 4.8625e-05,
      "loss": 0.0013,
      "step": 990
    },
    {
      "epoch": 0.05555555555555555,
      "grad_norm": 0.1978605091571808,
      "learning_rate": 4.8611111111111115e-05,
      "loss": 0.0013,
      "step": 1000
    },
    {
      "epoch": 0.05611111111111111,
      "grad_norm": 0.08812462538480759,
      "learning_rate": 4.859722222222223e-05,
      "loss": 0.0014,
      "step": 1010
    },
    {
      "epoch": 0.056666666666666664,
      "grad_norm": 0.12575578689575195,
      "learning_rate": 4.858333333333333e-05,
      "loss": 0.0019,
      "step": 1020
    },
    {
      "epoch": 0.05722222222222222,
      "grad_norm": 0.13826002180576324,
      "learning_rate": 4.8569444444444445e-05,
      "loss": 0.0013,
      "step": 1030
    },
    {
      "epoch": 0.057777777777777775,
      "grad_norm": 0.21603915095329285,
      "learning_rate": 4.855555555555556e-05,
      "loss": 0.0021,
      "step": 1040
    },
    {
      "epoch": 0.058333333333333334,
      "grad_norm": 0.03554252162575722,
      "learning_rate": 4.854166666666667e-05,
      "loss": 0.0009,
      "step": 1050
    },
    {
      "epoch": 0.058888888888888886,
      "grad_norm": 0.254773885011673,
      "learning_rate": 4.8527777777777775e-05,
      "loss": 0.0018,
      "step": 1060
    },
    {
      "epoch": 0.059444444444444446,
      "grad_norm": 0.0984562486410141,
      "learning_rate": 4.8513888888888894e-05,
      "loss": 0.0028,
      "step": 1070
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.20765148103237152,
      "learning_rate": 4.85e-05,
      "loss": 0.0021,
      "step": 1080
    },
    {
      "epoch": 0.06055555555555556,
      "grad_norm": 0.10445055365562439,
      "learning_rate": 4.848611111111111e-05,
      "loss": 0.0011,
      "step": 1090
    },
    {
      "epoch": 0.06111111111111111,
      "grad_norm": 0.0,
      "learning_rate": 4.8472222222222224e-05,
      "loss": 0.0017,
      "step": 1100
    },
    {
      "epoch": 0.06166666666666667,
      "grad_norm": 0.21366293728351593,
      "learning_rate": 4.845833333333334e-05,
      "loss": 0.002,
      "step": 1110
    },
    {
      "epoch": 0.06222222222222222,
      "grad_norm": 0.0813857764005661,
      "learning_rate": 4.844444444444445e-05,
      "loss": 0.0015,
      "step": 1120
    },
    {
      "epoch": 0.06277777777777778,
      "grad_norm": 0.2866953909397125,
      "learning_rate": 4.8430555555555554e-05,
      "loss": 0.0018,
      "step": 1130
    },
    {
      "epoch": 0.06333333333333334,
      "grad_norm": 0.18661879003047943,
      "learning_rate": 4.8416666666666673e-05,
      "loss": 0.0012,
      "step": 1140
    },
    {
      "epoch": 0.06388888888888888,
      "grad_norm": 0.09285517036914825,
      "learning_rate": 4.840277777777778e-05,
      "loss": 0.0018,
      "step": 1150
    },
    {
      "epoch": 0.06444444444444444,
      "grad_norm": 0.06609050929546356,
      "learning_rate": 4.838888888888889e-05,
      "loss": 0.0011,
      "step": 1160
    },
    {
      "epoch": 0.065,
      "grad_norm": 0.07352831959724426,
      "learning_rate": 4.8375000000000004e-05,
      "loss": 0.0009,
      "step": 1170
    },
    {
      "epoch": 0.06555555555555556,
      "grad_norm": 0.0,
      "learning_rate": 4.8361111111111116e-05,
      "loss": 0.0011,
      "step": 1180
    },
    {
      "epoch": 0.0661111111111111,
      "grad_norm": 0.041592858731746674,
      "learning_rate": 4.834722222222223e-05,
      "loss": 0.001,
      "step": 1190
    },
    {
      "epoch": 0.06666666666666667,
      "grad_norm": 0.14084070920944214,
      "learning_rate": 4.8333333333333334e-05,
      "loss": 0.001,
      "step": 1200
    },
    {
      "epoch": 0.06722222222222222,
      "grad_norm": 0.0,
      "learning_rate": 4.8319444444444446e-05,
      "loss": 0.0026,
      "step": 1210
    },
    {
      "epoch": 0.06777777777777778,
      "grad_norm": 0.0,
      "learning_rate": 4.830555555555556e-05,
      "loss": 0.0009,
      "step": 1220
    },
    {
      "epoch": 0.06833333333333333,
      "grad_norm": 0.09814096987247467,
      "learning_rate": 4.829166666666667e-05,
      "loss": 0.0019,
      "step": 1230
    },
    {
      "epoch": 0.06888888888888889,
      "grad_norm": 0.04134692624211311,
      "learning_rate": 4.8277777777777776e-05,
      "loss": 0.0011,
      "step": 1240
    },
    {
      "epoch": 0.06944444444444445,
      "grad_norm": 0.19329267740249634,
      "learning_rate": 4.8263888888888895e-05,
      "loss": 0.0016,
      "step": 1250
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.11557386070489883,
      "learning_rate": 4.825e-05,
      "loss": 0.0008,
      "step": 1260
    },
    {
      "epoch": 0.07055555555555555,
      "grad_norm": 0.1774863451719284,
      "learning_rate": 4.823611111111111e-05,
      "loss": 0.0013,
      "step": 1270
    },
    {
      "epoch": 0.07111111111111111,
      "grad_norm": 0.24271033704280853,
      "learning_rate": 4.8222222222222225e-05,
      "loss": 0.0013,
      "step": 1280
    },
    {
      "epoch": 0.07166666666666667,
      "grad_norm": 0.11590173840522766,
      "learning_rate": 4.820833333333333e-05,
      "loss": 0.0006,
      "step": 1290
    },
    {
      "epoch": 0.07222222222222222,
      "grad_norm": 0.06299872696399689,
      "learning_rate": 4.819444444444445e-05,
      "loss": 0.0004,
      "step": 1300
    },
    {
      "epoch": 0.07277777777777777,
      "grad_norm": 0.0,
      "learning_rate": 4.8180555555555555e-05,
      "loss": 0.0009,
      "step": 1310
    },
    {
      "epoch": 0.07333333333333333,
      "grad_norm": 0.09166835248470306,
      "learning_rate": 4.8166666666666674e-05,
      "loss": 0.003,
      "step": 1320
    },
    {
      "epoch": 0.07388888888888889,
      "grad_norm": 0.041564229875802994,
      "learning_rate": 4.815277777777778e-05,
      "loss": 0.0016,
      "step": 1330
    },
    {
      "epoch": 0.07444444444444444,
      "grad_norm": 0.09311800450086594,
      "learning_rate": 4.813888888888889e-05,
      "loss": 0.0014,
      "step": 1340
    },
    {
      "epoch": 0.075,
      "grad_norm": 0.1927453875541687,
      "learning_rate": 4.8125000000000004e-05,
      "loss": 0.0018,
      "step": 1350
    },
    {
      "epoch": 0.07555555555555556,
      "grad_norm": 0.044826336205005646,
      "learning_rate": 4.811111111111111e-05,
      "loss": 0.0007,
      "step": 1360
    },
    {
      "epoch": 0.07611111111111112,
      "grad_norm": 0.25722554326057434,
      "learning_rate": 4.809722222222223e-05,
      "loss": 0.0008,
      "step": 1370
    },
    {
      "epoch": 0.07666666666666666,
      "grad_norm": 0.07733900845050812,
      "learning_rate": 4.8083333333333334e-05,
      "loss": 0.0011,
      "step": 1380
    },
    {
      "epoch": 0.07722222222222222,
      "grad_norm": 0.08825422823429108,
      "learning_rate": 4.8069444444444447e-05,
      "loss": 0.0013,
      "step": 1390
    },
    {
      "epoch": 0.07777777777777778,
      "grad_norm": 0.19285127520561218,
      "learning_rate": 4.805555555555556e-05,
      "loss": 0.0012,
      "step": 1400
    },
    {
      "epoch": 0.07833333333333334,
      "grad_norm": 0.1295355260372162,
      "learning_rate": 4.804166666666667e-05,
      "loss": 0.0021,
      "step": 1410
    },
    {
      "epoch": 0.07888888888888888,
      "grad_norm": 0.0684913918375969,
      "learning_rate": 4.8027777777777783e-05,
      "loss": 0.0012,
      "step": 1420
    },
    {
      "epoch": 0.07944444444444444,
      "grad_norm": 0.0,
      "learning_rate": 4.801388888888889e-05,
      "loss": 0.0016,
      "step": 1430
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.08514221757650375,
      "learning_rate": 4.8e-05,
      "loss": 0.0006,
      "step": 1440
    },
    {
      "epoch": 0.08055555555555556,
      "grad_norm": 0.09709160029888153,
      "learning_rate": 4.7986111111111113e-05,
      "loss": 0.0015,
      "step": 1450
    },
    {
      "epoch": 0.0811111111111111,
      "grad_norm": 0.052346255630254745,
      "learning_rate": 4.7972222222222226e-05,
      "loss": 0.0016,
      "step": 1460
    },
    {
      "epoch": 0.08166666666666667,
      "grad_norm": 0.11343623697757721,
      "learning_rate": 4.795833333333333e-05,
      "loss": 0.0017,
      "step": 1470
    },
    {
      "epoch": 0.08222222222222222,
      "grad_norm": 0.06407797336578369,
      "learning_rate": 4.794444444444445e-05,
      "loss": 0.0014,
      "step": 1480
    },
    {
      "epoch": 0.08277777777777778,
      "grad_norm": 0.04864949733018875,
      "learning_rate": 4.7930555555555556e-05,
      "loss": 0.001,
      "step": 1490
    },
    {
      "epoch": 0.08333333333333333,
      "grad_norm": 0.13611772656440735,
      "learning_rate": 4.791666666666667e-05,
      "loss": 0.0006,
      "step": 1500
    },
    {
      "epoch": 0.08388888888888889,
      "grad_norm": 0.23858097195625305,
      "learning_rate": 4.790277777777778e-05,
      "loss": 0.0012,
      "step": 1510
    },
    {
      "epoch": 0.08444444444444445,
      "grad_norm": 0.17619480192661285,
      "learning_rate": 4.7888888888888886e-05,
      "loss": 0.0023,
      "step": 1520
    },
    {
      "epoch": 0.085,
      "grad_norm": 0.05234801024198532,
      "learning_rate": 4.7875000000000005e-05,
      "loss": 0.0018,
      "step": 1530
    },
    {
      "epoch": 0.08555555555555555,
      "grad_norm": 0.19175344705581665,
      "learning_rate": 4.786111111111111e-05,
      "loss": 0.0012,
      "step": 1540
    },
    {
      "epoch": 0.08611111111111111,
      "grad_norm": 0.23310987651348114,
      "learning_rate": 4.784722222222223e-05,
      "loss": 0.0011,
      "step": 1550
    },
    {
      "epoch": 0.08666666666666667,
      "grad_norm": 0.12238997966051102,
      "learning_rate": 4.7833333333333335e-05,
      "loss": 0.0013,
      "step": 1560
    },
    {
      "epoch": 0.08722222222222223,
      "grad_norm": 0.1845260113477707,
      "learning_rate": 4.781944444444445e-05,
      "loss": 0.0021,
      "step": 1570
    },
    {
      "epoch": 0.08777777777777777,
      "grad_norm": 0.04134557768702507,
      "learning_rate": 4.780555555555556e-05,
      "loss": 0.0015,
      "step": 1580
    },
    {
      "epoch": 0.08833333333333333,
      "grad_norm": 0.11119456589221954,
      "learning_rate": 4.7791666666666665e-05,
      "loss": 0.0022,
      "step": 1590
    },
    {
      "epoch": 0.08888888888888889,
      "grad_norm": 0.04403148964047432,
      "learning_rate": 4.7777777777777784e-05,
      "loss": 0.0015,
      "step": 1600
    },
    {
      "epoch": 0.08944444444444444,
      "grad_norm": 0.276980996131897,
      "learning_rate": 4.776388888888889e-05,
      "loss": 0.003,
      "step": 1610
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.08932390064001083,
      "learning_rate": 4.775e-05,
      "loss": 0.001,
      "step": 1620
    },
    {
      "epoch": 0.09055555555555556,
      "grad_norm": 0.20157462358474731,
      "learning_rate": 4.7736111111111114e-05,
      "loss": 0.0012,
      "step": 1630
    },
    {
      "epoch": 0.09111111111111111,
      "grad_norm": 0.2977445423603058,
      "learning_rate": 4.7722222222222226e-05,
      "loss": 0.0024,
      "step": 1640
    },
    {
      "epoch": 0.09166666666666666,
      "grad_norm": 0.08850123733282089,
      "learning_rate": 4.770833333333334e-05,
      "loss": 0.0009,
      "step": 1650
    },
    {
      "epoch": 0.09222222222222222,
      "grad_norm": 0.05672243982553482,
      "learning_rate": 4.7694444444444444e-05,
      "loss": 0.0011,
      "step": 1660
    },
    {
      "epoch": 0.09277777777777778,
      "grad_norm": 0.0,
      "learning_rate": 4.7680555555555557e-05,
      "loss": 0.002,
      "step": 1670
    },
    {
      "epoch": 0.09333333333333334,
      "grad_norm": 0.047325484454631805,
      "learning_rate": 4.766666666666667e-05,
      "loss": 0.0019,
      "step": 1680
    },
    {
      "epoch": 0.09388888888888888,
      "grad_norm": 0.2561717629432678,
      "learning_rate": 4.765277777777778e-05,
      "loss": 0.0014,
      "step": 1690
    },
    {
      "epoch": 0.09444444444444444,
      "grad_norm": 0.10735809057950974,
      "learning_rate": 4.7638888888888887e-05,
      "loss": 0.0019,
      "step": 1700
    },
    {
      "epoch": 0.095,
      "grad_norm": 0.08446011692285538,
      "learning_rate": 4.7625000000000006e-05,
      "loss": 0.0009,
      "step": 1710
    },
    {
      "epoch": 0.09555555555555556,
      "grad_norm": 0.3647388219833374,
      "learning_rate": 4.761111111111111e-05,
      "loss": 0.0019,
      "step": 1720
    },
    {
      "epoch": 0.0961111111111111,
      "grad_norm": 0.0,
      "learning_rate": 4.7597222222222223e-05,
      "loss": 0.0005,
      "step": 1730
    },
    {
      "epoch": 0.09666666666666666,
      "grad_norm": 0.2196165919303894,
      "learning_rate": 4.7583333333333336e-05,
      "loss": 0.0017,
      "step": 1740
    },
    {
      "epoch": 0.09722222222222222,
      "grad_norm": 0.1914108842611313,
      "learning_rate": 4.756944444444444e-05,
      "loss": 0.0012,
      "step": 1750
    },
    {
      "epoch": 0.09777777777777778,
      "grad_norm": 0.10699748992919922,
      "learning_rate": 4.755555555555556e-05,
      "loss": 0.0017,
      "step": 1760
    },
    {
      "epoch": 0.09833333333333333,
      "grad_norm": 0.0767059400677681,
      "learning_rate": 4.7541666666666666e-05,
      "loss": 0.0016,
      "step": 1770
    },
    {
      "epoch": 0.09888888888888889,
      "grad_norm": 0.0,
      "learning_rate": 4.7527777777777785e-05,
      "loss": 0.0016,
      "step": 1780
    },
    {
      "epoch": 0.09944444444444445,
      "grad_norm": 0.22016537189483643,
      "learning_rate": 4.751388888888889e-05,
      "loss": 0.0016,
      "step": 1790
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.09496558457612991,
      "learning_rate": 4.75e-05,
      "loss": 0.0013,
      "step": 1800
    },
    {
      "epoch": 0.10055555555555555,
      "grad_norm": 0.16782048344612122,
      "learning_rate": 4.7486111111111115e-05,
      "loss": 0.0004,
      "step": 1810
    },
    {
      "epoch": 0.10111111111111111,
      "grad_norm": 0.08619905263185501,
      "learning_rate": 4.747222222222222e-05,
      "loss": 0.0013,
      "step": 1820
    },
    {
      "epoch": 0.10166666666666667,
      "grad_norm": 0.09642317146062851,
      "learning_rate": 4.745833333333334e-05,
      "loss": 0.0006,
      "step": 1830
    },
    {
      "epoch": 0.10222222222222223,
      "grad_norm": 0.08841625601053238,
      "learning_rate": 4.7444444444444445e-05,
      "loss": 0.0011,
      "step": 1840
    },
    {
      "epoch": 0.10277777777777777,
      "grad_norm": 0.0,
      "learning_rate": 4.743055555555556e-05,
      "loss": 0.0008,
      "step": 1850
    },
    {
      "epoch": 0.10333333333333333,
      "grad_norm": 0.1390950232744217,
      "learning_rate": 4.741666666666667e-05,
      "loss": 0.0016,
      "step": 1860
    },
    {
      "epoch": 0.10388888888888889,
      "grad_norm": 0.10879552364349365,
      "learning_rate": 4.740277777777778e-05,
      "loss": 0.0011,
      "step": 1870
    },
    {
      "epoch": 0.10444444444444445,
      "grad_norm": 0.3119143843650818,
      "learning_rate": 4.7388888888888894e-05,
      "loss": 0.0014,
      "step": 1880
    },
    {
      "epoch": 0.105,
      "grad_norm": 0.0,
      "learning_rate": 4.7375e-05,
      "loss": 0.0007,
      "step": 1890
    },
    {
      "epoch": 0.10555555555555556,
      "grad_norm": 0.06702353060245514,
      "learning_rate": 4.736111111111111e-05,
      "loss": 0.0015,
      "step": 1900
    },
    {
      "epoch": 0.10611111111111111,
      "grad_norm": 0.12385260313749313,
      "learning_rate": 4.7347222222222224e-05,
      "loss": 0.0027,
      "step": 1910
    },
    {
      "epoch": 0.10666666666666667,
      "grad_norm": 0.24376052618026733,
      "learning_rate": 4.7333333333333336e-05,
      "loss": 0.0006,
      "step": 1920
    },
    {
      "epoch": 0.10722222222222222,
      "grad_norm": 0.045376330614089966,
      "learning_rate": 4.731944444444444e-05,
      "loss": 0.0022,
      "step": 1930
    },
    {
      "epoch": 0.10777777777777778,
      "grad_norm": 0.0,
      "learning_rate": 4.730555555555556e-05,
      "loss": 0.0016,
      "step": 1940
    },
    {
      "epoch": 0.10833333333333334,
      "grad_norm": 0.1096879243850708,
      "learning_rate": 4.7291666666666666e-05,
      "loss": 0.0015,
      "step": 1950
    },
    {
      "epoch": 0.10888888888888888,
      "grad_norm": 0.05118265002965927,
      "learning_rate": 4.727777777777778e-05,
      "loss": 0.0005,
      "step": 1960
    },
    {
      "epoch": 0.10944444444444444,
      "grad_norm": 0.11787282675504684,
      "learning_rate": 4.726388888888889e-05,
      "loss": 0.0023,
      "step": 1970
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.2266112118959427,
      "learning_rate": 4.7249999999999997e-05,
      "loss": 0.0017,
      "step": 1980
    },
    {
      "epoch": 0.11055555555555556,
      "grad_norm": 0.13251428306102753,
      "learning_rate": 4.7236111111111116e-05,
      "loss": 0.0018,
      "step": 1990
    },
    {
      "epoch": 0.1111111111111111,
      "grad_norm": 0.2565540373325348,
      "learning_rate": 4.722222222222222e-05,
      "loss": 0.0016,
      "step": 2000
    },
    {
      "epoch": 0.11166666666666666,
      "grad_norm": 0.11269671469926834,
      "learning_rate": 4.720833333333334e-05,
      "loss": 0.0018,
      "step": 2010
    },
    {
      "epoch": 0.11222222222222222,
      "grad_norm": 0.2062688171863556,
      "learning_rate": 4.7194444444444446e-05,
      "loss": 0.0008,
      "step": 2020
    },
    {
      "epoch": 0.11277777777777778,
      "grad_norm": 0.26658186316490173,
      "learning_rate": 4.718055555555556e-05,
      "loss": 0.002,
      "step": 2030
    },
    {
      "epoch": 0.11333333333333333,
      "grad_norm": 0.1396271139383316,
      "learning_rate": 4.716666666666667e-05,
      "loss": 0.0009,
      "step": 2040
    },
    {
      "epoch": 0.11388888888888889,
      "grad_norm": 0.0850532203912735,
      "learning_rate": 4.7152777777777776e-05,
      "loss": 0.0015,
      "step": 2050
    },
    {
      "epoch": 0.11444444444444445,
      "grad_norm": 0.024757253006100655,
      "learning_rate": 4.7138888888888895e-05,
      "loss": 0.0018,
      "step": 2060
    },
    {
      "epoch": 0.115,
      "grad_norm": 0.07527988404035568,
      "learning_rate": 4.7125e-05,
      "loss": 0.0012,
      "step": 2070
    },
    {
      "epoch": 0.11555555555555555,
      "grad_norm": 0.1691679209470749,
      "learning_rate": 4.711111111111111e-05,
      "loss": 0.0007,
      "step": 2080
    },
    {
      "epoch": 0.11611111111111111,
      "grad_norm": 0.16450347006320953,
      "learning_rate": 4.7097222222222225e-05,
      "loss": 0.0014,
      "step": 2090
    },
    {
      "epoch": 0.11666666666666667,
      "grad_norm": 0.19334560632705688,
      "learning_rate": 4.708333333333334e-05,
      "loss": 0.0018,
      "step": 2100
    },
    {
      "epoch": 0.11722222222222223,
      "grad_norm": 0.12866294384002686,
      "learning_rate": 4.706944444444445e-05,
      "loss": 0.0005,
      "step": 2110
    },
    {
      "epoch": 0.11777777777777777,
      "grad_norm": 0.06636548787355423,
      "learning_rate": 4.7055555555555555e-05,
      "loss": 0.0006,
      "step": 2120
    },
    {
      "epoch": 0.11833333333333333,
      "grad_norm": 0.1409977674484253,
      "learning_rate": 4.704166666666667e-05,
      "loss": 0.0012,
      "step": 2130
    },
    {
      "epoch": 0.11888888888888889,
      "grad_norm": 0.04619329795241356,
      "learning_rate": 4.702777777777778e-05,
      "loss": 0.0012,
      "step": 2140
    },
    {
      "epoch": 0.11944444444444445,
      "grad_norm": 0.11605995148420334,
      "learning_rate": 4.701388888888889e-05,
      "loss": 0.0009,
      "step": 2150
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.11176876723766327,
      "learning_rate": 4.7e-05,
      "loss": 0.002,
      "step": 2160
    },
    {
      "epoch": 0.12055555555555555,
      "grad_norm": 0.04311597719788551,
      "learning_rate": 4.6986111111111116e-05,
      "loss": 0.001,
      "step": 2170
    },
    {
      "epoch": 0.12111111111111111,
      "grad_norm": 0.1759122610092163,
      "learning_rate": 4.697222222222222e-05,
      "loss": 0.002,
      "step": 2180
    },
    {
      "epoch": 0.12166666666666667,
      "grad_norm": 0.043854162096977234,
      "learning_rate": 4.695833333333334e-05,
      "loss": 0.0011,
      "step": 2190
    },
    {
      "epoch": 0.12222222222222222,
      "grad_norm": 0.04996603727340698,
      "learning_rate": 4.6944444444444446e-05,
      "loss": 0.0011,
      "step": 2200
    },
    {
      "epoch": 0.12277777777777778,
      "grad_norm": 0.043234407901763916,
      "learning_rate": 4.693055555555556e-05,
      "loss": 0.0006,
      "step": 2210
    },
    {
      "epoch": 0.12333333333333334,
      "grad_norm": 0.16907081007957458,
      "learning_rate": 4.691666666666667e-05,
      "loss": 0.0009,
      "step": 2220
    },
    {
      "epoch": 0.1238888888888889,
      "grad_norm": 0.17117981612682343,
      "learning_rate": 4.6902777777777776e-05,
      "loss": 0.0008,
      "step": 2230
    },
    {
      "epoch": 0.12444444444444444,
      "grad_norm": 0.0,
      "learning_rate": 4.6888888888888895e-05,
      "loss": 0.0011,
      "step": 2240
    },
    {
      "epoch": 0.125,
      "grad_norm": 0.047656670212745667,
      "learning_rate": 4.6875e-05,
      "loss": 0.0019,
      "step": 2250
    },
    {
      "epoch": 0.12555555555555556,
      "grad_norm": 0.051932550966739655,
      "learning_rate": 4.686111111111111e-05,
      "loss": 0.0004,
      "step": 2260
    },
    {
      "epoch": 0.12611111111111112,
      "grad_norm": 0.05345761030912399,
      "learning_rate": 4.6847222222222226e-05,
      "loss": 0.0013,
      "step": 2270
    },
    {
      "epoch": 0.12666666666666668,
      "grad_norm": 0.11081065237522125,
      "learning_rate": 4.683333333333334e-05,
      "loss": 0.0006,
      "step": 2280
    },
    {
      "epoch": 0.1272222222222222,
      "grad_norm": 0.045131150633096695,
      "learning_rate": 4.681944444444445e-05,
      "loss": 0.0006,
      "step": 2290
    },
    {
      "epoch": 0.12777777777777777,
      "grad_norm": 0.12251117080450058,
      "learning_rate": 4.6805555555555556e-05,
      "loss": 0.0012,
      "step": 2300
    },
    {
      "epoch": 0.12833333333333333,
      "grad_norm": 0.17648378014564514,
      "learning_rate": 4.679166666666667e-05,
      "loss": 0.0007,
      "step": 2310
    },
    {
      "epoch": 0.1288888888888889,
      "grad_norm": 0.042076822370290756,
      "learning_rate": 4.677777777777778e-05,
      "loss": 0.0013,
      "step": 2320
    },
    {
      "epoch": 0.12944444444444445,
      "grad_norm": 0.09427372366189957,
      "learning_rate": 4.676388888888889e-05,
      "loss": 0.0015,
      "step": 2330
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.04133836552500725,
      "learning_rate": 4.6750000000000005e-05,
      "loss": 0.0014,
      "step": 2340
    },
    {
      "epoch": 0.13055555555555556,
      "grad_norm": 0.1160479262471199,
      "learning_rate": 4.673611111111112e-05,
      "loss": 0.0016,
      "step": 2350
    },
    {
      "epoch": 0.13111111111111112,
      "grad_norm": 0.0,
      "learning_rate": 4.672222222222222e-05,
      "loss": 0.0006,
      "step": 2360
    },
    {
      "epoch": 0.13166666666666665,
      "grad_norm": 0.20769758522510529,
      "learning_rate": 4.6708333333333335e-05,
      "loss": 0.002,
      "step": 2370
    },
    {
      "epoch": 0.1322222222222222,
      "grad_norm": 0.0996449813246727,
      "learning_rate": 4.669444444444445e-05,
      "loss": 0.0005,
      "step": 2380
    },
    {
      "epoch": 0.13277777777777777,
      "grad_norm": 0.12987284362316132,
      "learning_rate": 4.668055555555555e-05,
      "loss": 0.002,
      "step": 2390
    },
    {
      "epoch": 0.13333333333333333,
      "grad_norm": 0.05638108029961586,
      "learning_rate": 4.666666666666667e-05,
      "loss": 0.0009,
      "step": 2400
    },
    {
      "epoch": 0.1338888888888889,
      "grad_norm": 0.04376237839460373,
      "learning_rate": 4.665277777777778e-05,
      "loss": 0.0008,
      "step": 2410
    },
    {
      "epoch": 0.13444444444444445,
      "grad_norm": 0.20335601270198822,
      "learning_rate": 4.6638888888888896e-05,
      "loss": 0.0008,
      "step": 2420
    },
    {
      "epoch": 0.135,
      "grad_norm": 0.2010955810546875,
      "learning_rate": 4.6625e-05,
      "loss": 0.0016,
      "step": 2430
    },
    {
      "epoch": 0.13555555555555557,
      "grad_norm": 0.14865027368068695,
      "learning_rate": 4.6611111111111114e-05,
      "loss": 0.0021,
      "step": 2440
    },
    {
      "epoch": 0.1361111111111111,
      "grad_norm": 0.048851750791072845,
      "learning_rate": 4.6597222222222226e-05,
      "loss": 0.0007,
      "step": 2450
    },
    {
      "epoch": 0.13666666666666666,
      "grad_norm": 0.13428190350532532,
      "learning_rate": 4.658333333333333e-05,
      "loss": 0.0011,
      "step": 2460
    },
    {
      "epoch": 0.13722222222222222,
      "grad_norm": 0.1662909984588623,
      "learning_rate": 4.656944444444445e-05,
      "loss": 0.0006,
      "step": 2470
    },
    {
      "epoch": 0.13777777777777778,
      "grad_norm": 0.15404796600341797,
      "learning_rate": 4.6555555555555556e-05,
      "loss": 0.0011,
      "step": 2480
    },
    {
      "epoch": 0.13833333333333334,
      "grad_norm": 0.2274629920721054,
      "learning_rate": 4.654166666666667e-05,
      "loss": 0.0016,
      "step": 2490
    },
    {
      "epoch": 0.1388888888888889,
      "grad_norm": 0.19693511724472046,
      "learning_rate": 4.652777777777778e-05,
      "loss": 0.0011,
      "step": 2500
    },
    {
      "epoch": 0.13944444444444445,
      "grad_norm": 0.12898847460746765,
      "learning_rate": 4.651388888888889e-05,
      "loss": 0.0011,
      "step": 2510
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.14420568943023682,
      "learning_rate": 4.6500000000000005e-05,
      "loss": 0.0007,
      "step": 2520
    },
    {
      "epoch": 0.14055555555555554,
      "grad_norm": 0.2233819216489792,
      "learning_rate": 4.648611111111111e-05,
      "loss": 0.0018,
      "step": 2530
    },
    {
      "epoch": 0.1411111111111111,
      "grad_norm": 0.04530256241559982,
      "learning_rate": 4.647222222222222e-05,
      "loss": 0.0014,
      "step": 2540
    },
    {
      "epoch": 0.14166666666666666,
      "grad_norm": 0.05522354319691658,
      "learning_rate": 4.6458333333333335e-05,
      "loss": 0.0014,
      "step": 2550
    },
    {
      "epoch": 0.14222222222222222,
      "grad_norm": 0.14480659365653992,
      "learning_rate": 4.644444444444445e-05,
      "loss": 0.0008,
      "step": 2560
    },
    {
      "epoch": 0.14277777777777778,
      "grad_norm": 0.048554956912994385,
      "learning_rate": 4.643055555555556e-05,
      "loss": 0.0019,
      "step": 2570
    },
    {
      "epoch": 0.14333333333333334,
      "grad_norm": 0.022212281823158264,
      "learning_rate": 4.641666666666667e-05,
      "loss": 0.001,
      "step": 2580
    },
    {
      "epoch": 0.1438888888888889,
      "grad_norm": 0.04385120049118996,
      "learning_rate": 4.640277777777778e-05,
      "loss": 0.0014,
      "step": 2590
    },
    {
      "epoch": 0.14444444444444443,
      "grad_norm": 0.0,
      "learning_rate": 4.638888888888889e-05,
      "loss": 0.0011,
      "step": 2600
    },
    {
      "epoch": 0.145,
      "grad_norm": 0.058472417294979095,
      "learning_rate": 4.6375e-05,
      "loss": 0.0019,
      "step": 2610
    },
    {
      "epoch": 0.14555555555555555,
      "grad_norm": 0.21360041201114655,
      "learning_rate": 4.636111111111111e-05,
      "loss": 0.0007,
      "step": 2620
    },
    {
      "epoch": 0.1461111111111111,
      "grad_norm": 0.4120817482471466,
      "learning_rate": 4.634722222222223e-05,
      "loss": 0.002,
      "step": 2630
    },
    {
      "epoch": 0.14666666666666667,
      "grad_norm": 0.24517780542373657,
      "learning_rate": 4.633333333333333e-05,
      "loss": 0.002,
      "step": 2640
    },
    {
      "epoch": 0.14722222222222223,
      "grad_norm": 0.05238157510757446,
      "learning_rate": 4.631944444444445e-05,
      "loss": 0.0012,
      "step": 2650
    },
    {
      "epoch": 0.14777777777777779,
      "grad_norm": 0.08763739466667175,
      "learning_rate": 4.630555555555556e-05,
      "loss": 0.0011,
      "step": 2660
    },
    {
      "epoch": 0.14833333333333334,
      "grad_norm": 0.24458423256874084,
      "learning_rate": 4.629166666666667e-05,
      "loss": 0.0009,
      "step": 2670
    },
    {
      "epoch": 0.14888888888888888,
      "grad_norm": 0.048836544156074524,
      "learning_rate": 4.627777777777778e-05,
      "loss": 0.0009,
      "step": 2680
    },
    {
      "epoch": 0.14944444444444444,
      "grad_norm": 0.1622776985168457,
      "learning_rate": 4.626388888888889e-05,
      "loss": 0.0006,
      "step": 2690
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.19752661883831024,
      "learning_rate": 4.6250000000000006e-05,
      "loss": 0.0008,
      "step": 2700
    },
    {
      "epoch": 0.15055555555555555,
      "grad_norm": 0.06844804435968399,
      "learning_rate": 4.623611111111111e-05,
      "loss": 0.001,
      "step": 2710
    },
    {
      "epoch": 0.1511111111111111,
      "grad_norm": 0.43464845418930054,
      "learning_rate": 4.6222222222222224e-05,
      "loss": 0.0015,
      "step": 2720
    },
    {
      "epoch": 0.15166666666666667,
      "grad_norm": 0.043127093464136124,
      "learning_rate": 4.6208333333333336e-05,
      "loss": 0.0017,
      "step": 2730
    },
    {
      "epoch": 0.15222222222222223,
      "grad_norm": 0.0977475568652153,
      "learning_rate": 4.619444444444445e-05,
      "loss": 0.0011,
      "step": 2740
    },
    {
      "epoch": 0.1527777777777778,
      "grad_norm": 0.14474114775657654,
      "learning_rate": 4.618055555555556e-05,
      "loss": 0.0013,
      "step": 2750
    },
    {
      "epoch": 0.15333333333333332,
      "grad_norm": 0.027447624132037163,
      "learning_rate": 4.6166666666666666e-05,
      "loss": 0.0016,
      "step": 2760
    },
    {
      "epoch": 0.15388888888888888,
      "grad_norm": 0.1870274543762207,
      "learning_rate": 4.615277777777778e-05,
      "loss": 0.0018,
      "step": 2770
    },
    {
      "epoch": 0.15444444444444444,
      "grad_norm": 0.15851932764053345,
      "learning_rate": 4.613888888888889e-05,
      "loss": 0.0018,
      "step": 2780
    },
    {
      "epoch": 0.155,
      "grad_norm": 0.23239187896251678,
      "learning_rate": 4.6125e-05,
      "loss": 0.0007,
      "step": 2790
    },
    {
      "epoch": 0.15555555555555556,
      "grad_norm": 0.19545255601406097,
      "learning_rate": 4.6111111111111115e-05,
      "loss": 0.0013,
      "step": 2800
    },
    {
      "epoch": 0.15611111111111112,
      "grad_norm": 0.030549684539437294,
      "learning_rate": 4.609722222222223e-05,
      "loss": 0.0014,
      "step": 2810
    },
    {
      "epoch": 0.15666666666666668,
      "grad_norm": 0.17129439115524292,
      "learning_rate": 4.608333333333333e-05,
      "loss": 0.002,
      "step": 2820
    },
    {
      "epoch": 0.15722222222222224,
      "grad_norm": 0.04472600668668747,
      "learning_rate": 4.6069444444444445e-05,
      "loss": 0.002,
      "step": 2830
    },
    {
      "epoch": 0.15777777777777777,
      "grad_norm": 0.06438078731298447,
      "learning_rate": 4.605555555555556e-05,
      "loss": 0.0018,
      "step": 2840
    },
    {
      "epoch": 0.15833333333333333,
      "grad_norm": 0.12548549473285675,
      "learning_rate": 4.604166666666666e-05,
      "loss": 0.0018,
      "step": 2850
    },
    {
      "epoch": 0.15888888888888889,
      "grad_norm": 0.018897639587521553,
      "learning_rate": 4.602777777777778e-05,
      "loss": 0.0016,
      "step": 2860
    },
    {
      "epoch": 0.15944444444444444,
      "grad_norm": 0.2280125766992569,
      "learning_rate": 4.601388888888889e-05,
      "loss": 0.0017,
      "step": 2870
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.08688093721866608,
      "learning_rate": 4.600000000000001e-05,
      "loss": 0.0013,
      "step": 2880
    },
    {
      "epoch": 0.16055555555555556,
      "grad_norm": 0.04206268489360809,
      "learning_rate": 4.598611111111111e-05,
      "loss": 0.0016,
      "step": 2890
    },
    {
      "epoch": 0.16111111111111112,
      "grad_norm": 0.0,
      "learning_rate": 4.5972222222222225e-05,
      "loss": 0.0001,
      "step": 2900
    },
    {
      "epoch": 0.16166666666666665,
      "grad_norm": 0.1488776057958603,
      "learning_rate": 4.595833333333334e-05,
      "loss": 0.0018,
      "step": 2910
    },
    {
      "epoch": 0.1622222222222222,
      "grad_norm": 0.12610620260238647,
      "learning_rate": 4.594444444444444e-05,
      "loss": 0.0013,
      "step": 2920
    },
    {
      "epoch": 0.16277777777777777,
      "grad_norm": 0.14850565791130066,
      "learning_rate": 4.593055555555556e-05,
      "loss": 0.0005,
      "step": 2930
    },
    {
      "epoch": 0.16333333333333333,
      "grad_norm": 0.37554022669792175,
      "learning_rate": 4.591666666666667e-05,
      "loss": 0.0015,
      "step": 2940
    },
    {
      "epoch": 0.1638888888888889,
      "grad_norm": 0.050578776746988297,
      "learning_rate": 4.590277777777778e-05,
      "loss": 0.0014,
      "step": 2950
    },
    {
      "epoch": 0.16444444444444445,
      "grad_norm": 0.15250346064567566,
      "learning_rate": 4.588888888888889e-05,
      "loss": 0.0011,
      "step": 2960
    },
    {
      "epoch": 0.165,
      "grad_norm": 0.024770863354206085,
      "learning_rate": 4.5875000000000004e-05,
      "loss": 0.0014,
      "step": 2970
    },
    {
      "epoch": 0.16555555555555557,
      "grad_norm": 0.06230470910668373,
      "learning_rate": 4.5861111111111116e-05,
      "loss": 0.0011,
      "step": 2980
    },
    {
      "epoch": 0.1661111111111111,
      "grad_norm": 0.17181241512298584,
      "learning_rate": 4.584722222222222e-05,
      "loss": 0.001,
      "step": 2990
    },
    {
      "epoch": 0.16666666666666666,
      "grad_norm": 0.2157297283411026,
      "learning_rate": 4.5833333333333334e-05,
      "loss": 0.0011,
      "step": 3000
    },
    {
      "epoch": 0.16722222222222222,
      "grad_norm": 0.07653801888227463,
      "learning_rate": 4.5819444444444446e-05,
      "loss": 0.0031,
      "step": 3010
    },
    {
      "epoch": 0.16777777777777778,
      "grad_norm": 0.14998160302639008,
      "learning_rate": 4.580555555555556e-05,
      "loss": 0.0014,
      "step": 3020
    },
    {
      "epoch": 0.16833333333333333,
      "grad_norm": 0.08624674379825592,
      "learning_rate": 4.579166666666667e-05,
      "loss": 0.0008,
      "step": 3030
    },
    {
      "epoch": 0.1688888888888889,
      "grad_norm": 0.11317434906959534,
      "learning_rate": 4.577777777777778e-05,
      "loss": 0.0023,
      "step": 3040
    },
    {
      "epoch": 0.16944444444444445,
      "grad_norm": 0.04652314633131027,
      "learning_rate": 4.576388888888889e-05,
      "loss": 0.0007,
      "step": 3050
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.11097583174705505,
      "learning_rate": 4.575e-05,
      "loss": 0.0013,
      "step": 3060
    },
    {
      "epoch": 0.17055555555555554,
      "grad_norm": 0.13031671941280365,
      "learning_rate": 4.573611111111111e-05,
      "loss": 0.0009,
      "step": 3070
    },
    {
      "epoch": 0.1711111111111111,
      "grad_norm": 0.11824700981378555,
      "learning_rate": 4.572222222222222e-05,
      "loss": 0.001,
      "step": 3080
    },
    {
      "epoch": 0.17166666666666666,
      "grad_norm": 0.0,
      "learning_rate": 4.570833333333334e-05,
      "loss": 0.0007,
      "step": 3090
    },
    {
      "epoch": 0.17222222222222222,
      "grad_norm": 0.2012513130903244,
      "learning_rate": 4.569444444444444e-05,
      "loss": 0.0016,
      "step": 3100
    },
    {
      "epoch": 0.17277777777777778,
      "grad_norm": 0.07792060822248459,
      "learning_rate": 4.568055555555556e-05,
      "loss": 0.0022,
      "step": 3110
    },
    {
      "epoch": 0.17333333333333334,
      "grad_norm": 0.06739712506532669,
      "learning_rate": 4.566666666666667e-05,
      "loss": 0.0015,
      "step": 3120
    },
    {
      "epoch": 0.1738888888888889,
      "grad_norm": 0.08097121864557266,
      "learning_rate": 4.565277777777778e-05,
      "loss": 0.0003,
      "step": 3130
    },
    {
      "epoch": 0.17444444444444446,
      "grad_norm": 0.0846235603094101,
      "learning_rate": 4.563888888888889e-05,
      "loss": 0.0015,
      "step": 3140
    },
    {
      "epoch": 0.175,
      "grad_norm": 0.04506431519985199,
      "learning_rate": 4.5625e-05,
      "loss": 0.0016,
      "step": 3150
    },
    {
      "epoch": 0.17555555555555555,
      "grad_norm": 0.0,
      "learning_rate": 4.561111111111112e-05,
      "loss": 0.0007,
      "step": 3160
    },
    {
      "epoch": 0.1761111111111111,
      "grad_norm": 0.10311377793550491,
      "learning_rate": 4.559722222222222e-05,
      "loss": 0.0022,
      "step": 3170
    },
    {
      "epoch": 0.17666666666666667,
      "grad_norm": 0.2267320454120636,
      "learning_rate": 4.5583333333333335e-05,
      "loss": 0.0008,
      "step": 3180
    },
    {
      "epoch": 0.17722222222222223,
      "grad_norm": 0.04733956977725029,
      "learning_rate": 4.556944444444445e-05,
      "loss": 0.0009,
      "step": 3190
    },
    {
      "epoch": 0.17777777777777778,
      "grad_norm": 0.10310975462198257,
      "learning_rate": 4.555555555555556e-05,
      "loss": 0.0011,
      "step": 3200
    },
    {
      "epoch": 0.17833333333333334,
      "grad_norm": 0.1494600772857666,
      "learning_rate": 4.554166666666667e-05,
      "loss": 0.0011,
      "step": 3210
    },
    {
      "epoch": 0.17888888888888888,
      "grad_norm": 0.11970865726470947,
      "learning_rate": 4.5527777777777784e-05,
      "loss": 0.0011,
      "step": 3220
    },
    {
      "epoch": 0.17944444444444443,
      "grad_norm": 0.0,
      "learning_rate": 4.551388888888889e-05,
      "loss": 0.0008,
      "step": 3230
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.04418062046170235,
      "learning_rate": 4.55e-05,
      "loss": 0.0011,
      "step": 3240
    },
    {
      "epoch": 0.18055555555555555,
      "grad_norm": 0.18555107712745667,
      "learning_rate": 4.5486111111111114e-05,
      "loss": 0.0014,
      "step": 3250
    },
    {
      "epoch": 0.1811111111111111,
      "grad_norm": 0.11714736372232437,
      "learning_rate": 4.5472222222222226e-05,
      "loss": 0.0011,
      "step": 3260
    },
    {
      "epoch": 0.18166666666666667,
      "grad_norm": 0.07559676468372345,
      "learning_rate": 4.545833333333334e-05,
      "loss": 0.0014,
      "step": 3270
    },
    {
      "epoch": 0.18222222222222223,
      "grad_norm": 0.4781271815299988,
      "learning_rate": 4.5444444444444444e-05,
      "loss": 0.0019,
      "step": 3280
    },
    {
      "epoch": 0.1827777777777778,
      "grad_norm": 0.14411339163780212,
      "learning_rate": 4.543055555555556e-05,
      "loss": 0.0005,
      "step": 3290
    },
    {
      "epoch": 0.18333333333333332,
      "grad_norm": 0.05369213595986366,
      "learning_rate": 4.541666666666667e-05,
      "loss": 0.0004,
      "step": 3300
    },
    {
      "epoch": 0.18388888888888888,
      "grad_norm": 0.19657444953918457,
      "learning_rate": 4.540277777777778e-05,
      "loss": 0.0011,
      "step": 3310
    },
    {
      "epoch": 0.18444444444444444,
      "grad_norm": 0.020255042240023613,
      "learning_rate": 4.538888888888889e-05,
      "loss": 0.0013,
      "step": 3320
    },
    {
      "epoch": 0.185,
      "grad_norm": 0.06448888033628464,
      "learning_rate": 4.5375e-05,
      "loss": 0.0015,
      "step": 3330
    },
    {
      "epoch": 0.18555555555555556,
      "grad_norm": 0.23182009160518646,
      "learning_rate": 4.536111111111112e-05,
      "loss": 0.0023,
      "step": 3340
    },
    {
      "epoch": 0.18611111111111112,
      "grad_norm": 0.1458665430545807,
      "learning_rate": 4.534722222222222e-05,
      "loss": 0.0018,
      "step": 3350
    },
    {
      "epoch": 0.18666666666666668,
      "grad_norm": 0.04521891102194786,
      "learning_rate": 4.5333333333333335e-05,
      "loss": 0.0009,
      "step": 3360
    },
    {
      "epoch": 0.18722222222222223,
      "grad_norm": 0.05278720334172249,
      "learning_rate": 4.531944444444445e-05,
      "loss": 0.0014,
      "step": 3370
    },
    {
      "epoch": 0.18777777777777777,
      "grad_norm": 0.22059786319732666,
      "learning_rate": 4.530555555555556e-05,
      "loss": 0.0016,
      "step": 3380
    },
    {
      "epoch": 0.18833333333333332,
      "grad_norm": 0.19364947080612183,
      "learning_rate": 4.529166666666667e-05,
      "loss": 0.0016,
      "step": 3390
    },
    {
      "epoch": 0.18888888888888888,
      "grad_norm": 0.2820834815502167,
      "learning_rate": 4.527777777777778e-05,
      "loss": 0.0017,
      "step": 3400
    },
    {
      "epoch": 0.18944444444444444,
      "grad_norm": 0.12660233676433563,
      "learning_rate": 4.526388888888889e-05,
      "loss": 0.0008,
      "step": 3410
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.15594865381717682,
      "learning_rate": 4.525e-05,
      "loss": 0.0013,
      "step": 3420
    },
    {
      "epoch": 0.19055555555555556,
      "grad_norm": 0.044258639216423035,
      "learning_rate": 4.5236111111111114e-05,
      "loss": 0.0008,
      "step": 3430
    },
    {
      "epoch": 0.19111111111111112,
      "grad_norm": 0.14369720220565796,
      "learning_rate": 4.522222222222223e-05,
      "loss": 0.0024,
      "step": 3440
    },
    {
      "epoch": 0.19166666666666668,
      "grad_norm": 0.09403499215841293,
      "learning_rate": 4.520833333333334e-05,
      "loss": 0.0025,
      "step": 3450
    },
    {
      "epoch": 0.1922222222222222,
      "grad_norm": 0.11034614592790604,
      "learning_rate": 4.5194444444444444e-05,
      "loss": 0.0007,
      "step": 3460
    },
    {
      "epoch": 0.19277777777777777,
      "grad_norm": 0.0,
      "learning_rate": 4.518055555555556e-05,
      "loss": 0.0014,
      "step": 3470
    },
    {
      "epoch": 0.19333333333333333,
      "grad_norm": 0.0,
      "learning_rate": 4.516666666666667e-05,
      "loss": 0.0014,
      "step": 3480
    },
    {
      "epoch": 0.1938888888888889,
      "grad_norm": 0.04899391159415245,
      "learning_rate": 4.5152777777777775e-05,
      "loss": 0.0014,
      "step": 3490
    },
    {
      "epoch": 0.19444444444444445,
      "grad_norm": 0.1239139512181282,
      "learning_rate": 4.5138888888888894e-05,
      "loss": 0.0017,
      "step": 3500
    },
    {
      "epoch": 0.195,
      "grad_norm": 0.3158641457557678,
      "learning_rate": 4.5125e-05,
      "loss": 0.0013,
      "step": 3510
    },
    {
      "epoch": 0.19555555555555557,
      "grad_norm": 0.1771959364414215,
      "learning_rate": 4.511111111111112e-05,
      "loss": 0.001,
      "step": 3520
    },
    {
      "epoch": 0.19611111111111112,
      "grad_norm": 0.2355288863182068,
      "learning_rate": 4.5097222222222224e-05,
      "loss": 0.002,
      "step": 3530
    },
    {
      "epoch": 0.19666666666666666,
      "grad_norm": 0.07472962141036987,
      "learning_rate": 4.5083333333333336e-05,
      "loss": 0.0008,
      "step": 3540
    },
    {
      "epoch": 0.19722222222222222,
      "grad_norm": 0.06808900833129883,
      "learning_rate": 4.506944444444445e-05,
      "loss": 0.0005,
      "step": 3550
    },
    {
      "epoch": 0.19777777777777777,
      "grad_norm": 0.10218286514282227,
      "learning_rate": 4.5055555555555554e-05,
      "loss": 0.0006,
      "step": 3560
    },
    {
      "epoch": 0.19833333333333333,
      "grad_norm": 0.0,
      "learning_rate": 4.504166666666667e-05,
      "loss": 0.0005,
      "step": 3570
    },
    {
      "epoch": 0.1988888888888889,
      "grad_norm": 0.06749949604272842,
      "learning_rate": 4.502777777777778e-05,
      "loss": 0.0005,
      "step": 3580
    },
    {
      "epoch": 0.19944444444444445,
      "grad_norm": 0.0,
      "learning_rate": 4.501388888888889e-05,
      "loss": 0.0005,
      "step": 3590
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.01587950810790062,
      "learning_rate": 4.5e-05,
      "loss": 0.0011,
      "step": 3600
    },
    {
      "epoch": 0.20055555555555554,
      "grad_norm": 0.2615143656730652,
      "learning_rate": 4.4986111111111115e-05,
      "loss": 0.0013,
      "step": 3610
    },
    {
      "epoch": 0.2011111111111111,
      "grad_norm": 0.0,
      "learning_rate": 4.497222222222223e-05,
      "loss": 0.0014,
      "step": 3620
    },
    {
      "epoch": 0.20166666666666666,
      "grad_norm": 0.0493997298181057,
      "learning_rate": 4.495833333333333e-05,
      "loss": 0.0011,
      "step": 3630
    },
    {
      "epoch": 0.20222222222222222,
      "grad_norm": 0.13838425278663635,
      "learning_rate": 4.4944444444444445e-05,
      "loss": 0.0011,
      "step": 3640
    },
    {
      "epoch": 0.20277777777777778,
      "grad_norm": 0.04548271372914314,
      "learning_rate": 4.493055555555556e-05,
      "loss": 0.0012,
      "step": 3650
    },
    {
      "epoch": 0.20333333333333334,
      "grad_norm": 0.043933168053627014,
      "learning_rate": 4.491666666666667e-05,
      "loss": 0.001,
      "step": 3660
    },
    {
      "epoch": 0.2038888888888889,
      "grad_norm": 0.04404500499367714,
      "learning_rate": 4.490277777777778e-05,
      "loss": 0.0009,
      "step": 3670
    },
    {
      "epoch": 0.20444444444444446,
      "grad_norm": 0.21954359114170074,
      "learning_rate": 4.4888888888888894e-05,
      "loss": 0.0014,
      "step": 3680
    },
    {
      "epoch": 0.205,
      "grad_norm": 0.10261605679988861,
      "learning_rate": 4.4875e-05,
      "loss": 0.0007,
      "step": 3690
    },
    {
      "epoch": 0.20555555555555555,
      "grad_norm": 0.06706538796424866,
      "learning_rate": 4.486111111111111e-05,
      "loss": 0.0007,
      "step": 3700
    },
    {
      "epoch": 0.2061111111111111,
      "grad_norm": 0.05597972497344017,
      "learning_rate": 4.4847222222222224e-05,
      "loss": 0.0005,
      "step": 3710
    },
    {
      "epoch": 0.20666666666666667,
      "grad_norm": 0.2680944800376892,
      "learning_rate": 4.483333333333333e-05,
      "loss": 0.0012,
      "step": 3720
    },
    {
      "epoch": 0.20722222222222222,
      "grad_norm": 0.15193872153759003,
      "learning_rate": 4.481944444444445e-05,
      "loss": 0.0011,
      "step": 3730
    },
    {
      "epoch": 0.20777777777777778,
      "grad_norm": 0.12198380380868912,
      "learning_rate": 4.4805555555555554e-05,
      "loss": 0.0015,
      "step": 3740
    },
    {
      "epoch": 0.20833333333333334,
      "grad_norm": 0.21398776769638062,
      "learning_rate": 4.4791666666666673e-05,
      "loss": 0.0018,
      "step": 3750
    },
    {
      "epoch": 0.2088888888888889,
      "grad_norm": 0.14136892557144165,
      "learning_rate": 4.477777777777778e-05,
      "loss": 0.0015,
      "step": 3760
    },
    {
      "epoch": 0.20944444444444443,
      "grad_norm": 0.21122270822525024,
      "learning_rate": 4.476388888888889e-05,
      "loss": 0.0009,
      "step": 3770
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.09185495227575302,
      "learning_rate": 4.4750000000000004e-05,
      "loss": 0.0005,
      "step": 3780
    },
    {
      "epoch": 0.21055555555555555,
      "grad_norm": 0.0,
      "learning_rate": 4.473611111111111e-05,
      "loss": 0.0011,
      "step": 3790
    },
    {
      "epoch": 0.2111111111111111,
      "grad_norm": 0.06563444435596466,
      "learning_rate": 4.472222222222223e-05,
      "loss": 0.0011,
      "step": 3800
    },
    {
      "epoch": 0.21166666666666667,
      "grad_norm": 0.0474337600171566,
      "learning_rate": 4.4708333333333334e-05,
      "loss": 0.0006,
      "step": 3810
    },
    {
      "epoch": 0.21222222222222223,
      "grad_norm": 0.06211578845977783,
      "learning_rate": 4.4694444444444446e-05,
      "loss": 0.0026,
      "step": 3820
    },
    {
      "epoch": 0.2127777777777778,
      "grad_norm": 0.0,
      "learning_rate": 4.468055555555556e-05,
      "loss": 0.0006,
      "step": 3830
    },
    {
      "epoch": 0.21333333333333335,
      "grad_norm": 0.0,
      "learning_rate": 4.466666666666667e-05,
      "loss": 0.001,
      "step": 3840
    },
    {
      "epoch": 0.21388888888888888,
      "grad_norm": 0.08270961046218872,
      "learning_rate": 4.465277777777778e-05,
      "loss": 0.0015,
      "step": 3850
    },
    {
      "epoch": 0.21444444444444444,
      "grad_norm": 0.05275575816631317,
      "learning_rate": 4.463888888888889e-05,
      "loss": 0.0014,
      "step": 3860
    },
    {
      "epoch": 0.215,
      "grad_norm": 0.042354241013526917,
      "learning_rate": 4.4625e-05,
      "loss": 0.0005,
      "step": 3870
    },
    {
      "epoch": 0.21555555555555556,
      "grad_norm": 0.1792570948600769,
      "learning_rate": 4.461111111111111e-05,
      "loss": 0.0021,
      "step": 3880
    },
    {
      "epoch": 0.21611111111111111,
      "grad_norm": 0.0887368842959404,
      "learning_rate": 4.4597222222222225e-05,
      "loss": 0.0011,
      "step": 3890
    },
    {
      "epoch": 0.21666666666666667,
      "grad_norm": 0.22805823385715485,
      "learning_rate": 4.458333333333334e-05,
      "loss": 0.0011,
      "step": 3900
    },
    {
      "epoch": 0.21722222222222223,
      "grad_norm": 0.11946097761392593,
      "learning_rate": 4.456944444444445e-05,
      "loss": 0.0003,
      "step": 3910
    },
    {
      "epoch": 0.21777777777777776,
      "grad_norm": 0.17192108929157257,
      "learning_rate": 4.4555555555555555e-05,
      "loss": 0.0011,
      "step": 3920
    },
    {
      "epoch": 0.21833333333333332,
      "grad_norm": 0.2067430168390274,
      "learning_rate": 4.454166666666667e-05,
      "loss": 0.0009,
      "step": 3930
    },
    {
      "epoch": 0.21888888888888888,
      "grad_norm": 0.046286385506391525,
      "learning_rate": 4.452777777777778e-05,
      "loss": 0.0012,
      "step": 3940
    },
    {
      "epoch": 0.21944444444444444,
      "grad_norm": 0.07555431872606277,
      "learning_rate": 4.4513888888888885e-05,
      "loss": 0.0012,
      "step": 3950
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.09017648547887802,
      "learning_rate": 4.4500000000000004e-05,
      "loss": 0.0027,
      "step": 3960
    },
    {
      "epoch": 0.22055555555555556,
      "grad_norm": 0.09162858873605728,
      "learning_rate": 4.448611111111111e-05,
      "loss": 0.0012,
      "step": 3970
    },
    {
      "epoch": 0.22111111111111112,
      "grad_norm": 0.12783940136432648,
      "learning_rate": 4.447222222222223e-05,
      "loss": 0.0013,
      "step": 3980
    },
    {
      "epoch": 0.22166666666666668,
      "grad_norm": 0.08384612202644348,
      "learning_rate": 4.4458333333333334e-05,
      "loss": 0.0021,
      "step": 3990
    },
    {
      "epoch": 0.2222222222222222,
      "grad_norm": 0.1370377391576767,
      "learning_rate": 4.4444444444444447e-05,
      "loss": 0.0006,
      "step": 4000
    },
    {
      "epoch": 0.22277777777777777,
      "grad_norm": 0.11053536832332611,
      "learning_rate": 4.443055555555556e-05,
      "loss": 0.0012,
      "step": 4010
    },
    {
      "epoch": 0.22333333333333333,
      "grad_norm": 0.04248424619436264,
      "learning_rate": 4.4416666666666664e-05,
      "loss": 0.0021,
      "step": 4020
    },
    {
      "epoch": 0.2238888888888889,
      "grad_norm": 0.24461016058921814,
      "learning_rate": 4.4402777777777783e-05,
      "loss": 0.0014,
      "step": 4030
    },
    {
      "epoch": 0.22444444444444445,
      "grad_norm": 0.04206376522779465,
      "learning_rate": 4.438888888888889e-05,
      "loss": 0.0007,
      "step": 4040
    },
    {
      "epoch": 0.225,
      "grad_norm": 0.059857163578271866,
      "learning_rate": 4.4375e-05,
      "loss": 0.0007,
      "step": 4050
    },
    {
      "epoch": 0.22555555555555556,
      "grad_norm": 0.16056475043296814,
      "learning_rate": 4.4361111111111113e-05,
      "loss": 0.0015,
      "step": 4060
    },
    {
      "epoch": 0.22611111111111112,
      "grad_norm": 0.17272065579891205,
      "learning_rate": 4.4347222222222226e-05,
      "loss": 0.0007,
      "step": 4070
    },
    {
      "epoch": 0.22666666666666666,
      "grad_norm": 0.19919133186340332,
      "learning_rate": 4.433333333333334e-05,
      "loss": 0.0015,
      "step": 4080
    },
    {
      "epoch": 0.22722222222222221,
      "grad_norm": 0.04981708899140358,
      "learning_rate": 4.4319444444444444e-05,
      "loss": 0.0011,
      "step": 4090
    },
    {
      "epoch": 0.22777777777777777,
      "grad_norm": 0.12952813506126404,
      "learning_rate": 4.4305555555555556e-05,
      "loss": 0.0011,
      "step": 4100
    },
    {
      "epoch": 0.22833333333333333,
      "grad_norm": 0.12496473640203476,
      "learning_rate": 4.429166666666667e-05,
      "loss": 0.0008,
      "step": 4110
    },
    {
      "epoch": 0.2288888888888889,
      "grad_norm": 0.04633334279060364,
      "learning_rate": 4.427777777777778e-05,
      "loss": 0.0011,
      "step": 4120
    },
    {
      "epoch": 0.22944444444444445,
      "grad_norm": 0.04489467293024063,
      "learning_rate": 4.426388888888889e-05,
      "loss": 0.0008,
      "step": 4130
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.06079922616481781,
      "learning_rate": 4.4250000000000005e-05,
      "loss": 0.0005,
      "step": 4140
    },
    {
      "epoch": 0.23055555555555557,
      "grad_norm": 0.3462962508201599,
      "learning_rate": 4.423611111111111e-05,
      "loss": 0.0019,
      "step": 4150
    },
    {
      "epoch": 0.2311111111111111,
      "grad_norm": 0.03735419735312462,
      "learning_rate": 4.422222222222222e-05,
      "loss": 0.0012,
      "step": 4160
    },
    {
      "epoch": 0.23166666666666666,
      "grad_norm": 0.2104969024658203,
      "learning_rate": 4.4208333333333335e-05,
      "loss": 0.0024,
      "step": 4170
    },
    {
      "epoch": 0.23222222222222222,
      "grad_norm": 0.08533759415149689,
      "learning_rate": 4.419444444444444e-05,
      "loss": 0.0007,
      "step": 4180
    },
    {
      "epoch": 0.23277777777777778,
      "grad_norm": 0.0,
      "learning_rate": 4.418055555555556e-05,
      "loss": 0.0014,
      "step": 4190
    },
    {
      "epoch": 0.23333333333333334,
      "grad_norm": 0.08553444594144821,
      "learning_rate": 4.4166666666666665e-05,
      "loss": 0.002,
      "step": 4200
    },
    {
      "epoch": 0.2338888888888889,
      "grad_norm": 0.17423906922340393,
      "learning_rate": 4.4152777777777784e-05,
      "loss": 0.001,
      "step": 4210
    },
    {
      "epoch": 0.23444444444444446,
      "grad_norm": 0.09686154127120972,
      "learning_rate": 4.413888888888889e-05,
      "loss": 0.0015,
      "step": 4220
    },
    {
      "epoch": 0.235,
      "grad_norm": 0.12875954806804657,
      "learning_rate": 4.4125e-05,
      "loss": 0.0007,
      "step": 4230
    },
    {
      "epoch": 0.23555555555555555,
      "grad_norm": 0.1685188263654709,
      "learning_rate": 4.4111111111111114e-05,
      "loss": 0.0012,
      "step": 4240
    },
    {
      "epoch": 0.2361111111111111,
      "grad_norm": 0.06500351428985596,
      "learning_rate": 4.4097222222222226e-05,
      "loss": 0.0013,
      "step": 4250
    },
    {
      "epoch": 0.23666666666666666,
      "grad_norm": 0.06810339540243149,
      "learning_rate": 4.408333333333334e-05,
      "loss": 0.0011,
      "step": 4260
    },
    {
      "epoch": 0.23722222222222222,
      "grad_norm": 0.20916306972503662,
      "learning_rate": 4.4069444444444444e-05,
      "loss": 0.0015,
      "step": 4270
    },
    {
      "epoch": 0.23777777777777778,
      "grad_norm": 0.05212758481502533,
      "learning_rate": 4.4055555555555557e-05,
      "loss": 0.0009,
      "step": 4280
    },
    {
      "epoch": 0.23833333333333334,
      "grad_norm": 0.22451604902744293,
      "learning_rate": 4.404166666666667e-05,
      "loss": 0.001,
      "step": 4290
    },
    {
      "epoch": 0.2388888888888889,
      "grad_norm": 0.04594101756811142,
      "learning_rate": 4.402777777777778e-05,
      "loss": 0.001,
      "step": 4300
    },
    {
      "epoch": 0.23944444444444443,
      "grad_norm": 0.09669379889965057,
      "learning_rate": 4.401388888888889e-05,
      "loss": 0.0014,
      "step": 4310
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.05664478987455368,
      "learning_rate": 4.4000000000000006e-05,
      "loss": 0.0009,
      "step": 4320
    },
    {
      "epoch": 0.24055555555555555,
      "grad_norm": 0.0,
      "learning_rate": 4.398611111111111e-05,
      "loss": 0.0005,
      "step": 4330
    },
    {
      "epoch": 0.2411111111111111,
      "grad_norm": 0.16012504696846008,
      "learning_rate": 4.3972222222222223e-05,
      "loss": 0.0007,
      "step": 4340
    },
    {
      "epoch": 0.24166666666666667,
      "grad_norm": 0.03608764335513115,
      "learning_rate": 4.3958333333333336e-05,
      "loss": 0.0004,
      "step": 4350
    },
    {
      "epoch": 0.24222222222222223,
      "grad_norm": 0.025991257280111313,
      "learning_rate": 4.394444444444445e-05,
      "loss": 0.0012,
      "step": 4360
    },
    {
      "epoch": 0.2427777777777778,
      "grad_norm": 0.0,
      "learning_rate": 4.393055555555556e-05,
      "loss": 0.0004,
      "step": 4370
    },
    {
      "epoch": 0.24333333333333335,
      "grad_norm": 0.0,
      "learning_rate": 4.3916666666666666e-05,
      "loss": 0.0008,
      "step": 4380
    },
    {
      "epoch": 0.24388888888888888,
      "grad_norm": 0.0878094956278801,
      "learning_rate": 4.3902777777777785e-05,
      "loss": 0.0011,
      "step": 4390
    },
    {
      "epoch": 0.24444444444444444,
      "grad_norm": 0.3202565014362335,
      "learning_rate": 4.388888888888889e-05,
      "loss": 0.0016,
      "step": 4400
    },
    {
      "epoch": 0.245,
      "grad_norm": 0.08014269918203354,
      "learning_rate": 4.3875e-05,
      "loss": 0.0012,
      "step": 4410
    },
    {
      "epoch": 0.24555555555555555,
      "grad_norm": 0.2436593621969223,
      "learning_rate": 4.3861111111111115e-05,
      "loss": 0.0008,
      "step": 4420
    },
    {
      "epoch": 0.2461111111111111,
      "grad_norm": 0.0,
      "learning_rate": 4.384722222222222e-05,
      "loss": 0.0023,
      "step": 4430
    },
    {
      "epoch": 0.24666666666666667,
      "grad_norm": 0.23430722951889038,
      "learning_rate": 4.383333333333334e-05,
      "loss": 0.0014,
      "step": 4440
    },
    {
      "epoch": 0.24722222222222223,
      "grad_norm": 0.045330341905355453,
      "learning_rate": 4.3819444444444445e-05,
      "loss": 0.0009,
      "step": 4450
    },
    {
      "epoch": 0.2477777777777778,
      "grad_norm": 0.10867984592914581,
      "learning_rate": 4.380555555555556e-05,
      "loss": 0.0011,
      "step": 4460
    },
    {
      "epoch": 0.24833333333333332,
      "grad_norm": 0.04473796486854553,
      "learning_rate": 4.379166666666667e-05,
      "loss": 0.0009,
      "step": 4470
    },
    {
      "epoch": 0.24888888888888888,
      "grad_norm": 0.0,
      "learning_rate": 4.377777777777778e-05,
      "loss": 0.0011,
      "step": 4480
    },
    {
      "epoch": 0.24944444444444444,
      "grad_norm": 0.0,
      "learning_rate": 4.3763888888888894e-05,
      "loss": 0.0008,
      "step": 4490
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.09204942733049393,
      "learning_rate": 4.375e-05,
      "loss": 0.0012,
      "step": 4500
    },
    {
      "epoch": 0.25055555555555553,
      "grad_norm": 0.050554174929857254,
      "learning_rate": 4.373611111111111e-05,
      "loss": 0.0009,
      "step": 4510
    },
    {
      "epoch": 0.2511111111111111,
      "grad_norm": 0.26795440912246704,
      "learning_rate": 4.3722222222222224e-05,
      "loss": 0.0011,
      "step": 4520
    },
    {
      "epoch": 0.25166666666666665,
      "grad_norm": 0.04789755865931511,
      "learning_rate": 4.3708333333333336e-05,
      "loss": 0.0004,
      "step": 4530
    },
    {
      "epoch": 0.25222222222222224,
      "grad_norm": 0.11800418049097061,
      "learning_rate": 4.369444444444445e-05,
      "loss": 0.002,
      "step": 4540
    },
    {
      "epoch": 0.25277777777777777,
      "grad_norm": 0.029730359092354774,
      "learning_rate": 4.368055555555556e-05,
      "loss": 0.0011,
      "step": 4550
    },
    {
      "epoch": 0.25333333333333335,
      "grad_norm": 0.0993431955575943,
      "learning_rate": 4.3666666666666666e-05,
      "loss": 0.0009,
      "step": 4560
    },
    {
      "epoch": 0.2538888888888889,
      "grad_norm": 0.12729986011981964,
      "learning_rate": 4.365277777777778e-05,
      "loss": 0.0017,
      "step": 4570
    },
    {
      "epoch": 0.2544444444444444,
      "grad_norm": 0.04836089536547661,
      "learning_rate": 4.363888888888889e-05,
      "loss": 0.0016,
      "step": 4580
    },
    {
      "epoch": 0.255,
      "grad_norm": 0.1414177268743515,
      "learning_rate": 4.3625e-05,
      "loss": 0.001,
      "step": 4590
    },
    {
      "epoch": 0.25555555555555554,
      "grad_norm": 0.2383648008108139,
      "learning_rate": 4.3611111111111116e-05,
      "loss": 0.0009,
      "step": 4600
    },
    {
      "epoch": 0.2561111111111111,
      "grad_norm": 0.18543940782546997,
      "learning_rate": 4.359722222222222e-05,
      "loss": 0.0008,
      "step": 4610
    },
    {
      "epoch": 0.25666666666666665,
      "grad_norm": 0.0,
      "learning_rate": 4.358333333333334e-05,
      "loss": 0.0008,
      "step": 4620
    },
    {
      "epoch": 0.25722222222222224,
      "grad_norm": 0.0830816701054573,
      "learning_rate": 4.3569444444444446e-05,
      "loss": 0.001,
      "step": 4630
    },
    {
      "epoch": 0.2577777777777778,
      "grad_norm": 0.0,
      "learning_rate": 4.355555555555556e-05,
      "loss": 0.0004,
      "step": 4640
    },
    {
      "epoch": 0.25833333333333336,
      "grad_norm": 0.03713170439004898,
      "learning_rate": 4.354166666666667e-05,
      "loss": 0.0012,
      "step": 4650
    },
    {
      "epoch": 0.2588888888888889,
      "grad_norm": 0.0,
      "learning_rate": 4.3527777777777776e-05,
      "loss": 0.0012,
      "step": 4660
    },
    {
      "epoch": 0.2594444444444444,
      "grad_norm": 0.12906910479068756,
      "learning_rate": 4.3513888888888895e-05,
      "loss": 0.0029,
      "step": 4670
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.0,
      "learning_rate": 4.35e-05,
      "loss": 0.0006,
      "step": 4680
    },
    {
      "epoch": 0.26055555555555554,
      "grad_norm": 0.046604517847299576,
      "learning_rate": 4.348611111111111e-05,
      "loss": 0.0018,
      "step": 4690
    },
    {
      "epoch": 0.2611111111111111,
      "grad_norm": 0.06350665539503098,
      "learning_rate": 4.3472222222222225e-05,
      "loss": 0.0005,
      "step": 4700
    },
    {
      "epoch": 0.26166666666666666,
      "grad_norm": 0.35064104199409485,
      "learning_rate": 4.345833333333334e-05,
      "loss": 0.0008,
      "step": 4710
    },
    {
      "epoch": 0.26222222222222225,
      "grad_norm": 0.08631102740764618,
      "learning_rate": 4.344444444444445e-05,
      "loss": 0.001,
      "step": 4720
    },
    {
      "epoch": 0.2627777777777778,
      "grad_norm": 0.06293617188930511,
      "learning_rate": 4.3430555555555555e-05,
      "loss": 0.0009,
      "step": 4730
    },
    {
      "epoch": 0.2633333333333333,
      "grad_norm": 0.043325845152139664,
      "learning_rate": 4.341666666666667e-05,
      "loss": 0.001,
      "step": 4740
    },
    {
      "epoch": 0.2638888888888889,
      "grad_norm": 0.16450135409832,
      "learning_rate": 4.340277777777778e-05,
      "loss": 0.0019,
      "step": 4750
    },
    {
      "epoch": 0.2644444444444444,
      "grad_norm": 0.08619103580713272,
      "learning_rate": 4.338888888888889e-05,
      "loss": 0.0013,
      "step": 4760
    },
    {
      "epoch": 0.265,
      "grad_norm": 0.15912406146526337,
      "learning_rate": 4.3375000000000004e-05,
      "loss": 0.0012,
      "step": 4770
    },
    {
      "epoch": 0.26555555555555554,
      "grad_norm": 0.32904329895973206,
      "learning_rate": 4.3361111111111116e-05,
      "loss": 0.0016,
      "step": 4780
    },
    {
      "epoch": 0.26611111111111113,
      "grad_norm": 0.04443827271461487,
      "learning_rate": 4.334722222222222e-05,
      "loss": 0.0016,
      "step": 4790
    },
    {
      "epoch": 0.26666666666666666,
      "grad_norm": 0.09281299263238907,
      "learning_rate": 4.3333333333333334e-05,
      "loss": 0.0013,
      "step": 4800
    },
    {
      "epoch": 0.26722222222222225,
      "grad_norm": 0.22983606159687042,
      "learning_rate": 4.3319444444444446e-05,
      "loss": 0.0007,
      "step": 4810
    },
    {
      "epoch": 0.2677777777777778,
      "grad_norm": 0.0,
      "learning_rate": 4.330555555555556e-05,
      "loss": 0.001,
      "step": 4820
    },
    {
      "epoch": 0.2683333333333333,
      "grad_norm": 0.1130390614271164,
      "learning_rate": 4.329166666666667e-05,
      "loss": 0.0008,
      "step": 4830
    },
    {
      "epoch": 0.2688888888888889,
      "grad_norm": 0.04505636543035507,
      "learning_rate": 4.3277777777777776e-05,
      "loss": 0.0008,
      "step": 4840
    },
    {
      "epoch": 0.26944444444444443,
      "grad_norm": 0.04498416930437088,
      "learning_rate": 4.3263888888888895e-05,
      "loss": 0.0006,
      "step": 4850
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.041936036199331284,
      "learning_rate": 4.325e-05,
      "loss": 0.0013,
      "step": 4860
    },
    {
      "epoch": 0.27055555555555555,
      "grad_norm": 0.04513545334339142,
      "learning_rate": 4.323611111111111e-05,
      "loss": 0.0017,
      "step": 4870
    },
    {
      "epoch": 0.27111111111111114,
      "grad_norm": 0.13832245767116547,
      "learning_rate": 4.3222222222222226e-05,
      "loss": 0.001,
      "step": 4880
    },
    {
      "epoch": 0.27166666666666667,
      "grad_norm": 0.2744121253490448,
      "learning_rate": 4.320833333333333e-05,
      "loss": 0.0015,
      "step": 4890
    },
    {
      "epoch": 0.2722222222222222,
      "grad_norm": 0.046985525637865067,
      "learning_rate": 4.319444444444445e-05,
      "loss": 0.0014,
      "step": 4900
    },
    {
      "epoch": 0.2727777777777778,
      "grad_norm": 0.08192389458417892,
      "learning_rate": 4.3180555555555556e-05,
      "loss": 0.0019,
      "step": 4910
    },
    {
      "epoch": 0.2733333333333333,
      "grad_norm": 0.14751018583774567,
      "learning_rate": 4.316666666666667e-05,
      "loss": 0.0018,
      "step": 4920
    },
    {
      "epoch": 0.2738888888888889,
      "grad_norm": 0.02614673599600792,
      "learning_rate": 4.315277777777778e-05,
      "loss": 0.0011,
      "step": 4930
    },
    {
      "epoch": 0.27444444444444444,
      "grad_norm": 0.0880945548415184,
      "learning_rate": 4.313888888888889e-05,
      "loss": 0.0013,
      "step": 4940
    },
    {
      "epoch": 0.275,
      "grad_norm": 0.4054935574531555,
      "learning_rate": 4.3125000000000005e-05,
      "loss": 0.0013,
      "step": 4950
    },
    {
      "epoch": 0.27555555555555555,
      "grad_norm": 0.08671410381793976,
      "learning_rate": 4.311111111111111e-05,
      "loss": 0.0011,
      "step": 4960
    },
    {
      "epoch": 0.2761111111111111,
      "grad_norm": 0.12808755040168762,
      "learning_rate": 4.309722222222222e-05,
      "loss": 0.0015,
      "step": 4970
    },
    {
      "epoch": 0.27666666666666667,
      "grad_norm": 0.0,
      "learning_rate": 4.3083333333333335e-05,
      "loss": 0.0007,
      "step": 4980
    },
    {
      "epoch": 0.2772222222222222,
      "grad_norm": 0.27151456475257874,
      "learning_rate": 4.306944444444445e-05,
      "loss": 0.0012,
      "step": 4990
    },
    {
      "epoch": 0.2777777777777778,
      "grad_norm": 0.07996869832277298,
      "learning_rate": 4.305555555555556e-05,
      "loss": 0.0007,
      "step": 5000
    },
    {
      "epoch": 0.2783333333333333,
      "grad_norm": 0.050804253667593,
      "learning_rate": 4.304166666666667e-05,
      "loss": 0.0007,
      "step": 5010
    },
    {
      "epoch": 0.2788888888888889,
      "grad_norm": 0.08634942024946213,
      "learning_rate": 4.302777777777778e-05,
      "loss": 0.001,
      "step": 5020
    },
    {
      "epoch": 0.27944444444444444,
      "grad_norm": 0.18353766202926636,
      "learning_rate": 4.301388888888889e-05,
      "loss": 0.0009,
      "step": 5030
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.12422586977481842,
      "learning_rate": 4.3e-05,
      "loss": 0.0009,
      "step": 5040
    },
    {
      "epoch": 0.28055555555555556,
      "grad_norm": 0.0,
      "learning_rate": 4.2986111111111114e-05,
      "loss": 0.0003,
      "step": 5050
    },
    {
      "epoch": 0.2811111111111111,
      "grad_norm": 0.0,
      "learning_rate": 4.2972222222222226e-05,
      "loss": 0.0008,
      "step": 5060
    },
    {
      "epoch": 0.2816666666666667,
      "grad_norm": 0.04407297447323799,
      "learning_rate": 4.295833333333333e-05,
      "loss": 0.001,
      "step": 5070
    },
    {
      "epoch": 0.2822222222222222,
      "grad_norm": 0.31813618540763855,
      "learning_rate": 4.294444444444445e-05,
      "loss": 0.0015,
      "step": 5080
    },
    {
      "epoch": 0.2827777777777778,
      "grad_norm": 0.04334793612360954,
      "learning_rate": 4.2930555555555556e-05,
      "loss": 0.0009,
      "step": 5090
    },
    {
      "epoch": 0.2833333333333333,
      "grad_norm": 0.0,
      "learning_rate": 4.291666666666667e-05,
      "loss": 0.0008,
      "step": 5100
    },
    {
      "epoch": 0.2838888888888889,
      "grad_norm": 0.0439719632267952,
      "learning_rate": 4.290277777777778e-05,
      "loss": 0.002,
      "step": 5110
    },
    {
      "epoch": 0.28444444444444444,
      "grad_norm": 0.07508985698223114,
      "learning_rate": 4.2888888888888886e-05,
      "loss": 0.0012,
      "step": 5120
    },
    {
      "epoch": 0.285,
      "grad_norm": 0.08670218288898468,
      "learning_rate": 4.2875000000000005e-05,
      "loss": 0.0015,
      "step": 5130
    },
    {
      "epoch": 0.28555555555555556,
      "grad_norm": 0.14108708500862122,
      "learning_rate": 4.286111111111111e-05,
      "loss": 0.0008,
      "step": 5140
    },
    {
      "epoch": 0.2861111111111111,
      "grad_norm": 0.04147397726774216,
      "learning_rate": 4.284722222222222e-05,
      "loss": 0.0007,
      "step": 5150
    },
    {
      "epoch": 0.2866666666666667,
      "grad_norm": 0.1652686595916748,
      "learning_rate": 4.2833333333333335e-05,
      "loss": 0.0012,
      "step": 5160
    },
    {
      "epoch": 0.2872222222222222,
      "grad_norm": 0.0,
      "learning_rate": 4.281944444444445e-05,
      "loss": 0.0006,
      "step": 5170
    },
    {
      "epoch": 0.2877777777777778,
      "grad_norm": 0.08986900001764297,
      "learning_rate": 4.280555555555556e-05,
      "loss": 0.0008,
      "step": 5180
    },
    {
      "epoch": 0.28833333333333333,
      "grad_norm": 0.2062220722436905,
      "learning_rate": 4.2791666666666666e-05,
      "loss": 0.0005,
      "step": 5190
    },
    {
      "epoch": 0.28888888888888886,
      "grad_norm": 0.17286227643489838,
      "learning_rate": 4.277777777777778e-05,
      "loss": 0.0009,
      "step": 5200
    },
    {
      "epoch": 0.28944444444444445,
      "grad_norm": 0.2182643860578537,
      "learning_rate": 4.276388888888889e-05,
      "loss": 0.0014,
      "step": 5210
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.0,
      "learning_rate": 4.275e-05,
      "loss": 0.0015,
      "step": 5220
    },
    {
      "epoch": 0.29055555555555557,
      "grad_norm": 0.12523525953292847,
      "learning_rate": 4.2736111111111115e-05,
      "loss": 0.0018,
      "step": 5230
    },
    {
      "epoch": 0.2911111111111111,
      "grad_norm": 0.1914866417646408,
      "learning_rate": 4.272222222222223e-05,
      "loss": 0.0018,
      "step": 5240
    },
    {
      "epoch": 0.2916666666666667,
      "grad_norm": 0.23686069250106812,
      "learning_rate": 4.270833333333333e-05,
      "loss": 0.0008,
      "step": 5250
    },
    {
      "epoch": 0.2922222222222222,
      "grad_norm": 0.05259677767753601,
      "learning_rate": 4.2694444444444445e-05,
      "loss": 0.0011,
      "step": 5260
    },
    {
      "epoch": 0.2927777777777778,
      "grad_norm": 0.056360699236392975,
      "learning_rate": 4.268055555555556e-05,
      "loss": 0.001,
      "step": 5270
    },
    {
      "epoch": 0.29333333333333333,
      "grad_norm": 0.06512630730867386,
      "learning_rate": 4.266666666666667e-05,
      "loss": 0.0008,
      "step": 5280
    },
    {
      "epoch": 0.29388888888888887,
      "grad_norm": 0.052711814641952515,
      "learning_rate": 4.265277777777778e-05,
      "loss": 0.0001,
      "step": 5290
    },
    {
      "epoch": 0.29444444444444445,
      "grad_norm": 0.045755479484796524,
      "learning_rate": 4.263888888888889e-05,
      "loss": 0.0009,
      "step": 5300
    },
    {
      "epoch": 0.295,
      "grad_norm": 0.044603925198316574,
      "learning_rate": 4.2625000000000006e-05,
      "loss": 0.0013,
      "step": 5310
    },
    {
      "epoch": 0.29555555555555557,
      "grad_norm": 0.18579095602035522,
      "learning_rate": 4.261111111111111e-05,
      "loss": 0.0011,
      "step": 5320
    },
    {
      "epoch": 0.2961111111111111,
      "grad_norm": 0.2677452862262726,
      "learning_rate": 4.2597222222222224e-05,
      "loss": 0.0006,
      "step": 5330
    },
    {
      "epoch": 0.2966666666666667,
      "grad_norm": 0.045699868351221085,
      "learning_rate": 4.2583333333333336e-05,
      "loss": 0.001,
      "step": 5340
    },
    {
      "epoch": 0.2972222222222222,
      "grad_norm": 0.04336964711546898,
      "learning_rate": 4.256944444444445e-05,
      "loss": 0.0012,
      "step": 5350
    },
    {
      "epoch": 0.29777777777777775,
      "grad_norm": 0.23853430151939392,
      "learning_rate": 4.255555555555556e-05,
      "loss": 0.0011,
      "step": 5360
    },
    {
      "epoch": 0.29833333333333334,
      "grad_norm": 0.08027826994657516,
      "learning_rate": 4.2541666666666666e-05,
      "loss": 0.0013,
      "step": 5370
    },
    {
      "epoch": 0.29888888888888887,
      "grad_norm": 0.0861554965376854,
      "learning_rate": 4.252777777777778e-05,
      "loss": 0.0007,
      "step": 5380
    },
    {
      "epoch": 0.29944444444444446,
      "grad_norm": 0.0832032710313797,
      "learning_rate": 4.251388888888889e-05,
      "loss": 0.0006,
      "step": 5390
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.1853710561990738,
      "learning_rate": 4.25e-05,
      "loss": 0.0009,
      "step": 5400
    },
    {
      "epoch": 0.3005555555555556,
      "grad_norm": 0.0801519975066185,
      "learning_rate": 4.2486111111111115e-05,
      "loss": 0.0011,
      "step": 5410
    },
    {
      "epoch": 0.3011111111111111,
      "grad_norm": 0.10741277784109116,
      "learning_rate": 4.247222222222223e-05,
      "loss": 0.0016,
      "step": 5420
    },
    {
      "epoch": 0.3016666666666667,
      "grad_norm": 0.0,
      "learning_rate": 4.245833333333333e-05,
      "loss": 0.0012,
      "step": 5430
    },
    {
      "epoch": 0.3022222222222222,
      "grad_norm": 0.20073838531970978,
      "learning_rate": 4.2444444444444445e-05,
      "loss": 0.0015,
      "step": 5440
    },
    {
      "epoch": 0.30277777777777776,
      "grad_norm": 0.0,
      "learning_rate": 4.243055555555556e-05,
      "loss": 0.0003,
      "step": 5450
    },
    {
      "epoch": 0.30333333333333334,
      "grad_norm": 0.11981043219566345,
      "learning_rate": 4.241666666666667e-05,
      "loss": 0.0011,
      "step": 5460
    },
    {
      "epoch": 0.3038888888888889,
      "grad_norm": 0.0,
      "learning_rate": 4.240277777777778e-05,
      "loss": 0.0019,
      "step": 5470
    },
    {
      "epoch": 0.30444444444444446,
      "grad_norm": 0.04471993073821068,
      "learning_rate": 4.238888888888889e-05,
      "loss": 0.0019,
      "step": 5480
    },
    {
      "epoch": 0.305,
      "grad_norm": 0.0,
      "learning_rate": 4.237500000000001e-05,
      "loss": 0.0011,
      "step": 5490
    },
    {
      "epoch": 0.3055555555555556,
      "grad_norm": 0.0,
      "learning_rate": 4.236111111111111e-05,
      "loss": 0.0021,
      "step": 5500
    },
    {
      "epoch": 0.3061111111111111,
      "grad_norm": 0.23917987942695618,
      "learning_rate": 4.2347222222222225e-05,
      "loss": 0.0003,
      "step": 5510
    },
    {
      "epoch": 0.30666666666666664,
      "grad_norm": 0.04399069771170616,
      "learning_rate": 4.233333333333334e-05,
      "loss": 0.0016,
      "step": 5520
    },
    {
      "epoch": 0.30722222222222223,
      "grad_norm": 0.17254148423671722,
      "learning_rate": 4.231944444444444e-05,
      "loss": 0.0013,
      "step": 5530
    },
    {
      "epoch": 0.30777777777777776,
      "grad_norm": 0.04372701048851013,
      "learning_rate": 4.230555555555556e-05,
      "loss": 0.001,
      "step": 5540
    },
    {
      "epoch": 0.30833333333333335,
      "grad_norm": 0.0,
      "learning_rate": 4.229166666666667e-05,
      "loss": 0.0016,
      "step": 5550
    },
    {
      "epoch": 0.3088888888888889,
      "grad_norm": 0.20537596940994263,
      "learning_rate": 4.227777777777778e-05,
      "loss": 0.0008,
      "step": 5560
    },
    {
      "epoch": 0.30944444444444447,
      "grad_norm": 0.06349653005599976,
      "learning_rate": 4.226388888888889e-05,
      "loss": 0.001,
      "step": 5570
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.0,
      "learning_rate": 4.2250000000000004e-05,
      "loss": 0.0009,
      "step": 5580
    },
    {
      "epoch": 0.31055555555555553,
      "grad_norm": 0.07924599200487137,
      "learning_rate": 4.2236111111111116e-05,
      "loss": 0.0007,
      "step": 5590
    },
    {
      "epoch": 0.3111111111111111,
      "grad_norm": 0.04345814138650894,
      "learning_rate": 4.222222222222222e-05,
      "loss": 0.0014,
      "step": 5600
    },
    {
      "epoch": 0.31166666666666665,
      "grad_norm": 0.08651435375213623,
      "learning_rate": 4.2208333333333334e-05,
      "loss": 0.0012,
      "step": 5610
    },
    {
      "epoch": 0.31222222222222223,
      "grad_norm": 0.0,
      "learning_rate": 4.2194444444444446e-05,
      "loss": 0.0008,
      "step": 5620
    },
    {
      "epoch": 0.31277777777777777,
      "grad_norm": 0.08871716260910034,
      "learning_rate": 4.218055555555556e-05,
      "loss": 0.0018,
      "step": 5630
    },
    {
      "epoch": 0.31333333333333335,
      "grad_norm": 0.2549079954624176,
      "learning_rate": 4.216666666666667e-05,
      "loss": 0.0008,
      "step": 5640
    },
    {
      "epoch": 0.3138888888888889,
      "grad_norm": 0.0518987774848938,
      "learning_rate": 4.215277777777778e-05,
      "loss": 0.0012,
      "step": 5650
    },
    {
      "epoch": 0.31444444444444447,
      "grad_norm": 0.2668325901031494,
      "learning_rate": 4.213888888888889e-05,
      "loss": 0.0015,
      "step": 5660
    },
    {
      "epoch": 0.315,
      "grad_norm": 0.21131862699985504,
      "learning_rate": 4.2125e-05,
      "loss": 0.0009,
      "step": 5670
    },
    {
      "epoch": 0.31555555555555553,
      "grad_norm": 0.30188584327697754,
      "learning_rate": 4.211111111111111e-05,
      "loss": 0.0006,
      "step": 5680
    },
    {
      "epoch": 0.3161111111111111,
      "grad_norm": 0.1972581297159195,
      "learning_rate": 4.2097222222222225e-05,
      "loss": 0.001,
      "step": 5690
    },
    {
      "epoch": 0.31666666666666665,
      "grad_norm": 0.0,
      "learning_rate": 4.208333333333334e-05,
      "loss": 0.001,
      "step": 5700
    },
    {
      "epoch": 0.31722222222222224,
      "grad_norm": 0.04433687776327133,
      "learning_rate": 4.206944444444444e-05,
      "loss": 0.0013,
      "step": 5710
    },
    {
      "epoch": 0.31777777777777777,
      "grad_norm": 0.060218695551157,
      "learning_rate": 4.205555555555556e-05,
      "loss": 0.0011,
      "step": 5720
    },
    {
      "epoch": 0.31833333333333336,
      "grad_norm": 0.13459059596061707,
      "learning_rate": 4.204166666666667e-05,
      "loss": 0.0013,
      "step": 5730
    },
    {
      "epoch": 0.3188888888888889,
      "grad_norm": 0.0,
      "learning_rate": 4.202777777777778e-05,
      "loss": 0.0008,
      "step": 5740
    },
    {
      "epoch": 0.3194444444444444,
      "grad_norm": 0.0,
      "learning_rate": 4.201388888888889e-05,
      "loss": 0.0014,
      "step": 5750
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.0,
      "learning_rate": 4.2e-05,
      "loss": 0.0012,
      "step": 5760
    },
    {
      "epoch": 0.32055555555555554,
      "grad_norm": 0.0,
      "learning_rate": 4.198611111111112e-05,
      "loss": 0.0004,
      "step": 5770
    },
    {
      "epoch": 0.3211111111111111,
      "grad_norm": 0.0,
      "learning_rate": 4.197222222222222e-05,
      "loss": 0.0006,
      "step": 5780
    },
    {
      "epoch": 0.32166666666666666,
      "grad_norm": 0.0,
      "learning_rate": 4.1958333333333335e-05,
      "loss": 0.0006,
      "step": 5790
    },
    {
      "epoch": 0.32222222222222224,
      "grad_norm": 0.04506303369998932,
      "learning_rate": 4.194444444444445e-05,
      "loss": 0.0014,
      "step": 5800
    },
    {
      "epoch": 0.3227777777777778,
      "grad_norm": 0.0,
      "learning_rate": 4.193055555555556e-05,
      "loss": 0.0004,
      "step": 5810
    },
    {
      "epoch": 0.3233333333333333,
      "grad_norm": 0.045664627104997635,
      "learning_rate": 4.191666666666667e-05,
      "loss": 0.0014,
      "step": 5820
    },
    {
      "epoch": 0.3238888888888889,
      "grad_norm": 0.04291914775967598,
      "learning_rate": 4.190277777777778e-05,
      "loss": 0.0008,
      "step": 5830
    },
    {
      "epoch": 0.3244444444444444,
      "grad_norm": 0.0,
      "learning_rate": 4.188888888888889e-05,
      "loss": 0.0012,
      "step": 5840
    },
    {
      "epoch": 0.325,
      "grad_norm": 0.04704344645142555,
      "learning_rate": 4.1875e-05,
      "loss": 0.0014,
      "step": 5850
    },
    {
      "epoch": 0.32555555555555554,
      "grad_norm": 0.05401583015918732,
      "learning_rate": 4.1861111111111114e-05,
      "loss": 0.0012,
      "step": 5860
    },
    {
      "epoch": 0.32611111111111113,
      "grad_norm": 0.1756427139043808,
      "learning_rate": 4.1847222222222226e-05,
      "loss": 0.0004,
      "step": 5870
    },
    {
      "epoch": 0.32666666666666666,
      "grad_norm": 0.04890856891870499,
      "learning_rate": 4.183333333333334e-05,
      "loss": 0.0004,
      "step": 5880
    },
    {
      "epoch": 0.32722222222222225,
      "grad_norm": 0.048346228897571564,
      "learning_rate": 4.1819444444444444e-05,
      "loss": 0.0015,
      "step": 5890
    },
    {
      "epoch": 0.3277777777777778,
      "grad_norm": 0.22054284811019897,
      "learning_rate": 4.1805555555555556e-05,
      "loss": 0.001,
      "step": 5900
    },
    {
      "epoch": 0.3283333333333333,
      "grad_norm": 0.34863007068634033,
      "learning_rate": 4.179166666666667e-05,
      "loss": 0.0009,
      "step": 5910
    },
    {
      "epoch": 0.3288888888888889,
      "grad_norm": 0.2758380174636841,
      "learning_rate": 4.177777777777778e-05,
      "loss": 0.0019,
      "step": 5920
    },
    {
      "epoch": 0.32944444444444443,
      "grad_norm": 0.10786734521389008,
      "learning_rate": 4.176388888888889e-05,
      "loss": 0.0029,
      "step": 5930
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.1387997567653656,
      "learning_rate": 4.175e-05,
      "loss": 0.0005,
      "step": 5940
    },
    {
      "epoch": 0.33055555555555555,
      "grad_norm": 0.3193420171737671,
      "learning_rate": 4.173611111111112e-05,
      "loss": 0.0013,
      "step": 5950
    },
    {
      "epoch": 0.33111111111111113,
      "grad_norm": 0.09139847010374069,
      "learning_rate": 4.172222222222222e-05,
      "loss": 0.0006,
      "step": 5960
    },
    {
      "epoch": 0.33166666666666667,
      "grad_norm": 0.0,
      "learning_rate": 4.1708333333333335e-05,
      "loss": 0.0011,
      "step": 5970
    },
    {
      "epoch": 0.3322222222222222,
      "grad_norm": 0.0701657235622406,
      "learning_rate": 4.169444444444445e-05,
      "loss": 0.0004,
      "step": 5980
    },
    {
      "epoch": 0.3327777777777778,
      "grad_norm": 0.10974399745464325,
      "learning_rate": 4.168055555555555e-05,
      "loss": 0.0011,
      "step": 5990
    },
    {
      "epoch": 0.3333333333333333,
      "grad_norm": 0.1177607923746109,
      "learning_rate": 4.166666666666667e-05,
      "loss": 0.0015,
      "step": 6000
    },
    {
      "epoch": 0.3338888888888889,
      "grad_norm": 0.046024929732084274,
      "learning_rate": 4.165277777777778e-05,
      "loss": 0.0013,
      "step": 6010
    },
    {
      "epoch": 0.33444444444444443,
      "grad_norm": 0.034726858139038086,
      "learning_rate": 4.163888888888889e-05,
      "loss": 0.0019,
      "step": 6020
    },
    {
      "epoch": 0.335,
      "grad_norm": 0.1051238626241684,
      "learning_rate": 4.1625e-05,
      "loss": 0.0011,
      "step": 6030
    },
    {
      "epoch": 0.33555555555555555,
      "grad_norm": 0.2063445746898651,
      "learning_rate": 4.1611111111111114e-05,
      "loss": 0.0016,
      "step": 6040
    },
    {
      "epoch": 0.33611111111111114,
      "grad_norm": 0.0437643826007843,
      "learning_rate": 4.159722222222223e-05,
      "loss": 0.0015,
      "step": 6050
    },
    {
      "epoch": 0.33666666666666667,
      "grad_norm": 0.051360324025154114,
      "learning_rate": 4.158333333333333e-05,
      "loss": 0.0016,
      "step": 6060
    },
    {
      "epoch": 0.3372222222222222,
      "grad_norm": 0.12567727267742157,
      "learning_rate": 4.1569444444444444e-05,
      "loss": 0.0019,
      "step": 6070
    },
    {
      "epoch": 0.3377777777777778,
      "grad_norm": 0.05468510463833809,
      "learning_rate": 4.155555555555556e-05,
      "loss": 0.0018,
      "step": 6080
    },
    {
      "epoch": 0.3383333333333333,
      "grad_norm": 0.4276755750179291,
      "learning_rate": 4.154166666666667e-05,
      "loss": 0.0008,
      "step": 6090
    },
    {
      "epoch": 0.3388888888888889,
      "grad_norm": 0.17596054077148438,
      "learning_rate": 4.152777777777778e-05,
      "loss": 0.0011,
      "step": 6100
    },
    {
      "epoch": 0.33944444444444444,
      "grad_norm": 0.08946418762207031,
      "learning_rate": 4.1513888888888894e-05,
      "loss": 0.0016,
      "step": 6110
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.08799098432064056,
      "learning_rate": 4.15e-05,
      "loss": 0.002,
      "step": 6120
    },
    {
      "epoch": 0.34055555555555556,
      "grad_norm": 0.13308341801166534,
      "learning_rate": 4.148611111111111e-05,
      "loss": 0.0024,
      "step": 6130
    },
    {
      "epoch": 0.3411111111111111,
      "grad_norm": 0.12669546902179718,
      "learning_rate": 4.1472222222222224e-05,
      "loss": 0.0011,
      "step": 6140
    },
    {
      "epoch": 0.3416666666666667,
      "grad_norm": 0.1898183971643448,
      "learning_rate": 4.1458333333333336e-05,
      "loss": 0.0012,
      "step": 6150
    },
    {
      "epoch": 0.3422222222222222,
      "grad_norm": 0.38962775468826294,
      "learning_rate": 4.144444444444445e-05,
      "loss": 0.0028,
      "step": 6160
    },
    {
      "epoch": 0.3427777777777778,
      "grad_norm": 0.044469982385635376,
      "learning_rate": 4.1430555555555554e-05,
      "loss": 0.001,
      "step": 6170
    },
    {
      "epoch": 0.3433333333333333,
      "grad_norm": 0.1315256804227829,
      "learning_rate": 4.141666666666667e-05,
      "loss": 0.0013,
      "step": 6180
    },
    {
      "epoch": 0.3438888888888889,
      "grad_norm": 0.049413926899433136,
      "learning_rate": 4.140277777777778e-05,
      "loss": 0.001,
      "step": 6190
    },
    {
      "epoch": 0.34444444444444444,
      "grad_norm": 0.04905727133154869,
      "learning_rate": 4.138888888888889e-05,
      "loss": 0.0016,
      "step": 6200
    },
    {
      "epoch": 0.345,
      "grad_norm": 0.04323756322264671,
      "learning_rate": 4.1375e-05,
      "loss": 0.0019,
      "step": 6210
    },
    {
      "epoch": 0.34555555555555556,
      "grad_norm": 0.18959833681583405,
      "learning_rate": 4.136111111111111e-05,
      "loss": 0.0016,
      "step": 6220
    },
    {
      "epoch": 0.3461111111111111,
      "grad_norm": 0.04629623889923096,
      "learning_rate": 4.134722222222223e-05,
      "loss": 0.001,
      "step": 6230
    },
    {
      "epoch": 0.3466666666666667,
      "grad_norm": 0.1995828002691269,
      "learning_rate": 4.133333333333333e-05,
      "loss": 0.0008,
      "step": 6240
    },
    {
      "epoch": 0.3472222222222222,
      "grad_norm": 0.12967441976070404,
      "learning_rate": 4.1319444444444445e-05,
      "loss": 0.0011,
      "step": 6250
    },
    {
      "epoch": 0.3477777777777778,
      "grad_norm": 0.044041503220796585,
      "learning_rate": 4.130555555555556e-05,
      "loss": 0.0012,
      "step": 6260
    },
    {
      "epoch": 0.34833333333333333,
      "grad_norm": 0.04940823093056679,
      "learning_rate": 4.129166666666667e-05,
      "loss": 0.0008,
      "step": 6270
    },
    {
      "epoch": 0.3488888888888889,
      "grad_norm": 0.375733882188797,
      "learning_rate": 4.127777777777778e-05,
      "loss": 0.0011,
      "step": 6280
    },
    {
      "epoch": 0.34944444444444445,
      "grad_norm": 0.030587760731577873,
      "learning_rate": 4.126388888888889e-05,
      "loss": 0.0011,
      "step": 6290
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.2892574667930603,
      "learning_rate": 4.125e-05,
      "loss": 0.0019,
      "step": 6300
    },
    {
      "epoch": 0.35055555555555556,
      "grad_norm": 0.32648125290870667,
      "learning_rate": 4.123611111111111e-05,
      "loss": 0.0014,
      "step": 6310
    },
    {
      "epoch": 0.3511111111111111,
      "grad_norm": 0.0,
      "learning_rate": 4.1222222222222224e-05,
      "loss": 0.0012,
      "step": 6320
    },
    {
      "epoch": 0.3516666666666667,
      "grad_norm": 0.04249855503439903,
      "learning_rate": 4.120833333333334e-05,
      "loss": 0.0018,
      "step": 6330
    },
    {
      "epoch": 0.3522222222222222,
      "grad_norm": 0.11496595293283463,
      "learning_rate": 4.119444444444445e-05,
      "loss": 0.001,
      "step": 6340
    },
    {
      "epoch": 0.3527777777777778,
      "grad_norm": 0.044753722846508026,
      "learning_rate": 4.1180555555555554e-05,
      "loss": 0.0009,
      "step": 6350
    },
    {
      "epoch": 0.35333333333333333,
      "grad_norm": 0.18930037319660187,
      "learning_rate": 4.116666666666667e-05,
      "loss": 0.0011,
      "step": 6360
    },
    {
      "epoch": 0.35388888888888886,
      "grad_norm": 0.13144193589687347,
      "learning_rate": 4.115277777777778e-05,
      "loss": 0.0017,
      "step": 6370
    },
    {
      "epoch": 0.35444444444444445,
      "grad_norm": 0.05806836485862732,
      "learning_rate": 4.113888888888889e-05,
      "loss": 0.0014,
      "step": 6380
    },
    {
      "epoch": 0.355,
      "grad_norm": 0.03326094150543213,
      "learning_rate": 4.1125000000000004e-05,
      "loss": 0.0007,
      "step": 6390
    },
    {
      "epoch": 0.35555555555555557,
      "grad_norm": 0.0,
      "learning_rate": 4.111111111111111e-05,
      "loss": 0.0003,
      "step": 6400
    },
    {
      "epoch": 0.3561111111111111,
      "grad_norm": 0.042822156101465225,
      "learning_rate": 4.109722222222223e-05,
      "loss": 0.0015,
      "step": 6410
    },
    {
      "epoch": 0.3566666666666667,
      "grad_norm": 0.01738160103559494,
      "learning_rate": 4.1083333333333334e-05,
      "loss": 0.0017,
      "step": 6420
    },
    {
      "epoch": 0.3572222222222222,
      "grad_norm": 0.13149233162403107,
      "learning_rate": 4.1069444444444446e-05,
      "loss": 0.0013,
      "step": 6430
    },
    {
      "epoch": 0.35777777777777775,
      "grad_norm": 0.10133574903011322,
      "learning_rate": 4.105555555555556e-05,
      "loss": 0.0013,
      "step": 6440
    },
    {
      "epoch": 0.35833333333333334,
      "grad_norm": 0.05733839049935341,
      "learning_rate": 4.104166666666667e-05,
      "loss": 0.0013,
      "step": 6450
    },
    {
      "epoch": 0.35888888888888887,
      "grad_norm": 0.08747453987598419,
      "learning_rate": 4.102777777777778e-05,
      "loss": 0.0006,
      "step": 6460
    },
    {
      "epoch": 0.35944444444444446,
      "grad_norm": 0.0,
      "learning_rate": 4.101388888888889e-05,
      "loss": 0.0013,
      "step": 6470
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.10705125331878662,
      "learning_rate": 4.1e-05,
      "loss": 0.0006,
      "step": 6480
    },
    {
      "epoch": 0.3605555555555556,
      "grad_norm": 0.10224854946136475,
      "learning_rate": 4.098611111111111e-05,
      "loss": 0.0009,
      "step": 6490
    },
    {
      "epoch": 0.3611111111111111,
      "grad_norm": 0.1269807517528534,
      "learning_rate": 4.0972222222222225e-05,
      "loss": 0.0006,
      "step": 6500
    },
    {
      "epoch": 0.3616666666666667,
      "grad_norm": 0.12436042726039886,
      "learning_rate": 4.095833333333334e-05,
      "loss": 0.0011,
      "step": 6510
    },
    {
      "epoch": 0.3622222222222222,
      "grad_norm": 0.0,
      "learning_rate": 4.094444444444445e-05,
      "loss": 0.002,
      "step": 6520
    },
    {
      "epoch": 0.36277777777777775,
      "grad_norm": 0.043772388249635696,
      "learning_rate": 4.0930555555555555e-05,
      "loss": 0.0015,
      "step": 6530
    },
    {
      "epoch": 0.36333333333333334,
      "grad_norm": 0.043351028114557266,
      "learning_rate": 4.091666666666667e-05,
      "loss": 0.001,
      "step": 6540
    },
    {
      "epoch": 0.3638888888888889,
      "grad_norm": 0.21845312416553497,
      "learning_rate": 4.090277777777778e-05,
      "loss": 0.0012,
      "step": 6550
    },
    {
      "epoch": 0.36444444444444446,
      "grad_norm": 0.0,
      "learning_rate": 4.088888888888889e-05,
      "loss": 0.0011,
      "step": 6560
    },
    {
      "epoch": 0.365,
      "grad_norm": 0.0,
      "learning_rate": 4.0875000000000004e-05,
      "loss": 0.0008,
      "step": 6570
    },
    {
      "epoch": 0.3655555555555556,
      "grad_norm": 0.0,
      "learning_rate": 4.086111111111111e-05,
      "loss": 0.0013,
      "step": 6580
    },
    {
      "epoch": 0.3661111111111111,
      "grad_norm": 0.09526295214891434,
      "learning_rate": 4.084722222222223e-05,
      "loss": 0.0005,
      "step": 6590
    },
    {
      "epoch": 0.36666666666666664,
      "grad_norm": 0.23672328889369965,
      "learning_rate": 4.0833333333333334e-05,
      "loss": 0.0013,
      "step": 6600
    },
    {
      "epoch": 0.3672222222222222,
      "grad_norm": 0.11739754676818848,
      "learning_rate": 4.0819444444444447e-05,
      "loss": 0.001,
      "step": 6610
    },
    {
      "epoch": 0.36777777777777776,
      "grad_norm": 0.17373427748680115,
      "learning_rate": 4.080555555555556e-05,
      "loss": 0.0013,
      "step": 6620
    },
    {
      "epoch": 0.36833333333333335,
      "grad_norm": 0.09797254949808121,
      "learning_rate": 4.0791666666666664e-05,
      "loss": 0.0011,
      "step": 6630
    },
    {
      "epoch": 0.3688888888888889,
      "grad_norm": 0.46072179079055786,
      "learning_rate": 4.0777777777777783e-05,
      "loss": 0.0011,
      "step": 6640
    },
    {
      "epoch": 0.36944444444444446,
      "grad_norm": 0.0,
      "learning_rate": 4.076388888888889e-05,
      "loss": 0.0012,
      "step": 6650
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.052863676100969315,
      "learning_rate": 4.075e-05,
      "loss": 0.001,
      "step": 6660
    },
    {
      "epoch": 0.3705555555555556,
      "grad_norm": 0.1186191737651825,
      "learning_rate": 4.0736111111111113e-05,
      "loss": 0.0015,
      "step": 6670
    },
    {
      "epoch": 0.3711111111111111,
      "grad_norm": 0.0,
      "learning_rate": 4.0722222222222226e-05,
      "loss": 0.0004,
      "step": 6680
    },
    {
      "epoch": 0.37166666666666665,
      "grad_norm": 0.044320400804281235,
      "learning_rate": 4.070833333333334e-05,
      "loss": 0.0007,
      "step": 6690
    },
    {
      "epoch": 0.37222222222222223,
      "grad_norm": 0.042020559310913086,
      "learning_rate": 4.0694444444444444e-05,
      "loss": 0.0007,
      "step": 6700
    },
    {
      "epoch": 0.37277777777777776,
      "grad_norm": 0.04387078061699867,
      "learning_rate": 4.0680555555555556e-05,
      "loss": 0.0006,
      "step": 6710
    },
    {
      "epoch": 0.37333333333333335,
      "grad_norm": 0.12579603493213654,
      "learning_rate": 4.066666666666667e-05,
      "loss": 0.0016,
      "step": 6720
    },
    {
      "epoch": 0.3738888888888889,
      "grad_norm": 0.030548660084605217,
      "learning_rate": 4.065277777777778e-05,
      "loss": 0.0013,
      "step": 6730
    },
    {
      "epoch": 0.37444444444444447,
      "grad_norm": 0.2786332368850708,
      "learning_rate": 4.063888888888889e-05,
      "loss": 0.001,
      "step": 6740
    },
    {
      "epoch": 0.375,
      "grad_norm": 0.016265278682112694,
      "learning_rate": 4.0625000000000005e-05,
      "loss": 0.0013,
      "step": 6750
    },
    {
      "epoch": 0.37555555555555553,
      "grad_norm": 0.043714478611946106,
      "learning_rate": 4.061111111111111e-05,
      "loss": 0.0014,
      "step": 6760
    },
    {
      "epoch": 0.3761111111111111,
      "grad_norm": 0.09822240471839905,
      "learning_rate": 4.059722222222222e-05,
      "loss": 0.0007,
      "step": 6770
    },
    {
      "epoch": 0.37666666666666665,
      "grad_norm": 0.08963686227798462,
      "learning_rate": 4.0583333333333335e-05,
      "loss": 0.0014,
      "step": 6780
    },
    {
      "epoch": 0.37722222222222224,
      "grad_norm": 0.0,
      "learning_rate": 4.056944444444445e-05,
      "loss": 0.0018,
      "step": 6790
    },
    {
      "epoch": 0.37777777777777777,
      "grad_norm": 0.30682915449142456,
      "learning_rate": 4.055555555555556e-05,
      "loss": 0.0013,
      "step": 6800
    },
    {
      "epoch": 0.37833333333333335,
      "grad_norm": 0.2465386688709259,
      "learning_rate": 4.0541666666666665e-05,
      "loss": 0.0016,
      "step": 6810
    },
    {
      "epoch": 0.3788888888888889,
      "grad_norm": 0.1419212520122528,
      "learning_rate": 4.0527777777777784e-05,
      "loss": 0.0006,
      "step": 6820
    },
    {
      "epoch": 0.3794444444444444,
      "grad_norm": 0.18071258068084717,
      "learning_rate": 4.051388888888889e-05,
      "loss": 0.0008,
      "step": 6830
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.09267187863588333,
      "learning_rate": 4.05e-05,
      "loss": 0.0006,
      "step": 6840
    },
    {
      "epoch": 0.38055555555555554,
      "grad_norm": 0.04432178661227226,
      "learning_rate": 4.0486111111111114e-05,
      "loss": 0.0006,
      "step": 6850
    },
    {
      "epoch": 0.3811111111111111,
      "grad_norm": 0.08973490446805954,
      "learning_rate": 4.047222222222222e-05,
      "loss": 0.0015,
      "step": 6860
    },
    {
      "epoch": 0.38166666666666665,
      "grad_norm": 0.0,
      "learning_rate": 4.045833333333334e-05,
      "loss": 0.0009,
      "step": 6870
    },
    {
      "epoch": 0.38222222222222224,
      "grad_norm": 0.09464853256940842,
      "learning_rate": 4.0444444444444444e-05,
      "loss": 0.0007,
      "step": 6880
    },
    {
      "epoch": 0.3827777777777778,
      "grad_norm": 0.043241869658231735,
      "learning_rate": 4.0430555555555556e-05,
      "loss": 0.0007,
      "step": 6890
    },
    {
      "epoch": 0.38333333333333336,
      "grad_norm": 0.14348819851875305,
      "learning_rate": 4.041666666666667e-05,
      "loss": 0.0007,
      "step": 6900
    },
    {
      "epoch": 0.3838888888888889,
      "grad_norm": 0.0,
      "learning_rate": 4.040277777777778e-05,
      "loss": 0.0006,
      "step": 6910
    },
    {
      "epoch": 0.3844444444444444,
      "grad_norm": 0.08623744547367096,
      "learning_rate": 4.038888888888889e-05,
      "loss": 0.0008,
      "step": 6920
    },
    {
      "epoch": 0.385,
      "grad_norm": 0.10493137687444687,
      "learning_rate": 4.0375e-05,
      "loss": 0.0009,
      "step": 6930
    },
    {
      "epoch": 0.38555555555555554,
      "grad_norm": 0.08936965465545654,
      "learning_rate": 4.036111111111111e-05,
      "loss": 0.0011,
      "step": 6940
    },
    {
      "epoch": 0.3861111111111111,
      "grad_norm": 0.0,
      "learning_rate": 4.0347222222222223e-05,
      "loss": 0.001,
      "step": 6950
    },
    {
      "epoch": 0.38666666666666666,
      "grad_norm": 0.04840671271085739,
      "learning_rate": 4.0333333333333336e-05,
      "loss": 0.0017,
      "step": 6960
    },
    {
      "epoch": 0.38722222222222225,
      "grad_norm": 0.08283567428588867,
      "learning_rate": 4.031944444444445e-05,
      "loss": 0.0009,
      "step": 6970
    },
    {
      "epoch": 0.3877777777777778,
      "grad_norm": 0.0,
      "learning_rate": 4.030555555555556e-05,
      "loss": 0.0009,
      "step": 6980
    },
    {
      "epoch": 0.3883333333333333,
      "grad_norm": 0.06607447564601898,
      "learning_rate": 4.0291666666666666e-05,
      "loss": 0.0003,
      "step": 6990
    },
    {
      "epoch": 0.3888888888888889,
      "grad_norm": 0.045963943004608154,
      "learning_rate": 4.027777777777778e-05,
      "loss": 0.0009,
      "step": 7000
    },
    {
      "epoch": 0.3894444444444444,
      "grad_norm": 0.1297377645969391,
      "learning_rate": 4.026388888888889e-05,
      "loss": 0.0007,
      "step": 7010
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.0,
      "learning_rate": 4.025e-05,
      "loss": 0.0013,
      "step": 7020
    },
    {
      "epoch": 0.39055555555555554,
      "grad_norm": 0.04757936671376228,
      "learning_rate": 4.0236111111111115e-05,
      "loss": 0.0011,
      "step": 7030
    },
    {
      "epoch": 0.39111111111111113,
      "grad_norm": 0.08909283578395844,
      "learning_rate": 4.022222222222222e-05,
      "loss": 0.0007,
      "step": 7040
    },
    {
      "epoch": 0.39166666666666666,
      "grad_norm": 0.27779585123062134,
      "learning_rate": 4.020833333333334e-05,
      "loss": 0.0008,
      "step": 7050
    },
    {
      "epoch": 0.39222222222222225,
      "grad_norm": 0.16743646562099457,
      "learning_rate": 4.0194444444444445e-05,
      "loss": 0.0005,
      "step": 7060
    },
    {
      "epoch": 0.3927777777777778,
      "grad_norm": 0.25080880522727966,
      "learning_rate": 4.018055555555556e-05,
      "loss": 0.0014,
      "step": 7070
    },
    {
      "epoch": 0.3933333333333333,
      "grad_norm": 0.049291111528873444,
      "learning_rate": 4.016666666666667e-05,
      "loss": 0.0013,
      "step": 7080
    },
    {
      "epoch": 0.3938888888888889,
      "grad_norm": 0.13426080346107483,
      "learning_rate": 4.0152777777777775e-05,
      "loss": 0.001,
      "step": 7090
    },
    {
      "epoch": 0.39444444444444443,
      "grad_norm": 0.1505548357963562,
      "learning_rate": 4.0138888888888894e-05,
      "loss": 0.0006,
      "step": 7100
    },
    {
      "epoch": 0.395,
      "grad_norm": 0.0,
      "learning_rate": 4.0125e-05,
      "loss": 0.0007,
      "step": 7110
    },
    {
      "epoch": 0.39555555555555555,
      "grad_norm": 0.11419486999511719,
      "learning_rate": 4.011111111111111e-05,
      "loss": 0.0008,
      "step": 7120
    },
    {
      "epoch": 0.39611111111111114,
      "grad_norm": 0.0,
      "learning_rate": 4.0097222222222224e-05,
      "loss": 0.0005,
      "step": 7130
    },
    {
      "epoch": 0.39666666666666667,
      "grad_norm": 0.13125577569007874,
      "learning_rate": 4.0083333333333336e-05,
      "loss": 0.0003,
      "step": 7140
    },
    {
      "epoch": 0.3972222222222222,
      "grad_norm": 0.0,
      "learning_rate": 4.006944444444445e-05,
      "loss": 0.0004,
      "step": 7150
    },
    {
      "epoch": 0.3977777777777778,
      "grad_norm": 0.16016127169132233,
      "learning_rate": 4.0055555555555554e-05,
      "loss": 0.0005,
      "step": 7160
    },
    {
      "epoch": 0.3983333333333333,
      "grad_norm": 0.0,
      "learning_rate": 4.0041666666666666e-05,
      "loss": 0.0004,
      "step": 7170
    },
    {
      "epoch": 0.3988888888888889,
      "grad_norm": 0.22350837290287018,
      "learning_rate": 4.002777777777778e-05,
      "loss": 0.0006,
      "step": 7180
    },
    {
      "epoch": 0.39944444444444444,
      "grad_norm": 0.0,
      "learning_rate": 4.001388888888889e-05,
      "loss": 0.0011,
      "step": 7190
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.16600212454795837,
      "learning_rate": 4e-05,
      "loss": 0.0017,
      "step": 7200
    },
    {
      "epoch": 0.40055555555555555,
      "grad_norm": 0.08563253283500671,
      "learning_rate": 3.9986111111111116e-05,
      "loss": 0.0011,
      "step": 7210
    },
    {
      "epoch": 0.4011111111111111,
      "grad_norm": 0.0,
      "learning_rate": 3.997222222222222e-05,
      "loss": 0.0014,
      "step": 7220
    },
    {
      "epoch": 0.40166666666666667,
      "grad_norm": 0.0,
      "learning_rate": 3.995833333333333e-05,
      "loss": 0.0011,
      "step": 7230
    },
    {
      "epoch": 0.4022222222222222,
      "grad_norm": 0.041718363761901855,
      "learning_rate": 3.9944444444444446e-05,
      "loss": 0.0011,
      "step": 7240
    },
    {
      "epoch": 0.4027777777777778,
      "grad_norm": 0.11932073533535004,
      "learning_rate": 3.993055555555556e-05,
      "loss": 0.0016,
      "step": 7250
    },
    {
      "epoch": 0.4033333333333333,
      "grad_norm": 0.15014420449733734,
      "learning_rate": 3.991666666666667e-05,
      "loss": 0.0007,
      "step": 7260
    },
    {
      "epoch": 0.4038888888888889,
      "grad_norm": 0.09807965159416199,
      "learning_rate": 3.9902777777777776e-05,
      "loss": 0.0014,
      "step": 7270
    },
    {
      "epoch": 0.40444444444444444,
      "grad_norm": 0.3557966649532318,
      "learning_rate": 3.9888888888888895e-05,
      "loss": 0.0012,
      "step": 7280
    },
    {
      "epoch": 0.405,
      "grad_norm": 0.26235222816467285,
      "learning_rate": 3.9875e-05,
      "loss": 0.0006,
      "step": 7290
    },
    {
      "epoch": 0.40555555555555556,
      "grad_norm": 0.13088983297348022,
      "learning_rate": 3.986111111111111e-05,
      "loss": 0.0019,
      "step": 7300
    },
    {
      "epoch": 0.4061111111111111,
      "grad_norm": 0.0,
      "learning_rate": 3.9847222222222225e-05,
      "loss": 0.0012,
      "step": 7310
    },
    {
      "epoch": 0.4066666666666667,
      "grad_norm": 0.10252745449542999,
      "learning_rate": 3.983333333333333e-05,
      "loss": 0.0015,
      "step": 7320
    },
    {
      "epoch": 0.4072222222222222,
      "grad_norm": 0.07885315269231796,
      "learning_rate": 3.981944444444445e-05,
      "loss": 0.0012,
      "step": 7330
    },
    {
      "epoch": 0.4077777777777778,
      "grad_norm": 0.14892302453517914,
      "learning_rate": 3.9805555555555555e-05,
      "loss": 0.0014,
      "step": 7340
    },
    {
      "epoch": 0.4083333333333333,
      "grad_norm": 0.0455181859433651,
      "learning_rate": 3.979166666666667e-05,
      "loss": 0.0003,
      "step": 7350
    },
    {
      "epoch": 0.4088888888888889,
      "grad_norm": 0.08715097606182098,
      "learning_rate": 3.977777777777778e-05,
      "loss": 0.0009,
      "step": 7360
    },
    {
      "epoch": 0.40944444444444444,
      "grad_norm": 0.03389459475874901,
      "learning_rate": 3.976388888888889e-05,
      "loss": 0.0009,
      "step": 7370
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.07851792871952057,
      "learning_rate": 3.9750000000000004e-05,
      "loss": 0.0007,
      "step": 7380
    },
    {
      "epoch": 0.41055555555555556,
      "grad_norm": 0.13706786930561066,
      "learning_rate": 3.973611111111111e-05,
      "loss": 0.0008,
      "step": 7390
    },
    {
      "epoch": 0.4111111111111111,
      "grad_norm": 0.27804476022720337,
      "learning_rate": 3.972222222222222e-05,
      "loss": 0.0015,
      "step": 7400
    },
    {
      "epoch": 0.4116666666666667,
      "grad_norm": 0.3100965619087219,
      "learning_rate": 3.9708333333333334e-05,
      "loss": 0.0018,
      "step": 7410
    },
    {
      "epoch": 0.4122222222222222,
      "grad_norm": 0.0,
      "learning_rate": 3.9694444444444446e-05,
      "loss": 0.0007,
      "step": 7420
    },
    {
      "epoch": 0.4127777777777778,
      "grad_norm": 0.02074384316802025,
      "learning_rate": 3.968055555555556e-05,
      "loss": 0.0014,
      "step": 7430
    },
    {
      "epoch": 0.41333333333333333,
      "grad_norm": 0.2301638126373291,
      "learning_rate": 3.966666666666667e-05,
      "loss": 0.0018,
      "step": 7440
    },
    {
      "epoch": 0.41388888888888886,
      "grad_norm": 0.12943421304225922,
      "learning_rate": 3.9652777777777776e-05,
      "loss": 0.0011,
      "step": 7450
    },
    {
      "epoch": 0.41444444444444445,
      "grad_norm": 0.13620921969413757,
      "learning_rate": 3.9638888888888895e-05,
      "loss": 0.0005,
      "step": 7460
    },
    {
      "epoch": 0.415,
      "grad_norm": 0.04784006252884865,
      "learning_rate": 3.9625e-05,
      "loss": 0.0012,
      "step": 7470
    },
    {
      "epoch": 0.41555555555555557,
      "grad_norm": 0.12437458336353302,
      "learning_rate": 3.961111111111111e-05,
      "loss": 0.0011,
      "step": 7480
    },
    {
      "epoch": 0.4161111111111111,
      "grad_norm": 0.283944696187973,
      "learning_rate": 3.9597222222222225e-05,
      "loss": 0.0019,
      "step": 7490
    },
    {
      "epoch": 0.4166666666666667,
      "grad_norm": 0.3898508548736572,
      "learning_rate": 3.958333333333333e-05,
      "loss": 0.0004,
      "step": 7500
    },
    {
      "epoch": 0.4172222222222222,
      "grad_norm": 0.0,
      "learning_rate": 3.956944444444445e-05,
      "loss": 0.0006,
      "step": 7510
    },
    {
      "epoch": 0.4177777777777778,
      "grad_norm": 0.2486189752817154,
      "learning_rate": 3.9555555555555556e-05,
      "loss": 0.0014,
      "step": 7520
    },
    {
      "epoch": 0.41833333333333333,
      "grad_norm": 0.06397732347249985,
      "learning_rate": 3.9541666666666675e-05,
      "loss": 0.0027,
      "step": 7530
    },
    {
      "epoch": 0.41888888888888887,
      "grad_norm": 0.050396598875522614,
      "learning_rate": 3.952777777777778e-05,
      "loss": 0.001,
      "step": 7540
    },
    {
      "epoch": 0.41944444444444445,
      "grad_norm": 0.1273767501115799,
      "learning_rate": 3.951388888888889e-05,
      "loss": 0.0022,
      "step": 7550
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.1379818320274353,
      "learning_rate": 3.9500000000000005e-05,
      "loss": 0.0002,
      "step": 7560
    },
    {
      "epoch": 0.42055555555555557,
      "grad_norm": 0.04999140277504921,
      "learning_rate": 3.948611111111111e-05,
      "loss": 0.0011,
      "step": 7570
    },
    {
      "epoch": 0.4211111111111111,
      "grad_norm": 0.17337727546691895,
      "learning_rate": 3.947222222222222e-05,
      "loss": 0.0021,
      "step": 7580
    },
    {
      "epoch": 0.4216666666666667,
      "grad_norm": 0.04780326783657074,
      "learning_rate": 3.9458333333333335e-05,
      "loss": 0.0006,
      "step": 7590
    },
    {
      "epoch": 0.4222222222222222,
      "grad_norm": 0.09809990227222443,
      "learning_rate": 3.944444444444445e-05,
      "loss": 0.0014,
      "step": 7600
    },
    {
      "epoch": 0.42277777777777775,
      "grad_norm": 0.08040071278810501,
      "learning_rate": 3.943055555555556e-05,
      "loss": 0.0015,
      "step": 7610
    },
    {
      "epoch": 0.42333333333333334,
      "grad_norm": 0.0,
      "learning_rate": 3.941666666666667e-05,
      "loss": 0.0006,
      "step": 7620
    },
    {
      "epoch": 0.42388888888888887,
      "grad_norm": 0.20364220440387726,
      "learning_rate": 3.940277777777778e-05,
      "loss": 0.0023,
      "step": 7630
    },
    {
      "epoch": 0.42444444444444446,
      "grad_norm": 0.4076803922653198,
      "learning_rate": 3.938888888888889e-05,
      "loss": 0.0008,
      "step": 7640
    },
    {
      "epoch": 0.425,
      "grad_norm": 0.0,
      "learning_rate": 3.9375e-05,
      "loss": 0.0013,
      "step": 7650
    },
    {
      "epoch": 0.4255555555555556,
      "grad_norm": 0.2568082809448242,
      "learning_rate": 3.9361111111111114e-05,
      "loss": 0.0011,
      "step": 7660
    },
    {
      "epoch": 0.4261111111111111,
      "grad_norm": 0.24246370792388916,
      "learning_rate": 3.9347222222222226e-05,
      "loss": 0.002,
      "step": 7670
    },
    {
      "epoch": 0.4266666666666667,
      "grad_norm": 0.23501156270503998,
      "learning_rate": 3.933333333333333e-05,
      "loss": 0.0011,
      "step": 7680
    },
    {
      "epoch": 0.4272222222222222,
      "grad_norm": 0.08704627305269241,
      "learning_rate": 3.931944444444445e-05,
      "loss": 0.0009,
      "step": 7690
    },
    {
      "epoch": 0.42777777777777776,
      "grad_norm": 0.3416500687599182,
      "learning_rate": 3.9305555555555556e-05,
      "loss": 0.0009,
      "step": 7700
    },
    {
      "epoch": 0.42833333333333334,
      "grad_norm": 0.047915711998939514,
      "learning_rate": 3.929166666666667e-05,
      "loss": 0.0008,
      "step": 7710
    },
    {
      "epoch": 0.4288888888888889,
      "grad_norm": 0.3827340602874756,
      "learning_rate": 3.927777777777778e-05,
      "loss": 0.0011,
      "step": 7720
    },
    {
      "epoch": 0.42944444444444446,
      "grad_norm": 0.0,
      "learning_rate": 3.9263888888888886e-05,
      "loss": 0.0017,
      "step": 7730
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.1779973804950714,
      "learning_rate": 3.9250000000000005e-05,
      "loss": 0.0005,
      "step": 7740
    },
    {
      "epoch": 0.4305555555555556,
      "grad_norm": 0.04677652195096016,
      "learning_rate": 3.923611111111111e-05,
      "loss": 0.001,
      "step": 7750
    },
    {
      "epoch": 0.4311111111111111,
      "grad_norm": 0.1478358656167984,
      "learning_rate": 3.922222222222223e-05,
      "loss": 0.0009,
      "step": 7760
    },
    {
      "epoch": 0.43166666666666664,
      "grad_norm": 0.1160070151090622,
      "learning_rate": 3.9208333333333335e-05,
      "loss": 0.0011,
      "step": 7770
    },
    {
      "epoch": 0.43222222222222223,
      "grad_norm": 0.21934211254119873,
      "learning_rate": 3.919444444444445e-05,
      "loss": 0.0014,
      "step": 7780
    },
    {
      "epoch": 0.43277777777777776,
      "grad_norm": 0.0,
      "learning_rate": 3.918055555555556e-05,
      "loss": 0.0012,
      "step": 7790
    },
    {
      "epoch": 0.43333333333333335,
      "grad_norm": 0.21053607761859894,
      "learning_rate": 3.9166666666666665e-05,
      "loss": 0.0004,
      "step": 7800
    },
    {
      "epoch": 0.4338888888888889,
      "grad_norm": 0.0,
      "learning_rate": 3.915277777777778e-05,
      "loss": 0.0006,
      "step": 7810
    },
    {
      "epoch": 0.43444444444444447,
      "grad_norm": 0.0,
      "learning_rate": 3.913888888888889e-05,
      "loss": 0.001,
      "step": 7820
    },
    {
      "epoch": 0.435,
      "grad_norm": 0.020670413970947266,
      "learning_rate": 3.9125e-05,
      "loss": 0.0007,
      "step": 7830
    },
    {
      "epoch": 0.43555555555555553,
      "grad_norm": 0.2792604863643646,
      "learning_rate": 3.9111111111111115e-05,
      "loss": 0.0001,
      "step": 7840
    },
    {
      "epoch": 0.4361111111111111,
      "grad_norm": 0.343173623085022,
      "learning_rate": 3.909722222222223e-05,
      "loss": 0.0007,
      "step": 7850
    },
    {
      "epoch": 0.43666666666666665,
      "grad_norm": 0.0,
      "learning_rate": 3.908333333333333e-05,
      "loss": 0.0007,
      "step": 7860
    },
    {
      "epoch": 0.43722222222222223,
      "grad_norm": 0.12148002535104752,
      "learning_rate": 3.9069444444444445e-05,
      "loss": 0.002,
      "step": 7870
    },
    {
      "epoch": 0.43777777777777777,
      "grad_norm": 0.0232881810516119,
      "learning_rate": 3.905555555555556e-05,
      "loss": 0.0012,
      "step": 7880
    },
    {
      "epoch": 0.43833333333333335,
      "grad_norm": 0.21038973331451416,
      "learning_rate": 3.904166666666667e-05,
      "loss": 0.0012,
      "step": 7890
    },
    {
      "epoch": 0.4388888888888889,
      "grad_norm": 0.050585269927978516,
      "learning_rate": 3.902777777777778e-05,
      "loss": 0.0017,
      "step": 7900
    },
    {
      "epoch": 0.43944444444444447,
      "grad_norm": 0.175381138920784,
      "learning_rate": 3.901388888888889e-05,
      "loss": 0.0011,
      "step": 7910
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.11055339872837067,
      "learning_rate": 3.9000000000000006e-05,
      "loss": 0.0017,
      "step": 7920
    },
    {
      "epoch": 0.44055555555555553,
      "grad_norm": 0.31898608803749084,
      "learning_rate": 3.898611111111111e-05,
      "loss": 0.0013,
      "step": 7930
    },
    {
      "epoch": 0.4411111111111111,
      "grad_norm": 0.0,
      "learning_rate": 3.8972222222222224e-05,
      "loss": 0.0018,
      "step": 7940
    },
    {
      "epoch": 0.44166666666666665,
      "grad_norm": 0.13692069053649902,
      "learning_rate": 3.8958333333333336e-05,
      "loss": 0.0013,
      "step": 7950
    },
    {
      "epoch": 0.44222222222222224,
      "grad_norm": 0.08541014790534973,
      "learning_rate": 3.894444444444444e-05,
      "loss": 0.0009,
      "step": 7960
    },
    {
      "epoch": 0.44277777777777777,
      "grad_norm": 0.1626676321029663,
      "learning_rate": 3.893055555555556e-05,
      "loss": 0.0007,
      "step": 7970
    },
    {
      "epoch": 0.44333333333333336,
      "grad_norm": 0.04410002380609512,
      "learning_rate": 3.8916666666666666e-05,
      "loss": 0.0016,
      "step": 7980
    },
    {
      "epoch": 0.4438888888888889,
      "grad_norm": 0.04575132206082344,
      "learning_rate": 3.890277777777778e-05,
      "loss": 0.0007,
      "step": 7990
    },
    {
      "epoch": 0.4444444444444444,
      "grad_norm": 0.13752204179763794,
      "learning_rate": 3.888888888888889e-05,
      "loss": 0.0007,
      "step": 8000
    },
    {
      "epoch": 0.445,
      "grad_norm": 0.19526031613349915,
      "learning_rate": 3.8875e-05,
      "loss": 0.0005,
      "step": 8010
    },
    {
      "epoch": 0.44555555555555554,
      "grad_norm": 0.12557834386825562,
      "learning_rate": 3.8861111111111115e-05,
      "loss": 0.0008,
      "step": 8020
    },
    {
      "epoch": 0.4461111111111111,
      "grad_norm": 0.0,
      "learning_rate": 3.884722222222222e-05,
      "loss": 0.001,
      "step": 8030
    },
    {
      "epoch": 0.44666666666666666,
      "grad_norm": 0.19748558104038239,
      "learning_rate": 3.883333333333333e-05,
      "loss": 0.0015,
      "step": 8040
    },
    {
      "epoch": 0.44722222222222224,
      "grad_norm": 0.14152300357818604,
      "learning_rate": 3.8819444444444445e-05,
      "loss": 0.0019,
      "step": 8050
    },
    {
      "epoch": 0.4477777777777778,
      "grad_norm": 0.26142677664756775,
      "learning_rate": 3.880555555555556e-05,
      "loss": 0.0008,
      "step": 8060
    },
    {
      "epoch": 0.4483333333333333,
      "grad_norm": 0.19089823961257935,
      "learning_rate": 3.879166666666667e-05,
      "loss": 0.0016,
      "step": 8070
    },
    {
      "epoch": 0.4488888888888889,
      "grad_norm": 0.04478331282734871,
      "learning_rate": 3.877777777777778e-05,
      "loss": 0.0004,
      "step": 8080
    },
    {
      "epoch": 0.4494444444444444,
      "grad_norm": 0.2181297093629837,
      "learning_rate": 3.876388888888889e-05,
      "loss": 0.0009,
      "step": 8090
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.13324812054634094,
      "learning_rate": 3.875e-05,
      "loss": 0.0006,
      "step": 8100
    },
    {
      "epoch": 0.45055555555555554,
      "grad_norm": 0.05821142718195915,
      "learning_rate": 3.873611111111111e-05,
      "loss": 0.0023,
      "step": 8110
    },
    {
      "epoch": 0.45111111111111113,
      "grad_norm": 0.0,
      "learning_rate": 3.8722222222222225e-05,
      "loss": 0.0014,
      "step": 8120
    },
    {
      "epoch": 0.45166666666666666,
      "grad_norm": 0.08594682812690735,
      "learning_rate": 3.870833333333334e-05,
      "loss": 0.0013,
      "step": 8130
    },
    {
      "epoch": 0.45222222222222225,
      "grad_norm": 0.04429202154278755,
      "learning_rate": 3.869444444444444e-05,
      "loss": 0.0026,
      "step": 8140
    },
    {
      "epoch": 0.4527777777777778,
      "grad_norm": 0.056758005172014236,
      "learning_rate": 3.868055555555556e-05,
      "loss": 0.0009,
      "step": 8150
    },
    {
      "epoch": 0.4533333333333333,
      "grad_norm": 0.19570347666740417,
      "learning_rate": 3.866666666666667e-05,
      "loss": 0.001,
      "step": 8160
    },
    {
      "epoch": 0.4538888888888889,
      "grad_norm": 0.3493805527687073,
      "learning_rate": 3.865277777777778e-05,
      "loss": 0.0021,
      "step": 8170
    },
    {
      "epoch": 0.45444444444444443,
      "grad_norm": 0.16728448867797852,
      "learning_rate": 3.863888888888889e-05,
      "loss": 0.0006,
      "step": 8180
    },
    {
      "epoch": 0.455,
      "grad_norm": 0.08539334684610367,
      "learning_rate": 3.8625e-05,
      "loss": 0.0009,
      "step": 8190
    },
    {
      "epoch": 0.45555555555555555,
      "grad_norm": 0.1344558745622635,
      "learning_rate": 3.8611111111111116e-05,
      "loss": 0.0008,
      "step": 8200
    },
    {
      "epoch": 0.45611111111111113,
      "grad_norm": 0.12222188711166382,
      "learning_rate": 3.859722222222222e-05,
      "loss": 0.0017,
      "step": 8210
    },
    {
      "epoch": 0.45666666666666667,
      "grad_norm": 0.0,
      "learning_rate": 3.8583333333333334e-05,
      "loss": 0.0009,
      "step": 8220
    },
    {
      "epoch": 0.4572222222222222,
      "grad_norm": 0.170521080493927,
      "learning_rate": 3.8569444444444446e-05,
      "loss": 0.0006,
      "step": 8230
    },
    {
      "epoch": 0.4577777777777778,
      "grad_norm": 0.12541238963603973,
      "learning_rate": 3.855555555555556e-05,
      "loss": 0.001,
      "step": 8240
    },
    {
      "epoch": 0.4583333333333333,
      "grad_norm": 0.23048906028270721,
      "learning_rate": 3.854166666666667e-05,
      "loss": 0.0009,
      "step": 8250
    },
    {
      "epoch": 0.4588888888888889,
      "grad_norm": 0.4152999520301819,
      "learning_rate": 3.8527777777777776e-05,
      "loss": 0.0007,
      "step": 8260
    },
    {
      "epoch": 0.45944444444444443,
      "grad_norm": 0.23823849856853485,
      "learning_rate": 3.851388888888889e-05,
      "loss": 0.0006,
      "step": 8270
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.0890619084239006,
      "learning_rate": 3.85e-05,
      "loss": 0.0005,
      "step": 8280
    },
    {
      "epoch": 0.46055555555555555,
      "grad_norm": 0.0,
      "learning_rate": 3.848611111111111e-05,
      "loss": 0.001,
      "step": 8290
    },
    {
      "epoch": 0.46111111111111114,
      "grad_norm": 0.0,
      "learning_rate": 3.8472222222222225e-05,
      "loss": 0.0015,
      "step": 8300
    },
    {
      "epoch": 0.46166666666666667,
      "grad_norm": 0.04394925385713577,
      "learning_rate": 3.845833333333334e-05,
      "loss": 0.0009,
      "step": 8310
    },
    {
      "epoch": 0.4622222222222222,
      "grad_norm": 0.06526199728250504,
      "learning_rate": 3.844444444444444e-05,
      "loss": 0.0013,
      "step": 8320
    },
    {
      "epoch": 0.4627777777777778,
      "grad_norm": 0.0,
      "learning_rate": 3.8430555555555555e-05,
      "loss": 0.0008,
      "step": 8330
    },
    {
      "epoch": 0.4633333333333333,
      "grad_norm": 0.0829051211476326,
      "learning_rate": 3.841666666666667e-05,
      "loss": 0.0011,
      "step": 8340
    },
    {
      "epoch": 0.4638888888888889,
      "grad_norm": 0.05414247140288353,
      "learning_rate": 3.840277777777778e-05,
      "loss": 0.0009,
      "step": 8350
    },
    {
      "epoch": 0.46444444444444444,
      "grad_norm": 0.0,
      "learning_rate": 3.838888888888889e-05,
      "loss": 0.0009,
      "step": 8360
    },
    {
      "epoch": 0.465,
      "grad_norm": 0.24893800914287567,
      "learning_rate": 3.8375e-05,
      "loss": 0.0012,
      "step": 8370
    },
    {
      "epoch": 0.46555555555555556,
      "grad_norm": 0.03395039960741997,
      "learning_rate": 3.836111111111112e-05,
      "loss": 0.0013,
      "step": 8380
    },
    {
      "epoch": 0.4661111111111111,
      "grad_norm": 0.04480283707380295,
      "learning_rate": 3.834722222222222e-05,
      "loss": 0.0008,
      "step": 8390
    },
    {
      "epoch": 0.4666666666666667,
      "grad_norm": 0.0,
      "learning_rate": 3.8333333333333334e-05,
      "loss": 0.0011,
      "step": 8400
    },
    {
      "epoch": 0.4672222222222222,
      "grad_norm": 0.20602001249790192,
      "learning_rate": 3.831944444444445e-05,
      "loss": 0.0019,
      "step": 8410
    },
    {
      "epoch": 0.4677777777777778,
      "grad_norm": 0.08475533872842789,
      "learning_rate": 3.830555555555555e-05,
      "loss": 0.0007,
      "step": 8420
    },
    {
      "epoch": 0.4683333333333333,
      "grad_norm": 0.17308185994625092,
      "learning_rate": 3.829166666666667e-05,
      "loss": 0.0007,
      "step": 8430
    },
    {
      "epoch": 0.4688888888888889,
      "grad_norm": 0.083951935172081,
      "learning_rate": 3.827777777777778e-05,
      "loss": 0.0013,
      "step": 8440
    },
    {
      "epoch": 0.46944444444444444,
      "grad_norm": 0.08715993165969849,
      "learning_rate": 3.826388888888889e-05,
      "loss": 0.0012,
      "step": 8450
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.3734372854232788,
      "learning_rate": 3.825e-05,
      "loss": 0.0011,
      "step": 8460
    },
    {
      "epoch": 0.47055555555555556,
      "grad_norm": 0.2832506597042084,
      "learning_rate": 3.8236111111111114e-05,
      "loss": 0.0003,
      "step": 8470
    },
    {
      "epoch": 0.4711111111111111,
      "grad_norm": 0.0,
      "learning_rate": 3.8222222222222226e-05,
      "loss": 0.0012,
      "step": 8480
    },
    {
      "epoch": 0.4716666666666667,
      "grad_norm": 0.3897625207901001,
      "learning_rate": 3.820833333333334e-05,
      "loss": 0.001,
      "step": 8490
    },
    {
      "epoch": 0.4722222222222222,
      "grad_norm": 0.12848909199237823,
      "learning_rate": 3.8194444444444444e-05,
      "loss": 0.0008,
      "step": 8500
    },
    {
      "epoch": 0.4727777777777778,
      "grad_norm": 0.1452050507068634,
      "learning_rate": 3.8180555555555556e-05,
      "loss": 0.002,
      "step": 8510
    },
    {
      "epoch": 0.47333333333333333,
      "grad_norm": 0.0,
      "learning_rate": 3.816666666666667e-05,
      "loss": 0.001,
      "step": 8520
    },
    {
      "epoch": 0.4738888888888889,
      "grad_norm": 0.045773349702358246,
      "learning_rate": 3.815277777777778e-05,
      "loss": 0.0008,
      "step": 8530
    },
    {
      "epoch": 0.47444444444444445,
      "grad_norm": 0.0,
      "learning_rate": 3.813888888888889e-05,
      "loss": 0.0016,
      "step": 8540
    },
    {
      "epoch": 0.475,
      "grad_norm": 0.11815821379423141,
      "learning_rate": 3.8125e-05,
      "loss": 0.0009,
      "step": 8550
    },
    {
      "epoch": 0.47555555555555556,
      "grad_norm": 0.17852012813091278,
      "learning_rate": 3.811111111111112e-05,
      "loss": 0.0011,
      "step": 8560
    },
    {
      "epoch": 0.4761111111111111,
      "grad_norm": 0.02819119580090046,
      "learning_rate": 3.809722222222222e-05,
      "loss": 0.001,
      "step": 8570
    },
    {
      "epoch": 0.4766666666666667,
      "grad_norm": 0.06822910159826279,
      "learning_rate": 3.8083333333333335e-05,
      "loss": 0.0016,
      "step": 8580
    },
    {
      "epoch": 0.4772222222222222,
      "grad_norm": 0.0474582314491272,
      "learning_rate": 3.806944444444445e-05,
      "loss": 0.0011,
      "step": 8590
    },
    {
      "epoch": 0.4777777777777778,
      "grad_norm": 0.0,
      "learning_rate": 3.805555555555555e-05,
      "loss": 0.0006,
      "step": 8600
    },
    {
      "epoch": 0.47833333333333333,
      "grad_norm": 0.04716607555747032,
      "learning_rate": 3.804166666666667e-05,
      "loss": 0.0011,
      "step": 8610
    },
    {
      "epoch": 0.47888888888888886,
      "grad_norm": 0.12174180895090103,
      "learning_rate": 3.802777777777778e-05,
      "loss": 0.0011,
      "step": 8620
    },
    {
      "epoch": 0.47944444444444445,
      "grad_norm": 0.04791077598929405,
      "learning_rate": 3.8013888888888897e-05,
      "loss": 0.0012,
      "step": 8630
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.0,
      "learning_rate": 3.8e-05,
      "loss": 0.0024,
      "step": 8640
    },
    {
      "epoch": 0.48055555555555557,
      "grad_norm": 0.18198621273040771,
      "learning_rate": 3.7986111111111114e-05,
      "loss": 0.0012,
      "step": 8650
    },
    {
      "epoch": 0.4811111111111111,
      "grad_norm": 0.0,
      "learning_rate": 3.797222222222223e-05,
      "loss": 0.0018,
      "step": 8660
    },
    {
      "epoch": 0.4816666666666667,
      "grad_norm": 0.11737965792417526,
      "learning_rate": 3.795833333333333e-05,
      "loss": 0.0011,
      "step": 8670
    },
    {
      "epoch": 0.4822222222222222,
      "grad_norm": 0.0,
      "learning_rate": 3.7944444444444444e-05,
      "loss": 0.0007,
      "step": 8680
    },
    {
      "epoch": 0.48277777777777775,
      "grad_norm": 0.13262183964252472,
      "learning_rate": 3.793055555555556e-05,
      "loss": 0.0019,
      "step": 8690
    },
    {
      "epoch": 0.48333333333333334,
      "grad_norm": 0.047760698944330215,
      "learning_rate": 3.791666666666667e-05,
      "loss": 0.0012,
      "step": 8700
    },
    {
      "epoch": 0.48388888888888887,
      "grad_norm": 0.11864586919546127,
      "learning_rate": 3.790277777777778e-05,
      "loss": 0.0016,
      "step": 8710
    },
    {
      "epoch": 0.48444444444444446,
      "grad_norm": 0.0,
      "learning_rate": 3.7888888888888894e-05,
      "loss": 0.0009,
      "step": 8720
    },
    {
      "epoch": 0.485,
      "grad_norm": 0.2689019441604614,
      "learning_rate": 3.7875e-05,
      "loss": 0.0014,
      "step": 8730
    },
    {
      "epoch": 0.4855555555555556,
      "grad_norm": 0.34101176261901855,
      "learning_rate": 3.786111111111111e-05,
      "loss": 0.0013,
      "step": 8740
    },
    {
      "epoch": 0.4861111111111111,
      "grad_norm": 0.0,
      "learning_rate": 3.7847222222222224e-05,
      "loss": 0.0009,
      "step": 8750
    },
    {
      "epoch": 0.4866666666666667,
      "grad_norm": 0.08515840023756027,
      "learning_rate": 3.7833333333333336e-05,
      "loss": 0.0004,
      "step": 8760
    },
    {
      "epoch": 0.4872222222222222,
      "grad_norm": 0.04266206547617912,
      "learning_rate": 3.781944444444445e-05,
      "loss": 0.0008,
      "step": 8770
    },
    {
      "epoch": 0.48777777777777775,
      "grad_norm": 0.12281867861747742,
      "learning_rate": 3.7805555555555554e-05,
      "loss": 0.001,
      "step": 8780
    },
    {
      "epoch": 0.48833333333333334,
      "grad_norm": 0.4730646312236786,
      "learning_rate": 3.779166666666667e-05,
      "loss": 0.0003,
      "step": 8790
    },
    {
      "epoch": 0.4888888888888889,
      "grad_norm": 0.0517386756837368,
      "learning_rate": 3.777777777777778e-05,
      "loss": 0.0009,
      "step": 8800
    },
    {
      "epoch": 0.48944444444444446,
      "grad_norm": 0.0,
      "learning_rate": 3.776388888888889e-05,
      "loss": 0.0008,
      "step": 8810
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.0,
      "learning_rate": 3.775e-05,
      "loss": 0.0004,
      "step": 8820
    },
    {
      "epoch": 0.4905555555555556,
      "grad_norm": 0.0,
      "learning_rate": 3.773611111111111e-05,
      "loss": 0.0008,
      "step": 8830
    },
    {
      "epoch": 0.4911111111111111,
      "grad_norm": 0.1322547346353531,
      "learning_rate": 3.772222222222223e-05,
      "loss": 0.0013,
      "step": 8840
    },
    {
      "epoch": 0.49166666666666664,
      "grad_norm": 0.08745086193084717,
      "learning_rate": 3.770833333333333e-05,
      "loss": 0.0006,
      "step": 8850
    },
    {
      "epoch": 0.4922222222222222,
      "grad_norm": 0.04375768452882767,
      "learning_rate": 3.769444444444445e-05,
      "loss": 0.0019,
      "step": 8860
    },
    {
      "epoch": 0.49277777777777776,
      "grad_norm": 0.21063657104969025,
      "learning_rate": 3.768055555555556e-05,
      "loss": 0.0009,
      "step": 8870
    },
    {
      "epoch": 0.49333333333333335,
      "grad_norm": 0.043783750385046005,
      "learning_rate": 3.766666666666667e-05,
      "loss": 0.0014,
      "step": 8880
    },
    {
      "epoch": 0.4938888888888889,
      "grad_norm": 0.0,
      "learning_rate": 3.765277777777778e-05,
      "loss": 0.0021,
      "step": 8890
    },
    {
      "epoch": 0.49444444444444446,
      "grad_norm": 0.07844525575637817,
      "learning_rate": 3.763888888888889e-05,
      "loss": 0.0009,
      "step": 8900
    },
    {
      "epoch": 0.495,
      "grad_norm": 0.14366209506988525,
      "learning_rate": 3.7625e-05,
      "loss": 0.0011,
      "step": 8910
    },
    {
      "epoch": 0.4955555555555556,
      "grad_norm": 0.20357805490493774,
      "learning_rate": 3.761111111111111e-05,
      "loss": 0.0009,
      "step": 8920
    },
    {
      "epoch": 0.4961111111111111,
      "grad_norm": 0.059987377375364304,
      "learning_rate": 3.7597222222222224e-05,
      "loss": 0.001,
      "step": 8930
    },
    {
      "epoch": 0.49666666666666665,
      "grad_norm": 0.2080269455909729,
      "learning_rate": 3.7583333333333337e-05,
      "loss": 0.0008,
      "step": 8940
    },
    {
      "epoch": 0.49722222222222223,
      "grad_norm": 0.16399265825748444,
      "learning_rate": 3.756944444444445e-05,
      "loss": 0.001,
      "step": 8950
    },
    {
      "epoch": 0.49777777777777776,
      "grad_norm": 0.049710992723703384,
      "learning_rate": 3.7555555555555554e-05,
      "loss": 0.0009,
      "step": 8960
    },
    {
      "epoch": 0.49833333333333335,
      "grad_norm": 0.03539242595434189,
      "learning_rate": 3.754166666666667e-05,
      "loss": 0.0007,
      "step": 8970
    },
    {
      "epoch": 0.4988888888888889,
      "grad_norm": 0.3261003792285919,
      "learning_rate": 3.752777777777778e-05,
      "loss": 0.0016,
      "step": 8980
    },
    {
      "epoch": 0.49944444444444447,
      "grad_norm": 0.0,
      "learning_rate": 3.751388888888889e-05,
      "loss": 0.0014,
      "step": 8990
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.1395142376422882,
      "learning_rate": 3.7500000000000003e-05,
      "loss": 0.0016,
      "step": 9000
    },
    {
      "epoch": 0.5005555555555555,
      "grad_norm": 0.04333379492163658,
      "learning_rate": 3.748611111111111e-05,
      "loss": 0.0011,
      "step": 9010
    },
    {
      "epoch": 0.5011111111111111,
      "grad_norm": 0.1146312803030014,
      "learning_rate": 3.747222222222223e-05,
      "loss": 0.0009,
      "step": 9020
    },
    {
      "epoch": 0.5016666666666667,
      "grad_norm": 0.062065448611974716,
      "learning_rate": 3.7458333333333334e-05,
      "loss": 0.0008,
      "step": 9030
    },
    {
      "epoch": 0.5022222222222222,
      "grad_norm": 0.0,
      "learning_rate": 3.7444444444444446e-05,
      "loss": 0.0024,
      "step": 9040
    },
    {
      "epoch": 0.5027777777777778,
      "grad_norm": 0.0,
      "learning_rate": 3.743055555555556e-05,
      "loss": 0.0004,
      "step": 9050
    },
    {
      "epoch": 0.5033333333333333,
      "grad_norm": 0.0519687756896019,
      "learning_rate": 3.7416666666666664e-05,
      "loss": 0.0007,
      "step": 9060
    },
    {
      "epoch": 0.5038888888888889,
      "grad_norm": 0.15174983441829681,
      "learning_rate": 3.740277777777778e-05,
      "loss": 0.0003,
      "step": 9070
    },
    {
      "epoch": 0.5044444444444445,
      "grad_norm": 0.09303775429725647,
      "learning_rate": 3.738888888888889e-05,
      "loss": 0.0007,
      "step": 9080
    },
    {
      "epoch": 0.505,
      "grad_norm": 0.0,
      "learning_rate": 3.737500000000001e-05,
      "loss": 0.0015,
      "step": 9090
    },
    {
      "epoch": 0.5055555555555555,
      "grad_norm": 0.13852377235889435,
      "learning_rate": 3.736111111111111e-05,
      "loss": 0.0008,
      "step": 9100
    },
    {
      "epoch": 0.5061111111111111,
      "grad_norm": 0.143242746591568,
      "learning_rate": 3.7347222222222225e-05,
      "loss": 0.0011,
      "step": 9110
    },
    {
      "epoch": 0.5066666666666667,
      "grad_norm": 0.12672705948352814,
      "learning_rate": 3.733333333333334e-05,
      "loss": 0.0012,
      "step": 9120
    },
    {
      "epoch": 0.5072222222222222,
      "grad_norm": 0.13519971072673798,
      "learning_rate": 3.731944444444444e-05,
      "loss": 0.0023,
      "step": 9130
    },
    {
      "epoch": 0.5077777777777778,
      "grad_norm": 0.0,
      "learning_rate": 3.7305555555555555e-05,
      "loss": 0.0009,
      "step": 9140
    },
    {
      "epoch": 0.5083333333333333,
      "grad_norm": 0.0,
      "learning_rate": 3.729166666666667e-05,
      "loss": 0.0009,
      "step": 9150
    },
    {
      "epoch": 0.5088888888888888,
      "grad_norm": 0.0,
      "learning_rate": 3.727777777777778e-05,
      "loss": 0.0012,
      "step": 9160
    },
    {
      "epoch": 0.5094444444444445,
      "grad_norm": 0.12363854795694351,
      "learning_rate": 3.726388888888889e-05,
      "loss": 0.0011,
      "step": 9170
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.10515041649341583,
      "learning_rate": 3.7250000000000004e-05,
      "loss": 0.0015,
      "step": 9180
    },
    {
      "epoch": 0.5105555555555555,
      "grad_norm": 0.04928278177976608,
      "learning_rate": 3.723611111111111e-05,
      "loss": 0.0005,
      "step": 9190
    },
    {
      "epoch": 0.5111111111111111,
      "grad_norm": 0.0,
      "learning_rate": 3.722222222222222e-05,
      "loss": 0.0011,
      "step": 9200
    },
    {
      "epoch": 0.5116666666666667,
      "grad_norm": 0.04364936053752899,
      "learning_rate": 3.7208333333333334e-05,
      "loss": 0.0001,
      "step": 9210
    },
    {
      "epoch": 0.5122222222222222,
      "grad_norm": 0.1528174728155136,
      "learning_rate": 3.7194444444444447e-05,
      "loss": 0.0001,
      "step": 9220
    },
    {
      "epoch": 0.5127777777777778,
      "grad_norm": 0.09639600664377213,
      "learning_rate": 3.718055555555556e-05,
      "loss": 0.001,
      "step": 9230
    },
    {
      "epoch": 0.5133333333333333,
      "grad_norm": 0.17201842367649078,
      "learning_rate": 3.7166666666666664e-05,
      "loss": 0.001,
      "step": 9240
    },
    {
      "epoch": 0.5138888888888888,
      "grad_norm": 0.17247362434864044,
      "learning_rate": 3.715277777777778e-05,
      "loss": 0.0004,
      "step": 9250
    },
    {
      "epoch": 0.5144444444444445,
      "grad_norm": 0.0,
      "learning_rate": 3.713888888888889e-05,
      "loss": 0.0009,
      "step": 9260
    },
    {
      "epoch": 0.515,
      "grad_norm": 0.15012991428375244,
      "learning_rate": 3.7125e-05,
      "loss": 0.0008,
      "step": 9270
    },
    {
      "epoch": 0.5155555555555555,
      "grad_norm": 0.1300673633813858,
      "learning_rate": 3.7111111111111113e-05,
      "loss": 0.0012,
      "step": 9280
    },
    {
      "epoch": 0.5161111111111111,
      "grad_norm": 0.05044617876410484,
      "learning_rate": 3.709722222222222e-05,
      "loss": 0.0013,
      "step": 9290
    },
    {
      "epoch": 0.5166666666666667,
      "grad_norm": 0.24799181520938873,
      "learning_rate": 3.708333333333334e-05,
      "loss": 0.0005,
      "step": 9300
    },
    {
      "epoch": 0.5172222222222222,
      "grad_norm": 0.29458630084991455,
      "learning_rate": 3.7069444444444443e-05,
      "loss": 0.0015,
      "step": 9310
    },
    {
      "epoch": 0.5177777777777778,
      "grad_norm": 0.4139556884765625,
      "learning_rate": 3.705555555555556e-05,
      "loss": 0.0014,
      "step": 9320
    },
    {
      "epoch": 0.5183333333333333,
      "grad_norm": 0.04587594419717789,
      "learning_rate": 3.704166666666667e-05,
      "loss": 0.0006,
      "step": 9330
    },
    {
      "epoch": 0.5188888888888888,
      "grad_norm": 0.17834988236427307,
      "learning_rate": 3.702777777777778e-05,
      "loss": 0.0009,
      "step": 9340
    },
    {
      "epoch": 0.5194444444444445,
      "grad_norm": 0.03505200147628784,
      "learning_rate": 3.701388888888889e-05,
      "loss": 0.0009,
      "step": 9350
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.0,
      "learning_rate": 3.7e-05,
      "loss": 0.0013,
      "step": 9360
    },
    {
      "epoch": 0.5205555555555555,
      "grad_norm": 0.13990077376365662,
      "learning_rate": 3.698611111111111e-05,
      "loss": 0.0011,
      "step": 9370
    },
    {
      "epoch": 0.5211111111111111,
      "grad_norm": 0.0442451536655426,
      "learning_rate": 3.697222222222222e-05,
      "loss": 0.0016,
      "step": 9380
    },
    {
      "epoch": 0.5216666666666666,
      "grad_norm": 0.0,
      "learning_rate": 3.6958333333333335e-05,
      "loss": 0.0022,
      "step": 9390
    },
    {
      "epoch": 0.5222222222222223,
      "grad_norm": 0.18746130168437958,
      "learning_rate": 3.694444444444445e-05,
      "loss": 0.0016,
      "step": 9400
    },
    {
      "epoch": 0.5227777777777778,
      "grad_norm": 0.13855034112930298,
      "learning_rate": 3.693055555555556e-05,
      "loss": 0.001,
      "step": 9410
    },
    {
      "epoch": 0.5233333333333333,
      "grad_norm": 0.2865823805332184,
      "learning_rate": 3.6916666666666665e-05,
      "loss": 0.0009,
      "step": 9420
    },
    {
      "epoch": 0.5238888888888888,
      "grad_norm": 0.3585791289806366,
      "learning_rate": 3.690277777777778e-05,
      "loss": 0.0014,
      "step": 9430
    },
    {
      "epoch": 0.5244444444444445,
      "grad_norm": 0.1700940579175949,
      "learning_rate": 3.688888888888889e-05,
      "loss": 0.001,
      "step": 9440
    },
    {
      "epoch": 0.525,
      "grad_norm": 0.10334301739931107,
      "learning_rate": 3.6875e-05,
      "loss": 0.0007,
      "step": 9450
    },
    {
      "epoch": 0.5255555555555556,
      "grad_norm": 0.1404232680797577,
      "learning_rate": 3.6861111111111114e-05,
      "loss": 0.002,
      "step": 9460
    },
    {
      "epoch": 0.5261111111111111,
      "grad_norm": 0.042610421776771545,
      "learning_rate": 3.684722222222222e-05,
      "loss": 0.0013,
      "step": 9470
    },
    {
      "epoch": 0.5266666666666666,
      "grad_norm": 0.13183747231960297,
      "learning_rate": 3.683333333333334e-05,
      "loss": 0.0006,
      "step": 9480
    },
    {
      "epoch": 0.5272222222222223,
      "grad_norm": 0.1655910164117813,
      "learning_rate": 3.6819444444444444e-05,
      "loss": 0.0008,
      "step": 9490
    },
    {
      "epoch": 0.5277777777777778,
      "grad_norm": 0.2339555025100708,
      "learning_rate": 3.6805555555555556e-05,
      "loss": 0.0014,
      "step": 9500
    },
    {
      "epoch": 0.5283333333333333,
      "grad_norm": 0.047246113419532776,
      "learning_rate": 3.679166666666667e-05,
      "loss": 0.0008,
      "step": 9510
    },
    {
      "epoch": 0.5288888888888889,
      "grad_norm": 0.10031266510486603,
      "learning_rate": 3.677777777777778e-05,
      "loss": 0.0007,
      "step": 9520
    },
    {
      "epoch": 0.5294444444444445,
      "grad_norm": 0.10032323002815247,
      "learning_rate": 3.676388888888889e-05,
      "loss": 0.0006,
      "step": 9530
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.05802421644330025,
      "learning_rate": 3.675e-05,
      "loss": 0.0015,
      "step": 9540
    },
    {
      "epoch": 0.5305555555555556,
      "grad_norm": 0.14765070378780365,
      "learning_rate": 3.673611111111112e-05,
      "loss": 0.0008,
      "step": 9550
    },
    {
      "epoch": 0.5311111111111111,
      "grad_norm": 0.05814805626869202,
      "learning_rate": 3.672222222222222e-05,
      "loss": 0.0008,
      "step": 9560
    },
    {
      "epoch": 0.5316666666666666,
      "grad_norm": 0.11161655932664871,
      "learning_rate": 3.6708333333333336e-05,
      "loss": 0.0006,
      "step": 9570
    },
    {
      "epoch": 0.5322222222222223,
      "grad_norm": 0.17520561814308167,
      "learning_rate": 3.669444444444445e-05,
      "loss": 0.0014,
      "step": 9580
    },
    {
      "epoch": 0.5327777777777778,
      "grad_norm": 0.10954128205776215,
      "learning_rate": 3.668055555555556e-05,
      "loss": 0.0011,
      "step": 9590
    },
    {
      "epoch": 0.5333333333333333,
      "grad_norm": 0.08769743144512177,
      "learning_rate": 3.6666666666666666e-05,
      "loss": 0.0018,
      "step": 9600
    },
    {
      "epoch": 0.5338888888888889,
      "grad_norm": 0.045389387756586075,
      "learning_rate": 3.665277777777778e-05,
      "loss": 0.0008,
      "step": 9610
    },
    {
      "epoch": 0.5344444444444445,
      "grad_norm": 0.13170403242111206,
      "learning_rate": 3.663888888888889e-05,
      "loss": 0.0015,
      "step": 9620
    },
    {
      "epoch": 0.535,
      "grad_norm": 0.0,
      "learning_rate": 3.6625e-05,
      "loss": 0.0009,
      "step": 9630
    },
    {
      "epoch": 0.5355555555555556,
      "grad_norm": 0.0,
      "learning_rate": 3.6611111111111115e-05,
      "loss": 0.0012,
      "step": 9640
    },
    {
      "epoch": 0.5361111111111111,
      "grad_norm": 0.3303285837173462,
      "learning_rate": 3.659722222222222e-05,
      "loss": 0.0009,
      "step": 9650
    },
    {
      "epoch": 0.5366666666666666,
      "grad_norm": 0.0,
      "learning_rate": 3.658333333333334e-05,
      "loss": 0.0003,
      "step": 9660
    },
    {
      "epoch": 0.5372222222222223,
      "grad_norm": 0.05377599969506264,
      "learning_rate": 3.6569444444444445e-05,
      "loss": 0.0015,
      "step": 9670
    },
    {
      "epoch": 0.5377777777777778,
      "grad_norm": 0.03928687795996666,
      "learning_rate": 3.655555555555556e-05,
      "loss": 0.0012,
      "step": 9680
    },
    {
      "epoch": 0.5383333333333333,
      "grad_norm": 0.3185040056705475,
      "learning_rate": 3.654166666666667e-05,
      "loss": 0.002,
      "step": 9690
    },
    {
      "epoch": 0.5388888888888889,
      "grad_norm": 0.0,
      "learning_rate": 3.6527777777777775e-05,
      "loss": 0.0012,
      "step": 9700
    },
    {
      "epoch": 0.5394444444444444,
      "grad_norm": 0.0,
      "learning_rate": 3.6513888888888894e-05,
      "loss": 0.0006,
      "step": 9710
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.0687030702829361,
      "learning_rate": 3.65e-05,
      "loss": 0.0014,
      "step": 9720
    },
    {
      "epoch": 0.5405555555555556,
      "grad_norm": 0.047644201666116714,
      "learning_rate": 3.648611111111112e-05,
      "loss": 0.0003,
      "step": 9730
    },
    {
      "epoch": 0.5411111111111111,
      "grad_norm": 0.0,
      "learning_rate": 3.6472222222222224e-05,
      "loss": 0.0008,
      "step": 9740
    },
    {
      "epoch": 0.5416666666666666,
      "grad_norm": 0.0,
      "learning_rate": 3.6458333333333336e-05,
      "loss": 0.0006,
      "step": 9750
    },
    {
      "epoch": 0.5422222222222223,
      "grad_norm": 0.06032847985625267,
      "learning_rate": 3.644444444444445e-05,
      "loss": 0.0019,
      "step": 9760
    },
    {
      "epoch": 0.5427777777777778,
      "grad_norm": 0.05709121376276016,
      "learning_rate": 3.6430555555555554e-05,
      "loss": 0.0012,
      "step": 9770
    },
    {
      "epoch": 0.5433333333333333,
      "grad_norm": 0.1683674454689026,
      "learning_rate": 3.641666666666667e-05,
      "loss": 0.0007,
      "step": 9780
    },
    {
      "epoch": 0.5438888888888889,
      "grad_norm": 0.3573131561279297,
      "learning_rate": 3.640277777777778e-05,
      "loss": 0.0013,
      "step": 9790
    },
    {
      "epoch": 0.5444444444444444,
      "grad_norm": 0.1348276138305664,
      "learning_rate": 3.638888888888889e-05,
      "loss": 0.001,
      "step": 9800
    },
    {
      "epoch": 0.545,
      "grad_norm": 0.052984919399023056,
      "learning_rate": 3.6375e-05,
      "loss": 0.0013,
      "step": 9810
    },
    {
      "epoch": 0.5455555555555556,
      "grad_norm": 0.0795014351606369,
      "learning_rate": 3.6361111111111116e-05,
      "loss": 0.0021,
      "step": 9820
    },
    {
      "epoch": 0.5461111111111111,
      "grad_norm": 0.07791728526353836,
      "learning_rate": 3.634722222222222e-05,
      "loss": 0.0011,
      "step": 9830
    },
    {
      "epoch": 0.5466666666666666,
      "grad_norm": 0.05179397389292717,
      "learning_rate": 3.633333333333333e-05,
      "loss": 0.0007,
      "step": 9840
    },
    {
      "epoch": 0.5472222222222223,
      "grad_norm": 0.0,
      "learning_rate": 3.6319444444444446e-05,
      "loss": 0.0009,
      "step": 9850
    },
    {
      "epoch": 0.5477777777777778,
      "grad_norm": 0.23481062054634094,
      "learning_rate": 3.630555555555556e-05,
      "loss": 0.0015,
      "step": 9860
    },
    {
      "epoch": 0.5483333333333333,
      "grad_norm": 0.3028336763381958,
      "learning_rate": 3.629166666666667e-05,
      "loss": 0.0018,
      "step": 9870
    },
    {
      "epoch": 0.5488888888888889,
      "grad_norm": 0.08448981493711472,
      "learning_rate": 3.6277777777777776e-05,
      "loss": 0.0012,
      "step": 9880
    },
    {
      "epoch": 0.5494444444444444,
      "grad_norm": 0.0,
      "learning_rate": 3.6263888888888895e-05,
      "loss": 0.0015,
      "step": 9890
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.2521136999130249,
      "learning_rate": 3.625e-05,
      "loss": 0.0005,
      "step": 9900
    },
    {
      "epoch": 0.5505555555555556,
      "grad_norm": 0.0807848647236824,
      "learning_rate": 3.623611111111111e-05,
      "loss": 0.0017,
      "step": 9910
    },
    {
      "epoch": 0.5511111111111111,
      "grad_norm": 0.10348726063966751,
      "learning_rate": 3.6222222222222225e-05,
      "loss": 0.0016,
      "step": 9920
    },
    {
      "epoch": 0.5516666666666666,
      "grad_norm": 0.02085803635418415,
      "learning_rate": 3.620833333333333e-05,
      "loss": 0.0016,
      "step": 9930
    },
    {
      "epoch": 0.5522222222222222,
      "grad_norm": 0.1258024275302887,
      "learning_rate": 3.619444444444445e-05,
      "loss": 0.0011,
      "step": 9940
    },
    {
      "epoch": 0.5527777777777778,
      "grad_norm": 0.07470838725566864,
      "learning_rate": 3.6180555555555555e-05,
      "loss": 0.0006,
      "step": 9950
    },
    {
      "epoch": 0.5533333333333333,
      "grad_norm": 0.17250226438045502,
      "learning_rate": 3.6166666666666674e-05,
      "loss": 0.0016,
      "step": 9960
    },
    {
      "epoch": 0.5538888888888889,
      "grad_norm": 0.2084958553314209,
      "learning_rate": 3.615277777777778e-05,
      "loss": 0.0011,
      "step": 9970
    },
    {
      "epoch": 0.5544444444444444,
      "grad_norm": 0.09868065267801285,
      "learning_rate": 3.613888888888889e-05,
      "loss": 0.0003,
      "step": 9980
    },
    {
      "epoch": 0.555,
      "grad_norm": 0.04537120461463928,
      "learning_rate": 3.6125000000000004e-05,
      "loss": 0.0005,
      "step": 9990
    },
    {
      "epoch": 0.5555555555555556,
      "grad_norm": 0.045387301594018936,
      "learning_rate": 3.611111111111111e-05,
      "loss": 0.0008,
      "step": 10000
    },
    {
      "epoch": 0.5561111111111111,
      "grad_norm": 0.0,
      "learning_rate": 3.609722222222223e-05,
      "loss": 0.0005,
      "step": 10010
    },
    {
      "epoch": 0.5566666666666666,
      "grad_norm": 0.04371466860175133,
      "learning_rate": 3.6083333333333334e-05,
      "loss": 0.0015,
      "step": 10020
    },
    {
      "epoch": 0.5572222222222222,
      "grad_norm": 0.0,
      "learning_rate": 3.6069444444444446e-05,
      "loss": 0.0015,
      "step": 10030
    },
    {
      "epoch": 0.5577777777777778,
      "grad_norm": 0.34324905276298523,
      "learning_rate": 3.605555555555556e-05,
      "loss": 0.0014,
      "step": 10040
    },
    {
      "epoch": 0.5583333333333333,
      "grad_norm": 0.14950066804885864,
      "learning_rate": 3.604166666666667e-05,
      "loss": 0.0006,
      "step": 10050
    },
    {
      "epoch": 0.5588888888888889,
      "grad_norm": 0.04414231702685356,
      "learning_rate": 3.6027777777777776e-05,
      "loss": 0.0008,
      "step": 10060
    },
    {
      "epoch": 0.5594444444444444,
      "grad_norm": 0.05957532674074173,
      "learning_rate": 3.601388888888889e-05,
      "loss": 0.0005,
      "step": 10070
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.41613149642944336,
      "learning_rate": 3.6e-05,
      "loss": 0.0019,
      "step": 10080
    },
    {
      "epoch": 0.5605555555555556,
      "grad_norm": 0.0631161481142044,
      "learning_rate": 3.598611111111111e-05,
      "loss": 0.0014,
      "step": 10090
    },
    {
      "epoch": 0.5611111111111111,
      "grad_norm": 0.42665010690689087,
      "learning_rate": 3.5972222222222225e-05,
      "loss": 0.0018,
      "step": 10100
    },
    {
      "epoch": 0.5616666666666666,
      "grad_norm": 0.047730930149555206,
      "learning_rate": 3.595833333333333e-05,
      "loss": 0.0009,
      "step": 10110
    },
    {
      "epoch": 0.5622222222222222,
      "grad_norm": 0.1702064871788025,
      "learning_rate": 3.594444444444445e-05,
      "loss": 0.0009,
      "step": 10120
    },
    {
      "epoch": 0.5627777777777778,
      "grad_norm": 0.2082938849925995,
      "learning_rate": 3.5930555555555556e-05,
      "loss": 0.0008,
      "step": 10130
    },
    {
      "epoch": 0.5633333333333334,
      "grad_norm": 0.1693139374256134,
      "learning_rate": 3.591666666666667e-05,
      "loss": 0.0004,
      "step": 10140
    },
    {
      "epoch": 0.5638888888888889,
      "grad_norm": 0.04456412419676781,
      "learning_rate": 3.590277777777778e-05,
      "loss": 0.0006,
      "step": 10150
    },
    {
      "epoch": 0.5644444444444444,
      "grad_norm": 0.04414065182209015,
      "learning_rate": 3.5888888888888886e-05,
      "loss": 0.0003,
      "step": 10160
    },
    {
      "epoch": 0.565,
      "grad_norm": 0.049198321998119354,
      "learning_rate": 3.5875000000000005e-05,
      "loss": 0.0004,
      "step": 10170
    },
    {
      "epoch": 0.5655555555555556,
      "grad_norm": 0.08783493936061859,
      "learning_rate": 3.586111111111111e-05,
      "loss": 0.0011,
      "step": 10180
    },
    {
      "epoch": 0.5661111111111111,
      "grad_norm": 0.25056570768356323,
      "learning_rate": 3.584722222222223e-05,
      "loss": 0.0008,
      "step": 10190
    },
    {
      "epoch": 0.5666666666666667,
      "grad_norm": 0.11387738585472107,
      "learning_rate": 3.5833333333333335e-05,
      "loss": 0.0009,
      "step": 10200
    },
    {
      "epoch": 0.5672222222222222,
      "grad_norm": 0.09082689881324768,
      "learning_rate": 3.581944444444445e-05,
      "loss": 0.0009,
      "step": 10210
    },
    {
      "epoch": 0.5677777777777778,
      "grad_norm": 0.145171120762825,
      "learning_rate": 3.580555555555556e-05,
      "loss": 0.0007,
      "step": 10220
    },
    {
      "epoch": 0.5683333333333334,
      "grad_norm": 0.275562584400177,
      "learning_rate": 3.5791666666666665e-05,
      "loss": 0.0012,
      "step": 10230
    },
    {
      "epoch": 0.5688888888888889,
      "grad_norm": 0.1856364607810974,
      "learning_rate": 3.577777777777778e-05,
      "loss": 0.0009,
      "step": 10240
    },
    {
      "epoch": 0.5694444444444444,
      "grad_norm": 0.14455534517765045,
      "learning_rate": 3.576388888888889e-05,
      "loss": 0.0009,
      "step": 10250
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.0,
      "learning_rate": 3.575e-05,
      "loss": 0.0012,
      "step": 10260
    },
    {
      "epoch": 0.5705555555555556,
      "grad_norm": 0.12428051978349686,
      "learning_rate": 3.5736111111111114e-05,
      "loss": 0.0018,
      "step": 10270
    },
    {
      "epoch": 0.5711111111111111,
      "grad_norm": 0.04934634640812874,
      "learning_rate": 3.5722222222222226e-05,
      "loss": 0.0007,
      "step": 10280
    },
    {
      "epoch": 0.5716666666666667,
      "grad_norm": 0.09187015146017075,
      "learning_rate": 3.570833333333333e-05,
      "loss": 0.0019,
      "step": 10290
    },
    {
      "epoch": 0.5722222222222222,
      "grad_norm": 0.047076378017663956,
      "learning_rate": 3.5694444444444444e-05,
      "loss": 0.0009,
      "step": 10300
    },
    {
      "epoch": 0.5727777777777778,
      "grad_norm": 0.1533537060022354,
      "learning_rate": 3.5680555555555556e-05,
      "loss": 0.0007,
      "step": 10310
    },
    {
      "epoch": 0.5733333333333334,
      "grad_norm": 0.05074606463313103,
      "learning_rate": 3.566666666666667e-05,
      "loss": 0.0007,
      "step": 10320
    },
    {
      "epoch": 0.5738888888888889,
      "grad_norm": 0.04303012788295746,
      "learning_rate": 3.565277777777778e-05,
      "loss": 0.0009,
      "step": 10330
    },
    {
      "epoch": 0.5744444444444444,
      "grad_norm": 0.0,
      "learning_rate": 3.5638888888888886e-05,
      "loss": 0.0013,
      "step": 10340
    },
    {
      "epoch": 0.575,
      "grad_norm": 0.0861516147851944,
      "learning_rate": 3.5625000000000005e-05,
      "loss": 0.0013,
      "step": 10350
    },
    {
      "epoch": 0.5755555555555556,
      "grad_norm": 0.08816110342741013,
      "learning_rate": 3.561111111111111e-05,
      "loss": 0.0009,
      "step": 10360
    },
    {
      "epoch": 0.5761111111111111,
      "grad_norm": 0.0,
      "learning_rate": 3.559722222222222e-05,
      "loss": 0.0009,
      "step": 10370
    },
    {
      "epoch": 0.5766666666666667,
      "grad_norm": 0.13773469626903534,
      "learning_rate": 3.5583333333333335e-05,
      "loss": 0.001,
      "step": 10380
    },
    {
      "epoch": 0.5772222222222222,
      "grad_norm": 0.0,
      "learning_rate": 3.556944444444444e-05,
      "loss": 0.0014,
      "step": 10390
    },
    {
      "epoch": 0.5777777777777777,
      "grad_norm": 0.17670275270938873,
      "learning_rate": 3.555555555555556e-05,
      "loss": 0.0004,
      "step": 10400
    },
    {
      "epoch": 0.5783333333333334,
      "grad_norm": 0.0,
      "learning_rate": 3.5541666666666665e-05,
      "loss": 0.001,
      "step": 10410
    },
    {
      "epoch": 0.5788888888888889,
      "grad_norm": 0.035062093287706375,
      "learning_rate": 3.5527777777777785e-05,
      "loss": 0.0008,
      "step": 10420
    },
    {
      "epoch": 0.5794444444444444,
      "grad_norm": 0.09237483143806458,
      "learning_rate": 3.551388888888889e-05,
      "loss": 0.0009,
      "step": 10430
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.1770145446062088,
      "learning_rate": 3.55e-05,
      "loss": 0.0008,
      "step": 10440
    },
    {
      "epoch": 0.5805555555555556,
      "grad_norm": 0.09167374670505524,
      "learning_rate": 3.5486111111111115e-05,
      "loss": 0.0013,
      "step": 10450
    },
    {
      "epoch": 0.5811111111111111,
      "grad_norm": 0.08760417252779007,
      "learning_rate": 3.547222222222222e-05,
      "loss": 0.0011,
      "step": 10460
    },
    {
      "epoch": 0.5816666666666667,
      "grad_norm": 0.015768244862556458,
      "learning_rate": 3.545833333333333e-05,
      "loss": 0.001,
      "step": 10470
    },
    {
      "epoch": 0.5822222222222222,
      "grad_norm": 0.0,
      "learning_rate": 3.5444444444444445e-05,
      "loss": 0.0013,
      "step": 10480
    },
    {
      "epoch": 0.5827777777777777,
      "grad_norm": 0.0,
      "learning_rate": 3.543055555555556e-05,
      "loss": 0.0008,
      "step": 10490
    },
    {
      "epoch": 0.5833333333333334,
      "grad_norm": 0.11469592899084091,
      "learning_rate": 3.541666666666667e-05,
      "loss": 0.001,
      "step": 10500
    },
    {
      "epoch": 0.5838888888888889,
      "grad_norm": 0.0,
      "learning_rate": 3.540277777777778e-05,
      "loss": 0.0011,
      "step": 10510
    },
    {
      "epoch": 0.5844444444444444,
      "grad_norm": 0.23155780136585236,
      "learning_rate": 3.538888888888889e-05,
      "loss": 0.0012,
      "step": 10520
    },
    {
      "epoch": 0.585,
      "grad_norm": 0.16693313419818878,
      "learning_rate": 3.5375e-05,
      "loss": 0.0017,
      "step": 10530
    },
    {
      "epoch": 0.5855555555555556,
      "grad_norm": 0.0,
      "learning_rate": 3.536111111111111e-05,
      "loss": 0.0015,
      "step": 10540
    },
    {
      "epoch": 0.5861111111111111,
      "grad_norm": 0.2630104720592499,
      "learning_rate": 3.5347222222222224e-05,
      "loss": 0.0002,
      "step": 10550
    },
    {
      "epoch": 0.5866666666666667,
      "grad_norm": 0.14984720945358276,
      "learning_rate": 3.5333333333333336e-05,
      "loss": 0.0006,
      "step": 10560
    },
    {
      "epoch": 0.5872222222222222,
      "grad_norm": 0.0,
      "learning_rate": 3.531944444444444e-05,
      "loss": 0.001,
      "step": 10570
    },
    {
      "epoch": 0.5877777777777777,
      "grad_norm": 0.1554941087961197,
      "learning_rate": 3.530555555555556e-05,
      "loss": 0.0015,
      "step": 10580
    },
    {
      "epoch": 0.5883333333333334,
      "grad_norm": 0.09532011300325394,
      "learning_rate": 3.5291666666666666e-05,
      "loss": 0.0003,
      "step": 10590
    },
    {
      "epoch": 0.5888888888888889,
      "grad_norm": 0.08715671300888062,
      "learning_rate": 3.527777777777778e-05,
      "loss": 0.0011,
      "step": 10600
    },
    {
      "epoch": 0.5894444444444444,
      "grad_norm": 0.10941024869680405,
      "learning_rate": 3.526388888888889e-05,
      "loss": 0.0015,
      "step": 10610
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.0,
      "learning_rate": 3.525e-05,
      "loss": 0.001,
      "step": 10620
    },
    {
      "epoch": 0.5905555555555555,
      "grad_norm": 0.28248775005340576,
      "learning_rate": 3.5236111111111115e-05,
      "loss": 0.0011,
      "step": 10630
    },
    {
      "epoch": 0.5911111111111111,
      "grad_norm": 0.14068379998207092,
      "learning_rate": 3.522222222222222e-05,
      "loss": 0.0005,
      "step": 10640
    },
    {
      "epoch": 0.5916666666666667,
      "grad_norm": 0.0,
      "learning_rate": 3.520833333333334e-05,
      "loss": 0.0009,
      "step": 10650
    },
    {
      "epoch": 0.5922222222222222,
      "grad_norm": 0.0455978587269783,
      "learning_rate": 3.5194444444444445e-05,
      "loss": 0.0004,
      "step": 10660
    },
    {
      "epoch": 0.5927777777777777,
      "grad_norm": 0.25787267088890076,
      "learning_rate": 3.518055555555556e-05,
      "loss": 0.0017,
      "step": 10670
    },
    {
      "epoch": 0.5933333333333334,
      "grad_norm": 0.0,
      "learning_rate": 3.516666666666667e-05,
      "loss": 0.0004,
      "step": 10680
    },
    {
      "epoch": 0.5938888888888889,
      "grad_norm": 0.04754040390253067,
      "learning_rate": 3.515277777777778e-05,
      "loss": 0.0008,
      "step": 10690
    },
    {
      "epoch": 0.5944444444444444,
      "grad_norm": 0.04328721761703491,
      "learning_rate": 3.513888888888889e-05,
      "loss": 0.0003,
      "step": 10700
    },
    {
      "epoch": 0.595,
      "grad_norm": 0.12012189626693726,
      "learning_rate": 3.5125e-05,
      "loss": 0.0016,
      "step": 10710
    },
    {
      "epoch": 0.5955555555555555,
      "grad_norm": 0.08257345855236053,
      "learning_rate": 3.511111111111111e-05,
      "loss": 0.0006,
      "step": 10720
    },
    {
      "epoch": 0.5961111111111111,
      "grad_norm": 0.05340554192662239,
      "learning_rate": 3.5097222222222225e-05,
      "loss": 0.0013,
      "step": 10730
    },
    {
      "epoch": 0.5966666666666667,
      "grad_norm": 0.0,
      "learning_rate": 3.508333333333334e-05,
      "loss": 0.0005,
      "step": 10740
    },
    {
      "epoch": 0.5972222222222222,
      "grad_norm": 0.1446511447429657,
      "learning_rate": 3.506944444444444e-05,
      "loss": 0.0008,
      "step": 10750
    },
    {
      "epoch": 0.5977777777777777,
      "grad_norm": 0.17265653610229492,
      "learning_rate": 3.505555555555556e-05,
      "loss": 0.0008,
      "step": 10760
    },
    {
      "epoch": 0.5983333333333334,
      "grad_norm": 0.04918072372674942,
      "learning_rate": 3.504166666666667e-05,
      "loss": 0.0004,
      "step": 10770
    },
    {
      "epoch": 0.5988888888888889,
      "grad_norm": 0.04525098577141762,
      "learning_rate": 3.502777777777778e-05,
      "loss": 0.0009,
      "step": 10780
    },
    {
      "epoch": 0.5994444444444444,
      "grad_norm": 0.09860672056674957,
      "learning_rate": 3.501388888888889e-05,
      "loss": 0.0008,
      "step": 10790
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.046109817922115326,
      "learning_rate": 3.5e-05,
      "loss": 0.0008,
      "step": 10800
    },
    {
      "epoch": 0.6005555555555555,
      "grad_norm": 0.33682116866111755,
      "learning_rate": 3.4986111111111116e-05,
      "loss": 0.0012,
      "step": 10810
    },
    {
      "epoch": 0.6011111111111112,
      "grad_norm": 0.047733280807733536,
      "learning_rate": 3.497222222222222e-05,
      "loss": 0.0005,
      "step": 10820
    },
    {
      "epoch": 0.6016666666666667,
      "grad_norm": 0.05633874237537384,
      "learning_rate": 3.495833333333334e-05,
      "loss": 0.0005,
      "step": 10830
    },
    {
      "epoch": 0.6022222222222222,
      "grad_norm": 0.048890117555856705,
      "learning_rate": 3.4944444444444446e-05,
      "loss": 0.001,
      "step": 10840
    },
    {
      "epoch": 0.6027777777777777,
      "grad_norm": 0.1481267213821411,
      "learning_rate": 3.493055555555556e-05,
      "loss": 0.0012,
      "step": 10850
    },
    {
      "epoch": 0.6033333333333334,
      "grad_norm": 0.09199612587690353,
      "learning_rate": 3.491666666666667e-05,
      "loss": 0.0011,
      "step": 10860
    },
    {
      "epoch": 0.6038888888888889,
      "grad_norm": 0.0,
      "learning_rate": 3.4902777777777776e-05,
      "loss": 0.0027,
      "step": 10870
    },
    {
      "epoch": 0.6044444444444445,
      "grad_norm": 0.0,
      "learning_rate": 3.4888888888888895e-05,
      "loss": 0.0013,
      "step": 10880
    },
    {
      "epoch": 0.605,
      "grad_norm": 0.04924876615405083,
      "learning_rate": 3.4875e-05,
      "loss": 0.001,
      "step": 10890
    },
    {
      "epoch": 0.6055555555555555,
      "grad_norm": 0.16746146976947784,
      "learning_rate": 3.486111111111111e-05,
      "loss": 0.001,
      "step": 10900
    },
    {
      "epoch": 0.6061111111111112,
      "grad_norm": 0.0,
      "learning_rate": 3.4847222222222225e-05,
      "loss": 0.0005,
      "step": 10910
    },
    {
      "epoch": 0.6066666666666667,
      "grad_norm": 0.04870351403951645,
      "learning_rate": 3.483333333333334e-05,
      "loss": 0.0004,
      "step": 10920
    },
    {
      "epoch": 0.6072222222222222,
      "grad_norm": 0.0,
      "learning_rate": 3.481944444444444e-05,
      "loss": 0.0007,
      "step": 10930
    },
    {
      "epoch": 0.6077777777777778,
      "grad_norm": 0.018444957211613655,
      "learning_rate": 3.4805555555555555e-05,
      "loss": 0.0005,
      "step": 10940
    },
    {
      "epoch": 0.6083333333333333,
      "grad_norm": 0.17161768674850464,
      "learning_rate": 3.479166666666667e-05,
      "loss": 0.0007,
      "step": 10950
    },
    {
      "epoch": 0.6088888888888889,
      "grad_norm": 0.04491348937153816,
      "learning_rate": 3.477777777777778e-05,
      "loss": 0.001,
      "step": 10960
    },
    {
      "epoch": 0.6094444444444445,
      "grad_norm": 0.1231955736875534,
      "learning_rate": 3.476388888888889e-05,
      "loss": 0.001,
      "step": 10970
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.04626491665840149,
      "learning_rate": 3.475e-05,
      "loss": 0.0006,
      "step": 10980
    },
    {
      "epoch": 0.6105555555555555,
      "grad_norm": 0.0,
      "learning_rate": 3.473611111111112e-05,
      "loss": 0.0016,
      "step": 10990
    },
    {
      "epoch": 0.6111111111111112,
      "grad_norm": 0.42421701550483704,
      "learning_rate": 3.472222222222222e-05,
      "loss": 0.0012,
      "step": 11000
    },
    {
      "epoch": 0.6116666666666667,
      "grad_norm": 0.0,
      "learning_rate": 3.4708333333333334e-05,
      "loss": 0.0011,
      "step": 11010
    },
    {
      "epoch": 0.6122222222222222,
      "grad_norm": 0.5688384175300598,
      "learning_rate": 3.469444444444445e-05,
      "loss": 0.0014,
      "step": 11020
    },
    {
      "epoch": 0.6127777777777778,
      "grad_norm": 0.1572159230709076,
      "learning_rate": 3.468055555555555e-05,
      "loss": 0.0018,
      "step": 11030
    },
    {
      "epoch": 0.6133333333333333,
      "grad_norm": 0.09832898527383804,
      "learning_rate": 3.466666666666667e-05,
      "loss": 0.0006,
      "step": 11040
    },
    {
      "epoch": 0.6138888888888889,
      "grad_norm": 0.12865622341632843,
      "learning_rate": 3.465277777777778e-05,
      "loss": 0.0015,
      "step": 11050
    },
    {
      "epoch": 0.6144444444444445,
      "grad_norm": 0.13541682064533234,
      "learning_rate": 3.4638888888888896e-05,
      "loss": 0.0009,
      "step": 11060
    },
    {
      "epoch": 0.615,
      "grad_norm": 0.21833862364292145,
      "learning_rate": 3.4625e-05,
      "loss": 0.001,
      "step": 11070
    },
    {
      "epoch": 0.6155555555555555,
      "grad_norm": 0.0,
      "learning_rate": 3.4611111111111114e-05,
      "loss": 0.001,
      "step": 11080
    },
    {
      "epoch": 0.6161111111111112,
      "grad_norm": 0.0,
      "learning_rate": 3.4597222222222226e-05,
      "loss": 0.001,
      "step": 11090
    },
    {
      "epoch": 0.6166666666666667,
      "grad_norm": 0.0,
      "learning_rate": 3.458333333333333e-05,
      "loss": 0.0003,
      "step": 11100
    },
    {
      "epoch": 0.6172222222222222,
      "grad_norm": 0.0,
      "learning_rate": 3.456944444444445e-05,
      "loss": 0.0009,
      "step": 11110
    },
    {
      "epoch": 0.6177777777777778,
      "grad_norm": 0.0,
      "learning_rate": 3.4555555555555556e-05,
      "loss": 0.0015,
      "step": 11120
    },
    {
      "epoch": 0.6183333333333333,
      "grad_norm": 0.2590855062007904,
      "learning_rate": 3.454166666666667e-05,
      "loss": 0.001,
      "step": 11130
    },
    {
      "epoch": 0.6188888888888889,
      "grad_norm": 0.05114632099866867,
      "learning_rate": 3.452777777777778e-05,
      "loss": 0.0003,
      "step": 11140
    },
    {
      "epoch": 0.6194444444444445,
      "grad_norm": 0.0950869619846344,
      "learning_rate": 3.451388888888889e-05,
      "loss": 0.001,
      "step": 11150
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.1524384468793869,
      "learning_rate": 3.45e-05,
      "loss": 0.0009,
      "step": 11160
    },
    {
      "epoch": 0.6205555555555555,
      "grad_norm": 0.14349588751792908,
      "learning_rate": 3.448611111111111e-05,
      "loss": 0.0013,
      "step": 11170
    },
    {
      "epoch": 0.6211111111111111,
      "grad_norm": 0.03367502987384796,
      "learning_rate": 3.447222222222222e-05,
      "loss": 0.0005,
      "step": 11180
    },
    {
      "epoch": 0.6216666666666667,
      "grad_norm": 0.16926737129688263,
      "learning_rate": 3.4458333333333335e-05,
      "loss": 0.0018,
      "step": 11190
    },
    {
      "epoch": 0.6222222222222222,
      "grad_norm": 0.13373035192489624,
      "learning_rate": 3.444444444444445e-05,
      "loss": 0.0009,
      "step": 11200
    },
    {
      "epoch": 0.6227777777777778,
      "grad_norm": 0.02950167842209339,
      "learning_rate": 3.443055555555555e-05,
      "loss": 0.0011,
      "step": 11210
    },
    {
      "epoch": 0.6233333333333333,
      "grad_norm": 0.0,
      "learning_rate": 3.441666666666667e-05,
      "loss": 0.001,
      "step": 11220
    },
    {
      "epoch": 0.6238888888888889,
      "grad_norm": 0.0,
      "learning_rate": 3.440277777777778e-05,
      "loss": 0.0011,
      "step": 11230
    },
    {
      "epoch": 0.6244444444444445,
      "grad_norm": 0.0,
      "learning_rate": 3.438888888888889e-05,
      "loss": 0.0011,
      "step": 11240
    },
    {
      "epoch": 0.625,
      "grad_norm": 0.13110068440437317,
      "learning_rate": 3.4375e-05,
      "loss": 0.0011,
      "step": 11250
    },
    {
      "epoch": 0.6255555555555555,
      "grad_norm": 0.11858298629522324,
      "learning_rate": 3.436111111111111e-05,
      "loss": 0.0009,
      "step": 11260
    },
    {
      "epoch": 0.6261111111111111,
      "grad_norm": 0.2164721041917801,
      "learning_rate": 3.434722222222223e-05,
      "loss": 0.0013,
      "step": 11270
    },
    {
      "epoch": 0.6266666666666667,
      "grad_norm": 0.13195867836475372,
      "learning_rate": 3.433333333333333e-05,
      "loss": 0.0005,
      "step": 11280
    },
    {
      "epoch": 0.6272222222222222,
      "grad_norm": 0.04417533054947853,
      "learning_rate": 3.431944444444445e-05,
      "loss": 0.0013,
      "step": 11290
    },
    {
      "epoch": 0.6277777777777778,
      "grad_norm": 0.0,
      "learning_rate": 3.430555555555556e-05,
      "loss": 0.0007,
      "step": 11300
    },
    {
      "epoch": 0.6283333333333333,
      "grad_norm": 0.052091822028160095,
      "learning_rate": 3.429166666666667e-05,
      "loss": 0.0014,
      "step": 11310
    },
    {
      "epoch": 0.6288888888888889,
      "grad_norm": 0.12634655833244324,
      "learning_rate": 3.427777777777778e-05,
      "loss": 0.0005,
      "step": 11320
    },
    {
      "epoch": 0.6294444444444445,
      "grad_norm": 0.17735342681407928,
      "learning_rate": 3.426388888888889e-05,
      "loss": 0.0009,
      "step": 11330
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.2573864459991455,
      "learning_rate": 3.4250000000000006e-05,
      "loss": 0.0008,
      "step": 11340
    },
    {
      "epoch": 0.6305555555555555,
      "grad_norm": 0.24648144841194153,
      "learning_rate": 3.423611111111111e-05,
      "loss": 0.0009,
      "step": 11350
    },
    {
      "epoch": 0.6311111111111111,
      "grad_norm": 0.04984157159924507,
      "learning_rate": 3.4222222222222224e-05,
      "loss": 0.0005,
      "step": 11360
    },
    {
      "epoch": 0.6316666666666667,
      "grad_norm": 0.22294703125953674,
      "learning_rate": 3.4208333333333336e-05,
      "loss": 0.0014,
      "step": 11370
    },
    {
      "epoch": 0.6322222222222222,
      "grad_norm": 0.0,
      "learning_rate": 3.419444444444445e-05,
      "loss": 0.0007,
      "step": 11380
    },
    {
      "epoch": 0.6327777777777778,
      "grad_norm": 0.0,
      "learning_rate": 3.4180555555555554e-05,
      "loss": 0.0006,
      "step": 11390
    },
    {
      "epoch": 0.6333333333333333,
      "grad_norm": 0.0,
      "learning_rate": 3.4166666666666666e-05,
      "loss": 0.0009,
      "step": 11400
    },
    {
      "epoch": 0.6338888888888888,
      "grad_norm": 0.21682429313659668,
      "learning_rate": 3.415277777777778e-05,
      "loss": 0.0007,
      "step": 11410
    },
    {
      "epoch": 0.6344444444444445,
      "grad_norm": 0.0,
      "learning_rate": 3.413888888888889e-05,
      "loss": 0.0001,
      "step": 11420
    },
    {
      "epoch": 0.635,
      "grad_norm": 0.2681865096092224,
      "learning_rate": 3.4125e-05,
      "loss": 0.0009,
      "step": 11430
    },
    {
      "epoch": 0.6355555555555555,
      "grad_norm": 0.07879293709993362,
      "learning_rate": 3.411111111111111e-05,
      "loss": 0.0006,
      "step": 11440
    },
    {
      "epoch": 0.6361111111111111,
      "grad_norm": 0.03704730421304703,
      "learning_rate": 3.409722222222223e-05,
      "loss": 0.0008,
      "step": 11450
    },
    {
      "epoch": 0.6366666666666667,
      "grad_norm": 0.0928666964173317,
      "learning_rate": 3.408333333333333e-05,
      "loss": 0.0011,
      "step": 11460
    },
    {
      "epoch": 0.6372222222222222,
      "grad_norm": 0.08968879282474518,
      "learning_rate": 3.4069444444444445e-05,
      "loss": 0.0013,
      "step": 11470
    },
    {
      "epoch": 0.6377777777777778,
      "grad_norm": 0.0917174220085144,
      "learning_rate": 3.405555555555556e-05,
      "loss": 0.0012,
      "step": 11480
    },
    {
      "epoch": 0.6383333333333333,
      "grad_norm": 0.08808103948831558,
      "learning_rate": 3.404166666666666e-05,
      "loss": 0.0027,
      "step": 11490
    },
    {
      "epoch": 0.6388888888888888,
      "grad_norm": 0.10789153724908829,
      "learning_rate": 3.402777777777778e-05,
      "loss": 0.0009,
      "step": 11500
    },
    {
      "epoch": 0.6394444444444445,
      "grad_norm": 0.04795501008629799,
      "learning_rate": 3.401388888888889e-05,
      "loss": 0.0006,
      "step": 11510
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.0986800566315651,
      "learning_rate": 3.4000000000000007e-05,
      "loss": 0.0011,
      "step": 11520
    },
    {
      "epoch": 0.6405555555555555,
      "grad_norm": 0.22175359725952148,
      "learning_rate": 3.398611111111111e-05,
      "loss": 0.0014,
      "step": 11530
    },
    {
      "epoch": 0.6411111111111111,
      "grad_norm": 0.04953182861208916,
      "learning_rate": 3.3972222222222224e-05,
      "loss": 0.001,
      "step": 11540
    },
    {
      "epoch": 0.6416666666666667,
      "grad_norm": 0.17034274339675903,
      "learning_rate": 3.3958333333333337e-05,
      "loss": 0.0012,
      "step": 11550
    },
    {
      "epoch": 0.6422222222222222,
      "grad_norm": 0.05245361849665642,
      "learning_rate": 3.394444444444444e-05,
      "loss": 0.0008,
      "step": 11560
    },
    {
      "epoch": 0.6427777777777778,
      "grad_norm": 0.046127818524837494,
      "learning_rate": 3.393055555555556e-05,
      "loss": 0.0005,
      "step": 11570
    },
    {
      "epoch": 0.6433333333333333,
      "grad_norm": 0.0,
      "learning_rate": 3.391666666666667e-05,
      "loss": 0.0009,
      "step": 11580
    },
    {
      "epoch": 0.6438888888888888,
      "grad_norm": 0.05178030580282211,
      "learning_rate": 3.390277777777778e-05,
      "loss": 0.001,
      "step": 11590
    },
    {
      "epoch": 0.6444444444444445,
      "grad_norm": 0.0,
      "learning_rate": 3.388888888888889e-05,
      "loss": 0.0003,
      "step": 11600
    },
    {
      "epoch": 0.645,
      "grad_norm": 0.03701188415288925,
      "learning_rate": 3.3875000000000003e-05,
      "loss": 0.0009,
      "step": 11610
    },
    {
      "epoch": 0.6455555555555555,
      "grad_norm": 0.04427547752857208,
      "learning_rate": 3.386111111111111e-05,
      "loss": 0.0008,
      "step": 11620
    },
    {
      "epoch": 0.6461111111111111,
      "grad_norm": 0.26582708954811096,
      "learning_rate": 3.384722222222222e-05,
      "loss": 0.0008,
      "step": 11630
    },
    {
      "epoch": 0.6466666666666666,
      "grad_norm": 0.1252138763666153,
      "learning_rate": 3.3833333333333334e-05,
      "loss": 0.0012,
      "step": 11640
    },
    {
      "epoch": 0.6472222222222223,
      "grad_norm": 0.04659897834062576,
      "learning_rate": 3.3819444444444446e-05,
      "loss": 0.0014,
      "step": 11650
    },
    {
      "epoch": 0.6477777777777778,
      "grad_norm": 0.09072690457105637,
      "learning_rate": 3.380555555555556e-05,
      "loss": 0.0005,
      "step": 11660
    },
    {
      "epoch": 0.6483333333333333,
      "grad_norm": 0.0,
      "learning_rate": 3.3791666666666664e-05,
      "loss": 0.0012,
      "step": 11670
    },
    {
      "epoch": 0.6488888888888888,
      "grad_norm": 0.0853661596775055,
      "learning_rate": 3.377777777777778e-05,
      "loss": 0.0004,
      "step": 11680
    },
    {
      "epoch": 0.6494444444444445,
      "grad_norm": 0.304278165102005,
      "learning_rate": 3.376388888888889e-05,
      "loss": 0.0009,
      "step": 11690
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.0,
      "learning_rate": 3.375000000000001e-05,
      "loss": 0.0005,
      "step": 11700
    },
    {
      "epoch": 0.6505555555555556,
      "grad_norm": 0.08590608835220337,
      "learning_rate": 3.373611111111111e-05,
      "loss": 0.0,
      "step": 11710
    },
    {
      "epoch": 0.6511111111111111,
      "grad_norm": 0.0,
      "learning_rate": 3.3722222222222225e-05,
      "loss": 0.0013,
      "step": 11720
    },
    {
      "epoch": 0.6516666666666666,
      "grad_norm": 0.23713313043117523,
      "learning_rate": 3.370833333333334e-05,
      "loss": 0.0007,
      "step": 11730
    },
    {
      "epoch": 0.6522222222222223,
      "grad_norm": 0.28545644879341125,
      "learning_rate": 3.369444444444444e-05,
      "loss": 0.0007,
      "step": 11740
    },
    {
      "epoch": 0.6527777777777778,
      "grad_norm": 0.2112666815519333,
      "learning_rate": 3.368055555555556e-05,
      "loss": 0.001,
      "step": 11750
    },
    {
      "epoch": 0.6533333333333333,
      "grad_norm": 0.043841127306222916,
      "learning_rate": 3.366666666666667e-05,
      "loss": 0.0013,
      "step": 11760
    },
    {
      "epoch": 0.6538888888888889,
      "grad_norm": 0.08571678400039673,
      "learning_rate": 3.365277777777778e-05,
      "loss": 0.0009,
      "step": 11770
    },
    {
      "epoch": 0.6544444444444445,
      "grad_norm": 0.04908573254942894,
      "learning_rate": 3.363888888888889e-05,
      "loss": 0.0006,
      "step": 11780
    },
    {
      "epoch": 0.655,
      "grad_norm": 0.08844533562660217,
      "learning_rate": 3.3625000000000004e-05,
      "loss": 0.0011,
      "step": 11790
    },
    {
      "epoch": 0.6555555555555556,
      "grad_norm": 0.10402873158454895,
      "learning_rate": 3.3611111111111116e-05,
      "loss": 0.0012,
      "step": 11800
    },
    {
      "epoch": 0.6561111111111111,
      "grad_norm": 0.04778344929218292,
      "learning_rate": 3.359722222222222e-05,
      "loss": 0.001,
      "step": 11810
    },
    {
      "epoch": 0.6566666666666666,
      "grad_norm": 0.18493185937404633,
      "learning_rate": 3.3583333333333334e-05,
      "loss": 0.0012,
      "step": 11820
    },
    {
      "epoch": 0.6572222222222223,
      "grad_norm": 0.0442899689078331,
      "learning_rate": 3.3569444444444447e-05,
      "loss": 0.0005,
      "step": 11830
    },
    {
      "epoch": 0.6577777777777778,
      "grad_norm": 0.0,
      "learning_rate": 3.355555555555556e-05,
      "loss": 0.0012,
      "step": 11840
    },
    {
      "epoch": 0.6583333333333333,
      "grad_norm": 0.3345247209072113,
      "learning_rate": 3.3541666666666664e-05,
      "loss": 0.0008,
      "step": 11850
    },
    {
      "epoch": 0.6588888888888889,
      "grad_norm": 0.21172404289245605,
      "learning_rate": 3.352777777777778e-05,
      "loss": 0.0021,
      "step": 11860
    },
    {
      "epoch": 0.6594444444444445,
      "grad_norm": 0.2296251803636551,
      "learning_rate": 3.351388888888889e-05,
      "loss": 0.0009,
      "step": 11870
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.0,
      "learning_rate": 3.35e-05,
      "loss": 0.0004,
      "step": 11880
    },
    {
      "epoch": 0.6605555555555556,
      "grad_norm": 0.14483356475830078,
      "learning_rate": 3.3486111111111113e-05,
      "loss": 0.0005,
      "step": 11890
    },
    {
      "epoch": 0.6611111111111111,
      "grad_norm": 0.13453133404254913,
      "learning_rate": 3.347222222222222e-05,
      "loss": 0.0008,
      "step": 11900
    },
    {
      "epoch": 0.6616666666666666,
      "grad_norm": 0.043379563838243484,
      "learning_rate": 3.345833333333334e-05,
      "loss": 0.0009,
      "step": 11910
    },
    {
      "epoch": 0.6622222222222223,
      "grad_norm": 0.0,
      "learning_rate": 3.3444444444444443e-05,
      "loss": 0.0017,
      "step": 11920
    },
    {
      "epoch": 0.6627777777777778,
      "grad_norm": 0.08209389448165894,
      "learning_rate": 3.343055555555556e-05,
      "loss": 0.001,
      "step": 11930
    },
    {
      "epoch": 0.6633333333333333,
      "grad_norm": 0.0,
      "learning_rate": 3.341666666666667e-05,
      "loss": 0.0007,
      "step": 11940
    },
    {
      "epoch": 0.6638888888888889,
      "grad_norm": 0.08637198060750961,
      "learning_rate": 3.340277777777778e-05,
      "loss": 0.0005,
      "step": 11950
    },
    {
      "epoch": 0.6644444444444444,
      "grad_norm": 0.0,
      "learning_rate": 3.338888888888889e-05,
      "loss": 0.0004,
      "step": 11960
    },
    {
      "epoch": 0.665,
      "grad_norm": 0.08731768280267715,
      "learning_rate": 3.3375e-05,
      "loss": 0.0006,
      "step": 11970
    },
    {
      "epoch": 0.6655555555555556,
      "grad_norm": 0.16826629638671875,
      "learning_rate": 3.336111111111112e-05,
      "loss": 0.001,
      "step": 11980
    },
    {
      "epoch": 0.6661111111111111,
      "grad_norm": 0.17763075232505798,
      "learning_rate": 3.334722222222222e-05,
      "loss": 0.0015,
      "step": 11990
    },
    {
      "epoch": 0.6666666666666666,
      "grad_norm": 0.20000487565994263,
      "learning_rate": 3.3333333333333335e-05,
      "loss": 0.0027,
      "step": 12000
    },
    {
      "epoch": 0.6672222222222223,
      "grad_norm": 0.25523099303245544,
      "learning_rate": 3.331944444444445e-05,
      "loss": 0.001,
      "step": 12010
    },
    {
      "epoch": 0.6677777777777778,
      "grad_norm": 0.05146409943699837,
      "learning_rate": 3.330555555555556e-05,
      "loss": 0.0014,
      "step": 12020
    },
    {
      "epoch": 0.6683333333333333,
      "grad_norm": 0.15618282556533813,
      "learning_rate": 3.329166666666667e-05,
      "loss": 0.0008,
      "step": 12030
    },
    {
      "epoch": 0.6688888888888889,
      "grad_norm": 0.3594706356525421,
      "learning_rate": 3.327777777777778e-05,
      "loss": 0.0011,
      "step": 12040
    },
    {
      "epoch": 0.6694444444444444,
      "grad_norm": 0.1817125529050827,
      "learning_rate": 3.326388888888889e-05,
      "loss": 0.0014,
      "step": 12050
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.047359365969896317,
      "learning_rate": 3.325e-05,
      "loss": 0.0008,
      "step": 12060
    },
    {
      "epoch": 0.6705555555555556,
      "grad_norm": 0.08543530106544495,
      "learning_rate": 3.3236111111111114e-05,
      "loss": 0.0022,
      "step": 12070
    },
    {
      "epoch": 0.6711111111111111,
      "grad_norm": 0.0,
      "learning_rate": 3.322222222222222e-05,
      "loss": 0.0015,
      "step": 12080
    },
    {
      "epoch": 0.6716666666666666,
      "grad_norm": 0.049487002193927765,
      "learning_rate": 3.320833333333334e-05,
      "loss": 0.0019,
      "step": 12090
    },
    {
      "epoch": 0.6722222222222223,
      "grad_norm": 0.0696909949183464,
      "learning_rate": 3.3194444444444444e-05,
      "loss": 0.0015,
      "step": 12100
    },
    {
      "epoch": 0.6727777777777778,
      "grad_norm": 0.04647138714790344,
      "learning_rate": 3.3180555555555556e-05,
      "loss": 0.0009,
      "step": 12110
    },
    {
      "epoch": 0.6733333333333333,
      "grad_norm": 0.0,
      "learning_rate": 3.316666666666667e-05,
      "loss": 0.0007,
      "step": 12120
    },
    {
      "epoch": 0.6738888888888889,
      "grad_norm": 0.051554519683122635,
      "learning_rate": 3.3152777777777774e-05,
      "loss": 0.0006,
      "step": 12130
    },
    {
      "epoch": 0.6744444444444444,
      "grad_norm": 0.08339663594961166,
      "learning_rate": 3.313888888888889e-05,
      "loss": 0.0009,
      "step": 12140
    },
    {
      "epoch": 0.675,
      "grad_norm": 0.023548774421215057,
      "learning_rate": 3.3125e-05,
      "loss": 0.0007,
      "step": 12150
    },
    {
      "epoch": 0.6755555555555556,
      "grad_norm": 0.18106991052627563,
      "learning_rate": 3.311111111111112e-05,
      "loss": 0.0011,
      "step": 12160
    },
    {
      "epoch": 0.6761111111111111,
      "grad_norm": 0.1250084936618805,
      "learning_rate": 3.309722222222222e-05,
      "loss": 0.0008,
      "step": 12170
    },
    {
      "epoch": 0.6766666666666666,
      "grad_norm": 0.05060335993766785,
      "learning_rate": 3.3083333333333336e-05,
      "loss": 0.0002,
      "step": 12180
    },
    {
      "epoch": 0.6772222222222222,
      "grad_norm": 0.0443534329533577,
      "learning_rate": 3.306944444444445e-05,
      "loss": 0.0014,
      "step": 12190
    },
    {
      "epoch": 0.6777777777777778,
      "grad_norm": 0.04473114758729935,
      "learning_rate": 3.3055555555555553e-05,
      "loss": 0.0013,
      "step": 12200
    },
    {
      "epoch": 0.6783333333333333,
      "grad_norm": 0.14447976648807526,
      "learning_rate": 3.304166666666667e-05,
      "loss": 0.0015,
      "step": 12210
    },
    {
      "epoch": 0.6788888888888889,
      "grad_norm": 0.10582664608955383,
      "learning_rate": 3.302777777777778e-05,
      "loss": 0.0008,
      "step": 12220
    },
    {
      "epoch": 0.6794444444444444,
      "grad_norm": 0.11177285760641098,
      "learning_rate": 3.301388888888889e-05,
      "loss": 0.0011,
      "step": 12230
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.17274972796440125,
      "learning_rate": 3.3e-05,
      "loss": 0.0012,
      "step": 12240
    },
    {
      "epoch": 0.6805555555555556,
      "grad_norm": 0.0,
      "learning_rate": 3.2986111111111115e-05,
      "loss": 0.0006,
      "step": 12250
    },
    {
      "epoch": 0.6811111111111111,
      "grad_norm": 0.05013272166252136,
      "learning_rate": 3.297222222222223e-05,
      "loss": 0.0012,
      "step": 12260
    },
    {
      "epoch": 0.6816666666666666,
      "grad_norm": 0.22533950209617615,
      "learning_rate": 3.295833333333333e-05,
      "loss": 0.0009,
      "step": 12270
    },
    {
      "epoch": 0.6822222222222222,
      "grad_norm": 0.10093806684017181,
      "learning_rate": 3.2944444444444445e-05,
      "loss": 0.0003,
      "step": 12280
    },
    {
      "epoch": 0.6827777777777778,
      "grad_norm": 0.05218995735049248,
      "learning_rate": 3.293055555555556e-05,
      "loss": 0.0016,
      "step": 12290
    },
    {
      "epoch": 0.6833333333333333,
      "grad_norm": 0.29323527216911316,
      "learning_rate": 3.291666666666667e-05,
      "loss": 0.001,
      "step": 12300
    },
    {
      "epoch": 0.6838888888888889,
      "grad_norm": 0.4359298050403595,
      "learning_rate": 3.2902777777777775e-05,
      "loss": 0.0013,
      "step": 12310
    },
    {
      "epoch": 0.6844444444444444,
      "grad_norm": 0.2685449719429016,
      "learning_rate": 3.2888888888888894e-05,
      "loss": 0.0018,
      "step": 12320
    },
    {
      "epoch": 0.685,
      "grad_norm": 0.12637992203235626,
      "learning_rate": 3.2875e-05,
      "loss": 0.0014,
      "step": 12330
    },
    {
      "epoch": 0.6855555555555556,
      "grad_norm": 0.06016215309500694,
      "learning_rate": 3.286111111111111e-05,
      "loss": 0.0008,
      "step": 12340
    },
    {
      "epoch": 0.6861111111111111,
      "grad_norm": 0.16398538649082184,
      "learning_rate": 3.2847222222222224e-05,
      "loss": 0.0005,
      "step": 12350
    },
    {
      "epoch": 0.6866666666666666,
      "grad_norm": 0.08703061938285828,
      "learning_rate": 3.283333333333333e-05,
      "loss": 0.0014,
      "step": 12360
    },
    {
      "epoch": 0.6872222222222222,
      "grad_norm": 0.0,
      "learning_rate": 3.281944444444445e-05,
      "loss": 0.0008,
      "step": 12370
    },
    {
      "epoch": 0.6877777777777778,
      "grad_norm": 0.0565209724009037,
      "learning_rate": 3.2805555555555554e-05,
      "loss": 0.0006,
      "step": 12380
    },
    {
      "epoch": 0.6883333333333334,
      "grad_norm": 0.13564656674861908,
      "learning_rate": 3.279166666666667e-05,
      "loss": 0.0009,
      "step": 12390
    },
    {
      "epoch": 0.6888888888888889,
      "grad_norm": 0.37150371074676514,
      "learning_rate": 3.277777777777778e-05,
      "loss": 0.0011,
      "step": 12400
    },
    {
      "epoch": 0.6894444444444444,
      "grad_norm": 0.0,
      "learning_rate": 3.276388888888889e-05,
      "loss": 0.0007,
      "step": 12410
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.06069018319249153,
      "learning_rate": 3.275e-05,
      "loss": 0.0015,
      "step": 12420
    },
    {
      "epoch": 0.6905555555555556,
      "grad_norm": 0.4092181921005249,
      "learning_rate": 3.273611111111111e-05,
      "loss": 0.0019,
      "step": 12430
    },
    {
      "epoch": 0.6911111111111111,
      "grad_norm": 0.31669220328330994,
      "learning_rate": 3.272222222222223e-05,
      "loss": 0.0011,
      "step": 12440
    },
    {
      "epoch": 0.6916666666666667,
      "grad_norm": 0.43222442269325256,
      "learning_rate": 3.270833333333333e-05,
      "loss": 0.0012,
      "step": 12450
    },
    {
      "epoch": 0.6922222222222222,
      "grad_norm": 0.1843969076871872,
      "learning_rate": 3.2694444444444446e-05,
      "loss": 0.0017,
      "step": 12460
    },
    {
      "epoch": 0.6927777777777778,
      "grad_norm": 0.20787328481674194,
      "learning_rate": 3.268055555555556e-05,
      "loss": 0.001,
      "step": 12470
    },
    {
      "epoch": 0.6933333333333334,
      "grad_norm": 0.19411887228488922,
      "learning_rate": 3.266666666666667e-05,
      "loss": 0.0016,
      "step": 12480
    },
    {
      "epoch": 0.6938888888888889,
      "grad_norm": 0.046340711414813995,
      "learning_rate": 3.2652777777777776e-05,
      "loss": 0.0008,
      "step": 12490
    },
    {
      "epoch": 0.6944444444444444,
      "grad_norm": 0.12019956111907959,
      "learning_rate": 3.263888888888889e-05,
      "loss": 0.0013,
      "step": 12500
    },
    {
      "epoch": 0.695,
      "grad_norm": 0.058258965611457825,
      "learning_rate": 3.2625e-05,
      "loss": 0.0007,
      "step": 12510
    },
    {
      "epoch": 0.6955555555555556,
      "grad_norm": 0.12738899886608124,
      "learning_rate": 3.261111111111111e-05,
      "loss": 0.0014,
      "step": 12520
    },
    {
      "epoch": 0.6961111111111111,
      "grad_norm": 0.0357368029654026,
      "learning_rate": 3.2597222222222225e-05,
      "loss": 0.0017,
      "step": 12530
    },
    {
      "epoch": 0.6966666666666667,
      "grad_norm": 0.05224427208304405,
      "learning_rate": 3.258333333333333e-05,
      "loss": 0.0011,
      "step": 12540
    },
    {
      "epoch": 0.6972222222222222,
      "grad_norm": 0.06273354589939117,
      "learning_rate": 3.256944444444445e-05,
      "loss": 0.0014,
      "step": 12550
    },
    {
      "epoch": 0.6977777777777778,
      "grad_norm": 0.029322730377316475,
      "learning_rate": 3.2555555555555555e-05,
      "loss": 0.0013,
      "step": 12560
    },
    {
      "epoch": 0.6983333333333334,
      "grad_norm": 0.08983075618743896,
      "learning_rate": 3.254166666666667e-05,
      "loss": 0.0013,
      "step": 12570
    },
    {
      "epoch": 0.6988888888888889,
      "grad_norm": 0.04572681710124016,
      "learning_rate": 3.252777777777778e-05,
      "loss": 0.0005,
      "step": 12580
    },
    {
      "epoch": 0.6994444444444444,
      "grad_norm": 0.16675467789173126,
      "learning_rate": 3.2513888888888885e-05,
      "loss": 0.0011,
      "step": 12590
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.049534574151039124,
      "learning_rate": 3.2500000000000004e-05,
      "loss": 0.0017,
      "step": 12600
    },
    {
      "epoch": 0.7005555555555556,
      "grad_norm": 0.18477976322174072,
      "learning_rate": 3.248611111111111e-05,
      "loss": 0.0001,
      "step": 12610
    },
    {
      "epoch": 0.7011111111111111,
      "grad_norm": 0.2210797220468521,
      "learning_rate": 3.247222222222223e-05,
      "loss": 0.0009,
      "step": 12620
    },
    {
      "epoch": 0.7016666666666667,
      "grad_norm": 0.02734524756669998,
      "learning_rate": 3.2458333333333334e-05,
      "loss": 0.0001,
      "step": 12630
    },
    {
      "epoch": 0.7022222222222222,
      "grad_norm": 0.0,
      "learning_rate": 3.2444444444444446e-05,
      "loss": 0.0004,
      "step": 12640
    },
    {
      "epoch": 0.7027777777777777,
      "grad_norm": 0.0,
      "learning_rate": 3.243055555555556e-05,
      "loss": 0.0006,
      "step": 12650
    },
    {
      "epoch": 0.7033333333333334,
      "grad_norm": 0.02924352139234543,
      "learning_rate": 3.2416666666666664e-05,
      "loss": 0.0015,
      "step": 12660
    },
    {
      "epoch": 0.7038888888888889,
      "grad_norm": 0.05670417845249176,
      "learning_rate": 3.240277777777778e-05,
      "loss": 0.0003,
      "step": 12670
    },
    {
      "epoch": 0.7044444444444444,
      "grad_norm": 0.0,
      "learning_rate": 3.238888888888889e-05,
      "loss": 0.0007,
      "step": 12680
    },
    {
      "epoch": 0.705,
      "grad_norm": 0.10745994001626968,
      "learning_rate": 3.2375e-05,
      "loss": 0.0006,
      "step": 12690
    },
    {
      "epoch": 0.7055555555555556,
      "grad_norm": 0.17421583831310272,
      "learning_rate": 3.236111111111111e-05,
      "loss": 0.0012,
      "step": 12700
    },
    {
      "epoch": 0.7061111111111111,
      "grad_norm": 0.2335757315158844,
      "learning_rate": 3.2347222222222225e-05,
      "loss": 0.0016,
      "step": 12710
    },
    {
      "epoch": 0.7066666666666667,
      "grad_norm": 0.04599480703473091,
      "learning_rate": 3.233333333333333e-05,
      "loss": 0.0008,
      "step": 12720
    },
    {
      "epoch": 0.7072222222222222,
      "grad_norm": 0.045953527092933655,
      "learning_rate": 3.231944444444445e-05,
      "loss": 0.0004,
      "step": 12730
    },
    {
      "epoch": 0.7077777777777777,
      "grad_norm": 0.1998710036277771,
      "learning_rate": 3.2305555555555556e-05,
      "loss": 0.002,
      "step": 12740
    },
    {
      "epoch": 0.7083333333333334,
      "grad_norm": 0.08499261736869812,
      "learning_rate": 3.229166666666667e-05,
      "loss": 0.0014,
      "step": 12750
    },
    {
      "epoch": 0.7088888888888889,
      "grad_norm": 0.047342512756586075,
      "learning_rate": 3.227777777777778e-05,
      "loss": 0.0002,
      "step": 12760
    },
    {
      "epoch": 0.7094444444444444,
      "grad_norm": 0.0,
      "learning_rate": 3.2263888888888886e-05,
      "loss": 0.001,
      "step": 12770
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.14922109246253967,
      "learning_rate": 3.2250000000000005e-05,
      "loss": 0.0011,
      "step": 12780
    },
    {
      "epoch": 0.7105555555555556,
      "grad_norm": 0.18625648319721222,
      "learning_rate": 3.223611111111111e-05,
      "loss": 0.0007,
      "step": 12790
    },
    {
      "epoch": 0.7111111111111111,
      "grad_norm": 0.14446432888507843,
      "learning_rate": 3.222222222222223e-05,
      "loss": 0.0015,
      "step": 12800
    },
    {
      "epoch": 0.7116666666666667,
      "grad_norm": 0.04431569203734398,
      "learning_rate": 3.2208333333333335e-05,
      "loss": 0.0004,
      "step": 12810
    },
    {
      "epoch": 0.7122222222222222,
      "grad_norm": 0.15328103303909302,
      "learning_rate": 3.219444444444445e-05,
      "loss": 0.0002,
      "step": 12820
    },
    {
      "epoch": 0.7127777777777777,
      "grad_norm": 0.0,
      "learning_rate": 3.218055555555556e-05,
      "loss": 0.0001,
      "step": 12830
    },
    {
      "epoch": 0.7133333333333334,
      "grad_norm": 0.0,
      "learning_rate": 3.2166666666666665e-05,
      "loss": 0.0007,
      "step": 12840
    },
    {
      "epoch": 0.7138888888888889,
      "grad_norm": 0.049232278019189835,
      "learning_rate": 3.2152777777777784e-05,
      "loss": 0.0009,
      "step": 12850
    },
    {
      "epoch": 0.7144444444444444,
      "grad_norm": 0.06978248804807663,
      "learning_rate": 3.213888888888889e-05,
      "loss": 0.0009,
      "step": 12860
    },
    {
      "epoch": 0.715,
      "grad_norm": 0.04451856389641762,
      "learning_rate": 3.2125e-05,
      "loss": 0.0014,
      "step": 12870
    },
    {
      "epoch": 0.7155555555555555,
      "grad_norm": 0.0,
      "learning_rate": 3.2111111111111114e-05,
      "loss": 0.0004,
      "step": 12880
    },
    {
      "epoch": 0.7161111111111111,
      "grad_norm": 0.10186295956373215,
      "learning_rate": 3.2097222222222226e-05,
      "loss": 0.0001,
      "step": 12890
    },
    {
      "epoch": 0.7166666666666667,
      "grad_norm": 0.044082317501306534,
      "learning_rate": 3.208333333333334e-05,
      "loss": 0.0005,
      "step": 12900
    },
    {
      "epoch": 0.7172222222222222,
      "grad_norm": 0.0500795841217041,
      "learning_rate": 3.2069444444444444e-05,
      "loss": 0.0004,
      "step": 12910
    },
    {
      "epoch": 0.7177777777777777,
      "grad_norm": 0.33634069561958313,
      "learning_rate": 3.2055555555555556e-05,
      "loss": 0.0015,
      "step": 12920
    },
    {
      "epoch": 0.7183333333333334,
      "grad_norm": 0.0,
      "learning_rate": 3.204166666666667e-05,
      "loss": 0.0006,
      "step": 12930
    },
    {
      "epoch": 0.7188888888888889,
      "grad_norm": 0.0,
      "learning_rate": 3.202777777777778e-05,
      "loss": 0.0006,
      "step": 12940
    },
    {
      "epoch": 0.7194444444444444,
      "grad_norm": 0.06821588426828384,
      "learning_rate": 3.2013888888888886e-05,
      "loss": 0.0009,
      "step": 12950
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.1726331263780594,
      "learning_rate": 3.2000000000000005e-05,
      "loss": 0.0013,
      "step": 12960
    },
    {
      "epoch": 0.7205555555555555,
      "grad_norm": 0.0,
      "learning_rate": 3.198611111111111e-05,
      "loss": 0.0006,
      "step": 12970
    },
    {
      "epoch": 0.7211111111111111,
      "grad_norm": 0.05146246403455734,
      "learning_rate": 3.197222222222222e-05,
      "loss": 0.0001,
      "step": 12980
    },
    {
      "epoch": 0.7216666666666667,
      "grad_norm": 0.044170934706926346,
      "learning_rate": 3.1958333333333335e-05,
      "loss": 0.0015,
      "step": 12990
    },
    {
      "epoch": 0.7222222222222222,
      "grad_norm": 0.14312078058719635,
      "learning_rate": 3.194444444444444e-05,
      "loss": 0.0013,
      "step": 13000
    },
    {
      "epoch": 0.7227777777777777,
      "grad_norm": 0.04894401505589485,
      "learning_rate": 3.193055555555556e-05,
      "loss": 0.0023,
      "step": 13010
    },
    {
      "epoch": 0.7233333333333334,
      "grad_norm": 0.05254717171192169,
      "learning_rate": 3.1916666666666665e-05,
      "loss": 0.0006,
      "step": 13020
    },
    {
      "epoch": 0.7238888888888889,
      "grad_norm": 0.0,
      "learning_rate": 3.1902777777777785e-05,
      "loss": 0.0018,
      "step": 13030
    },
    {
      "epoch": 0.7244444444444444,
      "grad_norm": 0.0,
      "learning_rate": 3.188888888888889e-05,
      "loss": 0.0005,
      "step": 13040
    },
    {
      "epoch": 0.725,
      "grad_norm": 0.044303860515356064,
      "learning_rate": 3.1875e-05,
      "loss": 0.002,
      "step": 13050
    },
    {
      "epoch": 0.7255555555555555,
      "grad_norm": 0.29227378964424133,
      "learning_rate": 3.1861111111111115e-05,
      "loss": 0.0008,
      "step": 13060
    },
    {
      "epoch": 0.7261111111111112,
      "grad_norm": 0.17960518598556519,
      "learning_rate": 3.184722222222222e-05,
      "loss": 0.0016,
      "step": 13070
    },
    {
      "epoch": 0.7266666666666667,
      "grad_norm": 0.0844879224896431,
      "learning_rate": 3.183333333333334e-05,
      "loss": 0.0013,
      "step": 13080
    },
    {
      "epoch": 0.7272222222222222,
      "grad_norm": 0.09364473074674606,
      "learning_rate": 3.1819444444444445e-05,
      "loss": 0.0009,
      "step": 13090
    },
    {
      "epoch": 0.7277777777777777,
      "grad_norm": 0.0,
      "learning_rate": 3.180555555555556e-05,
      "loss": 0.0011,
      "step": 13100
    },
    {
      "epoch": 0.7283333333333334,
      "grad_norm": 0.0,
      "learning_rate": 3.179166666666667e-05,
      "loss": 0.0006,
      "step": 13110
    },
    {
      "epoch": 0.7288888888888889,
      "grad_norm": 0.05541745945811272,
      "learning_rate": 3.177777777777778e-05,
      "loss": 0.001,
      "step": 13120
    },
    {
      "epoch": 0.7294444444444445,
      "grad_norm": 0.12700510025024414,
      "learning_rate": 3.1763888888888894e-05,
      "loss": 0.001,
      "step": 13130
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.2033820003271103,
      "learning_rate": 3.175e-05,
      "loss": 0.0006,
      "step": 13140
    },
    {
      "epoch": 0.7305555555555555,
      "grad_norm": 0.0,
      "learning_rate": 3.173611111111111e-05,
      "loss": 0.0015,
      "step": 13150
    },
    {
      "epoch": 0.7311111111111112,
      "grad_norm": 0.23818980157375336,
      "learning_rate": 3.1722222222222224e-05,
      "loss": 0.0005,
      "step": 13160
    },
    {
      "epoch": 0.7316666666666667,
      "grad_norm": 0.02592042274773121,
      "learning_rate": 3.1708333333333336e-05,
      "loss": 0.0019,
      "step": 13170
    },
    {
      "epoch": 0.7322222222222222,
      "grad_norm": 0.07589314132928848,
      "learning_rate": 3.169444444444444e-05,
      "loss": 0.0002,
      "step": 13180
    },
    {
      "epoch": 0.7327777777777778,
      "grad_norm": 0.05777712166309357,
      "learning_rate": 3.168055555555556e-05,
      "loss": 0.002,
      "step": 13190
    },
    {
      "epoch": 0.7333333333333333,
      "grad_norm": 0.0,
      "learning_rate": 3.1666666666666666e-05,
      "loss": 0.0006,
      "step": 13200
    },
    {
      "epoch": 0.7338888888888889,
      "grad_norm": 0.0,
      "learning_rate": 3.165277777777778e-05,
      "loss": 0.0003,
      "step": 13210
    },
    {
      "epoch": 0.7344444444444445,
      "grad_norm": 0.16646473109722137,
      "learning_rate": 3.163888888888889e-05,
      "loss": 0.0006,
      "step": 13220
    },
    {
      "epoch": 0.735,
      "grad_norm": 0.14571376144886017,
      "learning_rate": 3.1624999999999996e-05,
      "loss": 0.001,
      "step": 13230
    },
    {
      "epoch": 0.7355555555555555,
      "grad_norm": 0.0,
      "learning_rate": 3.1611111111111115e-05,
      "loss": 0.0003,
      "step": 13240
    },
    {
      "epoch": 0.7361111111111112,
      "grad_norm": 0.06421026587486267,
      "learning_rate": 3.159722222222222e-05,
      "loss": 0.0016,
      "step": 13250
    },
    {
      "epoch": 0.7366666666666667,
      "grad_norm": 0.14898401498794556,
      "learning_rate": 3.158333333333334e-05,
      "loss": 0.0015,
      "step": 13260
    },
    {
      "epoch": 0.7372222222222222,
      "grad_norm": 0.04098259657621384,
      "learning_rate": 3.1569444444444445e-05,
      "loss": 0.0008,
      "step": 13270
    },
    {
      "epoch": 0.7377777777777778,
      "grad_norm": 0.11347121745347977,
      "learning_rate": 3.155555555555556e-05,
      "loss": 0.0018,
      "step": 13280
    },
    {
      "epoch": 0.7383333333333333,
      "grad_norm": 0.04652846232056618,
      "learning_rate": 3.154166666666667e-05,
      "loss": 0.0009,
      "step": 13290
    },
    {
      "epoch": 0.7388888888888889,
      "grad_norm": 0.0,
      "learning_rate": 3.1527777777777775e-05,
      "loss": 0.0026,
      "step": 13300
    },
    {
      "epoch": 0.7394444444444445,
      "grad_norm": 0.05200495570898056,
      "learning_rate": 3.1513888888888894e-05,
      "loss": 0.0003,
      "step": 13310
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.0,
      "learning_rate": 3.15e-05,
      "loss": 0.0003,
      "step": 13320
    },
    {
      "epoch": 0.7405555555555555,
      "grad_norm": 0.043726108968257904,
      "learning_rate": 3.148611111111111e-05,
      "loss": 0.002,
      "step": 13330
    },
    {
      "epoch": 0.7411111111111112,
      "grad_norm": 0.04328436776995659,
      "learning_rate": 3.1472222222222225e-05,
      "loss": 0.0008,
      "step": 13340
    },
    {
      "epoch": 0.7416666666666667,
      "grad_norm": 0.05176199972629547,
      "learning_rate": 3.145833333333334e-05,
      "loss": 0.0004,
      "step": 13350
    },
    {
      "epoch": 0.7422222222222222,
      "grad_norm": 0.1409841924905777,
      "learning_rate": 3.144444444444445e-05,
      "loss": 0.001,
      "step": 13360
    },
    {
      "epoch": 0.7427777777777778,
      "grad_norm": 0.1382737010717392,
      "learning_rate": 3.1430555555555555e-05,
      "loss": 0.0011,
      "step": 13370
    },
    {
      "epoch": 0.7433333333333333,
      "grad_norm": 0.34370356798171997,
      "learning_rate": 3.141666666666667e-05,
      "loss": 0.0004,
      "step": 13380
    },
    {
      "epoch": 0.7438888888888889,
      "grad_norm": 0.09128842502832413,
      "learning_rate": 3.140277777777778e-05,
      "loss": 0.0008,
      "step": 13390
    },
    {
      "epoch": 0.7444444444444445,
      "grad_norm": 0.09155724197626114,
      "learning_rate": 3.138888888888889e-05,
      "loss": 0.0014,
      "step": 13400
    },
    {
      "epoch": 0.745,
      "grad_norm": 0.26580023765563965,
      "learning_rate": 3.1375e-05,
      "loss": 0.001,
      "step": 13410
    },
    {
      "epoch": 0.7455555555555555,
      "grad_norm": 0.05942125618457794,
      "learning_rate": 3.1361111111111116e-05,
      "loss": 0.0015,
      "step": 13420
    },
    {
      "epoch": 0.7461111111111111,
      "grad_norm": 0.04345123469829559,
      "learning_rate": 3.134722222222222e-05,
      "loss": 0.0009,
      "step": 13430
    },
    {
      "epoch": 0.7466666666666667,
      "grad_norm": 0.0458490327000618,
      "learning_rate": 3.1333333333333334e-05,
      "loss": 0.0005,
      "step": 13440
    },
    {
      "epoch": 0.7472222222222222,
      "grad_norm": 0.171034574508667,
      "learning_rate": 3.1319444444444446e-05,
      "loss": 0.0006,
      "step": 13450
    },
    {
      "epoch": 0.7477777777777778,
      "grad_norm": 0.1381099373102188,
      "learning_rate": 3.130555555555555e-05,
      "loss": 0.0008,
      "step": 13460
    },
    {
      "epoch": 0.7483333333333333,
      "grad_norm": 0.0679120346903801,
      "learning_rate": 3.129166666666667e-05,
      "loss": 0.0006,
      "step": 13470
    },
    {
      "epoch": 0.7488888888888889,
      "grad_norm": 0.04549095034599304,
      "learning_rate": 3.1277777777777776e-05,
      "loss": 0.0005,
      "step": 13480
    },
    {
      "epoch": 0.7494444444444445,
      "grad_norm": 0.04311743378639221,
      "learning_rate": 3.1263888888888895e-05,
      "loss": 0.0009,
      "step": 13490
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.04437603801488876,
      "learning_rate": 3.125e-05,
      "loss": 0.0007,
      "step": 13500
    },
    {
      "epoch": 0.7505555555555555,
      "grad_norm": 0.0,
      "learning_rate": 3.123611111111111e-05,
      "loss": 0.0009,
      "step": 13510
    },
    {
      "epoch": 0.7511111111111111,
      "grad_norm": 0.19858697056770325,
      "learning_rate": 3.1222222222222225e-05,
      "loss": 0.0006,
      "step": 13520
    },
    {
      "epoch": 0.7516666666666667,
      "grad_norm": 0.18826651573181152,
      "learning_rate": 3.120833333333333e-05,
      "loss": 0.0013,
      "step": 13530
    },
    {
      "epoch": 0.7522222222222222,
      "grad_norm": 0.0,
      "learning_rate": 3.119444444444445e-05,
      "loss": 0.0003,
      "step": 13540
    },
    {
      "epoch": 0.7527777777777778,
      "grad_norm": 0.0,
      "learning_rate": 3.1180555555555555e-05,
      "loss": 0.0006,
      "step": 13550
    },
    {
      "epoch": 0.7533333333333333,
      "grad_norm": 0.1537972092628479,
      "learning_rate": 3.116666666666667e-05,
      "loss": 0.001,
      "step": 13560
    },
    {
      "epoch": 0.7538888888888889,
      "grad_norm": 0.29940569400787354,
      "learning_rate": 3.115277777777778e-05,
      "loss": 0.0002,
      "step": 13570
    },
    {
      "epoch": 0.7544444444444445,
      "grad_norm": 0.0517144612967968,
      "learning_rate": 3.113888888888889e-05,
      "loss": 0.0008,
      "step": 13580
    },
    {
      "epoch": 0.755,
      "grad_norm": 0.21639181673526764,
      "learning_rate": 3.1125000000000004e-05,
      "loss": 0.001,
      "step": 13590
    },
    {
      "epoch": 0.7555555555555555,
      "grad_norm": 0.13782843947410583,
      "learning_rate": 3.111111111111111e-05,
      "loss": 0.001,
      "step": 13600
    },
    {
      "epoch": 0.7561111111111111,
      "grad_norm": 0.13027921319007874,
      "learning_rate": 3.109722222222222e-05,
      "loss": 0.0014,
      "step": 13610
    },
    {
      "epoch": 0.7566666666666667,
      "grad_norm": 0.0,
      "learning_rate": 3.1083333333333334e-05,
      "loss": 0.001,
      "step": 13620
    },
    {
      "epoch": 0.7572222222222222,
      "grad_norm": 0.08986224979162216,
      "learning_rate": 3.106944444444445e-05,
      "loss": 0.0006,
      "step": 13630
    },
    {
      "epoch": 0.7577777777777778,
      "grad_norm": 0.17486190795898438,
      "learning_rate": 3.105555555555555e-05,
      "loss": 0.0015,
      "step": 13640
    },
    {
      "epoch": 0.7583333333333333,
      "grad_norm": 0.18351513147354126,
      "learning_rate": 3.104166666666667e-05,
      "loss": 0.0009,
      "step": 13650
    },
    {
      "epoch": 0.7588888888888888,
      "grad_norm": 0.02667071484029293,
      "learning_rate": 3.102777777777778e-05,
      "loss": 0.0008,
      "step": 13660
    },
    {
      "epoch": 0.7594444444444445,
      "grad_norm": 0.0,
      "learning_rate": 3.101388888888889e-05,
      "loss": 0.0003,
      "step": 13670
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.02552717737853527,
      "learning_rate": 3.1e-05,
      "loss": 0.0005,
      "step": 13680
    },
    {
      "epoch": 0.7605555555555555,
      "grad_norm": 0.2779495120048523,
      "learning_rate": 3.098611111111111e-05,
      "loss": 0.0012,
      "step": 13690
    },
    {
      "epoch": 0.7611111111111111,
      "grad_norm": 0.24751152098178864,
      "learning_rate": 3.0972222222222226e-05,
      "loss": 0.0013,
      "step": 13700
    },
    {
      "epoch": 0.7616666666666667,
      "grad_norm": 0.13201545178890228,
      "learning_rate": 3.095833333333333e-05,
      "loss": 0.0008,
      "step": 13710
    },
    {
      "epoch": 0.7622222222222222,
      "grad_norm": 0.0,
      "learning_rate": 3.094444444444445e-05,
      "loss": 0.0007,
      "step": 13720
    },
    {
      "epoch": 0.7627777777777778,
      "grad_norm": 0.1480524241924286,
      "learning_rate": 3.0930555555555556e-05,
      "loss": 0.0006,
      "step": 13730
    },
    {
      "epoch": 0.7633333333333333,
      "grad_norm": 0.0,
      "learning_rate": 3.091666666666667e-05,
      "loss": 0.0009,
      "step": 13740
    },
    {
      "epoch": 0.7638888888888888,
      "grad_norm": 0.0,
      "learning_rate": 3.090277777777778e-05,
      "loss": 0.0004,
      "step": 13750
    },
    {
      "epoch": 0.7644444444444445,
      "grad_norm": 0.04671350494027138,
      "learning_rate": 3.088888888888889e-05,
      "loss": 0.0016,
      "step": 13760
    },
    {
      "epoch": 0.765,
      "grad_norm": 0.10142292827367783,
      "learning_rate": 3.0875000000000005e-05,
      "loss": 0.0017,
      "step": 13770
    },
    {
      "epoch": 0.7655555555555555,
      "grad_norm": 0.08901724219322205,
      "learning_rate": 3.086111111111111e-05,
      "loss": 0.0012,
      "step": 13780
    },
    {
      "epoch": 0.7661111111111111,
      "grad_norm": 0.05074966698884964,
      "learning_rate": 3.084722222222222e-05,
      "loss": 0.001,
      "step": 13790
    },
    {
      "epoch": 0.7666666666666667,
      "grad_norm": 0.04760654643177986,
      "learning_rate": 3.0833333333333335e-05,
      "loss": 0.0007,
      "step": 13800
    },
    {
      "epoch": 0.7672222222222222,
      "grad_norm": 0.0,
      "learning_rate": 3.081944444444445e-05,
      "loss": 0.0005,
      "step": 13810
    },
    {
      "epoch": 0.7677777777777778,
      "grad_norm": 0.33394351601600647,
      "learning_rate": 3.080555555555556e-05,
      "loss": 0.0001,
      "step": 13820
    },
    {
      "epoch": 0.7683333333333333,
      "grad_norm": 0.04860127344727516,
      "learning_rate": 3.079166666666667e-05,
      "loss": 0.001,
      "step": 13830
    },
    {
      "epoch": 0.7688888888888888,
      "grad_norm": 0.04561515524983406,
      "learning_rate": 3.077777777777778e-05,
      "loss": 0.0014,
      "step": 13840
    },
    {
      "epoch": 0.7694444444444445,
      "grad_norm": 0.0,
      "learning_rate": 3.076388888888889e-05,
      "loss": 0.0008,
      "step": 13850
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.0,
      "learning_rate": 3.075e-05,
      "loss": 0.0002,
      "step": 13860
    },
    {
      "epoch": 0.7705555555555555,
      "grad_norm": 0.17912189662456512,
      "learning_rate": 3.073611111111111e-05,
      "loss": 0.0024,
      "step": 13870
    },
    {
      "epoch": 0.7711111111111111,
      "grad_norm": 0.14714518189430237,
      "learning_rate": 3.0722222222222227e-05,
      "loss": 0.0006,
      "step": 13880
    },
    {
      "epoch": 0.7716666666666666,
      "grad_norm": 0.16950054466724396,
      "learning_rate": 3.070833333333333e-05,
      "loss": 0.0008,
      "step": 13890
    },
    {
      "epoch": 0.7722222222222223,
      "grad_norm": 0.23852777481079102,
      "learning_rate": 3.069444444444445e-05,
      "loss": 0.0007,
      "step": 13900
    },
    {
      "epoch": 0.7727777777777778,
      "grad_norm": 0.09015721082687378,
      "learning_rate": 3.068055555555556e-05,
      "loss": 0.0014,
      "step": 13910
    },
    {
      "epoch": 0.7733333333333333,
      "grad_norm": 0.0,
      "learning_rate": 3.066666666666667e-05,
      "loss": 0.0008,
      "step": 13920
    },
    {
      "epoch": 0.7738888888888888,
      "grad_norm": 0.21976090967655182,
      "learning_rate": 3.065277777777778e-05,
      "loss": 0.0014,
      "step": 13930
    },
    {
      "epoch": 0.7744444444444445,
      "grad_norm": 0.139760360121727,
      "learning_rate": 3.063888888888889e-05,
      "loss": 0.0009,
      "step": 13940
    },
    {
      "epoch": 0.775,
      "grad_norm": 0.05915297567844391,
      "learning_rate": 3.0625000000000006e-05,
      "loss": 0.0014,
      "step": 13950
    },
    {
      "epoch": 0.7755555555555556,
      "grad_norm": 0.27381113171577454,
      "learning_rate": 3.061111111111111e-05,
      "loss": 0.0007,
      "step": 13960
    },
    {
      "epoch": 0.7761111111111111,
      "grad_norm": 0.046372219920158386,
      "learning_rate": 3.0597222222222224e-05,
      "loss": 0.0011,
      "step": 13970
    },
    {
      "epoch": 0.7766666666666666,
      "grad_norm": 0.0,
      "learning_rate": 3.0583333333333336e-05,
      "loss": 0.0015,
      "step": 13980
    },
    {
      "epoch": 0.7772222222222223,
      "grad_norm": 0.1732669472694397,
      "learning_rate": 3.056944444444445e-05,
      "loss": 0.0002,
      "step": 13990
    },
    {
      "epoch": 0.7777777777777778,
      "grad_norm": 0.29405564069747925,
      "learning_rate": 3.055555555555556e-05,
      "loss": 0.0017,
      "step": 14000
    },
    {
      "epoch": 0.7783333333333333,
      "grad_norm": 0.0,
      "learning_rate": 3.0541666666666666e-05,
      "loss": 0.0011,
      "step": 14010
    },
    {
      "epoch": 0.7788888888888889,
      "grad_norm": 0.04361811280250549,
      "learning_rate": 3.052777777777778e-05,
      "loss": 0.0016,
      "step": 14020
    },
    {
      "epoch": 0.7794444444444445,
      "grad_norm": 0.1710348129272461,
      "learning_rate": 3.051388888888889e-05,
      "loss": 0.0012,
      "step": 14030
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.0,
      "learning_rate": 3.05e-05,
      "loss": 0.0008,
      "step": 14040
    },
    {
      "epoch": 0.7805555555555556,
      "grad_norm": 0.08590849488973618,
      "learning_rate": 3.0486111111111115e-05,
      "loss": 0.0005,
      "step": 14050
    },
    {
      "epoch": 0.7811111111111111,
      "grad_norm": 0.1664387583732605,
      "learning_rate": 3.0472222222222224e-05,
      "loss": 0.0006,
      "step": 14060
    },
    {
      "epoch": 0.7816666666666666,
      "grad_norm": 0.04617474600672722,
      "learning_rate": 3.0458333333333333e-05,
      "loss": 0.001,
      "step": 14070
    },
    {
      "epoch": 0.7822222222222223,
      "grad_norm": 0.04240000247955322,
      "learning_rate": 3.044444444444445e-05,
      "loss": 0.0002,
      "step": 14080
    },
    {
      "epoch": 0.7827777777777778,
      "grad_norm": 0.04571165144443512,
      "learning_rate": 3.0430555555555557e-05,
      "loss": 0.0009,
      "step": 14090
    },
    {
      "epoch": 0.7833333333333333,
      "grad_norm": 0.08310303837060928,
      "learning_rate": 3.0416666666666666e-05,
      "loss": 0.0008,
      "step": 14100
    },
    {
      "epoch": 0.7838888888888889,
      "grad_norm": 0.0,
      "learning_rate": 3.040277777777778e-05,
      "loss": 0.0011,
      "step": 14110
    },
    {
      "epoch": 0.7844444444444445,
      "grad_norm": 0.0,
      "learning_rate": 3.0388888888888887e-05,
      "loss": 0.0006,
      "step": 14120
    },
    {
      "epoch": 0.785,
      "grad_norm": 0.045159850269556046,
      "learning_rate": 3.0375000000000003e-05,
      "loss": 0.0005,
      "step": 14130
    },
    {
      "epoch": 0.7855555555555556,
      "grad_norm": 0.023984676226973534,
      "learning_rate": 3.0361111111111112e-05,
      "loss": 0.0007,
      "step": 14140
    },
    {
      "epoch": 0.7861111111111111,
      "grad_norm": 0.19015054404735565,
      "learning_rate": 3.034722222222222e-05,
      "loss": 0.0019,
      "step": 14150
    },
    {
      "epoch": 0.7866666666666666,
      "grad_norm": 0.20140360295772552,
      "learning_rate": 3.0333333333333337e-05,
      "loss": 0.0002,
      "step": 14160
    },
    {
      "epoch": 0.7872222222222223,
      "grad_norm": 0.0,
      "learning_rate": 3.0319444444444445e-05,
      "loss": 0.0013,
      "step": 14170
    },
    {
      "epoch": 0.7877777777777778,
      "grad_norm": 0.031078238040208817,
      "learning_rate": 3.0305555555555558e-05,
      "loss": 0.0009,
      "step": 14180
    },
    {
      "epoch": 0.7883333333333333,
      "grad_norm": 0.05068008601665497,
      "learning_rate": 3.0291666666666667e-05,
      "loss": 0.0017,
      "step": 14190
    },
    {
      "epoch": 0.7888888888888889,
      "grad_norm": 0.1765071451663971,
      "learning_rate": 3.0277777777777776e-05,
      "loss": 0.0005,
      "step": 14200
    },
    {
      "epoch": 0.7894444444444444,
      "grad_norm": 0.04718148708343506,
      "learning_rate": 3.026388888888889e-05,
      "loss": 0.0006,
      "step": 14210
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.04717891663312912,
      "learning_rate": 3.025e-05,
      "loss": 0.0008,
      "step": 14220
    },
    {
      "epoch": 0.7905555555555556,
      "grad_norm": 0.3001348376274109,
      "learning_rate": 3.0236111111111116e-05,
      "loss": 0.0008,
      "step": 14230
    },
    {
      "epoch": 0.7911111111111111,
      "grad_norm": 0.042785678058862686,
      "learning_rate": 3.0222222222222225e-05,
      "loss": 0.0003,
      "step": 14240
    },
    {
      "epoch": 0.7916666666666666,
      "grad_norm": 0.0,
      "learning_rate": 3.0208333333333334e-05,
      "loss": 0.001,
      "step": 14250
    },
    {
      "epoch": 0.7922222222222223,
      "grad_norm": 0.03649517148733139,
      "learning_rate": 3.0194444444444446e-05,
      "loss": 0.0005,
      "step": 14260
    },
    {
      "epoch": 0.7927777777777778,
      "grad_norm": 0.05627651885151863,
      "learning_rate": 3.0180555555555555e-05,
      "loss": 0.0012,
      "step": 14270
    },
    {
      "epoch": 0.7933333333333333,
      "grad_norm": 0.0,
      "learning_rate": 3.016666666666667e-05,
      "loss": 0.0006,
      "step": 14280
    },
    {
      "epoch": 0.7938888888888889,
      "grad_norm": 0.14002005755901337,
      "learning_rate": 3.015277777777778e-05,
      "loss": 0.0005,
      "step": 14290
    },
    {
      "epoch": 0.7944444444444444,
      "grad_norm": 0.08657281845808029,
      "learning_rate": 3.0138888888888888e-05,
      "loss": 0.0019,
      "step": 14300
    },
    {
      "epoch": 0.795,
      "grad_norm": 0.23231983184814453,
      "learning_rate": 3.0125000000000004e-05,
      "loss": 0.0014,
      "step": 14310
    },
    {
      "epoch": 0.7955555555555556,
      "grad_norm": 0.0,
      "learning_rate": 3.0111111111111113e-05,
      "loss": 0.0004,
      "step": 14320
    },
    {
      "epoch": 0.7961111111111111,
      "grad_norm": 0.0,
      "learning_rate": 3.009722222222222e-05,
      "loss": 0.0013,
      "step": 14330
    },
    {
      "epoch": 0.7966666666666666,
      "grad_norm": 0.04244124889373779,
      "learning_rate": 3.0083333333333337e-05,
      "loss": 0.0016,
      "step": 14340
    },
    {
      "epoch": 0.7972222222222223,
      "grad_norm": 0.08716929703950882,
      "learning_rate": 3.0069444444444446e-05,
      "loss": 0.0009,
      "step": 14350
    },
    {
      "epoch": 0.7977777777777778,
      "grad_norm": 0.22440917789936066,
      "learning_rate": 3.005555555555556e-05,
      "loss": 0.0006,
      "step": 14360
    },
    {
      "epoch": 0.7983333333333333,
      "grad_norm": 0.2579016089439392,
      "learning_rate": 3.0041666666666667e-05,
      "loss": 0.0005,
      "step": 14370
    },
    {
      "epoch": 0.7988888888888889,
      "grad_norm": 0.09234373271465302,
      "learning_rate": 3.0027777777777776e-05,
      "loss": 0.001,
      "step": 14380
    },
    {
      "epoch": 0.7994444444444444,
      "grad_norm": 0.0,
      "learning_rate": 3.0013888888888892e-05,
      "loss": 0.0012,
      "step": 14390
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.12669728696346283,
      "learning_rate": 3e-05,
      "loss": 0.001,
      "step": 14400
    },
    {
      "epoch": 0.8005555555555556,
      "grad_norm": 0.09393615275621414,
      "learning_rate": 2.9986111111111116e-05,
      "loss": 0.0022,
      "step": 14410
    },
    {
      "epoch": 0.8011111111111111,
      "grad_norm": 0.04589146375656128,
      "learning_rate": 2.9972222222222225e-05,
      "loss": 0.0009,
      "step": 14420
    },
    {
      "epoch": 0.8016666666666666,
      "grad_norm": 0.19624626636505127,
      "learning_rate": 2.9958333333333334e-05,
      "loss": 0.001,
      "step": 14430
    },
    {
      "epoch": 0.8022222222222222,
      "grad_norm": 0.0,
      "learning_rate": 2.9944444444444446e-05,
      "loss": 0.0003,
      "step": 14440
    },
    {
      "epoch": 0.8027777777777778,
      "grad_norm": 0.3146655857563019,
      "learning_rate": 2.9930555555555555e-05,
      "loss": 0.0008,
      "step": 14450
    },
    {
      "epoch": 0.8033333333333333,
      "grad_norm": 0.09340396523475647,
      "learning_rate": 2.991666666666667e-05,
      "loss": 0.001,
      "step": 14460
    },
    {
      "epoch": 0.8038888888888889,
      "grad_norm": 0.044013991951942444,
      "learning_rate": 2.990277777777778e-05,
      "loss": 0.0003,
      "step": 14470
    },
    {
      "epoch": 0.8044444444444444,
      "grad_norm": 0.04331158101558685,
      "learning_rate": 2.988888888888889e-05,
      "loss": 0.0009,
      "step": 14480
    },
    {
      "epoch": 0.805,
      "grad_norm": 0.0,
      "learning_rate": 2.9875000000000004e-05,
      "loss": 0.0001,
      "step": 14490
    },
    {
      "epoch": 0.8055555555555556,
      "grad_norm": 0.04344526678323746,
      "learning_rate": 2.9861111111111113e-05,
      "loss": 0.0006,
      "step": 14500
    },
    {
      "epoch": 0.8061111111111111,
      "grad_norm": 0.22353330254554749,
      "learning_rate": 2.9847222222222226e-05,
      "loss": 0.0017,
      "step": 14510
    },
    {
      "epoch": 0.8066666666666666,
      "grad_norm": 0.13192425668239594,
      "learning_rate": 2.9833333333333335e-05,
      "loss": 0.0005,
      "step": 14520
    },
    {
      "epoch": 0.8072222222222222,
      "grad_norm": 0.19010791182518005,
      "learning_rate": 2.9819444444444443e-05,
      "loss": 0.0016,
      "step": 14530
    },
    {
      "epoch": 0.8077777777777778,
      "grad_norm": 0.23916317522525787,
      "learning_rate": 2.980555555555556e-05,
      "loss": 0.0008,
      "step": 14540
    },
    {
      "epoch": 0.8083333333333333,
      "grad_norm": 0.3233264088630676,
      "learning_rate": 2.9791666666666668e-05,
      "loss": 0.0007,
      "step": 14550
    },
    {
      "epoch": 0.8088888888888889,
      "grad_norm": 0.0482039712369442,
      "learning_rate": 2.9777777777777777e-05,
      "loss": 0.0003,
      "step": 14560
    },
    {
      "epoch": 0.8094444444444444,
      "grad_norm": 0.08386150747537613,
      "learning_rate": 2.9763888888888893e-05,
      "loss": 0.0005,
      "step": 14570
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.3053237795829773,
      "learning_rate": 2.975e-05,
      "loss": 0.0005,
      "step": 14580
    },
    {
      "epoch": 0.8105555555555556,
      "grad_norm": 0.0,
      "learning_rate": 2.9736111111111114e-05,
      "loss": 0.0005,
      "step": 14590
    },
    {
      "epoch": 0.8111111111111111,
      "grad_norm": 0.05563044920563698,
      "learning_rate": 2.9722222222222223e-05,
      "loss": 0.0008,
      "step": 14600
    },
    {
      "epoch": 0.8116666666666666,
      "grad_norm": 0.1850329041481018,
      "learning_rate": 2.970833333333333e-05,
      "loss": 0.0003,
      "step": 14610
    },
    {
      "epoch": 0.8122222222222222,
      "grad_norm": 0.026022426784038544,
      "learning_rate": 2.9694444444444447e-05,
      "loss": 0.0013,
      "step": 14620
    },
    {
      "epoch": 0.8127777777777778,
      "grad_norm": 0.0,
      "learning_rate": 2.9680555555555556e-05,
      "loss": 0.001,
      "step": 14630
    },
    {
      "epoch": 0.8133333333333334,
      "grad_norm": 0.16594333946704865,
      "learning_rate": 2.9666666666666672e-05,
      "loss": 0.0013,
      "step": 14640
    },
    {
      "epoch": 0.8138888888888889,
      "grad_norm": 0.0,
      "learning_rate": 2.965277777777778e-05,
      "loss": 0.0008,
      "step": 14650
    },
    {
      "epoch": 0.8144444444444444,
      "grad_norm": 0.04285857453942299,
      "learning_rate": 2.963888888888889e-05,
      "loss": 0.0006,
      "step": 14660
    },
    {
      "epoch": 0.815,
      "grad_norm": 0.0,
      "learning_rate": 2.9625000000000002e-05,
      "loss": 0.0009,
      "step": 14670
    },
    {
      "epoch": 0.8155555555555556,
      "grad_norm": 0.3150778114795685,
      "learning_rate": 2.961111111111111e-05,
      "loss": 0.0011,
      "step": 14680
    },
    {
      "epoch": 0.8161111111111111,
      "grad_norm": 0.3301098048686981,
      "learning_rate": 2.9597222222222226e-05,
      "loss": 0.0015,
      "step": 14690
    },
    {
      "epoch": 0.8166666666666667,
      "grad_norm": 0.1700836718082428,
      "learning_rate": 2.9583333333333335e-05,
      "loss": 0.0007,
      "step": 14700
    },
    {
      "epoch": 0.8172222222222222,
      "grad_norm": 0.10314743965864182,
      "learning_rate": 2.9569444444444444e-05,
      "loss": 0.0002,
      "step": 14710
    },
    {
      "epoch": 0.8177777777777778,
      "grad_norm": 0.0,
      "learning_rate": 2.955555555555556e-05,
      "loss": 0.0014,
      "step": 14720
    },
    {
      "epoch": 0.8183333333333334,
      "grad_norm": 0.13772664964199066,
      "learning_rate": 2.954166666666667e-05,
      "loss": 0.0011,
      "step": 14730
    },
    {
      "epoch": 0.8188888888888889,
      "grad_norm": 0.0,
      "learning_rate": 2.9527777777777778e-05,
      "loss": 0.0012,
      "step": 14740
    },
    {
      "epoch": 0.8194444444444444,
      "grad_norm": 0.10692786425352097,
      "learning_rate": 2.951388888888889e-05,
      "loss": 0.0003,
      "step": 14750
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.14341704547405243,
      "learning_rate": 2.95e-05,
      "loss": 0.0008,
      "step": 14760
    },
    {
      "epoch": 0.8205555555555556,
      "grad_norm": 0.041427988559007645,
      "learning_rate": 2.9486111111111114e-05,
      "loss": 0.0011,
      "step": 14770
    },
    {
      "epoch": 0.8211111111111111,
      "grad_norm": 0.37585335969924927,
      "learning_rate": 2.9472222222222223e-05,
      "loss": 0.0015,
      "step": 14780
    },
    {
      "epoch": 0.8216666666666667,
      "grad_norm": 0.21732625365257263,
      "learning_rate": 2.9458333333333332e-05,
      "loss": 0.0009,
      "step": 14790
    },
    {
      "epoch": 0.8222222222222222,
      "grad_norm": 0.21417199075222015,
      "learning_rate": 2.9444444444444448e-05,
      "loss": 0.0004,
      "step": 14800
    },
    {
      "epoch": 0.8227777777777778,
      "grad_norm": 0.0,
      "learning_rate": 2.9430555555555557e-05,
      "loss": 0.0002,
      "step": 14810
    },
    {
      "epoch": 0.8233333333333334,
      "grad_norm": 0.04366069287061691,
      "learning_rate": 2.941666666666667e-05,
      "loss": 0.0012,
      "step": 14820
    },
    {
      "epoch": 0.8238888888888889,
      "grad_norm": 0.0,
      "learning_rate": 2.9402777777777778e-05,
      "loss": 0.0006,
      "step": 14830
    },
    {
      "epoch": 0.8244444444444444,
      "grad_norm": 0.0,
      "learning_rate": 2.9388888888888887e-05,
      "loss": 0.0007,
      "step": 14840
    },
    {
      "epoch": 0.825,
      "grad_norm": 0.18365822732448578,
      "learning_rate": 2.9375000000000003e-05,
      "loss": 0.0012,
      "step": 14850
    },
    {
      "epoch": 0.8255555555555556,
      "grad_norm": 0.1501714587211609,
      "learning_rate": 2.936111111111111e-05,
      "loss": 0.0016,
      "step": 14860
    },
    {
      "epoch": 0.8261111111111111,
      "grad_norm": 0.0,
      "learning_rate": 2.9347222222222227e-05,
      "loss": 0.0008,
      "step": 14870
    },
    {
      "epoch": 0.8266666666666667,
      "grad_norm": 0.0,
      "learning_rate": 2.9333333333333336e-05,
      "loss": 0.0013,
      "step": 14880
    },
    {
      "epoch": 0.8272222222222222,
      "grad_norm": 0.0,
      "learning_rate": 2.9319444444444445e-05,
      "loss": 0.001,
      "step": 14890
    },
    {
      "epoch": 0.8277777777777777,
      "grad_norm": 0.2537679374217987,
      "learning_rate": 2.9305555555555557e-05,
      "loss": 0.0015,
      "step": 14900
    },
    {
      "epoch": 0.8283333333333334,
      "grad_norm": 0.05595872178673744,
      "learning_rate": 2.9291666666666666e-05,
      "loss": 0.0003,
      "step": 14910
    },
    {
      "epoch": 0.8288888888888889,
      "grad_norm": 0.3737354278564453,
      "learning_rate": 2.927777777777778e-05,
      "loss": 0.0006,
      "step": 14920
    },
    {
      "epoch": 0.8294444444444444,
      "grad_norm": 0.0,
      "learning_rate": 2.926388888888889e-05,
      "loss": 0.0007,
      "step": 14930
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.09203242510557175,
      "learning_rate": 2.925e-05,
      "loss": 0.001,
      "step": 14940
    },
    {
      "epoch": 0.8305555555555556,
      "grad_norm": 0.24903689324855804,
      "learning_rate": 2.9236111111111115e-05,
      "loss": 0.0011,
      "step": 14950
    },
    {
      "epoch": 0.8311111111111111,
      "grad_norm": 0.3114136755466461,
      "learning_rate": 2.9222222222222224e-05,
      "loss": 0.001,
      "step": 14960
    },
    {
      "epoch": 0.8316666666666667,
      "grad_norm": 0.0,
      "learning_rate": 2.9208333333333333e-05,
      "loss": 0.001,
      "step": 14970
    },
    {
      "epoch": 0.8322222222222222,
      "grad_norm": 0.228395476937294,
      "learning_rate": 2.9194444444444445e-05,
      "loss": 0.0005,
      "step": 14980
    },
    {
      "epoch": 0.8327777777777777,
      "grad_norm": 0.112599216401577,
      "learning_rate": 2.9180555555555554e-05,
      "loss": 0.0003,
      "step": 14990
    },
    {
      "epoch": 0.8333333333333334,
      "grad_norm": 0.09355460852384567,
      "learning_rate": 2.916666666666667e-05,
      "loss": 0.0017,
      "step": 15000
    },
    {
      "epoch": 0.8338888888888889,
      "grad_norm": 0.34375786781311035,
      "learning_rate": 2.915277777777778e-05,
      "loss": 0.0006,
      "step": 15010
    },
    {
      "epoch": 0.8344444444444444,
      "grad_norm": 0.0370476059615612,
      "learning_rate": 2.9138888888888888e-05,
      "loss": 0.0008,
      "step": 15020
    },
    {
      "epoch": 0.835,
      "grad_norm": 0.0,
      "learning_rate": 2.9125000000000003e-05,
      "loss": 0.0008,
      "step": 15030
    },
    {
      "epoch": 0.8355555555555556,
      "grad_norm": 0.0975288674235344,
      "learning_rate": 2.9111111111111112e-05,
      "loss": 0.0007,
      "step": 15040
    },
    {
      "epoch": 0.8361111111111111,
      "grad_norm": 0.08142895996570587,
      "learning_rate": 2.9097222222222224e-05,
      "loss": 0.0011,
      "step": 15050
    },
    {
      "epoch": 0.8366666666666667,
      "grad_norm": 0.04445287957787514,
      "learning_rate": 2.9083333333333333e-05,
      "loss": 0.0004,
      "step": 15060
    },
    {
      "epoch": 0.8372222222222222,
      "grad_norm": 0.054113082587718964,
      "learning_rate": 2.9069444444444442e-05,
      "loss": 0.0006,
      "step": 15070
    },
    {
      "epoch": 0.8377777777777777,
      "grad_norm": 0.0,
      "learning_rate": 2.9055555555555558e-05,
      "loss": 0.0009,
      "step": 15080
    },
    {
      "epoch": 0.8383333333333334,
      "grad_norm": 0.0,
      "learning_rate": 2.9041666666666667e-05,
      "loss": 0.0013,
      "step": 15090
    },
    {
      "epoch": 0.8388888888888889,
      "grad_norm": 0.04528576508164406,
      "learning_rate": 2.9027777777777782e-05,
      "loss": 0.001,
      "step": 15100
    },
    {
      "epoch": 0.8394444444444444,
      "grad_norm": 0.0,
      "learning_rate": 2.901388888888889e-05,
      "loss": 0.0011,
      "step": 15110
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.0,
      "learning_rate": 2.9e-05,
      "loss": 0.001,
      "step": 15120
    },
    {
      "epoch": 0.8405555555555555,
      "grad_norm": 0.19904978573322296,
      "learning_rate": 2.8986111111111112e-05,
      "loss": 0.0012,
      "step": 15130
    },
    {
      "epoch": 0.8411111111111111,
      "grad_norm": 0.09046941250562668,
      "learning_rate": 2.897222222222222e-05,
      "loss": 0.0007,
      "step": 15140
    },
    {
      "epoch": 0.8416666666666667,
      "grad_norm": 0.10091917216777802,
      "learning_rate": 2.8958333333333337e-05,
      "loss": 0.0009,
      "step": 15150
    },
    {
      "epoch": 0.8422222222222222,
      "grad_norm": 0.0,
      "learning_rate": 2.8944444444444446e-05,
      "loss": 0.0015,
      "step": 15160
    },
    {
      "epoch": 0.8427777777777777,
      "grad_norm": 0.1185634508728981,
      "learning_rate": 2.8930555555555555e-05,
      "loss": 0.0002,
      "step": 15170
    },
    {
      "epoch": 0.8433333333333334,
      "grad_norm": 0.044049546122550964,
      "learning_rate": 2.891666666666667e-05,
      "loss": 0.001,
      "step": 15180
    },
    {
      "epoch": 0.8438888888888889,
      "grad_norm": 0.0,
      "learning_rate": 2.890277777777778e-05,
      "loss": 0.0004,
      "step": 15190
    },
    {
      "epoch": 0.8444444444444444,
      "grad_norm": 0.08571871370077133,
      "learning_rate": 2.8888888888888888e-05,
      "loss": 0.0007,
      "step": 15200
    },
    {
      "epoch": 0.845,
      "grad_norm": 0.016364850103855133,
      "learning_rate": 2.8875e-05,
      "loss": 0.0009,
      "step": 15210
    },
    {
      "epoch": 0.8455555555555555,
      "grad_norm": 0.04479159787297249,
      "learning_rate": 2.886111111111111e-05,
      "loss": 0.0005,
      "step": 15220
    },
    {
      "epoch": 0.8461111111111111,
      "grad_norm": 0.05572371929883957,
      "learning_rate": 2.8847222222222225e-05,
      "loss": 0.0008,
      "step": 15230
    },
    {
      "epoch": 0.8466666666666667,
      "grad_norm": 0.04673542082309723,
      "learning_rate": 2.8833333333333334e-05,
      "loss": 0.0007,
      "step": 15240
    },
    {
      "epoch": 0.8472222222222222,
      "grad_norm": 0.042885102331638336,
      "learning_rate": 2.8819444444444443e-05,
      "loss": 0.0005,
      "step": 15250
    },
    {
      "epoch": 0.8477777777777777,
      "grad_norm": 0.0,
      "learning_rate": 2.880555555555556e-05,
      "loss": 0.0003,
      "step": 15260
    },
    {
      "epoch": 0.8483333333333334,
      "grad_norm": 0.044140979647636414,
      "learning_rate": 2.8791666666666667e-05,
      "loss": 0.0009,
      "step": 15270
    },
    {
      "epoch": 0.8488888888888889,
      "grad_norm": 0.11526583880186081,
      "learning_rate": 2.877777777777778e-05,
      "loss": 0.0008,
      "step": 15280
    },
    {
      "epoch": 0.8494444444444444,
      "grad_norm": 0.04433764889836311,
      "learning_rate": 2.876388888888889e-05,
      "loss": 0.0011,
      "step": 15290
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.045219890773296356,
      "learning_rate": 2.8749999999999997e-05,
      "loss": 0.0005,
      "step": 15300
    },
    {
      "epoch": 0.8505555555555555,
      "grad_norm": 0.09975942969322205,
      "learning_rate": 2.8736111111111113e-05,
      "loss": 0.0004,
      "step": 15310
    },
    {
      "epoch": 0.8511111111111112,
      "grad_norm": 0.0,
      "learning_rate": 2.8722222222222222e-05,
      "loss": 0.0007,
      "step": 15320
    },
    {
      "epoch": 0.8516666666666667,
      "grad_norm": 0.0471823625266552,
      "learning_rate": 2.8708333333333338e-05,
      "loss": 0.0009,
      "step": 15330
    },
    {
      "epoch": 0.8522222222222222,
      "grad_norm": 0.09940563142299652,
      "learning_rate": 2.8694444444444447e-05,
      "loss": 0.0012,
      "step": 15340
    },
    {
      "epoch": 0.8527777777777777,
      "grad_norm": 0.09603946655988693,
      "learning_rate": 2.8680555555555555e-05,
      "loss": 0.0011,
      "step": 15350
    },
    {
      "epoch": 0.8533333333333334,
      "grad_norm": 0.04576471447944641,
      "learning_rate": 2.8666666666666668e-05,
      "loss": 0.0011,
      "step": 15360
    },
    {
      "epoch": 0.8538888888888889,
      "grad_norm": 0.0,
      "learning_rate": 2.865277777777778e-05,
      "loss": 0.0005,
      "step": 15370
    },
    {
      "epoch": 0.8544444444444445,
      "grad_norm": 0.1872982233762741,
      "learning_rate": 2.8638888888888892e-05,
      "loss": 0.0009,
      "step": 15380
    },
    {
      "epoch": 0.855,
      "grad_norm": 0.20148441195487976,
      "learning_rate": 2.8625e-05,
      "loss": 0.0013,
      "step": 15390
    },
    {
      "epoch": 0.8555555555555555,
      "grad_norm": 0.27377235889434814,
      "learning_rate": 2.861111111111111e-05,
      "loss": 0.0013,
      "step": 15400
    },
    {
      "epoch": 0.8561111111111112,
      "grad_norm": 0.16183842718601227,
      "learning_rate": 2.8597222222222226e-05,
      "loss": 0.0004,
      "step": 15410
    },
    {
      "epoch": 0.8566666666666667,
      "grad_norm": 0.13636936247348785,
      "learning_rate": 2.8583333333333335e-05,
      "loss": 0.0003,
      "step": 15420
    },
    {
      "epoch": 0.8572222222222222,
      "grad_norm": 0.0672178566455841,
      "learning_rate": 2.8569444444444444e-05,
      "loss": 0.0015,
      "step": 15430
    },
    {
      "epoch": 0.8577777777777778,
      "grad_norm": 0.0,
      "learning_rate": 2.855555555555556e-05,
      "loss": 0.0004,
      "step": 15440
    },
    {
      "epoch": 0.8583333333333333,
      "grad_norm": 0.0,
      "learning_rate": 2.8541666666666668e-05,
      "loss": 0.0006,
      "step": 15450
    },
    {
      "epoch": 0.8588888888888889,
      "grad_norm": 0.1439712792634964,
      "learning_rate": 2.852777777777778e-05,
      "loss": 0.0006,
      "step": 15460
    },
    {
      "epoch": 0.8594444444444445,
      "grad_norm": 0.0,
      "learning_rate": 2.851388888888889e-05,
      "loss": 0.0016,
      "step": 15470
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.021296504884958267,
      "learning_rate": 2.8499999999999998e-05,
      "loss": 0.0006,
      "step": 15480
    },
    {
      "epoch": 0.8605555555555555,
      "grad_norm": 0.09293767809867859,
      "learning_rate": 2.8486111111111114e-05,
      "loss": 0.0005,
      "step": 15490
    },
    {
      "epoch": 0.8611111111111112,
      "grad_norm": 0.10045497864484787,
      "learning_rate": 2.8472222222222223e-05,
      "loss": 0.0009,
      "step": 15500
    },
    {
      "epoch": 0.8616666666666667,
      "grad_norm": 0.2820858657360077,
      "learning_rate": 2.845833333333334e-05,
      "loss": 0.0006,
      "step": 15510
    },
    {
      "epoch": 0.8622222222222222,
      "grad_norm": 0.11194979399442673,
      "learning_rate": 2.8444444444444447e-05,
      "loss": 0.0009,
      "step": 15520
    },
    {
      "epoch": 0.8627777777777778,
      "grad_norm": 0.1376924365758896,
      "learning_rate": 2.8430555555555556e-05,
      "loss": 0.002,
      "step": 15530
    },
    {
      "epoch": 0.8633333333333333,
      "grad_norm": 0.04919120669364929,
      "learning_rate": 2.841666666666667e-05,
      "loss": 0.0008,
      "step": 15540
    },
    {
      "epoch": 0.8638888888888889,
      "grad_norm": 0.2195759415626526,
      "learning_rate": 2.8402777777777777e-05,
      "loss": 0.0003,
      "step": 15550
    },
    {
      "epoch": 0.8644444444444445,
      "grad_norm": 0.0864817425608635,
      "learning_rate": 2.8388888888888893e-05,
      "loss": 0.0006,
      "step": 15560
    },
    {
      "epoch": 0.865,
      "grad_norm": 0.08936746418476105,
      "learning_rate": 2.8375000000000002e-05,
      "loss": 0.0005,
      "step": 15570
    },
    {
      "epoch": 0.8655555555555555,
      "grad_norm": 0.04417812079191208,
      "learning_rate": 2.836111111111111e-05,
      "loss": 0.001,
      "step": 15580
    },
    {
      "epoch": 0.8661111111111112,
      "grad_norm": 0.0,
      "learning_rate": 2.8347222222222226e-05,
      "loss": 0.0009,
      "step": 15590
    },
    {
      "epoch": 0.8666666666666667,
      "grad_norm": 0.0,
      "learning_rate": 2.8333333333333335e-05,
      "loss": 0.001,
      "step": 15600
    },
    {
      "epoch": 0.8672222222222222,
      "grad_norm": 0.06015516072511673,
      "learning_rate": 2.8319444444444448e-05,
      "loss": 0.0004,
      "step": 15610
    },
    {
      "epoch": 0.8677777777777778,
      "grad_norm": 0.09214955568313599,
      "learning_rate": 2.8305555555555557e-05,
      "loss": 0.0008,
      "step": 15620
    },
    {
      "epoch": 0.8683333333333333,
      "grad_norm": 0.0,
      "learning_rate": 2.8291666666666665e-05,
      "loss": 0.0006,
      "step": 15630
    },
    {
      "epoch": 0.8688888888888889,
      "grad_norm": 0.0,
      "learning_rate": 2.827777777777778e-05,
      "loss": 0.0007,
      "step": 15640
    },
    {
      "epoch": 0.8694444444444445,
      "grad_norm": 0.2232629954814911,
      "learning_rate": 2.826388888888889e-05,
      "loss": 0.0013,
      "step": 15650
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.0,
      "learning_rate": 2.825e-05,
      "loss": 0.0013,
      "step": 15660
    },
    {
      "epoch": 0.8705555555555555,
      "grad_norm": 0.048856668174266815,
      "learning_rate": 2.8236111111111115e-05,
      "loss": 0.0014,
      "step": 15670
    },
    {
      "epoch": 0.8711111111111111,
      "grad_norm": 0.0,
      "learning_rate": 2.8222222222222223e-05,
      "loss": 0.0009,
      "step": 15680
    },
    {
      "epoch": 0.8716666666666667,
      "grad_norm": 0.04753243178129196,
      "learning_rate": 2.8208333333333336e-05,
      "loss": 0.0008,
      "step": 15690
    },
    {
      "epoch": 0.8722222222222222,
      "grad_norm": 0.07983370125293732,
      "learning_rate": 2.8194444444444445e-05,
      "loss": 0.0011,
      "step": 15700
    },
    {
      "epoch": 0.8727777777777778,
      "grad_norm": 0.05147872865200043,
      "learning_rate": 2.8180555555555554e-05,
      "loss": 0.0004,
      "step": 15710
    },
    {
      "epoch": 0.8733333333333333,
      "grad_norm": 0.0,
      "learning_rate": 2.816666666666667e-05,
      "loss": 0.0008,
      "step": 15720
    },
    {
      "epoch": 0.8738888888888889,
      "grad_norm": 0.0388929657638073,
      "learning_rate": 2.8152777777777778e-05,
      "loss": 0.0007,
      "step": 15730
    },
    {
      "epoch": 0.8744444444444445,
      "grad_norm": 0.0,
      "learning_rate": 2.8138888888888894e-05,
      "loss": 0.0006,
      "step": 15740
    },
    {
      "epoch": 0.875,
      "grad_norm": 0.0,
      "learning_rate": 2.8125000000000003e-05,
      "loss": 0.0001,
      "step": 15750
    },
    {
      "epoch": 0.8755555555555555,
      "grad_norm": 0.2643122971057892,
      "learning_rate": 2.811111111111111e-05,
      "loss": 0.0009,
      "step": 15760
    },
    {
      "epoch": 0.8761111111111111,
      "grad_norm": 0.6868712306022644,
      "learning_rate": 2.8097222222222224e-05,
      "loss": 0.0022,
      "step": 15770
    },
    {
      "epoch": 0.8766666666666667,
      "grad_norm": 0.05004904419183731,
      "learning_rate": 2.8083333333333333e-05,
      "loss": 0.0014,
      "step": 15780
    },
    {
      "epoch": 0.8772222222222222,
      "grad_norm": 0.08860772103071213,
      "learning_rate": 2.806944444444445e-05,
      "loss": 0.0011,
      "step": 15790
    },
    {
      "epoch": 0.8777777777777778,
      "grad_norm": 0.16133274137973785,
      "learning_rate": 2.8055555555555557e-05,
      "loss": 0.0004,
      "step": 15800
    },
    {
      "epoch": 0.8783333333333333,
      "grad_norm": 0.0,
      "learning_rate": 2.8041666666666666e-05,
      "loss": 0.0011,
      "step": 15810
    },
    {
      "epoch": 0.8788888888888889,
      "grad_norm": 0.1703430712223053,
      "learning_rate": 2.8027777777777782e-05,
      "loss": 0.0018,
      "step": 15820
    },
    {
      "epoch": 0.8794444444444445,
      "grad_norm": 0.0,
      "learning_rate": 2.801388888888889e-05,
      "loss": 0.0016,
      "step": 15830
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.0,
      "learning_rate": 2.8000000000000003e-05,
      "loss": 0.0003,
      "step": 15840
    },
    {
      "epoch": 0.8805555555555555,
      "grad_norm": 0.0,
      "learning_rate": 2.7986111111111112e-05,
      "loss": 0.0005,
      "step": 15850
    },
    {
      "epoch": 0.8811111111111111,
      "grad_norm": 0.14598943293094635,
      "learning_rate": 2.797222222222222e-05,
      "loss": 0.0011,
      "step": 15860
    },
    {
      "epoch": 0.8816666666666667,
      "grad_norm": 0.12896504998207092,
      "learning_rate": 2.7958333333333336e-05,
      "loss": 0.0003,
      "step": 15870
    },
    {
      "epoch": 0.8822222222222222,
      "grad_norm": 0.05018512159585953,
      "learning_rate": 2.7944444444444445e-05,
      "loss": 0.0007,
      "step": 15880
    },
    {
      "epoch": 0.8827777777777778,
      "grad_norm": 0.0,
      "learning_rate": 2.7930555555555554e-05,
      "loss": 0.0015,
      "step": 15890
    },
    {
      "epoch": 0.8833333333333333,
      "grad_norm": 0.04856023192405701,
      "learning_rate": 2.791666666666667e-05,
      "loss": 0.0014,
      "step": 15900
    },
    {
      "epoch": 0.8838888888888888,
      "grad_norm": 0.0,
      "learning_rate": 2.790277777777778e-05,
      "loss": 0.002,
      "step": 15910
    },
    {
      "epoch": 0.8844444444444445,
      "grad_norm": 0.1563815027475357,
      "learning_rate": 2.788888888888889e-05,
      "loss": 0.0006,
      "step": 15920
    },
    {
      "epoch": 0.885,
      "grad_norm": 0.035700757056474686,
      "learning_rate": 2.7875e-05,
      "loss": 0.0006,
      "step": 15930
    },
    {
      "epoch": 0.8855555555555555,
      "grad_norm": 0.0,
      "learning_rate": 2.786111111111111e-05,
      "loss": 0.0005,
      "step": 15940
    },
    {
      "epoch": 0.8861111111111111,
      "grad_norm": 0.0,
      "learning_rate": 2.7847222222222224e-05,
      "loss": 0.0004,
      "step": 15950
    },
    {
      "epoch": 0.8866666666666667,
      "grad_norm": 0.15111985802650452,
      "learning_rate": 2.7833333333333333e-05,
      "loss": 0.0003,
      "step": 15960
    },
    {
      "epoch": 0.8872222222222222,
      "grad_norm": 0.13594645261764526,
      "learning_rate": 2.781944444444445e-05,
      "loss": 0.0014,
      "step": 15970
    },
    {
      "epoch": 0.8877777777777778,
      "grad_norm": 0.0,
      "learning_rate": 2.7805555555555558e-05,
      "loss": 0.0011,
      "step": 15980
    },
    {
      "epoch": 0.8883333333333333,
      "grad_norm": 0.0,
      "learning_rate": 2.7791666666666667e-05,
      "loss": 0.0013,
      "step": 15990
    },
    {
      "epoch": 0.8888888888888888,
      "grad_norm": 0.04674946516752243,
      "learning_rate": 2.777777777777778e-05,
      "loss": 0.0021,
      "step": 16000
    },
    {
      "epoch": 0.8894444444444445,
      "grad_norm": 0.0,
      "learning_rate": 2.7763888888888888e-05,
      "loss": 0.0009,
      "step": 16010
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.14798596501350403,
      "learning_rate": 2.7750000000000004e-05,
      "loss": 0.0015,
      "step": 16020
    },
    {
      "epoch": 0.8905555555555555,
      "grad_norm": 0.027804363518953323,
      "learning_rate": 2.7736111111111113e-05,
      "loss": 0.0011,
      "step": 16030
    },
    {
      "epoch": 0.8911111111111111,
      "grad_norm": 0.0,
      "learning_rate": 2.772222222222222e-05,
      "loss": 0.0011,
      "step": 16040
    },
    {
      "epoch": 0.8916666666666667,
      "grad_norm": 0.061566293239593506,
      "learning_rate": 2.7708333333333337e-05,
      "loss": 0.0002,
      "step": 16050
    },
    {
      "epoch": 0.8922222222222222,
      "grad_norm": 0.0,
      "learning_rate": 2.7694444444444446e-05,
      "loss": 0.0015,
      "step": 16060
    },
    {
      "epoch": 0.8927777777777778,
      "grad_norm": 0.16327106952667236,
      "learning_rate": 2.7680555555555558e-05,
      "loss": 0.0011,
      "step": 16070
    },
    {
      "epoch": 0.8933333333333333,
      "grad_norm": 0.10599032044410706,
      "learning_rate": 2.7666666666666667e-05,
      "loss": 0.0005,
      "step": 16080
    },
    {
      "epoch": 0.8938888888888888,
      "grad_norm": 0.17562711238861084,
      "learning_rate": 2.7652777777777776e-05,
      "loss": 0.0006,
      "step": 16090
    },
    {
      "epoch": 0.8944444444444445,
      "grad_norm": 0.22269129753112793,
      "learning_rate": 2.7638888888888892e-05,
      "loss": 0.0008,
      "step": 16100
    },
    {
      "epoch": 0.895,
      "grad_norm": 0.14404389262199402,
      "learning_rate": 2.7625e-05,
      "loss": 0.0021,
      "step": 16110
    },
    {
      "epoch": 0.8955555555555555,
      "grad_norm": 0.08815903961658478,
      "learning_rate": 2.761111111111111e-05,
      "loss": 0.0018,
      "step": 16120
    },
    {
      "epoch": 0.8961111111111111,
      "grad_norm": 0.4238940179347992,
      "learning_rate": 2.7597222222222225e-05,
      "loss": 0.0014,
      "step": 16130
    },
    {
      "epoch": 0.8966666666666666,
      "grad_norm": 0.1447744071483612,
      "learning_rate": 2.7583333333333334e-05,
      "loss": 0.0025,
      "step": 16140
    },
    {
      "epoch": 0.8972222222222223,
      "grad_norm": 0.0,
      "learning_rate": 2.7569444444444446e-05,
      "loss": 0.0006,
      "step": 16150
    },
    {
      "epoch": 0.8977777777777778,
      "grad_norm": 0.2992274761199951,
      "learning_rate": 2.7555555555555555e-05,
      "loss": 0.0019,
      "step": 16160
    },
    {
      "epoch": 0.8983333333333333,
      "grad_norm": 0.04739923030138016,
      "learning_rate": 2.7541666666666664e-05,
      "loss": 0.0009,
      "step": 16170
    },
    {
      "epoch": 0.8988888888888888,
      "grad_norm": 0.046852994710206985,
      "learning_rate": 2.752777777777778e-05,
      "loss": 0.0008,
      "step": 16180
    },
    {
      "epoch": 0.8994444444444445,
      "grad_norm": 0.0,
      "learning_rate": 2.751388888888889e-05,
      "loss": 0.0005,
      "step": 16190
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.0,
      "learning_rate": 2.7500000000000004e-05,
      "loss": 0.0005,
      "step": 16200
    },
    {
      "epoch": 0.9005555555555556,
      "grad_norm": 0.11900945752859116,
      "learning_rate": 2.7486111111111113e-05,
      "loss": 0.0004,
      "step": 16210
    },
    {
      "epoch": 0.9011111111111111,
      "grad_norm": 0.0,
      "learning_rate": 2.7472222222222222e-05,
      "loss": 0.0009,
      "step": 16220
    },
    {
      "epoch": 0.9016666666666666,
      "grad_norm": 0.04616810381412506,
      "learning_rate": 2.7458333333333334e-05,
      "loss": 0.001,
      "step": 16230
    },
    {
      "epoch": 0.9022222222222223,
      "grad_norm": 0.04544582962989807,
      "learning_rate": 2.7444444444444443e-05,
      "loss": 0.0005,
      "step": 16240
    },
    {
      "epoch": 0.9027777777777778,
      "grad_norm": 0.09189686924219131,
      "learning_rate": 2.743055555555556e-05,
      "loss": 0.0015,
      "step": 16250
    },
    {
      "epoch": 0.9033333333333333,
      "grad_norm": 0.06708193570375443,
      "learning_rate": 2.7416666666666668e-05,
      "loss": 0.0014,
      "step": 16260
    },
    {
      "epoch": 0.9038888888888889,
      "grad_norm": 0.04696628078818321,
      "learning_rate": 2.7402777777777777e-05,
      "loss": 0.0006,
      "step": 16270
    },
    {
      "epoch": 0.9044444444444445,
      "grad_norm": 0.08689044415950775,
      "learning_rate": 2.7388888888888892e-05,
      "loss": 0.0015,
      "step": 16280
    },
    {
      "epoch": 0.905,
      "grad_norm": 0.12523287534713745,
      "learning_rate": 2.7375e-05,
      "loss": 0.0014,
      "step": 16290
    },
    {
      "epoch": 0.9055555555555556,
      "grad_norm": 0.0,
      "learning_rate": 2.7361111111111114e-05,
      "loss": 0.0009,
      "step": 16300
    },
    {
      "epoch": 0.9061111111111111,
      "grad_norm": 0.09096615761518478,
      "learning_rate": 2.7347222222222222e-05,
      "loss": 0.0009,
      "step": 16310
    },
    {
      "epoch": 0.9066666666666666,
      "grad_norm": 0.10171139240264893,
      "learning_rate": 2.733333333333333e-05,
      "loss": 0.0012,
      "step": 16320
    },
    {
      "epoch": 0.9072222222222223,
      "grad_norm": 0.0,
      "learning_rate": 2.7319444444444447e-05,
      "loss": 0.0005,
      "step": 16330
    },
    {
      "epoch": 0.9077777777777778,
      "grad_norm": 0.23827782273292542,
      "learning_rate": 2.7305555555555556e-05,
      "loss": 0.0006,
      "step": 16340
    },
    {
      "epoch": 0.9083333333333333,
      "grad_norm": 0.06101154908537865,
      "learning_rate": 2.7291666666666665e-05,
      "loss": 0.0008,
      "step": 16350
    },
    {
      "epoch": 0.9088888888888889,
      "grad_norm": 0.04495654255151749,
      "learning_rate": 2.727777777777778e-05,
      "loss": 0.0007,
      "step": 16360
    },
    {
      "epoch": 0.9094444444444445,
      "grad_norm": 0.0,
      "learning_rate": 2.726388888888889e-05,
      "loss": 0.0004,
      "step": 16370
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.49212801456451416,
      "learning_rate": 2.725e-05,
      "loss": 0.0009,
      "step": 16380
    },
    {
      "epoch": 0.9105555555555556,
      "grad_norm": 0.1440768986940384,
      "learning_rate": 2.723611111111111e-05,
      "loss": 0.0011,
      "step": 16390
    },
    {
      "epoch": 0.9111111111111111,
      "grad_norm": 0.289602667093277,
      "learning_rate": 2.7222222222222223e-05,
      "loss": 0.0015,
      "step": 16400
    },
    {
      "epoch": 0.9116666666666666,
      "grad_norm": 0.23497073352336884,
      "learning_rate": 2.7208333333333335e-05,
      "loss": 0.0002,
      "step": 16410
    },
    {
      "epoch": 0.9122222222222223,
      "grad_norm": 0.0449925921857357,
      "learning_rate": 2.7194444444444444e-05,
      "loss": 0.001,
      "step": 16420
    },
    {
      "epoch": 0.9127777777777778,
      "grad_norm": 0.12605172395706177,
      "learning_rate": 2.718055555555556e-05,
      "loss": 0.0012,
      "step": 16430
    },
    {
      "epoch": 0.9133333333333333,
      "grad_norm": 0.0469503216445446,
      "learning_rate": 2.716666666666667e-05,
      "loss": 0.0011,
      "step": 16440
    },
    {
      "epoch": 0.9138888888888889,
      "grad_norm": 0.0,
      "learning_rate": 2.7152777777777777e-05,
      "loss": 0.0003,
      "step": 16450
    },
    {
      "epoch": 0.9144444444444444,
      "grad_norm": 0.31867414712905884,
      "learning_rate": 2.7138888888888893e-05,
      "loss": 0.0016,
      "step": 16460
    },
    {
      "epoch": 0.915,
      "grad_norm": 0.1422766149044037,
      "learning_rate": 2.7125000000000002e-05,
      "loss": 0.0016,
      "step": 16470
    },
    {
      "epoch": 0.9155555555555556,
      "grad_norm": 0.04357069730758667,
      "learning_rate": 2.7111111111111114e-05,
      "loss": 0.0013,
      "step": 16480
    },
    {
      "epoch": 0.9161111111111111,
      "grad_norm": 0.0,
      "learning_rate": 2.7097222222222223e-05,
      "loss": 0.0004,
      "step": 16490
    },
    {
      "epoch": 0.9166666666666666,
      "grad_norm": 0.043334413319826126,
      "learning_rate": 2.7083333333333332e-05,
      "loss": 0.0013,
      "step": 16500
    },
    {
      "epoch": 0.9172222222222223,
      "grad_norm": 0.15144525468349457,
      "learning_rate": 2.7069444444444448e-05,
      "loss": 0.0008,
      "step": 16510
    },
    {
      "epoch": 0.9177777777777778,
      "grad_norm": 0.22013899683952332,
      "learning_rate": 2.7055555555555557e-05,
      "loss": 0.0018,
      "step": 16520
    },
    {
      "epoch": 0.9183333333333333,
      "grad_norm": 0.04947059601545334,
      "learning_rate": 2.7041666666666672e-05,
      "loss": 0.001,
      "step": 16530
    },
    {
      "epoch": 0.9188888888888889,
      "grad_norm": 0.0563637912273407,
      "learning_rate": 2.702777777777778e-05,
      "loss": 0.0007,
      "step": 16540
    },
    {
      "epoch": 0.9194444444444444,
      "grad_norm": 0.0,
      "learning_rate": 2.701388888888889e-05,
      "loss": 0.0018,
      "step": 16550
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.086285799741745,
      "learning_rate": 2.7000000000000002e-05,
      "loss": 0.0014,
      "step": 16560
    },
    {
      "epoch": 0.9205555555555556,
      "grad_norm": 0.0,
      "learning_rate": 2.698611111111111e-05,
      "loss": 0.0002,
      "step": 16570
    },
    {
      "epoch": 0.9211111111111111,
      "grad_norm": 0.0,
      "learning_rate": 2.697222222222222e-05,
      "loss": 0.0007,
      "step": 16580
    },
    {
      "epoch": 0.9216666666666666,
      "grad_norm": 0.22325874865055084,
      "learning_rate": 2.6958333333333336e-05,
      "loss": 0.0006,
      "step": 16590
    },
    {
      "epoch": 0.9222222222222223,
      "grad_norm": 0.04914151132106781,
      "learning_rate": 2.6944444444444445e-05,
      "loss": 0.0005,
      "step": 16600
    },
    {
      "epoch": 0.9227777777777778,
      "grad_norm": 0.044744085520505905,
      "learning_rate": 2.693055555555556e-05,
      "loss": 0.0009,
      "step": 16610
    },
    {
      "epoch": 0.9233333333333333,
      "grad_norm": 0.0,
      "learning_rate": 2.691666666666667e-05,
      "loss": 0.0006,
      "step": 16620
    },
    {
      "epoch": 0.9238888888888889,
      "grad_norm": 0.04744775965809822,
      "learning_rate": 2.6902777777777778e-05,
      "loss": 0.0004,
      "step": 16630
    },
    {
      "epoch": 0.9244444444444444,
      "grad_norm": 0.0,
      "learning_rate": 2.688888888888889e-05,
      "loss": 0.0004,
      "step": 16640
    },
    {
      "epoch": 0.925,
      "grad_norm": 0.20743483304977417,
      "learning_rate": 2.6875e-05,
      "loss": 0.0003,
      "step": 16650
    },
    {
      "epoch": 0.9255555555555556,
      "grad_norm": 0.0,
      "learning_rate": 2.6861111111111115e-05,
      "loss": 0.0004,
      "step": 16660
    },
    {
      "epoch": 0.9261111111111111,
      "grad_norm": 0.14590442180633545,
      "learning_rate": 2.6847222222222224e-05,
      "loss": 0.0012,
      "step": 16670
    },
    {
      "epoch": 0.9266666666666666,
      "grad_norm": 0.15832960605621338,
      "learning_rate": 2.6833333333333333e-05,
      "loss": 0.0003,
      "step": 16680
    },
    {
      "epoch": 0.9272222222222222,
      "grad_norm": 0.08615152537822723,
      "learning_rate": 2.681944444444445e-05,
      "loss": 0.0005,
      "step": 16690
    },
    {
      "epoch": 0.9277777777777778,
      "grad_norm": 0.18200471997261047,
      "learning_rate": 2.6805555555555557e-05,
      "loss": 0.0003,
      "step": 16700
    },
    {
      "epoch": 0.9283333333333333,
      "grad_norm": 0.0,
      "learning_rate": 2.679166666666667e-05,
      "loss": 0.0007,
      "step": 16710
    },
    {
      "epoch": 0.9288888888888889,
      "grad_norm": 0.1263069212436676,
      "learning_rate": 2.677777777777778e-05,
      "loss": 0.0003,
      "step": 16720
    },
    {
      "epoch": 0.9294444444444444,
      "grad_norm": 0.1317991316318512,
      "learning_rate": 2.6763888888888887e-05,
      "loss": 0.0014,
      "step": 16730
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.04817267134785652,
      "learning_rate": 2.6750000000000003e-05,
      "loss": 0.0007,
      "step": 16740
    },
    {
      "epoch": 0.9305555555555556,
      "grad_norm": 0.09028873592615128,
      "learning_rate": 2.6736111111111112e-05,
      "loss": 0.0008,
      "step": 16750
    },
    {
      "epoch": 0.9311111111111111,
      "grad_norm": 0.0,
      "learning_rate": 2.6722222222222228e-05,
      "loss": 0.0011,
      "step": 16760
    },
    {
      "epoch": 0.9316666666666666,
      "grad_norm": 0.05523800477385521,
      "learning_rate": 2.6708333333333337e-05,
      "loss": 0.0004,
      "step": 16770
    },
    {
      "epoch": 0.9322222222222222,
      "grad_norm": 0.0,
      "learning_rate": 2.6694444444444445e-05,
      "loss": 0.0013,
      "step": 16780
    },
    {
      "epoch": 0.9327777777777778,
      "grad_norm": 0.0,
      "learning_rate": 2.6680555555555558e-05,
      "loss": 0.0013,
      "step": 16790
    },
    {
      "epoch": 0.9333333333333333,
      "grad_norm": 0.1309933215379715,
      "learning_rate": 2.6666666666666667e-05,
      "loss": 0.0021,
      "step": 16800
    },
    {
      "epoch": 0.9338888888888889,
      "grad_norm": 0.18500028550624847,
      "learning_rate": 2.6652777777777775e-05,
      "loss": 0.0005,
      "step": 16810
    },
    {
      "epoch": 0.9344444444444444,
      "grad_norm": 0.1777898520231247,
      "learning_rate": 2.663888888888889e-05,
      "loss": 0.001,
      "step": 16820
    },
    {
      "epoch": 0.935,
      "grad_norm": 0.0,
      "learning_rate": 2.6625e-05,
      "loss": 0.001,
      "step": 16830
    },
    {
      "epoch": 0.9355555555555556,
      "grad_norm": 0.38007035851478577,
      "learning_rate": 2.6611111111111116e-05,
      "loss": 0.0015,
      "step": 16840
    },
    {
      "epoch": 0.9361111111111111,
      "grad_norm": 0.15309815108776093,
      "learning_rate": 2.6597222222222225e-05,
      "loss": 0.0012,
      "step": 16850
    },
    {
      "epoch": 0.9366666666666666,
      "grad_norm": 0.09207025170326233,
      "learning_rate": 2.6583333333333333e-05,
      "loss": 0.0023,
      "step": 16860
    },
    {
      "epoch": 0.9372222222222222,
      "grad_norm": 0.0,
      "learning_rate": 2.6569444444444446e-05,
      "loss": 0.0005,
      "step": 16870
    },
    {
      "epoch": 0.9377777777777778,
      "grad_norm": 0.1579097956418991,
      "learning_rate": 2.6555555555555555e-05,
      "loss": 0.0007,
      "step": 16880
    },
    {
      "epoch": 0.9383333333333334,
      "grad_norm": 0.0,
      "learning_rate": 2.654166666666667e-05,
      "loss": 0.0007,
      "step": 16890
    },
    {
      "epoch": 0.9388888888888889,
      "grad_norm": 0.10954581201076508,
      "learning_rate": 2.652777777777778e-05,
      "loss": 0.0007,
      "step": 16900
    },
    {
      "epoch": 0.9394444444444444,
      "grad_norm": 0.0,
      "learning_rate": 2.6513888888888888e-05,
      "loss": 0.0006,
      "step": 16910
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.043269962072372437,
      "learning_rate": 2.6500000000000004e-05,
      "loss": 0.0016,
      "step": 16920
    },
    {
      "epoch": 0.9405555555555556,
      "grad_norm": 0.04439786821603775,
      "learning_rate": 2.6486111111111113e-05,
      "loss": 0.0013,
      "step": 16930
    },
    {
      "epoch": 0.9411111111111111,
      "grad_norm": 0.14251232147216797,
      "learning_rate": 2.6472222222222225e-05,
      "loss": 0.0021,
      "step": 16940
    },
    {
      "epoch": 0.9416666666666667,
      "grad_norm": 0.05302202329039574,
      "learning_rate": 2.6458333333333334e-05,
      "loss": 0.0003,
      "step": 16950
    },
    {
      "epoch": 0.9422222222222222,
      "grad_norm": 0.06127697601914406,
      "learning_rate": 2.6444444444444443e-05,
      "loss": 0.0014,
      "step": 16960
    },
    {
      "epoch": 0.9427777777777778,
      "grad_norm": 0.0,
      "learning_rate": 2.643055555555556e-05,
      "loss": 0.0002,
      "step": 16970
    },
    {
      "epoch": 0.9433333333333334,
      "grad_norm": 0.04345722496509552,
      "learning_rate": 2.6416666666666667e-05,
      "loss": 0.0002,
      "step": 16980
    },
    {
      "epoch": 0.9438888888888889,
      "grad_norm": 0.17593374848365784,
      "learning_rate": 2.6402777777777776e-05,
      "loss": 0.0009,
      "step": 16990
    },
    {
      "epoch": 0.9444444444444444,
      "grad_norm": 0.09198121726512909,
      "learning_rate": 2.6388888888888892e-05,
      "loss": 0.0011,
      "step": 17000
    },
    {
      "epoch": 0.945,
      "grad_norm": 0.025292227044701576,
      "learning_rate": 2.6375e-05,
      "loss": 0.0009,
      "step": 17010
    },
    {
      "epoch": 0.9455555555555556,
      "grad_norm": 0.27917590737342834,
      "learning_rate": 2.6361111111111113e-05,
      "loss": 0.0011,
      "step": 17020
    },
    {
      "epoch": 0.9461111111111111,
      "grad_norm": 0.0,
      "learning_rate": 2.6347222222222222e-05,
      "loss": 0.0003,
      "step": 17030
    },
    {
      "epoch": 0.9466666666666667,
      "grad_norm": 0.18177379667758942,
      "learning_rate": 2.633333333333333e-05,
      "loss": 0.0021,
      "step": 17040
    },
    {
      "epoch": 0.9472222222222222,
      "grad_norm": 0.05146379768848419,
      "learning_rate": 2.6319444444444446e-05,
      "loss": 0.0008,
      "step": 17050
    },
    {
      "epoch": 0.9477777777777778,
      "grad_norm": 0.34995973110198975,
      "learning_rate": 2.6305555555555555e-05,
      "loss": 0.0007,
      "step": 17060
    },
    {
      "epoch": 0.9483333333333334,
      "grad_norm": 0.1796567738056183,
      "learning_rate": 2.629166666666667e-05,
      "loss": 0.0004,
      "step": 17070
    },
    {
      "epoch": 0.9488888888888889,
      "grad_norm": 0.0,
      "learning_rate": 2.627777777777778e-05,
      "loss": 0.0006,
      "step": 17080
    },
    {
      "epoch": 0.9494444444444444,
      "grad_norm": 0.0,
      "learning_rate": 2.626388888888889e-05,
      "loss": 0.0013,
      "step": 17090
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.0,
      "learning_rate": 2.625e-05,
      "loss": 0.0008,
      "step": 17100
    },
    {
      "epoch": 0.9505555555555556,
      "grad_norm": 0.25963476300239563,
      "learning_rate": 2.623611111111111e-05,
      "loss": 0.0012,
      "step": 17110
    },
    {
      "epoch": 0.9511111111111111,
      "grad_norm": 0.11910669505596161,
      "learning_rate": 2.6222222222222226e-05,
      "loss": 0.0011,
      "step": 17120
    },
    {
      "epoch": 0.9516666666666667,
      "grad_norm": 0.3625364899635315,
      "learning_rate": 2.6208333333333335e-05,
      "loss": 0.0014,
      "step": 17130
    },
    {
      "epoch": 0.9522222222222222,
      "grad_norm": 0.0,
      "learning_rate": 2.6194444444444443e-05,
      "loss": 0.0007,
      "step": 17140
    },
    {
      "epoch": 0.9527777777777777,
      "grad_norm": 0.0928107351064682,
      "learning_rate": 2.618055555555556e-05,
      "loss": 0.0009,
      "step": 17150
    },
    {
      "epoch": 0.9533333333333334,
      "grad_norm": 0.0,
      "learning_rate": 2.6166666666666668e-05,
      "loss": 0.0006,
      "step": 17160
    },
    {
      "epoch": 0.9538888888888889,
      "grad_norm": 0.04576878249645233,
      "learning_rate": 2.615277777777778e-05,
      "loss": 0.0005,
      "step": 17170
    },
    {
      "epoch": 0.9544444444444444,
      "grad_norm": 0.0,
      "learning_rate": 2.613888888888889e-05,
      "loss": 0.0005,
      "step": 17180
    },
    {
      "epoch": 0.955,
      "grad_norm": 0.048696886748075485,
      "learning_rate": 2.6124999999999998e-05,
      "loss": 0.0008,
      "step": 17190
    },
    {
      "epoch": 0.9555555555555556,
      "grad_norm": 0.13217419385910034,
      "learning_rate": 2.6111111111111114e-05,
      "loss": 0.002,
      "step": 17200
    },
    {
      "epoch": 0.9561111111111111,
      "grad_norm": 0.18275675177574158,
      "learning_rate": 2.6097222222222223e-05,
      "loss": 0.0004,
      "step": 17210
    },
    {
      "epoch": 0.9566666666666667,
      "grad_norm": 0.1352127641439438,
      "learning_rate": 2.608333333333333e-05,
      "loss": 0.0011,
      "step": 17220
    },
    {
      "epoch": 0.9572222222222222,
      "grad_norm": 0.11735358089208603,
      "learning_rate": 2.6069444444444447e-05,
      "loss": 0.0007,
      "step": 17230
    },
    {
      "epoch": 0.9577777777777777,
      "grad_norm": 0.05659135431051254,
      "learning_rate": 2.6055555555555556e-05,
      "loss": 0.0007,
      "step": 17240
    },
    {
      "epoch": 0.9583333333333334,
      "grad_norm": 0.0,
      "learning_rate": 2.604166666666667e-05,
      "loss": 0.0006,
      "step": 17250
    },
    {
      "epoch": 0.9588888888888889,
      "grad_norm": 0.18150734901428223,
      "learning_rate": 2.6027777777777777e-05,
      "loss": 0.0009,
      "step": 17260
    },
    {
      "epoch": 0.9594444444444444,
      "grad_norm": 0.0,
      "learning_rate": 2.6013888888888886e-05,
      "loss": 0.0011,
      "step": 17270
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.0,
      "learning_rate": 2.6000000000000002e-05,
      "loss": 0.0002,
      "step": 17280
    },
    {
      "epoch": 0.9605555555555556,
      "grad_norm": 0.07547551393508911,
      "learning_rate": 2.598611111111111e-05,
      "loss": 0.0009,
      "step": 17290
    },
    {
      "epoch": 0.9611111111111111,
      "grad_norm": 0.09386298060417175,
      "learning_rate": 2.5972222222222226e-05,
      "loss": 0.0017,
      "step": 17300
    },
    {
      "epoch": 0.9616666666666667,
      "grad_norm": 0.2256792187690735,
      "learning_rate": 2.5958333333333335e-05,
      "loss": 0.0009,
      "step": 17310
    },
    {
      "epoch": 0.9622222222222222,
      "grad_norm": 0.2778034806251526,
      "learning_rate": 2.5944444444444444e-05,
      "loss": 0.0009,
      "step": 17320
    },
    {
      "epoch": 0.9627777777777777,
      "grad_norm": 0.13210290670394897,
      "learning_rate": 2.5930555555555556e-05,
      "loss": 0.0006,
      "step": 17330
    },
    {
      "epoch": 0.9633333333333334,
      "grad_norm": 0.2210373729467392,
      "learning_rate": 2.5916666666666665e-05,
      "loss": 0.001,
      "step": 17340
    },
    {
      "epoch": 0.9638888888888889,
      "grad_norm": 0.1345006227493286,
      "learning_rate": 2.590277777777778e-05,
      "loss": 0.0003,
      "step": 17350
    },
    {
      "epoch": 0.9644444444444444,
      "grad_norm": 0.12788644433021545,
      "learning_rate": 2.588888888888889e-05,
      "loss": 0.0006,
      "step": 17360
    },
    {
      "epoch": 0.965,
      "grad_norm": 0.0,
      "learning_rate": 2.5875e-05,
      "loss": 0.0006,
      "step": 17370
    },
    {
      "epoch": 0.9655555555555555,
      "grad_norm": 0.04519177973270416,
      "learning_rate": 2.5861111111111114e-05,
      "loss": 0.0004,
      "step": 17380
    },
    {
      "epoch": 0.9661111111111111,
      "grad_norm": 0.04533786699175835,
      "learning_rate": 2.5847222222222223e-05,
      "loss": 0.0009,
      "step": 17390
    },
    {
      "epoch": 0.9666666666666667,
      "grad_norm": 0.2798948884010315,
      "learning_rate": 2.5833333333333336e-05,
      "loss": 0.0003,
      "step": 17400
    },
    {
      "epoch": 0.9672222222222222,
      "grad_norm": 0.08719760924577713,
      "learning_rate": 2.5819444444444444e-05,
      "loss": 0.0006,
      "step": 17410
    },
    {
      "epoch": 0.9677777777777777,
      "grad_norm": 0.04640903323888779,
      "learning_rate": 2.5805555555555553e-05,
      "loss": 0.001,
      "step": 17420
    },
    {
      "epoch": 0.9683333333333334,
      "grad_norm": 0.0,
      "learning_rate": 2.579166666666667e-05,
      "loss": 0.0008,
      "step": 17430
    },
    {
      "epoch": 0.9688888888888889,
      "grad_norm": 0.08674997836351395,
      "learning_rate": 2.5777777777777778e-05,
      "loss": 0.0002,
      "step": 17440
    },
    {
      "epoch": 0.9694444444444444,
      "grad_norm": 0.0,
      "learning_rate": 2.5763888888888887e-05,
      "loss": 0.0006,
      "step": 17450
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.39788225293159485,
      "learning_rate": 2.5750000000000002e-05,
      "loss": 0.0007,
      "step": 17460
    },
    {
      "epoch": 0.9705555555555555,
      "grad_norm": 0.043704673647880554,
      "learning_rate": 2.573611111111111e-05,
      "loss": 0.0012,
      "step": 17470
    },
    {
      "epoch": 0.9711111111111111,
      "grad_norm": 0.09070831537246704,
      "learning_rate": 2.5722222222222224e-05,
      "loss": 0.0013,
      "step": 17480
    },
    {
      "epoch": 0.9716666666666667,
      "grad_norm": 0.0,
      "learning_rate": 2.5708333333333336e-05,
      "loss": 0.0009,
      "step": 17490
    },
    {
      "epoch": 0.9722222222222222,
      "grad_norm": 0.4189285635948181,
      "learning_rate": 2.5694444444444445e-05,
      "loss": 0.0007,
      "step": 17500
    },
    {
      "epoch": 0.9727777777777777,
      "grad_norm": 0.0481855608522892,
      "learning_rate": 2.5680555555555557e-05,
      "loss": 0.0009,
      "step": 17510
    },
    {
      "epoch": 0.9733333333333334,
      "grad_norm": 0.22476325929164886,
      "learning_rate": 2.5666666666666666e-05,
      "loss": 0.0019,
      "step": 17520
    },
    {
      "epoch": 0.9738888888888889,
      "grad_norm": 0.17827847599983215,
      "learning_rate": 2.565277777777778e-05,
      "loss": 0.0004,
      "step": 17530
    },
    {
      "epoch": 0.9744444444444444,
      "grad_norm": 0.04713942110538483,
      "learning_rate": 2.563888888888889e-05,
      "loss": 0.0005,
      "step": 17540
    },
    {
      "epoch": 0.975,
      "grad_norm": 0.17519895732402802,
      "learning_rate": 2.5625e-05,
      "loss": 0.001,
      "step": 17550
    },
    {
      "epoch": 0.9755555555555555,
      "grad_norm": 0.0,
      "learning_rate": 2.5611111111111115e-05,
      "loss": 0.0002,
      "step": 17560
    },
    {
      "epoch": 0.9761111111111112,
      "grad_norm": 0.0,
      "learning_rate": 2.5597222222222224e-05,
      "loss": 0.0008,
      "step": 17570
    },
    {
      "epoch": 0.9766666666666667,
      "grad_norm": 0.3063141703605652,
      "learning_rate": 2.5583333333333336e-05,
      "loss": 0.0013,
      "step": 17580
    },
    {
      "epoch": 0.9772222222222222,
      "grad_norm": 0.0,
      "learning_rate": 2.5569444444444445e-05,
      "loss": 0.0011,
      "step": 17590
    },
    {
      "epoch": 0.9777777777777777,
      "grad_norm": 0.023304183036088943,
      "learning_rate": 2.5555555555555554e-05,
      "loss": 0.0012,
      "step": 17600
    },
    {
      "epoch": 0.9783333333333334,
      "grad_norm": 0.0,
      "learning_rate": 2.554166666666667e-05,
      "loss": 0.001,
      "step": 17610
    },
    {
      "epoch": 0.9788888888888889,
      "grad_norm": 0.04529281333088875,
      "learning_rate": 2.552777777777778e-05,
      "loss": 0.0003,
      "step": 17620
    },
    {
      "epoch": 0.9794444444444445,
      "grad_norm": 0.21303406357765198,
      "learning_rate": 2.5513888888888894e-05,
      "loss": 0.0018,
      "step": 17630
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.10046879947185516,
      "learning_rate": 2.5500000000000003e-05,
      "loss": 0.0008,
      "step": 17640
    },
    {
      "epoch": 0.9805555555555555,
      "grad_norm": 0.0,
      "learning_rate": 2.5486111111111112e-05,
      "loss": 0.001,
      "step": 17650
    },
    {
      "epoch": 0.9811111111111112,
      "grad_norm": 0.13436321914196014,
      "learning_rate": 2.5472222222222224e-05,
      "loss": 0.0011,
      "step": 17660
    },
    {
      "epoch": 0.9816666666666667,
      "grad_norm": 0.0476568341255188,
      "learning_rate": 2.5458333333333333e-05,
      "loss": 0.0011,
      "step": 17670
    },
    {
      "epoch": 0.9822222222222222,
      "grad_norm": 0.0,
      "learning_rate": 2.5444444444444442e-05,
      "loss": 0.0009,
      "step": 17680
    },
    {
      "epoch": 0.9827777777777778,
      "grad_norm": 0.13161757588386536,
      "learning_rate": 2.5430555555555558e-05,
      "loss": 0.0003,
      "step": 17690
    },
    {
      "epoch": 0.9833333333333333,
      "grad_norm": 0.12130025774240494,
      "learning_rate": 2.5416666666666667e-05,
      "loss": 0.0003,
      "step": 17700
    },
    {
      "epoch": 0.9838888888888889,
      "grad_norm": 0.0,
      "learning_rate": 2.5402777777777782e-05,
      "loss": 0.0002,
      "step": 17710
    },
    {
      "epoch": 0.9844444444444445,
      "grad_norm": 0.0,
      "learning_rate": 2.538888888888889e-05,
      "loss": 0.0003,
      "step": 17720
    },
    {
      "epoch": 0.985,
      "grad_norm": 0.04841948300600052,
      "learning_rate": 2.5375e-05,
      "loss": 0.0012,
      "step": 17730
    },
    {
      "epoch": 0.9855555555555555,
      "grad_norm": 0.21449612081050873,
      "learning_rate": 2.5361111111111112e-05,
      "loss": 0.0006,
      "step": 17740
    },
    {
      "epoch": 0.9861111111111112,
      "grad_norm": 0.1710144728422165,
      "learning_rate": 2.534722222222222e-05,
      "loss": 0.0007,
      "step": 17750
    },
    {
      "epoch": 0.9866666666666667,
      "grad_norm": 0.13608914613723755,
      "learning_rate": 2.5333333333333337e-05,
      "loss": 0.0007,
      "step": 17760
    },
    {
      "epoch": 0.9872222222222222,
      "grad_norm": 0.0,
      "learning_rate": 2.5319444444444446e-05,
      "loss": 0.0006,
      "step": 17770
    },
    {
      "epoch": 0.9877777777777778,
      "grad_norm": 0.04758664220571518,
      "learning_rate": 2.5305555555555555e-05,
      "loss": 0.0008,
      "step": 17780
    },
    {
      "epoch": 0.9883333333333333,
      "grad_norm": 0.0,
      "learning_rate": 2.529166666666667e-05,
      "loss": 0.0004,
      "step": 17790
    },
    {
      "epoch": 0.9888888888888889,
      "grad_norm": 0.0,
      "learning_rate": 2.527777777777778e-05,
      "loss": 0.0006,
      "step": 17800
    },
    {
      "epoch": 0.9894444444444445,
      "grad_norm": 0.0,
      "learning_rate": 2.526388888888889e-05,
      "loss": 0.0008,
      "step": 17810
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.0,
      "learning_rate": 2.525e-05,
      "loss": 0.0001,
      "step": 17820
    },
    {
      "epoch": 0.9905555555555555,
      "grad_norm": 0.0,
      "learning_rate": 2.523611111111111e-05,
      "loss": 0.0004,
      "step": 17830
    },
    {
      "epoch": 0.9911111111111112,
      "grad_norm": 0.25099530816078186,
      "learning_rate": 2.5222222222222225e-05,
      "loss": 0.0011,
      "step": 17840
    },
    {
      "epoch": 0.9916666666666667,
      "grad_norm": 0.17008361220359802,
      "learning_rate": 2.5208333333333334e-05,
      "loss": 0.0004,
      "step": 17850
    },
    {
      "epoch": 0.9922222222222222,
      "grad_norm": 0.0,
      "learning_rate": 2.519444444444445e-05,
      "loss": 0.0004,
      "step": 17860
    },
    {
      "epoch": 0.9927777777777778,
      "grad_norm": 0.0,
      "learning_rate": 2.518055555555556e-05,
      "loss": 0.0005,
      "step": 17870
    },
    {
      "epoch": 0.9933333333333333,
      "grad_norm": 0.04491192847490311,
      "learning_rate": 2.5166666666666667e-05,
      "loss": 0.0002,
      "step": 17880
    },
    {
      "epoch": 0.9938888888888889,
      "grad_norm": 0.07783669233322144,
      "learning_rate": 2.515277777777778e-05,
      "loss": 0.0007,
      "step": 17890
    },
    {
      "epoch": 0.9944444444444445,
      "grad_norm": 0.0451861135661602,
      "learning_rate": 2.513888888888889e-05,
      "loss": 0.0006,
      "step": 17900
    },
    {
      "epoch": 0.995,
      "grad_norm": 0.17944994568824768,
      "learning_rate": 2.5124999999999997e-05,
      "loss": 0.0012,
      "step": 17910
    },
    {
      "epoch": 0.9955555555555555,
      "grad_norm": 0.15856413543224335,
      "learning_rate": 2.5111111111111113e-05,
      "loss": 0.0004,
      "step": 17920
    },
    {
      "epoch": 0.9961111111111111,
      "grad_norm": 0.0,
      "learning_rate": 2.5097222222222222e-05,
      "loss": 0.0012,
      "step": 17930
    },
    {
      "epoch": 0.9966666666666667,
      "grad_norm": 0.04763888195157051,
      "learning_rate": 2.5083333333333338e-05,
      "loss": 0.0013,
      "step": 17940
    },
    {
      "epoch": 0.9972222222222222,
      "grad_norm": 0.2057594656944275,
      "learning_rate": 2.5069444444444447e-05,
      "loss": 0.0008,
      "step": 17950
    },
    {
      "epoch": 0.9977777777777778,
      "grad_norm": 0.1818309873342514,
      "learning_rate": 2.5055555555555555e-05,
      "loss": 0.001,
      "step": 17960
    },
    {
      "epoch": 0.9983333333333333,
      "grad_norm": 0.05812196061015129,
      "learning_rate": 2.5041666666666668e-05,
      "loss": 0.0007,
      "step": 17970
    },
    {
      "epoch": 0.9988888888888889,
      "grad_norm": 0.35172417759895325,
      "learning_rate": 2.5027777777777777e-05,
      "loss": 0.0015,
      "step": 17980
    },
    {
      "epoch": 0.9994444444444445,
      "grad_norm": 0.23451241850852966,
      "learning_rate": 2.5013888888888892e-05,
      "loss": 0.0015,
      "step": 17990
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.05082099512219429,
      "learning_rate": 2.5e-05,
      "loss": 0.0013,
      "step": 18000
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.0009546108194626868,
      "eval_runtime": 10.5855,
      "eval_samples_per_second": 755.751,
      "eval_steps_per_second": 18.894,
      "step": 18000
    },
    {
      "epoch": 1.0005555555555556,
      "grad_norm": 0.05076887086033821,
      "learning_rate": 2.4986111111111113e-05,
      "loss": 0.0009,
      "step": 18010
    },
    {
      "epoch": 1.001111111111111,
      "grad_norm": 0.0,
      "learning_rate": 2.4972222222222226e-05,
      "loss": 0.001,
      "step": 18020
    },
    {
      "epoch": 1.0016666666666667,
      "grad_norm": 0.06619623303413391,
      "learning_rate": 2.4958333333333335e-05,
      "loss": 0.0006,
      "step": 18030
    },
    {
      "epoch": 1.0022222222222221,
      "grad_norm": 0.0,
      "learning_rate": 2.4944444444444447e-05,
      "loss": 0.0005,
      "step": 18040
    },
    {
      "epoch": 1.0027777777777778,
      "grad_norm": 0.26516011357307434,
      "learning_rate": 2.4930555555555556e-05,
      "loss": 0.0011,
      "step": 18050
    },
    {
      "epoch": 1.0033333333333334,
      "grad_norm": 0.09548506140708923,
      "learning_rate": 2.4916666666666668e-05,
      "loss": 0.0005,
      "step": 18060
    },
    {
      "epoch": 1.0038888888888888,
      "grad_norm": 0.18500916659832,
      "learning_rate": 2.4902777777777777e-05,
      "loss": 0.0006,
      "step": 18070
    },
    {
      "epoch": 1.0044444444444445,
      "grad_norm": 0.24220162630081177,
      "learning_rate": 2.488888888888889e-05,
      "loss": 0.0014,
      "step": 18080
    },
    {
      "epoch": 1.005,
      "grad_norm": 0.11822137981653214,
      "learning_rate": 2.4875e-05,
      "loss": 0.0012,
      "step": 18090
    },
    {
      "epoch": 1.0055555555555555,
      "grad_norm": 0.0,
      "learning_rate": 2.4861111111111114e-05,
      "loss": 0.0009,
      "step": 18100
    },
    {
      "epoch": 1.0061111111111112,
      "grad_norm": 0.049432795494794846,
      "learning_rate": 2.4847222222222226e-05,
      "loss": 0.0002,
      "step": 18110
    },
    {
      "epoch": 1.0066666666666666,
      "grad_norm": 0.18280227482318878,
      "learning_rate": 2.4833333333333335e-05,
      "loss": 0.0003,
      "step": 18120
    },
    {
      "epoch": 1.0072222222222222,
      "grad_norm": 0.09716203808784485,
      "learning_rate": 2.4819444444444444e-05,
      "loss": 0.0006,
      "step": 18130
    },
    {
      "epoch": 1.0077777777777779,
      "grad_norm": 0.08684178441762924,
      "learning_rate": 2.4805555555555556e-05,
      "loss": 0.0002,
      "step": 18140
    },
    {
      "epoch": 1.0083333333333333,
      "grad_norm": 0.0,
      "learning_rate": 2.479166666666667e-05,
      "loss": 0.001,
      "step": 18150
    },
    {
      "epoch": 1.008888888888889,
      "grad_norm": 0.2911006510257721,
      "learning_rate": 2.477777777777778e-05,
      "loss": 0.0002,
      "step": 18160
    },
    {
      "epoch": 1.0094444444444444,
      "grad_norm": 0.04492149502038956,
      "learning_rate": 2.476388888888889e-05,
      "loss": 0.0002,
      "step": 18170
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.07303619384765625,
      "learning_rate": 2.4750000000000002e-05,
      "loss": 0.001,
      "step": 18180
    },
    {
      "epoch": 1.0105555555555557,
      "grad_norm": 0.0,
      "learning_rate": 2.4736111111111114e-05,
      "loss": 0.001,
      "step": 18190
    },
    {
      "epoch": 1.011111111111111,
      "grad_norm": 0.16428032517433167,
      "learning_rate": 2.4722222222222223e-05,
      "loss": 0.0018,
      "step": 18200
    },
    {
      "epoch": 1.0116666666666667,
      "grad_norm": 0.09355498105287552,
      "learning_rate": 2.4708333333333332e-05,
      "loss": 0.0005,
      "step": 18210
    },
    {
      "epoch": 1.0122222222222221,
      "grad_norm": 0.04561895877122879,
      "learning_rate": 2.4694444444444444e-05,
      "loss": 0.0012,
      "step": 18220
    },
    {
      "epoch": 1.0127777777777778,
      "grad_norm": 0.08805886656045914,
      "learning_rate": 2.4680555555555557e-05,
      "loss": 0.0005,
      "step": 18230
    },
    {
      "epoch": 1.0133333333333334,
      "grad_norm": 0.7804283499717712,
      "learning_rate": 2.466666666666667e-05,
      "loss": 0.002,
      "step": 18240
    },
    {
      "epoch": 1.0138888888888888,
      "grad_norm": 0.0,
      "learning_rate": 2.465277777777778e-05,
      "loss": 0.0005,
      "step": 18250
    },
    {
      "epoch": 1.0144444444444445,
      "grad_norm": 0.240594744682312,
      "learning_rate": 2.463888888888889e-05,
      "loss": 0.0011,
      "step": 18260
    },
    {
      "epoch": 1.015,
      "grad_norm": 0.0,
      "learning_rate": 2.4625000000000002e-05,
      "loss": 0.0004,
      "step": 18270
    },
    {
      "epoch": 1.0155555555555555,
      "grad_norm": 0.21461068093776703,
      "learning_rate": 2.461111111111111e-05,
      "loss": 0.0006,
      "step": 18280
    },
    {
      "epoch": 1.0161111111111112,
      "grad_norm": 0.0,
      "learning_rate": 2.4597222222222223e-05,
      "loss": 0.0003,
      "step": 18290
    },
    {
      "epoch": 1.0166666666666666,
      "grad_norm": 0.37772136926651,
      "learning_rate": 2.4583333333333332e-05,
      "loss": 0.0004,
      "step": 18300
    },
    {
      "epoch": 1.0172222222222222,
      "grad_norm": 0.0,
      "learning_rate": 2.4569444444444445e-05,
      "loss": 0.0016,
      "step": 18310
    },
    {
      "epoch": 1.0177777777777777,
      "grad_norm": 0.047065749764442444,
      "learning_rate": 2.4555555555555557e-05,
      "loss": 0.0011,
      "step": 18320
    },
    {
      "epoch": 1.0183333333333333,
      "grad_norm": 0.23503731191158295,
      "learning_rate": 2.454166666666667e-05,
      "loss": 0.0005,
      "step": 18330
    },
    {
      "epoch": 1.018888888888889,
      "grad_norm": 0.0,
      "learning_rate": 2.452777777777778e-05,
      "loss": 0.0007,
      "step": 18340
    },
    {
      "epoch": 1.0194444444444444,
      "grad_norm": 0.10716881603002548,
      "learning_rate": 2.451388888888889e-05,
      "loss": 0.0004,
      "step": 18350
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.0,
      "learning_rate": 2.45e-05,
      "loss": 0.0002,
      "step": 18360
    },
    {
      "epoch": 1.0205555555555557,
      "grad_norm": 0.0,
      "learning_rate": 2.448611111111111e-05,
      "loss": 0.0015,
      "step": 18370
    },
    {
      "epoch": 1.021111111111111,
      "grad_norm": 0.08877435326576233,
      "learning_rate": 2.4472222222222224e-05,
      "loss": 0.001,
      "step": 18380
    },
    {
      "epoch": 1.0216666666666667,
      "grad_norm": 0.11542695015668869,
      "learning_rate": 2.4458333333333336e-05,
      "loss": 0.001,
      "step": 18390
    },
    {
      "epoch": 1.0222222222222221,
      "grad_norm": 0.4665954113006592,
      "learning_rate": 2.4444444444444445e-05,
      "loss": 0.0009,
      "step": 18400
    },
    {
      "epoch": 1.0227777777777778,
      "grad_norm": 0.19616560637950897,
      "learning_rate": 2.4430555555555557e-05,
      "loss": 0.0012,
      "step": 18410
    },
    {
      "epoch": 1.0233333333333334,
      "grad_norm": 0.16685982048511505,
      "learning_rate": 2.441666666666667e-05,
      "loss": 0.0007,
      "step": 18420
    },
    {
      "epoch": 1.0238888888888888,
      "grad_norm": 0.05080186575651169,
      "learning_rate": 2.440277777777778e-05,
      "loss": 0.0008,
      "step": 18430
    },
    {
      "epoch": 1.0244444444444445,
      "grad_norm": 0.20268754661083221,
      "learning_rate": 2.4388888888888887e-05,
      "loss": 0.0007,
      "step": 18440
    },
    {
      "epoch": 1.025,
      "grad_norm": 0.0,
      "learning_rate": 2.4375e-05,
      "loss": 0.0009,
      "step": 18450
    },
    {
      "epoch": 1.0255555555555556,
      "grad_norm": 0.0,
      "learning_rate": 2.4361111111111112e-05,
      "loss": 0.0008,
      "step": 18460
    },
    {
      "epoch": 1.0261111111111112,
      "grad_norm": 0.04393806308507919,
      "learning_rate": 2.4347222222222224e-05,
      "loss": 0.0004,
      "step": 18470
    },
    {
      "epoch": 1.0266666666666666,
      "grad_norm": 0.0,
      "learning_rate": 2.4333333333333336e-05,
      "loss": 0.0012,
      "step": 18480
    },
    {
      "epoch": 1.0272222222222223,
      "grad_norm": 0.0,
      "learning_rate": 2.4319444444444445e-05,
      "loss": 0.0001,
      "step": 18490
    },
    {
      "epoch": 1.0277777777777777,
      "grad_norm": 0.07036541402339935,
      "learning_rate": 2.4305555555555558e-05,
      "loss": 0.0008,
      "step": 18500
    },
    {
      "epoch": 1.0283333333333333,
      "grad_norm": 0.04096468165516853,
      "learning_rate": 2.4291666666666666e-05,
      "loss": 0.0002,
      "step": 18510
    },
    {
      "epoch": 1.028888888888889,
      "grad_norm": 0.1357942372560501,
      "learning_rate": 2.427777777777778e-05,
      "loss": 0.001,
      "step": 18520
    },
    {
      "epoch": 1.0294444444444444,
      "grad_norm": 0.09121164679527283,
      "learning_rate": 2.4263888888888888e-05,
      "loss": 0.0002,
      "step": 18530
    },
    {
      "epoch": 1.03,
      "grad_norm": 0.1135047897696495,
      "learning_rate": 2.425e-05,
      "loss": 0.0005,
      "step": 18540
    },
    {
      "epoch": 1.0305555555555554,
      "grad_norm": 0.0,
      "learning_rate": 2.4236111111111112e-05,
      "loss": 0.0019,
      "step": 18550
    },
    {
      "epoch": 1.031111111111111,
      "grad_norm": 0.4628669321537018,
      "learning_rate": 2.4222222222222224e-05,
      "loss": 0.0004,
      "step": 18560
    },
    {
      "epoch": 1.0316666666666667,
      "grad_norm": 0.17833681404590607,
      "learning_rate": 2.4208333333333337e-05,
      "loss": 0.0013,
      "step": 18570
    },
    {
      "epoch": 1.0322222222222222,
      "grad_norm": 0.0,
      "learning_rate": 2.4194444444444446e-05,
      "loss": 0.0008,
      "step": 18580
    },
    {
      "epoch": 1.0327777777777778,
      "grad_norm": 0.08852805942296982,
      "learning_rate": 2.4180555555555558e-05,
      "loss": 0.0004,
      "step": 18590
    },
    {
      "epoch": 1.0333333333333334,
      "grad_norm": 0.18432839214801788,
      "learning_rate": 2.4166666666666667e-05,
      "loss": 0.0013,
      "step": 18600
    },
    {
      "epoch": 1.0338888888888889,
      "grad_norm": 0.04366810619831085,
      "learning_rate": 2.415277777777778e-05,
      "loss": 0.0005,
      "step": 18610
    },
    {
      "epoch": 1.0344444444444445,
      "grad_norm": 0.22752591967582703,
      "learning_rate": 2.4138888888888888e-05,
      "loss": 0.001,
      "step": 18620
    },
    {
      "epoch": 1.035,
      "grad_norm": 0.0,
      "learning_rate": 2.4125e-05,
      "loss": 0.0004,
      "step": 18630
    },
    {
      "epoch": 1.0355555555555556,
      "grad_norm": 0.0,
      "learning_rate": 2.4111111111111113e-05,
      "loss": 0.0009,
      "step": 18640
    },
    {
      "epoch": 1.0361111111111112,
      "grad_norm": 0.0,
      "learning_rate": 2.4097222222222225e-05,
      "loss": 0.0007,
      "step": 18650
    },
    {
      "epoch": 1.0366666666666666,
      "grad_norm": 0.03394506499171257,
      "learning_rate": 2.4083333333333337e-05,
      "loss": 0.0007,
      "step": 18660
    },
    {
      "epoch": 1.0372222222222223,
      "grad_norm": 0.04720462113618851,
      "learning_rate": 2.4069444444444446e-05,
      "loss": 0.0012,
      "step": 18670
    },
    {
      "epoch": 1.0377777777777777,
      "grad_norm": 0.0,
      "learning_rate": 2.4055555555555555e-05,
      "loss": 0.0003,
      "step": 18680
    },
    {
      "epoch": 1.0383333333333333,
      "grad_norm": 0.053073301911354065,
      "learning_rate": 2.4041666666666667e-05,
      "loss": 0.0003,
      "step": 18690
    },
    {
      "epoch": 1.038888888888889,
      "grad_norm": 0.0,
      "learning_rate": 2.402777777777778e-05,
      "loss": 0.0004,
      "step": 18700
    },
    {
      "epoch": 1.0394444444444444,
      "grad_norm": 0.0,
      "learning_rate": 2.4013888888888892e-05,
      "loss": 0.0011,
      "step": 18710
    },
    {
      "epoch": 1.04,
      "grad_norm": 0.13853846490383148,
      "learning_rate": 2.4e-05,
      "loss": 0.0001,
      "step": 18720
    },
    {
      "epoch": 1.0405555555555555,
      "grad_norm": 0.25063008069992065,
      "learning_rate": 2.3986111111111113e-05,
      "loss": 0.0005,
      "step": 18730
    },
    {
      "epoch": 1.041111111111111,
      "grad_norm": 0.0,
      "learning_rate": 2.3972222222222225e-05,
      "loss": 0.0004,
      "step": 18740
    },
    {
      "epoch": 1.0416666666666667,
      "grad_norm": 0.0,
      "learning_rate": 2.3958333333333334e-05,
      "loss": 0.0005,
      "step": 18750
    },
    {
      "epoch": 1.0422222222222222,
      "grad_norm": 0.04729059711098671,
      "learning_rate": 2.3944444444444443e-05,
      "loss": 0.0005,
      "step": 18760
    },
    {
      "epoch": 1.0427777777777778,
      "grad_norm": 0.29271379113197327,
      "learning_rate": 2.3930555555555555e-05,
      "loss": 0.0006,
      "step": 18770
    },
    {
      "epoch": 1.0433333333333334,
      "grad_norm": 0.043680235743522644,
      "learning_rate": 2.3916666666666668e-05,
      "loss": 0.0015,
      "step": 18780
    },
    {
      "epoch": 1.0438888888888889,
      "grad_norm": 0.0,
      "learning_rate": 2.390277777777778e-05,
      "loss": 0.0007,
      "step": 18790
    },
    {
      "epoch": 1.0444444444444445,
      "grad_norm": 0.0,
      "learning_rate": 2.3888888888888892e-05,
      "loss": 0.0008,
      "step": 18800
    },
    {
      "epoch": 1.045,
      "grad_norm": 0.4146175980567932,
      "learning_rate": 2.3875e-05,
      "loss": 0.0004,
      "step": 18810
    },
    {
      "epoch": 1.0455555555555556,
      "grad_norm": 0.0,
      "learning_rate": 2.3861111111111113e-05,
      "loss": 0.0008,
      "step": 18820
    },
    {
      "epoch": 1.0461111111111112,
      "grad_norm": 0.053323958069086075,
      "learning_rate": 2.3847222222222222e-05,
      "loss": 0.0005,
      "step": 18830
    },
    {
      "epoch": 1.0466666666666666,
      "grad_norm": 0.20751099288463593,
      "learning_rate": 2.3833333333333334e-05,
      "loss": 0.0008,
      "step": 18840
    },
    {
      "epoch": 1.0472222222222223,
      "grad_norm": 0.03524494916200638,
      "learning_rate": 2.3819444444444443e-05,
      "loss": 0.0003,
      "step": 18850
    },
    {
      "epoch": 1.0477777777777777,
      "grad_norm": 0.0,
      "learning_rate": 2.3805555555555556e-05,
      "loss": 0.0001,
      "step": 18860
    },
    {
      "epoch": 1.0483333333333333,
      "grad_norm": 0.23214519023895264,
      "learning_rate": 2.3791666666666668e-05,
      "loss": 0.0003,
      "step": 18870
    },
    {
      "epoch": 1.048888888888889,
      "grad_norm": 0.0,
      "learning_rate": 2.377777777777778e-05,
      "loss": 0.0009,
      "step": 18880
    },
    {
      "epoch": 1.0494444444444444,
      "grad_norm": 0.09242428839206696,
      "learning_rate": 2.3763888888888892e-05,
      "loss": 0.0005,
      "step": 18890
    },
    {
      "epoch": 1.05,
      "grad_norm": 0.2849065959453583,
      "learning_rate": 2.375e-05,
      "loss": 0.0012,
      "step": 18900
    },
    {
      "epoch": 1.0505555555555555,
      "grad_norm": 0.09251735359430313,
      "learning_rate": 2.373611111111111e-05,
      "loss": 0.0016,
      "step": 18910
    },
    {
      "epoch": 1.051111111111111,
      "grad_norm": 0.19735826551914215,
      "learning_rate": 2.3722222222222222e-05,
      "loss": 0.0008,
      "step": 18920
    },
    {
      "epoch": 1.0516666666666667,
      "grad_norm": 0.16324733197689056,
      "learning_rate": 2.3708333333333335e-05,
      "loss": 0.0008,
      "step": 18930
    },
    {
      "epoch": 1.0522222222222222,
      "grad_norm": 0.0,
      "learning_rate": 2.3694444444444447e-05,
      "loss": 0.0011,
      "step": 18940
    },
    {
      "epoch": 1.0527777777777778,
      "grad_norm": 0.06675970554351807,
      "learning_rate": 2.3680555555555556e-05,
      "loss": 0.0007,
      "step": 18950
    },
    {
      "epoch": 1.0533333333333332,
      "grad_norm": 0.08896062523126602,
      "learning_rate": 2.3666666666666668e-05,
      "loss": 0.0008,
      "step": 18960
    },
    {
      "epoch": 1.0538888888888889,
      "grad_norm": 0.06652884930372238,
      "learning_rate": 2.365277777777778e-05,
      "loss": 0.0006,
      "step": 18970
    },
    {
      "epoch": 1.0544444444444445,
      "grad_norm": 0.10302284359931946,
      "learning_rate": 2.363888888888889e-05,
      "loss": 0.001,
      "step": 18980
    },
    {
      "epoch": 1.055,
      "grad_norm": 0.15405341982841492,
      "learning_rate": 2.3624999999999998e-05,
      "loss": 0.0006,
      "step": 18990
    },
    {
      "epoch": 1.0555555555555556,
      "grad_norm": 0.046509236097335815,
      "learning_rate": 2.361111111111111e-05,
      "loss": 0.0004,
      "step": 19000
    },
    {
      "epoch": 1.056111111111111,
      "grad_norm": 0.0,
      "learning_rate": 2.3597222222222223e-05,
      "loss": 0.0002,
      "step": 19010
    },
    {
      "epoch": 1.0566666666666666,
      "grad_norm": 0.1732475310564041,
      "learning_rate": 2.3583333333333335e-05,
      "loss": 0.0011,
      "step": 19020
    },
    {
      "epoch": 1.0572222222222223,
      "grad_norm": 0.08792757987976074,
      "learning_rate": 2.3569444444444447e-05,
      "loss": 0.0003,
      "step": 19030
    },
    {
      "epoch": 1.0577777777777777,
      "grad_norm": 0.0,
      "learning_rate": 2.3555555555555556e-05,
      "loss": 0.0005,
      "step": 19040
    },
    {
      "epoch": 1.0583333333333333,
      "grad_norm": 0.0,
      "learning_rate": 2.354166666666667e-05,
      "loss": 0.0006,
      "step": 19050
    },
    {
      "epoch": 1.058888888888889,
      "grad_norm": 0.22898295521736145,
      "learning_rate": 2.3527777777777777e-05,
      "loss": 0.0003,
      "step": 19060
    },
    {
      "epoch": 1.0594444444444444,
      "grad_norm": 0.04742398485541344,
      "learning_rate": 2.351388888888889e-05,
      "loss": 0.0004,
      "step": 19070
    },
    {
      "epoch": 1.06,
      "grad_norm": 0.09457249939441681,
      "learning_rate": 2.35e-05,
      "loss": 0.0008,
      "step": 19080
    },
    {
      "epoch": 1.0605555555555555,
      "grad_norm": 0.16611932218074799,
      "learning_rate": 2.348611111111111e-05,
      "loss": 0.0012,
      "step": 19090
    },
    {
      "epoch": 1.0611111111111111,
      "grad_norm": 0.0,
      "learning_rate": 2.3472222222222223e-05,
      "loss": 0.0005,
      "step": 19100
    },
    {
      "epoch": 1.0616666666666668,
      "grad_norm": 0.0943751335144043,
      "learning_rate": 2.3458333333333335e-05,
      "loss": 0.0006,
      "step": 19110
    },
    {
      "epoch": 1.0622222222222222,
      "grad_norm": 0.051183830946683884,
      "learning_rate": 2.3444444444444448e-05,
      "loss": 0.0006,
      "step": 19120
    },
    {
      "epoch": 1.0627777777777778,
      "grad_norm": 0.21046245098114014,
      "learning_rate": 2.3430555555555557e-05,
      "loss": 0.0017,
      "step": 19130
    },
    {
      "epoch": 1.0633333333333332,
      "grad_norm": 0.0,
      "learning_rate": 2.341666666666667e-05,
      "loss": 0.0002,
      "step": 19140
    },
    {
      "epoch": 1.0638888888888889,
      "grad_norm": 0.0,
      "learning_rate": 2.3402777777777778e-05,
      "loss": 0.0004,
      "step": 19150
    },
    {
      "epoch": 1.0644444444444445,
      "grad_norm": 0.09198225289583206,
      "learning_rate": 2.338888888888889e-05,
      "loss": 0.0024,
      "step": 19160
    },
    {
      "epoch": 1.065,
      "grad_norm": 0.08289562910795212,
      "learning_rate": 2.3375000000000002e-05,
      "loss": 0.0005,
      "step": 19170
    },
    {
      "epoch": 1.0655555555555556,
      "grad_norm": 0.37042275071144104,
      "learning_rate": 2.336111111111111e-05,
      "loss": 0.0005,
      "step": 19180
    },
    {
      "epoch": 1.066111111111111,
      "grad_norm": 0.0,
      "learning_rate": 2.3347222222222224e-05,
      "loss": 0.0003,
      "step": 19190
    },
    {
      "epoch": 1.0666666666666667,
      "grad_norm": 0.0,
      "learning_rate": 2.3333333333333336e-05,
      "loss": 0.0006,
      "step": 19200
    },
    {
      "epoch": 1.0672222222222223,
      "grad_norm": 0.0,
      "learning_rate": 2.3319444444444448e-05,
      "loss": 0.0001,
      "step": 19210
    },
    {
      "epoch": 1.0677777777777777,
      "grad_norm": 0.05001729726791382,
      "learning_rate": 2.3305555555555557e-05,
      "loss": 0.0006,
      "step": 19220
    },
    {
      "epoch": 1.0683333333333334,
      "grad_norm": 0.0,
      "learning_rate": 2.3291666666666666e-05,
      "loss": 0.0002,
      "step": 19230
    },
    {
      "epoch": 1.068888888888889,
      "grad_norm": 0.0,
      "learning_rate": 2.3277777777777778e-05,
      "loss": 0.0017,
      "step": 19240
    },
    {
      "epoch": 1.0694444444444444,
      "grad_norm": 0.07438786327838898,
      "learning_rate": 2.326388888888889e-05,
      "loss": 0.001,
      "step": 19250
    },
    {
      "epoch": 1.07,
      "grad_norm": 0.09537298232316971,
      "learning_rate": 2.3250000000000003e-05,
      "loss": 0.0007,
      "step": 19260
    },
    {
      "epoch": 1.0705555555555555,
      "grad_norm": 0.0,
      "learning_rate": 2.323611111111111e-05,
      "loss": 0.0014,
      "step": 19270
    },
    {
      "epoch": 1.0711111111111111,
      "grad_norm": 0.04756517708301544,
      "learning_rate": 2.3222222222222224e-05,
      "loss": 0.0005,
      "step": 19280
    },
    {
      "epoch": 1.0716666666666668,
      "grad_norm": 0.0,
      "learning_rate": 2.3208333333333336e-05,
      "loss": 0.0011,
      "step": 19290
    },
    {
      "epoch": 1.0722222222222222,
      "grad_norm": 0.1067296639084816,
      "learning_rate": 2.3194444444444445e-05,
      "loss": 0.0009,
      "step": 19300
    },
    {
      "epoch": 1.0727777777777778,
      "grad_norm": 0.16075387597084045,
      "learning_rate": 2.3180555555555554e-05,
      "loss": 0.0003,
      "step": 19310
    },
    {
      "epoch": 1.0733333333333333,
      "grad_norm": 0.060923706740140915,
      "learning_rate": 2.3166666666666666e-05,
      "loss": 0.0005,
      "step": 19320
    },
    {
      "epoch": 1.073888888888889,
      "grad_norm": 0.04817449674010277,
      "learning_rate": 2.315277777777778e-05,
      "loss": 0.0012,
      "step": 19330
    },
    {
      "epoch": 1.0744444444444445,
      "grad_norm": 0.04953276365995407,
      "learning_rate": 2.313888888888889e-05,
      "loss": 0.0009,
      "step": 19340
    },
    {
      "epoch": 1.075,
      "grad_norm": 0.03406708315014839,
      "learning_rate": 2.3125000000000003e-05,
      "loss": 0.0008,
      "step": 19350
    },
    {
      "epoch": 1.0755555555555556,
      "grad_norm": 0.0,
      "learning_rate": 2.3111111111111112e-05,
      "loss": 0.0014,
      "step": 19360
    },
    {
      "epoch": 1.076111111111111,
      "grad_norm": 0.051308490335941315,
      "learning_rate": 2.3097222222222224e-05,
      "loss": 0.0013,
      "step": 19370
    },
    {
      "epoch": 1.0766666666666667,
      "grad_norm": 0.2581102252006531,
      "learning_rate": 2.3083333333333333e-05,
      "loss": 0.0004,
      "step": 19380
    },
    {
      "epoch": 1.0772222222222223,
      "grad_norm": 0.0,
      "learning_rate": 2.3069444444444445e-05,
      "loss": 0.0006,
      "step": 19390
    },
    {
      "epoch": 1.0777777777777777,
      "grad_norm": 0.05538133531808853,
      "learning_rate": 2.3055555555555558e-05,
      "loss": 0.0017,
      "step": 19400
    },
    {
      "epoch": 1.0783333333333334,
      "grad_norm": 0.2498113363981247,
      "learning_rate": 2.3041666666666667e-05,
      "loss": 0.0008,
      "step": 19410
    },
    {
      "epoch": 1.0788888888888888,
      "grad_norm": 0.0,
      "learning_rate": 2.302777777777778e-05,
      "loss": 0.0002,
      "step": 19420
    },
    {
      "epoch": 1.0794444444444444,
      "grad_norm": 0.21630898118019104,
      "learning_rate": 2.301388888888889e-05,
      "loss": 0.0009,
      "step": 19430
    },
    {
      "epoch": 1.08,
      "grad_norm": 0.18602634966373444,
      "learning_rate": 2.3000000000000003e-05,
      "loss": 0.0005,
      "step": 19440
    },
    {
      "epoch": 1.0805555555555555,
      "grad_norm": 0.2916145920753479,
      "learning_rate": 2.2986111111111112e-05,
      "loss": 0.001,
      "step": 19450
    },
    {
      "epoch": 1.0811111111111111,
      "grad_norm": 0.0,
      "learning_rate": 2.297222222222222e-05,
      "loss": 0.0009,
      "step": 19460
    },
    {
      "epoch": 1.0816666666666666,
      "grad_norm": 0.0,
      "learning_rate": 2.2958333333333333e-05,
      "loss": 0.0014,
      "step": 19470
    },
    {
      "epoch": 1.0822222222222222,
      "grad_norm": 0.0896158367395401,
      "learning_rate": 2.2944444444444446e-05,
      "loss": 0.0007,
      "step": 19480
    },
    {
      "epoch": 1.0827777777777778,
      "grad_norm": 0.0,
      "learning_rate": 2.2930555555555558e-05,
      "loss": 0.0006,
      "step": 19490
    },
    {
      "epoch": 1.0833333333333333,
      "grad_norm": 0.1943357139825821,
      "learning_rate": 2.2916666666666667e-05,
      "loss": 0.0002,
      "step": 19500
    },
    {
      "epoch": 1.083888888888889,
      "grad_norm": 0.0,
      "learning_rate": 2.290277777777778e-05,
      "loss": 0.0003,
      "step": 19510
    },
    {
      "epoch": 1.0844444444444445,
      "grad_norm": 0.0,
      "learning_rate": 2.288888888888889e-05,
      "loss": 0.0004,
      "step": 19520
    },
    {
      "epoch": 1.085,
      "grad_norm": 0.1021878644824028,
      "learning_rate": 2.2875e-05,
      "loss": 0.0019,
      "step": 19530
    },
    {
      "epoch": 1.0855555555555556,
      "grad_norm": 0.18135735392570496,
      "learning_rate": 2.286111111111111e-05,
      "loss": 0.0012,
      "step": 19540
    },
    {
      "epoch": 1.086111111111111,
      "grad_norm": 0.17603299021720886,
      "learning_rate": 2.284722222222222e-05,
      "loss": 0.0012,
      "step": 19550
    },
    {
      "epoch": 1.0866666666666667,
      "grad_norm": 0.0,
      "learning_rate": 2.2833333333333334e-05,
      "loss": 0.0006,
      "step": 19560
    },
    {
      "epoch": 1.0872222222222223,
      "grad_norm": 0.040185295045375824,
      "learning_rate": 2.2819444444444446e-05,
      "loss": 0.001,
      "step": 19570
    },
    {
      "epoch": 1.0877777777777777,
      "grad_norm": 0.0,
      "learning_rate": 2.280555555555556e-05,
      "loss": 0.0009,
      "step": 19580
    },
    {
      "epoch": 1.0883333333333334,
      "grad_norm": 0.5695158839225769,
      "learning_rate": 2.2791666666666667e-05,
      "loss": 0.0012,
      "step": 19590
    },
    {
      "epoch": 1.0888888888888888,
      "grad_norm": 0.05642584711313248,
      "learning_rate": 2.277777777777778e-05,
      "loss": 0.001,
      "step": 19600
    },
    {
      "epoch": 1.0894444444444444,
      "grad_norm": 0.03760606795549393,
      "learning_rate": 2.2763888888888892e-05,
      "loss": 0.0011,
      "step": 19610
    },
    {
      "epoch": 1.09,
      "grad_norm": 0.21989668905735016,
      "learning_rate": 2.275e-05,
      "loss": 0.0009,
      "step": 19620
    },
    {
      "epoch": 1.0905555555555555,
      "grad_norm": 0.16266889870166779,
      "learning_rate": 2.2736111111111113e-05,
      "loss": 0.0009,
      "step": 19630
    },
    {
      "epoch": 1.0911111111111111,
      "grad_norm": 0.0,
      "learning_rate": 2.2722222222222222e-05,
      "loss": 0.0005,
      "step": 19640
    },
    {
      "epoch": 1.0916666666666666,
      "grad_norm": 0.0884941965341568,
      "learning_rate": 2.2708333333333334e-05,
      "loss": 0.0005,
      "step": 19650
    },
    {
      "epoch": 1.0922222222222222,
      "grad_norm": 0.0,
      "learning_rate": 2.2694444444444446e-05,
      "loss": 0.0004,
      "step": 19660
    },
    {
      "epoch": 1.0927777777777778,
      "grad_norm": 0.12772592902183533,
      "learning_rate": 2.268055555555556e-05,
      "loss": 0.0008,
      "step": 19670
    },
    {
      "epoch": 1.0933333333333333,
      "grad_norm": 0.0,
      "learning_rate": 2.2666666666666668e-05,
      "loss": 0.001,
      "step": 19680
    },
    {
      "epoch": 1.093888888888889,
      "grad_norm": 0.0,
      "learning_rate": 2.265277777777778e-05,
      "loss": 0.0003,
      "step": 19690
    },
    {
      "epoch": 1.0944444444444446,
      "grad_norm": 0.049630943685770035,
      "learning_rate": 2.263888888888889e-05,
      "loss": 0.0005,
      "step": 19700
    },
    {
      "epoch": 1.095,
      "grad_norm": 0.0,
      "learning_rate": 2.2625e-05,
      "loss": 0.001,
      "step": 19710
    },
    {
      "epoch": 1.0955555555555556,
      "grad_norm": 0.19445686042308807,
      "learning_rate": 2.2611111111111113e-05,
      "loss": 0.0003,
      "step": 19720
    },
    {
      "epoch": 1.096111111111111,
      "grad_norm": 0.06829486787319183,
      "learning_rate": 2.2597222222222222e-05,
      "loss": 0.0008,
      "step": 19730
    },
    {
      "epoch": 1.0966666666666667,
      "grad_norm": 0.10415974259376526,
      "learning_rate": 2.2583333333333335e-05,
      "loss": 0.0013,
      "step": 19740
    },
    {
      "epoch": 1.0972222222222223,
      "grad_norm": 0.048516467213630676,
      "learning_rate": 2.2569444444444447e-05,
      "loss": 0.0008,
      "step": 19750
    },
    {
      "epoch": 1.0977777777777777,
      "grad_norm": 0.0,
      "learning_rate": 2.255555555555556e-05,
      "loss": 0.0008,
      "step": 19760
    },
    {
      "epoch": 1.0983333333333334,
      "grad_norm": 0.2327624261379242,
      "learning_rate": 2.2541666666666668e-05,
      "loss": 0.0017,
      "step": 19770
    },
    {
      "epoch": 1.0988888888888888,
      "grad_norm": 0.10481048375368118,
      "learning_rate": 2.2527777777777777e-05,
      "loss": 0.0021,
      "step": 19780
    },
    {
      "epoch": 1.0994444444444444,
      "grad_norm": 0.2835448384284973,
      "learning_rate": 2.251388888888889e-05,
      "loss": 0.0008,
      "step": 19790
    },
    {
      "epoch": 1.1,
      "grad_norm": 0.0,
      "learning_rate": 2.25e-05,
      "loss": 0.0009,
      "step": 19800
    },
    {
      "epoch": 1.1005555555555555,
      "grad_norm": 0.05592603236436844,
      "learning_rate": 2.2486111111111114e-05,
      "loss": 0.0004,
      "step": 19810
    },
    {
      "epoch": 1.1011111111111112,
      "grad_norm": 0.0289728082716465,
      "learning_rate": 2.2472222222222223e-05,
      "loss": 0.0008,
      "step": 19820
    },
    {
      "epoch": 1.1016666666666666,
      "grad_norm": 0.059903278946876526,
      "learning_rate": 2.2458333333333335e-05,
      "loss": 0.0004,
      "step": 19830
    },
    {
      "epoch": 1.1022222222222222,
      "grad_norm": 0.0,
      "learning_rate": 2.2444444444444447e-05,
      "loss": 0.0004,
      "step": 19840
    },
    {
      "epoch": 1.1027777777777779,
      "grad_norm": 0.0,
      "learning_rate": 2.2430555555555556e-05,
      "loss": 0.0004,
      "step": 19850
    },
    {
      "epoch": 1.1033333333333333,
      "grad_norm": 0.0,
      "learning_rate": 2.2416666666666665e-05,
      "loss": 0.0005,
      "step": 19860
    },
    {
      "epoch": 1.103888888888889,
      "grad_norm": 0.04566206410527229,
      "learning_rate": 2.2402777777777777e-05,
      "loss": 0.0011,
      "step": 19870
    },
    {
      "epoch": 1.1044444444444443,
      "grad_norm": 0.04819539561867714,
      "learning_rate": 2.238888888888889e-05,
      "loss": 0.0007,
      "step": 19880
    },
    {
      "epoch": 1.105,
      "grad_norm": 0.04577154666185379,
      "learning_rate": 2.2375000000000002e-05,
      "loss": 0.0009,
      "step": 19890
    },
    {
      "epoch": 1.1055555555555556,
      "grad_norm": 0.2829681634902954,
      "learning_rate": 2.2361111111111114e-05,
      "loss": 0.0017,
      "step": 19900
    },
    {
      "epoch": 1.106111111111111,
      "grad_norm": 0.0,
      "learning_rate": 2.2347222222222223e-05,
      "loss": 0.0006,
      "step": 19910
    },
    {
      "epoch": 1.1066666666666667,
      "grad_norm": 0.2787327170372009,
      "learning_rate": 2.2333333333333335e-05,
      "loss": 0.0009,
      "step": 19920
    },
    {
      "epoch": 1.107222222222222,
      "grad_norm": 0.0470736138522625,
      "learning_rate": 2.2319444444444444e-05,
      "loss": 0.0008,
      "step": 19930
    },
    {
      "epoch": 1.1077777777777778,
      "grad_norm": 0.04588742554187775,
      "learning_rate": 2.2305555555555556e-05,
      "loss": 0.0004,
      "step": 19940
    },
    {
      "epoch": 1.1083333333333334,
      "grad_norm": 0.0,
      "learning_rate": 2.229166666666667e-05,
      "loss": 0.0005,
      "step": 19950
    },
    {
      "epoch": 1.1088888888888888,
      "grad_norm": 0.3007849454879761,
      "learning_rate": 2.2277777777777778e-05,
      "loss": 0.0007,
      "step": 19960
    },
    {
      "epoch": 1.1094444444444445,
      "grad_norm": 0.04463958367705345,
      "learning_rate": 2.226388888888889e-05,
      "loss": 0.0008,
      "step": 19970
    },
    {
      "epoch": 1.11,
      "grad_norm": 0.04745053872466087,
      "learning_rate": 2.2250000000000002e-05,
      "loss": 0.0012,
      "step": 19980
    },
    {
      "epoch": 1.1105555555555555,
      "grad_norm": 0.0879841074347496,
      "learning_rate": 2.2236111111111114e-05,
      "loss": 0.0003,
      "step": 19990
    },
    {
      "epoch": 1.1111111111111112,
      "grad_norm": 0.046974945813417435,
      "learning_rate": 2.2222222222222223e-05,
      "loss": 0.0017,
      "step": 20000
    },
    {
      "epoch": 1.1116666666666666,
      "grad_norm": 0.0,
      "learning_rate": 2.2208333333333332e-05,
      "loss": 0.0006,
      "step": 20010
    },
    {
      "epoch": 1.1122222222222222,
      "grad_norm": 0.09039484709501266,
      "learning_rate": 2.2194444444444444e-05,
      "loss": 0.0005,
      "step": 20020
    },
    {
      "epoch": 1.1127777777777779,
      "grad_norm": 0.0,
      "learning_rate": 2.2180555555555557e-05,
      "loss": 0.0007,
      "step": 20030
    },
    {
      "epoch": 1.1133333333333333,
      "grad_norm": 0.044854238629341125,
      "learning_rate": 2.216666666666667e-05,
      "loss": 0.0004,
      "step": 20040
    },
    {
      "epoch": 1.113888888888889,
      "grad_norm": 0.1879747062921524,
      "learning_rate": 2.2152777777777778e-05,
      "loss": 0.0008,
      "step": 20050
    },
    {
      "epoch": 1.1144444444444443,
      "grad_norm": 0.08966754376888275,
      "learning_rate": 2.213888888888889e-05,
      "loss": 0.0002,
      "step": 20060
    },
    {
      "epoch": 1.115,
      "grad_norm": 0.0,
      "learning_rate": 2.2125000000000002e-05,
      "loss": 0.0005,
      "step": 20070
    },
    {
      "epoch": 1.1155555555555556,
      "grad_norm": 0.04729349538683891,
      "learning_rate": 2.211111111111111e-05,
      "loss": 0.0005,
      "step": 20080
    },
    {
      "epoch": 1.116111111111111,
      "grad_norm": 0.04634542763233185,
      "learning_rate": 2.209722222222222e-05,
      "loss": 0.001,
      "step": 20090
    },
    {
      "epoch": 1.1166666666666667,
      "grad_norm": 0.11671940237283707,
      "learning_rate": 2.2083333333333333e-05,
      "loss": 0.0009,
      "step": 20100
    },
    {
      "epoch": 1.1172222222222223,
      "grad_norm": 0.0,
      "learning_rate": 2.2069444444444445e-05,
      "loss": 0.0004,
      "step": 20110
    },
    {
      "epoch": 1.1177777777777778,
      "grad_norm": 0.06585097312927246,
      "learning_rate": 2.2055555555555557e-05,
      "loss": 0.0005,
      "step": 20120
    },
    {
      "epoch": 1.1183333333333334,
      "grad_norm": 0.0,
      "learning_rate": 2.204166666666667e-05,
      "loss": 0.0014,
      "step": 20130
    },
    {
      "epoch": 1.1188888888888888,
      "grad_norm": 0.16821955144405365,
      "learning_rate": 2.2027777777777778e-05,
      "loss": 0.0005,
      "step": 20140
    },
    {
      "epoch": 1.1194444444444445,
      "grad_norm": 0.04654055833816528,
      "learning_rate": 2.201388888888889e-05,
      "loss": 0.0017,
      "step": 20150
    },
    {
      "epoch": 1.12,
      "grad_norm": 0.04581144452095032,
      "learning_rate": 2.2000000000000003e-05,
      "loss": 0.0006,
      "step": 20160
    },
    {
      "epoch": 1.1205555555555555,
      "grad_norm": 0.04442264884710312,
      "learning_rate": 2.1986111111111112e-05,
      "loss": 0.0008,
      "step": 20170
    },
    {
      "epoch": 1.1211111111111112,
      "grad_norm": 0.027469104155898094,
      "learning_rate": 2.1972222222222224e-05,
      "loss": 0.0012,
      "step": 20180
    },
    {
      "epoch": 1.1216666666666666,
      "grad_norm": 0.2925204038619995,
      "learning_rate": 2.1958333333333333e-05,
      "loss": 0.0013,
      "step": 20190
    },
    {
      "epoch": 1.1222222222222222,
      "grad_norm": 0.0,
      "learning_rate": 2.1944444444444445e-05,
      "loss": 0.0005,
      "step": 20200
    },
    {
      "epoch": 1.1227777777777779,
      "grad_norm": 0.04449622705578804,
      "learning_rate": 2.1930555555555557e-05,
      "loss": 0.0007,
      "step": 20210
    },
    {
      "epoch": 1.1233333333333333,
      "grad_norm": 0.048677168786525726,
      "learning_rate": 2.191666666666667e-05,
      "loss": 0.0014,
      "step": 20220
    },
    {
      "epoch": 1.123888888888889,
      "grad_norm": 0.1361863762140274,
      "learning_rate": 2.190277777777778e-05,
      "loss": 0.0016,
      "step": 20230
    },
    {
      "epoch": 1.1244444444444444,
      "grad_norm": 0.05243312940001488,
      "learning_rate": 2.188888888888889e-05,
      "loss": 0.0015,
      "step": 20240
    },
    {
      "epoch": 1.125,
      "grad_norm": 0.0,
      "learning_rate": 2.1875e-05,
      "loss": 0.0004,
      "step": 20250
    },
    {
      "epoch": 1.1255555555555556,
      "grad_norm": 0.14292433857917786,
      "learning_rate": 2.1861111111111112e-05,
      "loss": 0.0017,
      "step": 20260
    },
    {
      "epoch": 1.126111111111111,
      "grad_norm": 0.04515092819929123,
      "learning_rate": 2.1847222222222224e-05,
      "loss": 0.0004,
      "step": 20270
    },
    {
      "epoch": 1.1266666666666667,
      "grad_norm": 0.2563917636871338,
      "learning_rate": 2.1833333333333333e-05,
      "loss": 0.0003,
      "step": 20280
    },
    {
      "epoch": 1.1272222222222221,
      "grad_norm": 0.06654630601406097,
      "learning_rate": 2.1819444444444446e-05,
      "loss": 0.0015,
      "step": 20290
    },
    {
      "epoch": 1.1277777777777778,
      "grad_norm": 0.0,
      "learning_rate": 2.1805555555555558e-05,
      "loss": 0.0015,
      "step": 20300
    },
    {
      "epoch": 1.1283333333333334,
      "grad_norm": 0.19719713926315308,
      "learning_rate": 2.179166666666667e-05,
      "loss": 0.0009,
      "step": 20310
    },
    {
      "epoch": 1.1288888888888888,
      "grad_norm": 0.04973456263542175,
      "learning_rate": 2.177777777777778e-05,
      "loss": 0.0006,
      "step": 20320
    },
    {
      "epoch": 1.1294444444444445,
      "grad_norm": 0.28788766264915466,
      "learning_rate": 2.1763888888888888e-05,
      "loss": 0.0006,
      "step": 20330
    },
    {
      "epoch": 1.13,
      "grad_norm": 0.20983794331550598,
      "learning_rate": 2.175e-05,
      "loss": 0.0015,
      "step": 20340
    },
    {
      "epoch": 1.1305555555555555,
      "grad_norm": 0.04587801918387413,
      "learning_rate": 2.1736111111111112e-05,
      "loss": 0.0015,
      "step": 20350
    },
    {
      "epoch": 1.1311111111111112,
      "grad_norm": 0.4147297143936157,
      "learning_rate": 2.1722222222222225e-05,
      "loss": 0.0009,
      "step": 20360
    },
    {
      "epoch": 1.1316666666666666,
      "grad_norm": 0.021410329267382622,
      "learning_rate": 2.1708333333333334e-05,
      "loss": 0.001,
      "step": 20370
    },
    {
      "epoch": 1.1322222222222222,
      "grad_norm": 0.16329163312911987,
      "learning_rate": 2.1694444444444446e-05,
      "loss": 0.001,
      "step": 20380
    },
    {
      "epoch": 1.1327777777777777,
      "grad_norm": 0.1954677551984787,
      "learning_rate": 2.1680555555555558e-05,
      "loss": 0.0011,
      "step": 20390
    },
    {
      "epoch": 1.1333333333333333,
      "grad_norm": 0.20545172691345215,
      "learning_rate": 2.1666666666666667e-05,
      "loss": 0.0004,
      "step": 20400
    },
    {
      "epoch": 1.133888888888889,
      "grad_norm": 0.26610448956489563,
      "learning_rate": 2.165277777777778e-05,
      "loss": 0.0006,
      "step": 20410
    },
    {
      "epoch": 1.1344444444444444,
      "grad_norm": 0.0,
      "learning_rate": 2.1638888888888888e-05,
      "loss": 0.0016,
      "step": 20420
    },
    {
      "epoch": 1.135,
      "grad_norm": 0.05263806879520416,
      "learning_rate": 2.1625e-05,
      "loss": 0.0005,
      "step": 20430
    },
    {
      "epoch": 1.1355555555555557,
      "grad_norm": 0.0,
      "learning_rate": 2.1611111111111113e-05,
      "loss": 0.0005,
      "step": 20440
    },
    {
      "epoch": 1.136111111111111,
      "grad_norm": 0.20684948563575745,
      "learning_rate": 2.1597222222222225e-05,
      "loss": 0.0006,
      "step": 20450
    },
    {
      "epoch": 1.1366666666666667,
      "grad_norm": 0.0,
      "learning_rate": 2.1583333333333334e-05,
      "loss": 0.0008,
      "step": 20460
    },
    {
      "epoch": 1.1372222222222221,
      "grad_norm": 0.04511968791484833,
      "learning_rate": 2.1569444444444446e-05,
      "loss": 0.0006,
      "step": 20470
    },
    {
      "epoch": 1.1377777777777778,
      "grad_norm": 0.013115258887410164,
      "learning_rate": 2.1555555555555555e-05,
      "loss": 0.0008,
      "step": 20480
    },
    {
      "epoch": 1.1383333333333334,
      "grad_norm": 0.0,
      "learning_rate": 2.1541666666666667e-05,
      "loss": 0.0006,
      "step": 20490
    },
    {
      "epoch": 1.1388888888888888,
      "grad_norm": 0.0,
      "learning_rate": 2.152777777777778e-05,
      "loss": 0.0005,
      "step": 20500
    },
    {
      "epoch": 1.1394444444444445,
      "grad_norm": 0.11689513921737671,
      "learning_rate": 2.151388888888889e-05,
      "loss": 0.0002,
      "step": 20510
    },
    {
      "epoch": 1.1400000000000001,
      "grad_norm": 0.04690040275454521,
      "learning_rate": 2.15e-05,
      "loss": 0.001,
      "step": 20520
    },
    {
      "epoch": 1.1405555555555555,
      "grad_norm": 0.13571205735206604,
      "learning_rate": 2.1486111111111113e-05,
      "loss": 0.0005,
      "step": 20530
    },
    {
      "epoch": 1.1411111111111112,
      "grad_norm": 0.0958845317363739,
      "learning_rate": 2.1472222222222225e-05,
      "loss": 0.0006,
      "step": 20540
    },
    {
      "epoch": 1.1416666666666666,
      "grad_norm": 0.04613981768488884,
      "learning_rate": 2.1458333333333334e-05,
      "loss": 0.0003,
      "step": 20550
    },
    {
      "epoch": 1.1422222222222222,
      "grad_norm": 0.0,
      "learning_rate": 2.1444444444444443e-05,
      "loss": 0.0011,
      "step": 20560
    },
    {
      "epoch": 1.142777777777778,
      "grad_norm": 0.0,
      "learning_rate": 2.1430555555555555e-05,
      "loss": 0.0004,
      "step": 20570
    },
    {
      "epoch": 1.1433333333333333,
      "grad_norm": 0.04418826103210449,
      "learning_rate": 2.1416666666666668e-05,
      "loss": 0.0008,
      "step": 20580
    },
    {
      "epoch": 1.143888888888889,
      "grad_norm": 0.3130840063095093,
      "learning_rate": 2.140277777777778e-05,
      "loss": 0.0006,
      "step": 20590
    },
    {
      "epoch": 1.1444444444444444,
      "grad_norm": 0.14678561687469482,
      "learning_rate": 2.138888888888889e-05,
      "loss": 0.0011,
      "step": 20600
    },
    {
      "epoch": 1.145,
      "grad_norm": 0.0546862818300724,
      "learning_rate": 2.1375e-05,
      "loss": 0.0013,
      "step": 20610
    },
    {
      "epoch": 1.1455555555555557,
      "grad_norm": 0.046815112233161926,
      "learning_rate": 2.1361111111111113e-05,
      "loss": 0.001,
      "step": 20620
    },
    {
      "epoch": 1.146111111111111,
      "grad_norm": 0.0,
      "learning_rate": 2.1347222222222222e-05,
      "loss": 0.0006,
      "step": 20630
    },
    {
      "epoch": 1.1466666666666667,
      "grad_norm": 0.14378319680690765,
      "learning_rate": 2.1333333333333335e-05,
      "loss": 0.0008,
      "step": 20640
    },
    {
      "epoch": 1.1472222222222221,
      "grad_norm": 0.36172914505004883,
      "learning_rate": 2.1319444444444444e-05,
      "loss": 0.0004,
      "step": 20650
    },
    {
      "epoch": 1.1477777777777778,
      "grad_norm": 0.1692393720149994,
      "learning_rate": 2.1305555555555556e-05,
      "loss": 0.0006,
      "step": 20660
    },
    {
      "epoch": 1.1483333333333334,
      "grad_norm": 0.18061082065105438,
      "learning_rate": 2.1291666666666668e-05,
      "loss": 0.0007,
      "step": 20670
    },
    {
      "epoch": 1.1488888888888888,
      "grad_norm": 0.0,
      "learning_rate": 2.127777777777778e-05,
      "loss": 0.0002,
      "step": 20680
    },
    {
      "epoch": 1.1494444444444445,
      "grad_norm": 0.0,
      "learning_rate": 2.126388888888889e-05,
      "loss": 0.0006,
      "step": 20690
    },
    {
      "epoch": 1.15,
      "grad_norm": 0.6048929691314697,
      "learning_rate": 2.125e-05,
      "loss": 0.0007,
      "step": 20700
    },
    {
      "epoch": 1.1505555555555556,
      "grad_norm": 0.0739964097738266,
      "learning_rate": 2.1236111111111114e-05,
      "loss": 0.0009,
      "step": 20710
    },
    {
      "epoch": 1.1511111111111112,
      "grad_norm": 0.28410282731056213,
      "learning_rate": 2.1222222222222223e-05,
      "loss": 0.0014,
      "step": 20720
    },
    {
      "epoch": 1.1516666666666666,
      "grad_norm": 0.0,
      "learning_rate": 2.1208333333333335e-05,
      "loss": 0.001,
      "step": 20730
    },
    {
      "epoch": 1.1522222222222223,
      "grad_norm": 0.267192542552948,
      "learning_rate": 2.1194444444444444e-05,
      "loss": 0.0011,
      "step": 20740
    },
    {
      "epoch": 1.1527777777777777,
      "grad_norm": 0.0,
      "learning_rate": 2.1180555555555556e-05,
      "loss": 0.0,
      "step": 20750
    },
    {
      "epoch": 1.1533333333333333,
      "grad_norm": 0.0,
      "learning_rate": 2.116666666666667e-05,
      "loss": 0.0004,
      "step": 20760
    },
    {
      "epoch": 1.153888888888889,
      "grad_norm": 0.0,
      "learning_rate": 2.115277777777778e-05,
      "loss": 0.0012,
      "step": 20770
    },
    {
      "epoch": 1.1544444444444444,
      "grad_norm": 0.11707025021314621,
      "learning_rate": 2.113888888888889e-05,
      "loss": 0.001,
      "step": 20780
    },
    {
      "epoch": 1.155,
      "grad_norm": 0.20535598695278168,
      "learning_rate": 2.1125000000000002e-05,
      "loss": 0.0011,
      "step": 20790
    },
    {
      "epoch": 1.1555555555555554,
      "grad_norm": 0.0,
      "learning_rate": 2.111111111111111e-05,
      "loss": 0.0013,
      "step": 20800
    },
    {
      "epoch": 1.156111111111111,
      "grad_norm": 0.16739557683467865,
      "learning_rate": 2.1097222222222223e-05,
      "loss": 0.0007,
      "step": 20810
    },
    {
      "epoch": 1.1566666666666667,
      "grad_norm": 0.04764707759022713,
      "learning_rate": 2.1083333333333335e-05,
      "loss": 0.0009,
      "step": 20820
    },
    {
      "epoch": 1.1572222222222222,
      "grad_norm": 0.0,
      "learning_rate": 2.1069444444444444e-05,
      "loss": 0.0007,
      "step": 20830
    },
    {
      "epoch": 1.1577777777777778,
      "grad_norm": 0.27184081077575684,
      "learning_rate": 2.1055555555555556e-05,
      "loss": 0.0003,
      "step": 20840
    },
    {
      "epoch": 1.1583333333333332,
      "grad_norm": 0.0,
      "learning_rate": 2.104166666666667e-05,
      "loss": 0.0014,
      "step": 20850
    },
    {
      "epoch": 1.1588888888888889,
      "grad_norm": 0.0,
      "learning_rate": 2.102777777777778e-05,
      "loss": 0.0008,
      "step": 20860
    },
    {
      "epoch": 1.1594444444444445,
      "grad_norm": 0.0,
      "learning_rate": 2.101388888888889e-05,
      "loss": 0.0011,
      "step": 20870
    },
    {
      "epoch": 1.16,
      "grad_norm": 0.09059072285890579,
      "learning_rate": 2.1e-05,
      "loss": 0.0007,
      "step": 20880
    },
    {
      "epoch": 1.1605555555555556,
      "grad_norm": 0.10372345894575119,
      "learning_rate": 2.098611111111111e-05,
      "loss": 0.0003,
      "step": 20890
    },
    {
      "epoch": 1.1611111111111112,
      "grad_norm": 0.09388581663370132,
      "learning_rate": 2.0972222222222223e-05,
      "loss": 0.0008,
      "step": 20900
    },
    {
      "epoch": 1.1616666666666666,
      "grad_norm": 0.04375074803829193,
      "learning_rate": 2.0958333333333336e-05,
      "loss": 0.0007,
      "step": 20910
    },
    {
      "epoch": 1.1622222222222223,
      "grad_norm": 0.0,
      "learning_rate": 2.0944444444444445e-05,
      "loss": 0.0006,
      "step": 20920
    },
    {
      "epoch": 1.1627777777777777,
      "grad_norm": 0.04852612689137459,
      "learning_rate": 2.0930555555555557e-05,
      "loss": 0.0003,
      "step": 20930
    },
    {
      "epoch": 1.1633333333333333,
      "grad_norm": 0.1666252613067627,
      "learning_rate": 2.091666666666667e-05,
      "loss": 0.0003,
      "step": 20940
    },
    {
      "epoch": 1.163888888888889,
      "grad_norm": 0.20251035690307617,
      "learning_rate": 2.0902777777777778e-05,
      "loss": 0.0008,
      "step": 20950
    },
    {
      "epoch": 1.1644444444444444,
      "grad_norm": 0.09551599621772766,
      "learning_rate": 2.088888888888889e-05,
      "loss": 0.0018,
      "step": 20960
    },
    {
      "epoch": 1.165,
      "grad_norm": 0.0,
      "learning_rate": 2.0875e-05,
      "loss": 0.0013,
      "step": 20970
    },
    {
      "epoch": 1.1655555555555557,
      "grad_norm": 0.06170579418540001,
      "learning_rate": 2.086111111111111e-05,
      "loss": 0.0006,
      "step": 20980
    },
    {
      "epoch": 1.166111111111111,
      "grad_norm": 0.09419254958629608,
      "learning_rate": 2.0847222222222224e-05,
      "loss": 0.0005,
      "step": 20990
    },
    {
      "epoch": 1.1666666666666667,
      "grad_norm": 0.0,
      "learning_rate": 2.0833333333333336e-05,
      "loss": 0.0003,
      "step": 21000
    },
    {
      "epoch": 1.1672222222222222,
      "grad_norm": 0.04511382058262825,
      "learning_rate": 2.0819444444444445e-05,
      "loss": 0.0003,
      "step": 21010
    },
    {
      "epoch": 1.1677777777777778,
      "grad_norm": 0.0,
      "learning_rate": 2.0805555555555557e-05,
      "loss": 0.0008,
      "step": 21020
    },
    {
      "epoch": 1.1683333333333334,
      "grad_norm": 0.05210766941308975,
      "learning_rate": 2.0791666666666666e-05,
      "loss": 0.0003,
      "step": 21030
    },
    {
      "epoch": 1.1688888888888889,
      "grad_norm": 0.0,
      "learning_rate": 2.077777777777778e-05,
      "loss": 0.0002,
      "step": 21040
    },
    {
      "epoch": 1.1694444444444445,
      "grad_norm": 0.18538178503513336,
      "learning_rate": 2.076388888888889e-05,
      "loss": 0.0008,
      "step": 21050
    },
    {
      "epoch": 1.17,
      "grad_norm": 0.0,
      "learning_rate": 2.075e-05,
      "loss": 0.0007,
      "step": 21060
    },
    {
      "epoch": 1.1705555555555556,
      "grad_norm": 0.0,
      "learning_rate": 2.0736111111111112e-05,
      "loss": 0.0,
      "step": 21070
    },
    {
      "epoch": 1.1711111111111112,
      "grad_norm": 0.03778110817074776,
      "learning_rate": 2.0722222222222224e-05,
      "loss": 0.0005,
      "step": 21080
    },
    {
      "epoch": 1.1716666666666666,
      "grad_norm": 0.3506658673286438,
      "learning_rate": 2.0708333333333336e-05,
      "loss": 0.0006,
      "step": 21090
    },
    {
      "epoch": 1.1722222222222223,
      "grad_norm": 0.05798313021659851,
      "learning_rate": 2.0694444444444445e-05,
      "loss": 0.0004,
      "step": 21100
    },
    {
      "epoch": 1.1727777777777777,
      "grad_norm": 0.3907179832458496,
      "learning_rate": 2.0680555555555554e-05,
      "loss": 0.0003,
      "step": 21110
    },
    {
      "epoch": 1.1733333333333333,
      "grad_norm": 0.049821801483631134,
      "learning_rate": 2.0666666666666666e-05,
      "loss": 0.0009,
      "step": 21120
    },
    {
      "epoch": 1.173888888888889,
      "grad_norm": 0.0,
      "learning_rate": 2.065277777777778e-05,
      "loss": 0.0015,
      "step": 21130
    },
    {
      "epoch": 1.1744444444444444,
      "grad_norm": 0.30011266469955444,
      "learning_rate": 2.063888888888889e-05,
      "loss": 0.0019,
      "step": 21140
    },
    {
      "epoch": 1.175,
      "grad_norm": 0.15990224480628967,
      "learning_rate": 2.0625e-05,
      "loss": 0.0004,
      "step": 21150
    },
    {
      "epoch": 1.1755555555555555,
      "grad_norm": 0.21433430910110474,
      "learning_rate": 2.0611111111111112e-05,
      "loss": 0.0007,
      "step": 21160
    },
    {
      "epoch": 1.176111111111111,
      "grad_norm": 0.18845434486865997,
      "learning_rate": 2.0597222222222224e-05,
      "loss": 0.0008,
      "step": 21170
    },
    {
      "epoch": 1.1766666666666667,
      "grad_norm": 0.04437113553285599,
      "learning_rate": 2.0583333333333333e-05,
      "loss": 0.0005,
      "step": 21180
    },
    {
      "epoch": 1.1772222222222222,
      "grad_norm": 0.0,
      "learning_rate": 2.0569444444444446e-05,
      "loss": 0.0001,
      "step": 21190
    },
    {
      "epoch": 1.1777777777777778,
      "grad_norm": 0.08735138177871704,
      "learning_rate": 2.0555555555555555e-05,
      "loss": 0.0008,
      "step": 21200
    },
    {
      "epoch": 1.1783333333333332,
      "grad_norm": 0.15772059559822083,
      "learning_rate": 2.0541666666666667e-05,
      "loss": 0.0003,
      "step": 21210
    },
    {
      "epoch": 1.1788888888888889,
      "grad_norm": 0.09656573832035065,
      "learning_rate": 2.052777777777778e-05,
      "loss": 0.0004,
      "step": 21220
    },
    {
      "epoch": 1.1794444444444445,
      "grad_norm": 0.0,
      "learning_rate": 2.051388888888889e-05,
      "loss": 0.001,
      "step": 21230
    },
    {
      "epoch": 1.18,
      "grad_norm": 0.04763530194759369,
      "learning_rate": 2.05e-05,
      "loss": 0.0007,
      "step": 21240
    },
    {
      "epoch": 1.1805555555555556,
      "grad_norm": 0.08948861062526703,
      "learning_rate": 2.0486111111111113e-05,
      "loss": 0.0008,
      "step": 21250
    },
    {
      "epoch": 1.181111111111111,
      "grad_norm": 0.3470279276371002,
      "learning_rate": 2.0472222222222225e-05,
      "loss": 0.0008,
      "step": 21260
    },
    {
      "epoch": 1.1816666666666666,
      "grad_norm": 0.22981582581996918,
      "learning_rate": 2.0458333333333334e-05,
      "loss": 0.0004,
      "step": 21270
    },
    {
      "epoch": 1.1822222222222223,
      "grad_norm": 0.0,
      "learning_rate": 2.0444444444444446e-05,
      "loss": 0.0019,
      "step": 21280
    },
    {
      "epoch": 1.1827777777777777,
      "grad_norm": 0.2799457013607025,
      "learning_rate": 2.0430555555555555e-05,
      "loss": 0.001,
      "step": 21290
    },
    {
      "epoch": 1.1833333333333333,
      "grad_norm": 0.0,
      "learning_rate": 2.0416666666666667e-05,
      "loss": 0.001,
      "step": 21300
    },
    {
      "epoch": 1.1838888888888888,
      "grad_norm": 0.36721277236938477,
      "learning_rate": 2.040277777777778e-05,
      "loss": 0.0008,
      "step": 21310
    },
    {
      "epoch": 1.1844444444444444,
      "grad_norm": 0.0,
      "learning_rate": 2.0388888888888892e-05,
      "loss": 0.0006,
      "step": 21320
    },
    {
      "epoch": 1.185,
      "grad_norm": 0.0325113944709301,
      "learning_rate": 2.0375e-05,
      "loss": 0.0012,
      "step": 21330
    },
    {
      "epoch": 1.1855555555555555,
      "grad_norm": 0.32176145911216736,
      "learning_rate": 2.0361111111111113e-05,
      "loss": 0.0014,
      "step": 21340
    },
    {
      "epoch": 1.1861111111111111,
      "grad_norm": 0.046494826674461365,
      "learning_rate": 2.0347222222222222e-05,
      "loss": 0.0007,
      "step": 21350
    },
    {
      "epoch": 1.1866666666666668,
      "grad_norm": 0.0,
      "learning_rate": 2.0333333333333334e-05,
      "loss": 0.0005,
      "step": 21360
    },
    {
      "epoch": 1.1872222222222222,
      "grad_norm": 0.0,
      "learning_rate": 2.0319444444444446e-05,
      "loss": 0.0003,
      "step": 21370
    },
    {
      "epoch": 1.1877777777777778,
      "grad_norm": 0.0,
      "learning_rate": 2.0305555555555555e-05,
      "loss": 0.0004,
      "step": 21380
    },
    {
      "epoch": 1.1883333333333332,
      "grad_norm": 0.0,
      "learning_rate": 2.0291666666666667e-05,
      "loss": 0.0011,
      "step": 21390
    },
    {
      "epoch": 1.1888888888888889,
      "grad_norm": 0.0,
      "learning_rate": 2.027777777777778e-05,
      "loss": 0.0002,
      "step": 21400
    },
    {
      "epoch": 1.1894444444444445,
      "grad_norm": 0.047073911875486374,
      "learning_rate": 2.0263888888888892e-05,
      "loss": 0.0012,
      "step": 21410
    },
    {
      "epoch": 1.19,
      "grad_norm": 0.09900488704442978,
      "learning_rate": 2.025e-05,
      "loss": 0.0008,
      "step": 21420
    },
    {
      "epoch": 1.1905555555555556,
      "grad_norm": 0.04183180630207062,
      "learning_rate": 2.023611111111111e-05,
      "loss": 0.0011,
      "step": 21430
    },
    {
      "epoch": 1.1911111111111112,
      "grad_norm": 0.04762014001607895,
      "learning_rate": 2.0222222222222222e-05,
      "loss": 0.0007,
      "step": 21440
    },
    {
      "epoch": 1.1916666666666667,
      "grad_norm": 0.20601291954517365,
      "learning_rate": 2.0208333333333334e-05,
      "loss": 0.0011,
      "step": 21450
    },
    {
      "epoch": 1.1922222222222223,
      "grad_norm": 0.0,
      "learning_rate": 2.0194444444444447e-05,
      "loss": 0.0008,
      "step": 21460
    },
    {
      "epoch": 1.1927777777777777,
      "grad_norm": 0.0503426268696785,
      "learning_rate": 2.0180555555555556e-05,
      "loss": 0.0004,
      "step": 21470
    },
    {
      "epoch": 1.1933333333333334,
      "grad_norm": 0.0,
      "learning_rate": 2.0166666666666668e-05,
      "loss": 0.0003,
      "step": 21480
    },
    {
      "epoch": 1.193888888888889,
      "grad_norm": 0.0,
      "learning_rate": 2.015277777777778e-05,
      "loss": 0.0003,
      "step": 21490
    },
    {
      "epoch": 1.1944444444444444,
      "grad_norm": 0.05302674323320389,
      "learning_rate": 2.013888888888889e-05,
      "loss": 0.0008,
      "step": 21500
    },
    {
      "epoch": 1.195,
      "grad_norm": 0.05871843174099922,
      "learning_rate": 2.0125e-05,
      "loss": 0.0009,
      "step": 21510
    },
    {
      "epoch": 1.1955555555555555,
      "grad_norm": 0.03513266146183014,
      "learning_rate": 2.011111111111111e-05,
      "loss": 0.0006,
      "step": 21520
    },
    {
      "epoch": 1.1961111111111111,
      "grad_norm": 0.1310207098722458,
      "learning_rate": 2.0097222222222222e-05,
      "loss": 0.0015,
      "step": 21530
    },
    {
      "epoch": 1.1966666666666668,
      "grad_norm": 0.19613374769687653,
      "learning_rate": 2.0083333333333335e-05,
      "loss": 0.0004,
      "step": 21540
    },
    {
      "epoch": 1.1972222222222222,
      "grad_norm": 0.049782894551754,
      "learning_rate": 2.0069444444444447e-05,
      "loss": 0.0006,
      "step": 21550
    },
    {
      "epoch": 1.1977777777777778,
      "grad_norm": 0.0,
      "learning_rate": 2.0055555555555556e-05,
      "loss": 0.0001,
      "step": 21560
    },
    {
      "epoch": 1.1983333333333333,
      "grad_norm": 0.09817288815975189,
      "learning_rate": 2.0041666666666668e-05,
      "loss": 0.0001,
      "step": 21570
    },
    {
      "epoch": 1.198888888888889,
      "grad_norm": 0.0,
      "learning_rate": 2.0027777777777777e-05,
      "loss": 0.001,
      "step": 21580
    },
    {
      "epoch": 1.1994444444444445,
      "grad_norm": 0.06849978864192963,
      "learning_rate": 2.001388888888889e-05,
      "loss": 0.0014,
      "step": 21590
    },
    {
      "epoch": 1.2,
      "grad_norm": 0.0,
      "learning_rate": 2e-05,
      "loss": 0.0008,
      "step": 21600
    },
    {
      "epoch": 1.2005555555555556,
      "grad_norm": 0.13452322781085968,
      "learning_rate": 1.998611111111111e-05,
      "loss": 0.0014,
      "step": 21610
    },
    {
      "epoch": 1.201111111111111,
      "grad_norm": 0.04499693214893341,
      "learning_rate": 1.9972222222222223e-05,
      "loss": 0.0005,
      "step": 21620
    },
    {
      "epoch": 1.2016666666666667,
      "grad_norm": 0.0,
      "learning_rate": 1.9958333333333335e-05,
      "loss": 0.0004,
      "step": 21630
    },
    {
      "epoch": 1.2022222222222223,
      "grad_norm": 0.0,
      "learning_rate": 1.9944444444444447e-05,
      "loss": 0.0006,
      "step": 21640
    },
    {
      "epoch": 1.2027777777777777,
      "grad_norm": 0.04902542382478714,
      "learning_rate": 1.9930555555555556e-05,
      "loss": 0.0004,
      "step": 21650
    },
    {
      "epoch": 1.2033333333333334,
      "grad_norm": 0.24262747168540955,
      "learning_rate": 1.9916666666666665e-05,
      "loss": 0.0009,
      "step": 21660
    },
    {
      "epoch": 1.2038888888888888,
      "grad_norm": 0.22848890721797943,
      "learning_rate": 1.9902777777777777e-05,
      "loss": 0.0004,
      "step": 21670
    },
    {
      "epoch": 1.2044444444444444,
      "grad_norm": 0.0,
      "learning_rate": 1.988888888888889e-05,
      "loss": 0.0004,
      "step": 21680
    },
    {
      "epoch": 1.205,
      "grad_norm": 0.0,
      "learning_rate": 1.9875000000000002e-05,
      "loss": 0.0013,
      "step": 21690
    },
    {
      "epoch": 1.2055555555555555,
      "grad_norm": 0.2323666661977768,
      "learning_rate": 1.986111111111111e-05,
      "loss": 0.0008,
      "step": 21700
    },
    {
      "epoch": 1.2061111111111111,
      "grad_norm": 0.06884258985519409,
      "learning_rate": 1.9847222222222223e-05,
      "loss": 0.0004,
      "step": 21710
    },
    {
      "epoch": 1.2066666666666666,
      "grad_norm": 0.04365621507167816,
      "learning_rate": 1.9833333333333335e-05,
      "loss": 0.0012,
      "step": 21720
    },
    {
      "epoch": 1.2072222222222222,
      "grad_norm": 0.04989594966173172,
      "learning_rate": 1.9819444444444448e-05,
      "loss": 0.0006,
      "step": 21730
    },
    {
      "epoch": 1.2077777777777778,
      "grad_norm": 0.0,
      "learning_rate": 1.9805555555555557e-05,
      "loss": 0.0007,
      "step": 21740
    },
    {
      "epoch": 1.2083333333333333,
      "grad_norm": 0.0,
      "learning_rate": 1.9791666666666665e-05,
      "loss": 0.0002,
      "step": 21750
    },
    {
      "epoch": 1.208888888888889,
      "grad_norm": 0.0,
      "learning_rate": 1.9777777777777778e-05,
      "loss": 0.0003,
      "step": 21760
    },
    {
      "epoch": 1.2094444444444443,
      "grad_norm": 0.0,
      "learning_rate": 1.976388888888889e-05,
      "loss": 0.0003,
      "step": 21770
    },
    {
      "epoch": 1.21,
      "grad_norm": 0.0,
      "learning_rate": 1.9750000000000002e-05,
      "loss": 0.0001,
      "step": 21780
    },
    {
      "epoch": 1.2105555555555556,
      "grad_norm": 0.04739903658628464,
      "learning_rate": 1.973611111111111e-05,
      "loss": 0.0002,
      "step": 21790
    },
    {
      "epoch": 1.211111111111111,
      "grad_norm": 0.0,
      "learning_rate": 1.9722222222222224e-05,
      "loss": 0.0004,
      "step": 21800
    },
    {
      "epoch": 1.2116666666666667,
      "grad_norm": 0.09059042483568192,
      "learning_rate": 1.9708333333333336e-05,
      "loss": 0.0002,
      "step": 21810
    },
    {
      "epoch": 1.2122222222222223,
      "grad_norm": 0.0,
      "learning_rate": 1.9694444444444445e-05,
      "loss": 0.0005,
      "step": 21820
    },
    {
      "epoch": 1.2127777777777777,
      "grad_norm": 0.04405204579234123,
      "learning_rate": 1.9680555555555557e-05,
      "loss": 0.0002,
      "step": 21830
    },
    {
      "epoch": 1.2133333333333334,
      "grad_norm": 0.04627710580825806,
      "learning_rate": 1.9666666666666666e-05,
      "loss": 0.0002,
      "step": 21840
    },
    {
      "epoch": 1.2138888888888888,
      "grad_norm": 0.04575749486684799,
      "learning_rate": 1.9652777777777778e-05,
      "loss": 0.0006,
      "step": 21850
    },
    {
      "epoch": 1.2144444444444444,
      "grad_norm": 0.0636112168431282,
      "learning_rate": 1.963888888888889e-05,
      "loss": 0.0008,
      "step": 21860
    },
    {
      "epoch": 1.215,
      "grad_norm": 0.0,
      "learning_rate": 1.9625000000000003e-05,
      "loss": 0.0007,
      "step": 21870
    },
    {
      "epoch": 1.2155555555555555,
      "grad_norm": 0.045511383563280106,
      "learning_rate": 1.9611111111111115e-05,
      "loss": 0.001,
      "step": 21880
    },
    {
      "epoch": 1.2161111111111111,
      "grad_norm": 0.06101343408226967,
      "learning_rate": 1.9597222222222224e-05,
      "loss": 0.0007,
      "step": 21890
    },
    {
      "epoch": 1.2166666666666668,
      "grad_norm": 0.0,
      "learning_rate": 1.9583333333333333e-05,
      "loss": 0.0009,
      "step": 21900
    },
    {
      "epoch": 1.2172222222222222,
      "grad_norm": 0.35852205753326416,
      "learning_rate": 1.9569444444444445e-05,
      "loss": 0.0013,
      "step": 21910
    },
    {
      "epoch": 1.2177777777777778,
      "grad_norm": 0.0,
      "learning_rate": 1.9555555555555557e-05,
      "loss": 0.0002,
      "step": 21920
    },
    {
      "epoch": 1.2183333333333333,
      "grad_norm": 0.2582652270793915,
      "learning_rate": 1.9541666666666666e-05,
      "loss": 0.0015,
      "step": 21930
    },
    {
      "epoch": 1.218888888888889,
      "grad_norm": 0.04921727254986763,
      "learning_rate": 1.952777777777778e-05,
      "loss": 0.0009,
      "step": 21940
    },
    {
      "epoch": 1.2194444444444446,
      "grad_norm": 0.30122852325439453,
      "learning_rate": 1.951388888888889e-05,
      "loss": 0.0013,
      "step": 21950
    },
    {
      "epoch": 1.22,
      "grad_norm": 0.16401320695877075,
      "learning_rate": 1.9500000000000003e-05,
      "loss": 0.0012,
      "step": 21960
    },
    {
      "epoch": 1.2205555555555556,
      "grad_norm": 0.2788356840610504,
      "learning_rate": 1.9486111111111112e-05,
      "loss": 0.0016,
      "step": 21970
    },
    {
      "epoch": 1.221111111111111,
      "grad_norm": 0.0,
      "learning_rate": 1.947222222222222e-05,
      "loss": 0.0001,
      "step": 21980
    },
    {
      "epoch": 1.2216666666666667,
      "grad_norm": 0.0,
      "learning_rate": 1.9458333333333333e-05,
      "loss": 0.0011,
      "step": 21990
    },
    {
      "epoch": 1.2222222222222223,
      "grad_norm": 0.050439875572919846,
      "learning_rate": 1.9444444444444445e-05,
      "loss": 0.0011,
      "step": 22000
    },
    {
      "epoch": 1.2227777777777777,
      "grad_norm": 0.09365322440862656,
      "learning_rate": 1.9430555555555558e-05,
      "loss": 0.0015,
      "step": 22010
    },
    {
      "epoch": 1.2233333333333334,
      "grad_norm": 0.0,
      "learning_rate": 1.9416666666666667e-05,
      "loss": 0.0005,
      "step": 22020
    },
    {
      "epoch": 1.2238888888888888,
      "grad_norm": 0.28740787506103516,
      "learning_rate": 1.940277777777778e-05,
      "loss": 0.0009,
      "step": 22030
    },
    {
      "epoch": 1.2244444444444444,
      "grad_norm": 0.34036704897880554,
      "learning_rate": 1.938888888888889e-05,
      "loss": 0.0005,
      "step": 22040
    },
    {
      "epoch": 1.225,
      "grad_norm": 0.09646832942962646,
      "learning_rate": 1.9375e-05,
      "loss": 0.0017,
      "step": 22050
    },
    {
      "epoch": 1.2255555555555555,
      "grad_norm": 0.3504648804664612,
      "learning_rate": 1.9361111111111112e-05,
      "loss": 0.0008,
      "step": 22060
    },
    {
      "epoch": 1.2261111111111112,
      "grad_norm": 0.0,
      "learning_rate": 1.934722222222222e-05,
      "loss": 0.0006,
      "step": 22070
    },
    {
      "epoch": 1.2266666666666666,
      "grad_norm": 0.22896477580070496,
      "learning_rate": 1.9333333333333333e-05,
      "loss": 0.0004,
      "step": 22080
    },
    {
      "epoch": 1.2272222222222222,
      "grad_norm": 0.07333279401063919,
      "learning_rate": 1.9319444444444446e-05,
      "loss": 0.0009,
      "step": 22090
    },
    {
      "epoch": 1.2277777777777779,
      "grad_norm": 0.09578876942396164,
      "learning_rate": 1.9305555555555558e-05,
      "loss": 0.0008,
      "step": 22100
    },
    {
      "epoch": 1.2283333333333333,
      "grad_norm": 0.09880794584751129,
      "learning_rate": 1.9291666666666667e-05,
      "loss": 0.0007,
      "step": 22110
    },
    {
      "epoch": 1.228888888888889,
      "grad_norm": 0.054045263677835464,
      "learning_rate": 1.927777777777778e-05,
      "loss": 0.0011,
      "step": 22120
    },
    {
      "epoch": 1.2294444444444443,
      "grad_norm": 0.3477022349834442,
      "learning_rate": 1.9263888888888888e-05,
      "loss": 0.0011,
      "step": 22130
    },
    {
      "epoch": 1.23,
      "grad_norm": 0.0,
      "learning_rate": 1.925e-05,
      "loss": 0.0004,
      "step": 22140
    },
    {
      "epoch": 1.2305555555555556,
      "grad_norm": 0.054411448538303375,
      "learning_rate": 1.9236111111111113e-05,
      "loss": 0.0003,
      "step": 22150
    },
    {
      "epoch": 1.231111111111111,
      "grad_norm": 0.0,
      "learning_rate": 1.922222222222222e-05,
      "loss": 0.0002,
      "step": 22160
    },
    {
      "epoch": 1.2316666666666667,
      "grad_norm": 0.20972713828086853,
      "learning_rate": 1.9208333333333334e-05,
      "loss": 0.0009,
      "step": 22170
    },
    {
      "epoch": 1.232222222222222,
      "grad_norm": 0.0,
      "learning_rate": 1.9194444444444446e-05,
      "loss": 0.0009,
      "step": 22180
    },
    {
      "epoch": 1.2327777777777778,
      "grad_norm": 0.22648076713085175,
      "learning_rate": 1.918055555555556e-05,
      "loss": 0.0006,
      "step": 22190
    },
    {
      "epoch": 1.2333333333333334,
      "grad_norm": 0.14520040154457092,
      "learning_rate": 1.9166666666666667e-05,
      "loss": 0.0011,
      "step": 22200
    },
    {
      "epoch": 1.2338888888888888,
      "grad_norm": 0.24925224483013153,
      "learning_rate": 1.9152777777777776e-05,
      "loss": 0.0005,
      "step": 22210
    },
    {
      "epoch": 1.2344444444444445,
      "grad_norm": 0.0,
      "learning_rate": 1.913888888888889e-05,
      "loss": 0.0006,
      "step": 22220
    },
    {
      "epoch": 1.2349999999999999,
      "grad_norm": 0.31994977593421936,
      "learning_rate": 1.9125e-05,
      "loss": 0.0014,
      "step": 22230
    },
    {
      "epoch": 1.2355555555555555,
      "grad_norm": 0.0,
      "learning_rate": 1.9111111111111113e-05,
      "loss": 0.0019,
      "step": 22240
    },
    {
      "epoch": 1.2361111111111112,
      "grad_norm": 0.04824023321270943,
      "learning_rate": 1.9097222222222222e-05,
      "loss": 0.0011,
      "step": 22250
    },
    {
      "epoch": 1.2366666666666666,
      "grad_norm": 0.059880081564188004,
      "learning_rate": 1.9083333333333334e-05,
      "loss": 0.0005,
      "step": 22260
    },
    {
      "epoch": 1.2372222222222222,
      "grad_norm": 0.0,
      "learning_rate": 1.9069444444444446e-05,
      "loss": 0.001,
      "step": 22270
    },
    {
      "epoch": 1.2377777777777779,
      "grad_norm": 0.0,
      "learning_rate": 1.905555555555556e-05,
      "loss": 0.0009,
      "step": 22280
    },
    {
      "epoch": 1.2383333333333333,
      "grad_norm": 0.049307726323604584,
      "learning_rate": 1.9041666666666668e-05,
      "loss": 0.0011,
      "step": 22290
    },
    {
      "epoch": 1.238888888888889,
      "grad_norm": 0.046587537974119186,
      "learning_rate": 1.9027777777777776e-05,
      "loss": 0.001,
      "step": 22300
    },
    {
      "epoch": 1.2394444444444443,
      "grad_norm": 0.05638976767659187,
      "learning_rate": 1.901388888888889e-05,
      "loss": 0.0007,
      "step": 22310
    },
    {
      "epoch": 1.24,
      "grad_norm": 0.2357940673828125,
      "learning_rate": 1.9e-05,
      "loss": 0.0013,
      "step": 22320
    },
    {
      "epoch": 1.2405555555555556,
      "grad_norm": 0.289783239364624,
      "learning_rate": 1.8986111111111113e-05,
      "loss": 0.0011,
      "step": 22330
    },
    {
      "epoch": 1.241111111111111,
      "grad_norm": 0.04700218513607979,
      "learning_rate": 1.8972222222222222e-05,
      "loss": 0.0012,
      "step": 22340
    },
    {
      "epoch": 1.2416666666666667,
      "grad_norm": 0.21480217576026917,
      "learning_rate": 1.8958333333333334e-05,
      "loss": 0.0009,
      "step": 22350
    },
    {
      "epoch": 1.2422222222222223,
      "grad_norm": 0.15137425065040588,
      "learning_rate": 1.8944444444444447e-05,
      "loss": 0.0009,
      "step": 22360
    },
    {
      "epoch": 1.2427777777777778,
      "grad_norm": 0.0,
      "learning_rate": 1.8930555555555556e-05,
      "loss": 0.0004,
      "step": 22370
    },
    {
      "epoch": 1.2433333333333334,
      "grad_norm": 0.050378888845443726,
      "learning_rate": 1.8916666666666668e-05,
      "loss": 0.0004,
      "step": 22380
    },
    {
      "epoch": 1.2438888888888888,
      "grad_norm": 0.0,
      "learning_rate": 1.8902777777777777e-05,
      "loss": 0.0008,
      "step": 22390
    },
    {
      "epoch": 1.2444444444444445,
      "grad_norm": 0.06752441078424454,
      "learning_rate": 1.888888888888889e-05,
      "loss": 0.0005,
      "step": 22400
    },
    {
      "epoch": 1.245,
      "grad_norm": 0.043790798634290695,
      "learning_rate": 1.8875e-05,
      "loss": 0.0005,
      "step": 22410
    },
    {
      "epoch": 1.2455555555555555,
      "grad_norm": 0.0,
      "learning_rate": 1.8861111111111114e-05,
      "loss": 0.0007,
      "step": 22420
    },
    {
      "epoch": 1.2461111111111112,
      "grad_norm": 0.056366320699453354,
      "learning_rate": 1.8847222222222226e-05,
      "loss": 0.0005,
      "step": 22430
    },
    {
      "epoch": 1.2466666666666666,
      "grad_norm": 0.0,
      "learning_rate": 1.8833333333333335e-05,
      "loss": 0.0017,
      "step": 22440
    },
    {
      "epoch": 1.2472222222222222,
      "grad_norm": 0.1305747926235199,
      "learning_rate": 1.8819444444444444e-05,
      "loss": 0.0005,
      "step": 22450
    },
    {
      "epoch": 1.2477777777777779,
      "grad_norm": 0.0,
      "learning_rate": 1.8805555555555556e-05,
      "loss": 0.0004,
      "step": 22460
    },
    {
      "epoch": 1.2483333333333333,
      "grad_norm": 0.3247692584991455,
      "learning_rate": 1.8791666666666668e-05,
      "loss": 0.0007,
      "step": 22470
    },
    {
      "epoch": 1.248888888888889,
      "grad_norm": 0.04968416318297386,
      "learning_rate": 1.8777777777777777e-05,
      "loss": 0.001,
      "step": 22480
    },
    {
      "epoch": 1.2494444444444444,
      "grad_norm": 0.0,
      "learning_rate": 1.876388888888889e-05,
      "loss": 0.0005,
      "step": 22490
    },
    {
      "epoch": 1.25,
      "grad_norm": 0.207071915268898,
      "learning_rate": 1.8750000000000002e-05,
      "loss": 0.0005,
      "step": 22500
    },
    {
      "epoch": 1.2505555555555556,
      "grad_norm": 0.04715965315699577,
      "learning_rate": 1.8736111111111114e-05,
      "loss": 0.0011,
      "step": 22510
    },
    {
      "epoch": 1.251111111111111,
      "grad_norm": 0.024016041308641434,
      "learning_rate": 1.8722222222222223e-05,
      "loss": 0.0013,
      "step": 22520
    },
    {
      "epoch": 1.2516666666666667,
      "grad_norm": 0.05036872625350952,
      "learning_rate": 1.8708333333333332e-05,
      "loss": 0.0002,
      "step": 22530
    },
    {
      "epoch": 1.2522222222222221,
      "grad_norm": 0.0,
      "learning_rate": 1.8694444444444444e-05,
      "loss": 0.0003,
      "step": 22540
    },
    {
      "epoch": 1.2527777777777778,
      "grad_norm": 0.47554701566696167,
      "learning_rate": 1.8680555555555556e-05,
      "loss": 0.001,
      "step": 22550
    },
    {
      "epoch": 1.2533333333333334,
      "grad_norm": 0.0451180525124073,
      "learning_rate": 1.866666666666667e-05,
      "loss": 0.0007,
      "step": 22560
    },
    {
      "epoch": 1.2538888888888888,
      "grad_norm": 0.0,
      "learning_rate": 1.8652777777777778e-05,
      "loss": 0.0009,
      "step": 22570
    },
    {
      "epoch": 1.2544444444444445,
      "grad_norm": 0.045345596969127655,
      "learning_rate": 1.863888888888889e-05,
      "loss": 0.0018,
      "step": 22580
    },
    {
      "epoch": 1.255,
      "grad_norm": 0.06780342757701874,
      "learning_rate": 1.8625000000000002e-05,
      "loss": 0.0004,
      "step": 22590
    },
    {
      "epoch": 1.2555555555555555,
      "grad_norm": 0.0,
      "learning_rate": 1.861111111111111e-05,
      "loss": 0.0005,
      "step": 22600
    },
    {
      "epoch": 1.2561111111111112,
      "grad_norm": 0.07622681558132172,
      "learning_rate": 1.8597222222222223e-05,
      "loss": 0.0008,
      "step": 22610
    },
    {
      "epoch": 1.2566666666666666,
      "grad_norm": 0.0,
      "learning_rate": 1.8583333333333332e-05,
      "loss": 0.0002,
      "step": 22620
    },
    {
      "epoch": 1.2572222222222222,
      "grad_norm": 0.05345997214317322,
      "learning_rate": 1.8569444444444444e-05,
      "loss": 0.0004,
      "step": 22630
    },
    {
      "epoch": 1.2577777777777777,
      "grad_norm": 0.0,
      "learning_rate": 1.8555555555555557e-05,
      "loss": 0.0009,
      "step": 22640
    },
    {
      "epoch": 1.2583333333333333,
      "grad_norm": 0.04418675974011421,
      "learning_rate": 1.854166666666667e-05,
      "loss": 0.0006,
      "step": 22650
    },
    {
      "epoch": 1.258888888888889,
      "grad_norm": 0.38794663548469543,
      "learning_rate": 1.852777777777778e-05,
      "loss": 0.0008,
      "step": 22660
    },
    {
      "epoch": 1.2594444444444444,
      "grad_norm": 0.2937472462654114,
      "learning_rate": 1.851388888888889e-05,
      "loss": 0.0012,
      "step": 22670
    },
    {
      "epoch": 1.26,
      "grad_norm": 0.09351599216461182,
      "learning_rate": 1.85e-05,
      "loss": 0.0007,
      "step": 22680
    },
    {
      "epoch": 1.2605555555555554,
      "grad_norm": 0.2533394694328308,
      "learning_rate": 1.848611111111111e-05,
      "loss": 0.0003,
      "step": 22690
    },
    {
      "epoch": 1.261111111111111,
      "grad_norm": 0.0,
      "learning_rate": 1.8472222222222224e-05,
      "loss": 0.0001,
      "step": 22700
    },
    {
      "epoch": 1.2616666666666667,
      "grad_norm": 0.0,
      "learning_rate": 1.8458333333333333e-05,
      "loss": 0.0011,
      "step": 22710
    },
    {
      "epoch": 1.2622222222222224,
      "grad_norm": 0.08030447363853455,
      "learning_rate": 1.8444444444444445e-05,
      "loss": 0.0005,
      "step": 22720
    },
    {
      "epoch": 1.2627777777777778,
      "grad_norm": 0.0,
      "learning_rate": 1.8430555555555557e-05,
      "loss": 0.0012,
      "step": 22730
    },
    {
      "epoch": 1.2633333333333332,
      "grad_norm": 0.042179420590400696,
      "learning_rate": 1.841666666666667e-05,
      "loss": 0.0006,
      "step": 22740
    },
    {
      "epoch": 1.2638888888888888,
      "grad_norm": 0.05409497395157814,
      "learning_rate": 1.8402777777777778e-05,
      "loss": 0.0012,
      "step": 22750
    },
    {
      "epoch": 1.2644444444444445,
      "grad_norm": 0.2673162817955017,
      "learning_rate": 1.838888888888889e-05,
      "loss": 0.0002,
      "step": 22760
    },
    {
      "epoch": 1.2650000000000001,
      "grad_norm": 0.0,
      "learning_rate": 1.8375e-05,
      "loss": 0.0014,
      "step": 22770
    },
    {
      "epoch": 1.2655555555555555,
      "grad_norm": 0.0,
      "learning_rate": 1.836111111111111e-05,
      "loss": 0.0004,
      "step": 22780
    },
    {
      "epoch": 1.2661111111111112,
      "grad_norm": 0.055751584470272064,
      "learning_rate": 1.8347222222222224e-05,
      "loss": 0.0004,
      "step": 22790
    },
    {
      "epoch": 1.2666666666666666,
      "grad_norm": 0.0,
      "learning_rate": 1.8333333333333333e-05,
      "loss": 0.0006,
      "step": 22800
    },
    {
      "epoch": 1.2672222222222222,
      "grad_norm": 0.09138182550668716,
      "learning_rate": 1.8319444444444445e-05,
      "loss": 0.0014,
      "step": 22810
    },
    {
      "epoch": 1.267777777777778,
      "grad_norm": 0.04826187342405319,
      "learning_rate": 1.8305555555555557e-05,
      "loss": 0.0011,
      "step": 22820
    },
    {
      "epoch": 1.2683333333333333,
      "grad_norm": 0.0,
      "learning_rate": 1.829166666666667e-05,
      "loss": 0.0009,
      "step": 22830
    },
    {
      "epoch": 1.268888888888889,
      "grad_norm": 0.05265984684228897,
      "learning_rate": 1.827777777777778e-05,
      "loss": 0.0001,
      "step": 22840
    },
    {
      "epoch": 1.2694444444444444,
      "grad_norm": 0.0,
      "learning_rate": 1.8263888888888887e-05,
      "loss": 0.0007,
      "step": 22850
    },
    {
      "epoch": 1.27,
      "grad_norm": 0.04471846669912338,
      "learning_rate": 1.825e-05,
      "loss": 0.0008,
      "step": 22860
    },
    {
      "epoch": 1.2705555555555557,
      "grad_norm": 0.13530117273330688,
      "learning_rate": 1.8236111111111112e-05,
      "loss": 0.0005,
      "step": 22870
    },
    {
      "epoch": 1.271111111111111,
      "grad_norm": 0.0,
      "learning_rate": 1.8222222222222224e-05,
      "loss": 0.0003,
      "step": 22880
    },
    {
      "epoch": 1.2716666666666667,
      "grad_norm": 0.13061800599098206,
      "learning_rate": 1.8208333333333337e-05,
      "loss": 0.0018,
      "step": 22890
    },
    {
      "epoch": 1.2722222222222221,
      "grad_norm": 0.04669618606567383,
      "learning_rate": 1.8194444444444445e-05,
      "loss": 0.0011,
      "step": 22900
    },
    {
      "epoch": 1.2727777777777778,
      "grad_norm": 0.0,
      "learning_rate": 1.8180555555555558e-05,
      "loss": 0.0003,
      "step": 22910
    },
    {
      "epoch": 1.2733333333333334,
      "grad_norm": 0.2343042939901352,
      "learning_rate": 1.8166666666666667e-05,
      "loss": 0.0006,
      "step": 22920
    },
    {
      "epoch": 1.2738888888888888,
      "grad_norm": 0.0,
      "learning_rate": 1.815277777777778e-05,
      "loss": 0.0002,
      "step": 22930
    },
    {
      "epoch": 1.2744444444444445,
      "grad_norm": 0.09803708642721176,
      "learning_rate": 1.8138888888888888e-05,
      "loss": 0.0001,
      "step": 22940
    },
    {
      "epoch": 1.275,
      "grad_norm": 0.057426292449235916,
      "learning_rate": 1.8125e-05,
      "loss": 0.0013,
      "step": 22950
    },
    {
      "epoch": 1.2755555555555556,
      "grad_norm": 0.09366531670093536,
      "learning_rate": 1.8111111111111112e-05,
      "loss": 0.0007,
      "step": 22960
    },
    {
      "epoch": 1.2761111111111112,
      "grad_norm": 0.046484243124723434,
      "learning_rate": 1.8097222222222225e-05,
      "loss": 0.0008,
      "step": 22970
    },
    {
      "epoch": 1.2766666666666666,
      "grad_norm": 0.05048409476876259,
      "learning_rate": 1.8083333333333337e-05,
      "loss": 0.0009,
      "step": 22980
    },
    {
      "epoch": 1.2772222222222223,
      "grad_norm": 0.0,
      "learning_rate": 1.8069444444444446e-05,
      "loss": 0.0002,
      "step": 22990
    },
    {
      "epoch": 1.2777777777777777,
      "grad_norm": 0.14574481546878815,
      "learning_rate": 1.8055555555555555e-05,
      "loss": 0.0005,
      "step": 23000
    },
    {
      "epoch": 1.2783333333333333,
      "grad_norm": 0.10665346682071686,
      "learning_rate": 1.8041666666666667e-05,
      "loss": 0.0008,
      "step": 23010
    },
    {
      "epoch": 1.278888888888889,
      "grad_norm": 0.04583701118826866,
      "learning_rate": 1.802777777777778e-05,
      "loss": 0.001,
      "step": 23020
    },
    {
      "epoch": 1.2794444444444444,
      "grad_norm": 0.0,
      "learning_rate": 1.8013888888888888e-05,
      "loss": 0.001,
      "step": 23030
    },
    {
      "epoch": 1.28,
      "grad_norm": 0.16107235848903656,
      "learning_rate": 1.8e-05,
      "loss": 0.0012,
      "step": 23040
    },
    {
      "epoch": 1.2805555555555554,
      "grad_norm": 0.0,
      "learning_rate": 1.7986111111111113e-05,
      "loss": 0.0003,
      "step": 23050
    },
    {
      "epoch": 1.281111111111111,
      "grad_norm": 0.0,
      "learning_rate": 1.7972222222222225e-05,
      "loss": 0.0004,
      "step": 23060
    },
    {
      "epoch": 1.2816666666666667,
      "grad_norm": 0.04840617626905441,
      "learning_rate": 1.7958333333333334e-05,
      "loss": 0.0011,
      "step": 23070
    },
    {
      "epoch": 1.2822222222222222,
      "grad_norm": 0.19142726063728333,
      "learning_rate": 1.7944444444444443e-05,
      "loss": 0.0016,
      "step": 23080
    },
    {
      "epoch": 1.2827777777777778,
      "grad_norm": 0.04617636650800705,
      "learning_rate": 1.7930555555555555e-05,
      "loss": 0.0008,
      "step": 23090
    },
    {
      "epoch": 1.2833333333333332,
      "grad_norm": 0.0,
      "learning_rate": 1.7916666666666667e-05,
      "loss": 0.0004,
      "step": 23100
    },
    {
      "epoch": 1.2838888888888889,
      "grad_norm": 0.1430746465921402,
      "learning_rate": 1.790277777777778e-05,
      "loss": 0.0003,
      "step": 23110
    },
    {
      "epoch": 1.2844444444444445,
      "grad_norm": 0.0,
      "learning_rate": 1.788888888888889e-05,
      "loss": 0.0005,
      "step": 23120
    },
    {
      "epoch": 1.285,
      "grad_norm": 0.04631977900862694,
      "learning_rate": 1.7875e-05,
      "loss": 0.0006,
      "step": 23130
    },
    {
      "epoch": 1.2855555555555556,
      "grad_norm": 0.0,
      "learning_rate": 1.7861111111111113e-05,
      "loss": 0.0002,
      "step": 23140
    },
    {
      "epoch": 1.286111111111111,
      "grad_norm": 0.0,
      "learning_rate": 1.7847222222222222e-05,
      "loss": 0.0008,
      "step": 23150
    },
    {
      "epoch": 1.2866666666666666,
      "grad_norm": 0.04452551528811455,
      "learning_rate": 1.7833333333333334e-05,
      "loss": 0.0004,
      "step": 23160
    },
    {
      "epoch": 1.2872222222222223,
      "grad_norm": 0.0,
      "learning_rate": 1.7819444444444443e-05,
      "loss": 0.0006,
      "step": 23170
    },
    {
      "epoch": 1.287777777777778,
      "grad_norm": 0.04608067870140076,
      "learning_rate": 1.7805555555555555e-05,
      "loss": 0.0011,
      "step": 23180
    },
    {
      "epoch": 1.2883333333333333,
      "grad_norm": 0.049990300089120865,
      "learning_rate": 1.7791666666666668e-05,
      "loss": 0.0018,
      "step": 23190
    },
    {
      "epoch": 1.2888888888888888,
      "grad_norm": 0.0,
      "learning_rate": 1.777777777777778e-05,
      "loss": 0.0008,
      "step": 23200
    },
    {
      "epoch": 1.2894444444444444,
      "grad_norm": 0.1953963041305542,
      "learning_rate": 1.7763888888888892e-05,
      "loss": 0.001,
      "step": 23210
    },
    {
      "epoch": 1.29,
      "grad_norm": 0.04821602627635002,
      "learning_rate": 1.775e-05,
      "loss": 0.0017,
      "step": 23220
    },
    {
      "epoch": 1.2905555555555557,
      "grad_norm": 0.19095367193222046,
      "learning_rate": 1.773611111111111e-05,
      "loss": 0.0009,
      "step": 23230
    },
    {
      "epoch": 1.291111111111111,
      "grad_norm": 0.13872221112251282,
      "learning_rate": 1.7722222222222222e-05,
      "loss": 0.0003,
      "step": 23240
    },
    {
      "epoch": 1.2916666666666667,
      "grad_norm": 0.12261036038398743,
      "learning_rate": 1.7708333333333335e-05,
      "loss": 0.0002,
      "step": 23250
    },
    {
      "epoch": 1.2922222222222222,
      "grad_norm": 0.052063629031181335,
      "learning_rate": 1.7694444444444443e-05,
      "loss": 0.0005,
      "step": 23260
    },
    {
      "epoch": 1.2927777777777778,
      "grad_norm": 0.1564607173204422,
      "learning_rate": 1.7680555555555556e-05,
      "loss": 0.0003,
      "step": 23270
    },
    {
      "epoch": 1.2933333333333334,
      "grad_norm": 0.04598488286137581,
      "learning_rate": 1.7666666666666668e-05,
      "loss": 0.001,
      "step": 23280
    },
    {
      "epoch": 1.2938888888888889,
      "grad_norm": 0.0443778820335865,
      "learning_rate": 1.765277777777778e-05,
      "loss": 0.0008,
      "step": 23290
    },
    {
      "epoch": 1.2944444444444445,
      "grad_norm": 0.18934480845928192,
      "learning_rate": 1.763888888888889e-05,
      "loss": 0.0011,
      "step": 23300
    },
    {
      "epoch": 1.295,
      "grad_norm": 0.0,
      "learning_rate": 1.7625e-05,
      "loss": 0.0004,
      "step": 23310
    },
    {
      "epoch": 1.2955555555555556,
      "grad_norm": 0.045670680701732635,
      "learning_rate": 1.761111111111111e-05,
      "loss": 0.0008,
      "step": 23320
    },
    {
      "epoch": 1.2961111111111112,
      "grad_norm": 0.05442820489406586,
      "learning_rate": 1.7597222222222223e-05,
      "loss": 0.0003,
      "step": 23330
    },
    {
      "epoch": 1.2966666666666666,
      "grad_norm": 0.12620708346366882,
      "learning_rate": 1.7583333333333335e-05,
      "loss": 0.0009,
      "step": 23340
    },
    {
      "epoch": 1.2972222222222223,
      "grad_norm": 0.06126881763339043,
      "learning_rate": 1.7569444444444444e-05,
      "loss": 0.0003,
      "step": 23350
    },
    {
      "epoch": 1.2977777777777777,
      "grad_norm": 0.08922082930803299,
      "learning_rate": 1.7555555555555556e-05,
      "loss": 0.0006,
      "step": 23360
    },
    {
      "epoch": 1.2983333333333333,
      "grad_norm": 0.0,
      "learning_rate": 1.754166666666667e-05,
      "loss": 0.0003,
      "step": 23370
    },
    {
      "epoch": 1.298888888888889,
      "grad_norm": 0.0,
      "learning_rate": 1.752777777777778e-05,
      "loss": 0.0002,
      "step": 23380
    },
    {
      "epoch": 1.2994444444444444,
      "grad_norm": 0.09133632481098175,
      "learning_rate": 1.751388888888889e-05,
      "loss": 0.0007,
      "step": 23390
    },
    {
      "epoch": 1.3,
      "grad_norm": 0.05703787878155708,
      "learning_rate": 1.75e-05,
      "loss": 0.0003,
      "step": 23400
    },
    {
      "epoch": 1.3005555555555555,
      "grad_norm": 0.07277348637580872,
      "learning_rate": 1.748611111111111e-05,
      "loss": 0.0007,
      "step": 23410
    },
    {
      "epoch": 1.301111111111111,
      "grad_norm": 0.06681565195322037,
      "learning_rate": 1.7472222222222223e-05,
      "loss": 0.0006,
      "step": 23420
    },
    {
      "epoch": 1.3016666666666667,
      "grad_norm": 0.1879492998123169,
      "learning_rate": 1.7458333333333335e-05,
      "loss": 0.0018,
      "step": 23430
    },
    {
      "epoch": 1.3022222222222222,
      "grad_norm": 0.0,
      "learning_rate": 1.7444444444444448e-05,
      "loss": 0.0009,
      "step": 23440
    },
    {
      "epoch": 1.3027777777777778,
      "grad_norm": 0.0,
      "learning_rate": 1.7430555555555556e-05,
      "loss": 0.0008,
      "step": 23450
    },
    {
      "epoch": 1.3033333333333332,
      "grad_norm": 0.0,
      "learning_rate": 1.741666666666667e-05,
      "loss": 0.0004,
      "step": 23460
    },
    {
      "epoch": 1.3038888888888889,
      "grad_norm": 0.2782307267189026,
      "learning_rate": 1.7402777777777778e-05,
      "loss": 0.0006,
      "step": 23470
    },
    {
      "epoch": 1.3044444444444445,
      "grad_norm": 0.0,
      "learning_rate": 1.738888888888889e-05,
      "loss": 0.0008,
      "step": 23480
    },
    {
      "epoch": 1.305,
      "grad_norm": 0.04843486100435257,
      "learning_rate": 1.7375e-05,
      "loss": 0.0013,
      "step": 23490
    },
    {
      "epoch": 1.3055555555555556,
      "grad_norm": 0.0,
      "learning_rate": 1.736111111111111e-05,
      "loss": 0.0003,
      "step": 23500
    },
    {
      "epoch": 1.306111111111111,
      "grad_norm": 0.09134115278720856,
      "learning_rate": 1.7347222222222223e-05,
      "loss": 0.0004,
      "step": 23510
    },
    {
      "epoch": 1.3066666666666666,
      "grad_norm": 0.046882688999176025,
      "learning_rate": 1.7333333333333336e-05,
      "loss": 0.0005,
      "step": 23520
    },
    {
      "epoch": 1.3072222222222223,
      "grad_norm": 0.04765354469418526,
      "learning_rate": 1.7319444444444448e-05,
      "loss": 0.0006,
      "step": 23530
    },
    {
      "epoch": 1.3077777777777777,
      "grad_norm": 0.036315616220235825,
      "learning_rate": 1.7305555555555557e-05,
      "loss": 0.0006,
      "step": 23540
    },
    {
      "epoch": 1.3083333333333333,
      "grad_norm": 0.13394302129745483,
      "learning_rate": 1.7291666666666666e-05,
      "loss": 0.0008,
      "step": 23550
    },
    {
      "epoch": 1.3088888888888888,
      "grad_norm": 0.048388224095106125,
      "learning_rate": 1.7277777777777778e-05,
      "loss": 0.0004,
      "step": 23560
    },
    {
      "epoch": 1.3094444444444444,
      "grad_norm": 0.19073252379894257,
      "learning_rate": 1.726388888888889e-05,
      "loss": 0.0008,
      "step": 23570
    },
    {
      "epoch": 1.31,
      "grad_norm": 0.049251578748226166,
      "learning_rate": 1.725e-05,
      "loss": 0.0012,
      "step": 23580
    },
    {
      "epoch": 1.3105555555555555,
      "grad_norm": 0.037963125854730606,
      "learning_rate": 1.723611111111111e-05,
      "loss": 0.0006,
      "step": 23590
    },
    {
      "epoch": 1.3111111111111111,
      "grad_norm": 0.0,
      "learning_rate": 1.7222222222222224e-05,
      "loss": 0.0009,
      "step": 23600
    },
    {
      "epoch": 1.3116666666666665,
      "grad_norm": 0.3127293586730957,
      "learning_rate": 1.7208333333333336e-05,
      "loss": 0.0002,
      "step": 23610
    },
    {
      "epoch": 1.3122222222222222,
      "grad_norm": 0.0,
      "learning_rate": 1.7194444444444445e-05,
      "loss": 0.0008,
      "step": 23620
    },
    {
      "epoch": 1.3127777777777778,
      "grad_norm": 0.0,
      "learning_rate": 1.7180555555555554e-05,
      "loss": 0.0003,
      "step": 23630
    },
    {
      "epoch": 1.3133333333333335,
      "grad_norm": 0.054136186838150024,
      "learning_rate": 1.7166666666666666e-05,
      "loss": 0.0005,
      "step": 23640
    },
    {
      "epoch": 1.3138888888888889,
      "grad_norm": 0.054652195423841476,
      "learning_rate": 1.715277777777778e-05,
      "loss": 0.0021,
      "step": 23650
    },
    {
      "epoch": 1.3144444444444445,
      "grad_norm": 0.0,
      "learning_rate": 1.713888888888889e-05,
      "loss": 0.0003,
      "step": 23660
    },
    {
      "epoch": 1.315,
      "grad_norm": 0.08632583171129227,
      "learning_rate": 1.7125000000000003e-05,
      "loss": 0.0018,
      "step": 23670
    },
    {
      "epoch": 1.3155555555555556,
      "grad_norm": 0.33416497707366943,
      "learning_rate": 1.7111111111111112e-05,
      "loss": 0.0003,
      "step": 23680
    },
    {
      "epoch": 1.3161111111111112,
      "grad_norm": 0.2969069182872772,
      "learning_rate": 1.7097222222222224e-05,
      "loss": 0.0003,
      "step": 23690
    },
    {
      "epoch": 1.3166666666666667,
      "grad_norm": 0.0,
      "learning_rate": 1.7083333333333333e-05,
      "loss": 0.0012,
      "step": 23700
    },
    {
      "epoch": 1.3172222222222223,
      "grad_norm": 0.0,
      "learning_rate": 1.7069444444444445e-05,
      "loss": 0.0004,
      "step": 23710
    },
    {
      "epoch": 1.3177777777777777,
      "grad_norm": 0.0,
      "learning_rate": 1.7055555555555554e-05,
      "loss": 0.0001,
      "step": 23720
    },
    {
      "epoch": 1.3183333333333334,
      "grad_norm": 0.04425402358174324,
      "learning_rate": 1.7041666666666666e-05,
      "loss": 0.0005,
      "step": 23730
    },
    {
      "epoch": 1.318888888888889,
      "grad_norm": 0.0,
      "learning_rate": 1.702777777777778e-05,
      "loss": 0.0008,
      "step": 23740
    },
    {
      "epoch": 1.3194444444444444,
      "grad_norm": 0.29488909244537354,
      "learning_rate": 1.701388888888889e-05,
      "loss": 0.0005,
      "step": 23750
    },
    {
      "epoch": 1.32,
      "grad_norm": 0.0,
      "learning_rate": 1.7000000000000003e-05,
      "loss": 0.0002,
      "step": 23760
    },
    {
      "epoch": 1.3205555555555555,
      "grad_norm": 0.15629148483276367,
      "learning_rate": 1.6986111111111112e-05,
      "loss": 0.0004,
      "step": 23770
    },
    {
      "epoch": 1.3211111111111111,
      "grad_norm": 0.11738230288028717,
      "learning_rate": 1.697222222222222e-05,
      "loss": 0.0005,
      "step": 23780
    },
    {
      "epoch": 1.3216666666666668,
      "grad_norm": 0.0,
      "learning_rate": 1.6958333333333333e-05,
      "loss": 0.0005,
      "step": 23790
    },
    {
      "epoch": 1.3222222222222222,
      "grad_norm": 0.0,
      "learning_rate": 1.6944444444444446e-05,
      "loss": 0.0004,
      "step": 23800
    },
    {
      "epoch": 1.3227777777777778,
      "grad_norm": 0.13182885944843292,
      "learning_rate": 1.6930555555555554e-05,
      "loss": 0.0005,
      "step": 23810
    },
    {
      "epoch": 1.3233333333333333,
      "grad_norm": 0.0,
      "learning_rate": 1.6916666666666667e-05,
      "loss": 0.0008,
      "step": 23820
    },
    {
      "epoch": 1.323888888888889,
      "grad_norm": 0.16309860348701477,
      "learning_rate": 1.690277777777778e-05,
      "loss": 0.0007,
      "step": 23830
    },
    {
      "epoch": 1.3244444444444445,
      "grad_norm": 0.045647475868463516,
      "learning_rate": 1.688888888888889e-05,
      "loss": 0.0003,
      "step": 23840
    },
    {
      "epoch": 1.325,
      "grad_norm": 0.0,
      "learning_rate": 1.6875000000000004e-05,
      "loss": 0.0008,
      "step": 23850
    },
    {
      "epoch": 1.3255555555555556,
      "grad_norm": 0.2753596007823944,
      "learning_rate": 1.6861111111111112e-05,
      "loss": 0.0006,
      "step": 23860
    },
    {
      "epoch": 1.326111111111111,
      "grad_norm": 0.24025201797485352,
      "learning_rate": 1.684722222222222e-05,
      "loss": 0.0022,
      "step": 23870
    },
    {
      "epoch": 1.3266666666666667,
      "grad_norm": 0.4365665018558502,
      "learning_rate": 1.6833333333333334e-05,
      "loss": 0.0007,
      "step": 23880
    },
    {
      "epoch": 1.3272222222222223,
      "grad_norm": 0.09225945174694061,
      "learning_rate": 1.6819444444444446e-05,
      "loss": 0.0006,
      "step": 23890
    },
    {
      "epoch": 1.3277777777777777,
      "grad_norm": 0.0,
      "learning_rate": 1.6805555555555558e-05,
      "loss": 0.0009,
      "step": 23900
    },
    {
      "epoch": 1.3283333333333334,
      "grad_norm": 0.05071408674120903,
      "learning_rate": 1.6791666666666667e-05,
      "loss": 0.0006,
      "step": 23910
    },
    {
      "epoch": 1.3288888888888888,
      "grad_norm": 0.0,
      "learning_rate": 1.677777777777778e-05,
      "loss": 0.0011,
      "step": 23920
    },
    {
      "epoch": 1.3294444444444444,
      "grad_norm": 0.04843616858124733,
      "learning_rate": 1.676388888888889e-05,
      "loss": 0.0004,
      "step": 23930
    },
    {
      "epoch": 1.33,
      "grad_norm": 0.16738654673099518,
      "learning_rate": 1.675e-05,
      "loss": 0.0008,
      "step": 23940
    },
    {
      "epoch": 1.3305555555555555,
      "grad_norm": 0.052848462015390396,
      "learning_rate": 1.673611111111111e-05,
      "loss": 0.0013,
      "step": 23950
    },
    {
      "epoch": 1.3311111111111111,
      "grad_norm": 0.0,
      "learning_rate": 1.6722222222222222e-05,
      "loss": 0.0004,
      "step": 23960
    },
    {
      "epoch": 1.3316666666666666,
      "grad_norm": 0.04413345083594322,
      "learning_rate": 1.6708333333333334e-05,
      "loss": 0.0006,
      "step": 23970
    },
    {
      "epoch": 1.3322222222222222,
      "grad_norm": 0.07275714725255966,
      "learning_rate": 1.6694444444444446e-05,
      "loss": 0.001,
      "step": 23980
    },
    {
      "epoch": 1.3327777777777778,
      "grad_norm": 0.051363248378038406,
      "learning_rate": 1.668055555555556e-05,
      "loss": 0.0008,
      "step": 23990
    },
    {
      "epoch": 1.3333333333333333,
      "grad_norm": 0.14494569599628448,
      "learning_rate": 1.6666666666666667e-05,
      "loss": 0.0007,
      "step": 24000
    },
    {
      "epoch": 1.333888888888889,
      "grad_norm": 0.19381549954414368,
      "learning_rate": 1.665277777777778e-05,
      "loss": 0.0015,
      "step": 24010
    },
    {
      "epoch": 1.3344444444444443,
      "grad_norm": 0.0,
      "learning_rate": 1.663888888888889e-05,
      "loss": 0.0005,
      "step": 24020
    },
    {
      "epoch": 1.335,
      "grad_norm": 0.04472234845161438,
      "learning_rate": 1.6625e-05,
      "loss": 0.0013,
      "step": 24030
    },
    {
      "epoch": 1.3355555555555556,
      "grad_norm": 0.28934362530708313,
      "learning_rate": 1.661111111111111e-05,
      "loss": 0.0004,
      "step": 24040
    },
    {
      "epoch": 1.3361111111111112,
      "grad_norm": 0.0,
      "learning_rate": 1.6597222222222222e-05,
      "loss": 0.0014,
      "step": 24050
    },
    {
      "epoch": 1.3366666666666667,
      "grad_norm": 0.2877817749977112,
      "learning_rate": 1.6583333333333334e-05,
      "loss": 0.0005,
      "step": 24060
    },
    {
      "epoch": 1.337222222222222,
      "grad_norm": 0.17546606063842773,
      "learning_rate": 1.6569444444444447e-05,
      "loss": 0.0012,
      "step": 24070
    },
    {
      "epoch": 1.3377777777777777,
      "grad_norm": 0.050335802137851715,
      "learning_rate": 1.655555555555556e-05,
      "loss": 0.0009,
      "step": 24080
    },
    {
      "epoch": 1.3383333333333334,
      "grad_norm": 0.0,
      "learning_rate": 1.6541666666666668e-05,
      "loss": 0.0005,
      "step": 24090
    },
    {
      "epoch": 1.338888888888889,
      "grad_norm": 0.03089122660458088,
      "learning_rate": 1.6527777777777777e-05,
      "loss": 0.0002,
      "step": 24100
    },
    {
      "epoch": 1.3394444444444444,
      "grad_norm": 0.048640284687280655,
      "learning_rate": 1.651388888888889e-05,
      "loss": 0.0008,
      "step": 24110
    },
    {
      "epoch": 1.34,
      "grad_norm": 0.04328743740916252,
      "learning_rate": 1.65e-05,
      "loss": 0.0004,
      "step": 24120
    },
    {
      "epoch": 1.3405555555555555,
      "grad_norm": 0.0,
      "learning_rate": 1.6486111111111114e-05,
      "loss": 0.0005,
      "step": 24130
    },
    {
      "epoch": 1.3411111111111111,
      "grad_norm": 0.0,
      "learning_rate": 1.6472222222222222e-05,
      "loss": 0.0002,
      "step": 24140
    },
    {
      "epoch": 1.3416666666666668,
      "grad_norm": 0.0505903922021389,
      "learning_rate": 1.6458333333333335e-05,
      "loss": 0.0012,
      "step": 24150
    },
    {
      "epoch": 1.3422222222222222,
      "grad_norm": 0.044998299330472946,
      "learning_rate": 1.6444444444444447e-05,
      "loss": 0.0008,
      "step": 24160
    },
    {
      "epoch": 1.3427777777777778,
      "grad_norm": 0.0,
      "learning_rate": 1.6430555555555556e-05,
      "loss": 0.0001,
      "step": 24170
    },
    {
      "epoch": 1.3433333333333333,
      "grad_norm": 0.1833595484495163,
      "learning_rate": 1.6416666666666665e-05,
      "loss": 0.0004,
      "step": 24180
    },
    {
      "epoch": 1.343888888888889,
      "grad_norm": 0.27364620566368103,
      "learning_rate": 1.6402777777777777e-05,
      "loss": 0.0011,
      "step": 24190
    },
    {
      "epoch": 1.3444444444444446,
      "grad_norm": 0.23999816179275513,
      "learning_rate": 1.638888888888889e-05,
      "loss": 0.0004,
      "step": 24200
    },
    {
      "epoch": 1.345,
      "grad_norm": 0.0,
      "learning_rate": 1.6375e-05,
      "loss": 0.0006,
      "step": 24210
    },
    {
      "epoch": 1.3455555555555556,
      "grad_norm": 0.0,
      "learning_rate": 1.6361111111111114e-05,
      "loss": 0.0004,
      "step": 24220
    },
    {
      "epoch": 1.346111111111111,
      "grad_norm": 0.092937171459198,
      "learning_rate": 1.6347222222222223e-05,
      "loss": 0.0006,
      "step": 24230
    },
    {
      "epoch": 1.3466666666666667,
      "grad_norm": 0.04833035543560982,
      "learning_rate": 1.6333333333333335e-05,
      "loss": 0.0001,
      "step": 24240
    },
    {
      "epoch": 1.3472222222222223,
      "grad_norm": 0.0,
      "learning_rate": 1.6319444444444444e-05,
      "loss": 0.001,
      "step": 24250
    },
    {
      "epoch": 1.3477777777777777,
      "grad_norm": 0.0,
      "learning_rate": 1.6305555555555556e-05,
      "loss": 0.0003,
      "step": 24260
    },
    {
      "epoch": 1.3483333333333334,
      "grad_norm": 0.1464371532201767,
      "learning_rate": 1.6291666666666665e-05,
      "loss": 0.0003,
      "step": 24270
    },
    {
      "epoch": 1.3488888888888888,
      "grad_norm": 0.30963844060897827,
      "learning_rate": 1.6277777777777777e-05,
      "loss": 0.0009,
      "step": 24280
    },
    {
      "epoch": 1.3494444444444444,
      "grad_norm": 0.3573177754878998,
      "learning_rate": 1.626388888888889e-05,
      "loss": 0.0004,
      "step": 24290
    },
    {
      "epoch": 1.35,
      "grad_norm": 0.1951090395450592,
      "learning_rate": 1.6250000000000002e-05,
      "loss": 0.0007,
      "step": 24300
    },
    {
      "epoch": 1.3505555555555555,
      "grad_norm": 0.049617283046245575,
      "learning_rate": 1.6236111111111114e-05,
      "loss": 0.0009,
      "step": 24310
    },
    {
      "epoch": 1.3511111111111112,
      "grad_norm": 0.16789013147354126,
      "learning_rate": 1.6222222222222223e-05,
      "loss": 0.0003,
      "step": 24320
    },
    {
      "epoch": 1.3516666666666666,
      "grad_norm": 0.058217182755470276,
      "learning_rate": 1.6208333333333332e-05,
      "loss": 0.0008,
      "step": 24330
    },
    {
      "epoch": 1.3522222222222222,
      "grad_norm": 0.05594886466860771,
      "learning_rate": 1.6194444444444444e-05,
      "loss": 0.0004,
      "step": 24340
    },
    {
      "epoch": 1.3527777777777779,
      "grad_norm": 0.079776830971241,
      "learning_rate": 1.6180555555555557e-05,
      "loss": 0.001,
      "step": 24350
    },
    {
      "epoch": 1.3533333333333333,
      "grad_norm": 0.0,
      "learning_rate": 1.6166666666666665e-05,
      "loss": 0.0003,
      "step": 24360
    },
    {
      "epoch": 1.353888888888889,
      "grad_norm": 0.0,
      "learning_rate": 1.6152777777777778e-05,
      "loss": 0.0002,
      "step": 24370
    },
    {
      "epoch": 1.3544444444444443,
      "grad_norm": 0.0,
      "learning_rate": 1.613888888888889e-05,
      "loss": 0.0013,
      "step": 24380
    },
    {
      "epoch": 1.355,
      "grad_norm": 0.046179067343473434,
      "learning_rate": 1.6125000000000002e-05,
      "loss": 0.0003,
      "step": 24390
    },
    {
      "epoch": 1.3555555555555556,
      "grad_norm": 0.0,
      "learning_rate": 1.6111111111111115e-05,
      "loss": 0.0014,
      "step": 24400
    },
    {
      "epoch": 1.356111111111111,
      "grad_norm": 0.0,
      "learning_rate": 1.6097222222222223e-05,
      "loss": 0.0008,
      "step": 24410
    },
    {
      "epoch": 1.3566666666666667,
      "grad_norm": 0.0,
      "learning_rate": 1.6083333333333332e-05,
      "loss": 0.0003,
      "step": 24420
    },
    {
      "epoch": 1.357222222222222,
      "grad_norm": 0.0801776722073555,
      "learning_rate": 1.6069444444444445e-05,
      "loss": 0.0002,
      "step": 24430
    },
    {
      "epoch": 1.3577777777777778,
      "grad_norm": 0.09189414232969284,
      "learning_rate": 1.6055555555555557e-05,
      "loss": 0.0002,
      "step": 24440
    },
    {
      "epoch": 1.3583333333333334,
      "grad_norm": 0.0,
      "learning_rate": 1.604166666666667e-05,
      "loss": 0.0007,
      "step": 24450
    },
    {
      "epoch": 1.3588888888888888,
      "grad_norm": 0.05102657526731491,
      "learning_rate": 1.6027777777777778e-05,
      "loss": 0.0008,
      "step": 24460
    },
    {
      "epoch": 1.3594444444444445,
      "grad_norm": 0.0892641618847847,
      "learning_rate": 1.601388888888889e-05,
      "loss": 0.0009,
      "step": 24470
    },
    {
      "epoch": 1.3599999999999999,
      "grad_norm": 0.03321652486920357,
      "learning_rate": 1.6000000000000003e-05,
      "loss": 0.0015,
      "step": 24480
    },
    {
      "epoch": 1.3605555555555555,
      "grad_norm": 0.0,
      "learning_rate": 1.598611111111111e-05,
      "loss": 0.0005,
      "step": 24490
    },
    {
      "epoch": 1.3611111111111112,
      "grad_norm": 0.043530553579330444,
      "learning_rate": 1.597222222222222e-05,
      "loss": 0.001,
      "step": 24500
    },
    {
      "epoch": 1.3616666666666668,
      "grad_norm": 0.49561089277267456,
      "learning_rate": 1.5958333333333333e-05,
      "loss": 0.001,
      "step": 24510
    },
    {
      "epoch": 1.3622222222222222,
      "grad_norm": 0.21461570262908936,
      "learning_rate": 1.5944444444444445e-05,
      "loss": 0.0004,
      "step": 24520
    },
    {
      "epoch": 1.3627777777777776,
      "grad_norm": 0.0,
      "learning_rate": 1.5930555555555557e-05,
      "loss": 0.0004,
      "step": 24530
    },
    {
      "epoch": 1.3633333333333333,
      "grad_norm": 0.0,
      "learning_rate": 1.591666666666667e-05,
      "loss": 0.0008,
      "step": 24540
    },
    {
      "epoch": 1.363888888888889,
      "grad_norm": 0.0,
      "learning_rate": 1.590277777777778e-05,
      "loss": 0.0002,
      "step": 24550
    },
    {
      "epoch": 1.3644444444444446,
      "grad_norm": 0.0,
      "learning_rate": 1.588888888888889e-05,
      "loss": 0.0011,
      "step": 24560
    },
    {
      "epoch": 1.365,
      "grad_norm": 0.0,
      "learning_rate": 1.5875e-05,
      "loss": 0.0002,
      "step": 24570
    },
    {
      "epoch": 1.3655555555555556,
      "grad_norm": 0.05763969197869301,
      "learning_rate": 1.5861111111111112e-05,
      "loss": 0.0009,
      "step": 24580
    },
    {
      "epoch": 1.366111111111111,
      "grad_norm": 0.05028625205159187,
      "learning_rate": 1.584722222222222e-05,
      "loss": 0.0008,
      "step": 24590
    },
    {
      "epoch": 1.3666666666666667,
      "grad_norm": 0.0,
      "learning_rate": 1.5833333333333333e-05,
      "loss": 0.0003,
      "step": 24600
    },
    {
      "epoch": 1.3672222222222223,
      "grad_norm": 0.2796744108200073,
      "learning_rate": 1.5819444444444445e-05,
      "loss": 0.0008,
      "step": 24610
    },
    {
      "epoch": 1.3677777777777778,
      "grad_norm": 0.0,
      "learning_rate": 1.5805555555555558e-05,
      "loss": 0.0001,
      "step": 24620
    },
    {
      "epoch": 1.3683333333333334,
      "grad_norm": 0.04759230837225914,
      "learning_rate": 1.579166666666667e-05,
      "loss": 0.0007,
      "step": 24630
    },
    {
      "epoch": 1.3688888888888888,
      "grad_norm": 0.2619056701660156,
      "learning_rate": 1.577777777777778e-05,
      "loss": 0.0009,
      "step": 24640
    },
    {
      "epoch": 1.3694444444444445,
      "grad_norm": 0.28569239377975464,
      "learning_rate": 1.5763888888888888e-05,
      "loss": 0.001,
      "step": 24650
    },
    {
      "epoch": 1.37,
      "grad_norm": 0.350202739238739,
      "learning_rate": 1.575e-05,
      "loss": 0.0007,
      "step": 24660
    },
    {
      "epoch": 1.3705555555555555,
      "grad_norm": 0.0968022495508194,
      "learning_rate": 1.5736111111111112e-05,
      "loss": 0.0013,
      "step": 24670
    },
    {
      "epoch": 1.3711111111111112,
      "grad_norm": 0.0,
      "learning_rate": 1.5722222222222225e-05,
      "loss": 0.0002,
      "step": 24680
    },
    {
      "epoch": 1.3716666666666666,
      "grad_norm": 0.0,
      "learning_rate": 1.5708333333333333e-05,
      "loss": 0.0006,
      "step": 24690
    },
    {
      "epoch": 1.3722222222222222,
      "grad_norm": 0.1868867576122284,
      "learning_rate": 1.5694444444444446e-05,
      "loss": 0.0009,
      "step": 24700
    },
    {
      "epoch": 1.3727777777777779,
      "grad_norm": 0.0,
      "learning_rate": 1.5680555555555558e-05,
      "loss": 0.0006,
      "step": 24710
    },
    {
      "epoch": 1.3733333333333333,
      "grad_norm": 0.05084940046072006,
      "learning_rate": 1.5666666666666667e-05,
      "loss": 0.0006,
      "step": 24720
    },
    {
      "epoch": 1.373888888888889,
      "grad_norm": 0.04328690841794014,
      "learning_rate": 1.5652777777777776e-05,
      "loss": 0.0016,
      "step": 24730
    },
    {
      "epoch": 1.3744444444444444,
      "grad_norm": 0.04499078914523125,
      "learning_rate": 1.5638888888888888e-05,
      "loss": 0.0006,
      "step": 24740
    },
    {
      "epoch": 1.375,
      "grad_norm": 0.08957236260175705,
      "learning_rate": 1.5625e-05,
      "loss": 0.0006,
      "step": 24750
    },
    {
      "epoch": 1.3755555555555556,
      "grad_norm": 0.0,
      "learning_rate": 1.5611111111111113e-05,
      "loss": 0.0002,
      "step": 24760
    },
    {
      "epoch": 1.376111111111111,
      "grad_norm": 0.05822988972067833,
      "learning_rate": 1.5597222222222225e-05,
      "loss": 0.0011,
      "step": 24770
    },
    {
      "epoch": 1.3766666666666667,
      "grad_norm": 0.0,
      "learning_rate": 1.5583333333333334e-05,
      "loss": 0.0002,
      "step": 24780
    },
    {
      "epoch": 1.3772222222222221,
      "grad_norm": 0.0,
      "learning_rate": 1.5569444444444446e-05,
      "loss": 0.0015,
      "step": 24790
    },
    {
      "epoch": 1.3777777777777778,
      "grad_norm": 0.3547377288341522,
      "learning_rate": 1.5555555555555555e-05,
      "loss": 0.0009,
      "step": 24800
    },
    {
      "epoch": 1.3783333333333334,
      "grad_norm": 0.0,
      "learning_rate": 1.5541666666666667e-05,
      "loss": 0.0005,
      "step": 24810
    },
    {
      "epoch": 1.3788888888888888,
      "grad_norm": 0.4106125831604004,
      "learning_rate": 1.5527777777777776e-05,
      "loss": 0.001,
      "step": 24820
    },
    {
      "epoch": 1.3794444444444445,
      "grad_norm": 0.0,
      "learning_rate": 1.551388888888889e-05,
      "loss": 0.0011,
      "step": 24830
    },
    {
      "epoch": 1.38,
      "grad_norm": 0.20044055581092834,
      "learning_rate": 1.55e-05,
      "loss": 0.0005,
      "step": 24840
    },
    {
      "epoch": 1.3805555555555555,
      "grad_norm": 0.08899592608213425,
      "learning_rate": 1.5486111111111113e-05,
      "loss": 0.0012,
      "step": 24850
    },
    {
      "epoch": 1.3811111111111112,
      "grad_norm": 0.0,
      "learning_rate": 1.5472222222222225e-05,
      "loss": 0.0001,
      "step": 24860
    },
    {
      "epoch": 1.3816666666666666,
      "grad_norm": 0.0,
      "learning_rate": 1.5458333333333334e-05,
      "loss": 0.0002,
      "step": 24870
    },
    {
      "epoch": 1.3822222222222222,
      "grad_norm": 0.13716399669647217,
      "learning_rate": 1.5444444444444446e-05,
      "loss": 0.0002,
      "step": 24880
    },
    {
      "epoch": 1.3827777777777777,
      "grad_norm": 0.09644690901041031,
      "learning_rate": 1.5430555555555555e-05,
      "loss": 0.0004,
      "step": 24890
    },
    {
      "epoch": 1.3833333333333333,
      "grad_norm": 0.05019048601388931,
      "learning_rate": 1.5416666666666668e-05,
      "loss": 0.0008,
      "step": 24900
    },
    {
      "epoch": 1.383888888888889,
      "grad_norm": 0.050264451652765274,
      "learning_rate": 1.540277777777778e-05,
      "loss": 0.001,
      "step": 24910
    },
    {
      "epoch": 1.3844444444444444,
      "grad_norm": 0.05943034589290619,
      "learning_rate": 1.538888888888889e-05,
      "loss": 0.0012,
      "step": 24920
    },
    {
      "epoch": 1.385,
      "grad_norm": 0.16344648599624634,
      "learning_rate": 1.5375e-05,
      "loss": 0.0008,
      "step": 24930
    },
    {
      "epoch": 1.3855555555555554,
      "grad_norm": 0.0,
      "learning_rate": 1.5361111111111113e-05,
      "loss": 0.0006,
      "step": 24940
    },
    {
      "epoch": 1.386111111111111,
      "grad_norm": 0.271674782037735,
      "learning_rate": 1.5347222222222226e-05,
      "loss": 0.0007,
      "step": 24950
    },
    {
      "epoch": 1.3866666666666667,
      "grad_norm": 0.09645885229110718,
      "learning_rate": 1.5333333333333334e-05,
      "loss": 0.0005,
      "step": 24960
    },
    {
      "epoch": 1.3872222222222224,
      "grad_norm": 0.04687207564711571,
      "learning_rate": 1.5319444444444443e-05,
      "loss": 0.0004,
      "step": 24970
    },
    {
      "epoch": 1.3877777777777778,
      "grad_norm": 0.052468862384557724,
      "learning_rate": 1.5305555555555556e-05,
      "loss": 0.0009,
      "step": 24980
    },
    {
      "epoch": 1.3883333333333332,
      "grad_norm": 0.04536932334303856,
      "learning_rate": 1.5291666666666668e-05,
      "loss": 0.0009,
      "step": 24990
    },
    {
      "epoch": 1.3888888888888888,
      "grad_norm": 0.0,
      "learning_rate": 1.527777777777778e-05,
      "loss": 0.0007,
      "step": 25000
    },
    {
      "epoch": 1.3894444444444445,
      "grad_norm": 0.04934801533818245,
      "learning_rate": 1.526388888888889e-05,
      "loss": 0.0006,
      "step": 25010
    },
    {
      "epoch": 1.3900000000000001,
      "grad_norm": 0.0,
      "learning_rate": 1.525e-05,
      "loss": 0.0016,
      "step": 25020
    },
    {
      "epoch": 1.3905555555555555,
      "grad_norm": 0.10137404501438141,
      "learning_rate": 1.5236111111111112e-05,
      "loss": 0.0005,
      "step": 25030
    },
    {
      "epoch": 1.3911111111111112,
      "grad_norm": 0.28850656747817993,
      "learning_rate": 1.5222222222222224e-05,
      "loss": 0.0009,
      "step": 25040
    },
    {
      "epoch": 1.3916666666666666,
      "grad_norm": 0.41576918959617615,
      "learning_rate": 1.5208333333333333e-05,
      "loss": 0.0005,
      "step": 25050
    },
    {
      "epoch": 1.3922222222222222,
      "grad_norm": 0.0,
      "learning_rate": 1.5194444444444444e-05,
      "loss": 0.0014,
      "step": 25060
    },
    {
      "epoch": 1.392777777777778,
      "grad_norm": 0.05112679302692413,
      "learning_rate": 1.5180555555555556e-05,
      "loss": 0.0006,
      "step": 25070
    },
    {
      "epoch": 1.3933333333333333,
      "grad_norm": 0.2971506714820862,
      "learning_rate": 1.5166666666666668e-05,
      "loss": 0.0004,
      "step": 25080
    },
    {
      "epoch": 1.393888888888889,
      "grad_norm": 0.0,
      "learning_rate": 1.5152777777777779e-05,
      "loss": 0.0003,
      "step": 25090
    },
    {
      "epoch": 1.3944444444444444,
      "grad_norm": 0.0,
      "learning_rate": 1.5138888888888888e-05,
      "loss": 0.0007,
      "step": 25100
    },
    {
      "epoch": 1.395,
      "grad_norm": 0.10114182531833649,
      "learning_rate": 1.5125e-05,
      "loss": 0.0009,
      "step": 25110
    },
    {
      "epoch": 1.3955555555555557,
      "grad_norm": 0.04700242727994919,
      "learning_rate": 1.5111111111111112e-05,
      "loss": 0.0004,
      "step": 25120
    },
    {
      "epoch": 1.396111111111111,
      "grad_norm": 0.20869451761245728,
      "learning_rate": 1.5097222222222223e-05,
      "loss": 0.0004,
      "step": 25130
    },
    {
      "epoch": 1.3966666666666667,
      "grad_norm": 0.0,
      "learning_rate": 1.5083333333333335e-05,
      "loss": 0.0006,
      "step": 25140
    },
    {
      "epoch": 1.3972222222222221,
      "grad_norm": 0.0,
      "learning_rate": 1.5069444444444444e-05,
      "loss": 0.0005,
      "step": 25150
    },
    {
      "epoch": 1.3977777777777778,
      "grad_norm": 0.056445904076099396,
      "learning_rate": 1.5055555555555556e-05,
      "loss": 0.0003,
      "step": 25160
    },
    {
      "epoch": 1.3983333333333334,
      "grad_norm": 0.0,
      "learning_rate": 1.5041666666666669e-05,
      "loss": 0.0002,
      "step": 25170
    },
    {
      "epoch": 1.3988888888888888,
      "grad_norm": 0.0,
      "learning_rate": 1.502777777777778e-05,
      "loss": 0.001,
      "step": 25180
    },
    {
      "epoch": 1.3994444444444445,
      "grad_norm": 0.0,
      "learning_rate": 1.5013888888888888e-05,
      "loss": 0.0003,
      "step": 25190
    },
    {
      "epoch": 1.4,
      "grad_norm": 0.09174878150224686,
      "learning_rate": 1.5e-05,
      "loss": 0.0005,
      "step": 25200
    },
    {
      "epoch": 1.4005555555555556,
      "grad_norm": 0.0,
      "learning_rate": 1.4986111111111113e-05,
      "loss": 0.0014,
      "step": 25210
    },
    {
      "epoch": 1.4011111111111112,
      "grad_norm": 0.04963089898228645,
      "learning_rate": 1.4972222222222223e-05,
      "loss": 0.0007,
      "step": 25220
    },
    {
      "epoch": 1.4016666666666666,
      "grad_norm": 0.049167342483997345,
      "learning_rate": 1.4958333333333336e-05,
      "loss": 0.0014,
      "step": 25230
    },
    {
      "epoch": 1.4022222222222223,
      "grad_norm": 0.0,
      "learning_rate": 1.4944444444444444e-05,
      "loss": 0.0005,
      "step": 25240
    },
    {
      "epoch": 1.4027777777777777,
      "grad_norm": 0.0,
      "learning_rate": 1.4930555555555557e-05,
      "loss": 0.0002,
      "step": 25250
    },
    {
      "epoch": 1.4033333333333333,
      "grad_norm": 0.2980935275554657,
      "learning_rate": 1.4916666666666667e-05,
      "loss": 0.0012,
      "step": 25260
    },
    {
      "epoch": 1.403888888888889,
      "grad_norm": 0.04660959169268608,
      "learning_rate": 1.490277777777778e-05,
      "loss": 0.0007,
      "step": 25270
    },
    {
      "epoch": 1.4044444444444444,
      "grad_norm": 0.2548864483833313,
      "learning_rate": 1.4888888888888888e-05,
      "loss": 0.0011,
      "step": 25280
    },
    {
      "epoch": 1.405,
      "grad_norm": 0.0,
      "learning_rate": 1.4875e-05,
      "loss": 0.0001,
      "step": 25290
    },
    {
      "epoch": 1.4055555555555554,
      "grad_norm": 0.1366845667362213,
      "learning_rate": 1.4861111111111111e-05,
      "loss": 0.0003,
      "step": 25300
    },
    {
      "epoch": 1.406111111111111,
      "grad_norm": 0.0,
      "learning_rate": 1.4847222222222224e-05,
      "loss": 0.0003,
      "step": 25310
    },
    {
      "epoch": 1.4066666666666667,
      "grad_norm": 0.12616227567195892,
      "learning_rate": 1.4833333333333336e-05,
      "loss": 0.0005,
      "step": 25320
    },
    {
      "epoch": 1.4072222222222222,
      "grad_norm": 0.20452027022838593,
      "learning_rate": 1.4819444444444445e-05,
      "loss": 0.0012,
      "step": 25330
    },
    {
      "epoch": 1.4077777777777778,
      "grad_norm": 0.0,
      "learning_rate": 1.4805555555555555e-05,
      "loss": 0.0005,
      "step": 25340
    },
    {
      "epoch": 1.4083333333333332,
      "grad_norm": 0.036563802510499954,
      "learning_rate": 1.4791666666666668e-05,
      "loss": 0.0009,
      "step": 25350
    },
    {
      "epoch": 1.4088888888888889,
      "grad_norm": 0.048344384878873825,
      "learning_rate": 1.477777777777778e-05,
      "loss": 0.0005,
      "step": 25360
    },
    {
      "epoch": 1.4094444444444445,
      "grad_norm": 0.09659086912870407,
      "learning_rate": 1.4763888888888889e-05,
      "loss": 0.0003,
      "step": 25370
    },
    {
      "epoch": 1.41,
      "grad_norm": 0.04347268119454384,
      "learning_rate": 1.475e-05,
      "loss": 0.0006,
      "step": 25380
    },
    {
      "epoch": 1.4105555555555556,
      "grad_norm": 0.0,
      "learning_rate": 1.4736111111111112e-05,
      "loss": 0.0006,
      "step": 25390
    },
    {
      "epoch": 1.411111111111111,
      "grad_norm": 0.23715636134147644,
      "learning_rate": 1.4722222222222224e-05,
      "loss": 0.0009,
      "step": 25400
    },
    {
      "epoch": 1.4116666666666666,
      "grad_norm": 0.18960171937942505,
      "learning_rate": 1.4708333333333335e-05,
      "loss": 0.0007,
      "step": 25410
    },
    {
      "epoch": 1.4122222222222223,
      "grad_norm": 0.03180425241589546,
      "learning_rate": 1.4694444444444443e-05,
      "loss": 0.001,
      "step": 25420
    },
    {
      "epoch": 1.412777777777778,
      "grad_norm": 0.26317107677459717,
      "learning_rate": 1.4680555555555556e-05,
      "loss": 0.0008,
      "step": 25430
    },
    {
      "epoch": 1.4133333333333333,
      "grad_norm": 0.04562942683696747,
      "learning_rate": 1.4666666666666668e-05,
      "loss": 0.0006,
      "step": 25440
    },
    {
      "epoch": 1.4138888888888888,
      "grad_norm": 0.05135186016559601,
      "learning_rate": 1.4652777777777779e-05,
      "loss": 0.0008,
      "step": 25450
    },
    {
      "epoch": 1.4144444444444444,
      "grad_norm": 0.0,
      "learning_rate": 1.463888888888889e-05,
      "loss": 0.0012,
      "step": 25460
    },
    {
      "epoch": 1.415,
      "grad_norm": 0.28228870034217834,
      "learning_rate": 1.4625e-05,
      "loss": 0.0011,
      "step": 25470
    },
    {
      "epoch": 1.4155555555555557,
      "grad_norm": 0.08188129961490631,
      "learning_rate": 1.4611111111111112e-05,
      "loss": 0.0009,
      "step": 25480
    },
    {
      "epoch": 1.416111111111111,
      "grad_norm": 0.047073427587747574,
      "learning_rate": 1.4597222222222223e-05,
      "loss": 0.0019,
      "step": 25490
    },
    {
      "epoch": 1.4166666666666667,
      "grad_norm": 0.08841080963611603,
      "learning_rate": 1.4583333333333335e-05,
      "loss": 0.001,
      "step": 25500
    },
    {
      "epoch": 1.4172222222222222,
      "grad_norm": 0.02978936955332756,
      "learning_rate": 1.4569444444444444e-05,
      "loss": 0.0006,
      "step": 25510
    },
    {
      "epoch": 1.4177777777777778,
      "grad_norm": 0.0,
      "learning_rate": 1.4555555555555556e-05,
      "loss": 0.0005,
      "step": 25520
    },
    {
      "epoch": 1.4183333333333334,
      "grad_norm": 0.1872173547744751,
      "learning_rate": 1.4541666666666667e-05,
      "loss": 0.0015,
      "step": 25530
    },
    {
      "epoch": 1.4188888888888889,
      "grad_norm": 0.0,
      "learning_rate": 1.4527777777777779e-05,
      "loss": 0.0003,
      "step": 25540
    },
    {
      "epoch": 1.4194444444444445,
      "grad_norm": 0.0,
      "learning_rate": 1.4513888888888891e-05,
      "loss": 0.0009,
      "step": 25550
    },
    {
      "epoch": 1.42,
      "grad_norm": 0.0,
      "learning_rate": 1.45e-05,
      "loss": 0.0008,
      "step": 25560
    },
    {
      "epoch": 1.4205555555555556,
      "grad_norm": 0.1602843850851059,
      "learning_rate": 1.448611111111111e-05,
      "loss": 0.0012,
      "step": 25570
    },
    {
      "epoch": 1.4211111111111112,
      "grad_norm": 0.08703534305095673,
      "learning_rate": 1.4472222222222223e-05,
      "loss": 0.0006,
      "step": 25580
    },
    {
      "epoch": 1.4216666666666666,
      "grad_norm": 0.0,
      "learning_rate": 1.4458333333333335e-05,
      "loss": 0.0007,
      "step": 25590
    },
    {
      "epoch": 1.4222222222222223,
      "grad_norm": 0.0,
      "learning_rate": 1.4444444444444444e-05,
      "loss": 0.0005,
      "step": 25600
    },
    {
      "epoch": 1.4227777777777777,
      "grad_norm": 0.19981014728546143,
      "learning_rate": 1.4430555555555555e-05,
      "loss": 0.0006,
      "step": 25610
    },
    {
      "epoch": 1.4233333333333333,
      "grad_norm": 0.09644792973995209,
      "learning_rate": 1.4416666666666667e-05,
      "loss": 0.0019,
      "step": 25620
    },
    {
      "epoch": 1.423888888888889,
      "grad_norm": 0.09204795211553574,
      "learning_rate": 1.440277777777778e-05,
      "loss": 0.0015,
      "step": 25630
    },
    {
      "epoch": 1.4244444444444444,
      "grad_norm": 0.0,
      "learning_rate": 1.438888888888889e-05,
      "loss": 0.0003,
      "step": 25640
    },
    {
      "epoch": 1.425,
      "grad_norm": 0.0,
      "learning_rate": 1.4374999999999999e-05,
      "loss": 0.0002,
      "step": 25650
    },
    {
      "epoch": 1.4255555555555555,
      "grad_norm": 0.0,
      "learning_rate": 1.4361111111111111e-05,
      "loss": 0.0004,
      "step": 25660
    },
    {
      "epoch": 1.426111111111111,
      "grad_norm": 0.036475133150815964,
      "learning_rate": 1.4347222222222223e-05,
      "loss": 0.0004,
      "step": 25670
    },
    {
      "epoch": 1.4266666666666667,
      "grad_norm": 0.0,
      "learning_rate": 1.4333333333333334e-05,
      "loss": 0.0007,
      "step": 25680
    },
    {
      "epoch": 1.4272222222222222,
      "grad_norm": 0.14206786453723907,
      "learning_rate": 1.4319444444444446e-05,
      "loss": 0.0007,
      "step": 25690
    },
    {
      "epoch": 1.4277777777777778,
      "grad_norm": 0.0,
      "learning_rate": 1.4305555555555555e-05,
      "loss": 0.0011,
      "step": 25700
    },
    {
      "epoch": 1.4283333333333332,
      "grad_norm": 0.0,
      "learning_rate": 1.4291666666666667e-05,
      "loss": 0.0001,
      "step": 25710
    },
    {
      "epoch": 1.4288888888888889,
      "grad_norm": 0.0,
      "learning_rate": 1.427777777777778e-05,
      "loss": 0.0001,
      "step": 25720
    },
    {
      "epoch": 1.4294444444444445,
      "grad_norm": 0.054234035313129425,
      "learning_rate": 1.426388888888889e-05,
      "loss": 0.0003,
      "step": 25730
    },
    {
      "epoch": 1.43,
      "grad_norm": 0.0,
      "learning_rate": 1.4249999999999999e-05,
      "loss": 0.0007,
      "step": 25740
    },
    {
      "epoch": 1.4305555555555556,
      "grad_norm": 0.0,
      "learning_rate": 1.4236111111111111e-05,
      "loss": 0.0003,
      "step": 25750
    },
    {
      "epoch": 1.431111111111111,
      "grad_norm": 0.0,
      "learning_rate": 1.4222222222222224e-05,
      "loss": 0.0003,
      "step": 25760
    },
    {
      "epoch": 1.4316666666666666,
      "grad_norm": 0.0,
      "learning_rate": 1.4208333333333334e-05,
      "loss": 0.0002,
      "step": 25770
    },
    {
      "epoch": 1.4322222222222223,
      "grad_norm": 0.08947695791721344,
      "learning_rate": 1.4194444444444447e-05,
      "loss": 0.0006,
      "step": 25780
    },
    {
      "epoch": 1.4327777777777777,
      "grad_norm": 0.021611234173178673,
      "learning_rate": 1.4180555555555555e-05,
      "loss": 0.0008,
      "step": 25790
    },
    {
      "epoch": 1.4333333333333333,
      "grad_norm": 0.20827481150627136,
      "learning_rate": 1.4166666666666668e-05,
      "loss": 0.0005,
      "step": 25800
    },
    {
      "epoch": 1.4338888888888888,
      "grad_norm": 0.049345556646585464,
      "learning_rate": 1.4152777777777778e-05,
      "loss": 0.0005,
      "step": 25810
    },
    {
      "epoch": 1.4344444444444444,
      "grad_norm": 0.04742835462093353,
      "learning_rate": 1.413888888888889e-05,
      "loss": 0.0013,
      "step": 25820
    },
    {
      "epoch": 1.435,
      "grad_norm": 0.05869030952453613,
      "learning_rate": 1.4125e-05,
      "loss": 0.0008,
      "step": 25830
    },
    {
      "epoch": 1.4355555555555555,
      "grad_norm": 0.13439255952835083,
      "learning_rate": 1.4111111111111112e-05,
      "loss": 0.0009,
      "step": 25840
    },
    {
      "epoch": 1.4361111111111111,
      "grad_norm": 0.04480108991265297,
      "learning_rate": 1.4097222222222222e-05,
      "loss": 0.001,
      "step": 25850
    },
    {
      "epoch": 1.4366666666666665,
      "grad_norm": 0.049136631190776825,
      "learning_rate": 1.4083333333333335e-05,
      "loss": 0.0,
      "step": 25860
    },
    {
      "epoch": 1.4372222222222222,
      "grad_norm": 0.04432908445596695,
      "learning_rate": 1.4069444444444447e-05,
      "loss": 0.0003,
      "step": 25870
    },
    {
      "epoch": 1.4377777777777778,
      "grad_norm": 0.046489205211400986,
      "learning_rate": 1.4055555555555556e-05,
      "loss": 0.0002,
      "step": 25880
    },
    {
      "epoch": 1.4383333333333335,
      "grad_norm": 0.19056753814220428,
      "learning_rate": 1.4041666666666666e-05,
      "loss": 0.0014,
      "step": 25890
    },
    {
      "epoch": 1.4388888888888889,
      "grad_norm": 0.21097984910011292,
      "learning_rate": 1.4027777777777779e-05,
      "loss": 0.0005,
      "step": 25900
    },
    {
      "epoch": 1.4394444444444445,
      "grad_norm": 0.0,
      "learning_rate": 1.4013888888888891e-05,
      "loss": 0.0004,
      "step": 25910
    },
    {
      "epoch": 1.44,
      "grad_norm": 0.05433299019932747,
      "learning_rate": 1.4000000000000001e-05,
      "loss": 0.0008,
      "step": 25920
    },
    {
      "epoch": 1.4405555555555556,
      "grad_norm": 0.34375515580177307,
      "learning_rate": 1.398611111111111e-05,
      "loss": 0.0005,
      "step": 25930
    },
    {
      "epoch": 1.4411111111111112,
      "grad_norm": 0.0,
      "learning_rate": 1.3972222222222223e-05,
      "loss": 0.0011,
      "step": 25940
    },
    {
      "epoch": 1.4416666666666667,
      "grad_norm": 0.05889924243092537,
      "learning_rate": 1.3958333333333335e-05,
      "loss": 0.0005,
      "step": 25950
    },
    {
      "epoch": 1.4422222222222223,
      "grad_norm": 0.0,
      "learning_rate": 1.3944444444444446e-05,
      "loss": 0.0006,
      "step": 25960
    },
    {
      "epoch": 1.4427777777777777,
      "grad_norm": 0.0,
      "learning_rate": 1.3930555555555554e-05,
      "loss": 0.0008,
      "step": 25970
    },
    {
      "epoch": 1.4433333333333334,
      "grad_norm": 0.0,
      "learning_rate": 1.3916666666666667e-05,
      "loss": 0.0007,
      "step": 25980
    },
    {
      "epoch": 1.443888888888889,
      "grad_norm": 0.0,
      "learning_rate": 1.3902777777777779e-05,
      "loss": 0.0004,
      "step": 25990
    },
    {
      "epoch": 1.4444444444444444,
      "grad_norm": 0.0,
      "learning_rate": 1.388888888888889e-05,
      "loss": 0.0002,
      "step": 26000
    },
    {
      "epoch": 1.445,
      "grad_norm": 0.0,
      "learning_rate": 1.3875000000000002e-05,
      "loss": 0.0007,
      "step": 26010
    },
    {
      "epoch": 1.4455555555555555,
      "grad_norm": 0.0,
      "learning_rate": 1.386111111111111e-05,
      "loss": 0.0005,
      "step": 26020
    },
    {
      "epoch": 1.4461111111111111,
      "grad_norm": 0.0,
      "learning_rate": 1.3847222222222223e-05,
      "loss": 0.0006,
      "step": 26030
    },
    {
      "epoch": 1.4466666666666668,
      "grad_norm": 0.04321448504924774,
      "learning_rate": 1.3833333333333334e-05,
      "loss": 0.0001,
      "step": 26040
    },
    {
      "epoch": 1.4472222222222222,
      "grad_norm": 0.2521013617515564,
      "learning_rate": 1.3819444444444446e-05,
      "loss": 0.0007,
      "step": 26050
    },
    {
      "epoch": 1.4477777777777778,
      "grad_norm": 0.13821826875209808,
      "learning_rate": 1.3805555555555555e-05,
      "loss": 0.0005,
      "step": 26060
    },
    {
      "epoch": 1.4483333333333333,
      "grad_norm": 0.10591499507427216,
      "learning_rate": 1.3791666666666667e-05,
      "loss": 0.0005,
      "step": 26070
    },
    {
      "epoch": 1.448888888888889,
      "grad_norm": 0.11901633441448212,
      "learning_rate": 1.3777777777777778e-05,
      "loss": 0.0015,
      "step": 26080
    },
    {
      "epoch": 1.4494444444444445,
      "grad_norm": 0.09115878492593765,
      "learning_rate": 1.376388888888889e-05,
      "loss": 0.001,
      "step": 26090
    },
    {
      "epoch": 1.45,
      "grad_norm": 0.0,
      "learning_rate": 1.3750000000000002e-05,
      "loss": 0.0005,
      "step": 26100
    },
    {
      "epoch": 1.4505555555555556,
      "grad_norm": 0.0,
      "learning_rate": 1.3736111111111111e-05,
      "loss": 0.0005,
      "step": 26110
    },
    {
      "epoch": 1.451111111111111,
      "grad_norm": 0.0,
      "learning_rate": 1.3722222222222222e-05,
      "loss": 0.0002,
      "step": 26120
    },
    {
      "epoch": 1.4516666666666667,
      "grad_norm": 0.04581807926297188,
      "learning_rate": 1.3708333333333334e-05,
      "loss": 0.0002,
      "step": 26130
    },
    {
      "epoch": 1.4522222222222223,
      "grad_norm": 0.05456721782684326,
      "learning_rate": 1.3694444444444446e-05,
      "loss": 0.0005,
      "step": 26140
    },
    {
      "epoch": 1.4527777777777777,
      "grad_norm": 0.0,
      "learning_rate": 1.3680555555555557e-05,
      "loss": 0.0007,
      "step": 26150
    },
    {
      "epoch": 1.4533333333333334,
      "grad_norm": 0.19059160351753235,
      "learning_rate": 1.3666666666666666e-05,
      "loss": 0.0002,
      "step": 26160
    },
    {
      "epoch": 1.4538888888888888,
      "grad_norm": 0.11113505810499191,
      "learning_rate": 1.3652777777777778e-05,
      "loss": 0.0003,
      "step": 26170
    },
    {
      "epoch": 1.4544444444444444,
      "grad_norm": 0.029007118195295334,
      "learning_rate": 1.363888888888889e-05,
      "loss": 0.0008,
      "step": 26180
    },
    {
      "epoch": 1.455,
      "grad_norm": 0.09366219490766525,
      "learning_rate": 1.3625e-05,
      "loss": 0.0006,
      "step": 26190
    },
    {
      "epoch": 1.4555555555555555,
      "grad_norm": 0.36045774817466736,
      "learning_rate": 1.3611111111111111e-05,
      "loss": 0.0012,
      "step": 26200
    },
    {
      "epoch": 1.4561111111111111,
      "grad_norm": 0.04849149286746979,
      "learning_rate": 1.3597222222222222e-05,
      "loss": 0.0011,
      "step": 26210
    },
    {
      "epoch": 1.4566666666666666,
      "grad_norm": 0.1900920569896698,
      "learning_rate": 1.3583333333333334e-05,
      "loss": 0.0004,
      "step": 26220
    },
    {
      "epoch": 1.4572222222222222,
      "grad_norm": 0.0,
      "learning_rate": 1.3569444444444447e-05,
      "loss": 0.001,
      "step": 26230
    },
    {
      "epoch": 1.4577777777777778,
      "grad_norm": 0.09148051589727402,
      "learning_rate": 1.3555555555555557e-05,
      "loss": 0.0007,
      "step": 26240
    },
    {
      "epoch": 1.4583333333333333,
      "grad_norm": 0.0,
      "learning_rate": 1.3541666666666666e-05,
      "loss": 0.0003,
      "step": 26250
    },
    {
      "epoch": 1.458888888888889,
      "grad_norm": 0.0,
      "learning_rate": 1.3527777777777778e-05,
      "loss": 0.0001,
      "step": 26260
    },
    {
      "epoch": 1.4594444444444443,
      "grad_norm": 0.050670258700847626,
      "learning_rate": 1.351388888888889e-05,
      "loss": 0.0011,
      "step": 26270
    },
    {
      "epoch": 1.46,
      "grad_norm": 0.044089607894420624,
      "learning_rate": 1.3500000000000001e-05,
      "loss": 0.0003,
      "step": 26280
    },
    {
      "epoch": 1.4605555555555556,
      "grad_norm": 0.21572750806808472,
      "learning_rate": 1.348611111111111e-05,
      "loss": 0.0002,
      "step": 26290
    },
    {
      "epoch": 1.4611111111111112,
      "grad_norm": 0.04671704024076462,
      "learning_rate": 1.3472222222222222e-05,
      "loss": 0.001,
      "step": 26300
    },
    {
      "epoch": 1.4616666666666667,
      "grad_norm": 0.04429135099053383,
      "learning_rate": 1.3458333333333335e-05,
      "loss": 0.0003,
      "step": 26310
    },
    {
      "epoch": 1.462222222222222,
      "grad_norm": 0.24913470447063446,
      "learning_rate": 1.3444444444444445e-05,
      "loss": 0.0006,
      "step": 26320
    },
    {
      "epoch": 1.4627777777777777,
      "grad_norm": 0.5602206587791443,
      "learning_rate": 1.3430555555555558e-05,
      "loss": 0.0004,
      "step": 26330
    },
    {
      "epoch": 1.4633333333333334,
      "grad_norm": 0.0,
      "learning_rate": 1.3416666666666666e-05,
      "loss": 0.0012,
      "step": 26340
    },
    {
      "epoch": 1.463888888888889,
      "grad_norm": 0.18017426133155823,
      "learning_rate": 1.3402777777777779e-05,
      "loss": 0.0004,
      "step": 26350
    },
    {
      "epoch": 1.4644444444444444,
      "grad_norm": 0.20328070223331451,
      "learning_rate": 1.338888888888889e-05,
      "loss": 0.0004,
      "step": 26360
    },
    {
      "epoch": 1.465,
      "grad_norm": 0.05207877606153488,
      "learning_rate": 1.3375000000000002e-05,
      "loss": 0.0005,
      "step": 26370
    },
    {
      "epoch": 1.4655555555555555,
      "grad_norm": 0.0475209578871727,
      "learning_rate": 1.3361111111111114e-05,
      "loss": 0.0007,
      "step": 26380
    },
    {
      "epoch": 1.4661111111111111,
      "grad_norm": 0.0,
      "learning_rate": 1.3347222222222223e-05,
      "loss": 0.0003,
      "step": 26390
    },
    {
      "epoch": 1.4666666666666668,
      "grad_norm": 0.059848934412002563,
      "learning_rate": 1.3333333333333333e-05,
      "loss": 0.0007,
      "step": 26400
    },
    {
      "epoch": 1.4672222222222222,
      "grad_norm": 0.04492850601673126,
      "learning_rate": 1.3319444444444446e-05,
      "loss": 0.0005,
      "step": 26410
    },
    {
      "epoch": 1.4677777777777778,
      "grad_norm": 0.0,
      "learning_rate": 1.3305555555555558e-05,
      "loss": 0.0006,
      "step": 26420
    },
    {
      "epoch": 1.4683333333333333,
      "grad_norm": 0.0,
      "learning_rate": 1.3291666666666667e-05,
      "loss": 0.002,
      "step": 26430
    },
    {
      "epoch": 1.468888888888889,
      "grad_norm": 0.05136634781956673,
      "learning_rate": 1.3277777777777777e-05,
      "loss": 0.0008,
      "step": 26440
    },
    {
      "epoch": 1.4694444444444446,
      "grad_norm": 0.0,
      "learning_rate": 1.326388888888889e-05,
      "loss": 0.0005,
      "step": 26450
    },
    {
      "epoch": 1.47,
      "grad_norm": 0.0,
      "learning_rate": 1.3250000000000002e-05,
      "loss": 0.0005,
      "step": 26460
    },
    {
      "epoch": 1.4705555555555556,
      "grad_norm": 0.0,
      "learning_rate": 1.3236111111111112e-05,
      "loss": 0.001,
      "step": 26470
    },
    {
      "epoch": 1.471111111111111,
      "grad_norm": 0.0,
      "learning_rate": 1.3222222222222221e-05,
      "loss": 0.0003,
      "step": 26480
    },
    {
      "epoch": 1.4716666666666667,
      "grad_norm": 0.0,
      "learning_rate": 1.3208333333333334e-05,
      "loss": 0.0012,
      "step": 26490
    },
    {
      "epoch": 1.4722222222222223,
      "grad_norm": 0.08113499730825424,
      "learning_rate": 1.3194444444444446e-05,
      "loss": 0.0013,
      "step": 26500
    },
    {
      "epoch": 1.4727777777777777,
      "grad_norm": 0.3047419488430023,
      "learning_rate": 1.3180555555555557e-05,
      "loss": 0.0006,
      "step": 26510
    },
    {
      "epoch": 1.4733333333333334,
      "grad_norm": 0.0,
      "learning_rate": 1.3166666666666665e-05,
      "loss": 0.0005,
      "step": 26520
    },
    {
      "epoch": 1.4738888888888888,
      "grad_norm": 0.0,
      "learning_rate": 1.3152777777777778e-05,
      "loss": 0.0005,
      "step": 26530
    },
    {
      "epoch": 1.4744444444444444,
      "grad_norm": 0.15448278188705444,
      "learning_rate": 1.313888888888889e-05,
      "loss": 0.0003,
      "step": 26540
    },
    {
      "epoch": 1.475,
      "grad_norm": 0.11737802624702454,
      "learning_rate": 1.3125e-05,
      "loss": 0.0003,
      "step": 26550
    },
    {
      "epoch": 1.4755555555555555,
      "grad_norm": 0.0,
      "learning_rate": 1.3111111111111113e-05,
      "loss": 0.0003,
      "step": 26560
    },
    {
      "epoch": 1.4761111111111112,
      "grad_norm": 0.0883903056383133,
      "learning_rate": 1.3097222222222222e-05,
      "loss": 0.0003,
      "step": 26570
    },
    {
      "epoch": 1.4766666666666666,
      "grad_norm": 0.0,
      "learning_rate": 1.3083333333333334e-05,
      "loss": 0.0004,
      "step": 26580
    },
    {
      "epoch": 1.4772222222222222,
      "grad_norm": 0.03743549436330795,
      "learning_rate": 1.3069444444444445e-05,
      "loss": 0.0005,
      "step": 26590
    },
    {
      "epoch": 1.4777777777777779,
      "grad_norm": 0.25636401772499084,
      "learning_rate": 1.3055555555555557e-05,
      "loss": 0.0007,
      "step": 26600
    },
    {
      "epoch": 1.4783333333333333,
      "grad_norm": 0.04954769089818001,
      "learning_rate": 1.3041666666666666e-05,
      "loss": 0.0021,
      "step": 26610
    },
    {
      "epoch": 1.478888888888889,
      "grad_norm": 0.0,
      "learning_rate": 1.3027777777777778e-05,
      "loss": 0.0006,
      "step": 26620
    },
    {
      "epoch": 1.4794444444444443,
      "grad_norm": 0.0,
      "learning_rate": 1.3013888888888889e-05,
      "loss": 0.0004,
      "step": 26630
    },
    {
      "epoch": 1.48,
      "grad_norm": 0.3076457679271698,
      "learning_rate": 1.3000000000000001e-05,
      "loss": 0.0014,
      "step": 26640
    },
    {
      "epoch": 1.4805555555555556,
      "grad_norm": 0.4158870577812195,
      "learning_rate": 1.2986111111111113e-05,
      "loss": 0.0005,
      "step": 26650
    },
    {
      "epoch": 1.481111111111111,
      "grad_norm": 0.0,
      "learning_rate": 1.2972222222222222e-05,
      "loss": 0.0012,
      "step": 26660
    },
    {
      "epoch": 1.4816666666666667,
      "grad_norm": 0.2575986087322235,
      "learning_rate": 1.2958333333333333e-05,
      "loss": 0.0008,
      "step": 26670
    },
    {
      "epoch": 1.482222222222222,
      "grad_norm": 0.05628368631005287,
      "learning_rate": 1.2944444444444445e-05,
      "loss": 0.001,
      "step": 26680
    },
    {
      "epoch": 1.4827777777777778,
      "grad_norm": 0.0,
      "learning_rate": 1.2930555555555557e-05,
      "loss": 0.0007,
      "step": 26690
    },
    {
      "epoch": 1.4833333333333334,
      "grad_norm": 0.04712548106908798,
      "learning_rate": 1.2916666666666668e-05,
      "loss": 0.0001,
      "step": 26700
    },
    {
      "epoch": 1.4838888888888888,
      "grad_norm": 0.052319031208753586,
      "learning_rate": 1.2902777777777777e-05,
      "loss": 0.0011,
      "step": 26710
    },
    {
      "epoch": 1.4844444444444445,
      "grad_norm": 0.0,
      "learning_rate": 1.2888888888888889e-05,
      "loss": 0.0002,
      "step": 26720
    },
    {
      "epoch": 1.4849999999999999,
      "grad_norm": 0.0,
      "learning_rate": 1.2875000000000001e-05,
      "loss": 0.0005,
      "step": 26730
    },
    {
      "epoch": 1.4855555555555555,
      "grad_norm": 0.0,
      "learning_rate": 1.2861111111111112e-05,
      "loss": 0.0021,
      "step": 26740
    },
    {
      "epoch": 1.4861111111111112,
      "grad_norm": 0.1558505892753601,
      "learning_rate": 1.2847222222222222e-05,
      "loss": 0.0012,
      "step": 26750
    },
    {
      "epoch": 1.4866666666666668,
      "grad_norm": 0.1679701954126358,
      "learning_rate": 1.2833333333333333e-05,
      "loss": 0.0007,
      "step": 26760
    },
    {
      "epoch": 1.4872222222222222,
      "grad_norm": 0.25577041506767273,
      "learning_rate": 1.2819444444444445e-05,
      "loss": 0.0002,
      "step": 26770
    },
    {
      "epoch": 1.4877777777777776,
      "grad_norm": 0.24355633556842804,
      "learning_rate": 1.2805555555555558e-05,
      "loss": 0.0003,
      "step": 26780
    },
    {
      "epoch": 1.4883333333333333,
      "grad_norm": 0.0,
      "learning_rate": 1.2791666666666668e-05,
      "loss": 0.0004,
      "step": 26790
    },
    {
      "epoch": 1.488888888888889,
      "grad_norm": 0.09747661650180817,
      "learning_rate": 1.2777777777777777e-05,
      "loss": 0.0003,
      "step": 26800
    },
    {
      "epoch": 1.4894444444444446,
      "grad_norm": 0.04910749942064285,
      "learning_rate": 1.276388888888889e-05,
      "loss": 0.0005,
      "step": 26810
    },
    {
      "epoch": 1.49,
      "grad_norm": 0.0,
      "learning_rate": 1.2750000000000002e-05,
      "loss": 0.0007,
      "step": 26820
    },
    {
      "epoch": 1.4905555555555556,
      "grad_norm": 0.0,
      "learning_rate": 1.2736111111111112e-05,
      "loss": 0.0007,
      "step": 26830
    },
    {
      "epoch": 1.491111111111111,
      "grad_norm": 0.04457179456949234,
      "learning_rate": 1.2722222222222221e-05,
      "loss": 0.0004,
      "step": 26840
    },
    {
      "epoch": 1.4916666666666667,
      "grad_norm": 0.28419747948646545,
      "learning_rate": 1.2708333333333333e-05,
      "loss": 0.0003,
      "step": 26850
    },
    {
      "epoch": 1.4922222222222223,
      "grad_norm": 0.054746054112911224,
      "learning_rate": 1.2694444444444446e-05,
      "loss": 0.0004,
      "step": 26860
    },
    {
      "epoch": 1.4927777777777778,
      "grad_norm": 0.0,
      "learning_rate": 1.2680555555555556e-05,
      "loss": 0.0005,
      "step": 26870
    },
    {
      "epoch": 1.4933333333333334,
      "grad_norm": 0.0,
      "learning_rate": 1.2666666666666668e-05,
      "loss": 0.0001,
      "step": 26880
    },
    {
      "epoch": 1.4938888888888888,
      "grad_norm": 0.0,
      "learning_rate": 1.2652777777777777e-05,
      "loss": 0.0007,
      "step": 26890
    },
    {
      "epoch": 1.4944444444444445,
      "grad_norm": 0.21108326315879822,
      "learning_rate": 1.263888888888889e-05,
      "loss": 0.0012,
      "step": 26900
    },
    {
      "epoch": 1.495,
      "grad_norm": 0.0493084192276001,
      "learning_rate": 1.2625e-05,
      "loss": 0.0004,
      "step": 26910
    },
    {
      "epoch": 1.4955555555555555,
      "grad_norm": 0.0,
      "learning_rate": 1.2611111111111113e-05,
      "loss": 0.0012,
      "step": 26920
    },
    {
      "epoch": 1.4961111111111112,
      "grad_norm": 0.050576914101839066,
      "learning_rate": 1.2597222222222225e-05,
      "loss": 0.0001,
      "step": 26930
    },
    {
      "epoch": 1.4966666666666666,
      "grad_norm": 0.0,
      "learning_rate": 1.2583333333333334e-05,
      "loss": 0.0005,
      "step": 26940
    },
    {
      "epoch": 1.4972222222222222,
      "grad_norm": 0.0,
      "learning_rate": 1.2569444444444444e-05,
      "loss": 0.0005,
      "step": 26950
    },
    {
      "epoch": 1.4977777777777779,
      "grad_norm": 0.0,
      "learning_rate": 1.2555555555555557e-05,
      "loss": 0.0007,
      "step": 26960
    },
    {
      "epoch": 1.4983333333333333,
      "grad_norm": 0.1872250735759735,
      "learning_rate": 1.2541666666666669e-05,
      "loss": 0.0004,
      "step": 26970
    },
    {
      "epoch": 1.498888888888889,
      "grad_norm": 0.04712355509400368,
      "learning_rate": 1.2527777777777778e-05,
      "loss": 0.0002,
      "step": 26980
    },
    {
      "epoch": 1.4994444444444444,
      "grad_norm": 0.0,
      "learning_rate": 1.2513888888888888e-05,
      "loss": 0.0003,
      "step": 26990
    },
    {
      "epoch": 1.5,
      "grad_norm": 0.0,
      "learning_rate": 1.25e-05,
      "loss": 0.0007,
      "step": 27000
    },
    {
      "epoch": 1.5005555555555556,
      "grad_norm": 0.23473036289215088,
      "learning_rate": 1.2486111111111113e-05,
      "loss": 0.0,
      "step": 27010
    },
    {
      "epoch": 1.501111111111111,
      "grad_norm": 0.08191156387329102,
      "learning_rate": 1.2472222222222223e-05,
      "loss": 0.0007,
      "step": 27020
    },
    {
      "epoch": 1.5016666666666667,
      "grad_norm": 0.0,
      "learning_rate": 1.2458333333333334e-05,
      "loss": 0.0007,
      "step": 27030
    },
    {
      "epoch": 1.5022222222222221,
      "grad_norm": 0.06973768025636673,
      "learning_rate": 1.2444444444444445e-05,
      "loss": 0.0013,
      "step": 27040
    },
    {
      "epoch": 1.5027777777777778,
      "grad_norm": 0.0,
      "learning_rate": 1.2430555555555557e-05,
      "loss": 0.0003,
      "step": 27050
    },
    {
      "epoch": 1.5033333333333334,
      "grad_norm": 0.0,
      "learning_rate": 1.2416666666666667e-05,
      "loss": 0.0017,
      "step": 27060
    },
    {
      "epoch": 1.503888888888889,
      "grad_norm": 0.0,
      "learning_rate": 1.2402777777777778e-05,
      "loss": 0.0012,
      "step": 27070
    },
    {
      "epoch": 1.5044444444444445,
      "grad_norm": 0.0,
      "learning_rate": 1.238888888888889e-05,
      "loss": 0.0003,
      "step": 27080
    },
    {
      "epoch": 1.505,
      "grad_norm": 0.0,
      "learning_rate": 1.2375000000000001e-05,
      "loss": 0.0007,
      "step": 27090
    },
    {
      "epoch": 1.5055555555555555,
      "grad_norm": 0.14063972234725952,
      "learning_rate": 1.2361111111111112e-05,
      "loss": 0.0004,
      "step": 27100
    },
    {
      "epoch": 1.5061111111111112,
      "grad_norm": 0.19829751551151276,
      "learning_rate": 1.2347222222222222e-05,
      "loss": 0.0005,
      "step": 27110
    },
    {
      "epoch": 1.5066666666666668,
      "grad_norm": 0.0,
      "learning_rate": 1.2333333333333334e-05,
      "loss": 0.001,
      "step": 27120
    },
    {
      "epoch": 1.5072222222222222,
      "grad_norm": 0.06145277991890907,
      "learning_rate": 1.2319444444444445e-05,
      "loss": 0.0008,
      "step": 27130
    },
    {
      "epoch": 1.5077777777777777,
      "grad_norm": 0.0,
      "learning_rate": 1.2305555555555556e-05,
      "loss": 0.0001,
      "step": 27140
    },
    {
      "epoch": 1.5083333333333333,
      "grad_norm": 0.2919505834579468,
      "learning_rate": 1.2291666666666666e-05,
      "loss": 0.0004,
      "step": 27150
    },
    {
      "epoch": 1.508888888888889,
      "grad_norm": 0.227525532245636,
      "learning_rate": 1.2277777777777778e-05,
      "loss": 0.0008,
      "step": 27160
    },
    {
      "epoch": 1.5094444444444446,
      "grad_norm": 0.28806209564208984,
      "learning_rate": 1.226388888888889e-05,
      "loss": 0.0005,
      "step": 27170
    },
    {
      "epoch": 1.51,
      "grad_norm": 0.20933690667152405,
      "learning_rate": 1.225e-05,
      "loss": 0.0003,
      "step": 27180
    },
    {
      "epoch": 1.5105555555555554,
      "grad_norm": 0.0,
      "learning_rate": 1.2236111111111112e-05,
      "loss": 0.0002,
      "step": 27190
    },
    {
      "epoch": 1.511111111111111,
      "grad_norm": 0.40209177136421204,
      "learning_rate": 1.2222222222222222e-05,
      "loss": 0.0008,
      "step": 27200
    },
    {
      "epoch": 1.5116666666666667,
      "grad_norm": 0.3139977753162384,
      "learning_rate": 1.2208333333333335e-05,
      "loss": 0.0007,
      "step": 27210
    },
    {
      "epoch": 1.5122222222222224,
      "grad_norm": 0.0,
      "learning_rate": 1.2194444444444444e-05,
      "loss": 0.0004,
      "step": 27220
    },
    {
      "epoch": 1.5127777777777778,
      "grad_norm": 0.248014435172081,
      "learning_rate": 1.2180555555555556e-05,
      "loss": 0.0008,
      "step": 27230
    },
    {
      "epoch": 1.5133333333333332,
      "grad_norm": 0.04352666810154915,
      "learning_rate": 1.2166666666666668e-05,
      "loss": 0.0008,
      "step": 27240
    },
    {
      "epoch": 1.5138888888888888,
      "grad_norm": 0.18688099086284637,
      "learning_rate": 1.2152777777777779e-05,
      "loss": 0.0002,
      "step": 27250
    },
    {
      "epoch": 1.5144444444444445,
      "grad_norm": 0.16863474249839783,
      "learning_rate": 1.213888888888889e-05,
      "loss": 0.0009,
      "step": 27260
    },
    {
      "epoch": 1.5150000000000001,
      "grad_norm": 0.0,
      "learning_rate": 1.2125e-05,
      "loss": 0.0006,
      "step": 27270
    },
    {
      "epoch": 1.5155555555555555,
      "grad_norm": 0.05245054513216019,
      "learning_rate": 1.2111111111111112e-05,
      "loss": 0.0014,
      "step": 27280
    },
    {
      "epoch": 1.516111111111111,
      "grad_norm": 0.04874083027243614,
      "learning_rate": 1.2097222222222223e-05,
      "loss": 0.0003,
      "step": 27290
    },
    {
      "epoch": 1.5166666666666666,
      "grad_norm": 0.0489017516374588,
      "learning_rate": 1.2083333333333333e-05,
      "loss": 0.001,
      "step": 27300
    },
    {
      "epoch": 1.5172222222222222,
      "grad_norm": 0.15284308791160583,
      "learning_rate": 1.2069444444444444e-05,
      "loss": 0.0007,
      "step": 27310
    },
    {
      "epoch": 1.517777777777778,
      "grad_norm": 0.04355340078473091,
      "learning_rate": 1.2055555555555556e-05,
      "loss": 0.0003,
      "step": 27320
    },
    {
      "epoch": 1.5183333333333333,
      "grad_norm": 0.04511301964521408,
      "learning_rate": 1.2041666666666669e-05,
      "loss": 0.0005,
      "step": 27330
    },
    {
      "epoch": 1.5188888888888887,
      "grad_norm": 0.09134114533662796,
      "learning_rate": 1.2027777777777777e-05,
      "loss": 0.0003,
      "step": 27340
    },
    {
      "epoch": 1.5194444444444444,
      "grad_norm": 0.0,
      "learning_rate": 1.201388888888889e-05,
      "loss": 0.0007,
      "step": 27350
    },
    {
      "epoch": 1.52,
      "grad_norm": 0.1831815093755722,
      "learning_rate": 1.2e-05,
      "loss": 0.0003,
      "step": 27360
    },
    {
      "epoch": 1.5205555555555557,
      "grad_norm": 0.049151282757520676,
      "learning_rate": 1.1986111111111113e-05,
      "loss": 0.0007,
      "step": 27370
    },
    {
      "epoch": 1.521111111111111,
      "grad_norm": 0.0,
      "learning_rate": 1.1972222222222221e-05,
      "loss": 0.0014,
      "step": 27380
    },
    {
      "epoch": 1.5216666666666665,
      "grad_norm": 0.043917857110500336,
      "learning_rate": 1.1958333333333334e-05,
      "loss": 0.0003,
      "step": 27390
    },
    {
      "epoch": 1.5222222222222221,
      "grad_norm": 0.04681267589330673,
      "learning_rate": 1.1944444444444446e-05,
      "loss": 0.0018,
      "step": 27400
    },
    {
      "epoch": 1.5227777777777778,
      "grad_norm": 0.04835488647222519,
      "learning_rate": 1.1930555555555557e-05,
      "loss": 0.0007,
      "step": 27410
    },
    {
      "epoch": 1.5233333333333334,
      "grad_norm": 0.0,
      "learning_rate": 1.1916666666666667e-05,
      "loss": 0.0004,
      "step": 27420
    },
    {
      "epoch": 1.5238888888888888,
      "grad_norm": 0.0,
      "learning_rate": 1.1902777777777778e-05,
      "loss": 0.0002,
      "step": 27430
    },
    {
      "epoch": 1.5244444444444445,
      "grad_norm": 0.0,
      "learning_rate": 1.188888888888889e-05,
      "loss": 0.0003,
      "step": 27440
    },
    {
      "epoch": 1.525,
      "grad_norm": 0.04666990414261818,
      "learning_rate": 1.1875e-05,
      "loss": 0.0004,
      "step": 27450
    },
    {
      "epoch": 1.5255555555555556,
      "grad_norm": 0.3680163323879242,
      "learning_rate": 1.1861111111111111e-05,
      "loss": 0.0013,
      "step": 27460
    },
    {
      "epoch": 1.5261111111111112,
      "grad_norm": 0.0,
      "learning_rate": 1.1847222222222224e-05,
      "loss": 0.0006,
      "step": 27470
    },
    {
      "epoch": 1.5266666666666666,
      "grad_norm": 0.02597193978726864,
      "learning_rate": 1.1833333333333334e-05,
      "loss": 0.0005,
      "step": 27480
    },
    {
      "epoch": 1.5272222222222223,
      "grad_norm": 0.041777316480875015,
      "learning_rate": 1.1819444444444445e-05,
      "loss": 0.0005,
      "step": 27490
    },
    {
      "epoch": 1.5277777777777777,
      "grad_norm": 0.0,
      "learning_rate": 1.1805555555555555e-05,
      "loss": 0.0006,
      "step": 27500
    },
    {
      "epoch": 1.5283333333333333,
      "grad_norm": 0.04775018244981766,
      "learning_rate": 1.1791666666666668e-05,
      "loss": 0.0004,
      "step": 27510
    },
    {
      "epoch": 1.528888888888889,
      "grad_norm": 0.05979805067181587,
      "learning_rate": 1.1777777777777778e-05,
      "loss": 0.0003,
      "step": 27520
    },
    {
      "epoch": 1.5294444444444446,
      "grad_norm": 0.0,
      "learning_rate": 1.1763888888888889e-05,
      "loss": 0.001,
      "step": 27530
    },
    {
      "epoch": 1.53,
      "grad_norm": 0.2396148145198822,
      "learning_rate": 1.175e-05,
      "loss": 0.0012,
      "step": 27540
    },
    {
      "epoch": 1.5305555555555554,
      "grad_norm": 0.04556863754987717,
      "learning_rate": 1.1736111111111112e-05,
      "loss": 0.0004,
      "step": 27550
    },
    {
      "epoch": 1.531111111111111,
      "grad_norm": 0.04927173629403114,
      "learning_rate": 1.1722222222222224e-05,
      "loss": 0.0007,
      "step": 27560
    },
    {
      "epoch": 1.5316666666666667,
      "grad_norm": 0.05202731117606163,
      "learning_rate": 1.1708333333333334e-05,
      "loss": 0.0009,
      "step": 27570
    },
    {
      "epoch": 1.5322222222222224,
      "grad_norm": 0.04669521376490593,
      "learning_rate": 1.1694444444444445e-05,
      "loss": 0.0003,
      "step": 27580
    },
    {
      "epoch": 1.5327777777777778,
      "grad_norm": 0.29423460364341736,
      "learning_rate": 1.1680555555555556e-05,
      "loss": 0.001,
      "step": 27590
    },
    {
      "epoch": 1.5333333333333332,
      "grad_norm": 0.046570923179388046,
      "learning_rate": 1.1666666666666668e-05,
      "loss": 0.0008,
      "step": 27600
    },
    {
      "epoch": 1.5338888888888889,
      "grad_norm": 0.048941485583782196,
      "learning_rate": 1.1652777777777778e-05,
      "loss": 0.0007,
      "step": 27610
    },
    {
      "epoch": 1.5344444444444445,
      "grad_norm": 0.0,
      "learning_rate": 1.1638888888888889e-05,
      "loss": 0.0,
      "step": 27620
    },
    {
      "epoch": 1.5350000000000001,
      "grad_norm": 0.049740683287382126,
      "learning_rate": 1.1625000000000001e-05,
      "loss": 0.0011,
      "step": 27630
    },
    {
      "epoch": 1.5355555555555556,
      "grad_norm": 0.04670580476522446,
      "learning_rate": 1.1611111111111112e-05,
      "loss": 0.0008,
      "step": 27640
    },
    {
      "epoch": 1.536111111111111,
      "grad_norm": 0.047048117965459824,
      "learning_rate": 1.1597222222222223e-05,
      "loss": 0.0007,
      "step": 27650
    },
    {
      "epoch": 1.5366666666666666,
      "grad_norm": 0.3535101115703583,
      "learning_rate": 1.1583333333333333e-05,
      "loss": 0.0008,
      "step": 27660
    },
    {
      "epoch": 1.5372222222222223,
      "grad_norm": 0.0,
      "learning_rate": 1.1569444444444445e-05,
      "loss": 0.0004,
      "step": 27670
    },
    {
      "epoch": 1.537777777777778,
      "grad_norm": 0.05589050054550171,
      "learning_rate": 1.1555555555555556e-05,
      "loss": 0.0013,
      "step": 27680
    },
    {
      "epoch": 1.5383333333333333,
      "grad_norm": 0.0,
      "learning_rate": 1.1541666666666667e-05,
      "loss": 0.0004,
      "step": 27690
    },
    {
      "epoch": 1.5388888888888888,
      "grad_norm": 0.11059772223234177,
      "learning_rate": 1.1527777777777779e-05,
      "loss": 0.0003,
      "step": 27700
    },
    {
      "epoch": 1.5394444444444444,
      "grad_norm": 0.09569332003593445,
      "learning_rate": 1.151388888888889e-05,
      "loss": 0.0003,
      "step": 27710
    },
    {
      "epoch": 1.54,
      "grad_norm": 0.08084361255168915,
      "learning_rate": 1.1500000000000002e-05,
      "loss": 0.0003,
      "step": 27720
    },
    {
      "epoch": 1.5405555555555557,
      "grad_norm": 0.3752589523792267,
      "learning_rate": 1.148611111111111e-05,
      "loss": 0.0004,
      "step": 27730
    },
    {
      "epoch": 1.541111111111111,
      "grad_norm": 0.29709020256996155,
      "learning_rate": 1.1472222222222223e-05,
      "loss": 0.0009,
      "step": 27740
    },
    {
      "epoch": 1.5416666666666665,
      "grad_norm": 0.0,
      "learning_rate": 1.1458333333333333e-05,
      "loss": 0.0013,
      "step": 27750
    },
    {
      "epoch": 1.5422222222222222,
      "grad_norm": 0.0,
      "learning_rate": 1.1444444444444446e-05,
      "loss": 0.0004,
      "step": 27760
    },
    {
      "epoch": 1.5427777777777778,
      "grad_norm": 0.22421762347221375,
      "learning_rate": 1.1430555555555555e-05,
      "loss": 0.0004,
      "step": 27770
    },
    {
      "epoch": 1.5433333333333334,
      "grad_norm": 0.35824745893478394,
      "learning_rate": 1.1416666666666667e-05,
      "loss": 0.0004,
      "step": 27780
    },
    {
      "epoch": 1.5438888888888889,
      "grad_norm": 0.044548287987709045,
      "learning_rate": 1.140277777777778e-05,
      "loss": 0.0011,
      "step": 27790
    },
    {
      "epoch": 1.5444444444444443,
      "grad_norm": 0.05026819929480553,
      "learning_rate": 1.138888888888889e-05,
      "loss": 0.0002,
      "step": 27800
    },
    {
      "epoch": 1.545,
      "grad_norm": 0.11978646367788315,
      "learning_rate": 1.1375e-05,
      "loss": 0.0002,
      "step": 27810
    },
    {
      "epoch": 1.5455555555555556,
      "grad_norm": 0.0,
      "learning_rate": 1.1361111111111111e-05,
      "loss": 0.0007,
      "step": 27820
    },
    {
      "epoch": 1.5461111111111112,
      "grad_norm": 0.0,
      "learning_rate": 1.1347222222222223e-05,
      "loss": 0.0008,
      "step": 27830
    },
    {
      "epoch": 1.5466666666666666,
      "grad_norm": 0.0,
      "learning_rate": 1.1333333333333334e-05,
      "loss": 0.0009,
      "step": 27840
    },
    {
      "epoch": 1.5472222222222223,
      "grad_norm": 0.0,
      "learning_rate": 1.1319444444444444e-05,
      "loss": 0.0008,
      "step": 27850
    },
    {
      "epoch": 1.5477777777777777,
      "grad_norm": 0.0,
      "learning_rate": 1.1305555555555557e-05,
      "loss": 0.0001,
      "step": 27860
    },
    {
      "epoch": 1.5483333333333333,
      "grad_norm": 0.06604359298944473,
      "learning_rate": 1.1291666666666667e-05,
      "loss": 0.0005,
      "step": 27870
    },
    {
      "epoch": 1.548888888888889,
      "grad_norm": 0.0,
      "learning_rate": 1.127777777777778e-05,
      "loss": 0.0015,
      "step": 27880
    },
    {
      "epoch": 1.5494444444444444,
      "grad_norm": 0.13785408437252045,
      "learning_rate": 1.1263888888888888e-05,
      "loss": 0.0004,
      "step": 27890
    },
    {
      "epoch": 1.55,
      "grad_norm": 0.05202218517661095,
      "learning_rate": 1.125e-05,
      "loss": 0.0006,
      "step": 27900
    },
    {
      "epoch": 1.5505555555555555,
      "grad_norm": 0.26655685901641846,
      "learning_rate": 1.1236111111111111e-05,
      "loss": 0.0007,
      "step": 27910
    },
    {
      "epoch": 1.551111111111111,
      "grad_norm": 0.048988159745931625,
      "learning_rate": 1.1222222222222224e-05,
      "loss": 0.0007,
      "step": 27920
    },
    {
      "epoch": 1.5516666666666667,
      "grad_norm": 0.04404429718852043,
      "learning_rate": 1.1208333333333332e-05,
      "loss": 0.001,
      "step": 27930
    },
    {
      "epoch": 1.5522222222222222,
      "grad_norm": 0.27539780735969543,
      "learning_rate": 1.1194444444444445e-05,
      "loss": 0.0003,
      "step": 27940
    },
    {
      "epoch": 1.5527777777777778,
      "grad_norm": 0.0,
      "learning_rate": 1.1180555555555557e-05,
      "loss": 0.0001,
      "step": 27950
    },
    {
      "epoch": 1.5533333333333332,
      "grad_norm": 0.0,
      "learning_rate": 1.1166666666666668e-05,
      "loss": 0.0007,
      "step": 27960
    },
    {
      "epoch": 1.5538888888888889,
      "grad_norm": 0.2237020879983902,
      "learning_rate": 1.1152777777777778e-05,
      "loss": 0.0007,
      "step": 27970
    },
    {
      "epoch": 1.5544444444444445,
      "grad_norm": 0.0,
      "learning_rate": 1.1138888888888889e-05,
      "loss": 0.0005,
      "step": 27980
    },
    {
      "epoch": 1.5550000000000002,
      "grad_norm": 0.07541782408952713,
      "learning_rate": 1.1125000000000001e-05,
      "loss": 0.0007,
      "step": 27990
    },
    {
      "epoch": 1.5555555555555556,
      "grad_norm": 0.19991222023963928,
      "learning_rate": 1.1111111111111112e-05,
      "loss": 0.0007,
      "step": 28000
    },
    {
      "epoch": 1.556111111111111,
      "grad_norm": 0.0,
      "learning_rate": 1.1097222222222222e-05,
      "loss": 0.0006,
      "step": 28010
    },
    {
      "epoch": 1.5566666666666666,
      "grad_norm": 0.0,
      "learning_rate": 1.1083333333333335e-05,
      "loss": 0.0012,
      "step": 28020
    },
    {
      "epoch": 1.5572222222222223,
      "grad_norm": 0.12569603323936462,
      "learning_rate": 1.1069444444444445e-05,
      "loss": 0.0002,
      "step": 28030
    },
    {
      "epoch": 1.557777777777778,
      "grad_norm": 0.0,
      "learning_rate": 1.1055555555555556e-05,
      "loss": 0.0004,
      "step": 28040
    },
    {
      "epoch": 1.5583333333333333,
      "grad_norm": 0.3978390097618103,
      "learning_rate": 1.1041666666666666e-05,
      "loss": 0.0002,
      "step": 28050
    },
    {
      "epoch": 1.5588888888888888,
      "grad_norm": 0.2238457351922989,
      "learning_rate": 1.1027777777777779e-05,
      "loss": 0.0006,
      "step": 28060
    },
    {
      "epoch": 1.5594444444444444,
      "grad_norm": 0.044487010687589645,
      "learning_rate": 1.1013888888888889e-05,
      "loss": 0.0004,
      "step": 28070
    },
    {
      "epoch": 1.56,
      "grad_norm": 0.0,
      "learning_rate": 1.1000000000000001e-05,
      "loss": 0.0003,
      "step": 28080
    },
    {
      "epoch": 1.5605555555555557,
      "grad_norm": 0.0,
      "learning_rate": 1.0986111111111112e-05,
      "loss": 0.0006,
      "step": 28090
    },
    {
      "epoch": 1.5611111111111111,
      "grad_norm": 0.18727003037929535,
      "learning_rate": 1.0972222222222223e-05,
      "loss": 0.0004,
      "step": 28100
    },
    {
      "epoch": 1.5616666666666665,
      "grad_norm": 0.0,
      "learning_rate": 1.0958333333333335e-05,
      "loss": 0.0001,
      "step": 28110
    },
    {
      "epoch": 1.5622222222222222,
      "grad_norm": 0.048988111317157745,
      "learning_rate": 1.0944444444444445e-05,
      "loss": 0.0006,
      "step": 28120
    },
    {
      "epoch": 1.5627777777777778,
      "grad_norm": 0.0,
      "learning_rate": 1.0930555555555556e-05,
      "loss": 0.0008,
      "step": 28130
    },
    {
      "epoch": 1.5633333333333335,
      "grad_norm": 0.057801324874162674,
      "learning_rate": 1.0916666666666667e-05,
      "loss": 0.0001,
      "step": 28140
    },
    {
      "epoch": 1.5638888888888889,
      "grad_norm": 0.0,
      "learning_rate": 1.0902777777777779e-05,
      "loss": 0.0008,
      "step": 28150
    },
    {
      "epoch": 1.5644444444444443,
      "grad_norm": 0.0,
      "learning_rate": 1.088888888888889e-05,
      "loss": 0.0007,
      "step": 28160
    },
    {
      "epoch": 1.565,
      "grad_norm": 0.0,
      "learning_rate": 1.0875e-05,
      "loss": 0.0003,
      "step": 28170
    },
    {
      "epoch": 1.5655555555555556,
      "grad_norm": 0.0,
      "learning_rate": 1.0861111111111112e-05,
      "loss": 0.0005,
      "step": 28180
    },
    {
      "epoch": 1.5661111111111112,
      "grad_norm": 0.0,
      "learning_rate": 1.0847222222222223e-05,
      "loss": 0.0005,
      "step": 28190
    },
    {
      "epoch": 1.5666666666666667,
      "grad_norm": 0.04795782268047333,
      "learning_rate": 1.0833333333333334e-05,
      "loss": 0.0009,
      "step": 28200
    },
    {
      "epoch": 1.567222222222222,
      "grad_norm": 0.04950503259897232,
      "learning_rate": 1.0819444444444444e-05,
      "loss": 0.0008,
      "step": 28210
    },
    {
      "epoch": 1.5677777777777777,
      "grad_norm": 0.14772282540798187,
      "learning_rate": 1.0805555555555556e-05,
      "loss": 0.0004,
      "step": 28220
    },
    {
      "epoch": 1.5683333333333334,
      "grad_norm": 0.12041688710451126,
      "learning_rate": 1.0791666666666667e-05,
      "loss": 0.0002,
      "step": 28230
    },
    {
      "epoch": 1.568888888888889,
      "grad_norm": 0.0,
      "learning_rate": 1.0777777777777778e-05,
      "loss": 0.0006,
      "step": 28240
    },
    {
      "epoch": 1.5694444444444444,
      "grad_norm": 0.0,
      "learning_rate": 1.076388888888889e-05,
      "loss": 0.0002,
      "step": 28250
    },
    {
      "epoch": 1.5699999999999998,
      "grad_norm": 0.09820529818534851,
      "learning_rate": 1.075e-05,
      "loss": 0.0004,
      "step": 28260
    },
    {
      "epoch": 1.5705555555555555,
      "grad_norm": 0.045875973999500275,
      "learning_rate": 1.0736111111111113e-05,
      "loss": 0.0004,
      "step": 28270
    },
    {
      "epoch": 1.5711111111111111,
      "grad_norm": 0.0884060487151146,
      "learning_rate": 1.0722222222222222e-05,
      "loss": 0.0011,
      "step": 28280
    },
    {
      "epoch": 1.5716666666666668,
      "grad_norm": 0.04986986145377159,
      "learning_rate": 1.0708333333333334e-05,
      "loss": 0.0006,
      "step": 28290
    },
    {
      "epoch": 1.5722222222222222,
      "grad_norm": 0.04562174901366234,
      "learning_rate": 1.0694444444444444e-05,
      "loss": 0.001,
      "step": 28300
    },
    {
      "epoch": 1.5727777777777778,
      "grad_norm": 0.0,
      "learning_rate": 1.0680555555555557e-05,
      "loss": 0.0006,
      "step": 28310
    },
    {
      "epoch": 1.5733333333333333,
      "grad_norm": 0.3754635155200958,
      "learning_rate": 1.0666666666666667e-05,
      "loss": 0.0003,
      "step": 28320
    },
    {
      "epoch": 1.573888888888889,
      "grad_norm": 0.0,
      "learning_rate": 1.0652777777777778e-05,
      "loss": 0.0002,
      "step": 28330
    },
    {
      "epoch": 1.5744444444444445,
      "grad_norm": 0.0,
      "learning_rate": 1.063888888888889e-05,
      "loss": 0.0004,
      "step": 28340
    },
    {
      "epoch": 1.575,
      "grad_norm": 0.1640348583459854,
      "learning_rate": 1.0625e-05,
      "loss": 0.0005,
      "step": 28350
    },
    {
      "epoch": 1.5755555555555556,
      "grad_norm": 0.0,
      "learning_rate": 1.0611111111111111e-05,
      "loss": 0.0004,
      "step": 28360
    },
    {
      "epoch": 1.576111111111111,
      "grad_norm": 0.07635831087827682,
      "learning_rate": 1.0597222222222222e-05,
      "loss": 0.0004,
      "step": 28370
    },
    {
      "epoch": 1.5766666666666667,
      "grad_norm": 0.1506301760673523,
      "learning_rate": 1.0583333333333334e-05,
      "loss": 0.0007,
      "step": 28380
    },
    {
      "epoch": 1.5772222222222223,
      "grad_norm": 0.34840214252471924,
      "learning_rate": 1.0569444444444445e-05,
      "loss": 0.0008,
      "step": 28390
    },
    {
      "epoch": 1.5777777777777777,
      "grad_norm": 0.17664748430252075,
      "learning_rate": 1.0555555555555555e-05,
      "loss": 0.0005,
      "step": 28400
    },
    {
      "epoch": 1.5783333333333334,
      "grad_norm": 0.05394819378852844,
      "learning_rate": 1.0541666666666668e-05,
      "loss": 0.0011,
      "step": 28410
    },
    {
      "epoch": 1.5788888888888888,
      "grad_norm": 0.04839624464511871,
      "learning_rate": 1.0527777777777778e-05,
      "loss": 0.0016,
      "step": 28420
    },
    {
      "epoch": 1.5794444444444444,
      "grad_norm": 0.0,
      "learning_rate": 1.051388888888889e-05,
      "loss": 0.0002,
      "step": 28430
    },
    {
      "epoch": 1.58,
      "grad_norm": 0.05837971717119217,
      "learning_rate": 1.05e-05,
      "loss": 0.0004,
      "step": 28440
    },
    {
      "epoch": 1.5805555555555557,
      "grad_norm": 0.0,
      "learning_rate": 1.0486111111111112e-05,
      "loss": 0.0015,
      "step": 28450
    },
    {
      "epoch": 1.5811111111111111,
      "grad_norm": 0.1688861846923828,
      "learning_rate": 1.0472222222222222e-05,
      "loss": 0.0006,
      "step": 28460
    },
    {
      "epoch": 1.5816666666666666,
      "grad_norm": 0.0,
      "learning_rate": 1.0458333333333335e-05,
      "loss": 0.0007,
      "step": 28470
    },
    {
      "epoch": 1.5822222222222222,
      "grad_norm": 0.04565530642867088,
      "learning_rate": 1.0444444444444445e-05,
      "loss": 0.0005,
      "step": 28480
    },
    {
      "epoch": 1.5827777777777778,
      "grad_norm": 0.09091144800186157,
      "learning_rate": 1.0430555555555556e-05,
      "loss": 0.001,
      "step": 28490
    },
    {
      "epoch": 1.5833333333333335,
      "grad_norm": 0.0,
      "learning_rate": 1.0416666666666668e-05,
      "loss": 0.0003,
      "step": 28500
    },
    {
      "epoch": 1.583888888888889,
      "grad_norm": 0.024909786880016327,
      "learning_rate": 1.0402777777777779e-05,
      "loss": 0.0004,
      "step": 28510
    },
    {
      "epoch": 1.5844444444444443,
      "grad_norm": 0.0,
      "learning_rate": 1.038888888888889e-05,
      "loss": 0.0013,
      "step": 28520
    },
    {
      "epoch": 1.585,
      "grad_norm": 0.15694785118103027,
      "learning_rate": 1.0375e-05,
      "loss": 0.0004,
      "step": 28530
    },
    {
      "epoch": 1.5855555555555556,
      "grad_norm": 0.21987846493721008,
      "learning_rate": 1.0361111111111112e-05,
      "loss": 0.0007,
      "step": 28540
    },
    {
      "epoch": 1.5861111111111112,
      "grad_norm": 0.0,
      "learning_rate": 1.0347222222222223e-05,
      "loss": 0.0007,
      "step": 28550
    },
    {
      "epoch": 1.5866666666666667,
      "grad_norm": 0.0,
      "learning_rate": 1.0333333333333333e-05,
      "loss": 0.0014,
      "step": 28560
    },
    {
      "epoch": 1.587222222222222,
      "grad_norm": 0.0,
      "learning_rate": 1.0319444444444445e-05,
      "loss": 0.0001,
      "step": 28570
    },
    {
      "epoch": 1.5877777777777777,
      "grad_norm": 0.0,
      "learning_rate": 1.0305555555555556e-05,
      "loss": 0.0007,
      "step": 28580
    },
    {
      "epoch": 1.5883333333333334,
      "grad_norm": 0.09348542988300323,
      "learning_rate": 1.0291666666666667e-05,
      "loss": 0.0003,
      "step": 28590
    },
    {
      "epoch": 1.588888888888889,
      "grad_norm": 0.045944686979055405,
      "learning_rate": 1.0277777777777777e-05,
      "loss": 0.0009,
      "step": 28600
    },
    {
      "epoch": 1.5894444444444444,
      "grad_norm": 0.0,
      "learning_rate": 1.026388888888889e-05,
      "loss": 0.0009,
      "step": 28610
    },
    {
      "epoch": 1.5899999999999999,
      "grad_norm": 0.288048654794693,
      "learning_rate": 1.025e-05,
      "loss": 0.0004,
      "step": 28620
    },
    {
      "epoch": 1.5905555555555555,
      "grad_norm": 0.13523657619953156,
      "learning_rate": 1.0236111111111112e-05,
      "loss": 0.0003,
      "step": 28630
    },
    {
      "epoch": 1.5911111111111111,
      "grad_norm": 0.05857793614268303,
      "learning_rate": 1.0222222222222223e-05,
      "loss": 0.0002,
      "step": 28640
    },
    {
      "epoch": 1.5916666666666668,
      "grad_norm": 0.12061023712158203,
      "learning_rate": 1.0208333333333334e-05,
      "loss": 0.0013,
      "step": 28650
    },
    {
      "epoch": 1.5922222222222222,
      "grad_norm": 0.0,
      "learning_rate": 1.0194444444444446e-05,
      "loss": 0.0004,
      "step": 28660
    },
    {
      "epoch": 1.5927777777777776,
      "grad_norm": 0.0,
      "learning_rate": 1.0180555555555556e-05,
      "loss": 0.0006,
      "step": 28670
    },
    {
      "epoch": 1.5933333333333333,
      "grad_norm": 0.12926910817623138,
      "learning_rate": 1.0166666666666667e-05,
      "loss": 0.001,
      "step": 28680
    },
    {
      "epoch": 1.593888888888889,
      "grad_norm": 0.0,
      "learning_rate": 1.0152777777777778e-05,
      "loss": 0.0001,
      "step": 28690
    },
    {
      "epoch": 1.5944444444444446,
      "grad_norm": 0.09064590185880661,
      "learning_rate": 1.013888888888889e-05,
      "loss": 0.0006,
      "step": 28700
    },
    {
      "epoch": 1.595,
      "grad_norm": 0.0,
      "learning_rate": 1.0125e-05,
      "loss": 0.0013,
      "step": 28710
    },
    {
      "epoch": 1.5955555555555554,
      "grad_norm": 0.05431033670902252,
      "learning_rate": 1.0111111111111111e-05,
      "loss": 0.0003,
      "step": 28720
    },
    {
      "epoch": 1.596111111111111,
      "grad_norm": 0.060652270913124084,
      "learning_rate": 1.0097222222222223e-05,
      "loss": 0.001,
      "step": 28730
    },
    {
      "epoch": 1.5966666666666667,
      "grad_norm": 0.37818655371665955,
      "learning_rate": 1.0083333333333334e-05,
      "loss": 0.0004,
      "step": 28740
    },
    {
      "epoch": 1.5972222222222223,
      "grad_norm": 0.07833906263113022,
      "learning_rate": 1.0069444444444445e-05,
      "loss": 0.0005,
      "step": 28750
    },
    {
      "epoch": 1.5977777777777777,
      "grad_norm": 0.09511491656303406,
      "learning_rate": 1.0055555555555555e-05,
      "loss": 0.0009,
      "step": 28760
    },
    {
      "epoch": 1.5983333333333334,
      "grad_norm": 0.0,
      "learning_rate": 1.0041666666666667e-05,
      "loss": 0.0004,
      "step": 28770
    },
    {
      "epoch": 1.5988888888888888,
      "grad_norm": 0.060212790966033936,
      "learning_rate": 1.0027777777777778e-05,
      "loss": 0.0004,
      "step": 28780
    },
    {
      "epoch": 1.5994444444444444,
      "grad_norm": 0.21085596084594727,
      "learning_rate": 1.0013888888888889e-05,
      "loss": 0.0006,
      "step": 28790
    },
    {
      "epoch": 1.6,
      "grad_norm": 0.10431471467018127,
      "learning_rate": 1e-05,
      "loss": 0.0012,
      "step": 28800
    },
    {
      "epoch": 1.6005555555555555,
      "grad_norm": 0.140393927693367,
      "learning_rate": 9.986111111111111e-06,
      "loss": 0.0009,
      "step": 28810
    },
    {
      "epoch": 1.6011111111111112,
      "grad_norm": 0.12035435438156128,
      "learning_rate": 9.972222222222224e-06,
      "loss": 0.0004,
      "step": 28820
    },
    {
      "epoch": 1.6016666666666666,
      "grad_norm": 0.2567327618598938,
      "learning_rate": 9.958333333333333e-06,
      "loss": 0.0004,
      "step": 28830
    },
    {
      "epoch": 1.6022222222222222,
      "grad_norm": 0.30935773253440857,
      "learning_rate": 9.944444444444445e-06,
      "loss": 0.0004,
      "step": 28840
    },
    {
      "epoch": 1.6027777777777779,
      "grad_norm": 0.07108206301927567,
      "learning_rate": 9.930555555555555e-06,
      "loss": 0.0003,
      "step": 28850
    },
    {
      "epoch": 1.6033333333333335,
      "grad_norm": 0.24249030649662018,
      "learning_rate": 9.916666666666668e-06,
      "loss": 0.001,
      "step": 28860
    },
    {
      "epoch": 1.603888888888889,
      "grad_norm": 0.045928798615932465,
      "learning_rate": 9.902777777777778e-06,
      "loss": 0.001,
      "step": 28870
    },
    {
      "epoch": 1.6044444444444443,
      "grad_norm": 0.12291718274354935,
      "learning_rate": 9.888888888888889e-06,
      "loss": 0.001,
      "step": 28880
    },
    {
      "epoch": 1.605,
      "grad_norm": 0.3429880738258362,
      "learning_rate": 9.875000000000001e-06,
      "loss": 0.0006,
      "step": 28890
    },
    {
      "epoch": 1.6055555555555556,
      "grad_norm": 0.1339862197637558,
      "learning_rate": 9.861111111111112e-06,
      "loss": 0.0012,
      "step": 28900
    },
    {
      "epoch": 1.6061111111111113,
      "grad_norm": 0.0,
      "learning_rate": 9.847222222222222e-06,
      "loss": 0.0002,
      "step": 28910
    },
    {
      "epoch": 1.6066666666666667,
      "grad_norm": 0.044330254197120667,
      "learning_rate": 9.833333333333333e-06,
      "loss": 0.0012,
      "step": 28920
    },
    {
      "epoch": 1.607222222222222,
      "grad_norm": 0.0,
      "learning_rate": 9.819444444444445e-06,
      "loss": 0.0004,
      "step": 28930
    },
    {
      "epoch": 1.6077777777777778,
      "grad_norm": 0.0,
      "learning_rate": 9.805555555555557e-06,
      "loss": 0.0006,
      "step": 28940
    },
    {
      "epoch": 1.6083333333333334,
      "grad_norm": 0.0,
      "learning_rate": 9.791666666666666e-06,
      "loss": 0.0003,
      "step": 28950
    },
    {
      "epoch": 1.608888888888889,
      "grad_norm": 0.13665680587291718,
      "learning_rate": 9.777777777777779e-06,
      "loss": 0.0007,
      "step": 28960
    },
    {
      "epoch": 1.6094444444444445,
      "grad_norm": 0.0,
      "learning_rate": 9.76388888888889e-06,
      "loss": 0.0004,
      "step": 28970
    },
    {
      "epoch": 1.6099999999999999,
      "grad_norm": 0.0,
      "learning_rate": 9.750000000000002e-06,
      "loss": 0.0006,
      "step": 28980
    },
    {
      "epoch": 1.6105555555555555,
      "grad_norm": 0.04919930920004845,
      "learning_rate": 9.73611111111111e-06,
      "loss": 0.0003,
      "step": 28990
    },
    {
      "epoch": 1.6111111111111112,
      "grad_norm": 0.09449131786823273,
      "learning_rate": 9.722222222222223e-06,
      "loss": 0.0006,
      "step": 29000
    },
    {
      "epoch": 1.6116666666666668,
      "grad_norm": 0.0,
      "learning_rate": 9.708333333333333e-06,
      "loss": 0.0009,
      "step": 29010
    },
    {
      "epoch": 1.6122222222222222,
      "grad_norm": 0.0,
      "learning_rate": 9.694444444444446e-06,
      "loss": 0.0012,
      "step": 29020
    },
    {
      "epoch": 1.6127777777777776,
      "grad_norm": 0.09494500607252121,
      "learning_rate": 9.680555555555556e-06,
      "loss": 0.0006,
      "step": 29030
    },
    {
      "epoch": 1.6133333333333333,
      "grad_norm": 0.047204744070768356,
      "learning_rate": 9.666666666666667e-06,
      "loss": 0.0005,
      "step": 29040
    },
    {
      "epoch": 1.613888888888889,
      "grad_norm": 0.05673415958881378,
      "learning_rate": 9.652777777777779e-06,
      "loss": 0.0003,
      "step": 29050
    },
    {
      "epoch": 1.6144444444444446,
      "grad_norm": 0.04050217941403389,
      "learning_rate": 9.63888888888889e-06,
      "loss": 0.0004,
      "step": 29060
    },
    {
      "epoch": 1.615,
      "grad_norm": 0.16938868165016174,
      "learning_rate": 9.625e-06,
      "loss": 0.0004,
      "step": 29070
    },
    {
      "epoch": 1.6155555555555554,
      "grad_norm": 0.0,
      "learning_rate": 9.61111111111111e-06,
      "loss": 0.0004,
      "step": 29080
    },
    {
      "epoch": 1.616111111111111,
      "grad_norm": 0.0,
      "learning_rate": 9.597222222222223e-06,
      "loss": 0.0001,
      "step": 29090
    },
    {
      "epoch": 1.6166666666666667,
      "grad_norm": 0.0,
      "learning_rate": 9.583333333333334e-06,
      "loss": 0.0003,
      "step": 29100
    },
    {
      "epoch": 1.6172222222222223,
      "grad_norm": 0.04535210505127907,
      "learning_rate": 9.569444444444444e-06,
      "loss": 0.0005,
      "step": 29110
    },
    {
      "epoch": 1.6177777777777778,
      "grad_norm": 0.07408785820007324,
      "learning_rate": 9.555555555555556e-06,
      "loss": 0.0005,
      "step": 29120
    },
    {
      "epoch": 1.6183333333333332,
      "grad_norm": 0.0,
      "learning_rate": 9.541666666666667e-06,
      "loss": 0.0007,
      "step": 29130
    },
    {
      "epoch": 1.6188888888888888,
      "grad_norm": 0.24697013199329376,
      "learning_rate": 9.52777777777778e-06,
      "loss": 0.0016,
      "step": 29140
    },
    {
      "epoch": 1.6194444444444445,
      "grad_norm": 0.0,
      "learning_rate": 9.513888888888888e-06,
      "loss": 0.0003,
      "step": 29150
    },
    {
      "epoch": 1.62,
      "grad_norm": 0.2480282187461853,
      "learning_rate": 9.5e-06,
      "loss": 0.0009,
      "step": 29160
    },
    {
      "epoch": 1.6205555555555555,
      "grad_norm": 0.0,
      "learning_rate": 9.486111111111111e-06,
      "loss": 0.0006,
      "step": 29170
    },
    {
      "epoch": 1.621111111111111,
      "grad_norm": 0.231293186545372,
      "learning_rate": 9.472222222222223e-06,
      "loss": 0.0008,
      "step": 29180
    },
    {
      "epoch": 1.6216666666666666,
      "grad_norm": 0.051325734704732895,
      "learning_rate": 9.458333333333334e-06,
      "loss": 0.0006,
      "step": 29190
    },
    {
      "epoch": 1.6222222222222222,
      "grad_norm": 0.04816984012722969,
      "learning_rate": 9.444444444444445e-06,
      "loss": 0.0001,
      "step": 29200
    },
    {
      "epoch": 1.6227777777777779,
      "grad_norm": 0.0,
      "learning_rate": 9.430555555555557e-06,
      "loss": 0.0012,
      "step": 29210
    },
    {
      "epoch": 1.6233333333333333,
      "grad_norm": 0.04435950517654419,
      "learning_rate": 9.416666666666667e-06,
      "loss": 0.0008,
      "step": 29220
    },
    {
      "epoch": 1.623888888888889,
      "grad_norm": 0.0,
      "learning_rate": 9.402777777777778e-06,
      "loss": 0.0003,
      "step": 29230
    },
    {
      "epoch": 1.6244444444444444,
      "grad_norm": 0.0,
      "learning_rate": 9.388888888888889e-06,
      "loss": 0.0005,
      "step": 29240
    },
    {
      "epoch": 1.625,
      "grad_norm": 0.0,
      "learning_rate": 9.375000000000001e-06,
      "loss": 0.0003,
      "step": 29250
    },
    {
      "epoch": 1.6255555555555556,
      "grad_norm": 0.0,
      "learning_rate": 9.361111111111111e-06,
      "loss": 0.001,
      "step": 29260
    },
    {
      "epoch": 1.626111111111111,
      "grad_norm": 0.0,
      "learning_rate": 9.347222222222222e-06,
      "loss": 0.0003,
      "step": 29270
    },
    {
      "epoch": 1.6266666666666667,
      "grad_norm": 0.13923834264278412,
      "learning_rate": 9.333333333333334e-06,
      "loss": 0.0001,
      "step": 29280
    },
    {
      "epoch": 1.6272222222222221,
      "grad_norm": 0.0,
      "learning_rate": 9.319444444444445e-06,
      "loss": 0.0001,
      "step": 29290
    },
    {
      "epoch": 1.6277777777777778,
      "grad_norm": 0.12736666202545166,
      "learning_rate": 9.305555555555555e-06,
      "loss": 0.0001,
      "step": 29300
    },
    {
      "epoch": 1.6283333333333334,
      "grad_norm": 0.0,
      "learning_rate": 9.291666666666666e-06,
      "loss": 0.0007,
      "step": 29310
    },
    {
      "epoch": 1.628888888888889,
      "grad_norm": 0.06783427298069,
      "learning_rate": 9.277777777777778e-06,
      "loss": 0.0007,
      "step": 29320
    },
    {
      "epoch": 1.6294444444444445,
      "grad_norm": 0.04872194305062294,
      "learning_rate": 9.26388888888889e-06,
      "loss": 0.0008,
      "step": 29330
    },
    {
      "epoch": 1.63,
      "grad_norm": 0.0,
      "learning_rate": 9.25e-06,
      "loss": 0.0004,
      "step": 29340
    },
    {
      "epoch": 1.6305555555555555,
      "grad_norm": 0.04794478788971901,
      "learning_rate": 9.236111111111112e-06,
      "loss": 0.0006,
      "step": 29350
    },
    {
      "epoch": 1.6311111111111112,
      "grad_norm": 0.0,
      "learning_rate": 9.222222222222222e-06,
      "loss": 0.0003,
      "step": 29360
    },
    {
      "epoch": 1.6316666666666668,
      "grad_norm": 0.0,
      "learning_rate": 9.208333333333335e-06,
      "loss": 0.0004,
      "step": 29370
    },
    {
      "epoch": 1.6322222222222222,
      "grad_norm": 0.04788373410701752,
      "learning_rate": 9.194444444444445e-06,
      "loss": 0.0013,
      "step": 29380
    },
    {
      "epoch": 1.6327777777777777,
      "grad_norm": 0.3129999339580536,
      "learning_rate": 9.180555555555556e-06,
      "loss": 0.0004,
      "step": 29390
    },
    {
      "epoch": 1.6333333333333333,
      "grad_norm": 0.0,
      "learning_rate": 9.166666666666666e-06,
      "loss": 0.0003,
      "step": 29400
    },
    {
      "epoch": 1.633888888888889,
      "grad_norm": 0.0,
      "learning_rate": 9.152777777777779e-06,
      "loss": 0.0004,
      "step": 29410
    },
    {
      "epoch": 1.6344444444444446,
      "grad_norm": 0.0,
      "learning_rate": 9.13888888888889e-06,
      "loss": 0.0005,
      "step": 29420
    },
    {
      "epoch": 1.635,
      "grad_norm": 0.04885096848011017,
      "learning_rate": 9.125e-06,
      "loss": 0.0009,
      "step": 29430
    },
    {
      "epoch": 1.6355555555555554,
      "grad_norm": 0.04998386651277542,
      "learning_rate": 9.111111111111112e-06,
      "loss": 0.0005,
      "step": 29440
    },
    {
      "epoch": 1.636111111111111,
      "grad_norm": 0.0,
      "learning_rate": 9.097222222222223e-06,
      "loss": 0.0003,
      "step": 29450
    },
    {
      "epoch": 1.6366666666666667,
      "grad_norm": 0.0837593600153923,
      "learning_rate": 9.083333333333333e-06,
      "loss": 0.0009,
      "step": 29460
    },
    {
      "epoch": 1.6372222222222224,
      "grad_norm": 0.04485860839486122,
      "learning_rate": 9.069444444444444e-06,
      "loss": 0.0003,
      "step": 29470
    },
    {
      "epoch": 1.6377777777777778,
      "grad_norm": 0.053947094827890396,
      "learning_rate": 9.055555555555556e-06,
      "loss": 0.0004,
      "step": 29480
    },
    {
      "epoch": 1.6383333333333332,
      "grad_norm": 0.0,
      "learning_rate": 9.041666666666668e-06,
      "loss": 0.0002,
      "step": 29490
    },
    {
      "epoch": 1.6388888888888888,
      "grad_norm": 0.0,
      "learning_rate": 9.027777777777777e-06,
      "loss": 0.0002,
      "step": 29500
    },
    {
      "epoch": 1.6394444444444445,
      "grad_norm": 0.0,
      "learning_rate": 9.01388888888889e-06,
      "loss": 0.0008,
      "step": 29510
    },
    {
      "epoch": 1.6400000000000001,
      "grad_norm": 0.05412532389163971,
      "learning_rate": 9e-06,
      "loss": 0.0006,
      "step": 29520
    },
    {
      "epoch": 1.6405555555555555,
      "grad_norm": 0.0,
      "learning_rate": 8.986111111111113e-06,
      "loss": 0.0007,
      "step": 29530
    },
    {
      "epoch": 1.641111111111111,
      "grad_norm": 0.09386978298425674,
      "learning_rate": 8.972222222222221e-06,
      "loss": 0.0006,
      "step": 29540
    },
    {
      "epoch": 1.6416666666666666,
      "grad_norm": 0.0,
      "learning_rate": 8.958333333333334e-06,
      "loss": 0.0001,
      "step": 29550
    },
    {
      "epoch": 1.6422222222222222,
      "grad_norm": 0.0968887135386467,
      "learning_rate": 8.944444444444444e-06,
      "loss": 0.0009,
      "step": 29560
    },
    {
      "epoch": 1.642777777777778,
      "grad_norm": 0.15314365923404694,
      "learning_rate": 8.930555555555557e-06,
      "loss": 0.0008,
      "step": 29570
    },
    {
      "epoch": 1.6433333333333333,
      "grad_norm": 0.0968216210603714,
      "learning_rate": 8.916666666666667e-06,
      "loss": 0.0004,
      "step": 29580
    },
    {
      "epoch": 1.6438888888888887,
      "grad_norm": 0.0,
      "learning_rate": 8.902777777777778e-06,
      "loss": 0.0009,
      "step": 29590
    },
    {
      "epoch": 1.6444444444444444,
      "grad_norm": 0.09020348638296127,
      "learning_rate": 8.88888888888889e-06,
      "loss": 0.0001,
      "step": 29600
    },
    {
      "epoch": 1.645,
      "grad_norm": 0.06055447831749916,
      "learning_rate": 8.875e-06,
      "loss": 0.0006,
      "step": 29610
    },
    {
      "epoch": 1.6455555555555557,
      "grad_norm": 0.3659559190273285,
      "learning_rate": 8.861111111111111e-06,
      "loss": 0.0009,
      "step": 29620
    },
    {
      "epoch": 1.646111111111111,
      "grad_norm": 0.0,
      "learning_rate": 8.847222222222222e-06,
      "loss": 0.0002,
      "step": 29630
    },
    {
      "epoch": 1.6466666666666665,
      "grad_norm": 0.05135510489344597,
      "learning_rate": 8.833333333333334e-06,
      "loss": 0.0009,
      "step": 29640
    },
    {
      "epoch": 1.6472222222222221,
      "grad_norm": 0.0,
      "learning_rate": 8.819444444444445e-06,
      "loss": 0.0009,
      "step": 29650
    },
    {
      "epoch": 1.6477777777777778,
      "grad_norm": 0.17557644844055176,
      "learning_rate": 8.805555555555555e-06,
      "loss": 0.0004,
      "step": 29660
    },
    {
      "epoch": 1.6483333333333334,
      "grad_norm": 0.08651848882436752,
      "learning_rate": 8.791666666666667e-06,
      "loss": 0.0001,
      "step": 29670
    },
    {
      "epoch": 1.6488888888888888,
      "grad_norm": 0.2604660391807556,
      "learning_rate": 8.777777777777778e-06,
      "loss": 0.0005,
      "step": 29680
    },
    {
      "epoch": 1.6494444444444445,
      "grad_norm": 0.0,
      "learning_rate": 8.76388888888889e-06,
      "loss": 0.0001,
      "step": 29690
    },
    {
      "epoch": 1.65,
      "grad_norm": 0.06155005097389221,
      "learning_rate": 8.75e-06,
      "loss": 0.0003,
      "step": 29700
    },
    {
      "epoch": 1.6505555555555556,
      "grad_norm": 0.0,
      "learning_rate": 8.736111111111112e-06,
      "loss": 0.0004,
      "step": 29710
    },
    {
      "epoch": 1.6511111111111112,
      "grad_norm": 0.0,
      "learning_rate": 8.722222222222224e-06,
      "loss": 0.0009,
      "step": 29720
    },
    {
      "epoch": 1.6516666666666666,
      "grad_norm": 0.0,
      "learning_rate": 8.708333333333334e-06,
      "loss": 0.0002,
      "step": 29730
    },
    {
      "epoch": 1.6522222222222223,
      "grad_norm": 0.0,
      "learning_rate": 8.694444444444445e-06,
      "loss": 0.0002,
      "step": 29740
    },
    {
      "epoch": 1.6527777777777777,
      "grad_norm": 0.0,
      "learning_rate": 8.680555555555556e-06,
      "loss": 0.0001,
      "step": 29750
    },
    {
      "epoch": 1.6533333333333333,
      "grad_norm": 0.04736625775694847,
      "learning_rate": 8.666666666666668e-06,
      "loss": 0.0009,
      "step": 29760
    },
    {
      "epoch": 1.653888888888889,
      "grad_norm": 0.07366015762090683,
      "learning_rate": 8.652777777777778e-06,
      "loss": 0.0006,
      "step": 29770
    },
    {
      "epoch": 1.6544444444444446,
      "grad_norm": 0.0,
      "learning_rate": 8.638888888888889e-06,
      "loss": 0.0015,
      "step": 29780
    },
    {
      "epoch": 1.655,
      "grad_norm": 0.2568209171295166,
      "learning_rate": 8.625e-06,
      "loss": 0.0011,
      "step": 29790
    },
    {
      "epoch": 1.6555555555555554,
      "grad_norm": 0.0,
      "learning_rate": 8.611111111111112e-06,
      "loss": 0.0006,
      "step": 29800
    },
    {
      "epoch": 1.656111111111111,
      "grad_norm": 0.0,
      "learning_rate": 8.597222222222222e-06,
      "loss": 0.0002,
      "step": 29810
    },
    {
      "epoch": 1.6566666666666667,
      "grad_norm": 0.0,
      "learning_rate": 8.583333333333333e-06,
      "loss": 0.0006,
      "step": 29820
    },
    {
      "epoch": 1.6572222222222224,
      "grad_norm": 0.13125193119049072,
      "learning_rate": 8.569444444444445e-06,
      "loss": 0.0005,
      "step": 29830
    },
    {
      "epoch": 1.6577777777777778,
      "grad_norm": 0.08451821655035019,
      "learning_rate": 8.555555555555556e-06,
      "loss": 0.0006,
      "step": 29840
    },
    {
      "epoch": 1.6583333333333332,
      "grad_norm": 0.1977566033601761,
      "learning_rate": 8.541666666666666e-06,
      "loss": 0.0005,
      "step": 29850
    },
    {
      "epoch": 1.6588888888888889,
      "grad_norm": 0.14286711812019348,
      "learning_rate": 8.527777777777777e-06,
      "loss": 0.0006,
      "step": 29860
    },
    {
      "epoch": 1.6594444444444445,
      "grad_norm": 0.0,
      "learning_rate": 8.51388888888889e-06,
      "loss": 0.0009,
      "step": 29870
    },
    {
      "epoch": 1.6600000000000001,
      "grad_norm": 0.04657302051782608,
      "learning_rate": 8.500000000000002e-06,
      "loss": 0.0007,
      "step": 29880
    },
    {
      "epoch": 1.6605555555555556,
      "grad_norm": 0.12348011881113052,
      "learning_rate": 8.48611111111111e-06,
      "loss": 0.0003,
      "step": 29890
    },
    {
      "epoch": 1.661111111111111,
      "grad_norm": 0.0,
      "learning_rate": 8.472222222222223e-06,
      "loss": 0.0002,
      "step": 29900
    },
    {
      "epoch": 1.6616666666666666,
      "grad_norm": 0.0,
      "learning_rate": 8.458333333333333e-06,
      "loss": 0.0001,
      "step": 29910
    },
    {
      "epoch": 1.6622222222222223,
      "grad_norm": 0.0,
      "learning_rate": 8.444444444444446e-06,
      "loss": 0.0011,
      "step": 29920
    },
    {
      "epoch": 1.662777777777778,
      "grad_norm": 0.052782006561756134,
      "learning_rate": 8.430555555555556e-06,
      "loss": 0.0005,
      "step": 29930
    },
    {
      "epoch": 1.6633333333333333,
      "grad_norm": 0.028208835050463676,
      "learning_rate": 8.416666666666667e-06,
      "loss": 0.0007,
      "step": 29940
    },
    {
      "epoch": 1.6638888888888888,
      "grad_norm": 0.0,
      "learning_rate": 8.402777777777779e-06,
      "loss": 0.0004,
      "step": 29950
    },
    {
      "epoch": 1.6644444444444444,
      "grad_norm": 0.21919190883636475,
      "learning_rate": 8.38888888888889e-06,
      "loss": 0.0005,
      "step": 29960
    },
    {
      "epoch": 1.665,
      "grad_norm": 0.049113307148218155,
      "learning_rate": 8.375e-06,
      "loss": 0.001,
      "step": 29970
    },
    {
      "epoch": 1.6655555555555557,
      "grad_norm": 0.11510385572910309,
      "learning_rate": 8.361111111111111e-06,
      "loss": 0.0013,
      "step": 29980
    },
    {
      "epoch": 1.666111111111111,
      "grad_norm": 0.0,
      "learning_rate": 8.347222222222223e-06,
      "loss": 0.0004,
      "step": 29990
    },
    {
      "epoch": 1.6666666666666665,
      "grad_norm": 0.058945462107658386,
      "learning_rate": 8.333333333333334e-06,
      "loss": 0.0001,
      "step": 30000
    },
    {
      "epoch": 1.6672222222222222,
      "grad_norm": 0.0,
      "learning_rate": 8.319444444444444e-06,
      "loss": 0.0009,
      "step": 30010
    },
    {
      "epoch": 1.6677777777777778,
      "grad_norm": 0.0,
      "learning_rate": 8.305555555555555e-06,
      "loss": 0.0004,
      "step": 30020
    },
    {
      "epoch": 1.6683333333333334,
      "grad_norm": 0.0,
      "learning_rate": 8.291666666666667e-06,
      "loss": 0.0001,
      "step": 30030
    },
    {
      "epoch": 1.6688888888888889,
      "grad_norm": 0.0,
      "learning_rate": 8.27777777777778e-06,
      "loss": 0.0007,
      "step": 30040
    },
    {
      "epoch": 1.6694444444444443,
      "grad_norm": 0.0,
      "learning_rate": 8.263888888888888e-06,
      "loss": 0.0006,
      "step": 30050
    },
    {
      "epoch": 1.67,
      "grad_norm": 0.03088287077844143,
      "learning_rate": 8.25e-06,
      "loss": 0.0003,
      "step": 30060
    },
    {
      "epoch": 1.6705555555555556,
      "grad_norm": 0.0,
      "learning_rate": 8.236111111111111e-06,
      "loss": 0.0001,
      "step": 30070
    },
    {
      "epoch": 1.6711111111111112,
      "grad_norm": 0.30289942026138306,
      "learning_rate": 8.222222222222223e-06,
      "loss": 0.0005,
      "step": 30080
    },
    {
      "epoch": 1.6716666666666666,
      "grad_norm": 0.04575955122709274,
      "learning_rate": 8.208333333333332e-06,
      "loss": 0.0007,
      "step": 30090
    },
    {
      "epoch": 1.6722222222222223,
      "grad_norm": 0.0,
      "learning_rate": 8.194444444444445e-06,
      "loss": 0.0002,
      "step": 30100
    },
    {
      "epoch": 1.6727777777777777,
      "grad_norm": 0.0,
      "learning_rate": 8.180555555555557e-06,
      "loss": 0.0001,
      "step": 30110
    },
    {
      "epoch": 1.6733333333333333,
      "grad_norm": 0.046095676720142365,
      "learning_rate": 8.166666666666668e-06,
      "loss": 0.0003,
      "step": 30120
    },
    {
      "epoch": 1.673888888888889,
      "grad_norm": 0.046764202415943146,
      "learning_rate": 8.152777777777778e-06,
      "loss": 0.0004,
      "step": 30130
    },
    {
      "epoch": 1.6744444444444444,
      "grad_norm": 0.04624473676085472,
      "learning_rate": 8.138888888888889e-06,
      "loss": 0.0005,
      "step": 30140
    },
    {
      "epoch": 1.675,
      "grad_norm": 0.0,
      "learning_rate": 8.125000000000001e-06,
      "loss": 0.0003,
      "step": 30150
    },
    {
      "epoch": 1.6755555555555555,
      "grad_norm": 0.0,
      "learning_rate": 8.111111111111112e-06,
      "loss": 0.0007,
      "step": 30160
    },
    {
      "epoch": 1.676111111111111,
      "grad_norm": 0.05185481160879135,
      "learning_rate": 8.097222222222222e-06,
      "loss": 0.0002,
      "step": 30170
    },
    {
      "epoch": 1.6766666666666667,
      "grad_norm": 0.05231108143925667,
      "learning_rate": 8.083333333333333e-06,
      "loss": 0.0005,
      "step": 30180
    },
    {
      "epoch": 1.6772222222222222,
      "grad_norm": 0.05276300385594368,
      "learning_rate": 8.069444444444445e-06,
      "loss": 0.0003,
      "step": 30190
    },
    {
      "epoch": 1.6777777777777778,
      "grad_norm": 0.0,
      "learning_rate": 8.055555555555557e-06,
      "loss": 0.0008,
      "step": 30200
    },
    {
      "epoch": 1.6783333333333332,
      "grad_norm": 0.04917800426483154,
      "learning_rate": 8.041666666666666e-06,
      "loss": 0.0002,
      "step": 30210
    },
    {
      "epoch": 1.6788888888888889,
      "grad_norm": 0.06267595291137695,
      "learning_rate": 8.027777777777778e-06,
      "loss": 0.001,
      "step": 30220
    },
    {
      "epoch": 1.6794444444444445,
      "grad_norm": 0.06926067918539047,
      "learning_rate": 8.013888888888889e-06,
      "loss": 0.0006,
      "step": 30230
    },
    {
      "epoch": 1.6800000000000002,
      "grad_norm": 0.0,
      "learning_rate": 8.000000000000001e-06,
      "loss": 0.001,
      "step": 30240
    },
    {
      "epoch": 1.6805555555555556,
      "grad_norm": 0.0,
      "learning_rate": 7.98611111111111e-06,
      "loss": 0.0008,
      "step": 30250
    },
    {
      "epoch": 1.681111111111111,
      "grad_norm": 0.0,
      "learning_rate": 7.972222222222223e-06,
      "loss": 0.0001,
      "step": 30260
    },
    {
      "epoch": 1.6816666666666666,
      "grad_norm": 0.0,
      "learning_rate": 7.958333333333335e-06,
      "loss": 0.001,
      "step": 30270
    },
    {
      "epoch": 1.6822222222222223,
      "grad_norm": 0.0,
      "learning_rate": 7.944444444444445e-06,
      "loss": 0.0004,
      "step": 30280
    },
    {
      "epoch": 1.682777777777778,
      "grad_norm": 0.0,
      "learning_rate": 7.930555555555556e-06,
      "loss": 0.0002,
      "step": 30290
    },
    {
      "epoch": 1.6833333333333333,
      "grad_norm": 0.0,
      "learning_rate": 7.916666666666667e-06,
      "loss": 0.0004,
      "step": 30300
    },
    {
      "epoch": 1.6838888888888888,
      "grad_norm": 0.0939098447561264,
      "learning_rate": 7.902777777777779e-06,
      "loss": 0.0009,
      "step": 30310
    },
    {
      "epoch": 1.6844444444444444,
      "grad_norm": 0.10195113718509674,
      "learning_rate": 7.88888888888889e-06,
      "loss": 0.0002,
      "step": 30320
    },
    {
      "epoch": 1.685,
      "grad_norm": 0.0,
      "learning_rate": 7.875e-06,
      "loss": 0.0028,
      "step": 30330
    },
    {
      "epoch": 1.6855555555555557,
      "grad_norm": 0.04748111218214035,
      "learning_rate": 7.861111111111112e-06,
      "loss": 0.0019,
      "step": 30340
    },
    {
      "epoch": 1.6861111111111111,
      "grad_norm": 0.044588908553123474,
      "learning_rate": 7.847222222222223e-06,
      "loss": 0.0005,
      "step": 30350
    },
    {
      "epoch": 1.6866666666666665,
      "grad_norm": 0.0,
      "learning_rate": 7.833333333333333e-06,
      "loss": 0.0005,
      "step": 30360
    },
    {
      "epoch": 1.6872222222222222,
      "grad_norm": 0.0,
      "learning_rate": 7.819444444444444e-06,
      "loss": 0.0004,
      "step": 30370
    },
    {
      "epoch": 1.6877777777777778,
      "grad_norm": 0.0,
      "learning_rate": 7.805555555555556e-06,
      "loss": 0.0008,
      "step": 30380
    },
    {
      "epoch": 1.6883333333333335,
      "grad_norm": 0.24576206505298615,
      "learning_rate": 7.791666666666667e-06,
      "loss": 0.0003,
      "step": 30390
    },
    {
      "epoch": 1.6888888888888889,
      "grad_norm": 0.048042915761470795,
      "learning_rate": 7.777777777777777e-06,
      "loss": 0.0002,
      "step": 30400
    },
    {
      "epoch": 1.6894444444444443,
      "grad_norm": 0.0,
      "learning_rate": 7.763888888888888e-06,
      "loss": 0.0005,
      "step": 30410
    },
    {
      "epoch": 1.69,
      "grad_norm": 0.339165598154068,
      "learning_rate": 7.75e-06,
      "loss": 0.001,
      "step": 30420
    },
    {
      "epoch": 1.6905555555555556,
      "grad_norm": 0.0942017063498497,
      "learning_rate": 7.736111111111113e-06,
      "loss": 0.0004,
      "step": 30430
    },
    {
      "epoch": 1.6911111111111112,
      "grad_norm": 0.06065767630934715,
      "learning_rate": 7.722222222222223e-06,
      "loss": 0.0009,
      "step": 30440
    },
    {
      "epoch": 1.6916666666666667,
      "grad_norm": 0.04856448620557785,
      "learning_rate": 7.708333333333334e-06,
      "loss": 0.0015,
      "step": 30450
    },
    {
      "epoch": 1.692222222222222,
      "grad_norm": 0.0,
      "learning_rate": 7.694444444444444e-06,
      "loss": 0.0003,
      "step": 30460
    },
    {
      "epoch": 1.6927777777777777,
      "grad_norm": 0.04366498067975044,
      "learning_rate": 7.680555555555557e-06,
      "loss": 0.0008,
      "step": 30470
    },
    {
      "epoch": 1.6933333333333334,
      "grad_norm": 0.0,
      "learning_rate": 7.666666666666667e-06,
      "loss": 0.0004,
      "step": 30480
    },
    {
      "epoch": 1.693888888888889,
      "grad_norm": 0.0,
      "learning_rate": 7.652777777777778e-06,
      "loss": 0.0002,
      "step": 30490
    },
    {
      "epoch": 1.6944444444444444,
      "grad_norm": 0.2760012149810791,
      "learning_rate": 7.63888888888889e-06,
      "loss": 0.0006,
      "step": 30500
    },
    {
      "epoch": 1.6949999999999998,
      "grad_norm": 0.14174766838550568,
      "learning_rate": 7.625e-06,
      "loss": 0.0008,
      "step": 30510
    },
    {
      "epoch": 1.6955555555555555,
      "grad_norm": 0.09516187012195587,
      "learning_rate": 7.611111111111112e-06,
      "loss": 0.0003,
      "step": 30520
    },
    {
      "epoch": 1.6961111111111111,
      "grad_norm": 0.0,
      "learning_rate": 7.597222222222222e-06,
      "loss": 0.0004,
      "step": 30530
    },
    {
      "epoch": 1.6966666666666668,
      "grad_norm": 0.09663158655166626,
      "learning_rate": 7.583333333333334e-06,
      "loss": 0.0028,
      "step": 30540
    },
    {
      "epoch": 1.6972222222222222,
      "grad_norm": 0.3596319556236267,
      "learning_rate": 7.569444444444444e-06,
      "loss": 0.0002,
      "step": 30550
    },
    {
      "epoch": 1.6977777777777778,
      "grad_norm": 0.03922206535935402,
      "learning_rate": 7.555555555555556e-06,
      "loss": 0.0004,
      "step": 30560
    },
    {
      "epoch": 1.6983333333333333,
      "grad_norm": 0.2299177199602127,
      "learning_rate": 7.541666666666668e-06,
      "loss": 0.0004,
      "step": 30570
    },
    {
      "epoch": 1.698888888888889,
      "grad_norm": 0.045934487134218216,
      "learning_rate": 7.527777777777778e-06,
      "loss": 0.0002,
      "step": 30580
    },
    {
      "epoch": 1.6994444444444445,
      "grad_norm": 0.0,
      "learning_rate": 7.51388888888889e-06,
      "loss": 0.0004,
      "step": 30590
    },
    {
      "epoch": 1.7,
      "grad_norm": 0.15882933139801025,
      "learning_rate": 7.5e-06,
      "loss": 0.0002,
      "step": 30600
    },
    {
      "epoch": 1.7005555555555556,
      "grad_norm": 0.0,
      "learning_rate": 7.486111111111112e-06,
      "loss": 0.0015,
      "step": 30610
    },
    {
      "epoch": 1.701111111111111,
      "grad_norm": 0.0,
      "learning_rate": 7.472222222222222e-06,
      "loss": 0.0004,
      "step": 30620
    },
    {
      "epoch": 1.7016666666666667,
      "grad_norm": 0.0,
      "learning_rate": 7.458333333333334e-06,
      "loss": 0.0,
      "step": 30630
    },
    {
      "epoch": 1.7022222222222223,
      "grad_norm": 0.0,
      "learning_rate": 7.444444444444444e-06,
      "loss": 0.0001,
      "step": 30640
    },
    {
      "epoch": 1.7027777777777777,
      "grad_norm": 0.0,
      "learning_rate": 7.430555555555556e-06,
      "loss": 0.0004,
      "step": 30650
    },
    {
      "epoch": 1.7033333333333334,
      "grad_norm": 0.048057738691568375,
      "learning_rate": 7.416666666666668e-06,
      "loss": 0.0002,
      "step": 30660
    },
    {
      "epoch": 1.7038888888888888,
      "grad_norm": 0.0,
      "learning_rate": 7.402777777777778e-06,
      "loss": 0.0008,
      "step": 30670
    },
    {
      "epoch": 1.7044444444444444,
      "grad_norm": 0.0,
      "learning_rate": 7.38888888888889e-06,
      "loss": 0.0013,
      "step": 30680
    },
    {
      "epoch": 1.705,
      "grad_norm": 0.17404475808143616,
      "learning_rate": 7.375e-06,
      "loss": 0.001,
      "step": 30690
    },
    {
      "epoch": 1.7055555555555557,
      "grad_norm": 0.0,
      "learning_rate": 7.361111111111112e-06,
      "loss": 0.0002,
      "step": 30700
    },
    {
      "epoch": 1.7061111111111111,
      "grad_norm": 0.0503133162856102,
      "learning_rate": 7.347222222222222e-06,
      "loss": 0.0001,
      "step": 30710
    },
    {
      "epoch": 1.7066666666666666,
      "grad_norm": 0.05156072974205017,
      "learning_rate": 7.333333333333334e-06,
      "loss": 0.0001,
      "step": 30720
    },
    {
      "epoch": 1.7072222222222222,
      "grad_norm": 0.0,
      "learning_rate": 7.319444444444445e-06,
      "loss": 0.0007,
      "step": 30730
    },
    {
      "epoch": 1.7077777777777778,
      "grad_norm": 0.0,
      "learning_rate": 7.305555555555556e-06,
      "loss": 0.0008,
      "step": 30740
    },
    {
      "epoch": 1.7083333333333335,
      "grad_norm": 0.01257521566003561,
      "learning_rate": 7.2916666666666674e-06,
      "loss": 0.0008,
      "step": 30750
    },
    {
      "epoch": 1.708888888888889,
      "grad_norm": 0.2955183982849121,
      "learning_rate": 7.277777777777778e-06,
      "loss": 0.0006,
      "step": 30760
    },
    {
      "epoch": 1.7094444444444443,
      "grad_norm": 0.0,
      "learning_rate": 7.2638888888888895e-06,
      "loss": 0.0004,
      "step": 30770
    },
    {
      "epoch": 1.71,
      "grad_norm": 0.11401292681694031,
      "learning_rate": 7.25e-06,
      "loss": 0.0005,
      "step": 30780
    },
    {
      "epoch": 1.7105555555555556,
      "grad_norm": 0.0,
      "learning_rate": 7.2361111111111115e-06,
      "loss": 0.0006,
      "step": 30790
    },
    {
      "epoch": 1.7111111111111112,
      "grad_norm": 0.0,
      "learning_rate": 7.222222222222222e-06,
      "loss": 0.001,
      "step": 30800
    },
    {
      "epoch": 1.7116666666666667,
      "grad_norm": 0.0,
      "learning_rate": 7.2083333333333335e-06,
      "loss": 0.0004,
      "step": 30810
    },
    {
      "epoch": 1.712222222222222,
      "grad_norm": 0.0,
      "learning_rate": 7.194444444444445e-06,
      "loss": 0.0008,
      "step": 30820
    },
    {
      "epoch": 1.7127777777777777,
      "grad_norm": 0.293351948261261,
      "learning_rate": 7.1805555555555555e-06,
      "loss": 0.0002,
      "step": 30830
    },
    {
      "epoch": 1.7133333333333334,
      "grad_norm": 0.0,
      "learning_rate": 7.166666666666667e-06,
      "loss": 0.0006,
      "step": 30840
    },
    {
      "epoch": 1.713888888888889,
      "grad_norm": 0.0,
      "learning_rate": 7.1527777777777775e-06,
      "loss": 0.0011,
      "step": 30850
    },
    {
      "epoch": 1.7144444444444444,
      "grad_norm": 0.0,
      "learning_rate": 7.13888888888889e-06,
      "loss": 0.0004,
      "step": 30860
    },
    {
      "epoch": 1.7149999999999999,
      "grad_norm": 0.0,
      "learning_rate": 7.1249999999999995e-06,
      "loss": 0.0002,
      "step": 30870
    },
    {
      "epoch": 1.7155555555555555,
      "grad_norm": 0.0,
      "learning_rate": 7.111111111111112e-06,
      "loss": 0.0005,
      "step": 30880
    },
    {
      "epoch": 1.7161111111111111,
      "grad_norm": 0.0,
      "learning_rate": 7.097222222222223e-06,
      "loss": 0.0011,
      "step": 30890
    },
    {
      "epoch": 1.7166666666666668,
      "grad_norm": 0.17798782885074615,
      "learning_rate": 7.083333333333334e-06,
      "loss": 0.0003,
      "step": 30900
    },
    {
      "epoch": 1.7172222222222222,
      "grad_norm": 0.0,
      "learning_rate": 7.069444444444445e-06,
      "loss": 0.0007,
      "step": 30910
    },
    {
      "epoch": 1.7177777777777776,
      "grad_norm": 0.0,
      "learning_rate": 7.055555555555556e-06,
      "loss": 0.0002,
      "step": 30920
    },
    {
      "epoch": 1.7183333333333333,
      "grad_norm": 0.2275356501340866,
      "learning_rate": 7.041666666666667e-06,
      "loss": 0.0007,
      "step": 30930
    },
    {
      "epoch": 1.718888888888889,
      "grad_norm": 0.046790361404418945,
      "learning_rate": 7.027777777777778e-06,
      "loss": 0.0004,
      "step": 30940
    },
    {
      "epoch": 1.7194444444444446,
      "grad_norm": 0.0,
      "learning_rate": 7.013888888888889e-06,
      "loss": 0.0003,
      "step": 30950
    },
    {
      "epoch": 1.72,
      "grad_norm": 0.0,
      "learning_rate": 7.000000000000001e-06,
      "loss": 0.001,
      "step": 30960
    },
    {
      "epoch": 1.7205555555555554,
      "grad_norm": 0.2163798063993454,
      "learning_rate": 6.986111111111111e-06,
      "loss": 0.001,
      "step": 30970
    },
    {
      "epoch": 1.721111111111111,
      "grad_norm": 0.0,
      "learning_rate": 6.972222222222223e-06,
      "loss": 0.0005,
      "step": 30980
    },
    {
      "epoch": 1.7216666666666667,
      "grad_norm": 0.30945858359336853,
      "learning_rate": 6.958333333333333e-06,
      "loss": 0.0008,
      "step": 30990
    },
    {
      "epoch": 1.7222222222222223,
      "grad_norm": 0.07040297240018845,
      "learning_rate": 6.944444444444445e-06,
      "loss": 0.0007,
      "step": 31000
    },
    {
      "epoch": 1.7227777777777777,
      "grad_norm": 0.0,
      "learning_rate": 6.930555555555555e-06,
      "loss": 0.0012,
      "step": 31010
    },
    {
      "epoch": 1.7233333333333334,
      "grad_norm": 0.051367226988077164,
      "learning_rate": 6.916666666666667e-06,
      "loss": 0.0004,
      "step": 31020
    },
    {
      "epoch": 1.7238888888888888,
      "grad_norm": 0.0,
      "learning_rate": 6.902777777777777e-06,
      "loss": 0.0002,
      "step": 31030
    },
    {
      "epoch": 1.7244444444444444,
      "grad_norm": 0.2089502215385437,
      "learning_rate": 6.888888888888889e-06,
      "loss": 0.0004,
      "step": 31040
    },
    {
      "epoch": 1.725,
      "grad_norm": 0.0,
      "learning_rate": 6.875000000000001e-06,
      "loss": 0.0003,
      "step": 31050
    },
    {
      "epoch": 1.7255555555555555,
      "grad_norm": 0.0,
      "learning_rate": 6.861111111111111e-06,
      "loss": 0.0004,
      "step": 31060
    },
    {
      "epoch": 1.7261111111111112,
      "grad_norm": 0.0,
      "learning_rate": 6.847222222222223e-06,
      "loss": 0.0004,
      "step": 31070
    },
    {
      "epoch": 1.7266666666666666,
      "grad_norm": 0.0,
      "learning_rate": 6.833333333333333e-06,
      "loss": 0.0001,
      "step": 31080
    },
    {
      "epoch": 1.7272222222222222,
      "grad_norm": 0.0,
      "learning_rate": 6.819444444444445e-06,
      "loss": 0.0001,
      "step": 31090
    },
    {
      "epoch": 1.7277777777777779,
      "grad_norm": 0.02966982312500477,
      "learning_rate": 6.805555555555556e-06,
      "loss": 0.0006,
      "step": 31100
    },
    {
      "epoch": 1.7283333333333335,
      "grad_norm": 0.055451251566410065,
      "learning_rate": 6.791666666666667e-06,
      "loss": 0.0003,
      "step": 31110
    },
    {
      "epoch": 1.728888888888889,
      "grad_norm": 0.0,
      "learning_rate": 6.777777777777779e-06,
      "loss": 0.0004,
      "step": 31120
    },
    {
      "epoch": 1.7294444444444443,
      "grad_norm": 0.24349236488342285,
      "learning_rate": 6.763888888888889e-06,
      "loss": 0.0013,
      "step": 31130
    },
    {
      "epoch": 1.73,
      "grad_norm": 0.0,
      "learning_rate": 6.750000000000001e-06,
      "loss": 0.0003,
      "step": 31140
    },
    {
      "epoch": 1.7305555555555556,
      "grad_norm": 0.06069941073656082,
      "learning_rate": 6.736111111111111e-06,
      "loss": 0.0008,
      "step": 31150
    },
    {
      "epoch": 1.7311111111111113,
      "grad_norm": 0.05425306782126427,
      "learning_rate": 6.722222222222223e-06,
      "loss": 0.0001,
      "step": 31160
    },
    {
      "epoch": 1.7316666666666667,
      "grad_norm": 0.0,
      "learning_rate": 6.708333333333333e-06,
      "loss": 0.0007,
      "step": 31170
    },
    {
      "epoch": 1.732222222222222,
      "grad_norm": 0.0,
      "learning_rate": 6.694444444444445e-06,
      "loss": 0.0008,
      "step": 31180
    },
    {
      "epoch": 1.7327777777777778,
      "grad_norm": 0.0,
      "learning_rate": 6.680555555555557e-06,
      "loss": 0.0006,
      "step": 31190
    },
    {
      "epoch": 1.7333333333333334,
      "grad_norm": 0.0,
      "learning_rate": 6.666666666666667e-06,
      "loss": 0.0003,
      "step": 31200
    },
    {
      "epoch": 1.733888888888889,
      "grad_norm": 0.0,
      "learning_rate": 6.652777777777779e-06,
      "loss": 0.0003,
      "step": 31210
    },
    {
      "epoch": 1.7344444444444445,
      "grad_norm": 0.0,
      "learning_rate": 6.638888888888889e-06,
      "loss": 0.0,
      "step": 31220
    },
    {
      "epoch": 1.7349999999999999,
      "grad_norm": 0.0,
      "learning_rate": 6.625000000000001e-06,
      "loss": 0.0004,
      "step": 31230
    },
    {
      "epoch": 1.7355555555555555,
      "grad_norm": 0.0,
      "learning_rate": 6.611111111111111e-06,
      "loss": 0.0007,
      "step": 31240
    },
    {
      "epoch": 1.7361111111111112,
      "grad_norm": 0.24416086077690125,
      "learning_rate": 6.597222222222223e-06,
      "loss": 0.001,
      "step": 31250
    },
    {
      "epoch": 1.7366666666666668,
      "grad_norm": 0.3086591362953186,
      "learning_rate": 6.583333333333333e-06,
      "loss": 0.0002,
      "step": 31260
    },
    {
      "epoch": 1.7372222222222222,
      "grad_norm": 0.0,
      "learning_rate": 6.569444444444445e-06,
      "loss": 0.0004,
      "step": 31270
    },
    {
      "epoch": 1.7377777777777776,
      "grad_norm": 0.12150635570287704,
      "learning_rate": 6.555555555555556e-06,
      "loss": 0.0005,
      "step": 31280
    },
    {
      "epoch": 1.7383333333333333,
      "grad_norm": 0.05542726442217827,
      "learning_rate": 6.541666666666667e-06,
      "loss": 0.0008,
      "step": 31290
    },
    {
      "epoch": 1.738888888888889,
      "grad_norm": 0.0,
      "learning_rate": 6.5277777777777784e-06,
      "loss": 0.0006,
      "step": 31300
    },
    {
      "epoch": 1.7394444444444446,
      "grad_norm": 0.0,
      "learning_rate": 6.513888888888889e-06,
      "loss": 0.0001,
      "step": 31310
    },
    {
      "epoch": 1.74,
      "grad_norm": 0.0,
      "learning_rate": 6.5000000000000004e-06,
      "loss": 0.0009,
      "step": 31320
    },
    {
      "epoch": 1.7405555555555554,
      "grad_norm": 0.0,
      "learning_rate": 6.486111111111111e-06,
      "loss": 0.0009,
      "step": 31330
    },
    {
      "epoch": 1.741111111111111,
      "grad_norm": 0.047286175191402435,
      "learning_rate": 6.4722222222222225e-06,
      "loss": 0.0005,
      "step": 31340
    },
    {
      "epoch": 1.7416666666666667,
      "grad_norm": 0.0,
      "learning_rate": 6.458333333333334e-06,
      "loss": 0.0001,
      "step": 31350
    },
    {
      "epoch": 1.7422222222222223,
      "grad_norm": 0.0,
      "learning_rate": 6.4444444444444445e-06,
      "loss": 0.0002,
      "step": 31360
    },
    {
      "epoch": 1.7427777777777778,
      "grad_norm": 0.0,
      "learning_rate": 6.430555555555556e-06,
      "loss": 0.0002,
      "step": 31370
    },
    {
      "epoch": 1.7433333333333332,
      "grad_norm": 0.0,
      "learning_rate": 6.4166666666666665e-06,
      "loss": 0.0001,
      "step": 31380
    },
    {
      "epoch": 1.7438888888888888,
      "grad_norm": 0.0,
      "learning_rate": 6.402777777777779e-06,
      "loss": 0.0001,
      "step": 31390
    },
    {
      "epoch": 1.7444444444444445,
      "grad_norm": 0.2546573579311371,
      "learning_rate": 6.3888888888888885e-06,
      "loss": 0.0004,
      "step": 31400
    },
    {
      "epoch": 1.745,
      "grad_norm": 0.0,
      "learning_rate": 6.375000000000001e-06,
      "loss": 0.0004,
      "step": 31410
    },
    {
      "epoch": 1.7455555555555555,
      "grad_norm": 0.0,
      "learning_rate": 6.3611111111111105e-06,
      "loss": 0.0004,
      "step": 31420
    },
    {
      "epoch": 1.746111111111111,
      "grad_norm": 0.051399972289800644,
      "learning_rate": 6.347222222222223e-06,
      "loss": 0.0005,
      "step": 31430
    },
    {
      "epoch": 1.7466666666666666,
      "grad_norm": 0.0,
      "learning_rate": 6.333333333333334e-06,
      "loss": 0.0002,
      "step": 31440
    },
    {
      "epoch": 1.7472222222222222,
      "grad_norm": 0.0,
      "learning_rate": 6.319444444444445e-06,
      "loss": 0.0006,
      "step": 31450
    },
    {
      "epoch": 1.7477777777777779,
      "grad_norm": 0.043740298599004745,
      "learning_rate": 6.305555555555556e-06,
      "loss": 0.0009,
      "step": 31460
    },
    {
      "epoch": 1.7483333333333333,
      "grad_norm": 0.1017400473356247,
      "learning_rate": 6.291666666666667e-06,
      "loss": 0.0004,
      "step": 31470
    },
    {
      "epoch": 1.748888888888889,
      "grad_norm": 0.04921736195683479,
      "learning_rate": 6.277777777777778e-06,
      "loss": 0.0006,
      "step": 31480
    },
    {
      "epoch": 1.7494444444444444,
      "grad_norm": 0.060977790504693985,
      "learning_rate": 6.263888888888889e-06,
      "loss": 0.0007,
      "step": 31490
    },
    {
      "epoch": 1.75,
      "grad_norm": 0.19262073934078217,
      "learning_rate": 6.25e-06,
      "loss": 0.0003,
      "step": 31500
    },
    {
      "epoch": 1.7505555555555556,
      "grad_norm": 0.0,
      "learning_rate": 6.236111111111112e-06,
      "loss": 0.0002,
      "step": 31510
    },
    {
      "epoch": 1.751111111111111,
      "grad_norm": 0.0,
      "learning_rate": 6.222222222222222e-06,
      "loss": 0.0007,
      "step": 31520
    },
    {
      "epoch": 1.7516666666666667,
      "grad_norm": 0.0,
      "learning_rate": 6.208333333333334e-06,
      "loss": 0.0001,
      "step": 31530
    },
    {
      "epoch": 1.7522222222222221,
      "grad_norm": 0.0,
      "learning_rate": 6.194444444444445e-06,
      "loss": 0.0002,
      "step": 31540
    },
    {
      "epoch": 1.7527777777777778,
      "grad_norm": 0.08515028655529022,
      "learning_rate": 6.180555555555556e-06,
      "loss": 0.0008,
      "step": 31550
    },
    {
      "epoch": 1.7533333333333334,
      "grad_norm": 0.04574429616332054,
      "learning_rate": 6.166666666666667e-06,
      "loss": 0.0006,
      "step": 31560
    },
    {
      "epoch": 1.753888888888889,
      "grad_norm": 0.08662179857492447,
      "learning_rate": 6.152777777777778e-06,
      "loss": 0.0003,
      "step": 31570
    },
    {
      "epoch": 1.7544444444444445,
      "grad_norm": 0.04289385303854942,
      "learning_rate": 6.138888888888889e-06,
      "loss": 0.0007,
      "step": 31580
    },
    {
      "epoch": 1.755,
      "grad_norm": 0.21199260652065277,
      "learning_rate": 6.125e-06,
      "loss": 0.0005,
      "step": 31590
    },
    {
      "epoch": 1.7555555555555555,
      "grad_norm": 0.0,
      "learning_rate": 6.111111111111111e-06,
      "loss": 0.0004,
      "step": 31600
    },
    {
      "epoch": 1.7561111111111112,
      "grad_norm": 0.05067982152104378,
      "learning_rate": 6.097222222222222e-06,
      "loss": 0.0004,
      "step": 31610
    },
    {
      "epoch": 1.7566666666666668,
      "grad_norm": 0.05508885532617569,
      "learning_rate": 6.083333333333334e-06,
      "loss": 0.0003,
      "step": 31620
    },
    {
      "epoch": 1.7572222222222222,
      "grad_norm": 0.05678064748644829,
      "learning_rate": 6.069444444444445e-06,
      "loss": 0.0013,
      "step": 31630
    },
    {
      "epoch": 1.7577777777777777,
      "grad_norm": 0.0,
      "learning_rate": 6.055555555555556e-06,
      "loss": 0.0004,
      "step": 31640
    },
    {
      "epoch": 1.7583333333333333,
      "grad_norm": 0.04137076437473297,
      "learning_rate": 6.041666666666667e-06,
      "loss": 0.0001,
      "step": 31650
    },
    {
      "epoch": 1.758888888888889,
      "grad_norm": 0.0,
      "learning_rate": 6.027777777777778e-06,
      "loss": 0.0014,
      "step": 31660
    },
    {
      "epoch": 1.7594444444444446,
      "grad_norm": 0.1097898930311203,
      "learning_rate": 6.013888888888889e-06,
      "loss": 0.0009,
      "step": 31670
    },
    {
      "epoch": 1.76,
      "grad_norm": 0.04489820450544357,
      "learning_rate": 6e-06,
      "loss": 0.0009,
      "step": 31680
    },
    {
      "epoch": 1.7605555555555554,
      "grad_norm": 0.0,
      "learning_rate": 5.986111111111111e-06,
      "loss": 0.0005,
      "step": 31690
    },
    {
      "epoch": 1.761111111111111,
      "grad_norm": 0.043862484395504,
      "learning_rate": 5.972222222222223e-06,
      "loss": 0.0007,
      "step": 31700
    },
    {
      "epoch": 1.7616666666666667,
      "grad_norm": 0.0872357115149498,
      "learning_rate": 5.958333333333334e-06,
      "loss": 0.0003,
      "step": 31710
    },
    {
      "epoch": 1.7622222222222224,
      "grad_norm": 0.1432151049375534,
      "learning_rate": 5.944444444444445e-06,
      "loss": 0.0005,
      "step": 31720
    },
    {
      "epoch": 1.7627777777777778,
      "grad_norm": 0.04639602452516556,
      "learning_rate": 5.930555555555556e-06,
      "loss": 0.0004,
      "step": 31730
    },
    {
      "epoch": 1.7633333333333332,
      "grad_norm": 0.0,
      "learning_rate": 5.916666666666667e-06,
      "loss": 0.0005,
      "step": 31740
    },
    {
      "epoch": 1.7638888888888888,
      "grad_norm": 0.0,
      "learning_rate": 5.902777777777778e-06,
      "loss": 0.0,
      "step": 31750
    },
    {
      "epoch": 1.7644444444444445,
      "grad_norm": 0.04530045762658119,
      "learning_rate": 5.888888888888889e-06,
      "loss": 0.0001,
      "step": 31760
    },
    {
      "epoch": 1.7650000000000001,
      "grad_norm": 0.0,
      "learning_rate": 5.875e-06,
      "loss": 0.001,
      "step": 31770
    },
    {
      "epoch": 1.7655555555555555,
      "grad_norm": 0.0,
      "learning_rate": 5.861111111111112e-06,
      "loss": 0.001,
      "step": 31780
    },
    {
      "epoch": 1.766111111111111,
      "grad_norm": 0.0,
      "learning_rate": 5.8472222222222225e-06,
      "loss": 0.0001,
      "step": 31790
    },
    {
      "epoch": 1.7666666666666666,
      "grad_norm": 0.048154566437006,
      "learning_rate": 5.833333333333334e-06,
      "loss": 0.0003,
      "step": 31800
    },
    {
      "epoch": 1.7672222222222222,
      "grad_norm": 0.04434690251946449,
      "learning_rate": 5.8194444444444445e-06,
      "loss": 0.0006,
      "step": 31810
    },
    {
      "epoch": 1.767777777777778,
      "grad_norm": 0.0,
      "learning_rate": 5.805555555555556e-06,
      "loss": 0.0001,
      "step": 31820
    },
    {
      "epoch": 1.7683333333333333,
      "grad_norm": 0.0,
      "learning_rate": 5.7916666666666666e-06,
      "loss": 0.0004,
      "step": 31830
    },
    {
      "epoch": 1.7688888888888887,
      "grad_norm": 0.0,
      "learning_rate": 5.777777777777778e-06,
      "loss": 0.0004,
      "step": 31840
    },
    {
      "epoch": 1.7694444444444444,
      "grad_norm": 0.21669258177280426,
      "learning_rate": 5.763888888888889e-06,
      "loss": 0.0006,
      "step": 31850
    },
    {
      "epoch": 1.77,
      "grad_norm": 0.0,
      "learning_rate": 5.750000000000001e-06,
      "loss": 0.0007,
      "step": 31860
    },
    {
      "epoch": 1.7705555555555557,
      "grad_norm": 0.2707328200340271,
      "learning_rate": 5.7361111111111114e-06,
      "loss": 0.0004,
      "step": 31870
    },
    {
      "epoch": 1.771111111111111,
      "grad_norm": 0.08315947651863098,
      "learning_rate": 5.722222222222223e-06,
      "loss": 0.0003,
      "step": 31880
    },
    {
      "epoch": 1.7716666666666665,
      "grad_norm": 0.04582315310835838,
      "learning_rate": 5.7083333333333335e-06,
      "loss": 0.0,
      "step": 31890
    },
    {
      "epoch": 1.7722222222222221,
      "grad_norm": 0.0,
      "learning_rate": 5.694444444444445e-06,
      "loss": 0.0003,
      "step": 31900
    },
    {
      "epoch": 1.7727777777777778,
      "grad_norm": 0.0,
      "learning_rate": 5.6805555555555555e-06,
      "loss": 0.0007,
      "step": 31910
    },
    {
      "epoch": 1.7733333333333334,
      "grad_norm": 0.0,
      "learning_rate": 5.666666666666667e-06,
      "loss": 0.0006,
      "step": 31920
    },
    {
      "epoch": 1.7738888888888888,
      "grad_norm": 0.170538067817688,
      "learning_rate": 5.652777777777778e-06,
      "loss": 0.0007,
      "step": 31930
    },
    {
      "epoch": 1.7744444444444445,
      "grad_norm": 0.0,
      "learning_rate": 5.63888888888889e-06,
      "loss": 0.0002,
      "step": 31940
    },
    {
      "epoch": 1.775,
      "grad_norm": 0.0,
      "learning_rate": 5.625e-06,
      "loss": 0.0005,
      "step": 31950
    },
    {
      "epoch": 1.7755555555555556,
      "grad_norm": 0.0,
      "learning_rate": 5.611111111111112e-06,
      "loss": 0.0003,
      "step": 31960
    },
    {
      "epoch": 1.7761111111111112,
      "grad_norm": 0.0,
      "learning_rate": 5.597222222222222e-06,
      "loss": 0.0003,
      "step": 31970
    },
    {
      "epoch": 1.7766666666666666,
      "grad_norm": 0.0,
      "learning_rate": 5.583333333333334e-06,
      "loss": 0.0007,
      "step": 31980
    },
    {
      "epoch": 1.7772222222222223,
      "grad_norm": 0.0,
      "learning_rate": 5.569444444444444e-06,
      "loss": 0.0007,
      "step": 31990
    },
    {
      "epoch": 1.7777777777777777,
      "grad_norm": 0.0,
      "learning_rate": 5.555555555555556e-06,
      "loss": 0.0008,
      "step": 32000
    },
    {
      "epoch": 1.7783333333333333,
      "grad_norm": 0.14148877561092377,
      "learning_rate": 5.541666666666667e-06,
      "loss": 0.0004,
      "step": 32010
    },
    {
      "epoch": 1.778888888888889,
      "grad_norm": 0.04568161815404892,
      "learning_rate": 5.527777777777778e-06,
      "loss": 0.0001,
      "step": 32020
    },
    {
      "epoch": 1.7794444444444446,
      "grad_norm": 0.0,
      "learning_rate": 5.513888888888889e-06,
      "loss": 0.0002,
      "step": 32030
    },
    {
      "epoch": 1.78,
      "grad_norm": 0.0,
      "learning_rate": 5.500000000000001e-06,
      "loss": 0.0008,
      "step": 32040
    },
    {
      "epoch": 1.7805555555555554,
      "grad_norm": 0.0,
      "learning_rate": 5.486111111111111e-06,
      "loss": 0.0006,
      "step": 32050
    },
    {
      "epoch": 1.781111111111111,
      "grad_norm": 0.0,
      "learning_rate": 5.472222222222223e-06,
      "loss": 0.0006,
      "step": 32060
    },
    {
      "epoch": 1.7816666666666667,
      "grad_norm": 0.0,
      "learning_rate": 5.458333333333333e-06,
      "loss": 0.0002,
      "step": 32070
    },
    {
      "epoch": 1.7822222222222224,
      "grad_norm": 0.0909336507320404,
      "learning_rate": 5.444444444444445e-06,
      "loss": 0.0009,
      "step": 32080
    },
    {
      "epoch": 1.7827777777777778,
      "grad_norm": 0.0,
      "learning_rate": 5.430555555555556e-06,
      "loss": 0.0001,
      "step": 32090
    },
    {
      "epoch": 1.7833333333333332,
      "grad_norm": 0.26411476731300354,
      "learning_rate": 5.416666666666667e-06,
      "loss": 0.0006,
      "step": 32100
    },
    {
      "epoch": 1.7838888888888889,
      "grad_norm": 0.0,
      "learning_rate": 5.402777777777778e-06,
      "loss": 0.0012,
      "step": 32110
    },
    {
      "epoch": 1.7844444444444445,
      "grad_norm": 0.0,
      "learning_rate": 5.388888888888889e-06,
      "loss": 0.0003,
      "step": 32120
    },
    {
      "epoch": 1.7850000000000001,
      "grad_norm": 0.3291522264480591,
      "learning_rate": 5.375e-06,
      "loss": 0.0003,
      "step": 32130
    },
    {
      "epoch": 1.7855555555555556,
      "grad_norm": 0.0,
      "learning_rate": 5.361111111111111e-06,
      "loss": 0.001,
      "step": 32140
    },
    {
      "epoch": 1.786111111111111,
      "grad_norm": 0.0,
      "learning_rate": 5.347222222222222e-06,
      "loss": 0.0009,
      "step": 32150
    },
    {
      "epoch": 1.7866666666666666,
      "grad_norm": 0.016368629410862923,
      "learning_rate": 5.333333333333334e-06,
      "loss": 0.0008,
      "step": 32160
    },
    {
      "epoch": 1.7872222222222223,
      "grad_norm": 0.12198162823915482,
      "learning_rate": 5.319444444444445e-06,
      "loss": 0.0009,
      "step": 32170
    },
    {
      "epoch": 1.787777777777778,
      "grad_norm": 0.0539303757250309,
      "learning_rate": 5.305555555555556e-06,
      "loss": 0.0003,
      "step": 32180
    },
    {
      "epoch": 1.7883333333333333,
      "grad_norm": 0.15556225180625916,
      "learning_rate": 5.291666666666667e-06,
      "loss": 0.0004,
      "step": 32190
    },
    {
      "epoch": 1.7888888888888888,
      "grad_norm": 0.08586900681257248,
      "learning_rate": 5.277777777777778e-06,
      "loss": 0.0009,
      "step": 32200
    },
    {
      "epoch": 1.7894444444444444,
      "grad_norm": 0.0,
      "learning_rate": 5.263888888888889e-06,
      "loss": 0.0007,
      "step": 32210
    },
    {
      "epoch": 1.79,
      "grad_norm": 0.12152470648288727,
      "learning_rate": 5.25e-06,
      "loss": 0.0005,
      "step": 32220
    },
    {
      "epoch": 1.7905555555555557,
      "grad_norm": 0.0,
      "learning_rate": 5.236111111111111e-06,
      "loss": 0.0002,
      "step": 32230
    },
    {
      "epoch": 1.791111111111111,
      "grad_norm": 0.050749000161886215,
      "learning_rate": 5.2222222222222226e-06,
      "loss": 0.0004,
      "step": 32240
    },
    {
      "epoch": 1.7916666666666665,
      "grad_norm": 0.0,
      "learning_rate": 5.208333333333334e-06,
      "loss": 0.0003,
      "step": 32250
    },
    {
      "epoch": 1.7922222222222222,
      "grad_norm": 0.060182273387908936,
      "learning_rate": 5.194444444444445e-06,
      "loss": 0.0002,
      "step": 32260
    },
    {
      "epoch": 1.7927777777777778,
      "grad_norm": 0.0,
      "learning_rate": 5.180555555555556e-06,
      "loss": 0.0008,
      "step": 32270
    },
    {
      "epoch": 1.7933333333333334,
      "grad_norm": 0.030868757516145706,
      "learning_rate": 5.166666666666667e-06,
      "loss": 0.0008,
      "step": 32280
    },
    {
      "epoch": 1.7938888888888889,
      "grad_norm": 0.0,
      "learning_rate": 5.152777777777778e-06,
      "loss": 0.0006,
      "step": 32290
    },
    {
      "epoch": 1.7944444444444443,
      "grad_norm": 0.0441422201693058,
      "learning_rate": 5.138888888888889e-06,
      "loss": 0.0013,
      "step": 32300
    },
    {
      "epoch": 1.795,
      "grad_norm": 0.0,
      "learning_rate": 5.125e-06,
      "loss": 0.0004,
      "step": 32310
    },
    {
      "epoch": 1.7955555555555556,
      "grad_norm": 0.043943364173173904,
      "learning_rate": 5.1111111111111115e-06,
      "loss": 0.0009,
      "step": 32320
    },
    {
      "epoch": 1.7961111111111112,
      "grad_norm": 0.0,
      "learning_rate": 5.097222222222223e-06,
      "loss": 0.0004,
      "step": 32330
    },
    {
      "epoch": 1.7966666666666666,
      "grad_norm": 0.0,
      "learning_rate": 5.0833333333333335e-06,
      "loss": 0.0006,
      "step": 32340
    },
    {
      "epoch": 1.7972222222222223,
      "grad_norm": 0.08952797204256058,
      "learning_rate": 5.069444444444445e-06,
      "loss": 0.0009,
      "step": 32350
    },
    {
      "epoch": 1.7977777777777777,
      "grad_norm": 0.0465739369392395,
      "learning_rate": 5.0555555555555555e-06,
      "loss": 0.0007,
      "step": 32360
    },
    {
      "epoch": 1.7983333333333333,
      "grad_norm": 0.0,
      "learning_rate": 5.041666666666667e-06,
      "loss": 0.0,
      "step": 32370
    },
    {
      "epoch": 1.798888888888889,
      "grad_norm": 0.0,
      "learning_rate": 5.0277777777777775e-06,
      "loss": 0.0003,
      "step": 32380
    },
    {
      "epoch": 1.7994444444444444,
      "grad_norm": 0.0,
      "learning_rate": 5.013888888888889e-06,
      "loss": 0.0002,
      "step": 32390
    },
    {
      "epoch": 1.8,
      "grad_norm": 0.06452950090169907,
      "learning_rate": 5e-06,
      "loss": 0.0007,
      "step": 32400
    },
    {
      "epoch": 1.8005555555555555,
      "grad_norm": 0.305113285779953,
      "learning_rate": 4.986111111111112e-06,
      "loss": 0.0012,
      "step": 32410
    },
    {
      "epoch": 1.801111111111111,
      "grad_norm": 0.0,
      "learning_rate": 4.9722222222222224e-06,
      "loss": 0.0005,
      "step": 32420
    },
    {
      "epoch": 1.8016666666666667,
      "grad_norm": 0.0481329970061779,
      "learning_rate": 4.958333333333334e-06,
      "loss": 0.0004,
      "step": 32430
    },
    {
      "epoch": 1.8022222222222222,
      "grad_norm": 0.0,
      "learning_rate": 4.9444444444444444e-06,
      "loss": 0.0002,
      "step": 32440
    },
    {
      "epoch": 1.8027777777777778,
      "grad_norm": 0.0,
      "learning_rate": 4.930555555555556e-06,
      "loss": 0.0012,
      "step": 32450
    },
    {
      "epoch": 1.8033333333333332,
      "grad_norm": 0.26478374004364014,
      "learning_rate": 4.9166666666666665e-06,
      "loss": 0.0003,
      "step": 32460
    },
    {
      "epoch": 1.8038888888888889,
      "grad_norm": 0.062166716903448105,
      "learning_rate": 4.902777777777779e-06,
      "loss": 0.0002,
      "step": 32470
    },
    {
      "epoch": 1.8044444444444445,
      "grad_norm": 0.08228450268507004,
      "learning_rate": 4.888888888888889e-06,
      "loss": 0.0005,
      "step": 32480
    },
    {
      "epoch": 1.8050000000000002,
      "grad_norm": 0.0,
      "learning_rate": 4.875000000000001e-06,
      "loss": 0.0005,
      "step": 32490
    },
    {
      "epoch": 1.8055555555555556,
      "grad_norm": 0.0,
      "learning_rate": 4.861111111111111e-06,
      "loss": 0.0003,
      "step": 32500
    },
    {
      "epoch": 1.806111111111111,
      "grad_norm": 0.056492988020181656,
      "learning_rate": 4.847222222222223e-06,
      "loss": 0.0004,
      "step": 32510
    },
    {
      "epoch": 1.8066666666666666,
      "grad_norm": 0.05820754915475845,
      "learning_rate": 4.833333333333333e-06,
      "loss": 0.0011,
      "step": 32520
    },
    {
      "epoch": 1.8072222222222223,
      "grad_norm": 0.27310195565223694,
      "learning_rate": 4.819444444444445e-06,
      "loss": 0.0009,
      "step": 32530
    },
    {
      "epoch": 1.807777777777778,
      "grad_norm": 0.0,
      "learning_rate": 4.805555555555555e-06,
      "loss": 0.0002,
      "step": 32540
    },
    {
      "epoch": 1.8083333333333333,
      "grad_norm": 0.044571105390787125,
      "learning_rate": 4.791666666666667e-06,
      "loss": 0.0003,
      "step": 32550
    },
    {
      "epoch": 1.8088888888888888,
      "grad_norm": 0.05791559815406799,
      "learning_rate": 4.777777777777778e-06,
      "loss": 0.0001,
      "step": 32560
    },
    {
      "epoch": 1.8094444444444444,
      "grad_norm": 0.029496412724256516,
      "learning_rate": 4.76388888888889e-06,
      "loss": 0.0007,
      "step": 32570
    },
    {
      "epoch": 1.81,
      "grad_norm": 0.0,
      "learning_rate": 4.75e-06,
      "loss": 0.001,
      "step": 32580
    },
    {
      "epoch": 1.8105555555555557,
      "grad_norm": 0.0,
      "learning_rate": 4.736111111111112e-06,
      "loss": 0.0003,
      "step": 32590
    },
    {
      "epoch": 1.8111111111111111,
      "grad_norm": 0.05229838937520981,
      "learning_rate": 4.722222222222222e-06,
      "loss": 0.0003,
      "step": 32600
    },
    {
      "epoch": 1.8116666666666665,
      "grad_norm": 0.0,
      "learning_rate": 4.708333333333334e-06,
      "loss": 0.0001,
      "step": 32610
    },
    {
      "epoch": 1.8122222222222222,
      "grad_norm": 0.0,
      "learning_rate": 4.694444444444444e-06,
      "loss": 0.0006,
      "step": 32620
    },
    {
      "epoch": 1.8127777777777778,
      "grad_norm": 0.0,
      "learning_rate": 4.680555555555556e-06,
      "loss": 0.0013,
      "step": 32630
    },
    {
      "epoch": 1.8133333333333335,
      "grad_norm": 0.0,
      "learning_rate": 4.666666666666667e-06,
      "loss": 0.0,
      "step": 32640
    },
    {
      "epoch": 1.8138888888888889,
      "grad_norm": 0.07202021777629852,
      "learning_rate": 4.652777777777778e-06,
      "loss": 0.0006,
      "step": 32650
    },
    {
      "epoch": 1.8144444444444443,
      "grad_norm": 0.0,
      "learning_rate": 4.638888888888889e-06,
      "loss": 0.0006,
      "step": 32660
    },
    {
      "epoch": 1.815,
      "grad_norm": 0.04629483073949814,
      "learning_rate": 4.625e-06,
      "loss": 0.0004,
      "step": 32670
    },
    {
      "epoch": 1.8155555555555556,
      "grad_norm": 0.0,
      "learning_rate": 4.611111111111111e-06,
      "loss": 0.0001,
      "step": 32680
    },
    {
      "epoch": 1.8161111111111112,
      "grad_norm": 0.0,
      "learning_rate": 4.597222222222223e-06,
      "loss": 0.0003,
      "step": 32690
    },
    {
      "epoch": 1.8166666666666667,
      "grad_norm": 0.0,
      "learning_rate": 4.583333333333333e-06,
      "loss": 0.0006,
      "step": 32700
    },
    {
      "epoch": 1.817222222222222,
      "grad_norm": 0.0,
      "learning_rate": 4.569444444444445e-06,
      "loss": 0.0004,
      "step": 32710
    },
    {
      "epoch": 1.8177777777777777,
      "grad_norm": 0.03576098382472992,
      "learning_rate": 4.555555555555556e-06,
      "loss": 0.0003,
      "step": 32720
    },
    {
      "epoch": 1.8183333333333334,
      "grad_norm": 0.0,
      "learning_rate": 4.541666666666667e-06,
      "loss": 0.0001,
      "step": 32730
    },
    {
      "epoch": 1.818888888888889,
      "grad_norm": 0.0,
      "learning_rate": 4.527777777777778e-06,
      "loss": 0.0003,
      "step": 32740
    },
    {
      "epoch": 1.8194444444444444,
      "grad_norm": 0.1040496677160263,
      "learning_rate": 4.513888888888889e-06,
      "loss": 0.001,
      "step": 32750
    },
    {
      "epoch": 1.8199999999999998,
      "grad_norm": 0.1197887510061264,
      "learning_rate": 4.5e-06,
      "loss": 0.001,
      "step": 32760
    },
    {
      "epoch": 1.8205555555555555,
      "grad_norm": 0.09669632464647293,
      "learning_rate": 4.486111111111111e-06,
      "loss": 0.0002,
      "step": 32770
    },
    {
      "epoch": 1.8211111111111111,
      "grad_norm": 0.0,
      "learning_rate": 4.472222222222222e-06,
      "loss": 0.001,
      "step": 32780
    },
    {
      "epoch": 1.8216666666666668,
      "grad_norm": 0.0,
      "learning_rate": 4.4583333333333336e-06,
      "loss": 0.0003,
      "step": 32790
    },
    {
      "epoch": 1.8222222222222222,
      "grad_norm": 0.0,
      "learning_rate": 4.444444444444445e-06,
      "loss": 0.0003,
      "step": 32800
    },
    {
      "epoch": 1.8227777777777778,
      "grad_norm": 0.21164147555828094,
      "learning_rate": 4.430555555555556e-06,
      "loss": 0.0001,
      "step": 32810
    },
    {
      "epoch": 1.8233333333333333,
      "grad_norm": 0.047695696353912354,
      "learning_rate": 4.416666666666667e-06,
      "loss": 0.0005,
      "step": 32820
    },
    {
      "epoch": 1.823888888888889,
      "grad_norm": 0.0,
      "learning_rate": 4.402777777777778e-06,
      "loss": 0.0001,
      "step": 32830
    },
    {
      "epoch": 1.8244444444444445,
      "grad_norm": 0.0,
      "learning_rate": 4.388888888888889e-06,
      "loss": 0.0003,
      "step": 32840
    },
    {
      "epoch": 1.825,
      "grad_norm": 0.1144603043794632,
      "learning_rate": 4.375e-06,
      "loss": 0.0003,
      "step": 32850
    },
    {
      "epoch": 1.8255555555555556,
      "grad_norm": 0.24223341047763824,
      "learning_rate": 4.361111111111112e-06,
      "loss": 0.0007,
      "step": 32860
    },
    {
      "epoch": 1.826111111111111,
      "grad_norm": 0.0,
      "learning_rate": 4.3472222222222225e-06,
      "loss": 0.0008,
      "step": 32870
    },
    {
      "epoch": 1.8266666666666667,
      "grad_norm": 0.04488590732216835,
      "learning_rate": 4.333333333333334e-06,
      "loss": 0.0005,
      "step": 32880
    },
    {
      "epoch": 1.8272222222222223,
      "grad_norm": 0.12475837022066116,
      "learning_rate": 4.3194444444444445e-06,
      "loss": 0.0005,
      "step": 32890
    },
    {
      "epoch": 1.8277777777777777,
      "grad_norm": 0.05313178896903992,
      "learning_rate": 4.305555555555556e-06,
      "loss": 0.0006,
      "step": 32900
    },
    {
      "epoch": 1.8283333333333334,
      "grad_norm": 0.0,
      "learning_rate": 4.2916666666666665e-06,
      "loss": 0.0001,
      "step": 32910
    },
    {
      "epoch": 1.8288888888888888,
      "grad_norm": 0.0,
      "learning_rate": 4.277777777777778e-06,
      "loss": 0.0001,
      "step": 32920
    },
    {
      "epoch": 1.8294444444444444,
      "grad_norm": 0.0,
      "learning_rate": 4.2638888888888885e-06,
      "loss": 0.0002,
      "step": 32930
    },
    {
      "epoch": 1.83,
      "grad_norm": 0.05725935846567154,
      "learning_rate": 4.250000000000001e-06,
      "loss": 0.001,
      "step": 32940
    },
    {
      "epoch": 1.8305555555555557,
      "grad_norm": 0.04872075840830803,
      "learning_rate": 4.236111111111111e-06,
      "loss": 0.0004,
      "step": 32950
    },
    {
      "epoch": 1.8311111111111111,
      "grad_norm": 0.04875856637954712,
      "learning_rate": 4.222222222222223e-06,
      "loss": 0.0007,
      "step": 32960
    },
    {
      "epoch": 1.8316666666666666,
      "grad_norm": 0.04364020749926567,
      "learning_rate": 4.208333333333333e-06,
      "loss": 0.0006,
      "step": 32970
    },
    {
      "epoch": 1.8322222222222222,
      "grad_norm": 0.0,
      "learning_rate": 4.194444444444445e-06,
      "loss": 0.0007,
      "step": 32980
    },
    {
      "epoch": 1.8327777777777778,
      "grad_norm": 0.0980604737997055,
      "learning_rate": 4.1805555555555554e-06,
      "loss": 0.0001,
      "step": 32990
    },
    {
      "epoch": 1.8333333333333335,
      "grad_norm": 0.0940612256526947,
      "learning_rate": 4.166666666666667e-06,
      "loss": 0.0005,
      "step": 33000
    },
    {
      "epoch": 1.833888888888889,
      "grad_norm": 0.04517997056245804,
      "learning_rate": 4.1527777777777775e-06,
      "loss": 0.0005,
      "step": 33010
    },
    {
      "epoch": 1.8344444444444443,
      "grad_norm": 0.0,
      "learning_rate": 4.13888888888889e-06,
      "loss": 0.0007,
      "step": 33020
    },
    {
      "epoch": 1.835,
      "grad_norm": 0.036214932799339294,
      "learning_rate": 4.125e-06,
      "loss": 0.0005,
      "step": 33030
    },
    {
      "epoch": 1.8355555555555556,
      "grad_norm": 0.0,
      "learning_rate": 4.111111111111112e-06,
      "loss": 0.0004,
      "step": 33040
    },
    {
      "epoch": 1.8361111111111112,
      "grad_norm": 0.0,
      "learning_rate": 4.097222222222222e-06,
      "loss": 0.0002,
      "step": 33050
    },
    {
      "epoch": 1.8366666666666667,
      "grad_norm": 0.0,
      "learning_rate": 4.083333333333334e-06,
      "loss": 0.0004,
      "step": 33060
    },
    {
      "epoch": 1.837222222222222,
      "grad_norm": 0.0500611886382103,
      "learning_rate": 4.069444444444444e-06,
      "loss": 0.0017,
      "step": 33070
    },
    {
      "epoch": 1.8377777777777777,
      "grad_norm": 0.0,
      "learning_rate": 4.055555555555556e-06,
      "loss": 0.0009,
      "step": 33080
    },
    {
      "epoch": 1.8383333333333334,
      "grad_norm": 0.0,
      "learning_rate": 4.041666666666666e-06,
      "loss": 0.0007,
      "step": 33090
    },
    {
      "epoch": 1.838888888888889,
      "grad_norm": 0.0,
      "learning_rate": 4.027777777777779e-06,
      "loss": 0.0008,
      "step": 33100
    },
    {
      "epoch": 1.8394444444444444,
      "grad_norm": 0.24817752838134766,
      "learning_rate": 4.013888888888889e-06,
      "loss": 0.0006,
      "step": 33110
    },
    {
      "epoch": 1.8399999999999999,
      "grad_norm": 0.0,
      "learning_rate": 4.000000000000001e-06,
      "loss": 0.0,
      "step": 33120
    },
    {
      "epoch": 1.8405555555555555,
      "grad_norm": 0.40592193603515625,
      "learning_rate": 3.986111111111111e-06,
      "loss": 0.0012,
      "step": 33130
    },
    {
      "epoch": 1.8411111111111111,
      "grad_norm": 0.0,
      "learning_rate": 3.972222222222223e-06,
      "loss": 0.0015,
      "step": 33140
    },
    {
      "epoch": 1.8416666666666668,
      "grad_norm": 0.07915447652339935,
      "learning_rate": 3.958333333333333e-06,
      "loss": 0.0008,
      "step": 33150
    },
    {
      "epoch": 1.8422222222222222,
      "grad_norm": 0.0466027706861496,
      "learning_rate": 3.944444444444445e-06,
      "loss": 0.0003,
      "step": 33160
    },
    {
      "epoch": 1.8427777777777776,
      "grad_norm": 0.04915164038538933,
      "learning_rate": 3.930555555555556e-06,
      "loss": 0.0003,
      "step": 33170
    },
    {
      "epoch": 1.8433333333333333,
      "grad_norm": 0.0,
      "learning_rate": 3.916666666666667e-06,
      "loss": 0.0004,
      "step": 33180
    },
    {
      "epoch": 1.843888888888889,
      "grad_norm": 0.24383330345153809,
      "learning_rate": 3.902777777777778e-06,
      "loss": 0.0005,
      "step": 33190
    },
    {
      "epoch": 1.8444444444444446,
      "grad_norm": 0.11578265577554703,
      "learning_rate": 3.888888888888889e-06,
      "loss": 0.0007,
      "step": 33200
    },
    {
      "epoch": 1.845,
      "grad_norm": 0.0,
      "learning_rate": 3.875e-06,
      "loss": 0.0002,
      "step": 33210
    },
    {
      "epoch": 1.8455555555555554,
      "grad_norm": 0.0,
      "learning_rate": 3.861111111111112e-06,
      "loss": 0.0002,
      "step": 33220
    },
    {
      "epoch": 1.846111111111111,
      "grad_norm": 0.0,
      "learning_rate": 3.847222222222222e-06,
      "loss": 0.0013,
      "step": 33230
    },
    {
      "epoch": 1.8466666666666667,
      "grad_norm": 0.0,
      "learning_rate": 3.833333333333334e-06,
      "loss": 0.0016,
      "step": 33240
    },
    {
      "epoch": 1.8472222222222223,
      "grad_norm": 0.0,
      "learning_rate": 3.819444444444445e-06,
      "loss": 0.0002,
      "step": 33250
    },
    {
      "epoch": 1.8477777777777777,
      "grad_norm": 0.04440364986658096,
      "learning_rate": 3.805555555555556e-06,
      "loss": 0.0,
      "step": 33260
    },
    {
      "epoch": 1.8483333333333334,
      "grad_norm": 0.23345036804676056,
      "learning_rate": 3.791666666666667e-06,
      "loss": 0.0006,
      "step": 33270
    },
    {
      "epoch": 1.8488888888888888,
      "grad_norm": 0.0,
      "learning_rate": 3.777777777777778e-06,
      "loss": 0.0004,
      "step": 33280
    },
    {
      "epoch": 1.8494444444444444,
      "grad_norm": 0.0,
      "learning_rate": 3.763888888888889e-06,
      "loss": 0.0005,
      "step": 33290
    },
    {
      "epoch": 1.85,
      "grad_norm": 0.2609756290912628,
      "learning_rate": 3.75e-06,
      "loss": 0.0006,
      "step": 33300
    },
    {
      "epoch": 1.8505555555555555,
      "grad_norm": 0.04828883707523346,
      "learning_rate": 3.736111111111111e-06,
      "loss": 0.0001,
      "step": 33310
    },
    {
      "epoch": 1.8511111111111112,
      "grad_norm": 0.05000932142138481,
      "learning_rate": 3.722222222222222e-06,
      "loss": 0.0009,
      "step": 33320
    },
    {
      "epoch": 1.8516666666666666,
      "grad_norm": 0.0,
      "learning_rate": 3.708333333333334e-06,
      "loss": 0.0016,
      "step": 33330
    },
    {
      "epoch": 1.8522222222222222,
      "grad_norm": 0.0,
      "learning_rate": 3.694444444444445e-06,
      "loss": 0.0007,
      "step": 33340
    },
    {
      "epoch": 1.8527777777777779,
      "grad_norm": 0.2022753208875656,
      "learning_rate": 3.680555555555556e-06,
      "loss": 0.0012,
      "step": 33350
    },
    {
      "epoch": 1.8533333333333335,
      "grad_norm": 0.04593341052532196,
      "learning_rate": 3.666666666666667e-06,
      "loss": 0.0005,
      "step": 33360
    },
    {
      "epoch": 1.853888888888889,
      "grad_norm": 0.0,
      "learning_rate": 3.652777777777778e-06,
      "loss": 0.0003,
      "step": 33370
    },
    {
      "epoch": 1.8544444444444443,
      "grad_norm": 0.13175207376480103,
      "learning_rate": 3.638888888888889e-06,
      "loss": 0.0002,
      "step": 33380
    },
    {
      "epoch": 1.855,
      "grad_norm": 0.0,
      "learning_rate": 3.625e-06,
      "loss": 0.0007,
      "step": 33390
    },
    {
      "epoch": 1.8555555555555556,
      "grad_norm": 0.0,
      "learning_rate": 3.611111111111111e-06,
      "loss": 0.0003,
      "step": 33400
    },
    {
      "epoch": 1.8561111111111113,
      "grad_norm": 0.0,
      "learning_rate": 3.5972222222222225e-06,
      "loss": 0.0004,
      "step": 33410
    },
    {
      "epoch": 1.8566666666666667,
      "grad_norm": 0.048162791877985,
      "learning_rate": 3.5833333333333335e-06,
      "loss": 0.0008,
      "step": 33420
    },
    {
      "epoch": 1.857222222222222,
      "grad_norm": 0.0,
      "learning_rate": 3.569444444444445e-06,
      "loss": 0.0011,
      "step": 33430
    },
    {
      "epoch": 1.8577777777777778,
      "grad_norm": 0.05594688281416893,
      "learning_rate": 3.555555555555556e-06,
      "loss": 0.0005,
      "step": 33440
    },
    {
      "epoch": 1.8583333333333334,
      "grad_norm": 0.0,
      "learning_rate": 3.541666666666667e-06,
      "loss": 0.0006,
      "step": 33450
    },
    {
      "epoch": 1.858888888888889,
      "grad_norm": 0.3260089159011841,
      "learning_rate": 3.527777777777778e-06,
      "loss": 0.0003,
      "step": 33460
    },
    {
      "epoch": 1.8594444444444445,
      "grad_norm": 0.0,
      "learning_rate": 3.513888888888889e-06,
      "loss": 0.0002,
      "step": 33470
    },
    {
      "epoch": 1.8599999999999999,
      "grad_norm": 0.14362749457359314,
      "learning_rate": 3.5000000000000004e-06,
      "loss": 0.0011,
      "step": 33480
    },
    {
      "epoch": 1.8605555555555555,
      "grad_norm": 0.0,
      "learning_rate": 3.4861111111111114e-06,
      "loss": 0.0011,
      "step": 33490
    },
    {
      "epoch": 1.8611111111111112,
      "grad_norm": 0.1891990602016449,
      "learning_rate": 3.4722222222222224e-06,
      "loss": 0.0003,
      "step": 33500
    },
    {
      "epoch": 1.8616666666666668,
      "grad_norm": 0.0,
      "learning_rate": 3.4583333333333334e-06,
      "loss": 0.0004,
      "step": 33510
    },
    {
      "epoch": 1.8622222222222222,
      "grad_norm": 0.049343377351760864,
      "learning_rate": 3.4444444444444444e-06,
      "loss": 0.0003,
      "step": 33520
    },
    {
      "epoch": 1.8627777777777776,
      "grad_norm": 0.17791388928890228,
      "learning_rate": 3.4305555555555554e-06,
      "loss": 0.0003,
      "step": 33530
    },
    {
      "epoch": 1.8633333333333333,
      "grad_norm": 0.0,
      "learning_rate": 3.4166666666666664e-06,
      "loss": 0.0009,
      "step": 33540
    },
    {
      "epoch": 1.863888888888889,
      "grad_norm": 0.05369684472680092,
      "learning_rate": 3.402777777777778e-06,
      "loss": 0.0003,
      "step": 33550
    },
    {
      "epoch": 1.8644444444444446,
      "grad_norm": 0.0,
      "learning_rate": 3.3888888888888893e-06,
      "loss": 0.001,
      "step": 33560
    },
    {
      "epoch": 1.865,
      "grad_norm": 0.0,
      "learning_rate": 3.3750000000000003e-06,
      "loss": 0.0009,
      "step": 33570
    },
    {
      "epoch": 1.8655555555555554,
      "grad_norm": 0.0,
      "learning_rate": 3.3611111111111113e-06,
      "loss": 0.0003,
      "step": 33580
    },
    {
      "epoch": 1.866111111111111,
      "grad_norm": 0.06295416504144669,
      "learning_rate": 3.3472222222222223e-06,
      "loss": 0.001,
      "step": 33590
    },
    {
      "epoch": 1.8666666666666667,
      "grad_norm": 0.0,
      "learning_rate": 3.3333333333333333e-06,
      "loss": 0.0008,
      "step": 33600
    },
    {
      "epoch": 1.8672222222222223,
      "grad_norm": 0.05913349241018295,
      "learning_rate": 3.3194444444444443e-06,
      "loss": 0.0003,
      "step": 33610
    },
    {
      "epoch": 1.8677777777777778,
      "grad_norm": 0.05844965949654579,
      "learning_rate": 3.3055555555555553e-06,
      "loss": 0.001,
      "step": 33620
    },
    {
      "epoch": 1.8683333333333332,
      "grad_norm": 0.0,
      "learning_rate": 3.2916666666666664e-06,
      "loss": 0.0013,
      "step": 33630
    },
    {
      "epoch": 1.8688888888888888,
      "grad_norm": 0.04609065130352974,
      "learning_rate": 3.277777777777778e-06,
      "loss": 0.0003,
      "step": 33640
    },
    {
      "epoch": 1.8694444444444445,
      "grad_norm": 0.27977272868156433,
      "learning_rate": 3.2638888888888892e-06,
      "loss": 0.0004,
      "step": 33650
    },
    {
      "epoch": 1.87,
      "grad_norm": 0.0,
      "learning_rate": 3.2500000000000002e-06,
      "loss": 0.0005,
      "step": 33660
    },
    {
      "epoch": 1.8705555555555555,
      "grad_norm": 0.049026042222976685,
      "learning_rate": 3.2361111111111112e-06,
      "loss": 0.0004,
      "step": 33670
    },
    {
      "epoch": 1.871111111111111,
      "grad_norm": 0.0,
      "learning_rate": 3.2222222222222222e-06,
      "loss": 0.0006,
      "step": 33680
    },
    {
      "epoch": 1.8716666666666666,
      "grad_norm": 0.11563301831483841,
      "learning_rate": 3.2083333333333332e-06,
      "loss": 0.0005,
      "step": 33690
    },
    {
      "epoch": 1.8722222222222222,
      "grad_norm": 0.0,
      "learning_rate": 3.1944444444444443e-06,
      "loss": 0.0003,
      "step": 33700
    },
    {
      "epoch": 1.8727777777777779,
      "grad_norm": 0.04603291302919388,
      "learning_rate": 3.1805555555555553e-06,
      "loss": 0.0004,
      "step": 33710
    },
    {
      "epoch": 1.8733333333333333,
      "grad_norm": 0.2300512045621872,
      "learning_rate": 3.166666666666667e-06,
      "loss": 0.0006,
      "step": 33720
    },
    {
      "epoch": 1.873888888888889,
      "grad_norm": 0.0,
      "learning_rate": 3.152777777777778e-06,
      "loss": 0.0009,
      "step": 33730
    },
    {
      "epoch": 1.8744444444444444,
      "grad_norm": 0.28950563073158264,
      "learning_rate": 3.138888888888889e-06,
      "loss": 0.0004,
      "step": 33740
    },
    {
      "epoch": 1.875,
      "grad_norm": 0.0,
      "learning_rate": 3.125e-06,
      "loss": 0.0003,
      "step": 33750
    },
    {
      "epoch": 1.8755555555555556,
      "grad_norm": 0.0,
      "learning_rate": 3.111111111111111e-06,
      "loss": 0.0001,
      "step": 33760
    },
    {
      "epoch": 1.876111111111111,
      "grad_norm": 0.2937539219856262,
      "learning_rate": 3.0972222222222226e-06,
      "loss": 0.0001,
      "step": 33770
    },
    {
      "epoch": 1.8766666666666667,
      "grad_norm": 0.05400320142507553,
      "learning_rate": 3.0833333333333336e-06,
      "loss": 0.0007,
      "step": 33780
    },
    {
      "epoch": 1.8772222222222221,
      "grad_norm": 0.0,
      "learning_rate": 3.0694444444444446e-06,
      "loss": 0.0002,
      "step": 33790
    },
    {
      "epoch": 1.8777777777777778,
      "grad_norm": 0.0,
      "learning_rate": 3.0555555555555556e-06,
      "loss": 0.0001,
      "step": 33800
    },
    {
      "epoch": 1.8783333333333334,
      "grad_norm": 0.045097868889570236,
      "learning_rate": 3.041666666666667e-06,
      "loss": 0.0002,
      "step": 33810
    },
    {
      "epoch": 1.878888888888889,
      "grad_norm": 0.24713502824306488,
      "learning_rate": 3.027777777777778e-06,
      "loss": 0.0011,
      "step": 33820
    },
    {
      "epoch": 1.8794444444444445,
      "grad_norm": 0.04523975029587746,
      "learning_rate": 3.013888888888889e-06,
      "loss": 0.0004,
      "step": 33830
    },
    {
      "epoch": 1.88,
      "grad_norm": 0.045007627457380295,
      "learning_rate": 3e-06,
      "loss": 0.0003,
      "step": 33840
    },
    {
      "epoch": 1.8805555555555555,
      "grad_norm": 0.04547189921140671,
      "learning_rate": 2.9861111111111115e-06,
      "loss": 0.0005,
      "step": 33850
    },
    {
      "epoch": 1.8811111111111112,
      "grad_norm": 0.20814098417758942,
      "learning_rate": 2.9722222222222225e-06,
      "loss": 0.0005,
      "step": 33860
    },
    {
      "epoch": 1.8816666666666668,
      "grad_norm": 0.054003193974494934,
      "learning_rate": 2.9583333333333335e-06,
      "loss": 0.0012,
      "step": 33870
    },
    {
      "epoch": 1.8822222222222222,
      "grad_norm": 0.0,
      "learning_rate": 2.9444444444444445e-06,
      "loss": 0.0008,
      "step": 33880
    },
    {
      "epoch": 1.8827777777777777,
      "grad_norm": 0.12993812561035156,
      "learning_rate": 2.930555555555556e-06,
      "loss": 0.0009,
      "step": 33890
    },
    {
      "epoch": 1.8833333333333333,
      "grad_norm": 0.0,
      "learning_rate": 2.916666666666667e-06,
      "loss": 0.0002,
      "step": 33900
    },
    {
      "epoch": 1.883888888888889,
      "grad_norm": 0.0,
      "learning_rate": 2.902777777777778e-06,
      "loss": 0.0007,
      "step": 33910
    },
    {
      "epoch": 1.8844444444444446,
      "grad_norm": 0.0,
      "learning_rate": 2.888888888888889e-06,
      "loss": 0.0007,
      "step": 33920
    },
    {
      "epoch": 1.885,
      "grad_norm": 0.0,
      "learning_rate": 2.8750000000000004e-06,
      "loss": 0.0008,
      "step": 33930
    },
    {
      "epoch": 1.8855555555555554,
      "grad_norm": 0.0,
      "learning_rate": 2.8611111111111114e-06,
      "loss": 0.0003,
      "step": 33940
    },
    {
      "epoch": 1.886111111111111,
      "grad_norm": 0.0,
      "learning_rate": 2.8472222222222224e-06,
      "loss": 0.0013,
      "step": 33950
    },
    {
      "epoch": 1.8866666666666667,
      "grad_norm": 0.050219710916280746,
      "learning_rate": 2.8333333333333335e-06,
      "loss": 0.0005,
      "step": 33960
    },
    {
      "epoch": 1.8872222222222224,
      "grad_norm": 0.0,
      "learning_rate": 2.819444444444445e-06,
      "loss": 0.0004,
      "step": 33970
    },
    {
      "epoch": 1.8877777777777778,
      "grad_norm": 0.045800261199474335,
      "learning_rate": 2.805555555555556e-06,
      "loss": 0.0004,
      "step": 33980
    },
    {
      "epoch": 1.8883333333333332,
      "grad_norm": 0.0,
      "learning_rate": 2.791666666666667e-06,
      "loss": 0.0004,
      "step": 33990
    },
    {
      "epoch": 1.8888888888888888,
      "grad_norm": 0.0,
      "learning_rate": 2.777777777777778e-06,
      "loss": 0.0009,
      "step": 34000
    },
    {
      "epoch": 1.8894444444444445,
      "grad_norm": 0.0,
      "learning_rate": 2.763888888888889e-06,
      "loss": 0.0003,
      "step": 34010
    },
    {
      "epoch": 1.8900000000000001,
      "grad_norm": 0.04927876591682434,
      "learning_rate": 2.7500000000000004e-06,
      "loss": 0.0005,
      "step": 34020
    },
    {
      "epoch": 1.8905555555555555,
      "grad_norm": 0.0,
      "learning_rate": 2.7361111111111114e-06,
      "loss": 0.0004,
      "step": 34030
    },
    {
      "epoch": 1.891111111111111,
      "grad_norm": 0.0,
      "learning_rate": 2.7222222222222224e-06,
      "loss": 0.0003,
      "step": 34040
    },
    {
      "epoch": 1.8916666666666666,
      "grad_norm": 0.2037208527326584,
      "learning_rate": 2.7083333333333334e-06,
      "loss": 0.0011,
      "step": 34050
    },
    {
      "epoch": 1.8922222222222222,
      "grad_norm": 0.04894133657217026,
      "learning_rate": 2.6944444444444444e-06,
      "loss": 0.0009,
      "step": 34060
    },
    {
      "epoch": 1.892777777777778,
      "grad_norm": 0.14059150218963623,
      "learning_rate": 2.6805555555555554e-06,
      "loss": 0.0007,
      "step": 34070
    },
    {
      "epoch": 1.8933333333333333,
      "grad_norm": 0.0,
      "learning_rate": 2.666666666666667e-06,
      "loss": 0.0007,
      "step": 34080
    },
    {
      "epoch": 1.8938888888888887,
      "grad_norm": 0.0,
      "learning_rate": 2.652777777777778e-06,
      "loss": 0.0004,
      "step": 34090
    },
    {
      "epoch": 1.8944444444444444,
      "grad_norm": 0.08126353472471237,
      "learning_rate": 2.638888888888889e-06,
      "loss": 0.0007,
      "step": 34100
    },
    {
      "epoch": 1.895,
      "grad_norm": 0.051425762474536896,
      "learning_rate": 2.625e-06,
      "loss": 0.0002,
      "step": 34110
    },
    {
      "epoch": 1.8955555555555557,
      "grad_norm": 0.0,
      "learning_rate": 2.6111111111111113e-06,
      "loss": 0.0003,
      "step": 34120
    },
    {
      "epoch": 1.896111111111111,
      "grad_norm": 0.12504668533802032,
      "learning_rate": 2.5972222222222223e-06,
      "loss": 0.0005,
      "step": 34130
    },
    {
      "epoch": 1.8966666666666665,
      "grad_norm": 0.047010958194732666,
      "learning_rate": 2.5833333333333333e-06,
      "loss": 0.001,
      "step": 34140
    },
    {
      "epoch": 1.8972222222222221,
      "grad_norm": 0.0,
      "learning_rate": 2.5694444444444443e-06,
      "loss": 0.0001,
      "step": 34150
    },
    {
      "epoch": 1.8977777777777778,
      "grad_norm": 0.0,
      "learning_rate": 2.5555555555555557e-06,
      "loss": 0.0002,
      "step": 34160
    },
    {
      "epoch": 1.8983333333333334,
      "grad_norm": 0.1737411916255951,
      "learning_rate": 2.5416666666666668e-06,
      "loss": 0.0005,
      "step": 34170
    },
    {
      "epoch": 1.8988888888888888,
      "grad_norm": 0.049242157489061356,
      "learning_rate": 2.5277777777777778e-06,
      "loss": 0.0003,
      "step": 34180
    },
    {
      "epoch": 1.8994444444444445,
      "grad_norm": 0.053274206817150116,
      "learning_rate": 2.5138888888888888e-06,
      "loss": 0.0003,
      "step": 34190
    },
    {
      "epoch": 1.9,
      "grad_norm": 0.042882028967142105,
      "learning_rate": 2.5e-06,
      "loss": 0.0012,
      "step": 34200
    },
    {
      "epoch": 1.9005555555555556,
      "grad_norm": 0.0,
      "learning_rate": 2.4861111111111112e-06,
      "loss": 0.0003,
      "step": 34210
    },
    {
      "epoch": 1.9011111111111112,
      "grad_norm": 0.04786434397101402,
      "learning_rate": 2.4722222222222222e-06,
      "loss": 0.0003,
      "step": 34220
    },
    {
      "epoch": 1.9016666666666666,
      "grad_norm": 0.0,
      "learning_rate": 2.4583333333333332e-06,
      "loss": 0.0008,
      "step": 34230
    },
    {
      "epoch": 1.9022222222222223,
      "grad_norm": 0.14880302548408508,
      "learning_rate": 2.4444444444444447e-06,
      "loss": 0.0011,
      "step": 34240
    },
    {
      "epoch": 1.9027777777777777,
      "grad_norm": 0.027163643389940262,
      "learning_rate": 2.4305555555555557e-06,
      "loss": 0.0,
      "step": 34250
    },
    {
      "epoch": 1.9033333333333333,
      "grad_norm": 0.0,
      "learning_rate": 2.4166666666666667e-06,
      "loss": 0.0003,
      "step": 34260
    },
    {
      "epoch": 1.903888888888889,
      "grad_norm": 0.0,
      "learning_rate": 2.4027777777777777e-06,
      "loss": 0.0008,
      "step": 34270
    },
    {
      "epoch": 1.9044444444444446,
      "grad_norm": 0.0,
      "learning_rate": 2.388888888888889e-06,
      "loss": 0.0016,
      "step": 34280
    },
    {
      "epoch": 1.905,
      "grad_norm": 0.0,
      "learning_rate": 2.375e-06,
      "loss": 0.0006,
      "step": 34290
    },
    {
      "epoch": 1.9055555555555554,
      "grad_norm": 0.0,
      "learning_rate": 2.361111111111111e-06,
      "loss": 0.0002,
      "step": 34300
    },
    {
      "epoch": 1.906111111111111,
      "grad_norm": 0.02490714006125927,
      "learning_rate": 2.347222222222222e-06,
      "loss": 0.0007,
      "step": 34310
    },
    {
      "epoch": 1.9066666666666667,
      "grad_norm": 0.0,
      "learning_rate": 2.3333333333333336e-06,
      "loss": 0.0006,
      "step": 34320
    },
    {
      "epoch": 1.9072222222222224,
      "grad_norm": 0.0,
      "learning_rate": 2.3194444444444446e-06,
      "loss": 0.0002,
      "step": 34330
    },
    {
      "epoch": 1.9077777777777778,
      "grad_norm": 0.2935009002685547,
      "learning_rate": 2.3055555555555556e-06,
      "loss": 0.0004,
      "step": 34340
    },
    {
      "epoch": 1.9083333333333332,
      "grad_norm": 0.054480116814374924,
      "learning_rate": 2.2916666666666666e-06,
      "loss": 0.0,
      "step": 34350
    },
    {
      "epoch": 1.9088888888888889,
      "grad_norm": 0.0,
      "learning_rate": 2.277777777777778e-06,
      "loss": 0.0004,
      "step": 34360
    },
    {
      "epoch": 1.9094444444444445,
      "grad_norm": 0.0,
      "learning_rate": 2.263888888888889e-06,
      "loss": 0.0008,
      "step": 34370
    },
    {
      "epoch": 1.9100000000000001,
      "grad_norm": 0.05436397343873978,
      "learning_rate": 2.25e-06,
      "loss": 0.0002,
      "step": 34380
    },
    {
      "epoch": 1.9105555555555556,
      "grad_norm": 0.09996812045574188,
      "learning_rate": 2.236111111111111e-06,
      "loss": 0.0003,
      "step": 34390
    },
    {
      "epoch": 1.911111111111111,
      "grad_norm": 0.0,
      "learning_rate": 2.2222222222222225e-06,
      "loss": 0.0008,
      "step": 34400
    },
    {
      "epoch": 1.9116666666666666,
      "grad_norm": 0.050742000341415405,
      "learning_rate": 2.2083333333333335e-06,
      "loss": 0.0001,
      "step": 34410
    },
    {
      "epoch": 1.9122222222222223,
      "grad_norm": 0.0,
      "learning_rate": 2.1944444444444445e-06,
      "loss": 0.0002,
      "step": 34420
    },
    {
      "epoch": 1.912777777777778,
      "grad_norm": 0.04731769114732742,
      "learning_rate": 2.180555555555556e-06,
      "loss": 0.0003,
      "step": 34430
    },
    {
      "epoch": 1.9133333333333333,
      "grad_norm": 0.0,
      "learning_rate": 2.166666666666667e-06,
      "loss": 0.0004,
      "step": 34440
    },
    {
      "epoch": 1.9138888888888888,
      "grad_norm": 0.05445791408419609,
      "learning_rate": 2.152777777777778e-06,
      "loss": 0.001,
      "step": 34450
    },
    {
      "epoch": 1.9144444444444444,
      "grad_norm": 0.0,
      "learning_rate": 2.138888888888889e-06,
      "loss": 0.0007,
      "step": 34460
    },
    {
      "epoch": 1.915,
      "grad_norm": 0.0,
      "learning_rate": 2.1250000000000004e-06,
      "loss": 0.0004,
      "step": 34470
    },
    {
      "epoch": 1.9155555555555557,
      "grad_norm": 0.0,
      "learning_rate": 2.1111111111111114e-06,
      "loss": 0.0005,
      "step": 34480
    },
    {
      "epoch": 1.916111111111111,
      "grad_norm": 0.0,
      "learning_rate": 2.0972222222222224e-06,
      "loss": 0.0003,
      "step": 34490
    },
    {
      "epoch": 1.9166666666666665,
      "grad_norm": 0.0,
      "learning_rate": 2.0833333333333334e-06,
      "loss": 0.0002,
      "step": 34500
    },
    {
      "epoch": 1.9172222222222222,
      "grad_norm": 0.0,
      "learning_rate": 2.069444444444445e-06,
      "loss": 0.0002,
      "step": 34510
    },
    {
      "epoch": 1.9177777777777778,
      "grad_norm": 0.0,
      "learning_rate": 2.055555555555556e-06,
      "loss": 0.0002,
      "step": 34520
    },
    {
      "epoch": 1.9183333333333334,
      "grad_norm": 0.09135885536670685,
      "learning_rate": 2.041666666666667e-06,
      "loss": 0.0002,
      "step": 34530
    },
    {
      "epoch": 1.9188888888888889,
      "grad_norm": 0.232574000954628,
      "learning_rate": 2.027777777777778e-06,
      "loss": 0.0001,
      "step": 34540
    },
    {
      "epoch": 1.9194444444444443,
      "grad_norm": 0.0,
      "learning_rate": 2.0138888888888893e-06,
      "loss": 0.0001,
      "step": 34550
    },
    {
      "epoch": 1.92,
      "grad_norm": 0.0,
      "learning_rate": 2.0000000000000003e-06,
      "loss": 0.0006,
      "step": 34560
    },
    {
      "epoch": 1.9205555555555556,
      "grad_norm": 0.18260225653648376,
      "learning_rate": 1.9861111111111113e-06,
      "loss": 0.0006,
      "step": 34570
    },
    {
      "epoch": 1.9211111111111112,
      "grad_norm": 0.05368947982788086,
      "learning_rate": 1.9722222222222224e-06,
      "loss": 0.0003,
      "step": 34580
    },
    {
      "epoch": 1.9216666666666666,
      "grad_norm": 0.0,
      "learning_rate": 1.9583333333333334e-06,
      "loss": 0.0001,
      "step": 34590
    },
    {
      "epoch": 1.9222222222222223,
      "grad_norm": 0.0,
      "learning_rate": 1.9444444444444444e-06,
      "loss": 0.0011,
      "step": 34600
    },
    {
      "epoch": 1.9227777777777777,
      "grad_norm": 0.0,
      "learning_rate": 1.930555555555556e-06,
      "loss": 0.0004,
      "step": 34610
    },
    {
      "epoch": 1.9233333333333333,
      "grad_norm": 0.0,
      "learning_rate": 1.916666666666667e-06,
      "loss": 0.0003,
      "step": 34620
    },
    {
      "epoch": 1.923888888888889,
      "grad_norm": 0.0,
      "learning_rate": 1.902777777777778e-06,
      "loss": 0.0004,
      "step": 34630
    },
    {
      "epoch": 1.9244444444444444,
      "grad_norm": 0.04629078134894371,
      "learning_rate": 1.888888888888889e-06,
      "loss": 0.0006,
      "step": 34640
    },
    {
      "epoch": 1.925,
      "grad_norm": 0.11825218051671982,
      "learning_rate": 1.875e-06,
      "loss": 0.0002,
      "step": 34650
    },
    {
      "epoch": 1.9255555555555555,
      "grad_norm": 0.04734457656741142,
      "learning_rate": 1.861111111111111e-06,
      "loss": 0.0007,
      "step": 34660
    },
    {
      "epoch": 1.926111111111111,
      "grad_norm": 0.0,
      "learning_rate": 1.8472222222222225e-06,
      "loss": 0.0008,
      "step": 34670
    },
    {
      "epoch": 1.9266666666666667,
      "grad_norm": 0.0,
      "learning_rate": 1.8333333333333335e-06,
      "loss": 0.0005,
      "step": 34680
    },
    {
      "epoch": 1.9272222222222222,
      "grad_norm": 0.28134679794311523,
      "learning_rate": 1.8194444444444445e-06,
      "loss": 0.0003,
      "step": 34690
    },
    {
      "epoch": 1.9277777777777778,
      "grad_norm": 0.0954803004860878,
      "learning_rate": 1.8055555555555555e-06,
      "loss": 0.0017,
      "step": 34700
    },
    {
      "epoch": 1.9283333333333332,
      "grad_norm": 0.0,
      "learning_rate": 1.7916666666666667e-06,
      "loss": 0.0003,
      "step": 34710
    },
    {
      "epoch": 1.9288888888888889,
      "grad_norm": 0.08645211905241013,
      "learning_rate": 1.777777777777778e-06,
      "loss": 0.0014,
      "step": 34720
    },
    {
      "epoch": 1.9294444444444445,
      "grad_norm": 0.050221774727106094,
      "learning_rate": 1.763888888888889e-06,
      "loss": 0.0003,
      "step": 34730
    },
    {
      "epoch": 1.9300000000000002,
      "grad_norm": 0.0,
      "learning_rate": 1.7500000000000002e-06,
      "loss": 0.0007,
      "step": 34740
    },
    {
      "epoch": 1.9305555555555556,
      "grad_norm": 0.0,
      "learning_rate": 1.7361111111111112e-06,
      "loss": 0.001,
      "step": 34750
    },
    {
      "epoch": 1.931111111111111,
      "grad_norm": 0.047778695821762085,
      "learning_rate": 1.7222222222222222e-06,
      "loss": 0.0002,
      "step": 34760
    },
    {
      "epoch": 1.9316666666666666,
      "grad_norm": 0.0,
      "learning_rate": 1.7083333333333332e-06,
      "loss": 0.0002,
      "step": 34770
    },
    {
      "epoch": 1.9322222222222223,
      "grad_norm": 0.0,
      "learning_rate": 1.6944444444444446e-06,
      "loss": 0.0004,
      "step": 34780
    },
    {
      "epoch": 1.932777777777778,
      "grad_norm": 0.0,
      "learning_rate": 1.6805555555555557e-06,
      "loss": 0.0007,
      "step": 34790
    },
    {
      "epoch": 1.9333333333333333,
      "grad_norm": 0.23584192991256714,
      "learning_rate": 1.6666666666666667e-06,
      "loss": 0.0003,
      "step": 34800
    },
    {
      "epoch": 1.9338888888888888,
      "grad_norm": 0.0,
      "learning_rate": 1.6527777777777777e-06,
      "loss": 0.0009,
      "step": 34810
    },
    {
      "epoch": 1.9344444444444444,
      "grad_norm": 0.0,
      "learning_rate": 1.638888888888889e-06,
      "loss": 0.001,
      "step": 34820
    },
    {
      "epoch": 1.935,
      "grad_norm": 0.0,
      "learning_rate": 1.6250000000000001e-06,
      "loss": 0.0009,
      "step": 34830
    },
    {
      "epoch": 1.9355555555555557,
      "grad_norm": 0.0,
      "learning_rate": 1.6111111111111111e-06,
      "loss": 0.0002,
      "step": 34840
    },
    {
      "epoch": 1.9361111111111111,
      "grad_norm": 0.0,
      "learning_rate": 1.5972222222222221e-06,
      "loss": 0.0009,
      "step": 34850
    },
    {
      "epoch": 1.9366666666666665,
      "grad_norm": 0.0,
      "learning_rate": 1.5833333333333336e-06,
      "loss": 0.001,
      "step": 34860
    },
    {
      "epoch": 1.9372222222222222,
      "grad_norm": 0.0,
      "learning_rate": 1.5694444444444446e-06,
      "loss": 0.0004,
      "step": 34870
    },
    {
      "epoch": 1.9377777777777778,
      "grad_norm": 0.0,
      "learning_rate": 1.5555555555555556e-06,
      "loss": 0.0002,
      "step": 34880
    },
    {
      "epoch": 1.9383333333333335,
      "grad_norm": 0.0,
      "learning_rate": 1.5416666666666668e-06,
      "loss": 0.0003,
      "step": 34890
    },
    {
      "epoch": 1.9388888888888889,
      "grad_norm": 0.0,
      "learning_rate": 1.5277777777777778e-06,
      "loss": 0.0002,
      "step": 34900
    },
    {
      "epoch": 1.9394444444444443,
      "grad_norm": 0.0,
      "learning_rate": 1.513888888888889e-06,
      "loss": 0.0005,
      "step": 34910
    },
    {
      "epoch": 1.94,
      "grad_norm": 0.0,
      "learning_rate": 1.5e-06,
      "loss": 0.0003,
      "step": 34920
    },
    {
      "epoch": 1.9405555555555556,
      "grad_norm": 0.0,
      "learning_rate": 1.4861111111111113e-06,
      "loss": 0.0005,
      "step": 34930
    },
    {
      "epoch": 1.9411111111111112,
      "grad_norm": 0.0,
      "learning_rate": 1.4722222222222223e-06,
      "loss": 0.0005,
      "step": 34940
    },
    {
      "epoch": 1.9416666666666667,
      "grad_norm": 0.0,
      "learning_rate": 1.4583333333333335e-06,
      "loss": 0.0008,
      "step": 34950
    },
    {
      "epoch": 1.942222222222222,
      "grad_norm": 0.09795248508453369,
      "learning_rate": 1.4444444444444445e-06,
      "loss": 0.001,
      "step": 34960
    },
    {
      "epoch": 1.9427777777777777,
      "grad_norm": 0.0,
      "learning_rate": 1.4305555555555557e-06,
      "loss": 0.0001,
      "step": 34970
    },
    {
      "epoch": 1.9433333333333334,
      "grad_norm": 0.0,
      "learning_rate": 1.4166666666666667e-06,
      "loss": 0.0004,
      "step": 34980
    },
    {
      "epoch": 1.943888888888889,
      "grad_norm": 0.05614951625466347,
      "learning_rate": 1.402777777777778e-06,
      "loss": 0.0003,
      "step": 34990
    },
    {
      "epoch": 1.9444444444444444,
      "grad_norm": 0.05377863347530365,
      "learning_rate": 1.388888888888889e-06,
      "loss": 0.0006,
      "step": 35000
    },
    {
      "epoch": 1.9449999999999998,
      "grad_norm": 0.08998305350542068,
      "learning_rate": 1.3750000000000002e-06,
      "loss": 0.0006,
      "step": 35010
    },
    {
      "epoch": 1.9455555555555555,
      "grad_norm": 0.04571729153394699,
      "learning_rate": 1.3611111111111112e-06,
      "loss": 0.0008,
      "step": 35020
    },
    {
      "epoch": 1.9461111111111111,
      "grad_norm": 0.242328941822052,
      "learning_rate": 1.3472222222222222e-06,
      "loss": 0.0009,
      "step": 35030
    },
    {
      "epoch": 1.9466666666666668,
      "grad_norm": 0.0,
      "learning_rate": 1.3333333333333334e-06,
      "loss": 0.0009,
      "step": 35040
    },
    {
      "epoch": 1.9472222222222222,
      "grad_norm": 0.087168388068676,
      "learning_rate": 1.3194444444444444e-06,
      "loss": 0.0009,
      "step": 35050
    },
    {
      "epoch": 1.9477777777777778,
      "grad_norm": 0.0,
      "learning_rate": 1.3055555555555556e-06,
      "loss": 0.0005,
      "step": 35060
    },
    {
      "epoch": 1.9483333333333333,
      "grad_norm": 0.0,
      "learning_rate": 1.2916666666666667e-06,
      "loss": 0.0007,
      "step": 35070
    },
    {
      "epoch": 1.948888888888889,
      "grad_norm": 0.28655368089675903,
      "learning_rate": 1.2777777777777779e-06,
      "loss": 0.0004,
      "step": 35080
    },
    {
      "epoch": 1.9494444444444445,
      "grad_norm": 0.3858736455440521,
      "learning_rate": 1.2638888888888889e-06,
      "loss": 0.0007,
      "step": 35090
    },
    {
      "epoch": 1.95,
      "grad_norm": 0.0,
      "learning_rate": 1.25e-06,
      "loss": 0.0008,
      "step": 35100
    },
    {
      "epoch": 1.9505555555555556,
      "grad_norm": 0.0,
      "learning_rate": 1.2361111111111111e-06,
      "loss": 0.0003,
      "step": 35110
    },
    {
      "epoch": 1.951111111111111,
      "grad_norm": 0.04363768920302391,
      "learning_rate": 1.2222222222222223e-06,
      "loss": 0.0009,
      "step": 35120
    },
    {
      "epoch": 1.9516666666666667,
      "grad_norm": 0.0,
      "learning_rate": 1.2083333333333333e-06,
      "loss": 0.0002,
      "step": 35130
    },
    {
      "epoch": 1.9522222222222223,
      "grad_norm": 0.0,
      "learning_rate": 1.1944444444444446e-06,
      "loss": 0.0003,
      "step": 35140
    },
    {
      "epoch": 1.9527777777777777,
      "grad_norm": 0.0,
      "learning_rate": 1.1805555555555556e-06,
      "loss": 0.0004,
      "step": 35150
    },
    {
      "epoch": 1.9533333333333334,
      "grad_norm": 0.08993913233280182,
      "learning_rate": 1.1666666666666668e-06,
      "loss": 0.0002,
      "step": 35160
    },
    {
      "epoch": 1.9538888888888888,
      "grad_norm": 0.0,
      "learning_rate": 1.1527777777777778e-06,
      "loss": 0.0003,
      "step": 35170
    },
    {
      "epoch": 1.9544444444444444,
      "grad_norm": 0.2169015109539032,
      "learning_rate": 1.138888888888889e-06,
      "loss": 0.0008,
      "step": 35180
    },
    {
      "epoch": 1.955,
      "grad_norm": 0.05230973660945892,
      "learning_rate": 1.125e-06,
      "loss": 0.0006,
      "step": 35190
    },
    {
      "epoch": 1.9555555555555557,
      "grad_norm": 0.05117468908429146,
      "learning_rate": 1.1111111111111112e-06,
      "loss": 0.0019,
      "step": 35200
    },
    {
      "epoch": 1.9561111111111111,
      "grad_norm": 0.0,
      "learning_rate": 1.0972222222222223e-06,
      "loss": 0.0003,
      "step": 35210
    },
    {
      "epoch": 1.9566666666666666,
      "grad_norm": 0.0,
      "learning_rate": 1.0833333333333335e-06,
      "loss": 0.0013,
      "step": 35220
    },
    {
      "epoch": 1.9572222222222222,
      "grad_norm": 0.0,
      "learning_rate": 1.0694444444444445e-06,
      "loss": 0.0,
      "step": 35230
    },
    {
      "epoch": 1.9577777777777778,
      "grad_norm": 0.24127842485904694,
      "learning_rate": 1.0555555555555557e-06,
      "loss": 0.0014,
      "step": 35240
    },
    {
      "epoch": 1.9583333333333335,
      "grad_norm": 0.052498623728752136,
      "learning_rate": 1.0416666666666667e-06,
      "loss": 0.0003,
      "step": 35250
    },
    {
      "epoch": 1.958888888888889,
      "grad_norm": 0.0,
      "learning_rate": 1.027777777777778e-06,
      "loss": 0.001,
      "step": 35260
    },
    {
      "epoch": 1.9594444444444443,
      "grad_norm": 0.26341235637664795,
      "learning_rate": 1.013888888888889e-06,
      "loss": 0.0008,
      "step": 35270
    },
    {
      "epoch": 1.96,
      "grad_norm": 0.0,
      "learning_rate": 1.0000000000000002e-06,
      "loss": 0.0011,
      "step": 35280
    },
    {
      "epoch": 1.9605555555555556,
      "grad_norm": 0.0,
      "learning_rate": 9.861111111111112e-07,
      "loss": 0.0001,
      "step": 35290
    },
    {
      "epoch": 1.9611111111111112,
      "grad_norm": 0.0,
      "learning_rate": 9.722222222222222e-07,
      "loss": 0.0004,
      "step": 35300
    },
    {
      "epoch": 1.9616666666666667,
      "grad_norm": 0.0,
      "learning_rate": 9.583333333333334e-07,
      "loss": 0.0007,
      "step": 35310
    },
    {
      "epoch": 1.962222222222222,
      "grad_norm": 0.0,
      "learning_rate": 9.444444444444445e-07,
      "loss": 0.0006,
      "step": 35320
    },
    {
      "epoch": 1.9627777777777777,
      "grad_norm": 0.048622775822877884,
      "learning_rate": 9.305555555555555e-07,
      "loss": 0.0005,
      "step": 35330
    },
    {
      "epoch": 1.9633333333333334,
      "grad_norm": 0.043867066502571106,
      "learning_rate": 9.166666666666667e-07,
      "loss": 0.0003,
      "step": 35340
    },
    {
      "epoch": 1.963888888888889,
      "grad_norm": 0.2653080224990845,
      "learning_rate": 9.027777777777778e-07,
      "loss": 0.0004,
      "step": 35350
    },
    {
      "epoch": 1.9644444444444444,
      "grad_norm": 0.0,
      "learning_rate": 8.88888888888889e-07,
      "loss": 0.0007,
      "step": 35360
    },
    {
      "epoch": 1.9649999999999999,
      "grad_norm": 0.05698433890938759,
      "learning_rate": 8.750000000000001e-07,
      "loss": 0.0004,
      "step": 35370
    },
    {
      "epoch": 1.9655555555555555,
      "grad_norm": 0.0,
      "learning_rate": 8.611111111111111e-07,
      "loss": 0.0004,
      "step": 35380
    },
    {
      "epoch": 1.9661111111111111,
      "grad_norm": 0.0,
      "learning_rate": 8.472222222222223e-07,
      "loss": 0.0001,
      "step": 35390
    },
    {
      "epoch": 1.9666666666666668,
      "grad_norm": 0.0,
      "learning_rate": 8.333333333333333e-07,
      "loss": 0.0009,
      "step": 35400
    },
    {
      "epoch": 1.9672222222222222,
      "grad_norm": 0.0,
      "learning_rate": 8.194444444444446e-07,
      "loss": 0.0008,
      "step": 35410
    },
    {
      "epoch": 1.9677777777777776,
      "grad_norm": 0.0,
      "learning_rate": 8.055555555555556e-07,
      "loss": 0.0003,
      "step": 35420
    },
    {
      "epoch": 1.9683333333333333,
      "grad_norm": 0.0,
      "learning_rate": 7.916666666666668e-07,
      "loss": 0.0004,
      "step": 35430
    },
    {
      "epoch": 1.968888888888889,
      "grad_norm": 0.0,
      "learning_rate": 7.777777777777778e-07,
      "loss": 0.0009,
      "step": 35440
    },
    {
      "epoch": 1.9694444444444446,
      "grad_norm": 0.04605967178940773,
      "learning_rate": 7.638888888888889e-07,
      "loss": 0.0003,
      "step": 35450
    },
    {
      "epoch": 1.97,
      "grad_norm": 0.0,
      "learning_rate": 7.5e-07,
      "loss": 0.0004,
      "step": 35460
    },
    {
      "epoch": 1.9705555555555554,
      "grad_norm": 0.0,
      "learning_rate": 7.361111111111111e-07,
      "loss": 0.0004,
      "step": 35470
    },
    {
      "epoch": 1.971111111111111,
      "grad_norm": 0.15779513120651245,
      "learning_rate": 7.222222222222222e-07,
      "loss": 0.0003,
      "step": 35480
    },
    {
      "epoch": 1.9716666666666667,
      "grad_norm": 0.04454788193106651,
      "learning_rate": 7.083333333333334e-07,
      "loss": 0.0001,
      "step": 35490
    },
    {
      "epoch": 1.9722222222222223,
      "grad_norm": 0.13236838579177856,
      "learning_rate": 6.944444444444445e-07,
      "loss": 0.0005,
      "step": 35500
    }
  ],
  "logging_steps": 10,
  "max_steps": 36000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 0.0,
  "train_batch_size": 40,
  "trial_name": null,
  "trial_params": null
}
