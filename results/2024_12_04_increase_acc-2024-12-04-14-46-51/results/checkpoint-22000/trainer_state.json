{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.9777777777777777,
  "eval_steps": 500,
  "global_step": 22000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.00044444444444444447,
      "grad_norm": 0.3743181526660919,
      "learning_rate": 4.997777777777778e-05,
      "loss": 0.0019,
      "step": 10
    },
    {
      "epoch": 0.0008888888888888889,
      "grad_norm": 0.29177767038345337,
      "learning_rate": 4.995555555555556e-05,
      "loss": 0.0018,
      "step": 20
    },
    {
      "epoch": 0.0013333333333333333,
      "grad_norm": 0.33346882462501526,
      "learning_rate": 4.993333333333334e-05,
      "loss": 0.0023,
      "step": 30
    },
    {
      "epoch": 0.0017777777777777779,
      "grad_norm": 0.22146375477313995,
      "learning_rate": 4.991111111111111e-05,
      "loss": 0.0025,
      "step": 40
    },
    {
      "epoch": 0.0022222222222222222,
      "grad_norm": 0.29123905301094055,
      "learning_rate": 4.9888888888888894e-05,
      "loss": 0.0025,
      "step": 50
    },
    {
      "epoch": 0.0026666666666666666,
      "grad_norm": 0.5674967765808105,
      "learning_rate": 4.986666666666667e-05,
      "loss": 0.0022,
      "step": 60
    },
    {
      "epoch": 0.003111111111111111,
      "grad_norm": 0.5208178758621216,
      "learning_rate": 4.984444444444445e-05,
      "loss": 0.0023,
      "step": 70
    },
    {
      "epoch": 0.0035555555555555557,
      "grad_norm": 0.08098272234201431,
      "learning_rate": 4.982222222222222e-05,
      "loss": 0.002,
      "step": 80
    },
    {
      "epoch": 0.004,
      "grad_norm": 0.09092400223016739,
      "learning_rate": 4.9800000000000004e-05,
      "loss": 0.0023,
      "step": 90
    },
    {
      "epoch": 0.0044444444444444444,
      "grad_norm": 0.23526591062545776,
      "learning_rate": 4.977777777777778e-05,
      "loss": 0.0026,
      "step": 100
    },
    {
      "epoch": 0.004888888888888889,
      "grad_norm": 0.5553855895996094,
      "learning_rate": 4.975555555555555e-05,
      "loss": 0.0025,
      "step": 110
    },
    {
      "epoch": 0.005333333333333333,
      "grad_norm": 0.21562905609607697,
      "learning_rate": 4.973333333333334e-05,
      "loss": 0.0021,
      "step": 120
    },
    {
      "epoch": 0.0057777777777777775,
      "grad_norm": 0.572628915309906,
      "learning_rate": 4.9711111111111115e-05,
      "loss": 0.002,
      "step": 130
    },
    {
      "epoch": 0.006222222222222222,
      "grad_norm": 0.2656748294830322,
      "learning_rate": 4.968888888888889e-05,
      "loss": 0.0024,
      "step": 140
    },
    {
      "epoch": 0.006666666666666667,
      "grad_norm": 0.5883641839027405,
      "learning_rate": 4.966666666666667e-05,
      "loss": 0.0024,
      "step": 150
    },
    {
      "epoch": 0.0071111111111111115,
      "grad_norm": 0.714474081993103,
      "learning_rate": 4.964444444444445e-05,
      "loss": 0.0021,
      "step": 160
    },
    {
      "epoch": 0.007555555555555556,
      "grad_norm": 0.44770610332489014,
      "learning_rate": 4.9622222222222225e-05,
      "loss": 0.0026,
      "step": 170
    },
    {
      "epoch": 0.008,
      "grad_norm": 0.1668509989976883,
      "learning_rate": 4.96e-05,
      "loss": 0.0025,
      "step": 180
    },
    {
      "epoch": 0.008444444444444444,
      "grad_norm": 0.03114468604326248,
      "learning_rate": 4.957777777777778e-05,
      "loss": 0.0025,
      "step": 190
    },
    {
      "epoch": 0.008888888888888889,
      "grad_norm": 0.3637666702270508,
      "learning_rate": 4.955555555555556e-05,
      "loss": 0.0019,
      "step": 200
    },
    {
      "epoch": 0.009333333333333334,
      "grad_norm": 0.07226796448230743,
      "learning_rate": 4.9533333333333336e-05,
      "loss": 0.0039,
      "step": 210
    },
    {
      "epoch": 0.009777777777777778,
      "grad_norm": 0.8094701170921326,
      "learning_rate": 4.951111111111112e-05,
      "loss": 0.0024,
      "step": 220
    },
    {
      "epoch": 0.010222222222222223,
      "grad_norm": 0.4490559697151184,
      "learning_rate": 4.948888888888889e-05,
      "loss": 0.0022,
      "step": 230
    },
    {
      "epoch": 0.010666666666666666,
      "grad_norm": 0.07035790383815765,
      "learning_rate": 4.9466666666666665e-05,
      "loss": 0.0025,
      "step": 240
    },
    {
      "epoch": 0.011111111111111112,
      "grad_norm": 0.38756558299064636,
      "learning_rate": 4.9444444444444446e-05,
      "loss": 0.0024,
      "step": 250
    },
    {
      "epoch": 0.011555555555555555,
      "grad_norm": 0.7057538628578186,
      "learning_rate": 4.942222222222223e-05,
      "loss": 0.0022,
      "step": 260
    },
    {
      "epoch": 0.012,
      "grad_norm": 0.34722304344177246,
      "learning_rate": 4.94e-05,
      "loss": 0.0021,
      "step": 270
    },
    {
      "epoch": 0.012444444444444444,
      "grad_norm": 0.18321561813354492,
      "learning_rate": 4.9377777777777776e-05,
      "loss": 0.0024,
      "step": 280
    },
    {
      "epoch": 0.012888888888888889,
      "grad_norm": 0.035444360226392746,
      "learning_rate": 4.935555555555556e-05,
      "loss": 0.0022,
      "step": 290
    },
    {
      "epoch": 0.013333333333333334,
      "grad_norm": 0.6388711333274841,
      "learning_rate": 4.933333333333334e-05,
      "loss": 0.0018,
      "step": 300
    },
    {
      "epoch": 0.013777777777777778,
      "grad_norm": 0.23523105680942535,
      "learning_rate": 4.931111111111111e-05,
      "loss": 0.0021,
      "step": 310
    },
    {
      "epoch": 0.014222222222222223,
      "grad_norm": 0.43014270067214966,
      "learning_rate": 4.928888888888889e-05,
      "loss": 0.0018,
      "step": 320
    },
    {
      "epoch": 0.014666666666666666,
      "grad_norm": 0.6955930590629578,
      "learning_rate": 4.926666666666667e-05,
      "loss": 0.0026,
      "step": 330
    },
    {
      "epoch": 0.015111111111111112,
      "grad_norm": 0.4411982595920563,
      "learning_rate": 4.924444444444445e-05,
      "loss": 0.0028,
      "step": 340
    },
    {
      "epoch": 0.015555555555555555,
      "grad_norm": 0.6494938731193542,
      "learning_rate": 4.922222222222222e-05,
      "loss": 0.0022,
      "step": 350
    },
    {
      "epoch": 0.016,
      "grad_norm": 0.28954029083251953,
      "learning_rate": 4.92e-05,
      "loss": 0.0028,
      "step": 360
    },
    {
      "epoch": 0.016444444444444446,
      "grad_norm": 0.08448728173971176,
      "learning_rate": 4.917777777777778e-05,
      "loss": 0.0017,
      "step": 370
    },
    {
      "epoch": 0.016888888888888887,
      "grad_norm": 0.19596046209335327,
      "learning_rate": 4.915555555555556e-05,
      "loss": 0.0025,
      "step": 380
    },
    {
      "epoch": 0.017333333333333333,
      "grad_norm": 0.20681434869766235,
      "learning_rate": 4.913333333333334e-05,
      "loss": 0.0026,
      "step": 390
    },
    {
      "epoch": 0.017777777777777778,
      "grad_norm": 0.36283111572265625,
      "learning_rate": 4.9111111111111114e-05,
      "loss": 0.0019,
      "step": 400
    },
    {
      "epoch": 0.018222222222222223,
      "grad_norm": 0.23556585609912872,
      "learning_rate": 4.908888888888889e-05,
      "loss": 0.0018,
      "step": 410
    },
    {
      "epoch": 0.018666666666666668,
      "grad_norm": 0.09869401156902313,
      "learning_rate": 4.906666666666667e-05,
      "loss": 0.0019,
      "step": 420
    },
    {
      "epoch": 0.01911111111111111,
      "grad_norm": 0.18208593130111694,
      "learning_rate": 4.904444444444445e-05,
      "loss": 0.0025,
      "step": 430
    },
    {
      "epoch": 0.019555555555555555,
      "grad_norm": 0.14128680527210236,
      "learning_rate": 4.9022222222222224e-05,
      "loss": 0.0021,
      "step": 440
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.4233314096927643,
      "learning_rate": 4.9e-05,
      "loss": 0.0032,
      "step": 450
    },
    {
      "epoch": 0.020444444444444446,
      "grad_norm": 0.03138251230120659,
      "learning_rate": 4.897777777777778e-05,
      "loss": 0.0021,
      "step": 460
    },
    {
      "epoch": 0.020888888888888887,
      "grad_norm": 0.29100707173347473,
      "learning_rate": 4.895555555555556e-05,
      "loss": 0.0019,
      "step": 470
    },
    {
      "epoch": 0.021333333333333333,
      "grad_norm": 0.029462845996022224,
      "learning_rate": 4.8933333333333335e-05,
      "loss": 0.0026,
      "step": 480
    },
    {
      "epoch": 0.021777777777777778,
      "grad_norm": 0.0329396091401577,
      "learning_rate": 4.8911111111111116e-05,
      "loss": 0.0023,
      "step": 490
    },
    {
      "epoch": 0.022222222222222223,
      "grad_norm": 0.058834947645664215,
      "learning_rate": 4.888888888888889e-05,
      "loss": 0.0017,
      "step": 500
    },
    {
      "epoch": 0.02266666666666667,
      "grad_norm": 0.0621454231441021,
      "learning_rate": 4.886666666666667e-05,
      "loss": 0.0019,
      "step": 510
    },
    {
      "epoch": 0.02311111111111111,
      "grad_norm": 0.4438784718513489,
      "learning_rate": 4.8844444444444445e-05,
      "loss": 0.0018,
      "step": 520
    },
    {
      "epoch": 0.023555555555555555,
      "grad_norm": 0.10230422765016556,
      "learning_rate": 4.8822222222222226e-05,
      "loss": 0.0022,
      "step": 530
    },
    {
      "epoch": 0.024,
      "grad_norm": 0.08725003153085709,
      "learning_rate": 4.88e-05,
      "loss": 0.0019,
      "step": 540
    },
    {
      "epoch": 0.024444444444444446,
      "grad_norm": 0.13342900574207306,
      "learning_rate": 4.8777777777777775e-05,
      "loss": 0.0026,
      "step": 550
    },
    {
      "epoch": 0.024888888888888887,
      "grad_norm": 0.5404277443885803,
      "learning_rate": 4.875555555555556e-05,
      "loss": 0.0022,
      "step": 560
    },
    {
      "epoch": 0.025333333333333333,
      "grad_norm": 0.3046089708805084,
      "learning_rate": 4.8733333333333337e-05,
      "loss": 0.002,
      "step": 570
    },
    {
      "epoch": 0.025777777777777778,
      "grad_norm": 0.46920520067214966,
      "learning_rate": 4.871111111111111e-05,
      "loss": 0.0018,
      "step": 580
    },
    {
      "epoch": 0.026222222222222223,
      "grad_norm": 0.15318146347999573,
      "learning_rate": 4.868888888888889e-05,
      "loss": 0.0021,
      "step": 590
    },
    {
      "epoch": 0.02666666666666667,
      "grad_norm": 0.20922598242759705,
      "learning_rate": 4.866666666666667e-05,
      "loss": 0.0016,
      "step": 600
    },
    {
      "epoch": 0.02711111111111111,
      "grad_norm": 0.0294947549700737,
      "learning_rate": 4.864444444444445e-05,
      "loss": 0.002,
      "step": 610
    },
    {
      "epoch": 0.027555555555555555,
      "grad_norm": 0.5543920397758484,
      "learning_rate": 4.862222222222222e-05,
      "loss": 0.0018,
      "step": 620
    },
    {
      "epoch": 0.028,
      "grad_norm": 0.16773545742034912,
      "learning_rate": 4.86e-05,
      "loss": 0.0022,
      "step": 630
    },
    {
      "epoch": 0.028444444444444446,
      "grad_norm": 0.08659695088863373,
      "learning_rate": 4.8577777777777776e-05,
      "loss": 0.0018,
      "step": 640
    },
    {
      "epoch": 0.028888888888888888,
      "grad_norm": 0.4576892554759979,
      "learning_rate": 4.855555555555556e-05,
      "loss": 0.0019,
      "step": 650
    },
    {
      "epoch": 0.029333333333333333,
      "grad_norm": 0.19701409339904785,
      "learning_rate": 4.853333333333334e-05,
      "loss": 0.0019,
      "step": 660
    },
    {
      "epoch": 0.029777777777777778,
      "grad_norm": 0.5116689801216125,
      "learning_rate": 4.851111111111111e-05,
      "loss": 0.0022,
      "step": 670
    },
    {
      "epoch": 0.030222222222222223,
      "grad_norm": 0.31670087575912476,
      "learning_rate": 4.848888888888889e-05,
      "loss": 0.0021,
      "step": 680
    },
    {
      "epoch": 0.030666666666666665,
      "grad_norm": 0.16735003888607025,
      "learning_rate": 4.8466666666666675e-05,
      "loss": 0.0023,
      "step": 690
    },
    {
      "epoch": 0.03111111111111111,
      "grad_norm": 0.2633399963378906,
      "learning_rate": 4.844444444444445e-05,
      "loss": 0.0023,
      "step": 700
    },
    {
      "epoch": 0.03155555555555556,
      "grad_norm": 0.29064419865608215,
      "learning_rate": 4.842222222222222e-05,
      "loss": 0.0024,
      "step": 710
    },
    {
      "epoch": 0.032,
      "grad_norm": 0.15305058658123016,
      "learning_rate": 4.8400000000000004e-05,
      "loss": 0.0019,
      "step": 720
    },
    {
      "epoch": 0.03244444444444444,
      "grad_norm": 0.34598907828330994,
      "learning_rate": 4.837777777777778e-05,
      "loss": 0.0023,
      "step": 730
    },
    {
      "epoch": 0.03288888888888889,
      "grad_norm": 0.022697309032082558,
      "learning_rate": 4.835555555555556e-05,
      "loss": 0.0022,
      "step": 740
    },
    {
      "epoch": 0.03333333333333333,
      "grad_norm": 0.46120917797088623,
      "learning_rate": 4.8333333333333334e-05,
      "loss": 0.0024,
      "step": 750
    },
    {
      "epoch": 0.033777777777777775,
      "grad_norm": 0.2265670746564865,
      "learning_rate": 4.8311111111111115e-05,
      "loss": 0.0019,
      "step": 760
    },
    {
      "epoch": 0.03422222222222222,
      "grad_norm": 0.1256120502948761,
      "learning_rate": 4.828888888888889e-05,
      "loss": 0.0019,
      "step": 770
    },
    {
      "epoch": 0.034666666666666665,
      "grad_norm": 0.4287290871143341,
      "learning_rate": 4.826666666666667e-05,
      "loss": 0.0022,
      "step": 780
    },
    {
      "epoch": 0.035111111111111114,
      "grad_norm": 0.6891762614250183,
      "learning_rate": 4.824444444444445e-05,
      "loss": 0.0024,
      "step": 790
    },
    {
      "epoch": 0.035555555555555556,
      "grad_norm": 0.16834330558776855,
      "learning_rate": 4.8222222222222225e-05,
      "loss": 0.003,
      "step": 800
    },
    {
      "epoch": 0.036,
      "grad_norm": 0.15210436284542084,
      "learning_rate": 4.82e-05,
      "loss": 0.002,
      "step": 810
    },
    {
      "epoch": 0.036444444444444446,
      "grad_norm": 0.6242002844810486,
      "learning_rate": 4.817777777777778e-05,
      "loss": 0.0026,
      "step": 820
    },
    {
      "epoch": 0.03688888888888889,
      "grad_norm": 0.44456788897514343,
      "learning_rate": 4.815555555555556e-05,
      "loss": 0.0019,
      "step": 830
    },
    {
      "epoch": 0.037333333333333336,
      "grad_norm": 0.1528301239013672,
      "learning_rate": 4.8133333333333336e-05,
      "loss": 0.002,
      "step": 840
    },
    {
      "epoch": 0.03777777777777778,
      "grad_norm": 0.27909398078918457,
      "learning_rate": 4.811111111111111e-05,
      "loss": 0.0021,
      "step": 850
    },
    {
      "epoch": 0.03822222222222222,
      "grad_norm": 0.6619415879249573,
      "learning_rate": 4.808888888888889e-05,
      "loss": 0.0019,
      "step": 860
    },
    {
      "epoch": 0.03866666666666667,
      "grad_norm": 0.1622498780488968,
      "learning_rate": 4.806666666666667e-05,
      "loss": 0.0018,
      "step": 870
    },
    {
      "epoch": 0.03911111111111111,
      "grad_norm": 0.44070789217948914,
      "learning_rate": 4.8044444444444446e-05,
      "loss": 0.0021,
      "step": 880
    },
    {
      "epoch": 0.03955555555555555,
      "grad_norm": 0.09733044356107712,
      "learning_rate": 4.802222222222223e-05,
      "loss": 0.0016,
      "step": 890
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.058598365634679794,
      "learning_rate": 4.8e-05,
      "loss": 0.0018,
      "step": 900
    },
    {
      "epoch": 0.04044444444444444,
      "grad_norm": 0.09869331121444702,
      "learning_rate": 4.797777777777778e-05,
      "loss": 0.0017,
      "step": 910
    },
    {
      "epoch": 0.04088888888888889,
      "grad_norm": 0.04552214592695236,
      "learning_rate": 4.7955555555555556e-05,
      "loss": 0.0023,
      "step": 920
    },
    {
      "epoch": 0.04133333333333333,
      "grad_norm": 0.2656184434890747,
      "learning_rate": 4.793333333333334e-05,
      "loss": 0.0019,
      "step": 930
    },
    {
      "epoch": 0.041777777777777775,
      "grad_norm": 0.16841280460357666,
      "learning_rate": 4.791111111111111e-05,
      "loss": 0.0017,
      "step": 940
    },
    {
      "epoch": 0.042222222222222223,
      "grad_norm": 0.11242921650409698,
      "learning_rate": 4.7888888888888886e-05,
      "loss": 0.0018,
      "step": 950
    },
    {
      "epoch": 0.042666666666666665,
      "grad_norm": 0.5111297965049744,
      "learning_rate": 4.7866666666666674e-05,
      "loss": 0.0022,
      "step": 960
    },
    {
      "epoch": 0.043111111111111114,
      "grad_norm": 0.14193232357501984,
      "learning_rate": 4.784444444444445e-05,
      "loss": 0.0016,
      "step": 970
    },
    {
      "epoch": 0.043555555555555556,
      "grad_norm": 0.49958786368370056,
      "learning_rate": 4.782222222222222e-05,
      "loss": 0.0026,
      "step": 980
    },
    {
      "epoch": 0.044,
      "grad_norm": 0.15385572612285614,
      "learning_rate": 4.78e-05,
      "loss": 0.0019,
      "step": 990
    },
    {
      "epoch": 0.044444444444444446,
      "grad_norm": 0.1267574429512024,
      "learning_rate": 4.7777777777777784e-05,
      "loss": 0.0025,
      "step": 1000
    },
    {
      "epoch": 0.04488888888888889,
      "grad_norm": 0.25080591440200806,
      "learning_rate": 4.775555555555556e-05,
      "loss": 0.0022,
      "step": 1010
    },
    {
      "epoch": 0.04533333333333334,
      "grad_norm": 0.18092913925647736,
      "learning_rate": 4.773333333333333e-05,
      "loss": 0.0023,
      "step": 1020
    },
    {
      "epoch": 0.04577777777777778,
      "grad_norm": 0.6556066274642944,
      "learning_rate": 4.7711111111111114e-05,
      "loss": 0.0024,
      "step": 1030
    },
    {
      "epoch": 0.04622222222222222,
      "grad_norm": 0.3404957354068756,
      "learning_rate": 4.768888888888889e-05,
      "loss": 0.0025,
      "step": 1040
    },
    {
      "epoch": 0.04666666666666667,
      "grad_norm": 0.5533216595649719,
      "learning_rate": 4.766666666666667e-05,
      "loss": 0.0021,
      "step": 1050
    },
    {
      "epoch": 0.04711111111111111,
      "grad_norm": 0.022392746061086655,
      "learning_rate": 4.764444444444445e-05,
      "loss": 0.0019,
      "step": 1060
    },
    {
      "epoch": 0.04755555555555555,
      "grad_norm": 0.2774026393890381,
      "learning_rate": 4.7622222222222224e-05,
      "loss": 0.0023,
      "step": 1070
    },
    {
      "epoch": 0.048,
      "grad_norm": 0.1284698247909546,
      "learning_rate": 4.76e-05,
      "loss": 0.0023,
      "step": 1080
    },
    {
      "epoch": 0.04844444444444444,
      "grad_norm": 0.508969783782959,
      "learning_rate": 4.757777777777778e-05,
      "loss": 0.0029,
      "step": 1090
    },
    {
      "epoch": 0.04888888888888889,
      "grad_norm": 0.33432331681251526,
      "learning_rate": 4.755555555555556e-05,
      "loss": 0.0027,
      "step": 1100
    },
    {
      "epoch": 0.04933333333333333,
      "grad_norm": 0.19373245537281036,
      "learning_rate": 4.7533333333333334e-05,
      "loss": 0.0023,
      "step": 1110
    },
    {
      "epoch": 0.049777777777777775,
      "grad_norm": 0.6353210806846619,
      "learning_rate": 4.751111111111111e-05,
      "loss": 0.0018,
      "step": 1120
    },
    {
      "epoch": 0.050222222222222224,
      "grad_norm": 0.06067745387554169,
      "learning_rate": 4.7488888888888897e-05,
      "loss": 0.0024,
      "step": 1130
    },
    {
      "epoch": 0.050666666666666665,
      "grad_norm": 0.12469007819890976,
      "learning_rate": 4.746666666666667e-05,
      "loss": 0.0024,
      "step": 1140
    },
    {
      "epoch": 0.051111111111111114,
      "grad_norm": 0.11298763751983643,
      "learning_rate": 4.7444444444444445e-05,
      "loss": 0.0026,
      "step": 1150
    },
    {
      "epoch": 0.051555555555555556,
      "grad_norm": 0.3591421842575073,
      "learning_rate": 4.7422222222222226e-05,
      "loss": 0.0027,
      "step": 1160
    },
    {
      "epoch": 0.052,
      "grad_norm": 0.7212416529655457,
      "learning_rate": 4.74e-05,
      "loss": 0.0024,
      "step": 1170
    },
    {
      "epoch": 0.052444444444444446,
      "grad_norm": 0.021156374365091324,
      "learning_rate": 4.737777777777778e-05,
      "loss": 0.0021,
      "step": 1180
    },
    {
      "epoch": 0.05288888888888889,
      "grad_norm": 0.0842277854681015,
      "learning_rate": 4.7355555555555555e-05,
      "loss": 0.0016,
      "step": 1190
    },
    {
      "epoch": 0.05333333333333334,
      "grad_norm": 0.11453357338905334,
      "learning_rate": 4.7333333333333336e-05,
      "loss": 0.0028,
      "step": 1200
    },
    {
      "epoch": 0.05377777777777778,
      "grad_norm": 0.292870432138443,
      "learning_rate": 4.731111111111111e-05,
      "loss": 0.0023,
      "step": 1210
    },
    {
      "epoch": 0.05422222222222222,
      "grad_norm": 0.04337293282151222,
      "learning_rate": 4.728888888888889e-05,
      "loss": 0.0026,
      "step": 1220
    },
    {
      "epoch": 0.05466666666666667,
      "grad_norm": 0.34562352299690247,
      "learning_rate": 4.726666666666667e-05,
      "loss": 0.0026,
      "step": 1230
    },
    {
      "epoch": 0.05511111111111111,
      "grad_norm": 0.018955057486891747,
      "learning_rate": 4.724444444444445e-05,
      "loss": 0.0024,
      "step": 1240
    },
    {
      "epoch": 0.05555555555555555,
      "grad_norm": 0.3033517599105835,
      "learning_rate": 4.722222222222222e-05,
      "loss": 0.0023,
      "step": 1250
    },
    {
      "epoch": 0.056,
      "grad_norm": 0.09951116144657135,
      "learning_rate": 4.72e-05,
      "loss": 0.0018,
      "step": 1260
    },
    {
      "epoch": 0.05644444444444444,
      "grad_norm": 0.2780522406101227,
      "learning_rate": 4.717777777777778e-05,
      "loss": 0.0018,
      "step": 1270
    },
    {
      "epoch": 0.05688888888888889,
      "grad_norm": 0.33405551314353943,
      "learning_rate": 4.715555555555556e-05,
      "loss": 0.0018,
      "step": 1280
    },
    {
      "epoch": 0.05733333333333333,
      "grad_norm": 0.2628854811191559,
      "learning_rate": 4.713333333333333e-05,
      "loss": 0.0018,
      "step": 1290
    },
    {
      "epoch": 0.057777777777777775,
      "grad_norm": 0.7623826265335083,
      "learning_rate": 4.711111111111111e-05,
      "loss": 0.0023,
      "step": 1300
    },
    {
      "epoch": 0.058222222222222224,
      "grad_norm": 0.02361314184963703,
      "learning_rate": 4.7088888888888894e-05,
      "loss": 0.0022,
      "step": 1310
    },
    {
      "epoch": 0.058666666666666666,
      "grad_norm": 0.039379268884658813,
      "learning_rate": 4.706666666666667e-05,
      "loss": 0.002,
      "step": 1320
    },
    {
      "epoch": 0.059111111111111114,
      "grad_norm": 0.3600398898124695,
      "learning_rate": 4.704444444444445e-05,
      "loss": 0.0023,
      "step": 1330
    },
    {
      "epoch": 0.059555555555555556,
      "grad_norm": 0.2627304792404175,
      "learning_rate": 4.702222222222222e-05,
      "loss": 0.0027,
      "step": 1340
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.2804802358150482,
      "learning_rate": 4.7e-05,
      "loss": 0.0018,
      "step": 1350
    },
    {
      "epoch": 0.060444444444444446,
      "grad_norm": 0.3376385271549225,
      "learning_rate": 4.6977777777777785e-05,
      "loss": 0.002,
      "step": 1360
    },
    {
      "epoch": 0.06088888888888889,
      "grad_norm": 0.11073191463947296,
      "learning_rate": 4.695555555555556e-05,
      "loss": 0.0023,
      "step": 1370
    },
    {
      "epoch": 0.06133333333333333,
      "grad_norm": 0.4223012328147888,
      "learning_rate": 4.6933333333333333e-05,
      "loss": 0.002,
      "step": 1380
    },
    {
      "epoch": 0.06177777777777778,
      "grad_norm": 0.0501064732670784,
      "learning_rate": 4.6911111111111114e-05,
      "loss": 0.0024,
      "step": 1390
    },
    {
      "epoch": 0.06222222222222222,
      "grad_norm": 0.2636459767818451,
      "learning_rate": 4.6888888888888895e-05,
      "loss": 0.0021,
      "step": 1400
    },
    {
      "epoch": 0.06266666666666666,
      "grad_norm": 0.3043234050273895,
      "learning_rate": 4.686666666666667e-05,
      "loss": 0.0017,
      "step": 1410
    },
    {
      "epoch": 0.06311111111111112,
      "grad_norm": 0.2209295928478241,
      "learning_rate": 4.6844444444444444e-05,
      "loss": 0.002,
      "step": 1420
    },
    {
      "epoch": 0.06355555555555556,
      "grad_norm": 0.5934833288192749,
      "learning_rate": 4.6822222222222225e-05,
      "loss": 0.0021,
      "step": 1430
    },
    {
      "epoch": 0.064,
      "grad_norm": 0.0893479660153389,
      "learning_rate": 4.6800000000000006e-05,
      "loss": 0.0031,
      "step": 1440
    },
    {
      "epoch": 0.06444444444444444,
      "grad_norm": 0.2642260789871216,
      "learning_rate": 4.677777777777778e-05,
      "loss": 0.0018,
      "step": 1450
    },
    {
      "epoch": 0.06488888888888888,
      "grad_norm": 0.47614067792892456,
      "learning_rate": 4.675555555555556e-05,
      "loss": 0.0021,
      "step": 1460
    },
    {
      "epoch": 0.06533333333333333,
      "grad_norm": 0.4575052559375763,
      "learning_rate": 4.6733333333333335e-05,
      "loss": 0.0034,
      "step": 1470
    },
    {
      "epoch": 0.06577777777777778,
      "grad_norm": 0.4982461631298065,
      "learning_rate": 4.671111111111111e-05,
      "loss": 0.0027,
      "step": 1480
    },
    {
      "epoch": 0.06622222222222222,
      "grad_norm": 0.19525554776191711,
      "learning_rate": 4.668888888888889e-05,
      "loss": 0.0016,
      "step": 1490
    },
    {
      "epoch": 0.06666666666666667,
      "grad_norm": 0.06072503700852394,
      "learning_rate": 4.666666666666667e-05,
      "loss": 0.0022,
      "step": 1500
    },
    {
      "epoch": 0.06711111111111111,
      "grad_norm": 0.14963315427303314,
      "learning_rate": 4.6644444444444446e-05,
      "loss": 0.0021,
      "step": 1510
    },
    {
      "epoch": 0.06755555555555555,
      "grad_norm": 0.4972296357154846,
      "learning_rate": 4.662222222222222e-05,
      "loss": 0.002,
      "step": 1520
    },
    {
      "epoch": 0.068,
      "grad_norm": 0.16715358197689056,
      "learning_rate": 4.660000000000001e-05,
      "loss": 0.0017,
      "step": 1530
    },
    {
      "epoch": 0.06844444444444445,
      "grad_norm": 0.042591385543346405,
      "learning_rate": 4.657777777777778e-05,
      "loss": 0.002,
      "step": 1540
    },
    {
      "epoch": 0.06888888888888889,
      "grad_norm": 0.5820361375808716,
      "learning_rate": 4.6555555555555556e-05,
      "loss": 0.0021,
      "step": 1550
    },
    {
      "epoch": 0.06933333333333333,
      "grad_norm": 0.14086861908435822,
      "learning_rate": 4.653333333333334e-05,
      "loss": 0.0018,
      "step": 1560
    },
    {
      "epoch": 0.06977777777777777,
      "grad_norm": 0.02408490888774395,
      "learning_rate": 4.651111111111111e-05,
      "loss": 0.002,
      "step": 1570
    },
    {
      "epoch": 0.07022222222222223,
      "grad_norm": 0.6831309795379639,
      "learning_rate": 4.648888888888889e-05,
      "loss": 0.0019,
      "step": 1580
    },
    {
      "epoch": 0.07066666666666667,
      "grad_norm": 0.3222556710243225,
      "learning_rate": 4.646666666666667e-05,
      "loss": 0.0019,
      "step": 1590
    },
    {
      "epoch": 0.07111111111111111,
      "grad_norm": 0.543073296546936,
      "learning_rate": 4.644444444444445e-05,
      "loss": 0.0025,
      "step": 1600
    },
    {
      "epoch": 0.07155555555555555,
      "grad_norm": 0.17966707050800323,
      "learning_rate": 4.642222222222222e-05,
      "loss": 0.0019,
      "step": 1610
    },
    {
      "epoch": 0.072,
      "grad_norm": 0.36329004168510437,
      "learning_rate": 4.64e-05,
      "loss": 0.0021,
      "step": 1620
    },
    {
      "epoch": 0.07244444444444445,
      "grad_norm": 0.23833626508712769,
      "learning_rate": 4.6377777777777784e-05,
      "loss": 0.0019,
      "step": 1630
    },
    {
      "epoch": 0.07288888888888889,
      "grad_norm": 0.1519518792629242,
      "learning_rate": 4.635555555555556e-05,
      "loss": 0.0021,
      "step": 1640
    },
    {
      "epoch": 0.07333333333333333,
      "grad_norm": 0.6981497406959534,
      "learning_rate": 4.633333333333333e-05,
      "loss": 0.0017,
      "step": 1650
    },
    {
      "epoch": 0.07377777777777778,
      "grad_norm": 0.15546752512454987,
      "learning_rate": 4.6311111111111113e-05,
      "loss": 0.002,
      "step": 1660
    },
    {
      "epoch": 0.07422222222222222,
      "grad_norm": 0.15297938883304596,
      "learning_rate": 4.6288888888888894e-05,
      "loss": 0.0017,
      "step": 1670
    },
    {
      "epoch": 0.07466666666666667,
      "grad_norm": 0.5249934792518616,
      "learning_rate": 4.626666666666667e-05,
      "loss": 0.0018,
      "step": 1680
    },
    {
      "epoch": 0.07511111111111111,
      "grad_norm": 1.0155056715011597,
      "learning_rate": 4.624444444444444e-05,
      "loss": 0.0021,
      "step": 1690
    },
    {
      "epoch": 0.07555555555555556,
      "grad_norm": 0.2803555428981781,
      "learning_rate": 4.6222222222222224e-05,
      "loss": 0.0023,
      "step": 1700
    },
    {
      "epoch": 0.076,
      "grad_norm": 0.17078420519828796,
      "learning_rate": 4.6200000000000005e-05,
      "loss": 0.0021,
      "step": 1710
    },
    {
      "epoch": 0.07644444444444444,
      "grad_norm": 0.04428841173648834,
      "learning_rate": 4.617777777777778e-05,
      "loss": 0.0021,
      "step": 1720
    },
    {
      "epoch": 0.0768888888888889,
      "grad_norm": 0.07165051251649857,
      "learning_rate": 4.615555555555556e-05,
      "loss": 0.0019,
      "step": 1730
    },
    {
      "epoch": 0.07733333333333334,
      "grad_norm": 0.048536717891693115,
      "learning_rate": 4.6133333333333334e-05,
      "loss": 0.0027,
      "step": 1740
    },
    {
      "epoch": 0.07777777777777778,
      "grad_norm": 0.30801069736480713,
      "learning_rate": 4.6111111111111115e-05,
      "loss": 0.0025,
      "step": 1750
    },
    {
      "epoch": 0.07822222222222222,
      "grad_norm": 0.061951689422130585,
      "learning_rate": 4.608888888888889e-05,
      "loss": 0.002,
      "step": 1760
    },
    {
      "epoch": 0.07866666666666666,
      "grad_norm": 0.3330831229686737,
      "learning_rate": 4.606666666666667e-05,
      "loss": 0.0022,
      "step": 1770
    },
    {
      "epoch": 0.0791111111111111,
      "grad_norm": 0.08424310386180878,
      "learning_rate": 4.6044444444444445e-05,
      "loss": 0.0017,
      "step": 1780
    },
    {
      "epoch": 0.07955555555555556,
      "grad_norm": 0.1550351232290268,
      "learning_rate": 4.602222222222222e-05,
      "loss": 0.0018,
      "step": 1790
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.11227988451719284,
      "learning_rate": 4.600000000000001e-05,
      "loss": 0.0018,
      "step": 1800
    },
    {
      "epoch": 0.08044444444444444,
      "grad_norm": 0.09707099199295044,
      "learning_rate": 4.597777777777778e-05,
      "loss": 0.0024,
      "step": 1810
    },
    {
      "epoch": 0.08088888888888889,
      "grad_norm": 0.20842939615249634,
      "learning_rate": 4.5955555555555555e-05,
      "loss": 0.0017,
      "step": 1820
    },
    {
      "epoch": 0.08133333333333333,
      "grad_norm": 0.10121442377567291,
      "learning_rate": 4.5933333333333336e-05,
      "loss": 0.0022,
      "step": 1830
    },
    {
      "epoch": 0.08177777777777778,
      "grad_norm": 0.16666579246520996,
      "learning_rate": 4.591111111111112e-05,
      "loss": 0.0023,
      "step": 1840
    },
    {
      "epoch": 0.08222222222222222,
      "grad_norm": 0.2798539996147156,
      "learning_rate": 4.588888888888889e-05,
      "loss": 0.002,
      "step": 1850
    },
    {
      "epoch": 0.08266666666666667,
      "grad_norm": 0.3195479214191437,
      "learning_rate": 4.5866666666666666e-05,
      "loss": 0.0021,
      "step": 1860
    },
    {
      "epoch": 0.08311111111111111,
      "grad_norm": 0.1696392446756363,
      "learning_rate": 4.584444444444445e-05,
      "loss": 0.0021,
      "step": 1870
    },
    {
      "epoch": 0.08355555555555555,
      "grad_norm": 0.031849950551986694,
      "learning_rate": 4.582222222222222e-05,
      "loss": 0.0019,
      "step": 1880
    },
    {
      "epoch": 0.084,
      "grad_norm": 0.5177317261695862,
      "learning_rate": 4.58e-05,
      "loss": 0.0021,
      "step": 1890
    },
    {
      "epoch": 0.08444444444444445,
      "grad_norm": 0.42905935645103455,
      "learning_rate": 4.577777777777778e-05,
      "loss": 0.002,
      "step": 1900
    },
    {
      "epoch": 0.08488888888888889,
      "grad_norm": 0.37408825755119324,
      "learning_rate": 4.575555555555556e-05,
      "loss": 0.0024,
      "step": 1910
    },
    {
      "epoch": 0.08533333333333333,
      "grad_norm": 0.16694369912147522,
      "learning_rate": 4.573333333333333e-05,
      "loss": 0.0021,
      "step": 1920
    },
    {
      "epoch": 0.08577777777777777,
      "grad_norm": 0.21382273733615875,
      "learning_rate": 4.571111111111111e-05,
      "loss": 0.0022,
      "step": 1930
    },
    {
      "epoch": 0.08622222222222223,
      "grad_norm": 0.061424631625413895,
      "learning_rate": 4.5688888888888893e-05,
      "loss": 0.0025,
      "step": 1940
    },
    {
      "epoch": 0.08666666666666667,
      "grad_norm": 0.07453074306249619,
      "learning_rate": 4.566666666666667e-05,
      "loss": 0.0025,
      "step": 1950
    },
    {
      "epoch": 0.08711111111111111,
      "grad_norm": 0.1803286075592041,
      "learning_rate": 4.564444444444444e-05,
      "loss": 0.0023,
      "step": 1960
    },
    {
      "epoch": 0.08755555555555555,
      "grad_norm": 0.23516765236854553,
      "learning_rate": 4.562222222222222e-05,
      "loss": 0.002,
      "step": 1970
    },
    {
      "epoch": 0.088,
      "grad_norm": 0.04611773416399956,
      "learning_rate": 4.5600000000000004e-05,
      "loss": 0.0019,
      "step": 1980
    },
    {
      "epoch": 0.08844444444444445,
      "grad_norm": 0.06973699480295181,
      "learning_rate": 4.557777777777778e-05,
      "loss": 0.0024,
      "step": 1990
    },
    {
      "epoch": 0.08888888888888889,
      "grad_norm": 0.4021797180175781,
      "learning_rate": 4.555555555555556e-05,
      "loss": 0.0022,
      "step": 2000
    },
    {
      "epoch": 0.08933333333333333,
      "grad_norm": 0.04434560239315033,
      "learning_rate": 4.553333333333333e-05,
      "loss": 0.0017,
      "step": 2010
    },
    {
      "epoch": 0.08977777777777778,
      "grad_norm": 0.22324202954769135,
      "learning_rate": 4.5511111111111114e-05,
      "loss": 0.0018,
      "step": 2020
    },
    {
      "epoch": 0.09022222222222222,
      "grad_norm": 0.4303717315196991,
      "learning_rate": 4.5488888888888895e-05,
      "loss": 0.0023,
      "step": 2030
    },
    {
      "epoch": 0.09066666666666667,
      "grad_norm": 0.2088499218225479,
      "learning_rate": 4.546666666666667e-05,
      "loss": 0.0022,
      "step": 2040
    },
    {
      "epoch": 0.09111111111111111,
      "grad_norm": 0.5258505940437317,
      "learning_rate": 4.5444444444444444e-05,
      "loss": 0.0022,
      "step": 2050
    },
    {
      "epoch": 0.09155555555555556,
      "grad_norm": 0.04760885238647461,
      "learning_rate": 4.5422222222222225e-05,
      "loss": 0.0021,
      "step": 2060
    },
    {
      "epoch": 0.092,
      "grad_norm": 0.38678959012031555,
      "learning_rate": 4.5400000000000006e-05,
      "loss": 0.0017,
      "step": 2070
    },
    {
      "epoch": 0.09244444444444444,
      "grad_norm": 0.052556950598955154,
      "learning_rate": 4.537777777777778e-05,
      "loss": 0.002,
      "step": 2080
    },
    {
      "epoch": 0.09288888888888888,
      "grad_norm": 0.24409380555152893,
      "learning_rate": 4.5355555555555554e-05,
      "loss": 0.0024,
      "step": 2090
    },
    {
      "epoch": 0.09333333333333334,
      "grad_norm": 0.12508012354373932,
      "learning_rate": 4.5333333333333335e-05,
      "loss": 0.002,
      "step": 2100
    },
    {
      "epoch": 0.09377777777777778,
      "grad_norm": 0.034864336252212524,
      "learning_rate": 4.5311111111111116e-05,
      "loss": 0.0028,
      "step": 2110
    },
    {
      "epoch": 0.09422222222222222,
      "grad_norm": 0.0247719194740057,
      "learning_rate": 4.528888888888889e-05,
      "loss": 0.0019,
      "step": 2120
    },
    {
      "epoch": 0.09466666666666666,
      "grad_norm": 0.3612257242202759,
      "learning_rate": 4.526666666666667e-05,
      "loss": 0.0022,
      "step": 2130
    },
    {
      "epoch": 0.0951111111111111,
      "grad_norm": 0.20897357165813446,
      "learning_rate": 4.5244444444444446e-05,
      "loss": 0.002,
      "step": 2140
    },
    {
      "epoch": 0.09555555555555556,
      "grad_norm": 0.1263689249753952,
      "learning_rate": 4.522222222222223e-05,
      "loss": 0.0025,
      "step": 2150
    },
    {
      "epoch": 0.096,
      "grad_norm": 0.3536613881587982,
      "learning_rate": 4.52e-05,
      "loss": 0.0031,
      "step": 2160
    },
    {
      "epoch": 0.09644444444444444,
      "grad_norm": 0.1581570953130722,
      "learning_rate": 4.517777777777778e-05,
      "loss": 0.0021,
      "step": 2170
    },
    {
      "epoch": 0.09688888888888889,
      "grad_norm": 0.70733243227005,
      "learning_rate": 4.5155555555555556e-05,
      "loss": 0.0019,
      "step": 2180
    },
    {
      "epoch": 0.09733333333333333,
      "grad_norm": 0.45586955547332764,
      "learning_rate": 4.513333333333333e-05,
      "loss": 0.0018,
      "step": 2190
    },
    {
      "epoch": 0.09777777777777778,
      "grad_norm": 0.22138507664203644,
      "learning_rate": 4.511111111111112e-05,
      "loss": 0.002,
      "step": 2200
    },
    {
      "epoch": 0.09822222222222222,
      "grad_norm": 0.5123352408409119,
      "learning_rate": 4.508888888888889e-05,
      "loss": 0.0019,
      "step": 2210
    },
    {
      "epoch": 0.09866666666666667,
      "grad_norm": 0.2486979365348816,
      "learning_rate": 4.5066666666666667e-05,
      "loss": 0.0018,
      "step": 2220
    },
    {
      "epoch": 0.09911111111111111,
      "grad_norm": 0.019279511645436287,
      "learning_rate": 4.504444444444445e-05,
      "loss": 0.0022,
      "step": 2230
    },
    {
      "epoch": 0.09955555555555555,
      "grad_norm": 0.48452627658843994,
      "learning_rate": 4.502222222222223e-05,
      "loss": 0.0018,
      "step": 2240
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.14046357572078705,
      "learning_rate": 4.5e-05,
      "loss": 0.002,
      "step": 2250
    },
    {
      "epoch": 0.10044444444444445,
      "grad_norm": 0.42806476354599,
      "learning_rate": 4.497777777777778e-05,
      "loss": 0.0023,
      "step": 2260
    },
    {
      "epoch": 0.10088888888888889,
      "grad_norm": 0.20769990980625153,
      "learning_rate": 4.495555555555556e-05,
      "loss": 0.0018,
      "step": 2270
    },
    {
      "epoch": 0.10133333333333333,
      "grad_norm": 0.08543548732995987,
      "learning_rate": 4.493333333333333e-05,
      "loss": 0.0019,
      "step": 2280
    },
    {
      "epoch": 0.10177777777777777,
      "grad_norm": 0.6211094856262207,
      "learning_rate": 4.491111111111111e-05,
      "loss": 0.0019,
      "step": 2290
    },
    {
      "epoch": 0.10222222222222223,
      "grad_norm": 0.028730742633342743,
      "learning_rate": 4.4888888888888894e-05,
      "loss": 0.002,
      "step": 2300
    },
    {
      "epoch": 0.10266666666666667,
      "grad_norm": 0.28973713517189026,
      "learning_rate": 4.486666666666667e-05,
      "loss": 0.0016,
      "step": 2310
    },
    {
      "epoch": 0.10311111111111111,
      "grad_norm": 0.26419922709465027,
      "learning_rate": 4.484444444444444e-05,
      "loss": 0.0021,
      "step": 2320
    },
    {
      "epoch": 0.10355555555555555,
      "grad_norm": 0.38530299067497253,
      "learning_rate": 4.4822222222222224e-05,
      "loss": 0.0019,
      "step": 2330
    },
    {
      "epoch": 0.104,
      "grad_norm": 0.3193081021308899,
      "learning_rate": 4.4800000000000005e-05,
      "loss": 0.0018,
      "step": 2340
    },
    {
      "epoch": 0.10444444444444445,
      "grad_norm": 0.4446619153022766,
      "learning_rate": 4.477777777777778e-05,
      "loss": 0.0023,
      "step": 2350
    },
    {
      "epoch": 0.10488888888888889,
      "grad_norm": 0.2502603530883789,
      "learning_rate": 4.475555555555555e-05,
      "loss": 0.0022,
      "step": 2360
    },
    {
      "epoch": 0.10533333333333333,
      "grad_norm": 0.11906887590885162,
      "learning_rate": 4.473333333333334e-05,
      "loss": 0.002,
      "step": 2370
    },
    {
      "epoch": 0.10577777777777778,
      "grad_norm": 0.1945936679840088,
      "learning_rate": 4.4711111111111115e-05,
      "loss": 0.0018,
      "step": 2380
    },
    {
      "epoch": 0.10622222222222222,
      "grad_norm": 0.11320764571428299,
      "learning_rate": 4.468888888888889e-05,
      "loss": 0.0022,
      "step": 2390
    },
    {
      "epoch": 0.10666666666666667,
      "grad_norm": 0.07052943110466003,
      "learning_rate": 4.466666666666667e-05,
      "loss": 0.0016,
      "step": 2400
    },
    {
      "epoch": 0.10711111111111112,
      "grad_norm": 0.018610704690217972,
      "learning_rate": 4.4644444444444445e-05,
      "loss": 0.002,
      "step": 2410
    },
    {
      "epoch": 0.10755555555555556,
      "grad_norm": 0.30518630146980286,
      "learning_rate": 4.4622222222222226e-05,
      "loss": 0.0029,
      "step": 2420
    },
    {
      "epoch": 0.108,
      "grad_norm": 0.41350534558296204,
      "learning_rate": 4.46e-05,
      "loss": 0.0025,
      "step": 2430
    },
    {
      "epoch": 0.10844444444444444,
      "grad_norm": 0.048298247158527374,
      "learning_rate": 4.457777777777778e-05,
      "loss": 0.0024,
      "step": 2440
    },
    {
      "epoch": 0.10888888888888888,
      "grad_norm": 0.372895747423172,
      "learning_rate": 4.4555555555555555e-05,
      "loss": 0.0022,
      "step": 2450
    },
    {
      "epoch": 0.10933333333333334,
      "grad_norm": 0.1378791183233261,
      "learning_rate": 4.4533333333333336e-05,
      "loss": 0.0021,
      "step": 2460
    },
    {
      "epoch": 0.10977777777777778,
      "grad_norm": 0.4701692759990692,
      "learning_rate": 4.451111111111112e-05,
      "loss": 0.0024,
      "step": 2470
    },
    {
      "epoch": 0.11022222222222222,
      "grad_norm": 0.12720553576946259,
      "learning_rate": 4.448888888888889e-05,
      "loss": 0.002,
      "step": 2480
    },
    {
      "epoch": 0.11066666666666666,
      "grad_norm": 0.5268071293830872,
      "learning_rate": 4.4466666666666666e-05,
      "loss": 0.0017,
      "step": 2490
    },
    {
      "epoch": 0.1111111111111111,
      "grad_norm": 0.32057538628578186,
      "learning_rate": 4.4444444444444447e-05,
      "loss": 0.0021,
      "step": 2500
    },
    {
      "epoch": 0.11155555555555556,
      "grad_norm": 0.11641546338796616,
      "learning_rate": 4.442222222222223e-05,
      "loss": 0.0028,
      "step": 2510
    },
    {
      "epoch": 0.112,
      "grad_norm": 0.1946418434381485,
      "learning_rate": 4.44e-05,
      "loss": 0.002,
      "step": 2520
    },
    {
      "epoch": 0.11244444444444444,
      "grad_norm": 0.23517905175685883,
      "learning_rate": 4.4377777777777776e-05,
      "loss": 0.0018,
      "step": 2530
    },
    {
      "epoch": 0.11288888888888889,
      "grad_norm": 0.7619451880455017,
      "learning_rate": 4.435555555555556e-05,
      "loss": 0.0022,
      "step": 2540
    },
    {
      "epoch": 0.11333333333333333,
      "grad_norm": 0.08436273038387299,
      "learning_rate": 4.433333333333334e-05,
      "loss": 0.0025,
      "step": 2550
    },
    {
      "epoch": 0.11377777777777778,
      "grad_norm": 0.24752874672412872,
      "learning_rate": 4.431111111111111e-05,
      "loss": 0.0021,
      "step": 2560
    },
    {
      "epoch": 0.11422222222222222,
      "grad_norm": 0.058953799307346344,
      "learning_rate": 4.428888888888889e-05,
      "loss": 0.0019,
      "step": 2570
    },
    {
      "epoch": 0.11466666666666667,
      "grad_norm": 0.33162492513656616,
      "learning_rate": 4.426666666666667e-05,
      "loss": 0.0022,
      "step": 2580
    },
    {
      "epoch": 0.11511111111111111,
      "grad_norm": 0.1000543162226677,
      "learning_rate": 4.424444444444444e-05,
      "loss": 0.0022,
      "step": 2590
    },
    {
      "epoch": 0.11555555555555555,
      "grad_norm": 0.20708002150058746,
      "learning_rate": 4.422222222222222e-05,
      "loss": 0.002,
      "step": 2600
    },
    {
      "epoch": 0.116,
      "grad_norm": 0.2341323047876358,
      "learning_rate": 4.4200000000000004e-05,
      "loss": 0.0024,
      "step": 2610
    },
    {
      "epoch": 0.11644444444444445,
      "grad_norm": 0.12421213090419769,
      "learning_rate": 4.417777777777778e-05,
      "loss": 0.0022,
      "step": 2620
    },
    {
      "epoch": 0.11688888888888889,
      "grad_norm": 0.8993995189666748,
      "learning_rate": 4.415555555555556e-05,
      "loss": 0.002,
      "step": 2630
    },
    {
      "epoch": 0.11733333333333333,
      "grad_norm": 0.441834956407547,
      "learning_rate": 4.413333333333334e-05,
      "loss": 0.0025,
      "step": 2640
    },
    {
      "epoch": 0.11777777777777777,
      "grad_norm": 0.028820952400565147,
      "learning_rate": 4.4111111111111114e-05,
      "loss": 0.0029,
      "step": 2650
    },
    {
      "epoch": 0.11822222222222223,
      "grad_norm": 0.6289480924606323,
      "learning_rate": 4.408888888888889e-05,
      "loss": 0.0025,
      "step": 2660
    },
    {
      "epoch": 0.11866666666666667,
      "grad_norm": 0.08378919214010239,
      "learning_rate": 4.406666666666667e-05,
      "loss": 0.002,
      "step": 2670
    },
    {
      "epoch": 0.11911111111111111,
      "grad_norm": 0.12985369563102722,
      "learning_rate": 4.404444444444445e-05,
      "loss": 0.0022,
      "step": 2680
    },
    {
      "epoch": 0.11955555555555555,
      "grad_norm": 0.2000781148672104,
      "learning_rate": 4.4022222222222225e-05,
      "loss": 0.002,
      "step": 2690
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.1397530734539032,
      "learning_rate": 4.4000000000000006e-05,
      "loss": 0.002,
      "step": 2700
    },
    {
      "epoch": 0.12044444444444445,
      "grad_norm": 0.41533297300338745,
      "learning_rate": 4.397777777777778e-05,
      "loss": 0.0023,
      "step": 2710
    },
    {
      "epoch": 0.12088888888888889,
      "grad_norm": 0.20924513041973114,
      "learning_rate": 4.3955555555555554e-05,
      "loss": 0.0024,
      "step": 2720
    },
    {
      "epoch": 0.12133333333333333,
      "grad_norm": 0.11173923313617706,
      "learning_rate": 4.3933333333333335e-05,
      "loss": 0.0021,
      "step": 2730
    },
    {
      "epoch": 0.12177777777777778,
      "grad_norm": 0.2146989405155182,
      "learning_rate": 4.3911111111111116e-05,
      "loss": 0.0022,
      "step": 2740
    },
    {
      "epoch": 0.12222222222222222,
      "grad_norm": 0.77150958776474,
      "learning_rate": 4.388888888888889e-05,
      "loss": 0.0021,
      "step": 2750
    },
    {
      "epoch": 0.12266666666666666,
      "grad_norm": 0.5249525904655457,
      "learning_rate": 4.3866666666666665e-05,
      "loss": 0.0021,
      "step": 2760
    },
    {
      "epoch": 0.12311111111111112,
      "grad_norm": 0.12544992566108704,
      "learning_rate": 4.384444444444445e-05,
      "loss": 0.0027,
      "step": 2770
    },
    {
      "epoch": 0.12355555555555556,
      "grad_norm": 0.08424215763807297,
      "learning_rate": 4.3822222222222227e-05,
      "loss": 0.002,
      "step": 2780
    },
    {
      "epoch": 0.124,
      "grad_norm": 0.2081090211868286,
      "learning_rate": 4.38e-05,
      "loss": 0.0019,
      "step": 2790
    },
    {
      "epoch": 0.12444444444444444,
      "grad_norm": 0.04449833184480667,
      "learning_rate": 4.377777777777778e-05,
      "loss": 0.002,
      "step": 2800
    },
    {
      "epoch": 0.12488888888888888,
      "grad_norm": 0.43092942237854004,
      "learning_rate": 4.3755555555555556e-05,
      "loss": 0.0024,
      "step": 2810
    },
    {
      "epoch": 0.12533333333333332,
      "grad_norm": 0.3582845628261566,
      "learning_rate": 4.373333333333334e-05,
      "loss": 0.0025,
      "step": 2820
    },
    {
      "epoch": 0.12577777777777777,
      "grad_norm": 0.06986290216445923,
      "learning_rate": 4.371111111111111e-05,
      "loss": 0.0018,
      "step": 2830
    },
    {
      "epoch": 0.12622222222222224,
      "grad_norm": 0.1660122126340866,
      "learning_rate": 4.368888888888889e-05,
      "loss": 0.0017,
      "step": 2840
    },
    {
      "epoch": 0.12666666666666668,
      "grad_norm": 0.09264983236789703,
      "learning_rate": 4.3666666666666666e-05,
      "loss": 0.0021,
      "step": 2850
    },
    {
      "epoch": 0.12711111111111112,
      "grad_norm": 0.08574316650629044,
      "learning_rate": 4.364444444444445e-05,
      "loss": 0.0021,
      "step": 2860
    },
    {
      "epoch": 0.12755555555555556,
      "grad_norm": 0.0836198478937149,
      "learning_rate": 4.362222222222223e-05,
      "loss": 0.0018,
      "step": 2870
    },
    {
      "epoch": 0.128,
      "grad_norm": 0.1111498773097992,
      "learning_rate": 4.36e-05,
      "loss": 0.0018,
      "step": 2880
    },
    {
      "epoch": 0.12844444444444444,
      "grad_norm": 0.25007641315460205,
      "learning_rate": 4.357777777777778e-05,
      "loss": 0.0016,
      "step": 2890
    },
    {
      "epoch": 0.1288888888888889,
      "grad_norm": 0.39060044288635254,
      "learning_rate": 4.355555555555556e-05,
      "loss": 0.0017,
      "step": 2900
    },
    {
      "epoch": 0.12933333333333333,
      "grad_norm": 0.5121284127235413,
      "learning_rate": 4.353333333333334e-05,
      "loss": 0.0024,
      "step": 2910
    },
    {
      "epoch": 0.12977777777777777,
      "grad_norm": 0.029594529420137405,
      "learning_rate": 4.351111111111111e-05,
      "loss": 0.0024,
      "step": 2920
    },
    {
      "epoch": 0.1302222222222222,
      "grad_norm": 0.2081836462020874,
      "learning_rate": 4.348888888888889e-05,
      "loss": 0.0018,
      "step": 2930
    },
    {
      "epoch": 0.13066666666666665,
      "grad_norm": 0.11029158532619476,
      "learning_rate": 4.346666666666667e-05,
      "loss": 0.0017,
      "step": 2940
    },
    {
      "epoch": 0.13111111111111112,
      "grad_norm": 0.4283592104911804,
      "learning_rate": 4.344444444444445e-05,
      "loss": 0.0017,
      "step": 2950
    },
    {
      "epoch": 0.13155555555555556,
      "grad_norm": 0.07568976283073425,
      "learning_rate": 4.3422222222222224e-05,
      "loss": 0.0021,
      "step": 2960
    },
    {
      "epoch": 0.132,
      "grad_norm": 0.07436490803956985,
      "learning_rate": 4.3400000000000005e-05,
      "loss": 0.002,
      "step": 2970
    },
    {
      "epoch": 0.13244444444444445,
      "grad_norm": 0.2784481644630432,
      "learning_rate": 4.337777777777778e-05,
      "loss": 0.0022,
      "step": 2980
    },
    {
      "epoch": 0.1328888888888889,
      "grad_norm": 0.024786263704299927,
      "learning_rate": 4.335555555555556e-05,
      "loss": 0.0022,
      "step": 2990
    },
    {
      "epoch": 0.13333333333333333,
      "grad_norm": 0.34721657633781433,
      "learning_rate": 4.3333333333333334e-05,
      "loss": 0.0019,
      "step": 3000
    },
    {
      "epoch": 0.13377777777777777,
      "grad_norm": 0.2095731794834137,
      "learning_rate": 4.3311111111111115e-05,
      "loss": 0.0021,
      "step": 3010
    },
    {
      "epoch": 0.13422222222222221,
      "grad_norm": 0.20673207938671112,
      "learning_rate": 4.328888888888889e-05,
      "loss": 0.0017,
      "step": 3020
    },
    {
      "epoch": 0.13466666666666666,
      "grad_norm": 0.238581582903862,
      "learning_rate": 4.3266666666666664e-05,
      "loss": 0.0022,
      "step": 3030
    },
    {
      "epoch": 0.1351111111111111,
      "grad_norm": 0.44283804297447205,
      "learning_rate": 4.324444444444445e-05,
      "loss": 0.0019,
      "step": 3040
    },
    {
      "epoch": 0.13555555555555557,
      "grad_norm": 0.375774085521698,
      "learning_rate": 4.3222222222222226e-05,
      "loss": 0.0019,
      "step": 3050
    },
    {
      "epoch": 0.136,
      "grad_norm": 0.3769705295562744,
      "learning_rate": 4.32e-05,
      "loss": 0.0019,
      "step": 3060
    },
    {
      "epoch": 0.13644444444444445,
      "grad_norm": 0.021421439945697784,
      "learning_rate": 4.317777777777778e-05,
      "loss": 0.0034,
      "step": 3070
    },
    {
      "epoch": 0.1368888888888889,
      "grad_norm": 0.4086611568927765,
      "learning_rate": 4.315555555555556e-05,
      "loss": 0.0023,
      "step": 3080
    },
    {
      "epoch": 0.13733333333333334,
      "grad_norm": 0.11166650056838989,
      "learning_rate": 4.3133333333333336e-05,
      "loss": 0.0017,
      "step": 3090
    },
    {
      "epoch": 0.13777777777777778,
      "grad_norm": 0.20787762105464935,
      "learning_rate": 4.311111111111111e-05,
      "loss": 0.0021,
      "step": 3100
    },
    {
      "epoch": 0.13822222222222222,
      "grad_norm": 0.13938140869140625,
      "learning_rate": 4.308888888888889e-05,
      "loss": 0.0021,
      "step": 3110
    },
    {
      "epoch": 0.13866666666666666,
      "grad_norm": 0.27874040603637695,
      "learning_rate": 4.3066666666666665e-05,
      "loss": 0.0017,
      "step": 3120
    },
    {
      "epoch": 0.1391111111111111,
      "grad_norm": 0.08665753901004791,
      "learning_rate": 4.3044444444444446e-05,
      "loss": 0.0021,
      "step": 3130
    },
    {
      "epoch": 0.13955555555555554,
      "grad_norm": 0.08836934715509415,
      "learning_rate": 4.302222222222223e-05,
      "loss": 0.0019,
      "step": 3140
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.058239810168743134,
      "learning_rate": 4.3e-05,
      "loss": 0.0018,
      "step": 3150
    },
    {
      "epoch": 0.14044444444444446,
      "grad_norm": 0.04416922852396965,
      "learning_rate": 4.2977777777777776e-05,
      "loss": 0.0018,
      "step": 3160
    },
    {
      "epoch": 0.1408888888888889,
      "grad_norm": 0.3585168123245239,
      "learning_rate": 4.295555555555556e-05,
      "loss": 0.002,
      "step": 3170
    },
    {
      "epoch": 0.14133333333333334,
      "grad_norm": 0.20814299583435059,
      "learning_rate": 4.293333333333334e-05,
      "loss": 0.002,
      "step": 3180
    },
    {
      "epoch": 0.14177777777777778,
      "grad_norm": 0.059099581092596054,
      "learning_rate": 4.291111111111111e-05,
      "loss": 0.0016,
      "step": 3190
    },
    {
      "epoch": 0.14222222222222222,
      "grad_norm": 0.12448707222938538,
      "learning_rate": 4.2888888888888886e-05,
      "loss": 0.0022,
      "step": 3200
    },
    {
      "epoch": 0.14266666666666666,
      "grad_norm": 0.23532521724700928,
      "learning_rate": 4.286666666666667e-05,
      "loss": 0.0022,
      "step": 3210
    },
    {
      "epoch": 0.1431111111111111,
      "grad_norm": 0.42996636033058167,
      "learning_rate": 4.284444444444445e-05,
      "loss": 0.0019,
      "step": 3220
    },
    {
      "epoch": 0.14355555555555555,
      "grad_norm": 0.4419437646865845,
      "learning_rate": 4.282222222222222e-05,
      "loss": 0.0021,
      "step": 3230
    },
    {
      "epoch": 0.144,
      "grad_norm": 0.09746408462524414,
      "learning_rate": 4.2800000000000004e-05,
      "loss": 0.0019,
      "step": 3240
    },
    {
      "epoch": 0.14444444444444443,
      "grad_norm": 0.23974157869815826,
      "learning_rate": 4.277777777777778e-05,
      "loss": 0.0019,
      "step": 3250
    },
    {
      "epoch": 0.1448888888888889,
      "grad_norm": 0.3609989583492279,
      "learning_rate": 4.275555555555556e-05,
      "loss": 0.0024,
      "step": 3260
    },
    {
      "epoch": 0.14533333333333334,
      "grad_norm": 0.1661677211523056,
      "learning_rate": 4.273333333333333e-05,
      "loss": 0.0027,
      "step": 3270
    },
    {
      "epoch": 0.14577777777777778,
      "grad_norm": 0.5928176641464233,
      "learning_rate": 4.2711111111111114e-05,
      "loss": 0.0016,
      "step": 3280
    },
    {
      "epoch": 0.14622222222222223,
      "grad_norm": 0.6493937969207764,
      "learning_rate": 4.268888888888889e-05,
      "loss": 0.0026,
      "step": 3290
    },
    {
      "epoch": 0.14666666666666667,
      "grad_norm": 0.6793121099472046,
      "learning_rate": 4.266666666666667e-05,
      "loss": 0.0027,
      "step": 3300
    },
    {
      "epoch": 0.1471111111111111,
      "grad_norm": 0.08756782114505768,
      "learning_rate": 4.264444444444445e-05,
      "loss": 0.0026,
      "step": 3310
    },
    {
      "epoch": 0.14755555555555555,
      "grad_norm": 0.01812569610774517,
      "learning_rate": 4.2622222222222224e-05,
      "loss": 0.0021,
      "step": 3320
    },
    {
      "epoch": 0.148,
      "grad_norm": 0.03342701494693756,
      "learning_rate": 4.26e-05,
      "loss": 0.0021,
      "step": 3330
    },
    {
      "epoch": 0.14844444444444443,
      "grad_norm": 0.15312327444553375,
      "learning_rate": 4.257777777777778e-05,
      "loss": 0.0018,
      "step": 3340
    },
    {
      "epoch": 0.14888888888888888,
      "grad_norm": 0.2226436287164688,
      "learning_rate": 4.255555555555556e-05,
      "loss": 0.002,
      "step": 3350
    },
    {
      "epoch": 0.14933333333333335,
      "grad_norm": 0.0457097589969635,
      "learning_rate": 4.2533333333333335e-05,
      "loss": 0.0023,
      "step": 3360
    },
    {
      "epoch": 0.1497777777777778,
      "grad_norm": 0.05726701766252518,
      "learning_rate": 4.2511111111111116e-05,
      "loss": 0.0017,
      "step": 3370
    },
    {
      "epoch": 0.15022222222222223,
      "grad_norm": 0.3315929174423218,
      "learning_rate": 4.248888888888889e-05,
      "loss": 0.0021,
      "step": 3380
    },
    {
      "epoch": 0.15066666666666667,
      "grad_norm": 0.11092725396156311,
      "learning_rate": 4.246666666666667e-05,
      "loss": 0.0022,
      "step": 3390
    },
    {
      "epoch": 0.1511111111111111,
      "grad_norm": 0.13924407958984375,
      "learning_rate": 4.2444444444444445e-05,
      "loss": 0.0022,
      "step": 3400
    },
    {
      "epoch": 0.15155555555555555,
      "grad_norm": 0.4513130187988281,
      "learning_rate": 4.2422222222222226e-05,
      "loss": 0.0029,
      "step": 3410
    },
    {
      "epoch": 0.152,
      "grad_norm": 0.3165263831615448,
      "learning_rate": 4.24e-05,
      "loss": 0.0023,
      "step": 3420
    },
    {
      "epoch": 0.15244444444444444,
      "grad_norm": 0.2916223108768463,
      "learning_rate": 4.2377777777777775e-05,
      "loss": 0.0019,
      "step": 3430
    },
    {
      "epoch": 0.15288888888888888,
      "grad_norm": 0.28958457708358765,
      "learning_rate": 4.235555555555556e-05,
      "loss": 0.0019,
      "step": 3440
    },
    {
      "epoch": 0.15333333333333332,
      "grad_norm": 0.19446198642253876,
      "learning_rate": 4.233333333333334e-05,
      "loss": 0.0016,
      "step": 3450
    },
    {
      "epoch": 0.1537777777777778,
      "grad_norm": 0.043017905205488205,
      "learning_rate": 4.231111111111111e-05,
      "loss": 0.002,
      "step": 3460
    },
    {
      "epoch": 0.15422222222222223,
      "grad_norm": 0.19366370141506195,
      "learning_rate": 4.228888888888889e-05,
      "loss": 0.0026,
      "step": 3470
    },
    {
      "epoch": 0.15466666666666667,
      "grad_norm": 0.5658806562423706,
      "learning_rate": 4.226666666666667e-05,
      "loss": 0.0027,
      "step": 3480
    },
    {
      "epoch": 0.15511111111111112,
      "grad_norm": 0.22161965072155,
      "learning_rate": 4.224444444444445e-05,
      "loss": 0.0026,
      "step": 3490
    },
    {
      "epoch": 0.15555555555555556,
      "grad_norm": 0.07308504730463028,
      "learning_rate": 4.222222222222222e-05,
      "loss": 0.0022,
      "step": 3500
    },
    {
      "epoch": 0.156,
      "grad_norm": 0.12564510107040405,
      "learning_rate": 4.22e-05,
      "loss": 0.002,
      "step": 3510
    },
    {
      "epoch": 0.15644444444444444,
      "grad_norm": 0.0567864291369915,
      "learning_rate": 4.217777777777778e-05,
      "loss": 0.0021,
      "step": 3520
    },
    {
      "epoch": 0.15688888888888888,
      "grad_norm": 0.3175002634525299,
      "learning_rate": 4.215555555555556e-05,
      "loss": 0.0018,
      "step": 3530
    },
    {
      "epoch": 0.15733333333333333,
      "grad_norm": 0.19465602934360504,
      "learning_rate": 4.213333333333334e-05,
      "loss": 0.0018,
      "step": 3540
    },
    {
      "epoch": 0.15777777777777777,
      "grad_norm": 0.056500691920518875,
      "learning_rate": 4.211111111111111e-05,
      "loss": 0.0018,
      "step": 3550
    },
    {
      "epoch": 0.1582222222222222,
      "grad_norm": 0.020558327436447144,
      "learning_rate": 4.208888888888889e-05,
      "loss": 0.0023,
      "step": 3560
    },
    {
      "epoch": 0.15866666666666668,
      "grad_norm": 0.19270393252372742,
      "learning_rate": 4.206666666666667e-05,
      "loss": 0.0018,
      "step": 3570
    },
    {
      "epoch": 0.15911111111111112,
      "grad_norm": 0.6067614555358887,
      "learning_rate": 4.204444444444445e-05,
      "loss": 0.0019,
      "step": 3580
    },
    {
      "epoch": 0.15955555555555556,
      "grad_norm": 0.5248732566833496,
      "learning_rate": 4.2022222222222223e-05,
      "loss": 0.0023,
      "step": 3590
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.16845789551734924,
      "learning_rate": 4.2e-05,
      "loss": 0.0022,
      "step": 3600
    },
    {
      "epoch": 0.16044444444444445,
      "grad_norm": 0.2484409511089325,
      "learning_rate": 4.1977777777777785e-05,
      "loss": 0.0016,
      "step": 3610
    },
    {
      "epoch": 0.1608888888888889,
      "grad_norm": 0.20802102982997894,
      "learning_rate": 4.195555555555556e-05,
      "loss": 0.002,
      "step": 3620
    },
    {
      "epoch": 0.16133333333333333,
      "grad_norm": 0.13764578104019165,
      "learning_rate": 4.1933333333333334e-05,
      "loss": 0.0017,
      "step": 3630
    },
    {
      "epoch": 0.16177777777777777,
      "grad_norm": 0.6197206974029541,
      "learning_rate": 4.1911111111111115e-05,
      "loss": 0.0018,
      "step": 3640
    },
    {
      "epoch": 0.1622222222222222,
      "grad_norm": 0.19563014805316925,
      "learning_rate": 4.188888888888889e-05,
      "loss": 0.002,
      "step": 3650
    },
    {
      "epoch": 0.16266666666666665,
      "grad_norm": 0.19440858066082,
      "learning_rate": 4.186666666666667e-05,
      "loss": 0.0018,
      "step": 3660
    },
    {
      "epoch": 0.16311111111111112,
      "grad_norm": 0.05974603816866875,
      "learning_rate": 4.1844444444444444e-05,
      "loss": 0.0018,
      "step": 3670
    },
    {
      "epoch": 0.16355555555555557,
      "grad_norm": 0.139860600233078,
      "learning_rate": 4.1822222222222225e-05,
      "loss": 0.002,
      "step": 3680
    },
    {
      "epoch": 0.164,
      "grad_norm": 0.3866492807865143,
      "learning_rate": 4.18e-05,
      "loss": 0.002,
      "step": 3690
    },
    {
      "epoch": 0.16444444444444445,
      "grad_norm": 0.18000590801239014,
      "learning_rate": 4.177777777777778e-05,
      "loss": 0.0017,
      "step": 3700
    },
    {
      "epoch": 0.1648888888888889,
      "grad_norm": 0.16691556572914124,
      "learning_rate": 4.175555555555556e-05,
      "loss": 0.0017,
      "step": 3710
    },
    {
      "epoch": 0.16533333333333333,
      "grad_norm": 0.111509770154953,
      "learning_rate": 4.1733333333333336e-05,
      "loss": 0.002,
      "step": 3720
    },
    {
      "epoch": 0.16577777777777777,
      "grad_norm": 0.6211227178573608,
      "learning_rate": 4.171111111111111e-05,
      "loss": 0.0022,
      "step": 3730
    },
    {
      "epoch": 0.16622222222222222,
      "grad_norm": 0.5509219765663147,
      "learning_rate": 4.168888888888889e-05,
      "loss": 0.0021,
      "step": 3740
    },
    {
      "epoch": 0.16666666666666666,
      "grad_norm": 0.3889717161655426,
      "learning_rate": 4.166666666666667e-05,
      "loss": 0.002,
      "step": 3750
    },
    {
      "epoch": 0.1671111111111111,
      "grad_norm": 0.5651034116744995,
      "learning_rate": 4.1644444444444446e-05,
      "loss": 0.002,
      "step": 3760
    },
    {
      "epoch": 0.16755555555555557,
      "grad_norm": 0.07186325639486313,
      "learning_rate": 4.162222222222222e-05,
      "loss": 0.0019,
      "step": 3770
    },
    {
      "epoch": 0.168,
      "grad_norm": 0.2646724581718445,
      "learning_rate": 4.16e-05,
      "loss": 0.0025,
      "step": 3780
    },
    {
      "epoch": 0.16844444444444445,
      "grad_norm": 0.026946203783154488,
      "learning_rate": 4.157777777777778e-05,
      "loss": 0.0021,
      "step": 3790
    },
    {
      "epoch": 0.1688888888888889,
      "grad_norm": 0.15183983743190765,
      "learning_rate": 4.155555555555556e-05,
      "loss": 0.0019,
      "step": 3800
    },
    {
      "epoch": 0.16933333333333334,
      "grad_norm": 0.7061581611633301,
      "learning_rate": 4.153333333333334e-05,
      "loss": 0.0024,
      "step": 3810
    },
    {
      "epoch": 0.16977777777777778,
      "grad_norm": 0.05691974610090256,
      "learning_rate": 4.151111111111111e-05,
      "loss": 0.0024,
      "step": 3820
    },
    {
      "epoch": 0.17022222222222222,
      "grad_norm": 0.20730414986610413,
      "learning_rate": 4.1488888888888886e-05,
      "loss": 0.0021,
      "step": 3830
    },
    {
      "epoch": 0.17066666666666666,
      "grad_norm": 0.04456686973571777,
      "learning_rate": 4.146666666666667e-05,
      "loss": 0.0021,
      "step": 3840
    },
    {
      "epoch": 0.1711111111111111,
      "grad_norm": 0.06156852841377258,
      "learning_rate": 4.144444444444445e-05,
      "loss": 0.0017,
      "step": 3850
    },
    {
      "epoch": 0.17155555555555554,
      "grad_norm": 0.05775696411728859,
      "learning_rate": 4.142222222222222e-05,
      "loss": 0.0019,
      "step": 3860
    },
    {
      "epoch": 0.172,
      "grad_norm": 0.3073769807815552,
      "learning_rate": 4.14e-05,
      "loss": 0.0018,
      "step": 3870
    },
    {
      "epoch": 0.17244444444444446,
      "grad_norm": 0.08370716869831085,
      "learning_rate": 4.1377777777777784e-05,
      "loss": 0.002,
      "step": 3880
    },
    {
      "epoch": 0.1728888888888889,
      "grad_norm": 0.04393182694911957,
      "learning_rate": 4.135555555555556e-05,
      "loss": 0.002,
      "step": 3890
    },
    {
      "epoch": 0.17333333333333334,
      "grad_norm": 0.08394238352775574,
      "learning_rate": 4.133333333333333e-05,
      "loss": 0.0018,
      "step": 3900
    },
    {
      "epoch": 0.17377777777777778,
      "grad_norm": 0.40014001727104187,
      "learning_rate": 4.1311111111111114e-05,
      "loss": 0.0019,
      "step": 3910
    },
    {
      "epoch": 0.17422222222222222,
      "grad_norm": 0.08653894811868668,
      "learning_rate": 4.1288888888888895e-05,
      "loss": 0.0021,
      "step": 3920
    },
    {
      "epoch": 0.17466666666666666,
      "grad_norm": 0.38533514738082886,
      "learning_rate": 4.126666666666667e-05,
      "loss": 0.0016,
      "step": 3930
    },
    {
      "epoch": 0.1751111111111111,
      "grad_norm": 0.16681374609470367,
      "learning_rate": 4.124444444444444e-05,
      "loss": 0.0017,
      "step": 3940
    },
    {
      "epoch": 0.17555555555555555,
      "grad_norm": 0.11271167546510696,
      "learning_rate": 4.1222222222222224e-05,
      "loss": 0.0023,
      "step": 3950
    },
    {
      "epoch": 0.176,
      "grad_norm": 0.13946190476417542,
      "learning_rate": 4.12e-05,
      "loss": 0.0016,
      "step": 3960
    },
    {
      "epoch": 0.17644444444444443,
      "grad_norm": 0.6913478970527649,
      "learning_rate": 4.117777777777778e-05,
      "loss": 0.002,
      "step": 3970
    },
    {
      "epoch": 0.1768888888888889,
      "grad_norm": 0.07136993110179901,
      "learning_rate": 4.115555555555556e-05,
      "loss": 0.0019,
      "step": 3980
    },
    {
      "epoch": 0.17733333333333334,
      "grad_norm": 0.4286482036113739,
      "learning_rate": 4.1133333333333335e-05,
      "loss": 0.0019,
      "step": 3990
    },
    {
      "epoch": 0.17777777777777778,
      "grad_norm": 0.4150605797767639,
      "learning_rate": 4.111111111111111e-05,
      "loss": 0.002,
      "step": 4000
    },
    {
      "epoch": 0.17822222222222223,
      "grad_norm": 0.19584397971630096,
      "learning_rate": 4.10888888888889e-05,
      "loss": 0.0027,
      "step": 4010
    },
    {
      "epoch": 0.17866666666666667,
      "grad_norm": 0.20803965628147125,
      "learning_rate": 4.106666666666667e-05,
      "loss": 0.0018,
      "step": 4020
    },
    {
      "epoch": 0.1791111111111111,
      "grad_norm": 0.03152536600828171,
      "learning_rate": 4.1044444444444445e-05,
      "loss": 0.002,
      "step": 4030
    },
    {
      "epoch": 0.17955555555555555,
      "grad_norm": 0.34616410732269287,
      "learning_rate": 4.1022222222222226e-05,
      "loss": 0.003,
      "step": 4040
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.6060037016868591,
      "learning_rate": 4.1e-05,
      "loss": 0.0017,
      "step": 4050
    },
    {
      "epoch": 0.18044444444444444,
      "grad_norm": 0.04290444403886795,
      "learning_rate": 4.097777777777778e-05,
      "loss": 0.0023,
      "step": 4060
    },
    {
      "epoch": 0.18088888888888888,
      "grad_norm": 0.043326687067747116,
      "learning_rate": 4.0955555555555556e-05,
      "loss": 0.0021,
      "step": 4070
    },
    {
      "epoch": 0.18133333333333335,
      "grad_norm": 0.5791558027267456,
      "learning_rate": 4.093333333333334e-05,
      "loss": 0.0019,
      "step": 4080
    },
    {
      "epoch": 0.1817777777777778,
      "grad_norm": 0.0450969859957695,
      "learning_rate": 4.091111111111111e-05,
      "loss": 0.0018,
      "step": 4090
    },
    {
      "epoch": 0.18222222222222223,
      "grad_norm": 0.26225075125694275,
      "learning_rate": 4.088888888888889e-05,
      "loss": 0.0018,
      "step": 4100
    },
    {
      "epoch": 0.18266666666666667,
      "grad_norm": 0.23509643971920013,
      "learning_rate": 4.086666666666667e-05,
      "loss": 0.0018,
      "step": 4110
    },
    {
      "epoch": 0.1831111111111111,
      "grad_norm": 0.607128918170929,
      "learning_rate": 4.084444444444445e-05,
      "loss": 0.0023,
      "step": 4120
    },
    {
      "epoch": 0.18355555555555556,
      "grad_norm": 0.08350589871406555,
      "learning_rate": 4.082222222222222e-05,
      "loss": 0.0018,
      "step": 4130
    },
    {
      "epoch": 0.184,
      "grad_norm": 0.6615681648254395,
      "learning_rate": 4.08e-05,
      "loss": 0.002,
      "step": 4140
    },
    {
      "epoch": 0.18444444444444444,
      "grad_norm": 0.20661045610904694,
      "learning_rate": 4.0777777777777783e-05,
      "loss": 0.0025,
      "step": 4150
    },
    {
      "epoch": 0.18488888888888888,
      "grad_norm": 0.5263738632202148,
      "learning_rate": 4.075555555555556e-05,
      "loss": 0.002,
      "step": 4160
    },
    {
      "epoch": 0.18533333333333332,
      "grad_norm": 0.26167598366737366,
      "learning_rate": 4.073333333333333e-05,
      "loss": 0.0023,
      "step": 4170
    },
    {
      "epoch": 0.18577777777777776,
      "grad_norm": 0.11225441098213196,
      "learning_rate": 4.071111111111111e-05,
      "loss": 0.0019,
      "step": 4180
    },
    {
      "epoch": 0.18622222222222223,
      "grad_norm": 0.20773789286613464,
      "learning_rate": 4.0688888888888894e-05,
      "loss": 0.0023,
      "step": 4190
    },
    {
      "epoch": 0.18666666666666668,
      "grad_norm": 0.4542434513568878,
      "learning_rate": 4.066666666666667e-05,
      "loss": 0.0017,
      "step": 4200
    },
    {
      "epoch": 0.18711111111111112,
      "grad_norm": 0.2083010971546173,
      "learning_rate": 4.064444444444445e-05,
      "loss": 0.0023,
      "step": 4210
    },
    {
      "epoch": 0.18755555555555556,
      "grad_norm": 0.10357444733381271,
      "learning_rate": 4.062222222222222e-05,
      "loss": 0.0025,
      "step": 4220
    },
    {
      "epoch": 0.188,
      "grad_norm": 0.051140639930963516,
      "learning_rate": 4.0600000000000004e-05,
      "loss": 0.0025,
      "step": 4230
    },
    {
      "epoch": 0.18844444444444444,
      "grad_norm": 0.8135650157928467,
      "learning_rate": 4.057777777777778e-05,
      "loss": 0.0019,
      "step": 4240
    },
    {
      "epoch": 0.18888888888888888,
      "grad_norm": 0.2082161009311676,
      "learning_rate": 4.055555555555556e-05,
      "loss": 0.0016,
      "step": 4250
    },
    {
      "epoch": 0.18933333333333333,
      "grad_norm": 0.0985231101512909,
      "learning_rate": 4.0533333333333334e-05,
      "loss": 0.002,
      "step": 4260
    },
    {
      "epoch": 0.18977777777777777,
      "grad_norm": 0.3053840398788452,
      "learning_rate": 4.051111111111111e-05,
      "loss": 0.0022,
      "step": 4270
    },
    {
      "epoch": 0.1902222222222222,
      "grad_norm": 0.019506733864545822,
      "learning_rate": 4.0488888888888896e-05,
      "loss": 0.0016,
      "step": 4280
    },
    {
      "epoch": 0.19066666666666668,
      "grad_norm": 0.6734967231750488,
      "learning_rate": 4.046666666666667e-05,
      "loss": 0.0022,
      "step": 4290
    },
    {
      "epoch": 0.19111111111111112,
      "grad_norm": 0.41242656111717224,
      "learning_rate": 4.0444444444444444e-05,
      "loss": 0.0024,
      "step": 4300
    },
    {
      "epoch": 0.19155555555555556,
      "grad_norm": 0.31753236055374146,
      "learning_rate": 4.0422222222222225e-05,
      "loss": 0.0018,
      "step": 4310
    },
    {
      "epoch": 0.192,
      "grad_norm": 0.11249897629022598,
      "learning_rate": 4.0400000000000006e-05,
      "loss": 0.0024,
      "step": 4320
    },
    {
      "epoch": 0.19244444444444445,
      "grad_norm": 0.2813621163368225,
      "learning_rate": 4.037777777777778e-05,
      "loss": 0.0028,
      "step": 4330
    },
    {
      "epoch": 0.1928888888888889,
      "grad_norm": 0.6881612539291382,
      "learning_rate": 4.0355555555555555e-05,
      "loss": 0.0028,
      "step": 4340
    },
    {
      "epoch": 0.19333333333333333,
      "grad_norm": 0.5538229942321777,
      "learning_rate": 4.0333333333333336e-05,
      "loss": 0.0025,
      "step": 4350
    },
    {
      "epoch": 0.19377777777777777,
      "grad_norm": 0.5235005021095276,
      "learning_rate": 4.031111111111111e-05,
      "loss": 0.0021,
      "step": 4360
    },
    {
      "epoch": 0.1942222222222222,
      "grad_norm": 0.46841683983802795,
      "learning_rate": 4.028888888888889e-05,
      "loss": 0.0024,
      "step": 4370
    },
    {
      "epoch": 0.19466666666666665,
      "grad_norm": 0.06946713477373123,
      "learning_rate": 4.026666666666667e-05,
      "loss": 0.0019,
      "step": 4380
    },
    {
      "epoch": 0.19511111111111112,
      "grad_norm": 0.4826357066631317,
      "learning_rate": 4.0244444444444446e-05,
      "loss": 0.0016,
      "step": 4390
    },
    {
      "epoch": 0.19555555555555557,
      "grad_norm": 0.3469691872596741,
      "learning_rate": 4.022222222222222e-05,
      "loss": 0.0022,
      "step": 4400
    },
    {
      "epoch": 0.196,
      "grad_norm": 0.05645906180143356,
      "learning_rate": 4.02e-05,
      "loss": 0.0017,
      "step": 4410
    },
    {
      "epoch": 0.19644444444444445,
      "grad_norm": 0.16671118140220642,
      "learning_rate": 4.017777777777778e-05,
      "loss": 0.0017,
      "step": 4420
    },
    {
      "epoch": 0.1968888888888889,
      "grad_norm": 0.4704623520374298,
      "learning_rate": 4.0155555555555557e-05,
      "loss": 0.0018,
      "step": 4430
    },
    {
      "epoch": 0.19733333333333333,
      "grad_norm": 0.10660705715417862,
      "learning_rate": 4.013333333333333e-05,
      "loss": 0.0022,
      "step": 4440
    },
    {
      "epoch": 0.19777777777777777,
      "grad_norm": 0.1933753937482834,
      "learning_rate": 4.011111111111111e-05,
      "loss": 0.002,
      "step": 4450
    },
    {
      "epoch": 0.19822222222222222,
      "grad_norm": 0.5502806305885315,
      "learning_rate": 4.008888888888889e-05,
      "loss": 0.0017,
      "step": 4460
    },
    {
      "epoch": 0.19866666666666666,
      "grad_norm": 0.4003710448741913,
      "learning_rate": 4.006666666666667e-05,
      "loss": 0.0019,
      "step": 4470
    },
    {
      "epoch": 0.1991111111111111,
      "grad_norm": 0.021006854251027107,
      "learning_rate": 4.004444444444445e-05,
      "loss": 0.0021,
      "step": 4480
    },
    {
      "epoch": 0.19955555555555557,
      "grad_norm": 0.13932617008686066,
      "learning_rate": 4.002222222222222e-05,
      "loss": 0.0018,
      "step": 4490
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.08461910486221313,
      "learning_rate": 4e-05,
      "loss": 0.0026,
      "step": 4500
    },
    {
      "epoch": 0.20044444444444445,
      "grad_norm": 0.3030877411365509,
      "learning_rate": 3.997777777777778e-05,
      "loss": 0.0017,
      "step": 4510
    },
    {
      "epoch": 0.2008888888888889,
      "grad_norm": 0.1520511507987976,
      "learning_rate": 3.995555555555556e-05,
      "loss": 0.0018,
      "step": 4520
    },
    {
      "epoch": 0.20133333333333334,
      "grad_norm": 0.043954718858003616,
      "learning_rate": 3.993333333333333e-05,
      "loss": 0.002,
      "step": 4530
    },
    {
      "epoch": 0.20177777777777778,
      "grad_norm": 0.033673372119665146,
      "learning_rate": 3.9911111111111114e-05,
      "loss": 0.0025,
      "step": 4540
    },
    {
      "epoch": 0.20222222222222222,
      "grad_norm": 0.27478697896003723,
      "learning_rate": 3.9888888888888895e-05,
      "loss": 0.002,
      "step": 4550
    },
    {
      "epoch": 0.20266666666666666,
      "grad_norm": 0.32992470264434814,
      "learning_rate": 3.986666666666667e-05,
      "loss": 0.0022,
      "step": 4560
    },
    {
      "epoch": 0.2031111111111111,
      "grad_norm": 0.027986453846096992,
      "learning_rate": 3.984444444444444e-05,
      "loss": 0.002,
      "step": 4570
    },
    {
      "epoch": 0.20355555555555555,
      "grad_norm": 0.783871591091156,
      "learning_rate": 3.9822222222222224e-05,
      "loss": 0.0033,
      "step": 4580
    },
    {
      "epoch": 0.204,
      "grad_norm": 0.059789761900901794,
      "learning_rate": 3.9800000000000005e-05,
      "loss": 0.0017,
      "step": 4590
    },
    {
      "epoch": 0.20444444444444446,
      "grad_norm": 0.15148712694644928,
      "learning_rate": 3.977777777777778e-05,
      "loss": 0.002,
      "step": 4600
    },
    {
      "epoch": 0.2048888888888889,
      "grad_norm": 0.12532077729701996,
      "learning_rate": 3.9755555555555554e-05,
      "loss": 0.0021,
      "step": 4610
    },
    {
      "epoch": 0.20533333333333334,
      "grad_norm": 0.41232073307037354,
      "learning_rate": 3.9733333333333335e-05,
      "loss": 0.0024,
      "step": 4620
    },
    {
      "epoch": 0.20577777777777778,
      "grad_norm": 0.12637971341609955,
      "learning_rate": 3.9711111111111116e-05,
      "loss": 0.0018,
      "step": 4630
    },
    {
      "epoch": 0.20622222222222222,
      "grad_norm": 0.04524652287364006,
      "learning_rate": 3.968888888888889e-05,
      "loss": 0.0022,
      "step": 4640
    },
    {
      "epoch": 0.20666666666666667,
      "grad_norm": 0.08493033796548843,
      "learning_rate": 3.966666666666667e-05,
      "loss": 0.0017,
      "step": 4650
    },
    {
      "epoch": 0.2071111111111111,
      "grad_norm": 0.1657615453004837,
      "learning_rate": 3.9644444444444445e-05,
      "loss": 0.0022,
      "step": 4660
    },
    {
      "epoch": 0.20755555555555555,
      "grad_norm": 0.19875548779964447,
      "learning_rate": 3.962222222222222e-05,
      "loss": 0.0019,
      "step": 4670
    },
    {
      "epoch": 0.208,
      "grad_norm": 0.361834317445755,
      "learning_rate": 3.960000000000001e-05,
      "loss": 0.0024,
      "step": 4680
    },
    {
      "epoch": 0.20844444444444443,
      "grad_norm": 0.03237514570355415,
      "learning_rate": 3.957777777777778e-05,
      "loss": 0.0023,
      "step": 4690
    },
    {
      "epoch": 0.2088888888888889,
      "grad_norm": 0.17980912327766418,
      "learning_rate": 3.9555555555555556e-05,
      "loss": 0.0022,
      "step": 4700
    },
    {
      "epoch": 0.20933333333333334,
      "grad_norm": 0.1703328937292099,
      "learning_rate": 3.9533333333333337e-05,
      "loss": 0.0024,
      "step": 4710
    },
    {
      "epoch": 0.20977777777777779,
      "grad_norm": 0.6357133984565735,
      "learning_rate": 3.951111111111112e-05,
      "loss": 0.0021,
      "step": 4720
    },
    {
      "epoch": 0.21022222222222223,
      "grad_norm": 0.07130835205316544,
      "learning_rate": 3.948888888888889e-05,
      "loss": 0.002,
      "step": 4730
    },
    {
      "epoch": 0.21066666666666667,
      "grad_norm": 0.49868160486221313,
      "learning_rate": 3.9466666666666666e-05,
      "loss": 0.0019,
      "step": 4740
    },
    {
      "epoch": 0.2111111111111111,
      "grad_norm": 0.747603178024292,
      "learning_rate": 3.944444444444445e-05,
      "loss": 0.002,
      "step": 4750
    },
    {
      "epoch": 0.21155555555555555,
      "grad_norm": 0.11207867413759232,
      "learning_rate": 3.942222222222222e-05,
      "loss": 0.002,
      "step": 4760
    },
    {
      "epoch": 0.212,
      "grad_norm": 0.07035902142524719,
      "learning_rate": 3.94e-05,
      "loss": 0.0025,
      "step": 4770
    },
    {
      "epoch": 0.21244444444444444,
      "grad_norm": 0.2928626239299774,
      "learning_rate": 3.937777777777778e-05,
      "loss": 0.0019,
      "step": 4780
    },
    {
      "epoch": 0.21288888888888888,
      "grad_norm": 0.20806312561035156,
      "learning_rate": 3.935555555555556e-05,
      "loss": 0.0019,
      "step": 4790
    },
    {
      "epoch": 0.21333333333333335,
      "grad_norm": 0.21040065586566925,
      "learning_rate": 3.933333333333333e-05,
      "loss": 0.0022,
      "step": 4800
    },
    {
      "epoch": 0.2137777777777778,
      "grad_norm": 0.09816794097423553,
      "learning_rate": 3.931111111111111e-05,
      "loss": 0.0022,
      "step": 4810
    },
    {
      "epoch": 0.21422222222222223,
      "grad_norm": 0.11095070093870163,
      "learning_rate": 3.9288888888888894e-05,
      "loss": 0.0017,
      "step": 4820
    },
    {
      "epoch": 0.21466666666666667,
      "grad_norm": 0.1532861292362213,
      "learning_rate": 3.926666666666667e-05,
      "loss": 0.0021,
      "step": 4830
    },
    {
      "epoch": 0.21511111111111111,
      "grad_norm": 0.7736828923225403,
      "learning_rate": 3.924444444444444e-05,
      "loss": 0.0022,
      "step": 4840
    },
    {
      "epoch": 0.21555555555555556,
      "grad_norm": 0.7598431706428528,
      "learning_rate": 3.922222222222223e-05,
      "loss": 0.0024,
      "step": 4850
    },
    {
      "epoch": 0.216,
      "grad_norm": 0.3728809356689453,
      "learning_rate": 3.9200000000000004e-05,
      "loss": 0.0017,
      "step": 4860
    },
    {
      "epoch": 0.21644444444444444,
      "grad_norm": 0.18143387138843536,
      "learning_rate": 3.917777777777778e-05,
      "loss": 0.0019,
      "step": 4870
    },
    {
      "epoch": 0.21688888888888888,
      "grad_norm": 0.23883599042892456,
      "learning_rate": 3.915555555555556e-05,
      "loss": 0.0022,
      "step": 4880
    },
    {
      "epoch": 0.21733333333333332,
      "grad_norm": 0.1494128406047821,
      "learning_rate": 3.9133333333333334e-05,
      "loss": 0.0028,
      "step": 4890
    },
    {
      "epoch": 0.21777777777777776,
      "grad_norm": 0.11266987770795822,
      "learning_rate": 3.9111111111111115e-05,
      "loss": 0.0018,
      "step": 4900
    },
    {
      "epoch": 0.21822222222222223,
      "grad_norm": 0.3996710181236267,
      "learning_rate": 3.908888888888889e-05,
      "loss": 0.0023,
      "step": 4910
    },
    {
      "epoch": 0.21866666666666668,
      "grad_norm": 0.19359268248081207,
      "learning_rate": 3.906666666666667e-05,
      "loss": 0.0017,
      "step": 4920
    },
    {
      "epoch": 0.21911111111111112,
      "grad_norm": 0.36563560366630554,
      "learning_rate": 3.9044444444444444e-05,
      "loss": 0.0019,
      "step": 4930
    },
    {
      "epoch": 0.21955555555555556,
      "grad_norm": 0.18159781396389008,
      "learning_rate": 3.9022222222222225e-05,
      "loss": 0.0023,
      "step": 4940
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.42930740118026733,
      "learning_rate": 3.9000000000000006e-05,
      "loss": 0.0026,
      "step": 4950
    },
    {
      "epoch": 0.22044444444444444,
      "grad_norm": 0.5659903287887573,
      "learning_rate": 3.897777777777778e-05,
      "loss": 0.0026,
      "step": 4960
    },
    {
      "epoch": 0.22088888888888888,
      "grad_norm": 0.5274110436439514,
      "learning_rate": 3.8955555555555555e-05,
      "loss": 0.0018,
      "step": 4970
    },
    {
      "epoch": 0.22133333333333333,
      "grad_norm": 0.11078985035419464,
      "learning_rate": 3.8933333333333336e-05,
      "loss": 0.0019,
      "step": 4980
    },
    {
      "epoch": 0.22177777777777777,
      "grad_norm": 0.4164082109928131,
      "learning_rate": 3.8911111111111117e-05,
      "loss": 0.0017,
      "step": 4990
    },
    {
      "epoch": 0.2222222222222222,
      "grad_norm": 0.1690087616443634,
      "learning_rate": 3.888888888888889e-05,
      "loss": 0.0024,
      "step": 5000
    },
    {
      "epoch": 0.22266666666666668,
      "grad_norm": 0.22470563650131226,
      "learning_rate": 3.8866666666666665e-05,
      "loss": 0.0022,
      "step": 5010
    },
    {
      "epoch": 0.22311111111111112,
      "grad_norm": 0.22151091694831848,
      "learning_rate": 3.8844444444444446e-05,
      "loss": 0.0019,
      "step": 5020
    },
    {
      "epoch": 0.22355555555555556,
      "grad_norm": 0.023526746779680252,
      "learning_rate": 3.882222222222223e-05,
      "loss": 0.0019,
      "step": 5030
    },
    {
      "epoch": 0.224,
      "grad_norm": 0.6385582685470581,
      "learning_rate": 3.88e-05,
      "loss": 0.0019,
      "step": 5040
    },
    {
      "epoch": 0.22444444444444445,
      "grad_norm": 0.47453150153160095,
      "learning_rate": 3.877777777777778e-05,
      "loss": 0.002,
      "step": 5050
    },
    {
      "epoch": 0.2248888888888889,
      "grad_norm": 0.47214120626449585,
      "learning_rate": 3.8755555555555556e-05,
      "loss": 0.002,
      "step": 5060
    },
    {
      "epoch": 0.22533333333333333,
      "grad_norm": 0.06347540766000748,
      "learning_rate": 3.873333333333333e-05,
      "loss": 0.0022,
      "step": 5070
    },
    {
      "epoch": 0.22577777777777777,
      "grad_norm": 0.16684266924858093,
      "learning_rate": 3.871111111111111e-05,
      "loss": 0.0021,
      "step": 5080
    },
    {
      "epoch": 0.2262222222222222,
      "grad_norm": 0.14127090573310852,
      "learning_rate": 3.868888888888889e-05,
      "loss": 0.0018,
      "step": 5090
    },
    {
      "epoch": 0.22666666666666666,
      "grad_norm": 0.31738361716270447,
      "learning_rate": 3.866666666666667e-05,
      "loss": 0.0022,
      "step": 5100
    },
    {
      "epoch": 0.22711111111111112,
      "grad_norm": 0.12736240029335022,
      "learning_rate": 3.864444444444444e-05,
      "loss": 0.0018,
      "step": 5110
    },
    {
      "epoch": 0.22755555555555557,
      "grad_norm": 0.31716054677963257,
      "learning_rate": 3.862222222222223e-05,
      "loss": 0.002,
      "step": 5120
    },
    {
      "epoch": 0.228,
      "grad_norm": 0.11126646399497986,
      "learning_rate": 3.86e-05,
      "loss": 0.0023,
      "step": 5130
    },
    {
      "epoch": 0.22844444444444445,
      "grad_norm": 0.021300744265317917,
      "learning_rate": 3.857777777777778e-05,
      "loss": 0.0019,
      "step": 5140
    },
    {
      "epoch": 0.2288888888888889,
      "grad_norm": 0.2503410577774048,
      "learning_rate": 3.855555555555556e-05,
      "loss": 0.0018,
      "step": 5150
    },
    {
      "epoch": 0.22933333333333333,
      "grad_norm": 0.484475702047348,
      "learning_rate": 3.853333333333334e-05,
      "loss": 0.002,
      "step": 5160
    },
    {
      "epoch": 0.22977777777777778,
      "grad_norm": 0.08413645625114441,
      "learning_rate": 3.8511111111111114e-05,
      "loss": 0.002,
      "step": 5170
    },
    {
      "epoch": 0.23022222222222222,
      "grad_norm": 0.03321876376867294,
      "learning_rate": 3.848888888888889e-05,
      "loss": 0.0022,
      "step": 5180
    },
    {
      "epoch": 0.23066666666666666,
      "grad_norm": 0.8272581100463867,
      "learning_rate": 3.846666666666667e-05,
      "loss": 0.0019,
      "step": 5190
    },
    {
      "epoch": 0.2311111111111111,
      "grad_norm": 0.2354329377412796,
      "learning_rate": 3.844444444444444e-05,
      "loss": 0.0021,
      "step": 5200
    },
    {
      "epoch": 0.23155555555555554,
      "grad_norm": 0.5101045370101929,
      "learning_rate": 3.8422222222222224e-05,
      "loss": 0.0017,
      "step": 5210
    },
    {
      "epoch": 0.232,
      "grad_norm": 0.7722319960594177,
      "learning_rate": 3.8400000000000005e-05,
      "loss": 0.0019,
      "step": 5220
    },
    {
      "epoch": 0.23244444444444445,
      "grad_norm": 0.2484774887561798,
      "learning_rate": 3.837777777777778e-05,
      "loss": 0.002,
      "step": 5230
    },
    {
      "epoch": 0.2328888888888889,
      "grad_norm": 0.02319236285984516,
      "learning_rate": 3.8355555555555553e-05,
      "loss": 0.0016,
      "step": 5240
    },
    {
      "epoch": 0.23333333333333334,
      "grad_norm": 0.024546144530177116,
      "learning_rate": 3.8333333333333334e-05,
      "loss": 0.0018,
      "step": 5250
    },
    {
      "epoch": 0.23377777777777778,
      "grad_norm": 0.03840582072734833,
      "learning_rate": 3.8311111111111115e-05,
      "loss": 0.0018,
      "step": 5260
    },
    {
      "epoch": 0.23422222222222222,
      "grad_norm": 0.5379554033279419,
      "learning_rate": 3.828888888888889e-05,
      "loss": 0.0023,
      "step": 5270
    },
    {
      "epoch": 0.23466666666666666,
      "grad_norm": 0.1828572154045105,
      "learning_rate": 3.8266666666666664e-05,
      "loss": 0.0017,
      "step": 5280
    },
    {
      "epoch": 0.2351111111111111,
      "grad_norm": 0.20658548176288605,
      "learning_rate": 3.8244444444444445e-05,
      "loss": 0.0017,
      "step": 5290
    },
    {
      "epoch": 0.23555555555555555,
      "grad_norm": 0.6205558180809021,
      "learning_rate": 3.8222222222222226e-05,
      "loss": 0.002,
      "step": 5300
    },
    {
      "epoch": 0.236,
      "grad_norm": 0.455110102891922,
      "learning_rate": 3.82e-05,
      "loss": 0.0026,
      "step": 5310
    },
    {
      "epoch": 0.23644444444444446,
      "grad_norm": 0.05951361730694771,
      "learning_rate": 3.817777777777778e-05,
      "loss": 0.002,
      "step": 5320
    },
    {
      "epoch": 0.2368888888888889,
      "grad_norm": 0.23515745997428894,
      "learning_rate": 3.8155555555555555e-05,
      "loss": 0.0017,
      "step": 5330
    },
    {
      "epoch": 0.23733333333333334,
      "grad_norm": 0.24877271056175232,
      "learning_rate": 3.8133333333333336e-05,
      "loss": 0.0014,
      "step": 5340
    },
    {
      "epoch": 0.23777777777777778,
      "grad_norm": 0.32944178581237793,
      "learning_rate": 3.811111111111112e-05,
      "loss": 0.0024,
      "step": 5350
    },
    {
      "epoch": 0.23822222222222222,
      "grad_norm": 0.09994370490312576,
      "learning_rate": 3.808888888888889e-05,
      "loss": 0.0022,
      "step": 5360
    },
    {
      "epoch": 0.23866666666666667,
      "grad_norm": 0.29397809505462646,
      "learning_rate": 3.8066666666666666e-05,
      "loss": 0.0023,
      "step": 5370
    },
    {
      "epoch": 0.2391111111111111,
      "grad_norm": 0.4847641587257385,
      "learning_rate": 3.804444444444445e-05,
      "loss": 0.0017,
      "step": 5380
    },
    {
      "epoch": 0.23955555555555555,
      "grad_norm": 0.1520884484052658,
      "learning_rate": 3.802222222222223e-05,
      "loss": 0.002,
      "step": 5390
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.5096917748451233,
      "learning_rate": 3.8e-05,
      "loss": 0.002,
      "step": 5400
    },
    {
      "epoch": 0.24044444444444443,
      "grad_norm": 0.40343615412712097,
      "learning_rate": 3.7977777777777776e-05,
      "loss": 0.0029,
      "step": 5410
    },
    {
      "epoch": 0.2408888888888889,
      "grad_norm": 0.07530353218317032,
      "learning_rate": 3.795555555555556e-05,
      "loss": 0.0019,
      "step": 5420
    },
    {
      "epoch": 0.24133333333333334,
      "grad_norm": 0.34463047981262207,
      "learning_rate": 3.793333333333334e-05,
      "loss": 0.002,
      "step": 5430
    },
    {
      "epoch": 0.24177777777777779,
      "grad_norm": 0.5645410418510437,
      "learning_rate": 3.791111111111111e-05,
      "loss": 0.0021,
      "step": 5440
    },
    {
      "epoch": 0.24222222222222223,
      "grad_norm": 0.7732968330383301,
      "learning_rate": 3.7888888888888894e-05,
      "loss": 0.0018,
      "step": 5450
    },
    {
      "epoch": 0.24266666666666667,
      "grad_norm": 0.2765975594520569,
      "learning_rate": 3.786666666666667e-05,
      "loss": 0.0026,
      "step": 5460
    },
    {
      "epoch": 0.2431111111111111,
      "grad_norm": 0.05744655057787895,
      "learning_rate": 3.784444444444445e-05,
      "loss": 0.0018,
      "step": 5470
    },
    {
      "epoch": 0.24355555555555555,
      "grad_norm": 0.31919074058532715,
      "learning_rate": 3.782222222222222e-05,
      "loss": 0.0022,
      "step": 5480
    },
    {
      "epoch": 0.244,
      "grad_norm": 0.41312628984451294,
      "learning_rate": 3.7800000000000004e-05,
      "loss": 0.0016,
      "step": 5490
    },
    {
      "epoch": 0.24444444444444444,
      "grad_norm": 0.04552057012915611,
      "learning_rate": 3.777777777777778e-05,
      "loss": 0.0021,
      "step": 5500
    },
    {
      "epoch": 0.24488888888888888,
      "grad_norm": 0.2486695498228073,
      "learning_rate": 3.775555555555555e-05,
      "loss": 0.002,
      "step": 5510
    },
    {
      "epoch": 0.24533333333333332,
      "grad_norm": 0.42733386158943176,
      "learning_rate": 3.773333333333334e-05,
      "loss": 0.0019,
      "step": 5520
    },
    {
      "epoch": 0.2457777777777778,
      "grad_norm": 0.5097174644470215,
      "learning_rate": 3.7711111111111114e-05,
      "loss": 0.0017,
      "step": 5530
    },
    {
      "epoch": 0.24622222222222223,
      "grad_norm": 0.7312104105949402,
      "learning_rate": 3.768888888888889e-05,
      "loss": 0.0019,
      "step": 5540
    },
    {
      "epoch": 0.24666666666666667,
      "grad_norm": 0.27616459131240845,
      "learning_rate": 3.766666666666667e-05,
      "loss": 0.002,
      "step": 5550
    },
    {
      "epoch": 0.24711111111111111,
      "grad_norm": 0.6087474226951599,
      "learning_rate": 3.764444444444445e-05,
      "loss": 0.0023,
      "step": 5560
    },
    {
      "epoch": 0.24755555555555556,
      "grad_norm": 0.2759532332420349,
      "learning_rate": 3.7622222222222225e-05,
      "loss": 0.0016,
      "step": 5570
    },
    {
      "epoch": 0.248,
      "grad_norm": 0.41342195868492126,
      "learning_rate": 3.76e-05,
      "loss": 0.0021,
      "step": 5580
    },
    {
      "epoch": 0.24844444444444444,
      "grad_norm": 0.4691220223903656,
      "learning_rate": 3.757777777777778e-05,
      "loss": 0.0017,
      "step": 5590
    },
    {
      "epoch": 0.24888888888888888,
      "grad_norm": 0.6486239433288574,
      "learning_rate": 3.7555555555555554e-05,
      "loss": 0.002,
      "step": 5600
    },
    {
      "epoch": 0.24933333333333332,
      "grad_norm": 0.605224072933197,
      "learning_rate": 3.7533333333333335e-05,
      "loss": 0.0023,
      "step": 5610
    },
    {
      "epoch": 0.24977777777777777,
      "grad_norm": 0.3729206323623657,
      "learning_rate": 3.7511111111111116e-05,
      "loss": 0.0019,
      "step": 5620
    },
    {
      "epoch": 0.25022222222222223,
      "grad_norm": 0.5094896554946899,
      "learning_rate": 3.748888888888889e-05,
      "loss": 0.0018,
      "step": 5630
    },
    {
      "epoch": 0.25066666666666665,
      "grad_norm": 0.5385710597038269,
      "learning_rate": 3.7466666666666665e-05,
      "loss": 0.0018,
      "step": 5640
    },
    {
      "epoch": 0.2511111111111111,
      "grad_norm": 0.10036768019199371,
      "learning_rate": 3.7444444444444446e-05,
      "loss": 0.0018,
      "step": 5650
    },
    {
      "epoch": 0.25155555555555553,
      "grad_norm": 0.36047637462615967,
      "learning_rate": 3.742222222222223e-05,
      "loss": 0.0022,
      "step": 5660
    },
    {
      "epoch": 0.252,
      "grad_norm": 0.5228933095932007,
      "learning_rate": 3.74e-05,
      "loss": 0.0017,
      "step": 5670
    },
    {
      "epoch": 0.25244444444444447,
      "grad_norm": 0.16707418859004974,
      "learning_rate": 3.7377777777777775e-05,
      "loss": 0.0024,
      "step": 5680
    },
    {
      "epoch": 0.2528888888888889,
      "grad_norm": 0.20705148577690125,
      "learning_rate": 3.7355555555555556e-05,
      "loss": 0.0028,
      "step": 5690
    },
    {
      "epoch": 0.25333333333333335,
      "grad_norm": 0.42774203419685364,
      "learning_rate": 3.733333333333334e-05,
      "loss": 0.0021,
      "step": 5700
    },
    {
      "epoch": 0.25377777777777777,
      "grad_norm": 0.04504503682255745,
      "learning_rate": 3.731111111111111e-05,
      "loss": 0.0024,
      "step": 5710
    },
    {
      "epoch": 0.25422222222222224,
      "grad_norm": 0.38793739676475525,
      "learning_rate": 3.728888888888889e-05,
      "loss": 0.0022,
      "step": 5720
    },
    {
      "epoch": 0.25466666666666665,
      "grad_norm": 0.3878081142902374,
      "learning_rate": 3.726666666666667e-05,
      "loss": 0.0016,
      "step": 5730
    },
    {
      "epoch": 0.2551111111111111,
      "grad_norm": 0.33050334453582764,
      "learning_rate": 3.724444444444445e-05,
      "loss": 0.0025,
      "step": 5740
    },
    {
      "epoch": 0.25555555555555554,
      "grad_norm": 0.26226064562797546,
      "learning_rate": 3.722222222222222e-05,
      "loss": 0.0026,
      "step": 5750
    },
    {
      "epoch": 0.256,
      "grad_norm": 0.4272986352443695,
      "learning_rate": 3.72e-05,
      "loss": 0.0019,
      "step": 5760
    },
    {
      "epoch": 0.2564444444444444,
      "grad_norm": 0.7981958389282227,
      "learning_rate": 3.717777777777778e-05,
      "loss": 0.0019,
      "step": 5770
    },
    {
      "epoch": 0.2568888888888889,
      "grad_norm": 0.2359267622232437,
      "learning_rate": 3.715555555555555e-05,
      "loss": 0.0022,
      "step": 5780
    },
    {
      "epoch": 0.25733333333333336,
      "grad_norm": 0.5794315934181213,
      "learning_rate": 3.713333333333334e-05,
      "loss": 0.0018,
      "step": 5790
    },
    {
      "epoch": 0.2577777777777778,
      "grad_norm": 0.08441141247749329,
      "learning_rate": 3.7111111111111113e-05,
      "loss": 0.0019,
      "step": 5800
    },
    {
      "epoch": 0.25822222222222224,
      "grad_norm": 0.26279330253601074,
      "learning_rate": 3.708888888888889e-05,
      "loss": 0.0021,
      "step": 5810
    },
    {
      "epoch": 0.25866666666666666,
      "grad_norm": 0.2081741988658905,
      "learning_rate": 3.706666666666667e-05,
      "loss": 0.0023,
      "step": 5820
    },
    {
      "epoch": 0.2591111111111111,
      "grad_norm": 0.42700955271720886,
      "learning_rate": 3.704444444444445e-05,
      "loss": 0.0018,
      "step": 5830
    },
    {
      "epoch": 0.25955555555555554,
      "grad_norm": 0.44349217414855957,
      "learning_rate": 3.7022222222222224e-05,
      "loss": 0.0019,
      "step": 5840
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.31925445795059204,
      "learning_rate": 3.7e-05,
      "loss": 0.002,
      "step": 5850
    },
    {
      "epoch": 0.2604444444444444,
      "grad_norm": 0.48396074771881104,
      "learning_rate": 3.697777777777778e-05,
      "loss": 0.0024,
      "step": 5860
    },
    {
      "epoch": 0.2608888888888889,
      "grad_norm": 0.4691327214241028,
      "learning_rate": 3.695555555555556e-05,
      "loss": 0.0019,
      "step": 5870
    },
    {
      "epoch": 0.2613333333333333,
      "grad_norm": 0.29107335209846497,
      "learning_rate": 3.6933333333333334e-05,
      "loss": 0.0017,
      "step": 5880
    },
    {
      "epoch": 0.2617777777777778,
      "grad_norm": 0.048269037157297134,
      "learning_rate": 3.6911111111111115e-05,
      "loss": 0.002,
      "step": 5890
    },
    {
      "epoch": 0.26222222222222225,
      "grad_norm": 0.034317634999752045,
      "learning_rate": 3.688888888888889e-05,
      "loss": 0.0021,
      "step": 5900
    },
    {
      "epoch": 0.26266666666666666,
      "grad_norm": 0.551815390586853,
      "learning_rate": 3.6866666666666664e-05,
      "loss": 0.0024,
      "step": 5910
    },
    {
      "epoch": 0.26311111111111113,
      "grad_norm": 0.43464040756225586,
      "learning_rate": 3.6844444444444445e-05,
      "loss": 0.0027,
      "step": 5920
    },
    {
      "epoch": 0.26355555555555554,
      "grad_norm": 0.16677987575531006,
      "learning_rate": 3.6822222222222226e-05,
      "loss": 0.0024,
      "step": 5930
    },
    {
      "epoch": 0.264,
      "grad_norm": 0.21014413237571716,
      "learning_rate": 3.68e-05,
      "loss": 0.0018,
      "step": 5940
    },
    {
      "epoch": 0.2644444444444444,
      "grad_norm": 0.5524168610572815,
      "learning_rate": 3.677777777777778e-05,
      "loss": 0.0019,
      "step": 5950
    },
    {
      "epoch": 0.2648888888888889,
      "grad_norm": 0.5716412663459778,
      "learning_rate": 3.675555555555556e-05,
      "loss": 0.0024,
      "step": 5960
    },
    {
      "epoch": 0.2653333333333333,
      "grad_norm": 0.4291333258152008,
      "learning_rate": 3.6733333333333336e-05,
      "loss": 0.0018,
      "step": 5970
    },
    {
      "epoch": 0.2657777777777778,
      "grad_norm": 0.03020920418202877,
      "learning_rate": 3.671111111111111e-05,
      "loss": 0.0019,
      "step": 5980
    },
    {
      "epoch": 0.26622222222222225,
      "grad_norm": 0.08895303308963776,
      "learning_rate": 3.668888888888889e-05,
      "loss": 0.0027,
      "step": 5990
    },
    {
      "epoch": 0.26666666666666666,
      "grad_norm": 0.04949643462896347,
      "learning_rate": 3.6666666666666666e-05,
      "loss": 0.003,
      "step": 6000
    },
    {
      "epoch": 0.26711111111111113,
      "grad_norm": 0.1795274019241333,
      "learning_rate": 3.664444444444445e-05,
      "loss": 0.0023,
      "step": 6010
    },
    {
      "epoch": 0.26755555555555555,
      "grad_norm": 0.11014921218156815,
      "learning_rate": 3.662222222222223e-05,
      "loss": 0.0018,
      "step": 6020
    },
    {
      "epoch": 0.268,
      "grad_norm": 0.18804574012756348,
      "learning_rate": 3.66e-05,
      "loss": 0.0021,
      "step": 6030
    },
    {
      "epoch": 0.26844444444444443,
      "grad_norm": 0.1518825888633728,
      "learning_rate": 3.6577777777777776e-05,
      "loss": 0.0022,
      "step": 6040
    },
    {
      "epoch": 0.2688888888888889,
      "grad_norm": 0.15424056351184845,
      "learning_rate": 3.655555555555556e-05,
      "loss": 0.0017,
      "step": 6050
    },
    {
      "epoch": 0.2693333333333333,
      "grad_norm": 0.38566410541534424,
      "learning_rate": 3.653333333333334e-05,
      "loss": 0.002,
      "step": 6060
    },
    {
      "epoch": 0.2697777777777778,
      "grad_norm": 0.061457857489585876,
      "learning_rate": 3.651111111111111e-05,
      "loss": 0.0023,
      "step": 6070
    },
    {
      "epoch": 0.2702222222222222,
      "grad_norm": 0.16657845675945282,
      "learning_rate": 3.648888888888889e-05,
      "loss": 0.0019,
      "step": 6080
    },
    {
      "epoch": 0.27066666666666667,
      "grad_norm": 0.019968431442975998,
      "learning_rate": 3.646666666666667e-05,
      "loss": 0.0019,
      "step": 6090
    },
    {
      "epoch": 0.27111111111111114,
      "grad_norm": 0.2905386984348297,
      "learning_rate": 3.644444444444445e-05,
      "loss": 0.0017,
      "step": 6100
    },
    {
      "epoch": 0.27155555555555555,
      "grad_norm": 0.07022236287593842,
      "learning_rate": 3.642222222222222e-05,
      "loss": 0.0018,
      "step": 6110
    },
    {
      "epoch": 0.272,
      "grad_norm": 0.2089211344718933,
      "learning_rate": 3.6400000000000004e-05,
      "loss": 0.0023,
      "step": 6120
    },
    {
      "epoch": 0.27244444444444443,
      "grad_norm": 0.0591031014919281,
      "learning_rate": 3.637777777777778e-05,
      "loss": 0.0021,
      "step": 6130
    },
    {
      "epoch": 0.2728888888888889,
      "grad_norm": 0.2347489893436432,
      "learning_rate": 3.635555555555556e-05,
      "loss": 0.0019,
      "step": 6140
    },
    {
      "epoch": 0.2733333333333333,
      "grad_norm": 0.37138766050338745,
      "learning_rate": 3.633333333333333e-05,
      "loss": 0.0017,
      "step": 6150
    },
    {
      "epoch": 0.2737777777777778,
      "grad_norm": 0.12445878982543945,
      "learning_rate": 3.6311111111111114e-05,
      "loss": 0.0015,
      "step": 6160
    },
    {
      "epoch": 0.2742222222222222,
      "grad_norm": 0.3035798966884613,
      "learning_rate": 3.628888888888889e-05,
      "loss": 0.0016,
      "step": 6170
    },
    {
      "epoch": 0.27466666666666667,
      "grad_norm": 0.018675856292247772,
      "learning_rate": 3.626666666666667e-05,
      "loss": 0.0024,
      "step": 6180
    },
    {
      "epoch": 0.2751111111111111,
      "grad_norm": 0.07287847995758057,
      "learning_rate": 3.624444444444445e-05,
      "loss": 0.0018,
      "step": 6190
    },
    {
      "epoch": 0.27555555555555555,
      "grad_norm": 0.1810539960861206,
      "learning_rate": 3.6222222222222225e-05,
      "loss": 0.0017,
      "step": 6200
    },
    {
      "epoch": 0.276,
      "grad_norm": 0.2616080939769745,
      "learning_rate": 3.62e-05,
      "loss": 0.0019,
      "step": 6210
    },
    {
      "epoch": 0.27644444444444444,
      "grad_norm": 0.16798433661460876,
      "learning_rate": 3.617777777777778e-05,
      "loss": 0.0028,
      "step": 6220
    },
    {
      "epoch": 0.2768888888888889,
      "grad_norm": 0.4526595175266266,
      "learning_rate": 3.615555555555556e-05,
      "loss": 0.0025,
      "step": 6230
    },
    {
      "epoch": 0.2773333333333333,
      "grad_norm": 0.2078627198934555,
      "learning_rate": 3.6133333333333335e-05,
      "loss": 0.0018,
      "step": 6240
    },
    {
      "epoch": 0.2777777777777778,
      "grad_norm": 0.23452959954738617,
      "learning_rate": 3.611111111111111e-05,
      "loss": 0.002,
      "step": 6250
    },
    {
      "epoch": 0.2782222222222222,
      "grad_norm": 0.06255431473255157,
      "learning_rate": 3.608888888888889e-05,
      "loss": 0.0021,
      "step": 6260
    },
    {
      "epoch": 0.2786666666666667,
      "grad_norm": 0.04732251912355423,
      "learning_rate": 3.606666666666667e-05,
      "loss": 0.002,
      "step": 6270
    },
    {
      "epoch": 0.2791111111111111,
      "grad_norm": 0.23559662699699402,
      "learning_rate": 3.6044444444444446e-05,
      "loss": 0.002,
      "step": 6280
    },
    {
      "epoch": 0.27955555555555556,
      "grad_norm": 0.4474036693572998,
      "learning_rate": 3.602222222222223e-05,
      "loss": 0.0025,
      "step": 6290
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.2199794352054596,
      "learning_rate": 3.6e-05,
      "loss": 0.0019,
      "step": 6300
    },
    {
      "epoch": 0.28044444444444444,
      "grad_norm": 0.34754249453544617,
      "learning_rate": 3.5977777777777775e-05,
      "loss": 0.0023,
      "step": 6310
    },
    {
      "epoch": 0.2808888888888889,
      "grad_norm": 0.16579902172088623,
      "learning_rate": 3.5955555555555556e-05,
      "loss": 0.0019,
      "step": 6320
    },
    {
      "epoch": 0.2813333333333333,
      "grad_norm": 0.29685479402542114,
      "learning_rate": 3.593333333333334e-05,
      "loss": 0.0019,
      "step": 6330
    },
    {
      "epoch": 0.2817777777777778,
      "grad_norm": 0.4836116135120392,
      "learning_rate": 3.591111111111111e-05,
      "loss": 0.0017,
      "step": 6340
    },
    {
      "epoch": 0.2822222222222222,
      "grad_norm": 0.18061137199401855,
      "learning_rate": 3.5888888888888886e-05,
      "loss": 0.0017,
      "step": 6350
    },
    {
      "epoch": 0.2826666666666667,
      "grad_norm": 0.17930641770362854,
      "learning_rate": 3.586666666666667e-05,
      "loss": 0.0018,
      "step": 6360
    },
    {
      "epoch": 0.2831111111111111,
      "grad_norm": 0.01868075132369995,
      "learning_rate": 3.584444444444445e-05,
      "loss": 0.0024,
      "step": 6370
    },
    {
      "epoch": 0.28355555555555556,
      "grad_norm": 0.1953163594007492,
      "learning_rate": 3.582222222222222e-05,
      "loss": 0.002,
      "step": 6380
    },
    {
      "epoch": 0.284,
      "grad_norm": 0.37236618995666504,
      "learning_rate": 3.58e-05,
      "loss": 0.0028,
      "step": 6390
    },
    {
      "epoch": 0.28444444444444444,
      "grad_norm": 0.3628142774105072,
      "learning_rate": 3.577777777777778e-05,
      "loss": 0.0022,
      "step": 6400
    },
    {
      "epoch": 0.2848888888888889,
      "grad_norm": 0.1389545500278473,
      "learning_rate": 3.575555555555556e-05,
      "loss": 0.002,
      "step": 6410
    },
    {
      "epoch": 0.2853333333333333,
      "grad_norm": 0.5876399874687195,
      "learning_rate": 3.573333333333333e-05,
      "loss": 0.0021,
      "step": 6420
    },
    {
      "epoch": 0.2857777777777778,
      "grad_norm": 0.22176489233970642,
      "learning_rate": 3.571111111111111e-05,
      "loss": 0.0016,
      "step": 6430
    },
    {
      "epoch": 0.2862222222222222,
      "grad_norm": 0.33219313621520996,
      "learning_rate": 3.568888888888889e-05,
      "loss": 0.0018,
      "step": 6440
    },
    {
      "epoch": 0.2866666666666667,
      "grad_norm": 0.5936088562011719,
      "learning_rate": 3.566666666666667e-05,
      "loss": 0.0018,
      "step": 6450
    },
    {
      "epoch": 0.2871111111111111,
      "grad_norm": 0.019937686622142792,
      "learning_rate": 3.564444444444445e-05,
      "loss": 0.0026,
      "step": 6460
    },
    {
      "epoch": 0.28755555555555556,
      "grad_norm": 0.13829536736011505,
      "learning_rate": 3.5622222222222224e-05,
      "loss": 0.0018,
      "step": 6470
    },
    {
      "epoch": 0.288,
      "grad_norm": 0.09848874807357788,
      "learning_rate": 3.56e-05,
      "loss": 0.0017,
      "step": 6480
    },
    {
      "epoch": 0.28844444444444445,
      "grad_norm": 0.5548790693283081,
      "learning_rate": 3.557777777777778e-05,
      "loss": 0.002,
      "step": 6490
    },
    {
      "epoch": 0.28888888888888886,
      "grad_norm": 0.42685821652412415,
      "learning_rate": 3.555555555555556e-05,
      "loss": 0.0018,
      "step": 6500
    },
    {
      "epoch": 0.28933333333333333,
      "grad_norm": 0.10292286425828934,
      "learning_rate": 3.5533333333333334e-05,
      "loss": 0.0021,
      "step": 6510
    },
    {
      "epoch": 0.2897777777777778,
      "grad_norm": 0.37287992238998413,
      "learning_rate": 3.551111111111111e-05,
      "loss": 0.0026,
      "step": 6520
    },
    {
      "epoch": 0.2902222222222222,
      "grad_norm": 0.4167136251926422,
      "learning_rate": 3.548888888888889e-05,
      "loss": 0.0023,
      "step": 6530
    },
    {
      "epoch": 0.2906666666666667,
      "grad_norm": 0.18123343586921692,
      "learning_rate": 3.546666666666667e-05,
      "loss": 0.0021,
      "step": 6540
    },
    {
      "epoch": 0.2911111111111111,
      "grad_norm": 0.11285282671451569,
      "learning_rate": 3.5444444444444445e-05,
      "loss": 0.0021,
      "step": 6550
    },
    {
      "epoch": 0.29155555555555557,
      "grad_norm": 0.16632497310638428,
      "learning_rate": 3.5422222222222226e-05,
      "loss": 0.0017,
      "step": 6560
    },
    {
      "epoch": 0.292,
      "grad_norm": 0.6068741083145142,
      "learning_rate": 3.54e-05,
      "loss": 0.002,
      "step": 6570
    },
    {
      "epoch": 0.29244444444444445,
      "grad_norm": 0.5676343441009521,
      "learning_rate": 3.537777777777778e-05,
      "loss": 0.0017,
      "step": 6580
    },
    {
      "epoch": 0.29288888888888887,
      "grad_norm": 0.22213639318943024,
      "learning_rate": 3.5355555555555555e-05,
      "loss": 0.0022,
      "step": 6590
    },
    {
      "epoch": 0.29333333333333333,
      "grad_norm": 0.3716207444667816,
      "learning_rate": 3.5333333333333336e-05,
      "loss": 0.0021,
      "step": 6600
    },
    {
      "epoch": 0.2937777777777778,
      "grad_norm": 0.34662607312202454,
      "learning_rate": 3.531111111111111e-05,
      "loss": 0.0019,
      "step": 6610
    },
    {
      "epoch": 0.2942222222222222,
      "grad_norm": 0.04194658622145653,
      "learning_rate": 3.528888888888889e-05,
      "loss": 0.0022,
      "step": 6620
    },
    {
      "epoch": 0.2946666666666667,
      "grad_norm": 0.20669673383235931,
      "learning_rate": 3.526666666666667e-05,
      "loss": 0.0021,
      "step": 6630
    },
    {
      "epoch": 0.2951111111111111,
      "grad_norm": 0.12551891803741455,
      "learning_rate": 3.5244444444444447e-05,
      "loss": 0.002,
      "step": 6640
    },
    {
      "epoch": 0.29555555555555557,
      "grad_norm": 0.11102454364299774,
      "learning_rate": 3.522222222222222e-05,
      "loss": 0.002,
      "step": 6650
    },
    {
      "epoch": 0.296,
      "grad_norm": 0.2511975169181824,
      "learning_rate": 3.52e-05,
      "loss": 0.0021,
      "step": 6660
    },
    {
      "epoch": 0.29644444444444445,
      "grad_norm": 0.34608739614486694,
      "learning_rate": 3.517777777777778e-05,
      "loss": 0.0022,
      "step": 6670
    },
    {
      "epoch": 0.29688888888888887,
      "grad_norm": 0.46755334734916687,
      "learning_rate": 3.515555555555556e-05,
      "loss": 0.0028,
      "step": 6680
    },
    {
      "epoch": 0.29733333333333334,
      "grad_norm": 0.4012179970741272,
      "learning_rate": 3.513333333333334e-05,
      "loss": 0.0015,
      "step": 6690
    },
    {
      "epoch": 0.29777777777777775,
      "grad_norm": 0.1519482135772705,
      "learning_rate": 3.511111111111111e-05,
      "loss": 0.0023,
      "step": 6700
    },
    {
      "epoch": 0.2982222222222222,
      "grad_norm": 0.07307512313127518,
      "learning_rate": 3.5088888888888886e-05,
      "loss": 0.0022,
      "step": 6710
    },
    {
      "epoch": 0.2986666666666667,
      "grad_norm": 0.6849331855773926,
      "learning_rate": 3.506666666666667e-05,
      "loss": 0.0017,
      "step": 6720
    },
    {
      "epoch": 0.2991111111111111,
      "grad_norm": 0.5649993419647217,
      "learning_rate": 3.504444444444445e-05,
      "loss": 0.0019,
      "step": 6730
    },
    {
      "epoch": 0.2995555555555556,
      "grad_norm": 0.1250513792037964,
      "learning_rate": 3.502222222222222e-05,
      "loss": 0.0018,
      "step": 6740
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.8989410400390625,
      "learning_rate": 3.5e-05,
      "loss": 0.0023,
      "step": 6750
    },
    {
      "epoch": 0.30044444444444446,
      "grad_norm": 0.27595117688179016,
      "learning_rate": 3.4977777777777785e-05,
      "loss": 0.0023,
      "step": 6760
    },
    {
      "epoch": 0.3008888888888889,
      "grad_norm": 0.3737509250640869,
      "learning_rate": 3.495555555555556e-05,
      "loss": 0.0018,
      "step": 6770
    },
    {
      "epoch": 0.30133333333333334,
      "grad_norm": 0.058691855520009995,
      "learning_rate": 3.493333333333333e-05,
      "loss": 0.0022,
      "step": 6780
    },
    {
      "epoch": 0.30177777777777776,
      "grad_norm": 0.2616630792617798,
      "learning_rate": 3.4911111111111114e-05,
      "loss": 0.0022,
      "step": 6790
    },
    {
      "epoch": 0.3022222222222222,
      "grad_norm": 0.234396293759346,
      "learning_rate": 3.4888888888888895e-05,
      "loss": 0.0027,
      "step": 6800
    },
    {
      "epoch": 0.30266666666666664,
      "grad_norm": 0.3438907861709595,
      "learning_rate": 3.486666666666667e-05,
      "loss": 0.0022,
      "step": 6810
    },
    {
      "epoch": 0.3031111111111111,
      "grad_norm": 0.1667150855064392,
      "learning_rate": 3.4844444444444444e-05,
      "loss": 0.0025,
      "step": 6820
    },
    {
      "epoch": 0.3035555555555556,
      "grad_norm": 0.0897998958826065,
      "learning_rate": 3.4822222222222225e-05,
      "loss": 0.0018,
      "step": 6830
    },
    {
      "epoch": 0.304,
      "grad_norm": 0.4158532917499542,
      "learning_rate": 3.48e-05,
      "loss": 0.0016,
      "step": 6840
    },
    {
      "epoch": 0.30444444444444446,
      "grad_norm": 0.5386968851089478,
      "learning_rate": 3.477777777777778e-05,
      "loss": 0.0017,
      "step": 6850
    },
    {
      "epoch": 0.3048888888888889,
      "grad_norm": 0.4541671574115753,
      "learning_rate": 3.475555555555556e-05,
      "loss": 0.0024,
      "step": 6860
    },
    {
      "epoch": 0.30533333333333335,
      "grad_norm": 0.11186035722494125,
      "learning_rate": 3.4733333333333335e-05,
      "loss": 0.002,
      "step": 6870
    },
    {
      "epoch": 0.30577777777777776,
      "grad_norm": 0.1656171977519989,
      "learning_rate": 3.471111111111111e-05,
      "loss": 0.0016,
      "step": 6880
    },
    {
      "epoch": 0.30622222222222223,
      "grad_norm": 0.5092616081237793,
      "learning_rate": 3.468888888888889e-05,
      "loss": 0.0021,
      "step": 6890
    },
    {
      "epoch": 0.30666666666666664,
      "grad_norm": 0.4837549030780792,
      "learning_rate": 3.466666666666667e-05,
      "loss": 0.0023,
      "step": 6900
    },
    {
      "epoch": 0.3071111111111111,
      "grad_norm": 0.07481714338064194,
      "learning_rate": 3.4644444444444446e-05,
      "loss": 0.0025,
      "step": 6910
    },
    {
      "epoch": 0.3075555555555556,
      "grad_norm": 0.11060325801372528,
      "learning_rate": 3.462222222222222e-05,
      "loss": 0.002,
      "step": 6920
    },
    {
      "epoch": 0.308,
      "grad_norm": 0.16566284000873566,
      "learning_rate": 3.46e-05,
      "loss": 0.0022,
      "step": 6930
    },
    {
      "epoch": 0.30844444444444447,
      "grad_norm": 0.385471910238266,
      "learning_rate": 3.457777777777778e-05,
      "loss": 0.002,
      "step": 6940
    },
    {
      "epoch": 0.3088888888888889,
      "grad_norm": 0.3032967746257782,
      "learning_rate": 3.4555555555555556e-05,
      "loss": 0.002,
      "step": 6950
    },
    {
      "epoch": 0.30933333333333335,
      "grad_norm": 0.06997283548116684,
      "learning_rate": 3.453333333333334e-05,
      "loss": 0.0019,
      "step": 6960
    },
    {
      "epoch": 0.30977777777777776,
      "grad_norm": 0.12975314259529114,
      "learning_rate": 3.451111111111111e-05,
      "loss": 0.002,
      "step": 6970
    },
    {
      "epoch": 0.31022222222222223,
      "grad_norm": 0.2202846258878708,
      "learning_rate": 3.448888888888889e-05,
      "loss": 0.0017,
      "step": 6980
    },
    {
      "epoch": 0.31066666666666665,
      "grad_norm": 0.48290660977363586,
      "learning_rate": 3.4466666666666666e-05,
      "loss": 0.0017,
      "step": 6990
    },
    {
      "epoch": 0.3111111111111111,
      "grad_norm": 1.1303356885910034,
      "learning_rate": 3.444444444444445e-05,
      "loss": 0.0019,
      "step": 7000
    },
    {
      "epoch": 0.31155555555555553,
      "grad_norm": 0.3080275356769562,
      "learning_rate": 3.442222222222222e-05,
      "loss": 0.0019,
      "step": 7010
    },
    {
      "epoch": 0.312,
      "grad_norm": 0.33882370591163635,
      "learning_rate": 3.4399999999999996e-05,
      "loss": 0.0026,
      "step": 7020
    },
    {
      "epoch": 0.31244444444444447,
      "grad_norm": 0.13782528042793274,
      "learning_rate": 3.4377777777777784e-05,
      "loss": 0.0023,
      "step": 7030
    },
    {
      "epoch": 0.3128888888888889,
      "grad_norm": 0.20820218324661255,
      "learning_rate": 3.435555555555556e-05,
      "loss": 0.0018,
      "step": 7040
    },
    {
      "epoch": 0.31333333333333335,
      "grad_norm": 0.523535966873169,
      "learning_rate": 3.433333333333333e-05,
      "loss": 0.0024,
      "step": 7050
    },
    {
      "epoch": 0.31377777777777777,
      "grad_norm": 0.11156231164932251,
      "learning_rate": 3.431111111111111e-05,
      "loss": 0.0018,
      "step": 7060
    },
    {
      "epoch": 0.31422222222222224,
      "grad_norm": 0.2082223892211914,
      "learning_rate": 3.4288888888888894e-05,
      "loss": 0.002,
      "step": 7070
    },
    {
      "epoch": 0.31466666666666665,
      "grad_norm": 0.1536867916584015,
      "learning_rate": 3.426666666666667e-05,
      "loss": 0.0019,
      "step": 7080
    },
    {
      "epoch": 0.3151111111111111,
      "grad_norm": 0.5245407223701477,
      "learning_rate": 3.424444444444444e-05,
      "loss": 0.0023,
      "step": 7090
    },
    {
      "epoch": 0.31555555555555553,
      "grad_norm": 0.41248923540115356,
      "learning_rate": 3.4222222222222224e-05,
      "loss": 0.002,
      "step": 7100
    },
    {
      "epoch": 0.316,
      "grad_norm": 0.27573931217193604,
      "learning_rate": 3.4200000000000005e-05,
      "loss": 0.0022,
      "step": 7110
    },
    {
      "epoch": 0.3164444444444444,
      "grad_norm": 0.06943929195404053,
      "learning_rate": 3.417777777777778e-05,
      "loss": 0.0019,
      "step": 7120
    },
    {
      "epoch": 0.3168888888888889,
      "grad_norm": 0.15250587463378906,
      "learning_rate": 3.415555555555556e-05,
      "loss": 0.0019,
      "step": 7130
    },
    {
      "epoch": 0.31733333333333336,
      "grad_norm": 0.3169633448123932,
      "learning_rate": 3.4133333333333334e-05,
      "loss": 0.0024,
      "step": 7140
    },
    {
      "epoch": 0.31777777777777777,
      "grad_norm": 0.21024665236473083,
      "learning_rate": 3.411111111111111e-05,
      "loss": 0.002,
      "step": 7150
    },
    {
      "epoch": 0.31822222222222224,
      "grad_norm": 0.07183916121721268,
      "learning_rate": 3.408888888888889e-05,
      "loss": 0.0022,
      "step": 7160
    },
    {
      "epoch": 0.31866666666666665,
      "grad_norm": 0.234676793217659,
      "learning_rate": 3.406666666666667e-05,
      "loss": 0.0018,
      "step": 7170
    },
    {
      "epoch": 0.3191111111111111,
      "grad_norm": 0.033213887363672256,
      "learning_rate": 3.4044444444444445e-05,
      "loss": 0.0017,
      "step": 7180
    },
    {
      "epoch": 0.31955555555555554,
      "grad_norm": 0.2206137329339981,
      "learning_rate": 3.402222222222222e-05,
      "loss": 0.0018,
      "step": 7190
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.6745121479034424,
      "learning_rate": 3.4000000000000007e-05,
      "loss": 0.0023,
      "step": 7200
    },
    {
      "epoch": 0.3204444444444444,
      "grad_norm": 0.2893175482749939,
      "learning_rate": 3.397777777777778e-05,
      "loss": 0.0022,
      "step": 7210
    },
    {
      "epoch": 0.3208888888888889,
      "grad_norm": 0.536837100982666,
      "learning_rate": 3.3955555555555555e-05,
      "loss": 0.0018,
      "step": 7220
    },
    {
      "epoch": 0.32133333333333336,
      "grad_norm": 0.2499845027923584,
      "learning_rate": 3.3933333333333336e-05,
      "loss": 0.0018,
      "step": 7230
    },
    {
      "epoch": 0.3217777777777778,
      "grad_norm": 0.29031509160995483,
      "learning_rate": 3.391111111111111e-05,
      "loss": 0.0027,
      "step": 7240
    },
    {
      "epoch": 0.32222222222222224,
      "grad_norm": 0.2210347056388855,
      "learning_rate": 3.388888888888889e-05,
      "loss": 0.0017,
      "step": 7250
    },
    {
      "epoch": 0.32266666666666666,
      "grad_norm": 0.019685354083776474,
      "learning_rate": 3.3866666666666665e-05,
      "loss": 0.0022,
      "step": 7260
    },
    {
      "epoch": 0.3231111111111111,
      "grad_norm": 0.08387303352355957,
      "learning_rate": 3.3844444444444446e-05,
      "loss": 0.0018,
      "step": 7270
    },
    {
      "epoch": 0.32355555555555554,
      "grad_norm": 0.07429654151201248,
      "learning_rate": 3.382222222222222e-05,
      "loss": 0.0022,
      "step": 7280
    },
    {
      "epoch": 0.324,
      "grad_norm": 0.15180104970932007,
      "learning_rate": 3.38e-05,
      "loss": 0.002,
      "step": 7290
    },
    {
      "epoch": 0.3244444444444444,
      "grad_norm": 0.4541368782520294,
      "learning_rate": 3.377777777777778e-05,
      "loss": 0.0017,
      "step": 7300
    },
    {
      "epoch": 0.3248888888888889,
      "grad_norm": 0.23401783406734467,
      "learning_rate": 3.375555555555556e-05,
      "loss": 0.0017,
      "step": 7310
    },
    {
      "epoch": 0.3253333333333333,
      "grad_norm": 0.1840745061635971,
      "learning_rate": 3.373333333333333e-05,
      "loss": 0.0022,
      "step": 7320
    },
    {
      "epoch": 0.3257777777777778,
      "grad_norm": 0.06050413101911545,
      "learning_rate": 3.371111111111111e-05,
      "loss": 0.0016,
      "step": 7330
    },
    {
      "epoch": 0.32622222222222225,
      "grad_norm": 0.6195433735847473,
      "learning_rate": 3.368888888888889e-05,
      "loss": 0.0019,
      "step": 7340
    },
    {
      "epoch": 0.32666666666666666,
      "grad_norm": 0.18134582042694092,
      "learning_rate": 3.366666666666667e-05,
      "loss": 0.0017,
      "step": 7350
    },
    {
      "epoch": 0.32711111111111113,
      "grad_norm": 0.16620759665966034,
      "learning_rate": 3.364444444444445e-05,
      "loss": 0.0024,
      "step": 7360
    },
    {
      "epoch": 0.32755555555555554,
      "grad_norm": 0.24793598055839539,
      "learning_rate": 3.362222222222222e-05,
      "loss": 0.0017,
      "step": 7370
    },
    {
      "epoch": 0.328,
      "grad_norm": 0.16590134799480438,
      "learning_rate": 3.3600000000000004e-05,
      "loss": 0.0018,
      "step": 7380
    },
    {
      "epoch": 0.32844444444444443,
      "grad_norm": 0.12436101585626602,
      "learning_rate": 3.357777777777778e-05,
      "loss": 0.0023,
      "step": 7390
    },
    {
      "epoch": 0.3288888888888889,
      "grad_norm": 0.09737911075353622,
      "learning_rate": 3.355555555555556e-05,
      "loss": 0.0017,
      "step": 7400
    },
    {
      "epoch": 0.3293333333333333,
      "grad_norm": 0.18040333688259125,
      "learning_rate": 3.353333333333333e-05,
      "loss": 0.002,
      "step": 7410
    },
    {
      "epoch": 0.3297777777777778,
      "grad_norm": 0.04941439628601074,
      "learning_rate": 3.3511111111111114e-05,
      "loss": 0.002,
      "step": 7420
    },
    {
      "epoch": 0.3302222222222222,
      "grad_norm": 0.03207322582602501,
      "learning_rate": 3.3488888888888895e-05,
      "loss": 0.002,
      "step": 7430
    },
    {
      "epoch": 0.33066666666666666,
      "grad_norm": 0.5077126026153564,
      "learning_rate": 3.346666666666667e-05,
      "loss": 0.0021,
      "step": 7440
    },
    {
      "epoch": 0.33111111111111113,
      "grad_norm": 0.16729769110679626,
      "learning_rate": 3.3444444444444443e-05,
      "loss": 0.0018,
      "step": 7450
    },
    {
      "epoch": 0.33155555555555555,
      "grad_norm": 0.0844820886850357,
      "learning_rate": 3.3422222222222224e-05,
      "loss": 0.002,
      "step": 7460
    },
    {
      "epoch": 0.332,
      "grad_norm": 0.2900882959365845,
      "learning_rate": 3.3400000000000005e-05,
      "loss": 0.0023,
      "step": 7470
    },
    {
      "epoch": 0.33244444444444443,
      "grad_norm": 0.4692407250404358,
      "learning_rate": 3.337777777777778e-05,
      "loss": 0.0021,
      "step": 7480
    },
    {
      "epoch": 0.3328888888888889,
      "grad_norm": 0.23444584012031555,
      "learning_rate": 3.3355555555555554e-05,
      "loss": 0.0017,
      "step": 7490
    },
    {
      "epoch": 0.3333333333333333,
      "grad_norm": 0.7159494161605835,
      "learning_rate": 3.3333333333333335e-05,
      "loss": 0.0021,
      "step": 7500
    },
    {
      "epoch": 0.3337777777777778,
      "grad_norm": 0.5350269675254822,
      "learning_rate": 3.3311111111111116e-05,
      "loss": 0.0019,
      "step": 7510
    },
    {
      "epoch": 0.3342222222222222,
      "grad_norm": 0.3709772229194641,
      "learning_rate": 3.328888888888889e-05,
      "loss": 0.0021,
      "step": 7520
    },
    {
      "epoch": 0.33466666666666667,
      "grad_norm": 0.2484235167503357,
      "learning_rate": 3.326666666666667e-05,
      "loss": 0.0021,
      "step": 7530
    },
    {
      "epoch": 0.33511111111111114,
      "grad_norm": 0.35559508204460144,
      "learning_rate": 3.3244444444444445e-05,
      "loss": 0.0028,
      "step": 7540
    },
    {
      "epoch": 0.33555555555555555,
      "grad_norm": 0.247547447681427,
      "learning_rate": 3.322222222222222e-05,
      "loss": 0.0027,
      "step": 7550
    },
    {
      "epoch": 0.336,
      "grad_norm": 0.12492760270833969,
      "learning_rate": 3.32e-05,
      "loss": 0.0022,
      "step": 7560
    },
    {
      "epoch": 0.33644444444444443,
      "grad_norm": 0.26889756321907043,
      "learning_rate": 3.317777777777778e-05,
      "loss": 0.0022,
      "step": 7570
    },
    {
      "epoch": 0.3368888888888889,
      "grad_norm": 0.15123429894447327,
      "learning_rate": 3.3155555555555556e-05,
      "loss": 0.0019,
      "step": 7580
    },
    {
      "epoch": 0.3373333333333333,
      "grad_norm": 0.17898142337799072,
      "learning_rate": 3.313333333333333e-05,
      "loss": 0.0019,
      "step": 7590
    },
    {
      "epoch": 0.3377777777777778,
      "grad_norm": 0.25087782740592957,
      "learning_rate": 3.311111111111112e-05,
      "loss": 0.0019,
      "step": 7600
    },
    {
      "epoch": 0.3382222222222222,
      "grad_norm": 0.16561119258403778,
      "learning_rate": 3.308888888888889e-05,
      "loss": 0.0018,
      "step": 7610
    },
    {
      "epoch": 0.33866666666666667,
      "grad_norm": 0.11156731098890305,
      "learning_rate": 3.3066666666666666e-05,
      "loss": 0.0018,
      "step": 7620
    },
    {
      "epoch": 0.3391111111111111,
      "grad_norm": 0.23410460352897644,
      "learning_rate": 3.304444444444445e-05,
      "loss": 0.002,
      "step": 7630
    },
    {
      "epoch": 0.33955555555555555,
      "grad_norm": 0.19735564291477203,
      "learning_rate": 3.302222222222222e-05,
      "loss": 0.0017,
      "step": 7640
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.2623324990272522,
      "learning_rate": 3.3e-05,
      "loss": 0.0018,
      "step": 7650
    },
    {
      "epoch": 0.34044444444444444,
      "grad_norm": 0.3859582245349884,
      "learning_rate": 3.297777777777778e-05,
      "loss": 0.0022,
      "step": 7660
    },
    {
      "epoch": 0.3408888888888889,
      "grad_norm": 0.29027679562568665,
      "learning_rate": 3.295555555555556e-05,
      "loss": 0.0019,
      "step": 7670
    },
    {
      "epoch": 0.3413333333333333,
      "grad_norm": 0.08453787863254547,
      "learning_rate": 3.293333333333333e-05,
      "loss": 0.0018,
      "step": 7680
    },
    {
      "epoch": 0.3417777777777778,
      "grad_norm": 0.16758379340171814,
      "learning_rate": 3.291111111111111e-05,
      "loss": 0.0015,
      "step": 7690
    },
    {
      "epoch": 0.3422222222222222,
      "grad_norm": 0.12534160912036896,
      "learning_rate": 3.2888888888888894e-05,
      "loss": 0.0026,
      "step": 7700
    },
    {
      "epoch": 0.3426666666666667,
      "grad_norm": 0.1655082404613495,
      "learning_rate": 3.286666666666667e-05,
      "loss": 0.0024,
      "step": 7710
    },
    {
      "epoch": 0.3431111111111111,
      "grad_norm": 0.2916153073310852,
      "learning_rate": 3.284444444444444e-05,
      "loss": 0.002,
      "step": 7720
    },
    {
      "epoch": 0.34355555555555556,
      "grad_norm": 0.46767884492874146,
      "learning_rate": 3.2822222222222223e-05,
      "loss": 0.002,
      "step": 7730
    },
    {
      "epoch": 0.344,
      "grad_norm": 0.2351827174425125,
      "learning_rate": 3.2800000000000004e-05,
      "loss": 0.002,
      "step": 7740
    },
    {
      "epoch": 0.34444444444444444,
      "grad_norm": 0.22479148209095,
      "learning_rate": 3.277777777777778e-05,
      "loss": 0.0019,
      "step": 7750
    },
    {
      "epoch": 0.3448888888888889,
      "grad_norm": 0.5777937769889832,
      "learning_rate": 3.275555555555555e-05,
      "loss": 0.0021,
      "step": 7760
    },
    {
      "epoch": 0.3453333333333333,
      "grad_norm": 0.19293998181819916,
      "learning_rate": 3.2733333333333334e-05,
      "loss": 0.0018,
      "step": 7770
    },
    {
      "epoch": 0.3457777777777778,
      "grad_norm": 0.16605037450790405,
      "learning_rate": 3.2711111111111115e-05,
      "loss": 0.0018,
      "step": 7780
    },
    {
      "epoch": 0.3462222222222222,
      "grad_norm": 0.45433342456817627,
      "learning_rate": 3.268888888888889e-05,
      "loss": 0.0028,
      "step": 7790
    },
    {
      "epoch": 0.3466666666666667,
      "grad_norm": 0.7728009223937988,
      "learning_rate": 3.266666666666667e-05,
      "loss": 0.0021,
      "step": 7800
    },
    {
      "epoch": 0.3471111111111111,
      "grad_norm": 0.4284213185310364,
      "learning_rate": 3.2644444444444444e-05,
      "loss": 0.002,
      "step": 7810
    },
    {
      "epoch": 0.34755555555555556,
      "grad_norm": 0.7300171256065369,
      "learning_rate": 3.2622222222222225e-05,
      "loss": 0.0018,
      "step": 7820
    },
    {
      "epoch": 0.348,
      "grad_norm": 0.3852369487285614,
      "learning_rate": 3.26e-05,
      "loss": 0.0018,
      "step": 7830
    },
    {
      "epoch": 0.34844444444444445,
      "grad_norm": 0.5515483021736145,
      "learning_rate": 3.257777777777778e-05,
      "loss": 0.0019,
      "step": 7840
    },
    {
      "epoch": 0.3488888888888889,
      "grad_norm": 0.5916919708251953,
      "learning_rate": 3.2555555555555555e-05,
      "loss": 0.0018,
      "step": 7850
    },
    {
      "epoch": 0.34933333333333333,
      "grad_norm": 0.04635686054825783,
      "learning_rate": 3.253333333333333e-05,
      "loss": 0.0016,
      "step": 7860
    },
    {
      "epoch": 0.3497777777777778,
      "grad_norm": 0.3310186564922333,
      "learning_rate": 3.251111111111112e-05,
      "loss": 0.0023,
      "step": 7870
    },
    {
      "epoch": 0.3502222222222222,
      "grad_norm": 0.5636261701583862,
      "learning_rate": 3.248888888888889e-05,
      "loss": 0.0018,
      "step": 7880
    },
    {
      "epoch": 0.3506666666666667,
      "grad_norm": 0.39932093024253845,
      "learning_rate": 3.2466666666666665e-05,
      "loss": 0.0026,
      "step": 7890
    },
    {
      "epoch": 0.3511111111111111,
      "grad_norm": 0.1248926892876625,
      "learning_rate": 3.2444444444444446e-05,
      "loss": 0.0026,
      "step": 7900
    },
    {
      "epoch": 0.35155555555555557,
      "grad_norm": 0.2763323187828064,
      "learning_rate": 3.242222222222223e-05,
      "loss": 0.0021,
      "step": 7910
    },
    {
      "epoch": 0.352,
      "grad_norm": 0.1540655940771103,
      "learning_rate": 3.24e-05,
      "loss": 0.0019,
      "step": 7920
    },
    {
      "epoch": 0.35244444444444445,
      "grad_norm": 0.05746317654848099,
      "learning_rate": 3.2377777777777776e-05,
      "loss": 0.0021,
      "step": 7930
    },
    {
      "epoch": 0.35288888888888886,
      "grad_norm": 0.2891645133495331,
      "learning_rate": 3.235555555555556e-05,
      "loss": 0.0024,
      "step": 7940
    },
    {
      "epoch": 0.35333333333333333,
      "grad_norm": 0.28918761014938354,
      "learning_rate": 3.233333333333333e-05,
      "loss": 0.0018,
      "step": 7950
    },
    {
      "epoch": 0.3537777777777778,
      "grad_norm": 0.2334357500076294,
      "learning_rate": 3.231111111111111e-05,
      "loss": 0.0028,
      "step": 7960
    },
    {
      "epoch": 0.3542222222222222,
      "grad_norm": 0.03134968876838684,
      "learning_rate": 3.228888888888889e-05,
      "loss": 0.002,
      "step": 7970
    },
    {
      "epoch": 0.3546666666666667,
      "grad_norm": 0.22228606045246124,
      "learning_rate": 3.226666666666667e-05,
      "loss": 0.0016,
      "step": 7980
    },
    {
      "epoch": 0.3551111111111111,
      "grad_norm": 0.10008792579174042,
      "learning_rate": 3.224444444444444e-05,
      "loss": 0.0018,
      "step": 7990
    },
    {
      "epoch": 0.35555555555555557,
      "grad_norm": 0.03505546972155571,
      "learning_rate": 3.222222222222223e-05,
      "loss": 0.0017,
      "step": 8000
    },
    {
      "epoch": 0.356,
      "grad_norm": 0.13879893720149994,
      "learning_rate": 3.2200000000000003e-05,
      "loss": 0.0019,
      "step": 8010
    },
    {
      "epoch": 0.35644444444444445,
      "grad_norm": 0.3578920066356659,
      "learning_rate": 3.217777777777778e-05,
      "loss": 0.0018,
      "step": 8020
    },
    {
      "epoch": 0.35688888888888887,
      "grad_norm": 0.5167778730392456,
      "learning_rate": 3.215555555555556e-05,
      "loss": 0.0022,
      "step": 8030
    },
    {
      "epoch": 0.35733333333333334,
      "grad_norm": 0.2614193558692932,
      "learning_rate": 3.213333333333334e-05,
      "loss": 0.002,
      "step": 8040
    },
    {
      "epoch": 0.35777777777777775,
      "grad_norm": 0.23534491658210754,
      "learning_rate": 3.2111111111111114e-05,
      "loss": 0.0018,
      "step": 8050
    },
    {
      "epoch": 0.3582222222222222,
      "grad_norm": 0.11624470353126526,
      "learning_rate": 3.208888888888889e-05,
      "loss": 0.002,
      "step": 8060
    },
    {
      "epoch": 0.3586666666666667,
      "grad_norm": 0.24695472419261932,
      "learning_rate": 3.206666666666667e-05,
      "loss": 0.0018,
      "step": 8070
    },
    {
      "epoch": 0.3591111111111111,
      "grad_norm": 0.28935757279396057,
      "learning_rate": 3.204444444444444e-05,
      "loss": 0.0018,
      "step": 8080
    },
    {
      "epoch": 0.3595555555555556,
      "grad_norm": 0.5917963981628418,
      "learning_rate": 3.2022222222222224e-05,
      "loss": 0.0022,
      "step": 8090
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.07070960104465485,
      "learning_rate": 3.2000000000000005e-05,
      "loss": 0.0018,
      "step": 8100
    },
    {
      "epoch": 0.36044444444444446,
      "grad_norm": 0.17915113270282745,
      "learning_rate": 3.197777777777778e-05,
      "loss": 0.002,
      "step": 8110
    },
    {
      "epoch": 0.36088888888888887,
      "grad_norm": 0.11159297078847885,
      "learning_rate": 3.1955555555555554e-05,
      "loss": 0.0018,
      "step": 8120
    },
    {
      "epoch": 0.36133333333333334,
      "grad_norm": 0.022002220153808594,
      "learning_rate": 3.1933333333333335e-05,
      "loss": 0.0017,
      "step": 8130
    },
    {
      "epoch": 0.36177777777777775,
      "grad_norm": 0.05668748915195465,
      "learning_rate": 3.1911111111111116e-05,
      "loss": 0.0024,
      "step": 8140
    },
    {
      "epoch": 0.3622222222222222,
      "grad_norm": 0.11261345446109772,
      "learning_rate": 3.188888888888889e-05,
      "loss": 0.0019,
      "step": 8150
    },
    {
      "epoch": 0.3626666666666667,
      "grad_norm": 0.11107278615236282,
      "learning_rate": 3.1866666666666664e-05,
      "loss": 0.0018,
      "step": 8160
    },
    {
      "epoch": 0.3631111111111111,
      "grad_norm": 0.28821277618408203,
      "learning_rate": 3.1844444444444445e-05,
      "loss": 0.0018,
      "step": 8170
    },
    {
      "epoch": 0.3635555555555556,
      "grad_norm": 0.16566459834575653,
      "learning_rate": 3.1822222222222226e-05,
      "loss": 0.0024,
      "step": 8180
    },
    {
      "epoch": 0.364,
      "grad_norm": 0.11151532083749771,
      "learning_rate": 3.18e-05,
      "loss": 0.0019,
      "step": 8190
    },
    {
      "epoch": 0.36444444444444446,
      "grad_norm": 0.45313793420791626,
      "learning_rate": 3.177777777777778e-05,
      "loss": 0.0021,
      "step": 8200
    },
    {
      "epoch": 0.3648888888888889,
      "grad_norm": 0.04411410912871361,
      "learning_rate": 3.1755555555555556e-05,
      "loss": 0.0017,
      "step": 8210
    },
    {
      "epoch": 0.36533333333333334,
      "grad_norm": 0.40220382809638977,
      "learning_rate": 3.173333333333334e-05,
      "loss": 0.0022,
      "step": 8220
    },
    {
      "epoch": 0.36577777777777776,
      "grad_norm": 0.08453594148159027,
      "learning_rate": 3.171111111111111e-05,
      "loss": 0.0018,
      "step": 8230
    },
    {
      "epoch": 0.3662222222222222,
      "grad_norm": 0.08589451014995575,
      "learning_rate": 3.168888888888889e-05,
      "loss": 0.0018,
      "step": 8240
    },
    {
      "epoch": 0.36666666666666664,
      "grad_norm": 0.07044550776481628,
      "learning_rate": 3.1666666666666666e-05,
      "loss": 0.0018,
      "step": 8250
    },
    {
      "epoch": 0.3671111111111111,
      "grad_norm": 0.5492437481880188,
      "learning_rate": 3.164444444444444e-05,
      "loss": 0.0021,
      "step": 8260
    },
    {
      "epoch": 0.3675555555555556,
      "grad_norm": 0.24906031787395477,
      "learning_rate": 3.162222222222223e-05,
      "loss": 0.002,
      "step": 8270
    },
    {
      "epoch": 0.368,
      "grad_norm": 0.35727885365486145,
      "learning_rate": 3.16e-05,
      "loss": 0.002,
      "step": 8280
    },
    {
      "epoch": 0.36844444444444446,
      "grad_norm": 0.2754836082458496,
      "learning_rate": 3.1577777777777777e-05,
      "loss": 0.0023,
      "step": 8290
    },
    {
      "epoch": 0.3688888888888889,
      "grad_norm": 0.13803577423095703,
      "learning_rate": 3.155555555555556e-05,
      "loss": 0.0019,
      "step": 8300
    },
    {
      "epoch": 0.36933333333333335,
      "grad_norm": 0.09986806660890579,
      "learning_rate": 3.153333333333334e-05,
      "loss": 0.0016,
      "step": 8310
    },
    {
      "epoch": 0.36977777777777776,
      "grad_norm": 0.34286850690841675,
      "learning_rate": 3.151111111111111e-05,
      "loss": 0.002,
      "step": 8320
    },
    {
      "epoch": 0.37022222222222223,
      "grad_norm": 0.019746076315641403,
      "learning_rate": 3.148888888888889e-05,
      "loss": 0.0022,
      "step": 8330
    },
    {
      "epoch": 0.37066666666666664,
      "grad_norm": 0.19307252764701843,
      "learning_rate": 3.146666666666667e-05,
      "loss": 0.002,
      "step": 8340
    },
    {
      "epoch": 0.3711111111111111,
      "grad_norm": 0.22068007290363312,
      "learning_rate": 3.144444444444445e-05,
      "loss": 0.002,
      "step": 8350
    },
    {
      "epoch": 0.37155555555555553,
      "grad_norm": 0.15157324075698853,
      "learning_rate": 3.142222222222222e-05,
      "loss": 0.0018,
      "step": 8360
    },
    {
      "epoch": 0.372,
      "grad_norm": 0.4001745879650116,
      "learning_rate": 3.1400000000000004e-05,
      "loss": 0.0017,
      "step": 8370
    },
    {
      "epoch": 0.37244444444444447,
      "grad_norm": 0.16552117466926575,
      "learning_rate": 3.137777777777778e-05,
      "loss": 0.0019,
      "step": 8380
    },
    {
      "epoch": 0.3728888888888889,
      "grad_norm": 0.23513448238372803,
      "learning_rate": 3.135555555555555e-05,
      "loss": 0.0019,
      "step": 8390
    },
    {
      "epoch": 0.37333333333333335,
      "grad_norm": 0.4539588987827301,
      "learning_rate": 3.1333333333333334e-05,
      "loss": 0.0018,
      "step": 8400
    },
    {
      "epoch": 0.37377777777777776,
      "grad_norm": 0.30222901701927185,
      "learning_rate": 3.1311111111111115e-05,
      "loss": 0.0022,
      "step": 8410
    },
    {
      "epoch": 0.37422222222222223,
      "grad_norm": 0.16625899076461792,
      "learning_rate": 3.128888888888889e-05,
      "loss": 0.002,
      "step": 8420
    },
    {
      "epoch": 0.37466666666666665,
      "grad_norm": 0.20873388648033142,
      "learning_rate": 3.126666666666666e-05,
      "loss": 0.0017,
      "step": 8430
    },
    {
      "epoch": 0.3751111111111111,
      "grad_norm": 0.31616154313087463,
      "learning_rate": 3.124444444444445e-05,
      "loss": 0.0021,
      "step": 8440
    },
    {
      "epoch": 0.37555555555555553,
      "grad_norm": 0.26230955123901367,
      "learning_rate": 3.1222222222222225e-05,
      "loss": 0.002,
      "step": 8450
    },
    {
      "epoch": 0.376,
      "grad_norm": 0.13845394551753998,
      "learning_rate": 3.12e-05,
      "loss": 0.0021,
      "step": 8460
    },
    {
      "epoch": 0.37644444444444447,
      "grad_norm": 0.37219443917274475,
      "learning_rate": 3.117777777777778e-05,
      "loss": 0.002,
      "step": 8470
    },
    {
      "epoch": 0.3768888888888889,
      "grad_norm": 0.3023170828819275,
      "learning_rate": 3.1155555555555555e-05,
      "loss": 0.0019,
      "step": 8480
    },
    {
      "epoch": 0.37733333333333335,
      "grad_norm": 0.46768778562545776,
      "learning_rate": 3.1133333333333336e-05,
      "loss": 0.0018,
      "step": 8490
    },
    {
      "epoch": 0.37777777777777777,
      "grad_norm": 0.0889076516032219,
      "learning_rate": 3.111111111111111e-05,
      "loss": 0.0023,
      "step": 8500
    },
    {
      "epoch": 0.37822222222222224,
      "grad_norm": 0.5777088403701782,
      "learning_rate": 3.108888888888889e-05,
      "loss": 0.002,
      "step": 8510
    },
    {
      "epoch": 0.37866666666666665,
      "grad_norm": 0.7148486971855164,
      "learning_rate": 3.1066666666666665e-05,
      "loss": 0.0021,
      "step": 8520
    },
    {
      "epoch": 0.3791111111111111,
      "grad_norm": 0.3304300606250763,
      "learning_rate": 3.1044444444444446e-05,
      "loss": 0.0019,
      "step": 8530
    },
    {
      "epoch": 0.37955555555555553,
      "grad_norm": 0.0984061062335968,
      "learning_rate": 3.102222222222223e-05,
      "loss": 0.0017,
      "step": 8540
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.23581968247890472,
      "learning_rate": 3.1e-05,
      "loss": 0.0022,
      "step": 8550
    },
    {
      "epoch": 0.3804444444444444,
      "grad_norm": 0.14224767684936523,
      "learning_rate": 3.0977777777777776e-05,
      "loss": 0.002,
      "step": 8560
    },
    {
      "epoch": 0.3808888888888889,
      "grad_norm": 0.26161670684814453,
      "learning_rate": 3.0955555555555557e-05,
      "loss": 0.0018,
      "step": 8570
    },
    {
      "epoch": 0.38133333333333336,
      "grad_norm": 0.371433824300766,
      "learning_rate": 3.093333333333334e-05,
      "loss": 0.0018,
      "step": 8580
    },
    {
      "epoch": 0.38177777777777777,
      "grad_norm": 0.3172776401042938,
      "learning_rate": 3.091111111111111e-05,
      "loss": 0.0018,
      "step": 8590
    },
    {
      "epoch": 0.38222222222222224,
      "grad_norm": 0.4417807161808014,
      "learning_rate": 3.088888888888889e-05,
      "loss": 0.0017,
      "step": 8600
    },
    {
      "epoch": 0.38266666666666665,
      "grad_norm": 0.022531770169734955,
      "learning_rate": 3.086666666666667e-05,
      "loss": 0.0022,
      "step": 8610
    },
    {
      "epoch": 0.3831111111111111,
      "grad_norm": 0.38023075461387634,
      "learning_rate": 3.084444444444445e-05,
      "loss": 0.0019,
      "step": 8620
    },
    {
      "epoch": 0.38355555555555554,
      "grad_norm": 0.564495861530304,
      "learning_rate": 3.082222222222222e-05,
      "loss": 0.0018,
      "step": 8630
    },
    {
      "epoch": 0.384,
      "grad_norm": 0.45359519124031067,
      "learning_rate": 3.08e-05,
      "loss": 0.0025,
      "step": 8640
    },
    {
      "epoch": 0.3844444444444444,
      "grad_norm": 0.24733026325702667,
      "learning_rate": 3.077777777777778e-05,
      "loss": 0.0017,
      "step": 8650
    },
    {
      "epoch": 0.3848888888888889,
      "grad_norm": 0.04655863717198372,
      "learning_rate": 3.075555555555556e-05,
      "loss": 0.0018,
      "step": 8660
    },
    {
      "epoch": 0.38533333333333336,
      "grad_norm": 0.3300914466381073,
      "learning_rate": 3.073333333333334e-05,
      "loss": 0.0017,
      "step": 8670
    },
    {
      "epoch": 0.3857777777777778,
      "grad_norm": 0.03237676993012428,
      "learning_rate": 3.0711111111111114e-05,
      "loss": 0.0016,
      "step": 8680
    },
    {
      "epoch": 0.38622222222222224,
      "grad_norm": 0.05706126242876053,
      "learning_rate": 3.068888888888889e-05,
      "loss": 0.0017,
      "step": 8690
    },
    {
      "epoch": 0.38666666666666666,
      "grad_norm": 0.43231719732284546,
      "learning_rate": 3.066666666666667e-05,
      "loss": 0.0022,
      "step": 8700
    },
    {
      "epoch": 0.38711111111111113,
      "grad_norm": 0.4945580065250397,
      "learning_rate": 3.064444444444445e-05,
      "loss": 0.0019,
      "step": 8710
    },
    {
      "epoch": 0.38755555555555554,
      "grad_norm": 0.1394568830728531,
      "learning_rate": 3.0622222222222224e-05,
      "loss": 0.0021,
      "step": 8720
    },
    {
      "epoch": 0.388,
      "grad_norm": 0.2894388437271118,
      "learning_rate": 3.06e-05,
      "loss": 0.002,
      "step": 8730
    },
    {
      "epoch": 0.3884444444444444,
      "grad_norm": 0.7978606224060059,
      "learning_rate": 3.057777777777778e-05,
      "loss": 0.0018,
      "step": 8740
    },
    {
      "epoch": 0.3888888888888889,
      "grad_norm": 0.1817122846841812,
      "learning_rate": 3.055555555555556e-05,
      "loss": 0.0021,
      "step": 8750
    },
    {
      "epoch": 0.3893333333333333,
      "grad_norm": 0.3162882924079895,
      "learning_rate": 3.0533333333333335e-05,
      "loss": 0.0017,
      "step": 8760
    },
    {
      "epoch": 0.3897777777777778,
      "grad_norm": 0.525026798248291,
      "learning_rate": 3.0511111111111112e-05,
      "loss": 0.0025,
      "step": 8770
    },
    {
      "epoch": 0.39022222222222225,
      "grad_norm": 0.20760078728199005,
      "learning_rate": 3.048888888888889e-05,
      "loss": 0.0021,
      "step": 8780
    },
    {
      "epoch": 0.39066666666666666,
      "grad_norm": 0.024570249021053314,
      "learning_rate": 3.0466666666666664e-05,
      "loss": 0.0019,
      "step": 8790
    },
    {
      "epoch": 0.39111111111111113,
      "grad_norm": 0.08395129442214966,
      "learning_rate": 3.044444444444445e-05,
      "loss": 0.0021,
      "step": 8800
    },
    {
      "epoch": 0.39155555555555555,
      "grad_norm": 0.43973803520202637,
      "learning_rate": 3.0422222222222223e-05,
      "loss": 0.002,
      "step": 8810
    },
    {
      "epoch": 0.392,
      "grad_norm": 0.20747239887714386,
      "learning_rate": 3.04e-05,
      "loss": 0.0018,
      "step": 8820
    },
    {
      "epoch": 0.39244444444444443,
      "grad_norm": 0.3860238790512085,
      "learning_rate": 3.0377777777777778e-05,
      "loss": 0.0026,
      "step": 8830
    },
    {
      "epoch": 0.3928888888888889,
      "grad_norm": 0.3163036108016968,
      "learning_rate": 3.035555555555556e-05,
      "loss": 0.0023,
      "step": 8840
    },
    {
      "epoch": 0.3933333333333333,
      "grad_norm": 0.23476070165634155,
      "learning_rate": 3.0333333333333337e-05,
      "loss": 0.0016,
      "step": 8850
    },
    {
      "epoch": 0.3937777777777778,
      "grad_norm": 0.10136192291975021,
      "learning_rate": 3.031111111111111e-05,
      "loss": 0.002,
      "step": 8860
    },
    {
      "epoch": 0.3942222222222222,
      "grad_norm": 0.4117760956287384,
      "learning_rate": 3.028888888888889e-05,
      "loss": 0.0019,
      "step": 8870
    },
    {
      "epoch": 0.39466666666666667,
      "grad_norm": 0.3308617174625397,
      "learning_rate": 3.0266666666666666e-05,
      "loss": 0.0017,
      "step": 8880
    },
    {
      "epoch": 0.39511111111111114,
      "grad_norm": 0.16705866158008575,
      "learning_rate": 3.0244444444444447e-05,
      "loss": 0.0018,
      "step": 8890
    },
    {
      "epoch": 0.39555555555555555,
      "grad_norm": 0.2752157151699066,
      "learning_rate": 3.0222222222222225e-05,
      "loss": 0.0018,
      "step": 8900
    },
    {
      "epoch": 0.396,
      "grad_norm": 0.248306006193161,
      "learning_rate": 3.02e-05,
      "loss": 0.0018,
      "step": 8910
    },
    {
      "epoch": 0.39644444444444443,
      "grad_norm": 0.20824487507343292,
      "learning_rate": 3.0177777777777776e-05,
      "loss": 0.0018,
      "step": 8920
    },
    {
      "epoch": 0.3968888888888889,
      "grad_norm": 0.04575498774647713,
      "learning_rate": 3.0155555555555557e-05,
      "loss": 0.0023,
      "step": 8930
    },
    {
      "epoch": 0.3973333333333333,
      "grad_norm": 0.3606063723564148,
      "learning_rate": 3.0133333333333335e-05,
      "loss": 0.0025,
      "step": 8940
    },
    {
      "epoch": 0.3977777777777778,
      "grad_norm": 0.3039596974849701,
      "learning_rate": 3.0111111111111113e-05,
      "loss": 0.0026,
      "step": 8950
    },
    {
      "epoch": 0.3982222222222222,
      "grad_norm": 0.07046573609113693,
      "learning_rate": 3.008888888888889e-05,
      "loss": 0.002,
      "step": 8960
    },
    {
      "epoch": 0.39866666666666667,
      "grad_norm": 0.3311172127723694,
      "learning_rate": 3.006666666666667e-05,
      "loss": 0.0022,
      "step": 8970
    },
    {
      "epoch": 0.39911111111111114,
      "grad_norm": 0.26209375262260437,
      "learning_rate": 3.004444444444445e-05,
      "loss": 0.0016,
      "step": 8980
    },
    {
      "epoch": 0.39955555555555555,
      "grad_norm": 0.2230532467365265,
      "learning_rate": 3.0022222222222223e-05,
      "loss": 0.002,
      "step": 8990
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.13052882254123688,
      "learning_rate": 3e-05,
      "loss": 0.0018,
      "step": 9000
    },
    {
      "epoch": 0.40044444444444444,
      "grad_norm": 0.4421435594558716,
      "learning_rate": 2.997777777777778e-05,
      "loss": 0.0024,
      "step": 9010
    },
    {
      "epoch": 0.4008888888888889,
      "grad_norm": 0.19227628409862518,
      "learning_rate": 2.995555555555556e-05,
      "loss": 0.002,
      "step": 9020
    },
    {
      "epoch": 0.4013333333333333,
      "grad_norm": 0.11240198463201523,
      "learning_rate": 2.9933333333333337e-05,
      "loss": 0.0018,
      "step": 9030
    },
    {
      "epoch": 0.4017777777777778,
      "grad_norm": 0.4536508321762085,
      "learning_rate": 2.991111111111111e-05,
      "loss": 0.0032,
      "step": 9040
    },
    {
      "epoch": 0.4022222222222222,
      "grad_norm": 0.11581932008266449,
      "learning_rate": 2.988888888888889e-05,
      "loss": 0.0016,
      "step": 9050
    },
    {
      "epoch": 0.4026666666666667,
      "grad_norm": 0.5361680388450623,
      "learning_rate": 2.986666666666667e-05,
      "loss": 0.0019,
      "step": 9060
    },
    {
      "epoch": 0.4031111111111111,
      "grad_norm": 0.29006314277648926,
      "learning_rate": 2.9844444444444447e-05,
      "loss": 0.0022,
      "step": 9070
    },
    {
      "epoch": 0.40355555555555556,
      "grad_norm": 0.4946085512638092,
      "learning_rate": 2.9822222222222225e-05,
      "loss": 0.0026,
      "step": 9080
    },
    {
      "epoch": 0.404,
      "grad_norm": 0.1792224943637848,
      "learning_rate": 2.98e-05,
      "loss": 0.0019,
      "step": 9090
    },
    {
      "epoch": 0.40444444444444444,
      "grad_norm": 0.16845445334911346,
      "learning_rate": 2.9777777777777777e-05,
      "loss": 0.0018,
      "step": 9100
    },
    {
      "epoch": 0.4048888888888889,
      "grad_norm": 0.3591485917568207,
      "learning_rate": 2.9755555555555558e-05,
      "loss": 0.0019,
      "step": 9110
    },
    {
      "epoch": 0.4053333333333333,
      "grad_norm": 0.3990466296672821,
      "learning_rate": 2.9733333333333336e-05,
      "loss": 0.0024,
      "step": 9120
    },
    {
      "epoch": 0.4057777777777778,
      "grad_norm": 0.05856514722108841,
      "learning_rate": 2.9711111111111113e-05,
      "loss": 0.0017,
      "step": 9130
    },
    {
      "epoch": 0.4062222222222222,
      "grad_norm": 0.22218897938728333,
      "learning_rate": 2.9688888888888887e-05,
      "loss": 0.0018,
      "step": 9140
    },
    {
      "epoch": 0.4066666666666667,
      "grad_norm": 0.5235646963119507,
      "learning_rate": 2.9666666666666672e-05,
      "loss": 0.0024,
      "step": 9150
    },
    {
      "epoch": 0.4071111111111111,
      "grad_norm": 0.09810223430395126,
      "learning_rate": 2.9644444444444446e-05,
      "loss": 0.0024,
      "step": 9160
    },
    {
      "epoch": 0.40755555555555556,
      "grad_norm": 0.10171286761760712,
      "learning_rate": 2.9622222222222224e-05,
      "loss": 0.0021,
      "step": 9170
    },
    {
      "epoch": 0.408,
      "grad_norm": 0.09969067573547363,
      "learning_rate": 2.96e-05,
      "loss": 0.0027,
      "step": 9180
    },
    {
      "epoch": 0.40844444444444444,
      "grad_norm": 0.5514262914657593,
      "learning_rate": 2.9577777777777775e-05,
      "loss": 0.002,
      "step": 9190
    },
    {
      "epoch": 0.4088888888888889,
      "grad_norm": 0.4847358167171478,
      "learning_rate": 2.955555555555556e-05,
      "loss": 0.0019,
      "step": 9200
    },
    {
      "epoch": 0.4093333333333333,
      "grad_norm": 0.034964803606271744,
      "learning_rate": 2.9533333333333334e-05,
      "loss": 0.0018,
      "step": 9210
    },
    {
      "epoch": 0.4097777777777778,
      "grad_norm": 0.19322732090950012,
      "learning_rate": 2.951111111111111e-05,
      "loss": 0.0021,
      "step": 9220
    },
    {
      "epoch": 0.4102222222222222,
      "grad_norm": 0.5087286233901978,
      "learning_rate": 2.948888888888889e-05,
      "loss": 0.0017,
      "step": 9230
    },
    {
      "epoch": 0.4106666666666667,
      "grad_norm": 0.38505449891090393,
      "learning_rate": 2.946666666666667e-05,
      "loss": 0.0021,
      "step": 9240
    },
    {
      "epoch": 0.4111111111111111,
      "grad_norm": 0.13225284218788147,
      "learning_rate": 2.9444444444444448e-05,
      "loss": 0.0018,
      "step": 9250
    },
    {
      "epoch": 0.41155555555555556,
      "grad_norm": 0.24779805541038513,
      "learning_rate": 2.9422222222222222e-05,
      "loss": 0.0023,
      "step": 9260
    },
    {
      "epoch": 0.412,
      "grad_norm": 0.12539364397525787,
      "learning_rate": 2.94e-05,
      "loss": 0.0022,
      "step": 9270
    },
    {
      "epoch": 0.41244444444444445,
      "grad_norm": 0.15292076766490936,
      "learning_rate": 2.937777777777778e-05,
      "loss": 0.0015,
      "step": 9280
    },
    {
      "epoch": 0.4128888888888889,
      "grad_norm": 0.5230079293251038,
      "learning_rate": 2.935555555555556e-05,
      "loss": 0.0019,
      "step": 9290
    },
    {
      "epoch": 0.41333333333333333,
      "grad_norm": 0.08508139848709106,
      "learning_rate": 2.9333333333333336e-05,
      "loss": 0.0021,
      "step": 9300
    },
    {
      "epoch": 0.4137777777777778,
      "grad_norm": 0.49466192722320557,
      "learning_rate": 2.931111111111111e-05,
      "loss": 0.0017,
      "step": 9310
    },
    {
      "epoch": 0.4142222222222222,
      "grad_norm": 0.27622362971305847,
      "learning_rate": 2.9288888888888888e-05,
      "loss": 0.0016,
      "step": 9320
    },
    {
      "epoch": 0.4146666666666667,
      "grad_norm": 0.45465749502182007,
      "learning_rate": 2.926666666666667e-05,
      "loss": 0.002,
      "step": 9330
    },
    {
      "epoch": 0.4151111111111111,
      "grad_norm": 0.3129892945289612,
      "learning_rate": 2.9244444444444446e-05,
      "loss": 0.0026,
      "step": 9340
    },
    {
      "epoch": 0.41555555555555557,
      "grad_norm": 0.048357244580984116,
      "learning_rate": 2.9222222222222224e-05,
      "loss": 0.0018,
      "step": 9350
    },
    {
      "epoch": 0.416,
      "grad_norm": 0.11037199944257736,
      "learning_rate": 2.9199999999999998e-05,
      "loss": 0.0019,
      "step": 9360
    },
    {
      "epoch": 0.41644444444444445,
      "grad_norm": 0.36783474683761597,
      "learning_rate": 2.9177777777777783e-05,
      "loss": 0.0024,
      "step": 9370
    },
    {
      "epoch": 0.41688888888888886,
      "grad_norm": 0.30207154154777527,
      "learning_rate": 2.9155555555555557e-05,
      "loss": 0.0029,
      "step": 9380
    },
    {
      "epoch": 0.41733333333333333,
      "grad_norm": 0.5359537601470947,
      "learning_rate": 2.9133333333333334e-05,
      "loss": 0.0018,
      "step": 9390
    },
    {
      "epoch": 0.4177777777777778,
      "grad_norm": 0.05675235018134117,
      "learning_rate": 2.9111111111111112e-05,
      "loss": 0.0018,
      "step": 9400
    },
    {
      "epoch": 0.4182222222222222,
      "grad_norm": 0.08345626294612885,
      "learning_rate": 2.9088888888888886e-05,
      "loss": 0.0018,
      "step": 9410
    },
    {
      "epoch": 0.4186666666666667,
      "grad_norm": 0.13522270321846008,
      "learning_rate": 2.906666666666667e-05,
      "loss": 0.0018,
      "step": 9420
    },
    {
      "epoch": 0.4191111111111111,
      "grad_norm": 0.3674933910369873,
      "learning_rate": 2.9044444444444445e-05,
      "loss": 0.0018,
      "step": 9430
    },
    {
      "epoch": 0.41955555555555557,
      "grad_norm": 0.04330256208777428,
      "learning_rate": 2.9022222222222223e-05,
      "loss": 0.0022,
      "step": 9440
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.08475740998983383,
      "learning_rate": 2.9e-05,
      "loss": 0.0019,
      "step": 9450
    },
    {
      "epoch": 0.42044444444444445,
      "grad_norm": 0.15194745361804962,
      "learning_rate": 2.897777777777778e-05,
      "loss": 0.0021,
      "step": 9460
    },
    {
      "epoch": 0.42088888888888887,
      "grad_norm": 0.08598119765520096,
      "learning_rate": 2.895555555555556e-05,
      "loss": 0.002,
      "step": 9470
    },
    {
      "epoch": 0.42133333333333334,
      "grad_norm": 0.047023553401231766,
      "learning_rate": 2.8933333333333333e-05,
      "loss": 0.0021,
      "step": 9480
    },
    {
      "epoch": 0.42177777777777775,
      "grad_norm": 0.30281996726989746,
      "learning_rate": 2.891111111111111e-05,
      "loss": 0.0019,
      "step": 9490
    },
    {
      "epoch": 0.4222222222222222,
      "grad_norm": 0.40686744451522827,
      "learning_rate": 2.8888888888888888e-05,
      "loss": 0.0019,
      "step": 9500
    },
    {
      "epoch": 0.4226666666666667,
      "grad_norm": 0.4536742866039276,
      "learning_rate": 2.886666666666667e-05,
      "loss": 0.0021,
      "step": 9510
    },
    {
      "epoch": 0.4231111111111111,
      "grad_norm": 0.17925047874450684,
      "learning_rate": 2.8844444444444447e-05,
      "loss": 0.0016,
      "step": 9520
    },
    {
      "epoch": 0.4235555555555556,
      "grad_norm": 0.021613480523228645,
      "learning_rate": 2.882222222222222e-05,
      "loss": 0.0023,
      "step": 9530
    },
    {
      "epoch": 0.424,
      "grad_norm": 0.4401879906654358,
      "learning_rate": 2.88e-05,
      "loss": 0.0017,
      "step": 9540
    },
    {
      "epoch": 0.42444444444444446,
      "grad_norm": 0.6610695123672485,
      "learning_rate": 2.877777777777778e-05,
      "loss": 0.0022,
      "step": 9550
    },
    {
      "epoch": 0.42488888888888887,
      "grad_norm": 0.41275325417518616,
      "learning_rate": 2.8755555555555557e-05,
      "loss": 0.0017,
      "step": 9560
    },
    {
      "epoch": 0.42533333333333334,
      "grad_norm": 0.6465375423431396,
      "learning_rate": 2.8733333333333335e-05,
      "loss": 0.0017,
      "step": 9570
    },
    {
      "epoch": 0.42577777777777776,
      "grad_norm": 0.37201836705207825,
      "learning_rate": 2.8711111111111113e-05,
      "loss": 0.002,
      "step": 9580
    },
    {
      "epoch": 0.4262222222222222,
      "grad_norm": 0.13104376196861267,
      "learning_rate": 2.8688888888888894e-05,
      "loss": 0.0022,
      "step": 9590
    },
    {
      "epoch": 0.4266666666666667,
      "grad_norm": 0.288265585899353,
      "learning_rate": 2.8666666666666668e-05,
      "loss": 0.0019,
      "step": 9600
    },
    {
      "epoch": 0.4271111111111111,
      "grad_norm": 0.048357781022787094,
      "learning_rate": 2.8644444444444445e-05,
      "loss": 0.0025,
      "step": 9610
    },
    {
      "epoch": 0.4275555555555556,
      "grad_norm": 0.17927512526512146,
      "learning_rate": 2.8622222222222223e-05,
      "loss": 0.002,
      "step": 9620
    },
    {
      "epoch": 0.428,
      "grad_norm": 0.48186299204826355,
      "learning_rate": 2.86e-05,
      "loss": 0.002,
      "step": 9630
    },
    {
      "epoch": 0.42844444444444446,
      "grad_norm": 0.31606394052505493,
      "learning_rate": 2.857777777777778e-05,
      "loss": 0.0018,
      "step": 9640
    },
    {
      "epoch": 0.4288888888888889,
      "grad_norm": 0.03137398138642311,
      "learning_rate": 2.855555555555556e-05,
      "loss": 0.0023,
      "step": 9650
    },
    {
      "epoch": 0.42933333333333334,
      "grad_norm": 0.17441703379154205,
      "learning_rate": 2.8533333333333333e-05,
      "loss": 0.0019,
      "step": 9660
    },
    {
      "epoch": 0.42977777777777776,
      "grad_norm": 0.15185105800628662,
      "learning_rate": 2.851111111111111e-05,
      "loss": 0.0044,
      "step": 9670
    },
    {
      "epoch": 0.43022222222222223,
      "grad_norm": 0.3859485387802124,
      "learning_rate": 2.8488888888888892e-05,
      "loss": 0.002,
      "step": 9680
    },
    {
      "epoch": 0.43066666666666664,
      "grad_norm": 0.2623445391654968,
      "learning_rate": 2.846666666666667e-05,
      "loss": 0.0022,
      "step": 9690
    },
    {
      "epoch": 0.4311111111111111,
      "grad_norm": 0.6208088397979736,
      "learning_rate": 2.8444444444444447e-05,
      "loss": 0.0018,
      "step": 9700
    },
    {
      "epoch": 0.4315555555555556,
      "grad_norm": 0.13940812647342682,
      "learning_rate": 2.842222222222222e-05,
      "loss": 0.0019,
      "step": 9710
    },
    {
      "epoch": 0.432,
      "grad_norm": 0.08536412566900253,
      "learning_rate": 2.84e-05,
      "loss": 0.0022,
      "step": 9720
    },
    {
      "epoch": 0.43244444444444446,
      "grad_norm": 0.09649550169706345,
      "learning_rate": 2.837777777777778e-05,
      "loss": 0.0019,
      "step": 9730
    },
    {
      "epoch": 0.4328888888888889,
      "grad_norm": 0.08553635329008102,
      "learning_rate": 2.8355555555555558e-05,
      "loss": 0.0017,
      "step": 9740
    },
    {
      "epoch": 0.43333333333333335,
      "grad_norm": 0.34486231207847595,
      "learning_rate": 2.8333333333333335e-05,
      "loss": 0.002,
      "step": 9750
    },
    {
      "epoch": 0.43377777777777776,
      "grad_norm": 0.412423700094223,
      "learning_rate": 2.831111111111111e-05,
      "loss": 0.0019,
      "step": 9760
    },
    {
      "epoch": 0.43422222222222223,
      "grad_norm": 0.26295608282089233,
      "learning_rate": 2.8288888888888894e-05,
      "loss": 0.0018,
      "step": 9770
    },
    {
      "epoch": 0.43466666666666665,
      "grad_norm": 0.2750834822654724,
      "learning_rate": 2.8266666666666668e-05,
      "loss": 0.0017,
      "step": 9780
    },
    {
      "epoch": 0.4351111111111111,
      "grad_norm": 0.15206825733184814,
      "learning_rate": 2.8244444444444446e-05,
      "loss": 0.0022,
      "step": 9790
    },
    {
      "epoch": 0.43555555555555553,
      "grad_norm": 0.3164009153842926,
      "learning_rate": 2.8222222222222223e-05,
      "loss": 0.0023,
      "step": 9800
    },
    {
      "epoch": 0.436,
      "grad_norm": 0.07338332384824753,
      "learning_rate": 2.8199999999999998e-05,
      "loss": 0.0016,
      "step": 9810
    },
    {
      "epoch": 0.43644444444444447,
      "grad_norm": 0.20748883485794067,
      "learning_rate": 2.8177777777777782e-05,
      "loss": 0.0018,
      "step": 9820
    },
    {
      "epoch": 0.4368888888888889,
      "grad_norm": 0.1241057962179184,
      "learning_rate": 2.8155555555555556e-05,
      "loss": 0.0017,
      "step": 9830
    },
    {
      "epoch": 0.43733333333333335,
      "grad_norm": 0.26176533102989197,
      "learning_rate": 2.8133333333333334e-05,
      "loss": 0.002,
      "step": 9840
    },
    {
      "epoch": 0.43777777777777777,
      "grad_norm": 0.49557414650917053,
      "learning_rate": 2.811111111111111e-05,
      "loss": 0.0017,
      "step": 9850
    },
    {
      "epoch": 0.43822222222222224,
      "grad_norm": 0.6742783784866333,
      "learning_rate": 2.8088888888888893e-05,
      "loss": 0.0022,
      "step": 9860
    },
    {
      "epoch": 0.43866666666666665,
      "grad_norm": 0.6460348963737488,
      "learning_rate": 2.806666666666667e-05,
      "loss": 0.0017,
      "step": 9870
    },
    {
      "epoch": 0.4391111111111111,
      "grad_norm": 0.4008508026599884,
      "learning_rate": 2.8044444444444444e-05,
      "loss": 0.0018,
      "step": 9880
    },
    {
      "epoch": 0.43955555555555553,
      "grad_norm": 0.04226483032107353,
      "learning_rate": 2.8022222222222222e-05,
      "loss": 0.0018,
      "step": 9890
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.20613566040992737,
      "learning_rate": 2.8000000000000003e-05,
      "loss": 0.0019,
      "step": 9900
    },
    {
      "epoch": 0.44044444444444447,
      "grad_norm": 0.6189021468162537,
      "learning_rate": 2.797777777777778e-05,
      "loss": 0.002,
      "step": 9910
    },
    {
      "epoch": 0.4408888888888889,
      "grad_norm": 0.04392392188310623,
      "learning_rate": 2.7955555555555558e-05,
      "loss": 0.0024,
      "step": 9920
    },
    {
      "epoch": 0.44133333333333336,
      "grad_norm": 0.08295414596796036,
      "learning_rate": 2.7933333333333332e-05,
      "loss": 0.0019,
      "step": 9930
    },
    {
      "epoch": 0.44177777777777777,
      "grad_norm": 0.24934767186641693,
      "learning_rate": 2.791111111111111e-05,
      "loss": 0.002,
      "step": 9940
    },
    {
      "epoch": 0.44222222222222224,
      "grad_norm": 0.6602951288223267,
      "learning_rate": 2.788888888888889e-05,
      "loss": 0.0016,
      "step": 9950
    },
    {
      "epoch": 0.44266666666666665,
      "grad_norm": 0.26274171471595764,
      "learning_rate": 2.786666666666667e-05,
      "loss": 0.0017,
      "step": 9960
    },
    {
      "epoch": 0.4431111111111111,
      "grad_norm": 0.22024528682231903,
      "learning_rate": 2.7844444444444446e-05,
      "loss": 0.0018,
      "step": 9970
    },
    {
      "epoch": 0.44355555555555554,
      "grad_norm": 0.12579330801963806,
      "learning_rate": 2.782222222222222e-05,
      "loss": 0.0021,
      "step": 9980
    },
    {
      "epoch": 0.444,
      "grad_norm": 0.030581960454583168,
      "learning_rate": 2.7800000000000005e-05,
      "loss": 0.002,
      "step": 9990
    },
    {
      "epoch": 0.4444444444444444,
      "grad_norm": 0.32931745052337646,
      "learning_rate": 2.777777777777778e-05,
      "loss": 0.0025,
      "step": 10000
    },
    {
      "epoch": 0.4448888888888889,
      "grad_norm": 0.02130981720983982,
      "learning_rate": 2.7755555555555557e-05,
      "loss": 0.0021,
      "step": 10010
    },
    {
      "epoch": 0.44533333333333336,
      "grad_norm": 0.5896783471107483,
      "learning_rate": 2.7733333333333334e-05,
      "loss": 0.0021,
      "step": 10020
    },
    {
      "epoch": 0.4457777777777778,
      "grad_norm": 0.16548407077789307,
      "learning_rate": 2.771111111111111e-05,
      "loss": 0.0015,
      "step": 10030
    },
    {
      "epoch": 0.44622222222222224,
      "grad_norm": 0.12490434944629669,
      "learning_rate": 2.7688888888888893e-05,
      "loss": 0.002,
      "step": 10040
    },
    {
      "epoch": 0.44666666666666666,
      "grad_norm": 0.049329452216625214,
      "learning_rate": 2.7666666666666667e-05,
      "loss": 0.0017,
      "step": 10050
    },
    {
      "epoch": 0.4471111111111111,
      "grad_norm": 0.38411733508110046,
      "learning_rate": 2.7644444444444445e-05,
      "loss": 0.0017,
      "step": 10060
    },
    {
      "epoch": 0.44755555555555554,
      "grad_norm": 0.04418875649571419,
      "learning_rate": 2.7622222222222222e-05,
      "loss": 0.0017,
      "step": 10070
    },
    {
      "epoch": 0.448,
      "grad_norm": 0.23492920398712158,
      "learning_rate": 2.7600000000000003e-05,
      "loss": 0.0017,
      "step": 10080
    },
    {
      "epoch": 0.4484444444444444,
      "grad_norm": 0.16632919013500214,
      "learning_rate": 2.757777777777778e-05,
      "loss": 0.0018,
      "step": 10090
    },
    {
      "epoch": 0.4488888888888889,
      "grad_norm": 0.45341411232948303,
      "learning_rate": 2.7555555555555555e-05,
      "loss": 0.002,
      "step": 10100
    },
    {
      "epoch": 0.4493333333333333,
      "grad_norm": 0.1125291958451271,
      "learning_rate": 2.7533333333333333e-05,
      "loss": 0.0017,
      "step": 10110
    },
    {
      "epoch": 0.4497777777777778,
      "grad_norm": 0.04394087940454483,
      "learning_rate": 2.751111111111111e-05,
      "loss": 0.0021,
      "step": 10120
    },
    {
      "epoch": 0.45022222222222225,
      "grad_norm": 0.4277127981185913,
      "learning_rate": 2.748888888888889e-05,
      "loss": 0.0023,
      "step": 10130
    },
    {
      "epoch": 0.45066666666666666,
      "grad_norm": 0.13922369480133057,
      "learning_rate": 2.746666666666667e-05,
      "loss": 0.0018,
      "step": 10140
    },
    {
      "epoch": 0.45111111111111113,
      "grad_norm": 0.371273010969162,
      "learning_rate": 2.7444444444444443e-05,
      "loss": 0.0022,
      "step": 10150
    },
    {
      "epoch": 0.45155555555555554,
      "grad_norm": 0.2542140483856201,
      "learning_rate": 2.742222222222222e-05,
      "loss": 0.0022,
      "step": 10160
    },
    {
      "epoch": 0.452,
      "grad_norm": 0.27801015973091125,
      "learning_rate": 2.7400000000000002e-05,
      "loss": 0.0021,
      "step": 10170
    },
    {
      "epoch": 0.4524444444444444,
      "grad_norm": 0.3024035096168518,
      "learning_rate": 2.737777777777778e-05,
      "loss": 0.002,
      "step": 10180
    },
    {
      "epoch": 0.4528888888888889,
      "grad_norm": 0.31710243225097656,
      "learning_rate": 2.7355555555555557e-05,
      "loss": 0.0018,
      "step": 10190
    },
    {
      "epoch": 0.4533333333333333,
      "grad_norm": 0.09850708395242691,
      "learning_rate": 2.733333333333333e-05,
      "loss": 0.0018,
      "step": 10200
    },
    {
      "epoch": 0.4537777777777778,
      "grad_norm": 0.11194591969251633,
      "learning_rate": 2.7311111111111116e-05,
      "loss": 0.0021,
      "step": 10210
    },
    {
      "epoch": 0.45422222222222225,
      "grad_norm": 0.19255225360393524,
      "learning_rate": 2.728888888888889e-05,
      "loss": 0.0018,
      "step": 10220
    },
    {
      "epoch": 0.45466666666666666,
      "grad_norm": 0.03196123242378235,
      "learning_rate": 2.7266666666666668e-05,
      "loss": 0.002,
      "step": 10230
    },
    {
      "epoch": 0.45511111111111113,
      "grad_norm": 0.3982183635234833,
      "learning_rate": 2.7244444444444445e-05,
      "loss": 0.0024,
      "step": 10240
    },
    {
      "epoch": 0.45555555555555555,
      "grad_norm": 0.014308513142168522,
      "learning_rate": 2.7222222222222223e-05,
      "loss": 0.002,
      "step": 10250
    },
    {
      "epoch": 0.456,
      "grad_norm": 0.23544076085090637,
      "learning_rate": 2.7200000000000004e-05,
      "loss": 0.002,
      "step": 10260
    },
    {
      "epoch": 0.45644444444444443,
      "grad_norm": 0.05687011405825615,
      "learning_rate": 2.717777777777778e-05,
      "loss": 0.0018,
      "step": 10270
    },
    {
      "epoch": 0.4568888888888889,
      "grad_norm": 0.05785286799073219,
      "learning_rate": 2.7155555555555556e-05,
      "loss": 0.0019,
      "step": 10280
    },
    {
      "epoch": 0.4573333333333333,
      "grad_norm": 0.6317675113677979,
      "learning_rate": 2.7133333333333333e-05,
      "loss": 0.002,
      "step": 10290
    },
    {
      "epoch": 0.4577777777777778,
      "grad_norm": 0.28921282291412354,
      "learning_rate": 2.7111111111111114e-05,
      "loss": 0.0017,
      "step": 10300
    },
    {
      "epoch": 0.4582222222222222,
      "grad_norm": 0.3334338366985321,
      "learning_rate": 2.7088888888888892e-05,
      "loss": 0.0024,
      "step": 10310
    },
    {
      "epoch": 0.45866666666666667,
      "grad_norm": 0.20604963600635529,
      "learning_rate": 2.706666666666667e-05,
      "loss": 0.0019,
      "step": 10320
    },
    {
      "epoch": 0.45911111111111114,
      "grad_norm": 0.4264373183250427,
      "learning_rate": 2.7044444444444444e-05,
      "loss": 0.0022,
      "step": 10330
    },
    {
      "epoch": 0.45955555555555555,
      "grad_norm": 0.1801835596561432,
      "learning_rate": 2.702222222222222e-05,
      "loss": 0.0015,
      "step": 10340
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.0436197891831398,
      "learning_rate": 2.7000000000000002e-05,
      "loss": 0.0022,
      "step": 10350
    },
    {
      "epoch": 0.46044444444444443,
      "grad_norm": 0.08661260455846786,
      "learning_rate": 2.697777777777778e-05,
      "loss": 0.002,
      "step": 10360
    },
    {
      "epoch": 0.4608888888888889,
      "grad_norm": 0.4407045543193817,
      "learning_rate": 2.6955555555555558e-05,
      "loss": 0.0016,
      "step": 10370
    },
    {
      "epoch": 0.4613333333333333,
      "grad_norm": 0.0852932557463646,
      "learning_rate": 2.6933333333333332e-05,
      "loss": 0.0024,
      "step": 10380
    },
    {
      "epoch": 0.4617777777777778,
      "grad_norm": 0.4394032061100006,
      "learning_rate": 2.6911111111111116e-05,
      "loss": 0.002,
      "step": 10390
    },
    {
      "epoch": 0.4622222222222222,
      "grad_norm": 0.2624111771583557,
      "learning_rate": 2.688888888888889e-05,
      "loss": 0.0021,
      "step": 10400
    },
    {
      "epoch": 0.46266666666666667,
      "grad_norm": 0.036451928317546844,
      "learning_rate": 2.6866666666666668e-05,
      "loss": 0.0019,
      "step": 10410
    },
    {
      "epoch": 0.4631111111111111,
      "grad_norm": 0.026009200140833855,
      "learning_rate": 2.6844444444444446e-05,
      "loss": 0.0023,
      "step": 10420
    },
    {
      "epoch": 0.46355555555555555,
      "grad_norm": 0.2753346264362335,
      "learning_rate": 2.682222222222222e-05,
      "loss": 0.0023,
      "step": 10430
    },
    {
      "epoch": 0.464,
      "grad_norm": 0.16548675298690796,
      "learning_rate": 2.6800000000000004e-05,
      "loss": 0.0017,
      "step": 10440
    },
    {
      "epoch": 0.46444444444444444,
      "grad_norm": 0.031020741909742355,
      "learning_rate": 2.677777777777778e-05,
      "loss": 0.0018,
      "step": 10450
    },
    {
      "epoch": 0.4648888888888889,
      "grad_norm": 0.09862998872995377,
      "learning_rate": 2.6755555555555556e-05,
      "loss": 0.0018,
      "step": 10460
    },
    {
      "epoch": 0.4653333333333333,
      "grad_norm": 0.24698135256767273,
      "learning_rate": 2.6733333333333334e-05,
      "loss": 0.0018,
      "step": 10470
    },
    {
      "epoch": 0.4657777777777778,
      "grad_norm": 0.3162999451160431,
      "learning_rate": 2.6711111111111115e-05,
      "loss": 0.002,
      "step": 10480
    },
    {
      "epoch": 0.4662222222222222,
      "grad_norm": 0.12424656003713608,
      "learning_rate": 2.6688888888888892e-05,
      "loss": 0.0017,
      "step": 10490
    },
    {
      "epoch": 0.4666666666666667,
      "grad_norm": 0.08635658025741577,
      "learning_rate": 2.6666666666666667e-05,
      "loss": 0.0018,
      "step": 10500
    },
    {
      "epoch": 0.4671111111111111,
      "grad_norm": 0.030597712844610214,
      "learning_rate": 2.6644444444444444e-05,
      "loss": 0.0023,
      "step": 10510
    },
    {
      "epoch": 0.46755555555555556,
      "grad_norm": 0.1706298440694809,
      "learning_rate": 2.6622222222222225e-05,
      "loss": 0.002,
      "step": 10520
    },
    {
      "epoch": 0.468,
      "grad_norm": 0.03426964208483696,
      "learning_rate": 2.6600000000000003e-05,
      "loss": 0.0017,
      "step": 10530
    },
    {
      "epoch": 0.46844444444444444,
      "grad_norm": 0.027985285967588425,
      "learning_rate": 2.657777777777778e-05,
      "loss": 0.0018,
      "step": 10540
    },
    {
      "epoch": 0.4688888888888889,
      "grad_norm": 0.24721376597881317,
      "learning_rate": 2.6555555555555555e-05,
      "loss": 0.002,
      "step": 10550
    },
    {
      "epoch": 0.4693333333333333,
      "grad_norm": 0.11427322030067444,
      "learning_rate": 2.6533333333333332e-05,
      "loss": 0.0017,
      "step": 10560
    },
    {
      "epoch": 0.4697777777777778,
      "grad_norm": 0.7014704346656799,
      "learning_rate": 2.6511111111111113e-05,
      "loss": 0.0018,
      "step": 10570
    },
    {
      "epoch": 0.4702222222222222,
      "grad_norm": 0.21934691071510315,
      "learning_rate": 2.648888888888889e-05,
      "loss": 0.0023,
      "step": 10580
    },
    {
      "epoch": 0.4706666666666667,
      "grad_norm": 0.12881915271282196,
      "learning_rate": 2.646666666666667e-05,
      "loss": 0.0018,
      "step": 10590
    },
    {
      "epoch": 0.4711111111111111,
      "grad_norm": 0.040458377450704575,
      "learning_rate": 2.6444444444444443e-05,
      "loss": 0.0019,
      "step": 10600
    },
    {
      "epoch": 0.47155555555555556,
      "grad_norm": 0.1527651846408844,
      "learning_rate": 2.6422222222222227e-05,
      "loss": 0.002,
      "step": 10610
    },
    {
      "epoch": 0.472,
      "grad_norm": 0.11477509140968323,
      "learning_rate": 2.64e-05,
      "loss": 0.0019,
      "step": 10620
    },
    {
      "epoch": 0.47244444444444444,
      "grad_norm": 0.41391152143478394,
      "learning_rate": 2.637777777777778e-05,
      "loss": 0.0017,
      "step": 10630
    },
    {
      "epoch": 0.4728888888888889,
      "grad_norm": 0.16633030772209167,
      "learning_rate": 2.6355555555555557e-05,
      "loss": 0.0018,
      "step": 10640
    },
    {
      "epoch": 0.47333333333333333,
      "grad_norm": 0.06086146831512451,
      "learning_rate": 2.633333333333333e-05,
      "loss": 0.0022,
      "step": 10650
    },
    {
      "epoch": 0.4737777777777778,
      "grad_norm": 0.3443567454814911,
      "learning_rate": 2.6311111111111115e-05,
      "loss": 0.002,
      "step": 10660
    },
    {
      "epoch": 0.4742222222222222,
      "grad_norm": 0.30291247367858887,
      "learning_rate": 2.628888888888889e-05,
      "loss": 0.0023,
      "step": 10670
    },
    {
      "epoch": 0.4746666666666667,
      "grad_norm": 0.2890472114086151,
      "learning_rate": 2.6266666666666667e-05,
      "loss": 0.0028,
      "step": 10680
    },
    {
      "epoch": 0.4751111111111111,
      "grad_norm": 0.0838327407836914,
      "learning_rate": 2.6244444444444445e-05,
      "loss": 0.0022,
      "step": 10690
    },
    {
      "epoch": 0.47555555555555556,
      "grad_norm": 0.24907323718070984,
      "learning_rate": 2.6222222222222226e-05,
      "loss": 0.0018,
      "step": 10700
    },
    {
      "epoch": 0.476,
      "grad_norm": 0.4064463973045349,
      "learning_rate": 2.6200000000000003e-05,
      "loss": 0.002,
      "step": 10710
    },
    {
      "epoch": 0.47644444444444445,
      "grad_norm": 0.16622304916381836,
      "learning_rate": 2.6177777777777777e-05,
      "loss": 0.0017,
      "step": 10720
    },
    {
      "epoch": 0.47688888888888886,
      "grad_norm": 0.3316335678100586,
      "learning_rate": 2.6155555555555555e-05,
      "loss": 0.002,
      "step": 10730
    },
    {
      "epoch": 0.47733333333333333,
      "grad_norm": 0.6199423670768738,
      "learning_rate": 2.6133333333333333e-05,
      "loss": 0.0015,
      "step": 10740
    },
    {
      "epoch": 0.4777777777777778,
      "grad_norm": 0.1517631858587265,
      "learning_rate": 2.6111111111111114e-05,
      "loss": 0.0018,
      "step": 10750
    },
    {
      "epoch": 0.4782222222222222,
      "grad_norm": 0.1661127656698227,
      "learning_rate": 2.608888888888889e-05,
      "loss": 0.0022,
      "step": 10760
    },
    {
      "epoch": 0.4786666666666667,
      "grad_norm": 0.4272002577781677,
      "learning_rate": 2.6066666666666666e-05,
      "loss": 0.0015,
      "step": 10770
    },
    {
      "epoch": 0.4791111111111111,
      "grad_norm": 0.34433653950691223,
      "learning_rate": 2.6044444444444443e-05,
      "loss": 0.0019,
      "step": 10780
    },
    {
      "epoch": 0.47955555555555557,
      "grad_norm": 0.030784379690885544,
      "learning_rate": 2.6022222222222224e-05,
      "loss": 0.0017,
      "step": 10790
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.34395870566368103,
      "learning_rate": 2.6000000000000002e-05,
      "loss": 0.0018,
      "step": 10800
    },
    {
      "epoch": 0.48044444444444445,
      "grad_norm": 0.17205429077148438,
      "learning_rate": 2.597777777777778e-05,
      "loss": 0.0016,
      "step": 10810
    },
    {
      "epoch": 0.48088888888888887,
      "grad_norm": 0.19449299573898315,
      "learning_rate": 2.5955555555555554e-05,
      "loss": 0.0017,
      "step": 10820
    },
    {
      "epoch": 0.48133333333333334,
      "grad_norm": 0.2064274549484253,
      "learning_rate": 2.5933333333333338e-05,
      "loss": 0.0019,
      "step": 10830
    },
    {
      "epoch": 0.4817777777777778,
      "grad_norm": 0.0858829915523529,
      "learning_rate": 2.5911111111111112e-05,
      "loss": 0.0019,
      "step": 10840
    },
    {
      "epoch": 0.4822222222222222,
      "grad_norm": 0.48238012194633484,
      "learning_rate": 2.588888888888889e-05,
      "loss": 0.0019,
      "step": 10850
    },
    {
      "epoch": 0.4826666666666667,
      "grad_norm": 0.4446277320384979,
      "learning_rate": 2.5866666666666667e-05,
      "loss": 0.002,
      "step": 10860
    },
    {
      "epoch": 0.4831111111111111,
      "grad_norm": 0.30181416869163513,
      "learning_rate": 2.5844444444444442e-05,
      "loss": 0.0023,
      "step": 10870
    },
    {
      "epoch": 0.48355555555555557,
      "grad_norm": 0.02257639914751053,
      "learning_rate": 2.5822222222222226e-05,
      "loss": 0.0021,
      "step": 10880
    },
    {
      "epoch": 0.484,
      "grad_norm": 0.46842145919799805,
      "learning_rate": 2.58e-05,
      "loss": 0.0022,
      "step": 10890
    },
    {
      "epoch": 0.48444444444444446,
      "grad_norm": 0.34314754605293274,
      "learning_rate": 2.5777777777777778e-05,
      "loss": 0.0027,
      "step": 10900
    },
    {
      "epoch": 0.48488888888888887,
      "grad_norm": 0.31617146730422974,
      "learning_rate": 2.5755555555555556e-05,
      "loss": 0.002,
      "step": 10910
    },
    {
      "epoch": 0.48533333333333334,
      "grad_norm": 0.6468037962913513,
      "learning_rate": 2.5733333333333337e-05,
      "loss": 0.0018,
      "step": 10920
    },
    {
      "epoch": 0.48577777777777775,
      "grad_norm": 0.31633809208869934,
      "learning_rate": 2.5711111111111114e-05,
      "loss": 0.0023,
      "step": 10930
    },
    {
      "epoch": 0.4862222222222222,
      "grad_norm": 0.20646816492080688,
      "learning_rate": 2.5688888888888892e-05,
      "loss": 0.002,
      "step": 10940
    },
    {
      "epoch": 0.4866666666666667,
      "grad_norm": 0.5644192695617676,
      "learning_rate": 2.5666666666666666e-05,
      "loss": 0.0018,
      "step": 10950
    },
    {
      "epoch": 0.4871111111111111,
      "grad_norm": 0.03896545618772507,
      "learning_rate": 2.5644444444444444e-05,
      "loss": 0.0024,
      "step": 10960
    },
    {
      "epoch": 0.4875555555555556,
      "grad_norm": 0.11068582534790039,
      "learning_rate": 2.5622222222222225e-05,
      "loss": 0.0019,
      "step": 10970
    },
    {
      "epoch": 0.488,
      "grad_norm": 0.2374923825263977,
      "learning_rate": 2.5600000000000002e-05,
      "loss": 0.002,
      "step": 10980
    },
    {
      "epoch": 0.48844444444444446,
      "grad_norm": 0.27432578802108765,
      "learning_rate": 2.557777777777778e-05,
      "loss": 0.0018,
      "step": 10990
    },
    {
      "epoch": 0.4888888888888889,
      "grad_norm": 0.15188460052013397,
      "learning_rate": 2.5555555555555554e-05,
      "loss": 0.002,
      "step": 11000
    },
    {
      "epoch": 0.48933333333333334,
      "grad_norm": 0.020854709669947624,
      "learning_rate": 2.553333333333334e-05,
      "loss": 0.0018,
      "step": 11010
    },
    {
      "epoch": 0.48977777777777776,
      "grad_norm": 0.12411370128393173,
      "learning_rate": 2.5511111111111113e-05,
      "loss": 0.002,
      "step": 11020
    },
    {
      "epoch": 0.4902222222222222,
      "grad_norm": 0.2481578290462494,
      "learning_rate": 2.548888888888889e-05,
      "loss": 0.002,
      "step": 11030
    },
    {
      "epoch": 0.49066666666666664,
      "grad_norm": 0.4398224949836731,
      "learning_rate": 2.5466666666666668e-05,
      "loss": 0.002,
      "step": 11040
    },
    {
      "epoch": 0.4911111111111111,
      "grad_norm": 0.12431365251541138,
      "learning_rate": 2.5444444444444442e-05,
      "loss": 0.002,
      "step": 11050
    },
    {
      "epoch": 0.4915555555555556,
      "grad_norm": 0.5630912184715271,
      "learning_rate": 2.5422222222222227e-05,
      "loss": 0.002,
      "step": 11060
    },
    {
      "epoch": 0.492,
      "grad_norm": 0.28921499848365784,
      "learning_rate": 2.54e-05,
      "loss": 0.0017,
      "step": 11070
    },
    {
      "epoch": 0.49244444444444446,
      "grad_norm": 0.3297930657863617,
      "learning_rate": 2.537777777777778e-05,
      "loss": 0.0021,
      "step": 11080
    },
    {
      "epoch": 0.4928888888888889,
      "grad_norm": 0.24882405996322632,
      "learning_rate": 2.5355555555555556e-05,
      "loss": 0.0019,
      "step": 11090
    },
    {
      "epoch": 0.49333333333333335,
      "grad_norm": 0.17930947244167328,
      "learning_rate": 2.5333333333333337e-05,
      "loss": 0.0018,
      "step": 11100
    },
    {
      "epoch": 0.49377777777777776,
      "grad_norm": 0.9064620733261108,
      "learning_rate": 2.5311111111111115e-05,
      "loss": 0.0021,
      "step": 11110
    },
    {
      "epoch": 0.49422222222222223,
      "grad_norm": 0.3579029440879822,
      "learning_rate": 2.528888888888889e-05,
      "loss": 0.0025,
      "step": 11120
    },
    {
      "epoch": 0.49466666666666664,
      "grad_norm": 0.4397766590118408,
      "learning_rate": 2.5266666666666666e-05,
      "loss": 0.0019,
      "step": 11130
    },
    {
      "epoch": 0.4951111111111111,
      "grad_norm": 0.302985817193985,
      "learning_rate": 2.5244444444444447e-05,
      "loss": 0.0021,
      "step": 11140
    },
    {
      "epoch": 0.4955555555555556,
      "grad_norm": 0.3027600049972534,
      "learning_rate": 2.5222222222222225e-05,
      "loss": 0.002,
      "step": 11150
    },
    {
      "epoch": 0.496,
      "grad_norm": 0.1513020098209381,
      "learning_rate": 2.5200000000000003e-05,
      "loss": 0.0019,
      "step": 11160
    },
    {
      "epoch": 0.49644444444444447,
      "grad_norm": 0.2066670060157776,
      "learning_rate": 2.5177777777777777e-05,
      "loss": 0.0017,
      "step": 11170
    },
    {
      "epoch": 0.4968888888888889,
      "grad_norm": 0.33115527033805847,
      "learning_rate": 2.5155555555555555e-05,
      "loss": 0.0018,
      "step": 11180
    },
    {
      "epoch": 0.49733333333333335,
      "grad_norm": 0.1395769715309143,
      "learning_rate": 2.5133333333333336e-05,
      "loss": 0.0021,
      "step": 11190
    },
    {
      "epoch": 0.49777777777777776,
      "grad_norm": 0.48048120737075806,
      "learning_rate": 2.5111111111111113e-05,
      "loss": 0.0022,
      "step": 11200
    },
    {
      "epoch": 0.49822222222222223,
      "grad_norm": 0.17871089279651642,
      "learning_rate": 2.508888888888889e-05,
      "loss": 0.0029,
      "step": 11210
    },
    {
      "epoch": 0.49866666666666665,
      "grad_norm": 0.026625754311680794,
      "learning_rate": 2.5066666666666665e-05,
      "loss": 0.0016,
      "step": 11220
    },
    {
      "epoch": 0.4991111111111111,
      "grad_norm": 0.1789732426404953,
      "learning_rate": 2.504444444444445e-05,
      "loss": 0.0019,
      "step": 11230
    },
    {
      "epoch": 0.49955555555555553,
      "grad_norm": 0.33123159408569336,
      "learning_rate": 2.5022222222222224e-05,
      "loss": 0.0026,
      "step": 11240
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.046906277537345886,
      "learning_rate": 2.5e-05,
      "loss": 0.0019,
      "step": 11250
    },
    {
      "epoch": 0.5004444444444445,
      "grad_norm": 0.2507469356060028,
      "learning_rate": 2.497777777777778e-05,
      "loss": 0.0023,
      "step": 11260
    },
    {
      "epoch": 0.5008888888888889,
      "grad_norm": 0.06273800879716873,
      "learning_rate": 2.4955555555555556e-05,
      "loss": 0.0017,
      "step": 11270
    },
    {
      "epoch": 0.5013333333333333,
      "grad_norm": 0.4257030189037323,
      "learning_rate": 2.4933333333333334e-05,
      "loss": 0.0018,
      "step": 11280
    },
    {
      "epoch": 0.5017777777777778,
      "grad_norm": 0.13821138441562653,
      "learning_rate": 2.491111111111111e-05,
      "loss": 0.0022,
      "step": 11290
    },
    {
      "epoch": 0.5022222222222222,
      "grad_norm": 0.4116761386394501,
      "learning_rate": 2.488888888888889e-05,
      "loss": 0.0019,
      "step": 11300
    },
    {
      "epoch": 0.5026666666666667,
      "grad_norm": 0.20621035993099213,
      "learning_rate": 2.486666666666667e-05,
      "loss": 0.0021,
      "step": 11310
    },
    {
      "epoch": 0.5031111111111111,
      "grad_norm": 0.2088359296321869,
      "learning_rate": 2.4844444444444444e-05,
      "loss": 0.0016,
      "step": 11320
    },
    {
      "epoch": 0.5035555555555555,
      "grad_norm": 0.1257646381855011,
      "learning_rate": 2.4822222222222225e-05,
      "loss": 0.002,
      "step": 11330
    },
    {
      "epoch": 0.504,
      "grad_norm": 0.07480599731206894,
      "learning_rate": 2.48e-05,
      "loss": 0.0017,
      "step": 11340
    },
    {
      "epoch": 0.5044444444444445,
      "grad_norm": 0.33113163709640503,
      "learning_rate": 2.477777777777778e-05,
      "loss": 0.0029,
      "step": 11350
    },
    {
      "epoch": 0.5048888888888889,
      "grad_norm": 0.16720427572727203,
      "learning_rate": 2.475555555555556e-05,
      "loss": 0.0024,
      "step": 11360
    },
    {
      "epoch": 0.5053333333333333,
      "grad_norm": 0.08442061394453049,
      "learning_rate": 2.4733333333333333e-05,
      "loss": 0.0019,
      "step": 11370
    },
    {
      "epoch": 0.5057777777777778,
      "grad_norm": 0.44039028882980347,
      "learning_rate": 2.4711111111111114e-05,
      "loss": 0.0019,
      "step": 11380
    },
    {
      "epoch": 0.5062222222222222,
      "grad_norm": 0.1667681634426117,
      "learning_rate": 2.4688888888888888e-05,
      "loss": 0.0022,
      "step": 11390
    },
    {
      "epoch": 0.5066666666666667,
      "grad_norm": 0.021462585777044296,
      "learning_rate": 2.466666666666667e-05,
      "loss": 0.002,
      "step": 11400
    },
    {
      "epoch": 0.5071111111111111,
      "grad_norm": 0.22175824642181396,
      "learning_rate": 2.4644444444444446e-05,
      "loss": 0.0022,
      "step": 11410
    },
    {
      "epoch": 0.5075555555555555,
      "grad_norm": 0.28978538513183594,
      "learning_rate": 2.4622222222222224e-05,
      "loss": 0.0023,
      "step": 11420
    },
    {
      "epoch": 0.508,
      "grad_norm": 0.8510445952415466,
      "learning_rate": 2.46e-05,
      "loss": 0.0021,
      "step": 11430
    },
    {
      "epoch": 0.5084444444444445,
      "grad_norm": 0.30220863223075867,
      "learning_rate": 2.457777777777778e-05,
      "loss": 0.0019,
      "step": 11440
    },
    {
      "epoch": 0.5088888888888888,
      "grad_norm": 0.5369617938995361,
      "learning_rate": 2.4555555555555557e-05,
      "loss": 0.0019,
      "step": 11450
    },
    {
      "epoch": 0.5093333333333333,
      "grad_norm": 0.49401891231536865,
      "learning_rate": 2.4533333333333334e-05,
      "loss": 0.0023,
      "step": 11460
    },
    {
      "epoch": 0.5097777777777778,
      "grad_norm": 0.08366774767637253,
      "learning_rate": 2.4511111111111112e-05,
      "loss": 0.0017,
      "step": 11470
    },
    {
      "epoch": 0.5102222222222222,
      "grad_norm": 0.033382315188646317,
      "learning_rate": 2.448888888888889e-05,
      "loss": 0.0022,
      "step": 11480
    },
    {
      "epoch": 0.5106666666666667,
      "grad_norm": 0.02415117807686329,
      "learning_rate": 2.4466666666666667e-05,
      "loss": 0.0015,
      "step": 11490
    },
    {
      "epoch": 0.5111111111111111,
      "grad_norm": 0.3159103989601135,
      "learning_rate": 2.4444444444444445e-05,
      "loss": 0.0018,
      "step": 11500
    },
    {
      "epoch": 0.5115555555555555,
      "grad_norm": 0.07314266264438629,
      "learning_rate": 2.4422222222222223e-05,
      "loss": 0.0019,
      "step": 11510
    },
    {
      "epoch": 0.512,
      "grad_norm": 0.2603580057621002,
      "learning_rate": 2.44e-05,
      "loss": 0.0019,
      "step": 11520
    },
    {
      "epoch": 0.5124444444444445,
      "grad_norm": 0.08456014841794968,
      "learning_rate": 2.437777777777778e-05,
      "loss": 0.0024,
      "step": 11530
    },
    {
      "epoch": 0.5128888888888888,
      "grad_norm": 0.49373456835746765,
      "learning_rate": 2.4355555555555555e-05,
      "loss": 0.0023,
      "step": 11540
    },
    {
      "epoch": 0.5133333333333333,
      "grad_norm": 0.03728841245174408,
      "learning_rate": 2.4333333333333336e-05,
      "loss": 0.002,
      "step": 11550
    },
    {
      "epoch": 0.5137777777777778,
      "grad_norm": 0.5521319508552551,
      "learning_rate": 2.431111111111111e-05,
      "loss": 0.0018,
      "step": 11560
    },
    {
      "epoch": 0.5142222222222222,
      "grad_norm": 0.14067766070365906,
      "learning_rate": 2.4288888888888888e-05,
      "loss": 0.002,
      "step": 11570
    },
    {
      "epoch": 0.5146666666666667,
      "grad_norm": 0.034159861505031586,
      "learning_rate": 2.426666666666667e-05,
      "loss": 0.0018,
      "step": 11580
    },
    {
      "epoch": 0.5151111111111111,
      "grad_norm": 0.035261690616607666,
      "learning_rate": 2.4244444444444443e-05,
      "loss": 0.0021,
      "step": 11590
    },
    {
      "epoch": 0.5155555555555555,
      "grad_norm": 0.06241639703512192,
      "learning_rate": 2.4222222222222224e-05,
      "loss": 0.0022,
      "step": 11600
    },
    {
      "epoch": 0.516,
      "grad_norm": 0.17923039197921753,
      "learning_rate": 2.4200000000000002e-05,
      "loss": 0.0023,
      "step": 11610
    },
    {
      "epoch": 0.5164444444444445,
      "grad_norm": 0.4394707977771759,
      "learning_rate": 2.417777777777778e-05,
      "loss": 0.0022,
      "step": 11620
    },
    {
      "epoch": 0.5168888888888888,
      "grad_norm": 0.4677799940109253,
      "learning_rate": 2.4155555555555557e-05,
      "loss": 0.0021,
      "step": 11630
    },
    {
      "epoch": 0.5173333333333333,
      "grad_norm": 0.12943485379219055,
      "learning_rate": 2.4133333333333335e-05,
      "loss": 0.0021,
      "step": 11640
    },
    {
      "epoch": 0.5177777777777778,
      "grad_norm": 0.19206571578979492,
      "learning_rate": 2.4111111111111113e-05,
      "loss": 0.0019,
      "step": 11650
    },
    {
      "epoch": 0.5182222222222223,
      "grad_norm": 0.08860078454017639,
      "learning_rate": 2.408888888888889e-05,
      "loss": 0.0016,
      "step": 11660
    },
    {
      "epoch": 0.5186666666666667,
      "grad_norm": 0.6353375315666199,
      "learning_rate": 2.4066666666666668e-05,
      "loss": 0.0024,
      "step": 11670
    },
    {
      "epoch": 0.5191111111111111,
      "grad_norm": 0.5774883031845093,
      "learning_rate": 2.4044444444444445e-05,
      "loss": 0.002,
      "step": 11680
    },
    {
      "epoch": 0.5195555555555555,
      "grad_norm": 0.18155978620052338,
      "learning_rate": 2.4022222222222223e-05,
      "loss": 0.0018,
      "step": 11690
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.18045584857463837,
      "learning_rate": 2.4e-05,
      "loss": 0.0024,
      "step": 11700
    },
    {
      "epoch": 0.5204444444444445,
      "grad_norm": 0.12443426996469498,
      "learning_rate": 2.3977777777777778e-05,
      "loss": 0.0019,
      "step": 11710
    },
    {
      "epoch": 0.5208888888888888,
      "grad_norm": 0.5520777702331543,
      "learning_rate": 2.3955555555555556e-05,
      "loss": 0.0019,
      "step": 11720
    },
    {
      "epoch": 0.5213333333333333,
      "grad_norm": 0.2343582957983017,
      "learning_rate": 2.3933333333333337e-05,
      "loss": 0.0019,
      "step": 11730
    },
    {
      "epoch": 0.5217777777777778,
      "grad_norm": 0.13992300629615784,
      "learning_rate": 2.391111111111111e-05,
      "loss": 0.0016,
      "step": 11740
    },
    {
      "epoch": 0.5222222222222223,
      "grad_norm": 0.12797769904136658,
      "learning_rate": 2.3888888888888892e-05,
      "loss": 0.002,
      "step": 11750
    },
    {
      "epoch": 0.5226666666666666,
      "grad_norm": 0.5903971791267395,
      "learning_rate": 2.3866666666666666e-05,
      "loss": 0.0018,
      "step": 11760
    },
    {
      "epoch": 0.5231111111111111,
      "grad_norm": 0.09972350299358368,
      "learning_rate": 2.3844444444444444e-05,
      "loss": 0.0018,
      "step": 11770
    },
    {
      "epoch": 0.5235555555555556,
      "grad_norm": 0.3293399512767792,
      "learning_rate": 2.3822222222222225e-05,
      "loss": 0.0018,
      "step": 11780
    },
    {
      "epoch": 0.524,
      "grad_norm": 0.5368973016738892,
      "learning_rate": 2.38e-05,
      "loss": 0.0022,
      "step": 11790
    },
    {
      "epoch": 0.5244444444444445,
      "grad_norm": 0.0317954458296299,
      "learning_rate": 2.377777777777778e-05,
      "loss": 0.0017,
      "step": 11800
    },
    {
      "epoch": 0.5248888888888888,
      "grad_norm": 0.11355118453502655,
      "learning_rate": 2.3755555555555554e-05,
      "loss": 0.002,
      "step": 11810
    },
    {
      "epoch": 0.5253333333333333,
      "grad_norm": 0.19885262846946716,
      "learning_rate": 2.3733333333333335e-05,
      "loss": 0.0017,
      "step": 11820
    },
    {
      "epoch": 0.5257777777777778,
      "grad_norm": 0.32974299788475037,
      "learning_rate": 2.3711111111111113e-05,
      "loss": 0.0016,
      "step": 11830
    },
    {
      "epoch": 0.5262222222222223,
      "grad_norm": 0.5215638875961304,
      "learning_rate": 2.368888888888889e-05,
      "loss": 0.0022,
      "step": 11840
    },
    {
      "epoch": 0.5266666666666666,
      "grad_norm": 0.044924475252628326,
      "learning_rate": 2.3666666666666668e-05,
      "loss": 0.0019,
      "step": 11850
    },
    {
      "epoch": 0.5271111111111111,
      "grad_norm": 0.2652943730354309,
      "learning_rate": 2.3644444444444446e-05,
      "loss": 0.0021,
      "step": 11860
    },
    {
      "epoch": 0.5275555555555556,
      "grad_norm": 0.08770275115966797,
      "learning_rate": 2.3622222222222223e-05,
      "loss": 0.002,
      "step": 11870
    },
    {
      "epoch": 0.528,
      "grad_norm": 0.2620376646518707,
      "learning_rate": 2.36e-05,
      "loss": 0.0021,
      "step": 11880
    },
    {
      "epoch": 0.5284444444444445,
      "grad_norm": 0.020861176773905754,
      "learning_rate": 2.357777777777778e-05,
      "loss": 0.0017,
      "step": 11890
    },
    {
      "epoch": 0.5288888888888889,
      "grad_norm": 0.32941922545433044,
      "learning_rate": 2.3555555555555556e-05,
      "loss": 0.0019,
      "step": 11900
    },
    {
      "epoch": 0.5293333333333333,
      "grad_norm": 0.08472568541765213,
      "learning_rate": 2.3533333333333334e-05,
      "loss": 0.0019,
      "step": 11910
    },
    {
      "epoch": 0.5297777777777778,
      "grad_norm": 0.12485167384147644,
      "learning_rate": 2.351111111111111e-05,
      "loss": 0.0021,
      "step": 11920
    },
    {
      "epoch": 0.5302222222222223,
      "grad_norm": 0.15404710173606873,
      "learning_rate": 2.3488888888888893e-05,
      "loss": 0.0018,
      "step": 11930
    },
    {
      "epoch": 0.5306666666666666,
      "grad_norm": 0.08749091625213623,
      "learning_rate": 2.3466666666666667e-05,
      "loss": 0.0018,
      "step": 11940
    },
    {
      "epoch": 0.5311111111111111,
      "grad_norm": 0.12467344850301743,
      "learning_rate": 2.3444444444444448e-05,
      "loss": 0.002,
      "step": 11950
    },
    {
      "epoch": 0.5315555555555556,
      "grad_norm": 0.03114459663629532,
      "learning_rate": 2.3422222222222222e-05,
      "loss": 0.002,
      "step": 11960
    },
    {
      "epoch": 0.532,
      "grad_norm": 0.1805923879146576,
      "learning_rate": 2.3400000000000003e-05,
      "loss": 0.002,
      "step": 11970
    },
    {
      "epoch": 0.5324444444444445,
      "grad_norm": 0.056965332478284836,
      "learning_rate": 2.337777777777778e-05,
      "loss": 0.0019,
      "step": 11980
    },
    {
      "epoch": 0.5328888888888889,
      "grad_norm": 0.15135061740875244,
      "learning_rate": 2.3355555555555555e-05,
      "loss": 0.0023,
      "step": 11990
    },
    {
      "epoch": 0.5333333333333333,
      "grad_norm": 0.24861688911914825,
      "learning_rate": 2.3333333333333336e-05,
      "loss": 0.0019,
      "step": 12000
    },
    {
      "epoch": 0.5337777777777778,
      "grad_norm": 0.3300313353538513,
      "learning_rate": 2.331111111111111e-05,
      "loss": 0.0019,
      "step": 12010
    },
    {
      "epoch": 0.5342222222222223,
      "grad_norm": 0.05040993541479111,
      "learning_rate": 2.328888888888889e-05,
      "loss": 0.0017,
      "step": 12020
    },
    {
      "epoch": 0.5346666666666666,
      "grad_norm": 0.3174171447753906,
      "learning_rate": 2.326666666666667e-05,
      "loss": 0.002,
      "step": 12030
    },
    {
      "epoch": 0.5351111111111111,
      "grad_norm": 0.13790053129196167,
      "learning_rate": 2.3244444444444446e-05,
      "loss": 0.0022,
      "step": 12040
    },
    {
      "epoch": 0.5355555555555556,
      "grad_norm": 0.4145010709762573,
      "learning_rate": 2.3222222222222224e-05,
      "loss": 0.0019,
      "step": 12050
    },
    {
      "epoch": 0.536,
      "grad_norm": 0.045219890773296356,
      "learning_rate": 2.32e-05,
      "loss": 0.002,
      "step": 12060
    },
    {
      "epoch": 0.5364444444444444,
      "grad_norm": 0.020920496433973312,
      "learning_rate": 2.317777777777778e-05,
      "loss": 0.0018,
      "step": 12070
    },
    {
      "epoch": 0.5368888888888889,
      "grad_norm": 0.13935630023479462,
      "learning_rate": 2.3155555555555557e-05,
      "loss": 0.002,
      "step": 12080
    },
    {
      "epoch": 0.5373333333333333,
      "grad_norm": 0.12919658422470093,
      "learning_rate": 2.3133333333333334e-05,
      "loss": 0.0018,
      "step": 12090
    },
    {
      "epoch": 0.5377777777777778,
      "grad_norm": 0.28814393281936646,
      "learning_rate": 2.3111111111111112e-05,
      "loss": 0.0018,
      "step": 12100
    },
    {
      "epoch": 0.5382222222222223,
      "grad_norm": 0.2215593308210373,
      "learning_rate": 2.308888888888889e-05,
      "loss": 0.0017,
      "step": 12110
    },
    {
      "epoch": 0.5386666666666666,
      "grad_norm": 0.275692880153656,
      "learning_rate": 2.3066666666666667e-05,
      "loss": 0.0028,
      "step": 12120
    },
    {
      "epoch": 0.5391111111111111,
      "grad_norm": 0.01824139431118965,
      "learning_rate": 2.3044444444444445e-05,
      "loss": 0.0021,
      "step": 12130
    },
    {
      "epoch": 0.5395555555555556,
      "grad_norm": 0.1376659870147705,
      "learning_rate": 2.3022222222222222e-05,
      "loss": 0.0023,
      "step": 12140
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.20698654651641846,
      "learning_rate": 2.3000000000000003e-05,
      "loss": 0.0018,
      "step": 12150
    },
    {
      "epoch": 0.5404444444444444,
      "grad_norm": 0.08469334989786148,
      "learning_rate": 2.2977777777777778e-05,
      "loss": 0.0019,
      "step": 12160
    },
    {
      "epoch": 0.5408888888888889,
      "grad_norm": 0.09823017567396164,
      "learning_rate": 2.295555555555556e-05,
      "loss": 0.0019,
      "step": 12170
    },
    {
      "epoch": 0.5413333333333333,
      "grad_norm": 0.08561895042657852,
      "learning_rate": 2.2933333333333333e-05,
      "loss": 0.0021,
      "step": 12180
    },
    {
      "epoch": 0.5417777777777778,
      "grad_norm": 0.5496360063552856,
      "learning_rate": 2.291111111111111e-05,
      "loss": 0.002,
      "step": 12190
    },
    {
      "epoch": 0.5422222222222223,
      "grad_norm": 0.2339523285627365,
      "learning_rate": 2.288888888888889e-05,
      "loss": 0.002,
      "step": 12200
    },
    {
      "epoch": 0.5426666666666666,
      "grad_norm": 0.016219129785895348,
      "learning_rate": 2.2866666666666666e-05,
      "loss": 0.0019,
      "step": 12210
    },
    {
      "epoch": 0.5431111111111111,
      "grad_norm": 0.2620144486427307,
      "learning_rate": 2.2844444444444447e-05,
      "loss": 0.0017,
      "step": 12220
    },
    {
      "epoch": 0.5435555555555556,
      "grad_norm": 0.08605797588825226,
      "learning_rate": 2.282222222222222e-05,
      "loss": 0.002,
      "step": 12230
    },
    {
      "epoch": 0.544,
      "grad_norm": 0.12477316707372665,
      "learning_rate": 2.2800000000000002e-05,
      "loss": 0.0021,
      "step": 12240
    },
    {
      "epoch": 0.5444444444444444,
      "grad_norm": 0.3172996938228607,
      "learning_rate": 2.277777777777778e-05,
      "loss": 0.0018,
      "step": 12250
    },
    {
      "epoch": 0.5448888888888889,
      "grad_norm": 0.5089178681373596,
      "learning_rate": 2.2755555555555557e-05,
      "loss": 0.0024,
      "step": 12260
    },
    {
      "epoch": 0.5453333333333333,
      "grad_norm": 0.42500653862953186,
      "learning_rate": 2.2733333333333335e-05,
      "loss": 0.002,
      "step": 12270
    },
    {
      "epoch": 0.5457777777777778,
      "grad_norm": 0.193935826420784,
      "learning_rate": 2.2711111111111112e-05,
      "loss": 0.0018,
      "step": 12280
    },
    {
      "epoch": 0.5462222222222223,
      "grad_norm": 0.025500932708382607,
      "learning_rate": 2.268888888888889e-05,
      "loss": 0.0019,
      "step": 12290
    },
    {
      "epoch": 0.5466666666666666,
      "grad_norm": 0.11199497431516647,
      "learning_rate": 2.2666666666666668e-05,
      "loss": 0.0024,
      "step": 12300
    },
    {
      "epoch": 0.5471111111111111,
      "grad_norm": 0.5087125897407532,
      "learning_rate": 2.2644444444444445e-05,
      "loss": 0.0024,
      "step": 12310
    },
    {
      "epoch": 0.5475555555555556,
      "grad_norm": 0.1400267332792282,
      "learning_rate": 2.2622222222222223e-05,
      "loss": 0.0023,
      "step": 12320
    },
    {
      "epoch": 0.548,
      "grad_norm": 0.5627101063728333,
      "learning_rate": 2.26e-05,
      "loss": 0.0022,
      "step": 12330
    },
    {
      "epoch": 0.5484444444444444,
      "grad_norm": 0.20720475912094116,
      "learning_rate": 2.2577777777777778e-05,
      "loss": 0.0015,
      "step": 12340
    },
    {
      "epoch": 0.5488888888888889,
      "grad_norm": 0.04017436504364014,
      "learning_rate": 2.255555555555556e-05,
      "loss": 0.0026,
      "step": 12350
    },
    {
      "epoch": 0.5493333333333333,
      "grad_norm": 0.15599162876605988,
      "learning_rate": 2.2533333333333333e-05,
      "loss": 0.0025,
      "step": 12360
    },
    {
      "epoch": 0.5497777777777778,
      "grad_norm": 0.058179426938295364,
      "learning_rate": 2.2511111111111114e-05,
      "loss": 0.002,
      "step": 12370
    },
    {
      "epoch": 0.5502222222222222,
      "grad_norm": 0.3429222106933594,
      "learning_rate": 2.248888888888889e-05,
      "loss": 0.0023,
      "step": 12380
    },
    {
      "epoch": 0.5506666666666666,
      "grad_norm": 0.19479681551456451,
      "learning_rate": 2.2466666666666666e-05,
      "loss": 0.0023,
      "step": 12390
    },
    {
      "epoch": 0.5511111111111111,
      "grad_norm": 0.2489822804927826,
      "learning_rate": 2.2444444444444447e-05,
      "loss": 0.0022,
      "step": 12400
    },
    {
      "epoch": 0.5515555555555556,
      "grad_norm": 0.0976669117808342,
      "learning_rate": 2.242222222222222e-05,
      "loss": 0.0019,
      "step": 12410
    },
    {
      "epoch": 0.552,
      "grad_norm": 0.08401405066251755,
      "learning_rate": 2.2400000000000002e-05,
      "loss": 0.0025,
      "step": 12420
    },
    {
      "epoch": 0.5524444444444444,
      "grad_norm": 0.26166045665740967,
      "learning_rate": 2.2377777777777777e-05,
      "loss": 0.0029,
      "step": 12430
    },
    {
      "epoch": 0.5528888888888889,
      "grad_norm": 0.0295448899269104,
      "learning_rate": 2.2355555555555558e-05,
      "loss": 0.0021,
      "step": 12440
    },
    {
      "epoch": 0.5533333333333333,
      "grad_norm": 0.4642128348350525,
      "learning_rate": 2.2333333333333335e-05,
      "loss": 0.0021,
      "step": 12450
    },
    {
      "epoch": 0.5537777777777778,
      "grad_norm": 0.18728524446487427,
      "learning_rate": 2.2311111111111113e-05,
      "loss": 0.0021,
      "step": 12460
    },
    {
      "epoch": 0.5542222222222222,
      "grad_norm": 0.043105751276016235,
      "learning_rate": 2.228888888888889e-05,
      "loss": 0.0018,
      "step": 12470
    },
    {
      "epoch": 0.5546666666666666,
      "grad_norm": 0.2618255615234375,
      "learning_rate": 2.2266666666666668e-05,
      "loss": 0.0017,
      "step": 12480
    },
    {
      "epoch": 0.5551111111111111,
      "grad_norm": 0.4444832503795624,
      "learning_rate": 2.2244444444444446e-05,
      "loss": 0.0018,
      "step": 12490
    },
    {
      "epoch": 0.5555555555555556,
      "grad_norm": 0.2219155728816986,
      "learning_rate": 2.2222222222222223e-05,
      "loss": 0.0017,
      "step": 12500
    },
    {
      "epoch": 0.556,
      "grad_norm": 0.34299978613853455,
      "learning_rate": 2.22e-05,
      "loss": 0.002,
      "step": 12510
    },
    {
      "epoch": 0.5564444444444444,
      "grad_norm": 0.2896410822868347,
      "learning_rate": 2.217777777777778e-05,
      "loss": 0.0029,
      "step": 12520
    },
    {
      "epoch": 0.5568888888888889,
      "grad_norm": 0.26025789976119995,
      "learning_rate": 2.2155555555555556e-05,
      "loss": 0.0024,
      "step": 12530
    },
    {
      "epoch": 0.5573333333333333,
      "grad_norm": 0.2263009250164032,
      "learning_rate": 2.2133333333333334e-05,
      "loss": 0.0018,
      "step": 12540
    },
    {
      "epoch": 0.5577777777777778,
      "grad_norm": 0.6869087219238281,
      "learning_rate": 2.211111111111111e-05,
      "loss": 0.0021,
      "step": 12550
    },
    {
      "epoch": 0.5582222222222222,
      "grad_norm": 0.133391872048378,
      "learning_rate": 2.208888888888889e-05,
      "loss": 0.0022,
      "step": 12560
    },
    {
      "epoch": 0.5586666666666666,
      "grad_norm": 0.13919030129909515,
      "learning_rate": 2.206666666666667e-05,
      "loss": 0.0021,
      "step": 12570
    },
    {
      "epoch": 0.5591111111111111,
      "grad_norm": 0.2364712804555893,
      "learning_rate": 2.2044444444444444e-05,
      "loss": 0.002,
      "step": 12580
    },
    {
      "epoch": 0.5595555555555556,
      "grad_norm": 0.020987434312701225,
      "learning_rate": 2.2022222222222225e-05,
      "loss": 0.0017,
      "step": 12590
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.577200710773468,
      "learning_rate": 2.2000000000000003e-05,
      "loss": 0.0019,
      "step": 12600
    },
    {
      "epoch": 0.5604444444444444,
      "grad_norm": 0.16603508591651917,
      "learning_rate": 2.1977777777777777e-05,
      "loss": 0.0016,
      "step": 12610
    },
    {
      "epoch": 0.5608888888888889,
      "grad_norm": 0.2482595443725586,
      "learning_rate": 2.1955555555555558e-05,
      "loss": 0.0019,
      "step": 12620
    },
    {
      "epoch": 0.5613333333333334,
      "grad_norm": 0.22056937217712402,
      "learning_rate": 2.1933333333333332e-05,
      "loss": 0.0019,
      "step": 12630
    },
    {
      "epoch": 0.5617777777777778,
      "grad_norm": 0.5065817832946777,
      "learning_rate": 2.1911111111111113e-05,
      "loss": 0.0017,
      "step": 12640
    },
    {
      "epoch": 0.5622222222222222,
      "grad_norm": 0.03466600924730301,
      "learning_rate": 2.188888888888889e-05,
      "loss": 0.0019,
      "step": 12650
    },
    {
      "epoch": 0.5626666666666666,
      "grad_norm": 0.1666194498538971,
      "learning_rate": 2.186666666666667e-05,
      "loss": 0.0016,
      "step": 12660
    },
    {
      "epoch": 0.5631111111111111,
      "grad_norm": 0.04788317158818245,
      "learning_rate": 2.1844444444444446e-05,
      "loss": 0.0018,
      "step": 12670
    },
    {
      "epoch": 0.5635555555555556,
      "grad_norm": 0.04338014870882034,
      "learning_rate": 2.1822222222222224e-05,
      "loss": 0.002,
      "step": 12680
    },
    {
      "epoch": 0.564,
      "grad_norm": 0.029922453686594963,
      "learning_rate": 2.18e-05,
      "loss": 0.002,
      "step": 12690
    },
    {
      "epoch": 0.5644444444444444,
      "grad_norm": 0.38436439633369446,
      "learning_rate": 2.177777777777778e-05,
      "loss": 0.0021,
      "step": 12700
    },
    {
      "epoch": 0.5648888888888889,
      "grad_norm": 0.20790788531303406,
      "learning_rate": 2.1755555555555557e-05,
      "loss": 0.0019,
      "step": 12710
    },
    {
      "epoch": 0.5653333333333334,
      "grad_norm": 0.0430343896150589,
      "learning_rate": 2.1733333333333334e-05,
      "loss": 0.002,
      "step": 12720
    },
    {
      "epoch": 0.5657777777777778,
      "grad_norm": 0.12460556626319885,
      "learning_rate": 2.1711111111111112e-05,
      "loss": 0.0018,
      "step": 12730
    },
    {
      "epoch": 0.5662222222222222,
      "grad_norm": 0.043223924934864044,
      "learning_rate": 2.168888888888889e-05,
      "loss": 0.0019,
      "step": 12740
    },
    {
      "epoch": 0.5666666666666667,
      "grad_norm": 0.06056363880634308,
      "learning_rate": 2.1666666666666667e-05,
      "loss": 0.002,
      "step": 12750
    },
    {
      "epoch": 0.5671111111111111,
      "grad_norm": 0.26285651326179504,
      "learning_rate": 2.1644444444444445e-05,
      "loss": 0.0027,
      "step": 12760
    },
    {
      "epoch": 0.5675555555555556,
      "grad_norm": 0.29262080788612366,
      "learning_rate": 2.1622222222222226e-05,
      "loss": 0.0026,
      "step": 12770
    },
    {
      "epoch": 0.568,
      "grad_norm": 0.3575221002101898,
      "learning_rate": 2.16e-05,
      "loss": 0.0025,
      "step": 12780
    },
    {
      "epoch": 0.5684444444444444,
      "grad_norm": 0.193817138671875,
      "learning_rate": 2.157777777777778e-05,
      "loss": 0.0021,
      "step": 12790
    },
    {
      "epoch": 0.5688888888888889,
      "grad_norm": 0.22014586627483368,
      "learning_rate": 2.1555555555555555e-05,
      "loss": 0.0022,
      "step": 12800
    },
    {
      "epoch": 0.5693333333333334,
      "grad_norm": 0.37045350670814514,
      "learning_rate": 2.1533333333333333e-05,
      "loss": 0.0019,
      "step": 12810
    },
    {
      "epoch": 0.5697777777777778,
      "grad_norm": 0.042463403195142746,
      "learning_rate": 2.1511111111111114e-05,
      "loss": 0.0017,
      "step": 12820
    },
    {
      "epoch": 0.5702222222222222,
      "grad_norm": 0.20679864287376404,
      "learning_rate": 2.1488888888888888e-05,
      "loss": 0.002,
      "step": 12830
    },
    {
      "epoch": 0.5706666666666667,
      "grad_norm": 0.2647418677806854,
      "learning_rate": 2.146666666666667e-05,
      "loss": 0.0025,
      "step": 12840
    },
    {
      "epoch": 0.5711111111111111,
      "grad_norm": 0.16675002872943878,
      "learning_rate": 2.1444444444444443e-05,
      "loss": 0.0021,
      "step": 12850
    },
    {
      "epoch": 0.5715555555555556,
      "grad_norm": 0.10322180390357971,
      "learning_rate": 2.1422222222222224e-05,
      "loss": 0.002,
      "step": 12860
    },
    {
      "epoch": 0.572,
      "grad_norm": 0.07261038571596146,
      "learning_rate": 2.1400000000000002e-05,
      "loss": 0.0016,
      "step": 12870
    },
    {
      "epoch": 0.5724444444444444,
      "grad_norm": 0.3699333071708679,
      "learning_rate": 2.137777777777778e-05,
      "loss": 0.002,
      "step": 12880
    },
    {
      "epoch": 0.5728888888888889,
      "grad_norm": 0.020024625584483147,
      "learning_rate": 2.1355555555555557e-05,
      "loss": 0.0016,
      "step": 12890
    },
    {
      "epoch": 0.5733333333333334,
      "grad_norm": 0.26310065388679504,
      "learning_rate": 2.1333333333333335e-05,
      "loss": 0.0021,
      "step": 12900
    },
    {
      "epoch": 0.5737777777777778,
      "grad_norm": 0.22008705139160156,
      "learning_rate": 2.1311111111111112e-05,
      "loss": 0.0017,
      "step": 12910
    },
    {
      "epoch": 0.5742222222222222,
      "grad_norm": 0.01969621330499649,
      "learning_rate": 2.128888888888889e-05,
      "loss": 0.0024,
      "step": 12920
    },
    {
      "epoch": 0.5746666666666667,
      "grad_norm": 0.1662742644548416,
      "learning_rate": 2.1266666666666667e-05,
      "loss": 0.0022,
      "step": 12930
    },
    {
      "epoch": 0.5751111111111111,
      "grad_norm": 0.4259980320930481,
      "learning_rate": 2.1244444444444445e-05,
      "loss": 0.0017,
      "step": 12940
    },
    {
      "epoch": 0.5755555555555556,
      "grad_norm": 0.08419138938188553,
      "learning_rate": 2.1222222222222223e-05,
      "loss": 0.0018,
      "step": 12950
    },
    {
      "epoch": 0.576,
      "grad_norm": 0.12429090589284897,
      "learning_rate": 2.12e-05,
      "loss": 0.0021,
      "step": 12960
    },
    {
      "epoch": 0.5764444444444444,
      "grad_norm": 0.3436540365219116,
      "learning_rate": 2.117777777777778e-05,
      "loss": 0.0026,
      "step": 12970
    },
    {
      "epoch": 0.5768888888888889,
      "grad_norm": 0.15149220824241638,
      "learning_rate": 2.1155555555555556e-05,
      "loss": 0.0018,
      "step": 12980
    },
    {
      "epoch": 0.5773333333333334,
      "grad_norm": 0.2478439211845398,
      "learning_rate": 2.1133333333333337e-05,
      "loss": 0.0017,
      "step": 12990
    },
    {
      "epoch": 0.5777777777777777,
      "grad_norm": 0.22142240405082703,
      "learning_rate": 2.111111111111111e-05,
      "loss": 0.0015,
      "step": 13000
    },
    {
      "epoch": 0.5782222222222222,
      "grad_norm": 0.1372804194688797,
      "learning_rate": 2.108888888888889e-05,
      "loss": 0.0018,
      "step": 13010
    },
    {
      "epoch": 0.5786666666666667,
      "grad_norm": 0.38455456495285034,
      "learning_rate": 2.106666666666667e-05,
      "loss": 0.002,
      "step": 13020
    },
    {
      "epoch": 0.5791111111111111,
      "grad_norm": 0.20613417029380798,
      "learning_rate": 2.1044444444444444e-05,
      "loss": 0.0022,
      "step": 13030
    },
    {
      "epoch": 0.5795555555555556,
      "grad_norm": 0.38627198338508606,
      "learning_rate": 2.1022222222222225e-05,
      "loss": 0.0018,
      "step": 13040
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.1519218534231186,
      "learning_rate": 2.1e-05,
      "loss": 0.0021,
      "step": 13050
    },
    {
      "epoch": 0.5804444444444444,
      "grad_norm": 0.3089534640312195,
      "learning_rate": 2.097777777777778e-05,
      "loss": 0.0018,
      "step": 13060
    },
    {
      "epoch": 0.5808888888888889,
      "grad_norm": 0.14258266985416412,
      "learning_rate": 2.0955555555555557e-05,
      "loss": 0.0019,
      "step": 13070
    },
    {
      "epoch": 0.5813333333333334,
      "grad_norm": 0.37140968441963196,
      "learning_rate": 2.0933333333333335e-05,
      "loss": 0.0022,
      "step": 13080
    },
    {
      "epoch": 0.5817777777777777,
      "grad_norm": 0.24671581387519836,
      "learning_rate": 2.0911111111111113e-05,
      "loss": 0.0018,
      "step": 13090
    },
    {
      "epoch": 0.5822222222222222,
      "grad_norm": 0.5991830825805664,
      "learning_rate": 2.088888888888889e-05,
      "loss": 0.0018,
      "step": 13100
    },
    {
      "epoch": 0.5826666666666667,
      "grad_norm": 0.5891843438148499,
      "learning_rate": 2.0866666666666668e-05,
      "loss": 0.0018,
      "step": 13110
    },
    {
      "epoch": 0.5831111111111111,
      "grad_norm": 0.3087694048881531,
      "learning_rate": 2.0844444444444446e-05,
      "loss": 0.0021,
      "step": 13120
    },
    {
      "epoch": 0.5835555555555556,
      "grad_norm": 0.4136863350868225,
      "learning_rate": 2.0822222222222223e-05,
      "loss": 0.0019,
      "step": 13130
    },
    {
      "epoch": 0.584,
      "grad_norm": 0.04702894762158394,
      "learning_rate": 2.08e-05,
      "loss": 0.0015,
      "step": 13140
    },
    {
      "epoch": 0.5844444444444444,
      "grad_norm": 0.139326274394989,
      "learning_rate": 2.077777777777778e-05,
      "loss": 0.0018,
      "step": 13150
    },
    {
      "epoch": 0.5848888888888889,
      "grad_norm": 0.04508676752448082,
      "learning_rate": 2.0755555555555556e-05,
      "loss": 0.0022,
      "step": 13160
    },
    {
      "epoch": 0.5853333333333334,
      "grad_norm": 0.02052934654057026,
      "learning_rate": 2.0733333333333334e-05,
      "loss": 0.0017,
      "step": 13170
    },
    {
      "epoch": 0.5857777777777777,
      "grad_norm": 0.1517004668712616,
      "learning_rate": 2.071111111111111e-05,
      "loss": 0.0018,
      "step": 13180
    },
    {
      "epoch": 0.5862222222222222,
      "grad_norm": 0.10026540607213974,
      "learning_rate": 2.0688888888888892e-05,
      "loss": 0.002,
      "step": 13190
    },
    {
      "epoch": 0.5866666666666667,
      "grad_norm": 0.19395697116851807,
      "learning_rate": 2.0666666666666666e-05,
      "loss": 0.0019,
      "step": 13200
    },
    {
      "epoch": 0.5871111111111111,
      "grad_norm": 0.15293756127357483,
      "learning_rate": 2.0644444444444447e-05,
      "loss": 0.0016,
      "step": 13210
    },
    {
      "epoch": 0.5875555555555556,
      "grad_norm": 0.20558235049247742,
      "learning_rate": 2.062222222222222e-05,
      "loss": 0.002,
      "step": 13220
    },
    {
      "epoch": 0.588,
      "grad_norm": 0.2532292902469635,
      "learning_rate": 2.06e-05,
      "loss": 0.0018,
      "step": 13230
    },
    {
      "epoch": 0.5884444444444444,
      "grad_norm": 0.05807230994105339,
      "learning_rate": 2.057777777777778e-05,
      "loss": 0.0019,
      "step": 13240
    },
    {
      "epoch": 0.5888888888888889,
      "grad_norm": 0.2339170277118683,
      "learning_rate": 2.0555555555555555e-05,
      "loss": 0.0023,
      "step": 13250
    },
    {
      "epoch": 0.5893333333333334,
      "grad_norm": 0.4935097396373749,
      "learning_rate": 2.0533333333333336e-05,
      "loss": 0.0017,
      "step": 13260
    },
    {
      "epoch": 0.5897777777777777,
      "grad_norm": 0.1387229561805725,
      "learning_rate": 2.0511111111111113e-05,
      "loss": 0.0026,
      "step": 13270
    },
    {
      "epoch": 0.5902222222222222,
      "grad_norm": 0.42730578780174255,
      "learning_rate": 2.048888888888889e-05,
      "loss": 0.0017,
      "step": 13280
    },
    {
      "epoch": 0.5906666666666667,
      "grad_norm": 0.08816630393266678,
      "learning_rate": 2.046666666666667e-05,
      "loss": 0.0019,
      "step": 13290
    },
    {
      "epoch": 0.5911111111111111,
      "grad_norm": 0.18548843264579773,
      "learning_rate": 2.0444444444444446e-05,
      "loss": 0.0018,
      "step": 13300
    },
    {
      "epoch": 0.5915555555555555,
      "grad_norm": 0.12471076101064682,
      "learning_rate": 2.0422222222222224e-05,
      "loss": 0.0017,
      "step": 13310
    },
    {
      "epoch": 0.592,
      "grad_norm": 0.3294084966182709,
      "learning_rate": 2.04e-05,
      "loss": 0.002,
      "step": 13320
    },
    {
      "epoch": 0.5924444444444444,
      "grad_norm": 0.6312301158905029,
      "learning_rate": 2.037777777777778e-05,
      "loss": 0.0025,
      "step": 13330
    },
    {
      "epoch": 0.5928888888888889,
      "grad_norm": 0.11411485821008682,
      "learning_rate": 2.0355555555555556e-05,
      "loss": 0.0019,
      "step": 13340
    },
    {
      "epoch": 0.5933333333333334,
      "grad_norm": 0.3571462333202362,
      "learning_rate": 2.0333333333333334e-05,
      "loss": 0.002,
      "step": 13350
    },
    {
      "epoch": 0.5937777777777777,
      "grad_norm": 0.11721678823232651,
      "learning_rate": 2.031111111111111e-05,
      "loss": 0.0019,
      "step": 13360
    },
    {
      "epoch": 0.5942222222222222,
      "grad_norm": 0.19329150021076202,
      "learning_rate": 2.028888888888889e-05,
      "loss": 0.0019,
      "step": 13370
    },
    {
      "epoch": 0.5946666666666667,
      "grad_norm": 0.1272449940443039,
      "learning_rate": 2.0266666666666667e-05,
      "loss": 0.0023,
      "step": 13380
    },
    {
      "epoch": 0.5951111111111111,
      "grad_norm": 0.1533125638961792,
      "learning_rate": 2.0244444444444448e-05,
      "loss": 0.0021,
      "step": 13390
    },
    {
      "epoch": 0.5955555555555555,
      "grad_norm": 0.18541303277015686,
      "learning_rate": 2.0222222222222222e-05,
      "loss": 0.0017,
      "step": 13400
    },
    {
      "epoch": 0.596,
      "grad_norm": 0.28945401310920715,
      "learning_rate": 2.0200000000000003e-05,
      "loss": 0.0018,
      "step": 13410
    },
    {
      "epoch": 0.5964444444444444,
      "grad_norm": 0.15757448971271515,
      "learning_rate": 2.0177777777777777e-05,
      "loss": 0.0024,
      "step": 13420
    },
    {
      "epoch": 0.5968888888888889,
      "grad_norm": 0.27506914734840393,
      "learning_rate": 2.0155555555555555e-05,
      "loss": 0.0016,
      "step": 13430
    },
    {
      "epoch": 0.5973333333333334,
      "grad_norm": 0.233622744679451,
      "learning_rate": 2.0133333333333336e-05,
      "loss": 0.0019,
      "step": 13440
    },
    {
      "epoch": 0.5977777777777777,
      "grad_norm": 0.03257857263088226,
      "learning_rate": 2.011111111111111e-05,
      "loss": 0.0018,
      "step": 13450
    },
    {
      "epoch": 0.5982222222222222,
      "grad_norm": 0.29248476028442383,
      "learning_rate": 2.008888888888889e-05,
      "loss": 0.0017,
      "step": 13460
    },
    {
      "epoch": 0.5986666666666667,
      "grad_norm": 0.39840415120124817,
      "learning_rate": 2.0066666666666665e-05,
      "loss": 0.0022,
      "step": 13470
    },
    {
      "epoch": 0.5991111111111111,
      "grad_norm": 0.41242673993110657,
      "learning_rate": 2.0044444444444446e-05,
      "loss": 0.0018,
      "step": 13480
    },
    {
      "epoch": 0.5995555555555555,
      "grad_norm": 0.4250601530075073,
      "learning_rate": 2.0022222222222224e-05,
      "loss": 0.0017,
      "step": 13490
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.4817892014980316,
      "learning_rate": 2e-05,
      "loss": 0.0017,
      "step": 13500
    },
    {
      "epoch": 0.6004444444444444,
      "grad_norm": 0.5209936499595642,
      "learning_rate": 1.997777777777778e-05,
      "loss": 0.0017,
      "step": 13510
    },
    {
      "epoch": 0.6008888888888889,
      "grad_norm": 0.2477041333913803,
      "learning_rate": 1.9955555555555557e-05,
      "loss": 0.0019,
      "step": 13520
    },
    {
      "epoch": 0.6013333333333334,
      "grad_norm": 0.3187662959098816,
      "learning_rate": 1.9933333333333334e-05,
      "loss": 0.0021,
      "step": 13530
    },
    {
      "epoch": 0.6017777777777777,
      "grad_norm": 0.26092684268951416,
      "learning_rate": 1.9911111111111112e-05,
      "loss": 0.0017,
      "step": 13540
    },
    {
      "epoch": 0.6022222222222222,
      "grad_norm": 0.20566898584365845,
      "learning_rate": 1.988888888888889e-05,
      "loss": 0.0022,
      "step": 13550
    },
    {
      "epoch": 0.6026666666666667,
      "grad_norm": 0.42558199167251587,
      "learning_rate": 1.9866666666666667e-05,
      "loss": 0.0023,
      "step": 13560
    },
    {
      "epoch": 0.6031111111111112,
      "grad_norm": 0.23404420912265778,
      "learning_rate": 1.9844444444444445e-05,
      "loss": 0.0017,
      "step": 13570
    },
    {
      "epoch": 0.6035555555555555,
      "grad_norm": 0.18312667310237885,
      "learning_rate": 1.9822222222222223e-05,
      "loss": 0.0017,
      "step": 13580
    },
    {
      "epoch": 0.604,
      "grad_norm": 0.02013930305838585,
      "learning_rate": 1.9800000000000004e-05,
      "loss": 0.002,
      "step": 13590
    },
    {
      "epoch": 0.6044444444444445,
      "grad_norm": 0.24824197590351105,
      "learning_rate": 1.9777777777777778e-05,
      "loss": 0.0017,
      "step": 13600
    },
    {
      "epoch": 0.6048888888888889,
      "grad_norm": 0.0425216443836689,
      "learning_rate": 1.975555555555556e-05,
      "loss": 0.0022,
      "step": 13610
    },
    {
      "epoch": 0.6053333333333333,
      "grad_norm": 0.13790680468082428,
      "learning_rate": 1.9733333333333333e-05,
      "loss": 0.0017,
      "step": 13620
    },
    {
      "epoch": 0.6057777777777777,
      "grad_norm": 0.1239451989531517,
      "learning_rate": 1.971111111111111e-05,
      "loss": 0.0017,
      "step": 13630
    },
    {
      "epoch": 0.6062222222222222,
      "grad_norm": 0.42794960737228394,
      "learning_rate": 1.968888888888889e-05,
      "loss": 0.0024,
      "step": 13640
    },
    {
      "epoch": 0.6066666666666667,
      "grad_norm": 0.26079028844833374,
      "learning_rate": 1.9666666666666666e-05,
      "loss": 0.002,
      "step": 13650
    },
    {
      "epoch": 0.6071111111111112,
      "grad_norm": 0.2608971893787384,
      "learning_rate": 1.9644444444444447e-05,
      "loss": 0.0023,
      "step": 13660
    },
    {
      "epoch": 0.6075555555555555,
      "grad_norm": 0.11191851645708084,
      "learning_rate": 1.962222222222222e-05,
      "loss": 0.0019,
      "step": 13670
    },
    {
      "epoch": 0.608,
      "grad_norm": 0.4392368793487549,
      "learning_rate": 1.9600000000000002e-05,
      "loss": 0.0017,
      "step": 13680
    },
    {
      "epoch": 0.6084444444444445,
      "grad_norm": 0.07228782027959824,
      "learning_rate": 1.957777777777778e-05,
      "loss": 0.0018,
      "step": 13690
    },
    {
      "epoch": 0.6088888888888889,
      "grad_norm": 0.08365057408809662,
      "learning_rate": 1.9555555555555557e-05,
      "loss": 0.0017,
      "step": 13700
    },
    {
      "epoch": 0.6093333333333333,
      "grad_norm": 0.3190453350543976,
      "learning_rate": 1.9533333333333335e-05,
      "loss": 0.0023,
      "step": 13710
    },
    {
      "epoch": 0.6097777777777778,
      "grad_norm": 0.19283616542816162,
      "learning_rate": 1.9511111111111113e-05,
      "loss": 0.0018,
      "step": 13720
    },
    {
      "epoch": 0.6102222222222222,
      "grad_norm": 0.28906506299972534,
      "learning_rate": 1.948888888888889e-05,
      "loss": 0.0016,
      "step": 13730
    },
    {
      "epoch": 0.6106666666666667,
      "grad_norm": 0.1929573118686676,
      "learning_rate": 1.9466666666666668e-05,
      "loss": 0.0017,
      "step": 13740
    },
    {
      "epoch": 0.6111111111111112,
      "grad_norm": 0.38470274209976196,
      "learning_rate": 1.9444444444444445e-05,
      "loss": 0.0024,
      "step": 13750
    },
    {
      "epoch": 0.6115555555555555,
      "grad_norm": 0.23412872850894928,
      "learning_rate": 1.9422222222222223e-05,
      "loss": 0.0021,
      "step": 13760
    },
    {
      "epoch": 0.612,
      "grad_norm": 0.0217630285769701,
      "learning_rate": 1.94e-05,
      "loss": 0.0018,
      "step": 13770
    },
    {
      "epoch": 0.6124444444444445,
      "grad_norm": 0.49379029870033264,
      "learning_rate": 1.9377777777777778e-05,
      "loss": 0.002,
      "step": 13780
    },
    {
      "epoch": 0.6128888888888889,
      "grad_norm": 0.1963788866996765,
      "learning_rate": 1.9355555555555556e-05,
      "loss": 0.0017,
      "step": 13790
    },
    {
      "epoch": 0.6133333333333333,
      "grad_norm": 0.30412381887435913,
      "learning_rate": 1.9333333333333333e-05,
      "loss": 0.0023,
      "step": 13800
    },
    {
      "epoch": 0.6137777777777778,
      "grad_norm": 0.3165791928768158,
      "learning_rate": 1.9311111111111114e-05,
      "loss": 0.0016,
      "step": 13810
    },
    {
      "epoch": 0.6142222222222222,
      "grad_norm": 0.07040686905384064,
      "learning_rate": 1.928888888888889e-05,
      "loss": 0.002,
      "step": 13820
    },
    {
      "epoch": 0.6146666666666667,
      "grad_norm": 0.05285054072737694,
      "learning_rate": 1.926666666666667e-05,
      "loss": 0.0021,
      "step": 13830
    },
    {
      "epoch": 0.6151111111111112,
      "grad_norm": 0.2060498297214508,
      "learning_rate": 1.9244444444444444e-05,
      "loss": 0.0016,
      "step": 13840
    },
    {
      "epoch": 0.6155555555555555,
      "grad_norm": 0.23350195586681366,
      "learning_rate": 1.922222222222222e-05,
      "loss": 0.0021,
      "step": 13850
    },
    {
      "epoch": 0.616,
      "grad_norm": 0.1393834799528122,
      "learning_rate": 1.9200000000000003e-05,
      "loss": 0.0023,
      "step": 13860
    },
    {
      "epoch": 0.6164444444444445,
      "grad_norm": 0.23314712941646576,
      "learning_rate": 1.9177777777777777e-05,
      "loss": 0.0018,
      "step": 13870
    },
    {
      "epoch": 0.6168888888888889,
      "grad_norm": 0.08425538241863251,
      "learning_rate": 1.9155555555555558e-05,
      "loss": 0.0018,
      "step": 13880
    },
    {
      "epoch": 0.6173333333333333,
      "grad_norm": 0.20569132268428802,
      "learning_rate": 1.9133333333333332e-05,
      "loss": 0.0023,
      "step": 13890
    },
    {
      "epoch": 0.6177777777777778,
      "grad_norm": 0.09728467464447021,
      "learning_rate": 1.9111111111111113e-05,
      "loss": 0.0019,
      "step": 13900
    },
    {
      "epoch": 0.6182222222222222,
      "grad_norm": 0.10047687590122223,
      "learning_rate": 1.908888888888889e-05,
      "loss": 0.0019,
      "step": 13910
    },
    {
      "epoch": 0.6186666666666667,
      "grad_norm": 0.08320900052785873,
      "learning_rate": 1.9066666666666668e-05,
      "loss": 0.0017,
      "step": 13920
    },
    {
      "epoch": 0.6191111111111111,
      "grad_norm": 0.17012248933315277,
      "learning_rate": 1.9044444444444446e-05,
      "loss": 0.0017,
      "step": 13930
    },
    {
      "epoch": 0.6195555555555555,
      "grad_norm": 0.34971147775650024,
      "learning_rate": 1.9022222222222223e-05,
      "loss": 0.0025,
      "step": 13940
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.05851339176297188,
      "learning_rate": 1.9e-05,
      "loss": 0.0028,
      "step": 13950
    },
    {
      "epoch": 0.6204444444444445,
      "grad_norm": 0.3563297688961029,
      "learning_rate": 1.897777777777778e-05,
      "loss": 0.0022,
      "step": 13960
    },
    {
      "epoch": 0.6208888888888889,
      "grad_norm": 0.17909598350524902,
      "learning_rate": 1.8955555555555556e-05,
      "loss": 0.0018,
      "step": 13970
    },
    {
      "epoch": 0.6213333333333333,
      "grad_norm": 0.2207915186882019,
      "learning_rate": 1.8933333333333334e-05,
      "loss": 0.002,
      "step": 13980
    },
    {
      "epoch": 0.6217777777777778,
      "grad_norm": 0.0459112823009491,
      "learning_rate": 1.891111111111111e-05,
      "loss": 0.0017,
      "step": 13990
    },
    {
      "epoch": 0.6222222222222222,
      "grad_norm": 0.3707684576511383,
      "learning_rate": 1.888888888888889e-05,
      "loss": 0.0018,
      "step": 14000
    },
    {
      "epoch": 0.6226666666666667,
      "grad_norm": 0.43872371315956116,
      "learning_rate": 1.886666666666667e-05,
      "loss": 0.0017,
      "step": 14010
    },
    {
      "epoch": 0.6231111111111111,
      "grad_norm": 0.32994288206100464,
      "learning_rate": 1.8844444444444444e-05,
      "loss": 0.0019,
      "step": 14020
    },
    {
      "epoch": 0.6235555555555555,
      "grad_norm": 0.6854814291000366,
      "learning_rate": 1.8822222222222225e-05,
      "loss": 0.0019,
      "step": 14030
    },
    {
      "epoch": 0.624,
      "grad_norm": 0.439079225063324,
      "learning_rate": 1.88e-05,
      "loss": 0.0016,
      "step": 14040
    },
    {
      "epoch": 0.6244444444444445,
      "grad_norm": 0.1823837161064148,
      "learning_rate": 1.8777777777777777e-05,
      "loss": 0.002,
      "step": 14050
    },
    {
      "epoch": 0.6248888888888889,
      "grad_norm": 0.5039714574813843,
      "learning_rate": 1.8755555555555558e-05,
      "loss": 0.0019,
      "step": 14060
    },
    {
      "epoch": 0.6253333333333333,
      "grad_norm": 0.37132930755615234,
      "learning_rate": 1.8733333333333332e-05,
      "loss": 0.0023,
      "step": 14070
    },
    {
      "epoch": 0.6257777777777778,
      "grad_norm": 0.38530319929122925,
      "learning_rate": 1.8711111111111113e-05,
      "loss": 0.0022,
      "step": 14080
    },
    {
      "epoch": 0.6262222222222222,
      "grad_norm": 0.08379620313644409,
      "learning_rate": 1.8688888888888888e-05,
      "loss": 0.0018,
      "step": 14090
    },
    {
      "epoch": 0.6266666666666667,
      "grad_norm": 0.08323954045772552,
      "learning_rate": 1.866666666666667e-05,
      "loss": 0.0021,
      "step": 14100
    },
    {
      "epoch": 0.6271111111111111,
      "grad_norm": 0.5634238719940186,
      "learning_rate": 1.8644444444444446e-05,
      "loss": 0.002,
      "step": 14110
    },
    {
      "epoch": 0.6275555555555555,
      "grad_norm": 0.14178994297981262,
      "learning_rate": 1.8622222222222224e-05,
      "loss": 0.0021,
      "step": 14120
    },
    {
      "epoch": 0.628,
      "grad_norm": 0.05575709044933319,
      "learning_rate": 1.86e-05,
      "loss": 0.0021,
      "step": 14130
    },
    {
      "epoch": 0.6284444444444445,
      "grad_norm": 0.5778632760047913,
      "learning_rate": 1.8577777777777776e-05,
      "loss": 0.0017,
      "step": 14140
    },
    {
      "epoch": 0.6288888888888889,
      "grad_norm": 0.17797933518886566,
      "learning_rate": 1.8555555555555557e-05,
      "loss": 0.0019,
      "step": 14150
    },
    {
      "epoch": 0.6293333333333333,
      "grad_norm": 0.30256274342536926,
      "learning_rate": 1.8533333333333334e-05,
      "loss": 0.0018,
      "step": 14160
    },
    {
      "epoch": 0.6297777777777778,
      "grad_norm": 0.09852534532546997,
      "learning_rate": 1.8511111111111112e-05,
      "loss": 0.0019,
      "step": 14170
    },
    {
      "epoch": 0.6302222222222222,
      "grad_norm": 0.24412040412425995,
      "learning_rate": 1.848888888888889e-05,
      "loss": 0.0021,
      "step": 14180
    },
    {
      "epoch": 0.6306666666666667,
      "grad_norm": 0.2996508479118347,
      "learning_rate": 1.8466666666666667e-05,
      "loss": 0.0024,
      "step": 14190
    },
    {
      "epoch": 0.6311111111111111,
      "grad_norm": 0.5361383557319641,
      "learning_rate": 1.8444444444444445e-05,
      "loss": 0.002,
      "step": 14200
    },
    {
      "epoch": 0.6315555555555555,
      "grad_norm": 0.058897193521261215,
      "learning_rate": 1.8422222222222222e-05,
      "loss": 0.002,
      "step": 14210
    },
    {
      "epoch": 0.632,
      "grad_norm": 0.23437851667404175,
      "learning_rate": 1.84e-05,
      "loss": 0.002,
      "step": 14220
    },
    {
      "epoch": 0.6324444444444445,
      "grad_norm": 0.37005797028541565,
      "learning_rate": 1.837777777777778e-05,
      "loss": 0.0025,
      "step": 14230
    },
    {
      "epoch": 0.6328888888888888,
      "grad_norm": 0.7681260704994202,
      "learning_rate": 1.8355555555555555e-05,
      "loss": 0.0017,
      "step": 14240
    },
    {
      "epoch": 0.6333333333333333,
      "grad_norm": 0.11107704043388367,
      "learning_rate": 1.8333333333333333e-05,
      "loss": 0.002,
      "step": 14250
    },
    {
      "epoch": 0.6337777777777778,
      "grad_norm": 0.08576808869838715,
      "learning_rate": 1.8311111111111114e-05,
      "loss": 0.0028,
      "step": 14260
    },
    {
      "epoch": 0.6342222222222222,
      "grad_norm": 0.6593990325927734,
      "learning_rate": 1.8288888888888888e-05,
      "loss": 0.002,
      "step": 14270
    },
    {
      "epoch": 0.6346666666666667,
      "grad_norm": 0.2887580394744873,
      "learning_rate": 1.826666666666667e-05,
      "loss": 0.002,
      "step": 14280
    },
    {
      "epoch": 0.6351111111111111,
      "grad_norm": 0.13854411244392395,
      "learning_rate": 1.8244444444444443e-05,
      "loss": 0.0017,
      "step": 14290
    },
    {
      "epoch": 0.6355555555555555,
      "grad_norm": 0.28854942321777344,
      "learning_rate": 1.8222222222222224e-05,
      "loss": 0.0017,
      "step": 14300
    },
    {
      "epoch": 0.636,
      "grad_norm": 0.22112810611724854,
      "learning_rate": 1.8200000000000002e-05,
      "loss": 0.0018,
      "step": 14310
    },
    {
      "epoch": 0.6364444444444445,
      "grad_norm": 0.15245476365089417,
      "learning_rate": 1.817777777777778e-05,
      "loss": 0.0019,
      "step": 14320
    },
    {
      "epoch": 0.6368888888888888,
      "grad_norm": 0.6712918281555176,
      "learning_rate": 1.8155555555555557e-05,
      "loss": 0.0019,
      "step": 14330
    },
    {
      "epoch": 0.6373333333333333,
      "grad_norm": 0.5766529440879822,
      "learning_rate": 1.8133333333333335e-05,
      "loss": 0.0015,
      "step": 14340
    },
    {
      "epoch": 0.6377777777777778,
      "grad_norm": 0.27498891949653625,
      "learning_rate": 1.8111111111111112e-05,
      "loss": 0.0019,
      "step": 14350
    },
    {
      "epoch": 0.6382222222222222,
      "grad_norm": 0.4252801537513733,
      "learning_rate": 1.808888888888889e-05,
      "loss": 0.0019,
      "step": 14360
    },
    {
      "epoch": 0.6386666666666667,
      "grad_norm": 0.025316361337900162,
      "learning_rate": 1.8066666666666668e-05,
      "loss": 0.0018,
      "step": 14370
    },
    {
      "epoch": 0.6391111111111111,
      "grad_norm": 0.12621581554412842,
      "learning_rate": 1.8044444444444445e-05,
      "loss": 0.0019,
      "step": 14380
    },
    {
      "epoch": 0.6395555555555555,
      "grad_norm": 0.31623855233192444,
      "learning_rate": 1.8022222222222223e-05,
      "loss": 0.0019,
      "step": 14390
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.27595728635787964,
      "learning_rate": 1.8e-05,
      "loss": 0.0017,
      "step": 14400
    },
    {
      "epoch": 0.6404444444444445,
      "grad_norm": 0.019983287900686264,
      "learning_rate": 1.7977777777777778e-05,
      "loss": 0.0018,
      "step": 14410
    },
    {
      "epoch": 0.6408888888888888,
      "grad_norm": 0.206258162856102,
      "learning_rate": 1.7955555555555556e-05,
      "loss": 0.0023,
      "step": 14420
    },
    {
      "epoch": 0.6413333333333333,
      "grad_norm": 0.07460357248783112,
      "learning_rate": 1.7933333333333337e-05,
      "loss": 0.0023,
      "step": 14430
    },
    {
      "epoch": 0.6417777777777778,
      "grad_norm": 0.42552223801612854,
      "learning_rate": 1.791111111111111e-05,
      "loss": 0.002,
      "step": 14440
    },
    {
      "epoch": 0.6422222222222222,
      "grad_norm": 0.42468374967575073,
      "learning_rate": 1.788888888888889e-05,
      "loss": 0.0017,
      "step": 14450
    },
    {
      "epoch": 0.6426666666666667,
      "grad_norm": 0.2057725042104721,
      "learning_rate": 1.7866666666666666e-05,
      "loss": 0.0019,
      "step": 14460
    },
    {
      "epoch": 0.6431111111111111,
      "grad_norm": 0.1784205585718155,
      "learning_rate": 1.7844444444444444e-05,
      "loss": 0.0017,
      "step": 14470
    },
    {
      "epoch": 0.6435555555555555,
      "grad_norm": 0.3729471266269684,
      "learning_rate": 1.7822222222222225e-05,
      "loss": 0.0018,
      "step": 14480
    },
    {
      "epoch": 0.644,
      "grad_norm": 0.19233748316764832,
      "learning_rate": 1.78e-05,
      "loss": 0.0016,
      "step": 14490
    },
    {
      "epoch": 0.6444444444444445,
      "grad_norm": 0.4003303349018097,
      "learning_rate": 1.777777777777778e-05,
      "loss": 0.0023,
      "step": 14500
    },
    {
      "epoch": 0.6448888888888888,
      "grad_norm": 0.02541782148182392,
      "learning_rate": 1.7755555555555554e-05,
      "loss": 0.0018,
      "step": 14510
    },
    {
      "epoch": 0.6453333333333333,
      "grad_norm": 0.07702969759702682,
      "learning_rate": 1.7733333333333335e-05,
      "loss": 0.0022,
      "step": 14520
    },
    {
      "epoch": 0.6457777777777778,
      "grad_norm": 0.23334914445877075,
      "learning_rate": 1.7711111111111113e-05,
      "loss": 0.0018,
      "step": 14530
    },
    {
      "epoch": 0.6462222222222223,
      "grad_norm": 0.0847475603222847,
      "learning_rate": 1.768888888888889e-05,
      "loss": 0.002,
      "step": 14540
    },
    {
      "epoch": 0.6466666666666666,
      "grad_norm": 0.151808500289917,
      "learning_rate": 1.7666666666666668e-05,
      "loss": 0.002,
      "step": 14550
    },
    {
      "epoch": 0.6471111111111111,
      "grad_norm": 0.2479095309972763,
      "learning_rate": 1.7644444444444446e-05,
      "loss": 0.0018,
      "step": 14560
    },
    {
      "epoch": 0.6475555555555556,
      "grad_norm": 0.06087455525994301,
      "learning_rate": 1.7622222222222223e-05,
      "loss": 0.002,
      "step": 14570
    },
    {
      "epoch": 0.648,
      "grad_norm": 0.2878517210483551,
      "learning_rate": 1.76e-05,
      "loss": 0.0025,
      "step": 14580
    },
    {
      "epoch": 0.6484444444444445,
      "grad_norm": 0.12600141763687134,
      "learning_rate": 1.757777777777778e-05,
      "loss": 0.0017,
      "step": 14590
    },
    {
      "epoch": 0.6488888888888888,
      "grad_norm": 0.1532703936100006,
      "learning_rate": 1.7555555555555556e-05,
      "loss": 0.0023,
      "step": 14600
    },
    {
      "epoch": 0.6493333333333333,
      "grad_norm": 0.060651980340480804,
      "learning_rate": 1.7533333333333334e-05,
      "loss": 0.0018,
      "step": 14610
    },
    {
      "epoch": 0.6497777777777778,
      "grad_norm": 0.4811522364616394,
      "learning_rate": 1.751111111111111e-05,
      "loss": 0.0021,
      "step": 14620
    },
    {
      "epoch": 0.6502222222222223,
      "grad_norm": 0.4382559359073639,
      "learning_rate": 1.7488888888888892e-05,
      "loss": 0.0018,
      "step": 14630
    },
    {
      "epoch": 0.6506666666666666,
      "grad_norm": 0.12590140104293823,
      "learning_rate": 1.7466666666666667e-05,
      "loss": 0.0024,
      "step": 14640
    },
    {
      "epoch": 0.6511111111111111,
      "grad_norm": 0.466816246509552,
      "learning_rate": 1.7444444444444448e-05,
      "loss": 0.0023,
      "step": 14650
    },
    {
      "epoch": 0.6515555555555556,
      "grad_norm": 0.08735213428735733,
      "learning_rate": 1.7422222222222222e-05,
      "loss": 0.0021,
      "step": 14660
    },
    {
      "epoch": 0.652,
      "grad_norm": 0.24747364223003387,
      "learning_rate": 1.74e-05,
      "loss": 0.0021,
      "step": 14670
    },
    {
      "epoch": 0.6524444444444445,
      "grad_norm": 0.056930575519800186,
      "learning_rate": 1.737777777777778e-05,
      "loss": 0.0023,
      "step": 14680
    },
    {
      "epoch": 0.6528888888888889,
      "grad_norm": 0.08361198753118515,
      "learning_rate": 1.7355555555555555e-05,
      "loss": 0.0018,
      "step": 14690
    },
    {
      "epoch": 0.6533333333333333,
      "grad_norm": 0.12330813705921173,
      "learning_rate": 1.7333333333333336e-05,
      "loss": 0.0018,
      "step": 14700
    },
    {
      "epoch": 0.6537777777777778,
      "grad_norm": 0.19259239733219147,
      "learning_rate": 1.731111111111111e-05,
      "loss": 0.0018,
      "step": 14710
    },
    {
      "epoch": 0.6542222222222223,
      "grad_norm": 0.2208353579044342,
      "learning_rate": 1.728888888888889e-05,
      "loss": 0.0019,
      "step": 14720
    },
    {
      "epoch": 0.6546666666666666,
      "grad_norm": 0.34383735060691833,
      "learning_rate": 1.726666666666667e-05,
      "loss": 0.0023,
      "step": 14730
    },
    {
      "epoch": 0.6551111111111111,
      "grad_norm": 0.31336721777915955,
      "learning_rate": 1.7244444444444446e-05,
      "loss": 0.0022,
      "step": 14740
    },
    {
      "epoch": 0.6555555555555556,
      "grad_norm": 0.4968232810497284,
      "learning_rate": 1.7222222222222224e-05,
      "loss": 0.0026,
      "step": 14750
    },
    {
      "epoch": 0.656,
      "grad_norm": 0.15202617645263672,
      "learning_rate": 1.7199999999999998e-05,
      "loss": 0.0017,
      "step": 14760
    },
    {
      "epoch": 0.6564444444444445,
      "grad_norm": 0.08651852607727051,
      "learning_rate": 1.717777777777778e-05,
      "loss": 0.0021,
      "step": 14770
    },
    {
      "epoch": 0.6568888888888889,
      "grad_norm": 0.5349106192588806,
      "learning_rate": 1.7155555555555557e-05,
      "loss": 0.0018,
      "step": 14780
    },
    {
      "epoch": 0.6573333333333333,
      "grad_norm": 0.17946657538414001,
      "learning_rate": 1.7133333333333334e-05,
      "loss": 0.0018,
      "step": 14790
    },
    {
      "epoch": 0.6577777777777778,
      "grad_norm": 0.19451557099819183,
      "learning_rate": 1.7111111111111112e-05,
      "loss": 0.0015,
      "step": 14800
    },
    {
      "epoch": 0.6582222222222223,
      "grad_norm": 0.0432916022837162,
      "learning_rate": 1.708888888888889e-05,
      "loss": 0.0019,
      "step": 14810
    },
    {
      "epoch": 0.6586666666666666,
      "grad_norm": 0.137486070394516,
      "learning_rate": 1.7066666666666667e-05,
      "loss": 0.0022,
      "step": 14820
    },
    {
      "epoch": 0.6591111111111111,
      "grad_norm": 0.0890531837940216,
      "learning_rate": 1.7044444444444445e-05,
      "loss": 0.0018,
      "step": 14830
    },
    {
      "epoch": 0.6595555555555556,
      "grad_norm": 0.06660965085029602,
      "learning_rate": 1.7022222222222222e-05,
      "loss": 0.0017,
      "step": 14840
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.09730006754398346,
      "learning_rate": 1.7000000000000003e-05,
      "loss": 0.0019,
      "step": 14850
    },
    {
      "epoch": 0.6604444444444444,
      "grad_norm": 0.2883589267730713,
      "learning_rate": 1.6977777777777777e-05,
      "loss": 0.002,
      "step": 14860
    },
    {
      "epoch": 0.6608888888888889,
      "grad_norm": 0.1659032553434372,
      "learning_rate": 1.6955555555555555e-05,
      "loss": 0.0025,
      "step": 14870
    },
    {
      "epoch": 0.6613333333333333,
      "grad_norm": 0.5758968591690063,
      "learning_rate": 1.6933333333333333e-05,
      "loss": 0.0018,
      "step": 14880
    },
    {
      "epoch": 0.6617777777777778,
      "grad_norm": 0.46650511026382446,
      "learning_rate": 1.691111111111111e-05,
      "loss": 0.0022,
      "step": 14890
    },
    {
      "epoch": 0.6622222222222223,
      "grad_norm": 0.12479357421398163,
      "learning_rate": 1.688888888888889e-05,
      "loss": 0.0022,
      "step": 14900
    },
    {
      "epoch": 0.6626666666666666,
      "grad_norm": 0.1653222143650055,
      "learning_rate": 1.6866666666666666e-05,
      "loss": 0.0019,
      "step": 14910
    },
    {
      "epoch": 0.6631111111111111,
      "grad_norm": 0.017024710774421692,
      "learning_rate": 1.6844444444444447e-05,
      "loss": 0.002,
      "step": 14920
    },
    {
      "epoch": 0.6635555555555556,
      "grad_norm": 0.11059077084064484,
      "learning_rate": 1.6822222222222224e-05,
      "loss": 0.0023,
      "step": 14930
    },
    {
      "epoch": 0.664,
      "grad_norm": 0.030138637870550156,
      "learning_rate": 1.6800000000000002e-05,
      "loss": 0.0017,
      "step": 14940
    },
    {
      "epoch": 0.6644444444444444,
      "grad_norm": 0.1001301258802414,
      "learning_rate": 1.677777777777778e-05,
      "loss": 0.002,
      "step": 14950
    },
    {
      "epoch": 0.6648888888888889,
      "grad_norm": 0.027826501056551933,
      "learning_rate": 1.6755555555555557e-05,
      "loss": 0.0019,
      "step": 14960
    },
    {
      "epoch": 0.6653333333333333,
      "grad_norm": 0.0844305083155632,
      "learning_rate": 1.6733333333333335e-05,
      "loss": 0.0019,
      "step": 14970
    },
    {
      "epoch": 0.6657777777777778,
      "grad_norm": 0.1693403124809265,
      "learning_rate": 1.6711111111111112e-05,
      "loss": 0.0024,
      "step": 14980
    },
    {
      "epoch": 0.6662222222222223,
      "grad_norm": 0.13955120742321014,
      "learning_rate": 1.668888888888889e-05,
      "loss": 0.002,
      "step": 14990
    },
    {
      "epoch": 0.6666666666666666,
      "grad_norm": 0.13825632631778717,
      "learning_rate": 1.6666666666666667e-05,
      "loss": 0.0019,
      "step": 15000
    },
    {
      "epoch": 0.6671111111111111,
      "grad_norm": 0.045597728341817856,
      "learning_rate": 1.6644444444444445e-05,
      "loss": 0.0017,
      "step": 15010
    },
    {
      "epoch": 0.6675555555555556,
      "grad_norm": 0.34473472833633423,
      "learning_rate": 1.6622222222222223e-05,
      "loss": 0.002,
      "step": 15020
    },
    {
      "epoch": 0.668,
      "grad_norm": 0.3034372925758362,
      "learning_rate": 1.66e-05,
      "loss": 0.0017,
      "step": 15030
    },
    {
      "epoch": 0.6684444444444444,
      "grad_norm": 0.04406849294900894,
      "learning_rate": 1.6577777777777778e-05,
      "loss": 0.002,
      "step": 15040
    },
    {
      "epoch": 0.6688888888888889,
      "grad_norm": 0.6870867609977722,
      "learning_rate": 1.655555555555556e-05,
      "loss": 0.0021,
      "step": 15050
    },
    {
      "epoch": 0.6693333333333333,
      "grad_norm": 0.288587361574173,
      "learning_rate": 1.6533333333333333e-05,
      "loss": 0.0019,
      "step": 15060
    },
    {
      "epoch": 0.6697777777777778,
      "grad_norm": 0.4948718249797821,
      "learning_rate": 1.651111111111111e-05,
      "loss": 0.0019,
      "step": 15070
    },
    {
      "epoch": 0.6702222222222223,
      "grad_norm": 0.16582821309566498,
      "learning_rate": 1.648888888888889e-05,
      "loss": 0.0018,
      "step": 15080
    },
    {
      "epoch": 0.6706666666666666,
      "grad_norm": 0.08432576060295105,
      "learning_rate": 1.6466666666666666e-05,
      "loss": 0.0019,
      "step": 15090
    },
    {
      "epoch": 0.6711111111111111,
      "grad_norm": 0.045078061521053314,
      "learning_rate": 1.6444444444444447e-05,
      "loss": 0.0016,
      "step": 15100
    },
    {
      "epoch": 0.6715555555555556,
      "grad_norm": 0.5209901332855225,
      "learning_rate": 1.642222222222222e-05,
      "loss": 0.002,
      "step": 15110
    },
    {
      "epoch": 0.672,
      "grad_norm": 0.16560229659080505,
      "learning_rate": 1.6400000000000002e-05,
      "loss": 0.0018,
      "step": 15120
    },
    {
      "epoch": 0.6724444444444444,
      "grad_norm": 0.09774425625801086,
      "learning_rate": 1.6377777777777776e-05,
      "loss": 0.0015,
      "step": 15130
    },
    {
      "epoch": 0.6728888888888889,
      "grad_norm": 0.11157815903425217,
      "learning_rate": 1.6355555555555557e-05,
      "loss": 0.0017,
      "step": 15140
    },
    {
      "epoch": 0.6733333333333333,
      "grad_norm": 0.12477929890155792,
      "learning_rate": 1.6333333333333335e-05,
      "loss": 0.0021,
      "step": 15150
    },
    {
      "epoch": 0.6737777777777778,
      "grad_norm": 0.09826882183551788,
      "learning_rate": 1.6311111111111113e-05,
      "loss": 0.0019,
      "step": 15160
    },
    {
      "epoch": 0.6742222222222222,
      "grad_norm": 0.16519761085510254,
      "learning_rate": 1.628888888888889e-05,
      "loss": 0.002,
      "step": 15170
    },
    {
      "epoch": 0.6746666666666666,
      "grad_norm": 0.058387670665979385,
      "learning_rate": 1.6266666666666665e-05,
      "loss": 0.002,
      "step": 15180
    },
    {
      "epoch": 0.6751111111111111,
      "grad_norm": 0.2890740931034088,
      "learning_rate": 1.6244444444444446e-05,
      "loss": 0.002,
      "step": 15190
    },
    {
      "epoch": 0.6755555555555556,
      "grad_norm": 0.24746385216712952,
      "learning_rate": 1.6222222222222223e-05,
      "loss": 0.0016,
      "step": 15200
    },
    {
      "epoch": 0.676,
      "grad_norm": 0.2760349214076996,
      "learning_rate": 1.62e-05,
      "loss": 0.002,
      "step": 15210
    },
    {
      "epoch": 0.6764444444444444,
      "grad_norm": 0.12531492114067078,
      "learning_rate": 1.617777777777778e-05,
      "loss": 0.002,
      "step": 15220
    },
    {
      "epoch": 0.6768888888888889,
      "grad_norm": 0.2341795563697815,
      "learning_rate": 1.6155555555555556e-05,
      "loss": 0.0016,
      "step": 15230
    },
    {
      "epoch": 0.6773333333333333,
      "grad_norm": 0.08339612185955048,
      "learning_rate": 1.6133333333333334e-05,
      "loss": 0.0019,
      "step": 15240
    },
    {
      "epoch": 0.6777777777777778,
      "grad_norm": 0.4805160462856293,
      "learning_rate": 1.6111111111111115e-05,
      "loss": 0.0016,
      "step": 15250
    },
    {
      "epoch": 0.6782222222222222,
      "grad_norm": 0.19356268644332886,
      "learning_rate": 1.608888888888889e-05,
      "loss": 0.0018,
      "step": 15260
    },
    {
      "epoch": 0.6786666666666666,
      "grad_norm": 0.05010423809289932,
      "learning_rate": 1.606666666666667e-05,
      "loss": 0.0017,
      "step": 15270
    },
    {
      "epoch": 0.6791111111111111,
      "grad_norm": 0.05755282938480377,
      "learning_rate": 1.6044444444444444e-05,
      "loss": 0.0016,
      "step": 15280
    },
    {
      "epoch": 0.6795555555555556,
      "grad_norm": 0.397726833820343,
      "learning_rate": 1.602222222222222e-05,
      "loss": 0.002,
      "step": 15290
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.32929807901382446,
      "learning_rate": 1.6000000000000003e-05,
      "loss": 0.002,
      "step": 15300
    },
    {
      "epoch": 0.6804444444444444,
      "grad_norm": 0.28876641392707825,
      "learning_rate": 1.5977777777777777e-05,
      "loss": 0.002,
      "step": 15310
    },
    {
      "epoch": 0.6808888888888889,
      "grad_norm": 0.06116718798875809,
      "learning_rate": 1.5955555555555558e-05,
      "loss": 0.0024,
      "step": 15320
    },
    {
      "epoch": 0.6813333333333333,
      "grad_norm": 0.4944680631160736,
      "learning_rate": 1.5933333333333332e-05,
      "loss": 0.002,
      "step": 15330
    },
    {
      "epoch": 0.6817777777777778,
      "grad_norm": 0.13928362727165222,
      "learning_rate": 1.5911111111111113e-05,
      "loss": 0.002,
      "step": 15340
    },
    {
      "epoch": 0.6822222222222222,
      "grad_norm": 0.09828607738018036,
      "learning_rate": 1.588888888888889e-05,
      "loss": 0.0022,
      "step": 15350
    },
    {
      "epoch": 0.6826666666666666,
      "grad_norm": 0.37109556794166565,
      "learning_rate": 1.586666666666667e-05,
      "loss": 0.0019,
      "step": 15360
    },
    {
      "epoch": 0.6831111111111111,
      "grad_norm": 0.21969880163669586,
      "learning_rate": 1.5844444444444446e-05,
      "loss": 0.0016,
      "step": 15370
    },
    {
      "epoch": 0.6835555555555556,
      "grad_norm": 0.22045446932315826,
      "learning_rate": 1.582222222222222e-05,
      "loss": 0.0018,
      "step": 15380
    },
    {
      "epoch": 0.684,
      "grad_norm": 0.2634313404560089,
      "learning_rate": 1.58e-05,
      "loss": 0.0017,
      "step": 15390
    },
    {
      "epoch": 0.6844444444444444,
      "grad_norm": 0.029764588922262192,
      "learning_rate": 1.577777777777778e-05,
      "loss": 0.002,
      "step": 15400
    },
    {
      "epoch": 0.6848888888888889,
      "grad_norm": 0.15230348706245422,
      "learning_rate": 1.5755555555555556e-05,
      "loss": 0.0019,
      "step": 15410
    },
    {
      "epoch": 0.6853333333333333,
      "grad_norm": 0.12607327103614807,
      "learning_rate": 1.5733333333333334e-05,
      "loss": 0.002,
      "step": 15420
    },
    {
      "epoch": 0.6857777777777778,
      "grad_norm": 0.2698986530303955,
      "learning_rate": 1.571111111111111e-05,
      "loss": 0.0018,
      "step": 15430
    },
    {
      "epoch": 0.6862222222222222,
      "grad_norm": 0.017801860347390175,
      "learning_rate": 1.568888888888889e-05,
      "loss": 0.0018,
      "step": 15440
    },
    {
      "epoch": 0.6866666666666666,
      "grad_norm": 0.05971182510256767,
      "learning_rate": 1.5666666666666667e-05,
      "loss": 0.0021,
      "step": 15450
    },
    {
      "epoch": 0.6871111111111111,
      "grad_norm": 0.04890206828713417,
      "learning_rate": 1.5644444444444444e-05,
      "loss": 0.0018,
      "step": 15460
    },
    {
      "epoch": 0.6875555555555556,
      "grad_norm": 0.42579057812690735,
      "learning_rate": 1.5622222222222225e-05,
      "loss": 0.0023,
      "step": 15470
    },
    {
      "epoch": 0.688,
      "grad_norm": 0.39784547686576843,
      "learning_rate": 1.56e-05,
      "loss": 0.0018,
      "step": 15480
    },
    {
      "epoch": 0.6884444444444444,
      "grad_norm": 0.057583995163440704,
      "learning_rate": 1.5577777777777777e-05,
      "loss": 0.0019,
      "step": 15490
    },
    {
      "epoch": 0.6888888888888889,
      "grad_norm": 0.19193610548973083,
      "learning_rate": 1.5555555555555555e-05,
      "loss": 0.0021,
      "step": 15500
    },
    {
      "epoch": 0.6893333333333334,
      "grad_norm": 0.2753938138484955,
      "learning_rate": 1.5533333333333333e-05,
      "loss": 0.0017,
      "step": 15510
    },
    {
      "epoch": 0.6897777777777778,
      "grad_norm": 0.4540744423866272,
      "learning_rate": 1.5511111111111114e-05,
      "loss": 0.0021,
      "step": 15520
    },
    {
      "epoch": 0.6902222222222222,
      "grad_norm": 0.35774704813957214,
      "learning_rate": 1.5488888888888888e-05,
      "loss": 0.0019,
      "step": 15530
    },
    {
      "epoch": 0.6906666666666667,
      "grad_norm": 0.24968893826007843,
      "learning_rate": 1.546666666666667e-05,
      "loss": 0.0019,
      "step": 15540
    },
    {
      "epoch": 0.6911111111111111,
      "grad_norm": 0.3035494089126587,
      "learning_rate": 1.5444444444444446e-05,
      "loss": 0.0017,
      "step": 15550
    },
    {
      "epoch": 0.6915555555555556,
      "grad_norm": 0.12422068417072296,
      "learning_rate": 1.5422222222222224e-05,
      "loss": 0.0019,
      "step": 15560
    },
    {
      "epoch": 0.692,
      "grad_norm": 0.08391285687685013,
      "learning_rate": 1.54e-05,
      "loss": 0.0016,
      "step": 15570
    },
    {
      "epoch": 0.6924444444444444,
      "grad_norm": 0.2352360635995865,
      "learning_rate": 1.537777777777778e-05,
      "loss": 0.0025,
      "step": 15580
    },
    {
      "epoch": 0.6928888888888889,
      "grad_norm": 0.24744033813476562,
      "learning_rate": 1.5355555555555557e-05,
      "loss": 0.0016,
      "step": 15590
    },
    {
      "epoch": 0.6933333333333334,
      "grad_norm": 0.1802314817905426,
      "learning_rate": 1.5333333333333334e-05,
      "loss": 0.0016,
      "step": 15600
    },
    {
      "epoch": 0.6937777777777778,
      "grad_norm": 0.2480039894580841,
      "learning_rate": 1.5311111111111112e-05,
      "loss": 0.0021,
      "step": 15610
    },
    {
      "epoch": 0.6942222222222222,
      "grad_norm": 0.11184966564178467,
      "learning_rate": 1.528888888888889e-05,
      "loss": 0.0022,
      "step": 15620
    },
    {
      "epoch": 0.6946666666666667,
      "grad_norm": 0.020556984469294548,
      "learning_rate": 1.5266666666666667e-05,
      "loss": 0.0023,
      "step": 15630
    },
    {
      "epoch": 0.6951111111111111,
      "grad_norm": 0.16545021533966064,
      "learning_rate": 1.5244444444444445e-05,
      "loss": 0.0017,
      "step": 15640
    },
    {
      "epoch": 0.6955555555555556,
      "grad_norm": 0.034823931753635406,
      "learning_rate": 1.5222222222222224e-05,
      "loss": 0.0022,
      "step": 15650
    },
    {
      "epoch": 0.696,
      "grad_norm": 0.24860921502113342,
      "learning_rate": 1.52e-05,
      "loss": 0.0019,
      "step": 15660
    },
    {
      "epoch": 0.6964444444444444,
      "grad_norm": 0.36872345209121704,
      "learning_rate": 1.517777777777778e-05,
      "loss": 0.0024,
      "step": 15670
    },
    {
      "epoch": 0.6968888888888889,
      "grad_norm": 0.3439537286758423,
      "learning_rate": 1.5155555555555555e-05,
      "loss": 0.002,
      "step": 15680
    },
    {
      "epoch": 0.6973333333333334,
      "grad_norm": 0.3853244185447693,
      "learning_rate": 1.5133333333333333e-05,
      "loss": 0.002,
      "step": 15690
    },
    {
      "epoch": 0.6977777777777778,
      "grad_norm": 0.12511438131332397,
      "learning_rate": 1.5111111111111112e-05,
      "loss": 0.0017,
      "step": 15700
    },
    {
      "epoch": 0.6982222222222222,
      "grad_norm": 0.06993257254362106,
      "learning_rate": 1.5088888888888888e-05,
      "loss": 0.002,
      "step": 15710
    },
    {
      "epoch": 0.6986666666666667,
      "grad_norm": 0.08378894627094269,
      "learning_rate": 1.5066666666666668e-05,
      "loss": 0.0017,
      "step": 15720
    },
    {
      "epoch": 0.6991111111111111,
      "grad_norm": 0.2209920585155487,
      "learning_rate": 1.5044444444444445e-05,
      "loss": 0.0019,
      "step": 15730
    },
    {
      "epoch": 0.6995555555555556,
      "grad_norm": 0.2747599184513092,
      "learning_rate": 1.5022222222222224e-05,
      "loss": 0.0017,
      "step": 15740
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.18244783580303192,
      "learning_rate": 1.5e-05,
      "loss": 0.0021,
      "step": 15750
    },
    {
      "epoch": 0.7004444444444444,
      "grad_norm": 0.2903786301612854,
      "learning_rate": 1.497777777777778e-05,
      "loss": 0.0018,
      "step": 15760
    },
    {
      "epoch": 0.7008888888888889,
      "grad_norm": 0.35830238461494446,
      "learning_rate": 1.4955555555555556e-05,
      "loss": 0.0023,
      "step": 15770
    },
    {
      "epoch": 0.7013333333333334,
      "grad_norm": 0.020177843049168587,
      "learning_rate": 1.4933333333333335e-05,
      "loss": 0.002,
      "step": 15780
    },
    {
      "epoch": 0.7017777777777777,
      "grad_norm": 0.19251573085784912,
      "learning_rate": 1.4911111111111113e-05,
      "loss": 0.0016,
      "step": 15790
    },
    {
      "epoch": 0.7022222222222222,
      "grad_norm": 0.08596429973840714,
      "learning_rate": 1.4888888888888888e-05,
      "loss": 0.0018,
      "step": 15800
    },
    {
      "epoch": 0.7026666666666667,
      "grad_norm": 0.03528070077300072,
      "learning_rate": 1.4866666666666668e-05,
      "loss": 0.0019,
      "step": 15810
    },
    {
      "epoch": 0.7031111111111111,
      "grad_norm": 0.2891913056373596,
      "learning_rate": 1.4844444444444444e-05,
      "loss": 0.0021,
      "step": 15820
    },
    {
      "epoch": 0.7035555555555556,
      "grad_norm": 0.19257687032222748,
      "learning_rate": 1.4822222222222223e-05,
      "loss": 0.0026,
      "step": 15830
    },
    {
      "epoch": 0.704,
      "grad_norm": 0.39947232604026794,
      "learning_rate": 1.48e-05,
      "loss": 0.0027,
      "step": 15840
    },
    {
      "epoch": 0.7044444444444444,
      "grad_norm": 0.4665055274963379,
      "learning_rate": 1.477777777777778e-05,
      "loss": 0.0024,
      "step": 15850
    },
    {
      "epoch": 0.7048888888888889,
      "grad_norm": 0.13946139812469482,
      "learning_rate": 1.4755555555555556e-05,
      "loss": 0.0019,
      "step": 15860
    },
    {
      "epoch": 0.7053333333333334,
      "grad_norm": 0.11183572560548782,
      "learning_rate": 1.4733333333333335e-05,
      "loss": 0.0022,
      "step": 15870
    },
    {
      "epoch": 0.7057777777777777,
      "grad_norm": 0.23454876244068146,
      "learning_rate": 1.4711111111111111e-05,
      "loss": 0.0017,
      "step": 15880
    },
    {
      "epoch": 0.7062222222222222,
      "grad_norm": 0.12687550485134125,
      "learning_rate": 1.468888888888889e-05,
      "loss": 0.0017,
      "step": 15890
    },
    {
      "epoch": 0.7066666666666667,
      "grad_norm": 0.32912981510162354,
      "learning_rate": 1.4666666666666668e-05,
      "loss": 0.0018,
      "step": 15900
    },
    {
      "epoch": 0.7071111111111111,
      "grad_norm": 0.4808287024497986,
      "learning_rate": 1.4644444444444444e-05,
      "loss": 0.0019,
      "step": 15910
    },
    {
      "epoch": 0.7075555555555556,
      "grad_norm": 0.09663604199886322,
      "learning_rate": 1.4622222222222223e-05,
      "loss": 0.0018,
      "step": 15920
    },
    {
      "epoch": 0.708,
      "grad_norm": 0.09005226194858551,
      "learning_rate": 1.4599999999999999e-05,
      "loss": 0.0021,
      "step": 15930
    },
    {
      "epoch": 0.7084444444444444,
      "grad_norm": 0.15206532180309296,
      "learning_rate": 1.4577777777777778e-05,
      "loss": 0.0019,
      "step": 15940
    },
    {
      "epoch": 0.7088888888888889,
      "grad_norm": 0.046173788607120514,
      "learning_rate": 1.4555555555555556e-05,
      "loss": 0.0019,
      "step": 15950
    },
    {
      "epoch": 0.7093333333333334,
      "grad_norm": 0.24874770641326904,
      "learning_rate": 1.4533333333333335e-05,
      "loss": 0.0018,
      "step": 15960
    },
    {
      "epoch": 0.7097777777777777,
      "grad_norm": 0.28907349705696106,
      "learning_rate": 1.4511111111111111e-05,
      "loss": 0.0019,
      "step": 15970
    },
    {
      "epoch": 0.7102222222222222,
      "grad_norm": 0.30409640073776245,
      "learning_rate": 1.448888888888889e-05,
      "loss": 0.0018,
      "step": 15980
    },
    {
      "epoch": 0.7106666666666667,
      "grad_norm": 0.2891993820667267,
      "learning_rate": 1.4466666666666667e-05,
      "loss": 0.002,
      "step": 15990
    },
    {
      "epoch": 0.7111111111111111,
      "grad_norm": 0.072407566010952,
      "learning_rate": 1.4444444444444444e-05,
      "loss": 0.0016,
      "step": 16000
    },
    {
      "epoch": 0.7115555555555556,
      "grad_norm": 0.07181179523468018,
      "learning_rate": 1.4422222222222223e-05,
      "loss": 0.002,
      "step": 16010
    },
    {
      "epoch": 0.712,
      "grad_norm": 0.17952822148799896,
      "learning_rate": 1.44e-05,
      "loss": 0.0018,
      "step": 16020
    },
    {
      "epoch": 0.7124444444444444,
      "grad_norm": 0.04668138548731804,
      "learning_rate": 1.4377777777777779e-05,
      "loss": 0.0017,
      "step": 16030
    },
    {
      "epoch": 0.7128888888888889,
      "grad_norm": 0.08758468180894852,
      "learning_rate": 1.4355555555555556e-05,
      "loss": 0.0025,
      "step": 16040
    },
    {
      "epoch": 0.7133333333333334,
      "grad_norm": 0.24766188859939575,
      "learning_rate": 1.4333333333333334e-05,
      "loss": 0.0019,
      "step": 16050
    },
    {
      "epoch": 0.7137777777777777,
      "grad_norm": 0.2889711558818817,
      "learning_rate": 1.4311111111111111e-05,
      "loss": 0.0024,
      "step": 16060
    },
    {
      "epoch": 0.7142222222222222,
      "grad_norm": 0.5643506050109863,
      "learning_rate": 1.428888888888889e-05,
      "loss": 0.0024,
      "step": 16070
    },
    {
      "epoch": 0.7146666666666667,
      "grad_norm": 0.37141185998916626,
      "learning_rate": 1.4266666666666667e-05,
      "loss": 0.0022,
      "step": 16080
    },
    {
      "epoch": 0.7151111111111111,
      "grad_norm": 0.20852088928222656,
      "learning_rate": 1.4244444444444446e-05,
      "loss": 0.0017,
      "step": 16090
    },
    {
      "epoch": 0.7155555555555555,
      "grad_norm": 0.3301321268081665,
      "learning_rate": 1.4222222222222224e-05,
      "loss": 0.0015,
      "step": 16100
    },
    {
      "epoch": 0.716,
      "grad_norm": 0.4538823664188385,
      "learning_rate": 1.42e-05,
      "loss": 0.0017,
      "step": 16110
    },
    {
      "epoch": 0.7164444444444444,
      "grad_norm": 0.1662857085466385,
      "learning_rate": 1.4177777777777779e-05,
      "loss": 0.002,
      "step": 16120
    },
    {
      "epoch": 0.7168888888888889,
      "grad_norm": 0.12503287196159363,
      "learning_rate": 1.4155555555555555e-05,
      "loss": 0.0023,
      "step": 16130
    },
    {
      "epoch": 0.7173333333333334,
      "grad_norm": 0.19410565495491028,
      "learning_rate": 1.4133333333333334e-05,
      "loss": 0.0016,
      "step": 16140
    },
    {
      "epoch": 0.7177777777777777,
      "grad_norm": 0.1658928543329239,
      "learning_rate": 1.4111111111111112e-05,
      "loss": 0.002,
      "step": 16150
    },
    {
      "epoch": 0.7182222222222222,
      "grad_norm": 0.1668517142534256,
      "learning_rate": 1.4088888888888891e-05,
      "loss": 0.002,
      "step": 16160
    },
    {
      "epoch": 0.7186666666666667,
      "grad_norm": 0.013054050505161285,
      "learning_rate": 1.4066666666666667e-05,
      "loss": 0.0018,
      "step": 16170
    },
    {
      "epoch": 0.7191111111111111,
      "grad_norm": 0.2091762274503708,
      "learning_rate": 1.4044444444444446e-05,
      "loss": 0.0016,
      "step": 16180
    },
    {
      "epoch": 0.7195555555555555,
      "grad_norm": 0.168765589594841,
      "learning_rate": 1.4022222222222222e-05,
      "loss": 0.0019,
      "step": 16190
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.45391419529914856,
      "learning_rate": 1.4000000000000001e-05,
      "loss": 0.0025,
      "step": 16200
    },
    {
      "epoch": 0.7204444444444444,
      "grad_norm": 0.19412635266780853,
      "learning_rate": 1.3977777777777779e-05,
      "loss": 0.0023,
      "step": 16210
    },
    {
      "epoch": 0.7208888888888889,
      "grad_norm": 0.31730514764785767,
      "learning_rate": 1.3955555555555555e-05,
      "loss": 0.0018,
      "step": 16220
    },
    {
      "epoch": 0.7213333333333334,
      "grad_norm": 0.46741336584091187,
      "learning_rate": 1.3933333333333334e-05,
      "loss": 0.0017,
      "step": 16230
    },
    {
      "epoch": 0.7217777777777777,
      "grad_norm": 0.24749216437339783,
      "learning_rate": 1.391111111111111e-05,
      "loss": 0.0023,
      "step": 16240
    },
    {
      "epoch": 0.7222222222222222,
      "grad_norm": 0.17986217141151428,
      "learning_rate": 1.388888888888889e-05,
      "loss": 0.0017,
      "step": 16250
    },
    {
      "epoch": 0.7226666666666667,
      "grad_norm": 0.08437655121088028,
      "learning_rate": 1.3866666666666667e-05,
      "loss": 0.0017,
      "step": 16260
    },
    {
      "epoch": 0.7231111111111111,
      "grad_norm": 0.018705636262893677,
      "learning_rate": 1.3844444444444446e-05,
      "loss": 0.0018,
      "step": 16270
    },
    {
      "epoch": 0.7235555555555555,
      "grad_norm": 0.022953076288104057,
      "learning_rate": 1.3822222222222222e-05,
      "loss": 0.002,
      "step": 16280
    },
    {
      "epoch": 0.724,
      "grad_norm": 0.26176729798316956,
      "learning_rate": 1.3800000000000002e-05,
      "loss": 0.002,
      "step": 16290
    },
    {
      "epoch": 0.7244444444444444,
      "grad_norm": 0.6197811365127563,
      "learning_rate": 1.3777777777777778e-05,
      "loss": 0.0023,
      "step": 16300
    },
    {
      "epoch": 0.7248888888888889,
      "grad_norm": 0.24832597374916077,
      "learning_rate": 1.3755555555555555e-05,
      "loss": 0.0018,
      "step": 16310
    },
    {
      "epoch": 0.7253333333333334,
      "grad_norm": 0.11900942772626877,
      "learning_rate": 1.3733333333333335e-05,
      "loss": 0.0019,
      "step": 16320
    },
    {
      "epoch": 0.7257777777777777,
      "grad_norm": 0.2623383700847626,
      "learning_rate": 1.371111111111111e-05,
      "loss": 0.0018,
      "step": 16330
    },
    {
      "epoch": 0.7262222222222222,
      "grad_norm": 0.28988879919052124,
      "learning_rate": 1.368888888888889e-05,
      "loss": 0.0021,
      "step": 16340
    },
    {
      "epoch": 0.7266666666666667,
      "grad_norm": 0.28936460614204407,
      "learning_rate": 1.3666666666666666e-05,
      "loss": 0.002,
      "step": 16350
    },
    {
      "epoch": 0.7271111111111112,
      "grad_norm": 0.12425645440816879,
      "learning_rate": 1.3644444444444445e-05,
      "loss": 0.0023,
      "step": 16360
    },
    {
      "epoch": 0.7275555555555555,
      "grad_norm": 0.23457059264183044,
      "learning_rate": 1.3622222222222223e-05,
      "loss": 0.0018,
      "step": 16370
    },
    {
      "epoch": 0.728,
      "grad_norm": 0.07111512869596481,
      "learning_rate": 1.3600000000000002e-05,
      "loss": 0.0019,
      "step": 16380
    },
    {
      "epoch": 0.7284444444444444,
      "grad_norm": 0.02136009931564331,
      "learning_rate": 1.3577777777777778e-05,
      "loss": 0.002,
      "step": 16390
    },
    {
      "epoch": 0.7288888888888889,
      "grad_norm": 0.05483328923583031,
      "learning_rate": 1.3555555555555557e-05,
      "loss": 0.0018,
      "step": 16400
    },
    {
      "epoch": 0.7293333333333333,
      "grad_norm": 0.4267580807209015,
      "learning_rate": 1.3533333333333335e-05,
      "loss": 0.0019,
      "step": 16410
    },
    {
      "epoch": 0.7297777777777777,
      "grad_norm": 0.16650943458080292,
      "learning_rate": 1.351111111111111e-05,
      "loss": 0.0022,
      "step": 16420
    },
    {
      "epoch": 0.7302222222222222,
      "grad_norm": 0.2074076384305954,
      "learning_rate": 1.348888888888889e-05,
      "loss": 0.0017,
      "step": 16430
    },
    {
      "epoch": 0.7306666666666667,
      "grad_norm": 0.11150659620761871,
      "learning_rate": 1.3466666666666666e-05,
      "loss": 0.0026,
      "step": 16440
    },
    {
      "epoch": 0.7311111111111112,
      "grad_norm": 0.16578006744384766,
      "learning_rate": 1.3444444444444445e-05,
      "loss": 0.0018,
      "step": 16450
    },
    {
      "epoch": 0.7315555555555555,
      "grad_norm": 0.7418625950813293,
      "learning_rate": 1.3422222222222223e-05,
      "loss": 0.0021,
      "step": 16460
    },
    {
      "epoch": 0.732,
      "grad_norm": 0.09776637703180313,
      "learning_rate": 1.3400000000000002e-05,
      "loss": 0.0019,
      "step": 16470
    },
    {
      "epoch": 0.7324444444444445,
      "grad_norm": 0.2355932742357254,
      "learning_rate": 1.3377777777777778e-05,
      "loss": 0.0018,
      "step": 16480
    },
    {
      "epoch": 0.7328888888888889,
      "grad_norm": 0.2339458167552948,
      "learning_rate": 1.3355555555555557e-05,
      "loss": 0.0018,
      "step": 16490
    },
    {
      "epoch": 0.7333333333333333,
      "grad_norm": 0.3434932827949524,
      "learning_rate": 1.3333333333333333e-05,
      "loss": 0.0022,
      "step": 16500
    },
    {
      "epoch": 0.7337777777777778,
      "grad_norm": 0.15180006623268127,
      "learning_rate": 1.3311111111111113e-05,
      "loss": 0.0018,
      "step": 16510
    },
    {
      "epoch": 0.7342222222222222,
      "grad_norm": 0.16621239483356476,
      "learning_rate": 1.328888888888889e-05,
      "loss": 0.0019,
      "step": 16520
    },
    {
      "epoch": 0.7346666666666667,
      "grad_norm": 0.2753711938858032,
      "learning_rate": 1.3266666666666666e-05,
      "loss": 0.002,
      "step": 16530
    },
    {
      "epoch": 0.7351111111111112,
      "grad_norm": 0.17930369079113007,
      "learning_rate": 1.3244444444444445e-05,
      "loss": 0.0021,
      "step": 16540
    },
    {
      "epoch": 0.7355555555555555,
      "grad_norm": 0.20621934533119202,
      "learning_rate": 1.3222222222222221e-05,
      "loss": 0.002,
      "step": 16550
    },
    {
      "epoch": 0.736,
      "grad_norm": 0.018280988559126854,
      "learning_rate": 1.32e-05,
      "loss": 0.0018,
      "step": 16560
    },
    {
      "epoch": 0.7364444444444445,
      "grad_norm": 0.2617488503456116,
      "learning_rate": 1.3177777777777778e-05,
      "loss": 0.0019,
      "step": 16570
    },
    {
      "epoch": 0.7368888888888889,
      "grad_norm": 0.2338264435529709,
      "learning_rate": 1.3155555555555558e-05,
      "loss": 0.0017,
      "step": 16580
    },
    {
      "epoch": 0.7373333333333333,
      "grad_norm": 0.16544903814792633,
      "learning_rate": 1.3133333333333334e-05,
      "loss": 0.0017,
      "step": 16590
    },
    {
      "epoch": 0.7377777777777778,
      "grad_norm": 0.11110016703605652,
      "learning_rate": 1.3111111111111113e-05,
      "loss": 0.0018,
      "step": 16600
    },
    {
      "epoch": 0.7382222222222222,
      "grad_norm": 0.12539122998714447,
      "learning_rate": 1.3088888888888889e-05,
      "loss": 0.0024,
      "step": 16610
    },
    {
      "epoch": 0.7386666666666667,
      "grad_norm": 0.20677804946899414,
      "learning_rate": 1.3066666666666666e-05,
      "loss": 0.0018,
      "step": 16620
    },
    {
      "epoch": 0.7391111111111112,
      "grad_norm": 0.45260122418403625,
      "learning_rate": 1.3044444444444446e-05,
      "loss": 0.002,
      "step": 16630
    },
    {
      "epoch": 0.7395555555555555,
      "grad_norm": 0.20855790376663208,
      "learning_rate": 1.3022222222222222e-05,
      "loss": 0.0018,
      "step": 16640
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.38610488176345825,
      "learning_rate": 1.3000000000000001e-05,
      "loss": 0.0017,
      "step": 16650
    },
    {
      "epoch": 0.7404444444444445,
      "grad_norm": 0.1934812217950821,
      "learning_rate": 1.2977777777777777e-05,
      "loss": 0.002,
      "step": 16660
    },
    {
      "epoch": 0.7408888888888889,
      "grad_norm": 0.45289915800094604,
      "learning_rate": 1.2955555555555556e-05,
      "loss": 0.002,
      "step": 16670
    },
    {
      "epoch": 0.7413333333333333,
      "grad_norm": 0.046720102429389954,
      "learning_rate": 1.2933333333333334e-05,
      "loss": 0.0019,
      "step": 16680
    },
    {
      "epoch": 0.7417777777777778,
      "grad_norm": 0.37109488248825073,
      "learning_rate": 1.2911111111111113e-05,
      "loss": 0.0018,
      "step": 16690
    },
    {
      "epoch": 0.7422222222222222,
      "grad_norm": 0.4268074929714203,
      "learning_rate": 1.2888888888888889e-05,
      "loss": 0.0019,
      "step": 16700
    },
    {
      "epoch": 0.7426666666666667,
      "grad_norm": 0.22122816741466522,
      "learning_rate": 1.2866666666666668e-05,
      "loss": 0.0019,
      "step": 16710
    },
    {
      "epoch": 0.7431111111111111,
      "grad_norm": 0.044336121529340744,
      "learning_rate": 1.2844444444444446e-05,
      "loss": 0.0019,
      "step": 16720
    },
    {
      "epoch": 0.7435555555555555,
      "grad_norm": 0.7419490218162537,
      "learning_rate": 1.2822222222222222e-05,
      "loss": 0.0021,
      "step": 16730
    },
    {
      "epoch": 0.744,
      "grad_norm": 0.04525667428970337,
      "learning_rate": 1.2800000000000001e-05,
      "loss": 0.0017,
      "step": 16740
    },
    {
      "epoch": 0.7444444444444445,
      "grad_norm": 0.09323088824748993,
      "learning_rate": 1.2777777777777777e-05,
      "loss": 0.0019,
      "step": 16750
    },
    {
      "epoch": 0.7448888888888889,
      "grad_norm": 0.12665243446826935,
      "learning_rate": 1.2755555555555556e-05,
      "loss": 0.0016,
      "step": 16760
    },
    {
      "epoch": 0.7453333333333333,
      "grad_norm": 0.34347209334373474,
      "learning_rate": 1.2733333333333334e-05,
      "loss": 0.002,
      "step": 16770
    },
    {
      "epoch": 0.7457777777777778,
      "grad_norm": 0.112407386302948,
      "learning_rate": 1.2711111111111113e-05,
      "loss": 0.0019,
      "step": 16780
    },
    {
      "epoch": 0.7462222222222222,
      "grad_norm": 0.329504132270813,
      "learning_rate": 1.268888888888889e-05,
      "loss": 0.0018,
      "step": 16790
    },
    {
      "epoch": 0.7466666666666667,
      "grad_norm": 0.07664017379283905,
      "learning_rate": 1.2666666666666668e-05,
      "loss": 0.0019,
      "step": 16800
    },
    {
      "epoch": 0.7471111111111111,
      "grad_norm": 0.20645862817764282,
      "learning_rate": 1.2644444444444444e-05,
      "loss": 0.0018,
      "step": 16810
    },
    {
      "epoch": 0.7475555555555555,
      "grad_norm": 0.04273916035890579,
      "learning_rate": 1.2622222222222224e-05,
      "loss": 0.0018,
      "step": 16820
    },
    {
      "epoch": 0.748,
      "grad_norm": 0.27544090151786804,
      "learning_rate": 1.2600000000000001e-05,
      "loss": 0.002,
      "step": 16830
    },
    {
      "epoch": 0.7484444444444445,
      "grad_norm": 0.19355639815330505,
      "learning_rate": 1.2577777777777777e-05,
      "loss": 0.0025,
      "step": 16840
    },
    {
      "epoch": 0.7488888888888889,
      "grad_norm": 0.39931944012641907,
      "learning_rate": 1.2555555555555557e-05,
      "loss": 0.0023,
      "step": 16850
    },
    {
      "epoch": 0.7493333333333333,
      "grad_norm": 0.28923285007476807,
      "learning_rate": 1.2533333333333332e-05,
      "loss": 0.0019,
      "step": 16860
    },
    {
      "epoch": 0.7497777777777778,
      "grad_norm": 0.033143300563097,
      "learning_rate": 1.2511111111111112e-05,
      "loss": 0.0017,
      "step": 16870
    },
    {
      "epoch": 0.7502222222222222,
      "grad_norm": 0.16556806862354279,
      "learning_rate": 1.248888888888889e-05,
      "loss": 0.0018,
      "step": 16880
    },
    {
      "epoch": 0.7506666666666667,
      "grad_norm": 0.3858157694339752,
      "learning_rate": 1.2466666666666667e-05,
      "loss": 0.0018,
      "step": 16890
    },
    {
      "epoch": 0.7511111111111111,
      "grad_norm": 0.19260092079639435,
      "learning_rate": 1.2444444444444445e-05,
      "loss": 0.0017,
      "step": 16900
    },
    {
      "epoch": 0.7515555555555555,
      "grad_norm": 0.302592009305954,
      "learning_rate": 1.2422222222222222e-05,
      "loss": 0.0017,
      "step": 16910
    },
    {
      "epoch": 0.752,
      "grad_norm": 0.057225584983825684,
      "learning_rate": 1.24e-05,
      "loss": 0.0018,
      "step": 16920
    },
    {
      "epoch": 0.7524444444444445,
      "grad_norm": 0.43940481543540955,
      "learning_rate": 1.237777777777778e-05,
      "loss": 0.0021,
      "step": 16930
    },
    {
      "epoch": 0.7528888888888889,
      "grad_norm": 0.028331156820058823,
      "learning_rate": 1.2355555555555557e-05,
      "loss": 0.0017,
      "step": 16940
    },
    {
      "epoch": 0.7533333333333333,
      "grad_norm": 0.5496813654899597,
      "learning_rate": 1.2333333333333334e-05,
      "loss": 0.0023,
      "step": 16950
    },
    {
      "epoch": 0.7537777777777778,
      "grad_norm": 0.4268113970756531,
      "learning_rate": 1.2311111111111112e-05,
      "loss": 0.002,
      "step": 16960
    },
    {
      "epoch": 0.7542222222222222,
      "grad_norm": 0.12527519464492798,
      "learning_rate": 1.228888888888889e-05,
      "loss": 0.0019,
      "step": 16970
    },
    {
      "epoch": 0.7546666666666667,
      "grad_norm": 0.46508315205574036,
      "learning_rate": 1.2266666666666667e-05,
      "loss": 0.0021,
      "step": 16980
    },
    {
      "epoch": 0.7551111111111111,
      "grad_norm": 0.4020032584667206,
      "learning_rate": 1.2244444444444445e-05,
      "loss": 0.0017,
      "step": 16990
    },
    {
      "epoch": 0.7555555555555555,
      "grad_norm": 0.23398837447166443,
      "learning_rate": 1.2222222222222222e-05,
      "loss": 0.0016,
      "step": 17000
    },
    {
      "epoch": 0.756,
      "grad_norm": 0.11087924987077713,
      "learning_rate": 1.22e-05,
      "loss": 0.0018,
      "step": 17010
    },
    {
      "epoch": 0.7564444444444445,
      "grad_norm": 0.1662788838148117,
      "learning_rate": 1.2177777777777778e-05,
      "loss": 0.0019,
      "step": 17020
    },
    {
      "epoch": 0.7568888888888889,
      "grad_norm": 0.24696463346481323,
      "learning_rate": 1.2155555555555555e-05,
      "loss": 0.0018,
      "step": 17030
    },
    {
      "epoch": 0.7573333333333333,
      "grad_norm": 0.2488335371017456,
      "learning_rate": 1.2133333333333335e-05,
      "loss": 0.0019,
      "step": 17040
    },
    {
      "epoch": 0.7577777777777778,
      "grad_norm": 0.08311328291893005,
      "learning_rate": 1.2111111111111112e-05,
      "loss": 0.0018,
      "step": 17050
    },
    {
      "epoch": 0.7582222222222222,
      "grad_norm": 0.08446421474218369,
      "learning_rate": 1.208888888888889e-05,
      "loss": 0.0019,
      "step": 17060
    },
    {
      "epoch": 0.7586666666666667,
      "grad_norm": 0.1116417944431305,
      "learning_rate": 1.2066666666666667e-05,
      "loss": 0.0016,
      "step": 17070
    },
    {
      "epoch": 0.7591111111111111,
      "grad_norm": 0.11147301644086838,
      "learning_rate": 1.2044444444444445e-05,
      "loss": 0.002,
      "step": 17080
    },
    {
      "epoch": 0.7595555555555555,
      "grad_norm": 0.262560099363327,
      "learning_rate": 1.2022222222222223e-05,
      "loss": 0.0022,
      "step": 17090
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.2472614049911499,
      "learning_rate": 1.2e-05,
      "loss": 0.0025,
      "step": 17100
    },
    {
      "epoch": 0.7604444444444445,
      "grad_norm": 0.07174909859895706,
      "learning_rate": 1.1977777777777778e-05,
      "loss": 0.0017,
      "step": 17110
    },
    {
      "epoch": 0.7608888888888888,
      "grad_norm": 0.0982920378446579,
      "learning_rate": 1.1955555555555556e-05,
      "loss": 0.0016,
      "step": 17120
    },
    {
      "epoch": 0.7613333333333333,
      "grad_norm": 0.08501748740673065,
      "learning_rate": 1.1933333333333333e-05,
      "loss": 0.0017,
      "step": 17130
    },
    {
      "epoch": 0.7617777777777778,
      "grad_norm": 0.01901760697364807,
      "learning_rate": 1.1911111111111112e-05,
      "loss": 0.0022,
      "step": 17140
    },
    {
      "epoch": 0.7622222222222222,
      "grad_norm": 0.043494436889886856,
      "learning_rate": 1.188888888888889e-05,
      "loss": 0.0017,
      "step": 17150
    },
    {
      "epoch": 0.7626666666666667,
      "grad_norm": 0.384657621383667,
      "learning_rate": 1.1866666666666668e-05,
      "loss": 0.0017,
      "step": 17160
    },
    {
      "epoch": 0.7631111111111111,
      "grad_norm": 0.08515392243862152,
      "learning_rate": 1.1844444444444445e-05,
      "loss": 0.002,
      "step": 17170
    },
    {
      "epoch": 0.7635555555555555,
      "grad_norm": 0.3338289260864258,
      "learning_rate": 1.1822222222222223e-05,
      "loss": 0.0017,
      "step": 17180
    },
    {
      "epoch": 0.764,
      "grad_norm": 0.1926237791776657,
      "learning_rate": 1.18e-05,
      "loss": 0.0016,
      "step": 17190
    },
    {
      "epoch": 0.7644444444444445,
      "grad_norm": 0.3718979060649872,
      "learning_rate": 1.1777777777777778e-05,
      "loss": 0.0017,
      "step": 17200
    },
    {
      "epoch": 0.7648888888888888,
      "grad_norm": 0.1794910877943039,
      "learning_rate": 1.1755555555555556e-05,
      "loss": 0.0019,
      "step": 17210
    },
    {
      "epoch": 0.7653333333333333,
      "grad_norm": 0.03403439372777939,
      "learning_rate": 1.1733333333333333e-05,
      "loss": 0.0016,
      "step": 17220
    },
    {
      "epoch": 0.7657777777777778,
      "grad_norm": 0.4809598922729492,
      "learning_rate": 1.1711111111111111e-05,
      "loss": 0.0019,
      "step": 17230
    },
    {
      "epoch": 0.7662222222222222,
      "grad_norm": 0.08563140034675598,
      "learning_rate": 1.168888888888889e-05,
      "loss": 0.0017,
      "step": 17240
    },
    {
      "epoch": 0.7666666666666667,
      "grad_norm": 0.1953016221523285,
      "learning_rate": 1.1666666666666668e-05,
      "loss": 0.0016,
      "step": 17250
    },
    {
      "epoch": 0.7671111111111111,
      "grad_norm": 0.23388361930847168,
      "learning_rate": 1.1644444444444446e-05,
      "loss": 0.0018,
      "step": 17260
    },
    {
      "epoch": 0.7675555555555555,
      "grad_norm": 0.1657736897468567,
      "learning_rate": 1.1622222222222223e-05,
      "loss": 0.0021,
      "step": 17270
    },
    {
      "epoch": 0.768,
      "grad_norm": 0.031270913779735565,
      "learning_rate": 1.16e-05,
      "loss": 0.0017,
      "step": 17280
    },
    {
      "epoch": 0.7684444444444445,
      "grad_norm": 0.302067369222641,
      "learning_rate": 1.1577777777777778e-05,
      "loss": 0.0018,
      "step": 17290
    },
    {
      "epoch": 0.7688888888888888,
      "grad_norm": 0.6181604862213135,
      "learning_rate": 1.1555555555555556e-05,
      "loss": 0.0023,
      "step": 17300
    },
    {
      "epoch": 0.7693333333333333,
      "grad_norm": 0.3163211941719055,
      "learning_rate": 1.1533333333333334e-05,
      "loss": 0.002,
      "step": 17310
    },
    {
      "epoch": 0.7697777777777778,
      "grad_norm": 0.5625362396240234,
      "learning_rate": 1.1511111111111111e-05,
      "loss": 0.0021,
      "step": 17320
    },
    {
      "epoch": 0.7702222222222223,
      "grad_norm": 0.1732957810163498,
      "learning_rate": 1.1488888888888889e-05,
      "loss": 0.0019,
      "step": 17330
    },
    {
      "epoch": 0.7706666666666667,
      "grad_norm": 0.7141879200935364,
      "learning_rate": 1.1466666666666666e-05,
      "loss": 0.0019,
      "step": 17340
    },
    {
      "epoch": 0.7711111111111111,
      "grad_norm": 0.39878129959106445,
      "learning_rate": 1.1444444444444446e-05,
      "loss": 0.0022,
      "step": 17350
    },
    {
      "epoch": 0.7715555555555556,
      "grad_norm": 0.23472584784030914,
      "learning_rate": 1.1422222222222223e-05,
      "loss": 0.0019,
      "step": 17360
    },
    {
      "epoch": 0.772,
      "grad_norm": 0.38525596261024475,
      "learning_rate": 1.1400000000000001e-05,
      "loss": 0.0018,
      "step": 17370
    },
    {
      "epoch": 0.7724444444444445,
      "grad_norm": 0.4397335350513458,
      "learning_rate": 1.1377777777777779e-05,
      "loss": 0.0021,
      "step": 17380
    },
    {
      "epoch": 0.7728888888888888,
      "grad_norm": 0.22110803425312042,
      "learning_rate": 1.1355555555555556e-05,
      "loss": 0.0022,
      "step": 17390
    },
    {
      "epoch": 0.7733333333333333,
      "grad_norm": 0.33341866731643677,
      "learning_rate": 1.1333333333333334e-05,
      "loss": 0.0015,
      "step": 17400
    },
    {
      "epoch": 0.7737777777777778,
      "grad_norm": 0.1534482091665268,
      "learning_rate": 1.1311111111111111e-05,
      "loss": 0.002,
      "step": 17410
    },
    {
      "epoch": 0.7742222222222223,
      "grad_norm": 0.17920395731925964,
      "learning_rate": 1.1288888888888889e-05,
      "loss": 0.0017,
      "step": 17420
    },
    {
      "epoch": 0.7746666666666666,
      "grad_norm": 0.23391097784042358,
      "learning_rate": 1.1266666666666667e-05,
      "loss": 0.0022,
      "step": 17430
    },
    {
      "epoch": 0.7751111111111111,
      "grad_norm": 0.4945031404495239,
      "learning_rate": 1.1244444444444444e-05,
      "loss": 0.0016,
      "step": 17440
    },
    {
      "epoch": 0.7755555555555556,
      "grad_norm": 0.38558873534202576,
      "learning_rate": 1.1222222222222224e-05,
      "loss": 0.002,
      "step": 17450
    },
    {
      "epoch": 0.776,
      "grad_norm": 0.26309239864349365,
      "learning_rate": 1.1200000000000001e-05,
      "loss": 0.0021,
      "step": 17460
    },
    {
      "epoch": 0.7764444444444445,
      "grad_norm": 0.04655565693974495,
      "learning_rate": 1.1177777777777779e-05,
      "loss": 0.0021,
      "step": 17470
    },
    {
      "epoch": 0.7768888888888889,
      "grad_norm": 0.21216385066509247,
      "learning_rate": 1.1155555555555556e-05,
      "loss": 0.0022,
      "step": 17480
    },
    {
      "epoch": 0.7773333333333333,
      "grad_norm": 0.15630380809307098,
      "learning_rate": 1.1133333333333334e-05,
      "loss": 0.0019,
      "step": 17490
    },
    {
      "epoch": 0.7777777777777778,
      "grad_norm": 0.4947841465473175,
      "learning_rate": 1.1111111111111112e-05,
      "loss": 0.0018,
      "step": 17500
    },
    {
      "epoch": 0.7782222222222223,
      "grad_norm": 0.39794984459877014,
      "learning_rate": 1.108888888888889e-05,
      "loss": 0.0018,
      "step": 17510
    },
    {
      "epoch": 0.7786666666666666,
      "grad_norm": 0.08697010576725006,
      "learning_rate": 1.1066666666666667e-05,
      "loss": 0.0025,
      "step": 17520
    },
    {
      "epoch": 0.7791111111111111,
      "grad_norm": 0.04665399715304375,
      "learning_rate": 1.1044444444444444e-05,
      "loss": 0.0018,
      "step": 17530
    },
    {
      "epoch": 0.7795555555555556,
      "grad_norm": 0.249872088432312,
      "learning_rate": 1.1022222222222222e-05,
      "loss": 0.0017,
      "step": 17540
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.04215924069285393,
      "learning_rate": 1.1000000000000001e-05,
      "loss": 0.0021,
      "step": 17550
    },
    {
      "epoch": 0.7804444444444445,
      "grad_norm": 0.06344891339540482,
      "learning_rate": 1.0977777777777779e-05,
      "loss": 0.0019,
      "step": 17560
    },
    {
      "epoch": 0.7808888888888889,
      "grad_norm": 0.04031110182404518,
      "learning_rate": 1.0955555555555557e-05,
      "loss": 0.002,
      "step": 17570
    },
    {
      "epoch": 0.7813333333333333,
      "grad_norm": 0.6173912286758423,
      "learning_rate": 1.0933333333333334e-05,
      "loss": 0.0019,
      "step": 17580
    },
    {
      "epoch": 0.7817777777777778,
      "grad_norm": 0.20705893635749817,
      "learning_rate": 1.0911111111111112e-05,
      "loss": 0.0018,
      "step": 17590
    },
    {
      "epoch": 0.7822222222222223,
      "grad_norm": 0.4123660922050476,
      "learning_rate": 1.088888888888889e-05,
      "loss": 0.002,
      "step": 17600
    },
    {
      "epoch": 0.7826666666666666,
      "grad_norm": 0.30329787731170654,
      "learning_rate": 1.0866666666666667e-05,
      "loss": 0.0016,
      "step": 17610
    },
    {
      "epoch": 0.7831111111111111,
      "grad_norm": 0.08756457269191742,
      "learning_rate": 1.0844444444444445e-05,
      "loss": 0.0023,
      "step": 17620
    },
    {
      "epoch": 0.7835555555555556,
      "grad_norm": 0.1383645236492157,
      "learning_rate": 1.0822222222222222e-05,
      "loss": 0.0019,
      "step": 17630
    },
    {
      "epoch": 0.784,
      "grad_norm": 0.46790841221809387,
      "learning_rate": 1.08e-05,
      "loss": 0.002,
      "step": 17640
    },
    {
      "epoch": 0.7844444444444445,
      "grad_norm": 0.04017985239624977,
      "learning_rate": 1.0777777777777778e-05,
      "loss": 0.0021,
      "step": 17650
    },
    {
      "epoch": 0.7848888888888889,
      "grad_norm": 0.024301232770085335,
      "learning_rate": 1.0755555555555557e-05,
      "loss": 0.0018,
      "step": 17660
    },
    {
      "epoch": 0.7853333333333333,
      "grad_norm": 0.27466511726379395,
      "learning_rate": 1.0733333333333334e-05,
      "loss": 0.0017,
      "step": 17670
    },
    {
      "epoch": 0.7857777777777778,
      "grad_norm": 0.4935620129108429,
      "learning_rate": 1.0711111111111112e-05,
      "loss": 0.0019,
      "step": 17680
    },
    {
      "epoch": 0.7862222222222223,
      "grad_norm": 0.0607021227478981,
      "learning_rate": 1.068888888888889e-05,
      "loss": 0.0019,
      "step": 17690
    },
    {
      "epoch": 0.7866666666666666,
      "grad_norm": 0.04646926745772362,
      "learning_rate": 1.0666666666666667e-05,
      "loss": 0.0021,
      "step": 17700
    },
    {
      "epoch": 0.7871111111111111,
      "grad_norm": 0.0323394350707531,
      "learning_rate": 1.0644444444444445e-05,
      "loss": 0.0018,
      "step": 17710
    },
    {
      "epoch": 0.7875555555555556,
      "grad_norm": 0.08369705080986023,
      "learning_rate": 1.0622222222222223e-05,
      "loss": 0.0021,
      "step": 17720
    },
    {
      "epoch": 0.788,
      "grad_norm": 0.24774996936321259,
      "learning_rate": 1.06e-05,
      "loss": 0.0017,
      "step": 17730
    },
    {
      "epoch": 0.7884444444444444,
      "grad_norm": 0.030024094507098198,
      "learning_rate": 1.0577777777777778e-05,
      "loss": 0.0016,
      "step": 17740
    },
    {
      "epoch": 0.7888888888888889,
      "grad_norm": 0.04943984001874924,
      "learning_rate": 1.0555555555555555e-05,
      "loss": 0.0018,
      "step": 17750
    },
    {
      "epoch": 0.7893333333333333,
      "grad_norm": 0.20626762509346008,
      "learning_rate": 1.0533333333333335e-05,
      "loss": 0.0022,
      "step": 17760
    },
    {
      "epoch": 0.7897777777777778,
      "grad_norm": 0.22272121906280518,
      "learning_rate": 1.0511111111111112e-05,
      "loss": 0.0018,
      "step": 17770
    },
    {
      "epoch": 0.7902222222222223,
      "grad_norm": 0.07131896167993546,
      "learning_rate": 1.048888888888889e-05,
      "loss": 0.0018,
      "step": 17780
    },
    {
      "epoch": 0.7906666666666666,
      "grad_norm": 0.7825363874435425,
      "learning_rate": 1.0466666666666668e-05,
      "loss": 0.0022,
      "step": 17790
    },
    {
      "epoch": 0.7911111111111111,
      "grad_norm": 0.17941685020923615,
      "learning_rate": 1.0444444444444445e-05,
      "loss": 0.002,
      "step": 17800
    },
    {
      "epoch": 0.7915555555555556,
      "grad_norm": 0.33029356598854065,
      "learning_rate": 1.0422222222222223e-05,
      "loss": 0.0021,
      "step": 17810
    },
    {
      "epoch": 0.792,
      "grad_norm": 0.14160627126693726,
      "learning_rate": 1.04e-05,
      "loss": 0.0023,
      "step": 17820
    },
    {
      "epoch": 0.7924444444444444,
      "grad_norm": 0.044963594526052475,
      "learning_rate": 1.0377777777777778e-05,
      "loss": 0.0018,
      "step": 17830
    },
    {
      "epoch": 0.7928888888888889,
      "grad_norm": 0.28857991099357605,
      "learning_rate": 1.0355555555555556e-05,
      "loss": 0.0018,
      "step": 17840
    },
    {
      "epoch": 0.7933333333333333,
      "grad_norm": 0.3446287512779236,
      "learning_rate": 1.0333333333333333e-05,
      "loss": 0.0015,
      "step": 17850
    },
    {
      "epoch": 0.7937777777777778,
      "grad_norm": 0.09776636958122253,
      "learning_rate": 1.031111111111111e-05,
      "loss": 0.002,
      "step": 17860
    },
    {
      "epoch": 0.7942222222222223,
      "grad_norm": 0.04387073218822479,
      "learning_rate": 1.028888888888889e-05,
      "loss": 0.002,
      "step": 17870
    },
    {
      "epoch": 0.7946666666666666,
      "grad_norm": 0.5075442790985107,
      "learning_rate": 1.0266666666666668e-05,
      "loss": 0.0016,
      "step": 17880
    },
    {
      "epoch": 0.7951111111111111,
      "grad_norm": 0.3299326002597809,
      "learning_rate": 1.0244444444444445e-05,
      "loss": 0.0017,
      "step": 17890
    },
    {
      "epoch": 0.7955555555555556,
      "grad_norm": 0.344123899936676,
      "learning_rate": 1.0222222222222223e-05,
      "loss": 0.0019,
      "step": 17900
    },
    {
      "epoch": 0.796,
      "grad_norm": 0.20795053243637085,
      "learning_rate": 1.02e-05,
      "loss": 0.0019,
      "step": 17910
    },
    {
      "epoch": 0.7964444444444444,
      "grad_norm": 0.48098185658454895,
      "learning_rate": 1.0177777777777778e-05,
      "loss": 0.0022,
      "step": 17920
    },
    {
      "epoch": 0.7968888888888889,
      "grad_norm": 0.2610345780849457,
      "learning_rate": 1.0155555555555556e-05,
      "loss": 0.0019,
      "step": 17930
    },
    {
      "epoch": 0.7973333333333333,
      "grad_norm": 0.28846707940101624,
      "learning_rate": 1.0133333333333333e-05,
      "loss": 0.0019,
      "step": 17940
    },
    {
      "epoch": 0.7977777777777778,
      "grad_norm": 0.27460160851478577,
      "learning_rate": 1.0111111111111111e-05,
      "loss": 0.002,
      "step": 17950
    },
    {
      "epoch": 0.7982222222222223,
      "grad_norm": 0.036394450813531876,
      "learning_rate": 1.0088888888888889e-05,
      "loss": 0.0021,
      "step": 17960
    },
    {
      "epoch": 0.7986666666666666,
      "grad_norm": 0.08307424187660217,
      "learning_rate": 1.0066666666666668e-05,
      "loss": 0.0018,
      "step": 17970
    },
    {
      "epoch": 0.7991111111111111,
      "grad_norm": 0.11085604131221771,
      "learning_rate": 1.0044444444444446e-05,
      "loss": 0.0022,
      "step": 17980
    },
    {
      "epoch": 0.7995555555555556,
      "grad_norm": 0.09529373049736023,
      "learning_rate": 1.0022222222222223e-05,
      "loss": 0.0018,
      "step": 17990
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.13927464187145233,
      "learning_rate": 1e-05,
      "loss": 0.0019,
      "step": 18000
    },
    {
      "epoch": 0.8004444444444444,
      "grad_norm": 0.3851248621940613,
      "learning_rate": 9.977777777777778e-06,
      "loss": 0.0025,
      "step": 18010
    },
    {
      "epoch": 0.8008888888888889,
      "grad_norm": 0.020414752885699272,
      "learning_rate": 9.955555555555556e-06,
      "loss": 0.0018,
      "step": 18020
    },
    {
      "epoch": 0.8013333333333333,
      "grad_norm": 0.5064030885696411,
      "learning_rate": 9.933333333333334e-06,
      "loss": 0.0018,
      "step": 18030
    },
    {
      "epoch": 0.8017777777777778,
      "grad_norm": 0.1386815905570984,
      "learning_rate": 9.911111111111111e-06,
      "loss": 0.0019,
      "step": 18040
    },
    {
      "epoch": 0.8022222222222222,
      "grad_norm": 0.2889156639575958,
      "learning_rate": 9.888888888888889e-06,
      "loss": 0.0022,
      "step": 18050
    },
    {
      "epoch": 0.8026666666666666,
      "grad_norm": 0.30348044633865356,
      "learning_rate": 9.866666666666667e-06,
      "loss": 0.0015,
      "step": 18060
    },
    {
      "epoch": 0.8031111111111111,
      "grad_norm": 0.141514390707016,
      "learning_rate": 9.844444444444446e-06,
      "loss": 0.0022,
      "step": 18070
    },
    {
      "epoch": 0.8035555555555556,
      "grad_norm": 0.275237113237381,
      "learning_rate": 9.822222222222223e-06,
      "loss": 0.0022,
      "step": 18080
    },
    {
      "epoch": 0.804,
      "grad_norm": 0.4568540155887604,
      "learning_rate": 9.800000000000001e-06,
      "loss": 0.002,
      "step": 18090
    },
    {
      "epoch": 0.8044444444444444,
      "grad_norm": 0.7411183714866638,
      "learning_rate": 9.777777777777779e-06,
      "loss": 0.002,
      "step": 18100
    },
    {
      "epoch": 0.8048888888888889,
      "grad_norm": 0.26142698526382446,
      "learning_rate": 9.755555555555556e-06,
      "loss": 0.0019,
      "step": 18110
    },
    {
      "epoch": 0.8053333333333333,
      "grad_norm": 0.016880882903933525,
      "learning_rate": 9.733333333333334e-06,
      "loss": 0.002,
      "step": 18120
    },
    {
      "epoch": 0.8057777777777778,
      "grad_norm": 0.2608143091201782,
      "learning_rate": 9.711111111111111e-06,
      "loss": 0.0022,
      "step": 18130
    },
    {
      "epoch": 0.8062222222222222,
      "grad_norm": 0.24792443215847015,
      "learning_rate": 9.688888888888889e-06,
      "loss": 0.0023,
      "step": 18140
    },
    {
      "epoch": 0.8066666666666666,
      "grad_norm": 0.2061253786087036,
      "learning_rate": 9.666666666666667e-06,
      "loss": 0.002,
      "step": 18150
    },
    {
      "epoch": 0.8071111111111111,
      "grad_norm": 0.015149340033531189,
      "learning_rate": 9.644444444444444e-06,
      "loss": 0.0015,
      "step": 18160
    },
    {
      "epoch": 0.8075555555555556,
      "grad_norm": 0.09745205193758011,
      "learning_rate": 9.622222222222222e-06,
      "loss": 0.0017,
      "step": 18170
    },
    {
      "epoch": 0.808,
      "grad_norm": 0.49548283219337463,
      "learning_rate": 9.600000000000001e-06,
      "loss": 0.0016,
      "step": 18180
    },
    {
      "epoch": 0.8084444444444444,
      "grad_norm": 0.23437675833702087,
      "learning_rate": 9.577777777777779e-06,
      "loss": 0.0019,
      "step": 18190
    },
    {
      "epoch": 0.8088888888888889,
      "grad_norm": 0.6854152679443359,
      "learning_rate": 9.555555555555556e-06,
      "loss": 0.0021,
      "step": 18200
    },
    {
      "epoch": 0.8093333333333333,
      "grad_norm": 0.03118273988366127,
      "learning_rate": 9.533333333333334e-06,
      "loss": 0.0023,
      "step": 18210
    },
    {
      "epoch": 0.8097777777777778,
      "grad_norm": 0.04027993977069855,
      "learning_rate": 9.511111111111112e-06,
      "loss": 0.0018,
      "step": 18220
    },
    {
      "epoch": 0.8102222222222222,
      "grad_norm": 0.30295485258102417,
      "learning_rate": 9.48888888888889e-06,
      "loss": 0.0019,
      "step": 18230
    },
    {
      "epoch": 0.8106666666666666,
      "grad_norm": 0.37136510014533997,
      "learning_rate": 9.466666666666667e-06,
      "loss": 0.0021,
      "step": 18240
    },
    {
      "epoch": 0.8111111111111111,
      "grad_norm": 0.48085615038871765,
      "learning_rate": 9.444444444444445e-06,
      "loss": 0.0019,
      "step": 18250
    },
    {
      "epoch": 0.8115555555555556,
      "grad_norm": 0.1305532157421112,
      "learning_rate": 9.422222222222222e-06,
      "loss": 0.0018,
      "step": 18260
    },
    {
      "epoch": 0.812,
      "grad_norm": 0.05864586681127548,
      "learning_rate": 9.4e-06,
      "loss": 0.0018,
      "step": 18270
    },
    {
      "epoch": 0.8124444444444444,
      "grad_norm": 0.16520437598228455,
      "learning_rate": 9.377777777777779e-06,
      "loss": 0.0016,
      "step": 18280
    },
    {
      "epoch": 0.8128888888888889,
      "grad_norm": 0.17962947487831116,
      "learning_rate": 9.355555555555557e-06,
      "loss": 0.0016,
      "step": 18290
    },
    {
      "epoch": 0.8133333333333334,
      "grad_norm": 0.021719876676797867,
      "learning_rate": 9.333333333333334e-06,
      "loss": 0.0019,
      "step": 18300
    },
    {
      "epoch": 0.8137777777777778,
      "grad_norm": 0.5768252611160278,
      "learning_rate": 9.311111111111112e-06,
      "loss": 0.002,
      "step": 18310
    },
    {
      "epoch": 0.8142222222222222,
      "grad_norm": 0.16516390442848206,
      "learning_rate": 9.288888888888888e-06,
      "loss": 0.0016,
      "step": 18320
    },
    {
      "epoch": 0.8146666666666667,
      "grad_norm": 0.35655128955841064,
      "learning_rate": 9.266666666666667e-06,
      "loss": 0.002,
      "step": 18330
    },
    {
      "epoch": 0.8151111111111111,
      "grad_norm": 0.08619935810565948,
      "learning_rate": 9.244444444444445e-06,
      "loss": 0.0018,
      "step": 18340
    },
    {
      "epoch": 0.8155555555555556,
      "grad_norm": 0.27586373686790466,
      "learning_rate": 9.222222222222222e-06,
      "loss": 0.002,
      "step": 18350
    },
    {
      "epoch": 0.816,
      "grad_norm": 0.14311392605304718,
      "learning_rate": 9.2e-06,
      "loss": 0.0019,
      "step": 18360
    },
    {
      "epoch": 0.8164444444444444,
      "grad_norm": 0.2475842833518982,
      "learning_rate": 9.177777777777778e-06,
      "loss": 0.0018,
      "step": 18370
    },
    {
      "epoch": 0.8168888888888889,
      "grad_norm": 0.3294486403465271,
      "learning_rate": 9.155555555555557e-06,
      "loss": 0.0018,
      "step": 18380
    },
    {
      "epoch": 0.8173333333333334,
      "grad_norm": 0.20968365669250488,
      "learning_rate": 9.133333333333335e-06,
      "loss": 0.0018,
      "step": 18390
    },
    {
      "epoch": 0.8177777777777778,
      "grad_norm": 0.04489244893193245,
      "learning_rate": 9.111111111111112e-06,
      "loss": 0.0016,
      "step": 18400
    },
    {
      "epoch": 0.8182222222222222,
      "grad_norm": 0.0836179181933403,
      "learning_rate": 9.08888888888889e-06,
      "loss": 0.0016,
      "step": 18410
    },
    {
      "epoch": 0.8186666666666667,
      "grad_norm": 0.026100749149918556,
      "learning_rate": 9.066666666666667e-06,
      "loss": 0.0021,
      "step": 18420
    },
    {
      "epoch": 0.8191111111111111,
      "grad_norm": 0.4892115592956543,
      "learning_rate": 9.044444444444445e-06,
      "loss": 0.0017,
      "step": 18430
    },
    {
      "epoch": 0.8195555555555556,
      "grad_norm": 0.10071424394845963,
      "learning_rate": 9.022222222222223e-06,
      "loss": 0.0019,
      "step": 18440
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.28885164856910706,
      "learning_rate": 9e-06,
      "loss": 0.0017,
      "step": 18450
    },
    {
      "epoch": 0.8204444444444444,
      "grad_norm": 0.04702242091298103,
      "learning_rate": 8.977777777777778e-06,
      "loss": 0.002,
      "step": 18460
    },
    {
      "epoch": 0.8208888888888889,
      "grad_norm": 0.13862678408622742,
      "learning_rate": 8.955555555555555e-06,
      "loss": 0.002,
      "step": 18470
    },
    {
      "epoch": 0.8213333333333334,
      "grad_norm": 0.16618719696998596,
      "learning_rate": 8.933333333333333e-06,
      "loss": 0.002,
      "step": 18480
    },
    {
      "epoch": 0.8217777777777778,
      "grad_norm": 0.05830438435077667,
      "learning_rate": 8.911111111111112e-06,
      "loss": 0.0022,
      "step": 18490
    },
    {
      "epoch": 0.8222222222222222,
      "grad_norm": 0.2894189953804016,
      "learning_rate": 8.88888888888889e-06,
      "loss": 0.0019,
      "step": 18500
    },
    {
      "epoch": 0.8226666666666667,
      "grad_norm": 0.015877816826105118,
      "learning_rate": 8.866666666666668e-06,
      "loss": 0.002,
      "step": 18510
    },
    {
      "epoch": 0.8231111111111111,
      "grad_norm": 0.02002577669918537,
      "learning_rate": 8.844444444444445e-06,
      "loss": 0.0019,
      "step": 18520
    },
    {
      "epoch": 0.8235555555555556,
      "grad_norm": 0.17888586223125458,
      "learning_rate": 8.822222222222223e-06,
      "loss": 0.0019,
      "step": 18530
    },
    {
      "epoch": 0.824,
      "grad_norm": 0.042580634355545044,
      "learning_rate": 8.8e-06,
      "loss": 0.0017,
      "step": 18540
    },
    {
      "epoch": 0.8244444444444444,
      "grad_norm": 0.08817367255687714,
      "learning_rate": 8.777777777777778e-06,
      "loss": 0.0023,
      "step": 18550
    },
    {
      "epoch": 0.8248888888888889,
      "grad_norm": 0.19309687614440918,
      "learning_rate": 8.755555555555556e-06,
      "loss": 0.0021,
      "step": 18560
    },
    {
      "epoch": 0.8253333333333334,
      "grad_norm": 0.3022269010543823,
      "learning_rate": 8.733333333333333e-06,
      "loss": 0.0018,
      "step": 18570
    },
    {
      "epoch": 0.8257777777777778,
      "grad_norm": 0.04313834756612778,
      "learning_rate": 8.711111111111111e-06,
      "loss": 0.0021,
      "step": 18580
    },
    {
      "epoch": 0.8262222222222222,
      "grad_norm": 0.35742896795272827,
      "learning_rate": 8.68888888888889e-06,
      "loss": 0.0023,
      "step": 18590
    },
    {
      "epoch": 0.8266666666666667,
      "grad_norm": 0.019303008913993835,
      "learning_rate": 8.666666666666668e-06,
      "loss": 0.002,
      "step": 18600
    },
    {
      "epoch": 0.8271111111111111,
      "grad_norm": 0.13812872767448425,
      "learning_rate": 8.644444444444445e-06,
      "loss": 0.002,
      "step": 18610
    },
    {
      "epoch": 0.8275555555555556,
      "grad_norm": 0.31775814294815063,
      "learning_rate": 8.622222222222223e-06,
      "loss": 0.0016,
      "step": 18620
    },
    {
      "epoch": 0.828,
      "grad_norm": 0.11712072044610977,
      "learning_rate": 8.599999999999999e-06,
      "loss": 0.0016,
      "step": 18630
    },
    {
      "epoch": 0.8284444444444444,
      "grad_norm": 0.1657441258430481,
      "learning_rate": 8.577777777777778e-06,
      "loss": 0.0021,
      "step": 18640
    },
    {
      "epoch": 0.8288888888888889,
      "grad_norm": 0.056917838752269745,
      "learning_rate": 8.555555555555556e-06,
      "loss": 0.0027,
      "step": 18650
    },
    {
      "epoch": 0.8293333333333334,
      "grad_norm": 0.1659897118806839,
      "learning_rate": 8.533333333333334e-06,
      "loss": 0.0018,
      "step": 18660
    },
    {
      "epoch": 0.8297777777777777,
      "grad_norm": 0.1116330549120903,
      "learning_rate": 8.511111111111111e-06,
      "loss": 0.0021,
      "step": 18670
    },
    {
      "epoch": 0.8302222222222222,
      "grad_norm": 0.28842389583587646,
      "learning_rate": 8.488888888888889e-06,
      "loss": 0.0017,
      "step": 18680
    },
    {
      "epoch": 0.8306666666666667,
      "grad_norm": 0.02231750078499317,
      "learning_rate": 8.466666666666666e-06,
      "loss": 0.0018,
      "step": 18690
    },
    {
      "epoch": 0.8311111111111111,
      "grad_norm": 0.26225313544273376,
      "learning_rate": 8.444444444444446e-06,
      "loss": 0.0021,
      "step": 18700
    },
    {
      "epoch": 0.8315555555555556,
      "grad_norm": 0.03637605533003807,
      "learning_rate": 8.422222222222223e-06,
      "loss": 0.0023,
      "step": 18710
    },
    {
      "epoch": 0.832,
      "grad_norm": 0.3041762113571167,
      "learning_rate": 8.400000000000001e-06,
      "loss": 0.0022,
      "step": 18720
    },
    {
      "epoch": 0.8324444444444444,
      "grad_norm": 0.22213530540466309,
      "learning_rate": 8.377777777777779e-06,
      "loss": 0.0017,
      "step": 18730
    },
    {
      "epoch": 0.8328888888888889,
      "grad_norm": 0.125087708234787,
      "learning_rate": 8.355555555555556e-06,
      "loss": 0.0019,
      "step": 18740
    },
    {
      "epoch": 0.8333333333333334,
      "grad_norm": 0.0841858983039856,
      "learning_rate": 8.333333333333334e-06,
      "loss": 0.0015,
      "step": 18750
    },
    {
      "epoch": 0.8337777777777777,
      "grad_norm": 0.29289892315864563,
      "learning_rate": 8.311111111111111e-06,
      "loss": 0.002,
      "step": 18760
    },
    {
      "epoch": 0.8342222222222222,
      "grad_norm": 0.8154131770133972,
      "learning_rate": 8.288888888888889e-06,
      "loss": 0.002,
      "step": 18770
    },
    {
      "epoch": 0.8346666666666667,
      "grad_norm": 0.3161122500896454,
      "learning_rate": 8.266666666666667e-06,
      "loss": 0.0018,
      "step": 18780
    },
    {
      "epoch": 0.8351111111111111,
      "grad_norm": 0.48144954442977905,
      "learning_rate": 8.244444444444444e-06,
      "loss": 0.0021,
      "step": 18790
    },
    {
      "epoch": 0.8355555555555556,
      "grad_norm": 0.12582898139953613,
      "learning_rate": 8.222222222222223e-06,
      "loss": 0.0019,
      "step": 18800
    },
    {
      "epoch": 0.836,
      "grad_norm": 0.049060288816690445,
      "learning_rate": 8.200000000000001e-06,
      "loss": 0.0021,
      "step": 18810
    },
    {
      "epoch": 0.8364444444444444,
      "grad_norm": 0.1656113564968109,
      "learning_rate": 8.177777777777779e-06,
      "loss": 0.0019,
      "step": 18820
    },
    {
      "epoch": 0.8368888888888889,
      "grad_norm": 0.07424022257328033,
      "learning_rate": 8.155555555555556e-06,
      "loss": 0.0018,
      "step": 18830
    },
    {
      "epoch": 0.8373333333333334,
      "grad_norm": 0.1656465232372284,
      "learning_rate": 8.133333333333332e-06,
      "loss": 0.002,
      "step": 18840
    },
    {
      "epoch": 0.8377777777777777,
      "grad_norm": 0.0705353245139122,
      "learning_rate": 8.111111111111112e-06,
      "loss": 0.0022,
      "step": 18850
    },
    {
      "epoch": 0.8382222222222222,
      "grad_norm": 0.12490683048963547,
      "learning_rate": 8.08888888888889e-06,
      "loss": 0.0021,
      "step": 18860
    },
    {
      "epoch": 0.8386666666666667,
      "grad_norm": 0.43950390815734863,
      "learning_rate": 8.066666666666667e-06,
      "loss": 0.0021,
      "step": 18870
    },
    {
      "epoch": 0.8391111111111111,
      "grad_norm": 0.1935969889163971,
      "learning_rate": 8.044444444444444e-06,
      "loss": 0.0018,
      "step": 18880
    },
    {
      "epoch": 0.8395555555555556,
      "grad_norm": 0.07515403628349304,
      "learning_rate": 8.022222222222222e-06,
      "loss": 0.0016,
      "step": 18890
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.16706745326519012,
      "learning_rate": 8.000000000000001e-06,
      "loss": 0.0017,
      "step": 18900
    },
    {
      "epoch": 0.8404444444444444,
      "grad_norm": 0.05958940088748932,
      "learning_rate": 7.977777777777779e-06,
      "loss": 0.0019,
      "step": 18910
    },
    {
      "epoch": 0.8408888888888889,
      "grad_norm": 0.03354445844888687,
      "learning_rate": 7.955555555555557e-06,
      "loss": 0.0017,
      "step": 18920
    },
    {
      "epoch": 0.8413333333333334,
      "grad_norm": 0.04878467693924904,
      "learning_rate": 7.933333333333334e-06,
      "loss": 0.002,
      "step": 18930
    },
    {
      "epoch": 0.8417777777777777,
      "grad_norm": 0.22057795524597168,
      "learning_rate": 7.91111111111111e-06,
      "loss": 0.0021,
      "step": 18940
    },
    {
      "epoch": 0.8422222222222222,
      "grad_norm": 0.07256510108709335,
      "learning_rate": 7.88888888888889e-06,
      "loss": 0.0019,
      "step": 18950
    },
    {
      "epoch": 0.8426666666666667,
      "grad_norm": 0.4265090227127075,
      "learning_rate": 7.866666666666667e-06,
      "loss": 0.0018,
      "step": 18960
    },
    {
      "epoch": 0.8431111111111111,
      "grad_norm": 0.2345765084028244,
      "learning_rate": 7.844444444444445e-06,
      "loss": 0.0017,
      "step": 18970
    },
    {
      "epoch": 0.8435555555555555,
      "grad_norm": 0.0465884730219841,
      "learning_rate": 7.822222222222222e-06,
      "loss": 0.0018,
      "step": 18980
    },
    {
      "epoch": 0.844,
      "grad_norm": 0.43922513723373413,
      "learning_rate": 7.8e-06,
      "loss": 0.0022,
      "step": 18990
    },
    {
      "epoch": 0.8444444444444444,
      "grad_norm": 0.7558259963989258,
      "learning_rate": 7.777777777777777e-06,
      "loss": 0.0015,
      "step": 19000
    },
    {
      "epoch": 0.8448888888888889,
      "grad_norm": 0.22133255004882812,
      "learning_rate": 7.755555555555557e-06,
      "loss": 0.0017,
      "step": 19010
    },
    {
      "epoch": 0.8453333333333334,
      "grad_norm": 0.302613228559494,
      "learning_rate": 7.733333333333334e-06,
      "loss": 0.0017,
      "step": 19020
    },
    {
      "epoch": 0.8457777777777777,
      "grad_norm": 0.15117518603801727,
      "learning_rate": 7.711111111111112e-06,
      "loss": 0.0019,
      "step": 19030
    },
    {
      "epoch": 0.8462222222222222,
      "grad_norm": 0.3314938247203827,
      "learning_rate": 7.68888888888889e-06,
      "loss": 0.0018,
      "step": 19040
    },
    {
      "epoch": 0.8466666666666667,
      "grad_norm": 0.05043809115886688,
      "learning_rate": 7.666666666666667e-06,
      "loss": 0.002,
      "step": 19050
    },
    {
      "epoch": 0.8471111111111111,
      "grad_norm": 0.019619986414909363,
      "learning_rate": 7.644444444444445e-06,
      "loss": 0.0017,
      "step": 19060
    },
    {
      "epoch": 0.8475555555555555,
      "grad_norm": 0.6037858724594116,
      "learning_rate": 7.6222222222222225e-06,
      "loss": 0.002,
      "step": 19070
    },
    {
      "epoch": 0.848,
      "grad_norm": 0.3844280540943146,
      "learning_rate": 7.6e-06,
      "loss": 0.0019,
      "step": 19080
    },
    {
      "epoch": 0.8484444444444444,
      "grad_norm": 0.03331310674548149,
      "learning_rate": 7.577777777777778e-06,
      "loss": 0.002,
      "step": 19090
    },
    {
      "epoch": 0.8488888888888889,
      "grad_norm": 0.14160363376140594,
      "learning_rate": 7.555555555555556e-06,
      "loss": 0.0016,
      "step": 19100
    },
    {
      "epoch": 0.8493333333333334,
      "grad_norm": 0.17930808663368225,
      "learning_rate": 7.533333333333334e-06,
      "loss": 0.0023,
      "step": 19110
    },
    {
      "epoch": 0.8497777777777777,
      "grad_norm": 0.07136550545692444,
      "learning_rate": 7.511111111111112e-06,
      "loss": 0.0019,
      "step": 19120
    },
    {
      "epoch": 0.8502222222222222,
      "grad_norm": 0.28957587480545044,
      "learning_rate": 7.48888888888889e-06,
      "loss": 0.0017,
      "step": 19130
    },
    {
      "epoch": 0.8506666666666667,
      "grad_norm": 0.1384393721818924,
      "learning_rate": 7.4666666666666675e-06,
      "loss": 0.0015,
      "step": 19140
    },
    {
      "epoch": 0.8511111111111112,
      "grad_norm": 0.2881644070148468,
      "learning_rate": 7.444444444444444e-06,
      "loss": 0.0022,
      "step": 19150
    },
    {
      "epoch": 0.8515555555555555,
      "grad_norm": 0.39829981327056885,
      "learning_rate": 7.422222222222222e-06,
      "loss": 0.0019,
      "step": 19160
    },
    {
      "epoch": 0.852,
      "grad_norm": 0.1250622272491455,
      "learning_rate": 7.4e-06,
      "loss": 0.0017,
      "step": 19170
    },
    {
      "epoch": 0.8524444444444444,
      "grad_norm": 0.33049020171165466,
      "learning_rate": 7.377777777777778e-06,
      "loss": 0.0019,
      "step": 19180
    },
    {
      "epoch": 0.8528888888888889,
      "grad_norm": 0.19307230412960052,
      "learning_rate": 7.3555555555555555e-06,
      "loss": 0.0018,
      "step": 19190
    },
    {
      "epoch": 0.8533333333333334,
      "grad_norm": 0.02555842325091362,
      "learning_rate": 7.333333333333334e-06,
      "loss": 0.0018,
      "step": 19200
    },
    {
      "epoch": 0.8537777777777777,
      "grad_norm": 0.07498493045568466,
      "learning_rate": 7.311111111111112e-06,
      "loss": 0.0021,
      "step": 19210
    },
    {
      "epoch": 0.8542222222222222,
      "grad_norm": 0.13933078944683075,
      "learning_rate": 7.288888888888889e-06,
      "loss": 0.0019,
      "step": 19220
    },
    {
      "epoch": 0.8546666666666667,
      "grad_norm": 0.059150904417037964,
      "learning_rate": 7.266666666666668e-06,
      "loss": 0.0016,
      "step": 19230
    },
    {
      "epoch": 0.8551111111111112,
      "grad_norm": 0.13729213178157806,
      "learning_rate": 7.244444444444445e-06,
      "loss": 0.0021,
      "step": 19240
    },
    {
      "epoch": 0.8555555555555555,
      "grad_norm": 0.13880008459091187,
      "learning_rate": 7.222222222222222e-06,
      "loss": 0.002,
      "step": 19250
    },
    {
      "epoch": 0.856,
      "grad_norm": 0.11139197647571564,
      "learning_rate": 7.2e-06,
      "loss": 0.0018,
      "step": 19260
    },
    {
      "epoch": 0.8564444444444445,
      "grad_norm": 0.37141796946525574,
      "learning_rate": 7.177777777777778e-06,
      "loss": 0.0016,
      "step": 19270
    },
    {
      "epoch": 0.8568888888888889,
      "grad_norm": 0.0849485993385315,
      "learning_rate": 7.155555555555556e-06,
      "loss": 0.0018,
      "step": 19280
    },
    {
      "epoch": 0.8573333333333333,
      "grad_norm": 0.6122610569000244,
      "learning_rate": 7.133333333333333e-06,
      "loss": 0.0018,
      "step": 19290
    },
    {
      "epoch": 0.8577777777777778,
      "grad_norm": 0.08556430041790009,
      "learning_rate": 7.111111111111112e-06,
      "loss": 0.0017,
      "step": 19300
    },
    {
      "epoch": 0.8582222222222222,
      "grad_norm": 0.39830344915390015,
      "learning_rate": 7.0888888888888894e-06,
      "loss": 0.0022,
      "step": 19310
    },
    {
      "epoch": 0.8586666666666667,
      "grad_norm": 0.6322258710861206,
      "learning_rate": 7.066666666666667e-06,
      "loss": 0.0017,
      "step": 19320
    },
    {
      "epoch": 0.8591111111111112,
      "grad_norm": 0.5350697636604309,
      "learning_rate": 7.0444444444444455e-06,
      "loss": 0.0018,
      "step": 19330
    },
    {
      "epoch": 0.8595555555555555,
      "grad_norm": 0.3438621163368225,
      "learning_rate": 7.022222222222223e-06,
      "loss": 0.0017,
      "step": 19340
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.11110711842775345,
      "learning_rate": 7.000000000000001e-06,
      "loss": 0.0021,
      "step": 19350
    },
    {
      "epoch": 0.8604444444444445,
      "grad_norm": 0.2322261482477188,
      "learning_rate": 6.9777777777777775e-06,
      "loss": 0.0018,
      "step": 19360
    },
    {
      "epoch": 0.8608888888888889,
      "grad_norm": 0.35740339756011963,
      "learning_rate": 6.955555555555555e-06,
      "loss": 0.0018,
      "step": 19370
    },
    {
      "epoch": 0.8613333333333333,
      "grad_norm": 0.027722220867872238,
      "learning_rate": 6.933333333333334e-06,
      "loss": 0.002,
      "step": 19380
    },
    {
      "epoch": 0.8617777777777778,
      "grad_norm": 0.020466122776269913,
      "learning_rate": 6.911111111111111e-06,
      "loss": 0.0016,
      "step": 19390
    },
    {
      "epoch": 0.8622222222222222,
      "grad_norm": 0.021159043535590172,
      "learning_rate": 6.888888888888889e-06,
      "loss": 0.0016,
      "step": 19400
    },
    {
      "epoch": 0.8626666666666667,
      "grad_norm": 0.5769794583320618,
      "learning_rate": 6.866666666666667e-06,
      "loss": 0.0018,
      "step": 19410
    },
    {
      "epoch": 0.8631111111111112,
      "grad_norm": 0.11179929971694946,
      "learning_rate": 6.844444444444445e-06,
      "loss": 0.0016,
      "step": 19420
    },
    {
      "epoch": 0.8635555555555555,
      "grad_norm": 0.08848197758197784,
      "learning_rate": 6.8222222222222225e-06,
      "loss": 0.0018,
      "step": 19430
    },
    {
      "epoch": 0.864,
      "grad_norm": 0.19249063730239868,
      "learning_rate": 6.800000000000001e-06,
      "loss": 0.0016,
      "step": 19440
    },
    {
      "epoch": 0.8644444444444445,
      "grad_norm": 0.5500009655952454,
      "learning_rate": 6.777777777777779e-06,
      "loss": 0.0019,
      "step": 19450
    },
    {
      "epoch": 0.8648888888888889,
      "grad_norm": 0.028387926518917084,
      "learning_rate": 6.755555555555555e-06,
      "loss": 0.0019,
      "step": 19460
    },
    {
      "epoch": 0.8653333333333333,
      "grad_norm": 0.16574355959892273,
      "learning_rate": 6.733333333333333e-06,
      "loss": 0.0019,
      "step": 19470
    },
    {
      "epoch": 0.8657777777777778,
      "grad_norm": 0.4536542594432831,
      "learning_rate": 6.711111111111111e-06,
      "loss": 0.0022,
      "step": 19480
    },
    {
      "epoch": 0.8662222222222222,
      "grad_norm": 0.3298182487487793,
      "learning_rate": 6.688888888888889e-06,
      "loss": 0.0017,
      "step": 19490
    },
    {
      "epoch": 0.8666666666666667,
      "grad_norm": 0.1260267198085785,
      "learning_rate": 6.666666666666667e-06,
      "loss": 0.0017,
      "step": 19500
    },
    {
      "epoch": 0.8671111111111112,
      "grad_norm": 0.23396332561969757,
      "learning_rate": 6.644444444444445e-06,
      "loss": 0.0019,
      "step": 19510
    },
    {
      "epoch": 0.8675555555555555,
      "grad_norm": 0.20647475123405457,
      "learning_rate": 6.622222222222223e-06,
      "loss": 0.0019,
      "step": 19520
    },
    {
      "epoch": 0.868,
      "grad_norm": 0.11267311871051788,
      "learning_rate": 6.6e-06,
      "loss": 0.0022,
      "step": 19530
    },
    {
      "epoch": 0.8684444444444445,
      "grad_norm": 0.03253253549337387,
      "learning_rate": 6.577777777777779e-06,
      "loss": 0.0016,
      "step": 19540
    },
    {
      "epoch": 0.8688888888888889,
      "grad_norm": 0.2339826375246048,
      "learning_rate": 6.555555555555556e-06,
      "loss": 0.002,
      "step": 19550
    },
    {
      "epoch": 0.8693333333333333,
      "grad_norm": 0.290022075176239,
      "learning_rate": 6.533333333333333e-06,
      "loss": 0.0018,
      "step": 19560
    },
    {
      "epoch": 0.8697777777777778,
      "grad_norm": 0.11748693138360977,
      "learning_rate": 6.511111111111111e-06,
      "loss": 0.0016,
      "step": 19570
    },
    {
      "epoch": 0.8702222222222222,
      "grad_norm": 0.1402186006307602,
      "learning_rate": 6.488888888888888e-06,
      "loss": 0.0024,
      "step": 19580
    },
    {
      "epoch": 0.8706666666666667,
      "grad_norm": 0.3716486096382141,
      "learning_rate": 6.466666666666667e-06,
      "loss": 0.0017,
      "step": 19590
    },
    {
      "epoch": 0.8711111111111111,
      "grad_norm": 0.14302107691764832,
      "learning_rate": 6.4444444444444445e-06,
      "loss": 0.002,
      "step": 19600
    },
    {
      "epoch": 0.8715555555555555,
      "grad_norm": 0.45388659834861755,
      "learning_rate": 6.422222222222223e-06,
      "loss": 0.0017,
      "step": 19610
    },
    {
      "epoch": 0.872,
      "grad_norm": 0.2904001474380493,
      "learning_rate": 6.4000000000000006e-06,
      "loss": 0.0021,
      "step": 19620
    },
    {
      "epoch": 0.8724444444444445,
      "grad_norm": 0.1291772574186325,
      "learning_rate": 6.377777777777778e-06,
      "loss": 0.0019,
      "step": 19630
    },
    {
      "epoch": 0.8728888888888889,
      "grad_norm": 0.08549554646015167,
      "learning_rate": 6.355555555555557e-06,
      "loss": 0.0019,
      "step": 19640
    },
    {
      "epoch": 0.8733333333333333,
      "grad_norm": 0.2472105622291565,
      "learning_rate": 6.333333333333334e-06,
      "loss": 0.0018,
      "step": 19650
    },
    {
      "epoch": 0.8737777777777778,
      "grad_norm": 0.4534110724925995,
      "learning_rate": 6.311111111111112e-06,
      "loss": 0.0017,
      "step": 19660
    },
    {
      "epoch": 0.8742222222222222,
      "grad_norm": 0.07174395024776459,
      "learning_rate": 6.288888888888889e-06,
      "loss": 0.0018,
      "step": 19670
    },
    {
      "epoch": 0.8746666666666667,
      "grad_norm": 0.03294619172811508,
      "learning_rate": 6.266666666666666e-06,
      "loss": 0.0017,
      "step": 19680
    },
    {
      "epoch": 0.8751111111111111,
      "grad_norm": 0.315746009349823,
      "learning_rate": 6.244444444444445e-06,
      "loss": 0.0017,
      "step": 19690
    },
    {
      "epoch": 0.8755555555555555,
      "grad_norm": 0.07050689309835434,
      "learning_rate": 6.222222222222222e-06,
      "loss": 0.0019,
      "step": 19700
    },
    {
      "epoch": 0.876,
      "grad_norm": 0.02364083006978035,
      "learning_rate": 6.2e-06,
      "loss": 0.002,
      "step": 19710
    },
    {
      "epoch": 0.8764444444444445,
      "grad_norm": 0.24992439150810242,
      "learning_rate": 6.177777777777778e-06,
      "loss": 0.0019,
      "step": 19720
    },
    {
      "epoch": 0.8768888888888889,
      "grad_norm": 0.315978080034256,
      "learning_rate": 6.155555555555556e-06,
      "loss": 0.0017,
      "step": 19730
    },
    {
      "epoch": 0.8773333333333333,
      "grad_norm": 0.4537663459777832,
      "learning_rate": 6.133333333333334e-06,
      "loss": 0.0018,
      "step": 19740
    },
    {
      "epoch": 0.8777777777777778,
      "grad_norm": 0.08845396339893341,
      "learning_rate": 6.111111111111111e-06,
      "loss": 0.0016,
      "step": 19750
    },
    {
      "epoch": 0.8782222222222222,
      "grad_norm": 0.19352604448795319,
      "learning_rate": 6.088888888888889e-06,
      "loss": 0.002,
      "step": 19760
    },
    {
      "epoch": 0.8786666666666667,
      "grad_norm": 0.1662481129169464,
      "learning_rate": 6.066666666666667e-06,
      "loss": 0.0017,
      "step": 19770
    },
    {
      "epoch": 0.8791111111111111,
      "grad_norm": 0.3297233283519745,
      "learning_rate": 6.044444444444445e-06,
      "loss": 0.0016,
      "step": 19780
    },
    {
      "epoch": 0.8795555555555555,
      "grad_norm": 0.2344648540019989,
      "learning_rate": 6.0222222222222225e-06,
      "loss": 0.0016,
      "step": 19790
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.1664114147424698,
      "learning_rate": 6e-06,
      "loss": 0.0018,
      "step": 19800
    },
    {
      "epoch": 0.8804444444444445,
      "grad_norm": 0.049527380615472794,
      "learning_rate": 5.977777777777778e-06,
      "loss": 0.0021,
      "step": 19810
    },
    {
      "epoch": 0.8808888888888889,
      "grad_norm": 0.05922465771436691,
      "learning_rate": 5.955555555555556e-06,
      "loss": 0.0017,
      "step": 19820
    },
    {
      "epoch": 0.8813333333333333,
      "grad_norm": 0.08564403653144836,
      "learning_rate": 5.933333333333334e-06,
      "loss": 0.0019,
      "step": 19830
    },
    {
      "epoch": 0.8817777777777778,
      "grad_norm": 0.261794775724411,
      "learning_rate": 5.9111111111111115e-06,
      "loss": 0.0019,
      "step": 19840
    },
    {
      "epoch": 0.8822222222222222,
      "grad_norm": 0.07804102450609207,
      "learning_rate": 5.888888888888889e-06,
      "loss": 0.0017,
      "step": 19850
    },
    {
      "epoch": 0.8826666666666667,
      "grad_norm": 0.16541141271591187,
      "learning_rate": 5.866666666666667e-06,
      "loss": 0.0019,
      "step": 19860
    },
    {
      "epoch": 0.8831111111111111,
      "grad_norm": 0.04209566116333008,
      "learning_rate": 5.844444444444445e-06,
      "loss": 0.0022,
      "step": 19870
    },
    {
      "epoch": 0.8835555555555555,
      "grad_norm": 0.08622730523347855,
      "learning_rate": 5.822222222222223e-06,
      "loss": 0.0024,
      "step": 19880
    },
    {
      "epoch": 0.884,
      "grad_norm": 0.13819482922554016,
      "learning_rate": 5.8e-06,
      "loss": 0.0019,
      "step": 19890
    },
    {
      "epoch": 0.8844444444444445,
      "grad_norm": 0.09932105243206024,
      "learning_rate": 5.777777777777778e-06,
      "loss": 0.0022,
      "step": 19900
    },
    {
      "epoch": 0.8848888888888888,
      "grad_norm": 0.6051117777824402,
      "learning_rate": 5.755555555555556e-06,
      "loss": 0.0019,
      "step": 19910
    },
    {
      "epoch": 0.8853333333333333,
      "grad_norm": 0.12645789980888367,
      "learning_rate": 5.733333333333333e-06,
      "loss": 0.0021,
      "step": 19920
    },
    {
      "epoch": 0.8857777777777778,
      "grad_norm": 0.19334037601947784,
      "learning_rate": 5.711111111111112e-06,
      "loss": 0.0022,
      "step": 19930
    },
    {
      "epoch": 0.8862222222222222,
      "grad_norm": 0.01779685914516449,
      "learning_rate": 5.688888888888889e-06,
      "loss": 0.0015,
      "step": 19940
    },
    {
      "epoch": 0.8866666666666667,
      "grad_norm": 0.044062595814466476,
      "learning_rate": 5.666666666666667e-06,
      "loss": 0.0019,
      "step": 19950
    },
    {
      "epoch": 0.8871111111111111,
      "grad_norm": 0.2754448652267456,
      "learning_rate": 5.6444444444444445e-06,
      "loss": 0.002,
      "step": 19960
    },
    {
      "epoch": 0.8875555555555555,
      "grad_norm": 0.3854837119579315,
      "learning_rate": 5.622222222222222e-06,
      "loss": 0.0019,
      "step": 19970
    },
    {
      "epoch": 0.888,
      "grad_norm": 0.2473628669977188,
      "learning_rate": 5.600000000000001e-06,
      "loss": 0.0018,
      "step": 19980
    },
    {
      "epoch": 0.8884444444444445,
      "grad_norm": 0.020776664838194847,
      "learning_rate": 5.577777777777778e-06,
      "loss": 0.0018,
      "step": 19990
    },
    {
      "epoch": 0.8888888888888888,
      "grad_norm": 0.19370968639850616,
      "learning_rate": 5.555555555555556e-06,
      "loss": 0.0021,
      "step": 20000
    },
    {
      "epoch": 0.8893333333333333,
      "grad_norm": 0.11289028078317642,
      "learning_rate": 5.5333333333333334e-06,
      "loss": 0.002,
      "step": 20010
    },
    {
      "epoch": 0.8897777777777778,
      "grad_norm": 0.20696593821048737,
      "learning_rate": 5.511111111111111e-06,
      "loss": 0.0016,
      "step": 20020
    },
    {
      "epoch": 0.8902222222222222,
      "grad_norm": 0.24448657035827637,
      "learning_rate": 5.4888888888888895e-06,
      "loss": 0.0022,
      "step": 20030
    },
    {
      "epoch": 0.8906666666666667,
      "grad_norm": 0.27711623907089233,
      "learning_rate": 5.466666666666667e-06,
      "loss": 0.0023,
      "step": 20040
    },
    {
      "epoch": 0.8911111111111111,
      "grad_norm": 0.2745800018310547,
      "learning_rate": 5.444444444444445e-06,
      "loss": 0.0019,
      "step": 20050
    },
    {
      "epoch": 0.8915555555555555,
      "grad_norm": 0.05789494141936302,
      "learning_rate": 5.422222222222222e-06,
      "loss": 0.0018,
      "step": 20060
    },
    {
      "epoch": 0.892,
      "grad_norm": 0.1795923113822937,
      "learning_rate": 5.4e-06,
      "loss": 0.0016,
      "step": 20070
    },
    {
      "epoch": 0.8924444444444445,
      "grad_norm": 0.03217235580086708,
      "learning_rate": 5.3777777777777784e-06,
      "loss": 0.0017,
      "step": 20080
    },
    {
      "epoch": 0.8928888888888888,
      "grad_norm": 0.13857735693454742,
      "learning_rate": 5.355555555555556e-06,
      "loss": 0.0025,
      "step": 20090
    },
    {
      "epoch": 0.8933333333333333,
      "grad_norm": 0.20679278671741486,
      "learning_rate": 5.333333333333334e-06,
      "loss": 0.0021,
      "step": 20100
    },
    {
      "epoch": 0.8937777777777778,
      "grad_norm": 0.20715805888175964,
      "learning_rate": 5.311111111111111e-06,
      "loss": 0.0017,
      "step": 20110
    },
    {
      "epoch": 0.8942222222222223,
      "grad_norm": 0.6575769186019897,
      "learning_rate": 5.288888888888889e-06,
      "loss": 0.0023,
      "step": 20120
    },
    {
      "epoch": 0.8946666666666667,
      "grad_norm": 0.13775835931301117,
      "learning_rate": 5.266666666666667e-06,
      "loss": 0.0021,
      "step": 20130
    },
    {
      "epoch": 0.8951111111111111,
      "grad_norm": 0.165646031498909,
      "learning_rate": 5.244444444444445e-06,
      "loss": 0.0018,
      "step": 20140
    },
    {
      "epoch": 0.8955555555555555,
      "grad_norm": 0.13980138301849365,
      "learning_rate": 5.2222222222222226e-06,
      "loss": 0.0022,
      "step": 20150
    },
    {
      "epoch": 0.896,
      "grad_norm": 0.11366434395313263,
      "learning_rate": 5.2e-06,
      "loss": 0.002,
      "step": 20160
    },
    {
      "epoch": 0.8964444444444445,
      "grad_norm": 0.17937694489955902,
      "learning_rate": 5.177777777777778e-06,
      "loss": 0.0024,
      "step": 20170
    },
    {
      "epoch": 0.8968888888888888,
      "grad_norm": 0.32395827770233154,
      "learning_rate": 5.155555555555555e-06,
      "loss": 0.0018,
      "step": 20180
    },
    {
      "epoch": 0.8973333333333333,
      "grad_norm": 0.07486221939325333,
      "learning_rate": 5.133333333333334e-06,
      "loss": 0.002,
      "step": 20190
    },
    {
      "epoch": 0.8977777777777778,
      "grad_norm": 0.15286606550216675,
      "learning_rate": 5.1111111111111115e-06,
      "loss": 0.0016,
      "step": 20200
    },
    {
      "epoch": 0.8982222222222223,
      "grad_norm": 0.3568163216114044,
      "learning_rate": 5.088888888888889e-06,
      "loss": 0.002,
      "step": 20210
    },
    {
      "epoch": 0.8986666666666666,
      "grad_norm": 0.3135693073272705,
      "learning_rate": 5.066666666666667e-06,
      "loss": 0.0016,
      "step": 20220
    },
    {
      "epoch": 0.8991111111111111,
      "grad_norm": 0.3576872944831848,
      "learning_rate": 5.044444444444444e-06,
      "loss": 0.002,
      "step": 20230
    },
    {
      "epoch": 0.8995555555555556,
      "grad_norm": 0.2530425488948822,
      "learning_rate": 5.022222222222223e-06,
      "loss": 0.0018,
      "step": 20240
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.33066239953041077,
      "learning_rate": 5e-06,
      "loss": 0.0018,
      "step": 20250
    },
    {
      "epoch": 0.9004444444444445,
      "grad_norm": 0.16713234782218933,
      "learning_rate": 4.977777777777778e-06,
      "loss": 0.0021,
      "step": 20260
    },
    {
      "epoch": 0.9008888888888889,
      "grad_norm": 0.03541823849081993,
      "learning_rate": 4.955555555555556e-06,
      "loss": 0.0017,
      "step": 20270
    },
    {
      "epoch": 0.9013333333333333,
      "grad_norm": 0.28991642594337463,
      "learning_rate": 4.933333333333333e-06,
      "loss": 0.0018,
      "step": 20280
    },
    {
      "epoch": 0.9017777777777778,
      "grad_norm": 0.17989382147789001,
      "learning_rate": 4.911111111111112e-06,
      "loss": 0.0019,
      "step": 20290
    },
    {
      "epoch": 0.9022222222222223,
      "grad_norm": 0.22681960463523865,
      "learning_rate": 4.888888888888889e-06,
      "loss": 0.0022,
      "step": 20300
    },
    {
      "epoch": 0.9026666666666666,
      "grad_norm": 0.31680113077163696,
      "learning_rate": 4.866666666666667e-06,
      "loss": 0.0021,
      "step": 20310
    },
    {
      "epoch": 0.9031111111111111,
      "grad_norm": 0.1255342811346054,
      "learning_rate": 4.8444444444444446e-06,
      "loss": 0.0021,
      "step": 20320
    },
    {
      "epoch": 0.9035555555555556,
      "grad_norm": 0.36227327585220337,
      "learning_rate": 4.822222222222222e-06,
      "loss": 0.0018,
      "step": 20330
    },
    {
      "epoch": 0.904,
      "grad_norm": 0.28878331184387207,
      "learning_rate": 4.800000000000001e-06,
      "loss": 0.0017,
      "step": 20340
    },
    {
      "epoch": 0.9044444444444445,
      "grad_norm": 0.0525163933634758,
      "learning_rate": 4.777777777777778e-06,
      "loss": 0.0017,
      "step": 20350
    },
    {
      "epoch": 0.9048888888888889,
      "grad_norm": 0.7133661508560181,
      "learning_rate": 4.755555555555556e-06,
      "loss": 0.0018,
      "step": 20360
    },
    {
      "epoch": 0.9053333333333333,
      "grad_norm": 0.20679132640361786,
      "learning_rate": 4.7333333333333335e-06,
      "loss": 0.0022,
      "step": 20370
    },
    {
      "epoch": 0.9057777777777778,
      "grad_norm": 0.07735998928546906,
      "learning_rate": 4.711111111111111e-06,
      "loss": 0.0015,
      "step": 20380
    },
    {
      "epoch": 0.9062222222222223,
      "grad_norm": 0.026541398838162422,
      "learning_rate": 4.6888888888888895e-06,
      "loss": 0.0019,
      "step": 20390
    },
    {
      "epoch": 0.9066666666666666,
      "grad_norm": 0.2646341919898987,
      "learning_rate": 4.666666666666667e-06,
      "loss": 0.0017,
      "step": 20400
    },
    {
      "epoch": 0.9071111111111111,
      "grad_norm": 0.061301663517951965,
      "learning_rate": 4.644444444444444e-06,
      "loss": 0.0017,
      "step": 20410
    },
    {
      "epoch": 0.9075555555555556,
      "grad_norm": 0.16553863883018494,
      "learning_rate": 4.622222222222222e-06,
      "loss": 0.0018,
      "step": 20420
    },
    {
      "epoch": 0.908,
      "grad_norm": 0.16588035225868225,
      "learning_rate": 4.6e-06,
      "loss": 0.0022,
      "step": 20430
    },
    {
      "epoch": 0.9084444444444445,
      "grad_norm": 0.025021551176905632,
      "learning_rate": 4.5777777777777785e-06,
      "loss": 0.002,
      "step": 20440
    },
    {
      "epoch": 0.9088888888888889,
      "grad_norm": 0.11354527622461319,
      "learning_rate": 4.555555555555556e-06,
      "loss": 0.0019,
      "step": 20450
    },
    {
      "epoch": 0.9093333333333333,
      "grad_norm": 0.08384494483470917,
      "learning_rate": 4.533333333333334e-06,
      "loss": 0.0019,
      "step": 20460
    },
    {
      "epoch": 0.9097777777777778,
      "grad_norm": 0.35781329870224,
      "learning_rate": 4.511111111111111e-06,
      "loss": 0.0019,
      "step": 20470
    },
    {
      "epoch": 0.9102222222222223,
      "grad_norm": 0.17952434718608856,
      "learning_rate": 4.488888888888889e-06,
      "loss": 0.0016,
      "step": 20480
    },
    {
      "epoch": 0.9106666666666666,
      "grad_norm": 0.1149907112121582,
      "learning_rate": 4.4666666666666665e-06,
      "loss": 0.0017,
      "step": 20490
    },
    {
      "epoch": 0.9111111111111111,
      "grad_norm": 0.27535831928253174,
      "learning_rate": 4.444444444444445e-06,
      "loss": 0.0018,
      "step": 20500
    },
    {
      "epoch": 0.9115555555555556,
      "grad_norm": 0.3991925120353699,
      "learning_rate": 4.422222222222223e-06,
      "loss": 0.0021,
      "step": 20510
    },
    {
      "epoch": 0.912,
      "grad_norm": 0.24910305440425873,
      "learning_rate": 4.4e-06,
      "loss": 0.0019,
      "step": 20520
    },
    {
      "epoch": 0.9124444444444444,
      "grad_norm": 0.3307506740093231,
      "learning_rate": 4.377777777777778e-06,
      "loss": 0.0016,
      "step": 20530
    },
    {
      "epoch": 0.9128888888888889,
      "grad_norm": 0.0680224671959877,
      "learning_rate": 4.3555555555555555e-06,
      "loss": 0.0016,
      "step": 20540
    },
    {
      "epoch": 0.9133333333333333,
      "grad_norm": 0.24894380569458008,
      "learning_rate": 4.333333333333334e-06,
      "loss": 0.0024,
      "step": 20550
    },
    {
      "epoch": 0.9137777777777778,
      "grad_norm": 0.16663508117198944,
      "learning_rate": 4.3111111111111115e-06,
      "loss": 0.0018,
      "step": 20560
    },
    {
      "epoch": 0.9142222222222223,
      "grad_norm": 0.018535476177930832,
      "learning_rate": 4.288888888888889e-06,
      "loss": 0.0017,
      "step": 20570
    },
    {
      "epoch": 0.9146666666666666,
      "grad_norm": 0.12169383466243744,
      "learning_rate": 4.266666666666667e-06,
      "loss": 0.0018,
      "step": 20580
    },
    {
      "epoch": 0.9151111111111111,
      "grad_norm": 0.04473323002457619,
      "learning_rate": 4.244444444444444e-06,
      "loss": 0.0015,
      "step": 20590
    },
    {
      "epoch": 0.9155555555555556,
      "grad_norm": 0.05825648829340935,
      "learning_rate": 4.222222222222223e-06,
      "loss": 0.0021,
      "step": 20600
    },
    {
      "epoch": 0.916,
      "grad_norm": 0.41301047801971436,
      "learning_rate": 4.2000000000000004e-06,
      "loss": 0.0019,
      "step": 20610
    },
    {
      "epoch": 0.9164444444444444,
      "grad_norm": 0.08799219131469727,
      "learning_rate": 4.177777777777778e-06,
      "loss": 0.0021,
      "step": 20620
    },
    {
      "epoch": 0.9168888888888889,
      "grad_norm": 0.08616670966148376,
      "learning_rate": 4.155555555555556e-06,
      "loss": 0.0016,
      "step": 20630
    },
    {
      "epoch": 0.9173333333333333,
      "grad_norm": 0.29634109139442444,
      "learning_rate": 4.133333333333333e-06,
      "loss": 0.0017,
      "step": 20640
    },
    {
      "epoch": 0.9177777777777778,
      "grad_norm": 0.20628651976585388,
      "learning_rate": 4.111111111111112e-06,
      "loss": 0.002,
      "step": 20650
    },
    {
      "epoch": 0.9182222222222223,
      "grad_norm": 0.1681828498840332,
      "learning_rate": 4.088888888888889e-06,
      "loss": 0.0018,
      "step": 20660
    },
    {
      "epoch": 0.9186666666666666,
      "grad_norm": 0.20809727907180786,
      "learning_rate": 4.066666666666666e-06,
      "loss": 0.0018,
      "step": 20670
    },
    {
      "epoch": 0.9191111111111111,
      "grad_norm": 0.5502994656562805,
      "learning_rate": 4.044444444444445e-06,
      "loss": 0.0016,
      "step": 20680
    },
    {
      "epoch": 0.9195555555555556,
      "grad_norm": 0.07219897955656052,
      "learning_rate": 4.022222222222222e-06,
      "loss": 0.0019,
      "step": 20690
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.6181192994117737,
      "learning_rate": 4.000000000000001e-06,
      "loss": 0.0018,
      "step": 20700
    },
    {
      "epoch": 0.9204444444444444,
      "grad_norm": 0.20792974531650543,
      "learning_rate": 3.977777777777778e-06,
      "loss": 0.0018,
      "step": 20710
    },
    {
      "epoch": 0.9208888888888889,
      "grad_norm": 0.2060745507478714,
      "learning_rate": 3.955555555555555e-06,
      "loss": 0.0016,
      "step": 20720
    },
    {
      "epoch": 0.9213333333333333,
      "grad_norm": 0.03385554254055023,
      "learning_rate": 3.9333333333333335e-06,
      "loss": 0.0018,
      "step": 20730
    },
    {
      "epoch": 0.9217777777777778,
      "grad_norm": 0.05334793031215668,
      "learning_rate": 3.911111111111111e-06,
      "loss": 0.0018,
      "step": 20740
    },
    {
      "epoch": 0.9222222222222223,
      "grad_norm": 0.05788498744368553,
      "learning_rate": 3.888888888888889e-06,
      "loss": 0.0016,
      "step": 20750
    },
    {
      "epoch": 0.9226666666666666,
      "grad_norm": 0.11238161474466324,
      "learning_rate": 3.866666666666667e-06,
      "loss": 0.0017,
      "step": 20760
    },
    {
      "epoch": 0.9231111111111111,
      "grad_norm": 0.28085917234420776,
      "learning_rate": 3.844444444444445e-06,
      "loss": 0.0017,
      "step": 20770
    },
    {
      "epoch": 0.9235555555555556,
      "grad_norm": 0.05169825628399849,
      "learning_rate": 3.8222222222222224e-06,
      "loss": 0.002,
      "step": 20780
    },
    {
      "epoch": 0.924,
      "grad_norm": 0.09063229709863663,
      "learning_rate": 3.8e-06,
      "loss": 0.0017,
      "step": 20790
    },
    {
      "epoch": 0.9244444444444444,
      "grad_norm": 0.6867849826812744,
      "learning_rate": 3.777777777777778e-06,
      "loss": 0.0019,
      "step": 20800
    },
    {
      "epoch": 0.9248888888888889,
      "grad_norm": 0.6050440073013306,
      "learning_rate": 3.755555555555556e-06,
      "loss": 0.0019,
      "step": 20810
    },
    {
      "epoch": 0.9253333333333333,
      "grad_norm": 0.1414925903081894,
      "learning_rate": 3.7333333333333337e-06,
      "loss": 0.0017,
      "step": 20820
    },
    {
      "epoch": 0.9257777777777778,
      "grad_norm": 0.04795355722308159,
      "learning_rate": 3.711111111111111e-06,
      "loss": 0.0021,
      "step": 20830
    },
    {
      "epoch": 0.9262222222222222,
      "grad_norm": 0.11126571893692017,
      "learning_rate": 3.688888888888889e-06,
      "loss": 0.002,
      "step": 20840
    },
    {
      "epoch": 0.9266666666666666,
      "grad_norm": 0.3026685416698456,
      "learning_rate": 3.666666666666667e-06,
      "loss": 0.002,
      "step": 20850
    },
    {
      "epoch": 0.9271111111111111,
      "grad_norm": 0.14105427265167236,
      "learning_rate": 3.6444444444444446e-06,
      "loss": 0.0017,
      "step": 20860
    },
    {
      "epoch": 0.9275555555555556,
      "grad_norm": 0.13958682119846344,
      "learning_rate": 3.6222222222222226e-06,
      "loss": 0.0017,
      "step": 20870
    },
    {
      "epoch": 0.928,
      "grad_norm": 0.27882519364356995,
      "learning_rate": 3.6e-06,
      "loss": 0.0018,
      "step": 20880
    },
    {
      "epoch": 0.9284444444444444,
      "grad_norm": 0.2891086935997009,
      "learning_rate": 3.577777777777778e-06,
      "loss": 0.0017,
      "step": 20890
    },
    {
      "epoch": 0.9288888888888889,
      "grad_norm": 0.23751381039619446,
      "learning_rate": 3.555555555555556e-06,
      "loss": 0.0017,
      "step": 20900
    },
    {
      "epoch": 0.9293333333333333,
      "grad_norm": 0.06890968233346939,
      "learning_rate": 3.5333333333333335e-06,
      "loss": 0.0018,
      "step": 20910
    },
    {
      "epoch": 0.9297777777777778,
      "grad_norm": 0.255874902009964,
      "learning_rate": 3.5111111111111116e-06,
      "loss": 0.0021,
      "step": 20920
    },
    {
      "epoch": 0.9302222222222222,
      "grad_norm": 0.45284804701805115,
      "learning_rate": 3.4888888888888888e-06,
      "loss": 0.0021,
      "step": 20930
    },
    {
      "epoch": 0.9306666666666666,
      "grad_norm": 0.08628197014331818,
      "learning_rate": 3.466666666666667e-06,
      "loss": 0.0019,
      "step": 20940
    },
    {
      "epoch": 0.9311111111111111,
      "grad_norm": 0.43626827001571655,
      "learning_rate": 3.4444444444444444e-06,
      "loss": 0.002,
      "step": 20950
    },
    {
      "epoch": 0.9315555555555556,
      "grad_norm": 0.1538829803466797,
      "learning_rate": 3.4222222222222224e-06,
      "loss": 0.0019,
      "step": 20960
    },
    {
      "epoch": 0.932,
      "grad_norm": 0.10511337220668793,
      "learning_rate": 3.4000000000000005e-06,
      "loss": 0.0017,
      "step": 20970
    },
    {
      "epoch": 0.9324444444444444,
      "grad_norm": 0.026311447843909264,
      "learning_rate": 3.3777777777777777e-06,
      "loss": 0.0022,
      "step": 20980
    },
    {
      "epoch": 0.9328888888888889,
      "grad_norm": 0.29431378841400146,
      "learning_rate": 3.3555555555555557e-06,
      "loss": 0.0016,
      "step": 20990
    },
    {
      "epoch": 0.9333333333333333,
      "grad_norm": 0.5337648987770081,
      "learning_rate": 3.3333333333333333e-06,
      "loss": 0.0018,
      "step": 21000
    },
    {
      "epoch": 0.9337777777777778,
      "grad_norm": 0.11473952233791351,
      "learning_rate": 3.3111111111111114e-06,
      "loss": 0.0019,
      "step": 21010
    },
    {
      "epoch": 0.9342222222222222,
      "grad_norm": 0.45459091663360596,
      "learning_rate": 3.2888888888888894e-06,
      "loss": 0.0019,
      "step": 21020
    },
    {
      "epoch": 0.9346666666666666,
      "grad_norm": 0.04464557394385338,
      "learning_rate": 3.2666666666666666e-06,
      "loss": 0.0019,
      "step": 21030
    },
    {
      "epoch": 0.9351111111111111,
      "grad_norm": 0.2897311747074127,
      "learning_rate": 3.244444444444444e-06,
      "loss": 0.0023,
      "step": 21040
    },
    {
      "epoch": 0.9355555555555556,
      "grad_norm": 0.23502537608146667,
      "learning_rate": 3.2222222222222222e-06,
      "loss": 0.0017,
      "step": 21050
    },
    {
      "epoch": 0.936,
      "grad_norm": 0.3848675489425659,
      "learning_rate": 3.2000000000000003e-06,
      "loss": 0.0017,
      "step": 21060
    },
    {
      "epoch": 0.9364444444444444,
      "grad_norm": 0.16587573289871216,
      "learning_rate": 3.1777777777777783e-06,
      "loss": 0.0017,
      "step": 21070
    },
    {
      "epoch": 0.9368888888888889,
      "grad_norm": 0.22154955565929413,
      "learning_rate": 3.155555555555556e-06,
      "loss": 0.0017,
      "step": 21080
    },
    {
      "epoch": 0.9373333333333334,
      "grad_norm": 0.24724502861499786,
      "learning_rate": 3.133333333333333e-06,
      "loss": 0.0021,
      "step": 21090
    },
    {
      "epoch": 0.9377777777777778,
      "grad_norm": 0.059933505952358246,
      "learning_rate": 3.111111111111111e-06,
      "loss": 0.002,
      "step": 21100
    },
    {
      "epoch": 0.9382222222222222,
      "grad_norm": 0.12521906197071075,
      "learning_rate": 3.088888888888889e-06,
      "loss": 0.0026,
      "step": 21110
    },
    {
      "epoch": 0.9386666666666666,
      "grad_norm": 0.19798150658607483,
      "learning_rate": 3.066666666666667e-06,
      "loss": 0.0018,
      "step": 21120
    },
    {
      "epoch": 0.9391111111111111,
      "grad_norm": 0.06101825833320618,
      "learning_rate": 3.0444444444444444e-06,
      "loss": 0.0018,
      "step": 21130
    },
    {
      "epoch": 0.9395555555555556,
      "grad_norm": 0.19260522723197937,
      "learning_rate": 3.0222222222222225e-06,
      "loss": 0.0018,
      "step": 21140
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.18160992860794067,
      "learning_rate": 3e-06,
      "loss": 0.0018,
      "step": 21150
    },
    {
      "epoch": 0.9404444444444444,
      "grad_norm": 0.3045293390750885,
      "learning_rate": 2.977777777777778e-06,
      "loss": 0.0019,
      "step": 21160
    },
    {
      "epoch": 0.9408888888888889,
      "grad_norm": 0.10259491205215454,
      "learning_rate": 2.9555555555555557e-06,
      "loss": 0.0018,
      "step": 21170
    },
    {
      "epoch": 0.9413333333333334,
      "grad_norm": 0.2753993570804596,
      "learning_rate": 2.9333333333333333e-06,
      "loss": 0.0018,
      "step": 21180
    },
    {
      "epoch": 0.9417777777777778,
      "grad_norm": 0.2753499150276184,
      "learning_rate": 2.9111111111111114e-06,
      "loss": 0.0021,
      "step": 21190
    },
    {
      "epoch": 0.9422222222222222,
      "grad_norm": 0.26146969199180603,
      "learning_rate": 2.888888888888889e-06,
      "loss": 0.002,
      "step": 21200
    },
    {
      "epoch": 0.9426666666666667,
      "grad_norm": 0.10020726919174194,
      "learning_rate": 2.8666666666666666e-06,
      "loss": 0.0017,
      "step": 21210
    },
    {
      "epoch": 0.9431111111111111,
      "grad_norm": 0.5775408744812012,
      "learning_rate": 2.8444444444444446e-06,
      "loss": 0.0019,
      "step": 21220
    },
    {
      "epoch": 0.9435555555555556,
      "grad_norm": 0.09878885746002197,
      "learning_rate": 2.8222222222222223e-06,
      "loss": 0.0018,
      "step": 21230
    },
    {
      "epoch": 0.944,
      "grad_norm": 0.1942024976015091,
      "learning_rate": 2.8000000000000003e-06,
      "loss": 0.0022,
      "step": 21240
    },
    {
      "epoch": 0.9444444444444444,
      "grad_norm": 0.11261455714702606,
      "learning_rate": 2.777777777777778e-06,
      "loss": 0.002,
      "step": 21250
    },
    {
      "epoch": 0.9448888888888889,
      "grad_norm": 0.20780722796916962,
      "learning_rate": 2.7555555555555555e-06,
      "loss": 0.0017,
      "step": 21260
    },
    {
      "epoch": 0.9453333333333334,
      "grad_norm": 0.3867283761501312,
      "learning_rate": 2.7333333333333336e-06,
      "loss": 0.0018,
      "step": 21270
    },
    {
      "epoch": 0.9457777777777778,
      "grad_norm": 0.1936013251543045,
      "learning_rate": 2.711111111111111e-06,
      "loss": 0.0015,
      "step": 21280
    },
    {
      "epoch": 0.9462222222222222,
      "grad_norm": 0.4254770278930664,
      "learning_rate": 2.6888888888888892e-06,
      "loss": 0.0017,
      "step": 21290
    },
    {
      "epoch": 0.9466666666666667,
      "grad_norm": 0.24780964851379395,
      "learning_rate": 2.666666666666667e-06,
      "loss": 0.0019,
      "step": 21300
    },
    {
      "epoch": 0.9471111111111111,
      "grad_norm": 0.3901631236076355,
      "learning_rate": 2.6444444444444444e-06,
      "loss": 0.0017,
      "step": 21310
    },
    {
      "epoch": 0.9475555555555556,
      "grad_norm": 0.124822236597538,
      "learning_rate": 2.6222222222222225e-06,
      "loss": 0.002,
      "step": 21320
    },
    {
      "epoch": 0.948,
      "grad_norm": 0.2214801162481308,
      "learning_rate": 2.6e-06,
      "loss": 0.002,
      "step": 21330
    },
    {
      "epoch": 0.9484444444444444,
      "grad_norm": 0.17869932949543,
      "learning_rate": 2.5777777777777777e-06,
      "loss": 0.0016,
      "step": 21340
    },
    {
      "epoch": 0.9488888888888889,
      "grad_norm": 0.11193916946649551,
      "learning_rate": 2.5555555555555557e-06,
      "loss": 0.0019,
      "step": 21350
    },
    {
      "epoch": 0.9493333333333334,
      "grad_norm": 0.38528504967689514,
      "learning_rate": 2.5333333333333334e-06,
      "loss": 0.0017,
      "step": 21360
    },
    {
      "epoch": 0.9497777777777778,
      "grad_norm": 0.13987532258033752,
      "learning_rate": 2.5111111111111114e-06,
      "loss": 0.0016,
      "step": 21370
    },
    {
      "epoch": 0.9502222222222222,
      "grad_norm": 0.37255948781967163,
      "learning_rate": 2.488888888888889e-06,
      "loss": 0.0016,
      "step": 21380
    },
    {
      "epoch": 0.9506666666666667,
      "grad_norm": 0.12452079355716705,
      "learning_rate": 2.4666666666666666e-06,
      "loss": 0.0019,
      "step": 21390
    },
    {
      "epoch": 0.9511111111111111,
      "grad_norm": 0.050528381019830704,
      "learning_rate": 2.4444444444444447e-06,
      "loss": 0.002,
      "step": 21400
    },
    {
      "epoch": 0.9515555555555556,
      "grad_norm": 0.45375484228134155,
      "learning_rate": 2.4222222222222223e-06,
      "loss": 0.0019,
      "step": 21410
    },
    {
      "epoch": 0.952,
      "grad_norm": 0.12583090364933014,
      "learning_rate": 2.4000000000000003e-06,
      "loss": 0.0022,
      "step": 21420
    },
    {
      "epoch": 0.9524444444444444,
      "grad_norm": 0.12584519386291504,
      "learning_rate": 2.377777777777778e-06,
      "loss": 0.0018,
      "step": 21430
    },
    {
      "epoch": 0.9528888888888889,
      "grad_norm": 0.6178209185600281,
      "learning_rate": 2.3555555555555555e-06,
      "loss": 0.0016,
      "step": 21440
    },
    {
      "epoch": 0.9533333333333334,
      "grad_norm": 0.12371495366096497,
      "learning_rate": 2.3333333333333336e-06,
      "loss": 0.0018,
      "step": 21450
    },
    {
      "epoch": 0.9537777777777777,
      "grad_norm": 0.22012585401535034,
      "learning_rate": 2.311111111111111e-06,
      "loss": 0.0019,
      "step": 21460
    },
    {
      "epoch": 0.9542222222222222,
      "grad_norm": 0.16697539389133453,
      "learning_rate": 2.2888888888888892e-06,
      "loss": 0.0017,
      "step": 21470
    },
    {
      "epoch": 0.9546666666666667,
      "grad_norm": 0.04022059217095375,
      "learning_rate": 2.266666666666667e-06,
      "loss": 0.0019,
      "step": 21480
    },
    {
      "epoch": 0.9551111111111111,
      "grad_norm": 0.22039835155010223,
      "learning_rate": 2.2444444444444445e-06,
      "loss": 0.0017,
      "step": 21490
    },
    {
      "epoch": 0.9555555555555556,
      "grad_norm": 0.4124866724014282,
      "learning_rate": 2.2222222222222225e-06,
      "loss": 0.002,
      "step": 21500
    },
    {
      "epoch": 0.956,
      "grad_norm": 0.3713434934616089,
      "learning_rate": 2.2e-06,
      "loss": 0.0019,
      "step": 21510
    },
    {
      "epoch": 0.9564444444444444,
      "grad_norm": 0.06032261252403259,
      "learning_rate": 2.1777777777777777e-06,
      "loss": 0.0018,
      "step": 21520
    },
    {
      "epoch": 0.9568888888888889,
      "grad_norm": 0.20690524578094482,
      "learning_rate": 2.1555555555555558e-06,
      "loss": 0.0019,
      "step": 21530
    },
    {
      "epoch": 0.9573333333333334,
      "grad_norm": 0.04585586488246918,
      "learning_rate": 2.1333333333333334e-06,
      "loss": 0.0018,
      "step": 21540
    },
    {
      "epoch": 0.9577777777777777,
      "grad_norm": 0.019743138924241066,
      "learning_rate": 2.1111111111111114e-06,
      "loss": 0.0018,
      "step": 21550
    },
    {
      "epoch": 0.9582222222222222,
      "grad_norm": 0.2767736613750458,
      "learning_rate": 2.088888888888889e-06,
      "loss": 0.0018,
      "step": 21560
    },
    {
      "epoch": 0.9586666666666667,
      "grad_norm": 0.08757154643535614,
      "learning_rate": 2.0666666666666666e-06,
      "loss": 0.0016,
      "step": 21570
    },
    {
      "epoch": 0.9591111111111111,
      "grad_norm": 0.15373800694942474,
      "learning_rate": 2.0444444444444447e-06,
      "loss": 0.0018,
      "step": 21580
    },
    {
      "epoch": 0.9595555555555556,
      "grad_norm": 0.36547666788101196,
      "learning_rate": 2.0222222222222223e-06,
      "loss": 0.0021,
      "step": 21590
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.1111510619521141,
      "learning_rate": 2.0000000000000003e-06,
      "loss": 0.0017,
      "step": 21600
    },
    {
      "epoch": 0.9604444444444444,
      "grad_norm": 0.4124929904937744,
      "learning_rate": 1.9777777777777775e-06,
      "loss": 0.0018,
      "step": 21610
    },
    {
      "epoch": 0.9608888888888889,
      "grad_norm": 0.3567846715450287,
      "learning_rate": 1.9555555555555556e-06,
      "loss": 0.0017,
      "step": 21620
    },
    {
      "epoch": 0.9613333333333334,
      "grad_norm": 0.09908810257911682,
      "learning_rate": 1.9333333333333336e-06,
      "loss": 0.0021,
      "step": 21630
    },
    {
      "epoch": 0.9617777777777777,
      "grad_norm": 0.1791871041059494,
      "learning_rate": 1.9111111111111112e-06,
      "loss": 0.002,
      "step": 21640
    },
    {
      "epoch": 0.9622222222222222,
      "grad_norm": 0.29376158118247986,
      "learning_rate": 1.888888888888889e-06,
      "loss": 0.0017,
      "step": 21650
    },
    {
      "epoch": 0.9626666666666667,
      "grad_norm": 0.28901028633117676,
      "learning_rate": 1.8666666666666669e-06,
      "loss": 0.0017,
      "step": 21660
    },
    {
      "epoch": 0.9631111111111111,
      "grad_norm": 0.05702256038784981,
      "learning_rate": 1.8444444444444445e-06,
      "loss": 0.0016,
      "step": 21670
    },
    {
      "epoch": 0.9635555555555556,
      "grad_norm": 0.19311289489269257,
      "learning_rate": 1.8222222222222223e-06,
      "loss": 0.0017,
      "step": 21680
    },
    {
      "epoch": 0.964,
      "grad_norm": 0.04255777597427368,
      "learning_rate": 1.8e-06,
      "loss": 0.0017,
      "step": 21690
    },
    {
      "epoch": 0.9644444444444444,
      "grad_norm": 0.0306099820882082,
      "learning_rate": 1.777777777777778e-06,
      "loss": 0.0016,
      "step": 21700
    },
    {
      "epoch": 0.9648888888888889,
      "grad_norm": 0.03334355726838112,
      "learning_rate": 1.7555555555555558e-06,
      "loss": 0.0021,
      "step": 21710
    },
    {
      "epoch": 0.9653333333333334,
      "grad_norm": 0.0490419939160347,
      "learning_rate": 1.7333333333333334e-06,
      "loss": 0.0025,
      "step": 21720
    },
    {
      "epoch": 0.9657777777777777,
      "grad_norm": 0.0583837628364563,
      "learning_rate": 1.7111111111111112e-06,
      "loss": 0.0021,
      "step": 21730
    },
    {
      "epoch": 0.9662222222222222,
      "grad_norm": 0.0861753448843956,
      "learning_rate": 1.6888888888888888e-06,
      "loss": 0.0016,
      "step": 21740
    },
    {
      "epoch": 0.9666666666666667,
      "grad_norm": 0.16643384099006653,
      "learning_rate": 1.6666666666666667e-06,
      "loss": 0.002,
      "step": 21750
    },
    {
      "epoch": 0.9671111111111111,
      "grad_norm": 0.19414600729942322,
      "learning_rate": 1.6444444444444447e-06,
      "loss": 0.0019,
      "step": 21760
    },
    {
      "epoch": 0.9675555555555555,
      "grad_norm": 0.35770317912101746,
      "learning_rate": 1.622222222222222e-06,
      "loss": 0.0017,
      "step": 21770
    },
    {
      "epoch": 0.968,
      "grad_norm": 0.02278445102274418,
      "learning_rate": 1.6000000000000001e-06,
      "loss": 0.002,
      "step": 21780
    },
    {
      "epoch": 0.9684444444444444,
      "grad_norm": 0.1661674678325653,
      "learning_rate": 1.577777777777778e-06,
      "loss": 0.0016,
      "step": 21790
    },
    {
      "epoch": 0.9688888888888889,
      "grad_norm": 0.16628152132034302,
      "learning_rate": 1.5555555555555556e-06,
      "loss": 0.0018,
      "step": 21800
    },
    {
      "epoch": 0.9693333333333334,
      "grad_norm": 0.13957807421684265,
      "learning_rate": 1.5333333333333334e-06,
      "loss": 0.0022,
      "step": 21810
    },
    {
      "epoch": 0.9697777777777777,
      "grad_norm": 0.24735137820243835,
      "learning_rate": 1.5111111111111112e-06,
      "loss": 0.0017,
      "step": 21820
    },
    {
      "epoch": 0.9702222222222222,
      "grad_norm": 0.3023903965950012,
      "learning_rate": 1.488888888888889e-06,
      "loss": 0.0016,
      "step": 21830
    },
    {
      "epoch": 0.9706666666666667,
      "grad_norm": 0.07875300943851471,
      "learning_rate": 1.4666666666666667e-06,
      "loss": 0.002,
      "step": 21840
    },
    {
      "epoch": 0.9711111111111111,
      "grad_norm": 0.0387883186340332,
      "learning_rate": 1.4444444444444445e-06,
      "loss": 0.0018,
      "step": 21850
    },
    {
      "epoch": 0.9715555555555555,
      "grad_norm": 0.35921812057495117,
      "learning_rate": 1.4222222222222223e-06,
      "loss": 0.0017,
      "step": 21860
    },
    {
      "epoch": 0.972,
      "grad_norm": 0.15342795848846436,
      "learning_rate": 1.4000000000000001e-06,
      "loss": 0.0015,
      "step": 21870
    },
    {
      "epoch": 0.9724444444444444,
      "grad_norm": 0.027990376576781273,
      "learning_rate": 1.3777777777777778e-06,
      "loss": 0.0018,
      "step": 21880
    },
    {
      "epoch": 0.9728888888888889,
      "grad_norm": 0.18204465508460999,
      "learning_rate": 1.3555555555555556e-06,
      "loss": 0.0017,
      "step": 21890
    },
    {
      "epoch": 0.9733333333333334,
      "grad_norm": 0.4406043589115143,
      "learning_rate": 1.3333333333333334e-06,
      "loss": 0.0017,
      "step": 21900
    },
    {
      "epoch": 0.9737777777777777,
      "grad_norm": 0.4806605279445648,
      "learning_rate": 1.3111111111111112e-06,
      "loss": 0.002,
      "step": 21910
    },
    {
      "epoch": 0.9742222222222222,
      "grad_norm": 0.13958576321601868,
      "learning_rate": 1.2888888888888889e-06,
      "loss": 0.0018,
      "step": 21920
    },
    {
      "epoch": 0.9746666666666667,
      "grad_norm": 0.2614002227783203,
      "learning_rate": 1.2666666666666667e-06,
      "loss": 0.002,
      "step": 21930
    },
    {
      "epoch": 0.9751111111111112,
      "grad_norm": 0.5909057855606079,
      "learning_rate": 1.2444444444444445e-06,
      "loss": 0.002,
      "step": 21940
    },
    {
      "epoch": 0.9755555555555555,
      "grad_norm": 0.13907977938652039,
      "learning_rate": 1.2222222222222223e-06,
      "loss": 0.0019,
      "step": 21950
    },
    {
      "epoch": 0.976,
      "grad_norm": 0.2628645598888397,
      "learning_rate": 1.2000000000000002e-06,
      "loss": 0.0019,
      "step": 21960
    },
    {
      "epoch": 0.9764444444444444,
      "grad_norm": 0.04876915365457535,
      "learning_rate": 1.1777777777777778e-06,
      "loss": 0.0019,
      "step": 21970
    },
    {
      "epoch": 0.9768888888888889,
      "grad_norm": 0.07668550312519073,
      "learning_rate": 1.1555555555555556e-06,
      "loss": 0.0025,
      "step": 21980
    },
    {
      "epoch": 0.9773333333333334,
      "grad_norm": 0.06279957294464111,
      "learning_rate": 1.1333333333333334e-06,
      "loss": 0.0016,
      "step": 21990
    },
    {
      "epoch": 0.9777777777777777,
      "grad_norm": 0.05721060559153557,
      "learning_rate": 1.1111111111111112e-06,
      "loss": 0.0018,
      "step": 22000
    }
  ],
  "logging_steps": 10,
  "max_steps": 22500,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 0.0,
  "train_batch_size": 40,
  "trial_name": null,
  "trial_params": null
}
